<!DOCTYPE html>




<html class="theme-next muse" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Kubernetes,k8s," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="参考：  Kubernetes: https://zh.wikipedia.org/wiki/Kubernetes 官方文档: https://kubernetes.io/docs/ 中文文档: http://docs.kubernetes.org.cn/ GitHub: https://github.com/kubernetes/kubernetes etcd: https://coreos.c">
<meta name="keywords" content="Kubernetes,k8s">
<meta property="og:type" content="article">
<meta property="og:title" content="Kubernetes">
<meta property="og:url" content="https://zhang21.github.io/2018/06/26/Kubernetes/index.html">
<meta property="og:site_name" content="风继续吹">
<meta property="og:description" content="参考：  Kubernetes: https://zh.wikipedia.org/wiki/Kubernetes 官方文档: https://kubernetes.io/docs/ 中文文档: http://docs.kubernetes.org.cn/ GitHub: https://github.com/kubernetes/kubernetes etcd: https://coreos.c">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/Kubernetes_logo.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/buildingLinuxPackages.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/k8s_dashboard_nodeport.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/k8s_dashboard_forbidden.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/login_view.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/bearer_token.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/kubeconfig.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/admin_user_token.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/admin_user_dashboard.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/pause-container.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/logging-node-level.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/logging-with-node-agent.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/logging-with-streaming-sidecar.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/logging-with-sidecar-agent.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/filebeat-log-collector-arch.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/logging-from-application.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/k8s_extensions.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/k8s_extension_points.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/k8s_extensions_start.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/pod_multi_container.png">
<meta property="og:image" content="https://zhang21.github.io/images/K8s/init_container.png">
<meta property="og:updated_time" content="2018-09-11T10:11:45.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kubernetes">
<meta name="twitter:description" content="参考：  Kubernetes: https://zh.wikipedia.org/wiki/Kubernetes 官方文档: https://kubernetes.io/docs/ 中文文档: http://docs.kubernetes.org.cn/ GitHub: https://github.com/kubernetes/kubernetes etcd: https://coreos.c">
<meta name="twitter:image" content="https://zhang21.github.io/images/K8s/Kubernetes_logo.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.2',
    sidebar: {"position":"left","display":"hide","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://zhang21.github.io/2018/06/26/Kubernetes/"/>





  <title>Kubernetes | 风继续吹</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">风继续吹</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Yesterday, you said tomorrow!</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhang21.github.io/2018/06/26/Kubernetes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhang21">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/leslie.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="风继续吹">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Kubernetes</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-26T11:38:33+08:00">
                2018-06-26
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-09-11T18:11:45+08:00">
                2018-09-11
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DevOps/" itemprop="url" rel="index">
                    <span itemprop="name">DevOps</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/06/26/Kubernetes/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/06/26/Kubernetes/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          
            <div class="post-wordcount">
              
                
                  <span class="post-meta-divider">|</span>
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  62,836
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>参考：</p>
<ul>
<li>Kubernetes: <a href="https://zh.wikipedia.org/wiki/Kubernetes" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/Kubernetes</a></li>
<li>官方文档: <a href="https://kubernetes.io/docs/" target="_blank" rel="noopener">https://kubernetes.io/docs/</a></li>
<li>中文文档: <a href="http://docs.kubernetes.org.cn/" target="_blank" rel="noopener">http://docs.kubernetes.org.cn/</a></li>
<li>GitHub: <a href="https://github.com/kubernetes/kubernetes" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes</a></li>
<li>etcd: <a href="https://coreos.com/etcd/docs/latest/" target="_blank" rel="noopener">https://coreos.com/etcd/docs/latest/</a></li>
<li>flannel: <a href="https://coreos.com/flannel/docs/latest/" target="_blank" rel="noopener">https://coreos.com/flannel/docs/latest/</a></li>
</ul>
<p>环境：</p>
<ul>
<li>CentOS7x86_64</li>
<li>Kubernetes v1.11</li>
</ul>
<p><br><br><br></p>
<a id="more"></a>
<hr>
<p><br></p>
<p><img src="/images/K8s/Kubernetes_logo.png" alt="Kubernetes"></p>
<p><br></p>
<h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p>此章节提供了有关安装k8s和配置k8s集群的相关说明。</p>
<p><br></p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>有几种方式创建k8s集群：</p>
<ul>
<li>minikube(自动部署)</li>
<li>kubeadm(自动部署)</li>
<li>软件包(建议初学者使用此方式)</li>
</ul>
<p><br></p>
<h3 id="使用minikube创建集群"><a href="#使用minikube创建集群" class="headerlink" title="使用minikube创建集群"></a>使用minikube创建集群</h3><p>Using Minikube to Create a Cluster</p>
<p>目标：</p>
<ul>
<li>了解k8s集群是什么</li>
<li>了解Minikube是什么</li>
<li>启动一个k8s集群</li>
</ul>
<p><br></p>
<p><strong>k8s 集群</strong><br>k8s协调一个高度可用的计算机集群，它们连接起来作为一个单元工作 。<br>k8s以更有效的方式自动化跨集群分发和调整应用程序容器。</p>
<p>k8s集群包含两种类型的资源：</p>
<ul>
<li>Master</li>
<li>Nodes</li>
</ul>
<p>Master负责管理集群。它协调集群中的所有活动。<br>Node是工作主机。每个节点有一个Kubelet的Agent，负责管理节点并与Master(API)通信。此外，节点上还应有处理容器操作的工具(如Docker)。生成环境的k8s集群至少有三个节点。<br>用户可通过k8s API直接与集群进行交互。</p>
<p><br></p>
<p>使用Minikube部署集群: <a href="https://github.com/kubernetes/minikube" target="_blank" rel="noopener">https://github.com/kubernetes/minikube</a><br>Minikube是一个工具，它运行一个单节点的k8s集群供开发用户使用。</p>
<p><strong>Linux平台</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 &amp;&amp; \</span><br><span class="line">chmod +x minikube &amp;&amp; \</span><br><span class="line">sudo mv minikube /usr/<span class="built_in">local</span>/bin/</span><br><span class="line"></span><br><span class="line"><span class="comment">##安装kubectl</span></span><br><span class="line">curl -Lo kubectl https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubectl &amp;&amp; \</span><br><span class="line">chmod +x kubectl &amp;&amp; \</span><br><span class="line">sudo mv kubectl /usr/<span class="built_in">local</span>/bin/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">minikube version</span><br><span class="line">minikube start</span><br><span class="line"></span><br><span class="line">kubectl version</span><br><span class="line">kubectl cluster-info</span><br><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h3 id="kubeadm创建集群"><a href="#kubeadm创建集群" class="headerlink" title="kubeadm创建集群"></a>kubeadm创建集群</h3><h4 id="安装kubeadm"><a href="#安装kubeadm" class="headerlink" title="安装kubeadm"></a>安装kubeadm</h4><p>本节介绍了如何安装<strong>kubeadm</strong>工具。</p>
<p><strong>安装前</strong></p>
<ul>
<li>2GB RAM+</li>
<li>2 cpus+</li>
<li>集群主机网络互通</li>
<li>node上唯一的主机名，MAC，UUID</li>
<li>开放特定端口(防火墙)</li>
<li>Swap disabled。必须关闭swap才能使kubelet正常工作。</li>
</ul>
<p><br></p>
<p><strong>验证MAC或UUID对每个node都是唯一的</strong></p>
<ul>
<li><code>ifconfig -a</code>获取MAC</li>
<li><code>cat /sys/class/dmi/id/product_uuid</code>查看UUID</li>
</ul>
<p><br></p>
<p><strong>检查网络适配器</strong></p>
<p>如果k8s组件不可达，请手动添加路由。</p>
<p><br></p>
<p><strong>检查需要的端口</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#master</span><br><span class="line">Protocol    Direction	Port Range	Purpose					Used By</span><br><span class="line">TCP    Inbound		6443*		Kubernetes API server	All</span><br><span class="line">TCP    Inbound		2379-2380	etcd server client API	kube-apiserver, etcd</span><br><span class="line">TCP    Inbound		10250		Kubelet API				Self, Control plane</span><br><span class="line">TCP    Inbound		10251		kube-scheduler			Self</span><br><span class="line">TCP	   Inbound		10252		kube-controller-manager	Self</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#worker</span><br><span class="line">Protocol	Direction	Port Range	Purpose			Used By</span><br><span class="line">TCP		Inbound		10250		Kubelet API		Self, Control plane</span><br><span class="line">TCP		Inbound		30000-32767	NodePort Services**	All</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>安装docker</strong><br>使用阿里云镜像。<br><code>kubeadm v1.11.1</code>最高支持<code>Docker 17.03</code>，请注意。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line">mv docker-ce.repo /etc/yum.repos.d</span><br><span class="line"></span><br><span class="line">yum install -y docker-ce.x84_64</span><br><span class="line"></span><br><span class="line"><span class="comment">#由于kubeadm不支持最新版的docker，所以需要安装指定版本</span></span><br><span class="line">yum list docker-ce --showduplicates</span><br><span class="line"></span><br><span class="line">yum install -y docker-ce-17.03.2.ce</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>安装kubeadm, kubelet, kubectl</strong></p>
<ul>
<li>kubeadm: 引导集群</li>
<li>kubelet: k8s agent</li>
<li>kubectl: command line</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建repo</span></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment">#国外镜像凉凉，所以换用阿里云</span></span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#禁用防火墙</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#关闭selinux</span></span><br><span class="line">setenforce 0</span><br><span class="line">sed -i <span class="string">"s/^SELINUX=permissive/SELINUX=disabled/g"</span> /etc/selinux/config</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#关闭swap，否则kubelet无法正常使用</span></span><br><span class="line">swapoff -a</span><br><span class="line"><span class="comment">#将/etc/fstab中swap注释掉</span></span><br><span class="line">sed -i <span class="string">'s/.*swap.*/#&amp;/'</span> /etc/fstab</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#安装</span></span><br><span class="line">yum install -y epel-release ebtables ethtool</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">yum install -y kubelet kubeadm kubectl</span><br><span class="line">systemctl <span class="built_in">enable</span> kubelet &amp;&amp; systemctl start kubelet</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#系统配置，开启网络桥接</span></span><br><span class="line">cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment">#生效</span></span><br><span class="line">sysctl -p /etc/sysctl.d/k8s.conf</span><br><span class="line">sysctl --system</span><br><span class="line">systemctl daemon-reload</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#各主机时区，时间同步</span></span><br><span class="line">timedatectl <span class="built_in">set</span>-timezone Asia/Shanghai</span><br><span class="line"></span><br><span class="line"><span class="comment">#crontab -e</span></span><br><span class="line"><span class="comment">#ntp</span></span><br><span class="line">*/30 * * * * /sbin/ntpdate 1.cn.pool.ntp.org &gt; /dev/null 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#hosts</span></span><br><span class="line">&lt;master-ip&gt; master</span><br><span class="line">&lt;node-ip&gt; node</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>配置cgroup driver</strong><br>使用docker时，kubelet会将其驱动设置与Docker相同。kubeadm会自动检查kubelet的cgroup驱动，并在运行时将其设置到<code>/var/lib/kubelet/kubeadm-flags.env</code>文件。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">docker info | grep -i <span class="string">'cgroup driver'</span></span><br><span class="line">Cgroup Driver: systemd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#此文件是kubeadm init生成的</span></span><br><span class="line">cat /var/lib/kubelet/kubeadm-flags.env</span><br><span class="line">KUBELET_KUBEADM_ARGS=--cgroup-driver=systemd --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#如果此文件未配置此信息，我们手动添加</span></span><br><span class="line"><span class="built_in">cd</span> /etc/systemd/system/kubelet.service.d</span><br><span class="line">vim 10-kubeadm.conf</span><br><span class="line">KUBELET_KUBEADM_ARGS=--cgroup-driver=systemd --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="拉取k8s-gcr-io镜像"><a href="#拉取k8s-gcr-io镜像" class="headerlink" title="拉取k8s.gcr.io镜像"></a>拉取k8s.gcr.io镜像</h4><p>链接: <a href="https://console.cloud.google.com/gcr/images/google-containers/GLOBAL?location=GLOBAL&amp;project=google-containers" target="_blank" rel="noopener">https://console.cloud.google.com/gcr/images/google-containers/GLOBAL?location=GLOBAL&amp;project=google-containers</a></p>
<p>利用某台能上网的主机，拉取Google上kubeadm需要的<code>k8s.gcr.io/image</code>镜像。</p>
<p><br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br></pre></td><td class="code"><pre><span class="line">#查看kubeadm需要使用的image</span><br><span class="line">kubeadm config images list</span><br><span class="line"></span><br><span class="line">k8s.gcr.io/kube-apiserver-amd64:v1.11.1</span><br><span class="line">k8s.gcr.io/kube-controller-manager-amd64:v1.11.1</span><br><span class="line">k8s.gcr.io/kube-scheduler-amd64:v1.11.1</span><br><span class="line">k8s.gcr.io/kube-proxy-amd64:v1.11.1</span><br><span class="line">k8s.gcr.io/pause-amd64:3.1</span><br><span class="line">k8s.gcr.io/etcd-amd64:3.2.18</span><br><span class="line">k8s.gcr.io/coredns:1.1.3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#最好把所有镜像都拉下来，否则后面初始化的时候容易报错</span><br><span class="line">#在gcr.io上查找镜像</span><br><span class="line">#浏览器访问: &lt;https://console.cloud.google.com/gcr/images/google-containers/GLOBAL?location=GLOBAL&amp;project=google-containers&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#找一台能用的服务器，将这些image拉下来，推到自己的repo上再在kubeadm机器上拉取镜像，之后tag成kubeadm需要的格式</span><br><span class="line">#写一个脚本自动拉取镜像，更名镜像，推送镜像</span><br><span class="line">#我基本上把全部镜像都拉了</span><br><span class="line">vim k8sImages.sh</span><br><span class="line"></span><br><span class="line">images=(</span><br><span class="line">coredns:1.1.3</span><br><span class="line">etcd-amd64:3.1.15</span><br><span class="line">etcd-amd64:3.1.16</span><br><span class="line">etcd-amd64:3.1.17</span><br><span class="line">etcd-amd64:3.2.17</span><br><span class="line">etcd-amd64:3.2.18</span><br><span class="line">flannel-amd64:0.5.5</span><br><span class="line">heapster-amd64:v1.4.0</span><br><span class="line">heapster-amd64:v1.4.1</span><br><span class="line">heapster-amd64:v1.4.2</span><br><span class="line">heapster-amd64:v1.4.3</span><br><span class="line">heapster-amd64:v1.5.0</span><br><span class="line">heapster-amd64:v1.5.1</span><br><span class="line">heapster-amd64:v1.5.2</span><br><span class="line">heapster-amd64:v1.5.3</span><br><span class="line">heapster-amd64:v1.5.4</span><br><span class="line">heapster-grafana-amd64:v4.4.3</span><br><span class="line">heapster-grafana-amd64:v5.0.4</span><br><span class="line">heapster-influxdb-amd64:v1.3.3</span><br><span class="line">heapster-influxdb-amd64:v1.5.2</span><br><span class="line">k8s-dns-dnsmasq-nanny-amd64:1.14.10</span><br><span class="line">k8s-dns-dnsmasq-nanny-amd64:1.14.6</span><br><span class="line">k8s-dns-dnsmasq-nanny-amd64:1.14.7</span><br><span class="line">k8s-dns-dnsmasq-nanny-amd64:1.14.8</span><br><span class="line">k8s-dns-dnsmasq-nanny-amd64:1.14.9</span><br><span class="line">k8s-dns-kube-dns-amd64:1.14.10</span><br><span class="line">k8s-dns-kube-dns-amd64:1.14.5</span><br><span class="line">k8s-dns-kube-dns-amd64:1.14.6</span><br><span class="line">k8s-dns-kube-dns-amd64:1.14.7</span><br><span class="line">k8s-dns-kube-dns-amd64:1.14.8</span><br><span class="line">k8s-dns-kube-dns-amd64:1.14.9</span><br><span class="line">k8s-dns-sidecar-amd64:1.14.10</span><br><span class="line">k8s-dns-sidecar-amd64:1.14.5</span><br><span class="line">k8s-dns-sidecar-amd64:1.14.6</span><br><span class="line">k8s-dns-sidecar-amd64:1.14.7</span><br><span class="line">k8s-dns-sidecar-amd64:1.14.8</span><br><span class="line">k8s-dns-sidecar-amd64:1.14.9</span><br><span class="line">kube-apiserver-amd64:v1.10.5</span><br><span class="line">kube-apiserver-amd64:v1.10.6</span><br><span class="line">kube-apiserver-amd64:v1.11.0</span><br><span class="line">kube-apiserver-amd64:v1.11.1</span><br><span class="line">kube-apiserver-amd64:v1.9.10</span><br><span class="line">kube-controller-manager-amd64:v1.10.5</span><br><span class="line">kube-controller-manager-amd64:v1.10.6</span><br><span class="line">kube-controller-manager-amd64:v1.11.0</span><br><span class="line">kube-controller-manager-amd64:v1.11.1</span><br><span class="line">kube-controller-manager-amd64:v1.9.10</span><br><span class="line">kube-proxy-amd64:v1.10.6</span><br><span class="line">kube-proxy-amd64:v1.11.0</span><br><span class="line">kube-proxy-amd64:v1.11.1</span><br><span class="line">kube-proxy-amd64:v1.9.10</span><br><span class="line">kubernetes-dashboard-amd64:v1.6.2</span><br><span class="line">kubernetes-dashboard-amd64:v1.6.3</span><br><span class="line">kubernetes-dashboard-amd64:v1.7.0</span><br><span class="line">kubernetes-dashboard-amd64:v1.7.1</span><br><span class="line">kubernetes-dashboard-amd64:v1.8.0</span><br><span class="line">kubernetes-dashboard-amd64:v1.8.1</span><br><span class="line">kubernetes-dashboard-amd64:v1.8.2</span><br><span class="line">kubernetes-dashboard-amd64:v1.8.3</span><br><span class="line">kube-scheduler-amd64:v1.10.6</span><br><span class="line">kube-scheduler-amd64:v1.11.0</span><br><span class="line">kube-scheduler-amd64:v1.11.1</span><br><span class="line">kube-scheduler-amd64:v1.9.10</span><br><span class="line">pause-amd64:3.0</span><br><span class="line">pause-amd64:3.1</span><br><span class="line">pause:3.1</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">#可能pause与pause-amd64是一个，到时只需拉一个，然后tag</span><br><span class="line"></span><br><span class="line">for image in $&#123;images[@]&#125;</span><br><span class="line">do</span><br><span class="line">    docker pull k8s.gcr.io/$&#123;image&#125;</span><br><span class="line">    docker tag k8s.gcr.io/$&#123;image&#125; zhang21/$&#123;image&#125;</span><br><span class="line">    docker image rm k8s.gcr.io/$&#123;image&#125;</span><br><span class="line">    docker push zhang21/$&#123;image&#125;</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#查看</span><br><span class="line">docker image ls</span><br><span class="line"></span><br><span class="line">#到我的docker-hub中查看</span><br><span class="line">#https://hub.docker.com/u/zhang21/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#现在在kubeadm集群机器上操作</span><br><span class="line">#还是写一个脚本来拉取镜像，更名镜像，删除镜像</span><br><span class="line">vim k8sImage.sh</span><br><span class="line"></span><br><span class="line">images=(</span><br><span class="line">coredns:1.1.3</span><br><span class="line">etcd-amd64:3.1.15</span><br><span class="line">etcd-amd64:3.1.16</span><br><span class="line">etcd-amd64:3.1.17</span><br><span class="line">etcd-amd64:3.2.17</span><br><span class="line">etcd-amd64:3.2.18</span><br><span class="line">flannel-amd64:0.5.5</span><br><span class="line">heapster-amd64:v1.4.0</span><br><span class="line">heapster-amd64:v1.4.1</span><br><span class="line">heapster-amd64:v1.4.2</span><br><span class="line">heapster-amd64:v1.4.3</span><br><span class="line">heapster-amd64:v1.5.0</span><br><span class="line">heapster-amd64:v1.5.1</span><br><span class="line">heapster-amd64:v1.5.2</span><br><span class="line">heapster-amd64:v1.5.3</span><br><span class="line">heapster-amd64:v1.5.4</span><br><span class="line">heapster-grafana-amd64:v4.4.3</span><br><span class="line">heapster-grafana-amd64:v5.0.4</span><br><span class="line">heapster-influxdb-amd64:v1.3.3</span><br><span class="line">heapster-influxdb-amd64:v1.5.2</span><br><span class="line">k8s-dns-dnsmasq-nanny-amd64:1.14.10</span><br><span class="line">k8s-dns-dnsmasq-nanny-amd64:1.14.6</span><br><span class="line">k8s-dns-dnsmasq-nanny-amd64:1.14.7</span><br><span class="line">k8s-dns-dnsmasq-nanny-amd64:1.14.8</span><br><span class="line">k8s-dns-dnsmasq-nanny-amd64:1.14.9</span><br><span class="line">k8s-dns-kube-dns-amd64:1.14.10</span><br><span class="line">k8s-dns-kube-dns-amd64:1.14.5</span><br><span class="line">k8s-dns-kube-dns-amd64:1.14.6</span><br><span class="line">k8s-dns-kube-dns-amd64:1.14.7</span><br><span class="line">k8s-dns-kube-dns-amd64:1.14.8</span><br><span class="line">k8s-dns-kube-dns-amd64:1.14.9</span><br><span class="line">k8s-dns-sidecar-amd64:1.14.10</span><br><span class="line">k8s-dns-sidecar-amd64:1.14.5</span><br><span class="line">k8s-dns-sidecar-amd64:1.14.6</span><br><span class="line">k8s-dns-sidecar-amd64:1.14.7</span><br><span class="line">k8s-dns-sidecar-amd64:1.14.8</span><br><span class="line">k8s-dns-sidecar-amd64:1.14.9</span><br><span class="line">kube-apiserver-amd64:v1.10.5</span><br><span class="line">kube-apiserver-amd64:v1.10.6</span><br><span class="line">kube-apiserver-amd64:v1.11.0</span><br><span class="line">kube-apiserver-amd64:v1.11.1</span><br><span class="line">kube-apiserver-amd64:v1.9.10</span><br><span class="line">kube-controller-manager-amd64:v1.10.5</span><br><span class="line">kube-controller-manager-amd64:v1.10.6</span><br><span class="line">kube-controller-manager-amd64:v1.11.0</span><br><span class="line">kube-controller-manager-amd64:v1.11.1</span><br><span class="line">kube-controller-manager-amd64:v1.9.10</span><br><span class="line">kube-proxy-amd64:v1.10.6</span><br><span class="line">kube-proxy-amd64:v1.11.0</span><br><span class="line">kube-proxy-amd64:v1.11.1</span><br><span class="line">kube-proxy-amd64:v1.9.10</span><br><span class="line">kubernetes-dashboard-amd64:v1.6.2</span><br><span class="line">kubernetes-dashboard-amd64:v1.6.3</span><br><span class="line">kubernetes-dashboard-amd64:v1.7.0</span><br><span class="line">kubernetes-dashboard-amd64:v1.7.1</span><br><span class="line">kubernetes-dashboard-amd64:v1.8.0</span><br><span class="line">kubernetes-dashboard-amd64:v1.8.1</span><br><span class="line">kubernetes-dashboard-amd64:v1.8.2</span><br><span class="line">kubernetes-dashboard-amd64:v1.8.3</span><br><span class="line">kube-scheduler-amd64:v1.10.6</span><br><span class="line">kube-scheduler-amd64:v1.11.0</span><br><span class="line">kube-scheduler-amd64:v1.11.1</span><br><span class="line">kube-scheduler-amd64:v1.9.10</span><br><span class="line">pause-amd64:3.0</span><br><span class="line">pause-amd64:3.1</span><br><span class="line">pause:3.1</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">for image in $&#123;images[@]&#125;</span><br><span class="line">do</span><br><span class="line">    docker pull zhang21/$&#123;image&#125;</span><br><span class="line">    docker tag zhang21/$&#123;image&#125; k8s.gcr.io/$&#123;image&#125;</span><br><span class="line">    docker image rm zhang21/$&#123;image&#125;</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#查看</span><br><span class="line">docker image ls</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="创建单master集群"><a href="#创建单master集群" class="headerlink" title="创建单master集群"></a>创建单master集群</h4><p><code>kubeadm</code>可帮助你引导符合最佳实践的最小化可行的k8s集群。使用<code>kubeadm</code>，你的集群应通过k8s一致性测试。<code>kubeadm</code>还支持其它集群生命周期功能，如升级、降级和管理引导令牌(bootstrap token)。<br><code>kubeadm</code>旨在成为新用户开始尝试k8s的一种简单方法。可使用deb/rpm软件包在系统上轻松安装<code>kubeadm</code>。<br>因为你可在各种类型的机器上安装<code>kubeadm</code>，所以它非常适合于Ansible/Salt等配置系统集成。</p>
<p><code>kubeadm</code>的简单性意味着它可以服务于各种用例：</p>
<ul>
<li>新用户可以从<code>kubeadm</code>开始，第一次尝试k8s</li>
<li>熟悉k8s的用户可以使用<code>kubeadm</code>启动集群，并测试他们的应用程序</li>
<li>较大的项目可以包括<code>kubeadm</code>作为更复杂系统中的构件，也可以包括其它安装程序工具</li>
</ul>
<p>kubeadm Maturity(成熟度)</p>
<table>
<thead>
<tr>
<th>Area</th>
<th>Maturity Level</th>
</tr>
</thead>
<tbody>
<tr>
<td>Command line UX</td>
<td>beta</td>
</tr>
<tr>
<td>Implementation</td>
<td>beta</td>
</tr>
<tr>
<td>Config file API</td>
<td>alpha</td>
</tr>
<tr>
<td>Self-hosting</td>
<td>alpha</td>
</tr>
<tr>
<td>kubeadm alpha subcommands</td>
<td>alpha</td>
</tr>
<tr>
<td>CoreDNS</td>
<td>GA</td>
</tr>
<tr>
<td>DynamicKubeletConfig</td>
<td>alpha</td>
</tr>
</tbody>
</table>
<p>kubeadm的整体功能状态为Beta，并将很快添加到GA(General Availability)。一些子功能，如自托管(self-hosting)和配置文件API仍在积极开发中。</p>
<p>k8s版本通常支持九个月，这也适用于kubeadm。</p>
<table>
<thead>
<tr>
<th>Kubernetes version</th>
<th>Release month</th>
<th>End-of-life-month</th>
</tr>
</thead>
<tbody>
<tr>
<td>v1.6.x</td>
<td>March 2017</td>
<td>December 2017</td>
</tr>
<tr>
<td>v1.7.x</td>
<td>June 2017</td>
<td>March 2018</td>
</tr>
<tr>
<td>v1.8.x</td>
<td>September 2017</td>
<td>June 2018</td>
</tr>
<tr>
<td>v1.9.x</td>
<td>December 2017</td>
<td>September 2018</td>
</tr>
<tr>
<td>v1.10.x</td>
<td>March 2018</td>
<td>December 2018</td>
</tr>
<tr>
<td>v1.11.x</td>
<td>June 2018</td>
<td>March 2019</td>
</tr>
</tbody>
</table>
<p><br></p>
<p><strong>开始前</strong></p>
<ul>
<li>一台或多台主机</li>
<li>2GB+ RAM(每台机器)</li>
<li>2CPUs+(master)</li>
<li>网络互通</li>
</ul>
<p><br></p>
<p><strong>目标</strong></p>
<ul>
<li>安装 <strong>单master/高可用性</strong> 的k8s集群</li>
<li>在集群上安装pod-network，以便pod间可互相通信</li>
</ul>
<p><br></p>
<p><strong>组件</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#Master</span><br><span class="line">etcd</span><br><span class="line">kube-apisever</span><br><span class="line">kube-controller-manager</span><br><span class="line">kube-scheduler</span><br><span class="line">kube-flannel</span><br><span class="line">kube-proxy</span><br><span class="line">kube-dns</span><br><span class="line">kubectl</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#Node</span><br><span class="line">kube-flannel</span><br><span class="line">kube-proxy</span><br><span class="line">kubectl</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>说明</strong></p>
<ul>
<li>安装kubeadm<br>如已安装，可升级到最新版。</li>
</ul>
<p><br></p>
<ul>
<li>初始化集群<br>master主机是控制组件运行的地方，包括<code>etcd</code>, <code>API server</code>…</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#1</span><br><span class="line">#选择一个 pod network add-on，并验证是够需要将任何参数传递给kubeadm初始化。你可以使用--pod-network-cidr来指定特定值</span><br><span class="line">#这里使用flannel</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#2，可选</span><br><span class="line">#除非另有说明，否则kubeadm使用与默认网关关联的网络接口来通告master</span><br><span class="line">#使用kubeadm init --apiserver-advertise-address=&lt;ip-addr&gt;来使用不同网络接口</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#3，可选</span><br><span class="line">#在kubeadm init之前运行kubeadm config images pull以验证与gcr.io的连接</span><br><span class="line">#或kubeadm config images list查看需要的镜像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#运行</span><br><span class="line">kubeadm init &lt;args&gt;</span><br></pre></td></tr></table></figure>
<p><br></p>
<ul>
<li>更多信息<br><code>kubeadm init</code>首先运行一系列检查，以确保机器 已准备好运行k8s。这些预检查会显示警告并退出错误。然后<code>kubeadm init</code>下载并安装集群控制组件。这可能需要一些时间。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br></pre></td><td class="code"><pre><span class="line">kubeadm --help</span><br><span class="line">kubeadm init --help</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#k8s底层环境依赖于Docker</span><br><span class="line">#on master</span><br><span class="line">systemctl enable docker kubelet &amp;&amp; systemctl start docker</span><br><span class="line">kubeadm init</span><br><span class="line"></span><br><span class="line">I0806 14:04:54.415853    2191 feature_gate.go:230] feature gates: &amp;&#123;map[]&#125;</span><br><span class="line">[init] using Kubernetes version: v1.11.1</span><br><span class="line">[preflight] running pre-flight checks</span><br><span class="line">        [WARNING Service-Docker]: docker service is not enabled, please run &apos;systemctl enable docker.service&apos;</span><br><span class="line">I0806 14:04:54.433879    2191 kernel_validator.go:81] Validating kernel version</span><br><span class="line">I0806 14:04:54.433934    2191 kernel_validator.go:96] Validating kernel config</span><br><span class="line">[preflight/images] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight/images] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight/images] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[preflight] Some fatal errors occurred:</span><br><span class="line">        [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-apiserver-amd64:v1.11.1]: exit status 1</span><br><span class="line">        [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-controller-manager-amd64:v1.11.1]: exit status 1</span><br><span class="line">        [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-scheduler-amd64:v1.11.1]: exit status 1</span><br><span class="line">        [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-proxy-amd64:v1.11.1]: exit status 1</span><br><span class="line">        [ERROR ImagePull]: failed to pull image [k8s.gcr.io/pause-amd64:3.1]: exit status 1</span><br><span class="line">        [ERROR ImagePull]: failed to pull image [k8s.gcr.io/etcd-amd64:3.2.18]: exit status 1</span><br><span class="line">        [ERROR ImagePull]: failed to pull image [k8s.gcr.io/coredns:1.1.3]: exit status 1</span><br><span class="line">[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#此处错误，由于镜像在Google，国内访问会超时。因此需要额外准备镜像。</span><br><span class="line">#需要做上面一步操作来拉取镜像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#初始化</span><br><span class="line">#请确保资源满足条件，我就是由于VM内存为1GB而导致初始化失败，找了很久才找到这个错误</span><br><span class="line"></span><br><span class="line">kubeadm init --kubernetes-version=v1.11.1 --pod-network-cidr=10.244.0.0/16</span><br><span class="line"></span><br><span class="line">[init] using Kubernetes version: v1.11.1</span><br><span class="line">[preflight] running pre-flight checks</span><br><span class="line">I0807 14:47:10.658405   10612 kernel_validator.go:81] Validating kernel version</span><br><span class="line">I0807 14:47:10.658484   10612 kernel_validator.go:96] Validating kernel config</span><br><span class="line">[preflight/images] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight/images] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight/images] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class="line">[kubelet] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[preflight] Activating the kubelet service</span><br><span class="line">[certificates] Generated ca certificate and key.</span><br><span class="line">[certificates] Generated apiserver certificate and key.</span><br><span class="line">[certificates] apiserver serving cert is signed for DNS names [master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.31.49]</span><br><span class="line">[certificates] Generated apiserver-kubelet-client certificate and key.</span><br><span class="line">[certificates] Generated sa key and public key.</span><br><span class="line">[certificates] Generated front-proxy-ca certificate and key.</span><br><span class="line">[certificates] Generated front-proxy-client certificate and key.</span><br><span class="line">[certificates] Generated etcd/ca certificate and key.</span><br><span class="line">[certificates] Generated etcd/server certificate and key.</span><br><span class="line">[certificates] etcd/server serving cert is signed for DNS names [master localhost] and IPs [127.0.0.1 ::1]</span><br><span class="line">[certificates] Generated etcd/peer certificate and key.</span><br><span class="line">[certificates] etcd/peer serving cert is signed for DNS names [master localhost] and IPs [192.168.31.49 127.0.0.1 ::1]</span><br><span class="line">[certificates] Generated etcd/healthcheck-client certificate and key.</span><br><span class="line">[certificates] Generated apiserver-etcd-client certificate and key.</span><br><span class="line">[certificates] valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/admin.conf&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/kubelet.conf&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/controller-manager.conf&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/scheduler.conf&quot;</span><br><span class="line">[controlplane] wrote Static Pod manifest for component kube-apiserver to &quot;/etc/kubernetes/manifests/kube-apiserver.yaml&quot;</span><br><span class="line">[controlplane] wrote Static Pod manifest for component kube-controller-manager to &quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&quot;</span><br><span class="line">[controlplane] wrote Static Pod manifest for component kube-scheduler to &quot;/etc/kubernetes/manifests/kube-scheduler.yaml&quot;</span><br><span class="line">[etcd] Wrote Static Pod manifest for a local etcd instance to &quot;/etc/kubernetes/manifests/etcd.yaml&quot;</span><br><span class="line">[init] waiting for the kubelet to boot up the control plane as Static Pods from directory &quot;/etc/kubernetes/manifests&quot; </span><br><span class="line">[init] this might take a minute or longer if the control plane images have to be pulled</span><br><span class="line">[apiclient] All control plane components are healthy after 42.001662 seconds</span><br><span class="line">[uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.11&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class="line">[markmaster] Marking the node master as master by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class="line">[markmaster] Marking the node master as master by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;master&quot; as an annotation</span><br><span class="line">[bootstraptoken] using token: uzdl9x.91uu2p155jczkgb3</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class="line">[bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes master has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of machines by running the following on each node</span><br><span class="line">as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 192.168.31.49:6443 --token uzdl9x.91uu2p155jczkgb3 --discovery-token-ca-cert-hash sha256:bc5af0f4fbee0d0500c9d6782a279ee172ed45547a006136bfbad93d61ad39c7</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#root用户</span><br><span class="line">#一定要记得做此步骤，由于kubeadm设置的apiserver的监听端口为6443，而不是8080，所以执行会报错。</span><br><span class="line">export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line">#之后，可将其写入/etc/profile</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#安装pod-network</span><br><span class="line">#你必须先安装pod network add-on，才能和pod相互通信。</span><br><span class="line">#必须在应用程序之前部署网络。</span><br><span class="line">#配置flannel</span><br><span class="line">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.10.0/Documentation/kube-flannel.yml</span><br><span class="line">#如果无法访问，可将此文件下载到本地</span><br><span class="line">#kubectl apply -f /etc/kubernetes/kube-flannel.yml</span><br><span class="line"></span><br><span class="line">clusterrole.rbac.authorization.k8s.io/flannel created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/flannel created</span><br><span class="line">serviceaccount/flannel created</span><br><span class="line">configmap/kube-flannel-cfg created</span><br><span class="line">daemonset.extensions/kube-flannel-ds created</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#token用于master与node之间相互认证，它是加密的。</span><br><span class="line">#使用kubeadm token列出、创建和删除token</span><br><span class="line">#kubeadm token create</span><br><span class="line">#kubeadm token list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#on node</span><br><span class="line">#kubeadm join</span><br><span class="line">#kubeadm join --token xxxxxxxxxxx host:port</span><br><span class="line">systemctl enable kubelet docker &amp;&amp; systemctl start docker</span><br><span class="line">kubeadm join 192.168.31.49:6443 --token uzdl9x.91uu2p155jczkgb3 --discovery-token-ca-cert-hash sha256:bc5af0f4fbee0d0500c9d6782a279ee172ed45547a006136bfbad93d61ad39c7</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#测试</span><br><span class="line">kubectl get node</span><br><span class="line"></span><br><span class="line">NAME      STATUS    ROLES     AGE       VERSION</span><br><span class="line">master    Ready     master    48m       v1.11.1</span><br><span class="line">node      Ready     &lt;none&gt;    15m       v1.11.1</span><br><span class="line"></span><br><span class="line">#查看</span><br><span class="line">kubectl get pods --all-namespaces -o wide</span><br><span class="line">NAMESPACE     NAME                             READY     STATUS    RESTARTS   AGE       IP               NODE</span><br><span class="line">kube-system   coredns-78fcdf6894-hn46d         1/1       Running   0          52m       10.244.0.3       master</span><br><span class="line">kube-system   coredns-78fcdf6894-wqxbx         1/1       Running   0          52m       10.244.0.2       master</span><br><span class="line">kube-system   etcd-master                      1/1       Running   0          41m       192.168.31.49    master</span><br><span class="line">kube-system   kube-apiserver-master            1/1       Running   0          41m       192.168.31.49    master</span><br><span class="line">kube-system   kube-controller-manager-master   1/1       Running   0          41m       192.168.31.49    master</span><br><span class="line">kube-system   kube-flannel-ds-7gbvd            1/1       Running   0          41m       192.168.31.49    master</span><br><span class="line">kube-system   kube-flannel-ds-ktkxp            1/1       Running   0          19m       192.168.31.174   node</span><br><span class="line">kube-system   kube-proxy-pw7gz                 1/1       Running   0          19m       192.168.31.174   node</span><br><span class="line">kube-system   kube-proxy-rhrks                 1/1       Running   0          52m       192.168.31.49    master</span><br><span class="line">kube-system   kube-scheduler-master            1/1       Running   0          41m       192.168.31.49    master</span><br></pre></td></tr></table></figure>
<p><br></p>
<ul>
<li>master isolation<br>默认情况下，出于安全原因，你的集群不会在master上调度pod。如果你想在master上调度pod，对于单master的k8s集群，执行如下命令：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#从拥有它的节点删除node-role.kubernetes.io/master污染</span><br><span class="line">kubectl taint nodes --all node-role.kubernetes.io/master-</span><br></pre></td></tr></table></figure>
<p><br></p>
<ul>
<li>加入节点<br>要向集群添加新节点，请为每台计算机执行以下操作：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#node</span><br><span class="line"></span><br><span class="line">#root/sudo</span><br><span class="line"></span><br><span class="line">#kubeadm init后执行下命令</span><br><span class="line">#kubeadm token list</span><br><span class="line">kubeadm join --token &lt;token&gt; &lt;master-ip&gt;:&lt;master-port&gt; --discovery-token-ca-cert-hash sha256:&lt;hash&gt;</span><br></pre></td></tr></table></figure>
<p><br></p>
<ul>
<li>从master之外控制集群(可选)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp root@&lt;master-ip&gt;:/etc/kubernetes/admin.conf .</span><br><span class="line">kubeclt --kubeconfig ./admin.conf get nodes</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>局限性</strong><br>此处创建的集群只有一个master，其上运行一个etcd数据库。这意味着如果master出现故障，你的集群可能会丢失数据。可考虑向k8s添加高可用支持。</p>
<p><br><br><br></p>
<h4 id="使用kubeadm配置kubelet"><a href="#使用kubeadm配置kubelet" class="headerlink" title="使用kubeadm配置kubelet"></a>使用kubeadm配置kubelet</h4><p>Configuring each kubelet in your cluster using kubeadm</p>
<p><code>kubeadm CLI</code>工具的生命周期与<code>Kubernetes Node  Agent(kubelet)</code>相分离，kubelet是运行在k8s集群master/node上的守护进程，它始终在后台运行。而<code>kubeadm CLI</code>工具由用户执行。<br>由于<code>kubelet</code>是一个守护进程，它需要由<code>init system</code>或服务管理器来维护。Redhat7上使用<code>systemd</code>来进行管理。<br>在集群设计的kubelet中，一些kubelet配置细节需相同；而其它方面则需要在每台机器的kubelet上单独配置。你可以手动管理kubelet配置，但kubeadm现在提供了一个<code>MaterConfig API</code>来集中管理kubelet配置。</p>
<p>注意，本节是利用<code>kubeadm</code>来配置<code>kubelet</code>，而不是手动配置<code>kubelet</code>。</p>
<p><br></p>
<p><strong>kubelet配置模式</strong></p>
<ul>
<li>将集群级别配置传播到每个kubelet<br>kubelet提供了一个版本化、结构化的API对象，可配置kubelet中大多数参数，并将此配置推送到集群中所有正在运行的kubelet。它被称为  the kubelet’s ComponentConfig(组件配置)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#为kubelet提供默认值。</span><br><span class="line">kubeadm init</span><br><span class="line">kubeadm join</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#修改服务默认子网</span><br><span class="line">kubeadm init --service-cidr 10.96.0.0/12</span><br><span class="line">#现在服务的VIP由此子网分配</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#还需要设置kubelet使用的DNS地址，每个kubelet必须相同</span><br><span class="line">--cluster-dns</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#componentConfig</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">clusterDNS:</span><br><span class="line">  - 10.96.0.10</span><br></pre></td></tr></table></figure>
<p><br></p>
<ul>
<li>提供特定实例的配置细节<br>由于不同硬件、操作系统、网络…，一些主机需要特定的kubelet配置。<br>由于我是使用<code>systemd</code>管理kubelet，所以可相应的修改对应的值。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">#DNS解析文件路径，如果路径错误，则在kubelet配置错误的节点上DNS将解析失败</span><br><span class="line">--resolve-conf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#节点API对象，默认被设置为主机名</span><br><span class="line">.metadata.name</span><br><span class="line">#使用如下标志指定节点名来服务默认值</span><br><span class="line">--hostname-overide</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#目前，kubelet无法自动检查CRI runtime的cgroup driver</span><br><span class="line">#指定的驱动请与docker保持一致</span><br><span class="line">--cgroup-driver</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#根据集群使用的CRI runtime，可能需要为kubelet指定不同的标志</span><br><span class="line">#如，当使用Docker时，你需要指定如 --network-plugin=cni</span><br><span class="line">#但，当使用额外runtime，你需要指定 --container-runtime=remote, --container-runtime-path-endpoint=&lt;path&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#systemd</span><br><span class="line">cd /etc/systemd/system/kubelet.service.d/</span><br><span class="line">vim 10-kubeadm.conf</span><br><span class="line">#修改具体配置项</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#EnvFile</span><br><span class="line">vim /var/lib/kubelet/kubeadm-flags.env</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">systemctl daemon-reload &amp;&amp; systemctl restart kubelet</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>使用kubeadm配置kubelet</strong><br><code>kubeadm config API</code>的<code>MasterConfiguration</code>类型，嵌入了<code>kubelet&#39;s ComponentConfig</code>到<code>.kubeletConfiguration.baseConfig</code>键下面。任何用户都可编写<code>MasterConfiguration</code>文件使用此配置键为集群中的所有kubelet设置基本配置。</p>
<ul>
<li>使用<code>kubeadm init</code>的工作流程(workflow)<br>当调用<code>kubeadm init</code>时，<code>.kubeletConfiguration.baseConfig</code>结构被整理到磁盘<code>/var/lib/kubelet/config.yaml</code>，并且上传到集群中的<code>ConfigMap</code>。ConfigMap名为<code>kubelet-config-1.x</code>，<code>.x</code>表示k8s的次要版本。kubelet配置文件同样被写入<code>/etc/kubernetes/kubelet.conf</code>。此配置文件指向允许kubelet与API server通信的客户端证书。</li>
</ul>
<p>为了解决特定实例的配置细节的模式，<code>kubeadm</code>将环境文件写入<code>/var/lib/kubelet/kubeadm-flags.env</code>，它包含了在启动时传递给kubelet的许多标志。它还包含许多动态参数(如cgroup driver)。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#标志栗子</span><br><span class="line">KUBELET_KUBEADM_ARGS=&quot;--flag1=value1, --flag2=value2 ...&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#在将这两个文件整理到磁盘后，kubeadm会尝试运行如下两个命令</span><br><span class="line">systemctl daemon-reload &amp;&amp; systemctl restart kubelet</span><br><span class="line"></span><br><span class="line">#在上面两个命令执行成功后，初始化会继续</span><br></pre></td></tr></table></figure>
<p><br></p>
<ul>
<li>使用<code>kubeadm join</code>的工作流程<br>当运行<code>kubeadm join</code>命令时，kubeadm使用Bootstrap Token凭据执行TLS bootstrap，它下载<code>kubelet-config-1.x</code> ConfigMap并将其写入<code>/var/lib/kubelet/config.yaml</code>。动态环境文件<code>/vat/lib/kubelet/kubeadm-flags.env</code>的生成方式与<code>kubeadm init</code>完成相同。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#同样，执行这两条命令</span><br><span class="line">systemctl daemon-reload &amp;&amp; systemctl restart kubelet</span><br></pre></td></tr></table></figure>
<p>在kubelet载入新的配置文件后，kubeadm会写入<code>/etc/kubernetes/bootstrap-kubelet.conf</code> KubeConfig文件，该文件包含CA证书和Bootstrap Token。这些由kubelet用于执行TLS Bootstrap并获得唯一的凭证，该凭证存储在<code>/etc/kubernetes/kubelet.conf</code>中。<br>写入文件后，kubelet完成执行TLS Bootstrap.</p>
<p><br></p>
<p><strong>systemd的kubelet管理文件</strong><br>此配置文件在RPM包安装的时候写入<code>/etc/systemd/system/kubelet.service.d/10-kubeadm.conf</code>，它由<code>systemd</code>使用。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/systemd/system/kubelet.service.d/10-kubeadm.conf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Note: This dropin only works with kubeadm and kubelet v1.11+</span><br><span class="line">[Service]</span><br><span class="line">Environment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf&quot;</span><br><span class="line">Environment=&quot;KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml&quot;</span><br><span class="line"># This is a file that &quot;kubeadm init&quot; and &quot;kubeadm join&quot; generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically</span><br><span class="line">EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env</span><br><span class="line"># This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use</span><br><span class="line"># the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file.</span><br><span class="line">EnvironmentFile=-/etc/sysconfig/kubelet</span><br><span class="line">ExecStart=</span><br><span class="line">ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#此文件指定kubeadm为kubelet管理的所有文件的默认位置</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#TLS Bootstrap</span><br><span class="line">/etc/kubernetes/bootstrap-kubelet.conf</span><br><span class="line"></span><br><span class="line">#unique kubelet identity</span><br><span class="line">/etc/kubernetes/kubelet.conf</span><br><span class="line"></span><br><span class="line">#kubelet&apos;s ComponentConfig</span><br><span class="line">/var/lib/kubelet/config.yaml</span><br><span class="line"></span><br><span class="line">#dynamic env file, KUBELET_KUBEADM_ARGS</span><br><span class="line">/var/lib/kubelt/kubeadm-flags.env</span><br><span class="line"></span><br><span class="line">#user-specified  flag overrides, KUBELET_EXTRA_ARGS, 它具有最高优先级</span><br><span class="line">/etc/sysconfig/kubelet</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>k8s 二进制文件和包内容</strong></p>
<p>k8s release附带的DEB和RPM包：</p>
<table>
<thead>
<tr>
<th>Package name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>kubeadm</td>
<td>Installs the /usr/bin/kubeadm CLI tool and [The kubelet drop-in file(#the-kubelet-drop-in-file-for-systemd) for the kubelet.</td>
</tr>
<tr>
<td>kubelet</td>
<td>Installs the /usr/bin/kubelet binary.</td>
</tr>
<tr>
<td>kubectl</td>
<td>Installs the /usr/bin/kubectl binary.</td>
</tr>
<tr>
<td>kubernetes-cni</td>
<td>Installs the official CNI binaries into the /opt/cni/bin directory.</td>
</tr>
<tr>
<td>cri-tools</td>
<td>Installs the /usr/bin/crictl binary from <a href="https://github.com/kubernetes-incubator/cri-tools" target="_blank" rel="noopener">https://github.com/kubernetes-incubator/cri-tools</a>.</td>
</tr>
</tbody>
</table>
<p><br><br><br></p>
<h4 id="使用kubeadm自定义控制面板配置"><a href="#使用kubeadm自定义控制面板配置" class="headerlink" title="使用kubeadm自定义控制面板配置"></a>使用kubeadm自定义控制面板配置</h4><p>Customizing control plane configuration with kubeadm</p>
<p><code>kubeadm</code>配置公开以下字段，这些字段可覆盖传递给控制面板组件的默认标志：</p>
<ul>
<li>APIServerExtraArgs</li>
<li>ControllerManagerExtraArgs</li>
<li>SchedulerExtraArgs</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">#apiserver</span><br><span class="line">#栗子</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1alpha2</span><br><span class="line">kind: MasterConfiguration</span><br><span class="line">kubernetesVersion: v1.11.0</span><br><span class="line">metadata:</span><br><span class="line">  name: 1.11-sample</span><br><span class="line">apiServerExtraArgs:</span><br><span class="line">  advertise-address: 192.168.0.103</span><br><span class="line">  anonymous-auth: false</span><br><span class="line">  enable-admission-plugins: AlwaysPullImages,DefaultStorageClass</span><br><span class="line">  audit-log-path: /home/johndoe/audit.log</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#controllermanager</span><br><span class="line">#栗子</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1alpha2</span><br><span class="line">kind: MasterConfiguration</span><br><span class="line">kubernetesVersion: v1.11.0</span><br><span class="line">metadata:</span><br><span class="line">  name: 1.11-sample</span><br><span class="line">controllerManagerExtraArgs:</span><br><span class="line">  cluster-signing-key-file: /home/johndoe/keys/ca.key</span><br><span class="line">  bind-address: 0.0.0.0</span><br><span class="line">  deployment-controller-sync-period: 50</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#scheduler</span><br><span class="line">#栗子</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1alpha2</span><br><span class="line">kind: MasterConfiguration</span><br><span class="line">kubernetesVersion: v1.11.0</span><br><span class="line">metadata:</span><br><span class="line">  name: 1.11-sample</span><br><span class="line">schedulerExtraArgs:</span><br><span class="line">  address: 0.0.0.0</span><br><span class="line">  config: /home/johndoe/schedconfig.yaml</span><br><span class="line">  kubeconfig: /home/johndoe/kubeconfig.yaml</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="使用kubeadm创建高可用集群"><a href="#使用kubeadm创建高可用集群" class="headerlink" title="使用kubeadm创建高可用集群"></a>使用kubeadm创建高可用集群</h4><p>Creating Highly Available Clusters with kubeadm</p>
<p><br><br><br></p>
<h4 id="使用kubeadm配置etcd高可用集群"><a href="#使用kubeadm配置etcd高可用集群" class="headerlink" title="使用kubeadm配置etcd高可用集群"></a>使用kubeadm配置etcd高可用集群</h4><p>Set up a Highly Availabile etcd Cluster With kubeadm</p>
<p><br><br><br></p>
<h4 id="Troubleshooting-kubeadm"><a href="#Troubleshooting-kubeadm" class="headerlink" title="Troubleshooting kubeadm"></a>Troubleshooting kubeadm</h4><p>官方Troubleshooting: <a href="https://kubernetes.io/docs/setup/independent/troubleshooting-kubeadm/" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/independent/troubleshooting-kubeadm/</a></p>
<p><br></p>
<p>此外，在我启动<code>kubelet</code>之后，<code>kubelet</code>频繁出现一个错误信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#错误信息</span><br><span class="line">#journal -u kubelet</span><br><span class="line">kubelet[10720]: E0810 14:32:14.748713   10720 summary.go:102] Failed to get system container stats for &quot;/system.slice/kubelet.service&quot;: failed to get cgroup stats for &quot;/system.slice/kubelet.service&quot;: failed to get container info for &quot;/system.slice/kubelet.service&quot;: unknown container &quot;/system.slice/kubelet.service&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#解决方法</span><br><span class="line">vim /etc/sysconfig/kubelet</span><br><span class="line"></span><br><span class="line">#添加额外参数</span><br><span class="line">KUBELET_EXTRA_ARGS=&quot;--runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#重启服务</span><br><span class="line">systemctl restart kubelet</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h3 id="使用软件包创建集群"><a href="#使用软件包创建集群" class="headerlink" title="使用软件包创建集群"></a>使用软件包创建集群</h3><p>请定义相应的防火墙规则！</p>
<p>我是CentOS7x86_64，所以只包含了RPM包。</p>
<p>自带的源安装的k8s可能版本比较老，如需较新版本，可以在网上搜索kubernetes rpm包进行手动安装。<br>Rpmfind: <a href="https://rpmfind.net/" target="_blank" rel="noopener">https://rpmfind.net/</a></p>
<p><br></p>
<p><strong>k8s集群组件</strong></p>
<ul>
<li>etcd</li>
<li>flannel</li>
<li>kube-apiserver</li>
<li>kube-controller-manager</li>
<li>kube-scheduler</li>
<li>kubelet</li>
<li>kube-proxy</li>
<li>kube-dns</li>
<li>kubectl</li>
</ul>
<p><br></p>
<p><strong>Master</strong></p>
<ul>
<li>etcd</li>
<li>flannel</li>
<li>kube-apiserver</li>
<li>kube-controller-manager</li>
<li>kube-scheduler</li>
<li>kubectl</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#默认镜像源安装</span></span><br><span class="line">yum install -y etcd flannel kubernetes-master kubernetes-client</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置kubernetes-master</span></span><br><span class="line"><span class="comment">#cd /etc/kubernetes</span></span><br><span class="line"><span class="comment">#apiserver  config  controller-manager  scheduler</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#修改监听地址</span></span><br><span class="line">vim apiserver</span><br><span class="line">KUBE_API_ADDRESS=<span class="string">"--insecure-bind-address=0.0.0.0"</span></span><br><span class="line"><span class="comment">#生成环境一定要加上认证，我由于是测试，并未做认证</span></span><br><span class="line"><span class="comment">#未添加认证，去掉 KUBE_ADMISSION_CONTROL中的SecurityContextDeny,ServiceAccount</span></span><br><span class="line"><span class="comment">#Flag --admission-control has been deprecated, Use --enable-admission-plugins or --disable-admission-plugins instead.</span></span><br><span class="line"><span class="comment">#KUBE_ADMISSION_CONTROL="--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota"</span></span><br><span class="line">KUBE_ADMISSION_CONTROL=<span class="string">"--enable-admission-plugins=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#此处我修改了cidr</span></span><br><span class="line">KUBE_SERVICE_ADDRESSES=<span class="string">"--service-cluster-ip-range=172.16.0.0/16"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置etcd，可先使用默认值</span></span><br><span class="line"><span class="comment">#后面可创建etcd-cluster</span></span><br><span class="line">vim /etc/etcd/etcd.conf</span><br><span class="line"><span class="comment">#修改监听地址</span></span><br><span class="line">ETCD_LISTEN_CLIENT_URLS=<span class="string">"http://0.0.0.0:2379"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建pod-network，cidr为kube-apiserver中的配置项</span></span><br><span class="line"><span class="comment">#/atomic.io/network为flannel_etcd前缀,之后再启动flannel</span></span><br><span class="line">etcdctl mk /atomic.io/network/config <span class="string">'&#123;"Network":"172.16.0.0/16"&#125;'</span></span><br><span class="line">etcdctl ls</span><br><span class="line">etcdctl get <span class="string">'/atomic.io/network/config'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置flannel</span></span><br><span class="line">vim /etc/sysconfig/flanneld</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置后启动</span></span><br><span class="line">systemctl start etcd flannel kube-apiserver kube-controller-manager kube-scheduler</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看</span></span><br><span class="line">[root@master kubernetes]<span class="comment"># kubectl get all</span></span><br><span class="line">NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">service/kubernetes   ClusterIP   172.16.0.1   &lt;none&gt;        443/TCP   4m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#具体参数请根据实际情况来配置</span></span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>Node</strong></p>
<ul>
<li>flannel</li>
<li>kubelet</li>
<li>kube-porxy</li>
<li>kubectl</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#epel</span></span><br><span class="line">yum install -y flannel kubernetes-node kubernetes-client</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#ls /etc/kubertes</span></span><br><span class="line"><span class="comment">#config  kubelet  proxy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置etcd的地址</span></span><br><span class="line">vim /etc/sysconfig/flanneld</span><br><span class="line">FLANNEL_ETCD_ENDPOINTS=<span class="string">"http://master:2379</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">vim /etc/kubernertes/config</span></span><br><span class="line"><span class="string">KUBE_MASTER="</span>--master=http://master:8080<span class="string">"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#修改kubelet地址</span></span><br><span class="line"><span class="string">KUBELET_ADDRESS="</span>--address=node_addr<span class="string">"</span></span><br><span class="line"><span class="string">KUBELET_HOSTNAME="</span>--hostname-override=node_addr<span class="string">"</span></span><br><span class="line"><span class="string">KUBELET_API_SERVER="</span>--api-servers=http://master:8080<span class="string">"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#配置后启动</span></span><br><span class="line"><span class="string">systemctl start flanneld kube-proxy kubelet</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#具体参数请根据实际情况来配置</span></span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>验证集群</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#Master</span><br><span class="line">#kubectl安装如前</span><br><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>安装较新的k8s</strong><br>由于自带的源k8s版本比较低，可能我们需要较新的k8s版本。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#安装较新的Kubernetes</span><br><span class="line"></span><br><span class="line">浏览器访问 https://rpmfind.net/</span><br><span class="line"></span><br><span class="line">搜索：</span><br><span class="line">kubernetes-master(x86-64)</span><br><span class="line">kubernetes-node(x86-64)</span><br><span class="line">kubernetes-client(x86-64)</span><br><span class="line"></span><br><span class="line">选择合适的版本进行下载，三者版本请一致</span><br><span class="line">安装步骤和下面类似</span><br><span class="line"></span><br><span class="line">请注意，k8s组件安装好后，还需要安装额外组件。</span><br><span class="line">如docker, flannel, etcd...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#master</span><br><span class="line">yum install -y k8s-master k8s-client</span><br><span class="line"></span><br><span class="line">#node</span><br><span class="line">yum install -y k8s-node k8s-client</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h3 id="k8s-release生成rpm包"><a href="#k8s-release生成rpm包" class="headerlink" title="k8s-release生成rpm包"></a>k8s-release生成rpm包</h3><p>kubernetes-release: <a href="https://github.com/kubernetes/release" target="_blank" rel="noopener">https://github.com/kubernetes/release</a></p>
<p>使用k8s-release手动生成rpm/dep包。<br>由于yum源更不上k8s的更新速度，所以才需要我们手动制作。</p>
<p>需要安装并运行Docker，它要运行一个<code>rpm-builder</code>容器。</p>
<p>它生成一下rpm包：</p>
<ul>
<li>kubeadm</li>
<li>kubelet</li>
<li>kubectl</li>
</ul>
<p><br></p>
<p>官方说明：</p>
<p><img src="/images/K8s/buildingLinuxPackages.png" alt="官方"></p>
<p><br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/kubernetes/release.git</span><br><span class="line"></span><br><span class="line">cd ./release/rpm</span><br><span class="line">./docker-build.sh</span><br><span class="line"></span><br><span class="line">#此处如果连接google下载超时的话，可以在其它主机上下载，然后复制到此目录下</span><br><span class="line"></span><br><span class="line">#成功</span><br><span class="line"></span><br><span class="line">----------------------------------------</span><br><span class="line"></span><br><span class="line">RPMs written to:</span><br><span class="line">cri-tools-1.11.0-0.x86_64.rpm  kubectl-1.11.0-0.x86_64.rpm  kubernetes-cni-0.6.0-0.x86_64.rpm</span><br><span class="line">kubeadm-1.11.0-0.x86_64.rpm    kubelet-1.11.0-0.x86_64.rpm  repodata</span><br><span class="line"></span><br><span class="line">Yum repodata written to:</span><br><span class="line">5e470d3c1c28cdd798237a48172b46f753655edee30988f4fde7000fde859d5a-primary.xml.gz</span><br><span class="line">9497c84e5650b15bf6edcffb68900b4f59f7271fa6318d3c0336386c99afd2d8-other.xml.gz</span><br><span class="line">94da9da6abd2dc8364ef51b4ca135b804deef0a37f1f13e4abeee455a8b0e897-primary.sqlite.bz2</span><br><span class="line">971e5af9d861f5ba85b12bad481749aa26546051090fa4e21c2393c21590dd5a-filelists.xml.gz</span><br><span class="line">b752df67070ff5552bd3137f00fb217578f1d810084a3e42579a53eee2a26085-other.sqlite.bz2</span><br><span class="line">f0ec7692c0654c1ec5ad9c8576ebe5b8f135c45b5d5242066df6e2d631a3ef6f-filelists.sqlite.bz2</span><br><span class="line">repomd.xml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#会在./release/rpm/output/x86_64下生成特定版本的rpm包</span><br><span class="line">pwd</span><br><span class="line">#/root/release/rpm/output/x86_64</span><br><span class="line"></span><br><span class="line">ls -l</span><br><span class="line">total 47056</span><br><span class="line">-rw-r--r-- 1 root root  4383318 Aug  3 10:25 cri-tools-1.11.0-0.x86_64.rpm</span><br><span class="line">-rw-r--r-- 1 root root  7906382 Aug  3 10:25 kubeadm-1.11.0-0.x86_64.rpm</span><br><span class="line">-rw-r--r-- 1 root root  7859238 Aug  3 10:25 kubectl-1.11.0-0.x86_64.rpm</span><br><span class="line">-rw-r--r-- 1 root root 19012182 Aug  3 10:25 kubelet-1.11.0-0.x86_64.rpm</span><br><span class="line">-rw-r--r-- 1 root root  9008530 Aug  3 10:25 kubernetes-cni-0.6.0-0.x86_64.rpm</span><br><span class="line">drwxr-xr-x 2 root root     4096 Aug  3 10:25 repodata</span><br></pre></td></tr></table></figure>
<p>请注意，默认会自动编译所有平台。如果只需要<code>x84_64</code>，可以更改<code>entry.sh</code>文件，将其它平台去掉，以加快编译速度。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim ./release/rpm/entry.sh</span><br><span class="line"></span><br><span class="line">  ARCHS=(</span><br><span class="line">    amd64/x86_64</span><br><span class="line">    #arm/armhfp</span><br><span class="line">    #arm64/aarch64</span><br><span class="line">    #ppc64le/ppc64le</span><br><span class="line">    #s390x/s390x</span><br><span class="line">  )</span><br></pre></td></tr></table></figure>
<p>后面还是需要使用<code>kubeadm</code>来进行引导！</p>
<p><br><br><br></p>
<h3 id="编译源码生成rpm包"><a href="#编译源码生成rpm包" class="headerlink" title="编译源码生成rpm包"></a>编译源码生成rpm包</h3><p>参考：</p>
<ul>
<li>How to build Kubernetes RPM: <a href="https://mritd.me/2017/07/12/how-to-build-kubernetes-rpm/" target="_blank" rel="noopener">https://mritd.me/2017/07/12/how-to-build-kubernetes-rpm/</a></li>
</ul>
<p>由于墙的原因，使用kubeadm进行引导还是会timeout。使用自带的yum源或网上下载的k8s rpm可能也不是最新的版本。因此需要手动编译源码以生成rpm包。</p>
<p>生成如下rpm包：</p>
<ul>
<li>kubernetes-master</li>
<li>kubernetes-client</li>
<li>kubernetes-node</li>
</ul>
<p><br><br><br></p>
<h3 id="k8s-Dashboard"><a href="#k8s-Dashboard" class="headerlink" title="k8s Dashboard"></a>k8s Dashboard</h3><p>说明:</p>
<ul>
<li>GitHub: <a href="https://github.com/kubernetes/dashboard" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard</a></li>
<li>image: kubernetes-dashboard-amd64:v1.8.3</li>
<li>FAQ: <a href="https://github.com/kubernetes/dashboard/wiki/FAQ" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard/wiki/FAQ</a></li>
<li>Let’s Encrypt: <a href="https://letsencrypt.org/" target="_blank" rel="noopener">https://letsencrypt.org/</a></li>
</ul>
<p>Let’s Encrypt是一个免费，自动化和开放的证书颁发机构。</p>
<p><br></p>
<h4 id="快速配置"><a href="#快速配置" class="headerlink" title="快速配置"></a>快速配置</h4><p>Quick setup</p>
<p>快速部署<code>kubernetes-dashboard</code>的方法请参考README。它适用于k8s新手并希望快速开始使用Dashboard的人。其它配置适用于有一定经验的用户，详情在以下章节。</p>
<p>k8s Dashboard是k8s集群的基于Web的通用UI。它允许用户管理运行在集群中的应用程序，并对应用程序进行故障排除，以及管理集群本身。</p>
<p>请注意，Dashboard使用了安全设置。这意味着，默认情况下它具有最小的权限集，并且只能通过https访问。<br>建议在安装和执行Dashboard之前，先阅读<strong><a href="https://github.com/kubernetes/dashboard/wiki/Access-control" target="_blank" rel="noopener">Access Control</a></strong>指南。</p>
<p><br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml</span><br><span class="line"></span><br><span class="line">#或</span><br><span class="line">#wget https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml</span><br><span class="line">#kubectl apply -f /path/kubernetes-dashboard.yaml</span><br><span class="line"></span><br><span class="line">secret/kubernetes-dashboard-certs created</span><br><span class="line">serviceaccount/kubernetes-dashboard created</span><br><span class="line">role.rbac.authorization.k8s.io/kubernetes-dashboard-minimal created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard-minimal created</span><br><span class="line">deployment.apps/kubernetes-dashboard created</span><br><span class="line">service/kubernetes-dashboard created</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#查看</span><br><span class="line">kubectl get pods -n kube-system -o wide |grep dashboard</span><br><span class="line">kubernetes-dashboard-6948bdb78-rnnjp   1/1       Running   1          1d        10.244.1.2       node</span><br><span class="line"></span><br><span class="line"> kubectl get service -n kube-system -o wide |grep dashboard</span><br><span class="line">kubernetes-dashboard   ClusterIP   10.110.83.129   &lt;none&gt;        443/TCP         13m       k8s-app=kubernetes-dashboard</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#要从本地访问Dashboard，必须为k8s集群创建安全通道</span><br><span class="line">kubectl apply</span><br><span class="line">Starting to serve on 127.0.0.1:8001</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#访问Dashboard</span><br><span class="line">http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</span><br><span class="line"></span><br><span class="line">#http://localhost:8001/ui已弃用</span><br><span class="line">#&lt;h3&gt;Unauthorized&lt;/h3&gt;</span><br><span class="line">#会直接报403，还需要做前面所说的操作。</span><br><span class="line"></span><br><span class="line">#Heapster必须在集群中运行才能使metric, graphs可用</span><br><span class="line">#Heapster已被弃用，请考虑使用metrics-server和第三方metrics pipeline收集Prometheus格式的指标</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h4><p>Installation</p>
<p><strong>官方版</strong><br>当从旧版Dashboard升级到 <code>v1.7+</code>，请确保删除<code>kubernetes-dashboard</code>服务账户的集群角色绑定，否则Dashboard将具有对集群的完全管理权限。</p>
<p><br></p>
<p><strong>快速配置</strong><br>快速部署<code>kubernetes-dashboard</code>的方法请参考README。它适用于k8s新手并希望快速开始使用Dashboard的人。</p>
<p><br></p>
<p><strong>推荐配置</strong><br>直接访问Dashboard(不是<code>kubectl proxy</code>)，应该使用有效的证书来建立安全的HTTPS连接。它们可由公共可信证书颁发机构(如<a href="https://letsencrypt.org/" target="_blank" rel="noopener">Let’s Encrypt</a>)生成，使用它们替代Dashboard自动生成的证书。</p>
<p>此配置要求证书存储在<code>kube-system</code>命名空间中名为<code>kubernetes-dashboard-certs</code>的证书中。<br>假设你有存储在<code>$HOME/certs</code>目录下的<code>dashboard.crt</code>和<code>dashboard.key</code>文件。你应该使用这些文件创建<code>secret</code>。之后，便可以开始配置Dashboard。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看</span></span><br><span class="line">kubectl get secret -n kube-system | grep dashboard</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看</span></span><br><span class="line">kubectl describe secret/kubernetes-dashboard-certs -n kube-system</span><br><span class="line">Name:         kubernetes-dashboard-certs</span><br><span class="line">Namespace:    kube-system</span><br><span class="line">Labels:       k8s-app=kubernetes-dashboard</span><br><span class="line">Annotations:</span><br><span class="line">Type:         Opaque</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建</span></span><br><span class="line">kubectl create secret generic kubernetes-dashboard-certs --from-file=<span class="variable">$HOME</span>/certs -n kube-system</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#部署Dashboard</span></span><br><span class="line">kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>替代配置</strong><br>此配置并不安全。不使用证书，仅通过HTTP公开Dashboard。在此配置中，只能通过使用<code>Authorization Header</code>功能来确保访问控制。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#配置</span></span><br><span class="line">kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/alternative/kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>开发版</strong><br>不建议在线上环境使用开发版，请使用稳定的正式版。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#部署</span></span><br><span class="line">kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard-head.yaml</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>升级</strong><br>安装后，Deployment不会自动更新。为了更新它，你需要删除部署的pod并等待它重新创建。重新创建之后，它会使用最新的镜像<code>image:latest</code>.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#删除pod</span></span><br><span class="line">kubectl -n kube-system delete $(kubectl -n kube-system get pod -o name | grep dashboard)</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="证书管理"><a href="#证书管理" class="headerlink" title="证书管理"></a>证书管理</h4><p>Certificate management</p>
<p>本节简短介绍了如何获取可在Dashboard中启用HTTPS的证书。有两个步骤要做：</p>
<ul>
<li>生成证书<ul>
<li>证书认证机构(Certificate Authority)</li>
<li>自签名证书(Self-signed certificate)</li>
</ul>
</li>
<li>将证书传递给Dashboard<ul>
<li>按照前面的推荐配置方法</li>
<li>其它情况，你需要修改Dashboard的YAML部署文件，并将<code>--tls-key-file</code>, <code>--tls-cert-file</code>传递给Dashboard</li>
</ul>
</li>
</ul>
<p><br></p>
<p><strong>公众信任的证书认证机构</strong><br>Public trusted Certificate Authority</p>
<p>有许多公共和免费的证书提供商可供选择。如前面提到的<a href="https://letsencrypt.org/" target="_blank" rel="noopener">Let’s encrypt</a>，具体操作查看此网站说明。</p>
<p><br></p>
<p><strong>自签名证书</strong><br>Self-signed certificate</p>
<p>如果你打算自己生成证书，你需要像<a href="https://www.openssl.org/" target="_blank" rel="noopener">OpenSSL</a>这样的库来帮助你。</p>
<ul>
<li>生成私钥(private key)和证书签名请求(certificate signing request)</li>
<li>生成SSL证书</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">#Generate private key and certificate signing request</span><br><span class="line">#创建SSL证书需要私钥和证书签名请求</span><br><span class="line"></span><br><span class="line">openssl genrsa -des3 -passout pass:x -out dashboard.pass.key 2048</span><br><span class="line"></span><br><span class="line">openssl rsa -passin pass:x -in dashboard.pass.key -out dashboard.key</span><br><span class="line"></span><br><span class="line">rm dashboard.pass.key</span><br><span class="line"></span><br><span class="line">#需要填写一些信息</span><br><span class="line">#A challenge password []请直接按回车，不要填写内容</span><br><span class="line">openssl req -new -key dashboard.key -out dashboard.csr</span><br><span class="line"></span><br><span class="line">Country Name (2 letter code) [XX]:CN</span><br><span class="line">State or Province Name (full name) []:SC</span><br><span class="line">Locality Name (eg, city) [Default City]:CD</span><br><span class="line">Organization Name (eg, company) [Default Company Ltd]:Student</span><br><span class="line">Organizational Unit Name (eg, section) []:HT</span><br><span class="line">Common Name (eg, your name or your server&apos;s hostname) []:Zhang21</span><br><span class="line">Email Address []:reds@zhang21.cn</span><br><span class="line"></span><br><span class="line">Please enter the following &apos;extra&apos; attributes</span><br><span class="line">to be sent with your certificate request</span><br><span class="line">A challenge password []:</span><br><span class="line">An optional company name []:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#Generate SSL certificate</span><br><span class="line">#自签名SSL证书由 .key私钥 和 .csr生成</span><br><span class="line">openssl x509 -req -sha256 -days 1000 -in dashboard.csr -signkey dashboard.key -out dashboard.crt</span><br><span class="line"></span><br><span class="line">Signature ok</span><br><span class="line">subject=/C=CN/ST=SC/L=CD/O=Student/OU=HT/CN=Zhang21/emailAddress=reds@zhang21.cn</span><br><span class="line">Getting Private key</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#查看</span><br><span class="line">ls</span><br><span class="line">dashboard.crt  dashboard.csr  dashboard.key</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#将密钥和证书移动到需要的目录下</span><br><span class="line">mv ./dashboard.* /etc/kubernetes/pki/dashboard</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#接下来便可以创建secret了</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="访问Dashboard"><a href="#访问Dashboard" class="headerlink" title="访问Dashboard"></a>访问Dashboard</h4><p>Accessing Dashboard</p>
<p>在集群上安装Dashboard后，可通过几种不同的方式访问它。遇到什么问题，可查看FAQ。</p>
<ul>
<li>1.6.x and below</li>
<li>1.7.x and above</li>
</ul>
<p><br></p>
<h5 id="1-7-x-and-above"><a href="#1-7-x-and-above" class="headerlink" title="1.7.x and above"></a>1.7.x and above</h5><p>Accessing Dashboard 1.7.X and above</p>
<p>我的Dashboard v1.8.5.</p>
<p>前面的HTTP/HTTPs都不说了。<br>但请注意，不要把Dashboard使用HTTP公开展示。</p>
<p><br></p>
<p><strong>kubectl proxy</strong><br><code>kubectl proxy</code>在你的计算机和k8s APIserver之间创建代理服务器。默认情况下它只能在本地访问。</p>
<p>注意，不应该使用<code>kubectl proxy</code>命令公开Dashboard，因为它只允许HTTP连接。对于<code>localhost</code>和<code>127.0.0.1</code>以外的域，将无法登录。</p>
<p>首先让我们检查kubectl是否已正确配置并是否可访问集群:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">kubectl cluster-info</span><br><span class="line"></span><br><span class="line"><span class="comment">#Kubernetes master is running at https://192.168.31.49:6443</span></span><br><span class="line"><span class="comment">#KubeDNS is running at https://192.168.31.49:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#启动代理服务器</span></span><br><span class="line">kubectl proxy</span><br><span class="line"></span><br><span class="line"><span class="comment">#Starting to serve on 127.0.0.1:8001</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#之后你便可以从浏览器访问Dashboard</span></span><br><span class="line"><span class="comment">#http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</span></span><br><span class="line"><span class="comment">#但我访问还是403，应该还需要创建Service Token之类。</span></span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>NodePort</strong><br>这种访问Dashboard的方式，建议用于单节点设置的开发环境中。<br>请注意，此HTTPS方式需要安装前面生成的证书。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#编辑 kubernetes-dashboard服务</span></span><br><span class="line">kubectl -n kube-system edit service/kubernetes-dashboard</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Please edit the object below. Lines beginning with a '#' will be ignored,</span></span><br><span class="line"><span class="comment"># and an empty file will abort the edit. If an error occurs while saving this file will be</span></span><br><span class="line"><span class="comment"># reopened with the relevant failures.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    kubectl.kubernetes.io/last-applied-configuration: |</span><br><span class="line">      &#123;<span class="string">"apiVersion"</span>:<span class="string">"v1"</span>,<span class="string">"kind"</span>:<span class="string">"Service"</span>,<span class="string">"metadata"</span>:&#123;<span class="string">"annotations"</span>:&#123;&#125;,<span class="string">"labels"</span>:&#123;<span class="string">"k8s-app"</span>:<span class="string">"kubernetes-dashboard"</span>&#125;,<span class="string">"name"</span>:<span class="string">"kubernetes-dashboard"</span>,<span class="string">"namespace"</span>:<span class="string">"kube-system"</span>&#125;,<span class="string">"spec"</span>:&#123;<span class="string">"ports"</span>:[&#123;<span class="string">"port"</span>:443,<span class="string">"targetPort"</span>:8443&#125;],<span class="string">"selector"</span>:&#123;<span class="string">"k8s-app"</span>:<span class="string">"kubernetes-dashboard"</span>&#125;&#125;&#125;</span><br><span class="line">  creationTimestamp: 2018-08-09T01:14:01Z</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  resourceVersion: <span class="string">"200618"</span></span><br><span class="line">  selfLink: /api/v1/namespaces/kube-system/services/kubernetes-dashboard</span><br><span class="line">  uid: 80091845-9b71-11e8-a08a-000c298ee39f</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: 10.110.83.129</span><br><span class="line">  ports:</span><br><span class="line">  - port: 443</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 8443</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  sessionAffinity: None</span><br><span class="line">  <span class="built_in">type</span>: ClusterIP</span><br><span class="line">status:</span><br><span class="line">  loadBalancer: &#123;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#将 type: ClusterIP 修改为 type: NodePort</span></span><br><span class="line"><span class="built_in">type</span>: NodePort</span><br><span class="line"></span><br><span class="line"><span class="comment">#直接保存退出(:wq)</span></span><br><span class="line"><span class="comment">#service/kubernetes-dashboard edited</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看</span></span><br><span class="line">kubectl -n kube-system get service/kubernetes-dashboard</span><br><span class="line">NAME                   TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">kubernetes-dashboard   NodePort   10.110.83.129   &lt;none&gt;        443:31965/TCP   6h</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看端口</span></span><br><span class="line">netstat -nltup | grep 31965</span><br><span class="line">tcp6       0      0 :::31965                :::*                    LISTEN      11280/kube-proxy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Dashboard展示在 31965(HTTPS) 端口上。</span></span><br><span class="line"><span class="comment">#现在可在浏览器访问 &lt;master-ip&gt;:31965</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#可使用Nginx做前端代理</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#此处注意，需要将dashboard.crt证书安装到你的电脑上</span></span><br><span class="line"><span class="comment">#不然浏览器会拒绝</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#如果你尝试在多节点集群上使用`NodePort`公开Dashboard，则必须找到运行Dashboard的节点的IP才能访问它。</span></span><br><span class="line">https://&lt;node-ip&gt;:&lt;nodeport&gt;</span><br></pre></td></tr></table></figure>
<p><img src="/images/K8s/k8s_dashboard_nodeport.png" alt="Dashboard NodePort"></p>
<p><img src="/images/K8s/k8s_dashboard_forbidden.png" alt="没有权限"></p>
<p>由图可看出，还需要配置权限才能够正常访问Dashboard！</p>
<p><br></p>
<p><strong>API Server</strong><br>如果公开k8s API server并可以从外部访问，则你可直接访问url。<br>Dashboard: <a href="https://master-ip:apiserver-port/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/" target="_blank" rel="noopener">https://master-ip:apiserver-port/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</a></p>
<p>注意，只有在浏览器中安装证书时，才能使用这用访问方式。</p>
<p><br></p>
<p><strong>Ingress</strong><br>Dashboard可以使用 <code>ingress</code> 进行公开。详情: <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/services-networking/ingress/</a></p>
<p><br><br><br></p>
<h4 id="Nginx反向代理"><a href="#Nginx反向代理" class="headerlink" title="Nginx反向代理"></a>Nginx反向代理</h4><p>直接使用<code>NodePort</code>方式访问比较麻烦，所以配置使用Nginx反向代理来访问。</p>
<p>Nginx配置文件:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/nginx/conf.d/k8sUI.conf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 443 ssl;</span><br><span class="line">    server_name k8s.ui;</span><br><span class="line"></span><br><span class="line">    ssl_certificate /etc/kubernetes/pki/dashboard/dashboard.crt;</span><br><span class="line">    ssl_certificate_key /etc/kubernetes/pki/dashboard/dashboard.key;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">      proxy_pass https://127.0.0.1:31965;</span><br><span class="line">      proxy_read_timeout 60s;</span><br><span class="line">      proxy_send_timeout 60s;</span><br><span class="line">      proxy_connect_timeout 60s;</span><br><span class="line">      proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_404;</span><br><span class="line"></span><br><span class="line">      proxy_set_header Upgrade $http_upgrade;</span><br><span class="line">      proxy_set_header Connection &apos;upgrade&apos;;</span><br><span class="line">      proxy_set_header Host $host;</span><br><span class="line">      proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">      proxy_set_header X-Forwarded-Proto https;</span><br><span class="line"></span><br><span class="line">      proxy_buffer_size 64k;</span><br><span class="line">      proxy_buffers 4 64k;</span><br><span class="line">      proxy_busy_buffers_size 128k;</span><br><span class="line">      proxy_temp_file_write_size 128k;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">nginx -t</span><br><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure>
<p>之后解析DNS，就可直接通过域名访问了。</p>
<p><br><br><br></p>
<h4 id="访问控制"><a href="#访问控制" class="headerlink" title="访问控制"></a>访问控制</h4><p>Access Control</p>
<p>安装Dashboard后，我们便可以专注于为用户配置对集群资源的访问控制。从 <code>v1.7</code> 开始，Dashboard默认不再具有完全管理权限(admin privilige)，所有权限都被撤销，并且只授予了Dashboard工作所需的最小权限。所以下面的介绍都只针对于 <code>v1.7+</code> 版本。<br>如果Dashboard只能由受信任的人员访问，你可能希望授予他们完全管理权限，则所有人都具有完全管理的权限。请注意，其它应用程序不应直接访问Dashboard，因为它可能导致权限升级。确保集群内的流量仅限于命名空间，或者只是撤销集群内应用程序对Dashboard的访问权限。</p>
<p>可查看<code>kubernetst-dashboard.yaml</code>配置文件，里面有<code>minimal</code>的权限。</p>
<p><br></p>
<p><strong>介绍</strong><br>k8s支持几种方法来认证(authenticating)和授权(authorizing)用户。授权由k8s API server处理。Dashboard仅充当代理并将所有认证信息传递给API server。在禁止访问的情况下，相应的警告信息会显示到Dashboard上。</p>
<p><br></p>
<p><strong>默认Dashboard权限</strong></p>
<ul>
<li><p><code>v1.7</code></p>
<ul>
<li><code>create</code> and <code>watch</code> permissions for secrets in <code>kube-system</code> namespace required to create and watch for changes of <code>kubernetes-dashboard-key-holder</code> secret.</li>
<li><code>get</code>, <code>update</code> and <code>delete</code> permissions for secrets named <code>kubernetes-dashboard-key-holder</code> and <code>kubernetes-dashboard-certs</code> in <code>kube-system</code> namespace.</li>
<li><code>proxy</code> permission to <code>heapster</code> service in <code>kube-system</code> namespace required to allow getting metrics from heapster.</li>
</ul>
</li>
<li><p><code>v1.8</code></p>
<ul>
<li><code>create</code> permission for secrets in <code>kube-system</code> namespace required to create <code>kubernetes-dashboard-key-holder</code> secret.</li>
<li><code>get</code>, <code>update</code> and <code>delete</code> permissions for secrets named <code>kubernetes-dashboard-key-holder</code> and <code>kubernetes-dashboard-certs</code> in <code>kube-system</code> namespace.</li>
<li><code>get</code> and <code>update</code> permissions for config map named <code>kubernetes-dashboard-settings</code> in <code>kube-system</code> namespace.</li>
<li><code>proxy</code> permission to <code>heapster</code> service in <code>kube-system</code> namespace required to allow getting metrics from heapster.</li>
</ul>
</li>
</ul>
<p><br></p>
<p><strong>Authentication</strong><br>从<code>v1.7</code>版本开始，Dashboard支持的用户认证基于：</p>
<ul>
<li><code>Authorization: Bearer &lt;token&gt;</code></li>
<li><code>Bearer Token</code></li>
<li><code>Username/password</code></li>
<li><code>Kubeconfig</code></li>
</ul>
<p><br></p>
<p><strong>Login view</strong><br>要使其显示在Dashboard中，你需要启用HTTPS访问Dashboard。</p>
<p>使用跳过选项将使Dashboard使用Service Account权限。</p>
<p><img src="/images/K8s/login_view.png" alt="Login view"></p>
<p><br></p>
<p><strong>Authorization header</strong><br>在通过HTTP访问Dashboard时，使用 <code>authorization header</code> 是使Dashboard充当用户的唯一方法。</p>
<p>要使Dashboard使用<code>authorization header</code>，你只需将每个请求中的<code>Authorization: Bearer &lt;token&gt;</code>传递给Dashboard。这可以通过在Dashboard前端配置反向代理来实现。代理将负责身份提供者的身份验证，并将请求头部中生成的token传递给Dashboard。注意，需要正确配置k8s API server才能接受这些token。</p>
<p>注意： 如果通过API server proxy访问Dashboard，则<code>authorization header</code>将不起作用。这是因为一旦请求到达API server，所有其它header都将被删除。</p>
<p><br></p>
<p><strong>Bearer Token</strong><br>建议先熟悉<a href="https://kubernetes.io/docs/reference/access-authn-authz/authentication/" target="_blank" rel="noopener">k8s authentication doc</a>，以了解如何获取可用于登录的token。例如，每个<code>Service Account</code>都有一个具有有效<code>Bearer token</code>，用于登录Dashboard。</p>
<p>推荐讲座，了解如何创建服务账户并对其进行授权：</p>
<ul>
<li><a href="https://kubernetes.io/docs/reference/access-authn-authz/authentication/#service-account-tokens" target="_blank" rel="noopener">Service Account Tokens</a></li>
<li><a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/#role-and-clusterrole" target="_blank" rel="noopener">Role and  ClusterRole</a></li>
<li><a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/#service-account-permissions" target="_blank" rel="noopener">Service Account Permissions</a></li>
</ul>
<p><img src="/images/K8s/bearer_token.png" alt="Bearer Token"></p>
<p><br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">#使用kubectl获取token</span><br><span class="line">#默认情况下，k8s创建了许多服务账号。所有都具有不同的访问权限</span><br><span class="line"></span><br><span class="line">kubectl -n kube-system get secret</span><br><span class="line"></span><br><span class="line">NAME                                             TYPE                                  DATA      AGE</span><br><span class="line">attachdetach-controller-token-bszq5              kubernetes.io/service-account-token   3         2d</span><br><span class="line">bootstrap-signer-token-bqv44                     kubernetes.io/service-account-token   3         2d</span><br><span class="line">bootstrap-token-uzdl9x                           bootstrap.kubernetes.io/token         7         2d</span><br><span class="line">certificate-controller-token-rsftn               kubernetes.io/service-account-token   3         2d</span><br><span class="line">clusterrole-aggregation-controller-token-x64f5   kubernetes.io/service-account-token   3         2d</span><br><span class="line">coredns-token-dfmpb                              kubernetes.io/service-account-token   3         2d</span><br><span class="line">cronjob-controller-token-xwtkc                   kubernetes.io/service-account-token   3         2d</span><br><span class="line">daemon-set-controller-token-vxzp4                kubernetes.io/service-account-token   3         2d</span><br><span class="line">default-token-5868t                              kubernetes.io/service-account-token   3         2d</span><br><span class="line">deployment-controller-token-jc6bs                kubernetes.io/service-account-token   3         2d</span><br><span class="line">disruption-controller-token-znghk                kubernetes.io/service-account-token   3         2d</span><br><span class="line">endpoint-controller-token-mnxfh                  kubernetes.io/service-account-token   3         2d</span><br><span class="line">expand-controller-token-6srzj                    kubernetes.io/service-account-token   3         2d</span><br><span class="line">flannel-token-7548k                              kubernetes.io/service-account-token   3         2d</span><br><span class="line">generic-garbage-collector-token-22qd2            kubernetes.io/service-account-token   3         2d</span><br><span class="line">horizontal-pod-autoscaler-token-zs8pj            kubernetes.io/service-account-token   3         2d</span><br><span class="line">job-controller-token-zbfhd                       kubernetes.io/service-account-token   3         2d</span><br><span class="line">kube-proxy-token-xxp9h                           kubernetes.io/service-account-token   3         2d</span><br><span class="line">kubernetes-dashboard-certs                       Opaque                                3         1h</span><br><span class="line">kubernetes-dashboard-key-holder                  Opaque                                2         2d</span><br><span class="line">kubernetes-dashboard-token-sgq5t                 kubernetes.io/service-account-token   3         2d</span><br><span class="line">namespace-controller-token-25n2k                 kubernetes.io/service-account-token   3         2d</span><br><span class="line">node-controller-token-289v8                      kubernetes.io/service-account-token   3         2d</span><br><span class="line">persistent-volume-binder-token-x7t7x             kubernetes.io/service-account-token   3         2d</span><br><span class="line">pod-garbage-collector-token-xxjqp                kubernetes.io/service-account-token   3         2d</span><br><span class="line">pv-protection-controller-token-9s4x7             kubernetes.io/service-account-token   3         2d</span><br><span class="line">pvc-protection-controller-token-l7m7j            kubernetes.io/service-account-token   3         2d</span><br><span class="line">replicaset-controller-token-mszv9                kubernetes.io/service-account-token   3         2d</span><br><span class="line">replication-controller-token-8gl9s               kubernetes.io/service-account-token   3         2d</span><br><span class="line">resourcequota-controller-token-whljw             kubernetes.io/service-account-token   3         2d</span><br><span class="line">service-account-controller-token-h87wp           kubernetes.io/service-account-token   3         2d</span><br><span class="line">service-controller-token-qn5jz                   kubernetes.io/service-account-token   3         2d</span><br><span class="line">statefulset-controller-token-zps2l               kubernetes.io/service-account-token   3         2d</span><br><span class="line">token-cleaner-token-nccrw                        kubernetes.io/service-account-token   3         2d</span><br><span class="line">ttl-controller-token-dmmb9                       kubernetes.io/service-account-token   3         2d</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl -n kube-system describe secret/replicaset-controller-token-mszv9</span><br><span class="line">Name:         replicaset-controller-token-mszv9</span><br><span class="line">Namespace:    kube-system</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name=replicaset-controller</span><br><span class="line">              kubernetes.io/service-account.uid=d18a5f8f-9a0d-11e8-a08a-000c298ee39f</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">ca.crt:     1025 bytes</span><br><span class="line">namespace:  11 bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJyZXBsaWNhc2V0LWNvbnRyb2xsZXItdG9rZW4tbXN6djkiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoicmVwbGljYXNldC1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZDE4YTVmOGYtOWEwZC0xMWU4LWEwOGEtMDAwYzI5OGVlMzlmIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOnJlcGxpY2FzZXQtY29udHJvbGxlciJ9.O6hXQwsXdSXREsaao_V7pmeQkfWGEd4QLDxczxNZVcrT2yN9F1KFJ9IklYVlGSTo1cKA4OxkYqjKWzWPBEn6wVLhVbf6_WqTrFi4qEtj_nmhXwqcwkpioJzyXu7x7wljpH-H32bEaLW1l-y5kQBUztF9fAHZZyv0f9vaRK4u4zVzuq4JzauLB9aVBrgt6rSaOENdr8OGm1yjM_--gQtc1qoF8mLo3RK6qLpFjT70EZKgyys_GXpFrrnhG5maUmlFqCPZ6P0cl8d6SuDfkQIlFxNHxtJmOPSCIE6wjgkOncRtgWHRRVsRPnhDGOp0kbmdLTfpOx2zZEiCD5btXL0OkA</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#我们可以使用显示的token登录Dashboard</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>Basic</strong><br>默认情况下，禁用基本身份认证，也就是用户密码认证。原因是需要使用授权模式<code>RBAC</code>和<code>--basic-auth-file</code>标志配置k8s API server。没有的话，API server会自动回退到匿名用户(anonymous user)，并且无法检查提供的凭据是否有效。</p>
<p>修改<code>--authentication-mode=basic</code>标志在Dashboard中启用基本身份认证，默认值为<code>--authentication-mode=token</code>。</p>
<p><br></p>
<p><strong>kubeconfig</strong><br>这种登录方法是为了方便起见而提供的。<code>kubeconfig file</code>仅支持<code>--authentication-mode</code>标志指定认证选项。如果它配置为其它方式，Dashboard中将显示错误消息。</p>
<p><img src="/images/K8s/kubeconfig.png" alt="kubeconfig"></p>
<p><br></p>
<p><strong>Admin privileges</strong><br>注意： 在操作之前，请确保你知道自己在做什么。向Dashboard的服务账号赋予管理权限可能会存在安全风险。</p>
<p>你可以通过创建<code>ClusterRoleBinding</code>来授权Dashboard的服务账号完全的管理权限。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">#栗子</span><br><span class="line">dashboard-admin.yaml</span><br><span class="line"></span><br><span class="line">#官方文档版</span><br><span class="line"></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#开发版</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard-head</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard-head</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: kubernetes-dashboard-head</span><br><span class="line">  namespace: kube-system</span><br></pre></td></tr></table></figure>
<p><br></p>
<h4 id="创建示例用户"><a href="#创建示例用户" class="headerlink" title="创建示例用户"></a>创建示例用户</h4><p>Creating sample user</p>
<p>在本节中，我们将了解如何使用k8s Service Account机制创建新用户，授权用户管理权限并使用与此用户关联的<code>Bearer Token</code>进行登录。<br>关于<code>grant/deny</code>权限，请查看文档<a href="https://kubernetes.io/docs/reference/access-authn-authz/authentication/" target="_blank" rel="noopener">authentication</a>和<a href="https://kubernetes.io/docs/reference/access-authn-authz/authorization/" target="_blank" rel="noopener">authorization</a>以了解详情。</p>
<p>创建<code>xxx.yaml</code>文件，并使用<code>kubectl create -f xxx.yaml</code>命令创建它们。</p>
<p><br></p>
<p><strong>创建 Service Account</strong><br>在<code>kube-system</code>命名空间中创建名为<code>admin-user</code>的服务账户:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">admin-user</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建</span></span><br><span class="line">kubectl create -f /etc/kubernetes/auth/admin-user_SA.yaml</span><br><span class="line"><span class="comment">#serviceaccount/admin-user created</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看</span></span><br><span class="line">kubectl -n kube-system get secret | grep admin-user</span><br><span class="line"><span class="comment">#admin-user-token-qj8hj                           kubernetes.io/service-account-token   3         56s</span></span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>创建 ClusterRoleBinding</strong><br>在大多数情况下，在使用<code>kops</code>, <code>kubeadm</code>等管理配置集群后，<code>Role</code>都已存在于集群中。我们可使用它为<code>ServiceAccount</code>仅创建<code>RoleBinding</code>。</p>
<p>注意: <code>ClusterRoleBinding</code>的<code>apiVersion</code>资源可能不同于k8s version。从<code>v1.8</code>开始，它被提升为<code>rbac.authorization.k8s.io/v1</code>。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">admin-user</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">cluster-admin</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">- kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">admin-user</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建</span></span><br><span class="line">kubectl create -f /etc/kubernetes/Auth/cluster-admin_CRB.yaml </span><br><span class="line"><span class="comment">#clusterrolebinding.rbac.authorization.k8s.io/admin-user created</span></span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>Bearer Token</strong><br>现在我们需要去找到用于登录的Token。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk &apos;&#123;print $1&#125;&apos;)</span><br><span class="line"></span><br><span class="line">Name:         admin-user-token-qj8hj</span><br><span class="line">Namespace:    kube-system</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name=admin-user</span><br><span class="line">              kubernetes.io/service-account.uid=58d39b31-9c40-11e8-a08a-000c298ee39f</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">ca.crt:     1025 bytes</span><br><span class="line">namespace:  11 bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLXFqOGhqIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI1OGQzOWIzMS05YzQwLTExZTgtYTA4YS0wMDBjMjk4ZWUzOWYiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.4hCqFj7R7CwAewnFxsy5QC91v6288T7aOCZXae7AbqXECiFb2yB5x7VQs0GjnUj8jbSZamBpI_D6D7p8PoRUmPZg2NOF46TEztsR9wcsEywUr6EHdXMGy6HUtvedy45K1j9h8oFp9nAqvxa6M7hrfV_yy-XlJdqTo7J06VlT_czpWNScCkjejIOlZXFvYL5f5ha0V4L5XCdlFkf7DYbsNV6odquIKavg270g4nAr1ZAJ14SjeFdfRVvimS4N-W7pb9vmOeZBnAmGuotKoqU1OlzZrMfpsPGIXy5GW3zD8PvsbGU9Xn6lyPHH08X0kXCUACQHx4UiaMFzlnhaC2XIMQ</span><br></pre></td></tr></table></figure>
<p>现在复制Token来登录.</p>
<p><img src="/images/K8s/admin_user_token.png" alt="Login"></p>
<p><img src="/images/K8s/admin_user_dashboard.png" alt="Dashboash"></p>
<p><br><br><br></p>
<h3 id="Heapster"><a href="#Heapster" class="headerlink" title="Heapster"></a>Heapster</h3><p>GitHub: <a href="https://github.com/kubernetes/heapster" target="_blank" rel="noopener">https://github.com/kubernetes/heapster</a></p>
<p>注意: Heapster已被启用，考虑使用<code>metric-server</code>和第三方<code>metric pipeline</code>来收集Prometheus格式的指标。</p>
<p><br></p>
<p><strong>Heapster 启用时间轴</strong></p>
<table>
<thead>
<tr>
<th>Kubernetes Release</th>
<th>Action</th>
<th>Policy/Support</th>
</tr>
</thead>
<tbody>
<tr>
<td>Kubernetes 1.11</td>
<td>Initial Deprecation</td>
<td>No new features or sinks are added. Bugfixes may be made.</td>
</tr>
<tr>
<td>Kubernetes 1.12</td>
<td>Setup Removal</td>
<td>The optional to install Heapster via the Kubernetes setup script is removed.</td>
</tr>
<tr>
<td>Kubernetes 1.13</td>
<td>Removal</td>
<td>No new bugfixes will be made. Move to kubernetes-retired organization.</td>
</tr>
</tbody>
</table>
<p><br><br><br></p>
<h3 id="metric-server"><a href="#metric-server" class="headerlink" title="metric-server"></a>metric-server</h3><p>GitHub: <a href="https://github.com/kubernetes-incubator/metrics-server" target="_blank" rel="noopener">https://github.com/kubernetes-incubator/metrics-server</a></p>
<p>具体详情可参考README。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">#下载到本地</span><br><span class="line">git clone https://github.com/kubernetes-incubator/metrics-server.git</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#移动到管理目录</span><br><span class="line">mv metrics-server/ /etc/kubernetes/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#k8s v1.8+</span><br><span class="line">ls /etc/kubernetes/metrics-server/deploy/v1.8+/</span><br><span class="line">auth-delegator.yaml  auth-reader.yaml  metrics-apiservice.yaml  metrics-server-deployment.yaml  metrics-server-service.yaml  resource-reader.yaml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#注意metrics-server-deployment.yaml文件，需要一个镜像，请准备</span><br><span class="line">#gcr.io/google_containers/metrics-server-amd64:v0.2.1</span><br><span class="line"></span><br><span class="line">docker pull zhang21/metrics-server-amd64:v0.2.1</span><br><span class="line">docker tag zhang21/metrics-server-amd64:v0.2.1 gcr.io/google_containers/metrics-server-amd64:v0.2.1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#创建</span><br><span class="line">#注意，在顶层进行创建</span><br><span class="line">cd /etc/kubernetes/metrics-server</span><br><span class="line">kubectl create -f deploy/v1.8+/</span><br><span class="line"></span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created</span><br><span class="line">apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created</span><br><span class="line">serviceaccount/metrics-server created</span><br><span class="line">deployment.extensions/metrics-server created</span><br><span class="line">service/metrics-server created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#查看</span><br><span class="line">kubectl -n kube-system  get deployment</span><br><span class="line"></span><br><span class="line">NAME                   DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">coredns                2         2         2            2           2d</span><br><span class="line">kubernetes-dashboard   1         1         1            1           19h</span><br><span class="line">metrics-server         1         1         1            0           39s</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h2 id="pause容器"><a href="#pause容器" class="headerlink" title="pause容器"></a>pause容器</h2><p>参考:</p>
<ul>
<li>《Kubernetes之“暂停”容器》: <a href="http://dockone.io/article/2785" target="_blank" rel="noopener">http://dockone.io/article/2785</a></li>
<li>《Pause容器》: <a href="https://jimmysong.io/kubernetes-handbook/concepts/pause-container.html" target="_blank" rel="noopener">https://jimmysong.io/kubernetes-handbook/concepts/pause-container.html</a></li>
<li>GitHub: <a href="https://github.com/kubernetes/kubernetes/tree/master/build/pause" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes/tree/master/build/pause</a></li>
</ul>
<p><br></p>
<p>Pause容器，又叫Infra容器。它不是pod，而是一个容器。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">docker ps | grep pause</span><br><span class="line">35c9aaa68a06        k8s.gcr.io/pause:3.1   &quot;/pause&quot;                 18 hours ago        Up 18 hours                             k8s_POD_coredns-78fcdf6894-hn46d_kube-system_daab8e60-9a0d-11e8-a08a-000c298ee39f_0</span><br><span class="line">d22a1baac736        k8s.gcr.io/pause:3.1   &quot;/pause&quot;                 18 hours ago        Up 18 hours                             k8s_POD_coredns-78fcdf6894-wqxbx_kube-system_daac5838-9a0d-11e8-a08a-000c298ee39f_0</span><br><span class="line">4d0cdc392629        k8s.gcr.io/pause:3.1   &quot;/pause&quot;                 18 hours ago        Up 18 hours                             k8s_POD_kube-flannel-ds-7gbvd_kube-system_59129dff-9a0f-11e8-a08a-000c298ee39f_0</span><br><span class="line">4f28747a2044        k8s.gcr.io/pause:3.1   &quot;/pause&quot;                 18 hours ago        Up 18 hours                             k8s_POD_kube-proxy-rhrks_kube-system_da990e28-9a0d-11e8-a08a-000c298ee39f_0</span><br><span class="line">f2bd7bd47eb4        k8s.gcr.io/pause:3.1   &quot;/pause&quot;                 18 hours ago        Up 18 hours                             k8s_POD_kube-scheduler-master_kube-system_537879acc30dd5eff5497cb2720a6d64_0</span><br><span class="line">d732ffba5530        k8s.gcr.io/pause:3.1   &quot;/pause&quot;                 18 hours ago        Up 18 hours                             k8s_POD_kube-controller-manager-master_kube-system_01c36146e2c80849d7b6993e68aa5e67_0</span><br><span class="line">cd7636bac6df        k8s.gcr.io/pause:3.1   &quot;/pause&quot;                 18 hours ago        Up 18 hours                             k8s_POD_kube-apiserver-master_kube-system_1bd24cc043a06bf7e71b96167946c220_0</span><br><span class="line">d4adb3504543        k8s.gcr.io/pause:3.1   &quot;/pause&quot;                 18 hours ago        Up 18 hours                             k8s_POD_etcd-master_kube-system_2cc1c8a24b68ab9b46bca47e153e74c6_0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#或者是这样</span><br><span class="line">#registry.access.redhat.com/rhel7/pod-infrastructure:latest</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#rpm包安装kubelet的默认配置</span><br><span class="line">KUBELET_POD_INFRA_CONTAINER=&quot;--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest&quot;</span><br><span class="line"></span><br><span class="line">#kubeadm安装kubelet的默认配置</span><br><span class="line">KUBELET_POD_INFRA_CONTAINER=--pod-infra-container-image=k8s.gcr.io/pause:3.1</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>pause容器的作用</strong><br>k8s中的pause容器主要为每个业务提供以下功能：</p>
<ul>
<li>在<code>pod</code>中担任Linux命名空间共享的基础</li>
<li>启用<code>pid</code>命名空间，开启<code>init</code>进程</li>
</ul>
<p><img src="/images/K8s/pause-container.png" alt="pause容器"></p>
<p><br></p>
<p>使用<code>pause</code>容器和共享命名空间创建pod示例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">#启动pause，以便可以将容器添加到pod中</span><br><span class="line">docker run -d --name pause k8s.gcr.io/pause-amd64:3.1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#nginx</span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; /tmp/nginx.conf</span><br><span class="line">&gt; error_log stderr;</span><br><span class="line">&gt; events &#123; worker_connections  1024; &#125;</span><br><span class="line">&gt; http &#123;</span><br><span class="line">&gt;     access_log /dev/stdout combined;</span><br><span class="line">&gt;     server &#123;</span><br><span class="line">&gt;         listen 80 default_server;</span><br><span class="line">&gt;         server_name example.com www.example.com;</span><br><span class="line">&gt;         location / &#123;</span><br><span class="line">&gt;             proxy_pass http://127.0.0.1:2368;</span><br><span class="line">&gt;         &#125;</span><br><span class="line">&gt;     &#125;</span><br><span class="line">&gt; &#125;</span><br><span class="line">&gt; EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#指定网络和命名空间</span><br><span class="line"></span><br><span class="line">docker run -d --name nginx -v /tmp/nginx.conf:/etc/nginc/nginx.conf -p 8880:80 --net=container:pause --ipc=container:pause --pid=container:pause docker.io/nginx:lates</span><br><span class="line"></span><br><span class="line">#ghost博客</span><br><span class="line">docker run -d --name ghost --net=container:pause --ipc=container:pause --pid=container:pause docker.io/ghost:latest</span><br></pre></td></tr></table></figure>
<p>在这两种情况下，我们将<code>pasue</code>容器指定为我们要加入的<strong>命名空间</strong>容器。这将有效地创建我们的pod。</p>
<p>访问<localhost:8880>可以看到<code>ghost</code>通过<code>nginx</code>代理运行。因为网络命名空间在<code>pause</code>, <code>nginx</code>, <code>ghost</code>容器之间共享。<br>而这两个容器的<code>init</code>进程都是<code>pause</code>这个容器。</localhost:8880></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">docker logs -f nginx</span><br><span class="line"></span><br><span class="line">192.168.31.28 - - [08/Aug/2018:02:00:49 +0000] &quot;GET / HTTP/1.1&quot; 200 3195 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36&quot;</span><br><span class="line">192.168.31.28 - - [08/Aug/2018:02:00:49 +0000] &quot;GET /assets/built/screen.css?v=0bf822a279 HTTP/1.1&quot; 200 7360 &quot;http://node:8880/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36&quot;</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker logs -f ghost</span><br><span class="line"></span><br><span class="line">[2018-08-08 02:00:30] INFO Creating table: posts</span><br><span class="line">[2018-08-08 02:00:30] INFO Creating table: users</span><br><span class="line">[2018-08-08 02:00:30] INFO Creating table: posts_authors</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#查看init</span><br><span class="line">docker exec -it ghost /bin/bash</span><br><span class="line"></span><br><span class="line">root@f12a374141a7:/var/lib/ghost# ps  -ef</span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root         1     0  0 01:55 ?        00:00:00 /pause</span><br><span class="line">root         5     0  0 01:58 ?        00:00:00 nginx: master process nginx -g daemon off;</span><br><span class="line">systemd+     9     5  0 01:58 ?        00:00:00 nginx: worker process</span><br><span class="line">node        10     0  0 02:00 ?        00:00:03 node current/index.js</span><br><span class="line">root       127     0  0 02:37 ?        00:00:00 /bin/bash</span><br><span class="line">root       131   127  0 02:37 ?        00:00:00 ps -ef</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h2 id="构建大型集群"><a href="#构建大型集群" class="headerlink" title="构建大型集群"></a>构建大型集群</h2><p>Building Large Clusters</p>
<p>在k8s v1.11，k8s支持做多5 000个节点的集群。更具体地说，支持满足以下条件的配置：</p>
<ul>
<li>不超过5 000个node</li>
<li>总量不超过150 000个pod</li>
<li>总量不超过300 000个container</li>
<li>每个节点不超过100个pod</li>
</ul>
<p><br><br><br></p>
<h2 id="使用salt配置k8s"><a href="#使用salt配置k8s" class="headerlink" title="使用salt配置k8s"></a>使用salt配置k8s</h2><p>Configuring Kubernetes with Salt</p>
<p>k8s集群能够使用salt进行配置。</p>
<p><br><br><br></p>
<h2 id="验证节点配置"><a href="#验证节点配置" class="headerlink" title="验证节点配置"></a>验证节点配置</h2><p>Validate Node Setup</p>
<p><br></p>
<p><strong>节点一致性测试</strong><br>Node Conformance Test</p>
<p>节点一致性测试是一种容器化测试框架，为节点提供系统验证和功能测试。<br>该测试验证节点是够满足k8s的最低要求，通过测试的节点有资格加入k8s集群。</p>
<p><br></p>
<p><strong>局限</strong><br>Limitations</p>
<p>在k8s v1.5中，节点一致性测试具有如下限制：</p>
<ul>
<li>节点一致性测试仅支持Docker作为容器runtime</li>
</ul>
<p><br></p>
<p><strong>节点先决条件</strong><br>Node Prerequisite</p>
<p>要运行节点一致性测试，节点必须满足与标准k8s节点相同的先决条件。该节点至少要安装一下守护进程:</p>
<ul>
<li>Container Runtime(Docker)</li>
<li>Kubelet</li>
</ul>
<p><br></p>
<p><strong>运行节点一致性测试</strong><br>Running Node Conformance Test</p>
<p>执行如下步骤：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">1. 将kubelet执行localhost，测试框架启动一个master来测试kubelet</span><br><span class="line">#可使用 --pod-cidr, --cloud-provide标志</span><br><span class="line">--api-servers=&quot;http://localhost:8080&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">2. 运行节点一致性测试</span><br><span class="line"># $CONFIG_DIR is the pod manifest path of your Kubelet.</span><br><span class="line"># $LOG_DIR is the test output path.</span><br><span class="line">sudo docker run -it --rm --privileged --net=host \</span><br><span class="line">  -v /:/rootfs -v $CONFIG_DIR:$CONFIG_DIR -v $LOG_DIR:/var/result \</span><br><span class="line">  k8s.gcr.io/node-test:0.2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#一致性测试的架构支持</span><br><span class="line">node-test-adm64</span><br><span class="line">node-test-arm</span><br><span class="line">node-test-arm64</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>运行选定测试</strong><br>Running Selected Test</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#运行指定测试，使用你想要运行的测试的正则表达式 覆盖环境变量FOCUS</span><br><span class="line">sudo docker run -it --rm --privileged --net=host \</span><br><span class="line">  -v /:/rootfs:ro -v $CONFIG_DIR:$CONFIG_DIR -v $LOG_DIR:/var/result \</span><br><span class="line">  -e FOCUS=MirrorPod \ # Only run MirrorPod test</span><br><span class="line">  k8s.gcr.io/node-test:0.2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#跳过指定测试，覆盖环境变量SKIP</span><br><span class="line">sudo docker run -it --rm --privileged --net=host \</span><br><span class="line">  -v /:/rootfs:ro -v $CONFIG_DIR:$CONFIG_DIR -v $LOG_DIR:/var/result \</span><br><span class="line">  -e SKIP=MirrorPod \ # Run all conformance tests but skip MirrorPod test</span><br><span class="line">  k8s.gcr.io/node-test:0.2</span><br></pre></td></tr></table></figure>
<p>强烈建议仅运行一致性测试，因为它需要更复杂的配置来运行不一致性测试。</p>
<p><br><br><br></p>
<hr>
<p><br></p>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>concepts</p>
<p>概念部分可帮助你了解k8s系统的各个部分以及k8s用于表示集群的抽象，并帮助你更深入地了解k8s的工作原理。</p>
<p><br></p>
<h2 id="标准词汇"><a href="#标准词汇" class="headerlink" title="标准词汇"></a>标准词汇</h2><p>Standardized Glossary</p>
<p><br></p>
<ul>
<li><p><strong>Annotation</strong><br>用于将任意非标识元数据(metadata)附加到随想的键值对。</p>
</li>
<li><p><strong>Application Architect</strong><br>负责程序高级设计的人员。</p>
</li>
<li><p><strong>Application Developer</strong><br>编写在Kubernetes集群中运行的应用程序的人。</p>
</li>
<li><p><strong>Approver</strong><br>可以审批Kubernetes代码贡献的人。</p>
</li>
<li><p><strong>CLA(Contributor License Agreement)</strong><br>贡献者向开源项目授予其贡献许可的条款。</p>
</li>
<li><p><strong>Certificate</strong><br>一个加密安全文件，用于验证对Kubernetes集群的访问的加密。</p>
</li>
<li><p><strong>Cloud Controller Manager</strong></p>
</li>
<li><p><strong>Cloud Provider</strong></p>
</li>
<li><p><strong>Cluster</strong><br>一组称为节点(node)的机器，运行着由Kubernetes管理的容器化的应用程序。</p>
</li>
<li><p><strong>Cluster Architect</strong><br>设计一个或多个Kubernetes集群的基础架构的人。</p>
</li>
<li><p><strong>Cluster Operator</strong><br>配置，控制和监控集群的人。</p>
</li>
<li><p><strong>Code Contributor</strong><br>为Kubernetes开源代码库开发和共享代码的人。</p>
</li>
<li><p><strong>ConfigMap</strong><br>一个API对象，用于在键值对中存储非机密的数据。可认为是环境变量，命令行参数…</p>
</li>
<li><p><strong>Container</strong><br>一个轻量化和可移植的包含应用程序及其依赖项的可执行的镜像。</p>
</li>
<li><p><strong>Container Environment Variables</strong><br>容器环境变量是<code>name/value</code>对，为Pod中运行的容器提供有用的信息。</p>
</li>
<li><p><strong>Contributor</strong><br>捐赠代码，文档或时间来帮助Kubernetes项目或社区的人。</p>
</li>
<li><p><strong>Controller</strong><br>一个控制循环，通过APIServer监视集群的共享状态，并进行修改，尝试将当前状态移至理想(desired)状态。</p>
</li>
<li><p><strong>CronJob</strong><br>管理一个定期运行的工作。</p>
</li>
<li><p><strong>CustomResourceDefinition</strong><br>自定义码，用于定义要添加到Kubernetes APIServer的资源，而无需构建完整的自定义服务器。</p>
</li>
<li><p><strong>DaemonSet</strong><br>确保Pod的副本在集群的一组节点上运行。</p>
</li>
<li><p><strong>Deployment</strong><br>一个管理副本应用程序的API对象</p>
</li>
<li><p><strong>Dynamic Volume Provision</strong><br>允许用户请求自动创建存储卷。</p>
</li>
<li><p><strong>etcd</strong><br>一致且高度可用的键值存储，用作Kubernetes所有集群数据的备份存储。</p>
</li>
<li><p><strong>Helm Chart</strong><br>可以使用Helm工具管理的预配置Kubernetes资源包。</p>
</li>
<li><p><strong>Horizontal Pod Autoscaler</strong><br>一个API资源，可根据目标CPU利用率或自定义的指标自动调整Pod副本数。</p>
</li>
<li><p><strong>Image</strong><br>一个容器的存储实例，其中包含运行一个应用程序需要的一组软件。</p>
</li>
<li><p><strong>Ingress</strong><br>一个管理集群中服务的外部访问的API对象，通常是HTTP。</p>
</li>
<li><p><strong>Init Container</strong><br>一个或多个初始化容器，必须在任意应用程序容器运行之前完成运行。</p>
</li>
<li><p><strong>Istio</strong><br>一个开放平台，提供统一的方式来继承微服务，管理流量，实施策略和聚合遥测数据。</p>
</li>
<li><p><strong>Job</strong><br>运行完成的 有限/一批 任务。</p>
</li>
<li><p><strong>Kops</strong><br>一个命令行工具，可帮助你创建，销毁，升级和维护生产级、高可用性的Kubernetes集群。(仅支持AWS)</p>
</li>
<li><p><strong>Kubeadm</strong><br>一个快速安装Kubernetes和设置安全集群的工具。</p>
</li>
<li><p><strong>Kubectl</strong><br>用于与Kubernetes APIServer通信的命令行工具。</p>
</li>
<li><p><strong>Kubelet</strong><br>在集群的每个节点上运行的Agent。它确保容器运行在Pod中。</p>
</li>
<li><p><strong>Kubernetes API</strong><br>通过RESTful接口提供Kubernetes功能的应用程序，用于存储集群的状态。</p>
</li>
<li><p><strong>Label</strong><br>标记与用户有意义且相关的标识属性的对象。</p>
</li>
<li><p><strong>Minikube</strong><br>一个在本地运行Kubernetes的工具。</p>
</li>
<li><p><strong>Name</strong><br>客户端提供的字符串，用于引用资源URL中的对象。如<code>/api/vi/pods/some-name</code>.</p>
</li>
<li><p><strong>Namespace</strong><br>一个抽象概念，用于Kubernetes支持同一物理集群上的多个虚拟集群。</p>
</li>
<li><p><strong>Network Policy</strong><br>允许Pod组如何与其它网络端点进行通信的规范。</p>
</li>
<li><p><strong>Node</strong><br>节点是Kubernetes中的一个工作机器。</p>
</li>
<li><p><strong>Persistent Volume</strong><br>一个表示集群中一块存储的API对象。</p>
</li>
<li><p><strong>Persistent Volume Claim</strong><br>声明定义在一个PersistentVolume中的存储资源，以便可以作为一个volume挂载到容器中。</p>
</li>
<li><p><strong>Pod</strong><br>最小和最简单的Kubernetes对象。Pod表示集群上一组正在运行的容器。</p>
</li>
<li><p><strong>Pod Security Policy</strong><br>启用Pod创建和更新的细粒度授权。</p>
</li>
<li><p><strong>PodPreset</strong><br>一个API对象，在创建时将信息(secrets, volume, env var…)注入到Pod中。</p>
</li>
<li><p><strong>RBAC（role-basesd access control)</strong><br>管理授权决策，允许管理员通过Kubernetes API动态配置访问策略。</p>
</li>
<li><p><strong>ReplicaSet</strong><br>副本集是下一代副本控制器。</p>
</li>
<li><p><strong>Resource Quotas</strong><br>提供限制每个命名空间的聚合资源消耗的约束。</p>
</li>
<li><p><strong>Reviemer</strong><br>在项目的某些部分检查代码质量和正确性的人。</p>
</li>
<li><p><strong>Secret</strong><br>存储敏感信息，如密码，token…</p>
</li>
<li><p><strong>Security Context</strong><br><code>securityContext</code>字段定义Pod或容器的权限和访问控制设置，包括运行时UID和GID。</p>
</li>
<li><p><strong>Selector</strong><br>允许用户根据label过滤资源列表。</p>
</li>
<li><p><strong>Service</strong><br>一个API对象，描述如何访问应用程序，并可以描述端口和负载均衡器。</p>
</li>
<li><p><strong>Service Account</strong><br>为运行在Pod中的进程提供一个标识。</p>
</li>
<li><p><strong>Service Catalog</strong><br>一个扩展API，允许Kubernetes集群中运行的应用程序能够轻松使用外部托管软件，如数据库存储服务。</p>
</li>
<li><p><strong>StatefulSet</strong><br>管理一组Pods的部署和伸缩，并提供有关这些Pod的排序和唯一性的保证。</p>
</li>
<li><p><strong>UID</strong><br>Kubernetes系统生成的一个字符串，用于唯一标识对象。</p>
</li>
<li><p><strong>Volume</strong><br>一个包含数据的目录，可供Pod中的容器访问。</p>
</li>
<li><p><strong>Volume Plugin</strong><br>卷插件可在Pod中集成存储。</p>
</li>
<li><p><strong>kube-apiserver</strong><br>一个Master组件，用于暴露Kubernetes API。它是Kubernetes控制面的前端。</p>
</li>
<li><p><strong>kube-controller-manager</strong><br>一个Master组件，用于运行控制器。</p>
</li>
<li><p><strong>kube-proxy</strong><br>运行在集群中的每一个节点上的网络代理。</p>
</li>
<li><p><strong>kube-scheduler</strong><br>Master上的组件，用于监测未创建节点新创建的Pod，并选择一个节点供其运行。</p>
</li>
</ul>
<p><br><br><br></p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="K8s是什么"><a href="#K8s是什么" class="headerlink" title="K8s是什么"></a>K8s是什么</h3><p>Kubernetes（常简称为K8s），Kubernetes的名字来自希腊语，意思是“舵手”或“领航员”。K8s是将8个字母“ubernete”替换为“8”的缩写。<br>它用于自动部署、扩展和管理容器化（containerized）应用程序的开源系统。它旨在提供“跨主机集群的自动部署、扩展以及运行应用程序容器的平台”。它支持一系列容器工具, 包括Docker等。</p>
<p>通过Kubernetes你可以：</p>
<ul>
<li>快速部署应用</li>
<li>快速扩展应用</li>
<li>无缝对接新的应用功能</li>
<li>优化硬件资源，降低成本</li>
</ul>
<p>Kubernetes特点：</p>
<ul>
<li>可移植(portable)</li>
<li>可扩展( extensible)</li>
<li>自动化(automatic)</li>
</ul>
<p>容器优点：</p>
<ul>
<li>快速创建/部署应用</li>
<li>持续开发、集成和部署(CI/CD)</li>
<li>开发和运维相分离</li>
<li>开发、测试、生产环境的一致性</li>
<li>可移植性</li>
<li>松耦合、分布式、弹性伸缩、微服务化</li>
<li>资源隔离</li>
<li>资源利用</li>
</ul>
<p><br></p>
<p><strong>Kubernetes能做什么</strong><br>Kubernetes还允许开发人员从物理和虚拟机脱离，从以主机为中心的基础架构转移到以容器为中心的基础架构。这样可以使用容器固有的全部优点。</p>
<p>Kubernetes满足的应用程序常见需求：</p>
<ul>
<li>Pod</li>
<li>挂载外部存储</li>
<li>分布式secrets</li>
<li>应用健康检查</li>
<li>副本应用实例</li>
<li>横向自动伸缩</li>
<li>服务发现</li>
<li>负载均衡</li>
<li>滚动更新</li>
<li>资源监控</li>
<li>日志采集和存储</li>
<li>自检和调试</li>
<li>认证和授权</li>
</ul>
<p>这提供了<strong>平台即服务(PAAS)</strong>的简单性以及<strong>基础架构即服务(IAAS)</strong>的灵活性，并促进基础设施供应商的可移植性。</p>
<p><br></p>
<p><strong>Kubernetes不是什么</strong><br>Kubernetes 不是一个传统意义上，包罗万象的PaaS(平台即服务)系统。</p>
<ul>
<li>不限制支持的应用程序类型，不限制应用程序框架</li>
<li>不提供中间件(如消息中间件)、数据处理框架(如spark)，数据库或集群存储系统</li>
<li>不提供点击即部署的服务市场</li>
<li>不部署代码不构建应用</li>
<li>允许用户选择日志、监控和报警</li>
<li>不提供或授权一个全面的应用程序配置系统/语言</li>
<li>不提供任何机器配置、维护、管理或自我修复系统</li>
</ul>
<p>你可以自定义你的PAAS，与你选择的CI系统集成，或与Kubernetes一起使用，将你的容器镜像部署到Kubernetes。<br>由于Kubernetes在应用级别而不仅仅在硬件级别上运行，因此它提供了PAAS产品通用的一些功能。如部署、扩展、负载均衡、日志记录、监控等。</p>
<p><br><br><br></p>
<h3 id="k8s组件"><a href="#k8s组件" class="headerlink" title="k8s组件"></a>k8s组件</h3><p>Kubernetes Components</p>
<p>Kubernetes 所需的各种二进制组件, 用于提供齐全的功能。</p>
<p><br></p>
<h4 id="Master组件"><a href="#Master组件" class="headerlink" title="Master组件"></a>Master组件</h4><p>Master组件提供的集群控制面(control plane)。Master作出集群的全局决策，以及检测和相应集群事件。<br>Master组件可在集群中任何节点上运行。然而，为了简单，通常在一台机器上启动所有Master组件，并且不会在此机器上运行用户容器。<br>可使用多个机器的设置来构建<strong>高可用性能集群</strong>。</p>
<p><br></p>
<p><strong>kube-apiserver</strong><br><code>kube-apiserver</code>对外展示Kubernetes API。它是Kubernetes前端控制层，任何的资源请求/调用都是通过它提供的接口进行。<br>它被设计为水平扩展，即通过部署更多实例来扩展。</p>
<p><br></p>
<p><strong>etcd</strong><br>持久化和高可用的K/V存储，用于Kubernetes所有集群数据的后端存储。<br>请始终为k8s集群的etcd数据做备份。</p>
<p><br></p>
<p><strong>kube-controller-manager</strong><br>Master上运行的控制器组件，它们是集群中处理常规任务的后台线程。<br>逻辑上讲，每个控制器都是一个单独的进程，但为了降低复杂性，它们都被编译为单个二进制文件并在单个进程中运行。</p>
<p>这些控制器包含：</p>
<ul>
<li>节点控制器(Node Controller): 负责在节点故障时通知和响应</li>
<li>副本控制器(Replication Controller): 负责维护系统中每个副本控制器对象正确的pod数</li>
<li>端点控制器(Endpoints Controller): 填入端点对象</li>
<li>服务账户(service accoute)和令牌控制器(token controller): 为新的命名空间(namespace)创建默认账户和API访问令牌</li>
</ul>
<p><br></p>
<p><strong>cloud-controller-manager</strong><br>云控制器管理器用于与底层云提供商进行交互。它仅运行云提供商特定的控制器循环。你必须在<code>kube-controller-manager</code>中禁用这些controller loops，将<code>--cloud-provider</code>标志设置为<code>external</code>来禁用。</p>
<p>以下控制器具有云提供商依赖关系：</p>
<ul>
<li>节点控制器: 用于检查云服务商提供的程序</li>
<li>路由控制器: 用于在底层云基础架构中设置路由</li>
<li>服务控制器: 用于创建，更新，删除云服务商提供的负载均衡器</li>
<li>数据卷控制器: 用于创建，附件和挂载卷，以及与云服务商提供的卷进行交互</li>
</ul>
<p><br></p>
<p><strong>kube-scheduler</strong><br>监视还未分配节点的新创建的pod，选择一个节点供pod运行。<br>调度决策所考虑的因素包括： 个体/集体的资源需求，硬件/软件/策略的约束，亲和力/反亲和性的规范，工作负载和期限。</p>
<p><br><br><br></p>
<h4 id="Node组件"><a href="#Node组件" class="headerlink" title="Node组件"></a>Node组件</h4><p>节点(node)组件运行在每个节点，维护运行的pod并提供Kubernetes运行时环境。</p>
<p><br></p>
<p><strong>kubelet</strong><br>在集群中每个节点上运行的Agent，它确保container运行在pod中。<br>kubelet采用通过各种机制提供的一组PodSpecs，并确保这些PodSpecs中描述的容器运行且健康。kubelet不管理不是由k8s创建的容器。</p>
<p>提供如下功能：</p>
<ul>
<li>挂载pod所需的数据卷</li>
<li>下载pod的secrets</li>
<li>pod中运行docker容器</li>
<li>周期性的容器健康检查</li>
<li>如有需要，通过创建<code>mirror pod</code>将pod的状态报告回系统的其余部分</li>
<li>将节点的状态报告回系统的其余部分</li>
</ul>
<p><br></p>
<p><strong>kube-proxy</strong><br>通过维护主机上的网络规则并执行连接转发，来实现Kubernetes服务抽象。</p>
<p><br></p>
<p><strong>container runtime</strong><br>负责运行容器的软件。k8s支持多种runtimes： docker, rkt, runc…</p>
<p><br></p>
<p><strong>docker, rkt, supervisord, fluentd…</strong></p>
<p><br><br><br></p>
<h4 id="Addons"><a href="#Addons" class="headerlink" title="Addons"></a>Addons</h4><p>扩展是实现集群功能的Pod和Service。pod可由Deployment， Replication等管理。命名空间扩展对象在<code>kube-system</code>命名空间中创建。</p>
<p><br></p>
<p><strong>DNS</strong><br>虽然其它插件并非严格要求，但所有k8s集群都应具有集群DNS，因为许多示例都依赖于它。<br>集群DNS是一个DNS服务器，除了你环境中的DNS服务器，它还为k8s服务提供DNS记录。<br>由k8s启动的容器会在DNS搜索中自动包含此DNS服务器。</p>
<p><br></p>
<p><strong>Web UI(dashboard)</strong><br>仪表盘。</p>
<p><br></p>
<p><strong>container resource monitoring</strong><br>记录有关中央数据库中容器的通用时间序列度量标准，并提供用于浏览该数据的UI。</p>
<p><br></p>
<p><strong>cluster-level logging</strong><br>集群级别的日志记录机制，复制将容器日志保存到具有<code>search/browse</code>界面的中央日志存储。</p>
<p><br><br><br></p>
<h3 id="k8s-API"><a href="#k8s-API" class="headerlink" title="k8s API"></a>k8s API</h3><p>k8s API还可作为系统声明性配置架构的基础。<code>kubectl</code>命令行工具可用于创建，更新，删除和获取API对象。<br>k8s还根据API资源存储其序列化状态(etcd中)。k8s自身被分解为多个组件，这些组件通过其API进行交互。</p>
<p><br></p>
<p><strong>OpenAPI和Swagger定义</strong><br>完整的API详细信息记录在<code>Swagger v1.2</code>和<code>OpenAPI</code>。k8s apiserver(master)公开了一个API，可用于检索位于<code>/swaggerapi</code>的<code>Swagger v1.2 k8s API</code>.<br>从k8s 1.10开始，OpenAPI规范在单个<code>/openapi/v2</code>端点中提供。单独格式的端点(如<code>swagger.json...</code>)已被弃用，后面会被移除。</p>
<p>通过设置HTTP header指定请求格式:</p>
<table>
<thead>
<tr>
<th>Header</th>
<th>Possible Values</th>
</tr>
</thead>
<tbody>
<tr>
<td>Accept</td>
<td>application/json, application/com.github.proto-openapi.spec.v2@v1.0+protobuf (the default content-type is application/json for <em>/</em> or not passing this header)</td>
</tr>
<tr>
<td>Accept-Encoding</td>
<td>gzip (not passing this header is acceptable)</td>
</tr>
</tbody>
</table>
<p>栗子：</p>
<table>
<thead>
<tr>
<th>Before 1.10</th>
<th>Starting with Kubernetes 1.10</th>
</tr>
</thead>
<tbody>
<tr>
<td>GET /swagger.json</td>
<td>GET /openapi/v2 Accept: application/json</td>
</tr>
<tr>
<td>GET /swagger-2.0.0.pb-v1</td>
<td>GET /openapi/v2 Accept: application/com.github.proto-openapi.spec.v2@v1.0+protobuf</td>
</tr>
<tr>
<td>GET /swagger-2.0.0.pb-v1.gz</td>
<td>GET /openapi/v2 Accept: application/com.github.proto-openapi.spec.v2@v1.0+protobuf Accept-Encoding: gzip</td>
</tr>
</tbody>
</table>
<p><br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">#查看</span><br><span class="line">curl localhost:8080</span><br><span class="line">&#123;</span><br><span class="line">  &quot;paths&quot;: [</span><br><span class="line">    &quot;/api&quot;,</span><br><span class="line">    &quot;/api/v1&quot;,</span><br><span class="line">    &quot;/apis&quot;,</span><br><span class="line">    &quot;/apis/apps&quot;,</span><br><span class="line">    &quot;/apis/apps/v1beta1&quot;,</span><br><span class="line">    &quot;/apis/authentication.k8s.io&quot;,</span><br><span class="line">    &quot;/apis/authentication.k8s.io/v1beta1&quot;,</span><br><span class="line">    &quot;/apis/authorization.k8s.io&quot;,</span><br><span class="line">    &quot;/apis/authorization.k8s.io/v1beta1&quot;,</span><br><span class="line">    &quot;/apis/autoscaling&quot;,</span><br><span class="line">    &quot;/apis/autoscaling/v1&quot;,</span><br><span class="line">    &quot;/apis/batch&quot;,</span><br><span class="line">    &quot;/apis/batch/v1&quot;,</span><br><span class="line">    &quot;/apis/batch/v2alpha1&quot;,</span><br><span class="line">    &quot;/apis/certificates.k8s.io&quot;,</span><br><span class="line">    &quot;/apis/certificates.k8s.io/v1alpha1&quot;,</span><br><span class="line">    &quot;/apis/extensions&quot;,</span><br><span class="line">    &quot;/apis/extensions/v1beta1&quot;,</span><br><span class="line">    &quot;/apis/policy&quot;,</span><br><span class="line">    &quot;/apis/policy/v1beta1&quot;,</span><br><span class="line">    &quot;/apis/rbac.authorization.k8s.io&quot;,</span><br><span class="line">    &quot;/apis/rbac.authorization.k8s.io/v1alpha1&quot;,</span><br><span class="line">    &quot;/apis/storage.k8s.io&quot;,</span><br><span class="line">    &quot;/apis/storage.k8s.io/v1beta1&quot;,</span><br><span class="line">    &quot;/healthz&quot;,</span><br><span class="line">    &quot;/healthz/ping&quot;,</span><br><span class="line">    &quot;/healthz/poststarthook/bootstrap-controller&quot;,</span><br><span class="line">    &quot;/healthz/poststarthook/extensions/third-party-resources&quot;,</span><br><span class="line">    &quot;/healthz/poststarthook/rbac/bootstrap-roles&quot;,</span><br><span class="line">    &quot;/logs&quot;,</span><br><span class="line">    &quot;/metrics&quot;,</span><br><span class="line">    &quot;/swaggerapi/&quot;,</span><br><span class="line">    &quot;/ui/&quot;,</span><br><span class="line">    &quot;/version&quot;</span><br><span class="line">  ]</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>API 版本</strong><br>为了更容易消除字段或重构资源表示，k8s支持多个API版本，每个版本位于不同的API路径。如<code>/api/vi</code>或<code>/apis/extensions/v1beta1</code>.</p>
<p>我们选择在API级别，而不是资源级别/字段级别进行版本控制，以确保API提供干净、一致的系统资源和行为视图，并允许控制对生命末端和实验性API的访问。json和protobuf序列化模式都遵循相同的模式更改指南。请注意，API版本和软件版本仅间接相关。</p>
<p>不同的API版本意味着不同级别的稳定性和支持：</p>
<ul>
<li>Alpha level<ul>
<li>版本名包含alpha(如 v1aplha1)</li>
<li>启用该功能可能会暴露bug，默认禁用</li>
<li>可随时删除对功能的支持，恕不另行通知</li>
<li>可能会在以后软件版本中以不兼容的方式更改，恕不另行通知</li>
<li>由于错误风险和缺乏长期支持，建议仅在短期测试集群中使用</li>
</ul>
</li>
<li>Beta level<ul>
<li>版本名包含beta(如 v2beta3)</li>
<li>代码经过充分测试，启用该功能被认为是安全的。默认启用</li>
<li>虽然细节会有所变化，但不会删除对整体功能的支持</li>
<li>建议仅用于非关键业务，因为后续版本可能会发生不兼容的更改</li>
<li>请尝试我们测试版功能并提供反馈</li>
</ul>
</li>
<li>Stable level<ul>
<li>版本名是vx，x为整数</li>
<li>许多后续版本的软件将出现稳定版的功能</li>
</ul>
</li>
</ul>
<p><br></p>
<p><strong>API groups</strong><br>为了更容易扩展k8s API，我们实施了<code>API Groups</code>，它在REST path和序列化对象的apiVersion字段中指定。</p>
<p>目前在使用的几个API groups:</p>
<ul>
<li>核心组(core group)，又称遗留组，位于REST path的<code>/api/v1</code>，并使用<code>apiVersion: v1</code></li>
<li>命名组(named group)，位于REST path的<code>/apis/$GROUP_NAME/$VERSION</code>，并使用<code>apiVersion: $GROUP_NAME/$VERSION</code></li>
</ul>
<p>两种受支持的自定义资源扩展API的路径：</p>
<ul>
<li>自定义资源(CustomResourceDefiniton) 适用于具有非常基本CRUD需求的用户</li>
<li>需要完整k8s API语义的用户可以实现自己的apiserver，并使用聚合器使其无缝连接到客户端</li>
</ul>
<p><br></p>
<p><strong>启用 API groups</strong><br>默认情况下启用某些资源和API groups。通过在apiserver设置<code>--runtime-config</code>可启用/禁用它。此配置接收逗号分隔的KV，描述了apiserver运行时配置。</p>
<p><br></p>
<p><strong>在API groups中启用资源</strong><br>默认情况下启动 DeamonSets, Deployments, HorizontalPodAutoscalers, Ingress, Jobs, ReplicaSets。其它扩展资源可通过在apiserver上设置<code>--runtime-config</code>启用或禁用。</p>
<p><br><br><br></p>
<h3 id="k8s-对象"><a href="#k8s-对象" class="headerlink" title="k8s 对象"></a>k8s 对象</h3><p>本节解释了如何在k8s API中表示k8s对象，以及如何以<code>.yaml</code>格式表示它们。</p>
<p><br></p>
<h4 id="理解k8s对象"><a href="#理解k8s对象" class="headerlink" title="理解k8s对象"></a>理解k8s对象</h4><p>在k8s系统中，k8s对象是持久化的实体。k8s使用这些实体来表示整个集群的状态。特别地，它们描述了如下信息：</p>
<ul>
<li>哪些容器化应用程序正在运行(以及运行在哪个节点上)</li>
<li>可以被这些应用程序使用的资源</li>
<li>应用程序行为方式的策略(重启、升级、容错)</li>
</ul>
<p>k8s 对象是一个<strong>意图记录(record of intent)</strong> —— 一旦创建了对象，k8s系统将持续工作以确保对象存在。通过创建一个对象，你可以有效地告诉k8s系统你希望集群的工作负载看起来像什么，这是你的集群的<strong>期望状态(desired state)</strong>。<br>要使用k8s对象(创建, 修改, 删除)，需要使用k8s API。当你使用<code>kubectl</code>命令行接口时，CLI会为你进行必要的k8s API调用。</p>
<p><br></p>
<p><strong>对象规约与状态</strong><br>Object Spec and Status</p>
<p>每个k8s 对象都包含了两个嵌套的对象字段，用于控制对象的配置：<strong>对象规约</strong>和<strong>对象状态</strong>。<br>在任何时刻，k8s controller plane都会主动管理对象的实际状态，以匹配你提供的期望状态。</p>
<ul>
<li>规约(spec)，必须提供。描述了对象的期望状态(diresed state)——你希望对象具有的特征。</li>
<li>状态(status)，描述对象的实际状态，由k8s系统提供和更新。</li>
</ul>
<p>例如，k8s Deployment是一个可以表示你集群上运行的应用程序的对象。当你创建一个Deployment，你可以设置部署规约以指定你希望应用程序运行三个副本。k8s系统读取部署规约并启动应用程序所需的三个实例——更新状态以符合你的规范。如果这些事例中的任何一个失败(状态改变)，k8s系统通过进行校正来响应规约和状态之间的差异。在这种情况下，启动替换实例。</p>
<p><br></p>
<p><strong>描述k8s 对象</strong><br>在k8s中创建对象时，必须提供描述其期望状态的对象规约，以及有关对象的一些基本信息(如 名称)。当你使用k8s API来创建对象时，API请求必须在请求正文中将信息作为JSON格式。通常，你在<code>.yaml</code>文件中向<code>kubectl</code>提供信息，<code>kubectl</code>在发出API请求时将信息转换为JSON格式。</p>
<p>栗子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># for versions before 1.9.0 use apps/v1beta2</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.7.9</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br></pre></td></tr></table></figure>
<p>使用类似上面的<code>.yaml</code>文件创建部署的方法，是在<code>kubectl</code>命令行工具中使用<code>kubectl create</code>命令，将<code>.yaml</code>文件作为参数传递。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f https://k8s.io/examples/application/deployment.yaml --record</span><br><span class="line">#deployment &quot;nginx-deployment&quot; created</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>必填字段</strong><br>在要创建k8s 对象的<code>.yaml</code>文件中，必须配置一下字段：</p>
<ul>
<li><code>apiVersion</code>： 创建对象的k8s API版本</li>
<li><code>kind</code>： 创建的对象类型</li>
<li><code>metadata</code>： 有助于识别对象唯一性的数据，包括name, uid, namespace…</li>
</ul>
<p>你还需要提供<code>spec</code>字段。对于每个k8s对象，对象规约的精确格式是不同的，并且包含特定于该对象的嵌套字段。</p>
<p><br><br><br></p>
<h4 id="Names"><a href="#Names" class="headerlink" title="Names"></a>Names</h4><p>Kubernetes REST API中所有对象都用<strong>Name</strong>和<strong>UID</strong>来明确标识。<br>对于用户提供的非唯一的属性，k8s提供<strong>labels</strong>和<strong>annotations</strong>。</p>
<p><br></p>
<p><strong>Names</strong><br>客户端提供的字符串，用于引用资源URL中的对象。如<code>/api/v1/pods/some-name</code>.<br>一个给定<code>kind</code>的对象同时只能有一个<code>name</code>。但如果你删除了此对象，便可以为新对象赋予此名字。<br>按照惯例，k8s资源的名称的最大长度应为253个字符，并由<code>小写字母,数字, -, .</code>字符组成。但某些资源可能具有更过限制。</p>
<p><br></p>
<p><strong>UIDs</strong><br>k8s 系统生成的字符串，用于唯一标识对象。<br>在k8s集群的整个生命周期中创建的每个对象都具有一个唯一的UID。它旨在区分类似实体的历史事件。</p>
<p><br><br><br></p>
<h4 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h4><p>k8s支持在物理集群中创建多个虚拟集群，这些虚拟机群称为<code>namespaces</code>。命名空间是一种将集群资源划分为多个用途的方法。<br>命名空间名称满足正则表达式，最大长度为63位。</p>
<p><br></p>
<p><strong>什么时候使用多个命名空间</strong><br>命名空间旨在用于多个用户分布在多个团队/多个项目的环境中。对于具有几个到几十个用户的集群，你根本不需要创建和考虑命名空间。<br>命名空间提供名称范围。资源名称在命名空间中必须唯一，但不能跨命名空间。<br>命名空间是一种在多个用户之间划分集群资源的方法。<br>在k8s的未来版本中，默认情况下，同一命名空间中的对象将具有相同的访问控制策略(ACP)。<br>没有必要使用多个命名空间仅来分隔略有不同的资源。如同一软件的不同版本，使用<code>labels</code>来区分同一命名空间内的资源。</p>
<p><br></p>
<p><strong>操作命名空间</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看</span></span><br><span class="line">kubectl get ns</span><br><span class="line">NAME          STATUS    AGE</span><br><span class="line">default       Active    13d</span><br><span class="line">kube-system   Active    13d</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#通过命令创建</span></span><br><span class="line">kubectl create namespace my-namespace</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#或通过文件创建</span></span><br><span class="line">vim my-namespace.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: my-namespace</span><br><span class="line"></span><br><span class="line">kubectl create -f ./my-namespace.yaml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看</span></span><br><span class="line">kubectl get namespace</span><br><span class="line">NAME           STATUS    AGE</span><br><span class="line">default        Active    13d</span><br><span class="line">kube-system    Active    13d</span><br><span class="line">my-namespace   Active    4s</span><br><span class="line"></span><br><span class="line"><span class="comment">#删除</span></span><br><span class="line">kubectl delete namespace my-namespace</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#设置请求的命名空间</span></span><br><span class="line"><span class="comment">#使用--namespace标志临时设置请求的命名空间</span></span><br><span class="line">kubectl kubectl get pods --namespace=default</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置命名空间首选项</span></span><br><span class="line">kubectl config <span class="built_in">set</span>-context $(kubectl config current-context) --namespace=my-namespace</span><br><span class="line">kubectl config view</span><br></pre></td></tr></table></figure>
<p>Kubernetes有三个初始的命名空间：</p>
<ul>
<li><code>default</code>: 没有其它命名空间时，对象的默认命名空间</li>
<li><code>kube-system</code>: k8s系统创建的对象的命名空间</li>
<li><code>kube-public</code>: 此命名空间是自动创建的，可供所有用户读取(包括未认证用户)。此命名空间主要用于集群使用，以防止某些资源在整个集群中可见且可公开读取。此命名空间的公共方面只是一个约定，而非要求。</li>
</ul>
<p>注意：</p>
<ul>
<li>删除一个命名空间会自动删除所有属于该命名空间的资源</li>
<li>k8s初始化的两个命名空间无法删除</li>
<li>持久化卷(persistent volume)不属于任何命名空间，但持久化卷声明(persistent volume claim)是属于某个特定命名空间的</li>
<li>事件(event)是否属于命名空间取决于产生事件的对象</li>
</ul>
<p><br></p>
<p><strong>命名空间和DNS</strong><br>当你创建一个服务(service)，它会创建相应的DNS条目(dns entry)。此条目的格式为<code>&lt;service-name&gt;.&lt;namespace-name&gt;.svc.cluster.local</code>，这表示如果一个容器只是用<code>&lt;service-name&gt;</code>，它将会解析为命名空间本地的服务。这对于在多个命名空间(如 开发/测试/生产)中使用相同的配置非常有用。如果想要扩命名空间访问，则需要使用完全限定的域名(fully qualified domain name)。</p>
<p><br></p>
<p><strong>不是所有对象都在命名空间中</strong><br>大多数k8s资源(pods, services, replication controller…)都在某些命名空间中。然而，命名空间资源本身并不在命名空间中。并且，低级资源(node, persistentVolumes)并不在任何命名空间中。</p>
<p>查看k8s资源是否在命名空间中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl api-resources --namespaced=true</span><br><span class="line">kubectl api-resources --namespaced=false</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="Labels和Selectors"><a href="#Labels和Selectors" class="headerlink" title="Labels和Selectors"></a>Labels和Selectors</h4><p>标签是被关联到对象上的<code>key/value</code>对。标签旨在用于指定对用户有意义且相关的对象的标识属性，但不直接按时核心系统的语义。标签可用于组织和选择对象的子集。标签可在创建时附加到对象，随时可以添加和修改。每个对象可拥有多个标签，对于给定的对象，<code>key</code>必须唯一。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">"metadata": &#123;</span><br><span class="line">  "labels": &#123;</span><br><span class="line">    "key1" : "value1",</span><br><span class="line">    "key2" : "value2",</span><br><span class="line">    "keyN" : "valueN"</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#栗子</span><br><span class="line">"labels": &#123;</span><br><span class="line">  "release" : "stable",</span><br><span class="line">  "environment" : "dev",</span><br><span class="line">  "track" : "daily"</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们最终将<strong>索引(index)</strong>和<strong>反向索引(reverse-index)</strong>标签，用于高效查询和监视，使用它们在UI和CLI中进行排序和分组。我们不希望对非标识(non-identifying)信息使用标签，特别是大型结构化数据。非标识信息应该记录到<code>annorations</code>。</p>
<p>标签使用户能够以松散耦合的方式将自己的组织结构映射到系统对象中，而无需客户端存储这些映射。</p>
<p><br></p>
<p><strong>语法和字符集</strong><br>有效的label key有两个字段: 可选前缀和名称，用斜杆分隔。<br>名字字段是必须的，小于等于63个字符，以字母数字开头和结尾，还可使用<code>-, _, .</code>三个字符。<br>前缀可选。如果指定，前缀必须是DNS子域，不超过253个字符，后跟斜杆<code>/</code>。如果省略，则假定label key对用户是私有的。向最终用户对象添加标签的自动系统组件(kube-scheduler, kube-apserver…)必须制定前缀。<code>kuberneter.io/</code>前缀保留个k8s核心组件。</p>
<p>有效的label value必须小于等于63个字符，可为空，或以字母数字开头和结尾，还可使用<code>-, _, .</code>三个字符。</p>
<p><br></p>
<p><strong>label selectors</strong><br>标签不提供唯一性。通常，我们希望许多对象携带相同的标签。<br>通过<code>label selector</code>，客户端/用户 可以识别一组对象。标签选择器是k8s中的核心分组原语。</p>
<p>API目前支持两种类型的选择器: <code>equality-based</code>和<code>set-based</code>。标签选择器可由逗号<code>,</code>分隔的多个要求组成。<br>一个空(empty)标签选择器(zero requirements)，选择集合中的每个对象。<br>一个空(null)标签选择器(仅可用于选择器字段)不选择任何对象。</p>
<p><strong>equality-based requirement</strong><br>基于平等/不平等的要求允许按标签键和值进行过滤。匹配对象必须满足所有指定的标签约束，尽管它们也可能具有其它标签。<br>允许三种运算符:<code>=, ==, !=</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">environment = production</span><br><span class="line">tier != frontend</span><br></pre></td></tr></table></figure>
<p><strong>set-based requirement</strong><br>基于集合的标签的要求允许根据一组值过滤键。<br>支持三种操作符: <code>in, notin, exists</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">environment in (production, qa)</span><br><span class="line">tier notin (frontend, backend)</span><br><span class="line">partition</span><br><span class="line">!partition</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>API</strong></p>
<p>LIST and WATCH filtering<br><code>LIST</code>和<code>WATCH</code>操作可以指定标签选择器来过滤使用查询参数返回的对象集。两个要求都是允许的。<br>两种标签选择器的样式都可使用通过TEST客户端列出或查看资源。</p>
<ul>
<li>equality-based requirements: <code>?labelSelector=environment%3Dproduction,tier%3Dfrontend</code></li>
<li>set-based requirements: <code>?labelSelector=environment+in+%28production%2Cqa%29%2Ctier+in+%28frontend%29</code></li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#equality-based</span></span><br><span class="line">kubectl get pods -l environment=production,tier=frontend</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#set-based</span></span><br><span class="line">kubectl get pods -l <span class="string">'environment in (production),tier in (frontend)'</span></span><br><span class="line">kubectl get pods -l <span class="string">'environment in (production, qa)'</span></span><br><span class="line">kubectl get pods -l <span class="string">'environment,environment notin (frontend)'</span></span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>Service and ReplicationController</strong><br>服务所针对的一组pod使用标签选择器进行定义。类似地，副本控制器应该管理的pod数量也使用标签选择器定义。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#json格式</span><br><span class="line">&quot;selector&quot;: &#123;</span><br><span class="line">  &quot;component&quot;: &quot;redis&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#yaml格式</span><br><span class="line">selector:</span><br><span class="line">  component: redis</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="Annotation"><a href="#Annotation" class="headerlink" title="Annotation"></a>Annotation</h4><p>你可使用k8s <code>annotation</code>(注释)将任意非标识(non-identifying)元数据附加到对象。工具和库等客户端可以检索此元数据。它也是<code>key/value</code>对。<br>Annotations不会被k8s直接使用，其主要目的是方便用户阅读查找。</p>
<p><br></p>
<p><strong>将元数据追加到对象</strong><br>你可使用<code>label</code>或<code>annotations</code>将原数据追加到k8s对象。<br>标签用于选择对象和查找满足特定条件的对象集合。<br>相反，注释不用于识别和选择对象。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">"metadata": &#123;</span><br><span class="line">  "annotations": &#123;</span><br><span class="line">    "key1" : "value1",</span><br><span class="line">    "key2" : "value2"</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="Field-Selectors"><a href="#Field-Selectors" class="headerlink" title="Field Selectors"></a>Field Selectors</h4><p>字段选择器允许你根据一个或多个资源字段的值选择k8s资源。</p>
<p>栗子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">#三种操作符</span><br><span class="line">=, ==, !=</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">metadata.name=my-service</span><br><span class="line">metadata.namespace!=default</span><br><span class="line">status.phase=Pending</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#</span><br><span class="line">kubectl get pods --field-selector status.phase=Running</span><br><span class="line">NAME                           READY     STATUS    RESTARTS   AGE</span><br><span class="line">hello-world-3198537413-138pg   1/1       Running   0          5d</span><br><span class="line">hello-world-3198537413-67g6d   1/1       Running   0          5d</span><br><span class="line">hello-world-3198537413-bf73l   1/1       Running   0          5d</span><br><span class="line">hello-world-3198537413-ddgb3   1/1       Running   0          5d</span><br><span class="line">hello-world-3198537413-ffj90   1/1       Running   0          5d</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line">kubectl get  ingress --field-selector foo.bar=baz</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line">kubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line">kubectl get statefulsets,services --field-selector metadata.namespace!=default</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="Recommended-Labels"><a href="#Recommended-Labels" class="headerlink" title="Recommended Labels"></a>Recommended Labels</h4><p>你可以使用比<code>kubectl</code>和<code>dashboard</code>更多的工具来可视化和管理k8s对象。一组通用的标签允许工具以互操作的方式工作，以所有工具都能理解的通用方式描述对象。<br>除了支持工具之外，推荐的标签还以可查询的方式描述应用程序。</p>
<p><code>shared labels and annotations</code>共享一个通用的前缀: <code>app.kubernetes.io</code>。没有前缀的标签对用户是私有的。共享前缀可确保共享标签不会干扰自定义用户标签。</p>
<p><br></p>
<p>为了充分利用这些标签，应将它们应用于每个资源对象。</p>
<table>
<thead>
<tr>
<th>Key</th>
<th>Description</th>
<th>Example</th>
<th>Type</th>
</tr>
</thead>
<tbody>
<tr>
<td>app.kubernetes.io/name</td>
<td>The name of the application</td>
<td>mysql</td>
<td>string</td>
</tr>
<tr>
<td>app.kubernetes.io/instance</td>
<td>A unique name identifying the instance of an application</td>
<td>wordpress-abcxzy</td>
<td>string</td>
</tr>
<tr>
<td>app.kubernetes.io/version</td>
<td>The current version of the application (e.g., a semantic version, revision hash, etc.)</td>
<td>5.7.21</td>
<td>string</td>
</tr>
<tr>
<td>app.kubernetes.io/component</td>
<td>The component within the architecture</td>
<td>database</td>
<td>string</td>
</tr>
<tr>
<td>app.kubernetes.io/part-of</td>
<td>The name of a higher level application this one is part of</td>
<td>wordpress</td>
<td>string</td>
</tr>
<tr>
<td>app.kubernetes.io/managed-by</td>
<td>The tool being used to manage the operation of an application</td>
<td>helm</td>
<td>string</td>
</tr>
</tbody>
</table>
<p>要说明这些标签的运行情况，请考虑一下<code>StatefulSet</code>对象:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line">    <span class="string">app.kubernetes.io/name:</span> <span class="string">mysql</span></span><br><span class="line">    <span class="string">app.kubernetes.io/instance:</span> <span class="string">wordpress-abcxzy</span></span><br><span class="line">    <span class="string">app.kubernetes.io/version:</span> <span class="string">"5.7.21"</span></span><br><span class="line">    <span class="string">app.kubernetes.io/component:</span> <span class="string">database</span></span><br><span class="line">    <span class="string">app.kubernetes.io/part-of:</span> <span class="string">wordpress</span></span><br><span class="line">    <span class="string">app.kubernetes.io/managed-by:</span> <span class="string">helm</span></span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h3 id="使用kubectl进行对象管理"><a href="#使用kubectl进行对象管理" class="headerlink" title="使用kubectl进行对象管理"></a>使用kubectl进行对象管理</h3><p><code>kubectl</code>命令行工具支持多种方式来创建和管理k8s对象。<br>应该只使用一种技术来管理k8s对象。对同一个对象的混合和匹配技术会导致未定义的行为。</p>
<table>
<thead>
<tr>
<th>Management technique</th>
<th>Operates on</th>
<th>Recommended environment</th>
<th>Supported writers</th>
<th>Learning curve</th>
</tr>
</thead>
<tbody>
<tr>
<td>Imperative commands</td>
<td>Live objects</td>
<td>Development projects</td>
<td>1+</td>
<td>Lowest</td>
</tr>
<tr>
<td>Imperative object configuration</td>
<td>Individual files</td>
<td>Production projects</td>
<td>1</td>
<td>Moderate</td>
</tr>
<tr>
<td>Declarative object configuration</td>
<td>Directories of files</td>
<td>Production projects</td>
<td>1+</td>
<td>Highest</td>
</tr>
</tbody>
</table>
<p><br><br><br></p>
<h4 id="必要的命令"><a href="#必要的命令" class="headerlink" title="必要的命令"></a>必要的命令</h4><p>Managing Kubernetes Objects Using Imperative Commands</p>
<p>使用k8s命令行工具内置的必要命令，可直接快速创建、更新、删除k8s对象。</p>
<p><br></p>
<p><strong>权衡</strong><br><code>kubectl</code>工具支持三种对象管理：</p>
<ul>
<li>Imperative commands(必要的命令)</li>
<li>Imperative object configuration(必要的对象配置)</li>
<li>Declarative object configuration(声明的对象配置)</li>
</ul>
<p><br><br><br></p>
<h5 id="创建对象"><a href="#创建对象" class="headerlink" title="创建对象"></a>创建对象</h5><p><code>kubectl</code>工具支持动词驱动的命令，用以创建一些最常见的对象类型。这些命令被命名为即使不熟悉k8s对象类型的用户也能够识别。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建一个新的Deployment对象，以在一个或多个pod中运行container</span></span><br><span class="line">run</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个新的Service对象，以在pod间对流量进行负载均衡</span></span><br><span class="line">expose</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个新的Autoscaler对象，用以自动水平伸缩控制器</span></span><br><span class="line">autoscale</span><br></pre></td></tr></table></figure>
<p><code>kubectl</code>工具还支持由对象类型驱动的创建命令。这些命令支持更多对象类型，并且更明确地表达了它们的意图，但要求用户知道他们打算创建的对象类型。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create &lt;objecttype&gt; [&lt;subtype&gt;] &lt;instancename&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">#栗子</span></span><br><span class="line">kubectl create service nodeport &lt;service-name&gt;</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h5 id="更新对象"><a href="#更新对象" class="headerlink" title="更新对象"></a>更新对象</h5><p><code>kubectl</code>命令支持动词驱动的命令，用于一些常见的更新操作。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过更新控制器的副本数，水平伸缩控制器，以添加或删除pod</span></span><br><span class="line">scale</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#在对象中添加或删除注释</span></span><br><span class="line">annotate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#在对象中添加或删除标签</span></span><br><span class="line">label</span><br></pre></td></tr></table></figure>
<p><code>kubectl</code>工具还支持由对象的某个驱动的更新命令:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设置对象的一个方面</span></span><br><span class="line"><span class="built_in">set</span></span><br></pre></td></tr></table></figure>
<p><code>kubectl</code>工具支持这些直接地更新实时对象的额外方法，但他们需要更好地裂解k8s对象模式。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过在编辑器中打开其配置，直接编辑实时对象的原始配置文件</span></span><br><span class="line">edit</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#使用补丁字符串，直接修改实时对象的特定字段</span></span><br><span class="line">patch</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h5 id="删除对象"><a href="#删除对象" class="headerlink" title="删除对象"></a>删除对象</h5><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#从集群中删除对象</span></span><br><span class="line">delete &lt;<span class="built_in">type</span>&gt;/&lt;name&gt;</span><br><span class="line"></span><br><span class="line">kubectl delete deployment/nginx</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h5 id="查看对象"><a href="#查看对象" class="headerlink" title="查看对象"></a>查看对象</h5><p>如下这些命令可用于打印除对象信息:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#打印有关匹配对象的基本信息</span></span><br><span class="line">get</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#打印有关匹配对象的详细信息</span></span><br><span class="line">describe</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#打印运行在pod中容器的stdout和stderr</span></span><br><span class="line">logs</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h5 id="创建对象前修改对象"><a href="#创建对象前修改对象" class="headerlink" title="创建对象前修改对象"></a>创建对象前修改对象</h5><p>有些对象字段没有可在<code>create</code>命令汇总使用的标志。在某些情况下，你可使用<code>set</code>和<code>create</code>的组合在对象创建之前为字段指定值。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#set命令</span></span><br><span class="line">kubectl create service clusterip my-svc --clusterip=<span class="string">"None"</span> -o yaml --dry-run \</span><br><span class="line">| kubectl <span class="built_in">set</span> selector --<span class="built_in">local</span> -f - <span class="string">'environment=qa'</span> -o yaml \</span><br><span class="line">| kubectl create -f -</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#--edit标志</span></span><br><span class="line">kubectl create service clusterip my-svc --clusterip=<span class="string">"None"</span> -o yaml --dry-run &gt; /tmp/srv.yaml</span><br><span class="line">kubectl create --edit -f /tmp/srv.yaml</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h4><p>Imperative Management of Kubernetes Objects Using Configuration Files</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#创建对象</span><br><span class="line">kubectl create -f &lt;file | url&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#更新</span><br><span class="line">kubectl replace -f &lt;file | url&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#删除</span><br><span class="line">kubectl delete -f &lt;file | url&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#查看</span><br><span class="line">kubectl get -f &lt;file | url&gt; -o yaml</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="使用配置文件声明管理的k8s对象"><a href="#使用配置文件声明管理的k8s对象" class="headerlink" title="使用配置文件声明管理的k8s对象"></a>使用配置文件声明管理的k8s对象</h4><p>Declarative Management of Kubernetes Objects Using Configuration Files</p>
<p>可通过在目录中存储多个对象配置文件来创建、更新、删除k8s对象，并使用<code>kubectl apply</code>根据递归创建和更新这些对象。<br><code>kubectl apply</code>不支持对象配置命令<code>create</code>和<code>replace</code>。</p>
<p><br></p>
<p><strong>开始前</strong><br>声明性对象配置需要深入理解k8s对象定义和配置。</p>
<p><br><br><br></p>
<h5 id="创建对象-1"><a href="#创建对象-1" class="headerlink" title="创建对象"></a>创建对象</h5><p>使用<code>kubectl apply</code>创建除指定目录中的配置文件定义的已存在的所有对象。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f &lt;directory&gt;/</span><br></pre></td></tr></table></figure>
<p>栗子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  minReadySeconds: 5</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.7.9</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#创建</span><br><span class="line">kubectl apply -f https://k8s.io/examples/application/simple_deployment.yaml</span><br><span class="line">#查看</span><br><span class="line">kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h5 id="更新对象-1"><a href="#更新对象-1" class="headerlink" title="更新对象"></a>更新对象</h5><p>使用<code>kubectl apply</code>更新目录中定义的所有对象，即使这些对象已经存在。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f &lt;directory&gt;/</span><br></pre></td></tr></table></figure>
<p>栗子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">#伸缩</span><br><span class="line">kubectl scale deployment/nginx-deployment --replicas=2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#更新nginx版本，从1.7.9升级到1.11.9</span><br><span class="line">#删除minReadySeconds字段</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.11.9</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#应用更新</span><br><span class="line">kubectl apply -f https://k8s.io/examples/application/update_deployment.yaml</span><br><span class="line">#查看</span><br><span class="line">kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h5 id="删除对象-1"><a href="#删除对象-1" class="headerlink" title="删除对象"></a>删除对象</h5><p>有两种方法:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#推荐</span><br><span class="line">kubectl delete -f &lt;filename&gt;</span><br><span class="line"></span><br><span class="line">#选择</span><br><span class="line">kubectl apply -f &lt;directory/&gt; --prune -l &lt;labels&gt;</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h5 id="查看对象-1"><a href="#查看对象-1" class="headerlink" title="查看对象"></a>查看对象</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get -f &lt;file | url&gt; -o yaml</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h2 id="计算-存储和网络"><a href="#计算-存储和网络" class="headerlink" title="计算,存储和网络"></a>计算,存储和网络</h2><p>Compute, Storage, and Networking Extensions</p>
<p><br></p>
<h3 id="集群管理"><a href="#集群管理" class="headerlink" title="集群管理"></a>集群管理</h3><p>Cluster Administration</p>
<ul>
<li>规划集群</li>
<li>管理集群</li>
<li>保护集群</li>
<li>集群服务</li>
</ul>
<p>详情见配置章节。</p>
<p><br><br><br></p>
<h3 id="证书"><a href="#证书" class="headerlink" title="证书"></a>证书</h3><p>Certificates</p>
<p>当使用客户端证书认证时，你可以通过<code>easyras, openssl, cfssl</code>手动生成证书。</p>
<p><br></p>
<h4 id="openssl"><a href="#openssl" class="headerlink" title="openssl"></a>openssl</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Generate a ca.key with 2048bit</span></span><br><span class="line">openssl genrsa -out ca.key 2048</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#According to the ca.key generate a ca.crt</span></span><br><span class="line">openssl req -x509 -new -nodes -key ca.key -subj <span class="string">"/CN=<span class="variable">$&#123;MASTER_IP&#125;</span>"</span> -days 10000 -out ca.crt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Generate a server.key with 2048bit</span></span><br><span class="line">openssl genrsa -out server.key 2048</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#reate a config file for generating a Certificate Signing Request (CSR)</span></span><br><span class="line">[ req ]</span><br><span class="line">default_bits = 2048</span><br><span class="line">prompt = no</span><br><span class="line">default_md = sha256</span><br><span class="line">req_extensions = req_ext</span><br><span class="line">distinguished_name = dn</span><br><span class="line"></span><br><span class="line">[ dn ]</span><br><span class="line">C = &lt;country&gt;</span><br><span class="line">ST = &lt;state&gt;</span><br><span class="line">L = &lt;city&gt;</span><br><span class="line">O = &lt;organization&gt;</span><br><span class="line">OU = &lt;organization unit&gt;</span><br><span class="line">CN = &lt;MASTER_IP&gt;</span><br><span class="line"></span><br><span class="line">[ req_ext ]</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line"></span><br><span class="line">[ alt_names ]</span><br><span class="line">DNS.1 = kubernetes</span><br><span class="line">DNS.2 = kubernetes.default</span><br><span class="line">DNS.3 = kubernetes.default.svc</span><br><span class="line">DNS.4 = kubernetes.default.svc.cluster</span><br><span class="line">DNS.5 = kubernetes.default.svc.cluster.local</span><br><span class="line">IP.1 = &lt;MASTER_IP&gt;</span><br><span class="line">IP.2 = &lt;MASTER_CLUSTER_IP&gt;</span><br><span class="line"></span><br><span class="line">[ v3_ext ]</span><br><span class="line">authorityKeyIdentifier=keyid,issuer:always</span><br><span class="line">basicConstraints=CA:FALSE</span><br><span class="line">keyUsage=keyEncipherment,dataEncipherment</span><br><span class="line">extendedKeyUsage=serverAuth,clientAuth</span><br><span class="line">subjectAltName=@alt_names</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Generate the certificate signing request based on the config file</span></span><br><span class="line">openssl req -new -key server.key -out server.csr -config csr.conf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Generate the server certificate using the ca.key, ca.crt and server.csr</span></span><br><span class="line">openssl x509 -req -<span class="keyword">in</span> server.csr -CA ca.crt -CAkey ca.key \</span><br><span class="line">-CAcreateserial -out server.crt -days 10000 \</span><br><span class="line">-extensions v3_ext -extfile csr.conf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#View the certificate</span></span><br><span class="line">openssl x509  -noout -text -<span class="keyword">in</span> ./server.crt</span><br></pre></td></tr></table></figure>
<p><br></p>
<h4 id="easyrsa"><a href="#easyrsa" class="headerlink" title="easyrsa"></a>easyrsa</h4><p><br></p>
<h4 id="cfssl"><a href="#cfssl" class="headerlink" title="cfssl"></a>cfssl</h4><p><br></p>
<h4 id="分发自签名CA证书"><a href="#分发自签名CA证书" class="headerlink" title="分发自签名CA证书"></a>分发自签名CA证书</h4><p>客户端节点可以拒绝将自签名(self-signed)CA 证书识别为有效。对于非生产环境火灾防火墙后面运行的部署，你可以将自签名CA证书分发给客户端，并刷新本地列表以获取有效证书。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo cp ca.crt /usr/<span class="built_in">local</span>/share/ca-certificates/kubernetes.crt</span><br><span class="line">sudo update-ca-certificates</span><br><span class="line"></span><br><span class="line">Updating certificates <span class="keyword">in</span> /etc/ssl/certs...</span><br><span class="line">1 added, 0 removed; <span class="keyword">done</span>.</span><br><span class="line">Running hooks <span class="keyword">in</span> /etc/ca-certificates/update.d....</span><br><span class="line"><span class="keyword">done</span>.</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h3 id="云提供商"><a href="#云提供商" class="headerlink" title="云提供商"></a>云提供商</h3><p>跳过！</p>
<p><br><br><br></p>
<h3 id="管理资源"><a href="#管理资源" class="headerlink" title="管理资源"></a>管理资源</h3><p>可能，你已经部署应用程序并通过服务公开它。接下来怎么办？k8s提供了许多工具来帮助你管理应用程序部署(包括伸缩和更新)。我们将更深入讨论配置文件和标签。</p>
<p><br></p>
<h4 id="组织资源配置"><a href="#组织资源配置" class="headerlink" title="组织资源配置"></a>组织资源配置</h4><p>Organizing resource configurations</p>
<p>许多应用程序需要创建多个资源，如Deployment和Service。通过将多个资源组合在同一个文件中(在yaml中以<code>---</code>分隔)，可以简化多个资源的管理。</p>
<p>栗子：<code>nginx-app.yaml</code></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">my-nginx-svc</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">LoadBalancer</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">  - port:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">my-nginx</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">        image:</span> <span class="attr">nginx:1.7.9</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>
<p>使用与单个资源相同的方式创建多个资源。<br>资源将按照它们在文件中出现的顺序创建。因此，最好首先指定Service，因为这将确保Scheduler可以扩展与服务关联的pod，因为它们是由Controller创建的。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f https://k8s.io/examples/application/nginx-app.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment">#service "my-nginx-svc" created</span></span><br><span class="line"><span class="comment">#deployment "my-nginx" created</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#同样也支持多个-f</span></span><br><span class="line">kubectl create -f https://k8s.io/examples/application/nginx/nginx-svc.yaml -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#或者指定一个目录，读取yaml, yml, json文件</span></span><br><span class="line">kubectl create -f https://k8s.io/examples/application/nginx/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#url</span></span><br><span class="line">kubectl create -f https://raw.githubusercontent.com/kubernetes/website/master/content/en/examples/application/nginx/nginx-deployment.yaml</span><br></pre></td></tr></table></figure>
<p><strong>建议的做法是，将与同一微服务或应用程序相关的资源放入同一配置文件中，或将相关联的配置文件分组到同一目录下。</strong></p>
<p><br><br><br></p>
<h4 id="kubectl批量操作"><a href="#kubectl批量操作" class="headerlink" title="kubectl批量操作"></a>kubectl批量操作</h4><p>Bulk operations in kubectl</p>
<p>资源创建并不是<code>kubectl</code>可执行的唯一操作。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete -f https://k8s.io/examples/application/nginx-app.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment">#deployment "my-nginx" deleted</span></span><br><span class="line"><span class="comment">#service "my-nginx-svc" deleted</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#分开的资源</span></span><br><span class="line">kubectl delete deployments/my-nginx    services/my-nginx-svc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#指定label(selector)删除</span></span><br><span class="line">kubectl delete deployment,services -l app=nginx</span><br><span class="line"></span><br><span class="line"><span class="comment">#deployment "my-nginx" deleted</span></span><br><span class="line"><span class="comment">#service "my-nginx-svc" deleted</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#递归删除--recursive -R</span></span><br><span class="line">kubectl create -f project/k8s/development --recursive</span><br><span class="line">kubectl create -f project/k8s/namespaces -f project/k8s/development --recursive</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="高效使用label"><a href="#高效使用label" class="headerlink" title="高效使用label"></a>高效使用label</h4><p>Using labels effectively</p>
<p>到目前为止，我们使用的示例最多只能将一个标签应用于任意资源。在许多情况下，应该使用多个标签来区分集合。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">     labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">guestbook</span></span><br><span class="line"><span class="attr">        tier:</span> <span class="string">backend</span></span><br><span class="line"><span class="attr">        role:</span> <span class="string">master</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看</span></span><br><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">pods</span> <span class="bullet">-Lapp</span> <span class="bullet">-Ltier</span> <span class="bullet">-Lrole</span></span><br><span class="line"></span><br><span class="line"><span class="string">kubectl</span> <span class="string">get</span> <span class="string">pods</span> <span class="bullet">-l</span> <span class="string">app=guestbook,role=master</span></span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="Canary-deployments"><a href="#Canary-deployments" class="headerlink" title="Canary deployments"></a>Canary deployments</h4><p>需要多个标签的另一种情况是区分不同版本的部署，或同一组件的配置。通常的做法是将新应用程序版本的canary与先前版本并排部署，以便新版本可以在完全推出前接收实时生产流量。</p>
<p>例如，你可以使用<code>track</code>标签来区分不同的版本:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#stable version</span></span><br><span class="line"><span class="attr">     name:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">     replicas:</span> <span class="number">3</span></span><br><span class="line">     <span class="string">...</span></span><br><span class="line"><span class="attr">     labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">guestbook</span></span><br><span class="line"><span class="attr">        tier:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">        track:</span> <span class="string">stable</span></span><br><span class="line">     <span class="string">...</span></span><br><span class="line"><span class="attr">     image:</span> <span class="attr">gb-frontend:v3</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#new version</span></span><br><span class="line"><span class="attr">     name:</span> <span class="string">frontend-canary</span></span><br><span class="line"><span class="attr">     replicas:</span> <span class="number">1</span></span><br><span class="line">     <span class="string">...</span></span><br><span class="line"><span class="attr">     labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">guestbook</span></span><br><span class="line"><span class="attr">        tier:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">        track:</span> <span class="string">canary</span></span><br><span class="line">     <span class="string">...</span></span><br><span class="line"><span class="attr">     image:</span> <span class="attr">gb-frontend:v4</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#前端服务将通过选择其标签的公共子集(`track`)来跨越两组副本，以便将流量定向到两个应用程序。</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">     app:</span> <span class="string">guestbook</span></span><br><span class="line"><span class="attr">     tier:</span> <span class="string">frontend</span></span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="更新标签"><a href="#更新标签" class="headerlink" title="更新标签"></a>更新标签</h4><p>Updating labels</p>
<p>有时，在创建新资源之前，需要重新标记现有的pod和其它资源。这可使用<code>kubectl label</code>来完成。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#更新</span><br><span class="line">kubectl label pods -l app=nginx tier=fe</span><br><span class="line"></span><br><span class="line">#查看</span><br><span class="line">kubectl get pods -l app=nginx -L tier</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="更新注释"><a href="#更新注释" class="headerlink" title="更新注释"></a>更新注释</h4><p>Updating annotations</p>
<p>有时，你会想要将注释附加到资源。这个使用<code>kubectl annotatie</code>来完成。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl annotate pods my-nginx-v4-9gw19 description=&apos;my frontend running nginx&apos;</span><br><span class="line"></span><br><span class="line">#查看</span><br><span class="line">kubectl get pod my-nginx-v4-9gw19 -o yaml</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="伸缩应用程序"><a href="#伸缩应用程序" class="headerlink" title="伸缩应用程序"></a>伸缩应用程序</h4><p>Scaling your application</p>
<p>当应用程序上的负载增大或缩小时，可以使用<code>kubectl</code>轻松扩展。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubectl scale deployment/my-nginx --replicas=2</span><br><span class="line"></span><br><span class="line">kubectl get pods -l app=nginx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#自动伸缩</span></span><br><span class="line">kubectl autoscale deployment/my-nginx --min=1 --max=3</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="就地更新资源"><a href="#就地更新资源" class="headerlink" title="就地更新资源"></a>就地更新资源</h4><p>In-place updates of resources</p>
<p>有时，需要对创建的资源进行简单，无中断(non-disruptive)的更新。</p>
<p><strong>kubectl apply</strong><br>建议在源代码管理中维护一组配置文件，以便可以对它们配置的资源的代码进行维护和版本化。这样，你可以使用<code>kubectl apply</code>将更改的配置推送的集群。<br><code>kubectl apply</code>会将注释附加到资源，以便确定自上次调用以来对配置所做的更改。在调用它是，<code>kubectl apply</code>会在先前的配置，提供的输入和资源的当前配置之间进行差异比较，已确定如何修改资源。</p>
<p><br></p>
<p><strong>kubectl edit</strong><br>或者，你可使用<code>kubectl edit</code>来更新资源。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit deployment/my-nginx</span><br><span class="line">#这样就和vim差不多，可修改此部署</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>kubectl patch</strong><br>你可使用<code>kubectl patch</code>来更新API对象。此命令支持JSON patch, JSON merge patch和 strategic merge patch。</p>
<p><br><br><br></p>
<h4 id="破坏性更新"><a href="#破坏性更新" class="headerlink" title="破坏性更新"></a>破坏性更新</h4><p>Disruptive updates</p>
<p>在某些情况下，你可能需要更新初始化后无法更新的资源字段，或者你可能只想立即进行递归更改，例如修复部署创建的损坏的pod。要更改此类资源，请使用<code>replace --force</code>——它将删除并重新创建资源。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl replace -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml --force</span><br><span class="line">deployment &quot;my-nginx&quot; deleted</span><br><span class="line">deployment &quot;my-nginx&quot; replaced</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="在服务没有中断的情况下更新应用程序"><a href="#在服务没有中断的情况下更新应用程序" class="headerlink" title="在服务没有中断的情况下更新应用程序"></a>在服务没有中断的情况下更新应用程序</h4><p>Updating your application without a service outage</p>
<p>在某些时候，你最终需要更新已部署的应用程序，通常是指定新的image或image tag。<code>kubectl</code>支持多种更新操作，每种操作都适用于不同的场景。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kubectl run my-nginx --image=nginx:1.7.9 --replicas=3</span><br><span class="line">#deployment &quot;my-nginx&quot; created</span><br><span class="line"></span><br><span class="line">#更新nginx版本为: 1.9.1</span><br><span class="line">kubectl edit deployment/my-nginx</span><br><span class="line">#修改镜像那一行</span><br></pre></td></tr></table></figure>
<p>部署将以声明的方式逐步更新已部署的nginx应用程序。它确保在更新时只有一定数量的旧副本可能会关闭，并且在所需数量的pod之上只能创建一定数量的新副本。</p>
<p><br><br><br></p>
<h3 id="集群网络"><a href="#集群网络" class="headerlink" title="集群网络"></a>集群网络</h3><p>Cluster Networking</p>
<p>默认情况下，k8s与docker的网络方式有所不同。有4个网络问题需要解决：</p>
<ul>
<li><strong>高度耦合的容器到容器的通信</strong>: 这通过pod和localhost通信解决</li>
<li><strong>pod到pod的通信</strong>： 这是侧重点</li>
<li><strong>pod到service的通信</strong>： 这包含在Service中</li>
<li><strong>external到service的通信</strong>： 这包含在service中</li>
</ul>
<p>k8s假设pod与pod间是可以通信的，无论它们位于哪个主机。每个pod都有自己的IP地址，因此你无需在pod之间明确创建链接，也几乎不需要处理映射容器端口到主机端口。这创建了一个干净的向后兼容的模型，从端口分配、命名、服务发现、负载均衡、应用程序配置和迁移的角度来看，pod可以像VM或物理主机一样。</p>
<p>为实现此目的，你需要设置集群网络。</p>
<p><br></p>
<h4 id="Docker模型"><a href="#Docker模型" class="headerlink" title="Docker模型"></a>Docker模型</h4><p>在讨论k8s网络方法之前，有必要回顾Docker网络方式。默认情况下，Docker使用<code>host-private</code>网络。它创建一个虚拟网桥(称为docker0)，并从RFC1918中为该网桥定义的一个专用地址块中分配一个子网。对于Docker创建的每个容器，它分配一个连接到网桥的虚拟以太网设备(称为veth)。使用Linux命名空间将<code>veth</code>映射为容器中的<code>eth0</code>。容器内的<code>eth0</code>网口从桥接器的地址范围获取IP地址。<br>为了使Docker容器跨节点进行通信，必须在计算机自己的IP地址上分配端口，然后将这些端口转发/代理到容器。这意味着容器必须小心地使用端口，或动态分配端口。</p>
<p><br><br><br></p>
<h4 id="k8s模型"><a href="#k8s模型" class="headerlink" title="k8s模型"></a>k8s模型</h4><p>跨多开发者协调端口非常难以大规模地进行，并使用户暴露在他们无法控制的集群级别问题之外。动态端口分配给系统带来了很多复杂性——每个应用程序都必须将端口作为标志，API server必须知道如何将动态端口号插入配置块，服务必须知道如何找到彼此。与此相关，k8s采取了不同的方法。</p>
<p>k8s对任何网络实施都强加了一下基本要求：</p>
<ul>
<li>容器间可互相通信而无需NAT</li>
<li>所有节点都可与所有容器通信而无需NAT</li>
<li>容器看到的IP与其他人看到的IP相同</li>
</ul>
<p>实际上，k8s在pod范围应用IP地址，pod中的容器共享其网络命名空间(包括IP地址)。这意味着pod中的容器都可以在localhost上彼此通信。这被称为<code>ip-per-pod</code>模型。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">#在Docker中查看</span><br><span class="line">docker network inspect bridge</span><br><span class="line"></span><br><span class="line">#可看到副本集的容器，都是pod，而非container</span><br><span class="line">#这也证明container共享pod的网络空间</span><br><span class="line">#注意它的网关便是docker0</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;Name&quot;: &quot;bridge&quot;,</span><br><span class="line">        &quot;Id&quot;: &quot;68bc0cf07a4d7666e1d35f2c1cf179ae8605b431353ba93446abc898de086a9c&quot;,</span><br><span class="line">        &quot;Created&quot;: &quot;2018-07-23T17:45:54.42038221+08:00&quot;,</span><br><span class="line">        &quot;Scope&quot;: &quot;local&quot;,</span><br><span class="line">        &quot;Driver&quot;: &quot;bridge&quot;,</span><br><span class="line">        &quot;EnableIPv6&quot;: false,</span><br><span class="line">        &quot;IPAM&quot;: &#123;</span><br><span class="line">            &quot;Driver&quot;: &quot;default&quot;,</span><br><span class="line">            &quot;Options&quot;: null,</span><br><span class="line">            &quot;Config&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;Subnet&quot;: &quot;10.254.76.0/24&quot;,</span><br><span class="line">                    &quot;Gateway&quot;: &quot;10.254.76.1&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Internal&quot;: false,</span><br><span class="line">        &quot;Attachable&quot;: false,</span><br><span class="line">        &quot;Containers&quot;: &#123;</span><br><span class="line">            &quot;7d2e6561fa81730ae05743f78871666df75cf5e6f483b71da33137823c172333&quot;: &#123;</span><br><span class="line">                &quot;Name&quot;: &quot;k8s_POD.24f70ba9_hello-world-3198537413-138pg_default_adb8f0fe-8fea-11e8-b10b-000c29aa7e75_785c4a84&quot;,</span><br><span class="line">                &quot;EndpointID&quot;: &quot;bf50c5a71ad26531a370a73ce8da5903d32b9e2f8b8397d7405b914203071c45&quot;,</span><br><span class="line">                &quot;MacAddress&quot;: &quot;02:42:0a:fe:4c:06&quot;,</span><br><span class="line">                &quot;IPv4Address&quot;: &quot;10.254.76.6/24&quot;,</span><br><span class="line">                &quot;IPv6Address&quot;: &quot;&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;ea9fbf660f27943b866759a084dc26457474d73c50082939f157ed1dfe0bc806&quot;: &#123;</span><br><span class="line">                &quot;Name&quot;: &quot;k8s_POD.24f70ba9_hello-world-3198537413-ddgb3_default_adb90c8c-8fea-11e8-b10b-000c29aa7e75_0452e1f4&quot;,</span><br><span class="line">                &quot;EndpointID&quot;: &quot;e83401827e0e6d2896eb46c7b252594c1694ca119d0cbd74c29383209b80a128&quot;,</span><br><span class="line">                &quot;MacAddress&quot;: &quot;02:42:0a:fe:4c:02&quot;,</span><br><span class="line">                &quot;IPv4Address&quot;: &quot;10.254.76.2/24&quot;,</span><br><span class="line">                &quot;IPv6Address&quot;: &quot;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Options&quot;: &#123;</span><br><span class="line">            &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;,</span><br><span class="line">            &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;,</span><br><span class="line">            &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;,</span><br><span class="line">            &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;,</span><br><span class="line">            &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;,</span><br><span class="line">            &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Labels&quot;: &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="如何实现k8s网络模型"><a href="#如何实现k8s网络模型" class="headerlink" title="如何实现k8s网络模型"></a>如何实现k8s网络模型</h4><p>How to implement the Kubernetes networking model</p>
<p>有多种方式实现此网络模型，以下做一个概述。</p>
<ul>
<li>ACI</li>
<li>AOS from Apstra</li>
<li>Big Cloud Fabric from Big Switch Networks</li>
<li>Cilium</li>
<li>CNI-Genie from Huawei</li>
<li>Contiv</li>
<li>Contrail</li>
<li>Flannel</li>
<li>Google Compute Engine</li>
<li>Kube-router</li>
<li>L2 networks and linux bridging</li>
<li>Multus</li>
<li>NSX-T</li>
<li>Nuage Networks VCS</li>
<li>OpenVSwitch</li>
<li>OVN</li>
<li>Project Calico</li>
<li>Romana</li>
<li>Weave Net from Weaveworks</li>
</ul>
<p><br><br><br></p>
<h3 id="日志架构"><a href="#日志架构" class="headerlink" title="日志架构"></a>日志架构</h3><p>Logging Architecture</p>
<p>应用程序和系统日志可以帮助你了解集群内部发生的情况。大多数现代应用程序都有某种日志机制，因此，大多数容器化引擎同样设计来支持多种日志。容器化应用程序最简单、最受欢迎的日志方法是写入<code>stdout</code>和<code>stderr</code>。</p>
<p>但是，容器引擎或<code>runtime</code>提供的本地(native)功能通常不足以构建完整的日志解决方案。例如，如果container crashe、pod evicted、node dies，你通常仍然希望访问应用程序的日志。因此，日志应独立于container、pod、node，并具有单独存储(separate storage)和生命周期(lifecycle)。这个概念称为集群级日志(cluster-level-loggin)。集群级日志需要单独的后端来<strong>存储(store)、分析(analyze)、查询(query)</strong>日志。k8s不提供日志数据的本地存储解决方案，但你可以将许多现有的日志解决方案集成到k8s集群中。</p>
<p>集群级日志架构假设在集群内部或外部存在日志记录后端。</p>
<p><br><br><br></p>
<h4 id="k8s基本日志"><a href="#k8s基本日志" class="headerlink" title="k8s基本日志"></a>k8s基本日志</h4><p>Basic logging in Kubernetes</p>
<p>本节中，k8s将日志记录到到标准输出。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/k8s/test/counter-pod.yaml</span><br><span class="line">#此pod每秒输出一条信息</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: counter</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: count</span><br><span class="line">    image: busybox</span><br><span class="line">    args: [/bin/sh, -c,</span><br><span class="line">            &apos;i=0; while true; do echo &quot;$i: $(date)&quot;; i=$((i+1)); sleep 1; done&apos;]</span><br><span class="line"></span><br><span class="line">#创建</span><br><span class="line">#kubectl create -f /etc/k8s/test/counter-pod</span><br><span class="line"></span><br><span class="line">#不指定命名空间，则默认default</span><br><span class="line">#也可在配置文件里指定命名空间</span><br><span class="line">#kubectl create -f /etc/k8s/test/counter-pod --namespace=test</span><br><span class="line"></span><br><span class="line">#查看</span><br><span class="line">#如果pod有多个容器，则应该指定容器名称</span><br><span class="line">kubectl logs counter</span><br><span class="line"></span><br><span class="line">0: Fri Aug 10 07:43:09 UTC 2018</span><br><span class="line">1: Fri Aug 10 07:43:10 UTC 2018</span><br><span class="line">2: Fri Aug 10 07:43:11 UTC 2018</span><br><span class="line">3: Fri Aug 10 07:43:12 UTC 2018</span><br><span class="line">4: Fri Aug 10 07:43:13 UTC 2018</span><br><span class="line">5: Fri Aug 10 07:43:14 UTC 2018</span><br><span class="line">6: Fri Aug 10 07:43:15 UTC 2018</span><br><span class="line">7: Fri Aug 10 07:43:16 UTC 2018</span><br><span class="line">8: Fri Aug 10 07:43:17 UTC 2018</span><br><span class="line">9: Fri Aug 10 07:43:18 UTC 2018</span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="节点级日志记录"><a href="#节点级日志记录" class="headerlink" title="节点级日志记录"></a>节点级日志记录</h4><p>Logging at the node level</p>
<p><img src="/images/K8s/logging-node-level.png" alt="节点级日志"></p>
<p><br></p>
<p>容器化应用程序写入<code>stdout</code>, <code>stderr</code>的所有内容，都由容器引擎处理并重定向到某处。Docker容器引擎可修改日志驱动程序，将日志写入到其它地方(file, json, fluent…)。</p>
<blockquote>
<p>注意<br>Docker json日志驱动将每一行视为单独的消息，它没有直接支持多行消息，你需要使用更高级别来处理它。</p>
</blockquote>
<p>默认情况下，如果容器重启，<code>kubelet</code>会使用其日志保留一个已终止(terminated)的容器。如果从节点上驱逐pod，则所有相应的容器也会被驱逐(包括日志)。</p>
<p>节点级日志记录中，一个重要考虑因素是实现日志轮询(log rotation)，以便日志不会占用节点所有可用存储。k8s目前不负责轮询日志，但部署工具应该配置方案来解决日志轮询问题。<br>例如，在k8s集群中，部署一个脚本程序，用于日志轮询。或设置Docker container runtime的<code>log-opt</code>标志已自动轮询应用程序日志。</p>
<p>当在基本日志记录中运行<code>kubectl logs</code>命令时，节点上的<code>kubelet</code>会处理请求直接从日志文件读取，返回响应的内容。<br>注意： 如果某个外部系统已执行轮询，则<code>kubectl  logs</code>只能获取到最新的日志文件。</p>
<p><br></p>
<p><strong>system component logs</strong><br>有两种类型的系统组件:</p>
<ul>
<li><strong>run in container</strong>: 如<code>kube-proxy</code></li>
<li><strong>not run in container</strong>: 如<code>kubelet</code>, Docker</li>
</ul>
<p>在使用<code>systemd</code>的机器上，<code>kubelet</code>和<code>container runtime</code>将日志写到<code>journald</code>。如果没有<code>systemd</code>，则写到<code>/var/log/</code>下。容器内的系统组件始终将日志写入<code>/var/log</code>目录下，绕过默认的日志机制。<br>与容器日志类似，在<code>/var/log/</code>目录下的系统组件日志也应该被轮询。</p>
<p><br><br><br></p>
<h4 id="集群级日志架构"><a href="#集群级日志架构" class="headerlink" title="集群级日志架构"></a>集群级日志架构</h4><p>Cluster-level logging architectures</p>
<p>k8s官方没有提供原生的集群级日志记录，但你可以考虑集中常见方法：</p>
<ul>
<li>在每个节点上使用<code>node-level logging agent</code></li>
<li>用于记录应用程序pod的专用<code>sidecar container</code></li>
<li>将日志直接从应用程序推送到后端</li>
</ul>
<p><br></p>
<p><strong>Using a node logging agent</strong></p>
<p><img src="/images/K8s/logging-with-node-agent.png" alt=""></p>
<p>你可以通过在每个节点上包含一个 节点级日志记录代理 来实现集群级日志记录。它是一个用于公开日志或将日志推送到后端的专用工具。<br>通常，此日志代理是一个容器，它可以访问该节点上所有应用程序容器的日志文件的目录。</p>
<p>由于日志记录代理必须在每个节点上运行，因此，将其实现为节点上的<code>DaemonSet replica</code>, <code>manifest pod</code>, <code>dedicated native process</code>是很常见的。然后，后两种方法已被弃用，并且非常不建议。</p>
<p>对于k8s集群，使用节点级日志代理是最常见和鼓励的方法，因为它在每个节点上只创建一个Agent，并且不需要对节点上运行的应用程序进行任何更改。然而，节点级日志仅适用于应用程序的<code>stdout</code>和<code>stderr</code>。</p>
<p>k8s并未指定logging Agent，但有两个可选的日志代理与k8s一同打包。两者都使用<code>fluentd</code>的自定义配置作为节点上的代理。</p>
<ul>
<li>Stackdriver Logging: 用于Google Cloud Platform</li>
<li>Elasticsearch</li>
</ul>
<p><br></p>
<p><strong>Using a sidecar container with the logging agent</strong><br>你可通过以下方式使用<code>sidecar container</code>:</p>
<ul>
<li><code>sidecar container</code>将应用程序的日志传输到自己的<code>stdout</code></li>
<li><code>sidecar container</code>容器运行一个<code>Logging Agent</code>，此代理从应用程序容器中获取日志</li>
</ul>
<p><img src="/images/K8s/logging-with-streaming-sidecar.png" alt=""></p>
<p><br></p>
<p>通过让<code>sidecar container</code>的stream流向他们自己的<code>stdout/stderr</code>，你可利用已经在每个节点上运行的<code>kubelet</code>和<code>logging agent</code>。<code>sidecat container</code>从file、socket、journald读取日志。每个单独的<code>sidecar container</code>将日志打印到自己的<code>stdout/stderr</code>。<br>此方法允许你从应用程序的不同部分分离多个日志流，其中一些可能缺乏对写入<code>stdout/stderr</code>的支持。重定向日志背后的逻辑是最小的，因此它几乎不是一个重要的开销。此外，因为<code>stdout/stderr</code>由kubelet处理，所以你可以使用如<code>kubectl logs</code>这样的内置工具。</p>
<p><br></p>
<p>考虑如下栗子，pod运行单个容器，此容器使用两种不同的日志格式写入两个不同的日志。</p>
<p>two-files-counter-pod.yaml</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">counter</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">count</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    args:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">/bin/sh</span></span><br><span class="line"><span class="bullet">    -</span> <span class="bullet">-c</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">&gt;</span></span><br><span class="line"><span class="string">      i=0;</span></span><br><span class="line"><span class="string">      while true;</span></span><br><span class="line"><span class="string">      do</span></span><br><span class="line"><span class="string">        echo "$i: $(date)" &gt;&gt; /var/log/1.log;</span></span><br><span class="line"><span class="string">        echo "$(date) INFO $i" &gt;&gt; /var/log/2.log;</span></span><br><span class="line"><span class="string">        i=$((i+1));</span></span><br><span class="line"><span class="string">        sleep 1;</span></span><br><span class="line"><span class="string">      done</span></span><br><span class="line"><span class="string"></span><span class="attr">    volumeMounts:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">varlog</span></span><br><span class="line"><span class="attr">      mountPath:</span> <span class="string">/var/log</span></span><br><span class="line"><span class="attr">  volumes:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">varlog</span></span><br><span class="line"><span class="attr">    emptyDir:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure>
<p>即使你设法将两个组件重定向到容器的<code>stdout</code>，在同一个日志流中包含不同格式的日志条目也会很麻烦。相反，你可以引入两个<code>sidecar container</code>。每个<code>sidecar container</code>可以从共享卷(shared volume)中<code>tail</code>特定的日志文件，然后将日志重定向到自己的<code>stdout</code>。</p>
<p><br></p>
<p>这是pod运行两个<code>sidecat container</code>的配置文件。<br>三个容器共享了<code>/var/log</code>。</p>
<p>two-file-counter-pod-streaming-sidecar.yaml</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">counter</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">count</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    args:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">/bin/sh</span></span><br><span class="line"><span class="bullet">    -</span> <span class="bullet">-c</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">&gt;</span></span><br><span class="line"><span class="string">      i=0;</span></span><br><span class="line"><span class="string">      while true;</span></span><br><span class="line"><span class="string">      do</span></span><br><span class="line"><span class="string">        echo "$i: $(date)" &gt;&gt; /var/log/1.log;</span></span><br><span class="line"><span class="string">        echo "$(date) INFO $i" &gt;&gt; /var/log/2.log;</span></span><br><span class="line"><span class="string">        i=$((i+1));</span></span><br><span class="line"><span class="string">        sleep 1;</span></span><br><span class="line"><span class="string">      done</span></span><br><span class="line"><span class="string"></span><span class="attr">    volumeMounts:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">varlog</span></span><br><span class="line"><span class="attr">      mountPath:</span> <span class="string">/var/log</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">count-log-1</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    args:</span> <span class="string">[/bin/sh,</span> <span class="bullet">-c,</span> <span class="string">'tail -n+1 -f /var/log/1.log'</span><span class="string">]</span></span><br><span class="line"><span class="attr">    volumeMounts:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">varlog</span></span><br><span class="line"><span class="attr">      mountPath:</span> <span class="string">/var/log</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">count-log-2</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    args:</span> <span class="string">[/bin/sh,</span> <span class="bullet">-c,</span> <span class="string">'tail -n+1 -f /var/log/2.log'</span><span class="string">]</span></span><br><span class="line"><span class="attr">    volumeMounts:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">varlog</span></span><br><span class="line"><span class="attr">      mountPath:</span> <span class="string">/var/log</span></span><br><span class="line"><span class="attr">  volumes:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">varlog</span></span><br><span class="line"><span class="attr">    emptyDir:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure>
<p><br></p>
<p>现在运行此pod，并单独访问每个日志流:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#run</span></span><br><span class="line">kubectl create -f /etc/k8s/<span class="built_in">test</span>/two-file-counter-pod-streaming-sidecar.yaml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#get</span></span><br><span class="line">kubectl get pod/counter -o wide</span><br><span class="line">NAME      READY     STATUS    RESTARTS   AGE       IP           NODE</span><br><span class="line">counter   3/3       Running   0          9m        10.244.2.9   salt01</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">kubectl logs counter</span><br><span class="line">Error from server (BadRequest): a container name must be specified <span class="keyword">for</span> pod counter, choose one of: [count count-log-1 count-log-2]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#logs</span></span><br><span class="line">kubectl logs counter count-log-1</span><br><span class="line"></span><br><span class="line">0: Tue Aug 14 02:58:29 UTC 2018</span><br><span class="line">1: Tue Aug 14 02:58:30 UTC 2018</span><br><span class="line">2: Tue Aug 14 02:58:31 UTC 2018</span><br><span class="line">3: Tue Aug 14 02:58:32 UTC 2018</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl logs counter count-log-2</span><br><span class="line"></span><br><span class="line">Tue Aug 14 02:58:29 UTC 2018 INFO 0</span><br><span class="line">Tue Aug 14 02:58:30 UTC 2018 INFO 1</span><br><span class="line">Tue Aug 14 02:58:31 UTC 2018 INFO 2</span><br><span class="line">Tue Aug 14 02:58:32 UTC 2018 INFO 3</span><br></pre></td></tr></table></figure>
<p>集群中安装的节点级代理会自动获取这些日志流，而无需进一步配置。如果愿意，可将代理配置为根据源容器解析日志行。</p>
<p>注意，进错CPU和内存使用率很低，将日志写入文件然后将它们流式传输到<code>stdout</code>会使磁盘使用量增加一倍。如果你有一个应用程序将日志写到单个文件，通常最好将<code>/dev/stdout</code>设置为目标，而不是实现流式<code>sidecar container</code>方法。</p>
<p><code>sidecar container</code>还可用于应用程序本身日志轮询。然而，建议直接使用<code>stdout/stderr</code>并将日志的轮询和保留交给<code>kubelet</code>。</p>
<p><br></p>
<p><strong>Sidecar container wiht a logging agent</strong></p>
<p><img src="/images/K8s/logging-with-sidecar-agent.png" alt="官方栗子"></p>
<p><br></p>
<p><img src="/images/K8s/filebeat-log-collector-arch.png" alt="额外栗子"></p>
<p><br></p>
<p>如果节点级日志记录代理对你来说不够灵活，你可以创建一个带有单独日志记录代理程序的<code>sidecar container</code>，该代理可专门配置来与你的程序一起运行。</p>
<blockquote>
<p>注意：<br>在<code>sidecar container</code>使用日志记录代理将会消耗大量资源。此外，你将无法使用<code>kubectl logs</code>命令访问这些日志，因为它们不受kubelet控制。</p>
</blockquote>
<p>栗子使用<code>fluentd</code>作为<code>logging agent</code>。有两个可用于实现此方法的配置文件：</p>
<ul>
<li>ConfigMap<br>使用<code>ConfigMap</code>来配置fluentd。具体配置参考fluentd官方文档。</li>
</ul>
<p><code>fluentd-sidecat-config.yaml</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: fluentd-config</span><br><span class="line">data:</span><br><span class="line">  fluentd.conf: |</span><br><span class="line">    &lt;source&gt;</span><br><span class="line">      type tail</span><br><span class="line">      format none</span><br><span class="line">      path /var/log/1.log</span><br><span class="line">      pos_file /var/log/1.log.pos</span><br><span class="line">      tag count.format1</span><br><span class="line">    &lt;/source&gt;</span><br><span class="line"></span><br><span class="line">    &lt;source&gt;</span><br><span class="line">      type tail</span><br><span class="line">      format none</span><br><span class="line">      path /var/log/2.log</span><br><span class="line">      pos_file /var/log/2.log.pos</span><br><span class="line">      tag count.format2</span><br><span class="line">    &lt;/source&gt;</span><br><span class="line"></span><br><span class="line">    &lt;match **&gt;</span><br><span class="line">      type google_cloud</span><br><span class="line">    &lt;/match&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>pod<br>运行fluentd的<code>sidecat container</code>的pod。它挂载一个volume让fluentd获取配置数据。<br>下面需要用到<code>k8s.gcr.io/fluentd-gcp:1.30</code>镜像，请提前准备。要挂载目录，请创建。</li>
</ul>
<p><code>two-files-counter-pod-agent-sidecar.yaml</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: counter</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: count</span><br><span class="line">    image: busybox</span><br><span class="line">    args:</span><br><span class="line">    - /bin/sh</span><br><span class="line">    - -c</span><br><span class="line">    - &gt;</span><br><span class="line">      i=0;</span><br><span class="line">      while true;</span><br><span class="line">      do</span><br><span class="line">        echo &quot;$i: $(date)&quot; &gt;&gt; /var/log/1.log;</span><br><span class="line">        echo &quot;$(date) INFO $i&quot; &gt;&gt; /var/log/2.log;</span><br><span class="line">        i=$((i+1));</span><br><span class="line">        sleep 1;</span><br><span class="line">      done</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: varlog</span><br><span class="line">      mountPath: /var/log</span><br><span class="line">  - name: count-agent</span><br><span class="line">    image: k8s.gcr.io/fluentd-gcp:1.30</span><br><span class="line">    env:</span><br><span class="line">    - name: FLUENTD_ARGS</span><br><span class="line">      value: -c /etc/fluentd-config/fluentd.conf</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: varlog</span><br><span class="line">      mountPath: /var/log</span><br><span class="line">    - name: config-volume</span><br><span class="line">      mountPath: /etc/fluentd-config</span><br><span class="line">  volumes:</span><br><span class="line">  - name: varlog</span><br><span class="line">    emptyDir: &#123;&#125;</span><br><span class="line">  - name: config-volume</span><br><span class="line">    configMap:</span><br><span class="line">      name: fluentd-config</span><br></pre></td></tr></table></figure>
<p>这仅仅是一个栗子。你可以使用其它<code>logging agent</code>取代<code>fluentd</code>，如<code>filebeat</code>, <code>logstash</code>…</p>
<p><br></p>
<p><strong>Exposing logs directly from the application</strong></p>
<p><img src="/images/K8s/logging-from-application.png" alt=""></p>
<p><br></p>
<p>你可以通过直接公开每个应用程序的日志或push日志来实现集群级日志记录。就相当于在写得程序中加入日志收集和处理。<br>但是，这种日志记录机制超出了k8s的范围。</p>
<p><br><br><br></p>
<h3 id="kubelet垃圾回收"><a href="#kubelet垃圾回收" class="headerlink" title="kubelet垃圾回收"></a>kubelet垃圾回收</h3><p>Configuring kubelet Garbage Collection</p>
<p>垃圾回收是一个有用的kubelet功能，它将清理未使用的镜像和容器。每分钟对容器执行垃圾回收，每五分钟对镜像进行垃圾回收。<br>不推荐使用额外的垃圾回收工具，因为这可能会破坏<code>kubelet</code>的行为。</p>
<p><br></p>
<h4 id="镜像回收"><a href="#镜像回收" class="headerlink" title="镜像回收"></a>镜像回收</h4><p>Image Collection</p>
<p>k8s在<code>cadvisor</code>的配合下，通过<code>imageManager</code>管理所有镜像的生命周期。<br>镜像垃圾回收策略考虑了两个要素：</p>
<ul>
<li>HighThresholdPercent</li>
<li>LowThresholdPercent</li>
</ul>
<p>磁盘使用率高于高阈值将触发垃圾回收，垃圾回收将删除最近最少使用的镜像，直到满足低阈值。</p>
<p><br></p>
<p>镜像垃圾回收的kubelet flag:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#触发镜像垃圾回收的磁盘使用率百分比</span><br><span class="line">#默认值 90%</span><br><span class="line">image-gc-high-threshold</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#镜像垃圾回收尝试释放磁盘使用的百分比</span><br><span class="line">#默认值 80%</span><br><span class="line">image-gc-low-threshold</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="容器回收"><a href="#容器回收" class="headerlink" title="容器回收"></a>容器回收</h4><p>Container Collection</p>
<p>容器垃圾回收策略考虑了三个用户定义的变量：</p>
<ul>
<li>MinAge</li>
<li>MaxPerPodContainer</li>
<li>MaxContainers</li>
</ul>
<p><code>MinAge</code>是容器可以被垃圾回收的最小年龄。设置为0可禁用。<br><code>MaxPerPodContainer</code>是允许每个pod对允许拥有的最大死容器数。设置小于0可禁用。<br><code>MaxContainers</code>是总死亡容器的最大数量。设置小于0可禁用。</p>
<p>kubelet将对未识别、删除或标志设置的边界之外的容器起作用。通常首先移除最旧的容器。<br>不受kubelet管理的容器不受容器垃圾回收的限制。</p>
<p><br></p>
<p>容器垃圾回收的kubelet flag:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#完成的容器在垃圾回收之前的最低年龄</span><br><span class="line">#默认值 0min，意味着每个完成的容器都将被垃圾回收</span><br><span class="line">minimum-container-ttl-duration</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#每个容器要保留的最大旧实例数</span><br><span class="line">#默认值 1</span><br><span class="line">#强烈建议使用足够大的值，以允许每个预期容器保留至少1个死亡容器</span><br><span class="line">maximum-dead-containers-per-container</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#全局要保留的最大容器实例数</span><br><span class="line">#默认值 -1，意味着禁用</span><br><span class="line">#处于类似的原因，同样建议使用较大的值</span><br><span class="line">maximum-dead-containers</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="启用"><a href="#启用" class="headerlink" title="启用"></a>启用</h4><p>一些kubelet垃圾回收标志未来将被启用或取代。</p>
<table>
<thead>
<tr>
<th>Existing Flag</th>
<th>New Flag</th>
<th>Rationale</th>
</tr>
</thead>
<tbody>
<tr>
<td>–image-gc-high-threshold</td>
<td>–eviction-hard or –eviction-soft</td>
<td>existing eviction signals can trigger image garbage collection</td>
</tr>
<tr>
<td>–image-gc-low-threshold</td>
<td>–eviction-minimum-reclaim</td>
<td>eviction reclaims achieve the same behavior</td>
</tr>
<tr>
<td>–maximum-dead-containers</td>
<td>xxx</td>
<td>deprecated once old logs are stored outside of container’s context</td>
</tr>
<tr>
<td>–maximum-dead-containers-per-container</td>
<td>xxx</td>
<td>deprecated once old logs are stored outside of container’s context</td>
</tr>
<tr>
<td>–minimum-container-ttl-duration</td>
<td>xxx</td>
<td>deprecated once old logs are stored outside of container’s context</td>
</tr>
<tr>
<td>–low-diskspace-threshold-mb</td>
<td>–eviction-hard or eviction-soft</td>
<td>eviction generalizes disk thresholds to other resources</td>
</tr>
<tr>
<td>–outofdisk-transition-frequency</td>
<td>–eviction-pressure-transition-period</td>
<td>eviction generalizes disk pressure transition to other resources</td>
</tr>
</tbody>
</table>
<p><br><br><br></p>
<h3 id="Federation"><a href="#Federation" class="headerlink" title="Federation"></a>Federation</h3><p>先跳过，后面来学习。</p>
<p><br><br><br></p>
<h3 id="Proxy"><a href="#Proxy" class="headerlink" title="Proxy"></a>Proxy</h3><p>Proxies in Kubernetes</p>
<p>使用Kubernetes时可能会遇到几种不同的代理。<br>代理已经取代了重定向功能，重定向已被弃用。</p>
<p><br></p>
<h4 id="kubectl-proxy"><a href="#kubectl-proxy" class="headerlink" title="kubectl proxy"></a>kubectl proxy</h4><ol>
<li>runs on a user’s desktop or in a pod</li>
<li>proxies from a localhost address to the Kubernetes apiserver</li>
<li>client to proxy uses HTTP</li>
<li>proxy to apiserver uses HTTPS</li>
<li>locates apiserver</li>
<li>adds authentication headers</li>
</ol>
<p><br><br><br></p>
<h4 id="apiserver-proxy"><a href="#apiserver-proxy" class="headerlink" title="apiserver proxy"></a>apiserver proxy</h4><ol>
<li>is a bastion built into the apiserver</li>
<li>connects a user outside of the cluster to cluster IPs which otherwise might not be reachable</li>
<li>runs in the apiserver processes</li>
<li>client to proxy uses HTTPS (or http if apiserver so configured)</li>
<li>proxy to target may use HTTP or HTTPS as chosen by proxy using available information</li>
<li>can be used to reach a Node, Pod, or Service</li>
<li>does load balancing when used to reach a Service</li>
</ol>
<p><br><br><br></p>
<h4 id="kube-proxy"><a href="#kube-proxy" class="headerlink" title="kube proxy"></a>kube proxy</h4><ol>
<li>runs on each node</li>
<li>proxies UDP and TCP</li>
<li>does not understand HTTP</li>
<li>provides load balancing</li>
<li>is just used to reach services</li>
</ol>
<p><br><br><br></p>
<h4 id="A-Proxy-Load-balancer-in-front-of-apiserver"><a href="#A-Proxy-Load-balancer-in-front-of-apiserver" class="headerlink" title="A Proxy/Load-balancer in front of apiserver"></a>A Proxy/Load-balancer in front of apiserver</h4><ol>
<li>existence and implementation varies from cluster to cluster(e.g. nginx)</li>
<li>sits between all clients and one or more apiservers</li>
<li>acts as load balancer if there are several apiservers</li>
</ol>
<p><br><br><br></p>
<h4 id="云负载均衡器"><a href="#云负载均衡器" class="headerlink" title="云负载均衡器"></a>云负载均衡器</h4><ol>
<li>由云服务商提供</li>
<li>当k8s服务有LoadBalancer类型时自动创建</li>
<li>仅使用udp/tcp</li>
<li>具体详情因云服务商而异</li>
</ol>
<p><br><br><br></p>
<h3 id="控制器管理器指标"><a href="#控制器管理器指标" class="headerlink" title="控制器管理器指标"></a>控制器管理器指标</h3><p>Controller manager metrics</p>
<p>控制器管理器指标，提供有关控制器管理器性能和运行状况的重要信息。</p>
<p>这些指标包括常见的Go语言运行时指标、控制器特定指标。可用于衡量集群的运行状况。</p>
<p>在集群中，当控制器管理器运行时，可从<code>http://localhost:10252/metrics</code>获取控制器管理器指标。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">netstat -nltup | grep 10252</span><br><span class="line">tcp        0      0 127.0.0.1:10252         0.0.0.0:*               LISTEN      11088/kube-controll </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">curl http://localhost:10252/metrics</span><br></pre></td></tr></table></figure>
<p>这些指标以<code>prometheus format</code>格式发出，并且是人类可读的。</p>
<p><br><br><br></p>
<h3 id="附加组件"><a href="#附加组件" class="headerlink" title="附加组件"></a>附加组件</h3><p>Installing Addons</p>
<p>附加组件扩展了k8s的功能。</p>
<p><br></p>
<h4 id="网络和网络策略"><a href="#网络和网络策略" class="headerlink" title="网络和网络策略"></a>网络和网络策略</h4><p>Networking and Network Policy</p>
<ul>
<li>ACI： 通过 Cisco ACI提供集成的容器网络和网络完全</li>
<li>Calico： 是一个安全的L3网络和网络策略提供商</li>
<li>Canal: 将Flannel和Calico联合起来，提供网络和网络策略</li>
<li>Cilium： 是一个L3网络和网络策略插件</li>
<li>CNI-Genie： 使k8s能够无缝连接到各种CNI插件</li>
<li>Contiv： 提供可配置的网络，用于各种用例和丰富的策略框架</li>
<li>Flannel： 是一个可以与k8s一起使用的overlay网络提供商</li>
<li>Knitter： 是一个支持k8s多个网络的网络解决方案</li>
<li>Multus： 是一个用于k8s中多个网络支持，以支持所有CNI插件的多插件</li>
<li>NSX-T： 提供VMware NSX-T与容器协调器之间的集成</li>
<li>Nuage： 是一个SDN平台，可在k8s Pod和non-k8s环境之间提供基于策略的网络，并提供可见性和安全性监控</li>
<li>Romana： 用于Pod网络的L3网络解决方案</li>
<li>Weave Net： 提供网络和网络策略，将在网络分区的两侧进行工作，而不需要外部数据库</li>
</ul>
<p><br><br><br></p>
<h4 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h4><p>Service Discovery</p>
<ul>
<li><a href="https://coredns.io/" target="_blank" rel="noopener">CoreDNS</a>： 是一个灵活，可扩展的DNS服务器，可作为用于pod的集群DNS。</li>
</ul>
<p><br><br><br></p>
<h4 id="可视化，控制"><a href="#可视化，控制" class="headerlink" title="可视化，控制"></a>可视化，控制</h4><p>Visualization, Control</p>
<ul>
<li><a href="https://github.com/kubernetes/dashboard#kubernetes-dashboard" target="_blank" rel="noopener">Dashboard</a>： k8s的Dashboard Web Interface</li>
<li><a href="https://www.weave.works/docs/scope/latest/installing/#k8s" target="_blank" rel="noopener">Weave Scope</a>： 是一个用于以图形可视化显示container, pod, service…</li>
</ul>
<p><br><br><br><br><br></p>
<h2 id="k8s架构"><a href="#k8s架构" class="headerlink" title="k8s架构"></a>k8s架构</h2><p>Kubernetes Architecture</p>
<p><br></p>
<h3 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h3><p>node是k8s中的工作机器，以前称为minion。也就是集群中的一台主机。节点可以是VM或物理机。每个节点都具有用于运行pod所需的服务，并由master组件管理。节点上的服务包括<code>docker</code>, <code>kubelet</code>, <code>kube-proxy</code>。</p>
<p><br></p>
<h4 id="节点状态"><a href="#节点状态" class="headerlink" title="节点状态"></a>节点状态</h4><p>Node Status</p>
<p>节点的状态包含以下信息：</p>
<ul>
<li>地址(Address)</li>
<li>条件(Condition)</li>
<li>容量(Capacity)</li>
<li>信息(Info)</li>
</ul>
<p><br></p>
<p><strong>地址</strong><br>这些字段的使用取决于机器配置。</p>
<ul>
<li>HostName： 节点内核报告的主机名</li>
<li>ExternalIP： 通常是可从外部路由的节点IP地址</li>
<li>InternalIP： 通常是仅在集群内可路由的节点IP地址</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">kubectl get node -o wide</span><br><span class="line">NAME      STATUS    ROLES     AGE       VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION              CONTAINER-RUNTIME</span><br><span class="line">master    Ready     master    7d        v1.11.1   192.168.31.49    &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-862.9.1.el7.x86_64   docker://1.13.1</span><br><span class="line">node      Ready     &lt;none&gt;    7d        v1.11.1   192.168.31.174   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-862.9.1.el7.x86_64   docker://1.13.1</span><br><span class="line">salt01    Ready     &lt;none&gt;    1d        v1.11.1   192.168.31.159   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-862.9.1.el7.x86_64   docker://1.13.1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl describe node/salt01</span><br><span class="line">Addresses:</span><br><span class="line">  InternalIP:  192.168.31.159</span><br><span class="line">  Hostname:    salt01</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>条件</strong><br>该字段描述了所有运行中节点的状态。节点条件使用JSON对象表示。</p>
<table>
<thead>
<tr>
<th>条件</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>OutOfDisk</td>
<td>True(节点上的可用空间不足以添加新pod), 否则为False</td>
</tr>
<tr>
<td>Ready</td>
<td>True(节点健康并准备好接受pod) <br> False(节点不健康且不接受pod) <br> Unknown(节点控制器在最后一个<code>node-monitor-grace-period</code>期限内没有从节点收到消息。默认40s)</td>
</tr>
<tr>
<td>MemoryPressure</td>
<td>True(节点内存有压力，即内存不足)，否则为False</td>
</tr>
<tr>
<td>PIDPressure</td>
<td>True(进程存在压力，即节点上有太多进程)，否则为False</td>
</tr>
<tr>
<td>DiskPressure</td>
<td>True(磁盘大小存在压力，即磁盘容量较低), 否则为False</td>
</tr>
<tr>
<td>NetworkUnavailable</td>
<td>True(节点网络配置错误)，否则为False</td>
</tr>
<tr>
<td>ConfigOK</td>
<td>True(kubelet配置正确)，否则为False</td>
</tr>
</tbody>
</table>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe node/salt01</span><br><span class="line">Conditions:</span><br><span class="line">  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message</span><br><span class="line">  ----             ------  -----------------                 ------------------                ------                       -------</span><br><span class="line">  OutOfDisk        False   Wed, 15 Aug 2018 11:10:49 +0800   Mon, 13 Aug 2018 15:51:40 +0800   KubeletHasSufficientDisk     kubelet has sufficient disk space available</span><br><span class="line">  MemoryPressure   False   Wed, 15 Aug 2018 11:10:49 +0800   Mon, 13 Aug 2018 15:51:40 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available</span><br><span class="line">  DiskPressure     False   Wed, 15 Aug 2018 11:10:49 +0800   Mon, 13 Aug 2018 15:51:40 +0800   KubeletHasNoDiskPressure     kubelet has no disk pressure</span><br><span class="line">  PIDPressure      False   Wed, 15 Aug 2018 11:10:49 +0800   Mon, 13 Aug 2018 15:51:40 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available</span><br><span class="line">  Ready            True    Wed, 15 Aug 2018 11:10:49 +0800   Mon, 13 Aug 2018 15:53:00 +0800   KubeletReady                 kubelet is posting ready status</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>容量</strong><br>描述节点上的可用资源：CPU，内存，可调度到节点上的最大pods数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe node/salt01</span><br><span class="line">Capacity:</span><br><span class="line"> cpu:                2</span><br><span class="line"> ephemeral-storage:  49250820Ki</span><br><span class="line"> hugepages-2Mi:      0</span><br><span class="line"> memory:             3881332Ki</span><br><span class="line"> pods:               110</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>信息</strong><br>关于节点的一般信息，如Kernel版本，Kubernetes版本，Docker版本，OS…</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe node/salt01</span><br><span class="line">System Info:</span><br><span class="line"> Machine ID:                 e48d6bf22f9b4c8da5cb1a07b2fec730</span><br><span class="line"> System UUID:                564D1413-905B-64D6-E9A2-92E37F9B5BDA</span><br><span class="line"> Boot ID:                    1df89a81-77a4-44a0-9241-e6d766795e32</span><br><span class="line"> Kernel Version:             3.10.0-862.9.1.el7.x86_64</span><br><span class="line"> OS Image:                   CentOS Linux 7 (Core)</span><br><span class="line"> Operating System:           linux</span><br><span class="line"> Architecture:               amd64</span><br><span class="line"> Container Runtime Version:  docker://1.13.1</span><br><span class="line"> Kubelet Version:            v1.11.1</span><br><span class="line"> Kube-Proxy Version:         v1.11.1</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="管理"><a href="#管理" class="headerlink" title="管理"></a>管理</h4><p>Management</p>
<p>与Pod与Service不同，k8s本身并不创建节点： 它由云服务商创建，或存在于物理机/虚拟机的pool中。<br>当k8s创建节点时，它实际上只是创建了一个表示节点的对象。创建之后，k8s将检查节点是否有效。</p>
<p>栗子：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"kind"</span>: <span class="string">"Node"</span>,</span><br><span class="line">  <span class="attr">"apiVersion"</span>: <span class="string">"v1"</span>,</span><br><span class="line">  <span class="attr">"metadata"</span>: &#123;</span><br><span class="line">    <span class="attr">"name"</span>: <span class="string">"10.240.79.157"</span>,</span><br><span class="line">    <span class="attr">"labels"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"my-first-k8s-node"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>k8s将在内部创建节点对象，并通过基于<code>metadata.name</code>字段的运行状况检查来验证节点。<br>如果节点有效(valid)，即所有必要的服务都已运行，它就符合了运行pod的条件。否则它将被所有的集群动作忽略，直到它变为有效。请注意，Kubernetes将保持无效(invalide)节点的对象，除非它被手动删除。Kubernetes将持续检查节点是否变得可用。</p>
<p>目前，有3个组件与k8s节点接口交互：</p>
<ul>
<li>Node Controller</li>
<li>kubelet</li>
<li>kubectl</li>
</ul>
<p><br></p>
<p><strong>节点控制器</strong><br>节点控制器是一个k8s Master组件，用于管理节点的各个方面。</p>
<p>节点控制器在节点的生命周期中具有多个角色(role)。第一个便是在节点注册时为其分配CIDR地址块。<br>第二个是使节点控制器的内部节点列表与可用机器保持一致。只要节点不健康，节点控制器就会询问该节点是否仍然可用。如果不是，则节点控制器从其节点列表中删除该节点。<br>第三个是监控节点的健康状况。当节点不可达时，节点控制器负责更新节点的条件(condition)状态，从<code>Ready</code>变为<code>Unknown</code>。如果节点继续无法访问，则稍后从节点中驱逐(evict)所有pod(graceful termination)。默认超时时间为40s开始上报<code>Unknown</code>，然后5min之后开始驱逐pods。节点控制器通过<code>--node-nonitor-period</code>秒检查每个节点的状态。</p>
<p>在大多数情况下，节点控制器将驱逐率(evication rate)限制为<code>--node-eviction-rate</code>(默认值 0.1)每秒。这意味着它将不会每10s从超过1个节点驱逐pod。</p>
<p>当给定可用区域中的节点变得不健康时，节点驱逐行为会发生变化。同时，节点控制器检查此区域中不健康节点的百分比。<br>如果节点不健康比例至少为<code>--unhealthy-zone-threshold</code>(默认值 0.55)，那么驱逐率会降低；<br>如果集群很小，小于或等于<code>--large-cluster-size-threshold</code>(默认值 50)，则停止驱逐；<br>否则，驱逐率减小到每秒<code>--secondary-node-eviction-rate</code>(默认值 0.01)。<br>每个可用区域实施这些策略的原因是，一个可用区域可能与其它可用区域保持连接。</p>
<p>在可用区域之间传播节点的一个关键原因是，当整个区域出现故障时，工作负载可以转移到健康区域。因此，如果区域中的全部节点都不健康，则节点控制器以正常速率<code>--node-eviction-rate</code>驱逐。<br>The corner case是当所有区域都不健康时。在这种情况下，节点控制器假定Master连接存在一些问题，并在某些连接恢复之前停止所有驱逐。</p>
<p><br></p>
<p><strong>节点自注册</strong><br>Self-Registration of Nodes</p>
<p>当<code>kubelet</code>标志<code>--register-node</code>为true(默认)时，它会尝试向API server注册自己。这是大多数发行版使用的首选模式。</p>
<p>对于自注册，kubelet使用如下选项：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#向API server验证自身的凭据路径</span><br><span class="line">--kubeconfig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#r如何与云服务商交流</span><br><span class="line">--cloud-provider</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#向API server自动注册</span><br><span class="line">--register-node</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#节点IP地址</span><br><span class="line">--node-ip</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#集群中注册节点时要添加的标签</span><br><span class="line">--node-labels</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#指定kubelet将节点状态发送到master的频率</span><br><span class="line">--node-status-update-frequency</span><br></pre></td></tr></table></figure>
<p>目前，任何kubelet都有权 create/modify 任何节点资源，但实际上它只 创建/修改 自己的节点资源。(将来，k8s打算只允许kubelet修改自己的节点资源)</p>
<p><strong>手动管理节点</strong></p>
<p>如果希望手动创建节点对象，请设置<code>kubelet</code>标志<code>--register-node=false</code>。<br>修改包括在节点上设置标签(label)并将其标记为不可调度(unschedulable)。</p>
<p><br></p>
<p><strong>节点容量</strong><br>Node Capacity</p>
<p>节点容量(cpu, memory)是节点对象的一部分。通常，当创建节点对象时，节点注册自己并上报其容量。如果是手动管理节点，则需要你在添加节点时设置节点容量。<br>k8s调度器确保节点上的所有pod都有足够的资源。它检查节点上容器请求的总和不大于节点容量。它包括由kubelet启动的所有容器，但不包括由容器运行时直接启动的容器，也不包括容器外部的任何进程。所以，尽量不要在k8s集群节点上运行额外进程。</p>
<p>如果要为<code>non-pod</code>进程保留资源，你可以创建保留(placeholder)pod。将内存和CPU的值设置为要保留的资源量。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">resource-reserver</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">sleep-forever</span></span><br><span class="line"><span class="attr">  - image:</span> <span class="string">k8s.gcr.io/pause:0.8.0</span></span><br><span class="line"><span class="attr">  - resources:</span></span><br><span class="line"><span class="attr">      requests:</span></span><br><span class="line">	    <span class="attr">cpu:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line">		<span class="attr">memory:</span> <span class="number">100</span><span class="string">Mi</span></span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="API对象"><a href="#API对象" class="headerlink" title="API对象"></a>API对象</h4><p>Node is a top-level resource in the Kubernetes REST API.</p>
<p><br><br><br></p>
<h3 id="节点通信"><a href="#节点通信" class="headerlink" title="节点通信"></a>节点通信</h3><p>Master-Node communication</p>
<p>Master(APIserver)与k8s cluster之间的通信。<br>目的是允许用户自定义其安装以强化网络配置，以便集群可在不受信任的网络上运行。</p>
<p><br></p>
<h4 id="Cluster-gt-Master"><a href="#Cluster-gt-Master" class="headerlink" title="Cluster-&gt;Master"></a>Cluster-&gt;Master</h4><p>从Cluster到Master的所有通信路径都终止于API server。在典型部署中，API server配置为在安全的HTTPS(443)端口上监听远程连接，并启用一种或多种形式的Client认证。<br>应该为节点配置集群的公共根证书，以便他们可以使用有效证书安全地连接到API server。<br>希望连接到API server的Pod可以利用Service Account安全地执行此操作，这样k8s在实例化时自动将公共根证书和有效bearer token注入到Pod中。<code>the kubernetes service</code>配置了一个虚拟IP地址，该地址被重定向到API server的HTTPS endpoint。<br>Master组件还通过安全端口与Cluster API server通信。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get service</span><br><span class="line">NAME         TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)                         AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1     &lt;none&gt;        443/TCP                         8d</span><br></pre></td></tr></table></figure>
<p>因此，默认情况下，从Cluster到Master的连接的默认操作模式是安全的，可在不受信任网络/公共网络上运行。</p>
<p><br><br><br></p>
<h4 id="Master-gt-Cluster"><a href="#Master-gt-Cluster" class="headerlink" title="Master-&gt;Cluster"></a>Master-&gt;Cluster</h4><p>从Master(API server)到Cluster有两条主要通信路径：</p>
<ul>
<li>API server <code>-&gt;</code> kubelet</li>
<li>API server <code>-&gt;</code> node, pod, service</li>
</ul>
<p><br></p>
<p><strong>API server -&gt; kubelet</strong><br>从API server到kubelet(它运行在集群中的每个节点上)。</p>
<p>从API server到kubelet的连接用于：</p>
<ul>
<li>获取Pod的日志</li>
<li>附加到运行的Pod</li>
<li>提供kubelet的端口转发功能</li>
</ul>
<p>这些连接终止于kubelet的HTTPS endpoint。默认情况下，API server不会验证kubelet的证书，这会使连接可能受到中间人工具，并且不安全地运行在不受信任/公共的网络上。<br>要验证此连接，使用<code>--kubelet-certificate-authority</code>标志位API server提供根证书，用于验证kubelet的证书。</p>
<p>如果无法做到，请在API server和kubelet之间使用SSH隧道保障连接安全。</p>
<p><br></p>
<p><strong>API server -&gt; node, pod, service</strong><br>从API server到node, pod, service的连接默认为纯HTTP，因此既不需要认证也未加密。他们可以通过在API URI的前缀使用<a href="https://" target="_blank" rel="noopener">https://</a>来运行安全的HTTPS，但他们不会验证HTTPS endpoint提供的证书，也不会提供客户端凭据。因此连接将被加密，它不会提供任何完整性保证。</p>
<p><br><br><br></p>
<h3 id="云控制器管理器"><a href="#云控制器管理器" class="headerlink" title="云控制器管理器"></a>云控制器管理器</h3><p>Cloud Controller Manager</p>
<p>暂时跳过！</p>
<p><br><br><br><br><br></p>
<h2 id="扩展k8s"><a href="#扩展k8s" class="headerlink" title="扩展k8s"></a>扩展k8s</h2><p><br></p>
<h3 id="扩展k8s集群"><a href="#扩展k8s集群" class="headerlink" title="扩展k8s集群"></a>扩展k8s集群</h3><p>Extending your Kubernetes Cluster</p>
<p>k8s具有高度可配置化和可扩展化。</p>
<p>定制方法可大致分为配置，只涉及更改标志，本地配置文件或API资源；扩展，设计运行其它程序或服务。</p>
<p><br></p>
<h4 id="扩展模式"><a href="#扩展模式" class="headerlink" title="扩展模式"></a>扩展模式</h4><p>Extensions Patterns</p>
<p>k8s旨在通过编写客户端程序实现自动化。任意 read/write k8s API的程序都可以提供有用的自动化。自动化可在集群上启用或关闭。自动化通常适用于k8s集群，包括托管集群和管理安装。</p>
<p>有一种编写与k8s一起使用的称为控制器模式(Controller Pattern)客户端程序的特定模式。控制器通常读取对象的<code>.spec</code>，可能做些事情，然后更新对象的<code>.status</code>。<br>控制器(Controller)是一个k8s client。当k8s为client并调用远程服务时，它被称为<code>Webhook</code>。远程服务被称为<code>Webhook Backend</code>。与控制器一样，<code>Webhook</code>确实增加了一个失败点。</p>
<p>在webhook模式中，k8s 向远程服务发出网络请求。在二进制插件模型中，k8s执行二进制程序。二进制插件由kubelet和kubectl使用。</p>
<p><img src="/images/K8s/k8s_extensions.png" alt="k8s扩展"></p>
<p><br></p>
<h4 id="扩展点"><a href="#扩展点" class="headerlink" title="扩展点"></a>扩展点</h4><p>Extension Points</p>
<p>k8s 系统的扩展点:</p>
<p><img src="/images/K8s/k8s_extension_points.png" alt="k8s 扩展点"></p>
<p><br></p>
<ol>
<li>用户使用<code>kubectl</code>与k8s API进行交互</li>
<li>API server处理所有请求</li>
<li>API server提供各种资源</li>
<li>k8s调度器决定将pod放在哪个节点上</li>
<li>k8s大部分行为都是由控制器实现的</li>
<li>kubelet帮助pod在集群网络上显示为具有自己IP的虚拟服务</li>
<li>kubelet还可挂载和解挂容器的卷</li>
</ol>
<p><br></p>
<p>如果你不确定如何开始，查看如下流程图：</p>
<p><img src="/images/K8s/k8s_extensions_start.png" alt=""></p>
<p><br></p>
<h4 id="API扩展"><a href="#API扩展" class="headerlink" title="API扩展"></a>API扩展</h4><p>API Extensions</p>
<p><br></p>
<p><strong>User-Defined Types</strong><br>如果想要定义新的控制器、应用程序配置对象、声明性API并管理他们，请考虑向k8s添加自定义资源。<br>不要讲自定义资源用作应用程序、用户、监控数据的数据存储。</p>
<p><br></p>
<p><strong>Combining New APIs with Automation</strong><br>通常，当添加新API时，还会添加一个 read/write 新API的控制循环。当自定义API和控制循环的组合用于管理特定的，通常是有状态的应用程序时，这被称为操作者模式(Operator Pattern)。</p>
<p><br></p>
<p><strong>Changing Built-in Resources</strong><br>通过自定义资源添加扩展k8s API时，添加的资源始终属于新的API组。你无法替换或修改已经存在的API组。添加API不会直接影响现有API的行为，但API Access Extensions会影响现有API的行为。</p>
<p><br></p>
<p><strong>API Access Extensions</strong><br>当请求到达k8s API server时，它首先进行身份验证，然后授权，然后进行各种准入控制。每个步骤都提供了扩展点。</p>
<p><br></p>
<p><strong>Authentication</strong><br>身份验证将所有请求中的Header或证书映射到发出请求的客户端的用户名中。</p>
<p><br></p>
<p><strong>Authorization</strong><br>授权确定特定用户是否可以对API资源进行读写和其它操作。它只是在整个资源的层面上工作，不基于任意对象字段进行区分。</p>
<p><br></p>
<p><strong>Dynamic Admission Control</strong><br>当请求授权之后，如果它是一个写操作，它还需要通过<code>Admission Control</code>步骤。除了内建步骤之外，还有其它扩展：</p>
<ul>
<li><code>Image Policy webhook</code>限制可在容器中运行的镜像</li>
<li>为了做出任意的<code>admission control</code>决策，可使用普通<code>admission webhook</code></li>
<li>初始化程序可在创建对象之前修改对象的控制器</li>
</ul>
<p><br></p>
<h4 id="基础设施扩展"><a href="#基础设施扩展" class="headerlink" title="基础设施扩展"></a>基础设施扩展</h4><p>Infrastructure Extensions</p>
<p><br></p>
<p><strong>Storage Plugins</strong><br><code>Flex Volumes</code>允许用户通过<code>kubelet</code>调用二进制插件来安装卷，来安装没有内置支持的卷类型</p>
<p><br></p>
<p><strong>Device Plugins</strong><br>设备插件允许节点通过设备发现插件发现新的节点资源</p>
<p><br></p>
<p><strong>Network Plugins</strong><br>支持不同的网络结构</p>
<p><br></p>
<p><strong>Scheduler Extensions</strong><br>调度器是一种特殊类型的控制器，用于监视Pod，并将Pod分配给节点。</p>
<p><br><br><br></p>
<h3 id="扩展k8s-API"><a href="#扩展k8s-API" class="headerlink" title="扩展k8s API"></a>扩展k8s API</h3><p>Extending the Kubernetes API</p>
<p><br></p>
<h4 id="在聚合层扩展k8s-API"><a href="#在聚合层扩展k8s-API" class="headerlink" title="在聚合层扩展k8s API"></a>在聚合层扩展k8s API</h4><p>Extending the Kubernetes API with the aggregation layer</p>
<p>聚合层允许在集群中安装其它k8s-style的API。</p>
<p><br></p>
<h4 id="自定义资源"><a href="#自定义资源" class="headerlink" title="自定义资源"></a>自定义资源</h4><p>Custom Resources</p>
<p>自定义资源是k8s API的扩展，包括何时向k8s集群添加自定义资源以及何时使用独立服务。</p>
<p>资源是k8s API中的端点(endpoint)，用于存储某种API对象的集合。如，内建的pods资源包含了Pod对象的集合。<br>自定义资源是k8s API的扩展，不一定在每个k8s集群上都可用。换句话说，它代表了特定k8s的定制安装。<br>自定义资源可通过动态注册在正在运行的集群中出现和消失，集群管理员可独立于集群本身更新自定义资源。安装自定义资源后，用户可使用<code>kubectl</code>创建和访问其对象。</p>
<p><br></p>
<p>Custom controllers</p>
<p>自定义字段本身可让你存储和检索结构化数据。只有与控制器结合使用才能成为真正的声明性API。declare API允许你声明或指定资源的所需状态，并尝试将实际状态与此期望状态相匹配。这里，控制器将结构化的数据解释为用户期望状态的记录，并且不断采取行动以实现和维护该状态。<br>自定义控制器是一种用户可在正在运行的集群上进行部署和更新，而与集群自身的生命周期无关的控制器。自定义控制器可使用任何类型的资源，但与自定义资源结合使用时，它们更有效。</p>
<p><br></p>
<p>Should I add a custom resource to my Kubernetes Cluster?</p>
<p>当创建新的API时，考虑是使用k8s cluster API还是让API独立运行。</p>
<table>
<thead>
<tr>
<th>Consider API aggregation if:</th>
<th>Prefer a stand-alone API if:</th>
</tr>
</thead>
<tbody>
<tr>
<td>Your API is Declarative.</td>
<td>Your API does not fit the Declarative model.</td>
</tr>
<tr>
<td>You want your new types to be readable and writable using kubectl.</td>
<td>kubectl support is not required</td>
</tr>
<tr>
<td>You want to view your new types in a Kubernetes UI, such as dashboard, alongside built-in types.</td>
<td>Kubernetes UI support is not required.</td>
</tr>
<tr>
<td>You are developing a new API.</td>
<td>You already have a program that serves your API and works well.</td>
</tr>
<tr>
<td>You are willing to accept the format restriction that Kubernetes puts on REST resource paths, such as API Groups and Namespaces. (See the API Overview.)</td>
<td>You need to have specific REST paths to be compatible with an already defined REST API.</td>
</tr>
<tr>
<td>Your resources are naturally scoped to a cluster or to namespaces of a cluster.</td>
<td>Cluster or namespace scoped resources are a poor fit; you need control over the specifics of resource paths.</td>
</tr>
<tr>
<td>You want to reuse Kubernetes API support features.</td>
<td>You don’t need those features</td>
</tr>
</tbody>
</table>
<p><br></p>
<p><strong>声明性API</strong><br>Declarative APIs</p>
<p>在一个声明性API中，通常：</p>
<ul>
<li>你的API由相对较少的相对较小的对象组成</li>
<li>应用程序或基础结构的对象定义配置</li>
<li>对象很少更新</li>
<li>人们通常需要读写对象</li>
<li>对象的主要操作时CRUD</li>
<li>跨对象的事务不是必需的：API表示期望状态，而不是精确的状态</li>
</ul>
<p>imperative API不是声明性的，你的API可能不是声明性的标志包括：</p>
<ul>
<li>客户端说执行此操作，完成后获得同步响应</li>
<li>客户端说执行此操作，然后获取操作ID，并且必须检查单独的Operation对象以确定请求的完成</li>
<li>谈论Remote Procedure Calls(RPCs)</li>
<li>直接存储大量数据</li>
<li>需要高带宽访问</li>
<li>存储最终用户数据，或应用程序处理的其它大规模数据</li>
<li>对象非CRUD的自然操作</li>
<li>API不容易建模为对象</li>
<li>使用操作ID或操作对象表示挂起的操作</li>
</ul>
<p><br></p>
<p>Should I use a configMap or a custom resource?</p>
<p>如果符合以下任意条件，请使用ConfigMap:</p>
<ul>
<li>存在现有的，记录完备的配置文件格式</li>
<li>你希望将整个配置文件放入ConfigMap的一个key中</li>
<li>配置文件的主要用途是在集群上的Pod中运行的程序使用该文件来配置自身</li>
<li>文件的消费者更喜欢使用Pod中的文件或环境变量，而不是k8s API</li>
<li>你希望在文件更新时通过部署执行滚动升级</li>
</ul>
<p>如果符合以下大部分情况，请使用自定义资源：</p>
<ul>
<li>你希望使用k8s client library和CLI来创建和更新新资源</li>
<li>你希望来自<code>kubectl</code>的顶级支持</li>
<li>你希望构建新的自动化，监视新对象的更新，然后CRUD其它对象</li>
<li>你希望编写处理对象更新的自动化</li>
<li>你希望使用k8s API约定，如<code>.spec, .status, .metadata</code></li>
<li>你希望对象是受控资源集合的抽象，或其它资源的汇总</li>
</ul>
<p><br></p>
<p><strong>添加自定义资源</strong><br>k8s提供了两种方式来向你的集群中添加自定义资源：</p>
<ul>
<li>CRD很简单，无需任何编程即可创建</li>
<li>API聚合需要编程，但允许更多控制API行为，如数据的存储方式和API版本间的转换</li>
</ul>
<p>聚合API是位于主API server后面的从属API server，它充当代理。这种安排称为API聚合(AA, API Aggregation)。<br>CRD允许用户添加新类型的资源，而无需添加其它API server，你无需了解API聚合即可使用CRD。<br>无论如何安装，新资源都成为自定义资源，以区别于内置的k8s 资源。</p>
<p><br></p>
<p><strong>自定义资源定义</strong><br>自定义资源定义 API资源允许你去定义自定义资源。定义CRD对象会创建一个新的自定义资源，其中包含指定的名称和架构。k8s API提供并处理自定义资源的存储。<br>这使你无需编写自己的API server来处理自定义资源，但实现的一般特性意味着你的灵活性低于API server聚合。</p>
<p><br></p>
<p><strong>API server aggregation</strong><br>通常，k8s API中的每个资源都需要处理REST 请求的代码并管理对象的持久化存储。k8s API server处理pod等内建资源，还可通过CRD处理自定义资源。<br>聚合层允许你通过编写和部署自己的独立API server为自定义资源提供专门的实现。API server将请求委托给你处理的自定义资源，使其对所有客户端可用。</p>
<p>为添加自定义资源选择一个方法<br>通常情况下，CRD很适合，如果：</p>
<ul>
<li>你有少数几个领域</li>
<li>你正在使用公司内的资源，或作为小型开源项目的一部分</li>
</ul>
<p><br></p>
<p>易用性比较：</p>
<table>
<thead>
<tr>
<th>CRDs</th>
<th>Aggregated API</th>
</tr>
</thead>
<tbody>
<tr>
<td>Do not require programming. Users can choose any language for a CRD controller.</td>
<td>Requires programming in Go and building binary and image. Users can choose any language for a CRD controller.</td>
</tr>
<tr>
<td>No additional service to run; CRs are handled by API Server.</td>
<td>An additional service to create and that could fail.</td>
</tr>
<tr>
<td>No ongoing support once the CRD is created. Any bug fixes are picked up as part of normal Kubernetes Master upgrades.</td>
<td>May need to periodically pickup bug fixes from upstream and rebuild and update the Aggregated APIserver.</td>
</tr>
<tr>
<td>No need to handle multiple versions of your API. For example: when you control the client for this resource, you can upgrade it in sync with the API.</td>
<td>You need to handle multiple versions of your API, for example: when developing an extension to share with the world.</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>高级功能和灵活性：</p>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Description</th>
<th>CRDs</th>
<th>Aggregated API</th>
</tr>
</thead>
<tbody>
<tr>
<td>Validation</td>
<td>Help users prevent errors and allow you to evolve your API independently of your clients. These features are most useful when there are many clients who can’t all update at the same time.</td>
<td>Yes. Most validation can be specified in the CRD using OpenAPI v3.0 validation. Any other validations supported by addition of a Validating Webhook.</td>
<td>Yes, arbitrary validation checks</td>
</tr>
<tr>
<td>Defaulting</td>
<td>See above</td>
<td>Yes, via a Mutating Webhook; Planned, via CRD OpenAPI schema.</td>
<td>Yes</td>
</tr>
<tr>
<td>Multi-versioning</td>
<td>Allows serving the same object through two API versions. Can help ease API changes like renaming fields. Less important if you control your client versions.</td>
<td>No, but planned</td>
<td>Yes</td>
</tr>
<tr>
<td>Custom Storage</td>
<td>If you need storage with a different performance mode (for example, time-series database instead of key-value store) or isolation for security (for example, encryption secrets or different</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Custom Business Logic</td>
<td>Perform arbitrary checks or actions when creating, reading, updating or deleting an object</td>
<td>Yes, using Webhooks.</td>
<td>Yes</td>
</tr>
<tr>
<td>Scale Subresource</td>
<td>Allows systems like HorizontalPodAutoscaler and PodDisruptionBudget interact with your new resource</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Status Subresource</td>
<td></td>
</tr>
<tr>
<td>Finer-grained access control: user writes spec section, controller writes status section.</td>
</tr>
<tr>
<td>Allows incrementing object Generation on custom resource data mutation (requires separate spec and status sections in the resource)</td>
</tr>
<tr>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Other Subresources</td>
<td>Add operations other than CRUD, such as “logs” or “exec”.</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>strategic-merge-patch</td>
<td>The new endpoints support PATCH with Content-Type: application/strategic-merge-patch+json. Useful for updating objects that may be modified both locally, and by the server. For more information, see “Update API Objects in Place Using kubectl patch”</td>
<td>No, but similar functionality planned</td>
<td>Yes</td>
</tr>
<tr>
<td>Protocol Buffers</td>
<td>The new resource supports clients that want to use Protocol Buffers</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>OpenAPI Schema</td>
<td>Is there an OpenAPI (swagger) schema for the types that can be dynamically fetched from the server? Is the user protected from misspelling field names by ensuring only allowed fields are set? Are types enforced (in other words, don’t put an int in a string field?)</td>
<td>No, but planned</td>
<td>Yes</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>一般功能：</p>
<table>
<thead>
<tr>
<th>Feature</th>
<th>What it does</th>
</tr>
</thead>
<tbody>
<tr>
<td>CRUD</td>
<td>The new endpoints support CRUD basic operations via HTTP and kubectl</td>
</tr>
<tr>
<td>Watch</td>
<td>The new endpoints support Kubernetes Watch operations via HTTP</td>
</tr>
<tr>
<td>Discovery</td>
<td>Clients like kubectl and dashboard automatically offer list, display, and field edit operations on your resources</td>
</tr>
<tr>
<td>json-patch</td>
<td>The new endpoints support PATCH with Content-Type: application/json-patch+json</td>
</tr>
<tr>
<td>merge-patch</td>
<td>The new endpoints support PATCH with Content-Type: application/merge-patch+json</td>
</tr>
<tr>
<td>HTTPS</td>
<td>The new endpoints uses HTTPS</td>
</tr>
<tr>
<td>Built-in Authentication</td>
<td>Access to the extension uses the core apiserver (aggregation layer) for authentication</td>
</tr>
<tr>
<td>Built-in Authorization</td>
<td>Access to the extension can reuse the authorization used by the core apiserver (e.g. RBAC)</td>
</tr>
<tr>
<td>Finalizers</td>
<td>Block deletion of extension resources until external cleanup happens.</td>
</tr>
<tr>
<td>Admission Webhooks</td>
<td>Set default values and validate extension resources during any create/update/delete operation.</td>
</tr>
<tr>
<td>UI/CLI Display</td>
<td>Kubectl, dashboard can display extension resources.</td>
</tr>
<tr>
<td>Unset vs Empty</td>
<td>Clients can distinguish unset fields from zero-valued fields.</td>
</tr>
<tr>
<td>Client Libraries Generation</td>
<td>Kubernetes provides generic client libraries, as well as tools to generate type-specific client libraries.</td>
</tr>
<tr>
<td>Labels and annotations</td>
<td>Common metadata across objects that tools know how to edit for core and custom resources</td>
</tr>
</tbody>
</table>
<p><br></p>
<p><strong>安装自定义资源</strong><br>在向集群添加自定义资源之前，需要注意几点</p>
<ul>
<li>第三方代码和新的失败点</li>
<li>存储</li>
<li>认证，授权，审计</li>
</ul>
<p><br></p>
<p><strong>访问自定义资源</strong><br>k8s client library可用于访问自定义资源。并非所有client library都支持自定义资源，但go和python client library可以。</p>
<p>当你添加一个自定义资源时，你可以使用如下方式访问：</p>
<ul>
<li>kubectl</li>
<li>k8s dynamic client</li>
<li>REST client</li>
<li>由k8s client 生成工具生成的client</li>
</ul>
<p><br><br><br></p>
<h3 id="计算，存储和网络插件"><a href="#计算，存储和网络插件" class="headerlink" title="计算，存储和网络插件"></a>计算，存储和网络插件</h3><p>Compute, Storage, and Networking Extensions</p>
<p><br></p>
<h4 id="网络插件"><a href="#网络插件" class="headerlink" title="网络插件"></a>网络插件</h4><p>Network Plugins</p>
<blockquote>
<p>Notice:<br>FEATURE STATE: Kubernetes v1.11 alpha<br>Alpha features change rapidly</p>
</blockquote>
<p>k8s中的网络插件有几种风格：</p>
<ul>
<li>CNI plugins: 遵守appc/CNI规范，旨在实现互操作性</li>
<li>Kubenet plugin: 使用<code>bridge</code>和<code>host-local</code> CNI plugins实现基本的<code>cbr0</code></li>
</ul>
<p><br></p>
<p><strong>安装</strong><br>kubelet有一个默认的网络插件，以及整个集群的默认网络。它在启动时探测插件，记住它找到的内容，并在pod声明周期中的适当时间执行所选插件。<br>使用插件时，请记住两个<code>kubelet</code>命令行参数：</p>
<ul>
<li><code>cni-bin-dir</code>: kubelet在启动时检测此目录以获取插件</li>
<li><code>network-plugin</code>： 从<code>cni-bin-dir</code>使用的网络插件</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ps -ef | grep kubelet</span><br><span class="line"></span><br><span class="line">/usr/bin/kubelet xxx --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>网络插件需求</strong><br>除了提供网络插件接口来配置和清理pod网络外，该插件还可能需要对kube-proxy提供特定支持。iptables proxy依赖于iptables，插件可能需要确保容器流量可用于iptables。<br>默认情况下，如果未指定kubelet网络插件，则使用noop插件，它设置<code>net/bridge-nf-call-iptables=1</code>来确保简单配置与iptables proxy正常工作。</p>
<p><strong>CNI</strong><br>通过kubelet传递<code>--network-plugin=cni</code>选项来选择CNI插件。kubelet从<code>cni-conf-dir</code>(默认<code>/etc/cni/net.d</code>)中读取文件，并使用该文件中的CNI配置来设置每个pod的网络。引用的插件必须存在于<code>--cni-bin-dir</code>(默认<code>/opt/cni/bin</code>)中。<br>如果目录中有多个CNI配置文件，则使用文件名的词典顺序的第一个。<br>除了配置文件指定的CNI插件外，k8s还需要标准的CNI lo插件(loopback)，最低版本 v0.2.0</p>
<p><strong>kubenet</strong><br>kubelet是一个仅使用与Linux的基本和简单的网络插件。它本身并不实现高级的功能，如跨节点网络或网络策略。kubenet创建一个名为<code>cbr0</code>的Linux bridge，并为每个pod创建一个<code>veth</code>对，每对的主机端连接到连接到<code>cbr0</code>。通过配置或控制器管理器为该对的pod端分配范围内的IP地址。为cbr0分配一个MTU，该MTU与主机上启用的普通接口的最小MTU相匹配。</p>
<p>此插件需要一些东西：</p>
<ul>
<li>需要标准的CNI <code>bridge</code>, <code>lo</code>, <code>host-local</code>插件，最小版本 v0.2.0。首先从<code>/opt/cni/bin</code>查找。</li>
<li>kubelet必须使用<code>--network-plugin=kubenet</code>参数来启用此插件</li>
<li>kubelet应该指定<code>--non-masquerade-cidr=&lt;clusterCidr&gt;</code>参数确保超出范围的IP流量将使用IP masquerade。</li>
<li>必须通过kubelet的<code>--pod-cidr</code>选项或控制器管理器的<code>--allocate-node-cidrs=true --cluster-cidr=&lt;cidr&gt;</code>选项来为节点分配IP子网</li>
</ul>
<p><strong>自定义MTU(kubenet)</strong><br>应该始终正确配置MTU以获得最佳网络性能。网络插件通常会推断合理的MTU，但有时不会产生最佳的MTU。<br>如果需要，你可使用kubenet的<code>network-plugin-mtu</code>选项来明确指定MTU，仅有kubenet插件支持此选项。</p>
<p><br></p>
<p><strong>使用摘要</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--network-plugin=cni</span><br><span class="line">--network-plugin=kubenet</span><br><span class="line">--network-plugin-mtu=9001</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="设备插件"><a href="#设备插件" class="headerlink" title="设备插件"></a>设备插件</h4><p>Device Plugins</p>
<p>从v1.8开始，k8s为Vendors提供了设备插件框架，以便在不更改k8s核心代码的情况下将资源通知到kubelet，Vendor可实现手动部署或作为DaemonSet部署的设备插件，而不是编写自定义的k8s插件。目标设备包括GPU，高性能NIC， FPGA， InfiniBand和其它计算资源。</p>
<p><br></p>
<p><strong>设备插件注册</strong><br>设备插件功能由<code>DevicePlugins</code>功能控制，默认在 v1.10之前禁用。当启用设备插件功能，kubelet将导出Registration gRPC服务:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">service Registration &#123;</span><br><span class="line">  rpc Register(RegisterRequest) returns (Empty) &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>设备插件可通过gRPC服务向kubelet注册自己。在注册中，它需要发送：</p>
<ul>
<li>Unix socket名</li>
<li>设备插件API版本</li>
<li>想要告知的ResourceName</li>
</ul>
<p>栗子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: demo-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - name: demo-container-1</span><br><span class="line">      image: k8s.gcr.io/pause:2.0</span><br><span class="line">      resources:</span><br><span class="line">        limits:</span><br><span class="line">          vendor-domain/resource: 2 # requesting 2 vendor-domain/resource</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>设备插件实现</strong><br>设备插件的一般工作流包括如下步骤：</p>
<ul>
<li>初始化</li>
<li>插件启动gRPC服务</li>
<li>插件使用kubelet的Unix socket注册自己</li>
<li>注册成功之后，设备插件以服务模式运行，在此期间，它会持续监控设备运行状况，并在任何设备状况发生变化时向kubelet报告</li>
</ul>
<p><br></p>
<p><strong>设备插件部署</strong><br>设备插件可手动或作为DaemonSet来部署。<br>k8s 设备插件的支持人处于alpha状态。</p>
<p><br><br><br></p>
<h3 id="服务目录"><a href="#服务目录" class="headerlink" title="服务目录"></a>服务目录</h3><p>Service Catalog</p>
<p>服务目录是一种扩展API，它使在k8s集群中运行的应用程序能够轻松使用外部托管软件。<br>它提供了从Service Broker 列出，配置和绑定外部托管服务的方法，而无需详细了解如何创建或管理这些服务。<br>使用服务目录，集群操作人员可以浏览服务代理提供的托管服务列表，配置托管服务的实例，并与其绑定以使其可供k8s集群中应用程序使用。</p>
<p><br><br><br><br><br></p>
<h2 id="Containers"><a href="#Containers" class="headerlink" title="Containers"></a>Containers</h2><p><br></p>
<h3 id="Images"><a href="#Images" class="headerlink" title="Images"></a>Images</h3><p>你创建Docker image并将其push到registry，然后在k8s pod中引用它。<br>容器的镜像属性支持与Docker命令相同的语法，包括私有注册表和标记。</p>
<p><br></p>
<p><strong>更新镜像</strong><br>默认的拉取策略是<code>ifNotPresent</code>，这会导致kubelet跳过拉取镜像(如果镜像已存在)。所以在网络不好时，我们可以首先将镜像拉取下来。<br>如果你总想强制拉取镜像，可以执行如下操作：</p>
<ul>
<li>设置容器<code>imagePullPolicy</code>为<code>Always</code></li>
<li>使用<code>:latest</code>作为镜像的标记</li>
<li>启用<code>AlwaysPullImages</code>准入控制器</li>
</ul>
<p>如果没有对镜像指定标记，则假定为<code>:latest</code>标记。</p>
<p><br></p>
<p><strong>使用私有注册表</strong><br>Using a Private Registry</p>
<p>私有注册表有：</p>
<ul>
<li>Docker Hub</li>
<li>Aliyun</li>
<li>Tencent yun</li>
<li>Google Container Registry</li>
<li>AWS Container Registry</li>
<li>Azure Container Registry</li>
<li>…</li>
</ul>
<p>以下是配置节点已使用私有注册表的推荐步骤：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">1. 运行 docker login</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">2. 查看 ~/.docker/config.json</span><br><span class="line">&#123;</span><br><span class="line">        &quot;auths&quot;: &#123;</span><br><span class="line">                &quot;https://index.docker.io/v1/&quot;: &#123;</span><br><span class="line">                        &quot;auth&quot;: &quot;xxxxxxxxxxxxxxx&quot;</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;HttpHeaders&quot;: &#123;</span><br><span class="line">                &quot;User-Agent&quot;: &quot;Docker-Client/18.03.1-ce (linux)&quot;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">3. 获取节点列表</span><br><span class="line">#name</span><br><span class="line">nodes=$(kubectl get nodes -o jsonpath=&apos;&#123;range.items[*].metadata&#125;&#123;.name&#125; &#123;end&#125;&apos;)</span><br><span class="line"></span><br><span class="line">#IPs</span><br><span class="line">nodes=$(kubectl get nodes -o jsonpath=&apos;&#123;range .items[*].status.addresses[?(@.type==&quot;ExternalIP&quot;)]&#125;&#123;.address&#125; &#123;end&#125;&apos;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">4. 复制 .docker/config.json 到上面的搜索路径列表</span><br><span class="line"></span><br><span class="line">for n in $nodes; do scp ~/.docker/config.json root@$n:/var/lib/kubelet/config.json; done</span><br></pre></td></tr></table></figure>
<p><br></p>
<p>通过创建pod来验证私有镜像：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f - &lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: private-image-test-1</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - name: uses-private-image</span><br><span class="line">      image: $PRIVATE_IMAGE_NAME</span><br><span class="line">      imagePullPolicy: Always</span><br><span class="line">      command: [ &quot;echo&quot;, &quot;SUCCESS&quot; ]</span><br><span class="line">EOF</span><br><span class="line">pod &quot;private-image-test-1&quot; created</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>预拉取镜像</strong><br>Pre-pulling Images</p>
<p>默认情况下，kubelet将尝试从指定的注册表中拉取镜像。但是，如果容器的<code>imagePullPolicy</code>属性为<code>ifNotPresent</code>或<code>Never</code>，则会使用本地镜像。<br>如果你希望依赖于预先拉取的镜像作为注册表身份验证的替代，则必须确保集群中的所有节点都具有相同的预拉取镜像。<br>这可以用于预加载某些镜像以提高速度，或者作为对私有注册表进行身份认证的替代方法。<br>请确保所有的pods都对预拉取的镜像由访问权限。</p>
<p><br></p>
<p><strong>Specifying ImagePullSecrets on a Pod</strong><br>k8s支持在pod上指定registry keys。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#使用Docker config创建secret</span><br><span class="line">kubectl create secret docker-registry -h</span><br><span class="line">#Create a new secret for use with Docker registries.</span><br><span class="line"></span><br><span class="line">kubectl create secret docker-registry zhang21-secret --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAIL</span><br><span class="line">secret &quot;myregistrykey&quot; created.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl get secret</span><br><span class="line">NAME                  TYPE                                  DATA      AGE</span><br><span class="line">zhang21-secret        kubernetes.io/dockerconfigjson        1         22s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#查看和修改</span><br><span class="line">kubectl edit secret/zhang21-secret</span><br></pre></td></tr></table></figure>
<p>如果需要访问多个注册表，你可以为每个注册表创建一个secret。当为pod来取镜像时，kubelet会将<code>imagePullSecret</code>合并到 一个虚拟的<code>.docker/config.json</code>文件中。<br>pod只能在自己的命名空间中引用image pull secret，因此每个命名空间都需要执行一次此过程。</p>
<p><br></p>
<p>pod上的imagePullSecret</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">apiVersion:</span><br><span class="line">kind: Pod</span><br><span class="line">xxx</span><br><span class="line">spec:</span><br><span class="line">  container:</span><br><span class="line">    xxx</span><br><span class="line">  imagePullSecretes:</span><br><span class="line">    name: zhang21-secret</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h3 id="容器环境变量"><a href="#容器环境变量" class="headerlink" title="容器环境变量"></a>容器环境变量</h3><p>Container Environment Variables</p>
<p>k8s容器环境为容器提供了几个重要资源：</p>
<ul>
<li>文件系统(是镜像和卷的组合)</li>
<li>容器自身信息</li>
<li>集群中对象的信息</li>
</ul>
<p><br><br><br></p>
<h3 id="容器生命周期钩子"><a href="#容器生命周期钩子" class="headerlink" title="容器生命周期钩子"></a>容器生命周期钩子</h3><p>Container Lifecycle Hooks</p>
<p>本节描述了kubelet如何使用容器生命周期钩子框架来运行在管理生命周期中由事件触发的代码。<br>与许多具有组件生命周期钩子的编程语言框架类似，k8s为容器提供了生命周期钩子。钩子使容器能够了解其生命周期中的事件，并在执行相应的生命周期钩子时运行在处理程序中实现的代码。</p>
<p><br></p>
<h4 id="容器钩子"><a href="#容器钩子" class="headerlink" title="容器钩子"></a>容器钩子</h4><p>有两个公开给容器的钩子：</p>
<ul>
<li><p><strong>PostStart</strong><br>此钩子在容器创建后立即执行。但是，无法保证钩子将在容器<code>ENTRYPOINT</code>之前执行。没有参数传递给处理程序。</p>
</li>
<li><p><strong>PreStop</strong><br>此钩子在容器终止前立即调用。它是阻塞的，意味着它是同步的。所以它必须在调用删除容器之前完成才能发送。没有参数传递给处理程序。</p>
</li>
</ul>
<p><br></p>
<p><strong>Hook handler implementations</strong><br>容器可以通过实施和注册该钩子的处理程序来访问钩子。可为容器实施两种类型的钩子处理程序：</p>
<ul>
<li>Exec： 在cgroup和namespace内执行特定的命令</li>
<li>HTTP： 在容器的特定端点上执行一个HTTP请求</li>
</ul>
<p><br></p>
<p><strong>Hook handler exection</strong><br>调用容器生命周期管理钩子时，k8s管理系统会在为钩子注册的容器中执行处理程序。</p>
<p>钩子处理程序调用包含在容器的Pod的上下文中是同步的。这意味着对<strong>PostStart钩子</strong>，容器<code>ENTRYPOINT</code>和钩子异步启动。但是，如果钩子 运行/挂起 太长时间，则容器无法达到<code>running state</code>。<br><strong>PreStop钩子</strong>的行为类似。如果钩子在执行期间挂起，则pod阶段将保持在<code>Terminating state</code>，并在pod结束的<code>terminationGracePeriodSeconds</code>之后被杀掉。<br>如果<strong>PostStart</strong>或<strong>PreStop</strong>钩子失败，则会杀掉容器。</p>
<p>用户应该使他们的钩子处理程序尽可能的轻量化。</p>
<p><br></p>
<p><strong>Hook delivery guarantees</strong><br>钩子交付至少是一次，这意味着对于任何给定的事件可以多次调用钩子。由钩子实现来正确处理这个问题。<br>通常，只进行当次交付。在一些罕见的情况下，可能会发生双重交付。</p>
<p><br></p>
<p><strong>Debugging Hook handlers</strong><br>钩子处理程序的日志并不会在Pod事件中公开。如果处理程序由于某种原因失败，它会广播这个事件。</p>
<p><br><br><br><br><br></p>
<h2 id="工作负载"><a href="#工作负载" class="headerlink" title="工作负载"></a>工作负载</h2><p>Workloads</p>
<h3 id="Pods"><a href="#Pods" class="headerlink" title="Pods"></a>Pods</h3><p>Pod是k8s的基本构建块，是你创建和部署k8s对象模型中最小和最简单的单元。Pod代表了集群上正在运行的进程。<br>Pod封装了(encapsulates) 一个/多个 应用程序容器，存储资源，唯一的IP地址(集群内)以及控制容器运行需要的选项。Pod代表了一个部署单元，k8s中的单个应用程序实例可能包含单个或少量紧密耦合且共享资源的容器。<br>Docker是k8s Pod中最常使用的容器运行环境(runtime)，Pod同样也支持其它容器运行环境。</p>
<p>k8s 集群中的Pods可以用两种主要方法来使用：</p>
<ul>
<li><p><strong>运行单个容器的Pod</strong><br>Pods that run a single container<br><code>one-container-per-pod</code>模型时最常见的k8s用例。在这种情况下，你可将Pod视为单个容器的包装，而k8s直接管理Pod而不是容器。</p>
</li>
<li><p><strong>运行多个需要协同工作的容器的Pod</strong><br>Pods that run multiple containers that need to work together<br>Pod可能封装了由多个协同定位(co-located)容器组成的应用程序，这些容器紧密耦合并且需要共享资源。这些协同的容器可能形成一个统一的服务单元——一个容器从共享卷向公众提供文件，而一个单独的<code>sidecar</code>容器刷新或更新这些文件。Pod将这些容器和资源作为单个可管理的实体包装在一起。</p>
</li>
</ul>
<p><br></p>
<p>每个Pod都用于运行给定应用程序的单个实例。如果你想要水平扩展应用程序，你可以使用多个Pods(每个实例一个)。在k8s中，这通常称为<strong>副本(replication)</strong>。 <code>Replicated Pods</code>通常通过称为<strong>控制器(Controller)</strong>的抽象来创建和管理。</p>
<p><br></p>
<p><strong>Pod如何管理多个容器</strong><br>Pods旨在支持多个协作进程(as container)，形成一个具有凝聚力的服务单元。Pod中的容器将自动协同定位(co-located)，并在集群中的同一主机上协同调度(co-scheduled)。容器可以共享资源和依赖，彼此通信，并协调它们何时以及如何终止。</p>
<p>注意，将多个协同定位和协同管理的容器分组到一个Pod中是一个相对高级的栗子。你应该仅在容器紧密耦合的特定实例中使用此模式。<br>例如，你可能有一个容器充当共享卷中文件的Web Server，以及一个单独的<code>sidecat</code>容器——用于从远程更新这个文件：</p>
<p><img src="/images/K8s/pod_multi_container.png" alt="多容器Pod"></p>
<p><br></p>
<p><strong>Pod共享资源</strong><br>Pod为其组成容器提供了两种共享资源：</p>
<ul>
<li><p><strong>Networking</strong><br>每个Pod都被分配了一个唯一的IP地址(within cluster)。Pod中的每个容器都共享网络命名空间，包括IP地址和网络端口。Pod内的容器可使用<code>localhost</code>相互通信。当Pod内的容器与Pod外的实体通信时，它们必须协调如何使用共享网络资源。</p>
</li>
<li><p><strong>Storage</strong><br>Pod可以指定一组共享存储卷。Pod中的所有容器都可以访问这个共享卷，允许这些容器共享数据。还是关于数据持久化的卷。</p>
</li>
</ul>
<p><br></p>
<p><strong>使用Pods</strong><br>你很少直接在k8s(甚至是单例Pod)中创建单独的Pod。这是因为Pod被设计为相对短暂的一次性实体，即用后即焚。当Pod被创建后，都会被调度到集群中的节点上运行。Pod保留在该节点上，知道进程终止，Pod对象被删除，Pod因资源不足而被驱逐，或节点失效。Pod不会自愈。<br>注意： 重启Pod中的容器与重启Pod不是一回事。Pod本身不运行，它只提供容器的运行环境并保持容器的运行状态。但是容器运行的环境会持续存在，直到删除为止。</p>
<p>Pod本身不提供自我修复(self-heal)。如果将Pod调度到一个失败的节点，或调度操作本身失败，则会删除Pod。同样，由于缺乏资源或节点维护中，Pod将无法在驱逐中存活。k8s使用一个高更级别的抽象，称为控制器(Controller)。它管理相对可处理的Pod实例的工作。因此，尽管可以直接使用Pod，但在k8s中使用控制器管理Pod更为常见。<br>控制器可为你创建和管理多个Pod，处理副本和上线，并在集群范围内提供自我修复功能。例如，如果节点故障，控制器可能会通过在不同节点上安排相同的替换来自动替换Pod。<br>通常，控制器使用你提供的Pod模板来创建它负责的Pod。</p>
<p><br></p>
<p><strong>Pod Templates</strong><br>Pod模板是Pod规范，包含在其它对象中。控制器使用Pod模板制作实际的Pod。</p>
<p>栗子：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: myapp-pod</span><br><span class="line">  labels:</span><br><span class="line">    app: myapp</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: myapp-container</span><br><span class="line">    image: busybox</span><br><span class="line">    command: ['sh', '-c', 'echo Hello Kubernetes! &amp;&amp; sleep 3600']</span><br></pre></td></tr></table></figure>
<p>Pod模板不是指定所有副本的当前所需状态，而是像饼干切割器。饼干被切割后，饼干与切割器无关。</p>
<p><br><br><br></p>
<h4 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h4><p>Pod是可在k8s中创建和管理的最小可部署的计算单元。</p>
<p><br></p>
<p><strong>Pod是什么</strong><br>Pod是一组 一个/多个容器，具有共享存储/网络，以及如何运行容器的规范。Pod中的容器总是<code>co-located</code>和<code>co-scheduler</code>，并在共享上下文中运行。一个pod模拟特定应用程序的逻辑主机，它包含一个/多个紧密耦合的应用程序容器。<br>Pod的共享上下文十一组Linux namespace， cgroup，以及隔离方面。在Pod的上下文中，各个应用程序科恩能够回应用进一步的子隔离。<br>Pod中的容器共享IP地址和端口空间，并且可通过<code>localhsot</code>找到彼此。它们还可使用IPC相互通信。不同Pod中的容器具有不同的IP地址，默认情况下无法通信，需要进行额外配置。<br>Pod中的应用程序还可访问共享卷，共享卷被定义为Pod的一部分，可挂载到每个应用程序的文件系统中。<br>就Docker构造而言，Pod被建模为一组具有共享命名空间和共享卷的Docker容器。<br>与单个应用程序容器类似，Pod被认为是相对短暂(非持久)的实体。</p>
<p><br></p>
<p><strong>Pod动机</strong></p>
<ul>
<li><p>管理(Management)<br>Pod是多个协作过程进程模式的模型，形成了一个有凝聚力的服务单元。它们通过提供更高级别的抽象来简化应用程序部署和管理。Pod提供用于部署，水平扩展，副本的单元。对于Pod中的容器，它们将自动处理协同调度， 共享命运， 协同副本，资源共享和依赖管理…</p>
</li>
<li><p>资源共享和交流<br>Pod可以实现成员之间的数据共享和通信。<br>Pod中的应用程序都是用相同的网络命名空间，因此可通过<code>localhost</code>进行通信。因此，Pod中的应用程序必须协调对端口的使用。<br>主机名设置为Pod中应用程序容器的Pod名。<br>除了定义在Pod中运行的应用程序容器，Pod还制定了一组共享存储卷(持久化)。</p>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get pod -o wide</span><br><span class="line">NAME                                   READY     STATUS    RESTARTS   AGE       IP               NODE</span><br><span class="line">kubernetes-dashboard-6948bdb78-tdh5v   1/1       Running   0          8d        10.244.2.3       salt01</span><br><span class="line">metrics-server-85ff8f7b84-72rd4        1/1       Running   0          9d        10.244.2.2       salt01</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl -n kube-system <span class="built_in">exec</span> -it metrics-server-85ff8f7b84-72rd4 /bin/sh</span><br><span class="line">/ <span class="comment"># hostname</span></span><br><span class="line">metrics-server-85ff8f7b84-72rd4</span><br><span class="line">/ <span class="comment"># ifconfig</span></span><br><span class="line">eth0 10.244.2.2</span><br><span class="line">/ <span class="comment"># ping 10.244.2.3</span></span><br><span class="line">PING 10.244.2.3 (10.244.2.3): 56 data bytes</span><br><span class="line">64 bytes from 10.244.2.3: seq=0 ttl=64 time=0.115 ms</span><br><span class="line">64 bytes from 10.244.2.3: seq=1 ttl=64 time=0.062 ms</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>Pod使用</strong><br>Pod可用于托管垂直集成的应用程序栈，但主要动机是用于支持协同共处，协同管理的应用程序。如：</p>
<ul>
<li>内容管理系统，文件和数据加载器，本地缓存管理器</li>
<li>日志和检查点的备份、压缩、轮询、快照</li>
<li>数据变更观察器，日志和监控适配器，事件发布器</li>
<li>代理，网桥和适配器</li>
<li>控制器，管理器，配置器和更新器</li>
</ul>
<p>通常，单个Pod不用于运行同一程序的多个实例。</p>
<p><br></p>
<p><strong>替代考虑</strong><br>为什么不在单个容器中运行多个程序？</p>
<ol>
<li>透明度</li>
<li>解耦软件依赖关系</li>
<li>使用方便</li>
<li>效率</li>
</ol>
<p><br></p>
<p><strong>Pod耐久性</strong><br>Pod不应被视为耐用实体。它们不会在 调度失败，节点故障，驱逐，节点维护等情况下存活。<br>通常，用户不需要直接创建Pod。而应该(几乎总是)使用控制器。控制器提供了集群范围内的自修复(self-healing)，副本和上线管理。</p>
<p>Pod公开为一个原语以便于使用：</p>
<ul>
<li>调度器和控制器可插拔</li>
<li>支持Pod级操作，而无需通过控制器API代理</li>
<li>将Pod寿命与控制器寿命分离</li>
<li>控制器和服务的分离</li>
<li>kubelet实际是Pod控制器</li>
<li>高可用应用程序</li>
</ul>
<p><br></p>
<p><strong>Pod终止</strong><br>由于Pod表示集群中节点上正在运行的进程，因此允许这些进程在不需要时优雅地终止(gracefully terminate)非常重要。用户应该能够请求并指导进程何时终止，但也要确保删除最终完成。当用户请求删除Pod时，系统会在允许Pod强制终止之前记录预期的宽限期(grace period)，并将<code>TERM</code>信号(-15)发送到每个容器的主进程中。宽限期到期后，<code>KILL</code>信号(-9)发送到这些进程，然后从API server中删除该Pod。如果在等待进程终止时Kubelet或容器管理器重启了，则将在完整的宽限期内重试终止。</p>
<p>流程：</p>
<ol>
<li>用户发送删除Pod的命令，默认宽限期(30s)</li>
<li>API server中的Pod随着时间的推移而更新，在此之后，除了宽限期外，Pod被认为死亡</li>
<li>列出客户端命令时，Pod显示为<code>Terminating</code></li>
<li>当Kubelet发现Pod被标记为<code>Terminating</code>，它将开始Pod关闭过程<br> 4.1 如果Pod定义了<code>preStop hook</code>，则会在Pod内调用<br> 4.2 Pod中的进程发送<code>TERM</code>信号</li>
<li>Pod将从端点列表中删除，并且不再被视为副本控制器中运行的Pod的一部分。缓慢关闭的Pod无法继续为流量提供服务，因为负载均衡器会将其从轮询中删除</li>
<li>当宽限期到期后，仍在Pod中运行的任何进程都将被<code>KILL</code>信号杀死</li>
<li>Kubelet通过设置宽限期0（立即删除）完成删除API server上的Pod。Pod从API中消失，客户端不在可见</li>
</ol>
<p>默认情况下，所有删除都有30s的宽限期。<code>kubectl delete</code>命令支持指定<code>--grace-period=</code>选项。设置为0表示强制删除Pod。<code>--force --grace-period=0</code>强制删除。</p>
<p><strong>强制删除Pod</strong><br>强制删除Pod被定义为立即从集群状态和etcd中删除Pod。当执行强制删除时，API server不会等待来自Kubelet的确认——确认该Pod已在运行的节点上终止。它会立即删除API中的Pod，以便可使用相同的名称创建新的Pod。在节点上，设置为立即终止的Pod在被强制终止之前仍被授予一个小的宽限期。<br>强制删除可能会对某些Pod有潜在危险，请谨慎执行。</p>
<p><br></p>
<p><strong>Pod容器的特权模式(Privileged mode)</strong><br>在容器 spec的<code>SecurityContext</code>中使用<code>privileged</code>标志，来启用Pod中容器的特权模式。这对于想要使用Linux功能的容器非常有用。容器内的进程获得与可访问的容器外进程几乎相同的权限。使用特权模式，可以更容易的编写网络和卷插件，而不需要编译到kubelet。</p>
<p><br></p>
<p><strong>API对象</strong><br>Pod是k8s REST API中的顶级资源, <code>/pod/xxx</code>。</p>
<p><br><br><br></p>
<h4 id="Pod生命周期"><a href="#Pod生命周期" class="headerlink" title="Pod生命周期"></a>Pod生命周期</h4><p>Pod Lifecycle</p>
<p><br></p>
<p><strong>阶段(phase)</strong><br>Pod的<code>status</code>字段是一个<code>PodStatus</code>对象，它有一个<code>phase</code>字段。</p>
<p>阶段可能的值：</p>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Pending</td>
<td>The Pod has been accepted by the Kubernetes system, but one or more of the Container images has not been created. This includes time before being scheduled as well as time spent downloading images over the network, which could take a while.</td>
</tr>
<tr>
<td>Running</td>
<td>The Pod has been bound to a node, and all of the Containers have been created. At least one Container is still running, or is in the process of starting or restarting.</td>
</tr>
<tr>
<td>Succeeded</td>
<td>All Containers in the Pod have terminated in success, and will not be restarted.</td>
</tr>
<tr>
<td>Failed</td>
<td>All Containers in the Pod have terminated, and at least one Container has terminated in failure. That is, the Container either exited with non-zero status or was terminated by the system.</td>
</tr>
<tr>
<td>Unknown</td>
<td>For some reason the state of the Pod could not be obtained, typically due to an error in communicating with the host of the Pod.</td>
</tr>
</tbody>
</table>
<p><br></p>
<p><strong>状况(conditions)</strong><br>Pod有一个<code>PodStatus</code>，它有一个<code>PodConditions</code>数组，表示Pod是否通过。每个<code>PodCondition</code>数字的每个元素都有六个可能的字段：</p>
<ul>
<li><code>lastProbeTime</code>: 最后一次探测Pod状况的字段</li>
<li><code>lastTransitionTime</code>: Pod最后从一个状态转换到另一个状态的时间戳的字段</li>
<li><code>message</code>: 有关转换的人类可读的详细信息的字段</li>
<li><code>reason</code>: 一个独特的，单字的最后转换的原因的字段</li>
<li><code>status</code>: 字段值可能为<code>True, False, Unknown</code></li>
<li><code>type</code>: 字段可能有如下值:<ul>
<li><code>PodScheduled</code>: Pod已被调度到一个节点</li>
<li><code>Ready</code>: Pod能提供请求，并应该添加到所有匹配服务的负载均衡池中</li>
<li><code>Initialized</code>: 所有的初始化容器已成功启动</li>
<li><code>Unschedulable</code>: 调度器现在无法调度Pod，如缺乏资源…</li>
<li><code>ContainersReady</code>: Pod中的所有容器都已准备好了</li>
</ul>
</li>
</ul>
<p><br></p>
<p><strong>探测(probes)</strong><br>探测是由容器上的kubelet定期执行的诊断。为了执行诊断，kubelet调用容器执行处理器(Handler)。有三种类型的处理器:</p>
<ul>
<li><code>ExecAction</code>: 在容器内执行指定命令。如果状态码为0，则认为诊断成功</li>
<li><code>TCPSocketAction</code>: 在指定端口的容器IP地址执行TCP检查。如果端口打开，则认为诊断成功</li>
<li><code>HTTPGetAction</code>: 在容器IP的特定端口的路径下执行HTTP GET请求。如果请求成功，则认为诊断成功</li>
</ul>
<p>每个探测可能有三种结果:</p>
<ul>
<li>Success</li>
<li>Failure</li>
<li>Unknown</li>
</ul>
<p>kubelet可选择在运行容器上执行两种探测并对其作出反应:</p>
<ul>
<li><code>livenessProbe</code>: 确定容器是否正在运行</li>
<li><code>readinessProbe</code>: 确定容器是否准备好为请求提供服务</li>
</ul>
<p>什么时候使用这两中探测？<br>When should you use liveness or readiness probes?</p>
<p>如果容器中的进程在遇到问题或变得不健康时会自行崩溃(crash)，则你不一定需要<code>livenessProbe</code>。kubelet将根据Pod的<code>restartPolicy</code>自动执行正确的操作。<br>如果希望在探测失败时杀死并重启容器，则请指定<code>livenessPorbe</code>和指定<code>restartPolicy</code>为<code>Always</code></p>
<p>如果只想在探测成功时向Pod发送流量，请指定<code>readinessProbe</code>。<br>如果容器需要在启动期间除了大型数据，配置文件或迁移，请指定<code>readnessProbe</code>。<br>如果你希望容器能够自行维护，你可指定一个<code>readnessProbe</code>，它检查特定端点。</p>
<p>注意，如果你只想在删除Pod时排除请求，则不一定需要<code>readnessProbe</code>。无论是否存在<code>readnessProbe</code>，Pod都会自动将其置于未准备状态。Pod在等待Pod中容器停止时仍处于未准备状态。</p>
<p><br></p>
<p><strong>Pod readiness gate</strong><br>FEATURE STATE: Kubernetes v1.11 alpha</p>
<p>为了通过向PodStatus调价额外的反馈或信号来增加<code>Pod readness</code>的可扩展性，k8s v1.11引入了一个名为<code>Pod ready++</code>的功能。你可在<code>PodSpec</code>中使用新字段<code>ReadinessGate</code>来指定要为Pod准备情况评估的其它条件。如果k8s在Pod的<code>status.conditions</code>字段找不到这样的状况，则状况的状态默认为<code>False</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Kind: Pod</span><br><span class="line">...</span><br><span class="line">spec:</span><br><span class="line">  readinessGates:</span><br><span class="line">    - conditionType: &quot;www.example.com/feature-1&quot;</span><br><span class="line">status:</span><br><span class="line">  conditions:</span><br><span class="line">    - type: Ready  # this is a builtin PodCondition</span><br><span class="line">      status: &quot;True&quot;</span><br><span class="line">      lastProbeTime: null</span><br><span class="line">      lastTransitionTime: 2018-01-01T00:00:00Z</span><br><span class="line">    - type: &quot;www.example.com/feature-1&quot;   # an extra PodCondition</span><br><span class="line">      status: &quot;False&quot;</span><br><span class="line">      lastProbeTIme: null</span><br><span class="line">      lastTransitionTime: 2018-01-01T00:00:00Z</span><br><span class="line">  containerStatuses:</span><br><span class="line">    - containerID: docker://abcd...</span><br><span class="line">      ready: true</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>重启策略</strong><br><code>PodSpec</code>有一个<code>restartPolicy</code>字段，其值可能是<code>Always(默认值), OnFailure, Never</code>。此策略应用于Pod中的所有容器，它仅指由同一节点上的kubelet重启的容器。退出的容器将由kubelet以指定退避延迟(10s, 20s, 40s…)重新启动，上限5分钟，并在成功执行十分钟后重置。</p>
<p><br></p>
<p><strong>寿命(lifetime)</strong><br>一般来说，Pod不会消失，直到有人摧毁它们。唯一的例外是，具有成功或失败超过一段时间的阶段的Pod将过期并自动销毁。</p>
<p>有三种类型的控制器可用：</p>
<ul>
<li>Use a Job for Pod</li>
<li>Use a  ReplicationController/ReplicaSet/Deployment for Pod</li>
<li>Use a DaemonSet for Pod</li>
</ul>
<p>所有三种类型的控制器都包含了PodTemplate。推荐创建适当的控制器并让它创建Pod，而不是自己直接创建Pod。这是因为Pod单独对机器故障没有弹性，但控制器不会。<br>如果节点死亡或与集群的其余部分断开连接，k8s会应用策略将丢失节点上的所有Pod的阶段设置为Failed。</p>
<p><br><br><br></p>
<h4 id="Init-Containers"><a href="#Init-Containers" class="headerlink" title="Init Containers"></a>Init Containers</h4><p>本节提供了初始容器(init container)的概述，它是在应用程序容器运行之前的专用容器，可包含应用程序镜像中不存在的实用程序或脚本设置。</p>
<p><br></p>
<p><strong>理解初始容器</strong><br>Pod可以有多个容器在其中运行应用程序，但它同样可以有一个或多个初始容器——它在应用程序容器启动前运行。<br>初始容器与常规容器一样，除了：</p>
<ul>
<li>They always run to completion.</li>
<li>每一个必须在下一个启动之前成功完成</li>
</ul>
<p>如果Pod的初始容器失败，则k8s会重复重启直到初始容器成功。但是，如果Pod的<code>restartPolicy</code>为<code>Never</code>，则不会重启。<br>要将容器指定为初始容器，请将<code>PodSpec</code>上的<code>initContainers</code>字段添加为应用程序<code>container</code>数组旁边的容器类型对象的JSON数组。初始容器的状态在<code>.status.initContainerStatuses</code>字段中作为容器状态数据返回。</p>
<p><strong>与常规容器的不同</strong><br>初始容器支持应用程序容器的所有字段和功能，包括资源限制，卷和安全设置。但资源请求和处理方式略有不同。此外，初始容器不支持<code>readiness probes</code>，因为它必须在Pod准备好之前运行完成。<br>如果为Pod指定了多个初始容器，则按顺序依次运行一个容器。每个必须在下一个运行之前完成。当所有初始容器都运行完毕时，k8s会初始化Pod并像往常一样运行应用程序容器。</p>
<p><br></p>
<p><strong>初始容器可用于什么</strong><br>由于初始容器具有来自应用程序容器的单独镜像，因此它们对于启动相关代码具有一些优势：</p>
<ul>
<li>出于安全原因，它们可以包含并运行不希望包含在应用程序容器镜像中的使用程序</li>
<li>它可以包含应用程序镜像中不存在的实用程序或自定义代码。例如，在配置过程中，无需为了使用其他工具(sed, awk, dig…)而专门使用<code>FROM</code>创建一个镜像</li>
<li>应用程序镜像构建器和部署器角色可独立工作，而无需共同构建单个应用程序镜像</li>
<li>它们使用Linux命名空间，以便从应用程序容器中获得不同的文件系统视图。因此，它们可以访问应用程序容器无法访问的<code>Secrets</code></li>
<li>它们在应用程序容器启动前运行完成，因此初始容器提供了一种简单的方法来阻止或延迟应用程序容器的启动，知道满足一组前置条件。</li>
</ul>
<p><br></p>
<p><strong>栗子</strong><br>这有些初始容器的使用案例:</p>
<ul>
<li>等待使用shell命令创建服务: <code>for in in {1..100}; do sleep 1; if dig myservice; then exit 0; fi; done; exit 1</code></li>
<li>使用API从远程服务器注册此Pod: <code>curl -XPOST http://host:port/register -d &#39;instance=$()&amp;ip=$()&#39;</code></li>
<li>在启动应用程序之前等待一段时间: <code>sleep 60</code></li>
<li>克隆一个git repo到某个卷</li>
<li>替换配置文件中的值并运行模板来动态生成应用程序容器的配置文件</li>
</ul>
<p><br></p>
<p><strong>使用初始容器</strong><br>两个初始容器。第一个等待<code>myservice</code>，第二个等待<code>mydb</code>。一旦两个容器完成，Pod将开始。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">myapp-pod</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">myapp</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">myapp-container</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">['sh',</span> <span class="string">'-c'</span><span class="string">,</span> <span class="string">'echo The app is running! &amp;&amp; sleep 3600'</span><span class="string">]</span></span><br><span class="line"><span class="attr">  initContainers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">init-myservice</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">['sh',</span> <span class="string">'-c'</span><span class="string">,</span> <span class="string">'until nslookup myservice; do echo waiting for myservice; sleep 2; done;'</span><span class="string">]</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">init-mydb</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">['sh',</span> <span class="string">'-c'</span><span class="string">,</span> <span class="string">'until nslookup mydb; do echo waiting for mydb; sleep 2; done;'</span><span class="string">]</span></span><br></pre></td></tr></table></figure>
<p>创建:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f /etc/k8s/test/init-container.yaml</span><br><span class="line">pod/myapp-pod created</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl get pod</span><br><span class="line">NAME             READY     STATUS     RESTARTS   AGE</span><br><span class="line">init-container   0/1       Init:0/2   0          6s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl describe -f /etc/k8s/test/init-container.yaml</span><br><span class="line">Init Containers:</span><br><span class="line">  init-myservice:</span><br><span class="line">    Container ID:  docker://f9ca73d4d2c8903a1fe84937e34ae27b909a691d2e524254b8f4aec9d5cc754c</span><br><span class="line">    Image:         busybox</span><br><span class="line">    Image ID:      docker-pullable://docker.io/busybox@sha256:cb63aa0641a885f54de20f61d152187419e8f6b159ed11a251a09d115fdff9bd</span><br><span class="line">    Port:          &lt;none&gt;</span><br><span class="line">    Host Port:     &lt;none&gt;</span><br><span class="line">    Command:</span><br><span class="line">      sh</span><br><span class="line">      -c</span><br><span class="line">      until nslookup myservice; do echo waiting for myservice; sleep 2; done;</span><br><span class="line">    State:          Terminated</span><br><span class="line">      Reason:       Completed</span><br><span class="line">      Exit Code:    0</span><br><span class="line">      Started:      Fri, 24 Aug 2018 16:31:13 +0800</span><br><span class="line">      Finished:     Fri, 24 Aug 2018 16:31:18 +0800</span><br><span class="line">    Ready:          True</span><br><span class="line">    Restart Count:  0</span><br><span class="line">    Environment:    &lt;none&gt;</span><br><span class="line">    Mounts:</span><br><span class="line">      /var/run/secrets/kubernetes.io/serviceaccount from default-token-69vgk (ro)</span><br><span class="line">  init-mydb:</span><br><span class="line">    Container ID:  docker://a9946122976ff70ff1dd874299e3e63f4b07f2758f5e6518b84343c58daa3506</span><br><span class="line">    Image:         busybox</span><br><span class="line">    Image ID:      docker-pullable://docker.io/busybox@sha256:cb63aa0641a885f54de20f61d152187419e8f6b159ed11a251a09d115fdff9bd</span><br><span class="line">    Port:          &lt;none&gt;</span><br><span class="line">    Host Port:     &lt;none&gt;</span><br><span class="line">    Command:</span><br><span class="line">      sh</span><br><span class="line">      -c</span><br><span class="line">      until nslookup mydb; do echo waiting for mydb; sleep 2; done;</span><br><span class="line">    State:          Terminated</span><br><span class="line">      Reason:       Completed</span><br><span class="line">      Exit Code:    0</span><br><span class="line">      Started:      Fri, 24 Aug 2018 16:31:24 +0800</span><br><span class="line">      Finished:     Fri, 24 Aug 2018 16:31:29 +0800</span><br><span class="line">    Ready:          True</span><br><span class="line">    Restart Count:  0</span><br><span class="line">    Environment:    &lt;none&gt;</span><br><span class="line">    Mounts:</span><br><span class="line">      /var/run/secrets/kubernetes.io/serviceaccount from default-token-69vgk (ro)</span><br><span class="line">Containers:</span><br><span class="line">  myapp-container:</span><br><span class="line">    Container ID:  docker://b2c7a1f32d65dd41fa439d1f6879824b40c3014b32b15d61fed0cda171144a1b</span><br><span class="line">    Image:         busybox</span><br><span class="line">    Image ID:      docker-pullable://docker.io/busybox@sha256:cb63aa0641a885f54de20f61d152187419e8f6b159ed11a251a09d115fdff9bd</span><br><span class="line">    Port:          &lt;none&gt;</span><br><span class="line">    Host Port:     &lt;none&gt;</span><br><span class="line">    Command:</span><br><span class="line">      sh</span><br><span class="line">      -c</span><br><span class="line">      echo The app is running! &amp;&amp; sleep 3600</span><br><span class="line">    State:          Running</span><br><span class="line">      Started:      Fri, 24 Aug 2018 16:31:34 +0800</span><br><span class="line">    Ready:          True</span><br><span class="line">    Restart Count:  0</span><br><span class="line">    Environment:    &lt;none&gt;</span><br><span class="line">    Mounts:</span><br><span class="line">      /var/run/secrets/kubernetes.io/serviceaccount from default-token-69vgk (ro)</span><br></pre></td></tr></table></figure>
<p><img src="/images/K8s/init_container.png" alt="初始容器"></p>
<p><br></p>
<p><strong>详细行为</strong><br>在Pod启动期间，初始化网络和卷后，初始容器将按顺序启动。每个容器必须在下一个容器启动前成功退出。如果容器由于运行环境未能启动或失败退出而启动失败，则它根据Pod的<code>restartPolicy</code>重试。如果Pod的<code>restartPolicy</code>为<code>Always(默认)</code>，则初始容器使用<code>restartPolicy</code>为<code>OnFailure</code>。<br>在所有初始容器都成功之前，Pod无法变为<code>Ready</code>。初始容器上的端口无法聚合到服务下。正在初始化的Pod处于<code>Pending</code>状态，但应该具有<code>Initializing</code>设置为<code>true</code>的条件。<br>如果Pod重启，则所有初始都要执行一遍。<br><code>init container spec</code>的更改仅限于容器镜像字段。更改初始容器镜像字段相当于重启Pod。<br>由于初始容器可重启，重试或重新执行，因此初始容器代码应该是幂等的。In particular, code that writes to files on EmptyDirs should be prepared for the possibility that an output file already exists.<br>在Pod上使用<code>activeDeadlineSeconds</code>，在容器上使用<code>livenessProbe</code>，以防止初始容器永远失败。<br>Pod中每个应用程序和初始容器的名称必须是唯一的，否则会引发验证错误。</p>
<p><strong>资源</strong><br>给定初始容器的排序和执行，适用一下资源使用规则：</p>
<ul>
<li>在所有初始容器上定义的任何特定资源请求或限制的最高值是有效的初始 请求/限制</li>
<li>Pod对资源的有效请求/限制是以下值中的较高者:<ul>
<li>所有的应用程序容器对资源请求/限制的总和</li>
<li>对资源的有效初始请求/限制</li>
</ul>
</li>
<li>调度是基于有效请求/限制完成的，这意味着初始容器可以保留在Pod生命周期内未使用的初始化资源</li>
<li>Pod的有效QoS层与初始容器和应用程序容器一样</li>
</ul>
<p>Pod级别的cgroup基于有效的Pod请求和限制，与调度程序相同。</p>
<p><br></p>
<p><strong>Pod重启原因</strong><br>由于以下原因，Pod可重新启动，导致重新执行初始容器：</p>
<ul>
<li>用户更新了<code>PodSpec</code>，导致初始容器镜像发生噶变。应用程序容器镜像的更改仅重启应用程序容器</li>
<li>Pod的基础架构容器重启</li>
<li>Pod的所有容器都终止，而<code>restartPolicy</code>设置为<code>Always</code>，强制重启，并且初始容器完成记录由于垃圾回收而丢失</li>
</ul>
<p><br><br><br></p>
<h4 id="Pod预设"><a href="#Pod预设" class="headerlink" title="Pod预设"></a>Pod预设</h4><p>Pod Preset</p>
<p>Pod Presets是对象，在创建时将特定信息注入Pod。<br>Pod Preset是一种API资源，用于在创建时将其它运行时的需求写入到Pod。你可使用<code>label selectors</code>指定应用于Pod的给定Pod Preset。<br>使用Pod Preset允许pod template作者不必显示提供每个pod的所有信息。这样，作者不需要知道有关该服务的所有详细信息。</p>
<p><br></p>
<p><strong>它如何工作</strong><br>k8s提供了一个<code>admission controller(Pod Preset)</code>，启用后，会将Pod Preset应用于传入的pod创建请求。当Pod创建请求发生时，系统会执行一下操作：</p>
<ol>
<li>检索所有可供使用的Pod Preset</li>
<li>检查任何Pod Preset的<code>label selector</code>是否与正在创建的Pod上的标签匹配</li>
<li>尝试将Pod Preset定义的各种资源合并到正在创建的Pod中</li>
<li>出错时，抛出一个记录Pod 合并错误的事件，然后创建不从Pod Preset写入任何资源的pod</li>
<li>注释生成的修改后的Pod spec，以表明它已被Pod Preset修改——<code>podpreset.admission.kubernetes.io/podpreset-&lt;pod-preset name&gt;: &quot;&lt;resource version&gt;&quot;</code></li>
</ol>
<p>每个Pod能够被零个或多个PodPreset匹配，每个PodPreset可以被应用到零个或多个Pod。当PodPreset应用于一个或多个Pod时，k8s会修改Pod spec。对于<code>Env, EnvFrom, VolumeMounts</code>，k8s修改Pod中所有容器的<code>container spce</code>；对于<code>Volume</code>的更改，k8s修改<code>Pod spec</code>。</p>
<p><strong>为指定Pod禁用PodPreset</strong><br>在某些情况下，你希望Pod不被任何PodPreset修改。你可修改: <code>podpreset.admission.kubernetes.io/exclude: &quot;true&quot;</code></p>
<p><br></p>
<p><strong>启用PodPreset</strong><br>要在集群中使用PodPreset，你必须确保以下内容：</p>
<ol>
<li>你已启用API类型: <code>settings.k8s.io/v1alpha1/podpreset</code></li>
<li>你已经启动<code>admission controller</code> PodPreset</li>
<li>你已通过在将使用的命名空间中创建PodPreset对象来定义PodPreset</li>
</ol>
<p><br><br><br></p>
<h4 id="中断"><a href="#中断" class="headerlink" title="中断"></a>中断</h4><p>Disruptions</p>
<p>本节适用于想要构建高可用性应用程序的用户，因此需要了解Pod可能发生的中断类型。<br>这同样适用于希望执行自动化集群操作的集群管理员，例如升级或自动伸缩集群。</p>
<p><br></p>
<p><strong>自愿和非自愿中断</strong><br>Voluntary and Involuntary Disruptions</p>
<p><br><br><br></p>
<h3 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a>Controller</h3><p><br></p>
<h4 id="ReplicaSet"><a href="#ReplicaSet" class="headerlink" title="ReplicaSet"></a>ReplicaSet</h4><p>副本集是下一个副本控制器。现在副本集和副本控制器之间的唯一区别是<code>selector</code>的支持。副本集支持<code>labels user guide</code>中描述的新的基于集合<code>selector</code>的要求，而副本控制器仅支持基于等同<code>selector</code>的要求。</p>
<p><br></p>
<p><strong>如何使用副本集</strong><br>大多数支持副本控制器的<code>kubectl</code>命令也支持副本集。一个例外是<code>rolling-update</code>命令。如果你想要滚动更新功能，请考虑使用Deployments代替。<br>虽然副本集可独立使用，但它主要被Deployment用作协调Pod创建，删除和更新的机制。使用部署时，你不必担心管理它们创建的副本集，部署拥有并管理其副本集。</p>
<p><br></p>
<p><strong>何时使用副本集</strong><br>副本集确保在任何给定时间运行指定数量的Pod副本。但是，部署是一个更高级别的概念，它管理副本集并为Pod提供声明性更新以及许多其它有用的功能。因此，除非你需要自定义更新或无需更新，否则建议你使用部署而不是直接使用副本集。<br>这实际上意味着，你不需要操作副本集对象：改为使用部署，并在<code>spec</code>部分定义你的应用程序。</p>
<p><br></p>
<p><strong>栗子</strong></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicaSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">guestbook</span></span><br><span class="line"><span class="attr">    tier:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># modify replicas according to your case</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      tier:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">    matchExpressions:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">&#123;key:</span> <span class="string">tier,</span> <span class="attr">operator:</span> <span class="string">In,</span> <span class="attr">values:</span> <span class="string">[frontend]&#125;</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">guestbook</span></span><br><span class="line"><span class="attr">        tier:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">php-redis</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">gcr.io/google_samples/gb-frontend:v3</span></span><br><span class="line"><span class="attr">        resources:</span></span><br><span class="line"><span class="attr">          requests:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line"><span class="attr">            memory:</span> <span class="number">100</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">        env:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">GET_HOSTS_FROM</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">dns</span></span><br><span class="line">          <span class="comment"># If your cluster config does not include a dns service, then to</span></span><br><span class="line">          <span class="comment"># instead access environment variables to find service host</span></span><br><span class="line">          <span class="comment"># info, comment out the 'value: dns' line above, and uncomment the</span></span><br><span class="line">          <span class="comment"># line below.</span></span><br><span class="line">          <span class="comment"># value: env</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f /etc/k8s/test/frontend.yaml</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>编写副本集<code>spec</code></strong><br>与所有其它k8s API对象一样，副本集需要<code>apiVersion</code>, <code>kind</code>, <code>metadata</code>字段，副本集还需要一个<code>.spce</code>部分。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">#Pod Template</span><br><span class="line">.spec.template是.spec唯一必需的字段</span><br><span class="line">除了pod的必须字段，副本集中的Pod模板还必须指定适当的`label`和`restart policy`</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#Pod Selector</span><br><span class="line">.spec.selector字段是一个label selector。副本集使用与selector匹配的label来管理所有pod。</span><br><span class="line">它不区分创建或删除的Pod以及人或进程创建或删除的pod。这允许替换副本集而不会影响正在运行的Pod。</span><br><span class="line">.spec.template.metadata.labels 必须匹配 .spec.selector，否则它将被API拒绝。</span><br><span class="line">此外，你通常不应创建任何label与selector匹配的pod。如果你这样做了，副本集会认为它创建了其它pod，k8s并没有阻止你这样做。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#Labels on a ReplicaSet</span><br><span class="line">副本集本身可以有标签(.metadata.labels)。通常，你可将其设置为与 .spec.template.metadata.labels 一致。但，允许他们不同，并且 .metadata.labels 不会影响副本集的行为</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#Replicas</span><br><span class="line">你可通过设置 .spec.replicas 来指定应同时运行的pod数量。如果未指定，默认为1</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>使用副本集</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">#删除副本集和它的pods</span><br><span class="line">kubectl delete replicaset/xxx</span><br><span class="line">#或</span><br><span class="line">kubectl proxy --port=8080</span><br><span class="line">curl -XDELETE &apos;localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend \</span><br><span class="line">-d &apos;&#123;&quot;kind&quot;:&quot;DeleteOptions&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;propagationPolicy&quot;:&quot;Foreground&quot;&#125;&apos; \</span><br><span class="line">-H &quot;Content-Type: application/json&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#仅删除副本集</span><br><span class="line">kubectl delete rs/xxx --cascade=false</span><br><span class="line">#或</span><br><span class="line">kubectl proxy --port=8080</span><br><span class="line">curl -X DELETE  &apos;localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend&apos; \</span><br><span class="line">-d &apos;&#123;&quot;kind&quot;:&quot;DeleteOptions&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;propagationPolicy&quot;:&quot;Foreground&quot;&#125;&apos; \</span><br><span class="line">-H &quot;Content-Type: application/json&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#从副本隔离pods</span><br><span class="line">可通过更改label从副本集的目标中删除Pod。此技术可用于从服务中删除pod以进行调试，数据恢复等。以这种方式删除的pod将自动替换</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#伸缩副本集</span><br><span class="line">只需更新副本集的 .spec.replicas 字段轻松伸缩副本集。副本集控制器确保具有匹配 label selector 所需数量的pod可用且可操作。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#作为水平pod自动伸缩目标的副本集</span><br><span class="line">Horizontal Pod Autoscalers(HPA)，意味着副本集可通过HPA自动伸缩。</span><br><span class="line">#栗子</span><br><span class="line">apiVersion: autoscaling/v1</span><br><span class="line">kind: HorizontalPodAutoscaler</span><br><span class="line">metadata:</span><br><span class="line">  name: frontend-scaler</span><br><span class="line">spec:</span><br><span class="line">  scaleTargetRef:</span><br><span class="line">    kind: ReplicaSet</span><br><span class="line">    name: frontend</span><br><span class="line">  minReplicas: 3</span><br><span class="line">  maxReplicas: 10</span><br><span class="line">  targetCPUUtilizationPercentage: 50</span><br><span class="line"></span><br><span class="line">kubectl create -f /path/xx/hpa.rs.yaml</span><br><span class="line">#此外，可使用kubectl命令来自动伸缩</span><br><span class="line">#kubectl autoscale rs frontend</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>替代副本集</strong></p>
<ul>
<li>Deployment(推荐)</li>
<li>Bare Pods</li>
<li>Job</li>
<li>DaemonSet</li>
</ul>
<p><br><br><br></p>
<h4 id="ReplicationController"><a href="#ReplicationController" class="headerlink" title="ReplicationController"></a>ReplicationController</h4><p><strong>注意：现在，配置副本集的推荐方法是使用部署。</strong></p>
<p>副本控制器确保一次运行指定数量的Pod副本。换言之，副本控制器确保一个Pod或一组同类Pod总是可用。</p>
<p><br><br><br></p>
<h4 id="Deployments"><a href="#Deployments" class="headerlink" title="Deployments"></a>Deployments</h4><p>部署控制器为Pod和ReplicaSet提供了声明性更新。<br>在部署对象中描述所需的状态，部署控制器以受控速率将实际状态更改为所需状态。你可定义部署来创建新的副本集，或删除现有的部署并使用新的部署收纳所有资源。<br>你不应该直接管理部署所拥有的副本集，应该通过操作部署对象来涵盖所有用例。</p>
<p><br></p>
<p><strong>栗子</strong><br>以下是部署的典型案例：</p>
<ul>
<li>创建部署来上线副本集</li>
<li>声明Pod的新状态</li>
<li>回滚到早期的部署版本</li>
<li>伸缩部署</li>
<li>暂定部署</li>
<li>使用部署的状态</li>
<li>清理旧的副本集</li>
</ul>
<p><br></p>
<p><strong>创建一个部署</strong><br>下面的栗子，创建一个3个Nginx pods的副本集:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-deployment</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">        image:</span> <span class="attr">nginx:1.7.9</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f ./nginx-deployment.yaml</span><br><span class="line"></span><br><span class="line">kubectl get deployment</span><br><span class="line">kubectl get rs</span><br><span class="line">kubectl get pod --show-labels</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>更新部署</strong><br>当且仅当部署的pod template发生更改时，才会触发部署更新上线。<br>假如我们要更新Nginx的版本为<code>1.9.1</code>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1</span><br><span class="line">deployment.extensions/nginx-deployment image updated</span><br><span class="line"></span><br><span class="line">#或者</span><br><span class="line">kubectl edit deployment/nginx-deployment</span><br><span class="line">deployment.extensions/nginx-deployment edited</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#查看上线状态</span><br><span class="line">kubectl rollout status deployment/nginx-deployment</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 old replicas are pending termination...</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 old replicas are pending termination...</span><br><span class="line">deployment &quot;nginx-deployment&quot; successfully rolled out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#新旧副本集副本数</span><br><span class="line">kubectl get rs</span><br><span class="line">NAME                          DESIRED   CURRENT   READY     AGE</span><br><span class="line">nginx-deployment-67594d6bf6   0         0         0         16m</span><br><span class="line">nginx-deployment-d78fcfc84    3         3         3         3m</span><br></pre></td></tr></table></figure>
<p>部署可以确保在更新时只有一定数量的Pod可能会关闭。默认情况下，它确保最大不可用率25%。<br>部署确保在所需数量的Pod之上只能创建一定数量的Pod。默认情况下，它确保比最大数多25%。<br>例如，如果仔细查看上面的部署，你将看到它首先创建了一个新的Pod，然后删除了一些旧的Pod并创建新的Pod。在有足够数量的新Pod出现之前，它不会杀死旧的Pod，并且在足够数量的旧Pod被杀死之前不会创建新的Pod。</p>
<p>通常不鼓励进行<code>label selector</code>的更改，建议你事先规划好<code>selector</code>。</p>
<p><br></p>
<p><strong>回滚(rolling back)部署</strong><br>有时可能需要回滚部署，当部署不稳定时，如崩溃循环(crash looping)。默认情况下，所有的部署上线历史都保留在系统中，以便可以随时回滚。</p>
<p>假设我之间将<code>nginx:1.7.1</code>更新到<code>nginx:1.9.1</code>的时候错误的写成了<code>nginx:1.91</code>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">kubectl set image deployment/nginx-deployment nginx=nginx:1.91</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#上线就会卡在此处</span><br><span class="line">kubectl rollout status deployments nginx-deployment</span><br><span class="line">Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...</span><br><span class="line">error: deployment &quot;nginx-deployment&quot; exceeded its progress deadline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#查看容器错误，它会报镜像拉取错误</span><br><span class="line">kubectl get pod</span><br><span class="line">nginx-deployment-58c7645486-s5t6t   0/1       ImagePullBackOff   0          3m        &lt;none&gt;        node</span><br><span class="line">#UI里面的报错</span><br><span class="line">#Failed to pull image &quot;nginx:1.91&quot;: rpc error: code = Unknown desc = manifest for docker.io/nginx:1.91 not found</span><br></pre></td></tr></table></figure>
<p>部署控制器将自动停止错误的<code>rollout</code>，并将停止扩展新的副本集。这取决于滚动升级的参数(<code>maxUnavailable</code>)。默认情况下，k8s将值设置为1，将<code>.spec.replicas</code>设置为1，因此你无需关心设置这些参数。你的部署可能具有100%的不可用性。</p>
<p>要修复它，你需要回滚到先前稳定的部署版本。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">#检查上线历史</span><br><span class="line">kubectl rollout history deployment/nginx-deployment</span><br><span class="line">deployments &quot;nginx-deployment&quot;</span><br><span class="line">REVISION    CHANGE-CAUSE</span><br><span class="line">1           kubectl create -f ./nginx-deployment.yaml --record</span><br><span class="line">2           kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1</span><br><span class="line">3           kubectl set image deployment/nginx-deployment nginx=nginx:1.91</span><br><span class="line"></span><br><span class="line">#查看某个上线历史</span><br><span class="line">rollout history deployment/nginx-deployment --revision=2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#回滚</span><br><span class="line"></span><br><span class="line">#回滚到前一个版本</span><br><span class="line">kubectl rollout undo deployment/nginx-deployment</span><br><span class="line">deployment.extensions/nginx-deployment</span><br><span class="line"></span><br><span class="line">#回滚到指定版本</span><br><span class="line">kubectl rollout undo deployment/nginx-deployment --to-revision=2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#查看事件</span><br><span class="line">kubectl describe deployment/nginx-deployment</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason              Age                From                   Message</span><br><span class="line">  ----    ------              ----               ----                   -------</span><br><span class="line">  Normal  DeploymentRollback  2m                 deployment-controller  Rolled back deployment &quot;nginx-deployment&quot; to revision 3</span><br><span class="line">  Normal  ScalingReplicaSet   2m                 deployment-controller  Scaled down replica set nginx-deployment-58c7645486 to 0</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>伸缩副本</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#扩展部署</span><br><span class="line">kubectl scale deployment nginx-deployment --replicas=5</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#水平伸缩</span><br><span class="line">kubectl autoscale deployment nginx-deployment --min=3 --max=6 --cpu-percent=80</span><br><span class="line"></span><br><span class="line">#查看</span><br><span class="line">kubectl get horizontalpodautoscaler.autoscaling</span><br><span class="line">NAME               REFERENCE                     TARGETS         MINPODS   MAXPODS   REPLICAS   AGE</span><br><span class="line">nginx-deployment   Deployment/nginx-deployment   &lt;unknown&gt;/80%   3         6         5          1m</span><br></pre></td></tr></table></figure>
<p><strong>比例伸缩(proportional scaling)</strong><br>滚动升级部署支持同时运行多个版本的应用程序。当你或自动伸缩器正在上线滚动更新的部署时，部署控制器将平衡现有活动的副本集中的其它副本，以降低风险。这称为比例缩放。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">kubectl get deploy</span><br><span class="line">NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx-deployment   5         5         5            5           1h</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#更新一个错误镜像，它会卡住</span><br><span class="line">kubectl set image deploy/nginx-deployment nginx=nginx:sometag</span><br><span class="line"></span><br><span class="line">kubectl get rs -o wide</span><br><span class="line">NAME                         DESIRED   CURRENT   READY     AGE       CONTAINERS   IMAGES          SELECTOR</span><br><span class="line">nginx-deployment-895bd59bc   3         3         0         1m        nginx        nginx:sometag   app=nginx,pod-template-hash=451681567</span><br><span class="line">nginx-deployment-d78fcfc84   5         5         5         1h        nginx        nginx:1.7.1     app=nginx,pod-template-hash=834979740</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl get deploy -o wide</span><br><span class="line">NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE       CONTAINERS   IMAGES          SELECTOR</span><br><span class="line">nginx-deployment   6         8         3            5           1h        nginx        nginx:sometag   app=nginx</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>暂停和恢复部署</strong><br>你可以在触发一个或多个更新之前暂停(pause)部署，然后恢复(resume)它。这允许你在暂停和恢复之间应用多个修复，而不会触发不必要的上线。<br>注意： 在恢复暂停部署之前，无法执行回滚操作。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#暂停</span><br><span class="line">kubectl rollout pause deployment/nginx-deployment</span><br><span class="line">deployment.extensions/nginx-deployment paused</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl set image deploy/nginx-deployment nginx=nginx:1.9.1</span><br><span class="line">deployment.extensions/nginx-deployment image updated</span><br><span class="line"></span><br><span class="line">kubectl set resources deployment nginx-deployment -c=nginx --limits=cpu=200m,memory=128Mi</span><br><span class="line">deployment.extensions/nginx-deployment resource requirements updated</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#恢复</span><br><span class="line">kubectl rollout resume deployment/nginx-deployment</span><br><span class="line">deployment.extensions/nginx-deployment resumed</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>部署状态</strong><br>部署在其生命周期内会进入各种状态–<code>kubectl rollout status</code></p>
<ul>
<li><p>Progessing Deployment</p>
<ul>
<li>部署创建一个新的副本集</li>
<li>部署伸缩到新的/旧的副本集</li>
<li>新的Pod可用</li>
</ul>
</li>
<li><p>Complete Deployment</p>
<ul>
<li>所有与部署关联的副本都已完成</li>
<li>所有与部署关联的副本都可用</li>
<li>没有正在运行的旧的部署副本</li>
</ul>
</li>
<li><p>Failed Deployment</p>
<ul>
<li>配额不足</li>
<li>准备探针失败</li>
<li>镜像拉取失败</li>
<li>权限不足</li>
<li>限制范围</li>
<li>应用程序运行时配置错误</li>
</ul>
</li>
<li><p>Operating on a failed deployment</p>
</li>
</ul>
<p><br></p>
<p><strong>Clean up Policy</strong><br>可在部署中设置<code>.spec.revisionHistoryLimit</code>字段来指定需要保留的旧副本集数。其余的将在后台被垃圾回收，默认为10。</p>
<p><strong>注意：</strong>将此字段设置为0会导致清理部署的所有历史记录，从而部署将无法回滚。</p>
<p><br></p>
<p><strong>Deployment Spec</strong><br>与其它k8s配置一样，Deployment需要<code>apiVersion</code>, <code>kind</code>, <code>metadata</code>字段。但部署还需要<code>.spec</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">#pod template</span><br><span class="line">#必填字段</span><br><span class="line">.spec.template</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#Replicas</span><br><span class="line">.spec.replicas</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#Selector</span><br><span class="line">#它必须匹配.spec.template.metadata.labels，否则会被API拒绝</span><br><span class="line">.spec.selector</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#Strategy</span><br><span class="line">.spec.strategy</span><br><span class="line"></span><br><span class="line">#Recreate deployment</span><br><span class="line">.spec.strategy.type==Recreate</span><br><span class="line"></span><br><span class="line">#Rolling Update Deployment</span><br><span class="line">.spce.stratefy.type==RollingUpdate</span><br><span class="line">#Max Unavailable</span><br><span class="line">.spec.strategy.rollingUpdate.maxUnavailable</span><br><span class="line">#Max Surge</span><br><span class="line">.specstrategy.rollingUpdate.maxSurge</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#Progress Deadline Seconds</span><br><span class="line">.spec.progressDeadlineSeconds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#Min Ready Seconds</span><br><span class="line">.spec.minReadySeconds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#Rollback To</span><br><span class="line">.spec.rollbackTo</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#Revision History Limit</span><br><span class="line">.spec.revisionHistoryLimit</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#Paused</span><br><span class="line">.spec.paused</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>替代方案</strong></p>
<ul>
<li>kubectl rolling update<br><code>kubetl rolling update</code>以类似的方式更新Pod和副本集控制器。但建议使用部署，因为它是声明性的。</li>
</ul>
<p><br><br><br></p>
<h4 id="StatefulSets"><a href="#StatefulSets" class="headerlink" title="StatefulSets"></a>StatefulSets</h4><p><code>StatefulSet</code>是用于管理有状态应用程序的工作负载的API对象。<br><strong>Note: StatefulSets are stable (GA) in 1.9.</strong></p>
<p>管理一组Pod的部署和伸缩，并提供有关这些Pod的序列和唯一性的保证。<br>与部署类似，有状态集管理基于相同容器规范(spec)的Pod；与部署不同，有状态集为其每个Pod维护一个粘性(sticky)标识。这些Pod根据相同的规范创建，但不可互换，每个Pod都有一个持久的标识符，它可在任何重新调度时保留。<br>有状态集与任何其它控制器相同的模式运行。你在有状态集对象中定义所需的状态，有状态集控制器进行任何必要的更新以从当前状态到达期望状态。</p>
<p><br></p>
<p><strong>使用有状态集</strong><br>有状态集对于需要以下一个或多个应用程序非常有用：</p>
<ul>
<li>稳定，唯一的网络标识</li>
<li>稳定，持久存储</li>
<li>有序，优雅的部署和伸缩</li>
<li>有序，优雅的删除和终止</li>
<li>有序，自动的滚动更新</li>
</ul>
<p>如果应用程序不需要任何稳定标识或有序部署、删除、伸缩，则应该使用提供一组无状态副本的控制器来部署你的应用程序。如部署或副本集这样的控制器可能更适合无状态需求。</p>
<p><br></p>
<p><strong>局限(limitations)</strong></p>
<ul>
<li>k8s v1.9+</li>
<li>给定Pod的存储必须由<code>PersistentVolume Provisioner</code>根据请求的存储类进行配置，或由管理员预先配置</li>
<li>删除/伸缩有状态集将不会删除与有状态集相关联的卷。这是为了确保数据安</li>
<li>有状态集目前要求<code>headless service</code>负责Pod的网络身份，你有责任创建此服务</li>
</ul>
<p><br></p>
<p><strong>组件(components)</strong></p>
<ul>
<li><code>headless service</code>，用于控制网络域</li>
<li><code>StatefulSet</code></li>
<li><code>volumeClaimTemplates</code>，使用持久化卷提供稳定存储</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">  - port:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">  clusterIP:</span> <span class="string">None</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">nginx</span> <span class="comment"># has to match .spec.template.metadata.labels</span></span><br><span class="line"><span class="attr">  serviceName:</span> <span class="string">"nginx"</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span> <span class="comment"># by default is 1</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">nginx</span> <span class="comment"># has to match .spec.selector.matchLabels</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      terminationGracePeriodSeconds:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">k8s.gcr.io/nginx-slim:0.8</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">www</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/usr/share/nginx/html</span></span><br><span class="line"><span class="attr">  volumeClaimTemplates:</span></span><br><span class="line"><span class="attr">  - metadata:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">www</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      accessModes:</span> <span class="string">[</span> <span class="string">"ReadWriteOnce"</span> <span class="string">]</span></span><br><span class="line"><span class="attr">      storageClassName:</span> <span class="string">"my-storage-class"</span></span><br><span class="line"><span class="attr">      resources:</span></span><br><span class="line"><span class="attr">        requests:</span></span><br><span class="line"><span class="attr">          storage:</span> <span class="number">1</span><span class="string">Gi</span></span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>Pod Selector</strong><br>必须设置有状态集的<code>.spec.selector</code>字段以匹配<code>.spec.template.metadata.labels</code>的标签。</p>
<p><br></p>
<p><strong>Pod Identity</strong><br>有状态集Pod有一个唯一的标识，由序数、稳定的网络表示和稳定的网络存储组成。</p>
<ul>
<li><p>Ordinal Index<br>对于有多个副本的有状态集，有状态集中的每个Pod将被分配一个唯一的整数序数(ordinal)，从0–(N-1)。</p>
</li>
<li><p>Stable Network ID<br>有状态集中的每个Pod都从有状态集的名称和Pod的序号中派生其主机名。构造的主机名的模式时<code>$(statefulset name)-$(ordinal)</code>。</p>
</li>
<li><p>Stable Storage<br>k8s为每个<code>VolumeClaimTemplate</code>创建一个<code>PersistentVolume</code>。</p>
</li>
<li><p>Pod Name Label<br>当有状态集控制器创建Pod时，它会添加一个标签<code>statefulset.kubernetes.io/pod-name</code>，该标签设置为Pod的名称。该标签允许你将服务附加到有状态集中的特定Pod。</p>
</li>
</ul>
<p><br></p>
<p><strong>部署和伸缩保证(guarantees)</strong></p>
<ul>
<li>对于有多个副本的有状态集，当Pod被部署时，它们按顺序从{0…N-1}被创建</li>
<li>但Pod被删除，它们将以{N-1…0}的相反顺序终止</li>
<li>在伸缩操作应用于Pod之前，所有的前置任务(predecessors)必须是Running和Ready</li>
<li>在终止Pod之前，其所有后继者(successors)必须完全关闭</li>
</ul>
<p>有状态集不应该指定<code>pod.Spec.TerminationGracePeriodSeconds</code>为0，这很不安全，强烈建议不要这么做。</p>
<p>k8s v1.7+，有状态集允许你放宽Pod管理策略的排序保证，同时通过其<code>.spec.podManagementPolicy</code>字段保留期唯一性和身份保证。<br><code>OrderedReady</code> pod管理是有状态集的默认设置。<br><code>Parallel</code> pod管理告诉有状态集控制器并行(parallel)启动或终止所有Pod，并且在启动或终止另一个Pod之前不等待Pod变为Running、Ready或完全终止。</p>
<p><br></p>
<p><strong>更新策略</strong><br>有状态集的<code>.spec.updateStrategy</code>字段允许你为有状态集中的Pod配置和禁用容器、标签、资源请求/限制、注释的自动更新。</p>
<p><br><br><br></p>
<h4 id="DaemonSet"><a href="#DaemonSet" class="headerlink" title="DaemonSet"></a>DaemonSet</h4><p>守护进程集确保所有(或某些)节点运行Pod的副本。随着节点添加到集群中，会将Pod添加到集群中。随着节点从集群中移除，Pod将被垃圾回收。删除一个守护进程集会清除它创建的Pod。</p>
<p>守护进程集的一些典型用法：</p>
<ul>
<li>在每个节点上运行集群存储守护进程</li>
<li>在每个节点上运行日志收集守护进程</li>
<li>在每个节点上运行一个节点监控守护进程</li>
</ul>
<p><br></p>
<p><strong>Writing a DaemonSet Spec</strong></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">fluentd-elasticsearch</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">fluentd-logging</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">fluentd-elasticsearch</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">fluentd-elasticsearch</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      tolerations:</span></span><br><span class="line"><span class="attr">      - key:</span> <span class="string">node-role.kubernetes.io/master</span></span><br><span class="line"><span class="attr">        effect:</span> <span class="string">NoSchedule</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">fluentd-elasticsearch</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">k8s.gcr.io/fluentd-elasticsearch:1.20</span></span><br><span class="line"><span class="attr">        resources:</span></span><br><span class="line"><span class="attr">          limits:</span></span><br><span class="line"><span class="attr">            memory:</span> <span class="number">200</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">          requests:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line"><span class="attr">            memory:</span> <span class="number">200</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">varlog</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/var/log</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">varlibdockercontainers</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/var/lib/docker/containers</span></span><br><span class="line"><span class="attr">          readOnly:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">      terminationGracePeriodSeconds:</span> <span class="number">30</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">varlog</span></span><br><span class="line"><span class="attr">        hostPath:</span></span><br><span class="line"><span class="attr">          path:</span> <span class="string">/var/log</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">varlibdockercontainers</span></span><br><span class="line"><span class="attr">        hostPath:</span></span><br><span class="line"><span class="attr">          path:</span> <span class="string">/var/lib/docker/containers</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#创建守护进程集</span><br><span class="line">kubectl create -f ./daemonset.yaml</span><br></pre></td></tr></table></figure>
<ul>
<li><p>Required Fields<br>与其它k8s配置一样，守护进程集需要<code>apiVersion</code>, <code>kind</code>, <code>metadata</code>, <code>.spec</code>字段。</p>
</li>
<li><p>Pod Template<br><code>.spec.template</code>是<code>.spec</code>的必要字段。<br>守护进程集中的人Pod模板必须要<code>RestartPolicy: Always(默认)</code>。</p>
</li>
<li><p>Pod Selector</p>
</li>
<li><p>仅在某些节点上运行Pod<br>如果指定了<code>.spec.template.spce.nodeSelector</code>，则守护进程控制器将在<code>node selector</code>匹配的节点上创建Pod。同样，如果指定了<code>.spec.template.spec.affinity</code>，则守护进程控制器将在与该节点关联匹配的节点上创建Pod。<br>如果未指定任何一个，则守护进程控制器将在所有节点上创建Pod。</p>
</li>
</ul>
<p><br></p>
<p><strong>Daemon Pods如何调度</strong></p>
<ul>
<li><p>由守护进程集控制器调度（默认）<br>通常，Pod运行的机器由k8s调度程序选择。然而，由守护进程集控制器创建的Pod已经选择了机器(<code>.spec.nodeName</code>)。</p>
</li>
<li><p>由默认调度器调度<br>功能阶段： k8s v1.11 <code>alpha</code><br>守护进程集确保所有符合条件的节点都运行Pod的副本。</p>
</li>
<li><p>Taints and Tolerations</p>
</li>
</ul>
<p><br></p>
<p><strong>Daemon Pods间通信</strong><br>守护进程集中Pod通信的一些可能模式：</p>
<ul>
<li>Push</li>
<li>NodeIP and Known Port</li>
<li>DNS</li>
<li>Service</li>
</ul>
<p><br></p>
<p><strong>更新DaemonSet</strong><br>如果更改了节点标签，守护进程集会立即将Pod添加到新匹配的节点，并从新匹配的节点中删除Pod。<br>可以修改守护进程集创建的Pod。然而，Pod不允许更新所有字段。同样，守护进程集控制器在下次创建节点时使用原始模板。<br>你也可以删除守护进程集，若指定了<code>--cascade=false</code>，则会在节点上保留Pod。</p>
<p><br></p>
<p><strong>守护进程集的替代方案</strong></p>
<ul>
<li>Init Scripts</li>
<li>Bare Pods</li>
<li>Static Pods</li>
<li>Deployments</li>
</ul>
<p><br><br><br></p>
<h4 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h4><p>Garbage Collection</p>
<p>k8s垃圾回收的作用是删除曾经拥有所有者，但不再拥有所有者的某些对象。</p>
<p><br></p>
<p><strong>Owners and dependents</strong><br>一些k8s对象是其它对象的所有者。如副本集是一组Pod的所有者。拥有的对象称为所有者的依赖项(dependents)。每个依赖对象都有一个<code>metadata.ownerReferences</code>字段来指向所有者。</p>
<p><br></p>
<p><strong>控制垃圾回收器如何删除依赖项</strong><br>删除对象时，可以指定是否也自动删除对象的依赖项。<br>删除对象而不自动删除依赖项，则称依赖项为孤立对象(orphaned)。<br>自动删除依赖项被称为级联删除(cascading deletion)，这有两种级联删除模式：</p>
<ul>
<li>Foreground</li>
<li>Background</li>
</ul>
<p><br></p>
<p><strong>设置级联删除策略</strong><br>删除对象时，设置<code>deleteOptions</code>参数的<code>propagationPolicy</code>字段来控制级联删除策略。</p>
<p><br><br><br></p>
<h4 id="Jobs"><a href="#Jobs" class="headerlink" title="Jobs"></a>Jobs</h4><p>Jobs - Run to Completion</p>
<p>作业创建一个或多个Pod，并确保指定数量的Pod成功终止。随着Pod成功完成，作业跟踪也成功完成。删除作业将清除它创建的Pod。<br>作业还可用于并行运行多个Pod。</p>
<p><br></p>
<p><strong>栗子</strong></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">pi</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">pi</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">perl</span></span><br><span class="line"><span class="attr">        command:</span> <span class="string">["perl",</span>  <span class="string">"-Mbignum=bpi"</span><span class="string">,</span> <span class="string">"-wle"</span><span class="string">,</span> <span class="string">"print bpi(2000)"</span><span class="string">]</span></span><br><span class="line"><span class="attr">      restartPolicy:</span> <span class="string">Never</span></span><br><span class="line"><span class="attr">  backoffLimit:</span> <span class="number">4</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f ./job.yaml</span><br><span class="line">job.batch/pi created</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl get job</span><br><span class="line">kubectl describe job/pi</span><br><span class="line">kubectl get pod</span><br><span class="line"></span><br><span class="line">kubectl logs pi-xxx</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>Job Spec</strong><br>与其它k8s配置一样，Job也需要<code>apiVersion</code>, <code>kind</code>, <code>metadata</code>, <code>.spec</code>字段。</p>
<ul>
<li><p>Pod Template<br><code>.spec.template</code>是<code>.spce</code>字段的必要项。</p>
</li>
<li><p>Pod Selector<br><code>.spec.selector</code>字段可选。</p>
</li>
<li><p>Parallel Jobs: 有三种主要类型作业</p>
<ul>
<li>Non-parallel Jobs<ul>
<li>通常指启动一个Pod，除非Pod失败</li>
<li>Pod成功终止后，作业即告完成</li>
</ul>
</li>
<li>Parallel Jobs with a fixed completion count<ul>
<li>为<code>.spec.completions</code>指定非零正值</li>
<li>当1-<code>.spec.completions</code>范围内的每个值都有一个成功的Pod时，作业就完成了</li>
<li>尚未实施，每个Pod都传递了1-<code>.spec.completions</code>范围内不同的索引</li>
</ul>
</li>
<li>Parallel Jobs with a work queue<ul>
<li>每个Pod独立地确定是否所有对等都完成，因此整个Job完成</li>
<li>当任何Pod成功终止，不会创建新的Pod</li>
<li>一旦至少一个Pod成功终止并且所有Pod终止，则作业成功完成</li>
<li>一旦任意Pod已成功退出，其它任何Pod都不应该做任何工作或输出</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>控制并行</strong><br>Controlling Parallelism</p>
<p>请求的并行性(<code>.spec.parallelism</code>)可以设置为任何非负值。如果未指定，则默认为1.如果指定为0，则作业将暂停，直至其增加。<br>由于各种原因，实际并行性(在任何时刻运行的Pod数量)可能多于或少于请求的并行度：</p>
<ul>
<li>对于固定完成计数的作业，并行运行的实际Pod数不会超过剩余的Pod数</li>
<li>对于工作多列作业，任何Pod成功后都不会启动新的Pod，但允许剩余的Pod完成</li>
<li>如果控制器没有时间做出反应</li>
<li>如果控制器因任何原因无法创建Pod</li>
<li>由于同一作业中过多的先前Pod故障，控制器可能会限制新的Pod创建</li>
<li>当Pod正常关闭时，停止需要一些时间</li>
</ul>
<p><br></p>
<p><strong>处理Pod和Container失败</strong><br>Pod中的容器可能由于多种原因而失败，如果发生此情况，并且<code>.spec.template.spec.restartPolicy = &quot;OnFailure&quot;</code>，那么Pod会留在节点上，但容器会重新运行。因此，你的程序需要在本地处理此情况，或指定<code>.spec.template.spec.restartPolicy = &quot;Never&quot;</code>。</p>
<p>一个完整的Pod也可能由于多种原因而失败。当Pod失败时，作业控制器启动一个新的Pod。因此，你的程序需要在新Pod重启时处理此情况。</p>
<p><br></p>
<p><strong>Pod Backoff failure policy</strong><br>在某些情况下，由于配置中的逻辑错误等原因，你需要在重试一段时间后使作业失败。为此，可设置<code>.spec.backoffLimit</code>将作为视为失败前的重试次数。默认值为6s。与作业关联的失败的Pod由作业控制器重新创建，指数退避延迟(10s, 20s, 40s…)，上限6分钟。如果在作业的下一次状态检查之前没有出现新的故障Pod，则重置退避计数。</p>
<p><br></p>
<p><strong>作业终止和清理</strong><br>Job Termination and Cleanup</p>
<p>作业完成后，不会再创建Pod，也不会删除Pod。保持它们可让你仍然能查看已完成的Pod的日志以检查error, warning, 或其它诊断性输出。作业对象在完成后也会保留，以便可查看其状态。在注意到其状态后，用户可删除旧的作业。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#一并删除作业创建的Pod</span><br><span class="line">kubectl delete jobs/xxx</span><br><span class="line"></span><br><span class="line">#不删除作业创建的Pod</span><br><span class="line">kubectl delete jobs/xxx --</span><br></pre></td></tr></table></figure>
<p>默认情况下，除非Pod失败，否则作业将不间断运行，此时作业将延迟到上述的<code>.spec.backoffLimit</code>。终止作业的另一种方法是设置活动截止日期，通过设置<code>.spec.activateDeadlineSeconds</code>字段来执行此操作。请注意，作业的<code>.spec.activateDeadlineSeconds</code>优先于<code>.spec.backoffLimit</code>。因此，重试一个或多个失败的Pod的作业在达到<code>activeDeadlineSeconds</code>指定的时间限制后将不会重置其它Pod，即使尚未达到<code>backoffLimit</code>也是如此。</p>
<p><br></p>
<p><strong>作业模式</strong><br>Job Patterns</p>
<p>作业对象可用于支持Pod的可靠并行执行，它不是为了支持紧密通信的并行进程而设计。<br>在复杂系统中，可能存在多组不同的工作项。这里只考虑一组工作项——批处理作业</p>
<p>并行计算有几种不同的模式，每种模式都有有点和缺点：</p>
<ul>
<li>一个工作项一个作业对象 vs 所有工作项一个作业对象</li>
<li>创建的Pod数等于工作项数 vs 每个Pod可以处理多个工作项</li>
<li>多个方法使用一个工作队列</li>
</ul>
<p><br></p>
<p><strong>高级用法</strong><br>Advanced Usage</p>
<ul>
<li>指定自己的Pod selector<br>通常，创建作业对象时，不会指定<code>.spec.selector</code>。系统默认在创建作业时添加此字段。然而，在某些情况下，你可能需要设置它。这样做的时候要非常小心，如果你指定的label selector不是该作业的Pod所独有，并且与不想关的Pod匹配，则可能会删除不相关作业的Pod。如果选择了non-unique selector，则其它控制器及其Pod也可能以不可预测的方式进行。在指定<code>.spec.selector</code>时，k8s不会阻止你犯错误。</li>
</ul>
<p><br></p>
<p><strong>替代方案</strong><br>Alternatives</p>
<ul>
<li>Bare Pods</li>
<li>Replication Controller</li>
<li>Single Job starts Controller Pod</li>
</ul>
<p><br></p>
<p><strong>Cron Jobs</strong><br>在指定的时间/日期创建作业。</p>
<p><br><br><br></p>
<h4 id="CronJob"><a href="#CronJob" class="headerlink" title="CronJob"></a>CronJob</h4><p>Cron Job基于时间调度创建作业。<br>一个定时任务对象类似于crontab中的一行。它以给定的时间周期性运行作业。</p>
<p><strong>注意： 所有定时作业调度， 时间以UTC表示。</strong></p>
<p><br></p>
<p><strong>定时作业局限</strong><br>Cron Job Limitations</p>
<p>定时作业在其计划的每个执行时间创建一个作业对象。<br>如果<code>startingDeadlineSeconds</code>被设置为较大值或未设置(默认值)，并且<code>concurrencyPolicy</code>设置为Allow，则作业将始终至少运行一次。<br>如果设置了<code>startDeadlineSeconds</code>字段，则控制器会计算从<code>startingDeadlineSeconds</code>的值到现在发生的错过的作业数，而不是从上一个计划时间到现在。<br>如果定时作业未能在其预定时间创建，则将其视为未命中。</p>
<p>定时作业仅负责创建与其计划相匹配的作业，而作业则负责管理它所代表的Pod。</p>
<p><br><br><br><br><br></p>
<h2 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h2><p>Configuration</p>
<p><br></p>
<h3 id="配置最佳实践"><a href="#配置最佳实践" class="headerlink" title="配置最佳实践"></a>配置最佳实践</h3><p>Configuration Best Practices</p>
<p><br></p>
<h4 id="一般配置技巧"><a href="#一般配置技巧" class="headerlink" title="一般配置技巧"></a>一般配置技巧</h4><p>General Configuration Tips</p>
<ul>
<li>定义配置时，请指定最新的稳定的API版本</li>
<li>在推送到集群之前，配置文件应存储在版本控制系统中。这允许你在必要时快速回滚配置，有助于集群重建和恢复</li>
<li>使用YMAL而不是JSON来编写配置文件，YAML格式更用户友好</li>
<li>只要有意义，就将相关对象分组到一个文件中。管理一个文件比管理一堆文件更便捷</li>
<li>可以在目录上调用许多<code>kubectl</code>命令。例如，你可在配置文件目录上调用<code>kubectl create</code></li>
<li>不要不必要地指定默认值</li>
<li>将对象描述写在注释中，以便更好进行内省</li>
</ul>
<p><br><br><br></p>
<h4 id="Naked-Pod-vs-副本集，部署和作业"><a href="#Naked-Pod-vs-副本集，部署和作业" class="headerlink" title="Naked Pod vs 副本集，部署和作业"></a>Naked Pod vs 副本集，部署和作业</h4><p>“Naked” Pods vs ReplicaSets, Deployments, and Jobs</p>
<ul>
<li>不要使用Naked Pods(即未绑定到副本集或部署的Pod)<br>如果节点发生故障，裸Pod将不会被重新调度。</li>
</ul>
<p><br><br><br></p>
<h4 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h4><p>Service</p>
<ul>
<li><p>在相应的后端工作负载(部署或副本集)访问它之前创建服务<br>当k8s启动容器时，它提供指向启动容器时正在运行的所有服务的环境变量。</p>
</li>
<li><p>除非绝对必要，否则不要为Pod指定hostPort<br>将Pod绑定到hostPort时，它会限制Pod可调度的位置数。因为每个<code>hostIP, hostPort, protocol</code>的组合必须是独特的。如果没有指定hostIp和protocol，k8s将使用<code>0.0.0.0</code>作为默认的hostIP，使用TCP作为默认协议。</p>
</li>
</ul>
<p>如果你只需要访问端口以进行调试，可使用<code>apiserver proxy</code>或<code>kubectl port-forward</code>。<br>如果你需要公开节点上Pod的端口，考虑使用<code>NodePort</code>服务。</p>
<ul>
<li>避免使用hostNetwork， 原因与hostPort类似</li>
<li>当不需要<code>kube-proxy</code>负载均衡时，使用 headless Services可轻松服务发现</li>
</ul>
<p><br><br><br></p>
<h4 id="使用标签"><a href="#使用标签" class="headerlink" title="使用标签"></a>使用标签</h4><p>Using Labels</p>
<ul>
<li>为你的应用程序或部署定义和使用标签<br>你可使用这些标签为其它资源筛选合适的Pod</li>
</ul>
<p><br><br><br></p>
<h4 id="容器镜像"><a href="#容器镜像" class="headerlink" title="容器镜像"></a>容器镜像</h4><p>Container Images</p>
<ul>
<li>默认的镜像拉取策略。对于容器是<code>ifNotPresent</code>，kubelet只有在本地镜像不存在时才拉取镜像。如果希望每次k8s启动容器时都拉取镜像，请指定<code>imagePullPolicy: Always</code>。<br>一个已弃用的替代方案。设置k8s总是拉取镜像的<code>:latest</code>标记，它会隐式地将<code>imagePullPolicy</code>设置为<code>Always</code>。</li>
</ul>
<p><strong>注意： 在生产环境中部署容器时，你应该避免使用<code>:latest</code>标记，因为这使得正在运行的镜像版本难以回滚。</strong><br>如果镜像使用<code>:latest</code>标记，回滚的话其实需要回滚代码，然后打包上线，然后触发动态更新，之后就还原成了之前的版本。这样确实要复杂很缓慢一些。</p>
<ul>
<li>确保容器使用使用相同版本的镜像</li>
</ul>
<p><br><br><br></p>
<h4 id="使用kubectl"><a href="#使用kubectl" class="headerlink" title="使用kubectl"></a>使用kubectl</h4><ul>
<li><p>使用<code>kubectl apply -f &lt;directory&gt;</code> 或 <code>kubectl create -f &lt;directory&gt;</code><br>它在此目录中所有<code>.yaml</code>, <code>.yml</code>, <code>.json</code>文件汇总寻找k8s配置配置文件，并将其传递给kubectl。</p>
</li>
<li><p>使用label selectors进行<code>get</code>和<code>delete</code>操作，而不是特定的对象名称</p>
</li>
<li>使用<code>kubectl run</code>和<code>kubectl expose</code>快速创建单容器部署和服务</li>
</ul>
<p><br><br><br></p>
<h3 id="管理容器的计算资源"><a href="#管理容器的计算资源" class="headerlink" title="管理容器的计算资源"></a>管理容器的计算资源</h3><p>Managing Compute Resources for Containers</p>
<p>指定Pod时，可以选择指定每个容器需要多少CPU和MEM。当容器指定了请求(requests)的资源时，调度器可以更好地决定将Pod放在哪个节点上。当容器指定了限制(limit)时，可以以指定的方式处理节点上资源的争用。</p>
<p><br><br><br></p>
<h4 id="资源类型"><a href="#资源类型" class="headerlink" title="资源类型"></a>资源类型</h4><p>Resource types</p>
<p>CPU和MEM都是资源类型。资源类型具有基本单元(unix)。CPU以核(<code>cores</code>)为指定单位，MEM以字节(<code>Byte</code>)为指定单位。<br>CPU和MEM统称为计算资源，或资源。计算资源是可以请求，分配和使用的可测量数据。它们与API资源不同。API资源(如Pod和Service)，是可通过k8s APIserver读取和修改的对象。</p>
<p><br><br><br></p>
<h4 id="资源的请求和限制"><a href="#资源的请求和限制" class="headerlink" title="资源的请求和限制"></a>资源的请求和限制</h4><p>Resource requests and limits of Pod and Container</p>
<p>Pod中的容器都可指定一个或多个限制：</p>
<ul>
<li><code>spec.containers[].resources.limits.cpu</code></li>
<li><code>spec.containers[].resources.limits.memory</code></li>
<li><code>spec.containers[].resources.requests.cpu</code></li>
<li><code>spec.containers[].resources.requests.memory</code></li>
</ul>
<p>虽然只能在单独的容器上指定请求和限制，但是讨论Pod资源的请求和限制很方便。特定资源类型的Pod资源 请求/限制 是Pod中每个容器的该类型的资源 请求/限制 的总和。</p>
<p><br><br><br></p>
<h4 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h4><p>Meaning of CPU</p>
<p>CPU资源的限制和请求以CPU单位进行测量。在k8s中，1 cpu等于：</p>
<ul>
<li>1 AWS vCPU</li>
<li>1 GCP Core</li>
<li>1 Azure vCore</li>
<li>1 IBM vCPU</li>
<li>1 Hyperthread on a bare-metal Intel processor with Hyperthreading</li>
</ul>
<p>允许分数请求。如<code>spec.containers[].resources.requests.cpu: 0.5</code>。表达式<code>0.1</code>相当于表达式<code>100m</code>。具有小数点的请求资源(如<code>0.1</code>)由API转换为<code>100m</code>，不允许精度小于<code>1m</code>。<br>始终要求CPU作为绝对数量，而不是相对数量。因此，<code>0.1</code>单元对于单核，双核，八核机器上的CPU资源时相同的。</p>
<p><br><br><br></p>
<h4 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h4><p>Meaning of memory</p>
<p>内存的限制和请求以字节为单位。<br>你可使用以下后缀来表示整数内存: <code>E, P, T, G, M, K</code>；<br>你还还可以使用2的幂等: <code>Ei, Pi, Ti, Gi, Mi, Ki</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#相同值的不同表达</span><br><span class="line">128974848</span><br><span class="line">129e6</span><br><span class="line">129M</span><br><span class="line">123Mi</span><br></pre></td></tr></table></figure>
<p>栗子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: frontend</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: db</span><br><span class="line">    image: mysql</span><br><span class="line">    env:</span><br><span class="line">    - name: MYSQL_ROOT_PASSWORD</span><br><span class="line">      value: &quot;password&quot;</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        memory: &quot;64Mi&quot;</span><br><span class="line">        cpu: &quot;250m&quot;</span><br><span class="line">      limits:</span><br><span class="line">        memory: &quot;128Mi&quot;</span><br><span class="line">        cpu: &quot;500m&quot;</span><br><span class="line">  - name: wp</span><br><span class="line">    image: wordpress</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        memory: &quot;64Mi&quot;</span><br><span class="line">        cpu: &quot;250m&quot;</span><br><span class="line">      limits:</span><br><span class="line">        memory: &quot;128Mi&quot;</span><br><span class="line">        cpu: &quot;500m&quot;</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="如何调度具有资源请求的Pod"><a href="#如何调度具有资源请求的Pod" class="headerlink" title="如何调度具有资源请求的Pod"></a>如何调度具有资源请求的Pod</h4><p>How Pods with resource requests are scheduled</p>
<p>创建Pod时，k8s调度器会选择要运行Pod的节点。每个节点都具有每种资源类型的最大容量，它可为Pod提供CPU和MEM。调度程序确保对于每种资源类型，调度的容器的资源请求总和小于节点的容量。请注意，即使节点上的实际内存或CPU资源使用率非常低，但如果容量检查失败，调度器扔拒绝在节点上放置Pod。当资源使用随后增加时，这可以防止节点上的资源短缺。</p>
<p><br><br><br></p>
<h4 id="如何运行具有资源限制的Pod"><a href="#如何运行具有资源限制的Pod" class="headerlink" title="如何运行具有资源限制的Pod"></a>如何运行具有资源限制的Pod</h4><p>How Pods with resource limits are run</p>
<p>当<code>kubelet</code>启动Pod中的容器时，它会将CPU和MEM限制传递给容器运行环境。</p>
<p>当使用Docker时：</p>
<ul>
<li><p><code>spec.container[].resources.requests.cpu</code>被转换成core value，分数的话会乘以1024。此数字中的较大值用作<code>docker run</code>命令中<code>--cpu-shares</code>标志的值</p>
</li>
<li><p><code>spec.container[].resources.limits.cpu</code>被转换为millicore value并乘以100。结果值代表容器每100ms可以使用的CPU时间总量。<br>在此间隔期间，容器不能使用超过其CPU时间的份额。<br>默认配额时间是100ms，CPU配额的最小解析为1ms。</p>
</li>
</ul>
<ul>
<li><code>spec.containers[].resources.limits.memory</code>被转换为整数，并用作<code>docker run</code>命令中<code>--memory</code>标志的值</li>
</ul>
<p>如果容器超出其内存限制(mem limit)，则容器可能会终止。如果它可以重启，则kubelet将重启它；<br>如果容器超出其内存请求(mem request)，当节点内存不足时，它的Pod可能会被驱逐；<br>容器可能会/可能不会被允许在较长时间内超过其CPU限制。但是，它不会因CPU使用率过高而被杀死。</p>
<p><br><br><br></p>
<h4 id="监控计算资源使用"><a href="#监控计算资源使用" class="headerlink" title="监控计算资源使用"></a>监控计算资源使用</h4><p>Monitoring compute resource usage</p>
<p>Pod的资源使用情况将作为Pod Status的一部分进行上报。</p>
<p><br><br><br></p>
<h4 id="本地短暂存储"><a href="#本地短暂存储" class="headerlink" title="本地短暂存储"></a>本地短暂存储</h4><p>Local ephemeral storage</p>
<p>FEATURE STATE: Kubernetes v1.11 beta</p>
<p>k8s v1.8介绍了一种新资源，用于管理本地短暂存储的短暂存储(ephemeral-storage)。在每个k8s 节点上，kubelet的根目录(默认<code>/var/lib/kubelet</code>)和日志目录(<code>/var/log</code>)存储在节点的根分区上。Pod还通过<code>emptyDir volume</code>，容器日志，镜像层，容器可写层共享和使用此分区。<br>此分区是短暂的，应用程序不能指望来自此分区的任何SLA(如磁盘IO)。本地临时存储仅适用于根分区，镜像层和可写层的可选分区超出了范围。</p>
<p><br></p>
<p><strong>本地短暂存储的请求和限制设置</strong><br>Requests and limits setting for local ephemeral storage</p>
<p>Pod中的容器可指定一个或多个短暂存储：</p>
<ul>
<li><code>spec.containers[].resources.limits.ephemeral-storage</code></li>
<li><code>spec.containers[].resources.requests.ephemeral-storage</code></li>
</ul>
<p>短暂存储的限制和请求以字节(<code>Byte</code>)为单位。<br>你可以使用一下后缀表示整数存储: <code>E, P, T, G, M, K</code>；<br>你也可以使用2的幂等: <code>Ei, Pi, Ti, Gi, Mi, Ki</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">128974848</span><br><span class="line">129e6</span><br><span class="line">129M</span><br><span class="line">123Mi</span><br></pre></td></tr></table></figure>
<p><br></p>
<p>栗子： Pod由两个容器，每个容器都有2GiB的本地短暂存储请求，4GiB的本地短暂存储限制。因此，总共是4GiB请求，8GiB限制。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: frontend</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: db</span><br><span class="line">    image: mysql</span><br><span class="line">    env:</span><br><span class="line">    - name: MYSQL_ROOT_PASSWORD</span><br><span class="line">      value: &quot;password&quot;</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        ephemeral-storage: &quot;2Gi&quot;</span><br><span class="line">      limits:</span><br><span class="line">        ephemeral-storage: &quot;4Gi&quot;</span><br><span class="line">  - name: wp</span><br><span class="line">    image: wordpress</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        ephemeral-storage: &quot;2Gi&quot;</span><br><span class="line">      limits:</span><br><span class="line">        ephemeral-storage: &quot;4Gi&quot;</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>如何调度具有本地短暂存储的Pod</strong><br>How Pods with ephemeral-storage requests are scheduled</p>
<p>对于容器级的隔离，如果容器的可写层和日志使用量超过其存储限制，则Pod将被驱逐。对于Pod级别的隔离，如果所有容器的本地短暂存储使用量与Pod的<code>emptyDir volume</code>的总和超过了限制，则Pod将被驱逐。</p>
<p><br><br><br></p>
<h4 id="扩展的资源"><a href="#扩展的资源" class="headerlink" title="扩展的资源"></a>扩展的资源</h4><p>Extended resources</p>
<p>扩展资源是<code>kubernetes.io</code>域之外的完全限定资源名称。它们允许集群操作者通告和用户使用非k8s内置资源。<br>使用扩展资源需要两个步骤，首先，集群操作者必须通告扩展资源；其次，用户必须在Pod中请求扩展资源。</p>
<p><br></p>
<p><strong>节点级扩展资源</strong><br>节点级扩展资源与节点相关联。</p>
<p><br></p>
<p><strong>集群级扩展资源</strong><br>集群级扩展资源不依赖与节点。它们通常由调度器扩展程序管理——它处理资源消耗和资源配额。</p>
<p><br></p>
<p><strong>使用扩展资源</strong><br>用户可以在<code>pod spec</code>中项CPU和MEM一样使用扩展资源。调度程序负责资源核算，以便不会同时为Pod分配可用的数量。<br>API server将扩展资源的数量限制为整数。</p>
<p>要在Pod中使用扩展资源，在<code>container spec</code>中的<code>spec.container[].resources.limits</code>映射中包含资源名称作为键。<br>只有满足所有请求资源时，才会调度Pod。只要无法满足资源请求，Pod就会保持在<code>PENDING status</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: my-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: my-container</span><br><span class="line">    image: myimage</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: 2</span><br><span class="line">        example.com/foo: 1</span><br><span class="line">      limits:</span><br><span class="line">        example.com/foo: 1</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h3 id="分配Pod到节点"><a href="#分配Pod到节点" class="headerlink" title="分配Pod到节点"></a>分配Pod到节点</h3><p>Assigning Pods to Nodes</p>
<p>你可以将Pod约束为只能在特定节点上运行，或更喜欢在特定节点上运行。有几种方法做到这一点，它们都使用<code>label selector</code>来进行选择。通常这种约束是不必要的，因为调度程序将自动进行合理的放置。但在某些情况下，你可能希望对Pod放置的节点进行更多控制。如确保Pod放置在安装有SSD的计算机上…</p>
<p><br><br><br></p>
<h4 id="节点选择器"><a href="#节点选择器" class="headerlink" title="节点选择器"></a>节点选择器</h4><p>nodeSelector</p>
<p>节点选择器是最简单的约束形式。<code>nodeSelector</code>是<code>PodSpecs</code>的一个字段，它指定了一个键值对的映射。要使Pod有资格在节点上运行，该节点必须将每个指示的的键值对作为标签。最常见的用法是一个键值对。</p>
<ul>
<li><p>Prerequisites<br>k8s 集群</p>
</li>
<li><p>Attach label to the node</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#获取节点名</span><br><span class="line">kubectl get node</span><br><span class="line">NAME      STATUS    ROLES     AGE       VERSION</span><br><span class="line">master    Ready     master    33d       v1.11.1</span><br><span class="line">node      Ready     &lt;none&gt;    33d       v1.11.1</span><br><span class="line">salt01    Ready     &lt;none&gt;    27d       v1.11.1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#打标签</span><br><span class="line">kubectl label nodes &lt;node-name&gt; &lt;label-key&gt;=&lt;label-value&gt;</span><br><span class="line"></span><br><span class="line">#查看标签</span><br><span class="line">kubectl get node --show-labels</span><br></pre></td></tr></table></figure>
<ul>
<li>Add a nodeSelector field to your pod configuration</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">  labels:</span><br><span class="line">    env: test</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx</span><br><span class="line">    image: nginx</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">  nodeSelector:</span><br><span class="line">    &lt;label-key&gt;: &lt;label-value&gt;</span><br></pre></td></tr></table></figure>
<p>当创建这个资源时，Pod将调度到附加此标签的节点上。</p>
<p><br><br><br></p>
<h4 id="内置节点标签"><a href="#内置节点标签" class="headerlink" title="内置节点标签"></a>内置节点标签</h4><p>built-in node labels</p>
<p>除了你附加的标签之外，节点还有一些预先填充的标准标签。</p>
<ul>
<li><code>kubernetes.io/hostname</code></li>
<li><code>failure-domain.beta.kubernetes.io/zone</code></li>
<li><code>failure-domain.beta.kubernetes.io/region</code></li>
<li><code>beta.kubernetes.io/instance-type</code></li>
<li><code>beta.kubernetes.io/os</code></li>
<li><code>beta.kubernetes.io/arch</code></li>
</ul>
<p><br><br><br></p>
<h4 id="亲和力和反亲和力"><a href="#亲和力和反亲和力" class="headerlink" title="亲和力和反亲和力"></a>亲和力和反亲和力</h4><p>Affinity and anti-affinity</p>
<p>节点选择器提供了一种非常简单的方法，使用特定标签约束Pod到特定节点。目前处于测试阶段的亲和力/反亲和力功能，极大地扩展了你可以表达的约束类型。关键的改进有：</p>
<ul>
<li>语言更具表达性</li>
<li>你可以指示规则是<code>soft/preference</code>而不是硬性要求，因此如果调度程序不能满足，也仍然会调度Pod</li>
<li>你可以约束运行在节点上的其它Pod的标签，而不是对节点本身的标签进行约束</li>
</ul>
<p>亲和力有两种类型：</p>
<ul>
<li>node-affinity</li>
<li>inter-pod affinity/anti-affinity</li>
</ul>
<p><br></p>
<p><strong>节点亲和力</strong><br>节点亲和力在概念上类似于nodeSelector，它允许你根据节点标签约束pod调度的节点。<br>目前有两种类型的节点亲和力：</p>
<ul>
<li><code>requiredDuringSchedulingIgnoredDuringExecution</code></li>
<li><code>preferredDuringSchedulingIgnoredDuringExecution</code></li>
</ul>
<p>你可将它们分别是为<code>hard</code>和<code>soft</code>，前者指定了将Pod调度到节点上必须满足的规则，后者指定调度程序将尝试执行但不保证的首选项。名称的<code>IgnoredDuringExecution</code>部分意味着，与节点选择器的工作方式类似，如果节点标签在运行时更改，而不再满足Pod的亲和力规则，则Pod将继续在节点上运行。<br>未来，我们计划提供<code>requiredDuringSchedulingRequiredDuringExecution</code>，就像Ignored一样，它将从不再满足Pod的亲和力要求的节点中驱逐Pod。</p>
<p>节点亲和力在<code>spec.affinity.nodeAffinity</code>字段中指定：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: with-node-affinity</span><br><span class="line">spec:</span><br><span class="line">  affinity:</span><br><span class="line">    nodeAffinity:</span><br><span class="line">      requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">        nodeSelectorTerms:</span><br><span class="line">        - matchExpressions:</span><br><span class="line">          - key: kubernetes.io/e2e-az-name</span><br><span class="line">            operator: In</span><br><span class="line">            values:</span><br><span class="line">            - e2e-az1</span><br><span class="line">            - e2e-az2</span><br><span class="line">      preferredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">      - weight: 1</span><br><span class="line">        preference:</span><br><span class="line">          matchExpressions:</span><br><span class="line">          - key: another-node-label-key</span><br><span class="line">            operator: In</span><br><span class="line">            values:</span><br><span class="line">            - another-node-label-value</span><br><span class="line">  containers:</span><br><span class="line">  - name: with-node-affinity</span><br><span class="line">    image: k8s.gcr.io/pause:2.0</span><br></pre></td></tr></table></figure>
<p>此节点亲和力规则表示，Pod只能防止在<code>kubernetes.io/e2e-az-name</code>标签键，值为<code>e2e-az1</code>或<code>e2e-az2</code>的节点上。此外，在满足条件的节点中，应优先选择具有<code>another-node-label-key</code>键，值为<code>another-node-label-value</code>的节点。<br>节点亲和力语法支持如下操作符: <code>In, NotIn, Exists, DoesNotExist, Gt, Lt</code>。</p>
<p>如果你同时指定了<code>nodeSelector</code>和<code>nodeAffinity</code>，则必须满足两者以将Pod调度到候选节点上；<br>如果你指定了与<code>nodeAffinity</code>类型关联的多个<code>nodeSelectorTerms</code>。那么，如果满足其中一个<code>nodeSelectorTerms</code>，则可以将Pod调度到节点上；<br>如果你指定了与<code>nodeSelectorTerms</code>关联的多个<code>matchExpressions</code>。那么，只有满足所有<code>matchExpressions</code>的情况下，才能将Pod安排到节点上；<br>如果删除或更改调度Pod的节点标签，则Pod不会被删除。换句话说，亲和力仅在调度Pod时起作用。</p>
<p><br></p>
<p><strong>Pod间亲和力和反亲和力</strong><br>Pod间亲和力和反亲和力，你可以根据已在节点上运行的Pod上的标签(而不是节点标签)，来约束Pod可以调度的节点。与节点不同，Pod有命名空间，Pod标签的标签选择器必须指定选择器应该应用于哪些命名空间。</p>
<p>注意： Pod间亲和力和反亲和力需要大量的处理，可会显著减慢大型集群中的调度。因此，不建议在大于几百个节点的集群中使用；<br>注意： Pod反亲和力要求节点一致地标签节点，即集群中的每个节点都必须具有匹配的<code>topologyKey</code>标签，如果某些节点缺少，可能会导致意外情况。</p>
<p>目前有两种类型的Pod亲和力和反亲和力:</p>
<ul>
<li><code>requiredDuringSchedulingIgnoredDuringExecution</code></li>
<li><code>preferredDuringSchedulingIgnoredDuringExecution</code></li>
</ul>
<p>同样表示<code>hard</code>和<code>soft</code>要求。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: with-pod-affinity</span><br><span class="line">spec:</span><br><span class="line">  affinity:</span><br><span class="line">    podAffinity:</span><br><span class="line">      requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">      - labelSelector:</span><br><span class="line">          matchExpressions:</span><br><span class="line">          - key: security</span><br><span class="line">            operator: In</span><br><span class="line">            values:</span><br><span class="line">            - S1</span><br><span class="line">        topologyKey: failure-domain.beta.kubernetes.io/zone</span><br><span class="line">    podAntiAffinity:</span><br><span class="line">      preferredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">      - weight: 100</span><br><span class="line">        podAffinityTerm:</span><br><span class="line">          labelSelector:</span><br><span class="line">            matchExpressions:</span><br><span class="line">            - key: security</span><br><span class="line">              operator: In</span><br><span class="line">              values:</span><br><span class="line">              - S2</span><br><span class="line">          topologyKey: kubernetes.io/hostname</span><br><span class="line">  containers:</span><br><span class="line">  - name: with-pod-affinity</span><br><span class="line">    image: k8s.gcr.io/pause:2.0</span><br></pre></td></tr></table></figure>
<p>Pod亲和力和反亲和力的有效操作符有: <code>In, NotIn, Exists, DoesNotExist</code><br>原则上，<code>topologyKey</code>可以是任一合法的<code>label-key</code>。但是，出于性能和安全的原因，它也有一些限制：</p>
<ul>
<li>对于亲和力和<code>requiredDuringSchedulingIgnoredDuringExecution</code>的Pod的反亲和力，不允许使用空的<code>topologykey</code></li>
<li>对于<code>requiredDuringSchedulingIgnoredDuringExecution</code>的Pod的反亲和力，引入控制器<code>LimitPodHardAntiAffinityTopology</code>是为了将<code>topologyKey</code>限制为<code>kubernetes.io/hostname</code>。如果要使其可用于自定义，可修改控制器，或禁用它</li>
<li>对于<code>preferredDuringSchedulingIgnoredDuringExecution</code>的Pod的反亲和力，空的<code>topologyKey</code>被解释为<code>all topologies</code></li>
<li>除了上面提到的，<code>topologyKey</code>可以是任一合法的<code>label-key</code></li>
</ul>
<p>除了<code>labelSelector</code>和<code>topologyKey</code>之外，你还可以选择指定<code>labelSelector</code>应匹配的命名空间。如果为空或省略，则默认为Pod的亲和力/反亲和力的命名空间。</p>
<p><br><br><br></p>
<h3 id="污点和容忍"><a href="#污点和容忍" class="headerlink" title="污点和容忍"></a>污点和容忍</h3><p>Taints and Tolerations</p>
<p>节点亲和力是Pod的属性，它将它们吸引到节点；Taints则相反——它允许节点排斥Pod。<br>Taints 和 Tolerations 一起工作以确保Pod不被安排的不适当的节点上。将一个或多个污点(taints)应用于节点，这标志着节点不应该接受任何不能容忍污点的Pod。容忍(tolerations)应用于Pod，并允许Pod安排到具有匹配污点的节点上。</p>
<p><br><br><br><br><br></p>
<h2 id="服务，负载均衡和网络"><a href="#服务，负载均衡和网络" class="headerlink" title="服务，负载均衡和网络"></a>服务，负载均衡和网络</h2><p>Services, Load Balancing, and Networking</p>
<p><br><br><br><br><br></p>
<h2 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h2><p>Storage</p>
<p><br><br><br></p>
<h3 id="Volumes"><a href="#Volumes" class="headerlink" title="Volumes"></a>Volumes</h3><p>容器中的磁盘文件是短暂的，这在容器中运行时会给重大的应用程序带来一些问题。首先，当一个容器奔溃时，kubelet将重启它，但文件会丢失，容器将以干净的状态启动。其次，在Pod中一起运行容器时，通常需要在这些容器间共享文件。k8s volume抽象解决这些问题。</p>
<p><br><br><br></p>
<h4 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h4><p>Docker也有关于卷的概念，虽然它有点宽松和管理较少。在Docker中，卷是磁盘上或其它容器中的目录，声明周期不受管理。Docker提供了卷驱动，但目前功能非常有限。</p>
<p>另一方面，k8s的卷具有明确的生命周期。因此，卷可以比Pod中运行的任何容器活得更久，并且可在容器重启之间保留数据。当然，当Pod不再存在时，卷也将不复存在。更重要的是，k8s支持多种类型的卷，Pod可以同时使用任意数量的卷。<br>从本质上讲，卷只是一个目录，可能包含一些数据，Pod中的容器可以访问它。该目录如何形成，支持它的介质以及它的内容都由所用特定卷的类型决定。<br>要使用卷，Pod Spec要指定提供的卷(<code>.spec.volumes</code>字段)，以及将这些卷挂载到容器中的位置(<code>.spec.containers.volumeMounts</code>字段)。</p>
<p>容器中的进程可以看到由Docker镜像和卷组成的文件系统视图。Docker镜像位于文件系统层次结构的根下，任何卷都挂载到镜像中的指定路径。卷不能挂载到其它卷或其它卷的硬链接上，Pod中的每个容器必须独立的指定每个卷的挂载位置。</p>
<p><br><br><br></p>
<h4 id="卷类型"><a href="#卷类型" class="headerlink" title="卷类型"></a>卷类型</h4><p>k8s支持如下卷类型：</p>
<ul>
<li>awsElasticBlockStore</li>
<li>azureDisk</li>
<li>azureFile</li>
<li>cephfs</li>
<li>configMap</li>
<li>csi</li>
<li>downwardAPI</li>
<li>emptyDir</li>
<li>fc (fibre channel)</li>
<li>flocker</li>
<li>gcePersistentDisk</li>
<li>gitRepo (deprecated)</li>
<li>glusterfs</li>
<li>hostPath</li>
<li>iscsi</li>
<li>local</li>
<li>nfs</li>
<li>persistentVolumeClaim</li>
<li>projected</li>
<li>portworxVolume</li>
<li>quobyte</li>
<li>rbd</li>
<li>scaleIO</li>
<li>secret</li>
<li>storageos</li>
<li>vsphereVolume</li>
</ul>
<p>具体例子请参考: <a href="https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes</a></p>
<p><br><br><br></p>
<h4 id="使用子路径"><a href="#使用子路径" class="headerlink" title="使用子路径"></a>使用子路径</h4><p>Using subPath</p>
<p>有时，在单个Pod中共享一个卷用于多个用途是很有用的。<code>volumeMounts.subPath</code>属性可用于指定引用卷内的子路径，而不是根路径。</p>
<p>使用单个共享卷的Pod与LAMP Stack的示例，HTML内容被映射到html目录中，数据库存储在mysql目录中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: my-lamp-site</span><br><span class="line">spec:</span><br><span class="line">    containers:</span><br><span class="line">    - name: mysql</span><br><span class="line">      image: mysql</span><br><span class="line">      env:</span><br><span class="line">      - name: MYSQL_ROOT_PASSWORD</span><br><span class="line">        value: &quot;rootpasswd&quot; </span><br><span class="line">      volumeMounts:</span><br><span class="line">      - mountPath: /var/lib/mysql</span><br><span class="line">        name: site-data</span><br><span class="line">        subPath: mysql</span><br><span class="line">    - name: php</span><br><span class="line">      image: php:7.0-apache</span><br><span class="line">      volumeMounts:</span><br><span class="line">      - mountPath: /var/www/html</span><br><span class="line">        name: site-data</span><br><span class="line">        subPath: html</span><br><span class="line">    volumes:</span><br><span class="line">    - name: site-data</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">        claimName: my-lamp-site-data</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>使用带有扩展环境变量的子路径</strong><br>Using subPath with expanded environment variables</p>
<p>FEATURE STATE: <code>k8s v1.11 alpha</code></p>
<p><code>subPath</code>目录名也可从Downward API环境变量构造。在使用此功能之前，必须启用<code>VolumeSubpathEnvExpansion</code>。<br>下例中，Pod使用<code>subPath</code>在主机路径卷<code>/var/log/pods</code>中创建<code>pod1</code>目录，使用Downward API中的Pod名。主机目录<code>/var/log/pods/pod1</code>被挂载到容器中的<code>/logs</code>目录。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: pod1</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: container1</span><br><span class="line">    env:</span><br><span class="line">    - name: POD_NAME</span><br><span class="line">      valueFrom:</span><br><span class="line">        fieldRef:</span><br><span class="line">          apiVersion: v1</span><br><span class="line">          fieldPath: metadata.name</span><br><span class="line">    image: busybox</span><br><span class="line">    command: [ &quot;sh&quot;, &quot;-c&quot;, &quot;while [ true ]; do echo &apos;Hello&apos;; sleep 10; done | tee -a /logs/hello.txt&quot; ]</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: workdir1</span><br><span class="line">      mountPath: /logs</span><br><span class="line">      subPath: $(POD_NAME)</span><br><span class="line">  restartPolicy: Never</span><br><span class="line">  volumes:</span><br><span class="line">  - name: workdir1</span><br><span class="line">    hostPath:</span><br><span class="line">      path: /var/log/pods</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h4 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h4><p><code>emptyDir</code>卷的存储介质(磁盘，SSD…)由kubelet根目录的文件系统的介质确定。<code>emptyDir</code>或<code>hostPath</code>卷可以占用多少空间没有限制，容器之间或Pod之间没有隔离。</p>
<p><br><br><br></p>
<p>####挂载传播</p>
<p>Mount propagation</p>
<p>FEATURE STATE: <code>k8s v1.10 beta</code></p>
<p>挂载传播允许将容器挂载的卷共享到同一Pod的其它容器，或同一节点的其它Pod。<br>如果<code>MountPropagation</code>功能被禁用，或Pod未指明特定的挂载环境，则不会传播Pod的容器中的挂载卷。<br>卷的挂载传播由<code>Container.volumeMounts</code>中的<code>mountPropagation</code>字段控制。它的值为：</p>
<ul>
<li><p><code>None</code><br>此卷的挂载不会接收主机挂载到此卷或任何子目录的任何后续挂载。此模式等同于于Linux kernel中描述的<code>private</code>挂载传播。</p>
</li>
<li><p><code>HostToContainer</code><br>此卷的挂载将接收安装到此卷或其任何子目录的所有后续挂载。换句话说，如果主机在卷挂载中挂载任何内容，则容器将看到它挂载在那里。<br>类似地，如果任何具有双向挂载传播的Pod挂载到同一个卷中，那么具有<code>HostToContainer</code>挂载传播的容器将看到它。此模式等同于Linux Kernel中描述的<code>rslave</code>挂载传播。</p>
</li>
<li><p><code>Bidirectional</code><br>此卷的挂载行为与<code>HostToContainer</code>相同。此外，容器创建的所有卷 挂载都将传播会主机和所有使用相同卷的Pod中的容器。此模式等同于Linux kernel中描述的<code>rshared</code>挂载传播。</p>
</li>
</ul>
<p><br></p>
<p><strong>配置</strong><br>在挂载传播可以在某些部署上正常工作之前，必须在Docker中正确配置挂载共享，修改<code>docker systemd</code>服务文件，设置<code>MountFlags</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MountFlags=shared</span><br></pre></td></tr></table></figure>
<p>重启Docker：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h3 id="持久化卷"><a href="#持久化卷" class="headerlink" title="持久化卷"></a>持久化卷</h3><p>Persistent Volumes</p>
<p><br><br><br><br><br></p>
<h2 id="垃圾收集"><a href="#垃圾收集" class="headerlink" title="垃圾收集"></a>垃圾收集</h2><p>Kubernetes 垃圾收集器的角色是删除指定的对象，这些对象曾经有但以后不再拥有 Owner 了。</p>
<p>某些Kubernetes对象是其它一些对象的Owner。如，一个副本集是一组pod的Owner。<br>具有Owner的对象被称为是Owner的<strong>Dependent</strong>。每个Dependent对象具有一个执行所属对象的<code>metadata.ownerReference</code>字段。</p>
<p>有时，Kubernetes会自动设置<code>ownerReference</code>的值。<br>也可以手动设置<code>ownerReference</code>的值，来指定Owner和Dependent之间的关系。</p>
<p><br></p>
<p><strong>控制垃圾收集器删除Dependent</strong></p>
<ul>
<li><p>级联删除</p>
<ul>
<li>background</li>
<li>foreground<br>删除对象时自动删除Dependent。<br>在bg级联删除模式下，k8s会立即删除Owner对象，然后垃圾收集器会在后台删除这些Dependent。<br>在fg级联删除模式下，根对象首先进入删除中状态。一旦对象被设置为删除中状态，垃圾收集器会删除对象的所有Dependent。</li>
</ul>
</li>
<li><p>孤儿<br>删除对象时，不自动删除它的Dependent。这些Dependent就被称作孤儿。垃圾收集器在删除了所有 “Blocking” 状态的 Dependent（对象的 ownerReference.blockOwnerDeletion=true）之后，它会删除 Owner 对象。</p>
</li>
</ul>
<p><br><br><br></p>
<hr>
<p><br></p>
<h1 id="教程"><a href="#教程" class="headerlink" title="教程"></a>教程</h1><p>Tutorials</p>
<p>教程展示了如何实现比单个任务更大的目标(task)。</p>
<p><br></p>
<h2 id="k8s基本"><a href="#k8s基本" class="headerlink" title="k8s基本"></a>k8s基本</h2><p><br></p>
<h3 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h3><p>本教程提供了Kubernetes集群编排系统基础知识的介绍。</p>
<p>你将学到：</p>
<ul>
<li>在集群上部署容器化服务</li>
<li>伸缩部署</li>
<li>使用新软件版本更新容器化应用程序</li>
<li>调试容器化应用程序</li>
</ul>
<p><br></p>
<p><strong>k8s能为你做什么？</strong><br>容器化有助于打包软件以实现这些目标，是应用程序能够以简单快速的方式发布和更新，而无需停机。k8s可帮助你确保这些容器化应用程序随时随地运行，并帮助它们找到运行所需的资源。</p>
<p><br></p>
<p><strong>k8s 基础模块</strong></p>
<ol>
<li>创建(create)一个k8s集群</li>
<li>部署(deploy)应用程序</li>
<li>探索(explore)应用程序</li>
<li>公开(expose)展示应用程序</li>
<li>伸缩(scale)应用程序</li>
<li>升级(update)应用程序</li>
</ol>
<p><br><br><br></p>
<h3 id="创建集群"><a href="#创建集群" class="headerlink" title="创建集群"></a>创建集群</h3><p>Create a Cluseter</p>
<p>详情见安装部分。</p>
<p><br><br><br></p>
<h3 id="部署应用程序"><a href="#部署应用程序" class="headerlink" title="部署应用程序"></a>部署应用程序</h3><p>Deploy an APP</p>
<p><br></p>
<h4 id="使用kubectl创建部署"><a href="#使用kubectl创建部署" class="headerlink" title="使用kubectl创建部署"></a>使用kubectl创建部署</h4><p>Using kubectl to create a Deployment</p>
<p>目标：</p>
<ul>
<li>了解应用程序部署</li>
<li>在k8s上使用<code>kubectl</code>部署你的第一个应用程序</li>
</ul>
<p><br></p>
<p><strong>k8s Deployments</strong><br>一旦运行了k8s集群，就可在其上部署容器化应用程序。为此，你需要创建Kubernetes Deployment configuration。它指示k8s 如何创建和更新应用程序实例。创建部署后，k8s master将应用程序实例调度到各个node上。<br>创建应用程序实例后，Kubernetes Deployment Controller会持续监控这些实例。如果主机节点上的实例关闭或删除，Deployment Controller会替换它。这提供了一种自我修复(self-healing)机制来解决机器故障或维护。</p>
<p><br></p>
<p><strong>部署应用程序</strong><br>可使用<code>kubectl</code>(使用k8s api与集群交互)来创建和管理Deployment。下面有一些关于使用kubectl在k8s集群上创建和管理Deployment的基础命令。</p>
<p>创建部署时，你需要指定应用程序的容器镜像(image)，以及要运行的副本数(replicas)。你可在以后改变这些信息来更新你的部署。</p>
<p>栗子：<br>第一个部署，k8s使用一个Docker容器的<code>Node.js</code>应用程序包。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">kubectl version</span><br><span class="line">#client</span><br><span class="line">#server</span><br><span class="line"></span><br><span class="line">kubectl get nodes</span><br><span class="line"></span><br><span class="line">#创建名为k8s-bootcamp的deployment</span><br><span class="line">kubectl run kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1 --port=8080</span><br><span class="line">#这是国内镜像: docker.io/jocatalin/kubernetes-bootcamp:v1</span><br><span class="line"></span><br><span class="line">kubectl get deployments</span><br><span class="line">NAME           DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">kubenetes-bootcamp   1         1        1           1          1h</span><br><span class="line">#表示 希望副本数，当前副本数，最新副本数，可用副本数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#由于pod被封装在集群私网，没有对外开放</span><br><span class="line">#proxy将通信转发到集群内私网</span><br><span class="line">kubectl proxy</span><br><span class="line">curl http://localhost:8081/version</span><br><span class="line">curl http://localhost:8001/api/v1/namespaces/default/pods/$POD_NAME/proxy/</span><br><span class="line">#Hello Kubernetes bootcamp!</span><br></pre></td></tr></table></figure>
<p>此处我遇到一个错误，<code>replicats unavailable</code>:<br>原因是拉取的镜像在谷歌云上，无法访问<gcr.io>，拉取失败所以导致部署失败。<br>gcr(google container Registry)</gcr.io></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#查看部署信息</span><br><span class="line"> kubectl get deployment kubernetes-bootcamp -o yaml</span><br><span class="line">    message: &apos;unable to create pods: No API token found for service account &quot;default&quot;,</span><br><span class="line">      retry after the token is automatically created and added to the service account&apos;</span><br><span class="line">    reason: FailedCreate</span><br><span class="line">    status: &quot;True&quot;</span><br><span class="line">    type: ReplicaFailure</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl get deployments</span><br><span class="line">NAME                  DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">kubernetes-bootcamp   1         0         0            0           33m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl describe deployments kubernetes-bootcamp</span><br><span class="line">Replicas:               1 desired | 0 updated | 0 total | 0 available | 1 unavailable</span><br><span class="line">StrategyType:           RollingUpdate</span><br><span class="line">ReplicaFailure   True    FailedCreate</span><br></pre></td></tr></table></figure>
<p>针对<strong>unable to create pods: No API token found for service account “default”</strong>这个问题，需要修改kube-apiserver配置文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">#去掉 KUBE_ADMISSION_CONTROL中的SecurityContextDeny,ServiceAccount</span><br><span class="line">KUBE_ADMISSION_CONTROL=&quot;--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#重启kube-apiserver</span><br><span class="line">systemctl restart kube-apiserver</span><br><span class="line"></span><br><span class="line">#之后查看副本数就正常了</span><br><span class="line">kubectl get deployments</span><br><span class="line">NAME                  DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">kubernetes-bootcamp   1         1         1            0           8m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#这里available还是0</span><br><span class="line">kubectl get pods</span><br><span class="line">NAME                                  READY     STATUS              RESTARTS   AGE</span><br><span class="line">kubernetes-bootcamp-390780338-6x48n   0/1       ContainerCreating   0          21h</span><br><span class="line">#pod处于创建状态</span><br><span class="line"></span><br><span class="line">#查看详情</span><br><span class="line">kubectl describe pods</span><br><span class="line">#错误信息</span><br><span class="line">  Warning  FailedSync  4m (x258 over 21h)   kubelet, 192.168.31.159  Error syncing pod, skipping: failed to &quot;StartContainer&quot; for &quot;POD&quot; with ErrImagePull: &quot;image pull failed for registry.access.redhat.com/rhel7/pod-infrastructure:latest, this may be because there are no credentials on this request.  details: (open /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt: no such file or directory)&quot;</span><br><span class="line">  Warning  FailedSync  9s (x5728 over 21h)  kubelet, 192.168.31.159  Error syncing pod, skipping: failed to &quot;StartContainer&quot; for &quot;POD&quot; with ImagePullBackOff: &quot;Back-off pulling image \&quot;registry.access.redhat.com/rhel7/pod-infrastructure:latest\&quot;&quot;</span><br><span class="line"></span><br><span class="line">#在node上查看此文件，发现它指向了一个空链接</span><br><span class="line">#并不存在/etc/rhsm目录</span><br><span class="line">ll /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt</span><br><span class="line">lrwxrwxrwx. 1 root root 27 7月  16 16:58 /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt -&gt; /etc/rhsm/ca/redhat-uep.pem</span><br><span class="line"></span><br><span class="line">#在node安装此rhsm</span><br><span class="line">yum search rhsm</span><br><span class="line">#python-rhsm-certificates.x86_64</span><br><span class="line">#python-rhsm.x86_64</span><br><span class="line">yum install -y python-rhsm.x86_64 python-rhsm-certificates.x86_64</span><br><span class="line">#之后在node上手动拉取下image便可看到pod正常运行</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h3 id="探索应用程序"><a href="#探索应用程序" class="headerlink" title="探索应用程序"></a>探索应用程序</h3><p>Explore Your App</p>
<p><br></p>
<h4 id="查看Pods和Nodes"><a href="#查看Pods和Nodes" class="headerlink" title="查看Pods和Nodes"></a>查看Pods和Nodes</h4><p>目标：</p>
<ul>
<li>了解k8s Pods</li>
<li>了解k8s Nodes</li>
<li>部署应用的故障解决(troubleshoot)</li>
</ul>
<p><br></p>
<p><strong>k8s Pods</strong><br>当你创建一个部署时，k8s创建了一个pod来托管你的应用程序实例。pod是k8s的一个抽象，表示一组(一个/多个)应用程序容器，以及这些容器的共享资源。<br>pod有一个唯一的IP地址，甚至是同一节点上的pod。pod中的容器共享IP地址和端口，始终位于同一位置并共同调度，并在同一节点上共享上下文中运行。<br>这些资源包括：</p>
<ul>
<li>共享存储(volumes)</li>
<li>网络(唯一的集群内ip)</li>
<li>运行容器的相关信息</li>
</ul>
<p><br></p>
<p><strong>Nodes</strong><br>pod总是运行在node上，一个node上可运行多个pod。每个node由master管理，master自动处理在node上调度pod。<br>node至少运行如下组件：</p>
<ul>
<li>kubelet</li>
<li>container runtime(如docker)</li>
</ul>
<p><br></p>
<p><strong>Troubleshooting with kubectl</strong><br>最常用的<code>kubectl</code>命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#列出资源</span><br><span class="line">kubectl get</span><br><span class="line">#kubectl get nodes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#某个资源的详细信息</span><br><span class="line">kubectl describe</span><br><span class="line">#kubectl describe deployments kubernetes-bootcamp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#pod中容器日志</span><br><span class="line">kubectl logs</span><br><span class="line">#kubectl logs $pod --since=1h</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#在pod的容器执行命令</span><br><span class="line">kubectl exec</span><br><span class="line">#kubectl ecec $pod env</span><br><span class="line">#kubectl exec -it $pod /bin/bash</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h3 id="公开展示应用程序"><a href="#公开展示应用程序" class="headerlink" title="公开展示应用程序"></a>公开展示应用程序</h3><p>Expose Your App Publicly</p>
<p><br></p>
<h4 id="使用服务来展示应用程序"><a href="#使用服务来展示应用程序" class="headerlink" title="使用服务来展示应用程序"></a>使用服务来展示应用程序</h4><p>Using a Service to Expose Your App</p>
<p>目标：</p>
<ul>
<li>了解k8s中的服务(service)</li>
<li>理解labels和LabelSelector对象如何关联服务</li>
<li>使用服务将应用程序展示在集群外部</li>
</ul>
<p><br></p>
<p><strong>k8s Service</strong><br>事实上，pods有一个生命周期。当工作node死亡，node上运行的pods也会丢失。ReplicationController可以通过创建新的Pod来动态地将集群驱动会所需状态，以使应用程序保持运行。<br>k8s的服务是一个抽象概念，它定义了一组逻辑Pod和一个访问pods的策略。服务使用YAML或JSON来定义。由一组pods所构成的服务通常由LabelSelector来确定。<br>尽管每个Pod都有一个唯一的IP地址，但如果没有服务，这些IP就不会在集群外公开。<br>通过指定ServeceSpec中的type，可以不同方式公开服务:</p>
<ul>
<li><p>ClusterIP(默认方式)<br>在集群内部IP公开服务，只可内部访问</p>
</li>
<li><p>NodePort<br>使用NAT在集群的指定节点上公开服务</p>
</li>
<li><p>LoadBalancer<br>创建一个外部负载均衡器，并给服务分配一个外部IP</p>
</li>
<li><p>ExternalName<br>通过返回带有名称的CNAME(k8s-dns)记录，使用任意名称公开服务</p>
</li>
</ul>
<p><br></p>
<p><strong>Services和Labels</strong><br>服务使用labels和selectors匹配一组pod这是一个允许对k8s的对象进行逻辑操作的分组原语。<br>Label是附件到对象的键/值对，随时随地可修改。有多种方式可使用：</p>
<ul>
<li>指定用于开发(development)、测试(test)、生产(procuct)的对象</li>
<li>嵌入版本tag</li>
<li>使用tag对对象进行分类</li>
</ul>
<p><br></p>
<p>栗子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods</span><br><span class="line">#NAME                                  READY     STATUS    RESTARTS   AGE</span><br><span class="line">#kubernetes-bootcamp-390780338-6x48n   1/1       Running   0          22h</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl get services</span><br><span class="line">#NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">#kubernetes   ClusterIP   10.254.0.1   &lt;none&gt;        443/TCP   1d</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#公开展示应用程序</span><br><span class="line">kubectl expose deployment/kubernetes-bootcamp --type=&quot;NodePort&quot; --port 8080</span><br><span class="line">#service &quot;kubernetes-bootcamp&quot; exposed</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl get services</span><br><span class="line">#NAME                  TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">#kubernetes            ClusterIP   10.254.0.1     &lt;none&gt;        443/TCP          1d</span><br><span class="line">#kubernetes-bootcamp   NodePort    10.254.11.76   &lt;none&gt;        8080:31514/TCP   2m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl describe services/kubernetes-bootcamp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl describe deployment</span><br><span class="line">#Labels:                 run=kubernetes-bootcamp</span><br><span class="line">#使用label查询</span><br><span class="line">kubectl get pods -l run=kubernetes-bootcamp</span><br><span class="line">kubectl get services -l run=kubernetes-bootcamp</span><br><span class="line">#使用label删除</span><br><span class="line">kubectl delete service -l run=kubernetes-bootcamp</span><br><span class="line"></span><br><span class="line">kubectl describe pods kubernetes-bootcamp-390780338-6x48n</span><br><span class="line"></span><br><span class="line">kubectl exec -it kubernetes-bootcamp-390780338-6x48n /bin/bash</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h3 id="扩展应用程序"><a href="#扩展应用程序" class="headerlink" title="扩展应用程序"></a>扩展应用程序</h3><p>Scale Your App</p>
<p>Running Multiple Instances of Your App</p>
<p>目标：</p>
<ul>
<li>使用<code>kubectl</code>伸缩应用程序</li>
</ul>
<p><br></p>
<p><strong>伸缩应用程序</strong><br>前面通过部署创建的服务仅有一个pod，当遇到流量激增，我们便需要扩展应用程序。<br>通过更改部署中的副本数来完成扩展。</p>
<p>扩展部署将确保使用可用资源(available resource)创建新的pod并将其调度到node。k8s支持Pod的自动伸缩，缩放到0(也就是没有pod)也是可能的，它将终止指定部署的所有Pod。<br>对应用程序运行多个实例需要一种方法将流量分配给所有这些实例。服务有集成的负载均衡器(load-blancer)，可将网络流量分配到公开部署的所有Pod。服务将使用endpoint持续监控运行的Pod，以确保网络流量发送到可用的Pods。</p>
<p>一旦运行的应用程序有了多个实例，你就可以在不停机(downtime)的情况下执行滚动更新(rolling update)。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">kubectl get deployments</span><br><span class="line">#1个</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#扩展实例</span><br><span class="line">kubectl scale deployments/kubernetes-bootcamp --replicas=4</span><br><span class="line">#deployment.extensions &quot;kubernetes-bootcamp&quot; scaled</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl get deployments</span><br><span class="line">#4个</span><br><span class="line">kubectl get pods -o wide</span><br><span class="line">#4个</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl describe deployment/kubernetes-bootcamp</span><br><span class="line">kubectl describe services/kubernetes-bootcamp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#缩放实例</span><br><span class="line">kubectl scale deployments/kubernetes-bootcamp --replicas=2</span><br><span class="line">#deployment.extensions &quot;kubernetes-bootcamp&quot; scaled</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl get deployments</span><br><span class="line">#2个</span><br><span class="line"></span><br><span class="line">#有两个pods正在关闭中</span><br><span class="line">kubectl get pods -o wide</span><br><span class="line">NAME                                  READY     STATUS        RESTARTS   AGE       IP            NODE</span><br><span class="line">kubernetes-bootcamp-390780338-1zgvs   1/1       Terminating   0          7m        10.254.76.5   192.168.31.159</span><br><span class="line">kubernetes-bootcamp-390780338-6x48n   1/1       Running       0          2d        10.254.76.2   192.168.31.159</span><br><span class="line">kubernetes-bootcamp-390780338-bqztg   1/1       Running       0          7m        10.254.76.4   192.168.31.159</span><br><span class="line">kubernetes-bootcamp-390780338-hkwfd   1/1       Terminating   0          7m        10.254.76.3   192.168.31.159</span><br><span class="line"></span><br><span class="line">#关闭完成</span><br><span class="line">kubectl get pods -o wide</span><br><span class="line">NAME                                  READY     STATUS    RESTARTS   AGE       IP            NODE</span><br><span class="line">kubernetes-bootcamp-390780338-6x48n   1/1       Running   0          2d        10.254.76.2   192.168.31.159</span><br><span class="line">kubernetes-bootcamp-390780338-bqztg   1/1       Running   0          15m       10.254.76.4   192.168.31.159</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h3 id="升级应用程序"><a href="#升级应用程序" class="headerlink" title="升级应用程序"></a>升级应用程序</h3><p>Update your App<br>Performing a Rolling Update</p>
<p>目标：</p>
<ul>
<li>使用<code>kubectl</code>执行滚动升级</li>
</ul>
<p><br></p>
<p><strong>滚动更新</strong><br>用户希望应用程序始终可用，可发人员可能会多次部署新版本应用程序。在k8s中，这都可以通过滚动更新(rolling update)完成。<br>滚动更新允许通过使用新的实例逐步更新Pod来实现部署的更新，而不需停机(downtime)。新的Pod将在具有可用资源的node上进行调度。<br>在k8s中，更新是版本化的，任何部署更新都可以恢复到以前的版本。</p>
<p>与应用程序扩展类似，服务在更新期间仅会将流量负载均衡到可用的Pod(应用实例)。</p>
<p>滚动更新允许以下操作：</p>
<ul>
<li>将应用程序从一个环境推到另一个环境</li>
<li>回滚(rollback)到之前的版本</li>
<li>无需停机的持续集成(CI)和持续交付(CD)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">kubectl get deployments</span><br><span class="line">kubectl get pods</span><br><span class="line">#2个</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#更新镜像</span><br><span class="line">kubectl set image deployments/kubernetes-bootcamp  kubernetes-bootcamp=docker.io/jocatalin/kubernetes-bootcamp:v2</span><br><span class="line">deployment.apps &quot;kubernetes-bootcamp&quot; image updated</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line">kubectl get pods</span><br><span class="line">NAME                                  READY     STATUS        RESTARTS   AGE</span><br><span class="line">kubernetes-bootcamp-390780338-6x48n   1/1       Terminating   0          3d</span><br><span class="line">kubernetes-bootcamp-390780338-bqztg   1/1       Terminating   0          38m</span><br><span class="line">kubernetes-bootcamp-472176051-m6h1q   1/1       Running       0          29s</span><br><span class="line">kubernetes-bootcamp-472176051-z4wqs   1/1       Running       0          29s</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line">kubectl get pods</span><br><span class="line">NAME                                  READY     STATUS    RESTARTS   AGE</span><br><span class="line">kubernetes-bootcamp-472176051-m6h1q   1/1       Running   0          42s</span><br><span class="line">kubernetes-bootcamp-472176051-z4wqs   1/1       Running   0          42s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#检查回滚状态</span><br><span class="line">kubectl rollout status deployments/kubernetes-bootcamp</span><br><span class="line">deployment &quot;kubernetes-bootcamp&quot; successfully rolled out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#更新</span><br><span class="line">kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=docker.io/jocatalin/kubernetes-bootcamp:v10</span><br><span class="line">deployment.apps &quot;kubernetes-bootcamp&quot; image updated</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#有错</span><br><span class="line">kubectl get deployments</span><br><span class="line">NAME                  DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">kubernetes-bootcamp   2         3         2            1           3d</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#有错</span><br><span class="line">kubectl get pods</span><br><span class="line">NAME                                  READY     STATUS             RESTARTS   AGE</span><br><span class="line">kubernetes-bootcamp-384357858-7kjx1   0/1       ErrImagePull       0          2m</span><br><span class="line">kubernetes-bootcamp-384357858-t0wmt   0/1       ImagePullBackOff   0          2m</span><br><span class="line">kubernetes-bootcamp-472176051-m6h1q   1/1       Running            0          9m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#</span><br><span class="line">kubectl describe pods</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#回滚</span><br><span class="line">kubectl rollout undo deployments/kubernetes-bootcamp</span><br><span class="line">deployment.apps &quot;kubernetes-bootcamp&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#查看</span><br><span class="line">kubectl get pods</span><br><span class="line">kubectl decribe pods</span><br><span class="line">#Image:          docker.io/jocatalin/kubernetes-bootcamp:v2</span><br><span class="line">#回到了V2版</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h2 id="配置-2"><a href="#配置-2" class="headerlink" title="配置"></a>配置</h2><p>Configuration</p>
<p><br></p>
<h3 id="使用ConfigMap配置Redis"><a href="#使用ConfigMap配置Redis" class="headerlink" title="使用ConfigMap配置Redis"></a>使用ConfigMap配置Redis</h3><p><strong>目标(Objective)</strong></p>
<ul>
<li>创建ConfigMap</li>
<li>使用ConfigMap创建Pod规范</li>
<li>创建Pod</li>
<li>验证配置是否正确应用</li>
</ul>
<p><br></p>
<p><strong>开始之前</strong><br>需要有k8s集群，并且安装了<code>kubectl</code>命令行工具。</p>
<p><br></p>
<p><strong>栗子：使用ConfigMap配置Redis</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">#Master</span><br><span class="line">#创建redis的ConfigMap</span><br><span class="line">kubectl create configmap redis-config --from-file=xxx/redis-config</span><br><span class="line">kubectl get configmap redis-config -o yaml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#创建redis-pod.yaml文件</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: redis</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: redis</span><br><span class="line">    image: kubernetes/redis:v1</span><br><span class="line">    env:</span><br><span class="line">    - name: MASTER</span><br><span class="line">      value: &quot;true&quot;</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 6379</span><br><span class="line">    resources:</span><br><span class="line">      limits:</span><br><span class="line">        cpu: &quot;0.1&quot;</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /redis-master-data</span><br><span class="line">      name: data</span><br><span class="line">    - mountPath: /redis-master</span><br><span class="line">      name: config</span><br><span class="line">  volumes:</span><br><span class="line">    - name: data</span><br><span class="line">      emptyDir: &#123;&#125;</span><br><span class="line">    - name: config</span><br><span class="line">      configMap:</span><br><span class="line">        name: redis-config</span><br><span class="line">        items:</span><br><span class="line">        - key: redis-config</span><br><span class="line">          path: redis.conf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#创建pod</span><br><span class="line">kubectl create -f /etc/k8s/pods/config/redis-pod.yaml</span><br><span class="line"></span><br><span class="line">kubectl exec -it redis redis-cli</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h2 id="无状态应用程序"><a href="#无状态应用程序" class="headerlink" title="无状态应用程序"></a>无状态应用程序</h2><p>Stateless Applications</p>
<p><br></p>
<h3 id="公开外物IP以访问集群中的应用程序"><a href="#公开外物IP以访问集群中的应用程序" class="headerlink" title="公开外物IP以访问集群中的应用程序"></a>公开外物IP以访问集群中的应用程序</h3><p>Exposing an External IP Address to Access an Application in a Cluster</p>
<p><strong>目标</strong></p>
<ul>
<li>为一个Hello World应用程序运行五个实例</li>
<li>创建一个展示外部IP的服务对象</li>
<li>使用服务对象去访问运行的应用程序</li>
</ul>
<p><br></p>
<p><strong>为运行五个pods的应用程序创建一个服务</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#运行hello world</span><br><span class="line">kubectl run hello-world --replicas=5 --labels=&quot;run=load-balancer-example&quot; --image=gcr.io/google-samples/node-hello:1.0  --port=8080</span><br><span class="line">#--image=docker.io/jocatalin/hellonode:v1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#查看信息</span><br><span class="line">kubectl get deployments hello-world</span><br><span class="line">kubectl describe deployments hello-world</span><br><span class="line"></span><br><span class="line">kubectl get replicasets</span><br><span class="line">kubectl describe replicasets</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#创建展示部署的服务对象</span><br><span class="line">kubectl expose deployment hello-world --type=LoadBalancer --name=my-service</span><br><span class="line">#如果外部地址显示为pending，请等待几分钟</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#查看信息</span><br><span class="line">kubectl get services my-service</span><br><span class="line">kubectl describe services my-service</span><br><span class="line">#可看到LoanBlancer Ingress</span><br><span class="line"></span><br><span class="line">kubectl get pods --output=wide</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#访问外部地址(LoadBalancer Ingress)</span><br><span class="line">curl http://&lt;external-ip&gt;:&lt;port&gt;</span><br></pre></td></tr></table></figure>
<p><br></p>
<p><strong>清理</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#删除服务</span><br><span class="line">kubectl delete services my-service</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#删除正在运行的程序的Deployment，ReplicaSet，Pods</span><br><span class="line">kubectl delete deployment hello-world</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<hr>
<p><br></p>
<h1 id="状态集应用程序"><a href="#状态集应用程序" class="headerlink" title="状态集应用程序"></a>状态集应用程序</h1><p>StatefulSet Basics</p>
<p><br></p>
<hr>
<p><br><br><br></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Kubernetes/" rel="tag"># Kubernetes</a>
          
            <a href="/tags/k8s/" rel="tag"># k8s</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/05/14/性能分析/" rel="next" title="性能分析">
                <i class="fa fa-chevron-left"></i> 性能分析
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/07/19/Fluentd/" rel="prev" title="Fluentd">
                Fluentd <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          
            <img class="site-author-image" itemprop="image"
              src="/images/leslie.jpg"
              alt="Zhang21" />
          
            <p class="site-author-name" itemprop="name">Zhang21</p>
            <p class="site-description motion-element" itemprop="description">踏踏实实谋发展</p>
        </div>

        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
            
              <a href="/archives/">
            
                <span class="site-state-item-count">42</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">9</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">50</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="http://www.jianshu.com/u/f13278e94ecb" target="_blank" title="简书">
                  
                    <i class="fa fa-fw fa-circle-o"></i>简书</a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://github.com/Zhang21" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>GitHub</a>
              </span>
            
              <span class="links-of-author-item">
                <a href="mailto:elite_zhang21@163.com" target="_blank" title="E-Mail">
                  
                    <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://instagram.com/Zhang21_" target="_blank" title="Instagram">
                  
                    <i class="fa fa-fw fa-instagram"></i>Instagram</a>
              </span>
            
          
        </div>

        
        

        
        
<br>
<!--����������������ⲿ����,auto=1��ʾ�Զ�����-->
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=411315632&auto=0&height=66"></iframe>


        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#配置"><span class="nav-number">1.</span> <span class="nav-text">配置</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#安装"><span class="nav-number">1.1.</span> <span class="nav-text">安装</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#使用minikube创建集群"><span class="nav-number">1.1.1.</span> <span class="nav-text">使用minikube创建集群</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubeadm创建集群"><span class="nav-number">1.1.2.</span> <span class="nav-text">kubeadm创建集群</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#安装kubeadm"><span class="nav-number">1.1.2.1.</span> <span class="nav-text">安装kubeadm</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#拉取k8s-gcr-io镜像"><span class="nav-number">1.1.2.2.</span> <span class="nav-text">拉取k8s.gcr.io镜像</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建单master集群"><span class="nav-number">1.1.2.3.</span> <span class="nav-text">创建单master集群</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用kubeadm配置kubelet"><span class="nav-number">1.1.2.4.</span> <span class="nav-text">使用kubeadm配置kubelet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用kubeadm自定义控制面板配置"><span class="nav-number">1.1.2.5.</span> <span class="nav-text">使用kubeadm自定义控制面板配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用kubeadm创建高可用集群"><span class="nav-number">1.1.2.6.</span> <span class="nav-text">使用kubeadm创建高可用集群</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用kubeadm配置etcd高可用集群"><span class="nav-number">1.1.2.7.</span> <span class="nav-text">使用kubeadm配置etcd高可用集群</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Troubleshooting-kubeadm"><span class="nav-number">1.1.2.8.</span> <span class="nav-text">Troubleshooting kubeadm</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用软件包创建集群"><span class="nav-number">1.1.3.</span> <span class="nav-text">使用软件包创建集群</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#k8s-release生成rpm包"><span class="nav-number">1.1.4.</span> <span class="nav-text">k8s-release生成rpm包</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#编译源码生成rpm包"><span class="nav-number">1.1.5.</span> <span class="nav-text">编译源码生成rpm包</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#k8s-Dashboard"><span class="nav-number">1.1.6.</span> <span class="nav-text">k8s Dashboard</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#快速配置"><span class="nav-number">1.1.6.1.</span> <span class="nav-text">快速配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#安装-1"><span class="nav-number">1.1.6.2.</span> <span class="nav-text">安装</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#证书管理"><span class="nav-number">1.1.6.3.</span> <span class="nav-text">证书管理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#访问Dashboard"><span class="nav-number">1.1.6.4.</span> <span class="nav-text">访问Dashboard</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-7-x-and-above"><span class="nav-number">1.1.6.4.1.</span> <span class="nav-text">1.7.x and above</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Nginx反向代理"><span class="nav-number">1.1.6.5.</span> <span class="nav-text">Nginx反向代理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#访问控制"><span class="nav-number">1.1.6.6.</span> <span class="nav-text">访问控制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建示例用户"><span class="nav-number">1.1.6.7.</span> <span class="nav-text">创建示例用户</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Heapster"><span class="nav-number">1.1.7.</span> <span class="nav-text">Heapster</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#metric-server"><span class="nav-number">1.1.8.</span> <span class="nav-text">metric-server</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pause容器"><span class="nav-number">1.2.</span> <span class="nav-text">pause容器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#构建大型集群"><span class="nav-number">1.3.</span> <span class="nav-text">构建大型集群</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用salt配置k8s"><span class="nav-number">1.4.</span> <span class="nav-text">使用salt配置k8s</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#验证节点配置"><span class="nav-number">1.5.</span> <span class="nav-text">验证节点配置</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#概念"><span class="nav-number">2.</span> <span class="nav-text">概念</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#标准词汇"><span class="nav-number">2.1.</span> <span class="nav-text">标准词汇</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#概述"><span class="nav-number">2.2.</span> <span class="nav-text">概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#K8s是什么"><span class="nav-number">2.2.1.</span> <span class="nav-text">K8s是什么</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#k8s组件"><span class="nav-number">2.2.2.</span> <span class="nav-text">k8s组件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Master组件"><span class="nav-number">2.2.2.1.</span> <span class="nav-text">Master组件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Node组件"><span class="nav-number">2.2.2.2.</span> <span class="nav-text">Node组件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Addons"><span class="nav-number">2.2.2.3.</span> <span class="nav-text">Addons</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#k8s-API"><span class="nav-number">2.2.3.</span> <span class="nav-text">k8s API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#k8s-对象"><span class="nav-number">2.2.4.</span> <span class="nav-text">k8s 对象</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#理解k8s对象"><span class="nav-number">2.2.4.1.</span> <span class="nav-text">理解k8s对象</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Names"><span class="nav-number">2.2.4.2.</span> <span class="nav-text">Names</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Namespace"><span class="nav-number">2.2.4.3.</span> <span class="nav-text">Namespace</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Labels和Selectors"><span class="nav-number">2.2.4.4.</span> <span class="nav-text">Labels和Selectors</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Annotation"><span class="nav-number">2.2.4.5.</span> <span class="nav-text">Annotation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Field-Selectors"><span class="nav-number">2.2.4.6.</span> <span class="nav-text">Field Selectors</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Recommended-Labels"><span class="nav-number">2.2.4.7.</span> <span class="nav-text">Recommended Labels</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用kubectl进行对象管理"><span class="nav-number">2.2.5.</span> <span class="nav-text">使用kubectl进行对象管理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#必要的命令"><span class="nav-number">2.2.5.1.</span> <span class="nav-text">必要的命令</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#创建对象"><span class="nav-number">2.2.5.1.1.</span> <span class="nav-text">创建对象</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#更新对象"><span class="nav-number">2.2.5.1.2.</span> <span class="nav-text">更新对象</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#删除对象"><span class="nav-number">2.2.5.1.3.</span> <span class="nav-text">删除对象</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#查看对象"><span class="nav-number">2.2.5.1.4.</span> <span class="nav-text">查看对象</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#创建对象前修改对象"><span class="nav-number">2.2.5.1.5.</span> <span class="nav-text">创建对象前修改对象</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#配置文件"><span class="nav-number">2.2.5.2.</span> <span class="nav-text">配置文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用配置文件声明管理的k8s对象"><span class="nav-number">2.2.5.3.</span> <span class="nav-text">使用配置文件声明管理的k8s对象</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#创建对象-1"><span class="nav-number">2.2.5.3.1.</span> <span class="nav-text">创建对象</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#更新对象-1"><span class="nav-number">2.2.5.3.2.</span> <span class="nav-text">更新对象</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#删除对象-1"><span class="nav-number">2.2.5.3.3.</span> <span class="nav-text">删除对象</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#查看对象-1"><span class="nav-number">2.2.5.3.4.</span> <span class="nav-text">查看对象</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#计算-存储和网络"><span class="nav-number">2.3.</span> <span class="nav-text">计算,存储和网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#集群管理"><span class="nav-number">2.3.1.</span> <span class="nav-text">集群管理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#证书"><span class="nav-number">2.3.2.</span> <span class="nav-text">证书</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#openssl"><span class="nav-number">2.3.2.1.</span> <span class="nav-text">openssl</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#easyrsa"><span class="nav-number">2.3.2.2.</span> <span class="nav-text">easyrsa</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#cfssl"><span class="nav-number">2.3.2.3.</span> <span class="nav-text">cfssl</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#分发自签名CA证书"><span class="nav-number">2.3.2.4.</span> <span class="nav-text">分发自签名CA证书</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#云提供商"><span class="nav-number">2.3.3.</span> <span class="nav-text">云提供商</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#管理资源"><span class="nav-number">2.3.4.</span> <span class="nav-text">管理资源</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#组织资源配置"><span class="nav-number">2.3.4.1.</span> <span class="nav-text">组织资源配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#kubectl批量操作"><span class="nav-number">2.3.4.2.</span> <span class="nav-text">kubectl批量操作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#高效使用label"><span class="nav-number">2.3.4.3.</span> <span class="nav-text">高效使用label</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Canary-deployments"><span class="nav-number">2.3.4.4.</span> <span class="nav-text">Canary deployments</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#更新标签"><span class="nav-number">2.3.4.5.</span> <span class="nav-text">更新标签</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#更新注释"><span class="nav-number">2.3.4.6.</span> <span class="nav-text">更新注释</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#伸缩应用程序"><span class="nav-number">2.3.4.7.</span> <span class="nav-text">伸缩应用程序</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#就地更新资源"><span class="nav-number">2.3.4.8.</span> <span class="nav-text">就地更新资源</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#破坏性更新"><span class="nav-number">2.3.4.9.</span> <span class="nav-text">破坏性更新</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#在服务没有中断的情况下更新应用程序"><span class="nav-number">2.3.4.10.</span> <span class="nav-text">在服务没有中断的情况下更新应用程序</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#集群网络"><span class="nav-number">2.3.5.</span> <span class="nav-text">集群网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Docker模型"><span class="nav-number">2.3.5.1.</span> <span class="nav-text">Docker模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#k8s模型"><span class="nav-number">2.3.5.2.</span> <span class="nav-text">k8s模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#如何实现k8s网络模型"><span class="nav-number">2.3.5.3.</span> <span class="nav-text">如何实现k8s网络模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#日志架构"><span class="nav-number">2.3.6.</span> <span class="nav-text">日志架构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#k8s基本日志"><span class="nav-number">2.3.6.1.</span> <span class="nav-text">k8s基本日志</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#节点级日志记录"><span class="nav-number">2.3.6.2.</span> <span class="nav-text">节点级日志记录</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#集群级日志架构"><span class="nav-number">2.3.6.3.</span> <span class="nav-text">集群级日志架构</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubelet垃圾回收"><span class="nav-number">2.3.7.</span> <span class="nav-text">kubelet垃圾回收</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#镜像回收"><span class="nav-number">2.3.7.1.</span> <span class="nav-text">镜像回收</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#容器回收"><span class="nav-number">2.3.7.2.</span> <span class="nav-text">容器回收</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#启用"><span class="nav-number">2.3.7.3.</span> <span class="nav-text">启用</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Federation"><span class="nav-number">2.3.8.</span> <span class="nav-text">Federation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Proxy"><span class="nav-number">2.3.9.</span> <span class="nav-text">Proxy</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#kubectl-proxy"><span class="nav-number">2.3.9.1.</span> <span class="nav-text">kubectl proxy</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#apiserver-proxy"><span class="nav-number">2.3.9.2.</span> <span class="nav-text">apiserver proxy</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#kube-proxy"><span class="nav-number">2.3.9.3.</span> <span class="nav-text">kube proxy</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#A-Proxy-Load-balancer-in-front-of-apiserver"><span class="nav-number">2.3.9.4.</span> <span class="nav-text">A Proxy/Load-balancer in front of apiserver</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#云负载均衡器"><span class="nav-number">2.3.9.5.</span> <span class="nav-text">云负载均衡器</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#控制器管理器指标"><span class="nav-number">2.3.10.</span> <span class="nav-text">控制器管理器指标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#附加组件"><span class="nav-number">2.3.11.</span> <span class="nav-text">附加组件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#网络和网络策略"><span class="nav-number">2.3.11.1.</span> <span class="nav-text">网络和网络策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#服务发现"><span class="nav-number">2.3.11.2.</span> <span class="nav-text">服务发现</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#可视化，控制"><span class="nav-number">2.3.11.3.</span> <span class="nav-text">可视化，控制</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#k8s架构"><span class="nav-number">2.4.</span> <span class="nav-text">k8s架构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Node"><span class="nav-number">2.4.1.</span> <span class="nav-text">Node</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#节点状态"><span class="nav-number">2.4.1.1.</span> <span class="nav-text">节点状态</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#管理"><span class="nav-number">2.4.1.2.</span> <span class="nav-text">管理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#API对象"><span class="nav-number">2.4.1.3.</span> <span class="nav-text">API对象</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#节点通信"><span class="nav-number">2.4.2.</span> <span class="nav-text">节点通信</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Cluster-gt-Master"><span class="nav-number">2.4.2.1.</span> <span class="nav-text">Cluster-&gt;Master</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Master-gt-Cluster"><span class="nav-number">2.4.2.2.</span> <span class="nav-text">Master-&gt;Cluster</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#云控制器管理器"><span class="nav-number">2.4.3.</span> <span class="nav-text">云控制器管理器</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#扩展k8s"><span class="nav-number">2.5.</span> <span class="nav-text">扩展k8s</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#扩展k8s集群"><span class="nav-number">2.5.1.</span> <span class="nav-text">扩展k8s集群</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#扩展模式"><span class="nav-number">2.5.1.1.</span> <span class="nav-text">扩展模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#扩展点"><span class="nav-number">2.5.1.2.</span> <span class="nav-text">扩展点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#API扩展"><span class="nav-number">2.5.1.3.</span> <span class="nav-text">API扩展</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#基础设施扩展"><span class="nav-number">2.5.1.4.</span> <span class="nav-text">基础设施扩展</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#扩展k8s-API"><span class="nav-number">2.5.2.</span> <span class="nav-text">扩展k8s API</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#在聚合层扩展k8s-API"><span class="nav-number">2.5.2.1.</span> <span class="nav-text">在聚合层扩展k8s API</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#自定义资源"><span class="nav-number">2.5.2.2.</span> <span class="nav-text">自定义资源</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#计算，存储和网络插件"><span class="nav-number">2.5.3.</span> <span class="nav-text">计算，存储和网络插件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#网络插件"><span class="nav-number">2.5.3.1.</span> <span class="nav-text">网络插件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#设备插件"><span class="nav-number">2.5.3.2.</span> <span class="nav-text">设备插件</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#服务目录"><span class="nav-number">2.5.4.</span> <span class="nav-text">服务目录</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Containers"><span class="nav-number">2.6.</span> <span class="nav-text">Containers</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Images"><span class="nav-number">2.6.1.</span> <span class="nav-text">Images</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#容器环境变量"><span class="nav-number">2.6.2.</span> <span class="nav-text">容器环境变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#容器生命周期钩子"><span class="nav-number">2.6.3.</span> <span class="nav-text">容器生命周期钩子</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#容器钩子"><span class="nav-number">2.6.3.1.</span> <span class="nav-text">容器钩子</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#工作负载"><span class="nav-number">2.7.</span> <span class="nav-text">工作负载</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Pods"><span class="nav-number">2.7.1.</span> <span class="nav-text">Pods</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Pod"><span class="nav-number">2.7.1.1.</span> <span class="nav-text">Pod</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Pod生命周期"><span class="nav-number">2.7.1.2.</span> <span class="nav-text">Pod生命周期</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Init-Containers"><span class="nav-number">2.7.1.3.</span> <span class="nav-text">Init Containers</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Pod预设"><span class="nav-number">2.7.1.4.</span> <span class="nav-text">Pod预设</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#中断"><span class="nav-number">2.7.1.5.</span> <span class="nav-text">中断</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Controller"><span class="nav-number">2.7.2.</span> <span class="nav-text">Controller</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ReplicaSet"><span class="nav-number">2.7.2.1.</span> <span class="nav-text">ReplicaSet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ReplicationController"><span class="nav-number">2.7.2.2.</span> <span class="nav-text">ReplicationController</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Deployments"><span class="nav-number">2.7.2.3.</span> <span class="nav-text">Deployments</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#StatefulSets"><span class="nav-number">2.7.2.4.</span> <span class="nav-text">StatefulSets</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DaemonSet"><span class="nav-number">2.7.2.5.</span> <span class="nav-text">DaemonSet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#垃圾回收"><span class="nav-number">2.7.2.6.</span> <span class="nav-text">垃圾回收</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Jobs"><span class="nav-number">2.7.2.7.</span> <span class="nav-text">Jobs</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CronJob"><span class="nav-number">2.7.2.8.</span> <span class="nav-text">CronJob</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#配置-1"><span class="nav-number">2.8.</span> <span class="nav-text">配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#配置最佳实践"><span class="nav-number">2.8.1.</span> <span class="nav-text">配置最佳实践</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#一般配置技巧"><span class="nav-number">2.8.1.1.</span> <span class="nav-text">一般配置技巧</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Naked-Pod-vs-副本集，部署和作业"><span class="nav-number">2.8.1.2.</span> <span class="nav-text">Naked Pod vs 副本集，部署和作业</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#服务"><span class="nav-number">2.8.1.3.</span> <span class="nav-text">服务</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用标签"><span class="nav-number">2.8.1.4.</span> <span class="nav-text">使用标签</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#容器镜像"><span class="nav-number">2.8.1.5.</span> <span class="nav-text">容器镜像</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用kubectl"><span class="nav-number">2.8.1.6.</span> <span class="nav-text">使用kubectl</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#管理容器的计算资源"><span class="nav-number">2.8.2.</span> <span class="nav-text">管理容器的计算资源</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#资源类型"><span class="nav-number">2.8.2.1.</span> <span class="nav-text">资源类型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#资源的请求和限制"><span class="nav-number">2.8.2.2.</span> <span class="nav-text">资源的请求和限制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CPU"><span class="nav-number">2.8.2.3.</span> <span class="nav-text">CPU</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Memory"><span class="nav-number">2.8.2.4.</span> <span class="nav-text">Memory</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#如何调度具有资源请求的Pod"><span class="nav-number">2.8.2.5.</span> <span class="nav-text">如何调度具有资源请求的Pod</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#如何运行具有资源限制的Pod"><span class="nav-number">2.8.2.6.</span> <span class="nav-text">如何运行具有资源限制的Pod</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#监控计算资源使用"><span class="nav-number">2.8.2.7.</span> <span class="nav-text">监控计算资源使用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#本地短暂存储"><span class="nav-number">2.8.2.8.</span> <span class="nav-text">本地短暂存储</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#扩展的资源"><span class="nav-number">2.8.2.9.</span> <span class="nav-text">扩展的资源</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分配Pod到节点"><span class="nav-number">2.8.3.</span> <span class="nav-text">分配Pod到节点</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#节点选择器"><span class="nav-number">2.8.3.1.</span> <span class="nav-text">节点选择器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#内置节点标签"><span class="nav-number">2.8.3.2.</span> <span class="nav-text">内置节点标签</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#亲和力和反亲和力"><span class="nav-number">2.8.3.3.</span> <span class="nav-text">亲和力和反亲和力</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#污点和容忍"><span class="nav-number">2.8.4.</span> <span class="nav-text">污点和容忍</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#服务，负载均衡和网络"><span class="nav-number">2.9.</span> <span class="nav-text">服务，负载均衡和网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#存储"><span class="nav-number">2.10.</span> <span class="nav-text">存储</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Volumes"><span class="nav-number">2.10.1.</span> <span class="nav-text">Volumes</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Background"><span class="nav-number">2.10.1.1.</span> <span class="nav-text">Background</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#卷类型"><span class="nav-number">2.10.1.2.</span> <span class="nav-text">卷类型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用子路径"><span class="nav-number">2.10.1.3.</span> <span class="nav-text">使用子路径</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#资源"><span class="nav-number">2.10.1.4.</span> <span class="nav-text">资源</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#持久化卷"><span class="nav-number">2.10.2.</span> <span class="nav-text">持久化卷</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#垃圾收集"><span class="nav-number">2.11.</span> <span class="nav-text">垃圾收集</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#教程"><span class="nav-number">3.</span> <span class="nav-text">教程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#k8s基本"><span class="nav-number">3.1.</span> <span class="nav-text">k8s基本</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#综述"><span class="nav-number">3.1.1.</span> <span class="nav-text">综述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建集群"><span class="nav-number">3.1.2.</span> <span class="nav-text">创建集群</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#部署应用程序"><span class="nav-number">3.1.3.</span> <span class="nav-text">部署应用程序</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#使用kubectl创建部署"><span class="nav-number">3.1.3.1.</span> <span class="nav-text">使用kubectl创建部署</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#探索应用程序"><span class="nav-number">3.1.4.</span> <span class="nav-text">探索应用程序</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#查看Pods和Nodes"><span class="nav-number">3.1.4.1.</span> <span class="nav-text">查看Pods和Nodes</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#公开展示应用程序"><span class="nav-number">3.1.5.</span> <span class="nav-text">公开展示应用程序</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#使用服务来展示应用程序"><span class="nav-number">3.1.5.1.</span> <span class="nav-text">使用服务来展示应用程序</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#扩展应用程序"><span class="nav-number">3.1.6.</span> <span class="nav-text">扩展应用程序</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#升级应用程序"><span class="nav-number">3.1.7.</span> <span class="nav-text">升级应用程序</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#配置-2"><span class="nav-number">3.2.</span> <span class="nav-text">配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#使用ConfigMap配置Redis"><span class="nav-number">3.2.1.</span> <span class="nav-text">使用ConfigMap配置Redis</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#无状态应用程序"><span class="nav-number">3.3.</span> <span class="nav-text">无状态应用程序</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#公开外物IP以访问集群中的应用程序"><span class="nav-number">3.3.1.</span> <span class="nav-text">公开外物IP以访问集群中的应用程序</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#状态集应用程序"><span class="nav-number">4.</span> <span class="nav-text">状态集应用程序</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2017 &mdash; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhang21</span>

<!--字数统计-->
  <div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count"> 字数: 395.2k</span>
</div>


  
</div>



<!--

  <div class="powered-by">由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动</div>

  <span class="post-meta-divider">|</span>

  <div class="theme-info">主题 &mdash; <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.2</div>

-->


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>


  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  

    
      <script id="dsq-count-scr" src="https://Zhang21.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://zhang21.github.io/2018/06/26/Kubernetes/';
          this.page.identifier = '2018/06/26/Kubernetes/';
          this.page.title = 'Kubernetes';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://Zhang21.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  










  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->





  

  

  

  
  


  

  

</body>
</html>
