<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>风继续吹</title>
  
  <subtitle>Yesterday, you said tomorrow!</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://zhang21.github.io/"/>
  <updated>2019-04-30T09:32:38.000Z</updated>
  <id>https://zhang21.github.io/</id>
  
  <author>
    <name>Zhang21</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>OSTEP</title>
    <link href="https://zhang21.github.io/2019/04/28/OSThreeEasyPieces/"/>
    <id>https://zhang21.github.io/2019/04/28/OSThreeEasyPieces/</id>
    <published>2019-04-28T00:59:12.000Z</published>
    <updated>2019-04-30T09:32:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>OS Three Easy Pieces: <a href="https://book.douban.com/subject/19973015/" target="_blank" rel="noopener">https://book.douban.com/subject/19973015/</a></li><li>OSTEP: <a href="http://pages.cs.wisc.edu/~remzi/OSTEP/" target="_blank" rel="noopener">http://pages.cs.wisc.edu/~remzi/OSTEP/</a></li></ul><p><br></p><p>环境:</p><ul><li>ELRH7x86_64</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="操作系统介绍"><a href="#操作系统介绍" class="headerlink" title="操作系统介绍"></a>操作系统介绍</h1><p>Introduction to Operating Systems</p><p>如果你正在攻读本科操作系统课程，你应该已经知道计算机程序运行时的想法。如果没有，这本书将很难。</p><p>那么，程序运行时会发生什么呢？<br>好吧，正在运行的程序做了一件非常简单的事情: <strong>它执行指令(it executes instructions)</strong>。<br>每秒都有成千上万次，处理器从内存(mem)中取出(fetch)指令，对其进行解码(decode)——即确定这是哪条指令，并执行它。完成此指令后，进程将继续执行下一条指令，以此类推，直到程序最终完成。</p><p>刚刚描述了<strong>冯-诺依曼计算模型(Von Neumann model of computing)</strong>的基础知识。在本书中，我们将学习在程序运行的同时，还有许多其它的东西在运行，其主要目标是使系统易于使用。</p><p>事实上，有一大堆软件负责使应用程序运行变得容易，允许程序共享内存(share mem)，使程序与设备交互…该软件主体称为<strong>操作系统(Operating System)</strong>，它负责确保系统操作以易于使用的方式正确有效地运行。</p><p>操作系统执行此操作的主要方式是通过我们称为<strong>虚拟化(Virtualization)</strong>的通用技术。也就是说，操作系统采用<strong>物理资源(Physical Resource)</strong>(如处理器，内存，磁盘)并将其转换为更通用，功能强大且易于使用的虚拟形式。因此，我们有时将操作系统称为<strong>虚拟机(Virtual Machine)</strong>。</p><blockquote><p><strong>问题的关键: 如何虚拟化资源</strong><br>本书的一个核心问题：操作系统如何虚拟化资源？操作系统为什么要虚拟化资源——它使得系统更易于使用。因此，我们关注：操作系统使用什么机制和策略来实现虚拟化？操作系统如何有效地进行操作？需要什么硬件支持？</p></blockquote><p><br></p><p>当然，为了告诉用户操作系统做什么，从而利用虚拟机的功能(如运行程序、分配内存、访问文件…)，操作系统还提供了一些可调用的接口(API)。事实上，典型的操作系统会<strong>导出(Export)</strong>数百个可供应用程序访问的<strong>系统调用(System Call)</strong>。<br>由于操作系统提供这些系统调用来运行程序、访问内存和设备、以及其它相关操作，有时也会说操作系统为应用程序提供了一个<strong>标准库(Standard Library)</strong>。</p><p>最后，因为虚拟化允许多个程序运行(共享CPU)，并且许多程序同时(Concurrently)访问它们自己的指令和数据(共享内存)，以及许多程序访问设备(共享磁盘等)，操作系统有时被称为<strong>资源管理器(Resource Manager)</strong>。每个CPU、MEM、DISK都是系统的资源。因此，操作系统的角色是管理这些资源，有效或公平地执行。</p><p><br><br><br></p><h2 id="虚拟化CPU"><a href="#虚拟化CPU" class="headerlink" title="虚拟化CPU"></a>虚拟化CPU</h2><p>Virtualizing the CPU</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Code That Loops and Prints (cpu.c)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/time.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;assert.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"common.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span></span><br><span class="line">main(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (argc != <span class="number">2</span>) &#123;</span><br><span class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"usage: cpu &lt;string&gt;\n"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">char</span> *str = argv[<span class="number">1</span>];</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">        Spin(<span class="number">1</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%s\n"</span>, str);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br></p><p>上图的程序，它所做的只是调用<code>Spin()</code>——这是一个重复检查时间的函数。<br>接下来我们具有单个处理器的系统上编译和运行它:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 编译</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 此处遇到两个错误</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 1. cpu.c:(.text+0xe0)：对‘pthread_create’未定义的引用</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2. cpu.c:(.text+0x127)：对‘pthread_join’未定义的引用</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 网上方法: 在编译时需要添加 -lpthread 参数来使用 libpthread.a 库进行编译</span></span><br><span class="line">gcc -o cpu cpu.c -Wall -lpthread</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 运行</span></span><br><span class="line">./cpu "ABC"</span><br><span class="line">ABC</span><br><span class="line">ABC</span><br><span class="line">...</span><br><span class="line"><span class="meta">#</span><span class="bash"> 需手动终止</span></span><br><span class="line">Ctrl+C</span><br></pre></td></tr></table></figure><p><br></p><p>现在让程序复杂一点:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">./cpu A &amp;  ./cpu B &amp;  ./cpu C &amp;  ./cpu D &amp;</span><br><span class="line"></span><br><span class="line">[1] 7353</span><br><span class="line">[2] 7354</span><br><span class="line">[3] 7355</span><br><span class="line">[4] 7356</span><br><span class="line">A</span><br><span class="line">B</span><br><span class="line">D</span><br><span class="line">C</span><br><span class="line">A</span><br><span class="line">B</span><br><span class="line">D</span><br><span class="line">C</span><br><span class="line">A</span><br><span class="line">C</span><br><span class="line">B</span><br><span class="line">D</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>现在事情变得更有趣了。即使只有一个处理器，但不知何故，所有四个程序都在同时运行！这种魔力是如何发生的呢？</p><p>事实证明，操作系统在硬件的帮助下负责这种<strong>错觉(illusion)</strong>——即系统具有大量虚拟CPU的错觉。将单个CPU转换为看似无限数量的CPU，从而允许许多程序看起来像是一次运行，这就是我们所说的虚拟化CPU，这是本书第一部分的重点。</p><p>当然，要运行程序并停止它，以及告诉操作系统运行哪些程序，需要使用一些接口(API)来将你的需求传递给操作系统。实际上，它们是大多数用于与操作系统交互的主要方式。</p><p>你可能还注意到，一次运行多个程序会引发各种新问题。如，如果两个程序需要在特定时间运行，哪个应该运行。这些问题由操作系统的策略来回答，策略在操作系统中的许多不同位置用户回答这些类型的问题。</p><p><br><br><br></p><h2 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h2><p>Virtualizing Memory</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A Program that Accesses Memory (mem.c)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"common.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span></span><br><span class="line">main(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">int</span> *p = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">int</span>)); <span class="comment">// a1</span></span><br><span class="line">    assert(p != <span class="literal">NULL</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"(%d) memory address of p: %08x\n"</span>,</span><br><span class="line">        getpid(), (<span class="keyword">unsigned</span>) p); <span class="comment">// a2</span></span><br><span class="line">    *p = <span class="number">0</span>; <span class="comment">// a3</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">        Spin(<span class="number">1</span>);</span><br><span class="line">        *p = *p + <span class="number">1</span>;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"(%d) p: %d\n"</span>, getpid(), *p); <span class="comment">// a4</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br></p><p>现在让我们考虑一下<strong>内存(memory)</strong>。现代机器提供的物理内存的模型非常简单。内存只是一个<strong>字节数组(a array of bytes)</strong>。要读取内存，必须指定一个地址才能访问存储在那里的数据。要写入或更新(write/update)内存，还必须指定要写入数据的给定地址。</p><p>程序运行时始终访问内存。程序的所有数据结构保存在内存中，并通过各种指令访问它们，如<code>loads</code>, <code>stores</code>或其它在执行工作时访问内存的显式指令。不要忘记程序的每条指令也在内存中，每次<strong>取(fetch)指令</strong>时访问内存。</p><p>让我们来看下通过调用<code>malloc()</code>来分配一些内存的上面那个程序:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">./mem</span><br><span class="line">(6941) memory address of p: 01f13010</span><br><span class="line">(6941) p: 1</span><br><span class="line">(6941) p: 2</span><br><span class="line">^C</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 该程序做了几件事。首先，它分配一些内存(a1)。然后，它打印出内存的地址(a2)，然后将数字零放入新分配的存储器的第一个插槽(a3)。最后，它循环，延迟1秒并递增存储在p中保存的地址的值。它还打出程序的PID。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Running The Memory Program Multiple Times</span></span><br><span class="line">./mem &amp; ./mem &amp;</span><br><span class="line">[1] 7544</span><br><span class="line">[2] 7545</span><br><span class="line">(7544) memory address of p: 012f3010</span><br><span class="line">(7545) memory address of p: 006cf010</span><br><span class="line">(7544) p: 1</span><br><span class="line">(7545) p: 1</span><br><span class="line">(7544) p: 2</span><br><span class="line">(7545) p: 2</span><br><span class="line">(7544) p: 3</span><br><span class="line">(7545) p: 3</span><br></pre></td></tr></table></figure><p>实际上，这正是这里发生的事情，因为操作系统正在虚拟化内存。每个进程都访问自己的<strong>私有虚拟地址空间(private virtual address space)</strong>(有时也称为地址空间)，操作系统以某种方式将其映射到计算机的物理内存中。一个正在运行的程序中的内存引用不会影响其它进程的地址空间。就运行程序而言，它具有物理内存。然而，现实是物理内存是由操作系统管理的共享资源。</p><p><br><br><br><br><br></p><h2 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h2><p>Concurrency</p><p>本书另一个主题是<strong>并发性(concurrency)</strong>。使用这个术语来指代同一程序中同时处理多个事件(即并发)。并发问题首先出现在操作系统自身，如前面的虚拟化程序，操作系统同时处理多个事情。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// AMulti-threaded Program (threads.c)</span></span><br><span class="line"></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"common.h"</span></span></span><br><span class="line"></span><br><span class="line"> <span class="keyword">volatile</span> <span class="keyword">int</span> counter = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">int</span> loops;</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">void</span> *<span class="title">worker</span><span class="params">(<span class="keyword">void</span> *arg)</span> </span>&#123;</span><br><span class="line">     <span class="keyword">int</span> i;</span><br><span class="line">     <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; loops; i++) &#123;</span><br><span class="line">         counter++;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">int</span></span><br><span class="line"> main(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span><br><span class="line"> &#123;</span><br><span class="line">     <span class="keyword">if</span> (argc != <span class="number">2</span>) &#123;</span><br><span class="line">     <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"usage: threads &lt;value&gt;\n"</span>);</span><br><span class="line">     <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">     &#125;</span><br><span class="line">     loops = atoi(argv[<span class="number">1</span>]);</span><br><span class="line">     <span class="keyword">pthread_t</span> p1, p2;</span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">"Initial value : %d\n"</span>, counter);</span><br><span class="line"></span><br><span class="line">     Pthread_create(&amp;p1, <span class="literal">NULL</span>, worker, <span class="literal">NULL</span>);</span><br><span class="line">     Pthread_create(&amp;p2, <span class="literal">NULL</span>, worker, <span class="literal">NULL</span>);</span><br><span class="line">     Pthread_join(p1, <span class="literal">NULL</span>);</span><br><span class="line">     Pthread_join(p2, <span class="literal">NULL</span>);</span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">"Final value : %d\n"</span>, counter);</span><br><span class="line">     <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// &gt;本程序使用Pthread create()创建两个线程</span></span><br><span class="line"><span class="comment">// 你可将线程视为与其它函数相同的内存空间中运行的函数，一次使用多个函数</span></span><br></pre></td></tr></table></figure><p><br></p><blockquote><p><strong>如何构建正确的并发程序?</strong><br>当同一个内存空间中有许多并发执行的线程时，我们如何构建一个正常工作的程序？操作系统需要哪些原语？硬件提供哪些机制？如何使用它们来解决并发问题？</p></blockquote><p><br></p><p>运行:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">./threads</span><br><span class="line">usage: threads &lt;value&gt;</span><br><span class="line"></span><br><span class="line">./threads 1000</span><br><span class="line">Initial value : 0</span><br><span class="line">Final value : 2000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 看看更高的值</span></span><br><span class="line">./threads 10000</span><br><span class="line">Initial value : 0</span><br><span class="line">Final value : 17726</span><br><span class="line"></span><br><span class="line">./threads 10000</span><br><span class="line">Initial value : 0</span><br><span class="line">Final value : 18741</span><br><span class="line"></span><br><span class="line">./threads 10000</span><br><span class="line">Initial value : 0</span><br><span class="line">Final value : 20000</span><br></pre></td></tr></table></figure><p>上面出现了既正常又奇怪的结果。这些结果与指令的执行方式有关。不幸的是，上面程序的一个关键部分，共享计数器递增，需要三个指令：</p><ul><li>一个用于将计数器的值从内存加载到寄存器；</li><li>一个用于递增；</li><li>一个用于将其存储回内存。</li></ul><p>因为这三个指令不是原子地执行(一次全部执行)，所以会发生奇怪的事。</p><p><br><br><br><br><br></p><h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><p>Persistence</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Program That Does I/O (io.c)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;assert.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fcntl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span></span><br><span class="line">main(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">int</span> fd = open(<span class="string">"/tmp/file"</span>, O_WRONLY | O_CREAT | O_TRUNC, S_IRWXU);</span><br><span class="line">    assert(fd &gt; <span class="number">-1</span>);</span><br><span class="line">    <span class="keyword">int</span> rc = write(fd, <span class="string">"hello world\n"</span>, <span class="number">13</span>);</span><br><span class="line">    assert(rc == <span class="number">13</span>);</span><br><span class="line">    close(fd);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br></p><p>第三个主题是<strong>持久化(persistence)</strong>。在系统内存中，数据很容易丢失，因为如DRAM的设备是以易失的方式存储值。当断电或系统奔溃时，内存中的任何数据都会丢失。因此，我们需要硬件和软件能够持久存储数据。硬件以某种I/O设备的形式出现。</p><p>通常，操作系统中管理磁盘的软件被称为<strong>文件系统(file system)</strong>。它负责将用户创建的任何文件以可靠和有效的方式存储在磁盘上。</p><p>与操作系统为CPU何MEM提供的抽象不同，操作系统不回位每个应用程序创建专用的虚拟化磁盘。相反，它假设用户经常想要共享文件中的信息。</p><p>来看下上面的代码，它打开<code>/tmp/file</code>文件，并将<code>hello world</code>写入文件。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./io</span><br><span class="line"></span><br><span class="line">cat /tmp/file</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure></p><p><br></p><blockquote><p><strong>如何持久存储数据？</strong><br>文件系统是负责管理持久化数据的操作系统的一部分。正确地处理需要哪些技术呢？面对硬件和软件故障，如何实现可靠性？</p></blockquote><p>要完成此任务，程序会对操作系统进行三次调用。这些系统调用被路由到称为文件系统的操作系统部分，然后处理请求并向用户返回某种错误代码。</p><ul><li>第一，调用<code>open()</code>打开文件；</li><li>第二，调用<code>write()</code>将数据写入文件；</li><li>第三，调用<code>close()</code>关闭文件。</li></ul><p>你可能想知道操作系统为了写入磁盘而执行的操作。文件系统必须完成相当多的工作，首先确定这些新数据将驻留在磁盘上的哪个位置，然后在文件系统维护的各种结构中跟踪它。这样做需要向底层存储设备发出I/O请求，以读取现有结构或更新它们。<br>任何编写设备驱动程序的人都知道，让设备代表你做某事是一个复杂和详细的过程。它需要深入了解低级设备接口及其确切语义。幸运的是，操作系统提供了一个的标准和简单的方式——通过系统调用(system call)访问设备。因此，操作系统有时被视为<strong>标准库(standard library)</strong>。</p><p>为了处理写入期间系统崩溃的问题，大多数文件系统都包含某种复杂的写入协议。(如journaling或copy-on-write)。仔细写入磁盘以确保在写入序列期间发生故障时，系统之后可以恢复到合理的状态。为了使不同额公共操作高效，文件系统采用许多不同的数据结构和访问方法，从简单的列表到复杂的BTREE。</p><p><br><br><br><br><br></p><h2 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h2><p>Design Goals</p><p>现在我们知道了操作系统实际上做了什么：它使用物理资源(CPU, MEM, DISK…)，并虚拟化它们。它处理与并发相关的棘手的问题。它可以持久存储文件，从而使它们长期安全。最基本的目标是建立一些抽象，以使系统方便和易于使用。抽象是我们计算机科学中所做的一切的基础。</p><p>设计和实现操作系统的一个目标是提供<strong>高性能(High Performance)</strong>；另一个目标是尽量减少操作系统的<strong>开销(overhead)</strong>。虚拟化和使操作系统易于使用是值得的，但不是不惜任何代价。因此，我们必须提供虚拟化和其它操作系统功能，而无需过多开销。这些开销以多种形式出现：额外时间、额外空间。</p><p>另一个目标是在应用程序之间，以及操作系统和应用程序之间提供<strong>保护(Protection)</strong>。由于我们系统多个程序同时运行，所有希望确保每一个程序的恶意或偶然的不良行为不会伤害到其它程序或操作系统。保护操作系统的主要核心原则始操作系统的<strong>隔离(Isolation)</strong>。将进程彼此隔离是保护的关键，因此是操作系统必须做的大部分工作的基础。</p><p>操作系统必须不间断地运行，当它失败时，系统上运行的所有应用程序也会失败。由于这种依赖性，操作系统通常努力提供<strong>高度可靠性(high degree of reliability)</strong>。随着操作系统越来越复杂，构建可靠的操作系统是一个相当大的挑战，这也是一个确切的研究性问题。</p><p>其它目标也是有意义的:</p><ul><li><strong>能源效率</strong>：在绿色世界中越发重要；</li><li><strong>安全</strong>：对恶意应用程序的安全性至关重要；</li><li><strong>可移植性</strong>：随着操作系统在越来越小的设备上运行，可移植性也变得很重要。</li></ul><p><br><br><br><br><br></p><h2 id="一些历史"><a href="#一些历史" class="headerlink" title="一些历史"></a>一些历史</h2><p>Some History</p><p>让我们简单介绍下操作系统的发展过程。与人类构建的任何系统一样，随着时间的推移，操作系统中积累了许多好的想法。</p><p><br></p><h3 id="Early-Operating-Systems-Just-Libraries"><a href="#Early-Operating-Systems-Just-Libraries" class="headerlink" title="Early Operating Systems: Just Libraries"></a>Early Operating Systems: Just Libraries</h3><p>一开始，操作系统并没有做太多。基本上，它只是一组常用函数库(function library)。</p><p>通常，在这些旧的主机系统上，一个程序由人工控制运行一次。许多你认为的现代操作系统将执行的大部分操作是由人工执行的。如果你和操作员很好，则他可以将你的工作移动到队列的前面。<br>这种计算方式称为<strong>批处理(batch processing)</strong>，因为设置了很多作业，然后由人工以批处理的方式运行。到目前为止，计算机并没有以<strong>交互式(interactive)</strong>方式使用。因为成本：让用户坐在电脑面前使用它太昂贵了，因为大多数时候它只是闲置，而每小时需要花费数十万美元。</p><p><br><br><br></p><h3 id="Beyond-Libraries-Protection"><a href="#Beyond-Libraries-Protection" class="headerlink" title="Beyond Libraries: Protection"></a>Beyond Libraries: Protection</h3><p>作为一个简单的常用服务库，操作系统在管理机器方面发挥了中心角色的作用。其中一个重要的方面是认识到运行操作系统自身的代码是特殊的。它控制了设备，因此应该与正常的应用程序代码区别对待。<br>为什么这样？设想一下，如果你允许任何应用程序可以从磁盘的任何地方读取，隐私的概念就会消失，因为任何程序都可以读取任何文件。因此，实现文件系统作为一个库是没有任何意义的。</p><p>因此，<strong>系统调用(system call)</strong>的想法产生了。这里的想法是添加一对特殊的硬件指令和硬件状态，以便将操作系统转换为更正式、受控制的流程，而不是将操作系统例程(routine)作为库提供(你只需要进行过程调用以访问它们)。</p><p><strong>系统调用(system call)</strong>和<strong>过程调用(procedure call)</strong>之间的关键区别在于，系统调用将控制转移到中，同时提高<strong>硬件权限级别(hardware privilege level)</strong>。用户应用程序在所谓的<strong>用户模式(user mode)</strong>下运行，这意味着硬件限制应用程序可以执行的操作。例如，以用户模式运行的应用程序通常不能发起对磁盘的I/O请求，但可以访问物理内存页面或在网络上发送数据包。<br>当启动系统调用时，硬件将控制转移到预先指定的陷阱处理程序(trap handler)，并同时将特权级别提升到<strong>内核模式(kernel mode)</strong>。在内核模式下，操作系统可以完全访问系统的硬件，因此可以执行如启动I/O请求等操作。当操作系统完成对服务的请求时，它通过特殊返回陷阱指令(return-from-trap instrction)将控制权传递给用户，该指令恢复到用户模式，同事将控制权传递回应用程序停止的位置。</p><p><br><br><br></p><h3 id="The-Era-of-Multiprogramming"><a href="#The-Era-of-Multiprogramming" class="headerlink" title="The Era of Multiprogramming"></a>The Era of Multiprogramming</h3><p>操作系统真正起飞的时代是超大型计算时代，即minicomputer时代。成本的下降影响了使用者和开发者，从而使计算机系统更加有趣和美好。</p><p>特别是，由于希望更好地利用机器资源，<strong>多程序设计(multiprogramming)</strong>变得司空见惯。操作系统不是一次只运行一个作业，而是将大量作业加载到内存中并在它们之间快速切换，从而提高CPU利用率。这种切换特别重要，因为I/O设备很慢，而CPU很快。在I/O正在服务时让CPU等待程序是在浪费CPU时间。相反，为什么不切换到另一个工作运行呢？</p><p>在存在I/O和中断的情况下支持多程序设计和重叠的愿望迫使操作系统的概念开发沿着多个方向进行创新。内存保存等问题变得很重要，我们不希望一个程序能够访问另一个程序的内存。了解如何处理多程序设计引入的并发问题也很关键，尽管存在中断，确保操作系统正常运行是一项巨大的挑战。</p><p>当时一个主要的进步是Unix操作系统的引入。Unix从不同的操作系统获得了很多好主意，但使它们更简单易用。很快，这个团队向世界各地的人们发送了包含Unix源代码的磁带，随后有许多人加入到了这个项目中来。</p><p><br><br><br></p><h3 id="The-Modern-Era"><a href="#The-Modern-Era" class="headerlink" title="The Modern Era"></a>The Modern Era</h3><p>除了minicomputer之外，还出现了一种更便宜、速度更快的新机器，我们今天称之为PC(personal computer)。</p><p>不幸的是，对于操作系统而言，PC最初代表了一个巨大的飞跃，因为早期的系统忘记了在minicomputer时代学到的经验教训。例如，早期的操作系统，如DOS(the Disk Operating System, from Microsoft)，并不认为内存保护很重要。因此，恶意(或编程不佳)的应用程序可能会乱写内存。第一代Mac OS采用合作方式进行作业调度。因此，一个意外陷入无限循环的线程可以接管整个系统，迫使重启。这一代系统中缺少的操作系统功能的痛苦太多了…</p><p>幸运的是，经过几年的苦难，微机操作系统的旧功能开始找到它们的方式进入桌面系统。例如，Mac OS X/Mac OS的核心是Unix，包含了人们对这种成熟系统所期望的所有功能。Windows同样采用了计算历史中的许多好主意，特别是从Windows NT开始，这是Microsoft OS技术的一次重大飞跃。即便是今天的手机也运行这操作系统(如Linux)，这些操作系统更像是1970s年代的微型机，而不是1980s年代的PC。</p><p><br></p><blockquote><p>旁白：<strong>Unix的重要性</strong><br>在操作系统的历史中，很难夸大Unix的重要性。受其它早期系统的影响，Unix汇集了许多伟大的想法，并使得系统既简单又强大。<br>贝尔实验室的基础Unix是构建小型且强大程序的统一原则，这些程序可以连接在一起形成更大的工作流。shell提供了mete-level programing，当你输入命令，它将程序串联起来以完成更大的任务变得很容易。<br>Unix环境对编程人员和开发人员都很友好，同时也为C编程语言提供了编译器。编程人员可以轻松编写自己的程序并共享它们，这使得Unix非常受欢迎。它还是免费的。<br>同样重要的是代码的可读性和可访问性。拥有一个用C编写的漂亮的小内核(kernel)并邀请别人试玩、添加新的酷的功能。<br>不幸的是，随着公司试图主张版权并从中获利，Unix的传播速度便有所放缓。许多公司都有自己的变体，如SunOS、HPUX…贝尔实验室和其它玩家之间的法律纠纷在Unix上投下了一片乌云，许多人想知道它是否能够活下来，特别是在Windows被引入并占据了PC市场的大部分时…</p></blockquote><p><br></p><blockquote><p>旁白：<strong>然后来了Linux</strong>(ASIDE: AND THEN CAME LINUX)<br>对于Unix，幸运的是，一位名叫<strong>Linus Torvalds</strong>的年轻芬兰Hacker决定编写它自己的Unix版本，该版本大量借用原始系统背后的原则和思想，但不是来自代码库，因此避免了合法性问题。他获得了世界各地许多人的帮助，利用了已经存在的复杂的GNU工具，很快Linux就诞生了(以及现代开源软件运动)。<br>随着互联网时代的带来，大多数公司(如Google、Amazon、Facebook..)选择运行Linux，因为它是免费的，可以随时修改以满足自己的实际需求。随着智能手机成为一个占主导地位的面向用户的平台，由于许多相同的原因，Linux也在那里找到了一个据点(Android)。</p></blockquote><p><br><br><br></p><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>Summary</p><p>因此，我们介绍了操作系统。今天的操作系统相对易于使用，而你今天使用的几乎所有操作系统都受到将在本书中讨论的发展的影响。<br>不幸的是，书中不会介绍的很详细。例如，网络代码、图形设备、安全性。</p><p>但是，我们将介绍许多重要的主题，包括CPU和MEM的虚拟化知识，并发性以及通过设备和文件系统的持久性。别担心，虽然有很多方面可以覆盖，但大部分内容都非常酷，而且在路的尽头，你将对计算机系统的真正工作方式有了新的认识。现在开始吧！</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="虚拟化"><a href="#虚拟化" class="headerlink" title="虚拟化"></a>虚拟化</h1><p>Virtualization</p><p>包括以下章节:</p><ul><li>A Dialogue on Virtualization</li><li>The Abstraction: The Process</li><li>Interlude: Process API</li><li>Mechanism: Limited Direct Execution</li><li>CPU Scheduling</li><li>Scheduling: The Multi-Level Feedback Queue</li><li>Scheduling: Proportional Share</li><li>Multi-CPU Scheduling</li><li>Summary Dialogue on CPU Virtualization</li></ul><ul><li>A Dialogue on Memory Virtualization</li><li>The Abstraction: Address Spaces</li><li>Interlude: Memory API</li><li>Mechanism: Address Translation</li><li>Segmentation</li><li>Free-Space Management</li><li>Paging</li><li>Paging: Faster Translations</li><li>Paging: Smaller Tables</li><li>Beyond Physical Memory: Swapping Mechanisms</li><li>Beyond Physical Memory: Swapping Policies</li><li>Complete Virtual Memory Systems</li><li>Summary Dialogue on Memory Virtualization</li></ul><p><br><br><br></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OS Three Easy Pieces: &lt;a href=&quot;https://book.douban.com/subject/19973015/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://book.douban.com/subject/19973015/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;OSTEP: &lt;a href=&quot;http://pages.cs.wisc.edu/~remzi/OSTEP/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://pages.cs.wisc.edu/~remzi/OSTEP/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ELRH7x86_64&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="Linux" scheme="https://zhang21.github.io/tags/Linux/"/>
    
      <category term="OperatingSystem" scheme="https://zhang21.github.io/tags/OperatingSystem/"/>
    
      <category term="操作系统" scheme="https://zhang21.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="Optimization" scheme="https://zhang21.github.io/tags/Optimization/"/>
    
      <category term="性能优化" scheme="https://zhang21.github.io/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Istio</title>
    <link href="https://zhang21.github.io/2019/04/26/Istio/"/>
    <id>https://zhang21.github.io/2019/04/26/Istio/</id>
    <published>2019-04-25T18:21:15.000Z</published>
    <updated>2019-04-26T06:18:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>Istio docs: <a href="https://istio.io/docs" target="_blank" rel="noopener">https://istio.io/docs</a></li><li>Istio中文文档: <a href="https://istio.io/zh/docs/" target="_blank" rel="noopener">https://istio.io/zh/docs/</a></li><li>Istio github: <a href="https://github.com/istio/istio" target="_blank" rel="noopener">https://github.com/istio/istio</a></li></ul><p><br></p><p>环境:</p><ul><li>RHEL7x86_64</li><li>Istio v1.1</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p><a href="https://istio.io/docs/concepts/" target="_blank" rel="noopener">Concepts</a></p><p><br></p><h2 id="Istio是什么"><a href="#Istio是什么" class="headerlink" title="Istio是什么"></a>Istio是什么</h2><p><a href="https://istio.io/docs/concepts/what-is-istio/" target="_blank" rel="noopener">What is Istio?</a></p><p>Istio允许您连接(connect)，保护(secure)，控制(control)和观察(observe)服务。<br>在较高的层级上，Istio有助于降低部署的复杂性，减轻开发团队的压力。它是一个完全开源的<strong>服务网格(service mesh)</strong>，可透明地分层到现有的分布式应用程序上。它也是一个平台，包括可以将其集成到任何日志记录平台或策略系统的API。Istio的多样化功能使你能够成功，高效地运行分布式微服务(microservice)架构，并提供安全，连接和监控微服务的统一方法。</p><p><br></p><h3 id="服务网格"><a href="#服务网格" class="headerlink" title="服务网格"></a>服务网格</h3><p>Service Mesh</p><p>Istio解决了开发人员和运营商在单片应用程序向分布式微服务架构过渡时所面临的挑战。有必要详细了解Istio服务网格。</p><p>术语服务网格用于描述构成此类应用程序的微服务网络以及它们之间的交互。随着服务网格的大小和复杂性的增加，理解和管理变得更加困难。其要求包括:</p><ul><li><strong>发现(discovery)</strong></li><li><strong>负载均衡(load balancing)</strong></li><li><strong>故障恢复(failure recovery)</strong></li><li><strong>指标(metrics)</strong></li><li><strong>监控(monitoring)</strong></li></ul><p>服务网格通常还具有更复杂的操作要求，如:</p><ul><li><strong>A/B测试</strong></li><li><strong>金丝片部署(canary rollouts)</strong></li><li><strong>速率限制(rate limiting)</strong></li><li><strong>访问控制(access control)</strong></li><li><em>*端到端认证()</em>end-to-end authentication*</li></ul><p>Istio作为一个整体提供对服务网格的行为洞察和操作控制。</p><p><br><br><br></p><h3 id="为什么使用它"><a href="#为什么使用它" class="headerlink" title="为什么使用它"></a>为什么使用它</h3><p>Why use Istio?</p><p>通过负载均衡，服务到服务的身份认证，监控…使用服务代码中很少或不需要更改代码，Istio可以轻松创建已部署的服务网格。通过在整个环境中部署特殊的sidecar代理来拦截服务的Istio支持，该代理拦截微服务之间的所有网络通信，然后使用其控制平面配置和管理Istio。包括:</p><ul><li>HTTP, gRPC, WebSocket, TCP流量的自动负载均衡；</li><li>通过丰富的路由规则，重试(retries)，故障转移(failovers)，故障注入(fault injection)，对流量欣慰 进行细粒度控制；</li><li>可插入的策略层和API配置，支持访问控制，速率限制和配额；</li><li>集群中所有流浪的自动度量、日志和追踪，包括集群的ingress, egress；</li><li>通过强大的基于身份的认证和授权，在鸡群中实现安全的服务到服务的通信。</li></ul><p><br><br><br></p><h3 id="核心功能"><a href="#核心功能" class="headerlink" title="核心功能"></a>核心功能</h3><p>Core features</p><p><br></p><h4 id="流量管理"><a href="#流量管理" class="headerlink" title="流量管理"></a>流量管理</h4><p>Traffic management</p><p>通过Istio简单的规则配置和流量路由，你可以控制服务之间的流量和API调用。它简化了服务级别的属性配置，如熔断器(circuit breakers)，超时(timeouts)，重试(retries)，并且可以轻松设置A/B测试，金丝片部署(canary rollouts)，基于百分比流量分割的分阶段部署等重要任务。</p><p>通过更好地了解流量和开箱即用的故障恢复功能，你可在问题出现之前发现问题，使调用更加可靠、网络更加强大。</p><p><br><br><br></p><h4 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h4><p>Security</p><p>Istio的安全功能使开发人员可以更加专注于应用程序级别的安全性。Istio提供了底层安全通信信道，并大规模管理服务通信的认证、授权和加密。使用Istio，服务通信在默认情况下是安全的，允许你跨多种协议和运行时一致地实施策略。所有这些基本都不用对应用程序进行更改。</p><p>虽然Istio与平台无关，但与k8s网络策略一起使用时，其优势更大，包括在网络层和应用层保护<code>pod-to-pod</code>或<code>service-to-service</code>通信的能力。</p><p><br><br><br></p><h4 id="可观察性"><a href="#可观察性" class="headerlink" title="可观察性"></a>可观察性</h4><p>Observability</p><p>Istio强大的追踪、监控和日志记录功能可以让你更深入了解服务网格部署。通过Istio的监控功能，真正了解服务性能如何影响上下游(upstream, downstream)的功能，而其自定义的仪表盘可提供对所有服务性能的可视性，并让你了解该性能如何影响你的其他进程。</p><p>Istio的<strong>混合器（Mixer)</strong>组件负责策略控制和遥测收集。它提供后端抽象和中间媒介，将Istio的其余部分与各个基础架构后端的实现细节隔离开来，并为运营商提供对网格网络和基础架构后端之间所有交互的细粒度控制。</p><p>这些功能使你可以更有效地设置，监控和实施服务上的SLOs。当然，最重要的是，你可以快速有效地检测和修复问题。</p><p><br><br><br></p><h4 id="平台支持"><a href="#平台支持" class="headerlink" title="平台支持"></a>平台支持</h4><p>Platform support</p><p>Istio是独立于平台的，旨在各种环境中运行。包括跨云，内在部署，k8s，Mesos…<br>你可在k8s上部署Istio，或在带有Nomad的Consul上部署它。Istio目前支持:</p><ul><li>Service deployment on Kubernetes</li><li>Services registered with Consul</li><li>Services running on individual virtual machines</li></ul><p><br><br><br></p><h4 id="集成和自定义"><a href="#集成和自定义" class="headerlink" title="集成和自定义"></a>集成和自定义</h4><p>Integration and customization</p><p>可以扩展和自定义Istio的策略实施组件，来与现有的ACL，日志记录，监控，配额，审计等方案集成。</p><p><br><br><br></p><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>Architecture</p><p>Istio服务网格逻辑上分为<strong>数据平面(data plane)</strong>和<strong>控制平面(data plane)</strong>。</p><ul><li>数据平面由一组以 sidecar 方式部署的<strong>智能代理(Envoy)</strong>组成。这些代理可以调节和控制微服务及Mixer之间所有的网络通信。</li><li>控制平面负责管理和配置代理来路由流量。此外控制平面配置Mixer以实施策略和收集遥测数据。</li></ul><p><img src="images/Istio/arch.svg" alt=""></p><p><br></p><h4 id="Envoy"><a href="#Envoy" class="headerlink" title="Envoy"></a>Envoy</h4><p>Istio使用<strong>Envoy</strong>代理的扩展版本，Envoy是以<code>C++</code>开发的高性能代理，用于调解服务网格中所有服务的所有入站和出站流量。<br>Envoy 的许多内置功能被 Istio 发扬光大，如:</p><ul><li>动态服务发现(Dynamic service discovery)</li><li>负载均衡(Load balancing)</li><li>TLS termination</li><li>HTTP/2 and gRPC proxies</li><li>熔断器(Circuit breakers)</li><li>健康检查(Health checks)</li><li>基于百分比流量拆分的灰度发布</li><li>故障注入(Fault injection)</li><li>丰富的度量指标(Rich metrics)</li></ul><p>Envoy 被部署为 sidecar，和对应服务在同一个 k8s pod 中。这允许 Istio 将大量关于流量行为的信号作为属性提取出来，而这些属性又可以在 Mixer 中用于执行策略决策，并发送给监控系统，以提供整个网格行为的信息。<br>Sidecar 代理模型还可以将 Istio 的功能添加到现有部署中，而无需重新构建或重写代码。</p><p><br><br><br></p><h4 id="Mixer"><a href="#Mixer" class="headerlink" title="Mixer"></a>Mixer</h4><p><strong>Mixer</strong> 是一个独立于平台的组件，负责在服务网格上执行访问控制和使用策略，并从 Envoy 代理和其他服务收集遥测数据。代理提取请求级属性，发送到 Mixer 进行评估。</p><p>Mixer 中包括一个灵活的插件模型，使其能够接入到各种主机环境和基础设施后端，从这些细节中抽象出 Envoy 代理和 Istio 管理的服务。</p><p><br><br><br></p><h4 id="Pilot"><a href="#Pilot" class="headerlink" title="Pilot"></a>Pilot</h4><p><strong>Pilot</strong> 为 Envoy sidecar 提供服务发现功能，为智能路由（如 A/B测试、金丝雀部署）和弹性（超时、重试、熔断器）提供流量管理功能。</p><p>它将控制流量行为的高级路由规则转换为特定于 Envoy 的配置，并在运行时将它们传播到 sidecar。Pilot 将平台特定的服务发现机制抽象化并将其合成为符合 Envoy 数据平面 API 的任何 sidecar 都可以使用的标准格式。这种松散耦合使得 Istio 能够在多种环境下运行（如 k8s、Consul、Nomad），同时保持用于流量管理的相同操作界面。</p><p><br><br><br></p><h4 id="Citadel"><a href="#Citadel" class="headerlink" title="Citadel"></a>Citadel</h4><p><strong>Citadel</strong> 通过内置身份和凭证管理赋能强大的服务间和最终用户身份验证。可用于升级服务网格中未加密的流量，并为运维人员提供基于服务标识而不是网络控制的强制执行策略的能力。</p><p><br><br><br></p><h4 id="Galley"><a href="#Galley" class="headerlink" title="Galley"></a>Galley</h4><p><strong>Galley</strong> 代表其他的 Istio 控制平面组件，用来验证用户编写的 Istio API 配置。随着时间的推移，Galley 将接管 Istio 获取配置、 处理和分配组件的顶级责任。它将负责将其他的 Istio 组件与从底层平台(如k8s)获取用户配置的细节中隔离开来。</p><p><br><br><br></p><h3 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h3><p>Design Goals</p><p>Istio的架构设计中有几个关键目标，这些目标对于使系统能够应对大规模流量和高性能地服务处理至关重要。</p><ul><li>最大化透明度(Maximize Transparency)</li><li>可扩展性(Extensibility)</li><li>可移植性(Portability)</li><li>策略一致性(Policy Uniformity)</li></ul><p><br><br><br><br><br></p><h2 id="流量管理-1"><a href="#流量管理-1" class="headerlink" title="流量管理"></a>流量管理</h2><p><a href="https://istio.io/docs/concepts/traffic-management/" target="_blank" rel="noopener">Traffic Management</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Istio docs: &lt;a href=&quot;https://istio.io/docs&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://istio.io/docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Istio中文文档: &lt;a href=&quot;https://istio.io/zh/docs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://istio.io/zh/docs/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Istio github: &lt;a href=&quot;https://github.com/istio/istio&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/istio/istio&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RHEL7x86_64&lt;/li&gt;
&lt;li&gt;Istio v1.1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="k8s" scheme="https://zhang21.github.io/tags/k8s/"/>
    
      <category term="Service Mesh" scheme="https://zhang21.github.io/tags/Service-Mesh/"/>
    
      <category term="Microservice" scheme="https://zhang21.github.io/tags/Microservice/"/>
    
      <category term="微服务" scheme="https://zhang21.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="服务网格" scheme="https://zhang21.github.io/tags/%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC/"/>
    
  </entry>
  
  <entry>
    <title>CuckooSandbox</title>
    <link href="https://zhang21.github.io/2019/04/16/CuckooSandbox/"/>
    <id>https://zhang21.github.io/2019/04/16/CuckooSandbox/</id>
    <published>2019-04-16T07:25:45.000Z</published>
    <updated>2019-04-17T01:14:42.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>github: <a href="https://github.com/cuckoosandbox/cuckoo" target="_blank" rel="noopener">https://github.com/cuckoosandbox/cuckoo</a></li><li>docs: <a href="https://cuckoo.sh/docs/" target="_blank" rel="noopener">https://cuckoo.sh/docs/</a></li></ul><p><br></p><p>环境:</p><ul><li>REL7x86_64</li><li>Cuckoo v2.0.6</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p><a href="https://cuckoo.sh/docs/introduction/index.html" target="_blank" rel="noopener">Introduction</a></p><p>本章节介绍 Cuckoo Sandbox。它解释了一些基本的恶意软件(malware)分析概念，什么是CuckooSanbox以及它如何适应恶意软件分析。</p><p><br><br><br></p><h2 id="沙箱"><a href="#沙箱" class="headerlink" title="沙箱"></a>沙箱</h2><p><a href="https://cuckoo.sh/docs/introduction/sandboxing.html" target="_blank" rel="noopener">Sandboxing</a></p><p>如维基百科所定义，“在计算机安全中，沙箱是一种用于分离正在运行的程序的安全机制。它通常用于执行未经验证的代码，或来自未经验证的第三方、供应商、不受信任的用户或网站或程序。”</p><p>这个概念也适用于恶意软件分析的沙箱：我们的目标是在隔离的环境中运行位置和不受信任的应用程序或文件，并获取有关它的功能的信息。</p><p>恶意软件沙箱是动态分析方法的实际应用：它不是静态分析二进制文件，而是实事执行和监视。</p><p>这种方法显然有利有弊，但它获取有关恶意软件的其它详细信息的有价值的技术(如网络行为)。因此，在检查恶意软件时执行<strong>静态分析</strong>(static)和<strong>动态分析</strong>(dynamic analysis)是一种很好的做法，以便更深入地了解它。</p><p>简单来说，Cuckoo是一个允许你执行沙箱恶意软件分析的工具。</p><p><br><br><br></p><h3 id="使用沙箱"><a href="#使用沙箱" class="headerlink" title="使用沙箱"></a>使用沙箱</h3><p>在考虑安装、配置和使用Cuckoo之前，你应该花时间考虑一下你希望用它实现什么功能，以及如何实现。</p><p>你应该考虑的一些问题:</p><ul><li>我想分析那种文件？</li><li>我希望能够处理多少分析？</li><li>我想用哪个平台来运行我的分析？</li><li>我想要关于文件的哪些信息？</li></ul><p>隔离环境(如虚拟机)的创建时沙箱部署中最关键和最重要的部分：应该仔细进行并进行适当的规划。</p><p><br></p><p>在掌握你选择的虚拟化产品之前，你应该已经有一个设计的计划:</p><ul><li>使用哪种操作系统(os)、语言(language)和修补(patching)级别；</li><li>要安装哪个软件和版本。</li></ul><p><br></p><p>考虑到自动恶意软件(malware)分析不是确定性的，它的成功可能取决于很多因素：你试图在虚拟化系统中运行恶意软件，就像在本机系统上运行一样，这可能很难实现，并且可能并不总是如此成功。你的目标应该是创建一个能够满足你所有要求的系统，并尽可能使其尽可能真实。</p><p>例如，你可以考虑留下一些正常使用的故意的痕迹(如历史记录、Cookie、文档、图像…)。如果恶意软件旨在操作、操纵、窃取此类文件，你将能够注意到它。</p><p>虚拟化操作系统通常带有很多痕迹，使它们容易被检测到。即使你不应高估此问题，也可能需要处理此问题并尝试因此尽可能多的虚拟化跟踪。互联网上有很多关于虚拟化检测技术和对策的文献。</p><p>完成设计和准备所需系统原型后，你可以继续创建并部署它。你将总是及时改变或略微修复它们，但要记住，一开始的良好规划意味着从长远来看减少麻烦。</p><p><br><br><br><br><br></p><h2 id="Cuckoo是什么"><a href="#Cuckoo是什么" class="headerlink" title="Cuckoo是什么"></a>Cuckoo是什么</h2><p><a href="https://cuckoo.sh/docs/introduction/what.html" target="_blank" rel="noopener">What is Cuckoo</a></p><p>Cuckoo是一个开源的自动恶意软件分析系统。<br>它用于自动运行和分析文件，并收集全面的分析结果，概述恶意软件在隔离操作系统内运行时的作用。</p><p><br><br><br></p><h3 id="用例"><a href="#用例" class="headerlink" title="用例"></a>用例</h3><p>Use Cases</p><p>由于其机极为模块化的设计，Cuckoo既可以作为独立应用程序使用，也可以集成到更大的框架中。</p><p>它可用来分析:</p><ul><li>通用Windows EXE可执行文件</li><li>DLL文件</li><li>PDF文档</li><li>MS OFFICE文档</li><li>URLs和HTML文件</li><li>PHP脚本</li><li>CPL文件</li><li>VB脚本</li><li>ZIP文件</li><li>Python文件</li><li>Almost anything else</li></ul><p>由于其模块化和强大的脚本功能，使用Cuckoo可实现的目标没有限制。</p><p><br><br><br></p><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>Architecture</p><p>Cuckoo Sandbox由一个处理样本执行(Execution)和分析(Analysis)的中央管理软件组成。</p><p>每个分析都在一个新的和隔离的虚拟(物理)机器中启动。Cuckoo架构的主要组件是<strong>Host machine</strong>(管理软件)和许多<strong>Guest machines</strong>(用于分析的虚拟机或物理机)。<br>Host运行整个沙箱的分析进程的核心组件，而Guest是实际执行和分析恶意软件样本的隔离环境。</p><p><br></p><p>Cuckoo的主要架构图:</p><p><img src="/images/Cuckoo/architecture-main.png" alt=""></p><p><br><br><br></p><h3 id="获取Cuckoo"><a href="#获取Cuckoo" class="headerlink" title="获取Cuckoo"></a>获取Cuckoo</h3><p>Obtaining Cuckoo</p><p>虽然可以从官网上下载Cuckoo，也可从github下载，但还是建议使用<code>pip</code>安装。</p><p><br><br><br><br><br></p><h2 id="许可证"><a href="#许可证" class="headerlink" title="许可证"></a>许可证</h2><p><a href="https://cuckoo.sh/docs/introduction/license.html" target="_blank" rel="noopener">License</a></p><p>Cuckoo Foundation是一家非盈利组织，在荷兰成立，主要致力于支持开源的恶意软件分析系统Cuckoo Sandbox以及周边项目和计划的开发和发展。</p><p>该基金会致力于为软件项目提供财务和基础设施支持，并协调社区的发展和贡献。</p><p><br><br><br><br><br></p><h2 id="社区准则"><a href="#社区准则" class="headerlink" title="社区准则"></a>社区准则</h2><p><a href="https://cuckoo.sh/docs/introduction/community.html" target="_blank" rel="noopener">Community guidelines</a></p><p>Cuckoo Sandbox是一个开源项目，我们感谢任何形式的贡献。这些指南旨在帮助你和我们尽快回答问题、解决问题和合并代码。所以，你正在阅读的这些指南是很棒的！</p><p><br><br><br></p><h3 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h3><p>这些指南有:</p><ul><li>创建Issue要包含的内容<ul><li>Reporting bugs/errors/unexpected behavior</li><li>Feature suggestions/requests</li></ul></li><li>Contributing code/documentation</li></ul><p><br><br><br></p><hr><p><br><br><br></p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p><a href="https://cuckoo.sh/docs/installation/index.html" target="_blank" rel="noopener">Installation</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;github: &lt;a href=&quot;https://github.com/cuckoosandbox/cuckoo&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/cuckoosandbox/cuckoo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;docs: &lt;a href=&quot;https://cuckoo.sh/docs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://cuckoo.sh/docs/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;REL7x86_64&lt;/li&gt;
&lt;li&gt;Cuckoo v2.0.6&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="Test" scheme="https://zhang21.github.io/tags/Test/"/>
    
      <category term="Cuckoo" scheme="https://zhang21.github.io/tags/Cuckoo/"/>
    
      <category term="Sandbox" scheme="https://zhang21.github.io/tags/Sandbox/"/>
    
      <category term="Security" scheme="https://zhang21.github.io/tags/Security/"/>
    
      <category term="DynamicAnalysis" scheme="https://zhang21.github.io/tags/DynamicAnalysis/"/>
    
      <category term="MalwareAnalysis" scheme="https://zhang21.github.io/tags/MalwareAnalysis/"/>
    
  </entry>
  
  <entry>
    <title>OpenShift</title>
    <link href="https://zhang21.github.io/2019/03/26/OpenShift/"/>
    <id>https://zhang21.github.io/2019/03/26/OpenShift/</id>
    <published>2019-03-26T09:50:11.000Z</published>
    <updated>2019-03-26T09:46:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>Wikipedia</li><li>OpenShift docs: <a href="https://docs.openshift.com" target="_blank" rel="noopener">https://docs.openshift.com</a></li></ul><p><br></p><p>环境:</p><ul><li>RHELx86_64</li><li>OpenShift v3.11</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wikipedia&lt;/li&gt;
&lt;li&gt;OpenShift docs: &lt;a href=&quot;https://docs.openshift.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://docs.openshift.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RHELx86_64&lt;/li&gt;
&lt;li&gt;OpenShift v3.11&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="OpenShift" scheme="https://zhang21.github.io/tags/OpenShift/"/>
    
      <category term="PaaS" scheme="https://zhang21.github.io/tags/PaaS/"/>
    
      <category term="DevOps" scheme="https://zhang21.github.io/tags/DevOps/"/>
    
  </entry>
  
  <entry>
    <title>ZooKeeper</title>
    <link href="https://zhang21.github.io/2019/03/15/ZooKeeper/"/>
    <id>https://zhang21.github.io/2019/03/15/ZooKeeper/</id>
    <published>2019-03-15T08:57:20.000Z</published>
    <updated>2019-03-18T03:24:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li><li>ZooKeeper: <a href="https://zookeeper.apache.org/" target="_blank" rel="noopener">https://zookeeper.apache.org/</a></li><li>Docs: <a href="https://zookeeper.apache.org/doc/" target="_blank" rel="noopener">https://zookeeper.apache.org/doc/</a></li></ul><p>环境:</p><ul><li>RHEL7x86_64</li><li>ZooKeeper v3.5</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p><img src="/images/ZooKeeper/zookeeper_logo.jpg" alt=""></p><p><br></p><p>ZooKeeper: Because Coordinating Distributed Systems is a Zoo.</p><p><strong>Apache ZooKeeper</strong> 是Apache软件基金会的一个软件项目，它为大型分布式计算提供开源的分布式配置服务、同步服务和命名注册，实现高度可靠的分布式协调。ZooKeeper曾经是Hadoop的一个子项目，但现在是一个独立的顶级项目。</p><p>ZooKeeper 是一种集中式服务，用于维护<strong>配置信息</strong>(conf info)，<strong>命名</strong>(naming)，<strong>分布式同步</strong>(distributed synchronization)，<strong>组服务</strong>(group service)。所有这些类型的服务都以分布式应用程序的某种形式应用。每次实施它们都需要做很多工作来修复不可避免的错误和竞争条件。由于难以实现这些类型的服务，应用程序最初通常会吝啬它们，这使得它们在变化的情况下变得脆弱并且难以管理。即使正确完成，这些服务的不同实现也会在部署应用程序时导致管理复杂性。</p><p><strong>ZooKeeper的架构通过冗余服务实现高可用性</strong>。因此，如果第一次无应答，客户端就可以询问另一台ZooKeeper主机。ZooKeeper节点将它们的数据存储于一个分层的命名空间，非常类似于一个文件系统或一个前缀树结构。客户端可以在节点读写，从而以这种方式拥有一个共享的配置服务。更新是全序的。</p><p><br></p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p><a href="https://zookeeper.apache.org/doc/r3.5.4-beta/zookeeperOver.html" target="_blank" rel="noopener">ZooKeeper: A Distributed Coordination Service for Distributed Applications</a></p><p>ZooKeeper 是一种用于分布式应用程序的分布式开源协调(coordination)服务。它被设计为易于编程，并使用在熟悉的文件系统目录树结构之后设计的数据模型。它在Java中运行，并具有Java和C的绑定。</p><p>众所周知，协调服务很难做到。他们特别容易出现竞赛条件(race conditions)和死锁(deadlock)。ZooKeeper背后的动机是减轻分布式应用程序从头开始实施协调服务的责任。</p><p><br></p><h3 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h3><p>Design Goals</p><ul><li><strong>ZooKeeper is simple</strong></li></ul><p>ZooKeeper允许分布式进程通过 <strong>共享的层级命名空间</strong>(shared hierarchal namespace) 相互协调，该命名空间的组织方式与标准文件系统类似。命名空间由 <strong>数据寄存器</strong>(data registers) 组成——在ZooKeeper用语中被称为 <code>znodes</code>，这些与文件和目录类似。与专为存储而设计的典型文件系统不同，ZooKeeper数据保存在内存中，这意味着ZooKeeper可以实现高吞吐量(high throughput)和低延迟数(latency numbers)。</p><p>ZooKeeper的实现非常重视 <strong>高性能(high performance)</strong>， <strong>高可用(highly available)</strong>， <strong>严格有序的访问(strictly ordered access)</strong>。性能方面意味着它可以在大型分布式系统中使用。可靠性方面使其不会成为单点故障(a single point of failure)。严格的排序意味着可以在客户端实现复杂的同步原语。</p><p><br></p><ul><li><strong>ZooKeeper is replicated</strong></li></ul><p>与它协调的分布式进程一样，ZooKeeper本身也可以在称为 <strong>集合(ensemble)</strong> 的一组主机上进行 副本复制(replicated)。</p><p><img src="/images/ZooKeeper/zkservice.jpg" alt=""></p><p>组成ZooKeeper服务的Server必须了解彼此。它们维护一个内存中的状态镜像，以及持久性存储的事务日志和快照。只要大多数Servers可用，ZooKeeper服务就可用。</p><p>Client连接到单个Server。Client维护TCP连接，通过该连接发送请求，获取响应，获取监视事件(watch events)，以及发送心跳(heart beats)。如果与Server的TCP连接中断，则Client将连接到其它Server。</p><p><br></p><ul><li><strong>ZooKeeper is ordered</strong></li></ul><p>ZooKeeper使用反映所有ZooKeeper事务顺序的数字标记每个更新。后续操作可以使用该顺序来实现更高级别的抽象，例如同步原语。</p><p><br></p><ul><li><strong>ZooKeeper is fast</strong></li></ul><p>它在读取 <code>read-doninant</code> 工作负载中特别快。ZooKeeper应用程序运行在成千上万的计算机上，并且在读取别写入更常见的情况下(比率<code>10:1</code>)表现最佳。</p><p><br><br><br></p><h3 id="数据模型和分层命名空间"><a href="#数据模型和分层命名空间" class="headerlink" title="数据模型和分层命名空间"></a>数据模型和分层命名空间</h3><p>Data model and the hierarchical namespace</p><p>ZooKeeper提供的命名空间非常类似于标准文件系统。名称是由斜杠(<code>/</code>)分隔的路径元素序列。ZooKeeper命名空间中的每个节点都由路径标识。</p><p><img src="/images/ZooKeeper/zknamespace.jpg" alt=""></p><p><br><br><br></p><h3 id="节点和短暂节点"><a href="#节点和短暂节点" class="headerlink" title="节点和短暂节点"></a>节点和短暂节点</h3><p>Nodes and ephemeral nodes</p><p>与标准文件系统不同，ZooKeeper命名空间中的每个节点都可包含与之关联的数据以及孩子。这就像拥有一个允许文件也是目录的文件系统。ZooKeeper旨在存储协调数据：状态信息，配置，位置信息等，因此存储在每个节点的数据通常很小。我们使用术语 <strong>znode</strong> 来表明我们正在谈论的ZooKeeper数据节点。</p><p>Znodes 维护一个 <strong>状态结构(stat structure)</strong>，其中包括数据更改、ACL更改、时间戳更改，以允许缓存验证和协调更新。每次znode的数据更改时，版本号都会增加。例如，每当Client检索数据时，它也接收数据的版本。</p><p>存储在每个znode命名空间中的数据以原子(atomically)方式进行读写。读取与znode关联的所有数据字节，写入替换所有的数据。每个节点都有一个ACL限制谁可以做什么。</p><p>ZooKeeper也有 <strong>短暂节点(ephemeral nodes)</strong> 的概念。只要创建的znode处于活动状态，就会存在这些znode，回话结束时，znode将被删除。当你想要实现 <code>[tbd]</code> 时，短暂节点很有用。</p><p><br><br><br></p><h3 id="协调更新和监视"><a href="#协调更新和监视" class="headerlink" title="协调更新和监视"></a>协调更新和监视</h3><p>Conditional updates and watches</p><p>ZooKeeper支持监视(watch)的概念。Client可以在znode上设置监视。当znode更改时，将触发并删除监视。触发监视时，Client会受到一个数据包，指出znode已更改。如果Client与其中一个ZooKeeper Server之间的连接中断，则Client将收到本地通知。这可以用于 <code>[tbd]</code> 。</p><p><br><br><br></p><h3 id="保证"><a href="#保证" class="headerlink" title="保证"></a>保证</h3><p>Guarantees</p><p>ZooKeeper非常快速和简单。但是，由于基于目标是构建更复杂的服务(如同步)的基础，因此它提供了一系列保证。这些是:</p><ul><li><strong>顺序一致性(Sequential Consistency)</strong>: Client的更新将按发送顺序来应用</li><li><strong>原子性(Atomicity)</strong>: 更新成功或失败，没有其它结果</li><li><strong>单系统镜像(Single System Image)</strong>: 无论连接到哪个Server，Client都将看到相同的服务视图</li><li><strong>可靠性(Reliability)</strong>: 一旦更新被应用，它将从该时间开始持续，知道Client覆盖此更新</li><li><strong>时宜性(Timeliness)</strong>: 系统的Client视图保证在特定的时间范围内是最新的</li></ul><p><br><br><br></p><h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><p>ZooKeeper的设计目标之一是提供非常简单的编程接口。因此，它仅支持以下操作:</p><ul><li>create: creates a node at a location in the tree</li><li>delete: deletes a node</li><li>exists: tests if a node exists at a location</li><li>get data: reads the data from a node</li><li>set data: writes data to a node</li><li>get children: retrieves a list of children of a node</li><li>sync: waits for data to be propagated</li></ul><p><br><br><br></p><h3 id="执行"><a href="#执行" class="headerlink" title="执行"></a>执行</h3><p>Implementation</p><p>ZooKeeper组件显示了ZooKeeper服务的高级组件。除了请求处理器，构成ZooKeeper服务的每个Server都复制自己每个组件的副本。</p><p><img src="/images/ZooKeeper/zkcomponents.jpg" alt=""></p><ul><li>副本数据库是一个包含整个数据树的内存数据库。更新将记录到磁盘以获得可恢复性，并且在写入内存数据库之前会序列化的磁盘</li><li>每个ZooKeeper Server都为Client服务。Client只连接到一台Server以提交请求。读取请求由每个Server数据库的本地副本提供。更改服务状态的请求，写请求由 协定协议(agreement protocol) 处理</li><li>作为协定协议的一部分，来自Client的所有写入请求都被转发到称为 <strong>leader</strong> 的单个Server。其余的ZooKeeper Server，称为<strong>follower</strong>，接收来自<strong>leader</strong>的消息提议并同意消息传递。消息传递层负责替换失败的leader，并将follower与leader同步</li><li>ZooKeeper使用自定义的原子消息(atomic messaging)协议。由于消息传递层是原子的，因此ZooKeeper可以保证本地副本永远不会发散。当leader收到写入请求时，它会计算应用写入时系统的状态，并将其转换为捕获此新状态的事务。</li></ul><p><br><br><br></p><h3 id="用户"><a href="#用户" class="headerlink" title="用户"></a>用户</h3><p>ZooKeeper的编程接口非常简单。但是，通过它，您可以实现更高阶的操作，例如同步原语，组成员身份，所有权等。</p><p><br><br><br></p><h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><p>Performance</p><p>ZooKeeper旨在提供高性能。在读取数量超过写入的应用程序中，它的性能尤其高，因为写入涉及同步所有Server的状态。</p><p><img src="/images/ZooKeeper/zkperfRW.jpg" alt=""></p><p>The events marked in the figure are the following:</p><ul><li>Failure and recovery of a follower</li><li>Failure and recovery of a different follower</li><li>Failure of the leader</li><li>Failure and recovery of two followers</li><li>Failure of another leader</li></ul><p><br><br><br><br><br></p><h2 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h2><p><a href="https://zookeeper.apache.org/doc/r3.5.4-beta/zookeeperStarted.html" target="_blank" rel="noopener">ZooKeeper Getting Started Guide</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;li&gt;ZooKeeper: &lt;a href=&quot;https://zookeeper.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://zookeeper.apache.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Docs: &lt;a href=&quot;https://zookeeper.apache.org/doc/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://zookeeper.apache.org/doc/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RHEL7x86_64&lt;/li&gt;
&lt;li&gt;ZooKeeper v3.5&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="Apache" scheme="https://zhang21.github.io/tags/Apache/"/>
    
      <category term="DataAnalysis" scheme="https://zhang21.github.io/tags/DataAnalysis/"/>
    
      <category term="ZooKeeper" scheme="https://zhang21.github.io/tags/ZooKeeper/"/>
    
  </entry>
  
  <entry>
    <title>HBase</title>
    <link href="https://zhang21.github.io/2019/03/15/HBase/"/>
    <id>https://zhang21.github.io/2019/03/15/HBase/</id>
    <published>2019-03-15T02:57:20.000Z</published>
    <updated>2019-03-15T09:00:17.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li><li>HBase: <a href="https://hbase.apache.org/" target="_blank" rel="noopener">https://hbase.apache.org/</a></li><li>Reference Guide: <a href="http://hbase.apache.org/book.html" target="_blank" rel="noopener">http://hbase.apache.org/book.html</a></li></ul><p>环境:</p><ul><li>RHEL7x86_64</li><li>HBase v3.0</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p><img src="/images/HBase/hbase_logo.png" alt=""></p><p><br></p><p><strong>Apache HBase</strong> 是Hadoop数据库，是一个分布式(distributed)，可扩展(scalable)的大数据存储。</p><p>当你需要对大数据进行随机(random)，实时(realtime)R/W访问时，请使用Apache HBase。它的目标是在硬件集群上托管非常大的表——数十亿行数百万列。</p><p>HBase是一个开源的非关系型分布式数据库（NoSQL），它参考了谷歌的BigTable建模，实现的编程语言为 Java。它是Apache软件基金会的Hadoop项目的一部分，运行于HDFS文件系统之上，为 Hadoop 提供类似于BigTable 规模的服务。因此，它可以对稀疏文件提供极高的容错率。</p><p>HBase在列上实现了BigTable论文提到的压缩算法、内存操作和布隆过滤器。HBase的表能够作为MapReduce任务的输入和输出，可以通过Java API来访问数据，也可以通过REST、Avro或者Thrift的API来访问。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h1><p>Features</p><ul><li>线性和模块化可扩展性</li><li>严格一致的读写操作</li><li>表的自动和可配置分片</li><li>支持RegionServers之间的自动故障转移</li><li>方便的基类，用于使用Apache HBase表支持Hadoop MapReduce作业</li><li>易于使用的Java API，用于客户端访问</li><li>阻止缓存和bloom过滤器以进行实时查询</li><li>Query predicate push down via server side Filters</li><li>Thrift gateway和REST-ful Web service，支持XML， Protobuf， binary data encoding</li><li>可扩展的基于JRuby的（JIRB）shell</li><li>支持通过Hadoop Metrics子系统将指标导出到文件或其它</li><li>…</li></ul><p><br><br><br></p><hr><p><br><br><br></p><h1 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h1><p>Getting Started</p><p><br></p><h2 id="Standalone-HBase"><a href="#Standalone-HBase" class="headerlink" title="Standalone HBase"></a>Standalone HBase</h2><p>本节介绍在单节点的standalone实例上运行HBase。<strong>Standalone instance</strong> 包含了所有的<strong>HBase Daemons(Master, RegionServers, Zookeeper)</strong>，在单个JVM中运行并持久化到本地文件系统。这是一个最基本的配置，将展示如何使用HBase shell CLI在HBase中创建表、在表中插入行、对表执行放置和扫描操作、启用/禁用表、启动和停止HBase。</p><p><br></p><h3 id="JDK"><a href="#JDK" class="headerlink" title="JDK"></a>JDK</h3><p>HBase要求安装JDK。</p><p><br><br><br></p><h3 id="使用HBase"><a href="#使用HBase" class="headerlink" title="使用HBase"></a>使用HBase</h3><p>步骤:</p><ul><li>下载</li><li>配置</li><li>启动</li><li>使用</li><li>停止</li></ul><p><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"># 访问Apache DownLoad Mirrors，下载对应版本HBase</span><br><span class="line"># https://www.apache.org/dyn/closer.lua/hbase/</span><br><span class="line">cd opt</span><br><span class="line">wget http://mirror.bit.edu.cn/apache/hbase/3.0.0/hbase-3.0.0-bin.tar.gz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 解压</span><br><span class="line">tar xzvf hbase-3.0.0-SNAPSHOT-bin.tar.gz</span><br><span class="line">mv hbase-3.0.0-SNAPSHOT hbase</span><br><span class="line">cd hbase</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 启动前必须先设置JAVA_HOME环境变量</span><br><span class="line"># conf/hbase-env.sh</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_191-amd64</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 编辑conf/hbase-site.xml，这是主要的HBase配置文件</span><br><span class="line"># 您需要在本地文件系统上指定HBase和ZooKeeper写入数据并确认一些风险的目录</span><br><span class="line"># 栗子</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;file:///home/testuser/hbase&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/home/testuser/zookeeper&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">      Controls whether HBase will check for stream capabilities (hflush/hsync).</span><br><span class="line"></span><br><span class="line">      Disable this if you intend to run on LocalFileSystem, denoted by a rootdir</span><br><span class="line">      with the &apos;file://&apos; scheme, but be mindful of the NOTE below.</span><br><span class="line"></span><br><span class="line">      WARNING: Setting this to false blinds you to potential data loss and</span><br><span class="line">      inconsistent system state in the event of process and/or node failures. If</span><br><span class="line">      HBase is complaining of an inability to use hsync or hflush it&apos;s most</span><br><span class="line">      likely not a false positive.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># start a standalone instance of HBase</span><br><span class="line"># 一个JVM运行 HMaster, HRegionServer, Zookeeper</span><br><span class="line">bin/start-hbase.sh</span><br><span class="line"></span><br><span class="line"># http://localhost:16010 查看HBase Web UI</span><br></pre></td></tr></table></figure><p><br></p><p>你不需要创建HBase数据目录，它会自动做这件事。如果你创建目录，HBase将尝试进行迁移，这不是你想要的。</p><p>要在现有的HDFS实例上安装HBase，请将 <code>hbase.rootdir</code> 设置为指向实例上的目录(如: <code>hdfs://namenode.example.org:8020/hbase</code>)。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用hbase shell命令连接到HBase</span></span><br><span class="line">/bin/hbase shell</span><br><span class="line">xxxx</span><br><span class="line">xxxx</span><br><span class="line">2.3.7 :001 &gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示帮助</span></span><br><span class="line">&gt; <span class="built_in">help</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建表，你必须指定 Table name和ColumnFamily name</span></span><br><span class="line">&gt; create <span class="string">'t-test'</span>, <span class="string">'c-test'</span></span><br><span class="line">Took 1.7627 seconds</span><br><span class="line"> =&gt; Hbase::Table - t-test</span><br><span class="line"><span class="comment"># 也可在Web UI上查看相关信息</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出表信息</span></span><br><span class="line">&gt; list <span class="string">'c-test'</span></span><br><span class="line">TABLE</span><br><span class="line">t-test</span><br><span class="line">1 row(s)</span><br><span class="line">Took 0.0520 seconds</span><br><span class="line"> =&gt; [<span class="string">"t-test"</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; describe <span class="string">'t-test'</span></span><br><span class="line">Table t-test is ENABLED</span><br><span class="line">t-test</span><br><span class="line">COLUMN FAMILIES DESCRIPTION</span><br><span class="line">&#123;NAME =&gt; <span class="string">'c-test'</span>, VERSIONS =&gt; <span class="string">'1'</span>, EVICT_BLOCKS_ON_CLOSE =&gt; <span class="string">'false'</span>, NEW_VERSION_BEHAVIOR =&gt; <span class="string">'false'</span>, KEEP_DELETED_CELLS =&gt; <span class="string">'FALSE'</span>, CACHE_DATA_ON_WRITE =&gt; <span class="string">'false'</span>, DATA_BLOCK_ENCODING</span><br><span class="line">=&gt; <span class="string">'NONE'</span>, TTL =&gt; <span class="string">'FOREVER'</span>, MIN_VERSIONS =&gt; <span class="string">'0'</span>, REPLICATION_SCOPE =&gt; <span class="string">'0'</span>, BLOOMFILTER =&gt; <span class="string">'ROW'</span>, CACHE_INDEX_ON_WRITE =&gt; <span class="string">'false'</span>, IN_MEMORY =&gt; <span class="string">'false'</span>, CACHE_BLOOMS_ON_WRITE =&gt; <span class="string">'false'</span>,</span><br><span class="line"> PREFETCH_BLOCKS_ON_OPEN =&gt; <span class="string">'false'</span>, COMPRESSION =&gt; <span class="string">'NONE'</span>, BLOCKCACHE =&gt; <span class="string">'true'</span>, BLOCKSIZE =&gt; <span class="string">'65536'</span>&#125;</span><br><span class="line">1 row(s)</span><br><span class="line">Took 0.2293 seconds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据放入表中</span></span><br><span class="line">&gt;put <span class="string">'t-test'</span>,  <span class="string">'row1'</span>, <span class="string">'c-test:a'</span>, <span class="string">'value1'</span></span><br><span class="line">Took 0.2116 seconds</span><br><span class="line">&gt; put <span class="string">'t-test'</span>,  <span class="string">'row2'</span>, <span class="string">'c-test:b'</span>, <span class="string">'value2'</span></span><br><span class="line">Took 0.0082 seconds</span><br><span class="line">&gt; &gt; put <span class="string">'t-test'</span>,  <span class="string">'row3'</span>, <span class="string">'c-test:c'</span>, <span class="string">'value3'</span></span><br><span class="line">Took 0.0085 seconds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 一次扫描表中所有数据</span></span><br><span class="line">&gt; scan <span class="string">'t-test'</span></span><br><span class="line">&gt;   scan <span class="string">'t-test'</span></span><br><span class="line">ROW                                             COLUMN+CELL</span><br><span class="line"> row1                                           column=c-test:a, timestamp=1552630577582, value=value1</span><br><span class="line"> row2                                           column=c-test:b, timestamp=1552630591734, value=value2</span><br><span class="line"> row3                                           column=c-test:c, timestamp=1552630598817, value=value3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取单行数据</span></span><br><span class="line">&gt; get <span class="string">'t-test'</span> <span class="string">'row1'</span></span><br><span class="line">COLUMN                                          CELL</span><br><span class="line"> c-test:a                                       timestamp=1552630577582, value=value1</span><br><span class="line">1 row(s)</span><br><span class="line">Took 0.0225 seconds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 禁用/启用表</span></span><br><span class="line">&gt; <span class="built_in">disable</span> <span class="string">'t-test'</span></span><br><span class="line">&gt; <span class="built_in">enable</span> <span class="string">'t-test'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除表</span></span><br><span class="line">&gt; drop <span class="string">'t-test'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 退出HBase Shell</span></span><br><span class="line">&gt; quit</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># stop a standalone instance of HBase</span></span><br><span class="line"><span class="comment"># 可能需要几分钟，请耐心等待</span></span><br><span class="line">bin/stop-hbase.sh</span><br></pre></td></tr></table></figure><p><img src="/images/HBase/hbase_standalone.png" alt=""></p><p><br><br><br><br><br></p><h3 id="伪分布式本地安装"><a href="#伪分布式本地安装" class="headerlink" title="伪分布式本地安装"></a>伪分布式本地安装</h3><p>Pseudo-Distributed Local Install</p><p>通过standalone模式之后，你可以重新配置HBase以<strong>伪分布式模式(Pseudo-Distributed)</strong>运行。伪分布式意味着HBase仍然在单个主机上运行，但每个HBase Daemons(HMaster, HRegionServer, Zookeeper)作为一个单独的进程运行。默认数据存储在<code>/tmp</code>下，除非你像Standalone一样配置了<code>rootdir</code>。</p><p>假设将数据存储在HDFS中，并且HDFS可用。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Stop HBase if it is running.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置HBase</span></span><br><span class="line"><span class="comment"># 编辑hbase-site.xml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加指示HBase以分布式模式运行，每个守护进程有一个JVM实例</span></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;<span class="literal">true</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 hdfs://// URI语法将hbase.rootdir从本地文件系统更改为HDFS实例的地址，地址请查看HDFS配置</span></span><br><span class="line"><span class="comment"># 请确保删除hbase.unsafe.stream.capability.enforce的条目或将其设置为true</span></span><br><span class="line"><span class="comment"># 你不需要在HDFS中创建目录，HBase会为你做这件事。如果您创建目录，HBase将尝试进行迁移，这不是您想要的</span></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;hdfs://localhost:8020/hbase&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动HBase</span></span><br><span class="line">bin/start-hbase.sh</span><br><span class="line"><span class="comment"># 如果系统配置正确，则jps显示正在运行的HBase进程</span></span><br><span class="line">jps</span><br><span class="line">20065 HMaster</span><br><span class="line">20006 HQuorumPeer</span><br><span class="line">20137 HRegionServer</span><br><span class="line">20521 Jps</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查HDFS中的HBase目录</span></span><br><span class="line"><span class="comment"># 如果一切正常，HBase会在HDFS中创建它的目录</span></span><br><span class="line"><span class="comment"># 注意HDFS的安全模式</span></span><br><span class="line">bin/hadoop fs -ls /hbase</span><br><span class="line">Found 1 items</span><br><span class="line">drwxr-xr-x   - zhang supergroup          0 2019-03-15 15:33 /hbase/.tmp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个表，并用数据填充它</span></span><br><span class="line"><span class="comment"># 创建放入和前面一样</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动/停止一个 backup HBase Master Server(HMaster)</span></span><br><span class="line"><span class="comment"># 在同一硬件上运行多个HMaster实例在生产环境中没有意义，就像运行伪分布式集群对生产没有意义一样。此步骤仅用于测试和学习</span></span><br><span class="line">/bin/<span class="built_in">local</span>-master-backup.sh start 2 3 5</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在不杀死整个集群的情况下终止backup master</span></span><br><span class="line">cat /tmp/hbase-testuser-1-master.pid |xargs <span class="built_in">kill</span> -9</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动/停止additional RegionServers</span></span><br><span class="line"><span class="comment"># 在同一系统上运行多个HRegionServers对于以伪分布式模式进行测试非常有用。</span></span><br><span class="line">bin/<span class="built_in">local</span>-regionservers.sh start 2 3 4</span><br><span class="line">bin/<span class="built_in">local</span>-regionservers.sh stop 3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止HBase</span></span><br><span class="line">bin/stop-hbase.sh</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h3><p>Advanced - Fully Distributed</p><p>实际上，你需要完全分布式(fully-distributed)配置才能完全测试HBase并在实际场景中使用它。在分布式配置中，集群包含多个节点，每个节点运行一个或多个HBase守护进程(包括: Primary Master, Backup Master, Multiple ZooKeeper nodes, Multiple RegionServer nodes)。</p><p><br></p><h4 id="分布式集群架构"><a href="#分布式集群架构" class="headerlink" title="分布式集群架构"></a>分布式集群架构</h4><p>Distributed Cluster Demo Architecture</p><table><thead><tr><th>Node Name</th><th>Master</th><th>ZooKeeper</th><th>RegionServer</th></tr></thead><tbody><tr><td><code>node-a.example.com</code></td><td>yes</td><td>yes</td><td>no</td></tr><tr><td><code>node-b.example.com</code></td><td>backup</td><td>yes</td><td>yes</td></tr><tr><td><code>node-c.example.com</code></td><td>no</td><td>yes</td><td>yes</td></tr></tbody></table><p>确保集群之间的可访问性。</p><p><br><br><br></p><h4 id="SSH免密"><a href="#SSH免密" class="headerlink" title="SSH免密"></a>SSH免密</h4><p>Configure Passwordless SSH Access</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成公钥</span></span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 写入公钥</span></span><br><span class="line">cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意修改权限</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试免密登录</span></span><br><span class="line">ssh user@hostname</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="准备集群"><a href="#准备集群" class="headerlink" title="准备集群"></a>准备集群</h4><p>node-a 将运行 Primary Master, ZooKeeper, no RegionServers.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置conf/regionservers</span></span><br><span class="line"><span class="comment"># 删除node-a的RegionServer地址，并添加node-b, node-c的RegionServer地址</span></span><br><span class="line"><span class="comment"># node-b.example.com, node-c.example.com</span></span><br><span class="line">conf/regionservers</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置HBase使用node-b作为 Backup Master</span></span><br><span class="line"><span class="comment"># 创建 conf/backup-masters，并使用 node-b的主机名为其添加新行</span></span><br><span class="line">conf/backup-masters</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置ZooKeeper</span></span><br><span class="line"><span class="comment"># 实际情况中，你应该仔细考虑ZooKeeper配置</span></span><br><span class="line"><span class="comment"># node-a, conf/hbase-site.xml</span></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;node-a.example.com,node-b.example.com,node-c.example.com&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/usr/<span class="built_in">local</span>/zookeeper&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><br></p><p>node-b 将运行 backup master, ZooKeeper instance。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 复制 node-a conf/ 到 node-b, node-c conf/</span></span><br><span class="line"><span class="comment"># 集群中的每个节点都需要具有相同的配置</span></span><br><span class="line"><span class="comment"># 请注意不同节点的localhost这个地址</span></span><br></pre></td></tr></table></figure><p><br></p><p>配置完成后，便要启动并测试集群。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Be sure HBase is not running on any node</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Start the cluster</span></span><br><span class="line"><span class="comment"># On node-a, node-b, node-c</span></span><br><span class="line">bin/start-hbase.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># ZooKeeper starts first, followed by the master, then the RegionServers, and finally the backup masters.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Verify that the processes are running</span></span><br><span class="line">jps</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Browse to the Web UI</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Test what happens when nodes or services disappear</span></span><br><span class="line"><span class="comment"># 测试可用性</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><hr><p><br><br><br></p><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p>Apache HBase Configuration</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;li&gt;HBase: &lt;a href=&quot;https://hbase.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://hbase.apache.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Reference Guide: &lt;a href=&quot;http://hbase.apache.org/book.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://hbase.apache.org/book.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RHEL7x86_64&lt;/li&gt;
&lt;li&gt;HBase v3.0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="Apache" scheme="https://zhang21.github.io/tags/Apache/"/>
    
      <category term="DataAnalysis" scheme="https://zhang21.github.io/tags/DataAnalysis/"/>
    
      <category term="HBase" scheme="https://zhang21.github.io/tags/HBase/"/>
    
      <category term="NoSQL" scheme="https://zhang21.github.io/tags/NoSQL/"/>
    
  </entry>
  
  <entry>
    <title>Flume</title>
    <link href="https://zhang21.github.io/2019/03/07/Flume/"/>
    <id>https://zhang21.github.io/2019/03/07/Flume/</id>
    <published>2019-03-07T01:32:20.000Z</published>
    <updated>2019-03-15T02:24:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>wikipedia</li><li>Flume: <a href="https://flume.apache.org/" target="_blank" rel="noopener">https://flume.apache.org/</a></li><li>Flume docs: <a href="https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html" target="_blank" rel="noopener">https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html</a></li></ul><p>环境:</p><ul><li>ELRH7x86_64</li><li>Flume v1.9.0</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p><a href="https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#introduction" target="_blank" rel="noopener"></a></p><p><strong>Apache Flume</strong> 是一种分布式，可靠且可用的软件，使用Java编写，用于高效收集(collecting)，聚合(aggregating)和移动(moving)大量日志数据。它具有基于流数据流(stream data flows)的简单灵活的架构。它具有可靠性机制和许多故障转移和恢复机制，具有强大的容错能力。它使用简单的可扩展数据模型，允许在线分析应用程序。</p><p>Apache Flume的使用不仅限于日志数据聚合。由于数据源是可定制的，因此Flume可用于传输大量事件数据，包括但不限于网络流量数据，社交媒体生成的数据，电子邮件消息以及几乎任何可能的数据源。</p><p><img src="/imags/Flume/flume-logo.png" alt=""></p><p><br></p><h2 id="系统要求"><a href="#系统要求" class="headerlink" title="系统要求"></a>系统要求</h2><ul><li><strong>Java</strong>: Java 1.8+</li><li><strong>Mem</strong>: sources, channels, sinks有足够的内存</li><li><strong>Disk</strong>: channels, sinks有足够的磁盘空间</li><li><strong>Directory Permissions</strong>: Agent使用的目录的读写权限</li></ul><p><br><br><br><br><br></p><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p><br></p><h3 id="数据流模型"><a href="#数据流模型" class="headerlink" title="数据流模型"></a>数据流模型</h3><p>Data flow model</p><ul><li><strong>源(Source)</strong></li><li><strong>通道(Channel)</strong></li><li><strong>接收器(Sink)</strong></li><li><strong>事件(Event)</strong></li></ul><p><br></p><p><strong>Flume event</strong> 被定义为具有字节(byte)有效负载可可选字符串属性集的数据流单元(unit of data flow)。<strong>Flume agent</strong>是一个(JVM)进程，它承载事件从外部源流向下一个目标的组件。</p><p><img src="/images/Flume/flume-architecture.png" alt=""></p><p><br></p><p><strong>Flume源消费事件</strong>(source consumes events)通过<strong>外部源</strong>(external source)(如WebServer)传递给它。外部源通过<strong>目标Flume源</strong>(target Flume source)识别的格式向Flume发送事件。当Flume源接收事件时，它会将其存储到一个或多个<strong>通道</strong>(channels)中。通道是一个被动存储，可以保持事件直到它被<strong>Flume sink</strong>所消费。接收器从通道中移除事件，并将其放入外部存储库(如HDFS)或将其转发到流中的下一个Flume Agent(next hop)的Flume Source。给定Agent中的Source和Sink与Channel中暂存的Events异步运行。</p><p><br><br><br></p><h3 id="复杂流"><a href="#复杂流" class="headerlink" title="复杂流"></a>复杂流</h3><p>Complex flows</p><p>Flume允许用户构建多跳(hop)流，其中事件在到达最终目的地之前经过多个代理。它还允许 fan-in 和 fan-out flows, 上下文路由(contextual routing), 故障跳跃的备份路由(故障转移)。</p><p><br><br><br></p><h3 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h3><p>Reliability</p><p>事件在每个Agent的通道中进行，然后将事件传递到流中的下一个代理或终端存储库(如HDFS)。只有将事件存储在下一个代理的通道或终端存储库之后，才会从通道中删除这些事件。这就是Flume中的单跳消息传递语义如何提供流的端到端可靠性。</p><p>Flume使用事务方法来保证事件的可靠传递。源和接收器分别在事务中封装由信道提供的事务中放置/提供的事件的存储(storage)/检索(retrieval)。这可确保事件集在流中从一个点到另一个点可靠地传递。在多跳流的情况下，来自前一跳的接收器和来自下一跳的源都运行其事务以确保数据安全地存储在下一跳的信道中。</p><p><br><br><br></p><h3 id="可恢复性"><a href="#可恢复性" class="headerlink" title="可恢复性"></a>可恢复性</h3><p>Recoverability</p><p>事件在通道中进行，该通道管理从故障中恢复。Flume支持由本地文件系统支持的持久化(durable)文件通道。还有一个内存通道(memory channel)，它将事件存储到内存中的队列中，这更快，但是当代理进程死亡时仍然存留在内存通道中的任何事件都无法恢复。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h1><p><a href="https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#setup" target="_blank" rel="noopener">Setup</a></p><p><br></p><h2 id="设置代理"><a href="#设置代理" class="headerlink" title="设置代理"></a>设置代理</h2><p>Setting up an agent</p><p>Flume Agent配置文件存储在本地配置文件中。这是一个Java properties文件格式的文本文件。可以在同一个配置文件中指定一个或多个代理的配置。配置文件包括代理中的每个Source, Sink, Channel的属性，以及它们如何连接在一起以形成数据流。</p><p><br></p><h3 id="配置单个组件"><a href="#配置单个组件" class="headerlink" title="配置单个组件"></a>配置单个组件</h3><p>Configuring individual components</p><p>流中的每个组件(source, sink, channel)都具有特定于类型和实例化的名称(name)，类型(type)，属性集(properties)。</p><p><br><br><br></p><h3 id="连接各个部分"><a href="#连接各个部分" class="headerlink" title="连接各个部分"></a>连接各个部分</h3><p>Wiring the pieces together</p><p>Agent需要知道加载哪些组件，以及它们如何连接以构成流。这是通过列出代理中每个源，接收器和通道的名称，然后为每个接收器和源指定连接通道来完成的。</p><p><br><br><br></p><h3 id="启动代理"><a href="#启动代理" class="headerlink" title="启动代理"></a>启动代理</h3><p>Starting an agent</p><p>下载Flume发型版，使用名为<code>flume-ng</code>的shell脚本启动代理程序。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 你需要在命令行上指定代理名称、配置目录、配置文件</span></span><br><span class="line">bin/flume-ng agent -n <span class="variable">$agent_name</span> -c conf -f conf/flume-conf.properties.template</span><br><span class="line"></span><br><span class="line"><span class="comment"># 现在，代理开始运行在给定属性文件中配置的源和接收器</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="一个栗子"><a href="#一个栗子" class="headerlink" title="一个栗子"></a>一个栗子</h3><p>下面给出一个示例配置文件。此配置允许用户生成事件，并将其记录到console:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># example.conf: A single-node Flume configuration</span><br><span class="line"></span><br><span class="line"># Name the components on this agent</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># Describe/configure the source</span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure><p><br></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 运行它</span></span><br><span class="line">bin/flume-ng agent --conf conf --conf-file example.conf --name a1 -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="在配置文件中使用环境变量"><a href="#在配置文件中使用环境变量" class="headerlink" title="在配置文件中使用环境变量"></a>在配置文件中使用环境变量</h3><p>Using environment variables in configuration files</p><p>Flume能够替换配置中的环境变量:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a1.sources = r1</span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = 0.0.0.0</span><br><span class="line">a1.sources.r1.port = $&#123;NC_PORT&#125;</span><br><span class="line">a1.sources.r1.channels = c1</span><br></pre></td></tr></table></figure><p><strong>注意: 环境变量目前只使用于Value，不适用于Key。</strong></p><p><br><br><br></p><h3 id="记录原始数据"><a href="#记录原始数据" class="headerlink" title="记录原始数据"></a>记录原始数据</h3><p>Logging raw data</p><p>在许多生产环境中记录流经管道的原始数据流不是所希望的行为，因为这可能导致泄露敏感数据或安全相关配置到Flume日志文件。默认情况下，Flume不会记录此类信息。另一方法，如果数据管道出错，Flume也将尝试提供DEBUG信息。</p><p>为了能够记录事件和配置相关的数据，除了 <code>log4j</code> 属性外，还必须设置一些Java系统属性。<br>要启用与配置相关的日志记录，请设置Java系统属性 <code>-Dorg.apache.flume.log.printconfig=true</code> 。这也可以在命令行上进行传递，也可以在 <code>flume-env.sh</code> 中的 <code>JAVA_OPTS</code> 变量中设置。</p><p>要启用数据记录，请按照上述相同方式设置Java系统属性 <code>-Dorg.apache.flume.log.rawdata=true</code> 。对于大多数组件，还必须将 <code>log4j</code> 日志记录级别设置为DEBUG或TRACE，以使特定于事件的日志记录显示在Flume日志中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 启用配置日志记录和原始数据日志记录的示例，同时还将Log4j日志级别设置为DEBUG以用于控制台输出</span><br><span class="line">bin/flume-ng agent --conf conf --conf-file example.conf --name a1 -Dflume.root.logger=DEBUG,console -Dorg.apache.flume.log.printconfig=true -Dorg.apache.flume.log.rawdata=true</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="Zookeeeper基础配置"><a href="#Zookeeeper基础配置" class="headerlink" title="Zookeeeper基础配置"></a>Zookeeeper基础配置</h3><p>Zookeeper based Configuration</p><p>Flume支持通过<strong>Zookeeper</strong>配置Agent的配置。这是一个实验性功能。配置文件需要在可配置前缀下的Zookeeper中上传。配置文件存储在Zookeeper Node Data中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Agent1和Agent2的Zookeeper Node Tree的示例</span><br><span class="line">- /flume</span><br><span class="line"> |- /a1 [Agent config file]</span><br><span class="line"> |- /a2 [Agent config file]</span><br></pre></td></tr></table></figure><p>一旦上传了配置文件，使用以下选项启动Agent:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -z, Zookeeper connection string. Comma separated list of hostname:port</span></span><br><span class="line"><span class="comment"># -p, Base Path in Zookeeper to store Agent configurations</span></span><br><span class="line"></span><br><span class="line"> bin/flume-ng agent –conf conf -z zkhost:2181,zkhost1:2181 -p /flume –name a1 -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="安装第三方插件"><a href="#安装第三方插件" class="headerlink" title="安装第三方插件"></a>安装第三方插件</h3><p>Installing third-party plugins</p><p>Flume拥有完整的基于插件的架构。虽然Flume附带了许多开箱即用的sources, channels, sinks, serializers…但许多实现斗鱼Flume分开运行。</p><p>虽然通过将自己的jar包添加到 <code>flume-env.sh</code> 文件中的 <code>FLUME_CLASSPATH</code> 变量值，始终可以包含自定义Flume组件。但Flume现在支持一个名为 <code>plugins.d</code> 的特殊目录，该目录会自动获取以特定格式打包的插件。</p><p><br></p><p><strong>插件目录</strong><br>The plugins.d directory</p><p><code>plugins.d</code> 目录位于 <code>$FLUME_HOME/plugins.d</code>。在启动时，<code>flume-ng</code> 启动脚本在 <code>plugins.d</code> 目录中查找符合以下格式的插件，并在启动java时将它们包含在正确的路径中。</p><p><br></p><p><strong>插件目录布局</strong><br>Directory layout for plugins</p><p><code>plugins.d</code> 中的每个插件(子目录)最多可以有三个子目录:</p><ol><li><code>lib</code> - the plugin’s jar(s)</li><li><code>libext</code> - the plugin’s dependency jar(s)</li><li><code>native</code> - any required native libraries, such as <code>.so</code> files</li></ol><p>栗子:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plugins.d/</span><br><span class="line">plugins.d/custom-source-1/</span><br><span class="line">plugins.d/custom-source-1/lib/my-source.jar</span><br><span class="line">plugins.d/custom-source-1/libext/spring-core-2.5.6.jar</span><br><span class="line">plugins.d/custom-source-2/</span><br><span class="line">plugins.d/custom-source-2/lib/custom.jar</span><br><span class="line">plugins.d/custom-source-2/native/gettext.so</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="数据摄取"><a href="#数据摄取" class="headerlink" title="数据摄取"></a>数据摄取</h2><p>Data ingestion</p><p>Flume支持许多从外部源摄取数据的机制。</p><p><br></p><h3 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h3><p>可使用RPC机制将给定文件发送到Flume Source:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 栗子</span></span><br><span class="line"><span class="comment"># 将日志内容发送到监听该端口的Flume Source</span></span><br><span class="line">bin/flume-ng avro-client -H localhost -p 41414 -F /usr/logs/log.10</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="执行命令"><a href="#执行命令" class="headerlink" title="执行命令"></a>执行命令</h3><p>Executing commands</p><p>有一个exec source执行给定的命令并消费输出。</p><p><br><br><br></p><h3 id="网路流"><a href="#网路流" class="headerlink" title="网路流"></a>网路流</h3><p>Network streams</p><p>Flume支持以下机制从常用日志流(log stream)类型中读取数据。如:</p><ul><li>Avro</li><li>Thrift</li><li>Syslog</li><li>Netcat</li></ul><p><br><br><br><br><br></p><h2 id="多个代理流"><a href="#多个代理流" class="headerlink" title="多个代理流"></a>多个代理流</h2><p>Setting multi-agent flow</p><p><img src="/images/Flume/flume-multi-agent-flow.png" alt=""></p><p>为了跨多个代理/跳(multiple agents/hops)的数据流，先前代理的接收器和当前代理的源是同一类型，接收器指向源的hostname/ip和port。</p><p><br><br><br><br><br></p><h2 id="整合"><a href="#整合" class="headerlink" title="整合"></a>整合</h2><p>Consolidation</p><p>日志收集中非常常见的情况是生成大量日志的客户端将数据发送到连接到存储子系统的少数消费者代理。例如，从数百个Web服务器收集的日志发送给写入HDFS集群的十几个代理。</p><p>这可以通过在Flume中使用接收器配置多个第一层代理，所有这些代理都指向单个源。第二层代理商的源将接收的事件合并到单个通道中，该通道有接收器消费到最终的目的地。</p><p><img src="/images/Flume/flume-consolidation.png" alt=""></p><p><br><br><br><br><br></p><h2 id="多路复用流"><a href="#多路复用流" class="headerlink" title="多路复用流"></a>多路复用流</h2><p>Multiplexing the flow</p><p>Flume支持将事件流多路复用到一个或多个目的地。这是通过定义可以复制或选择性地将事件路由到一个或多个通道的流复用器来实现的。</p><p><img src="/images/Flume/flume-multiplexing-flow.png" alt=""></p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p><a href="https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#configuration" target="_blank" rel="noopener">Configuration</a></p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="过滤"><a href="#过滤" class="headerlink" title="过滤"></a>过滤</h1><p><a href="https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#configuration-filters" target="_blank" rel="noopener">Configuration Filters</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;wikipedia&lt;/li&gt;
&lt;li&gt;Flume: &lt;a href=&quot;https://flume.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://flume.apache.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Flume docs: &lt;a href=&quot;https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ELRH7x86_64&lt;/li&gt;
&lt;li&gt;Flume v1.9.0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="Apache" scheme="https://zhang21.github.io/tags/Apache/"/>
    
      <category term="DataAnalysis" scheme="https://zhang21.github.io/tags/DataAnalysis/"/>
    
      <category term="Flume" scheme="https://zhang21.github.io/tags/Flume/"/>
    
  </entry>
  
  <entry>
    <title>Sqoop</title>
    <link href="https://zhang21.github.io/2019/03/07/Sqoop/"/>
    <id>https://zhang21.github.io/2019/03/07/Sqoop/</id>
    <published>2019-03-07T01:25:20.000Z</published>
    <updated>2019-03-07T01:30:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>wikipedia</li><li>sqoop: <a href="https://sqoop.apache.org/" target="_blank" rel="noopener">https://sqoop.apache.org/</a></li></ul><p>环境:</p><ul><li>ELRH7x84_64</li><li>Sqoop v1.4.7</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><strong>Apache Sqoop</strong> 是一个命令行界面(CLI)的应用程序工具，使用Java开发，用于在<strong>关系型数据库</strong>和<strong>Hadoop</strong>之间传输数据。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;wikipedia&lt;/li&gt;
&lt;li&gt;sqoop: &lt;a href=&quot;https://sqoop.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://sqoop.apache.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ELRH7x84_64&lt;/li&gt;
&lt;li&gt;Sqoop v1.4.7&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="Apache" scheme="https://zhang21.github.io/tags/Apache/"/>
    
      <category term="DataAnalysis" scheme="https://zhang21.github.io/tags/DataAnalysis/"/>
    
      <category term="Sqoop" scheme="https://zhang21.github.io/tags/Sqoop/"/>
    
  </entry>
  
  <entry>
    <title>Hive</title>
    <link href="https://zhang21.github.io/2019/03/06/Hive/"/>
    <id>https://zhang21.github.io/2019/03/06/Hive/</id>
    <published>2019-03-06T00:57:20.000Z</published>
    <updated>2019-03-15T02:52:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>wikipedia</li><li>Hive: <a href="https://hive.apache.org/" target="_blank" rel="noopener">https://hive.apache.org/</a></li><li>Hive Wiki: <a href="https://cwiki.apache.org/confluence/display/Hive/Home" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/Home</a></li></ul><p>环境:</p><ul><li>ELRH7x86_64</li><li>Hive v3.1</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><strong>Apache Hive</strong> 是一个建立在Hadoop架构之上的数据仓库，由Java编写，能够提供数据的精炼，查询和分析。</p><p>Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的SQL查询功能，可以将SQL语句转换为MapReduce任务进行运行。其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。</p><p>Apache Hive 数据仓库软件有助于使用SQL读取，编写和管理驻留在分布式存储中的大型数据集。可以将结构投影到已存储的数据中。还提供了命令行工具和JDBC驱动程序以将用户连接到Hive。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;wikipedia&lt;/li&gt;
&lt;li&gt;Hive: &lt;a href=&quot;https://hive.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://hive.apache.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hive Wiki: &lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Home&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/Home&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ELRH7x86_64&lt;/li&gt;
&lt;li&gt;Hive v3.1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="Apache" scheme="https://zhang21.github.io/tags/Apache/"/>
    
      <category term="Hive" scheme="https://zhang21.github.io/tags/Hive/"/>
    
      <category term="DataAnalysis" scheme="https://zhang21.github.io/tags/DataAnalysis/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop</title>
    <link href="https://zhang21.github.io/2019/03/06/Hadoop/"/>
    <id>https://zhang21.github.io/2019/03/06/Hadoop/</id>
    <published>2019-03-05T16:57:11.000Z</published>
    <updated>2019-03-25T03:37:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>wikipeadia</li><li>Hadoop官网: <a href="https://hadoop.apache.org/" target="_blank" rel="noopener">https://hadoop.apache.org/</a></li><li>Apache Software Foundation: <a href="https://www.apache.org/" target="_blank" rel="noopener">https://www.apache.org/</a></li></ul><p><br></p><p>环境:</p><ul><li>RHEL7x86_64</li><li>Hadoop v3.2.0</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><strong>Apache Hadoop</strong> 是一款支持数据密集型分布式应用程序，使用Java编写，并以Apache 2.0许可协议发布的开源软件框架。<br>Hadoop是根据谷歌公司发表的MapReduce和Google文件系统的论文自行实现而成。所有的Hadoop模块都有一个基本假设，即硬件故障是常见情况，应该由框架自动处理。</p><p>Apach Hadoop项目开发了用于可靠(Reliable)，可扩展(Scalable)的分布式计算(Distributed Computing)的开源软件。</p><p>Hadoop框架透明地为应用提供可靠性和数据移动。它实现了名为MapReduce的编程范式：应用程序被分割成许多小部分，而每个部分都能在集群中的任意节点上运行或重新运行。此外，Hadoop还提供了分布式文件系统，用以存储所有计算节点的数据，这为整个集群带来了非常高的带宽。MapReduce和分布式文件系统的设计，使得整个框架能够自动处理节点故障。它使应用程序与成千上万的独立计算的计算机和PB级的数据连接起来。</p><p><img src="/images/Hadoop/hadoop-logo.jpg" alt=""></p><p><br></p><h2 id="Modules"><a href="#Modules" class="headerlink" title="Modules"></a>Modules</h2><p>Hadoop 项目包括以下模块:</p><ul><li><strong>Hadoop Common</strong>: 支持其它Hadoop模块的常用实用程序</li><li><strong>Hadoop Distributed File System (HDFS)</strong>: 一种分布式文件系统，提供对应用程序数据的高吞吐量访问</li><li><strong>Hadoop YARN</strong>: 用于作业调度和集群资源管理的框架</li><li><strong>Hadoop MapReduce</strong>: 基于YARN的系统，用于并行处理大型数据集</li><li><strong>Hadoop Ozone</strong>: Hadoop的对象存储</li><li><strong>Hadoop Submarine</strong>: Hadoop的机器学习引擎</li></ul><p><br><br><br><br><br></p><h2 id="相关项目"><a href="#相关项目" class="headerlink" title="相关项目"></a>相关项目</h2><p>现在普遍认为整个 <strong>Apache Hadoop Platform</strong> 包括了许多项目:</p><ul><li><strong>Ambari</strong>: 一个基于Web的工具，用于配置，管理和监控Apache Hadoop集群。包括对HDFS, MapReduce, Hive, HBase, ZooKeeper, Pig, Sqoop…的支持。它还提供了一个用于查看群集运行状况的仪表板，用于查看各个程序的状态</li><li><strong>Avro</strong>：数据序列化系统。新的数据序列化格式与传输工具，将逐步取代Hadoop原有的IPC机制</li><li><strong>Cassandra</strong>: 可扩展的多主数据库，没有单点故障</li><li><strong>Chukwa</strong>: 用于管理大型分布式系统的数据收集系统</li><li><strong>Flume</strong>: 一种分布式，可靠且可用的软件。用于高效收集(collecting)，聚合(aggregating)和移动(moving)大量日志数据</li><li><strong>HBase</strong>：可扩展的分布式NoSQL列数据库，支持大型表的结构化数据存储。类似谷歌公司BigTable</li><li><strong>Hive</strong>：一种数据仓库基础结构，提供数据摘要和即席查询。构建于hadoop之上的数据仓库，通过一种类SQL语言HiveQL为用户提供数据的归纳、查询和分析等功能。Hive最初由Facebook贡献</li><li><strong>Mahout</strong>：可扩展的机器学习和数据挖掘库</li><li><strong>Pig</strong>: 用于并行计算的高级数据流语言和执行框架</li><li><strong>Spark</strong>: 适用于Hadoop数据的快速通用计算引擎。Spark提供了一种简单而富有表现力的编程模型，支持广泛的应用程序</li><li><strong>Sqoop</strong>：结构化数据（如关系数据库）与Apache Hadoop之间的数据转换工具</li><li><strong>Tez</strong>: 基于Hadoop YARN的通用数据流编程框架，它提供了一个强大而灵活的引擎来执行任意DAG任务来处理批处理和交互式用例的数据</li><li><strong>ZooKeeper</strong>：适用于分布式应用程序的高性能协调服务。提供类似Google Chubby的功能，由Facebook贡献</li></ul><p><br><br><br></p><hr><p><br><br><br></p><h1 id="General"><a href="#General" class="headerlink" title="General"></a>General</h1><p><br></p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Overview</p><p><strong>Node Attributes Support in YARN</strong></p><p>节点属性(Node Attribute)有助于根据节点标记(tag)节点上的多个标签(label)，并支持根据这些标签的表达式放置容器。</p><p><br></p><p><strong>Hadoop Submarine on YARN</strong></p><p>Hadoop Submarine 使数据工程师能够在数据所在的同一Hadoop YARN集群上轻松开发(develop)、训练(train)和部署(deploy)深度学习模型(TensorFlow)。</p><p><br></p><p><strong>Storage Policy Satisfier</strong></p><p>支持HDFS(Hadoop Distributed File System)应用程序，以便在文件/目录上设置存储策略时在存储类型之间移动块(block)。</p><p><br></p><p><strong>ABFS Filesystem connector</strong></p><p>支持最新的Azure Datalake Gen2 Storage。</p><p><br></p><p><strong>Enhanced S3A connector</strong></p><p>支持增强型S3A连接器，包括更好地恢复受限制的AWS S3和DynamoDB IO。</p><p><br></p><p><strong>Upgrades for YARN long running services</strong></p><p>支持通过YARN Native Service API和CLI对长时间运行的容器进行就地无缝(seamless)升级。</p><p><br><br><br><br><br></p><h2 id="单节点集群"><a href="#单节点集群" class="headerlink" title="单节点集群"></a>单节点集群</h2><p>Setting up a Single Node Cluster</p><p><br></p><h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h3><p>本节介绍如何设置和配置单节点Hadoop集群，以便你可以快速使用Hadoop MapReduce和HDFS执行简单的操作。</p><p><br><br><br></p><h3 id="先决条件"><a href="#先决条件" class="headerlink" title="先决条件"></a>先决条件</h3><ul><li><p><strong>支持的平台</strong></p><ul><li>GNU/Linux: Hadoop has been demonstrated on GNU/Linux clusters with 2000 nodes</li><li>Windows is also a supported platform but the followings steps are for Linux only.</li></ul></li><li><p><strong>依赖软件(Linux)</strong></p><ul><li>Java: 具体版本参考 <a href="https://wiki.apache.org/hadoop/HadoopJavaVersions" target="_blank" rel="noopener">HadoopJavaVersions</a></li><li>ssh: 必须运行sshd才能使用管理远程Hadoop守护程序的Hadoop脚本，建议按照pdsh以实现更好的ssh资源管子</li></ul></li><li><p><strong>安装软件</strong></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Ubuntu</span></span><br><span class="line">sudo apt-get install ssh pdsh</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>获取Hadoop发行版，请从<a href="http://www.apache.org/dyn/closer.cgi/hadoop/common/" target="_blank" rel="noopener">Apache Download Mirrors</a>下载。</p><p><br><br><br></p><h3 id="准备启动Hadoop集群"><a href="#准备启动Hadoop集群" class="headerlink" title="准备启动Hadoop集群"></a>准备启动Hadoop集群</h3><p>解压前面下载的Hadoop发行版，编辑<code>hadoop/etc/hadoop/hadoop-env.sh</code>以定义一些参数:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># hadoop/etc/hadoop/hadoop-env.sh</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># set to the root of your Java installation</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.8.0_191-amd64</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME= /opt/hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment"># 由于我是使用rpm安装jdk8，所以为/usr/java/jdk1.8.0_191-amd64</span></span><br><span class="line"><span class="comment"># 我的hadoop放置于/opt/hadoop</span></span><br></pre></td></tr></table></figure><p>接着运行以下命令:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./bin/hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这将显示Hadoop的使用文档</span></span><br></pre></td></tr></table></figure><p><br></p><p><strong>有三种方式来启动Hadoop集群:</strong></p><ul><li>Local (Standalone) Mode</li><li>Pseudo-Distributed Mode</li><li>Fully-Distributed Mode</li></ul><p><br><br><br><br><br></p><h3 id="Standalone"><a href="#Standalone" class="headerlink" title="Standalone"></a>Standalone</h3><p>默认情况下，Hadoop配置为non-distibuted模式运行，作为单个Java进程。这对调试很有用。</p><p><br><br><br></p><h3 id="Pseudo-Distributed-Operation"><a href="#Pseudo-Distributed-Operation" class="headerlink" title="Pseudo-Distributed Operation"></a>Pseudo-Distributed Operation</h3><p>Hadoop也可以运行在伪分布模式下的单节点上，其中每个Hadoop Daemon在单独的java进程中运行。</p><p><br></p><p><strong>配置</strong><br><code>hadoop/etc/hadoop/core-site.xml</code>:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><code>hadoop/etc/hadoop/hdfs-site.xml</code>:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><br></p><p><strong>设置 passphraseless ssh</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查是否可以下无密码(passphrase)的情况下ssh到localhost</span></span><br><span class="line">ssh localhost</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果不行，请执行无密码登录操作</span></span><br><span class="line">ssh-keygen -t rsa -P <span class="string">''</span> -f ~/.ssh/id_rsa</span><br><span class="line">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">chmod 0600 ~/.ssh/authorized_keys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 之后再执行此操作</span></span><br><span class="line">ssh localhost</span><br></pre></td></tr></table></figure><p><br></p><p><strong>执行</strong></p><p>以下说明在本地运行MapReduce job。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意，以下位于hadoop目录</span></span><br><span class="line"><span class="comment"># 我的为 /opt/hadoop</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Format the filesystem</span></span><br><span class="line"><span class="comment"># namenode - run the DFS namenode</span></span><br><span class="line">bin/hdfs namenode -format</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Start NameNode daemon and DataNode daemon</span></span><br><span class="line">sbin/start-dfs.sh</span><br><span class="line"><span class="comment"># 日志输出到$HADOOP_HOME/logs</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. Browse the web interface for the NameNode; by default it is available at:</span></span><br><span class="line">NameNode - http://localhost:9870/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. Make the HDFS directories required to execute MapReduce jobs</span></span><br><span class="line">bin/hdfs dfs -mkdir /user</span><br><span class="line">bin/hdfs dfs -mkdir /user/&lt;username&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. Copy the input files into the distributed filesystem</span></span><br><span class="line">bin/hdfs dfs -mkdir input</span><br><span class="line">bin/hdfs dfs -put etc/hadoop/*.xml input</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. Run some of the examples provided</span></span><br><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.0.jar grep input output <span class="string">'dfs[a-z.]+'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 7. Examine the output files: Copy the output files from the distributed filesystem to the local filesystem and examine them</span></span><br><span class="line">bin/hdfs dfs -get output output</span><br><span class="line"><span class="comment"># cat output/*</span></span><br><span class="line"><span class="comment"># bin/hdfs dfs -cat output/*</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 8. When you’re done, stop the daemons with</span></span><br><span class="line">sbin/stop-dfs.sh</span><br></pre></td></tr></table></figure><p><br></p><p><strong>YARN on a Single Node</strong></p><p>你可以通过设置一些参数并运行ResourceManager Daemon和NodeManager Daemon，以伪分布模式在YARN上运行MapReduce Job。<br>以下指令假设你已运行上面的1-4步。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. Configure parameters as follows</span></span><br><span class="line"><span class="comment"># etc/hadoop/mapred-site.xml</span></span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;<span class="variable">$HADOOP_MAPRED_HOME</span>/share/hadoop/mapreduce/*:<span class="variable">$HADOOP_MAPRED_HOME</span>/share/hadoop/mapreduce/lib/*&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># etc/hadoop/yarn-site.xml</span></span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Start ResourceManager daemon and NodeManager daemon</span></span><br><span class="line">sbin/start-yarn.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Browse the web interface for the ResourceManager; by default it is available at</span></span><br><span class="line"><span class="comment"># ResourceManager - http://localhost:8088/</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. Run a MapReduce job</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. When you’re done, stop the daemons with</span></span><br><span class="line">sbin/stop-yarn.sh</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="集群设置"><a href="#集群设置" class="headerlink" title="集群设置"></a>集群设置</h2><p>Hadoop Cluster Setup</p><p>本节描述了如何安装和配置Hadoop集群，范围从几个节点到数千个节点。<br>但本节不包括安全性和高可用性等高级主题。</p><p><br></p><h3 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h3><ul><li>Java</li><li>Hadoop</li></ul><p><br><br><br></p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>通常，集群中的一台主机被指定为<strong>NameNode</strong>，而另一台主机被指定为<strong>ResourceManager</strong>，这些都是<strong>Master</strong>。其它服务(Web App Proxy Server, MapReduce…)通常在专用硬件或共享基础架构上运行，具体取决于负载。</p><p>集群中的其余主机充当<strong>DataNode</strong>和<strong>NodeManager</strong>。这些都是<strong>Worker</strong>。</p><p><br><br><br></p><h3 id="在非安全模式下配置Hadoop"><a href="#在非安全模式下配置Hadoop" class="headerlink" title="在非安全模式下配置Hadoop"></a>在非安全模式下配置Hadoop</h3><p>Configuring Hadoop in Non-Secure Mode</p><p>Hadoop的Java配置由两种类型的重要配置文件驱动:</p><ul><li><strong>只读(ReadOnly)的默认配置</strong><ul><li><code>core-default.xml</code></li><li><code>hdfs-default.xml</code></li><li><code>yarn-default.xml</code></li><li><code>mapred-default.xml</code></li></ul></li><li><strong>特定站点(site-specific)的配置</strong><ul><li><code>etc/hadoop/core-site.xml</code></li><li><code>etc/hadoop/hdfs-site.xml</code></li><li><code>etc/hadoop/yarn-site.xml</code></li><li><code>etc/hadoop/mapred-site.xml</code></li></ul></li></ul><p>此外，你可以通过<code>etc/hadoop/hadoop-env.sh</code>和<code>etc/hadoop/yarn-env.sh</code>配置特定于站点的值来控制分发的<code>bin/</code>目录下的Hadoop脚本。</p><p><br></p><p>要配置Hadoop Cluster，你需要配置Hadoop Daemon执行的<code>environment</code>以及<code>configuration parameters</code>。</p><ul><li>HDFS Daemon是 <strong>NameNode</strong>, <strong>SecondaryNameNode</strong> 和 <strong>DataNode</strong></li><li>YARN Daemon是 <strong>ResourceManager</strong>, <strong>NodeManager</strong> 和 <strong>WebAppProxy</strong></li><li>如果要使用MapReduce，则 <strong>MapReduce Job History Server</strong> 也将运行</li><li>对于大型安装，这些通常在不同的主机上运行</li></ul><p><br></p><h4 id="配置Hadoop守护进程的环境"><a href="#配置Hadoop守护进程的环境" class="headerlink" title="配置Hadoop守护进程的环境"></a>配置Hadoop守护进程的环境</h4><p>Configuring Environment of Hadoop Daemons</p><p>管理员应该使用 <code>etc/hadoop/hadoop-env.sh</code>， 可选择 <code>etc/hadoop/mapred-env.sh</code>, 以及 <code>etc/hadoop/yarn-env.sh</code>脚本来对Hadoop守护进程的进程环境进行特定站点的自定义配置。</p><p>至少，您必须指定 <code>JAVA_HOME</code>，以便在每个远程节点上正确定义它。</p><p>管理员可使用下表中的配置项配置各个守护进程:</p><table><thead><tr><th>Daemon</th><th>Environment Variable</th></tr></thead><tbody><tr><td>NameNode</td><td>HDFS_NAMENODE_OPTS</td></tr><tr><td>DataNode</td><td>HDFS_DATANODE_OPTS</td></tr><tr><td>Secondary NameNode</td><td>HDFS_SECONDARYNAMENODE_OPTS</td></tr><tr><td>ResourceManager</td><td>YARN_RESOURCEMANAGER_OPTS</td></tr><tr><td>NodeManager</td><td>YARN_NODEMANAGER_OPTS</td></tr><tr><td>WebAppProxy</td><td>YARN_PROXYSERVER_OPTS</td></tr><tr><td>Map Reduce Job History Server</td><td>MAPRED_HISTORYSERVER_OPTS</td></tr></tbody></table><p><br></p><p>其它你可自定义的有用的配置项包括:</p><ul><li><code>HADOOP_PID_DIR</code>:  The directory where the daemons’ process id files are stored</li><li><code>HADOOP_LOG_DIR</code>:  The directory where the daemons’ log files are stored. Log files are automatically created if they don’t exist</li><li><code>HADOOP_HEAPSIZE_MAX</code>:  The maximum amount of memory to use for the Java heapsize. Units supported by the JVM are also supported here. If no unit is present, it will be assumed the number is in megabytes. By default, Hadoop will let the JVM determine how much to use. This value can be overriden on a per-daemon basis using the appropriate _OPTS variable listed above. For example, setting HADOOP_HEAPSIZE_MAX=1g and HADOOP_NAMENODE_OPTS=”-Xmx5g” will configure the NameNode with 5GB heap.</li></ul><p>在大多数情况下，你需要指定 <code>HADOOP_PID_DIR</code> 和 <code>HADOOP_LOG</code> 目录，以便它们只能由将要运行Hadoop守护进程的用户写入。否则可能会发生符号链接攻击。</p><p><br><br><br></p><h4 id="配置Hadoop守护进程"><a href="#配置Hadoop守护进程" class="headerlink" title="配置Hadoop守护进程"></a>配置Hadoop守护进程</h4><p>Configuring the Hadoop Daemons</p><p>本节介绍给定配置文件中指定的重要参数。</p><ul><li><code>etc/hadoop/core-site.xml</code></li></ul><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>fs.defaultFS</code></td><td>NameNode URI</td><td>hdfs://host:port/</td></tr><tr><td><code>io.file.buffer.size</code></td><td>131072</td><td>Size of read/write buffer used in SequenceFiles.</td></tr></tbody></table><p><br></p><ul><li><code>etc/hadoop/hdfs-site.xml</code></li><li><strong>NameNode配置</strong></li></ul><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>dfs.namenode.name.dir</code></td><td>Path on the local filesystem where the NameNode stores the namespace and transactions logs persistently.</td><td>If this is a comma-delimited list of directories then the name table is replicated in all of the directories, for redundancy.</td></tr><tr><td><code>dfs.hosts /</code> <br> <code>dfs.hosts.exclude</code></td><td>List of permitted/excluded DataNodes.</td><td>If necessary, use these files to control the list of allowable datanodes.</td></tr><tr><td><code>dfs.blocksize</code></td><td>268435456</td><td>HDFS blocksize of 256MB for large file-systems.</td></tr><tr><td><code>dfs.namenode.handler.count</code></td><td>100</td><td>More NameNode server threads to handle RPCs from large number of DataNodes.</td></tr></tbody></table><p><br></p><ul><li><strong>DataNode配置</strong></li></ul><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td>dfs.datanode.data.dir</td><td>Comma separated list of paths on the local filesystem of a DataNode where it should store its blocks.</td><td>If this is a comma-delimited list of directories, then data will be stored in all named directories, typically on different devices.</td></tr></tbody></table><p><br></p><ul><li><code>etc/hadoop/yarn-site.xml</code></li><li><strong>ResourceManager和NodeManager配置</strong></li></ul><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>yarn.acl.enable</code></td><td>true / false</td><td>Enable ACLs? Defaults to false.</td></tr><tr><td><code>yarn.admin.acl</code></td><td>Admin ACL</td><td>ACL to set admins on the cluster. ACLs are of for comma-separated-usersspacecomma-separated-groups. Defaults to special value of * which means anyone. Special value of just space means no one has access.</td></tr><tr><td><code>yarn.log-aggregation-enable</code></td><td>false</td><td>Configuration to enable or disable log aggregation</td></tr></tbody></table><br><ul><li><strong>ResourceManager配置</strong></li></ul><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>yarn.resourcemanager.address</code></td><td>ResourceManager host:port for clients to submit jobs.</td><td>host:port If set, overrides the hostname set in yarn.resourcemanager.hostname.</td></tr><tr><td><code>yarn.resourcemanager.scheduler.address</code></td><td>ResourceManager host:port for ApplicationMasters to talk to Scheduler to obtain resources.</td><td>host:port If set, overrides the hostname set in yarn.resourcemanager.hostname.</td></tr><tr><td><code>yarn.resourcemanager.resource-tracker.address</code></td><td>ResourceManager host:port for NodeManagers.</td><td>host:port If set, overrides the hostname set in yarn.resourcemanager.hostname.</td></tr><tr><td><code>yarn.resourcemanager.admin.address</code></td><td>ResourceManager host:port for administrative commands.</td><td>host:port If set, overrides the hostname set in yarn.resourcemanager.hostname.</td></tr><tr><td><code>yarn.resourcemanager.webapp.address</code></td><td>ResourceManager web-ui host:port.</td><td>host:port If set, overrides the hostname set in yarn.resourcemanager.hostname.</td></tr><tr><td><code>yarn.resourcemanager.hostname</code></td><td>ResourceManager host.</td><td>host Single hostname that can be set in place of setting all yarn.resourcemanager*address resources. Results in default ports for ResourceManager components.</td></tr><tr><td><code>yarn.resourcemanager.scheduler.class</code></td><td>ResourceManager Scheduler class.</td><td>CapacityScheduler (recommended), FairScheduler (also recommended), or FifoScheduler.</td></tr><tr><td><code>yarn.scheduler.minimum-allocation-mb</code></td><td>Minimum limit of memory to allocate to each container request at the Resource Manager.</td><td>In MBs</td></tr><tr><td><code>yarn.scheduler.maximum-allocation-mb</code></td><td>Maximum limit of memory to allocate to each container request at the Resource Manager.</td><td>In MBs</td></tr><tr><td><code>yarn.resourcemanager.nodes.include-path</code> / <br> <code>yarn.resourcemanager.nodes.exclude-path</code></td><td>List of permitted/excluded NodeManagers.</td><td>If necessary, use these files to control the list of allowable NodeManagers.</td></tr></tbody></table><p><br></p><ul><li><strong>NodeManager配置</strong></li></ul><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>yarn.nodemanager.resource.memory-mb</code></td><td>Resource i.e. available physical memory, in MB, for given NodeManager</td><td>Defines total available resources on the NodeManager to be made available to running containers</td></tr><tr><td><code>yarn.nodemanager.vmem-pmem-ratio</code></td><td>Maximum ratio by which virtual memory usage of tasks may exceed physical memory</td><td>The virtual memory usage of each task may exceed its physical memory limit by this ratio. The total amount of virtual memory used by tasks on the NodeManager may exceed its physical memory usage by this ratio.</td></tr><tr><td><code>yarn.nodemanager.local-dirs</code></td><td>Comma-separated list of paths on the local filesystem where intermediate data is written.</td><td>Multiple paths help spread disk i/o.</td></tr><tr><td><code>yarn.nodemanager.log-dirs</code></td><td>Comma-separated list of paths on the local filesystem where logs are written.</td><td>Multiple paths help spread disk i/o.</td></tr><tr><td><code>yarn.nodemanager.log.retain-seconds</code></td><td>10800</td><td>Default time (in seconds) to retain log files on the NodeManager Only applicable if log-aggregation is disabled.</td></tr><tr><td><code>yarn.nodemanager.remote-app-log-dir</code></td><td>/logs</td><td>HDFS directory where the application logs are moved on application completion. Need to set appropriate permissions. Only applicable if log-aggregation is enabled.</td></tr><tr><td><code>yarn.nodemanager.remote-app-log-dir-suffix</code></td><td>logs</td><td>Suffix appended to the remote log dir. Logs will be aggregated to ${yarn.nodemanager.remote-app-log-dir}/${user}/${thisParam} Only applicable if log-aggregation is enabled.</td></tr><tr><td><code>yarn.nodemanager.aux-services</code></td><td>mapreduce_shuffle</td><td>Shuffle service that needs to be set for Map Reduce applications.</td></tr><tr><td><code>yarn.nodemanager.env-whitelist</code></td><td>Environment properties to be inherited by containers from NodeManagers</td><td>For mapreduce application in addition to the default values HADOOP_MAPRED_HOME should to be added. <br> 可能的值有: <code>JAVA_HOME</code>, <code>HADOOP_COMMON_HOME</code>, <code>HADOOP_HDFS_HOME</code>, <code>HADOOP_CONF_DIR</code>, <code>CLASSPATH_PREPEND_DISTCACHE</code>, <code>HADOOP_YARN_HOME</code>, <code>HADOOP_MAPRED_HOME</code></td></tr></tbody></table><p><br></p><ul><li><strong>History Server配置</strong></li></ul><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>yarn.log-aggregation.retain-seconds</code></td><td>-1</td><td>How long to keep aggregation logs before deleting them. -1 disables. Be careful, set this too small and you will spam the name node.</td></tr><tr><td><code>yarn.log-aggregation.retain-check-interval-seconds</code></td><td>-1</td><td>Time between checks for aggregated log retention. If set to 0 or a negative value then the value is computed as one-tenth of the aggregated log retention time. Be careful, set this too small and you will spam the name node.</td></tr></tbody></table><p><br></p><ul><li><code>etc/hadoop/mapred-site.xml</code></li><li><strong>MapReduce Applications配置</strong></li></ul><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>mapreduce.framework.name</code></td><td>yarn</td><td>Execution framework set to Hadoop YARN.</td></tr><tr><td><code>mapreduce.map.memory.mb</code></td><td>1536</td><td>Larger resource limit for maps.</td></tr><tr><td><code>mapreduce.map.java.opts</code></td><td>-Xmx1024M</td><td>Larger heap-size for child jvms of maps.</td></tr><tr><td><code>mapreduce.reduce.memory.mb</code></td><td>3072</td><td>Larger resource limit for reduces.</td></tr><tr><td><code>mapreduce.reduce.java.opts</code></td><td>-Xmx2560M</td><td>Larger heap-size for child jvms of reduces.</td></tr><tr><td><code>mapreduce.task.io.sort.mb</code></td><td>512</td><td>Higher memory-limit while sorting data for efficiency.</td></tr><tr><td><code>mapreduce.task.io.sort.factor</code></td><td>100</td><td>More streams merged at once while sorting files.</td></tr><tr><td><code>mapreduce.reduce.shuffle.parallelcopies</code></td><td>50</td><td>Higher number of parallel copies run by reduces to fetch outputs from very large number of maps.</td></tr></tbody></table><p><br></p><ul><li><strong>MapReduce JobHistory Server配置</strong></li></ul><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>mapreduce.jobhistory.address</code></td><td>MapReduce JobHistory Server host:port</td><td>Default port is 10020.</td></tr><tr><td><code>mapreduce.jobhistory.webapp.address</code></td><td>MapReduce JobHistory Server Web UI host:port</td><td>Default port is 19888.</td></tr><tr><td><code>mapreduce.jobhistory.intermediate-done-dir</code></td><td><code>/mr-history/tmp</code></td><td>Directory where history files are written by MapReduce jobs.</td></tr><tr><td><code>mapreduce.jobhistory.done-dir</code></td><td><code>/mr-history/done</code></td><td>Directory where history files are managed by the MR JobHistory Server.</td></tr></tbody></table><p><br><br><br></p><h3 id="监控NodeManager健康"><a href="#监控NodeManager健康" class="headerlink" title="监控NodeManager健康"></a>监控NodeManager健康</h3><p>Monitoring Health of NodeManagers</p><p>Hadoop提供了一种机制，管理员可通过该机制将NodeManager定期运行提供的脚本，以确定节点是否健康。</p><p>管理员可通过在脚本中执行对其选择的任何检查来确定节点是否处于正常状态。如果脚本检测到节点处于不健康状态，则必须以<strong>ERROR</strong>开头的字符串将其行输出到标准输出(std out)。NodeManager定期生成脚本并检查其输出。如果脚本的输出包含字符串<strong>ERROR</strong>(如上所述)，则节点的状态将报告为不健康(<strong>unhealthy</strong>)，并且ResourceManager将节点列入黑名单。之后便不会为此节点分配其它任务。但是，NodeManager继续运行脚本，因此如果节点再次变为健康(<strong>healthy</strong>)，它将自动从ResourceManager上的黑名单节点中被删除。在ResourceManger Web UI中，管理员可以使用节点的运行状况以及脚本的输出(如果不健康)。自节点健康依赖的时间也显示在Web UI上。</p><p>以下 <code>etc/hadoop/yarn-site.xml</code> 文件中的参数可用于控制节点健康监控脚本:</p><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>yarn.nodemanager.health-checker.script.path</code></td><td>Node health script</td><td>Script to check for node’s health status.</td></tr><tr><td><code>yarn.nodemanager.health-checker.script.opts</code></td><td>Node health script options</td><td>Options for script to check for node’s health status.</td></tr><tr><td><code>yarn.nodemanager.health-checker.interval-ms</code></td><td>Node health script interval</td><td>Time interval for running health script.</td></tr><tr><td><code>yarn.nodemanager.health-checker.script.timeout-ms</code></td><td>Node health script timeout interval</td><td>Timeout for health script execution.</td></tr></tbody></table><p>如果只有部分本地磁盘变坏，则运行健康检查的脚本不应该给出<strong>ERROR</strong>信息。NodeManager能够定期检查本地磁盘的运行状况（具体检查 <code>nodemanager-local-dirs</code> 和 <code>nodemanager-log-dirs</code> ），并在根据为配置属性 <code>yarn.nodemanager.disk-health-checker.min-healthy-disks</code> 设置的值达到坏目录数阈值(threshold of number of bad directories)，整个节点被标记为不健康，此信息也被发送到ResourceManager。引导磁盘(boot disk)中的故障也会被检查脚本所识别。</p><p><br><br><br></p><h3 id="Slaves-File"><a href="#Slaves-File" class="headerlink" title="Slaves File"></a>Slaves File</h3><p>在 <code>etc/hadoop/workers</code> 文件中列出所有Worker的hostname或IP addr，每行一个。帮助脚本将使用 <code>etc/hadoop/workers</code> 文件一次在多个主机上运行命令。它不用于任何基于Java的Hadoop配置。要使用此功能，必须为用于运行Hadoop的账户建立SSH信任(SSH无秘钥或Kerberos)。</p><p><br><br><br></p><h3 id="Rack-Awareness"><a href="#Rack-Awareness" class="headerlink" title="Rack Awareness"></a>Rack Awareness</h3><p>许多Hadoop组件都具有机架感知(<strong>rack-aware</strong>)功能，并利用网络拓扑结构提高性能和安全。Hadoop Daemons通过调用管理员配置的模块来获取集群中Workers的机架信息。</p><p>强烈建议在启动HDFS之前配置Rack Awareness！</p><p><br><br><br></p><h3 id="Logging"><a href="#Logging" class="headerlink" title="Logging"></a>Logging</h3><p>Hadoop通过Apache Commons Logging框架使用<strong>Apache log4j</strong>进行日志记录。编辑 <code>etc/hadoop/log4j.properties</code> 文件以自定义Hadoop Daemons的日志记录配置。</p><p><br><br><br></p><h3 id="操作集群"><a href="#操作集群" class="headerlink" title="操作集群"></a>操作集群</h3><p>Operating the Hadoop Cluster</p><p>完成所有必要的配置后，将文件分发到所有主机上的 <code>HADOOP_CONF_DIR</code> 目录。这应该是所有主机上的同一个目录。</p><p>通常，建议HDFS和YARN使用分开的用户来运行。在大多数安装中，HDFS进程以<code>hdfs</code>用户运行；YARN使用<code>yarn</code>用户运行。</p><p><br></p><h4 id="Startup-and-Shutdown"><a href="#Startup-and-Shutdown" class="headerlink" title="Startup and Shutdown"></a>Startup and Shutdown</h4><p>Hadoop Startup and Hadoop Shutdown</p><p><strong>要启动Hadoop集群，你需要启动HDFS和YARN集群。</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一次启动HDFS时，必须对其进行格式化。将新的分布式文件系统(distributed fs)格式化为hdfs</span></span><br><span class="line">[hdfs]$ <span class="variable">$HADOOP_HOME</span>/bin/hdfs namenode -format &lt;cluster_name&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在指定节点以hdfs启动HDFS NameNode</span></span><br><span class="line">[hdfs]$ <span class="variable">$HADOOP_HOME</span>/bin/hdfs --daemon start namenode</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止NameNode</span></span><br><span class="line">[hdfs]$ <span class="variable">$HADOOP_HOME</span>/bin/hdfs --daemon stop namenode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在每个指定节点以hdfs启动HDFS DataNode</span></span><br><span class="line">[hdfs]$ <span class="variable">$HADOOP_HOME</span>/bin/hdfs --daemon start datanode</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止DataNode</span></span><br><span class="line">[hdfs]$ <span class="variable">$HADOOP_HOME</span>/bin/hdfs --daemon stop datanode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果配置了 etc/hadoop/worker 和 SSH信任，则可以使用使用程序脚本以hdfs启动HDFS进程</span></span><br><span class="line">[hdfs]$ <span class="variable">$HADOOP_HOME</span>/sbin/start-dfs.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止HDFS进程</span></span><br><span class="line">[hdfs]$ <span class="variable">$HADOOP_HOME</span>/sbin/stop-dfs.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># SSH trusted access</span></span><br><span class="line">ssh-keygen -t rsa -P <span class="string">''</span> -f ~/.ssh/id_rsa</span><br><span class="line">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">chmod 0600 ~/.ssh/authorized_keys</span><br><span class="line"><span class="comment"># 也可将已有的公钥直接写入</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以yarn在指定的ResourceManager上启动YARN</span></span><br><span class="line">[yarn]$ <span class="variable">$HADOOP_HOME</span>/bin/yarn --daemon start resourcemanager</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止ResourceManager</span></span><br><span class="line">[yarn]$ <span class="variable">$HADOOP_HOME</span>/bin/yarn --daemon stop resourcemanager</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以yarn在每台指定主机上运行脚本启动NodeManager</span></span><br><span class="line">[yarn]$ <span class="variable">$HADOOP_HOME</span>/bin/yarn --daemon start nodemanager</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止NodeManager</span></span><br><span class="line">[yarn]$ <span class="variable">$HADOOP_HOME</span>/bin/yarn --daemon stop nodemanager</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以yarn在WebAppProxy Server上启动Standalone WebAPPProxy Server</span></span><br><span class="line"><span class="comment"># 如果使用多个Server进行负载均衡，则应在每台Server上运行</span></span><br><span class="line">[yarn]$ <span class="variable">$HADOOP_HOME</span>/bin/yarn --daemon start proxyserver</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止WebAppProxy server</span></span><br><span class="line">[yarn]$ <span class="variable">$HADOOP_HOME</span>/bin/yarn stop proxyserver</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果配置了 etc/hadoop/workers 和 SSH信任，则可以以yarn实用程序脚本启动YARN进程</span></span><br><span class="line">[yarn]$ <span class="variable">$HADOOP_HOME</span>/sbin/start-yarn.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止YARN进程</span></span><br><span class="line">[yarn]$ <span class="variable">$HADOOP_HOME</span>/sbin/stop-yarn.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以mapred在指定的服务器上运行MapReduce JobHistory Server</span></span><br><span class="line">[mapred]$ <span class="variable">$HADOOP_HOME</span>/bin/mapred --daemon start historyserver</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止MapReduce JobHistory Server</span></span><br><span class="line">[mapred]$ <span class="variable">$HADOOP_HOME</span>/bin/mapred --daemon stop historyserver</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="Web-Interfaces"><a href="#Web-Interfaces" class="headerlink" title="Web Interfaces"></a>Web Interfaces</h3><p>一旦Hadoop Cluster启动并运行，请检查组件的Web UI。具体如下:</p><table><thead><tr><th>Daemon</th><th>Web Interface</th><th>Notes</th></tr></thead><tbody><tr><td>NameNode</td><td><code>http://nn_host:port/</code></td><td>Default HTTP port is 9870</td></tr><tr><td>ResourceManager</td><td><code>http://rm_host:port/</code></td><td>Default HTTP port is 8088</td></tr><tr><td>MapReduce JobHistory Server</td><td><code>http://jhs_host:port/</code></td><td>Default HTTP port is 19888</td></tr></tbody></table><p><br><br><br><br><br></p><h2 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h2><p>Hadoop Commands Guide</p><p><br></p><h3 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h3><p>所有Hadoop命令和子项目都遵循相同的基本结构:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Usage</span></span><br><span class="line">shellcommand [SHELL_OPTIONS] [COMMAND] [GENERIC_OPTIONS] [COMMAND_OPTIONS]</span><br></pre></td></tr></table></figure><p><br></p><p><strong>Shell Options</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">--buildpathsEnables developer versions of jars.</span><br><span class="line"></span><br><span class="line">--config confdirOverwrites the default Configuration directory. Default is $HADOOP_HOME/etc/hadoop.</span><br><span class="line"></span><br><span class="line">--daemon modeIf the command supports daemonization (e.g., hdfs namenode), execute in the appropriate mode. Supported modes are start to start the process in daemon mode, stop to stop the process, and status to determine the active status of the process. status will return an LSB-compliant result code. If no option is provided, commands that support daemonization will run in the foreground. For commands that do not support daemonization, this option is ignored.</span><br><span class="line"></span><br><span class="line">--debugEnables shell level configuration debugging information</span><br><span class="line"></span><br><span class="line">--helpShell script usage information.</span><br><span class="line"></span><br><span class="line">--hostnamesWhen --workers is used, override the workers file with a space delimited list of hostnames where to execute a multi-host subcommand. If --workers is not used, this option is ignored.</span><br><span class="line"></span><br><span class="line">--hostsWhen --workers is used, override the workers file with another file that contains a list of hostnames where to execute a multi-host subcommand. If --workers is not used, this option is ignored.</span><br><span class="line"></span><br><span class="line">--loglevel loglevelOverrides the log level. Valid log levels are FATAL, ERROR, WARN, INFO, DEBUG, and TRACE. Default is INFO.</span><br><span class="line"></span><br><span class="line">--workersIf possible, execute this command on all hosts in the workers file.</span><br></pre></td></tr></table></figure><p><br></p><p><strong>Generic Options</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">-archives &lt;comma separated list of archives&gt;Specify comma separated archives to be unarchived on the compute machines. Applies only to job.</span><br><span class="line">-conf &lt;configuration file&gt;Specify an application configuration file.</span><br><span class="line">-D &lt;property&gt;=&lt;value&gt;Use value for given property.</span><br><span class="line">-files &lt;comma separated list of files&gt;Specify comma separated files to be copied to the map reduce cluster. Applies only to job.</span><br><span class="line">-fs &lt;file:///&gt; or &lt;hdfs://namenode:port&gt;Specify default filesystem URL to use. Overrides ‘fs.defaultFS’ property from configurations.</span><br><span class="line">-jt &lt;local&gt; or &lt;resourcemanager:port&gt;Specify a ResourceManager. Applies only to job.</span><br><span class="line">-libjars &lt;comma seperated list of jars&gt;Specify comma separated jar files to include in the classpath. Applies only to job.</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><p>Hadoop Common Commands</p><p>所有这些命令都是从<code>hadoop</code>命令执行的。它分为:</p><ul><li>用户命令(User Commands): 对hadoop集群的用户有用的命令</li><li>管理命令(Administration Commands): 对hadoop集群的管理员有用的命令</li></ul><p><br></p><h4 id="用户命令"><a href="#用户命令" class="headerlink" title="用户命令"></a>用户命令</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">archive    <span class="comment">#Creates a hadoop archive</span></span><br><span class="line">checknative    <span class="comment">#This command checks the availability of the Hadoop native code</span></span><br><span class="line">classpath    <span class="comment">#Prints the class path needed to get the Hadoop jar and the required libraries</span></span><br><span class="line">conftest    <span class="comment">#Validates configuration XML files</span></span><br><span class="line">credential    <span class="comment">#Command to manage credentials, passwords and secrets within credential providers.</span></span><br><span class="line">distch    <span class="comment">#Change the ownership and permissions on many files at once.</span></span><br><span class="line">distcp    <span class="comment">#Copy file or directories recursively.</span></span><br><span class="line">dtutil    <span class="comment">#Utility to fetch and manage hadoop delegation tokens inside credentials files</span></span><br><span class="line">fs    <span class="comment">#This command is documented in the File System Shell Guide.</span></span><br><span class="line">gridmix    <span class="comment">#Gridmix is a benchmark tool for Hadoop cluster</span></span><br><span class="line">jar    <span class="comment">#Runs a jar file.</span></span><br><span class="line">jnipath    <span class="comment">#Print the computed java.library.path.</span></span><br><span class="line">kerbname    <span class="comment">#Convert the named principal via the auth_to_local rules to the Hadoop user name.</span></span><br><span class="line">kdiag    <span class="comment">#Diagnose Kerberos Problems</span></span><br><span class="line">key    <span class="comment">#Manage keys via the KeyProvider</span></span><br><span class="line">kms    <span class="comment">#Run KMS, the Key Management Server.</span></span><br><span class="line">trace    <span class="comment">#View and modify Hadoop tracing settings</span></span><br><span class="line">version    <span class="comment">#Prints the version.</span></span><br><span class="line">CLASSNAME    <span class="comment">#Runs the class named CLASSNAME. The class must be part of a package.</span></span><br><span class="line">envvars    <span class="comment">#Display computed Hadoop environment variables.</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="管理命令"><a href="#管理命令" class="headerlink" title="管理命令"></a>管理命令</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Usage</span></span><br><span class="line">hadoop daemonlog -getlevel &lt;host:port&gt; &lt;classname&gt; [-protocol (http|https)]</span><br><span class="line">hadoop daemonlog -setlevel &lt;host:port&gt; &lt;classname&gt; &lt;level&gt; [-protocol (http|https)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 栗子</span></span><br><span class="line">bin/hadoop daemonlog -setlevel 127.0.0.1:9870 org.apache.hadoop.hdfs.server.namenode.NameNode DEBUG</span><br><span class="line">bin/hadoop daemonlog -getlevel 127.0.0.1:9871 org.apache.hadoop.hdfs.server.namenode.NameNode DEBUG -protocol https</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 还有以下守护进程</span></span><br><span class="line">Common    <span class="comment">#key management server</span></span><br><span class="line">HDFS    <span class="comment">#name node, secondary name node, data node, journal node, HttpFS server</span></span><br><span class="line">YARN    <span class="comment">#resource manager, node manager, Timeline server</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># hadoop shell commands全局设置</span><br><span class="line">etc/hadoop/hadoop-env.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 此文件允许高级用户覆盖某些shell 功能</span><br><span class="line">etc/hadoop/hadoop-user-functions.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 用户个人环境</span><br><span class="line">~/.hadooprc</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="FS-Shell"><a href="#FS-Shell" class="headerlink" title="FS Shell"></a>FS Shell</h2><p>FileSystem Shell</p><p>FS Shell包括了各种类似于shell的命令，它们直接与Hadoop分布式文件系统(HDFS)以及Hadoop支持的其它文件系统交互(如: Local FS, WebHDMIFS, S3 FS…)</p><p>All FS shell commands take path URIs as arguments.</p><p><br></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用方式</span></span><br><span class="line">bin/hadoop fs &lt;args&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Append single src, or multiple srcs from local file system to the destination file system</span></span><br><span class="line"> hadoop fs -appendToFile &lt;localsrc&gt; ... &lt;dst&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copies source paths to stdout.</span></span><br><span class="line">hadoop fs -cat [-ignoreCrc] URI [URI ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Returns the checksum information of a file</span></span><br><span class="line">hadoop fs -checksum URI</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Change group association of files</span></span><br><span class="line">hadoop fs -chgrp [-R] GROUP URI [URI ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Similar to the fs -put command, except that the source is restricted to a local file reference.</span></span><br><span class="line">hadoop fs -copyFromLocal &lt;localsrc&gt; URI</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Similar to get command, except that the destination is restricted to a local file reference</span></span><br><span class="line">hadoop fs -copyToLocal [-ignorecrc] [-crc] URI &lt;localdst&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Count the number of directories, files and bytes under the paths that match the specified file pattern</span></span><br><span class="line">hadoop fs -count [-q] [-h] [-v] [-x] [-t [&lt;storage <span class="built_in">type</span>&gt;]] [-u] [-e] &lt;paths&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copy files from source to destination</span></span><br><span class="line">hadoop fs -cp [-f] [-p | -p[topax]] URI [URI ...] &lt;dest&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">createSnapshot</span><br><span class="line">deleteSnapshot</span><br><span class="line">renameSnapshot</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Displays free space</span></span><br><span class="line">hadoop fs -df [-h] URI [URI ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Displays sizes of files and directories contained in the given directory or the length of a file in case its just a file.</span></span><br><span class="line">hadoop fs -du [-s] [-h] [-v] [-x] URI [URI ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Displays a summary of file lengths.</span></span><br><span class="line">hadoop fs -dus &lt;args&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Permanently delete files in checkpoints older than the retention threshold from trash directory, and create new checkpoint.</span></span><br><span class="line">hadoop fs -expunge</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Finds all files that match the specified expression and applies selected actions to them</span></span><br><span class="line">hadoop fs -find &lt;path&gt; ... &lt;expression&gt; ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copy files to the local file system</span></span><br><span class="line">hadoop fs -get [-ignorecrc] [-crc] [-p] [-f] &lt;src&gt; &lt;localdst&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copy files to the local file system</span></span><br><span class="line">hadoop fs -get [-ignorecrc] [-crc] [-p] [-f] &lt;src&gt; &lt;localdst&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Displays the Access Control Lists (ACLs) of files and directories</span></span><br><span class="line">hadoop fs -getfacl [-R] &lt;path&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Displays the extended attribute names and values (if any) for a file or directory</span></span><br><span class="line">hadoop fs -getfattr [-R] -n name | -d [-e en] &lt;path&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Takes a source directory and a destination file as input and concatenates files in src into the destination local file</span></span><br><span class="line">hadoop fs -getmerge [-nl] &lt;src&gt; &lt;localdst&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Displays first kilobyte of the file to stdout.</span></span><br><span class="line">hadoop fs -head URI</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Return usage output.</span></span><br><span class="line">hadoop fs -<span class="built_in">help</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hadoop fs -ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] &lt;args&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Recursive version of ls</span></span><br><span class="line">hadoop fs -lsr &lt;args&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Takes path uri’s as argument and creates directories.</span></span><br><span class="line">hadoop fs -mkdir [-p] &lt;paths&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Similar to put command, except that the source localsrc is deleted after it’s copied.</span></span><br><span class="line">hadoop fs -moveFromLocal &lt;localsrc&gt; &lt;dst&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Displays a “Not implemented yet” message.</span></span><br><span class="line">hadoop fs -moveToLocal [-crc] &lt;src&gt; &lt;dst&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Moves files from source to destination. This command allows multiple sources as well in which case the destination needs to be a directory. Moving files across file systems is not permitted.</span></span><br><span class="line">hadoop fs -mv URI [URI ...] &lt;dest&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copy single src, or multiple srcs from local file system to the destination file system. Also reads input from stdin and writes to destination file system if the source is set to “-”</span></span><br><span class="line">hadoop fs -put [-f] [-p] [-l] [-d] [ - | &lt;localsrc1&gt; .. ]. &lt;dst&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Delete files specified as args</span></span><br><span class="line">hadoop fs -rm [-f] [-r |-R] [-skipTrash] [-safely] URI [URI ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Delete a directory</span></span><br><span class="line">hadoop fs -rmdir [--ignore-fail-on-non-empty] URI [URI ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Recursive version of delete</span></span><br><span class="line">hadoop fs -rmr [-skipTrash] URI [URI ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Sets Access Control Lists (ACLs) of files and directories</span></span><br><span class="line">hadoop fs -setfacl [-R] [-b |-k -m |-x &lt;acl_spec&gt; &lt;path&gt;] |[--<span class="built_in">set</span> &lt;acl_spec&gt; &lt;path&gt;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Sets an extended attribute name and value for a file or directory</span></span><br><span class="line">hadoop fs -setfattr -n name [-v value] | -x name &lt;path&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Changes the replication factor of a file. If path is a directory then the command recursively changes the replication factor of all files under the directory tree rooted at path. The EC files will be ignored when executing this command</span></span><br><span class="line">hadoop fs -setrep [-R] [-w] &lt;numReplicas&gt; &lt;path&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print statistics about the file/directory at &lt;path&gt; in the specified format</span></span><br><span class="line">hadoop fs -<span class="built_in">stat</span> [format] &lt;path&gt; ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Displays last kilobyte of the file to stdout</span></span><br><span class="line">hadoop fs -tail [-f] URI</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hadoop fs -<span class="built_in">test</span> -[defsz] URI</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Takes a source file and outputs the file in text format. The allowed formats are zip and TextRecordInputStream.</span></span><br><span class="line">hadoop fs -text &lt;src&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Updates the access and modification times of the file specified by the URI to the current time.</span></span><br><span class="line">hadoop fs -touch [-a] [-m] [-t TIMESTAMP] [-c] URI [URI ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a file of zero length. An error is returned if the file exists with non-zero length</span></span><br><span class="line">hadoop fs -touchz URI [URI ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Truncate all files that match the specified file pattern to the specified length.</span></span><br><span class="line">hadoop fs -truncate [-w] &lt;length&gt; &lt;paths&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Return the help for an individual command</span></span><br><span class="line">hadoop fs -usage <span class="built_in">command</span></span><br></pre></td></tr></table></figure><p><br></p><h3 id="使用对象存储"><a href="#使用对象存储" class="headerlink" title="使用对象存储"></a>使用对象存储</h3><p>Working with Object Storage</p><p>The Hadoop FileSystem shell works with Object Stores such as Amazon S3, Azure WASB and OpenStack Swift.</p><p><br><br><br><br><br></p><h2 id="兼容性规范"><a href="#兼容性规范" class="headerlink" title="兼容性规范"></a>兼容性规范</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/Compatibility.html" target="_blank" rel="noopener">Apache Hadoop Compatibility Specification</a></p><p><br></p><h3 id="目的-1"><a href="#目的-1" class="headerlink" title="目的"></a>目的</h3><p>本节介绍Apache Hadoop项目的兼容性目标。所有Hadoop Interface都根据目标受众和稳定性进行分类，以保持与先前版本的兼容性。</p><p>本文档供Hadoop开发人员社区使用。</p><p><br><br><br><br><br></p><h2 id="开发者兼容指南"><a href="#开发者兼容指南" class="headerlink" title="开发者兼容指南"></a>开发者兼容指南</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/DownstreamDev.html" target="_blank" rel="noopener">Apache Hadoop Downstream Developer’s Guide</a></p><p><br></p><h3 id="目的-2"><a href="#目的-2" class="headerlink" title="目的"></a>目的</h3><p>本文档的目的是为下游开发人员提供明确的参考，以便在针对Hadoop源代码库构建应用程序时提供什么。本文档主要是Hadoop兼容性指南的精华，因此重点介绍了跨版本的各种Hadoop接口的兼容性保证。</p><p><br><br><br><br><br></p><h2 id="管理兼容指南"><a href="#管理兼容指南" class="headerlink" title="管理兼容指南"></a>管理兼容指南</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/AdminCompatibilityGuide.html" target="_blank" rel="noopener">Apache Hadoop Admin Compatibility Guide</a></p><p><br></p><h3 id="目的-3"><a href="#目的-3" class="headerlink" title="目的"></a>目的</h3><p>本文档的目的是将Hadoop兼容性指南提炼为与系统管理员相关的信息。</p><p>目标受众是负责维护Apache Hadoop集群以及必须规划和执行集群升级的管理员。</p><p><br><br><br></p><h3 id="发行版"><a href="#发行版" class="headerlink" title="发行版"></a>发行版</h3><p>Hadoop Releases</p><p>Hadoop开发社区定期发布新的Hadoop Release，以引入新功能并修复现有问题。发新版分为三类:</p><ul><li><strong>Major</strong>: 主要版本通常包含重要的新功能，通常代表最大的升级兼容性风险。(如 2.8.2 to 3.0.0)</li><li><strong>Minor</strong>: 次要版本通常会包含一些新功能以及针对某些值得注意的问题的修复程序。在大多数情况下，次要版本不应造成太大的升级风险。(如2.8.2 to 2.9.0)</li><li><strong>Maintenance</strong>: 维护版本不应包含任何新功能。维护版本的目的是解决开发人员社区认为足够重要的一组问题，以便推动新版本解决这些问题。维护版本的升级风险很小。(如2.8.2 to 2.8.3)</li></ul><p><br><br><br></p><h3 id="平台依赖"><a href="#平台依赖" class="headerlink" title="平台依赖"></a>平台依赖</h3><p>Platform Dependencies</p><p>Hadoop所依赖的本机组件集被视为Hadoop ABI的一部分。Hadoop开发社区致力于尽可能地保持ABI兼容性。在次要版本之间，除非必要，否则不会增加Hadoop本机依赖项的最低支持版本号，例如安全性或许可问题。</p><p>Hadoop依赖于JVM(Java Virtual Machine)。支持的最低版本的JVM在主要版本的Hadoop之间不会发生变化。</p><p><br><br><br></p><h3 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h3><p>Network</p><p>Hadoop依赖于某些传输层技术，如SSL。除非必要，否则不会增加这些依赖项的最低支持版本，例如安全性或许可问题。</p><p>Hadoop服务端口号将在主要版本中保持不变，但可能会在次要版本中更改。</p><p>Hadoop内部线程协议(wire protocol)将在同一主要版本中的次要版本进行向后和向前兼容，以实现滚动升级。</p><p><br><br><br></p><h3 id="脚本和自动化"><a href="#脚本和自动化" class="headerlink" title="脚本和自动化"></a>脚本和自动化</h3><p>Scripting and Automation</p><p><br></p><h4 id="REST-APIs"><a href="#REST-APIs" class="headerlink" title="REST APIs"></a>REST APIs</h4><p>Hadoop REST APTs提供了一种简单的机制，用于收集有关Hadoop系统状态的信息。为了支持REST客户端，Hadoop REST API是版本化的，并且在版本中不会发生不兼容的更改。<br>REST API版本是单个数字，与Hadoop版本号无关。</p><p><br><br><br></p><h4 id="解析Hadoop输出"><a href="#解析Hadoop输出" class="headerlink" title="解析Hadoop输出"></a>解析Hadoop输出</h4><p>Parsing Hadoop Output</p><p>Hadoop可以生成各种输出，可通过自动化工具进行解析。在使用Hadoop输出时，请考虑一下事项:</p><ul><li>除非解决了正确性问题，否则Hadoop日志输出不会随维护版本而更改</li><li>Hadoop为各种操作生成审计日志(audit log)。审计日志旨在是机器可读，但新纪录和字段的添加被认为是兼容的更改</li><li>Hadoop生成的度量数量(metrics data)主要用于自动化处理。</li></ul><p><br><br><br></p><h4 id="CLIs"><a href="#CLIs" class="headerlink" title="CLIs"></a>CLIs</h4><p>Hadoop的命令行集提供了管理系统各个方面以及发现系统状态信息的能力。请注意，CLI工具输出与CLI工具生成的日志输出不同。日志输出不适合自动消费，可能随时更改。</p><p><br><br><br></p><h4 id="Web-UI"><a href="#Web-UI" class="headerlink" title="Web UI"></a>Web UI</h4><p>Hadoop公开的Web UI供人类使用。</p><p><br><br><br></p><h3 id="状态数据"><a href="#状态数据" class="headerlink" title="状态数据"></a>状态数据</h3><p>Hadoop State Data</p><p>Hadoop内部系统状态是私有的，不应直接被修改。以下策略管理各种内部状态存储的升级特征:</p><ul><li>内部MapReduce状态数据在同一主要版本中的次要版本之间保持兼容，以便在MapReduce工作负载执行时促进滚动升级</li><li>HDFS以版本化的私有内部格式维护存储在HDFS中的数据的元数据。</li><li>AWS S3防护保留了版本化的私有内部元数据存储。不兼容的更改将导致版本号递增。</li><li>YARN 资源管理器保留版本化的应用程序和调度程序信息的内部状态存储。</li><li>YARN联合身份验证服务保留应用程序的私有内部状态存储以及版本化的群集信息。</li></ul><p><br><br><br></p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>Hadoop Configurations</p><p>Hadoop使用两种主要形式的配置文件: XML配置文件和日志记录配置文件。</p><p><br></p><p><strong>XML配置文件</strong></p><p>XML配置文件包含了一组属性作为键值对。属性的名称和含义由Hadoop定义，并保证在次要版本中稳定。属性只能在主要版本中删除，并且只有在至少完整主要版本被标记为已弃用时才能删除。大多数属性都有一个默认值，如果未在XML配置文件中显式设置该属性，则将使用该值。</p><p>下游项目和用户可以将自己的属性添加到XML配置文件中，以供其工具和应用程序使用。虽然Hadoop对定义新属性没有任何正式限制，但与Hadoop定义的属性冲突的新属性可能会导致意外和不良结果。建议用户避免使用与Hadoop定义的属性的名称空间冲突的自定义配置属性名称。</p><p><br></p><p><strong>日志记录配置文件</strong></p><p>Hadoop Daemon和CLI生成的日志输出由一组配置文件控制。这些文件控制将由Hadoop的各个组件输出的最小日志消息级别，以及这些消息的存储位置和方式。</p><p><br></p><p><strong>其它配置文件</strong></p><p>Hadoop使用各种格式的许多其它类型的配置文件，如JSON或XML。</p><p><br><br><br></p><h3 id="发行版-1"><a href="#发行版-1" class="headerlink" title="发行版"></a>发行版</h3><p>Hadoop Distribution</p><p><br></p><p><strong>配置文件</strong></p><p>Hadoop配置文件的位置和一般结构，作业历史信息和Hadoop生成的日志文件将在维护版中得到维护。</p><p><br></p><p><strong>JARs</strong></p><p>Hadoop发行版的内容，如JAR文件可能随时更改，Client artifact除外，不应视为可靠。当前客户端工具有:</p><ul><li>hadoop-client</li><li>hadoop-client-api</li><li>hadoop-client-minicluster</li><li>hadoop-client-runtime</li><li>hadoop-hdfs-client</li><li>hadoop-hdfs-native-client</li><li>hadoop-mapreduce-client-app</li><li>hadoop-mapreduce-client-common</li><li>hadoop-mapreduce-client-core</li><li>hadoop-mapreduce-client-jobclient</li><li>hadoop-mapreduce-client-nativetask</li><li>hadoop-yarn-client</li></ul><p><br></p><p><strong>ENV</strong></p><p>一些Hadoop组件通过环境变量接收信息。</p><p><br></p><p><strong>库依赖</strong></p><p>Hadoop依赖于大量第三方库来运行。</p><p><br></p><p><strong>硬件和系统依赖</strong></p><p>Hadoop目前由运行在x86和AMD处理器上的Linux和Windows上的Hadoop开发人员社区提供支持。<br>无法保证Hadoop守护程序所需的最低资源如何在发行版之间发生变化，甚至是维护版本。<br>任何支持Hadoop的文件系统，例如通过FileSystem API，在大多数情况下将继续在主要版本中得到支持。</p><p><br><br><br><br><br></p><h2 id="接口分类"><a href="#接口分类" class="headerlink" title="接口分类"></a>接口分类</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/InterfaceClassification.html" target="_blank" rel="noopener">Interface Classification</a></p><p><br><br><br><br><br></p><h2 id="文件系统规范"><a href="#文件系统规范" class="headerlink" title="文件系统规范"></a>文件系统规范</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/filesystem/index.html" target="_blank" rel="noopener">The Hadoop FileSystem API Definition</a></p><p>这是Hadoop FS API的规范，它将文件系统的内容建模为一组路径(目录、文件、符号链接)。<br>Unix文件系统有多种规范作为inode树，但没有任何公开定义 <em>Unix文件系统作为数据存储访问的概念模型</em> 的概念。</p><p>该规范视图这样做，定义Hadoop FS模型和API，以便多个文件系统可实现API并向应用程序提供其数据的一致模型。除了记录HDFS所展示的行为之外，它不会尝试正式指定文件系统的任何并发行为，因为这些行为是Hadoop客户端应用程序通常所期望的。</p><p><br></p><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p><br><br><br></p><h3 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h3><p>Notation</p><p><br><br><br></p><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>Model</p><p><br><br><br></p><h3 id="文件系统类"><a href="#文件系统类" class="headerlink" title="文件系统类"></a>文件系统类</h3><p>FileSystem class</p><p><br><br><br></p><h3 id="FSDataInputStream-class"><a href="#FSDataInputStream-class" class="headerlink" title="FSDataInputStream class"></a>FSDataInputStream class</h3><p><br><br><br></p><h3 id="FSDataOutputStreamBuilder-class"><a href="#FSDataOutputStreamBuilder-class" class="headerlink" title="FSDataOutputStreamBuilder class"></a>FSDataOutputStreamBuilder class</h3><p><br><br><br></p><h3 id="使用文件系统规范进行测试"><a href="#使用文件系统规范进行测试" class="headerlink" title="使用文件系统规范进行测试"></a>使用文件系统规范进行测试</h3><p>Testing with the Filesystem specification</p><p><br><br><br></p><h3 id="扩展规范及测试"><a href="#扩展规范及测试" class="headerlink" title="扩展规范及测试"></a>扩展规范及测试</h3><p>Extending the specification and its tests</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="Common"><a href="#Common" class="headerlink" title="Common"></a>Common</h1><p><br></p><h2 id="CLI-MiniCluster"><a href="#CLI-MiniCluster" class="headerlink" title="CLI MiniCluster"></a>CLI MiniCluster</h2><p><br></p><h3 id="目的-4"><a href="#目的-4" class="headerlink" title="目的"></a>目的</h3><p>使用 CLI MiniCluster，用户只需使用一个命令即可启动和停止单节点Hadoop集群，而无需设置任何环境变量或管理配置文件。CLI MiniCluster启用 YARN、MapReduce和HDFS集群。</p><p>这对于希望快速试验Hadoop集群或测试依赖于Hadoop工具的程序的用户来说非常有用。</p><p><br><br><br></p><h3 id="Hadoop-Tarball"><a href="#Hadoop-Tarball" class="headerlink" title="Hadoop Tarball"></a>Hadoop Tarball</h3><p>你要从发行版中获取Hadoop Tarball。此外，你也可以从源直接创建Tarball:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 请首先下载源码包并解压</span></span><br><span class="line"><span class="comment"># tarball在hadoop-dist/target/目录</span></span><br><span class="line"><span class="comment"># cd hadoop-3.2.0-src</span></span><br><span class="line">mvn clean install -DskipTests</span><br><span class="line">mvn package -Pdist -Dtar -DskipTests -Dmaven.javadoc.skip</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="运行MiniCluster"><a href="#运行MiniCluster" class="headerlink" title="运行MiniCluster"></a>运行MiniCluster</h3><p>从提取的Tarball目录内部，你可使用以下命令启动CLI MiniCluster:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># RM_PORT, JHS_PORT应替换为用户对这些端口号的选择，如果未指定，将使用随机空闲端口</span></span><br><span class="line">bin/mapred minicluster -rmport RM_PORT -jhsport JHS_PORT</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 命令行参数</span></span><br><span class="line">$ -D &lt;property=value&gt;    Options to pass into configuration object</span><br><span class="line">$ -datanodes &lt;arg&gt;       How many datanodes to start (default 1)</span><br><span class="line">$ -format                Format the DFS (default <span class="literal">false</span>)</span><br><span class="line">$ -<span class="built_in">help</span>                  Prints option <span class="built_in">help</span>.</span><br><span class="line">$ -jhsport &lt;arg&gt;         JobHistoryServer port (default 0--we choose)</span><br><span class="line">$ -namenode &lt;arg&gt;        URL of the namenode (default is either the DFS</span><br><span class="line">$                        cluster or a temporary dir)</span><br><span class="line">$ -nnport &lt;arg&gt;          NameNode port (default 0--we choose)</span><br><span class="line">$ -nnhttpport &lt;arg&gt;      NameNode HTTP port (default 0--we choose)</span><br><span class="line">$ -nodemanagers &lt;arg&gt;    How many nodemanagers to start (default 1)</span><br><span class="line">$ -nodfs                 Don<span class="string">'t start a mini DFS cluster</span></span><br><span class="line"><span class="string">$ -nomr                  Don'</span>t start a mini MR cluster</span><br><span class="line">$ -rmport &lt;arg&gt;          ResourceManager port (default 0--we choose)</span><br><span class="line">$ -writeConfig &lt;path&gt;    Save configuration to this XML file.</span><br><span class="line">$ -writeDetails &lt;path&gt;   Write basic information to this JSON file.</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="原生库"><a href="#原生库" class="headerlink" title="原生库"></a>原生库</h2><p>Native Libraries Guide</p><p>本节介绍原生(native)Hadoop库，并包含了有关共享库的讨论。</p><p>出于性能原因和Java实现的不可用性，Hadoop具有某些组件的原生实现。这些组件在单个动态链接的本机库可用，称为本机(原生)Hadoop库(<code>libhadoop.so</code>)。</p><p><br></p><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>使用原生Hadoop库相当容易:</p><ul><li>审阅组件</li><li>审阅支持的平台</li><li>下载Hadoop发行版(库名: <code>libhadoop.so</code>)</li><li>安装解码器开发包(<code>&gt;zlib-1.2</code>, <code>&gt;gzip-1.2</code>)</li><li>检查运行日志</li></ul><p><br><br><br></p><h3 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h3><p>原生Hadoop库包括各种组件:</p><ul><li>Compression Codecs (<code>bzip2</code>, <code>lz4</code>, <code>snappy</code>, <code>zlib</code>)</li><li>Native IO utilities for HDFS Short-Circuit Local Reads and Centralized Cache Management in HDFS</li><li>CRC32 checksum implementation</li></ul><p><br><br><br></p><h3 id="支持的平台"><a href="#支持的平台" class="headerlink" title="支持的平台"></a>支持的平台</h3><p>原生Hadoop库主要用于GNU/Linux平台，并在这些发行版上进行测试:</p><ul><li>RHEL4/Fedora</li><li>Ubuntu</li><li>Gentoo</li></ul><p><br><br><br></p><h3 id="构建"><a href="#构建" class="headerlink" title="构建"></a>构建</h3><p>原生Hadoop库使用 ANSI C编写，使用GNU autotools-chain 构建。<br>你需要在目标平台上安装的软件包:</p><ul><li>C compiler (e.g. GNU C Compiler)</li><li>GNU Autools Chain: autoconf, automake, libtool</li><li>zlib-development package (stable version &gt;= 1.2.0)</li><li>openssl-development package(e.g. libssl-dev)</li></ul><p>安装必备软件包后，使用标准的Hadoop <code>Pox.xml</code> 文件来构建原生Hadoop库:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mvn package -Pdist,native -DskipTests -Dtar</span><br><span class="line"></span><br><span class="line"><span class="comment"># You should see the newly-built library in</span></span><br><span class="line">hadoop-dist/target/hadoop-3.2.0/lib/native</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="Runtime"><a href="#Runtime" class="headerlink" title="Runtime"></a>Runtime</h3><p><code>bin/hadoop</code> 脚本通过系统属性(<code>-Djava.library.path=&lt;path&gt;</code>)确保原生Hadoop库位于库路径上。</p><p>在运行时，检查hadoop日志文件以查找MapReduce任务。</p><p><br><br><br></p><h3 id="检查"><a href="#检查" class="headerlink" title="检查"></a>检查</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 原生库检查其检查是否正确加载</span><br><span class="line">hadoop checknative -a</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="Proxy-User"><a href="#Proxy-User" class="headerlink" title="Proxy User"></a>Proxy User</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/Superusers.html" target="_blank" rel="noopener">Proxy user - Superusers Acting On Behalf Of Other Users</a></p><p>本节介绍超级用户(super user)如何代表另一个用户提交作业(submit job)或访问HDFS。</p><p><br></p><h3 id="用例"><a href="#用例" class="headerlink" title="用例"></a>用例</h3><p>用户名为<code>super</code>的超级用户希望代表用户<code>userA</code>提交作业并访问HDFS。某人任务需要以<code>userA</code>身份运行，并且namenode上的任何文件都需要以<code>userA</code>的身份完成。这要求用户<code>userA</code>可连接到使用<code>super</code>用户的kerberos凭据连接到namenode。换句话说，<code>super</code>模仿用户<code>userA</code>。</p><p><br><br><br></p><h3 id="代码栗子"><a href="#代码栗子" class="headerlink" title="代码栗子"></a>代码栗子</h3><p><code>super</code>超级用户的凭据用于登录，并为<code>joe</code>创建代理用户对象。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">//Create ugi for joe. The login user is &apos;super&apos;.</span><br><span class="line">UserGroupInformation ugi =</span><br><span class="line">        UserGroupInformation.createProxyUser(&quot;joe&quot;, UserGroupInformation.getLoginUser());</span><br><span class="line">ugi.doAs(new PrivilegedExceptionAction&lt;Void&gt;() &#123;</span><br><span class="line">  public Void run() throws Exception &#123;</span><br><span class="line">    //Submit a job</span><br><span class="line">    JobClient jc = new JobClient(conf);</span><br><span class="line">    jc.submitJob(conf);</span><br><span class="line">    //OR access hdfs</span><br><span class="line">    FileSystem fs = FileSystem.get(conf);</span><br><span class="line">    fs.mkdir(someFilePath);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h3><p>你可以使用<code>hadoop.proxyuser</code>属性(properties)来配置代理用户。<code>$superuser.hosts</code>以及<code>hadoop.proxyuser.$superuser.groups</code>, <code>hadoop.proxyuser.$superuser.users</code>其中的一个或两个。</p><p>在<code>core-site.xml</code>中，名为<code>super</code>的超级用户只能充<code>host1, host2</code>上进行连接，用于模拟<code>group1</code>, <code>group2</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.proxyuser.super.hosts&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;host1,host2&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.proxyuser.super.groups&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;group1,group2&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><br></p><p>如果需要更为宽松的安全性，则可以使用通配符:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.proxyuser.oozie.hosts&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.proxyuser.oozie.groups&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><br></p><p>当然，它也接受CIDR格式的ip地址范围或主机名:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.proxyuser.super.hosts&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;10.222.0.0/16,10.113.221.221&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.proxyuser.super.users&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;user1,user2&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="警告"><a href="#警告" class="headerlink" title="警告"></a>警告</h3><p>如果集群运行在安全模式(secure mode)下，则超级用户必须具有<code>kerberos</code>凭据才能模拟其他用户。</p><p><br><br><br><br><br></p><h2 id="Rack-Awareness-1"><a href="#Rack-Awareness-1" class="headerlink" title="Rack Awareness"></a>Rack Awareness</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/RackAwareness.html" target="_blank" rel="noopener">Rack Awareness</a></p><p>Hadoop组件具有机架感知功能(rack-aware)。例如，通过将一个块副本(block replica)放在不同的机架上，HDFS块放置将使用机架感知来实现容错(fault tolerance)。可以在网络故障或分区时提供数据可用性。</p><p>Hadoop主守护进程(master daemon)通过调用配置文件指定的<code>external scripts</code>或<code>java class</code>来获取集群工作者的<strong>rack id</strong>。输出必须遵守 java org.apache.hadoop.net.DNSToSwitchMapping interface，接口需要保持一对一的对应关系。</p><p>要使用 java class 进行拓扑映射，类名由配置文件中的 <code>net.topology.node.switch.mapping.impl</code> 参数指定。<br>如果想实现外部脚本，将使用配置文件中的 <code>net.topology.script.file.name</code> 参数指定它。<br>如果 <code>net.topology.script.file.name</code> 或 <code>net.topology.node.switch.mapping.impl</code> 没有设置，则会为任何IP返回机器ID。</p><p><br></p><h3 id="python栗子"><a href="#python栗子" class="headerlink" title="python栗子"></a>python栗子</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># this script makes assumptions about the physical environment.</span></span><br><span class="line"><span class="comment">#  1) each rack is its own layer 3 network with a /24 subnet, which</span></span><br><span class="line"><span class="comment"># could be typical where each rack has its own</span></span><br><span class="line"><span class="comment">#     switch with uplinks to a central core router.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#             +-----------+</span></span><br><span class="line"><span class="comment">#             |core router|</span></span><br><span class="line"><span class="comment">#             +-----------+</span></span><br><span class="line"><span class="comment">#            /             \</span></span><br><span class="line"><span class="comment">#   +-----------+        +-----------+</span></span><br><span class="line"><span class="comment">#   |rack switch|        |rack switch|</span></span><br><span class="line"><span class="comment">#   +-----------+        +-----------+</span></span><br><span class="line"><span class="comment">#   | data node |        | data node |</span></span><br><span class="line"><span class="comment">#   +-----------+        +-----------+</span></span><br><span class="line"><span class="comment">#   | data node |        | data node |</span></span><br><span class="line"><span class="comment">#   +-----------+        +-----------+</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># 2) topology script gets list of IP's as input, calculates network address, and prints '/network_address/ip'.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> netaddr</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.argv.pop(<span class="number">0</span>)                                                  <span class="comment"># discard name of topology script from argv list as we just want IP addresses</span></span><br><span class="line"></span><br><span class="line">netmask = <span class="string">'255.255.255.0'</span>                                        <span class="comment"># set netmask to what's being used in your environment.  The example uses a /24</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ip <span class="keyword">in</span> sys.argv:                                              <span class="comment"># loop over list of datanode IP's</span></span><br><span class="line">    address = <span class="string">'&#123;0&#125;/&#123;1&#125;'</span>.format(ip, netmask)                      <span class="comment"># format address string so it looks like 'ip/netmask' to make netaddr work</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        network_address = netaddr.IPNetwork(address).network     <span class="comment"># calculate and print network address</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">"/&#123;0&#125;"</span>.format(network_address)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"/rack-unknown"</span>                                    <span class="comment"># print catch-all value if unable to calculate network address</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="bash栗子"><a href="#bash栗子" class="headerlink" title="bash栗子"></a>bash栗子</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"><span class="comment"># Here's a bash example to show just how simple these scripts can be</span></span><br><span class="line"><span class="comment"># Assuming we have flat network with everything on a single switch, we can fake a rack topology.</span></span><br><span class="line"><span class="comment"># This could occur in a lab environment where we have limited nodes,like 2-8 physical machines on a unmanaged switch.</span></span><br><span class="line"><span class="comment"># This may also apply to multiple virtual machines running on the same physical hardware.</span></span><br><span class="line"><span class="comment"># The number of machines isn't important, but that we are trying to fake a network topology when there isn't one.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#       +----------+    +--------+</span></span><br><span class="line"><span class="comment">#       |jobtracker|    |datanode|</span></span><br><span class="line"><span class="comment">#       +----------+    +--------+</span></span><br><span class="line"><span class="comment">#              \        /</span></span><br><span class="line"><span class="comment">#  +--------+  +--------+  +--------+</span></span><br><span class="line"><span class="comment">#  |datanode|--| switch |--|datanode|</span></span><br><span class="line"><span class="comment">#  +--------+  +--------+  +--------+</span></span><br><span class="line"><span class="comment">#              /        \</span></span><br><span class="line"><span class="comment">#       +--------+    +--------+</span></span><br><span class="line"><span class="comment">#       |datanode|    |namenode|</span></span><br><span class="line"><span class="comment">#       +--------+    +--------+</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># With this network topology, we are treating each host as a rack.  This is being done by taking the last octet</span></span><br><span class="line"><span class="comment"># in the datanode's IP and prepending it with the word '/rack-'.  The advantage for doing this is so HDFS</span></span><br><span class="line"><span class="comment"># can create its 'off-rack' block copy.</span></span><br><span class="line"><span class="comment"># 1) 'echo $@' will echo all ARGV values to xargs.</span></span><br><span class="line"><span class="comment"># 2) 'xargs' will enforce that we print a single argv value per line</span></span><br><span class="line"><span class="comment"># 3) 'awk' will split fields on dots and append the last field to the string '/rack-'. If awk</span></span><br><span class="line"><span class="comment">#    fails to split on four dots, it will still print '/rack-' last field value</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$@</span> | xargs -n 1 | awk -F <span class="string">'.'</span> <span class="string">'&#123;print "/rack-"$NF&#125;'</span></span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="安全模式"><a href="#安全模式" class="headerlink" title="安全模式"></a>安全模式</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/SecureMode.html" target="_blank" rel="noopener">Hadoop in Secure Mode</a></p><p>本节介绍如何在 <strong>安全模式(secure mode)</strong> 下为Hadoop配置身份认证。当Hadoop配置为以安全模式运行时，Hadoop的每个服务和每个用户都必须由Kerberos进行身份认证。<br>必须正确配置所有服务主机的正向(forward)和反向(reverse)查找，以允许服务互相进行身份验证。可使用DNS或<code>/etc/hosts</code>文件配置主机查找(lookup)。在尝试以安全模式配置Hadoop服务之前，建议先了解Kerberos和DNS的工作知识。</p><p><br><br><br></p><h3 id="认证"><a href="#认证" class="headerlink" title="认证"></a>认证</h3><p>Authentication</p><p><br></p><h4 id="End-User-Accounts"><a href="#End-User-Accounts" class="headerlink" title="End User Accounts"></a>End User Accounts</h4><p>启用服务级别身份验证之后，最终用户必须在与Hadoop服务交互之前进行身份认证。最简单的方式是用户使用<code>kerberos kinit cmd</code>以交互方式进行身份认证，或者使用<code>Kerberos keytab</code>文件的编程身份进行认证。</p><p><br><br><br></p><h4 id="用户账户"><a href="#用户账户" class="headerlink" title="用户账户"></a>用户账户</h4><p>User Accounts for Hadoop Daemons</p><p>确保HDFS和YARN 守护进程以不同的Unix用户运行(如hdfs, yarn)。此外，确保 MapDrduce JobHistory Server以不同的用户运行(如mapred)。<br>建议让他们共享同一个Unix Group。</p><table><thead><tr><th>User:Group</th><th>Daemons</th></tr></thead><tbody><tr><td>hdfs:hadoop</td><td>NameNode, Secondary NameNode, JournalNode, DataNode</td></tr><tr><td>yarn:hadoop</td><td>ResourceManager, NodeManager</td></tr><tr><td>mapred:hadoop</td><td>MapReduce JobHistory Server</td></tr></tbody></table><p><br><br><br></p><h4 id="Kerberos"><a href="#Kerberos" class="headerlink" title="Kerberos"></a>Kerberos</h4><p>Kerberos principals for Hadoop Daemons</p><p>必须使用其<strong>Kerberos pricipal</strong>和<strong>keytab file</strong>配置每个Hadoop Service 实例。服务准则的一般格式是: <code>ServiceName/_HOST@REALM.TLD. e.g. dn/_HOST@EXAMPLE.COM</code>。</p><p>Hadoop通过允许将服务主体的主机名组件指定为<code>_HOST</code>通配符来简化配置文件的部署。每个服务实例将在运行时使用自己的完全限定主机名替换<code>_HOST</code>。这允许管理员在所有节点上部署同一组配置文件，但 keytab 文件有所不同。</p><p><br></p><p><strong>HDFS</strong></p><p>每个NameNode主机上的<strong>keytab</strong>文件，如下所示:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -e shows the encryption type</span></span><br><span class="line"><span class="comment"># -t shows keytab entry timestamps</span></span><br><span class="line"><span class="comment"># -k specifies keytab</span></span><br><span class="line">klist -e -k -t /etc/security/keytab/nn.service.keytab</span><br><span class="line">Keytab name: FILE:/etc/security/keytab/nn.service.keytab</span><br><span class="line">KVNO Timestamp         Principal</span><br><span class="line">   4 07/18/11 21:08:09 nn/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 nn/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 nn/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br></pre></td></tr></table></figure><p>第二个NameNode主机的<strong>keytab</strong>文件，如下所示:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">klist -e -k -t /etc/security/keytab/sn.service.keytab</span><br><span class="line">Keytab name: FILE:/etc/security/keytab/sn.service.keytab</span><br><span class="line">KVNO Timestamp         Principal</span><br><span class="line">   4 07/18/11 21:08:09 sn/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 sn/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 sn/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br></pre></td></tr></table></figure><p>每台主机上的DataNode的<strong>keytab</strong>文件，如下所示:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">klist -e -k -t /etc/security/keytab/dn.service.keytab</span><br><span class="line">Keytab name: FILE:/etc/security/keytab/dn.service.keytab</span><br><span class="line">KVNO Timestamp         Principal</span><br><span class="line">   4 07/18/11 21:08:09 dn/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 dn/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 dn/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br></pre></td></tr></table></figure><p><br></p><p><strong>YARN</strong></p><p>位于ResourceManager主机上的ResourceManager的<strong>keytab</strong>文件，如下所示:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">klist -e -k -t /etc/security/keytab/rm.service.keytab</span><br><span class="line">Keytab name: FILE:/etc/security/keytab/rm.service.keytab</span><br><span class="line">KVNO Timestamp         Principal</span><br><span class="line">   4 07/18/11 21:08:09 rm/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 rm/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 rm/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br></pre></td></tr></table></figure><p>每台主机上的NodeManager的<strong>keytab</strong>文件，如下所示:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">klist -e -k -t /etc/security/keytab/nm.service.keytab</span><br><span class="line">Keytab name: FILE:/etc/security/keytab/nm.service.keytab</span><br><span class="line">KVNO Timestamp         Principal</span><br><span class="line">   4 07/18/11 21:08:09 nm/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 nm/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 nm/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br></pre></td></tr></table></figure><p><br></p><p><strong>MapReduce JobHistory Server</strong></p><p>该主机上的MapReduce JobHistory Server的<strong>keytab</strong>文件，如下所示:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">klist -e -k -t /etc/security/keytab/jhs.service.keytab</span><br><span class="line">Keytab name: FILE:/etc/security/keytab/jhs.service.keytab</span><br><span class="line">KVNO Timestamp         Principal</span><br><span class="line">   4 07/18/11 21:08:09 jhs/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 jhs/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 jhs/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="从kerberos映射到系统用户账户"><a href="#从kerberos映射到系统用户账户" class="headerlink" title="从kerberos映射到系统用户账户"></a>从kerberos映射到系统用户账户</h4><p>Mapping from Kerberos principals to OS user accounts</p><p>Hadoop使用<code>hadoop.security.auth_to_local</code>指定的规则将kerberos principal映射到系统账户。Hadoop如何评估这些规则取决于<code>hadoop.security.auth_to_local.mechanism</code>的设置。</p><p>在默认的hadoop模式下，必须将Kerberos主体与将主体转换为简单形式的规则匹配，即不带<code>@, /</code>的用户帐户名，否则将不会授权主体并记录错误。<br>另外，请注意，您不应该将 <code>auth_to_local</code> 规则作为ACL并使用适当的(OS)机制。</p><p><code>auth_to_local</code>可能的值:</p><ul><li><code>RULE:exp</code>, 本地名称将由exp指定</li><li><code>DEFAULT</code>, 当且仅当域与 <code>default_realm</code> 匹配时，才将主体名称的第一个组件选为系统用户名</li></ul><p>请注意，Hadoop不支持多个默认域。此外，Hadoop不会对映射是否存在本地系统帐户进行验证。</p><p><br><br><br></p><h4 id="规则栗子"><a href="#规则栗子" class="headerlink" title="规则栗子"></a>规则栗子</h4><p>Example rules</p><p>在典型的集群中，HDFS和YARN服务将分别作为系统hdfs和yarn用户启动。<code>hadoop.security.auth_to_local</code>可做如下配置:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;</span><br><span class="line">    RULE:[2:$1/$2@$0]([ndj]n/.*@REALM.\TLD)s/.*/hdfs/</span><br><span class="line">    RULE:[2:$1/$2@$0]([rn]m/.*@REALM\.TLD)s/.*/yarn/</span><br><span class="line">    RULE:[2:$1/$2@$0](jhs/.*@REALM\.TLD)s/.*/mapred/</span><br><span class="line">    DEFAULT</span><br><span class="line">  &lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>可以使用 <code>hadoop kerbname</code> 命令测试自定义规则。此命令允许指定主体并应用Hadoop的当前 <code>auth_to_local</code> 规则集。</p><p><br><br><br></p><h4 id="用户到组的映射"><a href="#用户到组的映射" class="headerlink" title="用户到组的映射"></a>用户到组的映射</h4><p>Mapping from user to group</p><p>可以通过 <code>hadoop.security.group.mapping</code> 配置系统用户到系统组的映射机制。<br>实际上，您需要使用Kerberos和LDAP for Hadoop以安全模式管理SSO环境。</p><p><br><br><br></p><h4 id="代理用户"><a href="#代理用户" class="headerlink" title="代理用户"></a>代理用户</h4><p>Proxy user</p><p>Some products such as Apache Oozie which access the services of Hadoop on behalf of end users need to be able to impersonate end users.</p><p><br><br><br></p><h4 id="Secure-DataNode"><a href="#Secure-DataNode" class="headerlink" title="Secure DataNode"></a>Secure DataNode</h4><p>由于DataNode数据传输协议不使用Hadoop RPC框架，因此DataNode必须使用由<code>dfs.datanode.address</code>和<code>dfs.datanode.http.address</code>指定的特权端口对自身进行身份验证。此认证基于以下假设: 攻击者无法在DataNode主机上获得root权限。</p><p>当以root身份执行<code>hdfs datanode</code>命令时，服务进程首先绑定特定端口，然后删除特权并以<code>HDFS_DATANODE_SECURE_USER</code>指定的用户账户运行。此启动过程安装到<code>JSVC_HOME</code>的jsvc程序。你必须在启动时将<code>JDFS_DATANODE_SECURE_USER</code>和<code>JSVC_HOME</code>指定为环境变量。(<code>hadoop-env.sh</code>文件中可配置)</p><p><br><br><br><br><br></p><h3 id="数据机密性"><a href="#数据机密性" class="headerlink" title="数据机密性"></a>数据机密性</h3><p><br></p><h4 id="Data-Encryption-on-RPC"><a href="#Data-Encryption-on-RPC" class="headerlink" title="Data Encryption on RPC"></a>Data Encryption on RPC</h4><p>在Hadoop Service 和 Client之间传输的数据可以在线路上加密。在 <code>core-site.xml</code> 中将 <code>hadoop.rpc.protection</code> 设置为 <code>privacy</code> 可激活数据加密。</p><p><br><br><br></p><h4 id="Data-Encryption-on-Block-data-transfer"><a href="#Data-Encryption-on-Block-data-transfer" class="headerlink" title="Data Encryption on Block data transfer"></a>Data Encryption on Block data transfer</h4><p>需要在 <code>hdfs-site.xml</code> 中将 <code>dfs.encrypt.data.transfer</code> 设置为 <code>true</code>，以便为DataNode 的数据传输协议激活数据加密。</p><p>或者，你可将 <code>dfs.encrypt.data.transfer.algorithm</code> 设置为 <code>3des</code>, <code>rc4</code> 以选择特定的加密算法。如果未指定，则使用系统上配置的JCE默认值(3des)。<br>将 <code>dfs.encrypt.data.transfer.cipher.suites</code> 设置为 <code>AES/CTR/NoPadding</code> 可激活AES加密。默认未指定，也就是不使用AES。使用AES时，在初始密钥交换期间仍会使用 <code>dfs.encrypt.dta.transfer.algorithm</code>的算法。可通过将 <code>dfs.encrypt.data.transfer.cipher.key.bitlength</code> 设置为128, 192, 256来配置AES密钥位长度(默认128)</p><p>AES提供最大的加密强度和最佳性能。目前，3DES和RC4在Hadoop集群中的使用频率更高。</p><p><br><br><br></p><h4 id="Data-Encryption-on-HTTP"><a href="#Data-Encryption-on-HTTP" class="headerlink" title="Data Encryption on HTTP"></a>Data Encryption on HTTP</h4><p>web-console和client之间的数据传输使用SSL(HTTPS)保护。在使用Kerberos配置Hadoop安全时，推荐使用SLL，但不是必须。</p><p>要为HDFS Daemon的 web-console 启用SSL，将<code>hdfs-site.xml</code>文件中的<code>dfs.http.policy</code>设置为<code>HTTPS_ONLY</code>或<code>HTTP_AND_HTTPS</code>两者之一。<br>要为YARN Daemon的 web-console 启用SSL，将<code>yarn-site.xml</code>文件中的<code>yarn.http.policy</code>设置为<code>HTTPS_ONLY</code>。<br>要为MapReduce JobHistory Server的 web-console 启用SSL，将<code>mapred-site.xml</code>文件中的<code>mapreduce.jobhistory.http.policy</code>设置为<code>HTTPS_ONLY</code>。</p><p><br><br><br></p><h3 id="配置-2"><a href="#配置-2" class="headerlink" title="配置"></a>配置</h3><p><br></p><h4 id="HDFS和本地文件系统路径的权限"><a href="#HDFS和本地文件系统路径的权限" class="headerlink" title="HDFS和本地文件系统路径的权限"></a>HDFS和本地文件系统路径的权限</h4><p>Permissions for both HDFS and local fileSystem paths</p><p>下表列出了HDFS和本地文件系统的各种路径，建议权限为:</p><table><thead><tr><th>Filesystem</th><th>Path</th><th>User:Group</th><th>Permissions</th></tr></thead><tbody><tr><td>local</td><td><code>dfs.namenode.name.dir</code></td><td>hdfs:hadoop</td><td>drwx——</td></tr><tr><td>local</td><td><code>dfs.datanode.data.dir</code></td><td>hdfs:hadoop</td><td>drwx——</td></tr><tr><td>local</td><td><code>$HADOOP_LOG_DIR</code></td><td>hdfs:hadoop</td><td>drwxrwxr-x</td></tr><tr><td>local</td><td><code>$YARN_LOG_DIR</code></td><td>yarn:hadoop</td><td>drwxrwxr-x</td></tr><tr><td>local</td><td><code>yarn.nodemanager.local-dirs</code></td><td>yarn:hadoop</td><td>drwxr-xr-x</td></tr><tr><td>local</td><td><code>yarn.nodemanager.log-dirs</code></td><td>yarn:hadoop</td><td>drwxr-xr-x</td></tr><tr><td>local</td><td><code>container-executor</code></td><td>root:hadoop</td><td>–Sr-s–*</td></tr><tr><td>local</td><td><code>conf/container-executor.cfg</code></td><td>root:hadoop</td><td>r——-*</td></tr><tr><td>hdfs</td><td><code>/</code></td><td>hdfs:hadoop</td><td>drwxr-xr-x</td></tr><tr><td>hdfs</td><td><code>/tmp</code></td><td>hdfs:hadoop</td><td>drwxrwxrwxt</td></tr><tr><td>hdfs</td><td><code>/user</code></td><td>hdfs:hadoop</td><td>drwxr-xr-x</td></tr><tr><td>hdfs</td><td><code>yarn.nodemanager.remote-app-log-dir</code></td><td>yarn:hadoop</td><td>drwxrwxrwxt</td></tr><tr><td>hdfs</td><td><code>mapreduce.jobhistory.intermediate-done-dir</code></td><td>mapred:hadoop</td><td>drwxrwxrwxt</td></tr><tr><td>hdfs</td><td><code>mapreduce.jobhistory.done-dir</code></td><td>mapred:hadoop</td><td>drwxr-x—</td></tr></tbody></table><p><br><br><br></p><h4 id="常见配置"><a href="#常见配置" class="headerlink" title="常见配置"></a>常见配置</h4><p>要在Hadoop中启用RPC身份认证，请将<code>hadoop.security.authentication</code>属性设置为<code>kerberos</code>，并适当地设置下面列出的安全相关的配置。</p><p>以下属性应位于集群中所有节点的<code>core-site.xml</code>中:</p><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>hadoop.security.authentication</code></td><td><code>kerberos</code></td><td>simple : No authentication. (default)  kerberos : Enable authentication by Kerberos.</td></tr><tr><td><code>hadoop.security.authorization</code></td><td><code>true</code></td><td>Enable RPC service-level authorization.</td></tr><tr><td><code>hadoop.rpc.protection</code></td><td><code>authentication</code></td><td>authentication : authentication only (default); integrity : integrity check in addition to authentication; privacy : data encryption in addition to integrity</td></tr><tr><td><code>hadoop.security.auth_to_local</code></td><td><code>RULE:exp1 RULE:exp2 … DEFAULT</code></td><td>The value is string containing new line characters. See Kerberos documentation for the format of exp.</td></tr><tr><td><code>hadoop.proxyuser.superuser.hosts</code></td><td>-</td><td>comma separated hosts from which superuser access are allowed to impersonation. * means wildcard.</td></tr><tr><td><code>hadoop.proxyuser.superuser.groups</code></td><td>-</td><td>comma separated groups to which users impersonated by superuser belong. * means wildcard.</td></tr></tbody></table><p><br><br><br></p><h4 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h4><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>dfs.block.access.token.enable</code></td><td><code>true</code></td><td>Enable HDFS block access tokens for secure operations.</td></tr><tr><td><code>dfs.namenode.kerberos.principal</code></td><td><code>nn/_HOST@REALM.TLD</code></td><td>Kerberos principal name for the NameNode.</td></tr><tr><td><code>dfs.namenode.keytab.file</code></td><td><code>/etc/security/keytab/nn.service.keytab</code></td><td>Kerberos keytab file for the NameNode.</td></tr><tr><td><code>dfs.namenode.kerberos.internal.spnego.principal</code></td><td><code>HTTP/_HOST@REALM.TLD</code></td><td>The server principal used by the NameNode for web UI SPNEGO authentication. The SPNEGO server principal begins with the prefix HTTP/ by convention. If the value is ‘*’, the web server will attempt to login with every principal specified in the keytab file dfs.web.authentication.kerberos.keytab. For most deployments this can be set to ${dfs.web.authentication.kerberos.principal} i.e use the value of dfs.web.authentication.kerberos.principal.</td></tr><tr><td><code>dfs.web.authentication.kerberos.keytab</code></td><td><code>/etc/security/keytab/spnego.service.keytab</code></td><td>SPNEGO keytab file for the NameNode. In HA clusters this setting is shared with the Journal Nodes.</td></tr></tbody></table><p>以下设置允许配置对NameNode Web UI的SSL访问(可选):</p><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>dfs.http.policy</code></td><td><code>HTTP_ONLY</code> or <code>HTTPS_ONLY</code> or <code>HTTP_AND_HTTPS</code></td><td>HTTPS_ONLY turns off http access. This option takes precedence over the deprecated configuration dfs.https.enable and hadoop.ssl.enabled. If using SASL to authenticate data transfer protocol instead of running DataNode as root and using privileged ports, then this property must be set to HTTPS_ONLY to guarantee authentication of HTTP servers. (See dfs.data.transfer.protection.)</td></tr><tr><td><code>dfs.namenode.https-address</code></td><td><code>0.0.0.0:9871</code></td><td>This parameter is used in non-HA mode and without federation. See HDFS High Availability and HDFS Federation for details.</td></tr><tr><td><code>dfs.https.enable</code></td><td><code>true</code></td><td>This value is deprecated. Use dfs.http.policy</td></tr></tbody></table><p><br><br><br></p><h4 id="Secondary-NameNode"><a href="#Secondary-NameNode" class="headerlink" title="Secondary NameNode"></a>Secondary NameNode</h4><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>dfs.namenode.secondary.http-address</code></td><td><code>0.0.0.0:9868</code></td><td>HTTP web UI address for the Secondary NameNode.</td></tr><tr><td><code>dfs.namenode.secondary.https-address</code></td><td><code>0.0.0.0:9869</code></td><td>HTTPS web UI address for the Secondary NameNode.</td></tr><tr><td><code>dfs.secondary.namenode.keytab.file</code></td><td><code>/etc/security/keytab/sn.service.keytab</code></td><td>Kerberos keytab file for the Secondary NameNode.</td></tr><tr><td><code>dfs.secondary.namenode.kerberos.principal</code></td><td><code>sn/_HOST@REALM.TLD</code></td><td>Kerberos principal name for the Secondary NameNode.</td></tr><tr><td><code>dfs.secondary.namenode.kerberos.internal.spnego.principal</code></td><td><code>HTTP/_HOST@REALM.TLD</code></td><td>The server principal used by the Secondary NameNode for web UI SPNEGO authentication. The SPNEGO server principal begins with the prefix HTTP/ by convention. If the value is ‘*’, the web server will attempt to login with every principal specified in the keytab file dfs.web.authentication.kerberos.keytab. For most deployments this can be set to ${dfs.web.authentication.kerberos.principal} i.e use the value of dfs.web.authentication.kerberos.principal.</td></tr></tbody></table><p><br><br><br></p><h4 id="JournalNode"><a href="#JournalNode" class="headerlink" title="JournalNode"></a>JournalNode</h4><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>dfs.journalnode.kerberos.principal</code></td><td><code>jn/_HOST@REALM.TLD</code></td><td>Kerberos principal name for the JournalNode.</td></tr><tr><td><code>dfs.journalnode.keytab.file</code></td><td><code>/etc/security/keytab/jn.service.keytab</code></td><td>Kerberos keytab file for the JournalNode.</td></tr><tr><td><code>dfs.journalnode.kerberos.internal.spnego.principal</code></td><td><code>HTTP/_HOST@REALM.TLD</code></td><td>The server principal used by the JournalNode for web UI SPNEGO authentication when Kerberos security is enabled. The SPNEGO server principal begins with the prefix HTTP/ by convention. If the value is ‘*’, the web server will attempt to login with every principal specified in the keytab file dfs.web.authentication.kerberos.keytab. For most deployments this can be set to ${dfs.web.authentication.kerberos.principal} i.e use the value of dfs.web.authentication.kerberos.principal.</td></tr><tr><td><code>dfs.web.authentication.kerberos.keytab</code></td><td><code>/etc/security/keytab/spnego.service.keytab</code></td><td>SPNEGO keytab file for the JournalNode. In HA clusters this setting is shared with the Name Nodes.</td></tr><tr><td><code>dfs.journalnode.https-address</code></td><td><code>0.0.0.0:8481</code></td><td>HTTPS web UI address for the JournalNode.</td></tr></tbody></table><p><br><br><br></p><h4 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h4><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>dfs.datanode.data.dir.perm</code></td><td><code>700</code></td><td>-</td></tr><tr><td><code>dfs.datanode.address</code></td><td><code>0.0.0.0:1004</code></td><td>Secure DataNode must use privileged port in order to assure that the server was started securely. This means that the server must be started via jsvc. Alternatively, this must be set to a non-privileged port if using SASL to authenticate data transfer protocol. (See dfs.data.transfer.protection.)</td></tr><tr><td><code>dfs.datanode.http.address</code></td><td><code>0.0.0.0:1006</code></td><td>Secure DataNode must use privileged port in order to assure that the server was started securely. This means that the server must be started via jsvc.</td></tr><tr><td><code>dfs.datanode.https.address</code></td><td><code>0.0.0.0:9865</code></td><td>HTTPS web UI address for the Data Node.</td></tr><tr><td><code>dfs.datanode.kerberos.principal</code></td><td><code>dn/_HOST@REALM.TLD</code></td><td>Kerberos principal name for the DataNode.</td></tr><tr><td><code>dfs.datanode.keytab.file</code></td><td><code>/etc/security/keytab/dn.service.keytab</code></td><td>Kerberos keytab file for the DataNode.</td></tr><tr><td><code>dfs.encrypt.data.transfer</code></td><td><code>false</code></td><td>set to true when using data encryption</td></tr><tr><td><code>dfs.encrypt.data.transfer.algorithm</code></td><td>-</td><td>optionally set to 3des or rc4 when using data encryption to control encryption algorithm</td></tr><tr><td><code>dfs.encrypt.data.transfer.cipher.suites</code></td><td>-</td><td>optionally set to AES/CTR/NoPadding to activate AES encryption when using data encryption</td></tr><tr><td><code>dfs.encrypt.data.transfer.cipher.key.bitlength</code></td><td>-</td><td>optionally set to 128, 192 or 256 to control key bit length when using AES with data encryption</td></tr><tr><td><code>dfs.data.transfer.protection</code></td><td>-</td><td>authentication : authentication only; integrity : integrity check in addition to authentication; privacy : data encryption in addition to integrity This property is unspecified by default. Setting this property enables SASL for authentication of data transfer protocol. If this is enabled, then dfs.datanode.address must use a non-privileged port, dfs.http.policy must be set to HTTPS_ONLY and the HDFS_DATANODE_SECURE_USER environment variable must be undefined when starting the DataNode process.</td></tr></tbody></table><p><br><br><br></p><h4 id="WebHDFS"><a href="#WebHDFS" class="headerlink" title="WebHDFS"></a>WebHDFS</h4><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>dfs.web.authentication.kerberos.principal</code></td><td><code>http/_HOST@REALM.TLD</code></td><td>Kerberos principal name for the WebHDFS. In HA clusters this setting is commonly used by the JournalNodes for securing access to the JournalNode HTTP server with SPNEGO.</td></tr><tr><td><code>dfs.web.authentication.kerberos.keytab</code></td><td><code>/etc/security/keytab/http.service.keytab</code></td><td>Kerberos keytab file for WebHDFS. In HA clusters this setting is commonly used the JournalNodes for securing access to the JournalNode HTTP server with SPNEGO.</td></tr></tbody></table><p><br><br><br></p><h4 id="ResourceManager"><a href="#ResourceManager" class="headerlink" title="ResourceManager"></a>ResourceManager</h4><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>yarn.resourcemanager.principal</code></td><td><code>rm/_HOST@REALM.TLD</code></td><td>Kerberos principal name for the ResourceManager.</td></tr><tr><td><code>yarn.resourcemanager.keytab</code></td><td><code>/etc/security/keytab/rm.service.keytab</code></td><td>Kerberos keytab file for the ResourceManager.</td></tr><tr><td><code>yarn.resourcemanager.webapp.https.address</code></td><td><code>${yarn.resourcemanager.hostname}:8090</code></td><td>The https adddress of the RM web application for non-HA. In HA clusters, use yarn.resourcemanager.webapp.https.address.rm-id for each ResourceManager. See ResourceManager High Availability for details.</td></tr></tbody></table><p><br><br><br></p><h4 id="NodeManager"><a href="#NodeManager" class="headerlink" title="NodeManager"></a>NodeManager</h4><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>yarn.nodemanager.principal</code></td><td><code>nm/_HOST@REALM.TLD</code></td><td>Kerberos principal name for the NodeManager.</td></tr><tr><td><code>yarn.nodemanager.keytab</code></td><td><code>/etc/security/keytab/nm.service.keytab</code></td><td>Kerberos keytab file for the NodeManager.</td></tr><tr><td><code>yarn.nodemanager.container-executor.class</code></td><td><code>org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor</code></td><td>Use LinuxContainerExecutor.</td></tr><tr><td><code>yarn.nodemanager.linux-container-executor.group</code></td><td><code>hadoop</code></td><td>Unix group of the NodeManager.</td></tr><tr><td><code>yarn.nodemanager.linux-container-executor.path</code></td><td><code>/path/to/bin/container-executor</code></td><td>The path to the executable of Linux container executor.</td></tr><tr><td><code>yarn.nodemanager.webapp.https.address</code></td><td><code>0.0.0.0:8044</code></td><td>The https adddress of the NM web application.</td></tr></tbody></table><p><br><br><br></p><h4 id="Configuration-for-WebAppProxy"><a href="#Configuration-for-WebAppProxy" class="headerlink" title="Configuration for WebAppProxy"></a>Configuration for WebAppProxy</h4><p>WebAppProxy在应用程序和用户导出的Web应用程序之间提供代理。如果启用了安全性，它将在访问可能不安全的Web应用程序之前警告用户。使用代理的身份验证和授权与任何其他特权Web应用程序一样处理。</p><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>yarn.web-proxy.address</code></td><td>WebAppProxy host:port for proxy to AM web apps.</td><td>host:port if this is the same as yarn.resourcemanager.webapp.address or it is not defined then the ResourceManager will run the proxy otherwise a standalone proxy server will need to be launched.</td></tr><tr><td><code>yarn.web-proxy.keytab</code></td><td><code>/etc/security/keytab/web-app.service.keytab</code></td><td>Kerberos keytab file for the WebAppProxy.</td></tr><tr><td><code>yarn.web-proxy.principal</code></td><td><code>wap/_HOST@REALM.TLD</code></td><td>Kerberos principal name for the WebAppProxy.</td></tr></tbody></table><p><br><br><br></p><h4 id="LinuxContainerExecutor"><a href="#LinuxContainerExecutor" class="headerlink" title="LinuxContainerExecutor"></a>LinuxContainerExecutor</h4><p>YARN框架使用的ContainerExecutor，用于定义任何容器的启动和控制方式。</p><p>以下是Hadoop YARN中可用内容:</p><table><thead><tr><th>ContainerExecutor</th><th>Description</th></tr></thead><tbody><tr><td>DefaultContainerExecutor</td><td>The default executor which YARN uses to manage container execution. The container process has the same Unix user as the NodeManager.</td></tr><tr><td>LinuxContainerExecutor</td><td>Supported only on GNU/Linux, this executor runs the containers as either the YARN user who submitted the application (when full security is enabled) or as a dedicated user (defaults to nobody) when full security is not enabled. When full security is enabled, this executor requires all user accounts to be created on the cluster nodes where the containers are launched. It uses a setuid executable that is included in the Hadoop distribution. The NodeManager uses this executable to launch and kill containers. The setuid executable switches to the user who has submitted the application and launches or kills the containers. For maximum security, this executor sets up restricted permissions and user/group ownership of local files and directories used by the containers such as the shared objects, jars, intermediate files, log files etc. Particularly note that, because of this, except the application owner and NodeManager, no other user can access any of the local files/directories including those localized as part of the distributed cache.</td></tr></tbody></table><p><br></p><p>要构建LinuxContainerExecutor可执行:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 集群配置文件路径</span></span><br><span class="line">mvn package -Dcontainer-executor.conf.dir=/opt/hadoop/etc/hadoop/</span><br></pre></td></tr></table></figure><p>LinuxTaskController 要求包含和导向 <code>yarn.nodemanager.local-dirs</code> 和 <code>yarn.nodemanager.log-dirs</code> 中指定的目录的路径设置为755权限。</p><p><br></p><p>可执行文件需要一个名为<code>container-executor.cfg(conf/container-executor.cfg)</code>的配置文件，该文件存在于上述mvn的目标配置目录里。该配置文件必须有NodeNanager的用户所有，权限应为<code>0400</code>。<br>可执行文件要求此配置文件存在以下配置项(KV):</p><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td>yarn.nodemanager.linux-container-executor.group</td><td>hadoop</td><td>Unix group of the NodeManager. The group owner of the container-executor binary should be this group. Should be same as the value with which the NodeManager is configured. This configuration is required for validating the secure access of the container-executor binary.</td></tr><tr><td>banned.users</td><td>hdfs,yarn,mapred,bin</td><td>Banned users.</td></tr><tr><td>allowed.system.users</td><td>foo,bar</td><td>Allowed system users.</td></tr><tr><td>min.user.id</td><td>1000</td><td>Prevent other super-users.</td></tr></tbody></table><p><br></p><p>以下是与LinuxContainerExecutor相关的各种路径所需的本地文件系统权限：</p><table><thead><tr><th>Filesystem</th><th>Path</th><th>User:Group</th><th>Permissions</th></tr></thead><tbody><tr><td><code>local</code></td><td><code>container-executor</code></td><td>root:hadoop</td><td>–Sr-s–*</td></tr><tr><td><code>local</code></td><td><code>conf/container-executor.cfg</code></td><td>root:hadoop</td><td>r——-*</td></tr><tr><td><code>local</code></td><td><code>yarn.nodemanager.local-dirs</code></td><td>yarn:hadoop</td><td>drwxr-xr-x</td></tr><tr><td><code>local</code></td><td><code>yarn.nodemanager.log-dirs</code></td><td>yarn:hadoop</td><td>drwxr-xr-x</td></tr></tbody></table><p><br><br><br></p><h4 id="MapReduce-JobHistory-Server"><a href="#MapReduce-JobHistory-Server" class="headerlink" title="MapReduce JobHistory Server"></a>MapReduce JobHistory Server</h4><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>mapreduce.jobhistory.address</code></td><td>MapReduce JobHistory Server <code>host:port</code></td><td>Default port is 10020.</td></tr><tr><td><code>mapreduce.jobhistory.keytab</code></td><td><code>/etc/security/keytab/jhs.service.keytab</code></td><td>Kerberos keytab file for the MapReduce JobHistory Server.</td></tr><tr><td><code>mapreduce.jobhistory.principal</code></td><td><code>jhs/_HOST@REALM.TLD</code></td><td>Kerberos principal name for the MapReduce JobHistory Server.</td></tr></tbody></table><p><br><br><br><br><br></p><h3 id="Multihoming"><a href="#Multihoming" class="headerlink" title="Multihoming"></a>Multihoming</h3><p>多宿主设置，其中每个主机在DNS中具有多个主机名(如，对应于公共和专用网络接口的不同主机名)。可能需要额外的配置才能使Kerberos身份认证工作。</p><p><br><br><br></p><h3 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h3><p>Kerberos is hard to set up，and harder to debug。常见问题有:</p><ul><li>Network and DNS configuration</li><li>Kerberos configuration on hosts (<code>/etc/krb5.conf</code>)</li><li>Keytab creation and maintenance</li><li>Environment setup: JVM, user login, system clocks, etc</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Set the environment variable HADOOP_JAAS_DEBUG to true</span><br><span class="line">export HADOOP_JAAS_DEBUG=true</span><br><span class="line"></span><br><span class="line"># Edit the log4j.properties file to log Hadoop’s security package at DEBUG level</span><br><span class="line">log4j.logger.org.apache.hadoop.security=DEBUG</span><br><span class="line"></span><br><span class="line"># Enable JVM-level debugging by setting some system properties</span><br><span class="line">export HADOOP_OPTS=&quot;-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug&quot;</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="KDiag"><a href="#KDiag" class="headerlink" title="KDiag"></a>KDiag</h3><p>Troubleshooting with KDiag</p><p>Hadoop有一个工具来帮助验证设置：<strong>KDiag</strong>。</p><p>它包含一系列用于JVM配置和环境的探测器，转储出一些系统文件（<code>/etc/krb5.conf</code>, <code>/etc/ntp.conf</code>），打印出一些系统状态，然后尝试登录到Kerberos作为当前用户或命名密钥表中的特定主体。<br>该命令的输出可用于本地诊断，或转发给支持群集的任何人。<br>KDiag命令有自己的入口点，通过将kdiag传递给<code>hadoop</code>命令来调用它。因此，它将显示用于调用它的命令的kerberos客户端状态。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">hadoop kdiag</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 帮助</span></span><br><span class="line">bin/hadoop kdiag --<span class="built_in">help</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 栗子</span></span><br><span class="line">hadoop kdiag \</span><br><span class="line">  --nofail \</span><br><span class="line">  --resource hdfs-site.xml --resource yarn-site.xml \</span><br><span class="line">  --keylen 1024 \</span><br><span class="line">  --keytab zk.service.keytab --principal zookeeper/devix.example.org@REALM</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="关闭安全模式"><a href="#关闭安全模式" class="headerlink" title="关闭安全模式"></a>关闭安全模式</h3><p>Hadoop Secure Mode默认是开启的！</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看</span></span><br><span class="line"><span class="comment"># bin/hadoop dfsadmin -safemode get(旧)</span></span><br><span class="line">bin/hdfs dfsadmin -safemode get</span><br><span class="line">Safe mode is ON</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭</span></span><br><span class="line"><span class="comment"># bin/hdfs dfsadmin -safemode leave(旧)</span></span><br><span class="line">bin/hdfs dfsadmin -safemode  leave</span><br><span class="line">Safe mode is OFF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用</span></span><br><span class="line"><span class="comment"># bin/hdfs dfsadmin -safemode enter(旧)</span></span><br><span class="line">bin/hdfs dfsadmin -safemode enter</span><br><span class="line">Safe mode is ON</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="服务级别授权"><a href="#服务级别授权" class="headerlink" title="服务级别授权"></a>服务级别授权</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/ServiceLevelAuth.html" target="_blank" rel="noopener">Service Level Authorization Guide</a></p><p>本节描述了如何配置和管理Hadoop服务级别的授权(Service Level Authorization)。</p><p><br></p><p><strong>Prerequisites:</strong></p><p>确已正确安装、配置和设置Hadoop！</p><p><br></p><h3 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h3><p>服务级别授权是初始化授权机制，用于确保连接到特定的Hadoop服务的客户端具有必要的预配置设置，并且有权访问给定服务。例如，MapReduce集群可以使用此机制来允许已配置的用户/组列表提交作业。</p><p><code>$HADOOP_CONF_DIR/hadoop-policy.xml</code>配置文件用于定义各种Hadoop服务的访问控制列表(ACL)。<br>服务级别授权在其他访问控制检查之前执行很久，例如文件权限检查，作业队列上的访问控制等。</p><p><br><br><br></p><h3 id="配置-3"><a href="#配置-3" class="headerlink" title="配置"></a>配置</h3><p>通过配置文件<code>$HADOOP_CONF_DIR/hadoop-policy.xml</code>配置服务级别的授权。</p><p><br></p><h4 id="启用服务级别授权"><a href="#启用服务级别授权" class="headerlink" title="启用服务级别授权"></a>启用服务级别授权</h4><p>Enable Service Level Authorization</p><p>默认情况下，Hadoop禁用服务级别授权。要启用它，请在<code>$HADOOP_CONF_DIR/core-site.xml</code>中将配置属性<code>hadoop.security.authorization</code>设置为<code>true</code>。</p><p><br><br><br></p><h4 id="Hadoop服务和配置项"><a href="#Hadoop服务和配置项" class="headerlink" title="Hadoop服务和配置项"></a>Hadoop服务和配置项</h4><p>Hadoop Services and Configuration Properties</p><p>下面列出各种Hadoop服务及其配置项:</p><table><thead><tr><th>Property</th><th>Service</th></tr></thead><tbody><tr><td><code>security.client.protocol.acl</code></td><td>ACL for ClientProtocol, which is used by user code via the DistributedFileSystem.</td></tr><tr><td><code>security.client.datanode.protocol.acl</code></td><td>ACL for ClientDatanodeProtocol, the client-to-datanode protocol for block recovery.</td></tr><tr><td><code>security.datanode.protocol.acl</code></td><td>ACL for DatanodeProtocol, which is used by datanodes to communicate with the namenode.</td></tr><tr><td><code>security.inter.datanode.protocol.acl</code></td><td>ACL for InterDatanodeProtocol, the inter-datanode protocol for updating generation timestamp.</td></tr><tr><td><code>security.namenode.protocol.acl</code></td><td>ACL for NamenodeProtocol, the protocol used by the secondary namenode to communicate with the namenode.</td></tr><tr><td><code>security.job.client.protocol.acl</code></td><td>ACL for JobSubmissionProtocol, used by job clients to communciate with the resourcemanager for job submission, querying job status etc.</td></tr><tr><td><code>security.job.task.protocol.acl</code></td><td>ACL for TaskUmbilicalProtocol, used by the map and reduce tasks to communicate with the parent nodemanager.</td></tr><tr><td><code>security.refresh.policy.protocol.acl</code></td><td>ACL for RefreshAuthorizationPolicyProtocol, used by the dfsadmin and rmadmin commands to refresh the security policy in-effect.</td></tr><tr><td><code>security.ha.service.protocol.acl</code></td><td>ACL for HAService protocol used by HAAdmin to manage the active and stand-by states of namenode.</td></tr></tbody></table><p><br><br><br></p><h4 id="访问控制列表"><a href="#访问控制列表" class="headerlink" title="访问控制列表"></a>访问控制列表</h4><p>Access Control Lists</p><p><code>$HADOOP_CONF_DIR/hadoop-policy.xml</code>为每个Hadoop服务定义一个访问控制列表。</p><p>每个访问控制列表都有一个简单的格式: users/groups都是用逗号分隔的名称列表。如: <code>user1, user2, group1, group2</code></p><p>如果仅提供组列表，则在行的开头添加空格，等效地以逗号分隔的用户列表后跟空格或不显示仅包含一组给定用户。特殊值<code>*</code>表示允许所有用户访问该服务。如果未为服务定义访问控制列表，则应用<code>security.service.authorization.default.acl</code> 的值。如果未定义 <code>security.service.authorization.default.acl</code>，则应用<code>*</code>。</p><p><br><br><br></p><h4 id="被阻止的访问控制列表"><a href="#被阻止的访问控制列表" class="headerlink" title="被阻止的访问控制列表"></a>被阻止的访问控制列表</h4><p>Blocked Access Control Lists</p><p>在某些情况下，需要为服务指定阻止的访问控制列表。这指定了未授权访问该服务的用户和组的列表。被阻止的访问控制列表的格式与访问控制列表的格式相同。<br>可通过<code>$HADOOP_CONF_DIR/hadoop-policy.xml</code>指定阻止的访问控制列表。属性名称通过后缀<code>.blocked</code>派生。栗子: <code>security.client.protocol.acl</code> 的阻止访问控制列表的属性名称为<code>security.client.protocol.acl.blocked</code> 。</p><p>对于服务，可以指定访问控制列表和阻止的控制列表。如果用户在访问控制中而不在阻止的访问控制列表中，则授权用户访问该服务。</p><p>如果未为服务定义阻止访问控制列表，则应用 <code>security.service.authorization.default.acl.blocked</code> 的值。如果未定义 <code>security.service.authorization.default.acl.blocked</code>，则应用空的阻止访问控制列表。</p><p><br><br><br></p><h4 id="IP地址，主机名，IP范围进行访问控制"><a href="#IP地址，主机名，IP范围进行访问控制" class="headerlink" title="IP地址，主机名，IP范围进行访问控制"></a>IP地址，主机名，IP范围进行访问控制</h4><p>Access Control using Lists of IP Addresses, Host Names and IP Ranges</p><p>可以基于访问服务的客户端IP地址来控制对服务的访问。通过指定IP地址，主机名和IP范围列表，可以限制从一组计算机访问服务。每个服务的属性名称都是从相应的acl属性名称派生的。如果acl的属性名称为<code>security.client.protocol.acl</code>，则hosts列表的属性名称为 <code>security.client.protocol.hosts</code>。<br>如果未为服务定义主机列表，则应用 <code>security.service.authorization.default.hosts</code> 的值。如果未定义 <code>security.service.authorization.default.hosts</code>，则应用 <code>*</code> 。</p><p>可以指定阻止的主机列表。只有那些位于主机列表中但未在阻止主机列表中的计算机才会被授予对该服务的访问权限。属性名称通过后缀 <code>.blocked</code> 派生。栗子: <code>security.client.protocol.hosts</code> 的被阻止主机列表的属性名称为 <code>security.client.protocol.hosts.blocked</code>。<br>如果未为服务定义阻止主机列表，则应用 <code>security.service.authorization.default.hosts.blocked</code> 的值。如果未定义 <code>security.service.authorization.default.hosts.blocked</code>，则应用空的阻止主机列表。</p><p><br><br><br></p><h4 id="刷新服务级别授权配置"><a href="#刷新服务级别授权配置" class="headerlink" title="刷新服务级别授权配置"></a>刷新服务级别授权配置</h4><p>Refreshing Service Level Authorization Configuration</p><p>可在不重启Hadoop Daemon的情况下更改NameNode和ResourceManager的服务级别授权配置。集群管理员可在Master节点上更改<code>$HADOOP_CONF_DIR/hadoop-policy.xml</code>，并指示NameNode和ResourceManager分别通过<code>-refreshServiceAcl</code>开关将其各自的配置重新加载到<code>dfsadmin</code>和<code>rmadmin</code>命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 刷新NameNode的服务级别的授权配置</span></span><br><span class="line">bin/hdfs dfsadmin -refreshServiceAcl</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 刷新ResourceManager的服务级别授权配置</span></span><br><span class="line">bin/yarn rmadmin -refreshServiceAcl</span><br></pre></td></tr></table></figure><p>当然，也可以使用<code>$HADOOP_CONF_DIR/hadoop-policy.xml</code>中的<code>security.refresh.policy.protocol.acl</code>属性来限制对某些users/groups刷新服务级别授权的访问权限。</p><p><br><br><br></p><h4 id="栗子"><a href="#栗子" class="headerlink" title="栗子"></a>栗子</h4><p>仅允许mapreduce gruop中的a, b users将作业提交到MapReduce集群:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">     &lt;name&gt;security.job.client.protocol.acl&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;a,b mapreduce&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><br></p><p>仅允许数据属于group datanodes的users运行的DataNode与NameNode进行通信:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">     &lt;name&gt;security.datanode.protocol.acl&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;datanodes&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><br></p><p>允许任何用户作为DFSClient与HDFS集群通信:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">     &lt;name&gt;security.client.protocol.acl&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="HTTP认证"><a href="#HTTP认证" class="headerlink" title="HTTP认证"></a>HTTP认证</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/HttpAuthentication.html" target="_blank" rel="noopener">Authentication for Hadoop HTTP web-consoles</a></p><p><br></p><h3 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h3><p>本节介绍如何配置Hadoop HTTP web-console以要求用户身份认证。</p><p>默认情况下，Hadoop HTTP web-console(ResourceManager, NameNode, NodeManager, DataNodes)允许无需任何形式的身份认证的访问。</p><p>可将Hadoop HTTP web-console配置为使用HTTP SPNEGO协议要求Kerberos身份认证。<br>此外，Hadoop HTTP web-console支持相当于Hadoop的 Pseudo/Simple 认证。如果启用此选项，则必须使用 <code>user.name</code> 查询字符串参数在浏览器交互中地址用户名。 如: <code>http://localhost:8088/cluster?user.name=usera</code>。<br>如果HTTP web-console需要自定义身份认证机制，则可以实现插件以支持备用身份认证机制。</p><p><br><br><br></p><h3 id="配置-4"><a href="#配置-4" class="headerlink" title="配置"></a>配置</h3><p>以下属性应位于集群中所有节点的 <code>core-site.xml</code> 中:</p><table><thead><tr><th>Property Name</th><th>Default Value</th><th>Description</th></tr></thead><tbody><tr><td><code>hadoop.http.filter.initializers</code></td><td>-</td><td>Add to this property the org.apache.hadoop.security.AuthenticationFilterInitializer initializer class.</td></tr><tr><td><code>hadoop.http.authentication.type</code></td><td>simple</td><td>Defines authentication used for the HTTP web-consoles. The supported values are: simple</td><td>kerberos</td><td>#AUTHENTICATION_HANDLER_CLASSNAME#.</td></tr><tr><td><code>hadoop.http.authentication.token.validity</code></td><td>36000</td><td>Indicates how long (in seconds) an authentication token is valid before it has to be renewed.</td></tr><tr><td><code>hadoop.http.authentication.token.max-inactive-interval</code></td><td>-1 (disabled)</td><td>Specifies the time, in seconds, between client requests the server will invalidate the token.</td></tr><tr><td><code>hadoop.http.authentication.signature.secret.file</code></td><td><code>$user.home/hadoop-http-auth-signature-secret</code></td><td>The signature secret file for signing the authentication tokens. The same secret should be used for all nodes in the cluster, ResourceManager, NameNode, DataNode and NodeManager. This file should be readable only by the Unix user running the daemons.</td></tr><tr><td><code>hadoop.http.authentication.cookie.domain</code></td><td>-</td><td>The domain to use for the HTTP cookie that stores the authentication token. For authentication to work correctly across all nodes in the cluster the domain must be correctly set. There is no default value, the HTTP cookie will not have a domain working only with the hostname issuing the HTTP cookie.</td></tr><tr><td><code>hadoop.http.authentication.cookie.persistent</code></td><td>false (session cookie)</td><td>Specifies the persistence of the HTTP cookie. If the value is true, the cookie is a persistent one. Otherwise, it is a session cookie. IMPORTANT: when using IP addresses, browsers ignore cookies with domain settings. For this setting to work properly all nodes in the cluster must be configured to generate URLs with hostname.domain names on it.</td></tr><tr><td><code>hadoop.http.authentication.simple.anonymous.allowed</code></td><td>true</td><td>Indicates whether anonymous requests are allowed when using ‘simple’ authentication.</td></tr><tr><td><code>hadoop.http.authentication.kerberos.principal</code></td><td><code>HTTP/_HOST@$LOCALHOST</code></td><td>Indicates the Kerberos principal to be used for HTTP endpoint when using ‘kerberos’ authentication. The principal short name must be HTTP per Kerberos HTTP SPNEGO specification. _HOST -if present- is replaced with bind address of the HTTP server.</td></tr><tr><td><code>hadoop.http.authentication.kerberos.keytab</code></td><td><code>$user.home/hadoop.keytab</code></td><td>Location of the keytab file with the credentials for the Kerberos principal used for the HTTP endpoint.</td></tr></tbody></table><p><br><br><br></p><h3 id="CORS"><a href="#CORS" class="headerlink" title="CORS"></a>CORS</h3><p>要启用跨域支持(CORS)，请设置以下配置参数:</p><p>将 <code>org.apache.hadoop.security.HttpCrossOriginFilterInitializer</code> 添加到 <code>core-site.xml</code> 中的 <code>hadoop.http.filter.initializers</code>。您还需要在 <code>core-site.xml</code> 中设置以下属性:</p><table><thead><tr><th>Property</th><th>Default Value</th><th>Description</th></tr></thead><tbody><tr><td><code>hadoop.http.cross-origin.enabled</code></td><td><code>false</code></td><td>Enables cross origin support for all web-services</td></tr><tr><td><code>hadoop.http.cross-origin.allowed-origins</code></td><td><code>*</code></td><td>Comma separated list of origins that are allowed. Values prefixed with regex: are interpreted as regular expressions. Values containing wildcards (*) are possible as well, here a regular expression is generated, the use is discouraged and support is only available for backward compatibility.</td></tr><tr><td><code>hadoop.http.cross-origin.allowed-methods</code></td><td>GET,POST,HEAD</td><td>Comma separated list of methods that are allowed</td></tr><tr><td><code>hadoop.http.cross-origin.allowed-headers</code></td><td>X-Requested-With,Content-Type,Accept,Origin</td><td>Comma separated list of headers that are allowed</td></tr><tr><td><code>hadoop.http.cross-origin.max-age</code></td><td>1800</td><td>Number of seconds a pre-flighted request can be cached</td></tr></tbody></table><p><br><br><br><br><br></p><h2 id="Credential-Provider-API"><a href="#Credential-Provider-API" class="headerlink" title="Credential Provider API"></a>Credential Provider API</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/CredentialProviderAPI.html" target="_blank" rel="noopener">CredentialProvider API Guide</a></p><p>CredentialProvider API是一个用于插入可扩展凭据提供程序的SPI框架。凭据提供程序用于将敏感令牌(token)，机密(secret)和密码(passwd)的使用与其存储和管理的详细信息分开。选择各种存储机制来保护这些凭证的能力使我们能够使这些敏感资产远离明文(clear text)，远离窥探并可能由第三方解决方案管理。</p><p>本节描述CredentialProvider API的设计，开箱即用的实现，使用它们以及如何使用它们。</p><p><br><br><br><br><br></p><h2 id="密钥管理"><a href="#密钥管理" class="headerlink" title="密钥管理"></a>密钥管理</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-kms/index.html" target="_blank" rel="noopener">Hadoop Key Management Server (KMS)</a></p><p><strong>Hadoop KMS</strong> 是一个基于Hadoop KeyProvider API的加密秘钥管理服务器。<br>它提供了一个Client和Server组件，它们使用REST API通过HTTP进行通信。<br>Client是KeyProvider实现，使用KMS HTTP REST API与KMS交互。<br>KMS及其Client內建有安全性，并且支持HTTP和 SPNEGO Kerberos认证和HTTPS安全传输。<br>KMS是一个Java Jetty Web应用程序。</p><p><br><br><br><br><br></p><h2 id="Tracing"><a href="#Tracing" class="headerlink" title="Tracing"></a>Tracing</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/Tracing.html" target="_blank" rel="noopener">Enabling Dapper-like Tracing in Hadoop</a></p><p><br></p><h3 id="HTrace"><a href="#HTrace" class="headerlink" title="HTrace"></a>HTrace</h3><p>HDFS-5274 使用开源跟踪库(Apache HTrace)增加了对通过HDFS跟踪请求的支持。设置跟踪非常简单，但是它需要对客户端代码进行一些非常小的更改。</p><p><br><br><br></p><h3 id="SpanReceivers"><a href="#SpanReceivers" class="headerlink" title="SpanReceivers"></a>SpanReceivers</h3><p><br><br><br></p><hr><p><br><br><br></p><h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><p><br></p><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p><a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" target="_blank" rel="noopener">HDFS Architecture</a></p><p>Hadoop Distributed File System(HDFS) 是一种分布式文件系统，设计用于在商业硬件上运行。它与现有的分布式文件系统有许多相似之处。但是，与其它分布式文件系统的差异很大。HDFS具有高度容错(fault-tolerant)能力，旨在部署在低成本硬件上。HDFS提供对应用程序数据的高吞吐量访问，适用于具有大型数据集的应用程序。HDFS放宽了一些POSIX要求，以实现对文件系统数据的流式访问。</p><p><br><br><br></p><h3 id="假设和目标"><a href="#假设和目标" class="headerlink" title="假设和目标"></a>假设和目标</h3><p>Assumptions and Goals</p><p><br></p><h4 id="硬件故障"><a href="#硬件故障" class="headerlink" title="硬件故障"></a>硬件故障</h4><p>Hardware Failure</p><p>硬件故障是常态而非异常。HDFS实例可能包含成百上千的主机，每台主机都存储文件系统数据的一部分。事实上，存在大量组件并且每个组件具有非平凡(non-trivial)的故障概率，这意味着HDFS某些组件始终不起作用(non-functional)。因此，检测故障并从中快速自动地恢复是HDFS的核心架构目标。</p><p><br><br><br></p><h4 id="流数据访问"><a href="#流数据访问" class="headerlink" title="流数据访问"></a>流数据访问</h4><p>Streaming Data Access</p><p>在HDFS上运行的应用程序需要对其数据集进行流式访问。它们不是通常在通用文件系统上运行的通用应用程序。HDFS设计用于批处理而不是用户的交互式使用。重点是数据访问的高吞吐量(high throughput)而不是数据访问的低延迟(low latency)。POSIX强加了许多针对HDFS的应用程序不需要的硬性要求。</p><p><br><br><br></p><h4 id="大型数据集"><a href="#大型数据集" class="headerlink" title="大型数据集"></a>大型数据集</h4><p>Large Data Sets</p><p>在HDFS上运行的应用程序具有大型数据集。HDFS中的典型文件大小为gigabytes到terabytes。因此，HDFS被调整为支持大文件。它应该为单个集群中的成百上千的节点提供高聚合数据带宽和扩展。它应该在单个实例中支持数千万个文件。</p><p><br><br><br></p><h4 id="简单的一致性模型"><a href="#简单的一致性模型" class="headerlink" title="简单的一致性模型"></a>简单的一致性模型</h4><p>Simple Coherency Model</p><p>HDFS应用程序需要一个<code>write-once-read-many</code>的文件访问模型。除了追加(append)和截断(truncates)之外，无需更改创建，写入和关闭的文件。支持将内容附加到文件末尾，但无法在任意点更新。此假设简化了数据一致性问题，并实现了高吞吐量数据访问。MapReduce应用程序或Web Crawler应用程序适合此模型。</p><p><br><br><br></p><h4 id="移动计算比移动数据更便宜"><a href="#移动计算比移动数据更便宜" class="headerlink" title="移动计算比移动数据更便宜"></a>移动计算比移动数据更便宜</h4><p>Moving Computation is Cheaper than Moving Data</p><p>如果应用程序在其操作的数据附近执行，则计算所请求的计算效率更高。当数据集很大时尤其如此。这可以最大限度地减少网络拥塞(network congestion)并提高系统的整体吞吐量。这个假设通常更好的是将计算迁移到更靠近数据所在的地方，而不是将数据移动到应用程序运行的地方。HDFS为应用程序移动到更靠近数据所在的地方的接口。</p><p><br><br><br></p><h4 id="可移植性"><a href="#可移植性" class="headerlink" title="可移植性"></a>可移植性</h4><p>Portability Across Heterogeneous Hardware and Software Platforms</p><p>HDFS的设计便于从一个平台移植到另一个平台。</p><p><br><br><br><br><br></p><h3 id="NameNode和DataNode"><a href="#NameNode和DataNode" class="headerlink" title="NameNode和DataNode"></a>NameNode和DataNode</h3><p>HDFS具有主从架构(Master-Slave)。HDFS集群由单个<strong>NameNode</strong>、一个管理文件系统命名空间和管理客户端对文件的访问的<strong>Master Server</strong>组成。此外，还有许多<strong>DataNode</strong>，通常是集群中每个节点一个，用于管理附加到它们运行节点的存储。HDFS公开文件系统命名空间，并允许用户数据存储在文件中。在内部，文件被分成一个或多个块(block)，这些块存储在一组DataNode中。<br>NameNode执行文件系统命名空间操作(如打开、关闭、重命名文件目录)。它还确定了block到DataNode的映射。<br>DataNode负责提供来自文件系统客户端的读写请求，它还根据NameNode的指令执行块操作(如创建、删除、副本)。</p><p><img src="/images/Hadoop/hdfsarchitecture.png" alt=""></p><p><br></p><p>NameNode和DataNode是设计用于在商用机器上运行的软件，这些机器通常运行GNU/Linux操作系统。HDFS使用Java语言构建，任何支持Java的机器都可运行NameNode或DataNode软件。使用高度可移植的Java语言意味着可以在各种计算机上部署HDFS。<br>典型部署具有仅运行NameNode软件的专用主机，群集中的每台其它主机都运行一个DataNode软件实例。虽然可以讲它们运行在同一台主机上，但这并不推荐。</p><p>群集中存在单个NameNode极大地简化了系统结构。NameNode是所有HDFS Metadata的仲裁者(arbitrator)和存储库(repository)。系统的设计使用户数据永远不会流经NameNode。</p><p><br><br><br><br><br></p><h3 id="文件系统命名空间"><a href="#文件系统命名空间" class="headerlink" title="文件系统命名空间"></a>文件系统命名空间</h3><p>The File System Namespace</p><p>HDFS支持传统的层次文件组织。用户或应用程序可以创建目录，并在这些目录中存储文件。文件系统命名空间层次结构类似于大多数其它现有文件系统；可创建、删除、移动、重命名文件。HDFS支持用户配额(user quotas)和访问权限。HDFS不支持硬链接和软链接。但是，HDFS架构并不排除实现这些功能。</p><p>NameNode维护文件系统命名空间。NameNode Record对文件系统命名空间或其属性的任何更改。应用程序可以指定应由HDFS维护的文件的副本数。文件的副本数称为该文件的复制因子，该信息由NameNode存储。</p><p><br><br><br><br><br></p><h3 id="数据副本"><a href="#数据副本" class="headerlink" title="数据副本"></a>数据副本</h3><p>Data Replication</p><p>HDFS旨在可靠地在大型群集中的计算机上存储非常大的文件。它将每个文件存储为一系列块。文件块的副本用以实现容错(fault tolerance)。块大小和副本因子可根据文件进行配置。</p><p>除了最后一个块之外，文件中的所有块都具有相同的大小。而用户可以在添加对可变长度块的支持以追加和hsync之后启动新块而不将最后一个块填充到配置的块大小。</p><p>应用程序可以指定文件的副本数量。副本因子可在文件创建时指定，并且可以在之后修改。HDFS中的文件是一次写入的，并且在任何时候都有一个写入器。</p><p>NameNode做出有关副本的所有决定。它定期从集群中的每个DataNode接收Heartbeat和Blockreport。收到心跳意味着DataNode正常运行，块上报包含DataNode上所有块的列表。</p><p><img src="/images/Hadoop/hdfsdatanodes.png" alt=""></p><p><br></p><h4 id="副本安置"><a href="#副本安置" class="headerlink" title="副本安置"></a>副本安置</h4><p>Replica Placement: The First Baby Steps</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;wikipeadia&lt;/li&gt;
&lt;li&gt;Hadoop官网: &lt;a href=&quot;https://hadoop.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://hadoop.apache.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Apache Software Foundation: &lt;a href=&quot;https://www.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.apache.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RHEL7x86_64&lt;/li&gt;
&lt;li&gt;Hadoop v3.2.0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="Apache" scheme="https://zhang21.github.io/tags/Apache/"/>
    
      <category term="DataAnalysis" scheme="https://zhang21.github.io/tags/DataAnalysis/"/>
    
      <category term="Hadoop" scheme="https://zhang21.github.io/tags/Hadoop/"/>
    
      <category term="BigData" scheme="https://zhang21.github.io/tags/BigData/"/>
    
  </entry>
  
  <entry>
    <title>SonarQube</title>
    <link href="https://zhang21.github.io/2019/02/22/SonarQube/"/>
    <id>https://zhang21.github.io/2019/02/22/SonarQube/</id>
    <published>2019-02-22T07:28:44.000Z</published>
    <updated>2019-03-05T08:42:13.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>GitHub: <a href="https://github.com/SonarSource/sonarqube" target="_blank" rel="noopener">https://github.com/SonarSource/sonarqube</a></li><li>Website: <a href="https://www.sonarqube.org/" target="_blank" rel="noopener">https://www.sonarqube.org/</a></li><li>Docs: <a href="https://docs.sonarqube.org" target="_blank" rel="noopener">https://docs.sonarqube.org</a></li></ul><p>环境:</p><ul><li>RHEL7x86_64</li><li>SonarQube v7.6</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p><strong>SonarQube</strong> 是一个开源的代码质量管理系统。支持超过25中编程语言，不过有些是商业插件。</p><p>SonarQube 是一种自动代码审查(code review)工具，用于检测代码中的<strong>错误(bugs)</strong>，<strong>漏洞(vulnerabilities)</strong>和<strong>代码异味(code smell)</strong>。它可以与您现有的工作流程集成，以便在项目分支和拉取请求之间进行连续的代码检查。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="架构与集成"><a href="#架构与集成" class="headerlink" title="架构与集成"></a>架构与集成</h1><p>Architecture and Integration</p><p><br></p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>SonarQube平台由4个组件组成:</p><p><img src="/images/SonarQube/architecture-scanning.png" alt=""></p><p><br></p><ul><li><strong>SonarQube Server</strong>启动三个主进程:<ul><li><strong>Web Server</strong>，供开发人员，管理人员浏览质量快照并配置SonarQube实例</li><li><strong>Search Server</strong>，基于ElasticSearch从UI返回搜索</li><li><strong>Compute Engine Server</strong>，负责处理代码分析和上报并将其保存到SonarQube数据库中</li></ul></li><li><strong>SonarQube Database</strong>用于存储<ul><li>SonarQube实例的配置(安全，插件…的设置)</li><li>项目，视图…的质量快照</li></ul></li><li>Server上安装了多个插件，可能包括Language，SCM，Intergration，Authentication，Governance…</li><li>在CI/CD Server上运行一个或多个 <strong>SonarScanner</strong> 来分析项目</li></ul><p><br><br><br><br><br></p><h2 id="集成"><a href="#集成" class="headerlink" title="集成"></a>集成</h2><p>Integration</p><p>以下模式显示了SonarQube如何与其它ALM工具进行集成，以及在哪里使用SonarQube的各种组件。</p><p><img src="/images/SonarQube/architecture-integrate.png" alt=""></p><p><br></p><ol><li>开发者在他们的IDE中集成SonarLint运行本地分析</li><li>开发者推送他们的代码到代码库</li><li>CI Server触发自动构建，以及执行运行SonarQube分析所需的SonarScanner</li><li>分析报告将发送到SonarQube Server进行处理</li><li>SonarQube Server处理分析报告并将结果存储在SonarQuebe数据库中，并在UI中显示结果</li><li>开发者通过SonarQube UI审核，评论，挑战他们的Issues以管理和减少他们的技术债务</li><li>管理者从分析中接收报告，运维使用API自动配置并从SonarQube中提取数据，使用JMX监控SonarQube Server</li></ol><p><br><br><br><br><br></p><h2 id="关于机器和位置"><a href="#关于机器和位置" class="headerlink" title="关于机器和位置"></a>关于机器和位置</h2><p>About Machines and Locations</p><ul><li>SonarQube平台不能够有多个SonarQube Server和SonarQube Database</li><li>为获得最佳性能，每个组件(Server, Database, Scanner)应该安装在单独的机器上，并且此机器应该是专用的</li><li>SonarScanner通过添加机器进行扩展</li><li>所有机器必须时钟同步</li><li>SonarQube Server和SonarQube Database必须位于同一网络下</li><li>SonarScanner不需要与SonarQube Server位于同一网络下</li><li>SonarScanner与SonarQube Database之间没有通信</li></ul><p><br><br><br></p><hr><p><br><br><br></p><h1 id="要求"><a href="#要求" class="headerlink" title="要求"></a>要求</h1><p>Requirements</p><p><br></p><h2 id="先决条件"><a href="#先决条件" class="headerlink" title="先决条件"></a>先决条件</h2><p>Prerequisites and Overview</p><p>运行SonarQube的唯一先决条件是安装Java(Oracle JRE 8/OpenJDK 8)。</p><p><br></p><h3 id="硬件要求"><a href="#硬件要求" class="headerlink" title="硬件要求"></a>硬件要求</h3><ul><li>2Cores+</li><li>2GB RAM+</li><li>建议使用高性能I/O的磁盘</li></ul><p><br><br><br></p><h3 id="支持的平台"><a href="#支持的平台" class="headerlink" title="支持的平台"></a>支持的平台</h3><ul><li>Java<ul><li>Oracle JRE 8</li><li>OpenJDK 8</li></ul></li><li>Database<ul><li>PostgreSQL v9.3-v9.6, v10. UTF-8 charset</li><li>SQL Server v2014, v2016. </li><li>Oracle v11, v12, vXE. UTF8-family charset, thin mode</li><li>MySQL v5.6, v5.7. UTF8 charset, InnoDB storage, mysql-connector-java</li></ul></li><li>Web Browser<ul><li>IE 11</li><li>Edge Latest</li><li>FireFox Latest</li><li>Chrome</li><li>Safari</li></ul></li></ul><p><br><br><br></p><h3 id="平台说明"><a href="#平台说明" class="headerlink" title="平台说明"></a>平台说明</h3><p><br></p><h4 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h4><p>如果在Linux上运行，请确保:</p><ul><li><code>vm.max_map_count</code> 大于或等于 262144</li><li><code>fs.file-max</code> 大于或等于 65535</li><li>运行SonarQube的用户可以打开至少65535个文件描述符</li><li>运行SonarQube的用户可以打开至少2048个线程</li></ul><p>用以下命令查看和配置它们:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">sysctl vm.max_map_count</span><br><span class="line">sysctl fs.file-max</span><br><span class="line"><span class="built_in">ulimit</span> -n</span><br><span class="line"><span class="built_in">ulimit</span> -u</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置，但只是临时生效</span></span><br><span class="line"><span class="comment"># root</span></span><br><span class="line">sysctl -w vm.max_map_count=262144</span><br><span class="line">sysctl -w fs.file-max=65536</span><br><span class="line"><span class="built_in">ulimit</span> -n 65536</span><br><span class="line"><span class="built_in">ulimit</span> -u 2048</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 永久生效</span></span><br><span class="line"><span class="comment"># /etc/sysctl.d/99-sonarqube.conf 或 /etc/sysctl.conf</span></span><br><span class="line"><span class="comment"># user: sonarqube</span></span><br><span class="line">sonarqube   -   nofile   65536</span><br><span class="line">sonarqube   -   nproc    2048</span><br></pre></td></tr></table></figure><p><br></p><p>如果使用<code>systemd</code>来启动SonarQube，你必须在<code>[Service]</code>的单元文件中指定这些限制:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[Service]</span><br><span class="line">...</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">LimitNPROC=2048</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="seccomp-filter"><a href="#seccomp-filter" class="headerlink" title="seccomp filter"></a>seccomp filter</h4><p>默认情况下，ElasticSearch使用<strong>seccomp filter</strong>。在大多数发行版中，此功能在内核中激活。但在RHL6等发行版上，此功能已停用。如果你的发行版中没有此功能，请无法升级到激活了seccomp filter功能的版本，则必须通过更新<code>$SONARQUBEHOME/conf/sonar.properties_</code>中的<code>sonar.search.javaAdditionalOpts</code>配置:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sonar.search.javaAdditionalOpts=-Dbootstrap.system_call_filter=false</span><br><span class="line"></span><br><span class="line"># 检查</span><br><span class="line">grep SECCOMP /boot/config-$(uname -r)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 如果内核有它，你将看到</span><br><span class="line">CONFIG_HAVE_ARCH_SECCOMP_FILTER=y</span><br><span class="line">CONFIG_SECCOMP_FILTER=y</span><br><span class="line">CONFIG_SECCOMP=y</span><br></pre></td></tr></table></figure><p><br><br><br></p><hr><p><br><br><br></p><h1 id="配置和升级"><a href="#配置和升级" class="headerlink" title="配置和升级"></a>配置和升级</h1><p>Setup and Upgrade</p><p><br></p><h2 id="快速入门"><a href="#快速入门" class="headerlink" title="快速入门"></a>快速入门</h2><p>Get Started in Two Minutes Guide</p><ul><li>从ZIP文件安装</li><li>使用Docker</li></ul><p><br></p><h3 id="zip文件安装"><a href="#zip文件安装" class="headerlink" title="zip文件安装"></a>zip文件安装</h3><ol><li>现在 SonarQube CE</li><li>解压</li><li>运行</li><li>访问</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 具体位置取决于你的安装位置</span></span><br><span class="line">/opt/sonarqube/bin/[OS]/sonar.sh console</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># localhost:9000（admin/admin）</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="Docker安装"><a href="#Docker安装" class="headerlink" title="Docker安装"></a>Docker安装</h3><p>在<a href="https://hub.docker.com/_/sonarqube/" target="_blank" rel="noopener">Docker Hub</a>上下载对应CE的镜像，上面有安装和配置的详细信息。</p><p><br><br><br><br><br></p><h2 id="安装Server"><a href="#安装Server" class="headerlink" title="安装Server"></a>安装Server</h2><p>支持多个数据库引擎，请务必遵守各个数据库引擎的要求。</p><p>创建一个空的schema和一个<code>sonarqube</code>用户。授予此用户<code>create, update, delete</code>此<code>schema</code>对象的权限。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">SCHEMA</span> <span class="string">`sonar`</span> <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8 ;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">'sonarqube'</span>@<span class="string">'localhost'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'sonarqube-PW123'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">ON</span> sonar.* <span class="keyword">TO</span> <span class="string">'sonarqube'</span>@<span class="string">'localhost'</span>;</span><br></pre></td></tr></table></figure><p><br></p><h3 id="安装数据库"><a href="#安装数据库" class="headerlink" title="安装数据库"></a>安装数据库</h3><p><br></p><h4 id="SQL-Server"><a href="#SQL-Server" class="headerlink" title="SQL Server"></a>SQL Server</h4><p>跳过，有需要的请看: <a href="https://docs.sonarqube.org/latest/setup/install-server/" target="_blank" rel="noopener">https://docs.sonarqube.org/latest/setup/install-server/</a></p><p><br><br><br></p><h4 id="Oracle"><a href="#Oracle" class="headerlink" title="Oracle"></a>Oracle</h4><p>跳过！</p><p><br><br><br></p><h4 id="PostgreSQL"><a href="#PostgreSQL" class="headerlink" title="PostgreSQL"></a>PostgreSQL</h4><p>如果你想使用<code>custom schema</code>而不是默认的<code>public schema</code>，则必须设置PostgreSQL的<code>search_path</code>属性:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">USER</span> mySonarUser <span class="keyword">SET</span> search_path <span class="keyword">to</span> mySonarQubeSchema</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h4><blockquote><p>注意:<br>Data Center Edition(Enterprise)不支持MySQL!<br>Data Center Edition: Designed for High Availability</p></blockquote><p>可在MySQL中使用两种众所周知的数据库引擎: <strong>MyISAM</strong>和<strong>InnoDB</strong>。MyISAM是最老的，并且正在逐渐被InnoDB替代。随着质量控制项目数量的增加，InnoDB显然更快，并且使用SonarQube可以更好地扩展。<br>如果你是SonarQube的早期使用者，你可能有一系列仍在使用MyISAM引擎的表。你应该将所有表的引擎更改为InnoDB。</p><p>一旦所有SonarQube表都使用InnoDB引擎，首先要做的是使用<code>innodb_buffer_pool_size</code>参数为MySQL实例分配最大的RAM，并为<code>query_cache_size</code>参数提供至少<code>15Mb</code>。</p><p>阅读这篇文档<a href="https://www.percona.com/blog/2007/11/01/innodb-performance-optimization-basics/" target="_blank" rel="noopener">InnoDB Performance Optimization</a>来优化InnoDB。</p><p><br><br><br></p><h3 id="安装Web-Server"><a href="#安装Web-Server" class="headerlink" title="安装Web Server"></a>安装Web Server</h3><p>首先，检查安装要求；<br>下载和解压压缩的发行版(不要解压到以数字开头的目录)；<br>下面变量<code>SONARQUBE-HOME</code>指的是解压的路径。</p><p><br></p><h4 id="设置数据库访问"><a href="#设置数据库访问" class="headerlink" title="设置数据库访问"></a>设置数据库访问</h4><p>编辑<code>$SONARQUBE-HOME/conf/sonar.properties</code>来配置数据库设置。模板可用于每个受支持的数据库。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Example for MySQL</span><br><span class="line">sonar.jdbc.username=sonarqube</span><br><span class="line">sonar.jdbc.password=sonarqube-PW123</span><br><span class="line">sonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance&amp;useSSL=false</span><br></pre></td></tr></table></figure><p><br></p><h4 id="添加JDBC驱动"><a href="#添加JDBC驱动" class="headerlink" title="添加JDBC驱动"></a>添加JDBC驱动</h4><p>已提供受支持数据库(Oracle除外)的驱动程序。不要更换提供的驱动程序，它们是唯一受支持的。</p><p>对于Oracle，将JDBC驱动复制到<code>$SONARQUBE-HOME/extensions/jdbc-driver/oracle</code>。</p><p><br><br><br></p><h4 id="配置ElasticSearch存储路径"><a href="#配置ElasticSearch存储路径" class="headerlink" title="配置ElasticSearch存储路径"></a>配置ElasticSearch存储路径</h4><p>默认情况下，ES数据存储在<code>$SONARQUBE-HOME/data</code>中，但不建议用于生产环境。相反，你应该将数据存储在其它位置，最好是在具有高速I/O的专用卷。除了保持可接受的性能之外，还可简化SonarQube的升级。</p><p>编辑<code>$SONARQUBE-HOME/conf/sonar.properties</code>来配置以下设置:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 请记得添加读写权限</span><br><span class="line">sonar.path.data=/var/sonarqube/data</span><br><span class="line">sonar.path.temp=/var/sonarqube/temp</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="启动Web-Server"><a href="#启动Web-Server" class="headerlink" title="启动Web Server"></a>启动Web Server</h4><p>可在<code>$SONARQUBE-HOME/conf/sonar.properties</code>配置监听地址和端口等。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sonar.web.host=192.0.0.1</span><br><span class="line">sonar.web.port=80</span><br><span class="line">sonar.web.context=/sonarqube</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">bin/sonar.sh start</span><br><span class="line"></span><br><span class="line"><span class="comment"># 默认admin/admin</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="调整Web服务器"><a href="#调整Web服务器" class="headerlink" title="调整Web服务器"></a>调整Web服务器</h4><p>默认情况下，SonarQube配置为在任何具有简单Java JRE的计算机上运行。</p><p>为了更好地性能，生产环境实例要做的第一件事是使用Java JDK并通过在<code>sonar.web.javaOpts=-server</code>中设置以下行来激活服务器模式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sonar.web.javaOpts=-server</span><br></pre></td></tr></table></figure><p>要修改SonarQube使用的Java JVM只需编辑<code>$SONARQUBE-HOME/conf/wrapper.conf</code>并更新以下行:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wrapper.java.command=/path/to/my/jdk/bin/java</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h4><p>docs: <a href="https://docs.sonarqube.org/latest/setup/install-server/" target="_blank" rel="noopener">https://docs.sonarqube.org/latest/setup/install-server/</a></p><p><br><br><br><br><br></p><h2 id="配置和操作Server"><a href="#配置和操作Server" class="headerlink" title="配置和操作Server"></a>配置和操作Server</h2><p>Configure &amp; Operate the Server</p><p><br></p><h3 id="以SystemD运行"><a href="#以SystemD运行" class="headerlink" title="以SystemD运行"></a>以SystemD运行</h3><p>Running SonarQube as a Service on Linux with SystemD</p><p>假设如下信息:</p><ul><li>sonarqube用户</li><li>sonarqube组</li><li>java virtual machine安装在<code>/opt/java/</code></li><li>sonarqube解压在<code>/opt/sonarqube/</code></li></ul><p><br></p><p>创建<code>sonarqube</code>用户:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">useradd -M -s /sbin/nologin</span><br></pre></td></tr></table></figure><p><br></p><p>创建service文件<code>/etc/systemd/system/sonarqube.service</code>，具体详情请安装自己的实际情况进行修改。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=SonarQube service</span><br><span class="line">After=syslog.target network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">User=sonarqube</span><br><span class="line">Group=sonarqube</span><br><span class="line">PermissionsStartOnly=true</span><br><span class="line">ExecStart=/bin/nohup /opt/java/bin/java -Xms32m -Xmx32m -Djava.net.preferIPv4Stack=true -jar /opt/sonarqube/lib/sonar-application-7.6.jar</span><br><span class="line">StandardOutput=syslog</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">LimitNPROC=8192</span><br><span class="line">TimeoutStartSec=5</span><br><span class="line">Restart=always</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">sudo systemctl <span class="built_in">enable</span> sonarqube.service</span><br><span class="line">sudo systemctl start sonarqube.service</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="在代理服务器后保护Server"><a href="#在代理服务器后保护Server" class="headerlink" title="在代理服务器后保护Server"></a>在代理服务器后保护Server</h3><p>Securing the Server Behind a Proxy</p><p><br></p><h4 id="Server配置"><a href="#Server配置" class="headerlink" title="Server配置"></a>Server配置</h4><p>要通过HTTPS运行SonarQube Server，必须构建标准的反向代理服务器。<br>必须配置反向代理，在每个HTTP Request Header中设置<code>X_FORWARDED_PROTO: https</code>值。如果没有此属性，SonarQube Server启动的重定向将回退到HTTP。</p><p><br><br><br></p><h4 id="使用Apache代理"><a href="#使用Apache代理" class="headerlink" title="使用Apache代理"></a>使用Apache代理</h4><p>跳过！</p><p><br><br><br></p><h4 id="使用Nginx代理"><a href="#使用Nginx代理" class="headerlink" title="使用Nginx代理"></a>使用Nginx代理</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># the server directive is nginx&apos;s virtual host directive</span><br><span class="line">server &#123;</span><br><span class="line">  # port to listen on. Can also be set to an IP:PORT</span><br><span class="line">  listen 80;</span><br><span class="line"></span><br><span class="line">  # sets the domain[s] that this vhost server requests for</span><br><span class="line">  server_name www.somecompany.com;</span><br><span class="line"></span><br><span class="line">  location / &#123;</span><br><span class="line">    proxy_pass http://sonarhost:sonarport;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="使用IIS"><a href="#使用IIS" class="headerlink" title="使用IIS"></a>使用IIS</h4><p>跳过！</p><p><br><br><br><br><br></p><h2 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h2><p>在SonarQube中安装插件有两种选择:</p><ul><li><strong>Marketplace</strong>，从SonarQube UI自动地安装插件</li><li><strong>手动安装</strong>， 如果SonarQube实例无法访问Internet，请使用此方法</li></ul><p><br><br><br><br><br></p><h2 id="安装C-C-插件"><a href="#安装C-C-插件" class="headerlink" title="安装C/C++插件"></a>安装C/C++插件</h2><p>由于SonarQube的C, C++是商业版才有的功能，所以我使用的CE版就不支持对这两个语言的静态检查。</p><p>后来看到 <strong>SonarOpenCommunity</strong>: <a href="https://github.com/SonarOpenCommunity" target="_blank" rel="noopener">https://github.com/SonarOpenCommunity</a>，它里面有这个插件，先感谢开发者，然后再使用。</p><p>sonar-cxx: <a href="https://github.com/SonarOpenCommunity/sonar-cxx" target="_blank" rel="noopener">https://github.com/SonarOpenCommunity/sonar-cxx</a>，查看相关说明进行安装和配置。</p><p><br></p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><ul><li>明白哪个插件版本与当前使用的SonarQube版本监控</li><li>下载jar插件，将其放置于<code>$ SONARQUBE_HOME/extensions/plugins</code>目录下<ul><li><code>sonar-cxx-plugin-x.y.z.jar</code>: c++ plug-in</li><li><code>sonar-c-plugin-x.y.z.jar</code>: c plug-in</li></ul></li><li>重启SonarQube Server</li><li>在UI上的Marketplace查看更新</li></ul><p><br><br><br><br><br></p><h2 id="安装PS-SQL插件"><a href="#安装PS-SQL插件" class="headerlink" title="安装PS/SQL插件"></a>安装PS/SQL插件</h2><p>由于SonarQube的PL, SQL是商业版才有的功能，所以我使用的CE版就不支持对这两个语言的静态检查。</p><p>后来看到: sonar-plsql: <a href="https://github.com/felipebz/sonar-plsql" target="_blank" rel="noopener">https://github.com/felipebz/sonar-plsql</a> 社区开源项目，先感谢开发者，再使用。</p><p>安装方法与上面的C/C++一样，下载当前版本支持的插件到对应目录，重启SonarQube Server。</p><p><br><br><br><br><br></p><h2 id="将Server安装为集群"><a href="#将Server安装为集群" class="headerlink" title="将Server安装为集群"></a>将Server安装为集群</h2><p>docs: <a href="https://docs.sonarqube.org/latest/setup/install-cluster/" target="_blank" rel="noopener">https://docs.sonarqube.org/latest/setup/install-cluster/</a></p><p>先跳过！</p><p><br><br><br><br><br></p><h2 id="配置和操作集群"><a href="#配置和操作集群" class="headerlink" title="配置和操作集群"></a>配置和操作集群</h2><p>Configure &amp; Operate a Cluster</p><p>docs: <a href="https://docs.sonarqube.org/latest/setup/operate-cluster/" target="_blank" rel="noopener">https://docs.sonarqube.org/latest/setup/operate-cluster/</a></p><p>先跳过！</p><p><br><br><br><br><br></p><h2 id="升级"><a href="#升级" class="headerlink" title="升级"></a>升级</h2><p>Upgrade the Server</p><p>自动处理<code>non-LTS</code>版本的升级。但是，如果在迁移路径中有LTS版本，则必须先迁移LTS，然后再迁移到目标版本。</p><p>例如，<code>v5.1</code> -&gt; <code>v7.0</code>，迁移路径为 <code>v5.1</code> -&gt; <code>5.6.7 LTS</code> -&gt; <code>v6.7.x LTS</code> -&gt; <code>v7.0</code>。</p><p><br></p><h3 id="如何升级"><a href="#如何升级" class="headerlink" title="如何升级"></a>如何升级</h3><p>在开始之前，请备份SnarQube Database。升级问题虽然很少见，但备份确实必须的。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="分析源代码"><a href="#分析源代码" class="headerlink" title="分析源代码"></a>分析源代码</h1><p>Analyzing Source Code</p><p><br></p><h2 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h2><p>一旦安装了SonarQube平台，你就可以安装分析器(analyzer)并开始创建项目了。为此，你必须安装和配置适合你需求的扫描器(scanner)。<br>Do you build with:</p><ul><li><strong>Gradle</strong> - <a href="https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner+for+Gradle" target="_blank" rel="noopener">SonarScanner for Gradle</a></li><li><strong>MSBuild</strong> - <a href="https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner+for+MSBuild" target="_blank" rel="noopener">SonarScanner for MSBuild</a></li><li><strong>Maven</strong> - <a href="https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner+for+Maven" target="_blank" rel="noopener">use the SonarScanner for Maven</a></li><li><strong>Jenkins</strong> - <a href="https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner+for+Jenkins" target="_blank" rel="noopener">SonarScanner for Jenkins</a></li><li><strong>Azure DevOps</strong> - <a href="https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Extension+for+VSTS-TFS" target="_blank" rel="noopener">SonarQube Extension for Azure DevOps</a></li><li><strong>Ant</strong> - <a href="https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner+for+Ant" target="_blank" rel="noopener">SonarScanner for Ant</a></li><li><strong>anything else (CLI)</strong> - <a href="https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner" target="_blank" rel="noopener">SonarScanner</a></li></ul><p><strong>注意</strong>，不建议在运行SonarQube Scanner Analysis的机器上运行反病毒扫描程序，这可能会导致不可预测的行为。</p><p><br></p><h3 id="分析产生了什么"><a href="#分析产生了什么" class="headerlink" title="分析产生了什么"></a>分析产生了什么</h3><p>What does analysis produce?</p><p>SonarQube可以对20多种不同的语言进行分析。该分析的结果是 quality measures 和 issues。但是，分析的结果也会因语言而异:</p><ul><li>在所有语言中，<strong>blame</strong>数据将自动从支持的SCM提供程序导入(自动支持Git和SVN)。其它提供需要额外的插件</li><li>在所有语言中，执行源代码的静态分析</li><li>可对某些语言执行编译代码的静态分析</li><li>可对某些语言执行代码的动态分析</li></ul><p><br><br><br></p><h3 id="是否会分析所有文件"><a href="#是否会分析所有文件" class="headerlink" title="是否会分析所有文件"></a>是否会分析所有文件</h3><p>Will all files be analyzed?</p><p>默认情况下，在分析期间，只有语言分析器(language analyzer)可识别的文件才会加载到项目中。</p><p><br><br><br></p><h3 id="分析期间会发生什么"><a href="#分析期间会发生什么" class="headerlink" title="分析期间会发生什么"></a>分析期间会发生什么</h3><p>What happens during analysis?</p><p>在分析期间，从Server请求数据，分析提供给分析的文件，并以报告的形式将结果返回到Server，然后在Server-Side异步分析。</p><p>分析上报排队并按顺序处理，因此很可能在分析日志显示完成后的短暂时间内，更新的值在SonarQube项目中不可见。但是，你能够分辨出正在发生的事情，因为项目名称右侧的项目主页上会有一个图标。</p><p><img src="/images/SonarQube/backgroundTaskProcessingInProgress.jpeg" alt=""></p><p><img src="/images/SonarQube/backgroundTaskProcessingFailedIcon.jpeg" alt=""></p><p><br><br><br><br><br></p><h2 id="分析参数"><a href="#分析参数" class="headerlink" title="分析参数"></a>分析参数</h2><p>Analysis Parameters</p><p>可以在多个位置设置用于配置项目分析的参数。这是参数的层次结构：</p><ul><li>在UI里定义的<strong>全局分析参数(Global)</strong>，<code>Administration &gt; Configuration &gt; General Settings</code></li><li>在UI里定义的<strong>项目分析参数(Project)</strong>，<code>Project Level &gt; Administration &gt; General Settings</code></li><li>在项目分析配置文件或分析器配置文件中定义的<strong>项目分析参数</strong></li><li><strong>分析/命令行参数</strong>，再启动分析时定义，覆盖项目分析参数</li></ul><p>注意，只有通过UI设置的参数才会存储在数据库中。</p><p><br></p><h3 id="强制参数"><a href="#强制参数" class="headerlink" title="强制参数"></a>强制参数</h3><p>Mandatory Parameters</p><p><br></p><ul><li><strong>Server</strong></li></ul><table><thead><tr><th>Key</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>sonar.host.url</code></td><td>the server URL</td><td><code>http://localhost:9000</code></td></tr></tbody></table><p><br></p><ul><li><strong>Project Configuration</strong></li></ul><table><thead><tr><th>Key</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>sonar.projectKey</code></td><td>The project’s unique key. Allowed characters are: letters, numbers, - , _ , . and : , with at least one non-digit.</td><td>For Maven projects, this is automatically set to <code>&lt;groupId&gt;:&lt;artifactId&gt;</code></td></tr><tr><td><code>sonar.sources</code></td><td>Comma-separated paths to directories containing source files.</td><td>Read from build system for Maven, Gradle, MSBuild projects</td></tr></tbody></table><p><br><br><br></p><h3 id="可选参数"><a href="#可选参数" class="headerlink" title="可选参数"></a>可选参数</h3><p>Optional Parameters</p><ul><li><strong>Project Identity</strong></li></ul><table><thead><tr><th>Key</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>sonar.projectName</code></td><td>显示在Web实例上的项目名称</td><td>Maven项目的<code>&lt;name&gt;</code>，否则为项目密钥。如果DB中已有名称，则不会覆盖该名称</td></tr><tr><td><code>sonar.projectVersion</code></td><td>项目版本</td><td>Maven项目的<code>&lt;version&gt;</code>，否则未提供</td></tr></tbody></table><p><br></p><ul><li><strong>Authentication</strong></li></ul><table><thead><tr><th>Key</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>sonar.login</code></td><td>具有项目执行分析权限的SonarQube用户的登录或身份验证Token</td><td>xxx</td></tr><tr><td><code>sonar.password</code></td><td>与<code>sonar.login</code>用户名一起使用的密码。如果正在使用身份验Token，则应将此项留空</td><td>xxx</td></tr></tbody></table><p><br></p><ul><li><strong>Web Services</strong></li></ul><table><thead><tr><th>Key</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>sonar.ws.timeout</code></td><td>等待Web服务调用响应的最长时间（秒）。只有在等待服务器响应Web服务调用时在分析期间遇到超时时，才能从默认值修改此值。</td><td>60</td></tr></tbody></table><p><br></p><ul><li><strong>Project Configuration</strong></li></ul><table><thead><tr><th>Key</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>sonar.projectDescription</code></td><td>项目描述。与Maven不兼容</td><td><code>&lt;description</code>用于Maven项目</td></tr><tr><td><code>sonar.links.homepage</code></td><td>项目主页，与Maven不兼容</td><td><code>&lt;url&gt;</code>用于Maven项目</td></tr><tr><td><code>sonar.links.ci</code></td><td>CI，与Maven不兼容</td><td><code>&lt;ciManagement&gt;&lt;url&gt;</code>用于Maven项目</td></tr><tr><td><code>sonar.links.issue</code></td><td>Issue tracker，与Maven不兼容</td><td><code>&lt;issueManagement&gt;&lt;url&gt;</code>用于Maven项目</td></tr><tr><td><code>sonar.links.scm</code></td><td>项目原仓库，与Maven不兼容</td><td><code>&lt;scm&gt;&lt;url&gt;</code>用于Maven项目</td></tr><tr><td><code>sonar.links.scm_dev</code></td><td>开发者连接，与Maven不兼容</td><td><code>&lt;scm&gt;&lt;developerConnection&gt;</code>用于Maven项目</td></tr><tr><td><code>sonar.tests</code></td><td>包含测试的目录的逗号分隔路径,与Maven不兼容</td><td>Maven项目的默认测试位置</td></tr><tr><td><code>sonar.sourceEncoding</code></td><td>源文件编码</td><td>系统编码</td></tr><tr><td><code>sonar.externalIssuesReportPaths</code></td><td>以逗号分隔的通用Issue上报路径列表</td></tr><tr><td><code>sonar.projectDate</code></td><td>为分析指定日期(yyyy-MM-dd)</td><td>当前日志</td></tr><tr><td><code>sonar.projectBaseDir</code></td><td>当您需要在除启动它之外的目录中进行分析时，请使用此属性</td><td>xxx</td></tr><tr><td><code>sonar.working.directory</code></td><td>设置使用SonarScanner或SonarScanner for Ant（版本大于2.0）触发的分析的工作目录</td><td><code>.sonar</code></td></tr><tr><td><code>sonar.scm.provider</code></td><td>此属性可用于明确告知SonarQube应使用哪个SCM插件来获取项目上的SCM数据</td><td>xxx</td></tr><tr><td><code>sonar.scm.forceReloadAll</code></td><td>默认情况下，仅检索已更改文件的blame信息。将此属性设置为true可加载所有文件的blame信息</td><td>xxx</td></tr><tr><td><code>sonar.coverage.jacoco.xmlReportPaths</code></td><td>导入以XML文件形式提供的JaCoCo代码覆盖率报告。此属性接受多个逗号分隔的条目。必须在分析之前生成JaCoCo XML报告</td><td><code>target/site/jacoco/jacoco.xml</code> <br> <code>build/reports/jacoco/test/jacocoTestReport.xml</code></td></tr></tbody></table><p><br></p><ul><li><strong>Duplications</strong></li></ul><table><thead><tr><th>Key</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>sonar.cpd.exclusions</code></td><td>要从复制检测中排除的以逗号分隔的文件路径模式列表</td><td>xxx</td></tr><tr><td><code>sonar.cpd.${language}.minimumtokens</code></td><td>xxx</td><td>100</td></tr><tr><td><code>sonar.cpd.${language}.minimumLines</code></td><td>如上</td><td>10</td></tr></tbody></table><p><br></p><ul><li><strong>Analysis Logging</strong></li></ul><table><thead><tr><th>Key</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>sonar.log.level</code></td><td>控制分析期间生成的日志级别</td><td>INFO</td></tr><tr><td><code>sonar.verbose</code></td><td>向客户端和服务器端分析日志添加更多详细信息</td><td>false</td></tr><tr><td><code>sonar.showProfiling</code></td><td>显示日志以查看分析仪花费时间的位置</td><td>false</td></tr><tr><td><code>sonar.scanner.dumpToFile</code></td><td>将指向文件的完整属性列表输出到扫描程序API，作为调试分析的方法</td><td>xxx</td></tr><tr><td><code>sonar.scanner.metadataFilePath</code></td><td>设置扫描程序写入report-task.txt文件的位置，该文件包含ceTaskId等</td><td><code>sonar.working.directory</code>的值</td></tr></tbody></table><p><br><br><br><br><br></p><h2 id="后台任务"><a href="#后台任务" class="headerlink" title="后台任务"></a>后台任务</h2><p>Background Tasks</p><p>一个后台任务可以是:</p><ul><li>导入一个分析报告</li><li>the computation of a Portfolio</li><li>导入或导出一个项目</li></ul><p><br></p><p>###　扫描程序完成分析后会发生什么</p><p>What happens after the scanner is done analyzing?</p><p>在相关后台任务完成之前，分析尚未完成。即使SonarScanner的日志显示执行完成，在完成后台任务之前，分析结果在SonarQube项目中将不可见。在SonarScanner外出分析代码后，分析结果(Sources, Issues, Metrics) - 分析报告 - 将发送到SonarQube Server，一共计算引擎进行最终处理。分析报告按顺序排队和处理。</p><p>在项目级别，当有待处理的分析报告等待消耗时，标题中的<strong>Pending（待处理）</strong>通知将在最近完成的分析的日期旁。</p><p>全局管理员可在<code>Administration &gt; Projects &gt; Background Tasks</code>查看当前队列；项目管理员可在<code>Administration &gt; Background Tasks</code>查看相关任务。</p><p><br><br><br></p><h3 id="如何知道分析报告处理失败的时间"><a href="#如何知道分析报告处理失败的时间" class="headerlink" title="如何知道分析报告处理失败的时间"></a>如何知道分析报告处理失败的时间</h3><p>How do I know when analysis report processing fails?</p><p>后台任务通常会成功，但有时候异常会导致处理失败。例如:</p><ul><li>处理大项目是内存不足(OOM)</li><li>现有模块或项目的密钥与报告中的密钥冲突</li><li>…</li></ul><p>当发生这种情况时，失败的状态会反映在项目主页上，但这需要有人注意到它。你还可以选择在后台任务失败时通过电子邮件接收通知(Notifications)——无论是逐个还是全局。</p><p><br><br><br></p><h3 id="如何诊断失败的后台任务"><a href="#如何诊断失败的后台任务" class="headerlink" title="如何诊断失败的后台任务"></a>如何诊断失败的后台任务</h3><p>How do I diagnose a failing background task?</p><p>对于没法分析报告，都有一个下拉菜单，允许你访问<strong>扫描程序上下文(Scanner Context)</strong>，显示代码扫描是扫描程序的配置。<br>如果任务处理失败，则可使用其它选项<strong>显示错误详细信息(Show Error Details)</strong>，以获取处理后台任务失败的详情。</p><p><br><br><br></p><h3 id="如何取消待处理的分析报告"><a href="#如何取消待处理的分析报告" class="headerlink" title="如何取消待处理的分析报告"></a>如何取消待处理的分析报告</h3><p>How do I cancel a pending analysis report?</p><p>管理员可通过单击取消处理待处理任务(pending task)，一旦报告开始处理，取消它就为时已晚。</p><p><br><br><br><br><br></p><h2 id="通用问题数据"><a href="#通用问题数据" class="headerlink" title="通用问题数据"></a>通用问题数据</h2><p>Generic Issue Data</p><p>SonarQube支持通用导入格式，用于在代码中引发<em>external</em> issues。它旨在允许你从你喜欢的<em>linter</em>导入issues，即使它不存在插件。</p><p>外部问题受到两个重要限制:</p><ul><li>它们无法在SonarQube内管理</li><li>在SonarQube中无法管理引发这些问题的规则的激活</li></ul><p><br></p><h3 id="Import"><a href="#Import" class="headerlink" title="Import"></a>Import</h3><p>分析参数<code>sonar.externalIssueReportPaths</code>接受以逗号分隔的报告路径列表。<br>每个报告必须在顶层(top-level)包含一个名为issues对象的问题对象数组。</p><p><strong>Issue字段:</strong></p><ul><li><code>engineId</code> - string</li><li><code>ruleId</code> - string</li><li><code>primaryLocation</code> - Location object</li><li><code>type</code> - string. One of BUG, VULNERABILITY, CODE_SMELL</li><li><code>severity</code> - string. One of BLOCKER, CRITICAL, MAJOR, MINOR, INFO</li><li><code>effortMinutes</code> - integer, optional. Defaults to 0</li><li><code>secondaryLocations</code> - array of Location objects, optional</li></ul><p><br></p><p><strong>Location字段:</strong></p><ul><li><code>message</code> - string</li><li><code>filePath</code> - string</li><li><code>textRange</code> - TextRange object, optional for secondary locations only</li></ul><p><br></p><p><strong>TextRange字段:</strong></p><ul><li><code>startLine</code> - integer. 1-indexed</li><li><code>endLine</code> - integer, optional. 1-indexed</li><li><code>startColumn</code> - integer, optional. 0-indexed</li><li><code>endColumn</code> - integer, optional. 0-indexed</li></ul><p><br><br><br></p><h3 id="栗子"><a href="#栗子" class="headerlink" title="栗子"></a>栗子</h3><p>以下是预期格式的栗子:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">&#123; &quot;issues&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;engineId&quot;: &quot;test&quot;,</span><br><span class="line">      &quot;ruleId&quot;: &quot;rule1&quot;,</span><br><span class="line">      &quot;severity&quot;:&quot;BLOCKER&quot;,</span><br><span class="line">      &quot;type&quot;:&quot;CODE_SMELL&quot;,</span><br><span class="line">      &quot;primaryLocation&quot;: &#123;</span><br><span class="line">        &quot;message&quot;: &quot;fully-fleshed issue&quot;,</span><br><span class="line">        &quot;filePath&quot;: &quot;sources/A.java&quot;,</span><br><span class="line">        &quot;textRange&quot;: &#123;</span><br><span class="line">          &quot;startLine&quot;: 30,</span><br><span class="line">          &quot;endLine&quot;: 30,</span><br><span class="line">          &quot;startColumn&quot;: 9,</span><br><span class="line">          &quot;endColumn&quot;: 14</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;effortMinutes&quot;: 90,</span><br><span class="line">      &quot;secondaryLocations&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;message&quot;: &quot;cross-file 2ndary location&quot;,</span><br><span class="line">          &quot;filePath&quot;: &quot;sources/B.java&quot;,</span><br><span class="line">          &quot;textRange&quot;: &#123;</span><br><span class="line">            &quot;startLine&quot;: 10,</span><br><span class="line">            &quot;endLine&quot;: 10,</span><br><span class="line">            &quot;startColumn&quot;: 6,</span><br><span class="line">            &quot;endColumn&quot;: 38</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;engineId&quot;: &quot;test&quot;,</span><br><span class="line">      &quot;ruleId&quot;: &quot;rule2&quot;,</span><br><span class="line">      &quot;severity&quot;: &quot;INFO&quot;,</span><br><span class="line">      &quot;type&quot;: &quot;BUG&quot;,</span><br><span class="line">      &quot;primaryLocation&quot;: &#123;</span><br><span class="line">        &quot;message&quot;: &quot;minimal issue raised at file level&quot;,</span><br><span class="line">        &quot;filePath&quot;: &quot;sources/Measure.java&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">]&#125;</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="通用测试数据"><a href="#通用测试数据" class="headerlink" title="通用测试数据"></a>通用测试数据</h2><p>Generic Test Data</p><p>开箱即用，SonarQube支持用于测试覆盖和测试执行导入的通用格式。如果你的语言不插件不支持你的Coverage引擎的本机输出格式，只需将它们转换为这些格式即可。</p><p><br></p><h3 id="Generic-Coverage"><a href="#Generic-Coverage" class="headerlink" title="Generic Coverage"></a>Generic Coverage</h3><p>报告路径应该以逗号分隔的列表传递给: <code>sonar.coverageReportPaths</code></p><p>支持的格式由<code>sonar-generic-coverage.xsd</code>进行描述:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:schema&gt;</span><br><span class="line">  &lt;xs:element name=&quot;coverage&quot;&gt;</span><br><span class="line">    &lt;xs:complexType&gt;</span><br><span class="line">      &lt;xs:sequence&gt;</span><br><span class="line">        &lt;xs:element name=&quot;file&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;&gt;</span><br><span class="line">          &lt;xs:complexType&gt;</span><br><span class="line">            &lt;xs:sequence&gt;</span><br><span class="line">              &lt;xs:element name=&quot;lineToCover&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;&gt;</span><br><span class="line">                &lt;xs:complexType&gt;</span><br><span class="line">                  &lt;xs:attribute name=&quot;lineNumber&quot; type=&quot;xs:positiveInteger&quot; use=&quot;required&quot;/&gt;</span><br><span class="line">                  &lt;xs:attribute name=&quot;covered&quot; type=&quot;xs:boolean&quot; use=&quot;required&quot;/&gt;</span><br><span class="line">                  &lt;xs:attribute name=&quot;branchesToCover&quot; type=&quot;xs:nonNegativeInteger&quot;/&gt;</span><br><span class="line">                  &lt;xs:attribute name=&quot;coveredBranches&quot; type=&quot;xs:nonNegativeInteger&quot;/&gt;</span><br><span class="line">                &lt;/xs:complexType&gt;</span><br><span class="line">              &lt;/xs:element&gt;</span><br><span class="line">            &lt;/xs:sequence&gt;</span><br><span class="line">          &lt;xs:attribute name=&quot;path&quot; type=&quot;xs:string&quot; use=&quot;required&quot;/&gt;</span><br><span class="line">          &lt;/xs:complexType&gt;</span><br><span class="line">        &lt;/xs:element&gt;</span><br><span class="line">      &lt;/xs:sequence&gt;</span><br><span class="line">      &lt;xs:attribute name=&quot;version&quot; type=&quot;xs:positiveInteger&quot; use=&quot;required&quot;/&gt;</span><br><span class="line">    &lt;/xs:complexType&gt;</span><br><span class="line">  &lt;/xs:element&gt;</span><br><span class="line">&lt;/xs:schema&gt;</span><br></pre></td></tr></table></figure><p>看起来像这样:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;coverage version=&quot;1&quot;&gt;</span><br><span class="line">  &lt;file path=&quot;xources/hello/NoConditions.xoo&quot;&gt;</span><br><span class="line">    &lt;lineToCover lineNumber=&quot;6&quot; covered=&quot;true&quot;/&gt;</span><br><span class="line">    &lt;lineToCover lineNumber=&quot;7&quot; covered=&quot;false&quot;/&gt;</span><br><span class="line">  &lt;/file&gt;</span><br><span class="line">  &lt;file path=&quot;xources/hello/WithConditions.xoo&quot;&gt;</span><br><span class="line">    &lt;lineToCover lineNumber=&quot;3&quot; covered=&quot;true&quot; branchesToCover=&quot;2&quot; coveredBranches=&quot;1&quot;/&gt;</span><br><span class="line">  &lt;/file&gt;</span><br><span class="line">&lt;/coverage&gt;</span><br></pre></td></tr></table></figure><p>根节点应该命名为<code>coverage</code>，其<code>version</code>属性应设置为1。</p><p>为每个文件插入一个可由测试覆盖的文件元素。其<code>path</code>属性可以是绝对的，也可是相对的。它具有以下属性:</p><ul><li><code>lineNumber</code>(强制性)</li><li><code>covered</code>(强制性) - 布尔值，指示测试是否实际命中改行</li><li><code>branchesToCover</code>(可选) - 可覆盖的分支数量</li><li><code>coveredBranches</code>(可选) - 实际有测试覆盖的分支数量</li></ul><p><br><br><br></p><h3 id="Generic-Execution"><a href="#Generic-Execution" class="headerlink" title="Generic Execution"></a>Generic Execution</h3><p>报告路径应以逗号分隔的列表传递给: <code>sonar.testExecutionReportPaths</code></p><p>支持的格式如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;testExecutions version=&quot;1&quot;&gt;</span><br><span class="line">  &lt;file path=&quot;testx/ClassOneTest.xoo&quot;&gt;</span><br><span class="line">    &lt;testCase name=&quot;test1&quot; duration=&quot;5&quot;/&gt;</span><br><span class="line">    &lt;testCase name=&quot;test2&quot; duration=&quot;500&quot;&gt;</span><br><span class="line">      &lt;skipped message=&quot;short message&quot;&gt;other&lt;/skipped&gt;</span><br><span class="line">    &lt;/testCase&gt;</span><br><span class="line">    &lt;testCase name=&quot;test3&quot; duration=&quot;100&quot;&gt;</span><br><span class="line">      &lt;failure message=&quot;short&quot;&gt;stacktrace&lt;/failure&gt;</span><br><span class="line">    &lt;/testCase&gt;</span><br><span class="line">    &lt;testCase name=&quot;test4&quot; duration=&quot;500&quot;&gt;</span><br><span class="line">      &lt;error message=&quot;short&quot;&gt;stacktrace&lt;/error&gt;</span><br><span class="line">    &lt;/testCase&gt;</span><br><span class="line">  &lt;/file&gt;</span><br><span class="line">&lt;/testExecutions&gt;</span><br></pre></td></tr></table></figure><p>根节点应该被命名为<code>testExecutions</code>，它的<code>version</code>属性应该被设置成1。<br>为每个测试文件插入一个文件元素，其<code>path</code>属性可以是绝对的，也可是相对于模块的根。</p><p>注意，与覆盖率报告不同，报告中的文件必须是测试文件名，而不是测试所涵盖的源代码文件。</p><p>在<code>file</code>元素内，通过单元测试为每个测试运行插入一个<code>testCase</code>。它具有以下属性/子项:</p><ul><li><code>testCase</code>（强制性）<ul><li><code>name</code>（强制性）: 测试事例的名称</li><li><code>duration</code>(强制性): long value，ms为单位</li><li><code>failure|error|skipped</code>(可选): 如果测试不正确，请使用消息和长描述报告原因</li><li><code>message</code>(强制): 描述原因的短消息</li><li><code>stacktrace</code>（可选）: 包含有关失败、错误、跳过状态的详细信息</li></ul></li></ul><p><br><br><br><br><br></p><h2 id="PR分析"><a href="#PR分析" class="headerlink" title="PR分析"></a>PR分析</h2><p>Pull Request Analysis</p><p>PR分析是作为Developer Edtion的一部分提供。它允许你:</p><ul><li>在SonarQube UI中查看你的PR分析结果并查看状态以显示存在未解决的问题</li><li>在你的SCM提供商界面中使用SonarQube issue自动装饰你的PR</li></ul><p>从项目的<strong>branch and pull request</strong>的下拉菜单中可以在SonarQube中看到PR。启用PR装饰后，SonarQube会在PR上发布分析状态。</p><p><br><br><br><br><br></p><h2 id="SCM集成"><a href="#SCM集成" class="headerlink" title="SCM集成"></a>SCM集成</h2><p>在代码分期期间收集SCM数据可以解锁许多SonarQube功能:</p><ul><li>自动Issue分配</li><li>代码查看器中查看代码注释</li><li>SCM-driver的新代码检测，没有SCM数据，SonarQube使用分析日期确定新代码</li></ul><p>SCM集成需要你的SCM提供商，默认情况下支持SVN和Git。其它提供商，请参阅Marketplace。<br>如果需要，你可以通过管理设置将其在全局/项目级别将其关闭。</p><p><br></p><h3 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h3><p><br><br><br></p><h3 id="SVN"><a href="#SVN" class="headerlink" title="SVN"></a>SVN</h3><p><br><br><br></p><hr><p><br><br><br></p><h1 id="Branches"><a href="#Branches" class="headerlink" title="Branches"></a>Branches</h1><p>分支分析作为Developer Editon的一部分提供。分支分析允许你:</p><ul><li>分析 long-lived branches</li><li>分析 short-lived branches</li><li>在短期分支的状态受到影响时通知外部系统</li></ul><p><br></p><p>由于分支功能是开发版(也就是付费版)功能，因此社区版只能对每个分支创建一个项目。</p><p>例如:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">repo: zhang-repo</span><br><span class="line"></span><br><span class="line">branch:</span><br><span class="line">  - master</span><br><span class="line">  - test</span><br><span class="line">  - zhang</span><br><span class="line"></span><br><span class="line">projects:</span><br><span class="line">  - zhang-repo-master</span><br><span class="line">  - zhang-repo-test</span><br><span class="line">  - zhang-repo-zhang</span><br></pre></td></tr></table></figure><p><br><br><br></p><hr><p><br><br><br></p><h1 id="用户指南"><a href="#用户指南" class="headerlink" title="用户指南"></a>用户指南</h1><p>User Guide</p><p><br></p><h2 id="修复漏水"><a href="#修复漏水" class="headerlink" title="修复漏水"></a>修复漏水</h2><p>Fixing the Water Leak</p><p><br></p><h3 id="什么是漏水"><a href="#什么是漏水" class="headerlink" title="什么是漏水"></a>什么是漏水</h3><p>What is the Water Leak</p><p>想象一下，有一天你回到家发现厨房地板上有一滩水，水慢慢变大。<br>你想去拿拖把？还是找到漏水源头并修复它？选择很明显，你得修复它。</p><p>那么为什么与代码质量(code quality)有什么不同呢？当你使用SonarQube分析应用程序并意识到它有很多技术债务(technical debt)，这种下意识的反应通常是开始修复-这样那样，要么整理一个补救计划。这就像每天拖地一次而却忽略了漏水源头一样。</p><p><br></p><p>通常在这种传统方法中，在发布版本之前，定期进行代码质量(code quality)审计结果是开发人员在发布之前应该采取的行动。这种方法可能在短期内有效，特别是在强有力的管理支持下，但在中长期内始终失败，因为:</p><ul><li>代码审查(code review)过程太迟，没有利益相关者热衷于解决问题，每个人都希望新版本发布</li><li>开发者通常会推迟不了解项目上下文的外部团队提出的建议。顺便提一下，正在审查的代码已经过时了</li><li>使用这种方法明显缺乏对代码质量的所有权。谁拥有质量审查权限？没有人</li><li>在整个应用程序投入生产之前，需要检查整个应用程序，显然不可能对所有应用程序使用相同的标准。每个项目都会进行谈判，这将耗尽整个过程的可信度</li></ul><p><br></p><p>相反，为什么不将你在家中使用的相同的简单逻辑应用于管理代码质量的方式？修复泄露(leak)意味着将重点放在<strong>新代码</strong>上，即自上次发布以来添加或更改的代码。然后事情就变得很容易了:</p><ul><li>Quality Gate可以每天运行，并且可通过它。发版时没有任何意外</li><li>开发人员很难回避他们前一天介绍的问题。相反，他们通常很乐意在代码仍然新鲜时修复问题</li><li>代码质量有明确的所有权</li><li>做不做的标准在不同的应用程序中是一致的，并且在团队之间共享</li><li>成本微不足道，因为它是开发过程中的一部分</li></ul><p>最为奖励，变化最大的代码具有最高的可维护性，并且未变更的代码具有最低的维护性，这很有意义。</p><p><br><br><br></p><h3 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h3><p>SonarQube提供两种主要工具来帮助你找到泄漏点:</p><ul><li>新代码指标(metrics)显示当前代码与你在其历史记录(<code>previous_version</code>)中选择的特定点之间的度量差异</li><li>新代码主要基于SCM blame 数据监测，从新代码期(泄漏期)的第一次分析开始，需要时使用回退机制</li><li>Quality Gates允许你设置测量代码的布尔阈值。将它们与差异指标一起使用，可确保你的代码质量随着时间的推移在正确的方向上行驶</li></ul><p><br><br><br><br><br></p><h2 id="项目页"><a href="#项目页" class="headerlink" title="项目页"></a>项目页</h2><p>Project Page</p><p>项目主页(Project Homepage)是任何项目的切入点，它显示:</p><ul><li>the releasability status of the project</li><li>the current state of its quality</li><li>the quality of what has been produced since the beginning of its New Code Period</li></ul><p>项目页面回答了两个问题:</p><ul><li>can I release my project today?</li><li>if not, what should I improve to make the project pass the Quality Gate?</li></ul><p><br></p><h3 id="今天能发版吗"><a href="#今天能发版吗" class="headerlink" title="今天能发版吗"></a>今天能发版吗</h3><p>Can I release today?</p><p>由于 Quality Gate 是你执行质量策略的最强大的工具，因此该页面以项目的当前质量门状态开始。如果项目通过，则会显示一个简单的绿色全清除。</p><p>如果没有，可立即获得详细信息和drill-downs，以便快速识别出错的地方，每个错误条件的一个部分显示当前项目值是什么以及它应该是什么。像往常一样，你可以点击当前值来进行深入分析。</p><p><br><br><br></p><h3 id="应该优先解决什么"><a href="#应该优先解决什么" class="headerlink" title="应该优先解决什么"></a>应该优先解决什么</h3><p>What should I fix first?</p><p>因为提高项目质量的最佳方法是在问题变得根深蒂固之前捕获并修复新问题，项目的第一个视图以新代码周期为中心，在项目主页右侧以黄色突出显示。项目空间页面显示关键指标的高级摘要，包括当前值和新代码周期值。</p><p>在Quality Gate信息的下方，可以获得可靠性和安全域中的旧问题和新问题的数量。然后是可维护性域。单击页面上的任何图形将转到“详细信息”页面或“问题”页面中的详细视图。</p><p>开发人员必须做的最重要的事情是确保屏幕黄色部分的新问题得到确认，审核和修复，并确保测试涵盖新代码以防止将来出现回归。无论过去引入了多少问题，或者总体上测试覆盖范围有多少，关注新增问题将确保情况不会降低您之前在生产中发布的版本。</p><p>那么，您应该先找到哪些问题：错误，漏洞或代码异味？这取决于，因为答案取决于您的问题的性质。假设你有一个重复5次的代码块问题，在这个重复的代码块中，你有3个Bug和5个安全问题。最好的方法可能是首先修复重复，然后解决新集中位置的错误和漏洞，而不是修复它们5次。<br>这就是为什么您需要在开始解决之前检查新问题。</p><p><br><br><br><br><br></p><h2 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h2><p>Applications are available as part of the Enterprise Edition.</p><p><br><br><br><br><br></p><h2 id="Portfolios"><a href="#Portfolios" class="headerlink" title="Portfolios"></a>Portfolios</h2><p>Portfolios are available as part of the Enterprise Edition.</p><p><br><br><br><br><br></p><h2 id="Issues"><a href="#Issues" class="headerlink" title="Issues"></a>Issues</h2><p>在运行分析时，每当一段代码破坏编码规则时，SonarQube就会引发一个issue。编码规则(coding rules)是通过每种语言的相关质量配置文件定义的。</p><p>每个问题有五种严重程度:</p><ul><li><strong>BLOCKER</strong> - 很有可能影响生产中应用程序行为的错误。必须立即修复</li><li><strong>CRITICAL</strong> - 要么是在生产环境中影响应用程序行为可能性很小的bug，要么是代表安全漏洞的问题。必须立即检查代码</li><li><strong>MAJOR</strong> - 可能严重影响开发人员生产力的质量缺陷</li><li><strong>MINOR</strong> - 会轻微影响开发人员生产力产生的质量缺陷</li><li><strong>INFO</strong> - 既不是错误，也不是质量缺陷，只是一个提示</li></ul><p><br></p><h3 id="理解issue上下文"><a href="#理解issue上下文" class="headerlink" title="理解issue上下文"></a>理解issue上下文</h3><p>Understanding issue context</p><p>有时，一旦指出问题，问题就不言而喻了。例如，你的团队已约定了变量命名规则，在某个变量名出线问题时，你不需要理解大量上下文来理解该问题。但在其它情况下，上下文可能对理解为什么会出现这个问题至关重要。这就是为什么SonarQube不仅支持显示问题消息的主要问题位置，还支持次要问题位置。</p><p>但有时候，贡献位置地点并不足以理解问题。例如，当通过代码在某些路径上取消引用空指针时，您真正需要的是问题流。每个流程都是一组辅助位置，用于显示可能发生问题的代码的确切路径。</p><p><br><br><br></p><h3 id="生命周期"><a href="#生命周期" class="headerlink" title="生命周期"></a>生命周期</h3><p>Lifecycle of Code Smell, Bug, and Vulnerability Issues</p><p><br></p><h4 id="状态"><a href="#状态" class="headerlink" title="状态"></a>状态</h4><p>Status</p><p>创建之后，Issue会在生命周期中流动，可能为以下五种状态之一:</p><ul><li><strong>打开(Open)</strong> - 由SonarQube在新问题上设定</li><li><strong>确认(Confirmed)</strong> - 手动确认以指示问题有效</li><li><strong>解决(Resolved)</strong> - 手动设置以指示下一个分析应该关闭改问题</li><li><strong>重开(Reopened)</strong> - 当一个已解决的问题实际上没有得到纠正时，SonarQube会自动设置</li><li><strong>关闭(Closed)</strong> - 有SonarQube自动设置自动创建的问题</li></ul><p><br><br><br></p><h4 id="处理方式"><a href="#处理方式" class="headerlink" title="处理方式"></a>处理方式</h4><p>Resolutions</p><p>已关闭的问题将有一下两种方式之一:</p><ul><li><strong>已修复(Fixed)</strong> - 当后续分析显示问题已更正或文件不再可用时自动设置</li><li><strong>已移除(Removed)</strong> - 当相关规则不再可用时自动设置。改规则可能无法使用，因为它已从质量配置文件中删除，或者因为已卸载基础插件</li></ul><p>Resolved issues好友两个处理方式:</p><ul><li><strong>误判(False Positive)</strong> - 手动设置</li><li><strong>不会修复(Won’t Fix)</strong> - 不会修复</li></ul><p><br><br><br></p><h4 id="问题工作流程"><a href="#问题工作流程" class="headerlink" title="问题工作流程"></a>问题工作流程</h4><p>Issue Workflow</p><p>在以下情况下，问题会自动关闭(Status: Closed):</p><ul><li>问题以正确修复（Resolution: Fixed）</li><li>问题不再存在，因为相关编码规则已停用或不再可用(Resolution: Removed)</li></ul><p>在以下情况下，问题会自动重新打开(Status: Reopened):</p><ul><li>手动修改解决方式为已修复(但是不是误判)的问题，有后续分析显示仍然存在</li></ul><p><br><br><br></p><h3 id="安全热点问题的生命周期"><a href="#安全热点问题的生命周期" class="headerlink" title="安全热点问题的生命周期"></a>安全热点问题的生命周期</h3><p>Lifecycle of Security Hotspot Issues</p><p>安全热点问题具有专用的生命周期。它们不被视为可操作，必须由具有相关权限的用户进行审核。</p><p>创建之后，安全热点问题将流经专用的生命周期，可能是以下四种状态之一:</p><ul><li><strong>Open</strong> - 由SonarQube在新问题上自动设置</li><li><strong>Resolved</strong>(Won’t Fix) - 当安全审核员接受开发人员针对手动漏洞所做的修复或安全审核员清楚打开的热点或手动漏洞时，SonarQube会自动设置</li><li><strong>To Revied</strong> - 当开发人员请求安全审核员查看他对手动漏洞所做的修复时自动设置</li><li><strong>Reopened</strong> - 当开发人员解除打开的手动漏洞或安全审计员手动重新打开问题以便对已解决的问题运行新审计时设置</li></ul><p>如果删除了包含安全热点的代码，则只会关闭安全热点问题。如果从项目的质量配置文件中删除了标识热点的规则，则安全热点也可能会被删除。</p><p><br><br><br></p><h3 id="理解哪些问题是新的"><a href="#理解哪些问题是新的" class="headerlink" title="理解哪些问题是新的"></a>理解哪些问题是新的</h3><p>Understanding which Issues are “New”</p><p>为了确定问题的创建日期，在每次分析期间执行算法已确定问题是新的还是之前存在的。此算法依赖于报告问题的行的内容的哈希值(不包括空格)。对于多行问题，使用第一行的哈希值。对于每个文件(在检测到文件重命名后)，算法将从先前的分析中获取问题的基本列表，并尝试将这些问题与新分析报告的原始问题列表进行匹配。该算法尝试使用最强的证据进行首次匹配，然后再回到较弱的启发式算法。</p><ul><li>如果问题是在同一规则上，具有相同的行号和相同的行哈希 - 匹配</li><li>检测到块在文件内移动，然后如果问题出在同一行(移动的)和同一条规则上- 匹配</li><li>在相同的规则上，使用相同的消息并使用相同的行哈希 - 匹配</li><li>在相同的规则上，使用相同的消息并使用相同的行号 - 匹配</li><li>在相同的规则上，使用相同的行哈希 - 匹配</li><li>是否有匹配CLOSED的问题 - 匹配和重新打开</li></ul><p><br><br><br></p><h3 id="了解问题回溯"><a href="#了解问题回溯" class="headerlink" title="了解问题回溯"></a>了解问题回溯</h3><p>Understanding Issue Backdating</p><p>一旦问题被确定为新，下一个问题便是提供它的日期。例如，如果它已经在代码中存在了很长时间，但只能在最近的分析中找到，因为新的规则被添加到配置文件中？该问题是否应该在其行的最后一次更改日期或首次提出的分析日期之间给出？那就是它应该回溯吗？</p><p>如果最后一次更改改行的日期可用，那么在某些情况下，该问题将被回溯:</p><ul><li>首先分析项目或分支</li><li>当配置文件中的规则为新时</li><li>当分析程序升级后</li><li>当规则是外部的</li></ul><p>因此，回溯可能会使新提出的问题原理New Code Period。</p><p><br><br><br></p><h3 id="自动问题分配"><a href="#自动问题分配" class="headerlink" title="自动问题分配"></a>自动问题分配</h3><p>Automatic Issue Assignment</p><ul><li>For Bug, Vulnerability and Code Smell</li><li>For Security Hotspot</li><li>User Correlation</li><li>Known Limitation</li></ul><p><br><br><br></p><h3 id="问题编辑"><a href="#问题编辑" class="headerlink" title="问题编辑"></a>问题编辑</h3><p>Issue edits</p><p>SonarQube的问题工作流程可帮助你管理问题。你可对一个Issue做七件不同事情，这些行为可分为三类:</p><ul><li>Technical Review<ul><li>Confirm</li><li>False Positive</li><li>Won’t Fix</li><li>Severity change</li><li>Resolve</li></ul></li><li>Security Hotspots<ul><li>Detect</li><li>Clear</li><li>Request Review</li><li>Reject</li></ul></li><li>Dispositioning</li><li>General<ul><li>Comments</li><li>Tag</li></ul></li><li>Bulk Change</li></ul><p><br><br><br></p><h3 id="清除已解决的问题"><a href="#清除已解决的问题" class="headerlink" title="清除已解决的问题"></a>清除已解决的问题</h3><p>Purging Closed Issues</p><p>默认情况下，已关闭的问题将保留30天。当然，你也可以修改它。</p><p><br><br><br><br><br></p><h2 id="Rules"><a href="#Rules" class="headerlink" title="Rules"></a>Rules</h2><p>SonarSource Rules: <a href="https://rules.sonarsource.com/" target="_blank" rel="noopener">https://rules.sonarsource.com/</a></p><p><br></p><h3 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h3><p>在SonarQube中，分析程序提供在源代码上执行的规则来生成问题。有四种类型的规则:</p><ul><li>Code Smell (Maintainability domain)</li><li>Bug (Reliability domain)</li><li>Vulnerability (Security domain)</li><li>Security Hotspot (Security domain)</li></ul><p><br><br><br></p><h3 id="规则"><a href="#规则" class="headerlink" title="规则"></a>规则</h3><p>默认情况下，点击带单栏<strong>Rules</strong>时，你将看到SonarQube实例上安装的分析程序带来的所有可用规则。你可根据以下条件缩小范围:</p><ul><li>Language</li><li>Type</li><li>Tag</li><li>Repository</li><li>Default Severity</li><li>Status</li><li>Available Since</li><li>Template: 显示允许创建自定义规则的规则模板</li><li>Quality Profile</li></ul><p><br><br><br></p><h3 id="规则细节"><a href="#规则细节" class="headerlink" title="规则细节"></a>规则细节</h3><p>要查看规则的详细信息，请点击它。除了基本规则数据之外，您还可以查看其中活动的配置文件（如果有）以及已经引发了多少未解决的问题。<br>只有拥有正确的权限时，才能使用以下两个操作:</p><ul><li>Add/Remove Tags</li><li>Extend Description</li></ul><p><br><br><br></p><h3 id="规则模板和自定义规则"><a href="#规则模板和自定义规则" class="headerlink" title="规则模板和自定义规则"></a>规则模板和自定义规则</h3><p>Rule Templates and Custom Rules</p><p>规则模板(Rule templates)由创建提供，允许用户在SonarQube中定义自己的规则。它位于<code>Rules -&gt; Template</code>。</p><p>要从模板创建自定义规则，你必须填写一下信息:</p><ul><li>Name</li><li>Key (auto-suggested)</li><li>Description (Markdown format is supported)</li><li>Default Severity</li><li>Status</li><li>The parameters specified by the template</li></ul><p><br><br><br></p><h3 id="扩展编码规则"><a href="#扩展编码规则" class="headerlink" title="扩展编码规则"></a>扩展编码规则</h3><p>Extending Coding Rules</p><p>可以添加<a href="https://docs.sonarqube.org/display/DEV/Adding+Coding+Rules" target="_blank" rel="noopener">自定义编码规则</a>。</p><p><br><br><br></p><h3 id="规则类型和严重性"><a href="#规则类型和严重性" class="headerlink" title="规则类型和严重性"></a>规则类型和严重性</h3><p>Rule Types and Severities</p><p>Type:</p><ul><li>Bug</li><li>Vulnerability</li><li>Code Smell</li><li>Security Hotspot</li></ul><p>Severity:</p><ul><li>Blocker</li><li>Critical</li><li>Major</li><li>Minor</li><li>Info</li></ul><p><br><br><br></p><h2 id="安全相关的规则"><a href="#安全相关的规则" class="headerlink" title="安全相关的规则"></a>安全相关的规则</h2><p>Security-related Rules</p><p>SonarQube质量类型有三种不同的规则:</p><ul><li>Reliability (bug)</li><li>Vulnerability (security)</li><li>Maintainability (code smell)</li></ul><p>但另外一种方式，只有两种类型:</p><ul><li>security rule</li><li>其它</li></ul><p>两者之间的区别并不在它们捕获的内容，而在于她们来自何处以及强加于它们的标准。</p><p><br></p><h3 id="从安全相关的规则的期望是什么"><a href="#从安全相关的规则的期望是什么" class="headerlink" title="从安全相关的规则的期望是什么"></a>从安全相关的规则的期望是什么</h3><p>What to expect from security-related rules</p><p>需要明确的是，SonarQube语言插件中实现的大多数规则的标准是非常严格: 没有误报。对于正常规则，你应该能够确信任何报告给你的问题确实是一个问题。</p><p>但对于与安全相关的规则，情况略有不同。例如，许多安全指南讨论了应如何处理<em>敏感数据</em>。但是，由于规则中不可能确定哪些数据是敏感，哪些是不敏感。因此选择变为： 保持无误判标准并且不实施与安全相关的规则，或者实施与安全的规则不同的标准。</p><p>这就是为什么与安全相关的规则很广泛。官方的想法是，该规则将标记任何可疑的内容，并将其留给安全审核人员来剔除误报并发送真正的问题进行补救。</p><p>安全热点是一种特殊类型的问题，用于识别安全审核人员应审核的敏感区域，以确定它们是否真的是漏洞。有关热点和审计过程的详细信息，请参阅安全审核和报告。</p><p><br><br><br></p><h3 id="与安全相关的规则来自何方"><a href="#与安全相关的规则来自何方" class="headerlink" title="与安全相关的规则来自何方"></a>与安全相关的规则来自何方</h3><p>Where security-related rules come from</p><p>绝大多数与安全相关的规则源于既定标准:</p><ul><li><strong>CWE(Common Weakness Enumeration)</strong>：是美国MITRE机构提出的一套语言标准，用于描述软件安全弱点的通用化描述语言。每个CWE条目都包含了CWE标识符/弱点类型名称、类型的描述、弱点的行为、弱点的利用方法、利用弱点的可能性、可能导致的后果、应对措施、代码示例、对应的CVE漏洞数量、参考信息等内容。</li><li><strong>SANS Top 25</strong> - <a href="https://www.sans.org/top25-software-errors/" target="_blank" rel="noopener">CWE/SANS TOP 25 Most Dangerous Software Errors</a></li><li><strong>OWASP Top 10</strong> - <a href="https://www.owasp.org/index.php/Top_10-2017_Top_10" target="_blank" rel="noopener">OWASP Top 10 Application Security Risks</a></li></ul><p>要查找与任何这些标准相关的规则，你可以按标签或文本搜索规则。</p><p><br></p><h4 id="CWE"><a href="#CWE" class="headerlink" title="CWE"></a>CWE</h4><p>CWE标准代表Common Weakness Enumeration:</p><p>Common Weakness Enumeration (CWE™) 是一个常见软件弱点的正式列表或字典，可能出现在软件的体系结构、设计代码或实现中。可能导致可利用的安全漏洞。创建CWE是为了描述软件安全漏洞的通用语言，作为针对这些弱点的软件安全工具的衡量标准；并为弱点识别、缓解和预防工作提供共同的基线标准。<br>CWE是弱化的描述的层次结构。层次结构中的最低级别是弱点基础(Weakness Base)，它描述了细腻度的弱点。</p><p>符合特定要求的工具可以认证为CWE兼容。这些要求是:</p><ul><li>您必须能够使用CWE标识符搜索与CWE相关的规则。要在SonarQube平台中执行此操作，只需将CWE标识符（例如CWE-595）放在规则页面上的搜索文本输入中并运行搜索</li><li>规则必须与其相关的CWE项目准确链接。要查看SonarQube规则的CWE映射，请参阅规则说明底部的规则参见部分</li><li>您必须能够从问题中识别相关的CWE。要在SonarQube平台中执行此操作，请参阅相关规则</li><li>产品文档必须包含CWE和CWE兼容性的说明</li><li>除了通过CWE id搜索规则外，您还可以通过 cwe rule tag 进行搜索</li></ul><p><br><br><br></p><h4 id="SANS-TOP-25"><a href="#SANS-TOP-25" class="headerlink" title="SANS TOP 25"></a>SANS TOP 25</h4><p>SANS Top 25列表是由SANS组织编制的CWE中列出的25个最危险错误的集合。当前的SANS列表分为三类：</p><ul><li>Insecure Interaction Between Components</li><li>Risky Resource Management</li><li>Porous Defenses</li></ul><p>要查找与SANS Top 25相关的规则，您可以对类别或相关CWE项目执行文本搜索，或执行规则标记搜索。</p><p><br><br><br></p><h4 id="OWASP-Top-10"><a href="#OWASP-Top-10" class="headerlink" title="OWASP Top 10"></a>OWASP Top 10</h4><p>OWASP代表Open Web Application Security Project。它是:</p><p><code>501(c)(3)</code>全球非营利慈善组织，致力于提高软件的安全性。我们的使命是使软件安全可见，以便全世界的个人和组织能够就真正的软件安全风险做出明智的决策。</p><p>OWASP Top 10列出了各种各样的弱点，每个弱点都可以映射到许多单独的规则。<br>OWASP TOP 10在SonarQube中也对应相关的tag。</p><p>要查找与OWASP Top 10相关的规则，您可以对类别执行文本搜索，或执行规则标记搜索。</p><p><br><br><br><br><br></p><h2 id="內建规则和标签"><a href="#內建规则和标签" class="headerlink" title="內建规则和标签"></a>內建规则和标签</h2><p>Built-in Rule Tags</p><p>标签(tag) 是一种对问题(issue)和规则(rule)进行分类的方法。问题会继承引发它们的规则上的标记。有些标签适用于特定语言，但是更多的标签出现在各种语言中。用户可以为规则和问题添加标签。但大多数规则都有一些开箱即用的标签。<br>以下是一些非全面的、包含一些內建标签:</p><ul><li><code>brain-overload</code> - 一次有太多的东西要留在脑海里</li><li><code>bad-practice</code> - 代码可能按设计工作，但它的设计方式被广泛认为是一个坏主意</li><li><code>cert</code> - 设计CERT标准中的规则</li><li><code>clumsy</code> - 用于完成可以更清晰和简洁地完成的事情的额外步骤</li><li><code>confusing</code> - 将使维护者更长时间地理解，而不是代码实际所做的事情</li><li><code>convention</code> - 编码约定，如格式化、命名、空格…</li><li><code>cwe</code> - CWE安全规则</li><li><code>design</code> - 代码设计存在一些问题</li><li><code>lock-in</code> - 使用特定于环境的功能</li><li><code>misra</code> - MISRA标准相关的规则</li><li><code>owasp</code> - 与OWASP TOP 10安全标准相关的规则</li><li><code>pitfall</code> - 没有什么不对，但未来可能出现问题;已经为下一个人设置了一个陷阱，他可能会陷入其中并搞砸了代码</li><li><code>sans-top25</code> - 与SANS Top 25 Coding Errors安全相关</li><li><code>suspicious</code> - 它不能保证这是一个bug，但它看起来很可疑。至少，代码应该重新检查并且可能为了清晰而重构</li><li><code>unpredictable</code> - 代码可以在当前条件下正常工作，但如果条件发生变化可能会失败</li><li><code>unused</code> - 未使用的代码</li><li><code>user-experience</code> - 代码在技术上没有任何问题，但它可能会使您的部分或全部用户讨厌您</li></ul><p><br><br><br><br><br></p><h2 id="Quality-Gates"><a href="#Quality-Gates" class="headerlink" title="Quality Gates"></a>Quality Gates</h2><p><br></p><h3 id="概述-3"><a href="#概述-3" class="headerlink" title="概述"></a>概述</h3><p>质量阈(Quality Gates)是你在组织中实施质量策略的最佳方式。它可以回答一个问题: 我今天可以将项目发上线吗？<br>为了回答这个问题，你可以根据测量项目的度量阈值定义一组布尔条件，例如:</p><ul><li>No new blocker issues</li><li>Code coverage on new code greater than 80%</li><li>…</li></ul><p>理想状况下，所有项目都将通过同一质量阈进行验证。但这并不总是实用的。例如，你可能会发现:</p><ul><li>技术实现因应用程序而异</li><li>您希望确保对某些应用程序有更强的要求</li><li>…</li></ul><p>这就是为什么你可以根据需要自定义质量阈，它就在顶部的菜单栏上。</p><p><br><br><br></p><h3 id="最佳质量阈配置"><a href="#最佳质量阈配置" class="headerlink" title="最佳质量阈配置"></a>最佳质量阈配置</h3><p>Use the Best Quality Gate Configuration</p><p>质量阈默认激活并视为內建和只读的<code>Sonar war</code>方式，由SonarQube提供。它代表了我们对实施修复泄露。根据SonarQube的功能自动调整</p><p>有三个指标允许你强制执行给定的可靠性，安全性和可维护性的评级。不仅仅是整体而且还有新代码。建议使用这些指标，并将其作为默认质量阈的一部分，以便开发人员在项目页面上查看质量阈时更清楚的反馈。</p><p>不要忘记质量阈条件必须使用差值，检查绝对值是没有意义的(如: 代码行数大于1000)。</p><p><br></p><p><strong>推荐的质量阈(Recommended Quality Gate)</strong></p><p>內建的<code>Sonar way</code>质量阈都推荐用于大多数项目。如果专注于保持新代码清洁，而不是花费大量时间来修复旧代码。它开箱即用，已被设置为默认配置文件。</p><p><br><br><br></p><h3 id="质量阈状态"><a href="#质量阈状态" class="headerlink" title="质量阈状态"></a>质量阈状态</h3><p>Quality Gate Status</p><p><img src="/images/SonarQube/quality-gate-status.jpeg" alt=""></p><p><br><br><br></p><h3 id="当质量阈失败时获得通知"><a href="#当质量阈失败时获得通知" class="headerlink" title="当质量阈失败时获得通知"></a>当质量阈失败时获得通知</h3><p>Getting Notified When a Quality Gate Fails</p><p>使用通知机制，在质量阈失败时通知用户。为此，请订阅<strong>New quality gate status</strong>通知。</p><p><br><br><br></p><h3 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h3><p>Security</p><p>任何用户(甚至是匿名用户)都可以访问质量阈。<br>要就行更改(create, edit, delete)，必须授予用户管理质量阈的权限。<br>项目管理员可选择与他们项目相关的质量阈。</p><p><br><br><br></p><h3 id="定义质量阈"><a href="#定义质量阈" class="headerlink" title="定义质量阈"></a>定义质量阈</h3><p>Defining Quality Gates</p><p>要管理质量阈，请转到菜单栏的<strong>Quality Gates</strong>。</p><p>每个质量阈条件都是以下组合:</p><ul><li>测量(measure)</li><li>比较符(comparison operator)</li><li>错误值(error value)</li></ul><p>栗子，条件可能是:</p><ul><li>measure: <code>Blocker issue</code></li><li>comparison operator: <code>&gt;</code></li><li>error value: <code>0</code></li></ul><p><br><br><br><br><br></p><h2 id="指标"><a href="#指标" class="headerlink" title="指标"></a>指标</h2><p>Metric Definitions</p><p>项目有如下指标:</p><ul><li>复杂度(Complexity)</li><li>重复(Duplications)</li><li>问题(Issues)</li><li>可维护性(Maintainability)</li><li>质量阈(Quality Gates)</li><li>可靠性(Reliability)</li><li>安全性(Security)</li><li>大小(Size)</li><li>测试(Tests)</li></ul><p><br></p><h3 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h3><p>应用的控制流是简单还是复杂。</p><p><br></p><h4 id="圈复杂度"><a href="#圈复杂度" class="headerlink" title="圈复杂度"></a>圈复杂度</h4><p>Cyclomatic Complexity</p><p>可以计算出达到全面覆盖需要的最少测试用例。<br>它是基于通过代码的路径数计算的，每当函数的控制流分裂时，复杂度计数器就会增加1。每个函数的最小复杂度为1.此计算因语言而异，因为关键字和功能有所不同。</p><p><br></p><p><strong>特定语言的详细信息:</strong></p><table><thead><tr><th>Language</th><th>Notes</th></tr></thead><tbody><tr><td>ABAP</td><td>这些关键字将使复杂度加一: <code>AND , CATCH , CONTINUE , DO , ELSEIF , IF , LOOP , LOOPAT , OR , PROVIDE , SELECT…ENDSELECT , TRY , WHEN , WHILE</code></td></tr><tr><td>C/C++/Objective-C</td><td>复杂度加一: `function definitions, while , do while , for , throw statements, switch , case , default , &amp;&amp; operator,</td><td></td><td>operator, ? ternary operator, catch , break , continue , goto`</td></tr><tr><td>COBOL</td><td>复杂度加一: <code>ALSO , ALTER , AND , DEPENDING , END_OF_PAGE , ENTRY , EOP , EXCEPTION , EXIT , GOBACK , CONTINUE , IF , INVALID , OR , OVERFLOW , SIZE , STOP , TIMES , UNTIL , USE , VARYING , WHEN , EXEC CICS HANDLE , EXEC CICS LINK , EXEC CICS XCTL , EXEC CICS RETURN</code></td></tr><tr><td>Java</td><td>复杂度加一: `if , for , while , case , catch , throw , &amp;&amp; ,</td><td></td><td>, ?`</td></tr><tr><td>JS, PHP</td><td>复杂度加一: `function, if, &amp;&amp;,</td><td></td><td>, loop, switch case, throw, catch, go to`</td></tr><tr><td>PL/I</td><td>复杂度加一: `PROC , PROCEDURE , GOTO , GO TO , DO , IF , WHEN ,</td><td>, ! ,</td><td>= , != , &amp; , &amp;=`</td></tr><tr><td>PL/SQL</td><td>复杂度加一: create procedure, create trigger, procedure definition, basic loop statement, when clause statement, continue statement,exit statement, for loop statement, forall statement, if statement, elsif clause, raise statement, return statement, while loop statement, and expression, or expression, when clause expression</td></tr><tr><td>VB.NET</td><td>复杂度加一: <code>method or constructor declaration,  AndAlso , Case , Continue , End , Error , Exit , If , Loop , On Error , GoTo , OrElse , Resume , Stop , Throw , Try</code></td></tr></tbody></table><p><br><br><br></p><h4 id="认知复杂度"><a href="#认知复杂度" class="headerlink" title="认知复杂度"></a>认知复杂度</h4><p>Cognitive Complexity</p><p>对应这个应用是否很难被理解，理解代码的控制流程有多难。</p><p><br><br><br></p><h3 id="重复"><a href="#重复" class="headerlink" title="重复"></a>重复</h3><p>有:</p><ul><li>重复的块(Duplicated blocks)</li><li>重复的行(Duplicated lines)</li><li>重读文件(Duplicated files)</li><li>密度/重复行%(Duplicated lines %)</li></ul><p><br></p><h4 id="重复的块"><a href="#重复的块" class="headerlink" title="重复的块"></a>重复的块</h4><p>重复的行的块数。</p><p><br></p><p><strong>特定语言的详细信息</strong></p><p>非Java项目:</p><ul><li>There should be at least 100 successive and duplicated tokens.</li><li>Those tokens should be spread at least on:<ul><li>30 lines of code for COBOL</li><li>20 lines of code for ABAP</li><li>10 lines of code for other languages</li></ul></li></ul><p>Java项目:</p><p>There should be at least 10 successive and duplicated statements whatever the number of tokens and lines.检测重复时忽略缩进和字符串文字的差异。</p><p><br><br><br></p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>有:</p><ul><li>新问题(New issues)</li><li>新的严重问题(New xxx issues)</li><li>所有问题(Issues)</li><li>严重问题(xxx issues)</li><li>误判问题(False positive issues)</li><li>开启问题(Open issues)</li><li>确认问题(Confirmed issues)</li><li>重开问题(Reopened issues)</li></ul><p><br><br><br></p><h3 id="可维护性"><a href="#可维护性" class="headerlink" title="可维护性"></a>可维护性</h3><p>有:</p><ul><li>异味(Code Smells)</li><li>新异味(New Code Smells)</li><li>维护率(Maintainability Rating)</li><li>技术债务(Technical Debt)</li><li>新代码的技术债务(Technical Debt on New Code)</li><li>技术债务率(Technical Debt Ratio)</li><li>新代码的技术债务率(Technical Debt Ratio on New Code)</li></ul><p><br></p><h4 id="维护率"><a href="#维护率" class="headerlink" title="维护率"></a>维护率</h4><p>使用<strong>SQALE评级</strong>。与您的技术债务比率值相关的项目评级。<br>默认的可维护性评级网格是:</p><ul><li>A=<code>0-0.05 (&lt;5%)</code></li><li>B=<code>0.06-0.1 (6%-10%)</code></li><li>C=<code>0.11-0.20(11%-20%)</code></li><li>D=<code>0.21-0.5(21%-50%)</code></li><li>E=<code>0.51-1(50%-100%)</code></li></ul><p><br><br><br></p><h4 id="技术债务"><a href="#技术债务" class="headerlink" title="技术债务"></a>技术债务</h4><p>努力修复所有异味。以分钟(min)为度量单位存储在数据库中，单位值中的天假设为8小时(h)。</p><p><br><br><br></p><h4 id="技术债务率"><a href="#技术债务率" class="headerlink" title="技术债务率"></a>技术债务率</h4><p>开发成本与修复成本之间的比率。技术债务公式为: <code>Remediation cost / Development cost</code></p><p>开发一行代码的成本价值为<code>0.06 day == 0.06 * 8 * 60 min</code></p><p><br><br><br></p><h3 id="质量阈"><a href="#质量阈" class="headerlink" title="质量阈"></a>质量阈</h3><p>有:</p><ul><li>质量阈状态(Quality Gate Status)</li><li>质量阈详情(Quality Gate Details)</li></ul><p><br><br><br></p><h3 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h3><p>有:</p><ul><li>Bugs</li><li>New Bugs</li><li>可靠率(Reliability Rating)</li><li>可靠性的修复工作(Reliability remediation effort)</li><li>新代码可靠性的修复工作(Reliability remediation effort on new code)</li></ul><p><br></p><h4 id="可靠率"><a href="#可靠率" class="headerlink" title="可靠率"></a>可靠率</h4><ul><li>A = 0 Bugs</li><li>B = at least 1 Minor Bug</li><li>C = at least 1 Major Bug</li><li>D = at least 1 Critical Bug</li><li>E = at least 1 Blocker Bug</li></ul><p><br><br><br></p><h4 id="修复工作"><a href="#修复工作" class="headerlink" title="修复工作"></a>修复工作</h4><p>努力解决所有Bugs。以分钟为单位度量值存储在数据库中。如果数值天，则假设一天为8小时。</p><p><br><br><br></p><h3 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h3><p>有:</p><ul><li>漏洞(Vulnerabilities)</li><li>新漏洞(New Vulnerabilities)</li><li>安全级(Security Rating)</li><li>安全修复工作(Security remediation effort )</li><li>新代码的安全修复工作(Security remedation effort on new code)</li></ul><p><br></p><h4 id="安全评级"><a href="#安全评级" class="headerlink" title="安全评级"></a>安全评级</h4><ul><li>A = 0 Vulnerabilities</li><li>B = at least 1 Minor Vulnerability</li><li>C = at least 1 Major Vulnerability</li><li>D = at least 1 Critical Vulnerability</li><li>E = at least 1 Blocker Vulnerability</li></ul><p><br><br><br></p><h3 id="大小"><a href="#大小" class="headerlink" title="大小"></a>大小</h3><p>有:</p><ul><li>类(Classes)</li><li>注释行(Comment lines)</li><li>注释占比(Comments %) - <code>Comment lines / (Lines of code + Comment lines) * 100</code></li><li>目录(Directories)</li><li>文件(Files)</li><li>行数(Lines)</li><li>代码行数(Lines of code)</li><li>每种语言的代码行数(Lines of code per language)</li><li>函数(Functions)</li></ul><p><br><br><br></p><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>有:</p><ul><li>条件覆盖(Condition coverage)</li><li>新代码条件覆盖(Condition coverage on new code)</li><li>条件覆盖命中(Condition coverage hits)</li><li>逐行条件(Conditions by line)</li><li>逐行条件覆盖(Covered conditions by line)</li><li>覆盖(Coverage)</li><li>新代码覆盖(Coverage on new code)</li><li>行覆盖(Line coverage)</li><li>新代码行覆盖(Line coverage on new code)</li><li>行覆盖命中(Line coverage hits)</li><li>要覆盖的行(Lines to cover)</li><li>新代码要覆盖的行(Lines to cover on new code)</li><li>跳过单元测试(Skipped unit tests)</li><li>未覆盖条件(Uncovered conditions)</li><li>新代码未覆盖条件(Uncovered conditions on new code)</li><li>未覆盖行(Uncovered lines)</li><li>新代码未覆盖行(Uncovered lines on new code)</li><li>单元测试(Unit tests)</li><li>单元测试持续时间(Unit tests duration)</li><li>单元测试错误(Unit test errors)</li><li>单元测试失败(Unit test failures)</li><li>单元测试成功密度(Unit test success density %) - <code>Test success density = (Unit tests - (Unit test errors + Unit test failures)) / Unit tests * 100</code></li></ul><p><br></p><h4 id="条件覆盖"><a href="#条件覆盖" class="headerlink" title="条件覆盖"></a>条件覆盖</h4><p>在包含一些布尔表达式的每行代码中，条件覆盖只是回答了以下问题: <em>每个布尔表达式是否都被评估为 <code>true</code> 和 <code>false</code>?</em>。这是在单元测试执行期间遵循的流控制结构中可能的条件密度。</p><p><code>Condition coverage = (CT + CF) / (2*B)</code>, where:</p><ul><li>CT = conditions that have been evaluated to ‘true’ at least once(已经被评估为<code>true</code>至少一次的条件)</li><li>CF = conditions that have been evaluated to ‘false’ at least once(已经被评估为<code>false</code>至少一次的条件)</li><li>B = 条件总数(total number of conditions)</li></ul><p><br><br><br></p><h4 id="覆盖"><a href="#覆盖" class="headerlink" title="覆盖"></a>覆盖</h4><p>它是行覆盖和条件覆盖的混合。它的目标是为以下问题提供更准确的答案: <em>单元测试覆盖了多少源代码?</em></p><p><code>Coverage = (CT + CF + LC)/(2*B + EL)</code>, where:</p><ul><li>CT = 已经被评估为<code>true</code>至少一次的条件</li><li>CF = 已经被评估为<code>false</code>至少一次的条件</li><li>LC = 覆盖的行(covered lines)</li><li>B = 条件总数</li><li>EL = 可执行行的总数( total number of executable lines)</li></ul><p><br><br><br></p><h4 id="行覆盖"><a href="#行覆盖" class="headerlink" title="行覆盖"></a>行覆盖</h4><p>在给定的代码行上，行覆盖简单地回答了以下问题: <em>在执行单元测试期间是否执行了这行代码?</em></p><p>它是单元测试的覆盖率密度:</p><p><code>Line coverage = LC / EL</code>, where:</p><ul><li>LC = 覆盖的行(covered lines)</li><li>EL = 可执行行的总数(total number of executable lines)</li></ul><p><br><br><br><br><br></p><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>Concepts</p><p><br><br><br></p><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>Architecture</p><table><thead><tr><th>概念</th><th>定义</th></tr></thead><tbody><tr><td>Analyzer</td><td>用于分析源代码以计算快照的客户端程序</td></tr><tr><td>Database</td><td>存储配置和快照</td></tr><tr><td>Server</td><td>用于浏览快照数据和进行配置修改的Web界面</td></tr></tbody></table><p><br><br><br></p><h3 id="质量"><a href="#质量" class="headerlink" title="质量"></a>质量</h3><p>Quality</p><table><thead><tr><th>概念</th><th>定义</th></tr></thead><tbody><tr><td>Bug</td><td>表示代码中出错的问题</td></tr><tr><td>Code Smell</td><td>代码中与可维护性相关的问题</td></tr><tr><td>Cost</td><td>花费</td></tr><tr><td>Debt</td><td>解决问题所需的时间</td></tr><tr><td>Issue</td><td>代码不符合规则时，快照上会记录一个问题。有: Bugs , Code Smells and Vulnerabilities</td></tr><tr><td>Measure</td><td>给定时间内给定文件或项目的度量值</td></tr><tr><td>Metric</td><td>一种测量方式。随着时间的推移，度量标准可能具有不同的值或度量</td></tr><tr><td>New Code Period</td><td>需要密切关注代码中引入新问题的时间段</td></tr><tr><td>Quality Profile</td><td>一组规则</td></tr><tr><td>Rule</td><td>应该遵循的编码标准或惯例</td></tr><tr><td>Remediation Cost</td><td>修复漏洞和可靠性问题所需的估计时间</td></tr><tr><td>Snapshot</td><td>在给定时间内针对给定项目的一组度量和问题</td></tr><tr><td>Security Hotspot</td><td>与安全相关的问题，突出显示使用安全敏感API的一段代码</td></tr><tr><td>Technical Debt</td><td>修复问题所需的估计时间</td></tr><tr><td>Vulnerability</td><td>与安全相关的问题，代表攻击者的后门</td></tr></tbody></table><p><br><br><br><br><br></p><h2 id="活动"><a href="#活动" class="headerlink" title="活动"></a>活动</h2><p>Activity and History</p><p>项目活动页面提供项目文件分析的完整列表，以及随着时间推移看到项目措施演变的能力。<br>活动页面上的图标可帮助你了解几种相互选择的度量方法的演变。</p><p><br></p><h3 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h3><p>Events</p><p>有四种类型的事件:</p><ul><li>Quality Gate</li><li>Profile</li><li>Version</li><li>Other</li></ul><p><br><br><br><br><br></p><h2 id="SonarLint"><a href="#SonarLint" class="headerlink" title="SonarLint"></a>SonarLint</h2><p>SonarLint Smart Notifications</p><p>SonarLint Smart Notifications是作为Developer Edtion的一部分来提供。</p><p>智能通知允许使用SonarLint中的连接模式的开发人员以一下情况下从SonarQube接收IDE内的通知:</p><ul><li>the Quality Gate status (failed / success) of a project /solution open in the IDE changes</li><li>a SonarQube analysis raises new issues introduced by this developer in a project /solution open in the IDE</li></ul><p>SonarLint智能通知的激活和取消必须由每个开发人员直接在SonarLint(IDE端)进行单独完成。<br>可以在SonarQube上逐个服务器地在SonarLint端配置接收通知。</p><p><br><br><br><br><br></p><h2 id="Security-Reports"><a href="#Security-Reports" class="headerlink" title="Security Reports"></a>Security Reports</h2><p><br></p><h3 id="安全报告显示了什么"><a href="#安全报告显示了什么" class="headerlink" title="安全报告显示了什么"></a>安全报告显示了什么</h3><p>What do the Security Reports show?</p><p>安全报告旨在快速为您提供有关应用程序安全性的全景图，并详细说明OWASP, SANS, CWE标准的详细信息。安全报告由分析器提供，分析器依赖于质量配置文件中激活的规则来引发安全问题。</p><p><br><br><br></p><h3 id="热点和漏洞有什么区别"><a href="#热点和漏洞有什么区别" class="headerlink" title="热点和漏洞有什么区别"></a>热点和漏洞有什么区别</h3><p>What’s the difference between a Hotspot and a Vulnerability?</p><p>漏洞是代码中可以攻击的点。安全热点是安全敏感的代码段，应由具有安全审计员帽的人仔细审查。<br>安全热点的主要目标是帮助集中手动审查应用程序源代码的安全审核员的工作。第二个目标是教育开发人员并提高他们的安全意识。</p><p><br><br><br></p><h3 id="为什么某些热点和漏洞非常相似"><a href="#为什么某些热点和漏洞非常相似" class="headerlink" title="为什么某些热点和漏洞非常相似"></a>为什么某些热点和漏洞非常相似</h3><p>Why are some Hotspot and Vulnerability rules very similar?</p><p>它们是故意重叠的。热点规则应该包括漏洞规则的所有匹配，以及污点分析引擎无法检测漏洞的情况。</p><p><br><br><br></p><h3 id="为什么我看不到任何热点"><a href="#为什么我看不到任何热点" class="headerlink" title="为什么我看不到任何热点"></a>为什么我看不到任何热点</h3><p>Why are some Hotspot and Vulnerability rules very similar?</p><p>有三个原因:</p><ul><li>可能真的没有它们，因为代码是在没有使用任何安全敏感API的情况下编写的</li><li>热点规则可能可用，但尚未在你的质量配置文件中激活，因此自然不会引发任何问题</li><li>你正在使用的语言分析器可能还没有提供热点规则，所以它不会引发任何热点</li></ul><p><br><br><br></p><h3 id="为什么我看不到任何漏洞"><a href="#为什么我看不到任何漏洞" class="headerlink" title="为什么我看不到任何漏洞"></a>为什么我看不到任何漏洞</h3><p>由于一些热点原因，你可能没有看到任何漏洞的，但你可能会看到项目主页中报告了一些漏洞，而安全报告中没有漏洞。这是因为语言分析器可能尚未提供安全报告中可见问题所需的安全标准的元数据。</p><p><br><br><br></p><h3 id="开发者是否应该关心热点"><a href="#开发者是否应该关心热点" class="headerlink" title="开发者是否应该关心热点"></a>开发者是否应该关心热点</h3><p>可能并不需要。热点并不是真正可行的，它们只是标记潜在的问题，所以在代码上没有立即做任何事情。这就是为什么在引发热点问题时没有收到通知。</p><p><br><br><br></p><h3 id="如果热点确实标记为漏洞怎么办"><a href="#如果热点确实标记为漏洞怎么办" class="headerlink" title="如果热点确实标记为漏洞怎么办"></a>如果热点确实标记为漏洞怎么办</h3><p>如果您查看引发热点的代码并意识到确实存在问题，请单击当前状态以注册您在代码中检测到漏洞。完成后，它将转换为漏洞，最后触摸该行的开发人员将收到新问题通知。</p><p><br><br><br></p><h3 id="热点变为漏洞后会发生什么"><a href="#热点变为漏洞后会发生什么" class="headerlink" title="热点变为漏洞后会发生什么"></a>热点变为漏洞后会发生什么</h3><p>一旦您检测到热点位置确实存在问题，它将被分配给相应的开发人员，他们将进行修复，然后必须通过UI请求审核。</p><p><br><br><br></p><h3 id="热点被标记为不会修复是什么意思"><a href="#热点被标记为不会修复是什么意思" class="headerlink" title="热点被标记为不会修复是什么意思"></a>热点被标记为不会修复是什么意思</h3><p>What does it mean for a Hotspot to be marked “Won’t Fix”?</p><p>不会修复标记用于表示已经审查了热点，并且目前无法利用这段代码创建攻击。</p><p><br><br><br><br><br></p><h2 id="用户账户"><a href="#用户账户" class="headerlink" title="用户账户"></a>用户账户</h2><p>User Account</p><p>SonarQube用户可拥有自己的空间，可查看与自己相关的内容。</p><p><br><br><br><br><br></p><h2 id="User-Token"><a href="#User-Token" class="headerlink" title="User Token"></a>User Token</h2><p>每个用户都可生成令牌，这些令牌可用于运行分析或调用Web服务，而无需用户的实际凭据。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="项目管理"><a href="#项目管理" class="headerlink" title="项目管理"></a>项目管理</h1><p>Project Administration</p><p><br></p><h2 id="项目存在"><a href="#项目存在" class="headerlink" title="项目存在"></a>项目存在</h2><p>Project Existence</p><p>通常，项目在第一次分析时创建，不会删除(除非手动删除)。你可以管你你有权限管理的项目。</p><p><br></p><ul><li>在第一次分析之前配置项目</li><li>配置还未分析的项目</li><li>修改项目权限(Private/Public) - 默认情况下，任何新创建的项目都被视为Public。这意味着每个经过认证的用户都能够<strong>Browse</strong>和<strong>See Source Code</strong></li><li>删除项目</li><li>查找不再分析的项目</li></ul><p><br><br><br></p><h2 id="管理项目历史"><a href="#管理项目历史" class="headerlink" title="管理项目历史"></a>管理项目历史</h2><p>Managing Project History</p><p>SonarQube最强大的功能之一是它不仅向你展示了你今天的项目健康状况，还展示了它随时间的变化情况。它通过有选择地保留以前分析的数据来做到这一点。它没有保留所有以前的分析——这会使数据库膨胀。同样，对于它确实存在的分析，SonarQube不会保留所有数据。一旦项目快照(snapshot)从最后分析(Last analysis)移动到项目历史的一部分，项目级别下面的数据就会被清除——再次放置数据库膨胀。</p><p>通常这些都不是你需要考虑的事情。SonarQube只为你专门处理它们。但有时你可能需要从项目的历史记录中删除错误的快照或修改内存处理算法。</p><p><br></p><p>可查看数据库表大小:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># sonar</span><br><span class="line"><span class="keyword">USE</span> information_schema;</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESCRIBE</span> <span class="keyword">TABLES</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> TABLE_SCHEMA, TABLE_NAME, TABLE_ROWS, DATA_LENGTH <span class="keyword">FROM</span> <span class="keyword">TABLES</span> <span class="keyword">WHERE</span> TABLE_SCHEMA = <span class="string">'sonar'</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> DATA_LENGTH <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure><p><br></p><p>有时你可能需要手动删除项目快照，无论是因为使用了错误的质量配置文件，还是因为分析存在问题…请注意，永远不能删除最新的快照。</p><p>对于每个快照，可以手动:</p><ul><li>Add, rename or remove a version</li><li>Add, rename or remove an event</li><li>Delete the snapshot</li></ul><p><br><br><br></p><h2 id="缩小关注点"><a href="#缩小关注点" class="headerlink" title="缩小关注点"></a>缩小关注点</h2><p>Narrowing the Focus</p><p>如果SonarQube的结果不相关，那么没有人会想要使用它。这就是为什么精确配置每个项目要分析的内容是非常重要的一步。<br>SonarQube为你提供了几种选项，可以准确配置要分析的内容。你可以:</p><ul><li>完全忽略一些文件或目录</li><li>从问题中排除文件或目录，但分析所有其它方面</li><li>从重复性中排除文件或目录，但分析所有其它方面</li><li>从覆盖率中排除文件或目录，但分析其它所有方面</li></ul><p>你可以在全局或项目级别配置它们。</p><p><br></p><h3 id="忽略文件"><a href="#忽略文件" class="headerlink" title="忽略文件"></a>忽略文件</h3><p>Ignore Files</p><p>建议你从库中排除生成的代码，源代码等。有四种不同的方法可将分析范围缩小到与开发团队相关的源代码。</p><ul><li>源目录(Source Directories)</li><li>文件后缀(File Suffixes)</li><li>选择文件(Choosing Files)<ul><li>源文件排除(Source File Exclusions)</li><li>测试文件排除(Test File Exclusions)</li><li>源文件包含(Source File Inclusions)</li><li>测试文件包含(Test File Inclusions)</li></ul></li></ul><p><img src="/images/SonarQube/exclusions.jpg" alt=""></p><p><img src="/images/SonarQube/inclusions.jpg" alt=""></p><p><br><br><br></p><h3 id="忽略问题"><a href="#忽略问题" class="headerlink" title="忽略问题"></a>忽略问题</h3><p>Ignore Issues</p><p>可使用SonarQube忽略某些组件和某些编码规则的问题。<code>Administration &gt; General Settings &gt; Analysis Scope &gt; Issues</code>。</p><p>请注意，以下属性只能通过Web界面设置，因为它们是多值的。</p><ul><li>Ignore Issues on Files</li><li>Ignore Issues in Blocks</li><li>Ignore Issues on Multiple Criteria</li><li>Restrict Scope of Coding Rules</li></ul><p><br><br><br></p><h3 id="忽略重复"><a href="#忽略重复" class="headerlink" title="忽略重复"></a>忽略重复</h3><p>Ignore Duplications</p><p>可在SonarQube中阻止检查某些文件的重复性。<code>Administration &gt; General Settings &gt; Analysis Scope &gt; Duplications</code>。</p><p><br><br><br></p><h3 id="忽略代码覆盖率"><a href="#忽略代码覆盖率" class="headerlink" title="忽略代码覆盖率"></a>忽略代码覆盖率</h3><p>Ignore Code Coverage</p><p>可以通过单元测试防止某些文件考虑用于代码覆盖。<code>Administration &gt; General Settings &gt; Analysis Scope &gt; Code Coverage &gt; Coverage Exclusions</code>。</p><p><br><br><br></p><h3 id="模式"><a href="#模式" class="headerlink" title="模式"></a>模式</h3><p>Patterns</p><p>SonarQube中可以使用以下通配符:</p><ul><li><code>*</code>    - 零个或多个字符(zero or more characters)</li><li><code>**</code> - 零个或多个目录(zero or more directories)</li><li><code>?</code> - 单个字符(a single character)</li></ul><p><br><br><br><br><br></p><h2 id="项目设置"><a href="#项目设置" class="headerlink" title="项目设置"></a>项目设置</h2><p>Project Settings</p><p><br></p><h3 id="Tags"><a href="#Tags" class="headerlink" title="Tags"></a>Tags</h3><p>项目标签(tags) 允许对项目进行分类和分组，以便在项目页面上更容易地选择。可以从项目主页管理项目标签。</p><p><br><br><br></p><h3 id="管理项"><a href="#管理项" class="headerlink" title="管理项"></a>管理项</h3><p>Administration Items:</p><ul><li>Adding a Project</li><li>Analysis Report Processing</li><li>Deleting a Project</li><li>Setting the New Code Period</li><li>Updating Project Key</li><li>Default Issue Assignee</li><li>Setting Quality Gate and Quality Profiles</li><li>Setting Exclusions</li><li>Customizing Links</li></ul><p><br><br><br><br><br></p><h2 id="Webhooks"><a href="#Webhooks" class="headerlink" title="Webhooks"></a>Webhooks</h2><p>网络调用(Webhooks) 在项目完成分析后通知外部服——An HTTP POST request including a JSON payload is sent to each URL。可在项目级别和全局指定URL。项目级别的配置不会取代全局的配置，两个级别的所有Webhooks都被调用。</p><p>HTTP(s) 调用:</p><ul><li>无论后台任务的状态如何</li><li>使用POST方法将JSON文档作为负载</li><li>使用<code>UTF-8</code>编码的内容类型<code>application/json</code></li></ul><p><br></p><h3 id="Delivery-and-Payload"><a href="#Delivery-and-Payload" class="headerlink" title="Delivery and Payload"></a>Delivery and Payload</h3><p>Webhook 管理控制台显示每个Webhook的最新交付的结果和时间戳，其中有效负载可通过列表图标获得。默认保留30天的记录。URL必须在10s响应，否则传递将标记为失败。</p><p>发送带有project key的 HTTP header <code>X-SonarQube-Project</code>，以便快速识别所涉及的项目。</p><p>Payload是一个JSON文档，包括:</p><ul><li>什么时候运行分析(<code>analysedAt</code>)</li><li>分析的项目的标识(<code>project</code>)</li><li>每个质量阈标准和状态(<code>qualityGate</code>)</li><li>每个项目的质量阈状态(<code>qualityGate.status</code>)</li><li>后台任务的状态和标识(<code>status</code>, <code>taskId</code>)</li><li>用于定义的属性(<code>properties</code>)</li></ul><p>栗子:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"analysedAt"</span>: <span class="string">"2016-11-18T10:46:28+0100"</span>,</span><br><span class="line">    <span class="attr">"project"</span>: &#123;</span><br><span class="line">        <span class="attr">"key"</span>: <span class="string">"org.sonarqube:example"</span>,</span><br><span class="line">        <span class="attr">"name"</span>: <span class="string">"Example"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"qualityGate"</span>: &#123;</span><br><span class="line">        <span class="attr">"conditions"</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">"errorThreshold"</span>: <span class="string">"1"</span>,</span><br><span class="line">                <span class="attr">"metric"</span>: <span class="string">"new_security_rating"</span>,</span><br><span class="line">                <span class="attr">"onLeakPeriod"</span>: <span class="literal">true</span>,</span><br><span class="line">                <span class="attr">"operator"</span>: <span class="string">"GREATER_THAN"</span>,</span><br><span class="line">                <span class="attr">"status"</span>: <span class="string">"OK"</span>,</span><br><span class="line">                <span class="attr">"value"</span>: <span class="string">"1"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">"errorThreshold"</span>: <span class="string">"1"</span>,</span><br><span class="line">                <span class="attr">"metric"</span>: <span class="string">"new_reliability_rating"</span>,</span><br><span class="line">                <span class="attr">"onLeakPeriod"</span>: <span class="literal">true</span>,</span><br><span class="line">                <span class="attr">"operator"</span>: <span class="string">"GREATER_THAN"</span>,</span><br><span class="line">                <span class="attr">"status"</span>: <span class="string">"OK"</span>,</span><br><span class="line">                <span class="attr">"value"</span>: <span class="string">"1"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">"errorThreshold"</span>: <span class="string">"1"</span>,</span><br><span class="line">                <span class="attr">"metric"</span>: <span class="string">"new_maintainability_rating"</span>,</span><br><span class="line">                <span class="attr">"onLeakPeriod"</span>: <span class="literal">true</span>,</span><br><span class="line">                <span class="attr">"operator"</span>: <span class="string">"GREATER_THAN"</span>,</span><br><span class="line">                <span class="attr">"status"</span>: <span class="string">"OK"</span>,</span><br><span class="line">                <span class="attr">"value"</span>: <span class="string">"1"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">"errorThreshold"</span>: <span class="string">"80"</span>,</span><br><span class="line">                <span class="attr">"metric"</span>: <span class="string">"new_coverage"</span>,</span><br><span class="line">                <span class="attr">"onLeakPeriod"</span>: <span class="literal">true</span>,</span><br><span class="line">                <span class="attr">"operator"</span>: <span class="string">"LESS_THAN"</span>,</span><br><span class="line">                <span class="attr">"status"</span>: <span class="string">"NO_VALUE"</span></span><br><span class="line">            &#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="attr">"name"</span>: <span class="string">"SonarQube way"</span>,</span><br><span class="line">        <span class="attr">"status"</span>: <span class="string">"OK"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"serverUrl"</span>: <span class="string">"http://localhost:9000"</span>,</span><br><span class="line">    <span class="attr">"status"</span>: <span class="string">"SUCCESS"</span>,</span><br><span class="line">    <span class="attr">"taskId"</span>: <span class="string">"AVh21JS2JepAEhwQ-b3u"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="附加参数"><a href="#附加参数" class="headerlink" title="附加参数"></a>附加参数</h3><p>Additional parameters</p><p>通过在Webhook的URL中提供<code>user/passwd</code>来支持基本的身份认证机制。(如: <code>https://myLogin:myPassword@my_server/foo</code>)</p><p>如果使用了<code>sonar.analysis.*</code>属性为SonarScanner提供其它属性，则这些属性将自动添加到有效负载的<code>properties</code>部分。</p><p>栗子:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sonar-scanner -Dsonar.analysis.scmRevision=628f5175ada0d685fd7164baa7c6382c1f25cab4 -Dsonar.analysis.buildNumber=12345</span><br></pre></td></tr></table></figure><p><br><br><br></p><hr><p><br><br><br></p><h1 id="实例管理"><a href="#实例管理" class="headerlink" title="实例管理"></a>实例管理</h1><p>Instance Administration</p><p><br></p><h2 id="质量配置"><a href="#质量配置" class="headerlink" title="质量配置"></a>质量配置</h2><p>Quality Profiles</p><p><br></p><h3 id="概述-4"><a href="#概述-4" class="headerlink" title="概述"></a>概述</h3><p>质量配置(Quality Profiles)服务是SonarQube的核心，因为它是您通过定义规则集来定义需求的地方。。</p><p>理想情况下，对于任何给定的语言，所有项目都将使用相同的配置文件进行测量，但这并不总是实用的。<br>这就是为什么您可以根据需要定义尽可能多的质量配置文件，即使建议尽可能少的质量配置文件以确保公司项目的一致性。</p><p>每个语言都带有预定义的內建配置文件(通常称为 Sonar way)，因此你可以使用SonarQube分析进行快速开始。这就是为什么只要安装新的语言插件，就可以使用至少一个配置文件。</p><p>默认的Sonar way配置文件，它包含了通常适用于大多数项目的所有规则。但作为最佳实践，你应该创建一个新的配置文件(你可以通过复制Sonar way的内容来填充它)，并使用它。<br>因为默认的Sonar way是不可编辑的，因此你无法根据需要对其进行自定义。此外，这使你可将Sonar way视为一个基线，可在对其进行更改时跟踪自己的配置文件。此外Sonar way通常会随插件的每个新版本更新，已添加规则，有时还会调整规则严重性。任何继承自內建Sonar way的配置文件都将在事实上同时自动更新。</p><p><br><br><br></p><h3 id="我该怎么做"><a href="#我该怎么做" class="headerlink" title="我该怎么做"></a>我该怎么做</h3><p><br></p><p>####　将质量配置管理的权限移交给其他人</p><p>Delegate the management of Quality Profiles to someone else?</p><p>默认情况下，管理员才有此权限。但你可以授予用户/组权限来编辑配置文件。例如将Java配置文件权限分配给Java开发专家，将Python配置文件权限分配给Python专家…</p><p><br><br><br></p><h4 id="将规则从一个配置复制到另一个配置"><a href="#将规则从一个配置复制到另一个配置" class="headerlink" title="将规则从一个配置复制到另一个配置"></a>将规则从一个配置复制到另一个配置</h4><p>Copy the rules from one profile to another?</p><p>许多时候，人们希望使用基于內建的配置文件的配置文件进行工作，而无实际需要使用內建配置文件。</p><p><br><br><br></p><h4 id="了解配置中有什么改变"><a href="#了解配置中有什么改变" class="headerlink" title="了解配置中有什么改变"></a>了解配置中有什么改变</h4><p>Know what’s changed in a profile?</p><p>当SonarQube注意到使用与先前分析不同的配置文件执行分析时，会将质量配置文件事件添加到项目的事件日志中。</p><p><br><br><br></p><h4 id="将配置文件从一个实例复制到另一个实例"><a href="#将配置文件从一个实例复制到另一个实例" class="headerlink" title="将配置文件从一个实例复制到另一个实例"></a>将配置文件从一个实例复制到另一个实例</h4><p>Copy a profile from one SonarQube instance to another?</p><p>使用实例上的备份(Back UP)功能将配置文件导出到XML文件。然后在另一个实例中选择恢复(Restore)。</p><p><br><br><br></p><h4 id="将一组核心规则和附加规则应用于项目"><a href="#将一组核心规则和附加规则应用于项目" class="headerlink" title="将一组核心规则和附加规则应用于项目"></a>将一组核心规则和附加规则应用于项目</h4><p>Apply a core set of rules plus additional rules to a project?</p><p>使用继承，从root继承核心规则集。然后创建一个子配置文件(Sprout)，修改从Root继承，然后添加缺少的规则。</p><p><br><br><br></p><h4 id="确保我的非默认配置文件应用于项目"><a href="#确保我的非默认配置文件应用于项目" class="headerlink" title="确保我的非默认配置文件应用于项目"></a>确保我的非默认配置文件应用于项目</h4><p>Make sure my non-default profile is used on a project?</p><p><br><br><br></p><h4 id="确保我的个人配置中包含所有相关的新规则"><a href="#确保我的个人配置中包含所有相关的新规则" class="headerlink" title="确保我的个人配置中包含所有相关的新规则"></a>确保我的个人配置中包含所有相关的新规则</h4><p>Make sure I’ve got all the relevant new rules in my profile?</p><p><br><br><br></p><h4 id="比较两个规则"><a href="#比较两个规则" class="headerlink" title="比较两个规则"></a>比较两个规则</h4><p>Compare two profiles?</p><p><br><br><br></p><h4 id="确保我的配置中没有任何弃用的规则"><a href="#确保我的配置中没有任何弃用的规则" class="headerlink" title="确保我的配置中没有任何弃用的规则"></a>确保我的配置中没有任何弃用的规则</h4><p>Make sure I don’t have any deprecated rules in my profile?</p><p><br><br><br></p><h4 id="安全-1"><a href="#安全-1" class="headerlink" title="安全"></a>安全</h4><p>Security</p><p>任何用户都可以访问质量配置服务，你可以给他们配置质量配置管理权限，让他们可以创建，删除质量配置。</p><p><br><br><br><br><br></p><h2 id="安全-2"><a href="#安全-2" class="headerlink" title="安全"></a>安全</h2><p><br></p><h3 id="概述-5"><a href="#概述-5" class="headerlink" title="概述"></a>概述</h3><p>SonarQube具有许多全局安全功能:</p><ul><li>认证和授权机制</li><li>强制身份认证</li><li>委派认证</li></ul><p>除此之外，还可在group/user级别配置:</p><ul><li>查看一个已存在的项目</li><li>访问项目的源代码</li><li>管理一个项目</li><li>管理质量配置，质量阈，实例…</li></ul><p><br><br><br></p><h3 id="认证"><a href="#认证" class="headerlink" title="认证"></a>认证</h3><p>Authentication</p><p>第一个问题: 匿名用户是否可以浏览SonarQube实例？<br>当然不行！那就需要强制用户认证。</p><p><br></p><p><strong>认证机制(Authentication Mechanisms)</strong></p><p>可通过多种方式来管理认证机制:</p><ul><li>通过SonarQube內建的user/group数据库</li><li>通过外部程序(如LDAP)</li><li>通过HTTP headers</li></ul><p><br></p><p><strong>技术用户(Technical Users)</strong></p><p>当你在SonarQube数据库中创建用户时，他将被视为本地用户，并且针对SonarQube自己的user/group数据库进行身份认证，而不是通过任何外部工具。<br>默认情况下，<code>admin</code>是本地账户。</p><p>同样，所有非本地(non-local)账户将仅针对外部工具进行身份认证。</p><p>管理员可以管理所有用户的<strong>Tokens</strong>——创建和删除。一旦创建，Token就是运行分析所需的唯一凭证，作为<code>sonar.login</code>属性的值来传递。</p><p><br></p><p><strong>默认管理员(Default Admin Credentials)</strong></p><p>当安装SonarQube时，会自动创建具有管理系统权限的默认用户:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">user:</span> <span class="string">admin</span></span><br><span class="line"><span class="attr">passwd:</span> <span class="string">admin</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="重置管理员密码"><a href="#重置管理员密码" class="headerlink" title="重置管理员密码"></a>重置管理员密码</h3><p>Reinstating Admin Access</p><p>如果你修改了管理员密码，但又忘记了:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">USE</span> sonar;</span><br><span class="line"></span><br><span class="line"><span class="keyword">update</span> <span class="keyword">users</span> <span class="keyword">set</span> crypted_password = <span class="string">'$2a$12$uCkkXmhW5ThVK8mpBvnXOOJRLd64LJeHTeCkSuB3lfaR2N0AYBaSi'</span>, <span class="keyword">salt</span>=<span class="literal">null</span>, hash_method=<span class="string">'BCRYPT'</span> <span class="keyword">where</span> login = <span class="string">'admin'</span></span><br></pre></td></tr></table></figure><p>如果您删除了管理员并随后锁定了具有全局管理权限的其他用户:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">USE</span> sonar;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> user_roles(user_id, <span class="keyword">role</span>) <span class="keyword">VALUES</span> ((<span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> <span class="keyword">users</span> <span class="keyword">where</span> login=<span class="string">'mylogin'</span>), <span class="string">'admin'</span>);</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="授权"><a href="#授权" class="headerlink" title="授权"></a>授权</h3><p>Authorization</p><p>对不同组、不同用于仅限权限分配，以访问不同的资源。</p><ul><li>user</li><li>group</li><li>Global Permissions<ul><li>Administer System</li><li>Administer Quality Profiles</li><li>Administer Quality Gates</li><li>Execute Analysis</li><li>Create Projects</li><li>Create Applications</li><li>Create Portfolios</li></ul></li><li>Project Permissions<ul><li>Public and Private<ul><li>Administer Issues</li><li>Administer Security Hotspots</li><li>Administer</li><li>Execute Analysis</li></ul></li><li>Private<ul><li>Browse</li><li>See Source Code</li></ul></li></ul></li></ul><p><br><br><br></p><h3 id="默认权限的权限模板"><a href="#默认权限的权限模板" class="headerlink" title="默认权限的权限模板"></a>默认权限的权限模板</h3><p>Permission Templates for Default Permissions</p><p>SonarQube附带默认权限模板，该模板在创建项目，项目组合或应用程序自动授予特定组的特定权限。管理员可以编辑此模板。</p><p><br><br><br></p><h3 id="加密"><a href="#加密" class="headerlink" title="加密"></a>加密</h3><p>Encryption</p><p>加密主要用于从设置中删除明文密码。实现的解决方案是基于对称密钥算法，关键是密钥存储在磁盘上的安全文件中。此文件必须由运行SonarQube Server的系统账户拥有和读取。<br>该算法是AES 128位。</p><ul><li><strong>Generate the secret key</strong></li><li><strong>Store the secret key on the SonarQube server</strong></li><li><strong>Generate the encrypted values of your settings</strong></li><li><strong>Use the encrypted values in your SonarQube server configuration</strong></li></ul><p>必须在SonarQube基础架构的所有部分之间共享唯一的密钥。在<code>Administration &gt; Configuration &gt; Encryption</code>生成密钥。<br>生成密钥之后，会显示如何使用此密钥。</p><p><img src="/images/SonarQube/secretKey.png" alt=""></p><p>之后便可以为你设置的值进行加密。同样在前面的加密下进行配置。<br>之后在SonarQube Server中使用加密后的值:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># conf/sonar.properties</span><br><span class="line"></span><br><span class="line">sonar.jdbc.password=&#123;aes&#125;CCGCFg4Xpm6r+PiJb1Swfg==  # Encrypted DB password</span><br><span class="line">...</span><br><span class="line">sonar.secretKeyPath=C:/path/to/my/secure/location/my_secret_key.txt</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="委托认证"><a href="#委托认证" class="headerlink" title="委托认证"></a>委托认证</h2><p>Delegating Authentication</p><p>docs: <a href="https://docs.sonarqube.org/latest/instance-administration/delegated-auth/" target="_blank" rel="noopener">https://docs.sonarqube.org/latest/instance-administration/delegated-auth/</a></p><p>SonarQube认证:</p><ul><li>自带用户数据库认证</li><li>外部<ul><li>HTTP header</li><li>LDAP</li><li>…</li></ul></li></ul><p><br></p><h3 id="HTTP-header认证"><a href="#HTTP-header认证" class="headerlink" title="HTTP header认证"></a>HTTP header认证</h3><p><br><br><br></p><h3 id="LDAP认证"><a href="#LDAP认证" class="headerlink" title="LDAP认证"></a>LDAP认证</h3><p><br><br><br><br><br></p><h2 id="通知"><a href="#通知" class="headerlink" title="通知"></a>通知</h2><p>Notifications</p><p>可以通过邮件配置，向用户发送分析的信息的通知。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="使用实践"><a href="#使用实践" class="headerlink" title="使用实践"></a>使用实践</h1><blockquote><p><strong>注意:</strong><br>由于使用的是SonarQube CE(社区版)，因此不支持在IDE中上传分析数据，也不支持多分支(branch)分析。所以需要对这些方面做一些规范。</p></blockquote><p><br></p><p>SonarQube的使用主要分为两个方面:</p><ul><li><strong>开发者 IDE</strong></li><li><strong>CI SonarScanner</strong></li></ul><p><br></p><h2 id="CI"><a href="#CI" class="headerlink" title="CI"></a>CI</h2><p>CI端 需先安装 <code>SonarQube Scanner</code> 应用程序，并配置相应的路径和token。</p><p>由于社区版的缘故，我只对测试分支的CI进行SonarScanner分析，并将结果上传到SonarQube Server对应项目的路径。</p><p>由于测试分支(stage)的代码都是由开发者现在本地IDE中检测过代码质量(Code Quality)之后才MR过来，所以这样更方便和实用些。</p><p>CI SonarScanner分析上传之后，SonarQube会通知项目负责人此项目代码相关情况。由项目负责人去SonarQube Web UI上再去核查相关issues，核查无误之后，才能将测试分支的代码上线。<br>如果项目负责人检查出相关代码的某些问题，请于相关分支开发者交流，叮嘱他们现在本地IDE自测，通过之后在MR代码。</p><p><br><br><br></p><h2 id="IDE"><a href="#IDE" class="headerlink" title="IDE"></a>IDE</h2><p>只需在IDE中下载SonarLint插件，并配置上运维人员提供的地址和token就可以使用了。</p><p>由于社区版的缘故，我这里让<strong>开发者自己的分支</strong>在IDE中调用远程SonarQube进行本地代码质量检查，并不需要将开发者的分支代码情况上传到SonarQube Server端。</p><p>开发者自己检查和核对自己分支的代码质量，确认之后才将自己的代码MR到dev分支。<br>如果项目负责人检测到某位开发者的分支代码存在问题，则这个责任由分支开发者负责和处理。</p><p><br><br><br></p><h2 id="权限问题"><a href="#权限问题" class="headerlink" title="权限问题"></a>权限问题</h2><p>权限有一些地方需要注意:</p><ul><li>将项目设置为私有(默认: public)</li><li>项目对应项目组(group)，对应项目成员(user)</li><li>项目组中的CI, IDE用户具有不同的权限</li><li>…</li></ul><p><br></p><p>具体配置可以在使用的时候灵活修改！</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="API"><a href="#API" class="headerlink" title="API"></a>API</h1><p>可通过SonarQube API 进行许多操作。</p><p><br></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如导出python的代码规则</span></span><br><span class="line">curl -X GET -v -u user:passwd  http://localhost:9000/api/rules/search?language=python &gt; python.json</span><br></pre></td></tr></table></figure><p><br><br><br></p><hr><p><br><br><br></p><h1 id="Scanner"><a href="#Scanner" class="headerlink" title="Scanner"></a>Scanner</h1><ul><li>docs: <a href="https://docs.sonarqube.org/display/SCAN" target="_blank" rel="noopener">https://docs.sonarqube.org/display/SCAN</a></li></ul><p>建议将SonarQube Scanner用作使用SonarQube分析项目的默认扫描程序。</p><p><br></p><h2 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h2><p><br></p><h3 id="OS"><a href="#OS" class="headerlink" title="OS"></a>OS</h3><p>平台:</p><ul><li>Linux</li><li>Mac OS</li><li>Windows</li></ul><p><br></p><p>下载对应平台的Sonar Scanner应用程序，将它们解压之后加入系统路径(<code>$PATH</code>)。</p><p><br><br><br><br><br></p><h3 id="IDE-1"><a href="#IDE-1" class="headerlink" title="IDE"></a>IDE</h3><p>Sonar Scanner 支持的 IDE 有:</p><ul><li>MSBuild</li><li>Maven</li><li>Gradle</li><li>Ant</li><li>Jenkins</li><li>JetBrains</li></ul><p><br></p><p>在IDE中下载<strong>SonarLint</strong>插件，之后配置SonarQube Server地址和管理员给的Token便可以正常使用。<br>社区版的SonarQube 只能在IDE中检测，无法上传。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GitHub: &lt;a href=&quot;https://github.com/SonarSource/sonarqube&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/SonarSource/sonarqube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;https://www.sonarqube.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.sonarqube.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Docs: &lt;a href=&quot;https://docs.sonarqube.org&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://docs.sonarqube.org&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RHEL7x86_64&lt;/li&gt;
&lt;li&gt;SonarQube v7.6&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="SonarQube" scheme="https://zhang21.github.io/tags/SonarQube/"/>
    
      <category term="Static Analysis" scheme="https://zhang21.github.io/tags/Static-Analysis/"/>
    
      <category term="Code Quality" scheme="https://zhang21.github.io/tags/Code-Quality/"/>
    
  </entry>
  
  <entry>
    <title>DevOps</title>
    <link href="https://zhang21.github.io/2019/02/13/DevOps/"/>
    <id>https://zhang21.github.io/2019/02/13/DevOps/</id>
    <published>2019-02-12T21:22:15.000Z</published>
    <updated>2019-03-19T01:05:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li><li>GitLab</li><li>GitHub</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p><strong>DevOps</strong>（Development和Operations的组合词）是一种重视 <em>软件开发人员（Dev）</em> 和 <em>IT运维技术人员（Ops）</em> 之间沟通合作的文化、运动或惯例。透过自动化 <em>软件交付</em> 和 <em>架构变更</em> 的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。</p><p><img src="/images/DevOps/DevOps.png" alt=""></p><p><img src="/images/DevOps/devops-loop-and-spans-small.png" alt=""></p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="Auto-DevOps"><a href="#Auto-DevOps" class="headerlink" title="Auto DevOps"></a>Auto DevOps</h1><p>GitLab Auto DevOps:</p><ul><li>Auto Build</li><li>Auto Test</li><li>Auto Code Quality</li><li>Auto SAST (Static Application Security Testing)</li><li>Auto Dependency Scanning</li><li>Auto License Management</li><li>Auto Container Scanning</li><li>Auto Review Apps</li><li>Auto DAST (Dynamic Application Security Testing)</li><li>Auto Deploy</li><li>Auto Browser Performance Testing</li><li>Auto Monitoring</li></ul><p><br><br><br></p><hr><p><br><br><br></p><h1 id="DevOps工具"><a href="#DevOps工具" class="headerlink" title="DevOps工具"></a>DevOps工具</h1><p>下面介绍一些DevOps需要用到的工具，可能不够详细。</p><p><br></p><h2 id="基础环境"><a href="#基础环境" class="headerlink" title="基础环境"></a>基础环境</h2><p>IaaS:</p><ul><li>VMware</li><li>Xen</li><li>KVM</li><li>OpenStack</li><li>云平台</li><li>…</li></ul><p><br><br><br></p><h2 id="项目管理"><a href="#项目管理" class="headerlink" title="项目管理"></a>项目管理</h2><p>Task:</p><ul><li>RedaMine</li><li>Jira</li><li>禅道</li><li>…</li></ul><p><br><br><br></p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>Code:</p><ul><li>git</li><li>GitLab</li><li>Gogs</li><li>svn</li><li>云平台</li><li>…</li></ul><p><br><br><br></p><h2 id="持续集成-发布"><a href="#持续集成-发布" class="headerlink" title="持续集成/发布"></a>持续集成/发布</h2><p>CI/CD:</p><ul><li>Jenkins</li><li>Jenkins X</li><li>GitLab CICD</li><li>Bamboo</li><li>Maven</li><li>云平台</li><li>…</li></ul><p><br><br><br></p><h2 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h2><p>Container:</p><ul><li>Docker</li><li>K8s</li><li>CoreOS</li><li>Mesos</li><li>Helm</li><li>云平台</li><li>…</li></ul><p><br><br><br></p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>Test:</p><ul><li><strong>Selenium</strong></li><li><strong>Katalon Studio</strong></li><li><strong>Watir</strong></li><li><strong>Jmeter</strong></li><li><strong>Loadrunner</strong></li><li><strong>LOCUST</strong></li></ul><p><br></p><h3 id="Selenium"><a href="#Selenium" class="headerlink" title="Selenium"></a>Selenium</h3><ul><li>Website: <a href="https://www.seleniumhq.org/" target="_blank" rel="noopener">https://www.seleniumhq.org/</a></li></ul><p>Selenium是一个用于自动化测试Web apps的可移植框架。 Selenium提供了一种用于创作功能测试的回放工具，无需学习测试脚本语言。</p><p><br><br><br></p><h3 id="Katalon-Studio"><a href="#Katalon-Studio" class="headerlink" title="Katalon Studio"></a>Katalon Studio</h3><ul><li>Wetsite: <a href="https://www.katalon.com/" target="_blank" rel="noopener">https://www.katalon.com/</a></li></ul><p>Simplify API, Web, Mobile Automation Tests.</p><p><br><br><br></p><h3 id="Watir"><a href="#Watir" class="headerlink" title="Watir"></a>Watir</h3><ul><li>Website: <a href="http://watir.com/" target="_blank" rel="noopener">http://watir.com/</a></li></ul><p>An open source Ruby library for automating tests.<br>Watir interacts with a browser the same way people do: clicking links, filling out forms and validating text.</p><p><br><br><br></p><h3 id="JMeter"><a href="#JMeter" class="headerlink" title="JMeter"></a>JMeter</h3><p>Apache JMeter应用程序是开源软件，纯Java应用程序，旨在加载测试功能行为和测量性能。它最初是为测试Web应用程序而设计的，但后来扩展到其他测试功能。</p><p>Apache JMeter可用于测试静态和动态资源，Web动态应用程序的性能。<br>它可用于模拟服务器，服务器组，网络或对象上的重负载，以测试其强度或分析不同负载类型下的整体性能。</p><p><br></p><p>Apache JMeter功能包括:</p><ul><li>Ability to load and performance test many different applications/server/protocol types<ul><li>Web - HTTP, HTTPS (Java, NodeJS, PHP, ASP.NET, …)</li><li>SOAP / REST Webservices</li><li>FTP</li><li>Database via JDBC</li><li>LDAP</li><li>Message-oriented middleware (MOM) via JMS</li><li>Mail - SMTP(S), POP3(S) and IMAP(S)</li><li>Native commands or shell scripts</li><li>TCP</li><li>Java Objects</li></ul></li><li>Full featured Test IDE that allows fast Test Plan recording</li><li>CLI mode to load test from any Java compatible OS</li><li>Highly Extensible core</li><li>…</li></ul><p><br><br><br></p><h3 id="LoadRunner"><a href="#LoadRunner" class="headerlink" title="LoadRunner"></a>LoadRunner</h3><ul><li>Website: <a href="https://www.microfocus.com" target="_blank" rel="noopener">https://www.microfocus.com</a></li></ul><p>LoadRunner is a Load Testing Software</p><p><br><br><br></p><h3 id="LOCUST"><a href="#LOCUST" class="headerlink" title="LOCUST"></a>LOCUST</h3><ul><li>Website: <a href="https://locust.io/" target="_blank" rel="noopener">https://locust.io/</a></li><li>GitHub: <a href="https://github.com/locustio/locust/" target="_blank" rel="noopener">https://github.com/locustio/locust/</a></li></ul><p><br></p><p>An open source load testing tool.</p><p>Define user behaviour with Python code, and swarm your system with millions of simultaneous users.</p><p><br><br><br><br><br></p><h2 id="质量与安全"><a href="#质量与安全" class="headerlink" title="质量与安全"></a>质量与安全</h2><p>Quality and Security:</p><ul><li>infer</li><li>SonarQube</li><li>Cuckoo Sandbox</li><li>OWASP ZAProxy</li><li>Mobile-Security-Framework-MobSF</li><li>Clair</li></ul><p><br></p><h3 id="Infer"><a href="#Infer" class="headerlink" title="Infer"></a>Infer</h3><ul><li>GitHub: <a href="https://github.com/facebook/infer" target="_blank" rel="noopener">https://github.com/facebook/infer</a></li><li>Website: <a href="https://fbinfer.com/" target="_blank" rel="noopener">https://fbinfer.com/</a></li></ul><p><br></p><p><strong>Infer</strong> 是一个 <code>Java</code>，<code>C ++</code>，<code>Objective-C</code> 和 <code>C</code> 的代码静态分析工具。它会产生一个潜在的bug列表。任何人都可以使用Infer在发送给用户之前拦截关键错误，并帮助防止崩溃或性能不佳。</p><p>infer 主要用于 APP 端，也就是 Android/IOS App。</p><p><br><br><br></p><h3 id="SonarQube"><a href="#SonarQube" class="headerlink" title="SonarQube"></a>SonarQube</h3><ul><li>GitHub: <a href="https://github.com/SonarSource/sonarqube" target="_blank" rel="noopener">https://github.com/SonarSource/sonarqube</a></li><li>Website: <a href="https://www.sonarqube.org/" target="_blank" rel="noopener">https://www.sonarqube.org/</a></li></ul><p><br></p><p><strong>SonarQube</strong> 是一个开源平台，通过代码的自动化静态分析不断的检查代码质量。 SonarQube 支持20多种语言的分析，并在各种类型的项目中输出和存储问题。通过不同的插件对这些结果进行再加工处理，通过量化的方式度量代码质量的变化，从而可以方便地对不同规模和种类的工程进行代码质量管理。</p><p><br><br><br></p><h3 id="MobSF"><a href="#MobSF" class="headerlink" title="MobSF"></a>MobSF</h3><ul><li>GitHub: <a href="https://github.com/MobSF/Mobile-Security-Framework-MobSF" target="_blank" rel="noopener">https://github.com/MobSF/Mobile-Security-Framework-MobSF</a></li></ul><p><br></p><p>Mobile Security Framework is an automated, all-in-one mobile application (Android/iOS/Windows) pen-testing framework capable of performing static analysis, dynamic analysis, malware analysis and web API testing.</p><p><br><br><br></p><h3 id="Clair"><a href="#Clair" class="headerlink" title="Clair"></a>Clair</h3><ul><li>GitHub: <a href="https://github.com/coreos/clair" target="_blank" rel="noopener">https://github.com/coreos/clair</a></li></ul><p>Vulnerability Static Analysis for Containers.<br>Clair is an open source project for the static analysis of vulnerabilities in application containers (currently including appc and docker).</p><p><br><br><br><br><br></p><h2 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h2><p>Configuration Management:</p><ul><li>Ansible</li><li>ZooKeeper</li><li>CFEngine</li><li>Chef</li><li>MAAS</li><li>Puppet</li><li>SaltStack</li><li>Vagrant</li><li>Rundeck</li><li>Rudder</li><li>云平台</li><li>…</li></ul><p><br><br><br><br><br></p><h2 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h2><p>Data Analysis:</p><ul><li>Hadoop</li><li>Ambari</li><li>Avro</li><li>Flume</li><li>HBase</li><li>Hive</li><li>Spark</li><li>Sqoop</li><li>ZooKeeper</li></ul><p><br><br><br><br><br></p><h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p>Log:</p><ul><li>ElasticStack<ul><li>Elasticsearch</li><li>Logstash</li><li>Beat</li></ul></li><li>Hadoop, Hive - 与ELK类似的方案</li><li>Flume</li><li>Fluentd</li><li>Splunk</li><li>Kafka</li><li>Loggly</li><li>Papertrail</li><li>云平台</li><li>…</li></ul><p><br><br><br></p><h2 id="流"><a href="#流" class="headerlink" title="流"></a>流</h2><p>Stream:</p><ul><li>Kafka</li><li>Apex</li><li>Flink</li><li>Heron</li><li>Spark</li><li>Heka</li></ul><p><br><br><br></p><h2 id="Api网关"><a href="#Api网关" class="headerlink" title="Api网关"></a>Api网关</h2><p>Api Gateway:</p><ul><li>Gloo</li><li>Ambassador</li><li>Spring Cloud</li><li>Kong</li><li>Netflix Zuul</li><li>云平台</li><li>…</li></ul><p><br><br><br></p><h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><p>Performance:</p><ul><li>NetData</li><li>Pinpoint</li><li>Datadog</li><li>AppDynamics</li><li>Apache JMeter</li><li>ab(ApacheBench)</li><li>Gatling</li></ul><p><br><br><br></p><h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><p>Monitoring:</p><ul><li>Zabbix</li><li>Nagios</li><li>Prometheus</li><li>Grafana</li><li>Netdata</li><li>Graphite</li><li>Cacti</li><li>Glances</li><li>Collectd</li><li>Ganglia</li><li>Kibana</li><li>Sensu</li></ul><p><br><br><br></p><h2 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h2><p>Backup:</p><ul><li>全量</li><li>增量</li></ul><p><br><br><br></p><hr><p><br><br><br></p><h1 id="灰度发布"><a href="#灰度发布" class="headerlink" title="灰度发布"></a>灰度发布</h1><blockquote><p>ps:<br>参考百度百科!</p></blockquote><p><br></p><p>灰度发布（金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。在其上可以进行A/B testing，即让一部分用户继续用产品特性A，一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。<br>灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。</p><p>灰度期：灰度发布开始到结束期间的这一段时间，称为灰度期。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;li&gt;GitLab&lt;/li&gt;
&lt;li&gt;GitHub&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="自动化运维" scheme="https://zhang21.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"/>
    
      <category term="运维开发" scheme="https://zhang21.github.io/tags/%E8%BF%90%E7%BB%B4%E5%BC%80%E5%8F%91/"/>
    
      <category term="Auto DevOps" scheme="https://zhang21.github.io/tags/Auto-DevOps/"/>
    
  </entry>
  
  <entry>
    <title>谏逐客书</title>
    <link href="https://zhang21.github.io/2019/02/10/%E8%B0%8F%E9%80%90%E5%AE%A2%E4%B9%A6/"/>
    <id>https://zhang21.github.io/2019/02/10/谏逐客书/</id>
    <published>2019-02-10T13:45:14.000Z</published>
    <updated>2019-03-08T09:38:42.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li><li>百度百科</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>《谏逐客书》是李斯的一篇优秀古代公文，是应用写作法定公文研究的重要内容之一。这里的“书”不是书信，而是上书、奏章，为古代臣子向君主陈述政见的一种文体，是一种臣子向帝王逐条分析事理的公文名称，与表性质类似。该文能比较充分地体现公文的一些本质属性，正是这些公文本质属性形成了该文鲜明的特色。</p><p>文章先叙述自秦穆公以来皆以客致强的历史，说明秦若无客的辅助则未必强大的道理；然后列举各种女乐珠玉虽非秦地所产却被喜爱的事实作比，说明秦王不应该重物而轻人。文章立意高深，始终围绕“大一统”的目标，从秦王统一天下的高度立论，正反论证，利害并举，说明用客卿强国的重要性。此文理足词胜，雄辩滔滔，打动了秦王嬴政，使他收回逐客的成命，恢复了李斯的官职。</p><p>李斯（约前280年－前208年），战国末年楚国上蔡（今河南驻马店上蔡县）人，秦朝丞相，中国历史上著名的政治家、文学家和书法家。李斯早年从荀卿学帝王之术，后被秦王政任为客卿。秦王政十年（前237年）李斯上《谏逐客书》反对驱逐客卿，为秦王政所采纳。他在秦王政统一六国的事业中起了较大作用。秦统一天下后，李斯与王绾、冯劫尊秦王嬴政为皇帝，被任为丞相。李斯参与制定了秦朝的法律并完善了秦朝的制度；他主张实行郡县制、废除分封制；又主张焚烧民间收藏的《诗》、《书》、百家语，禁止私学，以加强专制主义中央集权的统治；提出并且主持了文字、车轨、货币、度量衡的统一。李斯实行郡县制等政治主张，奠定了中国两千多年政治制度的基本格局。秦始皇死后，他与赵高合谋立少子胡亥为帝。后为赵高所忌，于秦二世二年（前208年）被腰斩于咸阳。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h1><p>会韩人郑国来间秦，以作注溉渠，已而觉。秦宗室大臣皆言秦王曰：诸侯人来事秦者，大抵为其主游间于秦耳。请一切逐客！李斯议亦在逐中。</p><p>斯乃上曰：</p><p>臣闻吏议逐客，窃以为过矣。昔穆公求士，西取由余于戎，东得百里奚于宛，迎蹇叔于宋，求丕豹、公孙支于晋；此五子者，不产于秦，而穆公用之，并国二十，遂霸西戎。孝公用商鞅之法，移风易俗，民以殷盛，国以富强，百姓乐用，诸侯亲服，获楚、魏之师，举地千里，至今治强。惠王用张仪之计，拔三川[15]之地，西并巴、蜀，北收上郡，南取汉中，包九夷，制鄢[18]、郢，东据成皋之险，割膏腴之壤，遂散六国之从，使之西面事秦，功施到今。昭王得范睢，废穰侯，逐华阳，强公室，杜私门，蚕食诸侯，使秦成帝业。此四君者，皆以客之功。由此观之，客何负于秦哉？向使四君却客而不内，疏士而不用；是使国无富利之实，而秦无强大之名也。</p><p>今陛下致昆山之玉，有随、和之宝，垂明月之珠，服太阿之剑，乘纤离之马，建翠凤之旗，树灵鼍之鼓；此数宝者，秦不生一焉，而陛下说之，何也？必秦国之所生然后可；则是夜光之璧，不饰朝廷；犀象之器，不为玩好；郑、魏之女，不充后宫；而骏良駃騠，不实外廄；江南金锡不为用，西蜀丹青不为采。所以饰后宫，充下陈，娱心意，说耳目者，必出于秦然后可；则是宛珠之簪，傅玑之珥，阿缟之衣，锦绣之饰，不进于前，而随俗雅化。佳冶窈窕，赵女不立于侧也。夫击瓮叩缶，弹筝搏髀，而歌呼呜呜快耳目者，真秦之声也；郑、卫、桑间、《昭虞》、《武象》者，异国之乐也。今弃击瓮而就郑、卫，退弹筝而取《昭虞》，若是者何也？快意当前，适观而已矣。今取人则不然：不问可否，不论曲直，非秦者去，为客者逐。然则是所重者，在乎色、乐、珠、玉，而所轻者在乎人民也；此非所以跨海内，制诸侯之术也！</p><p>臣闻地广者粟多，国大者人众，兵疆者则士勇；是以泰山不让土壤，故能成其大；河海不择细流，故能就其深；王者不却众庶，故能明其德；是以地无四方，民无异国，四时充美，鬼神降福，此五帝、三王之所以无敌也。今乃弃黔首以资敌国，却宾客以业诸侯，使天下之士，退而不敢西向，裹足不入秦，此所谓借寇兵而赍盗粮者也。夫物不产于秦，可宝者多；士不产于秦，而愿忠者众。今逐客以资敌国，损民以益雠，内自虚而外树怨于诸侯，求国之无危，不可得也。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="译文"><a href="#译文" class="headerlink" title="译文"></a>译文</h1><p>我听说官吏在商议驱逐客卿这件事，私下里认为是错误的。从前秦穆公寻求贤士，西边从西戎取得由余，东边从宛地得到百里奚，又从宋国迎来蹇叔，还从晋国招来丕豹、公孙支。这五位贤人，不生在秦国，而秦穆公重用他们，吞并国家二十多个，于是称霸西戎。秦孝公采用商鞅的新法，移风易俗，人民因此殷实，国家因此富强，百姓乐意为国效力，诸侯亲附归服，战胜楚国、魏国的军队，攻取土地上千里，至今政治安定，国力强盛。秦惠王采纳张仪的计策，攻下三川地区，西进兼并巴、蜀两国，北上收得上郡，南下攻取汉中，席卷九夷各部，控制鄢、郢之地，东面占据成皋天险，割取肥田沃土，于是拆散六国的合纵同盟，使他们朝西事奉秦国，功烈延续到今天。昭王得到范雎，废黜穰侯，驱逐华阳君，加强、巩固了王室的权力，堵塞了权贵垄断政治的局面，蚕食诸侯领土，使秦国成就帝王大业。这四位君主，都依靠了客卿的功劳。由此看来，客卿哪有什么对不住秦国的地方呢！倘若四位君主拒绝远客而不予接纳，疏远贤士而不加任用，这就会使国家没有丰厚的实力，而让秦国没有强大的名声了。</p><p>陛下罗致昆山的美玉，宫中有随侯之珠，和氏之璧，衣饰上缀着光如明月的宝珠，身上佩带着太阿宝剑，乘坐的是名贵的纤离马，树立的是以翠凤羽毛为饰的旗子，陈设的是蒙着灵鼍之皮的好鼓。这些宝贵之物，没有一种是秦国产的，而陛下却很喜欢它们，这是为什么呢？如果一定要是秦国出产的才许可采用，那么这种夜光宝玉，决不会成为秦廷的装饰；犀角、象牙雕成的器物，也不会成为陛下的玩好之物；郑、卫二地能歌善舞的女子，也不会填满陛下的后宫；北方的名骥良马，决不会充实到陛下的马房；江南的金锡不会为陛下所用，西蜀的丹青也不会作为彩饰。用以装饰后宫、广充侍妾、爽心快意、悦入耳目的所有这些都要是秦国生长、生产的然后才可用的话，那么点缀有珠宝的簪子，耳上的玉坠，丝织的衣服，锦绣的装饰，就都不会进献到陛下面前；那些闲雅变化而能随俗推移的妖冶美好的佳丽，也不会立于陛下的身旁。那敲击瓦器，拍髀弹筝，乌乌呀呀地歌唱，能快人耳目的，确真是秦国的地道音乐了；那郑、卫桑间的歌声，《韶虞》《武象》等乐曲，可算是外国的音乐了。如今陛下却抛弃了秦国地道的敲击瓦器的音乐，而取用郑、卫淫靡悦耳之音，不要秦筝而要《韶虞》，这是为什么呢？难道不是因为外国音乐可以快意，可以满足耳目功能的需要么？可陛下对用人却不是这样，不问是否可用，不管是非曲直，凡不是秦国的就要离开，凡是客卿都要驱逐。这样做就说明，陛下所看重的，只在珠玉声色方面；而所轻视的，却是人民士众。这不是能用来驾驭天下，制服诸侯的方法啊！</p><p>我听说田地广就粮食多，国家大就人口众，武器精良将士就骁勇。因此，泰山不拒绝泥土，所以能成就它的高大；江河湖海不舍弃细流，所以能成就它的深邃；有志建立王业的人不嫌弃民众，所以能彰明他的德行。因此，土地不分东西南北，百姓不论异国它邦，那样便会一年四季富裕美好，天地鬼神降赐福运，这就是五帝、三王无可匹敌的缘故。抛弃百姓使之去帮助敌国，拒绝宾客使之去事奉诸侯，使天下的贤士退却而不敢西进，裹足止步不入秦国，这就叫做“借武器给敌寇，送粮食给盗贼”啊。物品中不出产在秦国，而宝贵的却很多；贤士中不出生于秦，愿意效忠的很多。如今驱逐宾客来资助敌国，减损百姓来充实对手，内部自己造成空虚而外部在诸侯中构筑怨恨，那要谋求国家没有危难，是不可能的啊。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;li&gt;百度百科&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="Literature" scheme="https://zhang21.github.io/categories/Literature/"/>
    
    
      <category term="古文" scheme="https://zhang21.github.io/tags/%E5%8F%A4%E6%96%87/"/>
    
      <category term="政论文" scheme="https://zhang21.github.io/tags/%E6%94%BF%E8%AE%BA%E6%96%87/"/>
    
      <category term="李斯" scheme="https://zhang21.github.io/tags/%E6%9D%8E%E6%96%AF/"/>
    
  </entry>
  
  <entry>
    <title>本朝百年无事札子</title>
    <link href="https://zhang21.github.io/2019/02/10/%E6%9C%AC%E6%9C%9D%E7%99%BE%E5%B9%B4%E6%97%A0%E4%BA%8B%E6%9C%AD%E5%AD%90/"/>
    <id>https://zhang21.github.io/2019/02/10/本朝百年无事札子/</id>
    <published>2019-02-10T13:45:12.000Z</published>
    <updated>2019-03-08T09:24:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li><li>百度百科</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>　　《本朝百年无事札子》是北宋王安石所作奏议。全文以扬为抑，褒中有贬，在探究北宋立国以来百余年间太平无事的原因的同时，剖析了宋仁宗统治时的种种弊病；透过“百年无事”的表象揭示出危机四伏的实质，犀利地指出因循守旧、故步自封的危害；并就吏治、教育、科举、农业、财政、军事等诸方面的改革提出了自己的见解与主张。文章条理清晰，措辞委婉，情感恳切坦诚，是历代奏议中的佳作。</p><p>　　王安石（1021–1086）北宋政治家、文学家、思想家。字介甫，晚号半山。抚州临（今属江西抚州）人。庆历进士。初知鄞县，嘉祜三年（1058）上万言书，主张改革政治。熙宁二年（1069），被任为参知政事。次年拜相，推行新法，遭到反对。熙宁七年辞退，次年再相，九年再辞．退居江宁（今江苏南京），封荆国公，世称“荆公”。卒谥文。散文雄健峭拔，为“唐宋八大家”之一。其诗遒劲清新，其词风格高峻。著有《临川集》、《临川集拾遗》等。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h1><p>　　臣前蒙陛下问及本朝所以享国百年、天下无事之故。臣以浅陋，误承圣问，迫于日晷，不敢久留，语不及悉，遂辞而退。窃惟念圣问及此，天下之福，而臣遂无一言之献，非近臣所以事君之义，故敢冒昧而粗有所陈。</p><p>　　伏惟太祖躬上智独见之明，而周知人物之情伪，指挥付托必尽其材，变置施设必当其务。故能驾驭将帅，训齐士卒，外以捍诸边，内以平中国。于是除苛赋，止虐刑，废强横之藩镇，诛贪残之官吏，躬以简俭为天下先。其于出政发令之间，一以安利元元为事。太宗承之以聪武，真宗守之以谦仁，以至仁宗、英宗，无有逸德。此所以享国百年而天下无事也。</p><p>　　仁宗在位，历年最久。臣于时实备从官，施为本末，臣所亲见。尝试为陛下陈其一二，而陛下详择其可，亦足以申鉴于方今。</p><p>　　伏惟仁宗之为君也，仰畏天，俯畏人，宽仁恭俭，出于自然。而忠恕诚悫，终始如一，未尝妄兴一役，未尝妄杀一人，断狱务在生之，而特恶吏之残扰。宁屈己弃财于外敌，而终不忍加兵。刑平而公，赏重而信。纳用谏官御史，公听并观，而不蔽于偏至之谗。因任众人耳目，拔举疏远，而随之以相坐之法。盖监司之吏以至州县，无敢暴虐残酷，擅有调发，以伤百姓。自夏人顺服，蛮夷遂无大变，边人父子夫妇，得免于兵死，而中国之人，安逸蕃息，以至今日者，未尝妄兴一役，未尝妄杀一人，断狱务在生之，而特恶吏之残扰，宁屈己弃财于夷狄而不忍加兵之效也。大臣贵戚、左右近习，莫敢强横犯法，其自重慎或甚于闾巷之人。此刑平而公之效也。募天下骁雄横猾以为兵，几至百万，非有良将以御之，而谋变者辄败。聚天下财物，虽有文籍，委之府史，非有能吏以钩考，而断盗者辄发。凶年饥岁，流者填道，死者相枕，而寇攘辄得。此赏重而信之效也。大臣贵戚、左右近习，莫能大擅威福，广私货赂，一有奸慝，随辄上闻。贪邪横猾，虽间或见用，未尝得久。此纳用谏官、御史，公听并观，而不蔽于偏至之谗之效也。自县令京官以至监司台阁，升擢之任，虽不皆得人，然一时之所谓才士，亦罕蔽塞而不见收举者。此因任众人之耳目、拔举疏远而随之以相坐之法之效也。升遐之日，天下号恸，如丧考妣，此宽仁恭俭出于自然，忠恕诚悫，终始如一之效也。</p><p>　　然本朝累世因循末俗之弊，而无亲友群臣之议。人君朝夕与处，不过宦官女子，出而视事，又不过有司之细故，未尝如古大有为之君，与学士大夫讨论先王之法以措之天下也。一切因任自然之理势，而精神之运有所不加，名实之间有所不察。君子非不见贵，然小人亦得厕其间。正论非不见容，然邪说亦有时而用。以诗赋记诵求天下之士，而无学校养成之法。以科名资历叙朝廷之位，而无官司课试之方。监司无检察之人，守将非选择之吏。转徙之亟既难于考绩，而游谈之众因得以乱真。交私养望者多得显官，独立营职者或见排沮。故上下偷惰取容而已。虽有能者在职，亦无以异于庸人。农民坏于徭役，而未尝特见救恤，又不为之设官，以修其水土之利。兵士杂于疲老，而未尝申敕训练，又不为之择将，而久其疆场之权。宿卫则聚卒伍无赖之人，而未有以变五代姑息羁縻之俗。宗室则无教训选举之实，而未有以合先王亲疏隆杀之宜。其于理财，大抵无法，故虽俭约而民不富，虽忧勤而国不强。赖非夷狄昌炽之时，又无尧、汤水旱之变，故天下无事，过于百年。虽曰人事，亦天助也。盖累圣相继，仰畏天，俯畏人，宽仁恭俭，忠恕诚悫，此其所以获天助也。</p><p>　　伏惟陛下躬上圣之质，承无穷之绪，知天助之不可常恃，知人事之不可怠终，则大有为之时，正在今日。臣不敢辄废“将明”之义，而苟逃讳忌之诛。伏惟陛下幸赦而留神，则天下之福也。取进止。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="译文"><a href="#译文" class="headerlink" title="译文"></a>译文</h1><p>　　我前些天承蒙陛下问到我朝之所以统治了上百年，天下太平无事的原因。我因为浅薄无知，错蒙皇上询问，由于时间紧迫，不敢长时间留在宫中，话还来不及说完，就告辞退朝。私下想到皇上问到这个问题，是天下的福气，而我却没有一句中肯的话奉献，不是身边官员效忠君主的态度，所以敢于不揣冒昧粗略地说说我的看法。</p><p>　　我想太祖具有极高的智慧独到的见解，详尽地了解各种人物的真伪，指挥任命，一定做到人尽其才，设置变革措施，一定能够符合现实情况。所以能够驾驭将帅，练好兵卒，对外抵抗外族入侵，对内靠他们平定动乱。于是废除苛捐杂税，禁止酷刑，废除强横的藩镇势力，诛杀贪婪残暴的官吏，自身俭朴，为天下做出了榜样。太祖在制定政策发布命令的时候，一切以百姓能平安、得利为准则。太宗继承了太祖的聪慧勇武，真宗保持了太祖的谦恭仁爱，到了仁宗、英宗，没有丧失道德的地方。这就是所以能够统治上百年，而天下太平的缘故。仁宗做皇上，时间最久。我当时担任侍从官员，所作所为，从头到尾，都是我所亲眼看到的。</p><p>　　我试为陛下陈说其中的几条，陛下详加考虑，选择可取之处，也足以用作今天的借鉴。 我想仁宗作为一位君主，对上敬畏天命，对下敬畏人民；宽厚仁爱，谦恭俭朴，出于天性；忠恕诚恳，始终如一。没有随意兴办一项工程，没有随意杀过一个人。审断案件尽量使犯人能够活下来，特别憎恨官吏对百姓的残暴骚扰。宁肯委屈自己输送钱财给辽、夏，却始终不忍心对他们开战。刑罚轻缓而公正，赏赐很重而守信用。采纳谏官、御史的建议，多方面地听取和观察，而不会受到偏见的谗言的蒙蔽；依靠众人的耳闻目睹，选拔举荐关系疏远的人才，且伴随着连坐的法律。从监察官吏到州、县的官员，没有人敢暴虐残酷，擅自增加赋税徭役，来损害老百姓。自从西夏人顺服以后，蛮横的外族就没有大的变化，边境人民的父子夫妇，能够不在战争中死亡，而内地的人民，安定和平繁荣兴旺，一直到今天，这是因为没有随意兴办一项工程，没有错杀一个人，审断案件尽量使犯人能够活下来，而特别憎恨官吏对百姓的残暴、骚扰，宁肯委屈自己输送财物给辽、夏外族，而不忍心对他们开战的结果。王公大臣，皇亲国戚，身边的近臣，没有人敢强横犯法，他们自重谨慎，有的甚至超过平民百姓，这是刑罚轻缓而公正的结果。招募天下骁雄强横奸诈之徒作为士兵，几乎达到百万，没有良将来统帅他们，而阴谋叛乱的人很快就败露；聚集天下的财物，虽然有账册，把这些交给府吏管理，没有贤能的官吏来检查考核，而贪污偷盗的人马上就被揭发出来；水旱灾年，逃荒的人堵塞了道路，尸横遍野，而抢夺财物的强盗立刻就被捕获，这是重赏赐而守信用的结果。王公大臣、皇亲国戚、身边的侍从官吏，没有能大肆作威作福，到处钻营受贿，一有奸邪不法的事，随即就报告到上面；贪婪奸邪强横狡猾之徒，即使偶尔被任用，不能够长久的。这是采纳谏官、御史的建议，广泛地听取观看，而不会受到偏见的谗言所蒙蔽的结果。从县令、京官，到监司、台阁，提拔任用，虽然不能全部称职，然而，闻名一时的所谓有才能的人，也很少有埋没不被任用的。这是依靠众人的耳闻目睹，选拔推荐关系疏远的人才而伴随着连坐之法的结果。驾崩的那一天，天下的人民放声痛哭，如同死去父母，这是宽厚仁爱谦恭俭朴，出于本性，忠恕诚恳，始终如一的结果。</p><p>　　但是，本朝几代墨守衰风颓俗的弊病，却没有皇亲国戚和诸位臣子议论它。和皇上朝夕相处的，不过是宦官宫女，出来处理政事，又不过是有关部门的琐事，没有像古代大有作为的君主那样，和学士、大夫们讨论先王治理国家的方法，把它实施到天下。一切听任自然趋势，而主观努力却有所不够，名义和实际效果之间的关系，没有加以考察。君子并不是不被容纳，但小人也能够混进来。正确的论断并不是不被采纳，然而不正确的怪论也有时候被采用。凭着写诗作赋博闻强记选拔天下的士人，而没有学校培养造就人才的方法；以科名贵贱资历深浅排列在朝中的官位，而没有官吏考核实绩的制度。监司部门没有设置检查的人，守将不是选拔上来的贤臣，频繁地调动迁官，既难于考核实绩，而夸夸其谈的人，因而能够乱真。结党营私，猎取名望的人，大多数得到了显要的职务，靠自己才能奉公守职的人，也无法显示出和庸人的不同。农民受到了徭役的牵累，没有看到特别的救济抚恤，又不为他们设置官员，兴修农田水利；士兵中混杂着老弱病员，没有加以告诫整顿，又不替他们选拔将领，让他们长久地掌握守边任务。保卫都城收罗的是些兵痞无赖，没有改变五代的纵容、笼络的坏习惯；皇室中没有教导训练、选拔推荐之实，因而不能符合先王亲近疏远、升官、降职的原则。至于管理财政，基本上没有法度，所以虽然皇上俭朴节约而人民却不富足，虽然操心勤勉而国家却不强大。幸赖不是夷狄昌盛的时候，又没有尧、汤时代水涝旱灾的特殊情况，所以天下无事，超过百年。虽然是人努力的结果，也靠了天的帮助。原因是几代圣君相传，对上敬畏天命，对下敬畏人民，宽厚仁爱谦恭俭朴，忠恕诚恳，这是他们之所以获得上天帮助的缘故。</p><p>　　我想陛下身具最为圣明的资质，继承无穷无尽的帝业，知道不能长久地依靠上天的帮助，知道人事不能始终懈怠下去，那么大有作为的时候，正在今天。我不敢随便放弃臣子应尽的职责，而只顾躲避独犯忌讳所遭到的惩罚。恳请陛下宽恕我并留神我的话，那就是天下人的福气了。恰当与否，请陛下裁决。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;li&gt;百度百科&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="Literature" scheme="https://zhang21.github.io/categories/Literature/"/>
    
    
      <category term="古文" scheme="https://zhang21.github.io/tags/%E5%8F%A4%E6%96%87/"/>
    
      <category term="政论文" scheme="https://zhang21.github.io/tags/%E6%94%BF%E8%AE%BA%E6%96%87/"/>
    
      <category term="王安石" scheme="https://zhang21.github.io/tags/%E7%8E%8B%E5%AE%89%E7%9F%B3/"/>
    
  </entry>
  
  <entry>
    <title>六国论</title>
    <link href="https://zhang21.github.io/2019/02/10/%E5%85%AD%E5%9B%BD%E8%AE%BA/"/>
    <id>https://zhang21.github.io/2019/02/10/六国论/</id>
    <published>2019-02-10T13:25:13.000Z</published>
    <updated>2019-03-08T09:29:44.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li><li>百度百科</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>《六国论》是苏洵政论文代表作品。《六国论》提出并论证了六国灭亡“弊在赂秦”的精辟论点，“借古讽今”，抨击宋王朝对辽和西夏的屈辱政策，告诫北宋统治者要吸取六国灭亡的教训，以免重蹈覆辙。</p><p>苏洵（1009—1066年），北宋著名散文家，字明允，号老泉，眉州眉山（今四川省眉山县）人。相传二十七岁时才发愤为学，应进士和茂才异等考试皆未中。于是愤而自焚平日所著文章，再度闭门潜心读书，终于博通六艺及诸子百家著作，撰写文章下笔顷时数千言。嘉祐间，得当时名盛一时的翰林学士欧阳修推誉，以文章著名于世。曾任秘书省校书郎、霸州文安县主簿。后与姚辟同修礼书《太常因革礼》一百卷，书成后不久去世。他主张抵抗辽的攻掠，对大地主的土地兼并、政治特权有所不满。为文擅长策论，语言明畅，笔力雄健，奔腾驰骋，纵横捭阖，老辣犀利，很有战国纵横家笔意。与其子轼、辙，合称“三苏”，俱被列入“唐宋八大家”。有《嘉祐集》行世。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h1><p>六国破灭，非兵不利，战不善，弊在赂秦。赂秦而力亏，破灭之道也。或曰：“六国互丧，率赂秦耶？”曰：“不赂者以赂者丧，盖失强援，不能独完，故曰弊在赂秦也。”</p><p>秦以攻取之外，小则获邑，大则得城，较秦之所得，与战胜而得者，其实百倍；诸侯之所亡，与战败而亡者，其实亦百倍。则秦之所大欲，诸侯之所大患，固不在战矣。思厥先祖父，暴霜露，斩荆棘，以有尺寸之地。子孙视之不甚惜，举以予人，如弃草芥。今日割五城，明日割十城，然后得一夕安寝。起视四境，而秦兵又至矣。然则诸侯之地有限，暴秦之欲无厌，奉之弥繁，侵之愈急，故不战而强弱胜负已判矣。至于颠覆，理固宜然。古人云：“以地事秦，犹抱薪救火，薪不尽，火不灭。”此言得之。</p><p>齐人未尝赂秦，终继五国迁灭，何哉？与嬴而不助五国也。五国既丧，齐亦不免矣。燕、赵之君，始有远略，能守其土，义不赂秦。是故燕虽小国而后亡，斯用兵之效也。至丹以荆卿为计，始速祸焉。[5]赵尝五战于秦，二败而三胜。后秦击赵者再，李牧连却之。洎牧以谗诛，邯郸为郡；惜其用武而不终也。</p><p>且燕、赵处秦革灭殆尽之际，可谓智力孤危，战败而亡，诚不得已。向使三国各爱其地，齐人勿附于秦，刺客不行，良将犹在，则胜负之数，存亡之理，当与秦相较，或未易量。</p><p>呜呼！以赂秦之地，封天下之谋臣；以事秦之心，礼天下之奇才；并力西向，则吾恐秦人食之不得下咽也。悲夫！有如此之势，而为秦人积威之所劫，日削月割，以趋于亡，为国者无使为积威之所劫哉！</p><p>夫六国与秦皆诸侯，其势弱于秦，而犹有可以不赂而胜之之势；茍以天下之大，而从六国破亡之故事，是又在六国下矣！</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="译文"><a href="#译文" class="headerlink" title="译文"></a>译文</h1><p>六国灭亡，不是武器不锐利，仗打得不好，弊病在于割地贿赂秦国。割地贿赂秦国，自己的力量就亏损了，这是灭亡的原因。有人说：“六国相继灭亡，全都是由于割地贿赂秦国吗？”回答说：“不割地贿赂秦国的国家因为割地贿赂秦国的国家而灭亡。因为他们失去了强有力的外援，不能单独保全。所以说：‘弊病在于割地贿赂秦国’啊！”</p><p>秦国除用攻战的方法取得土地之外（还得到诸侯的割地贿赂），小的就获得城镇，大的就获得都市，把秦国由受贿赂得到的土地与战胜而得到的土地比较，实际上有一百倍，把诸侯贿赂秦国所失去的土地与战败所失去的土地比较，实际上也有一百倍。那么秦国最大的欲望，诸侯最大的祸患，当然就不在于战争了。回想他们的祖辈父辈，冒着霜露，披荆斩棘，因而才有一点点土地。可是子孙们看待它却很不珍惜，拿它来送人，就像抛弃小草一样。今天割去五座城，明天割去十座城，然后才能睡上一夜安稳觉。待起床一看四周边境，秦国的军队又打来了。那么，诸侯的土地有限，暴秦的欲望没有满足；谁送给它土地越多，它侵犯谁就越急。所以不用打仗，谁强谁弱、谁胜谁败就已分得清清楚楚了。六国落到灭亡的地步，按理本来应当这样。古人说：“用土地侍奉秦国，就像抱着柴草救火，柴草没有烧完，火就不会熄灭。”这话说得在理啊！</p><p>齐国不曾割地贿赂秦国，最后也随着五国灭亡，为什么呢？这是因为它跟秦国交好而不帮助五国啊。五国灭亡之后，齐国也就不能幸免了。燕国和赵国的君主，起初有远大的谋略，能够守住自己的土地，坚持正义不贿赂秦国。因此燕国虽然是个小国，却灭亡在后，这是用兵抵抗的效果啊。到了燕太子丹用派遣荆轲刺杀秦王作为对付秦国的策略，才招致灭亡的祸患。赵国曾经与秦国多次作战，败少胜多。后来秦国又两次攻打赵国，李牧接连打退了它。等到李牧因受谗言被赵王杀害，都城邯郸就变成秦国的一个郡，可惜它用兵抵抗却没能坚持到底啊。况且燕赵正处在其他国家被消灭了的时候，可说是智谋已尽，力量单薄，战败而亡国，实在是没有办法的事啊。假使当初韩、魏、楚三国都各自珍惜自己的土地，齐国不依附秦国，燕国的刺客不去秦国，赵国的良将李牧还活着，那么胜败存亡的命运，如果与秦国较量，也许还不容易估量呢。</p><p>唉！如果六国把贿赂秦国的土地封赏给天下的谋臣，用侍奉秦国的心意礼遇天下非凡的人才，齐心协力向西对付秦国，那么我担心秦国人连饭也咽不下喉呢。可悲啊！有这样的形势，却被秦国积久的威势所胁制，土地天天削减，月月割让，以至于走向灭亡。治理国家的人切不要让自己被敌人积久的威势所胁制啊！</p><p>六国和秦国都是诸侯，他们的势力比秦国弱，可是还有能够不割地贿赂而战胜秦国的形势。如果凭借偌大国家，却自取下策反而重蹈六国灭亡的覆辙，这就又在六国之下了！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;li&gt;百度百科&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="Literature" scheme="https://zhang21.github.io/categories/Literature/"/>
    
    
      <category term="苏洵" scheme="https://zhang21.github.io/tags/%E8%8B%8F%E6%B4%B5/"/>
    
      <category term="古文" scheme="https://zhang21.github.io/tags/%E5%8F%A4%E6%96%87/"/>
    
      <category term="政论文" scheme="https://zhang21.github.io/tags/%E6%94%BF%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>上仁宗皇帝言事书</title>
    <link href="https://zhang21.github.io/2019/02/10/%E4%B8%8A%E4%BB%81%E5%AE%97%E7%9A%87%E5%B8%9D%E8%A8%80%E4%BA%8B%E4%B9%A6/"/>
    <id>https://zhang21.github.io/2019/02/10/上仁宗皇帝言事书/</id>
    <published>2019-02-10T13:15:11.000Z</published>
    <updated>2019-02-11T01:22:31.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li><li>百度百科</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>　　王安石（1021年12月19日－1086年5月21日），字介甫，号半山，临川盐阜岭（今江西省抚州市东乡县）人，生于宋真宗天禧五年，卒于宋哲宗元祐元年，由于被封为荆国公，后人常称他为“王荆公”。王安石是北宋著名的政治家、文学家、思想家，实官至司空、尚书左仆射、观文殿大学士、镇南军节度使。他去世后被追赠为太傅，谥曰文，享年66岁。</p><p>　　嘉佑三年（1058年），调为度支判官，王安石进京述职，作长达万言的《上仁宗皇帝言事书》，系统地提出了变法主张。在此次上疏中，王安石总结了自己多年的地方官经历，指出国家积弱积贫的现实：经济困窘、社会风气败坏、国防安全堪忧，认为症结的根源在于为政者不懂得法度，解决的根本途径在于效法古圣先贤之道、改革制度，进而提出了自己的人才政策和方案的基本设想，建议朝廷改革取士、重视人才。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h1><p>　　臣愚不肖，蒙恩备使一路，今又蒙恩召还阙廷，有所任属，而当以使事归报陛下。不自知其无以称职，而敢缘使事之所及，冒言天下之事，伏惟陛下详思而择其中，幸甚。</p><p>　　臣窃观陛下有恭俭之德，有聪明睿智之才，夙兴夜寐，无一日之懈，声色狗马，观游玩好之事，无纤介之蔽，而仁民爱物之意，孚于天下，而又公选天下之所愿以为辅相者，属之以事，而不贰于谗邪倾巧之臣，此虽二帝、三王之用心，不过如此而已，宜其家给人足，天下大治。而效不至于此，顾内则不能无以社稷为忧，外则不能无惧于夷狄，天下之财力日以困穷，而风俗日以衰坏，四方有志之士，諰諰然常恐天下之久不安。此其故何也？患在不知法度故也。</p><p>　　今朝廷法严令具，无所不有，而臣以谓无法度者，何哉？方今之法度，多不合乎先王之政故也。孟子曰：「有仁心仁闻，而泽不加于百姓者，为政不法于先王之道故也。」以孟子之说，观方今之失，正在于此而已。</p><p>　　夫以今之世，去先王之世远，所遭之变，所遇之势不一，而欲一二修先王之政，虽甚愚者，犹知其难也。然臣以谓今之失，患在不法先王之政者，以谓当法其意而已。夫二帝、三王，相去盖千有余载，一治一乱，其盛衰之时具矣。其所遭之变，所遇之势，亦各不同，其施设之方亦皆殊，而其为天下国家之意，本末先后，未尝不同也。臣故曰：当法其意而已。法其意，则吾所改易更革，不至乎倾骇天下之耳目，嚣天下之口，而固已合乎先王之政矣。</p><p>　　虽然，以方今之势揆之，陛下虽欲改易更革天下之事，合于先王之意，其势必不能也。陛下有恭俭之德，有聪明睿智之才，有仁民爱物之意，诚加之意，则何为而不成，何欲而不得？然而臣顾以谓陛下虽欲改易更革天下之事，合于先王之意，其势必不能者，何也？以方今天下之才不足故也。</p><p>　　臣尝试窃观天下在位之人，未有乏于此时者也。夫人才乏于上，则有沉废伏匿在下，而不为当时所知者矣。臣又求之于闾巷草野之间，而亦未见其多焉。岂非陶冶而成之者非其道而然乎？臣以谓方今在位之人才不足者，以臣使事之所及，则可知矣。今以一路数千里之间，能推行朝廷之法令，知其所缓急，而一切能使民以修其职事者甚少，而不才苟简贪鄙之人，至不可胜数。其能讲先王之意以合当时之变者，盖阖郡之间，往往而绝也。朝廷每一令下，其意虽善，在位者犹不能推行，使膏泽加于民，而吏辄缘之为奸，以扰百姓。臣故曰：在位之人才不足，而草野闾巷之间，亦未见其多也。夫人才不足，则陛下虽欲改易更革天下之事，以合先王之意，大臣虽有能当陛下之意而欲领此者，九州之大，四海之远，孰能称陛下之指，以一二推行此，而人人蒙其施者乎？臣故曰：其势必未能也。孟子曰：「徒法不能以自行。」非此之谓乎？然则方今之急，在于人才而已。诚能使天下人才众多，然后在位之才可以择其人而取足焉。在位者得其才矣，然后稍视时势之可否，而因人情之患苦，变更天下之弊法，以趋先王之意，甚易也。今之天下，亦先王之天下，先王之时，人才尝众矣，何至于今而独不足乎？故曰：陶冶而成之者，非其道故也。</p><p>　　商之时，天下尝大乱矣。在位贪毒祸败，皆非其人，及文王之起，而天下之才尝少矣。当是时，文王能陶冶天下之士，而使之皆有士君子之才，然后随其才之所有而官使之。诗曰：「岂弟君子，遐不作人」。此之谓也。及其成也，微贱兔置之人，犹莫不好德，兔置之诗是也。又况于在位之人乎？夫文王惟能如此，故以征则服，以守则治。诗曰：「奉璋峨峨，髦士攸宜。」又曰：「周王于迈，六师及之。」文言王所用，文武各得其才，而无废事也。及至夷、厉之乱，天下之才，又尝少矣。至宣王之起，所与图天下之事者，仲山甫而已。故诗人叹之曰：「德輶如毛，维仲山甫举之，爱莫助之。」盖闵人才之少，而山甫之无助也。宣王能用仲山甫，推其类以新美天下之士，而后人才复众。于是内修政事，外讨不庭，而复有文、武之境土。故诗人美之曰：「薄言采芑，于彼新田，于此葘亩。」言宣王能新美天下之士，使之有可用之才，如农夫新美其田，而使之有可采之芑也。由此观之，人之才，未尝不自人主陶冶而成之者也。</p><p>　　所谓陶冶而成之者何也？亦教之、养之、取之、任之有其道而已。</p><p>　　所谓教之之道何也？古者天子诸侯，自国至于乡党皆有学，博置教道之官而严其选。朝廷礼乐、刑政之事，皆在于学，学士所观而习者，皆先王之法言德行治天下之意，其材亦可以为天下国家之用。苟不可以为天下国家之用，则不教也。苟可以为天下国家之用者，则无法在于学。此教之之道也。</p><p>　　所谓养之之道何也？饶之以财，约之以礼，裁之以法也。何谓饶之以财？人之情，不足于财，则贪鄙苟得，无所不至。先王知其如此，故其制禄，自庶人之在官者，其禄已足以代其耕矣。由此等而上之，每有加焉，使其足以养廉耻，而离于贪鄙之行。犹以为未也，又推其禄以及其子孙，谓之世禄。使其生也，既于父子、兄弟、妻子之养，婚姻、朋友之接，皆无憾矣；其死也，又于子孙无不足之忧焉。何谓约之以礼？人情足于财而无礼以节之，则又放僻邪侈，无所不至。先王知其如此，故为之制度。婚丧、祭养、燕享之事，服食、器用之物，皆以命数为之节，而齐之以律度量衡之法。其命可以为之，而财不足以具，则弗具也；其财可以具，而命不得为之者，不使有铢两分寸之加焉。何谓裁之以法？先王于天下之士，教之以道艺矣，不帅教则待之以屏弃远方终身不齿之法。约之以礼矣，不循礼则待之以流、杀之法。《王制》曰：「变衣服者，其君流」，《酒诰》曰：「厥或诰曰『群饮，汝勿佚。尽拘执以归于周，予其杀！』」夫群饮、变衣服，小罪也；流、杀，大刑也。加小罪以大刑，先王所以忍而不疑者，以为不如是，不足以一天下之俗而成吾治。夫约之以礼，裁之以法，天下所以服从无抵冒者，又非独其禁严而治察之所能致也。盖亦以吾至诚恳恻之心，力行而为之倡。凡在左右通贵之人，皆顺上之欲而服行之，有一不帅者，法之加必自此始。夫上以至诚行之，而贵者知避上之所恶矣，则天下之不罚而止者众矣。故曰：此养之之道也。</p><p>　　所谓取之之道者，何也？先王之取人也，必于乡党，必于痒序，使众人推其所谓贤能，书之以告于上而察之。诚贤能也，然后随其德之大小、才之高下而官使之。所谓察之者，非专用耳目之聪明，而私听于一人之口也。欲审知其德，问以行；欲审知其才，问以言。得其言行，则试之以事。所谓察之者，，试之以事是也。虽尧之用舜，亦不过如此而已，又况其下乎？若夫九州之大，四海之远，万官亿丑之贱，所须士大夫之才则众矣，有天下者，又不可以一二自察之也，又不可以偏属于一人，而使之于一日二日之间考试其行能而进退之也。盖吾已能察其才行之大者，以为大官矣，因使之取其类以持久试之，而考其能者以告于上，而后以爵命、禄秩予之而已。此取之之道也。</p><p>　　所谓任之之道者，何也？人之才德，高下厚薄不同，其所任有宜有不宜。先王知其如此，故知农者以为后稷，知工者以为共工。其德厚而才高者以为之长。德薄而才下者以为之佐属。又以久于其职，则上狃习而知其事，下服驯而安其教，贤者则其功可以至于成，不肖者则其罪可以至于着，故久其任而待之以考绩之法。夫如此，故智能才力之士，则得尽其智以赴功，而不患其事之不终，其功之不就也。偷惰苟且之人，虽欲取容于一时，面顾戮辱在其后，安敢不勉乎！若夫无能之人，固知辞避而去矣。居职任事之日久，不胜任之罪，不可以幸而免故也。彼且不敢冒而知辞避矣，尚何有比周、谗谄、争进之人乎？取之既已详，使之既已当，处之既已久，至其任之也又专焉，而不一二以法束缚之，而使之得行其意，尧、舜之所以理百官而熙众工者，以此而已。书曰：「三载考绩，三考，黜陟幽明。」此之谓也。然尧、舜之时，其所黜者则闻之矣，盖四凶是也。其所陟者，则皋陶、稷、契皆终身一官而不徙。盖其所谓陟者，特加之爵命、禄赐而已耳。此任之之道也。</p><p>　　夫教之、养之、取之、任之之道如此，而当时人君，又能与其大臣，悉其耳目心力，至诚恻怛，思念而行之，此其人臣之所以无疑，而于天下国家之事，无所欲为而不得也。</p><p>　　方今州县虽有学，取墙壁具而已，非有教导之官，长育人才之事也。唯太学有教导之官，而亦未尝严其选。朝廷礼乐刑政之事，未尝在于学。学者亦漠然自以礼乐刑政为有司之事，而非</p><p>　　己所当知也。学者之所教，讲说章句而已。讲说章句，固非古者教人之道也。而近岁乃始教之以课试之文章。夫课试之文章，非博诵强学穷日之力则不能。及其能工也，大则不足以用天下国家，小则不足以为天下国家之用。故虽白首于庠序，穷日之力以帅上之教，及使之从政，则茫然不知其方者，皆是也。盖今之教者，非特不能成人之才而已，又从而困苦毁坏之，使不得成才者，何也？夫人之才，成于专而毁于杂。故先王之处民才，处工于官府，处农于畎亩，处商贾于肆，而处士于庠序，使各专其业而不见异物，惧异物之足以害其业也。所谓士者，又非特使之不得见异物而已，一示之以先王之道，而百家诸子之异说，皆屏之而莫敢习者焉。今士之所宜学者，天下国家之用也。今悉使置之不教，而教之以课试之文章，使其耗精疲神，穷日之力以从事于此。及其任之以官也，则又悉使置之，而责之以天下国家之事。夫古之人，以朝夕专其业于天下国家之事，而犹才有能有不能，今乃移其精神，夺其日力，以朝夕从事于无补之学，及其任之以事，然后卒然责之以为天下国家之用，宜其才之足以有为者少矣。臣故曰：非特不能成人之才，又从而困苦毁坏之，使不得成才也。又有什害者，先王之时，士之所学者，文武之道也。士之才，有可以为公卿大夫，有可以为士。其才之大小、宜不宜则有矣，至于武事，则随其才之大小，未有不学者也。故其大者，居则为六官之卿，出则为六军之将也；其次则比、闾、族、党之师，亦皆卒、两、师、旅之帅也。故边疆、宿卫，皆得士大夫为之，而小人不得奸其任。今之学者，以为文武异事，吾知治文事而已，至于边疆、宿卫之任，则推而属之于卒伍，往往天下奸悍无赖之人。苟其才行足以自托于乡里者，未有肯去亲戚而从召募者也。边疆、宿卫，此乃天下之重任，而人主之所当慎重者也。故古者教士，以射、御为急，其他伎能，则视其人才之所宜，而后教之，其才之所不能，则不强也。至于射，则为男子之事。苟人之生，有疾则已，苟无疾，未有去射而不学者也。在庠序之间，固常从事于射也。有宾客之事则以射，有祭祀之事则以射，别士之行同能偶则以射，于礼乐之事，未尝不寓以射，而 射亦未尝不在于礼乐、祭祀之间也。易曰：「弧矢之利，以威天下。」先王岂以射为可以习揖让之仪而已乎？固以为射者武事之尤大，而威天下、守国家之具也。居则以是习礼乐，出则以是从战伐。士既朝夕从事于此而能者众，则边疆、宿卫之任，皆可以择而取也。夫士尝学先王之道，其行义尝见推于乡党矣，然后因其才而托之以边疆、宿卫之士，此古之人君，所以推干戈以属之人，而无内外之虞也。今乃以夫天下之重任，人主所当至慎之选，推而属之奸悍无赖，才行不足自托于乡里之人，此方今所以諰諰然常抱边疆之忧，而虞宿卫之不足恃以为安也。今孰不知边疆、宿卫之士不足恃以为安哉？顾以为天下学士以执兵为耻，而亦未有能骑射行阵之事者，则非召募之卒伍，孰能任其事者乎？夫不严其教，高其选，则士之以执兵为耻，而未尝有能骑射行阵之事，固其理也。凡此皆教之非其道也。</p><p>　　方今制禄，大抵皆薄。自非朝廷侍从之列，食口稍众，未有不兼农商之利而能充其养者也。其下州县之吏，一月所得，多者钱八九千，少者四五千，以守选、待除、守阙通之，盖六七年而后得三年之禄，计一月所得，乃实不能四五千，少者乃实不能及三四千而已。虽厮养之给，亦窘于此矣，而其养生、丧死、婚姻、葬送之事，皆当出于此。夫出中人之上者，虽穷而失为君子；出中人以下者，虽泰而不失为小人。唯中人不然，穷则为小人，泰则为君子。计天下之士，出中人之上下者，千百而无十一，穷而为小人，泰而为君子者，则天下皆是也。先王以为众不可以力胜也，故制行不以己，而以中人为制，所以因其欲而利道之，以为中人之所能守，则其志可以行乎天下，而推之后世。以今之制禄，而欲士之无毁廉耻，盖中人之所不能也。故今官大者，往往交赂遗、营赀产，以负贪污之毁；官小者，贩鬻、乞丐、无所不为。夫士已尝毁廉耻以负累于世矣，则其偷堕取容之意起，而矜奋自强之小息，则职业安得而不弛，治道何从而兴乎？又况委法受赂，侵牟百姓者，往往而是也。此所谓不能饶之以财也。</p><p>　　婚丧、奉养、服食、器用之物，皆无制度以为之节，而天下以奢为荣，以俭为耻。苟其财之可以具，则无所为而不得，有司既不禁，而人又以此为荣。苟其财不足，而不能自称于流俗，则其婚丧之际，往往得罪于族人婚姻，而人以为耻矣。故富者贪而不知止，贫者则强勉其不足以追之。此士之所以重困，而廉耻之心毁也。凡此所谓不能约之以礼也。</p><p>　　方今陛下躬行俭约，以率天下，此左右通贵之臣所亲见。然而其闺门之内，奢靡无节，犯上之所恶，以伤天下之教者，有已甚者矣。未闻朝廷有所放绌，以示天下。昔周之人，拘群饮而被之以杀刑者，以为酒之末流生害，有至于死者众矣，故重禁其祸之所自生。重禁祸之所自生，故其施刑极省，而人之抵于祸败者少矣。今朝廷之法所尤重者，独贪吏耳。重禁贪吏，而轻奢靡之法，此所谓禁其末而弛其本。然而世之识者，以为方今官冗，而县官财用已不足以供之，其亦蔽于理矣。今之入官诚冗矣，然而前世置员盖其少，而赋禄又如此之薄，则财用之所不足，盖亦有说矣。吏禄岂足计哉？臣于财利，固未尝学，然窃观前世治财之大略矣。盖因天下之力，以生天下之财，取天下之财，以供天下之费。自古治世，未尝以不足为天下之公患也。患在治财无其道耳。今天下不见兵革之具，而元元安土乐业，人致其力，以生天下之财，然而公私尝以困穷为患者，殆亦理财未得其道，而有司不能度世之宜而通其变耳。诚能理财以其道，而通其变，臣虽愚，固知增吏禄不足以伤经费也。方今法严令具，所以罗天下之士，可主谓密矣。然而亦尝教之以道艺，而有不帅教之刑以待之乎？亦尝约之以制度，而有不循理之刑以待之乎？亦尝任之以职事，而有不任事之刑以待之乎？夫不先教之以道艺，诚不可以诛其不帅教；不先约之以制度，诚不可以诛其不循理；不先任之以职事，诚不可以诛其不任事。此三者，先王之法所先急也，今皆不可得诛，而薄物细故，非害治之急者，为之法禁，月异而岁不同，为束者至于不可胜记，又况能一二避之而无犯者乎？此法令所以滋而不行，小人有幸而免者，君子有不幸而及者焉。此所谓不能裁之以刑也。凡此皆治之非其道也。</p><p>　　方今取士，强记博诵而略通于文辞，谓之茂才异等、贤良方正。茂才异等、贤良方正者，公卿之选也。记不必强，诵不必博，略通于文辞，而又尝学诗赋，则谓之进士。进士之高者，亦公卿之选也。夫此二科所得之技能，不足以为公卿，不待论而后可知。而世之议者，乃以为吾常以此取天下之士，而才之可以为公卿者，常出于此，不必法古之取人然后得士也。其亦蔽于理矣。先王之时，尽所以取人之道，犹惧贤者之难进，而不肖者之杂于其间也。今悉废先王所以取士之道，而驱天下之才士，悉使为贤良、进士，则士之才可以为公卿者，固宜为贤良、进士，而贤良、进士亦固宜有时而得才之可以为公卿者也。然而不肖者，苟能雕虫篆刻之学，以此进至乎公卿，才之可以为公卿者，困于无补之学，而以此绌死于岩野，盖十八九矣。夫古之人有天下者，其所慎择者，公卿而已。公卿既得其人，因使推其类以聚于朝迁，则百司庶府，无不得其人也。今使不肖之人，幸而至乎公卿，因得推其类聚之朝廷，此朝廷所以多不肖之人，而虽有贤智，往往困于无助，不得行其意也。且公卿之不肖，既推其类以聚于朝廷，朝廷之不肖，又推其类以备四方之任使；四方之任使者，又各推其不肖以布于州郡。则虽有同罪举官之科，岂足恃哉？适足以为不肖者之资而已。其次九经、五经、学究、明法之科，朝廷固已尝患其无用于世，而稍责之以大义矣。然大义之所得，未有以贤于故也。今朝廷又开明经之选，以进经术之士。然明经之所取，亦记诵而略通于文辞者，则得之矣。彼通先王之意，而可以施于天下国家之用者，顾未必得与于此选也。其次则恩泽子弟，庠序不教之以道艺，官司不考问其才能，父兄不保任其行义，而朝廷辄以官予之，而任之以事。武王数纣之罪，则曰：「官人以世。」夫官人以世，而不计其才行，此乃纣之所以乱亡之道，而治世之所无也。又其次曰流外。朝廷固已挤之于廉耻之外，而限其进之路矣，顾属之以州县之事，使之临士民之上。岂所谓以贤治不肖者乎？以臣使事之所及，一路数千里之间，州县之吏，出于流外者，往往而有，可属任以事者，殆无二三，而当防闲其奸者，皆是也。盖古者有贤不肖之分，而无流品之别。故孔子之圣，而尝为季氏吏，盖虽为吏，而亦不害其为公卿。及后世有流品之别，则凡在流外者，其所成立，固尝自置于廉耻之外，而无高人之意矣。夫以近世风俗之流靡，自虽士大夫之才，势足以进取，而朝廷尝奖之以礼义者，晚节末路，往往怵而为奸，况又其素所成立，无高人之意，而朝廷固已挤之于廉耻之外，限其进取者乎？其临人亲职，放僻邪侈，固其理也。至于边疆、宿卫之选，则臣固已言其失矣。凡此皆取之非其道也。</p><p>　　方今取之既不以其道，至于任人，又不问其德之所宜，而问其出身之后先，不论其才之称否，而论其历任之多少。以文学进者，且使之治财。已使之治财矣，又转而使之典狱。已使之典狱矣，又转而使之治礼。是则一人之身，而责之以百官之所能备，宜其人才之难为也。夫责人以其所难为，则人之能为者少矣。人之能为者少，则相率而不为。故使之典礼，未尝以不知礼为忧，以今之典礼者未尝学礼故也。使之典狱，未尝以不知狱为耻，以今之典狱者，未尝学狱故也。天下之人，亦已渐渍于失教，被服于成俗，见朝廷有所任使，非其资序，则相议而讪之，至于任使之不当其才，未尝有非之者也。且在位者数徙，则不得久于其官，故上不能狃习而知其事，下不肯服驯而安其教，贤者则其功不可以及于成，不肖者则其罪不可以至于着。若夫迎新将故之劳，缘绝簿书之弊，固其害之小者，不足悉数也。设官大抵皆当久于其任，而至于所部者远，所任者重，则尤宜久于其官，而后可以责其有为。而方今尤不得久于其官，往往数日辄迁之矣。</p><p>　　取之既已不祥，使之既已不当，处之既已不久，至于任之则又不专，而又一二以法束缚之，使不得行其意，臣固知当今在位多非其人，稍假借之权，而不一二以法束缚之，则放恣而无不为。虽然，在位非其人，而恃法以为治，自古及今，未有能治者也。即使在位皆得其人矣，而一二以法束缚之，不使之得行其意，亦自古及今，未有能治者也。夫取之既已不详，使之既已不当，处之既已不久，任之又不专，而一二以法束缚之，故虽贤者在位，能者在职，与不肖而无能者，殆无以异。夫如此，故朝廷明知其贤能足以任事，苟非其资序，则不以任事而辄进之，虽进之，士犹不服也。明知其无能而不肖，苟非有罪，为在事者所劾，不敢以其不胜任而辄退之，虽退之，士犹不服也。彼诚不肖而无能，然而士不服者何也？以所谓贤能者任其事，与不肖而无能者，亦无以异故也。臣前以谓不能任人以职事，而无不任事之刑以待之者，盖谓此也。</p><p>　　夫教之、养之、取之、任之，有一非其道，则足以败乱天下之人才，又况兼此四者而有之？则在位不才、苟简、贪鄙之人，至于不可胜数，而草野闾巷之间，亦少可任之才，固不足怪。诗曰：「国虽靡止，或圣或否。民虽靡膴，或哲或谋，或肃或艾。如彼泉流，无沦胥以败。」此之谓也。</p><p>　　夫在位之人才不足矣，而闾巷草野之间，亦少可用之才，则岂特行先王之政而不得也，社稷之托，封疆之守，陛下其能久以天幸为常，而无一旦之忧乎？盖汉之张角，三十六万同日而起，而所在郡国，莫能发其谋；唐之黄巢，横行天下，而所至将吏，无敢与之抗者。汉、唐之所以亡，祸自此始。唐既亡矣，陵夷以至五代，而武夫用事，贤者伏匿消沮而不见，在位无复有知君臣之义、上下之礼者也。当是之时，变置社稷，盖甚于弈棋之易，而元元肝脑涂地，幸而不转死于沟壑者无几耳！夫人才不足，患盖如此，而方今公卿大夫，莫肯为陛下长虑后顾，为宗庙万世计，臣切惑之。昔晋武帝趣过目前，而不为子孙长远之谋，当时在位，亦皆偷合苟容，而风俗荡然，弃礼义，捐法制，上下同失，莫以为非，有识固知其将必乱矣。而其后果海内大扰，中国列于夷狄者，二百余年。伏惟三庙祖宗神灵所以付属陛下，固将为万世血食，而大庇元元于无穷也。臣愿陛下鉴汉、唐、五代之所以乱亡，惩晋武苟且因循之祸，明诏大臣，思所以陶成天下之才，虑之以谋，计之以数，为之以渐，期为合于当世之变，而无负于先王之意，则天下之人才不胜用矣。人才不胜用，则陛下何求而不得，何欲而不成哉？夫虑之以谋，计之以数，为之以渐，则成天下之才甚易也。</p><p>　　臣始读孟子，见孟子言王政之易行，心则以为诚然。及见与慎子论齐、鲁之地，以为先王之制国，大抵不过百里者，以为今有王者起，则凡诸侯之地，或千里，或五百里，皆将损之至于数十百里而后止。于是疑孟子虽贤，其仁智足以一天下，亦安能毋劫之以兵革，而使数百千里之强国，一旦肯损其地之十八九，而比于先王之诸侯？至其后，观汉武帝用主父偃之策，令诸侯王地悉得推恩分其子弟，而汉亲临定其号名，辄别属汉。于是诸侯王之子弟，各有分土，而势强地大者，卒以分析弱小。然后知虑之以谋，计之以数，为之以渐，则大者固可使小，强者固可使弱，而不至乎倾骇变乱败伤之衅。孟子之言不为过。又况今欲改易更革，其势非若孟子所为之难也。臣故曰：虑之以谋，计之以数，为之以渐，则其为什易也。</p><p>　　然先王之为天下，不患人之不为，而患人之不能，不患人之不能，而患己之不勉。何谓不患人之不为，而患人之不能？人之情所愿得者，善行、美名、尊爵、厚利也，而先王能操之以临天下之士。天下之士，有能遵之以治者，则悉以其所愿得者以与之。士不能则已矣，苟能，则孰肯舍其所愿得，而不自勉以为才？故曰：不患人之不为，患人之不能。何谓不患人之不能，而患己之不勉？先王之法，所以待人者尽矣，自非下愚不可移之才，未有不能赴者也。然而不谋之以至诚恻怛之心，亦未有能力行而应之者。故曰：不患人之不能，而患己之不勉。陛下诚有意乎成天下之才，则臣愿陛下勉之而已。</p><p>　　臣又观朝廷异时欲有所施为变革，其始计利害未尝熟也，顾一有流俗侥幸之人不悦而非之，则遂止而不敢为。夫法度立，则人无独蒙其幸者，故先王之政，虽足以利天下，而当其承弊坏之后，侥幸之时，其创法立制，未尝不艰难也。以其创法立制，而天下侥幸之人亦顺悦以趋之，无有龃龉，则先王之法，至今存而不废矣。惟其创法立制之艰难，而侥幸之人不肯顺悦而趋之，故古之人欲有所为，未尝不先之以征诛，而后得其意。诗曰：「是伐是肆，是绝是忽，四方以无拂。」此言文王先征诛而后得意于天下也。夫先王欲立法度，以变衰坏之俗而成人之才，虽有征诛之难，犹忍而为之，以为不若是，不可以有为也。及至孔子，以匹夫游诸侯，所至则使其君臣捐所习，逆所顺，强所劣，憧憧如也，卒困于排逐。然孔子亦终不为之变，以为不如是，不可以有为。此其所守，盖与文王同意。夫在上之圣人，莫如文王，在下之圣人，莫如孔子，而欲有所施为变革，则其事盖如此矣。今有天下之势，居先王之位，创立法制，非有征诛之难也。虽有侥幸之人不悦而非之，固不胜天下顺悦之人众也。然而一有流俗侥幸不悦之言，则遂止而不敢为者，惑也。陛下诚有意乎成天下之才，则臣又愿断之而已。</p><p>　　夫虑之以谋，计之以数，为之以渐，而又勉之以成，断之以果，然而犹不能成天下之才，则以臣所闻，盖未有也。</p><p>　　然臣之所称，流俗之所不讲，而今之议者以谓迂阔而熟烂者也。窃观近世士大夫所欲悉心力耳目以补助朝廷者有矣。彼其意，非一切利害，则以为当世所不能行。士大夫既以此希世，而朝廷所取于天下之士，亦不过如此。至于大伦大法，礼义之际，先王之所力学而守者，盖不及也。一有及此，则群聚而笑之，以为迂阔。今朝廷悉心于一切之利害，有司法令于刀笔之间，非一日也。然其效可观矣。则夫所谓迂阔而熟烂者，惟陛下亦可以少留神而察之矣。昔唐太宗贞观之初，人人异论，如封德彝之徒，皆以为非杂用秦、汉之政，不足以为天下。能思先王之事，开太宗者，魏郑公一人尔。其所施设，虽未能尽当先王之意，抑其大略，可谓合矣。故能以数年之间，而天下几致刑措，中国安宁，夷蛮顺服，自三王以来，未有如此盛时也。唐太宗之初，天下之俗，犹今之世也，魏郑公之言，固当时所谓迂阔而熟烂者也，然其效如此。贾谊曰：「今或言德教之不如法令，胡不引商、周、秦、汉以观之？」然则唐太宗事亦足以观矣。</p><p>　　臣幸以职事归报陛下，不自知其驽下无以称职，而敢及国家之大体者，诚以臣蒙陛下任使，而当归报。窃谓在位之人才不足，而无以称朝廷任使之意，而朝廷所以任使天下之士者，或非其理，而士不得尽其才，此亦臣使事之所及，而陛下之所宜先闻者也。释此一言，而毛举利害之一二，以污陛下之聪明，而终无补于世，则非臣所以事陛下惓惓之义也。伏惟陛下详思而择其中，天下幸甚！</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="译文"><a href="#译文" class="headerlink" title="译文"></a>译文</h1>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;li&gt;百度百科&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="Literature" scheme="https://zhang21.github.io/categories/Literature/"/>
    
    
      <category term="古文" scheme="https://zhang21.github.io/tags/%E5%8F%A4%E6%96%87/"/>
    
      <category term="政论文" scheme="https://zhang21.github.io/tags/%E6%94%BF%E8%AE%BA%E6%96%87/"/>
    
      <category term="王安石" scheme="https://zhang21.github.io/tags/%E7%8E%8B%E5%AE%89%E7%9F%B3/"/>
    
  </entry>
  
  <entry>
    <title>治安疏</title>
    <link href="https://zhang21.github.io/2019/02/10/%E6%B2%BB%E5%AE%89%E7%96%8F/"/>
    <id>https://zhang21.github.io/2019/02/10/治安疏/</id>
    <published>2019-02-10T12:51:11.000Z</published>
    <updated>2019-02-11T01:20:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li><li>百度百科</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>　　海瑞（1514－1587），字汝贤，号刚峰，海南海口人，明代著名的政治家，以刚直不阿，清正廉明著称于世，被世人誉为“海青天”。</p><p>　　《治安疏》是明代名臣海瑞写给明世宗朱厚熜的一篇奏疏。在这篇著名的奏疏中，海瑞大胆直言当时官场的弊端和统治阶级的罪责，同时劝谏统治者改正过失，实行改革，达到“天下大治”的目的。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h1><p>　　户部云南清吏司主事臣海瑞谨奏：为直言天下第一事，以正君道、明臣职，求万世治安事。</p><p>　　君者，天下臣民万物之主也。惟其为天下臣民万物之主，责任至重，凡民生利瘼一有所不闻，将一有所不得知而行，其任为不称。是故养君之道，宜无不备，而以其责寄臣工，使尽言焉。臣工尽言而君道斯称矣。昔之务为容悦、谀顺曲从，致使实祸蔽塞，主不上闻焉，无足言矣。过为计者，则又曰：“君子危明主，忧治世。” 夫世则治矣，以不治忧之；主则明矣，以不明危之。毋乃使之反求眩瞀，失趋舍矣乎？非通论也。</p><p>　　臣受国恩厚矣，请执有犯无隐之义。美曰美，不一毫虚美; 过曰过，不一毫讳过。不容悦，不过计，披肝胆为陛下言之。汉贾谊陈政事于文帝曰：“进言者皆曰天下已安已治矣，臣独以为未也。曰安且治者，非愚则谀。”夫文帝、汉贤君也，贾谊非苛责备也。文帝性仁类柔，慈恕恭俭，虽有近民之美；优游退逊，尚多怠废之政。不究其弊所不免，概以安且治当之，愚也；不究其才所不能，概以致安治颂之，谀也。陛下自视于汉文帝何如？陛下天质英断，睿识绝人，可为尧、舜，可为禹、汤、文、武，下之如汉宣帝之励精，光武之大度，唐太宗之英武无敌，宪宗之专志平僭乱，宋仁宗之仁恕，举一节可取者，陛下优为之。即位初年，刬除积弊，焕然与天下更始。举其略，如箴敬一以养心，定冠履以辨分，除圣贤土木之像，夺宦官内外之权，元世祖毁不与祀，祀孔子推及所生，天下忻忻然以大有作为仰之。识者谓辅相得人，太平指日可期也。非虚语也，高汉文帝远甚。然文帝能充其仁顺之性，节用爱人，吕祖谦称其能尽人之才力，诚是也。一时天下虽未可尽以治安予之，而贯朽粟陈，民少康阜，三代下称贤君焉。陛下则锐精未久，妄念牵之而去矣，反刚明而错用之，谓遥兴可得而一意修玄。富有四海，不曰民之膏脂在是也，而侈兴土木。二十余年不视朝，纲纪弛矣；数行推广事例，名爵滥矣。二王不相见，人以为薄于父子；以猜疑诽谤戮辱臣下，人以为薄于君臣，乐西苑而不返宫，人以为薄于夫妇。天下吏贪将弱，民不聊生，水旱靡时，盗贼滋炽，自陛下登极初年，亦有之而未什也。今赋役增常，万方则效，陛下破产礼佛日甚，室如悬磬，十余年来极矣。天下因即陛下改元之号，而臆之曰：“嘉靖者，言家家皆净而无财用也。”迩者，严嵩罢黜，世蕃极刑，差快人意，一时称清时焉。然严嵩罢相之后，犹之严嵩未相之先而已，非大清明世界也，不及汉文远甚。天下之人不直陛下久矣！内外臣工之所知也。知之不可谓愚，诗云：“衮职有阙，惟仲山甫补之。”今日所赖以弼棐匡救，格非而归之正，诸臣责也，岂以圣人而绝无过举哉？古昔设官，亮采惠畴足矣，不必责之以谏。保氏掌谏王恶，不必设也。木绳金砺，圣贤不必言之也。今乃建醮修斋，相率进香，天桃天药，相率表贺。建 宫筑室，工部极力经营；取香觅宝，户部差求四出。陛下误举，诸臣误顺，无一人为陛下一正言焉。都俞吁咈之风，陈善闭邪之义，邈无闻矣，谀之什也。然愧心馁气，退有后言，以从陛下；昧没本心，以歌颂陛下；欺君之罪何如！夫天下者，陛下之家也，人未有不顾其家者。内外臣工，其官守，其言责，皆所以奠陛下之家而磐石之也。一意玄修，是陛下心之惑也；过于苛断，是陛下情之偏也。而谓陛下不顾其家，人情乎？诸臣顾身念重，得一官多以欺败、脏败、不事事败，有不足以当陛下之心者。其不然者，君心臣心偶不相值也，遂谓陛下为贱薄臣工。诸臣正心之学微，所言或不免已私，或失详审，诚如胡寅挠乱政事之说，有不足以当陛下之心者。其不然者，君意臣言偶不相值也。遂谓陛下为是已拒谏。执陛下一二事不当之形迹，臆陛下千百事之尽然，陷陛下误终不复，诸臣欺君之罪大矣。《记》曰：“上人疑则百姓惑，下难知则君长劳。”今日之谓也。为身家心与惧心合，臣职不明，臣一二事形迹说既为诸臣解之矣。求长生心与惑心合，有辞于臣，君道不正，臣请再为陛下开之。陛下之误多矣，大端在修醮，修醮所以求长生也。自古圣贤止说修身立命，止说顺受其正，盖天地赋予于人而为性命者，此尽之矣。尧、舜、禹、汤、文、武之君，圣之盛也，未能久世不终。下之亦未见方外士汉、唐、宋存至今日，使陛下得以访其术者。陶仲文，陛下以师呼之，仲文则既死矣。仲文不能长生，而陛下独何求之？至谓天赐仙桃药丸，怪妄尤甚。昔伏羲氏王天下，龙马出河，因则其文以画八卦；禹治水时，神龟负文而列于背，因而第之以成九畴。《河图》、《洛书》，实有此瑞物。泄此万古不传之秘，天不爱道而显之圣人，借圣人以开示天下，犹之日月星辰之布列而历数成焉，非虚妄事也。宋真宗获天书于干佑山，孙奭进曰：“天何言哉！岂有书也？”桃必采而得，药必工捣合而成者也。无因而至，桃、药有足行耶？天赐之者，有手执而付之耶？陛下玄修多年矣，一无所得。至今日左右奸人，逆揣陛下悬思妄念，区区桃、药导之长生，理之所无，而玄修之无益可知矣。陛下又将谓悬刑赏以督率臣下，分理有人，天下无可不治，而玄修无害矣乎？夫人幼而学，无致君泽民异事之学；壮而行，亦无致君泽民殊用之心。太甲曰：“有言逆于汝心，必求诸道；有言逊于汝志，必求诸非道。”言顺者之未必为道也。即近事观，严嵩有一不顺陛下者乎？昔为贪窃，今为逆本。梁材守官守道，陛下以为逆者也。历任有声，官户部者，至今首称之。虽近日严嵩抄没，百官有惕心焉。无用于积贿求迁，稍自洗涤。然严嵩罢相之后，犹严嵩未相之先而已。诸臣为严嵩之顺，不为梁材之执。今甚者贪求，未甚者挨日。见称于人者，亦廊庙山林，交战热中，鹘突依违，苟举故事。洁已格物，任天下重，使社稷灵长终必赖之者，未见其人焉。得非有所牵掣其心，未能纯然精白使然乎？陛下欲诸臣惟予行而莫逆也，而责之效忠，付之以翼为明听也，又欲其顺吾玄修土木之误，是股肱耳目，不为腹心卫也，而自为视听持行之用。有臣如仪衍焉，可以成得志与民由之之业，无是理也。陛下诚知玄修无益，臣之改行，民之效尤，天下之不安不治由之，翻然悔悟，日视正朝，与宰辅、九卿、侍从、言官讲求天下利害，洗数十年君道之误，置其身于尧、舜、禹、汤、文、武之上；使其臣亦得洗数十年阿君之耻，置身与皋、夔、伊、傅相后先，明良喜起，都俞吁咈。内之宦官宫妾，外之光禄寺厨役、锦衣卫恩荫、诸衙门带俸，举凡无事而官多矣。上之内仓内库，下之户工部光禄寺诸厂藏段绢、粮料、珠宝、器用、木材诸物，多而积于无用，用之非所宜用亦多矣，诸臣必有为陛下言者。诸臣言之，陛下行之，此则在陛下一节省间而已。京师之一金，田野之百金也。一节省而国有余用，民有盖藏，不知其几也，而陛下何不为之？官有职掌，先年职守之正、职守之全，而未之行；今日职守之废、职守之苟且因循、不认真、不尽法，而自以为是。敦本行而端士习，止上纳以清仕途，久任吏将以责成功，练选军士以免召募，驱缁黄游食使归四民，责府州县兼举富教，使成礼俗。复屯盐本色以裕边储，均田赋丁差以苏困敝，举天下官之侵渔、将之怯懦、吏之为奸，刑之无少姑息焉。必世之仁，博厚高明悠远之业，诸臣必有为陛下言者。诸臣言之，陛下行之，此则在陛下一振作间而已。一振作而百 废具举，百弊刬绝，唐虞三代之治，粲然复兴矣。而陛下何不为之？节省之，振作之，又非有所劳于陛下也。九卿总其纲，百职分其绪，抚按科道纠率肃清于其间，陛下持大纲、稽治要而责成焉。劳于求贤，逸于任用，如天运于上而四时六气各得其序，恭已无为之道也。天地万物为一体，固有之性也。民物熙浃，薰为太和，而陛下性分中有真乐矣。可以赞天地之化育，则可以与天地参。道与天通，命由我立，而陛下性分中有真寿矣。此理之所有，可旋至而立有效者也。若夫服食不终之药，遥兴轻举，理所无者也。理之所无而切切然散爵禄、竦精神，玄修求之，悬思凿想，系风捕影，终其身如斯而已矣。求之其可得乎！</p><p>　　君道不下在、臣职不明，此天下第一事也。于此不言，更复何言？大臣持禄而外为谀，小臣畏罪而面为顺，陛下诚有不得知而改之行之者，臣每恨焉。是以昧死竭惓惓为陛下一言之。一反情易向之间，而天下之治与不治，民物之安与不安，于焉决焉。伏惟陛下留神，宗社幸甚，天下幸甚。臣不胜战栗恐惧之至，为此具本亲赍，谨具奏闻。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="译文"><a href="#译文" class="headerlink" title="译文"></a>译文</h1><p>　　户部云南清吏司主事海瑞在这里上奏：为了匡正君道，明确臣下的职责，求得万世治安，我要直陈天下第一事。</p><p>　　国君是天下臣民万物的主人，正是因为是天下臣民万物之主，所以责任重大。如果民生措置失当，就是君主没有负起责任。所以臣子就应当尽量为君主服务，忠于职守，畅所欲言。臣子尽到了自己的责任，君主的责任也才算尽到了。以前那种专图讨好，曲意逢迎，不让君主听到实际情况的人，现在用不着说他们了。</p><p>　　危言耸听的人或许会说：君子总是想法多，即使遇到贤明的君主，政治清明的时代，也常常居安思危，忧虑重重，只怕反而让人思维混乱，搞不清方向。这种说法不符合现在的情况！</p><p>　　臣蒙受国恩，宁可直言得罪也不想说假话，好的就是好的，坏的就是坏的，一丝一毫都不敢隐瞒。我不为讨上面的欢心，也不计较得失，今天披沥肝胆，掏出真心，对陛下您说几句实话。</p><p>　　汉代名臣贾谊曾和文帝这样说：“下面进言的人总是说：天下已经大治，臣独以为还没有。那些说天下已安已治的人，不是愚昧无知就是阿谀逢迎。”文帝算是汉代的贤君了，贾谊也不是对文帝要求过高。汉文帝的品质作风是好的，他有爱民的美德，为人也慈和俭朴，从容谦逊，但缺点在于游于玄老，不专事于政务，有许多政事都被耽误了，没有办好。假使臣下看不到这些弊病，一味认为天下已安已治，这就是愚昧无知。假使臣下看不到文帝的才能毕竟有限，一味用已安已治的话来歌颂他，这就是阿谀奉承。<br>　　陛下自视和汉文帝比较起来怎么样呢？陛下天资英断，睿识绝人，具有成为尧、舜、禹、汤、文、武这样的君王的潜力，陛下象汉宣帝一样做事努力认真，象光武帝一样为人大度，象唐太宗一样英武无敌，象唐宪宗一样能够消平各地藩镇叛乱，陛下还有宋仁宗的仁恕之德，总之象这些可取的优点，无论哪一项，您都是具有的。您即位初年，铲除积弊，明白宣示，同全国老百姓一道革新政事。举其大概吧：您作过一篇《敬一箴》，提倡规戒；改定了一些冠服制度，下令废除孔子庙里的塑像，只用木主；削弱了宦官的内外之权；将元世祖从历代帝王庙所祭牌位中剔除；在孔子庙兼祭孔子的父母。那时候天下人都很期待，认为您一定大有作为。有见识的人都认为：只要有好的臣子帮助，不需多久，天下就可太平，您一定比汉文帝要强得多。然而文帝能发扬仁恕之性，节约恭俭，体恤爱民，宋朝的吕祖谦说他善于用人，能尽人之才力。一时天下虽说不上已经大治，但国库充盈，连串钱的绳子都朽烂了，百姓安乐，财物丰足。大家公认他是夏、商、周三代以后的一位贤君。</p><p>　　陛下您立志要有作为，可是没过多久，就被杂乱的念头导引到别的地方去了。您把自己的刚强英明用到错误的地方，以为人真的能够长生不老，而一味的玄修。陛下富有四海，却不念及那都是民之脂膏，常常大兴土木，大修宫殿庙宇。陛下二十余年不上朝处理政务，导致纲纪松懈败坏。朝廷卖官买官，援用这种章程越来越滥，美其名曰推广事例，导致豪强四起，名爵泛滥。您专门和方士在一起炼丹，不与自己的儿子们相见，人们都以为您缺少父子之情。您常以猜疑诽谤戮辱臣下，人们都以为缺少君臣之礼。您整天待在西苑不回宫，人们都以为缺少夫妇之情。天下官吏贪污成风，军队弱小，水灾旱灾无时不有，民不聊生，导致流民暴乱象火烧一样，越来越盛。自陛下登基以来，前几年就这样，但还不严重，但是如今赋税徭役越来越重，各级官吏都效法朝廷，盘剥百姓无度。陛下花很多钱崇奉道教，十余年来已经做到极致了。因此，陛下改元号之时，天下人都猜想：这意思就是说“嘉靖者言家家皆净而无财用也”。</p><p>　　近来，严嵩罢相，严世蕃被处以极刑，勉强可以令人满意，一时人称天下清明。然而严嵩罢相以后的政事，不过和他作宰相以前差不多，也并不见得清明多少。陛下比汉文帝差远了。天下之人对您不满已经很久了，这内外臣工都知道。《诗经》上说：“衰职有阙，惟仲山甫补之”，意思是说宣王不能完全尽职，仲山甫能从旁补救。今日以辅助、匡正来补救、纠正错误并使一切走入正轨，正是诸位臣下的职责所在。圣人也不能不犯错误，否则古代设官，只要他做官办事就够了，不必要求他们进言劝谏，也不必设谏官，更不必说木绳金砺这类的话了。陛下修宫殿，设坛祈祷，就让群臣竞相进献香物和仙桃仙药，叫臣子进表管贺。陛下要兴建宫室，工部就极力经营；陛下要取香觅宝，户部就派人到处索取。陛下举动有误，诸臣顺从得也没道理，竟没有一个人为陛下正言。那种公开讨论对错、贡献良言，防止邪恶的做法，长久没有听到了，献媚的风气太甚。然而人们不敢直言，内心却不能不惭愧，气也不壮了，当面不敢说，却在背后议论是非，人们表面上顺从陛下，却把真心藏起来，这样为陛下歌功颂德，是多么大的欺君之罪？</p><p>　　天下者，陛下之家也，哪有不顾自己家的人呢？内外臣工都有行政职务和进言的责任，这些都是能够奠定您的家业，使它象磐石一样的稳固的基础。一意玄修，是陛下的心被妄念迷惑。过分苛刻武断，也不是您生性如此。不能就这样便断定陛下不顾其家，不合乎人情。臣子们往往为了顾及自己的身家性命，为了保住自己的乌纱帽，欺诈、贪赃、旷废职务而导致犯罪，这些人不合您的心意，是很自然的。假如不是为了上述的原因也不合您的心意，那就是您的心与臣子的心偶然不相投合啊，但也有人疑心是您看轻臣子，侮辱臣子。另外有一种人，自己的心思不正，或是为了个人的利益，或是说得不够详明正确，就象胡寅扰乱政事的奏疏那样：这些人不合您的意旨，也是很自然的。如果都不是以上的情况，君意臣意还不相符合，那就要让人疑心是不是因为陛下自以为是，不愿接受劝谏的缘故。抓住一二件这样的事，就推测您向来如此，害得您一直被人误解。《礼记》上说：“君主多疑于上，百姓就无所适从；臣子不忠于下，君主就劳苦不堪了。”说的就是今天这种情况。</p><p>　　臣子保身家的私心和怕触怒君主的心相结合，因而模糊了自己的职责，我已经举出一二件事例替他们作过分析了。君主求长生的妄念和迷惑不明相结合，就使臣子们心怀不满；陛下有失为君之道，请允许我再加以分析。 陛下的失误很多，大部分是因为修醮。修醮是为了求长生不老。古来的圣贤只不过讲求涵养道德，保养生命，顺应自然法则。天地赋予人生命，不过如此罢了。尧、舜、禹、汤、文、武都是圣人，也没有谁能长生不死。他们之后，也没有见到所谓僧道术士之人从汉、唐、宋活到今天。传给您长生法术的陶仲文，您称他为师傅，可是他自己就已经死了。仲文尚不能长生不死，陛下为什么还要求长生？至于那所谓的仙桃药丸，怪妄尤甚。伏羲氏做了天下的王，有龙马出河，于是便依据龙马的花纹画了八卦。夏禹治水时，出现神龟，就把神龟背上罗列的各种纹路排列起来，成为有关天道人事的九种法则。这些 “神物”透露了万古不传的秘密。天将天道显之于圣人，借圣人来明示天下，就像日月星辰的排列，并不虚妄。但宋真宗赵恒为了粉饰太平，听从王钦若等人的话，伪造天书，声称从天而降，他的大臣孙奭就谏言道：“上天哪里会说什么？怎么还能写书？”仙桃是从树上采摘下来的，仙药由人工捣制而成。你说它们能有什么天意？能起什么作用？天赐之物，难道能让人手里拿着给您？陛下玄修多年，一无所得。到今日，左右奸人迎合陛下玄修妄念，以为区区桃药就能让人长生不老，世上哪有这样的道理？玄修之无益可知矣。</p><p>　　陛下您莫非认为只要抓住刑和赏的权柄，就不怕无人办事，天下就可以治好，修道便没有什么害处了吗？那些阿谀逢迎的臣子，年轻时候就没有学到“致君泽民” （把君主辅佐好，使百姓得到好处）的特别本领和修养，壮年做官也没有“致君泽民”的特殊抱负和愿望。〈尚书·太甲〉曰：“有言逆于汝志，必求诸道，有言逊于汝志，必求诸非道。意思是说：遇有不合自己意旨的话，要看看是否合于道理；遇有顺从自己意旨的话，要看看是否不合道理。顺从旨意的未必就是有道理的。从近些年来看：严嵩哪有一处不是顺着陛下您的意思？然而严党过去是贪权窃利的祸害，今天是忤逆乱政的根源。象梁材这样的人谨守职责，历来做官有声誉有操守，以正直不阿著称，却被陛下认为大逆不道。虽然从严嵩抄家以后，百官有所畏惧，知道不能再以贿赂谋求升迁，稍改以前的恶习。然而严嵩罢相之后的局面也和严嵩做丞相之前没什么两样。百官仍然只情愿学严嵩的顺从，不肯学梁材的正直不阿。现在坏人还是贪求无厌，一般人也只是得过且过，混混日子。即使是好人，也不过是在做官和退隐之间犹豫不决，含糊敷衍，奉行做事罢了。而那种洁身自爱、探研真理，对天下负有责任，能够肩负国运，维护长治久安的人，却一个也没有发现。不就是因为好人受到牵制，不能尽忠做事，才弄到今天这个地步吗？您既要人顺从圣意，又要人尽忠；既要人充当助手和耳目，又要人顺从您做那些修道和兴修宫殿庙宇的错误事情：这就象不用四肢耳目去保卫心腹，而由心腹自己去执行看、听、拿东西和走路的任务一样。照此下去，您即便有了象张仪和公孙衍那样能干的臣子，要想成就与百姓同享太平的事业，那也是办不到的。</p><p>　　如果您承认修道有害无益，那么臣子的转变，百姓的祸福，天下的安危都将由此而不同，所以您应当立即悔悟，每日上朝理政，与宰辅、九卿、侍从、言官一起言说天下利害，洗刷数十年君道之误，那样就能置身于尧、舜、禹、汤、文、武这样的明君之中，也使得臣下能够洗刷数十年谄媚君主之耻，让他们置身于皋陶、伊、傅这样的贤臣之列，君臣便可互相勉励、互相敬重。内廷中的宦官宫女，外廷中光禄寺厨房的仆役，锦衣卫中那些受惠于祖先恩荫的人，以及各个衙门里那些额外的冗员，无事可干而为官的人太多了。皇家的仓库里，户部、工部以及光禄寺等衙门里，缎、绢、粮料、珠宝、器物、木材等东西很多，堆积在那里也无用，用了也用的不是地方，白白浪费了很可惜。臣子们进谏，您采纳实行，对您说来只不过动一动节省的念头罢了。京师里的一块金子，到了田野百姓那里抵得上一百块金子用。您稍稍节省一点，国库便有余用，老百姓则有了储蓄，好处真不知有多少啊，而陛下为何不这样做呢？</p><p>　　今天官吏设置不全，办事因循苟且，敷衍塞责，不守法纪，却还自以为不错。应该督促遵守基本的道德来端正官员们的行为，停止用钱买官那一套来理清仕途；让文武官员安于其位，责成他们做出成绩来；平常就练选军士以免打仗了临时召募百姓；让那些吃白食的和尚道士回家，回到士、农、工、商的行业里；府州县地方官要生计和教化并重，树立好的礼俗规范；屯田、运盐应该恢复征收实物，来充实边防军队的储备；按地亩交粮，按人口应役，以便恢复老百姓的元气；检举天下官员的贪污勒索行为，让那些贪赃枉法的人心生怯懦，按照刑律处罚他们，毫不宽容。如此以来，便是仁政，几十年之后才能收效，与天地并存的伟大功业便可成就了。这样的事由诸臣提议，陛下执行，也就在陛下一振作间而已。一振作而诸废具举，百弊铲绝，象唐、虞三代那样光明灿烂的大治便可复兴矣，而陛下为什么不实行呢？</p><p>　　陛下只要稍事节省和振作就行了，又不是要您多么劳心劳神。九卿掌握大政方针，百官承担具体的职责，巡抚、巡按、六科给事中等纠举肃清，维护风气，陛下考核政纲的实施情况，督促他们做出成绩来。努力去找贤才，任用他们办事，自己就省力了。就像天运于上，四时六气各得其序，君主只要自己有德，感化臣民，不必亲自动手管理一切。天地万物为一体，自有它的道理。百姓安居乐业，形成一片祥和气氛，而陛下自然能够感到真正的快乐和价值。天地是化生万物的，人也有帮助天地化生的能力，可以与天地并列而为“三才”。道与天通，命运可以由我们自己掌握，而陛下自然能够享受真寿。这是真正的道理，转身就能做到，立刻就能见效。要是依旧去服食什么长生不死之药，巴望着能成仙升天，不是道理所在。那么做只能匆忙的散爵禄，让精神徒然的紧张，玄修求长生，是捕风捉影的空想，陛下一辈子求之，究竟得到没得到呢？</p><p>　　君道不正，臣职不明，是天下第一大事。于此不言，更复何言？大臣为保乌纱帽而阿谀奉承，小臣害怕获罪表面顺从，陛下有错误却不知道，不能改正不能执行，臣每想到这里便痛心疾首。所以今天便冒死竭忠，诚恳的向陛下进言。望陛下能够改变心思，转换方向，而天下之治与不治，民物之安与不安都取决于您，若陛下真能采纳，是我宗庙、社稷、国家的幸运，是天下黎民百姓的幸运！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;li&gt;百度百科&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="Literature" scheme="https://zhang21.github.io/categories/Literature/"/>
    
    
      <category term="古文" scheme="https://zhang21.github.io/tags/%E5%8F%A4%E6%96%87/"/>
    
      <category term="政论文" scheme="https://zhang21.github.io/tags/%E6%94%BF%E8%AE%BA%E6%96%87/"/>
    
      <category term="海瑞" scheme="https://zhang21.github.io/tags/%E6%B5%B7%E7%91%9E/"/>
    
  </entry>
  
  <entry>
    <title>治安策</title>
    <link href="https://zhang21.github.io/2019/02/10/%E6%B2%BB%E5%AE%89%E7%AD%96/"/>
    <id>https://zhang21.github.io/2019/02/10/治安策/</id>
    <published>2019-02-10T12:27:11.000Z</published>
    <updated>2019-02-11T01:19:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>　　贾谊（前200—前168年），汉族，洛阳（今河南洛阳东）人，西汉初年著名政论家、文学家，世称贾生。贾谊少有才名，十八岁时，以善文为郡人所称。文帝时任博士，迁太中大夫，受大臣周勃、灌婴排挤，谪为长沙王太傅，故后世亦称贾长沙、贾太傅。三年后被召回长安，为梁怀王太傅。梁怀王坠马而死，贾谊深自歉疚，抑郁而亡，时仅33岁。司马迁对屈原、贾谊都寄予同情，为二人合传，后世因而往往把贾谊与屈原并称为“屈贾”。贾谊著作主要有散文和辞赋两类，散文的主要文学成就是政论文，评论时政，风格朴实峻拔，议论酣畅，鲁迅称之为“西汉鸿文”，代表作有《过秦论》《论积贮疏》《陈政事疏》等。其辞赋皆为骚体，形式趋于散体化，是汉赋发展的先声，以《吊屈原赋》《鵩鸟赋》最为著名。</p><p>　　《治安策》是西汉文学家贾谊创作的一篇政论文。这篇论文论及了文帝时潜在或明显的多种社会危机，包括“可为痛哭者一，可为流涕者二，可为长叹息者六”等众多严重问题，涉及中央与地方诸侯之间、汉庭与北方异族之间，以及社会各阶层之间的种种矛盾，针对这令人忧心的一切，贾谊富有针对性地一一指明相应对策和补救措施。这篇论文势忽峻忽缓、首尾相衔，大量采用夹叙夹议，还在议论说理的同时，不失时机地运用文学笔法。</p><p>　　西汉前期社会存在着三大矛盾：其一是匈奴为代表的边境少数民族与汉王朝之间的矛盾；其二是地方诸侯王的割据势力与中央政府之间的矛盾；其三是广大农民和地主、大工商业者的矛盾。汉文帝时期，天下大势已定，这些社会矛盾虽然尚未激化到即将公开破裂的程度，但却在酝酿并渐趋于激化的过程之中。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h1><p>　　臣窃惟事势，可为痛哭者一，可为流涕者二，可为长太息者六，若其它背理而伤道者，难遍以疏举。进言者皆曰天下已安已治矣，臣独以为未也。曰安且治者，非愚则谀，皆非事实知治乱之体者也。夫抱火厝之积薪之下而寝其上，火未及燃，因谓之安，方今之势，何以异此！本末舛逆，首尾衡决，国制抢攘，非甚有纪，胡可谓治！陛下何不壹令臣得孰数之于前，因陈治安之策，试详择焉！</p><p>　　夫射猎之娱，与安危之机孰急？使为治，劳智虑，苦身体，乏钟鼓之乐，勿为可也。乐与今同，而加之诸侯轨道，兵革不动，民保首领，匈奴宾服，四荒乡风，百姓素朴，狱讼衰息，大数既得，则天下顺治，海内之气清和咸理，生为明帝，没为明神，名誉之美，垂于无穷。礼祖有功而宗有德，使顾成之庙称为太宗，上配太祖，与汉亡极。建久安之势，成长治之业，以承祖庙，以奉六亲，至孝也；以幸天下，以育群生，至仁也；立经陈纪，轻重同得，后可以为万世法程，虽有愚幼不肖之嗣，犹得蒙业而安，至明也。以陛下之明达，因使少知治体者得佐下风，致此非难也。其具可素陈于前，愿幸无忽。臣谨稽之天地，验之往古，按之当今之务，日夜念此至孰也，虽使禹舜复生，为陛下计，亡以易此。</p><p>　　夫树国固必相疑之势，下数被其殃，上数爽其忧，甚非所以安上而全下也。今或亲弟谋为东帝，亲兄之子西乡而击，今吴又见告矣。天子春秋鼎盛，行义未过，德泽有加焉，犹尚如是，况莫大诸侯，权力且十此者虖！</p><p>　　然而天下少安，何也？大国之王幼弱未壮，汉之所置傅相方握其事。数年之后，诸侯之王大抵皆冠，血气方刚，汉之傅相称病而赐罢，彼自丞尉以上偏置私人，如此，有异淮南、济北之为邪！此时而欲为治安，虽尧舜不治。</p><p>　　黄帝曰：「日中必熭，操刀必割。」今令此道顺而全安，甚易，不肯早为，已乃堕骨肉之属而抗刭之，岂有异秦之季世虖！夫以天子之位，乘今之时，因天之助，尚惮以危为安，以乱为治，假设陛下居齐桓之处，将不合诸侯而匡天下乎？臣又以知陛下有所必不能矣。假设天下如曩时，淮阴侯尚王楚，黥布王淮南，彭越王梁，韩信王韩，张敖王赵，贯高为相，卢绾王燕，陈豨在代，令此六七公者皆亡恙，当是时而陛下即天子位，能自安乎？臣有以知陛下之不能也。天下淆乱，高皇帝与诸公并起，非有仄室之势以豫席之也。诸公幸者，乃为中涓，其次廑得舍人，材之不逮至远也。高皇帝以明圣威武即天子位，割膏腴之地以王诸公，多者百余城，少者乃三四十县，德至渥也，然其后十年之间，反者九起。陛下之与诸公，非亲角材而臣之也，又非身封王之也，自高皇帝不能以是一岁为安，故臣知陛下之不能也。然尚有可诿者，曰疏，臣请试言其亲者。假令悼惠王王齐，元王王楚，中子王赵，幽王王淮阳，共王王梁，灵王王燕，厉王王淮南，六七贵人皆亡恙，当是时陛下即位，能为治虖？臣又知陛下之不能也。若此诸王，虽名为臣，实皆有布衣昆弟之心，虑亡不帝制而天子自为者。擅爵人，赦死罪，甚者或戴黄屋，汉法令非行也。虽行不轨如厉王者，令之不肯听，召之安可致乎！幸而来至，法安可得加！动一亲戚，天下圜视而起，陛下之臣虽有悍如冯敬者，适启其口，匕首已陷其匈矣。陛下虽贤，谁与领此？故疏者必危，亲者必乱，已然之效也。其异姓负强而动者，汉已幸胜之矣，又不易其所以然。同姓袭是迹而动，既有征矣，其势尽又复然。殃旤之变，未知所移，明帝处之尚不能以安，后世将如之何！</p><p>　　屠牛坦一朝解十二牛，而芒刃不顿者，所排击剥割，皆众理解也。至于髋髀之所，非斤则斧。夫仁义恩厚，人主之芒刃也；权势法制，人主之斤斧也。今诸侯王皆众髋髀也，释斤斧之用，而欲婴以芒刃，臣以为不缺则折。胡不用之淮南、济北？势不可也。</p><p>　　臣窃迹前事，大抵强者先反。淮阴王楚最强，则最先反；韩信倚胡，则又反；贯高因赵资，则又反；陈豨兵精，则又反；彭越用梁，则又反；黥布用淮南，则又反；卢绾最弱，最后反。长沙乃在二万五千户耳，功少而最完，势疏而最忠，非独性异人也，亦形势然也。曩令樊、郦、绛、灌据数十城而王，今虽以残亡可也；令信、越之伦列为彻侯而居，虽至今存可也。然则天下之大计可知已。欲诸王之皆忠附，则莫若令如长沙王；欲臣子之勿菹醢，则莫若令如樊、郦等；欲天下之治安，莫若众建诸侯而少其力。力少则易使以义，国小则亡邪心。令海内之势如身之使臂，臂之使指，莫不制从，诸侯之君不敢有异心，辐凑并进而归命天子，虽在细民，且知其安，故天下咸知陛下之明。割地定制，令齐、赵、楚各为若干国，使悼惠王、幽王、元王之子孙毕以次各受祖之分地，地尽而止，及燕、梁它国皆然。其分地众而子孙少者，建以为国，空而置之，须其子孙生者，举使君之。诸侯之地其削颇入汉者，为徙其侯国及封其子孙也，所以数偿之：一寸之地，一人之众，天子亡所利焉，诚以定治而已，故天下咸知陛下之廉。地制壹定，宗室子孙莫虑不王，下无倍畔之心，上无诛伐之志，故天下咸知陛下之仁。法立而不犯，令行而不逆，贯高、利几之谋不生，柴奇、开章之计不萌，细民乡善，大臣致顺，故天下咸知陛下之义。卧赤子天下之上而安，植遗腹，朝委裘，而天下不乱，当时大治，后世诵圣。壹动而五业附，陛下谁惮而久不为此？</p><p>　　天下之势方病大瘇。一胫之大几如要，一指之大几如股，平居不可屈信，一二指搐，身虑亡聊。失今不治，必为锢疾，后虽有扁鹊，不能为已。病非徒瘇也，又苦𨂂盭。元王之子，帝之从弟也；今之王者，从弟之子也。惠王［之子］，亲兄子也；今之王者，兄子之子也。亲者或亡分地以安天下，疏者或制大权以逼天子，臣故曰非徒病瘇也，又苦𨂂盭。可痛哭者，此病是也。</p><p>　　天下之势方倒县。凡天子者，天下之首，何也？上也。蛮夷者，天下之足，何也？下也。今匈奴嫚娒侵掠，至不敬也，为天下患，至亡已也，而汉岁致金絮采缯以奉之。夷狄征令，是主上之操也；天子共贡，是臣下之礼也。足反居上，首顾居下，倒县如此，莫之能解，犹为国有人乎？非亶倒县而已，又类辟，且病痱。夫辟者一面病，痱者一方痛。今西边北边之郡，虽有长爵不轻得复，五尺以上不轻得息，斥候望烽燧不得卧，将吏被介胄而睡，臣故曰一方病矣。医能治之，而上不使，可为流涕者此也。</p><p>　　陛下何忍以帝皇之号为戎人诸侯，势既卑辱，而旤不息，长此安穷！进谋者率以为是，固不可解也，亡具甚矣。臣窃料匈奴之众不过汉一大县，以天下之大困于一县之众，甚为执事者羞之。陛下何不试以臣为属国之官以主匈奴？行臣之计，请必系单于之颈而制其命，伏中行说而笞其背，举匈奴之众唯上之令。今不猎猛敌而猎田彘，不搏反寇而搏畜菟，翫细娱而不图大患，非所以为安也。德可远施，威可远加，而直数百里外威令不信，可为流涕者此也。</p><p>　　今民卖童者，为之绣衣丝履偏诸缘，内之闲中，是古天子后服，所以庙而不晏者也，而庶人得以衣婢妾。白縠之表，薄纨之里，緁以偏诸，美者黼绣，是古天子之服，今富人大贾嘉会召客者以被墙。古者以奉一帝一后而节适，今庶人屋壁得为帝服，倡优下贱得为后饰，然而天下不屈者，殆未有也。且帝之身自衣皂绨，而富民墙屋被文绣；天子之后以缘其领，庶人㜸妾缘其履：此臣所谓舛也。夫百人作之不能衣一人，欲天下亡寒，胡可得也？一人耕之，十人聚而食之，欲天下亡饥，不可得也。饥寒切于民之肌肤，欲其亡为奸邪，不可得也。国已屈矣，盗贼直须时耳，然而献计者曰「毋动」，为大耳。夫俗至大不敬也，至亡等也，至冒上也，进计者犹曰「毋为」，可为长太息者此也。</p><p>　　商君遗礼义，弃仁恩，并心于进取，行之二岁，秦俗日败。故秦人家富子壮则出分，家贫子壮则出赘。借父耰鉏，虑有德色；母取箕箒，立而谇语。抱哺其子，与公并倨；妇姑不相说，则反唇而相稽。其慈子耆利，不同禽兽者亡几耳。然并心而赴时，犹曰蹷六国，兼天下。功成求得矣，终不知反廉愧之节，仁义之厚。信并兼之法，遂进取之业，天下大败；众掩寡，智欺愚，勇威怯，壮陵衰，其乱至矣。是以大贤起之，威震海内，德从天下。曩之为秦者，今转而为汉矣。然其遗风余俗，犹尚未改。今世以侈靡相竞，而上亡制度，弃礼谊，捐廉耻，日甚，可谓月异而岁不同矣。逐利不耳，虑非顾行也，今其甚者杀父兄矣。盗者剟寝户之帘，搴两庙之器，白昼大都之中剽吏而夺之金。矫伪者出几十万石粟，赋六百余万钱，乘传而行郡国，此其亡行义之（先）〔尤〕至者也。而大臣特以簿书不报，期会之间，以为大故。至于俗流失，世坏败，因恬而不知怪，虑不动于耳目，以为是适然耳。夫移风易俗，使天下回心而乡道，类非俗吏之所能为也。俗吏之所务，在于刀笔筐箧，而不知大（礼）〔体〕。陛下又不自忧，窃为陛下惜之。</p><p>　　夫立君臣，等上下，使父子有礼，六亲有纪，此非天之所为，人之所设也。夫人之所设，不为不立，不植则僵，不修则坏。管子曰：「礼义廉耻，是谓四维；四维不张，国乃灭亡。」使管子愚人也则可，管子而少知治体，则是岂可不为寒心哉！秦灭四维而不张，故君臣乖乱，六亲殃戮，奸人并起，万民离叛，凡十三岁，〔而〕社稷为虚。今四维犹未备也，故奸人几幸，而众心疑惑。岂如今定经制，令君君臣臣，上下有差，父子六亲各得其宜，奸人亡所几幸，而群臣众信，上不疑惑！此业壹定，世世常安，而后有所持循矣。若夫经制不定，是犹度江河亡维楫，中流而遇风波，舩必覆矣。可为长太息者此也。</p><p>　　夏为天子，十有余世，而殷受之。殷为天子，二十余世，而周受之。周为天子，三十余世，而秦受之。秦为天子，二世而亡。人性不甚相远也，何三代之君有道之长，而秦无道之暴也？其故可知也。古之王者，太子乃生，固举以礼，使士负之，有司齐肃端冕，见之南郊，见于天也。过阙则下，过庙则趋，孝子之道也。故自为赤子而教固已行矣。昔者成王幼在襁抱之中，召公为太保，周公为太傅，太公为太师。保，保其身体；傅，傅之德（意）〔义〕；师，道之教训：此三公之职也。于是为置三少，皆上大夫也，曰少保、少傅、少师，是与太子宴者也。故乃孩提有识，三公、三少固明孝仁礼义以道习之，逐去邪人，不使见恶行。于是皆选天下之端士孝悌博闻有道术者以卫翼之，使与太子居处出入。故太子乃生而见正事，闻正言，行正道，左右前后皆正人也。夫习与正人居之，不能毋正，犹生长于齐不能不齐言也；习与不正人居之，不能毋不正，犹生长于楚之地不能不楚言也。故择其所耆，必先受业，乃得尝之；择其所乐，必先有习，乃得为之。孔子曰：「少成若天性，习贯如自然。」及太子少长，知妃色，则入于学。学者，所学之官也。学礼曰：「帝入东学，上亲而贵仁，则亲疏有序而恩相及矣；帝入南学，上齿而贵信，则长幼有差而民不诬矣；帝入西学，上贤而贵德，则圣智在位而功不遗矣；帝入北学，上贵而尊爵，则贵贱有等而下不隃矣；帝入太学，承师问道，退习而考于太傅，太傅罚其不则而匡其不及，则德智长而治道得矣。此五学者既成于上，则百姓黎民化辑于下矣。」及太子既冠成人，免于保傅之严，则有记过之史，彻膳之宰，进善之旌，诽谤之木，敢谏之鼓。瞽史诵诗，工诵箴谏，大夫进谋，士传民语。习与智长，故切而不愧；化与心成，故中道若性。三代之礼：春朝朝日，秋暮夕月，所以明有敬也；春秋入学，坐国老，执酱而亲馈之，所以明有孝也；行以鸾和，步中采齐，趣中肆夏，所以明有度也；其于禽兽，见其生不食其死，闻其声不食其肉，故远庖厨，所以长恩，且明有仁也。</p><p>　　夫三代之所以长久者，以其辅翼太子有此具也。及秦而不然。其俗固非贵辞让也，所上者告讦也；固非贵礼义也，所上者刑罚也。使赵高傅胡亥而教之狱，所习者非斩劓人，则夷人之三族也。故胡亥今日即位而明日射人，忠谏者谓之诽谤，深计者谓之妖言，其视杀人若艾草菅然。岂惟胡亥之性恶哉？彼其所以道之者非其理故也。</p><p>　　鄙谚曰：「不习为吏，视已成事。」又曰：「前车覆，后车诫。」夫三代之所以长久者，其已事可知也；然而不能从者，是不法圣智也。秦世之所以亟绝者，其辙迹可见也；然而不避，是后车又将覆也。夫存亡之变，治乱之机，其要在是矣。天下之命，县于太子；太子之善，在于早谕教与选左右。夫心未滥而先谕教，则化易成也；开于道术智谊之指，则教之力也。若其服习积贯，则左右而已。夫胡、粤之人，生而同声，耆欲不异，及其长而成俗，累数译而不能相通，行者〔有〕虽死而不相为者，则教习然也。臣故曰选左右早谕教最急。夫教得而左右正，则太子正矣，太子正而天下定矣。书曰：「一人有庆，兆民赖之。」此时务也。</p><p>　　凡人之智，能见已然，不能见将然。夫礼者禁于将然之前，而法者禁于已然之后，是故法之所用易见，而礼之所为生难知也。若夫庆赏以劝善，刑罚以惩恶，先王执此之政，坚如金石，行此之令，信如四时，据此之公，无私如天地耳，岂顾不用哉？然而曰礼云礼云者，贵绝恶于未萌，而起教于微眇，使民日迁善远辠而不自知也。孔子曰：「听讼，吾犹人也，必也使毋讼乎！」为人主计者，莫如先审取舍；取舍之极定于内，而安危之萌应于外矣。安者非一日而安也，危者非一日而危也，皆以积渐然，不可不察也。人主之所积，在其取舍。以礼义治之者，积礼义；以刑罚治之者，积刑罚。刑罚积而民怨背，礼义积而民和亲。故世主欲民之善同，而所以使民善者或异。或道之以德教，或殴之以法令。道之以德教者，德教洽而民气乐；殴之以法令者，法令极而民风哀。哀乐之感，祸福之应也。秦王之欲尊宗庙而安子孙，与汤武同，然而汤武广大其德行，六七百岁而弗失，秦王治天下，十余岁则大败。此亡它故矣，汤武之定取舍审而秦王之定取舍不审矣。夫天下，大器也。今人之置器，置诸安处则安，置诸危处则危。天下之情与器亡以异，在天子之所置之。汤武置天下于仁义礼乐，而德泽洽，禽兽草木广裕，德被蛮貊四夷，累子孙数十世，此天下所共闻也。秦王置天下于法令刑罚，德泽亡一有，而怨毒盈于世，下憎恶之如仇仇，旤几及身，子孙诛绝，此天下之所共见也。是非其明效大验邪！人之言曰：「听言之道，必以其事观之，则言者莫敢妄言。」今或言礼谊之不如法令，教化之不如刑罚，人主胡不引殷、周、秦事以观之也？</p><p>　　人主之尊譬如堂，群臣如陛，众庶如地。故陛九级上，廉远地，则堂高；陛亡级，廉近地，则堂卑。高者难攀，卑者易陵，理势然也。故古者圣王制为等列，内有公卿大夫士，外有公侯伯子男，然后有官师小吏，延及庶人，等级分明，而天子加焉，故其尊不可及也。里谚曰：「欲投鼠而忌器。」此善谕也。鼠近于器，尚惮不投，恐伤其器，况于贵臣之近主乎！廉耻节礼以治君子，故有赐死而亡戮辱。是以黥劓之辠不及大夫，以其离主上不远也。礼不敢齿君之路马，蹴其刍者有罚；见君之几杖则起，遭君之乘车则下，入正门则趋；君之宠臣虽或有过，刑戮之辠不加其身者，尊君之故也。此所以为主上豫远不敬也，所以体貌大臣而厉其节也。今自王侯三公之贵，皆天子之所改容而礼之也，古天子之所谓伯父、伯舅也，而令与众庶同黥劓髠刖笞傌弃巿之法，然则堂不亡陛虖？被戮辱者不泰迫虖？廉耻不行，大臣无乃握重权，大官而有徒隶亡耻之心虖？夫望夷之事，二世见当以重法者，投鼠而不忌器之习也。</p><p>　　臣闻之，履虽鲜不加于枕，冠虽敝不以苴履。夫尝已在贵宠之位，天子改容而体貌之矣，吏民尝俯伏以敬畏之矣，今而有过，帝令废之可也，退之可也，赐之死可也，灭之可也；若夫束缚之，系緤之，输之司寇，编之徒官，司寇小吏詈骂而榜笞之，殆非所以令众庶见也。夫卑贱者习知尊贵者之一旦吾亦乃可以加此也，非所以习天下也，非尊尊贵贵之化也。夫天子之所尝敬，众庶之所尝宠，死而死耳，贱人安宜得如此而顿辱之哉！</p><p>　　豫让事中行之君，智伯伐而灭之，移事智伯。及赵灭智伯，豫让衅面吞炭，必报襄子，五起而不中。人问豫子，豫子曰：「中行众人畜我，我故众人事之；智伯国士遇我，我故国士报之。」故此一豫让也，反君事仇，行若狗彘，已而抗节致忠，行出虖列士，人主使然也。故主上遇其大臣如遇犬马，彼将犬马自为也；如遇官徒，彼将官徒自为也。顽顿亡耻奊诟亡节，廉耻不立，且不自好，苟若而可，故见利则逝，见便则夺。主上有败，则因而挻之矣；主上有患，则吾苟免而已，立而观之耳；有便吾身者，则欺卖而利之耳。人主将何便于此？群下至众，而主上至少也，所托财器职业者粹于群下也。俱亡耻，俱苟妄，则主上最病。故古者礼不及庶人，刑不至大夫，所以厉宠臣之节也。古者大臣有坐不廉而废者，不谓不廉，曰「簠簋不饰」；坐污秽淫乱男女亡别者，不曰污秽，曰「帷薄不修」；坐罢软不胜任者，不谓罢软，曰「下官不职」。故贵大臣定有其辠矣，犹未斥然正以謼之也，尚迁就而为之讳也。故其在大谴大何之域者，闻谴何则白冠牦缨，盘水加剑，造请室而请辠耳，上不执缚系引而行也。其有中罪者，闻命而自弛，上不使人颈盭而加也。其有大辠者，闻命则北面再拜，跪而自裁，上不使捽抑而刑之也，曰：「子大夫自有过耳！吾遇子有礼矣。」遇之有礼，故群臣自憙；婴以廉耻，故人矜节行。上设廉耻礼义以遇其臣，而臣不以节行报其上者，则非人类也。故化成俗定，则为人臣者主耳忘身，国耳忘家，公耳忘私，利不苟就，害不苟去，唯义所在。上之化也，故父兄之臣诚死宗庙，法度之臣诚死社稷，辅翼之臣诚死君上，守圄捍敌之臣诚死城郭封疆。故曰圣人有金城者，比物此志也。彼且为我死，故吾得与之俱生；彼且为我亡，故吾得与之俱存；夫将为我危，故吾得与之皆安。顾行而忘利，守节而仗义，故可以托不御之权，可以寄六尺之孤。此厉廉耻行礼谊之所致也，主上何丧焉！此之不为，而顾彼之久行，故曰可为长太息者此也。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="译文"><a href="#译文" class="headerlink" title="译文"></a>译文</h1><p>　　我私下考虑如今的局势，可为之痛哭的有一项，可为之流泪的有两项，应为之大声叹息的有六项，至于其他违背情理而伤害大道的事，很难一一列举。向陛下进言的人都说天下已经安定，治理得很好了，我却认为不是那么回事。说天下已经安定已经大治的人，不是愚昧无知，就是阿谀奉承，都不是真正了解治乱大体的人。有人抱着火种放在堆积的木柴之下，自己睡在木柴上，火没燃烧起来的时候，他便认为这是安宁的地方，如今国家的局势，与此有什么不同！本末颠倒，首尾冲突，国制混乱，不合理的现象严重，怎么能够说是大治！陛下为什么不让我对您详细地说明这一切，提出使国家真正大治大安的方策，以供陛下仔细斟酌选用呢？</p><p>　　射箭打猎之类的娱乐与国家安危的关键相比，哪一样更急迫？假若所提的治世方法，耗费心血，摧残身体，影响享受钟鼓所奏音乐，可以不采纳；我的治国方策，能保证使陛下所享受的乐趣不受影响，却可以带来封国诸侯各遵法规，战争不起，平民拥护首领，匈奴归顺，纯朴之风响彻边陲，百姓温良朴素，官司之类的事情停止不发。大势已定，那么，全国便会顺从而大治，四海之内，一派升平，万物都符合事理，陛下生时被称为明帝，死后成为明神，美名佳誉永垂青史。《礼》书上说宗庙有功德，使您的顾成庙被尊称为大宗，得以与太祖共享盛名，与大汉天下共存亡。创建长久安定的形势，造成永久太平的业绩，以此来承奉祖庙和六亲，这是最大的孝顺；以此来使老百姓得到幸福，使芸芸众生得到养育，这是最大的仁；创设准则，标立纪纲，使大小事物各得其所，为万世子孙树立楷模，即使是后世出现了愚鲁、幼稚、不肖的继承人，由于他继承了您的鸿业和福荫，还可以安享太平，这是最明智的办法。凭陛下的精明练达，再有稍微懂得治国之道的人辅佐，要达到这一境界并不困难。其内容全都可以向陛下陈述，希望陛下不要忽视。我谨慎地用它来考察过天地的变化，应验过往，核对当今，日夜思考而详细地知道了它的内容，即使是禹舜再生，也不能加以改变。</p><p>　　建立诸侯国过于强大，必然会造成天子与诸侯互相对立，臣下屡遭祸害，皇上也多次忧伤，这实在不是使皇上放心、使臣下保全的办法。如今亲兄弟图谋在东方称帝，亲侄子也向西袭击朝廷，吴王的谋反活动又被人告发。当今天子年富力强，品行道义上没有过错，对他们施加功德恩泽，而他们尚且如此，何况最大的诸侯，权力比他们还要大十倍呢！</p><p>　　虽然如此，但是天下还比较安定，这是什么原因呢？因为大诸侯国王年纪还小，汉朝安置在那的太傅、丞相还掌握着政事。几年以后，诸侯王大都加冠成人，血气方刚，而汉朝委派的太傅、丞相都要称病还乡，诸侯王会遍插亲信，如果这样的话，他们的行为同淮南王、济北王有什么区别呢？到了那时，想求得天下安定，即使是尧舜在世也办不到。</p><p>　　黄帝说：“到了中午要抓紧曝晒，拿着刀子要赶紧宰割。”如今要使安治之道顺利而稳妥地推行，是十分容易的。假使不肯及早行动，到头来就要毁掉亲骨肉，这同秦朝末年的局势还有什么区别吗？凭着天子的权位，趁着当今的有利时机，靠着上天的帮助，尚且对转危为安、改乱为治的措施有所顾虑，假设陛下处在齐桓公的境地，大概不会去联合诸侯匡正天下吧？我知道陛下一定不能那样做的。假如国家的局势还像从前那样，淮阴侯韩信还统治着楚，黥布统治着淮南，彭越统治着梁，韩王信统治着韩，张敖统治着赵，贯高做赵国的相，卢绾统治着燕，陈还在代国，假令这六七个王公都还健在，在这时陛下继位做天子，自己能感到安全吗？我判断陛下是不会感到安全的。在天下混乱的年代，高祖和这些王公们共同起事，并没有子侄亲属的势力做为依靠。这些王公走运的就成了亲近的侍从，差一点的仅当个管理宫中事务的官员，他们的才能远不及高祖。高祖凭着他的明智威武，即位做了天子，割出肥沃的土地，使这些王公成为诸侯王，多的有一百多个城，少的也有三四十个县，恩德是优厚的了，然而在以后的十年当中，反叛汉朝的事发生了九次。陛下跟这些王公，并没有亲自较量过才能而使他们甘心为臣的，也不是亲自封他们当诸侯王的。即使高祖也不能因此而得到一年的安宁，所以我知道陛下更不能得到安宁的。</p><p>　　不过，上面这些情况，还有可以推托的理由，说是“关系疏远”。那就请允许我试着谈谈那些亲属诸侯王吧。假如让齐悼惠王统治着齐，楚元王统治着楚，赵王统治着赵，幽王统治着淮阳，恭王统治着梁，灵王统治着燕，厉王统治着淮南，假如这六七位贵人都还健在，在这时陛下即皇帝位，能使天下太平吗？我又知陛下是不能的。像这些诸侯王，虽然名义上是臣子，实际上他们都怀有老百姓那种兄弟关系的想法，大概没有不想采用天子的制度，而把自己当做天子的。他们擅自把爵位赏给别人，赦免死罪，甚至有人乘坐天子的黄屋车。他们不执行汉朝的法令。即使执行了，像厉王那样的不守法的人，命令他都不肯听从，又怎么能招他来呢！幸而召来了，法律怎么能施加到他身上呢！动了一个近亲，天下诸王都环视着惊动起来。陛下的臣子当中即使有冯敬那样勇敢的人，但是他刚开口揭发诸侯王的不法行为，刺客的匕首已经刺进他的胸膛了。陛下虽然贤明，谁能和您一起来治理这些人呢？</p><p>　　所以说，关系疏远的诸侯王必定危险，关系亲近的诸侯王也一定作乱，这是事实所证明了的。那些自负强大而发动叛乱的异姓诸侯王，汉朝已经侥幸地战胜他们了，可是却没有改变酿成叛乱的制度。同姓诸侯王也袭用了这种做法，发动叛乱，如今已有征兆了，形势又完全恢复到以前那种状态！灾祸的变化，还不知道要转移到何处，英明的皇帝处在这种情况下，尚且不能使国家安宁，后代又将怎么办呢！</p><p>　　屠牛坦一早晨宰割了十二头牛，而屠刀的锋刃并不变钝，这是因为他所刮剔割剥的，都是顺着肉的肌理下刀。等碰到胯骨、大腿骨的地方，那就不是用砍刀就是用斧头去砍了。仁义恩厚好比是君王的刀刃，权势、法制好比是君王的砍刀、斧头。如今的诸侯王好比是胯骨、大腿骨，如果放弃砍刀、斧头不用，而要用刀刃去碰，我认为刀子不是出缺口就是被折断。为什么仁义恩厚不能用在淮南王、济北王的身上呢？因为形势不容许啊！</p><p>　　我私下里考察从前的事件，大体上是势力强大的先反：淮阴侯韩信统治着楚，势力最强，就最先反叛；韩王信依靠了匈奴的力量，就又反叛了；贯高借助了赵国的条件，就又反叛了；陈狶部队精锐，也反叛了；彭越凭借梁国，也反叛了；黥布凭借淮南，也反叛了；卢绾势力最弱，最后反叛。长沙王吴芮才有二万五千封户，功劳很少，却保全了下来，权势最小而对汉朝最忠顺；这不只是由于性情和别人不同，也是由于形势使他这样。倘若从前让樊哙、郦商、周勃、灌婴占据几十个城为王，那如今他们由于作恶而亡国，也是可能的。假使让韩信、彭越之流，只居于彻侯的地位，即便今天也还能保全，也是可能的。</p><p>　　既然如此，那么天下大计就可以知道了。要想使天下诸侯王都忠心归附汉朝，那最好让他们都像长沙王一样；要想让臣下不至于像韩信那样被杀掉，那最好让他们像樊哙、郦商那徉；要想使天下安定，最好多多建立诸侯国而使他们的势力减小。力量弱小就容易用道义来指使他们，国土小就不会有反叛的邪念。这样就使全国的形势，如同身体使唤手臂，手臂使唤手指似的，没有不听从指挥的。诸侯王不敢有反叛的想法，如同辐条聚向车轮一样，都归顺天子，即使是老百姓，也会知道他们都很安稳。这样，天下就都知道陛下的英明。分割土地，定出制度：把齐、赵、楚三个王国分成若干侯国，让齐王、赵王、楚王的子孙，全都依次受封先人的那份封地，一直到分尽为止。对燕、梁等其他王国也是这样。有些封地大而子孙少的，也都分成若干侯国，暂时空着搁置起来，等着他们的子孙出生以后，再封他当候。诸侯王的封地，有不少已被削除收归汉朝所有的，那就替他们调整侯国所在的地区，等到要封他的子孙到别的地方去的时候，按候国的应有户数，给以补偿。一寸土、一口人，皇帝也不沾他们的，确实只是为了安定太平罢了。这样，天下就都知道陛下的廉洁。分封土地的制度一旦确定，宗室子孙没有不考虑保住自己的统治的。臣子没有背叛的念头，皇帝没有讨伐的想法。所以天下就都知道陛下的仁德。法令制定了，没有人触犯；政令推行了，没有人抵触。贯高、利几一类的阴谋不会出现，柴奇、开章那样的诡计不会萌生。老百姓都向往良善，大臣都向皇上表示恭顺。所以天下就都知道陛下的道义。这样，即使让幼儿当皇帝，天下也很安定；即使立一个遗腹子作天子，让臣子朝拜老皇帝遗留下来的皇袍，天下也不致于混乱。这样，就可以使天下安定无事，后代也称颂陛下的圣明。只要采取这样的措施，上述五个方面的业绩也就随之而来了，而陛下又怕什么而久久不这样办呢？</p><p>　　当今，天下的形势像得了严重的浮肿病：小腿粗得差不多像腰围，脚指粗得差不多像大腿。平时都不能伸屈自如，一两个指头抽搐，浑身就觉得无所依赖。丧失了今天的机会而不医治，一定要成为难治的顽症。以后即使有扁鹊那样神医，也都无能为力。这个病还不只是浮肿，还苦于脚掌扭折不能走动。楚元王的儿子，是陛下的叔伯兄弟，当今的楚王，是叔伯兄弟的儿子，齐悼惠王的儿子，是陛下亲哥哥的儿子，当今的齐王是陛下哥哥的孙子。陛下自己的子孙，有的还没有分封土地，以便安定天下，旁支的子孙，倒有人掌握大权来威胁皇帝。所以，我说：不仅是害了浮肿病，还苦于脚掌扭折了不能走动。令人痛哭的就是这样一种病啊！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="Literature" scheme="https://zhang21.github.io/categories/Literature/"/>
    
    
      <category term="古文" scheme="https://zhang21.github.io/tags/%E5%8F%A4%E6%96%87/"/>
    
      <category term="政论文" scheme="https://zhang21.github.io/tags/%E6%94%BF%E8%AE%BA%E6%96%87/"/>
    
      <category term="贾谊" scheme="https://zhang21.github.io/tags/%E8%B4%BE%E8%B0%8A/"/>
    
  </entry>
  
  <entry>
    <title>封建论</title>
    <link href="https://zhang21.github.io/2019/02/10/%E5%B0%81%E5%BB%BA%E8%AE%BA/"/>
    <id>https://zhang21.github.io/2019/02/10/封建论/</id>
    <published>2019-02-10T12:13:11.000Z</published>
    <updated>2019-02-11T01:24:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>　　柳宗元（773年－819年11月28日），字子厚，河东（今山西运城）人，唐代著名文学家、思想家，唐宋八大家之一。参加永贞革新失败，被贬为永州司马。为当道者嫉恨，除短暂奉召入京外，终生未再北还。</p><p>　　《封建论》是柳宗元的政论文章，该文详尽分析了唐代以前中国历代政治得失，认为中国封建制度是百害而无一利，并阐发郡县制的优越性。<br>柳宗元被贬柳州（今广西柳州市）之时，引史为证，做“封建论”，结构严谨，文笔犀利而流畅。《封建论》说“彼封建者，更古圣王尧、舜、禹、汤、文、武而莫能去之。盖非不欲去之也，势不可也。……封建，非圣人意也”。</p><p>　　中唐时期，藩镇割据的情况愈演愈烈，当时各地藩镇极力鼓吹要恢复周以前的封建制度，反对中央集权的郡县制度，目的是为自己的割据制造舆论。和这种政治局面相适应，分封制的论调又开始抬头。针对这种情况，作者在永贞革新失败、被贬永州后，写下了这篇议论文。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h1><p>　　天地果无初乎？吾不得而知之也。生人果有初乎？吾不得而知之也。然则孰为近？曰有初为近。孰明之？由封建而明之也。彼封建者，更古圣王尧舜、禹汤、文武而莫能去之。盖非不欲去之也，势不可也。势之来（则），其生人之初乎？不初，无以有封建。封建，非圣人意也。</p><p>　　彼其初与万物皆生，草木榛榛，鹿豕狉狉，人不能搏噬，而且无毛羽，莫克自奉自卫。荀卿有言：必将假物以为用者也。夫假物者必争，争而不已，必就其能断曲直者而听命焉。其智而明者，所伏必众；告之以直而不改，必痛之而后畏；由是君长刑政生焉。故近者聚而为群。群之分，其争必大，大而后有兵有德。又有大者，众群之长又就而听命焉，以安其属，于是有诸侯之列。则其争又有大者焉。德又大者，诸侯之列又就而听命焉，以安其封，于是有方伯、连帅之类。则其争又有大者焉。德又大者，方伯、连帅之类又就而听命焉，以安其人，然后天下会于一。是故有里胥而后有县大夫，有县大夫而后有诸侯，有诸侯而后有方伯、连帅，有方伯、连帅而后有天子。自天子至于里胥，其德在人者，死必求其嗣而奉之。故封建非圣人意也，势也。</p><p>　　夫尧舜禹汤之事远矣，及有周而甚详。周有天下，裂土田而瓜分之，设五等，邦群后，布星罗，四周子天下，轮运而辐集。合为朝觐会同，离为守臣捍城。然而降于夷王，害礼伤尊，下堂而迎觐者，历于宣王，挟中兴复古之德，雄南征北伐之威，卒不能定鲁侯之嗣。陵夷迄于幽厉，王室东徙，而目列为诸侯。厥后，问鼎之轻重者有之，射三中肩者有之，代凡伯、诛苌宏者有之，天下乖盭，无君之心。予以为周之丧久矣，徒建空名于公侯之上耳！得非诸侯之盛强，末大不掉之咎欤？遂判为十二，合为七国，威分于陪臣之邦，国殄于后封之秦。则周之败端，其在乎此矣。</p><p>　　秦有天下，裂都会而为之郡邑，废侯卫而为之守宰，据天下之雄图，都六合之上游，摄制四海，运于掌握之内，此其所以为得也。不数载而天下大坏，其有由矣。亟役万人，暴其威刑，竭其货贿。负锄梃谪戍之徒，加圜视而合从，大呼而成群。时则有叛人而无叛吏，人怨于下，而吏畏于上，天下相合，杀守劫令而并起。咎在人怨，非郡邑之制失也。</p><p>　　汉有天下，矫秦之枉，徇周之制，剖海内而立宗子，封功臣。数年之间，奔命扶伤而不暇。困平城，病流矢，陵迟不救者三代。后乃谋臣献画，而离削自守矣。然而封建之始，郡国居半，时则有叛国而无叛郡。秦制之得，亦以明矣。继汉而帝者，虽百代可知也。</p><p>　　唐兴，制州邑，立守宰，此其所以为宜也。然犹桀猾时起，虐害方域者，失不在于州而在于兵，时则有叛将而无叛州。州县之设，固不可革也。</p><p>　　或者曰：「封建者，必私其土，子其人，适其俗，修其理，施化易也。守宰者，苟其心，思迁其秩而已，何能理乎？」予又非之。周之事迹，断可见矣。列侯骄盈，黩货事戎。大凡乱国多，理国寡。侯伯不得变其政，天子不得变其君。私土于人者，百不有一。失在于制，不在于政，周事然也。秦之事迹，亦断可见矣。有理人之制，而不委郡邑是矣；有理人之臣，而不使守宰是矣。郡邑不得正其制，守宰不得行其理，酷刑苦役，而万人侧目。失在于政，不在于制。秦事然也。汉兴，天子之政行于郡，不行于国；制其守宰，不制其侯王。侯王虽乱，不可变也；国人虽病，不可除也。及夫大逆不道，然后掩捕而迁之，勒兵而夷之耳。大逆未彰，奸利浚财，怙势作威，大刻于民者，无如之何。及夫郡邑，可谓理且安矣。何以言之？且汉知孟舒于田叔，得魏尚于冯唐，闻黄霸之明审，睹汲黯之简靖，拜之可也，复其位可也，卧而委之以辑一方可也。有罪得以黜，有能得以奖。朝拜而不道，夕斥之矣；夕受而不法，朝斥之矣。设使汉室尽城邑而侯王之，纵令其乱人，戚之而已。孟舒、魏尚之术，莫得而施；黄霸、汲黯之化，莫得而行。明谴而导之，拜受而退已违矣。下令而削之，缔交合从之谋，周于同列，则相顾裂眦，勃然而起。幸而不起，则削其半。削其半，民犹瘁矣，曷若举而移之，以全其人平？汉事然也。今国家尽制郡邑，连置守宰，其不可变也固矣。善制兵，谨择守，则理平矣。</p><p>　　或者又曰：「夏、商、周、汉封建而延，秦郡邑而促。」尤非所谓知理者也。魏之承汉也，封爵犹建。晋之承魏也，因循不革。而二姓陵替，不闻延祚。今矫而变之，垂二百祀，大业弥固，何系于诸侯哉？</p><p>　　或者又以为：「殷周圣王也，而不革其制，固不当复议也。」是大不然。夫殷周之不革者，是不得已也。盖以诸侯归殷者三千焉，资以黜夏，汤不得而废；归周老八百焉，资以胜殷，武王不得而易。徇之以为安，仍之以为俗，汤、武之所不得已也。夫不得已，非公之大者也，私其力于己也，私其卫于子孙也。秦之所以革之者，其为制，公之大者也；其情，私也，私其一己之威也，私其尽臣畜于我也。然而公天下之端自秦始。</p><p>　　夫天下之道，理安，斯得人者也。使贤者居上，不肖者居下，而后可以理安。今夫封建者，继世而理。继世而理者，上果贤乎？下果不肖乎？则生人之理乱，未可知也。将欲利其社稷，以一其人之视听，则又有世大夫世食禄邑，以尽其封略。圣贤生于其时，（亦）无以立于天下，封建者为之也。岂圣人之制使至于是乎？吾固曰：「非圣人之意也，势也。」</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="译文"><a href="#译文" class="headerlink" title="译文"></a>译文</h1><p>　　自然界果真没有原始阶段吗？我没法知道。人类果真有原始阶段吗？我也没法知道。那么，（有或没有原始阶段）哪种说法比较接近事实呢？我认为：有原始阶段这种说法比较接近事实。怎么知道这一点呢？从“封国土、建诸侯”的封建制就可以明白。那种封建制，经历了古代贤明的帝王唐尧、虞舜、夏禹、商汤、周文王和周武王，没有谁能把它废除掉。不是不想把它废除掉，而是事物发展的趋势不允许，这种形势的产生，大概是在人类的原始阶段吧？不是原始阶段的那种形势，就没有可能产生封建制。实行封建制，并不是古代圣人的本意。</p><p>　　人类在他的原始阶段跟万物一起生存，那时野草树木杂乱丛生，野兽成群四处奔走，人不能像禽兽那样抓扑啃咬，而且身上也没有毛羽来抵御严寒，不能够光靠自身来供养自己、保卫自己。荀卿说过：“人类一定要借用外物作为自己求生的工具。”借用外物来求生的必然会相争，争个不停，一定会去找那能判断是非的人而听从他的命令。那又有智慧又明白事理的人，服从他的人一定很多；他把正确的道理告诉那些相争的人，不肯改悔的，必然要惩罚他，使他受痛苦之后感到惧怕，于是君长、刑法、政令就产生了。这样附近的人就聚结成群，分成许多群以后，相互间争斗的规模一定会大，相争的规模大了就会产生军队和威望。这样，又出现了更有威德的人，各个群的首领又去听从他的命令，来安定自己的部属。于是产生了一大批诸侯，他们相争的规模就更大了。又有比诸侯威德更大的人，许多诸侯又去听从他的命令，来安定自己的封国。于是又产生了方伯、连帅一类诸侯领袖，他们相争的规模还要大。这就又出现了比方伯，连帅威德更大的人，方伯、连帅们又去听从他的命令，来安定自己的老百姓，这以后天下便统一于天子一人了。因此先有乡里的长官而后有县的长官，有了县的长官而后有诸侯，有了诸侯而后有方伯、连帅，有了方伯、连帅而后才有天子。从最高的天子到乡里的长官，那些对人民有恩德的人死了，人们一定会尊奉他们的子孙为首领。所以说封建制的产生不是圣人的本意，而是形势发展的必然结果。</p><p>　　尧、舜、禹、汤的事离我们很远了，到了周代记载就很详备了。周朝占有天下，把土地像剖瓜一样分割开来，设立了公、侯、伯、子、男五等爵位，分封了许多诸侯。诸侯国像繁星似地罗列，四面遍布在大地上，集结在周天子的周围，就像车轮围绕着中心运转，就像辐条集中于车毂；诸侯聚合起来就去朝见天子，分散开来就是守卫疆土的臣子、朝廷的捍卫者。但是往下传到周夷王的时候，破坏了礼法，损害了尊严，天子只得亲自下堂去迎接朝见的诸侯。传到周宣王的时候，他虽然倚仗着复兴周王朝的功德，显示出南征北伐的威风，终究还是无力决定鲁君的继承人。这样日渐衰败下去，直到周幽王、周厉王，后来周平王把国都向东迁移到洛邑，把自己排列在诸侯同等地位上去了。从那以后，问周天子传国九鼎的轻重的事情出现了，用箭射伤天子肩膀的事情出现了，讨伐天子大臣凡伯、逼迫天子杀死大夫苌弘这样的事情也出现了，天下大乱，再没有把天子看作天子的了。我认为周王朝丧失统治力量已经很久了，只不过还在公侯之上保存着一个空名罢了！这岂不是诸侯势力太强大而指挥不动，就像尾巴太大以至摇摆不动所造成的过失吗？于是周王朝的统治权分散到十二个诸侯国，后来又合并为七个强国，王朝的权力分散到陪臣掌政的国家，最后被很晚才封为诸侯的秦国灭掉。周朝败亡的原因，大概就在这里了。<br>秦朝统一了全国后，不分诸侯国而设置郡县，废除诸侯而委派郡县长官。秦占据了天下的险要地势，建都于全国的上游，控制着全国，把局势掌握在手里，这是它做得对的地方。但没过几年便天下大乱，那是有原因的。它多次征发数以万计的百姓服役，使刑法越来越残酷，耗尽了财力。于是那些扛着锄木棍被责罚防守边境的人们，彼此递个眼色就联合起来，怒吼着汇合成群，奋起反秦。那时有造反的老百姓而没有反叛的官吏，老百姓在下怨恨秦王朝；官吏在上惧怕朝廷。全国四面八方互相配合，杀郡守劫县令的事情在各地同时发生。错误在于激起了人民的怨恨，并不是郡县制的过失。</p><p>　　汉朝统一了全国之后，纠正秦朝的错误，沿袭周朝的封建制，分割天下，分封自己的子弟和功臣为诸侯王。但没有几年，为了平息诸侯国的叛乱便闻命奔赴镇压，以至连救死扶伤都来不及，汉高祖刘邦被围困在平城，被飞箭射伤，如此衰落不振达三代之久。后来由于谋臣献策，才分散削弱诸侯王的势力并由朝廷命官管理诸侯国。但是汉朝开始恢复封建制的时候，诸侯国和郡县各占一半疆域，那时只有反叛的诸侯国而没有反叛的郡县，秦朝郡县制的正确性也已经明白清楚了。继汉朝而称帝的，就是再过一百代，郡县制比封建制优越，也是可以知道的。</p><p>　　唐朝建立以后，设置州县，任命州县的长官，这是它做得正确的地方。但还是有凶暴狡猾的人不时起来叛乱、侵州夺县的情况出现，过失不在于设置州县而在于藩镇拥有重兵，那时有反叛的藩镇将领而没有反叛的州县长官。郡县制的建立，确实是不能改变的。</p><p>　　有的人说：“封建制的世袭君长，一定会把他管辖的地区当作自己的土地尽心治理，把他管辖的老百姓当作自己的儿女悉心爱护，使那里的风俗变好，把那里的政治治理好，这样施行教化就比较容易。郡县制的州县地方官，抱着得过且过的心理，一心只想升官罢了，怎么能把地方治理好呢？”我认为这种说法也是不对的。</p><p>　　周朝的情况，毫无疑问地可以看清楚了：诸侯骄横，贪财好战，大致是政治混乱的国家多，治理得好的国家少。诸侯的霸主不能改变乱国的政治措施，天子无法撤换不称职的诸侯国的君主，真正爱惜土地爱护人民的诸侯，一百个中间也没有一个。造成这种弊病的原因在于封建制，不在于政治方面。周朝的情况就是如此。</p><p>　　秦朝的情况，也完全可以看清楚了：朝廷有治理百姓的制度，而不让郡县专权，这是正确的；中央有管理政务的大臣，不让地方官自行其是，这也是正确的。但是郡县不能正确发挥郡县制的作用，郡守、县令不能很好地治理人民。残酷的刑罚、繁重的劳役，使万民怨恨。这种过失在于政治方面，不在于郡县制本身。秦朝的情况便是这样。</p><p>　　汉朝建立的时候，天子的政令只能在郡县推行，不能在诸侯国推行；天子只能控制郡县长官，不能控制诸侯王。诸侯王尽管胡作非为，天子也不能撤换他们；侯王国的百姓尽管深受祸害，朝廷却无法解除他们的痛苦。只是等到诸侯王叛乱造反，才把他们逮捕、流放或率兵讨伐、以至灭掉他们。当他们的罪恶尚未充分暴露的时候，尽管他们非法牟利搜刮钱财，依仗权势作威作福，给百姓造成严重的伤害，朝廷也不能对他们怎么样。至于郡县，可以说是政治清明、社会安定了。根据什么这样讲呢？汉文帝从田叔那里了解到孟舒，从冯唐那里了解到魏尚，汉宣帝听说黄霸执法明察审慎，汉武帝看到汲黯为政简约清静，那么就可以任命黄霸做官，可以恢复孟舒、魏尚原来的官职，甚至可以让汲黯躺着任职，委任他只凭威望去安抚一个地区。官吏犯了罪可以罢免，有才干可以奖赏。早上任命的官吏，如果发现他不行正道，晚上就可以撤了他；晚上接受任命的官吏，如果发现他违法乱纪，第二天早上就可以罢免他。假使汉王朝把城邑全部都分割给侯王，即使他们危害人民，也只好对它发愁罢了。孟舒、魏尚的治理方法不能施行，黄霸、汲黯的教化无法推行。如果公开谴责并劝导这些侯王，他们当面接受，但转过身去就违反了；如果下令削减他们的封地，互相串通联合行动的阴谋就会遍及侯王各国之间，那么大家都怒眼圆睁，气势汹汹地反叛朝廷。万一他们不起来闹事，就削减他们的一半封地，即使削减一半，百姓还是受害了，何不把诸侯王完全废除掉来保全那里的人民呢？汉朝的情况就是这样。</p><p>　　今天国家完全实行郡县制，不断地任命郡县长官，这种情况是肯定不能改变了。只要好好地控制军队，慎重地选择地方官吏，那么政局就会安定了。</p><p>　　有人又说：“夏、商、周、汉四代实行封建制，他们统治的时间都很长久，而秦朝实行郡县制，统治的时间却很短。”这更是不懂得治理国家的人说的话。</p><p>　　魏继承汉朝，分封贵族的爵位仍然实行封建制；西晋继承魏，因袭旧制不加改变，但魏和晋都很快就衰亡了，没听说有国运长久的。唐朝纠正魏晋的过失改变了制度，享国已近二百年，国家基业更加巩固，这与分封诸侯又有什么关系呢？</p><p>　　有人又认为：“治理商、周二代的是圣明的君王啊，他们都没有改变封建制，那么，本来就不应当再议论这件事了。”这种说法大大的不对。</p><p>　　商、周二代没有废除封建制，是不得已的。因为当时归附商朝的诸侯有三千个，商朝靠了他们的力量才灭掉了夏，所以商汤就不能废除他们；归附周朝的诸侯有八百个，周朝凭借他们的力量才战胜了商朝，所以周武王也不能废弃他们。沿用它来求得安定，因袭它来作为习俗，这就是商汤、周武王不得不这样做的原因。他们是不得已的，并不是什么大公无私的美德，而是有私心，是要使诸侯为自己出力，并保卫自己的子孙。秦朝用废除分封诸侯的办法来作为制度，是最大的公；它的动机是为私的，是皇帝想要巩固个人的权威，使天下的人都臣服于自己。但是废除分封，以天下为公，却是从秦朝开始的。</p><p>　　至于天下的常理，是治理得好、政局安定，这才能得到人民的拥护。使贤明的人居上位，不肖的人居下位，然后才会清明安定。封建制的君长，是一代继承一代地统治下去的。这种世袭的统治者，居上位的果真贤明吗？居下位的真的不肖吗？这样，人民究竟是得到太平还是遭遇祸乱，就无法知道了。如果想要对国家有利而统一人民的思想，而同时又有世袭大夫世世代代统治他们的封地，占尽了诸侯国的全部国土，即使有圣人贤人生在那个时代，也会没有立足之地，这种后果就是封建制造成的。难道是圣人的制度要使事情坏到这种地步吗？所以我说：“这不是圣人的本意，而是形势发展的结果。”</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="Literature" scheme="https://zhang21.github.io/categories/Literature/"/>
    
    
      <category term="古文" scheme="https://zhang21.github.io/tags/%E5%8F%A4%E6%96%87/"/>
    
      <category term="政论文" scheme="https://zhang21.github.io/tags/%E6%94%BF%E8%AE%BA%E6%96%87/"/>
    
      <category term="柳宗元" scheme="https://zhang21.github.io/tags/%E6%9F%B3%E5%AE%97%E5%85%83/"/>
    
  </entry>
  
  <entry>
    <title>2019小计划</title>
    <link href="https://zhang21.github.io/2019/02/10/2019%E5%B0%8F%E8%AE%A1%E5%88%92/"/>
    <id>https://zhang21.github.io/2019/02/10/2019小计划/</id>
    <published>2019-02-10T11:52:49.000Z</published>
    <updated>2019-02-18T00:57:02.000Z</updated>
    
    <content type="html"><![CDATA[<p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h1><ul><li style="list-style: none"><input type="checkbox"> 《MySQL文档》</li><li style="list-style: none"><input type="checkbox"> 《SaltStack文档》</li><li style="list-style: none"><input type="checkbox"> 《TCP/IP》</li><li style="list-style: none"><input type="checkbox"> 《Netdata文档》</li><li style="list-style: none"><input type="checkbox"> 《Pinpoint文档》</li><li style="list-style: none"><input type="checkbox"> 《Prometheus文档》</li><li style="list-style: none"><input type="checkbox"> 《Grafana文档》</li><li style="list-style: none"><input type="checkbox" checked> 《GitLab文档》</li><li style="list-style: none"><input type="checkbox"> 《Django文档》</li></ul><p><br><br><br></p><hr><p><br><br><br></p><h1 id="个人"><a href="#个人" class="headerlink" title="个人"></a>个人</h1><ul><li style="list-style: none"><input type="checkbox"> 《资本论》</li><li style="list-style: none"><input type="checkbox"> 《灵飞经小楷》</li><li style="list-style: none"><input type="checkbox"> 《经济学原理》</li><li style="list-style: none"><input type="checkbox"> 省考: 2-4月</li><li style="list-style: none"><input type="checkbox"> 《论美国的民主》</li><li style="list-style: none"><input type="checkbox"> 《论法的精神》</li><li style="list-style: none"><input type="checkbox"> 《社会契约论》</li><li style="list-style: none"><input type="checkbox"> 《新概念英语》</li></ul><p><br><br><br></p><hr><p><br><br><br></p><h1 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h1><ul><li style="list-style: none"><input type="checkbox"> 书法学习</li><li style="list-style: none"><input type="checkbox"> 修身养性</li><li style="list-style: none"><input type="checkbox"> 找寻另一半</li><li style="list-style: none"><input type="checkbox"> 是否入手Nokia 9</li><li style="list-style: none"><input type="checkbox"> 是否换台笔记本电脑</li><li style="list-style: none"><input type="checkbox"> 是否入手罗技G29+ARTG29桌子+GTSport</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="Zhang" scheme="https://zhang21.github.io/categories/Zhang/"/>
    
    
      <category term="2019" scheme="https://zhang21.github.io/tags/2019/"/>
    
  </entry>
  
</feed>
