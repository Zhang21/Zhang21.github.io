<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>风继续吹</title>
  
  <subtitle>Yesterday, you said tomorrow!</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://zhang21.github.io/"/>
  <updated>2019-05-24T09:14:28.000Z</updated>
  <id>https://zhang21.github.io/</id>
  
  <author>
    <name>Leslie Zhang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Kong</title>
    <link href="https://zhang21.github.io/2019/05/08/Kong/"/>
    <id>https://zhang21.github.io/2019/05/08/Kong/</id>
    <published>2019-05-07T18:44:31.000Z</published>
    <updated>2019-05-24T09:14:28.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考：</p><ul><li>Kong GitHub: <a href="https://github.com/Kong/kong" target="_blank" rel="noopener">https://github.com/Kong/kong</a></li><li>Kong Docs: <a href="https://docs.konghq.com/" target="_blank" rel="noopener">https://docs.konghq.com/</a></li></ul><p><br></p><p>环境：</p><ul><li>ELRH7x86_64</li><li>Kong v1.1</li><li>Docker CE v18.09</li><li>K8s v1.11</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h1><p>GETTING STARTED</p><p><img src="/images/Kong/kongLogo.png" alt></p><p>Kong是一个可扩展的开源<strong>API Layer</strong>（也称为<strong>API Gateway</strong>或<strong>API Middleware</strong>）。Kong运行在任何RESTful API之前，并通过<strong>插件(plugin)</strong>进行扩展。</p><p>Kong的优点：</p><ul><li><strong>Scalable</strong>：只需添加更多机器便可轻易扩展，这意味着你的平台可以处理任何负载，同时保持低延迟；</li><li><strong>Modular</strong>：可以通过添加新的插件来扩展Kong，这些插件可通过RESTful API配置；</li><li><strong>Runs on any infrastructure</strong>：Kong可以运行在任何地方。</li></ul><p>Kong建立在N影响和Apache Cassandra或PostgreSQL等可靠技术之上，为你提供易于使用的RESTful API来操作和配置系统。</p><p><img src="/images/Kong/kong-architecture.jpg" alt></p><p><br></p><p>下图是一个使用Kong请求API的典型工作流程。<br>一旦Kong运行，对API的所有请求都将首先到达Kong，然后代理到最终的API。在请求和相应之间，Kong将执行你决定安装的任何插件，为你的API提供支持。Kong有效地成为每个API请求的入口点。</p><p><img src="/images/Kong/kong-simple.png" alt></p><p><br><br><br></p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p><a href="https://docs.konghq.com/1.1.x/getting-started/introduction/" target="_blank" rel="noopener">Introduction</a></p><p>你可能听过Kong是建立在Nginx之上的，它利用它的稳定性和效率。<br>更确切地说，Kong是一个在Nginx中运行的Lua Application，并且可通过<code>lua-nginx-module</code>模块实现。Kong不是用这个模块编译Nginx，而是与<strong>OpenResty</strong>一起发布，OpenResty以及包含了<code>lua-nginx-module</code>模块。OpenResty不是Nginx的分支(fork)，而是一组扩展其功能的模块。</p><p>这位可插拔架构(pluggable architecture)奠定了基础，在运行时启动并执行Lua scripts(plugins)。因此，我们认为Kong是微服务架构的典范，它的核心是实现<strong>数据库抽象(database abstraction)</strong>、<strong>路由(routing)</strong>和<strong>插件管理(plugin management)</strong>。插件可以存在于单独的代码中，并可以在几行代码中诸如到请求生命周期的任何位置。</p><p><br><br><br><br><br></p><h2 id="快速开始"><a href="#快速开始" class="headerlink" title="快速开始"></a>快速开始</h2><p><a href="https://docs.konghq.com/1.1.x/getting-started/quickstart/" target="_blank" rel="noopener">Quickstart</a></p><p>在本章中，你讲学习如何管理Kong实例。首先，你将启动Kong，以便可访问RESTful Admin Interface，通过该界面管理服务(service)、路由(route)、消费者(consumer)…通过Admin API发送的数据存储在Kong的数据存储区中(PostgreSQL后Cassandra)。</p><p><br><br><br></p><h3 id="启动Kong"><a href="#启动Kong" class="headerlink" title="启动Kong"></a>启动Kong</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 运行kong migrations命令来准备数据存储</span></span><br><span class="line">kong migrations bootstrap [-c /path/to/kong.conf]</span><br><span class="line"><span class="comment"># 你应该看到Kong已成功迁移的消息。否则，你可能在配置文件中错误的配置了数据库连接。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里把默认配置文件中的postgre注释取消就好</span></span><br><span class="line">cp /etc/kong/kong.conf.default kong.conf</span><br><span class="line">vim kong.conf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可指定配置项</span></span><br><span class="line">kong start [-c /path/to/kong.conf]</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="验证Kong"><a href="#验证Kong" class="headerlink" title="验证Kong"></a>验证Kong</h3><p>如果一切顺利，你应该看到一条消息通知你Kong正在运行。</p><p>默认情况下，Kong监听以下端口：</p><ul><li><strong>8000</strong>：监听来自Client的传入流量，并将其转发到上游服务</li><li><strong>8443</strong>：与8000端口类似，它监听HTTPS流量</li><li><strong>8001</strong>：Admin API用于配置Kong监听</li><li><strong>8444</strong>：Admin API监听HTTPS流量</li></ul><p><br><br><br></p><h3 id="停止和重载"><a href="#停止和重载" class="headerlink" title="停止和重载"></a>停止和重载</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kong stop</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在不停机的情况下重新加载Kong</span></span><br><span class="line">kong reload</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="配置服务"><a href="#配置服务" class="headerlink" title="配置服务"></a>配置服务</h2><p><a href="https://docs.konghq.com/1.1.x/getting-started/configuring-a-service/" target="_blank" rel="noopener">Configuring a Service</a></p><p>在本章中，你将向Kong添加API。为此，你首先需要添加一个<strong>服务（Service）</strong>，这就是Kong又来指代它管理的上游API和微服务的名称。</p><p>出于测试的目的，将创建一个指向Mockbin API（返回请求作为响应）的服务。这有助于了解Kong如何代理你的API请求。</p><p>在开始向服务发出请求之前，你需要为其添加<strong>路由（Route）</strong>。路由指定请求在到达Kong后如何（以及是否）发送到服务。单个服务可以有多个路由。</p><p>在配置了服务和路由之后，你能够通过Kong使用它们发出请求。</p><p>Kong在端口<code>8001</code>上公开RESTful Admin API。Kong的配置（包括添加服务和路由），是通过该API的请求进行的。</p><p><br><br><br></p><h3 id="添加服务"><a href="#添加服务" class="headerlink" title="添加服务"></a>添加服务</h3><p>Add your Service using the Admin API</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 发出以下cURL请求，将服务添加到Kong</span></span><br><span class="line">curl -i -X POST \</span><br><span class="line">  --url http://localhost:8001/services/ \</span><br><span class="line">  --data <span class="string">'name=example-service'</span> \</span><br><span class="line">  --data <span class="string">'url=http://mockbin.org'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 你应该收到类似的响应</span></span><br><span class="line">HTTP/1.1 201 Created</span><br><span class="line">Content-Type: application/json</span><br><span class="line">Connection: keep-alive</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">   <span class="string">"host"</span>:<span class="string">"mockbin.org"</span>,</span><br><span class="line">   <span class="string">"created_at"</span>:1519130509,</span><br><span class="line">   <span class="string">"connect_timeout"</span>:60000,</span><br><span class="line">   <span class="string">"id"</span>:<span class="string">"92956672-f5ea-4e9a-b096-667bf55bc40c"</span>,</span><br><span class="line">   <span class="string">"protocol"</span>:<span class="string">"http"</span>,</span><br><span class="line">   <span class="string">"name"</span>:<span class="string">"example-service"</span>,</span><br><span class="line">   <span class="string">"read_timeout"</span>:60000,</span><br><span class="line">   <span class="string">"port"</span>:80,</span><br><span class="line">   <span class="string">"path"</span>:null,</span><br><span class="line">   <span class="string">"updated_at"</span>:1519130509,</span><br><span class="line">   <span class="string">"retries"</span>:5,</span><br><span class="line">   <span class="string">"write_timeout"</span>:60000</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="为服务添加路由"><a href="#为服务添加路由" class="headerlink" title="为服务添加路由"></a>为服务添加路由</h3><p>Add a Route for the Service</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">curl -i -X POST \</span><br><span class="line">  --url http://localhost:8001/services/example-service/routes \</span><br><span class="line">  --data <span class="string">'hosts[]=example.com'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 类似的响应</span></span><br><span class="line">HTTP/1.1 201 Created</span><br><span class="line">Content-Type: application/json</span><br><span class="line">Connection: keep-alive</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">   <span class="string">"created_at"</span>:1519131139,</span><br><span class="line">   <span class="string">"strip_path"</span>:<span class="literal">true</span>,</span><br><span class="line">   <span class="string">"hosts"</span>:[</span><br><span class="line">      <span class="string">"example.com"</span></span><br><span class="line">   ],</span><br><span class="line">   <span class="string">"preserve_host"</span>:<span class="literal">false</span>,</span><br><span class="line">   <span class="string">"regex_priority"</span>:0,</span><br><span class="line">   <span class="string">"updated_at"</span>:1519131139,</span><br><span class="line">   <span class="string">"paths"</span>:null,</span><br><span class="line">   <span class="string">"service"</span>:&#123;</span><br><span class="line">      <span class="string">"id"</span>:<span class="string">"79d7ee6e-9fc7-4b95-aa3b-61d2e17e7516"</span></span><br><span class="line">   &#125;,</span><br><span class="line">   <span class="string">"methods"</span>:null,</span><br><span class="line">   <span class="string">"protocols"</span>:[</span><br><span class="line">      <span class="string">"http"</span>,</span><br><span class="line">      <span class="string">"https"</span></span><br><span class="line">   ],</span><br><span class="line">   <span class="string">"id"</span>:<span class="string">"f9ce2ed7-c06e-4e16-bd5d-3a82daef3f9d"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Kong现在知道你的服务并准备代理请求。</p><p><br><br><br></p><h3 id="转发请求"><a href="#转发请求" class="headerlink" title="转发请求"></a>转发请求</h3><p>Forward your requests through Kong</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 发出一下cURL请求来验证Kong是否正确地将请求转发给服务</span></span><br><span class="line"><span class="comment"># 默认情况下，Kong在8000端口上处理代理请求</span></span><br><span class="line">curl -i -X GET \</span><br><span class="line">  --url http://localhost:8000/ \</span><br><span class="line">  --header <span class="string">'Host: example.com'</span></span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="启用插件"><a href="#启用插件" class="headerlink" title="启用插件"></a>启用插件</h2><p><a href="https://docs.konghq.com/1.1.x/getting-started/enabling-plugins/" target="_blank" rel="noopener">Enabling Plugins</a></p><p>在本章中，你将学习如何配置Kong<strong>插件（Plugins）</strong>。Kong的核心原则之一是它通过插件的可扩展性。插件允许你轻松地向服务添加新功能或使其更易于管理。</p><p>下面的栗子中，将配置<code>key-auth</code>插件以向服务添加身份认证。</p><p><br><br><br></p><h3 id="配置插件"><a href="#配置插件" class="headerlink" title="配置插件"></a>配置插件</h3><p>Configure the key-auth plugin</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 插件配置栗子</span></span><br><span class="line">curl -i -X POST \</span><br><span class="line">  --url http://localhost:8001/services/example-service/plugins/ \</span><br><span class="line">  --data <span class="string">'name=key-auth'</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="验证插件"><a href="#验证插件" class="headerlink" title="验证插件"></a>验证插件</h3><p>Verify that the plugin is properly configured</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">curl -i -X GET \</span><br><span class="line">  --url http://localhost:8000/ \</span><br><span class="line">  --header <span class="string">'Host: example.com'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 由于未指定key，因此响应为 401 Unauthorized</span></span><br><span class="line">HTTP/1.1 401 Unauthorized</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"message"</span>: <span class="string">"No API key found in request"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="添加消费者"><a href="#添加消费者" class="headerlink" title="添加消费者"></a>添加消费者</h2><p><a href="https://docs.konghq.com/1.1.x/getting-started/adding-consumers/" target="_blank" rel="noopener">Adding Consumers</a></p><p>在本章中，将介绍将<strong>消费者（Consumer）</strong>添加到Kong实例中。消费者与使用服务的个人相关联，并可用于追踪，访问管理等。</p><p><br></p><h3 id="创建消费者"><a href="#创建消费者" class="headerlink" title="创建消费者"></a>创建消费者</h3><p>Create a Consumer through the RESTful API</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个名为Jason的用户</span></span><br><span class="line"><span class="comment"># Kong还接受custom_id参数</span></span><br><span class="line">curl -i -X POST \</span><br><span class="line">  --url http://localhost:8001/consumers/ \</span><br><span class="line">  --data <span class="string">"username=Jason"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 类似响应</span></span><br><span class="line">HTTP/1.1 201 Created</span><br><span class="line">Content-Type: application/json</span><br><span class="line">Connection: keep-alive</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"username"</span>: <span class="string">"Jason"</span>,</span><br><span class="line">  <span class="string">"created_at"</span>: 1428555626000,</span><br><span class="line">  <span class="string">"id"</span>: <span class="string">"bbdf1c48-19dc-4ab7-cae0-ff4f59d87dc9"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="为消费者提供key"><a href="#为消费者提供key" class="headerlink" title="为消费者提供key"></a>为消费者提供key</h3><p>Provision key credentials for your Consumer</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为消费者创建密钥</span></span><br><span class="line">curl -i -X POST \</span><br><span class="line">  --url http://localhost:8001/consumers/Jason/key-auth/ \</span><br><span class="line">  --data <span class="string">'key=ENTER_KEY_HERE'</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="验证消费者凭证"><a href="#验证消费者凭证" class="headerlink" title="验证消费者凭证"></a>验证消费者凭证</h3><p> Verify that your Consumer credentials are valid</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 发出请求来验证凭据是否有效</span></span><br><span class="line">curl -i -X GET \</span><br><span class="line">  --url http://localhost:8000 \</span><br><span class="line">  --header <span class="string">"Host: example.com"</span> \</span><br><span class="line">  --header <span class="string">"apikey: ENTER_KEY_HERE"</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><hr><p><br><br><br></p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p><a href="https://konghq.com/install/" target="_blank" rel="noopener">install</a></p><p>Kong可以运行在多个环境中。</p><p><br><br><br></p><h2 id="CentOS"><a href="#CentOS" class="headerlink" title="CentOS"></a>CentOS</h2><p><a href="https://docs.konghq.com/install/centos/" target="_blank" rel="noopener">CentOS Installation</a></p><ul><li><strong>安装Kong</strong></li></ul><p>安装方式：</p><ul><li>yum repo</li><li>packages</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># repo</span></span><br><span class="line">wget https://bintray.com/kong/kong-rpm/rpm -O bintray-kong-kong-rpm.repo</span><br><span class="line"><span class="built_in">export</span> major_version=`grep -oE <span class="string">'[0-9]+\.[0-9]+'</span> /etc/redhat-release | cut -d <span class="string">"."</span> -f1`</span><br><span class="line">sed -i -e <span class="string">'s/baseurl.*/&amp;\/centos\/'</span><span class="variable">$major_version</span><span class="string">''</span>/ bintray-kong-kong-rpm.repo</span><br><span class="line">sudo mv bintray-kong-kong-rpm.repo /etc/yum.repos.d/</span><br><span class="line">sudo yum install -y kong</span><br></pre></td></tr></table></figure><p><br></p><ul><li><strong>准备数据库</strong></li></ul><p>Kong支持PostgreSQL v9.5+和Cassandra 3.x.x作为数据存储。</p><p>此处我按照文档安装PostgreSQL v11: <a href="https://www.postgresql.org/download/linux/redhat/" target="_blank" rel="noopener">https://www.postgresql.org/download/linux/redhat/</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装PostgreSQL v11</span></span><br><span class="line">sudo yum install -y https://download.postgresql.org/pub/repos/yum/11/redhat/rhel-7-x86_64/pgdg-centos11-11-2.noarch.rpm</span><br><span class="line"></span><br><span class="line">sudo yum install -y postgresql11</span><br><span class="line"></span><br><span class="line">sudo yum install -y postgresql11-server</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自启</span></span><br><span class="line">/usr/pgsql-11/bin/postgresql-11-setup initdb</span><br><span class="line">systemctl <span class="built_in">enable</span> postgresql-11</span><br><span class="line">systemctl start postgresql-11</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"># 登录psql</span><br><span class="line">sudo su postgres</span><br><span class="line">psql</span><br><span class="line"></span><br><span class="line"># 创建数据库，官方默认无密码，此处我使用密码</span><br><span class="line"># CREATE USER kong; CREATE DATABASE kong OWNER kong;</span><br><span class="line">CREATE USER kong with password &apos;kong&apos;; CREATE DATABASE kong OWNER kong; grant all privileges on database kong to kong;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 这里可能会报连接错误</span><br><span class="line"># psql: 致命错误:  对用户&quot;kong&quot;的对等认证失败</span><br><span class="line">sudo find / -name pg_hba.conf</span><br><span class="line">/var/lib/pgsql/11/data/pg_hba.conf</span><br><span class="line"></span><br><span class="line"># 修改安全配置</span><br><span class="line">vim /var/lib/pgsql/11/data/pg_hba.conf</span><br><span class="line"></span><br><span class="line"># METHOD指定如何处理客户端的认证。常用的有ident，md5，password，trust，reject</span><br><span class="line"># ident是Linux下PostgreSQL默认的local认证方式，凡是能正确登录服务器的操作系统用户（注：不是数据库用户）就能使用本用户映射的数据库用户不需密码登录数据库。</span><br><span class="line"># md5是常用的密码认证方式，如果你不使用ident，最好使用md5。密码是以md5形式传送给数据库，较安全，且不需建立同名的操作系统用户。</span><br><span class="line"># password是以明文密码传送给数据库，建议不要在生产环境中使用。</span><br><span class="line"># trust是只要知道数据库用户名就不需要密码或ident就能登录，建议不要在生产环境中使用。</span><br><span class="line"># reject是拒绝认证。</span><br><span class="line"></span><br><span class="line"># &quot;local&quot; is for Unix domain socket connections only</span><br><span class="line">local   all             all                                     peer</span><br><span class="line"># IPv4 local connections:</span><br><span class="line">host    all             all             127.0.0.1/32            ident</span><br><span class="line"># IPv6 local connections:</span><br><span class="line">host    all             all             ::1/128                 ident</span><br><span class="line"></span><br><span class="line"># 将peer改为md5（）</span><br><span class="line"># &quot;local&quot; is for Unix domain socket connections only</span><br><span class="line">local   all             all                                     md5</span><br><span class="line"># IPv4 local connections:</span><br><span class="line">host    all             all             127.0.0.1/32            ident</span><br><span class="line"># IPv6 local connections:</span><br><span class="line">host    all             all             ::1/128                 ident</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 重启psql</span><br><span class="line">systemctl restart postgresql-11</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 登录postgre</span><br><span class="line">psql -U kong</span><br><span class="line"># 输入密码</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 查看帮助</span><br><span class="line">\h</span><br><span class="line"></span><br><span class="line"># 退出</span><br><span class="line">\q</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里需要提前配置kong配置文件，默认/etc/kong/kong.conf.default</span></span><br><span class="line">cp /etc/kong/kong.conf.default /etc/kong/kong.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改里面的数据库配置，写入用户、密码、数据库、端口等信息</span></span><br><span class="line">vim /etc/kong/kong.conf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Kong migrations</span></span><br><span class="line">kong migrations bootstrap [-c /path/to/kong.conf]</span><br></pre></td></tr></table></figure><p><br></p><ul><li><strong>启动Kong</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kong start [-c /path/to/kong.conf]</span><br></pre></td></tr></table></figure><p><br></p><ul><li><strong>使用Kong</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -i http://localhost:8001/</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h2><p><a href="https://docs.konghq.com/install/docker/" target="_blank" rel="noopener">Docker Installation</a></p><p>以下是一个快速示例。</p><ul><li><strong>Create a Docker network</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network create kong-net</span><br></pre></td></tr></table></figure><p><br></p><ul><li><strong>Start your database</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PostgreSQL</span></span><br><span class="line">docker run -d --name kong-database \</span><br><span class="line">               --network=kong-net \</span><br><span class="line">               -p 5432:5432 \</span><br><span class="line">               -e <span class="string">"POSTGRES_USER=kong"</span> \</span><br><span class="line">               -e <span class="string">"POSTGRES_DB=kong"</span> \</span><br><span class="line">               postgres:9.6</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># or Cassandra</span></span><br><span class="line">docker run -d --name kong-database \</span><br><span class="line">               --network=kong-net \</span><br><span class="line">               -p 9042:9042 \</span><br><span class="line">               cassandra:3</span><br></pre></td></tr></table></figure><p><br></p><ul><li><strong>Prepare your database</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm \</span><br><span class="line">     --network=kong-net \</span><br><span class="line">     -e <span class="string">"KONG_DATABASE=postgres"</span> \</span><br><span class="line">     -e <span class="string">"KONG_PG_HOST=kong-database"</span> \</span><br><span class="line">     -e <span class="string">"KONG_CASSANDRA_CONTACT_POINTS=kong-database"</span> \</span><br><span class="line">     kong:latest kong migrations bootstrap</span><br></pre></td></tr></table></figure><p><br></p><ul><li><strong>Start Kong</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name kong \</span><br><span class="line">     --network=kong-net \</span><br><span class="line">     -e <span class="string">"KONG_DATABASE=postgres"</span> \</span><br><span class="line">     -e <span class="string">"KONG_PG_HOST=kong-database"</span> \</span><br><span class="line">     -e <span class="string">"KONG_CASSANDRA_CONTACT_POINTS=kong-database"</span> \</span><br><span class="line">     -e <span class="string">"KONG_PROXY_ACCESS_LOG=/dev/stdout"</span> \</span><br><span class="line">     -e <span class="string">"KONG_ADMIN_ACCESS_LOG=/dev/stdout"</span> \</span><br><span class="line">     -e <span class="string">"KONG_PROXY_ERROR_LOG=/dev/stderr"</span> \</span><br><span class="line">     -e <span class="string">"KONG_ADMIN_ERROR_LOG=/dev/stderr"</span> \</span><br><span class="line">     -e <span class="string">"KONG_ADMIN_LISTEN=0.0.0.0:8001, 0.0.0.0:8444 ssl"</span> \</span><br><span class="line">     -p 8000:8000 \</span><br><span class="line">     -p 8443:8443 \</span><br><span class="line">     -p 8001:8001 \</span><br><span class="line">     -p 8444:8444 \</span><br><span class="line">     kong:latest</span><br></pre></td></tr></table></figure><p><br></p><ul><li><strong>Use Kong</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -i http://localhost:8001/</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="k8s"><a href="#k8s" class="headerlink" title="k8s"></a>k8s</h2><p><a href="https://docs.konghq.com/install/kubernetes/" target="_blank" rel="noopener">Kong on Kubernetes</a></p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="无数据库和声明性配置"><a href="#无数据库和声明性配置" class="headerlink" title="无数据库和声明性配置"></a>无数据库和声明性配置</h1><p><a href="https://docs.konghq.com/1.1.x/db-less-and-declarative-config/" target="_blank" rel="noopener">DB-less and Declarative Configuration</a></p><p>传统上，Kong总是需要一个数据库（如PostgreSQL或Cassandra），来存储其配置的实体（如服务、路由和插件）。<br>Kong使用其配置文件（<code>kong.conf</code>）来指定各种设置。</p><p>Kong v1.1增加了在没有数据库的情况下运行Kong的能力，仅对实体使用内存存储。—— 称之为<strong>无数据库模式（DB-less mode）</strong>。当运行KOng无数据模式时，实体的配置是使用<strong>声明性配置（declarative configuration）</strong>（YAML或JSON）在第二本配置文件中完成的。</p><p>无数据库模式和声明性配置的组合具有许多优点：</p><ul><li>减少依赖的数量： 如果用例的整个设置适合内存，则无需管理数据库安装</li><li>非常适合CI/CD场景中的自动化：实体配置可以保存在通过Git Repo管理的单一源中</li><li>为Kong提供了更多的部署选项：在Service Mesh场景中非常适合轻量级Sidecar</li></ul><p><br><br><br></p><h2 id="声明性配置"><a href="#声明性配置" class="headerlink" title="声明性配置"></a>声明性配置</h2><p>What Is Declarative Configuration</p><p>正如其名称所言，声明性配置中的关键思想是陈述它是声明性（declarative）的，而不是命令式（ imperative style）配置。<br><strong>Imperative</strong>意味着配置是作为一系列顺序给出的：做这做那。<br><strong>Declarative</strong>意味着配置一次全部给出：宣布这是世界的状态。</p><p>Kong Admin API是命令式配置工具的一个栗子：配置的最终状态是通过一系列API调用获得。一个调用创建服务，一个调用创建路由，另一个调用添加插件…</p><p>像这样递增地执行具有中间状态的配置，会发生不期望的副作用。如在创建路由和添加插件之间存在时间窗口，其中路由没有应用插件。</p><p>另一方面，声明性配置文件将包含单个文件中所有所需实体的设置，并且一旦将改配置加载到Kong中，它将替换整个配置。当需要增量更改时，将对声明性配置文件进行更改，然后将其完整地重新加载。在任何时候，加载到Kong中的文件中描述的配置是系统的配置状态。</p><p><br><br><br></p><h2 id="在无数据库模式配置Kong"><a href="#在无数据库模式配置Kong" class="headerlink" title="在无数据库模式配置Kong"></a>在无数据库模式配置Kong</h2><p>Setting Up Kong in DB-less mode</p><p>要在无数据库模式下使用Kong，有两种方式：</p><ul><li>修改配置文件<code>kong.conf</code></li><li>修改环境变量<code>KONG_DATABASE</code></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/kong/kong.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># database = postgres</span></span><br><span class="line">database=off</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 或</span></span><br><span class="line"><span class="built_in">export</span> KONG_DATABASE=off</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kong start -c /etc/kong/kong.conf</span><br></pre></td></tr></table></figure><p>一旦Kong启动，访问Admin API的<code>/</code>根端点已验证它是否在没有数据库的情况下运行。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># httpie: &lt;https://github.com/jakubroztocil/httpie&gt;</span></span><br><span class="line">$ http :8001/</span><br><span class="line"></span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Access-Control-Allow-Origin: *</span><br><span class="line">Connection: keep-alive</span><br><span class="line">Content-Length: 6342</span><br><span class="line">Content-Type: application/json; charset=utf-8</span><br><span class="line">Date: Wed, 27 Mar 2019 15:24:58 GMT</span><br><span class="line">Server: kong/1.1.0</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"configuration:"</span> &#123;</span><br><span class="line">       ...</span><br><span class="line">       <span class="string">"database"</span>: <span class="string">"off"</span>,</span><br><span class="line">       ...</span><br><span class="line">    &#125;,</span><br><span class="line">    ...</span><br><span class="line">    <span class="string">"version"</span>: <span class="string">"1.1.0"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Kong正在运行，但尚未加载声明性配置。这意味着此节点的配置为空。没有任何类型的路由、服务或实体。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># httpie</span></span><br><span class="line">http :8001/routes</span><br><span class="line"></span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Access-Control-Allow-Origin: *</span><br><span class="line">Connection: keep-alive</span><br><span class="line">Content-Length: 23</span><br><span class="line">Content-Type: application/json; charset=utf-8</span><br><span class="line">Date: Tue, 14 May 2019 06:58:37 GMT</span><br><span class="line">Server: kong/1.1.2</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"data"</span>: [],</span><br><span class="line">    <span class="string">"next"</span>: null</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br><br><br></p><h2 id="创建声明性配置文件"><a href="#创建声明性配置文件" class="headerlink" title="创建声明性配置文件"></a>创建声明性配置文件</h2><p>Creating a Declarative Configuration File</p><p>要将实体载入到无数据库的Kong，我们需要一个声明性配置文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此命令在当前目录中创建kong.yml文件</span></span><br><span class="line">kong config -c kong.conf init</span><br><span class="line"></span><br><span class="line">ls .</span><br><span class="line">kong.yml</span><br></pre></td></tr></table></figure><p><br><br><br></p><h2 id="声明性配置格式"><a href="#声明性配置格式" class="headerlink" title="声明性配置格式"></a>声明性配置格式</h2><p>The Declarative Configuration Format</p><p>Kong声明性配置格式由实体列表及其属性组成。</p><p>看看<code>kong.yml</code>文件：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># This is an example file to get you started with using</span></span><br><span class="line"><span class="comment"># declarative configuration in Kong.</span></span><br><span class="line"><span class="comment"># ------------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Metadata fields start with an underscore (_)</span></span><br><span class="line"><span class="comment"># Fields that do not start with an underscore represent Kong entities and attributes</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># _format_version is mandatory,</span></span><br><span class="line"><span class="comment"># it specifies the minimum version of Kong that supports the format</span></span><br><span class="line"></span><br><span class="line"><span class="attr">_format_version:</span> <span class="string">"1.1"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Each Kong entity (core entity or custom entity introduced by a plugin)</span></span><br><span class="line"><span class="comment"># can be listed in the top-level as an array of objects:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># services:</span></span><br><span class="line"><span class="comment"># - name: example-service</span></span><br><span class="line"><span class="comment">#   url: http://example.com</span></span><br><span class="line"><span class="comment">#   # Entities can store tags as metadata</span></span><br><span class="line"><span class="comment">#   tags:</span></span><br><span class="line"><span class="comment">#   - example</span></span><br><span class="line"><span class="comment">#   # Entities that have a foreign-key relationship can be nested:</span></span><br><span class="line"><span class="comment">#   routes:</span></span><br><span class="line"><span class="comment">#   - name: example-route</span></span><br><span class="line"><span class="comment">#     paths:</span></span><br><span class="line"><span class="comment">#     - /</span></span><br><span class="line"><span class="comment">#   plugins:</span></span><br><span class="line"><span class="comment">#   - name: key-auth</span></span><br><span class="line"><span class="comment"># - name: another-service</span></span><br><span class="line"><span class="comment">#   url: https://example.org</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># routes:</span></span><br><span class="line"><span class="comment"># - name: another-route</span></span><br><span class="line"><span class="comment">#   # Relationships can also be specified between top-level entities,</span></span><br><span class="line"><span class="comment">#   # either by name or by id</span></span><br><span class="line"><span class="comment">#   service: example-service</span></span><br><span class="line"><span class="comment">#   hosts: ["hello.com"]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># consumers:</span></span><br><span class="line"><span class="comment"># - username: example-user</span></span><br><span class="line"><span class="comment">#   # Custom entities from plugin can also be specified</span></span><br><span class="line"><span class="comment">#   # If they specify a foreign-key relationshp, they can also be nested</span></span><br><span class="line"><span class="comment">#   keyauth_credentials:</span></span><br><span class="line"><span class="comment">#   - key: my-key</span></span><br><span class="line"><span class="comment">#   plugins:</span></span><br><span class="line"><span class="comment">#   - name: rate-limiting</span></span><br><span class="line"><span class="comment">#     _comment: "these are default rate-limits for user example-user"</span></span><br><span class="line"><span class="comment">#     config:</span></span><br><span class="line"><span class="comment">#       policy: local</span></span><br><span class="line"><span class="comment">#       second: 5</span></span><br><span class="line"><span class="comment">#       hour: 10000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># When an entity has multiple foreign-key relationships</span></span><br><span class="line"><span class="comment"># (e.g. a plugin matching on both consumer and service)</span></span><br><span class="line"><span class="comment"># it must be specified as a top-level entity, and not through</span></span><br><span class="line"><span class="comment"># nesting.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># plugins:</span></span><br><span class="line"><span class="comment"># - name: rate-limiting</span></span><br><span class="line"><span class="comment">#   consumer: example-user</span></span><br><span class="line"><span class="comment">#   service: another-service</span></span><br><span class="line"><span class="comment">#   _comment: "example-user is extra limited when using another-service"</span></span><br><span class="line"><span class="comment">#   config:</span></span><br><span class="line"><span class="comment">#     hour: 2</span></span><br><span class="line"><span class="comment">#   # tags are for your organization only and have no meaning for Kong:</span></span><br><span class="line"><span class="comment">#   tags:</span></span><br><span class="line"><span class="comment">#   - extra_limits</span></span><br><span class="line"><span class="comment">#   - my_tag</span></span><br></pre></td></tr></table></figure><p>唯一必须声明的元数据是<code>_format_version</code>，它指定声明性配置语法格式的版本号。这也匹配解析文件所需的Kong的最小版本。</p><p><br><br><br></p><h2 id="检查声明性配置文件"><a href="#检查声明性配置文件" class="headerlink" title="检查声明性配置文件"></a>检查声明性配置文件</h2><p>Checking The Declarative Configuration File</p><p>编辑完文件后，可在将声明性配置文件加载到Kong之前检查任何语法错误。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># parse &lt;file&gt;，Parse a declarative config file (check its syntax) but do not load it into Kong.</span></span><br><span class="line"><span class="comment"># kong config -c kong.conf parse kong.yml</span></span><br><span class="line">kong config parse kong.yml</span><br><span class="line"></span><br><span class="line">parse successful</span><br></pre></td></tr></table></figure><p><br><br><br></p><h2 id="加载声明性配置文件"><a href="#加载声明性配置文件" class="headerlink" title="加载声明性配置文件"></a>加载声明性配置文件</h2><p>Loading The Declarative Configuration File</p><p>有两种方式可将声明性配置文件加载到Kong：</p><ul><li>通过<code>kong.conf</code></li><li>通过Admin API</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kong.conf</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改环境变量</span></span><br><span class="line"><span class="built_in">export</span> KONG_DATABASE=off</span><br><span class="line"><span class="built_in">export</span> KONG_DECLARATIVE_CONFIG=kong.yml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或修改配置文件</span></span><br><span class="line">database=off</span><br><span class="line">declarative_config=kong.yml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kong start -c /etc/kong/kong.conf</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用/根端点通过其Admin API将声明性配置加载在正在运行的Kong节点中</span></span><br><span class="line"><span class="comment"># 栗子使用httpie加载kong.yml</span></span><br><span class="line">http :8001/config config=@kong.yml</span><br><span class="line"></span><br><span class="line">HTTP/1.1 201 Created</span><br><span class="line">Access-Control-Allow-Origin: *</span><br><span class="line">Connection: keep-alive</span><br><span class="line">Content-Length: 2</span><br><span class="line">Content-Type: application/json; charset=utf-8</span><br><span class="line">Date: Tue, 14 May 2019 06:59:57 GMT</span><br><span class="line">Server: kong/1.1.2</span><br></pre></td></tr></table></figure><p><br><br><br></p><h2 id="在无数据库模式下使用Kong"><a href="#在无数据库模式下使用Kong" class="headerlink" title="在无数据库模式下使用Kong"></a>在无数据库模式下使用Kong</h2><p>Using Kong in DB-less Mode</p><p>在无数据库模式下使用Kong时，有许多事项需要注意。</p><p><br></p><h3 id="内存缓存要求"><a href="#内存缓存要求" class="headerlink" title="内存缓存要求"></a>内存缓存要求</h3><p>Memory Cache Requirements</p><p>实体的整个配置必须适合Kong Cache。确保正确配置了内存缓存（memory cache）。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grep <span class="string">'mem_cache_size'</span> /etc/kong/kong.conf</span><br><span class="line"></span><br><span class="line"><span class="comment">#mem_cache_size = 128m</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="只读Admin-API"><a href="#只读Admin-API" class="headerlink" title="只读Admin API"></a>只读Admin API</h3><p>Read-Only Admin API</p><p>由于配置实体的唯一方法是通过声明性配置文件，因此在无数据库模式下运行Kong时，实体上的CRUD操作的端点在Admin API中实际上是只读的。<code>GET</code>操作正常工作，但在端点(/services, /plugins…)中<code>POST, PATCH, PUT, DELETE</code>将返回<code>HTTP 405 Not Allowed</code>。</p><p>此限制仅限于数据库操作。特别是，仍然启用<code>POST</code>来设置目标的运行状态，因为这是特定节点的内存中的操作。</p><p><br><br><br></p><h3 id="插件兼容性"><a href="#插件兼容性" class="headerlink" title="插件兼容性"></a>插件兼容性</h3><p>Plugin Compatibility</p><p>并非所有的Kong插件斗鱼无数据库模式兼容。因为其中一些插件需要中央数据库协调或动态创建实体。</p><p><br></p><p><strong>完全兼容（Fully Compatible）</strong><br>以下插件只从数据库中读取（大多是读取初始配置），因此与无数据库模式完全兼容。</p><ul><li><code>aws-lambda</code></li><li><code>azure-functions</code></li><li><code>bot-detection</code></li><li><code>correlation-id</code></li><li><code>cors</code></li><li><code>datadog</code></li><li><code>file-log</code></li><li><code>http-log</code></li><li><code>tcp-log</code></li><li><code>udp-log</code></li><li><code>syslog</code></li><li><code>ip-restriction</code></li><li><code>prometheus</code></li><li><code>zipkin</code></li><li><code>request-transformer</code></li><li><code>response-transformer</code></li><li><code>request-termination</code></li><li><code>kubernetes-sidecar-injector</code></li></ul><p><br></p><p><strong>部分兼容（Partial Compatibility）</strong><br>只要使用的凭证集是静态的并且指定为声明性配置的一部分，就可以使用认证插件。在无数据库模式下，无法使用Admin API端点来动态创建、更新或删除凭据。属于此类的插件有：</p><ul><li><code>acl</code></li><li><code>basic-auth</code></li><li><code>hmac-auth</code></li><li><code>jwt</code></li><li><code>key-auth</code></li></ul><p>与Kong捆绑在一起的速率限制插件提供了不同的策略来存储可协调计数器：</p><ul><li><code>Local</code>策略：用于存储计数器节点的内存，以每个节点的方式应用限制；</li><li><code>Redis</code>策略：使用Redis作为外部键值存储来协调跨节点的计数器；</li><li><code>Cluster</code>策略：使用Kong数据库作为集群范围限制的中心协调点。</li></ul><p>在无数据库模式下，Local和Redis策略可用，无法使用Cluster策略。属于此类的插件有：</p><ul><li><code>rate-limiting</code></li><li><code>response-ratelimiting</code></li></ul><p>无服务器（serverless）的<code>pre-function</code>和<code>post-function</code>可在无数据库模式下使用。但需注意，如果任何已配置的功能尝试写入数据库，则写入将失败。</p><p><br></p><p><strong>不兼容（Not Compatible）</strong></p><ul><li><code>oauth2</code>：对于常规工作，插件需生成和删除token，并将这些更改提交到数据库</li></ul><p><br><br><br></p><hr><p><br><br><br></p><h1 id="流和服务网格"><a href="#流和服务网格" class="headerlink" title="流和服务网格"></a>流和服务网格</h1><p><a href="https://docs.konghq.com/1.1.x/streams-and-service-mesh/" target="_blank" rel="noopener">Streams and Service Mesh</a></p><p>Kong v1.0.0增加了代理(proxy)和路由(route)原始TCP和TLS流(stream)的能力，并使用service-mesh sidecar和在Kong节点之间交互TLS来部署Kong。<br>本章将介绍使用简单工具简化Service Mesh部署的基本设置： 两台服务器，通过两个Kong节点在一台主机中互相通信。如果你有兴趣使用k8s运行Service Mesh，请查看<a href="https://github.com/Kong/kong-mesh-dist-kubernetes" target="_blank" rel="noopener">Kubernetes and Service Mesh example</a></p><p>Kong支持逐步部署sidecar。它即可以作为传统网关，也可作为服务网格节点同时工作。在Kong中，服务网格是动态构建的，只有在Kong节点之间存在活动连接时才存在。简而言之，这意味着Kong节点不必了解其它Kong节点，服务也不必了解Kong。</p><p><br></p><h2 id="先决条件"><a href="#先决条件" class="headerlink" title="先决条件"></a>先决条件</h2><p>Prerequisites</p><p>需使用Kong v1.1.0+来运行不同的部署方案。建议使用Linux发行版来演示。系统上需要的一些工具：</p><ul><li><code>ncat</code>(<code>nmap</code>)</li><li><code>iptables</code></li><li><code>curl</code></li></ul><p>你的主机需要监控<code>lo0</code>网络适配器绑定到这些ip：</p><ul><li><code>127.0.0.1</code> (Host C running Kong Control Plane)</li><li><code>127.0.0.2</code> (Host A running Service A)</li><li><code>127.0.0.3</code> (Host A running Kong A)</li><li><code>127.0.0.4</code> (Host B running Kong B)</li><li><code>127.0.0.5</code> (Host B running Service B)</li></ul><p>本章的教程在单个主机上运行所有内容。为了简单起见，我们还是用IP地址而不是DNS来配置所有内容。<br>对于某些更改，可能需要root权限。</p><p><br><br><br><br><br></p><h2 id="术语和定义"><a href="#术语和定义" class="headerlink" title="术语和定义"></a>术语和定义</h2><p>Terms and Definitions</p><ul><li><strong>Kong Control Plane</strong>： 在<code>127.0.0.1</code>上启动。它在<code>8001</code>和<code>8444</code>上监听Kong Admin API，它不代理任何流量；</li><li><strong>Service A</strong>：假象的业务实体（微服务），使网络连接到Service B；</li><li><strong>Service B</strong>：接受来自Service A的网络连接的业务实体；</li><li><strong>Kong A</strong>：它是服务A前端的sidecar代理。它不监听和提供Kong Admin API；</li><li><strong>Kong B</strong>：它是服务B前端的sidecar代理。它不监听和提供Kong Admin API；</li></ul><p><br><br><br><br><br></p><h2 id="步骤1：启动服务B"><a href="#步骤1：启动服务B" class="headerlink" title="步骤1：启动服务B"></a>步骤1：启动服务B</h2><p>Step1: Start Service B</p><p>启动Service B监听TCP流量：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ ncat --listen \</span><br><span class="line">       --keep-open \</span><br><span class="line">       --verbose \</span><br><span class="line">       --sh-exec <span class="string">"echo 'Hello from Service B (TCP)'"</span> \</span><br><span class="line">       127.0.0.5 19000</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Ncat: Version 7.50 ( https://nmap.org/ncat )</span><br><span class="line">Ncat: Listening on 127.0.0.5:19000</span><br></pre></td></tr></table></figure><p><br></p><p>让命令继续运行。开一个新控制台并启动Service B监听TLS流量。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ ncat --listen \</span><br><span class="line">       --keep-open \</span><br><span class="line">       --verbose \</span><br><span class="line">       --ssl \</span><br><span class="line">       --sh-exec <span class="string">"echo 'Hello from Service B (TLS)'"</span> \</span><br><span class="line">       127.0.0.5 19443</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Ncat: Version 7.50 ( https://nmap.org/ncat )</span><br><span class="line">Ncat: Listening on 127.0.0.5:19443</span><br></pre></td></tr></table></figure><p><br></p><p>让它继续运行。开一个新控制台并启动Service B监听HTTP流量。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ncat --listen \</span><br><span class="line">     --keep-open \</span><br><span class="line">     --verbose \</span><br><span class="line">     --sh-exec <span class="string">"echo 'HTTP/1.1 200 OK\r\n\r\nHello from Service (HTTP)'"</span> \</span><br><span class="line">     127.0.0.5 18000</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Ncat: Version 7.50 ( https://nmap.org/ncat )</span><br><span class="line">Ncat: Listening on 127.0.0.5:18000</span><br></pre></td></tr></table></figure><p><br></p><p>让它继续运行，开一个新控制台并启动Service B监听HTTPS流量。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ncat --listen \</span><br><span class="line">     --keep-open \</span><br><span class="line">     --verbose \</span><br><span class="line">     --ssl \</span><br><span class="line">     --sh-exec <span class="string">"echo 'HTTP/1.1 200 OK\r\n\r\nHello from Service B (HTTPS)'"</span> \</span><br><span class="line">     127.0.0.5 18443</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Ncat: Version 7.50 ( https://nmap.org/ncat )</span><br><span class="line">Ncat: Generating a temporary 1024-bit RSA key. Use --ssl-key and --ssl-cert to use a permanent one.</span><br><span class="line">Ncat: SHA-1 fingerprint: 9B41 1A89 664A 434A 35A7 6DFA 9540 3D21 9466 46D1</span><br><span class="line">Ncat: Listening on 127.0.0.5:18443</span><br></pre></td></tr></table></figure><p>同样，保持命令继续运行。<br>此时，应该有4个ncat进程在运行，表示Service B使用不同的协议进行监听。</p><p><br><br><br><br><br></p><h2 id="步骤2：确保服务A可以连接到服务B"><a href="#步骤2：确保服务A可以连接到服务B" class="headerlink" title="步骤2：确保服务A可以连接到服务B"></a>步骤2：确保服务A可以连接到服务B</h2><p>Step2: Ensure that Service A can connect Service B</p><p>Service A直接调用<code>ncat</code>和<code>curl</code>。</p><p><br></p><p>使用TCP与Service B连接。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ncat --<span class="built_in">source</span> 127.0.0.2 --recv-only 127.0.0.5 19000</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Hello from Service B (TCP)</span><br></pre></td></tr></table></figure><p><br></p><p>使用TLS与Service B连接。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ncat --<span class="built_in">source</span> 127.0.0.2 --recv-only --ssl 127.0.0.5 19443</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Hello from Service B (TLS)</span><br></pre></td></tr></table></figure><p><br></p><p>使用HTTP与Service B连接。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl --interface 127.0.0.2 http://127.0.0.5:18000</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Hello from Service B (HTTP)</span><br></pre></td></tr></table></figure><p><br></p><p>使用HTTPS与Service B连接。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl --interface 127.0.0.2 --insecure https://127.0.0.5:18443</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Hello from Service B (HTTPS)</span><br></pre></td></tr></table></figure><p>服务A运行在<code>127.0.0.2</code>并可以直接连接到服务B。</p><p><br><br><br><br><br></p><h2 id="步骤3：启动Kong控制面板"><a href="#步骤3：启动Kong控制面板" class="headerlink" title="步骤3：启动Kong控制面板"></a>步骤3：启动Kong控制面板</h2><p>Step 3: Start Kong Control Plane</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动金监听Kong Admin API的Kong节点</span></span><br><span class="line">KONG_PREFIX=kong-c \</span><br><span class="line">KONG_LOG_LEVEL=debug \</span><br><span class="line">KONG_STREAM_LISTEN=<span class="string">"off"</span> \</span><br><span class="line">KONG_PROXY_LISTEN=<span class="string">"off"</span> \</span><br><span class="line">KONG_ADMIN_LISTEN=<span class="string">"127.0.0.1:8001, 127.0.0.1:8444 ssl"</span> \</span><br><span class="line">  kong start</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Kong started</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="步骤4：启动Kong-A"><a href="#步骤4：启动Kong-A" class="headerlink" title="步骤4：启动Kong A"></a>步骤4：启动Kong A</h2><p>Step4: Start Kong A</p><p>Kong A将是一个作为Service A的sidecar的Kong实例。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">KONG_PREFIX=kong<span class="_">-a</span> \</span><br><span class="line">KONG_LOG_LEVEL=debug \</span><br><span class="line">KONG_STREAM_LISTEN=<span class="string">"127.0.0.3:9000 transparent, 127.0.0.3:9443 transparent"</span> \</span><br><span class="line">KONG_PROXY_LISTEN=<span class="string">"127.0.0.3:8000 transparent, 127.0.0.3:8443 ssl transparent"</span> \</span><br><span class="line">KONG_ADMIN_LISTEN=<span class="string">"off"</span> \</span><br><span class="line">KONG_NGINX_PROXY_PROXY_BIND=<span class="string">"127.0.0.3"</span> \</span><br><span class="line">KONG_NGINX_SPROXY_PROXY_BIND=<span class="string">"127.0.0.3"</span> \</span><br><span class="line">  kong start</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Kong started</span><br></pre></td></tr></table></figure><p><br></p><p><strong>关于<code>transparent</code>选项</strong></p><p><code>transparent</code>选项使Kong可使用<code>iptables PREROUTING</code>规则的请求，并在<code>iptables</code>堆栈透明地将其代理到其sidecar代理之前读取原始目标地址和客户端尝试连接的端口。</p><p><br><br><br><br><br></p><h2 id="步骤5：启动Kong-B"><a href="#步骤5：启动Kong-B" class="headerlink" title="步骤5：启动Kong B"></a>步骤5：启动Kong B</h2><p>Step 5: Start Kong B</p><p>Kong B将是一个作为Service B的sidecar的Kong实例。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">KONG_PREFIX=kong-b \</span><br><span class="line">KONG_LOG_LEVEL=debug \</span><br><span class="line">KONG_STREAM_LISTEN=<span class="string">"127.0.0.4:9000 transparent, 127.0.0.4:9443 transparent"</span> \</span><br><span class="line">KONG_PROXY_LISTEN=<span class="string">"127.0.0.4:8000 transparent, 127.0.0.4:8443 transparent ssl"</span> \</span><br><span class="line">KONG_ADMIN_LISTEN=<span class="string">"off"</span> \</span><br><span class="line">KONG_NGINX_PROXY_PROXY_BIND=<span class="string">"127.0.0.4"</span> \</span><br><span class="line">KONG_NGINX_SPROXY_PROXY_BIND=<span class="string">"127.0.0.4"</span> \</span><br><span class="line">  kong start</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Kong started</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="步骤6：创建Kong服务和路由"><a href="#步骤6：创建Kong服务和路由" class="headerlink" title="步骤6：创建Kong服务和路由"></a>步骤6：创建Kong服务和路由</h2><p>Step 6: Create Kong Services and Routes</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为Service B的TCP流量创建Kong服务</span></span><br><span class="line">curl -X PUT \</span><br><span class="line">       -d url=tcp://127.0.0.5:19000 \</span><br><span class="line">       http://127.0.0.1:8001/services/service-b-tcp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为服务创建路由</span></span><br><span class="line">curl -X POST \</span><br><span class="line">       -d name=service-b-tcp \</span><br><span class="line">       -d protocols=tcp \</span><br><span class="line">       -d destinations[1].ip=127.0.0.5 \</span><br><span class="line">       -d destinations[1].port=19000 \</span><br><span class="line">       http://127.0.0.1:8001/services/service-b-tcp/routes</span><br></pre></td></tr></table></figure><p><br></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为Service B的TLS流量创建服务</span></span><br><span class="line">curl -X PUT \</span><br><span class="line">       -d url=tls://127.0.0.5:19443 \</span><br><span class="line">       http://127.0.0.1:8001/services/service-b-tls</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加路由</span></span><br><span class="line">curl -X POST \</span><br><span class="line">       -d name=service-b-tls \</span><br><span class="line">       -d protocols=tls \</span><br><span class="line">       -d destinations[1].ip=127.0.0.5 \</span><br><span class="line">       -d destinations[1].port=19443 \</span><br><span class="line">       http://127.0.0.1:8001/services/service-b-tls/routes</span><br></pre></td></tr></table></figure><p><br></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为Service B的HTTP流量创建服务</span></span><br><span class="line">curl -X PUT \</span><br><span class="line">       -d url=http://127.0.0.5:18000 \</span><br><span class="line">       http://127.0.0.1:8001/services/service-b-http</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加路由</span></span><br><span class="line">curl -X POST \</span><br><span class="line">       -d name=service-b-http \</span><br><span class="line">       -d protocols=http \</span><br><span class="line">       -d hosts=127.0.0.5 \</span><br><span class="line">       http://127.0.0.1:8001/services/service-b-http/routes</span><br></pre></td></tr></table></figure><p><br></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为Service B的HTTPS流量创建服务</span></span><br><span class="line">curl -X PUT \</span><br><span class="line">       -d url=https://127.0.0.5:18443/ \</span><br><span class="line">       http://127.0.0.1:8001/services/service-b-https</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加路由</span></span><br><span class="line">curl -X POST \</span><br><span class="line">       -d name=service-b-https \</span><br><span class="line">       -d protocols=https \</span><br><span class="line">       -d hosts=127.0.0.5 \</span><br><span class="line">       http://127.0.0.1:8001/services/service-b-https/routes</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="步骤7：配置代理规则"><a href="#步骤7：配置代理规则" class="headerlink" title="步骤7：配置代理规则"></a>步骤7：配置代理规则</h2><p>Step 7: Configure Transparent Proxying Rules</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>Reference</p><p><br></p><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p><a href="https://docs.konghq.com/1.1.x/configuration/" target="_blank" rel="noopener">Configuration Reference</a></p><p><br></p><h3 id="配置加载"><a href="#配置加载" class="headerlink" title="配置加载"></a>配置加载</h3><p>Configuration loading</p><p>如果通关官方软件包安装Kong，则可以在<code>/etc/kong/kong.conf.default</code>找到此默认文件。</p><p>如果配置文件中的所有值都被注释掉，Kong将使用默认配置运行。为方便起见，可将布尔值指定为<code>on/off</code>或<code>true/false</code>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置Kong</span></span><br><span class="line">cp /etc/kong/kong.conf.default /etc/kong/kong.conf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动时，Kong会查找可能包含配置文件的多个默认位置</span></span><br><span class="line">/etc/kong.conf</span><br><span class="line">/etc/kong/kong.conf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过-c/--conf参数指定自定义配置文件来覆盖默认行为</span></span><br><span class="line">kong start --conf /path/to/kong.conf</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="验证配置"><a href="#验证配置" class="headerlink" title="验证配置"></a>验证配置</h3><p>Verifying your configuration</p><p>你可以通过命令验证配置的完整性：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kong check /path/to/kong.conf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># debug模式</span></span><br><span class="line">kong start -c /path/to/kong.conf --vv</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h3><p>Environment variables</p><p>从配置文件中加载属性时，Kong还是查找同名的环境变量。这允许你通过环境变量配置Kong，这对于容器结构非常方便。<br>要使用环境变量覆盖配置，请设置声明环境变量，如<code>KONG_XXX</code>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kong.conf</span></span><br><span class="line">log_level = debug</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># env</span></span><br><span class="line"><span class="built_in">export</span> KONG_LOG_LEVEL=error</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="注入Nginx指令"><a href="#注入Nginx指令" class="headerlink" title="注入Nginx指令"></a>注入Nginx指令</h3><p>Injecting Nginx directives</p><p>通过调整Kong实例的Nginx配置，你可以优化其基础架构的性能。</p><p>当Kong启动时，它会构建一个Nginx配置文件。你可通过Kong配置直接将自定义Nginx指令注入此文件。</p><p><br></p><h4 id="注入单个Nginx指令"><a href="#注入单个Nginx指令" class="headerlink" title="注入单个Nginx指令"></a>注入单个Nginx指令</h4><p>Injecting individual Nginx directives</p><p>添加到<code>kong.conf</code>文件的任何以<code>nginx_http_</code>, <code>nging_proxy_</code>, <code>nginx_admin_</code>为前缀的条目将通过删除前缀并添加到Nginx配置的相应部分而转换为等效的Nginx指令。</p><ul><li>带有<code>nginx_http_</code>前缀的条目将被注入http块；</li><li>带有<code>nginx_proxy_</code>前缀的条目将被注入处理Kong的代理端口的server块；</li><li>带有<code>nginx_admin_</code>前缀的条目将被注入处理Kong的Admin API端口的server块。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例如，将以下行添加到`kong.conf`文件：</span></span><br><span class="line">nginx_proxy_large_client_header_buffers=16 128k</span><br><span class="line"><span class="comment"># 它将添加到Kong的Nginx 配置的代理server</span></span><br><span class="line">large_client_header_buffers 16 128k;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 或通过环境变量</span></span><br><span class="line"><span class="built_in">export</span> KONG_NGINX_HTTP_OUTPUT_BUFFERS=<span class="string">"4 64k"</span></span><br><span class="line"><span class="comment"># 它将添加到nginx的http块</span></span><br><span class="line">output_buffers 4 64k;</span><br></pre></td></tr></table></figure><p>有关更多的Nginx指令，请参考<a href="https://nginx.org/en/docs/dirindex.html" target="_blank" rel="noopener">Nginx文档</a>。但请注意，某些执行依赖于特定Nginx模块，其中一些可能没有包含在Kong版本中。</p><p><br><br><br></p><h4 id="注入Nginx指令文件"><a href="#注入Nginx指令文件" class="headerlink" title="注入Nginx指令文件"></a>注入Nginx指令文件</h4><p>Including files via injected Nginx directives</p><p>对于更复杂的配置，可将Nginx指令写入配置文件，然后将其注入Kong。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 栗子，my-server.kong.conf</span></span><br><span class="line"><span class="comment"># custom server</span></span><br><span class="line">server &#123;</span><br><span class="line">  listen 2112;</span><br><span class="line">  location / &#123;</span><br><span class="line">    <span class="comment"># ...more settings...</span></span><br><span class="line">    <span class="built_in">return</span> 200;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在kong.conf配置文件中添加条目使kong节点服务此端口</span></span><br><span class="line">nginx_http_include = /path/to/your/my-server.kong.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或通过环境变量</span></span><br><span class="line"><span class="built_in">export</span> KONG_NGINX_HTTP_INCLUDE=<span class="string">"/path/to/your/my-server.kong.conf"</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试</span></span><br><span class="line">curl -I http://127.0.0.1:2112</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="自定义Nginx模板并嵌入Kong"><a href="#自定义Nginx模板并嵌入Kong" class="headerlink" title="自定义Nginx模板并嵌入Kong"></a>自定义Nginx模板并嵌入Kong</h3><p>Custom Nginx templates and embedding Kong</p><p>对于绝大多数用例，使用上面的指令注入已足够定义Kong的Nginx实例的行为。这样，你可从单个<code>kong.conf</code>文件（以及自己包含的文件）管理Kong节点的配置和调优，而无需自定义Nginx配置模板。</p><p>有两种情况，你希望直接使用自定义的Nginx配置模板：</p><ul><li>在极少数情况下，你可能需要修改一些不能通过其标准<code>kong.conf</code>属性调整的Kong默认的Nginx配置。你可以修改Kong用于生成器Nginx配置并使用你自定义的模板启动Kong的模板；</li><li>如果需要在已经运行的OpenResty实例中嵌入Kong，则可重用Kong生成的配置并将其包含在现有配置中。</li></ul><p><br></p><h4 id="自定义Nginx模板"><a href="#自定义Nginx模板" class="headerlink" title="自定义Nginx模板"></a>自定义Nginx模板</h4><p>Custom Nginx templates</p><p>可使用<code>--nginx-conf</code>参数启动、重载和重启Kong，该参数必须指定Nginx配置模板。这样的模板使用Penlight模板引擎，该引擎使用给定的Kong配置进行编译，然后在启动Nginx之前将其转储到Kong前缀目录中。</p><p>默认模板可在GitHub上查看: <a href="https://github.com/kong/kong/tree/master/kong/templates" target="_blank" rel="noopener">https://github.com/kong/kong/tree/master/kong/templates</a>。它分为两个Nginx配置文件<code>nginx.lua</code>和<code>nginx_kong.lua</code>。当<code>kong start</code>运行时，它会将这两个文件复制到前缀目录中，如下所示:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/kong</span><br><span class="line">├── nginx-kong.conf</span><br><span class="line">└── nginx.conf</span><br></pre></td></tr></table></figure><p>如果你必须调整Kong定义但不能通过<code>kong.conf</code>配置的全局设置，你可将<code>nginx_kong.lua</code>配置模板的内容内联到一个自定义模板文件，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># ---------------------</span><br><span class="line"># custom_nginx.template</span><br><span class="line"># ---------------------</span><br><span class="line"></span><br><span class="line">worker_processes $&#123;&#123;NGINX_WORKER_PROCESSES&#125;&#125;; # can be set by kong.conf</span><br><span class="line">daemon $&#123;&#123;NGINX_DAEMON&#125;&#125;;                     # can be set by kong.conf</span><br><span class="line"></span><br><span class="line">pid pids/nginx.pid;                      # this setting is mandatory</span><br><span class="line">error_log logs/error.log $&#123;&#123;LOG_LEVEL&#125;&#125;; # can be set by kong.conf</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    use epoll;          # a custom setting</span><br><span class="line">    multi_accept on;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line"></span><br><span class="line">  # contents of the nginx_kong.lua template follow:</span><br><span class="line"></span><br><span class="line">  resolver $&#123;&#123;DNS_RESOLVER&#125;&#125; ipv6=off;</span><br><span class="line">  charset UTF-8;</span><br><span class="line">  error_log logs/error.log $&#123;&#123;LOG_LEVEL&#125;&#125;;</span><br><span class="line">  access_log logs/access.log;</span><br><span class="line"></span><br><span class="line">  ... # etc</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">kong start -c kong.conf --nginx-conf custom_nginx.template</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="在OpenResty中嵌入Kong"><a href="#在OpenResty中嵌入Kong" class="headerlink" title="在OpenResty中嵌入Kong"></a>在OpenResty中嵌入Kong</h3><p>Embedding Kong in OpenResty</p><p>如果您正在运行自己的OpenResty Server，您还可以通过使用<code>include</code>指令包含Kong Nginx自配置来轻松嵌入Kong。栗子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># my_nginx.conf</span><br><span class="line"></span><br><span class="line"># ...your nginx settings...</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    include &apos;nginx-kong.conf&apos;;</span><br><span class="line"></span><br><span class="line">    # ...your nginx settings...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#启动Nginx实例</span></span><br><span class="line">nginx -p /usr/<span class="built_in">local</span>/openresty -c my_nginx.conf</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="同时提供来自Kong的Website和API"><a href="#同时提供来自Kong的Website和API" class="headerlink" title="同时提供来自Kong的Website和API"></a>同时提供来自Kong的Website和API</h3><p>Serving both a website and your APIs from Kong</p><p>提供API的一个常见用例是让Kong通过代理端口(80/443)在生产中同时为Website和API提供服务。例如，<code>https://example.net</code>（Website）和<code>https://example.net/api/v1</code>（API）。<br>为了实现此目标，我们不能简单地声明一个新的虚拟<code>server</code>块。一个好的解决办法是使用自定义Nginx配置模板，该模板内联<code>nginx_kong.lua</code>并添加一个新的<code>location</code>块，为Kong Proxy <code>location</code>块提供服务。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"># ---------------------</span><br><span class="line"># custom_nginx.template</span><br><span class="line"># ---------------------</span><br><span class="line"></span><br><span class="line">worker_processes $&#123;&#123;NGINX_WORKER_PROCESSES&#125;&#125;; # can be set by kong.conf</span><br><span class="line">daemon $&#123;&#123;NGINX_DAEMON&#125;&#125;;                     # can be set by kong.conf</span><br><span class="line"></span><br><span class="line">pid pids/nginx.pid;                      # this setting is mandatory</span><br><span class="line">error_log logs/error.log $&#123;&#123;LOG_LEVEL&#125;&#125;; # can be set by kong.conf</span><br><span class="line">events &#123;&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">  # here, we inline the contents of nginx_kong.lua</span><br><span class="line">  charset UTF-8;</span><br><span class="line"></span><br><span class="line">  # any contents until Kong&apos;s Proxy server block</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  # Kong&apos;s Proxy server block</span><br><span class="line">  server &#123;</span><br><span class="line">    server_name kong;</span><br><span class="line"></span><br><span class="line">    # any contents until the location / block</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    # here, we declare our custom location serving our website</span><br><span class="line">    # (or API portal) which we can optimize for serving static assets</span><br><span class="line">    location / &#123;</span><br><span class="line">      root /var/www/example.net;</span><br><span class="line">      index index.htm index.html;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    # Kong&apos;s Proxy location / has been changed to /api/v1</span><br><span class="line">    location /api/v1 &#123;</span><br><span class="line">      set $upstream_host nil;</span><br><span class="line">      set $upstream_scheme nil;</span><br><span class="line">      set $upstream_uri nil;</span><br><span class="line"></span><br><span class="line">      # Any remaining configuration for the Proxy location</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  # Kong&apos;s Admin server block goes below</span><br><span class="line">  # ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h3><p>Properties reference</p><p><br></p><h4 id="GENERAL"><a href="#GENERAL" class="headerlink" title="GENERAL"></a>GENERAL</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">#------------------------------------------------------------------------------</span><br><span class="line"># GENERAL</span><br><span class="line">#------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 工作目录。相当于Nginx的前缀路径，包含临时文件和日志</span><br><span class="line"># 每个Kong进程必须有一个单独的工作目录</span><br><span class="line">prefix = /usr/local/kong/  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Nginx Server的日志级别，位于&lt;prefix&gt;/logs/error.log</span><br><span class="line">log_level = notice  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 代理端口的访问日志路径。设置为off可禁用</span><br><span class="line"># 如果此值是相对路径，则它位于&lt;prefix&gt;</span><br><span class="line">proxy_access_log = logs/access.log  #default</span><br><span class="line"></span><br><span class="line"># 代理端口的错误日志路径</span><br><span class="line">proxy_error_log = logs/error.log  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Admin API请求访问的日志路径</span><br><span class="line">admin_access_log = logs/admin_access.log  #default</span><br><span class="line"></span><br><span class="line"># Admin API请求错误的日志路径</span><br><span class="line">admin_error_log = logs/error.log</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># plugins</span><br><span class="line"># 加载以逗号分隔的插件列表。默认情况下，只有捆绑在官方发行版中的插件才会通过bundled关键字加载。</span><br><span class="line"># 默认不启用加载插件</span><br><span class="line"># 特定名称将在Lua命名空间中替换为：kong.plugins.&#123;name&#125;.*</span><br><span class="line"># off关键字被指定为唯一时，不会加载任何插件</span><br><span class="line"># bundled和plugin名称可以混合在一起，示例如下：</span><br><span class="line">#  - plugins = bundled,custom-auth,custom-log</span><br><span class="line">#  - plugins = custom-auth,custom-log</span><br><span class="line">#  - plugins = off</span><br><span class="line"># 在禁用插件之前，请确保在重新启动Kong之前删除它的所有实例</span><br><span class="line">plugin = bundled  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 发送匿名使用数据，如错误栈追踪，以帮助改善Kong</span><br><span class="line">anonymous_reports = on  #default</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="NGINX"><a href="#NGINX" class="headerlink" title="NGINX"></a>NGINX</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br></pre></td><td class="code"><pre><span class="line">#------------------------------------------------------------------------------</span><br><span class="line"># NGINX</span><br><span class="line">#------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 以逗号分隔的代理服务器应监听HTTP/HTTPS流量的地址和端口列表</span><br><span class="line"># 代理服务器是Kong的公共入口点，它将来自消费者的流量代理到后端服务</span><br><span class="line"># 此值接受IPv4, IPv6, hostname</span><br><span class="line"># 可以为每对指定一些后缀：</span><br><span class="line">#  - ssl，要求通过特定地址/端口建立的所有连接都在启用TLS的情况下进行</span><br><span class="line">#  - http2，允许客户端打开到Kong代理服务器的HTTP2连接</span><br><span class="line">#  - proxy_protocol，为给定的地址/端口启用PROXY协议</span><br><span class="line">#  - transparent，Kong监听您在iptables中配置的任何IP 地址和端口，并进行响应</span><br><span class="line"># 此值可设为off，从而禁用此节点的HTTP/HTTPS代理端口</span><br><span class="line"># 栗子：proxy_listen = 0.0.0.0:443 ssl, 0.0.0.0:444 http2 ssl</span><br><span class="line">proxy_listen = 0.0.0.0:8000, 0.0.0.0:8443 ssl  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 流模式监听以逗号分隔的地址和端口列表</span><br><span class="line"># 此值接受 IPv4, Ipv6, hostname</span><br><span class="line"># 可为每队指定一些后缀：</span><br><span class="line">#  - proxy_protocol，为给定的地址/端口启用PROXY协议</span><br><span class="line">#  - transparent，Kong监听您在iptables中配置的任何IP 地址和端口，并进行响应</span><br><span class="line"># 不支持ssl后缀，并且每个地址/端口都将接受启用/未启用TLS的TCP</span><br><span class="line"># 栗子：</span><br><span class="line"># stream_listen = 127.0.0.1:7000</span><br><span class="line"># stream_listen = 0.0.0.0:989, 0.0.0.0:20</span><br><span class="line"># stream_listen = [::1]:1234</span><br><span class="line"># 默认设置为off，从而禁用此节点的流代理端口</span><br><span class="line">stream_listen = off  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Admin接口监听的地址和端口列表</span><br><span class="line"># Admin API允许您配置和管理Kong</span><br><span class="line"># 应仅限于Kong管理员访问此接口</span><br><span class="line"># 此值接受 IPv4, IPv6, Hostname</span><br><span class="line"># 可为每队执行一些后缀：</span><br><span class="line">#  - ssl</span><br><span class="line">#  - http2</span><br><span class="line">#  - proxy_protocol</span><br><span class="line"># 栗子</span><br><span class="line"># stream_listen = 127.0.0.1:8444 http2 ssl</span><br><span class="line">admin_listen = 127.0.0.1:8001, 127.0.0.1:8444 ssl  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义工作进程使用的用户和组凭据</span><br><span class="line"># 如果省略group，则默认为User一致</span><br><span class="line">nginx_user = nobody nobody</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Nginx生成的工作进程数</span><br><span class="line">nginx_worker_processes = auto  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Nginx是作为守护进程还是前台进程运行</span><br><span class="line"># 主要用于在Docker环境下运行Kong</span><br><span class="line">nginx_daemon = on  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 数据库实体的内存缓存大小</span><br><span class="line"># 单位接收KB和MB，最小推荐值几MBs</span><br><span class="line">mem_cache_size = 128m  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义Nginx提供的TLS密码</span><br><span class="line"># 可接受的值包括：modern, intermediate, old, custom</span><br><span class="line">ssl_cipher_suite = modern  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义由Nginx提供服务的TLS密码的自定义列表。此列表必须符合openssl密码定义的模式</span><br><span class="line">ssl_ciphers =  #Default: none</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 启用SL的proxy_listen值的SSL证书的绝对路径</span><br><span class="line">ssl_cert =  #Default: none</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 启用SSL的proxy_listen值的SSL Key的绝对路径</span><br><span class="line">ssl_cert_key =  #Default: none</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 确定代理请求时Nginx是否应发送客户端SSL证书</span><br><span class="line">client_ssl = off  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 如果启用了client_ssl，则为proxy_ssl_certificate指令的客户端SSL证书的绝对路径</span><br><span class="line"># 请注意，此值是在节点上静态定义的，并且当前无法基于每个API进行配置。</span><br><span class="line">client_ssl_cert =  #Default: none</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 如果启用了client_ssl，则为proxy_ssl_certificate_key地址的客户端SSL密钥的绝对路径</span><br><span class="line"># 请注意，此值是在节点上静态定义的，目前无法基于每个API进行配置</span><br><span class="line">client_ssl_cert_key =  #Default: none</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 启用SSL的admin_listen值的SSL证书的绝对路径</span><br><span class="line">admin_ssl_cert =  #Default: none</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 启用SSL的admin_listen值的SSL Key的绝对路径</span><br><span class="line">admin_ssl_cert_key =  #Default: none</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 设置在每个工作进程的缓存中保留的上游服务器的最大空闲keepalive连接数。</span><br><span class="line"># 超过此数量时，将关闭最近最少使用的连接。</span><br><span class="line"># 值为0表示禁用此功能</span><br><span class="line">upstream_keepalive = 60  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 以逗号分隔的Header列表应该在客户端响应中注入</span><br><span class="line"># 接受的值如下：</span><br><span class="line">#  - Server，Server: kong/x.y.z</span><br><span class="line">#  - Via，Via: kong/x.y.z</span><br><span class="line">#  - X-Kong-Proxy-Latency，Kong代理上游请求之前处理并运行所有插件所花费的时间(ms)</span><br><span class="line">#  - X-Kong-Upstream-Latency，上游服务发送响应头所花费的时间(ms)</span><br><span class="line">#  - X-Kong-Upstream-Status，上游服务返回的HTTP状态码。如果响应被插件重写，这对于客户端区分上游状态特别有用</span><br><span class="line">#  - server_tokens，与指定Server和Via相同</span><br><span class="line">#  - latency_tokens，与指定X-Kong-Proxy-Latency和X-Kong-Upstream-Latency相同</span><br><span class="line">headers = server_tokens, latency_tokens  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义已知可发送正确的 X-Forwarded-* Header 的可信IP地址块</span><br><span class="line"># 来自信任的IP的请求使Kong向上游转发了它们的 X-Forwarded-* Header</span><br><span class="line"># 不受信任的请求使Kong插入它自己的 X-Forwarded-* headers</span><br><span class="line"># 此属性还在Nginx配置中配置 set_real_ip_from 指令。它接受相同类型的值(CIDR)，以逗号分割的列表</span><br><span class="line"># 要信任所有IP，将值设置为 0.0.0.0/0,::/0</span><br><span class="line"># 如果指定为 unix:，则所有 UNIX-domain sockets都将被信任</span><br><span class="line">trusted_ips =    #default: none</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义请求头字段，其值将用于替换客户端地址</span><br><span class="line"># 此值设置Nginx配置中同名的 ngx_http_realip_module 指令</span><br><span class="line"># 如果此值接收 proxy_protocol</span><br><span class="line">#  - 至少有一个 proxy_listen 条目必须启用 proxy_protocol 标志</span><br><span class="line">#  - proxy_ptotocol 参数将附加到Nginx模板的 listen 指令</span><br><span class="line">real_ip_header = X-Real-IP  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 此值设置Nginx配置中同名的ngx_http_realip_module指令</span><br><span class="line">real_ip_recursive = off  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义由Kong代理的请求所运行的最大请求主体大小，在Content-Length请求头中指定。如果请求超过此限制，Kong将响应413（Request Entity Too Large）</span><br><span class="line"># 将此值设置为0禁用检查请求主体大小</span><br><span class="line">client_max_body_size = 0    #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义用于读取请求正文的缓冲区大小。如果客户端请求正文（request body）大于此值，则正文（body）将被缓冲到磁盘</span><br><span class="line"># 请注意，当主体缓冲到磁盘时，访问或操作请求主体可能无法正常工作，因此建议将此值设置得尽可能高。（例如，将其设置为与client_max_body_size一样，以强制保留请求主体在内存中）</span><br><span class="line"># 请注意，高并发环境将需要大量内存分配来处理许多并发的大型请求</span><br><span class="line">client_body_buffer_size = 8k  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 缺少Request Accept Header且Nginx返回请求错误时要使用的默认MIME类型</span><br><span class="line"># 接受的值有： text/plain, text/html, application/json, application/xml</span><br><span class="line">error_default_type = text/plain  #default</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="Database"><a href="#Database" class="headerlink" title="Database"></a>Database</h4><p>Kong把所有数据（如路由、服务、消费者、插件…）存储在Cassandra或PostgreSQL中，并且属于同一集群的所有Kong节点必须将它们自己连接到同一个数据库。</p><p>Kong支持的版本:</p><ul><li>PostgreSQL v9.5+</li><li>Cassandra v2.2+</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">#------------------------------------------------------------------------------</span><br><span class="line"># DATASTORE</span><br><span class="line">#------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 确定使用哪种存储</span><br><span class="line"># 接受的值有：postgres、cassandra、off</span><br><span class="line">database = postgres  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Postgres settings</span><br><span class="line">pg_host</span><br><span class="line">pg_port</span><br><span class="line">pg_timeout</span><br><span class="line">pg_user</span><br><span class="line">pg_password</span><br><span class="line">pg_database</span><br><span class="line">pg_schema</span><br><span class="line">pg_ssl</span><br><span class="line">pg_ssl_verify</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Cassandra settings</span><br><span class="line">cassandra_contact_points</span><br><span class="line">cassandra_port</span><br><span class="line">cassandra_keyspace</span><br><span class="line">cassandra_consistency</span><br><span class="line">cassandra_timeout</span><br><span class="line">cassandra_ssl</span><br><span class="line">cassandra_ssl_verify</span><br><span class="line">cassandra_username</span><br><span class="line">cassandra_password</span><br><span class="line">cassandra_lb_policy</span><br><span class="line">cassandra_local_datacenter</span><br><span class="line">cassandra_repl_strategy</span><br><span class="line">cassandra_repl_factor</span><br><span class="line">cassandra_data_centers</span><br><span class="line">cassandra_schema_consensus_timeout</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="Datastore-Cache"><a href="#Datastore-Cache" class="headerlink" title="Datastore Cache"></a>Datastore Cache</h4><p>为了避免与数据存储进行不必要的通信，Kong可将实体缓存一段可配置的时间。如果更新了这样的实体，它还会处理失效。<br>本节允许配置Kong关于此类配置实体的缓存的行为。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">#------------------------------------------------------------------------------</span><br><span class="line"># DATASTORE CACHE</span><br><span class="line">#------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 使用数据存储检查更新实体的频率（单位s）</span><br><span class="line"># 当节点通过Admin API创建，更新或删除实体时，其他节点需要等待下一轮询（由此值配置）以最终清除旧的缓存实体并开始使用新的实体</span><br><span class="line">db_update_frequency = 5  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 数据存储中的实体传播到另一个数据中心的副本节点所用的时间（单位s）</span><br><span class="line"># 单数据中心或单节点没有这样的问题，可安全地设置为0</span><br><span class="line">db_update_propagation = 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 此节点缓存时实体从数据存储区的ttl（单位s）</span><br><span class="line"># 如果设置为0，则永不过期</span><br><span class="line">db_cache_ttl = 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 数据存储区中的陈旧实体在无法刷新是的时间。当此TTL到期时，将进行刷新陈旧实体的新尝试</span><br><span class="line">db_resurrect_ttl = 30</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="DNS-Resolver"><a href="#DNS-Resolver" class="headerlink" title="DNS Resolver"></a>DNS Resolver</h4><p>默认情况下，DNS解析器将使用标准配置文件<code>/etc/hosts</code>和<code>/etc/resolv.conf</code>。如果已设置环境变量<code>LOCALDOMAIN</code>和<code>RES_OPTIONS</code>，则后一个文件的设置将被覆盖。</p><p>Kong会将主机名解析为<code>SRV</code>或<code>A</code>记录。如果名称被解析为SRV记录，它还将通过从DNS服务器接收的端口字段内容覆盖任何给定的端口号。</p><p>在ttl的持续时间内，内部DNS解析器将对通过DNS记录中的条目获得的每个请求进行负载均衡。对于SRV记录，权重（weight）字段将被接受，但它将仅使用记录中的最低优先级（priority）字段条目。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">#------------------------------------------------------------------------------</span><br><span class="line"># DNS RESOLVER</span><br><span class="line">#------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 以逗号分隔的nameserver列表，每个条目都采用 ip[:port] 的格式供Kong使用。如果省略，端口默认为53。它接受IPv4和IPv6地址</span><br><span class="line"># 如果未指定，将使用本地 resolv.conf 文件的配置</span><br><span class="line">dns_resolver =  #default: none</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 要使用的hosts文件。此文件只读一次便加载为静态内存内容</span><br><span class="line"># 要在修改后再次读取文件，必须重新加载Kong</span><br><span class="line">dns_hostsfile = /etc/hosts  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 解析不同记录类型的顺序</span><br><span class="line">dns_order = LAST,SRV,A,CNAME  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 默认情况下，使用响应的TTL值缓存DNS记录。如果此属性收到一个值（以秒为单位），它将覆盖所有记录的TTL</span><br><span class="line">dns_valid_ttl =  #default: none</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义记录在缓存中保留的时间长度</span><br><span class="line">dns_stale_ttl = 4  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 空DNS响应和名称错误响应的TTL</span><br><span class="line">dns_not_found_ttl = 30  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 错误响应的TTL</span><br><span class="line">dns_error_ttl = 1  #default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 如果启用，则在缓存未命中时，每个请求都将触发其自己的dns查询</span><br><span class="line"># 禁用时，同一名称/类型的多个请求将同步到单个查询</span><br><span class="line">dns_no_sync = off</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="Development"><a href="#Development" class="headerlink" title="Development"></a>Development</h4><p>从<code>lua-nginx-module</code>继承的其他设置允许更多的灵活性和高级用法。</p><p><br><br><br></p><h4 id="Additional"><a href="#Additional" class="headerlink" title="Additional"></a>Additional</h4><ul><li><strong>origin</strong></li></ul><p><strong>Origin Configuration</strong>在复杂的网络配置中非常有用，并且在Kong用于<strong>服务网格（Service Mesh）</strong>通常是必需的。</p><p><code>origins</code>是一个以逗号分隔的成对的对象列表，每对使用<code>=</code>。每对左侧的原（origin）被右侧的原(origin)覆盖。此覆盖发生在访问阶段之后和上游解析之前。它具有导致Kong将流向左侧origin的流量发送到右侧origin的效果。</p><p>术语 <code>origin</code> 是指特定 scheme/host或ip/port，如RFC 6454中所描述。在Kong的origin配置中，该方案必须是<code>http</code>, <code>https</code>, <code>tcp</code>, <code>tls</code>。在每对origin中，必须匹配。如http可与https配对，tcp可与tls配对，但http不能与tcp配对。</p><p>When an encrypted scheme like <code>tls</code> or <code>https</code> in the left origin is paired with an unencrypted scheme like <code>tcp</code> or <code>http</code> in the right origin, Kong will terminate TLS on incoming connections matching the left origin, and will then route traffic unencrypted to the specified right origin. This is useful when connections will be made to the Kong node over TLS, but the local service (for which Kong is proxying traffic) doesn’t or can’t terminate TLS. Similarly, if the left origin is <code>tcp</code> or <code>http</code> and the right origin is <code>tls</code> or https, Kong will accept unencrypted incoming traffic, and will then wrap that traffic in TLS as it is routed outbound. This capability is an important enabler of Kong Mesh.</p><p>与所有Kong配置设置一样，可在<code>kong.conf</code>文件中声明origin设置。但是，建议Kong管理员不要这么做。相反，应该使用环境变量在每个节点上设置origin。因此，默认的<code>kong.conf.default</code>中不存在origin。</p><p><br></p><p>栗子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 如果给定的Kong节点具有以下origin的配置</span><br><span class="line">http://upstream-foo-bar:1234=http://localhost:5678</span><br><span class="line"># Kong节点不会尝试解析upstream-foo-bar，而是将该节点路由到localhost:5678</span><br><span class="line"># 在Kong的服务网格部署中，这种覆盖是必要的，以使邻近 upstream-foo-bar 应用程序的实例 Kong sidecar 将流量路由到本地实例，而不是试图将流量通过网络路由回到 upstream-foo-bar 的非本地实例</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 在另一个典型的sidecar部署中，Kong节点作为Kong代理服务的一个实例，origin将配置为</span><br><span class="line">https://service-b:9876=http://localhost:5432</span><br><span class="line"># 这将导致Kong节点仅接受端口9876上的https连接，终止tls，然后将现在未加密的流量转发到localhost:5432</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 下面这个栗子由两对组成，由逗号分隔</span><br><span class="line">https://foo.bar.com:443=http://localhost:80,tls://dog.cat.org:9999=tcp://localhost:8888</span><br><span class="line"># 这将导致Kong仅接受端口443上的https流量，并仅接受 端口9999的TLS流量，在两种情况下都终止TLS，然后分别将流量转发到localhost:80和localhost:8888</span><br><span class="line"># 假设80和8888都与单独的服务相关，当Kong充当节点代理是，可能会发生这种配置，这是一个代表多个服务的本地代理</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="CLI"><a href="#CLI" class="headerlink" title="CLI"></a>CLI</h2><p><a href="https://docs.konghq.com/1.1.x/cli/" target="_blank" rel="noopener">CLI Reference</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Global flags</span></span><br><span class="line">--<span class="built_in">help</span>: <span class="built_in">print</span> the <span class="built_in">command</span>’s <span class="built_in">help</span> message</span><br><span class="line">--v: <span class="built_in">enable</span> verbose mode</span><br><span class="line">--vv: <span class="built_in">enable</span> debug mode (noisy)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kong --<span class="built_in">help</span></span><br><span class="line">No such <span class="built_in">command</span>: --<span class="built_in">help</span></span><br><span class="line"></span><br><span class="line">Usage: kong COMMAND [OPTIONS]</span><br><span class="line"></span><br><span class="line">The available commands are:</span><br><span class="line"> check</span><br><span class="line"> config</span><br><span class="line"> health</span><br><span class="line"> migrations</span><br><span class="line"> prepare</span><br><span class="line"> quit</span><br><span class="line"> reload</span><br><span class="line"> restart</span><br><span class="line"> roar</span><br><span class="line"> start</span><br><span class="line"> stop</span><br><span class="line"> version</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line"> --v              verbose</span><br><span class="line"> --vv             debug</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="Proxy"><a href="#Proxy" class="headerlink" title="Proxy"></a>Proxy</h2><p><a href="https://docs.konghq.com/1.1.x/proxy/" target="_blank" rel="noopener">Proxy Reference</a></p><p>本章我们将通过详细解释其路由功能(routing capabilities)和内部工作来涵盖Kong的代理功能(proxying capabilities)。</p><p>Kong公开了几个可以通过两个配置属性调整的接口:</p><ul><li><code>proxy_listen</code>，默认是<code>8000</code>，接受来自客户端的公共流量(public traffic)并将其代理带上游服务；</li><li><code>admin_listen</code>，默认<code>8001</code>，Admin API被限制为仅由管理员访问。</li></ul><p><br><br><br></p><h3 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h3><p>Terminology：</p><ul><li><code>client</code>，向Kong代理端口发出请求的下游客户端；</li><li><code>upstream service</code>，位于Kong后面的API/Service，转发客户端请求到此；</li><li><code>Service</code>，服务实体是每个上游服务的抽象；</li><li><code>Route</code>，Kong路由实体。路由是进入Kong的入口点(entrypoints)，并定义要匹配的请求的规则，并路由到给定的服务；</li><li><code>Plugin</code>，Kong插件。它们是在代理生命周期中运行的业务逻辑。可通过Admin API配置全局/特定路由和服务的插件。</li></ul><p><br><br><br></p><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>从高层次的角度来看，Kong在其配置的代理和端口上监听HTTP流量(<code>8000/8443</code>)。Kong将根据你配置的路由评估任何传入的HTTP请求，并尝试查找匹配的路由。如果给定的请求与特定路由的规则匹配，Kong将处理代理请求。由于每个路由都链接(link)到一个服务，因此Kong将运行你在路由及相关服务上配置的插件，然后代理请求到上游。</p><p>你可以通过Kong Admin API管理路由。路由的<code>hosts, pahts, methods</code>属性定义用于匹配传入HTTP请求的规则。</p><p>如果Kong收到的请求无法与任何已配置的路由匹配（或没有配置路由），它将返回；</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">HTTP/1.1 404 Not Found</span><br><span class="line">Content-Type: application/json</span><br><span class="line">Server: kong/&lt;x.x.x&gt;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    &quot;message&quot;: &quot;no route and no Service found with those values&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="如何配置服务"><a href="#如何配置服务" class="headerlink" title="如何配置服务"></a>如何配置服务</h3><p>How to configure a Service</p><p>在快速开始指南里面介绍了如何通过Admin API配置Kong。<br>通过向Admin API发送HTTP请求来向Kong添加服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">curl -i -X POST http://localhost:8001/services/ \</span><br><span class="line">    -d <span class="string">'name=foo-service'</span> \</span><br><span class="line">    -d <span class="string">'url=http://foo-service.com'</span></span><br><span class="line">HTTP/1.1 201 Created</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"connect_timeout"</span>: 60000,</span><br><span class="line">    <span class="string">"created_at"</span>: 1515537771,</span><br><span class="line">    <span class="string">"host"</span>: <span class="string">"foo-service.com"</span>,</span><br><span class="line">    <span class="string">"id"</span>: <span class="string">"d54da06c-d69f-4910-8896-915c63c270cd"</span>,</span><br><span class="line">    <span class="string">"name"</span>: <span class="string">"foo-service"</span>,</span><br><span class="line">    <span class="string">"path"</span>: <span class="string">"/"</span>,</span><br><span class="line">    <span class="string">"port"</span>: 80,</span><br><span class="line">    <span class="string">"protocol"</span>: <span class="string">"http"</span>,</span><br><span class="line">    <span class="string">"read_timeout"</span>: 60000,</span><br><span class="line">    <span class="string">"retries"</span>: 5,</span><br><span class="line">    <span class="string">"updated_at"</span>: 1515537771,</span><br><span class="line">    <span class="string">"write_timeout"</span>: 60000</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该请求指示Kong注册一个名为<code>foo-service</code>的服务，该服务指向<code>http://foo-service.com</code>（上游）。<br><code>url</code>参数是一个简写的参数，用于一次填充<code>protocol, host, prot, path</code>属性。</p><p><br></p><p>现在，为了通过Kong向这个服务发送流量，我们需要指定一个路由，它作为Kong的入口点：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">curl -i -X POST http://localhost:8001/routes/ \</span><br><span class="line">    -d <span class="string">'hosts[]=example.com'</span> \</span><br><span class="line">    -d <span class="string">'paths[]=/foo'</span> \</span><br><span class="line">    -d <span class="string">'service.id=d54da06c-d69f-4910-8896-915c63c270cd'</span></span><br><span class="line">HTTP/1.1 201 Created</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"created_at"</span>: 1515539858,</span><br><span class="line">    <span class="string">"hosts"</span>: [</span><br><span class="line">        <span class="string">"example.com"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="string">"id"</span>: <span class="string">"ee794195-6783-4056-a5cc-a7e0fde88c81"</span>,</span><br><span class="line">    <span class="string">"methods"</span>: null,</span><br><span class="line">    <span class="string">"paths"</span>: [</span><br><span class="line">        <span class="string">"/foo"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="string">"preserve_host"</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="string">"priority"</span>: 0,</span><br><span class="line">    <span class="string">"protocols"</span>: [</span><br><span class="line">        <span class="string">"http"</span>,</span><br><span class="line">        <span class="string">"https"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="string">"service"</span>: &#123;</span><br><span class="line">        <span class="string">"id"</span>: <span class="string">"d54da06c-d69f-4910-8896-915c63c270cd"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"strip_path"</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="string">"updated_at"</span>: 1515539858</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们现在已经配置了一个路由来匹配与给定<code>hosts</code>和<code>path</code>匹配的传入请求，并将它们转发到我们配置的<code>foo-service</code>服务，从而将此流量代理到<code>http://foo-service.com</code>。</p><p>Kong是一个透明的代理，它默认情况下会原封不同的(untouched)将请求转发给上游服务，但HTTP规范要求使用各种表头(Header)（如<code>Connection, Date ...</code>）</p><p><br><br><br></p><h3 id="路由和匹配"><a href="#路由和匹配" class="headerlink" title="路由和匹配"></a>路由和匹配</h3><p>Routes and matching capabilities</p><p>现在让我们讨论Kong如何匹配针对路由的已配置的<code>hosts, paths, methods</code>属性的请求。请注意，所有这三个字段都是可选的，但必须指定其中一个。</p><p>对于匹配路由的请求：</p><ul><li>请求必须包含所有已配置的字段；</li><li>请求中的字段值至少与其中一个配置值匹配（当字段配置接受一个或多个值时，请求只需其中一个值被视为匹配）。</li></ul><p><br></p><p>举个栗子。考虑如下配置的路由：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"hosts"</span>: [<span class="string">"example.com"</span>, <span class="string">"foo-service.com"</span>],</span><br><span class="line">    <span class="attr">"paths"</span>: [<span class="string">"/foo"</span>, <span class="string">"/bar"</span>],</span><br><span class="line">    <span class="attr">"methods"</span>: [<span class="string">"GET"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>与此路由匹配的一些可能的请求如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">GET /foo HTTP/1.1</span><br><span class="line">Host: example.com</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">GET /bar HTTP/1.1</span><br><span class="line">Host: foo-service.com</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">GET /foo/hello/world HTTP/1.1</span><br><span class="line">Host: example.com</span><br></pre></td></tr></table></figure><p>所有这三个请求都满足路径定义中设置的所有条件。</p><p>但是，以下请求与配置的路由条件不匹配：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># path不匹配</span><br><span class="line">GET / HTTP/1.1</span><br><span class="line">Host: example.com</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># method不匹配</span><br><span class="line">POST /foo HTTP/1.1</span><br><span class="line">Host: example.com</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># host不匹配</span><br><span class="line">GET /foo HTTP/1.1</span><br><span class="line">Host: foo.com</span><br></pre></td></tr></table></figure><p>现在我们了解了<code>hosts, pahts, mehtods</code>属性如何协作工作，让我们分别探索每个属性。</p><p><br><br><br></p><h4 id="请求主机头"><a href="#请求主机头" class="headerlink" title="请求主机头"></a>请求主机头</h4><p>Request Host header</p><p>基于其Host Header路由请求是通过Kong代理流量的最直接的方式，尤其是因为这是HTTP Host Header的预期用途。Kong可以通过路由实体的<code>hosts</code>字段轻松完成。</p><p><code>hosts</code>接受多个值，在通过Admin API指定它们时必须以逗号分隔。这些值很容易在JSON有效负载中表示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl -i -X POST http://localhost:8001/routes/ \</span><br><span class="line">    -H <span class="string">'Content-Type: application/json'</span> \</span><br><span class="line">    -d <span class="string">'&#123;"hosts":["example.com", "foo-service.com"]&#125;'</span></span><br><span class="line">HTTP/1.1 201 Created</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><br></p><p>由于Admin API还支持<strong>form-urlencoded</strong>内容类型，因此还可通过<code>[]</code>表示法指定数组：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl -i -X POST http://localhost:8001/routes/ \</span><br><span class="line">    -d <span class="string">'hosts[]=example.com'</span> \</span><br><span class="line">    -d <span class="string">'hosts[]=foo-service.com'</span></span><br><span class="line">HTTP/1.1 201 Created</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><br></p><p>要满足此路由的<code>hosts</code>条件，来自客户端的任何传入请求现在必须将Host Header设置为两者之一：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">Host:</span> <span class="string">example.com</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># or</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Host:</span> <span class="string">foo-service.com</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><h5 id="使用通配符主机名"><a href="#使用通配符主机名" class="headerlink" title="使用通配符主机名"></a>使用通配符主机名</h5><p>Using wildcard hostnames</p><p>为了提供灵活性，Kong允许你在<code>hosts</code>字段中指定带通配符的主机名。通配符主机名允许任何匹配的Host Header满足条件，从而匹配给定的路由。</p><p>通配符主机名必须在域的最左侧或最右侧标签中仅包含一个星号(<code>*</code>)：</p><ul><li><code>*.example.com</code><ul><li><code>a.example.com</code></li><li><code>x.y.z.example.com</code></li><li>…</li></ul></li><li><code>example.*</code><ul><li><code>example.com</code></li><li><code>example.org</code></li><li>…</li></ul></li></ul><p><br></p><p>栗子:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"hosts"</span>: [<span class="string">"*.example.com"</span>, <span class="string">"service.com"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>匹配的路由栗子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GET / HTTP/1.1</span><br><span class="line">Host: an.example.com</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">GET / HTTP/1.1</span><br><span class="line">Host: service.com</span><br></pre></td></tr></table></figure><p><br><br><br></p><h5 id="preserve-host属性"><a href="#preserve-host属性" class="headerlink" title="preserve_host属性"></a><code>preserve_host</code>属性</h5><p>代理时，Kong的默认行为是将上游请求的Host Header设置为服务<code>host</code>中指定的主机名。<code>preserve_host</code>字段接受一个布尔标志，指示Kong不要这样做。</p><p>例如，当<code>preserve_host</code>属性未更改且路由配置如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"hosts"</span>: [<span class="string">"service.com"</span>],</span><br><span class="line">    <span class="attr">"service"</span>: &#123;</span><br><span class="line">        <span class="attr">"id"</span>: <span class="string">"..."</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>客户端对Kong的可能请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET / HTTP/1.1</span><br><span class="line">Host: service.com</span><br></pre></td></tr></table></figure><p>Kong从服务的<code>host</code>属性中提取Host Header，并将发送以下上游请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET / HTTP/1.1</span><br><span class="line">Host: &lt;my-service-host.com&gt;</span><br></pre></td></tr></table></figure><p><br></p><p>但是，通过使用<code>preserve_host=true</code>显式配置路由：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"hosts"</span>: [<span class="string">"service.com"</span>],</span><br><span class="line">    <span class="attr">"preserve_host"</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="attr">"service"</span>: &#123;</span><br><span class="line">        <span class="attr">"id"</span>: <span class="string">"..."</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>假设来自客户端的相同请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET / HTTP/1.1</span><br><span class="line">Host: service.com</span><br></pre></td></tr></table></figure><p>Kong将根据客户端请求保留Host，并将发送以下上游请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET / HTTP/1.1</span><br><span class="line">Host: service.com</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="请求路径"><a href="#请求路径" class="headerlink" title="请求路径"></a>请求路径</h4><p>Request path</p><p>路由匹配的另一种方式是通过请求路径。要满足此路由条件，客户端请求的路径必须以<code>paths</code>属性的值之一为前缀。</p><p>例如，如下路由配置：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"paths"</span>: [<span class="string">"/service"</span>, <span class="string">"/hello/world"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以下请求将匹配：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">GET /service HTTP/1.1</span><br><span class="line">Host: example.com</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">GET /service/resource?param=value HTTP/1.1</span><br><span class="line">Host: example.com</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">GET /hello/world/resource HTTP/1.1</span><br><span class="line">Host: anything.com</span><br></pre></td></tr></table></figure><p>对于每一个请求，Kong检测其以路由的路径配置为前缀之一的URL path。默认情况下，Kong会在不更改URL path的情况下代理上游请求。<br>使用路径前缀进行代理时，首先评估最长路径(longest paths)。这允许你定力具有两个路径的两个路由：<code>/service</code>, <code>/service/resource</code>，并确保前者不会遮蔽(shadow)后者。</p><p><br><br><br></p><h5 id="在路径中使用正则"><a href="#在路径中使用正则" class="headerlink" title="在路径中使用正则"></a>在路径中使用正则</h5><p>Using regexes in paths</p><p>Kong通过PCRE(Perl Compatible Regular Expression)支持路由的路径字段的正则表达式模式匹配。你可以同时将路径作为前缀和正则表达式分配给路由。</p><p>例如，考虑如下路由：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"paths"</span>: [<span class="string">"/users/\d+/profile"</span>, <span class="string">"/following"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此路由匹配以下请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GET /following HTTP/1.1</span><br><span class="line">Host: ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">GET /users/123/profile HTTP/1.1</span><br><span class="line">Host: ...</span><br></pre></td></tr></table></figure><p><br></p><ul><li><strong>评估顺序(Evaluation order)</strong></li></ul><p>如前所述，Kong按长度评估前缀路径：首先评估最长路径。但是，Kong将根据路由的<code>regex_priority</code>属性从最高优先级到最低优先级来评估正则表达式。<br>考虑如下路由：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">"paths"</span>: [<span class="string">"/status/\d+"</span>],</span><br><span class="line">        <span class="attr">"regex_priority"</span>: <span class="number">0</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">"paths"</span>: [<span class="string">"/version/\d+/status/\d+"</span>],</span><br><span class="line">        <span class="attr">"regex_priority"</span>: <span class="number">6</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">"paths"</span>: [<span class="string">"/version"</span>],</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">"paths"</span>: [<span class="string">"/version/any/"</span>],</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>在这种情况下，Kong将按照以下顺序评估对以下定义的URL的传入请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. /version/any/</span><br><span class="line">2. /version</span><br><span class="line">3. /version/\d+/status/\d+</span><br><span class="line">4. /status/\d+</span><br></pre></td></tr></table></figure><p>始终在正则表达式之前评估前缀路径。</p><p>向往常一样，请求仍然必须匹配路由的<code>hosts</code>和<code>methods</code>属性，并且Kong将遍历你的路由，直到找到匹配最多规则的路由。</p><p><br></p><ul><li><strong>捕获组(Capturing groups)</strong></li></ul><p>还支持捕获组，并且将从路径中提取匹配的组并可用于插件使用。</p><p>考虑如下正则和请求路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/version/(?&lt;version&gt;\d+)/users/(?&lt;user&gt;\S+)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/version/1/users/john</span><br></pre></td></tr></table></figure><p>Kong会将请求路径视为匹配，如果匹配整个路由(考虑<code>hosts</code>, <code>methods</code>)，则可从<code>ngx.ctx</code>变量中的插件获取捕获组：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">local router_matches = ngx.ctx.router_matches</span><br><span class="line"></span><br><span class="line">-- router_matches.uri_captures is:</span><br><span class="line">-- &#123; &quot;1&quot;, &quot;john&quot;, version = &quot;1&quot;, user = &quot;john&quot; &#125;</span><br></pre></td></tr></table></figure><p><br></p><ul><li><strong>转义特殊字符(Escaping special characters)</strong></li></ul><p>通过Admin API配置具有正则表达式路径的路由时，请务必在必要时对你的有效负载进行URL编码。<br>例如，使用<code>curl</code>并使用<code>application/x-www-form-urlencoded</code>MIME类型：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -i -X POST http://localhost:8001/routes \</span><br><span class="line">    --data-urlencode 'uris[]=/status/\d+'</span><br><span class="line">HTTP/1.1 201 Created</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>请注意，<code>curl</code>不会自动对你的有效负载进行URL编码，并注意使用<code>--data-urlencode</code>，它可以防止对<code>+</code>字符进行URL编码，并将其解释为Kong的Admin API `` 空间。</p><p><br><br><br></p><h5 id="strip-path属性"><a href="#strip-path属性" class="headerlink" title="strip_path属性"></a><code>strip_path</code>属性</h5><p>可能需要指定路径前缀以匹配路由，但不将其包括在上游请求中。要这样做，请在路由配置中使用<code>strip_path</code>属性：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    &quot;paths&quot;: [&quot;/service&quot;],</span><br><span class="line">    &quot;strip_path&quot;: true,</span><br><span class="line">    &quot;service&quot;: &#123;</span><br><span class="line">        &quot;id&quot;: &quot;...&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启用此标志会指示Kong在匹配此路由并继续代理服务时，不应在上游请求的URL中包含URL路径的匹配部分。</p><p><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 例如，以下客户端对上述路由的请求</span><br><span class="line">GET /service/path/to/resource HTTP/1.1</span><br><span class="line">Host: ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 将导致Kong发送以下上游请求</span><br><span class="line">GET /path/to/resource HTTP/1.1</span><br><span class="line">Host: ...</span><br></pre></td></tr></table></figure><p><br></p><p>同样，如果启用了<code>strip_path</code>的路由上定义了正则表达式，则将剥离整个请求URL匹配序列。例如：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"paths"</span>: [<span class="string">"/version/\d+/service"</span>],</span><br><span class="line">    <span class="attr">"strip_path"</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="attr">"service"</span>: &#123;</span><br><span class="line">        <span class="attr">"id"</span>: <span class="string">"..."</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以下HTTP请求与提供的正则表达式路径匹配：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET /version/1/service/path/to/resource HTTP/1.1</span><br><span class="line">Host: ...</span><br></pre></td></tr></table></figure><p>有Kong代理到上游：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET /path/to/resource HTTP/1.1</span><br><span class="line">Host: ...</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="请求方法"><a href="#请求方法" class="headerlink" title="请求方法"></a>请求方法</h4><p>Request HTTP method</p><p><code>methods</code>字段允许根据HTTP方法匹配请求。它接受多个值。其默认值为空（HTTP方法不用于路由）。</p><p>以下路由允许通过<code>GET</code>和<code>HEAD</code>进行路由：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"methods"</span>: [<span class="string">"GET"</span>, <span class="string">"HEAD"</span>],</span><br><span class="line">    <span class="attr">"service"</span>: &#123;</span><br><span class="line">        <span class="attr">"id"</span>: <span class="string">"..."</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样的路由符合以下要求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GET / HTTP/1.1</span><br><span class="line">Host: ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">HEAD /resource HTTP/1.1</span><br><span class="line">Host: ...</span><br></pre></td></tr></table></figure><p>但它与<code>POST</code>和<code>DELETE</code>请求不匹配。在路由上配置插件时，这允许更多粒度。例如，你可以想象两个执行同一服务的路由：</p><ul><li>一个具有无限制的未认证的<code>GET</code>请求</li><li>另一个仅允许经过身份认证和速率限制的<code>POST</code>请求</li></ul><p><br><br><br></p><h3 id="匹配优先级"><a href="#匹配优先级" class="headerlink" title="匹配优先级"></a>匹配优先级</h3><p>Matching priorities</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kong GitHub: &lt;a href=&quot;https://github.com/Kong/kong&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/Kong/kong&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Kong Docs: &lt;a href=&quot;https://docs.konghq.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://docs.konghq.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;环境：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ELRH7x86_64&lt;/li&gt;
&lt;li&gt;Kong v1.1&lt;/li&gt;
&lt;li&gt;Docker CE v18.09&lt;/li&gt;
&lt;li&gt;K8s v1.11&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="Service Mesh" scheme="https://zhang21.github.io/tags/Service-Mesh/"/>
    
      <category term="API" scheme="https://zhang21.github.io/tags/API/"/>
    
      <category term="APIGateway" scheme="https://zhang21.github.io/tags/APIGateway/"/>
    
      <category term="MicroService" scheme="https://zhang21.github.io/tags/MicroService/"/>
    
  </entry>
  
  <entry>
    <title>OSTEP</title>
    <link href="https://zhang21.github.io/2019/04/28/OSThreeEasyPieces/"/>
    <id>https://zhang21.github.io/2019/04/28/OSThreeEasyPieces/</id>
    <published>2019-04-28T00:59:12.000Z</published>
    <updated>2019-05-23T02:37:47.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>OS Three Easy Pieces: <a href="https://book.douban.com/subject/19973015/" target="_blank" rel="noopener">https://book.douban.com/subject/19973015/</a></li><li>OSTEP: <a href="http://pages.cs.wisc.edu/~remzi/OSTEP/" target="_blank" rel="noopener">http://pages.cs.wisc.edu/~remzi/OSTEP/</a></li></ul><p><br></p><p>环境:</p><ul><li>ELRH7x86_64</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="操作系统介绍"><a href="#操作系统介绍" class="headerlink" title="操作系统介绍"></a>操作系统介绍</h1><p>Introduction to Operating Systems</p><p>如果你正在攻读本科操作系统课程，你应该已经知道计算机程序运行时的想法。如果没有，这本书将很难。</p><p>那么，程序运行时会发生什么呢？<br>好吧，正在运行的程序做了一件非常简单的事情: <strong>它执行指令(it executes instructions)</strong>。<br>每秒都有成千上万次，处理器从内存(mem)中取出(fetch)指令，对其进行解码(decode)——即确定这是哪条指令，并执行它。完成此指令后，进程将继续执行下一条指令，以此类推，直到程序最终完成。</p><p>刚刚描述了<strong>冯-诺依曼计算模型(Von Neumann model of computing)</strong>的基础知识。在本书中，我们将学习在程序运行的同时，还有许多其它的东西在运行，其主要目标是使系统易于使用。</p><p>事实上，有一大堆软件负责使应用程序运行变得容易，允许程序共享内存(share mem)，使程序与设备交互…该软件主体称为<strong>操作系统(Operating System)</strong>，它负责确保系统操作以易于使用的方式正确有效地运行。</p><p>操作系统执行此操作的主要方式是通过我们称为<strong>虚拟化(Virtualization)</strong>的通用技术。也就是说，操作系统采用<strong>物理资源(Physical Resource)</strong>(如处理器，内存，磁盘)并将其转换为更通用，功能强大且易于使用的虚拟形式。因此，我们有时将操作系统称为<strong>虚拟机(Virtual Machine)</strong>。</p><blockquote><p><strong>问题的关键: 如何虚拟化资源</strong><br>本书的一个核心问题：操作系统如何虚拟化资源？操作系统为什么要虚拟化资源——它使得系统更易于使用。因此，我们关注：操作系统使用什么机制和策略来实现虚拟化？操作系统如何有效地进行操作？需要什么硬件支持？</p></blockquote><p><br></p><p>当然，为了告诉用户操作系统做什么，从而利用虚拟机的功能(如运行程序、分配内存、访问文件…)，操作系统还提供了一些可调用的接口(API)。事实上，典型的操作系统会<strong>导出(Export)</strong>数百个可供应用程序访问的<strong>系统调用(System Call)</strong>。<br>由于操作系统提供这些系统调用来运行程序、访问内存和设备、以及其它相关操作，有时也会说操作系统为应用程序提供了一个<strong>标准库(Standard Library)</strong>。</p><p>最后，因为虚拟化允许多个程序运行(共享CPU)，并且许多程序同时(Concurrently)访问它们自己的指令和数据(共享内存)，以及许多程序访问设备(共享磁盘等)，操作系统有时被称为<strong>资源管理器(Resource Manager)</strong>。每个CPU、MEM、DISK都是系统的资源。因此，操作系统的角色是管理这些资源，有效或公平地执行。</p><p><br><br><br></p><h2 id="虚拟化CPU"><a href="#虚拟化CPU" class="headerlink" title="虚拟化CPU"></a>虚拟化CPU</h2><p>Virtualizing the CPU</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Code That Loops and Prints (cpu.c)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/time.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;assert.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"common.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span></span><br><span class="line">main(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (argc != <span class="number">2</span>) &#123;</span><br><span class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"usage: cpu &lt;string&gt;\n"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">char</span> *str = argv[<span class="number">1</span>];</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">        Spin(<span class="number">1</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%s\n"</span>, str);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br></p><p>上图的程序，它所做的只是调用<code>Spin()</code>——这是一个重复检查时间的函数。<br>接下来我们具有单个处理器的系统上编译和运行它:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 编译</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 此处遇到两个错误</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 1. cpu.c:(.text+0xe0)：对‘pthread_create’未定义的引用</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2. cpu.c:(.text+0x127)：对‘pthread_join’未定义的引用</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 网上方法: 在编译时需要添加 -lpthread 参数来使用 libpthread.a 库进行编译</span></span><br><span class="line">gcc -o cpu cpu.c -Wall -lpthread</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 运行</span></span><br><span class="line">./cpu "ABC"</span><br><span class="line">ABC</span><br><span class="line">ABC</span><br><span class="line">...</span><br><span class="line"><span class="meta">#</span><span class="bash"> 需手动终止</span></span><br><span class="line">Ctrl+C</span><br></pre></td></tr></table></figure><p><br></p><p>现在让程序复杂一点:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">./cpu A &amp;  ./cpu B &amp;  ./cpu C &amp;  ./cpu D &amp;</span><br><span class="line"></span><br><span class="line">[1] 7353</span><br><span class="line">[2] 7354</span><br><span class="line">[3] 7355</span><br><span class="line">[4] 7356</span><br><span class="line">A</span><br><span class="line">B</span><br><span class="line">D</span><br><span class="line">C</span><br><span class="line">A</span><br><span class="line">B</span><br><span class="line">D</span><br><span class="line">C</span><br><span class="line">A</span><br><span class="line">C</span><br><span class="line">B</span><br><span class="line">D</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>现在事情变得更有趣了。即使只有一个处理器，但不知何故，所有四个程序都在同时运行！这种魔力是如何发生的呢？</p><p>事实证明，操作系统在硬件的帮助下负责这种<strong>错觉(illusion)</strong>——即系统具有大量虚拟CPU的错觉。将单个CPU转换为看似无限数量的CPU，从而允许许多程序看起来像是一次运行，这就是我们所说的虚拟化CPU，这是本书第一部分的重点。</p><p>当然，要运行程序并停止它，以及告诉操作系统运行哪些程序，需要使用一些接口(API)来将你的需求传递给操作系统。实际上，它们是大多数用于与操作系统交互的主要方式。</p><p>你可能还注意到，一次运行多个程序会引发各种新问题。如，如果两个程序需要在特定时间运行，哪个应该运行。这些问题由操作系统的策略来回答，策略在操作系统中的许多不同位置用户回答这些类型的问题。</p><p><br><br><br><br><br></p><h2 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h2><p>Virtualizing Memory</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A Program that Accesses Memory (mem.c)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"common.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span></span><br><span class="line">main(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">int</span> *p = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">int</span>)); <span class="comment">// a1</span></span><br><span class="line">    assert(p != <span class="literal">NULL</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"(%d) memory address of p: %08x\n"</span>,</span><br><span class="line">        getpid(), (<span class="keyword">unsigned</span>) p); <span class="comment">// a2</span></span><br><span class="line">    *p = <span class="number">0</span>; <span class="comment">// a3</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">        Spin(<span class="number">1</span>);</span><br><span class="line">        *p = *p + <span class="number">1</span>;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"(%d) p: %d\n"</span>, getpid(), *p); <span class="comment">// a4</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br></p><p>现在让我们考虑一下<strong>内存(memory)</strong>。现代机器提供的物理内存的模型非常简单。内存只是一个<strong>字节数组(a array of bytes)</strong>。要读取内存，必须指定一个地址才能访问存储在那里的数据。要写入或更新(write/update)内存，还必须指定要写入数据的给定地址。</p><p>程序运行时始终访问内存。程序的所有数据结构保存在内存中，并通过各种指令访问它们，如<code>loads</code>, <code>stores</code>或其它在执行工作时访问内存的显式指令。不要忘记程序的每条指令也在内存中，每次<strong>取(fetch)指令</strong>时访问内存。</p><p>让我们来看下通过调用<code>malloc()</code>来分配一些内存的上面那个程序:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">./mem</span><br><span class="line">(6941) memory address of p: 01f13010</span><br><span class="line">(6941) p: 1</span><br><span class="line">(6941) p: 2</span><br><span class="line">^C</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 该程序做了几件事。首先，它分配一些内存(a1)。然后，它打印出内存的地址(a2)，然后将数字零放入新分配的存储器的第一个插槽(a3)。最后，它循环，延迟1秒并递增存储在p中保存的地址的值。它还打出程序的PID。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Running The Memory Program Multiple Times</span></span><br><span class="line">./mem &amp; ./mem &amp;</span><br><span class="line">[1] 7544</span><br><span class="line">[2] 7545</span><br><span class="line">(7544) memory address of p: 012f3010</span><br><span class="line">(7545) memory address of p: 006cf010</span><br><span class="line">(7544) p: 1</span><br><span class="line">(7545) p: 1</span><br><span class="line">(7544) p: 2</span><br><span class="line">(7545) p: 2</span><br><span class="line">(7544) p: 3</span><br><span class="line">(7545) p: 3</span><br></pre></td></tr></table></figure><p>实际上，这正是这里发生的事情，因为操作系统正在虚拟化内存。每个进程都访问自己的<strong>私有虚拟地址空间(private virtual address space)</strong>(有时也称为地址空间)，操作系统以某种方式将其映射到计算机的物理内存中。一个正在运行的程序中的内存引用不会影响其它进程的地址空间。就运行程序而言，它具有物理内存。然而，现实是物理内存是由操作系统管理的共享资源。</p><p><br><br><br><br><br><br><br></p><h2 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h2><p>Concurrency</p><p>本书另一个主题是<strong>并发性(concurrency)</strong>。使用这个术语来指代同一程序中同时处理多个事件(即并发)。并发问题首先出现在操作系统自身，如前面的虚拟化程序，操作系统同时处理多个事情。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// AMulti-threaded Program (threads.c)</span></span><br><span class="line"></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"common.h"</span></span></span><br><span class="line"></span><br><span class="line"> <span class="keyword">volatile</span> <span class="keyword">int</span> counter = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">int</span> loops;</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">void</span> *<span class="title">worker</span><span class="params">(<span class="keyword">void</span> *arg)</span> </span>&#123;</span><br><span class="line">     <span class="keyword">int</span> i;</span><br><span class="line">     <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; loops; i++) &#123;</span><br><span class="line">         counter++;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">int</span></span><br><span class="line"> main(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span><br><span class="line"> &#123;</span><br><span class="line">     <span class="keyword">if</span> (argc != <span class="number">2</span>) &#123;</span><br><span class="line">     <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"usage: threads &lt;value&gt;\n"</span>);</span><br><span class="line">     <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">     &#125;</span><br><span class="line">     loops = atoi(argv[<span class="number">1</span>]);</span><br><span class="line">     <span class="keyword">pthread_t</span> p1, p2;</span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">"Initial value : %d\n"</span>, counter);</span><br><span class="line"></span><br><span class="line">     Pthread_create(&amp;p1, <span class="literal">NULL</span>, worker, <span class="literal">NULL</span>);</span><br><span class="line">     Pthread_create(&amp;p2, <span class="literal">NULL</span>, worker, <span class="literal">NULL</span>);</span><br><span class="line">     Pthread_join(p1, <span class="literal">NULL</span>);</span><br><span class="line">     Pthread_join(p2, <span class="literal">NULL</span>);</span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">"Final value : %d\n"</span>, counter);</span><br><span class="line">     <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// &gt;本程序使用Pthread create()创建两个线程</span></span><br><span class="line"><span class="comment">// 你可将线程视为与其它函数相同的内存空间中运行的函数，一次使用多个函数</span></span><br></pre></td></tr></table></figure><p><br></p><blockquote><p><strong>如何构建正确的并发程序?</strong><br>当同一个内存空间中有许多并发执行的线程时，我们如何构建一个正常工作的程序？操作系统需要哪些原语？硬件提供哪些机制？如何使用它们来解决并发问题？</p></blockquote><p><br></p><p>运行:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">./threads</span><br><span class="line">usage: threads &lt;value&gt;</span><br><span class="line"></span><br><span class="line">./threads 1000</span><br><span class="line">Initial value : 0</span><br><span class="line">Final value : 2000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 看看更高的值</span></span><br><span class="line">./threads 10000</span><br><span class="line">Initial value : 0</span><br><span class="line">Final value : 17726</span><br><span class="line"></span><br><span class="line">./threads 10000</span><br><span class="line">Initial value : 0</span><br><span class="line">Final value : 18741</span><br><span class="line"></span><br><span class="line">./threads 10000</span><br><span class="line">Initial value : 0</span><br><span class="line">Final value : 20000</span><br></pre></td></tr></table></figure><p>上面出现了既正常又奇怪的结果。这些结果与指令的执行方式有关。不幸的是，上面程序的一个关键部分，共享计数器递增，需要三个指令：</p><ul><li>一个用于将计数器的值从内存加载到寄存器；</li><li>一个用于递增；</li><li>一个用于将其存储回内存。</li></ul><p>因为这三个指令不是原子地执行(一次全部执行)，所以会发生奇怪的事。</p><p><br><br><br><br><br><br><br></p><h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><p>Persistence</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Program That Does I/O (io.c)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;assert.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fcntl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span></span><br><span class="line">main(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">int</span> fd = open(<span class="string">"/tmp/file"</span>, O_WRONLY | O_CREAT | O_TRUNC, S_IRWXU);</span><br><span class="line">    assert(fd &gt; <span class="number">-1</span>);</span><br><span class="line">    <span class="keyword">int</span> rc = write(fd, <span class="string">"hello world\n"</span>, <span class="number">13</span>);</span><br><span class="line">    assert(rc == <span class="number">13</span>);</span><br><span class="line">    close(fd);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br></p><p>第三个主题是<strong>持久化(persistence)</strong>。在系统内存中，数据很容易丢失，因为如DRAM的设备是以易失的方式存储值。当断电或系统奔溃时，内存中的任何数据都会丢失。因此，我们需要硬件和软件能够持久存储数据。硬件以某种I/O设备的形式出现。</p><p>通常，操作系统中管理磁盘的软件被称为<strong>文件系统(file system)</strong>。它负责将用户创建的任何文件以可靠和有效的方式存储在磁盘上。</p><p>与操作系统为CPU何MEM提供的抽象不同，操作系统不会为每个应用程序创建专用的虚拟化磁盘。相反，它假设用户经常想要共享文件中的信息。</p><p>来看下上面的代码，它打开<code>/tmp/file</code>文件，并将<code>hello world</code>写入文件。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./io</span><br><span class="line"></span><br><span class="line">cat /tmp/file</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure></p><p><br></p><blockquote><p><strong>如何持久存储数据？</strong><br>文件系统是负责管理持久化数据的操作系统的一部分。正确地处理需要哪些技术呢？面对硬件和软件故障，如何实现可靠性？</p></blockquote><p>要完成此任务，程序会对操作系统进行三次调用。这些系统调用被路由到称为文件系统的操作系统部分，然后处理请求并向用户返回某种错误代码。</p><ul><li>第一，调用<code>open()</code>打开文件；</li><li>第二，调用<code>write()</code>将数据写入文件；</li><li>第三，调用<code>close()</code>关闭文件。</li></ul><p>你可能想知道操作系统为了写入磁盘而执行的操作。文件系统必须完成相当多的工作，首先确定这些新数据将驻留在磁盘上的哪个位置，然后在文件系统维护的各种结构中跟踪它。这样做需要向底层存储设备发出I/O请求，以读取现有结构或更新它们。<br>任何编写设备驱动程序的人都知道，让设备代表你做某事是一个复杂和详细的过程。它需要深入了解低级设备接口及其确切语义。幸运的是，操作系统提供了一个的标准和简单的方式——通过系统调用(system call)访问设备。因此，操作系统有时被视为<strong>标准库(standard library)</strong>。</p><p>为了处理写入期间系统崩溃的问题，大多数文件系统都包含某种复杂的写入协议。(如journaling或copy-on-write)。仔细写入磁盘以确保在写入序列期间发生故障时，系统之后可以恢复到合理的状态。为了使不同额公共操作高效，文件系统采用许多不同的数据结构和访问方法，从简单的列表到复杂的BTREE。</p><p><br><br><br><br><br><br><br></p><h2 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h2><p>Design Goals</p><p>现在我们知道了操作系统实际上做了什么：它使用物理资源(CPU, MEM, DISK…)，并虚拟化它们。它处理与并发相关的棘手的问题。它可以持久存储文件，从而使它们长期安全。最基本的目标是建立一些抽象，以使系统方便和易于使用。抽象是我们计算机科学中所做的一切的基础。</p><p>设计和实现操作系统的一个目标是提供<strong>高性能(High Performance)</strong>；另一个目标是尽量减少操作系统的<strong>开销(overhead)</strong>。虚拟化和使操作系统易于使用是值得的，但不是不惜任何代价。因此，我们必须提供虚拟化和其它操作系统功能，而无需过多开销。这些开销以多种形式出现：额外时间、额外空间。</p><p>另一个目标是在应用程序之间，以及操作系统和应用程序之间提供<strong>保护(Protection)</strong>。由于我们系统多个程序同时运行，所有希望确保每一个程序的恶意或偶然的不良行为不会伤害到其它程序或操作系统。保护操作系统的主要核心原则始操作系统的<strong>隔离(Isolation)</strong>。将进程彼此隔离是保护的关键，因此是操作系统必须做的大部分工作的基础。</p><p>操作系统必须不间断地运行，当它失败时，系统上运行的所有应用程序也会失败。由于这种依赖性，操作系统通常努力提供<strong>高度可靠性(high degree of reliability)</strong>。随着操作系统越来越复杂，构建可靠的操作系统是一个相当大的挑战，这也是一个确切的研究性问题。</p><p>其它目标也是有意义的:</p><ul><li><strong>能源效率</strong>：在绿色世界中越发重要；</li><li><strong>安全</strong>：对恶意应用程序的安全性至关重要；</li><li><strong>可移植性</strong>：随着操作系统在越来越小的设备上运行，可移植性也变得很重要。</li></ul><p><br><br><br><br><br><br><br></p><h2 id="一些历史"><a href="#一些历史" class="headerlink" title="一些历史"></a>一些历史</h2><p>Some History</p><p>让我们简单介绍下操作系统的发展过程。与人类构建的任何系统一样，随着时间的推移，操作系统中积累了许多好的想法。</p><p><br></p><h3 id="Early-Operating-Systems-Just-Libraries"><a href="#Early-Operating-Systems-Just-Libraries" class="headerlink" title="Early Operating Systems: Just Libraries"></a>Early Operating Systems: Just Libraries</h3><p>一开始，操作系统并没有做太多。基本上，它只是一组常用函数库(function library)。</p><p>通常，在这些旧的主机系统上，一个程序由人工控制运行一次。许多你认为的现代操作系统将执行的大部分操作是由人工执行的。如果你和操作员很好，则他可以将你的工作移动到队列的前面。<br>这种计算方式称为<strong>批处理(batch processing)</strong>，因为设置了很多作业，然后由人工以批处理的方式运行。到目前为止，计算机并没有以<strong>交互式(interactive)</strong>方式使用。因为成本：让用户坐在电脑面前使用它太昂贵了，因为大多数时候它只是闲置，而每小时需要花费数十万美元。</p><p><br><br><br></p><h3 id="Beyond-Libraries-Protection"><a href="#Beyond-Libraries-Protection" class="headerlink" title="Beyond Libraries: Protection"></a>Beyond Libraries: Protection</h3><p>作为一个简单的常用服务库，操作系统在管理机器方面发挥了中心角色的作用。其中一个重要的方面是认识到运行操作系统自身的代码是特殊的。它控制了设备，因此应该与正常的应用程序代码区别对待。<br>为什么这样？设想一下，如果你允许任何应用程序可以从磁盘的任何地方读取，隐私的概念就会消失，因为任何程序都可以读取任何文件。因此，实现文件系统作为一个库是没有任何意义的。</p><p>因此，<strong>系统调用(system call)</strong>的想法产生了。这里的想法是添加一对特殊的硬件指令和硬件状态，以便将操作系统转换为更正式、受控制的流程，而不是将操作系统例程(routine)作为库提供(你只需要进行过程调用以访问它们)。</p><p><strong>系统调用(system call)</strong>和<strong>过程调用(procedure call)</strong>之间的关键区别在于，系统调用将控制转移到中，同时提高<strong>硬件权限级别(hardware privilege level)</strong>。用户应用程序在所谓的<strong>用户模式(user mode)</strong>下运行，这意味着硬件限制应用程序可以执行的操作。例如，以用户模式运行的应用程序通常不能发起对磁盘的I/O请求，但可以访问物理内存页面或在网络上发送数据包。<br>当启动系统调用时，硬件将控制转移到预先指定的陷阱处理程序(trap handler)，并同时将特权级别提升到<strong>内核模式(kernel mode)</strong>。在内核模式下，操作系统可以完全访问系统的硬件，因此可以执行如启动I/O请求等操作。当操作系统完成对服务的请求时，它通过特殊返回陷阱指令(return-from-trap instrction)将控制权传递给用户，该指令恢复到用户模式，同事将控制权传递回应用程序停止的位置。</p><p><br><br><br></p><h3 id="The-Era-of-Multiprogramming"><a href="#The-Era-of-Multiprogramming" class="headerlink" title="The Era of Multiprogramming"></a>The Era of Multiprogramming</h3><p>操作系统真正起飞的时代是超大型计算时代，即minicomputer时代。成本的下降影响了使用者和开发者，从而使计算机系统更加有趣和美好。</p><p>特别是，由于希望更好地利用机器资源，<strong>多程序设计(multiprogramming)</strong>变得司空见惯。操作系统不是一次只运行一个作业，而是将大量作业加载到内存中并在它们之间快速切换，从而提高CPU利用率。这种切换特别重要，因为I/O设备很慢，而CPU很快。在I/O正在服务时让CPU等待程序是在浪费CPU时间。相反，为什么不切换到另一个工作运行呢？</p><p>在存在I/O和中断的情况下支持多程序设计和重叠的愿望迫使操作系统的概念开发沿着多个方向进行创新。内存保存等问题变得很重要，我们不希望一个程序能够访问另一个程序的内存。了解如何处理多程序设计引入的并发问题也很关键，尽管存在中断，确保操作系统正常运行是一项巨大的挑战。</p><p>当时一个主要的进步是Unix操作系统的引入。Unix从不同的操作系统获得了很多好主意，但使它们更简单易用。很快，这个团队向世界各地的人们发送了包含Unix源代码的磁带，随后有许多人加入到了这个项目中来。</p><p><br><br><br></p><h3 id="The-Modern-Era"><a href="#The-Modern-Era" class="headerlink" title="The Modern Era"></a>The Modern Era</h3><p>除了minicomputer之外，还出现了一种更便宜、速度更快的新机器，我们今天称之为PC(personal computer)。</p><p>不幸的是，对于操作系统而言，PC最初代表了一个巨大的飞跃，因为早期的系统忘记了在minicomputer时代学到的经验教训。例如，早期的操作系统，如DOS(the Disk Operating System, from Microsoft)，并不认为内存保护很重要。因此，恶意(或编程不佳)的应用程序可能会乱写内存。第一代Mac OS采用合作方式进行作业调度。因此，一个意外陷入无限循环的线程可以接管整个系统，迫使重启。这一代系统中缺少的操作系统功能的痛苦太多了…</p><p>幸运的是，经过几年的苦难，微机操作系统的旧功能开始找到它们的方式进入桌面系统。例如，Mac OS X/Mac OS的核心是Unix，包含了人们对这种成熟系统所期望的所有功能。Windows同样采用了计算历史中的许多好主意，特别是从Windows NT开始，这是Microsoft OS技术的一次重大飞跃。即便是今天的手机也运行这操作系统(如Linux)，这些操作系统更像是1970s年代的微型机，而不是1980s年代的PC。</p><p><br></p><blockquote><p>旁白：<strong>Unix的重要性</strong><br>在操作系统的历史中，很难夸大Unix的重要性。受其它早期系统的影响，Unix汇集了许多伟大的想法，并使得系统既简单又强大。<br>贝尔实验室的基础Unix是构建小型且强大程序的统一原则，这些程序可以连接在一起形成更大的工作流。shell提供了mete-level programing，当你输入命令，它将程序串联起来以完成更大的任务变得很容易。<br>Unix环境对编程人员和开发人员都很友好，同时也为C编程语言提供了编译器。编程人员可以轻松编写自己的程序并共享它们，这使得Unix非常受欢迎。它还是免费的。<br>同样重要的是代码的可读性和可访问性。拥有一个用C编写的漂亮的小内核(kernel)并邀请别人试玩、添加新的酷的功能。<br>不幸的是，随着公司试图主张版权并从中获利，Unix的传播速度便有所放缓。许多公司都有自己的变体，如SunOS、HPUX…贝尔实验室和其它玩家之间的法律纠纷在Unix上投下了一片乌云，许多人想知道它是否能够活下来，特别是在Windows被引入并占据了PC市场的大部分时…</p></blockquote><p><br></p><blockquote><p>旁白：<strong>然后来了Linux</strong>(ASIDE: AND THEN CAME LINUX)<br>对于Unix，幸运的是，一位名叫<strong>Linus Torvalds</strong>的年轻芬兰Hacker决定编写它自己的Unix版本，该版本大量借用原始系统背后的原则和思想，但不是来自代码库，因此避免了合法性问题。他获得了世界各地许多人的帮助，利用了已经存在的复杂的GNU工具，很快Linux就诞生了(以及现代开源软件运动)。<br>随着互联网时代的带来，大多数公司(如Google、Amazon、Facebook..)选择运行Linux，因为它是免费的，可以随时修改以满足自己的实际需求。随着智能手机成为一个占主导地位的面向用户的平台，由于许多相同的原因，Linux也在那里找到了一个据点(Android)。</p></blockquote><p><br><br><br></p><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>Summary</p><p>因此，我们介绍了操作系统。今天的操作系统相对易于使用，而你今天使用的几乎所有操作系统都受到将在本书中讨论的发展的影响。<br>不幸的是，书中不会介绍的很详细。例如，网络代码、图形设备、安全性。</p><p>但是，我们将介绍许多重要的主题，包括CPU和MEM的虚拟化知识，并发性以及通过设备和文件系统的持久性。别担心，虽然有很多方面可以覆盖，但大部分内容都非常酷，而且在路的尽头，你将对计算机系统的真正工作方式有了新的认识。现在开始吧！</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="虚拟化"><a href="#虚拟化" class="headerlink" title="虚拟化"></a>虚拟化</h1><p>Virtualization</p><p>CPU虚拟化：</p><ul><li>A Dialogue on Virtualization</li><li>The Abstraction: The Process</li><li>Interlude: Process API</li><li>Mechanism: Limited Direct Execution</li><li>CPU Scheduling</li><li>Scheduling: The Multi-Level Feedback Queue</li><li>Scheduling: Proportional Share</li><li>Multi-CPU Scheduling</li><li>Summary Dialogue on CPU Virtualization</li></ul><p><br></p><p>MEM虚拟化：</p><ul><li>A Dialogue on Memory Virtualization</li><li>The Abstraction: Address Spaces</li><li>Interlude: Memory API</li><li>Mechanism: Address Translation</li><li>Segmentation</li><li>Free-Space Management</li><li>Paging</li><li>Paging: Faster Translations</li><li>Paging: Smaller Tables</li><li>Beyond Physical Memory: Swapping Mechanisms</li><li>Beyond Physical Memory: Swapping Policies</li><li>Complete Virtual Memory Systems</li><li>Summary Dialogue on Memory Virtualization</li></ul><p><br><br><br></p><h2 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h2><p><a href="http://pages.cs.wisc.edu/~remzi/OSTEP/cpu-intro.pdf" target="_blank" rel="noopener">The Abstraction: The Process</a></p><p>本章，我们将讨论操作系统为用户提供的最基本的抽象之一：<strong>进程(process)</strong>。进程的定义非常简单：它是一个<strong>正在运行的程序(running program)</strong>。程序本身是一个没有生命的东西，它位于磁盘上，一对指令(可能是一些静态数据)，等待开始行动。操作系统采用这些字节并使它们运行，将程序转换为有用的东西。</p><p>事实证明，人们经常想要同时运行多个程序。如运行浏览器、音乐播放器、邮件程序…实际上，典型的操作系统似乎可能同时运行数百个进程。这样做使系统易于使用，因为不需要关心CPU是否可用。</p><p><br></p><blockquote><p>TIP: USE TIME SHARING (AND SPACE SHARING)<br><strong>时间共享(time sharing)</strong>是操作系统用于共享资源的基本技术。通过允许资源被一个实体使用一段时间，然后另一个实体使用一段时间…资源可以被许多实体共享。时间共享对应于<strong>空间共享(space sharing)</strong>，其中资源在希望使用它的人之间被划分。例如，磁盘空间是一个空间共享资源，一旦将块分配给文件，在用户删除原始文件之前，通常不会将其分配给另一个文件。</p></blockquote><p><br></p><p>我们的挑战是:</p><blockquote><p>如何提供许多CPU的错觉？<br>虽然只有少数物理CPU可用，但操作系统如何提供几乎无穷无尽的CPU供应的错觉？</p></blockquote><p>操作系统通过虚拟化(virtualizating)CPU来提供这种错觉。通过运行一个进程，然后停止它并运行另一个进程，等等。操作系统可以促使存在许多虚拟CPU存在的错觉，而实际上只有一个(几个)物理CPU。这种基本技术称为CPU的<strong>时间共享/分时(time sharing)</strong>，允许用户运行任意数量的并发进程(concurrent process)。潜在的成本是性能(Performance)，因为如果必须共享CPU，每个进程都会运行得更慢。</p><p>要实现CPU的虚拟化，操作系统需要一些低级机制(low-level machinery)和一些高级智能(high-level intelligence):</p><ul><li><strong>低级机制(low-level machinery mechanisms)</strong>，此机制是实现所需功能的低级方法或协议。例如，我们稍后将学习如何实现<strong>上下文切换(context switch)</strong>，这使操作系统能够停止运行一个程序并在给定的CPU上开始运行另一个程序。所有现代操作系统都采用这个<strong>分时机制(time-sharing mechanism)</strong>。</li><li>操作系统中还存在一些智能的<strong>策略(policy)</strong>，策略是在操作系统中做出某种决定的算法。例如，给定一些可能在CPU上运行的程序，操作系统运行哪个程序？操作系统中的调度策略将做出此决定，可能使用历史信息，工作负载信息，性能指标…来做出决定。</li></ul><p><br><br><br></p><h3 id="一个进程"><a href="#一个进程" class="headerlink" title="一个进程"></a>一个进程</h3><p>The Abstraction: A Process</p><p>为了理解进程的构成，我们必须了解其<strong>机器状态(machine state)</strong>：程序在运行时可以读取(read)或更新(update)的内容。在任何给定的时间，机器的哪些部分对于执行该程序很重要？包含进程的机器状态的一个明显组件是其内存(memory)。指令行在内存中，运行程序读写的数据也在内存中。因此，进程可以寻址的内存(称为其地址空间(address space))是进程的一部分。</p><p><strong>寄存器(registers)</strong>也是进程机器状态的一部分。许多指令明确地读取或更新寄存器，因此它们对于执行过程很重要。</p><p>请注意，有一些特殊的寄存器构成了这种机器状态的一部分。如，<strong>program counter(instruction pointer)</strong>告诉我们当前正在运行哪个程序指令；<strong>Stack Pointer</strong>和相关的<strong>frame pointer</strong>用于管理函数参数、局部变量和返回地址的堆栈。</p><p>最后，程序通常也访问持久存储设备。此类I/O信息可能包括进程当前打开的文件列表。</p><p><br></p><blockquote><p>TIP: SEPARATE POLICY AND MECHANISM<br>在许多操作系统中，常见的设计范例是将高级策略与其低级机制分开。如，操作系统如何执行上下文切换？操作系统现在应该运行哪个进程？将两者分开可以很容易地改变策略，而不必重新考虑该机制，因此是一种模块化形式，一般的软件设计原则。</p></blockquote><p><br><br><br></p><h3 id="Process-API"><a href="#Process-API" class="headerlink" title="Process API"></a>Process API</h3><p>先了解操作系统的任何接口中必须包含的内容，这些API以某种形式可用于任何现代操作系统。</p><ul><li><strong>Create</strong>：操作系统必须包含一些创建新进程的方法；</li><li><strong>Destroy</strong>：由于存在创建进程的接口，因此系统还提供了强制销毁进程的接口。当然，许多进程都会运行并在完成后自动退出。然而，当它们不这样做时，用户可能希望杀死它们；</li><li><strong>Wait</strong>：有时，等待进程停止运行时有用的；</li><li><strong>Miscellaneous Control</strong>：除了杀死或等待进程之外，有时还有其它可能的控制措施。如暂停进程，然后恢复它；</li><li><strong>Status</strong>：通常还有接口来获取有关进程的一些状态信息，如运行了多久…</li></ul><p><img src="/images/OSTEP/processToProcess.png" alt></p><p><br><br><br></p><h3 id="进程创建"><a href="#进程创建" class="headerlink" title="进程创建"></a>进程创建</h3><p>Process Creation: A Little More Detail</p><p>我们应揭开的一个谜团是如何将<strong>程序(program)</strong>转换为<strong>进程(process)</strong>。具体来说，操作系统如何启动并运行程序？进程创建实际上如何运作？</p><p>操作系统运行程序必须做的第一件事是将其代码和任何静态文件数据(如变量…)加载(load)到程序的地址空间中(address space of process)。程序最初以某种可执行格式驻留在磁盘(disk)上。因此，将程序和静态数据加载到内存中的过程需要操作系统从磁盘读取这些字节，并将它们放在内存中。<br>在早期操作系统中，加载过程是<strong>热切地(eagerly)</strong>完成，即在运行程序之前一次完成；现代操作系统<strong>懒惰地(lazily)</strong>执行该过程，即仅在程序执行期间需要加载代码或数据。要真正了解代码和数据的延迟加载是如何工作的，你必须更多地了解<strong>分页(paging)</strong>和<strong>交换(swapping)</strong>的机制，这将在内存虚拟化里讨论。现在只需记住，在运行任何操作之前，操作系统显然必须要做一些工作才能将重要的程序从磁盘放入内存。</p><p>一旦将代码和静态数据加载到内存中，操作系统在运行该进程之前还需要执行一些其它操作。必须为程序的<strong>运行时栈(runtime stack)</strong>分配一些内存。如C程序将堆栈用于局部变量、函数参数和返回地址。操作系统分配此内存并将其提供给进程。操作系统也可能使用参数初始化堆栈，具体来说，它将填充<code>main()</code>函数的参数(<code>argc, argv</code>数组)。</p><p>操作系统还可以为程序的<strong>堆(heap)</strong>分配一些内存。在C程序中，堆用于显式请求的动态分配数据调用<code>malloc()</code>来请求这样的空间，并通过调用<code>free()</code>显式释放它。数据结构需要堆，如链表(linked list)、哈希表(hash table)、树(tree)和其它又去的数据结构。堆最初会很小，当程序运行并通过<code>malloc()</code>库API请求更多内存时，操作系统可能会参与并为进程分配更多内存以满足此类调用。</p><p>操作系统还将执行一些其它初始化任务，尤其是与I/O相关的任务。例如，在Unix系统中，默认情况下每个进程都有三个打开的<strong>文件描述符(file descriptors)</strong>，用于stdin, stdout, stderr。这些描述符使程序可以轻松地从终端读取输入并将输出打印到屏幕。将在持久化中详细介绍I/O和文件描述符。</p><p>通过将代码和静态数据加载到内存中，通过创建和初始化堆，通过执行与I/O设置相关的其它工作，操作系统最终为程序执行设置了阶段。它还有最后一个任务：启动在入口点运行的程序，即<code>main()</code>。通过跳转到<code>main()</code>例程，操作系统将CPU的控制权转移到新创建的进程，从而程序开始执行。</p><p><br><br><br></p><h3 id="进程状态"><a href="#进程状态" class="headerlink" title="进程状态"></a>进程状态</h3><p>Process States</p><p>现在我们已经知道一个进程是什么以及如何创建它。现在来看看一个进程在给定事件可以处于的不同状态。进程可处以以下三种状态：</p><ul><li><strong>Running</strong>：进程正在处理器上运行，这意味着它正在执行指令；</li><li><strong>Ready</strong>：进程已准备好，但由于某种原因，操作系统已选择不在此刻运行它；</li><li><strong>Blocked</strong>：进程执行某种操作，使其在其它事件发生之前不准备运行。例如，当进程向磁盘发起I/O请求时，它会被阻塞，因此其它一些进程可以使用该处理器。</li></ul><p>如下图所示，可以根据系统的判断在准备和运行之间移动进程。从准备到运行意味着该进程已<strong>调度(scheduled)</strong>好；从运行转移到准备意味着该进程被<strong>取消调度(discheduled)</strong>。一旦进程被<strong>阻塞(blocked)</strong>，操作系统将保持这样知道某些事件完成，此时进程再次进入就绪状态。</p><p><img src="/images/OSTEP/processStateTransitions.png" alt></p><p><br></p><p>来看一个栗子，两个进程如果通过其中一些状态转换的示例。</p><div class="table-container"><table><thead><tr><th>Time</th><th>Process0</th><th>Process1</th><th>Notes</th></tr></thead><tbody><tr><td>1</td><td>Running</td><td>Ready</td><td></td></tr><tr><td>2</td><td>Running</td><td>Ready</td><td></td></tr><tr><td>3</td><td>Running</td><td>Ready</td><td></td></tr><tr><td>4</td><td>Running</td><td>Ready</td><td>Process0 now done</td></tr><tr><td>5</td><td>–</td><td>Running</td><td></td></tr><tr><td>6</td><td>–</td><td>Running</td><td></td></tr><tr><td>7</td><td>–</td><td>Running</td><td></td></tr><tr><td>8</td><td>–</td><td>Running</td><td>Process1 now done</td></tr></tbody></table></div><p><br></p><p>这个栗子中，process0在运行一段时间后发出I/O请求。此时，该进程被阻塞，使另一个进程有机会运行。<br>更具体地说，process0启动I/O并被阻塞等待它完成。例如，从磁盘读取或等待来自网络的数据包时，进程会被阻止。操作系统识别process0未使用CPU并开始运行process1。当process1运行时，process0的I/O完成，将process0移回准备状态。最后，process1完成，process0运行然后完成。</p><div class="table-container"><table><thead><tr><th>Time</th><th>Process0</th><th>Process1</th><th>Notes</th></tr></thead><tbody><tr><td>1</td><td>Running</td><td>Ready</td><td></td></tr><tr><td>2</td><td>Running</td><td>Ready</td><td></td></tr><tr><td>3</td><td>Running</td><td>Ready</td><td>Process0 initiates I/O</td></tr><tr><td>4</td><td>Blocked</td><td>Running</td><td>Process0 is blocked</td></tr><tr><td>5</td><td>Blocked</td><td>Running</td><td>so Process1 runs</td></tr><tr><td>6</td><td>Blocked</td><td>Running</td><td></td></tr><tr><td>7</td><td>Ready</td><td>Running</td><td>I/O done</td></tr><tr><td>8</td><td>Ready</td><td>Running</td><td>Process1 now done</td></tr><tr><td>9</td><td>Running</td><td>–</td><td></td></tr><tr><td>10</td><td>Running</td><td>–</td><td>Process0 now done</td></tr></tbody></table></div><p>请注意，即使在这个简单的示例中，操作系统也必须做出许多决定。首先，系统必须在process0发出I/O时运行process1；这样做可以通过保持CPU忙碌来提高资源利用率。其次，系统决定在其I/O完成时不切换会process0。目前尚不清楚这是否是一个好的决定。这些类型的决策是由操作系统调度程序做出的。</p><p><br><br><br></p><h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p>Data Structures</p><p>操作系统是一个程序，与任何程序一样，它有一些追踪各种相关信息的关键<strong>数据结构(data structure)</strong>。例如，为了追踪每个进程的状态，操作系统可能会为所有准备好的进程保留某种进程列表，并提供一些其它信息来追踪当前正在运行的进程。操作系统还必须以某种方式追踪被阻塞的进程；当I/O事件完成时，操作系统应确保唤醒正确的进程并准备好再次运行。</p><p>下面显示了操作系统需要跟踪内核中每个进程的信息类型。类似的过程结构存在于真实操作系统中，如Linux、Mac OSX、Windows…看看它们有多复杂。你可以看到操作系统追踪进程的几个重要信息。<br>对于已停止的进程，<strong>寄存器上下文(register context)</strong>将保持其寄存器的内容。当进程停止时，其寄存器将保持到该内存位置(memory location)。通过恢复这些寄存器，操作系统可以恢复运行该进程。这在以后上下文切换中详细介绍。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// the registers xv6 will save and restore</span></span><br><span class="line"><span class="comment">// to stop and subsequently restart a process</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">context</span> &#123;</span></span><br><span class="line"><span class="keyword">int</span> eip;</span><br><span class="line"><span class="keyword">int</span> esp;</span><br><span class="line"><span class="keyword">int</span> ebx;</span><br><span class="line"><span class="keyword">int</span> ecx;</span><br><span class="line"><span class="keyword">int</span> edx;</span><br><span class="line"><span class="keyword">int</span> esi;</span><br><span class="line"><span class="keyword">int</span> edi;</span><br><span class="line"><span class="keyword">int</span> ebp;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// the different states a process can be in</span></span><br><span class="line"><span class="keyword">enum</span> proc_state &#123; UNUSED, EMBRYO, SLEEPING,</span><br><span class="line">                  RUNNABLE, RUNNING, ZOMBIE &#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// the information xv6 tracks about each process</span></span><br><span class="line"><span class="comment">// including its register context and state</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">proc</span> &#123;</span></span><br><span class="line">  <span class="keyword">char</span> *mem; <span class="comment">// Start of process memory</span></span><br><span class="line">  uint sz; <span class="comment">// Size of process memory</span></span><br><span class="line">  <span class="keyword">char</span> *kstack; <span class="comment">// Bottom of kernel stack</span></span><br><span class="line">        <span class="comment">// for this process</span></span><br><span class="line">  <span class="keyword">enum</span> proc_state state; <span class="comment">// Process state</span></span><br><span class="line">  <span class="keyword">int</span> pid; <span class="comment">// Process ID</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">proc</span> *<span class="title">parent</span>;</span> <span class="comment">// Parent process</span></span><br><span class="line">  <span class="keyword">void</span> *chan; <span class="comment">// If non-zero, sleeping on chan</span></span><br><span class="line">  <span class="keyword">int</span> killed; <span class="comment">// If non-zero, have been killed</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">file</span> *<span class="title">ofile</span>[<span class="title">NOFILE</span>];</span> <span class="comment">// Open files</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">inode</span> *<span class="title">cwd</span>;</span> <span class="comment">// Current directory</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">context</span> <span class="title">context</span>;</span> <span class="comment">// Switch here to run process</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">trapframe</span> *<span class="title">tf</span>;</span> <span class="comment">// Trap frame for the</span></span><br><span class="line">        <span class="comment">// current interrupt</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>还可从图中看出，除了running, ready, blocked之外，还有一些进程可以处于其它状态。<br>有时，系统将具有该进程在创建是所处的<strong>初始状态(initial state)</strong>。此外，可将进程置于已退出但尚未清除的<strong>最终状态(final state)</strong>(在基于Unix的系统中，这称为<strong>僵尸状态(zombie state)</strong>)。这个最终状态非常有用，因为它允许其它进程(通常是创建此进程的父进程)检查进程的返回代码并查看刚刚完成的进程是否成功运行(通常，程序在基于Unix系统中的返回码为0时，表示已成功完成任务，否则返回非0)。完成后，父进程将进行最后一次调用以等待孩子进程的完成，并且还向操作系统指示它可以清理任何涉及现在已经灭绝的进程的相关数据结构。</p><p><br></p><blockquote><p>ASIDE: DATA STRUCTURE — THE PROCESS LIST<br>操作系统充满了各种重要的数据结构。进程列表(process list)，也称为任务列表(task list)。它是比较简单的一个，都是现在能够同时运行多个程序的操作系统都会有类似于这种结构的东西，以便追踪系统中所有正在运行的程序。有时，人们会将存储过程信息的单个结构称为<strong>进程控制块(PCB, process control block)</strong>。</p></blockquote><p><br></p><blockquote><p>ASIDE: KEY PROCESS TERMS(关键进程术语)<br><strong>进程(process)</strong>是正在运行的程序的主要操作系统抽象。在任何时间点，该进程都可以通过其状态来描述：其地址空间中的内存内容、CPU寄存器的内容、有关I/O的信息。<br><strong>进程API</strong>由可使进程相关联的调用程序组成。通常，这包括创建、销毁、其它有用的调用。<br>进程存在许多不同的<strong>进程状态(process state)</strong>，包括running、ready、blocking。不同的时间将进程从这些状态之一转换到另一个状态。<br><strong>进程列表(process list)</strong>包含有关系统中所有进程的信息。每个条目有时称为进程控制块(PCB)，它实际上只是一个包含特定进程信息的结构。</p></blockquote><p><br><br><br><br><br><br><br></p><h2 id="进程API"><a href="#进程API" class="headerlink" title="进程API"></a>进程API</h2><p><a href="http://pages.cs.wisc.edu/~remzi/OSTEP/cpu-api.pdf" target="_blank" rel="noopener">Process API</a></p><blockquote><p>ASIDE: INTERLUDES<br><strong>插曲(interludes)</strong>将涵盖系统的多个实际方面，包括特别关注系统API以及如何使用它们。如果你不喜欢实际的事物(practical things)，你可跳过它。但你应该了解它，因为它们通常在现实生活中很有用。</p></blockquote><p><br></p><blockquote><p>CRUX: HOW TO CREATE AND CONTROL PROCESSES<br>操作系统应该为进程创建和控制提供哪些接口？如何设计这些接口以实现强大的功能、易用性和高性能？</p></blockquote><p><br></p><p>在此插曲中，将讨论Unix系统中的进程创建。Unix提供了一种使用一对<strong>系统调用(system call)</strong>创建新进程的最有趣的方法:</p><ul><li><code>fork()</code></li><li><code>exec()</code></li></ul><p>第三个例程，可以由希望等待进程创建完成的进程使用：</p><ul><li><code>wait()</code></li></ul><p><br><br><br></p><h3 id="fork系统调用"><a href="#fork系统调用" class="headerlink" title="fork系统调用"></a>fork系统调用</h3><p>The fork() System Call</p><p><code>fork()</code>系统调用用于创建新进程。但是，要预先警告：这是你将要调用的最奇怪的例行程序。更具体的说，你有一个正在运行的程序，代码如下所示。输入并运行它。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Calling fork() (p1.c)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"hello world (pid:%d)\n"</span>, (<span class="keyword">int</span>) getpid());</span><br><span class="line">    <span class="keyword">int</span> rc = fork();</span><br><span class="line">    <span class="keyword">if</span> (rc &lt; <span class="number">0</span>) &#123; <span class="comment">// &gt;&gt;&gt;fork failed; exit</span></span><br><span class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"fork failed\n"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (rc == <span class="number">0</span>) &#123; <span class="comment">// child (new process)</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"hello, I am child (pid:%d)\n"</span>, (<span class="keyword">int</span>) getpid());</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; <span class="comment">// parent goes down this path (main)</span></span><br><span class="line">       <span class="built_in">printf</span>(<span class="string">"hello, I am parent of %d (pid:%d)\n"</span>,</span><br><span class="line">            rc, (<span class="keyword">int</span>) getpid());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./p1</span><br><span class="line">hello world (pid:14506)</span><br><span class="line">hello, I am parent of 14507 (pid:14506)</span><br><span class="line">hello, I am child (pid:14507)</span><br></pre></td></tr></table></figure><p>当它第一次运行时，该进程打印出<code>hello world</code>消息，包含在该消息中的<strong>进程标识符(PID, process identifier)</strong>。在Unix系统中，如果想要对进程执行某些操作(如停止它)，则使用PID来命名进程。</p><p>现在有趣的部分开始了：该进程调用<code>fork()</code>系统调用，操作系统提供该此方法来创建新进程。奇怪的部分：创建的进程是调用进程的精确副本。这意味着对于操作系统来说，现在看起来的两个进程都是p1程序运行的副本，并且两个进程都从<code>fork()</code>系统调用返回。新创建的进程(child)不会像<code>main()</code>那样开始在<code>main()</code>上运行(hello world只打印了一次)。相反，它刚出现时，好像它已经调用了<code>fork()</code>本身。</p><p>你可能注意到，子进程不是一个精确的副本。尽管它有自己的地址空间、寄存器、PC…，它返回给<code>fork()</code>调用者的值是不同的。具体来说，当父进程接收新创建的子进程PID时，子进程接收返回码0.</p><p>你可能还注意到：p1的输出不确定。系统中有两个活动的父进程和子进程。假设在单个CPU的系统上运行，可能会发生相反的情况。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./p1</span><br><span class="line">hello world (pid:29146)</span><br><span class="line">hello, I am child (pid:29147)</span><br><span class="line">hello, I am parent of 29147 (pid:29146)</span><br></pre></td></tr></table></figure><p>CPU调度器，确定哪个进程在给定时刻运行。因为调度程序很复杂，我们通常不能对它将选择做什么做出强有力的假设，如最先运行哪个进程。这些不确定性导致了一些有趣的问题，特别是在多线程程序中，这将在并发中讨论。</p><p><br><br><br></p><h3 id="wait系统调用"><a href="#wait系统调用" class="headerlink" title="wait系统调用"></a>wait系统调用</h3><p>The wait() System Call</p><p>到目前为止，我们还没有做太多工作：只创建了一个打印消息并退出的子进程。有时，事实证明，父进程等待子进程完成它一直在做的事情时非常有用的。这个任务是通过<code>wait()</code>系统调用完成的。</p><p>在下面的栗子中，父进程调用<code>wait()</code>以延迟执行，直到子进程执行完毕。子进程完成后，<code>wait()</code>返回父进程。添加了<code>wait()</code>调用使得数据具有稳定性，你们明白为什么吗？</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Calling fork() And wait() (p2.c)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"hello world (pid:%d)\n"</span>, (<span class="keyword">int</span>) getpid());</span><br><span class="line">    <span class="keyword">int</span> rc = fork();</span><br><span class="line">    <span class="keyword">if</span> (rc &lt; <span class="number">0</span>) &#123; <span class="comment">// &gt;&gt;&gt;fork failed; exit</span></span><br><span class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"fork failed\n"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (rc == <span class="number">0</span>) &#123; <span class="comment">// child (new process)</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"hello, I am child (pid:%d)\n"</span>, (<span class="keyword">int</span>) getpid());</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; <span class="comment">// parent goes down this path (main)</span></span><br><span class="line">        <span class="keyword">int</span> rc_wait = wait(<span class="literal">NULL</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"hello, I am parent of %d (rc_wait:%d) (pid:%d)\n"</span>,</span><br><span class="line">            rc, rc_wait, (<span class="keyword">int</span>) getpid());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> ./p2</span><br><span class="line">hello world (pid:29266)</span><br><span class="line">hello, I am child (pid:29267)</span><br><span class="line">hello, I am parent of 29267 (rc_wait:29267) (pid:29266)</span><br></pre></td></tr></table></figure><p>使用此代码，我们现在知道子进程将首先打印。但是，如果父进程碰巧先运行，它会立即调用<code>wait()</code>，这个系统调用在子进程运行并退出之前不会返回。因此，即使父进程先运行，它礼貌地等待子进程完成运行，然后<code>wait()</code>返回，然后父进程打印它的消息。</p><p><br><br><br></p><h3 id="exec系统调用"><a href="#exec系统调用" class="headerlink" title="exec系统调用"></a>exec系统调用</h3><p>The exec() System Call</p><p>进程创建API的最后一个重要部分是<code>exec()</code>系统调用。当你想要运行与调用程序不同的程序时，此系统调用很有用。例如，在p2中调用<code>fork()</code>仅在你希望继续运行同一程序的副本时才有用。但是，通常你想运行一个不同的程序，<code>exec()</code>就是这么做的。</p><p>在下面的栗子中，子进程调用<code>execvp()</code>以运行程序wc(word count)。实际上，它从p3上运行wc，返回行数、词数和字节数。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Calling fork(), wait(), And exec() (p3.c)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"hello world (pid:%d)\n"</span>, (<span class="keyword">int</span>) getpid());</span><br><span class="line">    <span class="keyword">int</span> rc = fork();</span><br><span class="line">    <span class="keyword">if</span> (rc &lt; <span class="number">0</span>) &#123; <span class="comment">// &gt;&gt;&gt;fork failed; exit</span></span><br><span class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"fork failed\n"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (rc == <span class="number">0</span>) &#123; <span class="comment">// child (new process)</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"hello, I am child (pid:%d)\n"</span>, (<span class="keyword">int</span>) getpid());</span><br><span class="line">        <span class="keyword">char</span> *myargs[<span class="number">3</span>];</span><br><span class="line">        myargs[<span class="number">0</span>] = strdup(<span class="string">"wc"</span>); <span class="comment">// program: "wc" (word count)</span></span><br><span class="line">        myargs[<span class="number">1</span>] = strdup(<span class="string">"p3.c"</span>); <span class="comment">// argument: file to count</span></span><br><span class="line">        myargs[<span class="number">2</span>] = <span class="literal">NULL</span>; <span class="comment">// marks end of array</span></span><br><span class="line">        execvp(myargs[<span class="number">0</span>], myargs); <span class="comment">// runs word count</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"this shouldn’t print out"</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; <span class="comment">// parent goes down this path (main)</span></span><br><span class="line">    <span class="keyword">int</span> rc_wait = wait(<span class="literal">NULL</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"hello, I am parent of %d (rc_wait:%d) (pid:%d)\n"</span>,</span><br><span class="line">         rc, rc_wait, (<span class="keyword">int</span>) getpid());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">./p3</span><br><span class="line">hello world (pid:29383)</span><br><span class="line">hello, I am child (pid:29384)</span><br><span class="line">29 107 1030 p3.c</span><br><span class="line">hello, I am parent of 29384 (rc_wait:29384) (pid:29383)</span><br></pre></td></tr></table></figure><p><code>fork()</code>系统调用很奇怪，它的伙伴<code>exec()</code>也不是那么正常。它的作用：给定可执行文件的名称和一些参数，从该可执行文件加载代码和静态数据并覆盖其当前代码段，重新初始化堆和栈以及程序内存空间的其它部分。然后操作系统运行该程序，传入任意参数为该进程的argv。因此，它不会创建新的进程。相反，它将当前运行的程序(p3)转换为不同的运行程序(wc)。在子进程的<code>exec()</code>之后，几乎就好像p3从未运行过，成功调用<code>exec()</code>永远不会有返回。</p><p><br><br><br></p><h3 id="Motivating-The-API"><a href="#Motivating-The-API" class="headerlink" title="Motivating The API"></a>Motivating The API</h3><p>Why? Motivating The API</p><p>当然，可能会遇到一个大问题：为什么要建立一个奇怪的接口来创建一个新进程？事实证明，<code>fork()</code>和<code>exec()</code>的分离对于构建Unix shell至关重要，因为它允许shell在调用<code>fork()</code>之后，在调用<code>exec()</code>之前运行代码。此代码可以改变即将运行的程序的环境，从而可以轻松构建各种有趣的功能。</p><p><br></p><blockquote><p>TIP: GETTING IT RIGHT<br>简单和抽象都不能代替正确。有很多方法可以为进程创建设计API，但是，<code>fork()</code>和<code>exec()</code>的组合非常简单和强大。在这里，Unix设计师做对了。</p></blockquote><p><br></p><p>shell只是一个用户程序。它会向你显示提示，然后等待你输入内容。你输入一个命令，在大多数情况下，shell确定文件系统中可执行文件所在的位置，调用<code>fork()</code>创建一个新的子进程来运行命令，调用<code>exec()</code>的某个变体来运行命令，然后通过调用<code>wati()</code>命令来等待命令的完成。当子进程完成时，shell从<code>wait()</code>返回并再次打印出一个提示，为下一个命令做好准备。</p><p><code>fork()</code>和<code>exec()</code>的分离允许shell很容易地完成一堆有用的东西。例如: <code>wc p3.c &gt; 1.txt</code><br>shell完成此任务的方式非常简单，在创建子进程时，在调用<code>exec()</code>之前，shell关闭stdout并打开文件<code>1.txt</code>。通过这样做，即将运行的此程序的任何输出都被发送到文件而不是屏幕。</p><p>下面的程序便完成这样的操作:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// All Of The Above With Redirection (p4.c)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fcntl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> rc = fork();</span><br><span class="line">    <span class="keyword">if</span> (rc &lt; <span class="number">0</span>) &#123; <span class="comment">// &gt;&gt;&gt;fork failed; exit</span></span><br><span class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"fork failed\n"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (rc == <span class="number">0</span>) &#123; <span class="comment">// child: redirect standard output to a file</span></span><br><span class="line">        close(STDOUT_FILENO);</span><br><span class="line">        open(<span class="string">"./p4.output"</span>, O_CREAT|O_WRONLY|O_TRUNC, S_IRWXU);</span><br><span class="line">        <span class="comment">// now exec "wc"...</span></span><br><span class="line">        <span class="keyword">char</span> *myargs[<span class="number">3</span>];</span><br><span class="line">        myargs[<span class="number">0</span>] = strdup(<span class="string">"wc"</span>); <span class="comment">// program: "wc" (word count)</span></span><br><span class="line">        myargs[<span class="number">1</span>] = strdup(<span class="string">"p4.c"</span>); <span class="comment">// argument: file to count</span></span><br><span class="line">        myargs[<span class="number">2</span>] = <span class="literal">NULL</span>; <span class="comment">// marks end of array</span></span><br><span class="line">        execvp(myargs[<span class="number">0</span>], myargs); <span class="comment">// runs word count</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; <span class="comment">// parent goes down this path (main)</span></span><br><span class="line">        <span class="keyword">int</span> rc_wait = wait(<span class="literal">NULL</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./p4</span><br><span class="line"></span><br><span class="line">cat p4.output</span><br><span class="line"> 29 116 874 p4.c</span><br></pre></td></tr></table></figure><p>首先，当运行p4时，看起来好像什么也没有发生过。shell只是打印命令提示符，并立即为下一个命令做准备。但事实并非如此，p4确实调用<code>fork()</code>来创建一个新子节点，然后通过调用<code>execvp()</code>来运行wc程序。你没有看到任何输出打印到屏幕是因为它已被重定向到文件中。</p><p>Unix <strong>管道(pipe)</strong> 以类似的方式实现，但使用<code>pipe()</code>系统调用。这种情况下，一个进程的输出连接到一个内核管道(即队列)，另一个进程的输入连接到同一个管道。因此，一个进程的输出无缝地用作下一个进程的输入，并且长而有用的命令链可以串在一起。如这个栗子: <code>grep -o foo file | wc -l</code>。</p><p>现在，只需说<code>fork()</code>和<code>exec()</code>组合是一种创建和操作进程的强大方法就足够了。</p><p><br></p><blockquote><p>ASIDE: <strong>READ THE MAN PAGES</strong><br>本书中，当提到特定的系统调用或库调用时，会让你阅读<strong>手册(man/manual pages)</strong>。花时间阅读手册石喜彤程序员成长的关键一步，这些手册页中隐藏了大量有用的花絮。<br>最后，阅读手册可让你避免一些尴尬。当你向别人询问问题是，别人可能会叫你阅读文档。</p></blockquote><p><br><br><br></p><h3 id="进程控制和用户"><a href="#进程控制和用户" class="headerlink" title="进程控制和用户"></a>进程控制和用户</h3><p>Process Control And Users</p><p>在Unix系统中，除了<code>fork()</code>, <code>exec()</code>, <code>wait()</code>之外，还有许多其它接口可与进程进行交互。例如，<code>kill()</code>系统调用用于向进程发送<strong>信号(signal)</strong>，包括暂停(pause)、死亡(die)和其它有用的指令。为了方便起见，在大多数Unix Shell中，某些键组合被配置为向当前运行的进程传递特定信号。栗子如下:</p><div class="table-container"><table><thead><tr><th>键组合</th><th>信号</th><th>描述</th></tr></thead><tbody><tr><td><code>ctrl+c</code></td><td>SIGINT(2)</td><td>中断</td></tr><tr><td><code>ctrl+z</code></td><td>SIGTSTOP(19)</td><td>停止(暂停)</td></tr></tbody></table></div><p>整个信号子系统提供了丰富的基础设施，可为进程提供外部事件，包括在各个进程中接收和处理这些信号的方法，以及向各个进程以及整个进程组(process groups)发送信号的方法。要使用这种通信形式，进程应使用<code>signal()</code>系统调用来捕获(catch)各种信号。这样做可确保当特定信号传递到进程时，它将暂停正常执行并运行特定代码以响应该信号。</p><p>这自然会提出一个问题：<strong>谁可以向进程发送信号，谁不能发送？</strong><br>通常，系统可以让多个用户同时使用。如果其中一个人可以随意发送信号(如<code>SIGINT</code>)，则系统的可用性和安全性将受到影响。因此，现代系统包含用户的强烈概念。用户在输入密码建立凭据后，登录以获取对系统资源的访问权限。然后，用户可以启动一个或多个进程，并对它们进行完全控制(pause, kill…)，用户通常只能控制自己的进程。操作系统的工作是将资源(cpu, mem, disk…)分配给每个用户(及其进程)以满足整体系统目标。</p><p><br><br><br></p><h3 id="有用的工具"><a href="#有用的工具" class="headerlink" title="有用的工具"></a>有用的工具</h3><p>Useful Tools</p><p>有许多命令行工具也很有用。如下:</p><ul><li><code>ps</code></li><li><code>top</code></li><li><code>sar</code></li><li><code>kill</code></li><li><code>killall</code></li></ul><p><br><br><br></p><h3 id="摘要-1"><a href="#摘要-1" class="headerlink" title="摘要"></a>摘要</h3><p>Summary</p><p>我们介绍了一些处理Unix进程创建的API: <code>fork(), exec(), wait()</code>。但是，我们刚刚撇去了表面。</p><p><strong>ASIDE: KEY PROCESS API TERMS</strong></p><ul><li>每个进程都有一个名字，在大多数系统中，该名称为<strong>PID</strong>；</li><li><code>fork()</code>系统调用在Unix系统中用于创建新进程。创建者被称为<strong>父进程（parent）</strong>，被创建的新进程被称为<strong>子进程（child）</strong>；</li><li><code>wait()</code>系统调用允许父进程等待其子进程完成执行；</li><li><code>exec()</code>系统调用允许子进程摆脱与父进程的相似性并执行一个全新的程序；</li><li>Unix Shell通常使用<code>fork(), exec(), wait()</code>来启动用户命令。<code>fork()</code>和<code>exec()</code>的分离支持I/O重定向、管道…；</li><li>进程控制以信号的方式提供，这可能导致作业停止、继续或终止；</li><li>可由特定用户控制哪些进程被封装在用户的概念中。操作系统允许多个用户同时登录，并确保用户只能控制自己的进程；</li><li><strong>超级用户(superuser)</strong>可以控制所有进程。出于安全考虑，请不要使用此用户进行直接操作。</li></ul><p><br><br><br><br><br></p><h2 id="直接执行"><a href="#直接执行" class="headerlink" title="直接执行"></a>直接执行</h2><p><a href="http://pages.cs.wisc.edu/~remzi/OSTEP/cpu-mechanisms.pdf" target="_blank" rel="noopener">Mechanism: Limited Direct Execution</a></p><p>为了虚拟化CPU，操作系统需要以某种方式在同时运行的许多作业中共享物理CPU。基本思路很简单：运行一个进程一段时间，然后运行另一个进程，以此类推。通过<strong>分时共享(time sharing)</strong>CPU，实现了虚拟化。</p><p>然而，构建这样的虚拟化也存在一些挑战：</p><ul><li>首先是<strong>性能（Performance）</strong>：如何在不增加系统过多开销的情况下实现虚拟化？</li><li>第二是<strong>控制（Control）</strong>：如何保持在对CPU的控制的同时有效地运行进程？控制对操作系统尤其重要，，因为它控制资源。如果没有控制权，进程就可以永远运行并接管机器，或者访问不应该被它访问的信息。</li></ul><p>因此，要在保持控制的同时获得高性能是构建操作系统的核心挑战之一。</p><blockquote><p>关键：<strong>如何通过控制有效地虚拟化CPU</strong><br>操作系统必须以有效地方式虚拟化CPU，同时保持对系统的控制。为此，需要硬件和操作系统的支持。操作系统通常会使用明智的硬件支持来完成其工作。</p></blockquote><p><br><br><br></p><h3 id="基本技术：有限的直接执行"><a href="#基本技术：有限的直接执行" class="headerlink" title="基本技术：有限的直接执行"></a>基本技术：有限的直接执行</h3><p>Basic Technique: Limited Direct Execution</p><p>为了使程序以预期的速度运行，操作系统开发人员提出了一种技术——<strong>有限的直接执行（limited direct execution）</strong>。<strong>直接执行（direct execution）</strong>的想法很简单：只需在CPU上直接运行程序即可。因此，当操作系统启动一个程序运行时，它会在进程列表中为它创建一个进程条目，为它分配一些内存，将程序代码加载到内存中，找到它的入口点(<code>main()</code>例程或类似的东西)，跳转到它，并开始运行用户的代码。</p><p><br></p><p><strong>Direct Execution Protocol (Without Limits)</strong></p><div class="table-container"><table><thead><tr><th>OS</th><th>Program</th></tr></thead><tbody><tr><td>创建进程列表条目<br>为程序分配内存<br>将程序加载到内存<br>使用<code>argc/argv</code>设置堆栈<br>清除寄存器<br>执行调用<code>main()</code></td><td></td></tr><tr><td></td><td>运行<code>main()</code><br>从main执行return</td></tr><tr><td>释放进程内存<br>从进程列表中删除条目</td></tr></tbody></table></div><p>听起来很简单，但这种方法在我们尝试虚拟化CPU的过程中会产生一些问题：</p><ul><li>如果我们只运行一个程序，操作系统如何确保程序不执行我们不希望它执行的操作，同时仍然有效地运行它？</li><li>当运行一个程序时，操作系统如何阻止它运行并切换到另一个进程，从而实现我们虚拟化CPU所需的分时共享？</li></ul><p><br><br><br></p><h3 id="问题1：受限制的操作"><a href="#问题1：受限制的操作" class="headerlink" title="问题1：受限制的操作"></a>问题1：受限制的操作</h3><p>Problem1: Restricted Operations</p><p>直接执行具有快速的明显优势，程序直接在原生CPU硬件上运行，因此可按照预期的速度执行。但是在CPU上运行会引发一个问题：如果进程希望执行某种受限制的操作（如向磁盘发出I/O请求，访问更多系统资源(cpu, kernel)…），该怎么办？</p><blockquote><p><strong>如何执行受限制的操作</strong><br>进程必须能够执行I/O或其它一些受限制的操作，但不能让进程完全控制系统。操作系统和硬件该如何协同工作？</p></blockquote><p><br></p><blockquote><p><strong>为什么系统调用看起来像程序调用</strong><br>你可能想知道为什么对系统调用（如<code>open(), read()...</code>）的调用看起来与C中的典型过程调用（procedure call）完全相同。也就是说，它看起来就像一个过程调用，系统如何知道它是一个系统调用，并做了所有正确的事情？原因很简单：它是一个过程调用，但隐藏在过程调用内部的是著名的<strong>陷阱指令（trap instruction）</strong>。举个栗子，当调用<code>open()</code>时，你正在执行对C library的过程调用。其中，无论是对于<code>open()</code>还是其它的系统调用，库都使用与内核达成一致的调用约定，将参数放在众所周知的位置（stack或register），也将系统调用号放入一个众所周知的位置(stack或register)，然后执行上述陷阱指令。陷阱解压后库中的代码将返回值，并将控制权返回给发出系统调用的程序。因此，进行系统调用的C库部分是在汇编中手工编码的，因为它们需要仔细准遵循约定，以便正确处理参数和返回值，以及执行特定于硬件的陷阱指令。这个汇编代码已经有人替你做了。</p></blockquote><p><br></p><p>一种方法是让任何进程在I/O和其它相关操作方面做任何它们想做的事情。然而，这样做会妨碍构建所需的多种操作系统。例如，如果我们希望构建一个在授予文件访问权限之前检查权限的文件系统，我们不能简单地让任何用户进程向磁盘发出I/O。如果这样做了，一个进程可以简单地读写整个磁盘，因此所有的保护都将丢失。</p><p>因此，我们采用一种新的处理器模式——<strong>用户模式（user mode）</strong>。在用户模式下运行的代码受限于它们可以执行的操作。例如，在用户模式下运行时，进程无法发出I/O请求，这样做了会导致处理器引发异常，操作系统可能会杀死这个进程。</p><p>与用户模式相反，<strong>内核模式（kernel mode）</strong>是操作系统运行的模式。在此模式下，运行的代码可以执行其喜欢的操作，包括发出I/O请求、执行所有类型的受限制的指令。</p><p>但是，当<strong>用户进程（user process）</strong>希望执行某种特权操作（如I/O）时应该做什么？为了实现这一点，几乎所有的现代硬件都为用户程序提供了执行系统调用的能力。系统调用允许内核小心地将某些关键功能部件暴露给用户程序。如访问文件系统、创建和销毁进程、与其它进程通信以及分配更多内存…大多数操作系统提供了几百个调用（详情请参考POSIX标准）。</p><p><br></p><blockquote><p><strong>使用受保护的控制转移</strong><br>硬件通过提供不同的执行模式来协助操作系统。<br>在用户模式下，应用程序无法完全访问硬件资源。<br>在内核模式下，操作系统可以访问机器的全部资源。<br>还提供了从陷阱（trap）到内核（kernel）并<strong>从陷阱返回（return-from-trap）</strong>到用户模式的特殊指令，以及允许操作系统告知硬件陷阱表（trap table）驻留在内存中的指令。</p></blockquote><p><br></p><p>要执行系统调用，程序必须执行特殊的陷阱指令。该指令同时跳转到内核并将权限级别提升为内核模式。一旦进入内核，系统现在可以执行所需的任何特权操作（如果允许），从而为调用进程执行所需的工作。完成后，操作系统会调用一个特殊的<strong>从陷阱返回（return-from-trap）</strong>指令，该指令将返回到调用用户程序，同时将权限级别降低到用户模式。</p><p>执行陷阱(trap)时硬件需要小心，它必须确保保存足够的调用程序寄存器（caller’s register），以便在操作系统发出<code>return-from-trap</code>指令时能够正确返回。例如，在x86上，处理器会将程序计数器（counter）、标志（flag）和一些其它寄存器（register）推送（push）到每个进程的<strong>内核栈（kernel stack）</strong>。<code>return-from-trap</code>会将这些值从栈中弹出（pop）并继续执行用户模式的程序。其它硬件系统可能有所不同，但基本概念在不同平台上是相同的。</p><p>还有一个重要细节：陷阱如何知道在操作系统中运行哪些代码？显然，调用进程无法指定要跳转的地址。这样做会让程序跳转到内核，这显然是一个非常糟糕的想法。因此内核必须消息控制在陷阱（trap）上执行的代码。</p><p>内核通过在启动时设置<strong>陷阱表（trap table）</strong>来实现。当机器启动时，它在特权（内核）模式下，因此可以根据需要自由配置机器硬件。操作系统首先要做的事情之一就是告诉硬件在发生某些异常事件时要运行什么代码。<br>例如，当发生硬盘中断、发生键盘中断或程序进行系统调用时，应该运行什么代码？操作系统通常通过某种特殊指令通知硬件这些<strong>陷阱处理程序（trap handler）</strong>的位置。一旦通知硬件，它会记住这些处理程序的位置，直到机器下次重启，因此当系统调用或其它异常事件发生时，硬件知道该做什么。</p><p><br></p><p><strong>Limited Direct Execution Protocol</strong></p><div class="table-container"><table><thead><tr><th>os@boot</th><th>hardware</th></tr></thead><tbody><tr><td>initialize trap table</td><td></td></tr><tr><td></td><td>remember address of… <br> syscall handler</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>os@run</th><th>hardware</th><th>program(user mode)</th></tr></thead><tbody><tr><td>Create entry for process list<br>Allocate memory for program<br>Load program into memory<br>Setup user stack with argv<br>Fill kernel stack with reg/PC<br>return-from-trap</td><td></td><td></td></tr><tr><td></td><td>restore regs(from kernel stack)<br>move to user mode<br>jump to main</td><td></td></tr><tr><td></td><td></td><td>Run main()<br>…<br>Call system call<br>trap into OS</td></tr><tr><td></td><td>save regs(to kernel stack)<br>move to kernel mode<br>jump to trap handler</td><td></td></tr><tr><td>Handle trap<br>Do work of syscall<br>return-from-trap</td><td></td><td></td></tr><tr><td></td><td>restore regs(from kernel stack)<br>move to user mode<br>jump to PC after trap</td><td></td></tr><tr><td></td><td></td><td>…<br>return from main<br>trap (via exit())</td></tr><tr><td>Free memory of process<br>Remove from process list</td><td></td></tr></tbody></table></div><p>此时间线总结了协议。假设每个进程都有一个内核寄存器，其中寄存器在进入和退出内核时保存到硬件，并从硬件恢复。</p><p><br></p><blockquote><p><strong>警惕安全系统中的用户输入</strong><br>即使我们在系统调用期间都非常努力地保护操作系统（通过添加硬件陷阱机制），但实现安全操作系统还有许多其它方面必须考虑。其中之一是在系统调用边界梳理参数，操作系统必须检查用户传入的内容并确保正确指定了参数，否则拒绝该调用。例如，通过<code>write()</code>调用，用户将缓冲区的地址指定为write调用的源。如果用户(意外或恶意)传入坏地址（如，内核地址空间的一部分），操作系统必须检测到这一点并拒绝该调用。否则，用户可以读取所有内核内存。鉴于kernel（virtual）内存通常还包括其它的所有物理内存，这个小的滑动将使程序能够读取系统中的任何其它进程的内存，这是非常危险的。<br>通常，安全系统必须非常怀疑地（great suspicion）处理用户输入。不这样做容易导致软件被黑，世界是一个不安全和可怕的地方。</p></blockquote><p><br></p><p>要指定确切地系统调用，通常会为每个系统调用分配<strong>系统调用号（system call number）</strong>。因此，用户代码负责将所有所需的系统调用号放在寄存器或栈上的特定位置。操作系统在陷阱处理程序内部处理系统调用时，检查此号码，确保它有效。如果有效，则执行相应的代码。这种间接性是一种保护形式，用户代码无法指定要跳转确切地址，而是必须通过号码请求特定服务。</p><p>能够执行指令告诉硬件陷阱表所在的位置是一个非常强大的功能。因此，如你所猜，它也是一种特权操作（ privileged operation）。如果你在用户模式下执行此指令，硬件不会鸟你。<br>如果你可以安装自己的陷阱表，你可以对系统做些什么可怕的事情？你能接管机器吗？</p><p><br></p><p>有限的直接执行（LDE）有两个阶段：</p><ul><li>启动时，内核初始化陷阱表，CPU会记住它的位置以供后续使用；</li><li>内核通过特权指令执行此操作。<br>内核在使用<code>return-from-trap</code>指令开始执行进程之前设置了一些东西（分配进程列表、内存…）。这会将CPU切换到用户模式并开始运行此进程。当进程希望发出系统调用时，操作系统处理进程并再次通过<code>return-from-trap</code>将控制权返回给进程。然后进程完成其工作，并从<code>main()</code>返回。它通常会返回存根代码，它将正确地退出程序。此时操作系统清理完毕，就完成了。</li></ul><p><br><br><br></p><h3 id="问题2：在进程间切换"><a href="#问题2：在进程间切换" class="headerlink" title="问题2：在进程间切换"></a>问题2：在进程间切换</h3><p>Problem2: Switching Between Processes</p><p>直接执行的下一个问题是实现<strong>进程之间的切换（switch between process）</strong>。进程之间的切换很简单吗？操作系统应该决定停止一个进程并启动另一个进程。这看起来简单，但实际上有点棘手。具体来说，如果一个进程在CPU上运行，这意味着操作系统没有运行。如果操作系统没有运行，它怎么能做任何事情？吐过操作系统没有在CPU上运行，它显然没有办法采取行动。</p><blockquote><p><strong>如何恢复控制CPU</strong><br>操作系统如何重新获得对CPU的控制，以便它可在进程间切换？</p></blockquote><p><br><br><br></p><h4 id="合作方法：等待系统调用"><a href="#合作方法：等待系统调用" class="headerlink" title="合作方法：等待系统调用"></a>合作方法：等待系统调用</h4><p>A Cooperative Approach: Wait For System Calls</p><p>一些系统过去采用一种<strong>合作方法（cooperative approach）</strong>。在这种风格中，操作系统信任系统的进程以合理地运行。假定运行时间过长的进程会定期放弃CPU，以便操作系统可以决定运行其它任务。</p><p>因此，你可能会问，友好的进程如何在这个乌托邦世界中放弃CPU？事实证明，大多数进程通过进行系统调用来非常频繁地将CPU的控制权转移到操作系统。像这样的系统通常包括一个显式的<code>yield</code>系统调用，除了将控制权转移到操作系统（以便操作系统可以运行其进程）之外什么都不做。</p><p>应用程序在执行非法操作时也会将控制权转移到操作系统。举个栗子，如果应用程序除以零，或者尝试访问它无法访问的内存，则会为操作系统生成陷阱（trap）。然后操作系统再次获得CPU控制权（并可能终止非法进程）。</p><p>因此，在协同调度（cooperative scheduling）系统中，操作系统通过等待系统调用或某种非法操作来重新获得CPU的控制权。你可能回想，这种被动方法也不理想呀！如果一个进程（恶意或错误）最终在无限循环中结束，并且从不进行系统调用，会发生什么？操作系统可以做什么？</p><p><br><br><br></p><h4 id="非合作方法：操作系统取得控制权"><a href="#非合作方法：操作系统取得控制权" class="headerlink" title="非合作方法：操作系统取得控制权"></a>非合作方法：操作系统取得控制权</h4><p>A Non-Cooperative Approach: The OS Takes Control</p><p>如果没有硬件的额外帮助，当一个进程拒绝进行系统调用并因此将控制权返回给操作系统时，操作系统根本无法做很多事情。事实上，在合作方法中，当一个进程陷入无限循环时，你唯一的办法就是采用古老的办法解决计算机系统中的所有问题：重启（Reboot）。因此，我们再次提出了获得CPU控制权的一个子问题。</p><p><br></p><blockquote><p><strong>如何在没有合作的情况下获得控制权（HOW TO GAIN CONTROL WITHOUT COOPERATION）</strong><br>即使进程没有合作，操作系统如何才能获得对CPU的控制？操作系统可以做些什么确保流氓进程不会接管机器？</p></blockquote><p><br></p><p>答案很简单，许多人在许多年前构建操作系统时已经发现了：<strong>定时器终端（timer interrupt）</strong>。可以对定时器设备进行编程，以便每隔几毫秒(ms)产生一次中断。当中断被引发时，当前正在运行的进程停止（halted），并且操作系统中预配置的中断处理程序运行。此时，操作系统重新获得CPU的控制权。因此可以随心所欲：停止当前进程并启动另一个进程。</p><p>如前面讨论的那样，系统调用时，操作系统必须通知硬件当中断定时器发生时执行什么代码。因此，在启动时，操作系统就是这样做的。其次，在引导序列期间，操作系统必须启动定时器（这当然是特权操作）。一旦计时器开始，操作系统就可以感觉安全，因为控制权最终将返回给它，因此操作系统可以自由运行用户程序。</p><p><br></p><blockquote><p><strong>处理应用程序的坏事（DEALING WITH APPLICATION MISBEHAVIOR）</strong><br>操作系统通常必须处理行为不当的进程，这些进程（恶意或错误）尝试做它们不应该做的事情。在现代操作系统中，操作系统处理此类不当行为的方式是简单地终止（terminate）违法者。但当你试图非法访问内存或执行非法指令时，操作系统应该做什么呢？</p></blockquote><p><br></p><p>请注意，当发生中断时硬件有一定的责任，特别是为了保存中断发生时运行的程序的足够的状态，以便后续的<code>return-from-trap</code>指令能够正确地恢复正在运行的程序。这组操作非常类似与在显式系统调用陷阱到内核期间硬件的行为，因此各种寄存器被保存，因此可通过<code>return-from-trap</code>轻松恢复。</p><p><br><br><br></p><h4 id="保存和恢复上下文"><a href="#保存和恢复上下文" class="headerlink" title="保存和恢复上下文"></a>保存和恢复上下文</h4><p>Saving and Restoring Context</p><p>现在操作系统已经重新获得了控制权，无论是通过系统调用，还是通过定时器中断，都必须做出决定——是继续运行当前进程，还是切换到另一个进程。该决定由称为<strong>调度程序（scheduler）</strong>的操作系统的一部分做出，这将在后面学习。</p><p>如果决定做切换，则操作系统执行低级代码。我们称之为<strong>上下文切换（context switch）</strong>。上下文切换的概念很简单：所有操作系统必须做的是为当前正在执行的进程保存一些寄存器值（如，在其内核栈上），并为即将执行的进程恢复（如，来自其内核栈）。通过这样做，操作系统因此确保当最终执行<code>return-from-trap</code>指令时，系统继续执行另一个进程，而不是返回到正在运行的进程。</p><p>为了保存当前正在运行的进程的上下文，操作系统将执行一些低级汇编代码（low-level assembly code），以保存和运行当前正在运行的进程的通用寄存器、PC、内核栈指针，然后恢复所述寄存器、PC，并切换到内核堆栈，以便于即将执行的进程。通过切换栈，内核在一个进程（被中断的进程）的上下文中进行切换代码的调用，并在另一个进程（将被执行的进程）的上下文中返回。操作系统最终执行<code>return-from-trap</code>指令，即将执行的进程将成为当前正在运行的进程。因此上下文切换完成。</p><p><br></p><blockquote><p><strong>使用定时器中断来重新获得控制权</strong><br>定时器中断使操作系统能够在CPU上再次运行，即使进程以非协作方式运行。因此，此硬件功能对于帮助操作系统维护机器的控制至关重要。</p></blockquote><p><br></p><blockquote><p><strong>重启是有用的</strong><br>早些时候，我们注意到在协作下抢占无限循环（infinite loops）的唯一解决办法是重启机器。虽然你可能会嘲笑，但研究人员已经证明重启可以成为构建健壮系统的一个非常有用的工具。<br>具体来时，重启是有用的。因为它将软件移回到已知且更加可测试的状态。重启还会回收陈旧或泄露的资源（如，memory），否则这些资源可能难以处理。最后，重启很容易实现自动化。</p></blockquote><p><br></p><p>整个进程的时间线如下所示。在此示例中，进程A正在运行，然后被定时器中断所中断。硬件保存其寄存器（在其内核栈上）并进入内核（切换到内核模式）。在定时器中断处理程序中，操作系统决定从正在运行的进程A切换到进程B。此时，它调用<code>switch()</code>例程，该例程小心地保存当前寄存器值（进入A的进程结构），恢复进程B的寄存器（来自其进程结构条目），然后切换上下文，特别是通过更改栈指针来使用B的内核栈（而不是A的）。最后，操作系统执行<code>return-from-trap</code>，它恢复B的寄存器并开始运行它。</p><p><strong>: Limited Direct Execution Protocol (Timer Interrupt)</strong></p><div class="table-container"><table><thead><tr><th>os@boot<br>kernel mode</th><th>hardware</th></tr></thead><tbody><tr><td>initialize trap table</td><td></td></tr><tr><td></td><td>remember addresses of…<br>syscall handler<br>timer handler</td></tr><tr><td>start interrupt timer</td><td></td></tr><tr><td></td><td>start timer<br>interrupt CPU in X ms</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>os@boot<br>kernel mode</th><th>hardware</th><th>program<br> user mode</th></tr></thead><tbody><tr><td></td><td></td><td>Process A<br>…</td></tr><tr><td></td><td>timer interrupt<br>save regs(A) → k-stack(A)<br>move to kernel mode<br>jump to trap handler</td><td></td></tr><tr><td>Handle the trap<br>Call <code>switch()</code> routine<br>save regs(A) → proc t(A)<br>restore regs(B) ← proc t(B)<br>switch to k-stack(B)</td><td></td><td></td></tr><tr><td>return-from-trap (into B)</td><td></td><td></td></tr><tr><td></td><td>restore regs(B) ← k-stack(B)<br>move to user mode<br>jump to B’s PC</td><td></td></tr><tr><td></td><td></td><td>Process B<br>…</td></tr></tbody></table></div><p><br><br><br></p><h3 id="担心并发？"><a href="#担心并发？" class="headerlink" title="担心并发？"></a>担心并发？</h3><p>Worried About Concurrency?</p><p>细心的读者可能会想到：在系统调用期间发生定时器中断，会发生什么？或，当你在处理一个中断时而另一个中断发生会发生什么？在内核中难处理吗？……</p><p>操作系统确实需要关注在中断或陷阱处理期间发生其它中断会发生什么。事实上，这是本书后面关于<strong>并发（concurrency）</strong>的内容。为了满足读者的胃口，这里介绍操作系统如何处理这些棘手情况的一些基础知识。</p><p>操作系统可能做的一件简单的事情，在中断处理期间<strong>禁用中断(disable interrupts)</strong>。这样做可确保在处理一个中断时，不会将其它任何中断传递到CPU。当然，操作系统必须小心这样做，长时间禁用可能会导致中断丢失，这是不好的。</p><p>操作系统还开发了许多复杂的<strong>锁定（locking）</strong>方案，以保护对内部数据结构的并发访问。这使得许多活动可以同时在内核中进行，特别适用于多处理器（multiprocessors）。这种锁定可能很复杂，并导致各种有趣且难以发现的错误(bugs)。</p><p><br><br><br></p><h3 id="摘要-2"><a href="#摘要-2" class="headerlink" title="摘要"></a>摘要</h3><p>我们描述了一些实现CPU虚拟化的关键低级机制，这是一组我们统称为<strong>有限直接执行（limited direct execution）</strong>的技术。基本思路很简单：只需运行你想在CPU上运行的程序，但首先要确保设置硬件以便在没有操作系统辅助的情况下限制进程可以执行的操作。</p><p>我们具有虚拟化CPU的基本机制。但是一个主要问题没有回答：我们应该在给定时间运行哪个进程？<strong>调度器</strong>必须回答这个问题，这是后面讨论的问题。</p><p><br></p><blockquote><p><strong>上下文切换会花费多长时间</strong><br>你可能回想：上下文切换需要多长时间？或系统调用？有一些工作可以准确测量这些东西，以及一些其它可能的指标。<br>这当然也和硬件配置有关系。应当注意，并非所有操作系统都追踪CPU性能。许多操作系统是内存密集型的，并且内存带宽并没有像处理器速度那样显著提高。所以，购买强大的硬件配置能加速你的操作系统。</p></blockquote><p><br></p><p><strong>CPU虚拟化术语</strong></p><ul><li>CPU至少支持两种执行模式：<strong>受限的用户模式</strong>和<strong>特权内核模式（非受限）</strong></li><li>典型的用户应用程序以用户模式运行，并使用系统调用来陷阱(trap)到内核中以请求操作系统服务</li><li>陷阱指令小心保存寄存器状态，将硬件状态更改为内核模式，并跳转到操作系统到预先指定的目标：<strong>陷阱表（trap table）</strong></li><li>当操作系统完成对系统调用的服务时，它会通过另一个特殊的<code>return-from-trap</code>指令返回到用户程序，这会降低权限并在跳转到操作系统的陷阱后将控制权返回给指令</li><li>操作系统必须在引导（boot）时设置陷阱表，并确保用户程序无法轻松修改它们。所有这些都是有限直接执行协议的一部分，改写以有效地运行程序但不会丢失操作系统控制</li><li>程序运行后，操作系统必须使用<strong>硬件机制（定时器中断）</strong>来确保用户程序不会永远运行。这种方法是CPU调度的非协作方法</li><li>有时，在定时器中断或系统调用期间，操作系统可能希望从运行当前进程切换到另一个进程，这是一种被称为<strong>上下文切换（context switch）</strong>的低级技术</li></ul><p><br><br><br><br><br></p><h2 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h2><p><a href="http://pages.cs.wisc.edu/~remzi/OSTEP/cpu-sched.pdf" target="_blank" rel="noopener">CPU Scheduling</a></p><p>到现在为止，运行进程的低级机制（上下文切换）应该是清楚的。但是，我们尚未了解操作系统调度程序使用的高级策略。<br>事实上，调度的起源早于计算机系统。早期的方法来自运营管理领域并应用于计算机。</p><p><br></p><blockquote><p><strong>如何制定调度策略（SCHEDULING POLICY）</strong><br>如何开发一个思考型调度策略的基本框架？关键假设是什么？哪些指标很重要？在最早的计算机系统中使用了哪些方法？</p></blockquote><p><br><br><br></p><h3 id="工作负载假设"><a href="#工作负载假设" class="headerlink" title="工作负载假设"></a>工作负载假设</h3><p>Workload Assumptions</p><p>在介绍可能的策略范围之前，让我们首先对系统中运行的进程做一些简化的假设，有时统称为<strong>工作负载（workload）</strong>。确定工作负载是构建策略的关键部分，对工作负载了解的越多，你的策略就越精细。</p><p>我们将对系统中的进程（有时称为作业(jobs)）做出以下假设：</p><ul><li>每个作业运行相同的时间</li><li>所有作业都在同一时间完成</li><li>一旦启动，每个作业都会运行完成</li><li>所有作业仅使用CPU</li><li>每个作业的运行时间都是已知的</li></ul><p>这些假设很多是不现实的，正如乔治奥威尔《动物农场》中的一些动物比其它动物更平等，本章的一些假设比其它假设更不切实际。特别是，每个作业的运行时间都是已知的。这样做使调度程序无所不知。</p><p><br><br><br></p><h3 id="调度指标"><a href="#调度指标" class="headerlink" title="调度指标"></a>调度指标</h3><p>Scheduling Metrics</p><p>除了进行工作负载假设之外，还需要一件事来使我们能够比较不同的调度策略：<strong>调度指标（Scheduling Metrics）</strong>。指标用来衡量某些事物，不同的指标在调度中也有不同的意义。<br>但是，就目前而言。我们来看一个简单的指标：<strong>周转时间（turnaround time）</strong>。作业的周转时间定义为作业完成时间减去作业到达系统的时间：</p><script type="math/tex; mode=display">T_{turnaround} = T_{completion} − T_{arrival}</script><p>应该注意，周转时间是一个性能指标。这将是本章的主要关注点。另一个有趣的指标是<strong>公平性（fairness）</strong>。在调度方面，性能和公平性往往不一致，这也告诉我们生活并不总是完美的。</p><p><br><br><br></p><h3 id="先进先出"><a href="#先进先出" class="headerlink" title="先进先出"></a>先进先出</h3><p>First In, First Out (FIFO)</p><p>一个最基本的算法为<strong>先进先出（First In First Out (FIFO)）</strong>调度。它具有许多积极的属性，简单且易于实现。并且根据假设，它运作良好。</p><p>让我们做一个快速的栗子。想象一下，有三个作业A, B, C在大致相同的时间到达系统（<script type="math/tex">T_{arrival}=0</script>）。由于先进先出必须放置一些工作，让我们假设A-B-C的顺序，假设每个作业运行10s。这些作业的平均周转时间是多少？</p><p><img src="/images/OSTEP/fifo71.png" alt></p><p>如图，A在10时完成，B在20时完成，C在30时完成。因此，三个作业的平均周转时间仅为<script type="math/tex">\frac{10+20+30}{3}=30</script>。</p><p><br></p><p>让我们举个栗子来说明不同长度的作业如何导致先进先出调度出现问题。特别是，假设A运行100s,B和C还是10s。</p><p><img src="/images/OSTEP/fifo72.png" alt></p><p>如图所示，在B或C有机会运行之前，作业A首先整整运行100s。因此，系统的平均周转时间很长：<script type="math/tex">\frac{100+110+120}{3}=110</script>，痛苦的110s。<br>这个问题通常被称为<strong>车队效应（convoy effect）</strong>，其中资源的一些小型消费者排在重量级消费者后面。那该怎么办？我们如何开发一种更好的算法来处理？</p><p><br><br><br></p><h3 id="最短作业优先"><a href="#最短作业优先" class="headerlink" title="最短作业优先"></a>最短作业优先</h3><p>Shortest Job First (SJF)</p><blockquote><p><strong>最短作业优先的原则</strong><br>最短作业优先表示可用于任何系统的一般调度原则，其中每个作业的感知周转时间很重要。如果有关机构关心客户满意度的话，很可能他们已经考虑使用最短作业优先。</p></blockquote><p><br></p><p><strong>最短作业优先（Shortest Job First(SJF)）</strong>，它首先运行最短的作业，然后是下一个最短的作业，依此类推。</p><p><img src="/images/OSTEP/sjf73.png" alt></p><p>如图，该图表明了最短作业优先在平均周转时间方面的表现要好得多。它将之前的平均周转时间从110s减少到50s（<script type="math/tex">\frac{10+20+120}{3}=50</script>），这是极大的改善。<br>事实上，鉴于我们对所有作业的假设都是同时到达，所以证明它是最优调度算法。但我们的假设相当不切实际。</p><p><br></p><p>这里再举个例子。假设A在<code>t=0</code>时到达并且需要运行100s，而B和C在<code>t=10</code>时到达并且每个需要运行10s。</p><p><img src="/images/OSTEP/sjf74.png" alt></p><p>如图，即使B和C在A之后不久到达，他们仍然被迫等到A完成，因此遭遇了同样的车队问题。平均周转时间为103.33s（<script type="math/tex">\frac{100+(110-10)+(120-10)}{3}</script>）。调度程序能做什么？</p><p><br></p><blockquote><p><strong>预备调度器</strong><br>事实上，所有现代调度程序都是先发制人，并且非常愿意停止一个运行的进程以运行其它进程。这意味着调度程序采用我们之前学习的机制。特别是，调度程序可以进行上下文切换，暂时停止一个正在运行的进程并恢复另一个进程。</p></blockquote><p><br><br><br></p><h3 id="最短完成时间优先"><a href="#最短完成时间优先" class="headerlink" title="最短完成时间优先"></a>最短完成时间优先</h3><p>Shortest Time-to-Completion First (STCF)</p><p>我们还需要调度程序本身内的一些机制。鉴于前面关于计时器中断和上下文切换的讨论，调度程序当然可以在B和C到达时执行其它操作：它可以抢占作业A并决定运行另一个作业，可能会在执行继续作业A。最短作业优先是<strong>非抢先式（non-preemptive）</strong>调度程序，因此会遇到上述问题。<br>幸运的是，有一个调度程序正是这样做：向最短作业优先添加抢占，称为<strong>最短完成时间优先（Shortest Time-to-Completion First (STCF)）</strong>，或<strong>抢先最短作业优先（Preemptive Shortest Job First (PSJF)）</strong>调度程序。每当新作业进入系统时，最短完成时间优先调度程序就会确定剩余作业（包括新作业）中的哪一个剩余时间最少，并安排该作业。</p><p><img src="/images/OSTEP/stcf75.png" alt></p><p>如图，最短完成时间优先将抢占作业A并运行作业B和作业C以完成。只有当它们完成时才会安排作业A的剩余时间。<br>这会大大改善平均周转时间：<script type="math/tex">\frac{(120-0)+(20-10)+(30-10)}{3}=50</script>。根据假设，可证明最短完成时间优先是最优。但假设相当不切实际。</p><p><br><br><br></p><h3 id="响应时间指标"><a href="#响应时间指标" class="headerlink" title="响应时间指标"></a>响应时间指标</h3><p>A New Metric: Response Time</p><p>如果我们知道工作长度，并且工作只使用了CPU，并且我们唯一的指标是周转时间。那个STCF将是一个很好的策略。实际上，对于早期的批处理计算系统，这些类型的算法有一定意义。然而，分时（shared time）机器的引入改变了这一切。现在，用户将坐在终端上并要求系统提供交互式性能。因此，一个新的指标诞生了：<strong>响应时间（response time）</strong>。</p><p>响应时间：<script type="math/tex">T_{response=T_{firstrun}-T_{arrival}}</script></p><p>例如，作业A在0时到达，作业B和作业C在10时到达。则每个作业的相应时间如下：A(0-0)，B(10-10)，C(20-10)，平均值(3.33)。</p><p>正如你可能认为那样，STCF和相关方法对响应时间并不是特别好。如果三个作业同时到达，则第三个作业必须等待前两个作业完全运行才能安排一次。虽然周转时间很好，但这种方法对于响应时间和交互性来说非常糟糕。事实上，想象一下坐在终端前，打字输入，并且不得不等待10s才能看到系统的响应，因为其它工作已安排在你前面：非常不爽。</p><p>因此，我们还有另外一个问题：如果构建一个对响应时间敏感的调度程序？</p><p><br><br><br></p><h3 id="轮询"><a href="#轮询" class="headerlink" title="轮询"></a>轮询</h3><p>Round Robin</p><p>为了解决这个问题，将引入一种新的调度算法，通常称为<strong>轮询调度（RR, Round Robin）</strong>。基本思路很简单：轮询不是运行作业完成，而是运行<strong>时间切片（time slice）</strong>作业，然后切换到运行队列中的下一个作业。它重复这样做，知道工作完成。因此，轮询有时被称为时间切片（ time-slicing）。注意，时间片的长度必须是定时器中断周期的倍数。例如，如果定时器中断每10ms中断一次，则时间片可以是10ms, 20ms, 10Nms。</p><p><br></p><p>为了更详细的了解轮询，让我们来看一个栗子。假设有三个作业A, B, C在系统中同时到达，并且每个作业都希望运行5s。最短作业优先在运行另一个作业之前运行每个作业（图7.6），相比之下，时间切片为1s的轮询将快速循环作业（图7.7）。</p><p><img src="/images/OSTEP/sjf76.png" alt></p><p><img src="/images/OSTEP/rr77.png" alt></p><p>平均响应时间：</p><ul><li>轮询（RR）：<script type="math/tex">\frac{0+1+2}{3}=1</script></li><li>最短作业优先（SJF）：<script type="math/tex">\frac{0+5+10}{3}=5</script></li></ul><p>如你所见，时间片的长度对轮询至关重要。它越短，响应时间的指标度量下轮询的性能越好。然而，使时间片太短是有问题的：上下文切换的成本将主导整体的性能。因此，决定时间片的长度给系统设计者带来了折中，使其足够长以<strong>分摊（amortize）</strong>切换成本不会使系统不再响应。</p><p><br></p><blockquote><p><strong>分摊可以降低成本（ AMORTIZATION CAN REDUCE COSTS）</strong><br>当某些操作存在固定成本时，一般的分摊技术通常用于系统中。通过较少地产生该成本，降低了系统的总成本。例如，如果时间片设置为10ms，并且上下文切换成本为1ms，则大约10%的时间用于上下文切换，浪费了。如果我们想分摊此成本，我们可以增加时间片（如100ms）。在这种情况下，上下文切换花费的时间少于1%，因此时间切片的成本已经分摊。</p></blockquote><p><br></p><p>请注意，上下文切换的成本不仅仅来自于操作系统保存和恢复一些寄存器的操作。程序运行时，它们在CPU Cache、TLBs、Branch Predictors和其它分片上构建了大量状态(state)。切换到另一个作业会导致刷新(flush)此状态，并且将引入与当前正在运行的作业相关的新状态，这可能导致显著的性能成本。</p><p>因此，如果响应时间是我们的唯一指标，那么具有合理时间片的轮询将是一个出色的调度程序。但我们的老朋友周转时间呢？来看个栗子。A、B、C各自需要5s运行时间，它们同时到达，并且轮询的时间片为1s。从上面轮序的运行图可看出，A在13完成，B在14完成，C在15完成，平均时间为14。</p><p>如果周转时间使我们的指标，则轮序是最糟的策略之一。轮序正在做的是延长每个作业，只要它可以，只需在移动到下一个作业之前运行每个作业一小段。由于周转时间紧关注作业何时完成，因此在很多情况下，轮询几乎是悲观的，甚至比简单的先进先出更差。</p><p>任何公平的策略（如RR），即在小时间范围内在活跃进程之间均匀划分CPU，将在如周转时间的指标上表现不佳。实际上，这是一种固有的权衡：如果你愿意不公平，你可以完成更短的工作，按时以响应时间为代价；如果你更重视公平，那么响应时间会降低，但会以周转时间为代价。这种权衡(trade-off)在系统中很常见。you can’t have your cake and eat it too.</p><p>我们介绍了两种类型的调度程序，当然这些都是基于假设下：</p><ul><li>SJF, STCF优化了周转时间，但对响应时间不利；</li><li>RR优化了响应时间，但对周转时间不利；</li></ul><p><br><br><br></p><h3 id="合并I-O"><a href="#合并I-O" class="headerlink" title="合并I/O"></a>合并I/O</h3><p>Incorporating I/O</p><blockquote><p><strong>重叠使得更高的使用率(OVERLAP ENABLES HIGHER UTILIZATION)</strong><br>如果可能，重叠(overlap)操作以最大化系统的利用率。重叠在许多不同的域中都很有用，包括执行磁盘I/O或向远程计算机发送消息时。在任何一种情况下，启动操作然和切换到其它作业是一个好主意，并提高系统的整体利用率和效率。</p></blockquote><p><br></p><p>放松假设4，假设所有程序都执行I/O。想象一个没有任何输入的程序，它每次会产生相同的输出。</p><p>当作业启动I/O请求时，调度程序明会做一个明确地决定。因为当前正在运行的作业在I/O期间不会使用CPU，它被阻止(blocked)以等待I/O完成。如果将I/O发送到磁盘驱动器，则该进程可能会被阻塞几毫秒或更长时间，具体取决于驱动器当前的I/O负载。因此，调度程序应该可能在那时在CPU上安排另一个作业。</p><p>调度程序还必须在I/O完成时做出决定。发生这种情况时，会引发中断，并且操作系统会运行并将发出I/O请求的进程从阻塞状态(blocked back)移回就绪状态(ready state)。当然，它甚至可以决定在那时开展工作。操作系统应如何处理每个工作？</p><p>为了更好地理解这个问题，让我们假设有两个作业A和B，每个作业需要50ms的CPU时间。但有一个明显的区别：A运行10ms然后发出I/O请求（假设也许10ms），而B只使用CPU 50ms并且不执行I/O。调度程序首先运行A，然后运行B。</p><p><img src="/images/OSTEP/incorporatingIO78.png" alt></p><p><br></p><p>假设正在尝试构建STCF调度程序。显然，只运行一个工作然后运行另一个工作而不考虑I/O是没有意义的。</p><p>一种常见的方法是将A的每个10ms子作业视为独立工作。因此，当系统启动时，它的选择是是否安排10ms A或50ms B。使用STCF是明确的。当A的第一个子作业完成时，只剩下B，它开始运行。接着提交一个A的新子作业，它会抢占B并运行10ms。这样做允许重叠，一个进程在等待另一个进程的I/O完成时使用CPU，这样可以更好地利用该系统。</p><p><img src="/images/OSTEP/incorporatingIO79.png" alt></p><p><br></p><p>因此，我们看到调度程序如何合并I/O。通过将每个CPU突发视为作业，调度程序可确保<strong>交互(interactive)</strong>的进程进程运行。当这些交互式作业执行I/O时，其它CPU密集型作业会运行，从而更好地利用处理器。</p><p><br><br><br></p><h3 id="摘要-3"><a href="#摘要-3" class="headerlink" title="摘要"></a>摘要</h3><p>我们前面假设知道每个作业的长度，这可能是最糟糕的假设。实际上，在通用操作系统中，操作系统对每项工作的长度知之甚少。</p><p>我们介绍了调度背后的基本思想，并开发了两类方法。第一个运行剩余的最短作业，从而优化周转时间；第二个在所有作业之间交替运行，从而优化响应时间。两者都有好有坏，在系统中需要一个权衡。我们还看到了如何将I/O合并到调度中，但仍然没有解决操作系统基本无法看到未来的问题。<br>不久我们将通过构建一个使用最近过去预测未来的调度程序，来了解如何克服这个问题。此调度程序称为<strong>多级反馈队列(multi-level feedback queue)</strong>，它是下一章的主题。</p><p><br><br><br><br><br></p><h2 id="多级反馈队列"><a href="#多级反馈队列" class="headerlink" title="多级反馈队列"></a>多级反馈队列</h2><p><a href="http://pages.cs.wisc.edu/~remzi/OSTEP/cpu-sched-mlfq.pdf" target="_blank" rel="noopener">Scheduling: The Multi-Level Feedback Queue</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OS Three Easy Pieces: &lt;a href=&quot;https://book.douban.com/subject/19973015/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://book.douban.com/subject/19973015/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;OSTEP: &lt;a href=&quot;http://pages.cs.wisc.edu/~remzi/OSTEP/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://pages.cs.wisc.edu/~remzi/OSTEP/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ELRH7x86_64&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="Linux" scheme="https://zhang21.github.io/tags/Linux/"/>
    
      <category term="OperatingSystem" scheme="https://zhang21.github.io/tags/OperatingSystem/"/>
    
      <category term="操作系统" scheme="https://zhang21.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="Optimization" scheme="https://zhang21.github.io/tags/Optimization/"/>
    
      <category term="性能优化" scheme="https://zhang21.github.io/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Istio</title>
    <link href="https://zhang21.github.io/2019/04/26/Istio/"/>
    <id>https://zhang21.github.io/2019/04/26/Istio/</id>
    <published>2019-04-25T18:21:15.000Z</published>
    <updated>2019-04-26T06:18:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>Istio docs: <a href="https://istio.io/docs" target="_blank" rel="noopener">https://istio.io/docs</a></li><li>Istio中文文档: <a href="https://istio.io/zh/docs/" target="_blank" rel="noopener">https://istio.io/zh/docs/</a></li><li>Istio github: <a href="https://github.com/istio/istio" target="_blank" rel="noopener">https://github.com/istio/istio</a></li></ul><p><br></p><p>环境:</p><ul><li>RHEL7x86_64</li><li>Istio v1.1</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p><a href="https://istio.io/docs/concepts/" target="_blank" rel="noopener">Concepts</a></p><p><br></p><h2 id="Istio是什么"><a href="#Istio是什么" class="headerlink" title="Istio是什么"></a>Istio是什么</h2><p><a href="https://istio.io/docs/concepts/what-is-istio/" target="_blank" rel="noopener">What is Istio?</a></p><p>Istio允许您连接(connect)，保护(secure)，控制(control)和观察(observe)服务。<br>在较高的层级上，Istio有助于降低部署的复杂性，减轻开发团队的压力。它是一个完全开源的<strong>服务网格(service mesh)</strong>，可透明地分层到现有的分布式应用程序上。它也是一个平台，包括可以将其集成到任何日志记录平台或策略系统的API。Istio的多样化功能使你能够成功，高效地运行分布式微服务(microservice)架构，并提供安全，连接和监控微服务的统一方法。</p><p><br></p><h3 id="服务网格"><a href="#服务网格" class="headerlink" title="服务网格"></a>服务网格</h3><p>Service Mesh</p><p>Istio解决了开发人员和运营商在单片应用程序向分布式微服务架构过渡时所面临的挑战。有必要详细了解Istio服务网格。</p><p>术语服务网格用于描述构成此类应用程序的微服务网络以及它们之间的交互。随着服务网格的大小和复杂性的增加，理解和管理变得更加困难。其要求包括:</p><ul><li><strong>发现(discovery)</strong></li><li><strong>负载均衡(load balancing)</strong></li><li><strong>故障恢复(failure recovery)</strong></li><li><strong>指标(metrics)</strong></li><li><strong>监控(monitoring)</strong></li></ul><p>服务网格通常还具有更复杂的操作要求，如:</p><ul><li><strong>A/B测试</strong></li><li><strong>金丝片部署(canary rollouts)</strong></li><li><strong>速率限制(rate limiting)</strong></li><li><strong>访问控制(access control)</strong></li><li><em>*端到端认证()</em>end-to-end authentication*</li></ul><p>Istio作为一个整体提供对服务网格的行为洞察和操作控制。</p><p><br><br><br></p><h3 id="为什么使用它"><a href="#为什么使用它" class="headerlink" title="为什么使用它"></a>为什么使用它</h3><p>Why use Istio?</p><p>通过负载均衡，服务到服务的身份认证，监控…使用服务代码中很少或不需要更改代码，Istio可以轻松创建已部署的服务网格。通过在整个环境中部署特殊的sidecar代理来拦截服务的Istio支持，该代理拦截微服务之间的所有网络通信，然后使用其控制平面配置和管理Istio。包括:</p><ul><li>HTTP, gRPC, WebSocket, TCP流量的自动负载均衡；</li><li>通过丰富的路由规则，重试(retries)，故障转移(failovers)，故障注入(fault injection)，对流量欣慰 进行细粒度控制；</li><li>可插入的策略层和API配置，支持访问控制，速率限制和配额；</li><li>集群中所有流浪的自动度量、日志和追踪，包括集群的ingress, egress；</li><li>通过强大的基于身份的认证和授权，在鸡群中实现安全的服务到服务的通信。</li></ul><p><br><br><br></p><h3 id="核心功能"><a href="#核心功能" class="headerlink" title="核心功能"></a>核心功能</h3><p>Core features</p><p><br></p><h4 id="流量管理"><a href="#流量管理" class="headerlink" title="流量管理"></a>流量管理</h4><p>Traffic management</p><p>通过Istio简单的规则配置和流量路由，你可以控制服务之间的流量和API调用。它简化了服务级别的属性配置，如熔断器(circuit breakers)，超时(timeouts)，重试(retries)，并且可以轻松设置A/B测试，金丝片部署(canary rollouts)，基于百分比流量分割的分阶段部署等重要任务。</p><p>通过更好地了解流量和开箱即用的故障恢复功能，你可在问题出现之前发现问题，使调用更加可靠、网络更加强大。</p><p><br><br><br></p><h4 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h4><p>Security</p><p>Istio的安全功能使开发人员可以更加专注于应用程序级别的安全性。Istio提供了底层安全通信信道，并大规模管理服务通信的认证、授权和加密。使用Istio，服务通信在默认情况下是安全的，允许你跨多种协议和运行时一致地实施策略。所有这些基本都不用对应用程序进行更改。</p><p>虽然Istio与平台无关，但与k8s网络策略一起使用时，其优势更大，包括在网络层和应用层保护<code>pod-to-pod</code>或<code>service-to-service</code>通信的能力。</p><p><br><br><br></p><h4 id="可观察性"><a href="#可观察性" class="headerlink" title="可观察性"></a>可观察性</h4><p>Observability</p><p>Istio强大的追踪、监控和日志记录功能可以让你更深入了解服务网格部署。通过Istio的监控功能，真正了解服务性能如何影响上下游(upstream, downstream)的功能，而其自定义的仪表盘可提供对所有服务性能的可视性，并让你了解该性能如何影响你的其他进程。</p><p>Istio的<strong>混合器（Mixer)</strong>组件负责策略控制和遥测收集。它提供后端抽象和中间媒介，将Istio的其余部分与各个基础架构后端的实现细节隔离开来，并为运营商提供对网格网络和基础架构后端之间所有交互的细粒度控制。</p><p>这些功能使你可以更有效地设置，监控和实施服务上的SLOs。当然，最重要的是，你可以快速有效地检测和修复问题。</p><p><br><br><br></p><h4 id="平台支持"><a href="#平台支持" class="headerlink" title="平台支持"></a>平台支持</h4><p>Platform support</p><p>Istio是独立于平台的，旨在各种环境中运行。包括跨云，内在部署，k8s，Mesos…<br>你可在k8s上部署Istio，或在带有Nomad的Consul上部署它。Istio目前支持:</p><ul><li>Service deployment on Kubernetes</li><li>Services registered with Consul</li><li>Services running on individual virtual machines</li></ul><p><br><br><br></p><h4 id="集成和自定义"><a href="#集成和自定义" class="headerlink" title="集成和自定义"></a>集成和自定义</h4><p>Integration and customization</p><p>可以扩展和自定义Istio的策略实施组件，来与现有的ACL，日志记录，监控，配额，审计等方案集成。</p><p><br><br><br></p><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>Architecture</p><p>Istio服务网格逻辑上分为<strong>数据平面(data plane)</strong>和<strong>控制平面(data plane)</strong>。</p><ul><li>数据平面由一组以 sidecar 方式部署的<strong>智能代理(Envoy)</strong>组成。这些代理可以调节和控制微服务及Mixer之间所有的网络通信。</li><li>控制平面负责管理和配置代理来路由流量。此外控制平面配置Mixer以实施策略和收集遥测数据。</li></ul><p><img src="images/Istio/arch.svg" alt></p><p><br></p><h4 id="Envoy"><a href="#Envoy" class="headerlink" title="Envoy"></a>Envoy</h4><p>Istio使用<strong>Envoy</strong>代理的扩展版本，Envoy是以<code>C++</code>开发的高性能代理，用于调解服务网格中所有服务的所有入站和出站流量。<br>Envoy 的许多内置功能被 Istio 发扬光大，如:</p><ul><li>动态服务发现(Dynamic service discovery)</li><li>负载均衡(Load balancing)</li><li>TLS termination</li><li>HTTP/2 and gRPC proxies</li><li>熔断器(Circuit breakers)</li><li>健康检查(Health checks)</li><li>基于百分比流量拆分的灰度发布</li><li>故障注入(Fault injection)</li><li>丰富的度量指标(Rich metrics)</li></ul><p>Envoy 被部署为 sidecar，和对应服务在同一个 k8s pod 中。这允许 Istio 将大量关于流量行为的信号作为属性提取出来，而这些属性又可以在 Mixer 中用于执行策略决策，并发送给监控系统，以提供整个网格行为的信息。<br>Sidecar 代理模型还可以将 Istio 的功能添加到现有部署中，而无需重新构建或重写代码。</p><p><br><br><br></p><h4 id="Mixer"><a href="#Mixer" class="headerlink" title="Mixer"></a>Mixer</h4><p><strong>Mixer</strong> 是一个独立于平台的组件，负责在服务网格上执行访问控制和使用策略，并从 Envoy 代理和其他服务收集遥测数据。代理提取请求级属性，发送到 Mixer 进行评估。</p><p>Mixer 中包括一个灵活的插件模型，使其能够接入到各种主机环境和基础设施后端，从这些细节中抽象出 Envoy 代理和 Istio 管理的服务。</p><p><br><br><br></p><h4 id="Pilot"><a href="#Pilot" class="headerlink" title="Pilot"></a>Pilot</h4><p><strong>Pilot</strong> 为 Envoy sidecar 提供服务发现功能，为智能路由（如 A/B测试、金丝雀部署）和弹性（超时、重试、熔断器）提供流量管理功能。</p><p>它将控制流量行为的高级路由规则转换为特定于 Envoy 的配置，并在运行时将它们传播到 sidecar。Pilot 将平台特定的服务发现机制抽象化并将其合成为符合 Envoy 数据平面 API 的任何 sidecar 都可以使用的标准格式。这种松散耦合使得 Istio 能够在多种环境下运行（如 k8s、Consul、Nomad），同时保持用于流量管理的相同操作界面。</p><p><br><br><br></p><h4 id="Citadel"><a href="#Citadel" class="headerlink" title="Citadel"></a>Citadel</h4><p><strong>Citadel</strong> 通过内置身份和凭证管理赋能强大的服务间和最终用户身份验证。可用于升级服务网格中未加密的流量，并为运维人员提供基于服务标识而不是网络控制的强制执行策略的能力。</p><p><br><br><br></p><h4 id="Galley"><a href="#Galley" class="headerlink" title="Galley"></a>Galley</h4><p><strong>Galley</strong> 代表其他的 Istio 控制平面组件，用来验证用户编写的 Istio API 配置。随着时间的推移，Galley 将接管 Istio 获取配置、 处理和分配组件的顶级责任。它将负责将其他的 Istio 组件与从底层平台(如k8s)获取用户配置的细节中隔离开来。</p><p><br><br><br></p><h3 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h3><p>Design Goals</p><p>Istio的架构设计中有几个关键目标，这些目标对于使系统能够应对大规模流量和高性能地服务处理至关重要。</p><ul><li>最大化透明度(Maximize Transparency)</li><li>可扩展性(Extensibility)</li><li>可移植性(Portability)</li><li>策略一致性(Policy Uniformity)</li></ul><p><br><br><br><br><br></p><h2 id="流量管理-1"><a href="#流量管理-1" class="headerlink" title="流量管理"></a>流量管理</h2><p><a href="https://istio.io/docs/concepts/traffic-management/" target="_blank" rel="noopener">Traffic Management</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Istio docs: &lt;a href=&quot;https://istio.io/docs&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://istio.io/docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Istio中文文档: &lt;a href=&quot;https://istio.io/zh/docs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://istio.io/zh/docs/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Istio github: &lt;a href=&quot;https://github.com/istio/istio&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/istio/istio&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RHEL7x86_64&lt;/li&gt;
&lt;li&gt;Istio v1.1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="k8s" scheme="https://zhang21.github.io/tags/k8s/"/>
    
      <category term="Service Mesh" scheme="https://zhang21.github.io/tags/Service-Mesh/"/>
    
      <category term="Microservice" scheme="https://zhang21.github.io/tags/Microservice/"/>
    
      <category term="微服务" scheme="https://zhang21.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="服务网格" scheme="https://zhang21.github.io/tags/%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC/"/>
    
  </entry>
  
  <entry>
    <title>CuckooSandbox</title>
    <link href="https://zhang21.github.io/2019/04/16/CuckooSandbox/"/>
    <id>https://zhang21.github.io/2019/04/16/CuckooSandbox/</id>
    <published>2019-04-16T07:25:45.000Z</published>
    <updated>2019-04-17T01:14:42.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>github: <a href="https://github.com/cuckoosandbox/cuckoo" target="_blank" rel="noopener">https://github.com/cuckoosandbox/cuckoo</a></li><li>docs: <a href="https://cuckoo.sh/docs/" target="_blank" rel="noopener">https://cuckoo.sh/docs/</a></li></ul><p><br></p><p>环境:</p><ul><li>REL7x86_64</li><li>Cuckoo v2.0.6</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p><a href="https://cuckoo.sh/docs/introduction/index.html" target="_blank" rel="noopener">Introduction</a></p><p>本章节介绍 Cuckoo Sandbox。它解释了一些基本的恶意软件(malware)分析概念，什么是CuckooSanbox以及它如何适应恶意软件分析。</p><p><br><br><br></p><h2 id="沙箱"><a href="#沙箱" class="headerlink" title="沙箱"></a>沙箱</h2><p><a href="https://cuckoo.sh/docs/introduction/sandboxing.html" target="_blank" rel="noopener">Sandboxing</a></p><p>如维基百科所定义，“在计算机安全中，沙箱是一种用于分离正在运行的程序的安全机制。它通常用于执行未经验证的代码，或来自未经验证的第三方、供应商、不受信任的用户或网站或程序。”</p><p>这个概念也适用于恶意软件分析的沙箱：我们的目标是在隔离的环境中运行位置和不受信任的应用程序或文件，并获取有关它的功能的信息。</p><p>恶意软件沙箱是动态分析方法的实际应用：它不是静态分析二进制文件，而是实事执行和监视。</p><p>这种方法显然有利有弊，但它获取有关恶意软件的其它详细信息的有价值的技术(如网络行为)。因此，在检查恶意软件时执行<strong>静态分析</strong>(static)和<strong>动态分析</strong>(dynamic analysis)是一种很好的做法，以便更深入地了解它。</p><p>简单来说，Cuckoo是一个允许你执行沙箱恶意软件分析的工具。</p><p><br><br><br></p><h3 id="使用沙箱"><a href="#使用沙箱" class="headerlink" title="使用沙箱"></a>使用沙箱</h3><p>在考虑安装、配置和使用Cuckoo之前，你应该花时间考虑一下你希望用它实现什么功能，以及如何实现。</p><p>你应该考虑的一些问题:</p><ul><li>我想分析那种文件？</li><li>我希望能够处理多少分析？</li><li>我想用哪个平台来运行我的分析？</li><li>我想要关于文件的哪些信息？</li></ul><p>隔离环境(如虚拟机)的创建时沙箱部署中最关键和最重要的部分：应该仔细进行并进行适当的规划。</p><p><br></p><p>在掌握你选择的虚拟化产品之前，你应该已经有一个设计的计划:</p><ul><li>使用哪种操作系统(os)、语言(language)和修补(patching)级别；</li><li>要安装哪个软件和版本。</li></ul><p><br></p><p>考虑到自动恶意软件(malware)分析不是确定性的，它的成功可能取决于很多因素：你试图在虚拟化系统中运行恶意软件，就像在本机系统上运行一样，这可能很难实现，并且可能并不总是如此成功。你的目标应该是创建一个能够满足你所有要求的系统，并尽可能使其尽可能真实。</p><p>例如，你可以考虑留下一些正常使用的故意的痕迹(如历史记录、Cookie、文档、图像…)。如果恶意软件旨在操作、操纵、窃取此类文件，你将能够注意到它。</p><p>虚拟化操作系统通常带有很多痕迹，使它们容易被检测到。即使你不应高估此问题，也可能需要处理此问题并尝试因此尽可能多的虚拟化跟踪。互联网上有很多关于虚拟化检测技术和对策的文献。</p><p>完成设计和准备所需系统原型后，你可以继续创建并部署它。你将总是及时改变或略微修复它们，但要记住，一开始的良好规划意味着从长远来看减少麻烦。</p><p><br><br><br><br><br></p><h2 id="Cuckoo是什么"><a href="#Cuckoo是什么" class="headerlink" title="Cuckoo是什么"></a>Cuckoo是什么</h2><p><a href="https://cuckoo.sh/docs/introduction/what.html" target="_blank" rel="noopener">What is Cuckoo</a></p><p>Cuckoo是一个开源的自动恶意软件分析系统。<br>它用于自动运行和分析文件，并收集全面的分析结果，概述恶意软件在隔离操作系统内运行时的作用。</p><p><br><br><br></p><h3 id="用例"><a href="#用例" class="headerlink" title="用例"></a>用例</h3><p>Use Cases</p><p>由于其机极为模块化的设计，Cuckoo既可以作为独立应用程序使用，也可以集成到更大的框架中。</p><p>它可用来分析:</p><ul><li>通用Windows EXE可执行文件</li><li>DLL文件</li><li>PDF文档</li><li>MS OFFICE文档</li><li>URLs和HTML文件</li><li>PHP脚本</li><li>CPL文件</li><li>VB脚本</li><li>ZIP文件</li><li>Python文件</li><li>Almost anything else</li></ul><p>由于其模块化和强大的脚本功能，使用Cuckoo可实现的目标没有限制。</p><p><br><br><br></p><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>Architecture</p><p>Cuckoo Sandbox由一个处理样本执行(Execution)和分析(Analysis)的中央管理软件组成。</p><p>每个分析都在一个新的和隔离的虚拟(物理)机器中启动。Cuckoo架构的主要组件是<strong>Host machine</strong>(管理软件)和许多<strong>Guest machines</strong>(用于分析的虚拟机或物理机)。<br>Host运行整个沙箱的分析进程的核心组件，而Guest是实际执行和分析恶意软件样本的隔离环境。</p><p><br></p><p>Cuckoo的主要架构图:</p><p><img src="/images/Cuckoo/architecture-main.png" alt></p><p><br><br><br></p><h3 id="获取Cuckoo"><a href="#获取Cuckoo" class="headerlink" title="获取Cuckoo"></a>获取Cuckoo</h3><p>Obtaining Cuckoo</p><p>虽然可以从官网上下载Cuckoo，也可从github下载，但还是建议使用<code>pip</code>安装。</p><p><br><br><br><br><br></p><h2 id="许可证"><a href="#许可证" class="headerlink" title="许可证"></a>许可证</h2><p><a href="https://cuckoo.sh/docs/introduction/license.html" target="_blank" rel="noopener">License</a></p><p>Cuckoo Foundation是一家非盈利组织，在荷兰成立，主要致力于支持开源的恶意软件分析系统Cuckoo Sandbox以及周边项目和计划的开发和发展。</p><p>该基金会致力于为软件项目提供财务和基础设施支持，并协调社区的发展和贡献。</p><p><br><br><br><br><br></p><h2 id="社区准则"><a href="#社区准则" class="headerlink" title="社区准则"></a>社区准则</h2><p><a href="https://cuckoo.sh/docs/introduction/community.html" target="_blank" rel="noopener">Community guidelines</a></p><p>Cuckoo Sandbox是一个开源项目，我们感谢任何形式的贡献。这些指南旨在帮助你和我们尽快回答问题、解决问题和合并代码。所以，你正在阅读的这些指南是很棒的！</p><p><br><br><br></p><h3 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h3><p>这些指南有:</p><ul><li>创建Issue要包含的内容<ul><li>Reporting bugs/errors/unexpected behavior</li><li>Feature suggestions/requests</li></ul></li><li>Contributing code/documentation</li></ul><p><br><br><br></p><hr><p><br><br><br></p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p><a href="https://cuckoo.sh/docs/installation/index.html" target="_blank" rel="noopener">Installation</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;github: &lt;a href=&quot;https://github.com/cuckoosandbox/cuckoo&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/cuckoosandbox/cuckoo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;docs: &lt;a href=&quot;https://cuckoo.sh/docs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://cuckoo.sh/docs/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;REL7x86_64&lt;/li&gt;
&lt;li&gt;Cuckoo v2.0.6&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="Test" scheme="https://zhang21.github.io/tags/Test/"/>
    
      <category term="Cuckoo" scheme="https://zhang21.github.io/tags/Cuckoo/"/>
    
      <category term="Sandbox" scheme="https://zhang21.github.io/tags/Sandbox/"/>
    
      <category term="Security" scheme="https://zhang21.github.io/tags/Security/"/>
    
      <category term="DynamicAnalysis" scheme="https://zhang21.github.io/tags/DynamicAnalysis/"/>
    
      <category term="MalwareAnalysis" scheme="https://zhang21.github.io/tags/MalwareAnalysis/"/>
    
  </entry>
  
  <entry>
    <title>OpenShift</title>
    <link href="https://zhang21.github.io/2019/03/26/OpenShift/"/>
    <id>https://zhang21.github.io/2019/03/26/OpenShift/</id>
    <published>2019-03-26T09:50:11.000Z</published>
    <updated>2019-03-26T09:46:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>Wikipedia</li><li>OpenShift docs: <a href="https://docs.openshift.com" target="_blank" rel="noopener">https://docs.openshift.com</a></li></ul><p><br></p><p>环境:</p><ul><li>RHELx86_64</li><li>OpenShift v3.11</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wikipedia&lt;/li&gt;
&lt;li&gt;OpenShift docs: &lt;a href=&quot;https://docs.openshift.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://docs.openshift.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RHELx86_64&lt;/li&gt;
&lt;li&gt;OpenShift v3.11&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="OpenShift" scheme="https://zhang21.github.io/tags/OpenShift/"/>
    
      <category term="PaaS" scheme="https://zhang21.github.io/tags/PaaS/"/>
    
      <category term="DevOps" scheme="https://zhang21.github.io/tags/DevOps/"/>
    
  </entry>
  
  <entry>
    <title>ZooKeeper</title>
    <link href="https://zhang21.github.io/2019/03/15/ZooKeeper/"/>
    <id>https://zhang21.github.io/2019/03/15/ZooKeeper/</id>
    <published>2019-03-15T08:57:20.000Z</published>
    <updated>2019-03-18T03:24:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li><li>ZooKeeper: <a href="https://zookeeper.apache.org/" target="_blank" rel="noopener">https://zookeeper.apache.org/</a></li><li>Docs: <a href="https://zookeeper.apache.org/doc/" target="_blank" rel="noopener">https://zookeeper.apache.org/doc/</a></li></ul><p>环境:</p><ul><li>RHEL7x86_64</li><li>ZooKeeper v3.5</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p><img src="/images/ZooKeeper/zookeeper_logo.jpg" alt></p><p><br></p><p>ZooKeeper: Because Coordinating Distributed Systems is a Zoo.</p><p><strong>Apache ZooKeeper</strong> 是Apache软件基金会的一个软件项目，它为大型分布式计算提供开源的分布式配置服务、同步服务和命名注册，实现高度可靠的分布式协调。ZooKeeper曾经是Hadoop的一个子项目，但现在是一个独立的顶级项目。</p><p>ZooKeeper 是一种集中式服务，用于维护<strong>配置信息</strong>(conf info)，<strong>命名</strong>(naming)，<strong>分布式同步</strong>(distributed synchronization)，<strong>组服务</strong>(group service)。所有这些类型的服务都以分布式应用程序的某种形式应用。每次实施它们都需要做很多工作来修复不可避免的错误和竞争条件。由于难以实现这些类型的服务，应用程序最初通常会吝啬它们，这使得它们在变化的情况下变得脆弱并且难以管理。即使正确完成，这些服务的不同实现也会在部署应用程序时导致管理复杂性。</p><p><strong>ZooKeeper的架构通过冗余服务实现高可用性</strong>。因此，如果第一次无应答，客户端就可以询问另一台ZooKeeper主机。ZooKeeper节点将它们的数据存储于一个分层的命名空间，非常类似于一个文件系统或一个前缀树结构。客户端可以在节点读写，从而以这种方式拥有一个共享的配置服务。更新是全序的。</p><p><br></p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p><a href="https://zookeeper.apache.org/doc/r3.5.4-beta/zookeeperOver.html" target="_blank" rel="noopener">ZooKeeper: A Distributed Coordination Service for Distributed Applications</a></p><p>ZooKeeper 是一种用于分布式应用程序的分布式开源协调(coordination)服务。它被设计为易于编程，并使用在熟悉的文件系统目录树结构之后设计的数据模型。它在Java中运行，并具有Java和C的绑定。</p><p>众所周知，协调服务很难做到。他们特别容易出现竞赛条件(race conditions)和死锁(deadlock)。ZooKeeper背后的动机是减轻分布式应用程序从头开始实施协调服务的责任。</p><p><br></p><h3 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h3><p>Design Goals</p><ul><li><strong>ZooKeeper is simple</strong></li></ul><p>ZooKeeper允许分布式进程通过 <strong>共享的层级命名空间</strong>(shared hierarchal namespace) 相互协调，该命名空间的组织方式与标准文件系统类似。命名空间由 <strong>数据寄存器</strong>(data registers) 组成——在ZooKeeper用语中被称为 <code>znodes</code>，这些与文件和目录类似。与专为存储而设计的典型文件系统不同，ZooKeeper数据保存在内存中，这意味着ZooKeeper可以实现高吞吐量(high throughput)和低延迟数(latency numbers)。</p><p>ZooKeeper的实现非常重视 <strong>高性能(high performance)</strong>， <strong>高可用(highly available)</strong>， <strong>严格有序的访问(strictly ordered access)</strong>。性能方面意味着它可以在大型分布式系统中使用。可靠性方面使其不会成为单点故障(a single point of failure)。严格的排序意味着可以在客户端实现复杂的同步原语。</p><p><br></p><ul><li><strong>ZooKeeper is replicated</strong></li></ul><p>与它协调的分布式进程一样，ZooKeeper本身也可以在称为 <strong>集合(ensemble)</strong> 的一组主机上进行 副本复制(replicated)。</p><p><img src="/images/ZooKeeper/zkservice.jpg" alt></p><p>组成ZooKeeper服务的Server必须了解彼此。它们维护一个内存中的状态镜像，以及持久性存储的事务日志和快照。只要大多数Servers可用，ZooKeeper服务就可用。</p><p>Client连接到单个Server。Client维护TCP连接，通过该连接发送请求，获取响应，获取监视事件(watch events)，以及发送心跳(heart beats)。如果与Server的TCP连接中断，则Client将连接到其它Server。</p><p><br></p><ul><li><strong>ZooKeeper is ordered</strong></li></ul><p>ZooKeeper使用反映所有ZooKeeper事务顺序的数字标记每个更新。后续操作可以使用该顺序来实现更高级别的抽象，例如同步原语。</p><p><br></p><ul><li><strong>ZooKeeper is fast</strong></li></ul><p>它在读取 <code>read-doninant</code> 工作负载中特别快。ZooKeeper应用程序运行在成千上万的计算机上，并且在读取别写入更常见的情况下(比率<code>10:1</code>)表现最佳。</p><p><br><br><br></p><h3 id="数据模型和分层命名空间"><a href="#数据模型和分层命名空间" class="headerlink" title="数据模型和分层命名空间"></a>数据模型和分层命名空间</h3><p>Data model and the hierarchical namespace</p><p>ZooKeeper提供的命名空间非常类似于标准文件系统。名称是由斜杠(<code>/</code>)分隔的路径元素序列。ZooKeeper命名空间中的每个节点都由路径标识。</p><p><img src="/images/ZooKeeper/zknamespace.jpg" alt></p><p><br><br><br></p><h3 id="节点和短暂节点"><a href="#节点和短暂节点" class="headerlink" title="节点和短暂节点"></a>节点和短暂节点</h3><p>Nodes and ephemeral nodes</p><p>与标准文件系统不同，ZooKeeper命名空间中的每个节点都可包含与之关联的数据以及孩子。这就像拥有一个允许文件也是目录的文件系统。ZooKeeper旨在存储协调数据：状态信息，配置，位置信息等，因此存储在每个节点的数据通常很小。我们使用术语 <strong>znode</strong> 来表明我们正在谈论的ZooKeeper数据节点。</p><p>Znodes 维护一个 <strong>状态结构(stat structure)</strong>，其中包括数据更改、ACL更改、时间戳更改，以允许缓存验证和协调更新。每次znode的数据更改时，版本号都会增加。例如，每当Client检索数据时，它也接收数据的版本。</p><p>存储在每个znode命名空间中的数据以原子(atomically)方式进行读写。读取与znode关联的所有数据字节，写入替换所有的数据。每个节点都有一个ACL限制谁可以做什么。</p><p>ZooKeeper也有 <strong>短暂节点(ephemeral nodes)</strong> 的概念。只要创建的znode处于活动状态，就会存在这些znode，回话结束时，znode将被删除。当你想要实现 <code>[tbd]</code> 时，短暂节点很有用。</p><p><br><br><br></p><h3 id="协调更新和监视"><a href="#协调更新和监视" class="headerlink" title="协调更新和监视"></a>协调更新和监视</h3><p>Conditional updates and watches</p><p>ZooKeeper支持监视(watch)的概念。Client可以在znode上设置监视。当znode更改时，将触发并删除监视。触发监视时，Client会受到一个数据包，指出znode已更改。如果Client与其中一个ZooKeeper Server之间的连接中断，则Client将收到本地通知。这可以用于 <code>[tbd]</code> 。</p><p><br><br><br></p><h3 id="保证"><a href="#保证" class="headerlink" title="保证"></a>保证</h3><p>Guarantees</p><p>ZooKeeper非常快速和简单。但是，由于基于目标是构建更复杂的服务(如同步)的基础，因此它提供了一系列保证。这些是:</p><ul><li><strong>顺序一致性(Sequential Consistency)</strong>: Client的更新将按发送顺序来应用</li><li><strong>原子性(Atomicity)</strong>: 更新成功或失败，没有其它结果</li><li><strong>单系统镜像(Single System Image)</strong>: 无论连接到哪个Server，Client都将看到相同的服务视图</li><li><strong>可靠性(Reliability)</strong>: 一旦更新被应用，它将从该时间开始持续，知道Client覆盖此更新</li><li><strong>时宜性(Timeliness)</strong>: 系统的Client视图保证在特定的时间范围内是最新的</li></ul><p><br><br><br></p><h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><p>ZooKeeper的设计目标之一是提供非常简单的编程接口。因此，它仅支持以下操作:</p><ul><li>create: creates a node at a location in the tree</li><li>delete: deletes a node</li><li>exists: tests if a node exists at a location</li><li>get data: reads the data from a node</li><li>set data: writes data to a node</li><li>get children: retrieves a list of children of a node</li><li>sync: waits for data to be propagated</li></ul><p><br><br><br></p><h3 id="执行"><a href="#执行" class="headerlink" title="执行"></a>执行</h3><p>Implementation</p><p>ZooKeeper组件显示了ZooKeeper服务的高级组件。除了请求处理器，构成ZooKeeper服务的每个Server都复制自己每个组件的副本。</p><p><img src="/images/ZooKeeper/zkcomponents.jpg" alt></p><ul><li>副本数据库是一个包含整个数据树的内存数据库。更新将记录到磁盘以获得可恢复性，并且在写入内存数据库之前会序列化的磁盘</li><li>每个ZooKeeper Server都为Client服务。Client只连接到一台Server以提交请求。读取请求由每个Server数据库的本地副本提供。更改服务状态的请求，写请求由 协定协议(agreement protocol) 处理</li><li>作为协定协议的一部分，来自Client的所有写入请求都被转发到称为 <strong>leader</strong> 的单个Server。其余的ZooKeeper Server，称为<strong>follower</strong>，接收来自<strong>leader</strong>的消息提议并同意消息传递。消息传递层负责替换失败的leader，并将follower与leader同步</li><li>ZooKeeper使用自定义的原子消息(atomic messaging)协议。由于消息传递层是原子的，因此ZooKeeper可以保证本地副本永远不会发散。当leader收到写入请求时，它会计算应用写入时系统的状态，并将其转换为捕获此新状态的事务。</li></ul><p><br><br><br></p><h3 id="用户"><a href="#用户" class="headerlink" title="用户"></a>用户</h3><p>ZooKeeper的编程接口非常简单。但是，通过它，您可以实现更高阶的操作，例如同步原语，组成员身份，所有权等。</p><p><br><br><br></p><h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><p>Performance</p><p>ZooKeeper旨在提供高性能。在读取数量超过写入的应用程序中，它的性能尤其高，因为写入涉及同步所有Server的状态。</p><p><img src="/images/ZooKeeper/zkperfRW.jpg" alt></p><p>The events marked in the figure are the following:</p><ul><li>Failure and recovery of a follower</li><li>Failure and recovery of a different follower</li><li>Failure of the leader</li><li>Failure and recovery of two followers</li><li>Failure of another leader</li></ul><p><br><br><br><br><br></p><h2 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h2><p><a href="https://zookeeper.apache.org/doc/r3.5.4-beta/zookeeperStarted.html" target="_blank" rel="noopener">ZooKeeper Getting Started Guide</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;li&gt;ZooKeeper: &lt;a href=&quot;https://zookeeper.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://zookeeper.apache.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Docs: &lt;a href=&quot;https://zookeeper.apache.org/doc/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://zookeeper.apache.org/doc/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RHEL7x86_64&lt;/li&gt;
&lt;li&gt;ZooKeeper v3.5&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="Apache" scheme="https://zhang21.github.io/tags/Apache/"/>
    
      <category term="DataAnalysis" scheme="https://zhang21.github.io/tags/DataAnalysis/"/>
    
      <category term="ZooKeeper" scheme="https://zhang21.github.io/tags/ZooKeeper/"/>
    
  </entry>
  
  <entry>
    <title>HBase</title>
    <link href="https://zhang21.github.io/2019/03/15/HBase/"/>
    <id>https://zhang21.github.io/2019/03/15/HBase/</id>
    <published>2019-03-15T02:57:20.000Z</published>
    <updated>2019-03-15T09:00:17.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li><li>HBase: <a href="https://hbase.apache.org/" target="_blank" rel="noopener">https://hbase.apache.org/</a></li><li>Reference Guide: <a href="http://hbase.apache.org/book.html" target="_blank" rel="noopener">http://hbase.apache.org/book.html</a></li></ul><p>环境:</p><ul><li>RHEL7x86_64</li><li>HBase v3.0</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p><img src="/images/HBase/hbase_logo.png" alt></p><p><br></p><p><strong>Apache HBase</strong> 是Hadoop数据库，是一个分布式(distributed)，可扩展(scalable)的大数据存储。</p><p>当你需要对大数据进行随机(random)，实时(realtime)R/W访问时，请使用Apache HBase。它的目标是在硬件集群上托管非常大的表——数十亿行数百万列。</p><p>HBase是一个开源的非关系型分布式数据库（NoSQL），它参考了谷歌的BigTable建模，实现的编程语言为 Java。它是Apache软件基金会的Hadoop项目的一部分，运行于HDFS文件系统之上，为 Hadoop 提供类似于BigTable 规模的服务。因此，它可以对稀疏文件提供极高的容错率。</p><p>HBase在列上实现了BigTable论文提到的压缩算法、内存操作和布隆过滤器。HBase的表能够作为MapReduce任务的输入和输出，可以通过Java API来访问数据，也可以通过REST、Avro或者Thrift的API来访问。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h1><p>Features</p><ul><li>线性和模块化可扩展性</li><li>严格一致的读写操作</li><li>表的自动和可配置分片</li><li>支持RegionServers之间的自动故障转移</li><li>方便的基类，用于使用Apache HBase表支持Hadoop MapReduce作业</li><li>易于使用的Java API，用于客户端访问</li><li>阻止缓存和bloom过滤器以进行实时查询</li><li>Query predicate push down via server side Filters</li><li>Thrift gateway和REST-ful Web service，支持XML， Protobuf， binary data encoding</li><li>可扩展的基于JRuby的（JIRB）shell</li><li>支持通过Hadoop Metrics子系统将指标导出到文件或其它</li><li>…</li></ul><p><br><br><br></p><hr><p><br><br><br></p><h1 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h1><p>Getting Started</p><p><br></p><h2 id="Standalone-HBase"><a href="#Standalone-HBase" class="headerlink" title="Standalone HBase"></a>Standalone HBase</h2><p>本节介绍在单节点的standalone实例上运行HBase。<strong>Standalone instance</strong> 包含了所有的<strong>HBase Daemons(Master, RegionServers, Zookeeper)</strong>，在单个JVM中运行并持久化到本地文件系统。这是一个最基本的配置，将展示如何使用HBase shell CLI在HBase中创建表、在表中插入行、对表执行放置和扫描操作、启用/禁用表、启动和停止HBase。</p><p><br></p><h3 id="JDK"><a href="#JDK" class="headerlink" title="JDK"></a>JDK</h3><p>HBase要求安装JDK。</p><p><br><br><br></p><h3 id="使用HBase"><a href="#使用HBase" class="headerlink" title="使用HBase"></a>使用HBase</h3><p>步骤:</p><ul><li>下载</li><li>配置</li><li>启动</li><li>使用</li><li>停止</li></ul><p><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"># 访问Apache DownLoad Mirrors，下载对应版本HBase</span><br><span class="line"># https://www.apache.org/dyn/closer.lua/hbase/</span><br><span class="line">cd opt</span><br><span class="line">wget http://mirror.bit.edu.cn/apache/hbase/3.0.0/hbase-3.0.0-bin.tar.gz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 解压</span><br><span class="line">tar xzvf hbase-3.0.0-SNAPSHOT-bin.tar.gz</span><br><span class="line">mv hbase-3.0.0-SNAPSHOT hbase</span><br><span class="line">cd hbase</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 启动前必须先设置JAVA_HOME环境变量</span><br><span class="line"># conf/hbase-env.sh</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_191-amd64</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 编辑conf/hbase-site.xml，这是主要的HBase配置文件</span><br><span class="line"># 您需要在本地文件系统上指定HBase和ZooKeeper写入数据并确认一些风险的目录</span><br><span class="line"># 栗子</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;file:///home/testuser/hbase&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/home/testuser/zookeeper&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">      Controls whether HBase will check for stream capabilities (hflush/hsync).</span><br><span class="line"></span><br><span class="line">      Disable this if you intend to run on LocalFileSystem, denoted by a rootdir</span><br><span class="line">      with the &apos;file://&apos; scheme, but be mindful of the NOTE below.</span><br><span class="line"></span><br><span class="line">      WARNING: Setting this to false blinds you to potential data loss and</span><br><span class="line">      inconsistent system state in the event of process and/or node failures. If</span><br><span class="line">      HBase is complaining of an inability to use hsync or hflush it&apos;s most</span><br><span class="line">      likely not a false positive.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># start a standalone instance of HBase</span><br><span class="line"># 一个JVM运行 HMaster, HRegionServer, Zookeeper</span><br><span class="line">bin/start-hbase.sh</span><br><span class="line"></span><br><span class="line"># http://localhost:16010 查看HBase Web UI</span><br></pre></td></tr></table></figure><p><br></p><p>你不需要创建HBase数据目录，它会自动做这件事。如果你创建目录，HBase将尝试进行迁移，这不是你想要的。</p><p>要在现有的HDFS实例上安装HBase，请将 <code>hbase.rootdir</code> 设置为指向实例上的目录(如: <code>hdfs://namenode.example.org:8020/hbase</code>)。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用hbase shell命令连接到HBase</span></span><br><span class="line">/bin/hbase shell</span><br><span class="line">xxxx</span><br><span class="line">xxxx</span><br><span class="line">2.3.7 :001 &gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示帮助</span></span><br><span class="line">&gt; <span class="built_in">help</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建表，你必须指定 Table name和ColumnFamily name</span></span><br><span class="line">&gt; create <span class="string">'t-test'</span>, <span class="string">'c-test'</span></span><br><span class="line">Took 1.7627 seconds</span><br><span class="line"> =&gt; Hbase::Table - t-test</span><br><span class="line"><span class="comment"># 也可在Web UI上查看相关信息</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出表信息</span></span><br><span class="line">&gt; list <span class="string">'c-test'</span></span><br><span class="line">TABLE</span><br><span class="line">t-test</span><br><span class="line">1 row(s)</span><br><span class="line">Took 0.0520 seconds</span><br><span class="line"> =&gt; [<span class="string">"t-test"</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; describe <span class="string">'t-test'</span></span><br><span class="line">Table t-test is ENABLED</span><br><span class="line">t-test</span><br><span class="line">COLUMN FAMILIES DESCRIPTION</span><br><span class="line">&#123;NAME =&gt; <span class="string">'c-test'</span>, VERSIONS =&gt; <span class="string">'1'</span>, EVICT_BLOCKS_ON_CLOSE =&gt; <span class="string">'false'</span>, NEW_VERSION_BEHAVIOR =&gt; <span class="string">'false'</span>, KEEP_DELETED_CELLS =&gt; <span class="string">'FALSE'</span>, CACHE_DATA_ON_WRITE =&gt; <span class="string">'false'</span>, DATA_BLOCK_ENCODING</span><br><span class="line">=&gt; <span class="string">'NONE'</span>, TTL =&gt; <span class="string">'FOREVER'</span>, MIN_VERSIONS =&gt; <span class="string">'0'</span>, REPLICATION_SCOPE =&gt; <span class="string">'0'</span>, BLOOMFILTER =&gt; <span class="string">'ROW'</span>, CACHE_INDEX_ON_WRITE =&gt; <span class="string">'false'</span>, IN_MEMORY =&gt; <span class="string">'false'</span>, CACHE_BLOOMS_ON_WRITE =&gt; <span class="string">'false'</span>,</span><br><span class="line"> PREFETCH_BLOCKS_ON_OPEN =&gt; <span class="string">'false'</span>, COMPRESSION =&gt; <span class="string">'NONE'</span>, BLOCKCACHE =&gt; <span class="string">'true'</span>, BLOCKSIZE =&gt; <span class="string">'65536'</span>&#125;</span><br><span class="line">1 row(s)</span><br><span class="line">Took 0.2293 seconds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据放入表中</span></span><br><span class="line">&gt;put <span class="string">'t-test'</span>,  <span class="string">'row1'</span>, <span class="string">'c-test:a'</span>, <span class="string">'value1'</span></span><br><span class="line">Took 0.2116 seconds</span><br><span class="line">&gt; put <span class="string">'t-test'</span>,  <span class="string">'row2'</span>, <span class="string">'c-test:b'</span>, <span class="string">'value2'</span></span><br><span class="line">Took 0.0082 seconds</span><br><span class="line">&gt; &gt; put <span class="string">'t-test'</span>,  <span class="string">'row3'</span>, <span class="string">'c-test:c'</span>, <span class="string">'value3'</span></span><br><span class="line">Took 0.0085 seconds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 一次扫描表中所有数据</span></span><br><span class="line">&gt; scan <span class="string">'t-test'</span></span><br><span class="line">&gt;   scan <span class="string">'t-test'</span></span><br><span class="line">ROW                                             COLUMN+CELL</span><br><span class="line"> row1                                           column=c-test:a, timestamp=1552630577582, value=value1</span><br><span class="line"> row2                                           column=c-test:b, timestamp=1552630591734, value=value2</span><br><span class="line"> row3                                           column=c-test:c, timestamp=1552630598817, value=value3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取单行数据</span></span><br><span class="line">&gt; get <span class="string">'t-test'</span> <span class="string">'row1'</span></span><br><span class="line">COLUMN                                          CELL</span><br><span class="line"> c-test:a                                       timestamp=1552630577582, value=value1</span><br><span class="line">1 row(s)</span><br><span class="line">Took 0.0225 seconds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 禁用/启用表</span></span><br><span class="line">&gt; <span class="built_in">disable</span> <span class="string">'t-test'</span></span><br><span class="line">&gt; <span class="built_in">enable</span> <span class="string">'t-test'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除表</span></span><br><span class="line">&gt; drop <span class="string">'t-test'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 退出HBase Shell</span></span><br><span class="line">&gt; quit</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># stop a standalone instance of HBase</span></span><br><span class="line"><span class="comment"># 可能需要几分钟，请耐心等待</span></span><br><span class="line">bin/stop-hbase.sh</span><br></pre></td></tr></table></figure><p><img src="/images/HBase/hbase_standalone.png" alt></p><p><br><br><br><br><br></p><h3 id="伪分布式本地安装"><a href="#伪分布式本地安装" class="headerlink" title="伪分布式本地安装"></a>伪分布式本地安装</h3><p>Pseudo-Distributed Local Install</p><p>通过standalone模式之后，你可以重新配置HBase以<strong>伪分布式模式(Pseudo-Distributed)</strong>运行。伪分布式意味着HBase仍然在单个主机上运行，但每个HBase Daemons(HMaster, HRegionServer, Zookeeper)作为一个单独的进程运行。默认数据存储在<code>/tmp</code>下，除非你像Standalone一样配置了<code>rootdir</code>。</p><p>假设将数据存储在HDFS中，并且HDFS可用。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Stop HBase if it is running.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置HBase</span></span><br><span class="line"><span class="comment"># 编辑hbase-site.xml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加指示HBase以分布式模式运行，每个守护进程有一个JVM实例</span></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;<span class="literal">true</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 hdfs://// URI语法将hbase.rootdir从本地文件系统更改为HDFS实例的地址，地址请查看HDFS配置</span></span><br><span class="line"><span class="comment"># 请确保删除hbase.unsafe.stream.capability.enforce的条目或将其设置为true</span></span><br><span class="line"><span class="comment"># 你不需要在HDFS中创建目录，HBase会为你做这件事。如果您创建目录，HBase将尝试进行迁移，这不是您想要的</span></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;hdfs://localhost:8020/hbase&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动HBase</span></span><br><span class="line">bin/start-hbase.sh</span><br><span class="line"><span class="comment"># 如果系统配置正确，则jps显示正在运行的HBase进程</span></span><br><span class="line">jps</span><br><span class="line">20065 HMaster</span><br><span class="line">20006 HQuorumPeer</span><br><span class="line">20137 HRegionServer</span><br><span class="line">20521 Jps</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查HDFS中的HBase目录</span></span><br><span class="line"><span class="comment"># 如果一切正常，HBase会在HDFS中创建它的目录</span></span><br><span class="line"><span class="comment"># 注意HDFS的安全模式</span></span><br><span class="line">bin/hadoop fs -ls /hbase</span><br><span class="line">Found 1 items</span><br><span class="line">drwxr-xr-x   - zhang supergroup          0 2019-03-15 15:33 /hbase/.tmp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个表，并用数据填充它</span></span><br><span class="line"><span class="comment"># 创建放入和前面一样</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动/停止一个 backup HBase Master Server(HMaster)</span></span><br><span class="line"><span class="comment"># 在同一硬件上运行多个HMaster实例在生产环境中没有意义，就像运行伪分布式集群对生产没有意义一样。此步骤仅用于测试和学习</span></span><br><span class="line">/bin/<span class="built_in">local</span>-master-backup.sh start 2 3 5</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在不杀死整个集群的情况下终止backup master</span></span><br><span class="line">cat /tmp/hbase-testuser-1-master.pid |xargs <span class="built_in">kill</span> -9</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动/停止additional RegionServers</span></span><br><span class="line"><span class="comment"># 在同一系统上运行多个HRegionServers对于以伪分布式模式进行测试非常有用。</span></span><br><span class="line">bin/<span class="built_in">local</span>-regionservers.sh start 2 3 4</span><br><span class="line">bin/<span class="built_in">local</span>-regionservers.sh stop 3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止HBase</span></span><br><span class="line">bin/stop-hbase.sh</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h3><p>Advanced - Fully Distributed</p><p>实际上，你需要完全分布式(fully-distributed)配置才能完全测试HBase并在实际场景中使用它。在分布式配置中，集群包含多个节点，每个节点运行一个或多个HBase守护进程(包括: Primary Master, Backup Master, Multiple ZooKeeper nodes, Multiple RegionServer nodes)。</p><p><br></p><h4 id="分布式集群架构"><a href="#分布式集群架构" class="headerlink" title="分布式集群架构"></a>分布式集群架构</h4><p>Distributed Cluster Demo Architecture</p><div class="table-container"><table><thead><tr><th>Node Name</th><th>Master</th><th>ZooKeeper</th><th>RegionServer</th></tr></thead><tbody><tr><td><code>node-a.example.com</code></td><td>yes</td><td>yes</td><td>no</td></tr><tr><td><code>node-b.example.com</code></td><td>backup</td><td>yes</td><td>yes</td></tr><tr><td><code>node-c.example.com</code></td><td>no</td><td>yes</td><td>yes</td></tr></tbody></table></div><p>确保集群之间的可访问性。</p><p><br><br><br></p><h4 id="SSH免密"><a href="#SSH免密" class="headerlink" title="SSH免密"></a>SSH免密</h4><p>Configure Passwordless SSH Access</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成公钥</span></span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 写入公钥</span></span><br><span class="line">cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意修改权限</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试免密登录</span></span><br><span class="line">ssh user@hostname</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="准备集群"><a href="#准备集群" class="headerlink" title="准备集群"></a>准备集群</h4><p>node-a 将运行 Primary Master, ZooKeeper, no RegionServers.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置conf/regionservers</span></span><br><span class="line"><span class="comment"># 删除node-a的RegionServer地址，并添加node-b, node-c的RegionServer地址</span></span><br><span class="line"><span class="comment"># node-b.example.com, node-c.example.com</span></span><br><span class="line">conf/regionservers</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置HBase使用node-b作为 Backup Master</span></span><br><span class="line"><span class="comment"># 创建 conf/backup-masters，并使用 node-b的主机名为其添加新行</span></span><br><span class="line">conf/backup-masters</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置ZooKeeper</span></span><br><span class="line"><span class="comment"># 实际情况中，你应该仔细考虑ZooKeeper配置</span></span><br><span class="line"><span class="comment"># node-a, conf/hbase-site.xml</span></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;node-a.example.com,node-b.example.com,node-c.example.com&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/usr/<span class="built_in">local</span>/zookeeper&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><br></p><p>node-b 将运行 backup master, ZooKeeper instance。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 复制 node-a conf/ 到 node-b, node-c conf/</span></span><br><span class="line"><span class="comment"># 集群中的每个节点都需要具有相同的配置</span></span><br><span class="line"><span class="comment"># 请注意不同节点的localhost这个地址</span></span><br></pre></td></tr></table></figure><p><br></p><p>配置完成后，便要启动并测试集群。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Be sure HBase is not running on any node</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Start the cluster</span></span><br><span class="line"><span class="comment"># On node-a, node-b, node-c</span></span><br><span class="line">bin/start-hbase.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># ZooKeeper starts first, followed by the master, then the RegionServers, and finally the backup masters.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Verify that the processes are running</span></span><br><span class="line">jps</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Browse to the Web UI</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Test what happens when nodes or services disappear</span></span><br><span class="line"><span class="comment"># 测试可用性</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><hr><p><br><br><br></p><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p>Apache HBase Configuration</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;li&gt;HBase: &lt;a href=&quot;https://hbase.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://hbase.apache.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Reference Guide: &lt;a href=&quot;http://hbase.apache.org/book.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://hbase.apache.org/book.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RHEL7x86_64&lt;/li&gt;
&lt;li&gt;HBase v3.0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="Apache" scheme="https://zhang21.github.io/tags/Apache/"/>
    
      <category term="DataAnalysis" scheme="https://zhang21.github.io/tags/DataAnalysis/"/>
    
      <category term="HBase" scheme="https://zhang21.github.io/tags/HBase/"/>
    
      <category term="NoSQL" scheme="https://zhang21.github.io/tags/NoSQL/"/>
    
  </entry>
  
  <entry>
    <title>Flume</title>
    <link href="https://zhang21.github.io/2019/03/07/Flume/"/>
    <id>https://zhang21.github.io/2019/03/07/Flume/</id>
    <published>2019-03-07T01:32:20.000Z</published>
    <updated>2019-03-15T02:24:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>wikipedia</li><li>Flume: <a href="https://flume.apache.org/" target="_blank" rel="noopener">https://flume.apache.org/</a></li><li>Flume docs: <a href="https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html" target="_blank" rel="noopener">https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html</a></li></ul><p>环境:</p><ul><li>ELRH7x86_64</li><li>Flume v1.9.0</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p><a href="https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#introduction" target="_blank" rel="noopener"></a></p><p><strong>Apache Flume</strong> 是一种分布式，可靠且可用的软件，使用Java编写，用于高效收集(collecting)，聚合(aggregating)和移动(moving)大量日志数据。它具有基于流数据流(stream data flows)的简单灵活的架构。它具有可靠性机制和许多故障转移和恢复机制，具有强大的容错能力。它使用简单的可扩展数据模型，允许在线分析应用程序。</p><p>Apache Flume的使用不仅限于日志数据聚合。由于数据源是可定制的，因此Flume可用于传输大量事件数据，包括但不限于网络流量数据，社交媒体生成的数据，电子邮件消息以及几乎任何可能的数据源。</p><p><img src="/imags/Flume/flume-logo.png" alt></p><p><br></p><h2 id="系统要求"><a href="#系统要求" class="headerlink" title="系统要求"></a>系统要求</h2><ul><li><strong>Java</strong>: Java 1.8+</li><li><strong>Mem</strong>: sources, channels, sinks有足够的内存</li><li><strong>Disk</strong>: channels, sinks有足够的磁盘空间</li><li><strong>Directory Permissions</strong>: Agent使用的目录的读写权限</li></ul><p><br><br><br><br><br></p><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p><br></p><h3 id="数据流模型"><a href="#数据流模型" class="headerlink" title="数据流模型"></a>数据流模型</h3><p>Data flow model</p><ul><li><strong>源(Source)</strong></li><li><strong>通道(Channel)</strong></li><li><strong>接收器(Sink)</strong></li><li><strong>事件(Event)</strong></li></ul><p><br></p><p><strong>Flume event</strong> 被定义为具有字节(byte)有效负载可可选字符串属性集的数据流单元(unit of data flow)。<strong>Flume agent</strong>是一个(JVM)进程，它承载事件从外部源流向下一个目标的组件。</p><p><img src="/images/Flume/flume-architecture.png" alt></p><p><br></p><p><strong>Flume源消费事件</strong>(source consumes events)通过<strong>外部源</strong>(external source)(如WebServer)传递给它。外部源通过<strong>目标Flume源</strong>(target Flume source)识别的格式向Flume发送事件。当Flume源接收事件时，它会将其存储到一个或多个<strong>通道</strong>(channels)中。通道是一个被动存储，可以保持事件直到它被<strong>Flume sink</strong>所消费。接收器从通道中移除事件，并将其放入外部存储库(如HDFS)或将其转发到流中的下一个Flume Agent(next hop)的Flume Source。给定Agent中的Source和Sink与Channel中暂存的Events异步运行。</p><p><br><br><br></p><h3 id="复杂流"><a href="#复杂流" class="headerlink" title="复杂流"></a>复杂流</h3><p>Complex flows</p><p>Flume允许用户构建多跳(hop)流，其中事件在到达最终目的地之前经过多个代理。它还允许 fan-in 和 fan-out flows, 上下文路由(contextual routing), 故障跳跃的备份路由(故障转移)。</p><p><br><br><br></p><h3 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h3><p>Reliability</p><p>事件在每个Agent的通道中进行，然后将事件传递到流中的下一个代理或终端存储库(如HDFS)。只有将事件存储在下一个代理的通道或终端存储库之后，才会从通道中删除这些事件。这就是Flume中的单跳消息传递语义如何提供流的端到端可靠性。</p><p>Flume使用事务方法来保证事件的可靠传递。源和接收器分别在事务中封装由信道提供的事务中放置/提供的事件的存储(storage)/检索(retrieval)。这可确保事件集在流中从一个点到另一个点可靠地传递。在多跳流的情况下，来自前一跳的接收器和来自下一跳的源都运行其事务以确保数据安全地存储在下一跳的信道中。</p><p><br><br><br></p><h3 id="可恢复性"><a href="#可恢复性" class="headerlink" title="可恢复性"></a>可恢复性</h3><p>Recoverability</p><p>事件在通道中进行，该通道管理从故障中恢复。Flume支持由本地文件系统支持的持久化(durable)文件通道。还有一个内存通道(memory channel)，它将事件存储到内存中的队列中，这更快，但是当代理进程死亡时仍然存留在内存通道中的任何事件都无法恢复。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h1><p><a href="https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#setup" target="_blank" rel="noopener">Setup</a></p><p><br></p><h2 id="设置代理"><a href="#设置代理" class="headerlink" title="设置代理"></a>设置代理</h2><p>Setting up an agent</p><p>Flume Agent配置文件存储在本地配置文件中。这是一个Java properties文件格式的文本文件。可以在同一个配置文件中指定一个或多个代理的配置。配置文件包括代理中的每个Source, Sink, Channel的属性，以及它们如何连接在一起以形成数据流。</p><p><br></p><h3 id="配置单个组件"><a href="#配置单个组件" class="headerlink" title="配置单个组件"></a>配置单个组件</h3><p>Configuring individual components</p><p>流中的每个组件(source, sink, channel)都具有特定于类型和实例化的名称(name)，类型(type)，属性集(properties)。</p><p><br><br><br></p><h3 id="连接各个部分"><a href="#连接各个部分" class="headerlink" title="连接各个部分"></a>连接各个部分</h3><p>Wiring the pieces together</p><p>Agent需要知道加载哪些组件，以及它们如何连接以构成流。这是通过列出代理中每个源，接收器和通道的名称，然后为每个接收器和源指定连接通道来完成的。</p><p><br><br><br></p><h3 id="启动代理"><a href="#启动代理" class="headerlink" title="启动代理"></a>启动代理</h3><p>Starting an agent</p><p>下载Flume发型版，使用名为<code>flume-ng</code>的shell脚本启动代理程序。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 你需要在命令行上指定代理名称、配置目录、配置文件</span></span><br><span class="line">bin/flume-ng agent -n <span class="variable">$agent_name</span> -c conf -f conf/flume-conf.properties.template</span><br><span class="line"></span><br><span class="line"><span class="comment"># 现在，代理开始运行在给定属性文件中配置的源和接收器</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="一个栗子"><a href="#一个栗子" class="headerlink" title="一个栗子"></a>一个栗子</h3><p>下面给出一个示例配置文件。此配置允许用户生成事件，并将其记录到console:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># example.conf: A single-node Flume configuration</span><br><span class="line"></span><br><span class="line"># Name the components on this agent</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># Describe/configure the source</span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure><p><br></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 运行它</span></span><br><span class="line">bin/flume-ng agent --conf conf --conf-file example.conf --name a1 -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="在配置文件中使用环境变量"><a href="#在配置文件中使用环境变量" class="headerlink" title="在配置文件中使用环境变量"></a>在配置文件中使用环境变量</h3><p>Using environment variables in configuration files</p><p>Flume能够替换配置中的环境变量:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a1.sources = r1</span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = 0.0.0.0</span><br><span class="line">a1.sources.r1.port = $&#123;NC_PORT&#125;</span><br><span class="line">a1.sources.r1.channels = c1</span><br></pre></td></tr></table></figure><p><strong>注意: 环境变量目前只使用于Value，不适用于Key。</strong></p><p><br><br><br></p><h3 id="记录原始数据"><a href="#记录原始数据" class="headerlink" title="记录原始数据"></a>记录原始数据</h3><p>Logging raw data</p><p>在许多生产环境中记录流经管道的原始数据流不是所希望的行为，因为这可能导致泄露敏感数据或安全相关配置到Flume日志文件。默认情况下，Flume不会记录此类信息。另一方法，如果数据管道出错，Flume也将尝试提供DEBUG信息。</p><p>为了能够记录事件和配置相关的数据，除了 <code>log4j</code> 属性外，还必须设置一些Java系统属性。<br>要启用与配置相关的日志记录，请设置Java系统属性 <code>-Dorg.apache.flume.log.printconfig=true</code> 。这也可以在命令行上进行传递，也可以在 <code>flume-env.sh</code> 中的 <code>JAVA_OPTS</code> 变量中设置。</p><p>要启用数据记录，请按照上述相同方式设置Java系统属性 <code>-Dorg.apache.flume.log.rawdata=true</code> 。对于大多数组件，还必须将 <code>log4j</code> 日志记录级别设置为DEBUG或TRACE，以使特定于事件的日志记录显示在Flume日志中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 启用配置日志记录和原始数据日志记录的示例，同时还将Log4j日志级别设置为DEBUG以用于控制台输出</span><br><span class="line">bin/flume-ng agent --conf conf --conf-file example.conf --name a1 -Dflume.root.logger=DEBUG,console -Dorg.apache.flume.log.printconfig=true -Dorg.apache.flume.log.rawdata=true</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="Zookeeeper基础配置"><a href="#Zookeeeper基础配置" class="headerlink" title="Zookeeeper基础配置"></a>Zookeeeper基础配置</h3><p>Zookeeper based Configuration</p><p>Flume支持通过<strong>Zookeeper</strong>配置Agent的配置。这是一个实验性功能。配置文件需要在可配置前缀下的Zookeeper中上传。配置文件存储在Zookeeper Node Data中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Agent1和Agent2的Zookeeper Node Tree的示例</span><br><span class="line">- /flume</span><br><span class="line"> |- /a1 [Agent config file]</span><br><span class="line"> |- /a2 [Agent config file]</span><br></pre></td></tr></table></figure><p>一旦上传了配置文件，使用以下选项启动Agent:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -z, Zookeeper connection string. Comma separated list of hostname:port</span></span><br><span class="line"><span class="comment"># -p, Base Path in Zookeeper to store Agent configurations</span></span><br><span class="line"></span><br><span class="line"> bin/flume-ng agent –conf conf -z zkhost:2181,zkhost1:2181 -p /flume –name a1 -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="安装第三方插件"><a href="#安装第三方插件" class="headerlink" title="安装第三方插件"></a>安装第三方插件</h3><p>Installing third-party plugins</p><p>Flume拥有完整的基于插件的架构。虽然Flume附带了许多开箱即用的sources, channels, sinks, serializers…但许多实现斗鱼Flume分开运行。</p><p>虽然通过将自己的jar包添加到 <code>flume-env.sh</code> 文件中的 <code>FLUME_CLASSPATH</code> 变量值，始终可以包含自定义Flume组件。但Flume现在支持一个名为 <code>plugins.d</code> 的特殊目录，该目录会自动获取以特定格式打包的插件。</p><p><br></p><p><strong>插件目录</strong><br>The plugins.d directory</p><p><code>plugins.d</code> 目录位于 <code>$FLUME_HOME/plugins.d</code>。在启动时，<code>flume-ng</code> 启动脚本在 <code>plugins.d</code> 目录中查找符合以下格式的插件，并在启动java时将它们包含在正确的路径中。</p><p><br></p><p><strong>插件目录布局</strong><br>Directory layout for plugins</p><p><code>plugins.d</code> 中的每个插件(子目录)最多可以有三个子目录:</p><ol><li><code>lib</code> - the plugin’s jar(s)</li><li><code>libext</code> - the plugin’s dependency jar(s)</li><li><code>native</code> - any required native libraries, such as <code>.so</code> files</li></ol><p>栗子:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plugins.d/</span><br><span class="line">plugins.d/custom-source-1/</span><br><span class="line">plugins.d/custom-source-1/lib/my-source.jar</span><br><span class="line">plugins.d/custom-source-1/libext/spring-core-2.5.6.jar</span><br><span class="line">plugins.d/custom-source-2/</span><br><span class="line">plugins.d/custom-source-2/lib/custom.jar</span><br><span class="line">plugins.d/custom-source-2/native/gettext.so</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="数据摄取"><a href="#数据摄取" class="headerlink" title="数据摄取"></a>数据摄取</h2><p>Data ingestion</p><p>Flume支持许多从外部源摄取数据的机制。</p><p><br></p><h3 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h3><p>可使用RPC机制将给定文件发送到Flume Source:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 栗子</span></span><br><span class="line"><span class="comment"># 将日志内容发送到监听该端口的Flume Source</span></span><br><span class="line">bin/flume-ng avro-client -H localhost -p 41414 -F /usr/logs/log.10</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="执行命令"><a href="#执行命令" class="headerlink" title="执行命令"></a>执行命令</h3><p>Executing commands</p><p>有一个exec source执行给定的命令并消费输出。</p><p><br><br><br></p><h3 id="网路流"><a href="#网路流" class="headerlink" title="网路流"></a>网路流</h3><p>Network streams</p><p>Flume支持以下机制从常用日志流(log stream)类型中读取数据。如:</p><ul><li>Avro</li><li>Thrift</li><li>Syslog</li><li>Netcat</li></ul><p><br><br><br><br><br></p><h2 id="多个代理流"><a href="#多个代理流" class="headerlink" title="多个代理流"></a>多个代理流</h2><p>Setting multi-agent flow</p><p><img src="/images/Flume/flume-multi-agent-flow.png" alt></p><p>为了跨多个代理/跳(multiple agents/hops)的数据流，先前代理的接收器和当前代理的源是同一类型，接收器指向源的hostname/ip和port。</p><p><br><br><br><br><br></p><h2 id="整合"><a href="#整合" class="headerlink" title="整合"></a>整合</h2><p>Consolidation</p><p>日志收集中非常常见的情况是生成大量日志的客户端将数据发送到连接到存储子系统的少数消费者代理。例如，从数百个Web服务器收集的日志发送给写入HDFS集群的十几个代理。</p><p>这可以通过在Flume中使用接收器配置多个第一层代理，所有这些代理都指向单个源。第二层代理商的源将接收的事件合并到单个通道中，该通道有接收器消费到最终的目的地。</p><p><img src="/images/Flume/flume-consolidation.png" alt></p><p><br><br><br><br><br></p><h2 id="多路复用流"><a href="#多路复用流" class="headerlink" title="多路复用流"></a>多路复用流</h2><p>Multiplexing the flow</p><p>Flume支持将事件流多路复用到一个或多个目的地。这是通过定义可以复制或选择性地将事件路由到一个或多个通道的流复用器来实现的。</p><p><img src="/images/Flume/flume-multiplexing-flow.png" alt></p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p><a href="https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#configuration" target="_blank" rel="noopener">Configuration</a></p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="过滤"><a href="#过滤" class="headerlink" title="过滤"></a>过滤</h1><p><a href="https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#configuration-filters" target="_blank" rel="noopener">Configuration Filters</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;wikipedia&lt;/li&gt;
&lt;li&gt;Flume: &lt;a href=&quot;https://flume.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://flume.apache.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Flume docs: &lt;a href=&quot;https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ELRH7x86_64&lt;/li&gt;
&lt;li&gt;Flume v1.9.0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="Apache" scheme="https://zhang21.github.io/tags/Apache/"/>
    
      <category term="DataAnalysis" scheme="https://zhang21.github.io/tags/DataAnalysis/"/>
    
      <category term="Flume" scheme="https://zhang21.github.io/tags/Flume/"/>
    
  </entry>
  
  <entry>
    <title>Sqoop</title>
    <link href="https://zhang21.github.io/2019/03/07/Sqoop/"/>
    <id>https://zhang21.github.io/2019/03/07/Sqoop/</id>
    <published>2019-03-07T01:25:20.000Z</published>
    <updated>2019-03-07T01:30:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>wikipedia</li><li>sqoop: <a href="https://sqoop.apache.org/" target="_blank" rel="noopener">https://sqoop.apache.org/</a></li></ul><p>环境:</p><ul><li>ELRH7x84_64</li><li>Sqoop v1.4.7</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><strong>Apache Sqoop</strong> 是一个命令行界面(CLI)的应用程序工具，使用Java开发，用于在<strong>关系型数据库</strong>和<strong>Hadoop</strong>之间传输数据。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;wikipedia&lt;/li&gt;
&lt;li&gt;sqoop: &lt;a href=&quot;https://sqoop.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://sqoop.apache.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ELRH7x84_64&lt;/li&gt;
&lt;li&gt;Sqoop v1.4.7&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="Apache" scheme="https://zhang21.github.io/tags/Apache/"/>
    
      <category term="DataAnalysis" scheme="https://zhang21.github.io/tags/DataAnalysis/"/>
    
      <category term="Sqoop" scheme="https://zhang21.github.io/tags/Sqoop/"/>
    
  </entry>
  
  <entry>
    <title>Hive</title>
    <link href="https://zhang21.github.io/2019/03/06/Hive/"/>
    <id>https://zhang21.github.io/2019/03/06/Hive/</id>
    <published>2019-03-06T00:57:20.000Z</published>
    <updated>2019-03-15T02:52:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>wikipedia</li><li>Hive: <a href="https://hive.apache.org/" target="_blank" rel="noopener">https://hive.apache.org/</a></li><li>Hive Wiki: <a href="https://cwiki.apache.org/confluence/display/Hive/Home" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/Home</a></li></ul><p>环境:</p><ul><li>ELRH7x86_64</li><li>Hive v3.1</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><strong>Apache Hive</strong> 是一个建立在Hadoop架构之上的数据仓库，由Java编写，能够提供数据的精炼，查询和分析。</p><p>Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的SQL查询功能，可以将SQL语句转换为MapReduce任务进行运行。其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。</p><p>Apache Hive 数据仓库软件有助于使用SQL读取，编写和管理驻留在分布式存储中的大型数据集。可以将结构投影到已存储的数据中。还提供了命令行工具和JDBC驱动程序以将用户连接到Hive。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;wikipedia&lt;/li&gt;
&lt;li&gt;Hive: &lt;a href=&quot;https://hive.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://hive.apache.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hive Wiki: &lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Home&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/Home&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ELRH7x86_64&lt;/li&gt;
&lt;li&gt;Hive v3.1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="Apache" scheme="https://zhang21.github.io/tags/Apache/"/>
    
      <category term="Hive" scheme="https://zhang21.github.io/tags/Hive/"/>
    
      <category term="DataAnalysis" scheme="https://zhang21.github.io/tags/DataAnalysis/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop</title>
    <link href="https://zhang21.github.io/2019/03/06/Hadoop/"/>
    <id>https://zhang21.github.io/2019/03/06/Hadoop/</id>
    <published>2019-03-05T16:57:11.000Z</published>
    <updated>2019-03-25T03:37:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>wikipeadia</li><li>Hadoop官网: <a href="https://hadoop.apache.org/" target="_blank" rel="noopener">https://hadoop.apache.org/</a></li><li>Apache Software Foundation: <a href="https://www.apache.org/" target="_blank" rel="noopener">https://www.apache.org/</a></li></ul><p><br></p><p>环境:</p><ul><li>RHEL7x86_64</li><li>Hadoop v3.2.0</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><strong>Apache Hadoop</strong> 是一款支持数据密集型分布式应用程序，使用Java编写，并以Apache 2.0许可协议发布的开源软件框架。<br>Hadoop是根据谷歌公司发表的MapReduce和Google文件系统的论文自行实现而成。所有的Hadoop模块都有一个基本假设，即硬件故障是常见情况，应该由框架自动处理。</p><p>Apach Hadoop项目开发了用于可靠(Reliable)，可扩展(Scalable)的分布式计算(Distributed Computing)的开源软件。</p><p>Hadoop框架透明地为应用提供可靠性和数据移动。它实现了名为MapReduce的编程范式：应用程序被分割成许多小部分，而每个部分都能在集群中的任意节点上运行或重新运行。此外，Hadoop还提供了分布式文件系统，用以存储所有计算节点的数据，这为整个集群带来了非常高的带宽。MapReduce和分布式文件系统的设计，使得整个框架能够自动处理节点故障。它使应用程序与成千上万的独立计算的计算机和PB级的数据连接起来。</p><p><img src="/images/Hadoop/hadoop-logo.jpg" alt></p><p><br></p><h2 id="Modules"><a href="#Modules" class="headerlink" title="Modules"></a>Modules</h2><p>Hadoop 项目包括以下模块:</p><ul><li><strong>Hadoop Common</strong>: 支持其它Hadoop模块的常用实用程序</li><li><strong>Hadoop Distributed File System (HDFS)</strong>: 一种分布式文件系统，提供对应用程序数据的高吞吐量访问</li><li><strong>Hadoop YARN</strong>: 用于作业调度和集群资源管理的框架</li><li><strong>Hadoop MapReduce</strong>: 基于YARN的系统，用于并行处理大型数据集</li><li><strong>Hadoop Ozone</strong>: Hadoop的对象存储</li><li><strong>Hadoop Submarine</strong>: Hadoop的机器学习引擎</li></ul><p><br><br><br><br><br></p><h2 id="相关项目"><a href="#相关项目" class="headerlink" title="相关项目"></a>相关项目</h2><p>现在普遍认为整个 <strong>Apache Hadoop Platform</strong> 包括了许多项目:</p><ul><li><strong>Ambari</strong>: 一个基于Web的工具，用于配置，管理和监控Apache Hadoop集群。包括对HDFS, MapReduce, Hive, HBase, ZooKeeper, Pig, Sqoop…的支持。它还提供了一个用于查看群集运行状况的仪表板，用于查看各个程序的状态</li><li><strong>Avro</strong>：数据序列化系统。新的数据序列化格式与传输工具，将逐步取代Hadoop原有的IPC机制</li><li><strong>Cassandra</strong>: 可扩展的多主数据库，没有单点故障</li><li><strong>Chukwa</strong>: 用于管理大型分布式系统的数据收集系统</li><li><strong>Flume</strong>: 一种分布式，可靠且可用的软件。用于高效收集(collecting)，聚合(aggregating)和移动(moving)大量日志数据</li><li><strong>HBase</strong>：可扩展的分布式NoSQL列数据库，支持大型表的结构化数据存储。类似谷歌公司BigTable</li><li><strong>Hive</strong>：一种数据仓库基础结构，提供数据摘要和即席查询。构建于hadoop之上的数据仓库，通过一种类SQL语言HiveQL为用户提供数据的归纳、查询和分析等功能。Hive最初由Facebook贡献</li><li><strong>Mahout</strong>：可扩展的机器学习和数据挖掘库</li><li><strong>Pig</strong>: 用于并行计算的高级数据流语言和执行框架</li><li><strong>Spark</strong>: 适用于Hadoop数据的快速通用计算引擎。Spark提供了一种简单而富有表现力的编程模型，支持广泛的应用程序</li><li><strong>Sqoop</strong>：结构化数据（如关系数据库）与Apache Hadoop之间的数据转换工具</li><li><strong>Tez</strong>: 基于Hadoop YARN的通用数据流编程框架，它提供了一个强大而灵活的引擎来执行任意DAG任务来处理批处理和交互式用例的数据</li><li><strong>ZooKeeper</strong>：适用于分布式应用程序的高性能协调服务。提供类似Google Chubby的功能，由Facebook贡献</li></ul><p><br><br><br></p><hr><p><br><br><br></p><h1 id="General"><a href="#General" class="headerlink" title="General"></a>General</h1><p><br></p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Overview</p><p><strong>Node Attributes Support in YARN</strong></p><p>节点属性(Node Attribute)有助于根据节点标记(tag)节点上的多个标签(label)，并支持根据这些标签的表达式放置容器。</p><p><br></p><p><strong>Hadoop Submarine on YARN</strong></p><p>Hadoop Submarine 使数据工程师能够在数据所在的同一Hadoop YARN集群上轻松开发(develop)、训练(train)和部署(deploy)深度学习模型(TensorFlow)。</p><p><br></p><p><strong>Storage Policy Satisfier</strong></p><p>支持HDFS(Hadoop Distributed File System)应用程序，以便在文件/目录上设置存储策略时在存储类型之间移动块(block)。</p><p><br></p><p><strong>ABFS Filesystem connector</strong></p><p>支持最新的Azure Datalake Gen2 Storage。</p><p><br></p><p><strong>Enhanced S3A connector</strong></p><p>支持增强型S3A连接器，包括更好地恢复受限制的AWS S3和DynamoDB IO。</p><p><br></p><p><strong>Upgrades for YARN long running services</strong></p><p>支持通过YARN Native Service API和CLI对长时间运行的容器进行就地无缝(seamless)升级。</p><p><br><br><br><br><br></p><h2 id="单节点集群"><a href="#单节点集群" class="headerlink" title="单节点集群"></a>单节点集群</h2><p>Setting up a Single Node Cluster</p><p><br></p><h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h3><p>本节介绍如何设置和配置单节点Hadoop集群，以便你可以快速使用Hadoop MapReduce和HDFS执行简单的操作。</p><p><br><br><br></p><h3 id="先决条件"><a href="#先决条件" class="headerlink" title="先决条件"></a>先决条件</h3><ul><li><p><strong>支持的平台</strong></p><ul><li>GNU/Linux: Hadoop has been demonstrated on GNU/Linux clusters with 2000 nodes</li><li>Windows is also a supported platform but the followings steps are for Linux only.</li></ul></li><li><p><strong>依赖软件(Linux)</strong></p><ul><li>Java: 具体版本参考 <a href="https://wiki.apache.org/hadoop/HadoopJavaVersions" target="_blank" rel="noopener">HadoopJavaVersions</a></li><li>ssh: 必须运行sshd才能使用管理远程Hadoop守护程序的Hadoop脚本，建议按照pdsh以实现更好的ssh资源管子</li></ul></li><li><p><strong>安装软件</strong></p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Ubuntu</span></span><br><span class="line">sudo apt-get install ssh pdsh</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>获取Hadoop发行版，请从<a href="http://www.apache.org/dyn/closer.cgi/hadoop/common/" target="_blank" rel="noopener">Apache Download Mirrors</a>下载。</p><p><br><br><br></p><h3 id="准备启动Hadoop集群"><a href="#准备启动Hadoop集群" class="headerlink" title="准备启动Hadoop集群"></a>准备启动Hadoop集群</h3><p>解压前面下载的Hadoop发行版，编辑<code>hadoop/etc/hadoop/hadoop-env.sh</code>以定义一些参数:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># hadoop/etc/hadoop/hadoop-env.sh</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># set to the root of your Java installation</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.8.0_191-amd64</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME= /opt/hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment"># 由于我是使用rpm安装jdk8，所以为/usr/java/jdk1.8.0_191-amd64</span></span><br><span class="line"><span class="comment"># 我的hadoop放置于/opt/hadoop</span></span><br></pre></td></tr></table></figure><p>接着运行以下命令:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./bin/hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这将显示Hadoop的使用文档</span></span><br></pre></td></tr></table></figure><p><br></p><p><strong>有三种方式来启动Hadoop集群:</strong></p><ul><li>Local (Standalone) Mode</li><li>Pseudo-Distributed Mode</li><li>Fully-Distributed Mode</li></ul><p><br><br><br><br><br></p><h3 id="Standalone"><a href="#Standalone" class="headerlink" title="Standalone"></a>Standalone</h3><p>默认情况下，Hadoop配置为non-distibuted模式运行，作为单个Java进程。这对调试很有用。</p><p><br><br><br></p><h3 id="Pseudo-Distributed-Operation"><a href="#Pseudo-Distributed-Operation" class="headerlink" title="Pseudo-Distributed Operation"></a>Pseudo-Distributed Operation</h3><p>Hadoop也可以运行在伪分布模式下的单节点上，其中每个Hadoop Daemon在单独的java进程中运行。</p><p><br></p><p><strong>配置</strong><br><code>hadoop/etc/hadoop/core-site.xml</code>:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><code>hadoop/etc/hadoop/hdfs-site.xml</code>:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><br></p><p><strong>设置 passphraseless ssh</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查是否可以下无密码(passphrase)的情况下ssh到localhost</span></span><br><span class="line">ssh localhost</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果不行，请执行无密码登录操作</span></span><br><span class="line">ssh-keygen -t rsa -P <span class="string">''</span> -f ~/.ssh/id_rsa</span><br><span class="line">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">chmod 0600 ~/.ssh/authorized_keys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 之后再执行此操作</span></span><br><span class="line">ssh localhost</span><br></pre></td></tr></table></figure><p><br></p><p><strong>执行</strong></p><p>以下说明在本地运行MapReduce job。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意，以下位于hadoop目录</span></span><br><span class="line"><span class="comment"># 我的为 /opt/hadoop</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Format the filesystem</span></span><br><span class="line"><span class="comment"># namenode - run the DFS namenode</span></span><br><span class="line">bin/hdfs namenode -format</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Start NameNode daemon and DataNode daemon</span></span><br><span class="line">sbin/start-dfs.sh</span><br><span class="line"><span class="comment"># 日志输出到$HADOOP_HOME/logs</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. Browse the web interface for the NameNode; by default it is available at:</span></span><br><span class="line">NameNode - http://localhost:9870/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. Make the HDFS directories required to execute MapReduce jobs</span></span><br><span class="line">bin/hdfs dfs -mkdir /user</span><br><span class="line">bin/hdfs dfs -mkdir /user/&lt;username&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. Copy the input files into the distributed filesystem</span></span><br><span class="line">bin/hdfs dfs -mkdir input</span><br><span class="line">bin/hdfs dfs -put etc/hadoop/*.xml input</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. Run some of the examples provided</span></span><br><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.0.jar grep input output <span class="string">'dfs[a-z.]+'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 7. Examine the output files: Copy the output files from the distributed filesystem to the local filesystem and examine them</span></span><br><span class="line">bin/hdfs dfs -get output output</span><br><span class="line"><span class="comment"># cat output/*</span></span><br><span class="line"><span class="comment"># bin/hdfs dfs -cat output/*</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 8. When you’re done, stop the daemons with</span></span><br><span class="line">sbin/stop-dfs.sh</span><br></pre></td></tr></table></figure><p><br></p><p><strong>YARN on a Single Node</strong></p><p>你可以通过设置一些参数并运行ResourceManager Daemon和NodeManager Daemon，以伪分布模式在YARN上运行MapReduce Job。<br>以下指令假设你已运行上面的1-4步。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. Configure parameters as follows</span></span><br><span class="line"><span class="comment"># etc/hadoop/mapred-site.xml</span></span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;<span class="variable">$HADOOP_MAPRED_HOME</span>/share/hadoop/mapreduce/*:<span class="variable">$HADOOP_MAPRED_HOME</span>/share/hadoop/mapreduce/lib/*&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># etc/hadoop/yarn-site.xml</span></span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Start ResourceManager daemon and NodeManager daemon</span></span><br><span class="line">sbin/start-yarn.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Browse the web interface for the ResourceManager; by default it is available at</span></span><br><span class="line"><span class="comment"># ResourceManager - http://localhost:8088/</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. Run a MapReduce job</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. When you’re done, stop the daemons with</span></span><br><span class="line">sbin/stop-yarn.sh</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="集群设置"><a href="#集群设置" class="headerlink" title="集群设置"></a>集群设置</h2><p>Hadoop Cluster Setup</p><p>本节描述了如何安装和配置Hadoop集群，范围从几个节点到数千个节点。<br>但本节不包括安全性和高可用性等高级主题。</p><p><br></p><h3 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h3><ul><li>Java</li><li>Hadoop</li></ul><p><br><br><br></p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>通常，集群中的一台主机被指定为<strong>NameNode</strong>，而另一台主机被指定为<strong>ResourceManager</strong>，这些都是<strong>Master</strong>。其它服务(Web App Proxy Server, MapReduce…)通常在专用硬件或共享基础架构上运行，具体取决于负载。</p><p>集群中的其余主机充当<strong>DataNode</strong>和<strong>NodeManager</strong>。这些都是<strong>Worker</strong>。</p><p><br><br><br></p><h3 id="在非安全模式下配置Hadoop"><a href="#在非安全模式下配置Hadoop" class="headerlink" title="在非安全模式下配置Hadoop"></a>在非安全模式下配置Hadoop</h3><p>Configuring Hadoop in Non-Secure Mode</p><p>Hadoop的Java配置由两种类型的重要配置文件驱动:</p><ul><li><strong>只读(ReadOnly)的默认配置</strong><ul><li><code>core-default.xml</code></li><li><code>hdfs-default.xml</code></li><li><code>yarn-default.xml</code></li><li><code>mapred-default.xml</code></li></ul></li><li><strong>特定站点(site-specific)的配置</strong><ul><li><code>etc/hadoop/core-site.xml</code></li><li><code>etc/hadoop/hdfs-site.xml</code></li><li><code>etc/hadoop/yarn-site.xml</code></li><li><code>etc/hadoop/mapred-site.xml</code></li></ul></li></ul><p>此外，你可以通过<code>etc/hadoop/hadoop-env.sh</code>和<code>etc/hadoop/yarn-env.sh</code>配置特定于站点的值来控制分发的<code>bin/</code>目录下的Hadoop脚本。</p><p><br></p><p>要配置Hadoop Cluster，你需要配置Hadoop Daemon执行的<code>environment</code>以及<code>configuration parameters</code>。</p><ul><li>HDFS Daemon是 <strong>NameNode</strong>, <strong>SecondaryNameNode</strong> 和 <strong>DataNode</strong></li><li>YARN Daemon是 <strong>ResourceManager</strong>, <strong>NodeManager</strong> 和 <strong>WebAppProxy</strong></li><li>如果要使用MapReduce，则 <strong>MapReduce Job History Server</strong> 也将运行</li><li>对于大型安装，这些通常在不同的主机上运行</li></ul><p><br></p><h4 id="配置Hadoop守护进程的环境"><a href="#配置Hadoop守护进程的环境" class="headerlink" title="配置Hadoop守护进程的环境"></a>配置Hadoop守护进程的环境</h4><p>Configuring Environment of Hadoop Daemons</p><p>管理员应该使用 <code>etc/hadoop/hadoop-env.sh</code>， 可选择 <code>etc/hadoop/mapred-env.sh</code>, 以及 <code>etc/hadoop/yarn-env.sh</code>脚本来对Hadoop守护进程的进程环境进行特定站点的自定义配置。</p><p>至少，您必须指定 <code>JAVA_HOME</code>，以便在每个远程节点上正确定义它。</p><p>管理员可使用下表中的配置项配置各个守护进程:</p><div class="table-container"><table><thead><tr><th>Daemon</th><th>Environment Variable</th></tr></thead><tbody><tr><td>NameNode</td><td>HDFS_NAMENODE_OPTS</td></tr><tr><td>DataNode</td><td>HDFS_DATANODE_OPTS</td></tr><tr><td>Secondary NameNode</td><td>HDFS_SECONDARYNAMENODE_OPTS</td></tr><tr><td>ResourceManager</td><td>YARN_RESOURCEMANAGER_OPTS</td></tr><tr><td>NodeManager</td><td>YARN_NODEMANAGER_OPTS</td></tr><tr><td>WebAppProxy</td><td>YARN_PROXYSERVER_OPTS</td></tr><tr><td>Map Reduce Job History Server</td><td>MAPRED_HISTORYSERVER_OPTS</td></tr></tbody></table></div><p><br></p><p>其它你可自定义的有用的配置项包括:</p><ul><li><code>HADOOP_PID_DIR</code>:  The directory where the daemons’ process id files are stored</li><li><code>HADOOP_LOG_DIR</code>:  The directory where the daemons’ log files are stored. Log files are automatically created if they don’t exist</li><li><code>HADOOP_HEAPSIZE_MAX</code>:  The maximum amount of memory to use for the Java heapsize. Units supported by the JVM are also supported here. If no unit is present, it will be assumed the number is in megabytes. By default, Hadoop will let the JVM determine how much to use. This value can be overriden on a per-daemon basis using the appropriate _OPTS variable listed above. For example, setting HADOOP_HEAPSIZE_MAX=1g and HADOOP_NAMENODE_OPTS=”-Xmx5g” will configure the NameNode with 5GB heap.</li></ul><p>在大多数情况下，你需要指定 <code>HADOOP_PID_DIR</code> 和 <code>HADOOP_LOG</code> 目录，以便它们只能由将要运行Hadoop守护进程的用户写入。否则可能会发生符号链接攻击。</p><p><br><br><br></p><h4 id="配置Hadoop守护进程"><a href="#配置Hadoop守护进程" class="headerlink" title="配置Hadoop守护进程"></a>配置Hadoop守护进程</h4><p>Configuring the Hadoop Daemons</p><p>本节介绍给定配置文件中指定的重要参数。</p><ul><li><code>etc/hadoop/core-site.xml</code></li></ul><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>fs.defaultFS</code></td><td>NameNode URI</td><td>hdfs://host:port/</td></tr><tr><td><code>io.file.buffer.size</code></td><td>131072</td><td>Size of read/write buffer used in SequenceFiles.</td></tr></tbody></table></div><p><br></p><ul><li><code>etc/hadoop/hdfs-site.xml</code></li><li><strong>NameNode配置</strong></li></ul><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>dfs.namenode.name.dir</code></td><td>Path on the local filesystem where the NameNode stores the namespace and transactions logs persistently.</td><td>If this is a comma-delimited list of directories then the name table is replicated in all of the directories, for redundancy.</td></tr><tr><td><code>dfs.hosts /</code> <br> <code>dfs.hosts.exclude</code></td><td>List of permitted/excluded DataNodes.</td><td>If necessary, use these files to control the list of allowable datanodes.</td></tr><tr><td><code>dfs.blocksize</code></td><td>268435456</td><td>HDFS blocksize of 256MB for large file-systems.</td></tr><tr><td><code>dfs.namenode.handler.count</code></td><td>100</td><td>More NameNode server threads to handle RPCs from large number of DataNodes.</td></tr></tbody></table></div><p><br></p><ul><li><strong>DataNode配置</strong></li></ul><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td>dfs.datanode.data.dir</td><td>Comma separated list of paths on the local filesystem of a DataNode where it should store its blocks.</td><td>If this is a comma-delimited list of directories, then data will be stored in all named directories, typically on different devices.</td></tr></tbody></table></div><p><br></p><ul><li><code>etc/hadoop/yarn-site.xml</code></li><li><strong>ResourceManager和NodeManager配置</strong></li></ul><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>yarn.acl.enable</code></td><td>true / false</td><td>Enable ACLs? Defaults to false.</td></tr><tr><td><code>yarn.admin.acl</code></td><td>Admin ACL</td><td>ACL to set admins on the cluster. ACLs are of for comma-separated-usersspacecomma-separated-groups. Defaults to special value of * which means anyone. Special value of just space means no one has access.</td></tr><tr><td><code>yarn.log-aggregation-enable</code></td><td>false</td><td>Configuration to enable or disable log aggregation</td></tr></tbody></table></div><br><ul><li><strong>ResourceManager配置</strong></li></ul><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>yarn.resourcemanager.address</code></td><td>ResourceManager host:port for clients to submit jobs.</td><td>host:port If set, overrides the hostname set in yarn.resourcemanager.hostname.</td></tr><tr><td><code>yarn.resourcemanager.scheduler.address</code></td><td>ResourceManager host:port for ApplicationMasters to talk to Scheduler to obtain resources.</td><td>host:port If set, overrides the hostname set in yarn.resourcemanager.hostname.</td></tr><tr><td><code>yarn.resourcemanager.resource-tracker.address</code></td><td>ResourceManager host:port for NodeManagers.</td><td>host:port If set, overrides the hostname set in yarn.resourcemanager.hostname.</td></tr><tr><td><code>yarn.resourcemanager.admin.address</code></td><td>ResourceManager host:port for administrative commands.</td><td>host:port If set, overrides the hostname set in yarn.resourcemanager.hostname.</td></tr><tr><td><code>yarn.resourcemanager.webapp.address</code></td><td>ResourceManager web-ui host:port.</td><td>host:port If set, overrides the hostname set in yarn.resourcemanager.hostname.</td></tr><tr><td><code>yarn.resourcemanager.hostname</code></td><td>ResourceManager host.</td><td>host Single hostname that can be set in place of setting all yarn.resourcemanager*address resources. Results in default ports for ResourceManager components.</td></tr><tr><td><code>yarn.resourcemanager.scheduler.class</code></td><td>ResourceManager Scheduler class.</td><td>CapacityScheduler (recommended), FairScheduler (also recommended), or FifoScheduler.</td></tr><tr><td><code>yarn.scheduler.minimum-allocation-mb</code></td><td>Minimum limit of memory to allocate to each container request at the Resource Manager.</td><td>In MBs</td></tr><tr><td><code>yarn.scheduler.maximum-allocation-mb</code></td><td>Maximum limit of memory to allocate to each container request at the Resource Manager.</td><td>In MBs</td></tr><tr><td><code>yarn.resourcemanager.nodes.include-path</code> / <br> <code>yarn.resourcemanager.nodes.exclude-path</code></td><td>List of permitted/excluded NodeManagers.</td><td>If necessary, use these files to control the list of allowable NodeManagers.</td></tr></tbody></table></div><p><br></p><ul><li><strong>NodeManager配置</strong></li></ul><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>yarn.nodemanager.resource.memory-mb</code></td><td>Resource i.e. available physical memory, in MB, for given NodeManager</td><td>Defines total available resources on the NodeManager to be made available to running containers</td></tr><tr><td><code>yarn.nodemanager.vmem-pmem-ratio</code></td><td>Maximum ratio by which virtual memory usage of tasks may exceed physical memory</td><td>The virtual memory usage of each task may exceed its physical memory limit by this ratio. The total amount of virtual memory used by tasks on the NodeManager may exceed its physical memory usage by this ratio.</td></tr><tr><td><code>yarn.nodemanager.local-dirs</code></td><td>Comma-separated list of paths on the local filesystem where intermediate data is written.</td><td>Multiple paths help spread disk i/o.</td></tr><tr><td><code>yarn.nodemanager.log-dirs</code></td><td>Comma-separated list of paths on the local filesystem where logs are written.</td><td>Multiple paths help spread disk i/o.</td></tr><tr><td><code>yarn.nodemanager.log.retain-seconds</code></td><td>10800</td><td>Default time (in seconds) to retain log files on the NodeManager Only applicable if log-aggregation is disabled.</td></tr><tr><td><code>yarn.nodemanager.remote-app-log-dir</code></td><td>/logs</td><td>HDFS directory where the application logs are moved on application completion. Need to set appropriate permissions. Only applicable if log-aggregation is enabled.</td></tr><tr><td><code>yarn.nodemanager.remote-app-log-dir-suffix</code></td><td>logs</td><td>Suffix appended to the remote log dir. Logs will be aggregated to ${yarn.nodemanager.remote-app-log-dir}/${user}/${thisParam} Only applicable if log-aggregation is enabled.</td></tr><tr><td><code>yarn.nodemanager.aux-services</code></td><td>mapreduce_shuffle</td><td>Shuffle service that needs to be set for Map Reduce applications.</td></tr><tr><td><code>yarn.nodemanager.env-whitelist</code></td><td>Environment properties to be inherited by containers from NodeManagers</td><td>For mapreduce application in addition to the default values HADOOP_MAPRED_HOME should to be added. <br> 可能的值有: <code>JAVA_HOME</code>, <code>HADOOP_COMMON_HOME</code>, <code>HADOOP_HDFS_HOME</code>, <code>HADOOP_CONF_DIR</code>, <code>CLASSPATH_PREPEND_DISTCACHE</code>, <code>HADOOP_YARN_HOME</code>, <code>HADOOP_MAPRED_HOME</code></td></tr></tbody></table></div><p><br></p><ul><li><strong>History Server配置</strong></li></ul><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>yarn.log-aggregation.retain-seconds</code></td><td>-1</td><td>How long to keep aggregation logs before deleting them. -1 disables. Be careful, set this too small and you will spam the name node.</td></tr><tr><td><code>yarn.log-aggregation.retain-check-interval-seconds</code></td><td>-1</td><td>Time between checks for aggregated log retention. If set to 0 or a negative value then the value is computed as one-tenth of the aggregated log retention time. Be careful, set this too small and you will spam the name node.</td></tr></tbody></table></div><p><br></p><ul><li><code>etc/hadoop/mapred-site.xml</code></li><li><strong>MapReduce Applications配置</strong></li></ul><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>mapreduce.framework.name</code></td><td>yarn</td><td>Execution framework set to Hadoop YARN.</td></tr><tr><td><code>mapreduce.map.memory.mb</code></td><td>1536</td><td>Larger resource limit for maps.</td></tr><tr><td><code>mapreduce.map.java.opts</code></td><td>-Xmx1024M</td><td>Larger heap-size for child jvms of maps.</td></tr><tr><td><code>mapreduce.reduce.memory.mb</code></td><td>3072</td><td>Larger resource limit for reduces.</td></tr><tr><td><code>mapreduce.reduce.java.opts</code></td><td>-Xmx2560M</td><td>Larger heap-size for child jvms of reduces.</td></tr><tr><td><code>mapreduce.task.io.sort.mb</code></td><td>512</td><td>Higher memory-limit while sorting data for efficiency.</td></tr><tr><td><code>mapreduce.task.io.sort.factor</code></td><td>100</td><td>More streams merged at once while sorting files.</td></tr><tr><td><code>mapreduce.reduce.shuffle.parallelcopies</code></td><td>50</td><td>Higher number of parallel copies run by reduces to fetch outputs from very large number of maps.</td></tr></tbody></table></div><p><br></p><ul><li><strong>MapReduce JobHistory Server配置</strong></li></ul><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>mapreduce.jobhistory.address</code></td><td>MapReduce JobHistory Server host:port</td><td>Default port is 10020.</td></tr><tr><td><code>mapreduce.jobhistory.webapp.address</code></td><td>MapReduce JobHistory Server Web UI host:port</td><td>Default port is 19888.</td></tr><tr><td><code>mapreduce.jobhistory.intermediate-done-dir</code></td><td><code>/mr-history/tmp</code></td><td>Directory where history files are written by MapReduce jobs.</td></tr><tr><td><code>mapreduce.jobhistory.done-dir</code></td><td><code>/mr-history/done</code></td><td>Directory where history files are managed by the MR JobHistory Server.</td></tr></tbody></table></div><p><br><br><br></p><h3 id="监控NodeManager健康"><a href="#监控NodeManager健康" class="headerlink" title="监控NodeManager健康"></a>监控NodeManager健康</h3><p>Monitoring Health of NodeManagers</p><p>Hadoop提供了一种机制，管理员可通过该机制将NodeManager定期运行提供的脚本，以确定节点是否健康。</p><p>管理员可通过在脚本中执行对其选择的任何检查来确定节点是否处于正常状态。如果脚本检测到节点处于不健康状态，则必须以<strong>ERROR</strong>开头的字符串将其行输出到标准输出(std out)。NodeManager定期生成脚本并检查其输出。如果脚本的输出包含字符串<strong>ERROR</strong>(如上所述)，则节点的状态将报告为不健康(<strong>unhealthy</strong>)，并且ResourceManager将节点列入黑名单。之后便不会为此节点分配其它任务。但是，NodeManager继续运行脚本，因此如果节点再次变为健康(<strong>healthy</strong>)，它将自动从ResourceManager上的黑名单节点中被删除。在ResourceManger Web UI中，管理员可以使用节点的运行状况以及脚本的输出(如果不健康)。自节点健康依赖的时间也显示在Web UI上。</p><p>以下 <code>etc/hadoop/yarn-site.xml</code> 文件中的参数可用于控制节点健康监控脚本:</p><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>yarn.nodemanager.health-checker.script.path</code></td><td>Node health script</td><td>Script to check for node’s health status.</td></tr><tr><td><code>yarn.nodemanager.health-checker.script.opts</code></td><td>Node health script options</td><td>Options for script to check for node’s health status.</td></tr><tr><td><code>yarn.nodemanager.health-checker.interval-ms</code></td><td>Node health script interval</td><td>Time interval for running health script.</td></tr><tr><td><code>yarn.nodemanager.health-checker.script.timeout-ms</code></td><td>Node health script timeout interval</td><td>Timeout for health script execution.</td></tr></tbody></table></div><p>如果只有部分本地磁盘变坏，则运行健康检查的脚本不应该给出<strong>ERROR</strong>信息。NodeManager能够定期检查本地磁盘的运行状况（具体检查 <code>nodemanager-local-dirs</code> 和 <code>nodemanager-log-dirs</code> ），并在根据为配置属性 <code>yarn.nodemanager.disk-health-checker.min-healthy-disks</code> 设置的值达到坏目录数阈值(threshold of number of bad directories)，整个节点被标记为不健康，此信息也被发送到ResourceManager。引导磁盘(boot disk)中的故障也会被检查脚本所识别。</p><p><br><br><br></p><h3 id="Slaves-File"><a href="#Slaves-File" class="headerlink" title="Slaves File"></a>Slaves File</h3><p>在 <code>etc/hadoop/workers</code> 文件中列出所有Worker的hostname或IP addr，每行一个。帮助脚本将使用 <code>etc/hadoop/workers</code> 文件一次在多个主机上运行命令。它不用于任何基于Java的Hadoop配置。要使用此功能，必须为用于运行Hadoop的账户建立SSH信任(SSH无秘钥或Kerberos)。</p><p><br><br><br></p><h3 id="Rack-Awareness"><a href="#Rack-Awareness" class="headerlink" title="Rack Awareness"></a>Rack Awareness</h3><p>许多Hadoop组件都具有机架感知(<strong>rack-aware</strong>)功能，并利用网络拓扑结构提高性能和安全。Hadoop Daemons通过调用管理员配置的模块来获取集群中Workers的机架信息。</p><p>强烈建议在启动HDFS之前配置Rack Awareness！</p><p><br><br><br></p><h3 id="Logging"><a href="#Logging" class="headerlink" title="Logging"></a>Logging</h3><p>Hadoop通过Apache Commons Logging框架使用<strong>Apache log4j</strong>进行日志记录。编辑 <code>etc/hadoop/log4j.properties</code> 文件以自定义Hadoop Daemons的日志记录配置。</p><p><br><br><br></p><h3 id="操作集群"><a href="#操作集群" class="headerlink" title="操作集群"></a>操作集群</h3><p>Operating the Hadoop Cluster</p><p>完成所有必要的配置后，将文件分发到所有主机上的 <code>HADOOP_CONF_DIR</code> 目录。这应该是所有主机上的同一个目录。</p><p>通常，建议HDFS和YARN使用分开的用户来运行。在大多数安装中，HDFS进程以<code>hdfs</code>用户运行；YARN使用<code>yarn</code>用户运行。</p><p><br></p><h4 id="Startup-and-Shutdown"><a href="#Startup-and-Shutdown" class="headerlink" title="Startup and Shutdown"></a>Startup and Shutdown</h4><p>Hadoop Startup and Hadoop Shutdown</p><p><strong>要启动Hadoop集群，你需要启动HDFS和YARN集群。</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一次启动HDFS时，必须对其进行格式化。将新的分布式文件系统(distributed fs)格式化为hdfs</span></span><br><span class="line">[hdfs]$ <span class="variable">$HADOOP_HOME</span>/bin/hdfs namenode -format &lt;cluster_name&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在指定节点以hdfs启动HDFS NameNode</span></span><br><span class="line">[hdfs]$ <span class="variable">$HADOOP_HOME</span>/bin/hdfs --daemon start namenode</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止NameNode</span></span><br><span class="line">[hdfs]$ <span class="variable">$HADOOP_HOME</span>/bin/hdfs --daemon stop namenode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在每个指定节点以hdfs启动HDFS DataNode</span></span><br><span class="line">[hdfs]$ <span class="variable">$HADOOP_HOME</span>/bin/hdfs --daemon start datanode</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止DataNode</span></span><br><span class="line">[hdfs]$ <span class="variable">$HADOOP_HOME</span>/bin/hdfs --daemon stop datanode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果配置了 etc/hadoop/worker 和 SSH信任，则可以使用使用程序脚本以hdfs启动HDFS进程</span></span><br><span class="line">[hdfs]$ <span class="variable">$HADOOP_HOME</span>/sbin/start-dfs.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止HDFS进程</span></span><br><span class="line">[hdfs]$ <span class="variable">$HADOOP_HOME</span>/sbin/stop-dfs.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># SSH trusted access</span></span><br><span class="line">ssh-keygen -t rsa -P <span class="string">''</span> -f ~/.ssh/id_rsa</span><br><span class="line">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">chmod 0600 ~/.ssh/authorized_keys</span><br><span class="line"><span class="comment"># 也可将已有的公钥直接写入</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以yarn在指定的ResourceManager上启动YARN</span></span><br><span class="line">[yarn]$ <span class="variable">$HADOOP_HOME</span>/bin/yarn --daemon start resourcemanager</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止ResourceManager</span></span><br><span class="line">[yarn]$ <span class="variable">$HADOOP_HOME</span>/bin/yarn --daemon stop resourcemanager</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以yarn在每台指定主机上运行脚本启动NodeManager</span></span><br><span class="line">[yarn]$ <span class="variable">$HADOOP_HOME</span>/bin/yarn --daemon start nodemanager</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止NodeManager</span></span><br><span class="line">[yarn]$ <span class="variable">$HADOOP_HOME</span>/bin/yarn --daemon stop nodemanager</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以yarn在WebAppProxy Server上启动Standalone WebAPPProxy Server</span></span><br><span class="line"><span class="comment"># 如果使用多个Server进行负载均衡，则应在每台Server上运行</span></span><br><span class="line">[yarn]$ <span class="variable">$HADOOP_HOME</span>/bin/yarn --daemon start proxyserver</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止WebAppProxy server</span></span><br><span class="line">[yarn]$ <span class="variable">$HADOOP_HOME</span>/bin/yarn stop proxyserver</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果配置了 etc/hadoop/workers 和 SSH信任，则可以以yarn实用程序脚本启动YARN进程</span></span><br><span class="line">[yarn]$ <span class="variable">$HADOOP_HOME</span>/sbin/start-yarn.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止YARN进程</span></span><br><span class="line">[yarn]$ <span class="variable">$HADOOP_HOME</span>/sbin/stop-yarn.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以mapred在指定的服务器上运行MapReduce JobHistory Server</span></span><br><span class="line">[mapred]$ <span class="variable">$HADOOP_HOME</span>/bin/mapred --daemon start historyserver</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止MapReduce JobHistory Server</span></span><br><span class="line">[mapred]$ <span class="variable">$HADOOP_HOME</span>/bin/mapred --daemon stop historyserver</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="Web-Interfaces"><a href="#Web-Interfaces" class="headerlink" title="Web Interfaces"></a>Web Interfaces</h3><p>一旦Hadoop Cluster启动并运行，请检查组件的Web UI。具体如下:</p><div class="table-container"><table><thead><tr><th>Daemon</th><th>Web Interface</th><th>Notes</th></tr></thead><tbody><tr><td>NameNode</td><td><code>http://nn_host:port/</code></td><td>Default HTTP port is 9870</td></tr><tr><td>ResourceManager</td><td><code>http://rm_host:port/</code></td><td>Default HTTP port is 8088</td></tr><tr><td>MapReduce JobHistory Server</td><td><code>http://jhs_host:port/</code></td><td>Default HTTP port is 19888</td></tr></tbody></table></div><p><br><br><br><br><br></p><h2 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h2><p>Hadoop Commands Guide</p><p><br></p><h3 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h3><p>所有Hadoop命令和子项目都遵循相同的基本结构:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Usage</span></span><br><span class="line">shellcommand [SHELL_OPTIONS] [COMMAND] [GENERIC_OPTIONS] [COMMAND_OPTIONS]</span><br></pre></td></tr></table></figure><p><br></p><p><strong>Shell Options</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">--buildpathsEnables developer versions of jars.</span><br><span class="line"></span><br><span class="line">--config confdirOverwrites the default Configuration directory. Default is $HADOOP_HOME/etc/hadoop.</span><br><span class="line"></span><br><span class="line">--daemon modeIf the command supports daemonization (e.g., hdfs namenode), execute in the appropriate mode. Supported modes are start to start the process in daemon mode, stop to stop the process, and status to determine the active status of the process. status will return an LSB-compliant result code. If no option is provided, commands that support daemonization will run in the foreground. For commands that do not support daemonization, this option is ignored.</span><br><span class="line"></span><br><span class="line">--debugEnables shell level configuration debugging information</span><br><span class="line"></span><br><span class="line">--helpShell script usage information.</span><br><span class="line"></span><br><span class="line">--hostnamesWhen --workers is used, override the workers file with a space delimited list of hostnames where to execute a multi-host subcommand. If --workers is not used, this option is ignored.</span><br><span class="line"></span><br><span class="line">--hostsWhen --workers is used, override the workers file with another file that contains a list of hostnames where to execute a multi-host subcommand. If --workers is not used, this option is ignored.</span><br><span class="line"></span><br><span class="line">--loglevel loglevelOverrides the log level. Valid log levels are FATAL, ERROR, WARN, INFO, DEBUG, and TRACE. Default is INFO.</span><br><span class="line"></span><br><span class="line">--workersIf possible, execute this command on all hosts in the workers file.</span><br></pre></td></tr></table></figure><p><br></p><p><strong>Generic Options</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">-archives &lt;comma separated list of archives&gt;Specify comma separated archives to be unarchived on the compute machines. Applies only to job.</span><br><span class="line">-conf &lt;configuration file&gt;Specify an application configuration file.</span><br><span class="line">-D &lt;property&gt;=&lt;value&gt;Use value for given property.</span><br><span class="line">-files &lt;comma separated list of files&gt;Specify comma separated files to be copied to the map reduce cluster. Applies only to job.</span><br><span class="line">-fs &lt;file:///&gt; or &lt;hdfs://namenode:port&gt;Specify default filesystem URL to use. Overrides ‘fs.defaultFS’ property from configurations.</span><br><span class="line">-jt &lt;local&gt; or &lt;resourcemanager:port&gt;Specify a ResourceManager. Applies only to job.</span><br><span class="line">-libjars &lt;comma seperated list of jars&gt;Specify comma separated jar files to include in the classpath. Applies only to job.</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><p>Hadoop Common Commands</p><p>所有这些命令都是从<code>hadoop</code>命令执行的。它分为:</p><ul><li>用户命令(User Commands): 对hadoop集群的用户有用的命令</li><li>管理命令(Administration Commands): 对hadoop集群的管理员有用的命令</li></ul><p><br></p><h4 id="用户命令"><a href="#用户命令" class="headerlink" title="用户命令"></a>用户命令</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">archive    <span class="comment">#Creates a hadoop archive</span></span><br><span class="line">checknative    <span class="comment">#This command checks the availability of the Hadoop native code</span></span><br><span class="line">classpath    <span class="comment">#Prints the class path needed to get the Hadoop jar and the required libraries</span></span><br><span class="line">conftest    <span class="comment">#Validates configuration XML files</span></span><br><span class="line">credential    <span class="comment">#Command to manage credentials, passwords and secrets within credential providers.</span></span><br><span class="line">distch    <span class="comment">#Change the ownership and permissions on many files at once.</span></span><br><span class="line">distcp    <span class="comment">#Copy file or directories recursively.</span></span><br><span class="line">dtutil    <span class="comment">#Utility to fetch and manage hadoop delegation tokens inside credentials files</span></span><br><span class="line">fs    <span class="comment">#This command is documented in the File System Shell Guide.</span></span><br><span class="line">gridmix    <span class="comment">#Gridmix is a benchmark tool for Hadoop cluster</span></span><br><span class="line">jar    <span class="comment">#Runs a jar file.</span></span><br><span class="line">jnipath    <span class="comment">#Print the computed java.library.path.</span></span><br><span class="line">kerbname    <span class="comment">#Convert the named principal via the auth_to_local rules to the Hadoop user name.</span></span><br><span class="line">kdiag    <span class="comment">#Diagnose Kerberos Problems</span></span><br><span class="line">key    <span class="comment">#Manage keys via the KeyProvider</span></span><br><span class="line">kms    <span class="comment">#Run KMS, the Key Management Server.</span></span><br><span class="line">trace    <span class="comment">#View and modify Hadoop tracing settings</span></span><br><span class="line">version    <span class="comment">#Prints the version.</span></span><br><span class="line">CLASSNAME    <span class="comment">#Runs the class named CLASSNAME. The class must be part of a package.</span></span><br><span class="line">envvars    <span class="comment">#Display computed Hadoop environment variables.</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="管理命令"><a href="#管理命令" class="headerlink" title="管理命令"></a>管理命令</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Usage</span></span><br><span class="line">hadoop daemonlog -getlevel &lt;host:port&gt; &lt;classname&gt; [-protocol (http|https)]</span><br><span class="line">hadoop daemonlog -setlevel &lt;host:port&gt; &lt;classname&gt; &lt;level&gt; [-protocol (http|https)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 栗子</span></span><br><span class="line">bin/hadoop daemonlog -setlevel 127.0.0.1:9870 org.apache.hadoop.hdfs.server.namenode.NameNode DEBUG</span><br><span class="line">bin/hadoop daemonlog -getlevel 127.0.0.1:9871 org.apache.hadoop.hdfs.server.namenode.NameNode DEBUG -protocol https</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 还有以下守护进程</span></span><br><span class="line">Common    <span class="comment">#key management server</span></span><br><span class="line">HDFS    <span class="comment">#name node, secondary name node, data node, journal node, HttpFS server</span></span><br><span class="line">YARN    <span class="comment">#resource manager, node manager, Timeline server</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># hadoop shell commands全局设置</span><br><span class="line">etc/hadoop/hadoop-env.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 此文件允许高级用户覆盖某些shell 功能</span><br><span class="line">etc/hadoop/hadoop-user-functions.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 用户个人环境</span><br><span class="line">~/.hadooprc</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="FS-Shell"><a href="#FS-Shell" class="headerlink" title="FS Shell"></a>FS Shell</h2><p>FileSystem Shell</p><p>FS Shell包括了各种类似于shell的命令，它们直接与Hadoop分布式文件系统(HDFS)以及Hadoop支持的其它文件系统交互(如: Local FS, WebHDMIFS, S3 FS…)</p><p>All FS shell commands take path URIs as arguments.</p><p><br></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用方式</span></span><br><span class="line">bin/hadoop fs &lt;args&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Append single src, or multiple srcs from local file system to the destination file system</span></span><br><span class="line"> hadoop fs -appendToFile &lt;localsrc&gt; ... &lt;dst&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copies source paths to stdout.</span></span><br><span class="line">hadoop fs -cat [-ignoreCrc] URI [URI ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Returns the checksum information of a file</span></span><br><span class="line">hadoop fs -checksum URI</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Change group association of files</span></span><br><span class="line">hadoop fs -chgrp [-R] GROUP URI [URI ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Similar to the fs -put command, except that the source is restricted to a local file reference.</span></span><br><span class="line">hadoop fs -copyFromLocal &lt;localsrc&gt; URI</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Similar to get command, except that the destination is restricted to a local file reference</span></span><br><span class="line">hadoop fs -copyToLocal [-ignorecrc] [-crc] URI &lt;localdst&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Count the number of directories, files and bytes under the paths that match the specified file pattern</span></span><br><span class="line">hadoop fs -count [-q] [-h] [-v] [-x] [-t [&lt;storage <span class="built_in">type</span>&gt;]] [-u] [-e] &lt;paths&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copy files from source to destination</span></span><br><span class="line">hadoop fs -cp [-f] [-p | -p[topax]] URI [URI ...] &lt;dest&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">createSnapshot</span><br><span class="line">deleteSnapshot</span><br><span class="line">renameSnapshot</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Displays free space</span></span><br><span class="line">hadoop fs -df [-h] URI [URI ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Displays sizes of files and directories contained in the given directory or the length of a file in case its just a file.</span></span><br><span class="line">hadoop fs -du [-s] [-h] [-v] [-x] URI [URI ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Displays a summary of file lengths.</span></span><br><span class="line">hadoop fs -dus &lt;args&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Permanently delete files in checkpoints older than the retention threshold from trash directory, and create new checkpoint.</span></span><br><span class="line">hadoop fs -expunge</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Finds all files that match the specified expression and applies selected actions to them</span></span><br><span class="line">hadoop fs -find &lt;path&gt; ... &lt;expression&gt; ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copy files to the local file system</span></span><br><span class="line">hadoop fs -get [-ignorecrc] [-crc] [-p] [-f] &lt;src&gt; &lt;localdst&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copy files to the local file system</span></span><br><span class="line">hadoop fs -get [-ignorecrc] [-crc] [-p] [-f] &lt;src&gt; &lt;localdst&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Displays the Access Control Lists (ACLs) of files and directories</span></span><br><span class="line">hadoop fs -getfacl [-R] &lt;path&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Displays the extended attribute names and values (if any) for a file or directory</span></span><br><span class="line">hadoop fs -getfattr [-R] -n name | -d [-e en] &lt;path&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Takes a source directory and a destination file as input and concatenates files in src into the destination local file</span></span><br><span class="line">hadoop fs -getmerge [-nl] &lt;src&gt; &lt;localdst&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Displays first kilobyte of the file to stdout.</span></span><br><span class="line">hadoop fs -head URI</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Return usage output.</span></span><br><span class="line">hadoop fs -<span class="built_in">help</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hadoop fs -ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] &lt;args&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Recursive version of ls</span></span><br><span class="line">hadoop fs -lsr &lt;args&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Takes path uri’s as argument and creates directories.</span></span><br><span class="line">hadoop fs -mkdir [-p] &lt;paths&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Similar to put command, except that the source localsrc is deleted after it’s copied.</span></span><br><span class="line">hadoop fs -moveFromLocal &lt;localsrc&gt; &lt;dst&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Displays a “Not implemented yet” message.</span></span><br><span class="line">hadoop fs -moveToLocal [-crc] &lt;src&gt; &lt;dst&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Moves files from source to destination. This command allows multiple sources as well in which case the destination needs to be a directory. Moving files across file systems is not permitted.</span></span><br><span class="line">hadoop fs -mv URI [URI ...] &lt;dest&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copy single src, or multiple srcs from local file system to the destination file system. Also reads input from stdin and writes to destination file system if the source is set to “-”</span></span><br><span class="line">hadoop fs -put [-f] [-p] [-l] [-d] [ - | &lt;localsrc1&gt; .. ]. &lt;dst&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Delete files specified as args</span></span><br><span class="line">hadoop fs -rm [-f] [-r |-R] [-skipTrash] [-safely] URI [URI ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Delete a directory</span></span><br><span class="line">hadoop fs -rmdir [--ignore-fail-on-non-empty] URI [URI ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Recursive version of delete</span></span><br><span class="line">hadoop fs -rmr [-skipTrash] URI [URI ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Sets Access Control Lists (ACLs) of files and directories</span></span><br><span class="line">hadoop fs -setfacl [-R] [-b |-k -m |-x &lt;acl_spec&gt; &lt;path&gt;] |[--<span class="built_in">set</span> &lt;acl_spec&gt; &lt;path&gt;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Sets an extended attribute name and value for a file or directory</span></span><br><span class="line">hadoop fs -setfattr -n name [-v value] | -x name &lt;path&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Changes the replication factor of a file. If path is a directory then the command recursively changes the replication factor of all files under the directory tree rooted at path. The EC files will be ignored when executing this command</span></span><br><span class="line">hadoop fs -setrep [-R] [-w] &lt;numReplicas&gt; &lt;path&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print statistics about the file/directory at &lt;path&gt; in the specified format</span></span><br><span class="line">hadoop fs -<span class="built_in">stat</span> [format] &lt;path&gt; ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Displays last kilobyte of the file to stdout</span></span><br><span class="line">hadoop fs -tail [-f] URI</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hadoop fs -<span class="built_in">test</span> -[defsz] URI</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Takes a source file and outputs the file in text format. The allowed formats are zip and TextRecordInputStream.</span></span><br><span class="line">hadoop fs -text &lt;src&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Updates the access and modification times of the file specified by the URI to the current time.</span></span><br><span class="line">hadoop fs -touch [-a] [-m] [-t TIMESTAMP] [-c] URI [URI ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a file of zero length. An error is returned if the file exists with non-zero length</span></span><br><span class="line">hadoop fs -touchz URI [URI ...]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Truncate all files that match the specified file pattern to the specified length.</span></span><br><span class="line">hadoop fs -truncate [-w] &lt;length&gt; &lt;paths&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Return the help for an individual command</span></span><br><span class="line">hadoop fs -usage <span class="built_in">command</span></span><br></pre></td></tr></table></figure><p><br></p><h3 id="使用对象存储"><a href="#使用对象存储" class="headerlink" title="使用对象存储"></a>使用对象存储</h3><p>Working with Object Storage</p><p>The Hadoop FileSystem shell works with Object Stores such as Amazon S3, Azure WASB and OpenStack Swift.</p><p><br><br><br><br><br></p><h2 id="兼容性规范"><a href="#兼容性规范" class="headerlink" title="兼容性规范"></a>兼容性规范</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/Compatibility.html" target="_blank" rel="noopener">Apache Hadoop Compatibility Specification</a></p><p><br></p><h3 id="目的-1"><a href="#目的-1" class="headerlink" title="目的"></a>目的</h3><p>本节介绍Apache Hadoop项目的兼容性目标。所有Hadoop Interface都根据目标受众和稳定性进行分类，以保持与先前版本的兼容性。</p><p>本文档供Hadoop开发人员社区使用。</p><p><br><br><br><br><br></p><h2 id="开发者兼容指南"><a href="#开发者兼容指南" class="headerlink" title="开发者兼容指南"></a>开发者兼容指南</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/DownstreamDev.html" target="_blank" rel="noopener">Apache Hadoop Downstream Developer’s Guide</a></p><p><br></p><h3 id="目的-2"><a href="#目的-2" class="headerlink" title="目的"></a>目的</h3><p>本文档的目的是为下游开发人员提供明确的参考，以便在针对Hadoop源代码库构建应用程序时提供什么。本文档主要是Hadoop兼容性指南的精华，因此重点介绍了跨版本的各种Hadoop接口的兼容性保证。</p><p><br><br><br><br><br></p><h2 id="管理兼容指南"><a href="#管理兼容指南" class="headerlink" title="管理兼容指南"></a>管理兼容指南</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/AdminCompatibilityGuide.html" target="_blank" rel="noopener">Apache Hadoop Admin Compatibility Guide</a></p><p><br></p><h3 id="目的-3"><a href="#目的-3" class="headerlink" title="目的"></a>目的</h3><p>本文档的目的是将Hadoop兼容性指南提炼为与系统管理员相关的信息。</p><p>目标受众是负责维护Apache Hadoop集群以及必须规划和执行集群升级的管理员。</p><p><br><br><br></p><h3 id="发行版"><a href="#发行版" class="headerlink" title="发行版"></a>发行版</h3><p>Hadoop Releases</p><p>Hadoop开发社区定期发布新的Hadoop Release，以引入新功能并修复现有问题。发新版分为三类:</p><ul><li><strong>Major</strong>: 主要版本通常包含重要的新功能，通常代表最大的升级兼容性风险。(如 2.8.2 to 3.0.0)</li><li><strong>Minor</strong>: 次要版本通常会包含一些新功能以及针对某些值得注意的问题的修复程序。在大多数情况下，次要版本不应造成太大的升级风险。(如2.8.2 to 2.9.0)</li><li><strong>Maintenance</strong>: 维护版本不应包含任何新功能。维护版本的目的是解决开发人员社区认为足够重要的一组问题，以便推动新版本解决这些问题。维护版本的升级风险很小。(如2.8.2 to 2.8.3)</li></ul><p><br><br><br></p><h3 id="平台依赖"><a href="#平台依赖" class="headerlink" title="平台依赖"></a>平台依赖</h3><p>Platform Dependencies</p><p>Hadoop所依赖的本机组件集被视为Hadoop ABI的一部分。Hadoop开发社区致力于尽可能地保持ABI兼容性。在次要版本之间，除非必要，否则不会增加Hadoop本机依赖项的最低支持版本号，例如安全性或许可问题。</p><p>Hadoop依赖于JVM(Java Virtual Machine)。支持的最低版本的JVM在主要版本的Hadoop之间不会发生变化。</p><p><br><br><br></p><h3 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h3><p>Network</p><p>Hadoop依赖于某些传输层技术，如SSL。除非必要，否则不会增加这些依赖项的最低支持版本，例如安全性或许可问题。</p><p>Hadoop服务端口号将在主要版本中保持不变，但可能会在次要版本中更改。</p><p>Hadoop内部线程协议(wire protocol)将在同一主要版本中的次要版本进行向后和向前兼容，以实现滚动升级。</p><p><br><br><br></p><h3 id="脚本和自动化"><a href="#脚本和自动化" class="headerlink" title="脚本和自动化"></a>脚本和自动化</h3><p>Scripting and Automation</p><p><br></p><h4 id="REST-APIs"><a href="#REST-APIs" class="headerlink" title="REST APIs"></a>REST APIs</h4><p>Hadoop REST APTs提供了一种简单的机制，用于收集有关Hadoop系统状态的信息。为了支持REST客户端，Hadoop REST API是版本化的，并且在版本中不会发生不兼容的更改。<br>REST API版本是单个数字，与Hadoop版本号无关。</p><p><br><br><br></p><h4 id="解析Hadoop输出"><a href="#解析Hadoop输出" class="headerlink" title="解析Hadoop输出"></a>解析Hadoop输出</h4><p>Parsing Hadoop Output</p><p>Hadoop可以生成各种输出，可通过自动化工具进行解析。在使用Hadoop输出时，请考虑一下事项:</p><ul><li>除非解决了正确性问题，否则Hadoop日志输出不会随维护版本而更改</li><li>Hadoop为各种操作生成审计日志(audit log)。审计日志旨在是机器可读，但新纪录和字段的添加被认为是兼容的更改</li><li>Hadoop生成的度量数量(metrics data)主要用于自动化处理。</li></ul><p><br><br><br></p><h4 id="CLIs"><a href="#CLIs" class="headerlink" title="CLIs"></a>CLIs</h4><p>Hadoop的命令行集提供了管理系统各个方面以及发现系统状态信息的能力。请注意，CLI工具输出与CLI工具生成的日志输出不同。日志输出不适合自动消费，可能随时更改。</p><p><br><br><br></p><h4 id="Web-UI"><a href="#Web-UI" class="headerlink" title="Web UI"></a>Web UI</h4><p>Hadoop公开的Web UI供人类使用。</p><p><br><br><br></p><h3 id="状态数据"><a href="#状态数据" class="headerlink" title="状态数据"></a>状态数据</h3><p>Hadoop State Data</p><p>Hadoop内部系统状态是私有的，不应直接被修改。以下策略管理各种内部状态存储的升级特征:</p><ul><li>内部MapReduce状态数据在同一主要版本中的次要版本之间保持兼容，以便在MapReduce工作负载执行时促进滚动升级</li><li>HDFS以版本化的私有内部格式维护存储在HDFS中的数据的元数据。</li><li>AWS S3防护保留了版本化的私有内部元数据存储。不兼容的更改将导致版本号递增。</li><li>YARN 资源管理器保留版本化的应用程序和调度程序信息的内部状态存储。</li><li>YARN联合身份验证服务保留应用程序的私有内部状态存储以及版本化的群集信息。</li></ul><p><br><br><br></p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>Hadoop Configurations</p><p>Hadoop使用两种主要形式的配置文件: XML配置文件和日志记录配置文件。</p><p><br></p><p><strong>XML配置文件</strong></p><p>XML配置文件包含了一组属性作为键值对。属性的名称和含义由Hadoop定义，并保证在次要版本中稳定。属性只能在主要版本中删除，并且只有在至少完整主要版本被标记为已弃用时才能删除。大多数属性都有一个默认值，如果未在XML配置文件中显式设置该属性，则将使用该值。</p><p>下游项目和用户可以将自己的属性添加到XML配置文件中，以供其工具和应用程序使用。虽然Hadoop对定义新属性没有任何正式限制，但与Hadoop定义的属性冲突的新属性可能会导致意外和不良结果。建议用户避免使用与Hadoop定义的属性的名称空间冲突的自定义配置属性名称。</p><p><br></p><p><strong>日志记录配置文件</strong></p><p>Hadoop Daemon和CLI生成的日志输出由一组配置文件控制。这些文件控制将由Hadoop的各个组件输出的最小日志消息级别，以及这些消息的存储位置和方式。</p><p><br></p><p><strong>其它配置文件</strong></p><p>Hadoop使用各种格式的许多其它类型的配置文件，如JSON或XML。</p><p><br><br><br></p><h3 id="发行版-1"><a href="#发行版-1" class="headerlink" title="发行版"></a>发行版</h3><p>Hadoop Distribution</p><p><br></p><p><strong>配置文件</strong></p><p>Hadoop配置文件的位置和一般结构，作业历史信息和Hadoop生成的日志文件将在维护版中得到维护。</p><p><br></p><p><strong>JARs</strong></p><p>Hadoop发行版的内容，如JAR文件可能随时更改，Client artifact除外，不应视为可靠。当前客户端工具有:</p><ul><li>hadoop-client</li><li>hadoop-client-api</li><li>hadoop-client-minicluster</li><li>hadoop-client-runtime</li><li>hadoop-hdfs-client</li><li>hadoop-hdfs-native-client</li><li>hadoop-mapreduce-client-app</li><li>hadoop-mapreduce-client-common</li><li>hadoop-mapreduce-client-core</li><li>hadoop-mapreduce-client-jobclient</li><li>hadoop-mapreduce-client-nativetask</li><li>hadoop-yarn-client</li></ul><p><br></p><p><strong>ENV</strong></p><p>一些Hadoop组件通过环境变量接收信息。</p><p><br></p><p><strong>库依赖</strong></p><p>Hadoop依赖于大量第三方库来运行。</p><p><br></p><p><strong>硬件和系统依赖</strong></p><p>Hadoop目前由运行在x86和AMD处理器上的Linux和Windows上的Hadoop开发人员社区提供支持。<br>无法保证Hadoop守护程序所需的最低资源如何在发行版之间发生变化，甚至是维护版本。<br>任何支持Hadoop的文件系统，例如通过FileSystem API，在大多数情况下将继续在主要版本中得到支持。</p><p><br><br><br><br><br></p><h2 id="接口分类"><a href="#接口分类" class="headerlink" title="接口分类"></a>接口分类</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/InterfaceClassification.html" target="_blank" rel="noopener">Interface Classification</a></p><p><br><br><br><br><br></p><h2 id="文件系统规范"><a href="#文件系统规范" class="headerlink" title="文件系统规范"></a>文件系统规范</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/filesystem/index.html" target="_blank" rel="noopener">The Hadoop FileSystem API Definition</a></p><p>这是Hadoop FS API的规范，它将文件系统的内容建模为一组路径(目录、文件、符号链接)。<br>Unix文件系统有多种规范作为inode树，但没有任何公开定义 <em>Unix文件系统作为数据存储访问的概念模型</em> 的概念。</p><p>该规范视图这样做，定义Hadoop FS模型和API，以便多个文件系统可实现API并向应用程序提供其数据的一致模型。除了记录HDFS所展示的行为之外，它不会尝试正式指定文件系统的任何并发行为，因为这些行为是Hadoop客户端应用程序通常所期望的。</p><p><br></p><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p><br><br><br></p><h3 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h3><p>Notation</p><p><br><br><br></p><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>Model</p><p><br><br><br></p><h3 id="文件系统类"><a href="#文件系统类" class="headerlink" title="文件系统类"></a>文件系统类</h3><p>FileSystem class</p><p><br><br><br></p><h3 id="FSDataInputStream-class"><a href="#FSDataInputStream-class" class="headerlink" title="FSDataInputStream class"></a>FSDataInputStream class</h3><p><br><br><br></p><h3 id="FSDataOutputStreamBuilder-class"><a href="#FSDataOutputStreamBuilder-class" class="headerlink" title="FSDataOutputStreamBuilder class"></a>FSDataOutputStreamBuilder class</h3><p><br><br><br></p><h3 id="使用文件系统规范进行测试"><a href="#使用文件系统规范进行测试" class="headerlink" title="使用文件系统规范进行测试"></a>使用文件系统规范进行测试</h3><p>Testing with the Filesystem specification</p><p><br><br><br></p><h3 id="扩展规范及测试"><a href="#扩展规范及测试" class="headerlink" title="扩展规范及测试"></a>扩展规范及测试</h3><p>Extending the specification and its tests</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="Common"><a href="#Common" class="headerlink" title="Common"></a>Common</h1><p><br></p><h2 id="CLI-MiniCluster"><a href="#CLI-MiniCluster" class="headerlink" title="CLI MiniCluster"></a>CLI MiniCluster</h2><p><br></p><h3 id="目的-4"><a href="#目的-4" class="headerlink" title="目的"></a>目的</h3><p>使用 CLI MiniCluster，用户只需使用一个命令即可启动和停止单节点Hadoop集群，而无需设置任何环境变量或管理配置文件。CLI MiniCluster启用 YARN、MapReduce和HDFS集群。</p><p>这对于希望快速试验Hadoop集群或测试依赖于Hadoop工具的程序的用户来说非常有用。</p><p><br><br><br></p><h3 id="Hadoop-Tarball"><a href="#Hadoop-Tarball" class="headerlink" title="Hadoop Tarball"></a>Hadoop Tarball</h3><p>你要从发行版中获取Hadoop Tarball。此外，你也可以从源直接创建Tarball:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 请首先下载源码包并解压</span></span><br><span class="line"><span class="comment"># tarball在hadoop-dist/target/目录</span></span><br><span class="line"><span class="comment"># cd hadoop-3.2.0-src</span></span><br><span class="line">mvn clean install -DskipTests</span><br><span class="line">mvn package -Pdist -Dtar -DskipTests -Dmaven.javadoc.skip</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="运行MiniCluster"><a href="#运行MiniCluster" class="headerlink" title="运行MiniCluster"></a>运行MiniCluster</h3><p>从提取的Tarball目录内部，你可使用以下命令启动CLI MiniCluster:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># RM_PORT, JHS_PORT应替换为用户对这些端口号的选择，如果未指定，将使用随机空闲端口</span></span><br><span class="line">bin/mapred minicluster -rmport RM_PORT -jhsport JHS_PORT</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 命令行参数</span></span><br><span class="line">$ -D &lt;property=value&gt;    Options to pass into configuration object</span><br><span class="line">$ -datanodes &lt;arg&gt;       How many datanodes to start (default 1)</span><br><span class="line">$ -format                Format the DFS (default <span class="literal">false</span>)</span><br><span class="line">$ -<span class="built_in">help</span>                  Prints option <span class="built_in">help</span>.</span><br><span class="line">$ -jhsport &lt;arg&gt;         JobHistoryServer port (default 0--we choose)</span><br><span class="line">$ -namenode &lt;arg&gt;        URL of the namenode (default is either the DFS</span><br><span class="line">$                        cluster or a temporary dir)</span><br><span class="line">$ -nnport &lt;arg&gt;          NameNode port (default 0--we choose)</span><br><span class="line">$ -nnhttpport &lt;arg&gt;      NameNode HTTP port (default 0--we choose)</span><br><span class="line">$ -nodemanagers &lt;arg&gt;    How many nodemanagers to start (default 1)</span><br><span class="line">$ -nodfs                 Don<span class="string">'t start a mini DFS cluster</span></span><br><span class="line"><span class="string">$ -nomr                  Don'</span>t start a mini MR cluster</span><br><span class="line">$ -rmport &lt;arg&gt;          ResourceManager port (default 0--we choose)</span><br><span class="line">$ -writeConfig &lt;path&gt;    Save configuration to this XML file.</span><br><span class="line">$ -writeDetails &lt;path&gt;   Write basic information to this JSON file.</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="原生库"><a href="#原生库" class="headerlink" title="原生库"></a>原生库</h2><p>Native Libraries Guide</p><p>本节介绍原生(native)Hadoop库，并包含了有关共享库的讨论。</p><p>出于性能原因和Java实现的不可用性，Hadoop具有某些组件的原生实现。这些组件在单个动态链接的本机库可用，称为本机(原生)Hadoop库(<code>libhadoop.so</code>)。</p><p><br></p><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>使用原生Hadoop库相当容易:</p><ul><li>审阅组件</li><li>审阅支持的平台</li><li>下载Hadoop发行版(库名: <code>libhadoop.so</code>)</li><li>安装解码器开发包(<code>&gt;zlib-1.2</code>, <code>&gt;gzip-1.2</code>)</li><li>检查运行日志</li></ul><p><br><br><br></p><h3 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h3><p>原生Hadoop库包括各种组件:</p><ul><li>Compression Codecs (<code>bzip2</code>, <code>lz4</code>, <code>snappy</code>, <code>zlib</code>)</li><li>Native IO utilities for HDFS Short-Circuit Local Reads and Centralized Cache Management in HDFS</li><li>CRC32 checksum implementation</li></ul><p><br><br><br></p><h3 id="支持的平台"><a href="#支持的平台" class="headerlink" title="支持的平台"></a>支持的平台</h3><p>原生Hadoop库主要用于GNU/Linux平台，并在这些发行版上进行测试:</p><ul><li>RHEL4/Fedora</li><li>Ubuntu</li><li>Gentoo</li></ul><p><br><br><br></p><h3 id="构建"><a href="#构建" class="headerlink" title="构建"></a>构建</h3><p>原生Hadoop库使用 ANSI C编写，使用GNU autotools-chain 构建。<br>你需要在目标平台上安装的软件包:</p><ul><li>C compiler (e.g. GNU C Compiler)</li><li>GNU Autools Chain: autoconf, automake, libtool</li><li>zlib-development package (stable version &gt;= 1.2.0)</li><li>openssl-development package(e.g. libssl-dev)</li></ul><p>安装必备软件包后，使用标准的Hadoop <code>Pox.xml</code> 文件来构建原生Hadoop库:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mvn package -Pdist,native -DskipTests -Dtar</span><br><span class="line"></span><br><span class="line"><span class="comment"># You should see the newly-built library in</span></span><br><span class="line">hadoop-dist/target/hadoop-3.2.0/lib/native</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="Runtime"><a href="#Runtime" class="headerlink" title="Runtime"></a>Runtime</h3><p><code>bin/hadoop</code> 脚本通过系统属性(<code>-Djava.library.path=&lt;path&gt;</code>)确保原生Hadoop库位于库路径上。</p><p>在运行时，检查hadoop日志文件以查找MapReduce任务。</p><p><br><br><br></p><h3 id="检查"><a href="#检查" class="headerlink" title="检查"></a>检查</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 原生库检查其检查是否正确加载</span><br><span class="line">hadoop checknative -a</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="Proxy-User"><a href="#Proxy-User" class="headerlink" title="Proxy User"></a>Proxy User</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/Superusers.html" target="_blank" rel="noopener">Proxy user - Superusers Acting On Behalf Of Other Users</a></p><p>本节介绍超级用户(super user)如何代表另一个用户提交作业(submit job)或访问HDFS。</p><p><br></p><h3 id="用例"><a href="#用例" class="headerlink" title="用例"></a>用例</h3><p>用户名为<code>super</code>的超级用户希望代表用户<code>userA</code>提交作业并访问HDFS。某人任务需要以<code>userA</code>身份运行，并且namenode上的任何文件都需要以<code>userA</code>的身份完成。这要求用户<code>userA</code>可连接到使用<code>super</code>用户的kerberos凭据连接到namenode。换句话说，<code>super</code>模仿用户<code>userA</code>。</p><p><br><br><br></p><h3 id="代码栗子"><a href="#代码栗子" class="headerlink" title="代码栗子"></a>代码栗子</h3><p><code>super</code>超级用户的凭据用于登录，并为<code>joe</code>创建代理用户对象。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">//Create ugi for joe. The login user is &apos;super&apos;.</span><br><span class="line">UserGroupInformation ugi =</span><br><span class="line">        UserGroupInformation.createProxyUser(&quot;joe&quot;, UserGroupInformation.getLoginUser());</span><br><span class="line">ugi.doAs(new PrivilegedExceptionAction&lt;Void&gt;() &#123;</span><br><span class="line">  public Void run() throws Exception &#123;</span><br><span class="line">    //Submit a job</span><br><span class="line">    JobClient jc = new JobClient(conf);</span><br><span class="line">    jc.submitJob(conf);</span><br><span class="line">    //OR access hdfs</span><br><span class="line">    FileSystem fs = FileSystem.get(conf);</span><br><span class="line">    fs.mkdir(someFilePath);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h3><p>你可以使用<code>hadoop.proxyuser</code>属性(properties)来配置代理用户。<code>$superuser.hosts</code>以及<code>hadoop.proxyuser.$superuser.groups</code>, <code>hadoop.proxyuser.$superuser.users</code>其中的一个或两个。</p><p>在<code>core-site.xml</code>中，名为<code>super</code>的超级用户只能充<code>host1, host2</code>上进行连接，用于模拟<code>group1</code>, <code>group2</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.proxyuser.super.hosts&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;host1,host2&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.proxyuser.super.groups&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;group1,group2&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><br></p><p>如果需要更为宽松的安全性，则可以使用通配符:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.proxyuser.oozie.hosts&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.proxyuser.oozie.groups&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><br></p><p>当然，它也接受CIDR格式的ip地址范围或主机名:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.proxyuser.super.hosts&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;10.222.0.0/16,10.113.221.221&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.proxyuser.super.users&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;user1,user2&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="警告"><a href="#警告" class="headerlink" title="警告"></a>警告</h3><p>如果集群运行在安全模式(secure mode)下，则超级用户必须具有<code>kerberos</code>凭据才能模拟其他用户。</p><p><br><br><br><br><br></p><h2 id="Rack-Awareness-1"><a href="#Rack-Awareness-1" class="headerlink" title="Rack Awareness"></a>Rack Awareness</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/RackAwareness.html" target="_blank" rel="noopener">Rack Awareness</a></p><p>Hadoop组件具有机架感知功能(rack-aware)。例如，通过将一个块副本(block replica)放在不同的机架上，HDFS块放置将使用机架感知来实现容错(fault tolerance)。可以在网络故障或分区时提供数据可用性。</p><p>Hadoop主守护进程(master daemon)通过调用配置文件指定的<code>external scripts</code>或<code>java class</code>来获取集群工作者的<strong>rack id</strong>。输出必须遵守 java org.apache.hadoop.net.DNSToSwitchMapping interface，接口需要保持一对一的对应关系。</p><p>要使用 java class 进行拓扑映射，类名由配置文件中的 <code>net.topology.node.switch.mapping.impl</code> 参数指定。<br>如果想实现外部脚本，将使用配置文件中的 <code>net.topology.script.file.name</code> 参数指定它。<br>如果 <code>net.topology.script.file.name</code> 或 <code>net.topology.node.switch.mapping.impl</code> 没有设置，则会为任何IP返回机器ID。</p><p><br></p><h3 id="python栗子"><a href="#python栗子" class="headerlink" title="python栗子"></a>python栗子</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># this script makes assumptions about the physical environment.</span></span><br><span class="line"><span class="comment">#  1) each rack is its own layer 3 network with a /24 subnet, which</span></span><br><span class="line"><span class="comment"># could be typical where each rack has its own</span></span><br><span class="line"><span class="comment">#     switch with uplinks to a central core router.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#             +-----------+</span></span><br><span class="line"><span class="comment">#             |core router|</span></span><br><span class="line"><span class="comment">#             +-----------+</span></span><br><span class="line"><span class="comment">#            /             \</span></span><br><span class="line"><span class="comment">#   +-----------+        +-----------+</span></span><br><span class="line"><span class="comment">#   |rack switch|        |rack switch|</span></span><br><span class="line"><span class="comment">#   +-----------+        +-----------+</span></span><br><span class="line"><span class="comment">#   | data node |        | data node |</span></span><br><span class="line"><span class="comment">#   +-----------+        +-----------+</span></span><br><span class="line"><span class="comment">#   | data node |        | data node |</span></span><br><span class="line"><span class="comment">#   +-----------+        +-----------+</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># 2) topology script gets list of IP's as input, calculates network address, and prints '/network_address/ip'.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> netaddr</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.argv.pop(<span class="number">0</span>)                                                  <span class="comment"># discard name of topology script from argv list as we just want IP addresses</span></span><br><span class="line"></span><br><span class="line">netmask = <span class="string">'255.255.255.0'</span>                                        <span class="comment"># set netmask to what's being used in your environment.  The example uses a /24</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ip <span class="keyword">in</span> sys.argv:                                              <span class="comment"># loop over list of datanode IP's</span></span><br><span class="line">    address = <span class="string">'&#123;0&#125;/&#123;1&#125;'</span>.format(ip, netmask)                      <span class="comment"># format address string so it looks like 'ip/netmask' to make netaddr work</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        network_address = netaddr.IPNetwork(address).network     <span class="comment"># calculate and print network address</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">"/&#123;0&#125;"</span>.format(network_address)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"/rack-unknown"</span>                                    <span class="comment"># print catch-all value if unable to calculate network address</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="bash栗子"><a href="#bash栗子" class="headerlink" title="bash栗子"></a>bash栗子</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"><span class="comment"># Here's a bash example to show just how simple these scripts can be</span></span><br><span class="line"><span class="comment"># Assuming we have flat network with everything on a single switch, we can fake a rack topology.</span></span><br><span class="line"><span class="comment"># This could occur in a lab environment where we have limited nodes,like 2-8 physical machines on a unmanaged switch.</span></span><br><span class="line"><span class="comment"># This may also apply to multiple virtual machines running on the same physical hardware.</span></span><br><span class="line"><span class="comment"># The number of machines isn't important, but that we are trying to fake a network topology when there isn't one.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#       +----------+    +--------+</span></span><br><span class="line"><span class="comment">#       |jobtracker|    |datanode|</span></span><br><span class="line"><span class="comment">#       +----------+    +--------+</span></span><br><span class="line"><span class="comment">#              \        /</span></span><br><span class="line"><span class="comment">#  +--------+  +--------+  +--------+</span></span><br><span class="line"><span class="comment">#  |datanode|--| switch |--|datanode|</span></span><br><span class="line"><span class="comment">#  +--------+  +--------+  +--------+</span></span><br><span class="line"><span class="comment">#              /        \</span></span><br><span class="line"><span class="comment">#       +--------+    +--------+</span></span><br><span class="line"><span class="comment">#       |datanode|    |namenode|</span></span><br><span class="line"><span class="comment">#       +--------+    +--------+</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># With this network topology, we are treating each host as a rack.  This is being done by taking the last octet</span></span><br><span class="line"><span class="comment"># in the datanode's IP and prepending it with the word '/rack-'.  The advantage for doing this is so HDFS</span></span><br><span class="line"><span class="comment"># can create its 'off-rack' block copy.</span></span><br><span class="line"><span class="comment"># 1) 'echo $@' will echo all ARGV values to xargs.</span></span><br><span class="line"><span class="comment"># 2) 'xargs' will enforce that we print a single argv value per line</span></span><br><span class="line"><span class="comment"># 3) 'awk' will split fields on dots and append the last field to the string '/rack-'. If awk</span></span><br><span class="line"><span class="comment">#    fails to split on four dots, it will still print '/rack-' last field value</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$@</span> | xargs -n 1 | awk -F <span class="string">'.'</span> <span class="string">'&#123;print "/rack-"$NF&#125;'</span></span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="安全模式"><a href="#安全模式" class="headerlink" title="安全模式"></a>安全模式</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/SecureMode.html" target="_blank" rel="noopener">Hadoop in Secure Mode</a></p><p>本节介绍如何在 <strong>安全模式(secure mode)</strong> 下为Hadoop配置身份认证。当Hadoop配置为以安全模式运行时，Hadoop的每个服务和每个用户都必须由Kerberos进行身份认证。<br>必须正确配置所有服务主机的正向(forward)和反向(reverse)查找，以允许服务互相进行身份验证。可使用DNS或<code>/etc/hosts</code>文件配置主机查找(lookup)。在尝试以安全模式配置Hadoop服务之前，建议先了解Kerberos和DNS的工作知识。</p><p><br><br><br></p><h3 id="认证"><a href="#认证" class="headerlink" title="认证"></a>认证</h3><p>Authentication</p><p><br></p><h4 id="End-User-Accounts"><a href="#End-User-Accounts" class="headerlink" title="End User Accounts"></a>End User Accounts</h4><p>启用服务级别身份验证之后，最终用户必须在与Hadoop服务交互之前进行身份认证。最简单的方式是用户使用<code>kerberos kinit cmd</code>以交互方式进行身份认证，或者使用<code>Kerberos keytab</code>文件的编程身份进行认证。</p><p><br><br><br></p><h4 id="用户账户"><a href="#用户账户" class="headerlink" title="用户账户"></a>用户账户</h4><p>User Accounts for Hadoop Daemons</p><p>确保HDFS和YARN 守护进程以不同的Unix用户运行(如hdfs, yarn)。此外，确保 MapDrduce JobHistory Server以不同的用户运行(如mapred)。<br>建议让他们共享同一个Unix Group。</p><div class="table-container"><table><thead><tr><th>User:Group</th><th>Daemons</th></tr></thead><tbody><tr><td>hdfs:hadoop</td><td>NameNode, Secondary NameNode, JournalNode, DataNode</td></tr><tr><td>yarn:hadoop</td><td>ResourceManager, NodeManager</td></tr><tr><td>mapred:hadoop</td><td>MapReduce JobHistory Server</td></tr></tbody></table></div><p><br><br><br></p><h4 id="Kerberos"><a href="#Kerberos" class="headerlink" title="Kerberos"></a>Kerberos</h4><p>Kerberos principals for Hadoop Daemons</p><p>必须使用其<strong>Kerberos pricipal</strong>和<strong>keytab file</strong>配置每个Hadoop Service 实例。服务准则的一般格式是: <code>ServiceName/_HOST@REALM.TLD. e.g. dn/_HOST@EXAMPLE.COM</code>。</p><p>Hadoop通过允许将服务主体的主机名组件指定为<code>_HOST</code>通配符来简化配置文件的部署。每个服务实例将在运行时使用自己的完全限定主机名替换<code>_HOST</code>。这允许管理员在所有节点上部署同一组配置文件，但 keytab 文件有所不同。</p><p><br></p><p><strong>HDFS</strong></p><p>每个NameNode主机上的<strong>keytab</strong>文件，如下所示:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -e shows the encryption type</span></span><br><span class="line"><span class="comment"># -t shows keytab entry timestamps</span></span><br><span class="line"><span class="comment"># -k specifies keytab</span></span><br><span class="line">klist -e -k -t /etc/security/keytab/nn.service.keytab</span><br><span class="line">Keytab name: FILE:/etc/security/keytab/nn.service.keytab</span><br><span class="line">KVNO Timestamp         Principal</span><br><span class="line">   4 07/18/11 21:08:09 nn/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 nn/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 nn/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br></pre></td></tr></table></figure><p>第二个NameNode主机的<strong>keytab</strong>文件，如下所示:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">klist -e -k -t /etc/security/keytab/sn.service.keytab</span><br><span class="line">Keytab name: FILE:/etc/security/keytab/sn.service.keytab</span><br><span class="line">KVNO Timestamp         Principal</span><br><span class="line">   4 07/18/11 21:08:09 sn/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 sn/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 sn/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br></pre></td></tr></table></figure><p>每台主机上的DataNode的<strong>keytab</strong>文件，如下所示:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">klist -e -k -t /etc/security/keytab/dn.service.keytab</span><br><span class="line">Keytab name: FILE:/etc/security/keytab/dn.service.keytab</span><br><span class="line">KVNO Timestamp         Principal</span><br><span class="line">   4 07/18/11 21:08:09 dn/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 dn/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 dn/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br></pre></td></tr></table></figure><p><br></p><p><strong>YARN</strong></p><p>位于ResourceManager主机上的ResourceManager的<strong>keytab</strong>文件，如下所示:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">klist -e -k -t /etc/security/keytab/rm.service.keytab</span><br><span class="line">Keytab name: FILE:/etc/security/keytab/rm.service.keytab</span><br><span class="line">KVNO Timestamp         Principal</span><br><span class="line">   4 07/18/11 21:08:09 rm/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 rm/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 rm/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br></pre></td></tr></table></figure><p>每台主机上的NodeManager的<strong>keytab</strong>文件，如下所示:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">klist -e -k -t /etc/security/keytab/nm.service.keytab</span><br><span class="line">Keytab name: FILE:/etc/security/keytab/nm.service.keytab</span><br><span class="line">KVNO Timestamp         Principal</span><br><span class="line">   4 07/18/11 21:08:09 nm/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 nm/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 nm/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br></pre></td></tr></table></figure><p><br></p><p><strong>MapReduce JobHistory Server</strong></p><p>该主机上的MapReduce JobHistory Server的<strong>keytab</strong>文件，如下所示:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">klist -e -k -t /etc/security/keytab/jhs.service.keytab</span><br><span class="line">Keytab name: FILE:/etc/security/keytab/jhs.service.keytab</span><br><span class="line">KVNO Timestamp         Principal</span><br><span class="line">   4 07/18/11 21:08:09 jhs/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 jhs/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 jhs/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC)</span><br><span class="line">   4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5)</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="从kerberos映射到系统用户账户"><a href="#从kerberos映射到系统用户账户" class="headerlink" title="从kerberos映射到系统用户账户"></a>从kerberos映射到系统用户账户</h4><p>Mapping from Kerberos principals to OS user accounts</p><p>Hadoop使用<code>hadoop.security.auth_to_local</code>指定的规则将kerberos principal映射到系统账户。Hadoop如何评估这些规则取决于<code>hadoop.security.auth_to_local.mechanism</code>的设置。</p><p>在默认的hadoop模式下，必须将Kerberos主体与将主体转换为简单形式的规则匹配，即不带<code>@, /</code>的用户帐户名，否则将不会授权主体并记录错误。<br>另外，请注意，您不应该将 <code>auth_to_local</code> 规则作为ACL并使用适当的(OS)机制。</p><p><code>auth_to_local</code>可能的值:</p><ul><li><code>RULE:exp</code>, 本地名称将由exp指定</li><li><code>DEFAULT</code>, 当且仅当域与 <code>default_realm</code> 匹配时，才将主体名称的第一个组件选为系统用户名</li></ul><p>请注意，Hadoop不支持多个默认域。此外，Hadoop不会对映射是否存在本地系统帐户进行验证。</p><p><br><br><br></p><h4 id="规则栗子"><a href="#规则栗子" class="headerlink" title="规则栗子"></a>规则栗子</h4><p>Example rules</p><p>在典型的集群中，HDFS和YARN服务将分别作为系统hdfs和yarn用户启动。<code>hadoop.security.auth_to_local</code>可做如下配置:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;</span><br><span class="line">    RULE:[2:$1/$2@$0]([ndj]n/.*@REALM.\TLD)s/.*/hdfs/</span><br><span class="line">    RULE:[2:$1/$2@$0]([rn]m/.*@REALM\.TLD)s/.*/yarn/</span><br><span class="line">    RULE:[2:$1/$2@$0](jhs/.*@REALM\.TLD)s/.*/mapred/</span><br><span class="line">    DEFAULT</span><br><span class="line">  &lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>可以使用 <code>hadoop kerbname</code> 命令测试自定义规则。此命令允许指定主体并应用Hadoop的当前 <code>auth_to_local</code> 规则集。</p><p><br><br><br></p><h4 id="用户到组的映射"><a href="#用户到组的映射" class="headerlink" title="用户到组的映射"></a>用户到组的映射</h4><p>Mapping from user to group</p><p>可以通过 <code>hadoop.security.group.mapping</code> 配置系统用户到系统组的映射机制。<br>实际上，您需要使用Kerberos和LDAP for Hadoop以安全模式管理SSO环境。</p><p><br><br><br></p><h4 id="代理用户"><a href="#代理用户" class="headerlink" title="代理用户"></a>代理用户</h4><p>Proxy user</p><p>Some products such as Apache Oozie which access the services of Hadoop on behalf of end users need to be able to impersonate end users.</p><p><br><br><br></p><h4 id="Secure-DataNode"><a href="#Secure-DataNode" class="headerlink" title="Secure DataNode"></a>Secure DataNode</h4><p>由于DataNode数据传输协议不使用Hadoop RPC框架，因此DataNode必须使用由<code>dfs.datanode.address</code>和<code>dfs.datanode.http.address</code>指定的特权端口对自身进行身份验证。此认证基于以下假设: 攻击者无法在DataNode主机上获得root权限。</p><p>当以root身份执行<code>hdfs datanode</code>命令时，服务进程首先绑定特定端口，然后删除特权并以<code>HDFS_DATANODE_SECURE_USER</code>指定的用户账户运行。此启动过程安装到<code>JSVC_HOME</code>的jsvc程序。你必须在启动时将<code>JDFS_DATANODE_SECURE_USER</code>和<code>JSVC_HOME</code>指定为环境变量。(<code>hadoop-env.sh</code>文件中可配置)</p><p><br><br><br><br><br></p><h3 id="数据机密性"><a href="#数据机密性" class="headerlink" title="数据机密性"></a>数据机密性</h3><p><br></p><h4 id="Data-Encryption-on-RPC"><a href="#Data-Encryption-on-RPC" class="headerlink" title="Data Encryption on RPC"></a>Data Encryption on RPC</h4><p>在Hadoop Service 和 Client之间传输的数据可以在线路上加密。在 <code>core-site.xml</code> 中将 <code>hadoop.rpc.protection</code> 设置为 <code>privacy</code> 可激活数据加密。</p><p><br><br><br></p><h4 id="Data-Encryption-on-Block-data-transfer"><a href="#Data-Encryption-on-Block-data-transfer" class="headerlink" title="Data Encryption on Block data transfer"></a>Data Encryption on Block data transfer</h4><p>需要在 <code>hdfs-site.xml</code> 中将 <code>dfs.encrypt.data.transfer</code> 设置为 <code>true</code>，以便为DataNode 的数据传输协议激活数据加密。</p><p>或者，你可将 <code>dfs.encrypt.data.transfer.algorithm</code> 设置为 <code>3des</code>, <code>rc4</code> 以选择特定的加密算法。如果未指定，则使用系统上配置的JCE默认值(3des)。<br>将 <code>dfs.encrypt.data.transfer.cipher.suites</code> 设置为 <code>AES/CTR/NoPadding</code> 可激活AES加密。默认未指定，也就是不使用AES。使用AES时，在初始密钥交换期间仍会使用 <code>dfs.encrypt.dta.transfer.algorithm</code>的算法。可通过将 <code>dfs.encrypt.data.transfer.cipher.key.bitlength</code> 设置为128, 192, 256来配置AES密钥位长度(默认128)</p><p>AES提供最大的加密强度和最佳性能。目前，3DES和RC4在Hadoop集群中的使用频率更高。</p><p><br><br><br></p><h4 id="Data-Encryption-on-HTTP"><a href="#Data-Encryption-on-HTTP" class="headerlink" title="Data Encryption on HTTP"></a>Data Encryption on HTTP</h4><p>web-console和client之间的数据传输使用SSL(HTTPS)保护。在使用Kerberos配置Hadoop安全时，推荐使用SLL，但不是必须。</p><p>要为HDFS Daemon的 web-console 启用SSL，将<code>hdfs-site.xml</code>文件中的<code>dfs.http.policy</code>设置为<code>HTTPS_ONLY</code>或<code>HTTP_AND_HTTPS</code>两者之一。<br>要为YARN Daemon的 web-console 启用SSL，将<code>yarn-site.xml</code>文件中的<code>yarn.http.policy</code>设置为<code>HTTPS_ONLY</code>。<br>要为MapReduce JobHistory Server的 web-console 启用SSL，将<code>mapred-site.xml</code>文件中的<code>mapreduce.jobhistory.http.policy</code>设置为<code>HTTPS_ONLY</code>。</p><p><br><br><br></p><h3 id="配置-2"><a href="#配置-2" class="headerlink" title="配置"></a>配置</h3><p><br></p><h4 id="HDFS和本地文件系统路径的权限"><a href="#HDFS和本地文件系统路径的权限" class="headerlink" title="HDFS和本地文件系统路径的权限"></a>HDFS和本地文件系统路径的权限</h4><p>Permissions for both HDFS and local fileSystem paths</p><p>下表列出了HDFS和本地文件系统的各种路径，建议权限为:</p><div class="table-container"><table><thead><tr><th>Filesystem</th><th>Path</th><th>User:Group</th><th>Permissions</th></tr></thead><tbody><tr><td>local</td><td><code>dfs.namenode.name.dir</code></td><td>hdfs:hadoop</td><td>drwx———</td></tr><tr><td>local</td><td><code>dfs.datanode.data.dir</code></td><td>hdfs:hadoop</td><td>drwx———</td></tr><tr><td>local</td><td><code>$HADOOP_LOG_DIR</code></td><td>hdfs:hadoop</td><td>drwxrwxr-x</td></tr><tr><td>local</td><td><code>$YARN_LOG_DIR</code></td><td>yarn:hadoop</td><td>drwxrwxr-x</td></tr><tr><td>local</td><td><code>yarn.nodemanager.local-dirs</code></td><td>yarn:hadoop</td><td>drwxr-xr-x</td></tr><tr><td>local</td><td><code>yarn.nodemanager.log-dirs</code></td><td>yarn:hadoop</td><td>drwxr-xr-x</td></tr><tr><td>local</td><td><code>container-executor</code></td><td>root:hadoop</td><td>—Sr-s—*</td></tr><tr><td>local</td><td><code>conf/container-executor.cfg</code></td><td>root:hadoop</td><td>r———-*</td></tr><tr><td>hdfs</td><td><code>/</code></td><td>hdfs:hadoop</td><td>drwxr-xr-x</td></tr><tr><td>hdfs</td><td><code>/tmp</code></td><td>hdfs:hadoop</td><td>drwxrwxrwxt</td></tr><tr><td>hdfs</td><td><code>/user</code></td><td>hdfs:hadoop</td><td>drwxr-xr-x</td></tr><tr><td>hdfs</td><td><code>yarn.nodemanager.remote-app-log-dir</code></td><td>yarn:hadoop</td><td>drwxrwxrwxt</td></tr><tr><td>hdfs</td><td><code>mapreduce.jobhistory.intermediate-done-dir</code></td><td>mapred:hadoop</td><td>drwxrwxrwxt</td></tr><tr><td>hdfs</td><td><code>mapreduce.jobhistory.done-dir</code></td><td>mapred:hadoop</td><td>drwxr-x—-</td></tr></tbody></table></div><p><br><br><br></p><h4 id="常见配置"><a href="#常见配置" class="headerlink" title="常见配置"></a>常见配置</h4><p>要在Hadoop中启用RPC身份认证，请将<code>hadoop.security.authentication</code>属性设置为<code>kerberos</code>，并适当地设置下面列出的安全相关的配置。</p><p>以下属性应位于集群中所有节点的<code>core-site.xml</code>中:</p><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>hadoop.security.authentication</code></td><td><code>kerberos</code></td><td>simple : No authentication. (default)  kerberos : Enable authentication by Kerberos.</td></tr><tr><td><code>hadoop.security.authorization</code></td><td><code>true</code></td><td>Enable RPC service-level authorization.</td></tr><tr><td><code>hadoop.rpc.protection</code></td><td><code>authentication</code></td><td>authentication : authentication only (default); integrity : integrity check in addition to authentication; privacy : data encryption in addition to integrity</td></tr><tr><td><code>hadoop.security.auth_to_local</code></td><td><code>RULE:exp1 RULE:exp2 … DEFAULT</code></td><td>The value is string containing new line characters. See Kerberos documentation for the format of exp.</td></tr><tr><td><code>hadoop.proxyuser.superuser.hosts</code></td><td>-</td><td>comma separated hosts from which superuser access are allowed to impersonation. * means wildcard.</td></tr><tr><td><code>hadoop.proxyuser.superuser.groups</code></td><td>-</td><td>comma separated groups to which users impersonated by superuser belong. * means wildcard.</td></tr></tbody></table></div><p><br><br><br></p><h4 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h4><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>dfs.block.access.token.enable</code></td><td><code>true</code></td><td>Enable HDFS block access tokens for secure operations.</td></tr><tr><td><code>dfs.namenode.kerberos.principal</code></td><td><code>nn/_HOST@REALM.TLD</code></td><td>Kerberos principal name for the NameNode.</td></tr><tr><td><code>dfs.namenode.keytab.file</code></td><td><code>/etc/security/keytab/nn.service.keytab</code></td><td>Kerberos keytab file for the NameNode.</td></tr><tr><td><code>dfs.namenode.kerberos.internal.spnego.principal</code></td><td><code>HTTP/_HOST@REALM.TLD</code></td><td>The server principal used by the NameNode for web UI SPNEGO authentication. The SPNEGO server principal begins with the prefix HTTP/ by convention. If the value is ‘*’, the web server will attempt to login with every principal specified in the keytab file dfs.web.authentication.kerberos.keytab. For most deployments this can be set to ${dfs.web.authentication.kerberos.principal} i.e use the value of dfs.web.authentication.kerberos.principal.</td></tr><tr><td><code>dfs.web.authentication.kerberos.keytab</code></td><td><code>/etc/security/keytab/spnego.service.keytab</code></td><td>SPNEGO keytab file for the NameNode. In HA clusters this setting is shared with the Journal Nodes.</td></tr></tbody></table></div><p>以下设置允许配置对NameNode Web UI的SSL访问(可选):</p><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>dfs.http.policy</code></td><td><code>HTTP_ONLY</code> or <code>HTTPS_ONLY</code> or <code>HTTP_AND_HTTPS</code></td><td>HTTPS_ONLY turns off http access. This option takes precedence over the deprecated configuration dfs.https.enable and hadoop.ssl.enabled. If using SASL to authenticate data transfer protocol instead of running DataNode as root and using privileged ports, then this property must be set to HTTPS_ONLY to guarantee authentication of HTTP servers. (See dfs.data.transfer.protection.)</td></tr><tr><td><code>dfs.namenode.https-address</code></td><td><code>0.0.0.0:9871</code></td><td>This parameter is used in non-HA mode and without federation. See HDFS High Availability and HDFS Federation for details.</td></tr><tr><td><code>dfs.https.enable</code></td><td><code>true</code></td><td>This value is deprecated. Use dfs.http.policy</td></tr></tbody></table></div><p><br><br><br></p><h4 id="Secondary-NameNode"><a href="#Secondary-NameNode" class="headerlink" title="Secondary NameNode"></a>Secondary NameNode</h4><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>dfs.namenode.secondary.http-address</code></td><td><code>0.0.0.0:9868</code></td><td>HTTP web UI address for the Secondary NameNode.</td></tr><tr><td><code>dfs.namenode.secondary.https-address</code></td><td><code>0.0.0.0:9869</code></td><td>HTTPS web UI address for the Secondary NameNode.</td></tr><tr><td><code>dfs.secondary.namenode.keytab.file</code></td><td><code>/etc/security/keytab/sn.service.keytab</code></td><td>Kerberos keytab file for the Secondary NameNode.</td></tr><tr><td><code>dfs.secondary.namenode.kerberos.principal</code></td><td><code>sn/_HOST@REALM.TLD</code></td><td>Kerberos principal name for the Secondary NameNode.</td></tr><tr><td><code>dfs.secondary.namenode.kerberos.internal.spnego.principal</code></td><td><code>HTTP/_HOST@REALM.TLD</code></td><td>The server principal used by the Secondary NameNode for web UI SPNEGO authentication. The SPNEGO server principal begins with the prefix HTTP/ by convention. If the value is ‘*’, the web server will attempt to login with every principal specified in the keytab file dfs.web.authentication.kerberos.keytab. For most deployments this can be set to ${dfs.web.authentication.kerberos.principal} i.e use the value of dfs.web.authentication.kerberos.principal.</td></tr></tbody></table></div><p><br><br><br></p><h4 id="JournalNode"><a href="#JournalNode" class="headerlink" title="JournalNode"></a>JournalNode</h4><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>dfs.journalnode.kerberos.principal</code></td><td><code>jn/_HOST@REALM.TLD</code></td><td>Kerberos principal name for the JournalNode.</td></tr><tr><td><code>dfs.journalnode.keytab.file</code></td><td><code>/etc/security/keytab/jn.service.keytab</code></td><td>Kerberos keytab file for the JournalNode.</td></tr><tr><td><code>dfs.journalnode.kerberos.internal.spnego.principal</code></td><td><code>HTTP/_HOST@REALM.TLD</code></td><td>The server principal used by the JournalNode for web UI SPNEGO authentication when Kerberos security is enabled. The SPNEGO server principal begins with the prefix HTTP/ by convention. If the value is ‘*’, the web server will attempt to login with every principal specified in the keytab file dfs.web.authentication.kerberos.keytab. For most deployments this can be set to ${dfs.web.authentication.kerberos.principal} i.e use the value of dfs.web.authentication.kerberos.principal.</td></tr><tr><td><code>dfs.web.authentication.kerberos.keytab</code></td><td><code>/etc/security/keytab/spnego.service.keytab</code></td><td>SPNEGO keytab file for the JournalNode. In HA clusters this setting is shared with the Name Nodes.</td></tr><tr><td><code>dfs.journalnode.https-address</code></td><td><code>0.0.0.0:8481</code></td><td>HTTPS web UI address for the JournalNode.</td></tr></tbody></table></div><p><br><br><br></p><h4 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h4><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>dfs.datanode.data.dir.perm</code></td><td><code>700</code></td><td>-</td></tr><tr><td><code>dfs.datanode.address</code></td><td><code>0.0.0.0:1004</code></td><td>Secure DataNode must use privileged port in order to assure that the server was started securely. This means that the server must be started via jsvc. Alternatively, this must be set to a non-privileged port if using SASL to authenticate data transfer protocol. (See dfs.data.transfer.protection.)</td></tr><tr><td><code>dfs.datanode.http.address</code></td><td><code>0.0.0.0:1006</code></td><td>Secure DataNode must use privileged port in order to assure that the server was started securely. This means that the server must be started via jsvc.</td></tr><tr><td><code>dfs.datanode.https.address</code></td><td><code>0.0.0.0:9865</code></td><td>HTTPS web UI address for the Data Node.</td></tr><tr><td><code>dfs.datanode.kerberos.principal</code></td><td><code>dn/_HOST@REALM.TLD</code></td><td>Kerberos principal name for the DataNode.</td></tr><tr><td><code>dfs.datanode.keytab.file</code></td><td><code>/etc/security/keytab/dn.service.keytab</code></td><td>Kerberos keytab file for the DataNode.</td></tr><tr><td><code>dfs.encrypt.data.transfer</code></td><td><code>false</code></td><td>set to true when using data encryption</td></tr><tr><td><code>dfs.encrypt.data.transfer.algorithm</code></td><td>-</td><td>optionally set to 3des or rc4 when using data encryption to control encryption algorithm</td></tr><tr><td><code>dfs.encrypt.data.transfer.cipher.suites</code></td><td>-</td><td>optionally set to AES/CTR/NoPadding to activate AES encryption when using data encryption</td></tr><tr><td><code>dfs.encrypt.data.transfer.cipher.key.bitlength</code></td><td>-</td><td>optionally set to 128, 192 or 256 to control key bit length when using AES with data encryption</td></tr><tr><td><code>dfs.data.transfer.protection</code></td><td>-</td><td>authentication : authentication only; integrity : integrity check in addition to authentication; privacy : data encryption in addition to integrity This property is unspecified by default. Setting this property enables SASL for authentication of data transfer protocol. If this is enabled, then dfs.datanode.address must use a non-privileged port, dfs.http.policy must be set to HTTPS_ONLY and the HDFS_DATANODE_SECURE_USER environment variable must be undefined when starting the DataNode process.</td></tr></tbody></table></div><p><br><br><br></p><h4 id="WebHDFS"><a href="#WebHDFS" class="headerlink" title="WebHDFS"></a>WebHDFS</h4><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>dfs.web.authentication.kerberos.principal</code></td><td><code>http/_HOST@REALM.TLD</code></td><td>Kerberos principal name for the WebHDFS. In HA clusters this setting is commonly used by the JournalNodes for securing access to the JournalNode HTTP server with SPNEGO.</td></tr><tr><td><code>dfs.web.authentication.kerberos.keytab</code></td><td><code>/etc/security/keytab/http.service.keytab</code></td><td>Kerberos keytab file for WebHDFS. In HA clusters this setting is commonly used the JournalNodes for securing access to the JournalNode HTTP server with SPNEGO.</td></tr></tbody></table></div><p><br><br><br></p><h4 id="ResourceManager"><a href="#ResourceManager" class="headerlink" title="ResourceManager"></a>ResourceManager</h4><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>yarn.resourcemanager.principal</code></td><td><code>rm/_HOST@REALM.TLD</code></td><td>Kerberos principal name for the ResourceManager.</td></tr><tr><td><code>yarn.resourcemanager.keytab</code></td><td><code>/etc/security/keytab/rm.service.keytab</code></td><td>Kerberos keytab file for the ResourceManager.</td></tr><tr><td><code>yarn.resourcemanager.webapp.https.address</code></td><td><code>${yarn.resourcemanager.hostname}:8090</code></td><td>The https adddress of the RM web application for non-HA. In HA clusters, use yarn.resourcemanager.webapp.https.address.rm-id for each ResourceManager. See ResourceManager High Availability for details.</td></tr></tbody></table></div><p><br><br><br></p><h4 id="NodeManager"><a href="#NodeManager" class="headerlink" title="NodeManager"></a>NodeManager</h4><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>yarn.nodemanager.principal</code></td><td><code>nm/_HOST@REALM.TLD</code></td><td>Kerberos principal name for the NodeManager.</td></tr><tr><td><code>yarn.nodemanager.keytab</code></td><td><code>/etc/security/keytab/nm.service.keytab</code></td><td>Kerberos keytab file for the NodeManager.</td></tr><tr><td><code>yarn.nodemanager.container-executor.class</code></td><td><code>org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor</code></td><td>Use LinuxContainerExecutor.</td></tr><tr><td><code>yarn.nodemanager.linux-container-executor.group</code></td><td><code>hadoop</code></td><td>Unix group of the NodeManager.</td></tr><tr><td><code>yarn.nodemanager.linux-container-executor.path</code></td><td><code>/path/to/bin/container-executor</code></td><td>The path to the executable of Linux container executor.</td></tr><tr><td><code>yarn.nodemanager.webapp.https.address</code></td><td><code>0.0.0.0:8044</code></td><td>The https adddress of the NM web application.</td></tr></tbody></table></div><p><br><br><br></p><h4 id="Configuration-for-WebAppProxy"><a href="#Configuration-for-WebAppProxy" class="headerlink" title="Configuration for WebAppProxy"></a>Configuration for WebAppProxy</h4><p>WebAppProxy在应用程序和用户导出的Web应用程序之间提供代理。如果启用了安全性，它将在访问可能不安全的Web应用程序之前警告用户。使用代理的身份验证和授权与任何其他特权Web应用程序一样处理。</p><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>yarn.web-proxy.address</code></td><td>WebAppProxy host:port for proxy to AM web apps.</td><td>host:port if this is the same as yarn.resourcemanager.webapp.address or it is not defined then the ResourceManager will run the proxy otherwise a standalone proxy server will need to be launched.</td></tr><tr><td><code>yarn.web-proxy.keytab</code></td><td><code>/etc/security/keytab/web-app.service.keytab</code></td><td>Kerberos keytab file for the WebAppProxy.</td></tr><tr><td><code>yarn.web-proxy.principal</code></td><td><code>wap/_HOST@REALM.TLD</code></td><td>Kerberos principal name for the WebAppProxy.</td></tr></tbody></table></div><p><br><br><br></p><h4 id="LinuxContainerExecutor"><a href="#LinuxContainerExecutor" class="headerlink" title="LinuxContainerExecutor"></a>LinuxContainerExecutor</h4><p>YARN框架使用的ContainerExecutor，用于定义任何容器的启动和控制方式。</p><p>以下是Hadoop YARN中可用内容:</p><div class="table-container"><table><thead><tr><th>ContainerExecutor</th><th>Description</th></tr></thead><tbody><tr><td>DefaultContainerExecutor</td><td>The default executor which YARN uses to manage container execution. The container process has the same Unix user as the NodeManager.</td></tr><tr><td>LinuxContainerExecutor</td><td>Supported only on GNU/Linux, this executor runs the containers as either the YARN user who submitted the application (when full security is enabled) or as a dedicated user (defaults to nobody) when full security is not enabled. When full security is enabled, this executor requires all user accounts to be created on the cluster nodes where the containers are launched. It uses a setuid executable that is included in the Hadoop distribution. The NodeManager uses this executable to launch and kill containers. The setuid executable switches to the user who has submitted the application and launches or kills the containers. For maximum security, this executor sets up restricted permissions and user/group ownership of local files and directories used by the containers such as the shared objects, jars, intermediate files, log files etc. Particularly note that, because of this, except the application owner and NodeManager, no other user can access any of the local files/directories including those localized as part of the distributed cache.</td></tr></tbody></table></div><p><br></p><p>要构建LinuxContainerExecutor可执行:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 集群配置文件路径</span></span><br><span class="line">mvn package -Dcontainer-executor.conf.dir=/opt/hadoop/etc/hadoop/</span><br></pre></td></tr></table></figure><p>LinuxTaskController 要求包含和导向 <code>yarn.nodemanager.local-dirs</code> 和 <code>yarn.nodemanager.log-dirs</code> 中指定的目录的路径设置为755权限。</p><p><br></p><p>可执行文件需要一个名为<code>container-executor.cfg(conf/container-executor.cfg)</code>的配置文件，该文件存在于上述mvn的目标配置目录里。该配置文件必须有NodeNanager的用户所有，权限应为<code>0400</code>。<br>可执行文件要求此配置文件存在以下配置项(KV):</p><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td>yarn.nodemanager.linux-container-executor.group</td><td>hadoop</td><td>Unix group of the NodeManager. The group owner of the container-executor binary should be this group. Should be same as the value with which the NodeManager is configured. This configuration is required for validating the secure access of the container-executor binary.</td></tr><tr><td>banned.users</td><td>hdfs,yarn,mapred,bin</td><td>Banned users.</td></tr><tr><td>allowed.system.users</td><td>foo,bar</td><td>Allowed system users.</td></tr><tr><td>min.user.id</td><td>1000</td><td>Prevent other super-users.</td></tr></tbody></table></div><p><br></p><p>以下是与LinuxContainerExecutor相关的各种路径所需的本地文件系统权限：</p><div class="table-container"><table><thead><tr><th>Filesystem</th><th>Path</th><th>User:Group</th><th>Permissions</th></tr></thead><tbody><tr><td><code>local</code></td><td><code>container-executor</code></td><td>root:hadoop</td><td>—Sr-s—*</td></tr><tr><td><code>local</code></td><td><code>conf/container-executor.cfg</code></td><td>root:hadoop</td><td>r———-*</td></tr><tr><td><code>local</code></td><td><code>yarn.nodemanager.local-dirs</code></td><td>yarn:hadoop</td><td>drwxr-xr-x</td></tr><tr><td><code>local</code></td><td><code>yarn.nodemanager.log-dirs</code></td><td>yarn:hadoop</td><td>drwxr-xr-x</td></tr></tbody></table></div><p><br><br><br></p><h4 id="MapReduce-JobHistory-Server"><a href="#MapReduce-JobHistory-Server" class="headerlink" title="MapReduce JobHistory Server"></a>MapReduce JobHistory Server</h4><div class="table-container"><table><thead><tr><th>Parameter</th><th>Value</th><th>Notes</th></tr></thead><tbody><tr><td><code>mapreduce.jobhistory.address</code></td><td>MapReduce JobHistory Server <code>host:port</code></td><td>Default port is 10020.</td></tr><tr><td><code>mapreduce.jobhistory.keytab</code></td><td><code>/etc/security/keytab/jhs.service.keytab</code></td><td>Kerberos keytab file for the MapReduce JobHistory Server.</td></tr><tr><td><code>mapreduce.jobhistory.principal</code></td><td><code>jhs/_HOST@REALM.TLD</code></td><td>Kerberos principal name for the MapReduce JobHistory Server.</td></tr></tbody></table></div><p><br><br><br><br><br></p><h3 id="Multihoming"><a href="#Multihoming" class="headerlink" title="Multihoming"></a>Multihoming</h3><p>多宿主设置，其中每个主机在DNS中具有多个主机名(如，对应于公共和专用网络接口的不同主机名)。可能需要额外的配置才能使Kerberos身份认证工作。</p><p><br><br><br></p><h3 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h3><p>Kerberos is hard to set up，and harder to debug。常见问题有:</p><ul><li>Network and DNS configuration</li><li>Kerberos configuration on hosts (<code>/etc/krb5.conf</code>)</li><li>Keytab creation and maintenance</li><li>Environment setup: JVM, user login, system clocks, etc</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Set the environment variable HADOOP_JAAS_DEBUG to true</span><br><span class="line">export HADOOP_JAAS_DEBUG=true</span><br><span class="line"></span><br><span class="line"># Edit the log4j.properties file to log Hadoop’s security package at DEBUG level</span><br><span class="line">log4j.logger.org.apache.hadoop.security=DEBUG</span><br><span class="line"></span><br><span class="line"># Enable JVM-level debugging by setting some system properties</span><br><span class="line">export HADOOP_OPTS=&quot;-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug&quot;</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="KDiag"><a href="#KDiag" class="headerlink" title="KDiag"></a>KDiag</h3><p>Troubleshooting with KDiag</p><p>Hadoop有一个工具来帮助验证设置：<strong>KDiag</strong>。</p><p>它包含一系列用于JVM配置和环境的探测器，转储出一些系统文件（<code>/etc/krb5.conf</code>, <code>/etc/ntp.conf</code>），打印出一些系统状态，然后尝试登录到Kerberos作为当前用户或命名密钥表中的特定主体。<br>该命令的输出可用于本地诊断，或转发给支持群集的任何人。<br>KDiag命令有自己的入口点，通过将kdiag传递给<code>hadoop</code>命令来调用它。因此，它将显示用于调用它的命令的kerberos客户端状态。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">hadoop kdiag</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 帮助</span></span><br><span class="line">bin/hadoop kdiag --<span class="built_in">help</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 栗子</span></span><br><span class="line">hadoop kdiag \</span><br><span class="line">  --nofail \</span><br><span class="line">  --resource hdfs-site.xml --resource yarn-site.xml \</span><br><span class="line">  --keylen 1024 \</span><br><span class="line">  --keytab zk.service.keytab --principal zookeeper/devix.example.org@REALM</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="关闭安全模式"><a href="#关闭安全模式" class="headerlink" title="关闭安全模式"></a>关闭安全模式</h3><p>Hadoop Secure Mode默认是开启的！</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看</span></span><br><span class="line"><span class="comment"># bin/hadoop dfsadmin -safemode get(旧)</span></span><br><span class="line">bin/hdfs dfsadmin -safemode get</span><br><span class="line">Safe mode is ON</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭</span></span><br><span class="line"><span class="comment"># bin/hdfs dfsadmin -safemode leave(旧)</span></span><br><span class="line">bin/hdfs dfsadmin -safemode  leave</span><br><span class="line">Safe mode is OFF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用</span></span><br><span class="line"><span class="comment"># bin/hdfs dfsadmin -safemode enter(旧)</span></span><br><span class="line">bin/hdfs dfsadmin -safemode enter</span><br><span class="line">Safe mode is ON</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="服务级别授权"><a href="#服务级别授权" class="headerlink" title="服务级别授权"></a>服务级别授权</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/ServiceLevelAuth.html" target="_blank" rel="noopener">Service Level Authorization Guide</a></p><p>本节描述了如何配置和管理Hadoop服务级别的授权(Service Level Authorization)。</p><p><br></p><p><strong>Prerequisites:</strong></p><p>确已正确安装、配置和设置Hadoop！</p><p><br></p><h3 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h3><p>服务级别授权是初始化授权机制，用于确保连接到特定的Hadoop服务的客户端具有必要的预配置设置，并且有权访问给定服务。例如，MapReduce集群可以使用此机制来允许已配置的用户/组列表提交作业。</p><p><code>$HADOOP_CONF_DIR/hadoop-policy.xml</code>配置文件用于定义各种Hadoop服务的访问控制列表(ACL)。<br>服务级别授权在其他访问控制检查之前执行很久，例如文件权限检查，作业队列上的访问控制等。</p><p><br><br><br></p><h3 id="配置-3"><a href="#配置-3" class="headerlink" title="配置"></a>配置</h3><p>通过配置文件<code>$HADOOP_CONF_DIR/hadoop-policy.xml</code>配置服务级别的授权。</p><p><br></p><h4 id="启用服务级别授权"><a href="#启用服务级别授权" class="headerlink" title="启用服务级别授权"></a>启用服务级别授权</h4><p>Enable Service Level Authorization</p><p>默认情况下，Hadoop禁用服务级别授权。要启用它，请在<code>$HADOOP_CONF_DIR/core-site.xml</code>中将配置属性<code>hadoop.security.authorization</code>设置为<code>true</code>。</p><p><br><br><br></p><h4 id="Hadoop服务和配置项"><a href="#Hadoop服务和配置项" class="headerlink" title="Hadoop服务和配置项"></a>Hadoop服务和配置项</h4><p>Hadoop Services and Configuration Properties</p><p>下面列出各种Hadoop服务及其配置项:</p><div class="table-container"><table><thead><tr><th>Property</th><th>Service</th></tr></thead><tbody><tr><td><code>security.client.protocol.acl</code></td><td>ACL for ClientProtocol, which is used by user code via the DistributedFileSystem.</td></tr><tr><td><code>security.client.datanode.protocol.acl</code></td><td>ACL for ClientDatanodeProtocol, the client-to-datanode protocol for block recovery.</td></tr><tr><td><code>security.datanode.protocol.acl</code></td><td>ACL for DatanodeProtocol, which is used by datanodes to communicate with the namenode.</td></tr><tr><td><code>security.inter.datanode.protocol.acl</code></td><td>ACL for InterDatanodeProtocol, the inter-datanode protocol for updating generation timestamp.</td></tr><tr><td><code>security.namenode.protocol.acl</code></td><td>ACL for NamenodeProtocol, the protocol used by the secondary namenode to communicate with the namenode.</td></tr><tr><td><code>security.job.client.protocol.acl</code></td><td>ACL for JobSubmissionProtocol, used by job clients to communciate with the resourcemanager for job submission, querying job status etc.</td></tr><tr><td><code>security.job.task.protocol.acl</code></td><td>ACL for TaskUmbilicalProtocol, used by the map and reduce tasks to communicate with the parent nodemanager.</td></tr><tr><td><code>security.refresh.policy.protocol.acl</code></td><td>ACL for RefreshAuthorizationPolicyProtocol, used by the dfsadmin and rmadmin commands to refresh the security policy in-effect.</td></tr><tr><td><code>security.ha.service.protocol.acl</code></td><td>ACL for HAService protocol used by HAAdmin to manage the active and stand-by states of namenode.</td></tr></tbody></table></div><p><br><br><br></p><h4 id="访问控制列表"><a href="#访问控制列表" class="headerlink" title="访问控制列表"></a>访问控制列表</h4><p>Access Control Lists</p><p><code>$HADOOP_CONF_DIR/hadoop-policy.xml</code>为每个Hadoop服务定义一个访问控制列表。</p><p>每个访问控制列表都有一个简单的格式: users/groups都是用逗号分隔的名称列表。如: <code>user1, user2, group1, group2</code></p><p>如果仅提供组列表，则在行的开头添加空格，等效地以逗号分隔的用户列表后跟空格或不显示仅包含一组给定用户。特殊值<code>*</code>表示允许所有用户访问该服务。如果未为服务定义访问控制列表，则应用<code>security.service.authorization.default.acl</code> 的值。如果未定义 <code>security.service.authorization.default.acl</code>，则应用<code>*</code>。</p><p><br><br><br></p><h4 id="被阻止的访问控制列表"><a href="#被阻止的访问控制列表" class="headerlink" title="被阻止的访问控制列表"></a>被阻止的访问控制列表</h4><p>Blocked Access Control Lists</p><p>在某些情况下，需要为服务指定阻止的访问控制列表。这指定了未授权访问该服务的用户和组的列表。被阻止的访问控制列表的格式与访问控制列表的格式相同。<br>可通过<code>$HADOOP_CONF_DIR/hadoop-policy.xml</code>指定阻止的访问控制列表。属性名称通过后缀<code>.blocked</code>派生。栗子: <code>security.client.protocol.acl</code> 的阻止访问控制列表的属性名称为<code>security.client.protocol.acl.blocked</code> 。</p><p>对于服务，可以指定访问控制列表和阻止的控制列表。如果用户在访问控制中而不在阻止的访问控制列表中，则授权用户访问该服务。</p><p>如果未为服务定义阻止访问控制列表，则应用 <code>security.service.authorization.default.acl.blocked</code> 的值。如果未定义 <code>security.service.authorization.default.acl.blocked</code>，则应用空的阻止访问控制列表。</p><p><br><br><br></p><h4 id="IP地址，主机名，IP范围进行访问控制"><a href="#IP地址，主机名，IP范围进行访问控制" class="headerlink" title="IP地址，主机名，IP范围进行访问控制"></a>IP地址，主机名，IP范围进行访问控制</h4><p>Access Control using Lists of IP Addresses, Host Names and IP Ranges</p><p>可以基于访问服务的客户端IP地址来控制对服务的访问。通过指定IP地址，主机名和IP范围列表，可以限制从一组计算机访问服务。每个服务的属性名称都是从相应的acl属性名称派生的。如果acl的属性名称为<code>security.client.protocol.acl</code>，则hosts列表的属性名称为 <code>security.client.protocol.hosts</code>。<br>如果未为服务定义主机列表，则应用 <code>security.service.authorization.default.hosts</code> 的值。如果未定义 <code>security.service.authorization.default.hosts</code>，则应用 <code>*</code> 。</p><p>可以指定阻止的主机列表。只有那些位于主机列表中但未在阻止主机列表中的计算机才会被授予对该服务的访问权限。属性名称通过后缀 <code>.blocked</code> 派生。栗子: <code>security.client.protocol.hosts</code> 的被阻止主机列表的属性名称为 <code>security.client.protocol.hosts.blocked</code>。<br>如果未为服务定义阻止主机列表，则应用 <code>security.service.authorization.default.hosts.blocked</code> 的值。如果未定义 <code>security.service.authorization.default.hosts.blocked</code>，则应用空的阻止主机列表。</p><p><br><br><br></p><h4 id="刷新服务级别授权配置"><a href="#刷新服务级别授权配置" class="headerlink" title="刷新服务级别授权配置"></a>刷新服务级别授权配置</h4><p>Refreshing Service Level Authorization Configuration</p><p>可在不重启Hadoop Daemon的情况下更改NameNode和ResourceManager的服务级别授权配置。集群管理员可在Master节点上更改<code>$HADOOP_CONF_DIR/hadoop-policy.xml</code>，并指示NameNode和ResourceManager分别通过<code>-refreshServiceAcl</code>开关将其各自的配置重新加载到<code>dfsadmin</code>和<code>rmadmin</code>命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 刷新NameNode的服务级别的授权配置</span></span><br><span class="line">bin/hdfs dfsadmin -refreshServiceAcl</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 刷新ResourceManager的服务级别授权配置</span></span><br><span class="line">bin/yarn rmadmin -refreshServiceAcl</span><br></pre></td></tr></table></figure><p>当然，也可以使用<code>$HADOOP_CONF_DIR/hadoop-policy.xml</code>中的<code>security.refresh.policy.protocol.acl</code>属性来限制对某些users/groups刷新服务级别授权的访问权限。</p><p><br><br><br></p><h4 id="栗子"><a href="#栗子" class="headerlink" title="栗子"></a>栗子</h4><p>仅允许mapreduce gruop中的a, b users将作业提交到MapReduce集群:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">     &lt;name&gt;security.job.client.protocol.acl&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;a,b mapreduce&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><br></p><p>仅允许数据属于group datanodes的users运行的DataNode与NameNode进行通信:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">     &lt;name&gt;security.datanode.protocol.acl&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;datanodes&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><br></p><p>允许任何用户作为DFSClient与HDFS集群通信:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">     &lt;name&gt;security.client.protocol.acl&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="HTTP认证"><a href="#HTTP认证" class="headerlink" title="HTTP认证"></a>HTTP认证</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/HttpAuthentication.html" target="_blank" rel="noopener">Authentication for Hadoop HTTP web-consoles</a></p><p><br></p><h3 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h3><p>本节介绍如何配置Hadoop HTTP web-console以要求用户身份认证。</p><p>默认情况下，Hadoop HTTP web-console(ResourceManager, NameNode, NodeManager, DataNodes)允许无需任何形式的身份认证的访问。</p><p>可将Hadoop HTTP web-console配置为使用HTTP SPNEGO协议要求Kerberos身份认证。<br>此外，Hadoop HTTP web-console支持相当于Hadoop的 Pseudo/Simple 认证。如果启用此选项，则必须使用 <code>user.name</code> 查询字符串参数在浏览器交互中地址用户名。 如: <code>http://localhost:8088/cluster?user.name=usera</code>。<br>如果HTTP web-console需要自定义身份认证机制，则可以实现插件以支持备用身份认证机制。</p><p><br><br><br></p><h3 id="配置-4"><a href="#配置-4" class="headerlink" title="配置"></a>配置</h3><p>以下属性应位于集群中所有节点的 <code>core-site.xml</code> 中:</p><div class="table-container"><table><thead><tr><th>Property Name</th><th>Default Value</th><th>Description</th></tr></thead><tbody><tr><td><code>hadoop.http.filter.initializers</code></td><td>-</td><td>Add to this property the org.apache.hadoop.security.AuthenticationFilterInitializer initializer class.</td></tr><tr><td><code>hadoop.http.authentication.type</code></td><td>simple</td><td>Defines authentication used for the HTTP web-consoles. The supported values are: simple</td><td>kerberos</td><td>#AUTHENTICATION_HANDLER_CLASSNAME#.</td></tr><tr><td><code>hadoop.http.authentication.token.validity</code></td><td>36000</td><td>Indicates how long (in seconds) an authentication token is valid before it has to be renewed.</td></tr><tr><td><code>hadoop.http.authentication.token.max-inactive-interval</code></td><td>-1 (disabled)</td><td>Specifies the time, in seconds, between client requests the server will invalidate the token.</td></tr><tr><td><code>hadoop.http.authentication.signature.secret.file</code></td><td><code>$user.home/hadoop-http-auth-signature-secret</code></td><td>The signature secret file for signing the authentication tokens. The same secret should be used for all nodes in the cluster, ResourceManager, NameNode, DataNode and NodeManager. This file should be readable only by the Unix user running the daemons.</td></tr><tr><td><code>hadoop.http.authentication.cookie.domain</code></td><td>-</td><td>The domain to use for the HTTP cookie that stores the authentication token. For authentication to work correctly across all nodes in the cluster the domain must be correctly set. There is no default value, the HTTP cookie will not have a domain working only with the hostname issuing the HTTP cookie.</td></tr><tr><td><code>hadoop.http.authentication.cookie.persistent</code></td><td>false (session cookie)</td><td>Specifies the persistence of the HTTP cookie. If the value is true, the cookie is a persistent one. Otherwise, it is a session cookie. IMPORTANT: when using IP addresses, browsers ignore cookies with domain settings. For this setting to work properly all nodes in the cluster must be configured to generate URLs with hostname.domain names on it.</td></tr><tr><td><code>hadoop.http.authentication.simple.anonymous.allowed</code></td><td>true</td><td>Indicates whether anonymous requests are allowed when using ‘simple’ authentication.</td></tr><tr><td><code>hadoop.http.authentication.kerberos.principal</code></td><td><code>HTTP/_HOST@$LOCALHOST</code></td><td>Indicates the Kerberos principal to be used for HTTP endpoint when using ‘kerberos’ authentication. The principal short name must be HTTP per Kerberos HTTP SPNEGO specification. _HOST -if present- is replaced with bind address of the HTTP server.</td></tr><tr><td><code>hadoop.http.authentication.kerberos.keytab</code></td><td><code>$user.home/hadoop.keytab</code></td><td>Location of the keytab file with the credentials for the Kerberos principal used for the HTTP endpoint.</td></tr></tbody></table></div><p><br><br><br></p><h3 id="CORS"><a href="#CORS" class="headerlink" title="CORS"></a>CORS</h3><p>要启用跨域支持(CORS)，请设置以下配置参数:</p><p>将 <code>org.apache.hadoop.security.HttpCrossOriginFilterInitializer</code> 添加到 <code>core-site.xml</code> 中的 <code>hadoop.http.filter.initializers</code>。您还需要在 <code>core-site.xml</code> 中设置以下属性:</p><div class="table-container"><table><thead><tr><th>Property</th><th>Default Value</th><th>Description</th></tr></thead><tbody><tr><td><code>hadoop.http.cross-origin.enabled</code></td><td><code>false</code></td><td>Enables cross origin support for all web-services</td></tr><tr><td><code>hadoop.http.cross-origin.allowed-origins</code></td><td><code>*</code></td><td>Comma separated list of origins that are allowed. Values prefixed with regex: are interpreted as regular expressions. Values containing wildcards (*) are possible as well, here a regular expression is generated, the use is discouraged and support is only available for backward compatibility.</td></tr><tr><td><code>hadoop.http.cross-origin.allowed-methods</code></td><td>GET,POST,HEAD</td><td>Comma separated list of methods that are allowed</td></tr><tr><td><code>hadoop.http.cross-origin.allowed-headers</code></td><td>X-Requested-With,Content-Type,Accept,Origin</td><td>Comma separated list of headers that are allowed</td></tr><tr><td><code>hadoop.http.cross-origin.max-age</code></td><td>1800</td><td>Number of seconds a pre-flighted request can be cached</td></tr></tbody></table></div><p><br><br><br><br><br></p><h2 id="Credential-Provider-API"><a href="#Credential-Provider-API" class="headerlink" title="Credential Provider API"></a>Credential Provider API</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/CredentialProviderAPI.html" target="_blank" rel="noopener">CredentialProvider API Guide</a></p><p>CredentialProvider API是一个用于插入可扩展凭据提供程序的SPI框架。凭据提供程序用于将敏感令牌(token)，机密(secret)和密码(passwd)的使用与其存储和管理的详细信息分开。选择各种存储机制来保护这些凭证的能力使我们能够使这些敏感资产远离明文(clear text)，远离窥探并可能由第三方解决方案管理。</p><p>本节描述CredentialProvider API的设计，开箱即用的实现，使用它们以及如何使用它们。</p><p><br><br><br><br><br></p><h2 id="密钥管理"><a href="#密钥管理" class="headerlink" title="密钥管理"></a>密钥管理</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-kms/index.html" target="_blank" rel="noopener">Hadoop Key Management Server (KMS)</a></p><p><strong>Hadoop KMS</strong> 是一个基于Hadoop KeyProvider API的加密秘钥管理服务器。<br>它提供了一个Client和Server组件，它们使用REST API通过HTTP进行通信。<br>Client是KeyProvider实现，使用KMS HTTP REST API与KMS交互。<br>KMS及其Client內建有安全性，并且支持HTTP和 SPNEGO Kerberos认证和HTTPS安全传输。<br>KMS是一个Java Jetty Web应用程序。</p><p><br><br><br><br><br></p><h2 id="Tracing"><a href="#Tracing" class="headerlink" title="Tracing"></a>Tracing</h2><p><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-common/Tracing.html" target="_blank" rel="noopener">Enabling Dapper-like Tracing in Hadoop</a></p><p><br></p><h3 id="HTrace"><a href="#HTrace" class="headerlink" title="HTrace"></a>HTrace</h3><p>HDFS-5274 使用开源跟踪库(Apache HTrace)增加了对通过HDFS跟踪请求的支持。设置跟踪非常简单，但是它需要对客户端代码进行一些非常小的更改。</p><p><br><br><br></p><h3 id="SpanReceivers"><a href="#SpanReceivers" class="headerlink" title="SpanReceivers"></a>SpanReceivers</h3><p><br><br><br></p><hr><p><br><br><br></p><h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><p><br></p><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p><a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" target="_blank" rel="noopener">HDFS Architecture</a></p><p>Hadoop Distributed File System(HDFS) 是一种分布式文件系统，设计用于在商业硬件上运行。它与现有的分布式文件系统有许多相似之处。但是，与其它分布式文件系统的差异很大。HDFS具有高度容错(fault-tolerant)能力，旨在部署在低成本硬件上。HDFS提供对应用程序数据的高吞吐量访问，适用于具有大型数据集的应用程序。HDFS放宽了一些POSIX要求，以实现对文件系统数据的流式访问。</p><p><br><br><br></p><h3 id="假设和目标"><a href="#假设和目标" class="headerlink" title="假设和目标"></a>假设和目标</h3><p>Assumptions and Goals</p><p><br></p><h4 id="硬件故障"><a href="#硬件故障" class="headerlink" title="硬件故障"></a>硬件故障</h4><p>Hardware Failure</p><p>硬件故障是常态而非异常。HDFS实例可能包含成百上千的主机，每台主机都存储文件系统数据的一部分。事实上，存在大量组件并且每个组件具有非平凡(non-trivial)的故障概率，这意味着HDFS某些组件始终不起作用(non-functional)。因此，检测故障并从中快速自动地恢复是HDFS的核心架构目标。</p><p><br><br><br></p><h4 id="流数据访问"><a href="#流数据访问" class="headerlink" title="流数据访问"></a>流数据访问</h4><p>Streaming Data Access</p><p>在HDFS上运行的应用程序需要对其数据集进行流式访问。它们不是通常在通用文件系统上运行的通用应用程序。HDFS设计用于批处理而不是用户的交互式使用。重点是数据访问的高吞吐量(high throughput)而不是数据访问的低延迟(low latency)。POSIX强加了许多针对HDFS的应用程序不需要的硬性要求。</p><p><br><br><br></p><h4 id="大型数据集"><a href="#大型数据集" class="headerlink" title="大型数据集"></a>大型数据集</h4><p>Large Data Sets</p><p>在HDFS上运行的应用程序具有大型数据集。HDFS中的典型文件大小为gigabytes到terabytes。因此，HDFS被调整为支持大文件。它应该为单个集群中的成百上千的节点提供高聚合数据带宽和扩展。它应该在单个实例中支持数千万个文件。</p><p><br><br><br></p><h4 id="简单的一致性模型"><a href="#简单的一致性模型" class="headerlink" title="简单的一致性模型"></a>简单的一致性模型</h4><p>Simple Coherency Model</p><p>HDFS应用程序需要一个<code>write-once-read-many</code>的文件访问模型。除了追加(append)和截断(truncates)之外，无需更改创建，写入和关闭的文件。支持将内容附加到文件末尾，但无法在任意点更新。此假设简化了数据一致性问题，并实现了高吞吐量数据访问。MapReduce应用程序或Web Crawler应用程序适合此模型。</p><p><br><br><br></p><h4 id="移动计算比移动数据更便宜"><a href="#移动计算比移动数据更便宜" class="headerlink" title="移动计算比移动数据更便宜"></a>移动计算比移动数据更便宜</h4><p>Moving Computation is Cheaper than Moving Data</p><p>如果应用程序在其操作的数据附近执行，则计算所请求的计算效率更高。当数据集很大时尤其如此。这可以最大限度地减少网络拥塞(network congestion)并提高系统的整体吞吐量。这个假设通常更好的是将计算迁移到更靠近数据所在的地方，而不是将数据移动到应用程序运行的地方。HDFS为应用程序移动到更靠近数据所在的地方的接口。</p><p><br><br><br></p><h4 id="可移植性"><a href="#可移植性" class="headerlink" title="可移植性"></a>可移植性</h4><p>Portability Across Heterogeneous Hardware and Software Platforms</p><p>HDFS的设计便于从一个平台移植到另一个平台。</p><p><br><br><br><br><br></p><h3 id="NameNode和DataNode"><a href="#NameNode和DataNode" class="headerlink" title="NameNode和DataNode"></a>NameNode和DataNode</h3><p>HDFS具有主从架构(Master-Slave)。HDFS集群由单个<strong>NameNode</strong>、一个管理文件系统命名空间和管理客户端对文件的访问的<strong>Master Server</strong>组成。此外，还有许多<strong>DataNode</strong>，通常是集群中每个节点一个，用于管理附加到它们运行节点的存储。HDFS公开文件系统命名空间，并允许用户数据存储在文件中。在内部，文件被分成一个或多个块(block)，这些块存储在一组DataNode中。<br>NameNode执行文件系统命名空间操作(如打开、关闭、重命名文件目录)。它还确定了block到DataNode的映射。<br>DataNode负责提供来自文件系统客户端的读写请求，它还根据NameNode的指令执行块操作(如创建、删除、副本)。</p><p><img src="/images/Hadoop/hdfsarchitecture.png" alt></p><p><br></p><p>NameNode和DataNode是设计用于在商用机器上运行的软件，这些机器通常运行GNU/Linux操作系统。HDFS使用Java语言构建，任何支持Java的机器都可运行NameNode或DataNode软件。使用高度可移植的Java语言意味着可以在各种计算机上部署HDFS。<br>典型部署具有仅运行NameNode软件的专用主机，群集中的每台其它主机都运行一个DataNode软件实例。虽然可以讲它们运行在同一台主机上，但这并不推荐。</p><p>群集中存在单个NameNode极大地简化了系统结构。NameNode是所有HDFS Metadata的仲裁者(arbitrator)和存储库(repository)。系统的设计使用户数据永远不会流经NameNode。</p><p><br><br><br><br><br></p><h3 id="文件系统命名空间"><a href="#文件系统命名空间" class="headerlink" title="文件系统命名空间"></a>文件系统命名空间</h3><p>The File System Namespace</p><p>HDFS支持传统的层次文件组织。用户或应用程序可以创建目录，并在这些目录中存储文件。文件系统命名空间层次结构类似于大多数其它现有文件系统；可创建、删除、移动、重命名文件。HDFS支持用户配额(user quotas)和访问权限。HDFS不支持硬链接和软链接。但是，HDFS架构并不排除实现这些功能。</p><p>NameNode维护文件系统命名空间。NameNode Record对文件系统命名空间或其属性的任何更改。应用程序可以指定应由HDFS维护的文件的副本数。文件的副本数称为该文件的复制因子，该信息由NameNode存储。</p><p><br><br><br><br><br></p><h3 id="数据副本"><a href="#数据副本" class="headerlink" title="数据副本"></a>数据副本</h3><p>Data Replication</p><p>HDFS旨在可靠地在大型群集中的计算机上存储非常大的文件。它将每个文件存储为一系列块。文件块的副本用以实现容错(fault tolerance)。块大小和副本因子可根据文件进行配置。</p><p>除了最后一个块之外，文件中的所有块都具有相同的大小。而用户可以在添加对可变长度块的支持以追加和hsync之后启动新块而不将最后一个块填充到配置的块大小。</p><p>应用程序可以指定文件的副本数量。副本因子可在文件创建时指定，并且可以在之后修改。HDFS中的文件是一次写入的，并且在任何时候都有一个写入器。</p><p>NameNode做出有关副本的所有决定。它定期从集群中的每个DataNode接收Heartbeat和Blockreport。收到心跳意味着DataNode正常运行，块上报包含DataNode上所有块的列表。</p><p><img src="/images/Hadoop/hdfsdatanodes.png" alt></p><p><br></p><h4 id="副本安置"><a href="#副本安置" class="headerlink" title="副本安置"></a>副本安置</h4><p>Replica Placement: The First Baby Steps</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;wikipeadia&lt;/li&gt;
&lt;li&gt;Hadoop官网: &lt;a href=&quot;https://hadoop.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://hadoop.apache.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Apache Software Foundation: &lt;a href=&quot;https://www.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.apache.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RHEL7x86_64&lt;/li&gt;
&lt;li&gt;Hadoop v3.2.0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="Apache" scheme="https://zhang21.github.io/tags/Apache/"/>
    
      <category term="DataAnalysis" scheme="https://zhang21.github.io/tags/DataAnalysis/"/>
    
      <category term="Hadoop" scheme="https://zhang21.github.io/tags/Hadoop/"/>
    
      <category term="BigData" scheme="https://zhang21.github.io/tags/BigData/"/>
    
  </entry>
  
  <entry>
    <title>SonarQube</title>
    <link href="https://zhang21.github.io/2019/02/22/SonarQube/"/>
    <id>https://zhang21.github.io/2019/02/22/SonarQube/</id>
    <published>2019-02-22T07:28:44.000Z</published>
    <updated>2019-03-05T08:42:13.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>GitHub: <a href="https://github.com/SonarSource/sonarqube" target="_blank" rel="noopener">https://github.com/SonarSource/sonarqube</a></li><li>Website: <a href="https://www.sonarqube.org/" target="_blank" rel="noopener">https://www.sonarqube.org/</a></li><li>Docs: <a href="https://docs.sonarqube.org" target="_blank" rel="noopener">https://docs.sonarqube.org</a></li></ul><p>环境:</p><ul><li>RHEL7x86_64</li><li>SonarQube v7.6</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p><strong>SonarQube</strong> 是一个开源的代码质量管理系统。支持超过25中编程语言，不过有些是商业插件。</p><p>SonarQube 是一种自动代码审查(code review)工具，用于检测代码中的<strong>错误(bugs)</strong>，<strong>漏洞(vulnerabilities)</strong>和<strong>代码异味(code smell)</strong>。它可以与您现有的工作流程集成，以便在项目分支和拉取请求之间进行连续的代码检查。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="架构与集成"><a href="#架构与集成" class="headerlink" title="架构与集成"></a>架构与集成</h1><p>Architecture and Integration</p><p><br></p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>SonarQube平台由4个组件组成:</p><p><img src="/images/SonarQube/architecture-scanning.png" alt></p><p><br></p><ul><li><strong>SonarQube Server</strong>启动三个主进程:<ul><li><strong>Web Server</strong>，供开发人员，管理人员浏览质量快照并配置SonarQube实例</li><li><strong>Search Server</strong>，基于ElasticSearch从UI返回搜索</li><li><strong>Compute Engine Server</strong>，负责处理代码分析和上报并将其保存到SonarQube数据库中</li></ul></li><li><strong>SonarQube Database</strong>用于存储<ul><li>SonarQube实例的配置(安全，插件…的设置)</li><li>项目，视图…的质量快照</li></ul></li><li>Server上安装了多个插件，可能包括Language，SCM，Intergration，Authentication，Governance…</li><li>在CI/CD Server上运行一个或多个 <strong>SonarScanner</strong> 来分析项目</li></ul><p><br><br><br><br><br></p><h2 id="集成"><a href="#集成" class="headerlink" title="集成"></a>集成</h2><p>Integration</p><p>以下模式显示了SonarQube如何与其它ALM工具进行集成，以及在哪里使用SonarQube的各种组件。</p><p><img src="/images/SonarQube/architecture-integrate.png" alt></p><p><br></p><ol><li>开发者在他们的IDE中集成SonarLint运行本地分析</li><li>开发者推送他们的代码到代码库</li><li>CI Server触发自动构建，以及执行运行SonarQube分析所需的SonarScanner</li><li>分析报告将发送到SonarQube Server进行处理</li><li>SonarQube Server处理分析报告并将结果存储在SonarQuebe数据库中，并在UI中显示结果</li><li>开发者通过SonarQube UI审核，评论，挑战他们的Issues以管理和减少他们的技术债务</li><li>管理者从分析中接收报告，运维使用API自动配置并从SonarQube中提取数据，使用JMX监控SonarQube Server</li></ol><p><br><br><br><br><br></p><h2 id="关于机器和位置"><a href="#关于机器和位置" class="headerlink" title="关于机器和位置"></a>关于机器和位置</h2><p>About Machines and Locations</p><ul><li>SonarQube平台不能够有多个SonarQube Server和SonarQube Database</li><li>为获得最佳性能，每个组件(Server, Database, Scanner)应该安装在单独的机器上，并且此机器应该是专用的</li><li>SonarScanner通过添加机器进行扩展</li><li>所有机器必须时钟同步</li><li>SonarQube Server和SonarQube Database必须位于同一网络下</li><li>SonarScanner不需要与SonarQube Server位于同一网络下</li><li>SonarScanner与SonarQube Database之间没有通信</li></ul><p><br><br><br></p><hr><p><br><br><br></p><h1 id="要求"><a href="#要求" class="headerlink" title="要求"></a>要求</h1><p>Requirements</p><p><br></p><h2 id="先决条件"><a href="#先决条件" class="headerlink" title="先决条件"></a>先决条件</h2><p>Prerequisites and Overview</p><p>运行SonarQube的唯一先决条件是安装Java(Oracle JRE 8/OpenJDK 8)。</p><p><br></p><h3 id="硬件要求"><a href="#硬件要求" class="headerlink" title="硬件要求"></a>硬件要求</h3><ul><li>2Cores+</li><li>2GB RAM+</li><li>建议使用高性能I/O的磁盘</li></ul><p><br><br><br></p><h3 id="支持的平台"><a href="#支持的平台" class="headerlink" title="支持的平台"></a>支持的平台</h3><ul><li>Java<ul><li>Oracle JRE 8</li><li>OpenJDK 8</li></ul></li><li>Database<ul><li>PostgreSQL v9.3-v9.6, v10. UTF-8 charset</li><li>SQL Server v2014, v2016. </li><li>Oracle v11, v12, vXE. UTF8-family charset, thin mode</li><li>MySQL v5.6, v5.7. UTF8 charset, InnoDB storage, mysql-connector-java</li></ul></li><li>Web Browser<ul><li>IE 11</li><li>Edge Latest</li><li>FireFox Latest</li><li>Chrome</li><li>Safari</li></ul></li></ul><p><br><br><br></p><h3 id="平台说明"><a href="#平台说明" class="headerlink" title="平台说明"></a>平台说明</h3><p><br></p><h4 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h4><p>如果在Linux上运行，请确保:</p><ul><li><code>vm.max_map_count</code> 大于或等于 262144</li><li><code>fs.file-max</code> 大于或等于 65535</li><li>运行SonarQube的用户可以打开至少65535个文件描述符</li><li>运行SonarQube的用户可以打开至少2048个线程</li></ul><p>用以下命令查看和配置它们:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">sysctl vm.max_map_count</span><br><span class="line">sysctl fs.file-max</span><br><span class="line"><span class="built_in">ulimit</span> -n</span><br><span class="line"><span class="built_in">ulimit</span> -u</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置，但只是临时生效</span></span><br><span class="line"><span class="comment"># root</span></span><br><span class="line">sysctl -w vm.max_map_count=262144</span><br><span class="line">sysctl -w fs.file-max=65536</span><br><span class="line"><span class="built_in">ulimit</span> -n 65536</span><br><span class="line"><span class="built_in">ulimit</span> -u 2048</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 永久生效</span></span><br><span class="line"><span class="comment"># /etc/sysctl.d/99-sonarqube.conf 或 /etc/sysctl.conf</span></span><br><span class="line"><span class="comment"># user: sonarqube</span></span><br><span class="line">sonarqube   -   nofile   65536</span><br><span class="line">sonarqube   -   nproc    2048</span><br></pre></td></tr></table></figure><p><br></p><p>如果使用<code>systemd</code>来启动SonarQube，你必须在<code>[Service]</code>的单元文件中指定这些限制:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[Service]</span><br><span class="line">...</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">LimitNPROC=2048</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="seccomp-filter"><a href="#seccomp-filter" class="headerlink" title="seccomp filter"></a>seccomp filter</h4><p>默认情况下，ElasticSearch使用<strong>seccomp filter</strong>。在大多数发行版中，此功能在内核中激活。但在RHL6等发行版上，此功能已停用。如果你的发行版中没有此功能，请无法升级到激活了seccomp filter功能的版本，则必须通过更新<code>$SONARQUBEHOME/conf/sonar.properties_</code>中的<code>sonar.search.javaAdditionalOpts</code>配置:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sonar.search.javaAdditionalOpts=-Dbootstrap.system_call_filter=false</span><br><span class="line"></span><br><span class="line"># 检查</span><br><span class="line">grep SECCOMP /boot/config-$(uname -r)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 如果内核有它，你将看到</span><br><span class="line">CONFIG_HAVE_ARCH_SECCOMP_FILTER=y</span><br><span class="line">CONFIG_SECCOMP_FILTER=y</span><br><span class="line">CONFIG_SECCOMP=y</span><br></pre></td></tr></table></figure><p><br><br><br></p><hr><p><br><br><br></p><h1 id="配置和升级"><a href="#配置和升级" class="headerlink" title="配置和升级"></a>配置和升级</h1><p>Setup and Upgrade</p><p><br></p><h2 id="快速入门"><a href="#快速入门" class="headerlink" title="快速入门"></a>快速入门</h2><p>Get Started in Two Minutes Guide</p><ul><li>从ZIP文件安装</li><li>使用Docker</li></ul><p><br></p><h3 id="zip文件安装"><a href="#zip文件安装" class="headerlink" title="zip文件安装"></a>zip文件安装</h3><ol><li>现在 SonarQube CE</li><li>解压</li><li>运行</li><li>访问</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 具体位置取决于你的安装位置</span></span><br><span class="line">/opt/sonarqube/bin/[OS]/sonar.sh console</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># localhost:9000（admin/admin）</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="Docker安装"><a href="#Docker安装" class="headerlink" title="Docker安装"></a>Docker安装</h3><p>在<a href="https://hub.docker.com/_/sonarqube/" target="_blank" rel="noopener">Docker Hub</a>上下载对应CE的镜像，上面有安装和配置的详细信息。</p><p><br><br><br><br><br></p><h2 id="安装Server"><a href="#安装Server" class="headerlink" title="安装Server"></a>安装Server</h2><p>支持多个数据库引擎，请务必遵守各个数据库引擎的要求。</p><p>创建一个空的schema和一个<code>sonarqube</code>用户。授予此用户<code>create, update, delete</code>此<code>schema</code>对象的权限。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">SCHEMA</span> <span class="string">`sonar`</span> <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8 ;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">'sonarqube'</span>@<span class="string">'localhost'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'sonarqube-PW123'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">ON</span> sonar.* <span class="keyword">TO</span> <span class="string">'sonarqube'</span>@<span class="string">'localhost'</span>;</span><br></pre></td></tr></table></figure><p><br></p><h3 id="安装数据库"><a href="#安装数据库" class="headerlink" title="安装数据库"></a>安装数据库</h3><p><br></p><h4 id="SQL-Server"><a href="#SQL-Server" class="headerlink" title="SQL Server"></a>SQL Server</h4><p>跳过，有需要的请看: <a href="https://docs.sonarqube.org/latest/setup/install-server/" target="_blank" rel="noopener">https://docs.sonarqube.org/latest/setup/install-server/</a></p><p><br><br><br></p><h4 id="Oracle"><a href="#Oracle" class="headerlink" title="Oracle"></a>Oracle</h4><p>跳过！</p><p><br><br><br></p><h4 id="PostgreSQL"><a href="#PostgreSQL" class="headerlink" title="PostgreSQL"></a>PostgreSQL</h4><p>如果你想使用<code>custom schema</code>而不是默认的<code>public schema</code>，则必须设置PostgreSQL的<code>search_path</code>属性:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">USER</span> mySonarUser <span class="keyword">SET</span> search_path <span class="keyword">to</span> mySonarQubeSchema</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h4><blockquote><p>注意:<br>Data Center Edition(Enterprise)不支持MySQL!<br>Data Center Edition: Designed for High Availability</p></blockquote><p>可在MySQL中使用两种众所周知的数据库引擎: <strong>MyISAM</strong>和<strong>InnoDB</strong>。MyISAM是最老的，并且正在逐渐被InnoDB替代。随着质量控制项目数量的增加，InnoDB显然更快，并且使用SonarQube可以更好地扩展。<br>如果你是SonarQube的早期使用者，你可能有一系列仍在使用MyISAM引擎的表。你应该将所有表的引擎更改为InnoDB。</p><p>一旦所有SonarQube表都使用InnoDB引擎，首先要做的是使用<code>innodb_buffer_pool_size</code>参数为MySQL实例分配最大的RAM，并为<code>query_cache_size</code>参数提供至少<code>15Mb</code>。</p><p>阅读这篇文档<a href="https://www.percona.com/blog/2007/11/01/innodb-performance-optimization-basics/" target="_blank" rel="noopener">InnoDB Performance Optimization</a>来优化InnoDB。</p><p><br><br><br></p><h3 id="安装Web-Server"><a href="#安装Web-Server" class="headerlink" title="安装Web Server"></a>安装Web Server</h3><p>首先，检查安装要求；<br>下载和解压压缩的发行版(不要解压到以数字开头的目录)；<br>下面变量<code>SONARQUBE-HOME</code>指的是解压的路径。</p><p><br></p><h4 id="设置数据库访问"><a href="#设置数据库访问" class="headerlink" title="设置数据库访问"></a>设置数据库访问</h4><p>编辑<code>$SONARQUBE-HOME/conf/sonar.properties</code>来配置数据库设置。模板可用于每个受支持的数据库。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Example for MySQL</span><br><span class="line">sonar.jdbc.username=sonarqube</span><br><span class="line">sonar.jdbc.password=sonarqube-PW123</span><br><span class="line">sonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance&amp;useSSL=false</span><br></pre></td></tr></table></figure><p><br></p><h4 id="添加JDBC驱动"><a href="#添加JDBC驱动" class="headerlink" title="添加JDBC驱动"></a>添加JDBC驱动</h4><p>已提供受支持数据库(Oracle除外)的驱动程序。不要更换提供的驱动程序，它们是唯一受支持的。</p><p>对于Oracle，将JDBC驱动复制到<code>$SONARQUBE-HOME/extensions/jdbc-driver/oracle</code>。</p><p><br><br><br></p><h4 id="配置ElasticSearch存储路径"><a href="#配置ElasticSearch存储路径" class="headerlink" title="配置ElasticSearch存储路径"></a>配置ElasticSearch存储路径</h4><p>默认情况下，ES数据存储在<code>$SONARQUBE-HOME/data</code>中，但不建议用于生产环境。相反，你应该将数据存储在其它位置，最好是在具有高速I/O的专用卷。除了保持可接受的性能之外，还可简化SonarQube的升级。</p><p>编辑<code>$SONARQUBE-HOME/conf/sonar.properties</code>来配置以下设置:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 请记得添加读写权限</span><br><span class="line">sonar.path.data=/var/sonarqube/data</span><br><span class="line">sonar.path.temp=/var/sonarqube/temp</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="启动Web-Server"><a href="#启动Web-Server" class="headerlink" title="启动Web Server"></a>启动Web Server</h4><p>可在<code>$SONARQUBE-HOME/conf/sonar.properties</code>配置监听地址和端口等。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sonar.web.host=192.0.0.1</span><br><span class="line">sonar.web.port=80</span><br><span class="line">sonar.web.context=/sonarqube</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">bin/sonar.sh start</span><br><span class="line"></span><br><span class="line"><span class="comment"># 默认admin/admin</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="调整Web服务器"><a href="#调整Web服务器" class="headerlink" title="调整Web服务器"></a>调整Web服务器</h4><p>默认情况下，SonarQube配置为在任何具有简单Java JRE的计算机上运行。</p><p>为了更好地性能，生产环境实例要做的第一件事是使用Java JDK并通过在<code>sonar.web.javaOpts=-server</code>中设置以下行来激活服务器模式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sonar.web.javaOpts=-server</span><br></pre></td></tr></table></figure><p>要修改SonarQube使用的Java JVM只需编辑<code>$SONARQUBE-HOME/conf/wrapper.conf</code>并更新以下行:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wrapper.java.command=/path/to/my/jdk/bin/java</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h4><p>docs: <a href="https://docs.sonarqube.org/latest/setup/install-server/" target="_blank" rel="noopener">https://docs.sonarqube.org/latest/setup/install-server/</a></p><p><br><br><br><br><br></p><h2 id="配置和操作Server"><a href="#配置和操作Server" class="headerlink" title="配置和操作Server"></a>配置和操作Server</h2><p>Configure &amp; Operate the Server</p><p><br></p><h3 id="以SystemD运行"><a href="#以SystemD运行" class="headerlink" title="以SystemD运行"></a>以SystemD运行</h3><p>Running SonarQube as a Service on Linux with SystemD</p><p>假设如下信息:</p><ul><li>sonarqube用户</li><li>sonarqube组</li><li>java virtual machine安装在<code>/opt/java/</code></li><li>sonarqube解压在<code>/opt/sonarqube/</code></li></ul><p><br></p><p>创建<code>sonarqube</code>用户:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">useradd -M -s /sbin/nologin</span><br></pre></td></tr></table></figure><p><br></p><p>创建service文件<code>/etc/systemd/system/sonarqube.service</code>，具体详情请安装自己的实际情况进行修改。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=SonarQube service</span><br><span class="line">After=syslog.target network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">User=sonarqube</span><br><span class="line">Group=sonarqube</span><br><span class="line">PermissionsStartOnly=true</span><br><span class="line">ExecStart=/bin/nohup /opt/java/bin/java -Xms32m -Xmx32m -Djava.net.preferIPv4Stack=true -jar /opt/sonarqube/lib/sonar-application-7.6.jar</span><br><span class="line">StandardOutput=syslog</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">LimitNPROC=8192</span><br><span class="line">TimeoutStartSec=5</span><br><span class="line">Restart=always</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">sudo systemctl <span class="built_in">enable</span> sonarqube.service</span><br><span class="line">sudo systemctl start sonarqube.service</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="在代理服务器后保护Server"><a href="#在代理服务器后保护Server" class="headerlink" title="在代理服务器后保护Server"></a>在代理服务器后保护Server</h3><p>Securing the Server Behind a Proxy</p><p><br></p><h4 id="Server配置"><a href="#Server配置" class="headerlink" title="Server配置"></a>Server配置</h4><p>要通过HTTPS运行SonarQube Server，必须构建标准的反向代理服务器。<br>必须配置反向代理，在每个HTTP Request Header中设置<code>X_FORWARDED_PROTO: https</code>值。如果没有此属性，SonarQube Server启动的重定向将回退到HTTP。</p><p><br><br><br></p><h4 id="使用Apache代理"><a href="#使用Apache代理" class="headerlink" title="使用Apache代理"></a>使用Apache代理</h4><p>跳过！</p><p><br><br><br></p><h4 id="使用Nginx代理"><a href="#使用Nginx代理" class="headerlink" title="使用Nginx代理"></a>使用Nginx代理</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># the server directive is nginx&apos;s virtual host directive</span><br><span class="line">server &#123;</span><br><span class="line">  # port to listen on. Can also be set to an IP:PORT</span><br><span class="line">  listen 80;</span><br><span class="line"></span><br><span class="line">  # sets the domain[s] that this vhost server requests for</span><br><span class="line">  server_name www.somecompany.com;</span><br><span class="line"></span><br><span class="line">  location / &#123;</span><br><span class="line">    proxy_pass http://sonarhost:sonarport;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br><br><br></p><h4 id="使用IIS"><a href="#使用IIS" class="headerlink" title="使用IIS"></a>使用IIS</h4><p>跳过！</p><p><br><br><br><br><br></p><h2 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h2><p>在SonarQube中安装插件有两种选择:</p><ul><li><strong>Marketplace</strong>，从SonarQube UI自动地安装插件</li><li><strong>手动安装</strong>， 如果SonarQube实例无法访问Internet，请使用此方法</li></ul><p><br><br><br><br><br></p><h2 id="安装C-C-插件"><a href="#安装C-C-插件" class="headerlink" title="安装C/C++插件"></a>安装C/C++插件</h2><p>由于SonarQube的C, C++是商业版才有的功能，所以我使用的CE版就不支持对这两个语言的静态检查。</p><p>后来看到 <strong>SonarOpenCommunity</strong>: <a href="https://github.com/SonarOpenCommunity" target="_blank" rel="noopener">https://github.com/SonarOpenCommunity</a>，它里面有这个插件，先感谢开发者，然后再使用。</p><p>sonar-cxx: <a href="https://github.com/SonarOpenCommunity/sonar-cxx" target="_blank" rel="noopener">https://github.com/SonarOpenCommunity/sonar-cxx</a>，查看相关说明进行安装和配置。</p><p><br></p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><ul><li>明白哪个插件版本与当前使用的SonarQube版本监控</li><li>下载jar插件，将其放置于<code>$ SONARQUBE_HOME/extensions/plugins</code>目录下<ul><li><code>sonar-cxx-plugin-x.y.z.jar</code>: c++ plug-in</li><li><code>sonar-c-plugin-x.y.z.jar</code>: c plug-in</li></ul></li><li>重启SonarQube Server</li><li>在UI上的Marketplace查看更新</li></ul><p><br><br><br><br><br></p><h2 id="安装PS-SQL插件"><a href="#安装PS-SQL插件" class="headerlink" title="安装PS/SQL插件"></a>安装PS/SQL插件</h2><p>由于SonarQube的PL, SQL是商业版才有的功能，所以我使用的CE版就不支持对这两个语言的静态检查。</p><p>后来看到: sonar-plsql: <a href="https://github.com/felipebz/sonar-plsql" target="_blank" rel="noopener">https://github.com/felipebz/sonar-plsql</a> 社区开源项目，先感谢开发者，再使用。</p><p>安装方法与上面的C/C++一样，下载当前版本支持的插件到对应目录，重启SonarQube Server。</p><p><br><br><br><br><br></p><h2 id="将Server安装为集群"><a href="#将Server安装为集群" class="headerlink" title="将Server安装为集群"></a>将Server安装为集群</h2><p>docs: <a href="https://docs.sonarqube.org/latest/setup/install-cluster/" target="_blank" rel="noopener">https://docs.sonarqube.org/latest/setup/install-cluster/</a></p><p>先跳过！</p><p><br><br><br><br><br></p><h2 id="配置和操作集群"><a href="#配置和操作集群" class="headerlink" title="配置和操作集群"></a>配置和操作集群</h2><p>Configure &amp; Operate a Cluster</p><p>docs: <a href="https://docs.sonarqube.org/latest/setup/operate-cluster/" target="_blank" rel="noopener">https://docs.sonarqube.org/latest/setup/operate-cluster/</a></p><p>先跳过！</p><p><br><br><br><br><br></p><h2 id="升级"><a href="#升级" class="headerlink" title="升级"></a>升级</h2><p>Upgrade the Server</p><p>自动处理<code>non-LTS</code>版本的升级。但是，如果在迁移路径中有LTS版本，则必须先迁移LTS，然后再迁移到目标版本。</p><p>例如，<code>v5.1</code> -&gt; <code>v7.0</code>，迁移路径为 <code>v5.1</code> -&gt; <code>5.6.7 LTS</code> -&gt; <code>v6.7.x LTS</code> -&gt; <code>v7.0</code>。</p><p><br></p><h3 id="如何升级"><a href="#如何升级" class="headerlink" title="如何升级"></a>如何升级</h3><p>在开始之前，请备份SnarQube Database。升级问题虽然很少见，但备份确实必须的。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="分析源代码"><a href="#分析源代码" class="headerlink" title="分析源代码"></a>分析源代码</h1><p>Analyzing Source Code</p><p><br></p><h2 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h2><p>一旦安装了SonarQube平台，你就可以安装分析器(analyzer)并开始创建项目了。为此，你必须安装和配置适合你需求的扫描器(scanner)。<br>Do you build with:</p><ul><li><strong>Gradle</strong> - <a href="https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner+for+Gradle" target="_blank" rel="noopener">SonarScanner for Gradle</a></li><li><strong>MSBuild</strong> - <a href="https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner+for+MSBuild" target="_blank" rel="noopener">SonarScanner for MSBuild</a></li><li><strong>Maven</strong> - <a href="https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner+for+Maven" target="_blank" rel="noopener">use the SonarScanner for Maven</a></li><li><strong>Jenkins</strong> - <a href="https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner+for+Jenkins" target="_blank" rel="noopener">SonarScanner for Jenkins</a></li><li><strong>Azure DevOps</strong> - <a href="https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Extension+for+VSTS-TFS" target="_blank" rel="noopener">SonarQube Extension for Azure DevOps</a></li><li><strong>Ant</strong> - <a href="https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner+for+Ant" target="_blank" rel="noopener">SonarScanner for Ant</a></li><li><strong>anything else (CLI)</strong> - <a href="https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner" target="_blank" rel="noopener">SonarScanner</a></li></ul><p><strong>注意</strong>，不建议在运行SonarQube Scanner Analysis的机器上运行反病毒扫描程序，这可能会导致不可预测的行为。</p><p><br></p><h3 id="分析产生了什么"><a href="#分析产生了什么" class="headerlink" title="分析产生了什么"></a>分析产生了什么</h3><p>What does analysis produce?</p><p>SonarQube可以对20多种不同的语言进行分析。该分析的结果是 quality measures 和 issues。但是，分析的结果也会因语言而异:</p><ul><li>在所有语言中，<strong>blame</strong>数据将自动从支持的SCM提供程序导入(自动支持Git和SVN)。其它提供需要额外的插件</li><li>在所有语言中，执行源代码的静态分析</li><li>可对某些语言执行编译代码的静态分析</li><li>可对某些语言执行代码的动态分析</li></ul><p><br><br><br></p><h3 id="是否会分析所有文件"><a href="#是否会分析所有文件" class="headerlink" title="是否会分析所有文件"></a>是否会分析所有文件</h3><p>Will all files be analyzed?</p><p>默认情况下，在分析期间，只有语言分析器(language analyzer)可识别的文件才会加载到项目中。</p><p><br><br><br></p><h3 id="分析期间会发生什么"><a href="#分析期间会发生什么" class="headerlink" title="分析期间会发生什么"></a>分析期间会发生什么</h3><p>What happens during analysis?</p><p>在分析期间，从Server请求数据，分析提供给分析的文件，并以报告的形式将结果返回到Server，然后在Server-Side异步分析。</p><p>分析上报排队并按顺序处理，因此很可能在分析日志显示完成后的短暂时间内，更新的值在SonarQube项目中不可见。但是，你能够分辨出正在发生的事情，因为项目名称右侧的项目主页上会有一个图标。</p><p><img src="/images/SonarQube/backgroundTaskProcessingInProgress.jpeg" alt></p><p><img src="/images/SonarQube/backgroundTaskProcessingFailedIcon.jpeg" alt></p><p><br><br><br><br><br></p><h2 id="分析参数"><a href="#分析参数" class="headerlink" title="分析参数"></a>分析参数</h2><p>Analysis Parameters</p><p>可以在多个位置设置用于配置项目分析的参数。这是参数的层次结构：</p><ul><li>在UI里定义的<strong>全局分析参数(Global)</strong>，<code>Administration &gt; Configuration &gt; General Settings</code></li><li>在UI里定义的<strong>项目分析参数(Project)</strong>，<code>Project Level &gt; Administration &gt; General Settings</code></li><li>在项目分析配置文件或分析器配置文件中定义的<strong>项目分析参数</strong></li><li><strong>分析/命令行参数</strong>，再启动分析时定义，覆盖项目分析参数</li></ul><p>注意，只有通过UI设置的参数才会存储在数据库中。</p><p><br></p><h3 id="强制参数"><a href="#强制参数" class="headerlink" title="强制参数"></a>强制参数</h3><p>Mandatory Parameters</p><p><br></p><ul><li><strong>Server</strong></li></ul><div class="table-container"><table><thead><tr><th>Key</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>sonar.host.url</code></td><td>the server URL</td><td><code>http://localhost:9000</code></td></tr></tbody></table></div><p><br></p><ul><li><strong>Project Configuration</strong></li></ul><div class="table-container"><table><thead><tr><th>Key</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>sonar.projectKey</code></td><td>The project’s unique key. Allowed characters are: letters, numbers, - , _ , . and : , with at least one non-digit.</td><td>For Maven projects, this is automatically set to <code>&lt;groupId&gt;:&lt;artifactId&gt;</code></td></tr><tr><td><code>sonar.sources</code></td><td>Comma-separated paths to directories containing source files.</td><td>Read from build system for Maven, Gradle, MSBuild projects</td></tr></tbody></table></div><p><br><br><br></p><h3 id="可选参数"><a href="#可选参数" class="headerlink" title="可选参数"></a>可选参数</h3><p>Optional Parameters</p><ul><li><strong>Project Identity</strong></li></ul><div class="table-container"><table><thead><tr><th>Key</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>sonar.projectName</code></td><td>显示在Web实例上的项目名称</td><td>Maven项目的<code>&lt;name&gt;</code>，否则为项目密钥。如果DB中已有名称，则不会覆盖该名称</td></tr><tr><td><code>sonar.projectVersion</code></td><td>项目版本</td><td>Maven项目的<code>&lt;version&gt;</code>，否则未提供</td></tr></tbody></table></div><p><br></p><ul><li><strong>Authentication</strong></li></ul><div class="table-container"><table><thead><tr><th>Key</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>sonar.login</code></td><td>具有项目执行分析权限的SonarQube用户的登录或身份验证Token</td><td>xxx</td></tr><tr><td><code>sonar.password</code></td><td>与<code>sonar.login</code>用户名一起使用的密码。如果正在使用身份验Token，则应将此项留空</td><td>xxx</td></tr></tbody></table></div><p><br></p><ul><li><strong>Web Services</strong></li></ul><div class="table-container"><table><thead><tr><th>Key</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>sonar.ws.timeout</code></td><td>等待Web服务调用响应的最长时间（秒）。只有在等待服务器响应Web服务调用时在分析期间遇到超时时，才能从默认值修改此值。</td><td>60</td></tr></tbody></table></div><p><br></p><ul><li><strong>Project Configuration</strong></li></ul><div class="table-container"><table><thead><tr><th>Key</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>sonar.projectDescription</code></td><td>项目描述。与Maven不兼容</td><td><code>&lt;description</code>用于Maven项目</td></tr><tr><td><code>sonar.links.homepage</code></td><td>项目主页，与Maven不兼容</td><td><code>&lt;url&gt;</code>用于Maven项目</td></tr><tr><td><code>sonar.links.ci</code></td><td>CI，与Maven不兼容</td><td><code>&lt;ciManagement&gt;&lt;url&gt;</code>用于Maven项目</td></tr><tr><td><code>sonar.links.issue</code></td><td>Issue tracker，与Maven不兼容</td><td><code>&lt;issueManagement&gt;&lt;url&gt;</code>用于Maven项目</td></tr><tr><td><code>sonar.links.scm</code></td><td>项目原仓库，与Maven不兼容</td><td><code>&lt;scm&gt;&lt;url&gt;</code>用于Maven项目</td></tr><tr><td><code>sonar.links.scm_dev</code></td><td>开发者连接，与Maven不兼容</td><td><code>&lt;scm&gt;&lt;developerConnection&gt;</code>用于Maven项目</td></tr><tr><td><code>sonar.tests</code></td><td>包含测试的目录的逗号分隔路径,与Maven不兼容</td><td>Maven项目的默认测试位置</td></tr><tr><td><code>sonar.sourceEncoding</code></td><td>源文件编码</td><td>系统编码</td></tr><tr><td><code>sonar.externalIssuesReportPaths</code></td><td>以逗号分隔的通用Issue上报路径列表</td></tr><tr><td><code>sonar.projectDate</code></td><td>为分析指定日期(yyyy-MM-dd)</td><td>当前日志</td></tr><tr><td><code>sonar.projectBaseDir</code></td><td>当您需要在除启动它之外的目录中进行分析时，请使用此属性</td><td>xxx</td></tr><tr><td><code>sonar.working.directory</code></td><td>设置使用SonarScanner或SonarScanner for Ant（版本大于2.0）触发的分析的工作目录</td><td><code>.sonar</code></td></tr><tr><td><code>sonar.scm.provider</code></td><td>此属性可用于明确告知SonarQube应使用哪个SCM插件来获取项目上的SCM数据</td><td>xxx</td></tr><tr><td><code>sonar.scm.forceReloadAll</code></td><td>默认情况下，仅检索已更改文件的blame信息。将此属性设置为true可加载所有文件的blame信息</td><td>xxx</td></tr><tr><td><code>sonar.coverage.jacoco.xmlReportPaths</code></td><td>导入以XML文件形式提供的JaCoCo代码覆盖率报告。此属性接受多个逗号分隔的条目。必须在分析之前生成JaCoCo XML报告</td><td><code>target/site/jacoco/jacoco.xml</code> <br> <code>build/reports/jacoco/test/jacocoTestReport.xml</code></td></tr></tbody></table></div><p><br></p><ul><li><strong>Duplications</strong></li></ul><div class="table-container"><table><thead><tr><th>Key</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>sonar.cpd.exclusions</code></td><td>要从复制检测中排除的以逗号分隔的文件路径模式列表</td><td>xxx</td></tr><tr><td><code>sonar.cpd.${language}.minimumtokens</code></td><td>xxx</td><td>100</td></tr><tr><td><code>sonar.cpd.${language}.minimumLines</code></td><td>如上</td><td>10</td></tr></tbody></table></div><p><br></p><ul><li><strong>Analysis Logging</strong></li></ul><div class="table-container"><table><thead><tr><th>Key</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>sonar.log.level</code></td><td>控制分析期间生成的日志级别</td><td>INFO</td></tr><tr><td><code>sonar.verbose</code></td><td>向客户端和服务器端分析日志添加更多详细信息</td><td>false</td></tr><tr><td><code>sonar.showProfiling</code></td><td>显示日志以查看分析仪花费时间的位置</td><td>false</td></tr><tr><td><code>sonar.scanner.dumpToFile</code></td><td>将指向文件的完整属性列表输出到扫描程序API，作为调试分析的方法</td><td>xxx</td></tr><tr><td><code>sonar.scanner.metadataFilePath</code></td><td>设置扫描程序写入report-task.txt文件的位置，该文件包含ceTaskId等</td><td><code>sonar.working.directory</code>的值</td></tr></tbody></table></div><p><br><br><br><br><br></p><h2 id="后台任务"><a href="#后台任务" class="headerlink" title="后台任务"></a>后台任务</h2><p>Background Tasks</p><p>一个后台任务可以是:</p><ul><li>导入一个分析报告</li><li>the computation of a Portfolio</li><li>导入或导出一个项目</li></ul><p><br></p><h3 id="扫描程序完成分析后会发生什么"><a href="#扫描程序完成分析后会发生什么" class="headerlink" title="　扫描程序完成分析后会发生什么"></a>　扫描程序完成分析后会发生什么</h3><p>What happens after the scanner is done analyzing?</p><p>在相关后台任务完成之前，分析尚未完成。即使SonarScanner的日志显示执行完成，在完成后台任务之前，分析结果在SonarQube项目中将不可见。在SonarScanner外出分析代码后，分析结果(Sources, Issues, Metrics) - 分析报告 - 将发送到SonarQube Server，一共计算引擎进行最终处理。分析报告按顺序排队和处理。</p><p>在项目级别，当有待处理的分析报告等待消耗时，标题中的<strong>Pending（待处理）</strong>通知将在最近完成的分析的日期旁。</p><p>全局管理员可在<code>Administration &gt; Projects &gt; Background Tasks</code>查看当前队列；项目管理员可在<code>Administration &gt; Background Tasks</code>查看相关任务。</p><p><br><br><br></p><h3 id="如何知道分析报告处理失败的时间"><a href="#如何知道分析报告处理失败的时间" class="headerlink" title="如何知道分析报告处理失败的时间"></a>如何知道分析报告处理失败的时间</h3><p>How do I know when analysis report processing fails?</p><p>后台任务通常会成功，但有时候异常会导致处理失败。例如:</p><ul><li>处理大项目是内存不足(OOM)</li><li>现有模块或项目的密钥与报告中的密钥冲突</li><li>…</li></ul><p>当发生这种情况时，失败的状态会反映在项目主页上，但这需要有人注意到它。你还可以选择在后台任务失败时通过电子邮件接收通知(Notifications)——无论是逐个还是全局。</p><p><br><br><br></p><h3 id="如何诊断失败的后台任务"><a href="#如何诊断失败的后台任务" class="headerlink" title="如何诊断失败的后台任务"></a>如何诊断失败的后台任务</h3><p>How do I diagnose a failing background task?</p><p>对于没法分析报告，都有一个下拉菜单，允许你访问<strong>扫描程序上下文(Scanner Context)</strong>，显示代码扫描是扫描程序的配置。<br>如果任务处理失败，则可使用其它选项<strong>显示错误详细信息(Show Error Details)</strong>，以获取处理后台任务失败的详情。</p><p><br><br><br></p><h3 id="如何取消待处理的分析报告"><a href="#如何取消待处理的分析报告" class="headerlink" title="如何取消待处理的分析报告"></a>如何取消待处理的分析报告</h3><p>How do I cancel a pending analysis report?</p><p>管理员可通过单击取消处理待处理任务(pending task)，一旦报告开始处理，取消它就为时已晚。</p><p><br><br><br><br><br></p><h2 id="通用问题数据"><a href="#通用问题数据" class="headerlink" title="通用问题数据"></a>通用问题数据</h2><p>Generic Issue Data</p><p>SonarQube支持通用导入格式，用于在代码中引发<em>external</em> issues。它旨在允许你从你喜欢的<em>linter</em>导入issues，即使它不存在插件。</p><p>外部问题受到两个重要限制:</p><ul><li>它们无法在SonarQube内管理</li><li>在SonarQube中无法管理引发这些问题的规则的激活</li></ul><p><br></p><h3 id="Import"><a href="#Import" class="headerlink" title="Import"></a>Import</h3><p>分析参数<code>sonar.externalIssueReportPaths</code>接受以逗号分隔的报告路径列表。<br>每个报告必须在顶层(top-level)包含一个名为issues对象的问题对象数组。</p><p><strong>Issue字段:</strong></p><ul><li><code>engineId</code> - string</li><li><code>ruleId</code> - string</li><li><code>primaryLocation</code> - Location object</li><li><code>type</code> - string. One of BUG, VULNERABILITY, CODE_SMELL</li><li><code>severity</code> - string. One of BLOCKER, CRITICAL, MAJOR, MINOR, INFO</li><li><code>effortMinutes</code> - integer, optional. Defaults to 0</li><li><code>secondaryLocations</code> - array of Location objects, optional</li></ul><p><br></p><p><strong>Location字段:</strong></p><ul><li><code>message</code> - string</li><li><code>filePath</code> - string</li><li><code>textRange</code> - TextRange object, optional for secondary locations only</li></ul><p><br></p><p><strong>TextRange字段:</strong></p><ul><li><code>startLine</code> - integer. 1-indexed</li><li><code>endLine</code> - integer, optional. 1-indexed</li><li><code>startColumn</code> - integer, optional. 0-indexed</li><li><code>endColumn</code> - integer, optional. 0-indexed</li></ul><p><br><br><br></p><h3 id="栗子"><a href="#栗子" class="headerlink" title="栗子"></a>栗子</h3><p>以下是预期格式的栗子:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">&#123; &quot;issues&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;engineId&quot;: &quot;test&quot;,</span><br><span class="line">      &quot;ruleId&quot;: &quot;rule1&quot;,</span><br><span class="line">      &quot;severity&quot;:&quot;BLOCKER&quot;,</span><br><span class="line">      &quot;type&quot;:&quot;CODE_SMELL&quot;,</span><br><span class="line">      &quot;primaryLocation&quot;: &#123;</span><br><span class="line">        &quot;message&quot;: &quot;fully-fleshed issue&quot;,</span><br><span class="line">        &quot;filePath&quot;: &quot;sources/A.java&quot;,</span><br><span class="line">        &quot;textRange&quot;: &#123;</span><br><span class="line">          &quot;startLine&quot;: 30,</span><br><span class="line">          &quot;endLine&quot;: 30,</span><br><span class="line">          &quot;startColumn&quot;: 9,</span><br><span class="line">          &quot;endColumn&quot;: 14</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;effortMinutes&quot;: 90,</span><br><span class="line">      &quot;secondaryLocations&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;message&quot;: &quot;cross-file 2ndary location&quot;,</span><br><span class="line">          &quot;filePath&quot;: &quot;sources/B.java&quot;,</span><br><span class="line">          &quot;textRange&quot;: &#123;</span><br><span class="line">            &quot;startLine&quot;: 10,</span><br><span class="line">            &quot;endLine&quot;: 10,</span><br><span class="line">            &quot;startColumn&quot;: 6,</span><br><span class="line">            &quot;endColumn&quot;: 38</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;engineId&quot;: &quot;test&quot;,</span><br><span class="line">      &quot;ruleId&quot;: &quot;rule2&quot;,</span><br><span class="line">      &quot;severity&quot;: &quot;INFO&quot;,</span><br><span class="line">      &quot;type&quot;: &quot;BUG&quot;,</span><br><span class="line">      &quot;primaryLocation&quot;: &#123;</span><br><span class="line">        &quot;message&quot;: &quot;minimal issue raised at file level&quot;,</span><br><span class="line">        &quot;filePath&quot;: &quot;sources/Measure.java&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">]&#125;</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="通用测试数据"><a href="#通用测试数据" class="headerlink" title="通用测试数据"></a>通用测试数据</h2><p>Generic Test Data</p><p>开箱即用，SonarQube支持用于测试覆盖和测试执行导入的通用格式。如果你的语言不插件不支持你的Coverage引擎的本机输出格式，只需将它们转换为这些格式即可。</p><p><br></p><h3 id="Generic-Coverage"><a href="#Generic-Coverage" class="headerlink" title="Generic Coverage"></a>Generic Coverage</h3><p>报告路径应该以逗号分隔的列表传递给: <code>sonar.coverageReportPaths</code></p><p>支持的格式由<code>sonar-generic-coverage.xsd</code>进行描述:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;xs:schema&gt;</span><br><span class="line">  &lt;xs:element name=&quot;coverage&quot;&gt;</span><br><span class="line">    &lt;xs:complexType&gt;</span><br><span class="line">      &lt;xs:sequence&gt;</span><br><span class="line">        &lt;xs:element name=&quot;file&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;&gt;</span><br><span class="line">          &lt;xs:complexType&gt;</span><br><span class="line">            &lt;xs:sequence&gt;</span><br><span class="line">              &lt;xs:element name=&quot;lineToCover&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;&gt;</span><br><span class="line">                &lt;xs:complexType&gt;</span><br><span class="line">                  &lt;xs:attribute name=&quot;lineNumber&quot; type=&quot;xs:positiveInteger&quot; use=&quot;required&quot;/&gt;</span><br><span class="line">                  &lt;xs:attribute name=&quot;covered&quot; type=&quot;xs:boolean&quot; use=&quot;required&quot;/&gt;</span><br><span class="line">                  &lt;xs:attribute name=&quot;branchesToCover&quot; type=&quot;xs:nonNegativeInteger&quot;/&gt;</span><br><span class="line">                  &lt;xs:attribute name=&quot;coveredBranches&quot; type=&quot;xs:nonNegativeInteger&quot;/&gt;</span><br><span class="line">                &lt;/xs:complexType&gt;</span><br><span class="line">              &lt;/xs:element&gt;</span><br><span class="line">            &lt;/xs:sequence&gt;</span><br><span class="line">          &lt;xs:attribute name=&quot;path&quot; type=&quot;xs:string&quot; use=&quot;required&quot;/&gt;</span><br><span class="line">          &lt;/xs:complexType&gt;</span><br><span class="line">        &lt;/xs:element&gt;</span><br><span class="line">      &lt;/xs:sequence&gt;</span><br><span class="line">      &lt;xs:attribute name=&quot;version&quot; type=&quot;xs:positiveInteger&quot; use=&quot;required&quot;/&gt;</span><br><span class="line">    &lt;/xs:complexType&gt;</span><br><span class="line">  &lt;/xs:element&gt;</span><br><span class="line">&lt;/xs:schema&gt;</span><br></pre></td></tr></table></figure><p>看起来像这样:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;coverage version=&quot;1&quot;&gt;</span><br><span class="line">  &lt;file path=&quot;xources/hello/NoConditions.xoo&quot;&gt;</span><br><span class="line">    &lt;lineToCover lineNumber=&quot;6&quot; covered=&quot;true&quot;/&gt;</span><br><span class="line">    &lt;lineToCover lineNumber=&quot;7&quot; covered=&quot;false&quot;/&gt;</span><br><span class="line">  &lt;/file&gt;</span><br><span class="line">  &lt;file path=&quot;xources/hello/WithConditions.xoo&quot;&gt;</span><br><span class="line">    &lt;lineToCover lineNumber=&quot;3&quot; covered=&quot;true&quot; branchesToCover=&quot;2&quot; coveredBranches=&quot;1&quot;/&gt;</span><br><span class="line">  &lt;/file&gt;</span><br><span class="line">&lt;/coverage&gt;</span><br></pre></td></tr></table></figure><p>根节点应该命名为<code>coverage</code>，其<code>version</code>属性应设置为1。</p><p>为每个文件插入一个可由测试覆盖的文件元素。其<code>path</code>属性可以是绝对的，也可是相对的。它具有以下属性:</p><ul><li><code>lineNumber</code>(强制性)</li><li><code>covered</code>(强制性) - 布尔值，指示测试是否实际命中改行</li><li><code>branchesToCover</code>(可选) - 可覆盖的分支数量</li><li><code>coveredBranches</code>(可选) - 实际有测试覆盖的分支数量</li></ul><p><br><br><br></p><h3 id="Generic-Execution"><a href="#Generic-Execution" class="headerlink" title="Generic Execution"></a>Generic Execution</h3><p>报告路径应以逗号分隔的列表传递给: <code>sonar.testExecutionReportPaths</code></p><p>支持的格式如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;testExecutions version=&quot;1&quot;&gt;</span><br><span class="line">  &lt;file path=&quot;testx/ClassOneTest.xoo&quot;&gt;</span><br><span class="line">    &lt;testCase name=&quot;test1&quot; duration=&quot;5&quot;/&gt;</span><br><span class="line">    &lt;testCase name=&quot;test2&quot; duration=&quot;500&quot;&gt;</span><br><span class="line">      &lt;skipped message=&quot;short message&quot;&gt;other&lt;/skipped&gt;</span><br><span class="line">    &lt;/testCase&gt;</span><br><span class="line">    &lt;testCase name=&quot;test3&quot; duration=&quot;100&quot;&gt;</span><br><span class="line">      &lt;failure message=&quot;short&quot;&gt;stacktrace&lt;/failure&gt;</span><br><span class="line">    &lt;/testCase&gt;</span><br><span class="line">    &lt;testCase name=&quot;test4&quot; duration=&quot;500&quot;&gt;</span><br><span class="line">      &lt;error message=&quot;short&quot;&gt;stacktrace&lt;/error&gt;</span><br><span class="line">    &lt;/testCase&gt;</span><br><span class="line">  &lt;/file&gt;</span><br><span class="line">&lt;/testExecutions&gt;</span><br></pre></td></tr></table></figure><p>根节点应该被命名为<code>testExecutions</code>，它的<code>version</code>属性应该被设置成1。<br>为每个测试文件插入一个文件元素，其<code>path</code>属性可以是绝对的，也可是相对于模块的根。</p><p>注意，与覆盖率报告不同，报告中的文件必须是测试文件名，而不是测试所涵盖的源代码文件。</p><p>在<code>file</code>元素内，通过单元测试为每个测试运行插入一个<code>testCase</code>。它具有以下属性/子项:</p><ul><li><code>testCase</code>（强制性）<ul><li><code>name</code>（强制性）: 测试事例的名称</li><li><code>duration</code>(强制性): long value，ms为单位</li><li><code>failure|error|skipped</code>(可选): 如果测试不正确，请使用消息和长描述报告原因</li><li><code>message</code>(强制): 描述原因的短消息</li><li><code>stacktrace</code>（可选）: 包含有关失败、错误、跳过状态的详细信息</li></ul></li></ul><p><br><br><br><br><br></p><h2 id="PR分析"><a href="#PR分析" class="headerlink" title="PR分析"></a>PR分析</h2><p>Pull Request Analysis</p><p>PR分析是作为Developer Edtion的一部分提供。它允许你:</p><ul><li>在SonarQube UI中查看你的PR分析结果并查看状态以显示存在未解决的问题</li><li>在你的SCM提供商界面中使用SonarQube issue自动装饰你的PR</li></ul><p>从项目的<strong>branch and pull request</strong>的下拉菜单中可以在SonarQube中看到PR。启用PR装饰后，SonarQube会在PR上发布分析状态。</p><p><br><br><br><br><br></p><h2 id="SCM集成"><a href="#SCM集成" class="headerlink" title="SCM集成"></a>SCM集成</h2><p>在代码分期期间收集SCM数据可以解锁许多SonarQube功能:</p><ul><li>自动Issue分配</li><li>代码查看器中查看代码注释</li><li>SCM-driver的新代码检测，没有SCM数据，SonarQube使用分析日期确定新代码</li></ul><p>SCM集成需要你的SCM提供商，默认情况下支持SVN和Git。其它提供商，请参阅Marketplace。<br>如果需要，你可以通过管理设置将其在全局/项目级别将其关闭。</p><p><br></p><h3 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h3><p><br><br><br></p><h3 id="SVN"><a href="#SVN" class="headerlink" title="SVN"></a>SVN</h3><p><br><br><br></p><hr><p><br><br><br></p><h1 id="Branches"><a href="#Branches" class="headerlink" title="Branches"></a>Branches</h1><p>分支分析作为Developer Editon的一部分提供。分支分析允许你:</p><ul><li>分析 long-lived branches</li><li>分析 short-lived branches</li><li>在短期分支的状态受到影响时通知外部系统</li></ul><p><br></p><p>由于分支功能是开发版(也就是付费版)功能，因此社区版只能对每个分支创建一个项目。</p><p>例如:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">repo: zhang-repo</span><br><span class="line"></span><br><span class="line">branch:</span><br><span class="line">  - master</span><br><span class="line">  - test</span><br><span class="line">  - zhang</span><br><span class="line"></span><br><span class="line">projects:</span><br><span class="line">  - zhang-repo-master</span><br><span class="line">  - zhang-repo-test</span><br><span class="line">  - zhang-repo-zhang</span><br></pre></td></tr></table></figure><p><br><br><br></p><hr><p><br><br><br></p><h1 id="用户指南"><a href="#用户指南" class="headerlink" title="用户指南"></a>用户指南</h1><p>User Guide</p><p><br></p><h2 id="修复漏水"><a href="#修复漏水" class="headerlink" title="修复漏水"></a>修复漏水</h2><p>Fixing the Water Leak</p><p><br></p><h3 id="什么是漏水"><a href="#什么是漏水" class="headerlink" title="什么是漏水"></a>什么是漏水</h3><p>What is the Water Leak</p><p>想象一下，有一天你回到家发现厨房地板上有一滩水，水慢慢变大。<br>你想去拿拖把？还是找到漏水源头并修复它？选择很明显，你得修复它。</p><p>那么为什么与代码质量(code quality)有什么不同呢？当你使用SonarQube分析应用程序并意识到它有很多技术债务(technical debt)，这种下意识的反应通常是开始修复-这样那样，要么整理一个补救计划。这就像每天拖地一次而却忽略了漏水源头一样。</p><p><br></p><p>通常在这种传统方法中，在发布版本之前，定期进行代码质量(code quality)审计结果是开发人员在发布之前应该采取的行动。这种方法可能在短期内有效，特别是在强有力的管理支持下，但在中长期内始终失败，因为:</p><ul><li>代码审查(code review)过程太迟，没有利益相关者热衷于解决问题，每个人都希望新版本发布</li><li>开发者通常会推迟不了解项目上下文的外部团队提出的建议。顺便提一下，正在审查的代码已经过时了</li><li>使用这种方法明显缺乏对代码质量的所有权。谁拥有质量审查权限？没有人</li><li>在整个应用程序投入生产之前，需要检查整个应用程序，显然不可能对所有应用程序使用相同的标准。每个项目都会进行谈判，这将耗尽整个过程的可信度</li></ul><p><br></p><p>相反，为什么不将你在家中使用的相同的简单逻辑应用于管理代码质量的方式？修复泄露(leak)意味着将重点放在<strong>新代码</strong>上，即自上次发布以来添加或更改的代码。然后事情就变得很容易了:</p><ul><li>Quality Gate可以每天运行，并且可通过它。发版时没有任何意外</li><li>开发人员很难回避他们前一天介绍的问题。相反，他们通常很乐意在代码仍然新鲜时修复问题</li><li>代码质量有明确的所有权</li><li>做不做的标准在不同的应用程序中是一致的，并且在团队之间共享</li><li>成本微不足道，因为它是开发过程中的一部分</li></ul><p>最为奖励，变化最大的代码具有最高的可维护性，并且未变更的代码具有最低的维护性，这很有意义。</p><p><br><br><br></p><h3 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h3><p>SonarQube提供两种主要工具来帮助你找到泄漏点:</p><ul><li>新代码指标(metrics)显示当前代码与你在其历史记录(<code>previous_version</code>)中选择的特定点之间的度量差异</li><li>新代码主要基于SCM blame 数据监测，从新代码期(泄漏期)的第一次分析开始，需要时使用回退机制</li><li>Quality Gates允许你设置测量代码的布尔阈值。将它们与差异指标一起使用，可确保你的代码质量随着时间的推移在正确的方向上行驶</li></ul><p><br><br><br><br><br></p><h2 id="项目页"><a href="#项目页" class="headerlink" title="项目页"></a>项目页</h2><p>Project Page</p><p>项目主页(Project Homepage)是任何项目的切入点，它显示:</p><ul><li>the releasability status of the project</li><li>the current state of its quality</li><li>the quality of what has been produced since the beginning of its New Code Period</li></ul><p>项目页面回答了两个问题:</p><ul><li>can I release my project today?</li><li>if not, what should I improve to make the project pass the Quality Gate?</li></ul><p><br></p><h3 id="今天能发版吗"><a href="#今天能发版吗" class="headerlink" title="今天能发版吗"></a>今天能发版吗</h3><p>Can I release today?</p><p>由于 Quality Gate 是你执行质量策略的最强大的工具，因此该页面以项目的当前质量门状态开始。如果项目通过，则会显示一个简单的绿色全清除。</p><p>如果没有，可立即获得详细信息和drill-downs，以便快速识别出错的地方，每个错误条件的一个部分显示当前项目值是什么以及它应该是什么。像往常一样，你可以点击当前值来进行深入分析。</p><p><br><br><br></p><h3 id="应该优先解决什么"><a href="#应该优先解决什么" class="headerlink" title="应该优先解决什么"></a>应该优先解决什么</h3><p>What should I fix first?</p><p>因为提高项目质量的最佳方法是在问题变得根深蒂固之前捕获并修复新问题，项目的第一个视图以新代码周期为中心，在项目主页右侧以黄色突出显示。项目空间页面显示关键指标的高级摘要，包括当前值和新代码周期值。</p><p>在Quality Gate信息的下方，可以获得可靠性和安全域中的旧问题和新问题的数量。然后是可维护性域。单击页面上的任何图形将转到“详细信息”页面或“问题”页面中的详细视图。</p><p>开发人员必须做的最重要的事情是确保屏幕黄色部分的新问题得到确认，审核和修复，并确保测试涵盖新代码以防止将来出现回归。无论过去引入了多少问题，或者总体上测试覆盖范围有多少，关注新增问题将确保情况不会降低您之前在生产中发布的版本。</p><p>那么，您应该先找到哪些问题：错误，漏洞或代码异味？这取决于，因为答案取决于您的问题的性质。假设你有一个重复5次的代码块问题，在这个重复的代码块中，你有3个Bug和5个安全问题。最好的方法可能是首先修复重复，然后解决新集中位置的错误和漏洞，而不是修复它们5次。<br>这就是为什么您需要在开始解决之前检查新问题。</p><p><br><br><br><br><br></p><h2 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h2><p>Applications are available as part of the Enterprise Edition.</p><p><br><br><br><br><br></p><h2 id="Portfolios"><a href="#Portfolios" class="headerlink" title="Portfolios"></a>Portfolios</h2><p>Portfolios are available as part of the Enterprise Edition.</p><p><br><br><br><br><br></p><h2 id="Issues"><a href="#Issues" class="headerlink" title="Issues"></a>Issues</h2><p>在运行分析时，每当一段代码破坏编码规则时，SonarQube就会引发一个issue。编码规则(coding rules)是通过每种语言的相关质量配置文件定义的。</p><p>每个问题有五种严重程度:</p><ul><li><strong>BLOCKER</strong> - 很有可能影响生产中应用程序行为的错误。必须立即修复</li><li><strong>CRITICAL</strong> - 要么是在生产环境中影响应用程序行为可能性很小的bug，要么是代表安全漏洞的问题。必须立即检查代码</li><li><strong>MAJOR</strong> - 可能严重影响开发人员生产力的质量缺陷</li><li><strong>MINOR</strong> - 会轻微影响开发人员生产力产生的质量缺陷</li><li><strong>INFO</strong> - 既不是错误，也不是质量缺陷，只是一个提示</li></ul><p><br></p><h3 id="理解issue上下文"><a href="#理解issue上下文" class="headerlink" title="理解issue上下文"></a>理解issue上下文</h3><p>Understanding issue context</p><p>有时，一旦指出问题，问题就不言而喻了。例如，你的团队已约定了变量命名规则，在某个变量名出线问题时，你不需要理解大量上下文来理解该问题。但在其它情况下，上下文可能对理解为什么会出现这个问题至关重要。这就是为什么SonarQube不仅支持显示问题消息的主要问题位置，还支持次要问题位置。</p><p>但有时候，贡献位置地点并不足以理解问题。例如，当通过代码在某些路径上取消引用空指针时，您真正需要的是问题流。每个流程都是一组辅助位置，用于显示可能发生问题的代码的确切路径。</p><p><br><br><br></p><h3 id="生命周期"><a href="#生命周期" class="headerlink" title="生命周期"></a>生命周期</h3><p>Lifecycle of Code Smell, Bug, and Vulnerability Issues</p><p><br></p><h4 id="状态"><a href="#状态" class="headerlink" title="状态"></a>状态</h4><p>Status</p><p>创建之后，Issue会在生命周期中流动，可能为以下五种状态之一:</p><ul><li><strong>打开(Open)</strong> - 由SonarQube在新问题上设定</li><li><strong>确认(Confirmed)</strong> - 手动确认以指示问题有效</li><li><strong>解决(Resolved)</strong> - 手动设置以指示下一个分析应该关闭改问题</li><li><strong>重开(Reopened)</strong> - 当一个已解决的问题实际上没有得到纠正时，SonarQube会自动设置</li><li><strong>关闭(Closed)</strong> - 有SonarQube自动设置自动创建的问题</li></ul><p><br><br><br></p><h4 id="处理方式"><a href="#处理方式" class="headerlink" title="处理方式"></a>处理方式</h4><p>Resolutions</p><p>已关闭的问题将有一下两种方式之一:</p><ul><li><strong>已修复(Fixed)</strong> - 当后续分析显示问题已更正或文件不再可用时自动设置</li><li><strong>已移除(Removed)</strong> - 当相关规则不再可用时自动设置。改规则可能无法使用，因为它已从质量配置文件中删除，或者因为已卸载基础插件</li></ul><p>Resolved issues好友两个处理方式:</p><ul><li><strong>误判(False Positive)</strong> - 手动设置</li><li><strong>不会修复(Won’t Fix)</strong> - 不会修复</li></ul><p><br><br><br></p><h4 id="问题工作流程"><a href="#问题工作流程" class="headerlink" title="问题工作流程"></a>问题工作流程</h4><p>Issue Workflow</p><p>在以下情况下，问题会自动关闭(Status: Closed):</p><ul><li>问题以正确修复（Resolution: Fixed）</li><li>问题不再存在，因为相关编码规则已停用或不再可用(Resolution: Removed)</li></ul><p>在以下情况下，问题会自动重新打开(Status: Reopened):</p><ul><li>手动修改解决方式为已修复(但是不是误判)的问题，有后续分析显示仍然存在</li></ul><p><br><br><br></p><h3 id="安全热点问题的生命周期"><a href="#安全热点问题的生命周期" class="headerlink" title="安全热点问题的生命周期"></a>安全热点问题的生命周期</h3><p>Lifecycle of Security Hotspot Issues</p><p>安全热点问题具有专用的生命周期。它们不被视为可操作，必须由具有相关权限的用户进行审核。</p><p>创建之后，安全热点问题将流经专用的生命周期，可能是以下四种状态之一:</p><ul><li><strong>Open</strong> - 由SonarQube在新问题上自动设置</li><li><strong>Resolved</strong>(Won’t Fix) - 当安全审核员接受开发人员针对手动漏洞所做的修复或安全审核员清楚打开的热点或手动漏洞时，SonarQube会自动设置</li><li><strong>To Revied</strong> - 当开发人员请求安全审核员查看他对手动漏洞所做的修复时自动设置</li><li><strong>Reopened</strong> - 当开发人员解除打开的手动漏洞或安全审计员手动重新打开问题以便对已解决的问题运行新审计时设置</li></ul><p>如果删除了包含安全热点的代码，则只会关闭安全热点问题。如果从项目的质量配置文件中删除了标识热点的规则，则安全热点也可能会被删除。</p><p><br><br><br></p><h3 id="理解哪些问题是新的"><a href="#理解哪些问题是新的" class="headerlink" title="理解哪些问题是新的"></a>理解哪些问题是新的</h3><p>Understanding which Issues are “New”</p><p>为了确定问题的创建日期，在每次分析期间执行算法已确定问题是新的还是之前存在的。此算法依赖于报告问题的行的内容的哈希值(不包括空格)。对于多行问题，使用第一行的哈希值。对于每个文件(在检测到文件重命名后)，算法将从先前的分析中获取问题的基本列表，并尝试将这些问题与新分析报告的原始问题列表进行匹配。该算法尝试使用最强的证据进行首次匹配，然后再回到较弱的启发式算法。</p><ul><li>如果问题是在同一规则上，具有相同的行号和相同的行哈希 - 匹配</li><li>检测到块在文件内移动，然后如果问题出在同一行(移动的)和同一条规则上- 匹配</li><li>在相同的规则上，使用相同的消息并使用相同的行哈希 - 匹配</li><li>在相同的规则上，使用相同的消息并使用相同的行号 - 匹配</li><li>在相同的规则上，使用相同的行哈希 - 匹配</li><li>是否有匹配CLOSED的问题 - 匹配和重新打开</li></ul><p><br><br><br></p><h3 id="了解问题回溯"><a href="#了解问题回溯" class="headerlink" title="了解问题回溯"></a>了解问题回溯</h3><p>Understanding Issue Backdating</p><p>一旦问题被确定为新，下一个问题便是提供它的日期。例如，如果它已经在代码中存在了很长时间，但只能在最近的分析中找到，因为新的规则被添加到配置文件中？该问题是否应该在其行的最后一次更改日期或首次提出的分析日期之间给出？那就是它应该回溯吗？</p><p>如果最后一次更改改行的日期可用，那么在某些情况下，该问题将被回溯:</p><ul><li>首先分析项目或分支</li><li>当配置文件中的规则为新时</li><li>当分析程序升级后</li><li>当规则是外部的</li></ul><p>因此，回溯可能会使新提出的问题原理New Code Period。</p><p><br><br><br></p><h3 id="自动问题分配"><a href="#自动问题分配" class="headerlink" title="自动问题分配"></a>自动问题分配</h3><p>Automatic Issue Assignment</p><ul><li>For Bug, Vulnerability and Code Smell</li><li>For Security Hotspot</li><li>User Correlation</li><li>Known Limitation</li></ul><p><br><br><br></p><h3 id="问题编辑"><a href="#问题编辑" class="headerlink" title="问题编辑"></a>问题编辑</h3><p>Issue edits</p><p>SonarQube的问题工作流程可帮助你管理问题。你可对一个Issue做七件不同事情，这些行为可分为三类:</p><ul><li>Technical Review<ul><li>Confirm</li><li>False Positive</li><li>Won’t Fix</li><li>Severity change</li><li>Resolve</li></ul></li><li>Security Hotspots<ul><li>Detect</li><li>Clear</li><li>Request Review</li><li>Reject</li></ul></li><li>Dispositioning</li><li>General<ul><li>Comments</li><li>Tag</li></ul></li><li>Bulk Change</li></ul><p><br><br><br></p><h3 id="清除已解决的问题"><a href="#清除已解决的问题" class="headerlink" title="清除已解决的问题"></a>清除已解决的问题</h3><p>Purging Closed Issues</p><p>默认情况下，已关闭的问题将保留30天。当然，你也可以修改它。</p><p><br><br><br><br><br></p><h2 id="Rules"><a href="#Rules" class="headerlink" title="Rules"></a>Rules</h2><p>SonarSource Rules: <a href="https://rules.sonarsource.com/" target="_blank" rel="noopener">https://rules.sonarsource.com/</a></p><p><br></p><h3 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h3><p>在SonarQube中，分析程序提供在源代码上执行的规则来生成问题。有四种类型的规则:</p><ul><li>Code Smell (Maintainability domain)</li><li>Bug (Reliability domain)</li><li>Vulnerability (Security domain)</li><li>Security Hotspot (Security domain)</li></ul><p><br><br><br></p><h3 id="规则"><a href="#规则" class="headerlink" title="规则"></a>规则</h3><p>默认情况下，点击带单栏<strong>Rules</strong>时，你将看到SonarQube实例上安装的分析程序带来的所有可用规则。你可根据以下条件缩小范围:</p><ul><li>Language</li><li>Type</li><li>Tag</li><li>Repository</li><li>Default Severity</li><li>Status</li><li>Available Since</li><li>Template: 显示允许创建自定义规则的规则模板</li><li>Quality Profile</li></ul><p><br><br><br></p><h3 id="规则细节"><a href="#规则细节" class="headerlink" title="规则细节"></a>规则细节</h3><p>要查看规则的详细信息，请点击它。除了基本规则数据之外，您还可以查看其中活动的配置文件（如果有）以及已经引发了多少未解决的问题。<br>只有拥有正确的权限时，才能使用以下两个操作:</p><ul><li>Add/Remove Tags</li><li>Extend Description</li></ul><p><br><br><br></p><h3 id="规则模板和自定义规则"><a href="#规则模板和自定义规则" class="headerlink" title="规则模板和自定义规则"></a>规则模板和自定义规则</h3><p>Rule Templates and Custom Rules</p><p>规则模板(Rule templates)由创建提供，允许用户在SonarQube中定义自己的规则。它位于<code>Rules -&gt; Template</code>。</p><p>要从模板创建自定义规则，你必须填写一下信息:</p><ul><li>Name</li><li>Key (auto-suggested)</li><li>Description (Markdown format is supported)</li><li>Default Severity</li><li>Status</li><li>The parameters specified by the template</li></ul><p><br><br><br></p><h3 id="扩展编码规则"><a href="#扩展编码规则" class="headerlink" title="扩展编码规则"></a>扩展编码规则</h3><p>Extending Coding Rules</p><p>可以添加<a href="https://docs.sonarqube.org/display/DEV/Adding+Coding+Rules" target="_blank" rel="noopener">自定义编码规则</a>。</p><p><br><br><br></p><h3 id="规则类型和严重性"><a href="#规则类型和严重性" class="headerlink" title="规则类型和严重性"></a>规则类型和严重性</h3><p>Rule Types and Severities</p><p>Type:</p><ul><li>Bug</li><li>Vulnerability</li><li>Code Smell</li><li>Security Hotspot</li></ul><p>Severity:</p><ul><li>Blocker</li><li>Critical</li><li>Major</li><li>Minor</li><li>Info</li></ul><p><br><br><br></p><h2 id="安全相关的规则"><a href="#安全相关的规则" class="headerlink" title="安全相关的规则"></a>安全相关的规则</h2><p>Security-related Rules</p><p>SonarQube质量类型有三种不同的规则:</p><ul><li>Reliability (bug)</li><li>Vulnerability (security)</li><li>Maintainability (code smell)</li></ul><p>但另外一种方式，只有两种类型:</p><ul><li>security rule</li><li>其它</li></ul><p>两者之间的区别并不在它们捕获的内容，而在于她们来自何处以及强加于它们的标准。</p><p><br></p><h3 id="从安全相关的规则的期望是什么"><a href="#从安全相关的规则的期望是什么" class="headerlink" title="从安全相关的规则的期望是什么"></a>从安全相关的规则的期望是什么</h3><p>What to expect from security-related rules</p><p>需要明确的是，SonarQube语言插件中实现的大多数规则的标准是非常严格: 没有误报。对于正常规则，你应该能够确信任何报告给你的问题确实是一个问题。</p><p>但对于与安全相关的规则，情况略有不同。例如，许多安全指南讨论了应如何处理<em>敏感数据</em>。但是，由于规则中不可能确定哪些数据是敏感，哪些是不敏感。因此选择变为： 保持无误判标准并且不实施与安全相关的规则，或者实施与安全的规则不同的标准。</p><p>这就是为什么与安全相关的规则很广泛。官方的想法是，该规则将标记任何可疑的内容，并将其留给安全审核人员来剔除误报并发送真正的问题进行补救。</p><p>安全热点是一种特殊类型的问题，用于识别安全审核人员应审核的敏感区域，以确定它们是否真的是漏洞。有关热点和审计过程的详细信息，请参阅安全审核和报告。</p><p><br><br><br></p><h3 id="与安全相关的规则来自何方"><a href="#与安全相关的规则来自何方" class="headerlink" title="与安全相关的规则来自何方"></a>与安全相关的规则来自何方</h3><p>Where security-related rules come from</p><p>绝大多数与安全相关的规则源于既定标准:</p><ul><li><strong>CWE(Common Weakness Enumeration)</strong>：是美国MITRE机构提出的一套语言标准，用于描述软件安全弱点的通用化描述语言。每个CWE条目都包含了CWE标识符/弱点类型名称、类型的描述、弱点的行为、弱点的利用方法、利用弱点的可能性、可能导致的后果、应对措施、代码示例、对应的CVE漏洞数量、参考信息等内容。</li><li><strong>SANS Top 25</strong> - <a href="https://www.sans.org/top25-software-errors/" target="_blank" rel="noopener">CWE/SANS TOP 25 Most Dangerous Software Errors</a></li><li><strong>OWASP Top 10</strong> - <a href="https://www.owasp.org/index.php/Top_10-2017_Top_10" target="_blank" rel="noopener">OWASP Top 10 Application Security Risks</a></li></ul><p>要查找与任何这些标准相关的规则，你可以按标签或文本搜索规则。</p><p><br></p><h4 id="CWE"><a href="#CWE" class="headerlink" title="CWE"></a>CWE</h4><p>CWE标准代表Common Weakness Enumeration:</p><p>Common Weakness Enumeration (CWE™) 是一个常见软件弱点的正式列表或字典，可能出现在软件的体系结构、设计代码或实现中。可能导致可利用的安全漏洞。创建CWE是为了描述软件安全漏洞的通用语言，作为针对这些弱点的软件安全工具的衡量标准；并为弱点识别、缓解和预防工作提供共同的基线标准。<br>CWE是弱化的描述的层次结构。层次结构中的最低级别是弱点基础(Weakness Base)，它描述了细腻度的弱点。</p><p>符合特定要求的工具可以认证为CWE兼容。这些要求是:</p><ul><li>您必须能够使用CWE标识符搜索与CWE相关的规则。要在SonarQube平台中执行此操作，只需将CWE标识符（例如CWE-595）放在规则页面上的搜索文本输入中并运行搜索</li><li>规则必须与其相关的CWE项目准确链接。要查看SonarQube规则的CWE映射，请参阅规则说明底部的规则参见部分</li><li>您必须能够从问题中识别相关的CWE。要在SonarQube平台中执行此操作，请参阅相关规则</li><li>产品文档必须包含CWE和CWE兼容性的说明</li><li>除了通过CWE id搜索规则外，您还可以通过 cwe rule tag 进行搜索</li></ul><p><br><br><br></p><h4 id="SANS-TOP-25"><a href="#SANS-TOP-25" class="headerlink" title="SANS TOP 25"></a>SANS TOP 25</h4><p>SANS Top 25列表是由SANS组织编制的CWE中列出的25个最危险错误的集合。当前的SANS列表分为三类：</p><ul><li>Insecure Interaction Between Components</li><li>Risky Resource Management</li><li>Porous Defenses</li></ul><p>要查找与SANS Top 25相关的规则，您可以对类别或相关CWE项目执行文本搜索，或执行规则标记搜索。</p><p><br><br><br></p><h4 id="OWASP-Top-10"><a href="#OWASP-Top-10" class="headerlink" title="OWASP Top 10"></a>OWASP Top 10</h4><p>OWASP代表Open Web Application Security Project。它是:</p><p><code>501(c)(3)</code>全球非营利慈善组织，致力于提高软件的安全性。我们的使命是使软件安全可见，以便全世界的个人和组织能够就真正的软件安全风险做出明智的决策。</p><p>OWASP Top 10列出了各种各样的弱点，每个弱点都可以映射到许多单独的规则。<br>OWASP TOP 10在SonarQube中也对应相关的tag。</p><p>要查找与OWASP Top 10相关的规则，您可以对类别执行文本搜索，或执行规则标记搜索。</p><p><br><br><br><br><br></p><h2 id="內建规则和标签"><a href="#內建规则和标签" class="headerlink" title="內建规则和标签"></a>內建规则和标签</h2><p>Built-in Rule Tags</p><p>标签(tag) 是一种对问题(issue)和规则(rule)进行分类的方法。问题会继承引发它们的规则上的标记。有些标签适用于特定语言，但是更多的标签出现在各种语言中。用户可以为规则和问题添加标签。但大多数规则都有一些开箱即用的标签。<br>以下是一些非全面的、包含一些內建标签:</p><ul><li><code>brain-overload</code> - 一次有太多的东西要留在脑海里</li><li><code>bad-practice</code> - 代码可能按设计工作，但它的设计方式被广泛认为是一个坏主意</li><li><code>cert</code> - 设计CERT标准中的规则</li><li><code>clumsy</code> - 用于完成可以更清晰和简洁地完成的事情的额外步骤</li><li><code>confusing</code> - 将使维护者更长时间地理解，而不是代码实际所做的事情</li><li><code>convention</code> - 编码约定，如格式化、命名、空格…</li><li><code>cwe</code> - CWE安全规则</li><li><code>design</code> - 代码设计存在一些问题</li><li><code>lock-in</code> - 使用特定于环境的功能</li><li><code>misra</code> - MISRA标准相关的规则</li><li><code>owasp</code> - 与OWASP TOP 10安全标准相关的规则</li><li><code>pitfall</code> - 没有什么不对，但未来可能出现问题;已经为下一个人设置了一个陷阱，他可能会陷入其中并搞砸了代码</li><li><code>sans-top25</code> - 与SANS Top 25 Coding Errors安全相关</li><li><code>suspicious</code> - 它不能保证这是一个bug，但它看起来很可疑。至少，代码应该重新检查并且可能为了清晰而重构</li><li><code>unpredictable</code> - 代码可以在当前条件下正常工作，但如果条件发生变化可能会失败</li><li><code>unused</code> - 未使用的代码</li><li><code>user-experience</code> - 代码在技术上没有任何问题，但它可能会使您的部分或全部用户讨厌您</li></ul><p><br><br><br><br><br></p><h2 id="Quality-Gates"><a href="#Quality-Gates" class="headerlink" title="Quality Gates"></a>Quality Gates</h2><p><br></p><h3 id="概述-3"><a href="#概述-3" class="headerlink" title="概述"></a>概述</h3><p>质量阈(Quality Gates)是你在组织中实施质量策略的最佳方式。它可以回答一个问题: 我今天可以将项目发上线吗？<br>为了回答这个问题，你可以根据测量项目的度量阈值定义一组布尔条件，例如:</p><ul><li>No new blocker issues</li><li>Code coverage on new code greater than 80%</li><li>…</li></ul><p>理想状况下，所有项目都将通过同一质量阈进行验证。但这并不总是实用的。例如，你可能会发现:</p><ul><li>技术实现因应用程序而异</li><li>您希望确保对某些应用程序有更强的要求</li><li>…</li></ul><p>这就是为什么你可以根据需要自定义质量阈，它就在顶部的菜单栏上。</p><p><br><br><br></p><h3 id="最佳质量阈配置"><a href="#最佳质量阈配置" class="headerlink" title="最佳质量阈配置"></a>最佳质量阈配置</h3><p>Use the Best Quality Gate Configuration</p><p>质量阈默认激活并视为內建和只读的<code>Sonar war</code>方式，由SonarQube提供。它代表了我们对实施修复泄露。根据SonarQube的功能自动调整</p><p>有三个指标允许你强制执行给定的可靠性，安全性和可维护性的评级。不仅仅是整体而且还有新代码。建议使用这些指标，并将其作为默认质量阈的一部分，以便开发人员在项目页面上查看质量阈时更清楚的反馈。</p><p>不要忘记质量阈条件必须使用差值，检查绝对值是没有意义的(如: 代码行数大于1000)。</p><p><br></p><p><strong>推荐的质量阈(Recommended Quality Gate)</strong></p><p>內建的<code>Sonar way</code>质量阈都推荐用于大多数项目。如果专注于保持新代码清洁，而不是花费大量时间来修复旧代码。它开箱即用，已被设置为默认配置文件。</p><p><br><br><br></p><h3 id="质量阈状态"><a href="#质量阈状态" class="headerlink" title="质量阈状态"></a>质量阈状态</h3><p>Quality Gate Status</p><p><img src="/images/SonarQube/quality-gate-status.jpeg" alt></p><p><br><br><br></p><h3 id="当质量阈失败时获得通知"><a href="#当质量阈失败时获得通知" class="headerlink" title="当质量阈失败时获得通知"></a>当质量阈失败时获得通知</h3><p>Getting Notified When a Quality Gate Fails</p><p>使用通知机制，在质量阈失败时通知用户。为此，请订阅<strong>New quality gate status</strong>通知。</p><p><br><br><br></p><h3 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h3><p>Security</p><p>任何用户(甚至是匿名用户)都可以访问质量阈。<br>要就行更改(create, edit, delete)，必须授予用户管理质量阈的权限。<br>项目管理员可选择与他们项目相关的质量阈。</p><p><br><br><br></p><h3 id="定义质量阈"><a href="#定义质量阈" class="headerlink" title="定义质量阈"></a>定义质量阈</h3><p>Defining Quality Gates</p><p>要管理质量阈，请转到菜单栏的<strong>Quality Gates</strong>。</p><p>每个质量阈条件都是以下组合:</p><ul><li>测量(measure)</li><li>比较符(comparison operator)</li><li>错误值(error value)</li></ul><p>栗子，条件可能是:</p><ul><li>measure: <code>Blocker issue</code></li><li>comparison operator: <code>&gt;</code></li><li>error value: <code>0</code></li></ul><p><br><br><br><br><br></p><h2 id="指标"><a href="#指标" class="headerlink" title="指标"></a>指标</h2><p>Metric Definitions</p><p>项目有如下指标:</p><ul><li>复杂度(Complexity)</li><li>重复(Duplications)</li><li>问题(Issues)</li><li>可维护性(Maintainability)</li><li>质量阈(Quality Gates)</li><li>可靠性(Reliability)</li><li>安全性(Security)</li><li>大小(Size)</li><li>测试(Tests)</li></ul><p><br></p><h3 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h3><p>应用的控制流是简单还是复杂。</p><p><br></p><h4 id="圈复杂度"><a href="#圈复杂度" class="headerlink" title="圈复杂度"></a>圈复杂度</h4><p>Cyclomatic Complexity</p><p>可以计算出达到全面覆盖需要的最少测试用例。<br>它是基于通过代码的路径数计算的，每当函数的控制流分裂时，复杂度计数器就会增加1。每个函数的最小复杂度为1.此计算因语言而异，因为关键字和功能有所不同。</p><p><br></p><p><strong>特定语言的详细信息:</strong></p><div class="table-container"><table><thead><tr><th>Language</th><th>Notes</th></tr></thead><tbody><tr><td>ABAP</td><td>这些关键字将使复杂度加一: <code>AND , CATCH , CONTINUE , DO , ELSEIF , IF , LOOP , LOOPAT , OR , PROVIDE , SELECT…ENDSELECT , TRY , WHEN , WHILE</code></td></tr><tr><td>C/C++/Objective-C</td><td>复杂度加一: `function definitions, while , do while , for , throw statements, switch , case , default , &amp;&amp; operator,</td><td></td><td>operator, ? ternary operator, catch , break , continue , goto`</td></tr><tr><td>COBOL</td><td>复杂度加一: <code>ALSO , ALTER , AND , DEPENDING , END_OF_PAGE , ENTRY , EOP , EXCEPTION , EXIT , GOBACK , CONTINUE , IF , INVALID , OR , OVERFLOW , SIZE , STOP , TIMES , UNTIL , USE , VARYING , WHEN , EXEC CICS HANDLE , EXEC CICS LINK , EXEC CICS XCTL , EXEC CICS RETURN</code></td></tr><tr><td>Java</td><td>复杂度加一: `if , for , while , case , catch , throw , &amp;&amp; ,</td><td></td><td>, ?`</td></tr><tr><td>JS, PHP</td><td>复杂度加一: `function, if, &amp;&amp;,</td><td></td><td>, loop, switch case, throw, catch, go to`</td></tr><tr><td>PL/I</td><td>复杂度加一: `PROC , PROCEDURE , GOTO , GO TO , DO , IF , WHEN ,</td><td>, ! ,</td><td>= , != , &amp; , &amp;=`</td></tr><tr><td>PL/SQL</td><td>复杂度加一: create procedure, create trigger, procedure definition, basic loop statement, when clause statement, continue statement,exit statement, for loop statement, forall statement, if statement, elsif clause, raise statement, return statement, while loop statement, and expression, or expression, when clause expression</td></tr><tr><td>VB.NET</td><td>复杂度加一: <code>method or constructor declaration,  AndAlso , Case , Continue , End , Error , Exit , If , Loop , On Error , GoTo , OrElse , Resume , Stop , Throw , Try</code></td></tr></tbody></table></div><p><br><br><br></p><h4 id="认知复杂度"><a href="#认知复杂度" class="headerlink" title="认知复杂度"></a>认知复杂度</h4><p>Cognitive Complexity</p><p>对应这个应用是否很难被理解，理解代码的控制流程有多难。</p><p><br><br><br></p><h3 id="重复"><a href="#重复" class="headerlink" title="重复"></a>重复</h3><p>有:</p><ul><li>重复的块(Duplicated blocks)</li><li>重复的行(Duplicated lines)</li><li>重读文件(Duplicated files)</li><li>密度/重复行%(Duplicated lines %)</li></ul><p><br></p><h4 id="重复的块"><a href="#重复的块" class="headerlink" title="重复的块"></a>重复的块</h4><p>重复的行的块数。</p><p><br></p><p><strong>特定语言的详细信息</strong></p><p>非Java项目:</p><ul><li>There should be at least 100 successive and duplicated tokens.</li><li>Those tokens should be spread at least on:<ul><li>30 lines of code for COBOL</li><li>20 lines of code for ABAP</li><li>10 lines of code for other languages</li></ul></li></ul><p>Java项目:</p><p>There should be at least 10 successive and duplicated statements whatever the number of tokens and lines.检测重复时忽略缩进和字符串文字的差异。</p><p><br><br><br></p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>有:</p><ul><li>新问题(New issues)</li><li>新的严重问题(New xxx issues)</li><li>所有问题(Issues)</li><li>严重问题(xxx issues)</li><li>误判问题(False positive issues)</li><li>开启问题(Open issues)</li><li>确认问题(Confirmed issues)</li><li>重开问题(Reopened issues)</li></ul><p><br><br><br></p><h3 id="可维护性"><a href="#可维护性" class="headerlink" title="可维护性"></a>可维护性</h3><p>有:</p><ul><li>异味(Code Smells)</li><li>新异味(New Code Smells)</li><li>维护率(Maintainability Rating)</li><li>技术债务(Technical Debt)</li><li>新代码的技术债务(Technical Debt on New Code)</li><li>技术债务率(Technical Debt Ratio)</li><li>新代码的技术债务率(Technical Debt Ratio on New Code)</li></ul><p><br></p><h4 id="维护率"><a href="#维护率" class="headerlink" title="维护率"></a>维护率</h4><p>使用<strong>SQALE评级</strong>。与您的技术债务比率值相关的项目评级。<br>默认的可维护性评级网格是:</p><ul><li>A=<code>0-0.05 (&lt;5%)</code></li><li>B=<code>0.06-0.1 (6%-10%)</code></li><li>C=<code>0.11-0.20(11%-20%)</code></li><li>D=<code>0.21-0.5(21%-50%)</code></li><li>E=<code>0.51-1(50%-100%)</code></li></ul><p><br><br><br></p><h4 id="技术债务"><a href="#技术债务" class="headerlink" title="技术债务"></a>技术债务</h4><p>努力修复所有异味。以分钟(min)为度量单位存储在数据库中，单位值中的天假设为8小时(h)。</p><p><br><br><br></p><h4 id="技术债务率"><a href="#技术债务率" class="headerlink" title="技术债务率"></a>技术债务率</h4><p>开发成本与修复成本之间的比率。技术债务公式为: <code>Remediation cost / Development cost</code></p><p>开发一行代码的成本价值为<code>0.06 day == 0.06 * 8 * 60 min</code></p><p><br><br><br></p><h3 id="质量阈"><a href="#质量阈" class="headerlink" title="质量阈"></a>质量阈</h3><p>有:</p><ul><li>质量阈状态(Quality Gate Status)</li><li>质量阈详情(Quality Gate Details)</li></ul><p><br><br><br></p><h3 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h3><p>有:</p><ul><li>Bugs</li><li>New Bugs</li><li>可靠率(Reliability Rating)</li><li>可靠性的修复工作(Reliability remediation effort)</li><li>新代码可靠性的修复工作(Reliability remediation effort on new code)</li></ul><p><br></p><h4 id="可靠率"><a href="#可靠率" class="headerlink" title="可靠率"></a>可靠率</h4><ul><li>A = 0 Bugs</li><li>B = at least 1 Minor Bug</li><li>C = at least 1 Major Bug</li><li>D = at least 1 Critical Bug</li><li>E = at least 1 Blocker Bug</li></ul><p><br><br><br></p><h4 id="修复工作"><a href="#修复工作" class="headerlink" title="修复工作"></a>修复工作</h4><p>努力解决所有Bugs。以分钟为单位度量值存储在数据库中。如果数值天，则假设一天为8小时。</p><p><br><br><br></p><h3 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h3><p>有:</p><ul><li>漏洞(Vulnerabilities)</li><li>新漏洞(New Vulnerabilities)</li><li>安全级(Security Rating)</li><li>安全修复工作(Security remediation effort )</li><li>新代码的安全修复工作(Security remedation effort on new code)</li></ul><p><br></p><h4 id="安全评级"><a href="#安全评级" class="headerlink" title="安全评级"></a>安全评级</h4><ul><li>A = 0 Vulnerabilities</li><li>B = at least 1 Minor Vulnerability</li><li>C = at least 1 Major Vulnerability</li><li>D = at least 1 Critical Vulnerability</li><li>E = at least 1 Blocker Vulnerability</li></ul><p><br><br><br></p><h3 id="大小"><a href="#大小" class="headerlink" title="大小"></a>大小</h3><p>有:</p><ul><li>类(Classes)</li><li>注释行(Comment lines)</li><li>注释占比(Comments %) - <code>Comment lines / (Lines of code + Comment lines) * 100</code></li><li>目录(Directories)</li><li>文件(Files)</li><li>行数(Lines)</li><li>代码行数(Lines of code)</li><li>每种语言的代码行数(Lines of code per language)</li><li>函数(Functions)</li></ul><p><br><br><br></p><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>有:</p><ul><li>条件覆盖(Condition coverage)</li><li>新代码条件覆盖(Condition coverage on new code)</li><li>条件覆盖命中(Condition coverage hits)</li><li>逐行条件(Conditions by line)</li><li>逐行条件覆盖(Covered conditions by line)</li><li>覆盖(Coverage)</li><li>新代码覆盖(Coverage on new code)</li><li>行覆盖(Line coverage)</li><li>新代码行覆盖(Line coverage on new code)</li><li>行覆盖命中(Line coverage hits)</li><li>要覆盖的行(Lines to cover)</li><li>新代码要覆盖的行(Lines to cover on new code)</li><li>跳过单元测试(Skipped unit tests)</li><li>未覆盖条件(Uncovered conditions)</li><li>新代码未覆盖条件(Uncovered conditions on new code)</li><li>未覆盖行(Uncovered lines)</li><li>新代码未覆盖行(Uncovered lines on new code)</li><li>单元测试(Unit tests)</li><li>单元测试持续时间(Unit tests duration)</li><li>单元测试错误(Unit test errors)</li><li>单元测试失败(Unit test failures)</li><li>单元测试成功密度(Unit test success density %) - <code>Test success density = (Unit tests - (Unit test errors + Unit test failures)) / Unit tests * 100</code></li></ul><p><br></p><h4 id="条件覆盖"><a href="#条件覆盖" class="headerlink" title="条件覆盖"></a>条件覆盖</h4><p>在包含一些布尔表达式的每行代码中，条件覆盖只是回答了以下问题: <em>每个布尔表达式是否都被评估为 <code>true</code> 和 <code>false</code>?</em>。这是在单元测试执行期间遵循的流控制结构中可能的条件密度。</p><p><code>Condition coverage = (CT + CF) / (2*B)</code>, where:</p><ul><li>CT = conditions that have been evaluated to ‘true’ at least once(已经被评估为<code>true</code>至少一次的条件)</li><li>CF = conditions that have been evaluated to ‘false’ at least once(已经被评估为<code>false</code>至少一次的条件)</li><li>B = 条件总数(total number of conditions)</li></ul><p><br><br><br></p><h4 id="覆盖"><a href="#覆盖" class="headerlink" title="覆盖"></a>覆盖</h4><p>它是行覆盖和条件覆盖的混合。它的目标是为以下问题提供更准确的答案: <em>单元测试覆盖了多少源代码?</em></p><p><code>Coverage = (CT + CF + LC)/(2*B + EL)</code>, where:</p><ul><li>CT = 已经被评估为<code>true</code>至少一次的条件</li><li>CF = 已经被评估为<code>false</code>至少一次的条件</li><li>LC = 覆盖的行(covered lines)</li><li>B = 条件总数</li><li>EL = 可执行行的总数( total number of executable lines)</li></ul><p><br><br><br></p><h4 id="行覆盖"><a href="#行覆盖" class="headerlink" title="行覆盖"></a>行覆盖</h4><p>在给定的代码行上，行覆盖简单地回答了以下问题: <em>在执行单元测试期间是否执行了这行代码?</em></p><p>它是单元测试的覆盖率密度:</p><p><code>Line coverage = LC / EL</code>, where:</p><ul><li>LC = 覆盖的行(covered lines)</li><li>EL = 可执行行的总数(total number of executable lines)</li></ul><p><br><br><br><br><br></p><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>Concepts</p><p><br><br><br></p><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>Architecture</p><div class="table-container"><table><thead><tr><th>概念</th><th>定义</th></tr></thead><tbody><tr><td>Analyzer</td><td>用于分析源代码以计算快照的客户端程序</td></tr><tr><td>Database</td><td>存储配置和快照</td></tr><tr><td>Server</td><td>用于浏览快照数据和进行配置修改的Web界面</td></tr></tbody></table></div><p><br><br><br></p><h3 id="质量"><a href="#质量" class="headerlink" title="质量"></a>质量</h3><p>Quality</p><div class="table-container"><table><thead><tr><th>概念</th><th>定义</th></tr></thead><tbody><tr><td>Bug</td><td>表示代码中出错的问题</td></tr><tr><td>Code Smell</td><td>代码中与可维护性相关的问题</td></tr><tr><td>Cost</td><td>花费</td></tr><tr><td>Debt</td><td>解决问题所需的时间</td></tr><tr><td>Issue</td><td>代码不符合规则时，快照上会记录一个问题。有: Bugs , Code Smells and Vulnerabilities</td></tr><tr><td>Measure</td><td>给定时间内给定文件或项目的度量值</td></tr><tr><td>Metric</td><td>一种测量方式。随着时间的推移，度量标准可能具有不同的值或度量</td></tr><tr><td>New Code Period</td><td>需要密切关注代码中引入新问题的时间段</td></tr><tr><td>Quality Profile</td><td>一组规则</td></tr><tr><td>Rule</td><td>应该遵循的编码标准或惯例</td></tr><tr><td>Remediation Cost</td><td>修复漏洞和可靠性问题所需的估计时间</td></tr><tr><td>Snapshot</td><td>在给定时间内针对给定项目的一组度量和问题</td></tr><tr><td>Security Hotspot</td><td>与安全相关的问题，突出显示使用安全敏感API的一段代码</td></tr><tr><td>Technical Debt</td><td>修复问题所需的估计时间</td></tr><tr><td>Vulnerability</td><td>与安全相关的问题，代表攻击者的后门</td></tr></tbody></table></div><p><br><br><br><br><br></p><h2 id="活动"><a href="#活动" class="headerlink" title="活动"></a>活动</h2><p>Activity and History</p><p>项目活动页面提供项目文件分析的完整列表，以及随着时间推移看到项目措施演变的能力。<br>活动页面上的图标可帮助你了解几种相互选择的度量方法的演变。</p><p><br></p><h3 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h3><p>Events</p><p>有四种类型的事件:</p><ul><li>Quality Gate</li><li>Profile</li><li>Version</li><li>Other</li></ul><p><br><br><br><br><br></p><h2 id="SonarLint"><a href="#SonarLint" class="headerlink" title="SonarLint"></a>SonarLint</h2><p>SonarLint Smart Notifications</p><p>SonarLint Smart Notifications是作为Developer Edtion的一部分来提供。</p><p>智能通知允许使用SonarLint中的连接模式的开发人员以一下情况下从SonarQube接收IDE内的通知:</p><ul><li>the Quality Gate status (failed / success) of a project /solution open in the IDE changes</li><li>a SonarQube analysis raises new issues introduced by this developer in a project /solution open in the IDE</li></ul><p>SonarLint智能通知的激活和取消必须由每个开发人员直接在SonarLint(IDE端)进行单独完成。<br>可以在SonarQube上逐个服务器地在SonarLint端配置接收通知。</p><p><br><br><br><br><br></p><h2 id="Security-Reports"><a href="#Security-Reports" class="headerlink" title="Security Reports"></a>Security Reports</h2><p><br></p><h3 id="安全报告显示了什么"><a href="#安全报告显示了什么" class="headerlink" title="安全报告显示了什么"></a>安全报告显示了什么</h3><p>What do the Security Reports show?</p><p>安全报告旨在快速为您提供有关应用程序安全性的全景图，并详细说明OWASP, SANS, CWE标准的详细信息。安全报告由分析器提供，分析器依赖于质量配置文件中激活的规则来引发安全问题。</p><p><br><br><br></p><h3 id="热点和漏洞有什么区别"><a href="#热点和漏洞有什么区别" class="headerlink" title="热点和漏洞有什么区别"></a>热点和漏洞有什么区别</h3><p>What’s the difference between a Hotspot and a Vulnerability?</p><p>漏洞是代码中可以攻击的点。安全热点是安全敏感的代码段，应由具有安全审计员帽的人仔细审查。<br>安全热点的主要目标是帮助集中手动审查应用程序源代码的安全审核员的工作。第二个目标是教育开发人员并提高他们的安全意识。</p><p><br><br><br></p><h3 id="为什么某些热点和漏洞非常相似"><a href="#为什么某些热点和漏洞非常相似" class="headerlink" title="为什么某些热点和漏洞非常相似"></a>为什么某些热点和漏洞非常相似</h3><p>Why are some Hotspot and Vulnerability rules very similar?</p><p>它们是故意重叠的。热点规则应该包括漏洞规则的所有匹配，以及污点分析引擎无法检测漏洞的情况。</p><p><br><br><br></p><h3 id="为什么我看不到任何热点"><a href="#为什么我看不到任何热点" class="headerlink" title="为什么我看不到任何热点"></a>为什么我看不到任何热点</h3><p>Why are some Hotspot and Vulnerability rules very similar?</p><p>有三个原因:</p><ul><li>可能真的没有它们，因为代码是在没有使用任何安全敏感API的情况下编写的</li><li>热点规则可能可用，但尚未在你的质量配置文件中激活，因此自然不会引发任何问题</li><li>你正在使用的语言分析器可能还没有提供热点规则，所以它不会引发任何热点</li></ul><p><br><br><br></p><h3 id="为什么我看不到任何漏洞"><a href="#为什么我看不到任何漏洞" class="headerlink" title="为什么我看不到任何漏洞"></a>为什么我看不到任何漏洞</h3><p>由于一些热点原因，你可能没有看到任何漏洞的，但你可能会看到项目主页中报告了一些漏洞，而安全报告中没有漏洞。这是因为语言分析器可能尚未提供安全报告中可见问题所需的安全标准的元数据。</p><p><br><br><br></p><h3 id="开发者是否应该关心热点"><a href="#开发者是否应该关心热点" class="headerlink" title="开发者是否应该关心热点"></a>开发者是否应该关心热点</h3><p>可能并不需要。热点并不是真正可行的，它们只是标记潜在的问题，所以在代码上没有立即做任何事情。这就是为什么在引发热点问题时没有收到通知。</p><p><br><br><br></p><h3 id="如果热点确实标记为漏洞怎么办"><a href="#如果热点确实标记为漏洞怎么办" class="headerlink" title="如果热点确实标记为漏洞怎么办"></a>如果热点确实标记为漏洞怎么办</h3><p>如果您查看引发热点的代码并意识到确实存在问题，请单击当前状态以注册您在代码中检测到漏洞。完成后，它将转换为漏洞，最后触摸该行的开发人员将收到新问题通知。</p><p><br><br><br></p><h3 id="热点变为漏洞后会发生什么"><a href="#热点变为漏洞后会发生什么" class="headerlink" title="热点变为漏洞后会发生什么"></a>热点变为漏洞后会发生什么</h3><p>一旦您检测到热点位置确实存在问题，它将被分配给相应的开发人员，他们将进行修复，然后必须通过UI请求审核。</p><p><br><br><br></p><h3 id="热点被标记为不会修复是什么意思"><a href="#热点被标记为不会修复是什么意思" class="headerlink" title="热点被标记为不会修复是什么意思"></a>热点被标记为不会修复是什么意思</h3><p>What does it mean for a Hotspot to be marked “Won’t Fix”?</p><p>不会修复标记用于表示已经审查了热点，并且目前无法利用这段代码创建攻击。</p><p><br><br><br><br><br></p><h2 id="用户账户"><a href="#用户账户" class="headerlink" title="用户账户"></a>用户账户</h2><p>User Account</p><p>SonarQube用户可拥有自己的空间，可查看与自己相关的内容。</p><p><br><br><br><br><br></p><h2 id="User-Token"><a href="#User-Token" class="headerlink" title="User Token"></a>User Token</h2><p>每个用户都可生成令牌，这些令牌可用于运行分析或调用Web服务，而无需用户的实际凭据。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="项目管理"><a href="#项目管理" class="headerlink" title="项目管理"></a>项目管理</h1><p>Project Administration</p><p><br></p><h2 id="项目存在"><a href="#项目存在" class="headerlink" title="项目存在"></a>项目存在</h2><p>Project Existence</p><p>通常，项目在第一次分析时创建，不会删除(除非手动删除)。你可以管你你有权限管理的项目。</p><p><br></p><ul><li>在第一次分析之前配置项目</li><li>配置还未分析的项目</li><li>修改项目权限(Private/Public) - 默认情况下，任何新创建的项目都被视为Public。这意味着每个经过认证的用户都能够<strong>Browse</strong>和<strong>See Source Code</strong></li><li>删除项目</li><li>查找不再分析的项目</li></ul><p><br><br><br></p><h2 id="管理项目历史"><a href="#管理项目历史" class="headerlink" title="管理项目历史"></a>管理项目历史</h2><p>Managing Project History</p><p>SonarQube最强大的功能之一是它不仅向你展示了你今天的项目健康状况，还展示了它随时间的变化情况。它通过有选择地保留以前分析的数据来做到这一点。它没有保留所有以前的分析——这会使数据库膨胀。同样，对于它确实存在的分析，SonarQube不会保留所有数据。一旦项目快照(snapshot)从最后分析(Last analysis)移动到项目历史的一部分，项目级别下面的数据就会被清除——再次放置数据库膨胀。</p><p>通常这些都不是你需要考虑的事情。SonarQube只为你专门处理它们。但有时你可能需要从项目的历史记录中删除错误的快照或修改内存处理算法。</p><p><br></p><p>可查看数据库表大小:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># sonar</span><br><span class="line"><span class="keyword">USE</span> information_schema;</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESCRIBE</span> <span class="keyword">TABLES</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> TABLE_SCHEMA, TABLE_NAME, TABLE_ROWS, DATA_LENGTH <span class="keyword">FROM</span> <span class="keyword">TABLES</span> <span class="keyword">WHERE</span> TABLE_SCHEMA = <span class="string">'sonar'</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> DATA_LENGTH <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure><p><br></p><p>有时你可能需要手动删除项目快照，无论是因为使用了错误的质量配置文件，还是因为分析存在问题…请注意，永远不能删除最新的快照。</p><p>对于每个快照，可以手动:</p><ul><li>Add, rename or remove a version</li><li>Add, rename or remove an event</li><li>Delete the snapshot</li></ul><p><br><br><br></p><h2 id="缩小关注点"><a href="#缩小关注点" class="headerlink" title="缩小关注点"></a>缩小关注点</h2><p>Narrowing the Focus</p><p>如果SonarQube的结果不相关，那么没有人会想要使用它。这就是为什么精确配置每个项目要分析的内容是非常重要的一步。<br>SonarQube为你提供了几种选项，可以准确配置要分析的内容。你可以:</p><ul><li>完全忽略一些文件或目录</li><li>从问题中排除文件或目录，但分析所有其它方面</li><li>从重复性中排除文件或目录，但分析所有其它方面</li><li>从覆盖率中排除文件或目录，但分析其它所有方面</li></ul><p>你可以在全局或项目级别配置它们。</p><p><br></p><h3 id="忽略文件"><a href="#忽略文件" class="headerlink" title="忽略文件"></a>忽略文件</h3><p>Ignore Files</p><p>建议你从库中排除生成的代码，源代码等。有四种不同的方法可将分析范围缩小到与开发团队相关的源代码。</p><ul><li>源目录(Source Directories)</li><li>文件后缀(File Suffixes)</li><li>选择文件(Choosing Files)<ul><li>源文件排除(Source File Exclusions)</li><li>测试文件排除(Test File Exclusions)</li><li>源文件包含(Source File Inclusions)</li><li>测试文件包含(Test File Inclusions)</li></ul></li></ul><p><img src="/images/SonarQube/exclusions.jpg" alt></p><p><img src="/images/SonarQube/inclusions.jpg" alt></p><p><br><br><br></p><h3 id="忽略问题"><a href="#忽略问题" class="headerlink" title="忽略问题"></a>忽略问题</h3><p>Ignore Issues</p><p>可使用SonarQube忽略某些组件和某些编码规则的问题。<code>Administration &gt; General Settings &gt; Analysis Scope &gt; Issues</code>。</p><p>请注意，以下属性只能通过Web界面设置，因为它们是多值的。</p><ul><li>Ignore Issues on Files</li><li>Ignore Issues in Blocks</li><li>Ignore Issues on Multiple Criteria</li><li>Restrict Scope of Coding Rules</li></ul><p><br><br><br></p><h3 id="忽略重复"><a href="#忽略重复" class="headerlink" title="忽略重复"></a>忽略重复</h3><p>Ignore Duplications</p><p>可在SonarQube中阻止检查某些文件的重复性。<code>Administration &gt; General Settings &gt; Analysis Scope &gt; Duplications</code>。</p><p><br><br><br></p><h3 id="忽略代码覆盖率"><a href="#忽略代码覆盖率" class="headerlink" title="忽略代码覆盖率"></a>忽略代码覆盖率</h3><p>Ignore Code Coverage</p><p>可以通过单元测试防止某些文件考虑用于代码覆盖。<code>Administration &gt; General Settings &gt; Analysis Scope &gt; Code Coverage &gt; Coverage Exclusions</code>。</p><p><br><br><br></p><h3 id="模式"><a href="#模式" class="headerlink" title="模式"></a>模式</h3><p>Patterns</p><p>SonarQube中可以使用以下通配符:</p><ul><li><code>*</code>    - 零个或多个字符(zero or more characters)</li><li><code>**</code> - 零个或多个目录(zero or more directories)</li><li><code>?</code> - 单个字符(a single character)</li></ul><p><br><br><br><br><br></p><h2 id="项目设置"><a href="#项目设置" class="headerlink" title="项目设置"></a>项目设置</h2><p>Project Settings</p><p><br></p><h3 id="Tags"><a href="#Tags" class="headerlink" title="Tags"></a>Tags</h3><p>项目标签(tags) 允许对项目进行分类和分组，以便在项目页面上更容易地选择。可以从项目主页管理项目标签。</p><p><br><br><br></p><h3 id="管理项"><a href="#管理项" class="headerlink" title="管理项"></a>管理项</h3><p>Administration Items:</p><ul><li>Adding a Project</li><li>Analysis Report Processing</li><li>Deleting a Project</li><li>Setting the New Code Period</li><li>Updating Project Key</li><li>Default Issue Assignee</li><li>Setting Quality Gate and Quality Profiles</li><li>Setting Exclusions</li><li>Customizing Links</li></ul><p><br><br><br><br><br></p><h2 id="Webhooks"><a href="#Webhooks" class="headerlink" title="Webhooks"></a>Webhooks</h2><p>网络调用(Webhooks) 在项目完成分析后通知外部服——An HTTP POST request including a JSON payload is sent to each URL。可在项目级别和全局指定URL。项目级别的配置不会取代全局的配置，两个级别的所有Webhooks都被调用。</p><p>HTTP(s) 调用:</p><ul><li>无论后台任务的状态如何</li><li>使用POST方法将JSON文档作为负载</li><li>使用<code>UTF-8</code>编码的内容类型<code>application/json</code></li></ul><p><br></p><h3 id="Delivery-and-Payload"><a href="#Delivery-and-Payload" class="headerlink" title="Delivery and Payload"></a>Delivery and Payload</h3><p>Webhook 管理控制台显示每个Webhook的最新交付的结果和时间戳，其中有效负载可通过列表图标获得。默认保留30天的记录。URL必须在10s响应，否则传递将标记为失败。</p><p>发送带有project key的 HTTP header <code>X-SonarQube-Project</code>，以便快速识别所涉及的项目。</p><p>Payload是一个JSON文档，包括:</p><ul><li>什么时候运行分析(<code>analysedAt</code>)</li><li>分析的项目的标识(<code>project</code>)</li><li>每个质量阈标准和状态(<code>qualityGate</code>)</li><li>每个项目的质量阈状态(<code>qualityGate.status</code>)</li><li>后台任务的状态和标识(<code>status</code>, <code>taskId</code>)</li><li>用于定义的属性(<code>properties</code>)</li></ul><p>栗子:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"analysedAt"</span>: <span class="string">"2016-11-18T10:46:28+0100"</span>,</span><br><span class="line">    <span class="attr">"project"</span>: &#123;</span><br><span class="line">        <span class="attr">"key"</span>: <span class="string">"org.sonarqube:example"</span>,</span><br><span class="line">        <span class="attr">"name"</span>: <span class="string">"Example"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"qualityGate"</span>: &#123;</span><br><span class="line">        <span class="attr">"conditions"</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">"errorThreshold"</span>: <span class="string">"1"</span>,</span><br><span class="line">                <span class="attr">"metric"</span>: <span class="string">"new_security_rating"</span>,</span><br><span class="line">                <span class="attr">"onLeakPeriod"</span>: <span class="literal">true</span>,</span><br><span class="line">                <span class="attr">"operator"</span>: <span class="string">"GREATER_THAN"</span>,</span><br><span class="line">                <span class="attr">"status"</span>: <span class="string">"OK"</span>,</span><br><span class="line">                <span class="attr">"value"</span>: <span class="string">"1"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">"errorThreshold"</span>: <span class="string">"1"</span>,</span><br><span class="line">                <span class="attr">"metric"</span>: <span class="string">"new_reliability_rating"</span>,</span><br><span class="line">                <span class="attr">"onLeakPeriod"</span>: <span class="literal">true</span>,</span><br><span class="line">                <span class="attr">"operator"</span>: <span class="string">"GREATER_THAN"</span>,</span><br><span class="line">                <span class="attr">"status"</span>: <span class="string">"OK"</span>,</span><br><span class="line">                <span class="attr">"value"</span>: <span class="string">"1"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">"errorThreshold"</span>: <span class="string">"1"</span>,</span><br><span class="line">                <span class="attr">"metric"</span>: <span class="string">"new_maintainability_rating"</span>,</span><br><span class="line">                <span class="attr">"onLeakPeriod"</span>: <span class="literal">true</span>,</span><br><span class="line">                <span class="attr">"operator"</span>: <span class="string">"GREATER_THAN"</span>,</span><br><span class="line">                <span class="attr">"status"</span>: <span class="string">"OK"</span>,</span><br><span class="line">                <span class="attr">"value"</span>: <span class="string">"1"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">"errorThreshold"</span>: <span class="string">"80"</span>,</span><br><span class="line">                <span class="attr">"metric"</span>: <span class="string">"new_coverage"</span>,</span><br><span class="line">                <span class="attr">"onLeakPeriod"</span>: <span class="literal">true</span>,</span><br><span class="line">                <span class="attr">"operator"</span>: <span class="string">"LESS_THAN"</span>,</span><br><span class="line">                <span class="attr">"status"</span>: <span class="string">"NO_VALUE"</span></span><br><span class="line">            &#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="attr">"name"</span>: <span class="string">"SonarQube way"</span>,</span><br><span class="line">        <span class="attr">"status"</span>: <span class="string">"OK"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"serverUrl"</span>: <span class="string">"http://localhost:9000"</span>,</span><br><span class="line">    <span class="attr">"status"</span>: <span class="string">"SUCCESS"</span>,</span><br><span class="line">    <span class="attr">"taskId"</span>: <span class="string">"AVh21JS2JepAEhwQ-b3u"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="附加参数"><a href="#附加参数" class="headerlink" title="附加参数"></a>附加参数</h3><p>Additional parameters</p><p>通过在Webhook的URL中提供<code>user/passwd</code>来支持基本的身份认证机制。(如: <code>https://myLogin:myPassword@my_server/foo</code>)</p><p>如果使用了<code>sonar.analysis.*</code>属性为SonarScanner提供其它属性，则这些属性将自动添加到有效负载的<code>properties</code>部分。</p><p>栗子:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sonar-scanner -Dsonar.analysis.scmRevision=628f5175ada0d685fd7164baa7c6382c1f25cab4 -Dsonar.analysis.buildNumber=12345</span><br></pre></td></tr></table></figure><p><br><br><br></p><hr><p><br><br><br></p><h1 id="实例管理"><a href="#实例管理" class="headerlink" title="实例管理"></a>实例管理</h1><p>Instance Administration</p><p><br></p><h2 id="质量配置"><a href="#质量配置" class="headerlink" title="质量配置"></a>质量配置</h2><p>Quality Profiles</p><p><br></p><h3 id="概述-4"><a href="#概述-4" class="headerlink" title="概述"></a>概述</h3><p>质量配置(Quality Profiles)服务是SonarQube的核心，因为它是您通过定义规则集来定义需求的地方。。</p><p>理想情况下，对于任何给定的语言，所有项目都将使用相同的配置文件进行测量，但这并不总是实用的。<br>这就是为什么您可以根据需要定义尽可能多的质量配置文件，即使建议尽可能少的质量配置文件以确保公司项目的一致性。</p><p>每个语言都带有预定义的內建配置文件(通常称为 Sonar way)，因此你可以使用SonarQube分析进行快速开始。这就是为什么只要安装新的语言插件，就可以使用至少一个配置文件。</p><p>默认的Sonar way配置文件，它包含了通常适用于大多数项目的所有规则。但作为最佳实践，你应该创建一个新的配置文件(你可以通过复制Sonar way的内容来填充它)，并使用它。<br>因为默认的Sonar way是不可编辑的，因此你无法根据需要对其进行自定义。此外，这使你可将Sonar way视为一个基线，可在对其进行更改时跟踪自己的配置文件。此外Sonar way通常会随插件的每个新版本更新，已添加规则，有时还会调整规则严重性。任何继承自內建Sonar way的配置文件都将在事实上同时自动更新。</p><p><br><br><br></p><h3 id="我该怎么做"><a href="#我该怎么做" class="headerlink" title="我该怎么做"></a>我该怎么做</h3><p><br></p><h4 id="将质量配置管理的权限移交给其他人"><a href="#将质量配置管理的权限移交给其他人" class="headerlink" title="　将质量配置管理的权限移交给其他人"></a>　将质量配置管理的权限移交给其他人</h4><p>Delegate the management of Quality Profiles to someone else?</p><p>默认情况下，管理员才有此权限。但你可以授予用户/组权限来编辑配置文件。例如将Java配置文件权限分配给Java开发专家，将Python配置文件权限分配给Python专家…</p><p><br><br><br></p><h4 id="将规则从一个配置复制到另一个配置"><a href="#将规则从一个配置复制到另一个配置" class="headerlink" title="将规则从一个配置复制到另一个配置"></a>将规则从一个配置复制到另一个配置</h4><p>Copy the rules from one profile to another?</p><p>许多时候，人们希望使用基于內建的配置文件的配置文件进行工作，而无实际需要使用內建配置文件。</p><p><br><br><br></p><h4 id="了解配置中有什么改变"><a href="#了解配置中有什么改变" class="headerlink" title="了解配置中有什么改变"></a>了解配置中有什么改变</h4><p>Know what’s changed in a profile?</p><p>当SonarQube注意到使用与先前分析不同的配置文件执行分析时，会将质量配置文件事件添加到项目的事件日志中。</p><p><br><br><br></p><h4 id="将配置文件从一个实例复制到另一个实例"><a href="#将配置文件从一个实例复制到另一个实例" class="headerlink" title="将配置文件从一个实例复制到另一个实例"></a>将配置文件从一个实例复制到另一个实例</h4><p>Copy a profile from one SonarQube instance to another?</p><p>使用实例上的备份(Back UP)功能将配置文件导出到XML文件。然后在另一个实例中选择恢复(Restore)。</p><p><br><br><br></p><h4 id="将一组核心规则和附加规则应用于项目"><a href="#将一组核心规则和附加规则应用于项目" class="headerlink" title="将一组核心规则和附加规则应用于项目"></a>将一组核心规则和附加规则应用于项目</h4><p>Apply a core set of rules plus additional rules to a project?</p><p>使用继承，从root继承核心规则集。然后创建一个子配置文件(Sprout)，修改从Root继承，然后添加缺少的规则。</p><p><br><br><br></p><h4 id="确保我的非默认配置文件应用于项目"><a href="#确保我的非默认配置文件应用于项目" class="headerlink" title="确保我的非默认配置文件应用于项目"></a>确保我的非默认配置文件应用于项目</h4><p>Make sure my non-default profile is used on a project?</p><p><br><br><br></p><h4 id="确保我的个人配置中包含所有相关的新规则"><a href="#确保我的个人配置中包含所有相关的新规则" class="headerlink" title="确保我的个人配置中包含所有相关的新规则"></a>确保我的个人配置中包含所有相关的新规则</h4><p>Make sure I’ve got all the relevant new rules in my profile?</p><p><br><br><br></p><h4 id="比较两个规则"><a href="#比较两个规则" class="headerlink" title="比较两个规则"></a>比较两个规则</h4><p>Compare two profiles?</p><p><br><br><br></p><h4 id="确保我的配置中没有任何弃用的规则"><a href="#确保我的配置中没有任何弃用的规则" class="headerlink" title="确保我的配置中没有任何弃用的规则"></a>确保我的配置中没有任何弃用的规则</h4><p>Make sure I don’t have any deprecated rules in my profile?</p><p><br><br><br></p><h4 id="安全-1"><a href="#安全-1" class="headerlink" title="安全"></a>安全</h4><p>Security</p><p>任何用户都可以访问质量配置服务，你可以给他们配置质量配置管理权限，让他们可以创建，删除质量配置。</p><p><br><br><br><br><br></p><h2 id="安全-2"><a href="#安全-2" class="headerlink" title="安全"></a>安全</h2><p><br></p><h3 id="概述-5"><a href="#概述-5" class="headerlink" title="概述"></a>概述</h3><p>SonarQube具有许多全局安全功能:</p><ul><li>认证和授权机制</li><li>强制身份认证</li><li>委派认证</li></ul><p>除此之外，还可在group/user级别配置:</p><ul><li>查看一个已存在的项目</li><li>访问项目的源代码</li><li>管理一个项目</li><li>管理质量配置，质量阈，实例…</li></ul><p><br><br><br></p><h3 id="认证"><a href="#认证" class="headerlink" title="认证"></a>认证</h3><p>Authentication</p><p>第一个问题: 匿名用户是否可以浏览SonarQube实例？<br>当然不行！那就需要强制用户认证。</p><p><br></p><p><strong>认证机制(Authentication Mechanisms)</strong></p><p>可通过多种方式来管理认证机制:</p><ul><li>通过SonarQube內建的user/group数据库</li><li>通过外部程序(如LDAP)</li><li>通过HTTP headers</li></ul><p><br></p><p><strong>技术用户(Technical Users)</strong></p><p>当你在SonarQube数据库中创建用户时，他将被视为本地用户，并且针对SonarQube自己的user/group数据库进行身份认证，而不是通过任何外部工具。<br>默认情况下，<code>admin</code>是本地账户。</p><p>同样，所有非本地(non-local)账户将仅针对外部工具进行身份认证。</p><p>管理员可以管理所有用户的<strong>Tokens</strong>——创建和删除。一旦创建，Token就是运行分析所需的唯一凭证，作为<code>sonar.login</code>属性的值来传递。</p><p><br></p><p><strong>默认管理员(Default Admin Credentials)</strong></p><p>当安装SonarQube时，会自动创建具有管理系统权限的默认用户:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">user:</span> <span class="string">admin</span></span><br><span class="line"><span class="attr">passwd:</span> <span class="string">admin</span></span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="重置管理员密码"><a href="#重置管理员密码" class="headerlink" title="重置管理员密码"></a>重置管理员密码</h3><p>Reinstating Admin Access</p><p>如果你修改了管理员密码，但又忘记了:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">USE</span> sonar;</span><br><span class="line"></span><br><span class="line"><span class="keyword">update</span> <span class="keyword">users</span> <span class="keyword">set</span> crypted_password = <span class="string">'$2a$12$uCkkXmhW5ThVK8mpBvnXOOJRLd64LJeHTeCkSuB3lfaR2N0AYBaSi'</span>, <span class="keyword">salt</span>=<span class="literal">null</span>, hash_method=<span class="string">'BCRYPT'</span> <span class="keyword">where</span> login = <span class="string">'admin'</span></span><br></pre></td></tr></table></figure><p>如果您删除了管理员并随后锁定了具有全局管理权限的其他用户:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">USE</span> sonar;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> user_roles(user_id, <span class="keyword">role</span>) <span class="keyword">VALUES</span> ((<span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> <span class="keyword">users</span> <span class="keyword">where</span> login=<span class="string">'mylogin'</span>), <span class="string">'admin'</span>);</span><br></pre></td></tr></table></figure><p><br><br><br></p><h3 id="授权"><a href="#授权" class="headerlink" title="授权"></a>授权</h3><p>Authorization</p><p>对不同组、不同用于仅限权限分配，以访问不同的资源。</p><ul><li>user</li><li>group</li><li>Global Permissions<ul><li>Administer System</li><li>Administer Quality Profiles</li><li>Administer Quality Gates</li><li>Execute Analysis</li><li>Create Projects</li><li>Create Applications</li><li>Create Portfolios</li></ul></li><li>Project Permissions<ul><li>Public and Private<ul><li>Administer Issues</li><li>Administer Security Hotspots</li><li>Administer</li><li>Execute Analysis</li></ul></li><li>Private<ul><li>Browse</li><li>See Source Code</li></ul></li></ul></li></ul><p><br><br><br></p><h3 id="默认权限的权限模板"><a href="#默认权限的权限模板" class="headerlink" title="默认权限的权限模板"></a>默认权限的权限模板</h3><p>Permission Templates for Default Permissions</p><p>SonarQube附带默认权限模板，该模板在创建项目，项目组合或应用程序自动授予特定组的特定权限。管理员可以编辑此模板。</p><p><br><br><br></p><h3 id="加密"><a href="#加密" class="headerlink" title="加密"></a>加密</h3><p>Encryption</p><p>加密主要用于从设置中删除明文密码。实现的解决方案是基于对称密钥算法，关键是密钥存储在磁盘上的安全文件中。此文件必须由运行SonarQube Server的系统账户拥有和读取。<br>该算法是AES 128位。</p><ul><li><strong>Generate the secret key</strong></li><li><strong>Store the secret key on the SonarQube server</strong></li><li><strong>Generate the encrypted values of your settings</strong></li><li><strong>Use the encrypted values in your SonarQube server configuration</strong></li></ul><p>必须在SonarQube基础架构的所有部分之间共享唯一的密钥。在<code>Administration &gt; Configuration &gt; Encryption</code>生成密钥。<br>生成密钥之后，会显示如何使用此密钥。</p><p><img src="/images/SonarQube/secretKey.png" alt></p><p>之后便可以为你设置的值进行加密。同样在前面的加密下进行配置。<br>之后在SonarQube Server中使用加密后的值:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># conf/sonar.properties</span><br><span class="line"></span><br><span class="line">sonar.jdbc.password=&#123;aes&#125;CCGCFg4Xpm6r+PiJb1Swfg==  # Encrypted DB password</span><br><span class="line">...</span><br><span class="line">sonar.secretKeyPath=C:/path/to/my/secure/location/my_secret_key.txt</span><br></pre></td></tr></table></figure><p><br><br><br><br><br></p><h2 id="委托认证"><a href="#委托认证" class="headerlink" title="委托认证"></a>委托认证</h2><p>Delegating Authentication</p><p>docs: <a href="https://docs.sonarqube.org/latest/instance-administration/delegated-auth/" target="_blank" rel="noopener">https://docs.sonarqube.org/latest/instance-administration/delegated-auth/</a></p><p>SonarQube认证:</p><ul><li>自带用户数据库认证</li><li>外部<ul><li>HTTP header</li><li>LDAP</li><li>…</li></ul></li></ul><p><br></p><h3 id="HTTP-header认证"><a href="#HTTP-header认证" class="headerlink" title="HTTP header认证"></a>HTTP header认证</h3><p><br><br><br></p><h3 id="LDAP认证"><a href="#LDAP认证" class="headerlink" title="LDAP认证"></a>LDAP认证</h3><p><br><br><br><br><br></p><h2 id="通知"><a href="#通知" class="headerlink" title="通知"></a>通知</h2><p>Notifications</p><p>可以通过邮件配置，向用户发送分析的信息的通知。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="使用实践"><a href="#使用实践" class="headerlink" title="使用实践"></a>使用实践</h1><blockquote><p><strong>注意:</strong><br>由于使用的是SonarQube CE(社区版)，因此不支持在IDE中上传分析数据，也不支持多分支(branch)分析。所以需要对这些方面做一些规范。</p></blockquote><p><br></p><p>SonarQube的使用主要分为两个方面:</p><ul><li><strong>开发者 IDE</strong></li><li><strong>CI SonarScanner</strong></li></ul><p><br></p><h2 id="CI"><a href="#CI" class="headerlink" title="CI"></a>CI</h2><p>CI端 需先安装 <code>SonarQube Scanner</code> 应用程序，并配置相应的路径和token。</p><p>由于社区版的缘故，我只对测试分支的CI进行SonarScanner分析，并将结果上传到SonarQube Server对应项目的路径。</p><p>由于测试分支(stage)的代码都是由开发者现在本地IDE中检测过代码质量(Code Quality)之后才MR过来，所以这样更方便和实用些。</p><p>CI SonarScanner分析上传之后，SonarQube会通知项目负责人此项目代码相关情况。由项目负责人去SonarQube Web UI上再去核查相关issues，核查无误之后，才能将测试分支的代码上线。<br>如果项目负责人检查出相关代码的某些问题，请于相关分支开发者交流，叮嘱他们现在本地IDE自测，通过之后在MR代码。</p><p><br><br><br></p><h2 id="IDE"><a href="#IDE" class="headerlink" title="IDE"></a>IDE</h2><p>只需在IDE中下载SonarLint插件，并配置上运维人员提供的地址和token就可以使用了。</p><p>由于社区版的缘故，我这里让<strong>开发者自己的分支</strong>在IDE中调用远程SonarQube进行本地代码质量检查，并不需要将开发者的分支代码情况上传到SonarQube Server端。</p><p>开发者自己检查和核对自己分支的代码质量，确认之后才将自己的代码MR到dev分支。<br>如果项目负责人检测到某位开发者的分支代码存在问题，则这个责任由分支开发者负责和处理。</p><p><br><br><br></p><h2 id="权限问题"><a href="#权限问题" class="headerlink" title="权限问题"></a>权限问题</h2><p>权限有一些地方需要注意:</p><ul><li>将项目设置为私有(默认: public)</li><li>项目对应项目组(group)，对应项目成员(user)</li><li>项目组中的CI, IDE用户具有不同的权限</li><li>…</li></ul><p><br></p><p>具体配置可以在使用的时候灵活修改！</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="API"><a href="#API" class="headerlink" title="API"></a>API</h1><p>可通过SonarQube API 进行许多操作。</p><p><br></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如导出python的代码规则</span></span><br><span class="line">curl -X GET -v -u user:passwd  http://localhost:9000/api/rules/search?language=python &gt; python.json</span><br></pre></td></tr></table></figure><p><br><br><br></p><hr><p><br><br><br></p><h1 id="Scanner"><a href="#Scanner" class="headerlink" title="Scanner"></a>Scanner</h1><ul><li>docs: <a href="https://docs.sonarqube.org/display/SCAN" target="_blank" rel="noopener">https://docs.sonarqube.org/display/SCAN</a></li></ul><p>建议将SonarQube Scanner用作使用SonarQube分析项目的默认扫描程序。</p><p><br></p><h2 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h2><p><br></p><h3 id="OS"><a href="#OS" class="headerlink" title="OS"></a>OS</h3><p>平台:</p><ul><li>Linux</li><li>Mac OS</li><li>Windows</li></ul><p><br></p><p>下载对应平台的Sonar Scanner应用程序，将它们解压之后加入系统路径(<code>$PATH</code>)。</p><p><br><br><br><br><br></p><h3 id="IDE-1"><a href="#IDE-1" class="headerlink" title="IDE"></a>IDE</h3><p>Sonar Scanner 支持的 IDE 有:</p><ul><li>MSBuild</li><li>Maven</li><li>Gradle</li><li>Ant</li><li>Jenkins</li><li>JetBrains</li></ul><p><br></p><p>在IDE中下载<strong>SonarLint</strong>插件，之后配置SonarQube Server地址和管理员给的Token便可以正常使用。<br>社区版的SonarQube 只能在IDE中检测，无法上传。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GitHub: &lt;a href=&quot;https://github.com/SonarSource/sonarqube&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/SonarSource/sonarqube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;https://www.sonarqube.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.sonarqube.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Docs: &lt;a href=&quot;https://docs.sonarqube.org&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://docs.sonarqube.org&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RHEL7x86_64&lt;/li&gt;
&lt;li&gt;SonarQube v7.6&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="SonarQube" scheme="https://zhang21.github.io/tags/SonarQube/"/>
    
      <category term="Static Analysis" scheme="https://zhang21.github.io/tags/Static-Analysis/"/>
    
      <category term="Code Quality" scheme="https://zhang21.github.io/tags/Code-Quality/"/>
    
  </entry>
  
  <entry>
    <title>DevOps</title>
    <link href="https://zhang21.github.io/2019/02/13/DevOps/"/>
    <id>https://zhang21.github.io/2019/02/13/DevOps/</id>
    <published>2019-02-12T21:22:15.000Z</published>
    <updated>2019-03-19T01:05:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li><li>GitLab</li><li>GitHub</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p><strong>DevOps</strong>（Development和Operations的组合词）是一种重视 <em>软件开发人员（Dev）</em> 和 <em>IT运维技术人员（Ops）</em> 之间沟通合作的文化、运动或惯例。透过自动化 <em>软件交付</em> 和 <em>架构变更</em> 的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。</p><p><img src="/images/DevOps/DevOps.png" alt></p><p><img src="/images/DevOps/devops-loop-and-spans-small.png" alt></p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="Auto-DevOps"><a href="#Auto-DevOps" class="headerlink" title="Auto DevOps"></a>Auto DevOps</h1><p>GitLab Auto DevOps:</p><ul><li>Auto Build</li><li>Auto Test</li><li>Auto Code Quality</li><li>Auto SAST (Static Application Security Testing)</li><li>Auto Dependency Scanning</li><li>Auto License Management</li><li>Auto Container Scanning</li><li>Auto Review Apps</li><li>Auto DAST (Dynamic Application Security Testing)</li><li>Auto Deploy</li><li>Auto Browser Performance Testing</li><li>Auto Monitoring</li></ul><p><br><br><br></p><hr><p><br><br><br></p><h1 id="DevOps工具"><a href="#DevOps工具" class="headerlink" title="DevOps工具"></a>DevOps工具</h1><p>下面介绍一些DevOps需要用到的工具，可能不够详细。</p><p><br></p><h2 id="基础环境"><a href="#基础环境" class="headerlink" title="基础环境"></a>基础环境</h2><p>IaaS:</p><ul><li>VMware</li><li>Xen</li><li>KVM</li><li>OpenStack</li><li>云平台</li><li>…</li></ul><p><br><br><br></p><h2 id="项目管理"><a href="#项目管理" class="headerlink" title="项目管理"></a>项目管理</h2><p>Task:</p><ul><li>RedaMine</li><li>Jira</li><li>禅道</li><li>…</li></ul><p><br><br><br></p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>Code:</p><ul><li>git</li><li>GitLab</li><li>Gogs</li><li>svn</li><li>云平台</li><li>…</li></ul><p><br><br><br></p><h2 id="持续集成-发布"><a href="#持续集成-发布" class="headerlink" title="持续集成/发布"></a>持续集成/发布</h2><p>CI/CD:</p><ul><li>Jenkins</li><li>Jenkins X</li><li>GitLab CICD</li><li>Bamboo</li><li>Maven</li><li>云平台</li><li>…</li></ul><p><br><br><br></p><h2 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h2><p>Container:</p><ul><li>Docker</li><li>K8s</li><li>CoreOS</li><li>Mesos</li><li>Helm</li><li>云平台</li><li>…</li></ul><p><br><br><br></p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>Test:</p><ul><li><strong>Selenium</strong></li><li><strong>Katalon Studio</strong></li><li><strong>Watir</strong></li><li><strong>Jmeter</strong></li><li><strong>Loadrunner</strong></li><li><strong>LOCUST</strong></li></ul><p><br></p><h3 id="Selenium"><a href="#Selenium" class="headerlink" title="Selenium"></a>Selenium</h3><ul><li>Website: <a href="https://www.seleniumhq.org/" target="_blank" rel="noopener">https://www.seleniumhq.org/</a></li></ul><p>Selenium是一个用于自动化测试Web apps的可移植框架。 Selenium提供了一种用于创作功能测试的回放工具，无需学习测试脚本语言。</p><p><br><br><br></p><h3 id="Katalon-Studio"><a href="#Katalon-Studio" class="headerlink" title="Katalon Studio"></a>Katalon Studio</h3><ul><li>Wetsite: <a href="https://www.katalon.com/" target="_blank" rel="noopener">https://www.katalon.com/</a></li></ul><p>Simplify API, Web, Mobile Automation Tests.</p><p><br><br><br></p><h3 id="Watir"><a href="#Watir" class="headerlink" title="Watir"></a>Watir</h3><ul><li>Website: <a href="http://watir.com/" target="_blank" rel="noopener">http://watir.com/</a></li></ul><p>An open source Ruby library for automating tests.<br>Watir interacts with a browser the same way people do: clicking links, filling out forms and validating text.</p><p><br><br><br></p><h3 id="JMeter"><a href="#JMeter" class="headerlink" title="JMeter"></a>JMeter</h3><p>Apache JMeter应用程序是开源软件，纯Java应用程序，旨在加载测试功能行为和测量性能。它最初是为测试Web应用程序而设计的，但后来扩展到其他测试功能。</p><p>Apache JMeter可用于测试静态和动态资源，Web动态应用程序的性能。<br>它可用于模拟服务器，服务器组，网络或对象上的重负载，以测试其强度或分析不同负载类型下的整体性能。</p><p><br></p><p>Apache JMeter功能包括:</p><ul><li>Ability to load and performance test many different applications/server/protocol types<ul><li>Web - HTTP, HTTPS (Java, NodeJS, PHP, ASP.NET, …)</li><li>SOAP / REST Webservices</li><li>FTP</li><li>Database via JDBC</li><li>LDAP</li><li>Message-oriented middleware (MOM) via JMS</li><li>Mail - SMTP(S), POP3(S) and IMAP(S)</li><li>Native commands or shell scripts</li><li>TCP</li><li>Java Objects</li></ul></li><li>Full featured Test IDE that allows fast Test Plan recording</li><li>CLI mode to load test from any Java compatible OS</li><li>Highly Extensible core</li><li>…</li></ul><p><br><br><br></p><h3 id="LoadRunner"><a href="#LoadRunner" class="headerlink" title="LoadRunner"></a>LoadRunner</h3><ul><li>Website: <a href="https://www.microfocus.com" target="_blank" rel="noopener">https://www.microfocus.com</a></li></ul><p>LoadRunner is a Load Testing Software</p><p><br><br><br></p><h3 id="LOCUST"><a href="#LOCUST" class="headerlink" title="LOCUST"></a>LOCUST</h3><ul><li>Website: <a href="https://locust.io/" target="_blank" rel="noopener">https://locust.io/</a></li><li>GitHub: <a href="https://github.com/locustio/locust/" target="_blank" rel="noopener">https://github.com/locustio/locust/</a></li></ul><p><br></p><p>An open source load testing tool.</p><p>Define user behaviour with Python code, and swarm your system with millions of simultaneous users.</p><p><br><br><br><br><br></p><h2 id="质量与安全"><a href="#质量与安全" class="headerlink" title="质量与安全"></a>质量与安全</h2><p>Quality and Security:</p><ul><li>infer</li><li>SonarQube</li><li>Cuckoo Sandbox</li><li>OWASP ZAProxy</li><li>Mobile-Security-Framework-MobSF</li><li>Clair</li></ul><p><br></p><h3 id="Infer"><a href="#Infer" class="headerlink" title="Infer"></a>Infer</h3><ul><li>GitHub: <a href="https://github.com/facebook/infer" target="_blank" rel="noopener">https://github.com/facebook/infer</a></li><li>Website: <a href="https://fbinfer.com/" target="_blank" rel="noopener">https://fbinfer.com/</a></li></ul><p><br></p><p><strong>Infer</strong> 是一个 <code>Java</code>，<code>C ++</code>，<code>Objective-C</code> 和 <code>C</code> 的代码静态分析工具。它会产生一个潜在的bug列表。任何人都可以使用Infer在发送给用户之前拦截关键错误，并帮助防止崩溃或性能不佳。</p><p>infer 主要用于 APP 端，也就是 Android/IOS App。</p><p><br><br><br></p><h3 id="SonarQube"><a href="#SonarQube" class="headerlink" title="SonarQube"></a>SonarQube</h3><ul><li>GitHub: <a href="https://github.com/SonarSource/sonarqube" target="_blank" rel="noopener">https://github.com/SonarSource/sonarqube</a></li><li>Website: <a href="https://www.sonarqube.org/" target="_blank" rel="noopener">https://www.sonarqube.org/</a></li></ul><p><br></p><p><strong>SonarQube</strong> 是一个开源平台，通过代码的自动化静态分析不断的检查代码质量。 SonarQube 支持20多种语言的分析，并在各种类型的项目中输出和存储问题。通过不同的插件对这些结果进行再加工处理，通过量化的方式度量代码质量的变化，从而可以方便地对不同规模和种类的工程进行代码质量管理。</p><p><br><br><br></p><h3 id="MobSF"><a href="#MobSF" class="headerlink" title="MobSF"></a>MobSF</h3><ul><li>GitHub: <a href="https://github.com/MobSF/Mobile-Security-Framework-MobSF" target="_blank" rel="noopener">https://github.com/MobSF/Mobile-Security-Framework-MobSF</a></li></ul><p><br></p><p>Mobile Security Framework is an automated, all-in-one mobile application (Android/iOS/Windows) pen-testing framework capable of performing static analysis, dynamic analysis, malware analysis and web API testing.</p><p><br><br><br></p><h3 id="Clair"><a href="#Clair" class="headerlink" title="Clair"></a>Clair</h3><ul><li>GitHub: <a href="https://github.com/coreos/clair" target="_blank" rel="noopener">https://github.com/coreos/clair</a></li></ul><p>Vulnerability Static Analysis for Containers.<br>Clair is an open source project for the static analysis of vulnerabilities in application containers (currently including appc and docker).</p><p><br><br><br><br><br></p><h2 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h2><p>Configuration Management:</p><ul><li>Ansible</li><li>ZooKeeper</li><li>CFEngine</li><li>Chef</li><li>MAAS</li><li>Puppet</li><li>SaltStack</li><li>Vagrant</li><li>Rundeck</li><li>Rudder</li><li>云平台</li><li>…</li></ul><p><br><br><br><br><br></p><h2 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h2><p>Data Analysis:</p><ul><li>Hadoop</li><li>Ambari</li><li>Avro</li><li>Flume</li><li>HBase</li><li>Hive</li><li>Spark</li><li>Sqoop</li><li>ZooKeeper</li></ul><p><br><br><br><br><br></p><h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p>Log:</p><ul><li>ElasticStack<ul><li>Elasticsearch</li><li>Logstash</li><li>Beat</li></ul></li><li>Hadoop, Hive - 与ELK类似的方案</li><li>Flume</li><li>Fluentd</li><li>Splunk</li><li>Kafka</li><li>Loggly</li><li>Papertrail</li><li>云平台</li><li>…</li></ul><p><br><br><br></p><h2 id="流"><a href="#流" class="headerlink" title="流"></a>流</h2><p>Stream:</p><ul><li>Kafka</li><li>Apex</li><li>Flink</li><li>Heron</li><li>Spark</li><li>Heka</li></ul><p><br><br><br></p><h2 id="Api网关"><a href="#Api网关" class="headerlink" title="Api网关"></a>Api网关</h2><p>Api Gateway:</p><ul><li>Gloo</li><li>Ambassador</li><li>Spring Cloud</li><li>Kong</li><li>Netflix Zuul</li><li>云平台</li><li>…</li></ul><p><br><br><br></p><h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><p>Performance:</p><ul><li>NetData</li><li>Pinpoint</li><li>Datadog</li><li>AppDynamics</li><li>Apache JMeter</li><li>ab(ApacheBench)</li><li>Gatling</li></ul><p><br><br><br></p><h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><p>Monitoring:</p><ul><li>Zabbix</li><li>Nagios</li><li>Prometheus</li><li>Grafana</li><li>Netdata</li><li>Graphite</li><li>Cacti</li><li>Glances</li><li>Collectd</li><li>Ganglia</li><li>Kibana</li><li>Sensu</li></ul><p><br><br><br></p><h2 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h2><p>Backup:</p><ul><li>全量</li><li>增量</li></ul><p><br><br><br></p><hr><p><br><br><br></p><h1 id="灰度发布"><a href="#灰度发布" class="headerlink" title="灰度发布"></a>灰度发布</h1><blockquote><p>ps:<br>参考百度百科!</p></blockquote><p><br></p><p>灰度发布（金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。在其上可以进行A/B testing，即让一部分用户继续用产品特性A，一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。<br>灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。</p><p>灰度期：灰度发布开始到结束期间的这一段时间，称为灰度期。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;li&gt;GitLab&lt;/li&gt;
&lt;li&gt;GitHub&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://zhang21.github.io/categories/DevOps/"/>
    
    
      <category term="自动化运维" scheme="https://zhang21.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"/>
    
      <category term="运维开发" scheme="https://zhang21.github.io/tags/%E8%BF%90%E7%BB%B4%E5%BC%80%E5%8F%91/"/>
    
      <category term="Auto DevOps" scheme="https://zhang21.github.io/tags/Auto-DevOps/"/>
    
  </entry>
  
  <entry>
    <title>谏逐客书</title>
    <link href="https://zhang21.github.io/2019/02/10/%E8%B0%8F%E9%80%90%E5%AE%A2%E4%B9%A6/"/>
    <id>https://zhang21.github.io/2019/02/10/谏逐客书/</id>
    <published>2019-02-10T13:45:14.000Z</published>
    <updated>2019-03-08T09:38:42.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li><li>百度百科</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>《谏逐客书》是李斯的一篇优秀古代公文，是应用写作法定公文研究的重要内容之一。这里的“书”不是书信，而是上书、奏章，为古代臣子向君主陈述政见的一种文体，是一种臣子向帝王逐条分析事理的公文名称，与表性质类似。该文能比较充分地体现公文的一些本质属性，正是这些公文本质属性形成了该文鲜明的特色。</p><p>文章先叙述自秦穆公以来皆以客致强的历史，说明秦若无客的辅助则未必强大的道理；然后列举各种女乐珠玉虽非秦地所产却被喜爱的事实作比，说明秦王不应该重物而轻人。文章立意高深，始终围绕“大一统”的目标，从秦王统一天下的高度立论，正反论证，利害并举，说明用客卿强国的重要性。此文理足词胜，雄辩滔滔，打动了秦王嬴政，使他收回逐客的成命，恢复了李斯的官职。</p><p>李斯（约前280年－前208年），战国末年楚国上蔡（今河南驻马店上蔡县）人，秦朝丞相，中国历史上著名的政治家、文学家和书法家。李斯早年从荀卿学帝王之术，后被秦王政任为客卿。秦王政十年（前237年）李斯上《谏逐客书》反对驱逐客卿，为秦王政所采纳。他在秦王政统一六国的事业中起了较大作用。秦统一天下后，李斯与王绾、冯劫尊秦王嬴政为皇帝，被任为丞相。李斯参与制定了秦朝的法律并完善了秦朝的制度；他主张实行郡县制、废除分封制；又主张焚烧民间收藏的《诗》、《书》、百家语，禁止私学，以加强专制主义中央集权的统治；提出并且主持了文字、车轨、货币、度量衡的统一。李斯实行郡县制等政治主张，奠定了中国两千多年政治制度的基本格局。秦始皇死后，他与赵高合谋立少子胡亥为帝。后为赵高所忌，于秦二世二年（前208年）被腰斩于咸阳。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h1><p>会韩人郑国来间秦，以作注溉渠，已而觉。秦宗室大臣皆言秦王曰：诸侯人来事秦者，大抵为其主游间于秦耳。请一切逐客！李斯议亦在逐中。</p><p>斯乃上曰：</p><p>臣闻吏议逐客，窃以为过矣。昔穆公求士，西取由余于戎，东得百里奚于宛，迎蹇叔于宋，求丕豹、公孙支于晋；此五子者，不产于秦，而穆公用之，并国二十，遂霸西戎。孝公用商鞅之法，移风易俗，民以殷盛，国以富强，百姓乐用，诸侯亲服，获楚、魏之师，举地千里，至今治强。惠王用张仪之计，拔三川[15]之地，西并巴、蜀，北收上郡，南取汉中，包九夷，制鄢[18]、郢，东据成皋之险，割膏腴之壤，遂散六国之从，使之西面事秦，功施到今。昭王得范睢，废穰侯，逐华阳，强公室，杜私门，蚕食诸侯，使秦成帝业。此四君者，皆以客之功。由此观之，客何负于秦哉？向使四君却客而不内，疏士而不用；是使国无富利之实，而秦无强大之名也。</p><p>今陛下致昆山之玉，有随、和之宝，垂明月之珠，服太阿之剑，乘纤离之马，建翠凤之旗，树灵鼍之鼓；此数宝者，秦不生一焉，而陛下说之，何也？必秦国之所生然后可；则是夜光之璧，不饰朝廷；犀象之器，不为玩好；郑、魏之女，不充后宫；而骏良駃騠，不实外廄；江南金锡不为用，西蜀丹青不为采。所以饰后宫，充下陈，娱心意，说耳目者，必出于秦然后可；则是宛珠之簪，傅玑之珥，阿缟之衣，锦绣之饰，不进于前，而随俗雅化。佳冶窈窕，赵女不立于侧也。夫击瓮叩缶，弹筝搏髀，而歌呼呜呜快耳目者，真秦之声也；郑、卫、桑间、《昭虞》、《武象》者，异国之乐也。今弃击瓮而就郑、卫，退弹筝而取《昭虞》，若是者何也？快意当前，适观而已矣。今取人则不然：不问可否，不论曲直，非秦者去，为客者逐。然则是所重者，在乎色、乐、珠、玉，而所轻者在乎人民也；此非所以跨海内，制诸侯之术也！</p><p>臣闻地广者粟多，国大者人众，兵疆者则士勇；是以泰山不让土壤，故能成其大；河海不择细流，故能就其深；王者不却众庶，故能明其德；是以地无四方，民无异国，四时充美，鬼神降福，此五帝、三王之所以无敌也。今乃弃黔首以资敌国，却宾客以业诸侯，使天下之士，退而不敢西向，裹足不入秦，此所谓借寇兵而赍盗粮者也。夫物不产于秦，可宝者多；士不产于秦，而愿忠者众。今逐客以资敌国，损民以益雠，内自虚而外树怨于诸侯，求国之无危，不可得也。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="译文"><a href="#译文" class="headerlink" title="译文"></a>译文</h1><p>我听说官吏在商议驱逐客卿这件事，私下里认为是错误的。从前秦穆公寻求贤士，西边从西戎取得由余，东边从宛地得到百里奚，又从宋国迎来蹇叔，还从晋国招来丕豹、公孙支。这五位贤人，不生在秦国，而秦穆公重用他们，吞并国家二十多个，于是称霸西戎。秦孝公采用商鞅的新法，移风易俗，人民因此殷实，国家因此富强，百姓乐意为国效力，诸侯亲附归服，战胜楚国、魏国的军队，攻取土地上千里，至今政治安定，国力强盛。秦惠王采纳张仪的计策，攻下三川地区，西进兼并巴、蜀两国，北上收得上郡，南下攻取汉中，席卷九夷各部，控制鄢、郢之地，东面占据成皋天险，割取肥田沃土，于是拆散六国的合纵同盟，使他们朝西事奉秦国，功烈延续到今天。昭王得到范雎，废黜穰侯，驱逐华阳君，加强、巩固了王室的权力，堵塞了权贵垄断政治的局面，蚕食诸侯领土，使秦国成就帝王大业。这四位君主，都依靠了客卿的功劳。由此看来，客卿哪有什么对不住秦国的地方呢！倘若四位君主拒绝远客而不予接纳，疏远贤士而不加任用，这就会使国家没有丰厚的实力，而让秦国没有强大的名声了。</p><p>陛下罗致昆山的美玉，宫中有随侯之珠，和氏之璧，衣饰上缀着光如明月的宝珠，身上佩带着太阿宝剑，乘坐的是名贵的纤离马，树立的是以翠凤羽毛为饰的旗子，陈设的是蒙着灵鼍之皮的好鼓。这些宝贵之物，没有一种是秦国产的，而陛下却很喜欢它们，这是为什么呢？如果一定要是秦国出产的才许可采用，那么这种夜光宝玉，决不会成为秦廷的装饰；犀角、象牙雕成的器物，也不会成为陛下的玩好之物；郑、卫二地能歌善舞的女子，也不会填满陛下的后宫；北方的名骥良马，决不会充实到陛下的马房；江南的金锡不会为陛下所用，西蜀的丹青也不会作为彩饰。用以装饰后宫、广充侍妾、爽心快意、悦入耳目的所有这些都要是秦国生长、生产的然后才可用的话，那么点缀有珠宝的簪子，耳上的玉坠，丝织的衣服，锦绣的装饰，就都不会进献到陛下面前；那些闲雅变化而能随俗推移的妖冶美好的佳丽，也不会立于陛下的身旁。那敲击瓦器，拍髀弹筝，乌乌呀呀地歌唱，能快人耳目的，确真是秦国的地道音乐了；那郑、卫桑间的歌声，《韶虞》《武象》等乐曲，可算是外国的音乐了。如今陛下却抛弃了秦国地道的敲击瓦器的音乐，而取用郑、卫淫靡悦耳之音，不要秦筝而要《韶虞》，这是为什么呢？难道不是因为外国音乐可以快意，可以满足耳目功能的需要么？可陛下对用人却不是这样，不问是否可用，不管是非曲直，凡不是秦国的就要离开，凡是客卿都要驱逐。这样做就说明，陛下所看重的，只在珠玉声色方面；而所轻视的，却是人民士众。这不是能用来驾驭天下，制服诸侯的方法啊！</p><p>我听说田地广就粮食多，国家大就人口众，武器精良将士就骁勇。因此，泰山不拒绝泥土，所以能成就它的高大；江河湖海不舍弃细流，所以能成就它的深邃；有志建立王业的人不嫌弃民众，所以能彰明他的德行。因此，土地不分东西南北，百姓不论异国它邦，那样便会一年四季富裕美好，天地鬼神降赐福运，这就是五帝、三王无可匹敌的缘故。抛弃百姓使之去帮助敌国，拒绝宾客使之去事奉诸侯，使天下的贤士退却而不敢西进，裹足止步不入秦国，这就叫做“借武器给敌寇，送粮食给盗贼”啊。物品中不出产在秦国，而宝贵的却很多；贤士中不出生于秦，愿意效忠的很多。如今驱逐宾客来资助敌国，减损百姓来充实对手，内部自己造成空虚而外部在诸侯中构筑怨恨，那要谋求国家没有危难，是不可能的啊。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;li&gt;百度百科&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="Literature" scheme="https://zhang21.github.io/categories/Literature/"/>
    
    
      <category term="古文" scheme="https://zhang21.github.io/tags/%E5%8F%A4%E6%96%87/"/>
    
      <category term="政论文" scheme="https://zhang21.github.io/tags/%E6%94%BF%E8%AE%BA%E6%96%87/"/>
    
      <category term="李斯" scheme="https://zhang21.github.io/tags/%E6%9D%8E%E6%96%AF/"/>
    
  </entry>
  
  <entry>
    <title>本朝百年无事札子</title>
    <link href="https://zhang21.github.io/2019/02/10/%E6%9C%AC%E6%9C%9D%E7%99%BE%E5%B9%B4%E6%97%A0%E4%BA%8B%E6%9C%AD%E5%AD%90/"/>
    <id>https://zhang21.github.io/2019/02/10/本朝百年无事札子/</id>
    <published>2019-02-10T13:45:12.000Z</published>
    <updated>2019-03-08T09:24:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li><li>百度百科</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>　　《本朝百年无事札子》是北宋王安石所作奏议。全文以扬为抑，褒中有贬，在探究北宋立国以来百余年间太平无事的原因的同时，剖析了宋仁宗统治时的种种弊病；透过“百年无事”的表象揭示出危机四伏的实质，犀利地指出因循守旧、故步自封的危害；并就吏治、教育、科举、农业、财政、军事等诸方面的改革提出了自己的见解与主张。文章条理清晰，措辞委婉，情感恳切坦诚，是历代奏议中的佳作。</p><p>　　王安石（1021—1086）北宋政治家、文学家、思想家。字介甫，晚号半山。抚州临（今属江西抚州）人。庆历进士。初知鄞县，嘉祜三年（1058）上万言书，主张改革政治。熙宁二年（1069），被任为参知政事。次年拜相，推行新法，遭到反对。熙宁七年辞退，次年再相，九年再辞．退居江宁（今江苏南京），封荆国公，世称“荆公”。卒谥文。散文雄健峭拔，为“唐宋八大家”之一。其诗遒劲清新，其词风格高峻。著有《临川集》、《临川集拾遗》等。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h1><p>　　臣前蒙陛下问及本朝所以享国百年、天下无事之故。臣以浅陋，误承圣问，迫于日晷，不敢久留，语不及悉，遂辞而退。窃惟念圣问及此，天下之福，而臣遂无一言之献，非近臣所以事君之义，故敢冒昧而粗有所陈。</p><p>　　伏惟太祖躬上智独见之明，而周知人物之情伪，指挥付托必尽其材，变置施设必当其务。故能驾驭将帅，训齐士卒，外以捍诸边，内以平中国。于是除苛赋，止虐刑，废强横之藩镇，诛贪残之官吏，躬以简俭为天下先。其于出政发令之间，一以安利元元为事。太宗承之以聪武，真宗守之以谦仁，以至仁宗、英宗，无有逸德。此所以享国百年而天下无事也。</p><p>　　仁宗在位，历年最久。臣于时实备从官，施为本末，臣所亲见。尝试为陛下陈其一二，而陛下详择其可，亦足以申鉴于方今。</p><p>　　伏惟仁宗之为君也，仰畏天，俯畏人，宽仁恭俭，出于自然。而忠恕诚悫，终始如一，未尝妄兴一役，未尝妄杀一人，断狱务在生之，而特恶吏之残扰。宁屈己弃财于外敌，而终不忍加兵。刑平而公，赏重而信。纳用谏官御史，公听并观，而不蔽于偏至之谗。因任众人耳目，拔举疏远，而随之以相坐之法。盖监司之吏以至州县，无敢暴虐残酷，擅有调发，以伤百姓。自夏人顺服，蛮夷遂无大变，边人父子夫妇，得免于兵死，而中国之人，安逸蕃息，以至今日者，未尝妄兴一役，未尝妄杀一人，断狱务在生之，而特恶吏之残扰，宁屈己弃财于夷狄而不忍加兵之效也。大臣贵戚、左右近习，莫敢强横犯法，其自重慎或甚于闾巷之人。此刑平而公之效也。募天下骁雄横猾以为兵，几至百万，非有良将以御之，而谋变者辄败。聚天下财物，虽有文籍，委之府史，非有能吏以钩考，而断盗者辄发。凶年饥岁，流者填道，死者相枕，而寇攘辄得。此赏重而信之效也。大臣贵戚、左右近习，莫能大擅威福，广私货赂，一有奸慝，随辄上闻。贪邪横猾，虽间或见用，未尝得久。此纳用谏官、御史，公听并观，而不蔽于偏至之谗之效也。自县令京官以至监司台阁，升擢之任，虽不皆得人，然一时之所谓才士，亦罕蔽塞而不见收举者。此因任众人之耳目、拔举疏远而随之以相坐之法之效也。升遐之日，天下号恸，如丧考妣，此宽仁恭俭出于自然，忠恕诚悫，终始如一之效也。</p><p>　　然本朝累世因循末俗之弊，而无亲友群臣之议。人君朝夕与处，不过宦官女子，出而视事，又不过有司之细故，未尝如古大有为之君，与学士大夫讨论先王之法以措之天下也。一切因任自然之理势，而精神之运有所不加，名实之间有所不察。君子非不见贵，然小人亦得厕其间。正论非不见容，然邪说亦有时而用。以诗赋记诵求天下之士，而无学校养成之法。以科名资历叙朝廷之位，而无官司课试之方。监司无检察之人，守将非选择之吏。转徙之亟既难于考绩，而游谈之众因得以乱真。交私养望者多得显官，独立营职者或见排沮。故上下偷惰取容而已。虽有能者在职，亦无以异于庸人。农民坏于徭役，而未尝特见救恤，又不为之设官，以修其水土之利。兵士杂于疲老，而未尝申敕训练，又不为之择将，而久其疆场之权。宿卫则聚卒伍无赖之人，而未有以变五代姑息羁縻之俗。宗室则无教训选举之实，而未有以合先王亲疏隆杀之宜。其于理财，大抵无法，故虽俭约而民不富，虽忧勤而国不强。赖非夷狄昌炽之时，又无尧、汤水旱之变，故天下无事，过于百年。虽曰人事，亦天助也。盖累圣相继，仰畏天，俯畏人，宽仁恭俭，忠恕诚悫，此其所以获天助也。</p><p>　　伏惟陛下躬上圣之质，承无穷之绪，知天助之不可常恃，知人事之不可怠终，则大有为之时，正在今日。臣不敢辄废“将明”之义，而苟逃讳忌之诛。伏惟陛下幸赦而留神，则天下之福也。取进止。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="译文"><a href="#译文" class="headerlink" title="译文"></a>译文</h1><p>　　我前些天承蒙陛下问到我朝之所以统治了上百年，天下太平无事的原因。我因为浅薄无知，错蒙皇上询问，由于时间紧迫，不敢长时间留在宫中，话还来不及说完，就告辞退朝。私下想到皇上问到这个问题，是天下的福气，而我却没有一句中肯的话奉献，不是身边官员效忠君主的态度，所以敢于不揣冒昧粗略地说说我的看法。</p><p>　　我想太祖具有极高的智慧独到的见解，详尽地了解各种人物的真伪，指挥任命，一定做到人尽其才，设置变革措施，一定能够符合现实情况。所以能够驾驭将帅，练好兵卒，对外抵抗外族入侵，对内靠他们平定动乱。于是废除苛捐杂税，禁止酷刑，废除强横的藩镇势力，诛杀贪婪残暴的官吏，自身俭朴，为天下做出了榜样。太祖在制定政策发布命令的时候，一切以百姓能平安、得利为准则。太宗继承了太祖的聪慧勇武，真宗保持了太祖的谦恭仁爱，到了仁宗、英宗，没有丧失道德的地方。这就是所以能够统治上百年，而天下太平的缘故。仁宗做皇上，时间最久。我当时担任侍从官员，所作所为，从头到尾，都是我所亲眼看到的。</p><p>　　我试为陛下陈说其中的几条，陛下详加考虑，选择可取之处，也足以用作今天的借鉴。 我想仁宗作为一位君主，对上敬畏天命，对下敬畏人民；宽厚仁爱，谦恭俭朴，出于天性；忠恕诚恳，始终如一。没有随意兴办一项工程，没有随意杀过一个人。审断案件尽量使犯人能够活下来，特别憎恨官吏对百姓的残暴骚扰。宁肯委屈自己输送钱财给辽、夏，却始终不忍心对他们开战。刑罚轻缓而公正，赏赐很重而守信用。采纳谏官、御史的建议，多方面地听取和观察，而不会受到偏见的谗言的蒙蔽；依靠众人的耳闻目睹，选拔举荐关系疏远的人才，且伴随着连坐的法律。从监察官吏到州、县的官员，没有人敢暴虐残酷，擅自增加赋税徭役，来损害老百姓。自从西夏人顺服以后，蛮横的外族就没有大的变化，边境人民的父子夫妇，能够不在战争中死亡，而内地的人民，安定和平繁荣兴旺，一直到今天，这是因为没有随意兴办一项工程，没有错杀一个人，审断案件尽量使犯人能够活下来，而特别憎恨官吏对百姓的残暴、骚扰，宁肯委屈自己输送财物给辽、夏外族，而不忍心对他们开战的结果。王公大臣，皇亲国戚，身边的近臣，没有人敢强横犯法，他们自重谨慎，有的甚至超过平民百姓，这是刑罚轻缓而公正的结果。招募天下骁雄强横奸诈之徒作为士兵，几乎达到百万，没有良将来统帅他们，而阴谋叛乱的人很快就败露；聚集天下的财物，虽然有账册，把这些交给府吏管理，没有贤能的官吏来检查考核，而贪污偷盗的人马上就被揭发出来；水旱灾年，逃荒的人堵塞了道路，尸横遍野，而抢夺财物的强盗立刻就被捕获，这是重赏赐而守信用的结果。王公大臣、皇亲国戚、身边的侍从官吏，没有能大肆作威作福，到处钻营受贿，一有奸邪不法的事，随即就报告到上面；贪婪奸邪强横狡猾之徒，即使偶尔被任用，不能够长久的。这是采纳谏官、御史的建议，广泛地听取观看，而不会受到偏见的谗言所蒙蔽的结果。从县令、京官，到监司、台阁，提拔任用，虽然不能全部称职，然而，闻名一时的所谓有才能的人，也很少有埋没不被任用的。这是依靠众人的耳闻目睹，选拔推荐关系疏远的人才而伴随着连坐之法的结果。驾崩的那一天，天下的人民放声痛哭，如同死去父母，这是宽厚仁爱谦恭俭朴，出于本性，忠恕诚恳，始终如一的结果。</p><p>　　但是，本朝几代墨守衰风颓俗的弊病，却没有皇亲国戚和诸位臣子议论它。和皇上朝夕相处的，不过是宦官宫女，出来处理政事，又不过是有关部门的琐事，没有像古代大有作为的君主那样，和学士、大夫们讨论先王治理国家的方法，把它实施到天下。一切听任自然趋势，而主观努力却有所不够，名义和实际效果之间的关系，没有加以考察。君子并不是不被容纳，但小人也能够混进来。正确的论断并不是不被采纳，然而不正确的怪论也有时候被采用。凭着写诗作赋博闻强记选拔天下的士人，而没有学校培养造就人才的方法；以科名贵贱资历深浅排列在朝中的官位，而没有官吏考核实绩的制度。监司部门没有设置检查的人，守将不是选拔上来的贤臣，频繁地调动迁官，既难于考核实绩，而夸夸其谈的人，因而能够乱真。结党营私，猎取名望的人，大多数得到了显要的职务，靠自己才能奉公守职的人，也无法显示出和庸人的不同。农民受到了徭役的牵累，没有看到特别的救济抚恤，又不为他们设置官员，兴修农田水利；士兵中混杂着老弱病员，没有加以告诫整顿，又不替他们选拔将领，让他们长久地掌握守边任务。保卫都城收罗的是些兵痞无赖，没有改变五代的纵容、笼络的坏习惯；皇室中没有教导训练、选拔推荐之实，因而不能符合先王亲近疏远、升官、降职的原则。至于管理财政，基本上没有法度，所以虽然皇上俭朴节约而人民却不富足，虽然操心勤勉而国家却不强大。幸赖不是夷狄昌盛的时候，又没有尧、汤时代水涝旱灾的特殊情况，所以天下无事，超过百年。虽然是人努力的结果，也靠了天的帮助。原因是几代圣君相传，对上敬畏天命，对下敬畏人民，宽厚仁爱谦恭俭朴，忠恕诚恳，这是他们之所以获得上天帮助的缘故。</p><p>　　我想陛下身具最为圣明的资质，继承无穷无尽的帝业，知道不能长久地依靠上天的帮助，知道人事不能始终懈怠下去，那么大有作为的时候，正在今天。我不敢随便放弃臣子应尽的职责，而只顾躲避独犯忌讳所遭到的惩罚。恳请陛下宽恕我并留神我的话，那就是天下人的福气了。恰当与否，请陛下裁决。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;li&gt;百度百科&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="Literature" scheme="https://zhang21.github.io/categories/Literature/"/>
    
    
      <category term="古文" scheme="https://zhang21.github.io/tags/%E5%8F%A4%E6%96%87/"/>
    
      <category term="政论文" scheme="https://zhang21.github.io/tags/%E6%94%BF%E8%AE%BA%E6%96%87/"/>
    
      <category term="王安石" scheme="https://zhang21.github.io/tags/%E7%8E%8B%E5%AE%89%E7%9F%B3/"/>
    
  </entry>
  
  <entry>
    <title>六国论</title>
    <link href="https://zhang21.github.io/2019/02/10/%E5%85%AD%E5%9B%BD%E8%AE%BA/"/>
    <id>https://zhang21.github.io/2019/02/10/六国论/</id>
    <published>2019-02-10T13:25:13.000Z</published>
    <updated>2019-03-08T09:29:44.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li><li>百度百科</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>《六国论》是苏洵政论文代表作品。《六国论》提出并论证了六国灭亡“弊在赂秦”的精辟论点，“借古讽今”，抨击宋王朝对辽和西夏的屈辱政策，告诫北宋统治者要吸取六国灭亡的教训，以免重蹈覆辙。</p><p>苏洵（1009—1066年），北宋著名散文家，字明允，号老泉，眉州眉山（今四川省眉山县）人。相传二十七岁时才发愤为学，应进士和茂才异等考试皆未中。于是愤而自焚平日所著文章，再度闭门潜心读书，终于博通六艺及诸子百家著作，撰写文章下笔顷时数千言。嘉祐间，得当时名盛一时的翰林学士欧阳修推誉，以文章著名于世。曾任秘书省校书郎、霸州文安县主簿。后与姚辟同修礼书《太常因革礼》一百卷，书成后不久去世。他主张抵抗辽的攻掠，对大地主的土地兼并、政治特权有所不满。为文擅长策论，语言明畅，笔力雄健，奔腾驰骋，纵横捭阖，老辣犀利，很有战国纵横家笔意。与其子轼、辙，合称“三苏”，俱被列入“唐宋八大家”。有《嘉祐集》行世。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h1><p>六国破灭，非兵不利，战不善，弊在赂秦。赂秦而力亏，破灭之道也。或曰：“六国互丧，率赂秦耶？”曰：“不赂者以赂者丧，盖失强援，不能独完，故曰弊在赂秦也。”</p><p>秦以攻取之外，小则获邑，大则得城，较秦之所得，与战胜而得者，其实百倍；诸侯之所亡，与战败而亡者，其实亦百倍。则秦之所大欲，诸侯之所大患，固不在战矣。思厥先祖父，暴霜露，斩荆棘，以有尺寸之地。子孙视之不甚惜，举以予人，如弃草芥。今日割五城，明日割十城，然后得一夕安寝。起视四境，而秦兵又至矣。然则诸侯之地有限，暴秦之欲无厌，奉之弥繁，侵之愈急，故不战而强弱胜负已判矣。至于颠覆，理固宜然。古人云：“以地事秦，犹抱薪救火，薪不尽，火不灭。”此言得之。</p><p>齐人未尝赂秦，终继五国迁灭，何哉？与嬴而不助五国也。五国既丧，齐亦不免矣。燕、赵之君，始有远略，能守其土，义不赂秦。是故燕虽小国而后亡，斯用兵之效也。至丹以荆卿为计，始速祸焉。[5]赵尝五战于秦，二败而三胜。后秦击赵者再，李牧连却之。洎牧以谗诛，邯郸为郡；惜其用武而不终也。</p><p>且燕、赵处秦革灭殆尽之际，可谓智力孤危，战败而亡，诚不得已。向使三国各爱其地，齐人勿附于秦，刺客不行，良将犹在，则胜负之数，存亡之理，当与秦相较，或未易量。</p><p>呜呼！以赂秦之地，封天下之谋臣；以事秦之心，礼天下之奇才；并力西向，则吾恐秦人食之不得下咽也。悲夫！有如此之势，而为秦人积威之所劫，日削月割，以趋于亡，为国者无使为积威之所劫哉！</p><p>夫六国与秦皆诸侯，其势弱于秦，而犹有可以不赂而胜之之势；茍以天下之大，而从六国破亡之故事，是又在六国下矣！</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="译文"><a href="#译文" class="headerlink" title="译文"></a>译文</h1><p>六国灭亡，不是武器不锐利，仗打得不好，弊病在于割地贿赂秦国。割地贿赂秦国，自己的力量就亏损了，这是灭亡的原因。有人说：“六国相继灭亡，全都是由于割地贿赂秦国吗？”回答说：“不割地贿赂秦国的国家因为割地贿赂秦国的国家而灭亡。因为他们失去了强有力的外援，不能单独保全。所以说：‘弊病在于割地贿赂秦国’啊！”</p><p>秦国除用攻战的方法取得土地之外（还得到诸侯的割地贿赂），小的就获得城镇，大的就获得都市，把秦国由受贿赂得到的土地与战胜而得到的土地比较，实际上有一百倍，把诸侯贿赂秦国所失去的土地与战败所失去的土地比较，实际上也有一百倍。那么秦国最大的欲望，诸侯最大的祸患，当然就不在于战争了。回想他们的祖辈父辈，冒着霜露，披荆斩棘，因而才有一点点土地。可是子孙们看待它却很不珍惜，拿它来送人，就像抛弃小草一样。今天割去五座城，明天割去十座城，然后才能睡上一夜安稳觉。待起床一看四周边境，秦国的军队又打来了。那么，诸侯的土地有限，暴秦的欲望没有满足；谁送给它土地越多，它侵犯谁就越急。所以不用打仗，谁强谁弱、谁胜谁败就已分得清清楚楚了。六国落到灭亡的地步，按理本来应当这样。古人说：“用土地侍奉秦国，就像抱着柴草救火，柴草没有烧完，火就不会熄灭。”这话说得在理啊！</p><p>齐国不曾割地贿赂秦国，最后也随着五国灭亡，为什么呢？这是因为它跟秦国交好而不帮助五国啊。五国灭亡之后，齐国也就不能幸免了。燕国和赵国的君主，起初有远大的谋略，能够守住自己的土地，坚持正义不贿赂秦国。因此燕国虽然是个小国，却灭亡在后，这是用兵抵抗的效果啊。到了燕太子丹用派遣荆轲刺杀秦王作为对付秦国的策略，才招致灭亡的祸患。赵国曾经与秦国多次作战，败少胜多。后来秦国又两次攻打赵国，李牧接连打退了它。等到李牧因受谗言被赵王杀害，都城邯郸就变成秦国的一个郡，可惜它用兵抵抗却没能坚持到底啊。况且燕赵正处在其他国家被消灭了的时候，可说是智谋已尽，力量单薄，战败而亡国，实在是没有办法的事啊。假使当初韩、魏、楚三国都各自珍惜自己的土地，齐国不依附秦国，燕国的刺客不去秦国，赵国的良将李牧还活着，那么胜败存亡的命运，如果与秦国较量，也许还不容易估量呢。</p><p>唉！如果六国把贿赂秦国的土地封赏给天下的谋臣，用侍奉秦国的心意礼遇天下非凡的人才，齐心协力向西对付秦国，那么我担心秦国人连饭也咽不下喉呢。可悲啊！有这样的形势，却被秦国积久的威势所胁制，土地天天削减，月月割让，以至于走向灭亡。治理国家的人切不要让自己被敌人积久的威势所胁制啊！</p><p>六国和秦国都是诸侯，他们的势力比秦国弱，可是还有能够不割地贿赂而战胜秦国的形势。如果凭借偌大国家，却自取下策反而重蹈六国灭亡的覆辙，这就又在六国之下了！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;li&gt;百度百科&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="Literature" scheme="https://zhang21.github.io/categories/Literature/"/>
    
    
      <category term="苏洵" scheme="https://zhang21.github.io/tags/%E8%8B%8F%E6%B4%B5/"/>
    
      <category term="古文" scheme="https://zhang21.github.io/tags/%E5%8F%A4%E6%96%87/"/>
    
      <category term="政论文" scheme="https://zhang21.github.io/tags/%E6%94%BF%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>上仁宗皇帝言事书</title>
    <link href="https://zhang21.github.io/2019/02/10/%E4%B8%8A%E4%BB%81%E5%AE%97%E7%9A%87%E5%B8%9D%E8%A8%80%E4%BA%8B%E4%B9%A6/"/>
    <id>https://zhang21.github.io/2019/02/10/上仁宗皇帝言事书/</id>
    <published>2019-02-10T13:15:11.000Z</published>
    <updated>2019-02-11T01:22:31.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li><li>百度百科</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>　　王安石（1021年12月19日－1086年5月21日），字介甫，号半山，临川盐阜岭（今江西省抚州市东乡县）人，生于宋真宗天禧五年，卒于宋哲宗元祐元年，由于被封为荆国公，后人常称他为“王荆公”。王安石是北宋著名的政治家、文学家、思想家，实官至司空、尚书左仆射、观文殿大学士、镇南军节度使。他去世后被追赠为太傅，谥曰文，享年66岁。</p><p>　　嘉佑三年（1058年），调为度支判官，王安石进京述职，作长达万言的《上仁宗皇帝言事书》，系统地提出了变法主张。在此次上疏中，王安石总结了自己多年的地方官经历，指出国家积弱积贫的现实：经济困窘、社会风气败坏、国防安全堪忧，认为症结的根源在于为政者不懂得法度，解决的根本途径在于效法古圣先贤之道、改革制度，进而提出了自己的人才政策和方案的基本设想，建议朝廷改革取士、重视人才。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h1><p>　　臣愚不肖，蒙恩备使一路，今又蒙恩召还阙廷，有所任属，而当以使事归报陛下。不自知其无以称职，而敢缘使事之所及，冒言天下之事，伏惟陛下详思而择其中，幸甚。</p><p>　　臣窃观陛下有恭俭之德，有聪明睿智之才，夙兴夜寐，无一日之懈，声色狗马，观游玩好之事，无纤介之蔽，而仁民爱物之意，孚于天下，而又公选天下之所愿以为辅相者，属之以事，而不贰于谗邪倾巧之臣，此虽二帝、三王之用心，不过如此而已，宜其家给人足，天下大治。而效不至于此，顾内则不能无以社稷为忧，外则不能无惧于夷狄，天下之财力日以困穷，而风俗日以衰坏，四方有志之士，諰諰然常恐天下之久不安。此其故何也？患在不知法度故也。</p><p>　　今朝廷法严令具，无所不有，而臣以谓无法度者，何哉？方今之法度，多不合乎先王之政故也。孟子曰：「有仁心仁闻，而泽不加于百姓者，为政不法于先王之道故也。」以孟子之说，观方今之失，正在于此而已。</p><p>　　夫以今之世，去先王之世远，所遭之变，所遇之势不一，而欲一二修先王之政，虽甚愚者，犹知其难也。然臣以谓今之失，患在不法先王之政者，以谓当法其意而已。夫二帝、三王，相去盖千有余载，一治一乱，其盛衰之时具矣。其所遭之变，所遇之势，亦各不同，其施设之方亦皆殊，而其为天下国家之意，本末先后，未尝不同也。臣故曰：当法其意而已。法其意，则吾所改易更革，不至乎倾骇天下之耳目，嚣天下之口，而固已合乎先王之政矣。</p><p>　　虽然，以方今之势揆之，陛下虽欲改易更革天下之事，合于先王之意，其势必不能也。陛下有恭俭之德，有聪明睿智之才，有仁民爱物之意，诚加之意，则何为而不成，何欲而不得？然而臣顾以谓陛下虽欲改易更革天下之事，合于先王之意，其势必不能者，何也？以方今天下之才不足故也。</p><p>　　臣尝试窃观天下在位之人，未有乏于此时者也。夫人才乏于上，则有沉废伏匿在下，而不为当时所知者矣。臣又求之于闾巷草野之间，而亦未见其多焉。岂非陶冶而成之者非其道而然乎？臣以谓方今在位之人才不足者，以臣使事之所及，则可知矣。今以一路数千里之间，能推行朝廷之法令，知其所缓急，而一切能使民以修其职事者甚少，而不才苟简贪鄙之人，至不可胜数。其能讲先王之意以合当时之变者，盖阖郡之间，往往而绝也。朝廷每一令下，其意虽善，在位者犹不能推行，使膏泽加于民，而吏辄缘之为奸，以扰百姓。臣故曰：在位之人才不足，而草野闾巷之间，亦未见其多也。夫人才不足，则陛下虽欲改易更革天下之事，以合先王之意，大臣虽有能当陛下之意而欲领此者，九州之大，四海之远，孰能称陛下之指，以一二推行此，而人人蒙其施者乎？臣故曰：其势必未能也。孟子曰：「徒法不能以自行。」非此之谓乎？然则方今之急，在于人才而已。诚能使天下人才众多，然后在位之才可以择其人而取足焉。在位者得其才矣，然后稍视时势之可否，而因人情之患苦，变更天下之弊法，以趋先王之意，甚易也。今之天下，亦先王之天下，先王之时，人才尝众矣，何至于今而独不足乎？故曰：陶冶而成之者，非其道故也。</p><p>　　商之时，天下尝大乱矣。在位贪毒祸败，皆非其人，及文王之起，而天下之才尝少矣。当是时，文王能陶冶天下之士，而使之皆有士君子之才，然后随其才之所有而官使之。诗曰：「岂弟君子，遐不作人」。此之谓也。及其成也，微贱兔置之人，犹莫不好德，兔置之诗是也。又况于在位之人乎？夫文王惟能如此，故以征则服，以守则治。诗曰：「奉璋峨峨，髦士攸宜。」又曰：「周王于迈，六师及之。」文言王所用，文武各得其才，而无废事也。及至夷、厉之乱，天下之才，又尝少矣。至宣王之起，所与图天下之事者，仲山甫而已。故诗人叹之曰：「德輶如毛，维仲山甫举之，爱莫助之。」盖闵人才之少，而山甫之无助也。宣王能用仲山甫，推其类以新美天下之士，而后人才复众。于是内修政事，外讨不庭，而复有文、武之境土。故诗人美之曰：「薄言采芑，于彼新田，于此葘亩。」言宣王能新美天下之士，使之有可用之才，如农夫新美其田，而使之有可采之芑也。由此观之，人之才，未尝不自人主陶冶而成之者也。</p><p>　　所谓陶冶而成之者何也？亦教之、养之、取之、任之有其道而已。</p><p>　　所谓教之之道何也？古者天子诸侯，自国至于乡党皆有学，博置教道之官而严其选。朝廷礼乐、刑政之事，皆在于学，学士所观而习者，皆先王之法言德行治天下之意，其材亦可以为天下国家之用。苟不可以为天下国家之用，则不教也。苟可以为天下国家之用者，则无法在于学。此教之之道也。</p><p>　　所谓养之之道何也？饶之以财，约之以礼，裁之以法也。何谓饶之以财？人之情，不足于财，则贪鄙苟得，无所不至。先王知其如此，故其制禄，自庶人之在官者，其禄已足以代其耕矣。由此等而上之，每有加焉，使其足以养廉耻，而离于贪鄙之行。犹以为未也，又推其禄以及其子孙，谓之世禄。使其生也，既于父子、兄弟、妻子之养，婚姻、朋友之接，皆无憾矣；其死也，又于子孙无不足之忧焉。何谓约之以礼？人情足于财而无礼以节之，则又放僻邪侈，无所不至。先王知其如此，故为之制度。婚丧、祭养、燕享之事，服食、器用之物，皆以命数为之节，而齐之以律度量衡之法。其命可以为之，而财不足以具，则弗具也；其财可以具，而命不得为之者，不使有铢两分寸之加焉。何谓裁之以法？先王于天下之士，教之以道艺矣，不帅教则待之以屏弃远方终身不齿之法。约之以礼矣，不循礼则待之以流、杀之法。《王制》曰：「变衣服者，其君流」，《酒诰》曰：「厥或诰曰『群饮，汝勿佚。尽拘执以归于周，予其杀！』」夫群饮、变衣服，小罪也；流、杀，大刑也。加小罪以大刑，先王所以忍而不疑者，以为不如是，不足以一天下之俗而成吾治。夫约之以礼，裁之以法，天下所以服从无抵冒者，又非独其禁严而治察之所能致也。盖亦以吾至诚恳恻之心，力行而为之倡。凡在左右通贵之人，皆顺上之欲而服行之，有一不帅者，法之加必自此始。夫上以至诚行之，而贵者知避上之所恶矣，则天下之不罚而止者众矣。故曰：此养之之道也。</p><p>　　所谓取之之道者，何也？先王之取人也，必于乡党，必于痒序，使众人推其所谓贤能，书之以告于上而察之。诚贤能也，然后随其德之大小、才之高下而官使之。所谓察之者，非专用耳目之聪明，而私听于一人之口也。欲审知其德，问以行；欲审知其才，问以言。得其言行，则试之以事。所谓察之者，，试之以事是也。虽尧之用舜，亦不过如此而已，又况其下乎？若夫九州之大，四海之远，万官亿丑之贱，所须士大夫之才则众矣，有天下者，又不可以一二自察之也，又不可以偏属于一人，而使之于一日二日之间考试其行能而进退之也。盖吾已能察其才行之大者，以为大官矣，因使之取其类以持久试之，而考其能者以告于上，而后以爵命、禄秩予之而已。此取之之道也。</p><p>　　所谓任之之道者，何也？人之才德，高下厚薄不同，其所任有宜有不宜。先王知其如此，故知农者以为后稷，知工者以为共工。其德厚而才高者以为之长。德薄而才下者以为之佐属。又以久于其职，则上狃习而知其事，下服驯而安其教，贤者则其功可以至于成，不肖者则其罪可以至于着，故久其任而待之以考绩之法。夫如此，故智能才力之士，则得尽其智以赴功，而不患其事之不终，其功之不就也。偷惰苟且之人，虽欲取容于一时，面顾戮辱在其后，安敢不勉乎！若夫无能之人，固知辞避而去矣。居职任事之日久，不胜任之罪，不可以幸而免故也。彼且不敢冒而知辞避矣，尚何有比周、谗谄、争进之人乎？取之既已详，使之既已当，处之既已久，至其任之也又专焉，而不一二以法束缚之，而使之得行其意，尧、舜之所以理百官而熙众工者，以此而已。书曰：「三载考绩，三考，黜陟幽明。」此之谓也。然尧、舜之时，其所黜者则闻之矣，盖四凶是也。其所陟者，则皋陶、稷、契皆终身一官而不徙。盖其所谓陟者，特加之爵命、禄赐而已耳。此任之之道也。</p><p>　　夫教之、养之、取之、任之之道如此，而当时人君，又能与其大臣，悉其耳目心力，至诚恻怛，思念而行之，此其人臣之所以无疑，而于天下国家之事，无所欲为而不得也。</p><p>　　方今州县虽有学，取墙壁具而已，非有教导之官，长育人才之事也。唯太学有教导之官，而亦未尝严其选。朝廷礼乐刑政之事，未尝在于学。学者亦漠然自以礼乐刑政为有司之事，而非</p><p>　　己所当知也。学者之所教，讲说章句而已。讲说章句，固非古者教人之道也。而近岁乃始教之以课试之文章。夫课试之文章，非博诵强学穷日之力则不能。及其能工也，大则不足以用天下国家，小则不足以为天下国家之用。故虽白首于庠序，穷日之力以帅上之教，及使之从政，则茫然不知其方者，皆是也。盖今之教者，非特不能成人之才而已，又从而困苦毁坏之，使不得成才者，何也？夫人之才，成于专而毁于杂。故先王之处民才，处工于官府，处农于畎亩，处商贾于肆，而处士于庠序，使各专其业而不见异物，惧异物之足以害其业也。所谓士者，又非特使之不得见异物而已，一示之以先王之道，而百家诸子之异说，皆屏之而莫敢习者焉。今士之所宜学者，天下国家之用也。今悉使置之不教，而教之以课试之文章，使其耗精疲神，穷日之力以从事于此。及其任之以官也，则又悉使置之，而责之以天下国家之事。夫古之人，以朝夕专其业于天下国家之事，而犹才有能有不能，今乃移其精神，夺其日力，以朝夕从事于无补之学，及其任之以事，然后卒然责之以为天下国家之用，宜其才之足以有为者少矣。臣故曰：非特不能成人之才，又从而困苦毁坏之，使不得成才也。又有什害者，先王之时，士之所学者，文武之道也。士之才，有可以为公卿大夫，有可以为士。其才之大小、宜不宜则有矣，至于武事，则随其才之大小，未有不学者也。故其大者，居则为六官之卿，出则为六军之将也；其次则比、闾、族、党之师，亦皆卒、两、师、旅之帅也。故边疆、宿卫，皆得士大夫为之，而小人不得奸其任。今之学者，以为文武异事，吾知治文事而已，至于边疆、宿卫之任，则推而属之于卒伍，往往天下奸悍无赖之人。苟其才行足以自托于乡里者，未有肯去亲戚而从召募者也。边疆、宿卫，此乃天下之重任，而人主之所当慎重者也。故古者教士，以射、御为急，其他伎能，则视其人才之所宜，而后教之，其才之所不能，则不强也。至于射，则为男子之事。苟人之生，有疾则已，苟无疾，未有去射而不学者也。在庠序之间，固常从事于射也。有宾客之事则以射，有祭祀之事则以射，别士之行同能偶则以射，于礼乐之事，未尝不寓以射，而 射亦未尝不在于礼乐、祭祀之间也。易曰：「弧矢之利，以威天下。」先王岂以射为可以习揖让之仪而已乎？固以为射者武事之尤大，而威天下、守国家之具也。居则以是习礼乐，出则以是从战伐。士既朝夕从事于此而能者众，则边疆、宿卫之任，皆可以择而取也。夫士尝学先王之道，其行义尝见推于乡党矣，然后因其才而托之以边疆、宿卫之士，此古之人君，所以推干戈以属之人，而无内外之虞也。今乃以夫天下之重任，人主所当至慎之选，推而属之奸悍无赖，才行不足自托于乡里之人，此方今所以諰諰然常抱边疆之忧，而虞宿卫之不足恃以为安也。今孰不知边疆、宿卫之士不足恃以为安哉？顾以为天下学士以执兵为耻，而亦未有能骑射行阵之事者，则非召募之卒伍，孰能任其事者乎？夫不严其教，高其选，则士之以执兵为耻，而未尝有能骑射行阵之事，固其理也。凡此皆教之非其道也。</p><p>　　方今制禄，大抵皆薄。自非朝廷侍从之列，食口稍众，未有不兼农商之利而能充其养者也。其下州县之吏，一月所得，多者钱八九千，少者四五千，以守选、待除、守阙通之，盖六七年而后得三年之禄，计一月所得，乃实不能四五千，少者乃实不能及三四千而已。虽厮养之给，亦窘于此矣，而其养生、丧死、婚姻、葬送之事，皆当出于此。夫出中人之上者，虽穷而失为君子；出中人以下者，虽泰而不失为小人。唯中人不然，穷则为小人，泰则为君子。计天下之士，出中人之上下者，千百而无十一，穷而为小人，泰而为君子者，则天下皆是也。先王以为众不可以力胜也，故制行不以己，而以中人为制，所以因其欲而利道之，以为中人之所能守，则其志可以行乎天下，而推之后世。以今之制禄，而欲士之无毁廉耻，盖中人之所不能也。故今官大者，往往交赂遗、营赀产，以负贪污之毁；官小者，贩鬻、乞丐、无所不为。夫士已尝毁廉耻以负累于世矣，则其偷堕取容之意起，而矜奋自强之小息，则职业安得而不弛，治道何从而兴乎？又况委法受赂，侵牟百姓者，往往而是也。此所谓不能饶之以财也。</p><p>　　婚丧、奉养、服食、器用之物，皆无制度以为之节，而天下以奢为荣，以俭为耻。苟其财之可以具，则无所为而不得，有司既不禁，而人又以此为荣。苟其财不足，而不能自称于流俗，则其婚丧之际，往往得罪于族人婚姻，而人以为耻矣。故富者贪而不知止，贫者则强勉其不足以追之。此士之所以重困，而廉耻之心毁也。凡此所谓不能约之以礼也。</p><p>　　方今陛下躬行俭约，以率天下，此左右通贵之臣所亲见。然而其闺门之内，奢靡无节，犯上之所恶，以伤天下之教者，有已甚者矣。未闻朝廷有所放绌，以示天下。昔周之人，拘群饮而被之以杀刑者，以为酒之末流生害，有至于死者众矣，故重禁其祸之所自生。重禁祸之所自生，故其施刑极省，而人之抵于祸败者少矣。今朝廷之法所尤重者，独贪吏耳。重禁贪吏，而轻奢靡之法，此所谓禁其末而弛其本。然而世之识者，以为方今官冗，而县官财用已不足以供之，其亦蔽于理矣。今之入官诚冗矣，然而前世置员盖其少，而赋禄又如此之薄，则财用之所不足，盖亦有说矣。吏禄岂足计哉？臣于财利，固未尝学，然窃观前世治财之大略矣。盖因天下之力，以生天下之财，取天下之财，以供天下之费。自古治世，未尝以不足为天下之公患也。患在治财无其道耳。今天下不见兵革之具，而元元安土乐业，人致其力，以生天下之财，然而公私尝以困穷为患者，殆亦理财未得其道，而有司不能度世之宜而通其变耳。诚能理财以其道，而通其变，臣虽愚，固知增吏禄不足以伤经费也。方今法严令具，所以罗天下之士，可主谓密矣。然而亦尝教之以道艺，而有不帅教之刑以待之乎？亦尝约之以制度，而有不循理之刑以待之乎？亦尝任之以职事，而有不任事之刑以待之乎？夫不先教之以道艺，诚不可以诛其不帅教；不先约之以制度，诚不可以诛其不循理；不先任之以职事，诚不可以诛其不任事。此三者，先王之法所先急也，今皆不可得诛，而薄物细故，非害治之急者，为之法禁，月异而岁不同，为束者至于不可胜记，又况能一二避之而无犯者乎？此法令所以滋而不行，小人有幸而免者，君子有不幸而及者焉。此所谓不能裁之以刑也。凡此皆治之非其道也。</p><p>　　方今取士，强记博诵而略通于文辞，谓之茂才异等、贤良方正。茂才异等、贤良方正者，公卿之选也。记不必强，诵不必博，略通于文辞，而又尝学诗赋，则谓之进士。进士之高者，亦公卿之选也。夫此二科所得之技能，不足以为公卿，不待论而后可知。而世之议者，乃以为吾常以此取天下之士，而才之可以为公卿者，常出于此，不必法古之取人然后得士也。其亦蔽于理矣。先王之时，尽所以取人之道，犹惧贤者之难进，而不肖者之杂于其间也。今悉废先王所以取士之道，而驱天下之才士，悉使为贤良、进士，则士之才可以为公卿者，固宜为贤良、进士，而贤良、进士亦固宜有时而得才之可以为公卿者也。然而不肖者，苟能雕虫篆刻之学，以此进至乎公卿，才之可以为公卿者，困于无补之学，而以此绌死于岩野，盖十八九矣。夫古之人有天下者，其所慎择者，公卿而已。公卿既得其人，因使推其类以聚于朝迁，则百司庶府，无不得其人也。今使不肖之人，幸而至乎公卿，因得推其类聚之朝廷，此朝廷所以多不肖之人，而虽有贤智，往往困于无助，不得行其意也。且公卿之不肖，既推其类以聚于朝廷，朝廷之不肖，又推其类以备四方之任使；四方之任使者，又各推其不肖以布于州郡。则虽有同罪举官之科，岂足恃哉？适足以为不肖者之资而已。其次九经、五经、学究、明法之科，朝廷固已尝患其无用于世，而稍责之以大义矣。然大义之所得，未有以贤于故也。今朝廷又开明经之选，以进经术之士。然明经之所取，亦记诵而略通于文辞者，则得之矣。彼通先王之意，而可以施于天下国家之用者，顾未必得与于此选也。其次则恩泽子弟，庠序不教之以道艺，官司不考问其才能，父兄不保任其行义，而朝廷辄以官予之，而任之以事。武王数纣之罪，则曰：「官人以世。」夫官人以世，而不计其才行，此乃纣之所以乱亡之道，而治世之所无也。又其次曰流外。朝廷固已挤之于廉耻之外，而限其进之路矣，顾属之以州县之事，使之临士民之上。岂所谓以贤治不肖者乎？以臣使事之所及，一路数千里之间，州县之吏，出于流外者，往往而有，可属任以事者，殆无二三，而当防闲其奸者，皆是也。盖古者有贤不肖之分，而无流品之别。故孔子之圣，而尝为季氏吏，盖虽为吏，而亦不害其为公卿。及后世有流品之别，则凡在流外者，其所成立，固尝自置于廉耻之外，而无高人之意矣。夫以近世风俗之流靡，自虽士大夫之才，势足以进取，而朝廷尝奖之以礼义者，晚节末路，往往怵而为奸，况又其素所成立，无高人之意，而朝廷固已挤之于廉耻之外，限其进取者乎？其临人亲职，放僻邪侈，固其理也。至于边疆、宿卫之选，则臣固已言其失矣。凡此皆取之非其道也。</p><p>　　方今取之既不以其道，至于任人，又不问其德之所宜，而问其出身之后先，不论其才之称否，而论其历任之多少。以文学进者，且使之治财。已使之治财矣，又转而使之典狱。已使之典狱矣，又转而使之治礼。是则一人之身，而责之以百官之所能备，宜其人才之难为也。夫责人以其所难为，则人之能为者少矣。人之能为者少，则相率而不为。故使之典礼，未尝以不知礼为忧，以今之典礼者未尝学礼故也。使之典狱，未尝以不知狱为耻，以今之典狱者，未尝学狱故也。天下之人，亦已渐渍于失教，被服于成俗，见朝廷有所任使，非其资序，则相议而讪之，至于任使之不当其才，未尝有非之者也。且在位者数徙，则不得久于其官，故上不能狃习而知其事，下不肯服驯而安其教，贤者则其功不可以及于成，不肖者则其罪不可以至于着。若夫迎新将故之劳，缘绝簿书之弊，固其害之小者，不足悉数也。设官大抵皆当久于其任，而至于所部者远，所任者重，则尤宜久于其官，而后可以责其有为。而方今尤不得久于其官，往往数日辄迁之矣。</p><p>　　取之既已不祥，使之既已不当，处之既已不久，至于任之则又不专，而又一二以法束缚之，使不得行其意，臣固知当今在位多非其人，稍假借之权，而不一二以法束缚之，则放恣而无不为。虽然，在位非其人，而恃法以为治，自古及今，未有能治者也。即使在位皆得其人矣，而一二以法束缚之，不使之得行其意，亦自古及今，未有能治者也。夫取之既已不详，使之既已不当，处之既已不久，任之又不专，而一二以法束缚之，故虽贤者在位，能者在职，与不肖而无能者，殆无以异。夫如此，故朝廷明知其贤能足以任事，苟非其资序，则不以任事而辄进之，虽进之，士犹不服也。明知其无能而不肖，苟非有罪，为在事者所劾，不敢以其不胜任而辄退之，虽退之，士犹不服也。彼诚不肖而无能，然而士不服者何也？以所谓贤能者任其事，与不肖而无能者，亦无以异故也。臣前以谓不能任人以职事，而无不任事之刑以待之者，盖谓此也。</p><p>　　夫教之、养之、取之、任之，有一非其道，则足以败乱天下之人才，又况兼此四者而有之？则在位不才、苟简、贪鄙之人，至于不可胜数，而草野闾巷之间，亦少可任之才，固不足怪。诗曰：「国虽靡止，或圣或否。民虽靡膴，或哲或谋，或肃或艾。如彼泉流，无沦胥以败。」此之谓也。</p><p>　　夫在位之人才不足矣，而闾巷草野之间，亦少可用之才，则岂特行先王之政而不得也，社稷之托，封疆之守，陛下其能久以天幸为常，而无一旦之忧乎？盖汉之张角，三十六万同日而起，而所在郡国，莫能发其谋；唐之黄巢，横行天下，而所至将吏，无敢与之抗者。汉、唐之所以亡，祸自此始。唐既亡矣，陵夷以至五代，而武夫用事，贤者伏匿消沮而不见，在位无复有知君臣之义、上下之礼者也。当是之时，变置社稷，盖甚于弈棋之易，而元元肝脑涂地，幸而不转死于沟壑者无几耳！夫人才不足，患盖如此，而方今公卿大夫，莫肯为陛下长虑后顾，为宗庙万世计，臣切惑之。昔晋武帝趣过目前，而不为子孙长远之谋，当时在位，亦皆偷合苟容，而风俗荡然，弃礼义，捐法制，上下同失，莫以为非，有识固知其将必乱矣。而其后果海内大扰，中国列于夷狄者，二百余年。伏惟三庙祖宗神灵所以付属陛下，固将为万世血食，而大庇元元于无穷也。臣愿陛下鉴汉、唐、五代之所以乱亡，惩晋武苟且因循之祸，明诏大臣，思所以陶成天下之才，虑之以谋，计之以数，为之以渐，期为合于当世之变，而无负于先王之意，则天下之人才不胜用矣。人才不胜用，则陛下何求而不得，何欲而不成哉？夫虑之以谋，计之以数，为之以渐，则成天下之才甚易也。</p><p>　　臣始读孟子，见孟子言王政之易行，心则以为诚然。及见与慎子论齐、鲁之地，以为先王之制国，大抵不过百里者，以为今有王者起，则凡诸侯之地，或千里，或五百里，皆将损之至于数十百里而后止。于是疑孟子虽贤，其仁智足以一天下，亦安能毋劫之以兵革，而使数百千里之强国，一旦肯损其地之十八九，而比于先王之诸侯？至其后，观汉武帝用主父偃之策，令诸侯王地悉得推恩分其子弟，而汉亲临定其号名，辄别属汉。于是诸侯王之子弟，各有分土，而势强地大者，卒以分析弱小。然后知虑之以谋，计之以数，为之以渐，则大者固可使小，强者固可使弱，而不至乎倾骇变乱败伤之衅。孟子之言不为过。又况今欲改易更革，其势非若孟子所为之难也。臣故曰：虑之以谋，计之以数，为之以渐，则其为什易也。</p><p>　　然先王之为天下，不患人之不为，而患人之不能，不患人之不能，而患己之不勉。何谓不患人之不为，而患人之不能？人之情所愿得者，善行、美名、尊爵、厚利也，而先王能操之以临天下之士。天下之士，有能遵之以治者，则悉以其所愿得者以与之。士不能则已矣，苟能，则孰肯舍其所愿得，而不自勉以为才？故曰：不患人之不为，患人之不能。何谓不患人之不能，而患己之不勉？先王之法，所以待人者尽矣，自非下愚不可移之才，未有不能赴者也。然而不谋之以至诚恻怛之心，亦未有能力行而应之者。故曰：不患人之不能，而患己之不勉。陛下诚有意乎成天下之才，则臣愿陛下勉之而已。</p><p>　　臣又观朝廷异时欲有所施为变革，其始计利害未尝熟也，顾一有流俗侥幸之人不悦而非之，则遂止而不敢为。夫法度立，则人无独蒙其幸者，故先王之政，虽足以利天下，而当其承弊坏之后，侥幸之时，其创法立制，未尝不艰难也。以其创法立制，而天下侥幸之人亦顺悦以趋之，无有龃龉，则先王之法，至今存而不废矣。惟其创法立制之艰难，而侥幸之人不肯顺悦而趋之，故古之人欲有所为，未尝不先之以征诛，而后得其意。诗曰：「是伐是肆，是绝是忽，四方以无拂。」此言文王先征诛而后得意于天下也。夫先王欲立法度，以变衰坏之俗而成人之才，虽有征诛之难，犹忍而为之，以为不若是，不可以有为也。及至孔子，以匹夫游诸侯，所至则使其君臣捐所习，逆所顺，强所劣，憧憧如也，卒困于排逐。然孔子亦终不为之变，以为不如是，不可以有为。此其所守，盖与文王同意。夫在上之圣人，莫如文王，在下之圣人，莫如孔子，而欲有所施为变革，则其事盖如此矣。今有天下之势，居先王之位，创立法制，非有征诛之难也。虽有侥幸之人不悦而非之，固不胜天下顺悦之人众也。然而一有流俗侥幸不悦之言，则遂止而不敢为者，惑也。陛下诚有意乎成天下之才，则臣又愿断之而已。</p><p>　　夫虑之以谋，计之以数，为之以渐，而又勉之以成，断之以果，然而犹不能成天下之才，则以臣所闻，盖未有也。</p><p>　　然臣之所称，流俗之所不讲，而今之议者以谓迂阔而熟烂者也。窃观近世士大夫所欲悉心力耳目以补助朝廷者有矣。彼其意，非一切利害，则以为当世所不能行。士大夫既以此希世，而朝廷所取于天下之士，亦不过如此。至于大伦大法，礼义之际，先王之所力学而守者，盖不及也。一有及此，则群聚而笑之，以为迂阔。今朝廷悉心于一切之利害，有司法令于刀笔之间，非一日也。然其效可观矣。则夫所谓迂阔而熟烂者，惟陛下亦可以少留神而察之矣。昔唐太宗贞观之初，人人异论，如封德彝之徒，皆以为非杂用秦、汉之政，不足以为天下。能思先王之事，开太宗者，魏郑公一人尔。其所施设，虽未能尽当先王之意，抑其大略，可谓合矣。故能以数年之间，而天下几致刑措，中国安宁，夷蛮顺服，自三王以来，未有如此盛时也。唐太宗之初，天下之俗，犹今之世也，魏郑公之言，固当时所谓迂阔而熟烂者也，然其效如此。贾谊曰：「今或言德教之不如法令，胡不引商、周、秦、汉以观之？」然则唐太宗事亦足以观矣。</p><p>　　臣幸以职事归报陛下，不自知其驽下无以称职，而敢及国家之大体者，诚以臣蒙陛下任使，而当归报。窃谓在位之人才不足，而无以称朝廷任使之意，而朝廷所以任使天下之士者，或非其理，而士不得尽其才，此亦臣使事之所及，而陛下之所宜先闻者也。释此一言，而毛举利害之一二，以污陛下之聪明，而终无补于世，则非臣所以事陛下惓惓之义也。伏惟陛下详思而择其中，天下幸甚！</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="译文"><a href="#译文" class="headerlink" title="译文"></a>译文</h1>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;li&gt;百度百科&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="Literature" scheme="https://zhang21.github.io/categories/Literature/"/>
    
    
      <category term="古文" scheme="https://zhang21.github.io/tags/%E5%8F%A4%E6%96%87/"/>
    
      <category term="政论文" scheme="https://zhang21.github.io/tags/%E6%94%BF%E8%AE%BA%E6%96%87/"/>
    
      <category term="王安石" scheme="https://zhang21.github.io/tags/%E7%8E%8B%E5%AE%89%E7%9F%B3/"/>
    
  </entry>
  
  <entry>
    <title>治安疏</title>
    <link href="https://zhang21.github.io/2019/02/10/%E6%B2%BB%E5%AE%89%E7%96%8F/"/>
    <id>https://zhang21.github.io/2019/02/10/治安疏/</id>
    <published>2019-02-10T12:51:11.000Z</published>
    <updated>2019-02-11T01:20:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li><li>百度百科</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>　　海瑞（1514－1587），字汝贤，号刚峰，海南海口人，明代著名的政治家，以刚直不阿，清正廉明著称于世，被世人誉为“海青天”。</p><p>　　《治安疏》是明代名臣海瑞写给明世宗朱厚熜的一篇奏疏。在这篇著名的奏疏中，海瑞大胆直言当时官场的弊端和统治阶级的罪责，同时劝谏统治者改正过失，实行改革，达到“天下大治”的目的。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h1><p>　　户部云南清吏司主事臣海瑞谨奏：为直言天下第一事，以正君道、明臣职，求万世治安事。</p><p>　　君者，天下臣民万物之主也。惟其为天下臣民万物之主，责任至重，凡民生利瘼一有所不闻，将一有所不得知而行，其任为不称。是故养君之道，宜无不备，而以其责寄臣工，使尽言焉。臣工尽言而君道斯称矣。昔之务为容悦、谀顺曲从，致使实祸蔽塞，主不上闻焉，无足言矣。过为计者，则又曰：“君子危明主，忧治世。” 夫世则治矣，以不治忧之；主则明矣，以不明危之。毋乃使之反求眩瞀，失趋舍矣乎？非通论也。</p><p>　　臣受国恩厚矣，请执有犯无隐之义。美曰美，不一毫虚美; 过曰过，不一毫讳过。不容悦，不过计，披肝胆为陛下言之。汉贾谊陈政事于文帝曰：“进言者皆曰天下已安已治矣，臣独以为未也。曰安且治者，非愚则谀。”夫文帝、汉贤君也，贾谊非苛责备也。文帝性仁类柔，慈恕恭俭，虽有近民之美；优游退逊，尚多怠废之政。不究其弊所不免，概以安且治当之，愚也；不究其才所不能，概以致安治颂之，谀也。陛下自视于汉文帝何如？陛下天质英断，睿识绝人，可为尧、舜，可为禹、汤、文、武，下之如汉宣帝之励精，光武之大度，唐太宗之英武无敌，宪宗之专志平僭乱，宋仁宗之仁恕，举一节可取者，陛下优为之。即位初年，刬除积弊，焕然与天下更始。举其略，如箴敬一以养心，定冠履以辨分，除圣贤土木之像，夺宦官内外之权，元世祖毁不与祀，祀孔子推及所生，天下忻忻然以大有作为仰之。识者谓辅相得人，太平指日可期也。非虚语也，高汉文帝远甚。然文帝能充其仁顺之性，节用爱人，吕祖谦称其能尽人之才力，诚是也。一时天下虽未可尽以治安予之，而贯朽粟陈，民少康阜，三代下称贤君焉。陛下则锐精未久，妄念牵之而去矣，反刚明而错用之，谓遥兴可得而一意修玄。富有四海，不曰民之膏脂在是也，而侈兴土木。二十余年不视朝，纲纪弛矣；数行推广事例，名爵滥矣。二王不相见，人以为薄于父子；以猜疑诽谤戮辱臣下，人以为薄于君臣，乐西苑而不返宫，人以为薄于夫妇。天下吏贪将弱，民不聊生，水旱靡时，盗贼滋炽，自陛下登极初年，亦有之而未什也。今赋役增常，万方则效，陛下破产礼佛日甚，室如悬磬，十余年来极矣。天下因即陛下改元之号，而臆之曰：“嘉靖者，言家家皆净而无财用也。”迩者，严嵩罢黜，世蕃极刑，差快人意，一时称清时焉。然严嵩罢相之后，犹之严嵩未相之先而已，非大清明世界也，不及汉文远甚。天下之人不直陛下久矣！内外臣工之所知也。知之不可谓愚，诗云：“衮职有阙，惟仲山甫补之。”今日所赖以弼棐匡救，格非而归之正，诸臣责也，岂以圣人而绝无过举哉？古昔设官，亮采惠畴足矣，不必责之以谏。保氏掌谏王恶，不必设也。木绳金砺，圣贤不必言之也。今乃建醮修斋，相率进香，天桃天药，相率表贺。建 宫筑室，工部极力经营；取香觅宝，户部差求四出。陛下误举，诸臣误顺，无一人为陛下一正言焉。都俞吁咈之风，陈善闭邪之义，邈无闻矣，谀之什也。然愧心馁气，退有后言，以从陛下；昧没本心，以歌颂陛下；欺君之罪何如！夫天下者，陛下之家也，人未有不顾其家者。内外臣工，其官守，其言责，皆所以奠陛下之家而磐石之也。一意玄修，是陛下心之惑也；过于苛断，是陛下情之偏也。而谓陛下不顾其家，人情乎？诸臣顾身念重，得一官多以欺败、脏败、不事事败，有不足以当陛下之心者。其不然者，君心臣心偶不相值也，遂谓陛下为贱薄臣工。诸臣正心之学微，所言或不免已私，或失详审，诚如胡寅挠乱政事之说，有不足以当陛下之心者。其不然者，君意臣言偶不相值也。遂谓陛下为是已拒谏。执陛下一二事不当之形迹，臆陛下千百事之尽然，陷陛下误终不复，诸臣欺君之罪大矣。《记》曰：“上人疑则百姓惑，下难知则君长劳。”今日之谓也。为身家心与惧心合，臣职不明，臣一二事形迹说既为诸臣解之矣。求长生心与惑心合，有辞于臣，君道不正，臣请再为陛下开之。陛下之误多矣，大端在修醮，修醮所以求长生也。自古圣贤止说修身立命，止说顺受其正，盖天地赋予于人而为性命者，此尽之矣。尧、舜、禹、汤、文、武之君，圣之盛也，未能久世不终。下之亦未见方外士汉、唐、宋存至今日，使陛下得以访其术者。陶仲文，陛下以师呼之，仲文则既死矣。仲文不能长生，而陛下独何求之？至谓天赐仙桃药丸，怪妄尤甚。昔伏羲氏王天下，龙马出河，因则其文以画八卦；禹治水时，神龟负文而列于背，因而第之以成九畴。《河图》、《洛书》，实有此瑞物。泄此万古不传之秘，天不爱道而显之圣人，借圣人以开示天下，犹之日月星辰之布列而历数成焉，非虚妄事也。宋真宗获天书于干佑山，孙奭进曰：“天何言哉！岂有书也？”桃必采而得，药必工捣合而成者也。无因而至，桃、药有足行耶？天赐之者，有手执而付之耶？陛下玄修多年矣，一无所得。至今日左右奸人，逆揣陛下悬思妄念，区区桃、药导之长生，理之所无，而玄修之无益可知矣。陛下又将谓悬刑赏以督率臣下，分理有人，天下无可不治，而玄修无害矣乎？夫人幼而学，无致君泽民异事之学；壮而行，亦无致君泽民殊用之心。太甲曰：“有言逆于汝心，必求诸道；有言逊于汝志，必求诸非道。”言顺者之未必为道也。即近事观，严嵩有一不顺陛下者乎？昔为贪窃，今为逆本。梁材守官守道，陛下以为逆者也。历任有声，官户部者，至今首称之。虽近日严嵩抄没，百官有惕心焉。无用于积贿求迁，稍自洗涤。然严嵩罢相之后，犹严嵩未相之先而已。诸臣为严嵩之顺，不为梁材之执。今甚者贪求，未甚者挨日。见称于人者，亦廊庙山林，交战热中，鹘突依违，苟举故事。洁已格物，任天下重，使社稷灵长终必赖之者，未见其人焉。得非有所牵掣其心，未能纯然精白使然乎？陛下欲诸臣惟予行而莫逆也，而责之效忠，付之以翼为明听也，又欲其顺吾玄修土木之误，是股肱耳目，不为腹心卫也，而自为视听持行之用。有臣如仪衍焉，可以成得志与民由之之业，无是理也。陛下诚知玄修无益，臣之改行，民之效尤，天下之不安不治由之，翻然悔悟，日视正朝，与宰辅、九卿、侍从、言官讲求天下利害，洗数十年君道之误，置其身于尧、舜、禹、汤、文、武之上；使其臣亦得洗数十年阿君之耻，置身与皋、夔、伊、傅相后先，明良喜起，都俞吁咈。内之宦官宫妾，外之光禄寺厨役、锦衣卫恩荫、诸衙门带俸，举凡无事而官多矣。上之内仓内库，下之户工部光禄寺诸厂藏段绢、粮料、珠宝、器用、木材诸物，多而积于无用，用之非所宜用亦多矣，诸臣必有为陛下言者。诸臣言之，陛下行之，此则在陛下一节省间而已。京师之一金，田野之百金也。一节省而国有余用，民有盖藏，不知其几也，而陛下何不为之？官有职掌，先年职守之正、职守之全，而未之行；今日职守之废、职守之苟且因循、不认真、不尽法，而自以为是。敦本行而端士习，止上纳以清仕途，久任吏将以责成功，练选军士以免召募，驱缁黄游食使归四民，责府州县兼举富教，使成礼俗。复屯盐本色以裕边储，均田赋丁差以苏困敝，举天下官之侵渔、将之怯懦、吏之为奸，刑之无少姑息焉。必世之仁，博厚高明悠远之业，诸臣必有为陛下言者。诸臣言之，陛下行之，此则在陛下一振作间而已。一振作而百 废具举，百弊刬绝，唐虞三代之治，粲然复兴矣。而陛下何不为之？节省之，振作之，又非有所劳于陛下也。九卿总其纲，百职分其绪，抚按科道纠率肃清于其间，陛下持大纲、稽治要而责成焉。劳于求贤，逸于任用，如天运于上而四时六气各得其序，恭已无为之道也。天地万物为一体，固有之性也。民物熙浃，薰为太和，而陛下性分中有真乐矣。可以赞天地之化育，则可以与天地参。道与天通，命由我立，而陛下性分中有真寿矣。此理之所有，可旋至而立有效者也。若夫服食不终之药，遥兴轻举，理所无者也。理之所无而切切然散爵禄、竦精神，玄修求之，悬思凿想，系风捕影，终其身如斯而已矣。求之其可得乎！</p><p>　　君道不下在、臣职不明，此天下第一事也。于此不言，更复何言？大臣持禄而外为谀，小臣畏罪而面为顺，陛下诚有不得知而改之行之者，臣每恨焉。是以昧死竭惓惓为陛下一言之。一反情易向之间，而天下之治与不治，民物之安与不安，于焉决焉。伏惟陛下留神，宗社幸甚，天下幸甚。臣不胜战栗恐惧之至，为此具本亲赍，谨具奏闻。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="译文"><a href="#译文" class="headerlink" title="译文"></a>译文</h1><p>　　户部云南清吏司主事海瑞在这里上奏：为了匡正君道，明确臣下的职责，求得万世治安，我要直陈天下第一事。</p><p>　　国君是天下臣民万物的主人，正是因为是天下臣民万物之主，所以责任重大。如果民生措置失当，就是君主没有负起责任。所以臣子就应当尽量为君主服务，忠于职守，畅所欲言。臣子尽到了自己的责任，君主的责任也才算尽到了。以前那种专图讨好，曲意逢迎，不让君主听到实际情况的人，现在用不着说他们了。</p><p>　　危言耸听的人或许会说：君子总是想法多，即使遇到贤明的君主，政治清明的时代，也常常居安思危，忧虑重重，只怕反而让人思维混乱，搞不清方向。这种说法不符合现在的情况！</p><p>　　臣蒙受国恩，宁可直言得罪也不想说假话，好的就是好的，坏的就是坏的，一丝一毫都不敢隐瞒。我不为讨上面的欢心，也不计较得失，今天披沥肝胆，掏出真心，对陛下您说几句实话。</p><p>　　汉代名臣贾谊曾和文帝这样说：“下面进言的人总是说：天下已经大治，臣独以为还没有。那些说天下已安已治的人，不是愚昧无知就是阿谀逢迎。”文帝算是汉代的贤君了，贾谊也不是对文帝要求过高。汉文帝的品质作风是好的，他有爱民的美德，为人也慈和俭朴，从容谦逊，但缺点在于游于玄老，不专事于政务，有许多政事都被耽误了，没有办好。假使臣下看不到这些弊病，一味认为天下已安已治，这就是愚昧无知。假使臣下看不到文帝的才能毕竟有限，一味用已安已治的话来歌颂他，这就是阿谀奉承。<br>　　陛下自视和汉文帝比较起来怎么样呢？陛下天资英断，睿识绝人，具有成为尧、舜、禹、汤、文、武这样的君王的潜力，陛下象汉宣帝一样做事努力认真，象光武帝一样为人大度，象唐太宗一样英武无敌，象唐宪宗一样能够消平各地藩镇叛乱，陛下还有宋仁宗的仁恕之德，总之象这些可取的优点，无论哪一项，您都是具有的。您即位初年，铲除积弊，明白宣示，同全国老百姓一道革新政事。举其大概吧：您作过一篇《敬一箴》，提倡规戒；改定了一些冠服制度，下令废除孔子庙里的塑像，只用木主；削弱了宦官的内外之权；将元世祖从历代帝王庙所祭牌位中剔除；在孔子庙兼祭孔子的父母。那时候天下人都很期待，认为您一定大有作为。有见识的人都认为：只要有好的臣子帮助，不需多久，天下就可太平，您一定比汉文帝要强得多。然而文帝能发扬仁恕之性，节约恭俭，体恤爱民，宋朝的吕祖谦说他善于用人，能尽人之才力。一时天下虽说不上已经大治，但国库充盈，连串钱的绳子都朽烂了，百姓安乐，财物丰足。大家公认他是夏、商、周三代以后的一位贤君。</p><p>　　陛下您立志要有作为，可是没过多久，就被杂乱的念头导引到别的地方去了。您把自己的刚强英明用到错误的地方，以为人真的能够长生不老，而一味的玄修。陛下富有四海，却不念及那都是民之脂膏，常常大兴土木，大修宫殿庙宇。陛下二十余年不上朝处理政务，导致纲纪松懈败坏。朝廷卖官买官，援用这种章程越来越滥，美其名曰推广事例，导致豪强四起，名爵泛滥。您专门和方士在一起炼丹，不与自己的儿子们相见，人们都以为您缺少父子之情。您常以猜疑诽谤戮辱臣下，人们都以为缺少君臣之礼。您整天待在西苑不回宫，人们都以为缺少夫妇之情。天下官吏贪污成风，军队弱小，水灾旱灾无时不有，民不聊生，导致流民暴乱象火烧一样，越来越盛。自陛下登基以来，前几年就这样，但还不严重，但是如今赋税徭役越来越重，各级官吏都效法朝廷，盘剥百姓无度。陛下花很多钱崇奉道教，十余年来已经做到极致了。因此，陛下改元号之时，天下人都猜想：这意思就是说“嘉靖者言家家皆净而无财用也”。</p><p>　　近来，严嵩罢相，严世蕃被处以极刑，勉强可以令人满意，一时人称天下清明。然而严嵩罢相以后的政事，不过和他作宰相以前差不多，也并不见得清明多少。陛下比汉文帝差远了。天下之人对您不满已经很久了，这内外臣工都知道。《诗经》上说：“衰职有阙，惟仲山甫补之”，意思是说宣王不能完全尽职，仲山甫能从旁补救。今日以辅助、匡正来补救、纠正错误并使一切走入正轨，正是诸位臣下的职责所在。圣人也不能不犯错误，否则古代设官，只要他做官办事就够了，不必要求他们进言劝谏，也不必设谏官，更不必说木绳金砺这类的话了。陛下修宫殿，设坛祈祷，就让群臣竞相进献香物和仙桃仙药，叫臣子进表管贺。陛下要兴建宫室，工部就极力经营；陛下要取香觅宝，户部就派人到处索取。陛下举动有误，诸臣顺从得也没道理，竟没有一个人为陛下正言。那种公开讨论对错、贡献良言，防止邪恶的做法，长久没有听到了，献媚的风气太甚。然而人们不敢直言，内心却不能不惭愧，气也不壮了，当面不敢说，却在背后议论是非，人们表面上顺从陛下，却把真心藏起来，这样为陛下歌功颂德，是多么大的欺君之罪？</p><p>　　天下者，陛下之家也，哪有不顾自己家的人呢？内外臣工都有行政职务和进言的责任，这些都是能够奠定您的家业，使它象磐石一样的稳固的基础。一意玄修，是陛下的心被妄念迷惑。过分苛刻武断，也不是您生性如此。不能就这样便断定陛下不顾其家，不合乎人情。臣子们往往为了顾及自己的身家性命，为了保住自己的乌纱帽，欺诈、贪赃、旷废职务而导致犯罪，这些人不合您的心意，是很自然的。假如不是为了上述的原因也不合您的心意，那就是您的心与臣子的心偶然不相投合啊，但也有人疑心是您看轻臣子，侮辱臣子。另外有一种人，自己的心思不正，或是为了个人的利益，或是说得不够详明正确，就象胡寅扰乱政事的奏疏那样：这些人不合您的意旨，也是很自然的。如果都不是以上的情况，君意臣意还不相符合，那就要让人疑心是不是因为陛下自以为是，不愿接受劝谏的缘故。抓住一二件这样的事，就推测您向来如此，害得您一直被人误解。《礼记》上说：“君主多疑于上，百姓就无所适从；臣子不忠于下，君主就劳苦不堪了。”说的就是今天这种情况。</p><p>　　臣子保身家的私心和怕触怒君主的心相结合，因而模糊了自己的职责，我已经举出一二件事例替他们作过分析了。君主求长生的妄念和迷惑不明相结合，就使臣子们心怀不满；陛下有失为君之道，请允许我再加以分析。 陛下的失误很多，大部分是因为修醮。修醮是为了求长生不老。古来的圣贤只不过讲求涵养道德，保养生命，顺应自然法则。天地赋予人生命，不过如此罢了。尧、舜、禹、汤、文、武都是圣人，也没有谁能长生不死。他们之后，也没有见到所谓僧道术士之人从汉、唐、宋活到今天。传给您长生法术的陶仲文，您称他为师傅，可是他自己就已经死了。仲文尚不能长生不死，陛下为什么还要求长生？至于那所谓的仙桃药丸，怪妄尤甚。伏羲氏做了天下的王，有龙马出河，于是便依据龙马的花纹画了八卦。夏禹治水时，出现神龟，就把神龟背上罗列的各种纹路排列起来，成为有关天道人事的九种法则。这些 “神物”透露了万古不传的秘密。天将天道显之于圣人，借圣人来明示天下，就像日月星辰的排列，并不虚妄。但宋真宗赵恒为了粉饰太平，听从王钦若等人的话，伪造天书，声称从天而降，他的大臣孙奭就谏言道：“上天哪里会说什么？怎么还能写书？”仙桃是从树上采摘下来的，仙药由人工捣制而成。你说它们能有什么天意？能起什么作用？天赐之物，难道能让人手里拿着给您？陛下玄修多年，一无所得。到今日，左右奸人迎合陛下玄修妄念，以为区区桃药就能让人长生不老，世上哪有这样的道理？玄修之无益可知矣。</p><p>　　陛下您莫非认为只要抓住刑和赏的权柄，就不怕无人办事，天下就可以治好，修道便没有什么害处了吗？那些阿谀逢迎的臣子，年轻时候就没有学到“致君泽民” （把君主辅佐好，使百姓得到好处）的特别本领和修养，壮年做官也没有“致君泽民”的特殊抱负和愿望。〈尚书·太甲〉曰：“有言逆于汝志，必求诸道，有言逊于汝志，必求诸非道。意思是说：遇有不合自己意旨的话，要看看是否合于道理；遇有顺从自己意旨的话，要看看是否不合道理。顺从旨意的未必就是有道理的。从近些年来看：严嵩哪有一处不是顺着陛下您的意思？然而严党过去是贪权窃利的祸害，今天是忤逆乱政的根源。象梁材这样的人谨守职责，历来做官有声誉有操守，以正直不阿著称，却被陛下认为大逆不道。虽然从严嵩抄家以后，百官有所畏惧，知道不能再以贿赂谋求升迁，稍改以前的恶习。然而严嵩罢相之后的局面也和严嵩做丞相之前没什么两样。百官仍然只情愿学严嵩的顺从，不肯学梁材的正直不阿。现在坏人还是贪求无厌，一般人也只是得过且过，混混日子。即使是好人，也不过是在做官和退隐之间犹豫不决，含糊敷衍，奉行做事罢了。而那种洁身自爱、探研真理，对天下负有责任，能够肩负国运，维护长治久安的人，却一个也没有发现。不就是因为好人受到牵制，不能尽忠做事，才弄到今天这个地步吗？您既要人顺从圣意，又要人尽忠；既要人充当助手和耳目，又要人顺从您做那些修道和兴修宫殿庙宇的错误事情：这就象不用四肢耳目去保卫心腹，而由心腹自己去执行看、听、拿东西和走路的任务一样。照此下去，您即便有了象张仪和公孙衍那样能干的臣子，要想成就与百姓同享太平的事业，那也是办不到的。</p><p>　　如果您承认修道有害无益，那么臣子的转变，百姓的祸福，天下的安危都将由此而不同，所以您应当立即悔悟，每日上朝理政，与宰辅、九卿、侍从、言官一起言说天下利害，洗刷数十年君道之误，那样就能置身于尧、舜、禹、汤、文、武这样的明君之中，也使得臣下能够洗刷数十年谄媚君主之耻，让他们置身于皋陶、伊、傅这样的贤臣之列，君臣便可互相勉励、互相敬重。内廷中的宦官宫女，外廷中光禄寺厨房的仆役，锦衣卫中那些受惠于祖先恩荫的人，以及各个衙门里那些额外的冗员，无事可干而为官的人太多了。皇家的仓库里，户部、工部以及光禄寺等衙门里，缎、绢、粮料、珠宝、器物、木材等东西很多，堆积在那里也无用，用了也用的不是地方，白白浪费了很可惜。臣子们进谏，您采纳实行，对您说来只不过动一动节省的念头罢了。京师里的一块金子，到了田野百姓那里抵得上一百块金子用。您稍稍节省一点，国库便有余用，老百姓则有了储蓄，好处真不知有多少啊，而陛下为何不这样做呢？</p><p>　　今天官吏设置不全，办事因循苟且，敷衍塞责，不守法纪，却还自以为不错。应该督促遵守基本的道德来端正官员们的行为，停止用钱买官那一套来理清仕途；让文武官员安于其位，责成他们做出成绩来；平常就练选军士以免打仗了临时召募百姓；让那些吃白食的和尚道士回家，回到士、农、工、商的行业里；府州县地方官要生计和教化并重，树立好的礼俗规范；屯田、运盐应该恢复征收实物，来充实边防军队的储备；按地亩交粮，按人口应役，以便恢复老百姓的元气；检举天下官员的贪污勒索行为，让那些贪赃枉法的人心生怯懦，按照刑律处罚他们，毫不宽容。如此以来，便是仁政，几十年之后才能收效，与天地并存的伟大功业便可成就了。这样的事由诸臣提议，陛下执行，也就在陛下一振作间而已。一振作而诸废具举，百弊铲绝，象唐、虞三代那样光明灿烂的大治便可复兴矣，而陛下为什么不实行呢？</p><p>　　陛下只要稍事节省和振作就行了，又不是要您多么劳心劳神。九卿掌握大政方针，百官承担具体的职责，巡抚、巡按、六科给事中等纠举肃清，维护风气，陛下考核政纲的实施情况，督促他们做出成绩来。努力去找贤才，任用他们办事，自己就省力了。就像天运于上，四时六气各得其序，君主只要自己有德，感化臣民，不必亲自动手管理一切。天地万物为一体，自有它的道理。百姓安居乐业，形成一片祥和气氛，而陛下自然能够感到真正的快乐和价值。天地是化生万物的，人也有帮助天地化生的能力，可以与天地并列而为“三才”。道与天通，命运可以由我们自己掌握，而陛下自然能够享受真寿。这是真正的道理，转身就能做到，立刻就能见效。要是依旧去服食什么长生不死之药，巴望着能成仙升天，不是道理所在。那么做只能匆忙的散爵禄，让精神徒然的紧张，玄修求长生，是捕风捉影的空想，陛下一辈子求之，究竟得到没得到呢？</p><p>　　君道不正，臣职不明，是天下第一大事。于此不言，更复何言？大臣为保乌纱帽而阿谀奉承，小臣害怕获罪表面顺从，陛下有错误却不知道，不能改正不能执行，臣每想到这里便痛心疾首。所以今天便冒死竭忠，诚恳的向陛下进言。望陛下能够改变心思，转换方向，而天下之治与不治，民物之安与不安都取决于您，若陛下真能采纳，是我宗庙、社稷、国家的幸运，是天下黎民百姓的幸运！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;li&gt;百度百科&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="Literature" scheme="https://zhang21.github.io/categories/Literature/"/>
    
    
      <category term="古文" scheme="https://zhang21.github.io/tags/%E5%8F%A4%E6%96%87/"/>
    
      <category term="政论文" scheme="https://zhang21.github.io/tags/%E6%94%BF%E8%AE%BA%E6%96%87/"/>
    
      <category term="海瑞" scheme="https://zhang21.github.io/tags/%E6%B5%B7%E7%91%9E/"/>
    
  </entry>
  
  <entry>
    <title>治安策</title>
    <link href="https://zhang21.github.io/2019/02/10/%E6%B2%BB%E5%AE%89%E7%AD%96/"/>
    <id>https://zhang21.github.io/2019/02/10/治安策/</id>
    <published>2019-02-10T12:27:11.000Z</published>
    <updated>2019-02-11T01:19:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>　　贾谊（前200—前168年），汉族，洛阳（今河南洛阳东）人，西汉初年著名政论家、文学家，世称贾生。贾谊少有才名，十八岁时，以善文为郡人所称。文帝时任博士，迁太中大夫，受大臣周勃、灌婴排挤，谪为长沙王太傅，故后世亦称贾长沙、贾太傅。三年后被召回长安，为梁怀王太傅。梁怀王坠马而死，贾谊深自歉疚，抑郁而亡，时仅33岁。司马迁对屈原、贾谊都寄予同情，为二人合传，后世因而往往把贾谊与屈原并称为“屈贾”。贾谊著作主要有散文和辞赋两类，散文的主要文学成就是政论文，评论时政，风格朴实峻拔，议论酣畅，鲁迅称之为“西汉鸿文”，代表作有《过秦论》《论积贮疏》《陈政事疏》等。其辞赋皆为骚体，形式趋于散体化，是汉赋发展的先声，以《吊屈原赋》《鵩鸟赋》最为著名。</p><p>　　《治安策》是西汉文学家贾谊创作的一篇政论文。这篇论文论及了文帝时潜在或明显的多种社会危机，包括“可为痛哭者一，可为流涕者二，可为长叹息者六”等众多严重问题，涉及中央与地方诸侯之间、汉庭与北方异族之间，以及社会各阶层之间的种种矛盾，针对这令人忧心的一切，贾谊富有针对性地一一指明相应对策和补救措施。这篇论文势忽峻忽缓、首尾相衔，大量采用夹叙夹议，还在议论说理的同时，不失时机地运用文学笔法。</p><p>　　西汉前期社会存在着三大矛盾：其一是匈奴为代表的边境少数民族与汉王朝之间的矛盾；其二是地方诸侯王的割据势力与中央政府之间的矛盾；其三是广大农民和地主、大工商业者的矛盾。汉文帝时期，天下大势已定，这些社会矛盾虽然尚未激化到即将公开破裂的程度，但却在酝酿并渐趋于激化的过程之中。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h1><p>　　臣窃惟事势，可为痛哭者一，可为流涕者二，可为长太息者六，若其它背理而伤道者，难遍以疏举。进言者皆曰天下已安已治矣，臣独以为未也。曰安且治者，非愚则谀，皆非事实知治乱之体者也。夫抱火厝之积薪之下而寝其上，火未及燃，因谓之安，方今之势，何以异此！本末舛逆，首尾衡决，国制抢攘，非甚有纪，胡可谓治！陛下何不壹令臣得孰数之于前，因陈治安之策，试详择焉！</p><p>　　夫射猎之娱，与安危之机孰急？使为治，劳智虑，苦身体，乏钟鼓之乐，勿为可也。乐与今同，而加之诸侯轨道，兵革不动，民保首领，匈奴宾服，四荒乡风，百姓素朴，狱讼衰息，大数既得，则天下顺治，海内之气清和咸理，生为明帝，没为明神，名誉之美，垂于无穷。礼祖有功而宗有德，使顾成之庙称为太宗，上配太祖，与汉亡极。建久安之势，成长治之业，以承祖庙，以奉六亲，至孝也；以幸天下，以育群生，至仁也；立经陈纪，轻重同得，后可以为万世法程，虽有愚幼不肖之嗣，犹得蒙业而安，至明也。以陛下之明达，因使少知治体者得佐下风，致此非难也。其具可素陈于前，愿幸无忽。臣谨稽之天地，验之往古，按之当今之务，日夜念此至孰也，虽使禹舜复生，为陛下计，亡以易此。</p><p>　　夫树国固必相疑之势，下数被其殃，上数爽其忧，甚非所以安上而全下也。今或亲弟谋为东帝，亲兄之子西乡而击，今吴又见告矣。天子春秋鼎盛，行义未过，德泽有加焉，犹尚如是，况莫大诸侯，权力且十此者虖！</p><p>　　然而天下少安，何也？大国之王幼弱未壮，汉之所置傅相方握其事。数年之后，诸侯之王大抵皆冠，血气方刚，汉之傅相称病而赐罢，彼自丞尉以上偏置私人，如此，有异淮南、济北之为邪！此时而欲为治安，虽尧舜不治。</p><p>　　黄帝曰：「日中必熭，操刀必割。」今令此道顺而全安，甚易，不肯早为，已乃堕骨肉之属而抗刭之，岂有异秦之季世虖！夫以天子之位，乘今之时，因天之助，尚惮以危为安，以乱为治，假设陛下居齐桓之处，将不合诸侯而匡天下乎？臣又以知陛下有所必不能矣。假设天下如曩时，淮阴侯尚王楚，黥布王淮南，彭越王梁，韩信王韩，张敖王赵，贯高为相，卢绾王燕，陈豨在代，令此六七公者皆亡恙，当是时而陛下即天子位，能自安乎？臣有以知陛下之不能也。天下淆乱，高皇帝与诸公并起，非有仄室之势以豫席之也。诸公幸者，乃为中涓，其次廑得舍人，材之不逮至远也。高皇帝以明圣威武即天子位，割膏腴之地以王诸公，多者百余城，少者乃三四十县，德至渥也，然其后十年之间，反者九起。陛下之与诸公，非亲角材而臣之也，又非身封王之也，自高皇帝不能以是一岁为安，故臣知陛下之不能也。然尚有可诿者，曰疏，臣请试言其亲者。假令悼惠王王齐，元王王楚，中子王赵，幽王王淮阳，共王王梁，灵王王燕，厉王王淮南，六七贵人皆亡恙，当是时陛下即位，能为治虖？臣又知陛下之不能也。若此诸王，虽名为臣，实皆有布衣昆弟之心，虑亡不帝制而天子自为者。擅爵人，赦死罪，甚者或戴黄屋，汉法令非行也。虽行不轨如厉王者，令之不肯听，召之安可致乎！幸而来至，法安可得加！动一亲戚，天下圜视而起，陛下之臣虽有悍如冯敬者，适启其口，匕首已陷其匈矣。陛下虽贤，谁与领此？故疏者必危，亲者必乱，已然之效也。其异姓负强而动者，汉已幸胜之矣，又不易其所以然。同姓袭是迹而动，既有征矣，其势尽又复然。殃旤之变，未知所移，明帝处之尚不能以安，后世将如之何！</p><p>　　屠牛坦一朝解十二牛，而芒刃不顿者，所排击剥割，皆众理解也。至于髋髀之所，非斤则斧。夫仁义恩厚，人主之芒刃也；权势法制，人主之斤斧也。今诸侯王皆众髋髀也，释斤斧之用，而欲婴以芒刃，臣以为不缺则折。胡不用之淮南、济北？势不可也。</p><p>　　臣窃迹前事，大抵强者先反。淮阴王楚最强，则最先反；韩信倚胡，则又反；贯高因赵资，则又反；陈豨兵精，则又反；彭越用梁，则又反；黥布用淮南，则又反；卢绾最弱，最后反。长沙乃在二万五千户耳，功少而最完，势疏而最忠，非独性异人也，亦形势然也。曩令樊、郦、绛、灌据数十城而王，今虽以残亡可也；令信、越之伦列为彻侯而居，虽至今存可也。然则天下之大计可知已。欲诸王之皆忠附，则莫若令如长沙王；欲臣子之勿菹醢，则莫若令如樊、郦等；欲天下之治安，莫若众建诸侯而少其力。力少则易使以义，国小则亡邪心。令海内之势如身之使臂，臂之使指，莫不制从，诸侯之君不敢有异心，辐凑并进而归命天子，虽在细民，且知其安，故天下咸知陛下之明。割地定制，令齐、赵、楚各为若干国，使悼惠王、幽王、元王之子孙毕以次各受祖之分地，地尽而止，及燕、梁它国皆然。其分地众而子孙少者，建以为国，空而置之，须其子孙生者，举使君之。诸侯之地其削颇入汉者，为徙其侯国及封其子孙也，所以数偿之：一寸之地，一人之众，天子亡所利焉，诚以定治而已，故天下咸知陛下之廉。地制壹定，宗室子孙莫虑不王，下无倍畔之心，上无诛伐之志，故天下咸知陛下之仁。法立而不犯，令行而不逆，贯高、利几之谋不生，柴奇、开章之计不萌，细民乡善，大臣致顺，故天下咸知陛下之义。卧赤子天下之上而安，植遗腹，朝委裘，而天下不乱，当时大治，后世诵圣。壹动而五业附，陛下谁惮而久不为此？</p><p>　　天下之势方病大瘇。一胫之大几如要，一指之大几如股，平居不可屈信，一二指搐，身虑亡聊。失今不治，必为锢疾，后虽有扁鹊，不能为已。病非徒瘇也，又苦𨂂盭。元王之子，帝之从弟也；今之王者，从弟之子也。惠王［之子］，亲兄子也；今之王者，兄子之子也。亲者或亡分地以安天下，疏者或制大权以逼天子，臣故曰非徒病瘇也，又苦𨂂盭。可痛哭者，此病是也。</p><p>　　天下之势方倒县。凡天子者，天下之首，何也？上也。蛮夷者，天下之足，何也？下也。今匈奴嫚娒侵掠，至不敬也，为天下患，至亡已也，而汉岁致金絮采缯以奉之。夷狄征令，是主上之操也；天子共贡，是臣下之礼也。足反居上，首顾居下，倒县如此，莫之能解，犹为国有人乎？非亶倒县而已，又类辟，且病痱。夫辟者一面病，痱者一方痛。今西边北边之郡，虽有长爵不轻得复，五尺以上不轻得息，斥候望烽燧不得卧，将吏被介胄而睡，臣故曰一方病矣。医能治之，而上不使，可为流涕者此也。</p><p>　　陛下何忍以帝皇之号为戎人诸侯，势既卑辱，而旤不息，长此安穷！进谋者率以为是，固不可解也，亡具甚矣。臣窃料匈奴之众不过汉一大县，以天下之大困于一县之众，甚为执事者羞之。陛下何不试以臣为属国之官以主匈奴？行臣之计，请必系单于之颈而制其命，伏中行说而笞其背，举匈奴之众唯上之令。今不猎猛敌而猎田彘，不搏反寇而搏畜菟，翫细娱而不图大患，非所以为安也。德可远施，威可远加，而直数百里外威令不信，可为流涕者此也。</p><p>　　今民卖童者，为之绣衣丝履偏诸缘，内之闲中，是古天子后服，所以庙而不晏者也，而庶人得以衣婢妾。白縠之表，薄纨之里，緁以偏诸，美者黼绣，是古天子之服，今富人大贾嘉会召客者以被墙。古者以奉一帝一后而节适，今庶人屋壁得为帝服，倡优下贱得为后饰，然而天下不屈者，殆未有也。且帝之身自衣皂绨，而富民墙屋被文绣；天子之后以缘其领，庶人㜸妾缘其履：此臣所谓舛也。夫百人作之不能衣一人，欲天下亡寒，胡可得也？一人耕之，十人聚而食之，欲天下亡饥，不可得也。饥寒切于民之肌肤，欲其亡为奸邪，不可得也。国已屈矣，盗贼直须时耳，然而献计者曰「毋动」，为大耳。夫俗至大不敬也，至亡等也，至冒上也，进计者犹曰「毋为」，可为长太息者此也。</p><p>　　商君遗礼义，弃仁恩，并心于进取，行之二岁，秦俗日败。故秦人家富子壮则出分，家贫子壮则出赘。借父耰鉏，虑有德色；母取箕箒，立而谇语。抱哺其子，与公并倨；妇姑不相说，则反唇而相稽。其慈子耆利，不同禽兽者亡几耳。然并心而赴时，犹曰蹷六国，兼天下。功成求得矣，终不知反廉愧之节，仁义之厚。信并兼之法，遂进取之业，天下大败；众掩寡，智欺愚，勇威怯，壮陵衰，其乱至矣。是以大贤起之，威震海内，德从天下。曩之为秦者，今转而为汉矣。然其遗风余俗，犹尚未改。今世以侈靡相竞，而上亡制度，弃礼谊，捐廉耻，日甚，可谓月异而岁不同矣。逐利不耳，虑非顾行也，今其甚者杀父兄矣。盗者剟寝户之帘，搴两庙之器，白昼大都之中剽吏而夺之金。矫伪者出几十万石粟，赋六百余万钱，乘传而行郡国，此其亡行义之（先）〔尤〕至者也。而大臣特以簿书不报，期会之间，以为大故。至于俗流失，世坏败，因恬而不知怪，虑不动于耳目，以为是适然耳。夫移风易俗，使天下回心而乡道，类非俗吏之所能为也。俗吏之所务，在于刀笔筐箧，而不知大（礼）〔体〕。陛下又不自忧，窃为陛下惜之。</p><p>　　夫立君臣，等上下，使父子有礼，六亲有纪，此非天之所为，人之所设也。夫人之所设，不为不立，不植则僵，不修则坏。管子曰：「礼义廉耻，是谓四维；四维不张，国乃灭亡。」使管子愚人也则可，管子而少知治体，则是岂可不为寒心哉！秦灭四维而不张，故君臣乖乱，六亲殃戮，奸人并起，万民离叛，凡十三岁，〔而〕社稷为虚。今四维犹未备也，故奸人几幸，而众心疑惑。岂如今定经制，令君君臣臣，上下有差，父子六亲各得其宜，奸人亡所几幸，而群臣众信，上不疑惑！此业壹定，世世常安，而后有所持循矣。若夫经制不定，是犹度江河亡维楫，中流而遇风波，舩必覆矣。可为长太息者此也。</p><p>　　夏为天子，十有余世，而殷受之。殷为天子，二十余世，而周受之。周为天子，三十余世，而秦受之。秦为天子，二世而亡。人性不甚相远也，何三代之君有道之长，而秦无道之暴也？其故可知也。古之王者，太子乃生，固举以礼，使士负之，有司齐肃端冕，见之南郊，见于天也。过阙则下，过庙则趋，孝子之道也。故自为赤子而教固已行矣。昔者成王幼在襁抱之中，召公为太保，周公为太傅，太公为太师。保，保其身体；傅，傅之德（意）〔义〕；师，道之教训：此三公之职也。于是为置三少，皆上大夫也，曰少保、少傅、少师，是与太子宴者也。故乃孩提有识，三公、三少固明孝仁礼义以道习之，逐去邪人，不使见恶行。于是皆选天下之端士孝悌博闻有道术者以卫翼之，使与太子居处出入。故太子乃生而见正事，闻正言，行正道，左右前后皆正人也。夫习与正人居之，不能毋正，犹生长于齐不能不齐言也；习与不正人居之，不能毋不正，犹生长于楚之地不能不楚言也。故择其所耆，必先受业，乃得尝之；择其所乐，必先有习，乃得为之。孔子曰：「少成若天性，习贯如自然。」及太子少长，知妃色，则入于学。学者，所学之官也。学礼曰：「帝入东学，上亲而贵仁，则亲疏有序而恩相及矣；帝入南学，上齿而贵信，则长幼有差而民不诬矣；帝入西学，上贤而贵德，则圣智在位而功不遗矣；帝入北学，上贵而尊爵，则贵贱有等而下不隃矣；帝入太学，承师问道，退习而考于太傅，太傅罚其不则而匡其不及，则德智长而治道得矣。此五学者既成于上，则百姓黎民化辑于下矣。」及太子既冠成人，免于保傅之严，则有记过之史，彻膳之宰，进善之旌，诽谤之木，敢谏之鼓。瞽史诵诗，工诵箴谏，大夫进谋，士传民语。习与智长，故切而不愧；化与心成，故中道若性。三代之礼：春朝朝日，秋暮夕月，所以明有敬也；春秋入学，坐国老，执酱而亲馈之，所以明有孝也；行以鸾和，步中采齐，趣中肆夏，所以明有度也；其于禽兽，见其生不食其死，闻其声不食其肉，故远庖厨，所以长恩，且明有仁也。</p><p>　　夫三代之所以长久者，以其辅翼太子有此具也。及秦而不然。其俗固非贵辞让也，所上者告讦也；固非贵礼义也，所上者刑罚也。使赵高傅胡亥而教之狱，所习者非斩劓人，则夷人之三族也。故胡亥今日即位而明日射人，忠谏者谓之诽谤，深计者谓之妖言，其视杀人若艾草菅然。岂惟胡亥之性恶哉？彼其所以道之者非其理故也。</p><p>　　鄙谚曰：「不习为吏，视已成事。」又曰：「前车覆，后车诫。」夫三代之所以长久者，其已事可知也；然而不能从者，是不法圣智也。秦世之所以亟绝者，其辙迹可见也；然而不避，是后车又将覆也。夫存亡之变，治乱之机，其要在是矣。天下之命，县于太子；太子之善，在于早谕教与选左右。夫心未滥而先谕教，则化易成也；开于道术智谊之指，则教之力也。若其服习积贯，则左右而已。夫胡、粤之人，生而同声，耆欲不异，及其长而成俗，累数译而不能相通，行者〔有〕虽死而不相为者，则教习然也。臣故曰选左右早谕教最急。夫教得而左右正，则太子正矣，太子正而天下定矣。书曰：「一人有庆，兆民赖之。」此时务也。</p><p>　　凡人之智，能见已然，不能见将然。夫礼者禁于将然之前，而法者禁于已然之后，是故法之所用易见，而礼之所为生难知也。若夫庆赏以劝善，刑罚以惩恶，先王执此之政，坚如金石，行此之令，信如四时，据此之公，无私如天地耳，岂顾不用哉？然而曰礼云礼云者，贵绝恶于未萌，而起教于微眇，使民日迁善远辠而不自知也。孔子曰：「听讼，吾犹人也，必也使毋讼乎！」为人主计者，莫如先审取舍；取舍之极定于内，而安危之萌应于外矣。安者非一日而安也，危者非一日而危也，皆以积渐然，不可不察也。人主之所积，在其取舍。以礼义治之者，积礼义；以刑罚治之者，积刑罚。刑罚积而民怨背，礼义积而民和亲。故世主欲民之善同，而所以使民善者或异。或道之以德教，或殴之以法令。道之以德教者，德教洽而民气乐；殴之以法令者，法令极而民风哀。哀乐之感，祸福之应也。秦王之欲尊宗庙而安子孙，与汤武同，然而汤武广大其德行，六七百岁而弗失，秦王治天下，十余岁则大败。此亡它故矣，汤武之定取舍审而秦王之定取舍不审矣。夫天下，大器也。今人之置器，置诸安处则安，置诸危处则危。天下之情与器亡以异，在天子之所置之。汤武置天下于仁义礼乐，而德泽洽，禽兽草木广裕，德被蛮貊四夷，累子孙数十世，此天下所共闻也。秦王置天下于法令刑罚，德泽亡一有，而怨毒盈于世，下憎恶之如仇仇，旤几及身，子孙诛绝，此天下之所共见也。是非其明效大验邪！人之言曰：「听言之道，必以其事观之，则言者莫敢妄言。」今或言礼谊之不如法令，教化之不如刑罚，人主胡不引殷、周、秦事以观之也？</p><p>　　人主之尊譬如堂，群臣如陛，众庶如地。故陛九级上，廉远地，则堂高；陛亡级，廉近地，则堂卑。高者难攀，卑者易陵，理势然也。故古者圣王制为等列，内有公卿大夫士，外有公侯伯子男，然后有官师小吏，延及庶人，等级分明，而天子加焉，故其尊不可及也。里谚曰：「欲投鼠而忌器。」此善谕也。鼠近于器，尚惮不投，恐伤其器，况于贵臣之近主乎！廉耻节礼以治君子，故有赐死而亡戮辱。是以黥劓之辠不及大夫，以其离主上不远也。礼不敢齿君之路马，蹴其刍者有罚；见君之几杖则起，遭君之乘车则下，入正门则趋；君之宠臣虽或有过，刑戮之辠不加其身者，尊君之故也。此所以为主上豫远不敬也，所以体貌大臣而厉其节也。今自王侯三公之贵，皆天子之所改容而礼之也，古天子之所谓伯父、伯舅也，而令与众庶同黥劓髠刖笞傌弃巿之法，然则堂不亡陛虖？被戮辱者不泰迫虖？廉耻不行，大臣无乃握重权，大官而有徒隶亡耻之心虖？夫望夷之事，二世见当以重法者，投鼠而不忌器之习也。</p><p>　　臣闻之，履虽鲜不加于枕，冠虽敝不以苴履。夫尝已在贵宠之位，天子改容而体貌之矣，吏民尝俯伏以敬畏之矣，今而有过，帝令废之可也，退之可也，赐之死可也，灭之可也；若夫束缚之，系緤之，输之司寇，编之徒官，司寇小吏詈骂而榜笞之，殆非所以令众庶见也。夫卑贱者习知尊贵者之一旦吾亦乃可以加此也，非所以习天下也，非尊尊贵贵之化也。夫天子之所尝敬，众庶之所尝宠，死而死耳，贱人安宜得如此而顿辱之哉！</p><p>　　豫让事中行之君，智伯伐而灭之，移事智伯。及赵灭智伯，豫让衅面吞炭，必报襄子，五起而不中。人问豫子，豫子曰：「中行众人畜我，我故众人事之；智伯国士遇我，我故国士报之。」故此一豫让也，反君事仇，行若狗彘，已而抗节致忠，行出虖列士，人主使然也。故主上遇其大臣如遇犬马，彼将犬马自为也；如遇官徒，彼将官徒自为也。顽顿亡耻奊诟亡节，廉耻不立，且不自好，苟若而可，故见利则逝，见便则夺。主上有败，则因而挻之矣；主上有患，则吾苟免而已，立而观之耳；有便吾身者，则欺卖而利之耳。人主将何便于此？群下至众，而主上至少也，所托财器职业者粹于群下也。俱亡耻，俱苟妄，则主上最病。故古者礼不及庶人，刑不至大夫，所以厉宠臣之节也。古者大臣有坐不廉而废者，不谓不廉，曰「簠簋不饰」；坐污秽淫乱男女亡别者，不曰污秽，曰「帷薄不修」；坐罢软不胜任者，不谓罢软，曰「下官不职」。故贵大臣定有其辠矣，犹未斥然正以謼之也，尚迁就而为之讳也。故其在大谴大何之域者，闻谴何则白冠牦缨，盘水加剑，造请室而请辠耳，上不执缚系引而行也。其有中罪者，闻命而自弛，上不使人颈盭而加也。其有大辠者，闻命则北面再拜，跪而自裁，上不使捽抑而刑之也，曰：「子大夫自有过耳！吾遇子有礼矣。」遇之有礼，故群臣自憙；婴以廉耻，故人矜节行。上设廉耻礼义以遇其臣，而臣不以节行报其上者，则非人类也。故化成俗定，则为人臣者主耳忘身，国耳忘家，公耳忘私，利不苟就，害不苟去，唯义所在。上之化也，故父兄之臣诚死宗庙，法度之臣诚死社稷，辅翼之臣诚死君上，守圄捍敌之臣诚死城郭封疆。故曰圣人有金城者，比物此志也。彼且为我死，故吾得与之俱生；彼且为我亡，故吾得与之俱存；夫将为我危，故吾得与之皆安。顾行而忘利，守节而仗义，故可以托不御之权，可以寄六尺之孤。此厉廉耻行礼谊之所致也，主上何丧焉！此之不为，而顾彼之久行，故曰可为长太息者此也。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="译文"><a href="#译文" class="headerlink" title="译文"></a>译文</h1><p>　　我私下考虑如今的局势，可为之痛哭的有一项，可为之流泪的有两项，应为之大声叹息的有六项，至于其他违背情理而伤害大道的事，很难一一列举。向陛下进言的人都说天下已经安定，治理得很好了，我却认为不是那么回事。说天下已经安定已经大治的人，不是愚昧无知，就是阿谀奉承，都不是真正了解治乱大体的人。有人抱着火种放在堆积的木柴之下，自己睡在木柴上，火没燃烧起来的时候，他便认为这是安宁的地方，如今国家的局势，与此有什么不同！本末颠倒，首尾冲突，国制混乱，不合理的现象严重，怎么能够说是大治！陛下为什么不让我对您详细地说明这一切，提出使国家真正大治大安的方策，以供陛下仔细斟酌选用呢？</p><p>　　射箭打猎之类的娱乐与国家安危的关键相比，哪一样更急迫？假若所提的治世方法，耗费心血，摧残身体，影响享受钟鼓所奏音乐，可以不采纳；我的治国方策，能保证使陛下所享受的乐趣不受影响，却可以带来封国诸侯各遵法规，战争不起，平民拥护首领，匈奴归顺，纯朴之风响彻边陲，百姓温良朴素，官司之类的事情停止不发。大势已定，那么，全国便会顺从而大治，四海之内，一派升平，万物都符合事理，陛下生时被称为明帝，死后成为明神，美名佳誉永垂青史。《礼》书上说宗庙有功德，使您的顾成庙被尊称为大宗，得以与太祖共享盛名，与大汉天下共存亡。创建长久安定的形势，造成永久太平的业绩，以此来承奉祖庙和六亲，这是最大的孝顺；以此来使老百姓得到幸福，使芸芸众生得到养育，这是最大的仁；创设准则，标立纪纲，使大小事物各得其所，为万世子孙树立楷模，即使是后世出现了愚鲁、幼稚、不肖的继承人，由于他继承了您的鸿业和福荫，还可以安享太平，这是最明智的办法。凭陛下的精明练达，再有稍微懂得治国之道的人辅佐，要达到这一境界并不困难。其内容全都可以向陛下陈述，希望陛下不要忽视。我谨慎地用它来考察过天地的变化，应验过往，核对当今，日夜思考而详细地知道了它的内容，即使是禹舜再生，也不能加以改变。</p><p>　　建立诸侯国过于强大，必然会造成天子与诸侯互相对立，臣下屡遭祸害，皇上也多次忧伤，这实在不是使皇上放心、使臣下保全的办法。如今亲兄弟图谋在东方称帝，亲侄子也向西袭击朝廷，吴王的谋反活动又被人告发。当今天子年富力强，品行道义上没有过错，对他们施加功德恩泽，而他们尚且如此，何况最大的诸侯，权力比他们还要大十倍呢！</p><p>　　虽然如此，但是天下还比较安定，这是什么原因呢？因为大诸侯国王年纪还小，汉朝安置在那的太傅、丞相还掌握着政事。几年以后，诸侯王大都加冠成人，血气方刚，而汉朝委派的太傅、丞相都要称病还乡，诸侯王会遍插亲信，如果这样的话，他们的行为同淮南王、济北王有什么区别呢？到了那时，想求得天下安定，即使是尧舜在世也办不到。</p><p>　　黄帝说：“到了中午要抓紧曝晒，拿着刀子要赶紧宰割。”如今要使安治之道顺利而稳妥地推行，是十分容易的。假使不肯及早行动，到头来就要毁掉亲骨肉，这同秦朝末年的局势还有什么区别吗？凭着天子的权位，趁着当今的有利时机，靠着上天的帮助，尚且对转危为安、改乱为治的措施有所顾虑，假设陛下处在齐桓公的境地，大概不会去联合诸侯匡正天下吧？我知道陛下一定不能那样做的。假如国家的局势还像从前那样，淮阴侯韩信还统治着楚，黥布统治着淮南，彭越统治着梁，韩王信统治着韩，张敖统治着赵，贯高做赵国的相，卢绾统治着燕，陈还在代国，假令这六七个王公都还健在，在这时陛下继位做天子，自己能感到安全吗？我判断陛下是不会感到安全的。在天下混乱的年代，高祖和这些王公们共同起事，并没有子侄亲属的势力做为依靠。这些王公走运的就成了亲近的侍从，差一点的仅当个管理宫中事务的官员，他们的才能远不及高祖。高祖凭着他的明智威武，即位做了天子，割出肥沃的土地，使这些王公成为诸侯王，多的有一百多个城，少的也有三四十个县，恩德是优厚的了，然而在以后的十年当中，反叛汉朝的事发生了九次。陛下跟这些王公，并没有亲自较量过才能而使他们甘心为臣的，也不是亲自封他们当诸侯王的。即使高祖也不能因此而得到一年的安宁，所以我知道陛下更不能得到安宁的。</p><p>　　不过，上面这些情况，还有可以推托的理由，说是“关系疏远”。那就请允许我试着谈谈那些亲属诸侯王吧。假如让齐悼惠王统治着齐，楚元王统治着楚，赵王统治着赵，幽王统治着淮阳，恭王统治着梁，灵王统治着燕，厉王统治着淮南，假如这六七位贵人都还健在，在这时陛下即皇帝位，能使天下太平吗？我又知陛下是不能的。像这些诸侯王，虽然名义上是臣子，实际上他们都怀有老百姓那种兄弟关系的想法，大概没有不想采用天子的制度，而把自己当做天子的。他们擅自把爵位赏给别人，赦免死罪，甚至有人乘坐天子的黄屋车。他们不执行汉朝的法令。即使执行了，像厉王那样的不守法的人，命令他都不肯听从，又怎么能招他来呢！幸而召来了，法律怎么能施加到他身上呢！动了一个近亲，天下诸王都环视着惊动起来。陛下的臣子当中即使有冯敬那样勇敢的人，但是他刚开口揭发诸侯王的不法行为，刺客的匕首已经刺进他的胸膛了。陛下虽然贤明，谁能和您一起来治理这些人呢？</p><p>　　所以说，关系疏远的诸侯王必定危险，关系亲近的诸侯王也一定作乱，这是事实所证明了的。那些自负强大而发动叛乱的异姓诸侯王，汉朝已经侥幸地战胜他们了，可是却没有改变酿成叛乱的制度。同姓诸侯王也袭用了这种做法，发动叛乱，如今已有征兆了，形势又完全恢复到以前那种状态！灾祸的变化，还不知道要转移到何处，英明的皇帝处在这种情况下，尚且不能使国家安宁，后代又将怎么办呢！</p><p>　　屠牛坦一早晨宰割了十二头牛，而屠刀的锋刃并不变钝，这是因为他所刮剔割剥的，都是顺着肉的肌理下刀。等碰到胯骨、大腿骨的地方，那就不是用砍刀就是用斧头去砍了。仁义恩厚好比是君王的刀刃，权势、法制好比是君王的砍刀、斧头。如今的诸侯王好比是胯骨、大腿骨，如果放弃砍刀、斧头不用，而要用刀刃去碰，我认为刀子不是出缺口就是被折断。为什么仁义恩厚不能用在淮南王、济北王的身上呢？因为形势不容许啊！</p><p>　　我私下里考察从前的事件，大体上是势力强大的先反：淮阴侯韩信统治着楚，势力最强，就最先反叛；韩王信依靠了匈奴的力量，就又反叛了；贯高借助了赵国的条件，就又反叛了；陈狶部队精锐，也反叛了；彭越凭借梁国，也反叛了；黥布凭借淮南，也反叛了；卢绾势力最弱，最后反叛。长沙王吴芮才有二万五千封户，功劳很少，却保全了下来，权势最小而对汉朝最忠顺；这不只是由于性情和别人不同，也是由于形势使他这样。倘若从前让樊哙、郦商、周勃、灌婴占据几十个城为王，那如今他们由于作恶而亡国，也是可能的。假使让韩信、彭越之流，只居于彻侯的地位，即便今天也还能保全，也是可能的。</p><p>　　既然如此，那么天下大计就可以知道了。要想使天下诸侯王都忠心归附汉朝，那最好让他们都像长沙王一样；要想让臣下不至于像韩信那样被杀掉，那最好让他们像樊哙、郦商那徉；要想使天下安定，最好多多建立诸侯国而使他们的势力减小。力量弱小就容易用道义来指使他们，国土小就不会有反叛的邪念。这样就使全国的形势，如同身体使唤手臂，手臂使唤手指似的，没有不听从指挥的。诸侯王不敢有反叛的想法，如同辐条聚向车轮一样，都归顺天子，即使是老百姓，也会知道他们都很安稳。这样，天下就都知道陛下的英明。分割土地，定出制度：把齐、赵、楚三个王国分成若干侯国，让齐王、赵王、楚王的子孙，全都依次受封先人的那份封地，一直到分尽为止。对燕、梁等其他王国也是这样。有些封地大而子孙少的，也都分成若干侯国，暂时空着搁置起来，等着他们的子孙出生以后，再封他当候。诸侯王的封地，有不少已被削除收归汉朝所有的，那就替他们调整侯国所在的地区，等到要封他的子孙到别的地方去的时候，按候国的应有户数，给以补偿。一寸土、一口人，皇帝也不沾他们的，确实只是为了安定太平罢了。这样，天下就都知道陛下的廉洁。分封土地的制度一旦确定，宗室子孙没有不考虑保住自己的统治的。臣子没有背叛的念头，皇帝没有讨伐的想法。所以天下就都知道陛下的仁德。法令制定了，没有人触犯；政令推行了，没有人抵触。贯高、利几一类的阴谋不会出现，柴奇、开章那样的诡计不会萌生。老百姓都向往良善，大臣都向皇上表示恭顺。所以天下就都知道陛下的道义。这样，即使让幼儿当皇帝，天下也很安定；即使立一个遗腹子作天子，让臣子朝拜老皇帝遗留下来的皇袍，天下也不致于混乱。这样，就可以使天下安定无事，后代也称颂陛下的圣明。只要采取这样的措施，上述五个方面的业绩也就随之而来了，而陛下又怕什么而久久不这样办呢？</p><p>　　当今，天下的形势像得了严重的浮肿病：小腿粗得差不多像腰围，脚指粗得差不多像大腿。平时都不能伸屈自如，一两个指头抽搐，浑身就觉得无所依赖。丧失了今天的机会而不医治，一定要成为难治的顽症。以后即使有扁鹊那样神医，也都无能为力。这个病还不只是浮肿，还苦于脚掌扭折不能走动。楚元王的儿子，是陛下的叔伯兄弟，当今的楚王，是叔伯兄弟的儿子，齐悼惠王的儿子，是陛下亲哥哥的儿子，当今的齐王是陛下哥哥的孙子。陛下自己的子孙，有的还没有分封土地，以便安定天下，旁支的子孙，倒有人掌握大权来威胁皇帝。所以，我说：不仅是害了浮肿病，还苦于脚掌扭折了不能走动。令人痛哭的就是这样一种病啊！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="Literature" scheme="https://zhang21.github.io/categories/Literature/"/>
    
    
      <category term="古文" scheme="https://zhang21.github.io/tags/%E5%8F%A4%E6%96%87/"/>
    
      <category term="政论文" scheme="https://zhang21.github.io/tags/%E6%94%BF%E8%AE%BA%E6%96%87/"/>
    
      <category term="贾谊" scheme="https://zhang21.github.io/tags/%E8%B4%BE%E8%B0%8A/"/>
    
  </entry>
  
  <entry>
    <title>封建论</title>
    <link href="https://zhang21.github.io/2019/02/10/%E5%B0%81%E5%BB%BA%E8%AE%BA/"/>
    <id>https://zhang21.github.io/2019/02/10/封建论/</id>
    <published>2019-02-10T12:13:11.000Z</published>
    <updated>2019-02-11T01:24:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考:</p><ul><li>维基百科</li></ul><p><br><br><br></p><hr><a id="more"></a><p><br><br><br></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>　　柳宗元（773年－819年11月28日），字子厚，河东（今山西运城）人，唐代著名文学家、思想家，唐宋八大家之一。参加永贞革新失败，被贬为永州司马。为当道者嫉恨，除短暂奉召入京外，终生未再北还。</p><p>　　《封建论》是柳宗元的政论文章，该文详尽分析了唐代以前中国历代政治得失，认为中国封建制度是百害而无一利，并阐发郡县制的优越性。<br>柳宗元被贬柳州（今广西柳州市）之时，引史为证，做“封建论”，结构严谨，文笔犀利而流畅。《封建论》说“彼封建者，更古圣王尧、舜、禹、汤、文、武而莫能去之。盖非不欲去之也，势不可也。……封建，非圣人意也”。</p><p>　　中唐时期，藩镇割据的情况愈演愈烈，当时各地藩镇极力鼓吹要恢复周以前的封建制度，反对中央集权的郡县制度，目的是为自己的割据制造舆论。和这种政治局面相适应，分封制的论调又开始抬头。针对这种情况，作者在永贞革新失败、被贬永州后，写下了这篇议论文。</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h1><p>　　天地果无初乎？吾不得而知之也。生人果有初乎？吾不得而知之也。然则孰为近？曰有初为近。孰明之？由封建而明之也。彼封建者，更古圣王尧舜、禹汤、文武而莫能去之。盖非不欲去之也，势不可也。势之来（则），其生人之初乎？不初，无以有封建。封建，非圣人意也。</p><p>　　彼其初与万物皆生，草木榛榛，鹿豕狉狉，人不能搏噬，而且无毛羽，莫克自奉自卫。荀卿有言：必将假物以为用者也。夫假物者必争，争而不已，必就其能断曲直者而听命焉。其智而明者，所伏必众；告之以直而不改，必痛之而后畏；由是君长刑政生焉。故近者聚而为群。群之分，其争必大，大而后有兵有德。又有大者，众群之长又就而听命焉，以安其属，于是有诸侯之列。则其争又有大者焉。德又大者，诸侯之列又就而听命焉，以安其封，于是有方伯、连帅之类。则其争又有大者焉。德又大者，方伯、连帅之类又就而听命焉，以安其人，然后天下会于一。是故有里胥而后有县大夫，有县大夫而后有诸侯，有诸侯而后有方伯、连帅，有方伯、连帅而后有天子。自天子至于里胥，其德在人者，死必求其嗣而奉之。故封建非圣人意也，势也。</p><p>　　夫尧舜禹汤之事远矣，及有周而甚详。周有天下，裂土田而瓜分之，设五等，邦群后，布星罗，四周子天下，轮运而辐集。合为朝觐会同，离为守臣捍城。然而降于夷王，害礼伤尊，下堂而迎觐者，历于宣王，挟中兴复古之德，雄南征北伐之威，卒不能定鲁侯之嗣。陵夷迄于幽厉，王室东徙，而目列为诸侯。厥后，问鼎之轻重者有之，射三中肩者有之，代凡伯、诛苌宏者有之，天下乖盭，无君之心。予以为周之丧久矣，徒建空名于公侯之上耳！得非诸侯之盛强，末大不掉之咎欤？遂判为十二，合为七国，威分于陪臣之邦，国殄于后封之秦。则周之败端，其在乎此矣。</p><p>　　秦有天下，裂都会而为之郡邑，废侯卫而为之守宰，据天下之雄图，都六合之上游，摄制四海，运于掌握之内，此其所以为得也。不数载而天下大坏，其有由矣。亟役万人，暴其威刑，竭其货贿。负锄梃谪戍之徒，加圜视而合从，大呼而成群。时则有叛人而无叛吏，人怨于下，而吏畏于上，天下相合，杀守劫令而并起。咎在人怨，非郡邑之制失也。</p><p>　　汉有天下，矫秦之枉，徇周之制，剖海内而立宗子，封功臣。数年之间，奔命扶伤而不暇。困平城，病流矢，陵迟不救者三代。后乃谋臣献画，而离削自守矣。然而封建之始，郡国居半，时则有叛国而无叛郡。秦制之得，亦以明矣。继汉而帝者，虽百代可知也。</p><p>　　唐兴，制州邑，立守宰，此其所以为宜也。然犹桀猾时起，虐害方域者，失不在于州而在于兵，时则有叛将而无叛州。州县之设，固不可革也。</p><p>　　或者曰：「封建者，必私其土，子其人，适其俗，修其理，施化易也。守宰者，苟其心，思迁其秩而已，何能理乎？」予又非之。周之事迹，断可见矣。列侯骄盈，黩货事戎。大凡乱国多，理国寡。侯伯不得变其政，天子不得变其君。私土于人者，百不有一。失在于制，不在于政，周事然也。秦之事迹，亦断可见矣。有理人之制，而不委郡邑是矣；有理人之臣，而不使守宰是矣。郡邑不得正其制，守宰不得行其理，酷刑苦役，而万人侧目。失在于政，不在于制。秦事然也。汉兴，天子之政行于郡，不行于国；制其守宰，不制其侯王。侯王虽乱，不可变也；国人虽病，不可除也。及夫大逆不道，然后掩捕而迁之，勒兵而夷之耳。大逆未彰，奸利浚财，怙势作威，大刻于民者，无如之何。及夫郡邑，可谓理且安矣。何以言之？且汉知孟舒于田叔，得魏尚于冯唐，闻黄霸之明审，睹汲黯之简靖，拜之可也，复其位可也，卧而委之以辑一方可也。有罪得以黜，有能得以奖。朝拜而不道，夕斥之矣；夕受而不法，朝斥之矣。设使汉室尽城邑而侯王之，纵令其乱人，戚之而已。孟舒、魏尚之术，莫得而施；黄霸、汲黯之化，莫得而行。明谴而导之，拜受而退已违矣。下令而削之，缔交合从之谋，周于同列，则相顾裂眦，勃然而起。幸而不起，则削其半。削其半，民犹瘁矣，曷若举而移之，以全其人平？汉事然也。今国家尽制郡邑，连置守宰，其不可变也固矣。善制兵，谨择守，则理平矣。</p><p>　　或者又曰：「夏、商、周、汉封建而延，秦郡邑而促。」尤非所谓知理者也。魏之承汉也，封爵犹建。晋之承魏也，因循不革。而二姓陵替，不闻延祚。今矫而变之，垂二百祀，大业弥固，何系于诸侯哉？</p><p>　　或者又以为：「殷周圣王也，而不革其制，固不当复议也。」是大不然。夫殷周之不革者，是不得已也。盖以诸侯归殷者三千焉，资以黜夏，汤不得而废；归周老八百焉，资以胜殷，武王不得而易。徇之以为安，仍之以为俗，汤、武之所不得已也。夫不得已，非公之大者也，私其力于己也，私其卫于子孙也。秦之所以革之者，其为制，公之大者也；其情，私也，私其一己之威也，私其尽臣畜于我也。然而公天下之端自秦始。</p><p>　　夫天下之道，理安，斯得人者也。使贤者居上，不肖者居下，而后可以理安。今夫封建者，继世而理。继世而理者，上果贤乎？下果不肖乎？则生人之理乱，未可知也。将欲利其社稷，以一其人之视听，则又有世大夫世食禄邑，以尽其封略。圣贤生于其时，（亦）无以立于天下，封建者为之也。岂圣人之制使至于是乎？吾固曰：「非圣人之意也，势也。」</p><p><br><br><br></p><hr><p><br><br><br></p><h1 id="译文"><a href="#译文" class="headerlink" title="译文"></a>译文</h1><p>　　自然界果真没有原始阶段吗？我没法知道。人类果真有原始阶段吗？我也没法知道。那么，（有或没有原始阶段）哪种说法比较接近事实呢？我认为：有原始阶段这种说法比较接近事实。怎么知道这一点呢？从“封国土、建诸侯”的封建制就可以明白。那种封建制，经历了古代贤明的帝王唐尧、虞舜、夏禹、商汤、周文王和周武王，没有谁能把它废除掉。不是不想把它废除掉，而是事物发展的趋势不允许，这种形势的产生，大概是在人类的原始阶段吧？不是原始阶段的那种形势，就没有可能产生封建制。实行封建制，并不是古代圣人的本意。</p><p>　　人类在他的原始阶段跟万物一起生存，那时野草树木杂乱丛生，野兽成群四处奔走，人不能像禽兽那样抓扑啃咬，而且身上也没有毛羽来抵御严寒，不能够光靠自身来供养自己、保卫自己。荀卿说过：“人类一定要借用外物作为自己求生的工具。”借用外物来求生的必然会相争，争个不停，一定会去找那能判断是非的人而听从他的命令。那又有智慧又明白事理的人，服从他的人一定很多；他把正确的道理告诉那些相争的人，不肯改悔的，必然要惩罚他，使他受痛苦之后感到惧怕，于是君长、刑法、政令就产生了。这样附近的人就聚结成群，分成许多群以后，相互间争斗的规模一定会大，相争的规模大了就会产生军队和威望。这样，又出现了更有威德的人，各个群的首领又去听从他的命令，来安定自己的部属。于是产生了一大批诸侯，他们相争的规模就更大了。又有比诸侯威德更大的人，许多诸侯又去听从他的命令，来安定自己的封国。于是又产生了方伯、连帅一类诸侯领袖，他们相争的规模还要大。这就又出现了比方伯，连帅威德更大的人，方伯、连帅们又去听从他的命令，来安定自己的老百姓，这以后天下便统一于天子一人了。因此先有乡里的长官而后有县的长官，有了县的长官而后有诸侯，有了诸侯而后有方伯、连帅，有了方伯、连帅而后才有天子。从最高的天子到乡里的长官，那些对人民有恩德的人死了，人们一定会尊奉他们的子孙为首领。所以说封建制的产生不是圣人的本意，而是形势发展的必然结果。</p><p>　　尧、舜、禹、汤的事离我们很远了，到了周代记载就很详备了。周朝占有天下，把土地像剖瓜一样分割开来，设立了公、侯、伯、子、男五等爵位，分封了许多诸侯。诸侯国像繁星似地罗列，四面遍布在大地上，集结在周天子的周围，就像车轮围绕着中心运转，就像辐条集中于车毂；诸侯聚合起来就去朝见天子，分散开来就是守卫疆土的臣子、朝廷的捍卫者。但是往下传到周夷王的时候，破坏了礼法，损害了尊严，天子只得亲自下堂去迎接朝见的诸侯。传到周宣王的时候，他虽然倚仗着复兴周王朝的功德，显示出南征北伐的威风，终究还是无力决定鲁君的继承人。这样日渐衰败下去，直到周幽王、周厉王，后来周平王把国都向东迁移到洛邑，把自己排列在诸侯同等地位上去了。从那以后，问周天子传国九鼎的轻重的事情出现了，用箭射伤天子肩膀的事情出现了，讨伐天子大臣凡伯、逼迫天子杀死大夫苌弘这样的事情也出现了，天下大乱，再没有把天子看作天子的了。我认为周王朝丧失统治力量已经很久了，只不过还在公侯之上保存着一个空名罢了！这岂不是诸侯势力太强大而指挥不动，就像尾巴太大以至摇摆不动所造成的过失吗？于是周王朝的统治权分散到十二个诸侯国，后来又合并为七个强国，王朝的权力分散到陪臣掌政的国家，最后被很晚才封为诸侯的秦国灭掉。周朝败亡的原因，大概就在这里了。<br>秦朝统一了全国后，不分诸侯国而设置郡县，废除诸侯而委派郡县长官。秦占据了天下的险要地势，建都于全国的上游，控制着全国，把局势掌握在手里，这是它做得对的地方。但没过几年便天下大乱，那是有原因的。它多次征发数以万计的百姓服役，使刑法越来越残酷，耗尽了财力。于是那些扛着锄木棍被责罚防守边境的人们，彼此递个眼色就联合起来，怒吼着汇合成群，奋起反秦。那时有造反的老百姓而没有反叛的官吏，老百姓在下怨恨秦王朝；官吏在上惧怕朝廷。全国四面八方互相配合，杀郡守劫县令的事情在各地同时发生。错误在于激起了人民的怨恨，并不是郡县制的过失。</p><p>　　汉朝统一了全国之后，纠正秦朝的错误，沿袭周朝的封建制，分割天下，分封自己的子弟和功臣为诸侯王。但没有几年，为了平息诸侯国的叛乱便闻命奔赴镇压，以至连救死扶伤都来不及，汉高祖刘邦被围困在平城，被飞箭射伤，如此衰落不振达三代之久。后来由于谋臣献策，才分散削弱诸侯王的势力并由朝廷命官管理诸侯国。但是汉朝开始恢复封建制的时候，诸侯国和郡县各占一半疆域，那时只有反叛的诸侯国而没有反叛的郡县，秦朝郡县制的正确性也已经明白清楚了。继汉朝而称帝的，就是再过一百代，郡县制比封建制优越，也是可以知道的。</p><p>　　唐朝建立以后，设置州县，任命州县的长官，这是它做得正确的地方。但还是有凶暴狡猾的人不时起来叛乱、侵州夺县的情况出现，过失不在于设置州县而在于藩镇拥有重兵，那时有反叛的藩镇将领而没有反叛的州县长官。郡县制的建立，确实是不能改变的。</p><p>　　有的人说：“封建制的世袭君长，一定会把他管辖的地区当作自己的土地尽心治理，把他管辖的老百姓当作自己的儿女悉心爱护，使那里的风俗变好，把那里的政治治理好，这样施行教化就比较容易。郡县制的州县地方官，抱着得过且过的心理，一心只想升官罢了，怎么能把地方治理好呢？”我认为这种说法也是不对的。</p><p>　　周朝的情况，毫无疑问地可以看清楚了：诸侯骄横，贪财好战，大致是政治混乱的国家多，治理得好的国家少。诸侯的霸主不能改变乱国的政治措施，天子无法撤换不称职的诸侯国的君主，真正爱惜土地爱护人民的诸侯，一百个中间也没有一个。造成这种弊病的原因在于封建制，不在于政治方面。周朝的情况就是如此。</p><p>　　秦朝的情况，也完全可以看清楚了：朝廷有治理百姓的制度，而不让郡县专权，这是正确的；中央有管理政务的大臣，不让地方官自行其是，这也是正确的。但是郡县不能正确发挥郡县制的作用，郡守、县令不能很好地治理人民。残酷的刑罚、繁重的劳役，使万民怨恨。这种过失在于政治方面，不在于郡县制本身。秦朝的情况便是这样。</p><p>　　汉朝建立的时候，天子的政令只能在郡县推行，不能在诸侯国推行；天子只能控制郡县长官，不能控制诸侯王。诸侯王尽管胡作非为，天子也不能撤换他们；侯王国的百姓尽管深受祸害，朝廷却无法解除他们的痛苦。只是等到诸侯王叛乱造反，才把他们逮捕、流放或率兵讨伐、以至灭掉他们。当他们的罪恶尚未充分暴露的时候，尽管他们非法牟利搜刮钱财，依仗权势作威作福，给百姓造成严重的伤害，朝廷也不能对他们怎么样。至于郡县，可以说是政治清明、社会安定了。根据什么这样讲呢？汉文帝从田叔那里了解到孟舒，从冯唐那里了解到魏尚，汉宣帝听说黄霸执法明察审慎，汉武帝看到汲黯为政简约清静，那么就可以任命黄霸做官，可以恢复孟舒、魏尚原来的官职，甚至可以让汲黯躺着任职，委任他只凭威望去安抚一个地区。官吏犯了罪可以罢免，有才干可以奖赏。早上任命的官吏，如果发现他不行正道，晚上就可以撤了他；晚上接受任命的官吏，如果发现他违法乱纪，第二天早上就可以罢免他。假使汉王朝把城邑全部都分割给侯王，即使他们危害人民，也只好对它发愁罢了。孟舒、魏尚的治理方法不能施行，黄霸、汲黯的教化无法推行。如果公开谴责并劝导这些侯王，他们当面接受，但转过身去就违反了；如果下令削减他们的封地，互相串通联合行动的阴谋就会遍及侯王各国之间，那么大家都怒眼圆睁，气势汹汹地反叛朝廷。万一他们不起来闹事，就削减他们的一半封地，即使削减一半，百姓还是受害了，何不把诸侯王完全废除掉来保全那里的人民呢？汉朝的情况就是这样。</p><p>　　今天国家完全实行郡县制，不断地任命郡县长官，这种情况是肯定不能改变了。只要好好地控制军队，慎重地选择地方官吏，那么政局就会安定了。</p><p>　　有人又说：“夏、商、周、汉四代实行封建制，他们统治的时间都很长久，而秦朝实行郡县制，统治的时间却很短。”这更是不懂得治理国家的人说的话。</p><p>　　魏继承汉朝，分封贵族的爵位仍然实行封建制；西晋继承魏，因袭旧制不加改变，但魏和晋都很快就衰亡了，没听说有国运长久的。唐朝纠正魏晋的过失改变了制度，享国已近二百年，国家基业更加巩固，这与分封诸侯又有什么关系呢？</p><p>　　有人又认为：“治理商、周二代的是圣明的君王啊，他们都没有改变封建制，那么，本来就不应当再议论这件事了。”这种说法大大的不对。</p><p>　　商、周二代没有废除封建制，是不得已的。因为当时归附商朝的诸侯有三千个，商朝靠了他们的力量才灭掉了夏，所以商汤就不能废除他们；归附周朝的诸侯有八百个，周朝凭借他们的力量才战胜了商朝，所以周武王也不能废弃他们。沿用它来求得安定，因袭它来作为习俗，这就是商汤、周武王不得不这样做的原因。他们是不得已的，并不是什么大公无私的美德，而是有私心，是要使诸侯为自己出力，并保卫自己的子孙。秦朝用废除分封诸侯的办法来作为制度，是最大的公；它的动机是为私的，是皇帝想要巩固个人的权威，使天下的人都臣服于自己。但是废除分封，以天下为公，却是从秦朝开始的。</p><p>　　至于天下的常理，是治理得好、政局安定，这才能得到人民的拥护。使贤明的人居上位，不肖的人居下位，然后才会清明安定。封建制的君长，是一代继承一代地统治下去的。这种世袭的统治者，居上位的果真贤明吗？居下位的真的不肖吗？这样，人民究竟是得到太平还是遭遇祸乱，就无法知道了。如果想要对国家有利而统一人民的思想，而同时又有世袭大夫世世代代统治他们的封地，占尽了诸侯国的全部国土，即使有圣人贤人生在那个时代，也会没有立足之地，这种后果就是封建制造成的。难道是圣人的制度要使事情坏到这种地步吗？所以我说：“这不是圣人的本意，而是形势发展的结果。”</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="Literature" scheme="https://zhang21.github.io/categories/Literature/"/>
    
    
      <category term="古文" scheme="https://zhang21.github.io/tags/%E5%8F%A4%E6%96%87/"/>
    
      <category term="政论文" scheme="https://zhang21.github.io/tags/%E6%94%BF%E8%AE%BA%E6%96%87/"/>
    
      <category term="柳宗元" scheme="https://zhang21.github.io/tags/%E6%9F%B3%E5%AE%97%E5%85%83/"/>
    
  </entry>
  
</feed>
