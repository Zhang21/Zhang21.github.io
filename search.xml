<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[OpenShift]]></title>
    <url>%2F2019%2F03%2F26%2FOpenShift%2F</url>
    <content type="text"><![CDATA[参考: Wikipedia OpenShift docs: https://docs.openshift.com 环境: RHELx86_64 OpenShift v3.11]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>OpenShift</tag>
        <tag>PaaS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZooKeeper]]></title>
    <url>%2F2019%2F03%2F15%2FZooKeeper%2F</url>
    <content type="text"><![CDATA[参考: 维基百科 ZooKeeper: https://zookeeper.apache.org/ Docs: https://zookeeper.apache.org/doc/ 环境: RHEL7x86_64 ZooKeeper v3.5 介绍 ZooKeeper: Because Coordinating Distributed Systems is a Zoo. Apache ZooKeeper 是Apache软件基金会的一个软件项目，它为大型分布式计算提供开源的分布式配置服务、同步服务和命名注册，实现高度可靠的分布式协调。ZooKeeper曾经是Hadoop的一个子项目，但现在是一个独立的顶级项目。 ZooKeeper 是一种集中式服务，用于维护配置信息(conf info)，命名(naming)，分布式同步(distributed synchronization)，组服务(group service)。所有这些类型的服务都以分布式应用程序的某种形式应用。每次实施它们都需要做很多工作来修复不可避免的错误和竞争条件。由于难以实现这些类型的服务，应用程序最初通常会吝啬它们，这使得它们在变化的情况下变得脆弱并且难以管理。即使正确完成，这些服务的不同实现也会在部署应用程序时导致管理复杂性。 ZooKeeper的架构通过冗余服务实现高可用性。因此，如果第一次无应答，客户端就可以询问另一台ZooKeeper主机。ZooKeeper节点将它们的数据存储于一个分层的命名空间，非常类似于一个文件系统或一个前缀树结构。客户端可以在节点读写，从而以这种方式拥有一个共享的配置服务。更新是全序的。 概述ZooKeeper: A Distributed Coordination Service for Distributed Applications ZooKeeper 是一种用于分布式应用程序的分布式开源协调(coordination)服务。它被设计为易于编程，并使用在熟悉的文件系统目录树结构之后设计的数据模型。它在Java中运行，并具有Java和C的绑定。 众所周知，协调服务很难做到。他们特别容易出现竞赛条件(race conditions)和死锁(deadlock)。ZooKeeper背后的动机是减轻分布式应用程序从头开始实施协调服务的责任。 设计目标Design Goals ZooKeeper is simple ZooKeeper允许分布式进程通过 共享的层级命名空间(shared hierarchal namespace) 相互协调，该命名空间的组织方式与标准文件系统类似。命名空间由 数据寄存器(data registers) 组成——在ZooKeeper用语中被称为 znodes，这些与文件和目录类似。与专为存储而设计的典型文件系统不同，ZooKeeper数据保存在内存中，这意味着ZooKeeper可以实现高吞吐量(high throughput)和低延迟数(latency numbers)。 ZooKeeper的实现非常重视 高性能(high performance)， 高可用(highly available)， 严格有序的访问(strictly ordered access)。性能方面意味着它可以在大型分布式系统中使用。可靠性方面使其不会成为单点故障(a single point of failure)。严格的排序意味着可以在客户端实现复杂的同步原语。 ZooKeeper is replicated 与它协调的分布式进程一样，ZooKeeper本身也可以在称为 集合(ensemble) 的一组主机上进行 副本复制(replicated)。 组成ZooKeeper服务的Server必须了解彼此。它们维护一个内存中的状态镜像，以及持久性存储的事务日志和快照。只要大多数Servers可用，ZooKeeper服务就可用。 Client连接到单个Server。Client维护TCP连接，通过该连接发送请求，获取响应，获取监视事件(watch events)，以及发送心跳(heart beats)。如果与Server的TCP连接中断，则Client将连接到其它Server。 ZooKeeper is ordered ZooKeeper使用反映所有ZooKeeper事务顺序的数字标记每个更新。后续操作可以使用该顺序来实现更高级别的抽象，例如同步原语。 ZooKeeper is fast 它在读取 read-doninant 工作负载中特别快。ZooKeeper应用程序运行在成千上万的计算机上，并且在读取别写入更常见的情况下(比率10:1)表现最佳。 数据模型和分层命名空间Data model and the hierarchical namespace ZooKeeper提供的命名空间非常类似于标准文件系统。名称是由斜杠(/)分隔的路径元素序列。ZooKeeper命名空间中的每个节点都由路径标识。 节点和短暂节点Nodes and ephemeral nodes 与标准文件系统不同，ZooKeeper命名空间中的每个节点都可包含与之关联的数据以及孩子。这就像拥有一个允许文件也是目录的文件系统。ZooKeeper旨在存储协调数据：状态信息，配置，位置信息等，因此存储在每个节点的数据通常很小。我们使用术语 znode 来表明我们正在谈论的ZooKeeper数据节点。 Znodes 维护一个 状态结构(stat structure)，其中包括数据更改、ACL更改、时间戳更改，以允许缓存验证和协调更新。每次znode的数据更改时，版本号都会增加。例如，每当Client检索数据时，它也接收数据的版本。 存储在每个znode命名空间中的数据以原子(atomically)方式进行读写。读取与znode关联的所有数据字节，写入替换所有的数据。每个节点都有一个ACL限制谁可以做什么。 ZooKeeper也有 短暂节点(ephemeral nodes) 的概念。只要创建的znode处于活动状态，就会存在这些znode，回话结束时，znode将被删除。当你想要实现 [tbd] 时，短暂节点很有用。 协调更新和监视Conditional updates and watches ZooKeeper支持监视(watch)的概念。Client可以在znode上设置监视。当znode更改时，将触发并删除监视。触发监视时，Client会受到一个数据包，指出znode已更改。如果Client与其中一个ZooKeeper Server之间的连接中断，则Client将收到本地通知。这可以用于 [tbd] 。 保证Guarantees ZooKeeper非常快速和简单。但是，由于基于目标是构建更复杂的服务(如同步)的基础，因此它提供了一系列保证。这些是: 顺序一致性(Sequential Consistency): Client的更新将按发送顺序来应用 原子性(Atomicity): 更新成功或失败，没有其它结果 单系统镜像(Single System Image): 无论连接到哪个Server，Client都将看到相同的服务视图 可靠性(Reliability): 一旦更新被应用，它将从该时间开始持续，知道Client覆盖此更新 时宜性(Timeliness): 系统的Client视图保证在特定的时间范围内是最新的 APIZooKeeper的设计目标之一是提供非常简单的编程接口。因此，它仅支持以下操作: create: creates a node at a location in the tree delete: deletes a node exists: tests if a node exists at a location get data: reads the data from a node set data: writes data to a node get children: retrieves a list of children of a node sync: waits for data to be propagated 执行Implementation ZooKeeper组件显示了ZooKeeper服务的高级组件。除了请求处理器，构成ZooKeeper服务的每个Server都复制自己每个组件的副本。 副本数据库是一个包含整个数据树的内存数据库。更新将记录到磁盘以获得可恢复性，并且在写入内存数据库之前会序列化的磁盘 每个ZooKeeper Server都为Client服务。Client只连接到一台Server以提交请求。读取请求由每个Server数据库的本地副本提供。更改服务状态的请求，写请求由 协定协议(agreement protocol) 处理 作为协定协议的一部分，来自Client的所有写入请求都被转发到称为 leader 的单个Server。其余的ZooKeeper Server，称为follower，接收来自leader的消息提议并同意消息传递。消息传递层负责替换失败的leader，并将follower与leader同步 ZooKeeper使用自定义的原子消息(atomic messaging)协议。由于消息传递层是原子的，因此ZooKeeper可以保证本地副本永远不会发散。当leader收到写入请求时，它会计算应用写入时系统的状态，并将其转换为捕获此新状态的事务。 用户ZooKeeper的编程接口非常简单。但是，通过它，您可以实现更高阶的操作，例如同步原语，组成员身份，所有权等。 性能Performance ZooKeeper旨在提供高性能。在读取数量超过写入的应用程序中，它的性能尤其高，因为写入涉及同步所有Server的状态。 The events marked in the figure are the following: Failure and recovery of a follower Failure and recovery of a different follower Failure of the leader Failure and recovery of two followers Failure of another leader 入门ZooKeeper Getting Started Guide]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Apache</tag>
        <tag>DataAnalysis</tag>
        <tag>ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HBase]]></title>
    <url>%2F2019%2F03%2F15%2FHBase%2F</url>
    <content type="text"><![CDATA[参考: 维基百科 HBase: https://hbase.apache.org/ Reference Guide: http://hbase.apache.org/book.html 环境: RHEL7x86_64 HBase v3.0 介绍 Apache HBase 是Hadoop数据库，是一个分布式(distributed)，可扩展(scalable)的大数据存储。 当你需要对大数据进行随机(random)，实时(realtime)R/W访问时，请使用Apache HBase。它的目标是在硬件集群上托管非常大的表——数十亿行数百万列。 HBase是一个开源的非关系型分布式数据库（NoSQL），它参考了谷歌的BigTable建模，实现的编程语言为 Java。它是Apache软件基金会的Hadoop项目的一部分，运行于HDFS文件系统之上，为 Hadoop 提供类似于BigTable 规模的服务。因此，它可以对稀疏文件提供极高的容错率。 HBase在列上实现了BigTable论文提到的压缩算法、内存操作和布隆过滤器。HBase的表能够作为MapReduce任务的输入和输出，可以通过Java API来访问数据，也可以通过REST、Avro或者Thrift的API来访问。 特点Features 线性和模块化可扩展性 严格一致的读写操作 表的自动和可配置分片 支持RegionServers之间的自动故障转移 方便的基类，用于使用Apache HBase表支持Hadoop MapReduce作业 易于使用的Java API，用于客户端访问 阻止缓存和bloom过滤器以进行实时查询 Query predicate push down via server side Filters Thrift gateway和REST-ful Web service，支持XML， Protobuf， binary data encoding 可扩展的基于JRuby的（JIRB）shell 支持通过Hadoop Metrics子系统将指标导出到文件或其它 … 入门Getting Started Standalone HBase本节介绍在单节点的standalone实例上运行HBase。Standalone instance 包含了所有的HBase Daemons(Master, RegionServers, Zookeeper)，在单个JVM中运行并持久化到本地文件系统。这是一个最基本的配置，将展示如何使用HBase shell CLI在HBase中创建表、在表中插入行、对表执行放置和扫描操作、启用/禁用表、启动和停止HBase。 JDKHBase要求安装JDK。 使用HBase步骤: 下载 配置 启动 使用 停止 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 访问Apache DownLoad Mirrors，下载对应版本HBase# https://www.apache.org/dyn/closer.lua/hbase/cd optwget http://mirror.bit.edu.cn/apache/hbase/3.0.0/hbase-3.0.0-bin.tar.gz# 解压tar xzvf hbase-3.0.0-SNAPSHOT-bin.tar.gzmv hbase-3.0.0-SNAPSHOT hbasecd hbase# 启动前必须先设置JAVA_HOME环境变量# conf/hbase-env.shexport JAVA_HOME=/usr/java/jdk1.8.0_191-amd64# 编辑conf/hbase-site.xml，这是主要的HBase配置文件# 您需要在本地文件系统上指定HBase和ZooKeeper写入数据并确认一些风险的目录# 栗子&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;file:///home/testuser/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/home/testuser/zookeeper&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;description&gt; Controls whether HBase will check for stream capabilities (hflush/hsync). Disable this if you intend to run on LocalFileSystem, denoted by a rootdir with the &apos;file://&apos; scheme, but be mindful of the NOTE below. WARNING: Setting this to false blinds you to potential data loss and inconsistent system state in the event of process and/or node failures. If HBase is complaining of an inability to use hsync or hflush it&apos;s most likely not a false positive. &lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt;# start a standalone instance of HBase# 一个JVM运行 HMaster, HRegionServer, Zookeeperbin/start-hbase.sh# http://localhost:16010 查看HBase Web UI 你不需要创建HBase数据目录，它会自动做这件事。如果你创建目录，HBase将尝试进行迁移，这不是你想要的。 要在现有的HDFS实例上安装HBase，请将 hbase.rootdir 设置为指向实例上的目录(如: hdfs://namenode.example.org:8020/hbase)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990# 使用hbase shell命令连接到HBase/bin/hbase shellxxxxxxxx2.3.7 :001 &gt;# 显示帮助&gt; help# 创建表，你必须指定 Table name和ColumnFamily name&gt; create 't-test', 'c-test'Took 1.7627 seconds =&gt; Hbase::Table - t-test# 也可在Web UI上查看相关信息# 列出表信息&gt; list 'c-test'TABLEt-test1 row(s)Took 0.0520 seconds =&gt; ["t-test"]&gt; describe 't-test'Table t-test is ENABLEDt-testCOLUMN FAMILIES DESCRIPTION&#123;NAME =&gt; 'c-test', VERSIONS =&gt; '1', EVICT_BLOCKS_ON_CLOSE =&gt; 'false', NEW_VERSION_BEHAVIOR =&gt; 'false', KEEP_DELETED_CELLS =&gt; 'FALSE', CACHE_DATA_ON_WRITE =&gt; 'false', DATA_BLOCK_ENCODING=&gt; 'NONE', TTL =&gt; 'FOREVER', MIN_VERSIONS =&gt; '0', REPLICATION_SCOPE =&gt; '0', BLOOMFILTER =&gt; 'ROW', CACHE_INDEX_ON_WRITE =&gt; 'false', IN_MEMORY =&gt; 'false', CACHE_BLOOMS_ON_WRITE =&gt; 'false', PREFETCH_BLOCKS_ON_OPEN =&gt; 'false', COMPRESSION =&gt; 'NONE', BLOCKCACHE =&gt; 'true', BLOCKSIZE =&gt; '65536'&#125;1 row(s)Took 0.2293 seconds# 将数据放入表中&gt;put 't-test', 'row1', 'c-test:a', 'value1'Took 0.2116 seconds&gt; put 't-test', 'row2', 'c-test:b', 'value2'Took 0.0082 seconds&gt; &gt; put 't-test', 'row3', 'c-test:c', 'value3'Took 0.0085 seconds# 一次扫描表中所有数据&gt; scan 't-test'&gt; scan 't-test'ROW COLUMN+CELL row1 column=c-test:a, timestamp=1552630577582, value=value1 row2 column=c-test:b, timestamp=1552630591734, value=value2 row3 column=c-test:c, timestamp=1552630598817, value=value3# 获取单行数据&gt; get 't-test' 'row1'COLUMN CELL c-test:a timestamp=1552630577582, value=value11 row(s)Took 0.0225 seconds# 禁用/启用表&gt; disable 't-test'&gt; enable 't-test'# 删除表&gt; drop 't-test'# 退出HBase Shell&gt; quit# stop a standalone instance of HBase# 可能需要几分钟，请耐心等待bin/stop-hbase.sh 伪分布式本地安装Pseudo-Distributed Local Install 通过standalone模式之后，你可以重新配置HBase以伪分布式模式(Pseudo-Distributed)运行。伪分布式意味着HBase仍然在单个主机上运行，但每个HBase Daemons(HMaster, HRegionServer, Zookeeper)作为一个单独的进程运行。默认数据存储在/tmp下，除非你像Standalone一样配置了rootdir。 假设将数据存储在HDFS中，并且HDFS可用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# Stop HBase if it is running.# 配置HBase# 编辑hbase-site.xml# 添加指示HBase以分布式模式运行，每个守护进程有一个JVM实例&lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;# 使用 hdfs://// URI语法将hbase.rootdir从本地文件系统更改为HDFS实例的地址，地址请查看HDFS配置# 请确保删除hbase.unsafe.stream.capability.enforce的条目或将其设置为true# 你不需要在HDFS中创建目录，HBase会为你做这件事。如果您创建目录，HBase将尝试进行迁移，这不是您想要的&lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://localhost:8020/hbase&lt;/value&gt;&lt;/property&gt;# 启动HBasebin/start-hbase.sh# 如果系统配置正确，则jps显示正在运行的HBase进程jps20065 HMaster20006 HQuorumPeer20137 HRegionServer20521 Jps# 检查HDFS中的HBase目录# 如果一切正常，HBase会在HDFS中创建它的目录# 注意HDFS的安全模式bin/hadoop fs -ls /hbaseFound 1 itemsdrwxr-xr-x - zhang supergroup 0 2019-03-15 15:33 /hbase/.tmp# 创建一个表，并用数据填充它# 创建放入和前面一样# 启动/停止一个 backup HBase Master Server(HMaster)# 在同一硬件上运行多个HMaster实例在生产环境中没有意义，就像运行伪分布式集群对生产没有意义一样。此步骤仅用于测试和学习/bin/local-master-backup.sh start 2 3 5# 在不杀死整个集群的情况下终止backup mastercat /tmp/hbase-testuser-1-master.pid |xargs kill -9# 启动/停止additional RegionServers# 在同一系统上运行多个HRegionServers对于以伪分布式模式进行测试非常有用。bin/local-regionservers.sh start 2 3 4bin/local-regionservers.sh stop 3# 停止HBasebin/stop-hbase.sh 分布式Advanced - Fully Distributed 实际上，你需要完全分布式(fully-distributed)配置才能完全测试HBase并在实际场景中使用它。在分布式配置中，集群包含多个节点，每个节点运行一个或多个HBase守护进程(包括: Primary Master, Backup Master, Multiple ZooKeeper nodes, Multiple RegionServer nodes)。 分布式集群架构Distributed Cluster Demo Architecture Node Name Master ZooKeeper RegionServer node-a.example.com yes yes no node-b.example.com backup yes yes node-c.example.com no yes yes 确保集群之间的可访问性。 SSH免密Configure Passwordless SSH Access 12345678910111213# 生成公钥ssh-keygen -t rsa# 写入公钥cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys# 注意修改权限# 测试免密登录ssh user@hostname 准备集群node-a 将运行 Primary Master, ZooKeeper, no RegionServers. 1234567891011121314151617181920212223# 配置conf/regionservers# 删除node-a的RegionServer地址，并添加node-b, node-c的RegionServer地址# node-b.example.com, node-c.example.comconf/regionservers# 配置HBase使用node-b作为 Backup Master# 创建 conf/backup-masters，并使用 node-b的主机名为其添加新行conf/backup-masters# 配置ZooKeeper# 实际情况中，你应该仔细考虑ZooKeeper配置# node-a, conf/hbase-site.xml&lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;node-a.example.com,node-b.example.com,node-c.example.com&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/usr/local/zookeeper&lt;/value&gt;&lt;/property&gt; node-b 将运行 backup master, ZooKeeper instance。 123# 复制 node-a conf/ 到 node-b, node-c conf/# 集群中的每个节点都需要具有相同的配置# 请注意不同节点的localhost这个地址 配置完成后，便要启动并测试集群。 1234567891011121314151617181920212223# Be sure HBase is not running on any node# Start the cluster# On node-a, node-b, node-cbin/start-hbase.sh# ZooKeeper starts first, followed by the master, then the RegionServers, and finally the backup masters.# Verify that the processes are runningjps# Browse to the Web UI# Test what happens when nodes or services disappear# 测试可用性 配置Apache HBase Configuration]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Apache</tag>
        <tag>DataAnalysis</tag>
        <tag>HBase</tag>
        <tag>NoSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flume]]></title>
    <url>%2F2019%2F03%2F07%2FFlume%2F</url>
    <content type="text"><![CDATA[参考: wikipedia Flume: https://flume.apache.org/ Flume docs: https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html 环境: ELRH7x86_64 Flume v1.9.0 介绍 Apache Flume 是一种分布式，可靠且可用的软件，使用Java编写，用于高效收集(collecting)，聚合(aggregating)和移动(moving)大量日志数据。它具有基于流数据流(stream data flows)的简单灵活的架构。它具有可靠性机制和许多故障转移和恢复机制，具有强大的容错能力。它使用简单的可扩展数据模型，允许在线分析应用程序。 Apache Flume的使用不仅限于日志数据聚合。由于数据源是可定制的，因此Flume可用于传输大量事件数据，包括但不限于网络流量数据，社交媒体生成的数据，电子邮件消息以及几乎任何可能的数据源。 系统要求 Java: Java 1.8+ Mem: sources, channels, sinks有足够的内存 Disk: channels, sinks有足够的磁盘空间 Directory Permissions: Agent使用的目录的读写权限 架构 数据流模型Data flow model 源(Source) 通道(Channel) 接收器(Sink) 事件(Event) Flume event 被定义为具有字节(byte)有效负载可可选字符串属性集的数据流单元(unit of data flow)。Flume agent是一个(JVM)进程，它承载事件从外部源流向下一个目标的组件。 Flume源消费事件(source consumes events)通过外部源(external source)(如WebServer)传递给它。外部源通过目标Flume源(target Flume source)识别的格式向Flume发送事件。当Flume源接收事件时，它会将其存储到一个或多个通道(channels)中。通道是一个被动存储，可以保持事件直到它被Flume sink所消费。接收器从通道中移除事件，并将其放入外部存储库(如HDFS)或将其转发到流中的下一个Flume Agent(next hop)的Flume Source。给定Agent中的Source和Sink与Channel中暂存的Events异步运行。 复杂流Complex flows Flume允许用户构建多跳(hop)流，其中事件在到达最终目的地之前经过多个代理。它还允许 fan-in 和 fan-out flows, 上下文路由(contextual routing), 故障跳跃的备份路由(故障转移)。 可靠性Reliability 事件在每个Agent的通道中进行，然后将事件传递到流中的下一个代理或终端存储库(如HDFS)。只有将事件存储在下一个代理的通道或终端存储库之后，才会从通道中删除这些事件。这就是Flume中的单跳消息传递语义如何提供流的端到端可靠性。 Flume使用事务方法来保证事件的可靠传递。源和接收器分别在事务中封装由信道提供的事务中放置/提供的事件的存储(storage)/检索(retrieval)。这可确保事件集在流中从一个点到另一个点可靠地传递。在多跳流的情况下，来自前一跳的接收器和来自下一跳的源都运行其事务以确保数据安全地存储在下一跳的信道中。 可恢复性Recoverability 事件在通道中进行，该通道管理从故障中恢复。Flume支持由本地文件系统支持的持久化(durable)文件通道。还有一个内存通道(memory channel)，它将事件存储到内存中的队列中，这更快，但是当代理进程死亡时仍然存留在内存通道中的任何事件都无法恢复。 设置Setup 设置代理Setting up an agent Flume Agent配置文件存储在本地配置文件中。这是一个Java properties文件格式的文本文件。可以在同一个配置文件中指定一个或多个代理的配置。配置文件包括代理中的每个Source, Sink, Channel的属性，以及它们如何连接在一起以形成数据流。 配置单个组件Configuring individual components 流中的每个组件(source, sink, channel)都具有特定于类型和实例化的名称(name)，类型(type)，属性集(properties)。 连接各个部分Wiring the pieces together Agent需要知道加载哪些组件，以及它们如何连接以构成流。这是通过列出代理中每个源，接收器和通道的名称，然后为每个接收器和源指定连接通道来完成的。 启动代理Starting an agent 下载Flume发型版，使用名为flume-ng的shell脚本启动代理程序。 1234# 你需要在命令行上指定代理名称、配置目录、配置文件bin/flume-ng agent -n $agent_name -c conf -f conf/flume-conf.properties.template# 现在，代理开始运行在给定属性文件中配置的源和接收器 一个栗子下面给出一个示例配置文件。此配置允许用户生成事件，并将其记录到console: 1234567891011121314151617181920212223# example.conf: A single-node Flume configuration# Name the components on this agenta1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = netcata1.sources.r1.bind = localhosta1.sources.r1.port = 44444# Describe the sinka1.sinks.k1.type = logger# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 12# 运行它bin/flume-ng agent --conf conf --conf-file example.conf --name a1 -Dflume.root.logger=INFO,console 在配置文件中使用环境变量Using environment variables in configuration files Flume能够替换配置中的环境变量: 12345a1.sources = r1a1.sources.r1.type = netcata1.sources.r1.bind = 0.0.0.0a1.sources.r1.port = $&#123;NC_PORT&#125;a1.sources.r1.channels = c1 注意: 环境变量目前只使用于Value，不适用于Key。 记录原始数据Logging raw data 在许多生产环境中记录流经管道的原始数据流不是所希望的行为，因为这可能导致泄露敏感数据或安全相关配置到Flume日志文件。默认情况下，Flume不会记录此类信息。另一方法，如果数据管道出错，Flume也将尝试提供DEBUG信息。 为了能够记录事件和配置相关的数据，除了 log4j 属性外，还必须设置一些Java系统属性。要启用与配置相关的日志记录，请设置Java系统属性 -Dorg.apache.flume.log.printconfig=true 。这也可以在命令行上进行传递，也可以在 flume-env.sh 中的 JAVA_OPTS 变量中设置。 要启用数据记录，请按照上述相同方式设置Java系统属性 -Dorg.apache.flume.log.rawdata=true 。对于大多数组件，还必须将 log4j 日志记录级别设置为DEBUG或TRACE，以使特定于事件的日志记录显示在Flume日志中。 12# 启用配置日志记录和原始数据日志记录的示例，同时还将Log4j日志级别设置为DEBUG以用于控制台输出bin/flume-ng agent --conf conf --conf-file example.conf --name a1 -Dflume.root.logger=DEBUG,console -Dorg.apache.flume.log.printconfig=true -Dorg.apache.flume.log.rawdata=true Zookeeeper基础配置Zookeeper based Configuration Flume支持通过Zookeeper配置Agent的配置。这是一个实验性功能。配置文件需要在可配置前缀下的Zookeeper中上传。配置文件存储在Zookeeper Node Data中。 1234# Agent1和Agent2的Zookeeper Node Tree的示例- /flume |- /a1 [Agent config file] |- /a2 [Agent config file] 一旦上传了配置文件，使用以下选项启动Agent: 1234# -z, Zookeeper connection string. Comma separated list of hostname:port# -p, Base Path in Zookeeper to store Agent configurations bin/flume-ng agent –conf conf -z zkhost:2181,zkhost1:2181 -p /flume –name a1 -Dflume.root.logger=INFO,console 安装第三方插件Installing third-party plugins Flume拥有完整的基于插件的架构。虽然Flume附带了许多开箱即用的sources, channels, sinks, serializers…但许多实现斗鱼Flume分开运行。 虽然通过将自己的jar包添加到 flume-env.sh 文件中的 FLUME_CLASSPATH 变量值，始终可以包含自定义Flume组件。但Flume现在支持一个名为 plugins.d 的特殊目录，该目录会自动获取以特定格式打包的插件。 插件目录The plugins.d directory plugins.d 目录位于 $FLUME_HOME/plugins.d。在启动时，flume-ng 启动脚本在 plugins.d 目录中查找符合以下格式的插件，并在启动java时将它们包含在正确的路径中。 插件目录布局Directory layout for plugins plugins.d 中的每个插件(子目录)最多可以有三个子目录: lib - the plugin’s jar(s) libext - the plugin’s dependency jar(s) native - any required native libraries, such as .so files 栗子: 1234567plugins.d/plugins.d/custom-source-1/plugins.d/custom-source-1/lib/my-source.jarplugins.d/custom-source-1/libext/spring-core-2.5.6.jarplugins.d/custom-source-2/plugins.d/custom-source-2/lib/custom.jarplugins.d/custom-source-2/native/gettext.so 数据摄取Data ingestion Flume支持许多从外部源摄取数据的机制。 RPC可使用RPC机制将给定文件发送到Flume Source: 123# 栗子# 将日志内容发送到监听该端口的Flume Sourcebin/flume-ng avro-client -H localhost -p 41414 -F /usr/logs/log.10 执行命令Executing commands 有一个exec source执行给定的命令并消费输出。 网路流Network streams Flume支持以下机制从常用日志流(log stream)类型中读取数据。如: Avro Thrift Syslog Netcat 多个代理流Setting multi-agent flow 为了跨多个代理/跳(multiple agents/hops)的数据流，先前代理的接收器和当前代理的源是同一类型，接收器指向源的hostname/ip和port。 整合Consolidation 日志收集中非常常见的情况是生成大量日志的客户端将数据发送到连接到存储子系统的少数消费者代理。例如，从数百个Web服务器收集的日志发送给写入HDFS集群的十几个代理。 这可以通过在Flume中使用接收器配置多个第一层代理，所有这些代理都指向单个源。第二层代理商的源将接收的事件合并到单个通道中，该通道有接收器消费到最终的目的地。 多路复用流Multiplexing the flow Flume支持将事件流多路复用到一个或多个目的地。这是通过定义可以复制或选择性地将事件路由到一个或多个通道的流复用器来实现的。 配置Configuration 过滤Configuration Filters]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Apache</tag>
        <tag>DataAnalysis</tag>
        <tag>Flume</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sqoop]]></title>
    <url>%2F2019%2F03%2F07%2FSqoop%2F</url>
    <content type="text"><![CDATA[参考: wikipedia sqoop: https://sqoop.apache.org/ 环境: ELRH7x84_64 Sqoop v1.4.7 简介Apache Sqoop 是一个命令行界面(CLI)的应用程序工具，使用Java开发，用于在关系型数据库和Hadoop之间传输数据。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Apache</tag>
        <tag>DataAnalysis</tag>
        <tag>Sqoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive]]></title>
    <url>%2F2019%2F03%2F06%2FHive%2F</url>
    <content type="text"><![CDATA[参考: wikipedia Hive: https://hive.apache.org/ Hive Wiki: https://cwiki.apache.org/confluence/display/Hive/Home 环境: ELRH7x86_64 Hive v3.1 简介Apache Hive 是一个建立在Hadoop架构之上的数据仓库，由Java编写，能够提供数据的精炼，查询和分析。 Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的SQL查询功能，可以将SQL语句转换为MapReduce任务进行运行。其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。 Apache Hive 数据仓库软件有助于使用SQL读取，编写和管理驻留在分布式存储中的大型数据集。可以将结构投影到已存储的数据中。还提供了命令行工具和JDBC驱动程序以将用户连接到Hive。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Apache</tag>
        <tag>Hive</tag>
        <tag>DataAnalysis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop]]></title>
    <url>%2F2019%2F03%2F06%2FHadoop%2F</url>
    <content type="text"><![CDATA[参考: wikipeadia Hadoop官网: https://hadoop.apache.org/ Apache Software Foundation: https://www.apache.org/ 环境: RHEL7x86_64 Hadoop v3.2.0 简介Apache Hadoop 是一款支持数据密集型分布式应用程序，使用Java编写，并以Apache 2.0许可协议发布的开源软件框架。Hadoop是根据谷歌公司发表的MapReduce和Google文件系统的论文自行实现而成。所有的Hadoop模块都有一个基本假设，即硬件故障是常见情况，应该由框架自动处理。 Apach Hadoop项目开发了用于可靠(Reliable)，可扩展(Scalable)的分布式计算(Distributed Computing)的开源软件。 Hadoop框架透明地为应用提供可靠性和数据移动。它实现了名为MapReduce的编程范式：应用程序被分割成许多小部分，而每个部分都能在集群中的任意节点上运行或重新运行。此外，Hadoop还提供了分布式文件系统，用以存储所有计算节点的数据，这为整个集群带来了非常高的带宽。MapReduce和分布式文件系统的设计，使得整个框架能够自动处理节点故障。它使应用程序与成千上万的独立计算的计算机和PB级的数据连接起来。 ModulesHadoop 项目包括以下模块: Hadoop Common: 支持其它Hadoop模块的常用实用程序 Hadoop Distributed File System (HDFS): 一种分布式文件系统，提供对应用程序数据的高吞吐量访问 Hadoop YARN: 用于作业调度和集群资源管理的框架 Hadoop MapReduce: 基于YARN的系统，用于并行处理大型数据集 Hadoop Ozone: Hadoop的对象存储 Hadoop Submarine: Hadoop的机器学习引擎 相关项目现在普遍认为整个 Apache Hadoop Platform 包括了许多项目: Ambari: 一个基于Web的工具，用于配置，管理和监控Apache Hadoop集群。包括对HDFS, MapReduce, Hive, HBase, ZooKeeper, Pig, Sqoop…的支持。它还提供了一个用于查看群集运行状况的仪表板，用于查看各个程序的状态 Avro：数据序列化系统。新的数据序列化格式与传输工具，将逐步取代Hadoop原有的IPC机制 Cassandra: 可扩展的多主数据库，没有单点故障 Chukwa: 用于管理大型分布式系统的数据收集系统 Flume: 一种分布式，可靠且可用的软件。用于高效收集(collecting)，聚合(aggregating)和移动(moving)大量日志数据 HBase：可扩展的分布式NoSQL列数据库，支持大型表的结构化数据存储。类似谷歌公司BigTable Hive：一种数据仓库基础结构，提供数据摘要和即席查询。构建于hadoop之上的数据仓库，通过一种类SQL语言HiveQL为用户提供数据的归纳、查询和分析等功能。Hive最初由Facebook贡献 Mahout：可扩展的机器学习和数据挖掘库 Pig: 用于并行计算的高级数据流语言和执行框架 Spark: 适用于Hadoop数据的快速通用计算引擎。Spark提供了一种简单而富有表现力的编程模型，支持广泛的应用程序 Sqoop：结构化数据（如关系数据库）与Apache Hadoop之间的数据转换工具 Tez: 基于Hadoop YARN的通用数据流编程框架，它提供了一个强大而灵活的引擎来执行任意DAG任务来处理批处理和交互式用例的数据 ZooKeeper：适用于分布式应用程序的高性能协调服务。提供类似Google Chubby的功能，由Facebook贡献 General 概述Overview Node Attributes Support in YARN 节点属性(Node Attribute)有助于根据节点标记(tag)节点上的多个标签(label)，并支持根据这些标签的表达式放置容器。 Hadoop Submarine on YARN Hadoop Submarine 使数据工程师能够在数据所在的同一Hadoop YARN集群上轻松开发(develop)、训练(train)和部署(deploy)深度学习模型(TensorFlow)。 Storage Policy Satisfier 支持HDFS(Hadoop Distributed File System)应用程序，以便在文件/目录上设置存储策略时在存储类型之间移动块(block)。 ABFS Filesystem connector 支持最新的Azure Datalake Gen2 Storage。 Enhanced S3A connector 支持增强型S3A连接器，包括更好地恢复受限制的AWS S3和DynamoDB IO。 Upgrades for YARN long running services 支持通过YARN Native Service API和CLI对长时间运行的容器进行就地无缝(seamless)升级。 单节点集群Setting up a Single Node Cluster 目的本节介绍如何设置和配置单节点Hadoop集群，以便你可以快速使用Hadoop MapReduce和HDFS执行简单的操作。 先决条件 支持的平台 GNU/Linux: Hadoop has been demonstrated on GNU/Linux clusters with 2000 nodes Windows is also a supported platform but the followings steps are for Linux only. 依赖软件(Linux) Java: 具体版本参考 HadoopJavaVersions ssh: 必须运行sshd才能使用管理远程Hadoop守护程序的Hadoop脚本，建议按照pdsh以实现更好的ssh资源管子 安装软件 12# Ubuntusudo apt-get install ssh pdsh 下载获取Hadoop发行版，请从Apache Download Mirrors下载。 准备启动Hadoop集群解压前面下载的Hadoop发行版，编辑hadoop/etc/hadoop/hadoop-env.sh以定义一些参数: 123456789# hadoop/etc/hadoop/hadoop-env.sh# set to the root of your Java installationexport JAVA_HOME=/usr/java/jdk1.8.0_191-amd64export HADOOP_HOME= /opt/hadoop# 由于我是使用rpm安装jdk8，所以为/usr/java/jdk1.8.0_191-amd64# 我的hadoop放置于/opt/hadoop 接着运行以下命令: 123./bin/hadoop# 这将显示Hadoop的使用文档 有三种方式来启动Hadoop集群: Local (Standalone) Mode Pseudo-Distributed Mode Fully-Distributed Mode Standalone默认情况下，Hadoop配置为non-distibuted模式运行，作为单个Java进程。这对调试很有用。 Pseudo-Distributed OperationHadoop也可以运行在伪分布模式下的单节点上，其中每个Hadoop Daemon在单独的java进程中运行。 配置hadoop/etc/hadoop/core-site.xml: 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hadoop/etc/hadoop/hdfs-site.xml: 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 设置 passphraseless ssh 123456789101112# 检查是否可以下无密码(passphrase)的情况下ssh到localhostssh localhost# 如果不行，请执行无密码登录操作ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsacat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keyschmod 0600 ~/.ssh/authorized_keys# 之后再执行此操作ssh localhost 执行 以下说明在本地运行MapReduce job。 123456789101112131415161718192021222324252627282930313233343536373839# 注意，以下位于hadoop目录# 我的为 /opt/hadoop# 1. Format the filesystem# namenode - run the DFS namenodebin/hdfs namenode -format# 2. Start NameNode daemon and DataNode daemonsbin/start-dfs.sh# 日志输出到$HADOOP_HOME/logs# 3. Browse the web interface for the NameNode; by default it is available at:NameNode - http://localhost:9870/# 4. Make the HDFS directories required to execute MapReduce jobsbin/hdfs dfs -mkdir /userbin/hdfs dfs -mkdir /user/&lt;username&gt;# 5. Copy the input files into the distributed filesystembin/hdfs dfs -mkdir inputbin/hdfs dfs -put etc/hadoop/*.xml input# 6. Run some of the examples providedbin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.0.jar grep input output 'dfs[a-z.]+'# 7. Examine the output files: Copy the output files from the distributed filesystem to the local filesystem and examine thembin/hdfs dfs -get output output# cat output/*# bin/hdfs dfs -cat output/*# 8. When you’re done, stop the daemons withsbin/stop-dfs.sh YARN on a Single Node 你可以通过设置一些参数并运行ResourceManager Daemon和NodeManager Daemon，以伪分布模式在YARN上运行MapReduce Job。以下指令假设你已运行上面的1-4步。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 1. Configure parameters as follows# etc/hadoop/mapred-site.xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.application.classpath&lt;/name&gt; &lt;value&gt;$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt;# etc/hadoop/yarn-site.xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt; &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt;# 2. Start ResourceManager daemon and NodeManager daemonsbin/start-yarn.sh# Browse the web interface for the ResourceManager; by default it is available at# ResourceManager - http://localhost:8088/# 4. Run a MapReduce job# 5. When you’re done, stop the daemons withsbin/stop-yarn.sh 集群设置Hadoop Cluster Setup 本节描述了如何安装和配置Hadoop集群，范围从几个节点到数千个节点。但本节不包括安全性和高可用性等高级主题。 Prerequisites Java Hadoop 安装通常，集群中的一台主机被指定为NameNode，而另一台主机被指定为ResourceManager，这些都是Master。其它服务(Web App Proxy Server, MapReduce…)通常在专用硬件或共享基础架构上运行，具体取决于负载。 集群中的其余主机充当DataNode和NodeManager。这些都是Worker。 在非安全模式下配置HadoopConfiguring Hadoop in Non-Secure Mode Hadoop的Java配置由两种类型的重要配置文件驱动: 只读(ReadOnly)的默认配置 core-default.xml hdfs-default.xml yarn-default.xml mapred-default.xml 特定站点(site-specific)的配置 etc/hadoop/core-site.xml etc/hadoop/hdfs-site.xml etc/hadoop/yarn-site.xml etc/hadoop/mapred-site.xml 此外，你可以通过etc/hadoop/hadoop-env.sh和etc/hadoop/yarn-env.sh配置特定于站点的值来控制分发的bin/目录下的Hadoop脚本。 要配置Hadoop Cluster，你需要配置Hadoop Daemon执行的environment以及configuration parameters。 HDFS Daemon是 NameNode, SecondaryNameNode 和 DataNode YARN Daemon是 ResourceManager, NodeManager 和 WebAppProxy 如果要使用MapReduce，则 MapReduce Job History Server 也将运行 对于大型安装，这些通常在不同的主机上运行 配置Hadoop守护进程的环境Configuring Environment of Hadoop Daemons 管理员应该使用 etc/hadoop/hadoop-env.sh， 可选择 etc/hadoop/mapred-env.sh, 以及 etc/hadoop/yarn-env.sh脚本来对Hadoop守护进程的进程环境进行特定站点的自定义配置。 至少，您必须指定 JAVA_HOME，以便在每个远程节点上正确定义它。 管理员可使用下表中的配置项配置各个守护进程: Daemon Environment Variable NameNode HDFS_NAMENODE_OPTS DataNode HDFS_DATANODE_OPTS Secondary NameNode HDFS_SECONDARYNAMENODE_OPTS ResourceManager YARN_RESOURCEMANAGER_OPTS NodeManager YARN_NODEMANAGER_OPTS WebAppProxy YARN_PROXYSERVER_OPTS Map Reduce Job History Server MAPRED_HISTORYSERVER_OPTS 其它你可自定义的有用的配置项包括: HADOOP_PID_DIR: The directory where the daemons’ process id files are stored HADOOP_LOG_DIR: The directory where the daemons’ log files are stored. Log files are automatically created if they don’t exist HADOOP_HEAPSIZE_MAX: The maximum amount of memory to use for the Java heapsize. Units supported by the JVM are also supported here. If no unit is present, it will be assumed the number is in megabytes. By default, Hadoop will let the JVM determine how much to use. This value can be overriden on a per-daemon basis using the appropriate _OPTS variable listed above. For example, setting HADOOP_HEAPSIZE_MAX=1g and HADOOP_NAMENODE_OPTS=”-Xmx5g” will configure the NameNode with 5GB heap. 在大多数情况下，你需要指定 HADOOP_PID_DIR 和 HADOOP_LOG 目录，以便它们只能由将要运行Hadoop守护进程的用户写入。否则可能会发生符号链接攻击。 配置Hadoop守护进程Configuring the Hadoop Daemons 本节介绍给定配置文件中指定的重要参数。 etc/hadoop/core-site.xml Parameter Value Notes fs.defaultFS NameNode URI hdfs://host:port/ io.file.buffer.size 131072 Size of read/write buffer used in SequenceFiles. etc/hadoop/hdfs-site.xml NameNode配置 Parameter Value Notes dfs.namenode.name.dir Path on the local filesystem where the NameNode stores the namespace and transactions logs persistently. If this is a comma-delimited list of directories then the name table is replicated in all of the directories, for redundancy. dfs.hosts / dfs.hosts.exclude List of permitted/excluded DataNodes. If necessary, use these files to control the list of allowable datanodes. dfs.blocksize 268435456 HDFS blocksize of 256MB for large file-systems. dfs.namenode.handler.count 100 More NameNode server threads to handle RPCs from large number of DataNodes. DataNode配置 Parameter Value Notes dfs.datanode.data.dir Comma separated list of paths on the local filesystem of a DataNode where it should store its blocks. If this is a comma-delimited list of directories, then data will be stored in all named directories, typically on different devices. etc/hadoop/yarn-site.xml ResourceManager和NodeManager配置 Parameter Value Notes yarn.acl.enable true / false Enable ACLs? Defaults to false. yarn.admin.acl Admin ACL ACL to set admins on the cluster. ACLs are of for comma-separated-usersspacecomma-separated-groups. Defaults to special value of * which means anyone. Special value of just space means no one has access. yarn.log-aggregation-enable false Configuration to enable or disable log aggregation ResourceManager配置 Parameter Value Notes yarn.resourcemanager.address ResourceManager host:port for clients to submit jobs. host:port If set, overrides the hostname set in yarn.resourcemanager.hostname. yarn.resourcemanager.scheduler.address ResourceManager host:port for ApplicationMasters to talk to Scheduler to obtain resources. host:port If set, overrides the hostname set in yarn.resourcemanager.hostname. yarn.resourcemanager.resource-tracker.address ResourceManager host:port for NodeManagers. host:port If set, overrides the hostname set in yarn.resourcemanager.hostname. yarn.resourcemanager.admin.address ResourceManager host:port for administrative commands. host:port If set, overrides the hostname set in yarn.resourcemanager.hostname. yarn.resourcemanager.webapp.address ResourceManager web-ui host:port. host:port If set, overrides the hostname set in yarn.resourcemanager.hostname. yarn.resourcemanager.hostname ResourceManager host. host Single hostname that can be set in place of setting all yarn.resourcemanager*address resources. Results in default ports for ResourceManager components. yarn.resourcemanager.scheduler.class ResourceManager Scheduler class. CapacityScheduler (recommended), FairScheduler (also recommended), or FifoScheduler. yarn.scheduler.minimum-allocation-mb Minimum limit of memory to allocate to each container request at the Resource Manager. In MBs yarn.scheduler.maximum-allocation-mb Maximum limit of memory to allocate to each container request at the Resource Manager. In MBs yarn.resourcemanager.nodes.include-path / yarn.resourcemanager.nodes.exclude-path List of permitted/excluded NodeManagers. If necessary, use these files to control the list of allowable NodeManagers. NodeManager配置 Parameter Value Notes yarn.nodemanager.resource.memory-mb Resource i.e. available physical memory, in MB, for given NodeManager Defines total available resources on the NodeManager to be made available to running containers yarn.nodemanager.vmem-pmem-ratio Maximum ratio by which virtual memory usage of tasks may exceed physical memory The virtual memory usage of each task may exceed its physical memory limit by this ratio. The total amount of virtual memory used by tasks on the NodeManager may exceed its physical memory usage by this ratio. yarn.nodemanager.local-dirs Comma-separated list of paths on the local filesystem where intermediate data is written. Multiple paths help spread disk i/o. yarn.nodemanager.log-dirs Comma-separated list of paths on the local filesystem where logs are written. Multiple paths help spread disk i/o. yarn.nodemanager.log.retain-seconds 10800 Default time (in seconds) to retain log files on the NodeManager Only applicable if log-aggregation is disabled. yarn.nodemanager.remote-app-log-dir /logs HDFS directory where the application logs are moved on application completion. Need to set appropriate permissions. Only applicable if log-aggregation is enabled. yarn.nodemanager.remote-app-log-dir-suffix logs Suffix appended to the remote log dir. Logs will be aggregated to ${yarn.nodemanager.remote-app-log-dir}/${user}/${thisParam} Only applicable if log-aggregation is enabled. yarn.nodemanager.aux-services mapreduce_shuffle Shuffle service that needs to be set for Map Reduce applications. yarn.nodemanager.env-whitelist Environment properties to be inherited by containers from NodeManagers For mapreduce application in addition to the default values HADOOP_MAPRED_HOME should to be added. 可能的值有: JAVA_HOME, HADOOP_COMMON_HOME, HADOOP_HDFS_HOME, HADOOP_CONF_DIR, CLASSPATH_PREPEND_DISTCACHE, HADOOP_YARN_HOME, HADOOP_MAPRED_HOME History Server配置 Parameter Value Notes yarn.log-aggregation.retain-seconds -1 How long to keep aggregation logs before deleting them. -1 disables. Be careful, set this too small and you will spam the name node. yarn.log-aggregation.retain-check-interval-seconds -1 Time between checks for aggregated log retention. If set to 0 or a negative value then the value is computed as one-tenth of the aggregated log retention time. Be careful, set this too small and you will spam the name node. etc/hadoop/mapred-site.xml MapReduce Applications配置 Parameter Value Notes mapreduce.framework.name yarn Execution framework set to Hadoop YARN. mapreduce.map.memory.mb 1536 Larger resource limit for maps. mapreduce.map.java.opts -Xmx1024M Larger heap-size for child jvms of maps. mapreduce.reduce.memory.mb 3072 Larger resource limit for reduces. mapreduce.reduce.java.opts -Xmx2560M Larger heap-size for child jvms of reduces. mapreduce.task.io.sort.mb 512 Higher memory-limit while sorting data for efficiency. mapreduce.task.io.sort.factor 100 More streams merged at once while sorting files. mapreduce.reduce.shuffle.parallelcopies 50 Higher number of parallel copies run by reduces to fetch outputs from very large number of maps. MapReduce JobHistory Server配置 Parameter Value Notes mapreduce.jobhistory.address MapReduce JobHistory Server host:port Default port is 10020. mapreduce.jobhistory.webapp.address MapReduce JobHistory Server Web UI host:port Default port is 19888. mapreduce.jobhistory.intermediate-done-dir /mr-history/tmp Directory where history files are written by MapReduce jobs. mapreduce.jobhistory.done-dir /mr-history/done Directory where history files are managed by the MR JobHistory Server. 监控NodeManager健康Monitoring Health of NodeManagers Hadoop提供了一种机制，管理员可通过该机制将NodeManager定期运行提供的脚本，以确定节点是否健康。 管理员可通过在脚本中执行对其选择的任何检查来确定节点是否处于正常状态。如果脚本检测到节点处于不健康状态，则必须以ERROR开头的字符串将其行输出到标准输出(std out)。NodeManager定期生成脚本并检查其输出。如果脚本的输出包含字符串ERROR(如上所述)，则节点的状态将报告为不健康(unhealthy)，并且ResourceManager将节点列入黑名单。之后便不会为此节点分配其它任务。但是，NodeManager继续运行脚本，因此如果节点再次变为健康(healthy)，它将自动从ResourceManager上的黑名单节点中被删除。在ResourceManger Web UI中，管理员可以使用节点的运行状况以及脚本的输出(如果不健康)。自节点健康依赖的时间也显示在Web UI上。 以下 etc/hadoop/yarn-site.xml 文件中的参数可用于控制节点健康监控脚本: Parameter Value Notes yarn.nodemanager.health-checker.script.path Node health script Script to check for node’s health status. yarn.nodemanager.health-checker.script.opts Node health script options Options for script to check for node’s health status. yarn.nodemanager.health-checker.interval-ms Node health script interval Time interval for running health script. yarn.nodemanager.health-checker.script.timeout-ms Node health script timeout interval Timeout for health script execution. 如果只有部分本地磁盘变坏，则运行健康检查的脚本不应该给出ERROR信息。NodeManager能够定期检查本地磁盘的运行状况（具体检查 nodemanager-local-dirs 和 nodemanager-log-dirs ），并在根据为配置属性 yarn.nodemanager.disk-health-checker.min-healthy-disks 设置的值达到坏目录数阈值(threshold of number of bad directories)，整个节点被标记为不健康，此信息也被发送到ResourceManager。引导磁盘(boot disk)中的故障也会被检查脚本所识别。 Slaves File在 etc/hadoop/workers 文件中列出所有Worker的hostname或IP addr，每行一个。帮助脚本将使用 etc/hadoop/workers 文件一次在多个主机上运行命令。它不用于任何基于Java的Hadoop配置。要使用此功能，必须为用于运行Hadoop的账户建立SSH信任(SSH无秘钥或Kerberos)。 Rack Awareness许多Hadoop组件都具有机架感知(rack-aware)功能，并利用网络拓扑结构提高性能和安全。Hadoop Daemons通过调用管理员配置的模块来获取集群中Workers的机架信息。 强烈建议在启动HDFS之前配置Rack Awareness！ LoggingHadoop通过Apache Commons Logging框架使用Apache log4j进行日志记录。编辑 etc/hadoop/log4j.properties 文件以自定义Hadoop Daemons的日志记录配置。 操作集群Operating the Hadoop Cluster 完成所有必要的配置后，将文件分发到所有主机上的 HADOOP_CONF_DIR 目录。这应该是所有主机上的同一个目录。 通常，建议HDFS和YARN使用分开的用户来运行。在大多数安装中，HDFS进程以hdfs用户运行；YARN使用yarn用户运行。 Startup and ShutdownHadoop Startup and Hadoop Shutdown 要启动Hadoop集群，你需要启动HDFS和YARN集群。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# 第一次启动HDFS时，必须对其进行格式化。将新的分布式文件系统(distributed fs)格式化为hdfs[hdfs]$ $HADOOP_HOME/bin/hdfs namenode -format &lt;cluster_name&gt;# 在指定节点以hdfs启动HDFS NameNode[hdfs]$ $HADOOP_HOME/bin/hdfs --daemon start namenode# 停止NameNode[hdfs]$ $HADOOP_HOME/bin/hdfs --daemon stop namenode# 在每个指定节点以hdfs启动HDFS DataNode[hdfs]$ $HADOOP_HOME/bin/hdfs --daemon start datanode# 停止DataNode[hdfs]$ $HADOOP_HOME/bin/hdfs --daemon stop datanode# 如果配置了 etc/hadoop/worker 和 SSH信任，则可以使用使用程序脚本以hdfs启动HDFS进程[hdfs]$ $HADOOP_HOME/sbin/start-dfs.sh# 停止HDFS进程[hdfs]$ $HADOOP_HOME/sbin/stop-dfs.sh# SSH trusted accessssh-keygen -t rsa -P '' -f ~/.ssh/id_rsacat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keyschmod 0600 ~/.ssh/authorized_keys# 也可将已有的公钥直接写入# 以yarn在指定的ResourceManager上启动YARN[yarn]$ $HADOOP_HOME/bin/yarn --daemon start resourcemanager# 停止ResourceManager[yarn]$ $HADOOP_HOME/bin/yarn --daemon stop resourcemanager# 以yarn在每台指定主机上运行脚本启动NodeManager[yarn]$ $HADOOP_HOME/bin/yarn --daemon start nodemanager# 停止NodeManager[yarn]$ $HADOOP_HOME/bin/yarn --daemon stop nodemanager# 以yarn在WebAppProxy Server上启动Standalone WebAPPProxy Server# 如果使用多个Server进行负载均衡，则应在每台Server上运行[yarn]$ $HADOOP_HOME/bin/yarn --daemon start proxyserver# 停止WebAppProxy server[yarn]$ $HADOOP_HOME/bin/yarn stop proxyserver# 如果配置了 etc/hadoop/workers 和 SSH信任，则可以以yarn实用程序脚本启动YARN进程[yarn]$ $HADOOP_HOME/sbin/start-yarn.sh# 停止YARN进程[yarn]$ $HADOOP_HOME/sbin/stop-yarn.sh# 以mapred在指定的服务器上运行MapReduce JobHistory Server[mapred]$ $HADOOP_HOME/bin/mapred --daemon start historyserver# 停止MapReduce JobHistory Server[mapred]$ $HADOOP_HOME/bin/mapred --daemon stop historyserver Web Interfaces一旦Hadoop Cluster启动并运行，请检查组件的Web UI。具体如下: Daemon Web Interface Notes NameNode http://nn_host:port/ Default HTTP port is 9870 ResourceManager http://rm_host:port/ Default HTTP port is 8088 MapReduce JobHistory Server http://jhs_host:port/ Default HTTP port is 19888 命令Hadoop Commands Guide 概述所有Hadoop命令和子项目都遵循相同的基本结构: 12# Usageshellcommand [SHELL_OPTIONS] [COMMAND] [GENERIC_OPTIONS] [COMMAND_OPTIONS] Shell Options 1234567891011121314151617--buildpaths Enables developer versions of jars.--config confdir Overwrites the default Configuration directory. Default is $HADOOP_HOME/etc/hadoop.--daemon mode If the command supports daemonization (e.g., hdfs namenode), execute in the appropriate mode. Supported modes are start to start the process in daemon mode, stop to stop the process, and status to determine the active status of the process. status will return an LSB-compliant result code. If no option is provided, commands that support daemonization will run in the foreground. For commands that do not support daemonization, this option is ignored.--debug Enables shell level configuration debugging information--help Shell script usage information.--hostnames When --workers is used, override the workers file with a space delimited list of hostnames where to execute a multi-host subcommand. If --workers is not used, this option is ignored.--hosts When --workers is used, override the workers file with another file that contains a list of hostnames where to execute a multi-host subcommand. If --workers is not used, this option is ignored.--loglevel loglevel Overrides the log level. Valid log levels are FATAL, ERROR, WARN, INFO, DEBUG, and TRACE. Default is INFO.--workers If possible, execute this command on all hosts in the workers file. Generic Options 1234567-archives &lt;comma separated list of archives&gt; Specify comma separated archives to be unarchived on the compute machines. Applies only to job.-conf &lt;configuration file&gt; Specify an application configuration file.-D &lt;property&gt;=&lt;value&gt; Use value for given property.-files &lt;comma separated list of files&gt; Specify comma separated files to be copied to the map reduce cluster. Applies only to job.-fs &lt;file:///&gt; or &lt;hdfs://namenode:port&gt; Specify default filesystem URL to use. Overrides ‘fs.defaultFS’ property from configurations.-jt &lt;local&gt; or &lt;resourcemanager:port&gt; Specify a ResourceManager. Applies only to job.-libjars &lt;comma seperated list of jars&gt; Specify comma separated jar files to include in the classpath. Applies only to job. 常用命令Hadoop Common Commands 所有这些命令都是从hadoop命令执行的。它分为: 用户命令(User Commands): 对hadoop集群的用户有用的命令 管理命令(Administration Commands): 对hadoop集群的管理员有用的命令 用户命令1234567891011121314151617181920archive #Creates a hadoop archivechecknative #This command checks the availability of the Hadoop native codeclasspath #Prints the class path needed to get the Hadoop jar and the required librariesconftest #Validates configuration XML filescredential #Command to manage credentials, passwords and secrets within credential providers.distch #Change the ownership and permissions on many files at once.distcp #Copy file or directories recursively.dtutil #Utility to fetch and manage hadoop delegation tokens inside credentials filesfs #This command is documented in the File System Shell Guide.gridmix #Gridmix is a benchmark tool for Hadoop clusterjar #Runs a jar file.jnipath #Print the computed java.library.path.kerbname #Convert the named principal via the auth_to_local rules to the Hadoop user name.kdiag #Diagnose Kerberos Problemskey #Manage keys via the KeyProviderkms #Run KMS, the Key Management Server.trace #View and modify Hadoop tracing settingsversion #Prints the version.CLASSNAME #Runs the class named CLASSNAME. The class must be part of a package.envvars #Display computed Hadoop environment variables. 管理命令123456789101112131415# Usagehadoop daemonlog -getlevel &lt;host:port&gt; &lt;classname&gt; [-protocol (http|https)]hadoop daemonlog -setlevel &lt;host:port&gt; &lt;classname&gt; &lt;level&gt; [-protocol (http|https)]# 栗子bin/hadoop daemonlog -setlevel 127.0.0.1:9870 org.apache.hadoop.hdfs.server.namenode.NameNode DEBUGbin/hadoop daemonlog -getlevel 127.0.0.1:9871 org.apache.hadoop.hdfs.server.namenode.NameNode DEBUG -protocol https# 还有以下守护进程Common #key management serverHDFS #name node, secondary name node, data node, journal node, HttpFS serverYARN #resource manager, node manager, Timeline server 文件12345678910# hadoop shell commands全局设置etc/hadoop/hadoop-env.sh# 此文件允许高级用户覆盖某些shell 功能etc/hadoop/hadoop-user-functions.sh# 用户个人环境~/.hadooprc FS ShellFileSystem Shell FS Shell包括了各种类似于shell的命令，它们直接与Hadoop分布式文件系统(HDFS)以及Hadoop支持的其它文件系统交互(如: Local FS, WebHDMIFS, S3 FS…) All FS shell commands take path URIs as arguments. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169# 调用方式bin/hadoop fs &lt;args&gt;# Append single src, or multiple srcs from local file system to the destination file system hadoop fs -appendToFile &lt;localsrc&gt; ... &lt;dst&gt;# Copies source paths to stdout.hadoop fs -cat [-ignoreCrc] URI [URI ...]# Returns the checksum information of a filehadoop fs -checksum URI# Change group association of fileshadoop fs -chgrp [-R] GROUP URI [URI ...]# Similar to the fs -put command, except that the source is restricted to a local file reference.hadoop fs -copyFromLocal &lt;localsrc&gt; URI# Similar to get command, except that the destination is restricted to a local file referencehadoop fs -copyToLocal [-ignorecrc] [-crc] URI &lt;localdst&gt;# Count the number of directories, files and bytes under the paths that match the specified file patternhadoop fs -count [-q] [-h] [-v] [-x] [-t [&lt;storage type&gt;]] [-u] [-e] &lt;paths&gt;# Copy files from source to destinationhadoop fs -cp [-f] [-p | -p[topax]] URI [URI ...] &lt;dest&gt;createSnapshotdeleteSnapshotrenameSnapshot# Displays free spacehadoop fs -df [-h] URI [URI ...]# Displays sizes of files and directories contained in the given directory or the length of a file in case its just a file.hadoop fs -du [-s] [-h] [-v] [-x] URI [URI ...]# Displays a summary of file lengths.hadoop fs -dus &lt;args&gt;# Permanently delete files in checkpoints older than the retention threshold from trash directory, and create new checkpoint.hadoop fs -expunge# Finds all files that match the specified expression and applies selected actions to themhadoop fs -find &lt;path&gt; ... &lt;expression&gt; ...# Copy files to the local file systemhadoop fs -get [-ignorecrc] [-crc] [-p] [-f] &lt;src&gt; &lt;localdst&gt;# Copy files to the local file systemhadoop fs -get [-ignorecrc] [-crc] [-p] [-f] &lt;src&gt; &lt;localdst&gt;# Displays the Access Control Lists (ACLs) of files and directorieshadoop fs -getfacl [-R] &lt;path&gt;# Displays the extended attribute names and values (if any) for a file or directoryhadoop fs -getfattr [-R] -n name | -d [-e en] &lt;path&gt;# Takes a source directory and a destination file as input and concatenates files in src into the destination local filehadoop fs -getmerge [-nl] &lt;src&gt; &lt;localdst&gt;# Displays first kilobyte of the file to stdout.hadoop fs -head URI# Return usage output.hadoop fs -helphadoop fs -ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] &lt;args&gt;# Recursive version of lshadoop fs -lsr &lt;args&gt;# Takes path uri’s as argument and creates directories.hadoop fs -mkdir [-p] &lt;paths&gt;# Similar to put command, except that the source localsrc is deleted after it’s copied.hadoop fs -moveFromLocal &lt;localsrc&gt; &lt;dst&gt;# Displays a “Not implemented yet” message.hadoop fs -moveToLocal [-crc] &lt;src&gt; &lt;dst&gt;# Moves files from source to destination. This command allows multiple sources as well in which case the destination needs to be a directory. Moving files across file systems is not permitted.hadoop fs -mv URI [URI ...] &lt;dest&gt;# Copy single src, or multiple srcs from local file system to the destination file system. Also reads input from stdin and writes to destination file system if the source is set to “-”hadoop fs -put [-f] [-p] [-l] [-d] [ - | &lt;localsrc1&gt; .. ]. &lt;dst&gt;# Delete files specified as argshadoop fs -rm [-f] [-r |-R] [-skipTrash] [-safely] URI [URI ...]# Delete a directoryhadoop fs -rmdir [--ignore-fail-on-non-empty] URI [URI ...]# Recursive version of deletehadoop fs -rmr [-skipTrash] URI [URI ...]# Sets Access Control Lists (ACLs) of files and directorieshadoop fs -setfacl [-R] [-b |-k -m |-x &lt;acl_spec&gt; &lt;path&gt;] |[--set &lt;acl_spec&gt; &lt;path&gt;]# Sets an extended attribute name and value for a file or directoryhadoop fs -setfattr -n name [-v value] | -x name &lt;path&gt;# Changes the replication factor of a file. If path is a directory then the command recursively changes the replication factor of all files under the directory tree rooted at path. The EC files will be ignored when executing this commandhadoop fs -setrep [-R] [-w] &lt;numReplicas&gt; &lt;path&gt;# Print statistics about the file/directory at &lt;path&gt; in the specified formathadoop fs -stat [format] &lt;path&gt; ...# Displays last kilobyte of the file to stdouthadoop fs -tail [-f] URIhadoop fs -test -[defsz] URI# Takes a source file and outputs the file in text format. The allowed formats are zip and TextRecordInputStream.hadoop fs -text &lt;src&gt;# Updates the access and modification times of the file specified by the URI to the current time.hadoop fs -touch [-a] [-m] [-t TIMESTAMP] [-c] URI [URI ...]# Create a file of zero length. An error is returned if the file exists with non-zero lengthhadoop fs -touchz URI [URI ...]# Truncate all files that match the specified file pattern to the specified length.hadoop fs -truncate [-w] &lt;length&gt; &lt;paths&gt;# Return the help for an individual commandhadoop fs -usage command 使用对象存储Working with Object Storage The Hadoop FileSystem shell works with Object Stores such as Amazon S3, Azure WASB and OpenStack Swift. 兼容性规范Apache Hadoop Compatibility Specification 目的本节介绍Apache Hadoop项目的兼容性目标。所有Hadoop Interface都根据目标受众和稳定性进行分类，以保持与先前版本的兼容性。 本文档供Hadoop开发人员社区使用。 开发者兼容指南Apache Hadoop Downstream Developer’s Guide 目的本文档的目的是为下游开发人员提供明确的参考，以便在针对Hadoop源代码库构建应用程序时提供什么。本文档主要是Hadoop兼容性指南的精华，因此重点介绍了跨版本的各种Hadoop接口的兼容性保证。 管理兼容指南Apache Hadoop Admin Compatibility Guide 目的本文档的目的是将Hadoop兼容性指南提炼为与系统管理员相关的信息。 目标受众是负责维护Apache Hadoop集群以及必须规划和执行集群升级的管理员。 发行版Hadoop Releases Hadoop开发社区定期发布新的Hadoop Release，以引入新功能并修复现有问题。发新版分为三类: Major: 主要版本通常包含重要的新功能，通常代表最大的升级兼容性风险。(如 2.8.2 to 3.0.0) Minor: 次要版本通常会包含一些新功能以及针对某些值得注意的问题的修复程序。在大多数情况下，次要版本不应造成太大的升级风险。(如2.8.2 to 2.9.0) Maintenance: 维护版本不应包含任何新功能。维护版本的目的是解决开发人员社区认为足够重要的一组问题，以便推动新版本解决这些问题。维护版本的升级风险很小。(如2.8.2 to 2.8.3) 平台依赖Platform Dependencies Hadoop所依赖的本机组件集被视为Hadoop ABI的一部分。Hadoop开发社区致力于尽可能地保持ABI兼容性。在次要版本之间，除非必要，否则不会增加Hadoop本机依赖项的最低支持版本号，例如安全性或许可问题。 Hadoop依赖于JVM(Java Virtual Machine)。支持的最低版本的JVM在主要版本的Hadoop之间不会发生变化。 网络Network Hadoop依赖于某些传输层技术，如SSL。除非必要，否则不会增加这些依赖项的最低支持版本，例如安全性或许可问题。 Hadoop服务端口号将在主要版本中保持不变，但可能会在次要版本中更改。 Hadoop内部线程协议(wire protocol)将在同一主要版本中的次要版本进行向后和向前兼容，以实现滚动升级。 脚本和自动化Scripting and Automation REST APIsHadoop REST APTs提供了一种简单的机制，用于收集有关Hadoop系统状态的信息。为了支持REST客户端，Hadoop REST API是版本化的，并且在版本中不会发生不兼容的更改。REST API版本是单个数字，与Hadoop版本号无关。 解析Hadoop输出Parsing Hadoop Output Hadoop可以生成各种输出，可通过自动化工具进行解析。在使用Hadoop输出时，请考虑一下事项: 除非解决了正确性问题，否则Hadoop日志输出不会随维护版本而更改 Hadoop为各种操作生成审计日志(audit log)。审计日志旨在是机器可读，但新纪录和字段的添加被认为是兼容的更改 Hadoop生成的度量数量(metrics data)主要用于自动化处理。 CLIsHadoop的命令行集提供了管理系统各个方面以及发现系统状态信息的能力。请注意，CLI工具输出与CLI工具生成的日志输出不同。日志输出不适合自动消费，可能随时更改。 Web UIHadoop公开的Web UI供人类使用。 状态数据Hadoop State Data Hadoop内部系统状态是私有的，不应直接被修改。以下策略管理各种内部状态存储的升级特征: 内部MapReduce状态数据在同一主要版本中的次要版本之间保持兼容，以便在MapReduce工作负载执行时促进滚动升级 HDFS以版本化的私有内部格式维护存储在HDFS中的数据的元数据。 AWS S3防护保留了版本化的私有内部元数据存储。不兼容的更改将导致版本号递增。 YARN 资源管理器保留版本化的应用程序和调度程序信息的内部状态存储。 YARN联合身份验证服务保留应用程序的私有内部状态存储以及版本化的群集信息。 配置Hadoop Configurations Hadoop使用两种主要形式的配置文件: XML配置文件和日志记录配置文件。 XML配置文件 XML配置文件包含了一组属性作为键值对。属性的名称和含义由Hadoop定义，并保证在次要版本中稳定。属性只能在主要版本中删除，并且只有在至少完整主要版本被标记为已弃用时才能删除。大多数属性都有一个默认值，如果未在XML配置文件中显式设置该属性，则将使用该值。 下游项目和用户可以将自己的属性添加到XML配置文件中，以供其工具和应用程序使用。虽然Hadoop对定义新属性没有任何正式限制，但与Hadoop定义的属性冲突的新属性可能会导致意外和不良结果。建议用户避免使用与Hadoop定义的属性的名称空间冲突的自定义配置属性名称。 日志记录配置文件 Hadoop Daemon和CLI生成的日志输出由一组配置文件控制。这些文件控制将由Hadoop的各个组件输出的最小日志消息级别，以及这些消息的存储位置和方式。 其它配置文件 Hadoop使用各种格式的许多其它类型的配置文件，如JSON或XML。 发行版Hadoop Distribution 配置文件 Hadoop配置文件的位置和一般结构，作业历史信息和Hadoop生成的日志文件将在维护版中得到维护。 JARs Hadoop发行版的内容，如JAR文件可能随时更改，Client artifact除外，不应视为可靠。当前客户端工具有: hadoop-client hadoop-client-api hadoop-client-minicluster hadoop-client-runtime hadoop-hdfs-client hadoop-hdfs-native-client hadoop-mapreduce-client-app hadoop-mapreduce-client-common hadoop-mapreduce-client-core hadoop-mapreduce-client-jobclient hadoop-mapreduce-client-nativetask hadoop-yarn-client ENV 一些Hadoop组件通过环境变量接收信息。 库依赖 Hadoop依赖于大量第三方库来运行。 硬件和系统依赖 Hadoop目前由运行在x86和AMD处理器上的Linux和Windows上的Hadoop开发人员社区提供支持。无法保证Hadoop守护程序所需的最低资源如何在发行版之间发生变化，甚至是维护版本。任何支持Hadoop的文件系统，例如通过FileSystem API，在大多数情况下将继续在主要版本中得到支持。 接口分类Interface Classification 文件系统规范The Hadoop FileSystem API Definition 这是Hadoop FS API的规范，它将文件系统的内容建模为一组路径(目录、文件、符号链接)。Unix文件系统有多种规范作为inode树，但没有任何公开定义 Unix文件系统作为数据存储访问的概念模型 的概念。 该规范视图这样做，定义Hadoop FS模型和API，以便多个文件系统可实现API并向应用程序提供其数据的一致模型。除了记录HDFS所展示的行为之外，它不会尝试正式指定文件系统的任何并发行为，因为这些行为是Hadoop客户端应用程序通常所期望的。 介绍 注释Notation 模型Model 文件系统类FileSystem class FSDataInputStream class FSDataOutputStreamBuilder class 使用文件系统规范进行测试Testing with the Filesystem specification 扩展规范及测试Extending the specification and its tests Common CLI MiniCluster 目的使用 CLI MiniCluster，用户只需使用一个命令即可启动和停止单节点Hadoop集群，而无需设置任何环境变量或管理配置文件。CLI MiniCluster启用 YARN、MapReduce和HDFS集群。 这对于希望快速试验Hadoop集群或测试依赖于Hadoop工具的程序的用户来说非常有用。 Hadoop Tarball你要从发行版中获取Hadoop Tarball。此外，你也可以从源直接创建Tarball: 12345# 请首先下载源码包并解压# tarball在hadoop-dist/target/目录# cd hadoop-3.2.0-srcmvn clean install -DskipTestsmvn package -Pdist -Dtar -DskipTests -Dmaven.javadoc.skip 运行MiniCluster从提取的Tarball目录内部，你可使用以下命令启动CLI MiniCluster: 123456789101112131415161718192021# RM_PORT, JHS_PORT应替换为用户对这些端口号的选择，如果未指定，将使用随机空闲端口bin/mapred minicluster -rmport RM_PORT -jhsport JHS_PORT# 命令行参数$ -D &lt;property=value&gt; Options to pass into configuration object$ -datanodes &lt;arg&gt; How many datanodes to start (default 1)$ -format Format the DFS (default false)$ -help Prints option help.$ -jhsport &lt;arg&gt; JobHistoryServer port (default 0--we choose)$ -namenode &lt;arg&gt; URL of the namenode (default is either the DFS$ cluster or a temporary dir)$ -nnport &lt;arg&gt; NameNode port (default 0--we choose)$ -nnhttpport &lt;arg&gt; NameNode HTTP port (default 0--we choose)$ -nodemanagers &lt;arg&gt; How many nodemanagers to start (default 1)$ -nodfs Don't start a mini DFS cluster$ -nomr Don't start a mini MR cluster$ -rmport &lt;arg&gt; ResourceManager port (default 0--we choose)$ -writeConfig &lt;path&gt; Save configuration to this XML file.$ -writeDetails &lt;path&gt; Write basic information to this JSON file. 原生库Native Libraries Guide 本节介绍原生(native)Hadoop库，并包含了有关共享库的讨论。 出于性能原因和Java实现的不可用性，Hadoop具有某些组件的原生实现。这些组件在单个动态链接的本机库可用，称为本机(原生)Hadoop库(libhadoop.so)。 使用使用原生Hadoop库相当容易: 审阅组件 审阅支持的平台 下载Hadoop发行版(库名: libhadoop.so) 安装解码器开发包(&gt;zlib-1.2, &gt;gzip-1.2) 检查运行日志 组件原生Hadoop库包括各种组件: Compression Codecs (bzip2, lz4, snappy, zlib) Native IO utilities for HDFS Short-Circuit Local Reads and Centralized Cache Management in HDFS CRC32 checksum implementation 支持的平台原生Hadoop库主要用于GNU/Linux平台，并在这些发行版上进行测试: RHEL4/Fedora Ubuntu Gentoo 构建原生Hadoop库使用 ANSI C编写，使用GNU autotools-chain 构建。你需要在目标平台上安装的软件包: C compiler (e.g. GNU C Compiler) GNU Autools Chain: autoconf, automake, libtool zlib-development package (stable version &gt;= 1.2.0) openssl-development package(e.g. libssl-dev) 安装必备软件包后，使用标准的Hadoop Pox.xml 文件来构建原生Hadoop库: 1234mvn package -Pdist,native -DskipTests -Dtar# You should see the newly-built library inhadoop-dist/target/hadoop-3.2.0/lib/native Runtimebin/hadoop 脚本通过系统属性(-Djava.library.path=&lt;path&gt;)确保原生Hadoop库位于库路径上。 在运行时，检查hadoop日志文件以查找MapReduce任务。 检查12# 原生库检查其检查是否正确加载hadoop checknative -a Proxy UserProxy user - Superusers Acting On Behalf Of Other Users 本节介绍超级用户(super user)如何代表另一个用户提交作业(submit job)或访问HDFS。 用例用户名为super的超级用户希望代表用户userA提交作业并访问HDFS。某人任务需要以userA身份运行，并且namenode上的任何文件都需要以userA的身份完成。这要求用户userA可连接到使用super用户的kerberos凭据连接到namenode。换句话说，super模仿用户userA。 代码栗子super超级用户的凭据用于登录，并为joe创建代理用户对象。 1234567891011121314...//Create ugi for joe. The login user is &apos;super&apos;.UserGroupInformation ugi = UserGroupInformation.createProxyUser(&quot;joe&quot;, UserGroupInformation.getLoginUser());ugi.doAs(new PrivilegedExceptionAction&lt;Void&gt;() &#123; public Void run() throws Exception &#123; //Submit a job JobClient jc = new JobClient(conf); jc.submitJob(conf); //OR access hdfs FileSystem fs = FileSystem.get(conf); fs.mkdir(someFilePath); &#125;&#125; 配置你可以使用hadoop.proxyuser属性(properties)来配置代理用户。$superuser.hosts以及hadoop.proxyuser.$superuser.groups, hadoop.proxyuser.$superuser.users其中的一个或两个。 在core-site.xml中，名为super的超级用户只能充host1, host2上进行连接，用于模拟group1, group2。 12345678&lt;property&gt; &lt;name&gt;hadoop.proxyuser.super.hosts&lt;/name&gt; &lt;value&gt;host1,host2&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.super.groups&lt;/name&gt; &lt;value&gt;group1,group2&lt;/value&gt;&lt;/property&gt; 如果需要更为宽松的安全性，则可以使用通配符: 12345678&lt;property&gt; &lt;name&gt;hadoop.proxyuser.oozie.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.oozie.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt; 当然，它也接受CIDR格式的ip地址范围或主机名: 12345678&lt;property&gt; &lt;name&gt;hadoop.proxyuser.super.hosts&lt;/name&gt; &lt;value&gt;10.222.0.0/16,10.113.221.221&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.super.users&lt;/name&gt; &lt;value&gt;user1,user2&lt;/value&gt;&lt;/property&gt; 警告如果集群运行在安全模式(secure mode)下，则超级用户必须具有kerberos凭据才能模拟其他用户。 Rack AwarenessRack Awareness Hadoop组件具有机架感知功能(rack-aware)。例如，通过将一个块副本(block replica)放在不同的机架上，HDFS块放置将使用机架感知来实现容错(fault tolerance)。可以在网络故障或分区时提供数据可用性。 Hadoop主守护进程(master daemon)通过调用配置文件指定的external scripts或java class来获取集群工作者的rack id。输出必须遵守 java org.apache.hadoop.net.DNSToSwitchMapping interface，接口需要保持一对一的对应关系。 要使用 java class 进行拓扑映射，类名由配置文件中的 net.topology.node.switch.mapping.impl 参数指定。如果想实现外部脚本，将使用配置文件中的 net.topology.script.file.name 参数指定它。如果 net.topology.script.file.name 或 net.topology.node.switch.mapping.impl 没有设置，则会为任何IP返回机器ID。 python栗子123456789101112131415161718192021222324252627282930313233#!/usr/bin/python# this script makes assumptions about the physical environment.# 1) each rack is its own layer 3 network with a /24 subnet, which# could be typical where each rack has its own# switch with uplinks to a central core router.## +-----------+# |core router|# +-----------+# / \# +-----------+ +-----------+# |rack switch| |rack switch|# +-----------+ +-----------+# | data node | | data node |# +-----------+ +-----------+# | data node | | data node |# +-----------+ +-----------+## 2) topology script gets list of IP's as input, calculates network address, and prints '/network_address/ip'.import netaddrimport syssys.argv.pop(0) # discard name of topology script from argv list as we just want IP addressesnetmask = '255.255.255.0' # set netmask to what's being used in your environment. The example uses a /24for ip in sys.argv: # loop over list of datanode IP's address = '&#123;0&#125;/&#123;1&#125;'.format(ip, netmask) # format address string so it looks like 'ip/netmask' to make netaddr work try: network_address = netaddr.IPNetwork(address).network # calculate and print network address print "/&#123;0&#125;".format(network_address) except: print "/rack-unknown" # print catch-all value if unable to calculate network address bash栗子12345678910111213141516171819202122232425262728#!/usr/bin/env bash# Here's a bash example to show just how simple these scripts can be# Assuming we have flat network with everything on a single switch, we can fake a rack topology.# This could occur in a lab environment where we have limited nodes,like 2-8 physical machines on a unmanaged switch.# This may also apply to multiple virtual machines running on the same physical hardware.# The number of machines isn't important, but that we are trying to fake a network topology when there isn't one.## +----------+ +--------+# |jobtracker| |datanode|# +----------+ +--------+# \ /# +--------+ +--------+ +--------+# |datanode|--| switch |--|datanode|# +--------+ +--------+ +--------+# / \# +--------+ +--------+# |datanode| |namenode|# +--------+ +--------+## With this network topology, we are treating each host as a rack. This is being done by taking the last octet# in the datanode's IP and prepending it with the word '/rack-'. The advantage for doing this is so HDFS# can create its 'off-rack' block copy.# 1) 'echo $@' will echo all ARGV values to xargs.# 2) 'xargs' will enforce that we print a single argv value per line# 3) 'awk' will split fields on dots and append the last field to the string '/rack-'. If awk# fails to split on four dots, it will still print '/rack-' last field valueecho $@ | xargs -n 1 | awk -F '.' '&#123;print "/rack-"$NF&#125;' 安全模式Hadoop in Secure Mode 本节介绍如何在 安全模式(secure mode) 下为Hadoop配置身份认证。当Hadoop配置为以安全模式运行时，Hadoop的每个服务和每个用户都必须由Kerberos进行身份认证。必须正确配置所有服务主机的正向(forward)和反向(reverse)查找，以允许服务互相进行身份验证。可使用DNS或/etc/hosts文件配置主机查找(lookup)。在尝试以安全模式配置Hadoop服务之前，建议先了解Kerberos和DNS的工作知识。 认证Authentication End User Accounts启用服务级别身份验证之后，最终用户必须在与Hadoop服务交互之前进行身份认证。最简单的方式是用户使用kerberos kinit cmd以交互方式进行身份认证，或者使用Kerberos keytab文件的编程身份进行认证。 用户账户User Accounts for Hadoop Daemons 确保HDFS和YARN 守护进程以不同的Unix用户运行(如hdfs, yarn)。此外，确保 MapDrduce JobHistory Server以不同的用户运行(如mapred)。建议让他们共享同一个Unix Group。 User:Group Daemons hdfs:hadoop NameNode, Secondary NameNode, JournalNode, DataNode yarn:hadoop ResourceManager, NodeManager mapred:hadoop MapReduce JobHistory Server KerberosKerberos principals for Hadoop Daemons 必须使用其Kerberos pricipal和keytab file配置每个Hadoop Service 实例。服务准则的一般格式是: ServiceName/_HOST@REALM.TLD. e.g. dn/_HOST@EXAMPLE.COM。 Hadoop通过允许将服务主体的主机名组件指定为_HOST通配符来简化配置文件的部署。每个服务实例将在运行时使用自己的完全限定主机名替换_HOST。这允许管理员在所有节点上部署同一组配置文件，但 keytab 文件有所不同。 HDFS 每个NameNode主机上的keytab文件，如下所示: 123456789101112# -e shows the encryption type# -t shows keytab entry timestamps# -k specifies keytabklist -e -k -t /etc/security/keytab/nn.service.keytabKeytab name: FILE:/etc/security/keytab/nn.service.keytabKVNO Timestamp Principal 4 07/18/11 21:08:09 nn/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 nn/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 nn/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5) 4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5) 第二个NameNode主机的keytab文件，如下所示: 123456789klist -e -k -t /etc/security/keytab/sn.service.keytabKeytab name: FILE:/etc/security/keytab/sn.service.keytabKVNO Timestamp Principal 4 07/18/11 21:08:09 sn/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 sn/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 sn/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5) 4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5) 每台主机上的DataNode的keytab文件，如下所示: 123456789klist -e -k -t /etc/security/keytab/dn.service.keytabKeytab name: FILE:/etc/security/keytab/dn.service.keytabKVNO Timestamp Principal 4 07/18/11 21:08:09 dn/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 dn/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 dn/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5) 4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5) YARN 位于ResourceManager主机上的ResourceManager的keytab文件，如下所示: 123456789klist -e -k -t /etc/security/keytab/rm.service.keytabKeytab name: FILE:/etc/security/keytab/rm.service.keytabKVNO Timestamp Principal 4 07/18/11 21:08:09 rm/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 rm/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 rm/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5) 4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5) 每台主机上的NodeManager的keytab文件，如下所示: 123456789klist -e -k -t /etc/security/keytab/nm.service.keytabKeytab name: FILE:/etc/security/keytab/nm.service.keytabKVNO Timestamp Principal 4 07/18/11 21:08:09 nm/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 nm/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 nm/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5) 4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5) MapReduce JobHistory Server 该主机上的MapReduce JobHistory Server的keytab文件，如下所示: 123456789klist -e -k -t /etc/security/keytab/jhs.service.keytabKeytab name: FILE:/etc/security/keytab/jhs.service.keytabKVNO Timestamp Principal 4 07/18/11 21:08:09 jhs/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 jhs/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 jhs/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5) 4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-256 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (AES-128 CTS mode with 96-bit SHA-1 HMAC) 4 07/18/11 21:08:09 host/full.qualified.domain.name@REALM.TLD (ArcFour with HMAC/md5) 从kerberos映射到系统用户账户Mapping from Kerberos principals to OS user accounts Hadoop使用hadoop.security.auth_to_local指定的规则将kerberos principal映射到系统账户。Hadoop如何评估这些规则取决于hadoop.security.auth_to_local.mechanism的设置。 在默认的hadoop模式下，必须将Kerberos主体与将主体转换为简单形式的规则匹配，即不带@, /的用户帐户名，否则将不会授权主体并记录错误。另外，请注意，您不应该将 auth_to_local 规则作为ACL并使用适当的(OS)机制。 auth_to_local可能的值: RULE:exp, 本地名称将由exp指定 DEFAULT, 当且仅当域与 default_realm 匹配时，才将主体名称的第一个组件选为系统用户名 请注意，Hadoop不支持多个默认域。此外，Hadoop不会对映射是否存在本地系统帐户进行验证。 规则栗子Example rules 在典型的集群中，HDFS和YARN服务将分别作为系统hdfs和yarn用户启动。hadoop.security.auth_to_local可做如下配置: 123456789&lt;property&gt; &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt; &lt;value&gt; RULE:[2:$1/$2@$0]([ndj]n/.*@REALM.\TLD)s/.*/hdfs/ RULE:[2:$1/$2@$0]([rn]m/.*@REALM\.TLD)s/.*/yarn/ RULE:[2:$1/$2@$0](jhs/.*@REALM\.TLD)s/.*/mapred/ DEFAULT &lt;/value&gt;&lt;/property&gt; 可以使用 hadoop kerbname 命令测试自定义规则。此命令允许指定主体并应用Hadoop的当前 auth_to_local 规则集。 用户到组的映射Mapping from user to group 可以通过 hadoop.security.group.mapping 配置系统用户到系统组的映射机制。实际上，您需要使用Kerberos和LDAP for Hadoop以安全模式管理SSO环境。 代理用户Proxy user Some products such as Apache Oozie which access the services of Hadoop on behalf of end users need to be able to impersonate end users. Secure DataNode由于DataNode数据传输协议不使用Hadoop RPC框架，因此DataNode必须使用由dfs.datanode.address和dfs.datanode.http.address指定的特权端口对自身进行身份验证。此认证基于以下假设: 攻击者无法在DataNode主机上获得root权限。 当以root身份执行hdfs datanode命令时，服务进程首先绑定特定端口，然后删除特权并以HDFS_DATANODE_SECURE_USER指定的用户账户运行。此启动过程安装到JSVC_HOME的jsvc程序。你必须在启动时将JDFS_DATANODE_SECURE_USER和JSVC_HOME指定为环境变量。(hadoop-env.sh文件中可配置) 数据机密性 Data Encryption on RPC在Hadoop Service 和 Client之间传输的数据可以在线路上加密。在 core-site.xml 中将 hadoop.rpc.protection 设置为 privacy 可激活数据加密。 Data Encryption on Block data transfer需要在 hdfs-site.xml 中将 dfs.encrypt.data.transfer 设置为 true，以便为DataNode 的数据传输协议激活数据加密。 或者，你可将 dfs.encrypt.data.transfer.algorithm 设置为 3des, rc4 以选择特定的加密算法。如果未指定，则使用系统上配置的JCE默认值(3des)。将 dfs.encrypt.data.transfer.cipher.suites 设置为 AES/CTR/NoPadding 可激活AES加密。默认未指定，也就是不使用AES。使用AES时，在初始密钥交换期间仍会使用 dfs.encrypt.dta.transfer.algorithm的算法。可通过将 dfs.encrypt.data.transfer.cipher.key.bitlength 设置为128, 192, 256来配置AES密钥位长度(默认128) AES提供最大的加密强度和最佳性能。目前，3DES和RC4在Hadoop集群中的使用频率更高。 Data Encryption on HTTPweb-console和client之间的数据传输使用SSL(HTTPS)保护。在使用Kerberos配置Hadoop安全时，推荐使用SLL，但不是必须。 要为HDFS Daemon的 web-console 启用SSL，将hdfs-site.xml文件中的dfs.http.policy设置为HTTPS_ONLY或HTTP_AND_HTTPS两者之一。要为YARN Daemon的 web-console 启用SSL，将yarn-site.xml文件中的yarn.http.policy设置为HTTPS_ONLY。要为MapReduce JobHistory Server的 web-console 启用SSL，将mapred-site.xml文件中的mapreduce.jobhistory.http.policy设置为HTTPS_ONLY。 配置 HDFS和本地文件系统路径的权限Permissions for both HDFS and local fileSystem paths 下表列出了HDFS和本地文件系统的各种路径，建议权限为: Filesystem Path User:Group Permissions local dfs.namenode.name.dir hdfs:hadoop drwx—— local dfs.datanode.data.dir hdfs:hadoop drwx—— local $HADOOP_LOG_DIR hdfs:hadoop drwxrwxr-x local $YARN_LOG_DIR yarn:hadoop drwxrwxr-x local yarn.nodemanager.local-dirs yarn:hadoop drwxr-xr-x local yarn.nodemanager.log-dirs yarn:hadoop drwxr-xr-x local container-executor root:hadoop –Sr-s–* local conf/container-executor.cfg root:hadoop r——-* hdfs / hdfs:hadoop drwxr-xr-x hdfs /tmp hdfs:hadoop drwxrwxrwxt hdfs /user hdfs:hadoop drwxr-xr-x hdfs yarn.nodemanager.remote-app-log-dir yarn:hadoop drwxrwxrwxt hdfs mapreduce.jobhistory.intermediate-done-dir mapred:hadoop drwxrwxrwxt hdfs mapreduce.jobhistory.done-dir mapred:hadoop drwxr-x— 常见配置要在Hadoop中启用RPC身份认证，请将hadoop.security.authentication属性设置为kerberos，并适当地设置下面列出的安全相关的配置。 以下属性应位于集群中所有节点的core-site.xml中: Parameter Value Notes hadoop.security.authentication kerberos simple : No authentication. (default) kerberos : Enable authentication by Kerberos. hadoop.security.authorization true Enable RPC service-level authorization. hadoop.rpc.protection authentication authentication : authentication only (default); integrity : integrity check in addition to authentication; privacy : data encryption in addition to integrity hadoop.security.auth_to_local RULE:exp1 RULE:exp2 … DEFAULT The value is string containing new line characters. See Kerberos documentation for the format of exp. hadoop.proxyuser.superuser.hosts - comma separated hosts from which superuser access are allowed to impersonation. * means wildcard. hadoop.proxyuser.superuser.groups - comma separated groups to which users impersonated by superuser belong. * means wildcard. NameNode Parameter Value Notes dfs.block.access.token.enable true Enable HDFS block access tokens for secure operations. dfs.namenode.kerberos.principal nn/_HOST@REALM.TLD Kerberos principal name for the NameNode. dfs.namenode.keytab.file /etc/security/keytab/nn.service.keytab Kerberos keytab file for the NameNode. dfs.namenode.kerberos.internal.spnego.principal HTTP/_HOST@REALM.TLD The server principal used by the NameNode for web UI SPNEGO authentication. The SPNEGO server principal begins with the prefix HTTP/ by convention. If the value is ‘*’, the web server will attempt to login with every principal specified in the keytab file dfs.web.authentication.kerberos.keytab. For most deployments this can be set to ${dfs.web.authentication.kerberos.principal} i.e use the value of dfs.web.authentication.kerberos.principal. dfs.web.authentication.kerberos.keytab /etc/security/keytab/spnego.service.keytab SPNEGO keytab file for the NameNode. In HA clusters this setting is shared with the Journal Nodes. 以下设置允许配置对NameNode Web UI的SSL访问(可选): Parameter Value Notes dfs.http.policy HTTP_ONLY or HTTPS_ONLY or HTTP_AND_HTTPS HTTPS_ONLY turns off http access. This option takes precedence over the deprecated configuration dfs.https.enable and hadoop.ssl.enabled. If using SASL to authenticate data transfer protocol instead of running DataNode as root and using privileged ports, then this property must be set to HTTPS_ONLY to guarantee authentication of HTTP servers. (See dfs.data.transfer.protection.) dfs.namenode.https-address 0.0.0.0:9871 This parameter is used in non-HA mode and without federation. See HDFS High Availability and HDFS Federation for details. dfs.https.enable true This value is deprecated. Use dfs.http.policy Secondary NameNode Parameter Value Notes dfs.namenode.secondary.http-address 0.0.0.0:9868 HTTP web UI address for the Secondary NameNode. dfs.namenode.secondary.https-address 0.0.0.0:9869 HTTPS web UI address for the Secondary NameNode. dfs.secondary.namenode.keytab.file /etc/security/keytab/sn.service.keytab Kerberos keytab file for the Secondary NameNode. dfs.secondary.namenode.kerberos.principal sn/_HOST@REALM.TLD Kerberos principal name for the Secondary NameNode. dfs.secondary.namenode.kerberos.internal.spnego.principal HTTP/_HOST@REALM.TLD The server principal used by the Secondary NameNode for web UI SPNEGO authentication. The SPNEGO server principal begins with the prefix HTTP/ by convention. If the value is ‘*’, the web server will attempt to login with every principal specified in the keytab file dfs.web.authentication.kerberos.keytab. For most deployments this can be set to ${dfs.web.authentication.kerberos.principal} i.e use the value of dfs.web.authentication.kerberos.principal. JournalNode Parameter Value Notes dfs.journalnode.kerberos.principal jn/_HOST@REALM.TLD Kerberos principal name for the JournalNode. dfs.journalnode.keytab.file /etc/security/keytab/jn.service.keytab Kerberos keytab file for the JournalNode. dfs.journalnode.kerberos.internal.spnego.principal HTTP/_HOST@REALM.TLD The server principal used by the JournalNode for web UI SPNEGO authentication when Kerberos security is enabled. The SPNEGO server principal begins with the prefix HTTP/ by convention. If the value is ‘*’, the web server will attempt to login with every principal specified in the keytab file dfs.web.authentication.kerberos.keytab. For most deployments this can be set to ${dfs.web.authentication.kerberos.principal} i.e use the value of dfs.web.authentication.kerberos.principal. dfs.web.authentication.kerberos.keytab /etc/security/keytab/spnego.service.keytab SPNEGO keytab file for the JournalNode. In HA clusters this setting is shared with the Name Nodes. dfs.journalnode.https-address 0.0.0.0:8481 HTTPS web UI address for the JournalNode. DataNode Parameter Value Notes dfs.datanode.data.dir.perm 700 - dfs.datanode.address 0.0.0.0:1004 Secure DataNode must use privileged port in order to assure that the server was started securely. This means that the server must be started via jsvc. Alternatively, this must be set to a non-privileged port if using SASL to authenticate data transfer protocol. (See dfs.data.transfer.protection.) dfs.datanode.http.address 0.0.0.0:1006 Secure DataNode must use privileged port in order to assure that the server was started securely. This means that the server must be started via jsvc. dfs.datanode.https.address 0.0.0.0:9865 HTTPS web UI address for the Data Node. dfs.datanode.kerberos.principal dn/_HOST@REALM.TLD Kerberos principal name for the DataNode. dfs.datanode.keytab.file /etc/security/keytab/dn.service.keytab Kerberos keytab file for the DataNode. dfs.encrypt.data.transfer false set to true when using data encryption dfs.encrypt.data.transfer.algorithm - optionally set to 3des or rc4 when using data encryption to control encryption algorithm dfs.encrypt.data.transfer.cipher.suites - optionally set to AES/CTR/NoPadding to activate AES encryption when using data encryption dfs.encrypt.data.transfer.cipher.key.bitlength - optionally set to 128, 192 or 256 to control key bit length when using AES with data encryption dfs.data.transfer.protection - authentication : authentication only; integrity : integrity check in addition to authentication; privacy : data encryption in addition to integrity This property is unspecified by default. Setting this property enables SASL for authentication of data transfer protocol. If this is enabled, then dfs.datanode.address must use a non-privileged port, dfs.http.policy must be set to HTTPS_ONLY and the HDFS_DATANODE_SECURE_USER environment variable must be undefined when starting the DataNode process. WebHDFS Parameter Value Notes dfs.web.authentication.kerberos.principal http/_HOST@REALM.TLD Kerberos principal name for the WebHDFS. In HA clusters this setting is commonly used by the JournalNodes for securing access to the JournalNode HTTP server with SPNEGO. dfs.web.authentication.kerberos.keytab /etc/security/keytab/http.service.keytab Kerberos keytab file for WebHDFS. In HA clusters this setting is commonly used the JournalNodes for securing access to the JournalNode HTTP server with SPNEGO. ResourceManager Parameter Value Notes yarn.resourcemanager.principal rm/_HOST@REALM.TLD Kerberos principal name for the ResourceManager. yarn.resourcemanager.keytab /etc/security/keytab/rm.service.keytab Kerberos keytab file for the ResourceManager. yarn.resourcemanager.webapp.https.address ${yarn.resourcemanager.hostname}:8090 The https adddress of the RM web application for non-HA. In HA clusters, use yarn.resourcemanager.webapp.https.address.rm-id for each ResourceManager. See ResourceManager High Availability for details. NodeManager Parameter Value Notes yarn.nodemanager.principal nm/_HOST@REALM.TLD Kerberos principal name for the NodeManager. yarn.nodemanager.keytab /etc/security/keytab/nm.service.keytab Kerberos keytab file for the NodeManager. yarn.nodemanager.container-executor.class org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor Use LinuxContainerExecutor. yarn.nodemanager.linux-container-executor.group hadoop Unix group of the NodeManager. yarn.nodemanager.linux-container-executor.path /path/to/bin/container-executor The path to the executable of Linux container executor. yarn.nodemanager.webapp.https.address 0.0.0.0:8044 The https adddress of the NM web application. Configuration for WebAppProxyWebAppProxy在应用程序和用户导出的Web应用程序之间提供代理。如果启用了安全性，它将在访问可能不安全的Web应用程序之前警告用户。使用代理的身份验证和授权与任何其他特权Web应用程序一样处理。 Parameter Value Notes yarn.web-proxy.address WebAppProxy host:port for proxy to AM web apps. host:port if this is the same as yarn.resourcemanager.webapp.address or it is not defined then the ResourceManager will run the proxy otherwise a standalone proxy server will need to be launched. yarn.web-proxy.keytab /etc/security/keytab/web-app.service.keytab Kerberos keytab file for the WebAppProxy. yarn.web-proxy.principal wap/_HOST@REALM.TLD Kerberos principal name for the WebAppProxy. LinuxContainerExecutorYARN框架使用的ContainerExecutor，用于定义任何容器的启动和控制方式。 以下是Hadoop YARN中可用内容: ContainerExecutor Description DefaultContainerExecutor The default executor which YARN uses to manage container execution. The container process has the same Unix user as the NodeManager. LinuxContainerExecutor Supported only on GNU/Linux, this executor runs the containers as either the YARN user who submitted the application (when full security is enabled) or as a dedicated user (defaults to nobody) when full security is not enabled. When full security is enabled, this executor requires all user accounts to be created on the cluster nodes where the containers are launched. It uses a setuid executable that is included in the Hadoop distribution. The NodeManager uses this executable to launch and kill containers. The setuid executable switches to the user who has submitted the application and launches or kills the containers. For maximum security, this executor sets up restricted permissions and user/group ownership of local files and directories used by the containers such as the shared objects, jars, intermediate files, log files etc. Particularly note that, because of this, except the application owner and NodeManager, no other user can access any of the local files/directories including those localized as part of the distributed cache. 要构建LinuxContainerExecutor可执行: 12# 集群配置文件路径mvn package -Dcontainer-executor.conf.dir=/opt/hadoop/etc/hadoop/ LinuxTaskController 要求包含和导向 yarn.nodemanager.local-dirs 和 yarn.nodemanager.log-dirs 中指定的目录的路径设置为755权限。 可执行文件需要一个名为container-executor.cfg(conf/container-executor.cfg)的配置文件，该文件存在于上述mvn的目标配置目录里。该配置文件必须有NodeNanager的用户所有，权限应为0400。可执行文件要求此配置文件存在以下配置项(KV): Parameter Value Notes yarn.nodemanager.linux-container-executor.group hadoop Unix group of the NodeManager. The group owner of the container-executor binary should be this group. Should be same as the value with which the NodeManager is configured. This configuration is required for validating the secure access of the container-executor binary. banned.users hdfs,yarn,mapred,bin Banned users. allowed.system.users foo,bar Allowed system users. min.user.id 1000 Prevent other super-users. 以下是与LinuxContainerExecutor相关的各种路径所需的本地文件系统权限： Filesystem Path User:Group Permissions local container-executor root:hadoop –Sr-s–* local conf/container-executor.cfg root:hadoop r——-* local yarn.nodemanager.local-dirs yarn:hadoop drwxr-xr-x local yarn.nodemanager.log-dirs yarn:hadoop drwxr-xr-x MapReduce JobHistory Server Parameter Value Notes mapreduce.jobhistory.address MapReduce JobHistory Server host:port Default port is 10020. mapreduce.jobhistory.keytab /etc/security/keytab/jhs.service.keytab Kerberos keytab file for the MapReduce JobHistory Server. mapreduce.jobhistory.principal jhs/_HOST@REALM.TLD Kerberos principal name for the MapReduce JobHistory Server. Multihoming多宿主设置，其中每个主机在DNS中具有多个主机名(如，对应于公共和专用网络接口的不同主机名)。可能需要额外的配置才能使Kerberos身份认证工作。 TroubleshootingKerberos is hard to set up，and harder to debug。常见问题有: Network and DNS configuration Kerberos configuration on hosts (/etc/krb5.conf) Keytab creation and maintenance Environment setup: JVM, user login, system clocks, etc 12345678# Set the environment variable HADOOP_JAAS_DEBUG to trueexport HADOOP_JAAS_DEBUG=true# Edit the log4j.properties file to log Hadoop’s security package at DEBUG levellog4j.logger.org.apache.hadoop.security=DEBUG# Enable JVM-level debugging by setting some system propertiesexport HADOOP_OPTS=&quot;-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug&quot; KDiagTroubleshooting with KDiag Hadoop有一个工具来帮助验证设置：KDiag。 它包含一系列用于JVM配置和环境的探测器，转储出一些系统文件（/etc/krb5.conf, /etc/ntp.conf），打印出一些系统状态，然后尝试登录到Kerberos作为当前用户或命名密钥表中的特定主体。该命令的输出可用于本地诊断，或转发给支持群集的任何人。KDiag命令有自己的入口点，通过将kdiag传递给hadoop命令来调用它。因此，它将显示用于调用它的命令的kerberos客户端状态。 12345678910111213hadoop kdiag# 帮助bin/hadoop kdiag --help# 栗子hadoop kdiag \ --nofail \ --resource hdfs-site.xml --resource yarn-site.xml \ --keylen 1024 \ --keytab zk.service.keytab --principal zookeeper/devix.example.org@REALM 关闭安全模式Hadoop Secure Mode默认是开启的！ 12345678910111213141516# 查看# bin/hadoop dfsadmin -safemode get(旧)bin/hdfs dfsadmin -safemode getSafe mode is ON# 关闭# bin/hdfs dfsadmin -safemode leave(旧)bin/hdfs dfsadmin -safemode leaveSafe mode is OFF# 启用# bin/hdfs dfsadmin -safemode enter(旧)bin/hdfs dfsadmin -safemode enterSafe mode is ON 服务级别授权Service Level Authorization Guide 本节描述了如何配置和管理Hadoop服务级别的授权(Service Level Authorization)。 Prerequisites: 确已正确安装、配置和设置Hadoop！ 概述服务级别授权是初始化授权机制，用于确保连接到特定的Hadoop服务的客户端具有必要的预配置设置，并且有权访问给定服务。例如，MapReduce集群可以使用此机制来允许已配置的用户/组列表提交作业。 $HADOOP_CONF_DIR/hadoop-policy.xml配置文件用于定义各种Hadoop服务的访问控制列表(ACL)。服务级别授权在其他访问控制检查之前执行很久，例如文件权限检查，作业队列上的访问控制等。 配置通过配置文件$HADOOP_CONF_DIR/hadoop-policy.xml配置服务级别的授权。 启用服务级别授权Enable Service Level Authorization 默认情况下，Hadoop禁用服务级别授权。要启用它，请在$HADOOP_CONF_DIR/core-site.xml中将配置属性hadoop.security.authorization设置为true。 Hadoop服务和配置项Hadoop Services and Configuration Properties 下面列出各种Hadoop服务及其配置项: Property Service security.client.protocol.acl ACL for ClientProtocol, which is used by user code via the DistributedFileSystem. security.client.datanode.protocol.acl ACL for ClientDatanodeProtocol, the client-to-datanode protocol for block recovery. security.datanode.protocol.acl ACL for DatanodeProtocol, which is used by datanodes to communicate with the namenode. security.inter.datanode.protocol.acl ACL for InterDatanodeProtocol, the inter-datanode protocol for updating generation timestamp. security.namenode.protocol.acl ACL for NamenodeProtocol, the protocol used by the secondary namenode to communicate with the namenode. security.job.client.protocol.acl ACL for JobSubmissionProtocol, used by job clients to communciate with the resourcemanager for job submission, querying job status etc. security.job.task.protocol.acl ACL for TaskUmbilicalProtocol, used by the map and reduce tasks to communicate with the parent nodemanager. security.refresh.policy.protocol.acl ACL for RefreshAuthorizationPolicyProtocol, used by the dfsadmin and rmadmin commands to refresh the security policy in-effect. security.ha.service.protocol.acl ACL for HAService protocol used by HAAdmin to manage the active and stand-by states of namenode. 访问控制列表Access Control Lists $HADOOP_CONF_DIR/hadoop-policy.xml为每个Hadoop服务定义一个访问控制列表。 每个访问控制列表都有一个简单的格式: users/groups都是用逗号分隔的名称列表。如: user1, user2, group1, group2 如果仅提供组列表，则在行的开头添加空格，等效地以逗号分隔的用户列表后跟空格或不显示仅包含一组给定用户。特殊值*表示允许所有用户访问该服务。如果未为服务定义访问控制列表，则应用security.service.authorization.default.acl 的值。如果未定义 security.service.authorization.default.acl，则应用*。 被阻止的访问控制列表Blocked Access Control Lists 在某些情况下，需要为服务指定阻止的访问控制列表。这指定了未授权访问该服务的用户和组的列表。被阻止的访问控制列表的格式与访问控制列表的格式相同。可通过$HADOOP_CONF_DIR/hadoop-policy.xml指定阻止的访问控制列表。属性名称通过后缀.blocked派生。栗子: security.client.protocol.acl 的阻止访问控制列表的属性名称为security.client.protocol.acl.blocked 。 对于服务，可以指定访问控制列表和阻止的控制列表。如果用户在访问控制中而不在阻止的访问控制列表中，则授权用户访问该服务。 如果未为服务定义阻止访问控制列表，则应用 security.service.authorization.default.acl.blocked 的值。如果未定义 security.service.authorization.default.acl.blocked，则应用空的阻止访问控制列表。 IP地址，主机名，IP范围进行访问控制Access Control using Lists of IP Addresses, Host Names and IP Ranges 可以基于访问服务的客户端IP地址来控制对服务的访问。通过指定IP地址，主机名和IP范围列表，可以限制从一组计算机访问服务。每个服务的属性名称都是从相应的acl属性名称派生的。如果acl的属性名称为security.client.protocol.acl，则hosts列表的属性名称为 security.client.protocol.hosts。如果未为服务定义主机列表，则应用 security.service.authorization.default.hosts 的值。如果未定义 security.service.authorization.default.hosts，则应用 * 。 可以指定阻止的主机列表。只有那些位于主机列表中但未在阻止主机列表中的计算机才会被授予对该服务的访问权限。属性名称通过后缀 .blocked 派生。栗子: security.client.protocol.hosts 的被阻止主机列表的属性名称为 security.client.protocol.hosts.blocked。如果未为服务定义阻止主机列表，则应用 security.service.authorization.default.hosts.blocked 的值。如果未定义 security.service.authorization.default.hosts.blocked，则应用空的阻止主机列表。 刷新服务级别授权配置Refreshing Service Level Authorization Configuration 可在不重启Hadoop Daemon的情况下更改NameNode和ResourceManager的服务级别授权配置。集群管理员可在Master节点上更改$HADOOP_CONF_DIR/hadoop-policy.xml，并指示NameNode和ResourceManager分别通过-refreshServiceAcl开关将其各自的配置重新加载到dfsadmin和rmadmin命令。 123456# 刷新NameNode的服务级别的授权配置bin/hdfs dfsadmin -refreshServiceAcl# 刷新ResourceManager的服务级别授权配置bin/yarn rmadmin -refreshServiceAcl 当然，也可以使用$HADOOP_CONF_DIR/hadoop-policy.xml中的security.refresh.policy.protocol.acl属性来限制对某些users/groups刷新服务级别授权的访问权限。 栗子仅允许mapreduce gruop中的a, b users将作业提交到MapReduce集群: 1234&lt;property&gt; &lt;name&gt;security.job.client.protocol.acl&lt;/name&gt; &lt;value&gt;a,b mapreduce&lt;/value&gt;&lt;/property&gt; 仅允许数据属于group datanodes的users运行的DataNode与NameNode进行通信: 1234&lt;property&gt; &lt;name&gt;security.datanode.protocol.acl&lt;/name&gt; &lt;value&gt;datanodes&lt;/value&gt;&lt;/property&gt; 允许任何用户作为DFSClient与HDFS集群通信: 1234&lt;property&gt; &lt;name&gt;security.client.protocol.acl&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt; HTTP认证Authentication for Hadoop HTTP web-consoles 介绍本节介绍如何配置Hadoop HTTP web-console以要求用户身份认证。 默认情况下，Hadoop HTTP web-console(ResourceManager, NameNode, NodeManager, DataNodes)允许无需任何形式的身份认证的访问。 可将Hadoop HTTP web-console配置为使用HTTP SPNEGO协议要求Kerberos身份认证。此外，Hadoop HTTP web-console支持相当于Hadoop的 Pseudo/Simple 认证。如果启用此选项，则必须使用 user.name 查询字符串参数在浏览器交互中地址用户名。 如: http://localhost:8088/cluster?user.name=usera。如果HTTP web-console需要自定义身份认证机制，则可以实现插件以支持备用身份认证机制。 配置以下属性应位于集群中所有节点的 core-site.xml 中: Property Name Default Value Description hadoop.http.filter.initializers - Add to this property the org.apache.hadoop.security.AuthenticationFilterInitializer initializer class. hadoop.http.authentication.type simple Defines authentication used for the HTTP web-consoles. The supported values are: simple kerberos #AUTHENTICATION_HANDLER_CLASSNAME#. hadoop.http.authentication.token.validity 36000 Indicates how long (in seconds) an authentication token is valid before it has to be renewed. hadoop.http.authentication.token.max-inactive-interval -1 (disabled) Specifies the time, in seconds, between client requests the server will invalidate the token. hadoop.http.authentication.signature.secret.file $user.home/hadoop-http-auth-signature-secret The signature secret file for signing the authentication tokens. The same secret should be used for all nodes in the cluster, ResourceManager, NameNode, DataNode and NodeManager. This file should be readable only by the Unix user running the daemons. hadoop.http.authentication.cookie.domain - The domain to use for the HTTP cookie that stores the authentication token. For authentication to work correctly across all nodes in the cluster the domain must be correctly set. There is no default value, the HTTP cookie will not have a domain working only with the hostname issuing the HTTP cookie. hadoop.http.authentication.cookie.persistent false (session cookie) Specifies the persistence of the HTTP cookie. If the value is true, the cookie is a persistent one. Otherwise, it is a session cookie. IMPORTANT: when using IP addresses, browsers ignore cookies with domain settings. For this setting to work properly all nodes in the cluster must be configured to generate URLs with hostname.domain names on it. hadoop.http.authentication.simple.anonymous.allowed true Indicates whether anonymous requests are allowed when using ‘simple’ authentication. hadoop.http.authentication.kerberos.principal HTTP/_HOST@$LOCALHOST Indicates the Kerberos principal to be used for HTTP endpoint when using ‘kerberos’ authentication. The principal short name must be HTTP per Kerberos HTTP SPNEGO specification. _HOST -if present- is replaced with bind address of the HTTP server. hadoop.http.authentication.kerberos.keytab $user.home/hadoop.keytab Location of the keytab file with the credentials for the Kerberos principal used for the HTTP endpoint. CORS要启用跨域支持(CORS)，请设置以下配置参数: 将 org.apache.hadoop.security.HttpCrossOriginFilterInitializer 添加到 core-site.xml 中的 hadoop.http.filter.initializers。您还需要在 core-site.xml 中设置以下属性: Property Default Value Description hadoop.http.cross-origin.enabled false Enables cross origin support for all web-services hadoop.http.cross-origin.allowed-origins * Comma separated list of origins that are allowed. Values prefixed with regex: are interpreted as regular expressions. Values containing wildcards (*) are possible as well, here a regular expression is generated, the use is discouraged and support is only available for backward compatibility. hadoop.http.cross-origin.allowed-methods GET,POST,HEAD Comma separated list of methods that are allowed hadoop.http.cross-origin.allowed-headers X-Requested-With,Content-Type,Accept,Origin Comma separated list of headers that are allowed hadoop.http.cross-origin.max-age 1800 Number of seconds a pre-flighted request can be cached Credential Provider APICredentialProvider API Guide CredentialProvider API是一个用于插入可扩展凭据提供程序的SPI框架。凭据提供程序用于将敏感令牌(token)，机密(secret)和密码(passwd)的使用与其存储和管理的详细信息分开。选择各种存储机制来保护这些凭证的能力使我们能够使这些敏感资产远离明文(clear text)，远离窥探并可能由第三方解决方案管理。 本节描述CredentialProvider API的设计，开箱即用的实现，使用它们以及如何使用它们。 密钥管理Hadoop Key Management Server (KMS) Hadoop KMS 是一个基于Hadoop KeyProvider API的加密秘钥管理服务器。它提供了一个Client和Server组件，它们使用REST API通过HTTP进行通信。Client是KeyProvider实现，使用KMS HTTP REST API与KMS交互。KMS及其Client內建有安全性，并且支持HTTP和 SPNEGO Kerberos认证和HTTPS安全传输。KMS是一个Java Jetty Web应用程序。 TracingEnabling Dapper-like Tracing in Hadoop HTraceHDFS-5274 使用开源跟踪库(Apache HTrace)增加了对通过HDFS跟踪请求的支持。设置跟踪非常简单，但是它需要对客户端代码进行一些非常小的更改。 SpanReceivers HDFS 架构HDFS Architecture Hadoop Distributed File System(HDFS) 是一种分布式文件系统，设计用于在商业硬件上运行。它与现有的分布式文件系统有许多相似之处。但是，与其它分布式文件系统的差异很大。HDFS具有高度容错(fault-tolerant)能力，旨在部署在低成本硬件上。HDFS提供对应用程序数据的高吞吐量访问，适用于具有大型数据集的应用程序。HDFS放宽了一些POSIX要求，以实现对文件系统数据的流式访问。 假设和目标Assumptions and Goals 硬件故障Hardware Failure 硬件故障是常态而非异常。HDFS实例可能包含成百上千的主机，每台主机都存储文件系统数据的一部分。事实上，存在大量组件并且每个组件具有非平凡(non-trivial)的故障概率，这意味着HDFS某些组件始终不起作用(non-functional)。因此，检测故障并从中快速自动地恢复是HDFS的核心架构目标。 流数据访问Streaming Data Access 在HDFS上运行的应用程序需要对其数据集进行流式访问。它们不是通常在通用文件系统上运行的通用应用程序。HDFS设计用于批处理而不是用户的交互式使用。重点是数据访问的高吞吐量(high throughput)而不是数据访问的低延迟(low latency)。POSIX强加了许多针对HDFS的应用程序不需要的硬性要求。 大型数据集Large Data Sets 在HDFS上运行的应用程序具有大型数据集。HDFS中的典型文件大小为gigabytes到terabytes。因此，HDFS被调整为支持大文件。它应该为单个集群中的成百上千的节点提供高聚合数据带宽和扩展。它应该在单个实例中支持数千万个文件。 简单的一致性模型Simple Coherency Model HDFS应用程序需要一个write-once-read-many的文件访问模型。除了追加(append)和截断(truncates)之外，无需更改创建，写入和关闭的文件。支持将内容附加到文件末尾，但无法在任意点更新。此假设简化了数据一致性问题，并实现了高吞吐量数据访问。MapReduce应用程序或Web Crawler应用程序适合此模型。 移动计算比移动数据更便宜Moving Computation is Cheaper than Moving Data 如果应用程序在其操作的数据附近执行，则计算所请求的计算效率更高。当数据集很大时尤其如此。这可以最大限度地减少网络拥塞(network congestion)并提高系统的整体吞吐量。这个假设通常更好的是将计算迁移到更靠近数据所在的地方，而不是将数据移动到应用程序运行的地方。HDFS为应用程序移动到更靠近数据所在的地方的接口。 可移植性Portability Across Heterogeneous Hardware and Software Platforms HDFS的设计便于从一个平台移植到另一个平台。 NameNode和DataNodeHDFS具有主从架构(Master-Slave)。HDFS集群由单个NameNode、一个管理文件系统命名空间和管理客户端对文件的访问的Master Server组成。此外，还有许多DataNode，通常是集群中每个节点一个，用于管理附加到它们运行节点的存储。HDFS公开文件系统命名空间，并允许用户数据存储在文件中。在内部，文件被分成一个或多个块(block)，这些块存储在一组DataNode中。NameNode执行文件系统命名空间操作(如打开、关闭、重命名文件目录)。它还确定了block到DataNode的映射。DataNode负责提供来自文件系统客户端的读写请求，它还根据NameNode的指令执行块操作(如创建、删除、副本)。 NameNode和DataNode是设计用于在商用机器上运行的软件，这些机器通常运行GNU/Linux操作系统。HDFS使用Java语言构建，任何支持Java的机器都可运行NameNode或DataNode软件。使用高度可移植的Java语言意味着可以在各种计算机上部署HDFS。典型部署具有仅运行NameNode软件的专用主机，群集中的每台其它主机都运行一个DataNode软件实例。虽然可以讲它们运行在同一台主机上，但这并不推荐。 群集中存在单个NameNode极大地简化了系统结构。NameNode是所有HDFS Metadata的仲裁者(arbitrator)和存储库(repository)。系统的设计使用户数据永远不会流经NameNode。 文件系统命名空间The File System Namespace HDFS支持传统的层次文件组织。用户或应用程序可以创建目录，并在这些目录中存储文件。文件系统命名空间层次结构类似于大多数其它现有文件系统；可创建、删除、移动、重命名文件。HDFS支持用户配额(user quotas)和访问权限。HDFS不支持硬链接和软链接。但是，HDFS架构并不排除实现这些功能。 NameNode维护文件系统命名空间。NameNode Record对文件系统命名空间或其属性的任何更改。应用程序可以指定应由HDFS维护的文件的副本数。文件的副本数称为该文件的复制因子，该信息由NameNode存储。 数据副本Data Replication HDFS旨在可靠地在大型群集中的计算机上存储非常大的文件。它将每个文件存储为一系列块。文件块的副本用以实现容错(fault tolerance)。块大小和副本因子可根据文件进行配置。 除了最后一个块之外，文件中的所有块都具有相同的大小。而用户可以在添加对可变长度块的支持以追加和hsync之后启动新块而不将最后一个块填充到配置的块大小。 应用程序可以指定文件的副本数量。副本因子可在文件创建时指定，并且可以在之后修改。HDFS中的文件是一次写入的，并且在任何时候都有一个写入器。 NameNode做出有关副本的所有决定。它定期从集群中的每个DataNode接收Heartbeat和Blockreport。收到心跳意味着DataNode正常运行，块上报包含DataNode上所有块的列表。 副本安置Replica Placement: The First Baby Steps]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Apache</tag>
        <tag>DataAnalysis</tag>
        <tag>Hadoop</tag>
        <tag>BigData</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SonarQube]]></title>
    <url>%2F2019%2F02%2F22%2FSonarQube%2F</url>
    <content type="text"><![CDATA[参考: GitHub: https://github.com/SonarSource/sonarqube Website: https://www.sonarqube.org/ Docs: https://docs.sonarqube.org 环境: RHEL7x86_64 SonarQube v7.6 介绍SonarQube 是一个开源的代码质量管理系统。支持超过25中编程语言，不过有些是商业插件。 SonarQube 是一种自动代码审查(code review)工具，用于检测代码中的错误(bugs)，漏洞(vulnerabilities)和代码异味(code smell)。它可以与您现有的工作流程集成，以便在项目分支和拉取请求之间进行连续的代码检查。 架构与集成Architecture and Integration 概述SonarQube平台由4个组件组成: SonarQube Server启动三个主进程: Web Server，供开发人员，管理人员浏览质量快照并配置SonarQube实例 Search Server，基于ElasticSearch从UI返回搜索 Compute Engine Server，负责处理代码分析和上报并将其保存到SonarQube数据库中 SonarQube Database用于存储 SonarQube实例的配置(安全，插件…的设置) 项目，视图…的质量快照 Server上安装了多个插件，可能包括Language，SCM，Intergration，Authentication，Governance… 在CI/CD Server上运行一个或多个 SonarScanner 来分析项目 集成Integration 以下模式显示了SonarQube如何与其它ALM工具进行集成，以及在哪里使用SonarQube的各种组件。 开发者在他们的IDE中集成SonarLint运行本地分析 开发者推送他们的代码到代码库 CI Server触发自动构建，以及执行运行SonarQube分析所需的SonarScanner 分析报告将发送到SonarQube Server进行处理 SonarQube Server处理分析报告并将结果存储在SonarQuebe数据库中，并在UI中显示结果 开发者通过SonarQube UI审核，评论，挑战他们的Issues以管理和减少他们的技术债务 管理者从分析中接收报告，运维使用API自动配置并从SonarQube中提取数据，使用JMX监控SonarQube Server 关于机器和位置About Machines and Locations SonarQube平台不能够有多个SonarQube Server和SonarQube Database 为获得最佳性能，每个组件(Server, Database, Scanner)应该安装在单独的机器上，并且此机器应该是专用的 SonarScanner通过添加机器进行扩展 所有机器必须时钟同步 SonarQube Server和SonarQube Database必须位于同一网络下 SonarScanner不需要与SonarQube Server位于同一网络下 SonarScanner与SonarQube Database之间没有通信 要求Requirements 先决条件Prerequisites and Overview 运行SonarQube的唯一先决条件是安装Java(Oracle JRE 8/OpenJDK 8)。 硬件要求 2Cores+ 2GB RAM+ 建议使用高性能I/O的磁盘 支持的平台 Java Oracle JRE 8 OpenJDK 8 Database PostgreSQL v9.3-v9.6, v10. UTF-8 charset SQL Server v2014, v2016. Oracle v11, v12, vXE. UTF8-family charset, thin mode MySQL v5.6, v5.7. UTF8 charset, InnoDB storage, mysql-connector-java Web Browser IE 11 Edge Latest FireFox Latest Chrome Safari 平台说明 Linux如果在Linux上运行，请确保: vm.max_map_count 大于或等于 262144 fs.file-max 大于或等于 65535 运行SonarQube的用户可以打开至少65535个文件描述符 运行SonarQube的用户可以打开至少2048个线程 用以下命令查看和配置它们: 12345678910111213141516171819sysctl vm.max_map_countsysctl fs.file-maxulimit -nulimit -u# 配置，但只是临时生效# rootsysctl -w vm.max_map_count=262144sysctl -w fs.file-max=65536ulimit -n 65536ulimit -u 2048# 永久生效# /etc/sysctl.d/99-sonarqube.conf 或 /etc/sysctl.conf# user: sonarqubesonarqube - nofile 65536sonarqube - nproc 2048 如果使用systemd来启动SonarQube，你必须在[Service]的单元文件中指定这些限制: 1234[Service]...LimitNOFILE=65536LimitNPROC=2048 seccomp filter默认情况下，ElasticSearch使用seccomp filter。在大多数发行版中，此功能在内核中激活。但在RHL6等发行版上，此功能已停用。如果你的发行版中没有此功能，请无法升级到激活了seccomp filter功能的版本，则必须通过更新$SONARQUBEHOME/conf/sonar.properties_中的sonar.search.javaAdditionalOpts配置: 12345678910sonar.search.javaAdditionalOpts=-Dbootstrap.system_call_filter=false# 检查grep SECCOMP /boot/config-$(uname -r)# 如果内核有它，你将看到CONFIG_HAVE_ARCH_SECCOMP_FILTER=yCONFIG_SECCOMP_FILTER=yCONFIG_SECCOMP=y 配置和升级Setup and Upgrade 快速入门Get Started in Two Minutes Guide 从ZIP文件安装 使用Docker zip文件安装 现在 SonarQube CE 解压 运行 访问 12345# 具体位置取决于你的安装位置/opt/sonarqube/bin/[OS]/sonar.sh console# localhost:9000（admin/admin） Docker安装在Docker Hub上下载对应CE的镜像，上面有安装和配置的详细信息。 安装Server支持多个数据库引擎，请务必遵守各个数据库引擎的要求。 创建一个空的schema和一个sonarqube用户。授予此用户create, update, delete此schema对象的权限。 1234CREATE SCHEMA `sonar` DEFAULT CHARACTER SET utf8 ;CREATE USER 'sonarqube'@'localhost' IDENTIFIED BY 'sonarqube-PW123';GRANT ALL ON sonar.* TO 'sonarqube'@'localhost'; 安装数据库 SQL Server跳过，有需要的请看: https://docs.sonarqube.org/latest/setup/install-server/ Oracle跳过！ PostgreSQL如果你想使用custom schema而不是默认的public schema，则必须设置PostgreSQL的search_path属性: 1ALTER USER mySonarUser SET search_path to mySonarQubeSchema MySQL 注意:Data Center Edition(Enterprise)不支持MySQL!Data Center Edition: Designed for High Availability 可在MySQL中使用两种众所周知的数据库引擎: MyISAM和InnoDB。MyISAM是最老的，并且正在逐渐被InnoDB替代。随着质量控制项目数量的增加，InnoDB显然更快，并且使用SonarQube可以更好地扩展。如果你是SonarQube的早期使用者，你可能有一系列仍在使用MyISAM引擎的表。你应该将所有表的引擎更改为InnoDB。 一旦所有SonarQube表都使用InnoDB引擎，首先要做的是使用innodb_buffer_pool_size参数为MySQL实例分配最大的RAM，并为query_cache_size参数提供至少15Mb。 阅读这篇文档InnoDB Performance Optimization来优化InnoDB。 安装Web Server首先，检查安装要求；下载和解压压缩的发行版(不要解压到以数字开头的目录)；下面变量SONARQUBE-HOME指的是解压的路径。 设置数据库访问编辑$SONARQUBE-HOME/conf/sonar.properties来配置数据库设置。模板可用于每个受支持的数据库。 1234# Example for MySQLsonar.jdbc.username=sonarqubesonar.jdbc.password=sonarqube-PW123sonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance&amp;useSSL=false 添加JDBC驱动已提供受支持数据库(Oracle除外)的驱动程序。不要更换提供的驱动程序，它们是唯一受支持的。 对于Oracle，将JDBC驱动复制到$SONARQUBE-HOME/extensions/jdbc-driver/oracle。 配置ElasticSearch存储路径默认情况下，ES数据存储在$SONARQUBE-HOME/data中，但不建议用于生产环境。相反，你应该将数据存储在其它位置，最好是在具有高速I/O的专用卷。除了保持可接受的性能之外，还可简化SonarQube的升级。 编辑$SONARQUBE-HOME/conf/sonar.properties来配置以下设置: 123# 请记得添加读写权限sonar.path.data=/var/sonarqube/datasonar.path.temp=/var/sonarqube/temp 启动Web Server可在$SONARQUBE-HOME/conf/sonar.properties配置监听地址和端口等。 123sonar.web.host=192.0.0.1sonar.web.port=80sonar.web.context=/sonarqube 1234# 启动bin/sonar.sh start# 默认admin/admin 调整Web服务器默认情况下，SonarQube配置为在任何具有简单Java JRE的计算机上运行。 为了更好地性能，生产环境实例要做的第一件事是使用Java JDK并通过在sonar.web.javaOpts=-server中设置以下行来激活服务器模式。 1sonar.web.javaOpts=-server 要修改SonarQube使用的Java JVM只需编辑$SONARQUBE-HOME/conf/wrapper.conf并更新以下行: 1wrapper.java.command=/path/to/my/jdk/bin/java FAQdocs: https://docs.sonarqube.org/latest/setup/install-server/ 配置和操作ServerConfigure &amp; Operate the Server 以SystemD运行Running SonarQube as a Service on Linux with SystemD 假设如下信息: sonarqube用户 sonarqube组 java virtual machine安装在/opt/java/ sonarqube解压在/opt/sonarqube/ 创建sonarqube用户: 1useradd -M -s /sbin/nologin 创建service文件/etc/systemd/system/sonarqube.service，具体详情请安装自己的实际情况进行修改。 123456789101112131415161718[Unit]Description=SonarQube serviceAfter=syslog.target network.target[Service]Type=simpleUser=sonarqubeGroup=sonarqubePermissionsStartOnly=trueExecStart=/bin/nohup /opt/java/bin/java -Xms32m -Xmx32m -Djava.net.preferIPv4Stack=true -jar /opt/sonarqube/lib/sonar-application-7.6.jarStandardOutput=syslogLimitNOFILE=65536LimitNPROC=8192TimeoutStartSec=5Restart=always[Install]WantedBy=multi-user.target 123# 启动sudo systemctl enable sonarqube.servicesudo systemctl start sonarqube.service 在代理服务器后保护ServerSecuring the Server Behind a Proxy Server配置要通过HTTPS运行SonarQube Server，必须构建标准的反向代理服务器。必须配置反向代理，在每个HTTP Request Header中设置X_FORWARDED_PROTO: https值。如果没有此属性，SonarQube Server启动的重定向将回退到HTTP。 使用Apache代理跳过！ 使用Nginx代理123456789101112# the server directive is nginx&apos;s virtual host directiveserver &#123; # port to listen on. Can also be set to an IP:PORT listen 80; # sets the domain[s] that this vhost server requests for server_name www.somecompany.com; location / &#123; proxy_pass http://sonarhost:sonarport; &#125;&#125; 使用IIS跳过！ 安装插件在SonarQube中安装插件有两种选择: Marketplace，从SonarQube UI自动地安装插件 手动安装， 如果SonarQube实例无法访问Internet，请使用此方法 安装C/C++插件由于SonarQube的C, C++是商业版才有的功能，所以我使用的CE版就不支持对这两个语言的静态检查。 后来看到 SonarOpenCommunity: https://github.com/SonarOpenCommunity，它里面有这个插件，先感谢开发者，然后再使用。 sonar-cxx: https://github.com/SonarOpenCommunity/sonar-cxx，查看相关说明进行安装和配置。 安装 明白哪个插件版本与当前使用的SonarQube版本监控 下载jar插件，将其放置于$ SONARQUBE_HOME/extensions/plugins目录下 sonar-cxx-plugin-x.y.z.jar: c++ plug-in sonar-c-plugin-x.y.z.jar: c plug-in 重启SonarQube Server 在UI上的Marketplace查看更新 安装PS/SQL插件由于SonarQube的PL, SQL是商业版才有的功能，所以我使用的CE版就不支持对这两个语言的静态检查。 后来看到: sonar-plsql: https://github.com/felipebz/sonar-plsql 社区开源项目，先感谢开发者，再使用。 安装方法与上面的C/C++一样，下载当前版本支持的插件到对应目录，重启SonarQube Server。 将Server安装为集群docs: https://docs.sonarqube.org/latest/setup/install-cluster/ 先跳过！ 配置和操作集群Configure &amp; Operate a Cluster docs: https://docs.sonarqube.org/latest/setup/operate-cluster/ 先跳过！ 升级Upgrade the Server 自动处理non-LTS版本的升级。但是，如果在迁移路径中有LTS版本，则必须先迁移LTS，然后再迁移到目标版本。 例如，v5.1 -&gt; v7.0，迁移路径为 v5.1 -&gt; 5.6.7 LTS -&gt; v6.7.x LTS -&gt; v7.0。 如何升级在开始之前，请备份SnarQube Database。升级问题虽然很少见，但备份确实必须的。 分析源代码Analyzing Source Code 概述一旦安装了SonarQube平台，你就可以安装分析器(analyzer)并开始创建项目了。为此，你必须安装和配置适合你需求的扫描器(scanner)。Do you build with: Gradle - SonarScanner for Gradle MSBuild - SonarScanner for MSBuild Maven - use the SonarScanner for Maven Jenkins - SonarScanner for Jenkins Azure DevOps - SonarQube Extension for Azure DevOps Ant - SonarScanner for Ant anything else (CLI) - SonarScanner 注意，不建议在运行SonarQube Scanner Analysis的机器上运行反病毒扫描程序，这可能会导致不可预测的行为。 分析产生了什么What does analysis produce? SonarQube可以对20多种不同的语言进行分析。该分析的结果是 quality measures 和 issues。但是，分析的结果也会因语言而异: 在所有语言中，blame数据将自动从支持的SCM提供程序导入(自动支持Git和SVN)。其它提供需要额外的插件 在所有语言中，执行源代码的静态分析 可对某些语言执行编译代码的静态分析 可对某些语言执行代码的动态分析 是否会分析所有文件Will all files be analyzed? 默认情况下，在分析期间，只有语言分析器(language analyzer)可识别的文件才会加载到项目中。 分析期间会发生什么What happens during analysis? 在分析期间，从Server请求数据，分析提供给分析的文件，并以报告的形式将结果返回到Server，然后在Server-Side异步分析。 分析上报排队并按顺序处理，因此很可能在分析日志显示完成后的短暂时间内，更新的值在SonarQube项目中不可见。但是，你能够分辨出正在发生的事情，因为项目名称右侧的项目主页上会有一个图标。 分析参数Analysis Parameters 可以在多个位置设置用于配置项目分析的参数。这是参数的层次结构： 在UI里定义的全局分析参数(Global)，Administration &gt; Configuration &gt; General Settings 在UI里定义的项目分析参数(Project)，Project Level &gt; Administration &gt; General Settings 在项目分析配置文件或分析器配置文件中定义的项目分析参数 分析/命令行参数，再启动分析时定义，覆盖项目分析参数 注意，只有通过UI设置的参数才会存储在数据库中。 强制参数Mandatory Parameters Server Key Description Default sonar.host.url the server URL http://localhost:9000 Project Configuration Key Description Default sonar.projectKey The project’s unique key. Allowed characters are: letters, numbers, - , _ , . and : , with at least one non-digit. For Maven projects, this is automatically set to &lt;groupId&gt;:&lt;artifactId&gt; sonar.sources Comma-separated paths to directories containing source files. Read from build system for Maven, Gradle, MSBuild projects 可选参数Optional Parameters Project Identity Key Description Default sonar.projectName 显示在Web实例上的项目名称 Maven项目的&lt;name&gt;，否则为项目密钥。如果DB中已有名称，则不会覆盖该名称 sonar.projectVersion 项目版本 Maven项目的&lt;version&gt;，否则未提供 Authentication Key Description Default sonar.login 具有项目执行分析权限的SonarQube用户的登录或身份验证Token xxx sonar.password 与sonar.login用户名一起使用的密码。如果正在使用身份验Token，则应将此项留空 xxx Web Services Key Description Default sonar.ws.timeout 等待Web服务调用响应的最长时间（秒）。只有在等待服务器响应Web服务调用时在分析期间遇到超时时，才能从默认值修改此值。 60 Project Configuration Key Description Default sonar.projectDescription 项目描述。与Maven不兼容 &lt;description用于Maven项目 sonar.links.homepage 项目主页，与Maven不兼容 &lt;url&gt;用于Maven项目 sonar.links.ci CI，与Maven不兼容 &lt;ciManagement&gt;&lt;url&gt;用于Maven项目 sonar.links.issue Issue tracker，与Maven不兼容 &lt;issueManagement&gt;&lt;url&gt;用于Maven项目 sonar.links.scm 项目原仓库，与Maven不兼容 &lt;scm&gt;&lt;url&gt;用于Maven项目 sonar.links.scm_dev 开发者连接，与Maven不兼容 &lt;scm&gt;&lt;developerConnection&gt;用于Maven项目 sonar.tests 包含测试的目录的逗号分隔路径,与Maven不兼容 Maven项目的默认测试位置 sonar.sourceEncoding 源文件编码 系统编码 sonar.externalIssuesReportPaths 以逗号分隔的通用Issue上报路径列表 sonar.projectDate 为分析指定日期(yyyy-MM-dd) 当前日志 sonar.projectBaseDir 当您需要在除启动它之外的目录中进行分析时，请使用此属性 xxx sonar.working.directory 设置使用SonarScanner或SonarScanner for Ant（版本大于2.0）触发的分析的工作目录 .sonar sonar.scm.provider 此属性可用于明确告知SonarQube应使用哪个SCM插件来获取项目上的SCM数据 xxx sonar.scm.forceReloadAll 默认情况下，仅检索已更改文件的blame信息。将此属性设置为true可加载所有文件的blame信息 xxx sonar.coverage.jacoco.xmlReportPaths 导入以XML文件形式提供的JaCoCo代码覆盖率报告。此属性接受多个逗号分隔的条目。必须在分析之前生成JaCoCo XML报告 target/site/jacoco/jacoco.xml build/reports/jacoco/test/jacocoTestReport.xml Duplications Key Description Default sonar.cpd.exclusions 要从复制检测中排除的以逗号分隔的文件路径模式列表 xxx sonar.cpd.${language}.minimumtokens xxx 100 sonar.cpd.${language}.minimumLines 如上 10 Analysis Logging Key Description Default sonar.log.level 控制分析期间生成的日志级别 INFO sonar.verbose 向客户端和服务器端分析日志添加更多详细信息 false sonar.showProfiling 显示日志以查看分析仪花费时间的位置 false sonar.scanner.dumpToFile 将指向文件的完整属性列表输出到扫描程序API，作为调试分析的方法 xxx sonar.scanner.metadataFilePath 设置扫描程序写入report-task.txt文件的位置，该文件包含ceTaskId等 sonar.working.directory的值 后台任务Background Tasks 一个后台任务可以是: 导入一个分析报告 the computation of a Portfolio 导入或导出一个项目 ### 扫描程序完成分析后会发生什么 What happens after the scanner is done analyzing? 在相关后台任务完成之前，分析尚未完成。即使SonarScanner的日志显示执行完成，在完成后台任务之前，分析结果在SonarQube项目中将不可见。在SonarScanner外出分析代码后，分析结果(Sources, Issues, Metrics) - 分析报告 - 将发送到SonarQube Server，一共计算引擎进行最终处理。分析报告按顺序排队和处理。 在项目级别，当有待处理的分析报告等待消耗时，标题中的Pending（待处理）通知将在最近完成的分析的日期旁。 全局管理员可在Administration &gt; Projects &gt; Background Tasks查看当前队列；项目管理员可在Administration &gt; Background Tasks查看相关任务。 如何知道分析报告处理失败的时间How do I know when analysis report processing fails? 后台任务通常会成功，但有时候异常会导致处理失败。例如: 处理大项目是内存不足(OOM) 现有模块或项目的密钥与报告中的密钥冲突 … 当发生这种情况时，失败的状态会反映在项目主页上，但这需要有人注意到它。你还可以选择在后台任务失败时通过电子邮件接收通知(Notifications)——无论是逐个还是全局。 如何诊断失败的后台任务How do I diagnose a failing background task? 对于没法分析报告，都有一个下拉菜单，允许你访问扫描程序上下文(Scanner Context)，显示代码扫描是扫描程序的配置。如果任务处理失败，则可使用其它选项显示错误详细信息(Show Error Details)，以获取处理后台任务失败的详情。 如何取消待处理的分析报告How do I cancel a pending analysis report? 管理员可通过单击取消处理待处理任务(pending task)，一旦报告开始处理，取消它就为时已晚。 通用问题数据Generic Issue Data SonarQube支持通用导入格式，用于在代码中引发external issues。它旨在允许你从你喜欢的linter导入issues，即使它不存在插件。 外部问题受到两个重要限制: 它们无法在SonarQube内管理 在SonarQube中无法管理引发这些问题的规则的激活 Import分析参数sonar.externalIssueReportPaths接受以逗号分隔的报告路径列表。每个报告必须在顶层(top-level)包含一个名为issues对象的问题对象数组。 Issue字段: engineId - string ruleId - string primaryLocation - Location object type - string. One of BUG, VULNERABILITY, CODE_SMELL severity - string. One of BLOCKER, CRITICAL, MAJOR, MINOR, INFO effortMinutes - integer, optional. Defaults to 0 secondaryLocations - array of Location objects, optional Location字段: message - string filePath - string textRange - TextRange object, optional for secondary locations only TextRange字段: startLine - integer. 1-indexed endLine - integer, optional. 1-indexed startColumn - integer, optional. 0-indexed endColumn - integer, optional. 0-indexed 栗子以下是预期格式的栗子: 1234567891011121314151617181920212223242526272829303132333435363738394041&#123; &quot;issues&quot;: [ &#123; &quot;engineId&quot;: &quot;test&quot;, &quot;ruleId&quot;: &quot;rule1&quot;, &quot;severity&quot;:&quot;BLOCKER&quot;, &quot;type&quot;:&quot;CODE_SMELL&quot;, &quot;primaryLocation&quot;: &#123; &quot;message&quot;: &quot;fully-fleshed issue&quot;, &quot;filePath&quot;: &quot;sources/A.java&quot;, &quot;textRange&quot;: &#123; &quot;startLine&quot;: 30, &quot;endLine&quot;: 30, &quot;startColumn&quot;: 9, &quot;endColumn&quot;: 14 &#125; &#125;, &quot;effortMinutes&quot;: 90, &quot;secondaryLocations&quot;: [ &#123; &quot;message&quot;: &quot;cross-file 2ndary location&quot;, &quot;filePath&quot;: &quot;sources/B.java&quot;, &quot;textRange&quot;: &#123; &quot;startLine&quot;: 10, &quot;endLine&quot;: 10, &quot;startColumn&quot;: 6, &quot;endColumn&quot;: 38 &#125; &#125; ] &#125;, &#123; &quot;engineId&quot;: &quot;test&quot;, &quot;ruleId&quot;: &quot;rule2&quot;, &quot;severity&quot;: &quot;INFO&quot;, &quot;type&quot;: &quot;BUG&quot;, &quot;primaryLocation&quot;: &#123; &quot;message&quot;: &quot;minimal issue raised at file level&quot;, &quot;filePath&quot;: &quot;sources/Measure.java&quot; &#125; &#125;]&#125; 通用测试数据Generic Test Data 开箱即用，SonarQube支持用于测试覆盖和测试执行导入的通用格式。如果你的语言不插件不支持你的Coverage引擎的本机输出格式，只需将它们转换为这些格式即可。 Generic Coverage报告路径应该以逗号分隔的列表传递给: sonar.coverageReportPaths 支持的格式由sonar-generic-coverage.xsd进行描述: 123456789101112131415161718192021222324&lt;xs:schema&gt; &lt;xs:element name=&quot;coverage&quot;&gt; &lt;xs:complexType&gt; &lt;xs:sequence&gt; &lt;xs:element name=&quot;file&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;&gt; &lt;xs:complexType&gt; &lt;xs:sequence&gt; &lt;xs:element name=&quot;lineToCover&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;&gt; &lt;xs:complexType&gt; &lt;xs:attribute name=&quot;lineNumber&quot; type=&quot;xs:positiveInteger&quot; use=&quot;required&quot;/&gt; &lt;xs:attribute name=&quot;covered&quot; type=&quot;xs:boolean&quot; use=&quot;required&quot;/&gt; &lt;xs:attribute name=&quot;branchesToCover&quot; type=&quot;xs:nonNegativeInteger&quot;/&gt; &lt;xs:attribute name=&quot;coveredBranches&quot; type=&quot;xs:nonNegativeInteger&quot;/&gt; &lt;/xs:complexType&gt; &lt;/xs:element&gt; &lt;/xs:sequence&gt; &lt;xs:attribute name=&quot;path&quot; type=&quot;xs:string&quot; use=&quot;required&quot;/&gt; &lt;/xs:complexType&gt; &lt;/xs:element&gt; &lt;/xs:sequence&gt; &lt;xs:attribute name=&quot;version&quot; type=&quot;xs:positiveInteger&quot; use=&quot;required&quot;/&gt; &lt;/xs:complexType&gt; &lt;/xs:element&gt;&lt;/xs:schema&gt; 看起来像这样: 123456789&lt;coverage version=&quot;1&quot;&gt; &lt;file path=&quot;xources/hello/NoConditions.xoo&quot;&gt; &lt;lineToCover lineNumber=&quot;6&quot; covered=&quot;true&quot;/&gt; &lt;lineToCover lineNumber=&quot;7&quot; covered=&quot;false&quot;/&gt; &lt;/file&gt; &lt;file path=&quot;xources/hello/WithConditions.xoo&quot;&gt; &lt;lineToCover lineNumber=&quot;3&quot; covered=&quot;true&quot; branchesToCover=&quot;2&quot; coveredBranches=&quot;1&quot;/&gt; &lt;/file&gt;&lt;/coverage&gt; 根节点应该命名为coverage，其version属性应设置为1。 为每个文件插入一个可由测试覆盖的文件元素。其path属性可以是绝对的，也可是相对的。它具有以下属性: lineNumber(强制性) covered(强制性) - 布尔值，指示测试是否实际命中改行 branchesToCover(可选) - 可覆盖的分支数量 coveredBranches(可选) - 实际有测试覆盖的分支数量 Generic Execution报告路径应以逗号分隔的列表传递给: sonar.testExecutionReportPaths 支持的格式如下: 1234567891011121314&lt;testExecutions version=&quot;1&quot;&gt; &lt;file path=&quot;testx/ClassOneTest.xoo&quot;&gt; &lt;testCase name=&quot;test1&quot; duration=&quot;5&quot;/&gt; &lt;testCase name=&quot;test2&quot; duration=&quot;500&quot;&gt; &lt;skipped message=&quot;short message&quot;&gt;other&lt;/skipped&gt; &lt;/testCase&gt; &lt;testCase name=&quot;test3&quot; duration=&quot;100&quot;&gt; &lt;failure message=&quot;short&quot;&gt;stacktrace&lt;/failure&gt; &lt;/testCase&gt; &lt;testCase name=&quot;test4&quot; duration=&quot;500&quot;&gt; &lt;error message=&quot;short&quot;&gt;stacktrace&lt;/error&gt; &lt;/testCase&gt; &lt;/file&gt;&lt;/testExecutions&gt; 根节点应该被命名为testExecutions，它的version属性应该被设置成1。为每个测试文件插入一个文件元素，其path属性可以是绝对的，也可是相对于模块的根。 注意，与覆盖率报告不同，报告中的文件必须是测试文件名，而不是测试所涵盖的源代码文件。 在file元素内，通过单元测试为每个测试运行插入一个testCase。它具有以下属性/子项: testCase（强制性） name（强制性）: 测试事例的名称 duration(强制性): long value，ms为单位 failure|error|skipped(可选): 如果测试不正确，请使用消息和长描述报告原因 message(强制): 描述原因的短消息 stacktrace（可选）: 包含有关失败、错误、跳过状态的详细信息 PR分析Pull Request Analysis PR分析是作为Developer Edtion的一部分提供。它允许你: 在SonarQube UI中查看你的PR分析结果并查看状态以显示存在未解决的问题 在你的SCM提供商界面中使用SonarQube issue自动装饰你的PR 从项目的branch and pull request的下拉菜单中可以在SonarQube中看到PR。启用PR装饰后，SonarQube会在PR上发布分析状态。 SCM集成在代码分期期间收集SCM数据可以解锁许多SonarQube功能: 自动Issue分配 代码查看器中查看代码注释 SCM-driver的新代码检测，没有SCM数据，SonarQube使用分析日期确定新代码 SCM集成需要你的SCM提供商，默认情况下支持SVN和Git。其它提供商，请参阅Marketplace。如果需要，你可以通过管理设置将其在全局/项目级别将其关闭。 Git SVN Branches分支分析作为Developer Editon的一部分提供。分支分析允许你: 分析 long-lived branches 分析 short-lived branches 在短期分支的状态受到影响时通知外部系统 由于分支功能是开发版(也就是付费版)功能，因此社区版只能对每个分支创建一个项目。 例如: 1234567891011repo: zhang-repobranch: - master - test - zhangprojects: - zhang-repo-master - zhang-repo-test - zhang-repo-zhang 用户指南User Guide 修复漏水Fixing the Water Leak 什么是漏水What is the Water Leak 想象一下，有一天你回到家发现厨房地板上有一滩水，水慢慢变大。你想去拿拖把？还是找到漏水源头并修复它？选择很明显，你得修复它。 那么为什么与代码质量(code quality)有什么不同呢？当你使用SonarQube分析应用程序并意识到它有很多技术债务(technical debt)，这种下意识的反应通常是开始修复-这样那样，要么整理一个补救计划。这就像每天拖地一次而却忽略了漏水源头一样。 通常在这种传统方法中，在发布版本之前，定期进行代码质量(code quality)审计结果是开发人员在发布之前应该采取的行动。这种方法可能在短期内有效，特别是在强有力的管理支持下，但在中长期内始终失败，因为: 代码审查(code review)过程太迟，没有利益相关者热衷于解决问题，每个人都希望新版本发布 开发者通常会推迟不了解项目上下文的外部团队提出的建议。顺便提一下，正在审查的代码已经过时了 使用这种方法明显缺乏对代码质量的所有权。谁拥有质量审查权限？没有人 在整个应用程序投入生产之前，需要检查整个应用程序，显然不可能对所有应用程序使用相同的标准。每个项目都会进行谈判，这将耗尽整个过程的可信度 相反，为什么不将你在家中使用的相同的简单逻辑应用于管理代码质量的方式？修复泄露(leak)意味着将重点放在新代码上，即自上次发布以来添加或更改的代码。然后事情就变得很容易了: Quality Gate可以每天运行，并且可通过它。发版时没有任何意外 开发人员很难回避他们前一天介绍的问题。相反，他们通常很乐意在代码仍然新鲜时修复问题 代码质量有明确的所有权 做不做的标准在不同的应用程序中是一致的，并且在团队之间共享 成本微不足道，因为它是开发过程中的一部分 最为奖励，变化最大的代码具有最高的可维护性，并且未变更的代码具有最低的维护性，这很有意义。 怎么做SonarQube提供两种主要工具来帮助你找到泄漏点: 新代码指标(metrics)显示当前代码与你在其历史记录(previous_version)中选择的特定点之间的度量差异 新代码主要基于SCM blame 数据监测，从新代码期(泄漏期)的第一次分析开始，需要时使用回退机制 Quality Gates允许你设置测量代码的布尔阈值。将它们与差异指标一起使用，可确保你的代码质量随着时间的推移在正确的方向上行驶 项目页Project Page 项目主页(Project Homepage)是任何项目的切入点，它显示: the releasability status of the project the current state of its quality the quality of what has been produced since the beginning of its New Code Period 项目页面回答了两个问题: can I release my project today? if not, what should I improve to make the project pass the Quality Gate? 今天能发版吗Can I release today? 由于 Quality Gate 是你执行质量策略的最强大的工具，因此该页面以项目的当前质量门状态开始。如果项目通过，则会显示一个简单的绿色全清除。 如果没有，可立即获得详细信息和drill-downs，以便快速识别出错的地方，每个错误条件的一个部分显示当前项目值是什么以及它应该是什么。像往常一样，你可以点击当前值来进行深入分析。 应该优先解决什么What should I fix first? 因为提高项目质量的最佳方法是在问题变得根深蒂固之前捕获并修复新问题，项目的第一个视图以新代码周期为中心，在项目主页右侧以黄色突出显示。项目空间页面显示关键指标的高级摘要，包括当前值和新代码周期值。 在Quality Gate信息的下方，可以获得可靠性和安全域中的旧问题和新问题的数量。然后是可维护性域。单击页面上的任何图形将转到“详细信息”页面或“问题”页面中的详细视图。 开发人员必须做的最重要的事情是确保屏幕黄色部分的新问题得到确认，审核和修复，并确保测试涵盖新代码以防止将来出现回归。无论过去引入了多少问题，或者总体上测试覆盖范围有多少，关注新增问题将确保情况不会降低您之前在生产中发布的版本。 那么，您应该先找到哪些问题：错误，漏洞或代码异味？这取决于，因为答案取决于您的问题的性质。假设你有一个重复5次的代码块问题，在这个重复的代码块中，你有3个Bug和5个安全问题。最好的方法可能是首先修复重复，然后解决新集中位置的错误和漏洞，而不是修复它们5次。这就是为什么您需要在开始解决之前检查新问题。 ApplicationApplications are available as part of the Enterprise Edition. PortfoliosPortfolios are available as part of the Enterprise Edition. Issues在运行分析时，每当一段代码破坏编码规则时，SonarQube就会引发一个issue。编码规则(coding rules)是通过每种语言的相关质量配置文件定义的。 每个问题有五种严重程度: BLOCKER - 很有可能影响生产中应用程序行为的错误。必须立即修复 CRITICAL - 要么是在生产环境中影响应用程序行为可能性很小的bug，要么是代表安全漏洞的问题。必须立即检查代码 MAJOR - 可能严重影响开发人员生产力的质量缺陷 MINOR - 会轻微影响开发人员生产力产生的质量缺陷 INFO - 既不是错误，也不是质量缺陷，只是一个提示 理解issue上下文Understanding issue context 有时，一旦指出问题，问题就不言而喻了。例如，你的团队已约定了变量命名规则，在某个变量名出线问题时，你不需要理解大量上下文来理解该问题。但在其它情况下，上下文可能对理解为什么会出现这个问题至关重要。这就是为什么SonarQube不仅支持显示问题消息的主要问题位置，还支持次要问题位置。 但有时候，贡献位置地点并不足以理解问题。例如，当通过代码在某些路径上取消引用空指针时，您真正需要的是问题流。每个流程都是一组辅助位置，用于显示可能发生问题的代码的确切路径。 生命周期Lifecycle of Code Smell, Bug, and Vulnerability Issues 状态Status 创建之后，Issue会在生命周期中流动，可能为以下五种状态之一: 打开(Open) - 由SonarQube在新问题上设定 确认(Confirmed) - 手动确认以指示问题有效 解决(Resolved) - 手动设置以指示下一个分析应该关闭改问题 重开(Reopened) - 当一个已解决的问题实际上没有得到纠正时，SonarQube会自动设置 关闭(Closed) - 有SonarQube自动设置自动创建的问题 处理方式Resolutions 已关闭的问题将有一下两种方式之一: 已修复(Fixed) - 当后续分析显示问题已更正或文件不再可用时自动设置 已移除(Removed) - 当相关规则不再可用时自动设置。改规则可能无法使用，因为它已从质量配置文件中删除，或者因为已卸载基础插件 Resolved issues好友两个处理方式: 误判(False Positive) - 手动设置 不会修复(Won’t Fix) - 不会修复 问题工作流程Issue Workflow 在以下情况下，问题会自动关闭(Status: Closed): 问题以正确修复（Resolution: Fixed） 问题不再存在，因为相关编码规则已停用或不再可用(Resolution: Removed) 在以下情况下，问题会自动重新打开(Status: Reopened): 手动修改解决方式为已修复(但是不是误判)的问题，有后续分析显示仍然存在 安全热点问题的生命周期Lifecycle of Security Hotspot Issues 安全热点问题具有专用的生命周期。它们不被视为可操作，必须由具有相关权限的用户进行审核。 创建之后，安全热点问题将流经专用的生命周期，可能是以下四种状态之一: Open - 由SonarQube在新问题上自动设置 Resolved(Won’t Fix) - 当安全审核员接受开发人员针对手动漏洞所做的修复或安全审核员清楚打开的热点或手动漏洞时，SonarQube会自动设置 To Revied - 当开发人员请求安全审核员查看他对手动漏洞所做的修复时自动设置 Reopened - 当开发人员解除打开的手动漏洞或安全审计员手动重新打开问题以便对已解决的问题运行新审计时设置 如果删除了包含安全热点的代码，则只会关闭安全热点问题。如果从项目的质量配置文件中删除了标识热点的规则，则安全热点也可能会被删除。 理解哪些问题是新的Understanding which Issues are “New” 为了确定问题的创建日期，在每次分析期间执行算法已确定问题是新的还是之前存在的。此算法依赖于报告问题的行的内容的哈希值(不包括空格)。对于多行问题，使用第一行的哈希值。对于每个文件(在检测到文件重命名后)，算法将从先前的分析中获取问题的基本列表，并尝试将这些问题与新分析报告的原始问题列表进行匹配。该算法尝试使用最强的证据进行首次匹配，然后再回到较弱的启发式算法。 如果问题是在同一规则上，具有相同的行号和相同的行哈希 - 匹配 检测到块在文件内移动，然后如果问题出在同一行(移动的)和同一条规则上- 匹配 在相同的规则上，使用相同的消息并使用相同的行哈希 - 匹配 在相同的规则上，使用相同的消息并使用相同的行号 - 匹配 在相同的规则上，使用相同的行哈希 - 匹配 是否有匹配CLOSED的问题 - 匹配和重新打开 了解问题回溯Understanding Issue Backdating 一旦问题被确定为新，下一个问题便是提供它的日期。例如，如果它已经在代码中存在了很长时间，但只能在最近的分析中找到，因为新的规则被添加到配置文件中？该问题是否应该在其行的最后一次更改日期或首次提出的分析日期之间给出？那就是它应该回溯吗？ 如果最后一次更改改行的日期可用，那么在某些情况下，该问题将被回溯: 首先分析项目或分支 当配置文件中的规则为新时 当分析程序升级后 当规则是外部的 因此，回溯可能会使新提出的问题原理New Code Period。 自动问题分配Automatic Issue Assignment For Bug, Vulnerability and Code Smell For Security Hotspot User Correlation Known Limitation 问题编辑Issue edits SonarQube的问题工作流程可帮助你管理问题。你可对一个Issue做七件不同事情，这些行为可分为三类: Technical Review Confirm False Positive Won’t Fix Severity change Resolve Security Hotspots Detect Clear Request Review Reject Dispositioning General Comments Tag Bulk Change 清除已解决的问题Purging Closed Issues 默认情况下，已关闭的问题将保留30天。当然，你也可以修改它。 RulesSonarSource Rules: https://rules.sonarsource.com/ 概述在SonarQube中，分析程序提供在源代码上执行的规则来生成问题。有四种类型的规则: Code Smell (Maintainability domain) Bug (Reliability domain) Vulnerability (Security domain) Security Hotspot (Security domain) 规则默认情况下，点击带单栏Rules时，你将看到SonarQube实例上安装的分析程序带来的所有可用规则。你可根据以下条件缩小范围: Language Type Tag Repository Default Severity Status Available Since Template: 显示允许创建自定义规则的规则模板 Quality Profile 规则细节要查看规则的详细信息，请点击它。除了基本规则数据之外，您还可以查看其中活动的配置文件（如果有）以及已经引发了多少未解决的问题。只有拥有正确的权限时，才能使用以下两个操作: Add/Remove Tags Extend Description 规则模板和自定义规则Rule Templates and Custom Rules 规则模板(Rule templates)由创建提供，允许用户在SonarQube中定义自己的规则。它位于Rules -&gt; Template。 要从模板创建自定义规则，你必须填写一下信息: Name Key (auto-suggested) Description (Markdown format is supported) Default Severity Status The parameters specified by the template 扩展编码规则Extending Coding Rules 可以添加自定义编码规则。 规则类型和严重性Rule Types and Severities Type: Bug Vulnerability Code Smell Security Hotspot Severity: Blocker Critical Major Minor Info 安全相关的规则Security-related Rules SonarQube质量类型有三种不同的规则: Reliability (bug) Vulnerability (security) Maintainability (code smell) 但另外一种方式，只有两种类型: security rule 其它 两者之间的区别并不在它们捕获的内容，而在于她们来自何处以及强加于它们的标准。 从安全相关的规则的期望是什么What to expect from security-related rules 需要明确的是，SonarQube语言插件中实现的大多数规则的标准是非常严格: 没有误报。对于正常规则，你应该能够确信任何报告给你的问题确实是一个问题。 但对于与安全相关的规则，情况略有不同。例如，许多安全指南讨论了应如何处理敏感数据。但是，由于规则中不可能确定哪些数据是敏感，哪些是不敏感。因此选择变为： 保持无误判标准并且不实施与安全相关的规则，或者实施与安全的规则不同的标准。 这就是为什么与安全相关的规则很广泛。官方的想法是，该规则将标记任何可疑的内容，并将其留给安全审核人员来剔除误报并发送真正的问题进行补救。 安全热点是一种特殊类型的问题，用于识别安全审核人员应审核的敏感区域，以确定它们是否真的是漏洞。有关热点和审计过程的详细信息，请参阅安全审核和报告。 与安全相关的规则来自何方Where security-related rules come from 绝大多数与安全相关的规则源于既定标准: CWE(Common Weakness Enumeration)：是美国MITRE机构提出的一套语言标准，用于描述软件安全弱点的通用化描述语言。每个CWE条目都包含了CWE标识符/弱点类型名称、类型的描述、弱点的行为、弱点的利用方法、利用弱点的可能性、可能导致的后果、应对措施、代码示例、对应的CVE漏洞数量、参考信息等内容。 SANS Top 25 - CWE/SANS TOP 25 Most Dangerous Software Errors OWASP Top 10 - OWASP Top 10 Application Security Risks 要查找与任何这些标准相关的规则，你可以按标签或文本搜索规则。 CWECWE标准代表Common Weakness Enumeration: Common Weakness Enumeration (CWE™) 是一个常见软件弱点的正式列表或字典，可能出现在软件的体系结构、设计代码或实现中。可能导致可利用的安全漏洞。创建CWE是为了描述软件安全漏洞的通用语言，作为针对这些弱点的软件安全工具的衡量标准；并为弱点识别、缓解和预防工作提供共同的基线标准。CWE是弱化的描述的层次结构。层次结构中的最低级别是弱点基础(Weakness Base)，它描述了细腻度的弱点。 符合特定要求的工具可以认证为CWE兼容。这些要求是: 您必须能够使用CWE标识符搜索与CWE相关的规则。要在SonarQube平台中执行此操作，只需将CWE标识符（例如CWE-595）放在规则页面上的搜索文本输入中并运行搜索 规则必须与其相关的CWE项目准确链接。要查看SonarQube规则的CWE映射，请参阅规则说明底部的规则参见部分 您必须能够从问题中识别相关的CWE。要在SonarQube平台中执行此操作，请参阅相关规则 产品文档必须包含CWE和CWE兼容性的说明 除了通过CWE id搜索规则外，您还可以通过 cwe rule tag 进行搜索 SANS TOP 25SANS Top 25列表是由SANS组织编制的CWE中列出的25个最危险错误的集合。当前的SANS列表分为三类： Insecure Interaction Between Components Risky Resource Management Porous Defenses 要查找与SANS Top 25相关的规则，您可以对类别或相关CWE项目执行文本搜索，或执行规则标记搜索。 OWASP Top 10OWASP代表Open Web Application Security Project。它是: 501(c)(3)全球非营利慈善组织，致力于提高软件的安全性。我们的使命是使软件安全可见，以便全世界的个人和组织能够就真正的软件安全风险做出明智的决策。 OWASP Top 10列出了各种各样的弱点，每个弱点都可以映射到许多单独的规则。OWASP TOP 10在SonarQube中也对应相关的tag。 要查找与OWASP Top 10相关的规则，您可以对类别执行文本搜索，或执行规则标记搜索。 內建规则和标签Built-in Rule Tags 标签(tag) 是一种对问题(issue)和规则(rule)进行分类的方法。问题会继承引发它们的规则上的标记。有些标签适用于特定语言，但是更多的标签出现在各种语言中。用户可以为规则和问题添加标签。但大多数规则都有一些开箱即用的标签。以下是一些非全面的、包含一些內建标签: brain-overload - 一次有太多的东西要留在脑海里 bad-practice - 代码可能按设计工作，但它的设计方式被广泛认为是一个坏主意 cert - 设计CERT标准中的规则 clumsy - 用于完成可以更清晰和简洁地完成的事情的额外步骤 confusing - 将使维护者更长时间地理解，而不是代码实际所做的事情 convention - 编码约定，如格式化、命名、空格… cwe - CWE安全规则 design - 代码设计存在一些问题 lock-in - 使用特定于环境的功能 misra - MISRA标准相关的规则 owasp - 与OWASP TOP 10安全标准相关的规则 pitfall - 没有什么不对，但未来可能出现问题;已经为下一个人设置了一个陷阱，他可能会陷入其中并搞砸了代码 sans-top25 - 与SANS Top 25 Coding Errors安全相关 suspicious - 它不能保证这是一个bug，但它看起来很可疑。至少，代码应该重新检查并且可能为了清晰而重构 unpredictable - 代码可以在当前条件下正常工作，但如果条件发生变化可能会失败 unused - 未使用的代码 user-experience - 代码在技术上没有任何问题，但它可能会使您的部分或全部用户讨厌您 Quality Gates 概述质量阈(Quality Gates)是你在组织中实施质量策略的最佳方式。它可以回答一个问题: 我今天可以将项目发上线吗？为了回答这个问题，你可以根据测量项目的度量阈值定义一组布尔条件，例如: No new blocker issues Code coverage on new code greater than 80% … 理想状况下，所有项目都将通过同一质量阈进行验证。但这并不总是实用的。例如，你可能会发现: 技术实现因应用程序而异 您希望确保对某些应用程序有更强的要求 … 这就是为什么你可以根据需要自定义质量阈，它就在顶部的菜单栏上。 最佳质量阈配置Use the Best Quality Gate Configuration 质量阈默认激活并视为內建和只读的Sonar war方式，由SonarQube提供。它代表了我们对实施修复泄露。根据SonarQube的功能自动调整 有三个指标允许你强制执行给定的可靠性，安全性和可维护性的评级。不仅仅是整体而且还有新代码。建议使用这些指标，并将其作为默认质量阈的一部分，以便开发人员在项目页面上查看质量阈时更清楚的反馈。 不要忘记质量阈条件必须使用差值，检查绝对值是没有意义的(如: 代码行数大于1000)。 推荐的质量阈(Recommended Quality Gate) 內建的Sonar way质量阈都推荐用于大多数项目。如果专注于保持新代码清洁，而不是花费大量时间来修复旧代码。它开箱即用，已被设置为默认配置文件。 质量阈状态Quality Gate Status 当质量阈失败时获得通知Getting Notified When a Quality Gate Fails 使用通知机制，在质量阈失败时通知用户。为此，请订阅New quality gate status通知。 安全Security 任何用户(甚至是匿名用户)都可以访问质量阈。要就行更改(create, edit, delete)，必须授予用户管理质量阈的权限。项目管理员可选择与他们项目相关的质量阈。 定义质量阈Defining Quality Gates 要管理质量阈，请转到菜单栏的Quality Gates。 每个质量阈条件都是以下组合: 测量(measure) 比较符(comparison operator) 错误值(error value) 栗子，条件可能是: measure: Blocker issue comparison operator: &gt; error value: 0 指标Metric Definitions 项目有如下指标: 复杂度(Complexity) 重复(Duplications) 问题(Issues) 可维护性(Maintainability) 质量阈(Quality Gates) 可靠性(Reliability) 安全性(Security) 大小(Size) 测试(Tests) 复杂度应用的控制流是简单还是复杂。 圈复杂度Cyclomatic Complexity 可以计算出达到全面覆盖需要的最少测试用例。它是基于通过代码的路径数计算的，每当函数的控制流分裂时，复杂度计数器就会增加1。每个函数的最小复杂度为1.此计算因语言而异，因为关键字和功能有所不同。 特定语言的详细信息: Language Notes ABAP 这些关键字将使复杂度加一: AND , CATCH , CONTINUE , DO , ELSEIF , IF , LOOP , LOOPAT , OR , PROVIDE , SELECT…ENDSELECT , TRY , WHEN , WHILE C/C++/Objective-C 复杂度加一: `function definitions, while , do while , for , throw statements, switch , case , default , &amp;&amp; operator, operator, ? ternary operator, catch , break , continue , goto` COBOL 复杂度加一: ALSO , ALTER , AND , DEPENDING , END_OF_PAGE , ENTRY , EOP , EXCEPTION , EXIT , GOBACK , CONTINUE , IF , INVALID , OR , OVERFLOW , SIZE , STOP , TIMES , UNTIL , USE , VARYING , WHEN , EXEC CICS HANDLE , EXEC CICS LINK , EXEC CICS XCTL , EXEC CICS RETURN Java 复杂度加一: `if , for , while , case , catch , throw , &amp;&amp; , , ?` JS, PHP 复杂度加一: `function, if, &amp;&amp;, , loop, switch case, throw, catch, go to` PL/I 复杂度加一: `PROC , PROCEDURE , GOTO , GO TO , DO , IF , WHEN , , ! , = , != , &amp; , &amp;=` PL/SQL 复杂度加一: create procedure, create trigger, procedure definition, basic loop statement, when clause statement, continue statement,exit statement, for loop statement, forall statement, if statement, elsif clause, raise statement, return statement, while loop statement, and expression, or expression, when clause expression VB.NET 复杂度加一: method or constructor declaration, AndAlso , Case , Continue , End , Error , Exit , If , Loop , On Error , GoTo , OrElse , Resume , Stop , Throw , Try 认知复杂度Cognitive Complexity 对应这个应用是否很难被理解，理解代码的控制流程有多难。 重复有: 重复的块(Duplicated blocks) 重复的行(Duplicated lines) 重读文件(Duplicated files) 密度/重复行%(Duplicated lines %) 重复的块重复的行的块数。 特定语言的详细信息 非Java项目: There should be at least 100 successive and duplicated tokens. Those tokens should be spread at least on: 30 lines of code for COBOL 20 lines of code for ABAP 10 lines of code for other languages Java项目: There should be at least 10 successive and duplicated statements whatever the number of tokens and lines.检测重复时忽略缩进和字符串文字的差异。 问题有: 新问题(New issues) 新的严重问题(New xxx issues) 所有问题(Issues) 严重问题(xxx issues) 误判问题(False positive issues) 开启问题(Open issues) 确认问题(Confirmed issues) 重开问题(Reopened issues) 可维护性有: 异味(Code Smells) 新异味(New Code Smells) 维护率(Maintainability Rating) 技术债务(Technical Debt) 新代码的技术债务(Technical Debt on New Code) 技术债务率(Technical Debt Ratio) 新代码的技术债务率(Technical Debt Ratio on New Code) 维护率使用SQALE评级。与您的技术债务比率值相关的项目评级。默认的可维护性评级网格是: A=0-0.05 (&lt;5%) B=0.06-0.1 (6%-10%) C=0.11-0.20(11%-20%) D=0.21-0.5(21%-50%) E=0.51-1(50%-100%) 技术债务努力修复所有异味。以分钟(min)为度量单位存储在数据库中，单位值中的天假设为8小时(h)。 技术债务率开发成本与修复成本之间的比率。技术债务公式为: Remediation cost / Development cost 开发一行代码的成本价值为0.06 day == 0.06 * 8 * 60 min 质量阈有: 质量阈状态(Quality Gate Status) 质量阈详情(Quality Gate Details) 可靠性有: Bugs New Bugs 可靠率(Reliability Rating) 可靠性的修复工作(Reliability remediation effort) 新代码可靠性的修复工作(Reliability remediation effort on new code) 可靠率 A = 0 Bugs B = at least 1 Minor Bug C = at least 1 Major Bug D = at least 1 Critical Bug E = at least 1 Blocker Bug 修复工作努力解决所有Bugs。以分钟为单位度量值存储在数据库中。如果数值天，则假设一天为8小时。 安全性有: 漏洞(Vulnerabilities) 新漏洞(New Vulnerabilities) 安全级(Security Rating) 安全修复工作(Security remediation effort ) 新代码的安全修复工作(Security remedation effort on new code) 安全评级 A = 0 Vulnerabilities B = at least 1 Minor Vulnerability C = at least 1 Major Vulnerability D = at least 1 Critical Vulnerability E = at least 1 Blocker Vulnerability 大小有: 类(Classes) 注释行(Comment lines) 注释占比(Comments %) - Comment lines / (Lines of code + Comment lines) * 100 目录(Directories) 文件(Files) 行数(Lines) 代码行数(Lines of code) 每种语言的代码行数(Lines of code per language) 函数(Functions) 测试有: 条件覆盖(Condition coverage) 新代码条件覆盖(Condition coverage on new code) 条件覆盖命中(Condition coverage hits) 逐行条件(Conditions by line) 逐行条件覆盖(Covered conditions by line) 覆盖(Coverage) 新代码覆盖(Coverage on new code) 行覆盖(Line coverage) 新代码行覆盖(Line coverage on new code) 行覆盖命中(Line coverage hits) 要覆盖的行(Lines to cover) 新代码要覆盖的行(Lines to cover on new code) 跳过单元测试(Skipped unit tests) 未覆盖条件(Uncovered conditions) 新代码未覆盖条件(Uncovered conditions on new code) 未覆盖行(Uncovered lines) 新代码未覆盖行(Uncovered lines on new code) 单元测试(Unit tests) 单元测试持续时间(Unit tests duration) 单元测试错误(Unit test errors) 单元测试失败(Unit test failures) 单元测试成功密度(Unit test success density %) - Test success density = (Unit tests - (Unit test errors + Unit test failures)) / Unit tests * 100 条件覆盖在包含一些布尔表达式的每行代码中，条件覆盖只是回答了以下问题: 每个布尔表达式是否都被评估为 true 和 false?。这是在单元测试执行期间遵循的流控制结构中可能的条件密度。 Condition coverage = (CT + CF) / (2*B), where: CT = conditions that have been evaluated to ‘true’ at least once(已经被评估为true至少一次的条件) CF = conditions that have been evaluated to ‘false’ at least once(已经被评估为false至少一次的条件) B = 条件总数(total number of conditions) 覆盖它是行覆盖和条件覆盖的混合。它的目标是为以下问题提供更准确的答案: 单元测试覆盖了多少源代码? Coverage = (CT + CF + LC)/(2*B + EL), where: CT = 已经被评估为true至少一次的条件 CF = 已经被评估为false至少一次的条件 LC = 覆盖的行(covered lines) B = 条件总数 EL = 可执行行的总数( total number of executable lines) 行覆盖在给定的代码行上，行覆盖简单地回答了以下问题: 在执行单元测试期间是否执行了这行代码? 它是单元测试的覆盖率密度: Line coverage = LC / EL, where: LC = 覆盖的行(covered lines) EL = 可执行行的总数(total number of executable lines) 概念Concepts 架构Architecture 概念 定义 Analyzer 用于分析源代码以计算快照的客户端程序 Database 存储配置和快照 Server 用于浏览快照数据和进行配置修改的Web界面 质量Quality 概念 定义 Bug 表示代码中出错的问题 Code Smell 代码中与可维护性相关的问题 Cost 花费 Debt 解决问题所需的时间 Issue 代码不符合规则时，快照上会记录一个问题。有: Bugs , Code Smells and Vulnerabilities Measure 给定时间内给定文件或项目的度量值 Metric 一种测量方式。随着时间的推移，度量标准可能具有不同的值或度量 New Code Period 需要密切关注代码中引入新问题的时间段 Quality Profile 一组规则 Rule 应该遵循的编码标准或惯例 Remediation Cost 修复漏洞和可靠性问题所需的估计时间 Snapshot 在给定时间内针对给定项目的一组度量和问题 Security Hotspot 与安全相关的问题，突出显示使用安全敏感API的一段代码 Technical Debt 修复问题所需的估计时间 Vulnerability 与安全相关的问题，代表攻击者的后门 活动Activity and History 项目活动页面提供项目文件分析的完整列表，以及随着时间推移看到项目措施演变的能力。活动页面上的图标可帮助你了解几种相互选择的度量方法的演变。 事件Events 有四种类型的事件: Quality Gate Profile Version Other SonarLintSonarLint Smart Notifications SonarLint Smart Notifications是作为Developer Edtion的一部分来提供。 智能通知允许使用SonarLint中的连接模式的开发人员以一下情况下从SonarQube接收IDE内的通知: the Quality Gate status (failed / success) of a project /solution open in the IDE changes a SonarQube analysis raises new issues introduced by this developer in a project /solution open in the IDE SonarLint智能通知的激活和取消必须由每个开发人员直接在SonarLint(IDE端)进行单独完成。可以在SonarQube上逐个服务器地在SonarLint端配置接收通知。 Security Reports 安全报告显示了什么What do the Security Reports show? 安全报告旨在快速为您提供有关应用程序安全性的全景图，并详细说明OWASP, SANS, CWE标准的详细信息。安全报告由分析器提供，分析器依赖于质量配置文件中激活的规则来引发安全问题。 热点和漏洞有什么区别What’s the difference between a Hotspot and a Vulnerability? 漏洞是代码中可以攻击的点。安全热点是安全敏感的代码段，应由具有安全审计员帽的人仔细审查。安全热点的主要目标是帮助集中手动审查应用程序源代码的安全审核员的工作。第二个目标是教育开发人员并提高他们的安全意识。 为什么某些热点和漏洞非常相似Why are some Hotspot and Vulnerability rules very similar? 它们是故意重叠的。热点规则应该包括漏洞规则的所有匹配，以及污点分析引擎无法检测漏洞的情况。 为什么我看不到任何热点Why are some Hotspot and Vulnerability rules very similar? 有三个原因: 可能真的没有它们，因为代码是在没有使用任何安全敏感API的情况下编写的 热点规则可能可用，但尚未在你的质量配置文件中激活，因此自然不会引发任何问题 你正在使用的语言分析器可能还没有提供热点规则，所以它不会引发任何热点 为什么我看不到任何漏洞由于一些热点原因，你可能没有看到任何漏洞的，但你可能会看到项目主页中报告了一些漏洞，而安全报告中没有漏洞。这是因为语言分析器可能尚未提供安全报告中可见问题所需的安全标准的元数据。 开发者是否应该关心热点可能并不需要。热点并不是真正可行的，它们只是标记潜在的问题，所以在代码上没有立即做任何事情。这就是为什么在引发热点问题时没有收到通知。 如果热点确实标记为漏洞怎么办如果您查看引发热点的代码并意识到确实存在问题，请单击当前状态以注册您在代码中检测到漏洞。完成后，它将转换为漏洞，最后触摸该行的开发人员将收到新问题通知。 热点变为漏洞后会发生什么一旦您检测到热点位置确实存在问题，它将被分配给相应的开发人员，他们将进行修复，然后必须通过UI请求审核。 热点被标记为不会修复是什么意思What does it mean for a Hotspot to be marked “Won’t Fix”? 不会修复标记用于表示已经审查了热点，并且目前无法利用这段代码创建攻击。 用户账户User Account SonarQube用户可拥有自己的空间，可查看与自己相关的内容。 User Token每个用户都可生成令牌，这些令牌可用于运行分析或调用Web服务，而无需用户的实际凭据。 项目管理Project Administration 项目存在Project Existence 通常，项目在第一次分析时创建，不会删除(除非手动删除)。你可以管你你有权限管理的项目。 在第一次分析之前配置项目 配置还未分析的项目 修改项目权限(Private/Public) - 默认情况下，任何新创建的项目都被视为Public。这意味着每个经过认证的用户都能够Browse和See Source Code 删除项目 查找不再分析的项目 管理项目历史Managing Project History SonarQube最强大的功能之一是它不仅向你展示了你今天的项目健康状况，还展示了它随时间的变化情况。它通过有选择地保留以前分析的数据来做到这一点。它没有保留所有以前的分析——这会使数据库膨胀。同样，对于它确实存在的分析，SonarQube不会保留所有数据。一旦项目快照(snapshot)从最后分析(Last analysis)移动到项目历史的一部分，项目级别下面的数据就会被清除——再次放置数据库膨胀。 通常这些都不是你需要考虑的事情。SonarQube只为你专门处理它们。但有时你可能需要从项目的历史记录中删除错误的快照或修改内存处理算法。 可查看数据库表大小: 123456# sonarUSE information_schema;DESCRIBE TABLES;SELECT TABLE_SCHEMA, TABLE_NAME, TABLE_ROWS, DATA_LENGTH FROM TABLES WHERE TABLE_SCHEMA = 'sonar' ORDER BY DATA_LENGTH DESC; 有时你可能需要手动删除项目快照，无论是因为使用了错误的质量配置文件，还是因为分析存在问题…请注意，永远不能删除最新的快照。 对于每个快照，可以手动: Add, rename or remove a version Add, rename or remove an event Delete the snapshot 缩小关注点Narrowing the Focus 如果SonarQube的结果不相关，那么没有人会想要使用它。这就是为什么精确配置每个项目要分析的内容是非常重要的一步。SonarQube为你提供了几种选项，可以准确配置要分析的内容。你可以: 完全忽略一些文件或目录 从问题中排除文件或目录，但分析所有其它方面 从重复性中排除文件或目录，但分析所有其它方面 从覆盖率中排除文件或目录，但分析其它所有方面 你可以在全局或项目级别配置它们。 忽略文件Ignore Files 建议你从库中排除生成的代码，源代码等。有四种不同的方法可将分析范围缩小到与开发团队相关的源代码。 源目录(Source Directories) 文件后缀(File Suffixes) 选择文件(Choosing Files) 源文件排除(Source File Exclusions) 测试文件排除(Test File Exclusions) 源文件包含(Source File Inclusions) 测试文件包含(Test File Inclusions) 忽略问题Ignore Issues 可使用SonarQube忽略某些组件和某些编码规则的问题。Administration &gt; General Settings &gt; Analysis Scope &gt; Issues。 请注意，以下属性只能通过Web界面设置，因为它们是多值的。 Ignore Issues on Files Ignore Issues in Blocks Ignore Issues on Multiple Criteria Restrict Scope of Coding Rules 忽略重复Ignore Duplications 可在SonarQube中阻止检查某些文件的重复性。Administration &gt; General Settings &gt; Analysis Scope &gt; Duplications。 忽略代码覆盖率Ignore Code Coverage 可以通过单元测试防止某些文件考虑用于代码覆盖。Administration &gt; General Settings &gt; Analysis Scope &gt; Code Coverage &gt; Coverage Exclusions。 模式Patterns SonarQube中可以使用以下通配符: * - 零个或多个字符(zero or more characters) ** - 零个或多个目录(zero or more directories) ? - 单个字符(a single character) 项目设置Project Settings Tags项目标签(tags) 允许对项目进行分类和分组，以便在项目页面上更容易地选择。可以从项目主页管理项目标签。 管理项Administration Items: Adding a Project Analysis Report Processing Deleting a Project Setting the New Code Period Updating Project Key Default Issue Assignee Setting Quality Gate and Quality Profiles Setting Exclusions Customizing Links Webhooks网络调用(Webhooks) 在项目完成分析后通知外部服——An HTTP POST request including a JSON payload is sent to each URL。可在项目级别和全局指定URL。项目级别的配置不会取代全局的配置，两个级别的所有Webhooks都被调用。 HTTP(s) 调用: 无论后台任务的状态如何 使用POST方法将JSON文档作为负载 使用UTF-8编码的内容类型application/json Delivery and PayloadWebhook 管理控制台显示每个Webhook的最新交付的结果和时间戳，其中有效负载可通过列表图标获得。默认保留30天的记录。URL必须在10s响应，否则传递将标记为失败。 发送带有project key的 HTTP header X-SonarQube-Project，以便快速识别所涉及的项目。 Payload是一个JSON文档，包括: 什么时候运行分析(analysedAt) 分析的项目的标识(project) 每个质量阈标准和状态(qualityGate) 每个项目的质量阈状态(qualityGate.status) 后台任务的状态和标识(status, taskId) 用于定义的属性(properties) 栗子: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&#123; "analysedAt": "2016-11-18T10:46:28+0100", "project": &#123; "key": "org.sonarqube:example", "name": "Example" &#125;, "properties": &#123; &#125;, "qualityGate": &#123; "conditions": [ &#123; "errorThreshold": "1", "metric": "new_security_rating", "onLeakPeriod": true, "operator": "GREATER_THAN", "status": "OK", "value": "1" &#125;, &#123; "errorThreshold": "1", "metric": "new_reliability_rating", "onLeakPeriod": true, "operator": "GREATER_THAN", "status": "OK", "value": "1" &#125;, &#123; "errorThreshold": "1", "metric": "new_maintainability_rating", "onLeakPeriod": true, "operator": "GREATER_THAN", "status": "OK", "value": "1" &#125;, &#123; "errorThreshold": "80", "metric": "new_coverage", "onLeakPeriod": true, "operator": "LESS_THAN", "status": "NO_VALUE" &#125; ], "name": "SonarQube way", "status": "OK" &#125;, "serverUrl": "http://localhost:9000", "status": "SUCCESS", "taskId": "AVh21JS2JepAEhwQ-b3u"&#125; 附加参数Additional parameters 通过在Webhook的URL中提供user/passwd来支持基本的身份认证机制。(如: https://myLogin:myPassword@my_server/foo) 如果使用了sonar.analysis.*属性为SonarScanner提供其它属性，则这些属性将自动添加到有效负载的properties部分。 栗子: 1sonar-scanner -Dsonar.analysis.scmRevision=628f5175ada0d685fd7164baa7c6382c1f25cab4 -Dsonar.analysis.buildNumber=12345 实例管理Instance Administration 质量配置Quality Profiles 概述质量配置(Quality Profiles)服务是SonarQube的核心，因为它是您通过定义规则集来定义需求的地方。。 理想情况下，对于任何给定的语言，所有项目都将使用相同的配置文件进行测量，但这并不总是实用的。这就是为什么您可以根据需要定义尽可能多的质量配置文件，即使建议尽可能少的质量配置文件以确保公司项目的一致性。 每个语言都带有预定义的內建配置文件(通常称为 Sonar way)，因此你可以使用SonarQube分析进行快速开始。这就是为什么只要安装新的语言插件，就可以使用至少一个配置文件。 默认的Sonar way配置文件，它包含了通常适用于大多数项目的所有规则。但作为最佳实践，你应该创建一个新的配置文件(你可以通过复制Sonar way的内容来填充它)，并使用它。因为默认的Sonar way是不可编辑的，因此你无法根据需要对其进行自定义。此外，这使你可将Sonar way视为一个基线，可在对其进行更改时跟踪自己的配置文件。此外Sonar way通常会随插件的每个新版本更新，已添加规则，有时还会调整规则严重性。任何继承自內建Sonar way的配置文件都将在事实上同时自动更新。 我该怎么做 #### 将质量配置管理的权限移交给其他人 Delegate the management of Quality Profiles to someone else? 默认情况下，管理员才有此权限。但你可以授予用户/组权限来编辑配置文件。例如将Java配置文件权限分配给Java开发专家，将Python配置文件权限分配给Python专家… 将规则从一个配置复制到另一个配置Copy the rules from one profile to another? 许多时候，人们希望使用基于內建的配置文件的配置文件进行工作，而无实际需要使用內建配置文件。 了解配置中有什么改变Know what’s changed in a profile? 当SonarQube注意到使用与先前分析不同的配置文件执行分析时，会将质量配置文件事件添加到项目的事件日志中。 将配置文件从一个实例复制到另一个实例Copy a profile from one SonarQube instance to another? 使用实例上的备份(Back UP)功能将配置文件导出到XML文件。然后在另一个实例中选择恢复(Restore)。 将一组核心规则和附加规则应用于项目Apply a core set of rules plus additional rules to a project? 使用继承，从root继承核心规则集。然后创建一个子配置文件(Sprout)，修改从Root继承，然后添加缺少的规则。 确保我的非默认配置文件应用于项目Make sure my non-default profile is used on a project? 确保我的个人配置中包含所有相关的新规则Make sure I’ve got all the relevant new rules in my profile? 比较两个规则Compare two profiles? 确保我的配置中没有任何弃用的规则Make sure I don’t have any deprecated rules in my profile? 安全Security 任何用户都可以访问质量配置服务，你可以给他们配置质量配置管理权限，让他们可以创建，删除质量配置。 安全 概述SonarQube具有许多全局安全功能: 认证和授权机制 强制身份认证 委派认证 除此之外，还可在group/user级别配置: 查看一个已存在的项目 访问项目的源代码 管理一个项目 管理质量配置，质量阈，实例… 认证Authentication 第一个问题: 匿名用户是否可以浏览SonarQube实例？当然不行！那就需要强制用户认证。 认证机制(Authentication Mechanisms) 可通过多种方式来管理认证机制: 通过SonarQube內建的user/group数据库 通过外部程序(如LDAP) 通过HTTP headers 技术用户(Technical Users) 当你在SonarQube数据库中创建用户时，他将被视为本地用户，并且针对SonarQube自己的user/group数据库进行身份认证，而不是通过任何外部工具。默认情况下，admin是本地账户。 同样，所有非本地(non-local)账户将仅针对外部工具进行身份认证。 管理员可以管理所有用户的Tokens——创建和删除。一旦创建，Token就是运行分析所需的唯一凭证，作为sonar.login属性的值来传递。 默认管理员(Default Admin Credentials) 当安装SonarQube时，会自动创建具有管理系统权限的默认用户: 12user: adminpasswd: admin 重置管理员密码Reinstating Admin Access 如果你修改了管理员密码，但又忘记了: 123USE sonar;update users set crypted_password = '$2a$12$uCkkXmhW5ThVK8mpBvnXOOJRLd64LJeHTeCkSuB3lfaR2N0AYBaSi', salt=null, hash_method='BCRYPT' where login = 'admin' 如果您删除了管理员并随后锁定了具有全局管理权限的其他用户: 123USE sonar;INSERT INTO user_roles(user_id, role) VALUES ((select id from users where login='mylogin'), 'admin'); 授权Authorization 对不同组、不同用于仅限权限分配，以访问不同的资源。 user group Global Permissions Administer System Administer Quality Profiles Administer Quality Gates Execute Analysis Create Projects Create Applications Create Portfolios Project Permissions Public and Private Administer Issues Administer Security Hotspots Administer Execute Analysis Private Browse See Source Code 默认权限的权限模板Permission Templates for Default Permissions SonarQube附带默认权限模板，该模板在创建项目，项目组合或应用程序自动授予特定组的特定权限。管理员可以编辑此模板。 加密Encryption 加密主要用于从设置中删除明文密码。实现的解决方案是基于对称密钥算法，关键是密钥存储在磁盘上的安全文件中。此文件必须由运行SonarQube Server的系统账户拥有和读取。该算法是AES 128位。 Generate the secret key Store the secret key on the SonarQube server Generate the encrypted values of your settings Use the encrypted values in your SonarQube server configuration 必须在SonarQube基础架构的所有部分之间共享唯一的密钥。在Administration &gt; Configuration &gt; Encryption生成密钥。生成密钥之后，会显示如何使用此密钥。 之后便可以为你设置的值进行加密。同样在前面的加密下进行配置。之后在SonarQube Server中使用加密后的值: 12345# conf/sonar.propertiessonar.jdbc.password=&#123;aes&#125;CCGCFg4Xpm6r+PiJb1Swfg== # Encrypted DB password...sonar.secretKeyPath=C:/path/to/my/secure/location/my_secret_key.txt 委托认证Delegating Authentication docs: https://docs.sonarqube.org/latest/instance-administration/delegated-auth/ SonarQube认证: 自带用户数据库认证 外部 HTTP header LDAP … HTTP header认证 LDAP认证 通知Notifications 可以通过邮件配置，向用户发送分析的信息的通知。 使用实践 注意:由于使用的是SonarQube CE(社区版)，因此不支持在IDE中上传分析数据，也不支持多分支(branch)分析。所以需要对这些方面做一些规范。 SonarQube的使用主要分为两个方面: 开发者 IDE CI SonarScanner CICI端 需先安装 SonarQube Scanner 应用程序，并配置相应的路径和token。 由于社区版的缘故，我只对测试分支的CI进行SonarScanner分析，并将结果上传到SonarQube Server对应项目的路径。 由于测试分支(stage)的代码都是由开发者现在本地IDE中检测过代码质量(Code Quality)之后才MR过来，所以这样更方便和实用些。 CI SonarScanner分析上传之后，SonarQube会通知项目负责人此项目代码相关情况。由项目负责人去SonarQube Web UI上再去核查相关issues，核查无误之后，才能将测试分支的代码上线。如果项目负责人检查出相关代码的某些问题，请于相关分支开发者交流，叮嘱他们现在本地IDE自测，通过之后在MR代码。 IDE只需在IDE中下载SonarLint插件，并配置上运维人员提供的地址和token就可以使用了。 由于社区版的缘故，我这里让开发者自己的分支在IDE中调用远程SonarQube进行本地代码质量检查，并不需要将开发者的分支代码情况上传到SonarQube Server端。 开发者自己检查和核对自己分支的代码质量，确认之后才将自己的代码MR到dev分支。如果项目负责人检测到某位开发者的分支代码存在问题，则这个责任由分支开发者负责和处理。 权限问题权限有一些地方需要注意: 将项目设置为私有(默认: public) 项目对应项目组(group)，对应项目成员(user) 项目组中的CI, IDE用户具有不同的权限 … 具体配置可以在使用的时候灵活修改！ API可通过SonarQube API 进行许多操作。 12# 如导出python的代码规则curl -X GET -v -u user:passwd http://localhost:9000/api/rules/search?language=python &gt; python.json Scanner docs: https://docs.sonarqube.org/display/SCAN 建议将SonarQube Scanner用作使用SonarQube分析项目的默认扫描程序。 安装 OS平台: Linux Mac OS Windows 下载对应平台的Sonar Scanner应用程序，将它们解压之后加入系统路径($PATH)。 IDESonar Scanner 支持的 IDE 有: MSBuild Maven Gradle Ant Jenkins JetBrains 在IDE中下载SonarLint插件，之后配置SonarQube Server地址和管理员给的Token便可以正常使用。社区版的SonarQube 只能在IDE中检测，无法上传。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>SonarQube</tag>
        <tag>Static Analysis</tag>
        <tag>Code Quality</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DevOps]]></title>
    <url>%2F2019%2F02%2F13%2FDevOps%2F</url>
    <content type="text"><![CDATA[参考: 维基百科 GitLab GitHub 介绍DevOps（Development和Operations的组合词）是一种重视 软件开发人员（Dev） 和 IT运维技术人员（Ops） 之间沟通合作的文化、运动或惯例。透过自动化 软件交付 和 架构变更 的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。 Auto DevOpsGitLab Auto DevOps: Auto Build Auto Test Auto Code Quality Auto SAST (Static Application Security Testing) Auto Dependency Scanning Auto License Management Auto Container Scanning Auto Review Apps Auto DAST (Dynamic Application Security Testing) Auto Deploy Auto Browser Performance Testing Auto Monitoring DevOps工具下面介绍一些DevOps需要用到的工具，可能不够详细。 基础环境IaaS: VMware Xen KVM OpenStack 云平台 … 项目管理Task: RedaMine Jira 禅道 … 代码Code: git GitLab Gogs svn 云平台 … 持续集成/发布CI/CD: Jenkins Jenkins X GitLab CICD Bamboo Maven 云平台 … 容器Container: Docker K8s CoreOS Mesos Helm 云平台 … 测试Test: Selenium Katalon Studio Watir Jmeter Loadrunner LOCUST Selenium Website: https://www.seleniumhq.org/ Selenium是一个用于自动化测试Web apps的可移植框架。 Selenium提供了一种用于创作功能测试的回放工具，无需学习测试脚本语言。 Katalon Studio Wetsite: https://www.katalon.com/ Simplify API, Web, Mobile Automation Tests. Watir Website: http://watir.com/ An open source Ruby library for automating tests.Watir interacts with a browser the same way people do: clicking links, filling out forms and validating text. JMeterApache JMeter应用程序是开源软件，纯Java应用程序，旨在加载测试功能行为和测量性能。它最初是为测试Web应用程序而设计的，但后来扩展到其他测试功能。 Apache JMeter可用于测试静态和动态资源，Web动态应用程序的性能。它可用于模拟服务器，服务器组，网络或对象上的重负载，以测试其强度或分析不同负载类型下的整体性能。 Apache JMeter功能包括: Ability to load and performance test many different applications/server/protocol types Web - HTTP, HTTPS (Java, NodeJS, PHP, ASP.NET, …) SOAP / REST Webservices FTP Database via JDBC LDAP Message-oriented middleware (MOM) via JMS Mail - SMTP(S), POP3(S) and IMAP(S) Native commands or shell scripts TCP Java Objects Full featured Test IDE that allows fast Test Plan recording CLI mode to load test from any Java compatible OS Highly Extensible core … LoadRunner Website: https://www.microfocus.com LoadRunner is a Load Testing Software LOCUST Website: https://locust.io/ GitHub: https://github.com/locustio/locust/ An open source load testing tool. Define user behaviour with Python code, and swarm your system with millions of simultaneous users. 质量与安全Quality and Security: infer SonarQube Cuckoo Sandbox OWASP ZAProxy Mobile-Security-Framework-MobSF Clair Infer GitHub: https://github.com/facebook/infer Website: https://fbinfer.com/ Infer 是一个 Java，C ++，Objective-C 和 C 的代码静态分析工具。它会产生一个潜在的bug列表。任何人都可以使用Infer在发送给用户之前拦截关键错误，并帮助防止崩溃或性能不佳。 infer 主要用于 APP 端，也就是 Android/IOS App。 SonarQube GitHub: https://github.com/SonarSource/sonarqube Website: https://www.sonarqube.org/ SonarQube 是一个开源平台，通过代码的自动化静态分析不断的检查代码质量。 SonarQube 支持20多种语言的分析，并在各种类型的项目中输出和存储问题。通过不同的插件对这些结果进行再加工处理，通过量化的方式度量代码质量的变化，从而可以方便地对不同规模和种类的工程进行代码质量管理。 MobSF GitHub: https://github.com/MobSF/Mobile-Security-Framework-MobSF Mobile Security Framework is an automated, all-in-one mobile application (Android/iOS/Windows) pen-testing framework capable of performing static analysis, dynamic analysis, malware analysis and web API testing. Clair GitHub: https://github.com/coreos/clair Vulnerability Static Analysis for Containers.Clair is an open source project for the static analysis of vulnerabilities in application containers (currently including appc and docker). 配置管理Configuration Management: Ansible ZooKeeper CFEngine Chef MAAS Puppet SaltStack Vagrant Rundeck Rudder 云平台 … 数据分析Data Analysis: Hadoop Ambari Avro Flume HBase Hive Spark Sqoop ZooKeeper 日志Log: ElasticStack Elasticsearch Logstash Beat Hadoop, Hive - 与ELK类似的方案 Flume Fluentd Splunk Kafka Loggly Papertrail 云平台 … 流Stream: Kafka Apex Flink Heron Spark Heka Api网关Api Gateway: Gloo Ambassador Spring Cloud Kong Netflix Zuul 云平台 … 性能Performance: NetData Pinpoint Datadog AppDynamics Apache JMeter ab(ApacheBench) Gatling 监控Monitoring: Zabbix Nagios Prometheus Grafana Netdata Graphite Cacti Glances Collectd Ganglia Kibana Sensu 备份Backup: 全量 增量 灰度发布 ps:参考百度百科! 灰度发布（金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。在其上可以进行A/B testing，即让一部分用户继续用产品特性A，一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。 灰度期：灰度发布开始到结束期间的这一段时间，称为灰度期。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
        <tag>运维开发</tag>
        <tag>Auto DevOps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谏逐客书]]></title>
    <url>%2F2019%2F02%2F10%2F%E8%B0%8F%E9%80%90%E5%AE%A2%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[参考: 维基百科 百度百科 介绍《谏逐客书》是李斯的一篇优秀古代公文，是应用写作法定公文研究的重要内容之一。这里的“书”不是书信，而是上书、奏章，为古代臣子向君主陈述政见的一种文体，是一种臣子向帝王逐条分析事理的公文名称，与表性质类似。该文能比较充分地体现公文的一些本质属性，正是这些公文本质属性形成了该文鲜明的特色。 文章先叙述自秦穆公以来皆以客致强的历史，说明秦若无客的辅助则未必强大的道理；然后列举各种女乐珠玉虽非秦地所产却被喜爱的事实作比，说明秦王不应该重物而轻人。文章立意高深，始终围绕“大一统”的目标，从秦王统一天下的高度立论，正反论证，利害并举，说明用客卿强国的重要性。此文理足词胜，雄辩滔滔，打动了秦王嬴政，使他收回逐客的成命，恢复了李斯的官职。 李斯（约前280年－前208年），战国末年楚国上蔡（今河南驻马店上蔡县）人，秦朝丞相，中国历史上著名的政治家、文学家和书法家。李斯早年从荀卿学帝王之术，后被秦王政任为客卿。秦王政十年（前237年）李斯上《谏逐客书》反对驱逐客卿，为秦王政所采纳。他在秦王政统一六国的事业中起了较大作用。秦统一天下后，李斯与王绾、冯劫尊秦王嬴政为皇帝，被任为丞相。李斯参与制定了秦朝的法律并完善了秦朝的制度；他主张实行郡县制、废除分封制；又主张焚烧民间收藏的《诗》、《书》、百家语，禁止私学，以加强专制主义中央集权的统治；提出并且主持了文字、车轨、货币、度量衡的统一。李斯实行郡县制等政治主张，奠定了中国两千多年政治制度的基本格局。秦始皇死后，他与赵高合谋立少子胡亥为帝。后为赵高所忌，于秦二世二年（前208年）被腰斩于咸阳。 原文会韩人郑国来间秦，以作注溉渠，已而觉。秦宗室大臣皆言秦王曰：诸侯人来事秦者，大抵为其主游间于秦耳。请一切逐客！李斯议亦在逐中。 斯乃上曰： 臣闻吏议逐客，窃以为过矣。昔穆公求士，西取由余于戎，东得百里奚于宛，迎蹇叔于宋，求丕豹、公孙支于晋；此五子者，不产于秦，而穆公用之，并国二十，遂霸西戎。孝公用商鞅之法，移风易俗，民以殷盛，国以富强，百姓乐用，诸侯亲服，获楚、魏之师，举地千里，至今治强。惠王用张仪之计，拔三川[15]之地，西并巴、蜀，北收上郡，南取汉中，包九夷，制鄢[18]、郢，东据成皋之险，割膏腴之壤，遂散六国之从，使之西面事秦，功施到今。昭王得范睢，废穰侯，逐华阳，强公室，杜私门，蚕食诸侯，使秦成帝业。此四君者，皆以客之功。由此观之，客何负于秦哉？向使四君却客而不内，疏士而不用；是使国无富利之实，而秦无强大之名也。 今陛下致昆山之玉，有随、和之宝，垂明月之珠，服太阿之剑，乘纤离之马，建翠凤之旗，树灵鼍之鼓；此数宝者，秦不生一焉，而陛下说之，何也？必秦国之所生然后可；则是夜光之璧，不饰朝廷；犀象之器，不为玩好；郑、魏之女，不充后宫；而骏良駃騠，不实外廄；江南金锡不为用，西蜀丹青不为采。所以饰后宫，充下陈，娱心意，说耳目者，必出于秦然后可；则是宛珠之簪，傅玑之珥，阿缟之衣，锦绣之饰，不进于前，而随俗雅化。佳冶窈窕，赵女不立于侧也。夫击瓮叩缶，弹筝搏髀，而歌呼呜呜快耳目者，真秦之声也；郑、卫、桑间、《昭虞》、《武象》者，异国之乐也。今弃击瓮而就郑、卫，退弹筝而取《昭虞》，若是者何也？快意当前，适观而已矣。今取人则不然：不问可否，不论曲直，非秦者去，为客者逐。然则是所重者，在乎色、乐、珠、玉，而所轻者在乎人民也；此非所以跨海内，制诸侯之术也！ 臣闻地广者粟多，国大者人众，兵疆者则士勇；是以泰山不让土壤，故能成其大；河海不择细流，故能就其深；王者不却众庶，故能明其德；是以地无四方，民无异国，四时充美，鬼神降福，此五帝、三王之所以无敌也。今乃弃黔首以资敌国，却宾客以业诸侯，使天下之士，退而不敢西向，裹足不入秦，此所谓借寇兵而赍盗粮者也。夫物不产于秦，可宝者多；士不产于秦，而愿忠者众。今逐客以资敌国，损民以益雠，内自虚而外树怨于诸侯，求国之无危，不可得也。 译文我听说官吏在商议驱逐客卿这件事，私下里认为是错误的。从前秦穆公寻求贤士，西边从西戎取得由余，东边从宛地得到百里奚，又从宋国迎来蹇叔，还从晋国招来丕豹、公孙支。这五位贤人，不生在秦国，而秦穆公重用他们，吞并国家二十多个，于是称霸西戎。秦孝公采用商鞅的新法，移风易俗，人民因此殷实，国家因此富强，百姓乐意为国效力，诸侯亲附归服，战胜楚国、魏国的军队，攻取土地上千里，至今政治安定，国力强盛。秦惠王采纳张仪的计策，攻下三川地区，西进兼并巴、蜀两国，北上收得上郡，南下攻取汉中，席卷九夷各部，控制鄢、郢之地，东面占据成皋天险，割取肥田沃土，于是拆散六国的合纵同盟，使他们朝西事奉秦国，功烈延续到今天。昭王得到范雎，废黜穰侯，驱逐华阳君，加强、巩固了王室的权力，堵塞了权贵垄断政治的局面，蚕食诸侯领土，使秦国成就帝王大业。这四位君主，都依靠了客卿的功劳。由此看来，客卿哪有什么对不住秦国的地方呢！倘若四位君主拒绝远客而不予接纳，疏远贤士而不加任用，这就会使国家没有丰厚的实力，而让秦国没有强大的名声了。 陛下罗致昆山的美玉，宫中有随侯之珠，和氏之璧，衣饰上缀着光如明月的宝珠，身上佩带着太阿宝剑，乘坐的是名贵的纤离马，树立的是以翠凤羽毛为饰的旗子，陈设的是蒙着灵鼍之皮的好鼓。这些宝贵之物，没有一种是秦国产的，而陛下却很喜欢它们，这是为什么呢？如果一定要是秦国出产的才许可采用，那么这种夜光宝玉，决不会成为秦廷的装饰；犀角、象牙雕成的器物，也不会成为陛下的玩好之物；郑、卫二地能歌善舞的女子，也不会填满陛下的后宫；北方的名骥良马，决不会充实到陛下的马房；江南的金锡不会为陛下所用，西蜀的丹青也不会作为彩饰。用以装饰后宫、广充侍妾、爽心快意、悦入耳目的所有这些都要是秦国生长、生产的然后才可用的话，那么点缀有珠宝的簪子，耳上的玉坠，丝织的衣服，锦绣的装饰，就都不会进献到陛下面前；那些闲雅变化而能随俗推移的妖冶美好的佳丽，也不会立于陛下的身旁。那敲击瓦器，拍髀弹筝，乌乌呀呀地歌唱，能快人耳目的，确真是秦国的地道音乐了；那郑、卫桑间的歌声，《韶虞》《武象》等乐曲，可算是外国的音乐了。如今陛下却抛弃了秦国地道的敲击瓦器的音乐，而取用郑、卫淫靡悦耳之音，不要秦筝而要《韶虞》，这是为什么呢？难道不是因为外国音乐可以快意，可以满足耳目功能的需要么？可陛下对用人却不是这样，不问是否可用，不管是非曲直，凡不是秦国的就要离开，凡是客卿都要驱逐。这样做就说明，陛下所看重的，只在珠玉声色方面；而所轻视的，却是人民士众。这不是能用来驾驭天下，制服诸侯的方法啊！ 我听说田地广就粮食多，国家大就人口众，武器精良将士就骁勇。因此，泰山不拒绝泥土，所以能成就它的高大；江河湖海不舍弃细流，所以能成就它的深邃；有志建立王业的人不嫌弃民众，所以能彰明他的德行。因此，土地不分东西南北，百姓不论异国它邦，那样便会一年四季富裕美好，天地鬼神降赐福运，这就是五帝、三王无可匹敌的缘故。抛弃百姓使之去帮助敌国，拒绝宾客使之去事奉诸侯，使天下的贤士退却而不敢西进，裹足止步不入秦国，这就叫做“借武器给敌寇，送粮食给盗贼”啊。物品中不出产在秦国，而宝贵的却很多；贤士中不出生于秦，愿意效忠的很多。如今驱逐宾客来资助敌国，减损百姓来充实对手，内部自己造成空虚而外部在诸侯中构筑怨恨，那要谋求国家没有危难，是不可能的啊。]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>古文</tag>
        <tag>政论文</tag>
        <tag>李斯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本朝百年无事札子]]></title>
    <url>%2F2019%2F02%2F10%2F%E6%9C%AC%E6%9C%9D%E7%99%BE%E5%B9%B4%E6%97%A0%E4%BA%8B%E6%9C%AD%E5%AD%90%2F</url>
    <content type="text"><![CDATA[参考: 维基百科 百度百科 介绍 《本朝百年无事札子》是北宋王安石所作奏议。全文以扬为抑，褒中有贬，在探究北宋立国以来百余年间太平无事的原因的同时，剖析了宋仁宗统治时的种种弊病；透过“百年无事”的表象揭示出危机四伏的实质，犀利地指出因循守旧、故步自封的危害；并就吏治、教育、科举、农业、财政、军事等诸方面的改革提出了自己的见解与主张。文章条理清晰，措辞委婉，情感恳切坦诚，是历代奏议中的佳作。 王安石（1021–1086）北宋政治家、文学家、思想家。字介甫，晚号半山。抚州临（今属江西抚州）人。庆历进士。初知鄞县，嘉祜三年（1058）上万言书，主张改革政治。熙宁二年（1069），被任为参知政事。次年拜相，推行新法，遭到反对。熙宁七年辞退，次年再相，九年再辞．退居江宁（今江苏南京），封荆国公，世称“荆公”。卒谥文。散文雄健峭拔，为“唐宋八大家”之一。其诗遒劲清新，其词风格高峻。著有《临川集》、《临川集拾遗》等。 原文 臣前蒙陛下问及本朝所以享国百年、天下无事之故。臣以浅陋，误承圣问，迫于日晷，不敢久留，语不及悉，遂辞而退。窃惟念圣问及此，天下之福，而臣遂无一言之献，非近臣所以事君之义，故敢冒昧而粗有所陈。 伏惟太祖躬上智独见之明，而周知人物之情伪，指挥付托必尽其材，变置施设必当其务。故能驾驭将帅，训齐士卒，外以捍诸边，内以平中国。于是除苛赋，止虐刑，废强横之藩镇，诛贪残之官吏，躬以简俭为天下先。其于出政发令之间，一以安利元元为事。太宗承之以聪武，真宗守之以谦仁，以至仁宗、英宗，无有逸德。此所以享国百年而天下无事也。 仁宗在位，历年最久。臣于时实备从官，施为本末，臣所亲见。尝试为陛下陈其一二，而陛下详择其可，亦足以申鉴于方今。 伏惟仁宗之为君也，仰畏天，俯畏人，宽仁恭俭，出于自然。而忠恕诚悫，终始如一，未尝妄兴一役，未尝妄杀一人，断狱务在生之，而特恶吏之残扰。宁屈己弃财于外敌，而终不忍加兵。刑平而公，赏重而信。纳用谏官御史，公听并观，而不蔽于偏至之谗。因任众人耳目，拔举疏远，而随之以相坐之法。盖监司之吏以至州县，无敢暴虐残酷，擅有调发，以伤百姓。自夏人顺服，蛮夷遂无大变，边人父子夫妇，得免于兵死，而中国之人，安逸蕃息，以至今日者，未尝妄兴一役，未尝妄杀一人，断狱务在生之，而特恶吏之残扰，宁屈己弃财于夷狄而不忍加兵之效也。大臣贵戚、左右近习，莫敢强横犯法，其自重慎或甚于闾巷之人。此刑平而公之效也。募天下骁雄横猾以为兵，几至百万，非有良将以御之，而谋变者辄败。聚天下财物，虽有文籍，委之府史，非有能吏以钩考，而断盗者辄发。凶年饥岁，流者填道，死者相枕，而寇攘辄得。此赏重而信之效也。大臣贵戚、左右近习，莫能大擅威福，广私货赂，一有奸慝，随辄上闻。贪邪横猾，虽间或见用，未尝得久。此纳用谏官、御史，公听并观，而不蔽于偏至之谗之效也。自县令京官以至监司台阁，升擢之任，虽不皆得人，然一时之所谓才士，亦罕蔽塞而不见收举者。此因任众人之耳目、拔举疏远而随之以相坐之法之效也。升遐之日，天下号恸，如丧考妣，此宽仁恭俭出于自然，忠恕诚悫，终始如一之效也。 然本朝累世因循末俗之弊，而无亲友群臣之议。人君朝夕与处，不过宦官女子，出而视事，又不过有司之细故，未尝如古大有为之君，与学士大夫讨论先王之法以措之天下也。一切因任自然之理势，而精神之运有所不加，名实之间有所不察。君子非不见贵，然小人亦得厕其间。正论非不见容，然邪说亦有时而用。以诗赋记诵求天下之士，而无学校养成之法。以科名资历叙朝廷之位，而无官司课试之方。监司无检察之人，守将非选择之吏。转徙之亟既难于考绩，而游谈之众因得以乱真。交私养望者多得显官，独立营职者或见排沮。故上下偷惰取容而已。虽有能者在职，亦无以异于庸人。农民坏于徭役，而未尝特见救恤，又不为之设官，以修其水土之利。兵士杂于疲老，而未尝申敕训练，又不为之择将，而久其疆场之权。宿卫则聚卒伍无赖之人，而未有以变五代姑息羁縻之俗。宗室则无教训选举之实，而未有以合先王亲疏隆杀之宜。其于理财，大抵无法，故虽俭约而民不富，虽忧勤而国不强。赖非夷狄昌炽之时，又无尧、汤水旱之变，故天下无事，过于百年。虽曰人事，亦天助也。盖累圣相继，仰畏天，俯畏人，宽仁恭俭，忠恕诚悫，此其所以获天助也。 伏惟陛下躬上圣之质，承无穷之绪，知天助之不可常恃，知人事之不可怠终，则大有为之时，正在今日。臣不敢辄废“将明”之义，而苟逃讳忌之诛。伏惟陛下幸赦而留神，则天下之福也。取进止。 译文 我前些天承蒙陛下问到我朝之所以统治了上百年，天下太平无事的原因。我因为浅薄无知，错蒙皇上询问，由于时间紧迫，不敢长时间留在宫中，话还来不及说完，就告辞退朝。私下想到皇上问到这个问题，是天下的福气，而我却没有一句中肯的话奉献，不是身边官员效忠君主的态度，所以敢于不揣冒昧粗略地说说我的看法。 我想太祖具有极高的智慧独到的见解，详尽地了解各种人物的真伪，指挥任命，一定做到人尽其才，设置变革措施，一定能够符合现实情况。所以能够驾驭将帅，练好兵卒，对外抵抗外族入侵，对内靠他们平定动乱。于是废除苛捐杂税，禁止酷刑，废除强横的藩镇势力，诛杀贪婪残暴的官吏，自身俭朴，为天下做出了榜样。太祖在制定政策发布命令的时候，一切以百姓能平安、得利为准则。太宗继承了太祖的聪慧勇武，真宗保持了太祖的谦恭仁爱，到了仁宗、英宗，没有丧失道德的地方。这就是所以能够统治上百年，而天下太平的缘故。仁宗做皇上，时间最久。我当时担任侍从官员，所作所为，从头到尾，都是我所亲眼看到的。 我试为陛下陈说其中的几条，陛下详加考虑，选择可取之处，也足以用作今天的借鉴。 我想仁宗作为一位君主，对上敬畏天命，对下敬畏人民；宽厚仁爱，谦恭俭朴，出于天性；忠恕诚恳，始终如一。没有随意兴办一项工程，没有随意杀过一个人。审断案件尽量使犯人能够活下来，特别憎恨官吏对百姓的残暴骚扰。宁肯委屈自己输送钱财给辽、夏，却始终不忍心对他们开战。刑罚轻缓而公正，赏赐很重而守信用。采纳谏官、御史的建议，多方面地听取和观察，而不会受到偏见的谗言的蒙蔽；依靠众人的耳闻目睹，选拔举荐关系疏远的人才，且伴随着连坐的法律。从监察官吏到州、县的官员，没有人敢暴虐残酷，擅自增加赋税徭役，来损害老百姓。自从西夏人顺服以后，蛮横的外族就没有大的变化，边境人民的父子夫妇，能够不在战争中死亡，而内地的人民，安定和平繁荣兴旺，一直到今天，这是因为没有随意兴办一项工程，没有错杀一个人，审断案件尽量使犯人能够活下来，而特别憎恨官吏对百姓的残暴、骚扰，宁肯委屈自己输送财物给辽、夏外族，而不忍心对他们开战的结果。王公大臣，皇亲国戚，身边的近臣，没有人敢强横犯法，他们自重谨慎，有的甚至超过平民百姓，这是刑罚轻缓而公正的结果。招募天下骁雄强横奸诈之徒作为士兵，几乎达到百万，没有良将来统帅他们，而阴谋叛乱的人很快就败露；聚集天下的财物，虽然有账册，把这些交给府吏管理，没有贤能的官吏来检查考核，而贪污偷盗的人马上就被揭发出来；水旱灾年，逃荒的人堵塞了道路，尸横遍野，而抢夺财物的强盗立刻就被捕获，这是重赏赐而守信用的结果。王公大臣、皇亲国戚、身边的侍从官吏，没有能大肆作威作福，到处钻营受贿，一有奸邪不法的事，随即就报告到上面；贪婪奸邪强横狡猾之徒，即使偶尔被任用，不能够长久的。这是采纳谏官、御史的建议，广泛地听取观看，而不会受到偏见的谗言所蒙蔽的结果。从县令、京官，到监司、台阁，提拔任用，虽然不能全部称职，然而，闻名一时的所谓有才能的人，也很少有埋没不被任用的。这是依靠众人的耳闻目睹，选拔推荐关系疏远的人才而伴随着连坐之法的结果。驾崩的那一天，天下的人民放声痛哭，如同死去父母，这是宽厚仁爱谦恭俭朴，出于本性，忠恕诚恳，始终如一的结果。 但是，本朝几代墨守衰风颓俗的弊病，却没有皇亲国戚和诸位臣子议论它。和皇上朝夕相处的，不过是宦官宫女，出来处理政事，又不过是有关部门的琐事，没有像古代大有作为的君主那样，和学士、大夫们讨论先王治理国家的方法，把它实施到天下。一切听任自然趋势，而主观努力却有所不够，名义和实际效果之间的关系，没有加以考察。君子并不是不被容纳，但小人也能够混进来。正确的论断并不是不被采纳，然而不正确的怪论也有时候被采用。凭着写诗作赋博闻强记选拔天下的士人，而没有学校培养造就人才的方法；以科名贵贱资历深浅排列在朝中的官位，而没有官吏考核实绩的制度。监司部门没有设置检查的人，守将不是选拔上来的贤臣，频繁地调动迁官，既难于考核实绩，而夸夸其谈的人，因而能够乱真。结党营私，猎取名望的人，大多数得到了显要的职务，靠自己才能奉公守职的人，也无法显示出和庸人的不同。农民受到了徭役的牵累，没有看到特别的救济抚恤，又不为他们设置官员，兴修农田水利；士兵中混杂着老弱病员，没有加以告诫整顿，又不替他们选拔将领，让他们长久地掌握守边任务。保卫都城收罗的是些兵痞无赖，没有改变五代的纵容、笼络的坏习惯；皇室中没有教导训练、选拔推荐之实，因而不能符合先王亲近疏远、升官、降职的原则。至于管理财政，基本上没有法度，所以虽然皇上俭朴节约而人民却不富足，虽然操心勤勉而国家却不强大。幸赖不是夷狄昌盛的时候，又没有尧、汤时代水涝旱灾的特殊情况，所以天下无事，超过百年。虽然是人努力的结果，也靠了天的帮助。原因是几代圣君相传，对上敬畏天命，对下敬畏人民，宽厚仁爱谦恭俭朴，忠恕诚恳，这是他们之所以获得上天帮助的缘故。 我想陛下身具最为圣明的资质，继承无穷无尽的帝业，知道不能长久地依靠上天的帮助，知道人事不能始终懈怠下去，那么大有作为的时候，正在今天。我不敢随便放弃臣子应尽的职责，而只顾躲避独犯忌讳所遭到的惩罚。恳请陛下宽恕我并留神我的话，那就是天下人的福气了。恰当与否，请陛下裁决。]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>古文</tag>
        <tag>政论文</tag>
        <tag>王安石</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[六国论]]></title>
    <url>%2F2019%2F02%2F10%2F%E5%85%AD%E5%9B%BD%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[参考: 维基百科 百度百科 介绍《六国论》是苏洵政论文代表作品。《六国论》提出并论证了六国灭亡“弊在赂秦”的精辟论点，“借古讽今”，抨击宋王朝对辽和西夏的屈辱政策，告诫北宋统治者要吸取六国灭亡的教训，以免重蹈覆辙。 苏洵（1009—1066年），北宋著名散文家，字明允，号老泉，眉州眉山（今四川省眉山县）人。相传二十七岁时才发愤为学，应进士和茂才异等考试皆未中。于是愤而自焚平日所著文章，再度闭门潜心读书，终于博通六艺及诸子百家著作，撰写文章下笔顷时数千言。嘉祐间，得当时名盛一时的翰林学士欧阳修推誉，以文章著名于世。曾任秘书省校书郎、霸州文安县主簿。后与姚辟同修礼书《太常因革礼》一百卷，书成后不久去世。他主张抵抗辽的攻掠，对大地主的土地兼并、政治特权有所不满。为文擅长策论，语言明畅，笔力雄健，奔腾驰骋，纵横捭阖，老辣犀利，很有战国纵横家笔意。与其子轼、辙，合称“三苏”，俱被列入“唐宋八大家”。有《嘉祐集》行世。 原文六国破灭，非兵不利，战不善，弊在赂秦。赂秦而力亏，破灭之道也。或曰：“六国互丧，率赂秦耶？”曰：“不赂者以赂者丧，盖失强援，不能独完，故曰弊在赂秦也。” 秦以攻取之外，小则获邑，大则得城，较秦之所得，与战胜而得者，其实百倍；诸侯之所亡，与战败而亡者，其实亦百倍。则秦之所大欲，诸侯之所大患，固不在战矣。思厥先祖父，暴霜露，斩荆棘，以有尺寸之地。子孙视之不甚惜，举以予人，如弃草芥。今日割五城，明日割十城，然后得一夕安寝。起视四境，而秦兵又至矣。然则诸侯之地有限，暴秦之欲无厌，奉之弥繁，侵之愈急，故不战而强弱胜负已判矣。至于颠覆，理固宜然。古人云：“以地事秦，犹抱薪救火，薪不尽，火不灭。”此言得之。 齐人未尝赂秦，终继五国迁灭，何哉？与嬴而不助五国也。五国既丧，齐亦不免矣。燕、赵之君，始有远略，能守其土，义不赂秦。是故燕虽小国而后亡，斯用兵之效也。至丹以荆卿为计，始速祸焉。[5]赵尝五战于秦，二败而三胜。后秦击赵者再，李牧连却之。洎牧以谗诛，邯郸为郡；惜其用武而不终也。 且燕、赵处秦革灭殆尽之际，可谓智力孤危，战败而亡，诚不得已。向使三国各爱其地，齐人勿附于秦，刺客不行，良将犹在，则胜负之数，存亡之理，当与秦相较，或未易量。 呜呼！以赂秦之地，封天下之谋臣；以事秦之心，礼天下之奇才；并力西向，则吾恐秦人食之不得下咽也。悲夫！有如此之势，而为秦人积威之所劫，日削月割，以趋于亡，为国者无使为积威之所劫哉！ 夫六国与秦皆诸侯，其势弱于秦，而犹有可以不赂而胜之之势；茍以天下之大，而从六国破亡之故事，是又在六国下矣！ 译文六国灭亡，不是武器不锐利，仗打得不好，弊病在于割地贿赂秦国。割地贿赂秦国，自己的力量就亏损了，这是灭亡的原因。有人说：“六国相继灭亡，全都是由于割地贿赂秦国吗？”回答说：“不割地贿赂秦国的国家因为割地贿赂秦国的国家而灭亡。因为他们失去了强有力的外援，不能单独保全。所以说：‘弊病在于割地贿赂秦国’啊！” 秦国除用攻战的方法取得土地之外（还得到诸侯的割地贿赂），小的就获得城镇，大的就获得都市，把秦国由受贿赂得到的土地与战胜而得到的土地比较，实际上有一百倍，把诸侯贿赂秦国所失去的土地与战败所失去的土地比较，实际上也有一百倍。那么秦国最大的欲望，诸侯最大的祸患，当然就不在于战争了。回想他们的祖辈父辈，冒着霜露，披荆斩棘，因而才有一点点土地。可是子孙们看待它却很不珍惜，拿它来送人，就像抛弃小草一样。今天割去五座城，明天割去十座城，然后才能睡上一夜安稳觉。待起床一看四周边境，秦国的军队又打来了。那么，诸侯的土地有限，暴秦的欲望没有满足；谁送给它土地越多，它侵犯谁就越急。所以不用打仗，谁强谁弱、谁胜谁败就已分得清清楚楚了。六国落到灭亡的地步，按理本来应当这样。古人说：“用土地侍奉秦国，就像抱着柴草救火，柴草没有烧完，火就不会熄灭。”这话说得在理啊！ 齐国不曾割地贿赂秦国，最后也随着五国灭亡，为什么呢？这是因为它跟秦国交好而不帮助五国啊。五国灭亡之后，齐国也就不能幸免了。燕国和赵国的君主，起初有远大的谋略，能够守住自己的土地，坚持正义不贿赂秦国。因此燕国虽然是个小国，却灭亡在后，这是用兵抵抗的效果啊。到了燕太子丹用派遣荆轲刺杀秦王作为对付秦国的策略，才招致灭亡的祸患。赵国曾经与秦国多次作战，败少胜多。后来秦国又两次攻打赵国，李牧接连打退了它。等到李牧因受谗言被赵王杀害，都城邯郸就变成秦国的一个郡，可惜它用兵抵抗却没能坚持到底啊。况且燕赵正处在其他国家被消灭了的时候，可说是智谋已尽，力量单薄，战败而亡国，实在是没有办法的事啊。假使当初韩、魏、楚三国都各自珍惜自己的土地，齐国不依附秦国，燕国的刺客不去秦国，赵国的良将李牧还活着，那么胜败存亡的命运，如果与秦国较量，也许还不容易估量呢。 唉！如果六国把贿赂秦国的土地封赏给天下的谋臣，用侍奉秦国的心意礼遇天下非凡的人才，齐心协力向西对付秦国，那么我担心秦国人连饭也咽不下喉呢。可悲啊！有这样的形势，却被秦国积久的威势所胁制，土地天天削减，月月割让，以至于走向灭亡。治理国家的人切不要让自己被敌人积久的威势所胁制啊！ 六国和秦国都是诸侯，他们的势力比秦国弱，可是还有能够不割地贿赂而战胜秦国的形势。如果凭借偌大国家，却自取下策反而重蹈六国灭亡的覆辙，这就又在六国之下了！]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>苏洵</tag>
        <tag>古文</tag>
        <tag>政论文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[上仁宗皇帝言事书]]></title>
    <url>%2F2019%2F02%2F10%2F%E4%B8%8A%E4%BB%81%E5%AE%97%E7%9A%87%E5%B8%9D%E8%A8%80%E4%BA%8B%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[参考: 维基百科 百度百科 介绍 王安石（1021年12月19日－1086年5月21日），字介甫，号半山，临川盐阜岭（今江西省抚州市东乡县）人，生于宋真宗天禧五年，卒于宋哲宗元祐元年，由于被封为荆国公，后人常称他为“王荆公”。王安石是北宋著名的政治家、文学家、思想家，实官至司空、尚书左仆射、观文殿大学士、镇南军节度使。他去世后被追赠为太傅，谥曰文，享年66岁。 嘉佑三年（1058年），调为度支判官，王安石进京述职，作长达万言的《上仁宗皇帝言事书》，系统地提出了变法主张。在此次上疏中，王安石总结了自己多年的地方官经历，指出国家积弱积贫的现实：经济困窘、社会风气败坏、国防安全堪忧，认为症结的根源在于为政者不懂得法度，解决的根本途径在于效法古圣先贤之道、改革制度，进而提出了自己的人才政策和方案的基本设想，建议朝廷改革取士、重视人才。 原文 臣愚不肖，蒙恩备使一路，今又蒙恩召还阙廷，有所任属，而当以使事归报陛下。不自知其无以称职，而敢缘使事之所及，冒言天下之事，伏惟陛下详思而择其中，幸甚。 臣窃观陛下有恭俭之德，有聪明睿智之才，夙兴夜寐，无一日之懈，声色狗马，观游玩好之事，无纤介之蔽，而仁民爱物之意，孚于天下，而又公选天下之所愿以为辅相者，属之以事，而不贰于谗邪倾巧之臣，此虽二帝、三王之用心，不过如此而已，宜其家给人足，天下大治。而效不至于此，顾内则不能无以社稷为忧，外则不能无惧于夷狄，天下之财力日以困穷，而风俗日以衰坏，四方有志之士，諰諰然常恐天下之久不安。此其故何也？患在不知法度故也。 今朝廷法严令具，无所不有，而臣以谓无法度者，何哉？方今之法度，多不合乎先王之政故也。孟子曰：「有仁心仁闻，而泽不加于百姓者，为政不法于先王之道故也。」以孟子之说，观方今之失，正在于此而已。 夫以今之世，去先王之世远，所遭之变，所遇之势不一，而欲一二修先王之政，虽甚愚者，犹知其难也。然臣以谓今之失，患在不法先王之政者，以谓当法其意而已。夫二帝、三王，相去盖千有余载，一治一乱，其盛衰之时具矣。其所遭之变，所遇之势，亦各不同，其施设之方亦皆殊，而其为天下国家之意，本末先后，未尝不同也。臣故曰：当法其意而已。法其意，则吾所改易更革，不至乎倾骇天下之耳目，嚣天下之口，而固已合乎先王之政矣。 虽然，以方今之势揆之，陛下虽欲改易更革天下之事，合于先王之意，其势必不能也。陛下有恭俭之德，有聪明睿智之才，有仁民爱物之意，诚加之意，则何为而不成，何欲而不得？然而臣顾以谓陛下虽欲改易更革天下之事，合于先王之意，其势必不能者，何也？以方今天下之才不足故也。 臣尝试窃观天下在位之人，未有乏于此时者也。夫人才乏于上，则有沉废伏匿在下，而不为当时所知者矣。臣又求之于闾巷草野之间，而亦未见其多焉。岂非陶冶而成之者非其道而然乎？臣以谓方今在位之人才不足者，以臣使事之所及，则可知矣。今以一路数千里之间，能推行朝廷之法令，知其所缓急，而一切能使民以修其职事者甚少，而不才苟简贪鄙之人，至不可胜数。其能讲先王之意以合当时之变者，盖阖郡之间，往往而绝也。朝廷每一令下，其意虽善，在位者犹不能推行，使膏泽加于民，而吏辄缘之为奸，以扰百姓。臣故曰：在位之人才不足，而草野闾巷之间，亦未见其多也。夫人才不足，则陛下虽欲改易更革天下之事，以合先王之意，大臣虽有能当陛下之意而欲领此者，九州之大，四海之远，孰能称陛下之指，以一二推行此，而人人蒙其施者乎？臣故曰：其势必未能也。孟子曰：「徒法不能以自行。」非此之谓乎？然则方今之急，在于人才而已。诚能使天下人才众多，然后在位之才可以择其人而取足焉。在位者得其才矣，然后稍视时势之可否，而因人情之患苦，变更天下之弊法，以趋先王之意，甚易也。今之天下，亦先王之天下，先王之时，人才尝众矣，何至于今而独不足乎？故曰：陶冶而成之者，非其道故也。 商之时，天下尝大乱矣。在位贪毒祸败，皆非其人，及文王之起，而天下之才尝少矣。当是时，文王能陶冶天下之士，而使之皆有士君子之才，然后随其才之所有而官使之。诗曰：「岂弟君子，遐不作人」。此之谓也。及其成也，微贱兔置之人，犹莫不好德，兔置之诗是也。又况于在位之人乎？夫文王惟能如此，故以征则服，以守则治。诗曰：「奉璋峨峨，髦士攸宜。」又曰：「周王于迈，六师及之。」文言王所用，文武各得其才，而无废事也。及至夷、厉之乱，天下之才，又尝少矣。至宣王之起，所与图天下之事者，仲山甫而已。故诗人叹之曰：「德輶如毛，维仲山甫举之，爱莫助之。」盖闵人才之少，而山甫之无助也。宣王能用仲山甫，推其类以新美天下之士，而后人才复众。于是内修政事，外讨不庭，而复有文、武之境土。故诗人美之曰：「薄言采芑，于彼新田，于此葘亩。」言宣王能新美天下之士，使之有可用之才，如农夫新美其田，而使之有可采之芑也。由此观之，人之才，未尝不自人主陶冶而成之者也。 所谓陶冶而成之者何也？亦教之、养之、取之、任之有其道而已。 所谓教之之道何也？古者天子诸侯，自国至于乡党皆有学，博置教道之官而严其选。朝廷礼乐、刑政之事，皆在于学，学士所观而习者，皆先王之法言德行治天下之意，其材亦可以为天下国家之用。苟不可以为天下国家之用，则不教也。苟可以为天下国家之用者，则无法在于学。此教之之道也。 所谓养之之道何也？饶之以财，约之以礼，裁之以法也。何谓饶之以财？人之情，不足于财，则贪鄙苟得，无所不至。先王知其如此，故其制禄，自庶人之在官者，其禄已足以代其耕矣。由此等而上之，每有加焉，使其足以养廉耻，而离于贪鄙之行。犹以为未也，又推其禄以及其子孙，谓之世禄。使其生也，既于父子、兄弟、妻子之养，婚姻、朋友之接，皆无憾矣；其死也，又于子孙无不足之忧焉。何谓约之以礼？人情足于财而无礼以节之，则又放僻邪侈，无所不至。先王知其如此，故为之制度。婚丧、祭养、燕享之事，服食、器用之物，皆以命数为之节，而齐之以律度量衡之法。其命可以为之，而财不足以具，则弗具也；其财可以具，而命不得为之者，不使有铢两分寸之加焉。何谓裁之以法？先王于天下之士，教之以道艺矣，不帅教则待之以屏弃远方终身不齿之法。约之以礼矣，不循礼则待之以流、杀之法。《王制》曰：「变衣服者，其君流」，《酒诰》曰：「厥或诰曰『群饮，汝勿佚。尽拘执以归于周，予其杀！』」夫群饮、变衣服，小罪也；流、杀，大刑也。加小罪以大刑，先王所以忍而不疑者，以为不如是，不足以一天下之俗而成吾治。夫约之以礼，裁之以法，天下所以服从无抵冒者，又非独其禁严而治察之所能致也。盖亦以吾至诚恳恻之心，力行而为之倡。凡在左右通贵之人，皆顺上之欲而服行之，有一不帅者，法之加必自此始。夫上以至诚行之，而贵者知避上之所恶矣，则天下之不罚而止者众矣。故曰：此养之之道也。 所谓取之之道者，何也？先王之取人也，必于乡党，必于痒序，使众人推其所谓贤能，书之以告于上而察之。诚贤能也，然后随其德之大小、才之高下而官使之。所谓察之者，非专用耳目之聪明，而私听于一人之口也。欲审知其德，问以行；欲审知其才，问以言。得其言行，则试之以事。所谓察之者，，试之以事是也。虽尧之用舜，亦不过如此而已，又况其下乎？若夫九州之大，四海之远，万官亿丑之贱，所须士大夫之才则众矣，有天下者，又不可以一二自察之也，又不可以偏属于一人，而使之于一日二日之间考试其行能而进退之也。盖吾已能察其才行之大者，以为大官矣，因使之取其类以持久试之，而考其能者以告于上，而后以爵命、禄秩予之而已。此取之之道也。 所谓任之之道者，何也？人之才德，高下厚薄不同，其所任有宜有不宜。先王知其如此，故知农者以为后稷，知工者以为共工。其德厚而才高者以为之长。德薄而才下者以为之佐属。又以久于其职，则上狃习而知其事，下服驯而安其教，贤者则其功可以至于成，不肖者则其罪可以至于着，故久其任而待之以考绩之法。夫如此，故智能才力之士，则得尽其智以赴功，而不患其事之不终，其功之不就也。偷惰苟且之人，虽欲取容于一时，面顾戮辱在其后，安敢不勉乎！若夫无能之人，固知辞避而去矣。居职任事之日久，不胜任之罪，不可以幸而免故也。彼且不敢冒而知辞避矣，尚何有比周、谗谄、争进之人乎？取之既已详，使之既已当，处之既已久，至其任之也又专焉，而不一二以法束缚之，而使之得行其意，尧、舜之所以理百官而熙众工者，以此而已。书曰：「三载考绩，三考，黜陟幽明。」此之谓也。然尧、舜之时，其所黜者则闻之矣，盖四凶是也。其所陟者，则皋陶、稷、契皆终身一官而不徙。盖其所谓陟者，特加之爵命、禄赐而已耳。此任之之道也。 夫教之、养之、取之、任之之道如此，而当时人君，又能与其大臣，悉其耳目心力，至诚恻怛，思念而行之，此其人臣之所以无疑，而于天下国家之事，无所欲为而不得也。 方今州县虽有学，取墙壁具而已，非有教导之官，长育人才之事也。唯太学有教导之官，而亦未尝严其选。朝廷礼乐刑政之事，未尝在于学。学者亦漠然自以礼乐刑政为有司之事，而非 己所当知也。学者之所教，讲说章句而已。讲说章句，固非古者教人之道也。而近岁乃始教之以课试之文章。夫课试之文章，非博诵强学穷日之力则不能。及其能工也，大则不足以用天下国家，小则不足以为天下国家之用。故虽白首于庠序，穷日之力以帅上之教，及使之从政，则茫然不知其方者，皆是也。盖今之教者，非特不能成人之才而已，又从而困苦毁坏之，使不得成才者，何也？夫人之才，成于专而毁于杂。故先王之处民才，处工于官府，处农于畎亩，处商贾于肆，而处士于庠序，使各专其业而不见异物，惧异物之足以害其业也。所谓士者，又非特使之不得见异物而已，一示之以先王之道，而百家诸子之异说，皆屏之而莫敢习者焉。今士之所宜学者，天下国家之用也。今悉使置之不教，而教之以课试之文章，使其耗精疲神，穷日之力以从事于此。及其任之以官也，则又悉使置之，而责之以天下国家之事。夫古之人，以朝夕专其业于天下国家之事，而犹才有能有不能，今乃移其精神，夺其日力，以朝夕从事于无补之学，及其任之以事，然后卒然责之以为天下国家之用，宜其才之足以有为者少矣。臣故曰：非特不能成人之才，又从而困苦毁坏之，使不得成才也。又有什害者，先王之时，士之所学者，文武之道也。士之才，有可以为公卿大夫，有可以为士。其才之大小、宜不宜则有矣，至于武事，则随其才之大小，未有不学者也。故其大者，居则为六官之卿，出则为六军之将也；其次则比、闾、族、党之师，亦皆卒、两、师、旅之帅也。故边疆、宿卫，皆得士大夫为之，而小人不得奸其任。今之学者，以为文武异事，吾知治文事而已，至于边疆、宿卫之任，则推而属之于卒伍，往往天下奸悍无赖之人。苟其才行足以自托于乡里者，未有肯去亲戚而从召募者也。边疆、宿卫，此乃天下之重任，而人主之所当慎重者也。故古者教士，以射、御为急，其他伎能，则视其人才之所宜，而后教之，其才之所不能，则不强也。至于射，则为男子之事。苟人之生，有疾则已，苟无疾，未有去射而不学者也。在庠序之间，固常从事于射也。有宾客之事则以射，有祭祀之事则以射，别士之行同能偶则以射，于礼乐之事，未尝不寓以射，而 射亦未尝不在于礼乐、祭祀之间也。易曰：「弧矢之利，以威天下。」先王岂以射为可以习揖让之仪而已乎？固以为射者武事之尤大，而威天下、守国家之具也。居则以是习礼乐，出则以是从战伐。士既朝夕从事于此而能者众，则边疆、宿卫之任，皆可以择而取也。夫士尝学先王之道，其行义尝见推于乡党矣，然后因其才而托之以边疆、宿卫之士，此古之人君，所以推干戈以属之人，而无内外之虞也。今乃以夫天下之重任，人主所当至慎之选，推而属之奸悍无赖，才行不足自托于乡里之人，此方今所以諰諰然常抱边疆之忧，而虞宿卫之不足恃以为安也。今孰不知边疆、宿卫之士不足恃以为安哉？顾以为天下学士以执兵为耻，而亦未有能骑射行阵之事者，则非召募之卒伍，孰能任其事者乎？夫不严其教，高其选，则士之以执兵为耻，而未尝有能骑射行阵之事，固其理也。凡此皆教之非其道也。 方今制禄，大抵皆薄。自非朝廷侍从之列，食口稍众，未有不兼农商之利而能充其养者也。其下州县之吏，一月所得，多者钱八九千，少者四五千，以守选、待除、守阙通之，盖六七年而后得三年之禄，计一月所得，乃实不能四五千，少者乃实不能及三四千而已。虽厮养之给，亦窘于此矣，而其养生、丧死、婚姻、葬送之事，皆当出于此。夫出中人之上者，虽穷而失为君子；出中人以下者，虽泰而不失为小人。唯中人不然，穷则为小人，泰则为君子。计天下之士，出中人之上下者，千百而无十一，穷而为小人，泰而为君子者，则天下皆是也。先王以为众不可以力胜也，故制行不以己，而以中人为制，所以因其欲而利道之，以为中人之所能守，则其志可以行乎天下，而推之后世。以今之制禄，而欲士之无毁廉耻，盖中人之所不能也。故今官大者，往往交赂遗、营赀产，以负贪污之毁；官小者，贩鬻、乞丐、无所不为。夫士已尝毁廉耻以负累于世矣，则其偷堕取容之意起，而矜奋自强之小息，则职业安得而不弛，治道何从而兴乎？又况委法受赂，侵牟百姓者，往往而是也。此所谓不能饶之以财也。 婚丧、奉养、服食、器用之物，皆无制度以为之节，而天下以奢为荣，以俭为耻。苟其财之可以具，则无所为而不得，有司既不禁，而人又以此为荣。苟其财不足，而不能自称于流俗，则其婚丧之际，往往得罪于族人婚姻，而人以为耻矣。故富者贪而不知止，贫者则强勉其不足以追之。此士之所以重困，而廉耻之心毁也。凡此所谓不能约之以礼也。 方今陛下躬行俭约，以率天下，此左右通贵之臣所亲见。然而其闺门之内，奢靡无节，犯上之所恶，以伤天下之教者，有已甚者矣。未闻朝廷有所放绌，以示天下。昔周之人，拘群饮而被之以杀刑者，以为酒之末流生害，有至于死者众矣，故重禁其祸之所自生。重禁祸之所自生，故其施刑极省，而人之抵于祸败者少矣。今朝廷之法所尤重者，独贪吏耳。重禁贪吏，而轻奢靡之法，此所谓禁其末而弛其本。然而世之识者，以为方今官冗，而县官财用已不足以供之，其亦蔽于理矣。今之入官诚冗矣，然而前世置员盖其少，而赋禄又如此之薄，则财用之所不足，盖亦有说矣。吏禄岂足计哉？臣于财利，固未尝学，然窃观前世治财之大略矣。盖因天下之力，以生天下之财，取天下之财，以供天下之费。自古治世，未尝以不足为天下之公患也。患在治财无其道耳。今天下不见兵革之具，而元元安土乐业，人致其力，以生天下之财，然而公私尝以困穷为患者，殆亦理财未得其道，而有司不能度世之宜而通其变耳。诚能理财以其道，而通其变，臣虽愚，固知增吏禄不足以伤经费也。方今法严令具，所以罗天下之士，可主谓密矣。然而亦尝教之以道艺，而有不帅教之刑以待之乎？亦尝约之以制度，而有不循理之刑以待之乎？亦尝任之以职事，而有不任事之刑以待之乎？夫不先教之以道艺，诚不可以诛其不帅教；不先约之以制度，诚不可以诛其不循理；不先任之以职事，诚不可以诛其不任事。此三者，先王之法所先急也，今皆不可得诛，而薄物细故，非害治之急者，为之法禁，月异而岁不同，为束者至于不可胜记，又况能一二避之而无犯者乎？此法令所以滋而不行，小人有幸而免者，君子有不幸而及者焉。此所谓不能裁之以刑也。凡此皆治之非其道也。 方今取士，强记博诵而略通于文辞，谓之茂才异等、贤良方正。茂才异等、贤良方正者，公卿之选也。记不必强，诵不必博，略通于文辞，而又尝学诗赋，则谓之进士。进士之高者，亦公卿之选也。夫此二科所得之技能，不足以为公卿，不待论而后可知。而世之议者，乃以为吾常以此取天下之士，而才之可以为公卿者，常出于此，不必法古之取人然后得士也。其亦蔽于理矣。先王之时，尽所以取人之道，犹惧贤者之难进，而不肖者之杂于其间也。今悉废先王所以取士之道，而驱天下之才士，悉使为贤良、进士，则士之才可以为公卿者，固宜为贤良、进士，而贤良、进士亦固宜有时而得才之可以为公卿者也。然而不肖者，苟能雕虫篆刻之学，以此进至乎公卿，才之可以为公卿者，困于无补之学，而以此绌死于岩野，盖十八九矣。夫古之人有天下者，其所慎择者，公卿而已。公卿既得其人，因使推其类以聚于朝迁，则百司庶府，无不得其人也。今使不肖之人，幸而至乎公卿，因得推其类聚之朝廷，此朝廷所以多不肖之人，而虽有贤智，往往困于无助，不得行其意也。且公卿之不肖，既推其类以聚于朝廷，朝廷之不肖，又推其类以备四方之任使；四方之任使者，又各推其不肖以布于州郡。则虽有同罪举官之科，岂足恃哉？适足以为不肖者之资而已。其次九经、五经、学究、明法之科，朝廷固已尝患其无用于世，而稍责之以大义矣。然大义之所得，未有以贤于故也。今朝廷又开明经之选，以进经术之士。然明经之所取，亦记诵而略通于文辞者，则得之矣。彼通先王之意，而可以施于天下国家之用者，顾未必得与于此选也。其次则恩泽子弟，庠序不教之以道艺，官司不考问其才能，父兄不保任其行义，而朝廷辄以官予之，而任之以事。武王数纣之罪，则曰：「官人以世。」夫官人以世，而不计其才行，此乃纣之所以乱亡之道，而治世之所无也。又其次曰流外。朝廷固已挤之于廉耻之外，而限其进之路矣，顾属之以州县之事，使之临士民之上。岂所谓以贤治不肖者乎？以臣使事之所及，一路数千里之间，州县之吏，出于流外者，往往而有，可属任以事者，殆无二三，而当防闲其奸者，皆是也。盖古者有贤不肖之分，而无流品之别。故孔子之圣，而尝为季氏吏，盖虽为吏，而亦不害其为公卿。及后世有流品之别，则凡在流外者，其所成立，固尝自置于廉耻之外，而无高人之意矣。夫以近世风俗之流靡，自虽士大夫之才，势足以进取，而朝廷尝奖之以礼义者，晚节末路，往往怵而为奸，况又其素所成立，无高人之意，而朝廷固已挤之于廉耻之外，限其进取者乎？其临人亲职，放僻邪侈，固其理也。至于边疆、宿卫之选，则臣固已言其失矣。凡此皆取之非其道也。 方今取之既不以其道，至于任人，又不问其德之所宜，而问其出身之后先，不论其才之称否，而论其历任之多少。以文学进者，且使之治财。已使之治财矣，又转而使之典狱。已使之典狱矣，又转而使之治礼。是则一人之身，而责之以百官之所能备，宜其人才之难为也。夫责人以其所难为，则人之能为者少矣。人之能为者少，则相率而不为。故使之典礼，未尝以不知礼为忧，以今之典礼者未尝学礼故也。使之典狱，未尝以不知狱为耻，以今之典狱者，未尝学狱故也。天下之人，亦已渐渍于失教，被服于成俗，见朝廷有所任使，非其资序，则相议而讪之，至于任使之不当其才，未尝有非之者也。且在位者数徙，则不得久于其官，故上不能狃习而知其事，下不肯服驯而安其教，贤者则其功不可以及于成，不肖者则其罪不可以至于着。若夫迎新将故之劳，缘绝簿书之弊，固其害之小者，不足悉数也。设官大抵皆当久于其任，而至于所部者远，所任者重，则尤宜久于其官，而后可以责其有为。而方今尤不得久于其官，往往数日辄迁之矣。 取之既已不祥，使之既已不当，处之既已不久，至于任之则又不专，而又一二以法束缚之，使不得行其意，臣固知当今在位多非其人，稍假借之权，而不一二以法束缚之，则放恣而无不为。虽然，在位非其人，而恃法以为治，自古及今，未有能治者也。即使在位皆得其人矣，而一二以法束缚之，不使之得行其意，亦自古及今，未有能治者也。夫取之既已不详，使之既已不当，处之既已不久，任之又不专，而一二以法束缚之，故虽贤者在位，能者在职，与不肖而无能者，殆无以异。夫如此，故朝廷明知其贤能足以任事，苟非其资序，则不以任事而辄进之，虽进之，士犹不服也。明知其无能而不肖，苟非有罪，为在事者所劾，不敢以其不胜任而辄退之，虽退之，士犹不服也。彼诚不肖而无能，然而士不服者何也？以所谓贤能者任其事，与不肖而无能者，亦无以异故也。臣前以谓不能任人以职事，而无不任事之刑以待之者，盖谓此也。 夫教之、养之、取之、任之，有一非其道，则足以败乱天下之人才，又况兼此四者而有之？则在位不才、苟简、贪鄙之人，至于不可胜数，而草野闾巷之间，亦少可任之才，固不足怪。诗曰：「国虽靡止，或圣或否。民虽靡膴，或哲或谋，或肃或艾。如彼泉流，无沦胥以败。」此之谓也。 夫在位之人才不足矣，而闾巷草野之间，亦少可用之才，则岂特行先王之政而不得也，社稷之托，封疆之守，陛下其能久以天幸为常，而无一旦之忧乎？盖汉之张角，三十六万同日而起，而所在郡国，莫能发其谋；唐之黄巢，横行天下，而所至将吏，无敢与之抗者。汉、唐之所以亡，祸自此始。唐既亡矣，陵夷以至五代，而武夫用事，贤者伏匿消沮而不见，在位无复有知君臣之义、上下之礼者也。当是之时，变置社稷，盖甚于弈棋之易，而元元肝脑涂地，幸而不转死于沟壑者无几耳！夫人才不足，患盖如此，而方今公卿大夫，莫肯为陛下长虑后顾，为宗庙万世计，臣切惑之。昔晋武帝趣过目前，而不为子孙长远之谋，当时在位，亦皆偷合苟容，而风俗荡然，弃礼义，捐法制，上下同失，莫以为非，有识固知其将必乱矣。而其后果海内大扰，中国列于夷狄者，二百余年。伏惟三庙祖宗神灵所以付属陛下，固将为万世血食，而大庇元元于无穷也。臣愿陛下鉴汉、唐、五代之所以乱亡，惩晋武苟且因循之祸，明诏大臣，思所以陶成天下之才，虑之以谋，计之以数，为之以渐，期为合于当世之变，而无负于先王之意，则天下之人才不胜用矣。人才不胜用，则陛下何求而不得，何欲而不成哉？夫虑之以谋，计之以数，为之以渐，则成天下之才甚易也。 臣始读孟子，见孟子言王政之易行，心则以为诚然。及见与慎子论齐、鲁之地，以为先王之制国，大抵不过百里者，以为今有王者起，则凡诸侯之地，或千里，或五百里，皆将损之至于数十百里而后止。于是疑孟子虽贤，其仁智足以一天下，亦安能毋劫之以兵革，而使数百千里之强国，一旦肯损其地之十八九，而比于先王之诸侯？至其后，观汉武帝用主父偃之策，令诸侯王地悉得推恩分其子弟，而汉亲临定其号名，辄别属汉。于是诸侯王之子弟，各有分土，而势强地大者，卒以分析弱小。然后知虑之以谋，计之以数，为之以渐，则大者固可使小，强者固可使弱，而不至乎倾骇变乱败伤之衅。孟子之言不为过。又况今欲改易更革，其势非若孟子所为之难也。臣故曰：虑之以谋，计之以数，为之以渐，则其为什易也。 然先王之为天下，不患人之不为，而患人之不能，不患人之不能，而患己之不勉。何谓不患人之不为，而患人之不能？人之情所愿得者，善行、美名、尊爵、厚利也，而先王能操之以临天下之士。天下之士，有能遵之以治者，则悉以其所愿得者以与之。士不能则已矣，苟能，则孰肯舍其所愿得，而不自勉以为才？故曰：不患人之不为，患人之不能。何谓不患人之不能，而患己之不勉？先王之法，所以待人者尽矣，自非下愚不可移之才，未有不能赴者也。然而不谋之以至诚恻怛之心，亦未有能力行而应之者。故曰：不患人之不能，而患己之不勉。陛下诚有意乎成天下之才，则臣愿陛下勉之而已。 臣又观朝廷异时欲有所施为变革，其始计利害未尝熟也，顾一有流俗侥幸之人不悦而非之，则遂止而不敢为。夫法度立，则人无独蒙其幸者，故先王之政，虽足以利天下，而当其承弊坏之后，侥幸之时，其创法立制，未尝不艰难也。以其创法立制，而天下侥幸之人亦顺悦以趋之，无有龃龉，则先王之法，至今存而不废矣。惟其创法立制之艰难，而侥幸之人不肯顺悦而趋之，故古之人欲有所为，未尝不先之以征诛，而后得其意。诗曰：「是伐是肆，是绝是忽，四方以无拂。」此言文王先征诛而后得意于天下也。夫先王欲立法度，以变衰坏之俗而成人之才，虽有征诛之难，犹忍而为之，以为不若是，不可以有为也。及至孔子，以匹夫游诸侯，所至则使其君臣捐所习，逆所顺，强所劣，憧憧如也，卒困于排逐。然孔子亦终不为之变，以为不如是，不可以有为。此其所守，盖与文王同意。夫在上之圣人，莫如文王，在下之圣人，莫如孔子，而欲有所施为变革，则其事盖如此矣。今有天下之势，居先王之位，创立法制，非有征诛之难也。虽有侥幸之人不悦而非之，固不胜天下顺悦之人众也。然而一有流俗侥幸不悦之言，则遂止而不敢为者，惑也。陛下诚有意乎成天下之才，则臣又愿断之而已。 夫虑之以谋，计之以数，为之以渐，而又勉之以成，断之以果，然而犹不能成天下之才，则以臣所闻，盖未有也。 然臣之所称，流俗之所不讲，而今之议者以谓迂阔而熟烂者也。窃观近世士大夫所欲悉心力耳目以补助朝廷者有矣。彼其意，非一切利害，则以为当世所不能行。士大夫既以此希世，而朝廷所取于天下之士，亦不过如此。至于大伦大法，礼义之际，先王之所力学而守者，盖不及也。一有及此，则群聚而笑之，以为迂阔。今朝廷悉心于一切之利害，有司法令于刀笔之间，非一日也。然其效可观矣。则夫所谓迂阔而熟烂者，惟陛下亦可以少留神而察之矣。昔唐太宗贞观之初，人人异论，如封德彝之徒，皆以为非杂用秦、汉之政，不足以为天下。能思先王之事，开太宗者，魏郑公一人尔。其所施设，虽未能尽当先王之意，抑其大略，可谓合矣。故能以数年之间，而天下几致刑措，中国安宁，夷蛮顺服，自三王以来，未有如此盛时也。唐太宗之初，天下之俗，犹今之世也，魏郑公之言，固当时所谓迂阔而熟烂者也，然其效如此。贾谊曰：「今或言德教之不如法令，胡不引商、周、秦、汉以观之？」然则唐太宗事亦足以观矣。 臣幸以职事归报陛下，不自知其驽下无以称职，而敢及国家之大体者，诚以臣蒙陛下任使，而当归报。窃谓在位之人才不足，而无以称朝廷任使之意，而朝廷所以任使天下之士者，或非其理，而士不得尽其才，此亦臣使事之所及，而陛下之所宜先闻者也。释此一言，而毛举利害之一二，以污陛下之聪明，而终无补于世，则非臣所以事陛下惓惓之义也。伏惟陛下详思而择其中，天下幸甚！ 译文]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>古文</tag>
        <tag>政论文</tag>
        <tag>王安石</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[治安疏]]></title>
    <url>%2F2019%2F02%2F10%2F%E6%B2%BB%E5%AE%89%E7%96%8F%2F</url>
    <content type="text"><![CDATA[参考: 维基百科 百度百科 介绍 海瑞（1514－1587），字汝贤，号刚峰，海南海口人，明代著名的政治家，以刚直不阿，清正廉明著称于世，被世人誉为“海青天”。 《治安疏》是明代名臣海瑞写给明世宗朱厚熜的一篇奏疏。在这篇著名的奏疏中，海瑞大胆直言当时官场的弊端和统治阶级的罪责，同时劝谏统治者改正过失，实行改革，达到“天下大治”的目的。 原文 户部云南清吏司主事臣海瑞谨奏：为直言天下第一事，以正君道、明臣职，求万世治安事。 君者，天下臣民万物之主也。惟其为天下臣民万物之主，责任至重，凡民生利瘼一有所不闻，将一有所不得知而行，其任为不称。是故养君之道，宜无不备，而以其责寄臣工，使尽言焉。臣工尽言而君道斯称矣。昔之务为容悦、谀顺曲从，致使实祸蔽塞，主不上闻焉，无足言矣。过为计者，则又曰：“君子危明主，忧治世。” 夫世则治矣，以不治忧之；主则明矣，以不明危之。毋乃使之反求眩瞀，失趋舍矣乎？非通论也。 臣受国恩厚矣，请执有犯无隐之义。美曰美，不一毫虚美; 过曰过，不一毫讳过。不容悦，不过计，披肝胆为陛下言之。汉贾谊陈政事于文帝曰：“进言者皆曰天下已安已治矣，臣独以为未也。曰安且治者，非愚则谀。”夫文帝、汉贤君也，贾谊非苛责备也。文帝性仁类柔，慈恕恭俭，虽有近民之美；优游退逊，尚多怠废之政。不究其弊所不免，概以安且治当之，愚也；不究其才所不能，概以致安治颂之，谀也。陛下自视于汉文帝何如？陛下天质英断，睿识绝人，可为尧、舜，可为禹、汤、文、武，下之如汉宣帝之励精，光武之大度，唐太宗之英武无敌，宪宗之专志平僭乱，宋仁宗之仁恕，举一节可取者，陛下优为之。即位初年，刬除积弊，焕然与天下更始。举其略，如箴敬一以养心，定冠履以辨分，除圣贤土木之像，夺宦官内外之权，元世祖毁不与祀，祀孔子推及所生，天下忻忻然以大有作为仰之。识者谓辅相得人，太平指日可期也。非虚语也，高汉文帝远甚。然文帝能充其仁顺之性，节用爱人，吕祖谦称其能尽人之才力，诚是也。一时天下虽未可尽以治安予之，而贯朽粟陈，民少康阜，三代下称贤君焉。陛下则锐精未久，妄念牵之而去矣，反刚明而错用之，谓遥兴可得而一意修玄。富有四海，不曰民之膏脂在是也，而侈兴土木。二十余年不视朝，纲纪弛矣；数行推广事例，名爵滥矣。二王不相见，人以为薄于父子；以猜疑诽谤戮辱臣下，人以为薄于君臣，乐西苑而不返宫，人以为薄于夫妇。天下吏贪将弱，民不聊生，水旱靡时，盗贼滋炽，自陛下登极初年，亦有之而未什也。今赋役增常，万方则效，陛下破产礼佛日甚，室如悬磬，十余年来极矣。天下因即陛下改元之号，而臆之曰：“嘉靖者，言家家皆净而无财用也。”迩者，严嵩罢黜，世蕃极刑，差快人意，一时称清时焉。然严嵩罢相之后，犹之严嵩未相之先而已，非大清明世界也，不及汉文远甚。天下之人不直陛下久矣！内外臣工之所知也。知之不可谓愚，诗云：“衮职有阙，惟仲山甫补之。”今日所赖以弼棐匡救，格非而归之正，诸臣责也，岂以圣人而绝无过举哉？古昔设官，亮采惠畴足矣，不必责之以谏。保氏掌谏王恶，不必设也。木绳金砺，圣贤不必言之也。今乃建醮修斋，相率进香，天桃天药，相率表贺。建 宫筑室，工部极力经营；取香觅宝，户部差求四出。陛下误举，诸臣误顺，无一人为陛下一正言焉。都俞吁咈之风，陈善闭邪之义，邈无闻矣，谀之什也。然愧心馁气，退有后言，以从陛下；昧没本心，以歌颂陛下；欺君之罪何如！夫天下者，陛下之家也，人未有不顾其家者。内外臣工，其官守，其言责，皆所以奠陛下之家而磐石之也。一意玄修，是陛下心之惑也；过于苛断，是陛下情之偏也。而谓陛下不顾其家，人情乎？诸臣顾身念重，得一官多以欺败、脏败、不事事败，有不足以当陛下之心者。其不然者，君心臣心偶不相值也，遂谓陛下为贱薄臣工。诸臣正心之学微，所言或不免已私，或失详审，诚如胡寅挠乱政事之说，有不足以当陛下之心者。其不然者，君意臣言偶不相值也。遂谓陛下为是已拒谏。执陛下一二事不当之形迹，臆陛下千百事之尽然，陷陛下误终不复，诸臣欺君之罪大矣。《记》曰：“上人疑则百姓惑，下难知则君长劳。”今日之谓也。为身家心与惧心合，臣职不明，臣一二事形迹说既为诸臣解之矣。求长生心与惑心合，有辞于臣，君道不正，臣请再为陛下开之。陛下之误多矣，大端在修醮，修醮所以求长生也。自古圣贤止说修身立命，止说顺受其正，盖天地赋予于人而为性命者，此尽之矣。尧、舜、禹、汤、文、武之君，圣之盛也，未能久世不终。下之亦未见方外士汉、唐、宋存至今日，使陛下得以访其术者。陶仲文，陛下以师呼之，仲文则既死矣。仲文不能长生，而陛下独何求之？至谓天赐仙桃药丸，怪妄尤甚。昔伏羲氏王天下，龙马出河，因则其文以画八卦；禹治水时，神龟负文而列于背，因而第之以成九畴。《河图》、《洛书》，实有此瑞物。泄此万古不传之秘，天不爱道而显之圣人，借圣人以开示天下，犹之日月星辰之布列而历数成焉，非虚妄事也。宋真宗获天书于干佑山，孙奭进曰：“天何言哉！岂有书也？”桃必采而得，药必工捣合而成者也。无因而至，桃、药有足行耶？天赐之者，有手执而付之耶？陛下玄修多年矣，一无所得。至今日左右奸人，逆揣陛下悬思妄念，区区桃、药导之长生，理之所无，而玄修之无益可知矣。陛下又将谓悬刑赏以督率臣下，分理有人，天下无可不治，而玄修无害矣乎？夫人幼而学，无致君泽民异事之学；壮而行，亦无致君泽民殊用之心。太甲曰：“有言逆于汝心，必求诸道；有言逊于汝志，必求诸非道。”言顺者之未必为道也。即近事观，严嵩有一不顺陛下者乎？昔为贪窃，今为逆本。梁材守官守道，陛下以为逆者也。历任有声，官户部者，至今首称之。虽近日严嵩抄没，百官有惕心焉。无用于积贿求迁，稍自洗涤。然严嵩罢相之后，犹严嵩未相之先而已。诸臣为严嵩之顺，不为梁材之执。今甚者贪求，未甚者挨日。见称于人者，亦廊庙山林，交战热中，鹘突依违，苟举故事。洁已格物，任天下重，使社稷灵长终必赖之者，未见其人焉。得非有所牵掣其心，未能纯然精白使然乎？陛下欲诸臣惟予行而莫逆也，而责之效忠，付之以翼为明听也，又欲其顺吾玄修土木之误，是股肱耳目，不为腹心卫也，而自为视听持行之用。有臣如仪衍焉，可以成得志与民由之之业，无是理也。陛下诚知玄修无益，臣之改行，民之效尤，天下之不安不治由之，翻然悔悟，日视正朝，与宰辅、九卿、侍从、言官讲求天下利害，洗数十年君道之误，置其身于尧、舜、禹、汤、文、武之上；使其臣亦得洗数十年阿君之耻，置身与皋、夔、伊、傅相后先，明良喜起，都俞吁咈。内之宦官宫妾，外之光禄寺厨役、锦衣卫恩荫、诸衙门带俸，举凡无事而官多矣。上之内仓内库，下之户工部光禄寺诸厂藏段绢、粮料、珠宝、器用、木材诸物，多而积于无用，用之非所宜用亦多矣，诸臣必有为陛下言者。诸臣言之，陛下行之，此则在陛下一节省间而已。京师之一金，田野之百金也。一节省而国有余用，民有盖藏，不知其几也，而陛下何不为之？官有职掌，先年职守之正、职守之全，而未之行；今日职守之废、职守之苟且因循、不认真、不尽法，而自以为是。敦本行而端士习，止上纳以清仕途，久任吏将以责成功，练选军士以免召募，驱缁黄游食使归四民，责府州县兼举富教，使成礼俗。复屯盐本色以裕边储，均田赋丁差以苏困敝，举天下官之侵渔、将之怯懦、吏之为奸，刑之无少姑息焉。必世之仁，博厚高明悠远之业，诸臣必有为陛下言者。诸臣言之，陛下行之，此则在陛下一振作间而已。一振作而百 废具举，百弊刬绝，唐虞三代之治，粲然复兴矣。而陛下何不为之？节省之，振作之，又非有所劳于陛下也。九卿总其纲，百职分其绪，抚按科道纠率肃清于其间，陛下持大纲、稽治要而责成焉。劳于求贤，逸于任用，如天运于上而四时六气各得其序，恭已无为之道也。天地万物为一体，固有之性也。民物熙浃，薰为太和，而陛下性分中有真乐矣。可以赞天地之化育，则可以与天地参。道与天通，命由我立，而陛下性分中有真寿矣。此理之所有，可旋至而立有效者也。若夫服食不终之药，遥兴轻举，理所无者也。理之所无而切切然散爵禄、竦精神，玄修求之，悬思凿想，系风捕影，终其身如斯而已矣。求之其可得乎！ 君道不下在、臣职不明，此天下第一事也。于此不言，更复何言？大臣持禄而外为谀，小臣畏罪而面为顺，陛下诚有不得知而改之行之者，臣每恨焉。是以昧死竭惓惓为陛下一言之。一反情易向之间，而天下之治与不治，民物之安与不安，于焉决焉。伏惟陛下留神，宗社幸甚，天下幸甚。臣不胜战栗恐惧之至，为此具本亲赍，谨具奏闻。 译文 户部云南清吏司主事海瑞在这里上奏：为了匡正君道，明确臣下的职责，求得万世治安，我要直陈天下第一事。 国君是天下臣民万物的主人，正是因为是天下臣民万物之主，所以责任重大。如果民生措置失当，就是君主没有负起责任。所以臣子就应当尽量为君主服务，忠于职守，畅所欲言。臣子尽到了自己的责任，君主的责任也才算尽到了。以前那种专图讨好，曲意逢迎，不让君主听到实际情况的人，现在用不着说他们了。 危言耸听的人或许会说：君子总是想法多，即使遇到贤明的君主，政治清明的时代，也常常居安思危，忧虑重重，只怕反而让人思维混乱，搞不清方向。这种说法不符合现在的情况！ 臣蒙受国恩，宁可直言得罪也不想说假话，好的就是好的，坏的就是坏的，一丝一毫都不敢隐瞒。我不为讨上面的欢心，也不计较得失，今天披沥肝胆，掏出真心，对陛下您说几句实话。 汉代名臣贾谊曾和文帝这样说：“下面进言的人总是说：天下已经大治，臣独以为还没有。那些说天下已安已治的人，不是愚昧无知就是阿谀逢迎。”文帝算是汉代的贤君了，贾谊也不是对文帝要求过高。汉文帝的品质作风是好的，他有爱民的美德，为人也慈和俭朴，从容谦逊，但缺点在于游于玄老，不专事于政务，有许多政事都被耽误了，没有办好。假使臣下看不到这些弊病，一味认为天下已安已治，这就是愚昧无知。假使臣下看不到文帝的才能毕竟有限，一味用已安已治的话来歌颂他，这就是阿谀奉承。 陛下自视和汉文帝比较起来怎么样呢？陛下天资英断，睿识绝人，具有成为尧、舜、禹、汤、文、武这样的君王的潜力，陛下象汉宣帝一样做事努力认真，象光武帝一样为人大度，象唐太宗一样英武无敌，象唐宪宗一样能够消平各地藩镇叛乱，陛下还有宋仁宗的仁恕之德，总之象这些可取的优点，无论哪一项，您都是具有的。您即位初年，铲除积弊，明白宣示，同全国老百姓一道革新政事。举其大概吧：您作过一篇《敬一箴》，提倡规戒；改定了一些冠服制度，下令废除孔子庙里的塑像，只用木主；削弱了宦官的内外之权；将元世祖从历代帝王庙所祭牌位中剔除；在孔子庙兼祭孔子的父母。那时候天下人都很期待，认为您一定大有作为。有见识的人都认为：只要有好的臣子帮助，不需多久，天下就可太平，您一定比汉文帝要强得多。然而文帝能发扬仁恕之性，节约恭俭，体恤爱民，宋朝的吕祖谦说他善于用人，能尽人之才力。一时天下虽说不上已经大治，但国库充盈，连串钱的绳子都朽烂了，百姓安乐，财物丰足。大家公认他是夏、商、周三代以后的一位贤君。 陛下您立志要有作为，可是没过多久，就被杂乱的念头导引到别的地方去了。您把自己的刚强英明用到错误的地方，以为人真的能够长生不老，而一味的玄修。陛下富有四海，却不念及那都是民之脂膏，常常大兴土木，大修宫殿庙宇。陛下二十余年不上朝处理政务，导致纲纪松懈败坏。朝廷卖官买官，援用这种章程越来越滥，美其名曰推广事例，导致豪强四起，名爵泛滥。您专门和方士在一起炼丹，不与自己的儿子们相见，人们都以为您缺少父子之情。您常以猜疑诽谤戮辱臣下，人们都以为缺少君臣之礼。您整天待在西苑不回宫，人们都以为缺少夫妇之情。天下官吏贪污成风，军队弱小，水灾旱灾无时不有，民不聊生，导致流民暴乱象火烧一样，越来越盛。自陛下登基以来，前几年就这样，但还不严重，但是如今赋税徭役越来越重，各级官吏都效法朝廷，盘剥百姓无度。陛下花很多钱崇奉道教，十余年来已经做到极致了。因此，陛下改元号之时，天下人都猜想：这意思就是说“嘉靖者言家家皆净而无财用也”。 近来，严嵩罢相，严世蕃被处以极刑，勉强可以令人满意，一时人称天下清明。然而严嵩罢相以后的政事，不过和他作宰相以前差不多，也并不见得清明多少。陛下比汉文帝差远了。天下之人对您不满已经很久了，这内外臣工都知道。《诗经》上说：“衰职有阙，惟仲山甫补之”，意思是说宣王不能完全尽职，仲山甫能从旁补救。今日以辅助、匡正来补救、纠正错误并使一切走入正轨，正是诸位臣下的职责所在。圣人也不能不犯错误，否则古代设官，只要他做官办事就够了，不必要求他们进言劝谏，也不必设谏官，更不必说木绳金砺这类的话了。陛下修宫殿，设坛祈祷，就让群臣竞相进献香物和仙桃仙药，叫臣子进表管贺。陛下要兴建宫室，工部就极力经营；陛下要取香觅宝，户部就派人到处索取。陛下举动有误，诸臣顺从得也没道理，竟没有一个人为陛下正言。那种公开讨论对错、贡献良言，防止邪恶的做法，长久没有听到了，献媚的风气太甚。然而人们不敢直言，内心却不能不惭愧，气也不壮了，当面不敢说，却在背后议论是非，人们表面上顺从陛下，却把真心藏起来，这样为陛下歌功颂德，是多么大的欺君之罪？ 天下者，陛下之家也，哪有不顾自己家的人呢？内外臣工都有行政职务和进言的责任，这些都是能够奠定您的家业，使它象磐石一样的稳固的基础。一意玄修，是陛下的心被妄念迷惑。过分苛刻武断，也不是您生性如此。不能就这样便断定陛下不顾其家，不合乎人情。臣子们往往为了顾及自己的身家性命，为了保住自己的乌纱帽，欺诈、贪赃、旷废职务而导致犯罪，这些人不合您的心意，是很自然的。假如不是为了上述的原因也不合您的心意，那就是您的心与臣子的心偶然不相投合啊，但也有人疑心是您看轻臣子，侮辱臣子。另外有一种人，自己的心思不正，或是为了个人的利益，或是说得不够详明正确，就象胡寅扰乱政事的奏疏那样：这些人不合您的意旨，也是很自然的。如果都不是以上的情况，君意臣意还不相符合，那就要让人疑心是不是因为陛下自以为是，不愿接受劝谏的缘故。抓住一二件这样的事，就推测您向来如此，害得您一直被人误解。《礼记》上说：“君主多疑于上，百姓就无所适从；臣子不忠于下，君主就劳苦不堪了。”说的就是今天这种情况。 臣子保身家的私心和怕触怒君主的心相结合，因而模糊了自己的职责，我已经举出一二件事例替他们作过分析了。君主求长生的妄念和迷惑不明相结合，就使臣子们心怀不满；陛下有失为君之道，请允许我再加以分析。 陛下的失误很多，大部分是因为修醮。修醮是为了求长生不老。古来的圣贤只不过讲求涵养道德，保养生命，顺应自然法则。天地赋予人生命，不过如此罢了。尧、舜、禹、汤、文、武都是圣人，也没有谁能长生不死。他们之后，也没有见到所谓僧道术士之人从汉、唐、宋活到今天。传给您长生法术的陶仲文，您称他为师傅，可是他自己就已经死了。仲文尚不能长生不死，陛下为什么还要求长生？至于那所谓的仙桃药丸，怪妄尤甚。伏羲氏做了天下的王，有龙马出河，于是便依据龙马的花纹画了八卦。夏禹治水时，出现神龟，就把神龟背上罗列的各种纹路排列起来，成为有关天道人事的九种法则。这些 “神物”透露了万古不传的秘密。天将天道显之于圣人，借圣人来明示天下，就像日月星辰的排列，并不虚妄。但宋真宗赵恒为了粉饰太平，听从王钦若等人的话，伪造天书，声称从天而降，他的大臣孙奭就谏言道：“上天哪里会说什么？怎么还能写书？”仙桃是从树上采摘下来的，仙药由人工捣制而成。你说它们能有什么天意？能起什么作用？天赐之物，难道能让人手里拿着给您？陛下玄修多年，一无所得。到今日，左右奸人迎合陛下玄修妄念，以为区区桃药就能让人长生不老，世上哪有这样的道理？玄修之无益可知矣。 陛下您莫非认为只要抓住刑和赏的权柄，就不怕无人办事，天下就可以治好，修道便没有什么害处了吗？那些阿谀逢迎的臣子，年轻时候就没有学到“致君泽民” （把君主辅佐好，使百姓得到好处）的特别本领和修养，壮年做官也没有“致君泽民”的特殊抱负和愿望。〈尚书·太甲〉曰：“有言逆于汝志，必求诸道，有言逊于汝志，必求诸非道。意思是说：遇有不合自己意旨的话，要看看是否合于道理；遇有顺从自己意旨的话，要看看是否不合道理。顺从旨意的未必就是有道理的。从近些年来看：严嵩哪有一处不是顺着陛下您的意思？然而严党过去是贪权窃利的祸害，今天是忤逆乱政的根源。象梁材这样的人谨守职责，历来做官有声誉有操守，以正直不阿著称，却被陛下认为大逆不道。虽然从严嵩抄家以后，百官有所畏惧，知道不能再以贿赂谋求升迁，稍改以前的恶习。然而严嵩罢相之后的局面也和严嵩做丞相之前没什么两样。百官仍然只情愿学严嵩的顺从，不肯学梁材的正直不阿。现在坏人还是贪求无厌，一般人也只是得过且过，混混日子。即使是好人，也不过是在做官和退隐之间犹豫不决，含糊敷衍，奉行做事罢了。而那种洁身自爱、探研真理，对天下负有责任，能够肩负国运，维护长治久安的人，却一个也没有发现。不就是因为好人受到牵制，不能尽忠做事，才弄到今天这个地步吗？您既要人顺从圣意，又要人尽忠；既要人充当助手和耳目，又要人顺从您做那些修道和兴修宫殿庙宇的错误事情：这就象不用四肢耳目去保卫心腹，而由心腹自己去执行看、听、拿东西和走路的任务一样。照此下去，您即便有了象张仪和公孙衍那样能干的臣子，要想成就与百姓同享太平的事业，那也是办不到的。 如果您承认修道有害无益，那么臣子的转变，百姓的祸福，天下的安危都将由此而不同，所以您应当立即悔悟，每日上朝理政，与宰辅、九卿、侍从、言官一起言说天下利害，洗刷数十年君道之误，那样就能置身于尧、舜、禹、汤、文、武这样的明君之中，也使得臣下能够洗刷数十年谄媚君主之耻，让他们置身于皋陶、伊、傅这样的贤臣之列，君臣便可互相勉励、互相敬重。内廷中的宦官宫女，外廷中光禄寺厨房的仆役，锦衣卫中那些受惠于祖先恩荫的人，以及各个衙门里那些额外的冗员，无事可干而为官的人太多了。皇家的仓库里，户部、工部以及光禄寺等衙门里，缎、绢、粮料、珠宝、器物、木材等东西很多，堆积在那里也无用，用了也用的不是地方，白白浪费了很可惜。臣子们进谏，您采纳实行，对您说来只不过动一动节省的念头罢了。京师里的一块金子，到了田野百姓那里抵得上一百块金子用。您稍稍节省一点，国库便有余用，老百姓则有了储蓄，好处真不知有多少啊，而陛下为何不这样做呢？ 今天官吏设置不全，办事因循苟且，敷衍塞责，不守法纪，却还自以为不错。应该督促遵守基本的道德来端正官员们的行为，停止用钱买官那一套来理清仕途；让文武官员安于其位，责成他们做出成绩来；平常就练选军士以免打仗了临时召募百姓；让那些吃白食的和尚道士回家，回到士、农、工、商的行业里；府州县地方官要生计和教化并重，树立好的礼俗规范；屯田、运盐应该恢复征收实物，来充实边防军队的储备；按地亩交粮，按人口应役，以便恢复老百姓的元气；检举天下官员的贪污勒索行为，让那些贪赃枉法的人心生怯懦，按照刑律处罚他们，毫不宽容。如此以来，便是仁政，几十年之后才能收效，与天地并存的伟大功业便可成就了。这样的事由诸臣提议，陛下执行，也就在陛下一振作间而已。一振作而诸废具举，百弊铲绝，象唐、虞三代那样光明灿烂的大治便可复兴矣，而陛下为什么不实行呢？ 陛下只要稍事节省和振作就行了，又不是要您多么劳心劳神。九卿掌握大政方针，百官承担具体的职责，巡抚、巡按、六科给事中等纠举肃清，维护风气，陛下考核政纲的实施情况，督促他们做出成绩来。努力去找贤才，任用他们办事，自己就省力了。就像天运于上，四时六气各得其序，君主只要自己有德，感化臣民，不必亲自动手管理一切。天地万物为一体，自有它的道理。百姓安居乐业，形成一片祥和气氛，而陛下自然能够感到真正的快乐和价值。天地是化生万物的，人也有帮助天地化生的能力，可以与天地并列而为“三才”。道与天通，命运可以由我们自己掌握，而陛下自然能够享受真寿。这是真正的道理，转身就能做到，立刻就能见效。要是依旧去服食什么长生不死之药，巴望着能成仙升天，不是道理所在。那么做只能匆忙的散爵禄，让精神徒然的紧张，玄修求长生，是捕风捉影的空想，陛下一辈子求之，究竟得到没得到呢？ 君道不正，臣职不明，是天下第一大事。于此不言，更复何言？大臣为保乌纱帽而阿谀奉承，小臣害怕获罪表面顺从，陛下有错误却不知道，不能改正不能执行，臣每想到这里便痛心疾首。所以今天便冒死竭忠，诚恳的向陛下进言。望陛下能够改变心思，转换方向，而天下之治与不治，民物之安与不安都取决于您，若陛下真能采纳，是我宗庙、社稷、国家的幸运，是天下黎民百姓的幸运！]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>古文</tag>
        <tag>政论文</tag>
        <tag>海瑞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[治安策]]></title>
    <url>%2F2019%2F02%2F10%2F%E6%B2%BB%E5%AE%89%E7%AD%96%2F</url>
    <content type="text"><![CDATA[参考: 维基百科 介绍 贾谊（前200—前168年），汉族，洛阳（今河南洛阳东）人，西汉初年著名政论家、文学家，世称贾生。贾谊少有才名，十八岁时，以善文为郡人所称。文帝时任博士，迁太中大夫，受大臣周勃、灌婴排挤，谪为长沙王太傅，故后世亦称贾长沙、贾太傅。三年后被召回长安，为梁怀王太傅。梁怀王坠马而死，贾谊深自歉疚，抑郁而亡，时仅33岁。司马迁对屈原、贾谊都寄予同情，为二人合传，后世因而往往把贾谊与屈原并称为“屈贾”。贾谊著作主要有散文和辞赋两类，散文的主要文学成就是政论文，评论时政，风格朴实峻拔，议论酣畅，鲁迅称之为“西汉鸿文”，代表作有《过秦论》《论积贮疏》《陈政事疏》等。其辞赋皆为骚体，形式趋于散体化，是汉赋发展的先声，以《吊屈原赋》《鵩鸟赋》最为著名。 《治安策》是西汉文学家贾谊创作的一篇政论文。这篇论文论及了文帝时潜在或明显的多种社会危机，包括“可为痛哭者一，可为流涕者二，可为长叹息者六”等众多严重问题，涉及中央与地方诸侯之间、汉庭与北方异族之间，以及社会各阶层之间的种种矛盾，针对这令人忧心的一切，贾谊富有针对性地一一指明相应对策和补救措施。这篇论文势忽峻忽缓、首尾相衔，大量采用夹叙夹议，还在议论说理的同时，不失时机地运用文学笔法。 西汉前期社会存在着三大矛盾：其一是匈奴为代表的边境少数民族与汉王朝之间的矛盾；其二是地方诸侯王的割据势力与中央政府之间的矛盾；其三是广大农民和地主、大工商业者的矛盾。汉文帝时期，天下大势已定，这些社会矛盾虽然尚未激化到即将公开破裂的程度，但却在酝酿并渐趋于激化的过程之中。 原文 臣窃惟事势，可为痛哭者一，可为流涕者二，可为长太息者六，若其它背理而伤道者，难遍以疏举。进言者皆曰天下已安已治矣，臣独以为未也。曰安且治者，非愚则谀，皆非事实知治乱之体者也。夫抱火厝之积薪之下而寝其上，火未及燃，因谓之安，方今之势，何以异此！本末舛逆，首尾衡决，国制抢攘，非甚有纪，胡可谓治！陛下何不壹令臣得孰数之于前，因陈治安之策，试详择焉！ 夫射猎之娱，与安危之机孰急？使为治，劳智虑，苦身体，乏钟鼓之乐，勿为可也。乐与今同，而加之诸侯轨道，兵革不动，民保首领，匈奴宾服，四荒乡风，百姓素朴，狱讼衰息，大数既得，则天下顺治，海内之气清和咸理，生为明帝，没为明神，名誉之美，垂于无穷。礼祖有功而宗有德，使顾成之庙称为太宗，上配太祖，与汉亡极。建久安之势，成长治之业，以承祖庙，以奉六亲，至孝也；以幸天下，以育群生，至仁也；立经陈纪，轻重同得，后可以为万世法程，虽有愚幼不肖之嗣，犹得蒙业而安，至明也。以陛下之明达，因使少知治体者得佐下风，致此非难也。其具可素陈于前，愿幸无忽。臣谨稽之天地，验之往古，按之当今之务，日夜念此至孰也，虽使禹舜复生，为陛下计，亡以易此。 夫树国固必相疑之势，下数被其殃，上数爽其忧，甚非所以安上而全下也。今或亲弟谋为东帝，亲兄之子西乡而击，今吴又见告矣。天子春秋鼎盛，行义未过，德泽有加焉，犹尚如是，况莫大诸侯，权力且十此者虖！ 然而天下少安，何也？大国之王幼弱未壮，汉之所置傅相方握其事。数年之后，诸侯之王大抵皆冠，血气方刚，汉之傅相称病而赐罢，彼自丞尉以上偏置私人，如此，有异淮南、济北之为邪！此时而欲为治安，虽尧舜不治。 黄帝曰：「日中必熭，操刀必割。」今令此道顺而全安，甚易，不肯早为，已乃堕骨肉之属而抗刭之，岂有异秦之季世虖！夫以天子之位，乘今之时，因天之助，尚惮以危为安，以乱为治，假设陛下居齐桓之处，将不合诸侯而匡天下乎？臣又以知陛下有所必不能矣。假设天下如曩时，淮阴侯尚王楚，黥布王淮南，彭越王梁，韩信王韩，张敖王赵，贯高为相，卢绾王燕，陈豨在代，令此六七公者皆亡恙，当是时而陛下即天子位，能自安乎？臣有以知陛下之不能也。天下淆乱，高皇帝与诸公并起，非有仄室之势以豫席之也。诸公幸者，乃为中涓，其次廑得舍人，材之不逮至远也。高皇帝以明圣威武即天子位，割膏腴之地以王诸公，多者百余城，少者乃三四十县，德至渥也，然其后十年之间，反者九起。陛下之与诸公，非亲角材而臣之也，又非身封王之也，自高皇帝不能以是一岁为安，故臣知陛下之不能也。然尚有可诿者，曰疏，臣请试言其亲者。假令悼惠王王齐，元王王楚，中子王赵，幽王王淮阳，共王王梁，灵王王燕，厉王王淮南，六七贵人皆亡恙，当是时陛下即位，能为治虖？臣又知陛下之不能也。若此诸王，虽名为臣，实皆有布衣昆弟之心，虑亡不帝制而天子自为者。擅爵人，赦死罪，甚者或戴黄屋，汉法令非行也。虽行不轨如厉王者，令之不肯听，召之安可致乎！幸而来至，法安可得加！动一亲戚，天下圜视而起，陛下之臣虽有悍如冯敬者，适启其口，匕首已陷其匈矣。陛下虽贤，谁与领此？故疏者必危，亲者必乱，已然之效也。其异姓负强而动者，汉已幸胜之矣，又不易其所以然。同姓袭是迹而动，既有征矣，其势尽又复然。殃旤之变，未知所移，明帝处之尚不能以安，后世将如之何！ 屠牛坦一朝解十二牛，而芒刃不顿者，所排击剥割，皆众理解也。至于髋髀之所，非斤则斧。夫仁义恩厚，人主之芒刃也；权势法制，人主之斤斧也。今诸侯王皆众髋髀也，释斤斧之用，而欲婴以芒刃，臣以为不缺则折。胡不用之淮南、济北？势不可也。 臣窃迹前事，大抵强者先反。淮阴王楚最强，则最先反；韩信倚胡，则又反；贯高因赵资，则又反；陈豨兵精，则又反；彭越用梁，则又反；黥布用淮南，则又反；卢绾最弱，最后反。长沙乃在二万五千户耳，功少而最完，势疏而最忠，非独性异人也，亦形势然也。曩令樊、郦、绛、灌据数十城而王，今虽以残亡可也；令信、越之伦列为彻侯而居，虽至今存可也。然则天下之大计可知已。欲诸王之皆忠附，则莫若令如长沙王；欲臣子之勿菹醢，则莫若令如樊、郦等；欲天下之治安，莫若众建诸侯而少其力。力少则易使以义，国小则亡邪心。令海内之势如身之使臂，臂之使指，莫不制从，诸侯之君不敢有异心，辐凑并进而归命天子，虽在细民，且知其安，故天下咸知陛下之明。割地定制，令齐、赵、楚各为若干国，使悼惠王、幽王、元王之子孙毕以次各受祖之分地，地尽而止，及燕、梁它国皆然。其分地众而子孙少者，建以为国，空而置之，须其子孙生者，举使君之。诸侯之地其削颇入汉者，为徙其侯国及封其子孙也，所以数偿之：一寸之地，一人之众，天子亡所利焉，诚以定治而已，故天下咸知陛下之廉。地制壹定，宗室子孙莫虑不王，下无倍畔之心，上无诛伐之志，故天下咸知陛下之仁。法立而不犯，令行而不逆，贯高、利几之谋不生，柴奇、开章之计不萌，细民乡善，大臣致顺，故天下咸知陛下之义。卧赤子天下之上而安，植遗腹，朝委裘，而天下不乱，当时大治，后世诵圣。壹动而五业附，陛下谁惮而久不为此？ 天下之势方病大瘇。一胫之大几如要，一指之大几如股，平居不可屈信，一二指搐，身虑亡聊。失今不治，必为锢疾，后虽有扁鹊，不能为已。病非徒瘇也，又苦𨂂盭。元王之子，帝之从弟也；今之王者，从弟之子也。惠王［之子］，亲兄子也；今之王者，兄子之子也。亲者或亡分地以安天下，疏者或制大权以逼天子，臣故曰非徒病瘇也，又苦𨂂盭。可痛哭者，此病是也。 天下之势方倒县。凡天子者，天下之首，何也？上也。蛮夷者，天下之足，何也？下也。今匈奴嫚娒侵掠，至不敬也，为天下患，至亡已也，而汉岁致金絮采缯以奉之。夷狄征令，是主上之操也；天子共贡，是臣下之礼也。足反居上，首顾居下，倒县如此，莫之能解，犹为国有人乎？非亶倒县而已，又类辟，且病痱。夫辟者一面病，痱者一方痛。今西边北边之郡，虽有长爵不轻得复，五尺以上不轻得息，斥候望烽燧不得卧，将吏被介胄而睡，臣故曰一方病矣。医能治之，而上不使，可为流涕者此也。 陛下何忍以帝皇之号为戎人诸侯，势既卑辱，而旤不息，长此安穷！进谋者率以为是，固不可解也，亡具甚矣。臣窃料匈奴之众不过汉一大县，以天下之大困于一县之众，甚为执事者羞之。陛下何不试以臣为属国之官以主匈奴？行臣之计，请必系单于之颈而制其命，伏中行说而笞其背，举匈奴之众唯上之令。今不猎猛敌而猎田彘，不搏反寇而搏畜菟，翫细娱而不图大患，非所以为安也。德可远施，威可远加，而直数百里外威令不信，可为流涕者此也。 今民卖童者，为之绣衣丝履偏诸缘，内之闲中，是古天子后服，所以庙而不晏者也，而庶人得以衣婢妾。白縠之表，薄纨之里，緁以偏诸，美者黼绣，是古天子之服，今富人大贾嘉会召客者以被墙。古者以奉一帝一后而节适，今庶人屋壁得为帝服，倡优下贱得为后饰，然而天下不屈者，殆未有也。且帝之身自衣皂绨，而富民墙屋被文绣；天子之后以缘其领，庶人㜸妾缘其履：此臣所谓舛也。夫百人作之不能衣一人，欲天下亡寒，胡可得也？一人耕之，十人聚而食之，欲天下亡饥，不可得也。饥寒切于民之肌肤，欲其亡为奸邪，不可得也。国已屈矣，盗贼直须时耳，然而献计者曰「毋动」，为大耳。夫俗至大不敬也，至亡等也，至冒上也，进计者犹曰「毋为」，可为长太息者此也。 商君遗礼义，弃仁恩，并心于进取，行之二岁，秦俗日败。故秦人家富子壮则出分，家贫子壮则出赘。借父耰鉏，虑有德色；母取箕箒，立而谇语。抱哺其子，与公并倨；妇姑不相说，则反唇而相稽。其慈子耆利，不同禽兽者亡几耳。然并心而赴时，犹曰蹷六国，兼天下。功成求得矣，终不知反廉愧之节，仁义之厚。信并兼之法，遂进取之业，天下大败；众掩寡，智欺愚，勇威怯，壮陵衰，其乱至矣。是以大贤起之，威震海内，德从天下。曩之为秦者，今转而为汉矣。然其遗风余俗，犹尚未改。今世以侈靡相竞，而上亡制度，弃礼谊，捐廉耻，日甚，可谓月异而岁不同矣。逐利不耳，虑非顾行也，今其甚者杀父兄矣。盗者剟寝户之帘，搴两庙之器，白昼大都之中剽吏而夺之金。矫伪者出几十万石粟，赋六百余万钱，乘传而行郡国，此其亡行义之（先）〔尤〕至者也。而大臣特以簿书不报，期会之间，以为大故。至于俗流失，世坏败，因恬而不知怪，虑不动于耳目，以为是适然耳。夫移风易俗，使天下回心而乡道，类非俗吏之所能为也。俗吏之所务，在于刀笔筐箧，而不知大（礼）〔体〕。陛下又不自忧，窃为陛下惜之。 夫立君臣，等上下，使父子有礼，六亲有纪，此非天之所为，人之所设也。夫人之所设，不为不立，不植则僵，不修则坏。管子曰：「礼义廉耻，是谓四维；四维不张，国乃灭亡。」使管子愚人也则可，管子而少知治体，则是岂可不为寒心哉！秦灭四维而不张，故君臣乖乱，六亲殃戮，奸人并起，万民离叛，凡十三岁，〔而〕社稷为虚。今四维犹未备也，故奸人几幸，而众心疑惑。岂如今定经制，令君君臣臣，上下有差，父子六亲各得其宜，奸人亡所几幸，而群臣众信，上不疑惑！此业壹定，世世常安，而后有所持循矣。若夫经制不定，是犹度江河亡维楫，中流而遇风波，舩必覆矣。可为长太息者此也。 夏为天子，十有余世，而殷受之。殷为天子，二十余世，而周受之。周为天子，三十余世，而秦受之。秦为天子，二世而亡。人性不甚相远也，何三代之君有道之长，而秦无道之暴也？其故可知也。古之王者，太子乃生，固举以礼，使士负之，有司齐肃端冕，见之南郊，见于天也。过阙则下，过庙则趋，孝子之道也。故自为赤子而教固已行矣。昔者成王幼在襁抱之中，召公为太保，周公为太傅，太公为太师。保，保其身体；傅，傅之德（意）〔义〕；师，道之教训：此三公之职也。于是为置三少，皆上大夫也，曰少保、少傅、少师，是与太子宴者也。故乃孩提有识，三公、三少固明孝仁礼义以道习之，逐去邪人，不使见恶行。于是皆选天下之端士孝悌博闻有道术者以卫翼之，使与太子居处出入。故太子乃生而见正事，闻正言，行正道，左右前后皆正人也。夫习与正人居之，不能毋正，犹生长于齐不能不齐言也；习与不正人居之，不能毋不正，犹生长于楚之地不能不楚言也。故择其所耆，必先受业，乃得尝之；择其所乐，必先有习，乃得为之。孔子曰：「少成若天性，习贯如自然。」及太子少长，知妃色，则入于学。学者，所学之官也。学礼曰：「帝入东学，上亲而贵仁，则亲疏有序而恩相及矣；帝入南学，上齿而贵信，则长幼有差而民不诬矣；帝入西学，上贤而贵德，则圣智在位而功不遗矣；帝入北学，上贵而尊爵，则贵贱有等而下不隃矣；帝入太学，承师问道，退习而考于太傅，太傅罚其不则而匡其不及，则德智长而治道得矣。此五学者既成于上，则百姓黎民化辑于下矣。」及太子既冠成人，免于保傅之严，则有记过之史，彻膳之宰，进善之旌，诽谤之木，敢谏之鼓。瞽史诵诗，工诵箴谏，大夫进谋，士传民语。习与智长，故切而不愧；化与心成，故中道若性。三代之礼：春朝朝日，秋暮夕月，所以明有敬也；春秋入学，坐国老，执酱而亲馈之，所以明有孝也；行以鸾和，步中采齐，趣中肆夏，所以明有度也；其于禽兽，见其生不食其死，闻其声不食其肉，故远庖厨，所以长恩，且明有仁也。 夫三代之所以长久者，以其辅翼太子有此具也。及秦而不然。其俗固非贵辞让也，所上者告讦也；固非贵礼义也，所上者刑罚也。使赵高傅胡亥而教之狱，所习者非斩劓人，则夷人之三族也。故胡亥今日即位而明日射人，忠谏者谓之诽谤，深计者谓之妖言，其视杀人若艾草菅然。岂惟胡亥之性恶哉？彼其所以道之者非其理故也。 鄙谚曰：「不习为吏，视已成事。」又曰：「前车覆，后车诫。」夫三代之所以长久者，其已事可知也；然而不能从者，是不法圣智也。秦世之所以亟绝者，其辙迹可见也；然而不避，是后车又将覆也。夫存亡之变，治乱之机，其要在是矣。天下之命，县于太子；太子之善，在于早谕教与选左右。夫心未滥而先谕教，则化易成也；开于道术智谊之指，则教之力也。若其服习积贯，则左右而已。夫胡、粤之人，生而同声，耆欲不异，及其长而成俗，累数译而不能相通，行者〔有〕虽死而不相为者，则教习然也。臣故曰选左右早谕教最急。夫教得而左右正，则太子正矣，太子正而天下定矣。书曰：「一人有庆，兆民赖之。」此时务也。 凡人之智，能见已然，不能见将然。夫礼者禁于将然之前，而法者禁于已然之后，是故法之所用易见，而礼之所为生难知也。若夫庆赏以劝善，刑罚以惩恶，先王执此之政，坚如金石，行此之令，信如四时，据此之公，无私如天地耳，岂顾不用哉？然而曰礼云礼云者，贵绝恶于未萌，而起教于微眇，使民日迁善远辠而不自知也。孔子曰：「听讼，吾犹人也，必也使毋讼乎！」为人主计者，莫如先审取舍；取舍之极定于内，而安危之萌应于外矣。安者非一日而安也，危者非一日而危也，皆以积渐然，不可不察也。人主之所积，在其取舍。以礼义治之者，积礼义；以刑罚治之者，积刑罚。刑罚积而民怨背，礼义积而民和亲。故世主欲民之善同，而所以使民善者或异。或道之以德教，或殴之以法令。道之以德教者，德教洽而民气乐；殴之以法令者，法令极而民风哀。哀乐之感，祸福之应也。秦王之欲尊宗庙而安子孙，与汤武同，然而汤武广大其德行，六七百岁而弗失，秦王治天下，十余岁则大败。此亡它故矣，汤武之定取舍审而秦王之定取舍不审矣。夫天下，大器也。今人之置器，置诸安处则安，置诸危处则危。天下之情与器亡以异，在天子之所置之。汤武置天下于仁义礼乐，而德泽洽，禽兽草木广裕，德被蛮貊四夷，累子孙数十世，此天下所共闻也。秦王置天下于法令刑罚，德泽亡一有，而怨毒盈于世，下憎恶之如仇仇，旤几及身，子孙诛绝，此天下之所共见也。是非其明效大验邪！人之言曰：「听言之道，必以其事观之，则言者莫敢妄言。」今或言礼谊之不如法令，教化之不如刑罚，人主胡不引殷、周、秦事以观之也？ 人主之尊譬如堂，群臣如陛，众庶如地。故陛九级上，廉远地，则堂高；陛亡级，廉近地，则堂卑。高者难攀，卑者易陵，理势然也。故古者圣王制为等列，内有公卿大夫士，外有公侯伯子男，然后有官师小吏，延及庶人，等级分明，而天子加焉，故其尊不可及也。里谚曰：「欲投鼠而忌器。」此善谕也。鼠近于器，尚惮不投，恐伤其器，况于贵臣之近主乎！廉耻节礼以治君子，故有赐死而亡戮辱。是以黥劓之辠不及大夫，以其离主上不远也。礼不敢齿君之路马，蹴其刍者有罚；见君之几杖则起，遭君之乘车则下，入正门则趋；君之宠臣虽或有过，刑戮之辠不加其身者，尊君之故也。此所以为主上豫远不敬也，所以体貌大臣而厉其节也。今自王侯三公之贵，皆天子之所改容而礼之也，古天子之所谓伯父、伯舅也，而令与众庶同黥劓髠刖笞傌弃巿之法，然则堂不亡陛虖？被戮辱者不泰迫虖？廉耻不行，大臣无乃握重权，大官而有徒隶亡耻之心虖？夫望夷之事，二世见当以重法者，投鼠而不忌器之习也。 臣闻之，履虽鲜不加于枕，冠虽敝不以苴履。夫尝已在贵宠之位，天子改容而体貌之矣，吏民尝俯伏以敬畏之矣，今而有过，帝令废之可也，退之可也，赐之死可也，灭之可也；若夫束缚之，系緤之，输之司寇，编之徒官，司寇小吏詈骂而榜笞之，殆非所以令众庶见也。夫卑贱者习知尊贵者之一旦吾亦乃可以加此也，非所以习天下也，非尊尊贵贵之化也。夫天子之所尝敬，众庶之所尝宠，死而死耳，贱人安宜得如此而顿辱之哉！ 豫让事中行之君，智伯伐而灭之，移事智伯。及赵灭智伯，豫让衅面吞炭，必报襄子，五起而不中。人问豫子，豫子曰：「中行众人畜我，我故众人事之；智伯国士遇我，我故国士报之。」故此一豫让也，反君事仇，行若狗彘，已而抗节致忠，行出虖列士，人主使然也。故主上遇其大臣如遇犬马，彼将犬马自为也；如遇官徒，彼将官徒自为也。顽顿亡耻奊诟亡节，廉耻不立，且不自好，苟若而可，故见利则逝，见便则夺。主上有败，则因而挻之矣；主上有患，则吾苟免而已，立而观之耳；有便吾身者，则欺卖而利之耳。人主将何便于此？群下至众，而主上至少也，所托财器职业者粹于群下也。俱亡耻，俱苟妄，则主上最病。故古者礼不及庶人，刑不至大夫，所以厉宠臣之节也。古者大臣有坐不廉而废者，不谓不廉，曰「簠簋不饰」；坐污秽淫乱男女亡别者，不曰污秽，曰「帷薄不修」；坐罢软不胜任者，不谓罢软，曰「下官不职」。故贵大臣定有其辠矣，犹未斥然正以謼之也，尚迁就而为之讳也。故其在大谴大何之域者，闻谴何则白冠牦缨，盘水加剑，造请室而请辠耳，上不执缚系引而行也。其有中罪者，闻命而自弛，上不使人颈盭而加也。其有大辠者，闻命则北面再拜，跪而自裁，上不使捽抑而刑之也，曰：「子大夫自有过耳！吾遇子有礼矣。」遇之有礼，故群臣自憙；婴以廉耻，故人矜节行。上设廉耻礼义以遇其臣，而臣不以节行报其上者，则非人类也。故化成俗定，则为人臣者主耳忘身，国耳忘家，公耳忘私，利不苟就，害不苟去，唯义所在。上之化也，故父兄之臣诚死宗庙，法度之臣诚死社稷，辅翼之臣诚死君上，守圄捍敌之臣诚死城郭封疆。故曰圣人有金城者，比物此志也。彼且为我死，故吾得与之俱生；彼且为我亡，故吾得与之俱存；夫将为我危，故吾得与之皆安。顾行而忘利，守节而仗义，故可以托不御之权，可以寄六尺之孤。此厉廉耻行礼谊之所致也，主上何丧焉！此之不为，而顾彼之久行，故曰可为长太息者此也。 译文 我私下考虑如今的局势，可为之痛哭的有一项，可为之流泪的有两项，应为之大声叹息的有六项，至于其他违背情理而伤害大道的事，很难一一列举。向陛下进言的人都说天下已经安定，治理得很好了，我却认为不是那么回事。说天下已经安定已经大治的人，不是愚昧无知，就是阿谀奉承，都不是真正了解治乱大体的人。有人抱着火种放在堆积的木柴之下，自己睡在木柴上，火没燃烧起来的时候，他便认为这是安宁的地方，如今国家的局势，与此有什么不同！本末颠倒，首尾冲突，国制混乱，不合理的现象严重，怎么能够说是大治！陛下为什么不让我对您详细地说明这一切，提出使国家真正大治大安的方策，以供陛下仔细斟酌选用呢？ 射箭打猎之类的娱乐与国家安危的关键相比，哪一样更急迫？假若所提的治世方法，耗费心血，摧残身体，影响享受钟鼓所奏音乐，可以不采纳；我的治国方策，能保证使陛下所享受的乐趣不受影响，却可以带来封国诸侯各遵法规，战争不起，平民拥护首领，匈奴归顺，纯朴之风响彻边陲，百姓温良朴素，官司之类的事情停止不发。大势已定，那么，全国便会顺从而大治，四海之内，一派升平，万物都符合事理，陛下生时被称为明帝，死后成为明神，美名佳誉永垂青史。《礼》书上说宗庙有功德，使您的顾成庙被尊称为大宗，得以与太祖共享盛名，与大汉天下共存亡。创建长久安定的形势，造成永久太平的业绩，以此来承奉祖庙和六亲，这是最大的孝顺；以此来使老百姓得到幸福，使芸芸众生得到养育，这是最大的仁；创设准则，标立纪纲，使大小事物各得其所，为万世子孙树立楷模，即使是后世出现了愚鲁、幼稚、不肖的继承人，由于他继承了您的鸿业和福荫，还可以安享太平，这是最明智的办法。凭陛下的精明练达，再有稍微懂得治国之道的人辅佐，要达到这一境界并不困难。其内容全都可以向陛下陈述，希望陛下不要忽视。我谨慎地用它来考察过天地的变化，应验过往，核对当今，日夜思考而详细地知道了它的内容，即使是禹舜再生，也不能加以改变。 建立诸侯国过于强大，必然会造成天子与诸侯互相对立，臣下屡遭祸害，皇上也多次忧伤，这实在不是使皇上放心、使臣下保全的办法。如今亲兄弟图谋在东方称帝，亲侄子也向西袭击朝廷，吴王的谋反活动又被人告发。当今天子年富力强，品行道义上没有过错，对他们施加功德恩泽，而他们尚且如此，何况最大的诸侯，权力比他们还要大十倍呢！ 虽然如此，但是天下还比较安定，这是什么原因呢？因为大诸侯国王年纪还小，汉朝安置在那的太傅、丞相还掌握着政事。几年以后，诸侯王大都加冠成人，血气方刚，而汉朝委派的太傅、丞相都要称病还乡，诸侯王会遍插亲信，如果这样的话，他们的行为同淮南王、济北王有什么区别呢？到了那时，想求得天下安定，即使是尧舜在世也办不到。 黄帝说：“到了中午要抓紧曝晒，拿着刀子要赶紧宰割。”如今要使安治之道顺利而稳妥地推行，是十分容易的。假使不肯及早行动，到头来就要毁掉亲骨肉，这同秦朝末年的局势还有什么区别吗？凭着天子的权位，趁着当今的有利时机，靠着上天的帮助，尚且对转危为安、改乱为治的措施有所顾虑，假设陛下处在齐桓公的境地，大概不会去联合诸侯匡正天下吧？我知道陛下一定不能那样做的。假如国家的局势还像从前那样，淮阴侯韩信还统治着楚，黥布统治着淮南，彭越统治着梁，韩王信统治着韩，张敖统治着赵，贯高做赵国的相，卢绾统治着燕，陈还在代国，假令这六七个王公都还健在，在这时陛下继位做天子，自己能感到安全吗？我判断陛下是不会感到安全的。在天下混乱的年代，高祖和这些王公们共同起事，并没有子侄亲属的势力做为依靠。这些王公走运的就成了亲近的侍从，差一点的仅当个管理宫中事务的官员，他们的才能远不及高祖。高祖凭着他的明智威武，即位做了天子，割出肥沃的土地，使这些王公成为诸侯王，多的有一百多个城，少的也有三四十个县，恩德是优厚的了，然而在以后的十年当中，反叛汉朝的事发生了九次。陛下跟这些王公，并没有亲自较量过才能而使他们甘心为臣的，也不是亲自封他们当诸侯王的。即使高祖也不能因此而得到一年的安宁，所以我知道陛下更不能得到安宁的。 不过，上面这些情况，还有可以推托的理由，说是“关系疏远”。那就请允许我试着谈谈那些亲属诸侯王吧。假如让齐悼惠王统治着齐，楚元王统治着楚，赵王统治着赵，幽王统治着淮阳，恭王统治着梁，灵王统治着燕，厉王统治着淮南，假如这六七位贵人都还健在，在这时陛下即皇帝位，能使天下太平吗？我又知陛下是不能的。像这些诸侯王，虽然名义上是臣子，实际上他们都怀有老百姓那种兄弟关系的想法，大概没有不想采用天子的制度，而把自己当做天子的。他们擅自把爵位赏给别人，赦免死罪，甚至有人乘坐天子的黄屋车。他们不执行汉朝的法令。即使执行了，像厉王那样的不守法的人，命令他都不肯听从，又怎么能招他来呢！幸而召来了，法律怎么能施加到他身上呢！动了一个近亲，天下诸王都环视着惊动起来。陛下的臣子当中即使有冯敬那样勇敢的人，但是他刚开口揭发诸侯王的不法行为，刺客的匕首已经刺进他的胸膛了。陛下虽然贤明，谁能和您一起来治理这些人呢？ 所以说，关系疏远的诸侯王必定危险，关系亲近的诸侯王也一定作乱，这是事实所证明了的。那些自负强大而发动叛乱的异姓诸侯王，汉朝已经侥幸地战胜他们了，可是却没有改变酿成叛乱的制度。同姓诸侯王也袭用了这种做法，发动叛乱，如今已有征兆了，形势又完全恢复到以前那种状态！灾祸的变化，还不知道要转移到何处，英明的皇帝处在这种情况下，尚且不能使国家安宁，后代又将怎么办呢！ 屠牛坦一早晨宰割了十二头牛，而屠刀的锋刃并不变钝，这是因为他所刮剔割剥的，都是顺着肉的肌理下刀。等碰到胯骨、大腿骨的地方，那就不是用砍刀就是用斧头去砍了。仁义恩厚好比是君王的刀刃，权势、法制好比是君王的砍刀、斧头。如今的诸侯王好比是胯骨、大腿骨，如果放弃砍刀、斧头不用，而要用刀刃去碰，我认为刀子不是出缺口就是被折断。为什么仁义恩厚不能用在淮南王、济北王的身上呢？因为形势不容许啊！ 我私下里考察从前的事件，大体上是势力强大的先反：淮阴侯韩信统治着楚，势力最强，就最先反叛；韩王信依靠了匈奴的力量，就又反叛了；贯高借助了赵国的条件，就又反叛了；陈狶部队精锐，也反叛了；彭越凭借梁国，也反叛了；黥布凭借淮南，也反叛了；卢绾势力最弱，最后反叛。长沙王吴芮才有二万五千封户，功劳很少，却保全了下来，权势最小而对汉朝最忠顺；这不只是由于性情和别人不同，也是由于形势使他这样。倘若从前让樊哙、郦商、周勃、灌婴占据几十个城为王，那如今他们由于作恶而亡国，也是可能的。假使让韩信、彭越之流，只居于彻侯的地位，即便今天也还能保全，也是可能的。 既然如此，那么天下大计就可以知道了。要想使天下诸侯王都忠心归附汉朝，那最好让他们都像长沙王一样；要想让臣下不至于像韩信那样被杀掉，那最好让他们像樊哙、郦商那徉；要想使天下安定，最好多多建立诸侯国而使他们的势力减小。力量弱小就容易用道义来指使他们，国土小就不会有反叛的邪念。这样就使全国的形势，如同身体使唤手臂，手臂使唤手指似的，没有不听从指挥的。诸侯王不敢有反叛的想法，如同辐条聚向车轮一样，都归顺天子，即使是老百姓，也会知道他们都很安稳。这样，天下就都知道陛下的英明。分割土地，定出制度：把齐、赵、楚三个王国分成若干侯国，让齐王、赵王、楚王的子孙，全都依次受封先人的那份封地，一直到分尽为止。对燕、梁等其他王国也是这样。有些封地大而子孙少的，也都分成若干侯国，暂时空着搁置起来，等着他们的子孙出生以后，再封他当候。诸侯王的封地，有不少已被削除收归汉朝所有的，那就替他们调整侯国所在的地区，等到要封他的子孙到别的地方去的时候，按候国的应有户数，给以补偿。一寸土、一口人，皇帝也不沾他们的，确实只是为了安定太平罢了。这样，天下就都知道陛下的廉洁。分封土地的制度一旦确定，宗室子孙没有不考虑保住自己的统治的。臣子没有背叛的念头，皇帝没有讨伐的想法。所以天下就都知道陛下的仁德。法令制定了，没有人触犯；政令推行了，没有人抵触。贯高、利几一类的阴谋不会出现，柴奇、开章那样的诡计不会萌生。老百姓都向往良善，大臣都向皇上表示恭顺。所以天下就都知道陛下的道义。这样，即使让幼儿当皇帝，天下也很安定；即使立一个遗腹子作天子，让臣子朝拜老皇帝遗留下来的皇袍，天下也不致于混乱。这样，就可以使天下安定无事，后代也称颂陛下的圣明。只要采取这样的措施，上述五个方面的业绩也就随之而来了，而陛下又怕什么而久久不这样办呢？ 当今，天下的形势像得了严重的浮肿病：小腿粗得差不多像腰围，脚指粗得差不多像大腿。平时都不能伸屈自如，一两个指头抽搐，浑身就觉得无所依赖。丧失了今天的机会而不医治，一定要成为难治的顽症。以后即使有扁鹊那样神医，也都无能为力。这个病还不只是浮肿，还苦于脚掌扭折不能走动。楚元王的儿子，是陛下的叔伯兄弟，当今的楚王，是叔伯兄弟的儿子，齐悼惠王的儿子，是陛下亲哥哥的儿子，当今的齐王是陛下哥哥的孙子。陛下自己的子孙，有的还没有分封土地，以便安定天下，旁支的子孙，倒有人掌握大权来威胁皇帝。所以，我说：不仅是害了浮肿病，还苦于脚掌扭折了不能走动。令人痛哭的就是这样一种病啊！]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>古文</tag>
        <tag>政论文</tag>
        <tag>贾谊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[封建论]]></title>
    <url>%2F2019%2F02%2F10%2F%E5%B0%81%E5%BB%BA%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[参考: 维基百科 介绍 柳宗元（773年－819年11月28日），字子厚，河东（今山西运城）人，唐代著名文学家、思想家，唐宋八大家之一。参加永贞革新失败，被贬为永州司马。为当道者嫉恨，除短暂奉召入京外，终生未再北还。 《封建论》是柳宗元的政论文章，该文详尽分析了唐代以前中国历代政治得失，认为中国封建制度是百害而无一利，并阐发郡县制的优越性。柳宗元被贬柳州（今广西柳州市）之时，引史为证，做“封建论”，结构严谨，文笔犀利而流畅。《封建论》说“彼封建者，更古圣王尧、舜、禹、汤、文、武而莫能去之。盖非不欲去之也，势不可也。……封建，非圣人意也”。 中唐时期，藩镇割据的情况愈演愈烈，当时各地藩镇极力鼓吹要恢复周以前的封建制度，反对中央集权的郡县制度，目的是为自己的割据制造舆论。和这种政治局面相适应，分封制的论调又开始抬头。针对这种情况，作者在永贞革新失败、被贬永州后，写下了这篇议论文。 原文 天地果无初乎？吾不得而知之也。生人果有初乎？吾不得而知之也。然则孰为近？曰有初为近。孰明之？由封建而明之也。彼封建者，更古圣王尧舜、禹汤、文武而莫能去之。盖非不欲去之也，势不可也。势之来（则），其生人之初乎？不初，无以有封建。封建，非圣人意也。 彼其初与万物皆生，草木榛榛，鹿豕狉狉，人不能搏噬，而且无毛羽，莫克自奉自卫。荀卿有言：必将假物以为用者也。夫假物者必争，争而不已，必就其能断曲直者而听命焉。其智而明者，所伏必众；告之以直而不改，必痛之而后畏；由是君长刑政生焉。故近者聚而为群。群之分，其争必大，大而后有兵有德。又有大者，众群之长又就而听命焉，以安其属，于是有诸侯之列。则其争又有大者焉。德又大者，诸侯之列又就而听命焉，以安其封，于是有方伯、连帅之类。则其争又有大者焉。德又大者，方伯、连帅之类又就而听命焉，以安其人，然后天下会于一。是故有里胥而后有县大夫，有县大夫而后有诸侯，有诸侯而后有方伯、连帅，有方伯、连帅而后有天子。自天子至于里胥，其德在人者，死必求其嗣而奉之。故封建非圣人意也，势也。 夫尧舜禹汤之事远矣，及有周而甚详。周有天下，裂土田而瓜分之，设五等，邦群后，布星罗，四周子天下，轮运而辐集。合为朝觐会同，离为守臣捍城。然而降于夷王，害礼伤尊，下堂而迎觐者，历于宣王，挟中兴复古之德，雄南征北伐之威，卒不能定鲁侯之嗣。陵夷迄于幽厉，王室东徙，而目列为诸侯。厥后，问鼎之轻重者有之，射三中肩者有之，代凡伯、诛苌宏者有之，天下乖盭，无君之心。予以为周之丧久矣，徒建空名于公侯之上耳！得非诸侯之盛强，末大不掉之咎欤？遂判为十二，合为七国，威分于陪臣之邦，国殄于后封之秦。则周之败端，其在乎此矣。 秦有天下，裂都会而为之郡邑，废侯卫而为之守宰，据天下之雄图，都六合之上游，摄制四海，运于掌握之内，此其所以为得也。不数载而天下大坏，其有由矣。亟役万人，暴其威刑，竭其货贿。负锄梃谪戍之徒，加圜视而合从，大呼而成群。时则有叛人而无叛吏，人怨于下，而吏畏于上，天下相合，杀守劫令而并起。咎在人怨，非郡邑之制失也。 汉有天下，矫秦之枉，徇周之制，剖海内而立宗子，封功臣。数年之间，奔命扶伤而不暇。困平城，病流矢，陵迟不救者三代。后乃谋臣献画，而离削自守矣。然而封建之始，郡国居半，时则有叛国而无叛郡。秦制之得，亦以明矣。继汉而帝者，虽百代可知也。 唐兴，制州邑，立守宰，此其所以为宜也。然犹桀猾时起，虐害方域者，失不在于州而在于兵，时则有叛将而无叛州。州县之设，固不可革也。 或者曰：「封建者，必私其土，子其人，适其俗，修其理，施化易也。守宰者，苟其心，思迁其秩而已，何能理乎？」予又非之。周之事迹，断可见矣。列侯骄盈，黩货事戎。大凡乱国多，理国寡。侯伯不得变其政，天子不得变其君。私土于人者，百不有一。失在于制，不在于政，周事然也。秦之事迹，亦断可见矣。有理人之制，而不委郡邑是矣；有理人之臣，而不使守宰是矣。郡邑不得正其制，守宰不得行其理，酷刑苦役，而万人侧目。失在于政，不在于制。秦事然也。汉兴，天子之政行于郡，不行于国；制其守宰，不制其侯王。侯王虽乱，不可变也；国人虽病，不可除也。及夫大逆不道，然后掩捕而迁之，勒兵而夷之耳。大逆未彰，奸利浚财，怙势作威，大刻于民者，无如之何。及夫郡邑，可谓理且安矣。何以言之？且汉知孟舒于田叔，得魏尚于冯唐，闻黄霸之明审，睹汲黯之简靖，拜之可也，复其位可也，卧而委之以辑一方可也。有罪得以黜，有能得以奖。朝拜而不道，夕斥之矣；夕受而不法，朝斥之矣。设使汉室尽城邑而侯王之，纵令其乱人，戚之而已。孟舒、魏尚之术，莫得而施；黄霸、汲黯之化，莫得而行。明谴而导之，拜受而退已违矣。下令而削之，缔交合从之谋，周于同列，则相顾裂眦，勃然而起。幸而不起，则削其半。削其半，民犹瘁矣，曷若举而移之，以全其人平？汉事然也。今国家尽制郡邑，连置守宰，其不可变也固矣。善制兵，谨择守，则理平矣。 或者又曰：「夏、商、周、汉封建而延，秦郡邑而促。」尤非所谓知理者也。魏之承汉也，封爵犹建。晋之承魏也，因循不革。而二姓陵替，不闻延祚。今矫而变之，垂二百祀，大业弥固，何系于诸侯哉？ 或者又以为：「殷周圣王也，而不革其制，固不当复议也。」是大不然。夫殷周之不革者，是不得已也。盖以诸侯归殷者三千焉，资以黜夏，汤不得而废；归周老八百焉，资以胜殷，武王不得而易。徇之以为安，仍之以为俗，汤、武之所不得已也。夫不得已，非公之大者也，私其力于己也，私其卫于子孙也。秦之所以革之者，其为制，公之大者也；其情，私也，私其一己之威也，私其尽臣畜于我也。然而公天下之端自秦始。 夫天下之道，理安，斯得人者也。使贤者居上，不肖者居下，而后可以理安。今夫封建者，继世而理。继世而理者，上果贤乎？下果不肖乎？则生人之理乱，未可知也。将欲利其社稷，以一其人之视听，则又有世大夫世食禄邑，以尽其封略。圣贤生于其时，（亦）无以立于天下，封建者为之也。岂圣人之制使至于是乎？吾固曰：「非圣人之意也，势也。」 译文 自然界果真没有原始阶段吗？我没法知道。人类果真有原始阶段吗？我也没法知道。那么，（有或没有原始阶段）哪种说法比较接近事实呢？我认为：有原始阶段这种说法比较接近事实。怎么知道这一点呢？从“封国土、建诸侯”的封建制就可以明白。那种封建制，经历了古代贤明的帝王唐尧、虞舜、夏禹、商汤、周文王和周武王，没有谁能把它废除掉。不是不想把它废除掉，而是事物发展的趋势不允许，这种形势的产生，大概是在人类的原始阶段吧？不是原始阶段的那种形势，就没有可能产生封建制。实行封建制，并不是古代圣人的本意。 人类在他的原始阶段跟万物一起生存，那时野草树木杂乱丛生，野兽成群四处奔走，人不能像禽兽那样抓扑啃咬，而且身上也没有毛羽来抵御严寒，不能够光靠自身来供养自己、保卫自己。荀卿说过：“人类一定要借用外物作为自己求生的工具。”借用外物来求生的必然会相争，争个不停，一定会去找那能判断是非的人而听从他的命令。那又有智慧又明白事理的人，服从他的人一定很多；他把正确的道理告诉那些相争的人，不肯改悔的，必然要惩罚他，使他受痛苦之后感到惧怕，于是君长、刑法、政令就产生了。这样附近的人就聚结成群，分成许多群以后，相互间争斗的规模一定会大，相争的规模大了就会产生军队和威望。这样，又出现了更有威德的人，各个群的首领又去听从他的命令，来安定自己的部属。于是产生了一大批诸侯，他们相争的规模就更大了。又有比诸侯威德更大的人，许多诸侯又去听从他的命令，来安定自己的封国。于是又产生了方伯、连帅一类诸侯领袖，他们相争的规模还要大。这就又出现了比方伯，连帅威德更大的人，方伯、连帅们又去听从他的命令，来安定自己的老百姓，这以后天下便统一于天子一人了。因此先有乡里的长官而后有县的长官，有了县的长官而后有诸侯，有了诸侯而后有方伯、连帅，有了方伯、连帅而后才有天子。从最高的天子到乡里的长官，那些对人民有恩德的人死了，人们一定会尊奉他们的子孙为首领。所以说封建制的产生不是圣人的本意，而是形势发展的必然结果。 尧、舜、禹、汤的事离我们很远了，到了周代记载就很详备了。周朝占有天下，把土地像剖瓜一样分割开来，设立了公、侯、伯、子、男五等爵位，分封了许多诸侯。诸侯国像繁星似地罗列，四面遍布在大地上，集结在周天子的周围，就像车轮围绕着中心运转，就像辐条集中于车毂；诸侯聚合起来就去朝见天子，分散开来就是守卫疆土的臣子、朝廷的捍卫者。但是往下传到周夷王的时候，破坏了礼法，损害了尊严，天子只得亲自下堂去迎接朝见的诸侯。传到周宣王的时候，他虽然倚仗着复兴周王朝的功德，显示出南征北伐的威风，终究还是无力决定鲁君的继承人。这样日渐衰败下去，直到周幽王、周厉王，后来周平王把国都向东迁移到洛邑，把自己排列在诸侯同等地位上去了。从那以后，问周天子传国九鼎的轻重的事情出现了，用箭射伤天子肩膀的事情出现了，讨伐天子大臣凡伯、逼迫天子杀死大夫苌弘这样的事情也出现了，天下大乱，再没有把天子看作天子的了。我认为周王朝丧失统治力量已经很久了，只不过还在公侯之上保存着一个空名罢了！这岂不是诸侯势力太强大而指挥不动，就像尾巴太大以至摇摆不动所造成的过失吗？于是周王朝的统治权分散到十二个诸侯国，后来又合并为七个强国，王朝的权力分散到陪臣掌政的国家，最后被很晚才封为诸侯的秦国灭掉。周朝败亡的原因，大概就在这里了。秦朝统一了全国后，不分诸侯国而设置郡县，废除诸侯而委派郡县长官。秦占据了天下的险要地势，建都于全国的上游，控制着全国，把局势掌握在手里，这是它做得对的地方。但没过几年便天下大乱，那是有原因的。它多次征发数以万计的百姓服役，使刑法越来越残酷，耗尽了财力。于是那些扛着锄木棍被责罚防守边境的人们，彼此递个眼色就联合起来，怒吼着汇合成群，奋起反秦。那时有造反的老百姓而没有反叛的官吏，老百姓在下怨恨秦王朝；官吏在上惧怕朝廷。全国四面八方互相配合，杀郡守劫县令的事情在各地同时发生。错误在于激起了人民的怨恨，并不是郡县制的过失。 汉朝统一了全国之后，纠正秦朝的错误，沿袭周朝的封建制，分割天下，分封自己的子弟和功臣为诸侯王。但没有几年，为了平息诸侯国的叛乱便闻命奔赴镇压，以至连救死扶伤都来不及，汉高祖刘邦被围困在平城，被飞箭射伤，如此衰落不振达三代之久。后来由于谋臣献策，才分散削弱诸侯王的势力并由朝廷命官管理诸侯国。但是汉朝开始恢复封建制的时候，诸侯国和郡县各占一半疆域，那时只有反叛的诸侯国而没有反叛的郡县，秦朝郡县制的正确性也已经明白清楚了。继汉朝而称帝的，就是再过一百代，郡县制比封建制优越，也是可以知道的。 唐朝建立以后，设置州县，任命州县的长官，这是它做得正确的地方。但还是有凶暴狡猾的人不时起来叛乱、侵州夺县的情况出现，过失不在于设置州县而在于藩镇拥有重兵，那时有反叛的藩镇将领而没有反叛的州县长官。郡县制的建立，确实是不能改变的。 有的人说：“封建制的世袭君长，一定会把他管辖的地区当作自己的土地尽心治理，把他管辖的老百姓当作自己的儿女悉心爱护，使那里的风俗变好，把那里的政治治理好，这样施行教化就比较容易。郡县制的州县地方官，抱着得过且过的心理，一心只想升官罢了，怎么能把地方治理好呢？”我认为这种说法也是不对的。 周朝的情况，毫无疑问地可以看清楚了：诸侯骄横，贪财好战，大致是政治混乱的国家多，治理得好的国家少。诸侯的霸主不能改变乱国的政治措施，天子无法撤换不称职的诸侯国的君主，真正爱惜土地爱护人民的诸侯，一百个中间也没有一个。造成这种弊病的原因在于封建制，不在于政治方面。周朝的情况就是如此。 秦朝的情况，也完全可以看清楚了：朝廷有治理百姓的制度，而不让郡县专权，这是正确的；中央有管理政务的大臣，不让地方官自行其是，这也是正确的。但是郡县不能正确发挥郡县制的作用，郡守、县令不能很好地治理人民。残酷的刑罚、繁重的劳役，使万民怨恨。这种过失在于政治方面，不在于郡县制本身。秦朝的情况便是这样。 汉朝建立的时候，天子的政令只能在郡县推行，不能在诸侯国推行；天子只能控制郡县长官，不能控制诸侯王。诸侯王尽管胡作非为，天子也不能撤换他们；侯王国的百姓尽管深受祸害，朝廷却无法解除他们的痛苦。只是等到诸侯王叛乱造反，才把他们逮捕、流放或率兵讨伐、以至灭掉他们。当他们的罪恶尚未充分暴露的时候，尽管他们非法牟利搜刮钱财，依仗权势作威作福，给百姓造成严重的伤害，朝廷也不能对他们怎么样。至于郡县，可以说是政治清明、社会安定了。根据什么这样讲呢？汉文帝从田叔那里了解到孟舒，从冯唐那里了解到魏尚，汉宣帝听说黄霸执法明察审慎，汉武帝看到汲黯为政简约清静，那么就可以任命黄霸做官，可以恢复孟舒、魏尚原来的官职，甚至可以让汲黯躺着任职，委任他只凭威望去安抚一个地区。官吏犯了罪可以罢免，有才干可以奖赏。早上任命的官吏，如果发现他不行正道，晚上就可以撤了他；晚上接受任命的官吏，如果发现他违法乱纪，第二天早上就可以罢免他。假使汉王朝把城邑全部都分割给侯王，即使他们危害人民，也只好对它发愁罢了。孟舒、魏尚的治理方法不能施行，黄霸、汲黯的教化无法推行。如果公开谴责并劝导这些侯王，他们当面接受，但转过身去就违反了；如果下令削减他们的封地，互相串通联合行动的阴谋就会遍及侯王各国之间，那么大家都怒眼圆睁，气势汹汹地反叛朝廷。万一他们不起来闹事，就削减他们的一半封地，即使削减一半，百姓还是受害了，何不把诸侯王完全废除掉来保全那里的人民呢？汉朝的情况就是这样。 今天国家完全实行郡县制，不断地任命郡县长官，这种情况是肯定不能改变了。只要好好地控制军队，慎重地选择地方官吏，那么政局就会安定了。 有人又说：“夏、商、周、汉四代实行封建制，他们统治的时间都很长久，而秦朝实行郡县制，统治的时间却很短。”这更是不懂得治理国家的人说的话。 魏继承汉朝，分封贵族的爵位仍然实行封建制；西晋继承魏，因袭旧制不加改变，但魏和晋都很快就衰亡了，没听说有国运长久的。唐朝纠正魏晋的过失改变了制度，享国已近二百年，国家基业更加巩固，这与分封诸侯又有什么关系呢？ 有人又认为：“治理商、周二代的是圣明的君王啊，他们都没有改变封建制，那么，本来就不应当再议论这件事了。”这种说法大大的不对。 商、周二代没有废除封建制，是不得已的。因为当时归附商朝的诸侯有三千个，商朝靠了他们的力量才灭掉了夏，所以商汤就不能废除他们；归附周朝的诸侯有八百个，周朝凭借他们的力量才战胜了商朝，所以周武王也不能废弃他们。沿用它来求得安定，因袭它来作为习俗，这就是商汤、周武王不得不这样做的原因。他们是不得已的，并不是什么大公无私的美德，而是有私心，是要使诸侯为自己出力，并保卫自己的子孙。秦朝用废除分封诸侯的办法来作为制度，是最大的公；它的动机是为私的，是皇帝想要巩固个人的权威，使天下的人都臣服于自己。但是废除分封，以天下为公，却是从秦朝开始的。 至于天下的常理，是治理得好、政局安定，这才能得到人民的拥护。使贤明的人居上位，不肖的人居下位，然后才会清明安定。封建制的君长，是一代继承一代地统治下去的。这种世袭的统治者，居上位的果真贤明吗？居下位的真的不肖吗？这样，人民究竟是得到太平还是遭遇祸乱，就无法知道了。如果想要对国家有利而统一人民的思想，而同时又有世袭大夫世世代代统治他们的封地，占尽了诸侯国的全部国土，即使有圣人贤人生在那个时代，也会没有立足之地，这种后果就是封建制造成的。难道是圣人的制度要使事情坏到这种地步吗？所以我说：“这不是圣人的本意，而是形势发展的结果。”]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>古文</tag>
        <tag>政论文</tag>
        <tag>柳宗元</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019小计划]]></title>
    <url>%2F2019%2F02%2F10%2F2019%E5%B0%8F%E8%AE%A1%E5%88%92%2F</url>
    <content type="text"><![CDATA[工作 《MySQL文档》 《SaltStack文档》 《TCP/IP》 《Netdata文档》 《Pinpoint文档》 《Prometheus文档》 《Grafana文档》 《GitLab文档》 《Django文档》 个人 《资本论》 《灵飞经小楷》 《经济学原理》 省考: 2-4月 《论美国的民主》 《论法的精神》 《社会契约论》 《新概念英语》 生活 书法学习 修身养性 找寻另一半 是否入手Nokia 9 是否换台笔记本电脑 是否入手罗技G29+ARTG29桌子+GTSport]]></content>
      <categories>
        <category>Zhang</category>
      </categories>
      <tags>
        <tag>2019</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netdata]]></title>
    <url>%2F2019%2F02%2F02%2FNetdata%2F</url>
    <content type="text"><![CDATA[参考: GitHub: https://github.com/netdata/netdata Netdata: https://my-netdata.io/ Docs: https://docs.netdata.cloud/ 环境: EL7x86_64 Netdata v1.12 介绍Netdata 是可用于系统和应用程序的 分布式(distributed)、实时(real-time)、性能(performance)、健康监控(health monitoring) 的高度优化的监控代理开源程序，用于解决性能问题。 Netdata使用高度交互的Web仪表板，实时提供其运行的系统（包括Web服务器，数据库，应用程序）上发生的所有事情的无与伦比的见解(unparalleled insights)。它可以自动运行，无需任何第三方组件，也可以集成到现有的监控工具链中(Prometheus, Graphite, OpenTSDB, Kafka, Grafana…) Why NetdataNetdata采用完全不同的监控方法。Netdata 是一个位于你安装系统上的 monitoring agent。它是: a metrics collector: 收集系统和应用指标 a time-series database: 全部存储在内存中，在运行时不会触及磁盘 a metrics visualizer: 超快速、交互式、现代化，针对异常检测进行了优化 a alarms notification engine: 用于检测性能和可用性问题的高级监控程序 如何工作Netdata 是一个高效，高度模块化的度量管理引擎。其无锁设计使其成为指标并发操作的理想选择。 资料图详情: https://my-netdata.io/infographic.html Netdata 功能特色和体系架构的高级预览。 特性一般来说: 1s granularity: 所有指标的最高分辨率 Unlimited metrics: 收集所有可用的指标，越多越好 1% CPU utilization of a single core: 超级快，优化好 A few MB of RAM: 默认使用25MB Zero disk I/O: 运行时，不会加载和保存任何东西，日志除外 Zero configuration: 自动检测所有内容 Zero maintenance: 你只需运行它，它完成剩余的事情 Zero dependencies: 零依赖，自身便包含了Web服务器 Scales to infinity: 你可在servers, containers, VMs and IoTs 上安装它。默认情况下，度量标准不是集中式的，因此没有限制 Several operating modes: 自主主机监控（默认），无头数据收集器，转发代理，存储和转发代理，中央多主机监控 健康检查和告警: Sophisticated alerting: 自带上百个告警，开箱即用。支持动态阈值，滞后，警报模板，多种基于角色的通知方法 Notifications: 支持多种通知方式 集成: time-series dbs: 可将其指标以相同或更低的方案存档到 graphite, opentsdb, prometheus, json, document DB 监控什么Netdata 数据收集是可扩展的，您可以监控任何可以获得指标的内容。它的 Plugin API 支持所有的编程语言。 为了获得更好的性能，大多数与系统相关的插件都是用C语言编写 (cpu, mem, disk, fs, network…) 为了更快的开发和更轻松的贡献，大多数与应用程序相关的插件都是用python编写 (database, web server…) APM (Application Performance Monitoring): statsd: Netdata是一个功能齐全的statsd server Go expvar: 使用expvar包收集由Go语言编写的应用程序公开的度量标准 Spring Boot: 运行Java Spring Boot，这些应用程序使用Spring Boot库中包含的Spring Boot Actuator来公开其指标 uWSGI: 从uWSGI应用程序收集性能指标 System Resources: CPU Utilization: 总核心和每核心 的CPU使用率 Interrupts: 总核心和每核心 的CPU中断 SoftIRQs: 总核心和每核心 的SoftIRQs SoftNet: 与网络活动相关的总核心和每核心 的SoftIRQ CPU Throttling: 收集每个CPU的CPU限制 CPU Frequency: 收集当前的CPU频率 CPU Idle: 收集每个处理器状态所花费的时间 IdleJitter: 测量CPU延迟 Entropy: 随机数池，在密码学中使用 Interprocess Communication(IPC) Memory: ram: 收集有关RAM使用情况 swap: 收集有关SWAP使用情况 available memory: 收集可用于用户空间进程的RAM量 committed memory : 收集提交给用户空间进程的RAM量 Page Faults: 收集系统页面错误 writeback memory: 收集系统脏内存和回写活动 huge pages: 收集用于大页面的RAM量 KSM: 收集有关内核相同合并的信息 Numa: 在支持它的系统上收集Numa信息 slab: 收集有关Linux内核内存使用情况 Disks: block devices: 每个磁盘：I/O, 操作, 积压, 利用率, 空间… BCACHE: SSD缓存设备的详细性能 DiskSpace: 监视磁盘空间使用情况 mdstat: 软件RAID hddtemp: 磁盘温度 smartd: 磁盘 S.M.A.R.T 值 device mapper: 命名磁盘 Veritas Volume Manager: 命名磁盘 egacli: 适配器，物理驱动器和电池统计信息 adaptec_raid: 逻辑和物理设备健康指标 Filesystems: BTRFS: 详细的磁盘空间分配和使用 Ceph: OSD使用，池使用，对象数… NFS file servers and clients: NFS I/O, cache, read ahead, RPC调用 Samba : SAMBA文件共享的性能指标 ZFS: 详细的性能和资源使用情况 Networking: Network Stack: 关于网络堆栈(IPv4和IPv6的所有协议)和所有网络接口(每个接口: 带宽，数据包，错误，丢弃)的一切 Netfilter: 关于Netfilter连接跟踪器的一切 SynProxy: 收集有关linux SYNPROXY(DDoS)的性能数据 NFacct: 从iptables收集统计的数据 Network QoS: 实时显示网络tc类的工具 FPing: 测量任意数量的主机之间的延迟和数据包丢失 ISC dhcpd: 池利用… AP: 收集Linux访问点性能数据(hostapd) SNMP: 监视SNMP设备 port_check: 检查TCP端口的可用性和响应时间 Virtual Private Networks: OpenVPN: 收集每个隧道的状态 LibreSwan: 收集每个IPSEC隧道的指标 Tor: 收集Tor流量统计信息 Processes: System Processes: running, blocked, forks, active Applications: 分析每个进程组的资源情况 systemd: 使用CGROUPS监视systemd服务 Users: Users and User Groups resource usage: 总结每个用户和用户组资源使用情况 logind: 收集会话，用户和连接 Containers and VMs: Containers: 使用CGROUPS收集各种容器的资源使用情况 libvirt VMs: 使用CGROUPS收集各种VM的资源使用情况 dockerd: 收集docker健康指标 Web Servers: Apache and lighttpd: mod-status和日志统计信息 IPFS: 带宽，对等连接 LiteSpeed: 读取litespeed rtreport文件以收集指标 Nginx: stub-status Nginx+: 连接到多个nginx_plus服务器以收集实时性能指标 PHP-FPM: 多个实例，每个实例报告连接、请求、性能… Tomcat: 访问、线程、空闲内存、卷… web server access.log files: 实时提取，Web服务器和代理性能指标，并应用多个运行状况检查… HTTP check: 检查一个或多个Web服务器以获取HTTP状态代码和返回的内容 Proxies, Balancers, Accelerators: HAproxy: 带宽，会话，后端… Squid: 每个服务器显示，客户端带宽和请求、服务器带宽和请求 Traefik: 连接到多个traefik实例以收集API指标 Varnish: 线程，会话，命中，对象，后端… IPVS: 从Linux IPVS负载均衡器收集指标 Database Servers: CouchDB: I/O，请求方法，状态代码，任务，副本，每个数据库… MemCached: 带宽，连接，项目… MongoDB: 操作，客户端，事务，游标，连接，断言，锁… MySQL and mariadb: 带宽，查询率，锁，问题，tmp操作，连接，binlog指标，线程，innodb指标… PostgreSQL: 连接，元组读取/写入/返回，事务，锁定，后端进程，索引，表，预写，后台编写器… Proxy SQL: 收集后端和前端性能指标 Redis: 操作，命中率，内存，键，客户端，从库 RethinkDB: 连接到多个rethinkdb服务器以收集实时指标 Message Brokers: beanstalkd: 全局/每个 tube 监控 RabbitMQ: 性能和健康指标 Search and Indexing: ElasticSearch: 搜索和索引的性能、延迟、计时、集群统计、线程统计… DNS Servers: bind_rndc: 解析 named.stats 转储文件以收集实时性能指标 dnsdist: 性能和健康指标 ISC Bind (named): 客户端，请求，查询，更新，失败和每个视图指标 NSD: 查询，区域，协议，查询类型，传输… PowerDNS: 查询，回答，缓存，延迟… unbound: 性能和资源使用指标 dns_query_time: DNS查询时间统计信息 Time Servers: chrony: 频率，最后偏移，RMS偏移，残余频率，根延迟，根分散，偏斜，系统时间 ntpd: 收集统计信息 Mail Servers: Dovecot: POP3/IMAP 服务器 Exim: 消息队列(电子邮件排队) Postfix: 消息队列(条目，大小) Hardware Sensors: IPMI: 企业硬件传感器和事件 lm-sensors: 温度，电压，风扇，功率，湿度… Nvidia: 收集Nvidia GPU的信息 RPi: Raspberry Pi温度传感器 w1sensor: 从连接的1-Wire传感器收集数据 UPSes: apcupsd: 负载，充电，电池电压，温度，效用指标，输出指标 NUT: 负载，充电，电池电压，温度，效用指标，输出指标 Linux Power Supply: 收集Linux上电源驱动程序报告的指标 Social Sharing Servers: RetroShare: 连接到多个retroshare服务器以收集实时性能指标 Security: Fail2Ban: 监视fail2ban日志文件以检查所有活动jail的所有禁令 Authentication, Authorization, Accounting (AAA, RADIUS, LDAP) Servers: FreeRadius: 使用radclient命令提供freeradius统计信息（身份验证，账户统计，代理身份验证，代理统计） Telephony Servers: opensips: 连接到opensips服务器（仅限localhost）以收集实时性能指标 Household Appliances: SMA webbox: 连接到多个远程SMA网箱，以收集光伏（太阳能）发电的实时性能指标 Fronius: 连接到多个远程Fronius Symo服务器，以收集光伏（太阳能）发电的实时性能指标 StiebelEltron: 使用他们的互联网服务网关（ISG网站）从Stiebel Eltron加热系统收集温度和其他指标 Game Servers: SpigotMC: 使用Minecraft远程控制台监控Spigot Minecraft服务器每秒的滴答数和在线玩家数量 Distributed Computing: BOINC: 使用远程GUI RPC接口监视本地和远程BOINC客户端软件的任务状态。还为少数错误情况提供警报 Media Streaming Servers: IceCast: 收集活动源的侦听器数量 Monitoring Systems: Monit: 收集有关监控目标（文件系统，应用程序，网络）的指标 安全设计 匿名统计 安装]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Monitoring</tag>
        <tag>Performance</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenLDAP]]></title>
    <url>%2F2019%2F01%2F18%2FOpenLDAP%2F</url>
    <content type="text"><![CDATA[参考: LDAP维基百科: https://zh.wikipedia.org/wiki/LDAP OpenLDAP维基百科: https://zh.wikipedia.org/wiki/OpenLDAP x.500维基百科: https://zh.wikipedia.org/wiki/X.500 OpenLDAP文档: http://www.openldap.org/doc/ 环境: RHEL7.x86_64 LDAP v2.4.44 概述 LDAPLDAP(轻型目录访问协议, Lightweight Directory Access Protocol）是一个开放的、中立的、工业标准的应用协议，通过IP协议提供访问控制和维护分布式信息的目录信息。LDAP基于X.500标准的子集。因为这个关系，LDAP有时被称为X.500-lite。LDAP在TCP/IP之上定义了一个相对简单的升级和搜索目录的协议。 LDAP目录与普通数据库的主要不同之处在于数据的组织方式，它是一种有层次的、树形结构。所有条目的属性的定义是对象类object class的组成部分，并组成在一起构成schema；那些在组织内代表个人的schema被命名为white pages schema。数据库内的每个条目都与若干对象类联系，而这些对象类决定了一个属性是否为可选和它保存哪些类型的信息。 LDAP目录的条目（entry）由属性（attribute）的一个聚集组成，并由一个唯一性的名字引用，即专有名称（distinguished name，DN）。 DN: Distinguished Name CN: Common Name OU: Domain Component LDAP组织数据方式: 12345 dc=org |dc=wikipedia / \ou=people ou=groups LDAP主要的应用场景是查询多而修改极少，那就充分发挥LDAP的优势了。因为没有事务处理，那数据库的速度可是比不上。 还有LDAP能存储海量的数据，还可以轻松地在各个系统之间复制，可用性超高。 目录是一个为查询、浏览和搜索而优化的专业分布式数据库，它呈树状结构组织数据，就好象Linux/Unix系统中的文件目录一样。目录数据库和关系数据库不同，它有优异的读性能，但写性能差，并且没有事务处理、回滚等复杂功能，不适于存储修改频繁的数据。所以目录天生是用来查询的，就好象它的名字一样。 OpenLDAPOpenLDAP是轻型目录访问协议（Lightweight Directory Access Protocol，LDAP）的自由和开源的实现，在其OpenLDAP许可证下发行，并已经被包含在众多流行的Linux发行版中。 OpenLDAP主要包括下述4个部分： slapd: 独立LDAP守护服务 slurpd: 独立的LDAP更新复制守护服务 实现LDAP协议的库 工具软件和示例客户端 Why OpenLDAP账号是登录系统的唯一入口。要登录系统，首先系统要存在登录所使用的账号（/etc/passwd）及密码信息（/etc/shadow），然后经过系统查找顺序（/etc/nsswith.conf）及认证模块（/etc/pam.d/*）验证，得到授权后方可登录系统。如果多个用户登录系统，就需要在每个系统上创建用户名和密码；否则，就无法登录系统。 对于账号管理人员而言，维护10 台、100 台机器的账号，或许勉强可以维护、管理。如果机器数量达到1000 以上时，对于账号的创建、回收、权限的分配、密码策略、账号安全审计等一系列操作，账号管理人员就心有余而力不足了。此时OpenLDAP 账号集中管理软件就应用而生，它可以实现账号集中维护、管理，只需要将被管理的机器加入到服务器端即可，此后所有与账号相关的策略均在服务端实现，从而解决了运维案例所产生的众多管理问题。 关于账号的添加、删除、修改、权限的赋予等一系列操作只需要在服务端操作即可，无须在客户端机器进行单独操作。客户端账号及密码均通过OpenLDAP 服务器进行验证，从而实现账号集中认证管理，此时账号管理员只须维护OpenLDAP 服务器条目即可。 OpenLDAP目录服务Introduction to OpenLDAP Directory Services 本节介绍如何构建，配置和操作OpenLDAP软件以提供目录服务。这包括有关如何配置和运行standalone LDAP daemon——slapd的详细信息。它适用于系统管理员。本节提供目录服务的基本介绍，特别是slapd提供的目录服务。本简介提供足够的信息，以便您可以开始学习LDAP，X.500和目录服务。 目录服务是什么目录是专门用于搜索(search)和浏览(browse)的专用数据库，另外还支持基本查找(lookup)和更新(update)功能。 目录往往包含描述性的，基于属性的信息，并支持复杂的过滤功能。目录通常不支持在为处理大量复杂更新而设计的数据库管理系统中发现的复杂事务或回滚方案。如果允许，目录更新通常是简单的全有或全无更改。目录通常用于快速响应高容量查找或搜索操作。他们可能具有广泛复制信息的能力，以提高可用性和可靠性，同时缩短响应时间。复制目录信息时，只要及时解决不一致问题，副本之间的临时不一致就可以了。 有许多不同的方法来提供目录服务。不同的方法允许将不同类型的信息存储在目录中，对如何引用，查询和更新信息。一些目录服务是本地的，向受限制的上下文提供服务；其它服务是全球性的，为更广泛的环境提供服务。全局服务通常是分布式的，这意味着它们包含的数据分布在许多机器上，所有机器都协作提供目录服务。通常，全局服务定义统一命名空间(namespace)，无论您在何处与数据本身相关，都可以提供相同的数据视图。 LDAP是什么LDAP(Lightweight Directory Access Protocol, 轻型目录访问协议)，顾名思义，它是一种用于访问目录服务的轻量级协议，特别是基于X.500的目录服务。LDAP通过TCP / IP或其他面向连接的传输服务运行。 哪些种类的信息可以存储在目录中？DAP信息模型基于条目(entry)。条目是具有全局唯一可分辨名称（DN）的属性(attributes)集合。DN用于明确指代Entry，每个条目的属性都有一个类型(type)和一个或多个值(value)。 12345678#这些类型通常是助记符字符串cnmail#值的语法取决于属性类型cn: ldap-testmail: example@test.com 信息是如何安排的？在LDAP中，目录条目以分层树状结构(tree-like structure)排列。传统上，这种结构反映了地理/组织边界。表示国家/地区的条目显示在树的顶部。下面是代表各州和国家组织的条目。再下面可能是表示组织单位，人员，打印机，文档或您可以想到的任何其他内容的条目。 传统命名: 还可以基于因特网域名来安排树。这种命名方法正变得越来越流行，因为它允许使用DNS定位目录服务。 基于域名命名: 此外，LDAP允许您通过使用名为对象类(objectClass)的特殊属性来控制条目中所需和允许的属性。它的值确定条目必须遵守的模式规则。 如何引用信息？条目由其可分辨名称(DN)引用，该名称通过获取条目本身的名称来构造(称为Relative Distinguished Name, RDN)，并连接其祖先条目的名称。 如何保护信息免受未经授权的访问？某些目录服务不提供保护，允许任何人查看信息。LDAP为客户端提供了一种机制，用于对目录服务器进行身份验证或证明其身份。LDAP还支持数据安全性（完整性和机密性）服务。 什么时候应该使用LDAP通常，当您需要通过基于标准的方法集中管理、存储、访问数据时，应使用目录服务器。总是有新的方法来使用目录并应用LDAP原则来解决某些问题，因此这个问题没有简单的答案。 一些常见的栗子： 机器认证: Machine Authentication 用户认证: User Authentication 用户/系统组: User/System Groups 地址簿: Address book 组织代表: Organization Representation 资产追踪: Asset Tracking 电话信息存储: Telephony Information Store 用户资源管理: User resource management 电子邮件查找: E-mail address lookups 应用配置存储: Application Configuration store PBX Configuration store … LDAP如何工作LDAP使用C-S模式。一个或多个LDAP服务器包含组成目录信息树（DIT，directory information tree）的数据。客户端连接到服务器并发出请求。服务端响应客户端的请求。无论客户端连接到哪个LDAP服务器，它都会看到相同的目录视图，这是全局目录服务的一个重要特性。 关于x.500X.500是计算机目录服务的标准系列。X.500协议包括: DAP (Directory Access Protocol) DSP (Directory System Protocol) DISP (Directory Information Shadowing Protocol) DOP (Directory Operational Bindings Management Protocol) LDAP (Lightweight Directory Access Protocol) 从技术上讲，LDAP是X.500目录服务的目录访问协议。DAP是一种重量级协议，可在完整的OSI协议栈上运行，并且需要大量的计算资源。LDAP旨在通过TCP/IP进行操作，并以更低的成本提供DAP的大部分功能。 虽然LDAP仍然用于通过网关访问X.500目录服务，但现在更常见的是在X.500服务器中直接实现LDAP。 可以将 standalone LDAP daemon(slapd) 视为轻量级X.500目录服务器。也就是说，它没有实现X.500的DAP，也不支持完整的X.500模型。 LDAP与RDBMS最常见的问题是——为什么OpenLDAP不使用 RDBMS(关系数据库管理系统) 而是使用像 LMDB 那样的嵌入式键/值存储？总的来说，期望商业级 RDBMS 实现的复杂算法可以使 OpenLDAP更 快或更好，并且同时允许与其他应用程序共享数据。 简而言之，使用嵌入式数据库和自定义索引系统，OpenLDAP可以在不损失可靠性的情况下提供更高的性能和可扩展性。所以OpenLDAP使用 LMDB 并发/事务 数据库软件。 下面是一个详细而冗长的答案: &lt;&gt; 很有可能认为在目录中使用RDBMS后端可以解决所有问题。但是，它是一头猪。这是因为数据模型非常不同。使用关系数据库表示目录数据将需要将数据拆分为多个表。现在最大的问题是从一个条目访问数据需要在不同的磁盘区域上进行搜索。在某些应用程序中，这可能没问题但在许多应用程序中性能会受到影响。 slapdslapd是OpenLDAP的守护进程， 在许多不同平台上运行的LDAP目录服务器。 slapd有一些有趣的功能和特性: LDAPv3: slapd实现轻量级目录访问协议的第3版，slapd支持IPv4和IPv6以及Unix IPC上的LDAP。 Simple Authentication and Security Layer: slapd通过使用SASL支持强身份验证和数据安全性（完整性和机密性）服务 Transport Layer Security: slapd通过使用 TLS/SSL 持基于证书的身份验证和数据安全性（完整性和机密性）服务 Topology control: slapd可以配置为根据网络拓扑信息限制 socket 层的访问，基于 TCP wrapper Access control: slapd提供了丰富而强大的访问控制功能，允许您控制对数据库中信息的访问 Internationalization: slapd支持Unicode 和 Language tag Choice of database backends: slapd附带了各种不同的数据库后端，您可以从中选择 Multiple database instances: slapd可以配置为同时为多个数据库提供服务。这意味着单个slapd服务器可以使用相同或不同的数据库后端响应LDAP树的许多逻辑上不同部分的请求 Generic modules API: 如果您需要更多自定义，slapd可让您轻松编写自己的模块 Threads: slapd具有高性能的线程 Replication: slapd可以配置为维护目录信息的集群副本 Proxy Cache: slapd可以配置为缓存LDAP代理服务 Configuration: slapd可通过单个配置文件进行高度配置，允许您更改您想要更改的所有内容 快速入门A Quick-Start Guide 注意：本快速入门指南不使用强身份验证，也不使用任何完整性或机密保护服务。这些服务在OpenLDAP的其它章节中进行了描述。 以下包括OpenLDAP v2.4软件的快速入门指南。 获取软件 打开发行包 审阅文档 运行configure 构建软件 测试构建 安装软件 编辑配置文件 导入配置数据库 启动SLAPD 添加初始化条目到目录 查看是否正常运行 配置选择The Big Picture - Configuration Choices 本节简要概述了各种LDAP目录配置。 本地目录服务Local Directory Service 在此配置中，您运行 slapd 实例，该实例仅为您的本地域提供目录服务。它不以任何方式与其他目录服务器进行交互。 带推荐的本地目录服务Local Directory Service with Referrals 在此配置中，运行 slapd 实例，该实例为本地域提供目录服务，并将其配置为将引用返回到能够处理请求的其它服务器。 如果要提供本地服务并参与全局目录，或者要将下级条目的责任委派给其他服务器，请使用此配置。 副本目录服务Replicated Directory Service slapd 包括对基于LDAP Sync 的复制的支持，称为syncrepl。可用于在多个目录服务器上维护目录信息的副本。在其最基本的配置中，master 是 syncrepl provider，slavee 是 syncrepl consumer。集群和提供了可靠性和可用性。 分布式目录服务Distributed Local Directory Service 在此配置中，本地服务被划分为较小的服务，每个服务都可以被复制，并与上级和下级引用粘合在一起。 安装Building and Installing OpenLDAP Software 本章详细介绍了如何构建和安装OpenLDAP软件包。 源码安装官方文档中是使用源码进行构建和安装。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#提取软件gunzip -c openldap-VERSION.tgz | tar xf -cd openldap-VERSION#依赖软件#请参考REAME，安装它所需的依赖软件#Transport Layer Security#Simple Authentication and Security Layer#Kerberos Authentication Service#Database Software#Threads#TCP Wrappers#configure./configure --help./configure --enable-wrappers \ CPPFLAGS="-I/usr/local/include" \ LDFLAGS="-L/usr/local/lib -Wl,-rpath,/usr/local/lib"#构建软件make dependmake#测试make test#安装#如果未指定安装位置，默认安装到 /usr/local#通常，安装需要超级用户权限sudo make install#配置文件/usr/local/etc/openldap 包安装因为在base源里面可直接搜索到openldap软件包，所以就是用软件包进行安装。 RPM包： 123456789101112131415161718192021222324252627#查看yum search openldapopenldap.x86_64 : LDAP support librariesopenldap-devel.x86_64 : LDAP development libraries and header filesopenldap-servers.x86_64 : LDAP serveropenldap-clients.x86_64 : LDAP client utilitiesopenldap-servers-sql.x86_64 : SQL support module for OpenLDAP servercompat-openldap.x86_64 : OpenLDAP compatibility shared librariescollectd-openldap.x86_64 : OpenLDAP plugin for collectdnss-pam-ldapd.x86_64 : An nsswitch module which uses directory servers#安装yum install -y openldap.x86_64 openldap-servers.x86_64 openldap-clients.x86_64#yum install -y collectd-openldap.x86_64 openldap-servers-sql.x86_64 compat-openldap.x86_64 openldap-devel.x86_64 nss-pam-ldapd.x86_64#验证rpm -qa | grep openldap#配置文件/etc/openldap 配置Configuring slapd 安装完毕后，你就可以配置并使用它。 本章介绍 slapd-config 配置系统的一般格式。OpenLDAP v2.3及更高版本已转换为使用动态运行配置引擎slapd-config: 完全启用LDAP 使用标准LDAP操作进行管理 将其配置数据存储在LDIF数据库中(openldap/slap.d/) 允许所有slapd的配置选项在运行中进行更改，通常无需重新启动服务器即可使更改生效 注意：虽然 slapd-config 统将其配置存储为（基于文本的）LDIF文件，但您不应直接编辑任何LDIF文件。配置更改应通过LDAP操作执行，如 ldapadd, ldapdelete, ldapmodify 配置的布局Configuration Layout slapd配置存储为具有预定义模式和DIT的特殊LDAP目录。有特定的objectClasses用于承载全局配置选项，模式定义，后端和数据库定义以及各种其它项。 栗子配置树: slapd-config 配置树具有非常特定的结构。树的根名为 cn=config 并包含全局配置设置。其他设置包含在单独的子条目中： Dynamically loaded modules Schema definitions Backend-specific configuration Database-specific configuration LDIF文件的常用规则适用于配置信息: #表示注释 如果一行以单个空格开头，则将其视为前一行的延续（即使前一行是注释），并删除单个前导空格。条目由空行分隔 配置LDIF的一般布局如下： 12345678910111213141516171819202122232425262728293031323334#globalconfigurationsettingsdn:cn=configobjectClass:olcGlobalcn:config&lt;globalconfigsettings&gt;#schemadefinitionsdn:cn=schema,cn=configobjectClass:olcSchemaConfigcn:schema&lt;systemschema&gt;dn:cn=&#123;X&#125;core,cn=schema,cn=configobjectClass:olcSchemaConfigcn:&#123;X&#125;core&lt;coreschema&gt;#additionaluser-specifiedschema...#backenddefinitionsdn:olcBackend=&lt;typeA&gt;,cn=configobjectClass:olcBackendConfigolcBackend:&lt;typeA&gt;&lt;backend-specificsettings&gt;#databasedefinitionsdn:olcDatabase=&#123;X&#125;&lt;typeA&gt;,cn=configobjectClass:olcDatabaseConfigolcDatabase:&#123;X&#125;&lt;typeA&gt;&lt;database-specificsettings&gt;#subsequentdefinitionsandsettings... 配置指令Configuration Directives 本节详细介绍了常用的配置指令 cn=config本条目中包含的指令通常适用于整个服务器。其中大多数是系统或面向连接，而不是数据库相关。条目必须具有 olcGlobal 对象类(objectClass) 123456789101112131415161718192021222324252627282930313233343536373839404142#指定强制关闭空闲客户端连接之前等待的秒数#默认值为0，表示禁用此功能olcIdleTimeout: &lt;integer&gt;#该指令指定syslog（当前记录到syslogd）的调试语句和操作统计信息的级别。您必须已配置OpenLDAP --enable-debug（默认值）才能使用olcLogLevel: &lt;level&gt;#Debugging LevelsLevel Keyword Description-1 any enable all debugging0 no debugging1 (0x1 trace) trace function calls2 (0x2 packets) debug packet handling4 (0x4 args) heavy trace debugging8 (0x8 conns) connection management16 (0x10 BER) print out packets sent and received32 (0x20 filter) search filter processing64 (0x40 config) configuration processing128 (0x80 ACL) access control list processing256 (0x100 stats) stats log connections/operations/results512 (0x200 stats2) stats log entries sent1024 (0x400 shell) print communication with shell backends2048 (0x800 parse) print entry parsing debugging16384 (0x4000 sync) syncrepl consumer processing32768 (0x8000 none) only messages that get logged whatever log level is set#指定当slapd无法找到本地数据库来处理请求时要传回的引用olcReferral &lt;URI&gt;#栗子条目dn: cn=configobjectClass: olcGlobalcn: configolcIdleTimeout: 30olcLogLevel: StatsolcReferral: ldap://root.openldap.org cn=module如果在配置slapd时启用了对动态加载模块的支持，则可以使用 cn=module 条目来指定要加载的模块集。 12345678910111213141516171819202122#指定要加载的可动态加载模块的名称olcModuleLoad: &lt;filename&gt;#指定要搜索可加载模块的目录列表olcModulePath: &lt;pathspec&gt;#栗子dn: cn=module&#123;0&#125;,cn=configobjectClass: olcModuleListcn: module&#123;0&#125;olcModuleLoad: /usr/local/lib/smbk5pwd.ladn: cn=module&#123;1&#125;,cn=configobjectClass: olcModuleListcn: module&#123;1&#125;olcModulePath: /usr/local/lib:/usr/local/lib/slapdolcModuleLoad: accesslog.laolcModuleLoad: pcache.la cn=schema此条目包含在 slapd 中硬编码的所有模式定义。因此，此条目中的值由slapd生成，因此配置文件中不需要提供 schema value。仍必须定义该条目，以作为用户定义的模式添加到下面的基础。schema entry 必须具有 olcSchemaConfig 的对象类 (objectClass)。 1234567891011121314151617181920212223242526#定义了一个属性类型olcAttributeTypes: &lt;RFC4512 Attribute Type Description&gt;#定义一个对象类olcObjectClasses: &lt;RFC4512 Object Class Description&gt;#栗子条目dn: cn=schema,cn=configobjectClass: olcSchemaConfigcn: schemadn: cn=test,cn=schema,cn=configobjectClass: olcSchemaConfigcn: testolcAttributeTypes: ( 1.1.1 NAME &apos;testAttr&apos; EQUALITY integerMatch SYNTAX 1.3.6.1.4.1.1466.115.121.1.27 )olcAttributeTypes: ( 1.1.2 NAME &apos;testTwo&apos; EQUALITY caseIgnoreMatch SUBSTR caseIgnoreSubstringsMatch SYNTAX 1.3.6.1.4.1.1466.115.121.1.44 )olcObjectClasses: ( 1.1.3 NAME &apos;testObject&apos; MAY ( testAttr $ testTwo ) AUXILIARY ) Backend-specific Directives后端指令适用于所有相同类型的数据库实例，并且可能会被数据库指令覆盖，具体取决于指令。后端条目必须具有 olcBackendConfig 的对象类 (objectClass)。 1234567891011121314151617181920212223242526#命名特定于后端的配置条目olcBackend: &lt;type&gt;#Database BackendsTypes Descriptionbdb Berkeley DB transactional backend (deprecated)config Slapd configuration backenddnssrv DNS SRV backendhdb Hierarchical variant of bdb backend (deprecated)ldap Lightweight Directory Access Protocol (Proxy) backendldif Lightweight Data Interchange Format backendmdb Memory-Mapped DB backendmeta Meta Directory backendmonitor Monitor backendpasswd Provides read-only access to passwd(5)perl Perl Programmable backendshell Shell (extern program) backendsql SQL Programmable backend#栗子dn: olcBackend=bdb,cn=configobjectClass: olcBackendConfigolcBackend: bdb Database-specific Directives每种类型的数据库都支持本节中的指令。数据库条目必须含有 olcDatabaseConfig 对象类 (objectClass)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#命名特定的数据库实例#可以提供数字&#123;&lt;index&gt;&#125;以区分相同类型的多个数据库olcDatabase: [&#123;&lt;index&gt;&#125;]&lt;type&gt;#权限指令#如果未指定，默认使用 to * by * readolcAccess: to &lt;what&gt; [ by &lt;who&gt; [&lt;accesslevel&gt;] [&lt;control&gt;] ]+#将数据库置于“只读”模式olcReadonly &#123; TRUE | FALSE &#125;#指定不受此访问控制的DN或对此数据库的操作的管理限制#DN不需要引用此数据库中的条目，甚至不需要引用目录中的条目。olcRootDN: &lt;DN&gt;#用于为root dn 指定DN的密码olcRootPW: &lt;password&gt;#指定从搜索操作返回的最大条目数olcSizeLimit: &lt;integer&gt;#定将传递给此后端数据库的查询的DN后缀olcSuffix: &lt;dn suffix&gt;#将当前 slapd 建立为运行 syncrepl 复制引擎的复制使用者站点，将当前数据库指定为主内容的副本olcSyncrepl#指定slapd将用于回答搜索请求的最大秒数olcTimeLimit: &lt;integer&gt;#该指令仅适用于slave slapdolcUpdateref: &lt;URL&gt;#栗子条目dn: olcDatabase=frontend,cn=configobjectClass: olcDatabaseConfigobjectClass: olcFrontendConfigolcDatabase: frontendolcReadOnly: FALSEdn: olcDatabase=config,cn=configobjectClass: olcDatabaseConfigolcDatabase: configolcRootDN: cn=Manager,dc=example,dc=com BDB and HDB Database Directives此类别中的指令适用于BDB和HDB数据库。除了上面定义的通用数据库指令之外，它们还用在 olcDatabase 条目中。除了olcDatabaseConfig 对象类之外，BDB和HDB数据库条目还必须分别具有 olcBdbConfig 和 olcHdbConfig 对象类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#指定包含数据库和相关索引的BDB文件所在的目录olcDbDirectory: &lt;directory&gt;#指定BDB后端数据库实例维护的内存高速缓存条目的大小olcDbCachesize: &lt;integer&gt;#指定检查BDB事务日志的频率，检查点操作将数据库缓冲区刷新到磁盘，并在日志中写入检查点记录olcDbCheckpoint: &lt;kbyte&gt; &lt;min&gt;#指定要放置在数据库目录的DB_CONFIG文件中的配置指令olcDbConfig: &lt;DB_CONFIG setting&gt;#此选项会导致磁盘上的数据库内容在更改时不会立即与内存更改同步olcDbNosync: &#123; TRUE | FALSE &#125;#在索引槽中指定内存中索引缓存的大小。默认值为零olcDbIDLcacheSize: &lt;integer&gt;#指定要为给定属性维护的索引olcDbIndex: &#123;&lt;attrlist&gt; | default&#125; [pres,eq,approx,sub,none]#如果此设置为TRUE，则slapindex将一次索引一个属性。默认设置为FALSE，在这种情况下，条目的所有索引属性将同时处理olcDbLinearIndex: &#123; TRUE | FALSE &#125;#指定新创建的数据库索引文件应具有的文件保护模式olcDbMode: &#123; &lt;octal&gt; | &lt;symbolic&gt; &#125;#指定用于搜索过滤器评估的堆栈深度olcDbSearchStack: &lt;integer&gt;#为共享内存BDB环境指定 key 。默认情况下，BDB环境使用内存映射文件。如果指定了非零值，则它将用作标识将容纳环境的共享内存区域的键olcDbShmKey: &lt;integer&gt;#栗子条目dn: olcDatabase=hdb,cn=configobjectClass: olcDatabaseConfigobjectClass: olcHdbConfigolcDatabase: hdbolcSuffix: &quot;dc=example,dc=com&quot;olcDbDirectory: /usr/local/var/openldap-dataolcDbCacheSize: 1000olcDbCheckpoint: 1024 10olcDbConfig: set_cachesize 0 10485760 0olcDbConfig: set_lg_bsize 2097152olcDbConfig: set_lg_dir /var/tmp/bdb-logolcDbConfig: set_flags DB_LOG_AUTOREMOVEolcDbIDLcacheSize: 3000olcDbIndex: objectClass eq slapd配置文件The slapd Configuration File 本章介绍如何通过 slapd.conf 配置文件来配置 slapd。 slapd.conf 已被弃用，建议使用前面介绍的 slapd-config进行配置。 由于已经被弃用，所以此处我跳过。 文档: http://www.openldap.org/doc/admin24/slapdconfig.html 运行slapdslapd 旨在作为独立服务运行。这允许服务器利用缓存，管理底层数据库的并发问题，并节省系统资源。 由于我使用RPM包进行安装，所以可利用 systemd 进行OpenLDAP的管理。 ldap默认监听地址: URL Protocol Transport ldap:/// LDAP TCP port 389 ldaps:/// LDAP over SSL TCP port 636 ldapi:/// LDAP IPC (Unix-domain socket) slapd方式1234567891011#查看帮助#man slapdslapd --help#启动slapd --option#停止kill -INT `cat /usr/local/var/slapd.pid` systemd方式12345678910systemctl status slapdsystemctl start slapd#ps -ef | grep slapd#/usr/sbin/slapd -u ldap -h ldapi:/// ldap:///systemctl stop slapd 访问控制]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>LDAP</tag>
        <tag>Permission</tag>
        <tag>权限管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenVPN]]></title>
    <url>%2F2019%2F01%2F16%2FOpenVPN%2F</url>
    <content type="text"><![CDATA[参考: OpenVPN: https://github.com/OpenVPN/openvpn easy-rsa: https://github.com/OpenVPN/easy-rsa 环境: RHEL7 OpenVPN v2.4.6 easy-rsa v3.0.3 概述通过在云端VPC， k8s集群内运行OpenVPN Server，让本地可以通过连接OpenVPN进行访问云资源，而不需要将云资源开放公网访问。 我是将OpenVPN运行在k8s 集群了，对它提供ELB进行公网连接。在S端配置文件中推送对应的路由信息——如集群内节点CIDR， 服务CIDR, VPC CIDR… 安装和配置 安装需要安装: EPEL openvpn easy-rsa: 用于制作CA证书，S端证书，C端证书 安装了EPEL源之后就可以直接安装openvpn和easy-rsa，当然也可以从GitHub上拉取。 123yum install -y epel-releaseyum install -y openvpn easy-rsa 制作证书 编辑vars文件此处需注意，通过yum安装可能会没有example.vars这个栗子文件。没关系，请在easy-rsa GitHub去下载一份过来。 123456789101112131415161718192021222324mkdir -p /etc/openvpn/easy-rsa/servermkdir -p /etc/openvpn/easy-rsa/client#拷贝easy-rsa文件，用于制作证书cp -r /usr/share/easy-rsa/3.0.3/ /etc/openvpn/easy-rsa/server/cp -r /usr/share/easy-rsa/3.0.3/ /etc/openvpn/easy-rsa/client/#先制作CA和S端证书cd /etc/openvpn/easy-rsa/server/cp vars.example vars#修改几个配置vim vars#根据自己的情况进行修改set_var EASYRSA_REQ_COUNTRY “CN” #国家set_var EASYRSA_REQ_PROVINCE “Sichuan” #省份set_var EASYRSA_REQ_CITY “ChengDu” #城市set_var EASYRSA_REQ_ORG “TianFu” #非盈利组织，此处可填公司之类set_var EASYRSA_REQ_EMAIL “abc@xyz.com” #邮箱地址set_var EASYRSA_REQ_OU “My OpenVPN” #组织单元 创建证书和秘钥 CA证书和S端证书 123456789101112131415161718192021222324252627282930313233343536373839cd /etc/openvpn/easy-rsa/server./easyrsa -h#初始化，会读取vars文件./easyrsa init-pki#创建根证书#这里会要求输入PEM pass，这个请记住，后面签名需要此密码./easyrsa build-ca#这里生成CA证书#pki/ca.crt#创建S端证书#nopass选项表示不加密./easyrsa gen-req server nopass#这里生成两个文件#pki/reqs/server.req#pki/private/server.key#签约S端证书#第一个server表示S端，后面是取的名字./easyrsa sign server server#这里需要输入CA证书的PEM pass#之后会生成S端证书#pki/issued/server.crt#创建Diffie-Hellman./easyrsa gen-dh#生成dh.pem文件#pki/dh.pem C端证书 12345678910111213141516171819202122232425262728293031cd /etc/openvpn/easy-rsa/client/#./easyrsa -h#初始化./easyrsa init-pki#创建C端证书./easyrsa gen-req client nopass#这里生成两个文件#pki/reqs/client.req#pki/private/client.key#在CA端导入C端证书cd /etc/openvpn/easy-rsa/server./easy-rsa import-req /etc/openvpn/easy-rsa/client/reqs/client.req client#签约C端证书#第一个client表示C端，第二个为定义的名字./easyrsa sign client client#这里需要输入CA证书的PEM pass#之后会生成C端证书#/etc/openvpn/easy-rsa/server/pki/issued/client.crt#注意生成的位置，不要搞错了 梳理上面生成的文件 1234567891011121314server/pki/ca.crtserver/pki/dh.pemserver/pki/reqs/server.reqserver/pki/reqs/client.reqserver/pki/private/ca.keyserver/pki/private/server.keyserver/pki/issued/server.crtserver/pki/issued/client.crt#client/pki/reqs/client.reqclient/pki/private/client.key 拷贝相应证书到openvpn目录下123456789101112131415#S端cd /etc/openvpn/servercp /etc/openvpn/easy-rsa/server/pki/ca.crt .cp /etc/openvpn/easy-rsa/server/pki/private/server.key .cp /etc/openvpn/easy-rsa/server/pki/issued/server.crt .cp /etc/openvpn/easy-rsa/server/pki/dh.pem .#C端cd /etc/openvpn/clientcp /etc/openvpn/easy-rsa/server/pki/ca.crt .cp /etc/openvpn/easy-rsa/client/pki/private/client.key .cp /etc/openvpn/easy-rsa/server/pki/issued/client.crt . 配置文件在openvpn GitHub去下载对应配置文件，做相应的修改。 S端配置文件一下只是我的栗子，详细信息请参考自己的项目。具体的每个选项描述，栗子文件里面有解释。 vim server.conf: 123456789101112131415161718192021222324252627282930313233343536373839404142port 1194proto udpdev tunca /etc/openvpn/server/ca.crtcert /etc/openvpn/server/server.crtkey /etc/openvpn/server/server.keydh /etc/openvpn/server/dh.pem#VPN CIDRserver 10.8.0.0 255.255.255.0ifconfig-pool-persist ipp.txt#推送的S端的CIDR给C端路由push &quot;route 10.0.0.0 255.255.224.0&quot;#推送S端DNSpush &quot;dhcp-option DNS 10.247.3.10&quot;push &quot;dhcp-option DNS 114.114.114.114&quot;client-to-clientkeepalive 20 120cipher AES-256-CBCpersist-keypersist-tunlog /dev/stdoutlog-append /dev/stdoutverb 3explicit-exit-notify 1#启用用户/密码进行登录需要添加的选项#栗子文件里面没有这些信息script-security 3auth-user-pass-verify /etc/openvpn/checkpsw.sh via-env#http://openvpn.se/files/other/checkpsw.sh#去下载这个脚本#client-cert-not-required#此选项只使用用户密码，不使用证书#注释它，使用证书和用户密码双重登录username-as-common-name C端配置文件vim client.ovpn: 12345678910111213141516171819202122232425262728293031323334353637383940414243clientdev tunproto udpremote addr portresolv-retry infinitenobindpersist-keypersist-tun#此处我将CA证书和C端证书信息写入配置文件#当然，也可下载证书在指定，但这麻烦了&lt;ca&gt;-----BEGIN CERTIFICATE-----xxxxxxxxxxx-----END CERTIFICATE-----&lt;/ca&gt;&lt;cert&gt;-----BEGIN CERTIFICATE-----xxxxxxxxxxxxxxxxx-----END CERTIFICATE-----&lt;/cert&gt;&lt;key&gt;-----BEGIN PRIVATE KEY-----xxxxxxxxxxxxxxxx-----END PRIVATE KEY-----&lt;/key&gt;remote-cert-tls servercipher AES-256-CBCverb 3#用户认证script-security 3auth-user-pass#可将用户信息写入文件，用户密码各一行 另外几个配置vi checksw.sh: 12345678910111213141516171819202122232425262728293031323334#!/bin/sh############################################################ checkpsw.sh (C) 2004 Mathias Sundman &lt;mathias@openvpn.se&gt;## This script will authenticate OpenVPN users against# a plain text file. The passfile should simply contain# one row per user with the username first followed by# one or more space(s) or tab(s) and then the password. PASSFILE="/etc/openvpn/psw-file"LOG_FILE="/etc/openvpn/openvpn-password.log"TIME_STAMP=`date "+%Y-%m-%d %T"` ########################################################### if [ ! -r "$&#123;PASSFILE&#125;" ]; then echo "$&#123;TIME_STAMP&#125;: Could not open password file \"$&#123;PASSFILE&#125;\" for reading." &gt;&gt; $&#123;LOG_FILE&#125; exit 1fi CORRECT_PASSWORD=`awk '!/^;/&amp;&amp;!/^#/&amp;&amp;$1=="'$&#123;username&#125;'"&#123;print $2;exit&#125;' $&#123;PASSFILE&#125;` if [ "$&#123;CORRECT_PASSWORD&#125;" = "" ]; then echo "$&#123;TIME_STAMP&#125;: User does not exist: username=\"$&#123;username&#125;\", password=\"$&#123;password&#125;\"." &gt;&gt; $&#123;LOG_FILE&#125; exit 1fi if [ "$&#123;password&#125;" = "$&#123;CORRECT_PASSWORD&#125;" ]; then echo "$&#123;TIME_STAMP&#125;: Successful authentication: username=\"$&#123;username&#125;\"." &gt;&gt; $&#123;LOG_FILE&#125; exit 0fi echo "$&#123;TIME_STAMP&#125;: Incorrect password: username=\"$&#123;username&#125;\", password=\"$&#123;password&#125;\"." &gt;&gt; $&#123;LOG_FILE&#125;exit 1 vi psw-file: 这为可登录的用户密码 直接往这个文件写入用户和密码即可，并不需要重启openvpn服务。 1234user1 pass-user1#commentuser2 pass-user2 vi start_openvpn.sh: 启动脚本 12345678910111213141516171819#!/bin/bashmkdir -p /dev/netif [ ! -c /dev/net/tun ]; then mknod /dev/net/tun c 10 200fiecho 'net.ipv4.ip_forward=1' &gt;&gt; /etc/sysctl.conf &amp;&amp; sysctl -p#此处一定要记得写iptables，否则后面连上了VPN也无法正常访问#我也是找了好久才找到这个问题#这个网段为openvpn里面定义的网段iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -j MASQUERADEcd /etc/openvpn#--daemon，放入后台/sbin/openvpn --config /etc/openvpn/server/server.conf 由于我是运行在k8s集群容器内，所有还有几个文件: Dockerfile .dockerignore k8s.yaml: 由于它需要创建和使用系统资源，所以请使用特权容器运行 启动 启动S端 客户端连接 Windows客户端 Linux客户端 Mac客户端 启动之后应该就能正常访问了，如果不能正常访问，请查看你推送的CIDR和DNS，还有ipv4转发和iptables等。 1234567891011121314#S端#由于需要使用和创建系统资源，所以请用特权容器进行运行，不然会提示没有权限/sbin/openvpn --config /etc/openvpn/server/server.conf#C端#Windows下载Openvpn GUI，制定客户端配置文件进行连接，之后输入用户名和面膜#Linux下#/sbin/openvpn --config /etc/openvpn/client/client.ovpn#Mac下，下载对应Openvpn软件，指定配置文件进行连接]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>OpenVPN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apollo]]></title>
    <url>%2F2019%2F01%2F09%2FApollo%2F</url>
    <content type="text"><![CDATA[参考: Apollo官方文档: https://github.com/ctripcorp/apollo/wiki 环境: Apollo v1.2 Docker v1.18 K8s v1.11 概述基本上按照官方文档都没什么问题，说几点我在配置过程中容易出错的地方。 总的来说就是一个portal，多个config+admin，而Eruea注册的Meta Server是和config在一起的，每个环境的admin注册到对应环境的Meta Server(config)。 我是将其放入k8s集群中运行，所以针对官方给出的Dockerfile和k8s.yaml文件做了对应的修改。 看一下我画的架构图和官方架构图: 我自己画的一个Apollo项目架构图： 注意事项 为不同环境创建不同数据库 官方已经给出了创建数据库的sql语句，一个portadb, 多个configdb-project-env。我们需要修改数据库名，为不同的环境建立不同的数据库，所以需要在使用官方sql的时候把数据库名修改为自定义的即可，这样创建的各个环境数据库的表结构都是一样的。 配置了一个环境变量，它也就是部署服务的集群内访问地址(不在同一VPC可能需要外部访问地址) 官方是写入了Dockerfile里面作为环境变量，我是将其写入k8s yaml中的环境变量。当然，也可以写入启动脚本中。以下配置，随便用哪一个。 1234567891011121314#Dockerfile中ENV APOLLO_CONFIG_SERVICE_NAME="&#123;service-name&#125;.&#123;namespace&#125;.svc.cluster.local"#k8s yaml container中 env: - name: APOLLO_CONFIG_SERVICE_NAME value: &#123;service_name&#125;.&#123;namespace&#125;.svc.cluster.local#启动脚本#scripts/startup-kubernetes.sh#SERVER_URL="http://$&#123;APOLLO_ADMIN_SERVICE_NAME&#125;:$&#123;SERVER_PORT&#125;"SERVER_URL="http://&#123;service_name&#125;.&#123;namespace&#125;.svc.cluster.local:$&#123;SERVER_PORT&#125;" 将数据库和注册地址写入config/application-github.properties配置文件 官方是写入Dockerfile中作为环境变量，然后通过entrypoint.sh进行相应的替换。我直接将其写入此配置文件，并删除entrypoint.sh。 12345678spring.datasource.url = jdbc:mysql://&#123;mysql-ip&#125;:&#123;mysql-port&#125;/&#123;mysql-db&#125;?characterEncoding=utf8spring.datasource.username = userspring.datasource.password = passwdeureka.service.url = http://&#123;service-name&#125;.&#123;namespace&#125;.svc.cluster.local:8080/eureka/# 如果环境跨VPC，还需要指定公网地址的 HomePageUrl# eureka.instance.homePageUrl = http://ELB:PORT# 或 在启动命名指定: -Dapollo.configService=http://config-service的公网IP:端口来跳过meta service的服务发现# 如果不指定的话，则默认使用获取的内部地址，这无法正常访问 portal服务的默认环境是DEV，请注意 如果配置的第一个环境并不是DEV，请记得先修改数据库中的这个值，不然portal读取config, admin会失败。portaldb.serverconfig的apollo.portal.envs这个key，多个环境使用,分割，后面可以在UI上配置。其它环境请修改为其它环境名。 1UPDATE serverconfig SET Value='uat' WHERE Key='apollo.portal.envs'; 12345678910config/apollo-env.properties#dev.meta=http://DEV_META_SERVICE_NAME:8080#fat.meta=http://TEST_ALPHA_META_SERVICE_NAME:8080#uat.meta=http://TEST_BETA_META_SERVICE_NAME:8080#pro.meta=http://PROD_META_SERVICE_NAME:8080#某个环境的configuat.meta=http://&#123;service-name&#125;.&#123;namespace&#125;.svc.cluster.local:8080 将日志输出到标准输出/dev/stdout 由于我是运行在容器中，所以需要将日志输出到标准输出。 登录Web UI后可修改配置 如组织里面的部门名，管理员等等参数，在系统参数里面更新Key对应的Value。具体这个Key可参考文档 —— 调整服务端配置 每个环境下有多个config/admin 请注意，每个环境只有一个数据库，也就是这几个服务都要连接同一个configdb，这点请注意。后面还需要修改ConfigDB.ServerConfig表，每个环境的都需要单独配置。这里的eureka.service.url - Eureka服务Url要来修改。 ps: 官方文档不管是apollo-configservice还是apollo-adminservice都需要向eureka服务注册，所以需要配置eureka服务地址。 按照目前的实现，apollo-configservice本身就是一个eureka服务，所以只需要填入apollo-configservice的地址即可，如有多个，用逗号分隔（注意不要忘了/eureka/后缀）。需要注意的是每个环境只填入自己环境的eureka服务地址，比如FAT的apollo-configservice是1.1.1.1:8080和2.2.2.2:8080，UAT的apollo-configservice是3.3.3.3:8080和4.4.4.4:8080，PRO的apollo-configservice是5.5.5.5:8080和6.6.6.6:8080，那么：在FAT环境的ApolloConfigDB.ServerConfig表中设置eureka.service.url为：http://1.1.1.1:8080/eureka/,http://2.2.2.2:8080/eureka/在UAT环境的ApolloConfigDB.ServerConfig表中设置eureka.service.url为：http://3.3.3.3:8080/eureka/,http://4.4.4.4:8080/eureka/在PRO环境的ApolloConfigDB.ServerConfig表中设置eureka.service.url为：http://5.5.5.5:8080/eureka/,http://6.6.6.6:8080/eureka/ 更过详情请查看官方文档！ 假如UAT环境下有: config-cd, config-bj, config-gz admin-cd, admin-bj, admin-gz 他们需要向这三个Eureka(cd, bj, gz)注册。 之后查看config:8080地址，便可以看到这几个地址的信息；在Portal集群信息里面，也可看到有三个CONFIG，三个ADMIN。 栗子具体信息可以查看官方文档，然后根据官方文档给出的栗子做一些修改。 apollo-config12345678910111213141516ls -lapollo-configservice.confapollo-configservice.jarconfig/Dockerfilek8s-apollo-config-web-test.yamlREADME.mdscripts/ls config/application-github.propertiesapp.propertiesls scripts/startup-kubernetes.sh Dockerfile 12345678910111213141516FROM openjdk:8-jre-alpine3.8RUN \ echo &quot;http://mirrors.aliyun.com/alpine/v3.8/main&quot; &gt; /etc/apk/repositories &amp;&amp; \ echo &quot;http://mirrors.aliyun.com/alpine/v3.8/community&quot; &gt;&gt; /etc/apk/repositories &amp;&amp; \ apk update upgrade &amp;&amp; \ apk add --no-cache procps curl bash tzdata &amp;&amp; \ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; \ echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone &amp;&amp; \ mkdir -p /apollo-config-serverCOPY . /apollo-config-server/EXPOSE 8080CMD [&quot;/apollo-config-server/scripts/startup-kubernetes.sh&quot;] config/ 12345678910# app.properties不用修改# application-github.properties# DataSourcespring.datasource.url = jdbc:mysql://host:port/configdbwebtest?characterEncoding=utf8spring.datasource.username = userspring.datasource.password = passwdeureka.service.url = http://xxx.svc.cluster.local:8080/eureka/# 扩公网的话请修改 HomePageUrl# config-web-test service homepage ELB# eureka.instance.homePageUrl = http://ELB:PORT scripts/ startup-kubernetes.sh 这个文件，文件名你也可以随便修改。有些值既可以写在这里面，也可以配置成环境变量(Dockerfile， 或k8s yaml)这里把 APOLLO_CONFIG_SERVICE_NAME 配置成 k8s yaml 里的环境变量 xxx.apollo-test.svc.cluster.local（即 k8s service）。 12345678910111213141516171819202122232425262728293031323334353637#!/bin/bashSERVICE_NAME=apollo-configservice## Adjust log dir if necessaryLOG_DIR=/opt/logs/apollo-config-server## Adjust server port if necessarySERVER_PORT=8080SERVER_URL="http://$&#123;APOLLO_CONFIG_SERVICE_NAME&#125;:$&#123;SERVER_PORT&#125;"## Adjust memory settings if necessary#export JAVA_OPTS="-Xms6144m -Xmx6144m -Xss256k -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=384m -XX:NewSize=4096m -XX:MaxNewSize=4096m -XX:SurvivorRatio=8"## Only uncomment the following when you are using server jvm#export JAVA_OPTS="$JAVA_OPTS -server -XX:-ReduceInitialCardMarks"########### The following is the same for configservice, adminservice, portal ###########export JAVA_OPTS="$JAVA_OPTS -XX:+UseParNewGC -XX:ParallelGCThreads=4 -XX:MaxTenuringThreshold=9 -XX:+UseConcMarkSweepGC -XX:+DisableExplicitGC -XX:+UseCMSInitiatingOccupancyOnly -XX:+ScavengeBeforeFullGC -XX:+UseCMSCompactAtFullCollection -XX:+CMSParallelRemarkEnabled -XX:CMSFullGCsBeforeCompaction=9 -XX:CMSInitiatingOccupancyFraction=60 -XX:+CMSClassUnloadingEnabled -XX:SoftRefLRUPolicyMSPerMB=0 -XX:+CMSPermGenSweepingEnabled -XX:CMSInitiatingPermOccupancyFraction=70 -XX:+ExplicitGCInvokesConcurrent -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationConcurrentTime -XX:+PrintHeapAtGC -XX:+UseGCLogFileRotation -XX:+HeapDumpOnOutOfMemoryError -XX:-OmitStackTraceInFastThrow -Duser.timezone=Asia/Shanghai -Dclient.encoding.override=UTF-8 -Dfile.encoding=UTF-8 -Djava.security.egd=file:/dev/./urandom"export JAVA_OPTS="$JAVA_OPTS -Dserver.port=$SERVER_PORT -Dlogging.file=$LOG_DIR/$SERVICE_NAME.log -Xloggc:$LOG_DIR/gc.log -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=5M -XX:HeapDumpPath=$LOG_DIR/HeapDumpOnOutOfMemoryError/"#logs to /std/out#export JAVA_OPTS="$JAVA_OPTS -Dserver.port=$SERVER_PORT"printf "$(date) ==== Starting ==== \n"cd `dirname $0`/..chmod 755 $SERVICE_NAME".jar"./$SERVICE_NAME".jar" startrc=$?;if [[ $rc != 0 ]];then echo "$(date) Failed to start $SERVICE_NAME.jar, return code: $rc" exit $rc;fitail -f /dev/null apollo-configservice.conf 这个也不需要做什么修改，看个人情况。 123MODE=servicePID_FOLDER=.LOG_FOLDER=/opt/logs/apollo-config-server apollo-admin这个其实和 apollo-config 差不多配置，只是修改一些配置项。 apollo-portal这个也和上面差不多，只是修改一些配置项。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Apollo</tag>
        <tag>分布式</tag>
        <tag>配置中心</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[税收与债务]]></title>
    <url>%2F2019%2F01%2F01%2F%E6%94%BF%E5%BA%9C%E6%94%B6%E5%85%A5%E4%B8%8E%E5%80%BA%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[参考: 财政部 国家统计局 最近观《雍正王朝》、《李卫当官》，对政府收入和政务债务想做一个了解，故此收集整理相关资料。 财政 财政收入 中央政府财政收入 地方政府财政收入 财政支出 中央政府财政支出 地方政府财政支出 外债 外债负载率 外债债务率 外债偿债率 财政收入指国家财政参与社会产品分配所取得的收入，是实现国家职能的财力保证。主要包括： 税收收入： 下设增值税等21款。包括国内增值税、国内消费税、进口货物增值税和消费税、出口货物退增值税和消费税、营业税、企业所得税、个人所得税、资源税、城市维护建设税、房产税、印花税、城镇土地使用税、土地增值税、车船税、船舶吨税、车辆购置税、关税、耕地占用税、契税、烟叶税等。 社会保险基金收入： 下设基本养老保险基金收入等6款。 非税收入：下设政府性基金收入等7款。包括专项收入、行政事业性收费、罚没收入和其他收入。 贷款转贷回收本金收入： 下设国内贷款回收本金收入等4款。 债务收入： 分设国内债务收入、国外债务收入2款。 转移性收入： 分设返还性收入等10款。 国资收入 财政收入按现行分税制财政体制划分为中央本级收入和地方本级收入。 中央财政收入属于中央财政的收入包括关税，进口货物增值税和消费税，出口货物退增值税和消费税，消费税，铁道部门、各银行总行、各保险公司总公司等集中交纳的营业税和城市维护建设税，增值税75%部分，纳入共享范围的企业所得税60%部分，未纳入共享范围的中央企业所得税、中央企业上交的利润，个人所得税60%部分，车辆购置税，船舶吨税，证券交易印花税97%部分，海洋石油资源税，中央非税收入等。 地方财政收入属于地方财政的收入包括营业税（不含铁道部门、各银行总行、各保险公司总公司集中交纳的营业税），地方企业上交利润，城市维护建设税（不含铁道部门、各银行总行、各保险公司总公司集中交纳的部分），房产税，城镇土地使用税，土地增值税，车船税，耕地占用税，契税，烟叶税，印花税，增值税25%部分，纳入共享范围的企业所得税40%部分，个人所得税40%部分，证券交易印花税3%部分，海洋石油资源税以外的其他资源税，地方非税收入等。 财政支出指国家财政将筹集起来的资金进行分配使用，以满足经济建设和各项事业的需要。 主要包括：一般公共服务、外交、国防、公共安全、教育、科学技术、文化体育与传媒、社会保障和就业、医疗卫生、环境保护、城乡社区事务、农林水事务、交通运输、资源勘探电力信息等事务、商业服务等事务、金融监管支出、国土气象等事务、住房保障支出、粮油物资储备管理等事务、国债付息支出等方面的支出。 财政支出根据政府在经济和社会活动中的不同职权，划分为中央财政支出和地方财政支出。 中央财政支出中央财政支出包括一般公共服务，外交支出，国防支出，公共安全支出，以及中央政府调整国民经济结构、协调地区发展、实施宏观调控的支出等。 地方财政支出地方财政支出包括一般公共服务，公共安全支出，地方统筹的各项社会事业支出等。 外债外债（或对外债务）（英语：external debt或foreign debt）是一个国家所拥有的、债权人为外国的债务。债务人可以是政府、企业或私人。债权人可以是私人商业银行、其他政府或国际金融机构。 外债负债率指外债余额与当年国内生产总值之比。 外债债务率指外债余额 外债偿债率指偿还外债本息与当年贸易和非贸易外汇收入（国际收支口径）之比。 债务政府债务（亦称公债）是指政府在国内外发行的债券或向外国政府和银行借款所形成的政府债务。具体是指政府凭借其信誉，政府作为债务人与债权人之间按照有偿原则发生信用关系来筹集财政资金的一种信用方式，也是政府调度社会资金，弥补财政赤字，并借以调控经济运行的一种特殊分配方式。政府债务是整个社会债务的重要组成部分。 政府债务（Government debt）分为中央政府债务和地方政府债务。中央政府债务即国债，是中央政府为筹集财政资金而举借的一种债务。除中央政府举债之外，不少国家有财政收入的地方政府及地方公共机构也举借债务，即地方政府债务。由于中国地方政府尚不能举债，因此中国的政府债务即为国债。 按偿还期限划分： 可分为短期、中期和长期公债。按发行地域划分： 可分为内债和外债。按发行的方式： 可分为强制公债和自愿公债。]]></content>
      <categories>
        <category>Economics</category>
      </categories>
      <tags>
        <tag>经济</tag>
        <tag>财政</tag>
        <tag>税收</tag>
        <tag>债务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Helm]]></title>
    <url>%2F2018%2F12%2F25%2FHelm%2F</url>
    <content type="text"><![CDATA[环境： EL7x86_64 参考： HELM文档: https://docs.helm.sh/ 概述Helm是Kubernetes生态系统中的一个软件包管理工具，主要用来管理Charts，有点类似于Ubuntu中的apt或CentOS中的yum。由go编写，是Deis公司发起的一个开源工具，有助于简化部署和管理Kubernetes应用。在Kubernetes中，应用管理是需求最多、挑战最大的领域。Helm项目提供了一个统一软件打包方式，支持版本控制，可以大大简化Kubernetes应用分发与部署中的复杂性。 Helm Chart是用来封装 Kubernetes 原生应用程序的一系列 YAML 文件。可以在你部署应用的时候自定义应用程序的一些 Metadata，以便于应用程序的分发。对于应用发布者而言，可以通过 Helm 打包应用、管理应用依赖关系、管理应用版本并发布应用到软件仓库。对于使用者而言，使用 Helm 后不用需要编写复杂的应用部署文件，可以以简单的方式在 Kubernetes 上查找、安装、升级、回滚、卸载应用程序。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Helm</tag>
        <tag>K8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[存储方案]]></title>
    <url>%2F2018%2F12%2F10%2F%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[参考: 维基百科 Google 存储方案分类： DAS(Direct-Attached Storage)，直连式存储 NAS(Network Attached Storage)，网络附加存储 SAN(Storage Area Network)，存储区域网络 NAS和SAN既竞争又合作，很多高端NAS的后端存储就是SAN。NAS和SAN的整合也是存储设备的发展趋势。SAN提供的存储单位是LUN，属于block级别的。经过NAS创建成文件系统后，就变成文件级别的了。 NAS和SAN最本质的区别就是文件管理系统在哪里。 DAS直连式存储是指直接和计算机相连接的数据储存方式。像固态硬盘、机械硬盘、光盘驱动器与计算机直接相连的设备都是属于直连式存储设备。实际上，直连式存储的名称是后来为了区别于存储区域网络（SAN）和网络附加储存（NAS）而添加的。 缺点： 服务器本身容易成为系统瓶颈; 服务器发生故障，数据不可访问; 对于存在多个服务器的系统来说，设备分散，不便管理。同时多台服务器使用DAS时，存储空间不能在服务器之间动态分配，可能造成相当的资源浪费; 数据备份操作复杂。 NAS网络附加存储是一种专门的数据存储技术的名称，它可以直接连接在计算机网络上面，对异质网络用户提供了集中式数据访问服务。实际上就是网络文件服务器。NAS设备也提供了不止一种文件传输协议。NAS系统通常有一个以上的硬盘，而且和传统的文件服务器一样，通常会把它们组成RAID来提供服务。NAS设备直接连接到TCP/IP网络上，网络服务器通过TCP/IP网络存取管理数据。有了NAS以后，网络上的其他服务器就可以不必再兼任文件服务器的功能。 NAS是以文件为单位的通信协议，例如像是NFS（在UNIX系统上很常见）或是SMB（常用于Windows系统）。 缺点： 由于存储数据通过普通数据网络传输，因此易受网络上其它流量的影响。当网络上有其它大数据流量时会严重影响系统性能; 由于存储数据通过普通数据网络传输，因此容易产生数据泄漏等安全问题; 存储只能以文件方式访问，而不能像普通文件系统一样直接访问物理数据块，因此会在某些情况下严重影响系统效率，比如大型数据库就不能使用NAS. SAN存储区域网络是一种连接外接存储设备和服务器的架构。人们采用包括光纤通道技术(FC)、磁盘阵列(RAID)、磁带柜、光盘柜的各种技术进行实现。该架构的特点是，连接到服务器的存储设备，将被操作系统视为直接连接的存储设备。SAN实际是一种专门为存储建立的独立于TCP/IP网络之外的专用网络。SAN由于其基础是一个专用网络，因此扩展性很强，不管是在一个SAN系统中增加一定的存储空间还是增加几台使用存储空间的服务器都非常方便。 SAN是以区块为单位的通信协议，通常是透过SCSI再转为光纤通道或是iSCSI。还有其他各种不同的SAN通信协议。 缺点： 价格昂贵。不论是SAN阵列柜还是SAN必须的光纤通道交换机价格都是十分昂贵的，就连服务器上使用的光通道卡的价格也是不容易被小型商业企业所接受的; 需要单独建立光纤网络，异地扩展比较困难。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云计算]]></title>
    <url>%2F2018%2F12%2F07%2F%E4%BA%91%E8%AE%A1%E7%AE%97%2F</url>
    <content type="text"><![CDATA[参考： 维基百科 概述云计算（cloud computing），是一种基于互联网的计算方式，通过这种方式，共享的软硬件资源和信息可以按需求提供给计算机各种终端和其他设备。 用户不再需要了解“云”中基础设施的细节，不必具有相应的专业知识，也无需直接进行控制云计算描述了一种基于互联网的新的IT服务增加、使用和交付模式，通常涉及通过互联网来提供动态易扩展而且经常是虚拟化的资源。 三种模式美国国家标准和技术研究院的云计算定义中明确了三种服务模式： 基础环境即服务(IaaS, Infrastructure as a Service)消费者使用“基础计算资源”，如处理能力、存储空间、网络组件或中间件。消费者能掌控操作系统、存储空间、已部署的应用程序及网络组件（如防火墙、负载平衡器等），但并不掌控云基础架构。例如：Amazon AWS、Rackspace。 平台即服务(PaaS, Platform as a Service)消费者使用主机操作应用程序。消费者掌控运作应用程序的环境（也拥有主机部分掌控权），但并不掌控操作系统、硬件或运作的网络基础架构。平台通常是应用程序基础架构。例如：Google App Engine。 软件即服务(SaaS, Software as a Service)消费者使用应用程序，但并不掌控操作系统、硬件或运作的网络基础架构。是一种服务观念的基础，软件服务供应商，以租赁的概念提供客户服务，而非购买，比较常见的模式是提供一组账号密码。例如：Microsoft CRM与Salesforce.com。 部署模型美国国家标准和技术研究院的云计算定义中也涉及了关于云计算的部署模型: 公有云（Public Cloud）简而言之，公用云服务可透过网络及第三方服务供应者，开放给客户使用，“公用”一词并不一定代表“免费”，但也可能代表免费或相当廉价，公用云并不表示用户数据可供任何人查看，公用云供应者通常会对用户实施使用访问控制机制，公用云作为解决方案，既有弹性，又具备成本效益。 私有云（Private Cloud）私有云具备许多公用云环境的优点，例如弹性、适合提供服务，两者差别在于私有云服务中，数据与程序皆在组织内管理，且与公用云服务不同，不会受到网络带宽、安全疑虑、法规限制影响；此外，私有云服务让供应者及用户更能掌控云基础架构、改善安全与弹性，因为用户与网络都受到特殊限制。 社群云（Community Cloud）社群云由众多利益相仿的组织掌控及使用，例如特定安全要求、共同宗旨等。社群成员共同使用云数据及应用程序。 混合云（Hybrid Cloud）混合云结合公用云及私有云，这个模式中，用户通常将非企业关键信息外包，并在公用云上处理，但同时掌控企业关键服务及数据。 云技术 KVM XEN VMWare OpenStack(IaaS, 私有云) OpenShift(Paas) Docker Kubernetes Ansible Chef Puppet Salt]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>云服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitLab]]></title>
    <url>%2F2018%2F12%2F06%2FGitLab%2F</url>
    <content type="text"><![CDATA[参考: 维基百科 GitLab文档: https://docs.gitlab.com/ 版本: GitLib-CE: v11.6.0 GitLab-Runner: v11.6.0 GitLab是由GitLab Inc.开发，使用MIT许可证的基于网络的Git仓库管理工具。包括Git仓库管理、代码审查、问题跟踪、动态订阅、wiki等功能.以及GitLab内部集成的GitLab CI 更是一个持续集成和交付的好工具。 它有两个版本： CE EE UserUser docs AdminAdministrator documentation 安装和维护Installing and maintaining GitLab 安装Installation GitLab有多种方式进行安装。 依赖(requirements) 在安装之前，请先查看相关依赖文档。 依赖: https://docs.gitlab.com/ce/install/requirements.html 操作系统 Ruby版本 硬件 CPU Memory Storage 数据库 Unicorn WorkersUnicorn是多进程的Server容器。可以增加unicorn worker的数量，这通常有助于减少应用程序的响应时间并提高处理并行请求的能力。对于大多数情况，我们建议使用:CPU cores + 1 = unicorn workers 123456vi /etc/gitlab/gitlab.rb#CPU Cores=2unicorn['worker_processes'] = 3unicorn['worker_timeout'] = 60 Redis and SidekiqRedis存储所有用户会话和后台任务队列。Redis的存储要求很低，每个用户约25kB。Sidekiq是多线程的异步处理程序，使用多线程进程处理后台作业。 此过程从整个Rails Stack(200MB+)开始，如果存在内存泄漏，它可能会随着时间的推移而增长。 在非常活跃的服务器上（10,000+活动用户），Sidekiq进程可能使用1GB +内存。 GitLab Runner我们强烈不要在计划安装GitLab的同一台机器上安装GitLab Runner。根据您决定配置GitLab Runner的方式以及用于在CI环境中运行应用程序的工具，GitLab Runner可能会占用大量可用内存。如果您决定在同一台机器上运行GitLab Runner和GitLab Rails应用程序，则上面提供的内存消耗计算将无效。由于安全原因，将所有内容安装在一台计算机上也是不安全的——特别是当您计划将shell执行程序与GitLab Runner一起使用时。如果您打算使用CI功能，我们建议为每个GitLab Runner使用单独的计算机。 Prometheus and its exporters从Omnibus GitLab 9.0开始，Prometheus及其相关的exporter默认启用，一遍轻松、深入地监控GitLab。这些进程大概消耗200MB内存。 支持的浏览器 安装方式(Installation methods) Omnibus包: https://about.gitlab.com/install/ 源码 Docker 数据库(Database) PostgreSQL (highly recommended) MySQL/MariaDB (strongly discouraged, not all GitLab features are supported, no support for MySQL/MariaDB GTID) As of GitLab 10.0, PostgreSQL 9.6 or newer is required, and earlier versions are not supported. Users using PostgreSQL must ensure the pg_trgm extension is loaded into every GitLab database. This extension can be enabled (using a PostgreSQL super user) by running the following query for every database: 1CREATE EXTENSION pg_trgm; 在其它系统上，你可能需要安装附加包(e.g. postgresql-contrib)才能使得扩展可用。 如果你需要使用GitLab Geo，则需要postgres_fdw扩展： 1CREATE EXTENSION postgres_fdw; 包安装Centos7为栗子 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#安装依赖Ruby#因为需要v2.3版本，而yum查找出来的为v2.0，所以不使用yum安装#yum info ruby.x86_64#这里使用Ruby管理工具RVM（“Ruby Version Manager”）进行安装gpg --keyserver hkp://keys.gnupg.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB#开发版\curl -sSL https://get.rvm.io | bash#安装稳定版\curl -sSL https://get.rvm.io | bash -s stable --ruby#To start using RVM you need to run source ~/.rvm/scripts/rvmsource ~/.rvm/scripts/rvm#可把它写入profilevim /etc/profilesource ~/.rvm/scripts/rvmsource /etc/profile#查看rvm list known#安装ruby2.3rvm install 2.3ruby --versionruby 2.3.7p456 (2018-03-28 revision 63024) [x86_64-linux]#使用2.3rvm use 2.3#设为默认rvm use 2.3 --default#Install and configure the necessary dependenciessudo yum install -y curl policycoreutils-python openssh-serversudo systemctl enable sshdsudo systemctl start sshdsudo firewall-cmd --permanent --add-service=httpsudo systemctl reload firewalld#install Postfix to send notification emailssudo yum install postfixsudo systemctl enable postfixsudo systemctl start postfix#Add the GitLab package repository and install the packagecurl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bashsudo EXTERNAL_URL="http://gitlab.example.com" yum install -y gitlab-ce#镜像如无法下载，可使用国内清华，阿里镜像#重配置GitLabsudo gitlab-ctl reconfigure#这里GitLab会安装许多软件，如Nginx，Prometheus，Redis...#首次启动会有很多信息，请稍等#首次访问GitLab,系统会让你重新设置管理员的密码,设置成功后会返回登录界面.默认的管理员账号是root#在Web界面修改密码#Browse to the hostname and login#浏览器访问前面定义的URL##在Web界面修改密码，并登陆#Set up your communication preferences 配置域名或URL12345678910111213141516171819202122232425262728293031323334#Configuring the external URL for GitLabvi /etc/gitlab/gitlab.rbexternal_url "http://gitlab.example.com"#重载配置sudo gitlab-ctl reconfigure#Configuring a relative URL for Gitlab#从v8.17以后便不需要再重新编译#要求：4GB RAM, and 4 or 8 CPU cores#栗子: https://example.com/gitlab#Enable relative URL in GitLab#如果资源不够，可临时关闭 Unicorn and Sidekiq以节省资源sudo gitlab-ctl stop unicornsudo gitlab-ctl stop sidekiqvi /etc/gitlab/gitlab.rbexternal_url "https://example.com/gitlab"#重载配置sudo gitlab-ctl reconfigure#重新启动服务，以便Unicorn和Sidekiq获取更改sudo gitlab-ctl restart#Disable relative URL in GitLabexternal_url后面不包含相对路劲即可#之后重载配置sudo gitlab-ctl restart unicorn 从non-root用户载入配置Loading external configuration file from non-root user Omnibus-gitlab package 从 /etc/gitlab/gitlab.rb file载入所有配置。它属于root用户，有严格的权限配置。它通过root用户由ruby代码执行gitlab-ctl reconfigure。 指定其它配置: 123vim /etc/gitlab/gitlab.rbfrom_file "/home/admin/external_gitlab.rb" 将Git数据存储在备用目录中Storing Git data in an alternative directory 默认情况下，omnibus-gitlab将repository数据存放于/var/opt/gitlab/git-data目录下。repository存储在此目录下的repositories子目录中。可在/etc/gitlab/gitlab.rb中修改git-data来添加备用数据目录。请注意，目录和子目录的路径必须不是链接。 如果还运行了Gitaly，请为每个git数据目录包含gitaly_address。 123456789101112131415161718192021222324252627282930313233343536373839404142vim /etc/gitlab/gitlab.rb#git_data_dirs(&#123; "default" =&gt; &#123; "path" =&gt; "/mnt/nas/git-data" &#125; &#125;)#你可以添加不止一个数据目录git_data_dirs(&#123; "default" =&gt; &#123; "path" =&gt; "/var/opt/gitlab/git-data" &#125;, "alternative" =&gt; &#123; "path" =&gt; "/mnt/nas/git-data" &#125;&#125;)#重载配置，使得更改生效sudo gitlab-ctl reconfigure#查看sudo ls /var/opt/gitlab/git-datarepositories#如果你的/var/opt/gitlab/git-data已有Git repositories，则# Prevent users from writing to the repositories while you move them.sudo gitlab-ctl stop# Note there is _no_ slash behind 'repositories', but there _is_ a# slash behind 'git-data'.sudo rsync -av /var/opt/gitlab/git-data/repositories /mnt/nas/git-data/# Start the necessary processes and run reconfigure to fix permissions# if necessarysudo gitlab-ctl upgrade# Double-check directory layout in /mnt/nas/git-data. Expected output:# repositoriessudo ls /mnt/nas/git-data/# Done! Start GitLab and verify that you can browse through the repositories in# the web interface.sudo gitlab-ctl start #### 修改Git用户/组 Changing the name of the Git user / group 默认情况下，omnibus-gitLab使用git用户登录gitlab-shell和远程Web接口。不推荐改变已安装的User/Group。 1234567891011121314151617181920212223vim /etc/gitlab/gitlab.rb#用户名/组名user['username'] = "git"user['group'] = "git"##! The shell for the git user# user['shell'] = "/bin/sh"##! The home directory for the git user# user['home'] = "/var/opt/gitlab"#uid/gid#omnibus-gitlab creates users for GitLab, PostgreSQL, Redis and NGINX.你可以指定他们的IDuser['uid'] = 1234user['gid'] = 1234postgresql['uid'] = 1235postgresql['gid'] = 1235redis['uid'] = 1236redis['gid'] = 1236web_server['uid'] = 1237web_server['gid'] = 1237 禁用用户和组的账号管理Disable user and group account management 默认情况下，omnibus-gitlab会创建系统用户/组账户，这些系统账户运行包的各种组件。大多数用户都不需要去改变这些行为。然而，如果你的系统账户由其它软件管理，你或许需要禁用此功能。 1234567891011121314151617181920212223242526272829303132333435vim /etc/gitlab/gitlab.rbmanage_accounts['enable'] = false#omnibus-gitlab依然保留之前创建的账户#默认创建以下用户# GitLab user (required)git# Web server user (required)gitlab-www# Redis user for GitLab (only when using packaged Redis)gitlab-redis# Postgresql user (only when using packaged Postgresql)gitlab-psql# Prometheus user for prometheus monitoring and various exportersgitlab-prometheus# GitLab Mattermost user (only when using GitLab Mattermost)mattermost# GitLab Registry user (only when using GitLab Registry)registry# GitLab Consul user (only when using GitLab Consul)gitlab-consul#查看用户sudo awk -F':' '&#123;print $1&#125;' /etc/passwd 你也可以在GitLab配置文件里面更改: 12345678910111213141516171819202122232425262728293031vi /etc/gitlab/gitlab.rb# Do not manage user/group accountsmanage_accounts['enable'] = false# GitLabuser['username'] = "custom-gitlab"user['group'] = "custom-gitlab"user['shell'] = "/bin/sh"user['home'] = "/var/opt/custom-gitlab"# Web serverweb_server['username'] = 'webserver-gitlab'web_server['group'] = 'webserver-gitlab'web_server['shell'] = '/bin/false'web_server['home'] = '/var/opt/gitlab/webserver'# Postgresql (not needed when using external Postgresql)postgresql['username'] = "postgres-gitlab"postgresql['group'] = "postgres-gitlab"postgresql['shell'] = "/bin/sh"postgresql['home'] = "/var/opt/postgres-gitlab"# Redis (not needed when using external Redis)redis['username'] = "redis-gitlab"redis['group'] = "redis-gitlab"redis['shell'] = "/bin/false"redis['home'] = "/var/opt/redis-gitlab"# And so on for users/groups for GitLab Mattermost1 禁用存储目录管理Disable storage directories management omnibus-gitlab负责使用正确的所有权与权限创建所必须的目录，并保持更新。一种一些目录在配置时可能会包含大量数据，也可能会挂载到NFS。 123456789vi /etc/gitlab/gitlab.rb#如果已挂在/etc/gitlab，则可关闭此目录的管理manage_storage_directories['manage_etc'] = false#如果要挂载GitLab的所有存储目录，并且每个目录都是单独地挂载，则应完全禁用存储目录的管理manage_storage_directories['enable'] = false GitLab所有数据目录： Default location Permissions Ownership Purpose /var/opt/gitlab/git-data 0700 git:root Holds repositories directory /var/opt/gitlab/git-data/repositories 2770 git:git Holds git repositories /var/opt/gitlab/gitlab-rails/shared 0751 git:gitlab-www Holds large object directories /var/opt/gitlab/gitlab-rails/shared/artifacts 0700 git:root Holds CI artifacts /var/opt/gitlab/gitlab-rails/shared/lfs-objects 0700 git:root Holds LFS objects /var/opt/gitlab/gitlab-rails/uploads 0700 git:root Holds user attachments /var/opt/gitlab/gitlab-rails/shared/pages 0750 git:gitlab-www Holds user pages /var/opt/gitlab/gitlab-ci/builds 0700 git:root Holds CI build logs /var/opt/gitlab/.ssh 0700 git:git Holds authorized keys 仅在挂载给定文件系统后启动Omnibus-GitLab服务Only start Omnibus-GitLab services after a given filesystem is mounted 如果你想防止Omnibus-GitLab服务(Nginx，Redis，Unicorn…)在挂载给定文件系统之前启动，则: 12345vi /etc/gitlab/gitlab.rb# wait for /var/opt/gitlab to be mountedhigh_availability['mountpoint'] = '/var/opt/gitlab' 配置运行时目录Configuring runtime directory 启用Prometheus监控后，GitLab-monitor将对每个Unicorn进程(Rails metrics)进行监控。每个Unicorn进行都需要将度量文件(metrics file)写入每个控制器临时的位置，然后，Prometheus收集这些文件并处理他们的值。 为了避免创建磁盘I/O，Omnibus-GitLab包将会使用一个运行时目录。 1234567891011#During reconfigure, package will check if `/run` is a `tmpfs` mount. If it is not, warning will be printed, and Rails metrics will be disabled.Runtime directory '/run' is not a tmpfs mount.#To enable Rails metrics again, create a tmpfs mount and specify itvi /etc/gitlab/gitlab.rb# runtime_dir '/run'runtime_dir '/path/to/tmpfs' 在安装期间禁用自动缓存清理Disabling automatic cache cleaning during installation 如果安装了大型的GitLab，则你可能不希望运行rake cache:clean，因为它将会耗费很长时间。 123456789101112131415161718192021222324252627282930313233343536373839vi /etc/gitlab/gitlab.rb# This is advanced feature used by large gitlab deployments where loading# whole RAILS env takes a lot of time.gitlab_rails['rake_cache_clear'] = false#Enabling/Disabling Rack Attack and setting up basic auth throttlinggitlab_rails['rack_attack_git_basic_auth'] = &#123; 'enabled' =&gt; true, # Enable/Disable Rack Attack 'ip_whitelist' =&gt; ["127.0.0.1"], # Whitelisted urls 'maxretry' =&gt; 10, # Limit the number of Git HTTP authentication attempts per IP 'findtime' =&gt; 60, # Reset the auth attempt counter per IP after 60 seconds 'bantime' =&gt; 3600 # Ban an IP for one hour (3600s) after too many auth attempts&#125;#Setting up paths to be protected by Rack Attack#如果你想改变默认保护路径#警告：此动作将会被Omnibus-GitLab提供的列表所覆盖gitlab_rails['rack_attack_protected_paths'] = [ '/users/password', '/users/sign_in', '/api/#&#123;API::API.version&#125;/session.json', '/api/#&#123;API::API.version&#125;/session', '/users', '/users/confirmation', '/unsubscribes/', '/import/github/personal_access_token']#Setting up throttling for ‘paths to be protected’gitlab_rails['rate_limit_requests_per_period'] = 10gitlab_rails['rate_limit_period'] = 60 其它 Nginx HTTPS Database Redis SMTP … 具体参考官方文档。 更新Update 更新方式取决你你使用的安装方法。 不停机升级(Upgrading without downtime) 从GitLab 9.1.0开始便可以非脱机更新，但要遵循一下依赖： You can only upgrade 1 minor release at a time. So from 9.1 to 9.2, not to 9.3. You have to use post-deployment migrations You are using PostgreSQL. If you are using MySQL please look at the release post to see if downtime is required. 更新版本(Upgrading between editions) CE-&gt;EE EE-&gt;CE 杂项(Miscellaneous) MySQL to PostgreSQL Restoring from backup after a failed upgrade Upgrading PostgreSQL Using Slony 高可用High Availability: Configure multiple servers for scaling or high availability. GitLab支持多种不同类型的集群和高可用。方案取决于你所依赖的伸缩和可用的级别。最简单的方式是可伸缩，但并不一定是高可用的。由于Git的分布式特性，即使GitLab不可用，开发人员仍然可以在本地提交代码。 但是，当GitLab关闭时，某些GitLab功能（如issue tracker and Continuous Integration…）不可用。 请记住，所有高可用性解决方案都需要在成本/复杂性和正常运行时间之间进行权衡。想要正常运行的时间越久，则解决方案就越复杂，则设置和维护它的工作就越多。高可用不是免费的，每个高可用方案都应该考虑成本和收益。 架构Architecture 有两种配置： active/active active/passive Active/Active 此体系结构可轻松扩展，因为所有应用程序Server可同时处理用户请求。Database、Redis、GitLab都部署在不同的Server上，如果他们配置也是如此，则高度可用。 配置active/active所遵循的步骤： 配置Database 配置Redis 配置NFS 配置GitLab 配置LoadBlancer Active/Passive 对于没有扩展的高可用/故障转移，你可使用Active/Passive。这利用DRBD（Distributed Replicated Block Device）来保持所有数据同步。DRBD要求低延迟链接保持同步。 不建议尝试在数据中心之间或不同的云可用区域中运行DRBD。 至少需要两台机器(one active/one passive)。 配置Configuring GitLab 配置时区Adjust your instance’s timezone: Customize the default time zone of GitLab. GitLab默认时区为UTC， 123456789101112vi /etc/gitlab/gitlab.rb# gitlab_rails['time_zone'] = 'UTC'gitlab_rails['time_zone'] = 'Asia/Shanghai'#重载重启gitlab-ctl reconfigure gitlab-ctl restart#查看时区gitlab-rake time:zones:all 系统钩子System hook，Notifications when users, projects and keys are changed. GitLab实例可对以下事件执行HTTP POST请求： project_create project_destroy project_rename project_transfer project_update user_add_to_team user_remove_from_team user_create user_destroy user_failed_login user_rename key_create key_destroy group_create group_destroy group_rename user_add_to_group user_remove_from_group 可以使用系统钩子，如用于记录或更改 LDAP Server 中的信息。 注意：我们遵循Webhook中对Push和Tag事件的相同结构，但不会显示commit的信息。Webhook的相同弃用在此有效。 Hook请求Request Header:1X-Gitlab-Event: System Hook 项目创建栗子，还有删除、重名、更新、用户、组等其它事件。 123456789101112&#123; "created_at": "2012-07-21T07:30:54Z", "updated_at": "2012-07-21T07:38:22Z", "event_name": "project_create", "name": "StoreCloud", "owner_email": "johnsmith@gmail.com", "owner_name": "John Smith", "path": "storecloud", "path_with_namespace": "jsmith/storecloud", "project_id": 74, "project_visibility": "private"&#125; Tag事件当向仓库(Repository)创建或删除标记(tag)时触发，它为每个修改过的标记生成一个事件。。 Request header: 1X-Gitlab-Event: System Hook Request body: 1234567891011121314151617181920212223242526272829303132333435363738&#123; "event_name": "tag_push", "before": "0000000000000000000000000000000000000000", "after": "82b3d5ae55f7080f1e6022629cdb57bfae7cccc7", "ref": "refs/tags/v1.0.0", "checkout_sha": "5937ac0a7beb003549fc5fd26fc247adbce4a52e", "user_id": 1, "user_name": "John Smith", "user_avatar": "https://s.gravatar.com/avatar/d4c74594d841139328695756648b6bd6?s=8://s.gravatar.com/avatar/d4c74594d841139328695756648b6bd6?s=80", "project_id": 1, "project":&#123; "name":"Example", "description":"", "web_url":"http://example.com/jsmith/example", "avatar_url":null, "git_ssh_url":"git@example.com:jsmith/example.git", "git_http_url":"http://example.com/jsmith/example.git", "namespace":"Jsmith", "visibility_level":0, "path_with_namespace":"jsmith/example", "default_branch":"master", "homepage":"http://example.com/jsmith/example", "url":"git@example.com:jsmith/example.git", "ssh_url":"git@example.com:jsmith/example.git", "http_url":"http://example.com/jsmith/example.git" &#125;, "repository":&#123; "name": "Example", "url": "ssh://git@example.com/jsmith/example.git", "description": "", "homepage": "http://example.com/jsmith/example", "git_http_url":"http://example.com/jsmith/example.git", "git_ssh_url":"git@example.com:jsmith/example.git", "visibility_level":0 &#125;, "commits": [], "total_commits_count": 0&#125; Merge请求事件在创建一个新的合并(merge)请求时触发，更新、合并、关闭现有合并请求，或在源分支中添加commit。 Request Header: 1X-Gitlab-Event: System Hook 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114&#123; "object_kind": "merge_request", "user": &#123; "name": "Administrator", "username": "root", "avatar_url": "http://www.gravatar.com/avatar/e64c7d89f26bd1972efa854d13d7dd61?s=80&amp;d=identicon" &#125;, "project": &#123; "name": "Example", "description": "", "web_url": "http://example.com/jsmith/example", "avatar_url": null, "git_ssh_url": "git@example.com:jsmith/example.git", "git_http_url": "http://example.com/jsmith/example.git", "namespace": "Jsmith", "visibility_level": 0, "path_with_namespace": "jsmith/example", "default_branch": "master", "ci_config_path": "", "homepage": "http://example.com/jsmith/example", "url": "git@example.com:jsmith/example.git", "ssh_url": "git@example.com:jsmith/example.git", "http_url": "http://example.com/jsmith/example.git" &#125;, "object_attributes": &#123; "id": 90, "target_branch": "master", "source_branch": "ms-viewport", "source_project_id": 14, "author_id": 51, "assignee_id": 6, "title": "MS-Viewport", "created_at": "2017-09-20T08:31:45.944Z", "updated_at": "2017-09-28T12:23:42.365Z", "milestone_id": null, "state": "opened", "merge_status": "unchecked", "target_project_id": 14, "iid": 1, "description": "", "updated_by_id": 1, "merge_error": null, "merge_params": &#123; "force_remove_source_branch": "0" &#125;, "merge_when_pipeline_succeeds": false, "merge_user_id": null, "merge_commit_sha": null, "deleted_at": null, "in_progress_merge_commit_sha": null, "lock_version": 5, "time_estimate": 0, "last_edited_at": "2017-09-27T12:43:37.558Z", "last_edited_by_id": 1, "head_pipeline_id": 61, "ref_fetched": true, "merge_jid": null, "source": &#123; "name": "Awesome Project", "description": "", "web_url": "http://example.com/awesome_space/awesome_project", "avatar_url": null, "git_ssh_url": "git@example.com:awesome_space/awesome_project.git", "git_http_url": "http://example.com/awesome_space/awesome_project.git", "namespace": "root", "visibility_level": 0, "path_with_namespace": "awesome_space/awesome_project", "default_branch": "master", "ci_config_path": "", "homepage": "http://example.com/awesome_space/awesome_project", "url": "http://example.com/awesome_space/awesome_project.git", "ssh_url": "git@example.com:awesome_space/awesome_project.git", "http_url": "http://example.com/awesome_space/awesome_project.git" &#125;, "target": &#123; "name": "Awesome Project", "description": "Aut reprehenderit ut est.", "web_url": "http://example.com/awesome_space/awesome_project", "avatar_url": null, "git_ssh_url": "git@example.com:awesome_space/awesome_project.git", "git_http_url": "http://example.com/awesome_space/awesome_project.git", "namespace": "Awesome Space", "visibility_level": 0, "path_with_namespace": "awesome_space/awesome_project", "default_branch": "master", "ci_config_path": "", "homepage": "http://example.com/awesome_space/awesome_project", "url": "http://example.com/awesome_space/awesome_project.git", "ssh_url": "git@example.com:awesome_space/awesome_project.git", "http_url": "http://example.com/awesome_space/awesome_project.git" &#125;, "last_commit": &#123; "id": "ba3e0d8ff79c80d5b0bbb4f3e2e343e0aaa662b7", "message": "fixed readme", "timestamp": "2017-09-26T16:12:57Z", "url": "http://example.com/awesome_space/awesome_project/commits/da1560886d4f094c3e6c9ef40349f7d38b5d27d7", "author": &#123; "name": "GitLab dev user", "email": "gitlabdev@dv6700.(none)" &#125; &#125;, "work_in_progress": false, "total_time_spent": 0, "human_total_time_spent": null, "human_time_estimate": null &#125;, "labels": null, "repository": &#123; "name": "git-gpg-test", "url": "git@example.com:awesome_space/awesome_project.git", "description": "", "homepage": "http://example.com/awesome_space/awesome_project" &#125;&#125; 库更新事件Repository Update events 当你push到Repository(包括tag)的时候仅触发一次。 Request Header： 1X-Gitlab-Event: System Hook Request body: 1234567891011121314151617181920212223242526272829303132&#123; "event_name": "repository_update", "user_id": 1, "user_name": "John Smith", "user_email": "admin@example.com", "user_avatar": "https://s.gravatar.com/avatar/d4c74594d841139328695756648b6bd6?s=8://s.gravatar.com/avatar/d4c74594d841139328695756648b6bd6?s=80", "project_id": 1, "project": &#123; "name":"Example", "description":"", "web_url":"http://example.com/jsmith/example", "avatar_url":null, "git_ssh_url":"git@example.com:jsmith/example.git", "git_http_url":"http://example.com/jsmith/example.git", "namespace":"Jsmith", "visibility_level":0, "path_with_namespace":"jsmith/example", "default_branch":"master", "homepage":"http://example.com/jsmith/example", "url":"git@example.com:jsmith/example.git", "ssh_url":"git@example.com:jsmith/example.git", "http_url":"http://example.com/jsmith/example.git", &#125;, "changes": [ &#123; "before":"8205ea8d81ce0c6b90fbe8280d118cc9fdad6130", "after":"4045ea7a3df38697b3730a20fb73c8bed8a3e69e", "ref":"refs/heads/master" &#125; ], "refs":["refs/heads/master"]&#125; 安全Security: Learn what you can do to further secure your GitLab instance. 密码长度Password length limits 如果要强制使用更长的用户密码，可使用Devise initializer来设置。 如果未使用devise_password_length.rb初始化程序，则在config/initializers/devise.rb中设置密码长度。 123cd /home/git/gitlabsudo -u git -H cp config/initializers/devise_password_length.rb.example config/initializers/devise_password_length.rbsudo -u git -H editor config/initializers/devise_password_length.rb # inspect and edit the new password length limits 限制SSH秘钥和长度Restrict SSH key technologies and minimum length ssh-keygen允许用户创建少至768位的RSA密钥，这远低于某些标准组的建议。 这个功能在Web界面的设置里去设置。 机架攻击Rack attack Rack Attack, 也称为Rack::Attack.旨在通过自定义限制和阻止用户IP来保护GitLab。从v 11.2开始，默认禁用此功能。您可以通过限制来自发出大量请求的IP地址的请求来防止暴力密码攻击，抓取程序或任何其他违规者。 如果您发现限制不足以保护您免受滥用客户端的攻击，Rack Attack提供IP白名单，黑名单，Fail2ban样式过滤和跟踪。如果你的实例并未对外有任何传入连接，则建议你禁用此功能。 设置123456789101112131415vi /etc/gitlab/gitlab.rb#启用gitlab_rails['rack_attack_git_basic_auth'] = &#123; 'enabled' =&gt; true, 'ip_whitelist' =&gt; ["127.0.0.1"], 'maxretry' =&gt; 10, # Limit the number of Git HTTP authentication attempts per IP 'findtime' =&gt; 60, # Reset the auth attempt counter per IP after 60 seconds 'bantime' =&gt; 3600 # Ban an IP for one hour (3600s) after too many auth attempts&#125;#重载sudo gitlab-ctl reconfigure 通过Redis冲机架攻击中移除阻止的IPRemove blocked IPs from Rack Attack via Redis 如果想移除阻止的IPs，参考下： 123456789101112131415161718#在日志中找出被阻止的IPsgrep &quot;Rack_Attack&quot; /var/log/gitlab/gitlab-rails/production.log#由于黑名单存在Redis中，所以需要连接Redis/opt/gitlab/embedded/bin/redis-cli -s /var/opt/gitlab/redis/redis.socket#删除此IPDEL cache:gitlab:rack::attack:allow2ban:ban:&lt;ip&gt;#查看KEYS *rack::attack*#或者，将其加入白名单 如果所有流量来自于负载均衡器，请记得把负载均衡器加入白名单。 Webhooks和不安全的内部Web服务Webhooks and insecure internal web services 如果您的GitLab Server或其本地网络中运行non-GitLab Web服务，则这些服务可能很容易被Webhooks利用。使用Webhook，你便可以设置项目在发生特定事件时触发的URL。通常，这些请求被发送到专门为此目的设置的外部Web服务，以适当的方式处理请求及其附加数据。 然而，当Webhook设置的URL不是指向外部服务而是指向内部服务时，可能会在触发webhook并发送POST请求时完全无意中执行操作。因为Webhook请求是由GitLab Server本身发出的，所以它们可以完全访问服务器上运行的所有内容或服务器的本地网络，即使这些服务受到其他方面的保护，无法与外界联系。 如果一个Web服务不需要身份认证，Webhooks可以通过让GitLab Server向端点(endpoint)发出POST请求来触发破坏性命令，例如http://localhost:123/some-resource/delete 为了防止这种类型的利用，从GitLab v10.6开始，默认禁止对当前GitLab Instance Server Address或private network的所有Webhook请求。 1234567#这意味着这些地址都被禁止127.0.0.1::10.0.0.010.0.0.0/8172.16.0.0/12173.192.168.0.0/16 可在Web界面的设置里面的Outbound requests里启用Allow requests to the local network from hooks and services. 信息独占性Information exclusivity Git是一个分布式版本控制系统，这意味着使用源代码的每一个人都拥有完整Repository的本地副本。GitLab有Guest、 Reporter、Developer、Maintainer这些项目用户权限。在获取此Repository后，用户可在任何位置上传此Repository。您无法构建访问控制来阻止有权访问源代码的用户有意共享源代码。这是DVCS的固有特性，所有git管理系统都有此限制。显然你可以采取措施防止无意的共享和信息破坏，这就是为什么只有一些人被允许邀请其他人，没有人可以强制推动受保护的分支。 重置root密码reset your root password 使用root权限登录Ruby Rail控制台: 1234567891011121314151617181920212223sudo su -#控制台gitlab-rails console production#等待终端的载入#查找用户user = User.where(id: 1).first#oruser = User.find_by(email: 'admin@local.host')#修改密码user.password = 'secret_pass'user.password_confirmation = 'secret_pass'#保存更改和退出user.save! 解锁锁定的用户How to unlock a locked user 使用root权限登录Server，启动Ruby Rail Console: 123456789101112sudo su -gitlab-rails console productionuser = User.where(id: 1).first#oruser = User.find_by(email: 'admin@local.host')#解锁user.unlock_access! 用户文件上传User File Uploads 如果有人知道直接URL，则附加图像到问题，合并请求或评论不需要查看身份验证。此直接URL包含一个随机的32个字符的ID，可防止未经授权的人员将URL猜到包含敏感信息的图像。我们不启用身份验证，因为这些图像需要在通知电子邮件正文中可见，通常从未通过GitLab验证的电子邮件客户端读取，例如Outlook、Gmail.. 请注意，非图像附件确实需要查看身份验证。 管理CRIME漏洞How we manage the CRIME vulnerability CRIME(“Compression Ratio Info-leak Made Easy”)是一种针对使用HTTPS和SPDY协议进行连接的秘密Web cookie的安全漏洞，这些协议也使用数据压缩。当用于恢复秘密身份验证cookie的内容时，它允许攻击者在经过身份验证的Web会话上执行会话劫持，从而允许发起进一步的攻击。 TLS协议CRIME漏洞影响HTTPS上的压缩，因此它警告不要使用SSL压缩（例如gzip）或SPDY，它也可以选择使用压缩。虽然在Omnibus安装中启用了SPDY，但CRIME依赖于压缩（’C’），并且NGINX的SPDY模块中的默认压缩级别为0（无压缩）。 GitLab支持gzip和SPDY，并在启用HTTPS时通过停用gzip来缓解CRIME漏洞。你可以看到问题的来源： Source installation NGINX file Omnibus installation NGINX file 强制双重认证Enforce Two-factor Authentication (2FA) 双因素身份验证（2FA）为GitLab帐户提供了额外的安全级别。启用后，除了提供用户名和密码登录外，还要求在输入应用程序生成的代码。 为所有账户启用两步认证： 有两种方式： Enforce on next login. Suggest on next login, but allow a grace period before enforcing. 在Web界面里Admin区域里的设置里面的“Sign-in Restrictions”选项。 为组中的所有用户启用： 如果你只想对某些特定组启用两步认证，则你需要则群组设置中启用它。 为所有用户禁用： 123456# Omnibus installationssudo gitlab-rake gitlab:two_factor:disable_for_all_users# Installations from sourcesudo -u git -H bundle exec rake gitlab:two_factor:disable_for_all_users RAILS_ENV=production 注册时用户邮件确认User email confirmation at sign-up 如果您想在所有用户电子邮件登录之前确认，GitLab管理员可以在注册时启用电子邮件确认。 在Web界面的Admin区域的设置的“ Sign-up Restrictions”里启用“Send confirmation email on sign-up”。 统计、检查和pingUsage statistics, version check, and usage ping: Enable or disable information about your instance to be sent to GitLab, Inc. GitLab定期从实例收集各种信息。你可在Admin area &gt; Settings去设置他们。 停止使用ping： 在设置面板里面取消，并修改配置。 1234567891011121314#omnibusvi /etc/gitlab/gitlab.rbgitlab_rails[&apos;usage_ping_enabled&apos;] = false#sourcevi ./gitlab.ymlproduction: &amp;base # ... gitlab: # ... usage_ping_enabled: false 轮询配置Polling: Configure how often the GitLab UI polls for updates. GitLab UI按照适合资源的计划轮询不同资源的更新(issue notes, issue titles, pipeline statuses, etc.)在Web UI的应用程序使用功能中设置它： 1(默认值，推荐用于大多数安装)（Issue notes poll every 2 seconds, and issue titles poll every 5 seconds.) 0(禁用UI轮询) 大于1(将减慢轮询速度) 0-1之间(轮询更频繁，不推荐) GitLab PageGitLab Pages configuration: Enable and configure GitLab Pages. GitLab Pages使用GitLab Pages Daemon，这是一个用Go编写的简单HTTP Server，可以侦听外部IP地址并提供对自定义域和自定义证书的支持。它通过SNI支持动态证书，默认情况下使用HTTP2公开页面。 对于自定义域（但不是通配符域），Pages Daemon需要侦听端口80/443。因此，您可以灵活设置它： 在与GitLab相同的Server中运行Pages Daemon，监听 Secondary IP 在与GitLab相同的Server上运行Pages Daemon，监听同一IP的不同Port 在单独的Server中运行Pages Daemon 依赖在配置Pages之前，你需要： 拥有用于提供GitLab Pages的独占根域。请注意，您不能使用GitLab实例域的子域。 配置wildcard DNS record. HTTPS(可选) 启用shared runner(可选，但推荐) 将域添加到公共后缀列表Add the domain to the Public Suffix List DNS配置 您需要添加指向GitLab运行的主机的通配符DNS A记录。 ##### 配置 根据您的需要，您可以通过4种不同的方式设置GitLab页面。 Wildcard domains Wildcard domains with TLS support Custom domains Custom domains with TLS support Custom domain verification Access control 12345vi /etc/gitlab/gitlab.rbgitlab_pages... 其它一些配置： 1234567891011121314151617#日志记录gitlab_pages[&apos;log_verbose&apos;] = true#存储路径gitlab_rails[&apos;pages_path&apos;] = &quot;/mnt/storage/pages&quot;#监听和代理请求gitlab_pages[&apos;listen_proxy&apos;] = &quot;localhost:10080&quot;#禁用gitlab_pages[&apos;listen_proxy&apos;] = nil#安全#备份#page size... 环境变量Environment variables: Supported environment variables that can be used to override their defaults values in order to configure GitLab. GitLab公开了某些环境变量，这些变量可用于覆盖其默认值。 支持的环境变量： Variable Type Description GITLAB_CDN_HOST string Sets the base URL for a CDN to serve static assets (e.g. //mycdnsubdomain.fictional-cdn.com) GITLAB_ROOT_PASSWORD string Sets the password for the root user on installation GITLAB_HOST string The full URL of the GitLab server (including http:// or https://) RAILS_ENV string The Rails environment; can be one of production, development, staging or test DATABASE_URL string The database URL; is of the form: postgresql://localhost/blog_development GITLAB_EMAIL_FROM string The e-mail address used in the “From” field in e-mails sent by GitLab GITLAB_EMAIL_DISPLAY_NAME string The name used in the “From” field in e-mails sent by GitLab GITLAB_EMAIL_REPLY_TO string The e-mail address used in the “Reply-To” field in e-mails sent by GitLab GITLAB_EMAIL_SUBJECT_SUFFIX string The e-mail subject suffix used in e-mails sent by GitLab GITLAB_UNICORN_MEMORY_MIN integer The minimum memory threshold (in bytes) for the Unicorn worker killer GITLAB_UNICORN_MEMORY_MAX integer The maximum memory threshold (in bytes) for the Unicorn worker killer GITLAB_SHARED_RUNNERS_REGISTRATION_TOKEN string Sets the initial registration token used for GitLab Runners 完整的数据库变量： 指定数据库连接信息的推荐方法是设置DATABASE_URL环境变量。此变量仅保存连接信息(adapter, database, username, password, host, port)，没有行为信息(encoding, pool)。 如果你不想使用DATABASE_URL环境变量或想要使用数据库行为信息，则： 复制模板文件: cp config/database.yml.env config/database.yml 或，为GITLAB_DATABASE_XXX变量设置值 你可以设置的GITLAB_DATABASE_XXX变量列表： Variable Default value Overridden by DATABASE_URL? GITLAB_DATABASE_ADAPTER postgresql (for MySQL use mysql2) Yes GITLAB_DATABASE_DATABASE gitlab_#{ENV[‘RAILS_ENV’] Yes GITLAB_DATABASE_USERNAME root Yes GITLAB_DATABASE_PASSWORD None Yes GITLAB_DATABASE_HOST localhost Yes GITLAB_DATABASE_PORT 5432 Yes GITLAB_DATABASE_ENCODING unicode No GITLAB_DATABASE_POOL 10 No 添加更多变量： 我们欢迎合并请求，并通过变量进行更多配置。请在config/initializers/1_settings.rb文件中进行更改，并使用GITLAB_#{name in 1_settings.rb in upper case}这样的命名方案。 Omnibus设置自定义环境变量： 如有必要，您可以通过/etc/gitlab/gitlab.rb设置Unicorn，Sidekiq，Rails和Rake使用的自定义环境变量。这在您需要使用代理来访问Internet并且您希望将外部托管的存储库直接克隆到gitlab的情况下非常有用。 1234567891011121314151617181920212223242526272829gitlab_rails[&apos;env&apos;] = &#123; &quot;http_proxy&quot; =&gt; &quot;my_proxy&quot;, &quot;https_proxy&quot; =&gt; &quot;my_proxy&quot;&#125;#你还可以覆盖GitLab组件中的其它环境变量# Needed for proxying Git clonesgitaly[&apos;env&apos;] = &#123; &quot;http_proxy&quot; =&gt; &quot;my_proxy&quot;, &quot;https_proxy&quot; =&gt; &quot;my_proxy&quot;&#125;gitlab_workhorse[&apos;env&apos;] = &#123; &quot;http_proxy&quot; =&gt; &quot;my_proxy&quot;, &quot;https_proxy&quot; =&gt; &quot;my_proxy&quot;&#125;# If you use the docker registryregistry[&apos;env&apos;] = &#123; &quot;http_proxy&quot; =&gt; &quot;my_proxy&quot;, &quot;https_proxy&quot; =&gt; &quot;my_proxy&quot;&#125;#应用更改#对环境变量所做的任何更改都需要在重新配置后进行硬重启才能使其生效sudo gitlab-ctl reconfiguresudo gitlab-ctl restart 插件GitLab Plugin SystemPlugins: With custom plugins, GitLab administrators can introduce custom integrations without modifying GitLab’s source code. 使用自定义插件，GitLab管理员可以在不修改GitLab源代码的情况下引入自定义集成。你也可以之间修改GitLab源代码而不用编写插件。必须在GitLab Server上配置插件。 插件将在每个事件上运行，因此您可以在插件代码中过滤事件或项目。你可以拥有任意数量的插件。如果发生事件，每个插件都将由GitLab异步触发。 配置： 插件必须直接放在plugin目录中，按照以下步骤自定义hook: 在GitLab Server上，定位到plugin目录 source: /home/git/gitlab/plugins/ omnibus: /opt/gitlab/embedded/service/gitlab-rails/plugins 在plugins目录内，创建一个你需要的文件(文件名不要使用特殊字符) 使hook文件可执行，并有git用户所拥有 编写代码以使插件功能符合预期。这可以是任何语言 插件的数据将在STDIN上以JSON的形式提供 验证： 编写自己的插件可能会非常棘手，如果您可以在不改变系统的情况下进行检查，则会更容易。 123456# Omnibus installationssudo gitlab-rake plugins:validate# Installations from sourcecd /home/git/gitlabbundle exec rake plugins:validate RAILS_ENV=production 规范性Compliance: A collection of features from across the application that you may configure to help ensure that your 您可以配置以下GitLab功能，以帮助确保您的GitLab实例符合通用的规范性标准。 功能 GitLab tier Restrict SSH Keys 控制用于访问GitLab的SSH密钥的技术和密钥长度 Core+ Granular user roles and flexible permissions 使用五种不同的用户角色和外部用户设置管理访问权限和权限。根据人员的角色设置权限，而不是对存储库的读取或写入访问权限。不要与只需要访问问题跟踪器的人共享源代码。 Core+ Enforce TOS acceptance 通过阻止GitLab流量强制您的用户接受新的服务条款。 Core+ Email all users of a project, group, or entire server 管理员可以根据项目或组成员身份向用户组发送电子邮件，或使用GitLab实例向每个人发送电子邮件。 Starter+ Omnibus package supports log forwarding 将日志转发到中央系统。 Starter+ Lock project membership to group 组所有者可以阻止将新成员添加到组中的项目。 Starter+ LDAP group sync GitLab企业版使管理员能够自动同步组并管理SSH密钥，权限和身份验证，因此您可以专注于构建产品，而不是配置工具。 Starter+ LDAP group sync filters GitLab企业版Premium可以更灵活地基于过滤器与LDAP同步，这意味着您可以利用LDAP属性来映射GitLab权限。 Premium+ Audit logs 为了保持代码的完整性，GitLab Enterprise Edition Premium使管理员能够在高级审计日志系统中查看GitLab服务器内的任何修改，以便您可以控制，分析和跟踪每个更改。 Premium+ Auditor users 审核员用户是对GitLab实例上的所有项目，组和其他资源具有只读访问权限的用户。 Premium+ 自定义GitLab外观Customizing GitLab’s appearance 这些外观配置请在Web UI里面进行设置： Header logo Favicon Branded login page Welcome message “New Project” page 维护GitLabMaintaining GitLab 靶任务Raketasks: Perform various tasks for maintenance, backups, automatic webhooks setup, etc. 备份Backing up and restoring GitLab 应用程序数据备份会创建一个归档文件，其中包含数据库、所有Repository和所有附件。您只能将备份恢复到与其创建的GitLab完全相同的版本和类型（CE / EE）。将Repository从一个服务器迁移到另一个服务器的最佳方法是通过备份还原。 依赖(requirements)为了实现备份和还原，需要在系统上安装两个工具。 rsync tar v1.3+ 备份时间戳(Backup timestamp) Note: In GitLab 9.2 the timestamp format was changed from EPOCH_YYYY_MM_DD to EPOCH_YYYY_MM_DD_GitLab_version 备份存档将保存在backup_path中，它在config/gitlab.yml文件中指定。文件名为[TIMESTAMP] _gitlab_backup.tar，其中TIMESTAMP标识每个备份的创建时间以及GitLab版本。如果需要还原GitLab并且有多个备份可用，则需要时间戳。 创建备份(Creating a backup of the GitLab system) GitLab提供了一个简单的命令行接口来备份整个实例。包括： Database Attachments Git repositories data CI/CD job output logs CI/CD job artifacts LFS objects Container Registry images GitLab Pages content 注意：GitLab不会备份配置文件、SSL证书、系统文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#omnibussudo gitlab-rake gitlab:backup:create#sourcesudo -u git -H bundle exec rake gitlab:backup:create RAILS_ENV=production#dockerdocker exec -t &lt;container name&gt; gitlab-rake gitlab:backup:create#k8s clusterkubectl exec -it &lt;gitlab task-runner pod&gt; backup-utility#输出栗子sudo gitlab-rake gitlab:backup:createDumping database ...Dumping PostgreSQL database gitlabhq_production ... [DONE]doneDumping repositories ... * root/zhangbin-test ... [DONE][SKIPPED] Wiki * root/test02 ... [SKIPPED][SKIPPED] WikidoneDumping uploads ...doneDumping builds ...doneDumping artifacts ...doneDumping pages ...doneDumping lfs objects ...doneDumping container registry images ...[DISABLED]Creating backup archive: 1544578010_2018_12_12_11.5.1_gitlab_backup.tar ... doneUploading backup archive to remote storage ... skippedDeleting tmp directories ... donedonedonedonedonedonedonedoneDeleting old backups ... skipping#查看sudo ls /var/opt/gitlab/backups/1544578010_2018_12_12_11.5.1_gitlab_backup.tarsudo tar -tvf backups/1544578010_2018_12_12_11.5.1_gitlab_backup.tardrwx------ git/git 0 2018-12-12 09:26 repositories/drwxr-xr-x git/git 0 2018-12-12 09:26 repositories/root/-rw-r--r-- git/git 476 2018-12-12 09:26 repositories/root/zhangbin-test.bundledrwxr-xr-x git/git 0 2018-12-12 09:26 repositories/root/zhangbin-test/drwxr-xr-x git/git 0 2018-12-12 09:26 db/-rw------- git/git 84875 2018-12-12 09:26 db/database.sql.gz-rw------- git/git 152 2018-12-12 09:26 uploads.tar.gz-rw------- git/git 151 2018-12-12 09:26 builds.tar.gz-rw------- git/git 152 2018-12-12 09:26 artifacts.tar.gz-rw------- git/git 155 2018-12-12 09:26 pages.tar.gz-rw------- git/git 152 2018-12-12 09:26 lfs.tar.gz-rw-r--r-- git/git 190 2018-12-12 09:26 backup_information.yml 保存配置文件(Storing configuration files) Omnibus /etc/gitlab/gitlab-secrets.json /etc/gitlab/gitlab.rb Source /home/git/gitlab/config/secrets.yml /home/git/gitlab/config/gitlab.yml TLS keys and certificates SSH key … 备份选项(Backup options)备份策略提供了许多可用选项。 备份策略(Backup strategy option)默认备份策略是使用Linux命令tar和gzip将数据从相应的数据位置流式传输到备份。这在大多数情况下都可以正常工作，但在数据快速变化时会导致问题。当tar读取数据时数据发生变化，读取文件会发生错误，并导致备份过程失败。为了解决这个问题，v8.17引入了一种名为copy的新备份策略。该策略在调用tar和gzip之前将数据文件复制到临时位置，以避免错误。副作用(side-effect)是备份过程中占用额外的磁盘空间，该过程尽最大努力在每个阶段清理临时文件，因此问题不会复杂化，但对于大型安装而言，这可能是一个相当大的变化。 12#使用sudo gitlab-rake gitlab:backup:create STRATEGY=copy 从备份中排出特定目录(Excluding specific directories from the backup) db (database) uploads (attachments) repositories (Git repositories data) builds (CI job output logs) artifacts (CI job artifacts) lfs (LFS objects) registry (Container Registry images) pages (Pages content) 你可以使用SKIP环境变量来跳过不需要备份的内容，使用逗号来分隔多个 12#栗子sudo gitlab-rake gitlab:backup:create SKIP=db,uploads 上传到本地挂载来共享(Uploading to locally mounted shares)你也可以使用Fog Local存储提供程序将备份发送到已挂载的共享(NFS/CIFS/SMB…)。local_root key 指向的目录在挂载时必须由git用户拥有。除local_root key 外，还必须设置backup_upload_remote_directory，这是已挂载目录中将要复制备份的子目录，如果不存在则将创建。 1234567891011121314151617181920212223242526#Omnibus#vi /etc/gitlab/gitlab.rbgitlab_rails[&apos;backup_upload_connection&apos;] = &#123; :provider =&gt; &apos;Local&apos;, :local_root =&gt; &apos;/mnt/backups&apos;&#125;# The directory inside the mounted folder to copy backups to# Use &apos;.&apos; to store them in the root directorygitlab_rails[&apos;backup_upload_remote_directory&apos;] = &apos;gitlab_backups&apos;#source#vi home/git/gitlab/config/gitlab.ymlbackup: upload: # Fog storage connection settings, see http://fog.io/storage/ . connection: provider: Local local_root: &apos;/mnt/backups&apos; # The directory inside the mounted folder to copy backups to # Use &apos;.&apos; to store them in the root directory remote_directory: &apos;gitlab_backups&apos; 备份归档权限(Backup archive permissions)GitLab创建的备份归档文件的默认所属用户和组为(git:git)，这是为了避免其它系统用户读取GitLab数据。如果你需要备份文件具有其它权限，请在配置文件中修改它： 1234567891011#Omnibus#/etc/gitlab/gitlab.rbgitlab_rails['backup_archive_permissions'] = 0644 # Makes the backup archives world-readable#source#/home/git/gitlab/config/gitlab.yml:backup: archive_permissions: 0644 # Makes the backup archives world-readable 配置定时备份(Configuring cron to make daily backups) 请注意，backup_keep_time配置选项仅管理本地文件。 GitLab不会自动清理存储在第三方对象存储（例如，AWS S3）中的旧文件，因为用户可能没有列出和删除文件的权限。建议您为对象存储配置适当的保留策略。 1234567891011121314#Omnibus#/etc/gitlab/gitlab.rb#默认保留7天## Limit backup lifetime to 7 days - 604800 secondsgitlab_rails['backup_keep_time'] = 604800#cronsudo su -crontab -e#每天2AM0 2 * * * /opt/gitlab/bin/gitlab-rake gitlab:backup:create CRON=1 恢复Restore GitLab提供了一个简单的命令行界面来恢复整个安装，并且足够灵活，可以满足您的需求。您只能将备份恢复到与其创建的GitLab完全相同的版本和类型（CE / EE）。 先决条件(prerequisites)在执行还原之前，您需要安装有效的GitLab。这主要是因为通常不允许执行恢复操作（git）的系统用户创建或删除将数据导入（gitlabhq_production）所需的SQL数据库。所有现有数据将被删除或移动到单独的目录。要恢复备份，您还需要恢复/etc/gitlab/gitlab-secrets.json（Omnibus）或 /home/git/gitlab/.secret（Source），它包含了 database encryption key, CI/CD 变量 和 two-factor authentication的变量。如果您无法将此加密密钥文件与应用程序数据备份一起恢复，则启用了双因素身份验证的用户和GitLab Runners将无法访问您的GitLab服务器。你可能还需要还原TLS keys, certificates, or SSH host keys… 根据你的情况，你可能需要使用如下选项： BACKUP=timestamp_of_backup: 如果存在多个备份，则必需 force=yes: 不询问authorized_keys文件是否应该重新生成，并假设“yes”表示将删除数据库表，启用“写入authorized_keys文件”设置，并更新LDAP提供程序。 注意: 如果要还原到作为挂载点的目录，则需要在尝试还原之前确保这些目录为空。否则GitLab将在恢复新数据之前尝试移动这些目录，这将导致错误。 还原源码安装(Source) 1234# Stop processes that are connected to the databasesudo service gitlab stopbundle exec rake gitlab:backup:restore RAILS_ENV=production 还原包安装(Omnibus) 此过程假定： 你已使用包安装相同版本的GitLab 你至少已经运行了一次sudo gitlab-ctl reconfigure GitLab已经运行 首先确保你的备份文件已经放置到了备份目录中(默认为/var/opt/gitlab/backups)，并将其所属用户和组修改为git:git。 1234567891011121314151617181920#复制备份文件sudo cp 11493107454_2018_04_25_10.6.4-ce_gitlab_backup.tar /var/opt/gitlab/backups/sudo chown git.git /var/opt/gitlab/backups/11493107454_2018_04_25_10.6.4-ce_gitlab_backup.tar#暂停程序与数据库的连接sudo gitlab-ctl stop unicornsudo gitlab-ctl stop sidekiq# Verifysudo gitlab-ctl status#还原# This command will overwrite the contents of your GitLab database!sudo gitlab-rake gitlab:backup:restore BACKUP=1493107454_2018_04_25_10.6.4-ce#重启和检查sudo gitlab-ctl restartsudo gitlab-rake gitlab:check SANITIZE=true 还原Docker对于使用Docker或可k8s安装的GitLab，还原期望还原的目录为空。然而，使用Docker和k8s volume 挂载时，可能会在Volume根下创建一些系统级的目录(如: lost+found)。这些目录通常由root拥有，可能会导致访问权限错误。因为还原操作是以git用户运行。因此，要还原GitLab，请确保还原的目标目录为空。 12#Dockerdocker exec -it &lt;name of container&gt; gitlab-rake gitlab:backup:restore 其它备份策略Alternative backup strategies 如果您的GitLab服务器包含大量Git Repository数据，您可能会发现GitLab备份脚本太慢。在这种情况下，您可以考虑使用文件系统快照作为备份策略的一部分。 LVM snapshots + rsync建立一个临时的LVM快照，将它作为只读文件系统挂载到/mnt/gitlab_backup。现在我们可以有一个更长的rsync作业，它将在远程Server创建一致的副本。 完整性检查Integrity Check 仓库完整性(Repository Integrity) 即使Git非常有弹性并试图防止数据完整性问题，但有时候仍会出现问题。以下Rake task 旨在帮助GitLab管理员诊断问题 Repo，以便修复它们。 Git repository file system check Check for config.lock in the repository directory Check for any branch/references lock files in refs/heads 以下症状可能表示Repo完整性存在问题： Receiving an error when trying to push code - remote: error: cannot lock ref A 500 error when viewing the GitLab dashboard or when accessing a specific project 检查所有GitLab Repo完整性 此任务循环遍历GitLab服务器上的所有存储库，并运行前面描述的完整性检查。 123456#Omnibussudo gitlab-rake gitlab:git:fsck#sourcesudo -u git -H bundle exec rake gitlab:git:fsck RAILS_ENV=production 上传的文件完整性(Uploaded Files Integrity) 用户可以将各种类型的文件上传到GitLab上。此外，这些完整性检查可以检测丢失的文件。对于本地存储的文件，在上传时生成校验和(checksum)并将其存储在数据库中，并且这些检查将针对当前文件验证它们。目前，支持一下类型文件的完整性检查： CI artifacts LFS objects User uploads 12345678910#Omnibussudo gitlab-rake gitlab:artifacts:checksudo gitlab-rake gitlab:lfs:checksudo gitlab-rake gitlab:uploads:check#Sourcesudo -u git -H bundle exec rake gitlab:artifacts:check RAILS_ENV=productionsudo -u git -H bundle exec rake gitlab:lfs:check RAILS_ENV=productionsudo -u git -H bundle exec rake gitlab:uploads:check RAILS_ENV=production 这些任务还接受一些环境变量，您可以使用这些变量来覆盖某些值： Variable Type Description BATCH integer Specifies the size of the batch. Defaults to 200. ID_FROM integer Specifies the ID to start from, inclusive of the value. ID_TO integer Specifies the ID value to end at, inclusive of the value. VERBOSE boolean Causes failures to be listed individually, rather than being summarized. 1234#栗子sudo gitlab-rake gitlab:artifacts:check BATCH=100 ID_FROM=50 ID_TO=250sudo gitlab-rake gitlab:lfs:check BATCH=100 ID_FROM=50 ID_TO=250sudo gitlab-rake gitlab:uploads:check BATCH=100 ID_FROM=50 ID_TO=250 LDAP检查 清理Cleanup 从文件系统移除垃圾(Remove garbage from filesystem. Important! Data loss!) 如果GitLab数据库中不存在 namespace（dirs），则从所有Repo存储路径中删除它们。 123456# omnibus-gitlabsudo gitlab-rake gitlab:cleanup:dirs# installation from sourcebundle exec rake gitlab:cleanup:dirs RAILS_ENV=production 如果GitLab数据库中不存在Repo，则从所有Repo存储路径重命名存储库。Repo获得一个+orphaned+TIMESTAMP后缀，以便他们无法阻止新Repo的创建。 123456# omnibus-gitlabsudo gitlab-rake gitlab:cleanup:repos# installation from sourcebundle exec rake gitlab:cleanup:repos RAILS_ENV=production 如果GitLab数据库中不存在本地项目上传文件，请将其清除。该任务尝试修复文件，如果它可以找到它的项目，否则它将文件移动到丢失和找到的目录。 123456# omnibus-gitlabsudo gitlab-rake gitlab:cleanup:project_uploads# installation from sourcebundle exec rake gitlab:cleanup:project_uploads RAILS_ENV=production 如果GitLab数据库中不存在对象存储上载文件，请将其删除。 123456# omnibus-gitlabsudo gitlab-rake gitlab:cleanup:remote_upload_files# installation from sourcebundle exec rake gitlab:cleanup:remote_upload_files RAILS_ENV=production 命名空间Namespaces 为用户项目启用用户名和命名空间(Enable usernames and namespaces for user projects) 此命令启动命名空间，它将移动其命名空间文件夹中的每个项目。注意： 由于Repo Location发生改变，因此你需要更新git URL以指向新地址 用户名可在Profile中修改 12345678910#栗子#Old pathgit@example.org:myrepo.git#new pathgit@example.org:username/myrepo.git#orgit@example.org:groupname/myrepo.git LDAPLDAP Rake Tasks 检查(Check) LDAP检查Rake task 将测试bind_dn和password凭据（如果已配置），并将列出LDAP用户的示例。此任务作为gitlab:check任务的一部分执行，但可以使用以下命令单独运行。 123456#Omnibushsudo gitlab-rake gitlab:ldap:check#Sourcesudo -u git -H bundle exec rake gitlab:ldap:check RAILS_ENV=production 重命名提供商(Rename a provider) 如果更改了配置文件中的LDAP Server ID，则需要更新所有用户标识，否则将无法登录。输入旧的和新的提供商，此任务将更新数据库中的所有匹配标识。 12345678#栗子#main是LDAP Server IDmain: label: 'LDAP' host: '_your_ldap_server' port: 389 uid: 'sAMAccountName' ... 123456#Omnibussudo gitlab-rake gitlab:ldap:rename_provider[old_provider,new_provider]#Sourcebundle exec rake gitlab:ldap:rename_provider[old_provider,new_provider] RAILS_ENV=production 一般维护和自检收集有关GitLab及其运行的系统的信息 123456#Omnibussudo gitlab-rake gitlab:env:info#Sourcebundle exec rake gitlab:env:info RAILS_ENV=production 检查GitLab配置 运行以下rake tasks： gitlab:gitlab_shell:check gitlab:gitaly:check gitlab:sidekiq:check gitlab:app:check 它将检查每个组件是否已根据安装指南进行设置，并针对发现的问题提出修复建议。 123456#Omnibussudo gitlab-rake gitlab:check#Sourcebundle exec rake gitlab:check RAILS_ENV=production 重建authorized_keys文件 在某些情况下，有必要重建authorized_keys文件。 1234567#Omnibussudo gitlab-rake gitlab:shell:setup#Sourcecd /home/git/gitlabsudo -u git -H bundle exec rake gitlab:shell:setup RAILS_ENV=production 清理Redis缓存 如果由于某种原因，仪表板显示错误信息，您可能希望清除Redis的缓存。 1234567#Omnibussudo gitlab-rake cache:clear#Sourcecd /home/git/gitlabsudo -u git -H bundle exec rake cache:clear RAILS_ENV=production 跟踪部署(Tracking Deployments) GitLab提供了一个Rake task，可以让您跟踪GitLab性能监控中的部署。 1234567#Omnibussudo gitlab-rake gitlab:track_deployment#Sourcecd /home/git/gitlabsudo -u git -H bundle exec rake gitlab:track_deployment RAILS_ENV=production 创建或修复Repo hook符号链接(Create or repair repository hooks symlink) 如果GitLab shell hooks 目录位置更改或其他情况导致hooks符号链接丢失或无效，请运行此Rake task以创建或修复符号链接。 1234567#Omnibussudo gitlab-rake gitlab:shell:create_hooks#Sourcecd /home/git/gitlabsudo -u git -H bundle exec rake gitlab:shell:create_hooks RAILS_ENV=production 检查TCP连接(Check TCP connectivity to a remote site) 1234567#Omnibussudo gitlab-rake gitlab:tcp_check[example.com,80]#Sourcecd /home/git/gitlabsudo -u git -H bundle exec rake gitlab:tcp_check[example.com,80] RAILS_ENV=production 用户管理User management 将用户作为开发人员添加到所有项目中 12345# omnibus-gitlabsudo gitlab-rake gitlab:import:user_to_projects[username@domain.tld]# installation from sourcebundle exec rake gitlab:import:user_to_projects[username@domain.tld] RAILS_ENV=production 将所有用户添加到所有项目 12345# omnibus-gitlabsudo gitlab-rake gitlab:import:all_users_to_all_projects# installation from sourcebundle exec rake gitlab:import:all_users_to_all_projects RAILS_ENV=production 将用户作为开发人员添加到所有组 12345# omnibus-gitlabsudo gitlab-rake gitlab:import:user_to_groups[username@domain.tld]# installation from sourcebundle exec rake gitlab:import:user_to_groups[username@domain.tld] RAILS_ENV=production 将所有用户添加到所有组 12345# omnibus-gitlabsudo gitlab-rake gitlab:import:all_users_to_all_groups# installation from sourcebundle exec rake gitlab:import:all_users_to_all_groups RAILS_ENV=production 保持对GitLab上活跃用户数量的严格控制 12#启用此设置可以阻止新用户被管理员清除(默认：false)block_auto_created_users: false 禁用所有用户的双重验证（2FA） 123456# omnibus-gitlabsudo gitlab-rake gitlab:two_factor:disable_for_all_users# installation from sourcebundle exec rake gitlab:two_factor:disable_for_all_users RAILS_ENV=production 轮询双重认证的加密秘钥(Rotate Two-factor Authentication (2FA) encryption key) GitLab存储secret data，使双重认证(2FA)能够在加密的数据库列中工作。此数据的加密密钥称为otp_key_base，存储在config/secrets.yml中。如果该文件被泄露，但个别2FA secret 没有泄露，则可以使用新的加密密钥重新加密这些机密。这允许您更改泄漏的密钥，而不强制所有用户更改其2FA详细信息。 首先，查找old key。这是在config/secrets.yml文件中，但请确保您正在使用生产部分： 12production: otp_key_base: ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff 生成new secret 12345# omnibus-gitlabsudo gitlab-rake secret# installation from sourcebundle exec rake secret RAILS_ENV=production 现在您需要停止GitLab服务器，备份现有的secrets file并更新数据库： 12345678910# omnibus-gitlabsudo gitlab-ctl stopsudo cp config/secrets.yml config/secrets.yml.baksudo gitlab-rake gitlab:two_factor:rotate_key:apply filename=backup.csv old_key=&lt;old key&gt; new_key=&lt;new key&gt;# installation from sourcesudo /etc/init.d/gitlab stopcp config/secrets.yml config/secrets.yml.bakbundle exec rake gitlab:two_factor:rotate_key:apply filename=backup.csv old_key=&lt;old key&gt; new_key=&lt;new key&gt; RAILS_ENV=production 最后，将config/secrets.yml中的otp_key_base更改为&lt;new key&gt;并重新启动。再次，确保您在生产部分中运行： 12345678910#首先更改key#之后重启# omnibus-gitlabsudo gitlab-ctl start# installation from sourcesudo /etc/init.d/gitlab start 如果出现问题，你也可以进行回滚。 Webhooks为所有项目添加webhook 123456# omnibus-gitlabsudo gitlab-rake gitlab:web_hook:add URL="http://example.com/hook"# source installationsbundle exec rake gitlab:web_hook:add URL="http://example.com/hook" RAILS_ENV=production 为给定NAMESPACE中的项目添加webhook 123456# omnibus-gitlabsudo gitlab-rake gitlab:web_hook:add URL="http://example.com/hook" NAMESPACE=acme# source installationsbundle exec rake gitlab:web_hook:add URL="http://example.com/hook" NAMESPACE=acme RAILS_ENV=production 从所有项目中删除webhook 123456# omnibus-gitlabsudo gitlab-rake gitlab:web_hook:rm URL="http://example.com/hook"# source installationsbundle exec rake gitlab:web_hook:rm URL="http://example.com/hook" RAILS_ENV=production 从给定NAMESPACE中的项目中删除webhook： 123456# omnibus-gitlabsudo gitlab-rake gitlab:web_hook:rm URL="http://example.com/hook" NAMESPACE=acme# source installationsbundle exec rake gitlab:web_hook:rm URL="http://example.com/hook" NAMESPACE=acme RAILS_ENV=production 列出所有webhooks： 123456# omnibus-gitlabsudo gitlab-rake gitlab:web_hook:list# source installationsbundle exec rake gitlab:web_hook:list RAILS_ENV=production 列出给定NAMESPACE中项目的webhooks 1234# omnibus-gitlabsudo gitlab-rake gitlab:web_hook:list NAMESPACE=acme# source installationsbundle exec rake gitlab:web_hook:list NAMESPACE=acme RAILS_ENV=production 批量导入git库Import of git repositories in bulk 注意： The owner of the project will be the first admin The groups will be created as needed, including subgroups The owner of the group will be the first admin Existing projects will be skipped Projects in hashed storage may be skipped The existing Git repos will be moved from disk 如何使用： 创建一个新文件夹以从中导入您的Git Repo： 12#注意owner, group, permissionsudo -u git mkdir /var/opt/gitlab/git-data/repository-import-&lt;date&gt;/new_group 将Repo复制到新创建的文件夹中在任何子文件夹中找到的任何.git Repo 都将作为项目导入。将根据需要创建group 12345sudo cp -r /old/git/foo.git /var/opt/gitlab/git-data/repository-import-&lt;date&gt;/new_group/# Do this once when you are done copying git repositoriessudo chown -R git:git /var/opt/gitlab/git-data/repository-import-&lt;date&gt; 运行命令 1234567#Omnibussudo gitlab-rake gitlab:import:repos['/var/opt/gitlab/git-data/repository-import-&lt;date&gt;']#Sourcecd /home/git/gitlabsudo -u git -H bundle exec rake gitlab:import:repos['/var/opt/gitlab/git-data/repository-import-&lt;date&gt;'] RAILS_ENV=production 从hashed storage导入Repo 背景： 传统存储中的项目具有一个目录结构，该结构反映了GitLab中的完整项目路径，包括其命名空间结构。Repo导入程序利用此信息将项目导入其适当的位置。每个项目及其父命名空间都有名称。但是，散列存储中的项目的目录结构不包含此信息。这有利于各种原因，尤其是改进的性能和数据完整性。 GitLab v10.3 or earlier: 不支持导入hashed storage GitLab v10.4 and later: 为了支持从散列存储导入裸存储库，GitLab将每个存储库的完整项目路径存储在git Repo 配置文件的特殊部分中。 如果Repo发生以下事件，则可导入： Created Migrated to hashed storage Renamed Transferred to another namespace Ancestor renamed Ancestor transferred to another namespace 满足以下内容，Repo无法导入： It was created in GitLab 10.3 or earlier. It was not renamed, transferred, or migrated to hashed storage in GitLab 10.4 and later. Its ancestor namespaces were not renamed or transferred in GitLab 10.4 and later. 你也可以手动使用 Rails console 执行此操作： 1234567891011# start a Rails console for GitLabsudo gitlab-rails consoleproject = Project.find_by_full_path(&apos;gitlab-org/gitlab-ce&apos;)project.write_repository_config#在Rails控制台会话中，运行以下命令以迁移所有命名空间的项目namespace = Namespace.find_by_full_path(&apos;gitlab-org&apos;)namespace.send(:write_projects_repository_config) 上传Uploads 注意： 上传表示可以作为单个文件(single file)发送到GitLab的所有用户数据。例如，头像和附注的附件是上传的。上传是GitLab功能的组成部分，因此无法禁用。 使用本地存储(Local Storage)这是默认选项。 12345678910111213141516171819202122#Omnibus#上传默认存放位置： /var/opt/gitlab/gitlab-rails/uploads/-/system#修改vi /etc/gitlab/gitlab.rbgitlab_rails['uploads_storage_path'] = "/mnt/storage/"gitlab_rails['uploads_base_dir'] = "uploads"#Source#默认存放位置：/home/git/gitlab/public/uploads/-/system#修改vi /home/git/gitlab/config/gitlab.ymluploads: storage_path: /mnt/storage base_dir: uploads 使用对象存储(Object Storage) 如果不想使用本地存储，可使用对象存储(华为云、阿里云、腾讯云、aws…)。GitLab有几个选项，其它云服务商的配置请参考他们的文档。 uploads_object_store_ Description Default enabled Enable/disable object storage false remote_directory The bucket name where Uploads will be stored direct_upload Set to true to enable direct upload of Uploads without the need of local shared storage. Option may be removed once we decide to support only single storage for all files. false background_upload Set to false to disable automatic upload. Option may be removed once upload is direct to S3 true proxy_download Set to true to enable proxying all files served. Option allows to reduce egress traffic as this allows clients to download directly from remote storage instead of proxying all data false connection Various connection options described below ##### 迁移上传文件 Migrate Uploads 迁移到对象存储(Migrate to Object Storage) 为GitLab的上传配置对象存储之后，您可以使用此任务将现有的上传文件从本地存储迁移到远程存储。 All-in-one rake taskGitLab提供了一个 wrapper rake task，可以将所有上传的文件（头像，徽标，附件，图标等）一次性迁移到对象存储。在此之下，它会调用各个rake task来逐个迁移属于这个类别的文件。 123456#Omnibusgitlab-rake "gitlab:uploads:migrate:all"#Sourcesudo RAILS_ENV=production -u git -H bundle exec rake gitlab:uploads:migrate:all Individual rake tasks如果您已经运行了前面提到的rake task，则无需像自动完成那样运行这些单独的rake task。 rake task使用3个参数来查找要迁移的上传： Parameter Type Description uploader_class string Type of the uploader to migrate from model_class string Type of the model to migrate from mount_point string/symbol Name of the model’s column on which the uploader is mounted on. 注意：这些参数主要是GitLab结构的内部参数，您可能需要在下面引用任务列表。此任务还接受一些可用于覆盖某些值的环境变量： Variable Type Description BATCH integer Specifies the size of the batch. Defaults to 200. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#Omnibus# gitlab-rake gitlab:uploads:migrate[uploader_class, model_class, mount_point]# Avatarsgitlab-rake "gitlab:uploads:migrate[AvatarUploader, Project, :avatar]"gitlab-rake "gitlab:uploads:migrate[AvatarUploader, Group, :avatar]"gitlab-rake "gitlab:uploads:migrate[AvatarUploader, User, :avatar]"# Attachmentsgitlab-rake "gitlab:uploads:migrate[AttachmentUploader, Note, :attachment]"gitlab-rake "gitlab:uploads:migrate[AttachmentUploader, Appearance, :logo]"gitlab-rake "gitlab:uploads:migrate[AttachmentUploader, Appearance, :header_logo]"# Favicongitlab-rake "gitlab:uploads:migrate[FaviconUploader, Appearance, :favicon]"# Markdowngitlab-rake "gitlab:uploads:migrate[FileUploader, Project]"gitlab-rake "gitlab:uploads:migrate[PersonalFileUploader, Snippet]"gitlab-rake "gitlab:uploads:migrate[NamespaceFileUploader, Snippet]"gitlab-rake "gitlab:uploads:migrate[FileUploader, MergeRequest]"#Source#Use RAILS_ENV=production for every task.# sudo -u git -H bundle exec rake gitlab:uploads:migrate# Avatarssudo -u git -H bundle exec rake "gitlab:uploads:migrate[AvatarUploader, Project, :avatar]"sudo -u git -H bundle exec rake "gitlab:uploads:migrate[AvatarUploader, Group, :avatar]"sudo -u git -H bundle exec rake "gitlab:uploads:migrate[AvatarUploader, User, :avatar]"# Attachmentssudo -u git -H bundle exec rake "gitlab:uploads:migrate[AttachmentUploader, Note, :attachment]"sudo -u git -H bundle exec rake "gitlab:uploads:migrate[AttachmentUploader, Appearance, :logo]"sudo -u git -H bundle exec rake "gitlab:uploads:migrate[AttachmentUploader, Appearance, :header_logo]"# Faviconsudo -u git -H bundle exec rake "gitlab:uploads:migrate[FaviconUploader, Appearance, :favicon]"# Markdownsudo -u git -H bundle exec rake "gitlab:uploads:migrate[FileUploader, Project]"sudo -u git -H bundle exec rake "gitlab:uploads:migrate[PersonalFileUploader, Snippet]"sudo -u git -H bundle exec rake "gitlab:uploads:migrate[NamespaceFileUploader, Snippet]"sudo -u git -H bundle exec rake "gitlab:uploads:migrate[FileUploader, MergeRequest]" 操作Performing Operations in GitLabOperations: Keeping GitLab up and running (clean up Redis sessions, moving repositories, Sidekiq MemoryKiller, Unicorn) 清理陈旧的Redis回话Cleaning up stale Redis sessions 在GitLab v7.3之前，用户会话不会自动从Redis expire。 移动库Moving repositories 将GitLab管理的所有库移动到另一个文件系统或另一个服务器。 Sidekiq MemoryKiller配置Sidekiq MemoryKiller以重启Sidekiq。 GitLab Rails应用程序代码有内存泄漏。对于Web请求，使用unicorn-worker-killer可以管理这个问题，在需要时会在请求之间重新启动Unicorn工作进程。 Sidekiq MemoryKiller对GitLab用于处理后台作业的Sidekiq进程应用相同的方法。 与自从GitLab 6.4以来默认启用的所有GitLab安装的unicorn-worker-killer不同，Sidekiq MemoryKiller默认仅对Omnibus软件包启用。原因是MemoryKiller依赖于Runit在内存引发的关闭后重新启动Sidekiq，并且来自源的GitLab安装并不都使用Runit或等效的。 使用默认设置，MemoryKiller将导致Sidekiq重启频率不超过每15分钟一次，重启会导致传入后台作业延迟大约一分钟。 配置MemoryKillerMemoryKiller使用环境变量进行控制。 SIDEKIQ_MEMORY_KILLER_MAX_RSS如果设置了此变量，并且其值大于0，则在每个Sidekiq作业之后，MemoryKiller将检查执行该作业的Sidekiq进程的RSS。如果Sidekiq进程的RSS（KB）超过SIDEKIQ_MEMORY_KILLER_MAX_RSS，则会触发延迟关闭。默认值可在gitlab.rb当中查看。 SIDEKIQ_MEMORY_KILLER_GRACE_TIME默认为900s（15min）。当触发关闭时，Sidekiq进程将继续正常工作15分钟。 SIDEKIQ_MEMORY_KILLER_SHUTDOWN_WAIT默认为30秒。当宽限时间到期时，MemoryKiller告诉Sidekiq停止接受新的工作，现有工作有30s去完成。之后，MemoryKiller告诉Sidekiq去关闭，外部监督机制必须重启Sidekiq UnicornUnderstand Unicorn and unicorn-worker-killer UnicornGitLab使用Unicorn，一个pre-forking的Ruby Web服务器来处理Web请求。Unicorn是一个用Ruby和C编写的Daemon，可以加载和运行Ruby on Rails Application(如GitLab CE/EE)。 Unicorn具有多进程(multi-process)架构，可以更好地利用可用的CPU核心并具有更强的容错能力。在启动时，Unicorn的Master进程使用GitLab应用程序代码加载一个干净的Ruby环境，然后生成继承这个干净的初始环境的Worker。 Master永远不会处理任何请求，而是留给Worker。操作系统网络堆栈对传入的请求进行排队，并在Worker之间分配它们。 Unicorn的主要可调参数(Tunables)是工作进程(work process)的数量和请求超时(request timeout)。 unicorn-worker-killer GitLab存在内存泄漏。这些内存泄漏在长期运行的进程中表现出来，如Unicorn worker。为了使这些内存泄漏易于管理，GitLab附带了unicorn-worker-killer。这个gem修补了Unicorn工作人员在每16个请求后进行内存自检。如果Unicorn工作程序的内存超过预设限制，则工作进程退出。然后Unicorn Master自动替换Wroker。这是一种处理内存泄漏的强大方法：Unicorn旨在处理“崩溃”的Worker，因此不会丢弃任何用户请求。unicorn-worker-killer gem旨在仅在请求之间终止工作进程，因此不会影响用户请求。 加快SSH操作Speed up SSH operations by Authorizing SSH users via a fast, indexed lookup to the GitLab database, and/or by doing away with user SSH keys stored on GitLab entirely in favor of SSH certificates. 快速查找数据库中的授权SSH密钥(Fast lookup of authorized SSH keys in the database) https://docs.gitlab.com/ce/administration/operations/fast_ssh_key_lookup.html 通过Open SSH查找(User lookup via OpenSSH’s AuthorizedPrincipalsCommand) https://docs.gitlab.com/ce/administration/operations/ssh_certificates.html 文件系统性能基准测试Filesystem Performance Benchmarking 文件系统性能对整体GitLab性能有很大影响，特别是对于读取或写入Git Repo的操作。 写性能(Write Performance) 1234567891011121314#进入Repo root pathcd /var/opt/gitlab/git-data/repositories/test/#创建一个空目录，便于测试后删除mkdir test &amp;&amp; cd test#运行命令time for i in &#123;0..1000&#125;; do echo 'test' &gt; "test$&#123;i&#125;.txt"; done#删除测试目录cd .. &amp;&amp; rm -rf ./test 以下是消耗时间范围： Rating Benchmark result Best Less than 10 seconds OK 10-18 seconds Poor 18-25 seconds Very poor Greater than 25 seconds 重启Restart GitLab: Learn how to restart GitLab and its components 依据安装方式，有几种不同的方式： Omnibus GitLab restartGitLab Workhorse Sidekiq PostgreSQL (if you are using the bundled one) NGINX (if you are using the bundled one) Redis (if you are using the bundled one) Mailroom Logrotate Omnibus GitLab reconfigure Source installation restart 12345678910111213141516171819202122#Omnibus GitLab restart#GitLabsudo gitlab-ctl restart#Nginx组件sudo gitlab-ctl restart nginx#其它组件类似#GitLab Statussudo gitlab-ctl status#Nginx组件状态sudo gitlab-ctl status nginx#其它组件类似#有时，组件在重新启动期间会超时，有时会卡住#你可以发送kill信号gitlab-ctl kill &lt;service&gt; 12345#Omnibus GitLab reconfigure#在更改/etc/gitlab/gitlab.rb之后，需要重新配置GitLabsudo gitlab-ctl reconfigure 1234#Installations from sourcesudo service gitlab restart 更新Updating GitLab GitLab版本和维护策略GitLab versions and maintenance policy: Understand GitLab versions and releases (Major, Minor, Patch, Security), as well as update recommendations. GitLab releases: Major version: 主要版本，重要内容 Minor verson: 次要版本，小功能 Patch number: 补丁，fix bug Security: 安全，临时添加的安全补丁 123456#栗子GitLab v10.5.7#10 represents major version#5 represents minor version#7 represents patch number 升级建议: GitLab鼓励每个人运行最新的稳定版本(latest stable release)，以确保您可以轻松升级到最安全，功能最丰富的GitLab体验。如果您无法遵循GitLab的月度发布周期，则需要考虑几种情况： 在一个主要版本(Major)中升级补丁版本(Patch)和次要版本(Minor)被认为是安全的。 12345678#Upgrade the patch version:8.9.0 -&gt; 8.9.78.9.0 -&gt; 8.9.1#Upgrade the minor version:8.9.4 -&gt; 8.12.39.2.3 -&gt; 9.5.5 升级主要版本需要多加小心。GitLab无法保证主要版本之间的升级是无缝的。GitLab建议您首先升级到主要版本中的最新可用次要版本。通过执行此操作，您可以解决可能会在下一个主要版本中更改行为的任何弃用消息。 Latest stable version Your version Recommended upgrade path Note 9.4.5 8.13.4 8.13.4 -&gt; 8.17.7 -&gt; 9.4.5 8.17.7 is the last version in version 8 10.1.4 8.13.4 8.13.4 -&gt; 8.17.7 -&gt; 9.5.10 -&gt; 10.1.4 8.17.7 is the last version in version 8, 9.5.10 is the last version in version 9 11.3.4 8.13.4 8.13.4 -&gt; 8.17.7 -&gt; 9.5.10 -&gt; 10.8.7 -&gt; 11.3.4 8.17.7 is the last version in version 8, 9.5.10 is the last version in version 9, 10.8.7 is the last version in version 10 更新GitLabUpdate GitLab: Update guides to upgrade your installation to a new version. 根据安装方式与GitLab版本，有多种升级方法： Omnibus packages Source installation Docker installation 使用软件包的方式进行更新Updating GitLab installed with the Omnibus GitLab package 特定版本: GitLab 11 GitLab 10 GitLab 8 GitLab 7 GitLab 6 升级方法: 使用官方Repo 手动下载Package 零停机更新(Zero downtime updates) 注意：这仅适用于GitLab 9.1.0或更高版本。 地址: https://docs.gitlab.com/omnibus/update/README.html#zero-downtime-updates 降级(Downgrading): 注意：本指南假定您在要还原的版本下创建了备份存档。 步骤： Download the package of a target version Stop GitLab Install the old package Reconfigure GitLab Restoring the backup Starting GitLab 其它项的更新 MySQL to PostgreSQL PostgreSQL to MySQL 更新失败之后从备份文件进行还原 CE-EEUpgrading or downgrading GitLab Upgrade from GitLab CE to GitLab EE Downgrade from GitLab EE to GitLab CE 平台集成GitLab platform integrations 集成MattermostMattermost是一个开源，可托管的聊天服务。它被设计为组织和公司的内部聊天，并且主要将自己作为Slack的替代品。 https://docs.gitlab.com/omnibus/gitlab-mattermost/ 集成PlantUMLPlantUML是一个开源工具，允许用户使用纯文本语言创建UML图表。 https://docs.gitlab.com/ce/administration/integration/plantuml.html 集成Web终端从GitLab的CI/CD环境中提供对部署到Kubernetes的应用程序的终端访问。随着Kubernetes集成的引入，GitLab获得了为Kubernetes集群存储和使用凭证的能力。它使用这些凭据的一个原因是提供对环境的Web终端的访问。 Web终端的体系结构及其工作原理： GitLab依靠用户提供他们自己的Kubernetes凭据，并在部署时适当地标记他们创建的pod。 当用户到环境的终端页面时，它们将被提供一个JavaScript应用程序，该应用程序将WebSocket连接返回给GitLab。 WebSocket在Workhorse中处理，而不是Rails Application Server。 Workhorse查询Rails的连接细节和用户权限; Rails使用Sidekiq在后台查询Kubernetes Workhorse充当用户浏览器和Kubernetes API之间的代理服务器，在两者之间传递WebSocket frame Workhorse定期轮询Rails，如果用户不再具有访问终端的权限，或者连接详细信息已更改，则终止WebSocket连接。 ps: WebSocket是一种在单个TCP连接上进行全双工通信的协议。 启用/禁用终端支持(Enabling and disabling terminal support) 当Web终端使用WebSockets时，Workhorse前面的每个HTTP/HTTPS反向代理都需要配置为将Connection和Upgrade头传递给链中的下一个，在GitLab v8.15+，这是默认选项，不需要你配置。 但是，如果在GitLab前面运行负载均衡器，则可能需要对配置进行一些更改: Apache NGINX HAProxy Varnish Workhorse不会让WebSocket请求通过non-WebSocket端点，因此可以安全地在全局范围内启用对这些Header的支持。如果您宁愿使用较窄的规则集，则可以将其限制为以/terminal.ws结尾的URL。 如果您想在GitLab中禁用Web终端支持，只需停止在链中的第一个HTTP反向代理中传递Connection和Upgrade逐跳Header。对于大多数用户来说，这将是与Omnibus GitLab捆绑在一起的NGINX服务器： 123456#在gitLab.rb中找到 nginx[&apos;proxy_set_headers&apos;]#移除或注释 Connection和Upgrade# nginx[&apos;proxy_set_headers&apos;] = &#123;# &quot;Upgrade&quot; =&gt; &quot;$http_upgrade&quot;,# &quot;Connection&quot; =&gt; &quot;$connection_upgrade&quot; 限制Websocket连接时间(Limiting WebSocket connection time) ps: GitLab v8.17+ 终端会话使用长期连接。默认情况下，这些可能永远持续下去。如果从可伸缩性或安全性角度发现这是不受欢迎的，您可以在GitLab实例的Admin区域中配置最长会话时间。 用户设置和权限User settings and permissions LibravatarUse Libravatar instead of Gravatar for user avatars. https://docs.gitlab.com/ce/customization/libravatar.html 注册限制Sign-up restrictions: block email addresses of specific domains, or whitelist only specific domains. 您可以通过管理区域中的“应用程序设置”阻止特定域的电子邮件地址，或仅将某些特定域列入白名单。 Whitelist email domains Blacklist email domains 白名单和黑名单支持通配符。如可对白名单加自己信任的域(如：company.com)，再把所有加入黑名单(如： *) 访问限制Access restrictions: Define which Git access protocols can be used to talk to GitLab (SSH, HTTP, HTTPS). 启用Git访问协议 SSH 和 HTTP(s) 仅SSH 仅HTTP(s) 认证和授权Authentication/Authorization: Enforce 2FA, configure external authentication with LDAP, SAML, CAS and additional Omniauth providers. https://docs.gitlab.com/ce/topics/authentication/index.html 传入电子邮件Incoming email: Configure incoming emails to allow users to reply by email, create issues by email and merge requests by email, and to enable. GitLab有几个基于接收传入电子邮件的功能： Reply by Email: 允许GitLab用户通过回复notification电子邮件对issues发表comment并merge request New issue by email: 允许GitLab用户通过向用户特定的电子邮件地址发送电子邮件来创建新Issue New merge request by email: 允许GitLab用户通过向用户特定的电子邮件地址发送电子邮件来创建新的 merge request 依赖(Requirements)： Email sub-addressing Dedicated email address Catch-all mailbox 配置： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#Omnibus#在gitlab.rb中找到incoming_email，启用该功能并填写IMAP信息和账户信息### Reply by email###! Allow users to comment on issues and merge requests by replying to###! notification emails.###! Docs: https://docs.gitlab.com/ce/administration/reply_by_email.html# gitlab_rails['incoming_email_enabled'] = true#### Incoming Email Address####! The email address including the `%&#123;key&#125;` placeholder that will be replaced####! to reference the item being replied to.####! **The placeholder can be omitted but if present, it must appear in the####! "user" part of the address (before the `@`).**# gitlab_rails['incoming_email_address'] = "gitlab-incoming+%&#123;key&#125;@gmail.com"#### Email account username####! **With third party providers, this is usually the full email address.**####! **With self-hosted email servers, this is usually the user part of the####! email address.**# gitlab_rails['incoming_email_email'] = "gitlab-incoming@gmail.com"#### Email account password# gitlab_rails['incoming_email_password'] = "[REDACTED]"#### IMAP Settings# gitlab_rails['incoming_email_host'] = "imap.gmail.com"# gitlab_rails['incoming_email_port'] = 993# gitlab_rails['incoming_email_ssl'] = true# gitlab_rails['incoming_email_start_tls'] = false#### Incoming Mailbox Settings####! The mailbox where incoming mail will end up. Usually "inbox".# gitlab_rails['incoming_email_mailbox_name'] = "inbox"####! The IDLE command timeout.# gitlab_rails['incoming_email_idle_timeout'] = 60#重载配置和重启sudo gitlab-ctl reconfiguresudo gitlab-ctl restart#验证邮箱配置sudo gitlab-rake gitlab:incoming_email:check 项目设置Project settings Repo检查Repository checks: Periodic Git repository checks. 在GitLab 8.7中引入。它默认关闭，因为它仍会导致过多的误报。 Git有一个内置机制git fsck，用于验证提交到存储库的所有数据的完整性。GitLab管理员可以通过管理面板下的项目页面触发对项目的检查。检查以异步方式运行，因此可能需要几分钟才能在项目管理页面上显示检查结果。如果检查失败，您可以在repocheck.log下的管理日志页面上看到它们的输出。 定期检查(Periodic checks) 启用后，GitLab会定期对所有项目存储库和wiki存储库运行存储库检查，以检测数据损坏。一个项目每月检查不超过一次。如果任何项目未通过其存储库检查，则所有GitLab管理员都将收到有关该情况的电子邮件通知。\ 禁用 可在管理员面板上禁用定期检查。 检查失败 如果某个存储库检查失败，你应该在repocheck.log查找错误信息: 管理员面板 磁盘日志文件 /var/log/gitlab/gitlab-rails for Omnibus installations /home/git/gitlab/log for installations from source 如果由于某种原因定期检查导致大量错误警报，您可以在管理员设置里来选择清除所有存储库检查状态。 Repo存储路径Repository storage paths: Manage the paths used to store repositories. GitLab允许您定义多个存储库存储路径，以在多个挂载点之间分配存储负载。 注意: 您必须至少有一个名为default的存储路径 路径以键值对进行定义 目标目录及其任何子路径都不能是符号链接 目标目录不能是制定路径的子目录，因为不能嵌套 123456789101112#栗子default: path: /mnt/git-storage-1storage2: path: /mnt/git-storage-2#错误栗子default: path: /mnt/git-storage-1storage2: path: /mnt/git-storage-1/git-storage-2 # &lt;- NOT OK because of nesting 配置GitLab 注意:为了使备份正常工作，存储路径不能是挂载点，GitLab用户应具有路径父目录的正确权限。在Omnibus GitLab中，这是自动处理的，但对于Source Code安装，您应该格外小心。 12345678910gitlab.rbgit_data_dirs(&#123; &quot;default&quot; =&gt; &#123; &quot;path&quot; =&gt; &quot;/var/opt/gitlab/git-data&quot; &#125;, &quot;nfs&quot; =&gt; &#123; &quot;path&quot; =&gt; &quot;/mnt/nfs/git-data&quot; &#125;, &quot;cephfs&quot; =&gt; &#123; &quot;path&quot; =&gt; &quot;/mnt/cephfs/git-data&quot; &#125;&#125;)#Omnibus将存储库数据存储在git-data/repositories子目录下 选择新项目存储库的存储位置设置了多个存储路径后，可在Admin下Application Setting选择新项目的存储路径。从GitLab 8.13.4开始，可以选择多个路径。新项目将随机放置在其中一个选定路径上。 Repo存储靶任务Repository storage rake tasks: A collection of rake tasks to list and migrate existing projects and attachments associated with it from Legacy storage to Hashed storage 以下靶任务(rake task)，可用于帮助您列出现有项目以及与之关联的附件，从旧存储到新的Hashed存储类型。 将现有项目迁移到哈希存储Migrate existing projects to Hashed storage 在迁移现有项目之前，还应为新项目启用哈希/散列存储。 1234567#Omnibussudo gitlab-rake gitlab:storage:migrate_to_hashed# to migrate any non migrated project from ID 20 to 50.export ID_FROM=20 export ID_TO=50 你可在Admin &gt; Monitoring &gt; Background jobs里面进行查看。 在它达到零之后，您可以通过运行以下命令来确认已迁移每个项目。如果您认为有必要，可以再次运行此迁移脚本以安排缺少的项目。 列出旧版存储的项目List projects on Legacy storage 12345678#获取旧项目存储摘要#Ominibussudo gitlab-rake gitlab:storage:legacy_projects#列出项目使用的旧存储#Ominibussudo gitlab-rake gitlab:storage:list_legacy_projects 列出哈希散列上的项目List projects on Hashed storage 12345678#使用哈希存储的项目的简单摘要#Ominibussudo gitlab-rake gitlab:storage:hashed_projects#列出项目使用的散列存储#Ominibussudo gitlab-rake gitlab:storage:list_hashed_projects 列出旧版存储上的附件List attachments on Legacy storage 12345678#使用旧版存储的附件的简单摘要#Ominibussudo gitlab-rake gitlab:storage:legacy_attachments#列出使用旧版存储的项目附件#Ominibussudo gitlab-rake gitlab:storage:list_legacy_attachments ####列出哈希存储上的附件 List attachments on Hashed storage 12345678#使用哈希存储的附件的简单摘要#Ominibussudo gitlab-rake gitlab:storage:hashed_attachments#列出使用哈希存储的项目附件#Ominibussudo gitlab-rake gitlab:storage:list_hashed_attachments 限制Repo大小Limit repository size: Set a hard limit for your repositories’ size Introduced in GitLab Enterprise Edition 8.12. GitLab实例中的存储库可能会快速增长，尤其是在使用LFS时。它们的大小可以指数级增长，并且可以非常快速地耗尽您的存储设备。为了避免这种情况发生，您可以为存储库的大小设置硬限制。可以全局，按组或按项目设置此限制，每个项目限制具有最高优先级。 只有GitLab管理员才能设置这些限制。将限制设置为0表示没有限制。 到目前为止，无法检查新项目的第一次推送的大小，因此第一次推送将允许您上传超过限制规定，但每次后续推送都将被拒绝。但是，LFS对象可以在第一次推送时检查，如果它们的大小总和超过允许的最大存储库大小，则会被拒绝。 CIContinuous Integration settings 启用/禁用CICDEnable/disable GitLab CI/CD: Enable or disable GitLab CI/CD for your instance. 您可以在站点范围内禁用GitLab CI/CD，方法是修改配置文件。 有两点需要注意： 禁用GitLab CI/CD只会影响新创建的项目。在此修改之前启用它的项目将像以前一样工作 即使禁用了GitLab CI/CD，用户仍然可以在项目设置中启用它 123456789101112131415161718192021#Sourcevim gitlab.yml## Default project features settings, set build to falsedefault_projects_features: issues: true merge_requests: true wiki: true snippets: false builds: false#Omnibus/etc/gitlab/gitlab.rbgitlab_rails[&apos;gitlab_default_projects_features_builds&apos;] = false#重载sudo gitlab-ctl reconfigure CI/CD admin设置GitLab CI/CD admin settings: Enable or disable DevOps site-wide and define the artifacts’ max size and expiration time. 在以管理员登录GitLab Web UI，在Admin area里面，您将找到Auto DevOps，Runners和job artifacts的设置。 Auto DevOps 要为所有项目启用/禁用 Auto DevOps： 进入Admin area &gt; Settings &gt; Continuous Integration and Deployment 检查Default to Auto DevOps pipeline for all projects 可为Auto DevOps添加基本域 保存更改 从现在开始，每个现有项目和新创建的项目都没有.gitlab-ci.yml，将使用Auto DevOps pipeline。 Maximum artifacts size 可为GitLab实例设置[job artifacts][art-yml]的最大大小。它的单位为MB，默认为每个Job设置为100MB。GitLab.com上它被设置为1GB。 Default artifacts expiration 可为GitLab实例的job artifacts设置默认到期时间。GitLab.com它never expire。这里面的设置是按Job设置的，可在.gitlab-ci.yml中覆盖它。将其设置为0表示禁用过期，默认单位是秒。 Archive jobs 归档作业通过删除作业的一些功能（运行作业所需的元数据）来减少系统上的CI/CD占用空间，但是为了审计目的而保留跟踪(traces)和工件(artifacts)。一旦该时间过去，作业将被存档，不再能够重试。让它变空成为永不过期的工作(它必须不少于1天)。 Jobs artifactsJob artifacts: Enable, disable, and configure job artifacts (a set of files and directories which are outputted by a job when it completes successfully). Artifacts是在成功完成后附加到作业的文件和目录的列表。此功能在所有的安装中默认启用。 禁用 job artifacts 1234567#Omnibus#/etc/gitlab/gitlab.rbgitlab_rails['artifacts_enabled'] = false#重载 存储 job artifacts成功完成作业后，GitLab Runner将job artifacts的存档上传到GitLab。 使用本地存储 12#默认路径# gitlab_rails[&apos;artifacts_path&apos;] = &quot;/var/opt/gitlab/gitlab-rails/shared/artifacts&quot; 使用对象存储 Setting Description Default enabled Enable/disable object storage false remote_directory The bucket name where Artifacts will be stored direct_upload Set to true to enable direct upload of Artifacts without the need of local shared storage. Option may be removed once we decide to support only single storage for all files. false background_upload Set to false to disable automatic upload. Option may be removed once upload is direct to S3 true proxy_download Set to true to enable proxying all files served. Option allows to reduce egress traffic as this allows clients to download directly from remote storage instead of proxying all data false connection Various connection options described below - Expiring artifacts如果工件使用了失效日期，则在该日期过后立即标记为删除。文件由expire_build_artifacts_worker cron job清理，该作业由Sidekiq每小时的第50分钟（50 * * * *）运行。 更改工件过期的默认调度计划： 12345#Omnibus#/etc/gitlab/gitlab.rbgitlab_rails['expire_build_artifacts_worker_cron'] = "50 * * * *"#重配 依赖验证(dependencies validation)要禁用依赖验证，可在Rail Console设置。 1234567#Omnibus#rails consolesudo gitlab-rails console#禁用 Feature.enable(&apos;ci_disable_validates_dependencies&apos;) 实施细节当GitLab收到工件存档时，GitLab Workhorse也会生成存档元数据文件。此元数据文件描述了工件存档本身中的所有条目。元数据文件采用二进制格式，具有额外的GZIP压缩。 GitLab不解压工件存档以节省Disk，Mem和I/O。它改为检查包含所有相关信息的元数据文件。当存在大量工件或存档是非常大的文件时，这一点尤为重要。单击特定文件时，GitLab Workhorse会从存档中提取它并开始下载。此实现可节省空间，内存和磁盘I/O. Job tracesJob traces: Information about the job traces (logs). 作业跟踪由GitLab Runner在处理作业时发送。您可以在job, pipeline, email notification查看工作踪迹。 数据流Data flow 通常，作业踪迹中有两种状态： 实时跟踪(live trace) 存档跟踪(archived trace) Phase State Condition Data flow Stored path 1: patching Live trace When a job is running GitLab Runner =&gt; Unicorn =&gt; file storage #{ROOT_PATH}/builds/#{YYYY_mm}/#{project_id}/#{job_id}.log 2: overwriting Live trace When a job is finished GitLab Runner =&gt; Unicorn =&gt; file storage #{ROOT_PATH}/builds/#{YYYY_mm}/#{project_id}/#{job_id}.log 3: archiving Archived trace After a job is finished Sidekiq moves live trace to artifacts folder #{ROOT_PATH}/shared/artifacts/#{disk_hash}/#{YYYY_mm_dd}/#{job_id}/#{job_artifact_id}/job.log 4: uploading Archived trace After a trace is archived Sidekiq moves archived trace to object storage (if configured) #{bucket_name}/#{disk_hash}/#{YYYY_mm_dd}/#{job_id}/#{job_artifact_id}/job.log 修改工作踪迹本地位置Changing the job traces local location 更改存储Job Log的位置： 123456789101112#Omnibus#/etc/gitlab/gitlab.rbgitlab_ci[&apos;builds_directory&apos;] = &apos;/mnt/to/gitlab-ci/builds&apos;#Source#/home/git/gitlab/config/gitlab.ymlgitlab_ci: # The location where build traces are stored (default: builds/). # Relative paths are relative to Rails.root. builds_path: path/to/builds/ 将踪迹上传到对象存储Uploading traces to object storage 存档的踪迹被视为工作工件。因此，在设置对象存储集成时，作业踪迹会自动与其他作业工件一起迁移到它。 #### 如何归档旧的作业踪迹文件 How to archive legacy job trace files 旧的作业踪迹指的是在GitLab 10.5之前创建的，未定期归档的作业踪迹。那么你可能需要手动进行操作： 123456789#执行此任务后，GitLab实例将Sidekiq作业（异步进程）排队，以将作业跟踪文件从本地存储迁移到对象存储。完成所有迁移工作可能需要一些时间。gitlab-rake gitlab:traces:archivesudo gitlab-rails console#如果计数变为零，则归档过程完成[1] pry(main)&gt; Sidekiq::Stats.new.queues['pipeline_background:archive_trace'] =&gt; 100 如何将归档的作业踪迹迁移到对象存储How to migrate archived job traces to object storage 在GitLab 11.3中引入 如果作业踪迹已存档到本地存储中，并且您希望将这些踪迹迁移到对象存储： 确保已启用Job Artifacts的对象存储集成 执行此命令: gitlab-rake gitlab:traces:migrate 如何删除作业踪迹How to remove job traces 没有办法自动使旧的作业日志过期，但如果它们占用太多空间，则可以安全地删除它们。如果手动删除日志，则UI中的作业输出将为空。 新的实时踪迹架构New live trace architecture 在GitLab 10.4中引入。在GitLab 11.0中宣布的一般可用性。此功能默认禁用。 这是一个详细的数据流： GitLab Runner picks a job from GitLab GitLab Runner sends a piece of trace to GitLab GitLab appends the data to Redis Once the data in Redis reach 128KB, the data is flushed to a persistent store (object storage or the database). The above steps are repeated until the job is finished. Once the job is finished, GitLab schedules a Sidekiq worker to archive the trace. The Sidekiq worker archives the trace to object storage and cleans up the trace in Redis and a persistent store (object storage or the database) Enabling live trace 123456789101112131415161718#console# Omnibus GitLabgitlab-rails console# Installation from sourcecd /home/git/gitlabsudo -u git -H bin/rails console RAILS_ENV=production#检查实时踪迹Feature.enabled?(&apos;ci_enable_live_trace&apos;)#启用Feature.enable(&apos;ci_enable_live_trace&apos;)#禁用Feature.disable(&apos;ci_enable_live_trace&apos;) 潜在影响(Potential implications) 在某些情况下，将数据存储在Redis上可能会导致数据丢失： Case 1: When all data in Redis are accidentally flushed可以通过重新发送追踪来恢复实时踪迹。未归档的已完成作业的实时踪迹将丢失踪迹数据的最后一部分。 Case 2: When Sidekiq workers fail to archive目前，Redis中的所有踪迹数据将在一周后删除。如果Sidekiq Worker无法在过期之前完成，则踪迹数据的一部分将丢失。 可能出现的另一个问题是它可能占用Redis实例上的所有内存如果作业数为1000，则消耗128MB（128KB*1000）。 配置GitLab RunnerConfiguring GitLab RunnersRegister Shared and specific Runners: Learn how to register and configure Shared and specific Runners to your own instance. 在GitLab CI中，Runners运行.gitlab-ci.yml中定义的代码。它们是隔离(虚拟)机器，通过GitLab CI的协调器API获取作业。Runner可以特定于某个项目，也可以为GitLab CI中的任何项目提供服务。为所有项目提供服务的Runner称为shared Runner。理想情况下，GitLab Runner不应与GitLab安装在同一台机器上。你可以为GitLab实例配置多个Runner。 Runner的状态Shared, specific and group Runners 安装Runner后，您可以将其注册为共享的或特定的。如果您具有GitLab实例的管理员访问权限，则只能注册shared Runner。 每个Runner可处于一下状态； shared: Runner runs jobs from all unassigned projects group: Runner runs jobs from all unassigned projects in its group specific: Runner runs jobs from assigned projects locked: Runner cannot be assigned to other projects paused: Runner will not receive any new jobs 注册共享的RunnerRegistering a shared Runner 如果您是GitLab实例的管理员，则只能注册shared Runner。 在Web UI -&gt; Admin Area -&gt; Runner里面用它提供的URL和Token进行Runner注册。 默认情况下启用shared runner，但可在 Admin Area -&gt; CI/CD里面禁用。 注册特定的RunnerRegistering a specific Runner 注册特定的Runner有两种方式： 使用project registration token来注册Runner 将shared Runner 转换为 specific Runner(单向，仅限管理员) 使用项目Token注册特定的Runner：创建一个没有GitLab实例管理员权限的特定Runner。进入此项目， Setting -&gt; CI/CD -&gt; Runner进行配置。 注册一个组RunnerRegistering a group Runner 创建一个group Runner，然后访问词组，Setting -&gt; CI/CD -&gt; Runner。 将共享的Runner特定化(Making an existing shared Runner specific) 如果您是GitLab实例的管理员，则可以将任何shared Runner转换为specific Runner。请记住，这是一种单向转换，不能逆向转换。 Admin Ares -&gt; Overview -&gt; Runner -&gt; 需要的Runner 对项目启用Restrict projects for this Runner 这样，shared Runner便特定于某些项目。 之后此Runner的状态便发生了改变。 锁定特定RunnerLocking a specific Runner from being enabled for other projects 您可以配置Runner以将其专门分配给一个项目。当Runner以这种方式锁定时，不能再为其他项目启用它。 Visit your project’s Settings &gt; CI/CD Find the Runner you wish to lock/unlock and make sure it’s enabled Click the pencil button Check the Lock to current projects option Click Save changes for the changes to take effect 将Runner分配给另外的项目Assigning a Runner to another project 如果您是分配了特定Runner的项目的维护人员，并且Runner未仅锁定到该项目(not locked only to that project)，则还可以在具有Maintainer权限的任何其他项目上启用Runner。 请注意，如果您没有将特定的Runner锁定到特定项目，那么您项目中具有Maintainer角色的任何用户都可以将Runner分配给另一个任意项目，而无需您的授权，因此请谨慎使用。 启用： Visit your project’s Settings &gt; CI/CD Find the Runner you wish to enable/disable Click Enable for this project or Disable for this project 管理员可以为项目启用/禁用特定的Runner： Navigate to Admin &gt; Runners Find the Runner you wish to enable/disable Click edit on the Runner Click Enable or Disable on the project 受保护的RunnerProtected Runners 在GitLab 10.0中引入。 你可以保护Runner免于泄露敏感信息。每当Runner受到保护时，Runner仅选择在受保护的分支或受保护的标签上创建的作业，并忽略其他作业。 protect/unprotect: Visit your project’s Settings &gt; CI/CD Find a Runner you want to protect/unprotect and make sure it’s enabled Click the pencil button besides the Runner name Check the Protected option Click Save changes for the changes to take effect 手动清理Runner缓存Manually clearing the Runners cache Navigate to your project’s CI/CD &gt; Pipelines page. Click on the Clear Runner caches button to clean up the cache. On the next push, your CI/CD job will use a new cache. 共享Runner如何选择作业How shared Runners pick jobs 共享的Runner遵守我们称之为合理使用的进程队列(process queue)。公平的使用算法尝试从当前在shared Runners上运行的作业数量最少的项目中将作业分配给shared Runners。 有效地使用共享RunnerUsing shared Runners effectively 如果您打算使用共享的Runners，您应该记住几件事。 使用tags 您必须设置一个Runner才能运行所有不同类型的作业，它可能会在共享的项目中遇到。如果不使用tags，则对于大型项目可能会出现问题。通过为Runner打tag来标记它可以处理的作业类型，您可以确保shared Runners只运行它们配备的作业(only run the jobs they are equipped to run)。 例如，在GitLab中，如果Runners包含运行Rails测试套件的相应依赖项，那么我们将Runners标记为“rails” Preventing Runners with tags from picking jobs without tags您可以配置Runner以防止在Runner没有分配tag时使用tag选择作业。 Runner pick tagged/untagged jobs: Visit your project’s Settings ➔ CI/CD Find the Runner you wish and make sure it’s enabled Click the pencil button Check the Run untagged jobs option Click Save changes for the changes to take effect 为Runner设置做大作业超时 对于每个Runner，您可以指定最大作业超时时间。如果小于项目定义的超时，则此类超时将优先。 小心敏感信息 对于一些Runner Executors，如果您可以在Runner上运行作业，您就可以访问它运行的任何代码并获取Runner的Token。使用shared Runners，这意味着在Runner上运行作业的任何人都可以访问在Runner上运行的任何其他人的代码。 通过在大型公共GitLab实例上限制shared Runners的使用，控制对GitLab实例的访问以及使用更安全的Runner Executor，可以轻松避免上述情况。 Forks 每当项目forked时，它都会复制与其相关的作业的设置。这意味着如果您为项目设置了shared Runners并且有人fork该项目，则shated Runners也将为该项目的作业提供服务。 tagstags用于从允许运行此项目的所有Runner列表中选择特定的Runner。你可以制定Runner的tag. tags允许您使用分配了指定tag的Runners运行作业： 1234job: tags: - ruby - postgres 例子： 123456789101112131415windows job: stage: - build tags: - windows script: - echo Hello, %USERNAME%!osx job: stage: - build tags: - osx script: - echo "Hello, $USER!" 共享Runner的管道配额Shared Runners pipelines quota: Limit the usage of pipeline minutes for Shared Runners. 在Web UI的Admin Area下的Auto DevOps里面进行配置。 Auto DevOpsEnable/disable Auto DevOps: Enable or disable Auto DevOps for your instance 在GitLab 10.0中引入。一般在GitLab 11.0上可用。 Auto DevOps提供预定义的CI/CD配置，允许您自动检测(detect)，构建(build)，测试(test)，部署(deploy)和监控(monitor)应用程序。利用CI/CD最佳实践和工具，Auto DevOps旨在简化成熟和现代软件开发生命周期的设置和执行。 综述 从GitLab v11.3开始，默认情况下为所有项目启用Auto DevOps pipeline。如果尚未为项目显式启用，则会在第一个管道故障时自动禁用Auto DevOps。如果找到一个，您的项目将继续使用备用CI/CD配置文件。 借助Auto DevOps，软件开发过程变得更容易设置，因为每个项目都可以拥有从验证到监控的完整工作流程，并且配置最少。只需推送您的代码，GitLab就会处理其他所有事情。这样可以更轻松地启动新项目，并使整个公司的应用程序设置更加一致。 与应用程序平台和PaaS相比较Comparison to application platforms and PaaS Auto DevOps提供通常包含在应用程序平台或PaaS的功能。它有多个灵感： Auto DevOps适用于任何k8s集群;你不仅限于在GitLab的基础设施上运行。 没有额外成本，你可在任何公共云上使用自托管的k8s集群。 Auto DevOps包括了安全测试，性能测试和代码质量测试等众多功能。 Auto DevOps提供增量分级路径。如果您需要高级自定义，则可以开始修改模板，而无需在完全不同的平台上重新开始。 特性特性(Features): Auto Build Auto Test Auto Code Quality Auto SAST (Static Application Security Testing) Auto Dependency Scanning Auto License Management Auto Container Scanning Auto Review Apps Auto DAST (Dynamic Application Security Testing) Auto Deploy Auto Browser Performance Testing Auto Monitoring 由于Auto DevOps依赖于许多不同的组件，因此最好具备以下基本知识： Kubernetes Helm Docker GitLab Runner Prometheus Auto DevOps为所有阶段提供了很好的默认值;但是，您可以根据需要自定义几乎所有内容。 依赖Requirements 要充分利用Auto DevOps，您需要: GitLab Runner(所有阶段都需要)Runner需要配置为能够运行Docker(通常，这意味着使用Docker或Kubernetes executor，并启用特权模式)。Runner不需要安装在k8s集群中，但k8s executor易于使用并且可以自动进行自动伸缩。基于Docker的Runner也可以使用Docker Machine配置为自动伸缩。应将Runners注册为整个GitLab实例的shared Runners，或分配给特定项目的specific Runner。 Base domain(自动审阅和自动部署所需)您将需要一个配置了通配符DNS的域，该域将由您的所有Auto DevOps应用程序使用。 K8s(自动审阅、自动部署和自动监控所需)要启用部署，您需要k8s v1.5+。您需要项目的Kubernetes集群，或整个GitLab安装的Kubernetes默认服务模板。负载均衡器——您可以使用nginx-ingress Helm Chart将NGINX Ingress部署到Kubernetes集群，从而使用NGINX ingress。 Prometheus(自动监控所需)要启用自动监控，您需要在某处（集群内部或外部）安装Prometheus并配置为刮取您的Kubernetes集群。要获得除系统指标外的响应指标(Metrics)，您还需要配置Prometheus。 注意：如果您没有安装Kubernetes或Prometheus，则将自动跳过自动审阅，自动部署和自动监控。 自动化运维基本域Auto DevOps base domain 如果要使用自动审阅和自动部署，则需要启用Auto DevOps base domain。它可在三个地方定义： 在项目下的CI/CD 在Admin Area -&gt; Setting -&gt; CI/CD 在项目下配置变量: AUTO_DEVOPS_DOMAIN 在组级别配置变量: AUTO_DEVOPS_DOMAIN 需要一个与基本域匹配的通配符DNS A记录，如: 12345*.example.com 3600 A 1.2.3.4#在这种情况下，`example.com`是用于部署应用程序的域名，`1.2.3.4`是负载均衡器的IP地址(通常是NGINX)。如何设置DNS记录超出了本文档的范围;您应该咨询您的DNS提供商。#设置完成后，所有请求都会到达负载均衡器，然后负载均衡器会将它们路由到运行应用程序的Kubernetes pod 使用多个k8s集群Using multiple Kubernetes clusters 使用Auto DevOps时，您可能希望将不同的环境部署到不同的Kubernetes集群。在Auto DevOps template中，您需要知道3个已定义的环境名称： review/ (从review/开始每个环境) staging production 这些环境与使用自动部署的作业相关联，因此除了环境范围之外，它们还需要具有部署到的不同域。这就是您需要根据环境为上述所有内容定义单独的AUTO_DEVOPS_DOMAIN变量的原因。 下表是如何配置三个不同群集的示例: 集群名 集群环境范围 AUTO_DEVOPS_DOMAIN变量值 环境变量范围 备注 review review/* review.example.com review/* The review cluster which will run all Review Apps. * is a wildcard, which means it will be used by every environment name starting with review/. staging staging staging.example.com staging (Optional) The staging cluster which will run the deployments of the staging environments. You need to enable it first. production production example.com production The production cluster which will run the deployments of the production environment. You can use incremental rollouts. 要为每个环境添加不同的群集： 项目的Operations -&gt; Kubernetes并使用各自的环境范围创建Kubernetes集群，如上表所述 创建群集后，到每个群集并安装Helm Tiller和Ingress 确保已使用指定的自动化运维域配置DNS 到项目的Settings -&gt; CI/CD -&gt; Variables，添加AUTO_DEVOPS_DOMAIN变量及其各自的环境范围。 注意：具有多个群集的组不支持自动DevOps，因为无法在组级别上为每个环境设置AUTO_DEVOPS_DOMAIN。 启用/禁用Auto DevOps首次使用Auto Devops时，请查看要求以确保可以使用所有必要的组件来充分利用Auto DevOps。 在实例级别启用/禁用Auto DevOps（仅限管理员） Admin area -&gt; Settings -&gt; Continuous Integration and Deployment Default to Auto DevOps pipeline for all projects base domain 在项目级别启用/禁用 Auto DevOps project’s Settings -&gt; CI/CD -&gt; Auto DevOps Default to Auto DevOps pipeline Domain Deployment strategy 部署策略(Deployment strategy) Introduced in GitLab 11.0 你可以更改项目的部署策略。有三种策略: Continuous deployment to production: 允许master分支启用Auto Deploy来直接部署到生产环境 Continuous deployment to production using timed incremental rollout: 将INCREMENTAL_ROLLOUT_MODE变量设置为timed，并且将在rollout的每个增量之间延迟5分钟执行生产部署 Automatic deployment to staging, manual deployment to production: 设置STAGING_ENABLED为1，INCREMENTAL_ROLLOUT_MODE为manual。提供手动操作以部署到生产环境 自动化运维的阶段Stages of Auto DevOps 以下部分描述了Auto DevOps的各个阶段。仔细阅读它们以了解每个工作原理。 Auto Build自动化构建有两种方式创建应用程序的构建： 如果有Dockerfile, 则使用docker build来创建镜像 否则，它将使用Herokuish和Heroku buildpacks自动检测并将应用程序构建到Docker镜像中 无论哪种方式，生成的Docker镜像都会自动推送到Container Registry并使用commit SHA进行标记。 重要提示：如果您还使用Auto Review和Auto Deploy并选择提供自己的Dockerfile，请确保将应用程序expose到端口5000，因为这是默认Helm图表所假定的端口。 Auto TestAuto Test通过分析您的项目来检测语言和框架，使用Herokuish和Heroku buildpacket自动为您的应用程序运行相应的测试。自动检测多种语言和框架，但如果未检测到您的语言，您可以使用自定义构建包(Custom buildpacks)。可检查当前支持的语言。 注意：自动测试使用您在应用程序中已有的测试。如果没有测试，则由您来添加它们。 Auto Code Quality GitLab STARTER BRONZE Auto Code Quality使用Code Quality image对当前代码运行静态分析和其他代码检查。报告已创建，并作为工件上传，您可以在以后下载和检查。源分支和目标分支之间的任何差异也会显示在合并请求窗口小部件中。 Auto SAST GitLab ULTIMATE GOLD Static Application Security Testing(SAST)使用SAST Docker image对当前代码运行静态分析并检查潜在的安全问题。创建报告后，它将作为工件上载，您可以在以后下载和检查。 Auto Dependency Scanning GitLab ULTIMATE GOLD Dependency Scanning使用Dependency Scanning Docker image对项目依赖关系进行分析并检查潜在的安全问题。创建报告后，它将作为工件上载，您可以在以后下载和检查。 Auto License Management GitLab ULTIMATE GOLD License Management使用License Management Docker image搜索项目依赖项以获取其许可证。创建报告后，它将作为工件上载，您可以在以后下载和检查。 Auto Container Scanning GitLab ULTIMATE 容器的漏洞静态分析使用Clair在Docker image上运行静态分析并检查潜在的安全问题。创建报告后，它将作为工件上载，您可以在以后下载和检查。 Auto Review Apps 注意： 这是一个可选步骤，因为许多项目没有可用的Kubernetes集群。如果不满足要求，将默默跳过作业。警告：不应在Helm之外操作您的应用程序(直接使用Kubernetes)。这可能会导致Helm无法检测到更改，并且随后使用Auto DevOps进行部署可以撤消您的更改。此外，如果您更改某些内容并希望通过再次部署来撤消它，Helm可能无法检测到任何更改，因此没有意识到它需要重新应用旧配置。 Review App 是基于分支代码的临时应用程序环境，因此开发人员，设计人员，QA，产品经理和其他审阅者可以在审阅过程中实际查看代码更改并与之交互。Auto Review Apps为每个分支创建一个Review App。 Auto Review Apps 仅将您的应用部署到您的Kubernetes群集。如果没有可用的群集，则不会进行部署。Review App将具有基于项目名，分支名、唯一编号以及Auto DevOps基本域的唯一URL。如：user-project-branch-1234.example.com。审阅应用程序的链接显示在合并请求窗口小部件中，以便于发现。删除分支时，例如合并合并请求后，将自动删除Review App。 Auto DAST GitLab Ultimate Dynamic Application Security Testing (DAST)使用流行的开源工具OWASP ZAProxy对当前代码执行分析并检查潜在的安全问题。创建报告后，它将作为工件上载，您可以在以后下载和检查。 Auto Browser Performance Testing GitLab Premium 自动浏览器性能测试利用Sitespeed.io容器来衡量网页的性能。创建JSON报告并将其作为工件上载，其中包括每个页面的整体性能分数。默认情况下，将测试Review和Production环境的根页面。如果要添加其他URL以进行测试，只需将路径添加到根目录中名为.gitlab-urls.txt的文件中，每行一个。 栗子: 123//features/direction Auto Deploy 注意：这是一个可选步骤，因为许多项目没有可用的Kubernetes集群。如果不满足要求，将默默跳过作业。警告：不应在Helm之外操作您的应用程序（直接使用Kubernetes）。这可能会导致Helm无法检测到更改，并且随后使用Auto DevOps进行部署可以撤消您的更改。此外，如果您更改某些内容并希望通过再次部署来撤消它，Helm可能无法检测到任何更改，因此没有意识到它需要重新应用旧配置。 将branch或merge request合并到项目的默认分支（通常是master）后，Auto Deploy将应用程序部署到Kubernetes集群中的生产环境，其中包含基于项目名称和唯一项目ID的命名空间。您可以使用环境变量自动伸缩pod副本。 值得注意的是，当项目部署到Kubernetes集群时，它依赖于已推送到GitLab Container Registry的Docker image。k8s获取此镜像并运行应用。如果项目是公共的，Kubernetes可以在不进行任何身份验证的情况下访问该映像，从而使我们可以使部署更加可用。如果项目是私有/内部的，则注册表需要凭据才能提取镜像。目前，通过提供CI_JOB_TOKEN作为可以使用的密码来解决此问题，但是一旦部署作业完成，此标记将不再有效。这意味着Kubernetes可以运行应用程序，但是如果它应该重新启动或在其他地方执行，则无法再次访问。 Auto Monitoring 注意：检查自动监控的要求以使此阶段工作。 部署应用程序后，自动监控可以立即监控应用程序的服务器和响应指标。自动监控使用Prometheus直接从Kubernetes获取系统指标，如CPU和内存使用情况，以及来自NGINX服务器的响应指标，如HTTP错误率，延迟和吞吐量。 指标有： Response Metrics: latency, throughput, error rate System Metrics: CPU utilization, memory utilization 为了使用监控，你需要： 将Prometheus部署到k8s集群中 配置Prometheus以获取想要的指标 自定义Customizing 虽然Auto DevOps提供了很好的默认设置来帮助您入门，但您可以自定义几乎所有内容以满足您的需求;从自定义buildpacks到Dockerfiles，Helm chart，甚至将完整的CI/CD配置复制到项目中进行部署。 Custom buildpacks如果项目的自动buildpack检测失败，或者您想使用自定义buildpack，则可以使用项目变量或项目中的.buildpacks文件覆盖buildpack: Project variable: 使用要使用的buildpack的URL创建项目变量BUILDPACK_URL .buildpacks文件: 在项目中添加一个名为.buildpacks的文件，并添加要在文件中的一行使用的buildpack的URL(多个使用多行，一行一个) 警告：Auto DevOps尚不支持使用多个buildpack Custom Dockerfile如果您的项目的根目录中有一个Dockerfile，则Auto DevOps将基于Dockerfile而不是使用buildpacks构建Docker镜像。这可以更快，并导致更小的图像，尤其是如果您的Dockerfile基于Alpine。 Custom Helm ChartAuto DevOps使用Helm将您的应用程序部署到Kubernetes。您可以通过将chart捆绑到项目仓库中或通过指定项目变量来覆盖使用的Helm chart： Bundled chart: 如果您的项目有一个带有Chart.yaml文件的./chart目录，Auto DevOps将检测chart并使用它而不是默认chart。这可以很好地控制应用程序的部署方式 Project variable: 使用要使用的自定义chart的URL创建项目变量AUTO_DEVOPS_CHART Customizing .gitlab-ci.yml如果要修改Auto DevOps使用的CI/CD pipeline，可以将Auto DevOps template复制到项目的repo中并根据需要进行编辑。 假设您的项目是新的或者没有.gitlab-ci.yml文件： 在项目 CI/CD里面新建文件 选择.gitlab-ci.yml模板 选择Auto-DevOps 编辑此模板 提交 提示：Auto DevOps模板包含有用的注释，可帮助您自定义它。如果您希望部署转到临时(staging)环境而不是直接转到生产(production)环境，则可以通过将.staging重命名为staging来启用staging作业；然后确保取消注释生产作业的when，将其转换为手动操作，而不是自动部署。 PostgreSQL为了支持需要数据库的应用程序，默认情况下会配置PostgreSQL。访问数据库的凭据已预先配置，但可以通过设置关联的变量进行自定义。这些凭据可用于定义DATABASE_URL的格式：postgres://user:password@postgres-host:postgres-port/postgres-database Environment variables以下变量可用于设置Auto DevOps domain，提供自定义Helm chart或扩展应用程序。 PostgreSQL也可以自定义，您可以轻松使用自定义buildpack。 变量 描述 AUTO_DEVOPS_DOMAIN Auto DevOps domain AUTO_DEVOPS_CHART 用于部署应用的Helm Chart REPLICAS 要部署的副本数，默认为1 PRODUCTION_REPLICAS 要在生产环境中部署的副本数。这优先于REPLICAS;默认为1 CANARY_REPLICAS Canary Deployments部署的副本数，默认为1 CANARY_PRODUCTION_REPLICAS 生产环境的，优先于CANARY_REPLICAS，默认为1 POSTGRES_ENABLED 是否启用PostgreSQL,默认为true POSTGRES_USER PostgreSQL用户，默认为user POSTGRES_PASSWORD PostgreSQL密码，默认为testing-password POSTGRES_DB PostgreSQL数据库名称;默认值为$CI_ENVIRONMENT_SLUG BUILDPACK_URL buildpack的完整URL SAST_CONFIDENCE_LEVEL 您希望报告的安全问题的最低置信度; 1为低，2为中，3为高;默认为3 DEP_SCAN_DISABLE_REMOTE_CHECKS 是否禁用远程依赖扫描检查;默认为false DB_INITIALIZE 从GitLab 11.4开始，此变量可用于指定运行以初始化应用程序的PostgreSQL数据库的命令。它在应用程序pod内运行 DB_MIGRATE 从GitLab 11.4开始，此变量可用于指定运行以迁移应用程序的PostgreSQL数据库的命令。它在应用程序pod内运行 STAGING_ENABLED 可用于定义部署策略 CANARY_ENABLED 定义canary部署策略 INCREMENTAL_ROLLOUT_MODE 从GitLab 11.4开始，此变量（如果存在）可用于为生产环境启用应用程序的增量部署 TEST_DISABLED 从GitLab 11.0开始，此变量可用于禁用测试作业 CODE_QUALITY_DISABLED 从GitLab 11.0开始，此变量可用于禁用代码质量作业 SAST_DISABLED 从GitLab 11.0开始，此变量可用于禁用sast作业 DEPENDENCY_SCANNING_DISABLED 从GitLab 11.0开始，此变量可用于禁用dependency_scanning作业 CONTAINER_SCANNING_DISABLED 从GitLab 11.0开始，此变量可用于禁用sast：container作业 REVIEW_DISABLED 从GitLab 11.0开始，此变量可用于禁用审核和手动审核：停止作业 PERFORMANCE_DISABLED 从GitLab 11.0开始，此变量可用于禁用性能作业 提示：使用项目变量设置副本变量，并通过重新部署来扩展应用程序！小心: 你不应该直接使用k8s来扩展你的应用程序，这可能会导致Helm异常。 高级副本变量设置(Advanced replica variables setup) 除了上面提到的两个与副本相关的生产变量之外，您还可以将其它变量用于不同的环境。 目前支持的语言Currently supported languages 从GitLab 10.0开始，支持的构建包是： 12345678910111213- heroku-buildpack-multi v1.0.0- heroku-buildpack-ruby v168- heroku-buildpack-nodejs v99- heroku-buildpack-clojure v77- heroku-buildpack-python v99- heroku-buildpack-java v53- heroku-buildpack-gradle v23- heroku-buildpack-scala v78- heroku-buildpack-play v26- heroku-buildpack-php v122- heroku-buildpack-go v72- heroku-buildpack-erlang fa17af9- buildpack-nginx v8 Auto DevOps template各种模板: https://gitlab.com/gitlab-org/gitlab-ce/tree/master/lib/gitlab/ci/templates 在项目也可选择新建.gitlab-ci.yml模板文件，然后根据需要就行适当的修改。 CI/CD环境变量CI/CD Variables - Learn how to use variables defined in your .gitlab-ci.yml or the ones defined in your project’s settings 当从GitLab CI接收作业时，Runner准备构建环境。首先，设置预定义变量列表predefined variables（环境变量）和用户定义变量列表user-defined variables。 变量优先级Priority of variables 变量可以被覆盖，并且它们按此顺序优先于彼此： Trigger variables / scheduled pipeline variables Project-level variables / protected variables Group-level variables / protected variables YAML-defined job-level variables YAML-defined global variables Deployment variables Predefined variables 不支持的变量在某些情况下，某些变量无法在.gitlab-ci.yml定义的上下文中使用——如在script下定义的变量。 预定义变量Predefined variables (Environment variables) 注意：从GitLab 9.0开始，我们已经弃用了一些变量。阅读9.0重命名部分以找出它们的替代品。强烈建议您使用新变量，因为我们将在以后的GitLab版本中删除旧变量。 Variable GitLab Runner Description ARTIFACT_DOWNLOAD_ATTEMPTS 8.15 1.9 Number of attempts to download artifacts running a job CI all 0.4 Mark that job is executed in CI environment CI_COMMIT_BEFORE_SHA 11.2 all The previous latest commit present on a branch before a push request. CI_COMMIT_DESCRIPTION 10.8 all The description of the commit: the message without first line, if the title is shorter than 100 characters; full message in other case. CI_COMMIT_MESSAGE 10.8 all The full commit message. CI_COMMIT_REF_NAME 9.0 all The branch or tag name for which project is built CI_COMMIT_REF_SLUG 9.0 all $CI_COMMIT_REF_NAME lowercased, shortened to 63 bytes, and with everything except 0-9 and a-z replaced with -. No leading / trailing -. Use in URLs, host names and domain names. CI_COMMIT_SHA 9.0 all The commit revision for which project is built CI_COMMIT_SHORT_SHA 11.7 all The first eight characters of CI_COMMIT_SHA CI_COMMIT_TAG 9.0 0.5 The commit tag name. Present only when building tags. CI_COMMIT_TITLE 10.8 all The title of the commit - the full first line of the message CI_CONFIG_PATH 9.4 0.5 The path to CI config file. Defaults to .gitlab-ci.yml CI_DEBUG_TRACE all 1.7 Whether debug tracing is enabled CI_DEPLOY_PASSWORD 10.8 all Authentication password of the GitLab Deploy Token, only present if the Project has one related. CI_DEPLOY_USER 10.8 all Authentication username of the GitLab Deploy Token, only present if the Project has one related. CI_DISPOSABLE_ENVIRONMENT all 10.1 Marks that the job is executed in a disposable environment (something that is created only for this job and disposed of/destroyed after the execution - all executors except shell and ssh). If the environment is disposable, it is set to true, otherwise it is not defined at all. CI_ENVIRONMENT_NAME 8.15 all The name of the environment for this job CI_ENVIRONMENT_SLUG 8.15 all A simplified version of the environment name, suitable for inclusion in DNS, URLs, Kubernetes labels, etc. CI_ENVIRONMENT_URL 9.3 all The URL of the environment for this job CI_JOB_ID 9.0 all The unique id of the current job that GitLab CI uses internally CI_JOB_MANUAL 8.12 all The flag to indicate that job was manually started CI_JOB_NAME 9.0 0.5 The name of the job as defined in .gitlab-ci.yml CI_JOB_STAGE 9.0 0.5 The name of the stage as defined in .gitlab-ci.yml CI_JOB_TOKEN 9.0 1.2 Token used for authenticating with the GitLab Container Registry and downloading dependent repositories CI_JOB_URL 11.1 0.5 Job details URL CI_MERGE_REQUEST_ID 11.6 all The ID of the merge request if it’s pipelines for merge requests CI_MERGE_REQUEST_IID 11.6 all The IID of the merge request if it’s pipelines for merge requests CI_MERGE_REQUEST_PROJECT_ID 11.6 all The ID of the project of the merge request if it’s pipelines for merge requests CI_MERGE_REQUEST_PROJECT_PATH 11.6 all The path of the project of the merge request if it’s pipelines for merge requests (e.g. namespace/awesome-project) CI_MERGE_REQUEST_PROJECT_URL 11.6 all The URL of the project of the merge request if it’s pipelines for merge requests (e.g. http://192.168.10.15:3000/namespace/awesome-project) CI_MERGE_REQUEST_REF_PATH 11.6 all The ref path of the merge request if it’s pipelines for merge requests. (e.g. refs/merge-requests/1/head) CI_MERGE_REQUEST_SOURCE_BRANCH_NAME 11.6 all The source branch name of the merge request if it’s pipelines for merge requests CI_MERGE_REQUEST_SOURCE_PROJECT_ID 11.6 all The ID of the source project of the merge request if it’s pipelines for merge requests CI_MERGE_REQUEST_SOURCE_PROJECT_PATH 11.6 all The path of the source project of the merge request if it’s pipelines for merge requests CI_MERGE_REQUEST_SOURCE_PROJECT_URL 11.6 all The URL of the source project of the merge request if it’s pipelines for merge requests CI_MERGE_REQUEST_TARGET_BRANCH_NAME 11.6 all The target branch name of the merge request if it’s pipelines for merge requests CI_NODE_INDEX 11.5 all Index of the job in the job set. If the job is not parallelized, this variable is not set. CI_NODE_TOTAL 11.5 all Total number of instances of this job running in parallel. If the job is not parallelized, this variable is set to 1. CI_API_V4_URL 11.7 all The GitLab API v4 root URL CI_PIPELINE_ID 8.10 all The unique id of the current pipeline that GitLab CI uses internally CI_PIPELINE_IID 11.0 all The unique id of the current pipeline scoped to project CI_PIPELINE_SOURCE 10.0 all Indicates how the pipeline was triggered. Possible options are: push, web, trigger, schedule, api, and pipeline. For pipelines created before GitLab 9.5, this will show as unknown CI_PIPELINE_TRIGGERED all all The flag to indicate that job was triggered CI_PIPELINE_URL 11.1 0.5 Pipeline details URL CI_PROJECT_DIR all all The full path where the repository is cloned and where the job is run CI_PROJECT_ID all all The unique id of the current project that GitLab CI uses internally CI_PROJECT_NAME 8.10 0.5 The project name that is currently being built (actually it is project folder name) CI_PROJECT_NAMESPACE 8.10 0.5 The project namespace (username or groupname) that is currently being built CI_PROJECT_PATH 8.10 0.5 The namespace with project name CI_PROJECT_PATH_SLUG 9.3 all $CI_PROJECT_PATH lowercased and with everything except 0-9 and a-z replaced with -. Use in URLs and domain names. CI_PROJECT_URL 8.10 0.5 The HTTP address to access project CI_PROJECT_VISIBILITY 10.3 all The project visibility (internal, private, public) CI_REGISTRY 8.10 0.5 If the Container Registry is enabled it returns the address of GitLab’s Container Registry CI_REGISTRY_IMAGE 8.10 0.5 If the Container Registry is enabled for the project it returns the address of the registry tied to the specific project CI_REGISTRY_PASSWORD 9.0 all The password to use to push containers to the GitLab Container Registry CI_REGISTRY_USER 9.0 all The username to use to push containers to the GitLab Container Registry CI_REPOSITORY_URL 9.0 all The URL to clone the Git repository CI_RUNNER_DESCRIPTION 8.10 0.5 The description of the runner as saved in GitLab CI_RUNNER_EXECUTABLE_ARCH all 10.6 The OS/architecture of the GitLab Runner executable (note that this is not necessarily the same as the environment of the executor) CI_RUNNER_ID 8.10 0.5 The unique id of runner being used CI_RUNNER_REVISION all 10.6 GitLab Runner revision that is executing the current job CI_RUNNER_TAGS 8.10 0.5 The defined runner tags CI_RUNNER_VERSION all 10.6 GitLab Runner version that is executing the current job CI_SERVER all all Mark that job is executed in CI environment CI_SERVER_NAME all all The name of CI server that is used to coordinate jobs CI_SERVER_REVISION all all GitLab revision that is used to schedule jobs CI_SERVER_VERSION all all GitLab version that is used to schedule jobs CI_SERVER_VERSION_MAJOR 11.4 all GitLab version major component CI_SERVER_VERSION_MINOR 11.4 all GitLab version minor component CI_SERVER_VERSION_PATCH 11.4 all GitLab version patch component CI_SHARED_ENVIRONMENT all 10.1 Marks that the job is executed in a shared environment (something that is persisted across CI invocations like shell or ssh executor). If the environment is shared, it is set to true, otherwise it is not defined at all. GET_SOURCES_ATTEMPTS 8.15 1.9 Number of attempts to fetch sources running a job GITLAB_CI all all Mark that job is executed in GitLab CI environment GITLAB_USER_EMAIL 8.12 all The email of the user who started the job GITLAB_USER_ID 8.12 all The id of the user who started the job GITLAB_USER_LOGIN 10.0 all The login username of the user who started the job GITLAB_USER_NAME 10.0 all The real name of the user who started the job RESTORE_CACHE_ATTEMPTS 8.15 1.9 Number of attempts to restore the cache running a job GitLab 9.0 renaming 8.x name 9.0+ name CI_BUILD_ID CI_JOB_ID CI_BUILD_REF CI_COMMIT_SHA CI_BUILD_TAG CI_COMMIT_TAG CI_BUILD_BEFORE_SHA CI_COMMIT_BEFORE_SHA CI_BUILD_REF_NAME CI_COMMIT_REF_NAME CI_BUILD_REF_SLUG CI_COMMIT_REF_SLUG CI_BUILD_NAME CI_JOB_NAME CI_BUILD_STAGE CI_JOB_STAGE CI_BUILD_REPO CI_REPOSITORY_URL CI_BUILD_TRIGGERED CI_PIPELINE_TRIGGERED CI_BUILD_MANUAL CI_JOB_MANUAL CI_BUILD_TOKEN CI_JOB_TOKEN .gitlab-ci.yml定义的变量GitLab CI允许您添加在构建环境中设置的.gitlab-ci.yml变量。因此，变量保存在存储库中，它们用于存储非敏感项目配置。 组/库级别变量这个变量在Web UI上进行配置。 .gitlab-ci.yml配置使用.gitlab-ci.yml配置你的Jobs，该文件是GitLab Runner用来管理项目作业的文件。 JobsYAML文件定义了一组具有约束的作业，说明应该何时运行它们。您可以指定无限数量的作业，这些作业被定义为具有任意名称的顶级元素，并且始终必须至少包含script子句。可以是直接运行命令，也可以写成xxx.sh脚本，然后执行此脚本。 123456#两个单独的作业，执行各自的命令job1: script: "execute-script-for-job1"job2: script: "execute-script-for-job2" Runner选择Job并在Runner的环境中执行。重要的是，每项工作都是相互独立运作的，这里可对比Jenkins里面的workspace。 每个作业必须具有唯一的名称，但有一些保留的关键字(keywords)不能用作作业名称: image services stages types before_script after_script variables cache 作业由定义作业行为的参数列表定义: Keyword Required Description script yes Defines a shell script which is executed by Runner extends no Defines a configuration entry that this job is going to inherit from image no Use docker image, covered in Using Docker Images services no Use docker services, covered in Using Docker Images stage no Defines a job stage (default: test) type no Alias for stage variables no Define job variables on a job level only no Defines a list of git refs for which job is created except no Defines a list of git refs for which job is not created tags no Defines a list of tags which are used to select Runner allow_failure no Allow job to fail. Failed job doesn’t contribute to commit status when no Define when to run job. Can be on_success, on_failure, always or `manual dependencies no Define other jobs that a job depends on so that you can pass artifacts between them artifacts no Define list of job artifacts cache no Define list of files that should be cached between subsequent runs before_script no Override a set of commands that are executed before job after_script no Override a set of commands that are executed after job environment no Defines a name of environment to which deployment is done by this job coverage no Define code coverage settings for a given job retry no Define when and how many times a job can be auto-retried in case of a failure parallel no Defines how many instances of a job should be run in parallel extendsextends定义了一个使用extends的作业将继承的条目名称。 这是使用YAML锚点(anchor)的替代方案，并且更加灵活和可读： 12345678910111213.tests: script: rake test stage: test only: refs: - branchesrspec: extends: .tests script: rake rspec only: variables: - $RSPEC 在上面的示例中，rspec作业继承自.tests模板作业。GitLab将根据键执行反向深度合并。GitLab将: 将rspec内容以递归方式合并到.tests中 Not merge the values of the keys 这导致以下rspec作业: 123456789#注意，script: rake test将被script: rake rspec覆盖rspec: script: rake rspec stage: test only: refs: - branches variables: - $RSPEC 如果想要包含rake test, 请查看before_script-and-after_script.extends支持多级继承，但不建议使用三级以上。支持的最大嵌套级别为10。 一下栗子具有两级继承: 123456789101112131415161718192021.tests: only: - pushes.rspec: extends: .tests script: rake rspecrspec 1: variables: RSPEC_SUITE: '1' extends: .rspecrspec 2: variables: RSPEC_SUITE: '2' extends: .rspecspinach: extends: .tests script: rake spinach pagespages是一项特殊工作，用于将静态内容上传到GitLab，可用于为您的网站提供服务。它有一个特殊的语法，因此必须满足以下两个要求： 任何静态内容都必须放在public/目录下 须定义具有public/目录路径的artifacts 1234567891011pages: stage: deploy script: - mkdir .public - cp -r * .public - mv .public public artifacts: paths: - public only: - master 更多详细信息请参考GitLab Pages。 image and services这允许指定自定义Docker镜像和可用于作业时间的服务列表。 before_script and after_scriptbefore_script用于定义应在所有作业（包括部署作业）之前，在恢复工件(artifacts)之后，运行的命令；这可以是数组或多行字符串。after_script用于定义将在所有作业（包括失败的作业）之后运行的命令。这必须是数组或多行字符串。 before_script和main script连接在一个上下文/容器中运行。after_script是单独运行的，因此根据执行程序，在工作树之外完成的更改可能不可见。 如果在每个工作中定义了before_script和after_script，则可以覆盖全局定义： 12345678910before_script: - global before scriptjob: before_script: - execute this instead of global before script script: - my command after_script: - execute this after my script stagesstages用于在全局范围定义可由作业使用的阶段。stages规范允许具有灵活的多级阶段管道(multi stage pipeline)。stages元素的排序定义了作业执行的顺序: 同一阶段的作业是并行运行的 下一阶段的作业在上一阶段的作业成功完成之后运行 让我们考虑以下示例，它定义了3个阶段： 1234567891011stages: - build - test - deploy#首先，build阶段的所有作业都是并行执行的#如果build阶段的所有作业都成功，则test阶段的作业将并行执行#如果test阶段的所有作业都成功，则deploy阶段的作业将并行执行#如果deploy阶段的所有作业都成功，则commit将被标记为passwd#如果任何先前的作业失败，则commit被标记为failed，并且不执行其他阶段的作业 有两个边缘案例值得注意： 如果在.gitlab-ci.yml文件中没有定义stages，build、test和deploy用作默认情况允许的作业阶段； 如果作业未指定stage，则为作业分配test阶段 stagestage是按工作定义的，依赖于全局定义的stages。它允许将作业分组到不同的阶段，并且同一阶段的作业并行执行: 1234567891011121314151617181920stages: - build - test - deployjob 1: stage: build script: make build dependenciesjob 2: stage: build script: make build artifactsjob 3: stage: test script: make testjob 4: stage: deploy script: make deploy types不推荐使用types，可以在以后的某个版本中删除。请使用stages替代它。 scriptscript是作业所需的唯一必需关键字。这是一个由Runner执行的shell script。 123#栗子job: script: "bundle exec rspec" 此参数还可以包含使用数组的多个命令： 1234job: script: - uname -a - bundle exec rspec 有时，脚本命令需要用单引号或双引号括起来，例如命令中有特殊字符的时候。 only和except(简单)only和except两个参数，用于创建作业时设置作业策略来限制它: only定义作业将运行的branch和tag的名称 except定义作业不会运行的branch和tag的名称 有一些适用于作业策略的规则： only和except是包容性的，如果在作业规范中定义了only和except，则ref被only和except过滤 only和except允许使用正则表达式: Ruby regexp syntax only和except允许指定一个Repo path来为forks过滤作业 另外，only和except允许使用如下关键字: Value Description branches When a git reference of a pipeline is a branch tags When a git reference of a pipeline is a tag api When pipeline has been triggered by a second pipelines API (not triggers API) external When using CI services other than GitLab pipelines For multi-project triggers, created using the API with CI_JOB_TOKEN pushes Pipeline is triggered by a git push by the user schedules For scheduled pipelines triggers For pipelines created using a trigger token web For pipelines created using Run pipeline button in GitLab UI (under your project’s Pipelines) merge_requests When a merge request is created or updated 123456789101112131415161718192021222324252627#job将仅针对以issue-开头的refs运行，而所有分支都将被跳过job: # use regexp only: - /^issue-.*$/ # use special keyword except: - branches#job将仅对tagged refsjob: # use special keywords only: - tags - triggers - schedules#repo path可用于仅为parent repo而不是forks执行作业#将为除了master的gitlab-org/gitlab-ce上的所有分支运行jobjob: only: - branches@gitlab-org/gitlab-ce except: - master@gitlab-org/gitlab-ce 如果作业既没有only也没有except规则，则默认设置为only: [&#39;branches&#39;, &#39;tags&#39;]: 123456789#未配置job: script: echo 'test'#它被转换为下面这个样子job: script: echo 'test' only: ['branches', 'tags'] only和except(复杂) refs and kubernetes policies introduced in GitLab 10.0. variables policy introduced in GitLab 10.7. changes policy introduced in GitLab 11.4. 这是一个alpha功能，它可能随时更改，恕不另行通知！ GitLab支持简单和复杂的策略，因此可以使用数组和哈希配置方案。提供了4个key: refs variables changes kubernetes 可以使用AND组合多可键。 only: refs except: refs 12345deploy: only: refs: - master - schedules only: kubernetes except: kubernetes 1234#kubernetes策略只接受active关键字deploy: only: kubernetes: active only: variables except: variables 123456789#variables关键字用于定义变量表达式deploy: script: cap staging deploy only: refs: - branches variables: - $RELEASE == "staging" - $STAGING only: changes except: changes 1234567891011#是否应该根据git push事件修改的文件来创建作业docker build: script: docker build -t my-image:$CI_COMMIT_REF_SLUG . only: changes: - Dockerfile - docker/scripts/* - dockerfiles/**/* - more_scripts/*.&#123;rb,py,sh&#125;#这个例子中，只要有上面几个文件或文件夹内的内容发生了commit push tagstags从允许运行此项目的所有Runner中选择特定Runner。在注册Runner期间，您可以指定Runner的tag。tags允许你使用分配了特定标签的Runner运行作业。 12345678910111213141516171819202122job: tags: - ruby - postgres#栗子windows job: stage: - build tags: - windows script: - echo Hello, %USERNAME%!osx job: stage: - build tags: - osx script: - echo "Hello, $USER!" allow_failureallow_failure允许作业失败而不会影响CI套件的其余部分。除手动作业外，默认值为false。启用并且作业失败后，作业将在UI中显示橙色警告。但是，管道的逻辑流程将认为作业成功/通过，并且不会被阻止。假设所有其它作业都成功，作业的阶段及其管道将显示相同的橙色警告。但是，关联的提交将被标记为passed，而不会发出警告。 123456789101112131415job1: stage: test script: - execute_script_that_will_fail allow_failure: truejob2: stage: test script: - execute_script_that_will_succeedjob3: stage: deploy script: - deploy_to_staging whenwhen用于实现在发生故障或尽管失败时运行的作业，它有以下值: on_success： 只有当前几个阶段的所有工作都成功时才执行工作 on_failure： 仅当前一阶段中的至少一个作业失败时才执行作业 always： 无论先前阶段的工作状态如何，都可以执行工作 manual： 手动执行作业 delayed： 延迟执行作业(GitLab v11.4) 12345678910111213141516171819202122232425262728293031323334stages: - build - cleanup_build - test - deploy - cleanupbuild_job: stage: build script: - make buildcleanup_build_job: stage: cleanup_build script: - cleanup build when failed when: on_failuretest_job: stage: test script: - make testdeploy_job: stage: deploy script: - make deploy when: manualcleanup_job: stage: cleanup script: - cleanup after jobs when: always 手动操作是一种特殊类型的作业，不会自动执行，需要由用户明确启动。(例如，部署到生产环境)手动操作可以是可选的也可以是阻止的。阻止手动操作将在定义此操作的阶段阻止管道的执行。当有人通过单击播放按钮执行阻止手动操作时，可以继续执行管道。默认情况下，手动操作是非阻止的。如果要阻止手动操作，则需要添加allow_failure：false。手动操作被视为写入操作，因此当用户想要触发操作时，将使用受保护分支的权限。换句话说，为了触发分配给管道运行的分支的手动操作，用户需要具有合并到该分支的能力。 when: delayed，延迟作业用于在一段时间后执行脚本。如果要避免作业立即进入暂挂(pending)状态，这非常有用。你可以使用start_in键来设置时期，它的值是以秒(s)为单位的经过时间，或者你提供时间单位，它的值必须小于等于一小时。当阶段中的作业延迟时，管道将不会进展，直到延迟作业完成。这意味着此关键字也可用于在不同阶段之间插入延迟。延迟作业的计时器在前一阶段完成后立即开始。与其他类型的作业类似，除非前一阶段过去，否则延迟作业的计时器将无法启动。 12345678910#10 seconds#30 minutes#1 hour#栗子timed rollout 10%: stage: deploy script: echo &apos;Rolling out 10% ...&apos; when: delayed start_in: 30 minutes 您可以通过单击Unschedule按钮来停止延迟作业的活动计时器。除非您手动执行作业，否则将来不会执行此作业。您可以通过单击Play按钮立即开始延迟作业。 GitLab Runner很快就会选择你的工作并开始工作。 environmentenvironment用于定义作业部署到特定环境。如果指定了environment且该名称下没有环境，则将自动创建一个新环境。它有如下几个值: name url on_stop action 1234567891011121314151617181920212223242526272829303132333435363738#常见的名字有qa, staging, production#但你可以为你的工作流使用任何名称deploy to production: stage: deploy script: git push production HEAD:master environment: name: production#url是一个可选值#在设置时，它会在GitLab中的各个位置公开按钮，单击这些按钮会转到定义的URL#如果作业成功完成，它将在合并请求和environments/deployments页面中创建指向url的按钮deploy to production: stage: deploy script: git push production HEAD:master environment: name: production url: https://prod.example.com#on_stop来实现closing(stopping)环境。它声明了一个不同的工作，以便关闭环境#action与on_stop一起使用，在被调用以关闭环境的作业中定义review_app: stage: deploy script: make deploy-app environment: name: review on_stop: stop_review_appstop_review_app: stage: deploy script: make delete-app when: manual environment: name: review action: stop Dynamic environments123456deploy as review app: stage: deploy script: make deploy environment: name: review/$CI_COMMIT_REF_NAME url: https://$CI_ENVIRONMENT_SLUG.example.com/ cache Notes: Introduced in GitLab Runner v0.7.0 cache can be set globally and per-job From GitLab 9.0, caching is enabled and shared between pipelines and jobs by default-From GitLab 9.2, caches are restored before artifacts cache用于指定应在作业之间缓存的文件和目录列表，您只能使用项目工作区内的路径。如果在作业范围之外定义了cache，则表示它是全局设置的，并且所有作业都将使用该定义。 它的几个值: paths key untracked policy 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#paths指令选择要缓存的文件或目录。支持通配符rspec: script: test cache: paths: - binaries/*.apk - .config#由于cache是在作业之间共享的，如果对不同的作业使用不同的路径，则还应设置不同的cache:key，否则缓存内容可以被覆盖#key指令允许您定义作业之间的缓存关联，允许为所有作业提供single cache，cache per-job，cache per-branch或适合您工作流的任何其他方式cache: key: "$CI_COMMIT_REF_SLUG" paths: - binaries/#untracked：true缓存Git存储库中未跟踪的所有文件rspec: script: test cache: untracked: true paths: - binaries/#policy的默认行为是在执行开始时下载文件，并在结束时重新上载它们#这允许将作业所做的任何更改保留以供将来运行，并称为pull-push缓存策略#这有助于加快作业执行速度并减少缓存服务器上的负载，尤其是当您有大量并行执行缓存的作业时。stages: - setup - testprepare: stage: setup cache: key: gems paths: - vendor/bundle script: - bundle install --deploymentrspec: stage: test cache: key: gems paths: - vendor/bundle policy: pull script: - bundle exec rspec ... artifacts Notes: Introduced in GitLab Runner v0.7.0 for non-Windows platforms. Windows support was added in GitLab Runner v.1.0.0. From GitLab 9.2, caches are restored before artifacts. Not all executors are supported. Job artifacts are only collected for successful jobs by default. artifacts用于指定成功后应附加到作业的文件和目录列表。作业成功完成后，工件将被发送到GitLab，并可在GitLab UI中下载。 有以下值: paths name untracked when when: on_success when: on_failure when: always expire_in reports reports:junit reports:codequality reports:sast reports:dependency_scanning reports:container_scanning reports:dast reports:license_management reports:performance 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#artifacts:paths#要在不同作业之间传递工件，只能使用项目工作区内的路径default-job: script: - mvn test -U except: - tagsrelease-job: script: - mvn package -U artifacts: paths: - target/*.war only: - tags#artifacts:name#定义创建的工件归档的名称job: artifacts: name: "$CI_JOB_NAME" paths: - binaries/#artifacts:untracked#用于将所有Git未跟踪文件添加为工件artifacts: untracked: true paths: - binaries/#artifacts:when#用于在作业失败时上传工件job: artifacts: when: on_failure#artifacts:expire_in#允许您指定工件在到期之前应该存在多长时间并因此被删除，从它们上载和存储在GitLab上的时间开始计算#如果未定义到期时间，则默认为实例范围设置(默认30天)#到期后，每小时定时任务删除工件#默认单位是秒，支持提供时间单位#‘42’#‘3 mins 4 sec’#‘2 hrs 20 min’#‘2h20min’#‘6 mos 1 day’#‘47 yrs 6 mos and 4d’#‘3 weeks and 2 days’job: artifacts: expire_in: 1 week#artifacts:reports#用于从工作中收集测试报告并在GitLab UI中公开它们 dependencies此功能应与artifacts结合使用，并允许您定义要在不同作业之间传递的工件要使用此功能，请在作业上下文中定义dependencies，并传递应从中下载工件的所有先前作业的列表。 如果作为依赖项设置的作业的工件已过期或已擦除，则相关作业将失败。 1234567891011121314151617181920212223242526272829303132#当执行test:osx时，将在构建的上下文中下载并提取build:osx中的工件#test:linux也是如此，要从build: linux拉取工件build:osx: stage: build script: make build:osx artifacts: paths: - binaries/build:linux: stage: build script: make build:linux artifacts: paths: - binaries/test:osx: stage: test script: make test:osx dependencies: - build:osxtest:linux: stage: test script: make test:linux dependencies: - build:linuxdeploy: stage: deploy script: make deploy coverage允许您配置从作业输出中提取代码覆盖率的方式，正则表达式是此处唯一有效的值。 123job1: script: rspec coverage: '/Code coverage: \d+\.\d+/' retry允许您配置在发生故障时重试作业的次数。如果重试作业成功完成，则不会再进行剩余的重试。它的值为2&gt;=retry&gt;=0的正整数。 要更好的控制retry，可使用以下key: max: 最大重试次数 when: 败的情况下重试 always: 重试任何失败 (default) unknown_failure: 失败原因未知时重试 script_failure: 脚本失败时重试 api_failure: API失败重试 stuck_or_timeout_failure: 当作业卡住或超时时重试 runner_system_failure: 如果Runner故障，重试 missing_dependency_failure: 如果缺少依赖项，重试 runner_unsupported: 如果Runner不受支持，重试 123456789101112test: script: rspec retry: 2test: script: rspec retry: max: 2 when: - runner_system_failure - stuck_or_timeout_failure parallel允许您配置并行运行的作业实例数，它的值50&gt;=parallel&gt;=2。 1234#简单栗子test: script: rspec parallel: 5 include Introduced in GitLab Premium 10.5 使用include，可以允许包含外部YAML文件(本地Repo或远程URL)，但也需要为.yml和.yaml扩展格式。 1234567# Content of .gitlab-ci.ymlinclude: 'https://gitlab.com/awesome-project/raw/master/.before-script-template.yml'rspec: script: - bundle exec rspec variables 整数(浮点数)对于变量是有效的，浮点数无效。 GitLab CI/CD允许你在.gitlab-ci.yml中定义变量，然后在作业环境中传递。变量可以是全局的，也可以是基于每个作业的。当在作业级别定义了与全局或项目相同名称的变量时，则作业级别的变量会覆盖它们。 12variables: DATABASE_URL: "postgres://postgres@postgres/my_database" 特殊YAML功能可使用特殊的YAML功能，如锚点(anchors&amp;)、别名(aliases*)、map merging (&lt;&lt;)等，这大大降低了.gitlab-ci.yml的复杂性。 Hidden keys (jobs)如果要暂时禁用作业，而不是注释掉定义作业的所有行，你可是在作业名前加一个点(.)，这样GitLab CI将会忽略它。 123456789#hidden_job:# script:# - run test.hidden_job: script: - run test AnchorsYAML的锚点功能此处就不赘述了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#使用锚点和map merging.job_template: &amp;job_definition script: - test project.postgres_services: services: &amp;postgres_definition - postgres - ruby.mysql_services: services: &amp;mysql_definition - mysql - rubytest:postgres: &lt;&lt;: *job_definition services: *postgres_definitiontest:mysql: &lt;&lt;: *job_definition services: *mysql_definition---#扩展应该为这个样子.job_template: script: - test project.postgres_services: services: - postgres - ruby.mysql_services: services: - mysql - rubytest:postgres: script: - test project services: - postgres - rubytest:mysql: script: - test project services: - mysql - ruby GitLab CI/CD栗子各种语言、框架 、操作系统 CI/CD栗子: https://docs.gitlab.com/ce/ci/examples/README.html PHP Ruby Python Java Scala Clojure Elixir IOS and MacOS Android Debian Maven Git配置项Git configuration options 自定Git hooksCustom Git hooks: Custom Git hooks (on the filesystem) for when webhooks aren’t enough 注意：必须在GitLab服务器的文件系统上配置自定义Git hooks。只有GitLab服务器管理员才能完成这些任务。 Git本身支持在不同操作上执行的hooks。服务器端git hooks的示例包括预接收，后接收和更新。从gitlab-shell 2.2.0版（需要GitLab 7.5+）开始，GitLab管理员可以为任何GitLab项目添加自定义git hooks。 配置通常，Githooks放在存储库或项目的hooks目录中。 GitLab从每个项目的hooks目录创建一个符号链接到gitlab-shell hooks目录，以便于gitlab-shell升级之间的维护。因此，自定义挂钩的实现方式略有不同。但是，一旦创建了钩子，行为就完全相同了。 请按照以下步骤设置自定义hooks： 选择一个需要自定义Git hook的项目 在GitLab Server，导航到项目的存储库目录(如: /var/opt/gitlab/git-data/repositories/user/xx.git) 此位置创建名为custom_hooks的新目录 在custom_hooks目录中，创建一个名称与hook类型匹配的文件(如: pre-hook) 修改hook文件属主为git，添加可执行权限 编写代码以使Git hook函数按预期方式运行，可以是任何语言。确保顶部的shebang(#!/bin/python3)正确反映语言类型 假设正确实现了hook代码，hook将适当地触发。 链式hookChained hooks support 在GitLab Shell 4.1.0和GitLab 8.15中引入 hook也可以放在hook/&lt;hook_name&gt;.d（全局）或custom_hooks/&lt;hook_name&gt;.d（每个项目）目录中，支持钩子的链式执行。注意：&lt;hook_name&gt;.d需要pre-receive.d，post-receive.d或update.d才能正常工作。任何其他名称都将被忽略 要查看全局自定义hook（hook/&lt;hook_name.d&gt;）中的不同目录，请在gitlab-shell config中设置custom_hooks_dir。对于Omnibus安装，可在gitlab.rb中设置。 按以下顺序搜索并执行hook： gitlab-shell/hooks directory as known to Gitaly &lt;project&gt;.git/hooks/&lt;hook_name&gt; - executed by git itself, this is gitlab-shell/hooks/&lt;hook_name&gt; &lt;project&gt;.git/custom_hooks/&lt;hook_name&gt; - per project hook &lt;project&gt;.git/custom_hooks/&lt;hook_name&gt;.d/* - per project hooks &lt;project&gt;.git/hooks/&lt;hook_name&gt;.d/* OR &lt;custom_hooks_dir&gt;/&lt;hook_name.d&gt;/* - global hooks: all executable files 自定义错误信息Custom error messages 在GitLab 8.10中引入 如果commit被拒绝或在Git hook检查期间发生错误，则钩子的STDERR或STDOUT消息将出现在GitLab的UI中，STDERR优先于STDOUT。 Git LFS Git LFS: https://docs.gitlab.com/ce/workflow/lfs/manage_large_binaries_with_git_lfs.html Git LFS config: https://docs.gitlab.com/ce/workflow/lfs/lfs_administration.html 管理音频，视频和图形文件等大文件一直是Git的缺点之一。一般建议是不要让Git存储库大于1GB以保持性能。 HousekeepingHousekeeping(管家): Keep your Git repositories tidy and fast 在GitLab 8.4中引入 Automatic housekeeping在Git push后，GitLab会自动在存储库上运行git gc和git repack命令。如果需要，您可以更改这种情况发生的频率，或者将其关闭。在Admin ares -&gt; Setting Manual housekeepinghousekeeping功能将运行gc还是repack，取决于你的设置。 Git协议Configuring Git Protocol v2: Git protocol version 2 support 在GitLab 11.4中引入 Git第二版协议以多种方式改进了第一版协议，并且在GitLab中默认为HTTP请求启用。要为SSH启用，管理员需要进一步配置。 Requirements： 客户端，git v2.18.0+ 服务端，如果要配置SSH，需要设置sshd以接受GIT_PROTOCOL环境变量 12345678910111213141516171819202122232425262728293031323334#/etc/ssh/sshd_configAcceptEnv GIT_PROTOCOLsudo service ssh restart#配置新协议#局部git -c protocol.version=2#全局git config --global protocol.version 2#验证#HTTP#C端GIT_TRACE_CURL=1 git -c protocol.version=2 ls-remote https://your-gitlab-instance.com/group/repo.git 2&gt;&amp;1 | grep Git-Protocol#S端GIT_TRACE_PACKET=1 git -c protocol.version=2 ls-remote https://your-gitlab-instance.com/group/repo.git 2&gt;&amp;1 | head#SSH#C端GIT_SSH_COMMAND=&quot;ssh -v&quot; git -c protocol.version=2 ls-remote ssh://your-gitlab-instance.com:group/repo.git 2&gt;&amp;1 |grep GIT_PROTOCOL 监控Monitoring GitLab 故障排除Troubleshooting RunnerRunner是GitLab CI的客户端。 作为GitLab持续集成和持续部署(CI/CD)的一部分，主要用来配置和运行构建脚本以及其他的任务。GitLab Runner 是一个开源项目， 它用来运行你定制的任务（jobs）并把结果返回给 GitLab。 GitLab Runner配合GitLab CI（GitLab 内置的持续集成服务）协调完成任务。 要求(Requirements) GitLab Runner是用Go编写的，可以作为单个二进制文件运行，不需要语言特定的要求。它可在多个操作系统上运行，只要你在此平台上编译成二进制文件。支持Docker v1.5+。 特点(Feature) Allows to run: multiple jobs concurrently(同时) use multiple tokens with multiple server (even per-project) limit number of concurrent(并发) jobs per-token Jobs can be run: locally using Docker containers using Docker containers and executing job over SSH using Docker containers with autoscaling on different clouds and virtualization hypervisors connecting to remote SSH server Is written in Go and distributed as single binary without any other requirements Supports Bash, Windows Batch and Windows PowerShell Works on GNU/Linux, OS X and Windows (pretty much anywhere you can run Docker) Allows to customize the job running environment Automatic configuration reload without restart Easy to use setup with support for Docker, Docker-SSH, Parallels or SSH running environments Enables caching of Docker containers Easy installation as a service for GNU/Linux, OSX and Windows Embedded Prometheus metrics HTTP server 兼容性图表(Compatibility chart) GitLab Runner的版本应该与GitLab同步。如果存在版本差异，则功能可能无法使用或无法正常工作。 安装Install GitLab Runner Install using GitLab’s repository for Debian/Ubuntu/CentOS/RedHat (preferred) Install on GNU/Linux manually (advanced) Install on macOS Install on Windows Install as a Docker service Install in autoscaling mode using Docker machine Install on FreeBSD Install on Kubernetes Install the nightly binary manually (development) RepositoryInstall GitLab Runner using the official GitLab repositories 安装： 123456789101112131415161718192021222324252627282930313233343536#添加镜像库# For Debian/Ubuntu/Mintcurl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.deb.sh | sudo bash# For RHEL/CentOS/Fedoracurl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.rpm.sh | sudo bash#安装最新版# For Debian/Ubuntu/Mintsudo apt-get install gitlab-runner# For RHEL/CentOS/Fedorasudo yum install gitlab-runner#安装制定版本# for DEB based systemsapt-cache madison gitlab-runnersudo apt-get install gitlab-runner=10.0.0# for RPM based systemsyum list gitlab-runner --showduplicates | sort -rsudo yum install gitlab-runner-10.0.0-1#注册Runner#注册Runner参考后面 更新： 12345678# For Debian/Ubuntu/Mintsudo apt-get updatesudo apt-get install gitlab-runner# For RHEL/CentOS/Fedorasudo yum updatesudo yum install gitlab-runner 手动下载包安装 下载地址: https://packages.gitlab.com/runner/gitlab-runner 升级到GitLab Runner 10 1234567891011121314#移除旧库# For Debian/Ubuntu/Mintsudo rm /etc/apt/sources.list.d/runner_gitlab-ci-multi-runner.list# For RHEL/CentOS/Fedorasudo rm /etc/yum.repos.d/runner_gitlab-ci-multi-runner.repo#安装新库#再安装 手动安装12345678910111213141516171819202122232425262728293031#下载二进制包# Linux x86-64sudo wget -O /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64# Linux x86sudo wget -O /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-386# Linux armsudo wget -O /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-arm#添加可执行权限sudo chmod +x /usr/local/bin/gitlab-runner#如果想使用Dockercurl -sSL https://get.docker.com/ | sh#Create a GitLab CI user:sudo useradd --comment 'GitLab Runner' --create-home gitlab-runner --shell /bin/bash#Install and run as service:sudo gitlab-runner install --user=gitlab-runner --working-directory=/home/gitlab-runnersudo gitlab-runner start#Register the Runner#更新的话重新下载二进制包安装 Docker123456789101112131415#挂载运行 docker run -d --name gitlab-runner --restart always \ -v /srv/gitlab-runner/config:/etc/gitlab-runner \ -v /var/run/docker.sock:/var/run/docker.sock \ gitlab/gitlab-runner:latest#Register the Runner#更新的话，停止旧容器，拉取新镜像#GitLab Runner Logs#可以把Runner Logs目录挂载到宿主机，也可是使用docker 读取 k8s Autoscale 注册Register GitLab Runner 安装GitLab Runner后，需要将其注册到GitLab。注册Runner是将Runner与GitLab实例绑定的过程。 要求(Requirements)，在注册Runner之前，你需要： 将其安装在与安装GitLab位置不同的Server上 通过GitLab的界面获取共享或特定Runner的Token 注册环境： GNU/Linux macOS Windows FreeBSD Docker … GNU/Linux在GNU / Linux下注册Runner： 12345678910111213141516171819202122232425262728293031323334353637383940#URL和Token在GitLab实例的runner里面去看#运行命令sudo gitlab-runner register#输入GitLab 实例 URLPlease enter the gitlab-ci coordinator URL (e.g. https://gitlab.com )https://gitlab.com#输入获得的tokenPlease enter the gitlab-ci token for this runnerxxx#输入Runner的描述，之后可在Web UI下更改Please enter the gitlab-ci description for this runner[hostame] my-runner#输入与Runner相关联的tag，之后可在Web UI下更改Please enter the gitlab-ci tags for this runner (comma separated):my-tag,another-tag#输入Runner executorPlease enter the executor: ssh, docker+machine, docker-ssh+machine, kubernetes, docker, parallels, virtualbox, docker-ssh, shell:docker#如果您选择Docker作为执行程序，则会要求您未在.gitlab-ci.yml中定义的用于项目的默认imagePlease enter the Docker image (eg. ruby:2.1):alpine:latest#启动runnersudo systemctl start gitlab-runner 单行注册命令One-line registration command 如果要使用非交互模式注册Runner，可以使用register子命令或使用其等效的环境变量。 123456789101112131415#查看帮助gitlab-runner register -h#注册sudo gitlab-runner register \ --non-interactive \ --url "https://gitlab.com/" \ --registration-token "PROJECT_REGISTRATION_TOKEN" \ --executor "docker" \ --docker-image alpine:3 \ --description "docker-runner" \ --tag-list "docker,aws" \ --run-untagged \ --locked="false" \ 执行器Executors GitLab Runner实现了许多执行程序，可用于在不同的场景中运行构建。 执行器： Shell Docker Docker Machine and Docker Machine SSH (autoscaling) Parallels VirtualBox SSH Kubernetes 选择执行器Selecting the executor GitLab Runner实现了许多执行程序，可用于在不同的场景中运行构建。如果您不确定要选择什么，请阅读“我不确定”部分。访问兼容性图表，了解每个执行程序支持哪些功能，哪些功能不支持。 执行器支持不同平台和方法的项目构建： Executor SSH Shell VirtualBox Parallels Docker Kubernetes Clean build environment for every build ✗ ✗ ✓ ✓ ✓ ✓ Migrate runner machine ✗ ✗ partial partial ✓ ✓ Zero-configuration support for concurrent builds ✗ ✗ (1) ✓ ✓ ✓ ✓ Complicated build environments ✗ ✗ (2) ✓ (3) ✓ (3) ✓ ✓ Debugging build problems easy easy hard hard medium medium 不清楚该选择哪个执行器I am not sure ShellShell是最简单的配置执行器。需要在安装Runner的同一台机器上手动安装构建的所有必需依赖项。 Virtual Machine此类执行器允许您使用已创建的虚拟机，该虚拟机已克隆并用于运行构建。我们提供两种完整的系统虚拟化选项：VirtualBox和Parallels。如果您希望在不同的操作系统上运行构建，它们可以证明是有用的，因为它允许在Windows，Linux，OSX或FreeBSD上创建虚拟机，然后GitLab Runner连接到虚拟机并在其上运行构建。它的使用对于降低基础设施成本也很有用。 Docker一个很好的选择是使用Docker，因为它允许一个干净的构建环境，并且易于依赖管理（构建项目的所有依赖项都可以放在Docker镜像中）。 Docker执行程序允许您轻松创建具有依赖服务的构建环境，如MySQL KubernetesKubernetes执行程序允许您使用现有的Kubernetes集群进行构建。执行程序将调用Kubernetes集群API并为每个GitLab CI作业创建一个新的Pod（带有构建容器和服务容器）。 SSH添加SSH执行程序是为了完整性，但它是所有执行程序中支持最少的。它使GitLab Runner连接到外部服务器并在那里运行构建。(通常建议使用其它案例) 兼容性Compatibility 不同执行器支持的功能： Executor SSH Shell VirtualBox Parallels Docker Kubernetes Secure Variables ✓ ✓ ✓ ✓ ✓ ✓ GitLab Runner Exec command ✗ ✓ ✗ ✗ ✓ ✓ gitlab-ci.yml: image ✗ ✗ ✗ ✗ ✓ ✓ gitlab-ci.yml: services ✗ ✗ ✗ ✗ ✓ ✓ gitlab-ci.yml: cache ✓ ✓ ✓ ✓ ✓ ✓ gitlab-ci.yml: artifacts ✓ ✓ ✓ ✓ ✓ ✓ Absolute paths: caching, artifacts ✗ ✗ ✗ ✗ ✗ ✓ Passing artifacts between stages ✓ ✓ ✓ ✓ ✓ ✓ Use GitLab Container Registry private images n/a n/a n/a n/a ✓ ✓ Interactive Web terminal ✗ ✓ (bash) ✗ ✗ ✓ ✓ 不同shell支持的系统： Shells Bash Windows Batch PowerShell Windows ✓ ✓ (default) ✓ Linux ✓ (default) ✗ ✗ OSX ✓ (default) ✗ ✗ FreeBSD ✓ (default) ✗ ✗ 不同shell支持的交互式Web终端： Shells Bash Windows Batch PowerShell Windows ✗ ✗ ✗ Linux ✓ ✗ ✗ OSX ✓ ✗ ✗ FreeBSD ✓ ✗ ✗ ShellShell executor 是一个简单的执行程序，它允许您在运行Runner的机器上本地执行构建。它支持可以安装Runner的所有系统。这意味着它可使用Bash和PowerShell。 在Bash中，在gitlab-runner command命令之后加上--user，表示使用非特权用户运行。 源项目被切换到: &lt;working-directory&gt;/builds/&lt;short-token&gt;/&lt;concurrent-id&gt;/&lt;namespace&gt;/&lt;project-name&gt;项目的缓存放于: &lt;working-directory&gt;/cache/&lt;namespace&gt;/&lt;project-name&gt; 这些都在GitLab-runner的配置: /etc/gitlab-runner/atom.config.toml 以非特权用户运行(Running as unprivileged user) 在Linux上(rpm/dpk)，安装程序将尝试使用gitlab_ci_multi_runner用户(如果找到)；如果找不到，它将创建一个gitlab-runner用户并改为使用它。然后，所有shell build都将使用gitlab-runner或gitlab_ci_multi_runner用户执行。 在某些场景中，您的构建可能需要访问某些特权资源，例如Docker Engine或VirtualBox。在这种情况下，您需要将gitlab-runner用户添加到相应的组： 12usermod -aG docker gitlab-runnerusermod -aG vboxusers gitlab-runner DockerThe Docker executor 文档: https://docs.gitlab.com/runner/executors/docker.html K8sThe Kubernetes executor 文档: https://docs.gitlab.com/runner/executors/kubernetes.html 高级配置Advanced Configuration 配置文件Advanced configuration options Learn how to use the TOML configuration file that GitLab Runner uses. GitLab Runner配置使用TOML格式，配置文件可能在如下位置: /etc/gitlab-runner/config.toml ~/.gitlab-runner/config.toml ./config.toml global部分这定义了GitLab Runner的全局配置。 配置 描述 concurrent 限制全局可以同时运行多少个作业，0并不意味着无限制 log_level 日志级别(debug, info, warn, error, fatal, panic) log_format 日志格式(runner, text, json) check_interval 定义新作业检查之间的间隔长度(s)。默认值为3，如果设置为0或更低，将使用默认值 sentry_dsn 启用追踪所有系统级错误 listen_address host:port，Prometheus应该在其上进行监听 check_interval 如何工作: 如果config.toml配置文件中有多个[[runner]](称之为worker)，那么GitLab请求之间的间隔比人们预期的要频繁。GitLab Runner包含一个循环，该循环不断地为worker针对其配置的GitLab实例调度请求。 [session_server]部分[session_server]是系统运行程序级别的配置，因此应该在根级别指定，而不是每个执行器指定，即它应该在[[runners]]部分之外。session server允许用户与Runner负责的作业进行交互。如果想要禁用[session_server]部分，删掉它即可。 配置 描述 listen_address 用于session server的内部URL advertise_address 向GitLab公开的用于访问Runner的URL session_timeout 作业完成后，会话可以在多长时间内保持活动状态(默认1800s) [[runners]]部分如下定义了Runner entry: 配置 描述 name Runner的描述 url GitLab URL token Runner指定的token tls-ca-file HTTPS的CA证书 tls-cert-file HTTP的S端证书 tls-key-file HTTPS的S端Key limit 限制此token可同时处理的作业数，0为不限制 executor 执行器 shell 用于生成脚本的shell的名称 builds_dir 构建将存储在所选执行器的上下文中的目录(local, docker, ssh) cache_dir 构建缓存将存储在所选执行器的上下文中的目录(local, docker, ssh) environment 附加或覆盖环境变量 request_concurrency 限制GitLab新作业的并发请求数（默认值为1） output_limit 最大构建日志大小(默认4096KB) pre_clone_script 在克隆Git存储库之前要在Runner上执行的命令 pre_build_script 克隆Git存储库之后但在执行构建之前要在Runner上执行的命令 post_build_script 在执行构建之后但在执行after_script之前在Runner上执行的命令 clone_url 覆盖GitLab实例的URL clone_url怎样工作: 如果GitLab实例公开给Runner无法使用的URL，则可以配置clone_url。 #### EXECUTORS shell docker docker-ssh ssh parallels virtualbox docker+machine docker-ssh+machine kubernetes SHELLS bash sh cmd powershell #### [runners.docker]部分 参数 描述 host 指定Docker endpoint (默认 $DOCKER_HOST或unix:///var/run/docker.sock) hostname 为Docker容器指定主机名 runtime 为Docker容器指定一个运行环境 tls_cert_path 证书路径 image 使用此镜像进行构建 memory 容器内存限制 memory_swap 总内存限制 memory_reservation 容器内存soft limit oom_kill_disable 容器OOM后也不kill进程 cpuset_cpus 容器使用的CPU cpus CPU数量 dns 容器使用的DNS列表 dns_search DNS搜索域列表 privileged 特权容器 disable_entrypoint_overwrite 禁用镜像端点覆盖 userns_mode 启用usernamespace重映射选项时，为容器设置usernamespace模式 cap_add 向容器添加其他Linux功能 cap_drop 从容器中移除其他Linux功能 security_opt 设置安全选项(key: value) devices 与容器共享其他主机设备 cache_dir 指定缓存目录 disable_cache 禁用缓存 network_mode 将容器添加到一个自定义的网络 wait_for_services_timeout 等待docker的时间，0为禁用(默认30) volumes docker挂载卷 extra_hosts 指定应在容器环境中定义的主机 shm_size 指定镜像共享的内存大小(Byte)) volumes_from 指定从其它容器继承的卷(格式: `\[:\&lt;ro rw>]`) volume_driver 指定容器使用的卷的驱动 links 指定与其建立链接的容器 services 指定使用build运行的其它服务 allowed_images 指定可在.gitlab-ci.yml中指定的通配符图像列表 allowed_services 指定可在.gitlab-ci.yml中指定的通配符服务列表 pull_policy 指定镜像拉取策略 sysctls 指定sysctl options helper_image 覆盖用于克隆repos和上载工件的默认帮助程序镜像 [runners.parallels]部分 参数 描述 base_name 将克隆的Parallels VM的名称 template_name Parallels VM链接模板的自定义名称 disable_snapshots 如果禁用，则在构建之后将摧毁VM [runners.virtualbox]部分 参数 描述 base_name 要克隆的VirtualBox VM的名称 base_snapshot 要从中创建链接克隆的VM的特定快照的名称或UUID disable_snapshots 如果禁用，则在构建之后将摧毁VM [runners.ssh]部分 参数 描述 host 指定主机 port 指定端口 user 指定用户 password 指定密码 identity_file 指定私钥 [runners.machine]部分 Parameter Description IdleCount Number of machines, that need to be created and waiting in Idle state. IdleTime Time (in seconds) for machine to be in Idle state before it is removed. OffPeakPeriods Time periods when the scheduler is in the OffPeak mode. An array of cron-style patterns (described below). OffPeakTimezone Time zone for the times given in OffPeakPeriods. A timezone string like Europe/Berlin (defaults to the locale system setting of the host if omitted or empty). OffPeakIdleCount Like IdleCount, but for Off Peak time periods. OffPeakIdleTime Like IdleTime, but for Off Peak time mperiods. MaxBuilds Builds count after which machine will be removed. MachineName Name of the machine. It must contain %s, which will be replaced with a unique machine identifier. MachineDriver Docker Machine driver to use MachineOptions Docker Machine options [runners.cache]部分 Parameter Type Description Type string One of: s3, gcs Path string Name of the path to prepend to the cache URL Shared boolean Enables cache sharing between runners, false by default [runners.kubernetes]部分 参数 描述 host k8s master url cert_file k8s master认证证书 key_file k8s master 私钥 ca_file k8s master CA image 当未指定时，用于构建的默认docker镜像 namespace 命名空间 privileged 特权容器(true/false) node_selector 节点选择器 image_pull_secrets 镜像拉取秘钥 自签名证书Use self-signed certificates Configure certificates that are used to verify TLS peer when connecting to the GitLab server. 这允许在注册runner时解决由未知权限问题签名的证书(x509)。 支持自签名的证书: 默认情况下： GitLab Runner读取系统存储的证书并根据存储在系统中的CA验证GitLab服务器 GitLab Runner从预定义文件中读取PEM（不支持DER格式）证书: 如/etc/gitlab-runner/certs/ GitLab Runner在注册期间和[[runners]]部分下的config.toml配置中公开tls-ca-file选项，允许您指定带证书的自定义文件。每当Runner尝试访问GitLab服务器时，都会读取此文件。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>GitLab</tag>
        <tag>CI</tag>
        <tag>CD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大明官职]]></title>
    <url>%2F2018%2F12%2F05%2F%E6%98%8E%E6%9C%9D%E5%AE%98%E8%81%8C%2F</url>
    <content type="text"><![CDATA[参考： 维基百科 《万历十五年》 《南明史》 《中国历史地图集》 最近看《万历十五年》、《南明史》及电视剧“大明王朝1566”有感，想详细地了解一下大明王朝的官职制度。 朱明王朝是以“驱逐胡虏，恢复中华”为号召北伐中原。 1368年正月，朱元璋于南京称帝，即明太祖，年号洪武，明朝建立。大明朝（1368年1月23日）是中国历史上最后一个由汉人建立的大一统王朝。如按照李自成大顺军攻破北京，崇祯皇帝于煤山自缢(1644年)来算，历经十二世、十六位皇帝，国祚二百七十六年；如加上南明永历皇帝被吴三桂勒死于昆明(1662年)来算，历经十九位皇帝，国祚二百九十四年。 注：本文将按照万历时期来查看大明疆域和体制。 大明君主列表： 庙号 谥号 名讳 在世时间 年号 在位时间 太祖 高皇帝 朱元璋 1328年－1398年 洪武 1368年－1398年 惠宗 让皇帝 朱允炆 1377年－？ 建文 1398年－1402年 成祖 文皇帝 朱棣(di) 1360年－1424年 永乐 1402年－1424年 仁宗 昭皇帝 朱高炽(chi) 1378年－1425年 洪熙 1424年－1425年 宣宗 章皇帝 朱瞻基 1399年－1435年 宣德 1425年－1435年 英宗 睿皇帝 朱祁镇 1427年－1464年 正统 天顺(复辟) 1435年－1449年 1457年－1464年 代宗 景皇帝 朱祁钰 1428年－1457年 景泰 1449年－1457年 宪宗 纯皇帝 朱见深 1447年－1487年 成化 1464年－1487年 孝宗 敬皇帝 朱佑樘(cheng) 1470年－1505年 弘治 1487年－1505年 武宗 毅皇帝 朱厚照 1491年－1521年 正德 1505年－1521年 世宗 肃皇帝 朱厚熜 1507年－1567年 嘉靖 1521年－1567年 穆宗 庄皇帝 朱载坖(ji) 1537年－1572年 隆庆 1567年－1572年 神宗 显皇帝 朱翊钧 1563年－1620年 万历 1572年－1620年 光宗 贞皇帝 朱常洛 1582年－1620年 泰昌 1620年 熹宗 悊皇帝 朱由校 1605年－1627年 天启 1620年－1627年 怀宗 烈皇帝 朱由检 1611年－1644年 崇祯 1627年－1644年 南明 福王 朱由崧 1607年－1646年 弘光 1644年6月－1645年6月 南明 唐王 朱聿键 1602年－1646年 隆武 1645年8月－1646年10月 南明 桂王 朱由榔 1623年－1662年 永历 1646年12月－1661年8月 明一代为直隶二、布政使司十三。流俗称为两京一十三省。二直隶又称京师、南京二京，十三布政使司俗称十三省。 二京 京师顺天府(北直隶) 南京应天府(南直隶) 十三布政使司 陕西 山西 山东 河南 浙江 江西 湖广 四川 广东 福建 广西 贵州 云南 万历时期大明地图： 行政： 明朝一级地方行政区分置承宣布政使司（布政司）、提刑按察使司（按察司）与都指挥使司（都司）的都布按三司制度，分别掌管行政、司法与军事等三种治权，防止地方权力集中。 布政司通称省，底下依序有道、府州与县。道是明朝特别设置介于省和府州之间的行政单位，分为分守道和分巡道两种，分守道为布政司的派出机构，负责监督协调府州行政，分巡道为按察司的派出机构，负责监督协调府州司法治安。府为明朝最主要的统县政区，原为元朝的路，以税粮多寡为划分标准，粮廿万石以上为上府，廿万以下十万以上为中府，十万以下为下府。州与府同样是统县政区，但人口税收比府少，地位也比府低。州按照其行政隶属分为两类，直辖于布政司的州称直隶州，隶属于府的称散州或属州。军事区划有卫、所两级，但部分位于少数民族聚居区或边疆军屯区的卫所具有类似内地州县的行政职能，行政上分别相当于府与县。明代宗、明英宗时设有中央派出管理行政的巡抚与管理军事的总督，地位在布政司与都司之上。为限制巡抚与总督的权力，又设有都御史制衡之。明朝最后有140府，193州，1138县，493卫，359所。 巡抚主理民政，原本是明宣宗时期派六部、都察院大臣以此为名义督抚地方行政，到明代宗时正式形成一级行政区。总督于明英宗时设置，分短期与长期两种，管辖数个布政司的军务。 内阁 洪武十三年（1380年），明太祖以丞相胡惟庸谋反伏诛，于是废去中书省和丞相一职。秦、汉以降实行一千六百余年的宰相制度自此废除，六部直接向皇帝负责，相权与君权合而为一，大权独揽，施行军权、行政权、监察权三权分立的国家体制。由于国家事务繁多，皇帝无法处理，而明太祖也一度深感疲惫，于是设立四辅制度来辅佐政事。但这项制度效能不彰。洪武十七年（1384年）后被废。之后朱元璋请来几位翰林学士帮忙辅佐，这些翰林学士的官职效仿唐宋馆阁学士旧制，被命为“某某殿（阁）大学士”[注 24]，官阶只有正五品。明成祖登基后，特派解缙、胡广、杨荣等入午门值文渊阁，参预机务，由此始设内阁 内阁最初只是皇帝的咨询机构，相当于今日秘书或幕僚的职务，奏章的批答为皇帝的专责。到后来成为明朝实际上最高决策机构，首辅地位有时可比丞相，有票拟之权明朝内阁由始至终都不是明朝中枢的一级行政机构，所谓内阁只是文渊阁的别称。内阁大学士一职多以硕德宿儒或朝中大臣担任，只照皇帝的意旨写出，称“传旨当笔”，权力及地位远远不及过去的宰相，只有有实无名之地位，而没有法定地位。宣宗时期，由于杨溥、杨士奇、杨荣等三杨入阁，宣宗批准内阁在奏章上以条旨陈述己见，称为“票拟”制度，又授予宦官机构司礼监“批红”。票拟之法补救可君主不愿面见阁臣之弊，但内阁大臣与皇帝沟通，全赖司礼监（宦官）。 六部 明朝在中央设置吏、户、礼、工、刑、兵六部，与前代相比，明朝最初在每部增加尚书、侍郎各一。胡惟庸案之后，朱元璋废丞相之职，取消中书省。六部因此地位得到提高。每部只设一个尚书，两个侍郎，原有的各科尚书降为郎中。各部尚书和侍郎的官阶也上升。其中以礼部（主管教育，负责领导儒家学术，以及祭祀，外交等）和吏部（主管文官升迁）最为重要，户部（主管财政，土地和人口）人员最多。兵部（主管国防），刑部（主管司法，有对较大刑事案件的审判权）与工部（主管公共建设）地位较低。 在拟诏审议机构上，明朝开始只设给事中与中书舍人，不复设中书门下二省。明朝的审议机构为六科给事中，到洪武廿四年，设都给事中六人，分吏、户、礼、工、刑、兵六科，每科一人，每科都给事中下设左右给事中各一人及给事中若干。六科给事中制度基本是继承唐朝的门下省制度，但官位下降，机构更为精简，也失去了自魏晋以来皇帝内臣（皇室的收发站）和礼官的职责。六科官职品级虽低，然职权很高，他们可以批驳皇帝的意旨， 也能充当谏官的职责，对六部吏僚则具有分科对应的监察权，故该制度也发挥一定的改善朝政作用。明朝的拟诏机构为中书舍人官署，因其制度源流源于与门下并立的中书，故与六科相对俗称 “中书科”，但是其地位大为下降，职能也大幅削弱，事实上只是内阁与翰林院的誊抄机构。中央的重要事务执行机构为五寺，包括大理寺、太常寺、光禄寺、太仆寺、鸿胪寺，与唐宋相比，减省了四寺：宗正寺被并入宗人府，卫尉寺被并入兵部，司农寺与太府寺被并入户部。大理寺与刑部和都察院合为三法司，负责重大刑事案件的复审与复核。大理寺的首长称为大理寺卿，也是九卿之一。其余四个寺的卿职权较低。太常寺负责祭祀；太仆寺管理马匹与全国牧政；光禄寺负责寿宴；鸿胪寺负责接待外宾。 监察机构 在洪武十三年前，明朝还沿袭元的监察制度，设立御史台，有左右御史大夫各一名。洪武十三年后，朱元璋废御史台。两年之后，朱元璋设立新的监察机构—都察院。都察院下面设立监察御史若干人，分巡全国各省，称为十二道监察御史。每道有监察御史三至五人，范围大体为一省。但监察御史都驻在京师，有事带印出巡，事毕回京缴印。到明末，监察御史分为十三道，共有一百一十人。都察院与六科同样具有谏官的职能和风闻言事的职责，故合称“科道言官”。 厂卫制度 明初还实行特务机构，主要包括锦衣卫、东厂和西厂，武宗时期还一度设有内行厂。锦衣卫设立于洪武十五年，直接听命于皇上，可以逮捕任何人，并进行不公开的审讯。但是朱元璋晚年逐步废除了锦衣卫及其特权，还有一些比较残酷的刑法。在东厂设立后，锦衣卫权力受到削弱。东厂成立于永乐十八年，是明成祖为镇压政治上的反对力量而成立。地点位于京师东安门北。东厂的主要职责就是监视政府官员、社会名流、学者等各种政治力量，并有权将监视结果直接向皇帝汇报。依据监视得到的情报，对于那些地位较低的政治反对派，东厂可以直接逮捕、审讯；而对于担任政府高级官员或者有皇室贵族身份的反对派，东厂在得到皇帝的授权后也能够对其执行逮捕、审讯。东厂在设立之初，就由宦官担任提督，后来通常以司礼监秉笔太监中位居第二、第三者担任。西厂设立于宪宗时期，首领为汪直。1482年后被废。其后又被武宗短暂恢复。内厂设置于武宗时期，首领为宦官刘瑾，刘瑾伏诛后，内厂与西厂同时被废除，仅留东厂。 其它机构 公孤官包括三公与三孤，是名义上的诸臣之首，但这些官职都是虚衔，一般授予功劳相当大的大臣以示荣耀。三公为太师、太傅、太保，三孤则是辅弼他们的少师、少傅、少保。其中太保和太傅名义上是太子的老师，而太师则是皇帝名义上的老师，但实际上辅导太子的机构是詹事府。詹事府下设两坊、一局、一厅。此外还有太医院，专门负责皇室人员的健康和医疗。太医院附属有生药库和惠民药局。翰林院作为政府的官方学术最高机构，地位相当重要，甚至在政府中都有相当大的影响力。翰林院首长是翰林大学士，此职位者经常会同时兼任内阁大臣。 诸司指不属于各部院的司。主要指通政司和行人司。通政司负责传递公文，公告周知。行人司负责到地方上颁诏谕及赴外国作使臣。 外三监包括国子监、钦天监、上林苑监。钦天监负责观测星象。国子监是最高官方教育机构，也是全国官学的领导机构，有祭酒一人，司业一人，监丞一人，博士五人，助教十五人，学正十人，学录七人，典簿一人，典籍一人，典馔两人。上林苑监负责掌管皇帝的御花园，畜牧场与菜圃。 内十二监为宦官衙门。事实上只有在这些衙门工作的宦官才是太监。包括司礼监、内宫监、御用监、司设监、御马监、神宫监、尚膳监、尚宝监、印绶监、直殿监、尚衣监、都知监。以司礼监最为重要，监内的提督太监主管宫内一切宦官礼仪刑名。而秉笔太监在宦官极端专权时竟代替皇帝批公文。此外宫内还设有四个司（惜薪、钟鼓、宝钞、混堂），八个局（兵仗、银作、浣衣、巾帽、针工、内织染、酒醋面，司苑），合为内官廿四衙门。宫女也有六个局（尚宫、尚仪、尚服、尚食、尚寝、尚工），每个局下设四个司。]]></content>
      <categories>
        <category>History</category>
      </categories>
      <tags>
        <tag>大明</tag>
        <tag>历史</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一战二战武器]]></title>
    <url>%2F2018%2F11%2F18%2F%E4%B8%80%E6%88%98%E4%BA%8C%E6%88%98%E6%AD%A6%E5%99%A8%2F</url>
    <content type="text"><![CDATA[参考： 各国一战武器，维基百科 第一次世界大战武器装备，维基百科 各国二战武器，维基百科 第二次世界大战武器装备，维基百科 最近玩battlefield I(一战)有感，一时兴起，顺带在battlefield V(二战)发布前夕做一个一战二战各国使用的武器装备归纳总结。 玩了战地1，才体会到战争的残酷性，使我对战争的感觉从光辉转变为厌恶。没有什么英雄在我心中，你不知道自己何时会死去，或即将死去。战场上每个人都一样，都是一条鲜活的生命，有家人有朋友。从战争游戏来反思战争，这点DICE studio做的不错。 衷心祝愿世界和平！ 一战第一次世界大战（简称一次大战、一战，或称欧战；英语：World War I、WWI、Great War、First World War；法语：la première Guerre Mondiale、la Grande Guerre）是一场于1914年7月28日至1918年11月11日主要发生在欧洲的大战，然而战火最终延烧至全球，当时世界上大多数国家都被卷入这场战争，史称“第一次世界大战”。 主要介绍国家： 德国 法国 俄国 英国 美国 主要武器分类： 枪械 大炮 坦克 飞机 船舰 德国第一次世界大战德国主要武器 手榴弹hand grenade 柄式手榴弹 柄式手榴弹（德语：Stielhandgranate）为德国陆军自第一次世界大战中期至第二次世界大战末期所使用之手榴弹。 12345重量 595克长度 365毫米直径 70毫米填充 三硝基甲苯（TNT）引爆机制 5秒 手枪pistol 毛瑟C96(Mauser C96) 由毛瑟在1896年推出的手枪，在中国还有驳壳枪、快慢机、自来得、大镜面等别称。毛瑟（德语：Mauser）是一个德国的枪械制造商。 1234567891011121314151617重量 1.130公斤（空枪）长度 288毫米枪管长度 140毫米子弹 7.63×25mm毛瑟弹 9×19mm鲁格弹 .45 ACP 9×25mm毛瑟弹枪机 枪管短行程后座作用 单动发射模式 C96：半自动 M712速射型：半自动、全自动枪口初速 425米/秒有效射程 100米最大射程 200米供弹方式 C96：10发内置弹仓M712速射型：10发或20发弹匣瞄具 V型照门上刻度最大可调至1000米 鲁格手枪（Pistole 08 Luger) 简称P08该枪由奥地利人格奥尔格·鲁格于1898年设计，并由以德国武器及弹药兵工厂及毛瑟为首等多间工厂于1900年投入生产。 1234567891011重量 1.92磅（871克）长度 8.75英寸（222毫米）枪管长度 98毫米–203毫米 （3.9 -8.02英寸）子弹 7.65×21毫米帕拉贝伦弹 9毫米鲁格弹 .45 ACP（相当罕见）枪机 枪管短行程后座作用，肘节式起落闭锁（Toggle Lock）枪口初速 350 - 400米/秒有效射程 50米供弹方式 8发弹匣、32发弹鼓 帝国转轮手枪（Reichsrevolver） 该枪后来被著名的鲁格P08半自动手枪所取代。 12345678重量 1040克长度 310毫米子弹 10.6×25mmR口径 10.6mm射速 单动式枪口初速 205米/秒供弹方式 6发弹巢瞄具 V型缺口及准星 贝格曼1896型手枪 12345678910重量 1.13 kg长度 254 mm枪管长度 102 mm子弹 5毫米贝格曼弹6.5毫米贝格曼弹8×22毫米贝格曼弹枪机 反冲作用枪口初速 380米/秒供弹方式 5发载入内置弹仓内瞄具 固定式瞄具 费罗梅尔停止手枪()Frommer Stop 12345678重量 610 g（22 oz）长度 165 mm（6.5英寸）枪管长度 95毫米（3.7英寸）子弹 .32 ACP.380 ACP枪机 长行程后座作用枪口初速 280 m/s（919 ft/s）供弹方式 7发弹匣 冲锋枪Submachine Guns MP18 MP18冲锋枪是第一次世界大战时期由德国的胡戈·施梅瑟所开发的冲锋枪。MP18冲锋枪因其生产厂Bergmann也被称为伯格曼冲锋枪。 1234567891011重量 4.18公斤长度 832毫米枪管长度 200 毫米子弹 9毫米鲁格弹7.63×25毫米毛瑟弹枪机 反冲作用、开放式枪机发射模式 MP18：全自动MP28：半自动、全自动射速 500发/分枪口初速 380米/秒供弹方式 32发弹匣 TM 08 （一战）；20，30 和 50 发弹匣（二战前） 机枪machine gun MG08重机枪 Maschinengewehr 08（也称MG08，Maschinengewehr意为机枪）由海勒姆·马克沁1884年开发的马克沁机枪发展而来。 1234567891011121314重量 连冷却水一共 69 kg ，除去冷却水65 kg 枪身26.5 kg 4 kg水 三脚架38.5 kg MG08/15：连同两脚架17.8kg 水 3KG MG08/18：不含两脚架14.5KG长度 1175 mm MG08/15、MG08/18：1445 mm枪管长度 720mm操作人数 4人班组子弹 7.92×57毫米毛瑟枪机 枪管短后座，肘节式起落闭锁射速 450-500 发/分枪口初速 900米每秒（3,000英尺每秒）有效射程 2,000米（2,200码）最大射程 3,500米（3,800码）供弹方式 250 发弹链 麦德森轻机枪(Madsen machine gun) 这也是全世界上第一种大量生产的真正实用化的轻机枪。 123456789101112131415161718重量 空枪：9.07 千克（20 磅）长度 1,143 毫米（45 英寸）枪管长度 584.2 毫米（23 英寸）子弹6.5×55毫米瑞典子弹7×57毫米毛瑟子弹7.65×53毫米阿根廷子弹7.62×51毫米NATO7.62×54毫米R.303英式子弹[1]7.92×57毫米毛瑟子弹枪管 1 根，膛线4 条，右旋，枪管装上风冷式枪管套和消焰器枪机 枪管长行程后座作用发射模式 全自动射速 450发／分钟枪口初速 6.5×55毫米瑞典子弹：700—870米／秒（2,296.59—2,854.33英尺／秒）供弹方式 25、30、40发可拆卸式弹匣瞄具 机械瞄具：Ｖ型缺口式照门及柱状准星 步枪rifle Gewehr 98步枪 Gewehr 98步枪（又称：G98、Gew 98、毛瑟M1898或M98）是德国毛瑟枪厂在德国军方采用Gewehr 88步枪后，为了夺回在德国枪械市场的地位而研制的步枪。Gew 98在1898年到1935年间为德国军队的制式步枪，直到它在1935年被毛瑟Kar98k步枪取代为止。 12345678910111213重量 4.09千克（9.0磅） Gewehr 98（空枪） 3.50千克（7.7磅） Karabiner 98a长度 1,250 mm（49.2英寸） Gewehr 98 1,090 mm（42.9英寸） Karabiner 98a枪管长度 740 mm（29.1英寸） Gewehr 98 590 mm（23.2英寸） Karabiner 98a子弹 7.92×57mm毛瑟枪机 旋转后拉式枪机枪口初速 878 m/s（2,881 ft/s）有效射程 500米（550 yd） （机械瞄具） ≥800米（870 yd）（瞄准镜）供弹方式 5发内置弹仓（能够以弹夹条压入）瞄具 机械瞄具 蒙德拉贡步枪 蒙德拉贡步枪（西班牙语：Fusil Mondragón）是一种由墨西哥上将曼努埃尔·蒙德拉贡(Manuel Mondragón)设计，瑞士工业公司（SIG）生产的半自动步枪。 123456789101112重量 4.18 公斤长度 1105 毫米枪管长度 577 毫米子弹 7 × 57 毫米毛瑟弹/7.92 × 57 毫米毛瑟弹枪机 气动式 转拴式枪机枪口初速 760 米/秒有效射程 800 米最大射程 2,000 米供弹方式 8、10、20、30 发可拆式弹匣 100 发弹鼓瞄具 机械瞄具 毛瑟13.2毫米反坦克步枪 毛瑟13.2毫米反坦克步枪为德意志帝国陆军于第一次世界大战中针对协约国（主要是英国）的装甲车辆所研发生产的反装甲武器，初次登场时间是1918年2月。 12345678重量 15.8公斤长度 1.68米枪管长度 0.98米子弹 13.2mm TuF枪机 旋转后拉式枪机枪口初速 805米/秒供弹方式 单发装填瞄具 传统铁制照门 装甲车 埃尔哈特E-V/4装甲车 埃尔哈特E-V/4装甲车是德国二战前研发用于轻度战斗和警务的装甲车。 12345678910111213重量 7.12 - 7.75 吨长度 5.3 m宽度 2 m高度 2.85 m操作人数 8 - 9人装甲 约9 mm主武器 三挺机枪发动机 汽油80 hp (59 kw)功率/重量 10.3 hp/tonne悬挂 四轮驱动作战范围 250 km速度 61.3 km/h 坦克Tank A7V坦克 A7V（Sturmpanzerwagen A7V）是德意志帝国在第一次世界大战时开发的坦克。 1234567891011121314重量 30 至33 吨长度 7.34 米（24 尺 1 寸）宽度 3.1 米（10 尺）高度 3.3 米（10 尺 10 寸）操作人数 18人装甲 侧面20 毫米，正面50 毫米主武器 57 毫米主炮副武器 6挺7.92毫米机枪发动机 2具戴姆勒4汽缸汽油引擎100匹／800-900转（149 千瓦）x2功率/重量 6.5 匹／吨悬挂 履带、立式弹簧作战范围 30-80 公里（20-50 英里）速度 9 公里／小时 LK I Leichter Kampfwagen (中文：轻型战斗车辆) 或“LK I”是第一次世界大战期间德国制造的原型轻型坦克。 123456789101112重量 6.9 吨长度 5.1 米宽度 1.9 米高度 2.5 米操作人数 3 人装甲 8-14 毫米主武器 7.92 毫米 机枪发动机 戴姆勒-奔驰4缸发动机60 匹/44.7 千瓦悬挂 非悬挂作战范围 70 千米速度 14-18 千米/小时 飞机aircraft AEG B.I侦察机 AEG B.I侦察机是德国的双座双翼侦察机，于1914年小批量生产。它为AEG公司更成功的后继机型——B型和C型的设计提供了基础。 J.I攻击机 J.I攻击机（制造厂商将其定为“J 4”，以防止与1915年开发的“J 1”机混淆）是德意志帝国陆军航空队于第一次世界大战所使用的一款地面攻击机、侦察机和连络机，由容克斯所研制，属德国“J系列”装甲航空机之一。 信天翁C侦察机 信天翁C侦察机是由信天翁飞机公司研制的双翼侦察机，在第一次世界大战期间不单作为侦察机，还以其机载机枪件为战斗机和对地攻击机，信天翁飞机公司以此为基础推出信天翁D战斗机。 信天翁D战斗机 信天翁D战斗机是由信天翁飞机公司以信天翁C侦察机的基础和参考了法国纽波特11战斗机而研制的双翼战斗机，在第一次世界大战期间是继福克E单翼战斗机后德国空军的主力战斗机。 戈塔G轰炸机 戈塔G轰炸机是德国在第一次世界大战时的重型轰炸机，在大战期间主要用于轰炸英国，把死亡和恐惧带给英国民众。 巨人机 巨人机（德语：Riesenflugzeug，複數時寫作：Riesenflugzeuge），英语有时简称为R型飞机，是指一次世界大战中德意志帝国所使用的重型轰炸机。 柏法茨战斗机 柏法茨双翼战斗机是在第一次世界大战时由德国柏法茨飞机公司(德文:Pfalz Flugzeugwerke)研制的双翼战斗机。 汉诺威CL攻击机 汉诺威CL攻击机是在第一次世界大战时由德国汉诺威飞机公司(德文:Hannoversche Waggonfabrik)研制的双翼攻击机，CL原本是指比一般侦察机（代号为C）轻巧的双座机，原本是用作为侦察机提供直接的护航，但后来发展成为对地攻击机尤其以其后座机枪作为居高临下的机枪火力点。 福克战斗机 是福克飞机公司为了参加德国空军的“新型战斗机比赛”而提出的战斗机设计。 罗兰C-II侦察机 罗兰C-II侦察机是由LFG公司（Luft-Fahrzeug-Gesellschaft）研制的双翼侦察机，它被誉为第一次世界大战当中最漂亮的德国侦察机，它也因此被称为“鲸鱼”。 齐柏林-斯塔肯R-VI轰炸机 齐柏林-斯塔肯R-VI轰炸机是德国在第一次世界大战时的重型轰炸机，在大战期间主要和戈塔G轰炸机一起轰炸英国，把死亡和恐惧带给英国民众。 鸽式单翼机 鸽式单翼机是由奥地利(当时的“奥匈帝国)飞机工程师埃高．艾垂奇发明的，在第一次世界大战期间除了奥匈帝国，其同盟国盟友德意志帝国也大量采用作为侦察机、轰炸机和教练机等多种用途，虽然在1914年此机已算落伍，但毫无疑问的此后德国所有震惊世界的优秀军用飞机都是从鸽式单翼机开始的。 巡洋舰一次世界大战德国巡洋舰： https://zh.wikipedia.org/wiki/Category:%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%B8%96%E7%95%8C%E5%A4%A7%E6%88%B0%E5%BE%B7%E5%9C%8B%E5%B7%A1%E6%B4%8B%E8%89%A6 巡洋舰（英语：Cruiser）指在排水量、火力、装甲防护等方面仅次于战列舰的大型水面舰艇，拥有同时对付多个作战目标的能力，以及能胜任多种任务的多样性。历史上，巡洋舰由于吨位大、火力强、性能佳，一开始是指可以独立行动的战舰 ; 而与此相对的驱逐舰则需要其它船只（比如补给船只）的协助，才能执行任务。不过随着现今驱逐舰被大型化后的综合作战能力的提升，何潬吨位其实超过早年的巡洋舰，所以这个区分已经不明显了，很多新式的大型军舰都不再冠以巡洋舰之名了。 巡洋舰的用途顾名思义确实是用来巡逻的。 战列舰一次大战德国战列舰: https://zh.wikipedia.org/wiki/Category:%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%B8%96%E7%95%8C%E5%A4%A7%E6%88%98%E5%BE%B7%E5%9B%BD%E6%88%98%E5%88%97%E8%88%B0 战列舰（英语：Battleship），是装有厚重装甲和大口径主炮的大型军舰，是人类创造的最庞大和复杂的武器系统之一，大舰巨炮主义时代的极致产物。 法国手枪 FN M1900手枪(勃朗宁) FN M1900是一款由著名枪械设计师约翰·勃朗宁于1896年设计，交由比利时Fabrique Nationale生产的单动式半自动手枪。该枪亦是史上第一款使用套筒设计的手枪。 1234567重量 625克（空枪）长度 172亳米枪管长度 102亳米子弹 .32 ACP（7.65×17亳米）枪机 反冲作用，单动供弹方式 7 + 1发弹匣瞄具 固定式瞄具 M1892转轮手枪 M1892转轮手枪（或称：勒贝尔转轮手枪或圣埃蒂安8毫米）是法国采用的一种制式手枪。 12345678重量 0.85公斤（空枪）长度 24厘米子弹 8毫米法国军械弹口径 8毫米枪机 双动式枪口初速 220米/秒供弹方式 6发弹巢瞄具 机械瞄具 M1911手枪 M1911（45手枪）是一种在1911年起生产的.45 ACP口径半自动手枪，由约翰·勃朗宁设计。 123456789101112重量 空枪连弹匣：2.437磅（1,105克）[1]长度 8.25吋（210毫米）枪管长度政府型：5.03吋（127毫米）指挥官型：4.25吋（108毫米）军官ACP型：3.5吋（89毫米）子弹 .45 ACP枪机 枪管短行程后座作用、单动式板机枪口初速 251.46米/秒、〔825英尺/秒〕有效射程 50米供弹方式 7发（标准弹匣），膛室1发瞄具 机械瞄具：金属缺口式照门及准星 MAS 1873转轮手枪 MAS 1873（或称：Chamelot-Delvigne）是法国军队采用的第一种双动式转轮手枪，此枪不久便被更新的M1892转轮手枪所取代。 12345678910重量 1.04 kg长度 240 mm枪管长度 115 mm子弹 11毫米M1873口径 11 mm枪机 双动式射速 20 - 30发/分钟最大射程 50米供弹方式 6发弹巢瞄具 V型缺口及准星 冲锋枪 机枪 圣艾蒂安M1907中型机枪 圣艾蒂安M1907（法语：St. Étienne Mle 1907）是法国军队于第一次世界大战及第二次世界大战期间所装备的一种中型机枪。 1234567891011重量 26公斤长度 1,180毫米枪管长度 710毫米子弹 8×50毫米勒贝尔弹枪管 1根枪机 气动式射速 可调整：8 - 650发/分钟枪口初速 724米/秒供弹方式 25、30发金属弹链300发布制弹链（1916年）瞄具 机械瞄具 绍沙轻机枪 绍沙轻机枪，是在一战（1914年–1918年）时法国军队装备的制式轻机枪。官方名”Fusil Mitrailleur Modele 1915 CSRG”（机关步枪1915年型CSRG）。 12345678910111213重量 9.07千克（20.0英磅）长度 1,143毫米（45.0英寸）枪管长度 470毫米（19英寸）子弹 8×50毫米勒贝尔弹其他枪机 长行程后座作用、气动式、开放式枪机发射模式 半自动、全自动射速 约240发/分钟枪口初速 630米/秒有效射程 200米最大射程 2,000米供弹方式 20发弹匣瞄具 机械瞄具 刘易斯机枪 刘易斯机枪（Lewis Gun）由美国陆军上校艾萨克·牛顿·刘易斯发明，但美国陆军并未采用，而是在英国发扬光大。 12345678910111213重量 12公斤（空枪）长度 1,125 mm枪管长度 660 mm子弹 .303英式弹口径 7.7 mm枪机 气动式、开放式枪机发射模式 半自动、全自动射速 500 - 600发/分钟枪口初速 747米/秒有效射程 800 m最大射程 3,200 m供弹方式 47发、97发弹鼓瞄具 刀片式瞄具 霍奇克斯M1914重机枪 霍奇克斯M1914重机枪（法语：Hotchkiss Mle 1914）由美国人班杰明·霍奇克斯所开设的霍奇克斯公司研发。 123456789101112131415重量 24.4公斤46.8公斤（连三脚架）长度 1,390毫米枪管长度 800毫米子弹 8×50毫米勒贝尔子弹7×57毫米毛瑟子弹6.5×50毫米有坂子弹11毫米Gras子弹6.5×55毫米枪机 导气式射速 450发/分钟枪口初速 724米/秒供弹方式 24发保弹板250发铰接式弹链瞄具 机械瞄具 步枪 M1917RSC半自动步枪 M1917式RSC半自动步枪（法语：Fusil Automatique Modèle 1917，别名RSC M1917）是一种半自动气动式军用步枪，于第一次世界大战末期（1918年）装备法国军队。 123456789重量 5,25公斤（11,6磅）长度 1331毫米（52,4英寸）枪管长度 798毫米（31,4英寸）子弹 8×50mm勒贝尔弹枪机 长行程导气式活塞，滚转式枪机枪口初速 701米/秒有效射程 标尺最低射程250米，最大有效1200米供弹方式 5发内装漏夹供弹瞄具 铁质标尺，标尺直立射程2400米 Mle 1918 全自动卡宾枪 Mle 1918 利贝罗勒全自动卡宾枪（英语：Ribeyrolles 1918 automatic carbine ，法语：Carabine Mitrailleuse 1918）是法国的一款自动步枪，亦是世界首型应用突击步枪概念的枪械。 1234567891011重量 5.1公斤（空枪）长度 1090毫米枪管长度 450毫米子弹 8 × 35 毫米利贝罗勒弹口径 8 毫米枪机 直接反冲射速 550~600发/分钟枪口初速 570 米/秒有效射程 400 米供弹方式 25 发弹匣瞄具 机械瞄具 勒贝尔M1886步枪 勒贝尔M1886（法语：Fusil Lebel Modèle 1886）或勒贝尔步枪（法语：Fusil Lebel）是法国于1886年推出的栓式步枪，由尼古拉斯·勒贝尔上校研制。 123456789101112重量 4.41 kg（上弹）4.18 kg（空枪）长度 130 cm枪管长度 80 cm子弹 8×50毫米勒贝尔弹口径 8 mm枪机 旋转后拉式枪机枪口初速 610 - 700米/秒有效射程 400米最大射程 1,800米供弹方式 8发管状弹仓（若算上托弹板上和膛室内的额外两发子弹为10发）瞄具 机械瞄具 温彻斯特1907型半自动步枪 温彻斯特1907型是由美国枪械设计师托马斯·克罗斯利.约翰逊设计的一种半自动步枪，它在1906年到1958年期间由温彻斯特连发武器公司生产。 12345678重量 3.6 kg - 4.1 kg长度 1,000 mm枪管长度 510 mm子弹 .351 Winchester Self-Loading口径 .351枪机 后座作用供弹方式 5 发、10 发弹匣瞄具 机械瞄具 双管霰弹枪 双管霰弹枪（英语：Double-barreled shotgun，或称双管猎枪），是一种有两根枪管的猎枪，可分为水平排列或上下排列，可算是最早期的猎枪之一，前身为镇暴枪。 炮 皮托SA-18坦克炮 皮托SA-18坦克炮是法国在一战期间由设计的一种战车炮，主要装备于雷诺FT-17坦克上。 坦克 2C超级重战车 2C超重型坦克，又名Char 2C，是法国于一战时设计的超重型坦克。但是，它并没有参加一战。不过，这辆坦克是所有被正式量产的坦克中吨位第二大的，仅次于猎虎式驱逐战车。 123456789101112重量 69 t（68 long ton；76 short ton）长度 10.27米（33英尺8英寸）宽度 3米（9英尺10英寸）高度 4.09米（13英尺5英寸）操作人数 11人[注 1]装甲 45 mm（1.8英寸） max.主武器 75 mm 火炮副武器 4挺8 mm 机枪 (有一门在后炮塔上)发动机 双引擎 2 x 250 马力作战范围 150 km（93 mi）速度 15 km/h（9.3 mph） 施耐德CA1坦克 施耐德CA1坦克（法语：Char Schneider CA1）是法国研制的第一种坦克，研发的主要目的是破坏战场上的铁丝网。 123456789101112重量 13.6 吨长度 6.32 米宽度 2.05 米高度 2.30 米操作人数 6人装甲 5.5-11毫米钢板主武器 施耐德75mm迫击炮副武器 2门8mm霍奇基斯M1914机枪发动机 施耐德4缸55hp汽油引擎悬挂 弹簧作战范围 45 公里速度 8.1 公里／小时 雷诺FT-17坦克 雷诺FT-17，是一款法国轻型坦克。它于一战时由法国研发，是世界上第一款安装旋转炮塔的坦克。截至一战结束时，一共生产了3187辆。甚至在二战爆发时，还有1800辆FT-17坦克在法国军队中服役。 123456789101112131415重量 7吨长度 5米宽度 1.74米高度 2.14米操作人数 2（车长及驾驶员）装甲 6-22毫米主武器 皮托SA-18 37mmL/21战车炮或8mm哈奇开斯M1914机枪发动机 雷诺直立式4缸水冷汽油机35匹功率/重量 6马力/吨变速 机械式（4前进档，1倒车档）悬挂 垂直弹簧作战范围 35公里速度 7.7公里/时 飞机 纽波特战斗机 纽波特11战斗机是法国在第一次世界大战早期推出的双翼战斗机，因其机体细小而被称为“婴儿”，它是由纽波特飞机公司研制的，成立于1902年的纽波特飞机公司由1909年开始造飞机，该公司由纽波特兄弟创立但两兄弟后来都在飞行事故当中死去，公司由他人接手，而在推出纽波特11战斗机后该公司才在航空界打响名堂并开创了“纽波特皇朝”。 莫兰-索尼耶L单翼机** 莫兰-索尼耶L单翼机是法国莫兰-索尼耶飞机公司在1913年研制的单翼多用途飞机，该型机在当年12月的就在巴黎的航空展览上公开，在第一次世界大战爆发后就成为法国空军的侦察机，也是第一种在螺旋桨上加上钢铁制子弹偏导片而实现机枪安装在机头并开火，估计这样有大约1/4的子弹会被它挡住不伤到螺旋桨，其余3/4可穿过螺旋桨射击目标，此种做法是在同步射击系统出现前唯一的可行办法。莫兰-索尼耶L单翼机也因此被称为“历史上第一种战斗机”。 俄国 M1911手枪 毛瑟C96手枪 纳甘M1895转轮手枪 纳甘M1895（俄语：Револьвер системы Нагана，意为：纳甘系统转轮手枪）是由比利时工业家莱昂·纳甘为俄罗斯帝国所研发的7发双动式转轮手枪，发射7.62×38mmR弹药。 1234567891011重量 0.8 kg（空枪）长度 235 mm枪管长度 114 mm子弹 7.62×38mmR口径 7.62 mm枪机 单动式、双动式射速 14 - 21发/分钟枪口初速 272米/秒有效射程 22米供弹方式 7发转轮式弹巢瞄具 V型照门及准星 三八式步枪 三八式步枪（日语：三八式歩兵銃；さんぱちしきほへいじゅう，Sanpachi-shiki hohei-juu）为手动步枪，日本陆军于日俄战争同年（1905年，明治38年）正式采用为制式武器，一直到第二次世界大战。三八式步枪在中国一向俗称为三八大盖，由于其枪机上有一个随枪机连动的防尘盖以及机匣上刻有“三八式”字样而得名。 12345678910重量 3,730g（加上刺刀重4,100g）长度 127.6cm（上刺刀可达166.3cm）枪管长度 797毫米子弹 6.5×50mm有阪（Arisaka）口径 6.5毫米枪机 旋转后拉式枪机枪口初速 765米／秒有效射程 460米供弹方式 5发弹匣，内置弹仓瞄具 铁制直立式表尺 温彻斯特步枪 温彻斯特步枪（Winchester Rifle），有时亦称温彻斯特连发步枪（Winchester Repeating Rifle），是由美国温彻斯特连发武器公司研制及生产的一系列步枪。 123456789101112重量 4.3 kg长度 125.2 cm枪管长度 76.2 cm子弹 .44-40温彻斯特.38-40温彻斯特.32-20温彻斯特.30-30温彻斯特.22 LR其他枪机 杠杆式供弹方式 8（M1894）、10（M1866）、13（M1866）、15发内置管状弹仓瞄具 后方缺口及前准星 莫辛-纳甘步枪 莫辛-纳甘（法文：Mosin-Nagant）步枪是由设计者俄国陆军上校谢尔盖·伊凡诺维奇·莫辛和比利时枪械设计师李昂·纳甘共同命名的手动步枪，在俄语圈国家也被普遍的称为莫辛步枪 （俄文：Винтовка Мосина），官方名称为”三线M1891步枪”。 1234567891011121314重量 4.22公斤（空枪），各型号不同长度 1306毫米，各型号不同枪管长度 800毫米，各型号不同子弹 7.62×54毫米R枪弹口径 7.62毫米枪机 旋转后拉式枪机枪口初速 615米/秒（M1891）860米/秒（M1891/30）有效射程 548.64米（600码）最大射程 1828.8米（2000码）供弹方式 5发内置弹仓10发可拆式弹匣（现代化改版限定）瞄具 机械瞄具：后方可调式缺口表尺及前方柱状准星PU 3.5倍光学瞄准镜 费德洛夫M1916自动步枪 费德洛夫M1916 （俄语：Автомат Фёдорова）是一种战斗步枪，由弗拉基米尔·格里高利耶维奇·费德洛夫（Vladimir Grigoryevich Fyodorov）设计，1916年在沙俄境内生产。 1234567891011重量 4.4公斤 (全重：5.2公斤)长度 1,045毫米枪管长度 520 毫米子弹 6.5×50毫米有坂子弹口径 6.5毫米枪机 枪管短行程后座作用发射模式 半自动、全自动射速 600发/分钟[1]枪口初速 654米每秒（2,150英尺每秒）[1]供弹方式 25发可拆卸式弹匣瞄具 机械瞄具 绍沙轻机枪 麦德森轻机枪 刘易斯机枪 维克斯机枪 维克斯机枪（Vickers），是第一次世界大战与第二次世界大战期间英国军队所使用的中型机枪。基于维克斯机枪优异的设计，使它成为世界上著名的战争武器之一。 12345678910111213重量 15 kg长度 1,100 mm枪管长度 720 mm操作人数 3人子弹 .303英式弹口径 7.7毫米枪机 后坐式，水冷却射速 450 - 500发/分钟枪口初速 744米/秒有效射程 2,000米最大射程 4,100米供弹方式 250发布制弹链瞄具 机械瞄具 马克沁M1910重机枪 马克沁M1910重机枪（Пулемёт Максима на станке Соколова）又名PM M1910马克沁，是海勒姆·马克沁开发的马克沁机枪之衍生型，发射7.62×54毫米R弹药，配有轮式射架。 123456789重量 64.3公斤（139.6磅）长度 1067毫米枪管长度 721毫米子弹 7.62×54毫米R口径 7.62毫米枪机 后座作用射速 600发/分枪口初速 740米/秒（2,427.2尺/秒）供弹方式 250发布制弹链 英国 M1911手槍 毛瑟C96手槍 M1917左轮手枪 M1917左轮手枪（M1917 Revolver），官方正式名称为M1917 .45英寸美国左轮手枪（英语：United States Revolver, Caliber .45, M1917）是一把美国六发式左轮手枪，主要发射.45 ACP口径手枪子弹。 史密斯威森军警型左轮手枪 史密斯威森军警型（Smith &amp; Wesson Military &amp; Police，缩写：S&amp;W MP；简称：点三八），是一种.38口径的美国制左轮手枪。 韦伯利转轮手枪 韦伯利转轮手枪（英语：Webley Revolver）是由英国生产的一系列军用和警用转轮手枪。当中最著名的版本为韦伯利MK VI， 它在一次大战期间成为了英国军队以及其殖民地军队的制式手枪。 123456789101112重量 1.1公斤（空枪）长度 286毫米枪管长度 106毫米子弹 .455韦伯利.38/200口径 .455英寸（11.6×19毫米）、.38英寸枪机 单/双动式板机射速 20-30发/分钟枪口初速 190米/秒有效射程 50码供弹方式 6发弹巢瞄具 缺口式机械瞄具 三八步枪 温彻斯特步枪 恩菲尔德M1917步枪 恩菲尔德M1917步枪（M1917 Enfield，又名P17、P1917或Pattern 1917）是“美国恩菲尔德”（American Enfield）于1917至1918年间生产的.30-06口径手动步枪。 1234567重量 4.17 公斤（9磅3安士）长度 1175 毫米（3尺10.25寸）枪管长度 26 寸（660毫米）子弹 .30-06（7.62 x 63毫米）枪机 旋转后拉式枪机枪口初速 823 米/秒（2700尺/秒）供弹方式 5发弹夹、6发内置弹仓 李-恩菲尔德步枪 李-恩菲尔德步枪（Lee-Enfield）也译李恩飞步枪是1895年至1956年英军的制式手动步枪。 1234567891011121314重量 4.19公斤（MLE Mk.I）3.96公斤（SMLE No.1 Mk.III）长度 1257毫米（MLE Mk.I） 1138毫米（SMLE No.1 Mk.III） 1130毫米（No.4 Mk.I）枪管长度 767毫米（MLE Mk.I） 640毫米（SMLE No.1 Mk.III）子弹 .303 British（7.7×56mm R） 7.92×57毫米尖头弹(为适应中国战场所改膛的)枪机 旋转后拉式枪机枪口初速 744米／秒有效射程 914米（1000码）最大射程 1828米（2000码）供弹方式 10发内置弹仓（两个5发弹夹） 马提尼-亨利步枪 马提尼-亨利”（Martini-Henry）是一种英国陆军曾经装备的起落式枪机步枪。它于1871年首度投入服役，最终取代了原有的史奈德步枪，一款改良至发射定装弹的前装枪。马提尼-亨利的衍生型在大英帝国中一共服役了三十年。它采用了由亨利·O·皮博迪为其皮博迪步枪设计的起落式枪机，并由瑞士设计师里德里希·冯·马提尼进行改良，结合由苏格兰人亚历山大·亨利设计的多边形膛线。 123456789101112131415重量 3.827 kg（空枪）长度 1245 mm子弹 .577/450 Boxer-Henry .577/450马提尼-亨利 .303英式弹 11.43×55R（奥斯曼帝国） 11.43×59R（罗马尼亚） 7.65×53毫米（奥斯曼帝国）枪机 起落式枪机（Martini Falling Block）射速 12发/分钟枪口初速 400米/秒有效射程 370米最大射程 1,700米供弹方式 1发装在膛室内瞄具 可滑动式表尺及准星 维克斯机枪 刘易斯机枪 马克沁机枪 双管霰弹枪 勃朗宁M1917重机枪 M1917重机枪是由约翰·勃朗宁设计，美军在一战，二战及韩战中采用的重机枪，并有限延伸至越战，同时它也被其他国家使用。这是一种班组操作，弹链供弹的水冷重机枪，与同时期的M1919风冷中型机枪共同服役。该型机枪以营为单位配发同时也经常装备于各种载具之上。 123456789101112重量 47公斤长度 980毫米枪管长度 609毫米子弹 .30-06春田口径 7.62毫米枪机 短行程后座作用式射速 450发/分钟 600发/分钟（M1917A1）枪口初速 853.6米/秒最大射程 900米供弹方式 250发布制弹链瞄具 机械瞄具 Template:V及W級驱逐舰 步行者号驱逐舰 步行者号驱逐舰（舷号D27）是一艘英国皇家海军建造的驱逐舰，为W级驱逐舰的3号舰。她是英军第一艘以步行者（Walker）为名的军舰。 12345678标准排水量 设计：1,100吨全长 整体：300呎全宽 水线：26.75呎吃水 9呎最高速度 34节武器装备 4门4吋Mk V速射炮 2门单装2磅砰砰炮 2座3联装鱼雷发射管 范诺克号驱逐舰 范诺克号驱逐舰（舷号H33）是一艘英国皇家海军建造的驱逐舰，为V级驱逐舰的1号舰。她是英军第一艘以范诺克（Vanoc）为名的军舰，舰名取自圆桌骑士团的范诺克骑士。 12345678标准排水量 设计：1,272吨至1,339吨全长 整体：300呎全宽 水线：26呎9吋吃水 9呎最高速度 34节武器装备 4门4吋Mk V速射炮 2门单装2磅砰砰炮 2座双联装鱼雷发射管 Mark I 坦克 Mark I 坦克由英国研制并在第一次世界大战于英国军队服役，是世界上第一种正式参与战争的坦克。[1] Mark I 坦克在1916年8月开始服役，并于1916年9月15日首次应用在索姆河战役上。它的主要作用是破坏战场上的铁丝网、越过战壕、亦能抵御小型武器的射击。 123456789101112131415161718重量 雄性：28.4公吨（28.0长吨）雌性：27.4公吨（27.0长吨）长度 9.94米（32英尺7英寸）宽度 4.33米（14英尺2英寸）高度 2.44米（8英尺0英寸）操作人数 8人装甲 6-12 毫米主武器 雄性：2 × 霍奇基斯QF 6磅炮 雌性：4 × 维克斯机枪副武器 雄性：3 × 霍奇基斯轻机枪 雌性：1 × 霍奇基斯轻机枪发动机 戴姆勒-奈特6缸 13升 汽油引擎 105匹马力（78千瓦特）功率/重量 雄性：3.7匹马力每公吨（2.8千瓦每公吨） 雌性：4.0匹马力每公吨（3.0千瓦每公吨）悬挂 履带作战范围 23.6英里（38.0千米），巡航6.2小时速度 5.9千米每小时（3.7英里每小时） 美国 Mk 2手榴弹 Mk 2手榴弹（或写作Mk II）是一种反人员破片手榴弹，美军于1918年导入，用以取代Mk 1手榴弹，在二战、韩战至越战中所使用。由于外型相似凤梨又名凤梨手榴弹，因保险片的形状被称为“鸭嘴手榴弹”，因外观被称为“卵形手榴弹”、“凤梨手榴弹”或“癞瓜手榴弹”。 12345重量 595克长度 111毫米填充 TNT填充量 2安士引爆机制 4-5秒 M1911手枪 M1917左轮手枪 史密斯威森军警型左轮手枪 恩菲尔德M1917步枪 李-恩菲尔德步枪 温彻斯特步枪 温彻斯特1907型半自动步枪 莫辛-纳甘步枪 M1903春田步枪 M1903春田步枪是一种旋转后拉式枪机弹仓式手动步枪，1903年定型称为“0.30口径M1903式步枪”，因其由春田（Springfield）兵工厂研制而得名M1903春田步枪（Springfield rifle）。 1234567891011重量 3.95公斤长度 1,098毫米（44.9寸）枪管长度 610毫米（24寸）子弹 .30-03 .30-06（7.62×63毫米） 7.92×57毫米尖头弹(为适应中国与欧洲战场所改膛的)枪机 旋转后拉式枪机枪口初速 823 - 853米／秒有效射程 550米供弹方式 5发弹夹，内置弹仓瞄具 片状准星；带&quot;U&quot;形缺口折叠式框形表尺 温彻斯特M1897泵动式霰弹枪 温彻斯特M1897（英语：Winchester Model (M) 1897，俗称：Model 97或M97）是一枝由著名的美国枪械设计师约翰·勃朗宁设计、美国温彻斯特连发武器公司生产的泵动式及外置击锤型设计霰弹枪。 温彻斯特M1912泵动式霰弹枪 温彻斯特M1912（英语：Winchester Model（M） 1912，俗称：Model 12或M12）是一枝由美国温彻斯特连发武器公司生产的泵动式、内置式击锤设计及外部管式弹仓供弹的霰弹枪。此枪在推出后不久被流行地命名为完美的连发枪（英语：Perfect Repeater），基本奠定了此枪对泵动霰弹枪超过51年的高效率生产的生涯的标准。 勃朗宁Auto-5半自动霰彈槍 勃朗宁Auto-5（英语：Browning Automatic 5，简称：Auto-5、A-5，意为：勃朗宁自动五发式霰弹枪）是一枝由美国著名轻兵器设计家约翰·勃朗宁所研制、后座作用操作的半自动霰弹枪，可发射12铅径霰弹、16铅径霰弹或20铅径霰弹。 勃朗宁自动步枪 勃朗宁自动步枪（英语：Browning Automatic Rifle，简称：BAR），是美军在20世纪上半叶使用的一种自动步枪。 123456789101112131415重量 空枪重：7.2公斤（A1）空枪重：8.8公斤（A2）长度 1,214毫米（47.8寸）枪管长度 610毫米（24寸）子弹 .30-06 Springfield （7.62×63毫米） 7.92×57毫米尖头弹(为适应中国战场所改膛的)口径 7.62毫米（.30寸）枪机 长行程导气式活塞、开放式枪机发射模式 半自动、全自动射速 300-450发/分； 500-650发/分（A2）枪口初速 805米/秒有效射程 548米供弹方式 20发弹匣 刘易斯机枪 勃朗宁机枪 绍沙轻机枪 霍奇科斯重机枪 勃朗宁M1919中型机枪 勃朗宁M1919（M1919 Browning machine gun），俗称（Browning Machine Gun，30 Cal ），是由约翰·勃朗宁在一战后设计的机枪，主要是把水冷式M1917改为风冷式，采用.30-06 Springfield 步枪弹药。 12345678910111213重量 14公斤长度 964毫米（37.94英寸）操作人数 2至3名子弹 .30-06 Springfield（U.S.） 7.62×51mm NATO（U.S.） .303 British口径 7.62毫米/7.7毫米枪机 后坐作用射速 400–600发／分枪口初速 853米／秒有效射程 1,400米供弹方式 M9弹链供弹瞄具 可调机械照门 D级潜艇 D级潜艇是美国海军一战中建造的潜艇级，子合约由格罗昆的电船公司签订，由昆西的佛尔河船厂建造。 123456789101112131415舰型 Submarine排水量 288 long ton（293 t） surfaced 337 long ton（342 t） submerged全长 134英尺10英寸（41.10米）全宽 13英尺11英寸（4.24米）吃水 11英尺8英寸（3.56米）动力来源 2 x NELSECO gasoline engines, 600 hp（450 kW） total[1] 2 x electric motors, 260 hp（190 kW） total 2 x 60-cell batteries 2 shafts速度 12节（22千米每小时；14英里每小时） surfaced, 9.5节（17.6千米每小时；10.9英里每小时） submerged续航距离 1,240海里（2,300千米；1,430英里） (surfaced)潜航深度 200英尺（61米）乘员 15 officers and men武器装备 4 × 18 inch (457 mm) bow torpedo tubes, (4 torpedoes)[3] 美国一战驱逐舰 维基百科： https://zh.wikipedia.org/wiki/Category:%E7%BE%8E%E5%9B%BD%E4%B8%80%E6%88%98%E9%A9%B1%E9%80%90%E8%88%B0 驱逐舰（英语：destroyer）是一种多用途的军舰。驱逐舰的用途是保护舰队，驱逐和消灭鱼雷艇和潜艇等以鱼雷为主要武器的舰只，为舰队提供保护。 化学武器 三氯硝基甲烷 三氯硝基甲烷，俗称氯化苦（英语：Chloropicrin），是一种化学式为Cl3CNO2的有机氯化合物。这种高毒性的物质曾被用作代号为PS的化学武器；现在则主要用作熏蒸剂和杀线虫剂。 二氯甲基胂 二氯甲基胂，亦可简写为MD，是一种有机化合物，化学式为CH3AsCl2。它是一种无色、易挥发的液体，具有很强的毒性，是一种糜烂性毒剂，可作为化学武器使用。 氯丙酮 氯丙酮，结构式ClCH2COCH3。无色有极强刺激性臭味液体，对生物体有强刺激性，在日光下分解产生强催泪性气体。见光变为暗黄的琥珀色。 溴乙酸乙酯 溴乙酸乙酯是一种有机化合物，化学式为CH2BrCO2C2H5。它可由乙酸为原料合成。它是一种催泪剂，具有果味和刺激性气味。它是毒性很高的烷基化试剂。吸入、吞咽或与皮肤接触可能致命。 绿十字毒气 绿十字毒气（德语：Grünkreuz)是在第一次世界大战时使用的化学武器，属于窒息性毒剂，是由三氯硝基甲烷，光气或/和双光气的混合物。 芥子毒气 芥子毒气（英语：mustard gas），亦简称为芥子气，学名二氯二乙硫醚，是一种重要的糜烂性毒剂，因味道与芥末相似而得名。 二战第二次世界大战（又简称二次大战、二战、WWII等；英语：World War II；法语：Seconde Guerre mondiale；德语：Zweiter Weltkrieg；俄语：Вторая мировая война；日语：第二次世界大戰）是一次自1939年至1945年所爆发的全球军事冲突，整场战争涉及到全球绝大多数的国家，包括所有的大国，并最终分成两个彼此对立的军事同盟─同盟国和轴心国。这次战争是人类史上最大的战争，动员了1亿多名军人参与这次军事冲突。主要的参战国纷纷宣布进入总体战状态，几乎将自身国家的全部经济、工业和科学技术用于战争之上，同时将民用和军用的资源合并以便规划。包括有犹太人大屠杀、南京大屠杀、战争中日军对中国军民进行细菌战、以及最终美国对日本首次使用原子弹等事件，使第二次世界大战也是有纪录以来最多大规模民众死亡的军事冲突，全部将近有5,000万至7,000万人因而死亡，这让第二次世界大战成了人类历史上死伤人数最多的战争[2]。第二次世界大战改变了世界局势，英国、法国等欧洲殖民帝国衰落，美国和苏联取代了欧洲殖民帝国的地位成了新的超级大国并在战后形成了两极格局直到1991年。 二战装备比一战更加多样化，如坦克、飞机、潜艇、航空母舰… 德国此列表将列出所有纳粹德国在二次大战中使用过的武器（包括在占领地生产和缴获的武器，但从盟军缴获的武器除外）。 坦克德国第二次世界大战装甲战斗车辆: 1234567輕型坦克 一号坦克 二号坦克 35(t)坦克 38(t)坦克中型坦克 三号坦克 四号坦克 五号坦克豹式重型坦克 六号坦克 虎I 虎II突击炮 三号突击炮 四号突击炮 10.5厘米突击榴弹炮42 33B突击步兵炮 灰熊式 突击虎式驅逐戰車／坦克驱逐车 一号反坦克自走炮 黄鼠狼I式／II式／III式 追猎者式 四号驅逐戰車 犀牛式 猎豹式 猎虎式 象式自走炮 一号自走重步兵炮 二号自走重步兵炮 黄蜂式 野蜂式 蟋蟀式 装甲机动车 40型发射架 卡尔自走臼炮防空坦克 38(t)防空坦克 一号防空坦克 四号防空坦克 家具车式 旋风式 东风式 球状闪电 LT-35坦克 LT-35或LT vz. 35是捷克斯洛伐克制造的轻型坦克，在二战中被纳粹德国采用，德军称为Panzerkampfwagen 35(t)（Pz.Kpfw. 35(t)）或Panzer 35(t)。 123456789101112131415乘员 4人长度 4.9米宽度 2.16米高度 2.2米重量 11吨发动机 斯科达汽油T11功率 120匹 ( 89千瓦)功率重量比 10.9匹/吨悬挂系统 leaf spring bogie速度 34公里/小时最大行程 193公里装甲 25毫米主要武器 1 x Skoda 37毫米M1934炮辅助武器 2 x 7.92毫米MG34机枪 LT-38坦克 LT-38是捷克斯洛伐克斯柯达厂制造的LTvz-38轻型坦克，德军编号Sd.Kfz140 Pz.38(t)，由著名的斯科达（Skoda）兵工厂所制造，于1938年末起服役于捷军，1939年3月德国并吞捷克之后，鉴于此车设计优良，遂以Pz.38(t)的名号继续使用，一直到大战后期都还能看到此车的变种继续为德国在各地奋战。 1234567891011121314151617乘员 4人长度 4.61 米宽度 2.14 米高度 2.40 米重量 9.5吨发动机 汽油Praga EPA 6-cylinder功率 126匹 ( 95千瓦)功率重量比 13匹/吨悬挂系统 钢板弹簧速度 42公里/小时（公路） 15公里/小时（非公路）最大行程 160至250公里装甲 A-D型：8-30毫米E型：50毫米主要武器 1 x 37毫米 L/47.8炮辅助武器 2 x 7.92毫米ZB53机枪 一号坦克 一号坦克（德语：Panzerkampfwagen I，意为一号装甲战斗车辆）是德国于1930年代研制的一款轻型坦克，缩写为“PzKpfw I”，其官方军械署赋予的编号为SdKfz 101（“第101号特殊用途车辆”）。一号坦克自1932年开始设计，并于1934年开始大量生产，它原先仅作为德军建构新一代的装甲战斗与技术时所使用的训练车辆，但后来将其投入了西班牙内战、二战的波兰、法国、苏联、北非战场以及中国在抗日战争中使用。 1234567891011121314151617重量 5.4(A型)/5.8(B型)吨长度 4.02(A型)/4.42(B型)米宽度 2.06米高度 1.72米操作人数 2人；车长及驾驶员装甲 7至13毫米主武器 两门7.92毫米MG13机枪（A型和B型）发动机 克虏伯M 305 4汽缸气冷汽油引擎（A型） 梅巴赫NL 38 TR 6汽缸液冷汽油引擎（B型以后） 60PS（59匹，44千瓦） 100PS（98匹马力、73千瓦）功率/重量 11.1PS／吨悬挂 椭圆钢板弹簧作战范围 140千米（A型） 170千米（B型）速度 37千米／小时（A型） 40千米／小时（B型） 二号坦克 二号坦克（德语：Panzer II）是第二次世界大战纳粹德国的坦克，这型坦克是用来填补其他设计中坦克的空隙, 它在第二次世界大战中的波兰战役与法国战役扮演了一个很重要的角色。到1942年底前绝大多数二号坦克已经离开第一线单位，生产线到1943年终止，然而车体继续被改良回其他种类装甲车辆。 1234567891011121314151617乘员 3人(车长/炮手、装填手、驾驶)长度 4.8米宽度 2.2米高度 2.0米重量 7.2吨发动机 6-cyl汽油梅巴赫HL功率 140匹 (105千瓦)功率重量比 15匹/吨悬挂系统 钢板弹簧速度 40千米/小时最大行程 200千米装甲 5-14.5毫米主要武器 20毫米 KwK 30 L/55 Ausf.A-f 20毫米 KwK 38 L/55 Ausf.J-L辅助武器 7.92毫米MG34机枪 三号坦克 三号坦克（德语：Panzerkampfwagen III），是一款德军二战坦克。三号坦克拥有多种衍生及改进型，并由德军在二战中广泛使用，其改进和衍生型号一直服役到二战结束。 123456789101112131415161718192021重量 19.5 吨长度 5.38米 17ft 8in宽度 2.91米 9ft 7in高度 2.59米 8ft操作人数 5名装甲 30mm主武器 37mm KwK L/46.5（A、B、C、D、E型、部分F、G型） 50mm KwK L/42（部分F、G、J型，H型） 50mm KwK L/60（部分J型、L型） 75mm L/24（部分L型，M型，N型）副武器 3挺MG34（A-H型）2挺MG34（G型以后）发动机 迈巴赫HL108TR（A、B、C、D型） 迈巴赫HL120TR V形12缸（E型以后） 320匹（迈巴赫HL120TR） 变速 SRG 328-145型（E-G型） 迈巴赫SSG77（H型）悬挂 扭力杆悬挂[2]作战范围 200公里[6]速度 42公里/时[6] 四号坦克 四号坦克（德语：Panzerkampfwagen IV，或称IV号坦克）为纳粹德国在第二次世界大战中生产的一款中型坦克。它原本设计目的是支援步兵，并且与专门执行反坦克任务的三号坦克协同作战。在三号坦克的整体性能逐渐不敷二次大战中期装甲战斗需要时，四号坦克因所使用的技术较为成熟而比三号坦克有更大的改良空间，因此在不断改进的过程中，四号坦克逐渐成为装甲师装备的主力车种。四号坦克较大的改良空间亦使其较为容易改装，既有改造为突击炮、自行反坦克炮，也有改造为弹药运送车、架桥坦克等，成为用途最广泛的坦克。从投产至二战结束，德国共制造了逾8,800辆四号坦克或其改造型。四号坦克参加了几乎所有战役，而且表现出相当的可靠性，没有像豹式坦克初期型号有大量的技术问题，就数量、服役时间来看，这型坦克才是德国装甲兵的主力，因此被德军装甲兵昵称为“军马”。 1234567891011121314151617181920212223242526272829乘员 5人（车长、炮手、装填手、驾驶员及无线电操作员）长度 7.02米宽度 2.88米高度 2.68米重量 B型：16吨；C型：18.14吨 D型：20吨；F型：22.3吨 G型：23.6吨；H型：25吨发动机 梅巴赫A型：HL108TR 12缸汽油引擎 B型：HL120TR 12缸汽油引擎 C型：HL120TRM 12缸汽油引擎功率 A型：250hp；B型：300hp功率重量比 12匹/吨悬挂系统 弹簧悬挂（C型开始使用板簧悬挂系统）速度 A型：31公里/小时〔道路〕 B型：39公里/小时〔道路〕 42公里/小时（道路） 16公里/小时（越野）最大行程 200公里J型：320公里装甲 炮塔正面50毫米/10° 炮塔两侧30毫米/26° 炮塔后方30毫米/10° 炮塔顶10毫米 车体正面80毫米/11° 车体侧面30毫米（后期型号加5毫米裙甲） 车体后面20毫米主要武器 坦克炮-KwK40 75毫米43倍径炮（KwK-40 75mm）辅助武器 2×7.92毫米MG34 五号坦克 五号坦克 黑豹式（德语：Panzerkampfwagen V Panther）是第二次世界大战中纳粹德国所制造的中型坦克。制式编号为Sd.Kfz.171。其后，由于“五号坦克（V号坦克）”这个名称被废除，所以在后来以“黑豹式坦克（Pz.Kpfw. Panther）”作为制式名称。 1234567891011121314151617181920乘员 5人车长、炮手、驾驶、通讯员、装填手[3]长度 6.87米（车身） 8.66米（全长）宽度 3.27米高度 2.995米重量 44.8吨（战斗重量）发动机 梅巴赫230P30 水冷V型12汽缸汽油引擎功率 700匹功率重量比 15.625匹／吨悬挂系统 双扭力杆速度 55公里／小时（平地） 30公里／小时（越野）最大行程 250公里（平地）、100公里（越野）装甲 前方80毫米，倾斜装甲139.48毫米侧面及后方40毫米主要武器 7.5厘米Kwk42L/70炮（炮弹79发后期81发）辅助武器 7.92毫米MG34机枪 ×2 六号坦克 六号坦克（德语：Panzerkampfwagen VI）是纳粹德国在第二次世界大战期间所使用的重坦克。被称为六号坦克的坦克共有2款，分别是I型与II型，即为“虎I”与“虎II”。在当时被评为其中一系列世界上最强的坦克。一般称其为“虎式坦克”，或者以英文“Tiger Tank”来称呼。 虎I坦克 虎I坦克（德语：Panzerkampfwagen VI Ausf. E (Sd Kfz 181) Tiger），是第二次世界大战中德意志国防军及武装党卫队所使用的坦克，正式名称为六号坦克（VI号坦克）。一般称为虎式坦克，简称“虎式”或“Tiger”。从1942年下半年服役起至1945年纳粹德国投降为止，一直是活跃于第一线的重型坦克。 123456789101112131415161718192021乘员 5人车长、炮手、装填手、驾驶员、通讯员长度 8.45米（全长） 6.316米（车身）宽度 3.705米高度 3米重量 57吨（战斗重量）发动机 梅巴赫HL230 P45 水冷4冲程V型12汽缸汽油引擎[2]功率 700匹功率重量比 12.3匹／吨悬挂系统 扭力杆速度 40公里／小时（平地） 20-25公里／小时（越野）最大行程 100公里（平地）、60公里（越野）装甲 前方100毫米 侧面及后方80毫米 车顶25毫米主要武器 8.8厘米Kwk 36 L/56炮（炮弹92发）辅助武器 7.92毫米MG34机枪 ×2 虎II坦克 六号坦克B型 （德语：Panzerkampfwagen VI Ausf.B Tiger II，通称“虎王坦克”或“虎II坦克”），是一款纳粹德国在二战期间研发的重型坦克。虎王坦克是虎I坦克的继任者，它继承了虎I坦克的重装甲风格，还有着豹式坦克那样的倾斜装甲。虎王坦克重达70公吨，前装甲有100到180毫米厚，装配一门88毫米KwK 43 L/71式坦克炮。没有炮塔的猎虎式坦克歼击车与虎王坦克共用同一种底盘。 12345678910111213141516171819202122232425重量 68.5公吨（装备保时捷炮塔）69.8公吨（装备亨舍尔炮塔）长度 7.38米（车体） 10.286米（33英尺9英寸）（炮向前）宽度 3.755米高度 3.09米操作人数 五人（车长、炮手、装填手、通信兵、驾驶员）装甲 25～185毫米（1～7英寸）主武器 1门KwK43 88毫米坦克炮 保时捷型炮塔可携带80发炮弹 亨舍尔型炮塔可携带86发炮弹副武器 2挺7.92毫米MG 34 携带5850发弹药发动机 V-12 迈巴赫HL 230 P30汽油机 690匹功率/重量 8.97匹/公吨变速 迈巴赫OLVAR EG 40 12 16 B（8个前进档、4个倒车档）悬挂 扭力杆悬挂底盘高度 495至510毫米燃料容量 860升（190英制加仑）作战范围 于公路上行驶：170千米 越野时：120千米速度 公路上最大速度：41.5千米/时 能允许持续行进：38千米/时 越野时：15-20千米/时 !()[/images/Weapons/Tiger-II.png] 七号狮式坦克 七号狮式超重型坦克（Panzerkampfwagen VII Löwe）为二战纳粹德国研发的一款超重型坦克。制造数量 从未被制造出来。 八号坦克鼠式 八号坦克鼠式（Panzerkampfwagen VIII Maus），是德国在第二次世界大战设计并制造的超重型坦克。产量 2（原型车，其中只有一台完工）。 九/十号坦克 九号坦克（Panzerkampfwagen IX）及十号坦克（Panzerkampfwagen X），为纳粹德国在第二次世界大战晚期故意散布欺敌的虚构坦克开发计划。 陆地巡航者P. 1000老鼠 P. 1000 巨鼠重型巡航坦克（Landkreuzer P. 1000 Ratte）是纳粹德国计划开发的一种重量达1000吨的超重型坦克，由德国的克虏伯公司研制，但计划在1943年被放弃，没有一辆P-1000被生产出来。此超重型坦克非常巨大，高度有11米，炮台也有两个平常人的高度。制造数量 0（完全从未实际投产） 陆地巡航者P.1500怪物 P. 1500 怪物陆行舰（Landkreuzer P. 1500 Monster）外型和古斯塔夫超重型铁道炮相似，是纳粹德国计划开发的一种重量达1,500吨的超重型坦克。制造数量 0（完全从未实际投产） 潜艇submarine U-47潜艇 U-47号潜艇是一艘于第二次世界大战时于纳粹德国海军服役的VIIB型U-潜艇。它在1937年2月25日开始建造并于1938年10月29日在基尔的克虏伯造船厂下水。 1234567891011121314151617舰型 VIIB型排水量 761吨 865吨（潜入海底）全长 66.6米（219英尺）全宽 6.2米（20英尺）深度 220米（720英尺）动力来源 2 × 1400 马力的柴油机 2 × 375 PS （280 kW） 的电动马达速度 最大17.7节（海面） 最大7.6节（潜入海底）续航距离 6,500海里（12,000千米）乘员 44-48船员 47武器装备鱼雷发射管：前4后1，共5个533mm发射管 8.8厘米 SK C/35舰炮（虽同为88毫米口径但是与8.8 cm Flak 18/36/37高射炮不同），2厘米 MG C/30 机炮 U-2365 U-2365号潜艇为纳粹德国海军XXIII级潜艇（德语：Klasse XXIII、或称Typ XXIII）的一艘，属于近海小型攻击潜艇。U-2365号潜艇于1945年3月2日服役。由于服役时已临近战争尾声，该艇并未取得任何战果，最终于1945年5月8日中被凿沉在卡特加特海峡。 火炮第二次世界大战期间德国陆军所用火炮: 1234567891011121314151617181920212223242526272829坦克主炮 2厘米KwK 30炮 3.7厘米KwK 36炮 3.7厘米KwK 38炮(t) 5厘米KwK 38炮 5厘米KwK 39炮 7.5厘米KwK 37炮 7.5厘米KwK 40炮 7.5厘米KwK 42炮 8.8厘米 KwK 36炮 8.8厘米 KwK 43炮反坦克炮 sPzB 41反坦克炮 PaK 36反坦克炮 4.2厘米Pak 41反坦克炮 Pak 38反坦克炮 Pak 97/38反坦克炮 Pak 39反坦克炮 Pak 40反坦克炮 7.5厘米Pak 41反坦克炮 7.5厘米Pak 42反坦克炮 7.62厘米PaK 36反坦克炮(r) 8公分PAW 600反坦克炮 Pak 43反坦克炮 PaK 44反坦克炮步兵支援火炮 le.IG 1步兵支援火炮 IG 37步兵支援火炮 IG 42步兵支援火炮 sIG 33步兵支援火炮 GebH 34步兵支援火炮 GebG 36步兵支援火炮 GebH 40步兵支援火炮无后座力炮 7.5厘米LG 40无后座力炮 105毫米LG 40无后座力炮 LG 42无后座力炮重型迫击炮 10公分35年式喷烟者 10公分40年式喷烟者 leLdgW迫击炮 GrW 69迫击炮 schwerer Ladungswerfer迫击炮火箭炮 7.3厘米Föhn-Gerät 7.3厘米41年式Propagandawerfer 8厘米Raketen-Vielfachwerfer 15厘米Do-Gerät 15公分41年式喷烟者 21公分42年式喷烟者 28/32公分41年式喷烟者 30公分42年式喷烟者 30 cm Raketenwerfer 56 Wurfrahmen 40多管火箭炮中重型野战炮 FK 16 nA野战炮 FK 18野战炮 FK 38野战炮 FK 7M85野战炮 10 cm K 17野战炮 sK 18野战炮 leFH 16榴弹炮 leFH 18榴弹炮 leFH 18M榴弹炮 leFH 18/40榴弹炮 sK 18/40野战炮 sFH 13榴弹炮 SFH 18榴弹炮 K 16野战炮 K 18重炮 K 39重炮 SK C/28重炮 K 18重榴弹炮 Mrs 16重榴弹炮 Mrs 18重榴弹炮超重炮及攻城武器 K 38重炮 K 39重炮 H 39攻城榴弹炮 K(t)超重型攻城炮 Kanone L/46 K 3重型攻城炮 H L/12重型攻城榴弹炮 Haubitze M1攻城榴弹炮 Gamma Mörser攻城榴弹炮 卡尔臼炮 古斯塔夫超重型铁道炮列车炮15厘米K列车炮 17厘米K列车炮 20.3厘米K列车炮 21厘米K 12列车炮 24厘米Th K列车炮 24厘米ThBr K列车炮 28厘米kzBr K列车炮 28厘米lgBr K列车炮 28厘米sBr K列车炮 28厘米Br NK列车炮 K5列车炮 38厘米Siegfried K列车炮 古斯塔夫超重型铁道炮防空炮2厘米30/38年式高射炮 2厘米Gebirgsflak 38高射炮 3.7厘米18/36/37/43年式高射炮 5厘米41年式高射炮 8.8厘米18/36/37年式高射炮 8.8厘米41年式高射炮 10.5厘米38年式高射炮 12.8厘米40年式高射炮 Mrs 18重榴弹炮 Mrs 18重榴弹炮（21公分Mrs 18式）是纳粹德国于第二次世界大战中所使用的一种重型榴弹炮。 12345678910111213重量 16,700 公斤（36,817 磅）枪管长度 6.51米L/30（30倍径）炮弹 分离装填式弹药炮弹重量 113公斤（高爆弹）口径 211 毫米后膛 水平滑契式炮栓后坐力 液压机械复合式载具 box trail射击仰角 -6° to +70°回旋角度 16°（于轮上） 360°（于平台上）枪口初速 550 米/秒有效射程 14,500 米 3.7厘米KwK 36炮 3.7 cm KwK 36 L/45 (3.7 公分战车炮36 45倍径)是第二次世界大战时由德国所生产的3.7cm火炮，主要用做三号战车的主炮，亦见于其他德军装甲车辆上。 5厘米KwK 38炮 5 cm KwK 38 L/42(5公分战车炮 42倍径)是二战时德军所用的50毫米火炮，仅见于三号战车上使用。 5厘米KwK 39炮 5 cm KwK 39 L/60 (5公分战车炮 60倍径)是二战时德军所用的50毫米火炮，主要作为1941年以后，三号战车后续型号的主炮。 7.5厘米KwK 37炮 7.5 cm KwK 37 L/24(7.5公分战车炮24倍径)是一种二战时，德军所使用的75mm，类似榴弹炮的短管战车炮。主要用于四号战车的早期型号和三号突击炮的早期型号。 7.5厘米KwK 40炮 7.5 cm KwK 40是在二战时，德军所使用的战车炮。主要搭载于于四号战车（F2型以后）、三号突击炮以及四号突击炮上。 7.5厘米LG 40无后座力炮 7.5厘米LG 40无后座力炮是由德国军队在第二次世界大战期间使用的无后座力炮。 7.5厘米Pak 41反坦克炮 7.5 cm Pak 41是第二次世界大战后期进入服役，由德国制造的反坦克炮。 7.5厘米 Pak 39炮 7.5厘米Pak39(L/48)（德语：7.5 cm Panzerjägerkanone 39），是一款德国于第二次世界大战期间所使用的反坦克火炮。该火炮于1942年1月开始装备于四号驱逐战车和追猎者式驱逐战车等驱逐战车。 KwK36 88毫米战车炮 88 mm KwK 36 L/56 (德语：8.8 cm KampfwagenKanone 36 L/56) 是在第二次世界大战中德意志国防军所使用的88毫米坦克炮。由克鲁伯所研制，是虎I坦克的主武器。 KwK43 88毫米战车炮 8.8 cm KwK 43 L/71 (德语：KampfWagenKanone—坦克炮) 是在第二次世界大战中，克鲁伯公司所设计，德意志国防军所使用的一门坦克炮。它是虎II坦克的主武器，并且是在第二次世界大战中作为放在拥有可转动炮塔的战车上最具威力的一门炮。 装甲战斗车 飞机 船舰 武器 39型卵状手榴弹 39型卵状手榴弹（德语：Eihandgranate 39）是第二次世界大战期间德军所产的手榴弹。 柄式手榴弹 柄式手榴弹（德语：Stielhandgranate）为德国陆军自第一次世界大战中期至第二次世界大战末期所使用之手榴弹。 铁拳 铁拳（德语：Panzerfaust）又称作装甲拳或反坦克榴弹发射器，是第二次世界大战时由德国研发与制造的火药推进无后座力反装甲武器。 防空铁拳 防空铁拳(德文:Fliegerfaust)是第二次世界大战末期德国士兵使用的手提防空火箭弹，由于在二战末期，德军失去制空权(尤其在西线)，而研制出来的步兵手提防空火箭弹。 装甲投掷雷 装甲投掷雷（德语：Panzerwurfmine，也缩写为PWM）是一种由纳粹德国开发并在二战中生产使用的反坦克碰炸手榴弹。 坦克杀手 Panzerschreck（德语）是二战中，纳粹德国的Raketenpanzerbüchse（“反战车火箭步枪”，缩写为RPzB）的昵称，它是一种口径为88毫米，可重复使用的反战车火箭发射器。 LeGrW 36型50毫米迫击炮 LeGrW 36型50毫米迫击炮（德语：5cm leichter Granatenwerfer 36 ）是纳粹德国在第二次世界大战中使用的一种轻型迫击炮。 123456789101112重量 14 kg (31 lb)枪管长度 465 mm (18 in)操作人数 2炮弹 0.9 kg (2 lb) TNT 装药口径 50 mm (1.97 in)射击仰角 42°到 90°回旋角度 33°到 45°射速 15-25 发/每分钟枪口初速 75 m/s (246 ft/s)有效射程 50 m (54.7 yd) 最小 510 m (557.7 yd) 最大最大射程 520 m (568.7 yd) GrW 34型81毫米迫击炮 GrW 34型81毫米迫击炮（德语：8 cm Granatwerfer 34）是纳粹德国陆军在第二次世界大战使用的一种迫击炮，这种迫击炮的射速和射程都颇为优秀，在训练有素的士兵手中可以发挥出更大的威力。在单兵携带时，这种迫击炮可以分解为炮筒、底座和支架三个部分。 1234567891011重量 62 kg (136.6 lbs) 钢炮筒 57 kg (125.6 lbs) 合金炮筒枪管长度 1,143 mm (45 in)操作人数 8炮弹 3.5 kg (7.71 lbs)口径 81.4 mm (3.20 in)射击仰角 45°到90°回旋角度 10°到23°射速 15-25 发/每分钟枪口初速 174 m/s (571 ft/s)最大射程 2,400 m (2,624 yds) GrW 42型81毫米迫击炮 GrW 42型81毫米迫击炮（德语：kurzer 8 cm Granatwerfer 42 ）是纳粹德国在第二次世界大战中使用的一种前装式滑膛迫击炮。是GrW 34型81毫米迫击炮使用短炮筒后的轻量化版本，最初计划是供伞兵使用的。然而由于50毫米口径的LeGrW 36型50毫米迫击炮射程太近，此款迫击炮也常被用来替换前者。GrW 42发射的炮弹重量是前者的3.5倍，射程则为两倍，迫击炮的重量则不到前者两倍，同时还可分解为三个部分携带。 鲁格手枪 M1879帝国转轮手枪 毛瑟C96手枪 瓦尔特P38手枪 瓦尔特P38（德语：Walther P38）是由德国瓦尔特武器公司在1930年代为德意志国防军研制的一种9毫米口径半自动手枪，此枪在二战期间被广泛采用。尽管该枪的出现原先是为了取代成本昂贵的鲁格P08手枪，然而直到二战结束时也没有完全取代。 12345678910重量 800克长度 216毫米枪管长度 125毫米子弹 9毫米鲁格弹枪机 短行程后座单动/双动枪口初速 365米/秒有效射程 50米供弹方式 8发可拆式单排弹匣瞄具 凹形照门，刀片形准星 ViS wz. 35手枪 Pistolet ViS wz. 35是由波兰枪工Piotr Wilniewczyc研制的一款半自动手枪，于1935年成为波兰军队的制式手枪。ViS wz. 35一直都被认为是有史以来最好的手枪之一，更是一些枪械收藏家的珍藏之一。 12345678910重量 1.123 kg（上弹） 0.950 kg（空枪）长度 205 mm枪管长度 115 mm子弹 9毫米鲁格弹口径 9×19毫米枪机 枪管短行程后座作用、单动枪口初速 345米/秒供弹方式 8发弹匣瞄具 金属缺口式照门及准星 MP18冲锋枪 MP28冲锋枪 MP3008冲锋枪 MP 3008是纳粹德国在1945年二战末期制造的冲锋枪。主要目的是提供给在战争末期扩编的国民突击队使用。 12345678910重量 3.18公斤长度 760毫米枪管长度 196毫米子弹 9×19毫米口径 9毫米枪机 反冲作用，开放式枪机发射模式 全自动射速 450发/分锺枪口初速 365米/秒供弹方式 32发MP40可拆卸式弹匣 MP34冲锋枪 MP34（德语：Maschinenpistole 34，意为：34型冲锋枪）是一枝由奥地利斯泰尔兵工厂生产的冲锋枪，在1930年代至二战期间被奥地利警察以及随后的德国国防军和武装党卫队所采用。 MP35冲锋枪 MP35（德语：Maschinenpistole 35，意为：35型冲锋枪）是一枝由纳粹德国生产的冲锋枪，在二战以前和期间被德国国防军、武装党卫队和德国警察所采用。 MP40冲锋枪 MP40冲锋枪（Maschinenpistole 40），常被称为“施迈瑟冲锋枪”，是一种为方便大量生产而设计，与传统枪械制造观念不同的冲锋枪，亦是第二次世界大战期间德国军队使用最广泛、性能最优良的冲锋枪。 123456789101112重量 4公斤（8.82磅）长度 收起枪托：630毫米 展开枪托：833毫米枪管长度 251毫米子弹 9×19毫米鲁格弹枪机 提前击发底火式反冲作用及开放式枪机发射模式 全自动射速 500发／分钟枪口初速 约380米／秒有效射程 约100米供弹方式 32发弹匣瞄具 机械瞄具 MP41冲锋枪 MP41（德语：Maschinenpistole 41，意为：41型冲锋枪）是一款由纳粹德国枪械设计师胡戈·施迈瑟所研发、黑内尔公司生产的冲锋枪，外观而言是MP40冲锋枪改用MP28冲锋枪的木制枪托的修改型，发射9×19毫米鲁格手枪子弹。MP41是专门为出口和警察部门而生产。]]></content>
      <categories>
        <category>Weapon</category>
      </categories>
      <tags>
        <tag>武器</tag>
        <tag>战争</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[英语语法]]></title>
    <url>%2F2018%2F11%2F14%2F%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[参考: 《新概念英语语法手册》 名词概述名词是指人或事物的名称，也包括一些具有抽象概念的名词。 用法 充当动词的主语 12Our &apos;agent&apos; in Cairo sent a telex this morning.#今天早晨我们在开罗的代理人发来一封电传。 作动词的直接宾语 12Frank sent an urgent &apos;telex&apos; from Cairo this morning.#弗兰克今天早上从开罗发来一份加急电传。 作动词的间接宾语 12Frank sent his &apos;boss&apos; a telex.#弗兰克给他的老板发了一份电传。 作介词的宾语 12I read about it in &apos;the China Daily&apos;.#我在中国日报上看到了这个消息。 作be、seem等系动词的表语 12Jones is our &apos;guest&apos;.#琼斯是我们的客人 作同位语 12Laura, &apos;a BBC reporter&apos;, asked for an interview.#劳拉，BBC的记者，要求采访。 复合名词由两个或两个以上的名词部分组合而成的名词，称为复合名词。 复合名词通常有四种构成形式 123456789101112131. 名词+名词a keyboard(键盘)2. 形容词+名词a greenhouse(温室)3. 动名词+名词drinking water(饮用水)4. 名词+动名词sight-seeing(观光) 还有一些复合名词表示特定含义 1Oxford Road, Beijing Capital International Airport 分类 专有名词 专有名词指特定的人、地方、事物或概念，他们被认为是独一无二的。专有名词的开头字母要大写，前面一般不用冠词。 123456789101112131415#人名ParkerMr. Parker#称呼Mum#地名Asia#月份、星期、节日、季节AprilMondayChristmasspring(季节一般不大写) 普通名词 普通名词又可分为可数名词和不可数名词。在普通名词前通常要使用冠词a, an, the… 12345678910111213#可数名词a book, an envelophow many stamps do you have?#不可数名词water, milk, airhow much milk do you have?#既是可数又是不可数He ate much fish yesterday.There are a large variety of fishes in the pond. 复形名词 有些名词虽然形式上是复数形式，即以-s结尾，但实际上却表示单数意义。 1The news is at six. 名词的数 名词的单数形式和复数形式 拼写规则 单数 复数 一般情况下加-s cat cats 以 -o, -x, -ch, -sh 结尾的加 -es potato class box watch brush potatoes classes boxes watches brushes 以 辅音字母加 -y结尾，去-y加-ies 元音字母加 -y 结尾的加 -s country boys countries boys 以 -y 结尾的专有名词加 -s Fry Frys 以 -f, -fe 结尾的名词， 把-f, -fe变为 -ves wife wives 不规则变化 man sheep men sheep 以 -o 结尾一般要在后面加 -es 但元音字母加 -o 结尾的名词则只能加 -s。 不规则拼写法 123foot/feetmouse/micetooth/teeth 单/复数形式相同 1234sheepdeeraricraftChinese 名词的性 阳性 阴性 中性 123acrot(男演员)actress(女演员)guest(客人) 有些名词可以不加思索的用阳性代词he、阴性代词she、中性代词it来指代。表示动物性别相对的名词一般可用it指代。 名词的格 名词所有格的构成 说明 栗子 单数名词末尾加&#39;s child’s 以 -s结尾的单数名词末尾加&#39;s或加&#39; actress’s/actress’ 不规则的复数名词末尾加 &#39;s children’s 以-s结尾的复数名词末尾加 &#39; girls’ 一些以 -s 结尾的人名末尾加 &#39;s James’s 所有格一般表示人或事物的所属概念，通常可以回答Whose...?的问句。 通常来说&#39;s/s&#39;和of的作用是一样的，但&#39;s/s&#39;一般不和无生命的名词连用，而有生命的名词则两者通用。 冠词有若干个词可以用在名词或形容词+名词的前面，我们把这类词统称为限定词(determiners)，因为它们影响或限定着这个名词的意义。冠词就是其中一种。 限定词限定词分为两种： 有助于分类或确认的词 表数量的词 有助于分类或确认的词 不定冠词 123I bought &apos;a&apos; new shirt yesterday.&apos;A&apos; girl came in and put &apos;an&apos; envelope on his desk. 定冠词 1&apos;The&apos; shirt I am wearing is new. 指示代词 1I bought &apos;this/that&apos; shirt yesterday. 物主代词 1&apos;My&apos; shirt is blue. 表示数量的词 数词 1I bought &apos;two&apos; shirts yesterday. 量词 1I didn&apos;t buy &apos;many&apos; new shirts yesterday. 冠词的基本用法冠词分为： 不定冠词(a/an) 定冠词(the) 零冠词 代词代词是用来代替名词或名词短语的。 代词可分为： 人称代词: I, me, he… 物主代词: my, their, yours… 反身代词: myself, herself, themselves… 指示代词: this, that, those… 不定代词: some, many, each, any, all… 疑问代词: what, which… 关系代词: which, who(m), as, that… … 人称代词 主格人称代词在句子中一般用在谓语动词前面，充当句子的主语 1I think, therefore I am. it也可以用来表示人，它一般表示要确认什么人，或在表示弄不清楚小孩儿的性别的时候 1There&apos;s a knock at the door. Who is &apos;it&apos;? 宾格人称代词可代替处于宾语位置上的名词，充当动词或介词的宾语。有些动词接两个宾语：直接宾语和间接宾语。直接宾语指动作的承受者，间接宾语指动作所向的人或物。间接宾语必须与直接宾语连用 123I gave &apos;him&apos; a glass of water.#him 为间接宾语#a glass of water 为直接宾语 使用人称代词时无论主格还是宾格，都应考虑到其所处的具体位置，在系动词be后也可以使用宾格，但不强调 1Who is &apos;it&apos;? 当人称代词处于同位结构中时，应与其同位的部分保持一致。也就是说当其同位的部分为主语时，其同位代词也为主语(用主格)，而当其同位的部分为宾语时，所用代词也为宾语(用宾格) 1Both Jack an &apos;I&apos; can swim very well. 有时候，尤其在口语中，宾格人称代词me也可用作主语 1Me/Not me! 注意祈使句中可用宾格人称代词作主语，起强调作用 1She&apos;s been promoted. Lucky &apos;her&apos;! 关于动物、东西和国家，人们通常将其人格化，这样它们也就具有了阴/阳性 1The cuckoo lays &apos;her&apos; eggs in other birds&apos; nests. 当我们谈论汽车、船、摩托及其它机械时，常常把它们看做阴性 1My car&apos;s not fast, but &apos;she&apos; does 50 miles to the gallon. 国家通常也人格化，经常看成阴性 1In 1941, America assumed &apos;her&apos; role as a world power. 不定代词 不定代词指的是some, any, no, every…以及与之组成的复合词不定代词常常表示不确定的人、物或量。 123someone, anyone, none, everyonesomebody...something... 在表示一些时，some一般用于肯定陈述句中，而any则一般用于疑问句和否定句中 123There are &apos;some&apos; frogs in the pond.There aren&apos;t &apos;any&apos; frogs in the pod. 当表示建议或请求的时候，仍用some或something等 1Would you like &apos;something&apos; to drink? any或anything用于陈述句的肯定形式的时候，表示泛指概念，指任何 1You can choose &apos;anything&apos; you like here. 复合不定代词(如something, anything)等的定语一般应后置 123This is &apos;something&apos; special.Is there &apos;anything&apos; for me to sit on? 当需要排除概念时，经常将else与不定代词连用，构成如下组合词，表示另外的，别的之意 123everyone else, someone else, anyone else, anything else, nothing else...We need one more helper. Can you find &apos;anyone else&apos;? 指代a/an + 可数名词时，则必须用one作宾语 12Would you like a drink?I&apos;d love &apos;one&apos;. Thank you. 当不可数名词或复数名词用于非特指时，则必须使用some或any作宾语 1Have you got &apos;any&apos; sugar? Can you lend me &apos;some&apos;? 物主代词物主代词分为: 形容词性物主代词(或所有格形容词) 名词性物主代词(或所有格代词) 12形容词性: my, your, his, her, its, one's, our, your, their名词性: mine, yours, his, hers,ours, theirs 形容词性物主代词和名词性物主代词都表示所有，即某人或某物属于某个人，回答Whose…?的问题。形容词性物主代词是限定词，因此必须放在名词之前，不可单独使用。它们的形式取决于所有者，而不是被拥有的东西。 12345John&apos;s daugther = his daugtherJane&apos;s son = her sonthe cat&apos;s milk = its milk my, your, their可表示男性所有，也可表示女性所有。 123&quot;My house is there,&quot; Sally/John said.Your passports, please. their也可表示动物或物品所有。 123Dogs should have their own kennels outside the house.Cars with their engines at the back are very noisy. one’s 可用作非人称形容词性物主代词，但不能用作名词性物主代词。 1One&apos;s first duty is to one&apos;s family. 所有格代词mine, yours不能用在名词之前，且在说话时要加重语气。它们在指人或物时，单数或复数都一样。its从来不作所有格代词用。 123There are my children. These children are mine.I can&apos;t find my pen. Can you lend me yours? 名词性所有格可以放在句首。 1This is my cup. Yours is the one ttat&apos;s chipped. 在特别强调所有关系时，通常用one’s own。可以在任何形容词性物主代词而不是名词性物主代词后面加上own，这样形成的词组既可以起形容词性物主代词的作用，也可以起名词性物主代词的作用。 123I&apos;d love to have my own room / a room of my own.Our cat has its own corner / a corner of its own in this room. 如果需要再进一步强调则可以加上very。 1I&apos;d love to have my very own room /a room of my very own. 反身代词反身代词属于所有格形容词，其构成为”形容词性物主代词+self”组成的复合词，或”人称代词宾格+self”。 12单数: myself, yourself, himself, herself, itself, oneself复数: ourselves, yourselves, themselves 指示代词指示代词包括this, that, these, those。 其中， this, these为近指指示代词，与here对应； that, those为远指指示代词，与there对应。它们一般与名词连用。 1this girl, that boy, these teachers, those students 通常来说，单独用指示代词时，不指人而指物；但在Who…?问句中，也可指人。 123I found this watch. I found this.Who&apos;s this? Who&apos;s that? 数量词概述数量词或数量词组常用来修饰名词，表示我们所说的事物的数与量。 12345有些数量词修饰可数名词复数，如 many, (a) few, several...有些数量词修饰不可数名词，如 much, (a) little...有些两者皆可修饰，如 a lot of, lots of, some... 修饰可数名词时，用来回答How many…? 12How many eggs are there in the fridge?There are a few. 数量词修饰不可数名词时，用来回答How much…? 12How much milk is there in the fridge?There&apos;s a little. 两者皆可修饰，因此既能回答How many…? 也能回答How much…? 12345How many eggs are there in the fridge?There are plenty.How much milk is there in the fridge?There is plenty. 数量词+名词 的组合形式 搭配形式分类 同类数量词 数量词+复数可数名词 如: many books both, a couple of, hundreds of, (a) few, a number of, serval … 数量词+不可数名词 如: much sugar a amount of, a bit of, a drop of, a deal of, (a) little of … 数量词+复数可数名词,不可数名词 如: some books, some sugar some, any, all, hardly, a lot of, lots of, the other … 数量词+单数可数名词 如: each book another, each, either, the other, some, the whole … 不是不确定的数量1234567891011121314151617181920212223242526#数量可以是确定的，也就是可确切地说出到底有多少We need six eggs and half a kilo of butter.#更多的时候，数量是不确定的，它只说明了一个大致的情况Are there (any) apples in the bag?There is some milk in the fridge.#数量词后常和more连用I&apos;d like some more chipsI&apos;d like some more milk.#数量词后也常和less连用Much less soup, please.I want mush less, please.#数量词前用notNot enough is known about this subject.It has given not a little trouble. 数词的分类数词可分为: 基数词 序数词 分数 小数 百分数 … 123456789101112131415161718192021222324252627282930#基数词one, two, three...#序数词first, sixth, tenth...#分数#英语中分数的构成为: 一个基数词加一个序数词#分子为1时，分母直接使用序数词；分子大于1时，分母序数词+sone third, nine sixteenths#小数0.5, nought point five, point five2.5, two point five2.05, two nought five, two point o five#百分数8%, eight percent99%, ninety-nine percent#近似的数量about, almost, exactly, fewer than, at least, less than, nearly ...There wrer over seventy people at the party. not, no, none, little与bit等的区别12345678910#not, no, none的区别#构成否定句的方式可以用not来否定动词，也可用no来否定后面的名词#none可以直接作为一个代词来用，而no则不可There aren&apos;t buses after midnight.There are no buses after midnight.Do you have any diaries? We&apos;ve got none at the moment.]]></content>
      <categories>
        <category>English</category>
      </categories>
      <tags>
        <tag>English</tag>
        <tag>Grammar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[国际音标]]></title>
    <url>%2F2018%2F11%2F13%2F%E5%9B%BD%E9%99%85%E9%9F%B3%E6%A0%87%2F</url>
    <content type="text"><![CDATA[参考： 国际音标维基 巴士英语网: https://en-yinbiao.xiao84.com/yinbiaofayin/ 知乎@姜枣茶茶母的回答: https://www.zhihu.com/question/19913374 介绍英语发音有多个国家的区别，我们重点了解两个： 公认发音，英国标准（Received pronunciation, RP） 通用美式英语（General American, GA） 国际音标(International Phonetic Alphabet，缩写：IPA)旁边的分隔号和括号并非音标的一部分，它们是语言专家用以分辨两个主要标音方法：音位标音和语音学标音。 48个国际音标通常是国内学生学习英语、学好英语发音必须掌握的发音基础，48个国际音标表也被称作48个音标表、48个英语音标表、48个英语国际英标表，48个国际英语音标表，这些称呼通常都是指48个英语国际英标表。48个国际音标中有20个元音、28个辅音。 元音，又称母音。 元音是在发音过程中由气流通过口腔而不受阻碍发出的音。按前后分类为高 、中、低元音。按音节分，可分为单元音和双元音。 气流在口腔或咽头受到阻碍而形成的音叫做辅音，辅音又叫子音。 共分为清辅音、浊辅音、鼻音、舌侧音 、半元音五种不同类型。其中鼻音、舌侧音 、半元音为浊辅音。 英语元音和辅音在英语发音中扮演着重要的角色，英语元音和辅音组合起来就成为英语音标，共48个音位，是英语发音的基础。 发音与技巧巴士英语网有每个音标的发音: https://en-yinbiao.xiao84.com/yinbiaofayin/ 国际音标： 1 2 3 4 元音 单元音 双元音 前元音 中元音 后元音 开合双元音 集中双元音 /iː/, /ɪ/, /e/, /æ/ /ɜː/, /ə/, /ʌ/ /uː/, /ʊ/, /ɔː/, /ɒ/, /ɑː/ /eɪ/, /aɪ/, /ɔɪ/, /aʊ/, /əʊ/ /ɪə/, /eə/, /ʊə/ 辅音 爆破音 摩擦音 破擦音 鼻音 舌则音 半元音 清辅音 浊辅音 清辅音 浊辅音 清辅音 浊辅音 浊辅音 浊辅音 浊辅音 /p/, /t/, /k/ /b/, /d/, /ɡ/ /f/, /s/, /ʃ/, /θ/, /h/ /v/, /z/, /ʒ/, /ð/, /r/ /tʃ/, /tr/, /ts/ /dʒ/, /dr/, /dz/ /m/, /n/, /ŋ/ /l/ /j/, /w/ 1 2 3 元音20个 长元音 短元音 双元音 /iː/, /ɑː/, /ɔː/, /uː/, /ɜː/ /ɪ/, /ʌ/, /ɒ/, /ʊ/, /ə/, /æ/, /e/ /eɪ/, /aɪ/, /ɔɪ/, /ɪə/, /eə/, /ʊə/, /aʊ/, /əʊ/ 辅音28个 轻辅音 浊辅音 轻辅音 浊辅音 鼻音 半元音 边音 /p/, /t/, /k/, /f/, /θ/, /s/ /b/, /d/, /ɡ/, /v/, /ð/, /z/ /ʃ/, /h/, /ts/, /tʃ/, /tr/ /ʒ/, /r/, /dz/, /dʒ/, /dr/ /m/, /n/, /ŋ/ /j/, /w/ /l/ 知识点讲解长短元音的区别在于——是否有: 有，则拖长音节 无，则短促音结尾 双元音就是把两个单元音拼到一起 发音也是两个拼到一起的，如： 12345/iə/= /i/ + /ə//uə/= /u/ + /ə//εə/= /e/ + /ə/ 清浊辅音的区别在于——喉结是否震动 震动，浊辅音 不震动，清辅音 鼻音–鼻腔发出 难读的音标易出问题的地方： 核心技巧： 用中文的音近字代替 用简单的英文字母或单词进行备注 中文字很挫，两种方法结合使用，哪个好记用哪个。 元音部分发音讲解： 12345678/ei/ ：A/ai/ ：I/ɔi/ ：“噢一”/iə/ : /i/ + /ə/ = ear/eə/ : /e/ + /ə/ = air/uə/ : /u/ + /ə/ = 污饿/əu/ ：O/au/ ：嗷（张大嘴） 辅音部分发音讲解： 第一组：/s/, /z/ 和 /θ/, /ð/这两组发音听起来差不多，唯一的区别在于：舌头是否看得见 看不见，/s/, /z/ 看得见，/θ/, /ð/ 第二组：/ʃ/, /ʒ/ “屎” “日” 第三组：/h/, /r/ “喝” “弱” 第四组：/ts/, /dz/ “此” “滋” 第五组：/tʃ/, /dʒ/ “尺” “之” 第六组：/tr/, /dr/ “戳” “捉” 第七组：/m/, /n/, /ŋ/ 都是发“嗯”的音，只是嘴型大小不一样。 /m/, 闭紧 /n/, 半张开 /ŋ/, 张大嘴 第八组：/l/这个音最难发，因为声音有点奇怪，像大舌头。发音技巧在于，把舌尖抵在上门牙底端，然后自然发出声音，就是这个音标啦。 知识点讲解 /m/, /n/, /l/ 分别有两个发音，一个是上面讲解的发音，另一个是他们的本来音，即英文字母m/n/l的发音（么，讷，勒）。 本身发音： 出现在每个音节的开头 奇怪音： 出现在每个音节的中间 练习自己找单词书进行测试和练习。]]></content>
      <categories>
        <category>English</category>
      </categories>
      <tags>
        <tag>English</tag>
        <tag>国际音标</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[劳动法]]></title>
    <url>%2F2018%2F10%2F26%2F%E5%8A%B3%E5%8A%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[参考： 中华人民共和国劳动法（2009年修正本） 《中华人民共和国劳动法》是为了保护劳动者的合法权益，调整劳动关系，建立和维护适应社会主义市场经济的劳动制度，促进经济发展和社会进步，根据宪法，制定本法。1994年7月5日第八届全国人民代表大会常务委员会第八次会议通过，自1995年1月1日起施行。 （1994年7年5日第八届全国人民代表大会常务委员会第八次会议通过 1994年7月5日中华人民共和国主席令第28号公布 根据2009年8月27日中华人民共和国主席令第18号《全国人民代表大会常务委员会关于修改部分法律的决定》修正 自公布之日起施行） 总则第一条： 为了保护劳动者的合法权益，调整劳动关系，建立和维护适应社会主义市场经济的劳动制度，促进经济发展和社会进步，根据宪法，制定本法。 第二条： 在中华人民共和国境内的企业、个体经济组织（以下统称用人单位）和与之形成劳动关系的劳动者，适用本法。 国家机关、事业组织、社会团体和与之建立劳动合同关系的劳动者，依照本法执行。 第三条: 劳动者享有平等就业和选择职业的权利、取得劳动报酬的权利、休息休假的权利、获得劳动安全卫生保护的权利、接受职业技能培训的权利、享受社会保险和福利的权利、提请劳动争议处理的权利以及法律规定的其他劳动权利。 劳动者应当完成劳动任务，提高职业技能，执行劳动安全卫生规程，遵守劳动纪律和职业道德。 第四条: 用人单位应当依法建立和完善规章制度，保障劳动者享有劳动权利和履行劳动义务。 第五条: 国家采取各种措施，促进劳动就业，发展职业教育，制定劳动标准，调节社会收人，完善社会保险，协调劳动关系，逐步提高劳动者的生活水平。 第六条: 国家提倡劳动者参加社会义务劳动，开展劳动竞赛和合理化建议活动，鼓励和保护劳动者进行科学研究、技术革新和发明创造，表彰和奖励劳动模范和先进工作者。 第七条: 劳动者有权依法参加和组织工会。 工会代表和维护劳动者的合法权益，依法独立自主地开展活动。 第八条: 劳动者依照法律规定，通过职工大会、职工代表大会或者其他形式，参与民主管理或者就保护劳动者合法权益与用人单位进行平等协商。 第九条: 国务院劳动行政部门主管全国劳动工作。 县级以上地方人民政府劳动行政部门主管本行政区域内的劳动工作。 促进就业第十条: 国家通过促进经济和社会发展，创造就业条件，扩大就业机会。 国家鼓励企业、事业组织、社会团体在法律、行政法规规定的范围内兴办产业或者拓展经营，增加就业。国家支持劳动者自愿组织起来就业和从事个体经营实现就业。 第十一条: 地方各级人民政府应当采取措施，发展多种类型的职业介绍机构，提供就业服务。 第十二条: 劳动者就业，不因民族、种族、性别、宗教信仰不同而受歧视。 第十三条: 妇女享有与男子平等的就业权利，在录用职工时，除国家规定的不适合妇女的工种或者岗位外，不得以性别为由拒绝录用妇女或者提高对妇女的录用标准。 第十四条: 残疾人、少数民族人员、退出现役的军人的就业，法律、法规有特别规定的，从其规定。 第十五条: 禁止用人单位招用未满十六周岁的未成年人。 文艺、体育和特种工艺单位招用未满十六周岁的未成年人，必须依照国家有关规定，履行审批手续，并保障其接受义务教育的权利。 劳动合同和集体合同第十六条: 劳动合同是劳动者与用人单位确立劳动关系、明确双方权利和义务的协议。 建立劳动关系应当订立劳动合同。 第十七条: 订立和变更劳动合同，应当遵循平等自愿、协商一致的原则，不得违反法律、行政法规的规定。 劳动合同依法订立即具有法律约束力，当事人必须履行劳动合同规定的义务。 第十八条: 下列劳动合同无效：（一）违反法律、行政法规的劳动合同；（二）采取欺诈、威胁等手段订立的劳动合同。 无效的劳动合同，从订立的时候起，就没有法律约束力。确认劳动合同部分无效的，如果不影响其余部分的效力，其余部分仍然有效。劳动合同的无效，由劳动争仪仲裁委员会或者人民法院确认。 第十九条: 劳动合同应当以书面形式订立，并具备以下条款：（一）劳动合同期限；（二）工作内容；（三）劳动保护和劳动条件；（四）劳动报酬；（五）劳动纪律；（六）劳动合同终止的条件；（七）违反劳动合同的责任。 劳动合同除前款规定的必备条款外，当事人可以协商约定其他内容。 第二十条: 劳动合同的期限分为有固定期限、无固定期限和以完成一定的工作为期限。 劳动者在同一用人单位连续工作满十年以上，当事人双方同意续延劳动合同的，如果劳动者提出订立无固定期限的劳动合同，应当订立无固定期限的劳动合同。 第二十一条: 劳动合同可以约定试用期。试用期最长不得超过六个月。 第二十二条: 劳动合同当事人可以在劳动合同中约定保守用人单位商业秘密的有关事项。 第二十三条: 劳动合同期满或者当事人约定的劳动合同终止条件出现，劳动合同即行终止。 第二十四条: 经劳动合同当事人协商一致，劳动合同可以解除。 第二十五条: 劳动者有下列情形之一的，用人单位可以解除劳动合同：（一）试用期间被证明不符合录用条件的；（二）严重违反劳动纪律或者用人单位规章制度的；（三）严重失职，营私舞弊，对用人单位利益造成重大损害的；（四）被依法追究刑事责任的。 第二十六条： 有下列情形之一的，用人单位可以解除劳动合同，但是应当提前三十日以书面形式通知劳动者本人：（一）劳动者患病或者非因工负伤，医疗期满后，不能从事原工作也不能从事由用人单位另行安排的工作的；（二）劳动者不能胜任工作，经过培训或者调整工作岗位，仍不能胜任工作的。（三）劳动合同订立时所依据的客观情况发生重大变化，致使原劳动合同无法履行，经当事人协商不能就变更劳动合同达成协议的。 第二十七条: 用人单位濒临破产进行法定整顿期间或者生产经营状况发生严重困难，确需裁减人员的，应当提前三十日向工会或者全体职工说明情况，听取工会或者职工的意见，经向劳动行政部门报告后，可以裁减人员。 用人单位依据本条规定裁减人员，在六个月内录用人员的，应当优先录用被裁减的人员。 第二十八条: 用人单位依据本法第二十四条、第二十六条、第二十七条的规定解除劳动合同的，应当依照国家有关规定给予经济补偿。 第二十九条: 劳动者有下列情形之一的，用人单位不得依据本法第二十六条、第二十七条的规定解除劳动合同：（一）患职业病或者因工负伤并被确认丧失或者部分丧失劳动能力的；（二）患病或者负伤，在规定的医疗期内的；（三）女职工在孕期、产期、哺乳期内的；（四）法律、行政法规规定的其他情形。 第三十条: 用人单位解除劳动合同，工会认为不适当的，有权提出意见。如果用人单位违反法律、法规或者劳动合同，工会有权要求重新处理；劳动者申请仲裁或者提起诉讼的，工会应当依法给予支持和帮助。 第三十一条: 劳动者解除劳动合同，应当提前三十日以书面形式通知用人单位。 第三十二条: 有下列情形之一的，劳动者可以随时通知用人单位解除劳动合同：（一）在试用期内的；（二）用人单位以暴力、威胁或者非法限制人身自由的手段强迫劳动的；（三）用人单位未按照劳动合同约定支付劳动报酬或者提供劳动条件的。 第三十三条: 企业职工一方与企业可以就劳动报酬、工作时间、休息休假、劳动安全卫生、保险福利等事项，签订集体合同。集体合同草案应当提交职工代表大会或者全体职工讨论通过。 集体合同由工会代表职工与企业签订；没有建立工会的企业，由职工推举的代表与企业签订。 第三十四条: 集体合同签订后应当报送劳动行政部门；劳动行政部门自收到集体合同文本之日起十五日内未提出异议的，集体合同即行生效。 第三十五条: 依法签订的集体合同对企业和企业全体职工具有约束力，职工个人与企业订立的劳动合同中劳动条件和劳动报酬等标准不得低于集体合同的规定。 工资第三十六条: 国家实行劳动者每日工作时间不超过八小时、平均每周工作时间不超过四十四小时的工时制度。 第三十七条: 对实行计件工作的劳动者，用人单位应当根据本法第三十六条规定的工时制度合理确定其劳动定额和计件报酬标准。 第三十八条: 用人单位应当保证劳动者每周至少休息一日。 第三十九条: 企业因生产特点不能实行本法第三十六条、第三十八条规定的，经劳动部门批准，可以实行其他工作和休息办法。 第四十条: 用人单位在下列节日期间应当依法安排劳动者休假：（一）元旦；（二）春节；（三）国际劳动节；（四）国庆节；（五）法律、法规规定的其他休假节日。 第四十一条: 用人单位由于生产经营需要，经与工会和劳动者协商后可以延长工作时间，一般每日不得超过一小时；因特殊原因需要延长工作时间的，在保障劳动者身体健康的条件下延长工作时间每日不得超过三小时，但是每月不得超过三十六小时。 第四十二条: 有下列情形之一的，延长工作时间不受本法第四十一条规定的限制：（一）发生自然灾害、事故或者因其他原因，威胁劳动者生命健康和财产安全，需要紧急处理的；（二）生产设备、交通运输线路、公共设施发生故障，影响生产和公众利益，必须及时抢修的；（三）法律、行政法规规定的其他情形。 第四十三条: 用人单位不得违反本法规定延长劳动者的工作时间。 第四十四条: 有下列情形之一的，用人单位应当按照下列标准支付高于劳动者正常工作时间工资的工资报酬；（一）安排劳动者延长工作时间的，支付不低于工资的百分之一百五十的工资报酬；（二）休息日安排劳动者工作又不能安排补休的，支付不低于工资的百分之二百的工资报酬；（三）法定休假日安排劳动者工作的，支付不低于工资的百分之三百的工资报酬。 第四十五条: 国家实行带薪年休假制度。 劳动者连续工作一年以上的，享受带薪年休假。具体办法由国务院规定。 第四十六条: 工资分配应当遵循按劳分配原则，实行同工同酬。 工资水平在经济发展的基础上逐步提高。国家对工资总量实行宏观调控。 第四十七条: 用人单位根据本单位的生产经营特点和经济效益，依法自主确定本单位的工资分配方式和工资水平。 第四十八条: 国家实行最低工资保障制度。最低工资的具体标准由各省、自治区直辖市人民政府规定，报国务院备案。 用人单位支付劳动者的工资不得低于当地最低工资标准。 第四十九条: 确定和调整最低工资标准应当综合参考下列因素：（一）劳动者本人及平均赡养人口的最低生活费用；（二）社会平均工资水平；（三）劳动生产率；（四）就业状况；（五）地区之间经济发展水平的差异。 第五十条: 工资应当以货币形式按月支付给劳动者本人。不得克扣或者无故拖欠劳动者的工资。 第五十一条: 劳动者在法定休假日和婚丧假期间以及依法参加社会活动期间，用人单位应当依法支付工资。 劳动安全卫生第五十二条: 用人单位必须建立、健全劳动安全卫生制度，严格执行国家劳动安全卫生规程和标准，对劳动者进行劳动安全卫生教育，防止劳动过程中的事故，减少职业危害。 第五十三条: 劳动安全卫生设施必须符合国家规定的标准。 新建、改建、扩建工程的劳动安全卫生设施必须与主体工程同时设计、同时施工、同时投入生产和使用。 第五十四条: 用人单位必须为劳动者提供符合国家规定的劳动安全卫生条件和必要的劳动防护用品，对从事有职业危害作业的劳动者应当定期进行健康检查。 第五十五条: 从事特种作业的劳动者必须经过专门培训并取得特种作业资格。 第五十六条: 劳动者在劳动过程中必须严格遵守安全操作规程。 劳动者对用人单位管理人员违章指挥、强令冒险作业，有权拒绝执行；对危害生命安全和身体健康的行为，有权提出批评、检举和控告。 第五十七条: 国家建立伤亡事故和职业病统计报告和处理制度。县级以上各级人民政府劳动行政部门、有关部门和用人单位应当依法对劳动者在劳动过程中发生的伤亡事故和劳动者 的职业病状况，进行统计、报告和处理。 女职工和未成年工特殊保护第五十八条: 国家对女职工和未成年工实行特殊劳动保护。 未成年工是指年满十六周岁未满十八周岁的劳动者。 第五十九条: 禁止安排女职工从事矿山井下、国家规定的第四级体力劳动强度的劳动和其他禁忌从事的劳动。 第六十条: 不得安排女职工在经期从事高处、低温、冷水作业和国家规定的第三级体力劳动强度的劳动。 第六十一条: 不得安排女职工在怀孕期间从事国家规定的第三级体力劳动强度的劳动和孕期禁忌从事的劳动，对怀孕七个月以上的女职工，不得安排其延长工作时间和夜班劳动。 第六十二条: 女职工生育享受不少于九十天的产假。 第六十三条: 不得安排女职工在哺乳未满一周岁的婴儿期间从事国家规定的第三级体力劳动强度的劳动和哺乳期禁忌从事的其他劳动，不得安排其延长工作时间和夜班劳动。 第六十四条: 不得安排未成年工从事矿山井下、有毒有害、国家规定的第四级体力劳动强度的劳动和其他禁忌从事的劳动。 第六十五条: 用人单位应当对未成年工定期进行健康检查。 职业培训第六十六条: 国家通过各种途径，采取各种措施，发展职业培训事业，开发劳动者的职业技能，提高劳动者素质，增强劳动者的就业能力和工作能力。 第六十七条: 各级人民政府应当把发展职业培训纳入社会经济发展的规划，鼓励和支持有条件的企业、事业组织、社会团体和个人进行各种形式的职业培训。 第六十八条: 用人单位应建立职业培训制度，按照国家规定提取和使用职业培训经费，根据本单位实际，有计划地对劳动者进行职业培训。 从事技术工种的劳动者，上岗前必须经过培训。 第六十九条: 国家确定职业分类，对规定的职业制定职业技能标准，实行职业资格证书制度，由经过政府批准的考核鉴定机构负责对劳动者实施职业技能考核鉴定。 社会保险和福利第七十条: 国家发展社会保险事业，建立社会保险制度，设立社会保险基金，使劳动者在年老、患病、工伤、失业、生育等情况下获得帮助和补偿。 第七十一条: 社会保险水平应当与社会经济发展水平和社会承受能力相适应。 第七十二条: 社会保险基金按照保险类型确定资金来源，逐步实行社会统筹。用人单位和劳动者必须依法参加社会保险，缴纳社会保险费。 第七十三条: 劳动者在下列情形下，依法享受社会保险待遇：（一）退休；（二）患病、负伤；（三）因工伤残或者患职业病；（四）失业；（五）生育。 劳动者死亡后，其遗属依法享受遗属津贴。劳动者享受社会保险待遇的条件和标准由法律、法规规定。劳动者享受的社会保险金必须按时足额支付。 第七十四条: 社会保险基金经办机构依照法律规定收支、管理和运营社会保险基金，并负有使社会保险基金保值增值的责任。 社会保险基金监督机构依照法律规定、对社会保险基金的收支、管理和运营实施监督。社会保险基金经办机构和社会保险基金监督机构的设立和职能由法律规定。任何组织和个人不得挪用社会保险基金。 第七十五条: 国家鼓励用人单位根据本单位实际情况为劳动者建立补充保险。 国家提倡劳动者个人进行储蓄性保险。 第七十六条: 国家发展社会福利事业，兴建公共福利设施、为劳动者休息、休养和疗养提供条件。 用人单位应当创造条件，改善集体福利，提高劳动者的福利待遇。 劳动争议第七十七条: 用人单位与劳动者发生劳动争议，当事人可以依法申请调解、仲裁、提起诉讼，也可以协商解决。 调解原则适用于仲裁和诉讼程序。 第七十八条: 解决劳动争议、应当根据合法、公正、及时处理的原则，依法维护劳动争议当事人的合法权益。 第七十九条: 劳动争议发生后，当事人可以向本单位劳动争议调解委员会申请调解；调解不成，当事人一方要求仲裁的，可以向劳动争议仲裁委员会申请仲裁。当事人一方也可以直接向劳动争议仲裁委员会申请仲裁。对仲裁裁决不服的，可以向人民法院提起诉讼。 第八十条: 在用人单位内，可以设立劳动争议调解委员会。劳动争议调解委员会由职工代表、用人单位代表和工会代表组成。劳动争议调解委员会主任由工会代表担任。 劳动争议经调解达成协议的，当事人应当履行。 第八十一条: 劳动争议仲裁委员会由劳动行政部门代表、同级工会代表、用人单位方面的代表组成，劳动争议仲裁委员会主任由劳动行政部门代表担任。 第八十二条: 提出仲裁要求的一方应当自劳动争议发生之日起六十日内向劳动争议仲裁委员会提出书面申请。仲裁裁决一般应在收到仲裁申请的六十日内作出。对仲裁裁决无异议的，当事人必须履行。 第八十三条: 劳动争议当事人对仲裁裁决不服的，可以自收到仲裁裁决书之日起十五日内向人民法院提起诉讼。一方当事人在法定期限内不起诉又不履行仲裁裁决的，另一方当事人可以申请人民法院强制执行。 第八十四条: 因签订集体合同发生争议，当事人协商解决不成的，当地人民政府劳动行政部门可以组织有关各方协调处理。 因履行集体合同发生争议，当事人协商解决不成的，可以向劳动争议仲裁委员会申请仲裁；对仲裁裁决不服的，可以自收到仲裁裁决书之日起十五日内向人民法院提起诉讼。 监督检查第八十五条: 县级以上各级人民政府劳动行政部门依法对用人单位遵守劳动法律、法规的情况进行监督检查，对违反劳动法律、法规的行为有权制止，并责令改正。 第八十六条: 县级以上各级人民政府劳动行政部门监督检查人员执行公务，有权进入用人单位了解执行劳动法律、法规的情况，查阅必要的资料，并对劳动场所进行检查。 县级以上各级人民政府劳动行政部门监督检查人员执行公务，必须出示证件，秉公执法并遵守有关规定。 第八十七条: 县级以上各级人民政府有关部门在各自职责范围内，对用人单位遵守劳动法律、法规的情况进行监督。 第八十八条: 各级工会依法维护劳动者的合法权益，对用人单位遵守劳动法律、法规的情况进行监督。 任何组织和个人对于违反劳动法律、法规的行为有权检举和控告。 法律责任第八十九条: 用人单位制定的劳动规章制度违反法律、法规规定的，由劳动行政部门给予警告，责令改正；对劳动者造成损害的，应当承担赔偿责任。 第九十条: 用人单位违反本法规定，延长劳动者工作时间的，由劳动行政部门给予警告，责令改正，并可以处以罚款。 第九十一条: 用人单位有下列侵害劳动者合法权益情形之一的，由劳动行政部门责令支付劳动者的工资报酬、经济补偿，并可以责令支付赔偿金：（一）克扣或者无故拖欠劳动者工资的；（二）拒不支付劳动者延长工作时间工资报酬的；（三）低于当地最低工资标准支付劳动者工资的；（四）解除劳动合同后，未依照本法规定给予劳动者经济补偿的。 第九十二条: 用人单位的劳动安全设施和劳动卫生条件不符合国家规定或者未向劳动者提供必要的劳动防护用品和劳动保护设施的，由劳动行政部门或者有关部门责令改正，可以处以罚款；情节严重的，提请县级以上人民政府决定责令停产整顿；对事故隐患不采取措施，致使发生重大事故，造成劳动者生命和财产损失的，对责任人员比照刑法第一百八十七条的规定追究刑事责任。 第九十三条: 用人单位强令劳动者违章冒险作业、发生重大伤亡事故，造成严重后果的，对责任人员依法追究刑事责任。 第九十四条: 用人单位非法招用未满十六周岁的未成年人的，由劳动行政部门责令改正，处以罚款；情节严重的，由工商行政管理部门吊销营业执照。 第九十五条: 用人单位违反本法对女职工和未成年工的保护规定，侵害其合法权益的，由劳动行政部门责令改正，处以罚款；对女职工或者未成年工造成损害的，应当承担赔偿责任。 第九十六条: 用人单位有下列行为之一，由公安机关对责任人员处以十五日以下拘留、罚款或者警告；构成犯罪的，对责任人员依法追究刑事责任： （一）以暴力、威胁或者非法限制人身自由的手段强迫劳动的。（二）侮辱、体罚、殴打、非法搜查和拘禁劳动者的。 第九十七条: 由于用人单位的原因订立的无效合同，对劳动者造成损害的，应当承担赔偿责任。 第九十八条: 用人单位违反本法规定的条件解除劳动合同或者故意拖延不订立劳动合同的，由劳动行政部门责令改正；对劳动者造成损害的，应当承担赔偿责任。 第九十九条: 用人单位招用尚未解除劳动合同的劳动者，对原用人单位造成经济损失的，该用人单位应当依法承担连带赔偿责任。 第一百条: 用人单位无故不缴纳社会保险费的，由劳动行政部门责令其限期缴纳，逾期不缴的，可以加收滞纳金。 第一百零一条: 用人单位无理阻挠劳动行政部门、有关部门及其工作人员行使监督检查权，打击报复举报人员的，由劳动行政部门或者有关部门处以罚款；构成犯罪的，对责任人员依法追究刑事责任。 第一百零二条: 劳动者违反本法规定的条件解除劳动合同或者违反劳动合同中约定的保密事项，对用人单位造成经济损失的，应当依法承担赔偿责任。 第一百零三条: 劳动行政部门或者有关部门的工作人员滥用职权、玩忽职守、徇私舞弊、构成犯罪的，依法追究刑事责任；不构成犯罪的，给予行政处分。 第一百零四条:国家工作人员和社会保险基金经办机构的工作人员挪用社会保险基金，构成犯罪的，依法追究刑事责任。 第一百零五条: 违反本法规定侵害劳动者合法权益，其他法律、行政法规已规定处罚的，依照该法律、行政法规的规定处罚。 附则第一百零六条: 省、自治区、直辖市人民政府根据本法和本地区的实际情况，规定劳动合同制度的实施步骤，报国务院备案。 第一百零七条: 本法自1995年1月1日起施行。]]></content>
      <categories>
        <category>法律</category>
      </categories>
      <tags>
        <tag>劳动法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[劳动合同法]]></title>
    <url>%2F2018%2F10%2F26%2F%E5%8A%B3%E5%8A%A8%E5%90%88%E5%90%8C%E6%B3%95%2F</url>
    <content type="text"><![CDATA[参考： 全国人民代表大会常务委员会关于修改《中华人民共和国劳动合同法》的决定（附2012年修正本） 网址： 中华人民共和国中央人民政府： http://www.gov.cn/ 中国政府法制信息网： http://www.chinalaw.gov.cn 百度百科 《中华人民共和国劳动合同法》是为了完善劳动合同制度，明确劳动合同双方当事人的权利和义务，保护劳动者的合法权益，构建和发展和谐稳定的劳动关系，制定本法。由第十届全国人民代表大会常务委员会第二十八次会议于2007年6月29日修订通过，自2008年1月1日起施行。（2012年12月28日第十一届全国人民代表大会常务委员会第三十次会议通过 2012年12月28日中华人民共和国主席令第73号公布 自2013年7月1日起施行） 总则第一条： 为了完善劳动合同制度，明确劳动合同双方当事人的权利和义务，保护劳动者的合法权益，构建和发展和谐稳定的劳动关系，制定本法。 第二条： 中华人民共和国境内的企业、个体经济组织、民办非企业单位等组织（以下称用人单位）与劳动者建立劳动关系，订立、履行、变更、解除或者终止劳动合同，适用本法。 国家机关、事业单位、社会团体和与其建立劳动关系的劳动者，订立、履行、变更、解除或者终止劳动合同，依照本法执行。 第三条： 订立劳动合同，应当遵循合法、公平、平等自愿、协商一致、诚实信用的原则。 依法订立的劳动合同具有约束力，用人单位与劳动者应当履行劳动合同约定的义务。 第四条 用人单位应当依法建立和完善劳动规章制度，保障劳动者享有劳动权利、履行劳动义务。 用人单位在制定、修改或者决定有关劳动报酬、工作时间、休息休假、劳动安全卫生、保险福利、职工培训、劳动纪律以及劳动定额管理等直接涉及劳动者切身利益的规章制度或者重大事项时，应当经职工代表大会或者全体职工讨论，提出方案和意见，与工会或者职工代表平等协商确定。在规章制度和重大事项决定实施过程中，工会或者职工认为不适当的，有权向用人单位提出，通过协商予以修改完善。用人单位应当将直接涉及劳动者切身利益的规章制度和重大事项决定公示，或者告知劳动者。 第五条： 县级以上人民政府劳动行政部门会同工会和企业方面代表，建立健全协调劳动关系三方机制，共同研究解决有关劳动关系的重大问题。 第六条： 工会应当帮助、指导劳动者与用人单位依法订立和履行劳动合同，并与用人单位建立集体协商机制，维护劳动者的合法权益。 劳动合同的订立第七条: 用人单位自用工之日起即与劳动者建立劳动关系。用人单位应当建立职工名册备查。 第八条: 用人单位招用劳动者时，应当如实告知劳动者工作内容、工作条件、工作地点、职业危害、安全生产状况、劳动报酬，以及劳动者要求了解的其他情况；用人单位有权了解劳动者与劳动合同直接相关的基本情况，劳动者应当如实说明。 第九条： 用人单位招用劳动者，不得扣押劳动者的居民身份证和其他证件，不得要求劳动者提供担保或者以其他名义向劳动者收取财物。 第十条： 建立劳动关系，应当订立书面劳动合同。 已建立劳动关系，未同时订立书面劳动合同的，应当自用工之日起一个月内订立书面劳动合同。用人单位与劳动者在用工前订立劳动合同的，劳动关系自用工之日起建立。 第十一条： 用人单位未在用工的同时订立书面劳动合同，与劳动者约定的劳动报酬不明确的，新招用的劳动者的劳动报酬按照集体合同规定的标准执行；没有集体合同或者集体合同未规定的，实行同工同酬。 第十二条 劳动合同分为固定期限劳动合同、无固定期限劳动合同和以完成一定工作任务为期限的劳动合同。 第十三条 固定期限劳动合同，是指用人单位与劳动者约定合同终止时间的劳动合同。 用人单位与劳动者协商一致，可以订立固定期限劳动合同。 第十四条 无固定期限劳动合同，是指用人单位与劳动者约定无确定终止时间的劳动合同。 用人单位与劳动者协商一致，可以订立无固定期限劳动合同。有下列情形之一，劳动者提出或者同意续订、订立劳动合同的，除劳动者提出订立固定期限劳动合同外，应当订立无固定期限劳动合同：（一）劳动者在该用人单位连续工作满十年的；（二）用人单位初次实行劳动合同制度或者国有企业改制重新订立劳动合同时，劳动者在该用人单位连续工作满十年且距法定退休年龄不足十年的；（三）连续订立二次固定期限劳动合同，且劳动者没有本法第三十九条和第四十条第一项、第二项规定的情形，续订劳动合同的。 用人单位自用工之日起满一年不与劳动者订立书面劳动合同的，视为用人单位与劳动者已订立无固定期限劳动合同。 第十五条： 以完成一定工作任务为期限的劳动合同，是指用人单位与劳动者约定以某项工作的完成为合同期限的劳动合同。 用人单位与劳动者协商一致，可以订立以完成一定工作任务为期限的劳动合同。 第十六条： 劳动合同由用人单位与劳动者协商一致，并经用人单位与劳动者在劳动合同文本上签字或者盖章生效。 劳动合同文本由用人单位和劳动者各执一份。 第十七条： 劳动合同应当具备以下条款：（一）用人单位的名称、住所和法定代表人或者主要负责人；（二）劳动者的姓名、住址和居民身份证或者其他有效身份证件号码；（三）劳动合同期限；（四）工作内容和工作地点；（五）工作时间和休息休假；（六）劳动报酬；（七）社会保险；（八）劳动保护、劳动条件和职业危害防护；（九）法律、法规规定应当纳入劳动合同的其他事项。 劳动合同除前款规定的必备条款外，用人单位与劳动者可以约定试用期、培训、保守秘密、补充保险和福利待遇等其他事项。 第十八条： 劳动合同对劳动报酬和劳动条件等标准约定不明确，引发争议的，用人单位与劳动者可以重新协商；协商不成的，适用集体合同规定；没有集体合同或者集体合同未规定劳动报酬的，实行同工同酬；没有集体合同或者集体合同未规定劳动条件等标准的，适用国家有关规定。 第十九条： 劳动合同期限三个月以上不满一年的，试用期不得超过一个月；劳动合同期限一年以上不满三年的，试用期不得超过二个月；三年以上固定期限和无固定期限的劳动合同，试用期不得超过六个月。 同一用人单位与同一劳动者只能约定一次试用期。以完成一定工作任务为期限的劳动合同或者劳动合同期限不满三个月的，不得约定试用期。试用期包含在劳动合同期限内。劳动合同仅约定试用期的，试用期不成立，该期限为劳动合同期限。 第二十条： 劳动者在试用期的工资不得低于本单位相同岗位最低档工资或者劳动合同约定工资的百分之八十，并不得低于用人单位所在地的最低工资标准。 第二十一条： 在试用期中，除劳动者有本法第三十九条和第四十条第一项、第二项规定的情形外，用人单位不得解除劳动合同。用人单位在试用期解除劳动合同的，应当向劳动者说明理由。 第二十二条： 用人单位为劳动者提供专项培训费用，对其进行专业技术培训的，可以与该劳动者订立协议，约定服务期。 劳动者违反服务期约定的，应当按照约定向用人单位支付违约金。违约金的数额不得超过用人单位提供的培训费用。用人单位要求劳动者支付的违约金不得超过服务期尚未履行部分所应分摊的培训费用。用人单位与劳动者约定服务期的，不影响按照正常的工资调整机制提高劳动者在服务期期间的劳动报酬。 第二十三条： 用人单位与劳动者可以在劳动合同中约定保守用人单位的商业秘密和与知识产权相关的保密事项。 对负有保密义务的劳动者，用人单位可以在劳动合同或者保密协议中与劳动者约定竞业限制条款，并约定在解除或者终止劳动合同后，在竞业限制期限内按月给予劳动者经济补偿。劳动者违反竞业限制约定的，应当按照约定向用人单位支付违约金。 第二十四条： 竞业限制的人员限于用人单位的高级管理人员、高级技术人员和其他负有保密义务的人员。竞业限制的范围、地域、期限由用人单位与劳动者约定，竞业限制的约定不得违反法律、法规的规定。 在解除或者终止劳动合同后，前款规定的人员到与本单位生产或者经营同类产品、从事同类业务的有竞争关系的其他用人单位，或者自己开业生产或者经营同类产品、从事同类业务的竞业限制期限，不得超过二年。 第二十五条： 除本法第二十二条和第二十三条规定的情形外，用人单位不得与劳动者约定由劳动者承担违约金。 第二十六条： 下列劳动合同无效或者部分无效： （一）以欺诈、胁迫的手段或者乘人之危，使对方在违背真实意思的情况下订立或者变更劳动合同的；（二）用人单位免除自己的法定责任、排除劳动者权利的；（三）违反法律、行政法规强制性规定的。 对劳动合同的无效或者部分无效有争议的，由劳动争议仲裁机构或者人民法院确认。 第二十七条： 劳动合同部分无效，不影响其他部分效力的，其他部分仍然有效。 第二十八条： 劳动合同被确认无效，劳动者已付出劳动的，用人单位应当向劳动者支付劳动报酬。劳动报酬的数额，参照本单位相同或者相近岗位劳动者的劳动报酬确定。 劳动合同的履行和变更第二十九条： 用人单位与劳动者应当按照劳动合同的约定，全面履行各自的义务。 第三十条： 用人单位应当按照劳动合同约定和国家规定，向劳动者及时足额支付劳动报酬。 用人单位拖欠或者未足额支付劳动报酬的，劳动者可以依法向当地人民法院申请支付令，人民法院应当依法发出支付令。 第三十一条： 用人单位应当严格执行劳动定额标准，不得强迫或者变相强迫劳动者加班。用人单位安排加班的，应当按照国家有关规定向劳动者支付加班费。 第三十二条： 劳动者拒绝用人单位管理人员违章指挥、强令冒险作业的，不视为违反劳动合同。 劳动者对危害生命安全和身体健康的劳动条件，有权对用人单位提出批评、检举和控告。 第三十三条： 用人单位变更名称、法定代表人、主要负责人或者投资人等事项，不影响劳动合同的履行。 第三十四条： 用人单位发生合并或者分立等情况，原劳动合同继续有效，劳动合同由承继其权利和义务的用人单位继续履行。 第三十五条： 用人单位与劳动者协商一致，可以变更劳动合同约定的内容。变更劳动合同，应当采用书面形式。 变更后的劳动合同文本由用人单位和劳动者各执一份。 劳动合同的解除和终止第三十六条： 用人单位与劳动者协商一致，可以解除劳动合同。 第三十七条： 劳动者提前三十日以书面形式通知用人单位，可以解除劳动合同。劳动者在试用期内提前三日通知用人单位，可以解除劳动合同。 第三十八条： 用人单位有下列情形之一的，劳动者可以解除劳动合同：（一）未按照劳动合同约定提供劳动保护或者劳动条件的；（二）未及时足额支付劳动报酬的；（三）未依法为劳动者缴纳社会保险费的；（四）用人单位的规章制度违反法律、法规的规定，损害劳动者权益的；（五）因本法第二十六条第一款规定的情形致使劳动合同无效的；（六）法律、行政法规规定劳动者可以解除劳动合同的其他情形。 用人单位以暴力、威胁或者非法限制人身自由的手段强迫劳动者劳动的，或者用人单位违章指挥、强令冒险作业危及劳动者人身安全的，劳动者可以立即解除劳动合同，不需事先告知用人单位。 第三十九条： 劳动者有下列情形之一的，用人单位可以解除劳动合同：（一）在试用期间被证明不符合录用条件的；（二）严重违反用人单位的规章制度的；（三）严重失职，营私舞弊，给用人单位造成重大损害的；（四）劳动者同时与其他用人单位建立劳动关系，对完成本单位的工作任务造成严重影响，或者经用人单位提出，拒不改正的；（五）因本法第二十六条第一款第一项规定的情形致使劳动合同无效的；（六）被依法追究刑事责任的。 第四十条： 有下列情形之一的，用人单位提前三十日以书面形式通知劳动者本人或者额外支付劳动者一个月工资后，可以解除劳动合同：（一）劳动者患病或者非因工负伤，在规定的医疗期满后不能从事原工作，也不能从事由用人单位另行安排的工作的；（二）劳动者不能胜任工作，经过培训或者调整工作岗位，仍不能胜任工作的；（三）劳动合同订立时所依据的客观情况发生重大变化，致使劳动合同无法履行，经用人单位与劳动者协商，未能就变更劳动合同内容达成协议的。 第四十一条： 有下列情形之一，需要裁减人员二十人以上或者裁减不足二十人但占企业职工总数百分之十以上的，用人单位提前三十日向工会或者全体职工说明情况，听取工会或者职工的意见后，裁减人员方案经向劳动行政部门报告，可以裁减人员：（一）依照企业破产法规定进行重整的；（二）生产经营发生严重困难的；（三）企业转产、重大技术革新或者经营方式调整，经变更劳动合同后，仍需裁减人员的；（四）其他因劳动合同订立时所依据的客观经济情况发生重大变化，致使劳动合同无法履行的。 裁减人员时，应当优先留用下列人员：（一）与本单位订立较长期限的固定期限劳动合同的；（二）与本单位订立无固定期限劳动合同的；（三）家庭无其他就业人员，有需要扶养的老人或者未成年人的。 用人单位依照本条第一款规定裁减人员，在六个月内重新招用人员的，应当通知被裁减的人员，并在同等条件下优先招用被裁减的人员。 第四十二条： 劳动者有下列情形之一的，用人单位不得依照本法第四十条、第四十一条的规定解除劳动合同：（一）从事接触职业病危害作业的劳动者未进行离岗前职业健康检查，或者疑似职业病病人在诊断或者医学观察期间的；（二）在本单位患职业病或者因工负伤并被确认丧失或者部分丧失劳动能力的；（三）患病或者非因工负伤，在规定的医疗期内的；（四）女职工在孕期、产期、哺乳期的；（五）在本单位连续工作满十五年，且距法定退休年龄不足五年的；（六）法律、行政法规规定的其他情形。 第四十三条： 用人单位单方解除劳动合同，应当事先将理由通知工会。用人单位违反法律、行政法规规定或者劳动合同约定的，工会有权要求用人单位纠正。用人单位应当研究工会的意见，并将处理结果书面通知工会。 第四十四条： 有下列情形之一的，劳动合同终止：（一）劳动合同期满的；（二）劳动者开始依法享受基本养老保险待遇的；（三）劳动者死亡，或者被人民法院宣告死亡或者宣告失踪的；（四）用人单位被依法宣告破产的；（五）用人单位被吊销营业执照、责令关闭、撤销或者用人单位决定提前解散的；（六）法律、行政法规规定的其他情形。 第四十五条： 劳动合同期满，有本法第四十二条规定情形之一的，劳动合同应当续延至相应的情形消失时终止。但是，本法第四十二条第二项规定丧失或者部分丧失劳动能力劳动者的劳动合同的终止，按照国家有关工伤保险的规定执行。 第四十六条： 有下列情形之一的，用人单位应当向劳动者支付经济补偿：（一）劳动者依照本法第三十八条规定解除劳动合同的；（二）用人单位依照本法第三十六条规定向劳动者提出解除劳动合同并与劳动者协商一致解除劳动合同的；（三）用人单位依照本法第四十条规定解除劳动合同的；（四）用人单位依照本法第四十一条第一款规定解除劳动合同的；（五）除用人单位维持或者提高劳动合同约定条件续订劳动合同，劳动者不同意续订的情形外，依照本法第四十四条第一项规定终止固定期限劳动合同的；（六）依照本法第四十四条第四项、第五项规定终止劳动合同的；（七）法律、行政法规规定的其他情形。 第四十七条： 经济补偿按劳动者在本单位工作的年限，每满一年支付一个月工资的标准向劳动者支付。六个月以上不满一年的，按一年计算；不满六个月的，向劳动者支付半个月工资的经济补偿。 劳动者月工资高于用人单位所在直辖市、设区的市级人民政府公布的本地区上年度职工月平均工资三倍的，向其支付经济补偿的标准按职工月平均工资三倍的数额支付，向其支付经济补偿的年限最高不超过十二年。本条所称月工资是指劳动者在劳动合同解除或者终止前十二个月的平均工资。 第四十八条： 用人单位违反本法规定解除或者终止劳动合同，劳动者要求继续履行劳动合同的，用人单位应当继续履行；劳动者不要求继续履行劳动合同或者劳动合同已经不能继续履行的，用人单位应当依照本法第八十七条规定支付赔偿金。 第四十九条： 国家采取措施，建立健全劳动者社会保险关系跨地区转移接续制度。 第五十条： 用人单位应当在解除或者终止劳动合同时出具解除或者终止劳动合同的证明，并在十五日内为劳动者办理档案和社会保险关系转移手续。 劳动者应当按照双方约定，办理工作交接。用人单位依照本法有关规定应当向劳动者支付经济补偿的，在办结工作交接时支付。用人单位对已经解除或者终止的劳动合同的文本，至少保存二年备查。 特别规定第一节 集体合同第五十一条： 企业职工一方与用人单位通过平等协商，可以就劳动报酬、工作时间、休息休假、劳动安全卫生、保险福利等事项订立集体合同。集体合同草案应当提交职工代表大会或者全体职工讨论通过。 集体合同由工会代表企业职工一方与用人单位订立；尚未建立工会的用人单位，由上级工会指导劳动者推举的代表与用人单位订立。 第五十二条： 企业职工一方与用人单位可以订立劳动安全卫生、女职工权益保护、工资调整机制等专项集体合同。 第五十三条： 在县级以下区域内，建筑业、采矿业、餐饮服务业等行业可以由工会与企业方面代表订立行业性集体合同，或者订立区域性集体合同。 第五十四条： 集体合同订立后，应当报送劳动行政部门；劳动行政部门自收到集体合同文本之日起十五日内未提出异议的，集体合同即行生效。 依法订立的集体合同对用人单位和劳动者具有约束力。行业性、区域性集体合同对当地本行业、本区域的用人单位和劳动者具有约束力。 第五十五条： 集体合同中劳动报酬和劳动条件等标准不得低于当地人民政府规定的最低标准；用人单位与劳动者订立的劳动合同中劳动报酬和劳动条件等标准不得低于集体合同规定的标准。 第五十六条： 用人单位违反集体合同，侵犯职工劳动权益的，工会可以依法要求用人单位承担责任；因履行集体合同发生争议，经协商解决不成的，工会可以依法申请仲裁、提起诉讼。 ## 第二节 劳务派遣 第五十七条： 经营劳务派遣业务应当具备下列条件：（一）注册资本不得少于人民币二百万元；（二）有与开展业务相适应的固定的经营场所和设施；（三）有符合法律、行政法规规定的劳务派遣管理制度；（四）法律、行政法规规定的其他条件。 经营劳务派遣业务，应当向劳动行政部门依法申请行政许可；经许可的，依法办理相应的公司登记。未经许可，任何单位和个人不得经营劳务派遣业务。 第五十八条： 劳务派遣单位是本法所称用人单位，应当履行用人单位对劳动者的义务。劳务派遣单位与被派遣劳动者订立的劳动合同，除应当载明本法第十七条规定的事项外，还应当载明被派遣劳动者的用工单位以及派遣期限、工作岗位等情况。 劳务派遣单位应当与被派遣劳动者订立二年以上的固定期限劳动合同，按月支付劳动报酬；被派遣劳动者在无工作期间，劳务派遣单位应当按照所在地人民政府规定的最低工资标准，向其按月支付报酬。 第五十九条： 劳务派遣单位派遣劳动者应当与接受以劳务派遣形式用工的单位（以下称用工单位）订立劳务派遣协议。劳务派遣协议应当约定派遣岗位和人员数量、派遣期限、劳动报酬和社会保险费的数额与支付方式以及违反协议的责任。 用工单位应当根据工作岗位的实际需要与劳务派遣单位确定派遣期限，不得将连续用工期限分割订立数个短期劳务派遣协议。 第六十条： 劳务派遣单位应当将劳务派遣协议的内容告知被派遣劳动者。 劳务派遣单位不得克扣用工单位按照劳务派遣协议支付给被派遣劳动者的劳动报酬。劳务派遣单位和用工单位不得向被派遣劳动者收取费用。 第六十一条： 劳务派遣单位跨地区派遣劳动者的，被派遣劳动者享有的劳动报酬和劳动条件，按照用工单位所在地的标准执行。 第六十二条 用工单位应当履行下列义务：（一）执行国家劳动标准，提供相应的劳动条件和劳动保护；（二）告知被派遣劳动者的工作要求和劳动报酬；（三）支付加班费、绩效奖金，提供与工作岗位相关的福利待遇；（四）对在岗被派遣劳动者进行工作岗位所必需的培训；（五）连续用工的，实行正常的工资调整机制。 用工单位不得将被派遣劳动者再派遣到其他用人单位。 第六十三条： 被派遣劳动者享有与用工单位的劳动者同工同酬的权利。用工单位应当按照同工同酬原则，对被派遣劳动者与本单位同类岗位的劳动者实行相同的劳动报酬分配办法。用工单位无同类岗位劳动者的，参照用工单位所在地相同或者相近岗位劳动者的劳动报酬确定。 劳务派遣单位与被派遣劳动者订立的劳动合同和与用工单位订立的劳务派遣协议，载明或者约定的向被派遣劳动者支付的劳动报酬应当符合前款规定。 第六十四条： 被派遣劳动者有权在劳务派遣单位或者用工单位依法参加或者组织工会，维护自身的合法权益。 第六十五条： 被派遣劳动者可以依照本法第三十六条、第三十八条的规定与劳务派遣单位解除劳动合同。 被派遣劳动者有本法第三十九条和第四十条第一项、第二项规定情形的，用工单位可以将劳动者退回劳务派遣单位，劳务派遣单位依照本法有关规定，可以与劳动者解除劳动合同。 第六十六条： 劳动合同用工是我国的企业基本用工形式。劳务派遣用工是补充形式，只能在临时性、辅助性或者替代性的工作岗位上实施。 前款规定的临时性工作岗位是指存续时间不超过六个月的岗位；辅助性工作岗位是指为主营业务岗位提供服务的非主营业务岗位；替代性工作岗位是指用工单位的劳动者因脱产学习、休假等原因无法工作的一定期间内，可以由其他劳动者替代工作的岗位。用工单位应当严格控制劳务派遣用工数量，不得超过其用工总量的一定比例，具体比例由国务院劳动行政部门规定。 第六十七条： 用人单位不得设立劳务派遣单位向本单位或者所属单位派遣劳动者。 ## 第三节 非全日制用工 第六十八条: 非全日制用工，是指以小时计酬为主，劳动者在同一用人单位一般平均每日工作时间不超过四小时，每周工作时间累计不超过二十四小时的用工形式。 第六十九条: 非全日制用工双方当事人可以订立口头协议。 从事非全日制用工的劳动者可以与一个或者一个以上用人单位订立劳动合同；但是，后订立的劳动合同不得影响先订立的劳动合同的履行。 第七十条: 非全日制用工双方当事人不得约定试用期。 第七十一条: 非全日制用工双方当事人任何一方都可以随时通知对方终止用工。终止用工，用人单位不向劳动者支付经济补偿。 第七十二条: 非全日制用工小时计酬标准不得低于用人单位所在地人民政府规定的最低小时工资标准。 非全日制用工劳动报酬结算支付周期最长不得超过十五日。 # 监督检查 第七十三条： 国务院劳动行政部门负责全国劳动合同制度实施的监督管理。 县级以上地方人民政府劳动行政部门负责本行政区域内劳动合同制度实施的监督管理。县级以上各级人民政府劳动行政部门在劳动合同制度实施的监督管理工作中，应当听取工会、企业方面代表以及有关行业主管部门的意见。 第七十四条： 县级以上地方人民政府劳动行政部门依法对下列实施劳动合同制度的情况进行监督检查：（一）用人单位制定直接涉及劳动者切身利益的规章制度及其执行的情况；（二）用人单位与劳动者订立和解除劳动合同的情况；（三）劳务派遣单位和用工单位遵守劳务派遣有关规定的情况；（四）用人单位遵守国家关于劳动者工作时间和休息休假规定的情况；（五）用人单位支付劳动合同约定的劳动报酬和执行最低工资标准的情况；（六）用人单位参加各项社会保险和缴纳社会保险费的情况；（七）法律、法规规定的其他劳动监察事项。 第七十五条： 县级以上地方人民政府劳动行政部门实施监督检查时，有权查阅与劳动合同、集体合同有关的材料，有权对劳动场所进行实地检查，用人单位和劳动者都应当如实提供有关情况和材料。 劳动行政部门的工作人员进行监督检查，应当出示证件，依法行使职权，文明执法。 第七十六条： 县级以上人民政府建设、卫生、安全生产监督管理等有关主管部门在各自职责范围内，对用人单位执行劳动合同制度的情况进行监督管理。 第七十七条： 劳动者合法权益受到侵害的，有权要求有关部门依法处理，或者依法申请仲裁、提起诉讼。 第七十八条： 工会依法维护劳动者的合法权益，对用人单位履行劳动合同、集体合同的情况进行监督。用人单位违反劳动法律、法规和劳动合同、集体合同的，工会有权提出意见或者要求纠正；劳动者申请仲裁、提起诉讼的，工会依法给予支持和帮助。 第七十九条： 任何组织或者个人对违反本法的行为都有权举报，县级以上人民政府劳动行政部门应当及时核实、处理，并对举报有功人员给予奖励。 # 法律责任 第八十条： 用人单位直接涉及劳动者切身利益的规章制度违反法律、法规规定的，由劳动行政部门责令改正，给予警告；给劳动者造成损害的，应当承担赔偿责任。 第八十一条： 用人单位提供的劳动合同文本未载明本法规定的劳动合同必备条款或者用人单位未将劳动合同文本交付劳动者的，由劳动行政部门责令改正；给劳动者造成损害的，应当承担赔偿责任。 第八十二条： 用人单位自用工之日起超过一个月不满一年未与劳动者订立书面劳动合同的，应当向劳动者每月支付二倍的工资。 用人单位违反本法规定不与劳动者订立无固定期限劳动合同的，自应当订立无固定期限劳动合同之日起向劳动者每月支付二倍的工资。 第八十三条： 用人单位违反本法规定与劳动者约定试用期的，由劳动行政部门责令改正；违法约定的试用期已经履行的，由用人单位以劳动者试用期满月工资为标准，按已经履行的超过法定试用期的期间向劳动者支付赔偿金。 第八十四条： 用人单位违反本法规定，扣押劳动者居民身份证等证件的，由劳动行政部门责令限期退还劳动者本人，并依照有关法律规定给予处罚。 用人单位违反本法规定，以担保或者其他名义向劳动者收取财物的，由劳动行政部门责令限期退还劳动者本人，并以每人五百元以上二千元以下的标准处以罚款；给劳动者造成损害的，应当承担赔偿责任。劳动者依法解除或者终止劳动合同，用人单位扣押劳动者档案或者其他物品的，依照前款规定处罚。 第八十五条： 用人单位有下列情形之一的，由劳动行政部门责令限期支付劳动报酬、加班费或者经济补偿；劳动报酬低于当地最低工资标准的，应当支付其差额部分；逾期不支付的，责令用人单位按应付金额百分之五十以上百分之一百以下的标准向劳动者加付赔偿金：（一）未按照劳动合同的约定或者国家规定及时足额支付劳动者劳动报酬的；（二）低于当地最低工资标准支付劳动者工资的；（三）安排加班不支付加班费的；（四）解除或者终止劳动合同，未依照本法规定向劳动者支付经济补偿的。 第八十六条： 劳动合同依照本法第二十六条规定被确认无效，给对方造成损害的，有过错的一方应当承担赔偿责任。 第八十七条： 用人单位违反本法规定解除或者终止劳动合同的，应当依照本法第四十七条规定的经济补偿标准的二倍向劳动者支付赔偿金。 第八十八条： 用人单位有下列情形之一的，依法给予行政处罚；构成犯罪的，依法追究刑事责任；给劳动者造成损害的，应当承担赔偿责任：（一）以暴力、威胁或者非法限制人身自由的手段强迫劳动的；（二）违章指挥或者强令冒险作业危及劳动者人身安全的；（三）侮辱、体罚、殴打、非法搜查或者拘禁劳动者的；（四）劳动条件恶劣、环境污染严重，给劳动者身心健康造成严重损害的。 第八十九条： 用人单位违反本法规定未向劳动者出具解除或者终止劳动合同的书面证明，由劳动行政部门责令改正；给劳动者造成损害的，应当承担赔偿责任。 第九十条： 劳动者违反本法规定解除劳动合同，或者违反劳动合同中约定的保密义务或者竞业限制，给用人单位造成损失的，应当承担赔偿责任。 第九十一条： 用人单位招用与其他用人单位尚未解除或者终止劳动合同的劳动者，给其他用人单位造成损失的，应当承担连带赔偿责任。 第九十二条： 违反本法规定，未经许可，擅自经营劳务派遣业务的，由劳动行政部门责令停止违法行为，没收违法所得，并处违法所得一倍以上五倍以下的罚款；没有违法所得的，可以处五万元以下的罚款。 劳务派遣单位、用工单位违反本法有关劳务派遣规定的，由劳动行政部门责令限期改正；逾期不改正的，以每人五千元以上一万元以下的标准处以罚款，对劳务派遣单位，吊销其劳务派遣业务经营许可证。用工单位给被派遣劳动者造成损害的，劳务派遣单位与用工单位承担连带赔偿责任。 第九十三条： 对不具备合法经营资格的用人单位的违法犯罪行为，依法追究法律责任；劳动者已经付出劳动的，该单位或者其出资人应当依照本法有关规定向劳动者支付劳动报酬、经济补偿、赔偿金；给劳动者造成损害的，应当承担赔偿责任。 第九十四条： 个人承包经营违反本法规定招用劳动者，给劳动者造成损害的，发包的组织与个人承包经营者承担连带赔偿责任。 第九十五条： 劳动行政部门和其他有关主管部门及其工作人员玩忽职守、不履行法定职责，或者违法行使职权，给劳动者或者用人单位造成损害的，应当承担赔偿责任；对直接负责的主管人员和其他直接责任人员，依法给予行政处分；构成犯罪的，依法追究刑事责任。 # 附则 第九十六条： 事业单位与实行聘用制的工作人员订立、履行、变更、解除或者终止劳动合同，法律、行政法规或者国务院另有规定的，依照其规定；未作规定的，依照本法有关规定执行。 第九十七条： 本法施行前已依法订立且在本法施行之日存续的劳动合同，继续履行；本法第十四条第二款第三项规定连续订立固定期限劳动合同的次数，自本法施行后续订固定期限劳动合同时开始计算。 本法施行前已建立劳动关系，尚未订立书面劳动合同的，应当自本法施行之日起一个月内订立。本法施行之日存续的劳动合同在本法施行后解除或者终止，依照本法第四十六条规定应当支付经济补偿的，经济补偿年限自本法施行之日起计算；本法施行前按照当时有关规定，用人单位应当向劳动者支付经济补偿的，按照当时有关规定执行。 第九十八条： 本法自2008年1月1日起施行。]]></content>
      <categories>
        <category>法律</category>
      </categories>
      <tags>
        <tag>劳动合同法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文体格式]]></title>
    <url>%2F2018%2F10%2F12%2F%E6%96%87%E4%BD%93%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Grafana]]></title>
    <url>%2F2018%2F09%2F13%2FGrafana%2F</url>
    <content type="text"><![CDATA[参考： Grafana 文档: http://docs.grafana.org/ GitHub: https://github.com/grafana/ 环境： CentOS7x86_64 Grafana v5.2]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Grafana</tag>
        <tag>Monitoring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Prometheus]]></title>
    <url>%2F2018%2F09%2F11%2FPrometheus%2F</url>
    <content type="text"><![CDATA[参考： Prometheus文档： https://prometheus.io/docs GitHub: https://github.com/prometheus/ 环境： CentOS7x86_64 Prometheus v2.3 介绍Introduction 概述 Prometheus是什么What is Prometheus? Prometheus是一个最初在SoundCloud上构建的开源监控系统和报警工具包。现在是一个独立的开源项目，由社区进行维护。 功能(Features)Prometheus的主要特点： 具有由度量名称(metric name)和键值对(key-value)标识的时间序列(time series)数据的多维(multi-dimensional)数据模型 灵活的查询语言，以利用此维度 不依赖分布式存储(distributed storage)，单个服务器节点是自治的(autonomous) 时间序列集合通过HTPP的pull model发生 push时间序列通过中间网关(intermediary gateway)的支持 通过服务发现或静态配置来发现目标 图形和仪表盘支持多种模式 组件(Components)Prometheus系统由多个组件构成，其中某些组件是可选的： 主要的Prometheus Server，用于存储时间序列数据 client libraries，用于检测应用程序代码 push gateway，用于支持短暂的(short-lived)工作 exporters，用于服务的特殊目的 alertmanager，用于处理报警 各种支持工具 架构(Architecture)Prometheus的体系结构和系统组件图： 什么时候适合When does it fit? Prometheus适用于记录任何纯数字时间序列。它既适用于以机器为中心的监控，也适用于高度动态的面向服务架构的监控。在微服务的世界中，它对多维数据收集和查询的支持是一种特殊的优势。Prometheus专为提高可靠性而设计，是你在断电期间可以快速诊断问题的系统。每个Prometheus Server都是独立的，不依赖于网络存储或其它远程服务。当基础架构其它部分损坏时，你仍可以依赖它，并且你不需要设置大量的基础架构来使用它。 什么时候不适合When does it not fit? Prometheus重视可靠性。即使在系统故障情况下，你也可以随时查看有关系统的可用统计信息。如果你需要100%的准确度，Prometheus不是一个好的选择，你可能需要使用其它系统。 第一步步骤： 下载 配置 运行 使用表达式浏览器 使用图形接口 监控其它目标 术语GLOSSARY Alert是Prometheus正在开火的警报规则的结果。警报从Prometheus发送到AlterManger。 Alertmanager接收警报，将它们聚合成组，删除重复数据，应用静音、限制，然后发送电子邮件等通知。 Bridge是一个从Client Library中获取样本并将它们暴露给 non-Prometheus 监控系统的组件。例如，Python、Java、Go…客户端可将指标导出到Graphite。 Client library是某种语言的库(Go, Java, Python…)，可以直接检测代码，编写自定义收集器以从其它系统中收集指标并将指标公开给Prometheus。 Collector是表示一组度量标准的 exporter 的一部分。如果它是直接检测的一部分，则可以是单个度量，如果是从另一个系统提取度量，则可以是许多度量。 Direct instrumentation作为源代码程序的一部分内联添加的检测。 Endpoint Exporter是一个公开Prometheus指标的程序，通常将 non-prometheus 格式的指标转换为 Prometheus 支持的格式。 Instance唯一标识作业中目标的标签 Job具有相同目的的目标集合 Notification代表一组多个警报 Promdash原生Prometheus仪表盘构建器。它已被弃用，并被 Grafana 取代 Prometheus通常指的是Prometheus System的核心程序，也可指整个监控系统。 PromQLPrometheus Query Language Pushgateway持续从批量作业中最新推出的指标 Remote Read允许从其它系统透明读取时间序列作为查询的一部分 Remote Read Adapter并非所有系统都支持远程读取。远程读取适配器便是用于此。 Remote Read EndpointPrometheus进行远程读取时的对象 Remote Write允许动态地将采集的样本发送到其它系统 Remote Write Adapter Remote Write Endpoint Sample时间序列中某个时间点的单个值，Prometheus中，每个样本都包含一个float64和ms精度的时间戳。 Silence防止报警 Target抓取对象的定义 FAQfaq: https://prometheus.io/docs/introduction/faq/ 概念CONCEPTS 数据模型Data model Prometheus从根本上将所有数据存储为时间序列(time series): 属于同一指标和同一标记维度的带时间戳值的流。除了存储时间序列，Prometheus还可以临时生成时间序列作为查询的结果。 指标名称和标签Metric names and labels 每个时间序列都是有指标名称(metric name)和一组键值对(也称为标签(label))来唯一标识。 指标名称： 可能包含ASCII字母，下划线，冒号。它必须匹配正则: [a-zA-Z_:][a-zA-Z0-9_:]*。标签启用Prometheus的维度数据模型： 指标类型metric types 工作和实例Job and Instance Prometheus 入门GETTING STARTED 本节介绍如何安装，配置，使用Prometheus的简单例子。你将在本地安装和运行Prometheus，将其配置为自我填充和示例应用程序，然后使用查询，规则和图表来使用收集的序列数据。 下载 下载地址: https://prometheus.io/download/ 123tar xvfz prometheus-*.tar.gzcd prometheus-* 配置和监控Prometheus通过在目标上通过HTTP endPoints来抓取指标，来收集受监控目标的指标。由于Prometheus也以相同的方式公开自身数据，它也可以获取和监测自身的健康状况。虽然Prometheus Server只收集有关自身的数据在实践中不是很有用，但它是一个很好的示例。如prometheus.yml示例配置文件： 12345678910111213141516171819global: scrape_interval: 15s # By default, scrape targets every 15 seconds. # Attach these labels to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: monitor: 'codelab-monitor'# A scrape configuration containing exactly one endpoint to scrape:# Here it's Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: 'prometheus' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:9090'] 启动启动后，可访问9090端口查看状态。可访问localhost:9090/metrics查看有关自身的相关指标。 12cd prometheus-2.3.2.linux-amd64./prometheus --config.file=&quot;prometheus.yml&quot; 使用表达式浏览器让我们看一下Prometheus收集的一些数据。要使用Prometheus的内建表达式浏览器(expression browser)，请跳转到http://localhost:9090/graph并选择Graph -&gt; Console，在其中输入表达式。绘制表达式图形同样在此操作。 12345678910#表达式prometheus_target_interval_length_seconds#表达式prometheus_target_interval_length_seconds&#123;quantile=&quot;0.99&quot;&#125;#计算返回的时间序列数count(prometheus_target_interval_length_seconds) 启动简单的目标启动一些示例目标让Prometheus获取。确保已安装Go表一起并设置了正常的GO PATH。 123456789101112131415161718mkdir ./sample &amp;&amp; cd samplegit clone https://github.com/prometheus/client_golang.gitcd client_golang/examples/randomgo get -dgo build# Start 3 example targets in separate terminals:./random -listen-address=:9091./random -listen-address=:9092./random -listen-address=:9093#访问http://localhost:9091/metriceshttp://localhost:9092/metriceshttp://localhost:9093/metrices 监控示例目标现在需要配置Prometheus来抓取目标。 1234567891011121314scrape_configs: - job_name: 'example-random' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:8080', 'localhost:8081'] labels: group: 'production' - targets: ['localhost:8082'] labels: group: 'canary' 重启Prometheus，检测rpc_durations_seconds metric来验证。 配置规则Configure rules for aggregating scraped data into new time series 聚合超过数千个时间序列的查询在计算ad-hoc时会变慢。为了提高效率，Prometheus允许你通过配置的规则将预录表达式预先记录到全新的持久时间序列中。 创建规则文件prometheus.rules.yml：123456#job_service:rpc_durations_seconds_count:avg_rate5mgroups:- name: example rules: - record: job_service:rpc_durations_seconds_count:avg_rate5m expr: avg(rate(rpc_durations_seconds_count[5m])) by (job, service) 要是Prometheus选择此新规则，需要修改Prometheus配置： 123456789101112131415161718192021222324252627282930313233global: scrape_interval: 15s # By default, scrape targets every 15 seconds. evaluation_interval: 15s # Evaluate rules every 15 seconds. # Attach these extra labels to all timeseries collected by this Prometheus instance. external_labels: monitor: &apos;codelab-monitor&apos;rule_files: - &apos;prometheus.rules.yml&apos;scrape_configs: - job_name: &apos;prometheus&apos; # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: [&apos;localhost:9090&apos;] - job_name: &apos;example-random&apos; # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: [&apos;localhost:8091&apos;, &apos;localhost:8092&apos;] labels: group: &apos;production&apos; - targets: [&apos;localhost:9093&apos;] labels: group: &apos;canary&apos; 重启Prometheus，使用job_service:rpc_durations_seconds_count:avg_rate5m metric验证。 安装 使用预编译的二进制文件 使用源码 使用Docker所有的Prometheus服务都可以作为 Docker image 来使用。Prometheus image 使用 volume 来存储实际的指标。对于生产部署，强烈建议使用 Data Volume Container 来升级数据的管理。 栗子： 123456#bind-mountdocker run -p 9090:9090 -v /tmp/prometheus.yml:/etc/prometheus.yml prom/prometheus#volumedocker run -p 9090:9090 -v /promethe-data prom/prometheus --config.file=/prometheus-data/prometheus.yml 自定义镜像 Dockerfile: 123FROM prom/prometheusADD prometheus.yml /etc/prometheus/xxx 构建： 1docker build -t my-prometheus . 使用配置管理系统 Ansible Chef Puppet SaltStack 配置Configuration Prometheus通过命令行标志(flag)和配置文件进行配置。使用./prometheus -h查看所有命令行标志。Prometheus可在运行时重新加载配置。 配置文件configuration file: https://prometheus.io/docs/prometheus/latest/configuration/configuration/ 使用--config.file标志指定配置文件。配置文件使用YAML格式。 一个配置文件栗子: 1234567891011121314151617181920212223242526272829303132333435363738global: # How frequently to scrape targets by default. [ scrape_interval: &lt;duration&gt; | default = 1m ] # How long until a scrape request times out. [ scrape_timeout: &lt;duration&gt; | default = 10s ] # How frequently to evaluate rules. [ evaluation_interval: &lt;duration&gt; | default = 1m ] # The labels to add to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: [ &lt;labelname&gt;: &lt;labelvalue&gt; ... ]# Rule files specifies a list of globs. Rules and alerts are read from# all matching files.rule_files: [ - &lt;filepath_glob&gt; ... ]# A list of scrape configurations.scrape_configs: [ - &lt;scrape_config&gt; ... ]# Alerting specifies settings related to the Alertmanager.alerting: alert_relabel_configs: [ - &lt;relabel_config&gt; ... ] alertmanagers: [ - &lt;alertmanager_config&gt; ... ]# Settings related to the remote write feature.remote_write: [ - &lt;remote_write&gt; ... ]# Settings related to the remote read feature.remote_read: [ - &lt;remote_read&gt; ... ] 各个配置项： scrape_config tls_config azure_sd_config consul_sd_config dns_sd_config ec2_sd_config openstack_sd_config file_sd_config gce_sd_config kubernetes_sd_config marathon_sd_config nerve_sd_config serverset_sd_config triton_sd_config static_config relabel_config metric_relabel_configs alert_relabel_configs alertmanager_config remote_write remote_read 可视化Visualization 表达式浏览器Expression browser 表达其浏览器在 Prometheus Server 的 /graph 处。对于图形，请使用 Grafana 或 Console template。 GrafanaGrafana: https://grafana.com/ Grafana，美丽的分析和监控的开放平台，时序分析的开源那软件。 Grafana 支持查询 Prometheus。如下是一个Grafana仪表盘，用于查询Prometheus的数据： 安装完整的安装说明，请查看Grafana Docs。 CentOSRPM 12#sudo yum install &lt;rpm package url&gt;sudo yum install https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-5.1.4-1.x86_64.rpm repo 1234567891011121314151617181920[grafana]name=grafanabaseurl=https://packagecloud.io/grafana/stable/el/7/$basearchrepo_gpgcheck=1enabled=1gpgcheck=1gpgkey=https://packagecloud.io/gpg.key https://grafanarel.s3.amazonaws.com/RPM-GPG-KEY-grafanasslverify=1sslcacert=/etc/pki/tls/certs/ca-bundle.crtsudo yum install -y grafana#启动systemctl start grafana-server#命令行工具grafana-cli 包详情 Installs binary to /usr/sbin/grafana-server Copies init.d script to /etc/init.d/grafana-server Installs default file (environment vars) to /etc/sysconfig/grafana-server Copies configuration file to /etc/grafana/grafana.ini Installs systemd service (if systemd is available) name grafana-server.service The default configuration uses a log file at /var/log/grafana/grafana.log The default configuration specifies an sqlite3 database at /var/lib/grafana/grafana.db 二进制tar文件 1234567# Download and unpack Grafana from binary tar (adjust version as appropriate).curl -L -O https://grafanarel.s3.amazonaws.com/builds/grafana-2.5.0.linux-x64.tar.gztar zxf grafana-2.5.0.linux-x64.tar.gz# Start Grafana.cd grafana-2.5.0/./bin/grafana-server web Docker123456789101112131415161718192021#基础栗子docker run -d -p 3000:3000 grafana/grafana#配置化docker run \ -d \ -p 3000:3000 \ --name=grafana \ -e &quot;GF_SERVER_ROOT_URL=http://grafana.server.name&quot; \ -e &quot;GF_SECURITY_ADMIN_PASSWORD=secret&quot; \ grafana/grafana:version#默认环境变量值GF_PATHS_CONFIG /etc/grafana/grafana.iniGF_PATHS_DATA /var/lib/grafanaGF_PATHS_HOME /usr/share/grafanaGF_PATHS_LOGS /var/log/grafanaGF_PATHS_PLUGINS /var/lib/grafana/pluginsGF_PATHS_PROVISIONING /etc/grafana/provisioning 使用默认情况下，访问http://localhost:3000来访问Grafana。默认登录的用户名和密码： admin/admin。 创建Prometheus数据源 创建Prometheus图表 Console template控制台模板允许使用Go templating language创建任意控制台。这些都是从Prometheus Server提供的。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Monitoring</tag>
        <tag>Prometheus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fluentd]]></title>
    <url>%2F2018%2F07%2F19%2FFluentd%2F</url>
    <content type="text"><![CDATA[参考： Fluentd文档: https://docs.fluentd.org/v1.0/articles/quickstart 环境： CentOS7x86_64 Fluentd v1.0 综述 入门getting started Fluentd是一个完全免费且开源的日志收集器，支持多种事件类型。Fluentd将日志视为JSON(一种机器可读格式)，它主要用C语言编写，扩展部分使用Ruby。 安装由于我使用CentOS7，所以查看了此平台文档。 安装前在安装Fluentd前，请配置环境，避免一些问题。 设置ntp 增加max file descriptors 优化网络内核参数 123456789101112131415161718192021222324252627282930#ntp/sbin/ntpdate 1.cn.pool.ntp.org#文件描述符ulimit -n#1024#LimitNOFILE=65536vim /etc/security/limits.confroot soft nofile 65536root hard nofile 65536* soft nofile 65536* hard nofile 65536#之后重启机器#优化网络内核参数vim /etc/sysctl.confnet.core.somaxconn = 1024net.core.netdev_max_backlog = 5000net.core.rmem_max = 16777216net.core.wmem_max = 16777216net.ipv4.tcp_wmem = 4096 12582912 16777216net.ipv4.tcp_rmem = 4096 12582912 16777216net.ipv4.tcp_max_syn_backlog = 8096net.ipv4.tcp_slow_start_after_idle = 0net.ipv4.tcp_tw_reuse = 1net.ipv4.ip_local_port_range = 10240 65535sysctl -p rpm安装12345#此脚本会自动安装td.repo，并安装td-agent#non-rootcurl -L https://toolbelt.treasuredata.com/sh/install-redhat-td-agent3.sh | sh#你也可以将脚本内容复制下来执行 启动daemon自动支持systemd: 1234567ls /usr/lib/systemd/system/td-agent.service#默认配置文件ls /etc/td-agent/td-agent.confsystemctl start|stop|status td-agent 通过HTTP发送示例日志我们可通过POST发送日志栗子。 1curl -X POST -d 'json=&#123;"json": "message"&#125;' http://localhost:8888/debug.txt 安装后 系统管理 配置文件 日志 连接到其它服务 如何工作 插件管理 配置语法 数据源 输出点 系统管理 123456#配置文件ls /etc/td-agent/td-agent.conf#日志ls /var/log/td-agent/td-agent.log 连接到其它服务在Fluentd中，数据 input/output 最重要的部分由插件来管理。每个插件都知道如何与外部端点连接，并负责管理传输数据流的通道。插件以某种约定命名。如in_kafka, out_mongo。 配置栗子：in_forward插件作为输入源，out_file插件作为输出点。 123456789&lt;source&gt; @type forward port 9999&lt;/source&gt;&lt;match app.**&gt; @type file path /var/log/app/data.log compress gzip&lt;/match&gt; 插件管理：Fluentd将插件作为Ruby gems来管理。所以你需要使用td-agent-gem来管理Fluentd插件。 123#安装s3插件#查看插件: &lt;https://www.fluentd.org/plugins&gt;sudo /usr/sbin/td-agent-gem install fluent-plugin-s3 配置语法配置文件由许多块组成，每个块包含一组特定数据端点设置。 数据源: 1234567&lt;source&gt; @type syslog port 5140 tag system&lt;/source&gt;#@type确定要使用的插件，你就不需要再去加上前缀in 输出点：添加一个数据流输出端点，你需要定义一个&lt;match&gt;块。你可在过滤器汇表达式中使用通配符*来匹配多个。 12345&lt;match debug.log&gt; @type syslog prot 5140 tag system&lt;/source&gt; Fluentd事件的生命Life of a Fluentd event 基础设置使用in_http和out_stdout插件作为示例，来描述事件周期。 12345678910111213141516&lt;source&gt; @type http port 8888 bind 0.0.0.0&lt;/source&gt;&lt;match test.cycle&gt; @type stdout&lt;/match&gt;curl -i -X POST -d &apos;json=&#123;&apos;action&apos;: &apos;login&apos;, &apos;user&apos;: 2&#125;&apos; http://localhost:8888/test.cycleHTTP/1.1 200 OKContent-Type: text/plainConnection: Keep-AliveContent-Length: 0 事件结构Event structure Fluentd事件结构： tag: 事件来自何处 time: 事件发生事件(原子时间) record: log内容(json) 事件处理Processing Events Filters Labels Buffers 定义好配置时，路由引擎对输入数据应用配置规则。 Filters过滤的目的在于传递(pass)或拒绝(reject)事件。 12345678910111213141516171819202122232425#栗子过滤 排除任何logout操作&lt;source&gt; @type http port 8888 bind 0.0.0.0&lt;/source&gt;&lt;filter test.cycle&gt; @type grep &lt;exclude&gt; key action pattern ^logout$ &lt;/exclude&gt;&lt;/filter&gt;&lt;match test.cycle&gt; @type stdout&lt;/match&gt;curl -i -X POST -d &apos;json=&#123;&quot;action&quot;:&quot;login&quot;,&quot;user&quot;:2&#125;&apos; http://localhost:8888/test.cyclecurl -i -X POST -d &apos;json=&#123;&quot;action&quot;:&quot;logout&quot;,&quot;user&quot;:2&#125;&apos; http://localhost:8888/test.cycle#查看fluentd日志的过滤情况vim /var/log/td-agent/td-agent.log Fluentd允许继承许多过滤器，同时考虑到配置文件的增长会让读者觉得有点复杂。所以添加了一个Label功能，用于解决这个问题。 LabelsLabel这个功能，用于解决配置文件的复杂性，并允许定义不遵循从上到下的新路由部分，而是像链接引用一样。 栗子: 12345678910111213141516171819202122232425262728&lt;source&gt; @type http bind 0.0.0.0 port 8888 @label @STAGING&lt;/source&gt;&lt;filter test.cycle&gt; @type grep &lt;exclude&gt; key action pattern ^login$ &lt;/exclude&gt;&lt;/filter&gt;&lt;label @STAGING&gt; &lt;filter test.cycle&gt; @type grep &lt;exclude&gt; key action pattern ^logout$ &lt;/exclude&gt; &lt;/filter&gt; &lt;match test.cycle&gt; @type stdout &lt;/match&gt;&lt;/label&gt; Buffers前面的栗子中，我们使用non-buffered stdout。但是在生产环境中，会使用outputs in buffered。缓冲模式下的输出插件首先将接收到的事件存储到缓冲区，并通过满足刷新条件将缓冲区写入目标。 缓冲区对可靠性和吞吐量都很重要。 结论一旦事件由源上的Fluentd引擎所上报，就可逐步处理或引用Label内部处理，任何事件都有可能被过滤。新的路由引擎旨在提供更多灵活性，并在输出前使处理更容易。 使用案例Use cases 集中式应用程序日志Centralized App Logging Java Ruby Python PHP Perl Node.js Scala 监控服务日志Monitoring Service Logs FEKSplunk是一个检索日志的好工具，但它的高成本对很对团队来说便不可取了。我们通过结合三个开源项目: Elasticsearch， Kiban， Fluentd来免费替代Splunk。 请自行安装Elasticsearch和Kibana。 安装Fluentd的Elasticsearch插件:fluent-plugin-elasticsearch: https://github.com/uken/fluent-plugin-elasticsearch 123td-agent-gem install fluent-plugin-elasticsearch --no-documenttd-agent-gem list 修改配置文件: /etc/td-agent/td-agent.conf 1234567891011121314151617181920# get logs from syslog&lt;source&gt; @type syslog port 42185 tag syslog&lt;/source&gt;# get logs from fluent-logger, fluent-cat or other fluentd instances&lt;source&gt; @type forward&lt;/source&gt;&lt;match syslog.**&gt; @type elasticsearch logstash_format true &lt;buffer&gt; flush_interval 10s # for testing &lt;/buffer&gt;&lt;/match&gt;#fluent-plugin-elasticsearch插件附带一个logstash_format选项 Elasticsearch用户和密码: 1234567891011&lt;match my.logs&gt; @type elasticsearch host localhost port 9200 user elastic password xxxxx index_name fluentd type_name fluentd&lt;/match&gt;#hosts host1:port1,host2:port2... 具体详情请参考GitHub的README。 配置rsyslogd:将日志从rsyslogd转发到Fluentd。修改/etc/syslog.conf并重启rsyslogd。这将本地syslog转发到Fluentd，而Fluentd会将日志转发给Elasticsearch。 1234*.* @127.0.0.1:42185systemcrl restart rsyslog 存储和查询事件日志：访问Kibana配置索引logstash-*进行查看日志。 使用logger命令手动发送日志到Elasticsearch。1234#logger - a shell command interface to the syslog(3) system log modulelogger -t test foobar#之后可在kibana索引中查看到ident为test, message为foobar的两个文档 邮件报警Splunk-like Grep-and-Alert-Email System Using Fluentd Splunk的一个主要功能便是能够满足日志在某些条件时发送报警电子邮件。我们将使用Fluentd构建一个类似的系统。例如，当检测到Apache日志中的5xx HTTP status code时编发送报警邮件。 安装依赖安装两个插件 12td-agent-gem install fluent-plugin-grepcountertd-agent-gem install fluent-plugin-mail 配置 12345678910111213141516171819202122232425262728293031323334353637383940/etc/td-agent/td-agent.conf&lt;source&gt; @type tail path /var/log/apache2/access.log &lt;parse&gt; @type apache2 &lt;/parse&gt; tag apache.access&lt;/source&gt;&lt;match apache.access&gt; @type grepcounter count_interval 3 # The time window for counting errors (in secs) input_key code # The field to apply the regular expression regexp ^5\d\d$ # The regular expression to be applied threshold 1 # The minimum number of erros to trigger an alert add_tag_prefix error_5xx # Generate tags like &quot;error_5xx.apache.access&quot;&lt;/match&gt;&lt;match error_5xx.apache.access&gt; @type copy &lt;store&gt; @type stdout # Print to stdout for debugging &lt;/store&gt; &lt;store&gt; @type mail host smtp.gmail.com # Change this to your SMTP server host port 587 # Normally 25/587/465 are used for submission user USERNAME # Use your username to log in password PASSWORD # Use your login password enable_starttls_auto true # Use this option to enable STARTTLS from example@gmail.com # Set the sender address to alert@example.com # Set the recipient address subject &apos;HTTP SERVER ERROR&apos; message Total 5xx error count: %s\n\nPlease check your Apache webserver ASAP message_out_keys count # Use the &quot;count&quot; field to replace &quot;%s&quot; above &lt;/store&gt;&lt;/match&gt; 请确认： smtp配置正确 td-agent daemon具有适当权限访问log 测试配置 12345systemctl restart td-agent#如果安装了standalone的Fluentdfluentd -c alert-email.conf 数据分析Data Analytics 将数据收集到HadoopFluentd + HDFS: Instant Big Data Collection 背景Fluentd专门用于解决大数据日志收集问题。 HDFS(Hadoop)是一个存储和处理大量数据的选择，但直到最近它才拥有了除Java库之外的可访问的API。本节将展示如何使用Fluentd从HTTP接收数据流并传输到HDFS。 架构 安装本节配置一个单节点用于示例。请在同一节点安装如下软件： Fluentd WebHDFS Output Plug HDFS 12345678#安装插件sudo td-agent-gem install fluent-plugin-webhdfstd-agent-gem list#安装Hadoop#http://hadoop.apache.org/releases.html#在官网上下载对应二进制 Fluentd配置 http input: 1234&lt;source&gt; @type http port 8888&lt;/source&gt; webHDFS output: 123456789&lt;match hdfs.*.*&gt; @type webhdfs host namenode.your.cluster.local port 50070 path &quot;/log/%Y%m%d_%H/access.log.#&#123;Socket.gethostname&#125;&quot; &lt;buffer&gt; flush_interval 10s &lt;/buffer&gt;&lt;/match&gt; HDFS 配置 hdfs-site.xml: 1234567891011121314&lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.support.append&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.support.broken.append&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; 测试 12345curl -X POST -d &apos;json=&#123;&quot;action&quot;:&quot;login&quot;,&quot;user&quot;:2&#125;&apos; \ http://localhost:8888/hdfs.access.testkill -USR1 `cat /var/run/td-agent/td-agent.pid`sudo -u hdfs hadoop fs -lsr /log/ 连接到数据存储Connecting to Data Storages 将Apache logs存储到MongoDB本节使用Fluentd MongoDB Output plugin实时聚合半结构化日志。 安装插件 12sudo td-agent-gem install fluent-plugin-mongotd-agent list 配置 tail input: 123456789&lt;source&gt; @type tail path /var/log/apache2/access_log pos_file /var/log/td-agent/apache2.access_log.pos &lt;parse&gt; @type apache2 &lt;/parse&gt; tag mongo.apache.access&lt;/source&gt; mongodb output: 12345678910111213141516171819202122&lt;match mongo.**&gt; # plugin type @type mongo # mongodb db + collection database apache collection access # mongodb host + port host localhost port 27017 # interval &lt;buffer&gt; flush_interval 10s &lt;/buffer&gt; # make sure to include the time key &lt;inject&gt; time_key time &lt;/inject&gt;&lt;/match&gt; 流处理Stream Processing]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Fluentd</tag>
        <tag>日志处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes]]></title>
    <url>%2F2018%2F06%2F26%2FKubernetes%2F</url>
    <content type="text"><![CDATA[参考： Kubernetes: https://zh.wikipedia.org/wiki/Kubernetes 官方文档: https://kubernetes.io/docs/ 中文文档: http://docs.kubernetes.org.cn/ GitHub: https://github.com/kubernetes/kubernetes etcd: https://coreos.com/etcd/docs/latest/ flannel: https://coreos.com/flannel/docs/latest/ 环境： CentOS7x86_64 Kubernetes v1.11 配置此章节提供了有关安装k8s和配置k8s集群的相关说明。 安装有几种方式创建k8s集群： minikube(自动部署) kubeadm(自动部署) 软件包(建议初学者使用此方式) 使用minikube创建集群Using Minikube to Create a Cluster 目标： 了解k8s集群是什么 了解Minikube是什么 启动一个k8s集群 k8s 集群k8s协调一个高度可用的计算机集群，它们连接起来作为一个单元工作 。k8s以更有效的方式自动化跨集群分发和调整应用程序容器。 k8s集群包含两种类型的资源： Master Nodes Master负责管理集群。它协调集群中的所有活动。Node是工作主机。每个节点有一个Kubelet的Agent，负责管理节点并与Master(API)通信。此外，节点上还应有处理容器操作的工具(如Docker)。生成环境的k8s集群至少有三个节点。用户可通过k8s API直接与集群进行交互。 使用Minikube部署集群: https://github.com/kubernetes/minikubeMinikube是一个工具，它运行一个单节点的k8s集群供开发用户使用。 Linux平台 12345678910111213141516curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 &amp;&amp; \chmod +x minikube &amp;&amp; \sudo mv minikube /usr/local/bin/##安装kubectlcurl -Lo kubectl https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubectl &amp;&amp; \chmod +x kubectl &amp;&amp; \sudo mv kubectl /usr/local/bin/minikube versionminikube startkubectl versionkubectl cluster-infokubectl get nodes kubeadm创建集群安装kubeadm本节介绍了如何安装kubeadm工具。 安装前 2GB RAM+ 2 cpus+ 集群主机网络互通 node上唯一的主机名，MAC，UUID 开放特定端口(防火墙) Swap disabled。必须关闭swap才能使kubelet正常工作。 验证MAC或UUID对每个node都是唯一的 ifconfig -a获取MAC cat /sys/class/dmi/id/product_uuid查看UUID 检查网络适配器 如果k8s组件不可达，请手动添加路由。 检查需要的端口 12345678910111213#masterProtocol Direction Port Range Purpose Used ByTCP Inbound 6443* Kubernetes API server AllTCP Inbound 2379-2380 etcd server client API kube-apiserver, etcdTCP Inbound 10250 Kubelet API Self, Control planeTCP Inbound 10251 kube-scheduler SelfTCP Inbound 10252 kube-controller-manager Self#workerProtocol Direction Port Range Purpose Used ByTCP Inbound 10250 Kubelet API Self, Control planeTCP Inbound 30000-32767 NodePort Services** All 安装docker使用阿里云镜像。kubeadm v1.11.1最高支持Docker 17.03，请注意。 123456789wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repomv docker-ce.repo /etc/yum.repos.dyum install -y docker-ce.x84_64#由于kubeadm不支持最新版的docker，所以需要安装指定版本yum list docker-ce --showduplicatesyum install -y docker-ce-17.03.2.ce 安装kubeadm, kubelet, kubectl kubeadm: 引导集群 kubelet: k8s agent kubectl: command line 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#创建repocat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpgEOF#国外镜像凉凉，所以换用阿里云cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF#禁用防火墙systemctl stop firewalldsystemctl disable firewalld#关闭selinuxsetenforce 0sed -i "s/^SELINUX=permissive/SELINUX=disabled/g" /etc/selinux/config#关闭swap，否则kubelet无法正常使用swapoff -a#将/etc/fstab中swap注释掉sed -i 's/.*swap.*/#&amp;/' /etc/fstab#安装yum install -y epel-release ebtables ethtoolyum install -y kubelet kubeadm kubectlsystemctl enable kubelet &amp;&amp; systemctl start kubelet#系统配置，开启网络桥接cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOF#生效sysctl -p /etc/sysctl.d/k8s.confsysctl --systemsystemctl daemon-reload#各主机时区，时间同步timedatectl set-timezone Asia/Shanghai#crontab -e#ntp*/30 * * * * /sbin/ntpdate 1.cn.pool.ntp.org &gt; /dev/null 2&gt;&amp;1#hosts&lt;master-ip&gt; master&lt;node-ip&gt; node 配置cgroup driver使用docker时，kubelet会将其驱动设置与Docker相同。kubeadm会自动检查kubelet的cgroup驱动，并在运行时将其设置到/var/lib/kubelet/kubeadm-flags.env文件。 12345678910111213docker info | grep -i 'cgroup driver'Cgroup Driver: systemd#此文件是kubeadm init生成的cat /var/lib/kubelet/kubeadm-flags.envKUBELET_KUBEADM_ARGS=--cgroup-driver=systemd --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni#如果此文件未配置此信息，我们手动添加cd /etc/systemd/system/kubelet.service.dvim 10-kubeadm.confKUBELET_KUBEADM_ARGS=--cgroup-driver=systemd --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni 拉取k8s.gcr.io镜像链接: https://console.cloud.google.com/gcr/images/google-containers/GLOBAL?location=GLOBAL&amp;project=google-containers 利用某台能上网的主机，拉取Google上kubeadm需要的k8s.gcr.io/image镜像。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193#查看kubeadm需要使用的imagekubeadm config images listk8s.gcr.io/kube-apiserver-amd64:v1.11.1k8s.gcr.io/kube-controller-manager-amd64:v1.11.1k8s.gcr.io/kube-scheduler-amd64:v1.11.1k8s.gcr.io/kube-proxy-amd64:v1.11.1k8s.gcr.io/pause-amd64:3.1k8s.gcr.io/etcd-amd64:3.2.18k8s.gcr.io/coredns:1.1.3#最好把所有镜像都拉下来，否则后面初始化的时候容易报错#在gcr.io上查找镜像#浏览器访问: &lt;https://console.cloud.google.com/gcr/images/google-containers/GLOBAL?location=GLOBAL&amp;project=google-containers&gt;#找一台能用的服务器，将这些image拉下来，推到自己的repo上再在kubeadm机器上拉取镜像，之后tag成kubeadm需要的格式#写一个脚本自动拉取镜像，更名镜像，推送镜像#我基本上把全部镜像都拉了vim k8sImages.shimages=(coredns:1.1.3etcd-amd64:3.1.15etcd-amd64:3.1.16etcd-amd64:3.1.17etcd-amd64:3.2.17etcd-amd64:3.2.18flannel-amd64:0.5.5heapster-amd64:v1.4.0heapster-amd64:v1.4.1heapster-amd64:v1.4.2heapster-amd64:v1.4.3heapster-amd64:v1.5.0heapster-amd64:v1.5.1heapster-amd64:v1.5.2heapster-amd64:v1.5.3heapster-amd64:v1.5.4heapster-grafana-amd64:v4.4.3heapster-grafana-amd64:v5.0.4heapster-influxdb-amd64:v1.3.3heapster-influxdb-amd64:v1.5.2k8s-dns-dnsmasq-nanny-amd64:1.14.10k8s-dns-dnsmasq-nanny-amd64:1.14.6k8s-dns-dnsmasq-nanny-amd64:1.14.7k8s-dns-dnsmasq-nanny-amd64:1.14.8k8s-dns-dnsmasq-nanny-amd64:1.14.9k8s-dns-kube-dns-amd64:1.14.10k8s-dns-kube-dns-amd64:1.14.5k8s-dns-kube-dns-amd64:1.14.6k8s-dns-kube-dns-amd64:1.14.7k8s-dns-kube-dns-amd64:1.14.8k8s-dns-kube-dns-amd64:1.14.9k8s-dns-sidecar-amd64:1.14.10k8s-dns-sidecar-amd64:1.14.5k8s-dns-sidecar-amd64:1.14.6k8s-dns-sidecar-amd64:1.14.7k8s-dns-sidecar-amd64:1.14.8k8s-dns-sidecar-amd64:1.14.9kube-apiserver-amd64:v1.10.5kube-apiserver-amd64:v1.10.6kube-apiserver-amd64:v1.11.0kube-apiserver-amd64:v1.11.1kube-apiserver-amd64:v1.9.10kube-controller-manager-amd64:v1.10.5kube-controller-manager-amd64:v1.10.6kube-controller-manager-amd64:v1.11.0kube-controller-manager-amd64:v1.11.1kube-controller-manager-amd64:v1.9.10kube-proxy-amd64:v1.10.6kube-proxy-amd64:v1.11.0kube-proxy-amd64:v1.11.1kube-proxy-amd64:v1.9.10kubernetes-dashboard-amd64:v1.6.2kubernetes-dashboard-amd64:v1.6.3kubernetes-dashboard-amd64:v1.7.0kubernetes-dashboard-amd64:v1.7.1kubernetes-dashboard-amd64:v1.8.0kubernetes-dashboard-amd64:v1.8.1kubernetes-dashboard-amd64:v1.8.2kubernetes-dashboard-amd64:v1.8.3kube-scheduler-amd64:v1.10.6kube-scheduler-amd64:v1.11.0kube-scheduler-amd64:v1.11.1kube-scheduler-amd64:v1.9.10pause-amd64:3.0pause-amd64:3.1pause:3.1)#可能pause与pause-amd64是一个，到时只需拉一个，然后tagfor image in $&#123;images[@]&#125;do docker pull k8s.gcr.io/$&#123;image&#125; docker tag k8s.gcr.io/$&#123;image&#125; zhang21/$&#123;image&#125; docker image rm k8s.gcr.io/$&#123;image&#125; docker push zhang21/$&#123;image&#125;done#查看docker image ls#到我的docker-hub中查看#https://hub.docker.com/u/zhang21/#现在在kubeadm集群机器上操作#还是写一个脚本来拉取镜像，更名镜像，删除镜像vim k8sImage.shimages=(coredns:1.1.3etcd-amd64:3.1.15etcd-amd64:3.1.16etcd-amd64:3.1.17etcd-amd64:3.2.17etcd-amd64:3.2.18flannel-amd64:0.5.5heapster-amd64:v1.4.0heapster-amd64:v1.4.1heapster-amd64:v1.4.2heapster-amd64:v1.4.3heapster-amd64:v1.5.0heapster-amd64:v1.5.1heapster-amd64:v1.5.2heapster-amd64:v1.5.3heapster-amd64:v1.5.4heapster-grafana-amd64:v4.4.3heapster-grafana-amd64:v5.0.4heapster-influxdb-amd64:v1.3.3heapster-influxdb-amd64:v1.5.2k8s-dns-dnsmasq-nanny-amd64:1.14.10k8s-dns-dnsmasq-nanny-amd64:1.14.6k8s-dns-dnsmasq-nanny-amd64:1.14.7k8s-dns-dnsmasq-nanny-amd64:1.14.8k8s-dns-dnsmasq-nanny-amd64:1.14.9k8s-dns-kube-dns-amd64:1.14.10k8s-dns-kube-dns-amd64:1.14.5k8s-dns-kube-dns-amd64:1.14.6k8s-dns-kube-dns-amd64:1.14.7k8s-dns-kube-dns-amd64:1.14.8k8s-dns-kube-dns-amd64:1.14.9k8s-dns-sidecar-amd64:1.14.10k8s-dns-sidecar-amd64:1.14.5k8s-dns-sidecar-amd64:1.14.6k8s-dns-sidecar-amd64:1.14.7k8s-dns-sidecar-amd64:1.14.8k8s-dns-sidecar-amd64:1.14.9kube-apiserver-amd64:v1.10.5kube-apiserver-amd64:v1.10.6kube-apiserver-amd64:v1.11.0kube-apiserver-amd64:v1.11.1kube-apiserver-amd64:v1.9.10kube-controller-manager-amd64:v1.10.5kube-controller-manager-amd64:v1.10.6kube-controller-manager-amd64:v1.11.0kube-controller-manager-amd64:v1.11.1kube-controller-manager-amd64:v1.9.10kube-proxy-amd64:v1.10.6kube-proxy-amd64:v1.11.0kube-proxy-amd64:v1.11.1kube-proxy-amd64:v1.9.10kubernetes-dashboard-amd64:v1.6.2kubernetes-dashboard-amd64:v1.6.3kubernetes-dashboard-amd64:v1.7.0kubernetes-dashboard-amd64:v1.7.1kubernetes-dashboard-amd64:v1.8.0kubernetes-dashboard-amd64:v1.8.1kubernetes-dashboard-amd64:v1.8.2kubernetes-dashboard-amd64:v1.8.3kube-scheduler-amd64:v1.10.6kube-scheduler-amd64:v1.11.0kube-scheduler-amd64:v1.11.1kube-scheduler-amd64:v1.9.10pause-amd64:3.0pause-amd64:3.1pause:3.1)for image in $&#123;images[@]&#125;do docker pull zhang21/$&#123;image&#125; docker tag zhang21/$&#123;image&#125; k8s.gcr.io/$&#123;image&#125; docker image rm zhang21/$&#123;image&#125;done#查看docker image ls 创建单master集群kubeadm可帮助你引导符合最佳实践的最小化可行的k8s集群。使用kubeadm，你的集群应通过k8s一致性测试。kubeadm还支持其它集群生命周期功能，如升级、降级和管理引导令牌(bootstrap token)。kubeadm旨在成为新用户开始尝试k8s的一种简单方法。可使用deb/rpm软件包在系统上轻松安装kubeadm。因为你可在各种类型的机器上安装kubeadm，所以它非常适合于Ansible/Salt等配置系统集成。 kubeadm的简单性意味着它可以服务于各种用例： 新用户可以从kubeadm开始，第一次尝试k8s 熟悉k8s的用户可以使用kubeadm启动集群，并测试他们的应用程序 较大的项目可以包括kubeadm作为更复杂系统中的构件，也可以包括其它安装程序工具 kubeadm Maturity(成熟度) Area Maturity Level Command line UX beta Implementation beta Config file API alpha Self-hosting alpha kubeadm alpha subcommands alpha CoreDNS GA DynamicKubeletConfig alpha kubeadm的整体功能状态为Beta，并将很快添加到GA(General Availability)。一些子功能，如自托管(self-hosting)和配置文件API仍在积极开发中。 k8s版本通常支持九个月，这也适用于kubeadm。 Kubernetes version Release month End-of-life-month v1.6.x March 2017 December 2017 v1.7.x June 2017 March 2018 v1.8.x September 2017 June 2018 v1.9.x December 2017 September 2018 v1.10.x March 2018 December 2018 v1.11.x June 2018 March 2019 开始前 一台或多台主机 2GB+ RAM(每台机器) 2CPUs+(master) 网络互通 目标 安装 单master/高可用性 的k8s集群 在集群上安装pod-network，以便pod间可互相通信 组件 123456789101112131415#Masteretcdkube-apiseverkube-controller-managerkube-schedulerkube-flannelkube-proxykube-dnskubectl#Nodekube-flannelkube-proxykubectl 说明 安装kubeadm如已安装，可升级到最新版。 初始化集群master主机是控制组件运行的地方，包括etcd, API server… 1234567891011121314151617#1#选择一个 pod network add-on，并验证是够需要将任何参数传递给kubeadm初始化。你可以使用--pod-network-cidr来指定特定值#这里使用flannel#2，可选#除非另有说明，否则kubeadm使用与默认网关关联的网络接口来通告master#使用kubeadm init --apiserver-advertise-address=&lt;ip-addr&gt;来使用不同网络接口#3，可选#在kubeadm init之前运行kubeadm config images pull以验证与gcr.io的连接#或kubeadm config images list查看需要的镜像#运行kubeadm init &lt;args&gt; 更多信息kubeadm init首先运行一系列检查，以确保机器 已准备好运行k8s。这些预检查会显示警告并退出错误。然后kubeadm init下载并安装集群控制组件。这可能需要一些时间。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171kubeadm --helpkubeadm init --help#k8s底层环境依赖于Docker#on mastersystemctl enable docker kubelet &amp;&amp; systemctl start dockerkubeadm initI0806 14:04:54.415853 2191 feature_gate.go:230] feature gates: &amp;&#123;map[]&#125;[init] using Kubernetes version: v1.11.1[preflight] running pre-flight checks [WARNING Service-Docker]: docker service is not enabled, please run &apos;systemctl enable docker.service&apos;I0806 14:04:54.433879 2191 kernel_validator.go:81] Validating kernel versionI0806 14:04:54.433934 2191 kernel_validator.go:96] Validating kernel config[preflight/images] Pulling images required for setting up a Kubernetes cluster[preflight/images] This might take a minute or two, depending on the speed of your internet connection[preflight/images] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;[preflight] Some fatal errors occurred: [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-apiserver-amd64:v1.11.1]: exit status 1 [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-controller-manager-amd64:v1.11.1]: exit status 1 [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-scheduler-amd64:v1.11.1]: exit status 1 [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-proxy-amd64:v1.11.1]: exit status 1 [ERROR ImagePull]: failed to pull image [k8s.gcr.io/pause-amd64:3.1]: exit status 1 [ERROR ImagePull]: failed to pull image [k8s.gcr.io/etcd-amd64:3.2.18]: exit status 1 [ERROR ImagePull]: failed to pull image [k8s.gcr.io/coredns:1.1.3]: exit status 1[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`#此处错误，由于镜像在Google，国内访问会超时。因此需要额外准备镜像。#需要做上面一步操作来拉取镜像#初始化#请确保资源满足条件，我就是由于VM内存为1GB而导致初始化失败，找了很久才找到这个错误kubeadm init --kubernetes-version=v1.11.1 --pod-network-cidr=10.244.0.0/16[init] using Kubernetes version: v1.11.1[preflight] running pre-flight checksI0807 14:47:10.658405 10612 kernel_validator.go:81] Validating kernel versionI0807 14:47:10.658484 10612 kernel_validator.go:96] Validating kernel config[preflight/images] Pulling images required for setting up a Kubernetes cluster[preflight/images] This might take a minute or two, depending on the speed of your internet connection[preflight/images] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;[kubelet] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;[kubelet] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;[preflight] Activating the kubelet service[certificates] Generated ca certificate and key.[certificates] Generated apiserver certificate and key.[certificates] apiserver serving cert is signed for DNS names [master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.31.49][certificates] Generated apiserver-kubelet-client certificate and key.[certificates] Generated sa key and public key.[certificates] Generated front-proxy-ca certificate and key.[certificates] Generated front-proxy-client certificate and key.[certificates] Generated etcd/ca certificate and key.[certificates] Generated etcd/server certificate and key.[certificates] etcd/server serving cert is signed for DNS names [master localhost] and IPs [127.0.0.1 ::1][certificates] Generated etcd/peer certificate and key.[certificates] etcd/peer serving cert is signed for DNS names [master localhost] and IPs [192.168.31.49 127.0.0.1 ::1][certificates] Generated etcd/healthcheck-client certificate and key.[certificates] Generated apiserver-etcd-client certificate and key.[certificates] valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/admin.conf&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/kubelet.conf&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/controller-manager.conf&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/scheduler.conf&quot;[controlplane] wrote Static Pod manifest for component kube-apiserver to &quot;/etc/kubernetes/manifests/kube-apiserver.yaml&quot;[controlplane] wrote Static Pod manifest for component kube-controller-manager to &quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&quot;[controlplane] wrote Static Pod manifest for component kube-scheduler to &quot;/etc/kubernetes/manifests/kube-scheduler.yaml&quot;[etcd] Wrote Static Pod manifest for a local etcd instance to &quot;/etc/kubernetes/manifests/etcd.yaml&quot;[init] waiting for the kubelet to boot up the control plane as Static Pods from directory &quot;/etc/kubernetes/manifests&quot; [init] this might take a minute or longer if the control plane images have to be pulled[apiclient] All control plane components are healthy after 42.001662 seconds[uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace[kubelet] Creating a ConfigMap &quot;kubelet-config-1.11&quot; in namespace kube-system with the configuration for the kubelets in the cluster[markmaster] Marking the node master as master by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;[markmaster] Marking the node master as master by adding the taints [node-role.kubernetes.io/master:NoSchedule][patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;master&quot; as an annotation[bootstraptoken] using token: uzdl9x.91uu2p155jczkgb3[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes master has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/You can now join any number of machines by running the following on each nodeas root: kubeadm join 192.168.31.49:6443 --token uzdl9x.91uu2p155jczkgb3 --discovery-token-ca-cert-hash sha256:bc5af0f4fbee0d0500c9d6782a279ee172ed45547a006136bfbad93d61ad39c7#root用户#一定要记得做此步骤，由于kubeadm设置的apiserver的监听端口为6443，而不是8080，所以执行会报错。export KUBECONFIG=/etc/kubernetes/admin.conf#之后，可将其写入/etc/profile#安装pod-network#你必须先安装pod network add-on，才能和pod相互通信。#必须在应用程序之前部署网络。#配置flannelkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.10.0/Documentation/kube-flannel.yml#如果无法访问，可将此文件下载到本地#kubectl apply -f /etc/kubernetes/kube-flannel.ymlclusterrole.rbac.authorization.k8s.io/flannel createdclusterrolebinding.rbac.authorization.k8s.io/flannel createdserviceaccount/flannel createdconfigmap/kube-flannel-cfg createddaemonset.extensions/kube-flannel-ds created#token用于master与node之间相互认证，它是加密的。#使用kubeadm token列出、创建和删除token#kubeadm token create#kubeadm token list#on node#kubeadm join#kubeadm join --token xxxxxxxxxxx host:portsystemctl enable kubelet docker &amp;&amp; systemctl start dockerkubeadm join 192.168.31.49:6443 --token uzdl9x.91uu2p155jczkgb3 --discovery-token-ca-cert-hash sha256:bc5af0f4fbee0d0500c9d6782a279ee172ed45547a006136bfbad93d61ad39c7#测试kubectl get nodeNAME STATUS ROLES AGE VERSIONmaster Ready master 48m v1.11.1node Ready &lt;none&gt; 15m v1.11.1#查看kubectl get pods --all-namespaces -o wideNAMESPACE NAME READY STATUS RESTARTS AGE IP NODEkube-system coredns-78fcdf6894-hn46d 1/1 Running 0 52m 10.244.0.3 masterkube-system coredns-78fcdf6894-wqxbx 1/1 Running 0 52m 10.244.0.2 masterkube-system etcd-master 1/1 Running 0 41m 192.168.31.49 masterkube-system kube-apiserver-master 1/1 Running 0 41m 192.168.31.49 masterkube-system kube-controller-manager-master 1/1 Running 0 41m 192.168.31.49 masterkube-system kube-flannel-ds-7gbvd 1/1 Running 0 41m 192.168.31.49 masterkube-system kube-flannel-ds-ktkxp 1/1 Running 0 19m 192.168.31.174 nodekube-system kube-proxy-pw7gz 1/1 Running 0 19m 192.168.31.174 nodekube-system kube-proxy-rhrks 1/1 Running 0 52m 192.168.31.49 masterkube-system kube-scheduler-master 1/1 Running 0 41m 192.168.31.49 master master isolation默认情况下，出于安全原因，你的集群不会在master上调度pod。如果你想在master上调度pod，对于单master的k8s集群，执行如下命令： 12#从拥有它的节点删除node-role.kubernetes.io/master污染kubectl taint nodes --all node-role.kubernetes.io/master- 加入节点要向集群添加新节点，请为每台计算机执行以下操作： 1234567#node#root/sudo#kubeadm init后执行下命令#kubeadm token listkubeadm join --token &lt;token&gt; &lt;master-ip&gt;:&lt;master-port&gt; --discovery-token-ca-cert-hash sha256:&lt;hash&gt; 从master之外控制集群(可选) 12scp root@&lt;master-ip&gt;:/etc/kubernetes/admin.conf .kubeclt --kubeconfig ./admin.conf get nodes 局限性此处创建的集群只有一个master，其上运行一个etcd数据库。这意味着如果master出现故障，你的集群可能会丢失数据。可考虑向k8s添加高可用支持。 使用kubeadm配置kubeletConfiguring each kubelet in your cluster using kubeadm kubeadm CLI工具的生命周期与Kubernetes Node Agent(kubelet)相分离，kubelet是运行在k8s集群master/node上的守护进程，它始终在后台运行。而kubeadm CLI工具由用户执行。由于kubelet是一个守护进程，它需要由init system或服务管理器来维护。Redhat7上使用systemd来进行管理。在集群设计的kubelet中，一些kubelet配置细节需相同；而其它方面则需要在每台机器的kubelet上单独配置。你可以手动管理kubelet配置，但kubeadm现在提供了一个MaterConfig API来集中管理kubelet配置。 注意，本节是利用kubeadm来配置kubelet，而不是手动配置kubelet。 kubelet配置模式 将集群级别配置传播到每个kubeletkubelet提供了一个版本化、结构化的API对象，可配置kubelet中大多数参数，并将此配置推送到集群中所有正在运行的kubelet。它被称为 the kubelet’s ComponentConfig(组件配置) 12345678910111213141516171819#为kubelet提供默认值。kubeadm initkubeadm join#修改服务默认子网kubeadm init --service-cidr 10.96.0.0/12#现在服务的VIP由此子网分配#还需要设置kubelet使用的DNS地址，每个kubelet必须相同--cluster-dns#componentConfigapiVersion: kubelet.config.k8s.io/v1beta1kind: KubeletConfigurationclusterDNS: - 10.96.0.10 提供特定实例的配置细节由于不同硬件、操作系统、网络…，一些主机需要特定的kubelet配置。由于我是使用systemd管理kubelet，所以可相应的修改对应的值。 1234567891011121314151617181920212223242526272829303132#DNS解析文件路径，如果路径错误，则在kubelet配置错误的节点上DNS将解析失败--resolve-conf#节点API对象，默认被设置为主机名.metadata.name#使用如下标志指定节点名来服务默认值--hostname-overide#目前，kubelet无法自动检查CRI runtime的cgroup driver#指定的驱动请与docker保持一致--cgroup-driver#根据集群使用的CRI runtime，可能需要为kubelet指定不同的标志#如，当使用Docker时，你需要指定如 --network-plugin=cni#但，当使用额外runtime，你需要指定 --container-runtime=remote, --container-runtime-path-endpoint=&lt;path&gt;#systemdcd /etc/systemd/system/kubelet.service.d/vim 10-kubeadm.conf#修改具体配置项#EnvFilevim /var/lib/kubelet/kubeadm-flags.envsystemctl daemon-reload &amp;&amp; systemctl restart kubelet 使用kubeadm配置kubeletkubeadm config API的MasterConfiguration类型，嵌入了kubelet&#39;s ComponentConfig到.kubeletConfiguration.baseConfig键下面。任何用户都可编写MasterConfiguration文件使用此配置键为集群中的所有kubelet设置基本配置。 使用kubeadm init的工作流程(workflow)当调用kubeadm init时，.kubeletConfiguration.baseConfig结构被整理到磁盘/var/lib/kubelet/config.yaml，并且上传到集群中的ConfigMap。ConfigMap名为kubelet-config-1.x，.x表示k8s的次要版本。kubelet配置文件同样被写入/etc/kubernetes/kubelet.conf。此配置文件指向允许kubelet与API server通信的客户端证书。 为了解决特定实例的配置细节的模式，kubeadm将环境文件写入/var/lib/kubelet/kubeadm-flags.env，它包含了在启动时传递给kubelet的许多标志。它还包含许多动态参数(如cgroup driver)。 12345678#标志栗子KUBELET_KUBEADM_ARGS=&quot;--flag1=value1, --flag2=value2 ...&quot;#在将这两个文件整理到磁盘后，kubeadm会尝试运行如下两个命令systemctl daemon-reload &amp;&amp; systemctl restart kubelet#在上面两个命令执行成功后，初始化会继续 使用kubeadm join的工作流程当运行kubeadm join命令时，kubeadm使用Bootstrap Token凭据执行TLS bootstrap，它下载kubelet-config-1.x ConfigMap并将其写入/var/lib/kubelet/config.yaml。动态环境文件/vat/lib/kubelet/kubeadm-flags.env的生成方式与kubeadm init完成相同。 12#同样，执行这两条命令systemctl daemon-reload &amp;&amp; systemctl restart kubelet 在kubelet载入新的配置文件后，kubeadm会写入/etc/kubernetes/bootstrap-kubelet.conf KubeConfig文件，该文件包含CA证书和Bootstrap Token。这些由kubelet用于执行TLS Bootstrap并获得唯一的凭证，该凭证存储在/etc/kubernetes/kubelet.conf中。写入文件后，kubelet完成执行TLS Bootstrap. systemd的kubelet管理文件此配置文件在RPM包安装的时候写入/etc/systemd/system/kubelet.service.d/10-kubeadm.conf，它由systemd使用。 123456789101112131415161718192021222324252627282930313233cat /etc/systemd/system/kubelet.service.d/10-kubeadm.conf# Note: This dropin only works with kubeadm and kubelet v1.11+[Service]Environment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf&quot;Environment=&quot;KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml&quot;# This is a file that &quot;kubeadm init&quot; and &quot;kubeadm join&quot; generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamicallyEnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env# This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use# the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file.EnvironmentFile=-/etc/sysconfig/kubeletExecStart=ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS#此文件指定kubeadm为kubelet管理的所有文件的默认位置#TLS Bootstrap/etc/kubernetes/bootstrap-kubelet.conf#unique kubelet identity/etc/kubernetes/kubelet.conf#kubelet&apos;s ComponentConfig/var/lib/kubelet/config.yaml#dynamic env file, KUBELET_KUBEADM_ARGS/var/lib/kubelt/kubeadm-flags.env#user-specified flag overrides, KUBELET_EXTRA_ARGS, 它具有最高优先级/etc/sysconfig/kubelet k8s 二进制文件和包内容 k8s release附带的DEB和RPM包： Package name Description kubeadm Installs the /usr/bin/kubeadm CLI tool and [The kubelet drop-in file(#the-kubelet-drop-in-file-for-systemd) for the kubelet. kubelet Installs the /usr/bin/kubelet binary. kubectl Installs the /usr/bin/kubectl binary. kubernetes-cni Installs the official CNI binaries into the /opt/cni/bin directory. cri-tools Installs the /usr/bin/crictl binary from https://github.com/kubernetes-incubator/cri-tools. 使用kubeadm自定义控制面板配置Customizing control plane configuration with kubeadm kubeadm配置公开以下字段，这些字段可覆盖传递给控制面板组件的默认标志： APIServerExtraArgs ControllerManagerExtraArgs SchedulerExtraArgs 1234567891011121314151617181920212223242526272829303132333435363738#apiserver#栗子apiVersion: kubeadm.k8s.io/v1alpha2kind: MasterConfigurationkubernetesVersion: v1.11.0metadata: name: 1.11-sampleapiServerExtraArgs: advertise-address: 192.168.0.103 anonymous-auth: false enable-admission-plugins: AlwaysPullImages,DefaultStorageClass audit-log-path: /home/johndoe/audit.log#controllermanager#栗子apiVersion: kubeadm.k8s.io/v1alpha2kind: MasterConfigurationkubernetesVersion: v1.11.0metadata: name: 1.11-samplecontrollerManagerExtraArgs: cluster-signing-key-file: /home/johndoe/keys/ca.key bind-address: 0.0.0.0 deployment-controller-sync-period: 50#scheduler#栗子apiVersion: kubeadm.k8s.io/v1alpha2kind: MasterConfigurationkubernetesVersion: v1.11.0metadata: name: 1.11-sampleschedulerExtraArgs: address: 0.0.0.0 config: /home/johndoe/schedconfig.yaml kubeconfig: /home/johndoe/kubeconfig.yaml 使用kubeadm创建高可用集群Creating Highly Available Clusters with kubeadm 使用kubeadm配置etcd高可用集群Set up a Highly Availabile etcd Cluster With kubeadm Troubleshooting kubeadm官方Troubleshooting: https://kubernetes.io/docs/setup/independent/troubleshooting-kubeadm/ 此外，在我启动kubelet之后，kubelet频繁出现一个错误信息： 12345678910111213141516#错误信息#journal -u kubeletkubelet[10720]: E0810 14:32:14.748713 10720 summary.go:102] Failed to get system container stats for &quot;/system.slice/kubelet.service&quot;: failed to get cgroup stats for &quot;/system.slice/kubelet.service&quot;: failed to get container info for &quot;/system.slice/kubelet.service&quot;: unknown container &quot;/system.slice/kubelet.service&quot;#解决方法vim /etc/sysconfig/kubelet#添加额外参数KUBELET_EXTRA_ARGS=&quot;--runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice&quot;#重启服务systemctl restart kubelet 使用软件包创建集群请定义相应的防火墙规则！ 我是CentOS7x86_64，所以只包含了RPM包。 自带的源安装的k8s可能版本比较老，如需较新版本，可以在网上搜索kubernetes rpm包进行手动安装。Rpmfind: https://rpmfind.net/ k8s集群组件 etcd flannel kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy kube-dns kubectl Master etcd flannel kube-apiserver kube-controller-manager kube-scheduler kubectl 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#默认镜像源安装yum install -y etcd flannel kubernetes-master kubernetes-client#配置kubernetes-master#cd /etc/kubernetes#apiserver config controller-manager scheduler#修改监听地址vim apiserverKUBE_API_ADDRESS="--insecure-bind-address=0.0.0.0"#生成环境一定要加上认证，我由于是测试，并未做认证#未添加认证，去掉 KUBE_ADMISSION_CONTROL中的SecurityContextDeny,ServiceAccount#Flag --admission-control has been deprecated, Use --enable-admission-plugins or --disable-admission-plugins instead.#KUBE_ADMISSION_CONTROL="--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota"KUBE_ADMISSION_CONTROL="--enable-admission-plugins=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota"#此处我修改了cidrKUBE_SERVICE_ADDRESSES="--service-cluster-ip-range=172.16.0.0/16"#配置etcd，可先使用默认值#后面可创建etcd-clustervim /etc/etcd/etcd.conf#修改监听地址ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:2379"#创建pod-network，cidr为kube-apiserver中的配置项#/atomic.io/network为flannel_etcd前缀,之后再启动flanneletcdctl mk /atomic.io/network/config '&#123;"Network":"172.16.0.0/16"&#125;'etcdctl lsetcdctl get '/atomic.io/network/config'#配置flannelvim /etc/sysconfig/flanneld#配置后启动systemctl start etcd flannel kube-apiserver kube-controller-manager kube-scheduler#查看[root@master kubernetes]# kubectl get allNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 172.16.0.1 &lt;none&gt; 443/TCP 4m#具体参数请根据实际情况来配置 Node flannel kubelet kube-porxy kubectl 123456789101112131415161718192021222324252627#epelyum install -y flannel kubernetes-node kubernetes-client#ls /etc/kubertes#config kubelet proxy#配置etcd的地址vim /etc/sysconfig/flanneldFLANNEL_ETCD_ENDPOINTS="http://master:2379vim /etc/kubernertes/configKUBE_MASTER="--master=http://master:8080"#修改kubelet地址KUBELET_ADDRESS="--address=node_addr"KUBELET_HOSTNAME="--hostname-override=node_addr"KUBELET_API_SERVER="--api-servers=http://master:8080"#配置后启动systemctl start flanneld kube-proxy kubelet#具体参数请根据实际情况来配置 验证集群 123#Master#kubectl安装如前kubectl get nodes 安装较新的k8s由于自带的源k8s版本比较低，可能我们需要较新的k8s版本。 12345678910111213141516171819202122#安装较新的Kubernetes浏览器访问 https://rpmfind.net/搜索：kubernetes-master(x86-64)kubernetes-node(x86-64)kubernetes-client(x86-64)选择合适的版本进行下载，三者版本请一致安装步骤和下面类似请注意，k8s组件安装好后，还需要安装额外组件。如docker, flannel, etcd...#masteryum install -y k8s-master k8s-client#nodeyum install -y k8s-node k8s-client k8s-release生成rpm包kubernetes-release: https://github.com/kubernetes/release 使用k8s-release手动生成rpm/dep包。由于yum源更不上k8s的更新速度，所以才需要我们手动制作。 需要安装并运行Docker，它要运行一个rpm-builder容器。 它生成一下rpm包： kubeadm kubelet kubectl 官方说明： 12345678910111213141516171819202122232425262728293031323334353637git clone https://github.com/kubernetes/release.gitcd ./release/rpm./docker-build.sh#此处如果连接google下载超时的话，可以在其它主机上下载，然后复制到此目录下#成功----------------------------------------RPMs written to:cri-tools-1.11.0-0.x86_64.rpm kubectl-1.11.0-0.x86_64.rpm kubernetes-cni-0.6.0-0.x86_64.rpmkubeadm-1.11.0-0.x86_64.rpm kubelet-1.11.0-0.x86_64.rpm repodataYum repodata written to:5e470d3c1c28cdd798237a48172b46f753655edee30988f4fde7000fde859d5a-primary.xml.gz9497c84e5650b15bf6edcffb68900b4f59f7271fa6318d3c0336386c99afd2d8-other.xml.gz94da9da6abd2dc8364ef51b4ca135b804deef0a37f1f13e4abeee455a8b0e897-primary.sqlite.bz2971e5af9d861f5ba85b12bad481749aa26546051090fa4e21c2393c21590dd5a-filelists.xml.gzb752df67070ff5552bd3137f00fb217578f1d810084a3e42579a53eee2a26085-other.sqlite.bz2f0ec7692c0654c1ec5ad9c8576ebe5b8f135c45b5d5242066df6e2d631a3ef6f-filelists.sqlite.bz2repomd.xml#会在./release/rpm/output/x86_64下生成特定版本的rpm包pwd#/root/release/rpm/output/x86_64ls -ltotal 47056-rw-r--r-- 1 root root 4383318 Aug 3 10:25 cri-tools-1.11.0-0.x86_64.rpm-rw-r--r-- 1 root root 7906382 Aug 3 10:25 kubeadm-1.11.0-0.x86_64.rpm-rw-r--r-- 1 root root 7859238 Aug 3 10:25 kubectl-1.11.0-0.x86_64.rpm-rw-r--r-- 1 root root 19012182 Aug 3 10:25 kubelet-1.11.0-0.x86_64.rpm-rw-r--r-- 1 root root 9008530 Aug 3 10:25 kubernetes-cni-0.6.0-0.x86_64.rpmdrwxr-xr-x 2 root root 4096 Aug 3 10:25 repodata 请注意，默认会自动编译所有平台。如果只需要x84_64，可以更改entry.sh文件，将其它平台去掉，以加快编译速度。 123456789vim ./release/rpm/entry.sh ARCHS=( amd64/x86_64 #arm/armhfp #arm64/aarch64 #ppc64le/ppc64le #s390x/s390x ) 后面还是需要使用kubeadm来进行引导！ 编译源码生成rpm包参考： How to build Kubernetes RPM: https://mritd.me/2017/07/12/how-to-build-kubernetes-rpm/ 由于墙的原因，使用kubeadm进行引导还是会timeout。使用自带的yum源或网上下载的k8s rpm可能也不是最新的版本。因此需要手动编译源码以生成rpm包。 生成如下rpm包： kubernetes-master kubernetes-client kubernetes-node k8s Dashboard说明: GitHub: https://github.com/kubernetes/dashboard image: kubernetes-dashboard-amd64:v1.8.3 FAQ: https://github.com/kubernetes/dashboard/wiki/FAQ Let’s Encrypt: https://letsencrypt.org/ Let’s Encrypt是一个免费，自动化和开放的证书颁发机构。 快速配置Quick setup 快速部署kubernetes-dashboard的方法请参考README。它适用于k8s新手并希望快速开始使用Dashboard的人。其它配置适用于有一定经验的用户，详情在以下章节。 k8s Dashboard是k8s集群的基于Web的通用UI。它允许用户管理运行在集群中的应用程序，并对应用程序进行故障排除，以及管理集群本身。 请注意，Dashboard使用了安全设置。这意味着，默认情况下它具有最小的权限集，并且只能通过https访问。建议在安装和执行Dashboard之前，先阅读Access Control指南。 1234567891011121314151617181920212223242526272829303132333435363738kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml#或#wget https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml#kubectl apply -f /path/kubernetes-dashboard.yamlsecret/kubernetes-dashboard-certs createdserviceaccount/kubernetes-dashboard createdrole.rbac.authorization.k8s.io/kubernetes-dashboard-minimal createdrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard-minimal createddeployment.apps/kubernetes-dashboard createdservice/kubernetes-dashboard created#查看kubectl get pods -n kube-system -o wide |grep dashboardkubernetes-dashboard-6948bdb78-rnnjp 1/1 Running 1 1d 10.244.1.2 node kubectl get service -n kube-system -o wide |grep dashboardkubernetes-dashboard ClusterIP 10.110.83.129 &lt;none&gt; 443/TCP 13m k8s-app=kubernetes-dashboard#要从本地访问Dashboard，必须为k8s集群创建安全通道kubectl applyStarting to serve on 127.0.0.1:8001#访问Dashboardhttp://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#http://localhost:8001/ui已弃用#&lt;h3&gt;Unauthorized&lt;/h3&gt;#会直接报403，还需要做前面所说的操作。#Heapster必须在集群中运行才能使metric, graphs可用#Heapster已被弃用，请考虑使用metrics-server和第三方metrics pipeline收集Prometheus格式的指标 安装Installation 官方版当从旧版Dashboard升级到 v1.7+，请确保删除kubernetes-dashboard服务账户的集群角色绑定，否则Dashboard将具有对集群的完全管理权限。 快速配置快速部署kubernetes-dashboard的方法请参考README。它适用于k8s新手并希望快速开始使用Dashboard的人。 推荐配置直接访问Dashboard(不是kubectl proxy)，应该使用有效的证书来建立安全的HTTPS连接。它们可由公共可信证书颁发机构(如Let’s Encrypt)生成，使用它们替代Dashboard自动生成的证书。 此配置要求证书存储在kube-system命名空间中名为kubernetes-dashboard-certs的证书中。假设你有存储在$HOME/certs目录下的dashboard.crt和dashboard.key文件。你应该使用这些文件创建secret。之后，便可以开始配置Dashboard。 123456789101112131415161718192021#查看kubectl get secret -n kube-system | grep dashboard#查看kubectl describe secret/kubernetes-dashboard-certs -n kube-systemName: kubernetes-dashboard-certsNamespace: kube-systemLabels: k8s-app=kubernetes-dashboardAnnotations:Type: OpaqueData====#创建kubectl create secret generic kubernetes-dashboard-certs --from-file=$HOME/certs -n kube-system#部署Dashboardkubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml 替代配置此配置并不安全。不使用证书，仅通过HTTP公开Dashboard。在此配置中，只能通过使用Authorization Header功能来确保访问控制。 12#配置kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/alternative/kubernetes-dashboard.yaml 开发版不建议在线上环境使用开发版，请使用稳定的正式版。 12#部署kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard-head.yaml 升级安装后，Deployment不会自动更新。为了更新它，你需要删除部署的pod并等待它重新创建。重新创建之后，它会使用最新的镜像image:latest. 12#删除podkubectl -n kube-system delete $(kubectl -n kube-system get pod -o name | grep dashboard) 证书管理Certificate management 本节简短介绍了如何获取可在Dashboard中启用HTTPS的证书。有两个步骤要做： 生成证书 证书认证机构(Certificate Authority) 自签名证书(Self-signed certificate) 将证书传递给Dashboard 按照前面的推荐配置方法 其它情况，你需要修改Dashboard的YAML部署文件，并将--tls-key-file, --tls-cert-file传递给Dashboard 公众信任的证书认证机构Public trusted Certificate Authority 有许多公共和免费的证书提供商可供选择。如前面提到的Let’s encrypt，具体操作查看此网站说明。 自签名证书Self-signed certificate 如果你打算自己生成证书，你需要像OpenSSL这样的库来帮助你。 生成私钥(private key)和证书签名请求(certificate signing request) 生成SSL证书 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#Generate private key and certificate signing request#创建SSL证书需要私钥和证书签名请求openssl genrsa -des3 -passout pass:x -out dashboard.pass.key 2048openssl rsa -passin pass:x -in dashboard.pass.key -out dashboard.keyrm dashboard.pass.key#需要填写一些信息#A challenge password []请直接按回车，不要填写内容openssl req -new -key dashboard.key -out dashboard.csrCountry Name (2 letter code) [XX]:CNState or Province Name (full name) []:SCLocality Name (eg, city) [Default City]:CDOrganization Name (eg, company) [Default Company Ltd]:StudentOrganizational Unit Name (eg, section) []:HTCommon Name (eg, your name or your server&apos;s hostname) []:Zhang21Email Address []:reds@zhang21.cnPlease enter the following &apos;extra&apos; attributesto be sent with your certificate requestA challenge password []:An optional company name []:#Generate SSL certificate#自签名SSL证书由 .key私钥 和 .csr生成openssl x509 -req -sha256 -days 1000 -in dashboard.csr -signkey dashboard.key -out dashboard.crtSignature oksubject=/C=CN/ST=SC/L=CD/O=Student/OU=HT/CN=Zhang21/emailAddress=reds@zhang21.cnGetting Private key#查看lsdashboard.crt dashboard.csr dashboard.key#将密钥和证书移动到需要的目录下mv ./dashboard.* /etc/kubernetes/pki/dashboard#接下来便可以创建secret了 访问DashboardAccessing Dashboard 在集群上安装Dashboard后，可通过几种不同的方式访问它。遇到什么问题，可查看FAQ。 1.6.x and below 1.7.x and above 1.7.x and aboveAccessing Dashboard 1.7.X and above 我的Dashboard v1.8.5. 前面的HTTP/HTTPs都不说了。但请注意，不要把Dashboard使用HTTP公开展示。 kubectl proxykubectl proxy在你的计算机和k8s APIserver之间创建代理服务器。默认情况下它只能在本地访问。 注意，不应该使用kubectl proxy命令公开Dashboard，因为它只允许HTTP连接。对于localhost和127.0.0.1以外的域，将无法登录。 首先让我们检查kubectl是否已正确配置并是否可访问集群: 123456789101112131415kubectl cluster-info#Kubernetes master is running at https://192.168.31.49:6443#KubeDNS is running at https://192.168.31.49:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy#启动代理服务器kubectl proxy#Starting to serve on 127.0.0.1:8001#之后你便可以从浏览器访问Dashboard#http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#但我访问还是403，应该还需要创建Service Token之类。 NodePort这种访问Dashboard的方式，建议用于单节点设置的开发环境中。请注意，此HTTPS方式需要安装前面生成的证书。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#编辑 kubernetes-dashboard服务kubectl -n kube-system edit service/kubernetes-dashboard# Please edit the object below. Lines beginning with a '#' will be ignored,# and an empty file will abort the edit. If an error occurs while saving this file will be# reopened with the relevant failures.#apiVersion: v1kind: Servicemetadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"v1","kind":"Service","metadata":&#123;"annotations":&#123;&#125;,"labels":&#123;"k8s-app":"kubernetes-dashboard"&#125;,"name":"kubernetes-dashboard","namespace":"kube-system"&#125;,"spec":&#123;"ports":[&#123;"port":443,"targetPort":8443&#125;],"selector":&#123;"k8s-app":"kubernetes-dashboard"&#125;&#125;&#125; creationTimestamp: 2018-08-09T01:14:01Z labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kube-system resourceVersion: "200618" selfLink: /api/v1/namespaces/kube-system/services/kubernetes-dashboard uid: 80091845-9b71-11e8-a08a-000c298ee39fspec: clusterIP: 10.110.83.129 ports: - port: 443 protocol: TCP targetPort: 8443 selector: k8s-app: kubernetes-dashboard sessionAffinity: None type: ClusterIPstatus: loadBalancer: &#123;&#125;#将 type: ClusterIP 修改为 type: NodePorttype: NodePort#直接保存退出(:wq)#service/kubernetes-dashboard edited#查看kubectl -n kube-system get service/kubernetes-dashboardNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes-dashboard NodePort 10.110.83.129 &lt;none&gt; 443:31965/TCP 6h#查看端口netstat -nltup | grep 31965tcp6 0 0 :::31965 :::* LISTEN 11280/kube-proxy#Dashboard展示在 31965(HTTPS) 端口上。#现在可在浏览器访问 &lt;master-ip&gt;:31965#可使用Nginx做前端代理#此处注意，需要将dashboard.crt证书安装到你的电脑上#不然浏览器会拒绝#如果你尝试在多节点集群上使用`NodePort`公开Dashboard，则必须找到运行Dashboard的节点的IP才能访问它。https://&lt;node-ip&gt;:&lt;nodeport&gt; 由图可看出，还需要配置权限才能够正常访问Dashboard！ API Server如果公开k8s API server并可以从外部访问，则你可直接访问url。Dashboard: https://master-ip:apiserver-port/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/ 注意，只有在浏览器中安装证书时，才能使用这用访问方式。 IngressDashboard可以使用 ingress 进行公开。详情: https://kubernetes.io/docs/concepts/services-networking/ingress/ Nginx反向代理直接使用NodePort方式访问比较麻烦，所以配置使用Nginx反向代理来访问。 Nginx配置文件: 1234567891011121314151617181920212223242526272829303132333435vim /etc/nginx/conf.d/k8sUI.confserver &#123; listen 443 ssl; server_name k8s.ui; ssl_certificate /etc/kubernetes/pki/dashboard/dashboard.crt; ssl_certificate_key /etc/kubernetes/pki/dashboard/dashboard.key; location / &#123; proxy_pass https://127.0.0.1:31965; proxy_read_timeout 60s; proxy_send_timeout 60s; proxy_connect_timeout 60s; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_404; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &apos;upgrade&apos;; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto https; proxy_buffer_size 64k; proxy_buffers 4 64k; proxy_busy_buffers_size 128k; proxy_temp_file_write_size 128k; &#125;&#125;nginx -tnginx -s reload 之后解析DNS，就可直接通过域名访问了。 访问控制Access Control 安装Dashboard后，我们便可以专注于为用户配置对集群资源的访问控制。从 v1.7 开始，Dashboard默认不再具有完全管理权限(admin privilige)，所有权限都被撤销，并且只授予了Dashboard工作所需的最小权限。所以下面的介绍都只针对于 v1.7+ 版本。如果Dashboard只能由受信任的人员访问，你可能希望授予他们完全管理权限，则所有人都具有完全管理的权限。请注意，其它应用程序不应直接访问Dashboard，因为它可能导致权限升级。确保集群内的流量仅限于命名空间，或者只是撤销集群内应用程序对Dashboard的访问权限。 可查看kubernetst-dashboard.yaml配置文件，里面有minimal的权限。 介绍k8s支持几种方法来认证(authenticating)和授权(authorizing)用户。授权由k8s API server处理。Dashboard仅充当代理并将所有认证信息传递给API server。在禁止访问的情况下，相应的警告信息会显示到Dashboard上。 默认Dashboard权限 v1.7 create and watch permissions for secrets in kube-system namespace required to create and watch for changes of kubernetes-dashboard-key-holder secret. get, update and delete permissions for secrets named kubernetes-dashboard-key-holder and kubernetes-dashboard-certs in kube-system namespace. proxy permission to heapster service in kube-system namespace required to allow getting metrics from heapster. v1.8 create permission for secrets in kube-system namespace required to create kubernetes-dashboard-key-holder secret. get, update and delete permissions for secrets named kubernetes-dashboard-key-holder and kubernetes-dashboard-certs in kube-system namespace. get and update permissions for config map named kubernetes-dashboard-settings in kube-system namespace. proxy permission to heapster service in kube-system namespace required to allow getting metrics from heapster. Authentication从v1.7版本开始，Dashboard支持的用户认证基于： Authorization: Bearer &lt;token&gt; Bearer Token Username/password Kubeconfig Login view要使其显示在Dashboard中，你需要启用HTTPS访问Dashboard。 使用跳过选项将使Dashboard使用Service Account权限。 Authorization header在通过HTTP访问Dashboard时，使用 authorization header 是使Dashboard充当用户的唯一方法。 要使Dashboard使用authorization header，你只需将每个请求中的Authorization: Bearer &lt;token&gt;传递给Dashboard。这可以通过在Dashboard前端配置反向代理来实现。代理将负责身份提供者的身份验证，并将请求头部中生成的token传递给Dashboard。注意，需要正确配置k8s API server才能接受这些token。 注意： 如果通过API server proxy访问Dashboard，则authorization header将不起作用。这是因为一旦请求到达API server，所有其它header都将被删除。 Bearer Token建议先熟悉k8s authentication doc，以了解如何获取可用于登录的token。例如，每个Service Account都有一个具有有效Bearer token，用于登录Dashboard。 推荐讲座，了解如何创建服务账户并对其进行授权： Service Account Tokens Role and ClusterRole Service Account Permissions 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#使用kubectl获取token#默认情况下，k8s创建了许多服务账号。所有都具有不同的访问权限kubectl -n kube-system get secretNAME TYPE DATA AGEattachdetach-controller-token-bszq5 kubernetes.io/service-account-token 3 2dbootstrap-signer-token-bqv44 kubernetes.io/service-account-token 3 2dbootstrap-token-uzdl9x bootstrap.kubernetes.io/token 7 2dcertificate-controller-token-rsftn kubernetes.io/service-account-token 3 2dclusterrole-aggregation-controller-token-x64f5 kubernetes.io/service-account-token 3 2dcoredns-token-dfmpb kubernetes.io/service-account-token 3 2dcronjob-controller-token-xwtkc kubernetes.io/service-account-token 3 2ddaemon-set-controller-token-vxzp4 kubernetes.io/service-account-token 3 2ddefault-token-5868t kubernetes.io/service-account-token 3 2ddeployment-controller-token-jc6bs kubernetes.io/service-account-token 3 2ddisruption-controller-token-znghk kubernetes.io/service-account-token 3 2dendpoint-controller-token-mnxfh kubernetes.io/service-account-token 3 2dexpand-controller-token-6srzj kubernetes.io/service-account-token 3 2dflannel-token-7548k kubernetes.io/service-account-token 3 2dgeneric-garbage-collector-token-22qd2 kubernetes.io/service-account-token 3 2dhorizontal-pod-autoscaler-token-zs8pj kubernetes.io/service-account-token 3 2djob-controller-token-zbfhd kubernetes.io/service-account-token 3 2dkube-proxy-token-xxp9h kubernetes.io/service-account-token 3 2dkubernetes-dashboard-certs Opaque 3 1hkubernetes-dashboard-key-holder Opaque 2 2dkubernetes-dashboard-token-sgq5t kubernetes.io/service-account-token 3 2dnamespace-controller-token-25n2k kubernetes.io/service-account-token 3 2dnode-controller-token-289v8 kubernetes.io/service-account-token 3 2dpersistent-volume-binder-token-x7t7x kubernetes.io/service-account-token 3 2dpod-garbage-collector-token-xxjqp kubernetes.io/service-account-token 3 2dpv-protection-controller-token-9s4x7 kubernetes.io/service-account-token 3 2dpvc-protection-controller-token-l7m7j kubernetes.io/service-account-token 3 2dreplicaset-controller-token-mszv9 kubernetes.io/service-account-token 3 2dreplication-controller-token-8gl9s kubernetes.io/service-account-token 3 2dresourcequota-controller-token-whljw kubernetes.io/service-account-token 3 2dservice-account-controller-token-h87wp kubernetes.io/service-account-token 3 2dservice-controller-token-qn5jz kubernetes.io/service-account-token 3 2dstatefulset-controller-token-zps2l kubernetes.io/service-account-token 3 2dtoken-cleaner-token-nccrw kubernetes.io/service-account-token 3 2dttl-controller-token-dmmb9 kubernetes.io/service-account-token 3 2dkubectl -n kube-system describe secret/replicaset-controller-token-mszv9Name: replicaset-controller-token-mszv9Namespace: kube-systemLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name=replicaset-controller kubernetes.io/service-account.uid=d18a5f8f-9a0d-11e8-a08a-000c298ee39fType: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 11 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJyZXBsaWNhc2V0LWNvbnRyb2xsZXItdG9rZW4tbXN6djkiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoicmVwbGljYXNldC1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZDE4YTVmOGYtOWEwZC0xMWU4LWEwOGEtMDAwYzI5OGVlMzlmIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOnJlcGxpY2FzZXQtY29udHJvbGxlciJ9.O6hXQwsXdSXREsaao_V7pmeQkfWGEd4QLDxczxNZVcrT2yN9F1KFJ9IklYVlGSTo1cKA4OxkYqjKWzWPBEn6wVLhVbf6_WqTrFi4qEtj_nmhXwqcwkpioJzyXu7x7wljpH-H32bEaLW1l-y5kQBUztF9fAHZZyv0f9vaRK4u4zVzuq4JzauLB9aVBrgt6rSaOENdr8OGm1yjM_--gQtc1qoF8mLo3RK6qLpFjT70EZKgyys_GXpFrrnhG5maUmlFqCPZ6P0cl8d6SuDfkQIlFxNHxtJmOPSCIE6wjgkOncRtgWHRRVsRPnhDGOp0kbmdLTfpOx2zZEiCD5btXL0OkA#我们可以使用显示的token登录Dashboard Basic默认情况下，禁用基本身份认证，也就是用户密码认证。原因是需要使用授权模式RBAC和--basic-auth-file标志配置k8s API server。没有的话，API server会自动回退到匿名用户(anonymous user)，并且无法检查提供的凭据是否有效。 修改--authentication-mode=basic标志在Dashboard中启用基本身份认证，默认值为--authentication-mode=token。 kubeconfig这种登录方法是为了方便起见而提供的。kubeconfig file仅支持--authentication-mode标志指定认证选项。如果它配置为其它方式，Dashboard中将显示错误消息。 Admin privileges注意： 在操作之前，请确保你知道自己在做什么。向Dashboard的服务账号赋予管理权限可能会存在安全风险。 你可以通过创建ClusterRoleBinding来授权Dashboard的服务账号完全的管理权限。 123456789101112131415161718192021222324252627282930313233343536#栗子dashboard-admin.yaml#官方文档版apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: kubernetes-dashboard labels: k8s-app: kubernetes-dashboardroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: kubernetes-dashboard namespace: kube-system#开发版apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: kubernetes-dashboard-head labels: k8s-app: kubernetes-dashboard-headroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: kubernetes-dashboard-head namespace: kube-system 创建示例用户Creating sample user 在本节中，我们将了解如何使用k8s Service Account机制创建新用户，授权用户管理权限并使用与此用户关联的Bearer Token进行登录。关于grant/deny权限，请查看文档authentication和authorization以了解详情。 创建xxx.yaml文件，并使用kubectl create -f xxx.yaml命令创建它们。 创建 Service Account在kube-system命名空间中创建名为admin-user的服务账户: 12345apiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kube-system 12345678#创建kubectl create -f /etc/kubernetes/auth/admin-user_SA.yaml#serviceaccount/admin-user created#查看kubectl -n kube-system get secret | grep admin-user#admin-user-token-qj8hj kubernetes.io/service-account-token 3 56s 创建 ClusterRoleBinding在大多数情况下，在使用kops, kubeadm等管理配置集群后，Role都已存在于集群中。我们可使用它为ServiceAccount仅创建RoleBinding。 注意: ClusterRoleBinding的apiVersion资源可能不同于k8s version。从v1.8开始，它被提升为rbac.authorization.k8s.io/v1。 123456789101112apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kube-system 123#创建kubectl create -f /etc/kubernetes/Auth/cluster-admin_CRB.yaml #clusterrolebinding.rbac.authorization.k8s.io/admin-user created Bearer Token现在我们需要去找到用于登录的Token。 123456789101112131415kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk &apos;&#123;print $1&#125;&apos;)Name: admin-user-token-qj8hjNamespace: kube-systemLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name=admin-user kubernetes.io/service-account.uid=58d39b31-9c40-11e8-a08a-000c298ee39fType: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 11 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLXFqOGhqIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI1OGQzOWIzMS05YzQwLTExZTgtYTA4YS0wMDBjMjk4ZWUzOWYiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.4hCqFj7R7CwAewnFxsy5QC91v6288T7aOCZXae7AbqXECiFb2yB5x7VQs0GjnUj8jbSZamBpI_D6D7p8PoRUmPZg2NOF46TEztsR9wcsEywUr6EHdXMGy6HUtvedy45K1j9h8oFp9nAqvxa6M7hrfV_yy-XlJdqTo7J06VlT_czpWNScCkjejIOlZXFvYL5f5ha0V4L5XCdlFkf7DYbsNV6odquIKavg270g4nAr1ZAJ14SjeFdfRVvimS4N-W7pb9vmOeZBnAmGuotKoqU1OlzZrMfpsPGIXy5GW3zD8PvsbGU9Xn6lyPHH08X0kXCUACQHx4UiaMFzlnhaC2XIMQ 现在复制Token来登录. HeapsterGitHub: https://github.com/kubernetes/heapster 注意: Heapster已被启用，考虑使用metric-server和第三方metric pipeline来收集Prometheus格式的指标。 Heapster 启用时间轴 Kubernetes Release Action Policy/Support Kubernetes 1.11 Initial Deprecation No new features or sinks are added. Bugfixes may be made. Kubernetes 1.12 Setup Removal The optional to install Heapster via the Kubernetes setup script is removed. Kubernetes 1.13 Removal No new bugfixes will be made. Move to kubernetes-retired organization. metric-serverGitHub: https://github.com/kubernetes-incubator/metrics-server 具体详情可参考README。 12345678910111213141516171819202122232425262728293031323334353637383940414243#下载到本地git clone https://github.com/kubernetes-incubator/metrics-server.git#移动到管理目录mv metrics-server/ /etc/kubernetes/#k8s v1.8+ls /etc/kubernetes/metrics-server/deploy/v1.8+/auth-delegator.yaml auth-reader.yaml metrics-apiservice.yaml metrics-server-deployment.yaml metrics-server-service.yaml resource-reader.yaml#注意metrics-server-deployment.yaml文件，需要一个镜像，请准备#gcr.io/google_containers/metrics-server-amd64:v0.2.1docker pull zhang21/metrics-server-amd64:v0.2.1docker tag zhang21/metrics-server-amd64:v0.2.1 gcr.io/google_containers/metrics-server-amd64:v0.2.1#创建#注意，在顶层进行创建cd /etc/kubernetes/metrics-serverkubectl create -f deploy/v1.8+/clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator createdrolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader createdapiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io createdserviceaccount/metrics-server createddeployment.extensions/metrics-server createdservice/metrics-server createdclusterrole.rbac.authorization.k8s.io/system:metrics-server createdclusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created#查看kubectl -n kube-system get deploymentNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEcoredns 2 2 2 2 2dkubernetes-dashboard 1 1 1 1 19hmetrics-server 1 1 1 0 39s pause容器参考: 《Kubernetes之“暂停”容器》: http://dockone.io/article/2785 《Pause容器》: https://jimmysong.io/kubernetes-handbook/concepts/pause-container.html GitHub: https://github.com/kubernetes/kubernetes/tree/master/build/pause Pause容器，又叫Infra容器。它不是pod，而是一个容器。 123456789101112131415161718192021docker ps | grep pause35c9aaa68a06 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_coredns-78fcdf6894-hn46d_kube-system_daab8e60-9a0d-11e8-a08a-000c298ee39f_0d22a1baac736 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_coredns-78fcdf6894-wqxbx_kube-system_daac5838-9a0d-11e8-a08a-000c298ee39f_04d0cdc392629 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_kube-flannel-ds-7gbvd_kube-system_59129dff-9a0f-11e8-a08a-000c298ee39f_04f28747a2044 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_kube-proxy-rhrks_kube-system_da990e28-9a0d-11e8-a08a-000c298ee39f_0f2bd7bd47eb4 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_kube-scheduler-master_kube-system_537879acc30dd5eff5497cb2720a6d64_0d732ffba5530 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_kube-controller-manager-master_kube-system_01c36146e2c80849d7b6993e68aa5e67_0cd7636bac6df k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_kube-apiserver-master_kube-system_1bd24cc043a06bf7e71b96167946c220_0d4adb3504543 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_etcd-master_kube-system_2cc1c8a24b68ab9b46bca47e153e74c6_0#或者是这样#registry.access.redhat.com/rhel7/pod-infrastructure:latest#rpm包安装kubelet的默认配置KUBELET_POD_INFRA_CONTAINER=&quot;--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest&quot;#kubeadm安装kubelet的默认配置KUBELET_POD_INFRA_CONTAINER=--pod-infra-container-image=k8s.gcr.io/pause:3.1 pause容器的作用k8s中的pause容器主要为每个业务提供以下功能： 在pod中担任Linux命名空间共享的基础 启用pid命名空间，开启init进程 使用pause容器和共享命名空间创建pod示例： 123456789101112131415161718192021222324252627#启动pause，以便可以将容器添加到pod中docker run -d --name pause k8s.gcr.io/pause-amd64:3.1#nginxcat &lt;&lt;EOF &gt;&gt; /tmp/nginx.conf&gt; error_log stderr;&gt; events &#123; worker_connections 1024; &#125;&gt; http &#123;&gt; access_log /dev/stdout combined;&gt; server &#123;&gt; listen 80 default_server;&gt; server_name example.com www.example.com;&gt; location / &#123;&gt; proxy_pass http://127.0.0.1:2368;&gt; &#125;&gt; &#125;&gt; &#125;&gt; EOF#指定网络和命名空间docker run -d --name nginx -v /tmp/nginx.conf:/etc/nginc/nginx.conf -p 8880:80 --net=container:pause --ipc=container:pause --pid=container:pause docker.io/nginx:lates#ghost博客docker run -d --name ghost --net=container:pause --ipc=container:pause --pid=container:pause docker.io/ghost:latest 在这两种情况下，我们将pasue容器指定为我们要加入的命名空间容器。这将有效地创建我们的pod。 访问可以看到ghost通过nginx代理运行。因为网络命名空间在pause, nginx, ghost容器之间共享。而这两个容器的init进程都是pause这个容器。 123456789101112131415161718192021222324252627docker logs -f nginx192.168.31.28 - - [08/Aug/2018:02:00:49 +0000] &quot;GET / HTTP/1.1&quot; 200 3195 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36&quot;192.168.31.28 - - [08/Aug/2018:02:00:49 +0000] &quot;GET /assets/built/screen.css?v=0bf822a279 HTTP/1.1&quot; 200 7360 &quot;http://node:8880/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36&quot;......docker logs -f ghost[2018-08-08 02:00:30] INFO Creating table: posts[2018-08-08 02:00:30] INFO Creating table: users[2018-08-08 02:00:30] INFO Creating table: posts_authors......#查看initdocker exec -it ghost /bin/bashroot@f12a374141a7:/var/lib/ghost# ps -efUID PID PPID C STIME TTY TIME CMDroot 1 0 0 01:55 ? 00:00:00 /pauseroot 5 0 0 01:58 ? 00:00:00 nginx: master process nginx -g daemon off;systemd+ 9 5 0 01:58 ? 00:00:00 nginx: worker processnode 10 0 0 02:00 ? 00:00:03 node current/index.jsroot 127 0 0 02:37 ? 00:00:00 /bin/bashroot 131 127 0 02:37 ? 00:00:00 ps -ef 构建大型集群Building Large Clusters 在k8s v1.11，k8s支持做多5 000个节点的集群。更具体地说，支持满足以下条件的配置： 不超过5 000个node 总量不超过150 000个pod 总量不超过300 000个container 每个节点不超过100个pod 使用salt配置k8sConfiguring Kubernetes with Salt k8s集群能够使用salt进行配置。 验证节点配置Validate Node Setup 节点一致性测试Node Conformance Test 节点一致性测试是一种容器化测试框架，为节点提供系统验证和功能测试。该测试验证节点是够满足k8s的最低要求，通过测试的节点有资格加入k8s集群。 局限Limitations 在k8s v1.5中，节点一致性测试具有如下限制： 节点一致性测试仅支持Docker作为容器runtime 节点先决条件Node Prerequisite 要运行节点一致性测试，节点必须满足与标准k8s节点相同的先决条件。该节点至少要安装一下守护进程: Container Runtime(Docker) Kubelet 运行节点一致性测试Running Node Conformance Test 执行如下步骤： 12345678910111213141516171. 将kubelet执行localhost，测试框架启动一个master来测试kubelet#可使用 --pod-cidr, --cloud-provide标志--api-servers=&quot;http://localhost:8080&quot;2. 运行节点一致性测试# $CONFIG_DIR is the pod manifest path of your Kubelet.# $LOG_DIR is the test output path.sudo docker run -it --rm --privileged --net=host \ -v /:/rootfs -v $CONFIG_DIR:$CONFIG_DIR -v $LOG_DIR:/var/result \ k8s.gcr.io/node-test:0.2#一致性测试的架构支持node-test-adm64node-test-armnode-test-arm64 运行选定测试Running Selected Test 123456789101112#运行指定测试，使用你想要运行的测试的正则表达式 覆盖环境变量FOCUSsudo docker run -it --rm --privileged --net=host \ -v /:/rootfs:ro -v $CONFIG_DIR:$CONFIG_DIR -v $LOG_DIR:/var/result \ -e FOCUS=MirrorPod \ # Only run MirrorPod test k8s.gcr.io/node-test:0.2#跳过指定测试，覆盖环境变量SKIPsudo docker run -it --rm --privileged --net=host \ -v /:/rootfs:ro -v $CONFIG_DIR:$CONFIG_DIR -v $LOG_DIR:/var/result \ -e SKIP=MirrorPod \ # Run all conformance tests but skip MirrorPod test k8s.gcr.io/node-test:0.2 强烈建议仅运行一致性测试，因为它需要更复杂的配置来运行不一致性测试。 概念concepts 概念部分可帮助你了解k8s系统的各个部分以及k8s用于表示集群的抽象，并帮助你更深入地了解k8s的工作原理。 标准词汇Standardized Glossary Annotation用于将任意非标识元数据(metadata)附加到随想的键值对。 Application Architect负责程序高级设计的人员。 Application Developer编写在Kubernetes集群中运行的应用程序的人。 Approver可以审批Kubernetes代码贡献的人。 CLA(Contributor License Agreement)贡献者向开源项目授予其贡献许可的条款。 Certificate一个加密安全文件，用于验证对Kubernetes集群的访问的加密。 Cloud Controller Manager Cloud Provider Cluster一组称为节点(node)的机器，运行着由Kubernetes管理的容器化的应用程序。 Cluster Architect设计一个或多个Kubernetes集群的基础架构的人。 Cluster Operator配置，控制和监控集群的人。 Code Contributor为Kubernetes开源代码库开发和共享代码的人。 ConfigMap一个API对象，用于在键值对中存储非机密的数据。可认为是环境变量，命令行参数… Container一个轻量化和可移植的包含应用程序及其依赖项的可执行的镜像。 Container Environment Variables容器环境变量是name/value对，为Pod中运行的容器提供有用的信息。 Contributor捐赠代码，文档或时间来帮助Kubernetes项目或社区的人。 Controller一个控制循环，通过APIServer监视集群的共享状态，并进行修改，尝试将当前状态移至理想(desired)状态。 CronJob管理一个定期运行的工作。 CustomResourceDefinition自定义码，用于定义要添加到Kubernetes APIServer的资源，而无需构建完整的自定义服务器。 DaemonSet确保Pod的副本在集群的一组节点上运行。 Deployment一个管理副本应用程序的API对象 Dynamic Volume Provision允许用户请求自动创建存储卷。 etcd一致且高度可用的键值存储，用作Kubernetes所有集群数据的备份存储。 Helm Chart可以使用Helm工具管理的预配置Kubernetes资源包。 Horizontal Pod Autoscaler一个API资源，可根据目标CPU利用率或自定义的指标自动调整Pod副本数。 Image一个容器的存储实例，其中包含运行一个应用程序需要的一组软件。 Ingress一个管理集群中服务的外部访问的API对象，通常是HTTP。 Init Container一个或多个初始化容器，必须在任意应用程序容器运行之前完成运行。 Istio一个开放平台，提供统一的方式来继承微服务，管理流量，实施策略和聚合遥测数据。 Job运行完成的 有限/一批 任务。 Kops一个命令行工具，可帮助你创建，销毁，升级和维护生产级、高可用性的Kubernetes集群。(仅支持AWS) Kubeadm一个快速安装Kubernetes和设置安全集群的工具。 Kubectl用于与Kubernetes APIServer通信的命令行工具。 Kubelet在集群的每个节点上运行的Agent。它确保容器运行在Pod中。 Kubernetes API通过RESTful接口提供Kubernetes功能的应用程序，用于存储集群的状态。 Label标记与用户有意义且相关的标识属性的对象。 Minikube一个在本地运行Kubernetes的工具。 Name客户端提供的字符串，用于引用资源URL中的对象。如/api/vi/pods/some-name. Namespace一个抽象概念，用于Kubernetes支持同一物理集群上的多个虚拟集群。 Network Policy允许Pod组如何与其它网络端点进行通信的规范。 Node节点是Kubernetes中的一个工作机器。 Persistent Volume一个表示集群中一块存储的API对象。 Persistent Volume Claim声明定义在一个PersistentVolume中的存储资源，以便可以作为一个volume挂载到容器中。 Pod最小和最简单的Kubernetes对象。Pod表示集群上一组正在运行的容器。 Pod Security Policy启用Pod创建和更新的细粒度授权。 PodPreset一个API对象，在创建时将信息(secrets, volume, env var…)注入到Pod中。 RBAC（role-basesd access control)管理授权决策，允许管理员通过Kubernetes API动态配置访问策略。 ReplicaSet副本集是下一代副本控制器。 Resource Quotas提供限制每个命名空间的聚合资源消耗的约束。 Reviemer在项目的某些部分检查代码质量和正确性的人。 Secret存储敏感信息，如密码，token… Security ContextsecurityContext字段定义Pod或容器的权限和访问控制设置，包括运行时UID和GID。 Selector允许用户根据label过滤资源列表。 Service一个API对象，描述如何访问应用程序，并可以描述端口和负载均衡器。 Service Account为运行在Pod中的进程提供一个标识。 Service Catalog一个扩展API，允许Kubernetes集群中运行的应用程序能够轻松使用外部托管软件，如数据库存储服务。 StatefulSet管理一组Pods的部署和伸缩，并提供有关这些Pod的排序和唯一性的保证。 UIDKubernetes系统生成的一个字符串，用于唯一标识对象。 Volume一个包含数据的目录，可供Pod中的容器访问。 Volume Plugin卷插件可在Pod中集成存储。 kube-apiserver一个Master组件，用于暴露Kubernetes API。它是Kubernetes控制面的前端。 kube-controller-manager一个Master组件，用于运行控制器。 kube-proxy运行在集群中的每一个节点上的网络代理。 kube-schedulerMaster上的组件，用于监测未创建节点新创建的Pod，并选择一个节点供其运行。 概述K8s是什么Kubernetes（常简称为K8s），Kubernetes的名字来自希腊语，意思是“舵手”或“领航员”。K8s是将8个字母“ubernete”替换为“8”的缩写。它用于自动部署、扩展和管理容器化（containerized）应用程序的开源系统。它旨在提供“跨主机集群的自动部署、扩展以及运行应用程序容器的平台”。它支持一系列容器工具, 包括Docker等。 通过Kubernetes你可以： 快速部署应用 快速扩展应用 无缝对接新的应用功能 优化硬件资源，降低成本 Kubernetes特点： 可移植(portable) 可扩展( extensible) 自动化(automatic) 容器优点： 快速创建/部署应用 持续开发、集成和部署(CI/CD) 开发和运维相分离 开发、测试、生产环境的一致性 可移植性 松耦合、分布式、弹性伸缩、微服务化 资源隔离 资源利用 Kubernetes能做什么Kubernetes还允许开发人员从物理和虚拟机脱离，从以主机为中心的基础架构转移到以容器为中心的基础架构。这样可以使用容器固有的全部优点。 Kubernetes满足的应用程序常见需求： Pod 挂载外部存储 分布式secrets 应用健康检查 副本应用实例 横向自动伸缩 服务发现 负载均衡 滚动更新 资源监控 日志采集和存储 自检和调试 认证和授权 这提供了平台即服务(PAAS)的简单性以及基础架构即服务(IAAS)的灵活性，并促进基础设施供应商的可移植性。 Kubernetes不是什么Kubernetes 不是一个传统意义上，包罗万象的PaaS(平台即服务)系统。 不限制支持的应用程序类型，不限制应用程序框架 不提供中间件(如消息中间件)、数据处理框架(如spark)，数据库或集群存储系统 不提供点击即部署的服务市场 不部署代码不构建应用 允许用户选择日志、监控和报警 不提供或授权一个全面的应用程序配置系统/语言 不提供任何机器配置、维护、管理或自我修复系统 你可以自定义你的PAAS，与你选择的CI系统集成，或与Kubernetes一起使用，将你的容器镜像部署到Kubernetes。由于Kubernetes在应用级别而不仅仅在硬件级别上运行，因此它提供了PAAS产品通用的一些功能。如部署、扩展、负载均衡、日志记录、监控等。 k8s组件Kubernetes Components Kubernetes 所需的各种二进制组件, 用于提供齐全的功能。 Master组件Master组件提供的集群控制面(control plane)。Master作出集群的全局决策，以及检测和相应集群事件。Master组件可在集群中任何节点上运行。然而，为了简单，通常在一台机器上启动所有Master组件，并且不会在此机器上运行用户容器。可使用多个机器的设置来构建高可用性能集群。 kube-apiserverkube-apiserver对外展示Kubernetes API。它是Kubernetes前端控制层，任何的资源请求/调用都是通过它提供的接口进行。它被设计为水平扩展，即通过部署更多实例来扩展。 etcd持久化和高可用的K/V存储，用于Kubernetes所有集群数据的后端存储。请始终为k8s集群的etcd数据做备份。 kube-controller-managerMaster上运行的控制器组件，它们是集群中处理常规任务的后台线程。逻辑上讲，每个控制器都是一个单独的进程，但为了降低复杂性，它们都被编译为单个二进制文件并在单个进程中运行。 这些控制器包含： 节点控制器(Node Controller): 负责在节点故障时通知和响应 副本控制器(Replication Controller): 负责维护系统中每个副本控制器对象正确的pod数 端点控制器(Endpoints Controller): 填入端点对象 服务账户(service accoute)和令牌控制器(token controller): 为新的命名空间(namespace)创建默认账户和API访问令牌 cloud-controller-manager云控制器管理器用于与底层云提供商进行交互。它仅运行云提供商特定的控制器循环。你必须在kube-controller-manager中禁用这些controller loops，将--cloud-provider标志设置为external来禁用。 以下控制器具有云提供商依赖关系： 节点控制器: 用于检查云服务商提供的程序 路由控制器: 用于在底层云基础架构中设置路由 服务控制器: 用于创建，更新，删除云服务商提供的负载均衡器 数据卷控制器: 用于创建，附件和挂载卷，以及与云服务商提供的卷进行交互 kube-scheduler监视还未分配节点的新创建的pod，选择一个节点供pod运行。调度决策所考虑的因素包括： 个体/集体的资源需求，硬件/软件/策略的约束，亲和力/反亲和性的规范，工作负载和期限。 Node组件节点(node)组件运行在每个节点，维护运行的pod并提供Kubernetes运行时环境。 kubelet在集群中每个节点上运行的Agent，它确保container运行在pod中。kubelet采用通过各种机制提供的一组PodSpecs，并确保这些PodSpecs中描述的容器运行且健康。kubelet不管理不是由k8s创建的容器。 提供如下功能： 挂载pod所需的数据卷 下载pod的secrets pod中运行docker容器 周期性的容器健康检查 如有需要，通过创建mirror pod将pod的状态报告回系统的其余部分 将节点的状态报告回系统的其余部分 kube-proxy通过维护主机上的网络规则并执行连接转发，来实现Kubernetes服务抽象。 container runtime负责运行容器的软件。k8s支持多种runtimes： docker, rkt, runc… docker, rkt, supervisord, fluentd… Addons扩展是实现集群功能的Pod和Service。pod可由Deployment， Replication等管理。命名空间扩展对象在kube-system命名空间中创建。 DNS虽然其它插件并非严格要求，但所有k8s集群都应具有集群DNS，因为许多示例都依赖于它。集群DNS是一个DNS服务器，除了你环境中的DNS服务器，它还为k8s服务提供DNS记录。由k8s启动的容器会在DNS搜索中自动包含此DNS服务器。 Web UI(dashboard)仪表盘。 container resource monitoring记录有关中央数据库中容器的通用时间序列度量标准，并提供用于浏览该数据的UI。 cluster-level logging集群级别的日志记录机制，复制将容器日志保存到具有search/browse界面的中央日志存储。 k8s APIk8s API还可作为系统声明性配置架构的基础。kubectl命令行工具可用于创建，更新，删除和获取API对象。k8s还根据API资源存储其序列化状态(etcd中)。k8s自身被分解为多个组件，这些组件通过其API进行交互。 OpenAPI和Swagger定义完整的API详细信息记录在Swagger v1.2和OpenAPI。k8s apiserver(master)公开了一个API，可用于检索位于/swaggerapi的Swagger v1.2 k8s API.从k8s 1.10开始，OpenAPI规范在单个/openapi/v2端点中提供。单独格式的端点(如swagger.json...)已被弃用，后面会被移除。 通过设置HTTP header指定请求格式: Header Possible Values Accept application/json, application/com.github.proto-openapi.spec.v2@v1.0+protobuf (the default content-type is application/json for / or not passing this header) Accept-Encoding gzip (not passing this header is acceptable) 栗子： Before 1.10 Starting with Kubernetes 1.10 GET /swagger.json GET /openapi/v2 Accept: application/json GET /swagger-2.0.0.pb-v1 GET /openapi/v2 Accept: application/com.github.proto-openapi.spec.v2@v1.0+protobuf GET /swagger-2.0.0.pb-v1.gz GET /openapi/v2 Accept: application/com.github.proto-openapi.spec.v2@v1.0+protobuf Accept-Encoding: gzip 123456789101112131415161718192021222324252627282930313233343536373839#查看curl localhost:8080&#123; &quot;paths&quot;: [ &quot;/api&quot;, &quot;/api/v1&quot;, &quot;/apis&quot;, &quot;/apis/apps&quot;, &quot;/apis/apps/v1beta1&quot;, &quot;/apis/authentication.k8s.io&quot;, &quot;/apis/authentication.k8s.io/v1beta1&quot;, &quot;/apis/authorization.k8s.io&quot;, &quot;/apis/authorization.k8s.io/v1beta1&quot;, &quot;/apis/autoscaling&quot;, &quot;/apis/autoscaling/v1&quot;, &quot;/apis/batch&quot;, &quot;/apis/batch/v1&quot;, &quot;/apis/batch/v2alpha1&quot;, &quot;/apis/certificates.k8s.io&quot;, &quot;/apis/certificates.k8s.io/v1alpha1&quot;, &quot;/apis/extensions&quot;, &quot;/apis/extensions/v1beta1&quot;, &quot;/apis/policy&quot;, &quot;/apis/policy/v1beta1&quot;, &quot;/apis/rbac.authorization.k8s.io&quot;, &quot;/apis/rbac.authorization.k8s.io/v1alpha1&quot;, &quot;/apis/storage.k8s.io&quot;, &quot;/apis/storage.k8s.io/v1beta1&quot;, &quot;/healthz&quot;, &quot;/healthz/ping&quot;, &quot;/healthz/poststarthook/bootstrap-controller&quot;, &quot;/healthz/poststarthook/extensions/third-party-resources&quot;, &quot;/healthz/poststarthook/rbac/bootstrap-roles&quot;, &quot;/logs&quot;, &quot;/metrics&quot;, &quot;/swaggerapi/&quot;, &quot;/ui/&quot;, &quot;/version&quot; ] API 版本为了更容易消除字段或重构资源表示，k8s支持多个API版本，每个版本位于不同的API路径。如/api/vi或/apis/extensions/v1beta1. 我们选择在API级别，而不是资源级别/字段级别进行版本控制，以确保API提供干净、一致的系统资源和行为视图，并允许控制对生命末端和实验性API的访问。json和protobuf序列化模式都遵循相同的模式更改指南。请注意，API版本和软件版本仅间接相关。 不同的API版本意味着不同级别的稳定性和支持： Alpha level 版本名包含alpha(如 v1aplha1) 启用该功能可能会暴露bug，默认禁用 可随时删除对功能的支持，恕不另行通知 可能会在以后软件版本中以不兼容的方式更改，恕不另行通知 由于错误风险和缺乏长期支持，建议仅在短期测试集群中使用 Beta level 版本名包含beta(如 v2beta3) 代码经过充分测试，启用该功能被认为是安全的。默认启用 虽然细节会有所变化，但不会删除对整体功能的支持 建议仅用于非关键业务，因为后续版本可能会发生不兼容的更改 请尝试我们测试版功能并提供反馈 Stable level 版本名是vx，x为整数 许多后续版本的软件将出现稳定版的功能 API groups为了更容易扩展k8s API，我们实施了API Groups，它在REST path和序列化对象的apiVersion字段中指定。 目前在使用的几个API groups: 核心组(core group)，又称遗留组，位于REST path的/api/v1，并使用apiVersion: v1 命名组(named group)，位于REST path的/apis/$GROUP_NAME/$VERSION，并使用apiVersion: $GROUP_NAME/$VERSION 两种受支持的自定义资源扩展API的路径： 自定义资源(CustomResourceDefiniton) 适用于具有非常基本CRUD需求的用户 需要完整k8s API语义的用户可以实现自己的apiserver，并使用聚合器使其无缝连接到客户端 启用 API groups默认情况下启用某些资源和API groups。通过在apiserver设置--runtime-config可启用/禁用它。此配置接收逗号分隔的KV，描述了apiserver运行时配置。 在API groups中启用资源默认情况下启动 DeamonSets, Deployments, HorizontalPodAutoscalers, Ingress, Jobs, ReplicaSets。其它扩展资源可通过在apiserver上设置--runtime-config启用或禁用。 k8s 对象本节解释了如何在k8s API中表示k8s对象，以及如何以.yaml格式表示它们。 理解k8s对象在k8s系统中，k8s对象是持久化的实体。k8s使用这些实体来表示整个集群的状态。特别地，它们描述了如下信息： 哪些容器化应用程序正在运行(以及运行在哪个节点上) 可以被这些应用程序使用的资源 应用程序行为方式的策略(重启、升级、容错) k8s 对象是一个意图记录(record of intent) —— 一旦创建了对象，k8s系统将持续工作以确保对象存在。通过创建一个对象，你可以有效地告诉k8s系统你希望集群的工作负载看起来像什么，这是你的集群的期望状态(desired state)。要使用k8s对象(创建, 修改, 删除)，需要使用k8s API。当你使用kubectl命令行接口时，CLI会为你进行必要的k8s API调用。 对象规约与状态Object Spec and Status 每个k8s 对象都包含了两个嵌套的对象字段，用于控制对象的配置：对象规约和对象状态。在任何时刻，k8s controller plane都会主动管理对象的实际状态，以匹配你提供的期望状态。 规约(spec)，必须提供。描述了对象的期望状态(diresed state)——你希望对象具有的特征。 状态(status)，描述对象的实际状态，由k8s系统提供和更新。 例如，k8s Deployment是一个可以表示你集群上运行的应用程序的对象。当你创建一个Deployment，你可以设置部署规约以指定你希望应用程序运行三个副本。k8s系统读取部署规约并启动应用程序所需的三个实例——更新状态以符合你的规范。如果这些事例中的任何一个失败(状态改变)，k8s系统通过进行校正来响应规约和状态之间的差异。在这种情况下，启动替换实例。 描述k8s 对象在k8s中创建对象时，必须提供描述其期望状态的对象规约，以及有关对象的一些基本信息(如 名称)。当你使用k8s API来创建对象时，API请求必须在请求正文中将信息作为JSON格式。通常，你在.yaml文件中向kubectl提供信息，kubectl在发出API请求时将信息转换为JSON格式。 栗子： 1234567891011121314151617181920# for versions before 1.9.0 use apps/v1beta2apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 使用类似上面的.yaml文件创建部署的方法，是在kubectl命令行工具中使用kubectl create命令，将.yaml文件作为参数传递。 12kubectl create -f https://k8s.io/examples/application/deployment.yaml --record#deployment &quot;nginx-deployment&quot; created 必填字段在要创建k8s 对象的.yaml文件中，必须配置一下字段： apiVersion： 创建对象的k8s API版本 kind： 创建的对象类型 metadata： 有助于识别对象唯一性的数据，包括name, uid, namespace… 你还需要提供spec字段。对于每个k8s对象，对象规约的精确格式是不同的，并且包含特定于该对象的嵌套字段。 NamesKubernetes REST API中所有对象都用Name和UID来明确标识。对于用户提供的非唯一的属性，k8s提供labels和annotations。 Names客户端提供的字符串，用于引用资源URL中的对象。如/api/v1/pods/some-name.一个给定kind的对象同时只能有一个name。但如果你删除了此对象，便可以为新对象赋予此名字。按照惯例，k8s资源的名称的最大长度应为253个字符，并由小写字母,数字, -, .字符组成。但某些资源可能具有更过限制。 UIDsk8s 系统生成的字符串，用于唯一标识对象。在k8s集群的整个生命周期中创建的每个对象都具有一个唯一的UID。它旨在区分类似实体的历史事件。 Namespacek8s支持在物理集群中创建多个虚拟集群，这些虚拟机群称为namespaces。命名空间是一种将集群资源划分为多个用途的方法。命名空间名称满足正则表达式，最大长度为63位。 什么时候使用多个命名空间命名空间旨在用于多个用户分布在多个团队/多个项目的环境中。对于具有几个到几十个用户的集群，你根本不需要创建和考虑命名空间。命名空间提供名称范围。资源名称在命名空间中必须唯一，但不能跨命名空间。命名空间是一种在多个用户之间划分集群资源的方法。在k8s的未来版本中，默认情况下，同一命名空间中的对象将具有相同的访问控制策略(ACP)。没有必要使用多个命名空间仅来分隔略有不同的资源。如同一软件的不同版本，使用labels来区分同一命名空间内的资源。 操作命名空间 12345678910111213141516171819202122232425262728293031323334353637383940#查看kubectl get nsNAME STATUS AGEdefault Active 13dkube-system Active 13d#通过命令创建kubectl create namespace my-namespace#或通过文件创建vim my-namespace.yamlapiVersion: v1kind: Namespacemetadata: name: my-namespacekubectl create -f ./my-namespace.yaml#查看kubectl get namespaceNAME STATUS AGEdefault Active 13dkube-system Active 13dmy-namespace Active 4s#删除kubectl delete namespace my-namespace#设置请求的命名空间#使用--namespace标志临时设置请求的命名空间kubectl kubectl get pods --namespace=default#设置命名空间首选项kubectl config set-context $(kubectl config current-context) --namespace=my-namespacekubectl config view Kubernetes有三个初始的命名空间： default: 没有其它命名空间时，对象的默认命名空间 kube-system: k8s系统创建的对象的命名空间 kube-public: 此命名空间是自动创建的，可供所有用户读取(包括未认证用户)。此命名空间主要用于集群使用，以防止某些资源在整个集群中可见且可公开读取。此命名空间的公共方面只是一个约定，而非要求。 注意： 删除一个命名空间会自动删除所有属于该命名空间的资源 k8s初始化的两个命名空间无法删除 持久化卷(persistent volume)不属于任何命名空间，但持久化卷声明(persistent volume claim)是属于某个特定命名空间的 事件(event)是否属于命名空间取决于产生事件的对象 命名空间和DNS当你创建一个服务(service)，它会创建相应的DNS条目(dns entry)。此条目的格式为&lt;service-name&gt;.&lt;namespace-name&gt;.svc.cluster.local，这表示如果一个容器只是用&lt;service-name&gt;，它将会解析为命名空间本地的服务。这对于在多个命名空间(如 开发/测试/生产)中使用相同的配置非常有用。如果想要扩命名空间访问，则需要使用完全限定的域名(fully qualified domain name)。 不是所有对象都在命名空间中大多数k8s资源(pods, services, replication controller…)都在某些命名空间中。然而，命名空间资源本身并不在命名空间中。并且，低级资源(node, persistentVolumes)并不在任何命名空间中。 查看k8s资源是否在命名空间中： 12kubectl api-resources --namespaced=truekubectl api-resources --namespaced=false Labels和Selectors标签是被关联到对象上的key/value对。标签旨在用于指定对用户有意义且相关的对象的标识属性，但不直接按时核心系统的语义。标签可用于组织和选择对象的子集。标签可在创建时附加到对象，随时可以添加和修改。每个对象可拥有多个标签，对于给定的对象，key必须唯一。 123456789101112131415"metadata": &#123; "labels": &#123; "key1" : "value1", "key2" : "value2", "keyN" : "valueN" &#125;&#125;#栗子"labels": &#123; "release" : "stable", "environment" : "dev", "track" : "daily"&#125; 我们最终将索引(index)和反向索引(reverse-index)标签，用于高效查询和监视，使用它们在UI和CLI中进行排序和分组。我们不希望对非标识(non-identifying)信息使用标签，特别是大型结构化数据。非标识信息应该记录到annorations。 标签使用户能够以松散耦合的方式将自己的组织结构映射到系统对象中，而无需客户端存储这些映射。 语法和字符集有效的label key有两个字段: 可选前缀和名称，用斜杆分隔。名字字段是必须的，小于等于63个字符，以字母数字开头和结尾，还可使用-, _, .三个字符。前缀可选。如果指定，前缀必须是DNS子域，不超过253个字符，后跟斜杆/。如果省略，则假定label key对用户是私有的。向最终用户对象添加标签的自动系统组件(kube-scheduler, kube-apserver…)必须制定前缀。kuberneter.io/前缀保留个k8s核心组件。 有效的label value必须小于等于63个字符，可为空，或以字母数字开头和结尾，还可使用-, _, .三个字符。 label selectors标签不提供唯一性。通常，我们希望许多对象携带相同的标签。通过label selector，客户端/用户 可以识别一组对象。标签选择器是k8s中的核心分组原语。 API目前支持两种类型的选择器: equality-based和set-based。标签选择器可由逗号,分隔的多个要求组成。一个空(empty)标签选择器(zero requirements)，选择集合中的每个对象。一个空(null)标签选择器(仅可用于选择器字段)不选择任何对象。 equality-based requirement基于平等/不平等的要求允许按标签键和值进行过滤。匹配对象必须满足所有指定的标签约束，尽管它们也可能具有其它标签。允许三种运算符:=, ==, !=。 12environment = productiontier != frontend set-based requirement基于集合的标签的要求允许根据一组值过滤键。支持三种操作符: in, notin, exists。 1234environment in (production, qa)tier notin (frontend, backend)partition!partition API LIST and WATCH filteringLIST和WATCH操作可以指定标签选择器来过滤使用查询参数返回的对象集。两个要求都是允许的。两种标签选择器的样式都可使用通过TEST客户端列出或查看资源。 equality-based requirements: ?labelSelector=environment%3Dproduction,tier%3Dfrontend set-based requirements: ?labelSelector=environment+in+%28production%2Cqa%29%2Ctier+in+%28frontend%29 12345678#equality-basedkubectl get pods -l environment=production,tier=frontend#set-basedkubectl get pods -l 'environment in (production),tier in (frontend)'kubectl get pods -l 'environment in (production, qa)'kubectl get pods -l 'environment,environment notin (frontend)' Service and ReplicationController服务所针对的一组pod使用标签选择器进行定义。类似地，副本控制器应该管理的pod数量也使用标签选择器定义。 123456789#json格式&quot;selector&quot;: &#123; &quot;component&quot;: &quot;redis&quot;&#125;#yaml格式selector: component: redis Annotation你可使用k8s annotation(注释)将任意非标识(non-identifying)元数据附加到对象。工具和库等客户端可以检索此元数据。它也是key/value对。Annotations不会被k8s直接使用，其主要目的是方便用户阅读查找。 将元数据追加到对象你可使用label或annotations将原数据追加到k8s对象。标签用于选择对象和查找满足特定条件的对象集合。相反，注释不用于识别和选择对象。 123456"metadata": &#123; "annotations": &#123; "key1" : "value1", "key2" : "value2" &#125;&#125; Field Selectors字段选择器允许你根据一个或多个资源字段的值选择k8s资源。 栗子： 123456789101112131415161718192021222324252627#三种操作符=, ==, !=metadata.name=my-servicemetadata.namespace!=defaultstatus.phase=Pending#kubectl get pods --field-selector status.phase=RunningNAME READY STATUS RESTARTS AGEhello-world-3198537413-138pg 1/1 Running 0 5dhello-world-3198537413-67g6d 1/1 Running 0 5dhello-world-3198537413-bf73l 1/1 Running 0 5dhello-world-3198537413-ddgb3 1/1 Running 0 5dhello-world-3198537413-ffj90 1/1 Running 0 5d#kubectl get ingress --field-selector foo.bar=baz#kubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always#kubectl get statefulsets,services --field-selector metadata.namespace!=default Recommended Labels你可以使用比kubectl和dashboard更多的工具来可视化和管理k8s对象。一组通用的标签允许工具以互操作的方式工作，以所有工具都能理解的通用方式描述对象。除了支持工具之外，推荐的标签还以可查询的方式描述应用程序。 shared labels and annotations共享一个通用的前缀: app.kubernetes.io。没有前缀的标签对用户是私有的。共享前缀可确保共享标签不会干扰自定义用户标签。 为了充分利用这些标签，应将它们应用于每个资源对象。 Key Description Example Type app.kubernetes.io/name The name of the application mysql string app.kubernetes.io/instance A unique name identifying the instance of an application wordpress-abcxzy string app.kubernetes.io/version The current version of the application (e.g., a semantic version, revision hash, etc.) 5.7.21 string app.kubernetes.io/component The component within the architecture database string app.kubernetes.io/part-of The name of a higher level application this one is part of wordpress string app.kubernetes.io/managed-by The tool being used to manage the operation of an application helm string 要说明这些标签的运行情况，请考虑一下StatefulSet对象: 12345678910apiVersion: apps/v1kind: StatefulSetmetadata: labels: app.kubernetes.io/name: mysql app.kubernetes.io/instance: wordpress-abcxzy app.kubernetes.io/version: "5.7.21" app.kubernetes.io/component: database app.kubernetes.io/part-of: wordpress app.kubernetes.io/managed-by: helm 使用kubectl进行对象管理kubectl命令行工具支持多种方式来创建和管理k8s对象。应该只使用一种技术来管理k8s对象。对同一个对象的混合和匹配技术会导致未定义的行为。 Management technique Operates on Recommended environment Supported writers Learning curve Imperative commands Live objects Development projects 1+ Lowest Imperative object configuration Individual files Production projects 1 Moderate Declarative object configuration Directories of files Production projects 1+ Highest 必要的命令Managing Kubernetes Objects Using Imperative Commands 使用k8s命令行工具内置的必要命令，可直接快速创建、更新、删除k8s对象。 权衡kubectl工具支持三种对象管理： Imperative commands(必要的命令) Imperative object configuration(必要的对象配置) Declarative object configuration(声明的对象配置) 创建对象kubectl工具支持动词驱动的命令，用以创建一些最常见的对象类型。这些命令被命名为即使不熟悉k8s对象类型的用户也能够识别。 12345678910#创建一个新的Deployment对象，以在一个或多个pod中运行containerrun#创建一个新的Service对象，以在pod间对流量进行负载均衡expose#创建一个新的Autoscaler对象，用以自动水平伸缩控制器autoscale kubectl工具还支持由对象类型驱动的创建命令。这些命令支持更多对象类型，并且更明确地表达了它们的意图，但要求用户知道他们打算创建的对象类型。 1234create &lt;objecttype&gt; [&lt;subtype&gt;] &lt;instancename&gt;#栗子kubectl create service nodeport &lt;service-name&gt; 更新对象kubectl命令支持动词驱动的命令，用于一些常见的更新操作。 12345678910#通过更新控制器的副本数，水平伸缩控制器，以添加或删除podscale#在对象中添加或删除注释annotate#在对象中添加或删除标签label kubectl工具还支持由对象的某个驱动的更新命令: 12#设置对象的一个方面set kubectl工具支持这些直接地更新实时对象的额外方法，但他们需要更好地裂解k8s对象模式。 123456#通过在编辑器中打开其配置，直接编辑实时对象的原始配置文件edit#使用补丁字符串，直接修改实时对象的特定字段patch 删除对象1234#从集群中删除对象delete &lt;type&gt;/&lt;name&gt;kubectl delete deployment/nginx 查看对象如下这些命令可用于打印除对象信息: 12345678910#打印有关匹配对象的基本信息get#打印有关匹配对象的详细信息describe#打印运行在pod中容器的stdout和stderrlogs 创建对象前修改对象有些对象字段没有可在create命令汇总使用的标志。在某些情况下，你可使用set和create的组合在对象创建之前为字段指定值。 12345678910#set命令kubectl create service clusterip my-svc --clusterip="None" -o yaml --dry-run \| kubectl set selector --local -f - 'environment=qa' -o yaml \| kubectl create -f -#--edit标志kubectl create service clusterip my-svc --clusterip="None" -o yaml --dry-run &gt; /tmp/srv.yamlkubectl create --edit -f /tmp/srv.yaml 配置文件Imperative Management of Kubernetes Objects Using Configuration Files 1234567891011121314#创建对象kubectl create -f &lt;file | url&gt;#更新kubectl replace -f &lt;file | url&gt;#删除kubectl delete -f &lt;file | url&gt;#查看kubectl get -f &lt;file | url&gt; -o yaml 使用配置文件声明管理的k8s对象Declarative Management of Kubernetes Objects Using Configuration Files 可通过在目录中存储多个对象配置文件来创建、更新、删除k8s对象，并使用kubectl apply根据递归创建和更新这些对象。kubectl apply不支持对象配置命令create和replace。 开始前声明性对象配置需要深入理解k8s对象定义和配置。 创建对象使用kubectl apply创建除指定目录中的配置文件定义的已存在的所有对象。 1kubectl apply -f &lt;directory&gt;/ 栗子： 12345678910111213141516171819202122232425apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx minReadySeconds: 5 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80#创建kubectl apply -f https://k8s.io/examples/application/simple_deployment.yaml#查看kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml 更新对象使用kubectl apply更新目录中定义的所有对象，即使这些对象已经存在。 1kubectl apply -f &lt;directory&gt;/ 栗子： 12345678910111213141516171819202122232425262728293031#伸缩kubectl scale deployment/nginx-deployment --replicas=2#更新nginx版本，从1.7.9升级到1.11.9#删除minReadySeconds字段apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.11.9 ports: - containerPort: 80#应用更新kubectl apply -f https://k8s.io/examples/application/update_deployment.yaml#查看kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml 删除对象有两种方法: 12345#推荐kubectl delete -f &lt;filename&gt;#选择kubectl apply -f &lt;directory/&gt; --prune -l &lt;labels&gt; 查看对象1kubectl get -f &lt;file | url&gt; -o yaml 计算,存储和网络Compute, Storage, and Networking Extensions 集群管理Cluster Administration 规划集群 管理集群 保护集群 集群服务 详情见配置章节。 证书Certificates 当使用客户端证书认证时，你可以通过easyras, openssl, cfssl手动生成证书。 openssl123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#Generate a ca.key with 2048bitopenssl genrsa -out ca.key 2048#According to the ca.key generate a ca.crtopenssl req -x509 -new -nodes -key ca.key -subj "/CN=$&#123;MASTER_IP&#125;" -days 10000 -out ca.crt#Generate a server.key with 2048bitopenssl genrsa -out server.key 2048#reate a config file for generating a Certificate Signing Request (CSR)[ req ]default_bits = 2048prompt = nodefault_md = sha256req_extensions = req_extdistinguished_name = dn[ dn ]C = &lt;country&gt;ST = &lt;state&gt;L = &lt;city&gt;O = &lt;organization&gt;OU = &lt;organization unit&gt;CN = &lt;MASTER_IP&gt;[ req_ext ]subjectAltName = @alt_names[ alt_names ]DNS.1 = kubernetesDNS.2 = kubernetes.defaultDNS.3 = kubernetes.default.svcDNS.4 = kubernetes.default.svc.clusterDNS.5 = kubernetes.default.svc.cluster.localIP.1 = &lt;MASTER_IP&gt;IP.2 = &lt;MASTER_CLUSTER_IP&gt;[ v3_ext ]authorityKeyIdentifier=keyid,issuer:alwaysbasicConstraints=CA:FALSEkeyUsage=keyEncipherment,dataEnciphermentextendedKeyUsage=serverAuth,clientAuthsubjectAltName=@alt_names#Generate the certificate signing request based on the config fileopenssl req -new -key server.key -out server.csr -config csr.conf#Generate the server certificate using the ca.key, ca.crt and server.csropenssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key \-CAcreateserial -out server.crt -days 10000 \-extensions v3_ext -extfile csr.conf#View the certificateopenssl x509 -noout -text -in ./server.crt easyrsa cfssl 分发自签名CA证书客户端节点可以拒绝将自签名(self-signed)CA 证书识别为有效。对于非生产环境火灾防火墙后面运行的部署，你可以将自签名CA证书分发给客户端，并刷新本地列表以获取有效证书。 1234567sudo cp ca.crt /usr/local/share/ca-certificates/kubernetes.crtsudo update-ca-certificatesUpdating certificates in /etc/ssl/certs...1 added, 0 removed; done.Running hooks in /etc/ca-certificates/update.d....done. 云提供商跳过！ 管理资源可能，你已经部署应用程序并通过服务公开它。接下来怎么办？k8s提供了许多工具来帮助你管理应用程序部署(包括伸缩和更新)。我们将更深入讨论配置文件和标签。 组织资源配置Organizing resource configurations 许多应用程序需要创建多个资源，如Deployment和Service。通过将多个资源组合在同一个文件中(在yaml中以---分隔)，可以简化多个资源的管理。 栗子：nginx-app.yaml 12345678910111213141516171819202122232425262728293031323334apiVersion: v1kind: Servicemetadata: name: my-nginx-svc labels: app: nginxspec: type: LoadBalancer ports: - port: 80 selector: app: nginx---apiVersion: apps/v1kind: Deploymentmetadata: name: my-nginx labels: app: nginxspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 使用与单个资源相同的方式创建多个资源。资源将按照它们在文件中出现的顺序创建。因此，最好首先指定Service，因为这将确保Scheduler可以扩展与服务关联的pod，因为它们是由Controller创建的。 1234567891011121314151617kubectl create -f https://k8s.io/examples/application/nginx-app.yaml#service "my-nginx-svc" created#deployment "my-nginx" created#同样也支持多个-fkubectl create -f https://k8s.io/examples/application/nginx/nginx-svc.yaml -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml#或者指定一个目录，读取yaml, yml, json文件kubectl create -f https://k8s.io/examples/application/nginx/#urlkubectl create -f https://raw.githubusercontent.com/kubernetes/website/master/content/en/examples/application/nginx/nginx-deployment.yaml 建议的做法是，将与同一微服务或应用程序相关的资源放入同一配置文件中，或将相关联的配置文件分组到同一目录下。 kubectl批量操作Bulk operations in kubectl 资源创建并不是kubectl可执行的唯一操作。 1234567891011121314151617181920kubectl delete -f https://k8s.io/examples/application/nginx-app.yaml#deployment "my-nginx" deleted#service "my-nginx-svc" deleted#分开的资源kubectl delete deployments/my-nginx services/my-nginx-svc#指定label(selector)删除kubectl delete deployment,services -l app=nginx#deployment "my-nginx" deleted#service "my-nginx-svc" deleted#递归删除--recursive -Rkubectl create -f project/k8s/development --recursivekubectl create -f project/k8s/namespaces -f project/k8s/development --recursive 高效使用labelUsing labels effectively 到目前为止，我们使用的示例最多只能将一个标签应用于任意资源。在许多情况下，应该使用多个标签来区分集合。 12345678910 labels: app: guestbook tier: backend role: master#查看kubectl get pods -Lapp -Ltier -Lrolekubectl get pods -l app=guestbook,role=master Canary deployments需要多个标签的另一种情况是区分不同版本的部署，或同一组件的配置。通常的做法是将新应用程序版本的canary与先前版本并排部署，以便新版本可以在完全推出前接收实时生产流量。 例如，你可以使用track标签来区分不同的版本: 12345678910111213141516171819202122232425262728#stable version name: frontend replicas: 3 ... labels: app: guestbook tier: frontend track: stable ... image: gb-frontend:v3#new version name: frontend-canary replicas: 1 ... labels: app: guestbook tier: frontend track: canary ... image: gb-frontend:v4#前端服务将通过选择其标签的公共子集(`track`)来跨越两组副本，以便将流量定向到两个应用程序。 selector: app: guestbook tier: frontend 更新标签Updating labels 有时，在创建新资源之前，需要重新标记现有的pod和其它资源。这可使用kubectl label来完成。 12345#更新kubectl label pods -l app=nginx tier=fe#查看kubectl get pods -l app=nginx -L tier 更新注释Updating annotations 有时，你会想要将注释附加到资源。这个使用kubectl annotatie来完成。 1234kubectl annotate pods my-nginx-v4-9gw19 description=&apos;my frontend running nginx&apos;#查看kubectl get pod my-nginx-v4-9gw19 -o yaml 伸缩应用程序Scaling your application 当应用程序上的负载增大或缩小时，可以使用kubectl轻松扩展。 1234567kubectl scale deployment/my-nginx --replicas=2kubectl get pods -l app=nginx#自动伸缩kubectl autoscale deployment/my-nginx --min=1 --max=3 就地更新资源In-place updates of resources 有时，需要对创建的资源进行简单，无中断(non-disruptive)的更新。 kubectl apply建议在源代码管理中维护一组配置文件，以便可以对它们配置的资源的代码进行维护和版本化。这样，你可以使用kubectl apply将更改的配置推送的集群。kubectl apply会将注释附加到资源，以便确定自上次调用以来对配置所做的更改。在调用它是，kubectl apply会在先前的配置，提供的输入和资源的当前配置之间进行差异比较，已确定如何修改资源。 kubectl edit或者，你可使用kubectl edit来更新资源。 12kubectl edit deployment/my-nginx#这样就和vim差不多，可修改此部署 kubectl patch你可使用kubectl patch来更新API对象。此命令支持JSON patch, JSON merge patch和 strategic merge patch。 破坏性更新Disruptive updates 在某些情况下，你可能需要更新初始化后无法更新的资源字段，或者你可能只想立即进行递归更改，例如修复部署创建的损坏的pod。要更改此类资源，请使用replace --force——它将删除并重新创建资源。 123kubectl replace -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml --forcedeployment &quot;my-nginx&quot; deleteddeployment &quot;my-nginx&quot; replaced 在服务没有中断的情况下更新应用程序Updating your application without a service outage 在某些时候，你最终需要更新已部署的应用程序，通常是指定新的image或image tag。kubectl支持多种更新操作，每种操作都适用于不同的场景。 123456kubectl run my-nginx --image=nginx:1.7.9 --replicas=3#deployment &quot;my-nginx&quot; created#更新nginx版本为: 1.9.1kubectl edit deployment/my-nginx#修改镜像那一行 部署将以声明的方式逐步更新已部署的nginx应用程序。它确保在更新时只有一定数量的旧副本可能会关闭，并且在所需数量的pod之上只能创建一定数量的新副本。 集群网络Cluster Networking 默认情况下，k8s与docker的网络方式有所不同。有4个网络问题需要解决： 高度耦合的容器到容器的通信: 这通过pod和localhost通信解决 pod到pod的通信： 这是侧重点 pod到service的通信： 这包含在Service中 external到service的通信： 这包含在service中 k8s假设pod与pod间是可以通信的，无论它们位于哪个主机。每个pod都有自己的IP地址，因此你无需在pod之间明确创建链接，也几乎不需要处理映射容器端口到主机端口。这创建了一个干净的向后兼容的模型，从端口分配、命名、服务发现、负载均衡、应用程序配置和迁移的角度来看，pod可以像VM或物理主机一样。 为实现此目的，你需要设置集群网络。 Docker模型在讨论k8s网络方法之前，有必要回顾Docker网络方式。默认情况下，Docker使用host-private网络。它创建一个虚拟网桥(称为docker0)，并从RFC1918中为该网桥定义的一个专用地址块中分配一个子网。对于Docker创建的每个容器，它分配一个连接到网桥的虚拟以太网设备(称为veth)。使用Linux命名空间将veth映射为容器中的eth0。容器内的eth0网口从桥接器的地址范围获取IP地址。为了使Docker容器跨节点进行通信，必须在计算机自己的IP地址上分配端口，然后将这些端口转发/代理到容器。这意味着容器必须小心地使用端口，或动态分配端口。 k8s模型跨多开发者协调端口非常难以大规模地进行，并使用户暴露在他们无法控制的集群级别问题之外。动态端口分配给系统带来了很多复杂性——每个应用程序都必须将端口作为标志，API server必须知道如何将动态端口号插入配置块，服务必须知道如何找到彼此。与此相关，k8s采取了不同的方法。 k8s对任何网络实施都强加了一下基本要求： 容器间可互相通信而无需NAT 所有节点都可与所有容器通信而无需NAT 容器看到的IP与其他人看到的IP相同 实际上，k8s在pod范围应用IP地址，pod中的容器共享其网络命名空间(包括IP地址)。这意味着pod中的容器都可以在localhost上彼此通信。这被称为ip-per-pod模型。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#在Docker中查看docker network inspect bridge#可看到副本集的容器，都是pod，而非container#这也证明container共享pod的网络空间#注意它的网关便是docker0[ &#123; &quot;Name&quot;: &quot;bridge&quot;, &quot;Id&quot;: &quot;68bc0cf07a4d7666e1d35f2c1cf179ae8605b431353ba93446abc898de086a9c&quot;, &quot;Created&quot;: &quot;2018-07-23T17:45:54.42038221+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;10.254.76.0/24&quot;, &quot;Gateway&quot;: &quot;10.254.76.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Containers&quot;: &#123; &quot;7d2e6561fa81730ae05743f78871666df75cf5e6f483b71da33137823c172333&quot;: &#123; &quot;Name&quot;: &quot;k8s_POD.24f70ba9_hello-world-3198537413-138pg_default_adb8f0fe-8fea-11e8-b10b-000c29aa7e75_785c4a84&quot;, &quot;EndpointID&quot;: &quot;bf50c5a71ad26531a370a73ce8da5903d32b9e2f8b8397d7405b914203071c45&quot;, &quot;MacAddress&quot;: &quot;02:42:0a:fe:4c:06&quot;, &quot;IPv4Address&quot;: &quot;10.254.76.6/24&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125;, &quot;ea9fbf660f27943b866759a084dc26457474d73c50082939f157ed1dfe0bc806&quot;: &#123; &quot;Name&quot;: &quot;k8s_POD.24f70ba9_hello-world-3198537413-ddgb3_default_adb90c8c-8fea-11e8-b10b-000c29aa7e75_0452e1f4&quot;, &quot;EndpointID&quot;: &quot;e83401827e0e6d2896eb46c7b252594c1694ca119d0cbd74c29383209b80a128&quot;, &quot;MacAddress&quot;: &quot;02:42:0a:fe:4c:02&quot;, &quot;IPv4Address&quot;: &quot;10.254.76.2/24&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;, &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;, &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 如何实现k8s网络模型How to implement the Kubernetes networking model 有多种方式实现此网络模型，以下做一个概述。 ACI AOS from Apstra Big Cloud Fabric from Big Switch Networks Cilium CNI-Genie from Huawei Contiv Contrail Flannel Google Compute Engine Kube-router L2 networks and linux bridging Multus NSX-T Nuage Networks VCS OpenVSwitch OVN Project Calico Romana Weave Net from Weaveworks 日志架构Logging Architecture 应用程序和系统日志可以帮助你了解集群内部发生的情况。大多数现代应用程序都有某种日志机制，因此，大多数容器化引擎同样设计来支持多种日志。容器化应用程序最简单、最受欢迎的日志方法是写入stdout和stderr。 但是，容器引擎或runtime提供的本地(native)功能通常不足以构建完整的日志解决方案。例如，如果container crashe、pod evicted、node dies，你通常仍然希望访问应用程序的日志。因此，日志应独立于container、pod、node，并具有单独存储(separate storage)和生命周期(lifecycle)。这个概念称为集群级日志(cluster-level-loggin)。集群级日志需要单独的后端来存储(store)、分析(analyze)、查询(query)日志。k8s不提供日志数据的本地存储解决方案，但你可以将许多现有的日志解决方案集成到k8s集群中。 集群级日志架构假设在集群内部或外部存在日志记录后端。 k8s基本日志Basic logging in Kubernetes 本节中，k8s将日志记录到到标准输出。 123456789101112131415161718192021222324252627282930313233343536vim /etc/k8s/test/counter-pod.yaml#此pod每秒输出一条信息apiVersion: v1kind: Podmetadata: name: counterspec: containers: - name: count image: busybox args: [/bin/sh, -c, &apos;i=0; while true; do echo &quot;$i: $(date)&quot;; i=$((i+1)); sleep 1; done&apos;]#创建#kubectl create -f /etc/k8s/test/counter-pod#不指定命名空间，则默认default#也可在配置文件里指定命名空间#kubectl create -f /etc/k8s/test/counter-pod --namespace=test#查看#如果pod有多个容器，则应该指定容器名称kubectl logs counter0: Fri Aug 10 07:43:09 UTC 20181: Fri Aug 10 07:43:10 UTC 20182: Fri Aug 10 07:43:11 UTC 20183: Fri Aug 10 07:43:12 UTC 20184: Fri Aug 10 07:43:13 UTC 20185: Fri Aug 10 07:43:14 UTC 20186: Fri Aug 10 07:43:15 UTC 20187: Fri Aug 10 07:43:16 UTC 20188: Fri Aug 10 07:43:17 UTC 20189: Fri Aug 10 07:43:18 UTC 2018...... 节点级日志记录Logging at the node level 容器化应用程序写入stdout, stderr的所有内容，都由容器引擎处理并重定向到某处。Docker容器引擎可修改日志驱动程序，将日志写入到其它地方(file, json, fluent…)。 注意Docker json日志驱动将每一行视为单独的消息，它没有直接支持多行消息，你需要使用更高级别来处理它。 默认情况下，如果容器重启，kubelet会使用其日志保留一个已终止(terminated)的容器。如果从节点上驱逐pod，则所有相应的容器也会被驱逐(包括日志)。 节点级日志记录中，一个重要考虑因素是实现日志轮询(log rotation)，以便日志不会占用节点所有可用存储。k8s目前不负责轮询日志，但部署工具应该配置方案来解决日志轮询问题。例如，在k8s集群中，部署一个脚本程序，用于日志轮询。或设置Docker container runtime的log-opt标志已自动轮询应用程序日志。 当在基本日志记录中运行kubectl logs命令时，节点上的kubelet会处理请求直接从日志文件读取，返回响应的内容。注意： 如果某个外部系统已执行轮询，则kubectl logs只能获取到最新的日志文件。 system component logs有两种类型的系统组件: run in container: 如kube-proxy not run in container: 如kubelet, Docker 在使用systemd的机器上，kubelet和container runtime将日志写到journald。如果没有systemd，则写到/var/log/下。容器内的系统组件始终将日志写入/var/log目录下，绕过默认的日志机制。与容器日志类似，在/var/log/目录下的系统组件日志也应该被轮询。 集群级日志架构Cluster-level logging architectures k8s官方没有提供原生的集群级日志记录，但你可以考虑集中常见方法： 在每个节点上使用node-level logging agent 用于记录应用程序pod的专用sidecar container 将日志直接从应用程序推送到后端 Using a node logging agent 你可以通过在每个节点上包含一个 节点级日志记录代理 来实现集群级日志记录。它是一个用于公开日志或将日志推送到后端的专用工具。通常，此日志代理是一个容器，它可以访问该节点上所有应用程序容器的日志文件的目录。 由于日志记录代理必须在每个节点上运行，因此，将其实现为节点上的DaemonSet replica, manifest pod, dedicated native process是很常见的。然后，后两种方法已被弃用，并且非常不建议。 对于k8s集群，使用节点级日志代理是最常见和鼓励的方法，因为它在每个节点上只创建一个Agent，并且不需要对节点上运行的应用程序进行任何更改。然而，节点级日志仅适用于应用程序的stdout和stderr。 k8s并未指定logging Agent，但有两个可选的日志代理与k8s一同打包。两者都使用fluentd的自定义配置作为节点上的代理。 Stackdriver Logging: 用于Google Cloud Platform Elasticsearch Using a sidecar container with the logging agent你可通过以下方式使用sidecar container: sidecar container将应用程序的日志传输到自己的stdout sidecar container容器运行一个Logging Agent，此代理从应用程序容器中获取日志 通过让sidecar container的stream流向他们自己的stdout/stderr，你可利用已经在每个节点上运行的kubelet和logging agent。sidecat container从file、socket、journald读取日志。每个单独的sidecar container将日志打印到自己的stdout/stderr。此方法允许你从应用程序的不同部分分离多个日志流，其中一些可能缺乏对写入stdout/stderr的支持。重定向日志背后的逻辑是最小的，因此它几乎不是一个重要的开销。此外，因为stdout/stderr由kubelet处理，所以你可以使用如kubectl logs这样的内置工具。 考虑如下栗子，pod运行单个容器，此容器使用两种不同的日志格式写入两个不同的日志。 two-files-counter-pod.yaml 1234567891011121314151617181920212223242526apiVersion: v1kind: Podmetadata: name: counterspec: containers: - name: count image: busybox args: - /bin/sh - -c - &gt; i=0; while true; do echo "$i: $(date)" &gt;&gt; /var/log/1.log; echo "$(date) INFO $i" &gt;&gt; /var/log/2.log; i=$((i+1)); sleep 1; done volumeMounts: - name: varlog mountPath: /var/log volumes: - name: varlog emptyDir: &#123;&#125; 即使你设法将两个组件重定向到容器的stdout，在同一个日志流中包含不同格式的日志条目也会很麻烦。相反，你可以引入两个sidecar container。每个sidecar container可以从共享卷(shared volume)中tail特定的日志文件，然后将日志重定向到自己的stdout。 这是pod运行两个sidecat container的配置文件。三个容器共享了/var/log。 two-file-counter-pod-streaming-sidecar.yaml 1234567891011121314151617181920212223242526272829303132333435363738apiVersion: v1kind: Podmetadata: name: counterspec: containers: - name: count image: busybox args: - /bin/sh - -c - &gt; i=0; while true; do echo "$i: $(date)" &gt;&gt; /var/log/1.log; echo "$(date) INFO $i" &gt;&gt; /var/log/2.log; i=$((i+1)); sleep 1; done volumeMounts: - name: varlog mountPath: /var/log - name: count-log-1 image: busybox args: [/bin/sh, -c, 'tail -n+1 -f /var/log/1.log'] volumeMounts: - name: varlog mountPath: /var/log - name: count-log-2 image: busybox args: [/bin/sh, -c, 'tail -n+1 -f /var/log/2.log'] volumeMounts: - name: varlog mountPath: /var/log volumes: - name: varlog emptyDir: &#123;&#125; 现在运行此pod，并单独访问每个日志流: 123456789101112131415161718192021222324252627282930313233#runkubectl create -f /etc/k8s/test/two-file-counter-pod-streaming-sidecar.yaml#getkubectl get pod/counter -o wideNAME READY STATUS RESTARTS AGE IP NODEcounter 3/3 Running 0 9m 10.244.2.9 salt01#kubectl logs counterError from server (BadRequest): a container name must be specified for pod counter, choose one of: [count count-log-1 count-log-2]#logskubectl logs counter count-log-10: Tue Aug 14 02:58:29 UTC 20181: Tue Aug 14 02:58:30 UTC 20182: Tue Aug 14 02:58:31 UTC 20183: Tue Aug 14 02:58:32 UTC 2018kubectl logs counter count-log-2Tue Aug 14 02:58:29 UTC 2018 INFO 0Tue Aug 14 02:58:30 UTC 2018 INFO 1Tue Aug 14 02:58:31 UTC 2018 INFO 2Tue Aug 14 02:58:32 UTC 2018 INFO 3 集群中安装的节点级代理会自动获取这些日志流，而无需进一步配置。如果愿意，可将代理配置为根据源容器解析日志行。 注意，进错CPU和内存使用率很低，将日志写入文件然后将它们流式传输到stdout会使磁盘使用量增加一倍。如果你有一个应用程序将日志写到单个文件，通常最好将/dev/stdout设置为目标，而不是实现流式sidecar container方法。 sidecar container还可用于应用程序本身日志轮询。然而，建议直接使用stdout/stderr并将日志的轮询和保留交给kubelet。 Sidecar container wiht a logging agent 如果节点级日志记录代理对你来说不够灵活，你可以创建一个带有单独日志记录代理程序的sidecar container，该代理可专门配置来与你的程序一起运行。 注意：在sidecar container使用日志记录代理将会消耗大量资源。此外，你将无法使用kubectl logs命令访问这些日志，因为它们不受kubelet控制。 栗子使用fluentd作为logging agent。有两个可用于实现此方法的配置文件： ConfigMap使用ConfigMap来配置fluentd。具体配置参考fluentd官方文档。 fluentd-sidecat-config.yaml 12345678910111213141516171819202122232425apiVersion: v1kind: ConfigMapmetadata: name: fluentd-configdata: fluentd.conf: | &lt;source&gt; type tail format none path /var/log/1.log pos_file /var/log/1.log.pos tag count.format1 &lt;/source&gt; &lt;source&gt; type tail format none path /var/log/2.log pos_file /var/log/2.log.pos tag count.format2 &lt;/source&gt; &lt;match **&gt; type google_cloud &lt;/match&gt; pod运行fluentd的sidecat container的pod。它挂载一个volume让fluentd获取配置数据。下面需要用到k8s.gcr.io/fluentd-gcp:1.30镜像，请提前准备。要挂载目录，请创建。 two-files-counter-pod-agent-sidecar.yaml 123456789101112131415161718192021222324252627282930313233343536373839apiVersion: v1kind: Podmetadata: name: counterspec: containers: - name: count image: busybox args: - /bin/sh - -c - &gt; i=0; while true; do echo &quot;$i: $(date)&quot; &gt;&gt; /var/log/1.log; echo &quot;$(date) INFO $i&quot; &gt;&gt; /var/log/2.log; i=$((i+1)); sleep 1; done volumeMounts: - name: varlog mountPath: /var/log - name: count-agent image: k8s.gcr.io/fluentd-gcp:1.30 env: - name: FLUENTD_ARGS value: -c /etc/fluentd-config/fluentd.conf volumeMounts: - name: varlog mountPath: /var/log - name: config-volume mountPath: /etc/fluentd-config volumes: - name: varlog emptyDir: &#123;&#125; - name: config-volume configMap: name: fluentd-config 这仅仅是一个栗子。你可以使用其它logging agent取代fluentd，如filebeat, logstash… Exposing logs directly from the application 你可以通过直接公开每个应用程序的日志或push日志来实现集群级日志记录。就相当于在写得程序中加入日志收集和处理。但是，这种日志记录机制超出了k8s的范围。 kubelet垃圾回收Configuring kubelet Garbage Collection 垃圾回收是一个有用的kubelet功能，它将清理未使用的镜像和容器。每分钟对容器执行垃圾回收，每五分钟对镜像进行垃圾回收。不推荐使用额外的垃圾回收工具，因为这可能会破坏kubelet的行为。 镜像回收Image Collection k8s在cadvisor的配合下，通过imageManager管理所有镜像的生命周期。镜像垃圾回收策略考虑了两个要素： HighThresholdPercent LowThresholdPercent 磁盘使用率高于高阈值将触发垃圾回收，垃圾回收将删除最近最少使用的镜像，直到满足低阈值。 镜像垃圾回收的kubelet flag: 123456789#触发镜像垃圾回收的磁盘使用率百分比#默认值 90%image-gc-high-threshold#镜像垃圾回收尝试释放磁盘使用的百分比#默认值 80%image-gc-low-threshold 容器回收Container Collection 容器垃圾回收策略考虑了三个用户定义的变量： MinAge MaxPerPodContainer MaxContainers MinAge是容器可以被垃圾回收的最小年龄。设置为0可禁用。MaxPerPodContainer是允许每个pod对允许拥有的最大死容器数。设置小于0可禁用。MaxContainers是总死亡容器的最大数量。设置小于0可禁用。 kubelet将对未识别、删除或标志设置的边界之外的容器起作用。通常首先移除最旧的容器。不受kubelet管理的容器不受容器垃圾回收的限制。 容器垃圾回收的kubelet flag: 1234567891011121314151617#完成的容器在垃圾回收之前的最低年龄#默认值 0min，意味着每个完成的容器都将被垃圾回收minimum-container-ttl-duration#每个容器要保留的最大旧实例数#默认值 1#强烈建议使用足够大的值，以允许每个预期容器保留至少1个死亡容器maximum-dead-containers-per-container#全局要保留的最大容器实例数#默认值 -1，意味着禁用#处于类似的原因，同样建议使用较大的值maximum-dead-containers 启用一些kubelet垃圾回收标志未来将被启用或取代。 Existing Flag New Flag Rationale –image-gc-high-threshold –eviction-hard or –eviction-soft existing eviction signals can trigger image garbage collection –image-gc-low-threshold –eviction-minimum-reclaim eviction reclaims achieve the same behavior –maximum-dead-containers xxx deprecated once old logs are stored outside of container’s context –maximum-dead-containers-per-container xxx deprecated once old logs are stored outside of container’s context –minimum-container-ttl-duration xxx deprecated once old logs are stored outside of container’s context –low-diskspace-threshold-mb –eviction-hard or eviction-soft eviction generalizes disk thresholds to other resources –outofdisk-transition-frequency –eviction-pressure-transition-period eviction generalizes disk pressure transition to other resources Federation先跳过，后面来学习。 ProxyProxies in Kubernetes 使用Kubernetes时可能会遇到几种不同的代理。代理已经取代了重定向功能，重定向已被弃用。 kubectl proxy runs on a user’s desktop or in a pod proxies from a localhost address to the Kubernetes apiserver client to proxy uses HTTP proxy to apiserver uses HTTPS locates apiserver adds authentication headers apiserver proxy is a bastion built into the apiserver connects a user outside of the cluster to cluster IPs which otherwise might not be reachable runs in the apiserver processes client to proxy uses HTTPS (or http if apiserver so configured) proxy to target may use HTTP or HTTPS as chosen by proxy using available information can be used to reach a Node, Pod, or Service does load balancing when used to reach a Service kube proxy runs on each node proxies UDP and TCP does not understand HTTP provides load balancing is just used to reach services A Proxy/Load-balancer in front of apiserver existence and implementation varies from cluster to cluster(e.g. nginx) sits between all clients and one or more apiservers acts as load balancer if there are several apiservers 云负载均衡器 由云服务商提供 当k8s服务有LoadBalancer类型时自动创建 仅使用udp/tcp 具体详情因云服务商而异 控制器管理器指标Controller manager metrics 控制器管理器指标，提供有关控制器管理器性能和运行状况的重要信息。 这些指标包括常见的Go语言运行时指标、控制器特定指标。可用于衡量集群的运行状况。 在集群中，当控制器管理器运行时，可从http://localhost:10252/metrics获取控制器管理器指标。 12345netstat -nltup | grep 10252tcp 0 0 127.0.0.1:10252 0.0.0.0:* LISTEN 11088/kube-controll curl http://localhost:10252/metrics 这些指标以prometheus format格式发出，并且是人类可读的。 附加组件Installing Addons 附加组件扩展了k8s的功能。 网络和网络策略Networking and Network Policy ACI： 通过 Cisco ACI提供集成的容器网络和网络完全 Calico： 是一个安全的L3网络和网络策略提供商 Canal: 将Flannel和Calico联合起来，提供网络和网络策略 Cilium： 是一个L3网络和网络策略插件 CNI-Genie： 使k8s能够无缝连接到各种CNI插件 Contiv： 提供可配置的网络，用于各种用例和丰富的策略框架 Flannel： 是一个可以与k8s一起使用的overlay网络提供商 Knitter： 是一个支持k8s多个网络的网络解决方案 Multus： 是一个用于k8s中多个网络支持，以支持所有CNI插件的多插件 NSX-T： 提供VMware NSX-T与容器协调器之间的集成 Nuage： 是一个SDN平台，可在k8s Pod和non-k8s环境之间提供基于策略的网络，并提供可见性和安全性监控 Romana： 用于Pod网络的L3网络解决方案 Weave Net： 提供网络和网络策略，将在网络分区的两侧进行工作，而不需要外部数据库 服务发现Service Discovery CoreDNS： 是一个灵活，可扩展的DNS服务器，可作为用于pod的集群DNS。 可视化，控制Visualization, Control Dashboard： k8s的Dashboard Web Interface Weave Scope： 是一个用于以图形可视化显示container, pod, service… k8s架构Kubernetes Architecture Nodenode是k8s中的工作机器，以前称为minion。也就是集群中的一台主机。节点可以是VM或物理机。每个节点都具有用于运行pod所需的服务，并由master组件管理。节点上的服务包括docker, kubelet, kube-proxy。 节点状态Node Status 节点的状态包含以下信息： 地址(Address) 条件(Condition) 容量(Capacity) 信息(Info) 地址这些字段的使用取决于机器配置。 HostName： 节点内核报告的主机名 ExternalIP： 通常是可从外部路由的节点IP地址 InternalIP： 通常是仅在集群内可路由的节点IP地址 123456789101112kubectl get node -o wideNAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIMEmaster Ready master 7d v1.11.1 192.168.31.49 &lt;none&gt; CentOS Linux 7 (Core) 3.10.0-862.9.1.el7.x86_64 docker://1.13.1node Ready &lt;none&gt; 7d v1.11.1 192.168.31.174 &lt;none&gt; CentOS Linux 7 (Core) 3.10.0-862.9.1.el7.x86_64 docker://1.13.1salt01 Ready &lt;none&gt; 1d v1.11.1 192.168.31.159 &lt;none&gt; CentOS Linux 7 (Core) 3.10.0-862.9.1.el7.x86_64 docker://1.13.1kubectl describe node/salt01Addresses: InternalIP: 192.168.31.159 Hostname: salt01 条件该字段描述了所有运行中节点的状态。节点条件使用JSON对象表示。 条件 描述 OutOfDisk True(节点上的可用空间不足以添加新pod), 否则为False Ready True(节点健康并准备好接受pod) False(节点不健康且不接受pod) Unknown(节点控制器在最后一个node-monitor-grace-period期限内没有从节点收到消息。默认40s) MemoryPressure True(节点内存有压力，即内存不足)，否则为False PIDPressure True(进程存在压力，即节点上有太多进程)，否则为False DiskPressure True(磁盘大小存在压力，即磁盘容量较低), 否则为False NetworkUnavailable True(节点网络配置错误)，否则为False ConfigOK True(kubelet配置正确)，否则为False 123456789kubectl describe node/salt01Conditions: Type Status LastHeartbeatTime LastTransitionTime Reason Message ---- ------ ----------------- ------------------ ------ ------- OutOfDisk False Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:51:40 +0800 KubeletHasSufficientDisk kubelet has sufficient disk space available MemoryPressure False Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:51:40 +0800 KubeletHasSufficientMemory kubelet has sufficient memory available DiskPressure False Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:51:40 +0800 KubeletHasNoDiskPressure kubelet has no disk pressure PIDPressure False Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:51:40 +0800 KubeletHasSufficientPID kubelet has sufficient PID available Ready True Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:53:00 +0800 KubeletReady kubelet is posting ready status 容量描述节点上的可用资源：CPU，内存，可调度到节点上的最大pods数。 1234567kubectl describe node/salt01Capacity: cpu: 2 ephemeral-storage: 49250820Ki hugepages-2Mi: 0 memory: 3881332Ki pods: 110 信息关于节点的一般信息，如Kernel版本，Kubernetes版本，Docker版本，OS… 123456789101112kubectl describe node/salt01System Info: Machine ID: e48d6bf22f9b4c8da5cb1a07b2fec730 System UUID: 564D1413-905B-64D6-E9A2-92E37F9B5BDA Boot ID: 1df89a81-77a4-44a0-9241-e6d766795e32 Kernel Version: 3.10.0-862.9.1.el7.x86_64 OS Image: CentOS Linux 7 (Core) Operating System: linux Architecture: amd64 Container Runtime Version: docker://1.13.1 Kubelet Version: v1.11.1 Kube-Proxy Version: v1.11.1 管理Management 与Pod与Service不同，k8s本身并不创建节点： 它由云服务商创建，或存在于物理机/虚拟机的pool中。当k8s创建节点时，它实际上只是创建了一个表示节点的对象。创建之后，k8s将检查节点是否有效。 栗子： 12345678910&#123; "kind": "Node", "apiVersion": "v1", "metadata": &#123; "name": "10.240.79.157", "labels": &#123; "name": "my-first-k8s-node" &#125; &#125;&#125; k8s将在内部创建节点对象，并通过基于metadata.name字段的运行状况检查来验证节点。如果节点有效(valid)，即所有必要的服务都已运行，它就符合了运行pod的条件。否则它将被所有的集群动作忽略，直到它变为有效。请注意，Kubernetes将保持无效(invalide)节点的对象，除非它被手动删除。Kubernetes将持续检查节点是否变得可用。 目前，有3个组件与k8s节点接口交互： Node Controller kubelet kubectl 节点控制器节点控制器是一个k8s Master组件，用于管理节点的各个方面。 节点控制器在节点的生命周期中具有多个角色(role)。第一个便是在节点注册时为其分配CIDR地址块。第二个是使节点控制器的内部节点列表与可用机器保持一致。只要节点不健康，节点控制器就会询问该节点是否仍然可用。如果不是，则节点控制器从其节点列表中删除该节点。第三个是监控节点的健康状况。当节点不可达时，节点控制器负责更新节点的条件(condition)状态，从Ready变为Unknown。如果节点继续无法访问，则稍后从节点中驱逐(evict)所有pod(graceful termination)。默认超时时间为40s开始上报Unknown，然后5min之后开始驱逐pods。节点控制器通过--node-nonitor-period秒检查每个节点的状态。 在大多数情况下，节点控制器将驱逐率(evication rate)限制为--node-eviction-rate(默认值 0.1)每秒。这意味着它将不会每10s从超过1个节点驱逐pod。 当给定可用区域中的节点变得不健康时，节点驱逐行为会发生变化。同时，节点控制器检查此区域中不健康节点的百分比。如果节点不健康比例至少为--unhealthy-zone-threshold(默认值 0.55)，那么驱逐率会降低；如果集群很小，小于或等于--large-cluster-size-threshold(默认值 50)，则停止驱逐；否则，驱逐率减小到每秒--secondary-node-eviction-rate(默认值 0.01)。每个可用区域实施这些策略的原因是，一个可用区域可能与其它可用区域保持连接。 在可用区域之间传播节点的一个关键原因是，当整个区域出现故障时，工作负载可以转移到健康区域。因此，如果区域中的全部节点都不健康，则节点控制器以正常速率--node-eviction-rate驱逐。The corner case是当所有区域都不健康时。在这种情况下，节点控制器假定Master连接存在一些问题，并在某些连接恢复之前停止所有驱逐。 节点自注册Self-Registration of Nodes 当kubelet标志--register-node为true(默认)时，它会尝试向API server注册自己。这是大多数发行版使用的首选模式。 对于自注册，kubelet使用如下选项： 12345678910111213141516171819202122#向API server验证自身的凭据路径--kubeconfig#r如何与云服务商交流--cloud-provider#向API server自动注册--register-node#节点IP地址--node-ip#集群中注册节点时要添加的标签--node-labels#指定kubelet将节点状态发送到master的频率--node-status-update-frequency 目前，任何kubelet都有权 create/modify 任何节点资源，但实际上它只 创建/修改 自己的节点资源。(将来，k8s打算只允许kubelet修改自己的节点资源) 手动管理节点 如果希望手动创建节点对象，请设置kubelet标志--register-node=false。修改包括在节点上设置标签(label)并将其标记为不可调度(unschedulable)。 节点容量Node Capacity 节点容量(cpu, memory)是节点对象的一部分。通常，当创建节点对象时，节点注册自己并上报其容量。如果是手动管理节点，则需要你在添加节点时设置节点容量。k8s调度器确保节点上的所有pod都有足够的资源。它检查节点上容器请求的总和不大于节点容量。它包括由kubelet启动的所有容器，但不包括由容器运行时直接启动的容器，也不包括容器外部的任何进程。所以，尽量不要在k8s集群节点上运行额外进程。 如果要为non-pod进程保留资源，你可以创建保留(placeholder)pod。将内存和CPU的值设置为要保留的资源量。 123456789101112apiVersion: v1kind: Podmetadata: name: resource-reserverspec: containers: - name: sleep-forever - image: k8s.gcr.io/pause:0.8.0 - resources: requests: cpu: 100m memory: 100Mi API对象Node is a top-level resource in the Kubernetes REST API. 节点通信Master-Node communication Master(APIserver)与k8s cluster之间的通信。目的是允许用户自定义其安装以强化网络配置，以便集群可在不受信任的网络上运行。 Cluster-&gt;Master从Cluster到Master的所有通信路径都终止于API server。在典型部署中，API server配置为在安全的HTTPS(443)端口上监听远程连接，并启用一种或多种形式的Client认证。应该为节点配置集群的公共根证书，以便他们可以使用有效证书安全地连接到API server。希望连接到API server的Pod可以利用Service Account安全地执行此操作，这样k8s在实例化时自动将公共根证书和有效bearer token注入到Pod中。the kubernetes service配置了一个虚拟IP地址，该地址被重定向到API server的HTTPS endpoint。Master组件还通过安全端口与Cluster API server通信。 123kubectl get serviceNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 8d 因此，默认情况下，从Cluster到Master的连接的默认操作模式是安全的，可在不受信任网络/公共网络上运行。 Master-&gt;Cluster从Master(API server)到Cluster有两条主要通信路径： API server -&gt; kubelet API server -&gt; node, pod, service API server -&gt; kubelet从API server到kubelet(它运行在集群中的每个节点上)。 从API server到kubelet的连接用于： 获取Pod的日志 附加到运行的Pod 提供kubelet的端口转发功能 这些连接终止于kubelet的HTTPS endpoint。默认情况下，API server不会验证kubelet的证书，这会使连接可能受到中间人工具，并且不安全地运行在不受信任/公共的网络上。要验证此连接，使用--kubelet-certificate-authority标志位API server提供根证书，用于验证kubelet的证书。 如果无法做到，请在API server和kubelet之间使用SSH隧道保障连接安全。 API server -&gt; node, pod, service从API server到node, pod, service的连接默认为纯HTTP，因此既不需要认证也未加密。他们可以通过在API URI的前缀使用https://来运行安全的HTTPS，但他们不会验证HTTPS endpoint提供的证书，也不会提供客户端凭据。因此连接将被加密，它不会提供任何完整性保证。 云控制器管理器Cloud Controller Manager 暂时跳过！ 扩展k8s 扩展k8s集群Extending your Kubernetes Cluster k8s具有高度可配置化和可扩展化。 定制方法可大致分为配置，只涉及更改标志，本地配置文件或API资源；扩展，设计运行其它程序或服务。 扩展模式Extensions Patterns k8s旨在通过编写客户端程序实现自动化。任意 read/write k8s API的程序都可以提供有用的自动化。自动化可在集群上启用或关闭。自动化通常适用于k8s集群，包括托管集群和管理安装。 有一种编写与k8s一起使用的称为控制器模式(Controller Pattern)客户端程序的特定模式。控制器通常读取对象的.spec，可能做些事情，然后更新对象的.status。控制器(Controller)是一个k8s client。当k8s为client并调用远程服务时，它被称为Webhook。远程服务被称为Webhook Backend。与控制器一样，Webhook确实增加了一个失败点。 在webhook模式中，k8s 向远程服务发出网络请求。在二进制插件模型中，k8s执行二进制程序。二进制插件由kubelet和kubectl使用。 扩展点Extension Points k8s 系统的扩展点: 用户使用kubectl与k8s API进行交互 API server处理所有请求 API server提供各种资源 k8s调度器决定将pod放在哪个节点上 k8s大部分行为都是由控制器实现的 kubelet帮助pod在集群网络上显示为具有自己IP的虚拟服务 kubelet还可挂载和解挂容器的卷 如果你不确定如何开始，查看如下流程图： API扩展API Extensions User-Defined Types如果想要定义新的控制器、应用程序配置对象、声明性API并管理他们，请考虑向k8s添加自定义资源。不要讲自定义资源用作应用程序、用户、监控数据的数据存储。 Combining New APIs with Automation通常，当添加新API时，还会添加一个 read/write 新API的控制循环。当自定义API和控制循环的组合用于管理特定的，通常是有状态的应用程序时，这被称为操作者模式(Operator Pattern)。 Changing Built-in Resources通过自定义资源添加扩展k8s API时，添加的资源始终属于新的API组。你无法替换或修改已经存在的API组。添加API不会直接影响现有API的行为，但API Access Extensions会影响现有API的行为。 API Access Extensions当请求到达k8s API server时，它首先进行身份验证，然后授权，然后进行各种准入控制。每个步骤都提供了扩展点。 Authentication身份验证将所有请求中的Header或证书映射到发出请求的客户端的用户名中。 Authorization授权确定特定用户是否可以对API资源进行读写和其它操作。它只是在整个资源的层面上工作，不基于任意对象字段进行区分。 Dynamic Admission Control当请求授权之后，如果它是一个写操作，它还需要通过Admission Control步骤。除了内建步骤之外，还有其它扩展： Image Policy webhook限制可在容器中运行的镜像 为了做出任意的admission control决策，可使用普通admission webhook 初始化程序可在创建对象之前修改对象的控制器 基础设施扩展Infrastructure Extensions Storage PluginsFlex Volumes允许用户通过kubelet调用二进制插件来安装卷，来安装没有内置支持的卷类型 Device Plugins设备插件允许节点通过设备发现插件发现新的节点资源 Network Plugins支持不同的网络结构 Scheduler Extensions调度器是一种特殊类型的控制器，用于监视Pod，并将Pod分配给节点。 扩展k8s APIExtending the Kubernetes API 在聚合层扩展k8s APIExtending the Kubernetes API with the aggregation layer 聚合层允许在集群中安装其它k8s-style的API。 自定义资源Custom Resources 自定义资源是k8s API的扩展，包括何时向k8s集群添加自定义资源以及何时使用独立服务。 资源是k8s API中的端点(endpoint)，用于存储某种API对象的集合。如，内建的pods资源包含了Pod对象的集合。自定义资源是k8s API的扩展，不一定在每个k8s集群上都可用。换句话说，它代表了特定k8s的定制安装。自定义资源可通过动态注册在正在运行的集群中出现和消失，集群管理员可独立于集群本身更新自定义资源。安装自定义资源后，用户可使用kubectl创建和访问其对象。 Custom controllers 自定义字段本身可让你存储和检索结构化数据。只有与控制器结合使用才能成为真正的声明性API。declare API允许你声明或指定资源的所需状态，并尝试将实际状态与此期望状态相匹配。这里，控制器将结构化的数据解释为用户期望状态的记录，并且不断采取行动以实现和维护该状态。自定义控制器是一种用户可在正在运行的集群上进行部署和更新，而与集群自身的生命周期无关的控制器。自定义控制器可使用任何类型的资源，但与自定义资源结合使用时，它们更有效。 Should I add a custom resource to my Kubernetes Cluster? 当创建新的API时，考虑是使用k8s cluster API还是让API独立运行。 Consider API aggregation if: Prefer a stand-alone API if: Your API is Declarative. Your API does not fit the Declarative model. You want your new types to be readable and writable using kubectl. kubectl support is not required You want to view your new types in a Kubernetes UI, such as dashboard, alongside built-in types. Kubernetes UI support is not required. You are developing a new API. You already have a program that serves your API and works well. You are willing to accept the format restriction that Kubernetes puts on REST resource paths, such as API Groups and Namespaces. (See the API Overview.) You need to have specific REST paths to be compatible with an already defined REST API. Your resources are naturally scoped to a cluster or to namespaces of a cluster. Cluster or namespace scoped resources are a poor fit; you need control over the specifics of resource paths. You want to reuse Kubernetes API support features. You don’t need those features 声明性APIDeclarative APIs 在一个声明性API中，通常： 你的API由相对较少的相对较小的对象组成 应用程序或基础结构的对象定义配置 对象很少更新 人们通常需要读写对象 对象的主要操作时CRUD 跨对象的事务不是必需的：API表示期望状态，而不是精确的状态 imperative API不是声明性的，你的API可能不是声明性的标志包括： 客户端说执行此操作，完成后获得同步响应 客户端说执行此操作，然后获取操作ID，并且必须检查单独的Operation对象以确定请求的完成 谈论Remote Procedure Calls(RPCs) 直接存储大量数据 需要高带宽访问 存储最终用户数据，或应用程序处理的其它大规模数据 对象非CRUD的自然操作 API不容易建模为对象 使用操作ID或操作对象表示挂起的操作 Should I use a configMap or a custom resource? 如果符合以下任意条件，请使用ConfigMap: 存在现有的，记录完备的配置文件格式 你希望将整个配置文件放入ConfigMap的一个key中 配置文件的主要用途是在集群上的Pod中运行的程序使用该文件来配置自身 文件的消费者更喜欢使用Pod中的文件或环境变量，而不是k8s API 你希望在文件更新时通过部署执行滚动升级 如果符合以下大部分情况，请使用自定义资源： 你希望使用k8s client library和CLI来创建和更新新资源 你希望来自kubectl的顶级支持 你希望构建新的自动化，监视新对象的更新，然后CRUD其它对象 你希望编写处理对象更新的自动化 你希望使用k8s API约定，如.spec, .status, .metadata 你希望对象是受控资源集合的抽象，或其它资源的汇总 添加自定义资源k8s提供了两种方式来向你的集群中添加自定义资源： CRD很简单，无需任何编程即可创建 API聚合需要编程，但允许更多控制API行为，如数据的存储方式和API版本间的转换 聚合API是位于主API server后面的从属API server，它充当代理。这种安排称为API聚合(AA, API Aggregation)。CRD允许用户添加新类型的资源，而无需添加其它API server，你无需了解API聚合即可使用CRD。无论如何安装，新资源都成为自定义资源，以区别于内置的k8s 资源。 自定义资源定义自定义资源定义 API资源允许你去定义自定义资源。定义CRD对象会创建一个新的自定义资源，其中包含指定的名称和架构。k8s API提供并处理自定义资源的存储。这使你无需编写自己的API server来处理自定义资源，但实现的一般特性意味着你的灵活性低于API server聚合。 API server aggregation通常，k8s API中的每个资源都需要处理REST 请求的代码并管理对象的持久化存储。k8s API server处理pod等内建资源，还可通过CRD处理自定义资源。聚合层允许你通过编写和部署自己的独立API server为自定义资源提供专门的实现。API server将请求委托给你处理的自定义资源，使其对所有客户端可用。 为添加自定义资源选择一个方法通常情况下，CRD很适合，如果： 你有少数几个领域 你正在使用公司内的资源，或作为小型开源项目的一部分 易用性比较： CRDs Aggregated API Do not require programming. Users can choose any language for a CRD controller. Requires programming in Go and building binary and image. Users can choose any language for a CRD controller. No additional service to run; CRs are handled by API Server. An additional service to create and that could fail. No ongoing support once the CRD is created. Any bug fixes are picked up as part of normal Kubernetes Master upgrades. May need to periodically pickup bug fixes from upstream and rebuild and update the Aggregated APIserver. No need to handle multiple versions of your API. For example: when you control the client for this resource, you can upgrade it in sync with the API. You need to handle multiple versions of your API, for example: when developing an extension to share with the world. 高级功能和灵活性： Feature Description CRDs Aggregated API Validation Help users prevent errors and allow you to evolve your API independently of your clients. These features are most useful when there are many clients who can’t all update at the same time. Yes. Most validation can be specified in the CRD using OpenAPI v3.0 validation. Any other validations supported by addition of a Validating Webhook. Yes, arbitrary validation checks Defaulting See above Yes, via a Mutating Webhook; Planned, via CRD OpenAPI schema. Yes Multi-versioning Allows serving the same object through two API versions. Can help ease API changes like renaming fields. Less important if you control your client versions. No, but planned Yes Custom Storage If you need storage with a different performance mode (for example, time-series database instead of key-value store) or isolation for security (for example, encryption secrets or different No Yes Custom Business Logic Perform arbitrary checks or actions when creating, reading, updating or deleting an object Yes, using Webhooks. Yes Scale Subresource Allows systems like HorizontalPodAutoscaler and PodDisruptionBudget interact with your new resource Yes Yes Status Subresource Finer-grained access control: user writes spec section, controller writes status section. Allows incrementing object Generation on custom resource data mutation (requires separate spec and status sections in the resource) Yes Yes Other Subresources Add operations other than CRUD, such as “logs” or “exec”. No Yes strategic-merge-patch The new endpoints support PATCH with Content-Type: application/strategic-merge-patch+json. Useful for updating objects that may be modified both locally, and by the server. For more information, see “Update API Objects in Place Using kubectl patch” No, but similar functionality planned Yes Protocol Buffers The new resource supports clients that want to use Protocol Buffers No Yes OpenAPI Schema Is there an OpenAPI (swagger) schema for the types that can be dynamically fetched from the server? Is the user protected from misspelling field names by ensuring only allowed fields are set? Are types enforced (in other words, don’t put an int in a string field?) No, but planned Yes 一般功能： Feature What it does CRUD The new endpoints support CRUD basic operations via HTTP and kubectl Watch The new endpoints support Kubernetes Watch operations via HTTP Discovery Clients like kubectl and dashboard automatically offer list, display, and field edit operations on your resources json-patch The new endpoints support PATCH with Content-Type: application/json-patch+json merge-patch The new endpoints support PATCH with Content-Type: application/merge-patch+json HTTPS The new endpoints uses HTTPS Built-in Authentication Access to the extension uses the core apiserver (aggregation layer) for authentication Built-in Authorization Access to the extension can reuse the authorization used by the core apiserver (e.g. RBAC) Finalizers Block deletion of extension resources until external cleanup happens. Admission Webhooks Set default values and validate extension resources during any create/update/delete operation. UI/CLI Display Kubectl, dashboard can display extension resources. Unset vs Empty Clients can distinguish unset fields from zero-valued fields. Client Libraries Generation Kubernetes provides generic client libraries, as well as tools to generate type-specific client libraries. Labels and annotations Common metadata across objects that tools know how to edit for core and custom resources 安装自定义资源在向集群添加自定义资源之前，需要注意几点 第三方代码和新的失败点 存储 认证，授权，审计 访问自定义资源k8s client library可用于访问自定义资源。并非所有client library都支持自定义资源，但go和python client library可以。 当你添加一个自定义资源时，你可以使用如下方式访问： kubectl k8s dynamic client REST client 由k8s client 生成工具生成的client 计算，存储和网络插件Compute, Storage, and Networking Extensions 网络插件Network Plugins Notice:FEATURE STATE: Kubernetes v1.11 alphaAlpha features change rapidly k8s中的网络插件有几种风格： CNI plugins: 遵守appc/CNI规范，旨在实现互操作性 Kubenet plugin: 使用bridge和host-local CNI plugins实现基本的cbr0 安装kubelet有一个默认的网络插件，以及整个集群的默认网络。它在启动时探测插件，记住它找到的内容，并在pod声明周期中的适当时间执行所选插件。使用插件时，请记住两个kubelet命令行参数： cni-bin-dir: kubelet在启动时检测此目录以获取插件 network-plugin： 从cni-bin-dir使用的网络插件 123ps -ef | grep kubelet/usr/bin/kubelet xxx --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni 网络插件需求除了提供网络插件接口来配置和清理pod网络外，该插件还可能需要对kube-proxy提供特定支持。iptables proxy依赖于iptables，插件可能需要确保容器流量可用于iptables。默认情况下，如果未指定kubelet网络插件，则使用noop插件，它设置net/bridge-nf-call-iptables=1来确保简单配置与iptables proxy正常工作。 CNI通过kubelet传递--network-plugin=cni选项来选择CNI插件。kubelet从cni-conf-dir(默认/etc/cni/net.d)中读取文件，并使用该文件中的CNI配置来设置每个pod的网络。引用的插件必须存在于--cni-bin-dir(默认/opt/cni/bin)中。如果目录中有多个CNI配置文件，则使用文件名的词典顺序的第一个。除了配置文件指定的CNI插件外，k8s还需要标准的CNI lo插件(loopback)，最低版本 v0.2.0 kubenetkubelet是一个仅使用与Linux的基本和简单的网络插件。它本身并不实现高级的功能，如跨节点网络或网络策略。kubenet创建一个名为cbr0的Linux bridge，并为每个pod创建一个veth对，每对的主机端连接到连接到cbr0。通过配置或控制器管理器为该对的pod端分配范围内的IP地址。为cbr0分配一个MTU，该MTU与主机上启用的普通接口的最小MTU相匹配。 此插件需要一些东西： 需要标准的CNI bridge, lo, host-local插件，最小版本 v0.2.0。首先从/opt/cni/bin查找。 kubelet必须使用--network-plugin=kubenet参数来启用此插件 kubelet应该指定--non-masquerade-cidr=&lt;clusterCidr&gt;参数确保超出范围的IP流量将使用IP masquerade。 必须通过kubelet的--pod-cidr选项或控制器管理器的--allocate-node-cidrs=true --cluster-cidr=&lt;cidr&gt;选项来为节点分配IP子网 自定义MTU(kubenet)应该始终正确配置MTU以获得最佳网络性能。网络插件通常会推断合理的MTU，但有时不会产生最佳的MTU。如果需要，你可使用kubenet的network-plugin-mtu选项来明确指定MTU，仅有kubenet插件支持此选项。 使用摘要 123--network-plugin=cni--network-plugin=kubenet--network-plugin-mtu=9001 设备插件Device Plugins 从v1.8开始，k8s为Vendors提供了设备插件框架，以便在不更改k8s核心代码的情况下将资源通知到kubelet，Vendor可实现手动部署或作为DaemonSet部署的设备插件，而不是编写自定义的k8s插件。目标设备包括GPU，高性能NIC， FPGA， InfiniBand和其它计算资源。 设备插件注册设备插件功能由DevicePlugins功能控制，默认在 v1.10之前禁用。当启用设备插件功能，kubelet将导出Registration gRPC服务: 123service Registration &#123; rpc Register(RegisterRequest) returns (Empty) &#123;&#125;&#125; 设备插件可通过gRPC服务向kubelet注册自己。在注册中，它需要发送： Unix socket名 设备插件API版本 想要告知的ResourceName 栗子： 1234567891011apiVersion: v1kind: Podmetadata: name: demo-podspec: containers: - name: demo-container-1 image: k8s.gcr.io/pause:2.0 resources: limits: vendor-domain/resource: 2 # requesting 2 vendor-domain/resource 设备插件实现设备插件的一般工作流包括如下步骤： 初始化 插件启动gRPC服务 插件使用kubelet的Unix socket注册自己 注册成功之后，设备插件以服务模式运行，在此期间，它会持续监控设备运行状况，并在任何设备状况发生变化时向kubelet报告 设备插件部署设备插件可手动或作为DaemonSet来部署。k8s 设备插件的支持人处于alpha状态。 服务目录Service Catalog 服务目录是一种扩展API，它使在k8s集群中运行的应用程序能够轻松使用外部托管软件。它提供了从Service Broker 列出，配置和绑定外部托管服务的方法，而无需详细了解如何创建或管理这些服务。使用服务目录，集群操作人员可以浏览服务代理提供的托管服务列表，配置托管服务的实例，并与其绑定以使其可供k8s集群中应用程序使用。 Containers Images你创建Docker image并将其push到registry，然后在k8s pod中引用它。容器的镜像属性支持与Docker命令相同的语法，包括私有注册表和标记。 更新镜像默认的拉取策略是ifNotPresent，这会导致kubelet跳过拉取镜像(如果镜像已存在)。所以在网络不好时，我们可以首先将镜像拉取下来。如果你总想强制拉取镜像，可以执行如下操作： 设置容器imagePullPolicy为Always 使用:latest作为镜像的标记 启用AlwaysPullImages准入控制器 如果没有对镜像指定标记，则假定为:latest标记。 使用私有注册表Using a Private Registry 私有注册表有： Docker Hub Aliyun Tencent yun Google Container Registry AWS Container Registry Azure Container Registry … 以下是配置节点已使用私有注册表的推荐步骤： 12345678910111213141516171819202122232425261. 运行 docker login2. 查看 ~/.docker/config.json&#123; &quot;auths&quot;: &#123; &quot;https://index.docker.io/v1/&quot;: &#123; &quot;auth&quot;: &quot;xxxxxxxxxxxxxxx&quot; &#125; &#125;, &quot;HttpHeaders&quot;: &#123; &quot;User-Agent&quot;: &quot;Docker-Client/18.03.1-ce (linux)&quot; &#125;3. 获取节点列表#namenodes=$(kubectl get nodes -o jsonpath=&apos;&#123;range.items[*].metadata&#125;&#123;.name&#125; &#123;end&#125;&apos;)#IPsnodes=$(kubectl get nodes -o jsonpath=&apos;&#123;range .items[*].status.addresses[?(@.type==&quot;ExternalIP&quot;)]&#125;&#123;.address&#125; &#123;end&#125;&apos;)4. 复制 .docker/config.json 到上面的搜索路径列表for n in $nodes; do scp ~/.docker/config.json root@$n:/var/lib/kubelet/config.json; done 通过创建pod来验证私有镜像： 12345678910111213kubectl create -f - &lt;&lt;EOFapiVersion: v1kind: Podmetadata: name: private-image-test-1spec: containers: - name: uses-private-image image: $PRIVATE_IMAGE_NAME imagePullPolicy: Always command: [ &quot;echo&quot;, &quot;SUCCESS&quot; ]EOFpod &quot;private-image-test-1&quot; created 预拉取镜像Pre-pulling Images 默认情况下，kubelet将尝试从指定的注册表中拉取镜像。但是，如果容器的imagePullPolicy属性为ifNotPresent或Never，则会使用本地镜像。如果你希望依赖于预先拉取的镜像作为注册表身份验证的替代，则必须确保集群中的所有节点都具有相同的预拉取镜像。这可以用于预加载某些镜像以提高速度，或者作为对私有注册表进行身份认证的替代方法。请确保所有的pods都对预拉取的镜像由访问权限。 Specifying ImagePullSecrets on a Podk8s支持在pod上指定registry keys。 123456789101112131415#使用Docker config创建secretkubectl create secret docker-registry -h#Create a new secret for use with Docker registries.kubectl create secret docker-registry zhang21-secret --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAILsecret &quot;myregistrykey&quot; created.kubectl get secretNAME TYPE DATA AGEzhang21-secret kubernetes.io/dockerconfigjson 1 22s#查看和修改kubectl edit secret/zhang21-secret 如果需要访问多个注册表，你可以为每个注册表创建一个secret。当为pod来取镜像时，kubelet会将imagePullSecret合并到 一个虚拟的.docker/config.json文件中。pod只能在自己的命名空间中引用image pull secret，因此每个命名空间都需要执行一次此过程。 pod上的imagePullSecret 12345678apiVersion:kind: Podxxxspec: container: xxx imagePullSecretes: name: zhang21-secret 容器环境变量Container Environment Variables k8s容器环境为容器提供了几个重要资源： 文件系统(是镜像和卷的组合) 容器自身信息 集群中对象的信息 容器生命周期钩子Container Lifecycle Hooks 本节描述了kubelet如何使用容器生命周期钩子框架来运行在管理生命周期中由事件触发的代码。与许多具有组件生命周期钩子的编程语言框架类似，k8s为容器提供了生命周期钩子。钩子使容器能够了解其生命周期中的事件，并在执行相应的生命周期钩子时运行在处理程序中实现的代码。 容器钩子有两个公开给容器的钩子： PostStart此钩子在容器创建后立即执行。但是，无法保证钩子将在容器ENTRYPOINT之前执行。没有参数传递给处理程序。 PreStop此钩子在容器终止前立即调用。它是阻塞的，意味着它是同步的。所以它必须在调用删除容器之前完成才能发送。没有参数传递给处理程序。 Hook handler implementations容器可以通过实施和注册该钩子的处理程序来访问钩子。可为容器实施两种类型的钩子处理程序： Exec： 在cgroup和namespace内执行特定的命令 HTTP： 在容器的特定端点上执行一个HTTP请求 Hook handler exection调用容器生命周期管理钩子时，k8s管理系统会在为钩子注册的容器中执行处理程序。 钩子处理程序调用包含在容器的Pod的上下文中是同步的。这意味着对PostStart钩子，容器ENTRYPOINT和钩子异步启动。但是，如果钩子 运行/挂起 太长时间，则容器无法达到running state。PreStop钩子的行为类似。如果钩子在执行期间挂起，则pod阶段将保持在Terminating state，并在pod结束的terminationGracePeriodSeconds之后被杀掉。如果PostStart或PreStop钩子失败，则会杀掉容器。 用户应该使他们的钩子处理程序尽可能的轻量化。 Hook delivery guarantees钩子交付至少是一次，这意味着对于任何给定的事件可以多次调用钩子。由钩子实现来正确处理这个问题。通常，只进行当次交付。在一些罕见的情况下，可能会发生双重交付。 Debugging Hook handlers钩子处理程序的日志并不会在Pod事件中公开。如果处理程序由于某种原因失败，它会广播这个事件。 工作负载Workloads PodsPod是k8s的基本构建块，是你创建和部署k8s对象模型中最小和最简单的单元。Pod代表了集群上正在运行的进程。Pod封装了(encapsulates) 一个/多个 应用程序容器，存储资源，唯一的IP地址(集群内)以及控制容器运行需要的选项。Pod代表了一个部署单元，k8s中的单个应用程序实例可能包含单个或少量紧密耦合且共享资源的容器。Docker是k8s Pod中最常使用的容器运行环境(runtime)，Pod同样也支持其它容器运行环境。 k8s 集群中的Pods可以用两种主要方法来使用： 运行单个容器的PodPods that run a single containerone-container-per-pod模型时最常见的k8s用例。在这种情况下，你可将Pod视为单个容器的包装，而k8s直接管理Pod而不是容器。 运行多个需要协同工作的容器的PodPods that run multiple containers that need to work togetherPod可能封装了由多个协同定位(co-located)容器组成的应用程序，这些容器紧密耦合并且需要共享资源。这些协同的容器可能形成一个统一的服务单元——一个容器从共享卷向公众提供文件，而一个单独的sidecar容器刷新或更新这些文件。Pod将这些容器和资源作为单个可管理的实体包装在一起。 每个Pod都用于运行给定应用程序的单个实例。如果你想要水平扩展应用程序，你可以使用多个Pods(每个实例一个)。在k8s中，这通常称为副本(replication)。 Replicated Pods通常通过称为控制器(Controller)的抽象来创建和管理。 Pod如何管理多个容器Pods旨在支持多个协作进程(as container)，形成一个具有凝聚力的服务单元。Pod中的容器将自动协同定位(co-located)，并在集群中的同一主机上协同调度(co-scheduled)。容器可以共享资源和依赖，彼此通信，并协调它们何时以及如何终止。 注意，将多个协同定位和协同管理的容器分组到一个Pod中是一个相对高级的栗子。你应该仅在容器紧密耦合的特定实例中使用此模式。例如，你可能有一个容器充当共享卷中文件的Web Server，以及一个单独的sidecat容器——用于从远程更新这个文件： Pod共享资源Pod为其组成容器提供了两种共享资源： Networking每个Pod都被分配了一个唯一的IP地址(within cluster)。Pod中的每个容器都共享网络命名空间，包括IP地址和网络端口。Pod内的容器可使用localhost相互通信。当Pod内的容器与Pod外的实体通信时，它们必须协调如何使用共享网络资源。 StoragePod可以指定一组共享存储卷。Pod中的所有容器都可以访问这个共享卷，允许这些容器共享数据。还是关于数据持久化的卷。 使用Pods你很少直接在k8s(甚至是单例Pod)中创建单独的Pod。这是因为Pod被设计为相对短暂的一次性实体，即用后即焚。当Pod被创建后，都会被调度到集群中的节点上运行。Pod保留在该节点上，知道进程终止，Pod对象被删除，Pod因资源不足而被驱逐，或节点失效。Pod不会自愈。注意： 重启Pod中的容器与重启Pod不是一回事。Pod本身不运行，它只提供容器的运行环境并保持容器的运行状态。但是容器运行的环境会持续存在，直到删除为止。 Pod本身不提供自我修复(self-heal)。如果将Pod调度到一个失败的节点，或调度操作本身失败，则会删除Pod。同样，由于缺乏资源或节点维护中，Pod将无法在驱逐中存活。k8s使用一个高更级别的抽象，称为控制器(Controller)。它管理相对可处理的Pod实例的工作。因此，尽管可以直接使用Pod，但在k8s中使用控制器管理Pod更为常见。控制器可为你创建和管理多个Pod，处理副本和上线，并在集群范围内提供自我修复功能。例如，如果节点故障，控制器可能会通过在不同节点上安排相同的替换来自动替换Pod。通常，控制器使用你提供的Pod模板来创建它负责的Pod。 Pod TemplatesPod模板是Pod规范，包含在其它对象中。控制器使用Pod模板制作实际的Pod。 栗子： 1234567891011apiVersion: v1kind: Podmetadata: name: myapp-pod labels: app: myappspec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo Hello Kubernetes! &amp;&amp; sleep 3600'] Pod模板不是指定所有副本的当前所需状态，而是像饼干切割器。饼干被切割后，饼干与切割器无关。 PodPod是可在k8s中创建和管理的最小可部署的计算单元。 Pod是什么Pod是一组 一个/多个容器，具有共享存储/网络，以及如何运行容器的规范。Pod中的容器总是co-located和co-scheduler，并在共享上下文中运行。一个pod模拟特定应用程序的逻辑主机，它包含一个/多个紧密耦合的应用程序容器。Pod的共享上下文十一组Linux namespace， cgroup，以及隔离方面。在Pod的上下文中，各个应用程序科恩能够回应用进一步的子隔离。Pod中的容器共享IP地址和端口空间，并且可通过localhsot找到彼此。它们还可使用IPC相互通信。不同Pod中的容器具有不同的IP地址，默认情况下无法通信，需要进行额外配置。Pod中的应用程序还可访问共享卷，共享卷被定义为Pod的一部分，可挂载到每个应用程序的文件系统中。就Docker构造而言，Pod被建模为一组具有共享命名空间和共享卷的Docker容器。与单个应用程序容器类似，Pod被认为是相对短暂(非持久)的实体。 Pod动机 管理(Management)Pod是多个协作过程进程模式的模型，形成了一个有凝聚力的服务单元。它们通过提供更高级别的抽象来简化应用程序部署和管理。Pod提供用于部署，水平扩展，副本的单元。对于Pod中的容器，它们将自动处理协同调度， 共享命运， 协同副本，资源共享和依赖管理… 资源共享和交流Pod可以实现成员之间的数据共享和通信。Pod中的应用程序都是用相同的网络命名空间，因此可通过localhost进行通信。因此，Pod中的应用程序必须协调对端口的使用。主机名设置为Pod中应用程序容器的Pod名。除了定义在Pod中运行的应用程序容器，Pod还制定了一组共享存储卷(持久化)。 123456789101112131415kubectl -n kube-system get pod -o wideNAME READY STATUS RESTARTS AGE IP NODEkubernetes-dashboard-6948bdb78-tdh5v 1/1 Running 0 8d 10.244.2.3 salt01metrics-server-85ff8f7b84-72rd4 1/1 Running 0 9d 10.244.2.2 salt01kubectl -n kube-system exec -it metrics-server-85ff8f7b84-72rd4 /bin/sh/ # hostnamemetrics-server-85ff8f7b84-72rd4/ # ifconfigeth0 10.244.2.2/ # ping 10.244.2.3PING 10.244.2.3 (10.244.2.3): 56 data bytes64 bytes from 10.244.2.3: seq=0 ttl=64 time=0.115 ms64 bytes from 10.244.2.3: seq=1 ttl=64 time=0.062 ms Pod使用Pod可用于托管垂直集成的应用程序栈，但主要动机是用于支持协同共处，协同管理的应用程序。如： 内容管理系统，文件和数据加载器，本地缓存管理器 日志和检查点的备份、压缩、轮询、快照 数据变更观察器，日志和监控适配器，事件发布器 代理，网桥和适配器 控制器，管理器，配置器和更新器 通常，单个Pod不用于运行同一程序的多个实例。 替代考虑为什么不在单个容器中运行多个程序？ 透明度 解耦软件依赖关系 使用方便 效率 Pod耐久性Pod不应被视为耐用实体。它们不会在 调度失败，节点故障，驱逐，节点维护等情况下存活。通常，用户不需要直接创建Pod。而应该(几乎总是)使用控制器。控制器提供了集群范围内的自修复(self-healing)，副本和上线管理。 Pod公开为一个原语以便于使用： 调度器和控制器可插拔 支持Pod级操作，而无需通过控制器API代理 将Pod寿命与控制器寿命分离 控制器和服务的分离 kubelet实际是Pod控制器 高可用应用程序 Pod终止由于Pod表示集群中节点上正在运行的进程，因此允许这些进程在不需要时优雅地终止(gracefully terminate)非常重要。用户应该能够请求并指导进程何时终止，但也要确保删除最终完成。当用户请求删除Pod时，系统会在允许Pod强制终止之前记录预期的宽限期(grace period)，并将TERM信号(-15)发送到每个容器的主进程中。宽限期到期后，KILL信号(-9)发送到这些进程，然后从API server中删除该Pod。如果在等待进程终止时Kubelet或容器管理器重启了，则将在完整的宽限期内重试终止。 流程： 用户发送删除Pod的命令，默认宽限期(30s) API server中的Pod随着时间的推移而更新，在此之后，除了宽限期外，Pod被认为死亡 列出客户端命令时，Pod显示为Terminating 当Kubelet发现Pod被标记为Terminating，它将开始Pod关闭过程 4.1 如果Pod定义了preStop hook，则会在Pod内调用 4.2 Pod中的进程发送TERM信号 Pod将从端点列表中删除，并且不再被视为副本控制器中运行的Pod的一部分。缓慢关闭的Pod无法继续为流量提供服务，因为负载均衡器会将其从轮询中删除 当宽限期到期后，仍在Pod中运行的任何进程都将被KILL信号杀死 Kubelet通过设置宽限期0（立即删除）完成删除API server上的Pod。Pod从API中消失，客户端不在可见 默认情况下，所有删除都有30s的宽限期。kubectl delete命令支持指定--grace-period=选项。设置为0表示强制删除Pod。--force --grace-period=0强制删除。 强制删除Pod强制删除Pod被定义为立即从集群状态和etcd中删除Pod。当执行强制删除时，API server不会等待来自Kubelet的确认——确认该Pod已在运行的节点上终止。它会立即删除API中的Pod，以便可使用相同的名称创建新的Pod。在节点上，设置为立即终止的Pod在被强制终止之前仍被授予一个小的宽限期。强制删除可能会对某些Pod有潜在危险，请谨慎执行。 Pod容器的特权模式(Privileged mode)在容器 spec的SecurityContext中使用privileged标志，来启用Pod中容器的特权模式。这对于想要使用Linux功能的容器非常有用。容器内的进程获得与可访问的容器外进程几乎相同的权限。使用特权模式，可以更容易的编写网络和卷插件，而不需要编译到kubelet。 API对象Pod是k8s REST API中的顶级资源, /pod/xxx。 Pod生命周期Pod Lifecycle 阶段(phase)Pod的status字段是一个PodStatus对象，它有一个phase字段。 阶段可能的值： Value Description Pending The Pod has been accepted by the Kubernetes system, but one or more of the Container images has not been created. This includes time before being scheduled as well as time spent downloading images over the network, which could take a while. Running The Pod has been bound to a node, and all of the Containers have been created. At least one Container is still running, or is in the process of starting or restarting. Succeeded All Containers in the Pod have terminated in success, and will not be restarted. Failed All Containers in the Pod have terminated, and at least one Container has terminated in failure. That is, the Container either exited with non-zero status or was terminated by the system. Unknown For some reason the state of the Pod could not be obtained, typically due to an error in communicating with the host of the Pod. 状况(conditions)Pod有一个PodStatus，它有一个PodConditions数组，表示Pod是否通过。每个PodCondition数字的每个元素都有六个可能的字段： lastProbeTime: 最后一次探测Pod状况的字段 lastTransitionTime: Pod最后从一个状态转换到另一个状态的时间戳的字段 message: 有关转换的人类可读的详细信息的字段 reason: 一个独特的，单字的最后转换的原因的字段 status: 字段值可能为True, False, Unknown type: 字段可能有如下值: PodScheduled: Pod已被调度到一个节点 Ready: Pod能提供请求，并应该添加到所有匹配服务的负载均衡池中 Initialized: 所有的初始化容器已成功启动 Unschedulable: 调度器现在无法调度Pod，如缺乏资源… ContainersReady: Pod中的所有容器都已准备好了 探测(probes)探测是由容器上的kubelet定期执行的诊断。为了执行诊断，kubelet调用容器执行处理器(Handler)。有三种类型的处理器: ExecAction: 在容器内执行指定命令。如果状态码为0，则认为诊断成功 TCPSocketAction: 在指定端口的容器IP地址执行TCP检查。如果端口打开，则认为诊断成功 HTTPGetAction: 在容器IP的特定端口的路径下执行HTTP GET请求。如果请求成功，则认为诊断成功 每个探测可能有三种结果: Success Failure Unknown kubelet可选择在运行容器上执行两种探测并对其作出反应: livenessProbe: 确定容器是否正在运行 readinessProbe: 确定容器是否准备好为请求提供服务 什么时候使用这两中探测？When should you use liveness or readiness probes? 如果容器中的进程在遇到问题或变得不健康时会自行崩溃(crash)，则你不一定需要livenessProbe。kubelet将根据Pod的restartPolicy自动执行正确的操作。如果希望在探测失败时杀死并重启容器，则请指定livenessPorbe和指定restartPolicy为Always 如果只想在探测成功时向Pod发送流量，请指定readinessProbe。如果容器需要在启动期间除了大型数据，配置文件或迁移，请指定readnessProbe。如果你希望容器能够自行维护，你可指定一个readnessProbe，它检查特定端点。 注意，如果你只想在删除Pod时排除请求，则不一定需要readnessProbe。无论是否存在readnessProbe，Pod都会自动将其置于未准备状态。Pod在等待Pod中容器停止时仍处于未准备状态。 Pod readiness gateFEATURE STATE: Kubernetes v1.11 alpha 为了通过向PodStatus调价额外的反馈或信号来增加Pod readness的可扩展性，k8s v1.11引入了一个名为Pod ready++的功能。你可在PodSpec中使用新字段ReadinessGate来指定要为Pod准备情况评估的其它条件。如果k8s在Pod的status.conditions字段找不到这样的状况，则状况的状态默认为False。 12345678910111213141516171819Kind: Pod...spec: readinessGates: - conditionType: &quot;www.example.com/feature-1&quot;status: conditions: - type: Ready # this is a builtin PodCondition status: &quot;True&quot; lastProbeTime: null lastTransitionTime: 2018-01-01T00:00:00Z - type: &quot;www.example.com/feature-1&quot; # an extra PodCondition status: &quot;False&quot; lastProbeTIme: null lastTransitionTime: 2018-01-01T00:00:00Z containerStatuses: - containerID: docker://abcd... ready: true... 重启策略PodSpec有一个restartPolicy字段，其值可能是Always(默认值), OnFailure, Never。此策略应用于Pod中的所有容器，它仅指由同一节点上的kubelet重启的容器。退出的容器将由kubelet以指定退避延迟(10s, 20s, 40s…)重新启动，上限5分钟，并在成功执行十分钟后重置。 寿命(lifetime)一般来说，Pod不会消失，直到有人摧毁它们。唯一的例外是，具有成功或失败超过一段时间的阶段的Pod将过期并自动销毁。 有三种类型的控制器可用： Use a Job for Pod Use a ReplicationController/ReplicaSet/Deployment for Pod Use a DaemonSet for Pod 所有三种类型的控制器都包含了PodTemplate。推荐创建适当的控制器并让它创建Pod，而不是自己直接创建Pod。这是因为Pod单独对机器故障没有弹性，但控制器不会。如果节点死亡或与集群的其余部分断开连接，k8s会应用策略将丢失节点上的所有Pod的阶段设置为Failed。 Init Containers本节提供了初始容器(init container)的概述，它是在应用程序容器运行之前的专用容器，可包含应用程序镜像中不存在的实用程序或脚本设置。 理解初始容器Pod可以有多个容器在其中运行应用程序，但它同样可以有一个或多个初始容器——它在应用程序容器启动前运行。初始容器与常规容器一样，除了： They always run to completion. 每一个必须在下一个启动之前成功完成 如果Pod的初始容器失败，则k8s会重复重启直到初始容器成功。但是，如果Pod的restartPolicy为Never，则不会重启。要将容器指定为初始容器，请将PodSpec上的initContainers字段添加为应用程序container数组旁边的容器类型对象的JSON数组。初始容器的状态在.status.initContainerStatuses字段中作为容器状态数据返回。 与常规容器的不同初始容器支持应用程序容器的所有字段和功能，包括资源限制，卷和安全设置。但资源请求和处理方式略有不同。此外，初始容器不支持readiness probes，因为它必须在Pod准备好之前运行完成。如果为Pod指定了多个初始容器，则按顺序依次运行一个容器。每个必须在下一个运行之前完成。当所有初始容器都运行完毕时，k8s会初始化Pod并像往常一样运行应用程序容器。 初始容器可用于什么由于初始容器具有来自应用程序容器的单独镜像，因此它们对于启动相关代码具有一些优势： 出于安全原因，它们可以包含并运行不希望包含在应用程序容器镜像中的使用程序 它可以包含应用程序镜像中不存在的实用程序或自定义代码。例如，在配置过程中，无需为了使用其他工具(sed, awk, dig…)而专门使用FROM创建一个镜像 应用程序镜像构建器和部署器角色可独立工作，而无需共同构建单个应用程序镜像 它们使用Linux命名空间，以便从应用程序容器中获得不同的文件系统视图。因此，它们可以访问应用程序容器无法访问的Secrets 它们在应用程序容器启动前运行完成，因此初始容器提供了一种简单的方法来阻止或延迟应用程序容器的启动，知道满足一组前置条件。 栗子这有些初始容器的使用案例: 等待使用shell命令创建服务: for in in {1..100}; do sleep 1; if dig myservice; then exit 0; fi; done; exit 1 使用API从远程服务器注册此Pod: curl -XPOST http://host:port/register -d &#39;instance=$()&amp;ip=$()&#39; 在启动应用程序之前等待一段时间: sleep 60 克隆一个git repo到某个卷 替换配置文件中的值并运行模板来动态生成应用程序容器的配置文件 使用初始容器两个初始容器。第一个等待myservice，第二个等待mydb。一旦两个容器完成，Pod将开始。 123456789101112131415161718apiVersion: v1kind: Podmetadata: name: myapp-pod labels: app: myappspec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo The app is running! &amp;&amp; sleep 3600'] initContainers: - name: init-myservice image: busybox command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;'] - name: init-mydb image: busybox command: ['sh', '-c', 'until nslookup mydb; do echo waiting for mydb; sleep 2; done;'] 创建: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970kubectl create -f /etc/k8s/test/init-container.yamlpod/myapp-pod createdkubectl get podNAME READY STATUS RESTARTS AGEinit-container 0/1 Init:0/2 0 6skubectl describe -f /etc/k8s/test/init-container.yamlInit Containers: init-myservice: Container ID: docker://f9ca73d4d2c8903a1fe84937e34ae27b909a691d2e524254b8f4aec9d5cc754c Image: busybox Image ID: docker-pullable://docker.io/busybox@sha256:cb63aa0641a885f54de20f61d152187419e8f6b159ed11a251a09d115fdff9bd Port: &lt;none&gt; Host Port: &lt;none&gt; Command: sh -c until nslookup myservice; do echo waiting for myservice; sleep 2; done; State: Terminated Reason: Completed Exit Code: 0 Started: Fri, 24 Aug 2018 16:31:13 +0800 Finished: Fri, 24 Aug 2018 16:31:18 +0800 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-69vgk (ro) init-mydb: Container ID: docker://a9946122976ff70ff1dd874299e3e63f4b07f2758f5e6518b84343c58daa3506 Image: busybox Image ID: docker-pullable://docker.io/busybox@sha256:cb63aa0641a885f54de20f61d152187419e8f6b159ed11a251a09d115fdff9bd Port: &lt;none&gt; Host Port: &lt;none&gt; Command: sh -c until nslookup mydb; do echo waiting for mydb; sleep 2; done; State: Terminated Reason: Completed Exit Code: 0 Started: Fri, 24 Aug 2018 16:31:24 +0800 Finished: Fri, 24 Aug 2018 16:31:29 +0800 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-69vgk (ro)Containers: myapp-container: Container ID: docker://b2c7a1f32d65dd41fa439d1f6879824b40c3014b32b15d61fed0cda171144a1b Image: busybox Image ID: docker-pullable://docker.io/busybox@sha256:cb63aa0641a885f54de20f61d152187419e8f6b159ed11a251a09d115fdff9bd Port: &lt;none&gt; Host Port: &lt;none&gt; Command: sh -c echo The app is running! &amp;&amp; sleep 3600 State: Running Started: Fri, 24 Aug 2018 16:31:34 +0800 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-69vgk (ro) 详细行为在Pod启动期间，初始化网络和卷后，初始容器将按顺序启动。每个容器必须在下一个容器启动前成功退出。如果容器由于运行环境未能启动或失败退出而启动失败，则它根据Pod的restartPolicy重试。如果Pod的restartPolicy为Always(默认)，则初始容器使用restartPolicy为OnFailure。在所有初始容器都成功之前，Pod无法变为Ready。初始容器上的端口无法聚合到服务下。正在初始化的Pod处于Pending状态，但应该具有Initializing设置为true的条件。如果Pod重启，则所有初始都要执行一遍。init container spec的更改仅限于容器镜像字段。更改初始容器镜像字段相当于重启Pod。由于初始容器可重启，重试或重新执行，因此初始容器代码应该是幂等的。In particular, code that writes to files on EmptyDirs should be prepared for the possibility that an output file already exists.在Pod上使用activeDeadlineSeconds，在容器上使用livenessProbe，以防止初始容器永远失败。Pod中每个应用程序和初始容器的名称必须是唯一的，否则会引发验证错误。 资源给定初始容器的排序和执行，适用一下资源使用规则： 在所有初始容器上定义的任何特定资源请求或限制的最高值是有效的初始 请求/限制 Pod对资源的有效请求/限制是以下值中的较高者: 所有的应用程序容器对资源请求/限制的总和 对资源的有效初始请求/限制 调度是基于有效请求/限制完成的，这意味着初始容器可以保留在Pod生命周期内未使用的初始化资源 Pod的有效QoS层与初始容器和应用程序容器一样 Pod级别的cgroup基于有效的Pod请求和限制，与调度程序相同。 Pod重启原因由于以下原因，Pod可重新启动，导致重新执行初始容器： 用户更新了PodSpec，导致初始容器镜像发生噶变。应用程序容器镜像的更改仅重启应用程序容器 Pod的基础架构容器重启 Pod的所有容器都终止，而restartPolicy设置为Always，强制重启，并且初始容器完成记录由于垃圾回收而丢失 Pod预设Pod Preset Pod Presets是对象，在创建时将特定信息注入Pod。Pod Preset是一种API资源，用于在创建时将其它运行时的需求写入到Pod。你可使用label selectors指定应用于Pod的给定Pod Preset。使用Pod Preset允许pod template作者不必显示提供每个pod的所有信息。这样，作者不需要知道有关该服务的所有详细信息。 它如何工作k8s提供了一个admission controller(Pod Preset)，启用后，会将Pod Preset应用于传入的pod创建请求。当Pod创建请求发生时，系统会执行一下操作： 检索所有可供使用的Pod Preset 检查任何Pod Preset的label selector是否与正在创建的Pod上的标签匹配 尝试将Pod Preset定义的各种资源合并到正在创建的Pod中 出错时，抛出一个记录Pod 合并错误的事件，然后创建不从Pod Preset写入任何资源的pod 注释生成的修改后的Pod spec，以表明它已被Pod Preset修改——podpreset.admission.kubernetes.io/podpreset-&lt;pod-preset name&gt;: &quot;&lt;resource version&gt;&quot; 每个Pod能够被零个或多个PodPreset匹配，每个PodPreset可以被应用到零个或多个Pod。当PodPreset应用于一个或多个Pod时，k8s会修改Pod spec。对于Env, EnvFrom, VolumeMounts，k8s修改Pod中所有容器的container spce；对于Volume的更改，k8s修改Pod spec。 为指定Pod禁用PodPreset在某些情况下，你希望Pod不被任何PodPreset修改。你可修改: podpreset.admission.kubernetes.io/exclude: &quot;true&quot; 启用PodPreset要在集群中使用PodPreset，你必须确保以下内容： 你已启用API类型: settings.k8s.io/v1alpha1/podpreset 你已经启动admission controller PodPreset 你已通过在将使用的命名空间中创建PodPreset对象来定义PodPreset 中断Disruptions 本节适用于想要构建高可用性应用程序的用户，因此需要了解Pod可能发生的中断类型。这同样适用于希望执行自动化集群操作的集群管理员，例如升级或自动伸缩集群。 自愿和非自愿中断Voluntary and Involuntary Disruptions Controller ReplicaSet副本集是下一个副本控制器。现在副本集和副本控制器之间的唯一区别是selector的支持。副本集支持labels user guide中描述的新的基于集合selector的要求，而副本控制器仅支持基于等同selector的要求。 如何使用副本集大多数支持副本控制器的kubectl命令也支持副本集。一个例外是rolling-update命令。如果你想要滚动更新功能，请考虑使用Deployments代替。虽然副本集可独立使用，但它主要被Deployment用作协调Pod创建，删除和更新的机制。使用部署时，你不必担心管理它们创建的副本集，部署拥有并管理其副本集。 何时使用副本集副本集确保在任何给定时间运行指定数量的Pod副本。但是，部署是一个更高级别的概念，它管理副本集并为Pod提供声明性更新以及许多其它有用的功能。因此，除非你需要自定义更新或无需更新，否则建议你使用部署而不是直接使用副本集。这实际上意味着，你不需要操作副本集对象：改为使用部署，并在spec部分定义你的应用程序。 栗子 1234567891011121314151617181920212223242526272829303132333435363738apiVersion: apps/v1kind: ReplicaSetmetadata: name: frontend labels: app: guestbook tier: frontendspec: # modify replicas according to your case replicas: 3 selector: matchLabels: tier: frontend matchExpressions: - &#123;key: tier, operator: In, values: [frontend]&#125; template: metadata: labels: app: guestbook tier: frontend spec: containers: - name: php-redis image: gcr.io/google_samples/gb-frontend:v3 resources: requests: cpu: 100m memory: 100Mi env: - name: GET_HOSTS_FROM value: dns # If your cluster config does not include a dns service, then to # instead access environment variables to find service host # info, comment out the 'value: dns' line above, and uncomment the # line below. # value: env ports: - containerPort: 80 1kubectl create -f /etc/k8s/test/frontend.yaml 编写副本集spec与所有其它k8s API对象一样，副本集需要apiVersion, kind, metadata字段，副本集还需要一个.spce部分。 123456789101112131415161718#Pod Template.spec.template是.spec唯一必需的字段除了pod的必须字段，副本集中的Pod模板还必须指定适当的`label`和`restart policy`#Pod Selector.spec.selector字段是一个label selector。副本集使用与selector匹配的label来管理所有pod。它不区分创建或删除的Pod以及人或进程创建或删除的pod。这允许替换副本集而不会影响正在运行的Pod。.spec.template.metadata.labels 必须匹配 .spec.selector，否则它将被API拒绝。此外，你通常不应创建任何label与selector匹配的pod。如果你这样做了，副本集会认为它创建了其它pod，k8s并没有阻止你这样做。#Labels on a ReplicaSet副本集本身可以有标签(.metadata.labels)。通常，你可将其设置为与 .spec.template.metadata.labels 一致。但，允许他们不同，并且 .metadata.labels 不会影响副本集的行为#Replicas你可通过设置 .spec.replicas 来指定应同时运行的pod数量。如果未指定，默认为1 使用副本集 1234567891011121314151617181920212223242526272829303132333435363738394041424344#删除副本集和它的podskubectl delete replicaset/xxx#或kubectl proxy --port=8080curl -XDELETE &apos;localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend \-d &apos;&#123;&quot;kind&quot;:&quot;DeleteOptions&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;propagationPolicy&quot;:&quot;Foreground&quot;&#125;&apos; \-H &quot;Content-Type: application/json&quot;#仅删除副本集kubectl delete rs/xxx --cascade=false#或kubectl proxy --port=8080curl -X DELETE &apos;localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend&apos; \-d &apos;&#123;&quot;kind&quot;:&quot;DeleteOptions&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;propagationPolicy&quot;:&quot;Foreground&quot;&#125;&apos; \-H &quot;Content-Type: application/json&quot;#从副本隔离pods可通过更改label从副本集的目标中删除Pod。此技术可用于从服务中删除pod以进行调试，数据恢复等。以这种方式删除的pod将自动替换#伸缩副本集只需更新副本集的 .spec.replicas 字段轻松伸缩副本集。副本集控制器确保具有匹配 label selector 所需数量的pod可用且可操作。#作为水平pod自动伸缩目标的副本集Horizontal Pod Autoscalers(HPA)，意味着副本集可通过HPA自动伸缩。#栗子apiVersion: autoscaling/v1kind: HorizontalPodAutoscalermetadata: name: frontend-scalerspec: scaleTargetRef: kind: ReplicaSet name: frontend minReplicas: 3 maxReplicas: 10 targetCPUUtilizationPercentage: 50kubectl create -f /path/xx/hpa.rs.yaml#此外，可使用kubectl命令来自动伸缩#kubectl autoscale rs frontend 替代副本集 Deployment(推荐) Bare Pods Job DaemonSet ReplicationController注意：现在，配置副本集的推荐方法是使用部署。 副本控制器确保一次运行指定数量的Pod副本。换言之，副本控制器确保一个Pod或一组同类Pod总是可用。 Deployments部署控制器为Pod和ReplicaSet提供了声明性更新。在部署对象中描述所需的状态，部署控制器以受控速率将实际状态更改为所需状态。你可定义部署来创建新的副本集，或删除现有的部署并使用新的部署收纳所有资源。你不应该直接管理部署所拥有的副本集，应该通过操作部署对象来涵盖所有用例。 栗子以下是部署的典型案例： 创建部署来上线副本集 声明Pod的新状态 回滚到早期的部署版本 伸缩部署 暂定部署 使用部署的状态 清理旧的副本集 创建一个部署下面的栗子，创建一个3个Nginx pods的副本集: 123456789101112131415161718192021apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment labels: app: nginxspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 12345kubectl create -f ./nginx-deployment.yamlkubectl get deploymentkubectl get rskubectl get pod --show-labels 更新部署当且仅当部署的pod template发生更改时，才会触发部署更新上线。假如我们要更新Nginx的版本为1.9.1: 12345678910111213141516171819202122232425kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1deployment.extensions/nginx-deployment image updated#或者kubectl edit deployment/nginx-deploymentdeployment.extensions/nginx-deployment edited#查看上线状态kubectl rollout status deployment/nginx-deploymentWaiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 old replicas are pending termination...Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 old replicas are pending termination...deployment &quot;nginx-deployment&quot; successfully rolled out#新旧副本集副本数kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deployment-67594d6bf6 0 0 0 16mnginx-deployment-d78fcfc84 3 3 3 3m 部署可以确保在更新时只有一定数量的Pod可能会关闭。默认情况下，它确保最大不可用率25%。部署确保在所需数量的Pod之上只能创建一定数量的Pod。默认情况下，它确保比最大数多25%。例如，如果仔细查看上面的部署，你将看到它首先创建了一个新的Pod，然后删除了一些旧的Pod并创建新的Pod。在有足够数量的新Pod出现之前，它不会杀死旧的Pod，并且在足够数量的旧Pod被杀死之前不会创建新的Pod。 通常不鼓励进行label selector的更改，建议你事先规划好selector。 回滚(rolling back)部署有时可能需要回滚部署，当部署不稳定时，如崩溃循环(crash looping)。默认情况下，所有的部署上线历史都保留在系统中，以便可以随时回滚。 假设我之间将nginx:1.7.1更新到nginx:1.9.1的时候错误的写成了nginx:1.91: 1234567891011121314kubectl set image deployment/nginx-deployment nginx=nginx:1.91#上线就会卡在此处kubectl rollout status deployments nginx-deploymentWaiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...error: deployment &quot;nginx-deployment&quot; exceeded its progress deadline#查看容器错误，它会报镜像拉取错误kubectl get podnginx-deployment-58c7645486-s5t6t 0/1 ImagePullBackOff 0 3m &lt;none&gt; node#UI里面的报错#Failed to pull image &quot;nginx:1.91&quot;: rpc error: code = Unknown desc = manifest for docker.io/nginx:1.91 not found 部署控制器将自动停止错误的rollout，并将停止扩展新的副本集。这取决于滚动升级的参数(maxUnavailable)。默认情况下，k8s将值设置为1，将.spec.replicas设置为1，因此你无需关心设置这些参数。你的部署可能具有100%的不可用性。 要修复它，你需要回滚到先前稳定的部署版本。 1234567891011121314151617181920212223242526272829#检查上线历史kubectl rollout history deployment/nginx-deploymentdeployments &quot;nginx-deployment&quot;REVISION CHANGE-CAUSE1 kubectl create -f ./nginx-deployment.yaml --record2 kubectl set image deployment/nginx-deployment nginx=nginx:1.9.13 kubectl set image deployment/nginx-deployment nginx=nginx:1.91#查看某个上线历史rollout history deployment/nginx-deployment --revision=2#回滚#回滚到前一个版本kubectl rollout undo deployment/nginx-deploymentdeployment.extensions/nginx-deployment#回滚到指定版本kubectl rollout undo deployment/nginx-deployment --to-revision=2#查看事件kubectl describe deployment/nginx-deploymentEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal DeploymentRollback 2m deployment-controller Rolled back deployment &quot;nginx-deployment&quot; to revision 3 Normal ScalingReplicaSet 2m deployment-controller Scaled down replica set nginx-deployment-58c7645486 to 0 伸缩副本 1234567891011#扩展部署kubectl scale deployment nginx-deployment --replicas=5#水平伸缩kubectl autoscale deployment nginx-deployment --min=3 --max=6 --cpu-percent=80#查看kubectl get horizontalpodautoscaler.autoscalingNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGEnginx-deployment Deployment/nginx-deployment &lt;unknown&gt;/80% 3 6 5 1m 比例伸缩(proportional scaling)滚动升级部署支持同时运行多个版本的应用程序。当你或自动伸缩器正在上线滚动更新的部署时，部署控制器将平衡现有活动的副本集中的其它副本，以降低风险。这称为比例缩放。 1234567891011121314151617kubectl get deployNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx-deployment 5 5 5 5 1h#更新一个错误镜像，它会卡住kubectl set image deploy/nginx-deployment nginx=nginx:sometagkubectl get rs -o wideNAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTORnginx-deployment-895bd59bc 3 3 0 1m nginx nginx:sometag app=nginx,pod-template-hash=451681567nginx-deployment-d78fcfc84 5 5 5 1h nginx nginx:1.7.1 app=nginx,pod-template-hash=834979740kubectl get deploy -o wideNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTORnginx-deployment 6 8 3 5 1h nginx nginx:sometag app=nginx 暂停和恢复部署你可以在触发一个或多个更新之前暂停(pause)部署，然后恢复(resume)它。这允许你在暂停和恢复之间应用多个修复，而不会触发不必要的上线。注意： 在恢复暂停部署之前，无法执行回滚操作。 123456789101112131415#暂停kubectl rollout pause deployment/nginx-deploymentdeployment.extensions/nginx-deployment pausedkubectl set image deploy/nginx-deployment nginx=nginx:1.9.1deployment.extensions/nginx-deployment image updatedkubectl set resources deployment nginx-deployment -c=nginx --limits=cpu=200m,memory=128Mideployment.extensions/nginx-deployment resource requirements updated#恢复kubectl rollout resume deployment/nginx-deploymentdeployment.extensions/nginx-deployment resumed 部署状态部署在其生命周期内会进入各种状态–kubectl rollout status Progessing Deployment 部署创建一个新的副本集 部署伸缩到新的/旧的副本集 新的Pod可用 Complete Deployment 所有与部署关联的副本都已完成 所有与部署关联的副本都可用 没有正在运行的旧的部署副本 Failed Deployment 配额不足 准备探针失败 镜像拉取失败 权限不足 限制范围 应用程序运行时配置错误 Operating on a failed deployment Clean up Policy可在部署中设置.spec.revisionHistoryLimit字段来指定需要保留的旧副本集数。其余的将在后台被垃圾回收，默认为10。 注意：将此字段设置为0会导致清理部署的所有历史记录，从而部署将无法回滚。 Deployment Spec与其它k8s配置一样，Deployment需要apiVersion, kind, metadata字段。但部署还需要.spec 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#pod template#必填字段.spec.template#Replicas.spec.replicas#Selector#它必须匹配.spec.template.metadata.labels，否则会被API拒绝.spec.selector#Strategy.spec.strategy#Recreate deployment.spec.strategy.type==Recreate#Rolling Update Deployment.spce.stratefy.type==RollingUpdate#Max Unavailable.spec.strategy.rollingUpdate.maxUnavailable#Max Surge.specstrategy.rollingUpdate.maxSurge#Progress Deadline Seconds.spec.progressDeadlineSeconds#Min Ready Seconds.spec.minReadySeconds#Rollback To.spec.rollbackTo#Revision History Limit.spec.revisionHistoryLimit#Paused.spec.paused 替代方案 kubectl rolling updatekubetl rolling update以类似的方式更新Pod和副本集控制器。但建议使用部署，因为它是声明性的。 StatefulSetsStatefulSet是用于管理有状态应用程序的工作负载的API对象。Note: StatefulSets are stable (GA) in 1.9. 管理一组Pod的部署和伸缩，并提供有关这些Pod的序列和唯一性的保证。与部署类似，有状态集管理基于相同容器规范(spec)的Pod；与部署不同，有状态集为其每个Pod维护一个粘性(sticky)标识。这些Pod根据相同的规范创建，但不可互换，每个Pod都有一个持久的标识符，它可在任何重新调度时保留。有状态集与任何其它控制器相同的模式运行。你在有状态集对象中定义所需的状态，有状态集控制器进行任何必要的更新以从当前状态到达期望状态。 使用有状态集有状态集对于需要以下一个或多个应用程序非常有用： 稳定，唯一的网络标识 稳定，持久存储 有序，优雅的部署和伸缩 有序，优雅的删除和终止 有序，自动的滚动更新 如果应用程序不需要任何稳定标识或有序部署、删除、伸缩，则应该使用提供一组无状态副本的控制器来部署你的应用程序。如部署或副本集这样的控制器可能更适合无状态需求。 局限(limitations) k8s v1.9+ 给定Pod的存储必须由PersistentVolume Provisioner根据请求的存储类进行配置，或由管理员预先配置 删除/伸缩有状态集将不会删除与有状态集相关联的卷。这是为了确保数据安 有状态集目前要求headless service负责Pod的网络身份，你有责任创建此服务 组件(components) headless service，用于控制网络域 StatefulSet volumeClaimTemplates，使用持久化卷提供稳定存储 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748apiVersion: v1kind: Servicemetadata: name: nginx labels: app: nginxspec: ports: - port: 80 name: web clusterIP: None selector: app: nginx---apiVersion: apps/v1kind: StatefulSetmetadata: name: webspec: selector: matchLabels: app: nginx # has to match .spec.template.metadata.labels serviceName: "nginx" replicas: 3 # by default is 1 template: metadata: labels: app: nginx # has to match .spec.selector.matchLabels spec: terminationGracePeriodSeconds: 10 containers: - name: nginx image: k8s.gcr.io/nginx-slim:0.8 ports: - containerPort: 80 name: web volumeMounts: - name: www mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: www spec: accessModes: [ "ReadWriteOnce" ] storageClassName: "my-storage-class" resources: requests: storage: 1Gi Pod Selector必须设置有状态集的.spec.selector字段以匹配.spec.template.metadata.labels的标签。 Pod Identity有状态集Pod有一个唯一的标识，由序数、稳定的网络表示和稳定的网络存储组成。 Ordinal Index对于有多个副本的有状态集，有状态集中的每个Pod将被分配一个唯一的整数序数(ordinal)，从0–(N-1)。 Stable Network ID有状态集中的每个Pod都从有状态集的名称和Pod的序号中派生其主机名。构造的主机名的模式时$(statefulset name)-$(ordinal)。 Stable Storagek8s为每个VolumeClaimTemplate创建一个PersistentVolume。 Pod Name Label当有状态集控制器创建Pod时，它会添加一个标签statefulset.kubernetes.io/pod-name，该标签设置为Pod的名称。该标签允许你将服务附加到有状态集中的特定Pod。 部署和伸缩保证(guarantees) 对于有多个副本的有状态集，当Pod被部署时，它们按顺序从{0…N-1}被创建 但Pod被删除，它们将以{N-1…0}的相反顺序终止 在伸缩操作应用于Pod之前，所有的前置任务(predecessors)必须是Running和Ready 在终止Pod之前，其所有后继者(successors)必须完全关闭 有状态集不应该指定pod.Spec.TerminationGracePeriodSeconds为0，这很不安全，强烈建议不要这么做。 k8s v1.7+，有状态集允许你放宽Pod管理策略的排序保证，同时通过其.spec.podManagementPolicy字段保留期唯一性和身份保证。OrderedReady pod管理是有状态集的默认设置。Parallel pod管理告诉有状态集控制器并行(parallel)启动或终止所有Pod，并且在启动或终止另一个Pod之前不等待Pod变为Running、Ready或完全终止。 更新策略有状态集的.spec.updateStrategy字段允许你为有状态集中的Pod配置和禁用容器、标签、资源请求/限制、注释的自动更新。 DaemonSet守护进程集确保所有(或某些)节点运行Pod的副本。随着节点添加到集群中，会将Pod添加到集群中。随着节点从集群中移除，Pod将被垃圾回收。删除一个守护进程集会清除它创建的Pod。 守护进程集的一些典型用法： 在每个节点上运行集群存储守护进程 在每个节点上运行日志收集守护进程 在每个节点上运行一个节点监控守护进程 Writing a DaemonSet Spec 123456789101112131415161718192021222324252627282930313233343536373839404142apiVersion: apps/v1kind: DaemonSetmetadata: name: fluentd-elasticsearch namespace: kube-system labels: k8s-app: fluentd-loggingspec: selector: matchLabels: name: fluentd-elasticsearch template: metadata: labels: name: fluentd-elasticsearch spec: tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule containers: - name: fluentd-elasticsearch image: k8s.gcr.io/fluentd-elasticsearch:1.20 resources: limits: memory: 200Mi requests: cpu: 100m memory: 200Mi volumeMounts: - name: varlog mountPath: /var/log - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true terminationGracePeriodSeconds: 30 volumes: - name: varlog hostPath: path: /var/log - name: varlibdockercontainers hostPath: path: /var/lib/docker/containers 12#创建守护进程集kubectl create -f ./daemonset.yaml Required Fields与其它k8s配置一样，守护进程集需要apiVersion, kind, metadata, .spec字段。 Pod Template.spec.template是.spec的必要字段。守护进程集中的人Pod模板必须要RestartPolicy: Always(默认)。 Pod Selector 仅在某些节点上运行Pod如果指定了.spec.template.spce.nodeSelector，则守护进程控制器将在node selector匹配的节点上创建Pod。同样，如果指定了.spec.template.spec.affinity，则守护进程控制器将在与该节点关联匹配的节点上创建Pod。如果未指定任何一个，则守护进程控制器将在所有节点上创建Pod。 Daemon Pods如何调度 由守护进程集控制器调度（默认）通常，Pod运行的机器由k8s调度程序选择。然而，由守护进程集控制器创建的Pod已经选择了机器(.spec.nodeName)。 由默认调度器调度功能阶段： k8s v1.11 alpha守护进程集确保所有符合条件的节点都运行Pod的副本。 Taints and Tolerations Daemon Pods间通信守护进程集中Pod通信的一些可能模式： Push NodeIP and Known Port DNS Service 更新DaemonSet如果更改了节点标签，守护进程集会立即将Pod添加到新匹配的节点，并从新匹配的节点中删除Pod。可以修改守护进程集创建的Pod。然而，Pod不允许更新所有字段。同样，守护进程集控制器在下次创建节点时使用原始模板。你也可以删除守护进程集，若指定了--cascade=false，则会在节点上保留Pod。 守护进程集的替代方案 Init Scripts Bare Pods Static Pods Deployments 垃圾回收Garbage Collection k8s垃圾回收的作用是删除曾经拥有所有者，但不再拥有所有者的某些对象。 Owners and dependents一些k8s对象是其它对象的所有者。如副本集是一组Pod的所有者。拥有的对象称为所有者的依赖项(dependents)。每个依赖对象都有一个metadata.ownerReferences字段来指向所有者。 控制垃圾回收器如何删除依赖项删除对象时，可以指定是否也自动删除对象的依赖项。删除对象而不自动删除依赖项，则称依赖项为孤立对象(orphaned)。自动删除依赖项被称为级联删除(cascading deletion)，这有两种级联删除模式： Foreground Background 设置级联删除策略删除对象时，设置deleteOptions参数的propagationPolicy字段来控制级联删除策略。 JobsJobs - Run to Completion 作业创建一个或多个Pod，并确保指定数量的Pod成功终止。随着Pod成功完成，作业跟踪也成功完成。删除作业将清除它创建的Pod。作业还可用于并行运行多个Pod。 栗子 12345678910111213apiVersion: batch/v1kind: Jobmetadata: name: pispec: template: spec: containers: - name: pi image: perl command: ["perl", "-Mbignum=bpi", "-wle", "print bpi(2000)"] restartPolicy: Never backoffLimit: 4 123456789kubectl create -f ./job.yamljob.batch/pi createdkubectl get jobkubectl describe job/pikubectl get podkubectl logs pi-xxx Job Spec与其它k8s配置一样，Job也需要apiVersion, kind, metadata, .spec字段。 Pod Template.spec.template是.spce字段的必要项。 Pod Selector.spec.selector字段可选。 Parallel Jobs: 有三种主要类型作业 Non-parallel Jobs 通常指启动一个Pod，除非Pod失败 Pod成功终止后，作业即告完成 Parallel Jobs with a fixed completion count 为.spec.completions指定非零正值 当1-.spec.completions范围内的每个值都有一个成功的Pod时，作业就完成了 尚未实施，每个Pod都传递了1-.spec.completions范围内不同的索引 Parallel Jobs with a work queue 每个Pod独立地确定是否所有对等都完成，因此整个Job完成 当任何Pod成功终止，不会创建新的Pod 一旦至少一个Pod成功终止并且所有Pod终止，则作业成功完成 一旦任意Pod已成功退出，其它任何Pod都不应该做任何工作或输出 控制并行Controlling Parallelism 请求的并行性(.spec.parallelism)可以设置为任何非负值。如果未指定，则默认为1.如果指定为0，则作业将暂停，直至其增加。由于各种原因，实际并行性(在任何时刻运行的Pod数量)可能多于或少于请求的并行度： 对于固定完成计数的作业，并行运行的实际Pod数不会超过剩余的Pod数 对于工作多列作业，任何Pod成功后都不会启动新的Pod，但允许剩余的Pod完成 如果控制器没有时间做出反应 如果控制器因任何原因无法创建Pod 由于同一作业中过多的先前Pod故障，控制器可能会限制新的Pod创建 当Pod正常关闭时，停止需要一些时间 处理Pod和Container失败Pod中的容器可能由于多种原因而失败，如果发生此情况，并且.spec.template.spec.restartPolicy = &quot;OnFailure&quot;，那么Pod会留在节点上，但容器会重新运行。因此，你的程序需要在本地处理此情况，或指定.spec.template.spec.restartPolicy = &quot;Never&quot;。 一个完整的Pod也可能由于多种原因而失败。当Pod失败时，作业控制器启动一个新的Pod。因此，你的程序需要在新Pod重启时处理此情况。 Pod Backoff failure policy在某些情况下，由于配置中的逻辑错误等原因，你需要在重试一段时间后使作业失败。为此，可设置.spec.backoffLimit将作为视为失败前的重试次数。默认值为6s。与作业关联的失败的Pod由作业控制器重新创建，指数退避延迟(10s, 20s, 40s…)，上限6分钟。如果在作业的下一次状态检查之前没有出现新的故障Pod，则重置退避计数。 作业终止和清理Job Termination and Cleanup 作业完成后，不会再创建Pod，也不会删除Pod。保持它们可让你仍然能查看已完成的Pod的日志以检查error, warning, 或其它诊断性输出。作业对象在完成后也会保留，以便可查看其状态。在注意到其状态后，用户可删除旧的作业。 12345#一并删除作业创建的Podkubectl delete jobs/xxx#不删除作业创建的Podkubectl delete jobs/xxx -- 默认情况下，除非Pod失败，否则作业将不间断运行，此时作业将延迟到上述的.spec.backoffLimit。终止作业的另一种方法是设置活动截止日期，通过设置.spec.activateDeadlineSeconds字段来执行此操作。请注意，作业的.spec.activateDeadlineSeconds优先于.spec.backoffLimit。因此，重试一个或多个失败的Pod的作业在达到activeDeadlineSeconds指定的时间限制后将不会重置其它Pod，即使尚未达到backoffLimit也是如此。 作业模式Job Patterns 作业对象可用于支持Pod的可靠并行执行，它不是为了支持紧密通信的并行进程而设计。在复杂系统中，可能存在多组不同的工作项。这里只考虑一组工作项——批处理作业 并行计算有几种不同的模式，每种模式都有有点和缺点： 一个工作项一个作业对象 vs 所有工作项一个作业对象 创建的Pod数等于工作项数 vs 每个Pod可以处理多个工作项 多个方法使用一个工作队列 高级用法Advanced Usage 指定自己的Pod selector通常，创建作业对象时，不会指定.spec.selector。系统默认在创建作业时添加此字段。然而，在某些情况下，你可能需要设置它。这样做的时候要非常小心，如果你指定的label selector不是该作业的Pod所独有，并且与不想关的Pod匹配，则可能会删除不相关作业的Pod。如果选择了non-unique selector，则其它控制器及其Pod也可能以不可预测的方式进行。在指定.spec.selector时，k8s不会阻止你犯错误。 替代方案Alternatives Bare Pods Replication Controller Single Job starts Controller Pod Cron Jobs在指定的时间/日期创建作业。 CronJobCron Job基于时间调度创建作业。一个定时任务对象类似于crontab中的一行。它以给定的时间周期性运行作业。 注意： 所有定时作业调度， 时间以UTC表示。 定时作业局限Cron Job Limitations 定时作业在其计划的每个执行时间创建一个作业对象。如果startingDeadlineSeconds被设置为较大值或未设置(默认值)，并且concurrencyPolicy设置为Allow，则作业将始终至少运行一次。如果设置了startDeadlineSeconds字段，则控制器会计算从startingDeadlineSeconds的值到现在发生的错过的作业数，而不是从上一个计划时间到现在。如果定时作业未能在其预定时间创建，则将其视为未命中。 定时作业仅负责创建与其计划相匹配的作业，而作业则负责管理它所代表的Pod。 配置Configuration 配置最佳实践Configuration Best Practices 一般配置技巧General Configuration Tips 定义配置时，请指定最新的稳定的API版本 在推送到集群之前，配置文件应存储在版本控制系统中。这允许你在必要时快速回滚配置，有助于集群重建和恢复 使用YMAL而不是JSON来编写配置文件，YAML格式更用户友好 只要有意义，就将相关对象分组到一个文件中。管理一个文件比管理一堆文件更便捷 可以在目录上调用许多kubectl命令。例如，你可在配置文件目录上调用kubectl create 不要不必要地指定默认值 将对象描述写在注释中，以便更好进行内省 Naked Pod vs 副本集，部署和作业“Naked” Pods vs ReplicaSets, Deployments, and Jobs 不要使用Naked Pods(即未绑定到副本集或部署的Pod)如果节点发生故障，裸Pod将不会被重新调度。 服务Service 在相应的后端工作负载(部署或副本集)访问它之前创建服务当k8s启动容器时，它提供指向启动容器时正在运行的所有服务的环境变量。 除非绝对必要，否则不要为Pod指定hostPort将Pod绑定到hostPort时，它会限制Pod可调度的位置数。因为每个hostIP, hostPort, protocol的组合必须是独特的。如果没有指定hostIp和protocol，k8s将使用0.0.0.0作为默认的hostIP，使用TCP作为默认协议。 如果你只需要访问端口以进行调试，可使用apiserver proxy或kubectl port-forward。如果你需要公开节点上Pod的端口，考虑使用NodePort服务。 避免使用hostNetwork， 原因与hostPort类似 当不需要kube-proxy负载均衡时，使用 headless Services可轻松服务发现 使用标签Using Labels 为你的应用程序或部署定义和使用标签你可使用这些标签为其它资源筛选合适的Pod 容器镜像Container Images 默认的镜像拉取策略。对于容器是ifNotPresent，kubelet只有在本地镜像不存在时才拉取镜像。如果希望每次k8s启动容器时都拉取镜像，请指定imagePullPolicy: Always。一个已弃用的替代方案。设置k8s总是拉取镜像的:latest标记，它会隐式地将imagePullPolicy设置为Always。 注意： 在生产环境中部署容器时，你应该避免使用:latest标记，因为这使得正在运行的镜像版本难以回滚。如果镜像使用:latest标记，回滚的话其实需要回滚代码，然后打包上线，然后触发动态更新，之后就还原成了之前的版本。这样确实要复杂很缓慢一些。 确保容器使用使用相同版本的镜像 使用kubectl 使用kubectl apply -f &lt;directory&gt; 或 kubectl create -f &lt;directory&gt;它在此目录中所有.yaml, .yml, .json文件汇总寻找k8s配置配置文件，并将其传递给kubectl。 使用label selectors进行get和delete操作，而不是特定的对象名称 使用kubectl run和kubectl expose快速创建单容器部署和服务 管理容器的计算资源Managing Compute Resources for Containers 指定Pod时，可以选择指定每个容器需要多少CPU和MEM。当容器指定了请求(requests)的资源时，调度器可以更好地决定将Pod放在哪个节点上。当容器指定了限制(limit)时，可以以指定的方式处理节点上资源的争用。 资源类型Resource types CPU和MEM都是资源类型。资源类型具有基本单元(unix)。CPU以核(cores)为指定单位，MEM以字节(Byte)为指定单位。CPU和MEM统称为计算资源，或资源。计算资源是可以请求，分配和使用的可测量数据。它们与API资源不同。API资源(如Pod和Service)，是可通过k8s APIserver读取和修改的对象。 资源的请求和限制Resource requests and limits of Pod and Container Pod中的容器都可指定一个或多个限制： spec.containers[].resources.limits.cpu spec.containers[].resources.limits.memory spec.containers[].resources.requests.cpu spec.containers[].resources.requests.memory 虽然只能在单独的容器上指定请求和限制，但是讨论Pod资源的请求和限制很方便。特定资源类型的Pod资源 请求/限制 是Pod中每个容器的该类型的资源 请求/限制 的总和。 CPUMeaning of CPU CPU资源的限制和请求以CPU单位进行测量。在k8s中，1 cpu等于： 1 AWS vCPU 1 GCP Core 1 Azure vCore 1 IBM vCPU 1 Hyperthread on a bare-metal Intel processor with Hyperthreading 允许分数请求。如spec.containers[].resources.requests.cpu: 0.5。表达式0.1相当于表达式100m。具有小数点的请求资源(如0.1)由API转换为100m，不允许精度小于1m。始终要求CPU作为绝对数量，而不是相对数量。因此，0.1单元对于单核，双核，八核机器上的CPU资源时相同的。 MemoryMeaning of memory 内存的限制和请求以字节为单位。你可使用以下后缀来表示整数内存: E, P, T, G, M, K；你还还可以使用2的幂等: Ei, Pi, Ti, Gi, Mi, Ki。 12345#相同值的不同表达128974848129e6129M123Mi 栗子： 123456789101112131415161718192021222324252627apiVersion: v1kind: Podmetadata: name: frontendspec: containers: - name: db image: mysql env: - name: MYSQL_ROOT_PASSWORD value: &quot;password&quot; resources: requests: memory: &quot;64Mi&quot; cpu: &quot;250m&quot; limits: memory: &quot;128Mi&quot; cpu: &quot;500m&quot; - name: wp image: wordpress resources: requests: memory: &quot;64Mi&quot; cpu: &quot;250m&quot; limits: memory: &quot;128Mi&quot; cpu: &quot;500m&quot; 如何调度具有资源请求的PodHow Pods with resource requests are scheduled 创建Pod时，k8s调度器会选择要运行Pod的节点。每个节点都具有每种资源类型的最大容量，它可为Pod提供CPU和MEM。调度程序确保对于每种资源类型，调度的容器的资源请求总和小于节点的容量。请注意，即使节点上的实际内存或CPU资源使用率非常低，但如果容量检查失败，调度器扔拒绝在节点上放置Pod。当资源使用随后增加时，这可以防止节点上的资源短缺。 如何运行具有资源限制的PodHow Pods with resource limits are run 当kubelet启动Pod中的容器时，它会将CPU和MEM限制传递给容器运行环境。 当使用Docker时： spec.container[].resources.requests.cpu被转换成core value，分数的话会乘以1024。此数字中的较大值用作docker run命令中--cpu-shares标志的值 spec.container[].resources.limits.cpu被转换为millicore value并乘以100。结果值代表容器每100ms可以使用的CPU时间总量。在此间隔期间，容器不能使用超过其CPU时间的份额。默认配额时间是100ms，CPU配额的最小解析为1ms。 spec.containers[].resources.limits.memory被转换为整数，并用作docker run命令中--memory标志的值 如果容器超出其内存限制(mem limit)，则容器可能会终止。如果它可以重启，则kubelet将重启它；如果容器超出其内存请求(mem request)，当节点内存不足时，它的Pod可能会被驱逐；容器可能会/可能不会被允许在较长时间内超过其CPU限制。但是，它不会因CPU使用率过高而被杀死。 监控计算资源使用Monitoring compute resource usage Pod的资源使用情况将作为Pod Status的一部分进行上报。 本地短暂存储Local ephemeral storage FEATURE STATE: Kubernetes v1.11 beta k8s v1.8介绍了一种新资源，用于管理本地短暂存储的短暂存储(ephemeral-storage)。在每个k8s 节点上，kubelet的根目录(默认/var/lib/kubelet)和日志目录(/var/log)存储在节点的根分区上。Pod还通过emptyDir volume，容器日志，镜像层，容器可写层共享和使用此分区。此分区是短暂的，应用程序不能指望来自此分区的任何SLA(如磁盘IO)。本地临时存储仅适用于根分区，镜像层和可写层的可选分区超出了范围。 本地短暂存储的请求和限制设置Requests and limits setting for local ephemeral storage Pod中的容器可指定一个或多个短暂存储： spec.containers[].resources.limits.ephemeral-storage spec.containers[].resources.requests.ephemeral-storage 短暂存储的限制和请求以字节(Byte)为单位。你可以使用一下后缀表示整数存储: E, P, T, G, M, K；你也可以使用2的幂等: Ei, Pi, Ti, Gi, Mi, Ki。 1234128974848129e6129M123Mi 栗子： Pod由两个容器，每个容器都有2GiB的本地短暂存储请求，4GiB的本地短暂存储限制。因此，总共是4GiB请求，8GiB限制。 1234567891011121314151617181920212223apiVersion: v1kind: Podmetadata: name: frontendspec: containers: - name: db image: mysql env: - name: MYSQL_ROOT_PASSWORD value: &quot;password&quot; resources: requests: ephemeral-storage: &quot;2Gi&quot; limits: ephemeral-storage: &quot;4Gi&quot; - name: wp image: wordpress resources: requests: ephemeral-storage: &quot;2Gi&quot; limits: ephemeral-storage: &quot;4Gi&quot; 如何调度具有本地短暂存储的PodHow Pods with ephemeral-storage requests are scheduled 对于容器级的隔离，如果容器的可写层和日志使用量超过其存储限制，则Pod将被驱逐。对于Pod级别的隔离，如果所有容器的本地短暂存储使用量与Pod的emptyDir volume的总和超过了限制，则Pod将被驱逐。 扩展的资源Extended resources 扩展资源是kubernetes.io域之外的完全限定资源名称。它们允许集群操作者通告和用户使用非k8s内置资源。使用扩展资源需要两个步骤，首先，集群操作者必须通告扩展资源；其次，用户必须在Pod中请求扩展资源。 节点级扩展资源节点级扩展资源与节点相关联。 集群级扩展资源集群级扩展资源不依赖与节点。它们通常由调度器扩展程序管理——它处理资源消耗和资源配额。 使用扩展资源用户可以在pod spec中项CPU和MEM一样使用扩展资源。调度程序负责资源核算，以便不会同时为Pod分配可用的数量。API server将扩展资源的数量限制为整数。 要在Pod中使用扩展资源，在container spec中的spec.container[].resources.limits映射中包含资源名称作为键。只有满足所有请求资源时，才会调度Pod。只要无法满足资源请求，Pod就会保持在PENDING status。 1234567891011121314apiVersion: v1kind: Podmetadata: name: my-podspec: containers: - name: my-container image: myimage resources: requests: cpu: 2 example.com/foo: 1 limits: example.com/foo: 1 分配Pod到节点Assigning Pods to Nodes 你可以将Pod约束为只能在特定节点上运行，或更喜欢在特定节点上运行。有几种方法做到这一点，它们都使用label selector来进行选择。通常这种约束是不必要的，因为调度程序将自动进行合理的放置。但在某些情况下，你可能希望对Pod放置的节点进行更多控制。如确保Pod放置在安装有SSD的计算机上… 节点选择器nodeSelector 节点选择器是最简单的约束形式。nodeSelector是PodSpecs的一个字段，它指定了一个键值对的映射。要使Pod有资格在节点上运行，该节点必须将每个指示的的键值对作为标签。最常见的用法是一个键值对。 Prerequisitesk8s 集群 Attach label to the node 12345678910111213#获取节点名kubectl get nodeNAME STATUS ROLES AGE VERSIONmaster Ready master 33d v1.11.1node Ready &lt;none&gt; 33d v1.11.1salt01 Ready &lt;none&gt; 27d v1.11.1#打标签kubectl label nodes &lt;node-name&gt; &lt;label-key&gt;=&lt;label-value&gt;#查看标签kubectl get node --show-labels Add a nodeSelector field to your pod configuration 12345678910111213apiVersion: v1kind: Podmetadata: name: nginx labels: env: testspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent nodeSelector: &lt;label-key&gt;: &lt;label-value&gt; 当创建这个资源时，Pod将调度到附加此标签的节点上。 内置节点标签built-in node labels 除了你附加的标签之外，节点还有一些预先填充的标准标签。 kubernetes.io/hostname failure-domain.beta.kubernetes.io/zone failure-domain.beta.kubernetes.io/region beta.kubernetes.io/instance-type beta.kubernetes.io/os beta.kubernetes.io/arch 亲和力和反亲和力Affinity and anti-affinity 节点选择器提供了一种非常简单的方法，使用特定标签约束Pod到特定节点。目前处于测试阶段的亲和力/反亲和力功能，极大地扩展了你可以表达的约束类型。关键的改进有： 语言更具表达性 你可以指示规则是soft/preference而不是硬性要求，因此如果调度程序不能满足，也仍然会调度Pod 你可以约束运行在节点上的其它Pod的标签，而不是对节点本身的标签进行约束 亲和力有两种类型： node-affinity inter-pod affinity/anti-affinity 节点亲和力节点亲和力在概念上类似于nodeSelector，它允许你根据节点标签约束pod调度的节点。目前有两种类型的节点亲和力： requiredDuringSchedulingIgnoredDuringExecution preferredDuringSchedulingIgnoredDuringExecution 你可将它们分别是为hard和soft，前者指定了将Pod调度到节点上必须满足的规则，后者指定调度程序将尝试执行但不保证的首选项。名称的IgnoredDuringExecution部分意味着，与节点选择器的工作方式类似，如果节点标签在运行时更改，而不再满足Pod的亲和力规则，则Pod将继续在节点上运行。未来，我们计划提供requiredDuringSchedulingRequiredDuringExecution，就像Ignored一样，它将从不再满足Pod的亲和力要求的节点中驱逐Pod。 节点亲和力在spec.affinity.nodeAffinity字段中指定： 1234567891011121314151617181920212223242526apiVersion: v1kind: Podmetadata: name: with-node-affinityspec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/e2e-az-name operator: In values: - e2e-az1 - e2e-az2 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: another-node-label-key operator: In values: - another-node-label-value containers: - name: with-node-affinity image: k8s.gcr.io/pause:2.0 此节点亲和力规则表示，Pod只能防止在kubernetes.io/e2e-az-name标签键，值为e2e-az1或e2e-az2的节点上。此外，在满足条件的节点中，应优先选择具有another-node-label-key键，值为another-node-label-value的节点。节点亲和力语法支持如下操作符: In, NotIn, Exists, DoesNotExist, Gt, Lt。 如果你同时指定了nodeSelector和nodeAffinity，则必须满足两者以将Pod调度到候选节点上；如果你指定了与nodeAffinity类型关联的多个nodeSelectorTerms。那么，如果满足其中一个nodeSelectorTerms，则可以将Pod调度到节点上；如果你指定了与nodeSelectorTerms关联的多个matchExpressions。那么，只有满足所有matchExpressions的情况下，才能将Pod安排到节点上；如果删除或更改调度Pod的节点标签，则Pod不会被删除。换句话说，亲和力仅在调度Pod时起作用。 Pod间亲和力和反亲和力Pod间亲和力和反亲和力，你可以根据已在节点上运行的Pod上的标签(而不是节点标签)，来约束Pod可以调度的节点。与节点不同，Pod有命名空间，Pod标签的标签选择器必须指定选择器应该应用于哪些命名空间。 注意： Pod间亲和力和反亲和力需要大量的处理，可会显著减慢大型集群中的调度。因此，不建议在大于几百个节点的集群中使用；注意： Pod反亲和力要求节点一致地标签节点，即集群中的每个节点都必须具有匹配的topologyKey标签，如果某些节点缺少，可能会导致意外情况。 目前有两种类型的Pod亲和力和反亲和力: requiredDuringSchedulingIgnoredDuringExecution preferredDuringSchedulingIgnoredDuringExecution 同样表示hard和soft要求。 1234567891011121314151617181920212223242526272829apiVersion: v1kind: Podmetadata: name: with-pod-affinityspec: affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: security operator: In values: - S1 topologyKey: failure-domain.beta.kubernetes.io/zone podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: security operator: In values: - S2 topologyKey: kubernetes.io/hostname containers: - name: with-pod-affinity image: k8s.gcr.io/pause:2.0 Pod亲和力和反亲和力的有效操作符有: In, NotIn, Exists, DoesNotExist原则上，topologyKey可以是任一合法的label-key。但是，出于性能和安全的原因，它也有一些限制： 对于亲和力和requiredDuringSchedulingIgnoredDuringExecution的Pod的反亲和力，不允许使用空的topologykey 对于requiredDuringSchedulingIgnoredDuringExecution的Pod的反亲和力，引入控制器LimitPodHardAntiAffinityTopology是为了将topologyKey限制为kubernetes.io/hostname。如果要使其可用于自定义，可修改控制器，或禁用它 对于preferredDuringSchedulingIgnoredDuringExecution的Pod的反亲和力，空的topologyKey被解释为all topologies 除了上面提到的，topologyKey可以是任一合法的label-key 除了labelSelector和topologyKey之外，你还可以选择指定labelSelector应匹配的命名空间。如果为空或省略，则默认为Pod的亲和力/反亲和力的命名空间。 污点和容忍Taints and Tolerations 节点亲和力是Pod的属性，它将它们吸引到节点；Taints则相反——它允许节点排斥Pod。Taints 和 Tolerations 一起工作以确保Pod不被安排的不适当的节点上。将一个或多个污点(taints)应用于节点，这标志着节点不应该接受任何不能容忍污点的Pod。容忍(tolerations)应用于Pod，并允许Pod安排到具有匹配污点的节点上。 概念使用kubectl taint命令对节点添加污染: 123456#除非具有匹配的容忍，否则不会将Pod调度到此节点上kubectl taint nodes &lt;node-name&gt; key=value:NoSchedule#删除kubectl taint nodes &lt;node-name&gt; key:NoSchedule- 你可以在PodSpec的指定Pod的容忍度： 12345tolerations:- key: &quot;key&quot; operator: &quot;Equal&quot; #default value: &quot;value&quot; effect: &quot;NoSchedule&quot; 1234tolerations:- key: &quot;key&quot; operator: &quot;Exists&quot; effect: &quot;NoSchedule&quot; effect的三个选项： NoSchedule PreferNoSchedule: soft of NoSchedule NoExecute 你可在同一个节点上放置多个污点，并在同一个Pod上放置多个容忍。k8s处理多个污点和容忍的方式就像一个过滤器：从节点的所有污点开始，忽略Pod匹配的容忍度的那些，剩下的未被忽略的污点对Pod有明显的影响。尤其是： 如果至少有一个未被忽略的effect为NoSchedule的污点，则k8s将不会调度Pod到该节点 如果没有effect为NoSchedule，但至少有一个未被忽略的effect为PreferNoSchedule的污点，则k8s将尝试不将Pod调度到该节点 如果至少有一个未被忽略的effect为NoExecute的污点，则Pod将从节点驱逐(如果它已经在节点上运行)，并且不会被调度到该节点上 栗子： 123kubectl taint nodes node1 key1=value1:NoSchedulekubectl taint nodes node1 key1=value1:NoExecutekubectl taint nodes node1 key2=value2:NoSchedule 有两个容忍度的Pod： 123456789tolerations:- key: "key1" operator: "Equal" value: "value1" effect: "NoSchedule"- key: "key1" operator: "Equal" value: "value1" effect: "NoExecute" 对于NoExecute的容忍度可以指定一个可选tolerationSeconds字段，它指示在添加污点后Pod将保持绑定到节点的时间： 123456tolerations:- key: "key1" operator: "Equal" value: "value1" effect: "NoExecute" tolerationSeconds: 3600 使用案例Example Use Cases 污点和容忍是一种灵活的方式来引导Pod远离节点或驱逐不应该运行的Pod。一些栗子： 专用节点(Dedicated Nodes) 特殊硬件的节点(Nodes with Special Hardware) 基于污点的驱逐(Taint based Evictions) Taint based Evictions内置的污点： node.kubernetes.io/not-ready node.kubernetes.io/unreachable node.kubernetes.io/out-of-disk node.kubernetes.io/memory-pressure node.kubernetes.io/disk-pressure node.kubernetes.io/network-unavailable node.kubernetes.io/unschedulable node.cloudprovider.kubernetes.io/uninitialized 使用NoExecute容忍的DaemonSet Pod为以下污点创建，没有tolerationSeconds： node.alpha.kubernetes.io/unreachable node.kubernetes.io/not-ready 这可确保DaemonSet Pod永远不会因为这个问题而被驱逐，这与禁用此功能时的行为相匹配。 按条件污染节点Taint Nodes by Condition 节点控制器创建对应于节点条件的污点。当启用此功能，调度程序不检查节点条件，调度程序检查污点。这可确保节点条件不会影响节点上的调度。用户可以通过添加适当的Pod容忍来选择忽略节点的一些问题。 DaemonSet controller自动将一下NoSchedule的容忍度添加到所有的守护进程，以防止守护进程破坏： node.kubernetes.io/memory-pressure node.kubernetes.io/disk-pressure node.kubernetes.io/out-of-disk (only for critical pods) node.kubernetes.io/unschedulable (1.10 or later) node.kubernetes.io/network-unavailable (host network only) 添加这些容忍度可确保向后兼容，你还可以向DaemonSet添加任意容忍度。 SecretsSecrets类型的对象旨在保存敏感信息，如密码、OAuth token、ssh keys。把这些敏感信息放在Secrets中比将其放在Pod中或image中更安全、更灵活。 概述用户和系统都可以创建一些秘密(Secrets)。要使用秘密，Pod需要引用该秘密。秘密可以通过两种方式与Pod一起使用： 作为挂载到容器中的卷中的文件 为Pod拉取镜像时由kubelet使用的文件 内建的秘密Built-in Secrets Service Accounts Automatically Create and Attach Secrets with API Credentialsk8s会自动创建包含用于访问API的证书的秘密，并自动修改Pod以使用此类秘密。你可禁用它，但不推荐。 创建自己的秘密Creating your own Secrets 使用kubectl创建秘密(Creating a Secret Using kubectl create secret)假设一些Pod需要访问数据库： 12345678910111213141516171819202122232425$ echo -n &apos;admin&apos; &gt; ./username.txt$ echo -n &apos;1f2d1e2e67df&apos; &gt; ./password.txt#创建秘密$ kubectl create secret generic db-user-pass --from-file=./username.txt --from-file=./password.txtsecret/db-user-pass created#查看#默认都不会显示文件内容，为了安全kubectl get secretskubectl describe secrets/db-user-passName: db-user-passNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Type: OpaqueData====password.txt: 12 bytesusername.txt: 5 bytes 手动创建秘密(Creating a Secret Manually)每项必须是base64编码： 123456789101112131415161718192021$ echo -n &apos;admin&apos; | base64YWRtaW4=$ echo -n &apos;1f2d1e2e67df&apos; | base64MWYyZDFlMmU2N2Rm#现在编写一个秘密对象文件#db-user-pass.yamlapiVersion: v1kind: Secretmetadata: name: mysecrettype: Opaquedata: username: YWRtaW4= password: MWYyZDFlMmU2N2Rm#创建它$ kubectl create -f ./secret.yamlsecret &quot;mysecret&quot; created 解码秘密(Decoding a Secret) 12345678910111213141516171819kubectl get secret mysecret -o yamlapiVersion: v1data: username: YWRtaW4= password: MWYyZDFlMmU2N2Rmkind: Secretmetadata: creationTimestamp: 2016-01-22T18:41:56Z name: mysecret namespace: default resourceVersion: &quot;164619&quot; selfLink: /api/v1/namespaces/default/secrets/mysecret uid: cfee02d6-c137-11e5-8d73-42010af00002type: Opaque#解码$ echo &apos;MWYyZDFlMmU2N2Rm&apos; | base64 --decode1f2d1e2e67df 使用秘密Using Secrets秘密可以作为数据卷来挂载，也可作为环境变量公开，以供Pod中的容器使用。它们也可以由系统的其它部分使用，而不是直接暴露在Pod中。 将秘密用作Pod中的文件(Using Secrets as Files from a Pod)在Pod中的卷中使用秘密： 创建或使用已有的秘密。多个Pod可以引用相同的秘密 修改Pod定义以添加卷和挂载卷 修改镜像或命令行，以便程序在该挂载目录中查找文件 栗子： 12345678910111213141516apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: mypod image: redis volumeMounts: - name: foo mountPath: "/etc/foo" readOnly: true volumes: - name: foo secret: secretName: mysecret 向指定路径投射密钥(Projection of secret keys to specific paths)栗子： 123456789101112131415161718192021apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: mypod image: redis volumeMounts: - name: foo mountPath: "/etc/foo" readOnly: true volumes: - name: foo secret: secretName: mysecret items: - key: username path: my-group/my-username#username秘密存储在/etc/foo/my-group/my-username而不是/etc/foo/username#password秘密没有投射 **秘密文件权限(Secret files permissions)你还可以指定秘密所具有的的权限: 12345678910111213141516apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: mypod image: redis volumeMounts: - name: foo mountPath: "/etc/foo" volumes: - name: foo secret: secretName: mysecret defaultMode: 256 #0400(八进制) 12345678910111213141516171819apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: mypod image: redis volumeMounts: - name: foo mountPath: "/etc/foo" volumes: - name: foo secret: secretName: mysecret items: - key: username path: my-group/my-username mode: 511 #0777 从卷中使用秘密值(Consuming Secret Values from Volumes)在挂载秘密卷的容器内，密钥显示为文件，秘密值基于base64进行解码并存储在这些文件中。 1234567$ ls /etc/foo/usernamepassword$ cat /etc/foo/usernameadmin$ cat /etc/foo/password1f2d1e2e67df 挂载的秘密会自动更新(Mounted Secrets are updated automatically) 当更新卷中已经使用的秘密时，最终也会更新投射的密钥。 使用秘密作为环境变量(Using Secrets as Environment Variables)要在Pod中的环境变量中使用秘密： 创建或使用已有的秘密。多个Pod可引用同一个秘密 修改Pod定义 修改Image或命令行，以便程序在指定的环境变量中查找值 栗子： 1234567891011121314151617181920apiVersion: v1kind: Podmetadata: name: secret-env-podspec: containers: - name: mycontainer image: redis env: - name: SECRET_USERNAME valueFrom: secretKeyRef: name: mysecret key: username - name: SECRET_PASSWORD valueFrom: secretKeyRef: name: mysecret key: password restartPolicy: Never 从环境变量中使用秘密值Consuming Secret Values from Environment Variables 容器内使用的环境变量的秘密值，它显示为base64的解码值。 1234$ echo $SECRET_USERNAMEadmin$ echo $SECRET_PASSWORD1f2d1e2e67df Using imagePullSecretsimagePullSecret是一种包含docker image registry password的秘密传递给kubelet的方法，因此它可以用于Pod拉取你的私有镜像。 细节 限制Restrictions 验证密钥卷源以确保指定的对象引用实际指向的秘密类型对象。因此，需要在任何Pod依赖它之前先创建秘密。Secret API对象驻留在命名空间中，它们只能由同一命名空间中的Pod引用。单个秘密的大小被限制为1MB。这是为了阻止创建非常大的秘密，这会耗尽apiserver和kubelet的内存。然而，创建许多小的秘密也可能耗尽内存。更多关于限制秘密对内存的使用是未来的计划功能。kubelet仅支持使用从apiserver获取的Pod秘密。这包含由kubectl创建的秘密，不包含通过--manifest-url标志或REST API创建的秘密。 Secret和Pod的终生交互Secret and Pod Lifetime interaction 通过API创建Pod时，不会检查引用的秘密是否存在。一旦调度了Pod，kubelet将尝试获取秘密值。如果由于该秘密不存在或暂时缺少与apiserver的连接而无法获取该秘密，则kubelet将定期重试。它将报告有关Pod的事件，说明它尚未启动的原因。一旦获取到秘密，kubelet将创建并挂载包含它的卷，在挂载所有Pod的卷之前，Pod的容器都不会启动。 使用案例 Pod with ssh keys 1234567891011121314151617181920212223#创建包含ssh keys的秘密kubectl create secret generic ssh-key-secret --from-file=ssh-privatekey=/path/to/.ssh/id_rsa --from-file=ssh-publickey=/path/to/.ssh/id_rsa.pub#创建引用此秘密的Podkind: PodapiVersion: v1metadata: name: secret-test-pod labels: name: secret-testspec: volumes: - name: secret-volume secret: secretName: ssh-key-secret containers: - name: ssh-test-container image: mySshImage volumeMounts: - name: secret-volume readOnly: true mountPath: &quot;/etc/secret-volume&quot; Pods with prod / test credentials 12345678910111213141516171819202122232425262728293031323334353637383940414243444546$ kubectl create secret generic prod-db-secret --from-literal=username=produser --from-literal=password=Y4nys7f11secret &quot;prod-db-secret&quot; created$ kubectl create secret generic test-db-secret --from-literal=username=testuser --from-literal=password=iluvtestssecret &quot;test-db-secret&quot; created#Pod中引用apiVersion: v1kind: Listitems:- kind: Pod apiVersion: v1 metadata: name: prod-db-client-pod labels: name: prod-db-client spec: volumes: - name: secret-volume secret: secretName: prod-db-secret containers: - name: db-client-container image: myClientImage volumeMounts: - name: secret-volume readOnly: true mountPath: &quot;/etc/secret-volume&quot;- kind: Pod apiVersion: v1 metadata: name: test-db-client-pod labels: name: test-db-client spec: volumes: - name: secret-volume secret: secretName: test-db-secret containers: - name: db-client-container image: myClientImage volumeMounts: - name: secret-volume readOnly: true mountPath: &quot;/etc/secret-volume&quot; Dotfiles in secret volume隐藏文件 123456789101112131415161718192021222324252627kind: SecretapiVersion: v1metadata: name: dotfile-secretdata: .secret-file: dmFsdWUtMg0KDQo=---kind: PodapiVersion: v1metadata: name: secret-dotfiles-podspec: volumes: - name: secret-volume secret: secretName: dotfile-secret containers: - name: dotfile-test-container image: k8s.gcr.io/busybox command: - ls - &quot;-l&quot; - &quot;/etc/secret-volume&quot; volumeMounts: - name: secret-volume readOnly: true mountPath: &quot;/etc/secret-volume&quot; Secret visible to one container in a pod考虑一个需要处理HTTP请求，执行一些复杂业务逻辑，然后使用HMAC签署一些消息的程序。由于它具有复杂的逻辑，因此可能存在未被注意的文件读取漏洞，这可能会将私钥暴露给攻击者。 这可以分为两个容器中的两个进程： 前端容器处理用户交互和业务逻辑，但无法看到私钥 后端容器可查看签名的私钥，并相应来自前端的签名请求 最佳做法Clients that use the secrets API 在部署与Secret API交互的应用程序时，应使用RBAC等授权策略限制访问。 安全属性保护由于可以独立于P使用秘密的Pod来创建秘密，因此在创建、查看、编辑Pod的工作流程中泄露秘密的风险较小。系统还可以对秘密对象采取额外的预防措施，如尽可能避免将其写入磁盘。如果节点上的Pod需要秘密，则仅将秘密发送到节点。它不会写入磁盘，而是存储在tmpfs中(RAM)。一旦删除依赖它的Pod，它就会被删除。节点上的秘密数据存储在tmpfs volume中，因此不会停留在节点上。在大多数k8s项目维护的发行版中，用于与apiserver之间的通信，以及apiserver到kubelet的通信受到SSL/TLS保护。同一节点上可能存在多个Pod的秘密，但是，只有Pod请求的密码可能在其容器中可见。因此，一个Pod无法访问另一个Pod的秘密。同一个Pod中可能有几个容器，但是，Pod中的每个容器都必须在其volumeMounts中请求秘密卷，以使其在容器中可见。 风险 apiserver中，秘密数据以明文形式存储在etcd中。因此： 管理员应该限制用户对etcd的访问权限 apiserver中的秘密数据在etcd使用的磁盘上处于静止状态；管理员可能想要在不再使用时擦除etcd使用的磁盘 如果通过json/yaml文件配置秘密，该文件的秘密数据的编码为base64，则该秘密可能被泄露。base64编码不是加密方法，被认为与纯文本相同 应用程序仍然需要在从卷读取秘密值后保护它 可创建使用秘密的Pod的用户也可看到秘密的值 如果运行了etcd的多个副本，则它们之间将共享秘密 目前，任何在节点上具有root权限的用户都可以模拟kubelet从apiserver中读取任何秘密 使用kubeconfig文件组织集群访问Organizing Cluster Access Using kubeconfig Files 使用kubeconfig文件来组织有关集群、用户、命名空间、身份验证机制的信息。kubectl使用kubeconfig文件来查找选择集群并与集群apiserver通信所需的信息。用于配置对集群的访问的文件称为kubeconfig。这是引用配置文件的普通方法，这并不意味着有一个名为kubeconfig的文件。 默认情况下，kubectl从$HOME/.kube目录下查找名为config的文件。你可以通过--kubeconfig标志设置KUBECONFIG环境变量来指定kubeconfig文件。 支持多集群、用户、认证机制Supporting multiple clusters, users, and authentication mechanisms 假设你有多个集群，并且用户和组件以各种方式进行认证： 正在运行的kubelet可能使用证书进行认证 用户可能使用令牌认证 管理员可能拥有他为用户提供的证书集 使用kubeconfig，你可以组织集群、用户和命名空间。你还可以定义上下文，以便在集群和命名空间之间快速进行切换。 上下文kubeconfig文件中的上下文元素用于在方便的名称下对访问参数进行分组。每个上下文都有三个参数：集群、命名空间、用户。默认情况下，kubectl使用从当前上下文的参数与集群通信。 12#Modify kubeconfig fileskubectl config -h KUBECONFIG环境变量$KUBECONFIG环境变量包含kubeconfig文件列表，它不是必须的。如果不存在，则kubectl使用默认的$HOME/.kube/config；如果存在，则kubectl使用有效配置。在Linux/Mac上使用冒号分隔，Windows使用分号分隔。 12echo $KUBECONFIG/etc/kubernetes/admin.conf 合并kubeconfig文件Merging kubeconfig files 12#查看配置kubectl config view 如果设置了--kubeconfig标志，则仅使用指定的文件。不合并，只允许此标志的一个实例。 否则，如果设置了$KUBECONFIG环境变量，将其应用于合并的文件列表。遵循以下规则： 忽略空文件名 对包含无法反序列化内容的文件生成错误 设置成特定值或映射见的第一个文件获胜 切勿修改值或映射键 否则，使用默认的$HOME/.kube/config文件，不做合并 Pod优先级和抢占Pod Priority and Preemption FEATURE STATE: Kubernetes 1.8 alphaFEATURE STATE: Kubernetes 1.11 beta Pod也有优先级，优先级表示Pod相对于其它Pod的重要性。如果无法调度Pod，则调度程序会尝试抢占(驱逐)较低优先级的Pod，以便可以处理待调度(Pending)的Pod。优先级还会影响Pod的调度顺序和节点上的资源驱逐顺序。 使用优先级和抢占How to use priority and preemption 要在k8s v1.11+使用优先级和抢占，遵循以下步骤： 添加一个或多个优先级类(PriorityClassed) 创建带有priorityClassName的Pod设置为添加的优先级类之一。当然，你不需要直接创建Pod，通常你只需要将priorityClassName添加到对象的Pod模板(如deployment) 禁用抢占How to disable preemption 禁用Pod优先级和抢占要禁用Pod优先级，请为apiserver、调度程序、kubelet将该功能设置false——--feature-gates=PodPriority=false 仅禁用抢占在k8s v1.11+，抢占由kube-scheduler的disablePreemption标志控制，默认设置为fasle。 12345678apiVersion: componentconfig/v1alpha1kind: KubeSchedulerConfigurationalgorithmSource: provider: DefaultProvider...disablePreemption: true PriorityClass优先级类(priorityClass)是一个非命名空间的对象，它定义从优先级类名到优先级的整数值的映射。该名称在PriorityClass对象的metadata的name字段中指定，必须的值在value字段中定义。值越高，优先级越高。优先级类对象可以具有小于等于10亿的任何32位整数值。较大的数字保留给通常不会被抢占或驱逐的系统Pod。集群管理员应为他们想要的每个这样的映射创建一个优先级类对象。优先级类有两个可选字段： globalDefault： 表示该优先级类的值应该用于没有priorityClassName的Pod，系统中只能有一个globalDefault为true的Pod。如果没有设置为globalDefault的优先级类，则Pod的优先级为零。 description： 旨在告诉用户何时应该使用此优先级类 有关PodPriority和现有集群的说明： 如果升级现有集群并启用此功能，则现有的Pod的优先级实际上为零 将globalDefault设置为true的优先级类添加将不会更改现有Pod的优先级。它的值仅用于添加优先级类之后创建的Pod 如果删除优先级类，则使用已删除的优先级类名称的现有Pod保持不变，但无法创建使用已删除的优先级类名称的Pod 栗子： 1234567apiVersion: scheduling.k8s.io/v1beta1kind: PriorityClassmetadata: name: high-priorityvalue: 1000000globalDefault: falsedescription: &quot;This priority class should be used for XYZ service pods only.&quot; Pod priority当有一个或多个优先级类之后，你就可以创建在spec中指定priority class name的Pod。优先级许可控制器使用priorityClassName字段并填充优先级的整数值。如果为找到优先级，则决绝Pod。 栗子： 123456789101112apiVersion: v1kind: Podmetadata: name: nginx labels: env: testspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent priorityClassName: high-priority Pod优先级对调度顺序的影响启用Pod优先级后，调度程序按其优先级对挂起的Pod进行排序，并将挂起的Pod置于调度队列中优先级较低的其它挂起Pod之前。因此，如果满足调度要求，则优先级较低的Pod可以更快地安排具有较低优先级的Pod。如果无法调度此类Pod，则调度程序将继续并尝试安排其它较低优先级的Pod。 Preemption创建Pod时，它们会进入队列并等待调度。调度程序从队列中选择一个Pod并尝试在节点上调度它。如果未找到满足Pod的所有指定要求的节点，则会为挂起的Pod触发抢占逻辑。抢占逻辑试图找到一个节点，其中删除优先级低于Pod P的一个或多个Pod，使得能够在该节点上调度Pod P。如果找到了此节点，则会删除那些Pod，在他们消失后，可在节点上调度Pod P。 用户公开的信息User exposed information 当Pod P在节点上抢占一个或多个Pod时，Pod P的状态的nominatedNodeName字段被设置为节点的名称。该字段帮助调度器追踪为Pod P保留的资源，并且还向用户提供关于其集群中的抢占信息。请注意，Pod P不一定安排到nominated node。在受害Pod被抢占后，它们将获得优雅的终止期。如果在调度程序等待受害Pod终止时另一个节点可用，则调度程序将使用另一个节点来调度Pod P。因此，Pod spec中的nominatedNodeName和nodeName并不总是相同。此外，如果调度程序在节点上抢占Pod，然后有比Pod P更高优先级的Pod到达，则调度程序可以将节点提供给新的更高优先级的Pod。 抢占的局限性Limitations of preemption Graceful termination of preemption victims PodDisruptionBudget is supported, but not guaranteed! Inter-Pod affinity on lower-priority Pods Cross node preemption 调试Pod优先级和抢占优先级和抢占可能会引起潜在的问题： Pods are preempted unnecessarily Pods are preempted, but the preemptor is not scheduled Higher priority Pods are preempted before lower priority pods Pod优先级和QoS的交互Interactions of Pod priority and QoS 调度程序的抢占逻辑在选择抢占目标是会考虑QoS。考虑QoS和Pod优先级的唯一组件kubelet out of resource驱逐。kubelet首先根据他们对饥饿资源的使用是否超过请求，然后按优先级，通过相对于Pod的调度请求消耗的计算资源来排除Pod的驱逐。kubelet资源溢出驱逐不会驱逐资源使用不超过其请求的Pod。如果 优先级较低的未超过其请求，则不会被驱逐。另一个优先级高高于其请求的Pod可能被驱逐。 服务，负载均衡和网络Services, Load Balancing, and Networking Servicesk8s Pod是会死的，从出生到死亡，它们没有复活(resurrected)。副本集特别地动态创建和销毁Pod。虽然每个Pod都有自己的IP，但即使是那些IP也不能依赖它们随时间变得稳定。这导致一个问题，如果某些Pod为k8s集群内的其它Pod提供功能，那么它们如何找出并追踪它们呢？这就需要用到服务了。 k8s 服务是一个抽象，它定义了一组逻辑Pod和一个访问它们的策略，有时称为微服务(micro-service)。服务目标的Pod由Label Selector来确定。 对于原生k8s应用程序，k8s提供了提供了一个简单的Endpoints API，只要服务中的Pod集发生变化，它就会更新。对于非原生k8s应用程序，k8s提供了一个基于虚拟IP的服务桥接器，可以重定向到后端的Pod。 定义服务Defining a service k8s中的服务是一个REST对象，类似于Pod。与所有REST对象一样，可以将服务定义POST到apiserver以创建实例。 例如： 1234567891011kind: ServiceapiVersion: v1metadata: name: my-servicespec: selector: app: MyApp ports: - protocol: TCP port: 80 targetPort: 9376 此规范会创建一个名为my-service的服务对象，该对象使用app=MyApp的标签定位任何Pod上的TCP协议9376端口。服务还将分配一个IP地址(称为cluster IP)，由服务代理(service proxy)使用。将连续评估服务的selector，并将结果POST到名为my-service的Endpoints对象。请注意，服务可以将传入端口映射到任何targetPort。默认情况下，targetPort将设置为与port字段相同的值。也许更有趣的是targetPort可以是一个字符串，指的是后端Pod中端口的名称。分配给该名称的实际端口号在每个后端Pod中可以不同。这为部署和发展你的服务提供了很大的灵活性。例如，你可以更改Pod的后端软件中公开的端口号，而不会破坏客户端。k8s 服务支持TCP和UDP协议，默认是TCP。 Services without selectors服务通常抽象访问k8s Pods，但它们也可以抽象访问其它类型的后端。例如： 你希望在生产环境中拥有外部数据库集群，但在测试环境中你使用自己的数据库 你希望将服务指向另外的命名空间或集群 你正在将工作负载迁移到k8s，并且你的一些后端运行在k8s之外 在任何方案中，你都可以定义不带选择器(selector)的服务： 123456789kind: ServiceapiVersion: v1metadata: name: my-servicespec: ports: - protocol: TCP port: 80 targetPort: 9376 由于此服务没有选择器(selector)，因此不会创建相应的Endpoints对象。你可以手动将服务映射到你自己的特定端点： 123456789kind: EndpointsapiVersion: v1metadata: name: my-servicesubsets: - addresses: - ip: 1.2.3.4 ports: - port: 9376 在没有选择器的情况下访问服务的工作方式与使用选择器的方式相同。流量都会被路由到定义的端点。 ExternalName service是一种特殊的服务案例，它没有选择器并且使用DNS名称代替。 虚拟IP和服务代理Virtual IPs and service proxies 在k8s v1.0中，服务是四层构造(tcp/udp)，代理纯粹实在用户空间中。在k8s v1.1中，添加了Ingress API来表示七层服务(HTTP)，也添加了iptables proxy。并成为k8s v1.2的默认操作模式。在k8s v1.8.0中，添加了ipvs proxy。 k8s 集群中的每个节点都运行一个kube-proxy——它负责为ExternalName以外类型的服务实现一种形式的虚拟IP。在任何这些代理模式中，绑定到服务的ip:port的任何流量都将代理到适当的后端，而客户端不知道有关k8s或服务或Pod的任何信息。 Proxy-mode: userspace 在userspace模式下，kube-proxy会监视k8s master以添加和删除Service和Endpoints对象。对于每个服务，它在本地节点上打开一个端口(随机选择)。与此proxy port的任何连接都将代理到服务后端的Pod之一，并根据服务的SessionAffinity决定使用哪个后端Pod。最后，它将安装iptables规则，捕获流量到服务的cluster IP(虚拟IP)，并将流量重定向到代理后端Pod的代理端口。默认情况下，后端的选择是轮询(round robin)。 Proxy-mode: iptables 在iptables模式下，kube-proxy会监视k8s master以添加和删除Service和Endpoint对象。对于每个服务，它将安装iptables规则，捕获流量到服务的cluster IP和端口，并将流量重定向到服务的后端集之一。对于每个Endpoint对象，它会按照选择后端Pod的iptables规则。默认情况下，后端的选择是随机的。显然，iptables不需要再用户空间(userspace)和内核空间(kernelspace)之间切换，它应该比用户空间代理更快更可靠。然而，与用户空间代理不同，如果最初选择的Pod没有响应，则iptables代理无法自动重试另一个Pod，因此它依赖于readiness probes的工作。 Proxy-mode： ipvs FEATURE STATE: Kubernetes v1.9 beta 在ipvs模式下，kube-proxy监视k8s的Service和Endpoints，调用netlink接口以相应地创建ipvs规则，并定期与k8s的Service和Endpoint同步ipvs规则，以确保ipvs转台与期望一致。访问服务时，流量将被重定向到其中一个后端Pod。与iptables类似，ipvs基于netfilter hook函数，但是用hash table作为底层数据结构，并在内核空间中工作。这意味着ipvs可以更快地重定向流量，并且再同步代理规则时具有更好的性能。此外，ipvs为负载均衡算法提供了更多选项： rr： round-robin lc： least connection dh： destination hashing sh： source hashing sed： shortest expected delay nq： never queue 注意：ipvs模式假设在运行kube-proxy之前便已在节点上安装了IPVS内核模块。当kube-proxy以ipvs代理模式启动时，kube-proxy将验证节点上是否安装了IPVS模块，如果未安装，则kube-proxy将回退到iptables代理模式。 多端口服务Multi-Port Services 许多服务可能需要公开多个端口。对于此情况，k8s支持服务对象上的多个端口定义。当使用多个端口时，必须提供所有端口名称，以便消除端点(Endpoint)的歧义。请注意，端口名称只能包含小写字母数字和横杠-，并须以字母数字结尾。 12345678910111213141516kind: ServiceapiVersion: v1metadata: name: my-servicespec: selector: app: MyApp ports: - name: http protocol: TCP port: 80 targetPort: 9376 - name: https protocol: TCP port: 443 targetPort: 9377 选择自己的IPChoosing your own IP address 你可以将自己的cluster ip指定为服务创建请求的一部分。为此，请设置.spec.clusterIP字段。用户选择的IP地址必须是有效的IP地址，并且在apiserver的标志指定的service-cluster-ip-range CIDR范围内。如果IP地址无效，则apiserver返回422 HTTP statuscode以指示该值无效。 为什么不适用DNS轮询？Why not use round-robin DNS? 为什么我们使用虚拟IP来完成所有这些工作，而不仅仅是标准的DNS轮询。原因如下： DNS libraries的历史悠久，不尊重DNS TTL并缓存名称的查找结果 许多应用程序执行一次DNS查找并缓存结果 即使应用程序和库进行了适当的重新解析，每个客户算反复重新解析DNS的负载也是难以管理的 我们试图阻止用户做出伤害自己的事情。也就是说，如果有足够的人要求这样做，我们可以将其作为替代方案来实施。 服务发现Discovering services k8s支持两种寻找服务的主要模式： enviroment variables和DNS。 Environment variables当Pod在节点上运行时，kubelet为每个活跃的服务添加一组环境变量。它支持Docker links compatible变量和更简单的{SVCNAME}_SERVICE_HOST和{SVCNAME}_SERVICE_PORT变量。 栗子，如redis-master服务公开TCP6379端口，并分配了10.0.0.11的cluster ip以生成如下环境变量： 1234567REDIS_MASTER_SERVICE_HOST=10.0.0.11REDIS_MASTER_SERVICE_PORT=6379REDIS_MASTER_PORT=tcp://10.0.0.11:6379REDIS_MASTER_PORT_6379_TCP=tcp://10.0.0.11:6379REDIS_MASTER_PORT_6379_TCP_PROTO=tcpREDIS_MASTER_PORT_6379_TCP_PORT=6379REDIS_MASTER_PORT_6379_TCP_ADDR=10.0.0.11 这有一个要求——必须在Pod本身之前创建它想要访问的任何服务，否则将不会填充环境变量。DNS没有此限制。 DNS可选的集群加载项是DNS server(强烈推荐)。DNS server监视k8s API以获取新服务，并为每个服务创建一组DNS 记录。如果已在集群中启用DNS，则所有Pod应该能够自动对服务进行名称解析。 例如，如果你在k8s命名空间my-ns中创建一个服务my-service，则会创建my-service.my-ns的DNS记录。存在于my-ns命名空间中的Pod应该能够通过简单地对my-service服务进行名称查找来找到它。存在于其它命名空间的Pod必须将名称限定为my-service.my-ns。这些名称查找的结果是cluster ip。k8s还支持命名端口的DNS SRV(service)记录。如果my-service.my-ns服务具有带有TCP协议的名为http的端口，则可以对_http._tcp.my-service.my-ns执行DNS SRV查询以发现http的端口号。k8s DNS server是访问ExternalName类型的服务的唯一方法。 Headless services有时你不需要或不想要负载均衡和单个服务IP。在这种情况下，你可以通过将clusterIP(.spec.clusterIP)指定为None来创建一个headless服务。此选项允许开发人员通过允许他们自由地以自己的方式进行发现来减少与k8s系统的耦合。应用程序仍然可以使用自注册(self-registration)模式，并且可以轻松地在API上构建适用于其它发现系统的适配器。 对于此类服务，并未分配clusterIP，kube-proxy也不处理这些服务，并且平台没有为它们执行负载均衡和代理。如何自动配置DNS取决于服务是否已定义选择器(selector)： With selectors对于定义了选择器的headless服务，端点控制器(endpoints controller)在API中创建端点记录(Endpoint records)，并修改DNS配置以返回直接指向支持服务的Pod的A记录(地址)。 Without selectors对于没有定义选择器的headless服务，端点控制器不会创建端点记录。但是，DNS系统会查找并配置下面任一项； ExternalName类型的服务的CNAME记录 所有其它类型的，与服务共享名称的任何端点记录 发布服务和服务类型Publishing services - service types 对于应用程序的某些部分(如前端)，你可能希望将服务公开到外部IP地址(集群外)。k8s ServiceTypes允许你指定所需的服务类型，默认为ClusterIP。 类型如下： ClusterIp在集群内部IP上公开服务，选择此值使服务只能从集群内访问。这是默认的服务类型。 NodePort在每个节点IP的静态端口上公开服务。将自动创建cluster ip服务(NodePort服务将路由到此服务)。你可以在集群外部通过请求&lt;NodeIP&gt;:&lt;NodePort&gt;来联系NodePort服务 LoadBalancer使用云提供商的负载均衡器在外部公开服务。将自动创建外部负载均衡器路由到NodePort服务和ClusterIP服务。 ExternalName通过返回CNAME记录的值，将服务映射到externalName字段的内容。没有设置任何类型的代理。这需要kube-dns v1.7+。 NodePortNodePort类型下，k8s master将从--service-node-port-range标志指定的范围(默认 30000-32767)分配端口，(当然，你也可以在此范围了自定义)，并且每个节点将代理进入服务的端口(每个节点上的端口号相同)。服务中的.spec.ports[].nodePort字段。 如果要制定代理端口的特定IP，可将kube-proxy中的--nodeport-addresses标志 设置为特定IP块(从k8s v1.10+支持)。使用逗号,分隔IP块列表(如10.0.0.0/8,1.2.3.4/31)用于过滤此节点的本地地址。例如，如果你使用--nodeport-address=127.0.0.0/8标志启动kube-proxy，则kube-proxy将仅为NodePort服务选择环回地址接口(loopback)。--nodeport-address默认为空，这意味着选择所有可用的接口并符合当前的NodePort行为。 如果你需要特定的端口号，可以在nodePort字段中指定一个值，系统将为你分配该端口。请注意，指定的端口值必须在默认范围内，且没有端口冲突。 请注意，服务将同时显示&lt;NodeIP&gt;:spec.ports[*].nodePort和.spec.clusterIP:spec.ports[*].port。 LoadBalancer在支持外部负载均衡器的云提供商上，将type字段设置为LoadBalancer将为服务配置负载均衡器。负载均衡器的实际创建是异步(asynchronously)发生的，有关已配置的均衡器的信息将发布在服务的.status.loadBalancer字段。 栗子： 123456789101112131415161718kind: ServiceapiVersion: v1metadata: name: my-servicespec: selector: app: MyApp ports: - protocol: TCP port: 80 targetPort: 9376 clusterIP: 10.0.171.239 loadBalancerIP: 78.11.24.19 type: LoadBalancerstatus: loadBalancer: ingress: - ip: 146.148.47.155 来自外部负载均衡器的流量将指向后端Pod，但具体如何工作取决于云提供商。某些云提供商允许指定loaBalancerIP。在这些情况下，将使用用户指定的loadBalancerIP创建负载均衡器。如果未指定loadBalancerIP字段，则将为负载均衡器分配临时IP。如果指定了loadBalancerIP字段，但云提供商不支持该功能，则该字段被忽略。 一些云提供商： AWS Azure GCP Aliyun TencentCloud ExternalName NOTE: ExternalName Services are available only with kube-dns version 1.7 and later. ExternalName类型的服务将服务映射到DNS名称(使用spec.externalName)，而不是映射到传统的选择器(如my-service)。 栗子： 12345678kind: ServiceapiVersion: v1metadata: name: my-service namespace: prodspec: type: ExternalName externalName: my.database.example.com 查找主机my-service.prod.svc.CLUSTER时，集群DNS服务将返回my.database.example.com的CNAME记录。访问my-service服务的工作方式与其它服务的工作方式相同，但重要的区别在于重定向发生在DNS级别，而不是通过代理或转发。 External IPs如果有外部IP路由到一个或多个集群节点，则可以在这些externalIPs上公开k8s 服务。在服务端口上使用外部IP，进入集群的流量将路由到其中一个服务端点。外部IP不由k8s管理，它是集群管理员的责任。 栗子； 1234567891011121314kind: ServiceapiVersion: v1metadata: name: my-servicespec: selector: app: MyApp ports: - name: http protocol: TCP port: 80 targetPort: 9376 externalIPs: - 80.11.12.10 不足Shortcomings 使用虚拟IP(VIP)的用户空间(userspace)将在中小规模(small to medium scale)上工作，但不会扩展到具有成千上万个服务的大集群中。 使用用户空间代理会模糊访问服务的数据包的源IP，这使得某些类型的防火墙变得不可能。iptabels代理不会掩盖集群内源IP，但它仍然会影响通过负载均衡器或节点端口的客户端。 Type字段设置为嵌套功能——每个级别都添加到前一个级别。并非所有云服务商都严格要求这样做，但目前的API需要它。 VIP细节The gory details of virtual IPs 避免冲突(Avoiding collisions)k8s的主要哲学之一是用户不应该暴露可能导致他们的行为失败的情况，而不是他们自己的过错。在这种情况下，我们查看网络端口——用户不应该选择可能与另一个用户发生冲突的网络端口。这叫隔离失败。为了允许用户为服务选择端口号，我们必须确保没有服务间的冲突。我们通过为每个服务分配IP地址来做到这一点。 为了确保每个服务都接收到一个唯一的IP，内部分配器会在创建每个服务之前以原子方式更新etcd中的全局分配映射。映射对象必须存在于映射表中以获取IP，否则创建将失败并显示一条消息，指示无法分配IP。后台控制器负责创建该映射以及由于管理员的干预而检查无效的分配，并清除已分配但当前没有服务使用的任何IP。 IPs和VIPs与实际路由到目的地的Pod IP不同，Service IP实际上并未由单个主机应答。相反，我们使用iptables来定义根据需要透明重定向的虚拟IP。当客户端连接到VIP时，其流量会自动传输到适当的端点。服务的环境变量和DNS实际上是根据服务的VIP和端口填充的。支持三种代理模式： userspace、iptables、ipvs，它们的操作略有不同。 API对象服务在k8s REST API中是顶级资源。 DNSDNS for Services and Pods 介绍k8s DNS在集群上调度DNS Pod和Service，并配置kubelet以告知各个容器使用DNS Service’s IP 来解析DNS名称。集群中定义的每个服务(包括DNS服务自身)，都会分配一个DNS名称。默认情况下，客户端Pod的DNS搜索列表将包含Pod自己的命名空间和集群的默认域。 栗子：假设在k8s的bar命名空间中有一个foo服务，运行在bar命名空间中的Pod可通过简单地为foo执行DNS查询来查找此服务。运行在quux命名空间中的Pod可通过foo.bar执行DNS查询来查找此服务。 ServicesA records正常的服务(非headless)都分配了一个名为my-svc.my-namespace.svc.cluster.local形式的DNS A记录，这将解析为服务的cluster ip。Headless服务同样分配了一个名为my-svc.my-namespace.svc.cluster.local形式的DNS A记录。与服务不同，这将解析为服务选择的Pod的IP。 SRV records为命名端口创建SRV记录，这些端口是普通服务或headless服务的一部分。对于每个命名端口，SRV记录的格式为_my-port-name._my-port-protocol.my-svc.my-namespace.svc.cluster.local；对于常规的服务，这将解析为端口号和域名：my-svc.my-namespace.svc.cluster.local；对于headless服务，这将解析为多个答案。一个用于支持服务的每个Pod，并且包含Pod形式的端口号和域名:auto-generated-name.my-svc.my-namespace.svc.cluster.local。 PodsA records启用后，将以pod-ip-address.my-namespace.pod.cluster.local的形式为Pod分配DNS A记录。如10-0-1-11.default.pod.cluster.local。 Pod’s hostname and subdomain fields目前，当创建Pod时，其主机名时Pod的metadata.name值。Pod spec有一个可选的hostname字段，可用于指定Pod的主机名。指定后，它优先于Pod的名称作为Pod的主机名。Pod spec同样有一个可选的subdomain字段，可用于指定其子域。 栗子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344apiVersion: v1kind: Servicemetadata: name: default-subdomainspec: selector: name: busybox clusterIP: None ports: - name: foo port: 1234 targetPort: 1234---apiVersion: v1kind: Podmetadata: nam: busybox1 labels: name: busyboxspec: hostname: busybox-1 subdomain: default-subdomain containers: - image: busybox command: - sleep - '3600' name: busybox---apiVersion: v1kind: Podmetadata: name: busybox2 labels: name: busyboxspec: hostname: busybox-2 subdomain: default-subdomain containers: - image: busybox command: - sleep - "3600" name: busybox Pod’s DNS Policy可以基于每个Pod设置DNS策略。目前，k8s支持以下特定于Pod的DNS策略。这些策略在Pod spec中的dnsPolicy字段中指定。 DefaultPod从Pod的节点继承名称解析配置。 ClusterFirst任何与配置的集群域后缀名称不匹配的DNS查询，都会转发到从该节点继承的上游名称服务器。集群管理员可能配置了额外的存根域和上游DNS server。注意Default不是默认的DNS策略，如果未指定DNS策略，则使用ClusterFirst。 ClusterFirstWithHostNet对于使用hostNetwork运行的Pod，你应该明确设置其DNS策略为ClusterFirstWithHostNet。 Nonek8s v1.9+中引入的新功能。它允许Pod忽略k8s环境中的DNS设置。应该使用DNS spec中的dnsConfig字段提供所有的DNS设置。 Pod’s DNS Config要启用此功能，集群管理员需要在apiserver和kubelet上启用--feature-gates=CustomPodDNS=true,...。之后，用户便可以将Pod的dnsPolicy字段设置为None，并可以将新字段dnsConfig添加到Pod spec中。 dnsConfig字段是可选的，它可与任何dnsPolicy设置一起使用。但是，当Pod的dnsPolicy字段设置为None时，必须指定dnsConfig字段。 用户可在dnsConfig字段中指定的属性： nameservers用作Pod的DNS服务器的IP地址列表，最多可以指定3个IP地址。当dnsPolicy设置为None时，必须至少包含一个IP地址，否则此属性是可选的。 searchesPod中主机名查找的DNS搜索域列表，此属性是可选的。k8s最多允许6个搜索域。 options一个可选的对象属性，其中每个对象有name(必须): value(可选)。 栗子： 1234567891011121314151617181920apiVersion: v1kind: Podmetadata: namespace: default name: dns-examplespec: containers: - name: test image: nginx dnsPolicy: "None" dnsConfig: nameservers: - 1.2.3.4 searches: - ns1.svc.cluster.local - my.dns.search.suffix options: - name: ndots value: "2" - name: edns0 查看: 1234kubectl exec -it -- cat /etc/resolv.confnameserver 1.2.3.4search ns1.svc.cluster.local my.dns.search.suffixoptions ndots:2 edns0 连接应用与服务Connecting Applications with Services 现在你拥有了一个连续运行的副本应用程序，你可以在网络上公开它。在讨论k8s网络方法之前，值得将它与Docker的方式进行对比。默认情况下，Docker使用host-private网络，因此只有当容器位于同一台主机上时，容器才能与其它容器进行通信。为了使Docker容器能够跨节点通信，必须在主机的IP地址上分配端口，然后将这些端口转发或代理到容器。这意味着容器要小心协调它们使用的端口。k8s假设Pod可与其它Pod通信，无论它们着落在哪个主机。我们为每个Pod提供了集群专用IP，因此无需在Pod之间明确创建链接，或将容器端口映射到主机端口。这意味着Pod中的容器都可以在localhost上到达彼此的端口，并且集群中的所有Pod都可以在没有NAT的情况下看到对方。 将Pod公开给集群Exposing pods to the cluster 12345678910111213141516171819apiVersion: apps/v1kind: Deploymentmetadata: name: my-nginxspec: selector: matchLabels: run: my-nginx replicas: 2 template: metadata: labels: run: my-nginx spec: containers: - name: my-nginx image: nginx ports: - containerPort: 80 创建服务Creating a Service 123456789101112apiVersion: v1kind: Servicemetadata: name: my-nginx labels: run: my-nginxspec: ports: - port: 80 protocol: TCP selector: run: my-nginx 访问服务Accessing the Service Environment Variables DNS 1234kubectl exec &lt;pod&gt; -- printenvkubectl get services kube-dns --namespace=kube-system 服务安全Securing the Service 在将服务公开到因特网之前，你需要确保通信渠道是安全的。你需要： https签名证书 使用证书的nginx server 使证书可供Pod访问的secret 公开服务Exposing the Service NodePort LoadBalancer Ingress管理集群中外部访问服务的API对象，通常是HTTP。Ingress(入口)可以提供负载均衡，SSL终止和基于名称的虚拟主机。 术语Terminology Node Cluster Edge router Cluster network Service Ingress是什么通常，服务和Pod具有的IP仅可在集群网络路由。最终在边缘路由器上的所有流量都被丢弃或转发到其它地方。从概念上讲，这可能看起来像： 1234 internet |------------[ Services ] Ingress是一组允许访问连接到达集群服务的一组规则： 12345 internet |[ Ingress ]--|-----|--[ Services ] 它可以配置为微服务提供外部可访问的URL，负载均衡流量、ssl terminate、基于名称的虚拟主机等。用户通过POST ingress资源到api-server来请求ingress。Ingress Controller负责完成ingress，通常使用负载均衡器(loadbalancer)，但也可配置为edge router或其它前端以帮助以HA方式处理流量。 先决条件Prerequisites 在开始使用ingress资源之前，你应该了解一些事项。Ingress是beta resource，在k8s v1.1 之前的版本中都没有。你需要一个ingress controller来满足Ingress，简单地创建资源将无法生效。GCE/Google Kubernetes Engine在master上部署ingress controller。你可以在Pod中部署任意数量的自定义入口控制器。你必须使用适当的class对每个入口进行注释。在GCE/google kubernetes engine以外的环境中，你需要将ingress controller部署为Pod。 Ingress资源一个最小化的Ingress看起来如下： 123456789101112131415apiVersion: extensions/v1beta1kind: Ingressmetadata: name: test-ingress annotations: nginx.ingress.kubernetes.io/rewrite-target: /#ingress spec需要配置负载均衡器或代理服务器所需的信息spec: rules: - http: paths: - path: /testpath backend: serviceName: test servicePort: 80 如果尚未配置ingress controller，则将此操作发送到api-verser将不起作用。 和其它k8s配置一样，Ingress也需要apiVersion, kind, metadata, spec字段。Ingress spec字段需要配置负载均衡器和代理服务器所需的所有信息。最重要的是，它包含与所有传入请求匹配的规则列表。目前，Ingress仅支持http规则。每个http rule都包含如下信息： a host，默认值为*；与后端挂念的一组path列表。在负载均衡器将流量定向到后端之前，host和path都必须与传入请求的内容匹配。后端(backend)是一个service:port的组合。入口流量通常直接发送到与后端匹配的端点(endpoint)。实例中没有包含Ingress的全局参数(global patameters)，详情请查看文档。 Ingress controllers为了使ingress资源正常工作，集群必须运行ingress controller——这与其它类型的控制器不同，后者通常为kube-controller-manager程序的一部分，并且通常作为集群创建的一部分而自启动。选择最适合你的集群的ingress controller。 k8s目前支持和维护GCE和Nginx控制器GCE: https://github.com/kubernetes/ingress-gce/blob/master/README.md F5 BIG-IP Controller for Kubernetes链接： http://clouddocs.f5.com/products/connectors/k8s-bigip-ctlr/latest Kong Ingress Controller for Kubernetes链接： https://konghq.com/blog/kubernetes-ingress-controller-for-kong/ TraefikTraefik: https://github.com/containous/traefikContainous: https://containo.us/services NGINX Ingress Controller for Kubernetes链接: https://www.nginx.com/products/nginx/kubernetes-ingress-controller/github: https://github.com/jcmoraisjr/haproxy-ingress HAProxy Ingress Controller for Kubernetes链接： https://www.haproxy.com/blog/haproxy_ingress_controller_for_kubernetes/ 基于istio的Control Ingress Trafficistio: https://istio.io/链接: https://istio.io/docs/tasks/traffic-management/ingress/ ####Ingress的类型 Single Service Ingress现有的k8s概念允许你公开单个服务，但你也可以通过Ingress指定不使用规则的默认后端。 12345678apiVersion: extensions/v1beta1kind: Ingressmetadata: name: test-ingressspec: backend: serviceName: testsvc servicePort: 80 12345678#创建kubectl create -f#查看kubectl get ingress test-ingressNAME HOSTS ADDRESS PORTS AGEtest-ingress * 107.178.254.228 80 59s#107.178.254.228是ingress controller为满足此Ingress而分配的IP Simple fanout如前所述，k8s中Pod只能在集群内网络上看到IP，因此我们需要在边缘处接收入口流量并将其代理到正确的端点。该组件通常是高可用的负载均衡器。Ingress允许你将负载均衡器的数量将至最低。例如： 12foo.bar.com -&gt; 178.91.123.132 -&gt; / foo s1:80 / bar s2:80 需要一个Ingress，例如： 12345678910111213141516171819apiVersion: extensions/v1beta1kind: Ingressmetadata: name: test annotations: nginx.ingress.kubernetes.io/rewrite-target: /spec: rules: - host: foo.bar.com http: paths: - path: /foo backend: serviceName: s1 servicePort: 80 - path: /bar backend: serviceName: s2 servicePort: 80 12345678910111213141516171819kubectl create -f xxxkubectl describe ingress testName: testNamespace: defaultAddress: 178.91.123.132Default backend: default-http-backend:80 (10.8.2.3:8080)Rules: Host Path Backends ---- ---- -------- foo.bar.com /foo s1:80 (10.8.0.90:80) /bar s2:80 (10.8.0.91:80)Annotations: nginx.ingress.kubernetes.io/rewrite-target: /Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ADD 22s loadbalancer-controller default/test Name based virtual hosting基于名称的虚拟主机对同一IP地址使用多个主机名。 123foo.bar.com --| |-&gt; foo.bar.com s1:80 | 178.91.123.132 |bar.foo.com --| |-&gt; bar.foo.com s2:80 如下的Ingress告诉后端负载均衡器根据Host Header来路由请求： 123456789101112131415161718apiVersion: extensions/v1beta1kind: Ingressmetadata: name: testspec: rules: - host: foo.bar.com http: paths: - backend: serviceName: s1 servicePort: 80 - host: bar.foo.com http: paths: - backend: serviceName: s2 servicePort: 80 default backend： 没有指定规则的Ingress将所有流量发送到单个默认后端。你可以使用相同的技术来指定一组规则和默认后端来告诉负载均衡器在哪里找到网站的404页面。如果Ingress中的所有主机都与请求Header中的主机不匹配，并且没有任何路径与请求的URL匹配，则流量将路由到你的默认后端。 TLS可以通过指定包含TSL私钥和证书的机密来保护Ingress。目前，Ingress仅支持单个TLS 443端口。TLS Secret必须包含名为tls.crt和tls.key的证书和密钥： 123456789apiVersion: v1data: tls.crt: base64 encoded cert tls.key: base64 encoded keykind: Secretmetadata: name: testsecret namespace: defaulttype: Opaque 在Ingress中引用secret将此告知ingress controller： 12345678910apiVersion: extensions/v1beta1kind: Ingressmetadata: name: no-rules-mapspec: tls: - secretName: testsecret backend: serviceName: s1 servicePort: 80 请注意，各种ingress controller支持的TLS功能存在差异性。 Loadbalancingingress controller通过一些适用于所有Ingress的负载均衡策略设置进行引导(bootstrapped)，一些高级 的负载均衡概念(持久会话、动态权重)尚未通过Ingress进行公开。但你仍然可以通过服务负载均衡器获得这些功能。 更新Ingress 直接更新资源 更新配置文件 123456#直接更新资源kubectl edit ingress test#更新修改的配置文件kubectl replace -f xxx 未来计划 各种模式的HTTPS/TLS支持 通过声明请求IP或Hostname 结合L4和L7 Ingress 更多ingress controller Alternatives有多种方式公开服务： LoadBalancer NodePort Port Proxy LoadBalancer/NodePort/Ingress比较参考: Kubernetes NodePort vs LoadBalancer vs Ingress? When should I use what? 这几种服务类型的优缺点，以及什么时候使用它们。 Cluster IPCluster IP是默认的k8s服务，它提供集群内部的访问，外部无法访问。但你可以使用kubernetes proxy来访问它。 什么时候使用： 调试服务 内部访问就可 12345#开启proxykubectl proxy --port=8080#访问资源http://localhost:8080/api/v1/proxy/namespaces/&lt;NAMESPACE&gt;/services/&lt;SERVICE-NAME&gt;:&lt;PORT-NAME&gt;/ NodePortNodePort是公开服务的最原始的方式。 什么时候使用？此方法有许多缺点： 每个端口只能有一个服务 默认端口范文30000-32767 如果节点IP地址发生更改，则需要处理该问题 由于这些原因，不建议在生产环境使用这种方法 LoadBalancerLoadBalancer是公开服务的标准方式。 什么时候用： 指定端口上的所有流量都被转发到该服务，没有过滤、路由等。这意味着你可以发送任何类型的流量，如HTTP, TCP, UDP, Websocket, gRPC… 最大的缺点，你必须为每一个公开的服务使用一个负载均衡器，这个负载均衡器公开的服务都将获得自己的IP，这可能会付出比较大的代价 Ingress与以上方式不同，Ingress不是一种服务。相反，它位于多个服务之前，充当集群中的入口。你可以使用Ingress做很多不同的事，并且有许多类型的 ingress controller，具有不同的功能。 什么时候用： Ingress可能是公开服务最强大的方式，但也可能是最复杂的 如果你希望在相同的IP下公开多个服务，则Ingress是最有用的 网络策略Network Policies 网络策略是允许容器组如何与彼此以及其它网络端点通信的规范。NetworkPolicy资源使用labels选择Pod并定义规则，这些规则指定允许选定的Pod的流量。 先决条件网络策略由网络插件来实现，因此你必须使用支持NetworkPolicy的网络解决方案——简单地创建资源而没有控制器来实现它将不起作用。 Isolated and Non-isolated Pods默认情况下，Pod是非隔离的(non-isolated)。它们接受任何来源的流量。可选择NetworkPolicy来隔离Pod，一旦命名空间中任何NetworkPolicy选择了特定的Pod，该Pod将拒绝网络策略不允许的任何连接。 NetworkPolicy资源The NetworkPolicy Resource 栗子： 12345678910111213141516171819202122232425262728293031323334apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: test-network-policy namespace: defaultspec: podSelector: matchLabels: role: db policyTypes: - Ingress - Egress ingress: - from: - ipBlock: cidr: 172.17.0.0/16 except: - 172.17.1.0/24 - namespaceSelector: matchLabels: project: myproject - podSelector: matchLabels: role: frontend ports: - protocol: TCP port: 6379 egress: - to: - ipBlock: cidr: 10.0.0.0/24 ports: - protocol: TCP port: 5978 必填字段： NetworkPolicy, apiVersion, kind, metadata spec: 网络策略所需的所有信息 podSelector： 选择策略适用的Pod分组。(如果为空，则表示此命名空间下的所有Pod) policyTypes： 可能包含Ingress, Egress。指示给定策略是否适用于入口流量和出口流量。(如果为空，默认为Ingress) ingress： 允许配置from和ports部分的流量。ipBlock, namespaceSelector, podSelector指定具体信息 egress： 允许配置to和ports部分的流量 默认策略Default policies 默认情况下，如果命名空间中不存在任何策略，则允许所有入口(ingress)和出口(egress)流量进出该命名空间中的Pod。 默认拒绝所有入口流量(Default deny all ingress traffic)你可以通过创建NetworkPolicy来为命名空间创建默认的隔离策略，该策略选择所有Pod但不允许任何入口流量到这些Pod。 12345678apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: default-denyspec: podSelector: &#123;&#125; policyTypes: - Ingress 默认允许所有入口流量(Default allow all ingress traffic)如果要允许所有流量到命名空间的所有Pod，你可以创建一个明确允许该命名空间中所有流量的策略。 12345678apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: allow-allspec: podSelector: &#123;&#125; ingress: - &#123;&#125; 默认拒绝所有出口流量(Default deny all egress traffic)可通过创建NetworkPolicy来为命名空间创建默认的出口隔离策略，该策略选择所有Pod但不允许来自这些Pod的出口流量。 12345678apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: default-denyspec: podSelector: &#123;&#125; policyTypes: - Egress 默认允许所有出口流量(Default allow all egress traffic) 12345678910apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: allow-allspec: podSelector: &#123;&#125; egress: - &#123;&#125; policyTypes: - Egress 默认拒绝所有入口/出口流量(Default deny all ingress and all egress traffic) 123456789apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: default-denyspec: podSelector: &#123;&#125; policyTypes: - Ingress - Egress 使用HostAliases向Pod的hosts添加条目Adding entries to Pod /etc/hosts with HostAliases 当DNS和其它选项不适用时，向Pod的/etc/hosts文件添加条目可提供主机名解析的Pod级别的覆盖。在 v1.7 中，用户可以使用pod spec中的HostAliases字段来添加这些自定义条目。不建议不使用HostAliases进行修改，因为该文件由Kubelet管理，并且可以在Pod 创建/重启 期间覆盖。 默认hosts文件Default Hosts File Content 查看Pod hosts文件： 123456789101112131415kubectl get pod -o=wideNAME READY STATUS RESTARTS AGE IP NODEnginx-deployment-597549df56-chjps 1/1 Running 0 26d 10.244.2.52 salt01#kubectl exec POD [-c CONTAINER] -- COMMAND [args...] [options]kubectl exec nginx-deployment-597549df56-chjps -- cat /etc/hosts# Kubernetes-managed hosts file.127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetfe00::0 ip6-mcastprefixfe00::1 ip6-allnodesfe00::2 ip6-allrouters10.244.2.52 nginx-deployment-597549df56-chjps 使用HostAliases添加额外条目Adding Additional Entries with HostAliases hostaliases-pod.yaml: 123456789101112131415161718192021apiVersion: v1kind: Podmetadata: name: hostaliases-podspec: restartPolicy: Never hostAliases: - ip: "127.0.0.1" hostnames: - "foo.local" - "bar.local" - ip: "192.168.31.119" hostnames: - zhang21 containers: - name: cat-hosts image: busybox command: - cat args: - "/etc/hosts" 123456789101112131415kubectl apply -f hostaliases-pod.yamlkubeclt logs hostaliases-pod# Kubernetes-managed hosts file.127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetfe00::0 ip6-mcastprefixfe00::1 ip6-allnodesfe00::2 ip6-allrouters10.244.1.69 hostaliases-pod# Entries added by HostAliases.127.0.0.1 foo.local127.0.0.1 bar.local192.168.31.119 zhang21 为什么kubelet管理hostsWhy Does Kubelet Manage the Hosts File? Kubelet管理Pod中每个容器的hosts文件，以防止Docker在容器已启动后修改文件。由于文件的托管性质，只要在容器重启或Pod重新调度的情况下由Kubelet重新挂载hosts文件，因此用户编写的内容都将被覆盖。因此，不建议直接修改文件的内容。 存储Storage Volumes容器中的磁盘文件是短暂的，这在容器中运行时会给重大的应用程序带来一些问题。首先，当一个容器奔溃时，kubelet将重启它，但文件会丢失，容器将以干净的状态启动。其次，在Pod中一起运行容器时，通常需要在这些容器间共享文件。k8s volume抽象解决这些问题。 BackgroundDocker也有关于卷的概念，虽然它有点宽松和管理较少。在Docker中，卷是磁盘上或其它容器中的目录，声明周期不受管理。Docker提供了卷驱动，但目前功能非常有限。 另一方面，k8s的卷具有明确的生命周期。因此，卷可以比Pod中运行的任何容器活得更久，并且可在容器重启之间保留数据。当然，当Pod不再存在时，卷也将不复存在。更重要的是，k8s支持多种类型的卷，Pod可以同时使用任意数量的卷。从本质上讲，卷只是一个目录，可能包含一些数据，Pod中的容器可以访问它。该目录如何形成，支持它的介质以及它的内容都由所用特定卷的类型决定。要使用卷，Pod Spec要指定提供的卷(.spec.volumes字段)，以及将这些卷挂载到容器中的位置(.spec.containers.volumeMounts字段)。 容器中的进程可以看到由Docker镜像和卷组成的文件系统视图。Docker镜像位于文件系统层次结构的根下，任何卷都挂载到镜像中的指定路径。卷不能挂载到其它卷或其它卷的硬链接上，Pod中的每个容器必须独立的指定每个卷的挂载位置。 卷类型k8s支持如下卷类型。注意，这些卷并非全部都是持久化的(如emptyDir)，它们会随着Pod的消亡而消亡。 awsElasticBlockStore azureDisk azureFile cephfs configMap csi downwardAPI emptyDir fc (fibre channel) flocker gcePersistentDisk gitRepo (deprecated) glusterfs hostPath iscsi local nfs persistentVolumeClaim projected portworxVolume quobyte rbd scaleIO secret storageos vsphereVolume 具体例子请参考: https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes configMapconfigMap资源提供了一种将配置数据注入Pod的方法。存储在configMap对象中的数据可以在configMap类型的卷中引用，然后由Pod中运行的应用程序使用。引用configMap对象时，只需在卷中提供其名称即可引用它。你还可以自定义configMap中的特定条路的路径。 例如，要将log-config的ConfigMap挂载到名为configmap-pod的Pod上，你可以这样操作：注意，在使用之前你先得创建ConfigMap使用ConfigMap作为subPath的卷挂载将不会收到ConfigMap的更新 12345678910111213141516171819apiVersion: v1kind: Podmetadata: name: configmap-podspec: containers: - name: test image: busybox volumeMounts: - name: config-vol mountPath: /etc/config volumes: - name: config-vol configMap: name: log-config items: - key: log_level path: log_level#log-config configMap作为卷挂载，存储在`log_level`的所有内容都挂载到路径`/etc/config/log_level`的Pod中 emptyDir将Pod分配给节点时，首先会创建一个emptyDir卷。只要节点还在该节点上运行，它就会存在。就如同它的名称一样，它最初是空的。Pod中的容器都可以在emptyDir卷中读取和写入相同的文件，尽管改卷可以安装在每个容器中相同或不同的路径上。当从节点上删除Pod时，将永久删除emptyDir中的数据。注意：容器奔溃不会从节点中删除Pod，因此emptyDir卷中的数据在容器奔溃时是安全的。 emptyDir的一些用途： 临时空间 检查从崩溃中恢复的长计算 保存内容管理器容器在Web服务器提供数据时提取的文件 默认情况下，emptyDir卷存储在节点的任何介质上(磁盘、SSD、网络存储…)，取决于你的环境。但是，你可以将emptyDir.medium字段设置为Memory，以告诉k8s为你安装tmpfs(RAM支持的文件系统)。tmpfs非常快，但请注意断电就没有了，并且你编写的任何文件都将计入容器的内存限制。 栗子： 1234567891011121314apiVersion: v1kind: Podmetadata: name: test-pdspec: containers: - image: k8s.gcr.io/test-webserver name: test-container volumeMounts: - mountPath: /cache name: cache-volume volumes: - name: cache-volume emptyDir: &#123;&#125; hostPathhostPath卷将文件或目录从主机节点的文件系统挂载到Pod中。这不是大多数Pod需要的东西，但它为某些应用程序提供了强大的逃生舱。 hostPath的一些用途： 运行需要访问Docker内部的容器，使用/var/lib/docker的hostPath 在容器中运行cAdvisor 允许Pod指定在Pod运行之前是否应该存在给定的hostPath，是否应该创建它以及它应该存在的内容 三个字段: hostPath path type 支持的type的值： Value Behavior 空 Empty string (default) is for backward compatibility, which means that no checks will be performed before mounting the hostPath volume. DirectoryOrCreate If nothing exists at the given path, an empty directory will be created there as needed with permission set to 0755, having the same group and ownership with Kubelet. Directory A directory must exist at the given path FileOrCreate If nothing exists at the given path, an empty file will be created there as needed with permission set to 0644, having the same group and ownership with Kubelet. File A file must exist at the given path Socket A UNIX socket must exist at the given path CharDevice A character device must exist at the given path BlockDevice A block device must exist at the given path 请注意何时使用此类型的卷，因为： 由于节点上的文件不同，具有相同配置的Pod在不同节点上的行为可能有所不同 当k8s按计划添加资源，它将无法考虑hostPath使用的资源 在底层主机上创建的文件或目录只能由root写入 栗子: 123456789101112131415161718apiVersion: v1kind: Podmetadata: name: test-pdspec: containers: - image: k8s.gcr.io/test-webserver name: test-container volumeMounts: - mountPath: /test-pd name: test-volume volumes: - name: test-volume hostPath: # directory location on host path: /data # this field is optional type: Directory locallocal卷表示已挂载的本地存储设备，如磁盘，分区或目录。它只能用作静态创建的持久化卷，尚不支持动态配置。与hostPath卷相比，可以以持久且可移植的方式使用lobal卷，而无需手动将Pod调度到节点。然而，local卷仍受基础节点可用性的限制，并不适用于所有应用程序。如果节点变得不健康，则local卷也将变得不可访问，并且使用它的Pod将无法运行。使用local volume的应用程序必须能够容忍这种降低的可用性以及潜在的数据丢失，具体取决于底层磁盘的持久性特征。 栗子： 1234567891011121314151617181920212223apiVersion: v1kind: PersistentVolumemetadata: name: example-pvspec: capacity: storage: 100Gi # volumeMode field requires BlockVolume Alpha feature gate to be enabled. volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Delete storageClassName: local-storage local: path: /mnt/disks/ssd1 nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - example-node NFS栗子： 123456volumes:- name: nfs nfs: # FIXME: use the right hostname server: 10.254.234.223 path: "/" persistentVolumeClaimpersistentVolumeClaim卷用于将持久化卷挂载到Pod中。 使用子路径Using subPath 有时，在单个Pod中共享一个卷用于多个用途是很有用的。volumeMounts.subPath属性可用于指定引用卷内的子路径，而不是根路径。 使用单个共享卷的Pod与LAMP Stack的示例，HTML内容被映射到html目录中，数据库存储在mysql目录中： 12345678910111213141516171819202122232425apiVersion: v1kind: Podmetadata: name: my-lamp-sitespec: containers: - name: mysql image: mysql env: - name: MYSQL_ROOT_PASSWORD value: &quot;rootpasswd&quot; volumeMounts: - mountPath: /var/lib/mysql name: site-data subPath: mysql - name: php image: php:7.0-apache volumeMounts: - mountPath: /var/www/html name: site-data subPath: html volumes: - name: site-data persistentVolumeClaim: claimName: my-lamp-site-data 使用带有扩展环境变量的子路径Using subPath with expanded environment variables FEATURE STATE: k8s v1.11 alpha subPath目录名也可从Downward API环境变量构造。在使用此功能之前，必须启用VolumeSubpathEnvExpansion。下例中，Pod使用subPath在主机路径卷/var/log/pods中创建pod1目录，使用Downward API中的Pod名。主机目录/var/log/pods/pod1被挂载到容器中的/logs目录。 123456789101112131415161718192021222324apiVersion: v1kind: Podmetadata: name: pod1spec: containers: - name: container1 env: - name: POD_NAME valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.name image: busybox command: [ &quot;sh&quot;, &quot;-c&quot;, &quot;while [ true ]; do echo &apos;Hello&apos;; sleep 10; done | tee -a /logs/hello.txt&quot; ] volumeMounts: - name: workdir1 mountPath: /logs subPath: $(POD_NAME) restartPolicy: Never volumes: - name: workdir1 hostPath: path: /var/log/pods 资源emptyDir卷的存储介质(磁盘，SSD…)由kubelet根目录的文件系统的介质确定。emptyDir或hostPath卷可以占用多少空间没有限制，容器之间或Pod之间没有隔离。 ####挂载传播 Mount propagation FEATURE STATE: k8s v1.10 beta 挂载传播允许将容器挂载的卷共享到同一Pod的其它容器，或同一节点的其它Pod。如果MountPropagation功能被禁用，或Pod未指明特定的挂载环境，则不会传播Pod的容器中的挂载卷。卷的挂载传播由Container.volumeMounts中的mountPropagation字段控制。它的值为： None此卷的挂载不会接收主机挂载到此卷或任何子目录的任何后续挂载。此模式等同于于Linux kernel中描述的private挂载传播。 HostToContainer此卷的挂载将接收安装到此卷或其任何子目录的所有后续挂载。换句话说，如果主机在卷挂载中挂载任何内容，则容器将看到它挂载在那里。类似地，如果任何具有双向挂载传播的Pod挂载到同一个卷中，那么具有HostToContainer挂载传播的容器将看到它。此模式等同于Linux Kernel中描述的rslave挂载传播。 Bidirectional此卷的挂载行为与HostToContainer相同。此外，容器创建的所有卷 挂载都将传播会主机和所有使用相同卷的Pod中的容器。此模式等同于Linux kernel中描述的rshared挂载传播。 配置在挂载传播可以在某些部署上正常工作之前，必须在Docker中正确配置挂载共享，修改docker systemd服务文件，设置MountFlags： 1MountFlags=shared 重启Docker： 12systemctl daemon-reloadsystemctl restart docker 持久化卷Persistent Volumes 简介PersistentVolume 子系统为用户和管理员提供了一个API，它提供了如何根据消耗提供存储的详细信息。为此，我们引入了两个新的API资源： PersistentVolume(PV) PersistentVolumeClaim(PVC) PersistentVolume 是群集中由管理员配置的一块存储。它是集群中的资源，就像节点是集群资源一样。它是像 Volume 的 Volume Plugin，但其生命周期独立于使用它的任何单个 pod 。此API对象捕获存储实现的详细信息，包括NFS，iSCSI或特定于云提供程序的存储系统。 PersistentVolumeClaim 是用户存储的请求。与 Pod 类似，Pod 消耗 Node 资源，而 PVC 消耗 PV 的资源。Pod可以请求特定级别的资源(CPU, MEM)，Claim 可以请求特定的大小和访问模式。 虽然 PersistentVolumeClaims 允许用户使用抽象存储资源，但是对于不同的问题，用户需要具有不同属性的 PersistentVolumes。群集管理员需要能够提供各种PersistentVolume，这些PersistentVolume在多种方式上而不仅仅是大小和访问模式，而不会让用户了解这些卷的实现方式。对于这些需求，有 StorageClass 资源。 volume和claim的生命周期Lifecycle of a volume and claim PV是群集中的资源。 PVC是对这些资源的请求，并且还充当对资源的声明检查。PV和PVC之间的相互作用遵循如下生命周期。 Provisioning有两种方式配置PV: Static 集群管理员创建了许多PV。它们包含可供群集用户使用的实际存储的详细信息。它们存在于Kubernetes API中，可供使用。 Dynamic 当管理员创建的 Static PV 都不匹配用户的 PersistentVolumeClaim 时，群集可能会尝试为PVC 专门动态配置Volume。此 Provision 基于StorageClasses， PVC必须请求存储类，管理员必须已创建并配置该类，以便进行动态供应。 Binding用户在动态配置的情况下创建或已创建 PersistentVolumeClaim，其具有请求的特定存储量和某些访问模式。Master中的控制循环观察新PVC，找到匹配的PV（如果可能），并将它们绑定在一起。如果为新PVC动态配置PV，则循环将始终将该PV绑定到PVC。否则，用户将始终至少得到他们要求的内容，但是Volume可能超过所要求的数量。绑定后，PersistentVolumeClaim 绑定是独占的，无论它们如何绑定，PVC到PV绑定是一一对应。 如果不存在匹配的卷，则 Claim 将无限期地保持未绑定状态。Claim 将在匹配卷可用时受到绑定。例如，集群配置了许多50Gi PV，与请求100Gi的PVC不匹配。当100Gi PV添加到集群时，可以绑定PVC。 UsingPods 使用 Claim 作为 Volume。群集检查 Claim 以查找绑定卷并为该 Pod 挂载该卷。对于支持多种访问模式的卷，用户在将其声明用作 Pod 的卷时指定所需的模式。 一旦用户具有声明并且该声明被绑定，绑定的PV就属于用户，只要用户需要它。用户通过在Pod的 Volume Block 中包含 persistentVolumeClaim 来调度Pod并访问其声明的PV。 Storage Object in Use Protection使用中的存储对象保护 功能的目的是确保不会从系统中删除 绑定到 PVC，由 Pod 和 PV 主动使用的 PVC，因为这可能会导致数据丢失。 注意：当pod状态为Pending且pod已分配给Node，或pod状态为Running时，pod将主动使用PVC。 Reclaiming当用户完成卷时，他们可以从API中删除PVC对象，从而允许回收资源。PersistentVolume 的回收策略告诉群集在释放其声明后如何处理该卷。 目前，卷可以保留、回收、删除: Retain 保留回收政策允许手动回收资源。删除 PVC 时，PV 仍然存在，并且该卷被视为 已释放。但它还不能被 Claim 使用，因为之前的 Claim 的数据仍在卷上。管理员可以通过以下步骤手动回收该卷: 1231. 删除此PV2. 手动清理相关数据3. 手动删除关联的存储资产 Recycle 警告：Recycle Claim Policy 将会被移除，不推荐使用。相反，推荐的方法是使用动态配置。 Delete 对于支持删除回收策略的卷插件，将删除k8s中的 PV 对象以及外部基础结构中的关联存储资产。动态配置的卷继承其 StorageClass 的回收策略(默认为Delete)。管理员应根据用户的期望配置StorageClass，否则PV必须在创建后进行编辑或修补。 Expanding Persistent Volumes Claims FEATURE STATE: Kubernetes v1.8 alphaFEATURE STATE: Kubernetes v1.11 beta 只有将 StorageClass 的 allowVolumeExpansion 字段设置为 true，才能使用扩展的PVC。现在默认启用对扩展PVC的支持。您可以扩展以下类型的卷： gcePersistentDisk awsElasticBlockStore Cinder glusterfs rbd Azure File Azure Disk Portworx Resizing a volume containing a file system 如果文件系统是XFS，Ext3或Ext4，你可调整包含文件系统的卷的大小。当卷包含文件系统时，仅在使用 RW模式下的 PVC 启动新Pod时才调整文件系统的大小。 12#如果PVC的状态为FileSystemResizePending，则使用PVC重新创建pod是安全的kubectl describe pvc &lt;pvc_name&gt; Resizing an in-use PersistentVolumeClaim FEATURE STATE: Kubernetes v1.11 alpha 要使用它，请启用 ExpandInUsePersistentVolumes。在这种情况下，您无需删除并重新创建使用现有PVC的Pod或Deployment。任何正在使用的PVC在其文件系统扩展后自动可用于其Pod。 持久化卷的类型Types of Persistent Volumes PV类型实现为插件， k8s 目前支持以下插件: GCEPersistentDisk AWSElasticBlockStore AzureFile AzureDisk FC (Fibre Channel) FlexVolume Flocker NFS iSCSI RBD (Ceph Block Device) CephFS Cinder (OpenStack block storage) Glusterfs VsphereVolume Quobyte Volumes HostPath Portworx Volumes ScaleIO Volumes StorageOS Persistent Volumes每个PV都包含 spec 和 status: 123456789101112131415161718apiVersion: v1kind: PersistentVolumemetadata: name: pv0003spec: capacity: storage: 5Gi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle storageClassName: slow mountOptions: - hard - nfsvers=4.1 nfs: path: /tmp server: 172.17.0.2 PersistentVolumeClaims每个PVC都包含了 spec 和 status: 1234567891011121314151617kind: PersistentVolumeClaimapiVersion: v1metadata: name: myclaimspec: accessModes: - ReadWriteOnce volumeMode: Filesystem resources: requests: storage: 8Gi storageClassName: slow selector: matchLabels: release: "stable" matchExpressions: - &#123;key: environment, operator: In, values: [dev]&#125; Claims As VolumesPods使用 claim as a volume 来访问存储。声明必须与使用声明的pod存在于同一名称空间中。群集在pod的命名空间中查找声明，并使用它来获取支持声明的PV，然后将卷挂载到主机并进入容器。 123456789101112131415kind: PodapiVersion: v1metadata: name: mypodspec: containers: - name: myfrontend image: dockerfile/nginx volumeMounts: - mountPath: "/var/www/html" name: mypd volumes: - name: mypd persistentVolumeClaim: claimName: myclaim 编写可移植配置如果您正在编写在各种群集上运行并需要持久存储的配置模板或示例，我们建议您使用以下模式： 在配置中包含PVC对象 不要在配置中包含PV对象，因为实例化配置的用户可能没有创建PV的权限 在实例化模板时，为用户提供提供存储类名称的选项 如果用户提供存储类名称，请将该值放入 persistentVolumeClaim.storageClassName 字段中 如果用户未提供存储类名称，请将 persistentVolumeClaim.storageClassName 字段保留为 nil 这将导致使用群集中的默认StorageClass为用户自动配置PV 在您的工具中，请注意一段时间后未受约束的PVC并将其显示给用户，因为这可能表明群集没有动态存储支持或群集没有存储系统 Storage ClassesStorageClass 为管理员提供了一种描述他们提供的 存储类 的方法。不同的类可能映射到服务质量级别、备份策略，或者由集群管理员确定的任意策略。k8s 本身对于类代表什么是不受任何影响的，这个概念有时在其他存储系统中称为profile。 垃圾收集Kubernetes 垃圾收集器的角色是删除指定的对象，这些对象曾经有但以后不再拥有 Owner 了。 某些Kubernetes对象是其它一些对象的Owner。如，一个副本集是一组pod的Owner。具有Owner的对象被称为是Owner的Dependent。每个Dependent对象具有一个执行所属对象的metadata.ownerReference字段。 有时，Kubernetes会自动设置ownerReference的值。也可以手动设置ownerReference的值，来指定Owner和Dependent之间的关系。 控制垃圾收集器删除Dependent 级联删除 background foreground删除对象时自动删除Dependent。在bg级联删除模式下，k8s会立即删除Owner对象，然后垃圾收集器会在后台删除这些Dependent。在fg级联删除模式下，根对象首先进入删除中状态。一旦对象被设置为删除中状态，垃圾收集器会删除对象的所有Dependent。 孤儿删除对象时，不自动删除它的Dependent。这些Dependent就被称作孤儿。垃圾收集器在删除了所有 “Blocking” 状态的 Dependent（对象的 ownerReference.blockOwnerDeletion=true）之后，它会删除 Owner 对象。 教程Tutorials 教程展示了如何实现比单个任务更大的目标(task)。 一个栗子栗子里面包含一个Service和Deployment，请一定要注意yaml的语法格式，不使用-的话可能会报错。很多k8s配置我们只需要在云界面上小配置，看它生成的YAML文件如何，之后再进行相应修改即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130#注意yaml语法错误apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginx-deployment-test namespace: default labels: k8s-app: nginx env: test annotations: des: A k8s-deployment test author: Zhang21 date: 2018-09-13spec: replicas: 1 selector: matchLabels: k8s-app: nginx strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 50% maxSurge: 50% template: metadata: labels: k8s-app: nginx spec: dnsPolicy: ClusterFirst restartPolicy: Always volumes: - name: test01 emptyDir: &#123;&#125; - name: test02 hostPath: path: /tmp/k8s/volume/test02 containers: - name: nginx image: nginx:1.12.2 imagePullPolicy: Always #特权容器 securityContext: privileged: true workingDir: /usr/share/nginx/html ports: - protocol: TCP containerPort: 80 readinessProbe: httpGet: path: / port: 80 scheme: HTTP initialDelaySeconds: 10 periodSeconds: 5 livenessProbe: httpGet: path: / port: 80 scheme: HTTP #60s内，Server未启动则重启容器 initialDelaySeconds: 60 periodSeconds: 10 env: - name: AUTHOR value: Zhang21 - name: EMAIL value: me@zhang21.cn volumeMounts: - name: test01 mountPath: /usr/share/nginx/html/test01 - name: test02 mountPath: /usr/share/nginx/html/test02 resources: requests: cpu: 100m memory: 100Mi limits: cpu: 0.3 memory: 300Mi imagePullSecrets: - name: docker-secret---apiVersion: v1kind: Servicemetadata: name: nginx-service-test namespace: default labels: k8s-app: nginx annotations: des: A k8s Service test author: Zhang21 date: 2018-09-13spec: #记得指定应用，不然服务无法找到后端端点和容器组 selector: k8s-app: nginx type: NodePort ports: - name: http nodePort: 31234 #The range of valid ports is 30000-32767 protocol: TCP port: 80 targetPort: 80status: loadBalancer: &#123;&#125;##ClusterIP#spec:# ports:# - name: http# protocol: TCP# port: 80# targetPort: 80# selector:# k8s-app: nginx# type: ClusterIP###spec:# ports:# - name: http# protocol: TCP# port: 80# targetPort: 80# selector:# k8s-app: nginx# type: LoadBalancer# loadBalancerIP: 1.2.3.4 执行: 123456789kubectl apply -f ./nginx.yaml#apply可修改后更新kubectl apply -f ./nginx.yaml#之后在dashboard中查看成功与否#访问master 31234 portcurl master:31234 k8s基本 综述本教程提供了Kubernetes集群编排系统基础知识的介绍。 你将学到： 在集群上部署容器化服务 伸缩部署 使用新软件版本更新容器化应用程序 调试容器化应用程序 k8s能为你做什么？容器化有助于打包软件以实现这些目标，是应用程序能够以简单快速的方式发布和更新，而无需停机。k8s可帮助你确保这些容器化应用程序随时随地运行，并帮助它们找到运行所需的资源。 k8s 基础模块 创建(create)一个k8s集群 部署(deploy)应用程序 探索(explore)应用程序 公开(expose)展示应用程序 伸缩(scale)应用程序 升级(update)应用程序 创建集群Create a Cluseter 详情见安装部分。 部署应用程序Deploy an APP 使用kubectl创建部署Using kubectl to create a Deployment 目标： 了解应用程序部署 在k8s上使用kubectl部署你的第一个应用程序 k8s Deployments一旦运行了k8s集群，就可在其上部署容器化应用程序。为此，你需要创建Kubernetes Deployment configuration。它指示k8s 如何创建和更新应用程序实例。创建部署后，k8s master将应用程序实例调度到各个node上。创建应用程序实例后，Kubernetes Deployment Controller会持续监控这些实例。如果主机节点上的实例关闭或删除，Deployment Controller会替换它。这提供了一种自我修复(self-healing)机制来解决机器故障或维护。 部署应用程序可使用kubectl(使用k8s api与集群交互)来创建和管理Deployment。下面有一些关于使用kubectl在k8s集群上创建和管理Deployment的基础命令。 创建部署时，你需要指定应用程序的容器镜像(image)，以及要运行的副本数(replicas)。你可在以后改变这些信息来更新你的部署。 栗子：第一个部署，k8s使用一个Docker容器的Node.js应用程序包。 12345678910111213141516171819202122kubectl version#client#serverkubectl get nodes#创建名为k8s-bootcamp的deploymentkubectl run kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1 --port=8080#这是国内镜像: docker.io/jocatalin/kubernetes-bootcamp:v1kubectl get deploymentsNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEkubenetes-bootcamp 1 1 1 1 1h#表示 希望副本数，当前副本数，最新副本数，可用副本数#由于pod被封装在集群私网，没有对外开放#proxy将通信转发到集群内私网kubectl proxycurl http://localhost:8081/versioncurl http://localhost:8001/api/v1/namespaces/default/pods/$POD_NAME/proxy/#Hello Kubernetes bootcamp! 此处我遇到一个错误，replicats unavailable:原因是拉取的镜像在谷歌云上，无法访问，拉取失败所以导致部署失败。gcr(google container Registry) 12345678910111213141516171819#查看部署信息 kubectl get deployment kubernetes-bootcamp -o yaml message: &apos;unable to create pods: No API token found for service account &quot;default&quot;, retry after the token is automatically created and added to the service account&apos; reason: FailedCreate status: &quot;True&quot; type: ReplicaFailurekubectl get deploymentsNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEkubernetes-bootcamp 1 0 0 0 33mkubectl describe deployments kubernetes-bootcampReplicas: 1 desired | 0 updated | 0 total | 0 available | 1 unavailableStrategyType: RollingUpdateReplicaFailure True FailedCreate 针对unable to create pods: No API token found for service account “default”这个问题，需要修改kube-apiserver配置文件： 123456789101112131415161718192021222324252627282930313233343536#去掉 KUBE_ADMISSION_CONTROL中的SecurityContextDeny,ServiceAccountKUBE_ADMISSION_CONTROL=&quot;--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota&quot;#重启kube-apiserversystemctl restart kube-apiserver#之后查看副本数就正常了kubectl get deploymentsNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEkubernetes-bootcamp 1 1 1 0 8m#这里available还是0kubectl get podsNAME READY STATUS RESTARTS AGEkubernetes-bootcamp-390780338-6x48n 0/1 ContainerCreating 0 21h#pod处于创建状态#查看详情kubectl describe pods#错误信息 Warning FailedSync 4m (x258 over 21h) kubelet, 192.168.31.159 Error syncing pod, skipping: failed to &quot;StartContainer&quot; for &quot;POD&quot; with ErrImagePull: &quot;image pull failed for registry.access.redhat.com/rhel7/pod-infrastructure:latest, this may be because there are no credentials on this request. details: (open /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt: no such file or directory)&quot; Warning FailedSync 9s (x5728 over 21h) kubelet, 192.168.31.159 Error syncing pod, skipping: failed to &quot;StartContainer&quot; for &quot;POD&quot; with ImagePullBackOff: &quot;Back-off pulling image \&quot;registry.access.redhat.com/rhel7/pod-infrastructure:latest\&quot;&quot;#在node上查看此文件，发现它指向了一个空链接#并不存在/etc/rhsm目录ll /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crtlrwxrwxrwx. 1 root root 27 7月 16 16:58 /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt -&gt; /etc/rhsm/ca/redhat-uep.pem#在node安装此rhsmyum search rhsm#python-rhsm-certificates.x86_64#python-rhsm.x86_64yum install -y python-rhsm.x86_64 python-rhsm-certificates.x86_64#之后在node上手动拉取下image便可看到pod正常运行 探索应用程序Explore Your App 查看Pods和Nodes目标： 了解k8s Pods 了解k8s Nodes 部署应用的故障解决(troubleshoot) k8s Pods当你创建一个部署时，k8s创建了一个pod来托管你的应用程序实例。pod是k8s的一个抽象，表示一组(一个/多个)应用程序容器，以及这些容器的共享资源。pod有一个唯一的IP地址，甚至是同一节点上的pod。pod中的容器共享IP地址和端口，始终位于同一位置并共同调度，并在同一节点上共享上下文中运行。这些资源包括： 共享存储(volumes) 网络(唯一的集群内ip) 运行容器的相关信息 Nodespod总是运行在node上，一个node上可运行多个pod。每个node由master管理，master自动处理在node上调度pod。node至少运行如下组件： kubelet container runtime(如docker) Troubleshooting with kubectl最常用的kubectl命令： 12345678910111213141516171819#列出资源kubectl get#kubectl get nodes#某个资源的详细信息kubectl describe#kubectl describe deployments kubernetes-bootcamp#pod中容器日志kubectl logs#kubectl logs $pod --since=1h#在pod的容器执行命令kubectl exec#kubectl ecec $pod env#kubectl exec -it $pod /bin/bash 公开展示应用程序Expose Your App Publicly 使用服务来展示应用程序Using a Service to Expose Your App 目标： 了解k8s中的服务(service) 理解labels和LabelSelector对象如何关联服务 使用服务将应用程序展示在集群外部 k8s Service事实上，pods有一个生命周期。当工作node死亡，node上运行的pods也会丢失。ReplicationController可以通过创建新的Pod来动态地将集群驱动会所需状态，以使应用程序保持运行。k8s的服务是一个抽象概念，它定义了一组逻辑Pod和一个访问pods的策略。服务使用YAML或JSON来定义。由一组pods所构成的服务通常由LabelSelector来确定。尽管每个Pod都有一个唯一的IP地址，但如果没有服务，这些IP就不会在集群外公开。通过指定ServeceSpec中的type，可以不同方式公开服务: ClusterIP(默认方式)在集群内部IP公开服务，只可内部访问 NodePort使用NAT在集群的指定节点上公开服务 LoadBalancer创建一个外部负载均衡器，并给服务分配一个外部IP ExternalName通过返回带有名称的CNAME(k8s-dns)记录，使用任意名称公开服务 Services和Labels服务使用labels和selectors匹配一组pod这是一个允许对k8s的对象进行逻辑操作的分组原语。Label是附件到对象的键/值对，随时随地可修改。有多种方式可使用： 指定用于开发(development)、测试(test)、生产(procuct)的对象 嵌入版本tag 使用tag对对象进行分类 栗子： 1234567891011121314151617181920212223242526272829303132333435kubectl get pods#NAME READY STATUS RESTARTS AGE#kubernetes-bootcamp-390780338-6x48n 1/1 Running 0 22hkubectl get services#NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE#kubernetes ClusterIP 10.254.0.1 &lt;none&gt; 443/TCP 1d#公开展示应用程序kubectl expose deployment/kubernetes-bootcamp --type=&quot;NodePort&quot; --port 8080#service &quot;kubernetes-bootcamp&quot; exposedkubectl get services#NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE#kubernetes ClusterIP 10.254.0.1 &lt;none&gt; 443/TCP 1d#kubernetes-bootcamp NodePort 10.254.11.76 &lt;none&gt; 8080:31514/TCP 2mkubectl describe services/kubernetes-bootcampkubectl describe deployment#Labels: run=kubernetes-bootcamp#使用label查询kubectl get pods -l run=kubernetes-bootcampkubectl get services -l run=kubernetes-bootcamp#使用label删除kubectl delete service -l run=kubernetes-bootcampkubectl describe pods kubernetes-bootcamp-390780338-6x48nkubectl exec -it kubernetes-bootcamp-390780338-6x48n /bin/bash 扩展应用程序Scale Your App Running Multiple Instances of Your App 目标： 使用kubectl伸缩应用程序 伸缩应用程序前面通过部署创建的服务仅有一个pod，当遇到流量激增，我们便需要扩展应用程序。通过更改部署中的副本数来完成扩展。 扩展部署将确保使用可用资源(available resource)创建新的pod并将其调度到node。k8s支持Pod的自动伸缩，缩放到0(也就是没有pod)也是可能的，它将终止指定部署的所有Pod。对应用程序运行多个实例需要一种方法将流量分配给所有这些实例。服务有集成的负载均衡器(load-blancer)，可将网络流量分配到公开部署的所有Pod。服务将使用endpoint持续监控运行的Pod，以确保网络流量发送到可用的Pods。 一旦运行的应用程序有了多个实例，你就可以在不停机(downtime)的情况下执行滚动更新(rolling update)。 12345678910111213141516171819202122232425262728293031323334353637383940kubectl get deployments#1个#扩展实例kubectl scale deployments/kubernetes-bootcamp --replicas=4#deployment.extensions &quot;kubernetes-bootcamp&quot; scaledkubectl get deployments#4个kubectl get pods -o wide#4个kubectl describe deployment/kubernetes-bootcampkubectl describe services/kubernetes-bootcamp#缩放实例kubectl scale deployments/kubernetes-bootcamp --replicas=2#deployment.extensions &quot;kubernetes-bootcamp&quot; scaledkubectl get deployments#2个#有两个pods正在关闭中kubectl get pods -o wideNAME READY STATUS RESTARTS AGE IP NODEkubernetes-bootcamp-390780338-1zgvs 1/1 Terminating 0 7m 10.254.76.5 192.168.31.159kubernetes-bootcamp-390780338-6x48n 1/1 Running 0 2d 10.254.76.2 192.168.31.159kubernetes-bootcamp-390780338-bqztg 1/1 Running 0 7m 10.254.76.4 192.168.31.159kubernetes-bootcamp-390780338-hkwfd 1/1 Terminating 0 7m 10.254.76.3 192.168.31.159#关闭完成kubectl get pods -o wideNAME READY STATUS RESTARTS AGE IP NODEkubernetes-bootcamp-390780338-6x48n 1/1 Running 0 2d 10.254.76.2 192.168.31.159kubernetes-bootcamp-390780338-bqztg 1/1 Running 0 15m 10.254.76.4 192.168.31.159 升级应用程序Update your AppPerforming a Rolling Update 目标： 使用kubectl执行滚动升级 滚动更新用户希望应用程序始终可用，可发人员可能会多次部署新版本应用程序。在k8s中，这都可以通过滚动更新(rolling update)完成。滚动更新允许通过使用新的实例逐步更新Pod来实现部署的更新，而不需停机(downtime)。新的Pod将在具有可用资源的node上进行调度。在k8s中，更新是版本化的，任何部署更新都可以恢复到以前的版本。 与应用程序扩展类似，服务在更新期间仅会将流量负载均衡到可用的Pod(应用实例)。 滚动更新允许以下操作： 将应用程序从一个环境推到另一个环境 回滚(rollback)到之前的版本 无需停机的持续集成(CI)和持续交付(CD) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263kubectl get deploymentskubectl get pods#2个#更新镜像kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=docker.io/jocatalin/kubernetes-bootcamp:v2deployment.apps &quot;kubernetes-bootcamp&quot; image updated#kubectl get podsNAME READY STATUS RESTARTS AGEkubernetes-bootcamp-390780338-6x48n 1/1 Terminating 0 3dkubernetes-bootcamp-390780338-bqztg 1/1 Terminating 0 38mkubernetes-bootcamp-472176051-m6h1q 1/1 Running 0 29skubernetes-bootcamp-472176051-z4wqs 1/1 Running 0 29s#kubectl get podsNAME READY STATUS RESTARTS AGEkubernetes-bootcamp-472176051-m6h1q 1/1 Running 0 42skubernetes-bootcamp-472176051-z4wqs 1/1 Running 0 42s#检查回滚状态kubectl rollout status deployments/kubernetes-bootcampdeployment &quot;kubernetes-bootcamp&quot; successfully rolled out#更新kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=docker.io/jocatalin/kubernetes-bootcamp:v10deployment.apps &quot;kubernetes-bootcamp&quot; image updated#有错kubectl get deploymentsNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEkubernetes-bootcamp 2 3 2 1 3d#有错kubectl get podsNAME READY STATUS RESTARTS AGEkubernetes-bootcamp-384357858-7kjx1 0/1 ErrImagePull 0 2mkubernetes-bootcamp-384357858-t0wmt 0/1 ImagePullBackOff 0 2mkubernetes-bootcamp-472176051-m6h1q 1/1 Running 0 9m#kubectl describe pods#回滚kubectl rollout undo deployments/kubernetes-bootcampdeployment.apps &quot;kubernetes-bootcamp&quot;#查看kubectl get podskubectl decribe pods#Image: docker.io/jocatalin/kubernetes-bootcamp:v2#回到了V2版 配置Configuration 使用ConfigMap配置Redis目标(Objective) 创建ConfigMap 使用ConfigMap创建Pod规范 创建Pod 验证配置是否正确应用 开始之前需要有k8s集群，并且安装了kubectl命令行工具。 栗子：使用ConfigMap配置Redis 12345678910111213141516171819202122232425262728293031323334353637383940414243#Master#创建redis的ConfigMapkubectl create configmap redis-config --from-file=xxx/redis-configkubectl get configmap redis-config -o yaml#创建redis-pod.yaml文件apiVersion: v1kind: Podmetadata: name: redisspec: containers: - name: redis image: kubernetes/redis:v1 env: - name: MASTER value: &quot;true&quot; ports: - containerPort: 6379 resources: limits: cpu: &quot;0.1&quot; volumeMounts: - mountPath: /redis-master-data name: data - mountPath: /redis-master name: config volumes: - name: data emptyDir: &#123;&#125; - name: config configMap: name: redis-config items: - key: redis-config path: redis.conf#创建podkubectl create -f /etc/k8s/pods/config/redis-pod.yamlkubectl exec -it redis redis-cli 无状态应用程序Stateless Applications 公开外物IP以访问集群中的应用程序Exposing an External IP Address to Access an Application in a Cluster 目标 为一个Hello World应用程序运行五个实例 创建一个展示外部IP的服务对象 使用服务对象去访问运行的应用程序 为运行五个pods的应用程序创建一个服务 12345678910111213141516171819202122232425262728#运行hello worldkubectl run hello-world --replicas=5 --labels=&quot;run=load-balancer-example&quot; --image=gcr.io/google-samples/node-hello:1.0 --port=8080#--image=docker.io/jocatalin/hellonode:v1#查看信息kubectl get deployments hello-worldkubectl describe deployments hello-worldkubectl get replicasetskubectl describe replicasets#创建展示部署的服务对象kubectl expose deployment hello-world --type=LoadBalancer --name=my-service#如果外部地址显示为pending，请等待几分钟#查看信息kubectl get services my-servicekubectl describe services my-service#可看到LoanBlancer Ingresskubectl get pods --output=wide#访问外部地址(LoadBalancer Ingress)curl http://&lt;external-ip&gt;:&lt;port&gt; 清理 123456#删除服务kubectl delete services my-service#删除正在运行的程序的Deployment，ReplicaSet，Podskubectl delete deployment hello-world]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[性能分析]]></title>
    <url>%2F2018%2F05%2F14%2F%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[环境： CentOS7.x84_64 参考: strace命令: http://man.linuxde.net/strace pstack命令: http://man.linuxde.net/pstack lsof命令: http://man.linuxde.net/lsof 系统调用: https://zh.wikipedia.org/wiki/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8 Linux系统调用列表: https://www.ibm.com/developerworks/cn/linux/kernel/syscall/part1/appendix.html#8 高CPU分析: http://blog.51cto.com/yaocoder/1543352 系统调用系统调用(system call)，指运行在用户态的程序向操作系统内核请求需要更高权限运行的服务。系统调用提供用户程序与操作系统之间的接口。操作系统的进程空间可分为用户态和内核态，它们需要不同的执行权限。其中系统调用运行在内核态。 大多数系统交互式操作需求在内核态运行。如设备I/O或进程间通信。 内核态(kernel space)内核、核心扩充、驱动程序运行在内核空间上。 用户态(user space)其它的应用程序，则运行在用户空间上。所有运行在用户空间的应用程序，都被统称为用户级(userland)。 库函数系统调用和普通库函数调用非常相似，只是系统调用由操作系统内核提供，运行于内核核心态；而普通的库函数调用由函数库或用户自己提供，运行于用户态。 系统调用的意义 内核提供用户空间程序与内核空间进行交互的一套标准接口，这些接口让用户态程序能受限访问硬件设备，比如申请系统资源，操作设备读写，创建新进程等。用户空间发生请求，内核空间负责执行，这些接口便是用户空间和内核空间共同识别的桥梁，这里提到两个字“受限”，是由于为了保证内核稳定性，而不能让用户空间程序随意更改系统，必须是内核对外开放的且满足权限的程序才能调用相应接口。 在用户空间和内核空间之间，有一个叫做Syscall(系统调用, system call)的中间层，是连接用户态和内核态的桥梁。这样即提高了内核的安全型，也便于移植，只需实现同一套接口即可。Linux系统，用户空间通过向内核空间发出Syscall，产生软中断，从而让程序陷入内核态，执行相应的操作。对于每个系统调用都会有一个对应的系统调用号，比很多操作系统要少很多。 安全性与稳定性：内核驻留在受保护的地址空间，用户空间程序无法直接执行内核代码，也无法访问内核数据，通过系统调用 性能：Linux上下文切换时间很短，以及系统调用处理过程非常精简，内核优化得好，所以性能上往往比很多其他操作系统执行要好。 Linux系统调用方法 futexFutex 是fast userspace mutex的缩写，意思是快速用户空间互斥体。Linux内核把它们作为快速的用户空间的锁和信号量的预制构件提供给开发者。 selectselect系统调用允许程序同时在多个底层文件表述符上，等待输入的到达或输出的完成。 进程控制 函数 描述 fork 创建一个新进程 clone 按指定条件创建子进程 execve 运行可执行文件 exit 中止进程 _exit 立即中止当前进程 getdtablesize 进程所能打开的最大文件数 getpgid 获取指定进程组标识号 setpgid 设置指定进程组标志号 getpgrp 获取当前进程组标识号 setpgrp 设置当前进程组标志号 getpid 获取进程标识号 getppid 获取父进程标识号 getpriority 获取调度优先级 setpriority 设置调度优先级 modify_ldt 读写进程的本地描述表 nanosleep 使进程睡眠指定的时间 nice 改变分时进程的优先级 pause 挂起进程，等待信号 personality 设置进程运行域 prctl 对进程进行特定操作 ptrace 进程跟踪 sched_get_priority_max 取得静态优先级的上限 sched_get_priority_min 取得静态优先级的下限 sched_getparam 取得进程的调度参数 sched_getscheduler 取得指定进程的调度策略 sched_rr_get_interval 取得按RR算法调度的实时进程的时间片长度 sched_setparam 设置进程的调度参数 sched_setscheduler 设置指定进程的调度策略和参数 sched_yield 进程主动让出处理器,并将自己等候调度队列队尾 vfork 创建一个子进程，以供执行新程序，常与execve等同时使用 wait 等待子进程终止 wait3 参见wait waitpid 等待指定子进程终止 wait4 参见waitpid capget 获取进程权限 capset 设置进程权限 getsid 获取会晤标识号 setsid 设置会晤标识号 文件系统控制： 文件读写操作 fcntl 文件控制 open 打开文件 creat 创建新文件 close 关闭文件描述字 read 读文件 write 写文件 readv 从文件读入数据到缓冲数组中 writev 将缓冲数组里的数据写入文件 pread 对文件随机读 pwrite 对文件随机写 lseek 移动文件指针 _llseek 在64位地址空间里移动文件指针 dup 复制已打开的文件描述字 dup2 按指定条件复制文件描述字 flock 文件加/解锁 poll I/O多路转换 truncate 截断文件 ftruncate 参见truncate umask 设置文件权限掩码 fsync 把文件在内存中的部分写回磁盘 文件系统操作 access 确定文件的可存取性 chdir 改变当前工作目录 fchdir 参见chdir chmod 改变文件方式 fchmod 参见chmod chown 改变文件的属主或用户组 fchown 参见chown lchown 参见chown chroot 改变根目录 stat 取文件状态信息 lstat 参见stat fstat 参见stat statfs 取文件系统信息 fstatfs 参见statfs readdir 读取目录项 getdents 读取目录项 mkdir 创建目录 mknod 创建索引节点 rmdir 删除目录 rename 文件改名 link 创建链接 symlink 创建符号链接 unlink 删除链接 readlink 读符号链接的值 mount 安装文件系统 umount 卸下文件系统 ustat 取文件系统信息 utime 改变文件的访问修改时间 utimes 参见utime quotactl 控制磁盘配额 系统控制： ioctl I/O总控制函数 _sysctl 读/写系统参数 acct 启用或禁止进程记账 getrlimit 获取系统资源上限 setrlimit 设置系统资源上限 getrusage 获取系统资源使用情况 uselib 选择要使用的二进制函数库 ioperm 设置端口I/O权限 iopl 改变进程I/O权限级别 outb 低级端口操作 reboot 重新启动 swapon 打开交换文件和设备 swapoff 关闭交换文件和设备 bdflush 控制bdflush守护进程 sysfs 取核心支持的文件系统类型 sysinfo 取得系统信息 adjtimex 调整系统时钟 alarm 设置进程的闹钟 getitimer 获取计时器值 setitimer 设置计时器值 gettimeofday 取时间和时区 settimeofday 设置时间和时区 stime 设置系统日期和时间 time 取得系统时间 times 取进程运行时间 uname 获取当前UNIX系统的名称、版本和主机等信息 vhangup 挂起当前终端 nfsservctl 对NFS守护进程进行控制 vm86 进入模拟8086模式 create_module 创建可装载的模块项 delete_module 删除可装载的模块项 init_module 初始化模块 query_module 查询模块信息 *get_kernel_syms 取得核心符号,已被query_module代替 ioctl I/O总控制函数 _sysctl 读/写系统参数 acct 启用或禁止进程记账 getrlimit 获取系统资源上限 setrlimit 设置系统资源上限 getrusage 获取系统资源使用情况 uselib 选择要使用的二进制函数库 ioperm 设置端口I/O权限 iopl 改变进程I/O权限级别 outb 低级端口操作 reboot 重新启动 swapon 打开交换文件和设备 swapoff 关闭交换文件和设备 bdflush 控制bdflush守护进程 sysfs 取核心支持的文件系统类型 sysinfo 取得系统信息 adjtimex 调整系统时钟 alarm 设置进程的闹钟 getitimer 获取计时器值 setitimer 设置计时器值 gettimeofday 取时间和时区 settimeofday 设置时间和时区 stime 设置系统日期和时间 time 取得系统时间 times 取进程运行时间 uname 获取当前UNIX系统的名称、版本和主机等信息 vhangup 挂起当前终端 nfsservctl 对NFS守护进程进行控制 vm86 进入模拟8086模式 create_module 创建可装载的模块项 delete_module 删除可装载的模块项 init_module 初始化模块 query_module 查询模块信息 *get_kernel_syms 取得核心符号,已被query_module代替 内存管理： brk 改变数据段空间的分配 sbrk 参见brk mlock 内存页面加锁 munlock 内存页面解锁 mlockall 调用进程所有内存页面加锁 munlockall 调用进程所有内存页面解锁 mmap 映射虚拟内存页 munmap 去除内存页映射 mremap 重新映射虚拟内存地址 msync 将映射内存中的数据写回磁盘 mprotect 设置内存映像保护 getpagesize 获取页面大小 sync 将内存缓冲区数据写回硬盘 cacheflush 将指定缓冲区中的内容写回磁盘 网络管理： getdomainname 取域名 setdomainname 设置域名 gethostid 获取主机标识号 sethostid 设置主机标识号 gethostname 获取本主机名称 sethostname 设置主机名称 socket控制： socketcall socket系统调用 socket 建立socket bind 绑定socket到端口 connect 连接远程主机 accept 响应socket连接请求 send 通过socket发送信息 sendto 发送UDP信息 sendmsg 参见send recv 通过socket接收信息 recvfrom 接收UDP信息 recvmsg 参见recv listen 监听socket端口 select 对多路同步I/O进行轮询 shutdown 关闭socket上的连接 getsockname 取得本地socket名字 getpeername 获取通信对方的socket名字 getsockopt 取端口设置 setsockopt 设置端口参数 sendfile 在文件或端口间传输数据 socketpair 创建一对已联接的无名socket 用户管理： getuid 获取用户标识号 setuid 设置用户标志号 getgid 获取组标识号 setgid 设置组标志号 getegid 获取有效组标识号 setegid 设置有效组标识号 geteuid 获取有效用户标识号 seteuid 设置有效用户标识号 setregid 分别设置真实和有效的的组标识号 setreuid 分别设置真实和有效的用户标识号 getresgid 分别获取真实的,有效的和保存过的组标识号 setresgid 分别设置真实的,有效的和保存过的组标识号 getresuid 分别获取真实的,有效的和保存过的用户标识号 setresuid 分别设置真实的,有效的和保存过的用户标识号 setfsgid 设置文件系统检查时使用的组标识号 setfsuid 设置文件系统检查时使用的用户标识号 getgroups 获取后补组标志清单 setgroups 设置后补组标志清单 进程间通信： ipc, 进程间通信总控制调用 信号 sigaction 设置对指定信号的处理方法 sigprocmask 根据参数对信号集中的信号执行阻塞/解除阻塞等操作 sigpending 为指定的被阻塞信号设置队列 sigsuspend 挂起进程等待特定信号 signal 参见signal kill 向进程或进程组发信号 *sigblock 向被阻塞信号掩码中添加信号,已被sigprocmask代替 *siggetmask 取得现有阻塞信号掩码,已被sigprocmask代替 *sigsetmask 用给定信号掩码替换现有阻塞信号掩码,已被sigprocmask代替 *sigmask 将给定的信号转化为掩码,已被sigprocmask代替 *sigpause 作用同sigsuspend,已被sigsuspend代替 sigvec 为兼容BSD而设的信号处理函数,作用类似sigaction ssetmask ANSI-C的信号处理函数,作用类似sigaction 消息 msgctl 消息控制操作 msgget 获取消息队列 msgsnd 发消息 msgrcv 取消息 管道 pipe, 创建管道 信号量 shmctl 控制共享内存 shmget 获取共享内存 shmat 连接共享内存 shmdt 拆卸共享内存 共享内存 shmctl 控制共享内存 shmget 获取共享内存 shmat 连接共享内存 shmdt 拆卸共享内存 strace命令strace命令是一个集诊断、调试、统计与一体的工具，我们可以使用strace对应用的系统调用和信号传递的跟踪结果来对应用进行分析，以达到解决问题或者是了解应用工作过程的目的。当然strace与专业的调试工具比如说gdb之类的是没法相比的，因为它不是一个专业的调试器。 strace的最简单的用法就是执行一个指定的命令，在指定的命令结束之后它也就退出了。在命令执行的过程中，strace会记录和解析命令进程的所有系统调用以及这个进程所接收到的所有的信号值。 strace可跟踪一个命令或进程。 123strace - trace system calls and signalsstrace --help 问题案例当发现进程或服务异常时，我们可以通过strace来跟踪其系统调用，“看看它在干啥”，进而找到异常的原因。熟悉常用系统调用，能够更好地理解和使用strace。当然，万能的strace也不是真正的万能。当目标进程卡死在用户态时，strace就没有输出了。 定位进程异常退出 定位共享内存异常 性能分析 pstack命令pstack命令可显示每个进程(线程)的栈跟踪。 123yum install -y gdbpstack $PID lsof命令lsof命令用于查看你进程开打的文件，打开文件的进程，进程打开的端口(TCP、UDP)。 123456789101112-a：列出打开文件存在的进程-c&lt;进程名&gt;：列出指定进程所打开的文件-g：列出GID号进程详情-d&lt;文件号&gt;：列出占用该文件号的进程+d&lt;目录&gt;：列出目录下被打开的文件+D&lt;目录&gt;：递归列出目录下被打开的文件-n&lt;目录&gt;：列出使用NFS的文件-i&lt;条件&gt;：列出符合条件的进程（4、6、协议、:端口、 @ip ）-p&lt;进程号&gt;：列出指定进程号所打开的文件-u：列出UID号进程详情-h：显示帮助信息-v：显示版本信息 高CPU占用分析步骤： 查看进程 top 查看线程 top -H -p $pid 查看进程打开连接数 lsof -p ${pid} 追踪 strace -T -r -c -p $pid 栈 pstack $pid]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>系统调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python]]></title>
    <url>%2F2018%2F05%2F06%2FPython%2F</url>
    <content type="text"><![CDATA[环境: CentOS7x86_64 Python3.5 参考: Python教程: https://docs.python.org/3.5/tutorial/index.html Python术语: https://docs.python.org/3.5/glossary.html Python语言参考: https://docs.python.org/3.5/reference/index.html Python HOWTOs: https://docs.python.org/3.5/howto/index.html Python标准库: https://docs.python.org/3.5/library/ PyPI: https://pypi.org/ Awesome-Python https://github.com/vinta/awesome-python https://github.com/jobbole/awesome-python-cn 术语Glossary &gt;&gt;&gt;交互式shell的默认Python提示符 ...在为缩进代码块输入代码时，或在一对匹配的左右分隔符中，交互式shell的默认Python提示符 2to3将Python2.x代码转换为Python3.x代码的工具 抽象基类(abstract base class) 参数(argument)调用函数时传递给(或方法)的值: 关键字参数/可选参数 异步上下文管理器(asynchronous context manager)控制在异步语句中看到的环境对象 异步生成器(asynchronous generator)返回一个生成器迭代器的函数 异步生成器迭代器(asynchronous generator iterator)由异步生成器创建的对象 异步可迭代(asynchronous iterable)一个对象 异步迭代器(asynchronous iterator)一个对象 属性(attribute)按名称引用的对象关联的值 awaitable一个对象 二进制文件(binary file)能读写bytes-like对象的文件对象 bytes-like对象支持Buffer Protocol并可以导出C-contiguous buffer的对象 字节码(bytecode)Python源代码被编译成字节码 类(class)用于创建用户对象的模板 coercion在涉及两个相同类型参数的操作中，将一个类型的实例隐式转换为另一个类型的实例 复数(complex number) 上下文管理器(context manager) contiguous 协程(coroutine) coroutine function CPythonPython语言的规范实现 修饰器(decorator)返回另一个函数的函数 描述(descriptor) 字典(dictionary) 字典视图(dictionary view)从dict.keys(), dict.values(), dict.items()返回的对象称为字典视图 文档字符串(docstring)在类，函数，或模块中的第一个表达式出现的字符串文字 duck-typing一种编程风格 表达式(expression) 扩展模块(extension module)由C/C++编写，通过Python API与核心和用户代码交互 f-string 文件对象(file object) finder为正在导入的模块查找加载程序的对象 地板除(floor division) 函数(function) 函数注释(function annotation) __future__可使用伪模块来启用与当前解释器不兼容的新语言功能 垃圾回收(garbage collection)不再使用时释放内存的过程 生成器(generator) generator iterator 生成器表达式(generator expression)返回迭代器的表达式 通用函数(generic function)由多个函数组成的函数 global interpreter lock确保一次只有一个线程执行Python字节码的机制 hashable如果一个对象具有在其生命周期内从不改变的hash值，并且可与其它对象相比，那么这个对象就是可hash的 IDLEPython的集成开发环境 一成不变的(immutable)具有固定值的对象 易变的(mutable)可改变它们值得对象 import path importing一个模块中的Python代码在另一个Python代码中可获取 importer既能找到又能加载模块的对象 交互式(interactive) 解释型(interpreted)Python是一种解释型语言，与编译型语言相反 interpreter shutdown 迭代(iterable)一次能够返回其成员的对象 迭代器(iterator)表示数据流的对象 关键函数(key function)关键函数或整理函数是一个可调用函数，它返回用于排序的值 关键字参数(keyword argument) lambda一个匿名内联函数，由调用该函数时评估的单个表达式组成 LBYL三思而后行(Look before you leap) 列表(list)一个内建Python序列 list comprehension一种紧凑的方式来处理序列中的全部或部分元素，并返回列表和结果 loader加载模块的对象 映射(mapping)支持任意键查找并实现映射中指定方法的容器对象 meta path finder metaclassThe class of a class 方法(method)类里面定义的函数 method resolution order 模块(module)Python代码的组织单元的对象 module spec named tuple 命名空间(namespace)变量存储的地方 namespace package仅用作子包的包 嵌套范围(nested scope)能够在封闭变量中引用变量 new-style class 对象(object)具有状态和定义行为的任一数据 包(package)可包含子模块或递归子模块的Python模块 参数(parameter)函数或方法定义中的一个命名实体，用于指定该函数可接受的参数。有5中参数: positional-or-keyword: positional-only keyword-only var-positional var-keyword path entry path entry finder path entry hook path based finder path-like object portion单目录中的一组文件 positional argument provisional API provisional package Python 3000Python3.x发行版的昵称 Python化(Pythonic)与Python语言最常见的习惯用法密切相关的想法或代码片段，而不是使用其它语言通用的概念来实现该代码 合格的名字(qualified name) 引用计数(reference count)对某个对象的引用次数 regular package __slots__类中的声明，通过预先声明实例属性的空间并消除实例字典来节省内存 序列(sequence) 单一调度(single dispatch)通用函数调度的一种形式 切片(slice)通常包含一部分序列的对象 special method一种由Python隐式调用的方法 声明(statement) struct sequence具有命名元素的元组 text encoding text file 三重引号(triple-quoted string) type 通用换行符(universal newlines)Unix: \n; Windows: \r\n 变量注释(variable annotation)与模块全局变量或类属性关联的类型元数据值 虚拟环境(virtual environment) 虚拟机(virtual machine) Zen of PythonPythono的设计原理和哲学 教程官网: https://www.python.org/ Python教程非正式地向读者介绍了Python语言和系统的基本概念和功能。Python是一种易于学习，功能强大的编程语言。它具有高效的高级数据结构以及面向对象(object-oriented)编程的简单而有效的方法。优雅的语法和动态类型以及其解释的特性，使其成为大多数平台上许多领域脚本编写(scripting)和快速应用程序开发的理想语言。Python解释器很容易用C或C++实现新功能和数据类型进行扩展。Python也适合作为定制程序的扩展语言。 本教程非正式地向读者介绍了Python语言和系统的基本概念和功能，不会涵盖每个功能。相反，它引入了许多Python最值得注意的功能和语言风格。 激起你的胃口Whetting Your Appetite 将一些工作自动化，或编写一个小程序。 C/C++/Java，编写/编译/测试/重编译周期太慢，但你又不想为你的应用程序开发和设计一门全新的语言。 这样的话，Python就是适合你的语言！ 为一些任务编写Unix shell script或Windows batch file，但它们只适合文本数据，而不适合GUI应用程序…你可以编写C/C++/Java程序，但需要很长的开发时间。Python简单易用，可帮助你更快完成工作。 Python为大型程序提供更多的结构和支持，它提供了更多的错误检查。作为一种非常高级的语言，它有内建的高级数据类型(如灵活的数组和字典)。由于其更通用的数据类型，Python适用于比awk甚至Perl更大的问题域，但Python中的许多事情至少与这些语言一样容易。 Python允许你将你的程序拆分成模块，使其它Python程序能重用。它附带了大量的标准模块，你可将它们作为学习Python编程的基础。包括了: 文件I/O；系统调用；socket；GUI… Python是一种解释型语言，在程序开发中节省大量时间，因为不需要编译和链接。 Python可以使程序紧凑而易读，由Python编写的程序通常比等效的C/C++/Java程序代码少得多。原因如下: 高级数据类型允许你在单个语句中表达复杂的操作 语句分组通过缩进(4个空格)来完成，而不是开始和结束 无需声明变量和参数 Python是可扩展的，如果你会C编程的话，很容易为解释器添加一个新的内置函数或模块，或将Python程序链接到可用库的二进制形式。也可将Python解释器链接到C编写的应用程序中。 顺便说一句，该语言是根据BBC节目Monty Python’s Flying Circus命名，与爬行动物无关。 学习语言的最好方法就是使用它，以工代练！ 解释器Python Interpreter My Linux: /usr/bin/python3 /lib64/python3.5/ 交互模式Interactive Mode 1234python3&gt;&gt;&gt;for i in range(4):... 参数传递Argument Passing 使用sys模块的argv变量给脚本传递参数。 12345678910111213141516171819import sysnum = len(sys.argv)if num != 3: print('Usage: xxx.py argv1 argv2')else: print('argu[0] is ' + sys.argv[0]) print('argu[1] is ' + sys.argv[1]) print('argu[2] is ' + sys.argv[2])chmod u+x xxx.py./argvPass.py 1 22argu[0] is ./argvPass.pyargu[1] is 1argu[2] is 22 编码格式Source Code Encoding 12#!/usr/bin/python3# -*- coding: utf-8 -*- 介绍An Informal Introduction to Python 注意Python的两个默认提示符: &gt;&gt;&gt; ... 作为计算器Using Python as a Calculator Numbers12345678910111213+ -*///(取商)%(取余)**intfloatdecimalfraction(分数)comlex number(复数) Strings123456789101112131415'(single quote)"(double quote)\(转义)r(元字符)'''"""+*indexstring[-1]string[0:2]len() Lists1234567891011list = [xx, x, ...]indexlist[index]list[start:stop]methodappend()pop()del()... 编程第一步First Steps Towards Programming 斐波那契数列(Fibonacci series) 1234567a, b = 0, 1while b &lt; 10: print(b, end=',') a, b = b, a+b #多重赋值(multiple assignment) #关键字参数(keyword argument) 控制流Control Flow Tools whilewhile Statements 123456a = input(int('Please input an int: '))whiel a &lt; 50: a += 1print(a) ifif Statements 1234567891011x = int(input("please input an int: "))if x &lt; 0: x = 0 print('Negative changed to zero')elif x == 0: print('Zero')elif x == 1: print('Single')else: print('More') forfor Statements 12345678910111213141516words = ['a', 'bb', 'ccc']for w in words: print(w, len(w))'''如果需要修改迭代中的序列，建议先制作副本，遍历一个序列并不会隐式地创建一个副本'''words = ['a', 22, 'ccc']for w in words[:]: if type(w) is int: words.insert(0, w)words[22, 'a', 22, 'ccc'] rangeThe range() Function遍历一系列数字 1234567891011121314for i in range(5): print(i)for i in range(0, 101, 10): print(i)a = [1, 22, 'A', 'AA']for i in range(len(a)) print(i, a[i])list(range(5))[0, 1, 2, 3, 4] 注意在许多方面，由range()返回的对象的行为就好像它是一个列表，但事实并非如此。它是一个对象，在你迭代时才返回所需序列，但它并不真正生成列表，从而节省空间。我们说这样一个对象是可迭代的(iterable)。 12print(range(10))range(0, 10) break/continuebreak and continue Statements, and else Clauses on Loops break 结束循环 continue 结束本次循环 passpass Statementspass语句什么也不做！当语句需要语法而程序不需要任何操作时，可使用它。 12345while True: passclass emptyClass: pass 函数定义Defining Functions关键字def引入一个函数定义，必须跟随函数名称和形式参数。函数主体语句必须缩进 函数主体的第一个语句是可选的字符串文字(sting literal)，用于描述函数。在编写的代码中包含文档字符串是一种很好的做法，请养成此习惯。 函数中的所有变量赋值都将值存储在本地符号表中，而变量引用首先在本地符号表中查找，然后是封闭函数的本地符号表，然后是全局符号表，最后是内置名称表。因此，全局变量不能直接在函数内赋值(除非是global语句)，尽管它们可能被引用。 事实上即使是没有return语句的函数也会返回一个值，它被称为None(一个内建名) 1234567891011121314151617def fib(n): """function's documentation print a Fibonacci series up to n. """ a, b = 0, 1 while a &lt; n: print(a, end=' ') a, b = b, a+b print()fib(100)f = fibf(100)print(fib())None 也可以使用可变数量的参数来定会函数。 默认参数值Default Argument Values 最有用的形式是为一个或多个参数指定默认值。 1234567891011def ask_ok(prompt, retries=4, reminder='Please try again!'): while True: ok = input(prompt) if ok in ('y', 'ye', 'yes'): return True if ok in ('n', 'no', 'nop', 'nope'): return False retries = retries - 1 if retries &lt; 0: raise ValueError('invalid user response') print(reminder) 函数可通过如下方法调用: 只给出必须的参数: ask_os(&#39;Prompt xxx&#39;) 给出可选参数: ask_ok(&#39;Prompt xx&#39;, 3) 给出所有参数: ask_ok(agr1, arg2, arg3) 关键字参数Keyword Arguments 也可使用kwarg = value来调用函数。 1234567891011121314def parrot(voltage, state='a stiff', action='voom', type='Norwegian Blue'): print("-- This parrot wouldn't", action, end=' ') print("if you put", voltage, "volts through it.") print("-- Lovely plumage, the", type) print("-- It's", state, "!")parrot(1000) # 1 positional argumentparrot(voltage=1000) # 1 keyword argumentparrot(voltage=1000000, action='VOOOOOM') # 2 keyword argumentsparrot(action='VOOOOOM', voltage=1000000) # 2 keyword argumentsparrot('a million', 'bereft of life', 'jump') # 3 positional argumentsparrot('a thousand', state='pushing up the daisies') # 1 positional, 1 keyword *name/**name**name，它接收一个字典(keyword=value)。可能与*name结合使用。*name必须出现在**name之前。 123456789101112131415161718192021222324def shop(kind, *arguments, **keywords): print("-- Do you have any ", kind, "?") print("-- I'm sorry, we're all out of ", kind) for arg in arguments: print(arg) print('\n-----\n') for kw in keywords: print(kw, ':', keywords[kw])shop('Kind', 'arg1', 'arg2', kw1='KW1', kw2='KW2', kw3='KW3')"""-- Do you have any Kind ?-- I'm sorry, we're all out of Kindarg1arg2-----kw3 : KW3kw1 : KW1kw2 : KW2""" 任意参数列表Arbitrary Argument Lists 最不经常使用的选项是指定可以用任意数量的参数调用一个函数，这些参数将被封装在一个元组中。 12345def arb(*args): for arg in args: print(arg)art(1, 22, 'CCC') 解包参数Unpacking Argument Lists 当参数已经在一个列表或元组中时，会出现相反的情况。需要对单独的位置参数的函数调用进行解包。 123456list(range(5))[0, 1, 2, 3, 4]args = [5]list(range(*args))[0, 1, 2, 3, 4] Lambda表达式可以使用lambda关键字创建小的匿名函数。Lambda函数可用于需要函数对象的任何地方，它在语法上受限于单个表达式。 123456789def lambdaTest(n): return lambda x: x + nf = lambdaTest(10)f(1)11f(5)15 文档字符串Documentation Strings 以下是关于文档字符串内容和格式的一些约定: 第一行应该始终是对象目的的简短摘要 第二行应该是空白，如果有多行的话 以下几行应该是描述 12345678910111213def func(): """Document it. This func just print one argument. """ print(sys.argv[1])print(func.__doc__)Document it. This func just print one argument. 函数注释Function Annotations 函数注释完全是关于用户定义函数使用的类型的可选元数据信息。 Annotations以字典的形式存储在函数的__annotations__属性中，并且不影响函数的其它部分。参数注释由参数名称后面的冒号:定义，后跟表达式评估注释的值。注释由参数列表和def语句结束的冒号之间的-&gt;定义，后跟一个表达式。 123456def f(name: str, age: int = 18) -&gt; str: print("Annotations: ", f.__annotations__) print("Arguments: ", name, age) return name + 'and' + str(age)f('Zhang21') 编码风格不同的语言有不同的编码风格。但是，让别人很轻松便能阅读你的代码总是一个好主意！ 对于Python而言，PEP(Python Enhanced Proposals) 8 已成为大多数项目遵循的风格指南。它促进了非常可读和令人喜爱的编码风格，每个Python开发者都应该阅读它。以下是最重要的几点： 使用4空格缩进，而不是tab 自动换行，不要超过79个字符 使用空白行来分割函数和类，以及函数内的更大快代码 如有可能，请将注释放在它们的上一行 使用文档字符串 在运算符和逗号后面使用空格，但不要直接在包围结构中使用空格 -&gt; (a + b) 一致地命名函数和类 建议使用UTF-8编码方式 建议不要在标识符中使用non-ASCII字符，如果有其它语言的人会去维护代码 数据结构Data Structures 列表More on Lists 列表数据类型有多种方法： list.append(x)添加一个项到列表的末尾 list.extend(iterable)通过添加迭代中的所有项来扩展列表 list.insert(i, x)在列表中给定位置插入一个项 list.remove(x)删除列表中给定值的第一项 list.pop()返回并删除列表中给定位置的项如果未指定index，则默认为最后一项 list.clear()删除列表中的所有项 list.index(x)返回指定值的第一个索引如果没有此值，返回ValueError list.count(x)返回列表中指定值出现的次数 list.sort()对列表中的项进行排序 list.reverse()反转列表中的元素 list.copy()返回列表的shallow copy 列表用处： Stack Queue 列表解析List Comprehensions 12345678910111213 #列表解析提供了一个简洁的方式来创建列表l = []for i in range(10): l.append(i**2) #lambdal = list(map(lambda i: i**2, range(10))) #orl = [x**2 for i in range(10)][(x, y) for x in [1, 2, 3] for y in [3, 2, 1] if x != y] 嵌套列表解析Nested List Comprehensions 列表解析中的初始表达式可以是任意表达式，包括另一个列表解析。 1234567l = [ [1, 2, 3, 4], [5, 6, 7, 8], [9, 10 ,11, 12]][[row[i] for row in l] for i in range(4)] del语句del语句可从列表中删除切片或整个列表。 123456789a = [1, 2, 3, 4]del a[0]del a[1:3]del a[:]del a 元组和序列Tuples and Sequences 列表和字符串由许多共同属性，如索引和切片操作。列表是可变的，它们的元素通常是同类，并且通过遍历列表可访问。 元组是不可变的！无法对元组项赋值，但可创建包含可变对象的元组。 1234567891011121314151617181920212223t = (123, 321, 'hello')tt = t, ('a', 'bb')(123, 321, 'hello), ('a', 'bb') #对元组赋值会出错t[0] = 888TypeError: 'tuple' object does not support item assignment #序列拆包(unpacking) #要求变量数量等于元素数量x, y, z = tx123y321z'hello' 集合Sets Python中的集合是没有重复元素的无序集合，并支持数学操作: 并集 a | b 交集 a &amp; b 差集 a - b 异或 a ^ b 使用大(花)括号{}或set()创建集合，但创建一个空集合使用set()，而不是{}——后者创建一个空字典。 集合也支持集合解析。 123456789101112131415161718192021alpha = &#123;'a', 'b', 'c', 'a'&#125;alpha&#123;'c', 'b', 'a'&#125;'c' in alphaTrue #数学运算a = set('abracadabra')b = set('alacazam')a | ba &amp; ba - ba ^ b #集合解析&#123;x for x in 'abcdefgabc' if x not in 'abc'&#125; 字典Dictionaries 字典数据类型在其它语言中被称为“associative memories” or “associative arrays”。与由数字索引的序列不同，字典由key索引(可以是任何不可变类型)，字符串和数字都可作为key。如果元组只包含字符串，数字或元组，则可作为key。若包含任何可变对象，则不能作为key。你不能使用列表作为key。 可将字典视为无序的键:值对，并要求键是唯一！花括号{}创建一个空字典。 字典的主要操作是用某个key存储value，并提取给定key的value。使用del语句删除一个键值对；新键值对会替换旧键值对。 1234567891011121314151617181920info = &#123;'name': 'AA', 'id': 1, 'tel': 155&#125;info['addr'] = 'Chengdu'infoinfo['name']del info['id']list(info.keys())print(info.values())print(info.items()) #dict()构造函数dict([('name', 'A'), ('age', 11)])dict(&#123;'name': 'A', 'age': 11&#125;)dict(name='zhang', age=11) #字典解析&#123;x: x**2 for x in (2, 4, 6)&#125; 循环技巧Looping Techniques 字典循环 123456info = &#123;'name': 'AA', 'age': 11&#125;for k, v in info.items(): print(k, v, sep=':')name:AAage:11 序列循环可使用enumerate()函数同时检索位置索引和相应值 123456for i, v in enumerate(['a', 'b', 'c']): print(i, v)0 a1 b2 c 同时循环多个序列要同时循环多个序列，可将这些条目与zip()函数配对 123456789aa = [1, 2, 3]bb = ['a', 'b', 'c']for a, b in zip(aa, bb): print('&#123;0&#125;, &#123;1&#125;'.format(a, b))1, a2, b3, c 反向循环序列 1234for i in reversed(range(6)): print(i, end=',')5,4,3,2,1,0, 循环排序 123456789101112131415161718l = ['ac', 'fb', 'nx', 'by']for i in sorted(l): print(i)acbyfbnxll = ['ac', 'fb', 'nx', 'by', 'ac', 'by']for i in sorted(set(ll)): print(i)acbyfbnx 关于条件More on Conditions while和if语句中使用的条件可以包含任何运算符，而不仅仅是比较。 比较操作符in和not in检查值是否在序列中操作符is和is not比较两个对象是否相同，这适用于可变对象(如list) 比较操作可以使用布尔运算符and和or进行组合，结果可用not。它们的优先级低于比较操作所有的比较操作符(comparison operators)具有相同的优先级，都低于数值运算符 模块Modules 如果你从Python解释器中退出并重新进入，你所做的定义(函数和变量)将会丢失。因此，如果编写一个稍长的程序，最好使用文本编辑器，然后将代码文件作文输入来运行它。这就被称为创建一个脚本。随着程序变长，可能需要将其分割为便于维护的多个文件。你可能还想使用你在多个程序中编写的某个功能(函数)，而不是将其定义复制到每个程序中。 为了支持此，Python有一种方法可将定义(definition)放入一个文件中，并在脚本或交互式实例中使用它们。这样的文件被称为模块(module)。来自模块的定义可以被导入到其它模块或主模块中。 模块是一个包含Python定义和语句的文件。文件名是带有.py的模块名。在模块中，模块的名称(string)用作全局变量__name__的值。 编写一个模块：vim /path/fibo.py 12345678910111213141516 #Fibonacci numbers moduledef fib(n): a, b = 0, 1 while b &lt; n: print(b, end=' , ') a, b = b, a+b print()def fib2(n): result = [] a, b = 0, 1 while b &lt; n: result.appen(b) a, b = b, a+b return result 载入此模块：如果没有将此模块放入Python默认lib目录(如/usr/lib64/python3.5/)的话，则需要进入模块所在目录打开Python解释器。 12345678910111213cd /pathpython3&gt;&gt;&gt; import fibo&gt;&gt;&gt; fibo.fb(100)1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89,&gt;&gt;&gt; fibo.fib2(100)[1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89]&gt;&gt;&gt; fibo.__name__'fibo'&gt;&gt;&gt; fibo.__str__()module 'fibo' from '/path/fibo.py' 更多模块信息More on Modules 一个模块可以包含可执行语句以及函数定义。这些语句旨在初始化模块，它们仅在import语句中第一次遇到模块名称时执行。 每个模块都有自己的私人符号表(private symbol table)，它被模块中定义的所有函数(functions)用作全局符号表(global symbol talbe)。因此，模块的作者可以在模块中使用全局变量(global variable)，而不用担心与用户的全局变量发生意外冲突。 模块可以导入其它模块。习惯上(但不是硬性要求)，将import语句放在模块(脚本)的开头。导入模块的名称被放置在导入模块的全局符号表中。 将模块名称直接导入到导入模块的符号表中，这不会在本地符号表中引入导入模块的名称 12 #fibo模块名并没有被定义from fibo import fib, fib2 导入模块中定义的所有名称在大多数情况下，Python程序员不会使用这个工具。因为它会向解释器引入一组未知的名称，可能会隐藏你已经定义的一些东西。注意，通常从模块或包中import *的做法是不被接受的，因为它经常会导致代码可读性很差。但是，可以使用它来保存交互式会话中的输入。 12 #这会导入除了以下划线开头的所有名称from fibo import * 将导入模块名称绑定到指定名称 123456789import fibo as fibfib.fib(100)fib.fib2(100)from fibo import fib2 as fibonaccifibonacci(100) 把模块作为脚本来执行Executing modules as scripts 如果你将模块中的__name__设置为__main__，模块中的代码就会被执行，就像导入它一样。这意味着你需要在你的模块的末尾添加它们。如果模块被导入，代码也不会执行。 这通常用于为模块提供用户接口，或测试。 123456if __name__ == "__main__": import sys fib(int(sys.argv[1]))python3 fibo.py &#123;args&#125; 模块的搜索路径The Module Search Path 当import fibo模块时，解释器首先在内建模块中搜索此名称。如果找不到，它会在sys.path给出的目录列表中搜索fibo.py文件。 sys.path从以下位置初始化： 包含输入脚本的目录(未指定文件时的当前目录) PYTHONPATH 依赖于安装的默认值 包含符号链接的目录不会被添加到模块的搜索路径中 编译的Python文件Compiled Python files 为了加速载入模块，Python将每个模块的编译版本缓存在名为module.version.pyc的__pycache__目录下，对编译文件的格式进行编码，它通常包含Python版本号。Python根据编译后的版本检查源代码的修改日期，看它是否过期并需要重新编译。这是一个完全自动的过程。另外，编译后的模块时独立于平台的，因此可以在不同体系结构的系统之间共享相同的库。 有两种情况，Python不会检查缓存： 总是重新编译并且不存储从命令行直接加载的模块的结果 没有源模块 专家提示： 可以Python命令中使用-0或-00来减少已编译模块的大小 读取.pyc文件不会比.py文件快，唯一更快的事情是它们被加载的速度 模块compileall可以为目录中的所有模块创建.pyc文件 更多细节，参见PEP 3147 标准模块Standard Modules Python提供了一个标准模块库。 一些模块被内置到解释器中，提供了对操作的访问。这些操作不属于语言核心的一部分，但是为了提高效率或提供对操作系统的访问权限。 12345678910111213141516import syssys.ps1'&gt;&gt;&gt;'sys.ps2'...'sys.ps1 = '&lt;&lt;&lt;'sys.ps1'&lt;&lt;&lt;' #查看PYTHONPATHsys.path.__str__ #添加PYTHONPATHsys.path.append('/home/zhang/venv/python') dir()函数内建函数dir()用于找出模块定义的名称。它列出所有类型的名称： 变量，模块，函数… 123456789101112131415import fibo, sysdir(fibo)['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'fib', 'fib2']dir(sys)['__displayhook__', '__doc__', '__excepthook__', '__interactivehook__', '__loader__', '__name__', '__package__', '__spec__', '__stderr__', '__stdin__', '__stdout__', '_clear_type_cache', '_current_frames', '_debugmallocstats', '_getframe', '_home', '_mercurial', '_xoptions', 'abiflags', 'api_version', 'argv', 'base_exec_prefix', 'base_prefix', 'builtin_module_names', 'byteorder', 'call_tracing', 'callstats', 'copyright', 'displayhook', 'dont_write_bytecode', 'exc_info', 'excepthook', 'exec_prefix', 'executable', 'exit', 'flags', 'float_info', 'float_repr_style', 'getallocatedblocks', 'getcheckinterval', 'getdefaultencoding', 'getdlopenflags', 'getfilesystemencoding', 'getprofile', 'getrecursionlimit', 'getrefcount', 'getsizeof', 'getswitchinterval', 'gettrace', 'hash_info', 'hexversion', 'implementation', 'int_info', 'intern', 'last_traceback', 'last_type', 'last_value', 'maxsize', 'maxunicode', 'meta_path', 'modules', 'path', 'path_hooks', 'path_importer_cache', 'platform', 'prefix', 'ps1', 'ps2', 'setcheckinterval', 'setdlopenflags', 'setprofile', 'setrecursionlimit', 'setswitchinterval', 'settrace', 'stderr', 'stdin', 'stdout', 'thread_info', 'version', 'version_info', 'warnoptions'] #它不会列出内建函数和变量的名称，除非如下操作import builtinsdir(builtins)['ArithmeticError', 'AssertionError', 'AttributeError', 'BaseException', 'BlockingIOError', 'BrokenPipeError', 'BufferError', 'BytesWarning', 'ChildProcessError', 'ConnectionAbortedError', 'ConnectionError', 'ConnectionRefusedError', 'ConnectionResetError', 'DeprecationWarning', 'EOFError', 'Ellipsis', 'EnvironmentError', 'Exception', 'False', 'FileExistsError', 'FileNotFoundError', 'FloatingPointError', 'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError', 'ImportWarning', 'IndentationError', 'IndexError', 'InterruptedError', 'IsADirectoryError', 'KeyError', 'KeyboardInterrupt', 'LookupError', 'MemoryError', 'NameError', 'None', 'NotADirectoryError', 'NotImplemented', 'NotImplementedError', 'OSError', 'OverflowError', 'PendingDeprecationWarning', 'PermissionError', 'ProcessLookupError', 'ReferenceError', 'ResourceWarning', 'RuntimeError', 'RuntimeWarning', 'StopIteration', 'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit', 'TabError', 'TimeoutError', 'True', 'TypeError', 'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning', 'ValueError', 'Warning', 'ZeroDivisionError', '_', '__build_class__', '__debug__', '__doc__', '__import__', '__loader__', '__name__', '__package__', '__spec__', 'abs', 'all', 'any', 'ascii', 'bin', 'bool', 'bytearray', 'bytes', 'callable', 'chr', 'classmethod', 'compile', 'complex', 'copyright', 'credits', 'delattr', 'dict', 'dir', 'divmod', 'enumerate', 'eval', 'exec', 'exit', 'filter', 'float', 'format', 'frozenset', 'getattr', 'globals', 'hasattr', 'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', 'issubclass', 'iter', 'len', 'license', 'list', 'locals', 'map', 'max', 'memoryview', 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow', 'print', 'property', 'quit', 'range', 'repr', 'reversed', 'round', 'set', 'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type', 'vars', 'zip'] 包Packages 包是通过”dotted(.) module names“，来构造Python模块命名空间的一种方式。 假设你想设计一个模块集(包)来统一处理声音文件和声音数据。有许多不同的声音文件格式。因此你需要创建和维护不断增长的模块集合，以便在各种文件格式之间进行转换。你还可能需要对声音数据执行各种不同的操作，因此你还需要编写无止境的模块流以执行这些操作。 这可能是一个包结构: 1234567891011121314151617181920212223sound/ Top-level package __init__.py Initialize the sound package formats/ Subpackage for file format conversions __init__.py wavread.py wavwrite.py aiffread.py aiffwrite.py auread.py auwrite.py ... effects/ Subpackage for sound effects __init__.py echo.py surround.py reverse.py ... filters/ Subpackage for filters __init__.py equalizer.py vocoder.py karaoke.py ... 当导入包时，Python将搜索sys.path，并查找包的子目录。需要__init__.py文件才能使Python将目录视为包含包。这是为了防止具有通用名称的目录(如字符串)无意中隐藏稍后在模块搜索路径中发生的有效模块。在最简单的情况下，__init__.py可以是一个空文件，但它也可以执行包的初始化代码。 导入包: from package import itemitem可以是子模块，子包，函数，类，变量import语句首先测试项目是否在包中定义。 如果不在，它假定它是一个模块并尝试加载它。如果找不到它，则会引发ImportError异常 import item.subitem.subsubitem相反，当使用这种语法时，除最后一项外必须都是一个包，最后一项可以是模块或包，但不能是类或函数或变量 123import sound.effects.echofrom sound.effects import echo importing * from a package当输入from sound.effects import *会发生什么？理想情况下，人们会希望以某种方式进入文件系统，查找包中存在哪些子模块，然后将它们全部导入。这可能需要很长时间，并且导入子模块可能具有不希望的副作用，这些副作用在明确导入子模块时才会发生。 唯一的解决方案是软件包作者提供包的明确索引。import使用以下声明: 如果某个包的__init__.py定义了一个名为__all__的列表，则它将成为from package import *时应该导入的模块名称列表。当软件包新版本发布时，软件包作者需要保持该列表是最新版本。 栗子sound/effects/__init__.py: 12 #这意味着from sound.effects import *只会导入以下子模块__all__ = [&quot;echo&quot;, &quot;surround&quot;, &quot;reverse&quot;] 如果__all__没有被定义，则from sound.effcts import *语句不会将包sound.effects中所有子模块导入到当前命名空间。它只能确保包sound.effects被导入，然后导入包中定义的任何名称。这包括__init__.py定义的任何名称，还包括由以前的导入语句显示加载的软件包的任何子模块。 请记住，使用from packagee import submodule没有任何问题。事实上，这也是推荐的方法。除非导入模块需要使用不同包中具有相同名称的子模块。 内部包装Intra-package References 当包被构建为子包时，可以使用绝对导入来引用邻包中的模块。同样，也可以使用相对导入来导入邻包中的模块。 12345678 #Absolutefrom sound.effects import echo #Relativefrom . import echofrom .. import formatsfrom ..filter import equalizer 多个目录中的包Packages in Multiple Directories 包还支持一个特殊的属性__path__。在执行该文件中的代码之前，它被初始化为一个包含__init__.py的目录名称的列表。这个变量可以修改，这样做会影响将对包中包含的模块和子包的搜索。 虽然此功能通常不是必需的，但它可用于扩展包中找到的一组模块。 输入和输出Input and Output有多种方式来呈现程序的输出；数据也可以打印成人类可读的形式，或写入文件供将来使用。 幻想的输出格式Fancier Output Formatting 到目前为止，我们知晓两种写入值的方法: 表达式语句 print()函数 有两种方法可以格式化输出： 自己完成所有的字符串处理(使用切片和连接操作，你可创建任何你能想到的布局) 格式化字符串文字或str.format()方法 string模块提供了一个Template类，它提供了另一种将值替换为字符串的方法。Python有办法将任何值转换为字符串：将它传递给repr()或str()函数。 str()函数，用于返回相当可读(human-readable)的值的表示repr()函数，用于生成可由解释器读取的表示对于没有人定义的特定表示的对象，str()将返回与repr()相同的值 1234567891011121314for x in range(1, 6): print(repr(x).rjust(2), repr(x**2).rjust(3), end=' ') print(repr(x**3).rjust(4)) #Orfor x in range(1, 6): print('&#123;0:2d&#125; &#123;1:3d&#125; &#123;2:4d&#125;'.format(x, x**2, x**3)) 1 1 1 2 4 8 3 9 27 4 16 64 5 25 125 字符串对象的str.rjust()方法，它在给定宽度的字段中通过填充左边的空格来右对齐字符串。类似方法还有: str.ljust(), str.center()。这些方法不写入任何东西，它们只是返回一个新的字符串。 还有一种str.zfill()方法，它在数字字符串的左边填充数字0，它能识别加号和减号： 12345678&gt;&gt;&gt; '12'.zfill(5)'00012'&gt;&gt;&gt;&gt;&gt;&gt; '-3.14'.zfill(7)'-003.14'&gt;&gt;&gt;&gt;&gt;&gt; '3.1415678'.zfill(5)'3.1415678' str.format()方法: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152 #&#123;&#125;print('We are &#123;&#125; who say &#123;&#125; is "&#123;&#125;!".format('A', 'BB', 'WONDERFUL'))We are A who say BB is "WONDERFUL!" #括号中的数字用来指向传入的位置 #&#123;index&#125;,从0开始print('&#123;0&#125; and &#123;1&#125;'.format('A', 'BB'))A and BBprint('&#123;1&#125; and &#123;0&#125;'.format('A', 'BB'))BB and A #关键字参数print('My name is &#123;name&#125;, I\'m &#123;age&#125; years old!'.format(name='Zhang21', age=21))My name is Zhang21, I'm 21 years old! #位置参数和关键字参数的组合print('The story of &#123;0&#125;, &#123;1&#125;, and &#123;other&#125;'.format('A', 'BB', other='CCC'))The story of A, BB, and CCC'''!a, 应用ascii()!s, 应用str()!r, 应用repr():, 更好的控制格式:5:7d:.3f'''print('My full name is &#123;!s&#125;'.format('Zhang21'))My full name is Zhang21print('My full name is &#123;!r&#125;'.format('Zhang21'))My full name is 'Zhang21'print('The value of &#123;&#125; is approximately &#123;:.3f&#125;'.format('PI', 3.141567))The value of PI is approximately 3.142info = &#123;'A': 68, 'BB': 79, 'CCC': 89&#125;for k, v in info.items(): print('&#123;0:5&#125; ==&gt; &#123;1:6d&#125;'.format(k, v))A ==&gt; 68BB ==&gt; 79CCC ==&gt; 89print('A: &#123;A:d&#125;; B: &#123;BB:d&#125;, C: &#123;CCC:d&#125;'.format(**info))A: 68; B: 79, C: 89 %操作符同样可用于字符格式化: 12print('The value of %s is approximately %5.3f' % ('PI', 3.1415678))The value of PI is approximately 3.142 读写文件Reading and Writing Files open()返回一个文件对象，它最常用的两个参数：open(filename, mode) 12345678910f = open('/tmp/1.txt, 'r')f.readline()'1\n'f.closedFaslef.close()f.closedTrue mode: r: read only，未指定模式时的默认模式 w: only writing a: appending r+: reading and writing b: binary mode 通常情况下，文件以文本模式打开，这意味着你可读写文件中的字符串，并以特定编码方式进行编码(如UTF-8)。如果未指定编码，则默认值取决于平台。b以二进制模式打开文件，数据以字节对象的形式读写，该模式应该用于所有不包含文本的文件。在读写文件时要非常小心的使用二进制模式。 推荐使用with关键字处理文件对象，优点是，即使在某个时间点出现异常，文件在其套件结束后也能正常关闭。也比try-finally块短得多。如果没有使用with关键字，则你需要调用f.close()来关闭文件，并立即释放它使用的系统资源。如果你没有明确关闭一个文件，Python的垃圾回收器最终会摧毁这个对象并为你关闭吧这个打开的文件，但这个文件可能会保持打开一段时间。在关闭文件对象之后，尝试使用文件对象将会自动失败。 1234567891011with open('/tmp/1.txt') as f: read_Data = f.read()f.closedTruef.read()Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;ValueError: I/O operation on closed file. 文件对象方法Methods of File Objects f.read(size)读取文件内容，以字符串或字节对象的形式返回。size是一个可选的数值参数，当size被忽略或为负数时，文件的全部内容被读取并返回。如果超过内存限制，那就是你的问题了。f.readline()从文件读取一行，换行符Unix\n，Windows\r\nf.readlines(), list(f)读取文件的所有行f.write(string)向文件中写入字符内容，并返回写入的字符数f.tell()返回一个整数，表示二进制模式下文件开头的字节数f.seek(offset, from_what)改变文件对象的位置 1234567891011121314151617f = open('/tmp/1.txt', 'r+')f.write('Line4\n')6string = ('AAA', 11)s = str(string)f.write(s)11f = open('/tmp/1.txt', 'rb+')f.write(b'0123456789abcde')f.seek(1)1f.read(1)b'1' 使用json保存结构化数据Saving structured data with json 字符串可以很容易地读写文件和从文件读取。当你想要保存更复杂的数据类型——如嵌套列表和字典，手动解析和序列化将变得很复杂。 JSON格式通常被现代应用程序用于数据交换。Python允许你使用名为JSON的流行数据交换格式。称为json的标准模块可采用Python数据层次结构，并将其转换为字符串表示形式，这个过程被称为序列化(serializing)。重建字符串表示中的数据称为反序列化(deserializing)。 123456import jsonjson.dumps([1, 'simple', 'list'])'[1, "simple", "list"]'json.dump(x, f)x = json.load(f) 错误和异常Errors and Exceptions 至少有两种可区分的错误: syntax errors exceptions 语法错误Syntax Errors语法错误，也称为解析错误。这是最常见的语法问题错误。 异常Exceptions即使语法是正确的，但在执行时也可能导致错误。执行过程中检查到的错误称为异常。Built-in Exceptions列出了内置的异常及其含义。 1234567891011121314 &gt;&gt;&gt; 10 * (1/0)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;ZeroDivisionError: division by zero &gt;&gt;&gt; 4 + spam*3Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;NameError: name 'spam' is not defined &gt;&gt;&gt; '2' + 2Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: Can't convert 'int' object to str implicitly 处理异常Handling Exceptions编写处理选定异常的程序是可能的。 1234567891011while True: try: x = int(input("Please enter a number: ")) break except ValueError: print("Oops! That was no valid number. Try again...") #多个异常放入一个元组except (RuntimeError, TypeError, NameError): pass try语句工作原理： 首先，try子句(try...except之间的语句)被执行 如果没有异常发生，则执行try语句并跳过except子句后便结束 如果在执行try子句时发生异常，则跳过子句的其余部分。然后，如果异常类型匹配execpt后面的异常名称，则except子句被执行，然后在try语句后继续执行 如果产生的异常与except的异常名称不匹配，它将传递给外部try语句。如果没有找到处理程序，则它是一个未处理的异常，执行停止并显示错误消息 try语句可能有多个except子句，用于处理不同的异常。最多只有一个处理程序被执行 处理程序只处理发生在相应try子句中的异常，而不处理相同try语句的其它处理程序 except子句可将多个异常名放入一个元组 如果是相同的类或其基类，则except子句中的类与异常兼容 未使用异常名称的except子句作为通配符 请谨慎使用此功能，因为以这种方式很容易掩盖真正的编程错误 try...except语句还有一个可选的else子句。当存在时，它必须遵循所有except子句。如果try子句不引发异常，则必须执行该代码 12345678910111213import systry: f = open('/tmp/1.txt') s = f.readline() i = int(s.strip())except OSError as err: print('OS error: &#123;&#125;'.format(err))except ValueError: print("Could not convert data to an integer.")except: print("Unexpected erros", sys.exc_info()[0]) raise 123456try: sum = 'a' + 1except TypeError: print('TypeError')else: print('else: ', sum) 引发异常Raising Exceptions raise语句允许程序员强制执行指定的异常。 1234567891011121314151617&gt;&gt;&gt; raise NameError('HiThere')Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;NameError: HiThere&gt;&gt;&gt; try:... raise NameError('HiThere')... except NameError:... print('An exception flew by!')... raise...An exception flew by!Traceback (most recent call last): File "&lt;stdin&gt;", line 2, in &lt;module&gt;NameError: HiThere 用户定义的异常User-defined Exceptions 程序可以通过创建一个新的异常类(exception class)来为自己的异常命名。异常通常应该直接或间接地从 Exception class 派生。 可以定义异常类，它可以执行任何其它类可以执行的任何操作，但通常很简单，通常只提供一些属性，以便处理程序为异常提取有关错误的信息。创建可引发多个不同错误的模块时，通常的做法是为该模块定义的异常创建基类，并创建用于为不同错误条件创建特定异常类的子类: 123456789101112131415161718192021222324252627282930class Error(Exception): """Base class for exceptions in this module.""" passclass InputError(Error): """Exception raised for errors in the input. Attributes: expression -- input expression in which the error occurred message -- explanation of the error """ def __init__(self, expression, message): self.expression = expression self.message = messageclass TransitionError(Error): """Raised when an operation attempts a state transition that's not allowed. Attributes: previous -- state at beginning of transition next -- attempted new state message -- explanation of why the specific transition is not allowed """ def __init__(self, previous, next, message): self.previous = previous self.next = next self.message = message 大多数异常的名称都以Error结尾来定义，类似于标准异常的命名。许多标准模块定义了它们自己的异常，用于在其定义的功能中可能发生的错误。 定义清理行为Defining Clean-up Actions try语句还有一个可选的子句，用于定义在任何情况下都必须执行的清理操作(clean-up actions). finally子句总是在离开try语句之前执行，无论是否发生异常。 123456789&gt;&gt;&gt; try:... raise KeyboardInterrupt... finally:... print('Goodbye, world!')...Goodbye, world!KeyboardInterruptTraceback (most recent call last): File "&lt;stdin&gt;", line 2, in &lt;module&gt; 预定义的清理操作Predefined Clean-up Actions 某些对象定义了在不再需要对象是要执行的标准清楚操作，而不管使用对象的操作是成功还是失败。 123with open("myfile.txt") as f: for line in f: print(line, end="") 类Classes 类提供了将数据和功能捆绑在一起的手段。每个类实例都可附加属性以保持其状态。类实例也可以有方法来修改其状态。 与其它编程语言相比，Python的类机制为其添加了最少量的新语法和语义。Python类 提供了面向对象编程的所有标准功能: 类继承机制(inheritance mechanism)允许多个基类(base class)，派生类(derived class)可以重写其基类或类的任何方法，并且方法(method)可以调用具有相同名称的基类的方法。对象(object)可以包含任意数量和种类的数据。与模块一样，类也具有Python的动态特性: 它们是在运行时创建的，并且可以在创建后进一步修改。 关于名称和对象A Word About Names and Objects Objects have individuality, 并且可以将多个名称(在多作用域中)绑定到同一个对象。这在其它语言中被称为别名。别名在不可变类型中被安全地忽略。但对涉及可变对象(dict, list…)的Python代码的语义可能会有惊人的影响。这通常有利于程序，因为别名在某些方面表现得像指针。 作用域和命名空间Python Scopes and Namespaces 类定义在命名空间中扮演一些巧妙的技巧，并且你需要知道作用域和命名空间如何工作才能完全理解正在发生的事情。顺便一提，有关此主题的知识对于任何高级Python程序员都很有用。 让我们从一些定义开始: 命名空间是名称到对象的映射。大多数命名空间目前都是作为Python字典实现的，但通常不会以任何方式显示。命名空间的例子： 内建名称的集合；模块中的全局名称；函数调用中的本地名称。从某种意义上说，对象的一组属性也构成一个命名空间。了解命名空间的重要之处在于，不同命名空间中的名称之间没有绝对的关系。 顺便一提，使用单词属性来表示任意一个点.后面的名称——z.real，real是对象z的属性。严格地说，对模块中的名称引用是属性引用——modname.funcname，modname是一个模块对象，并且funcname是它的一个属性。在这种情况下，模块的属性和模块中定义的全局名称之间会有一个直接的映射关系: 它们共享相同的命名空间。 属性可以是只读或可写。 命名空间是在不同的时刻创建的，并且具有不同的生命周期。包含内建名称的命名空间是在Python解释器启动时创建的，并且永远不会被删除。读取模块定义时创建模块的全局命名空间，通常，模块命名空间也会持续到解释器退出。由解释器的顶层调用执行的语句，无论是从脚本文件读取还是交互式读取，都被视为名为__main__模块的一部分，因此它们具有其自己的全局命名空间。 函数的本地命名空间是在调用函数时创建，并在函数返回时删除或引发(raise)不在函数内处理的异常。当然，递归调用每个都有自己的本地命名空间。 作用域(scope)是Python程序的文本区域，可以直接访问命名空间(namespace)。这意味着对名称的非限定引用(unqualified reference)会尝试在命名空间中查找名称。 尽管作用域是静态确定的，但它们是动态使用的。在执行期间的任何时候，至少有三个作用域的命名空间都可以直接访问: 最先搜索的最内层作用域，包含本地名称 从最近封闭作用域开始搜索的任何封闭函数的作用域，包含非本地名称，也包含非全局名称 倒数第二个作用域包含当前模块的全局名称 最外层的作用域是包含内建名称的命名空间 如果某个名称被声明为全局(global)，则所有的引用(reference)和赋值(assignment)都将直接转到包含模块全局名称的中间作用域。要重新绑定(rebind)最内层作用域外发现的变量，可以使用nonlocal语句；如果没有声明nonlocal，那些变量是只读的。 通常，本地作用域引用当前函数的本地名称。在外部函数中，本地作用域引用与全局作用域相同的命名空间:模块的命名空间。类定义在本地作用域中放置另一个命名空间。 认识到作用域是以文本方式确定是很重要的: 模块中定义的函数的全局作用域是该模块的命名空间，无论从何处调用函数或调用函数的别名。另一方面，名称的实际搜索是在运行时动态完成的——但是，在编译时间，语言定义正在向静态名称解析发展，因此不要依赖动态名称解析。 Python的特殊之处在于——如果global语句没有生效，对名称的赋值总是进入最内层的范围。赋值不会分配数据——它们只是将名称绑定到对象。删除操作也是如此: 语句del x从本地作用域引用的命名空间中删除x的绑定。实际上，所有引用新名称的操作都是用本地作用域: 特别是，import语句和函数定义将模块或函数名称绑定到本地作用域。 global声明可以用来表明特定变量存在于全局作用域内，应该在此rebound(反弹)。nonlocal声明表明特定变量存在于封闭作用域内，应该在那里rebound. 作用域和命名空间的栗子 123456789101112131415161718192021222324252627282930313233def scope_test(): def do_local(): spam = "local spam" def do_nonlocal(): nonlocal spam spam = "nonlocal spam" def do_global(): global spam spam = "global spam" spam = "test spam" do_local() print("After local assignment: ", spam) do_nonlocal() print("After nonlocal assignment: ", spam) do_global() print("After global assignment: ", spam)scope_test()print("In global scope: ", spam)#输出After local assignment: test spamAfter nonlocal assignment: nonlocal spamAfter global assignment: nonlocal spamIn global scope: global spam 首先看类A first look at class 类引入了一些新的语法，三种新的对象类型和一些新的语义。 类定义语法Class Definition Syntax 类定义，像函数定义，必须在它们有效之前被执行。 123456class ClassName: &lt;statement-1&gt; . . . &lt;statement-N&gt; 实际上，类定义中的语句通常是函数定义，但其他语句是允许的，有时也是有用的。类中的函数定义通常有一个特殊形式的参数列表，由方法的调用约定决定。 当输入一个类定义时，会创建一个新的命名空间，并将其用作本地作用域——因此，所有对局部变量的赋值都会进入这个新的命名空间。特别是，函数定义在此绑定新函数的名称。 当类定义保持正常时，会创建一个类对象。这基本上是由类定义创建的命名空间的内容的一个包装。最初的本地作用域被恢复，并且类对象在这里被绑定到类定义头中给出的类名。 类对象Class Objects 类对象支持两种操作: 属性引用(attribute reference)和实例化(instantiation). 属性引用使用 用于Python中所有属性引用的标准语法: obj.name. 有效的属性名称在创建类对象时时位于类命名空间中的所有名称。 123456class MyClass: """A simple example class""" i = 12345 def f(self): return 'hello world' MyClass.i和MyClass.f是有效的属性引用，分别返回一个整数和函数对象。类属性也可以被分配，所以也可以通过赋值来改变MyClass.i的值。__doc__也是一个有效的属性，返回该类的文档字符串”A simple example class”. 类实例化使用函数表示法。假设类对象是一个返回类的新实例的无参数函数。 12#创建类的新实例，并将该对象分配给局部变量xx = MyClass() 实例化操作(“调用”一个类对象)创建一个空对象。许多类喜欢创建具有定制(customized)到特定初始状态(initial state)的实例对象。因此，类可以定义一个名为__init__()的特殊方法。 12def __init__(self): self.data = [] 当一个类定义了一个__init__()方法时，类实例化会自动为新创建的类实例调用__init__(). 当然，__init__()方法可能有更多灵活的参数。在这种情况下，给类实例化操作符的参数被传递给__init__(). 123456789class Complex: def __init__(self, realpart, imagpart): self.r = realpart self.i = imagpartx = Complex(3.0, -4.5)x.r, x.i3.0, -4.5 实例对象Instance Objects 实例对象理解的唯一操作是属性引用。有两种有效的属性名称，数据属性和方法。 数据属性不需要声明，像局部变量一样，当它们在第一次分配时就会弹出。另一种实力属性引用是一种方法。方法是属于对象的函数。 实例对象的有效方法名称取决于它的类。根据定义，作为函数对象的类的所有属性都定义其实例的相应方法。 方法对象Method Objects 关于方法的特殊之处在于 实例对象作为函数的第一个参数传递。一般来说，调用带有n个参数列表的方法相当于使用通过在第一个参数之前插入方法实例对象创建的参数列表来调用相应的函数。 当引用不是数据属性的实例属性时，将搜索类。如果名称表示一个有效的类属性，它是一个函数对象，则通过打包实例对象和在抽象对象中一起找到的函数对象来创建方法对象，这就是方法对象。当使用参数列表调用方法对象时，会从实例对象和参数列表构造一个新参数列表，并使用此新参数列表调用函数对象。 类变量和实例变量Class and Instance Variables 一般来说，实例变量是针对每个实例唯一的数据，而类变量是针对类的所有实例共享的属性和方法。 1234567891011121314151617class Dog: kind = 'canine' # class variable shared by all instances def __init__(self, name): self.name = name # instance variable unique to each instance&gt;&gt;&gt; d = Dog('Fido')&gt;&gt;&gt; e = Dog('Buddy')&gt;&gt;&gt; d.kind # shared by all dogs'canine'&gt;&gt;&gt; e.kind # shared by all dogs'canine'&gt;&gt;&gt; d.name # unique to d'Fido'&gt;&gt;&gt; e.name # unique to e'Buddy' 共享数据可能会带来令人惊讶的影响，涉及列表和字典等可变对象: 1234567891011121314151617class Dog: tricks = [] # mistaken use of a class variable def __init__(self, name): self.name = name def add_trick(self, trick): self.tricks.append(trick)&gt;&gt;&gt; d = Dog('Fido')&gt;&gt;&gt; e = Dog('Buddy')&gt;&gt;&gt; d.add_trick('roll over')&gt;&gt;&gt; e.add_trick('play dead')&gt;&gt;&gt; d.tricks # unexpectedly shared by all dogs['roll over', 'play dead'] 正确的类设计应该使用实例变量: 1234567891011121314151617class Dog: def __init__(self, name): self.name = name self.tricks = [] # creates a new empty list for each dog def add_trick(self, trick): self.tricks.append(trick)&gt;&gt;&gt; d = Dog('Fido')&gt;&gt;&gt; e = Dog('Buddy')&gt;&gt;&gt; d.add_trick('roll over')&gt;&gt;&gt; e.add_trick('play dead')&gt;&gt;&gt; d.tricks['roll over']&gt;&gt;&gt; e.tricks['play dead'] 随机备注Random Remarks 数据属性覆盖具有相同名称的方法属性；为了避免意外的名称冲突，这可能会在大型程序中导致难以发现的错误，使用某种最小化冲突几率的约定是明智的。可能的约定(convention)包括: 大写的方法名称，小唯一字符串(可能只是下划线)为数据属性名称加前缀，或者为方法和名词使用动词来表示数据属性。 数据属性可由方法及对象的普通用户引用。换句话说，累不可用于实现纯粹的抽象数据类型。事实上，Python中没有任何东西可以强制执行数据隐藏——它都基于约定。 客户端应该小心使用数据属性。请注意，客户端可以将自己的数据属性添加到实例对象，而不会影响方法的有效性，只要避免名称冲突——再次注意，命名约定可在此节省大量令人头痛的问题。 从方法中引用数据类型没有简写，这增加了方法的可读性: 在浏览方法时，不会混淆局部变量和实例变量。 通常，方法的第一个参数称为self。这只不过是一个约定: 名字self对Python来说绝对没有特殊含义。但是，请注意，不遵循约定的Python代码对于Python程序员来说可能不易读取。 任何作为类属性的函数对象都为该类的实例定义了一个方法 1234567891011121314# Function defined outside the classdef f1(self, x, y): return min(x, x+y)class C: f = f1 def g(self): return 'hello world' h = g#f, g, h都是类C的所有属性，它们都是指向函数对象的，因此它们都是C实例的所有方法。 方法可以通过使用self参数的方法属性来调用其它方法: 12345678910class Bag: def __init__(self): self.data = [] def add(self, x): self.data.append(x) def addtwice(self, x): self.add(x) self.add(x) 方法可以像普通函数一样引用全局名称。与方法关联的全局作用域是包含其定义的模块。(一个类永远不会被用作全局作用域) 虽然很少有人在方法中使用全局数据，但全局作用域有许多合法用途: 首先，导入全局作用域的函数和模块可以被方法使用，以及在其中定义的函数和类。通常，包含该方法的类本身是在全局作用域内定义的。 每个值都是一个对象，因此有一个类(类型)。它被存储为object.__class__ 继承Inheritance 当然，如果不支持继承，语言特性就不值得称为”类”。 1234567#派生(derived)class DerivedClassName(BaseClassName): &lt;statement-1&gt; . . . &lt;statement-N&gt; 基类(BaseClassName)必须在包含派生类(derived class)定义的作用域中定义。代替基类名称，其它表达式也是允许的。 12#当基类在另一个模块中被定义class DerivedClassName(modname.BaseClassName): 派生类(derived class)定义的执行过程与基类(base class)相同。当构造(constructed)类对象时，基类将被记住。这用于解析属性引用: 如果在类中未找到请求的属性，则搜索继续查找基类。如果基类本身是从其它类派生的，则此规则将递归应用。 派生类的实例化么有什么特别的: DerivedXlassName()创建一个新的类实例。方法解析如下: 如果需要，搜索相应的类属性，沿着基类链降序排列，如果产生函数对象，则方法引用是有效的。 派生类可以覆盖(override)基类的方法。由于方法在调用同一对象的其它方法时没有特殊的权限，因此调用另一个在同一基类中定义的方法的基类方法可能最终会调用派生类的方法来覆盖它。 派生类的覆盖(override)方法事实上可能需要扩展而不是简单地替换同名的基类方法。有一种简单的方法可以直接调用基类方法: 只需调用BaseClassName.methodname(self, arguments)即可。 Python有两个与继承有关的内建函数: isinstance()检查一个实例的类型。isinstance(obj, int)只有在obj.__class__是int或从int派生的某个类时才为true issubclass()检查类继承。 多重继承Multiple Inheritance Python支持多重继承的形式。 123456class DerivedClassName(Base1, Base2, Base3): &lt;statement-1&gt; . . . &lt;statement-N&gt; 在最简单的情况下，你可以将从父类继承的属性视为深度优先(depth first)，从左到右搜索，而不是在同一个类中进行两次搜索，其中层次结构中存在重叠。因此，如果在DerivedClassName中找不到属性，则在Base1中搜索该属性，然后(递归)在Base1的基类中搜索该属性。如果未找到，则在Base2中搜索该属性，依此类推。 动态排序是必要的，因为多重继承的情况都表现出一个或多个菱形关系。例如，所有类都从对象继承，所以任何多重继承的情况都会提供多条路径来达到对象。为了避免基类被多次访问，动态算法使搜索顺序线性化，以保留没各类众指定的从左到右的顺序，每个父类只调用一次，这是单调的。 私有变量Private Variables Python中不存在私有(private)实例变量，这些变量除了在对象内部以外不能访问。不过，大多数Python代码都有一个约定，以下划线_spam为前缀的名称应被视为API的非公共部分(无论是函数，方法或数据成员)。 由于私有类(class-private)成员有一个有效的用例(即为了避免名称与由子类定义的名称的冲突)，所以对这种称为name mangling的机制的支持有限。任何__spam形式的标识符在文本上用_classname__spam替换，其中classname是当前类名称，前导下划线被去除。只要它在类的定义类发生，就不会考虑标识符位置。 Name mangling 有助于让子类重写方法而不会破坏intraclass方法调用: 123456789101112131415161718class Mapping: def __init__(self, iterable): self.items_list = [] self.__update(iterable) def update(self, iterable): for item in iterable: self.items_list.append(item) __update = update # private copy of original update() methodclass MappingSubclass(Mapping): def update(self, keys, values): # provides new signature for update() # but does not break __init__() for item in zip(keys, values): self.items_list.append(item) 请注意，强化规则的设计主要是为了避免事故；它仍然可以访问或修改被认为是私有的变量。注意传递给exec()或eval()的代码并不认为调用类的类名是当前类；这与global语句的效果类似，其效果同样局限于一起进行字节编译的代码。getattr(), setattr()和delattr()以及直接使用__dict__时也有相同的限制。 Odds and Ends123456789class Employee: passjohn = Employee() # Create an empty employee record# Fill the fields of the recordjohn.name = 'John Doe'john.dept = 'computer lab'john.salary = 1000 一段期望特定抽象数据类型的Python代码通常通常可以传递一个模拟该数据类型方法的类。例如，如果你有一个函数可以格式化文件对象中的某些数据，则可以使用方法read()和readline()来定义一个类，以便从字符串缓冲区总获取数据，然后将其作为参数传递。 迭代器Iterators 你可能注意到大多数容器对象可以使用for语句循环遍历: 12345678910for element in [1, 2, 3]: print(element)for element in (1, 2, 3): print(element)for key in &#123;'one':1, 'two':2&#125;: print(key)for char in "123": print(char)for line in open("myfile.txt"): print(line, end='') 这种访问方式清晰，简洁，方便。迭代器的使用贯穿并统一了Python。for语句在容器对象上调用iter()。该函数返回一个迭代器对象，该对象定义一次访问容器中元素的方法__next__()。当没有更多元素是，__next__()引发一个StopIteration异常，它告诉for循环终止。你可使用next()内置函数调用__next__()方法: 123456789101112131415&gt;&gt;&gt; s = 'abc'&gt;&gt;&gt; it = iter(s)&gt;&gt;&gt; it&lt;iterator object at 0x00A1DB50&gt;&gt;&gt;&gt; next(it)'a'&gt;&gt;&gt; next(it)'b'&gt;&gt;&gt; next(it)'c'&gt;&gt;&gt; next(it)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; next(it)StopIteration 看到了迭代器协议背后的机制，很容易将迭代器行为添加到类中。定义一个__iter__()方法，该方法使用__next__()方法返回一个对象。 1234567891011121314class Reverse: """Iterator for looping over a sequence backwards.""" def __init__(self, data): self.data = data self.index = len(data) def __iter__(self): return self def __next__(self): if self.index == 0: raise StopIteration self.index = self.index - 1 return self.data[self.index] 12345678910&gt;&gt;&gt; rev = Reverse('spam')&gt;&gt;&gt; iter(rev)&lt;__main__.Reverse object at 0x00A1DB50&gt;&gt;&gt;&gt; for char in rev:... print(char)...maps 生成器Generators 生成器是创建迭代器的简单而强大的工具。它们像常规函数一样编写，但只要它们想返回数据就是用yield语句。每次next()被调用时，生成器都会从停止的地方恢复(它记住所有的数据值以上次执行的代码)。 123456789101112def reverse(data): for index in range(len(data)-1, -1, -1): yield data[index]&gt;&gt;&gt; for char in reverse('golf'):... print(char)...flog 任何可用生成器完成的事情也可用前面的基于类的迭代器完成。使生成器如此紧凑的原因是__iter__()和__next__()方法时自动创建的。 另一个关键特性是本地变量和执行状态在调用之间自动保存。这使得该函数更容易编写，并且比使用self.index和self.data等实例变量的方法更加清晰。除了自动方法创建和保存程序状态之外，当生成器终止时，它们会自动产生StopIteration。结合起来，这些功能可以轻松创建迭代器，而无需编写常规函数。 生成器表达式Generator Expressions 一些简单的生成器可以使用与列表解析类似的语法简洁地编码为表达式，带括号而不是方括号。这些表达式适用于通过封闭函数立即使用生成器的情况。生成器表达式比完整的生成器定义更紧凑但功能更少，并且倾向于比等效的列表解析更具有内存友好性。 123456789101112131415161718&gt;&gt;&gt; sum(i*i for i in range(10)) # sum of squares285&gt;&gt;&gt; xvec = [10, 20, 30]&gt;&gt;&gt; yvec = [7, 5, 3]&gt;&gt;&gt; sum(x*y for x,y in zip(xvec, yvec)) # dot product260&gt;&gt;&gt; from math import pi, sin&gt;&gt;&gt; sine_table = &#123;x: sin(x*pi/180) for x in range(0, 91)&#125;&gt;&gt;&gt; unique_words = set(word for line in page for word in line.split())&gt;&gt;&gt; valedictorian = max((student.gpa, student.name) for student in graduates)&gt;&gt;&gt; data = 'golf'&gt;&gt;&gt; list(data[i] for i in range(len(data)-1, -1, -1))['f', 'l', 'o', 'g'] 虚拟环境Virtual Environments and Packages 应用程序有时候需要特定的模块版本，或者某个模块只支持特定Python版本。这就意味着一个Python安装版本可能无法满足每个应用程序的要求。(如某个应用程序支持Python2.7，而某个应用程序支持Python3.x) 此问题的解决方案是创建一个虚拟环境(virtual environment)——一个包含特定Python安装包和软件包的目录树。这样，不同的应用程序就可以使用不同的虚拟环境。 创建虚拟环境Creating Virtual Environments 用于创建和管理虚拟环境额模块称为venv.它通常会为你安装最新版本的Python，你也可以选择Python版本。 激活虚拟环境后，会改变提示符并修改环境，以便提供特定的Python版本。 123456789101112131415#创建虚拟环境python3 -m venv /tmp/pythonVenv#激活source /tmp/pythonVenv/bin/activate(pythonVenv) [zhang@zhang21 ~]$(pythonVenv) [zhang@zhang21 ~]$ python&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.path[&apos;&apos;, &apos;/usr/lib64/python34.zip&apos;, &apos;/usr/lib64/python3.4&apos;, &apos;/usr/lib64/python3.4/plat-linux&apos;, &apos;/usr/lib64/python3.4/lib-dynload&apos;, &apos;/tmp/pythonVenv/lib64/python3.4/site-packages&apos;, &apos;/tmp/pythonVenv/lib/python3.4/site-packages&apos;]#退出deactivate pip包管理你可以使用pip程序进行搜索、安装、升级和移除软件包。pip程序默认从安装软件包。 pip freeze 以requirements的格式输出已安装软件包。这很重要。 12345678910111213141516171819202122pip search sh#默认安装最新版本pip install sh#安装指定版本pip install sh=1.10.2pip install --upgrade shpip uninstall sh#显示已安装的模块的详细信息pip show sh#列出已安装模块pip listpip freeze &gt; requirements.txt#安装依赖pip install -r ./requirements.txt 下划线参考: https://shahriar.svbtle.com/underscores-in-python https://segmentfault.com/a/1190000002611411 https://zhuanlan.zhihu.com/p/36173202 本节讨论Python中下划线(_)的使用，它的大部分用法都是一种惯例约定。 模式 栗子 含义 单下划线前缀 _var 命名约定，仅供内部使用。通常不会有Python解释器强制执行，只作为对程序员的提示 单下划线后缀 var_ 按约定使用以避免与Python关键字的命名冲突 双下划线前缀 __var 当在类上下文中使用时，触发名称修饰 双下划线前后缀 __var__ 表示Python语言定义的特殊方法 单个下划线 _ 三个情况 单个下划线单下划线(_)主要有三种情况: 解释器中下划线(_)符号指交互式解释器中最后一次执行语句的返回结果。 12345678910&gt;&gt;&gt; _Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;NameError: name &apos;_&apos; is not defined&gt;&gt;&gt;&gt;&gt;&gt; 111111&gt;&gt;&gt;&gt;&gt;&gt; _111 作为名称使用下划线(_)用作被丢弃的名称。这样可以让阅读你代码的人知道，这是个不会被使用的特定名称。 国际化下划线(_)用作函数名。这种情况下，单下划线经常被用作国际化和本地化字符串翻译查询的函数名。在Django中，你可能会看到: 123456from django.utils.translation import ugettext as _from django.http import HttpResponsedef my_view(request): output = _("Welcome to my site.") return HttpResponse(output) 单下划线前缀的名称以单下划线做前缀的名称(如_shahriar)，指定了这个名称是私有的。在有些import *的场景中，下一个使用你代码的人会明白这个名称仅供内部使用。下划线前缀的含义是告知其他程序员：以单个下划线开头的变量或方法仅供内部使用。 该约定在PEP 8中有定义。 如果你写了from module import *，那么以单下划线开头的名称都不会被导入，除非模块或包中的__all__列表显式地包含了它们。 单下划线后缀的名称以单下划线后缀的名称(如var_)，有时，一个变量的最合适的名称已被一个关键字所占用。在这种情况下，你可以附加一个下划线来解决命名冲突。 12345&gt;&gt;&gt; def make_object(name, class):SyntaxError: &quot;invalid syntax&quot;&gt;&gt;&gt; def make_object(name, class_):... pass 双下划线前缀的名称以双下划线做前缀的名称(如__shahriar)，它对解释器有特定含义。Python中的这种用法是为了避免与子类定义的名称冲突。 前后都有双下划线的名称前后都有双下划线的名称(如__init__)，是Python的特殊方法名，这是一种惯例，一种确保Python系统中的名称不会跟用户自定义的名称发生冲突的方式。 语言参考The Python Language Reference Python参考手册描述了Python语言的语法(syntax)和核心语义(core semantics)。 介绍Introduction 此参考手册描述了Python编程语言，它并不是一个教程。如果你正在使用Python并且想知道关于改语言的特定区域的精确规则是什么，那么你绝对应该能够在这里找到它们。 词法分析Lexical analysis 解析器(parser)读取Python程序。解析器的输入是由词法分析器生成的令牌流(stream of tokens)。本章描述了词法解析器如何将文件分解为令牌。 Python将程序文本读作Unicode code point，源文件的编码可以通过编码声明给出，默认为UTF-8，具体请参阅PEP 320。如果源文件无法被编码，则抛出语法错误。 行结构Line structure Python程序分为许多逻辑行。 逻辑行Logical lines 逻辑行的结尾由token NEWLINE表示。语句不能跨过逻辑行边界，除非语法允许NEWLINE。通过遵循显式或隐式的行连接规则，从一个或多个物理行构造逻辑行。 物理行Physical lines 物理行是由行尾序列终止的字符序列。在源文件和字符串中，可使用任何标准平台的行终止序列。Unix格式使用ASCII的LF，Windows格式使用ASCII的CR LF，或使用旧的Macintosh格式ASCII CR字符。无论平台如何，所有这些格式都可以平等使用。输入的结尾也充当最终物理行的隐式终止符。嵌入Python时，应使用标准C约定的换行符将源代码字符传递给Python API。 注释Comments 注释以哈希字符(#)开头，以物理行的末尾结束。注释表示逻辑行的结束，除非调用隐式行连接规则。语法会直接忽略注释。 编码声明Encoding declarations 如果Python脚本中的第一行或第二行中的注释与正则表达式coding[=:]\s*([-\w.]+)相匹配，则此注释将作为编码声明处理。编码声明必须出现在它自己的一行上。若果是第二行，则第一行也必须是仅注释行。编码表达式的推荐格式: 1# -*- coding: &lt;encoding-name&gt; -*- 如果未发现编码声明，默认编码为UTF-8。如果声明了编码，则必须有Python识别编码名称。编码用于所有词法分析，包括字符串文字，注释和标识符。 显式行连接Explicit line joining 可使用反斜杠(\)将两个或多个物理行连接到逻辑行中。 1234if 1900 &lt; year &lt; 2100 and 1 &lt;= month &lt;= 12 \ and 1 &lt;= day &lt;= 31 and 0 &lt;= hour &lt; 24 \ and 0 &lt;= minute &lt; 60 and 0 &lt;= secod &lt; 60: #Look like a valid date return 1 以反斜杠结尾的行不能编写注释。反斜杠在字符串文字外的一行上的其他位置是非法的。 隐式行连接Implicit line joining 括号，方括号，花括号中的表达式可以在不使用反斜杠的情况下分割为多个物理行。 1234month_names = ['January', ‘February', 'March', #comments 'April', 'May', 'June', #comments 'July', 'Auguest', 'September', #comments 'October, 'November', 'December'] 隐式的连续行可以带有注释，连续行的缩进并不重要。允许空白的连续行。 空白行Blank lines 包含空格，制表符，换页符，注释的逻辑行会被忽略。在标准的交互式解释器中，完全空白的逻辑行终止多行语句。 缩进Indentation 逻辑行开头的前导空白(空格和制表符)用于计算行的缩进级别，而后者又用于语句的分组。 tabs被1-8个空格替换(从左到右)，使得包括被替换的字节数总是八的倍数。第一个非空白字符前面的空格总数确定行的缩进。缩进不能够使用反斜杠在多个物理行上分隔。如果源文件以一种方式混合制表符(tab)和空格，使得含义取决于空格中制表符的价值，则缩进被拒绝为不一致。会抛出TabError异常。 跨平台兼容性说明： 由于non_Unix平台上文本编辑器的性质，在源文件中使用制表符和空格的混合来缩进是不明智的。还应注意，不同平台可以明确地限制最大缩进级别。 标识符和关键字Identifiers and keywords 标识符也称为名称，标识符的长度不受限制。Python中标识符的语法基于Unicode标准附件UAX-31，详情请参考PEP 3131在ASCII范围内(U+0001...U+007F)，有效的字符与Python2相同。大小写字母A-z，除第一个字符外的下划线(_)，数字0-9。Python3引入了ASCII范围外的其它字符，对于这些字符，分类使用unicodedata模块中包含的Unicode Character Database的版本。 Unicode类别代码表示： Lu： uppercase letters Ll： lowercase letters Lt： titlecase letters Lm： modifier letters Lo： other letters Nl： letter numbers Mn： nonspacing marks Mc： spacing combining marks Nd： decimal numbers Pc： connector punctuations Other_ID_Start： explicit list of characters in PropList.txt to support backwards compatibility Other_ID_Continue： likewise 关键字Keywords 以下标识符用作保留字或关键字，不能用作普通标识符。 123456789help(keywords)False class finally is returnNone continue for lambda tryTrue def from nonlocal whileand del global not withas elif if or yieldassert else import passbreak except in raise 保留的类标识符Reserved classes of identifiers 某些类标识符(除了关键字)具有特殊含义。这些类由前导/后置下划线(_)字符标识： _*特殊标识符_，用于交互式解释器中存储上次评估的结果，它保存在内建模块中。当不处于交互式模式时，下划线_没有特殊含义，也没有定义。名称_通常与国际化一起使用，这是一种约定。 __*__系统定义的名称。这些名称由解释器及其实现(包括标准库)来定义。在任何情况下，任何使用__*__名称都不会明确记录，在没有任何警告的情况下会受到破坏。 __*私有类(class-private)名称。在类定义的上下文中使用中使用此目录中的名称，名称将被重写，以使用损坏的格式来帮助避免基类和派生类(base and derived class)的私有属性之间的名称冲突。 文字值Literals 文字值是一些内建类型的常量值的符号。 字符串和字节文字值String and Bytes literals 字符串文字值和字节文字值描述： 12345678910111213141516171819202122stringliteral ::= [stringprefix](shortstring | longstring)stringprefix ::= &quot;r&quot; | &quot;u&quot; | &quot;R&quot; | &quot;U&quot; | &quot;f&quot; | &quot;F&quot; | &quot;fr&quot; | &quot;Fr&quot; | &quot;fR&quot; | &quot;FR&quot; | &quot;rf&quot; | &quot;rF&quot; | &quot;Rf&quot; | &quot;RF&quot;shortstring ::= &quot;&apos;&quot; shortstringitem* &quot;&apos;&quot; | &apos;&quot;&apos; shortstringitem* &apos;&quot;&apos;longstring ::= &quot;&apos;&apos;&apos;&quot; longstringitem* &quot;&apos;&apos;&apos;&quot; | &apos;&quot;&quot;&quot;&apos; longstringitem* &apos;&quot;&quot;&quot;&apos;shortstringitem ::= shortstringchar | stringescapeseqlongstringitem ::= longstringchar | stringescapeseqshortstringchar ::= &lt;any source character except &quot;\&quot; or newline or the quote&gt;longstringchar ::= &lt;any source character except &quot;\&quot;&gt;stringescapeseq ::= &quot;\&quot; &lt;any source character&gt;bytesliteral ::= bytesprefix(shortbytes | longbytes)bytesprefix ::= &quot;b&quot; | &quot;B&quot; | &quot;br&quot; | &quot;Br&quot; | &quot;bR&quot; | &quot;BR&quot; | &quot;rb&quot; | &quot;rB&quot; | &quot;Rb&quot; | &quot;RB&quot;shortbytes ::= &quot;&apos;&quot; shortbytesitem* &quot;&apos;&quot; | &apos;&quot;&apos; shortbytesitem* &apos;&quot;&apos;longbytes ::= &quot;&apos;&apos;&apos;&quot; longbytesitem* &quot;&apos;&apos;&apos;&quot; | &apos;&quot;&quot;&quot;&apos; longbytesitem* &apos;&quot;&quot;&quot;&apos;shortbytesitem ::= shortbyteschar | bytesescapeseqlongbytesitem ::= longbyteschar | bytesescapeseqshortbyteschar ::= &lt;any ASCII character except &quot;\&quot; or newline or the quote&gt;longbyteschar ::= &lt;any ASCII character except &quot;\&quot;&gt;bytesescapeseq ::= &quot;\&quot; &lt;any ASCII character&gt; 两种类型的文字值都可用单引号(&#39;)或双引号(&quot;)括起来，也能包含在三个引号中。反斜杠(\)字符用于转义好友特殊含义的字符。字节文字值总是以b或B为前缀，它们生成byte类型的实例，而不是str类型。它们可能只包含ASCII字符(128)，更大的字节必须转义。字符串和字节文字值都可以选择以字母r或R为前缀，如原始字符串将反斜杠视为文字字符。因此，在字符串文字值中，原始字符串中的\u和\U不会被特殊处理。 公认的转义序列： Escape Sequence Meaning \newline Backslash and newline ignored \\ Backslash () \&#39; Single quote (‘) \&quot; Double quote (“) \a ASCII Bell (BEL) \b ASCII Backspace (BS) \f ASCII Formfeed (FF) \n ASCII Linefeed (LF) \r ASCII Carriage Return (CR) \t ASCII Horizontal Tab (TAB) \v ASCII Vertical Tab (VT) \ooo Character with octal value ooo \xhh Character with hex value hh 仅在字符串文字值中识别的转义序列： Escape Sequence Meaning \N{name} Character named name in the Unicode database \uxxxx Character with 16-bit hex value xxxx \Uxxxxxxxx Character with 32-bit hex value xxxxxxxx 字符串文字串联String literal concatenation 多个相邻的字符串或字节文字值(由空格分隔)，可能使用不同的引用约定，并且它们的含义与它们的串联相同。因此，&quot;hello&quot; &#39;world&#39;等同于&quot;helloworld&quot;。此功能可用于减少反斜杠的数量，方便地跨长行分隔长字符串，甚至可以为字符串的某些部分添加注释。 123re.compile(&quot;[A-Za-z]&quot; #letter or underscore &quot;[A-Za-z0-9_]*&quot; #letter, digit or underscore ) 注意，此功能在语法级别上定义，但在编译时实现。必须使用+操作符在运行时连接字符串表达式。 格式化的字符串文字值Formatted string literals 格式化的字符串文字值是以f或F为前缀的字符串文字，这些字符串可能包含替换字段——由{}分隔的表达式。 12345678f_string ::= (literal_char | &quot;&#123;&#123;&quot; | &quot;&#125;&#125;&quot; | replacement_field)*replacement_field ::= &quot;&#123;&quot; f_expression [&quot;!&quot; conversion] [&quot;:&quot; format_spec] &quot;&#125;&quot;f_expression ::= (conditional_expression | &quot;*&quot; or_expr) (&quot;,&quot; conditional_expression | &quot;,&quot; &quot;*&quot; or_expr)* [&quot;,&quot;] | yield_expressionconversion ::= &quot;s&quot; | &quot;r&quot; | &quot;a&quot;format_spec ::= (literal_char | NULL | replacement_field)*literal_char ::= &lt;any code point except &quot;&#123;&quot;, &quot;&#125;&quot; or NULL&gt; 栗子： 12345678910111213141516&gt;&gt;&gt; name = &quot;Fred&quot;&gt;&gt;&gt; f&quot;He said his name is &#123;name!r&#125;.&quot;&quot;He said his name is &apos;Fred&apos;.&quot;&gt;&gt;&gt; f&quot;He said his name is &#123;repr(name)&#125;.&quot; # repr() is equivalent to !r&quot;He said his name is &apos;Fred&apos;.&quot;&gt;&gt;&gt; width = 10&gt;&gt;&gt; precision = 4&gt;&gt;&gt; value = decimal.Decimal(&quot;12.34567&quot;)&gt;&gt;&gt; f&quot;result: &#123;value:&#123;width&#125;.&#123;precision&#125;&#125;&quot; # nested fields&apos;result: 12.35&apos;&gt;&gt;&gt; today = datetime(year=2017, month=1, day=27)&gt;&gt;&gt; f&quot;&#123;today:%B %d, %Y&#125;&quot; # using date format specifier&apos;January 27, 2017&apos;&gt;&gt;&gt; number = 1024&gt;&gt;&gt; f&quot;&#123;number:#0x&#125;&quot; # using integer format specifier&apos;0x400&apos; 数字文字值Numeric literals 有三种类型的数字文字值： integers floating point numbers imaginary numbers 没有复数文字值。请注意，数字文字值不包含符号。像-1实际是由一元运算符-和文字值1组成的表达式。 整数文字值除了可以存储在可用内存中之外，整数文字值的长度没有限制。 12345678910integer ::= decinteger | bininteger | octinteger | hexintegerdecinteger ::= nonzerodigit ([&quot;_&quot;] digit)* | &quot;0&quot;+ ([&quot;_&quot;] &quot;0&quot;)*bininteger ::= &quot;0&quot; (&quot;b&quot; | &quot;B&quot;) ([&quot;_&quot;] bindigit)+octinteger ::= &quot;0&quot; (&quot;o&quot; | &quot;O&quot;) ([&quot;_&quot;] octdigit)+hexinteger ::= &quot;0&quot; (&quot;x&quot; | &quot;X&quot;) ([&quot;_&quot;] hexdigit)+nonzerodigit ::= &quot;1&quot;...&quot;9&quot;digit ::= &quot;0&quot;...&quot;9&quot;bindigit ::= &quot;0&quot; | &quot;1&quot;octdigit ::= &quot;0&quot;...&quot;7&quot;hexdigit ::= digit | &quot;a&quot;...&quot;f&quot; | &quot;A&quot;...&quot;F&quot; 浮点数文字值 123456floatnumber ::= pointfloat | exponentfloatpointfloat ::= [digitpart] fraction | digitpart &quot;.&quot;exponentfloat ::= (digitpart | pointfloat) exponentdigitpart ::= digit ([&quot;_&quot;] digit)*fraction ::= &quot;.&quot; digitpartexponent ::= (&quot;e&quot; | &quot;E&quot;) [&quot;+&quot; | &quot;-&quot;] digitpart 虚数文字值 1imagnumber ::= (floatnumber | digitpart) (&quot;j&quot; | &quot;J&quot;) 运算符Operators 123+ - * ** / // % @&lt;&lt; &gt;&gt; &amp; | ^ ~&lt; &gt; &lt;= &gt;= == != 分隔符Delimiters 1234( ) [ ] &#123; &#125;, : . ; @ = -&gt;+= -= *= /= //= %= @=&amp;= |= ^= &gt;&gt;= &lt;&lt;= **= Python中以下ASCII字符有重要意义： 1&apos; &quot; # \ Python中不使用以下ASCII字符: 1$ ? 数据模型Data model 对象，值和类型Objects, values and types 对象(Objects)是Python的数据抽象。Python程序中的所有数据都由对象或对象之间的关系表示。每个对象都有一个标识(Identity)，一个类型(Type)和一个值(Value)。对象的标识一旦创建就永远不会改变。is操作符就是比较两个对象的标识；id()函数返回一个表示其标识的整数。 12345name = 'zhang'NAME = 'ZHANG'name is NAMEFalse CPython中，id(x)是存储x的内存地址。 对象的类型(Type)确定了对象支持的操作，并且还定义了该类型的对象的可能值。type()函数返回对象的类型。与对象标识一样，对象的类型也是不可更改的。 某些对象的值(Value)可以改变。值可以改变的对象被认为是可变的(mutable)，值不可改变的的对象被称为是不可变的(immutable)。对象的可变性由其类型决定。例如，数字(number)，字符串(string)，元组(tulple)是不可变的，字典(dictionary)和列表(list)是不可变的。 对象永远不会被明确销毁，然而，当它们变得无法到达(unreachable)时，它们可能会被垃圾回收(garbage-collected)。允许实现推迟垃圾回收或完全省略垃圾回收——只要没有回收到仍然是可以访问的对象，垃圾回收的实现方式就是如此。 请注意，使用实现的tracing或debugging工具可以使对象保持活动状态，这些对象通常是可回收的。另请注意，使用try...except语句捕获异常可能会使对象保持活动状态。 某些对象包含对外部(external)资源的引用，如打开的文件。当对象被垃圾回收时，这些资源被释放，但由于不能保证垃圾回收发生，这些对象还提供了一种释放外部资源的明确的方法——close()方法。强烈建议程序明确关闭此类对象。try...finally语句和with语句提供了方便的方法。 一些对象包含对其它对象的引用，这被称为容器(container)，容器的栗子是元组，列表和字典。引用是容器值的一部分。在大多数情况下，当我们谈论容器的值时，指的是值而并非容器对象的标识；但是，但我们谈论容器的可变性时，只隐含了直接包含的对象的标识。因此，如果一个不可变容器(如元组)包含对可变对象的引用，则如果更改了可变对象，则其值会改变。 类型几乎影响对象行为的所有方面。在某种意义上，即使对象标识的重要性也会受到影响：对于不可变类型，计算新值的操作实际上可以返回对具有相同类型和值的任何对象的引用，而对于可变对象，这是不允许的。 标准类型层次结构The standard type hierarchy 下面列出了Python內建的类型，扩展模块可定义其它类型。下面的一些类型描述包含一个列出的special attributes段落。这些属性提供对实现的访问，不适用于一般用途。它们的定义未来可能发生变化。 None此类型具有单个值(single value)。有一个具有此值的对象，可通过內建名称None访问此对象。在许多情况下它用于表示缺少值，例如，它是未明确返回任何内容的函数的返回。Its truth value is false. NotImplemented此类型具有单个值。有一个具有此值的对象，可通过內建名称NotImplemented访问此对象。如果数值方法和富比较方法尉氏县所提供的操作数的操作，则返回此值。Its truth value is true. Ellipsis此类型具有单个值。有一个具有此值的对象，可通过...或內建名称Ellipsis访问此对象。Its truth value is true. numbers.Number由数字创建，并由算术运算符和算术内置函数作为结果返回。数值对象是不可变的。Python数字与数学数字密切相关，但收到计算机中数值表示的限制。Python区分整数(integer)、浮点数(floating point number)和复数(complex number)： numbers.Integral表示整数的数学集合(正数和复数)的元素，有两种类型的整数: Integers (int)这代表无限范围内(unlimited range)的数字，仅受到可用(virtual)memory的限制。 Booleans (bool)这代表真值的True和False，这两个对象是唯一的布尔值对象。布尔类型是整数类型的子类型，布尔值在几乎所有上下文中的行为分别类似于值0和1，例外的是，当转换为字符串时，分别返回字符串False或True。 numbers.Real (float)这代表机器级双精度(double precision)浮点数。您可以接受底层机器架构，以获得可接受的范围和溢出处理。Python不支持单精度浮点数，没有理由使用两种浮点数复杂化语言。 numbers.Complex (complex)这将复数表示为一对机器级双精度浮点数。可通过只读属性z.real和z.imag来检索复数z的实部(real)和虚部(imaginary)。 Sequences这表示由非负数索引的有限有序集。內建函数len()返回序列的项数。当序列长度为n时，索引集数字为0, 1, ..., n-1。序列的i项由a[i]选择。序列还支持切片(slicing): a[i:j]选择一定范围内的项。当使用表达式时，切片是相同类型的序列。一些序列还支持带有步进(step)参数的扩展切片: a[i:j:k]。序列根据其可变性进行区分： Immutable sequences不可变序列类型的对象一旦创建就不能更改。如果对象包含对其它对象的引用，则这些其它对象可能是可变的并且可能会被更改；但是，由不可变对象直接引用的对象集合不能更改。不可变序列有以下类型： Strings字符串是表示Unicode code ponit的值序列。U+0000 - U+10FFFF范围内的代码点都可以用字符串表示。Python没有char类型；相反，字符串中的每个代码点都表示为长度为1的字符串对象。內建函数ord()将代码点从字符串形式转换为0-10FFFF范围内的整数；chr()将0-10FFFF范围内的整数转化为对应长度为1的字符串对象；str.encode()可用于将str转换为bytes，而bytes.decode()用于实现相反的操作。 12345678&gt;&gt;&gt; ord('a')97&gt;&gt;&gt; chr(97)a&gt;&gt;&gt; str.encode('a')b'a'&gt;&gt;&gt; bytes.decode(b'a')a Tuples元组的项是任意Python对象。两个或多个项的元组由逗号分隔的表达式列表组成。空元组可由一对空括号组成。 Bytes字节对象是一个不可变的数组。这些项是8-bit bytes，由0-255范围内的整数表示。 Mutable sequences可变序列创建之后可以更改。订阅和切片表示法可用作赋值和del语句的目标。目前有两种可变序列类型： **Lists列表的项是任意Python对象。通过将逗号分隔的表达式放在方括号中来形成列表。 Byte Arraysbytearray对象是一个可变数组。它们由內建的bytearray()构造器(constructor)创建。 扩展模块array提供了可变序列类型的另一个示例，collections模块也是如此。 Set types这代表无序，有限的唯一不可变的对象集。因此，它们不能被任何下标索引。但是，它们可以迭代，內建函数len()返回集合的项目数。集合的常见用途是进行快速成员资格测试，从序列中删除重复项，以及计算数学运算(交集、并集、差集…)。对于集合元素，相同的不可变性规则适用于字典的键。请注意，数字类型遵循数字比较的常规规则：如果两个数字相等(如 1, 1.0)，则它们中只能包含其中一个。目前有两种固有的集合类型: Sets这代表一个可变集合。它们通过內建的set()构造器进行创建，之后可通过多种方法进行修改(如 add())。 Frozen sets这代表一个不可变集合。它们通过內建的frozenset()构造器进行创建。它是可变且可清除的，因此它可以再次用作另一个集合的元素，或作为字典的键。 Mappings这表示由任意索引集合索引的有限对象集。如下标符号a[k]从映射a中选择由k索引的项；这可在表达式中使用，也可作为赋值或del语句的目标。內建函数len()返回映射中的项数。目前有一种内在映射类型： Dictionaries这表示有几乎任意值索引的有限对象集。唯一不能作为键接受的值是包含列表或字典或其它可变类型的值，这些值通过值而不是按对象标识进行比较，原因是字典的有效实现需要键的哈希值保持不变。用于键的数字类型遵循用于数字比较的正常规则：如果两个数字相等(如1, 1.0)，则它们互相地用于索引相同的字典项。字典是可变的，它们可通过{...}符号创建。扩展模块dbm.ndbm和dbm.gnu提供了映射类型的其它实例，collections模块也是如此。 Callable types这是可应用函数调用操作的类型： User-defined functions用户定义的函数对象由函数定义创建。它应使用包含于函数的形式参数列表相同数量的项的参数列表来调用它。特殊属性(special attributes): Attribute Meaning - __doc__ The function’s documentation string, or None if unavailable; not inherited by subclasses Writable __name__ The function’s name Writable __qualname__ The function’s qualified name. New in version 3.3. Writable __module__ The name of the module the function was defined in, or None if unavailable. Writable __defaults__ A tuple containing default argument values for those arguments that have defaults, or None if no arguments have a default value Writable __code__ The code object representing the compiled function body. Writable __globals__ A reference to the dictionary that holds the function’s global variables — the global namespace of the module in which the function was defined. Read-only __dict__ The namespace supporting arbitrary function attributes. Writable __closure__ None or a tuple of cells that contain bindings for the function’s free variables. Read-only __annotations__ A dict containing annotations of parameters. The keys of the dict are the parameter names, and return for the return annotation, if provided. Writable __kwdefaults__ A dict containing defaults for keyword-only parameters. Writable 标记为可写的大多数属性都会检查指定值的类型。函数对象同样支持获取和设置任意属性。如，可使用这些属性将元数据附加到函数。常规属性.点表示法用于获取和设置此类属性。请注意，当前实现仅支持用户定义函数的函数属性。将来可能会支持内置函数的函数属性。 Instance methods实例方法对象组合了类(class)，类实例(class instance)和任何可调用对象(通常是用户定义的函数)。 特殊的只读属性：__self__是类实例对象，__func__是函数对象；__doc__是方法的文档(同__func__.__doc__)；__name__是方法名(同__func__.__name__)；__module__是定义的方法的模块的名称，如果不可用，则为None。 方法也支持访问底层函数对象上的任意函数属性。 当获取类的属性时，如果该属性是用户定义的函数对象或类方法对象，则可创建用户定义的方法对象。当通过实例从类中检索用户定义的函数对象来创建实例方法对象时，其__self__属性是实例，并且方法对象被称为绑定(bound)。新方法__func__属性是原始函数对象。当通过从类或实例检索另一个方法对象来创建用户定义的方法对象时，行为与函数对象的行为相同，只是新实例的__func__属性不是原始方法对象，而是其__func__属性。当通过从类或实例检索类方法对象来创建实例方法对象时，其__self__属性是类本身，其__func__属性是类方法的基础函数对象。调用实例方法对象时，将调用基础函数__func__，将类实例__self__插入参数列表前面。 注意，每次从实例检索属性时，都会发生从函数到实例方法对象的转换。在某些情况下，有成效的优化将属性分配给局部变量并调用局部变量。还要注意，此转换仅适用于用户定义的函数；在不进行转换的情况下检索其它可调用对象(以及不可调用对象)。作为类实例属性的用户定义函数不会转换为绑定方法;这只有在函数是类的属性时才会发生。 Generator functions使用yield语句的函数或方法被称为生成器函数。这样的函数在被调用时总是返回一个迭代器对象，它可以用来执行函数体：调用迭代器的iterator.__next__()方法将导致函数执行，直到它使用yield语句提供一个值。当函数执行return语句或结束时，会引发StopIteration异常，并且迭代器将到达要返回的值集合的末尾。 Coroutine functions使用async def定义的函数或方法称为协程函数。这样的函数在被调用时返回一个协程对象。它可能包含await表达式，以及async with和async for语句。 Asynchronous generator functions使用async def定义并使用yield语句的函数或方法称为异步生成器函数。这样的函数在调用时返回一个异步迭代器对象，该对象可在async for语句中用于执行函数体。 调用异步迭代器的aiterator.__anext__()方法将返回一个awaitable来等待执行，直到它使用yield表达式。当函数执行一个空的return语句或从结尾处掉落时，会引发StopAsyncIteration异常，异步迭代器将到达要生成的值集的末尾。 Built-in functions內建函数对象是C函数的包装器。 Built-in methods这实际上是内建函数的不同伪装，包含作为隐式额外参数传递给C函数的对象。 Classes类是可调用的。这些对象通常作为新实例的工程，但是对于覆盖__new__()的类类型可能存在变化。调用的参数传递给__new__()，在典型情况下，传递给__init__()以初始化新实例。 Class Instances通过在类中定义__call__()方法，可使任意类的实例可调用。 Modules模块是Python代码的基本组织单元，由导入系统(import system)创建，由import语句调用。模块对象具有由字典对象实现的命名空间(由模块中定义的函数的__globals__属性引用)。属性引用被转换为该字典中的查找，如m.x相当于m.__dict__[&#39;x&#39;]。模块对象不包含用于初始化模块的代码对象。属性赋值更新模块命名空间字典，如m.x = 1等效于m.__dict__[&#39;x&#39;] = 1。 预定义(可写)属性： __name__是模块的名称； __doc__是模块的文档字符串，不可用为None。特殊的只读属性； __annotations__是包含在模块正文执行期间收集的变量注释的字典； __file__是从加载模块的文件的路径名，如果是从文件加载的。 Custom classes自定义类类型通常由类定义创建。类具有由字典对象实现的命名空间。类属性引用被转换为此字典中的查找，如C.x被翻译为C.__dict__[&#39;x&#39;]。类属性赋值更新类的字典，而不是基类(base class)的字典。可调用类对象以生成(yield)类实例。 特殊属性： __name__是类名； __module__是类定义的模块名； __dict__是包含类的命名空间的字典； __bases__是包含基类的元组，按它们在基类列表中出现的顺序排列； __doc__是类的文档字符串，不可用为None； __annotations__是包含在类主体执行期间收集的变量注释的字典。 Class instances通过调用类对象来创建类实例。类实例具有作为字典实现的名称空间，该字典是搜索属性引用的第一个位置。当在那找不到属性，并且实例的类具有该名称的属性时，搜索继续使用类属性。如果找到的类属性是用户定义函数对象，则将其转换为实例方法对象，其__self__属性为实例。静态方法和类方法对象也同样被转换。如果没有找类属性，并且对象的类具有__getattr__()方法，则调用该方法以满足查找。 属性分配和删除更新实例的字典，而不是类的字典。如果类具有__setattr__()或__delattr__()方法，则调用此方法而不是直接更新实例字典。如果类实例具有某些特殊名称的方法，则它们可以假装为数字，序列或映射。 特殊属性： __dict__是属性字典； __class__是实例的类。 I/O objects (also known as file objects)文件对象表示打开的文件。各种快捷方式可用于创建文件对象：open()內建函数，os.popen()，os.fdopen()，套接字对象的makefile()方法。 sys.stdin, sys.stdout和sys.stderr对象被初始化为与解释器的标准输入，标准输出和标准错误流相对应的文件对象。它们都以文本模式打开，因此遵循io.TextIOBase抽象类定义的接口。 Internal types解释器内部使用的一些类型向用户公开。它们的定义可能会随着解释器的未来版本而改变，但为了完整起见，这里提到它们。 Code objects代码对象表示字节编译的可执行Python代码或字节码。代码对象和函数对象之间的区别在于函数对象包含对函数的全局变量的显示引用，而代码对象不包含上下文；默认参数值 也存储在函数对象中，而不是存储在代码对象中。与函数对象不同，代码对象是不可变的，并且不包含可变对象的引用。特殊的只读属性： co_name给出函数名； co_argcount是位置参数的数量； co_nlocals是函数使用的局部变量数； co_varnames是包含局部变量名称的元组； co_cellvars是包含嵌套函数引用的局部变量的名称； co_freevars是包含自由变量名称的元组； co_consts包含字节码使用文字的元组； co_names包含字节码使用名称的元组； co_filename是编译代码的文件名； co_firstlineno是函数的第一个行号； co_lnotab是用于编码从字节码偏移到行号的映射； co_stacksize是必须的堆栈大小； co_flags是一个整数，用于编码解释器的许多标志； 如果代码对象表示韩式，则co_consts中的第一项是函数的文档字符串，如果未定义，则为None。 Frame objects帧对象表示执行帧。它们可能出现在回溯(traceback)对象中。特殊只读属性: f_back是前一个堆栈帧，如果这是底部堆栈帧(bottom stack frame)，则为None； f_code是在此帧中执行的代码对象； f_locals是用于查找局部变量的字典； f_global用于全局变量； f_builtins用于內建名称； f_lasti给出了精确的指令。特殊可写属性: f_trace，如果非None，则在每个源代码行的开头调用的函数； f_lineno是帧的当前行号——从跟踪函数内写入此跳转到给定行。帧对象支持一个方法: frame.clear()此方法清除帧所持有的局部变量的所有引用。如果帧属于生成器，则确定生成器。这有助于打破涉及帧对象的参考循环。如果帧当前正在运行，则引发RuntimeError。 Traceback objects回溯对象表示异常的堆栈追踪，发生异常时会创建回溯对象。当搜索异常处理程序展开执行堆栈时，在每个展开的级别上，会在当前回溯之前插入回溯对象。输入异常处理程序时，堆栈追踪可供程序使用。它可作为sys.exc_info()返回的元组的第三项进行访问。当程序不包含合适的处理程序时，堆栈追踪被写入到标准错误流；如果解释器是交互式的，那它可作为sys.last_traceback提供给用户。特殊只读属性: tb_next是堆栈追踪中的下一级，如果没有，则为None； tb_frame指向当前级别的执行帧； tb_lineno给出发生异常的行号； tb_lasti表示准确的指令。如果在没有匹配的except子句或finally子句的try语句中发生异常，则回溯中的行号和最有一条指令可能与其帧对象的行号不同。 Slice objects切片对象用于表示__getitem__()方法的切片。它们也是由内置的slice()函数创建的。特殊只读属性: start是下限； stop是上限； step是步长； 如果忽略，则每个都是None。切片对象支持一个方法: slice.indices(self, length)此方法采用单个整数参数长度，并计算切片对象在应用于一些列长度项时将描述的切片的信息。它返回一个由三个整数组成的元组——(start, stop, step)。以和常规切片一致的方法处理丢失或越界的索引。 Static method objects静态方法对象提供了一种破坏函数对象到上述方法对象的转换的方法。静态方法对象是任何其它对象的包装器，通常是用户定义的方法对象。当从类或类实例中检索静态方法对象时，实际返回的对象时包装的对象，该对象不受任何进一步转换的影响。静态方法对象本身不可调用，尽管它们通常包装的对象是。静态方法对象由內建的staticmethod()够赞函数创建。 Class method objects类方法对象，与静态方法对象类似，是另一个对象的包装器，它改变了从类和类实例中检索该对象的方式。类方法对象由內建的classmethod()构造函数创建。 特殊方法名称Special method names 类可以通过定义具有特殊名称的方法来实现有特殊语法调用的某些操作。这是Python的运算符重载方法，允许类根据语言运算符定义自己的行为。将特殊方法设置为None表示相应的操作不可用。例如，如果将类的__iter__()设置为None，则该类不可迭代，因此在其实例调用iter()将引发TypeError。 基本定制Basic customization object.__new__(cls[,...])被调用来创建类cls.__new__()的新实例是一个静态方法，它将请求实例的类作为其第一个参数。其余参数是传递给对象构造函数表达式的参数。 执行模块Execution model 程序结构Structure of a program Python程序由代码块构成。块是一段Python程序文档，作为一个单元执行。模块、函数体、类定义都是块。交互式输入的每个命令都是一个块。脚本文件是代码块，脚本命令是代码块。传递给内建函数eval()和exec()的字符串参数是一个代码块。 命名和绑定Naming and binding 名称绑定Binding of names 名称指的是对象。名称有名称绑定操作引入。 以下构造绑定名称: 函数的形式参数(formal parameters) import语句from...import *的import语句绑定导入模块中定义的所有名称，但以下划线(_)开头的名称除外。 类和函数的定义 作为标识符的目标 for循环头 在with...as或except子句之后 在del语句中出现的目标也被认为是此目的绑定的。每个赋值或导入语句都发生在由类或函数定义或模块级别定义的块中。如果名称绑定在块中，则它是该块的局部变量(local variable)，除非声明为nonlocal或global。如果名称绑定在模块级别，则它是全局变量(global variable)。模块代码块中的变量是本地和全局的。如果一个变量在代码块中使用但未在此定义，则它是一个自由变量(free variable)。程序文本中每次出现的名称都是指由以下名称解析规则建立的名称的绑定。 名称解析Resolution of names 范围(scopt)定义了块内名称的可见性。如果在块中定义了局部变量，则其范围包括该块。如果定义发生在函数块内，则作用于将扩展到定义块中包含的任何块，除非包含块为名称引入不同的绑定。 在代码块中使用名称时，将使用最近的封闭范围解析该名称。代码块可见的所有此类范围的集合称为块的环境。如果找不到名称，则会引发NameError异常。如果当前作用域是函数作用域，并且名称引用尚未绑定到使用该名称的值的本地变量，则会引发UnboundLocalError异常(它是NameError的子类)。 如果名称绑定操作发生在代码块中的任何位置，则块中名称的所有使用都将被视为对当前块的引用。在绑定之前在块中使用名称时，可能会导致错误。这条规则很微妙，Python缺少声明，并允许在代码块中的任何位置进行名称绑定操作。可以通过扫描块的整个文本以确定名称绑定操作来确定代码块的局部变量。 如果global语句发生在块中，则语句中指定的名称的所有使用都将引用在顶级命名空间中的绑定的名称。通过搜索全局(global)命名空间(包含代码块的命名空间)和內建(build-in)命名空间(內建模块的命名空间)，在顶级命名空间中解析名称。首先搜索全局命名空间。如果在那里找不到名称，则搜索內建命名空间。global语句必须在名称的所有使用之前。 global语句与同一块中名称绑定具有相同的范围。如果自由变量的最近封闭范围包含全局语句，则将自由变量视为全局变量。nonlocal语句使相应的名称引用最近的封闭函数范围中的先前绑定的变量。如果任何封闭的函数作用域中不存在给定的名称，则在编译时引发SyntaxError。 模块的命名空间在第一次导入模块式自动创建。脚本的主要模块始终被称为__main__。 exec()和eval()的类定义块和参数在名称解析的上下文中是特殊的。类定义是可以使用和定义名称的可执行语句。这些引用遵循名称解析的常规规则，但在全局命名空间中查找未绑定的局部变量。类定义的命名空间成为类的属性字典。类块中定义的名称范围仅限于类块;它没有扩展到方法的代码块——这包括了解和生成器表达式，因为它们是使用函数作用域实现的。 內建和严格执行Builtins and restricted execution CPython实现细节：用户不该触碰__builtins__，它严格来说是一个实现细节。想要覆盖內建命名空间中的值的用户应该导入內建模块并适当地修改其属性。与代码块执行相关联的內建命名空间实际上是通过在其全局命名空间中查找名称__builtins__来找到的；这应该是字典或模块。默认情况下，在__main__模块中，__builtin__是內建的builtins模块；在任何其它模块中，__builtins__是內建模块本身的字典的别名。 与动态功能的交互 Interaction with dynamic features 自由变量的名称解析在运行时发生，而不是在编译时发生。 eval()和exec()函数无权访问用于解析名称的完整环境。可在调用者的本地好全局命名空间中解析名称。自由变量不在最近的封闭空间中解析，而是在全局命名空间中解析。 异常Exceptions 异常(exception)是一种打破代码块正常控制流已处理错误或其它异常情况的方法。检测到错误时会出现异常，它可以由周围的代码块直接或间接调用发生错误的代码块的任何代码块处理。 Python解释器在检测到运行时错误引发异常。Python程序也可使用raise语句显式地引发异常。使用try...execpt语句处理异常，这种语句的finally子句可用于指定不处理异常的清理代码。Python使用错误处理的termination模型：异常处理程序可找出发生的情况并继续在外层执行，但它无法修复错误原因并重试失败操作。 当根本不处理异常时，解释器终止程序的执行，或返回其交互式主循环。在任何一种情况下，它都会打印stack backtrace除非异常是SystemExit。异常由类实例标识。根据实例的类选择except子句，它必须引用实例的类或其基类。该实例可以由处理程序接收，并且可以携带关于异常情况的附加信息。 import系统The import system HOWTOsPython HOWTOs是覆盖单个特定主机的文档，并尝试完全包含它。此文档比Python参考库更详细。 标准库 介绍Python标准库包含了各种不同类型的组件。 一些模块提供了特定于Python的接口；一些提供特定于特定操作系统的接口，一些提供特定于特定应用程序的接口。一些模块适用于所有Python版本和端口；一些只有在底层系统支持或需要它们是才可用；还有一些只有在编译和安装Python特定配置时才可用。 内建函数Python解释器内置了许多功能和类型，它们始终可用。 内建函数 abs() dict() help() min() setattr() all() dir() hex() next() slice() any() divmod() id() object() sorted() ascii() enumerate() input() oct() staticmethod() bin() eval() int() open() str() bool() exec() isinstance() ord() sum() bytearray() filter() issubclass() pow() super() bytes() float() iter() print() tuple() callable() format() len() property() type() chr() frozenset() list() range() vars() classmethod() getattr() locals() repr() zip() compile() globals() map() reversed() __import__() complex() hasattr() max() round() delattr() hash() memoryview() set() abs(x)返回一个数字的绝对值 all(iterable)如果迭代的所有元素均为真(或为空)，返回True any(iterable)如果迭代的任一元素为真，返回True；为空返回False ascii(object) bin(x)将整数转换为二进制字符串 bool([x])返回一个布尔值，True或False bytearray()返回一个新的字节数组 byte()返回一个新的字节对象，它是一个在0&lt;=x&lt;256范围内的不可变整数序列 callable(object)如果对象参数显示为可调用，返回True；否则返回False chr(i)返回代表Unicode编码为整数i的字符的字符串 classmethod(function)为函数返回一个类方法 compile()将源编译为代码或AST对象 complex()返回一个复数，或将字符串或数字转换为复数 delattr(object, name)这是setattr()的相对值 dict(kwarg)创建一个新的字典 dir(object)无参数，返回当前本地作用域中的名称列表有参数，尝试返回该对象的有效属性列表 divmod(a, b)以两个数字(非复数)为参数，使用整数除法时返回由它们的商和余数组成的一对数字 enumerate(iterable, start=0)返回一个枚举对象 eval(expression, globals, locals) exec()动态执行Python代码 filter(function, iterable)从函数返回true的可迭代元素构造一个迭代器 float()返回由数字或字符串构造的浮点数 format()将值转换为特定格式 frozenset()返回一个新的frozenset对象，可选用来自迭代的元素 getattr()返回对象命名属性的值 globals()返回表示当前全局符号表的字典 hasattr(obj, name)参数是一个对象和一份字符串，如果字符串是对象属性之一的名称，结果为True，否则False hash(obj)返回对象的hash值 help()调用内建的帮助系统 hex(x)将整数转换为十六进制数 id(obj)返回一个对象的标识 input()从标准输入中读取一行，转换为字符串，然后返回该行 int(x)返回一个整数对象，如果没有参数，则返回0 isinstance(obj, classinfo)如果对象参数是classinfo参数的实例或其子类的实例，返回true issubclass(class, classinfo)如果class是类信息的子类，返回true iter(obj)返回一个迭代器对象 len()返回对象的长度 list()列表实际上是一个可变的序列类型，而不是一个函数 locals()更新并返回表示当前本地符号表的字典 map()返回一个将函数应用于每个迭代项的迭代器，从而产生结果 max()返回最大项 memoryview(obj)从给定参数返回内存视图对象 min()返回最小项 next()从迭代器中检索下一项 object()返回一个新的无特征的对象 oct()将整数转换为八进制字符串 open()打开文件并返回相应的文件对象 ord()给定一个表示一个Unicode编码的字符，返回一个表示该字符的Unicode编码的整数 pow() print()将对象打印到流文件 property()返回一个property属性 range()范围一个不可变的序列类型，而不是函数 repr()返回一个包含对象可打印表示的字符串 reversed()返回一个反向迭代器 round()返回数字小数点后ndigits精度 set()返回一个新的集合对象，可选来自迭代的元素 setattr()getattr的对应部分 slice()返回由范围指定的一组索引的切片(slice)对象 sorted()从迭代项中返回一个新的排序列表 staticmethod()为函数返回一个静态方法 str()返回一个字符串对象 sum()对迭代项求和 super()返回将方法调用委托个父类或同类的代理对象 tuple()元组是一个不可变的序列类型，而不是函数 vars()返回对象的__dict__属性 zip()制作一个迭代器，用于聚合来自每个迭代器的元素 __import__这个函数被import语句调用 内建常量少量常量存在于命名空间中。 False True None NotImplemented Ellipsis __debug__ 内建类型主要的内建类型有： 数字(numeric) 序列(sequence) 映射(mapping) 类(class) 实例(instance) 异常(exception) 真值测试任何对象都可进行真值测试。 布尔操作 and or not 比较操作Python中有8个比较操作： &lt; &lt;= &gt; &gt;= == != is isnot 数字类型 int float complex 迭代器类型Python支持对容器进行迭代的概念。 序列类型 list 列表是可变序列，通常用于存储同类项目的集合 tuple 元组是不可变序列，通常用于存储异构数据的集合 range 范围表示一个不可变的数字序列，通常用于for循环 range(start, stop, step) 通用序列操作 in not in + * [i] [i:j] [i:j:k] len() min() max() count() index() 不可变序列类型 可变序列类型可变定义类型的操作： [i] [i:j] del [i:j:k] append() clear() copy() += *= insert() pop remove() reverse() 文本序列类型Python中的文本数据由str对象处理，字符串是Unicode编码点的不可变序列。 字符串以各种方式书写： 单引号 双引号 三引号 字符串方法 https://docs.python.org/3.5/library/stdtypes.html#string-methods 样式字符串格式字符串对象有一个唯一的内建操作: %操作符，也称为字符串格式化操作符。 转换类型： % s i x f c 二进制序列类型 bytes 字节对象是单字节的不可变序列 bytearray 是字节对象的可变对象 memoryview 运行Python代码访问支持缓冲区协议的对象的内部数据，而无需复制 字节和字节数组对象操作符都支持普通序列操作符，同样也支持字节格式。 集合类型 set frozenset 集合对象是不同可散列对象的无序集合。常见用途包含成员测试、删除重复项，数学计算(交集，并集，差集) 映射类型 dict 映射对象可将散列值映射到任意对象，它是可变对象。 字典视图对象 dict.keys() dict.values() dict.items() 上下文管理类型Python的with语句支持由上下文管理器定义的运行时上下文的概念。 其它内建类型模块类和类实例函数方法代码对象类型对象null对象ellipsis对象notImplimented对象布尔值内部对象 特殊属性一些特殊的只读属性： object.__dict__ instance.__class__ class.__bases__ definition.__name__ definition.__qualname__ class.__mro__ class.__subclasses__() 内建异常在Python中，所有异常(exception)都必须是派生自Baseexception的类的实例。 基类 BaseException Exception ArithmeticError bufferError LookupError 具体异常 AssertionError AttributeError EOFError FloatingPointError GeneratorExit ImportError IndexError KeyError KerboardInterrupt MemoryError NameError NotImplementedError OSError OverflowError RecursionError ReferenceError RuntimeError StopAsyncIteration SyntaxError IndentationError TabError SystemError SystemExit TypeError UnboundLocalError UnicodeError UnicodeEncodeError UnicodeDecodeError UnicodeTranslateError ValueError ZeroDivisionError EnvironmentError IOError 文本处理stringstring模块，字符串操作 rere模块，提供了正则表达式匹配操作。 字符串模式匹配 12345678&gt;&gt;&gt; import re&gt;&gt;&gt; re.findall(r'f[a-z]*', 'which foot or hand fell fastest')['foot', 'fell', 'fastest']#替换&gt;&gt;&gt; 'aaa and bbb'.replace('bbb', 'BBB')'aaa and BBB' difflibdifflib，助手计算三角洲。该模块提供用于比较序列的类和函数。 textwraptextwrap模块，文本环绕和填充。将段落文本格式化以适应给定的屏幕宽度。 12345678&gt;&gt;&gt; import textwrap&gt;&gt;&gt; doc = """ 1111 1111 1111 1111 1111 1111... 2222 2222 2222 2222 2222 2222... 3333 3333 3333 3333 3333 3333"""&gt;&gt;&gt; print(textwrap.fill(doc, width=50)) 1111 1111 1111 1111 1111 1111 2222 2222 2222 22222222 2222 3333 3333 3333 3333 3333 3333 unicodedataunicodedata，Unicode数据库。该模块提供对Unicode字符数据库(UCD)的访问，此数据库为所有Unicode字符定义字符属性。 stringprepstringprep，因特网字符串准备。 readlinereadline，GNU读行接口。该模块定义了许多方便Python解释器完成和读写历史文件的函数。 rlcompleterrlcompleter，GNU读行的完成函数。该模块通过完成有效的Python标识符合关键字来定义适用于readline模块的完成函数。 二进制数据structstruct模块，将字节解释为打包的二进制数据。提供了pack()和unpack()函数来处理可变长度的二进制记录格式。 codecscodes，编解码注册和基类。 数据和时间timetime模块，提供了许多操作时间值(time value)的函数，用于取得Unix纪元时间戳。 123456789import time#Unix时间time.time()#1531364576.3187952#delay for a number of seconds given as a floattime.sleep()time.time();time.sleep(10);time.time() datetimedatetime模块，基本日期和时间类型。支持日期和时间计算，并对输出做格式化处理。 1234567891011121314151617181920212223242526import datetimedatetime.datetime.now()#datetime.datetime(2018, 7, 12, 13, 45, 43, 127838)datetime.datetime.now().year, datetime.datetime.now().month, datetime.datetime.now().hour#Unix纪元转换datetime.datetime.fromtimestamp(1531374507.8268566)#datetime.datetime.fromtimestamp(time.time())#datetime.datetime(2018, 7, 12, 13, 48, 27, 826857)#日期比较yesterday = datetime.datetime(2018, 7, 11, 00, 00, 00, 00000)today = datetime.datetime.now()future = datetime.datetime(2018, 8, 12, 00, 00, 00, 00000)today &gt; yesterdaywhile future &gt; today: time.sleep(1)#timedelta表示一段时间#周，时，分，秒，毫秒，微秒period = datetime.timedelta(days=7, hours=6, minutes=20, seconds=55)str(period)#'7 days, 6:20:55' datetime.datetime.strftime()将datetime对象转换为字符串datetime.datetime.strptime()将字符串转换为datetime对象格式栗子: %Y: 2018 %y: 18 %m: 07 %B: July %b: Jul %d: 一月中的第几天 %j: 一年中的第几天 %w: 一周中的第几天(0-6) %A: Thursday %a: Thu %H: 14(00-23) %I: 2(0-12) %M: 分(00-59) %S: 秒(00-59) %p: AM/PM 12345datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')#'2018-07-12 14:11:20'datetime.datetime.strptime(2018-07-12 14:11:20', '%Y-%m-%d %H:%M:%S')#datetime.datetime(2018, 7, 12, 14, 11, 20) calendarcalendar，日历相关函数。 collectionscollections，容器数据类型。 collections.abccollections.abc，容器的抽象基类 heapqheapq，堆队列算法。 bisectbisect，数组二等分算法。 arrayarray模块，有效的数值数组。它提供了一个array()对象，就像一个只存储同质数据并将其存储更紧凑的列表。 weakrefweakref，弱引用。weakref模块提供了用于跟踪对象而不创建参考的工具。当不再需要该对象时，它将自动从弱参考表中移除，并为弱参考对象触发回调。 Python支持自动内存管理，内存在最后一次被删除后不久就被释放。 copycopy，浅层和深层操作。 pprintpprint模块，漂亮打印。 12345678&gt;&gt;&gt; import pprint&gt;&gt;&gt; t =[[[['black', 'cyan'], 'white', ['green', 'red']], [['magenta','yellow'], 'blue']]]&gt;&gt;&gt; pprint.pprint(t, width=30)[[[['black', 'cyan'], 'white', ['green', 'red']], [['magenta', 'yellow'], 'blue']]] reprlibreprlib模块，提供repr自定义显示 enumenum，支持枚举。 数字和数学numbersnumbers，数字抽象基类。 round按指定精度四舍五入一个浮点数。 12round(1.23456, 4)#1.236 mathmath模块，数学函数。 12345&gt;&gt;&gt; import math&gt;&gt;&gt; math.sin(math.pi / 2)1.0&gt;&gt;&gt; math.log(256, 2)8.0 cmathcmath，复数数学函数。 decimaldecimal，十进制定点和浮点运算。 fractionsfractions，有理数。 randomrandom，生成伪随机数。 123456789&gt;&gt;&gt; import random&gt;&gt;&gt; random.choice(['a', 'b', 'c'])'a'&gt;&gt;&gt; random.sample(range(10), 2)[2, 6]&gt;&gt;&gt; random.random()0.9714711378164909&gt;&gt;&gt; random.randrange(10)5 statisticsstatistics模块，数学统计函数。计算基本的统计属性： 平均数(mean) 中位数(median) 方差(variance) 12345678&gt;&gt;&gt; import statistics&gt;&gt;&gt; num = [1, 2, 3, 4, 5]&gt;&gt;&gt; statistics.mean(num)3&gt;&gt;&gt; statistics.median(num)3&gt;&gt;&gt; statistics.variance(num)2.5 函数式编程模块本章模块提供了支持函数式编程风格的函数和类，以及可调用函数的一般操作。 itertoolsitertools，为高校循环创建迭代器。 functoolsfunctools，可调用对象的高阶函数和操作 operatoroperator，作为函数的标准操作符 文件和目录本章介绍的模块处理磁盘文件和目录。 pathlibpathlib，面向对象的文件系统路径此模块提供了代表文件系统路径的类，其语义适用于不同的操作系统。 os.pathos.path，通用路径名操作该模块在路径名上实现了一些有用的功能。 fileinputfileinput，迭代来自多个输入流的行该模块实现了从一个帮助类和函数，可在标准输入或文件列表上快速编写循环。 statstat，解释stat()结果此模块定义用于解释os.stat(),os.fstat(),os.lstat()的结果的常量和函数。 filecmpfilecmp，文件和目录比较此模块定义了比较文件和目录的函数，以及各种可选的时间和权衡。 tempfiletempfile，生成临时文件和目录此模块创建临时文件和目录。 globglob，Unix样式路径名称模式扩展此模块根据Unix shell使用的规则查找与指定模式匹配的所有路径名，结果以任意顺序返回。 fnmatchfnmatch，Unix文件名模式匹配此模块提供了对Unix shell风格的通配符的支持，它与正则表达式不同。 通配符: * ? [seq] [!seq] linecachelinecache，随机访问文本行此模块允许从Python源文件中获取任意行，同时尝试使用缓存进行内部优化，这是一种从单个文件中读取多行的常见情况。 shutilshutil，高级文件操作此模块提供了许多关于文件和文件集合的高级操作。 目录和文件操作 copytree rmtree 归档操作 12345&gt;&gt;&gt; shutil.copyfile('/tmp/1.txt', '/tmp/111.txt')'/tmp/111.txt'&gt;&gt;&gt; shutil.move('/tmp/today', '/tmp/TODAY')'/tmp/TODAY globglob模块，从通配符中搜索创建文件列表 123&gt;&gt;&gt; import glob&gt;&gt;&gt; glob.glob('/tmp/*.txt')['/tmp/1.txt', '/tmp/2.txt', '/tmp/111.txt'] 数据持久化本章介绍的模块支持将Python数据持久化存储到磁盘上。 picklepickle，Python对象序列化此模块用于实现序列化(serializing)和反序列化Python对象结构的二进制协议。 copyregcopyreg，注册pickle支持函数该模块提供了一种定义胭脂(pickle)特定对象时使用的函数方法。 shelveshelve，Python对象持久化shelf是一个持久的，类似字典的对象。 marshalmarshal，内部Python对象序列化此模块包含了可以以二进制格式读写Python值得函数。 dbmdbm，到Unix数据库的接口dbm是DBM数据库变体的通用接口。 sqlite3sqlite3，SQLite数据库的DB-API 2.0接口SQLite是一个C库，它提供了一个轻量级的基于磁盘的数据库，它不需要单独的服务器进程，并允许使用SQL查询语言的非标准变体访问数据库。 数据压缩和归档本章介绍的模块，支持使用zlib, gzip, bzip2, lzma算法进行数据压缩，以及创建zip和tar格式的归档文件。 zlibzlib，兼容gzip的压缩对于需要数据压缩的应用程序，此模块中的功能允许使用zlib库进行压缩(compression)和解压缩(decompression)。 gzipgzip，支持gzip文件此模块提供了一个简单的接口来压缩和解压缩文件，就行GNU程序gzip和gunzip一样。 bz2bz2，支持bz2压缩该模块提供了一个全面的接口，用于使用bzip2压缩算法进行压缩和解压缩数据。 lzmalzma，使用lzma算法进行压缩该模块提供了类和函数，用于使用lzma进行压缩和解压缩数据。 zipfilezipfile，使用zip归档zip文件格式是一个常用的归档和压缩标准。此模块提供了工具，用于创建，读写，追加和列出zip文件的工具。 tarfiletarfile，读写tar归档文件该模块可读写tar归档文件，包括使用gzip，bz2和lzma压缩。 文件格式本章描述的模块，解析各种各样的文件格式，不包含标记语言和e-mail。 csvcsv，读写CSV文件 所谓的CSV(comma separated values)逗号分隔值，它是一种简化的电子表格，保存为纯文本文件。是电子表格和数据库最常用的导入和导出格式。该模块实现了以CSV格式读写表格数据。 CSV文件很简单，缺少了Excel表格的许多功能： 值没有类型，都是字符串 没有字体大小或颜色 没有多个工作表 不能指定单元格的宽度和高度 不能合并单元格 不能签入图像和图标 1234567891011import csvfile = open(&apos;/tmp/test.csv&apos;)reader = csv.reader(file)data = list(reder)#写file = open(&apos;/tmp/test.csv&apos;, &apos;w&apos;, newline=&apos;&apos;)writer = csv.writer(file)writer.writerow(&apos;[1, 11, 111]&apos;)file.close() configparserconfigparser，配置文件解析器此模块提供了ConfigParser类，它实现了一种基本配置，你可以使用它来编写可由最终用户轻松定制的Python程序。 netrcnetrc文件处理netrc类解析和封装Unix FTP程序和其它FTP客户端使用的netrc文件格式。 xdrlibxdrlib，编码(encode)和解码(decode)XDR数据该模块支持外部数据表示标准(External Data Representation Standard)。此模块定义了两个类，一个将变量打包(packing)到XDR，另一个从XDR中解包(unpack)。 加密服务本章描述的模块，实现了各种加密(cryptographic)算法 hashlibhashlib，安全散列和消息摘要(digest)该模块为许多不同安全散列和消息摘要算法实现了通用接口。 SHA1 SHA224 SHA256 SHA384 MD5 hmachmac，用于消息认证的键控散列 操作系统接口本章介绍的模块，提供了操作系统功能的接口。 osos，各种操作系统接口该模块为使用操作系统相关的功能提供了一种便携方式。 文件名，命令行参数，环境变量 进程参数 文件对象创建 文件描述符操作 文件和目录的Linux扩展属性 进程管理 调度程序的接口 各种各样的系统信息 各种各样的功能 12345678&gt;&gt;&gt; import os&gt;&gt;&gt; os.getcwd()'/home/zhang'&gt;&gt;&gt; os.chdir('/tmp')#在shell中运行命令&gt;&gt;&gt; os.system('mkdir /tmp/today')0 ioio，流处理的核心工具该模块提供了Python用于处理各种类型I/O的主要工具。 text i/o binary i/o raw i/o timetime，访问和转换时间此模块提供了各种与时间相关的函数 argparseargparse，解析命令行选项、参数和子命令该模块可以轻松编写用户友好的命令行接口。 getoptgetopt，用于命令行选项的C风格解析器该模块帮助脚本解析sys.argv中的命令行参数。 logginglogging，Python的日志工具。该模块定义了函数和类，为应用程序和库实现灵活事件记录系统。 log level: DEBUG最低级别。用于小细节，通常只有在诊断问题时，才需要关心这些信息。 INFO用于记录程序中的一般事件的信息。 WARNING用于表示可能的问题 ERROR用于记录错误 CRITICAL最高级别，用于表示致命的错误 日志级别是一种建议。归根到底，还是由你来决定日志消息属于哪一种类型。 12345678910111213141516import logginglogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(lineno)d - %(message)s')logging.debug('Debugging information')logging.info('Informational message')logging.warning('Warning:config file %s not found', 'server.conf')logging.error('Error occurred')logging.critical('Critical error -- shutting down')#输出2018-07-10 14:50:13,060 - INFO - 6 - Informational message2018-07-10 14:50:13,061 - WARNING - 7 - Warning:config file server.conf not found2018-07-10 14:50:13,061 - ERROR - 8 - Error occurred2018-07-10 14:50:13,061 - CRITICAL - 9 - Critical error -- shutting down 日志格式: 12345678910111213141516| %(name)s Name of the logger (logging channel)| %(levelno)s Numeric logging level for the message (DEBUG, INFO, WARNING, ERROR, CRITICAL)| %(levelname)s Text logging level for the message (&quot;DEBUG&quot;, &quot;INFO&quot;, &quot;WARNING&quot;, &quot;ERROR&quot;, &quot;CRITICAL&quot;)| %(pathname)s Full pathname of the source file where the logging call was issued (if available)| %(filename)s Filename portion of pathname| %(module)s Module (name portion of filename)| %(lineno)d Source line number where the logging call was issued (if available)| %(funcName)s Function name| %(created)f Time when the LogRecord was created (time.time() return value)| %(asctime)s Textual time when the LogRecord was created| %(msecs)d Millisecond portion of the creation time| %(relativeCreated)d Time in milliseconds when the LogRecord was created, relative to the time the logging module was loaded (typically at application startup time)| %(thread)d Thread ID (if available)| %(threadName)s Thread name (if available)| %(process)d Process ID (if available)| %(message)s The result of record.getMessage(), computed just as the record is emitted logging.configlogging.config，日志配置 logging.handlerslogging.handlers，日志处理程序 getpassgetpass，便携式密码输入 cursescurses，字符单元显示的终端处理 curses.textpadcurses.textpad，用于curses程序的文本输入小部件此模块提供了一个Textbox类，他在curses窗口中处理基本的文本编辑。 curses.asciicurses.ascii，用于ASCII字符的使用程序该模块为ASCII字符提供名称常量，并为各种ASCII字符类中的成员测试函数。 curses.panelcurses.panel，curses的面板堆栈扩展面板是具有深度附加功能的窗口，因此它可堆叠在彼此的顶部，并且只显示每个窗口的可见部分。 platformplatform，访问底层平台的识别数据 errnoerrno，标准的errno系统符号 ctypesctypes，一个Python的外部函数库该模块提供了C兼容的数据类型，并允许在DLL或共享中调用函数。 并发执行本章介绍的模块，为并发执行(consurrent execution)代码提供了支持。 这里需要理解一些基本知识: 并发：并发的关键是处理多个任务，不一定要同时，可理解为交替做不同事情； 并行：并行的关键是同时处理多个任务，可理解为同时做不同事情； 进程：进程是操作系统资源分配的最小单元，每个进程拥有独立的内存单元； 线程：线程是程序执行的最小单元，是系统独立调度和分配CPU（独立运行）的基本单位。进程内的线程共享资源。进程内的线程通信比进程之间的通信更快更有效，因为共享资源； 多进程：同时执行多个进程——同时运行wecat, qq 多线程：同时执行多个线程——浏览器边看视频、边听歌、边下载 threadingthreading，基于线程的并行此模块在较低级别的_thread模块之上构建较高级别的线程接口。 如果多线程同时读写变量，导致互相干扰，就会发生所谓的并发问题。 1234567891011121314import time, threadingprint('thread start.')def wakeup(times): time.sleep(5) n = times for i in range(n): print('Wake Up!')thread01 = threading.Thread(target=wakeup, args=[3])#thread01 = threading.Thread(target=wakeup, kwargs=&#123;'times': 3&#125;)thread01.start()print('End of program!') 使用queue队列通信-经典的生产者和消费者模型一个负责生成，一个负责消费，所生成的产品存放在queue里，实现了不同线程间沟通 1234567891011121314151617181920212223242526272829303132333435363738# Producerclass Producer(threading.Thread): def __init__(self, name, queue): threading.Thread.__init__(self, name=name) self.queue = queue def run(self): for i in range(1, 5): print('&#123;&#125; 生产 &#123;&#125; 到队列'.format(self.getName(), i)) self.queue.put(i) time.sleep(random.randrange(10) / 5) print('&#123;&#125; 完成!'.format(self.getName()))# Consumerclass Consumer(threading.Thread): def __init__(self, name, queue): threading.Thread.__init__(self, name=name) self.queue = queue def run(self): for i in range(1, 5): val = self.queue.get() print('&#123;&#125; 消费队列中的 &#123;&#125;'.format(self.getName(), val)) time.sleep(random.randrange(10)) print('&#123;&#125; 完成!'.format(self.getName()))def main(): queue = Queue() producer = Producer('Producer', queue) consumer = Consumer('Consumer', queue) producer.start() consumer.start() producer.join() consumer.join() print('所有线程已完成!')if __name__ == "__main__": main() multiprocessing参考: https://zhuanlan.zhihu.com/p/46368084 multiprocessing，基于进程的并行它是一个使用类似线程模块的API来支持产生进程的包。 新创建的进程与进程的切换都是要耗资源的，所以平时工作中进程数不能开太大 同时可以运行的进程数一般受制于CPU的核数 除了使用Process方法，我们还可以使用Pool类创建多进程 12345678910111213141516171819202122232425262728293031323334353637383940414243'''Learn multiprocess Learn multiprocess of python.'''import timeimport osfrom multiprocessing import Process"""# singe processdef long_time_task(): print('当前进程: &#123;&#125;'.format(os.getpid())) time.sleep(2) print('结果: &#123;&#125;'.format(8 ** 20))if __name__ == "__main__": print('当前母进程: &#123;&#125;'.format(os.getpid())) start = time.time() for i in range(2): long_time_task() end = time.time() print('用时: &#123;&#125;s'.format((end - start)))"""# multiprocessdef long_time_task(i): print("子进程: &#123;&#125; - 任务&#123;&#125;".format(os.getpid(), i)) time.sleep(2) print("结果: &#123;&#125;".format(8 ** 20))if __name__ == '__main__': print('当前母进程: &#123;&#125;'.format(os.getpid())) start = time.time() p1 = Process(target=long_time_task, args=(1,)) p2 = Process(target=long_time_task, args=(2,)) print('等待所有子进程完成!') p1.start() p2.start() p1.join() p2.join() end = time.time() 多进程间的数据共享与通信通常，进程之间是相互独立的，每个进程都有独立的内存。通过共享内存(nmap模块)，进程之间可以共享对象，使多个进程可以访问同一个变量(地址相同，变量名可能不同)。多进程共享资源必然会导致进程间相互竞争，所以应该尽最大可能防止使用共享状态。还有一种方式就是使用队列queue来实现不同进程间的通信或数据共享，这一点和多线程编程类似。 1234567891011121314151617181920212223242526272829from multiprocessing import Process, Queueimport os, time, random# share data with multiprocess# 2 process, one for write, one for read. Implemented sharing a queuedef write(q): print('进程写: &#123;&#125;'.format(os.getpid())) for value in ['A', 'B', 'C']: print('将 &#123;&#125; 放入队列...'.format(value)) q.put(value) time.sleep(random.random())def read(q): print('进程读: &#123;&#125;'.format(os.getpid())) while True: value = q.get(True) print('从队列获取 &#123;&#125;'.format(value))if __name__ == '__main__': q = Queue() pw = Process(target=write, args=(q,)) pr = Process(target=read, args=(q,)) pw.start() pr.start() # 等待pw结束 pw.join() # pr进程里是死循环，无法等待其结束，只能强行终止 pr.terminate() concurrentconcurrent包中只有一个模块concurrent.futures，启动并行任务该模块为异步(asynchronously)执行可调用提供了一个高级的接口。 subprocesssubprocess，子进程管理该模块允许你生成新的进程，连接到它们的input/output/error pipes，并获得它们返回的代码。每个进程可以有多个线程。 1234567891011import subprocess#在Python脚本中启动一个外部程序subprocess.Popen(‘/tmp/hello.py’)#hello world!#用Popen传递参数，这需要传递一个列表subprocess.Popen([‘/tmp/hello.py’, 'argv1'])#它还有许多参数help(subprocess.Popen) schedsched，事件调度程序(scheduler)该模块定义了一个实现通用时间调度器的类。 queuequeue，一个同步队列类该模块实现了多生产者、多消费者队列。当信息必须在多线程之间安全地交换时，它在线程编程中特别有用。 进程间的通信和网络本章介绍的模块，提供了不同进程进行通信的机制。 socketsocket，低级网络接口该模块提供了对BSD socket的访问。 Socket是网络编程的一个抽象概念。通常我们用一个Socket表示“打开了一个网络链接”，而打开一个Socket需要知道目标计算机的IP地址和端口号，再指定协议类型即可。tcp需要建立连接，udp不需要建立连接，因此udp每次需要指定发送地址。 socket类型： socket.AF_UNIX本机通信 socket.AF_INET服务器间的网络通信 socket.AF_INET6IPv6的服务器间的通信 socket.SOCK_STREAM基于TCP的流式socket通信 socket.SOCK_DGRAM基于UDP数据包的socket通信 socket.SOCK_RAM原始套接字 socket.SOCK_SEQPACKET可靠的连续数据包服务 123456789101112131415161718192021#服务端socket函数：bind() 在AF_INET下，以tuple(host, port)的方式传入，如s.bind((host, port))listen() 可设置挂起的最大连接数accept() 接收tcp连接并返回(conn, address), conn是新的套接字对象, address是客户端地址#客户端socket函数：connect()connect_ex()#公共socket函数#tcprecv() 接受TCP套接字的数据，数据以字符串形式返回，buffsize指定要接受的最大数据量send()sendall() 完整发送tcp数据#udprecvfrom()sendto()close() socket编程思想： 12345678910111213#Server-side1. 创建socket2. 监听3. 接收client请求4. 接收C端数据5. 关闭头街子#Client-side1. 创建socket2. 连接到S端3. 发送数据4. 关闭套接字 注意在Python3.x中，byte strings 和 unicodestrings是两种不同的类型，相互之间需要进行decode()和encode()send()和recv()都是bytes类型，需要与str类型进行转换。 1234567891011121314151617181920212223242526272829303132333435363738394041424344#tcp#S端import sockethost = 'localhost'port = 5678bf = 1024maxConn = 3tcpS = socket.socket(socket.AF_INET, socket.SOCK_STREAM)tcpS.bind((host, port))tcpS.listen(maxConn)print('Server start at &#123;host&#125;:&#123;port&#125;'.format(host=host, port=port))print('Waiting for connection...')while True: conn, addr = tcpS.accept() print('Connected by: &#123;addr&#125;'.format(addr=addr)) while True: data = conn.recv(bf) print(data.decode('utf-8')) conn.send('server received message.'.encode('utf-8')) tcpS.close()#C端import sockethost = 'localhost'port = 5678bf = 1024tcpC = socket.socket(socket.AF_INET, socket.SOCK_STREAM)tcpC.connect((host, port))while True: msg = input('Please input message: \n') tcpC.send(msg.encode('utf-8')) data = tcpC.recv(bf) print(data.decode('utf-8')) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#udp#S端from pymongo import MongoClientimport socket, datetimehost = 'localhost'port = 5679bf = 1024mongoPort = 27017mongoUser = 'zhang'mongoPw = 'password'mongoDb = 'zhang'mongoColl = 'udpS'udpS = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)udpS.bind((host, port))collection = MongoClient(host=host, port=mongoPort, \ username=mongoUser, password=mongoPw).zhang.udpSprint('udp socket on &#123;host&#125;:&#123;port&#125;...'.format(host=host, port=port))while True: data, addr = udpS.recvfrom(bf) print('Received from &#123;addr&#125;'.format(addr=addr)) print(data.decode('utf-8')) print('\n') msg = 'Server has recived!\n' udpS.sendto(msg.encode('utf-8'), addr) dateTime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') post = &#123; 'author': 'Server', 'date': dateTime, 'message': data.decode('utf-8') &#125; collection.insert_one(post)#C端from pymongo import MongoClientimport socket, datetimehost = 'localhost'port = 5679bf = 1024mongoPort = 27017mongoUser = 'zhang'mongoPw = 'password'mongoDb = 'zhang'mongoColl = 'udpC'udpC = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)collection = MongoClient(host=host, port=mongoPort, \ username=mongoUser, password=mongoPw).zhang.udpCwhile True: msg = str(input('Please input message: \n')) udpC.sendto(msg.encode('utf-8'), (host, port)) data = udpC.recv(bf) print(data.decode('utf-8')) dateTime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') post = &#123; 'author': 'Client', 'date': dateTime, 'message': data.decode('utf-8') collection.insert_one(post) udpC.close() sslssl，套接字对象的TLS/SSL封装此模块提供了对网络套接字的传输层安全(通常称为安全套接字层)的加密和对等身份验证功能。 selectselect，等待I/O完成该模块提供对大多数操作系统中可用的select()和poll()函数的访问。 selectorselector，高级I/O复用该模块基于select()模块构建，有序高级和高效的I/O复用。 asyncioasyncio，异步I/O，事件循环，协同程序和任务该模块提供了使用协同程序编写单线程并发代码的基础结构，在套接字和其它资源上多路复用I/O访问，运行网络客户端和服务器以及其它相关基元。 asyncoreasyncore，异步套接字处理器该模块为编写异步套接字服务(客户端和服务端)提供了基本的基础结构。 asynchatasynchat，异步套接字命令/响应处理器该模块构建在asyncore之上，简化了异步客户端和服务端，并更容易处理其元素被任何字符串终止和长度可变的协议。 signalsignal，为异步事件设置处理器该模块提供了在Python中使用信号处理程序的机制。 mmapmmap，内存映射文件支持内存映射文件对象的行为与bytearray和文件对象类似。 网络数据处理本章介绍的模块，支持处理常用网络数据格式。 emailemail，一个email和MIME处理包该包是用于管理电子邮件信息的库，包含MIME和其它基于RFC 2822的消息文档。 MIME(Multipurpose Internet Mail Extensions)多用途互联网邮件扩展，是一种标准化的方式来标识文档的性质和格式。浏览器通常使用MIME类型(而不是文件扩展名)来确定如何处理文档。 栗子： 12345678910111213type/subtypetext/plaintext/htmlimage/jpegimage/pngaudio/mpegaudio/oggaudio/*video/mp4application/octet-stream… email.message表示一个电子邮件信息 email.parser解析电子邮件信息 email.generator生成MIME文档 email.policy政策对象 email.headerregistry自定义头对象 email.contentmanager管理MIME内容 email.mime从抓挠中创建电子邮件和MIME对象。 email.headerInternationalized headers email.charset表示字符集 email.encoders编码器 email.errors异常和缺陷类 email.utils各种各样的功能 email.iterators迭代器 jsonjson，JSON编码器和解码器JSON(JavaScript Object Notation)，是一个受JavaScript对象语法启发的轻量级的数据交换格式。 json只能包含如下Python数据类型的值： 字符串 整型 浮点数 布尔型 列表 字典 NoneType 123456import jsonJSONDATA = &apos;&#123;&quot;name&quot;: &quot;zhang&quot;, &quot;age&quot;: 21, &quot;likeFootball&quot;: true&#125;loadData = json.loads(JSONDATA)dumpData = json.dumps(jsonData) mailcapmailcap，mailcap文件处理mailcap文件用于配置感知MIME的应用程序(如邮件阅读器和Web浏览器)，如何对具有不同MIME类型的文件做出反应。 mailboxmailbox，以各种格式操作邮箱该模块定义了两个类: Mailbox和Message，用于访问和操作磁盘邮箱及其包含的邮件。 mimetypesmimetypes，将文件名映射到MIME类型该模块在文件名或URL和MIME类型之间进行转换。 base64base64，base16、base32，base64，base85数据编码该模块提供了将二进制数据编码为可打印的ASCII字符，并将这些编码解码回二进制数据的函数。 binhexbinhex，编码和解码binhex4文件 binasciibinascii，在二进制和ASCII之间进行转换该模块包含了许多方法，用于转换在二进制和各种ASCII编码的二进制表示之进行转换的方法。 quopriquopri，编码和解码MIME引用打印数据 uuuu，编码和解码uuencode文件该模块以uuencode格式对文件进行编码和解码，允许任意二进制数据仅通过ASCII连接进行传输。 结构化标记处理工具Python支持用以处理各种形式的结构化数据标记的模块。 标准通用标记语言，SGML() 超文本标记语言，HTML 扩展标记语言，XML htmlhtml，支持超文本标记语言该模块定义了用以操作HTML的实用程序。 html.parserhtml.parser，简单HTML和XHTML解析器该模块提供了一个类，用来解析HTML和XHTML格式的文本文件的基础。 html.entitieshtml.entities，HTML一般实体的定义 XML处理模块用于处理XML的Python接口被分组到xml包 网络协议本章介绍的模块，实现了网络协议并支持相关技术。 webbrowserwebbrowser - Interfaces for launching and remotely controlling Web browsers.webbrowser，便利的web浏览器控制器该模块提供了一个高级interface，允许向用户显示基于web的文档。 123import webbrowserwebbrowser.open(&apos;https://www.baidu.com&apos;) cgicgi，通用网关接口支持CGI 脚本的支持模块；该模块定义了许多用Python编写的CGI脚本的实用功能。 cgitbcgitb，CGI脚本的追溯管理器此模块为Python脚本提供了一个特殊的异常处理程序。 wsgirefwsgiref，WSGI功能和参考实现Web服务器网关接口(WSGI)，是Web服务器软件和Web应用程序(Python编写)之间的标准接口。拥有标准接口可以轻松使用支持WSGI和多个不同Web服务器的应用程序。 urllburllib模块，处理URL urllib.requesturllib.request模块，用于打开URL的可扩展库该模块定义了函数和类，用于在复杂的世界中打开URL——基本和身份认证，重定向，cookie等 urllib.responseurllib.response，响应类该模块定义了向接口这样的最小文件的函数和类。 urllib.parseurllib.parse，将URL解析为组件此模块定义了一个标准接口，用于在组件中分解统一资源定位符(URL)字符串，将组件重新组合为URL，并将相对URL转换为基本URL的绝对URL。 urlllib.errorurllib.error，由urllib.request引起的异常类该模块定义了由urllib.request引发的异常类。 urllib.robotparserurllib.robotparser，解析robot.txt此模块提供了一个RobotFileParser类，它回答了有关特定用户代理是否可以在发布robots.txt文件的Web站点上获取URL的问题。 httphttp，HTTP模块 http.clienthttp.client，HTTP协议客户端该模块定义了实现HTTP和HTTPS协议客户端的类。 ftplibftplib，FTP协议客户端此模块定义了FTP类和一些相关项。FTP类实现了FTP协议的客户端。 poplibpoplib，POP3协议客户端此模块定义了POP3类，它封装了一个到POP3服务器的连接，并实现了该协议。 imaplibimaplib，IMAP4协议客户端此模块定义了三个类，封装一个到IMAP服务器的连接，并实现IAP4客户端协议的大部分子集。 nntplibnntplib，NNTP协议客户端此模块定义了NNTP类，它实现网络新闻传输协议(NNTP)客户端。 smtplibsmtplib模块，SMTP协议客户端此模块定义了一个SMTP客户端会话对象，可使用SMTP守护进程发送邮件给任一互联网计算机。 12345678910111213import smtplib#send = smtplib.STMP('smtp.example.com', port=xxx)send = smtplib.SMTP_SSL(‘smpt.exmail.qq.com’, 465)send.helo()#(250, b'smtp.qq.com')#登录需要提前设置邮箱授权码，使用授权码作为密码登录send.login(user, passed)send.sendmail(from, to, message)send.quti() smtpdsmtpd，SMTP服务器该模块提供了几个类来实现SMTP服务器。 telnetlibtelnetlib，Telnet客户端此模块提供了一个telnet类，用于执行Telnet协议。 uuiduuid，UUID对象此模块提供了不可修改的UUID对象和uuid[1-5]函数。 socketserversocketserver，一个网络服务器的框架此模块简化了编写网络服务器的任务。 http.serverhttp.server，HTTP服务器此模块定义了类，用于实现HTTP服务器。 http.cookiehttp.cookie，HTTP状态管理此模块定义了类，用于抽象cookie概念(HTTP状态管理机制)。 http.cookiejarhttp.cookiejar，HTTP客户端的cookie处理此模块定义了类，用于自动处理HTTPcookie。 xmlrpcxmlrpc，XMLRPC服务器和客户端模块XML-RPC是一种远程过程调用方法，它使用通过HTTP传递的XML传输。 xmlrpc.clientxmlrpc.client，XML-RPC客户端访问 xmlrpc.serverxmlrpc.server，基本的XML-RPC服务器 ipaddressipaddress，IPv4/IPv6操作库此模块提供了创建、修改和操作IPv4和IPv6和网络的功能。 多媒体服务本章介绍的模块，实现了用于多媒体应用的各种算法和接口。 audioopaudioop，操作原始音频数据此模块包含一些对声音片段有用的操作。 aifcaifc，读写AIFF和AIFC文件此模块提供了对读写AIFF和AIFC文件的支持。 AIFF is Audio Interchange File Format 一种用于将数字音频样本存储在文件中的格式 AIFC是一种更新的格式，包括压缩音频数据 sunausunau，读写Sun AU文件此模块为Sun AU声音格式提供了一个便利的接口。 wavewave，读写WAV文件此模块为WAV声音格式提供了一个便利的接口。 chunkchunk，读取IFF分块数据此模块为读取使用EA IFF块的文件提供了接口。 colorsyscolorsys，颜色系统之家的转换此模块定义了计算机显示器RGB和其它三个坐标系统：YIQ, HLS, HSV中使用的RGB颜色空间中表示的颜色之间的颜色值的双向转换。 imghdrimghdr，确定图像类型此模块确定文件或字节流中包含的图像类型。 sndhdrsndhdr，确定声音文件类型此模块提供了实用功能，视图确定文件中的声音数据类型。 ossaudiodevossaudiodev，访问与OSS兼容的音频设备此模块允许你访问OSS(open sound system)音频接口。OSS是Linux和FreeBSD的标准音频接口。 语言环境本章介绍的模块，可帮助你编写独立于语言和语言环境的软件。 gettextgettext，多语言国际化服务此模块为你的Python模块和应用程序提供了国际化和本地化服务。 localelocale语言环境模块，打开对POSIX语言环境数据库和功能的访问。 程序框架本章介绍的模块，是基本上决定程序结构的框架。 turtleturtle，乌龟图形乌龟图形是向孩子们介绍编程的一种流行方式。 cmdcmd，支持面向行的命令解释器此类为编写面向行的命令解释器提供了一个简单的框架。 shlexshlex，简单的词法分析此类可以容易地编写词法分析器，以获得类似Unix shell的简单语法。 带有Tk的图形用户界面Tk/Tcl是Python的一部分。它提供了一个强大且独立于平台的窗口工具包，可供Python程序员使用的tkinter包。 Tcl(Tool Command Language)，是一种脚本语言 Tk，是基于Tcl的图形界面开发工具箱 tkintertkinter，与Tcl/Tk的Python接口此包是到Tk GUI工具箱的标准Python接口。 tkinter.ttktkinter.ttk，Tk主题小部件此模块提供了对Tk主题小部件集的访问。 tkinter.tixtkinter，Tk扩展小工具此模块提供了一组额外的小工具。 tkinter.scrolledtext滚动(scrolled)文本工具此模块提供了一个相同名称的类，它实现了基本的文本小部件，具有一个垂直滚动条，用于执行正确的事情。 IDELIDEL是Python的集成开发和学习环境。 其它GUI包 PyGObject PyGTK PyQt PySide wxPython 开发工具本章介绍的模块可帮助你你编写软件。 开发高质量软件的一种方法是在开发过程中为每个函数编写测试，并在开发过程中频繁运行这些测试。 typingtyping，支持类型提示此模块支持PEP 484指定的类型提示。 pydocpydoc，文档生成器和在线帮助系统此模块从Python模块自动生成文档，文档可作为控制台上的文本页面呈现，提供个Web浏览器或保存到HTML文件。 doctestdoctest模块，测试交互式Python示例此模块搜索类似于交互式Python会话的文本片段，然后执行这些会话以验证它们是否完全安装所示工作。 unittestunittest，单元测试框架 2to32to3，自动翻译Python2-3代码获取Python2源代码并应用一系列修复程序将其转换为有效的Python3代码。 testtest，用于Python的回归测试包此包包含了Python的所有回归测试。 test.supporttest.support，Python测试套件功能 调试和分析 调试器(Debugger)使你能遍历代码，分析堆栈并设置断点 分析器(Profiler)运行代码并给出执行时间的详细分类，使你识别程序中的瓶颈 bdbbdb，调试器框架此模块处理基本的调试器功能。 faulthandlerfaulthandler，转储Python回溯(traceback) pdbpdb，Python调试器此模块为Python程序定义了一个交互式源代码调试器。 Python分析器cProfile和profile提供了Python程序的确定性分析。 timeittimeit模块，测量小代码片段的执行时间此模块提供了一个简单的方法类计算一小段Python代码的时间。 123&gt;&gt;&gt; from timeit import Timer&gt;&gt;&gt; Timer('a,b = b,a', 'a=1; b=2').timeit()0.020318730967119336 tracetrace，追踪Python语句的执行此模块允许你追踪程序执行，生成带注释的语句覆盖列表，打印调用关系和在程序运行期间执行的函数列表。 tracemalloctracemalloc，追踪内存分配此模块是一个追踪由Python分配的内存块的调试工具。 软件打包和分发这些库可帮助你发布和安装Python软件。这些模块被设计来与PyPi结合使用，但它们也可以与本地索引服务器一起使用，或根本不需要任何索引服务器。 distutilsdistutils，构建和安装Python模块此软件包为构建和安装其它模块到Python提供支持。 ensurepipensurepip，引导pip安装程序此软件包支持将pip安装程序引导到现有的Python或虚拟环境中。 venvvenv，创建虚拟环境此模块为创建轻量虚拟环境提供支持，可选地域系统目录隔离。 zipappzipapp，管理可执行的python zip归档Python提供了管理创建包含Python代码的zip文件的工具。 Python服务组件本章介绍的模块，提供了与Python解释器及其与环境交互相关的各种服务。 syssys模块，系统特定的参数和功能此模块提供了对解释器使用或维护的一些变量以及与解释器交互的函数非访问。 命令行参数 12import sysprint(sys.argv) 错误输出重定向和程序终止(termination)sys模块还具有stdin, stdout, stderr属性。 12&gt;&gt;&gt; sys.stderr.write('Warning, log file not found starting a new one\n')Warning, log file not found starting a new one sysconfigsysconfig，提供对Python配置信息的访问此模块提供对Python配置信息的访问，如安装路径列表和当前平台相关的配置变量。 builtinsbuiltins，内建对象此模块提供了对Python所有内置标识符的直接访问。例如，builtins.open是内建函数open()的全名。 __main____main__，顶级脚本环境__main__是顶级代码执行的范围的名称。从标准输入、脚本或交互式提示读取时，模块的__name__设置为等于__main__ warningswarnings，警告控制警告信息通常在有用的情况下发出，以提醒用户程序中的某些条件，该条件不能保证引发异常并终止程序。Python程序员通过调用此模块中的warn()函数来发出警告。 contextlibcontextlib，with语句上下文实用程序此模块为涉及with语句的常见任务提供使用程序。 abcabc，抽象基类(Abstract Base Classes)此模块提供了在Python中定义抽象基类的基础结构。 atexitatexit，退出处理程序此模块定义了注册和注销清理函数的函数。 tracebacktraceback，打印或取回堆栈回溯该模块提供了一个标准接口，用来提取、格式化和打印Python程序的堆栈追踪。 __future____future__，未来的声明定义 gcgc，垃圾收集器接口(Garbage Collector interface)此模块为可选的垃圾收集器提供了一个接口。 inspectinspect，检查活对象(Inspect live objects)此模块提供了几个有用的功能来帮助获取有关活动对象的信息，如模块、类、函数、回溯、框架对象和代码对象。 sitesite，Site-specific configuration hook fpectlfpectl，浮点异常控制(Floating point exception control) 自定义Python解释器本章介绍的模块，允许编写类似于Python的交互式解释器接口。 codecode，解释器基本类此模块提供了一些工具，来实现Python的read-eval-print循环。 codeopcodeop，编译Python代码此模块提供了实用程序，用于模拟Python read-eval-print循环，像code模块中做的那样 导入模块本章介绍的模块，提供了导入其它Python模块和以自定义导入进程的hook的新方法。 zipimportzipimport，从zip归档文件导入模块此模块增加了从Zip格式的归档中导入Python模块和软件包的功能。通常不需要明确使用zipimport模块，内置导入机制将自动使用zip归档文件的路径(sys.path)。 pkgutilpkgutil，包扩展程序此模块为导入system提供实用程序，尤其是软件包的支持。 modulefindermodulefinder，查找脚本使用的模块此模块可用于确定脚本导入的模块集。 runpyrunpy，定位和执行Python模块此模块用于定位和运行Python模块，而不必先导入它们。 importlibimportlib，执行import此软件包有两个目的： 在Python源代码中提供import语句的实现(__import__函数) 实现import组件暴露在此软件包中，使用户更容易创建它们自己的定制对象参与导入过程 Python语言服务Python提供了许多模块来协助处理Python语言。包括： 标记 解析 语法分析 字节码反汇编 … parserparser，访问Python解析树此模块为python内部解析器和字节码编译器提供了一个接口。 astast，抽象语法树(Abstract Syntax Trees)此模块帮助Python应用程序处理Python抽象语法的树。 symtablesymtable，访问编译器的符号符号表由AST编译器在字节码生成之前生成。 symbolsymbol，用于Python解析的常量该模块提供了，表示解析树内部节点数值的常量。 tokentoken，与Python解析树一起使用的常量此模块提供了，表示解析树(终端令牌)的叶子节点数值的常量。 keywordkeyword，测试Python关键字此模块允许Python程序确定字符串是否为关键字。 tokenizetokenize，用于Python源代码的令牌器此模块为Python源代码提供了一个用Python实现的语言扫描器。 tabnannytabnanny，检查不明确的缩进(Detection of ambiguous indentation) pyclbrpyclbr，Python类浏览器支持此模块可用于，确定有关模块中定义的类、方法和顶级函数的一些限制信息。 py_compilepy_compile，编译Python源文件此模块提供了功能，从源文件生成字节码文件，以及当模块源文件作为脚本被调用时使用。 compileallcompileall，字节编译Python库此模块提供了实用功能来支持安装Python库。 disdis，用于Python字节码的反汇编器此模块支持通过反汇编来支持CPython字节码的分析。 pickletoolspickletools，pickle开发者的工具此模块包含了各种常量，涉及到pickle模块的细节，一些关于实现的冗长的评论，一些用于分析pickle数据的有用函数。 杂项服务本章介绍的模块，提供了在所有Python版本中可用的杂项(miscellaneous)服务。 formatterformatter，通用输出格式此模块支持两种接口定义，每种都有多种实现方式： 格式化接口 格式化接口所需的写入接口 Windows特定服务本章介绍的模块仅可在MS windows平台上可获取。 msilibmsillib，读写微软安装程序文件此模块支持创建Microsoft Installer (.msi) 文件。 msvcrtmsvcrt，MS VC++运行时的有用例程此函数可访问Windows平台上的一些有用功能。 winregwinreg，Windows注册表访问此模块将Windows注册表的API暴露给Python。 winsoundwinsound，Windows的声音播放接口此模块提供了对Windows平台提供的基本声音播放机器的访问。 Unix特定服务本章介绍的模块，提供了Unix操作系统(Unix-Like)特有的功能的接口。 posixposix，最基本的POSIX系统调用此模块提供了对由C标准和POSIX标准 标准化的操作系统功能的访问。 pwdpwd， The password database此模块提供了对Unix用户账户和密码数据库的访问。 1234import pwdpwd.getpwdnam('zhang')pwd.struct_passwd(pw_name='zhang', pw_passwd='x', pw_uid=1000, pw_gid=1000, pw_gecos='zhang', pw_dir='/home/zhang', pw_shell='/bin/bash') spwdspwd，The shadow password database此模块提供了对Unix shadow password database的访问。 grpgrp，The group database此模块提供了对Unix group database的访问。 cryptcrypt，Function to check Unix passwords此模块实现crypt(3)例程的接口，该例程是基于修改的DES算法的单向散列函数。 termiostermios，POSIX风格的tty控件此模块提供了一个接口，用于I/O控制的POSIX调用。 ttytty，终端控制函数此模块定义了将tty置入cbreak和raw模式的函数。 ptypty，伪(Pseudo)终端程序此模块定义了处理伪终端概念的操作： 启动另一个进程并以编程方式写入和读取其控制终端。 fcntlfcntl，The fcntl and ioctl system calls此模块对文件描述符执行文件控制和I/O控制。 pipespipes，shell pipelines的接口此模块定义了一个类来抽象管道的概念——从一个文件到另一个文件的一系列转换器。 resourceresource，资源使用信息此模块提供了测量和控制程序使用系统资源的基本机制。 syslogsyslog，Unix syslog library routines此模块为Unix系统日志库例程提供了一个接口。 第三方库基本上可将第三方库理解为开源库！ Awesome-Python: https://github.com/jobbole/awesome-python-cnPyPI: https://pypi.org/ 系统管理 sh Watchdog 数据库 PyMySQL pymongo redis PyMySQLPyMySQL：https://pypi.org/project/PyMySQL/ 首先创建数据库 1234567CREATE TABLE `users` ( `id` int(11) NOT NULL AUTO_INCREMENT, `email` varchar(255) COLLATE utf8_bin NOT NULL, `password` varchar(255) COLLATE utf8_bin NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_binAUTO_INCREMENT=1 ; 连接 1234567891011121314151617181920212223242526import pymysqlconnection = pymysql.connect( host='localhost', user='username', password='password', port=3306, db='DBname', charset='utf8', cursorclass=pymysql.cursors.DictCursor)try: with connection.cursor() as cursor: sql = "INSERT INTO `users` (`email`, `password`) VALUES (%s, %s)" cursor.execute(sql, ('webmaster@python.org', 'very-secret')) #commit to save connection.commit() with connection.cursor() as cursor: sql = "SELECT `id`, `password` FROM `users` WHERE `email`=%s" cursor.execute(sql, ('webmaster@python.org',)) result = cursor.fetchone() print(result)finally: connection.close() pyMongopyMongo Docs: https://api.mongodb.com/python/current/ pyMongo是一个用于使用MongoDB的工具的Python发行版，并且是从Python工作于MongoDB的推荐方式。 依赖 mongodb pyMongo 连接 1234567891011from pymongo import MongoClient#host and portclient = MongoClient('localhost', 27017)#url formatclient = MongoClient('mongodb://localhost:27017')#认证client = MongoClient(host='localhost', port=27017, username='user', password='pass') 获取数据库 12345db = client.$&#123;database&#125;#ordb = client['$&#123;database&#125;'] 获取集合 1234collection = db.$&#123;collection&#125;#orcollection = db['$&#123;collection&#125;'] 文档 123456789import datetimepost = &#123; '_id': 'post01', 'author': 'Zhang21', 'text': 'My first post!', 'tags': [ 'mongodb', 'python', 'pymongo' ], 'date': datetime.datetime.now()&#125; 插入文档 123456#新建集合$&#123;collection&#125; = db.posts$&#123;collection&#125;.insert_one(post)#已有集合collection.insert_one(post) 批量插入 123456789101112131415161718new_post = [ &#123; '_id': 'post02', 'author': 'Zhang02', 'text': '2nd post', 'tags': ['bulk', 'insert'], 'date': datetime.datetime.now() &#125;, &#123; '_id': 'post03', 'author': 'Zhang03', 'text': '3rd post', 'tags': ['bulk', 'insert'], 'date': datetime.datetime.now() &#125;]collection.insert_many(new_post) 获取文档 12345678910collection.find_one()collection.find_one(&#123; '_id': 'post01'&#125;)#orcollection.find_one(&#123;'author': 'Zhang21'&#125;)import pprintpprint.pprint(collection.find_one(&#123; '_id': 'post01'&#125;)) 查询多个文档 12345678910111213141516171819202122232425262728293031323334for post in collection.find(): pprint.pprint(post)&#123;'_id': 'post01', 'author': 'Zhang21', 'date': datetime.datetime(2018, 6, 14, 11, 13, 11, 372000), 'tags': ['mongodb', 'python', 'pymongo'], 'text': 'My first post!'&#125;&#123;'_id': 'post02', 'author': 'Zhang02', 'date': datetime.datetime(2018, 6, 14, 11, 34, 47, 93000), 'tags': ['bulk', 'insert'], 'text': '2nd post'&#125;&#123;'_id': 'post03', 'author': 'Zhang03', 'date': datetime.datetime(2018, 6, 14, 11, 34, 47, 93000), 'tags': ['bulk', 'insert'], 'text': '3rd post'&#125;#orfor post in collection.find(&#123;'tags': ['bulk', 'insert']&#125;): pprint.pprint(post)&#123;'_id': 'post02', 'author': 'Zhang02', 'date': datetime.datetime(2018, 6, 14, 11, 34, 47, 93000), 'tags': ['bulk', 'insert'], 'text': '2nd post'&#125;&#123;'_id': 'post03', 'author': 'Zhang03', 'date': datetime.datetime(2018, 6, 14, 11, 34, 47, 93000), 'tags': ['bulk', 'insert'], 'text': '3rd post'&#125; 删除文档 12345collection.delete_one(&#123;"_id" : "post01"&#125;)#删除多个collection.delete_many(&#123;"_id" : "post02", "_id" : "post03"&#125;) 计数 12345collection.count()3collection.count(&#123;'tags': ['bulk', 'insert']&#125;)2 **索引 1234result = db.profiles.create_index([('user_id', pymongo.ASCENDING)], unique=True)sorted(list(db.profiles.index_information()))[u'_id_', u'user_id_1'] redisThe Python interface to the Redis key-value store.redis模块: https://pypi.org/project/redis/ redis模块提供两个类Redis和StrictRedis用于实现Redis的命令: redis.Strictredis(推荐)StrictRedis用于实现大部分官方的命令，并使用官方的语法和命令 123help(redis.StrictRedis)__init__(self, host=&apos;localhost&apos;, port=6379, db=0, password=None, socket_timeout=None, socket_connect_timeout=None, socket_keepalive=None, socket_keepalive_options=None, connection_pool=None, unix_socket_path=None, encoding=&apos;utf-8&apos;, encoding_errors=&apos;strict&apos;, charset=None, errors=None, decode_responses=False, retry_on_timeout=False, ssl=False, ssl_keyfile=None, ssl_certfile=None, ssl_cert_reqs=None, ssl_ca_certs=None, max_connections=None) redis.Redis(不推荐)Redis是StrictRedis的子类，用于向后兼容旧版本的redis模块 连接 12345678910111213141516171819202122232425import redisr = redis.StrictRedis()#orr = redis.StrictRedis(host='localhost', port=6379, db=0, password='password')#字符串操作r.set('name', 'Zhang21')r.get('name')r.type('name')r.delete('name')#列表操作r.rpush('LIST', 'list-01', 'list-02')r.type('LIST')r.llen('LIST')#help(r.lrane)#lrange(name, start, end)lrange('LIST', 0, -1)#其它redis数据类型操作方法类同 Connection Pools假设Redis服务器与客户端分处在异地，虽然基于内存的Redis数据库有着超高的性能，但是底层的网络通信却占用了一次数据请求的大量时间，因为每次数据交互都需要先建立连接，假设一次数据交互总共用时30ms，超高性能的Redis数据库处理数据所花的时间可能不到1ms，也即是说前期的连接占用了29ms，连接池则可以实现在客户端建立多个链接并且不释放，当需要使用连接的时候通过一定的算法获取已经建立的连接，使用完了以后则还给连接池，这就免去了数据库连接所占用的时间。 1234567#help(redis.ConnectionPool)pool = redis.ConnectionPool()#orpool = redis.ConnectionPool(host='localhost', port=6379, db=0, passeord='password')r = redis.StrictRedis(connection_pool=pool) Web抓取 request BeautifulSoup selenium requests从Internet上下载文件和网页。 12345678910import requests, pprint#help(requests)r = request.get(&apos;https://www.baidu.com&apos;)r.status_coder.headersr.urlr.textpprint.pprint(r.text) beautifulsoup解析HTML 123pip3 install beautifulsoup4import bs4 栗子：12345678import requests, bs4r = request.get(&apos;https://www.baidu.com&apos;)soup = bs4.BeautifulSoup(r.text)type(soup)#soup.select()#soup.find() selenium启动并控制一个Web浏览器。selenium能够填写表单，并模拟鼠标在此浏览器找那个点击 1234from selenium import webdriverbrowser = webdriver.Firefox()browser.get(&apos;https://www.baidu.com&apos;) 文档处理 openpyxl PyPDF2 pytho-docx openpyxlopenpyxl is a Python library to read/write Excel 2010 xlsx/xlsm/xltx/xltm files. 关于Excel电子表格：一个Excel电子表格文档称为一个工作簿。一个工作簿保存在扩展名为.xlsx的文件中。每个工作簿可以包含多个表(工作表)。用户当前查看的表被称为活动表。每个表有一些列(地址为从A开始的字母)，一些行(地址从1开始的数字)。在特定行和列的方格被称为单元格。单元格形成的网格和数据构成了表。 1234567891011121314151617181920212223242526272829pip3 install openpyxlimport openpyxlworkbook = openpyxl.load_workbook(&apos;/tmp/test.xlsx&apos;)type(workbook)#&lt;class &apos;openpyxl.workbook.workbook.Workbook&apos;&gt;workbook.get_sheet_names()#[&apos;Sheet1&apos;, &apos;Sheet2&apos;, &apos;Sheet3&apos;]sheet1 = workbook.get_sheet_by_name(&apos;Sheet1&apos;)type(sheet1)sheet1.title#&apos;Sheet1&apos;workbook.get_active_sheet()#&lt;Worksheet &quot;Sheet1&quot;&gt;sheet1[&apos;A1&apos;].value#&apos;1A&apos;sheet1[&apos;A1&apos;].row#1sheet1[&apos;A1&apos;].colume#Asheet1.cell(row=2, column=2).value#2B PyPDF2PDF和Word文档是二进制文件，它们比文本文件要复制得多。 1234567891011pip3 install PyPDF2import PyPDF2pdfFile = open(&apos;/tmp/test.pdf&apos;, &apos;rb&apos;)pdfReader = PyPDF2.pdfFileReader(pdfFile)pdfWriter = PyPDF2.pdfFileWriter()page = pdfReader.getPage()page.extractText() python-docx利用python-docx模块，Python可创建和修改Word文档，它带有.docx文件扩展名。 1234567891011121314151617181920212223242526pip3 insntall python-docximport docxdoc = docx.Document(&apos;/tmp/test.docx&apos;)len(doc.paragraphs)#paragraphs和run属性doc.paragraphs[0].textdoc.paragraphs[0].run[0].text#写入doc.add_paragraph(&apos;Add line01&apos;)doc.add_paragraph(&apos;Add line02&apos;).add_run(&apos;tail !&apos;)doc.save(&apos;/tmp/test.docx&apos;)#标题doc.add_heading(&apos;Header 0&apos;, 0)doc.add_heading(&apos;Header 4&apos;, 4)#分页doc.add_page_broke()#图像doc.add_picture(xxx) 图像处理 pillow(PIL) pillowPIL - the Python Imaging Library. 请了解RGB和CMYK颜色方式。 123pip3 install pillowimport PIL 日志处理 elasticsearch elasticsearchPython Elasticsearch Client pypi: https://pypi.org/project/elasticsearchgithub: https://github.com/elastic/elasticsearch-pydocs: https://elasticsearch-py.readthedocs.io 几个ES概念： index document type id 安装: 1pip3 install elasticsearch 栗子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475from datetime import datetimefrom elasticsearch import Elasticsearch#curl localhost:9200/?pretty#default http://localhost:9200es=Elasticsearch()es.info()#auth#es=Elasticsearch('https://url:port', http_auth=('elastic', 'passwd'))#es.info#sslfrom ssl import create_default_contextes = Elasticsearch('https://url:port', ssl_context=context, http_auth=('ealstic', 'passwd'))#es.index#es.create#es.update#es.delete#创建索引es.indices.create(index='my-index')#&#123;'acknowledged': True, 'shards_acknowledged': True, 'index': 'my-index'&#125;#curl localhost:9200/_cat/indices#添加或修改某个索引的文档格式es.index(index='my-index', doc_type='test-type', id=2018, body=&#123;'any': 'data', 'timestamp': datetime.now()&#125;)#es.create(index='my-index', doc_type='test-type', id=2018, body=&#123;'any': 'data', 'timestamp': datetime.now()&#125;)#&#123;'result': 'created', '_primary_term': 1, '_index': 'my-index', '_shards': &#123;'total': 2, 'failed': 0, 'successful': 1&#125;, '_type': 'test-type', '_id': '2018', '_version': 1, '_seq_no': 0&#125;#查看索引es.get(index='my-index', doc_type='test-type', id=2018)#&#123;'_index': 'my-index', '_source': &#123;'timestamp': '2018-07-18T11:34:49.573721', 'any': 'data'&#125;, '_type': 'test-type', 'found': True, '_id': '2018', '_version': 1&#125;#不指定id，es会自动生成，但查询时候需要iddata=&#123; 'timestamp': datetime.now(), 'name': 'zhang21', 'msg': 'Hello'&#125;es.index(index='my-index', doc_type='test-type', body=data)#&#123;'result': 'created', '_primary_term': 1, '_index': 'my-index', '_shards': &#123;'total': 2, 'failed': 0, 'successful': 1&#125;, '_type': 'test-type', '_id': 'C_vnq2QBmuTERb-Wz39W', '_version': 1, '_seq_no': 0&#125;es.get(index='my-index', doc_type='test-type', id='C_vnq2QBmuTERb-Wz39W')#&#123;'_index': 'my-index', '_source': &#123;'name': 'Zhang21', 'timestamp': '2018-07-18T13:40:04.005192', 'msg': 'Hello'&#125;, '_type': 'test-type', 'found': True, '_id': 'C_vnq2QBmuTERb-Wz39W', '_version': 1&#125;#查询es.search(index='my-index')#批量操作from elasticsearch import helperhelp(helper.bulk)#bulk()支持index, create, delete, upsate动作package=[]for i in range(5): rom=&#123; 'count': i, 'timestamp': datetime.now() &#125; package.append(row)actions=[ &#123; '_op_type': 'index', '_index': 'my-index', '_type': 'test-type', '_source': i &#125; for i in package]pprint(actions)helpers.bulk(es, actions)pprint(es.search(index='my-index')) 具体信息请查看文档！ 数据分析基于《Python Data Analysis》一书！强烈建议使用Anaconda安装Python和Jupyter。 ipython jupyter pandas numpy statsmodels matplotlib Anaconda site: doc: 参考: Anaconda 是一种Python语言的免费增值开源发行版，用于进行大规模数据处理, 预测分析, 和科学计算, 致力于简化包的管理和部署。Anaconda使用软件包管理系统Conda进行包管理。你可能已经安装了Python，那为什么还需要Anaconda？ Anaconda附带了一大批常用的数据科学包 Conda管理包 管理环境 安装到官网下载不同平台的包进行安装。 1234567891011wget https://repo.anaconda.com/archive/Anaconda3-5.2.0-Linux-x86_64.shbash ./Anaconda3-5.2.0-Linux-x86_64.sh#之后可设置安装路径和环境变量#查看conda --version#更新所有包conda upgrade --all 包管理conda is a tool for managing and deploying applications, environments and packages. 123456789101112131415161718192021#它会自动安装依赖#其实和pip差不多conda install &lt;package&gt;conda install requests=1.10.0conda install pandas numpy#卸载conda remove &lt;package&gt;#更新conda update &lt;package&gt;conda update &lt;package&gt; --all#列出conda list#搜索conda search 环境管理为不同项目创建不同的运行环境。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#conda create -h#创建环境#默认为 ~/.conda/envs/&lt;evn_name&gt;conda create -n &lt;env_name&gt; &lt;package_names&gt;conda create -n py3 pandas#指定Python版本conda create -n py3 python=3conda create -n py2 python=2conda create -n py36 python=3.6#使用环境source activate &lt;env_name&gt;#或conda activeate &lt;env_name&gt;#关闭环境source deactivate#或conda deactivate#自定义目录conda create -p /path/py2 python=2.7#删除环境conda env remove -n &lt;env_name&gt;#列出环境conda env list#查看环境库conda list -n &lt;env_name&gt;#环境变量#导出cond env export &gt; envName.yaml#或pip freeze &gt; evnName.txt#导入conda env update -f=/path/envName.yaml#或pip install -r /path/envName.txt#列出conda env list ipython site: github: pypi: Python Shell有很多弊端，所以使用功能更强大的ipython。ipython提供了丰富的工具包，可帮助你以交互的方式充分利用Python: 强大的交互式Shell Jupyter的内核 支持交互式数据可视化和GUI工具箱 灵活，可嵌入式的解释器，可加载到自己的项目中 使用方便，高性能的并行计算工具 安装: 1234567891011#bashsudo pip3 install ipython#使用Anacondaconda install ipython#启动ipythonPython 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 17:14:51)Type 'copyright', 'credits' or 'license' for more informationIPython 6.5.0 -- An enhanced Interactive Python. Type '?' for help jupyter site: github: pypi: Jupyter notebook是一种Web应用，能让用户将说明文本、数学方程、代码和可视化内容全部组合到一个易于共享的文档中。 安装 1234567891011121314#bashsudo pip3 install jupyter#Anacondaconda install jupyter#运行jupyter notebook --no-browser --ip=0.0.0.0#建议先设置密码jupyter notebook passwordjupyter notebook --no-browser --ip=192.168.31.119 --notebook-dir=/tmp/notebook 打开浏览器访问，输入密码： Anaconda虚拟环境目录： 栗子：]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elatic Stack]]></title>
    <url>%2F2018%2F04%2F15%2FElastic%2F</url>
    <content type="text"><![CDATA[参考： Elastic指南: https://www.elastic.co/guide/index.html Elasticsearch文档: https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html Logstash文档: https://www.elastic.co/guide/en/logstash/current/index.html Kibana文档: https://www.elastic.co/guide/en/kibana/current/index.html Filebeat文档: https://www.elastic.co/guide/en/beats/filebeat/index.html Metricbeat文档: https://www.elastic.co/guide/en/beats/metricbeat/current/index.html Lucence查询语法: https://wizardforcel.gitbooks.io/mastering-elasticsearch/content/chapter-1/114_README.html 环境： CentOS7.x86_64 Elastcisearch v6.2.3 Kibana v6.2.3 Logstash v6.2.3 Beats v6.2.3 综述开源的 Elastic Stack:能够安全可靠地获取任何来源、任何格式的数据，并且能够实时地对数据进行搜索、分析和可视化。 Elastic指的是elastic公司下的几款产品： Elasticsearch Logstash Kibana Beats X-Pack Elasticsearch 开放源码且自由使用 License: Apache License 2.0 GitHub: https://github.com/elastic/elasticsearch Doc: https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html 搜索、分析和存储您的数据。Elasticsearch 是基于 JSON 的分布式搜索和分析引擎，专为实现水平扩展、高可用和管理便捷性而设计。Elasticsearch 是一个分布式的 RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为 Elastic Stack 的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况。 基于Lucene。Lucene是一套用于全文检索和搜寻的开放源码程式库，由Apache软件基金会支持和提供。Lucene提供了一个简单却强大的应用程式介面，能够做全文索引和搜寻，在Java开发环境里Lucene是一个成熟的免费开放原始码工具；就其本身而论，Lucene是现在并且是这几年，最受欢迎的免费Java资讯检索程式库。 Logstash 开放源码且自由使用 GitHub: https://github.com/elastic/logstash Doc: https://www.elastic.co/guide/en/logstash/current/index.html 集中、转换和存储数据Logstash 是动态数据收集管道，拥有可扩展的插件生态系统，能够与 Elasticsearch 产生强大的协同作用。Logstash 是开源的服务器端数据处理管道，能够同时 从多个来源采集数据、转换数据，然后将数据发送到您最喜欢的 “存储库” 中。（我们的存储库当然是 Elasticsearch。） Kibana 开放源码且自由使用 GitHub: https://github.com/elastic/kibana Doc: https://www.elastic.co/guide/en/kibana/current/index.html 实现数据可视化Kibana 让您能够可视化 Elasticsearch 中的数据并操作 Elastic Stack，因此您可以在这里解开任何疑问：例如，为何会在凌晨 2:00 被传呼，雨水会对季度数据造成怎样的影响。 Beats 开放源码且自由使用 GitHub: https://github.com/elastic/beats Doc: https://www.elastic.co/guide/en/beats/libbeat/current/index.html Beats 是轻量型采集器的平台，从边缘机器向 Logstash 和 Elasticsearch 发送数据。Beats 平台集合了多种单一用途数据采集器。这些采集器安装后可用作轻量型代理，从成百上千或成千上万台机器向 Logstash 或 Elasticsearch 发送数据。 X-Pack Doc: https://www.elastic.co/guide/en/x-pack/current/index.html 一个程序包，带来丰富的可能性单就其自身而言，Elastic Stack 就是一款值得考虑的强大工具。X-Pack 将诸多强大功能集合到一个单独的程序包中，更将它带上了一个新的层次。X-Pack 是集成了多种便捷功能的单个插件 — security、alerting、monitoring、reporting、graph 探索和 machine learning — 您可以在 Elastic Stack 中放心地使用这些功能。 使用Dockerdocker hub里面有ELK的镜像，可以直接拉取使用。推荐使用官方ELK镜像。 我自己做了一个ELK的image，上传到了我的docker hub里。我自己做这个镜像不推荐，因为使用了centos7，导致了镜像很大，这应该避免。 在docker中运行centos7 直接拉取的centos没有systemd的权限，需要在运行添加docker run -id --privileged &lt;image-id&gt; /usr/sbin/init选项。 或者使用Docker Hub上CentOS提供的支持systemd的Dockerfile来构建centos: https://hub.docker.com/_/centos/其实Dockfile就是有这条命令CMD [&quot;/usr/sbin/init 123456789101112131415161718192021222324252627282930313233docker pull centosdocker image lsREPOSITORY TAG IMAGE ID CREATED SIZEcentos latest e934aafc2206 2 weeks ago 199MB#运行docker#此处如果没有/bin/bash的话，生成的container立马就停止了#端口映射什么的后面再弄docker run -d -i &lt;image-id&gt; /bin/bash#查看容器docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES27b10f5015be e934aafc2206 "/bin/bash" About an hour ago Up About an hour ecstatic_boyd#进入dockerdocke exec -it &lt;container-id&gt; /bin/bash#当然，你也可以运行SSHD，通过端口映射，连接到docker内#[root@27b10f5015be /]##在docker中安装各类需要的软件了#可能需要设置一下/etc/resolv.conf 将安装了各类软件的容器构建为一个新的镜像 12345678910111213141516171819202122232425262728293031323334#从运行的容器中重构镜像#docker commit -m "centos7+elk" &lt;container-id&gt; user/repo:tagdocker commit -m 'centos7+elk' 27b10f5015be zhang21/centos7:elk#查看新镜像docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEzhang21/centos7 elk 0b22d93f7353 16 minutes ago 1.04GBcentos latest e934aafc2206 2 weeks ago 199MB#运行新镜像docker run -id -p 80:80 9200:9200 &lt;image-id&gt; /bin/bash#此处遇到一个错，因为docker的网络是通过iptables来转发的，因此主机上不能关闭firewalld，不能无法启动容器#进入新容器docker exec -it &lt;container-id&gt; /bin/bash#此处无法使用systemctl，原因已写到前面#Failed to get D-Bus connection: Operation not permitted#获得systemd权限启动docker run -id --privileged -p 80:80 &lt;image-id&gt; /usr/sbin/init#进入docker exec -it &lt;container-id&gt; /bin/bash#启动Nginxsystemctl start nginx 将新镜像上传到Hub 我用的是Docker Hub免费版，当然线上的话可能是阿里云或腾讯云。 12345678docker login -u zhang21#上传镜像到我的Hubdocker push zhang21/centos7:elk#拉取镜像docker pull zhang21/centos7:elk 安装安装步骤： Elasticsearch Kibana Logstash Install X-Pack into Elasticsearch Install X-Pack into Kibana 安装ELKF需要依赖JDK（java），请先安装。我是直接使用的RPM包安装。 12345678910111213141516171819202122#安装Javayum install java-1.8.0-openjdk-headless-1.8.0.161-0.b14.el7_4.x86_64 -y#编写repovim /etc/yum.repo.d/elk.repo[elasticsearch-6.x]name=Elasticsearch repository for 6.x packagesbaseurl=https://artifacts.elastic.co/packages/6.x/yumgpgcheck=1gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearchenabled=1autorefresh=1type=rpm-md#安装yum install -y elasticsearch logstash kibana filebeat 由于elk默认将软件安装到/usr/share/下，因此我把它们的bin路径加入PATH。 123456789vim /etc/profileexport PATH=$PATH:/usr/share/elasticsearch/bin:/usr/share/kibana/bin:/usr/share/logstash/bin:/usr/share/elasticsearch/bin/x-pack:/usr/share/filebeat/bin#执行source /etc/profile ELKF使用RPM安装的布局说明： 主目录 /usr/share/elasticsearch /usr/share/kibana /usr/share/logstash /usr/share/filebeat 二进制文件 /usr/share/elasticsearch/bin /usr/share/kibana/bin /usr/share/logstash/bin /usr/share/filebeat/bin 配置文件 /etc/elastcisearch /etc/kibana /etc/logstash /etc/filebeat 环境变量 /etc/sysconfig/elasticsearch 插件 /usr/share/elastcisearch/plugins /usr/share/kibana/plugins 安装X-Pack 注意由于自动升级到Elastic v6.3自带了X-Pack，不需要额外安装。之前安装的一些插件会导致Elastic无法运行，请卸载这些插件。 123456elasticsearch-plugin listelasticsearch-plugin remove x-packkibana-plugin remove x-packlogstash-plugin remove x-pack 安装X-Pack前，请先安装ELK。请安装匹配版本的X-Pack。 Install X-Pack on Elasticsearch Install X-Pack on Kibana Install X-Pack on Logstash 启用或禁用X-Pack功能 有些功能默认开启，有些默认关闭。请在配置文件中查看详情。添加某些功能可能导致软件无法启动，请注意查看日志。 在以下文件中配置它们： elasticsearch.yml kibana.yml logstash.yml filebeat.yml X-Pack功能： 功能 描述 xpack.graph.enabled X-Pack图形功能 xpack.ml.enabled X-Pack机器学习功能 xpack.monitoring.enabled X-Pack监视功能 xpack.reporting.enabled X-Pack报告功能 xpack.security.enabled X-Pack安全功能 xpack.watcher.enabled X-Pack观察器 在ELK中启动X-Pack monitoring功能 123456789101112131415161718192021222324252627282930#xpack.graph.enabled#xpack.ml.enabled#xpack.monitoring.enabled#xpack.reporting.enabled#xpack.security.enabled#xpack.watcher.enabled#在Elasticsearch和kibana中禁用验证后，不用在logstash中输入，否则会报错。xpack.security.enabled: false#启用验证#具体可参考官方文档#在logstash.yml中配置xpack.monitoringxpack.monitoring.enabled: true#xpack.monitoring.elasticsearch.url: &quot;http://127.0.0.1:9200&quot;#xpack.monitoring.elasticsearch.username: logstash_system#xpack.monitoring.elasticsearch.password: logstash#在Filebeat中添加monitoringxpack.monitoring: enabled: true #elasticsearch: #url: &quot;http://localhost:9200&quot; #usernaem: &quot;elastic&quot; #password: &quot;elastic&quot; 安装：建议使用密码！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#Elastcisearch安装X-Packelasticsearch-plugin install x-pack#启动#9200, 9300端口#elasticsearch不能使用root启动，所以我把elastic用户修改为/bin/bashsu elasticsearchelasticsearch -d#elasticsearch#生成默认用户密码，此密码针对elastic和kibana用户#/usr/share/elasticsearch/bin/x-pack#将此加入PATHsetup-passwords auto#或手动输入密码setup-passwords interactiveelastic#elastickibana#kibanalogstash_system#logstash#Kibana安装X-Packkibana-plugin install x-pack#对kibana.yml添加用户和密码#此密码是前面默认生成的vim /etc/kibana/kibana.yml`elasticsearch.username: &quot;elastic&quot;elasticsearch.password: &quot;elastic&quot;#修改监听地址server.host: &quot;0.0.0.0&quot;logging.dest: /var/log/kibana/kibana.log#kibana日志默认是stdout#修改为/var/log/kibana/kibana.logmkdir /var/log/kibana#启动kibana#5601端口#kibana可用root启动kibana#或systemctl start kibana#Logstash安装X-Packlogstash-plugin install x-pack 启动ELK建议给他们加上密码！不知道为什么，我的ElasticStack都能用systemd来管理了！ 12#最便捷systemctl start elasticsearch logstash filebeat metricbeat heartbeat packetbeat auditbeat 123456789101112131415161718192021#Elasticsearchsu elasticsearch#elasticsearch，查看输出elasticsearch -d#kill -15 pid &amp;&amp; elasticsearch -d#Kibanakibana&amp;systemctl start kibana#kill -15 pid &amp;&amp; kibana&amp;#Logstash#logstash -f xxx.confsystemctl start logstash#Filebeat#filebeat -e -c filebeat.yml，查看输出信息systemctl start filebeat 启动时可能遇到的问题 can not run elasticsearch as root 专门建立一个管理ELK的用户，切换到此用户后运行，注意修改ELK相关目录权限 或者修改ELK各自用户的/etc/passwd，切换到对应用户后运行。注意权限 – su elasticsearch &amp;&amp; elasticsearch elasticsearch process is too low, increase to at least [65536] 12345678vim /etc/security/limits.conf* soft nofile 655350* hard nofile 655350ulimit -a 访问elasticsearch 123456$ip:9200#此处访问是需要用户名和密码的#使用前面X-Pack生成的默认用户名和密码elastic elastic#登录之后便可看到node，cluster相关信息 访问kibana 12#5601端口http://0.0.0.0:5601 启用xpack注意事项启用X-PACK后，请注意在kibana配置文件中认证Elasticsearch用户和密码，并且使用Elasticsearch的用户和密码登录Kibana的前端界面。 由于我使用kibana用户登录，导致很多地方访问Elasticsearch都没有权限。请注意。 这样使用Elasticsearch登录后，便可以之间在Dev Tools中通过REST API获取和更新相关信息，并且创建和管理相关用户和角色。 安装Filebeat由于前面我们添加了ELK-repo，所以这里我们可以直接安装。 12345678yum install -y filebeat#开启X-Pack monitor#默认关闭vim /etc/filebeat/filebeat.ymlxpack.monitoring.enabled: true 修改ELK jvm内存大小在此版本中，可直接在配置文件目录下的jvm.options里修改JVM 内存大小。 12345678910111213#最小-Xms#最大-Xmxvim /etc/elasticsearch/jvm.options-Xms4g-Xmx4g#其它如此 与Nginx结合使用将Kibana展现到Nginx上的话，便可以不对Kibana开放外网访问。 1234567891011121314151617181920212223242526272829303132333435363738#安装Nginxvim /etc/yum.repo.d/nginx.repo[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=0enabled=1yum install -y nginx nginx-mod-stream#配置vim /etc/nginx/conf.d/kibana.conf#可把IP换成kibana相应的域名#再将域名解析到此IPserver &#123; listen 80; server_name 172.16.129.150;#Kibana location / &#123; proxy_pass http://127.0.0.1:5601; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &apos;upgrade&apos;; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; &#125;&#125; 可能会遇到的问题 Nignx错误日志: Permission denied) while connecting to upstream 1234567891011sudo cat /var/log/audit/audit.log | grep nginx | grep denied#后来判断是SELinux的问题getenforcesetenforce 0#修改SELinuxvim /etc/selinux/configSELINUX=disabled Logstash文档 Logstash的pipeline有两个必须的元素： input 消耗来自source的数据 output 将修改后的数据写入destination 以及一个可选元素： filter 根据你的定义来修改数据 介绍Logstash是一个具有实时流水线(pipeling)功能的开源数据收集引擎。它可以动态统一来自不同source的数据，并将数据正常化的你的destination。 任何类型的事件都可以通过大量的输入、过滤和输出插件进行丰富和转换，通过本地编解码器进一步简化了摄取过程。 Logstash的能量具有强大的Elasticsearch和Kibana系统的水平可伸缩数据处理流水线。 Logstash喜欢的数据所有数据来者不拒！ Logs and Metrics 处理所有类型的日志数据 Apache Nginx Syslog 使用Filebeat享受互补的安全日志转发功能 从Ganglia, JMx, NetFlow和TCP,UDP收集metrics Web 将http request转换为events 分析Web服务 支持Webhook 通过轮询HTTP endpoint创建事件 通过Web API捕获健康状况、性能和其它类型的数据 数据存储和流从你已经拥有的数据中发现更多价值。 Sensors and IoT探索广泛的其它数据。 轻松丰富一切在摄取过程中清理并转换数据，以便在index或output时立即获得实时信息。Logstash具有许多聚合和突变以及模式匹配，地理映射和动态查找功能。 Grok是Logstash filter的金刚钻，用于从非结构化数据中派生出结构化数据 通过解析来自IP的地理坐标，标准化提起复杂性，简单K-V对和CSV数据，并通过本地查找或Elasticsearch查询进一步丰富你的数据，从而扩展你的视野 编解码器通常用于缓解JSON和多行事件等常见事件结构的处理 选择你的储藏室将数据放在最重要的位置。通过存储，分析和对数据采取行动，解锁各种downstream分析和操作用例。 Analysis Elasticsearch Data stores(MongoDB, Redis) Archiving HDFS S3 Monitoring Nagios Zabbix Ganglia Alerting Watcher(Elasticsearch) Email 入门安装，储藏，解析，汇聚多个Input/Output。 储藏第一个事件测试Logstash和运行一个基本的pipeline 12345logstash -e &apos;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123;&#125; &#125;&apos;#等待启动，输入hello world#Logstash将时间戳和主机名添加到message#2018-04-13T08:17:51.702Z zhang22 helloworld 启动logstsh时的一个问题： WARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash 虽然通过RPM安装Logstash存在/etc/logstash文件，但是还是会报错。 123cd /usr/share/logstash/binln -s /etc/logstash ./config 通过Logstash解析Logs前面我们创建了一个基本的Logstash pipeline来测试Logstash，但真正处理logs的Logstash pipeline不会这么简单，它可能会有多个input, filter, output。 本节利用一个Filebeat，将Nginx Web Logs作为Logstash pipeline的input，解析这些logs中创建的特定命名字段，并将解析的数据写入Elasticsearch集群。 配置Filebeat以发送Log Lines到Logstash 在创建Logstash pipeline之前，你将配置Filebeat以发送Log lines到Logstash。Filebeat从服务器上的文件收集日志，并将这些日志转发给Logstash实例进行处理。Filebeat专为可靠性和低延迟而设计。它占用的资源极少，beats input插件(默认安装)最大限度地减少了Logstash实例的资源需求。任何Beat框架编写的beat都可以讲事件数据发送到Logstash。 在你的data source主机上安装Filebeat。安装之后，配置filebeat.yml文件: 12345678910111213141516171819vim /etc/filebeat/filebeat.ymlfilebeat.prospectors:- type: log#需要处理的日志的路径，如Nginx paths: - /var/log/nginx/*.logoutput.logstash: hosts: [&quot;localhost:5044&quot;]#运行FilebeatFilebeat -e -c filebeat.yml -d &quot;publish&quot;#Filebeat将会尝试连接到5044端口，在Logstash以一个活动的beats plugin开始前，不会有任何应答。 为Filebeat Input配置Logstash 配置一个Logstash pipeline，使用beat input plugin接受来自beats的事件。格式如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455cd /etc/logstash/conf.dvim ./first-pipeline.confinput &#123;&#125;#filter部分可选filter &#123;&#125;output &#123;&#125;#实例input &#123; beats &#123; port =&gt; &quot;5044&quot; &#125;&#125;output &#123; stdout &#123; codec =&gt; dubydebug &#125;&#125;#验证配置logstash -f first-pipe.conf --config.tst_and_exit#消息2018-04-17T14:15:46.187+0800 ERROR pipeline/output.go:74 Failed to connect: dial tcp [::1]:5044: getsockopt: connection refused2018-04-17T14:15:46.607+0800 INFO log/harvester.go:241 File is inactive: /var/log/nginx/access.log. Closing because close_inactive of 5m0s reached.2018-04-17T14:15:46.607+0800 INFO log/harvester.go:241 File is inactive: /var/log/nginx/error.log. Closing because close_inactive of 5m0s reached.2018-04-17T14:15:46.923+0800 INFO log/harvester.go:241 File is inactive: /var/log/secure-20180409. Closing because close_inactive of 5m0s reached.2018-04-17T14:15:51.096+0800 INFO log/harvester.go:241 File is inactive: /var/log/secure-20180401. Closing because close_inactive of 5m0s reached.2018-04-17T14:15:52.687+0800 INFO log/harvester.go:241 File is inactive: /var/log/secure-20180415. Closing because close_inactive of 5m0s reached.#启动Logstash#修改配置后可动态载入logstash -f first-pipe.conf --config.reload.automatic#消息2018-04-17T14:18:41.542+0800 INFO [monitoring] log/log.go:124 Non-zero metrics in the last 30s &#123;&quot;monitoring&quot;: &#123;&quot;metrics&quot;: &#123;&quot;beat&quot;:&#123;&quot;cpu&quot;:&#123;&quot;system&quot;:&#123;&quot;ticks&quot;:150,&quot;time&quot;:159&#125;,&quot;total&quot;:&#123;&quot;ticks&quot;:450,&quot;time&quot;:468,&quot;value&quot;:450&#125;,&quot;user&quot;:&#123;&quot;ticks&quot;:300,&quot;time&quot;:309&#125;&#125;,&quot;info&quot;:&#123;&quot;ephemeral_id&quot;:&quot;84cbf5cd-dfff-4391-9631-2b8e77329696&quot;,&quot;uptime&quot;:&#123;&quot;ms&quot;:480009&#125;&#125;,&quot;memstats&quot;:&#123;&quot;gc_next&quot;:11030992,&quot;memory_alloc&quot;:6588088,&quot;memory_total&quot;:40882600&#125;&#125;,&quot;filebeat&quot;:&#123;&quot;harvester&quot;:&#123;&quot;open_files&quot;:5,&quot;running&quot;:8&#125;&#125;,&quot;libbeat&quot;:&#123;&quot;config&quot;:&#123;&quot;module&quot;:&#123;&quot;running&quot;:2&#125;&#125;,&quot;pipeline&quot;:&#123;&quot;clients&quot;:8,&quot;events&quot;:&#123;&quot;active&quot;:4118&#125;&#125;&#125;,&quot;registrar&quot;:&#123;&quot;states&quot;:&#123;&quot;current&quot;:10&#125;&#125;,&quot;system&quot;:&#123;&quot;load&quot;:&#123;&quot;1&quot;:4.86,&quot;15&quot;:4.41,&quot;5&quot;:4.53,&quot;norm&quot;:&#123;&quot;1&quot;:2.43,&quot;15&quot;:2.205,&quot;5&quot;:2.265&#125;&#125;&#125;&#125;&#125;&#125; 使用Grok filter plugin解析Web Logs 在某些时候，可能输出的日志信息的格式并不理想。你想要解析log以创建特定的命名字段。 grok过滤插件使你能够将非结构化的日志数据解析为结构化和可查询的内容。由于grok过滤器插件在传入的日志数据中查找模式，因此配置插件需要你作出关于如何识别你的用例。 你可以使用%{COMBINEDAPACHELOG} grok模式，它从如下模式的日志中构建行： 信息 Field Name IP Add clientip User ID ident User Auth auth timestamp timestamp HTTP Verb verb Request body request HTTP Status code respone Referer URL referer User agent agent 12345678910111213141516171819202122232425vim first-pipline.confinput &#123; beats &#123; port =&gt; &quot;5044&quot; &#125;&#125;filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot; &#125; &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125;&#125;#启动查看效果 通过Geoip过滤插件增强数据 除了解析日志数据以获得更好的搜索外，过滤插件还可从现有的数据中后去补充信息。geoip插件查找IP地址，从IP地址获取地理位置信息，并将该位置信息添加到日志中。 配置Logstash实例来使用geoip过滤插件: 12345678910111213141516171819202122vim first-pipeline.confinput &#123; beats &#123; port =&gt; &quot;5044&quot; &#125;&#125; filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot;&#125; &#125; geoip &#123; source =&gt; &quot;clientip&quot; &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125;&#125;#重启服务 索引数据到Elasticsearch 现在Web log已经被处理为指定的字段，现在Logstash pipeline便可以索引数据到一个Elasticsearch集群中。 1234567891011121314151617181920212223vim first-pipeline.confinput &#123; beats &#123; port =&gt; &quot;5044&quot; &#125;&#125; filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot;&#125; &#125; geoip &#123; source =&gt; &quot;clientip&quot; &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [ &quot;localhost:9200&quot; ] &#125;&#125;#重启服务 验证： 这里遇到一个错误： index_not_found_exception 这里要将logstash-$DATE反映索引的实际名称，也就是在通过下面的命令得到的logstash-2018.04.13。把我坑惨了！ 123456789101112131415curl -XGET &apos;localhost:9200/logstash-$DATE/_search?pretty&amp;q=response=200&apos;#索引名称使用的日期基于UTC，而不是Logstash正在运行的timezone#查看可用索引列表curl &apos;localhost:9200/_cat/indices?v&apos;health status index uuid pri rep docs.count docs.deleted store.size pri.store.sizeyellow open logstash-2018.04.13 dRW2veUgS2ObZmP3lepqsQ 5 1 154 0 266.6kb 266.6kbcurl -XGET &apos;localhost:9200/logstash-2018.04.13/_search?pretty&amp;q=response=200&apos; Kibana中的可视化效果： 拼接多个输入和输出插件你需要管理的信息通常来自多个不同的source，并且可能需要多个不同的destination来存储数据。Lostash pipeline可以使用多个输入和输出插件来处理这些需求。 官方文档中使用Twitter and Filebeat这两者作为Logstash input，并将信息输出到Elasticsearch和file。 配置Logstash实例使用Filebeat input plugin 配置Logstash实例写入Elasticsearch多节点(cluster) 配置Logstash pipeline将数据写入file 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#配置Filebeat发送Log Line到Logstashvim /etc/filebeat/filebeat.ymlfilebeat.prospectors:- type: log paths: - /var/log/*.log fields: type: syslogoutput.logstash: hosts: [&quot;localhost:5044&quot;]########################cd /etc/logstash/conf.dvim 2nd-pipeline.confinput &#123; twitter &#123; consumer_key =&gt; &quot;enter_your_consumer_key_here&quot; consumer_secret =&gt; &quot;enter_your_secret_here&quot; keywords =&gt; [&quot;cloud&quot;] oauth_token =&gt; &quot;enter_your_access_token_here&quot; oauth_token_secret =&gt; &quot;enter_your_access_token_secret_here&quot; &#125; beats &#123; prot =&gt; &quot;5044&quot; &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;hosts1:port1&quot;, &quot;host2:port2&quot;...] &#125; file &#123; path =&gt; &quot;/path/to/target/file&quot; &#125;&#125;#重启服务#测试，Replace $DATE with the current date, in YYYY.MM.DD format.curl -XGET &apos;localhost:9200/logstash-$DATE/_search?pretty&amp;q=fields.type:syslog&apos; Input输入插件可以使特定的事件源由Logstash读取。 可用的输入插件：我只列出了常见的，具体请参考: https://www.elastic.co/guide/en/logstash/current/input-plugins.html 插件 描述 beats 从Elastic框架接收事件 couchdb_changes 从CouchDB的_changesURI流式传输事件 dead_letter_queue 从Logstash的dead letter queue读取事件 elasticsearch 从Elasticsearch集群中读取查询结果 exec 抓取shell命令的输出作为事件 file 来自文件的流事件 github 从GitHub webhook读取事件 heartbeat 为测试生成心跳事件 http 通过HTTP/HTTPS接收事件 http_poller 解码HTTP API输出为事件 imap 从IMAP服务器读取邮件 jmx 通过JVM从java程序检索标准 kafka 从kafka中读取事件 log4j 通过TCP socket从Log4j对象读取事件 pipe 从长时间运行的命令管道中获取流事件 rabbitmq 从Redis实例读取事件 sqlite 基于SQLite数据库中的行创建事件 stdin 从标准输入中读取事件 syslog 读取系统日志作为事件 tcp 从TCP socket读取事件 udp 从UDP读取事件 unix 通过Unix socket读取事件 websocket 从一个websocket读取事件 input filter通用选项: Setting Input type Required add_field hash No codec codec No enable_metric boolean No id string No tags array No type string No add_field添加一个字段到一个事件，默认值为{} codec用于输入数据的编解码器。默认值是plain enable_metric为特定插件实例禁用或启用度量标准日志记录，默认值为true id为插件配置添加一个唯一的ID，如果未指定，Logstash会自动生成一个 tags为事件添加任意数量的任意标签 type为所有input处理的事件添加一个type beats此插件使Logstash能够从Elasticsearch框架中接收事件。 栗子： 123456789101112131415input &#123; beats &#123; port =&gt; 5044 &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; &quot;localhost:9200&quot; #hosts =&gt; [&quot;hosts1&quot;, &quot;hosts2&quot;, ...] manage_template =&gt; false index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;[@metadata][version]&#125;-%&#123;+YYYY.MM.dd&#125;&quot; document_type =&gt; &quot;%&#123;[@metadata][type]&#125;&quot; &#125;&#125; Beats Input配置项： Setting Input_type Required cipher_suites array No client_inactivity_timeout number No host string No include_codec_tag boolean No port number Yes ssl boolean No ssl_certificate a valid filesystem path No ssl_certificate_authorities array No ssl_handshake_timeout number No ssl_key a valid filesystem path No ssl_key_passphrase password No ssl_verify_mode string, one of [none, peer,force_peer] No tls_max_version number No tls_min_version number No elasticsearchElasticsearch Input配置项： Setting Input_type Required ca_file a valid filesystem path No docinfo boolean No docinfo_fields array No docinfo_target string No hosts array No index string No password password No query string No schedule string No scroll string No size number No ssl boolean No user string No 栗子： 1234567891011121314151617input &#123; elasticsearch &#123; hosts =&gt; &quot;es.production.mysite.org&quot; index =&gt; &quot;mydata-2018.09.*&quot; query =&gt; &apos;&#123; &quot;query&quot;: &#123; &quot;query_string&quot;: &#123; &quot;query&quot;: &quot;*&quot; &#125; &#125; &#125;&apos; size =&gt; 500 scroll =&gt; &quot;5m&quot; docinfo =&gt; true &#125;&#125;output &#123; elasticsearch &#123; index =&gt; &quot;copy-of-production.%&#123;[@metadata][_index]&#125;&quot; document_type =&gt; &quot;%&#123;[@metadata][_type]&#125;&quot; document_id =&gt; &quot;%&#123;[@metadata][_id]&#125;&quot; &#125;&#125; exec定期运行shell命令，并抓取整个输出为事件。 栗子： 123456input &#123; exec &#123; command =&gt; &quot;ls&quot; interval =&gt; 30 &#125;&#125; exec Input配置项： Setting Input_type Required command string Yes interval number No schedule string No 此调度表示方法如同Linux中定时任务* 5 * 1-3 *。 file从文件读取流事件。 file input配置项： Setting Input_type Required close_older number No delimiter string No discover_interval number No exclude array No ignore_older number No max_open_files number No path array Yes sincedb_path string No sincedb_write_interval number No start_position string, one of [“beginning”, “end”] No stat_interval number No githubgithub input配置项： Setting Input_type Required drop_invalid boolean No ip string No port number Yes secret_token string No kafkahttps://www.elastic.co/guide/en/logstash/current/plugins-inputs-kafka.html redis从redis实例读取事件，它支持redis的channel和list类型。 redis input配置项： Setting Input_type Required batch_count number No data_type string, one of [list,channel,pattern_channel] Yes db number No host string No path string No key string Yes password password No port number No ssl boolean No threads number No timeout number No sqlite栗子： 1234567891011input &#123; sqlite &#123; path =&gt; &quot;/tmp/example.db&quot; type =&gt; weblogs &#125;&#125;output &#123; stdout &#123; debug =&gt; true &#125;&#125; sqlite input配置项： Setting Input_type Required batch number No exclude_tables array No path string Yes stdin syslog栗子： 12345678input &#123; syslog &#123; port =&gt; 12345 codec =&gt; cef syslog_field =&gt; &quot;syslog&quot; grok_pattern =&gt; &quot;&lt;%&#123;POSINT:priority&#125;&gt;%&#123;SYSLOGTIMESTAMP:timestamp&#125; CUSTOM GROK HERE&quot; &#125;&#125; syslog input配置项： Setting Input_type Required facility_labels array No grok_pattern string No host string No locale string No port number No proxy_protocol boolean No severity_labels array No syslog_field string No timezone string No use_labels boolean No tcp栗子： 123456input &#123; tcp &#123; port =&gt; 12345 codec =&gt; json &#125;&#125; tcp input配置项： Setting Input_type Required host string No mode string, one of [server, client] No port number Yes proxy_protocol boolean No ssl_cert a valid file system path No ssl_enable boolean No ssl_extra_chain_certs array No ssl_key a valid file system path No ssl_key_passphrase password No ssl_verify boolean No udp unix websocket Output输出将事件数据发送到特定的目标。输出是事件管道的最后阶段。 输出列表： boundary circonus CSV datadog Elasticsearch email exec file gelf ganglia http/https influxdb irc kafka librato loggly lumberjack metriccatcher mongodb nagios opentsdb pipe rabbitmq redis redmine stdout syslog tcp udp websocket zabbix output通用配置项： Setting Input type Required codec codec No enable_metric boolean No id string No codec用于输出数据的编解码器，默认值是json_lines enable_metric为特定插件实例启用或禁用度量日志记录，默认值是true id为插件配置添加一个唯一的ID，如果未指定ID，Logstash会自动生成。 csvcsv output配置选项： Setting Input_type Required create_if_deleted boolean No csv_options hash No dir_mode number No fields array Yes file_mode number No filename_failure string No flush_interval number No gzip boolean No path string Yes spreadsheet_safe boolean No elasticsearchElasticsearch output配置项： Setting Input type Required action string No bulk_path string No cacert a valid filesystem path No doc_as upsert boolean No document_id string No document_type string No failure_type logging whitelist array No healthcheck_path string No hosts uri No http_compression boolean No index string No keystore a valid filesystem path No keystore_password password No manage_template boolean No parameters hash No parent string No password password No path string No pipeline string No pool_max number No pool_max per route number No proxy uri No resurrect_delay number No retry_initial interval number No retry_max_interval number No retry_on_conflict number No routing string No script string No script_lang string No script_type string, one of [inline, indexed, file] No script_var_name string No scripted_upsert boolean No sniffing boolean No sniffing_delay number No sniffing_path string No ssl boolean No ssl_certificate verification boolean No template a valid filesystem path No template_name string No template_overwrite boolean No timeout number No truststore a valid filesystem path No truststore_password password No upsert string No user string No validate_after inactivity number No version string No version_type string, one of [internal, external, external gt, external gte, force] No exec栗子： 1234567output &#123; if [type] == &quot;abuse&quot; &#123; exec &#123; command =&gt; &quot;iptables -A INPUT -s %&#123;clientip&#125; -j DROP&quot; &#125; &#125;&#125; exec output配置项： Setting Input type Required command string Yes quiet boolean No file栗子： 123456output &#123; file &#123; path =&gt; ... codec =&gt; line &#123; format =&gt; &quot;custom format: %&#123;message&#125;&quot;&#125; &#125;&#125; file output配置项： Setting Input type Required create_if_deleted boolean No dir_mode number No file_mode number No filename_failure string No flush_interval number No gzip boolean No path string Yes write_behavior string No kafka栗子： 123456output &#123; kafka &#123; codec =&gt; json topic_id =&gt; &quot;mytopic&quot; &#125;&#125; kafka output配置项： Setting Input type Required acks string, one of [0, 1, all] No batch_size number No bootstrap_servers string No buffer_memory number No client_id string No compression_type string, one of [none, gzip, snappy, lz4] No jaas_path a valid filesystem path No kerberos_config a valid filesystem path No key_serializer string No linger_ms number No max_request size number No message_key string No metadata_fetch_timeout_ms number No metadata_max_age_ms number No receive_buffer_bytes number No reconnect_backoff_ms number No request_timeout_ms string No retries number No retry_backoff_ms number No sasl_kerberos_service name string No sasl_mechanism string No security_protocol string, one of [PLAINTEXT, SSL, SASL PLAINTEXT, SASL SSL] No send_buffer_bytes number No ssl_key_password password No ssl_keystore_location a valid filesystem path No ssl_keystore_password password No ssl_keystore_type string No ssl_truststore_location a valid filesystem path No ssl_truststore_password password No ssl_truststore_type string No topic_id string Yes value_serializer string No mongodbmongodb output配置项： Setting Input type Required bulk boolean No bulk_interval number No bulk_size number No collection string Yes database string Yes generateId boolean No isodate boolean No retry_delay number No uri string Yes redis将Redis作为消息队列缓存能极大降低系统负载，减轻系统压力。 redis output配置项： Setting Input type Required batch boolean No batch_events number No batch_timeout number No congestion_interval number No congestion_threshold number No data_type string, one of [list, channel] No db number No host array No key string No password password No port number No reconnect_interval number No shuffle_hosts boolean No timeout number No redmine栗子： 1234567891011output &#123; redmine &#123; url =&gt; &quot;http://redmineserver.tld&quot; token =&gt; &apos;token&apos; project_id =&gt; 200 tracker_id =&gt; 1 status_id =&gt; 3 priority_id =&gt; 2 subject =&gt; &quot;Error ... detected&quot; &#125;&#125; redmine output配置项： Setting Input type Required assigned_to_id number No categorie_id number No description string No fixed_version_id number No parent_issue_id number No priority_id number Yes project_id number Yes ssl boolean No status_id number Yes subject string No token string Yes tracker_id number Yes url string Yes output栗子： 123output &#123; stdout &#123; codec =&gt; json &#125;&#125; syslogsyslog output配置： Setting Input type Required appname string No facility string No host string Yes message string No msgid string No port number Yes priority string No procid string No protocol string, one of [tcp, udp, ssl-tcp] No reconnect interval number No rfc string, one of [rfc3164, rfc5424] No severity string No sourcehost string No ssl_cacert a valid filesystem path No ssl_cert a valid filesystem path No ssl_key a valid filesystem path No ssl_key passphrase password No ssl_verify boolean No use_labels boolean No zabbixzabbix output配置项： Setting Input type Required multi_value array No timeout number No zabbix_host string Yes zabbix_key string No zabbix_server host string No zabbix_server port number No zabbix_value string No Filter https://www.elastic.co/guide/en/logstash/current/filter-plugins.html 过滤器插件对事件执行中介(intermediary)处理，过滤器通常根据事件的特征有条件的应用。 下面是Elastic支持的插件列表: 插件 描述 aggregate 汇总来自单个任务的多个事件的信息 alter 对mutate过滤器无法处理的字段进行常规更改 cidr 根据网络块列表检查IP地址 cipher 对事件应用或移除cipher(密码) clone 重复事件 csv 将csv(comma separated value)解析为单个字段 date 解析字段中的日期，以用作事件的Logstash timestamp de_dot Computationally expensive filter that removes dots from a field name dissect 使用分隔符将非结构化事件数据提取到字段中 dns 执行标准或反向DNS查询 drop 删除所有事件 elapsed 计算一对事件之间的经过时间 elasticsearch 将Elasticsearch中以前的日志事件的字段复制到当前事件中 environment 将环境变量存储为元数据子字段 extractnumbers 从字符串中提取数字 fingerprint 由一致的散列值的替换值的指纹字段 geoip 添加有关IP地址的地理信息 grok 将非结构化事件数据解析到字段中 i18n 从字段中删除特定字符 jdbc_static 使用从远程数据库预加载的数据来丰富事件 jdbc_streaming 用你的数据库数据丰富事件 json 解析JSON事件 json_encode 将字段序列化为JSON kv 解析键值对 metricize 处理包含多个度量标准的复杂事件并将它们分成多个事件，每个事件都包含一个度量标准 metrics 汇总指标(Aggregates metrics) mutate 对字段执行突变 prune 将基于字段列表的事件数据精简为黑名单或白名单 range 检查指定的字段是否在给定的大小或长度限制内 ruby 执行任意Ruby代码 sleep 休息一段指定的时间 split 将多行消息拆分成不同的事件 syslog_pri 解析syslog消息的优先字段 throttle 限制事件的数量 tld 用你在配置中指定的任何内容替换默认消息字段的内容 translate 根据散列或YAML文件，替换字段内容 truncate 截断长度超过给定长度的字段 urldecode 解码URL编码的字段 useragent 将用户代理字符串解析到字段中 uuid 为事件添加UUID xml 将XML解析到字段 所有过滤器都支持的配置选项： Setting Input_type Required add_field hash No add_tag array No enable_metric boolean No id string No periodic_flush boolean No remove_field array No remove_tag array No add_field如果此过滤器成功，添加任意字段到此事件。字段名称可以是动态的，并使用%{field}包含事件的部分内容 add_tag如果此过滤器成功，添加任意标签到此事件。标签可以是动态的，并使用%{field}语法包含事件的部分内容 enable_metric为特定插件实例启用/禁用度量标准日志记录 id为插件配置添加一个唯一的ID，如果没有指定ID，Logstash会生成一个。强烈建议在配置中设置此ID当你有多个相同类型的插件时，这特别有用 periodic_flush定期调用过滤器flush方法 remove_field如果此过滤器成功，从事件中移除任意字段 remove_tag如果此过滤器成功，从事件中移除任意标签 Aggregate此过滤器的目的是聚合属于同一任务的多个事件(通常是日志行)中可用的信息，并将最终聚合信息推送到最终任务事件中。 Aggregate Filter Configuration Options: Setting Input_type Required aggregate_maps_path string, a valid filesystem path No code string Yes end_of_task boolean No inactivity_timeout number No map_action string, one of [“create”, “update”, “create_or_update”] No push_map_as_event_on_timeout boolean No push_previous_map_as_event boolean No task_id string Yes timeout number No timeout_code string No timeout_tags array No timeout_task_id_field string No timeout_timestamp_field string No aggregate_maps_pathLogstash停止时存储聚合地图的文件路径，以及Logstash启动时加载的路径。如果未定义，聚合映射将不会存储在Logstash中，并且会丢失。 code使用当前事件执行更新map的代码；或使用当前的map执行更新事件的代码你将有一个可用的map variable 和 event variable end_of_task告诉过滤器该任务已结束，因此在代码执行后删除聚合map inactivity_timeout一个任务被认为已到期的秒数当某个任务超时时，其聚合map将被逐出必须小于timeout map_action create update create_or_update告诉过滤器如何处理聚合map push_map_as_event_on_timeout每次检测到任务超时时，它都会将任务集合映射推送为新的Logstash事件 push_previous_map_as_event每次聚合插件检测到新任务ID时，它会将先前的聚合映射推送为新的Logstash事件，然后为下一个任务创建新的空映射 task_id定义了关联日志的任务ID的表达式该值必须唯一标识任务 timeout time_code timeout_tags在生成超时事件添加的标记 timeout_task_id_field timeout_timestamp_field默认情况下，使用系统时间计算超时 栗子： 给定日志: 1234INFO - 12345 - TASK_START - startINFO - 12345 - SQL - sqlQuery1 - 12INFO - 12345 - SQL - sqlQuery2 - 34INFO - 12345 - TASK_END - end 过滤器: 12345678910111213141516171819202122232425262728293031filter &#123; grok &#123; match =&gt; [ &quot;message&quot;, &quot;%&#123;LOGLEVEL:loglevel&#125; - %&#123;NOTSPACE:taskid&#125; - %&#123;NOTSPACE:logger&#125; - %&#123;WORD:label&#125;( - %&#123;INT:duration:int&#125;)?&quot; ] &#125; if [logger] == &quot;TASK_START&quot; &#123; aggregate &#123; task_id =&gt; &quot;%&#123;taskid&#125;&quot; code =&gt; &quot;map[&apos;sql_duration&apos;] = 0&quot; map_action =&gt; &quot;create&quot; &#125; &#125; if [logger] == &quot;SQL&quot; &#123; aggregate &#123; task_id =&gt; &quot;%&#123;taskid&#125;&quot; code =&gt; &quot;map[&apos;sql_duration&apos;] += event.get(&apos;duration&apos;)&quot; map_action =&gt; &quot;update&quot; &#125; &#125; if [logger] == &quot;TASK_END&quot; &#123; aggregate &#123; task_id =&gt; &quot;%&#123;taskid&#125;&quot; code =&gt; &quot;event.set(&apos;sql_duration&apos;, map[&apos;sql_duration&apos;])&quot; map_action =&gt; &quot;update&quot; end_of_task =&gt; true timeout =&gt; 120 &#125; &#125;&#125; Alteralter filter允许对未包含在正常变异过滤器中的字段进行一般更改。 安装: 1logstash-plugin install logstash-filter-alter 配置项: Setting Input type Required coalesce array No condrewrite array No condrewriteother array No coalesce将file_name的值设置为其参数的第一个非空表达式 condrewrite如果实际内容等于预期内容，则将字段内容更改为指定值 condrewriteother如果另一个字段内容等于预期内容，则将字段内容更改为指定值 cidrCIDR filter用于检查时间中的IP地址与可能包含它的网络块列表。可以针对多个网络检查多个地址，任何匹配都可以成功。成功后，可将其它标记/字段添加到事件中。 配置项: Setting Input_type Required address array No network array No network_path a valid filesystem path No refresh_interval number No separator string No address要检查的IP地址 network要检查的IP网络 network_path包含过滤器应检查的网络的外部文件的完整路径 refresh_interval检查外部文件的更新频率 seperator从network_path指定的外部文件解析网络的分隔符 csvcsv filter处理包含csv数据的事件字段，解析它，并将其存储为单个字段此过滤器还可解析使用任何分隔符的数据，而不仅仅是逗号 配置项: Setting Input_type Required autodetect_column_names boolean No autogenerate_column_names boolean No columns array No convert hash No quote_char string No separator string No skip_empty_columns boolean No skip_empty_rows boolean No skip_header boolean No source string No target string No autodetect_column_names是否应该从标题列自动检测列名称，默认false autogenerate_column_names是否应该自动生成列名，默认true。如果设置为false，那么没有指定header的列将不会被解析 columns列名称的列表 convert应用于列的数据类型转换的集合，可能的转换: integer, float, date, date_time, boolean quote_char用于引用csv字段的字符，默认&quot; separator列分隔符值。默认值comma, skip_empty_columns是否应该跳过空列，默认false skip_empty_rows是否应该跳过空行，默认false skip_header是否应该跳过header，默认false source源字段值中的csv数据将被扩展为数据结构 target放置数据的目标字段 datedate filter从字段中解析日期，然后使用该日期或时间戳作为事件的Logstash时间戳。它对事件排序和回填旧数据尤其重要。在没有此过滤器的情况下，如果timestamp尚未在事件中设置，则Logstash将根据首次查看事件是(input time)选择一个时间戳。 date filter配置项： Setting Input_type Required locale string No match array No tag_on_failure array No target string No timezone string No locale使用POSIX语言标记指定用于日期解析的环境(locale)，如en,en_US如果未指定，则将使用平台默认值 match有字段名称和格式模式的数组，[ field, formats…] 如果时间字段有多种格式，你可这样做: 12345match =&gt; [ &quot;filed-name&quot;, &quot;MMM dd yyyy HH:mm:ss&quot;, &quot;MMM d yyyy HH:mm:ss&quot;, &quot;ISO8601&quot; ]嵌套字段表示[foo][bar] 有几个例外: ISO8601: 解析任何有效的ISO8601时间戳，如2011-04-19T03:44:01.103Z UNIX: 解析float/int Unix原子时间(s) UNIX_MS: 解析int Unix原子时间 TAI64N: 解析tai64n时间值 语法细节:用于解析日期和时间文本的语法使用字母来指示时间值的种类，以及重复的字母来指示该值的形式。 以下是可用于解析日期和时间的内容： y year yyyy完整年号，如2018 yy 两位数年份，如18 M month of the year M最小数字月份,1-12 MM两位数字月份，01-12 MMM缩写的月份文本，Jan, Feb... MMMM完整的月份文本，January, February... d day of the month d最小数字日，1, 2... dd两位数字日，01, 02... H hour of the day H最小数字小时，0, 1... HH两位数字小时，00, 01... m minutes of the hour m最小数字分钟，0, 1... mm两位数字分钟，00, 01... s seconds of the minute s最小数字秒数，0, 1... ss两位数字秒数，00, 01... S 秒的最大精度(毫秒)，附加零 S十分之一秒 SS百分之一秒 SSS千分之一秒 Z time zone offset or identity Z时区偏移量结构为HHmm(如上海)，+0800 ZZ时区偏移量结构为HH:mm，+08:00 ZZZ时区身份(如上海)，Asia/Shanghai z time zone names. Time zone names (z) cannot be parsed w week of the year w最小数字周数，1, 2... ww两位数字周数，01, 02... D day of the year e day of the week(number) E day of the week(text) E, EE, EEE星期几的缩写，Mon, Tue, Wed, Thu, Fri, Sat, Sun EEEE星期几的全文，Monday, Tuesday... 对于非格式化的语法，你需要在值的周围放置单引号字符。如”yyyy-MM-dd’T’HH:mm:ss” tag_on_failure没有成功匹配时，将值附加到tag字段，默认值[&quot;_dateparsefailure&quot;] target将匹配的timestamp存储到给定目标字段中。如果未提供，则默认更新事件的@timestamp字段 timezone指定用于日期分析的时区标准ID，如Asia/Shanghai dissectdissect filter是一种拆分操作。与对整个字符串应用一个分隔符的常规拆分操作不同，此操作将一组分隔符应用于字符串值。dissect不使用正则表达式，所以速度非常快。但是，如果文本结构因行而异，则Grok更适合。有一种混合的情况，dissect可用来结构可靠地重复部分，然后Grok用于余下的字段值，并具有更多的正则表达式可预测性和更少的整体工作。 一组字段和分隔符被称为dissection，它使用一组%来描述: 123field: %&#123;a&#125;delimiter: -%&#123;a&#125; - %&#123;b&#125; - %&#123;c&#125; dissect filter配置项 Setting Input type Required convert_datatype hash No mapping hash No tag_on_failure array No convert_datatype可以指定int, float数据类型转换。这些将在mapping发生后完成，如果没有mapping部分，请自由使用此设置。 12345678filter &#123; dissect &#123; convert_datatype =&gt; &#123; cpu =&gt; &quot;float&quot; code =&gt; &quot;int&quot; &#125; &#125;&#125; mappingA hash of dissections of field =&gt; value不要在值中使用具有转移的\n，它会被看做两个字符\+n+而不是实际的换行符。 12345678910filter &#123; dissect &#123; mapping =&gt; &#123; # using an actual line break &quot;message&quot; =&gt; &apos;&quot;%&#123;field1&#125;&quot; &quot;%&#123;field2&#125;&quot; &quot;%&#123;description&#125;&quot;&apos; &quot;description&quot; =&gt; &quot;%&#123;field3&#125; %&#123;field4&#125; %&#123;field5&#125;&quot; &#125; &#125;&#125; tag_on_failuredissection失败时，将值添加到tag字段。默认值为[&quot;_dissectfailure&quot;] geoipgeoip filter根据Maxmind GeoLite2数据库的数据，添加有关IP地址的地理位置信息。 此插件与GeoLite City Database数据库捆绑在一起。GeoLite2是免费的IP地址位置数据库，与MaxMind的GeoIP2数据库相比，不如其精确。如果需要使用捆绑的DeoLite之外的数据库，可从MaxMind下载它: https://dev.maxmind.com/geoip/geoip2/geolite2/ 如果GeoIP返回查找到的经度(latitude)和纬度(longitude)，则会创建[geoip][location]字段。 Geoip Filter配置项 Setting Inpu_type Required cache_size number No database a valid filesystem path No default_database_type City or ASN No fields array No source string Yes tag_on_failure array No target string No cache_size默认值为1000。GeoIP查询的成本非常高昂。缓存设置的越高，项目在缓存中的可能性就越大，并且此filter运行的越快。但是，如果设置得太高，则会耗费太多内存。如果缓存已满，则无法添加更多记录。尝试使用此选项的不同值来为数据集找到最佳性能。这个值必须大于0。 database地理数据库的文件路径，如果未指定，则默认为logstash自带的GeoLite2-City数据库。 default_database_type默认值是City。唯一可接受的值是City和ASN。 fields包含在事件中的geoip字段数组。可能的字段取决于数据库类型。 source包含要通过geoip映射的IP地址或主机名的字段。 tag_on_failure默认值为[&quot;_geoip_lookup_failure&quot;]. target默认值为geoip.指定Logstash应该存储的geoip数据的字段。 grokParse arbitrary text and structure it.Grok是将非结构化日志数据解析为结构化和可查询的好方法。 它非常适用于syslog, apache or webserver logs, mysql logs以及通常为人类而不是计算机编写的任何日志格式。 默认情况下，Logstash ship附带了大约120种模式。它们在这: https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns要grok某类日志文件的时候，可以先到上面的地址查看有无对应的模式。然后复制对应内容到patterns_dir下，再在filter中使用。当然，你也可以自定义模式来匹配你的日志。在这测试: http://grokdebug.herokuapp.com Grok filter配置项 Setting Input_type Required break_on_match boolean No keep_empty_captures boolean No match hash No named_captures_only boolean No overwrite array No pattern_definitions hash No patterns_dir array No patterns_files_glob string No tag_on_failure array No tag_on_timeout string No timeout_millis number No break_on_matchBreak on first match. grok的第一个成功的匹配将导致filter结束。如果你想grok尝试所有的模式，请将其设置为false。默认值为true。 keep_empty_captures默认值为false。如果为true，则将空捕获保留为事件字段。 matchfield ⇒ value的散列匹配，默认值为{} 123filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; [ &quot;Duration: %&#123;NUMBER:duration&#125;&quot;, &quot;Speed: %&#123;NUMBER:speed&#125;&quot; ] &#125; &#125;&#125; named_captures_only默认值为true。如果为true，只保存来自grok的命名捕获。 overwrite要覆盖的字段，这使你可覆盖已存在的字段中的值。 123456filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;SYSLOGBASE&#125; %&#123;DATA:message&#125;&quot; &#125; overwrite =&gt; [ &quot;message&quot; ] &#125;&#125; pattern_definitions默认值为{}模式名称和模式元组的散列，用于定义当前过滤器要使用的自定义模式。匹配现用名称的模式将覆盖预先存在的定义。 patterns_dir默认值为[]logstash默认提供了一堆模式，除非添加额外模式，否则不需要自定义模式。你可以使用此设置指向多个模式目录。grok将读取与patterns_files_glob匹配的目录汇总的所有文件，并假定它为模式文件。 1patterns_dir =&gt; [&quot;/opt/logstash/patterns&quot;, &quot;/opt/logstash/extra_patterns&quot;] patterns_files_glob默认值为&quot;*&quot;Glob模式，用于从patterns_dir目录中选择模式文件。 tag_on_failure默认值为[&quot;_grokparsefailure&quot;]匹配没有成功时，将值添加到tags字段。 tag_on_timeout默认值为&quot;_groktimeout&quot;如果grok正则表达式超时，则应用此tag. timeout_millis默认值为30000尝试在这段时间后终止正则表达式。设置为0以禁用超时。 基础知识Grok工作方式，将文本模式组合成与你的日志模式相匹配的内容。 Grok模式的语法为 %{SYNTAX:SEMANTIC} SYNTAX, 文本匹配的模式的名称 SEMANTIC, 正在匹配的文本的标识符 1%&#123;NUMBER:duration&#125; %&#123;IP:client&#125; 你也可以将数据类型转换添加到Grok模式。默认情况下，所有的语义(semantic)都保存为字符串(strings)。如果你想转换语义的数据类型，如将string转换为int。例如%{NUMBER:num:int}将num语义从string转换为integer。当前情况下，只支持转换为int和float. 12345678910111213141516日志格式55.3.244.1 GET /index.html 15824 0.043grok pattern grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;IP:client&#125; %&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; %&#123;NUMBER:bytes&#125; %&#123;NUMBER:duration&#125;&quot; &#125; &#125;grok filter之后的格式client: 55.3.244.1method: GETrequest: /index.htmlbytes: 15824duration: 0.043 正则表达式Grok位于正则表达式之上，所以任何正则表达式在grok中都是有效的。Regular Expression Library: https://github.com/kkos/oniguruma/blob/master/doc/RE 示例grok处理nginx/access.log日志:首先针对nginx.conf中日志格式来决定如何写logstash pattern 1234567891011121314mkdir /etc/logstash/patternsvim nginxNGINX_ACCESS %&#123;IPORHOST:clientip&#125; (?:-|(%&#123;WORD&#125;.%&#123;WORD&#125;)) %&#123;USER:ident&#125; \[%&#123;HTTPDATE:timestamp&#125;\] &quot;(?:%&#123;WORD:verb&#125; %&#123;NOTSPACE:request&#125;(?: HTTP/%&#123;NUMBER:httpversion&#125;)?|%&#123;DATA:rawrequest&#125;)&quot; %&#123;NUMBER:response&#125; (?:%&#123;NUMBER:bytes&#125;|-) %&#123;QS:referrer&#125; %&#123;QS:agent&#125; %&#123;QS:forwarder&#125;grok &#123; patterns_dir =&gt; &quot;/etc/logstash/patterns&quot; match =&gt; &#123; &quot;message&quot; =&gt; %&#123;NGINX_ACCESS&#125;&#125;&#125; grok debugger grok-patterns这是grok官方写得patterns，当然，你也可以自己写。就像Nginx日志那样！ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495USERNAME [a-zA-Z0-9._-]+USER %&#123;USERNAME&#125;EMAILLOCALPART [a-zA-Z][a-zA-Z0-9_.+-=:]+EMAILADDRESS %&#123;EMAILLOCALPART&#125;@%&#123;HOSTNAME&#125;INT (?:[+-]?(?:[0-9]+))BASE10NUM (?&lt;![0-9.+-])(?&gt;[+-]?(?:(?:[0-9]+(?:\.[0-9]+)?)|(?:\.[0-9]+)))NUMBER (?:%&#123;BASE10NUM&#125;)BASE16NUM (?&lt;![0-9A-Fa-f])(?:[+-]?(?:0x)?(?:[0-9A-Fa-f]+))BASE16FLOAT \b(?&lt;![0-9A-Fa-f.])(?:[+-]?(?:0x)?(?:(?:[0-9A-Fa-f]+(?:\.[0-9A-Fa-f]*)?)|(?:\.[0-9A-Fa-f]+)))\bPOSINT \b(?:[1-9][0-9]*)\bNONNEGINT \b(?:[0-9]+)\bWORD \b\w+\bNOTSPACE \S+SPACE \s*DATA .*?GREEDYDATA .*QUOTEDSTRING (?&gt;(?&lt;!\\)(?&gt;&quot;(?&gt;\\.|[^\\&quot;]+)+&quot;|&quot;&quot;|(?&gt;&apos;(?&gt;\\.|[^\\&apos;]+)+&apos;)|&apos;&apos;|(?&gt;`(?&gt;\\.|[^\\`]+)+`)|``))UUID [A-Fa-f0-9]&#123;8&#125;-(?:[A-Fa-f0-9]&#123;4&#125;-)&#123;3&#125;[A-Fa-f0-9]&#123;12&#125;# URN, allowing use of RFC 2141 section 2.3 reserved charactersURN urn:[0-9A-Za-z][0-9A-Za-z-]&#123;0,31&#125;:(?:%[0-9a-fA-F]&#123;2&#125;|[0-9A-Za-z()+,.:=@;$_!*&apos;/?#-])+# NetworkingMAC (?:%&#123;CISCOMAC&#125;|%&#123;WINDOWSMAC&#125;|%&#123;COMMONMAC&#125;)CISCOMAC (?:(?:[A-Fa-f0-9]&#123;4&#125;\.)&#123;2&#125;[A-Fa-f0-9]&#123;4&#125;)WINDOWSMAC (?:(?:[A-Fa-f0-9]&#123;2&#125;-)&#123;5&#125;[A-Fa-f0-9]&#123;2&#125;)COMMONMAC (?:(?:[A-Fa-f0-9]&#123;2&#125;:)&#123;5&#125;[A-Fa-f0-9]&#123;2&#125;)IPV6 ((([0-9A-Fa-f]&#123;1,4&#125;:)&#123;7&#125;([0-9A-Fa-f]&#123;1,4&#125;|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;6&#125;(:[0-9A-Fa-f]&#123;1,4&#125;|((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;)|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;5&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,2&#125;)|:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;)|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;4&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,3&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)?:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;3&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,4&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,2&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;2&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,5&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,3&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;1&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,6&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,4&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(:(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,7&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,5&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:)))(%.+)?IPV4 (?&lt;![0-9])(?:(?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5]))(?![0-9])IP (?:%&#123;IPV6&#125;|%&#123;IPV4&#125;)HOSTNAME \b(?:[0-9A-Za-z][0-9A-Za-z-]&#123;0,62&#125;)(?:\.(?:[0-9A-Za-z][0-9A-Za-z-]&#123;0,62&#125;))*(\.?|\b)IPORHOST (?:%&#123;IP&#125;|%&#123;HOSTNAME&#125;)HOSTPORT %&#123;IPORHOST&#125;:%&#123;POSINT&#125;# pathsPATH (?:%&#123;UNIXPATH&#125;|%&#123;WINPATH&#125;)UNIXPATH (/([\w_%!$@:.,+~-]+|\\.)*)+TTY (?:/dev/(pts|tty([pq])?)(\w+)?/?(?:[0-9]+))WINPATH (?&gt;[A-Za-z]+:|\\)(?:\\[^\\?*]*)+URIPROTO [A-Za-z]([A-Za-z0-9+\-.]+)+URIHOST %&#123;IPORHOST&#125;(?::%&#123;POSINT:port&#125;)?# uripath comes loosely from RFC1738, but mostly from what Firefox# doesn&apos;t turn into %XXURIPATH (?:/[A-Za-z0-9$.+!*&apos;()&#123;&#125;,~:;=@#%&amp;_\-]*)+#URIPARAM \?(?:[A-Za-z0-9]+(?:=(?:[^&amp;]*))?(?:&amp;(?:[A-Za-z0-9]+(?:=(?:[^&amp;]*))?)?)*)?URIPARAM \?[A-Za-z0-9$.+!*&apos;|()&#123;&#125;,~@#%&amp;/=:;_?\-\[\]&lt;&gt;]*URIPATHPARAM %&#123;URIPATH&#125;(?:%&#123;URIPARAM&#125;)?URI %&#123;URIPROTO&#125;://(?:%&#123;USER&#125;(?::[^@]*)?@)?(?:%&#123;URIHOST&#125;)?(?:%&#123;URIPATHPARAM&#125;)?# Months: January, Feb, 3, 03, 12, DecemberMONTH \b(?:[Jj]an(?:uary|uar)?|[Ff]eb(?:ruary|ruar)?|[Mm](?:a|ä)?r(?:ch|z)?|[Aa]pr(?:il)?|[Mm]a(?:y|i)?|[Jj]un(?:e|i)?|[Jj]ul(?:y)?|[Aa]ug(?:ust)?|[Ss]ep(?:tember)?|[Oo](?:c|k)?t(?:ober)?|[Nn]ov(?:ember)?|[Dd]e(?:c|z)(?:ember)?)\bMONTHNUM (?:0?[1-9]|1[0-2])MONTHNUM2 (?:0[1-9]|1[0-2])MONTHDAY (?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9])# Days: Monday, Tue, Thu, etc...DAY (?:Mon(?:day)?|Tue(?:sday)?|Wed(?:nesday)?|Thu(?:rsday)?|Fri(?:day)?|Sat(?:urday)?|Sun(?:day)?)# Years?YEAR (?&gt;\d\d)&#123;1,2&#125;HOUR (?:2[0123]|[01]?[0-9])MINUTE (?:[0-5][0-9])# &apos;60&apos; is a leap second in most time standards and thus is valid.SECOND (?:(?:[0-5]?[0-9]|60)(?:[:.,][0-9]+)?)TIME (?!&lt;[0-9])%&#123;HOUR&#125;:%&#123;MINUTE&#125;(?::%&#123;SECOND&#125;)(?![0-9])# datestamp is YYYY/MM/DD-HH:MM:SS.UUUU (or something like it)DATE_US %&#123;MONTHNUM&#125;[/-]%&#123;MONTHDAY&#125;[/-]%&#123;YEAR&#125;DATE_EU %&#123;MONTHDAY&#125;[./-]%&#123;MONTHNUM&#125;[./-]%&#123;YEAR&#125;ISO8601_TIMEZONE (?:Z|[+-]%&#123;HOUR&#125;(?::?%&#123;MINUTE&#125;))ISO8601_SECOND (?:%&#123;SECOND&#125;|60)TIMESTAMP_ISO8601 %&#123;YEAR&#125;-%&#123;MONTHNUM&#125;-%&#123;MONTHDAY&#125;[T ]%&#123;HOUR&#125;:?%&#123;MINUTE&#125;(?::?%&#123;SECOND&#125;)?%&#123;ISO8601_TIMEZONE&#125;?DATE %&#123;DATE_US&#125;|%&#123;DATE_EU&#125;DATESTAMP %&#123;DATE&#125;[- ]%&#123;TIME&#125;TZ (?:[APMCE][SD]T|UTC)DATESTAMP_RFC822 %&#123;DAY&#125; %&#123;MONTH&#125; %&#123;MONTHDAY&#125; %&#123;YEAR&#125; %&#123;TIME&#125; %&#123;TZ&#125;DATESTAMP_RFC2822 %&#123;DAY&#125;, %&#123;MONTHDAY&#125; %&#123;MONTH&#125; %&#123;YEAR&#125; %&#123;TIME&#125; %&#123;ISO8601_TIMEZONE&#125;DATESTAMP_OTHER %&#123;DAY&#125; %&#123;MONTH&#125; %&#123;MONTHDAY&#125; %&#123;TIME&#125; %&#123;TZ&#125; %&#123;YEAR&#125;DATESTAMP_EVENTLOG %&#123;YEAR&#125;%&#123;MONTHNUM2&#125;%&#123;MONTHDAY&#125;%&#123;HOUR&#125;%&#123;MINUTE&#125;%&#123;SECOND&#125;# Syslog Dates: Month Day HH:MM:SSSYSLOGTIMESTAMP %&#123;MONTH&#125; +%&#123;MONTHDAY&#125; %&#123;TIME&#125;PROG [\x21-\x5a\x5c\x5e-\x7e]+SYSLOGPROG %&#123;PROG:program&#125;(?:\[%&#123;POSINT:pid&#125;\])?SYSLOGHOST %&#123;IPORHOST&#125;SYSLOGFACILITY &lt;%&#123;NONNEGINT:facility&#125;.%&#123;NONNEGINT:priority&#125;&gt;HTTPDATE %&#123;MONTHDAY&#125;/%&#123;MONTH&#125;/%&#123;YEAR&#125;:%&#123;TIME&#125; %&#123;INT&#125;# ShortcutsQS %&#123;QUOTEDSTRING&#125;# Log formatsSYSLOGBASE %&#123;SYSLOGTIMESTAMP:timestamp&#125; (?:%&#123;SYSLOGFACILITY&#125; )?%&#123;SYSLOGHOST:logsource&#125; %&#123;SYSLOGPROG&#125;:# Log LevelsLOGLEVEL ([Aa]lert|ALERT|[Tt]race|TRACE|[Dd]ebug|DEBUG|[Nn]otice|NOTICE|[Ii]nfo|INFO|[Ww]arn?(?:ing)?|WARN?(?:ING)?|[Ee]rr?(?:or)?|ERR?(?:OR)?|[Cc]rit?(?:ical)?|CRIT?(?:ICAL)?|[Ff]atal|FATAL|[Ss]evere|SEVERE|EMERG(?:ENCY)?|[Ee]merg(?:ency)?) json这是一个json解析过滤器。 Json Filter配置项 Setting Input_type Required skip_on_invalid_json boolean No source string Yes tag_on_failure array No target string No skip_on_invalid_json默认值是false.允许跳过无效json上的过滤器。 sourcejson filter的配置如，从message字段中解析json 12345filter &#123; json &#123; source =&gt; &quot;message&quot; &#125;&#125; target定义放置解析数据的目标字段。如果目标字段已存在，则它会被覆盖。 12345filter &#123; json &#123; target =&gt; &quot;doc&quot; &#125;&#125; kv此过滤器有助于自动解析key=value类型的消息。这对于postfix, iptables和倾向于key=value语法类型的日志非常有用。 123456789101112#beforeip=1.2.3.4 error=REFUSEDfilter &#123; kv &#123;&#125;&#125;#afterip: 1.2.3.4error: REFUSED kv filter配置项 Setting Input_type Required allow_duplicate_values boolean No default_keys hash No exclude_keys array No field_split string No include_brackets boolean No include_keys array No prefix string No recursive boolean No remove_char_key string No remove_char_value string No source string No target string No transform_key string, one of [“lowercase”, “uppercase”, “capitalize”] No transform_value string, one of [“lowercase”, “uppercase”, “capitalize”] No trim_key string No trim_value string No value_split string No allow_duplicate_values默认值为true.用于删除重复 键/值对的布尔选项。 default_keys默认值为{}.一个散列，用于指定在解析源字段中不存在的键时应添加到事件中的默认值及其值。 exclude_keys默认值为[].一个数组，用于指定不应添加到事件中的解析键。默认情况下，没有键被排除。 field_split默认值为&quot; &quot;.用作解析出键值对后的单字符字段分隔符的字符串。 12345678#栗子name=zhang21&amp;age=25&amp;email=ab123@gamil.comfilter &#123; kv &#123; field_split =&gt; &quot;&amp;&quot; &#125;&#125; field_split_pattern一个正则表达式，用作字段分隔符来解析键值对。用于定义多字符字段分隔符。它优先于field_split选项。 12345678#栗子k1=v1:k2=v2:::k3=v3::k4=v4filter &#123; kv &#123; field_split_pattern =&gt; &quot;:+&quot; &#125;&#125; include_brackets默认值为true.一个布尔值，指定是否将 方括号[square bracket]，尖括号和括号(bracket) 视为的包装器(wrapper)，是否应该从值中删除。 12345678910111213#栗子one=(o n e) two=[t w o] three=&lt;t h r e e&gt;filter &#123; kv &#123; include_brackets =&gt; tree &#125;&#125;#afterone: o n etwo: t w othree: t h r e e include_keys默认值为[].一个数字，用于指定应该添加到解析的键。默认情况下，所有的键都会被添加。 prefix默认值为空。预先添加到所有提取的键的字符串。 recursive默认值为false.一个布尔值，执行是否向下提取值并递归获取更多的键值对。 remove_char_key要从键中移除的字符串。 remove_char_value要从值中移除的字符串。 source默认值为message.要在其上执行key=value搜索的字段。 target将所有键值对放入的容器的名称。 transform_key将键转换为大写，小写。 transform_value将值转换为大写，小写 trim_key从键中修建的字符串。如果键包含在括号中或以空格开头，这很有用。 trim_value从值中修建的字符串。如果你的值包含在括号中或以逗号结尾。这很有用。 value_split默认值为=.一个非空字符串，用作解析出键值对的单字符分隔符。 value_split_pattern用作值分隔符来解析出键值对的正则表达式。优先级高于value_split。 metricsmetrics filter用于聚合度量(aggregating metrics). 12345678#计算每种http响应吗filter &#123; metrics &#123; meter =&gt; [ &quot;http_%&#123;response&#125;&quot; ] add_tag =&gt; &quot;metric&quot; &#125;&#125; metrics filter配置项 Setting Input_type Required clear_interval number No flush_interval number No ignore_older_than number No meter array No percentiles array No rates array No timer hash No clear_interval默认值为-1.清理间隔，所有的计数器都被重置。 flush_interval默认值为5.刷新间隔，当metrics事件被创建时。此值必须是5的倍数。 ignore_older_than默认值为0.不要跟着@timestamp超过某个秒数的事件。 meter语法: meter =&gt; [ &quot;name of metric&quot;, &quot;name of metric&quot; ] percentiles默认值为percentiles.计时器值应该测量和发出的百分位数。 rates默认值为[1, 5, 15].应该按分钟测量的比率。 timer语法: timer =&gt; [ &quot;name of metric&quot;, &quot;%{time_value}&quot; ] meter valuesmeter =&gt; &quot;something&quot;, 会收到如下字段: “[thing][count]” - the total count of events “[thing][rate_1m]” - the per-second event rate in a 1-minute sliding window “[thing][rate_5m]” - the per-second event rate in a 5-minute sliding window “[thing][rate_15m]” - the per-second event rate in a 15-minute sliding window timer valuestimer =&gt; { &quot;thing&quot; =&gt; &quot;%{duration}&quot;}, 会收到如下字段: “[thing][count]” - the total count of events “[thing][rate_1m]” - the per-second average value in a 1-minute sliding window “[thing][rate_5m]” - the per-second average value in a 5-minute sliding window “[thing][rate_15m]” - the per-second average value in a 15-minute sliding window “[thing][min]” - the minimum value seen for this metric “[thing][max]” - the maximum value seen for this metric “[thing][stddev]” - the standard deviation for this metric “[thing][mean]” - the mean for this metric “[thing][pXX]” - the XXth percentile for this metric (see percentiles) mutatemutate filter允许你在字段上执行常规突变。你可以重命名，删除，替换和修改事件中的字段。 mutate filter配置项 Setting Input_type Required convert hash No copy hash No gsub array No join hash No lowercase array No merge hash No coerce hash No rename hash No replace hash No split hash No strip array No update hash No uppercase array No capitalize array No convert将字段的值转换为其它类型，如将string转换为int.如果只为数组，则所有成员都将转换；如果是散列，则不处理。 copy将现有字段复制到另一个字段(会覆盖)。 gsub将正则表达式与字段值进行匹配，并用替换字符替换所有匹配项。只支持string或string array. 1234567filter &#123; mutate &#123; gsub =&gt; [ &quot;field1&quot;, &quot;value&quot;, &quot;replacement string&quot;, ] &#125;&#125; join加入一个带分隔符的数组。对非数组字段没有任何作用。 lowercase将字符串转换为小写 merge合并数组或散列的两个字段。字符串字段将被自动转换为数组。 12345filter &#123; mutate &#123; merge =&gt; &#123; &quot;dest_field&quot; =&gt; &quot;added_field&quot;&#125; &#125;&#125; coerce为已存在但为空的字段设置默认值。 rename重命名一个或多个字段。 replace用新值替换一个字段。新值可以包含%{foo}字符串，以帮助你从事件的其它部分创建新值。 1234567filter &#123; mutate &#123; replace =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;source_host&#125;: My new message&quot; &#125; &#125;&#125; split使用分隔符将字段拆分为数组。只适用于字符串字段。 strip从字段剥离空白符。 update用新值更新现有字段。 xmlXML filter.获取包含XML的字段并将其展开为实际的数据结构。 XML Filter配置项 Setting Input_type Required force_array boolean No force_content boolean No namespaces hash No remove_namespaces boolean No source string Yes store_xml boolean No suppress_empty boolean No target string No xpath hash No force_array默认值为true.过滤器强制单个元素为数组。将其设置为false防止在数组中存储单个元素。 force_content默认值为false.过滤器将以不同于标签内的内容的方式展开属性。 namespace默认值为{}.这允许配置所有命名空间声明来解析XML文档。 12345678filter &#123; xml &#123; namespaces =&gt; &#123; &quot;xsl&quot; =&gt; &quot;http://www.w3.org/1999/XSL/Transform&quot; &quot;xhtml&quot; =&gt; &quot;http://www.w3.org/1999/xhtml&quot; &#125; &#125;&#125; remove_namespaces从文档中的所有节点中删除所有命名空间。 source store_xml默认为true.过滤器会将整个解析的XML存储在目标字段中。 suppress_empty默认值为true.默认情况下，如果元素为空，这不输出。如果设置为false,则空元素将产生一个空的散列对象。 target定义放置数据的目标。 条件判断使用条件判断决定filter和output处理特定的事件。 Logstash条件类似于编程语言，条件语句，可以嵌套： if else if else 比较操作： == != &lt; &gt; &lt;= &gt;= =~ 匹配正则 !~ 不匹配正则 in 包含 not in 不包含 布尔操作： and or nand xor 一元运算符： ! 取反 () 复合表达式 栗子： 1234567891011121314151617181920output &#123; if [path] == &quot;/var/nginx/access.log&quot; &#123; elasticsearch &#123; hosts =&gt; user =&gt; password =&gt; index =&gt; &quot;nginx-access-%&#123;+YYYY.MM.dd&#125;&quot; &#125; &#125; else if [path] == &quot;/var/nginx/error.log&quot; &#123; elasticsearch &#123; hosts =&gt; user =&gt; password =&gt; index =&gt; &quot;nginx-error-%&#123;+YYYY.MM.dd&#125;&quot; &#125; &#125; else &#123; &#125;&#125; Filebeat文档 概述filebeat是一个beat，它基于libbeat框架。 Filebeat是一个本地文件的日志数据搬运(shipper)。作为Agent安装，filebeat监视日志目录或指定的日志文件，并将它们转发给Elasticsearch或logstash进行索引。启动filebeat时，它会启动一个或多个prospectors(勘探者)，查看为日志指定的本地路径。对于prospectors所在的每个日志文件，filebeat启动harvester。每个harvester为新内容读取单一日志文件，并将新日志发送到filebeat配置的输出。 入门开始filebeat前，请确保安装和配置了如下产品： Elasticsearch(存储和索引数据) Kibana(UI) Logstash(可选) 配置filebeat module为常用日志格式提供了入门体验。 123456789101112131415161718vim /etc/filebeat/filebeat.ymlfilebeat.prospectors: -type: log enabled: true paths: - /var/log/*.logoutput.elasticsearch: hosts: [ &quot;ip:9200&quot; ] #username #passwordsetup.kibana: host: &quot;localhost:5601&quot; #username #password 配置filebeat使用logstash123456vim /etc/filebeat/filebeat.ymloutput.logstash: hosts: [ &quot;127.0.0.1:5044&quot; ]#logstash需要配置监听beats 在Elasticsearch中载入索引模板在Elasticsearch中，索引模板用于定义设置(setting)和映射(mapping)，以确定如何分析字段(fields)。 filebeat推荐的索引模板文件有filebeat软件包安装。在成功连接到Elasticsearch后，它会默认自动载入索引模板(fields.yml)。如果模板存在，它不会覆盖除，除非你配置要覆盖。通过修改配置文件，你也可以禁用自动载入模板，或者载入你自己的模板。 配置模板载入 1234567891011vim /etc/filebeat/filebeat.ymlsetup.template.name: &quot;template-name&quot;setup.template.fields: &quot;/path/xxx/xxx.yml&quot;#强制覆盖已存在模板setup.template.overwrite: true#关闭自动载入模板setup.template.enabled: false 修改索引名 filebeat的默认索引名为 filebeat-&lt;version&gt;-yyyy.MM.dd 在output.elasticsearch设置选项 你指定的索引名称应该包含索引的根名、索引版本和日期信息 1234output.elasticsearch.index: &quot;customname-%&#123;[version]&#125;-%&#123;+yyyy.MM.dd&#125;&quot;setup.template.name: &quot;customname&quot;setup.template.pattern: &quot;customname-*&quot;setup.dashboards.index: &quot;customname-*&quot; 手动载入模板 1filebeat setup --template 强制Kibana查看最新文件 1curl -XDELETE &apos;http://localhost:9200/filebeat-*&apos; 设置Kibana面板Filebeat附带了实例的Kibana dashboards, visualization和可视化搜索。在使用仪表板前，你需要创建索引filebeat-*，并将仪表板加载到Kibana中。你可使用setup命令或配置文件加载它。 启动Filebeat1234systemctl start filebeat#前台启动并查看相关信息filebeat -e -c filebeat.yml 查看示例Kibana仪表板访问你的kibana web端(localhost:5601)，可用Nginx做反向代理，再加上域名解析。 快速开始常见日志格式filebeat提供了一套预构建模块，可使用它快速实施和部署日志监视方案。 先决条件： 安装和配置Elastic Stack 安装filebeat 安装Ingest Node GeoIP和User Agent plugins 验证Elasticsearch和Kibana能从filebeat接收数据 12elasticsearch-plugin install ingest-geoipelasticsearch-plugin install ingest-user-agent 运行filebeat模块 12345678#启用模块filebeat modules enable nginx system#配置pathcd /etc/filebeat/modules.dvim nginx.ymlvim system.yml 最后就可以在Kibana中可视化查看日志。 查看dashboard时，遇到一个错误: Could not locate that index-pattern (id: filebeat-*) 解决办法： 12#重新载入索引模板filebeat setup output我们可根据系统的负载情况将Filebeat的output到合适的地方，output只能有一个！如果有时候系统负载过高的话，可以考虑output到Redis或Elasticsearch。 redis和logstash都还需要logstash的pipeline转交给Elasticsearch，但你可以filter。而直接使用Elasticsearch便不能过滤。 Logstash Elasticsearch Redis 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556vim /etc/filebeat/filebeat.yml#找到output#redisoutput.redis: hosts: &quot;localhost&quot; port: 6379 key: &quot;filebeat&quot; #自定义key-name #password: #db: #data_type: &apos;list&apos;#logstashoutput.logstash: hosts: [ &quot;localhost:5044&quot; ]#Elasticsearchelasticsearch.output: hosts: [ &quot;localhost:9200&quot; ] #username: #name:==================#redis对应的pipelinevim /etc/logstash/conf.d/redis-pipeline.confinput &#123; redis &#123; data_type =&gt; &quot;list&quot; key =&gt; &quot;filebeat&quot; host =&gt; &quot;localhost&quot; port =&gt; 6379 #password =&gt; #db =&gt; &#125;&#125;#filter&#123; &#125;output &#123; elasticsearch &#123; hosts =&gt; [ &quot;localhost:9200&quot; ] #user #password index =&gt; &quot;filebeat-%&#123;+YYYY.MM.dd&#125;&quot; &#125;&#125; 定义索引为filebeat定义index: 123456789101112131415161718192021222324vim /etc/filebeat/filebeat.yml# Optional index name. The default is &quot;filebeat&quot; plus date# and generates [filebeat-]YYYY.MM.DD keys.# In case you modify this pattern you must update setup.template.name and setup.template.pattern accordingly.#index: &quot;filebeat-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;&quot;#写到事件中的索引名，默认 &quot;filebeat-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;&quot;#如果更改此设置，还需要配置setup.template.name和setup.template.pattern选项#如果使用的是预先构建的kibana dashboard，还需要配置setup.dashboards.index选项#定义索引output.elasticsearch: hosts: [&quot;10.0.1.8:9002&quot;, &quot;10.0.1.7:9002&quot;, &quot;10.0.1.9:9002&quot;] loadbalance: true username: &quot;elastic&quot; password: xxx index: &quot;filebeat-publish-%&#123;+yyyy.MM.dd&#125;&quot;#添加这几项setup.template.name: &quot;filebeat&quot;setup.template.pattern: &quot;filebeat-*&quot;setup.template.fields: &quot;fields.yml&quot;setup.template.overwrite: false 配置RPM安装的配置文件默认是/etc/filebeat/filebeat.yml，还有一个完整的示例配置文件/etc/filebeat/filebeat.reference.yml，显示了所有未弃用的选项。配置文件使用YAML语法。 指定运行moduleSpecify which modules to run Filebeat module提供了一种快速处理常见日志格式的方法。它包含默认配置。 有几种不同方法来启用modules: 配置modules.d目录 filebeat命令启动 配置filebeat.yml文件 1234567891011121314#modules.dfilebeat modules listfilebeat modules enable nginx#filebeat modules disable nginx#filebeat命令./filebeat -e --modules nginx#filebeat.ymlfilebeat.modules:- module: nginx- module: system 指定变量设置Specify variable settings 每个模块和文件集合都有变量，你可以设置这些变量来更改木块的默认行为。 12345678- module: nginx access: var.path: [&quot;/var/log/nginx/access.log*&quot;]#orfilebeat -M &quot;nginx.access.var.paths=[/var/log/access.log*]&quot;filebeat --modules nginx -M &quot;nginx.access.var.paths=[/var/log/nginx/access.log*]&quot; -M &quot;nginx.error.var.paths=[/var/log/nginx/error.log*]&quot; 高级设置在幕后，每个木块都会启动filebeat input。高级用户可以添加或覆盖任何input设置。 12345678910- module: nginx access: input: close_eof: true#orfilebeat -M &quot;nginx.access.input.close_eof=true&quot;filebeat --modules nginx -M &quot;nginx.access.input.close_eof=true&quot; 读取动态文件名filbeat配置文件虽然可以将索引设置为: indexname-%{+yyyy.MM.dd} 的日志格式，但这个是发送给ES的，ES可以处理此配置，但filebeat是无法直接处理的，它会把它当做普通字符。假如我要读取一个按日期取名的日志文件，如service_20180808.log，filebeat配置文件中是无法直接配置和处理。后来想到，可以用sh写一个脚本来做此操作。 1234567891011yesterday=`/bin/date +%Y%m%d --date='-1days'`today=`/bin/date +%Y%m%d`/bin/sed -i "s/service_err_$&#123;yesterday&#125;/service_err_$&#123;today&#125;/" /etc/filebeat/filebeat.yml/bin/filebeat test configif [ $? -eq 0 ] ;then /bin/systemctl restart filebeatelse exit 0fi inputDEPRECATED: prospectors are deprecated, Use inputs instead. Will be removed in version: 7.0.0要手动配置filebeat(而不是使用modules)，需要在filebeat.yml的filebeat.inputs部分指定输入列表(一个YAML 数据)。你可指定多个输入，并可多次指定相同的输入类型。 input types log stdin redis udp docker tcp syslog input 通用选项： 12345678910111213141516171819202122232425262728#启用/禁用inputsenabled#增加tags字段tags#向输出添加其他信息fieldsfilebeat.inputs:- type: log fields: author: zhang21#自定义字段存储为输出文档中的顶级字段，而不是在字段子字典下分组。如果与filebeat冲突，则会覆盖源字段fields_under_root#应用于inputs的处理器列表#已被弃用processors#为input生成的事件设置ingest node pipeline idpipeline log使用log input从日志文件中读取行。 12345filebeat.inputs:- type: log paths: - /var/log/messages - /var/log/*.log 你可以将其它配置设置(fields, include_lines, exclude_lines, mutiline)应用于从日志文件获取的行。这里指定的选项将应用于input的所有文件。将不同的配置应用于不同的文件，需要定义多个input sections: 1234567891011filebeat.inputs:- type: log paths: - /var/log/1.log - /var/log/2.log- type: log paths: - "/var/log/appache/*" fields: apache: true fields_under_root: true log input 配置项 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123paths#将读取的基于全局路径的列表recursive_glob.enabled#true允许扩展为递归模式encoding#读取数据的文件编码exclude_lines#正则表达式列表，用于匹配你希望filebeat排除的行filebeat.inputs:- type: log ... exclude_lines: ['^debug']include_lines#正则表达式列表，用于匹配你希望filebeat包含的行。#如果`exclude_lines`和`include_lines`都定义了，filebeat首先执行`include_lines`，之后才执行`exclude_lines`。filebeat.inputs:- type: log ... include_lines: ['^ERR', '^WARN']harvester_buffer_size#每个收集器在获取文件时使用的buffer大小，默认 16 384Byte。max_bytes#单日志消息可以具有的最大字节数。默认 10MBjson#此选项使filebeat解码日志结构为json消息。filebeat逐行处理日志，因此每一行要有json对象才有效。json.keys_under_rootjson.overwrite_keysjson.add_error_keyjson.message_keyjson.ignore_decoding_errormutiline#控制filebeat如果处理跨越多行的日志消息。exclude_files#正则表达式列表，用于匹配你希望filebeat忽略的文件。默认无。filebeat.inputs:- type: log ... exclude_files: ['\.gz$']ignore_older#如果启用此选项，filebeat将忽略在指定的事件跨度之前修改的所有文件。close_*#用于在某个标准或时间后关闭收集器。close_inactive#如果文件尚未在指定的时间内收获，则filebeat将关闭文件句柄。close_renamed#filebeat会在重命名文件时关闭文件处理程序，请注意日志轮询。close_removed#删除文件后，filebeat会关闭收集器。close_eof#一旦到达文件末尾，filebeat就会关闭文件。clean_*#用于清理注册表文件中的状态条目。clean_inactive#filebeat在指定的不活动事件段过去后删除文件的状态。clean_removed#如果在最后一个已知名称下无法在磁盘上找到文件，则filebeat会清除注册表中的文件。scan_frequency#filebeat检查指定路径文件的频率。官方不建议将此值设置为小于1s。默认 10s。tail_files#filebeat开始在每个文件的末尾而不是开头读取新文件。默认 falsesymlinks#允许filebeat收集符号链接，它读取符号链接的原始文件。由于此选项可能会导致数据丢失，默认 disabledbackoff#指定filebeat如何积极地抓取打开的文件以进行更新。max_backoff#在到达eof后再次检查文件之间filebeat等待的最长时间。backoff_factor#指定等待时间增加的速度。harvester_limit#限制一个input并行启动的收集器数量。 stdin使用stdin input从标准输入读取事件。此输入不可与其它输入类型同时运行。 12filebeat.inputs:- type: stdin stdin input 配置项： 123456789101112encodingexclude_linesinclude_linesharvester_buffer_sizemax_bytesjsonmultiline udp使用 udp input通过udp读取事件。 1234filebeat.inputs:- type: udp max_message_size: 10KB host: "localhost:5678" udp input 配置项： 123456#通过udp接收的最大消息大小，默认 10KBmax_message_size#udp hosthost tcp使用 tcp input 通过tcp读取事件。 1234filebeat.inputs:- type: tcp max_message_size: 10MB host: "localhost:5679" tcp input 配置项： 1234567891011121314max_message_size#通过tcp接收的最大消息大小， 默认 10MB#host and tcp porthost#指定用于拆分事件的字符，默认 \nline_delimiter#关闭连接前不活动的秒数， 默认 300stimeout docker使用docker input从docker container读取日志。 12345678filebeat.inputs:- type: docke containers: path: "/var/lib/docker/containers" stream: "all" ids: - 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'#必须填写容器ID docker input 配置项： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960container.ids#默认 /var/lib/docker/containerscontainer.path#从指定stream读取: all/stdout/stderr，默认 allcontainer.streamencodingexclude_lineinclude_lineharvester_buffer_sizemax_bytesjsonmultilineexclude_filesignore_olderclose_*close_inactiveclose_renamedclose_removedclose_eofclose_timeoutclean_*clean_inactiveclean_removedsacn_frequencytail_filessymlinksbackoffmax_backoffbackoff_factorharvester_limit syslog使用 syslog input通过tcp/udp/读取事件。 修改syslog配置： 123456vim /etc/rsyslog.d/filebeat.conf*.* @127.0.0.1:5678#重启服务systemctl restart rsyslog 123456789101112131415filebeat.inputs:- type: syslog protocol.udp: host: "localhost:5678" max_message_size: 100KB#定义索引setup.template.name: "filebeat"setup.template.pattern: "filebeat-*"setup.template.fields: "fields.yml"setup.template.overwrite: falseout.elastisearch： hosts: ["localhost:9200"] index: "syslog-%&#123;+yyyy.MM.dd&#125;" 它的配置项就是tcp/udp的配置项。 之后查看主机端口情况： 123netstat -nltup | grep 5678udp 0 0 127.0.0.1:5678 0.0.0.0:* 12434/filebeat output你可以通过在filebet.yml配置文件的output部分设置选项来配置filebeat以特定方式输出。只能定义一个输出。 filebeat支持如下输出： Elasticsearch Logstash Kafka Redis File Console elasticsearchfilebeat使用es http api将事务发送到es。 12345678output.elasticsearch: hosts: [&quot;https://localhost:9200&quot;] username: &quot;filebeat_internal&quot; password: &quot;YOUR_PASSWORD&quot; index: &quot;filebeat-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;&quot; #ssl.certificate_authorities: [&quot;/etc/pki/root/ca.pem&quot;] #ssl.certificate: &quot;/etc/pki/client/cert.pem&quot; #ssl.key: &quot;/etc/pki/client/cert.key&quot; 配置项： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103#启用/禁用output，默认 trueenabledhosts#["hsot1:port1", "host2:port2", "host3:port3"]username#建议为filebeat创建一个专门的用户用于发送事件，而不是使用es的用户passwordcompression_level#gzip压缩等级, 0-9，默认 0worker#每个配置主机向es发布事件的worker数，默认 1parameters#http 参数字典protocol#网络协议, http/httpspath#http api调用前面的http路径前缀headers#定义headersproxy_url#代理的urlindex#写到事件中的索引名，默认 "filebeat-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;"#如果更改此设置，还需要配置setup.template.name和setup.template.pattern选项#如果使用的是预先构建的kibana dashboard，还需要配置setup.dashboards.index选项indices#支持条件的索引选择器规则数组，基于格式字符串的字段访问和名称映射。indices.index: 要使用的索引格式字符串indices.mapping： 映射indices.default： 如果映射找不到匹配项的默认字符串值indices.when： 成功的条件才执行当前规则output.elasticsearch: hosts: ["http://localhost:9200"] index: "logs-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;" indices: - index: "critical-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;" when.contains: message: "CRITICAL" - index: "error-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;" when.contains: message: "ERR"pipeline#与indices类似，管道选择器配置数组filebeat.inputs:- type: log paths: ["/var/log/app/normal/*.log"] fields: type: "normal"- type: log paths: ["/var/log/app/critical/*.log"] fields: type: "critical"output.elasticsearch: hosts: ["http://localhost:9200"] index: "filebeat-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;" pipelines: - pipeline: critical_pipeline when.equals: fields.type: "critical" - pipeline: normal_pipeline when.equals: fields.type: "normal"max_retriesbulk_max_size#单个es批量挨批索引请求中要批量处理的最大事件数，默认 50backoff.init#在网络错误之后尝试重连到es之前等待的秒数，默认 1sbackoff.max#在网络错误后尝试连接到es之前等待的最大秒数，默认 60stimeout#超时时间ssl logstash kafka redisredis output将事件插入redis list或redis channel。 12345678output.redis: hosts: "localhost" port: 6379 key: "filebeat" #自定义key-name #password: #db: #data_type: 'list' 配置项： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#启用/禁用outputenabledhostsport#可将端口写在hosts里，默认6379usernamepassworddbkeydatatype#默认 listcodeckeyskeys.keykeys.mappingkeys.defaultkeys.whenoutput.redis: hosts: ["localhost"] key: "default_list" keys: - key: "info_list" # send to info_list if `message` field contains INFO when.contains: message: "INFO" - key: "debug_list" # send to debug_list if `message` field contains DEBUG when.contains: message: "DEBUG" - key: "%&#123;[fields.list]&#125;" mapping: "http": "frontend_list" "nginx": "frontend_list" "mysql": "backend_list"loadbalance#如果配置了多个主机，则输出插件会将已发布的事件负载均衡到所有redis主机上timeoutmax_retriesbulk_max_sizesslproxy_urlproxy_use_local_resolver filefile output将事务转储到文件中，每个事务都是json格式。 123output.file: path: "/tmp/filebeat" filename: filebeat 配置项： 12345678910111213141516enabledpathfilenamerotate_every_kb#默认 10 240KBnumber_of_files#路径下要保存的最大文件数permissions#创建的文件权限， 默认 0600codec consoleconsole output将事件以json格式输出到标准输出。 12output.console: pretty: true 配置项： 12345678pretty#美化输出， 默认 falsecodecenabledbulk_max_size loadbalancefilebeat提供配置项，用于将事件发送到多个主机时微调负载均衡。loadbalance对redis, logstash, es output可用。 123output.logstash: hosts: ["localhost:5044", "localhost:5045"] loadbalance: true Kibana文档Kibana是一个开源分析和可视化平台，旨在与Elasticsearch合作。你可使用Kibana来检索(search)，查看(view)存储在Elasticsearch索引中的数据并与其进行交互(interact)。你可以很轻松地执行高级数据分析，并在各种图表、表格和地图中可视化你的数据。Kibana可以很容易地理解大量的数据。基于浏览器的接口能够快速创建和分享动态仪表盘，实时显示Elasticsearch查询的变化。 入门在开始前，请确保已安装Kibana并与Elasticsearch建立了连接。 载入示例数据本节依赖如下示例数据： shakespeare.json: https://download.elastic.co/demos/kibana/gettingstarted/shakespeare_6.0.json accounts.zip: https://download.elastic.co/demos/kibana/gettingstarted/accounts.zip uzip accounts.zip logs.jsonl.gz: https://download.elastic.co/demos/kibana/gettingstarted/logs.jsonl.gz gunzip logs.jsonl.gz shakespeare按以下模式组织： 12345678&#123; "line_id": INT, "play_name": "String", "speech_number": INT, "line_number": "String", "speaker": "String", "text_entry": "String"&#125; accounts按以下模式组织： 12345678910111213&#123; "account_number": INT, "balance": INT, "firstname": "String", "lastname": "String", "age": INT, "gender": "M or F", "address": "String", "employer": "String", "email": "String", "city": "String", "state": "String"&#125; 日志数据的模式有许多不同的字段，此例使用字段如下： 12345&#123; "memory": INT, "geo.coordinates": "geo_point", "@timestamp": "date"&#125; 载入数据前，需要为字段设置映射。映射将索引中的文档分成逻辑组，并指定字段特性。如可搜索性、标记化、分解为单独的单词。 在Kibana界面中的Dev Tools中输入如下命令，为shakespeare数据设置映射。 12345678910111213PUT /shakespeare&#123; "mappings": &#123; "doc": &#123; "properties": &#123; "speaker": &#123;"type": "keyword"&#125;, "play_name": &#123;"type": "keyword"&#125;, "line_id": &#123;"type": "integer"&#125;, "speech_number": &#123;"type": "integer"&#125; &#125; &#125; &#125;&#125; 日志数据集logs.jsonl需要映射才能将日志中的经纬度标记为地理位置。 12345678910111213141516PUT /logstash-2015.05.18&#123; &quot;mappings&quot;: &#123; &quot;log&quot;: &#123; &quot;properties&quot;: &#123; &quot;geo&quot;: &#123; &quot;properties&quot;: &#123; &quot;coordinates&quot;: &#123; &quot;type&quot;: &quot;geo_point&quot; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 12345678910111213141516PUT /logstash-2015.05.19&#123; &quot;mappings&quot;: &#123; &quot;log&quot;: &#123; &quot;properties&quot;: &#123; &quot;geo&quot;: &#123; &quot;properties&quot;: &#123; &quot;coordinates&quot;: &#123; &quot;type&quot;: &quot;geo_point&quot; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 12345678910111213141516PUT /logstash-2015.05.20&#123; &quot;mappings&quot;: &#123; &quot;log&quot;: &#123; &quot;properties&quot;: &#123; &quot;geo&quot;: &#123; &quot;properties&quot;: &#123; &quot;coordinates&quot;: &#123; &quot;type&quot;: &quot;geo_point&quot; &#125; &#125; &#125; &#125; &#125; &#125;&#125; accounts数据集不需要映射，这一点上使用Elasticsearch的bulk API去载入数据集： 12345678910#这些命令要花一些时间curl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/bank/account/_bulk?pretty' --data-binary @accounts.jsoncurl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/shakespeare/doc/_bulk?pretty' --data-binary @shakespeare_6.0.jsoncurl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/_bulk?pretty' --data-binary @logs.jsonl#验证#在Kibana中的DevTools中运行GET /_cat/indices?v 定义你的索引模式加载到Elasticsearch的每组数据集都有一个索引模式(index pattern)。索引模式是一个带有可匹配多个索引的可使用通配符的字符串。 在前面，Shakespeare数据集有一个名为: shakespeare 的索引；Account数据集有一个名为：bank 的索引。如，在常见的日志文件中，一个典型的索引包含YYYY.MM.DD日期格式，类似于logstash-2015.05.*。 进入Kibana界面，点击Management， Index Patterns， Create Index Pattern 来创建一个索引模式。 shakespeare和account数据集不包含 time-series data。确保为此数据集创建索引模式时，不包含基于时间的事件。logs数据集包含了时序数据，因此索引需要包含基于时间的事件。 shakes* ba* logstash-2015* 定义索引模式时，与Elasticsearch匹配的索引必须存在。 在Kibana的DevTools中输入: GET _cat/indices 来查看索引。 数据发现点击Kibana界面中的Discover以显示数据发现功能。 可视化Visualize Visualize允许你在Elasticsearch索引中创建数据的可视化。然后可以构建显示相关可视化的仪表盘。 Kibana的可视化基于Elasticsearch查询。通过使用一系列Elasticsearch聚合来提取和处理你的数据。你可以创建图标来显示你需要了解的趋势。 创建可视化 Elasticsearch文档入门Elasticsearch是一个高度可扩展的开源全文搜索和分析引擎。它允许你快速、近乎实时地存储、搜索和分析大量数据。 Elasticsearch的几个例子： 使用Elasticsearch来存储产品目录和库存，并为其提供搜索和建议 收集日志或交易数据，并分析和挖掘数据以便于查找趋势、统计数据、汇总或异常信息 价格提醒平台，允许顾客制定规则，收到相应规则信息 分析智能需求，快速调查、分析、可视化并对大量数据提出特别的问题 基本概念Near Realtime(NRT)Elasticsearch是一个近乎实时的搜索平台。这意味着从索引文档到可搜索之间存在轻微的延迟(通常为1s) Cluster集群是一个或多个节点(服务器)的集合，它们一起保存所有数据，并提供跨节点的联合索引和搜索功能。集群由默认名为elasticsearch的唯一名称标识，它很重要。确保不要在不同的环境中重复使用相同集群名称，否则可能会导致节点加入错误的集群。集群可以只有一个节点！你也可以拥有多个独立的集群，每个集群有自己唯一的集群名称。 Node节点是属于集群一部分的单个服务器，存储数据并参与集群的索引和索引。与集群一样，一个节点由一个名称来标识，启动时随机分配的UUID。你也可以自定义节点名。配置节点通过集群名称加入特定的集群，默认加入elasticsearch集群。在单集群中，你可以拥有任意数量的节点。 Index索引是一些具有相似特征的文档集合。例如，客户数据的索引，产品目录的索引，订单数据的索引……索引由名称标识(必须全小写)，文档执行索引、搜索、更新和删除操作时引用索引。在一个单集群中，你可以定义任何你想要的索引。 Document文档是可被索引的基本信息单位。例如，单个客户的文档，单个产品的文档，单个订单的文档…文档以JSON格式表示。一条记录就是一个文档。 Shards和Replicas索引可潜在地存储大量数据，这些数据可能会超多单个节点的硬件限制。例如，占用1TB磁盘空间的十亿文档的单个索引可能不适合单个节点的磁盘，或者可能太慢而无法单独向单个节点提供搜索请求。为了解决这个问题，Elasticsearch提供了将索引细分为称为分片的多个碎片上。当你创建索引时，你可以简单定义所需的分片数量。每个分片本身都是一个功能齐全且独立的索引，可以在集群中的任何节点上进行托管。 分片重要的两个原因： 允许你水平分割/缩放内容量 允许分布和并行操作跨分片，从而提高性能和吞吐量(throughput) 在任何时候都可能出现的网络环境中，强烈建议使用故障切换机制，以防止分片/节点因任何原因而消失。为此，Elasticsearch允许你将索引分片制作为一个或多个称为副本分片的副本集。副本集分片永远不会分配到与原始分片相同的节点上。 副本集重要的原因： 在分片/节点失效的情况下提供高可用性 因为搜索可以在所有副本上并行执行，它允许你扩展搜索量和吞吐量 总而言之，每个索引都可以分成多个分片，索引也可以被复制。一旦复制，每个索引将具有主分片和副本分片。在创建索引时，可为每个索引定义分片和副本数量。在索引创建之后，你可以动态更改副本的数量，但无法更改分片的数量。 默认情况下，Elasticsearch中的每个索引都分配了5个主分片和副本。 每个Elasticsearch分片都是一个Lucene索引。单个Lucene索引有最大文档数量限制。 探索你的集群The REST APIREST(Representational State Transfer)表现层状态转换，是一种万维网软件架构风格，目的是便于不同程序在网络中互相传递信息。REST通常使用HTTP, URI, XML和HTML这些协议和标准。 启动节点，下一步便是理解如何与它通信。幸运的是，Elasticsearch提供了一个非常全面(comprehensive)和强大的REST API，可以使用它与集群进行交互。 使用API可以完成如下几件事： 检查集群、节点和索引的健康、状态和统计信息 管理集群、节点、索引数据和元数据 执行CRUD(create, read, update, delete) 执行高级搜索操作(分页、排序、过滤、脚本、聚合…) 集群健康基本健康检查，看看集群正在做什么。使用_catAPI检查集群健康。可使用Kibana Console或curl等工具。 12345678910#KibanaGET /_cat/health?v#cmdcurl -X GET &quot;localhost:9200/_cat/health?v&quot; -u elasticepoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent1525330981 15:03:01 docker-elk yellow 1 1 32 32 0 0 6 0 - 84.2% 集群健康： green: 万事OK(集群功能齐全) yellow: 所有数据可用，但一些副本尚未分配(集群功能齐全) red: 一些数据因某种原因不可用(集群部分功能) 集群名称： 集群名称被修改为docker-elk 列出集群中的节点： 12345GET /_cat/nodes?vip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name127.0.0.1 47 74 93 3.18 3.13 2.90 mdi * LGrAIE5 随机节点名： LGrAIE5 列出所有索引123456789GET /_cat/indicies?vhealth status index uuid pri rep docs.count docs.deleted store.size pri.store.sizegreen open .monitoring-kibana-6-2018.04.27 bsKsurh7TKaCsnekwHs3yg 1 0 870 0 328.1kb 328.1kbgreen open .watcher-history-7-2018.04.28 zuq3rjI8S0OSS7vcZl7kSQ 1 0 954 0 1.4mb 1.4mbgreen open .kibana 8t_7lqq4TFSfelA7phgv5g 1 0 142 18 191.8kb 191.8kbgreen open .monitoring-es-6-2018.04.28 vtUSjqaITT28CMHArpfNoA 1 0 20436 0 9.6mb 9.6mbyellow open filebeat-6.2.4-2018.05.03 sK3lIvMXS8GoRbWYCjdgzg 3 1 568 0 348.6kb 348.6kb 创建索引创建一个名为customer的索引，然后列出索引 1234567891011121314#pretty漂亮JSON显示PUT /customer?pretty#或curl -X PUT &quot;localhost:9200/zhang&quot; -u elastic:elasticGET /_cat/indices?v#pri主分片，rep副本health status index uuid pri rep docs.count docs.deleted store.size pri.store.sizeyellow open customer WQ3qEnPQRW6FpVIHYVJ7yA 5 1 0 0 1.1kb 1.1kbyellow open zhang nkOUPOWERsS1PT_wEui67g 5 1 0 0 1.1kb 1.1kb 你可能注意到了，索引的健康状态是yellow，表明有一些副本尚未分配。这个索引发生这种情况的原因是Elasticsearch默认为这个索引创建了一个副本。由于此刻我们只有一个节点在运行，因此只有在其它几点加入集群后才能分配一个副本。一旦副本分配到另外的节点，健康状态会变成green。 索引和查询文档现在让我们把一些东西放入customer索引中。讲一个简单的customer文档放入customer索引中，ID为1： 12345678910111213141516171819202122232425262728293031323334353637383940414243PUT /customer/_doc/1?pretty&#123; &quot;name&quot;: &quot;John Doe&quot;&#125;#或curl -X PUT -u elastic:elastic &quot;localhost:9200/customer/_doc/1?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;name&quot;: &quot;John Doe&quot;&#125;&apos;&#123; &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 0, &quot;_primary_term&quot; : 1&#125;GET /customer/_doc/1?pretty&#123; &quot;_index&quot;: &quot;customer&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;John Doe&quot; &#125;&#125;#name:John Doe _id:1 _type:_doc _index:customer _score:1 删除索引12345678DELETE /customer?prettycurl -X DELETE &quot;localhost:9200/customer?pretty&quot; -u elastic:elastic&#123; &quot;acknowledged&quot;: true&#125; 修改数据Elasticsearch几乎提示提供数据操作和搜索功能。从索引、更新、删除数据时可能会有1s延迟。数据在事物完成后立即可用。 索引/替换 文档 12345678910111213141516171819202122PUT /customer/_doc/1?pretty&#123; &quot;name&quot;: &quot;John Doe&quot;&#125;#如果我修改此处文档信息，则Elasticsearch会替换之前的文档PUT /customer/_doc/1?pretty&#123; &quot;name&quot;: &quot;Zhang&quot;&#125;#name:Zhang _id:1 _type:_doc _index:customer _score:1#或者新增一个文档PUT /customer/_doc/2?pretty&#123; &quot;name&quot;: &quot;Zhang&quot;&#125;#name:Zhang _id:2 _type:_doc _index:customer _score:1 未指定ID：ID是可选的。如果未指定ID，Elasticsearch会生成随机ID。注意，此时使用POST方法。 123456POST /customer/_doc?pretty&#123; &quot;name&quot;: &quot;Zhang&quot;&#125;#name:Zhang _id:76xJJWMBddhqcmsO07A_ _type:_doc _index:customer _score:1 更新文档除了能够索引和替换文档，我们还可以更新文档。Elasticsearch实际上并没有在原地就地更新，它是先删除旧文档，然后一次性更新索引新文档。 更新同样能够使用简单的脚本。Elasticsearch提供了通过查询条件(类似于SQL-UPDATE-WHERE)更细多个文档的能力。 1234567891011121314151617181920POST /customer/_doc/1/_update?pretty&#123; &quot;doc&quot;: &#123; &quot;name&quot;: &quot;Jane Doe&quot; &#125;&#125;#继续更新POST /customer/_doc/1/_update?pretty&#123; &quot;doc&quot;: &#123; &quot;name&quot;: &quot;Jane Doe&quot;, &quot;age&quot;: 20&#125;&#125;#简单脚本#ctx._source指即将更新的当前源文档POST /customer/_doc/1/_update?pretty&#123; &quot;script&quot;: &quot;ctx._source.age += 5&quot;&#125; 删除文档也可通过API匹配查询，删除所匹配的文档。 1DELETE /customer/_doc/2?pretty 批量处理Elasticsearch同样提供了使用_bulkAPI批量执行上述任何操作的功能。这是一种高效的机制，尽可能快地完成多项操作。 Bulk API不会因其中一个操作失败而停止，它将继续处理后面的动作。当它完成是，它会返回每个操作的状态，以便你可以检查是否失败。 123456789101112POST /customer/_doc/_bulk?pretty&#123; &quot;index&quot;: &#123; &quot;_id&quot;: &quot;1&quot; &#125; &#125;&#123; &quot;name&quot;: &quot;John Doe&quot; &#125;&#123; &quot;index&quot;: &#123; &quot;_id&quot;: &quot;2&quot; &#125; &#125;&#123; &quot;name&quot;: &quot;Jane Doe&quot; &#125;#更新POST /customer/_doc/_bulk?pretty&#123;&quot;update&quot;: &#123; &quot;_id&quot;: &quot;1&quot; &#125; &#125;&#123; &quot;doc&quot;: &#123; &quot;name&quot;: &quot;John Doe becomes Jane Doe&quot; &#125; &#125;&#123; &quot;delete&quot;: &#123; &quot;_id&quot;: &quot;2&quot; &#125; &#125; 探索你的数据简单数据集准备一个更加真实的数据集。如下生成的JSON文档，每个文档都有如下要点： 12345678910111213&#123; &quot;account_number&quot;: 0, &quot;balance&quot;: 16623, &quot;firstname&quot;: &quot;Bradshaw&quot;, &quot;lastname&quot;: &quot;Mckenzie&quot;, &quot;age&quot;: 29, &quot;gender&quot;: &quot;F&quot;, &quot;address&quot;: &quot;244 Columbus Place&quot;, &quot;employer&quot;: &quot;Euron&quot;, &quot;email&quot;: &quot;bradshawmckenzie@euron.com&quot;, &quot;city&quot;: &quot;Hobucken&quot;, &quot;state&quot;: &quot;CO&quot;&#125; 载入这个数据集下载Elasticsearch提供的accounts.json 123456curl -H &quot;Content-Type: application/json&quot; -u elastic:elastic -XPOST &quot;localhost:9200/bank/_doc/_bulk?pretty&amp;refresh&quot; --data-binary &quot;@accounts.json&quot;curl &quot;localhost:9200/_cat/indices?v&quot;health status index uuid pri rep docs.count docs.deleted store.size pri.store.sizeyellow open bank PGSvNwQwQIOhMDr1nmXIuw 5 1 1000 0 474.7kb 474.7kb 这样我们成功批量索引了1000个文档到bank索引。 Search API现在让我们做一些简单的搜索(search)。有两种基本搜索方式： REST request URI REST request body 以可读的JSON格式定义你的搜索，推荐方式 搜索的REST API可从_search端点访问: 12345678910111213141516171819202122232425262728293031323334353637#在bank索引下的_search端点搜索#匹配所有文档，并以账户字段顺序排列#最后以可读的JSON格式输出结果GET /bank/_search?q=*&amp;sort=account_number:asc&amp;pretty&#123; &quot;took&quot; : 63, &quot;timed_out&quot; : false, &quot;_shards&quot; : &#123; &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 &#125;, &quot;hits&quot; : &#123; &quot;total&quot; : 1000, &quot;max_score&quot; : null, &quot;hits&quot; : [ &#123; &quot;_index&quot; : &quot;bank&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;0&quot;, &quot;sort&quot;: [0], &quot;_score&quot; : null, &quot;_source&quot; : &#123;&quot;account_number&quot;:0,&quot;balance&quot;:16623,&quot;firstname&quot;:&quot;Bradshaw&quot;,&quot;lastname&quot;:&quot;Mckenzie&quot;,&quot;age&quot;:29,&quot;gender&quot;:&quot;F&quot;,&quot;address&quot;:&quot;244 Columbus Place&quot;,&quot;employer&quot;:&quot;Euron&quot;,&quot;email&quot;:&quot;bradshawmckenzie@euron.com&quot;,&quot;city&quot;:&quot;Hobucken&quot;,&quot;state&quot;:&quot;CO&quot;&#125; &#125;, &#123; &quot;_index&quot; : &quot;bank&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;sort&quot;: [1], &quot;_score&quot; : null, &quot;_source&quot; : &#123;&quot;account_number&quot;:1,&quot;balance&quot;:39225,&quot;firstname&quot;:&quot;Amber&quot;,&quot;lastname&quot;:&quot;Duke&quot;,&quot;age&quot;:32,&quot;gender&quot;:&quot;M&quot;,&quot;address&quot;:&quot;880 Holmes Lane&quot;,&quot;employer&quot;:&quot;Pyrami&quot;,&quot;email&quot;:&quot;amberduke@pyrami.com&quot;,&quot;city&quot;:&quot;Brogan&quot;,&quot;state&quot;:&quot;IL&quot;&#125; &#125;, ... ] &#125;&#125; took: Elasticsearch执行搜索花费的事件(ms) timed_out: 查询超时与否 _shards: 搜索了多少分片，包含成功和失败的次数 hits: 搜索结果 hits.total: 匹配搜索的文档数 hits.hits: 搜索结果数组(默认前十个文档) hits.sort: 结果的排序键 hits._score, max_score: 忽略的字段 REST request body方法 1234567GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;sort&quot;: [ &#123; &quot;account_number&quot;: &quot;asc&quot; &#125; ]&#125; 查询语法Elasticsearch提供了可用于执行查询的JSON格式语言，这被称为 Query DSL 12345#上一个查询栗子GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;&#125; 处理query参数，我们还可以传递其它参数来搜索结果: 123456789101112131415161718192021222324#size参数，返回从from开始多少个文档#from未指定，就默认为0GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;size&quot;: 1&#125;#from参数，指定从哪个文档索引开始GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;from&quot;: 10, &quot;size&quot;: 10&#125;#sort参数GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;sort&quot;: &#123; &quot;balance&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125; &#125;&#125; 执行搜索搜索某些字段： 12345GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;_source&quot;: [&quot;account_number&quot;, &quot;balance&quot;]&#125; 匹配查询： 12345678910111213141516GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;account_number&quot;: 20 &#125; &#125;&#125;GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;&#125;GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123; &quot;address&quot;: &quot;mill lane&quot; &#125; &#125;&#125; 布尔查询： must should must_not 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#mustGET /bank/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;lane&quot; &#125; &#125; ] &#125; &#125;&#125;#shouldGET /bank/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;should&quot;: [ &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;lane&quot; &#125; &#125; ] &#125; &#125;&#125;#must_notGET /bank/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must_not&quot;: [ &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;lane&quot; &#125; &#125; ] &#125; &#125;&#125;#组合使用must,must_not,shouldGET /bank/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;age&quot;: &quot;40&quot; &#125; &#125; ], &quot;must_not&quot;: [ &#123; &quot;match&quot;: &#123; &quot;state&quot;: &quot;ID&quot; &#125; &#125; ] &#125; &#125;&#125; 过滤前面我们跳过了称为文档分数的_score字段。它是文档与搜索查询匹配度相度量的一个数值。数值越大，与文档越相关。 但查询并不总是需要产生分数，特别是当它们仅用于过滤时。Elasticsearch检测这些情况并自动优化查询执行，以便不计算无用的分数。 range query: 通过一系列值来过滤文档 12345678910111213141516GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;balance&quot;: &#123; &quot;gte&quot;: 20000, &quot;lte&quot;: 30000 &#125; &#125; &#125; &#125; &#125;&#125; 除了前面这些查询类型，还有很多其它类型。由于只是入门章节，所以并不会涉及太多太难。 聚合聚合(Aggregation)提供了从数据中分组和提取统计的功能。考虑聚合最简单方法是将其大致等同于SQL GROUP BY和SQL聚合函数。 在Elasticsearch中，你可以执行返回匹配的搜索，同时还可以在一个响应中返回与匹配不同的聚合结果。你可以运行查询和多个聚合，并一次性获得多个操作的结果。 1234567891011121314GET /bank/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_state&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;state.keyword&quot; &#125; &#125; &#125;&#125;#类似的SQLSELECT state, COUNT(*) FROM bank GROUP BY state ORDER BY COUNT(*) DESC 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#group, averageGET /bank/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_state&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;state.keyword&quot; &#125;, &quot;aggs&quot;: &#123; &quot;average_balance&quot;: &#123; &quot;avg&quot;: &#123; &quot;field&quot;: &quot;balance&quot; &#125; &#125; &#125; &#125; &#125;&#125;GET /bank/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_age&quot;: &#123; &quot;range&quot;: &#123; &quot;field&quot;: &quot;age&quot;, &quot;ranges&quot;: [ &#123; &quot;from&quot;: 20, &quot;to&quot;: 30 &#125;, &#123; &quot;from&quot;: 30, &quot;to&quot;: 40 &#125;, &#123; &quot;from&quot;: 40, &quot;to&quot;: 50 &#125; ] &#125;, &quot;aggs&quot;: &#123; &quot;group_by_gender&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;gender.keyword&quot; &#125;, &quot;aggs&quot;: &#123; &quot;average_balance&quot;: &#123; &quot;avg&quot;: &#123; &quot;field&quot;: &quot;balance&quot; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 还有很多其它聚合方法，请参考https://www.elastic.co/guide/en/elasticsearch/reference/6.2/search-aggregations.html。 elasticsearch-pyPython可使用elasticsearch-py模块来操作Elasticsearch，具体文档请查看Python这篇文章的elasticsearch第三方模块。 Lucene查询ElasticSearch提供的一些查询方式(query types)能够被Lucene的查询解析器(query parser)语法所支持。可直接在Kibana的发现面板上直接使用。 全文搜索 string “string1 string2” Kibana会匹配和展示对应的string。 键值对 key:value: 全文搜索 &quot;key:value&quot;： 精确搜索 _exists_:key: 返回结果中需要有key字段 _missing__:key: 不能含有key字段 如:http.code:502，log-levle:warn 通配符 ? * 这两者都不能用作第一个字符，如?.txt, *.txt 正则表达式它也支持性能较差的正则表达式。 模糊搜索 ~: 在一个单词后面加上~启用模糊搜索 ~n： 设置编辑距离(整数)，指定需要多少相似度，越大越接近原始值 在短语后面加~，可以搜索到被隔开或顺序不同的单词 first~也可以匹配到frist&quot;hello world&quot;~5表示两者之间可以隔着5个单词 范围搜索数值/时间/IP/字符串 类型的字段可以对某一范围进行查询 1234567891011length:[100 TO 200]sip:[&quot;172.24.20.110&quot; TO &quot;172.24.20.140&quot;]date:&#123;&quot;now-6h&quot; TO &quot;now&quot;&#125;tag:&#123;b TO e&#125; 搜索b到e中间的字符count:[10 TO *] * 表示一端不限制范围count:[1 TO 5&#125; [ ] 表示端点数值包含在范围内，&#123; &#125; 表示端点数值不包含在范围内，可以混合使用，此语句为1到5，包括1，不包括5可以简化成以下写法：age:&gt;10age:&lt;=10age:(&gt;=10 AND &lt;20) 优先级使用^使一个词语比另一个搜索优先级更高，默认为1。可以为0~1之间的浮点数，来降低优先级 逻辑操作 AND OR NOT +: 搜索结果中必须包含此项 -: 不能包含此项 123(a OR b) AND chost:(baidu OR qq OR google) AND host:(com OR cn) 转义字符 \：使用转义字符来转移特殊字符 MetricbeatMetricbeat是一个轻量级的托运器(lightweight shipper), 你可从安装该软件的操作系统和服务器上定期收集指标信息。它可将收集到的指标信息或统计信息发送到指定的输出(如elasticsearch/Logstash)。 具体使用方法也和Filebeat差不多！ Metricbeat通过从服务器上运行的系统和服务收集指标来帮助你监控服务器。如： Apache Docker Kafka Kubernets HAProxy MongoDB MySQL Nginx PHP-FPM PostgreSQL Redis RabbitMQ System Zookeeper … PacketbeatPacketbeat是一个实时网络数据包分析器，可与Elasticsearch一起提供应用程序监控和性能分析。 Packetbeat通过捕获应用服务器之间的网络流量，解码应用层协议(HTTP, MySQL, Redis…)，将请求与响应关联起来，并记录每个事务感兴趣的字段。Packetbeat可以帮助你轻松地注意到后端应用程序的问题，例如错误或性能问题，并且可以更快地排除故障并进行修复。Packetbeat捕获服务器之间的流量，即时分析应用层协议，并将这些消息关联到事务中。并将这些事务插入到Elasticsearch或使用Redis和Logstash的队列中。 Packetbeat支持的协议如下: ICMP DNS HTTP AMQP Cassandra MySQL PostgreSQL Redis MongoDB Thrift-RPC TLS HeartbeatHeartbeat是一个轻量级守护进程，用以定期检查服务的状态并确定它们是否可用。与Metricbeat不同，Metricbeat只会告诉你服务器是down/up，而Heartbeat会告诉你服务是否可以访问(reached)。 当你需要验证是否满足服务级别协议的服务正常运行时间时，Heartbeat非常有用。当需要验证外部没有人能访问企私有服务器上的服务时，这也很有用。你可以配置Heartbeat来ping指定主机名的所有DNS可解析的IP地址。这样，你可以检查所有负载均衡的服务，看他们是否可用。配置Heartbeat时，你可以指定用于表示要检查的主机名的监视器(monitor)。每台监视器都根据你指定的时间表运行。 Heartbeat目前支持通过通过如下方式监控主机： ICMP当你指向检查服务是否可用时，请使用icmp监视器。此功能需要root权限 TCP支持SSL/TLS/proxy你可以选择配置此监视器，通过发送 and/or 接收自定义有效内容来验证端点 HTTP支持SSL/TLS/proxy你可以选择配置此监视器，来验证该服务是否会返回预期的响应。如特定状态码，响应header或内容 AuditbeatAuditbeat是一个轻量化的托运器(shipper)，在系统上安装它，以审核(audit)系统上用户和进程的活动。 例如，你可以使用Auditbeat从Linux Audit Framework收集和集中审计事件。你还可以使用它来检查关键文件的改动，并识别潜在的安全策略违规。 Topbeat在v5.0, Topbeat被Metricbeat取代！ Topbeat的版本与其它Elastic Stack组件不同步，ES是v6.2.4， 而Topbeat是v1.3。所以需要额外安装repo. Topbeat是一个轻量化的托运器(shipper)，来定期读取系统和每个进程的CPU和内存统计信息，然后为Elasticsearch中的统计信息编制索引。 Topbeat通过收集如下指标来帮助你监控你的服务器: ystem-wide statistics system load 1, 5, 15 system wide CPU usage user, system, idle, IOWait system wide memory uusage total, used, free system wide swap usage total, used, free Per-process statistics process name process parent pid process state process pid process CPU usage process Memory usage File system statistics avaliable disks name, type, mounted total, used, free, available APMAPM(Application Performance Monitoring)应用程序性能监控，自动收集应用程序内部的深入性能指标和错误。 它由三个组件组成: Agents Node.js Django Flask Ruby on Rails Rack JS Server UI ElastAlert GitHub: https://github.com/Yelp/elastalert Docs: https://elastalert.readthedocs.io ElastAlert是一个简单灵活的用于Elasticsearch中数据异常的告警框架。它使用Python2.x编写，不支持Python3。ElastAlert功能与Watcher类似，只不过Watcher是Elastic Enterprise中才支持，而ElastAlert是一个开源软件。 Kibana非常适合可视化和查询数据，但它需要一个配套工具来对数据进行告警，出于这种需要，ElastAlert诞生了。如果你几乎实时地将数据写入Elasticsearch，并希望在数据与某些模式匹配时收到告警，则ElastAlert就是适合你的工具。 综述ElastAlert被设计为可靠、高度模块化、易于设置和配置。它使用两种类型的组件与Elasticsearch进行结合： rule type alerts 定期检查Elasticsearch并将数据传递给规则类型，它确定了何时找到匹配项。当匹配发生时，它触发一个或多个报警，而这些报警便采取具体行动。 每组规则定义了一个查询、一个规则类型和一组警报。 ElasAlert几种通用规则类型： frequencyMatch where there are X events in Y time spikeMatch when the rate of events increases or decreases flatlineMatch when there are less than X events in Y time blacklist/whitelistMatch when a certain field matches a blacklist/whitelist anyMatch on any event matching a given filter changeMatch when a field has two different values within some time ElasAlert几种内建报警类型： Command Email JIRA OpsGenie SNS HipChat Slack Telegram Debug Stomp 你也可以导入和编写规则类型和报警类型。 除了这些基础用法外，还有许多其它功能: Alerts link to Kibana dashboards Aggregate counts for arbitrary fields Combine alerts into periodic reports Separate alerts by using a unique key field Intercept and enhance match data 可靠性Reliability ElasAlert有多种功能，可在restart或Elasticsearch不可用时使其更可靠: ElastAlert将其状态保存到Elasticsearch，并在启动时先恢复先前停止的状态 如果Elasticsearch没有响应，ElastAlert将等待它恢复，然后再继续 抛出错误的警报可能会在一段时间内自动重试 模块性Modularity ElastAlert有3个主要组件，可作为模块导入或自定义。 rule types规则类型负责处理从Elasticsearch返回的数据。 alerts警报负责根据匹配采取行动。 enhancements增强功能是一种拦截警报并以某种方式修改或增强警报的方法。 配置配置项ElastAlert有一个全局配置文件config.yaml，它定义了几个操作方面: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#ElastAlert将持续查询熊当前到buffer_time前的窗口buffer_time#ESes_hostes_port#可选es_usernamees_password#URL prefix for the Elasticsearch endpointes_url_prefix#Method for querying Elasticsearch，默认GETes_send_get_body_as#默认20es_conn_timeout#可选配置use_sslverify_certsclient_certclient_keyca_certs#规则配置文件目录rules_folder#递归，默认truescan_subdirectories#查询频率，如 minutes: 5run_every#elastalert将存储数据的索引名称writeback_index#报警失败的重试窗口alert_time_limit#单个查询中从es下载的最大文档数，默认10 000max_query_sizescroll_keepalive#聚合在一起的最大警报数，默认10 000max_aggregation#ElastAlert从最近开始运行的查询开始的最长时间old_query_limit#当抛出未知异常时，禁用rule。 默认truedisable_rules_on_error#Email#接收通知的邮件nottify_email#默认值ElastAlertfrom_addrsmpt_hostemail_reply_to#Amazon Elasticsearch Serviceaws_regionboto_profileprofile#在将文档写入Elasticsearch前，ElastAlert使用下划线替换字段名中的任意一个点(.)。默认值Falsereplace_dots_in_field_names#es中用于字符串多字段的子字段的后缀string_multi_field_name 运行ElastAlert运行： 1python elastalert/elastalert.py 一些参数： 1234567891011121314151617--config--debug--verbose--start--end--rule--slience--es_debug--es_debug_trace--pin_rules 首次运行ElastAlertRunning ElastAlert for the First Time 依赖Requirements: es ISO8601 or Unxi timestamped data Python 2.7 python2-pip python-dev libffi-dev libssl-dev 安装12345678910111213141516#依赖yum install python2-pip python-dev#setuptools &gt;= 11.3pip2 install --upgrade setuptools#elasticsearch &gt;= 5.0pip2 install elasticsearchpip2 install elastalert#or#git clone https://github.com/Yelp/elastalert.git#cd elastalert#python2 setup.py install 之后修改配置文件，我将ElastAlert目录移动到了/etc/下。修改配置文件，并将ElastAlert的config.yaml.example配置保存为config.yaml。 设置esSetting Up Elasticsearch ElastAlert将有关其查询及报警的信息和元数据报错到Elasticsearch。这虽然不是必须的，但却强烈建议使用。 12345678910111213141516#创建一个用于ElastAlert写入的indexelastalert-create-index#会有es主机，端口，用户，密码和索引相关信息Enter Elasticsearch host: zhang21Enter Elasticsearch port: 9200Use SSL? t/f: fEnter optional basic-auth username (or leave blank):Enter optional basic-auth password (or leave blank):Enter optional Elasticsearch URL prefix (prepends a string to the URL of every request): New index name? (Default elastalert_status)Name of existing index to copy? (Default None)Elastic Version:6Mapping used for string:&#123;&apos;type&apos;: &apos;keyword&apos;&#125;New index elastalert_status createdDone! 创建一个规则Creating a Rule 每个规则定义要执行的查询，触发匹配的参数以及每个匹配要触发的报警列表。cat ./example_rules/example_frequency.yaml 1234567891011121314151617181920212223242526272829303132333435es_host: elasticsearch.example.comes_port: 14900#唯一的规则名name: Example rule#规则类型type: frequency#要查询的索引index: logstash-*#触发报警的阈值num_events: 50#阈值的时间区间timeframe: hours: 4#过滤列表filter:- term: some_field: &quot;some_value&quot;#报警列表alert:- &quot;email&quot;#报警地址列表email:- &quot;elastalert@example.com&quot; 栗子elastalert: 12345678910111213141516171819vim /etc/elastalert/example_rules/example_frequency.yamles_host: &quot;192.168.1.11&quot;es_port: 9200name: &quot;test rule&quot;type: &quot;frequency&quot;#此处我用python新建一个索引，用于测试index: &quot;my-index&quot;num_events: 3timeframe: hours: 1filter:- term: name: &quot;zhang21&quot;alert:- &quot;email&quot;email:- &quot;elastalert@example.com&quot; 测试规则运行elasticalert-test-rule工具将测试你的配置文件是否成功加载并在过去24h内以调试模式运行： 1elastalert-test-rule ./example_frequency.yaml 配置首选项将按如下方式加载： yaml文件中指定的配置 配置文件中指定的配置 默认配置 运行ElastAlert有两种方式来调用ElastAlert： Supervisor Python 为了便于调试，下面将直接调用。 123456789python2 -m elastalert.elastalert --verbose --rule /etc/elastalert/example_rules/example_frequency.yamlINFO:elastalert:Starting up#这里遇到一个错误ERROR:root:Error running query: TransportError(400, u'search_phase_execution_exception', u'No mapping found for [@timestamp] in order to sort on')#解决方法，在规则文件example_frequency.yaml中添加timestamp_field: timestamp 使用Python3创建索引： 123456789101112131415from datetime import datetimefrom elasticsearch import Elasticsearches=Elasticsearch('http://192.168.1.11:9200')es.info()#写入文档data = &#123; 'timestamp': datetime.now(), 'name': 'zhang21'&#125;for i in range(1, 21): es.index(index='my-index', doc_type='test-type', id=i, body=data) 规则类型和配置项Rule Types and Configuration Options 规则配置项Rule Configuration Cheat Sheet 选项太多，自己去看: https://elastalert.readthedocs.io/en/latest/ruletypes.html 通用配置项每个在rules_folder下的.yaml文件默认都会被执行。 必须的配置 es_host es_port index name type alert 可选配置自己去看。 规则类型Rule Types 在elastalert/ruletypes.py中定义的各种RuleType class构成了ElastAlert的主要逻辑。每个规则都在内存中保存一个实例，传递通过给定过滤器查询es返回的所有数据，并根据该数据生成匹配。 any任意规则都将匹配所有内容。查询返回的每个匹配都会生成一个警报。 blacklist黑名单规则根据黑名单检查某个字段，如果它存在于黑名单中，则匹配。 黑名单规则需要两个额外项：compare_key——与黑名单进行比较的字段。如果为空，事件将被忽略。blacklist——黑名单列表值或黑名单文件列表(&quot;!file ./blacklist.txt&quot;) 栗子： 1234blacklist: - value1 - value2 - &quot;!file /tmp/blacklist1.txt&quot; whitelist白名单规则根据白名单检查某个字段，如果列表中不包含此字段，则匹配。 白名单规则需要三个额外项：compare_key——与白名单进行比较的字段ignore_null——如果为true，则没有compare_key字段的事件将不匹配whitelist——白名单列表值或白名单文件列表 栗子: 12345whitelist: - value1 - value2 - &quot;!file /tmp/whitelist1.txt&quot; - &quot;!file /tmp/whitelist2.txt&quot; change此规则将监视某个字段，如果此字段改变就匹配。 此规则需要三个额外项：compare_key——监控要改变的字段名。可以是一个列表，如果任意字段发生标号，都将触发警报。ignore_null——如果为true，则没有compare_key字段的事件将不计为已更改。query_key——此规则基于每个查询键应用。 一个可选字段：timeframe——改变之间的最大时间 frequency此规则匹配在给定时间范围内至少一定数量的事件。 此规则需要两个额外项：num_events——将会触发报警的事件数timeframe——上面事件的时间范围 spike(突增)当给定时间段内的事件量的spike_height次数大于或小于前一个时间段时，此规则匹配。它使用两个滑动窗口(引用和当前)来比较。 此规则需要三个额外项：spike_height——上次时间段时间数与前时间段事件数的比率，将处罚告警spike_type——up/down/bothtimeframe：时间段 flatline(脉波)当一段时间内事件总数匹配给定阈值时，此规则匹配。 此规则需要两个额外项：threshold——不触发警报的最小事件数timeframe——时间段 new term(术语)当一个以前从未见过的新值出现在字段中时，此规则匹配。 此规则需要一个额外项：fields——要监控的新术语的字段列表 cardinality(基数)在一个时间范围内，当某个字段的唯一值的总数高于或低于阈值时，此规则匹配。 此规则需要：timeframe——时间段cardinality_field——计算基数的字段 最大或最小基数取一个max_cardinality——数据的基数大于此报警min_cardinality——数据基数小于此报警 metric aggregation当计算窗口中的度量值高于或低于阈值时，此规则匹配。默认值为buffer_time。 此规则需要：metric_agg_key——计算度量标准的字段metric_agg_type——字段的类型doc_type——指定要搜索的文档类型 最大和最小至少需要一个max_threshold——计算的度量标准大与此，报警min_threshold——计算的度量标准小于此，报警 percentage match当计算窗口内匹配桶(bucket)中的文档百分比高于或低于阈值时，此规则匹配。默认情况下，计算窗口为buffer_time。 此规则需要：match_bucket_filter—— ES filter DSL。为匹配桶定义了一个过滤器，它应用匹配查询过滤器并返回文档的子集。doc_type——指定查询文档类型 最大和最小至少需要一个min_percentage——匹配文档的百分比小于此，报警max_percentage——匹配文档的百分比大于此，报警 Alerts每条规则都可以附加任意数量的报警。Alerts是Alerter的子类，并从ElastAlert传递包含相关信息的字典或字典列表。与规则配置类似，它们在规则配置文件中配置。 1234alert:- email- jira- xxx 多个邮件：12345alert:- emailfrom_addr: &quot;no-reply@example.com&quot;email: &quot;someone@example.com&quot; 1234567alert:- email: from_addr: &quot;no-reply@example.com&quot; email: &quot;someone@example.com&quot;- email: from_addr: &quot;xx&quot; email: &quot;xxx&quot; Alert Subject可通过添加包含自定义摘要的alert_subject来自定义电子邮件主题。 1alert_subject: &quot;Issue &#123;0&#125; ouccurreda at &#123;1&#125;&quot; 123alert_subject_args:- issue.name- &quot;@timestamp&quot; 如果规则匹配索引中的多个对象，则仅使用第一个匹配来填充格式化程序的参数。 Alert Content有几种方法可以格式化给种类型事件的正文： 1234567rule_name = namealert_text = alert_textruletype_text = Depends on typetop_counts_header = top_count_key, &quot;:&quot;top_counts_value = Value, &quot;: &quot;, Counttop_counts = top_counts_header, LF, top_counts_valuefield_values = Field, &quot;: &quot;, Value 默认：123456789body = rule_name [alert_text] ruletype_text &#123;top_counts&#125; &#123;field_values&#125; command命令报警允许你执行任意命令并从匹配中传递参数或stdin。该命令的参数可以使用Python格式的字符串语法来访问匹配的部分内容。报警器将打开一个子进程并可选地传递匹配，或在聚合报警的情况下，将其作为json阿虎组匹配到进程的stdin。 此报警需要一个选项：command——要执行的参数列表或要执行的字符串。如果是列表格式，则第一个参数是要执行的程序名。如果传递了一个字符串，则该命令通过shell执行。 字符串可使用%或.format()进行格式化。这是Python的替换。如果在命令中使用格式化数据，清泪建议使用args列表格式而不是shell字符串。 12345alert:- commandcommand: [&quot;/bin/send_alert&quot;, &quot;--username&quot;, &quot;%(username)s&quot;]#command: [&quot;/bin/send_alert&quot;, &quot;--username&quot;, &quot;&#123;match[username]&#125;&quot;] Email此报警将会发送电子邮件。它默认连接到smtp_host服务器。 它需要一个选项：email——接收报警的地址 Jira Debug调试报警器经使用Python logger的info level记录报警信息。它被记录到名为elastalert的Python logger对象中，可以使用getLogger命令轻松访问该对象。 HTTP POST此报警类型使用HTTP POST将结果发送到JSON ENDPOINT。默认情况下，json会包含所有匹配，除非你指定http_post_payload。 需要：http_post_url 123456alert: posthttp_post_url: &quot;http://example.com/api&quot;http_post_payload: ip: clientiphttp_post_static_payload: apikey: abc123 ElastAlert元数据索引ElastAlert Metadata Index ElastAlert使用Elasticsearch存储有关其状态的各种信息。这不仅允许对ElastAlert操作进行某种程度的审计和调试，而且还可以在ElastAlert关闭、重启或崩溃时避免数据丢失或重复报警。此集群和索引信息在全局配置文件中使用es_host, es_port, writeback_index定义。ElastAlert必须能够写入到此索引。elastalert-create-index将为你创建具有正确映射的索引，并可选择从现有的ElastAlert写回索引中复制文档。 ElastAlert将会在writeback index中创建三种不同类型的文档： elastalert_status elastalert elastalert_error elastalert_statuselastalert_status是为给定规则执行查询的日志，包含： @timestamp rule_name starttime endtime hits： 查询的结果数 matches： 匹配数 time_taken： 查询所用秒数 elastalertelastalert是有关触发的每个报警的日志信息，包含： @timestamp rule_name alert_info alert_sent alert_time match_body alert_exception aggregate_id elastalert_error当ElastAlert发生错误时，它将写入Elasticsearch和stderr。elastalert_error类型包含： @timestamp message traceback data silencesilence是指由于重新设置或使用-silence而抑制给定规则的警报的记录。 @timestamp rule_name until：警报在此开始发送的时间戳 exponent：除非设置了exponential_realert，否则它将为0 添加一个新规则类型Adding a New Rule Type 添加一个新报警器Adding a New Alerter 为规则编写过滤器Writing Filters For Rules 增强功能Enhancements 增强功能是一些模板，可让你在发送警报之前修改匹配项。 kibana-pluginelastalert kibana-plugin是一个第三方插件。ElastAlert Kibana plugin repository: https://github.com/bitsensor/elastalert-kibana-plugin 注意，安装的时候要注意kibana的版本。具体信息见README。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>Logstash</tag>
        <tag>Kibana</tag>
        <tag>Filebeat</tag>
        <tag>Metricbeat</tag>
        <tag>Heartbeat</tag>
        <tag>Packetbeat</tag>
        <tag>Auditbeat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Beanstalkd]]></title>
    <url>%2F2018%2F04%2F10%2FBeanstalkd%2F</url>
    <content type="text"><![CDATA[环境： CentOS7.x86_64 Beanstalkd v1.10 Beanstalkd介绍Beanstalk，一个高性能、轻量级的分布式内存队列系统。高性能离不开异步，异步离不开队列，而其内部都是Producer-Comsumer模式的原理。 Beanstalkd核心概念： job(任务)一个需要异步处理的任务，是beanstalkd中的基本单元，需要放在一个tube中。 tube(管道)一个有名的任务队列，用来存储同一类型的job。是producer和consumer操作的对象。 producer(生产者)job的生产者，通过put命令将一个job放到一个tube中。 consumer(消费者)job的消费者，通过reserve/release/bury/delete命令来获取或改变job的状态。 beanstalkd官方状态图： Beanstalkd特性 优先级支持0-2^32的优先级。值越小，优先级越高，默认是1024。 持久化可通过binlog将job及其状态记录到文件里面。在Beanstalkd下次启动时，可通过读取binlog来恢复之前的job及状态。 分布式容错分布式设计和Memcached类似，beanstalkd个server之间并不知道彼此的存在，都是通过client来实现分布式以及根据tube名称到特定server获取job。 超时控制为了防止某个consumer长时间占用任务但不能处理的情况，beanstalkd为reserve操作设置了timeout。如果该consumer不能在指定时间内完成job，job将被迁移会READY状态，供其它consumer执行。 安装Beanstalkd由于epel源可直接安装beanstalkd，So: 123456789101112yum install -y beanstalkd#配置文件/etc/sysconfig/beanstalkd#启动systemctl start beanstalkd#等同于#/usr/bin/beanstalkd -l 0.0.0.0 -p 11300 -u beanstalkd Beanstalk的客户端和管理端官方没有推出客户端和管理端，GitHub上有一些第三方插件，请自己选择使用。 客户端 pheanstalkd: https://github.com/pda/pheanstalk/ pheanstalk是一个在PHP中操作beanstalkd的客户端。具体使用方法参考README。 管理端 beanstalk_console： https://github.com/ptrofimov/beanstalk_console aurora: https://github.com/xuri/auroraaurora 是一个基于 Web 的 Beanstalk 消息队列服务器管理工具，单文件无需依赖其他组件，支持管理本地和远程多个队列服务器。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Beanstalkd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Supervisor]]></title>
    <url>%2F2018%2F04%2F08%2FSupervisor%2F</url>
    <content type="text"><![CDATA[参考： http://www.supervisord.org 环境： Supervisor 3.3.4 CentOS7.x86_64 介绍 综述Supervisor是一个C/S系统，允许用户在Unix-Like操作系统上控制许多进程。它受如下启发： Convenience Accuracy Delegation Process Group 特点 Simple Centralized(统一) Efficient Extensible Compatible Proven(久经考验) Supervisor组件 supervisord Supervisor的服务器部分被命名为supervisord。负责启动子进程，响应客户端的子进程，重启奔溃或退出的子进程，记录其stderr和stdout，以及生成对应的事件 默认使用的配置文件为/etc/supervisord.conf——Windows-INI格式的文件，由于它包含了未加密的username和password，请保证它安全 supervisorctl Supervisor的客户端部分被命名为supervisorctl。用户可连接到不同的supervisord，status/stop/start子进程，获取supervisord中正在运行的进程列表 通过Unix domain socket或TCP socket与server通信，客户端在执行命令前应该先提供认证。客户端和服务端使用同一个配置文件 Web server Web界面，可通过它查看或控制进程状态 XML-RPC接口 用于询问和控制管理程序及其运行的程序 平台要求 在Unix-Like系统上运行良好 不支持Windows系统 Supervisor运行在Python2.4或之后的版本，不支持Python3 安装安装方法取决于你的操作系统。 通过网络安装 推荐使用setuptools的easy_install 下载Supervisor包并调用一个命令 使用Setuptools的网络安装如果Python解释器安装了Setuptools: 1easy_install supervisor 不使用Setuptools的网络安装如果系统上未安装Setuptools，那么你需要手动去下载Supervisor发行套件和安装它。 PYPI： https://pypi.python.org/pypi/supervisor 123456wget https://pypi.python.org/pypi/supervisor/xxx.tar.gztar -xzf xxx.tar.gzpython setup.py install#它会自动通过网络下载依赖 安装一个分发包一些Linux发行版提供了可通过系统包管理工具安装Supervisor。这些包由第三方制作，包含了对特定发行版的一些修改。 1234yum info supervisoryum search supervisoryum install -y supervisor 通过pip安装1pip install supervisor 创建一个配置文件由于我是通过yum安装，所以supervisor配置文件自动在/etc下自动生成： 默认配置文件： /etc/supervisord.conf建议在此配置文件中加入[include]，默认已包含此配置 目录： /etc/supervisord.d建议将每个配置单独写在此目录下 运行Supervisor 添加一个程序在supervisord为你做任何有用的事情之前，你至少需要在配置文件中添加一个程序部分。program部分将定义在调用supervisord命令时如何运行和管理一个程序。 一个最简单的栗子： 12[program:foo]command=/bin/cat 上面的栗子只命名了一个命令，还有很多其它关于程序部分的设置。 运行supervisord使用supervisord命令启动supervisord，进程将自我守护，并从终端分离。并将操作日志默认放于$CWD/supervisor.log。你可传递-n/--nodaemon标志来将进程放置于前台，这样对于debug很有帮助。 要更改supervisord控制的程序集，请编辑配置文件并kill- HUP，或以其它方式重新启动supervisord进程。 supervisord命令接受许多命令行选项。这些命令行选项中的每一个都会覆盖配置文件中的任何等效值。 详细选项： http://www.supervisord.org/running.html#supervisord-command-line-options 运行supervisorctl使用supervisorclt命令启动supervisorctl客户端。如果需要验证supervisord调用，则系统会要求您提供验证凭据。 123supervisorctl status allsupervisorctl stop all supervisorctl Actions如果在命令行中指定了-i或未指定任何操作(action)，则将启动交互式输入的shell解释操作。 12345678supervisorctl help#查看可操作的actiondefault commands (type help &lt;topic&gt;):=====================================add clear fg open quit remove restart start stop updateavail exit maintail pid reload reread shutdown status tail version Signalssupervisord程序可能会发送某些actions，让它在运行时执行某些操作。你可将这些信号发送到一个单一的supervisord的PID。 信号处理程序 SIGTERM supervisord及其所有子进程都将关闭 SIGINT supervisord及其所有子进程都将关闭 SIGQUIT supervisord及其所有子进程都将关闭 SIGHUP supervisord将关闭所有进程，重新载入配置文件并启动所有进程 SIGUSR2 supervisord将关闭并重新打开主要活动日志和所有子日志文件 运行安全开发人员尽力确保以root身份运行的supervisord进程不会导致意外的权限升级。但supervisord允许在其配置文件中的任意路径规范写入数据，允许任意路径选择可能会造成符号链接工具的漏洞。确保supervisord配置文件的权限安全，除此之外，确保Python PATH和标准库都有足够的文件权限保护。 开机自启由于我是yum安装，所以能够直接使用系统服务管理来设置开机自启。 配置文件Supervisor的配置文件通常命名为supervisord.conf。如果没有指定-c配置文件，应用程序会从以下位置去寻找配置文件： $CWD/supervisord.conf $CWD/etc/supervisord.conf /etc/supervisord.conf /etc/supervisor/supervisord.conf (since Supervisor 3.3.0) ../etc/supervisord.conf (Relative to the executable) ../supervisord.conf (Relative to the executable) 文件格式supervisord.conf is a Windows-INI-style (Python ConfigParser) file.它包含section（[header]）和section中的key/value对。 环境变量使用Python字符串表达式语法%(ENV_X)%，可以在配置文件中使用环境中存在的环境变量 12[program:example]command=/usr/bin/example --loglevel=%(ENV_LOGLEVEL)s [unix_http_server]在此section中应该插入在Unix domain socket上监听的HTTP server的配置参数。如果没有配置此section，则Unix domain socket HTTP server将不会启动。 123456789101112131415161718192021[unix_http_server]#supervisor监听HTTP/XML-RPC请求的Unix domain socket的路径file#socket文件的权限模式chmod#socket的用户和组chown#访问HTTP server需要的认证username#密码可以是明文，或使用SHA加密的字符串password [inet_http_server]监听TCP(internet) socket 的HTTP server的配置参数。如果此section未配置，inet HTTP server将不会启动。 12345678910#tcp host:port，supervisor监听HTTP/XML-RPC请求的地址port#HTTP server认证username#密码可以是明文，或SHA加密passwd [supervisord]与supervisord进程有关的全局设置。 123456789101112131415161718192021222324252627282930313233logfilelogfile_maxbyteslogfile_backps#critical, error, warn, info, debug, tracelogevelpidfileumasknodaemonminfdsminprocs#防止supervisord在启动时清除任何现有子日志文件nocleanupchildlogdiruserdirectorystrip_ansienviromentidentifier [supervisorctl]supervisorctl交互式shell程序。 123456789serverurl#与前面设置的验证账户一致usernamepasswordprompthistory_file [program:x]supervisord知道的应该启动和控制的程序。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566 #该程序启动时将运行的命令command #进程名称process_name #多个实例numproc #用于计算numprocs开始的数量numprocs_start #程序在启动和关闭顺序中的相对优先级priority #当supervisord启动时，改程序将自动启动autostart #程序在启动后需要保持运行以考虑启动成功的总秒数，设置为0表示不需要再任何特定的事件内保持运行startsecs #允许失败的尝试次数，然后放弃并将进程置入fatal状态startretries #自动重启进程autorestart #异常退出码exitcodes #请求停止时用于杀死程序的信号stopsignal #发送停止信号后，等待系统将信号返回给supervisord的秒数stopwaitsecs #将停止信号发送给整个进程组stopagroup #killasgroup #以哪个用户运行该程序userredirect_stderrstdout_logfilestdout_logfile_maxbytesstdout_logfile_backupsstdout_capture_maxbytesstdout_events_enabledstderr_logfilestderr_logfile_maxbytesstderr_logfile_backupsstderr_capture_maxbytesstderr_events_enabledenvironmentdirectoryumaskserverurl [include]如果配置文件包含[include]部分，则它必须包含一个名为files的key。该key中的值包含了其它配置文件。 12#文件空间的空格分隔序列，路径可以是相对或绝对。files [group:x]将同质进程组组合成一个异质进程组通常很有用，所以它们可以作为supervisor各种控制器接口的一个单元进行控制。 12345#程序的逗号分隔列表programs#优先级priority [fcgi-program:x]12345678910#程序的fastCGI socket或TCP或Unix domain socketsocket#为socket指定特定user或groupsocket_owner#指定permission模式socket_mode [eventlistener:x]supervisor允许在配置文件中定义专门的同质进程组(event listener pools)。 12345buffer_sizeeventsresult_handler [rpcinterface:x][rpcinterface:x]适用于希望通过自定义行为扩展supervisor的人们。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Consul]]></title>
    <url>%2F2018%2F04%2F05%2FConsul%2F</url>
    <content type="text"><![CDATA[参考： https://www.consul.io/intro/index.html https://www.consul.io/docs/ Consul Template: https://www.hashicorp.com/blog/introducing-consul-template 环境： CentOS7x86_64 Consul v1.2.0 简介介绍consul是什么，它可以解决哪些问题，以及如何开始使用它。 Consul是什么Consule有多个组件，但总体而言，它是发现(discovery)和配置(config)基础架构(infrastructure)服务的工具。它提供几个关键特点： 服务发现(service discovery) Consul客户端可提供一个服务，如API或mysql，其它客户端能够使用Consul来发现给定服务的提供者。使用DNS或HTTP，应用程序可以轻松找到他们所依赖的服务 健康检查(health checking) Consul可以提供任何数量的健康检查，既可以与给定服务相关联(webserver return 200)，也可与本地节点(内存使用率小于90%)相关联。操作人员可用此信息来监视集群运行状况，服务发现组件使用此信息将流量(traffic)从不健康的主机中引导出去 KV store 应用程序可将Consul的分层Key/Value用于存储任何目的，包括动态配置(dynamic configuration)、功能标记(feature flagging)、协调(coordination)、领导选举(leader election)…简单的HTTP API使其易于使用 多数据中心(Multi Datacenter) Consul支持多数据中心，这意味着Consul的用户不必担心构建额外的抽象层以扩展到多个区域 Consul旨在与DevOps和应用程序开发者保持友好，使其成为现代化 ，弹性基础架构的完美选择。 Consul用例 服务发现(service )服务注册，集成健康检查，使用DNS或HTTP接口使得任何服务都能被其它服务发现。 服务分割(service segmentation)通过自动TLS加密和基于身份的授权实现安全的服务到服务通信。 服务配置(service configuration)功能丰富的 key/value 可轻易配置服务。 Consul基础架构Consul是一个分布式、高可用的系统。 每一个向Consul提供服务的节点都运行一个Consul agent。运行agent对于服务发现或get/set Key/Value不是必需的。agent负责健康检查节点上的服务和节点自身。 agent可与一个或多个Consul server交流。Consul server是数据存储和复制集所在之地。server之间选出一个leader。虽然Consul可以使用一台服务器，但推荐使用3-5台以避免数据丢失的故障情况。对每一个数据中心都推荐使用Consul server cluster。 需要发现其它服务或节点的基础架构组件 可以查询任何Consul server或Consul agent。agent自动将查询发送到server。 每个数据中心运行一组consul server cluster。当发生cross-datacenter服务发现或配置请求时，本地consul server将请求转发给远程数据中心并返回结果。 快速开始安装Consul 二进制包: https://www.consul.io/downloads.html 解压缩，得到一个consul二进制可执行文件，可将其放入系统路径 验证安装: consul 运行consul-agent安装consul后请务必运行agent，agent可运行在server或client模式。每个datacenter必须至少有一台server，推荐3-5台做一个集群。单一server部署非常不安全，在故障情况下数据丢失就不可避免了。 所有其它agents都以client模式运行。client是一个非常轻量化的进程——它注册服务、运行健康检查、转发查询给server。agent必须运行在集群的每个节点上。 启动agent测试consul development模式，不建议在生产环境使用此方法，此处做测试。 12345consul agent -devnetstat -nltp#可根据日志看出agent已成为server，并成为集群leader Consul成员members命令基于gossip protocol并最终保持一致。 12345678910111213consul members#节点名称、监听地址、健康状态、集群角色、版本信息Node Address Status Type Build Protocol DC Segmentzhang22 127.0.0.1:8301 alive server 1.0.6 2 dc1 &lt;all&gt;#使用HTTP API将请求转发给server以获取一致的view of worldculr localhost:8500/v1/catalog/nodes#DNS interface也可以查询节点，默认端口8600dig @127.0.0.1 -p 8600 zhang22.node.consul 停止agent可使用Ctrl + C优雅地终止agent，你可以看到它离开集群并关闭。 优雅关闭，Consul会通知集群其它节点此节点的离开。如果你强制kill agent，则集群的其它节点将检测该节点失败。当成员离开时，其服务和健康检查将从catalog中移除。当成员失败时，其健康状态被标记为critical，但不会从catalog中移除。Consul会自动尝试重连失败的节点，允许它从当前网络条件中修复，知道离开的节点不在联系。 此外，如果agent正作为server在运行，那么优雅地离开对避免造成严重的影响有帮助。 注册服务注册(register)服务并查询(query)服务。 定义一个服务服务可以通过以下两种方法注册： 服务定义(service definition) 调用HTTP API 服务定义是注册服务最常见的方式，我们将构建前面agent的配置。 1234567891011#创建一个consul配置目录mkdir /etc/consul.d#编写服务定义配置文件#假设有一个web服务运行在80端口，添加一个便于query的tagecho &apos;&#123;&quot;service&quot;: &#123;&quot;name: &quot;web&quot;, &quot;tag&quot;: [&quot;rails&quot;], &quot;port&quot;: 80 &#125;&#125;&apos; | tee /etc/consul.d/web.json#重启agent，指定配置目录consul agent -dev -config-dir=/etc/consul.d 如果你想注册多个服务，你可以在配置目录下创建多个服务定义文件。 查询服务一旦agent启动并且服务已同步，我们可通过HTTP API或DNS查询(query)服务。 DNS API使用DNS API(默认8600)查询服务 12345678#DNS name(默认) -- NAME.service.consul#只有IPdig @127.0.0.1 -p 8600 web.service.consul#返回IP/Portdig @127.0.0.1 -p 8600 web.service.consul SRV 我们还可以用DNS API按tag来过滤service。基于标签的查询格式为tag.name.service.consul。 1dig @127.0.0.1 -p 8600 rails.web.service.consul HTTP API除了DNS API，HTTP API(默认8500)同样可用于查询服务。 12#前面定义了web这个servicecurl http://localhost:8500/v1/catalog/service/web catalog API提供了给定服务的所有节点。 12#仅仅健康实例的查询 curl &apos;http://localhost:8500/v1/health/service/web?passing&apos; 更新服务服务定义可以通过更改配置文件并向agent发送SIGHUP来更新。这使得更新服务不会出现任何停机或查询服务不可达的情况。 另外，HTTP API能够用来动态地添加、移除、修改服务。 Consul集群具有多个成员的consul集群。 当consul节点启动时，它不知道任何其它节点，它是一个孤立的集群。为了了解到集群中的其它成员，agent必须要加入一个存在的集群。要加入一个现有的集群，只需知道一个现有成员。当加入集群后，agent将于其此成员闲聊，并迅速发现集群中的其它成员。一个agent可以加入任何其它agent，而不仅仅是server模式的agent。 启动agents123456789101112131415#node1consul agent -server -bootstrap-expect=1 \ -data-dir=/tmp/consul -node=agent-one -bind=ip1 \ -enable-script-checks=true -config-dir=/etc/consul.d#node2consul agent -data-dir=/tmp/consul -node=agent-two \ -bind=ip2 -enable-script-checks=true -config-dir=/etc/consul.d#两个独立的node#现在，我们有两个agent在运行中：一个server，一个client。但是他们两者并不知道对方，并仍然是一个单一节点的集群。#查看节点consul member 加入集群由于我们在启动agent的时候便已指定server，所以从哪个节点加入都一样。 12345678consul join ip#Successfully joined cluster by contacting 1 nodes.consul membersNode Address Status Type Build Protocol DC Segmentagent-one 172.16.129.141:8301 alive server 1.0.6 2 dc1 &lt;all&gt;agent-two 172.16.129.150:8301 alive client 1.0.6 2 dc1 &lt;default&gt; 在启动时自动加入集群理想情况下，每当一个新节点出现在数据中心时，它应该自动加入集群而不需要人工干预。 查询节点就像查询服务，consul有一个API用于查询节点。 123#NAME.node.consul或NAME.node.DATACENTER.conosuldig @localhost -p 8600 agent-one.node.consuldig @127.0.0.1 -p 8600 agent-two.node.consul 离开集群 优雅的退出: Ctrl+C 强制kill 健康检查对节点和服务添加健康检查(health check)。健康检查是服务发现的关键组件，可以防止使用不健康的服务。 定义检查与服务类似，一个检查能够通过定义检查或适当调用HTTP API来两种方式来注册。 定义检查是一个最基本和推荐的方法。 在consul配置目录中创建检查定义文件： 123456789#在基于脚本的健康检查上，它与consul进程使用同样的用户#如果命令以非0状态码退出，则该节点会被标记为unhealthyecho &apos;&#123;&quot;check&quot;: &#123;&quot;name&quot;: &quot;ping&quot;, &quot;args&quot;: [&quot;ping&quot;, &quot;-c1&quot;, &quot;baidu.com&quot;], &quot;interval&quot;: &quot;30s&quot;&#125;&#125;&apos; &gt;/etc/consul.d/ping.jsonecho &apos;&#123;&quot;service&quot;: &#123;&quot;name&quot;: &quot;web&quot;, &quot;tags&quot;: [&quot;rails&quot;], &quot;port&quot;: 80, &quot;check&quot;: &#123;&quot;args&quot;: [&quot;curl&quot;, &quot;localhost&quot;], &quot;interval&quot;: &quot;10s&quot;&#125;&#125;&#125;&apos; &gt;/etc/consul.d/web.jsonconsul reload 检查健康状态123curl http://localhost:8500/v1/health/state/criticaldig @127.0.0.1 -p 8600 web.service.consul KV数据Consul提供了一个易于使用的KV存储。这可以用来保存动态配置，协助服务协调，构建leader选举，并启用开发人员可以考虑构建的任何其它内容。 用法有两种方法与Consul K/V交互的方式： HTTP API Consul KV CLI 123456789101112131415161718192021222324252627282930#CLIconsul kv --helpconsul kv put name zhangconsul kv get name#zhangconsul kv get -detailed nameconsul kv puut -flags=42 who zhang21#所有key都支持设置一个64位的整数标志值#列出所有kvconsul kv get -recurse#删除consul kv delete name#使用 Check-And-Set 进行原子更新consul kv put -cas -modify-index=112 NAME zhang#导出与导入consul kv export &gt; xxx.jsonconsul kv import $xxx.json Web界面Consul支持美观的Web界面。用户界面可以查看所有的服务和节点，查看所有健康检查和当前状态，读取和设置kv数据，并自动支持多数据中心。 123consul agent -ui#localhost:8500/ui 内部详情Consul Internals 介绍Consul内部详情。 架构Architecture 词汇表Glossary Agent Client Server Datacenter Consensus Gossip LAN Geossip WAN Geossip RPC Consensus协议Consul使用consensus(共识) protocol来提供一致性(consistency)，它基于Raft(In search of an Understandable Consensus Algorithm) Raft协议Raft是基于Paxos的共识算法。 Raft的一些关键术语： LogThe primary unit of work in a Raft system is a log entry. FSM(Finite State Machine)An FSM(有限状态机) is a collection of finite states with transitions between them. Peer setThe peer set(对等集) is the set of all members participating in log replication. QuorumA quorum(仲裁) is a majority of members from a peer set: for a set of size n, quorum requires at least (n/2)+1 members. Committed EntryAn entry is considered committed when it is durably stored on a quorum of nodes. LeaderAt any given time, the peer set elects a single node to be the leader. Raft节点总是处于如下三种状态之一： follower(追随者) candidate(候选者) leader(领导者) 所有节点最初都是作为follower开始的。在这种状态下，节点可接受leader的日志条目并投票。如果一段时间内没有收到任何条目，则节点会自我提升到candidate。在candidate状态下，节点请求来自对等节点的投票。如果候选人获得仲裁(quorum)的票数，那么它将被提升为leader。leader必须接受新的日志条目并复制给其它所有follower。另外，如果陈旧读取不可接受，则所有查询也必须在leader上执行。 一旦集群具有leader，它就能够接受新的日志条目。Client可以请求leader添加新的日志条目。然后，leader将条目持久化，并尝试复制到仲裁的follower。一旦日志条目被认为提交(committed)，它就可以应用于有限状态机(FSM)。显然，允许复制日志以无限制的方式增长是不可取的。Raft提供了一种机制，可通过快照(snapshot)当前状态并压缩日志。达成共识是容错的，直到法定人数可用。建议为每个数据中心配置3-5台Consul Server。3个节点的Raft集群可以容忍单个节点故障，5个节点的Raft集群可以容忍2个节点故障。这可最大限制提高可用性。 Raft in Consul只有Consul Server节点参与Raft，并且是对等集的一部分。所有的Client节点都将请求转发给Server。 当启动的时候，单个Consul Server进入bootstrap模式，此模式允许它进行自我选举为leader。leader选出后，可以以一致性和安全性的方式将其它Server添加到对等集，之后，就可以禁用bootstrap模式。由于所有的Server作为对等集的一部分参与，因此他们都知道当前的leader。当一个RPC请求到达了non-leader Server时，请求被转发给leader。 如果RPC是查询(query)类型，意味着它是只读的，则leader根据FSM的当前状态生成结果 如果RPC是事务(transaction)类型，意味着它是可修改的，则leader生成新的日志条目并使用Raft应用它 提交日志条目并将其应用于FSM后，事务就完成了。 由于Raft副本的性质，性能对网络延迟很敏感。因此，每个数据中心选择一个独立的leader并维护一个不相交的对等集。数据由数据中心分区，每个leader仅负责其数据中心中的数据。 一致性模式Consistency Modes 虽然对副本日志的所有写入都通过Raft，但读取却更加灵活。Consul支持3种不同的读取一致性模式： default consistent stale 部署表 Servers Quorum Size Failere Tolerance 1 1 0 2 2 0 3 2 1 4 3 1 5 3 2 6 4 2 7 4 3 Gossip协议Consul 使用gossip协议来管理成员并向集群发送广播信息。所有这些都通过Serf Library提供。 Goossip in ConsulConsul使用两个不同的gossip pools: LAN pool WAN pool 网络坐标Network Coordinates Consul使用网络层层析系统来计算集群中节点的网络坐标。这些坐标允许使用非常简单的计算在任意两个节点之间估计网络往返时间。所有这些都通过使用Serf Library。 Consul中的网络坐标Network Coordinates in Consul 网络坐标在Consul中有多种表现方式： consul rtt Catalog/Health endpoints Prepared query Coordinate endpoint 使用坐标一旦你有了两个节点的坐标，则计算它们间的往返时间是很简单的： 123456&quot;Coord&quot;: &#123; &quot;Adjustment&quot;: 0.1, &quot;Error&quot;: 1.5, &quot;Height&quot;: 0.02, &quot;Vec&quot;: [0.34,0.68,0.003,0.01,0.05,0.1,0.34,0.06]&#125; 会话Sessions consul提供了一个用于构建分布式锁的会话机制。会话充当节点、健康检查和K/V数据之间的监听层。 会话设计 Agent启动和停止Consul Agent是Consul的核心进程。它维护成员关系信息，注册服务，运行检查，响应查询…Consul Agent必须运行在在Consul集群的每个节点上。 Agent有两种运行模式： server client Server节点承担了作为consensus quorum(共识法人)的额外责任，这些节点参与Raft，并在出现故障时提供强大的一致性和可用性。Client节点构成了集群的大部分，它们非常轻便。因为它们与Server进行大部分操作，保持自己的状态则很少。 运行Agent以下是一些重要信息： Node name Datacenter Server Client addr Cluster addr 123456789#直接指定配置项运行consul agent -options#将配置项写入文件，指定配置目录运行mkdir /etc/consul.dvim /etc/consul.d/consul.jsonconsul agent -config-dir=/etc/consul.d 停止Agent有两种停止方式： gracefully发送中断信号ctrl+c或运行kill -INT。优雅地退出，Agent首先通知集群它要离开集群。这样，集群便会通知其它成员该节点已离开。 forcefully通过kill signal来强制杀掉Consul。集群的其余部分最终会检测到该节点已死亡并通知集群节点已失效。 特别重要的是允许Server节点优雅地离开，以便对可用性产生最小的影响。对于Client Agent来说，节点失效和节点离开的区别对用例并不是那么重要。 生命周期Consul集群中的每个Agent都会经历一个生命周期(lifecycle)。当Agent首次启动时，他并不知道集群中的其它任何节点。要发现它的同伴，它必须加入集群。这使用join命令或在配置文件中配置。一旦一个节点加入，这个信息就会传递给整个集群，这意味着所有节点最终都会意识到对方。如果Agent是一个Server，则已经存在的Server就会开始复制(replicating)到新节点。 在网络故障的情况下，某些节点可能无法被其它节点访问。在这种情况下，无法访问的节点被标记为失败(failed)。无法区分网络故障和Agent崩溃，因此两种情况的处理方式都是相同的。该信息将在service catalog中被更新。 当一个节点离开时，它指定了它的意图，并且集群将该节点标记为已离开。与失败(failed)不同，节点提供的所有服务都立即注销(deregistered)。如果Agent是Server，则对其的复制(replication)将停止。 为了防止死亡(failed/left)节点的堆积，Consul会自动将死亡节点从目录中移除。这个过程被称为收割(reaping)。 DNS接口DNS接口允许应用程序利用服务发现，而无需与Consul进行高度整合。 有几个重要的配置项： client_addr ports.dns recursors domain dns_config 数据中心部分是可选的，如果没有提供，则默认为Agent自身的数据中心。 节点查找为了解析名称(name)，Consul依赖于特定的查询格式。基本上有两种类型的查询： node lookup service lookup 1234567#node lookup&lt;node&gt;.node[.datacenter].&lt;domain&gt;node1.node.dc1.consulnode1.node.consuldig @127.0.0.1 -p 8600 node1.node.consul 服务查找服务查找用于查询你服务提供者。 有两种查询方式： 标准查询DNS查询系统利用健康检查信息来防止路由到不健康的节点。为了实现简单的负载均衡，每次返回的节点集都是随机的。 123456[tag.]&lt;service&gt;.service[.datacenter].&lt;domain&gt;redis.service.consulpostgresql.service.dc2.consuldig @127.0.0.1 -p 8600 redis.service.consul SRV RFC 2782查询RFC 2782使用_下划线作为查询中服务和协议值的前缀，以防止DNS冲突。 123_&lt;service&gt;._&lt;protocol&gt;[.service][.datacenter][.domain]dig @127.0.0.1 -p 8600 _rabbitmq._amqp.service.consul SRV Prepared Query LookupsThe query or name is the ID or given name of an existing Prepared Query. 1&lt;query or name&gt;.query[.datacenter].&lt;domain&gt; 可连接的服务查找Connect-Capable Service Lookups. 1&lt;service&gt;.connect.&lt;domain&gt; Caching默认情况下，Consul服务的所有DNS结果都会设置一个为0的TTL。这会禁用DNS结果的缓存。但，很多情况下，缓存对性能和伸缩性都是可取的。 WAN地址转换默认情况下，Consul DNS查询将会返回一个节点的本地地址。如果你需要外部地址，则可使用advertise-wan和translate_wan_addrs选项来配置此行为。 配置Agent有许多通过命令行或配置文件配置的配置项。配置优先级如下： 命令行参数 环境变量 配置文件 配置文件可以是HCL或JSON格式。Consul可通过reload命令重新载入配置文件。 端口Consul默认使用的端口： 8300(tcp)Server RPC. Server用于处理来自其它Agent的传入请求。 8301(tcp/udp)Serf LAN. 用于处理LAN中的gossip，所有Agent都需要。 8302(tcp/udp)Serf WAN. Server用于处理WAN上gossip到其它Server。 8500(tcp)HTTP API. 8600(tcp/udp)DNS Interface. 可重新加载的配置Reloadable Configuration 重新加载配置文件不会加载所有配置项，如下这些配置项是可重新载入的： log level checks services watches http client address node metadata metric prefix filter discard check output rpc rate limiting 配置文件配置文件不仅用于设置代理，还用于提供检查和服务定义。 配置文件选项和命令行参数稍微有点不一样。使用consul agent -h查看具体配置项。 栗子： 12345678910111213141516#开始栗子vim /etc/consul.d/single.json&#123;&quot;bind_addr&quot;: &quot;192.168.1.11&quot;,&quot;bootstrap&quot;: true,&quot;client_addr&quot;: &quot;0.0.0.0&quot;,&quot;datacenter&quot;: &quot;zhang&quot;,&quot;data_dir&quot;: &quot;/var/lib/consul&quot;,&quot;log_level&quot;: &quot;WARN&quot;,&quot;node_name&quot;: &quot;zhang21&quot;,&quot;server&quot;: true,&quot;enable_syslog&quot;: true,&quot;ui&quot;: true&#125; 123456789101112131415161718192021222324#集群配置vim /etc/consul.d/cluster.json&#123; &quot;bind_addr&quot;: &quot;xxx&quot;, &quot;bootstrap_expect&quot;: 2, &quot;client_addr&quot;: &quot;0.0.0.0&quot;, &quot;datacenter&quot;: &quot;zhang&quot;, &quot;data_dir&quot;: &quot;/var/lib/consul&quot;, &quot;encrypt&quot;: &quot;a1b8vAA2==@xyz&quot;, &quot;log_level&quot;: &quot;WARN&quot;, &quot;node_name&quot;: &quot;zhang21&quot;, &quot;node_id&quot;: &quot;zhang21&quot;, &quot;server&quot;: true, &quot;enable_syslog&quot;: true, &quot;ui&quot;: true, &quot;retry_interval&quot;: 20s, &quot;retry_join&quot;: [ &quot;consul.domain.internal&quot;, &quot;10.0.1.2:8301&quot;, &quot;[::1]:8301&quot; ]&#125; 服务定义服务发现的主要目标之一是提供可用服务的目录(catalog)。为此，Agent提供了一种简单的服务定义格式来声明服务的可用性，并可能将其与健康检查相关联。如果健康检查与服务关联，则认为它是应用程序级别。 服务定义服务定义方式： 配置文件(推荐) HTTP API 一个服务定义包含的字段： name(必须) id(可选) tags(可选) address(可选) port(可选) check(可选) meta(可选) enable_tag_override(可选) token(可选) id必须唯一，如果未设置id，默认使用name。 服务可以关联健康检查，这是一个强大的功能。检查必须是脚本、HTTP、TCP或TTL类型。 脚本类型，必须提供参数和间隔 HTTP类型，必须提供http和interval TCP类型，必须提供tcp和interval TTL类型，只能提供ttl 检查名称自动生成为: service:&lt;service-id&gt;，如果有多个服务检查注册，生成的id为： service:&lt;service:-id&gt;:&lt;num&gt;，num是从1开始递增的数字。 栗子： 1234567891011121314151617181920212223242526vim /etc/consul.d/redis.json&#123; &quot;service&quot;: &#123; &quot;name&quot;: &quot;redis&quot;, &quot;id&quot;: &quot;redis01&quot;, &quot;tags&quot;: [ &quot;master&quot; ], &quot;address&quot;: &quot;127.0.0.1&quot;, &quot;port&quot;: 6379, &quot;meta&quot;: &#123; &quot;meta&quot;: &quot;service definition for redis&quot; &#125;, &quot;enable_tag_override&quot;: false, &quot;check&quot;: &#123; &quot;id&quot;: &quot;redisTCP&quot;, &quot;name&quot;: &quot;redis service check&quot;, &quot;tcp&quot;: &quot;localhost:6379&quot;, &quot;interval&quot;: &quot;10s&quot;, &quot;timeout&quot;: &quot;1s&quot; &#125; &#125;&#125; 多个服务定义1234567891011121314151617181920212223242526272829303132333435363738&#123; &quot;services&quot;: [ &#123; &quot;id&quot;: &quot;red0&quot;, &quot;name&quot;: &quot;redis&quot;, &quot;tags&quot;: [ &quot;primary&quot; ], &quot;address&quot;: &quot;&quot;, &quot;port&quot;: 6000, &quot;checks&quot;: [ &#123; &quot;args&quot;: [&quot;/bin/check_redis&quot;, &quot;-p&quot;, &quot;6000&quot;], &quot;interval&quot;: &quot;5s&quot;, &quot;ttl&quot;: &quot;20s&quot; &#125; ] &#125;, &#123; &quot;id&quot;: &quot;red1&quot;, &quot;name&quot;: &quot;redis&quot;, &quot;tags&quot;: [ &quot;delayed&quot;, &quot;secondary&quot; ], &quot;address&quot;: &quot;&quot;, &quot;port&quot;: 7000, &quot;checks&quot;: [ &#123; &quot;args&quot;: [&quot;/bin/check_redis&quot;, &quot;-p&quot;, &quot;7000&quot;], &quot;interval&quot;: &quot;30s&quot;, &quot;ttl&quot;: &quot;60s&quot; &#125; ] &#125;, ... ]&#125; 检查定义Agent的主要角色便是管理系统级和应用级的健康检查。一个检查的定义有两种方式： 配置文件 HTTP API 检查方式： Script + Interval HTTP + Interval TCP + Interval TTL Docker + Interval gRPC + Interval 定义检查A script check: 123456789&#123; &quot;check&quot;: &#123; &quot;id&quot;: &quot;mem-util&quot;, &quot;name&quot;: &quot;Memory utilization&quot;, &quot;args&quot;: [&quot;/usr/local/bin/check_mem.py&quot;, &quot;-limit&quot;, &quot;256MB&quot;], &quot;interval&quot;: &quot;10s&quot;, &quot;timeout&quot;: &quot;1s&quot; &#125;&#125; A HTTP check: 123456789101112&#123; &quot;check&quot;: &#123; &quot;id&quot;: &quot;api&quot;, &quot;name&quot;: &quot;HTTP API on port 5000&quot;, &quot;http&quot;: &quot;https://localhost:5000/health&quot;, &quot;tls_skip_verify&quot;: false, &quot;method&quot;: &quot;POST&quot;, &quot;header&quot;: &#123;&quot;x-foo&quot;:[&quot;bar&quot;, &quot;baz&quot;]&#125;, &quot;interval&quot;: &quot;10s&quot;, &quot;timeout&quot;: &quot;1s&quot; &#125;&#125; A TCP check: 123456789&#123; &quot;check&quot;: &#123; &quot;id&quot;: &quot;ssh&quot;, &quot;name&quot;: &quot;SSH TCP on port 22&quot;, &quot;tcp&quot;: &quot;localhost:22&quot;, &quot;interval&quot;: &quot;10s&quot;, &quot;timeout&quot;: &quot;1s&quot; &#125;&#125; A TTL check: 12345678&#123; &quot;check&quot;: &#123; &quot;id&quot;: &quot;web-app&quot;, &quot;name&quot;: &quot;Web App Status&quot;, &quot;notes&quot;: &quot;Web app does a curl internally every 10 seconds&quot;, &quot;ttl&quot;: &quot;30s&quot; &#125;&#125; A Docker check: 12345678910&#123;&quot;check&quot;: &#123; &quot;id&quot;: &quot;mem-util&quot;, &quot;name&quot;: &quot;Memory utilization&quot;, &quot;docker_container_id&quot;: &quot;f972c95ebf0e&quot;, &quot;shell&quot;: &quot;/bin/bash&quot;, &quot;args&quot;: [&quot;/usr/local/bin/check_mem.py&quot;], &quot;interval&quot;: &quot;10s&quot; &#125;&#125; A gRPC check: 123456789&#123;&quot;check&quot;: &#123; &quot;id&quot;: &quot;mem-util&quot;, &quot;name&quot;: &quot;Service health status&quot;, &quot;grpc&quot;: &quot;127.0.0.1:12345&quot;, &quot;grpc_use_tls&quot;: true, &quot;interval&quot;: &quot;10s&quot; &#125;&#125; 检查脚本使用enable_script_checks选项来启用脚本检查。 检查脚本的退出码(exit code)必须遵循如下约定： exit code o检查通过 exit code 1检查警告 any exit code检查失败 初始化健康检查状态在某些情况下，可能需要指定健康检查的初始状态。 12345678&#123; &quot;check&quot;: &#123; &quot;id&quot;: &quot;mem&quot;, &quot;args&quot;: [&quot;/bin/check_mem&quot;, &quot;-limit&quot;, &quot;256MB&quot;], &quot;interval&quot;: &quot;10s&quot;, &quot;status&quot;: &quot;passing&quot; &#125;&#125; 绑定服务检查健康检查可以选择性地绑定到特定服务。这可以确保健康检查的状态只会影响给定服务的健康状态，而不会影响整个节点。服务绑定检查需要添加一个service_id字段： 12345678&#123; &quot;check&quot;: &#123; &quot;id&quot;: &quot;web-app&quot;, &quot;name&quot;: &quot;Web App Status&quot;, &quot;service_id&quot;: &quot;web-app&quot;, &quot;ttl&quot;: &quot;30s&quot; &#125;&#125; 定义多个检查使用checks来定义多个服务检查。 1234567891011121314151617181920212223&#123; &quot;checks&quot;: [ &#123; &quot;id&quot;: &quot;chk1&quot;, &quot;name&quot;: &quot;mem&quot;, &quot;args&quot;: [&quot;/bin/check_mem&quot;, &quot;-limit&quot;, &quot;256MB&quot;], &quot;interval&quot;: &quot;5s&quot; &#125;, &#123; &quot;id&quot;: &quot;chk2&quot;, &quot;name&quot;: &quot;/health&quot;, &quot;http&quot;: &quot;http://localhost:5000/health&quot;, &quot;interval&quot;: &quot;15s&quot; &#125;, &#123; &quot;id&quot;: &quot;chk3&quot;, &quot;name&quot;: &quot;cpu&quot;, &quot;script&quot;: &quot;/bin/check_cpu&quot;, &quot;interval&quot;: &quot;10s&quot; &#125;, ... ]&#125; 加密Encryption Consul Agent支持加密所有流量。有两个独立的加密系统： gossip流量 RPC gossip加密启用geossip加密只需要你在启动Consul Agent时设置加密密钥(encryption key)。密钥是16Bytes的Base64编码。 123456789consul keygenFDGDpW55oCYJlh555Es1gA==vim /etc/consul.d/cluster.json&#123; &quot;encrypt&quot;: &quot;FDGDpW55oCYJlh555Es1gA==&quot;,&#125; consul集群的所有节点必须共享相同的加密密钥！ RPC加密Consul支持使用TLS来验证Server和Client之间的真实性。它们之间使用由证书机构颁发的密钥对，你可以自己生成CA。 TelemetryConsul Agent收集有关不同库和子系统的各种运行时指标。这些指标以10s为间隔进行汇总，并保留1min。查看这些数据，你需要向Consul进程发送信号： Unix: USR1 Windows: BREAK Consul收到信号后，它将当前的遥测(telemetry)信息转储到Agent’s STDERR。 12#USR1 10kill -10 $&#123;consul-pid&#125; 详情: https://www.consul.io/docs/agent/telemetry.html Watcheswatches是一种指定检测更新的数据视图的方式。检测到更新，将调用外部处理程序。watch使用HTTP API中的blocking query，Agent自动进行适当的API调用已检测更新，并在数据视图更新时通知处理程序。watch可以配置为Agent configuration的一部分，watch也可以在Agent之外启动。 处理程序监测配置指定要监测的数据视图，更新视图后，将调用指定的处理程序(Handler)。外部程序可为可执行程序(executable)或HTTP endpoint。 可执行程序可执行处理程序从stdin读取json信息，此外CONSUL_INDEX环境变量将被设置为Consul Index写入stdout。 12345678&#123; &quot;type&quot;: &quot;key&quot;, &quot;key&quot;: &quot;foo/bar/baz&quot;, &quot;handler_type&quot;: &quot;script&quot;, &quot;args&quot;: [&quot;/usr/bin/my-service-handler.sh&quot;, &quot;-redis&quot;]&#125;#在consul v1.0以后，args数组被添加，以便可在没有shell的情况下运行处理程序 HTTP endpoint当watch被调用时发送HTTP请求给HTTP处理程序。 123456789101112&#123; &quot;type&quot;: &quot;key&quot;, &quot;key&quot;: &quot;foo/bar/baz&quot;, &quot;handler_type&quot;: &quot;http&quot;, &quot;http_handler_config&quot;: &#123; &quot;path&quot;:&quot;https://localhost:8000/watch&quot;, &quot;method&quot;: &quot;POST&quot;, &quot;header&quot;: &#123;&quot;x-foo&quot;:[&quot;bar&quot;, &quot;baz&quot;]&#125;, &quot;timeout&quot;: &quot;10s&quot;, &quot;tls_skip_verify&quot;: false &#125;&#125; 全局参数Global Parameters datacenter token args handler Watch类型 key keyprefix services nodes service checks event 栗子： 123consul watch -type service -service redisconsul watch -type checks -service redis 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#key&#123; &quot;type&quot;: &quot;key&quot;, &quot;key&quot;: &quot;foo/bar/baz&quot;, &quot;args&quot;: [&quot;/usr/bin/my-service-handler.sh&quot;, &quot;-redis&quot;]&#125;#orconsul watch -type=key -key=foo/bar/baz /usr/bin/my-key-handler.sh#keyprefix&#123; &quot;type&quot;: &quot;keyprefix&quot;, &quot;prefix&quot;: &quot;foo/&quot;, &quot;args&quot;: [&quot;/usr/bin/my-service-handler.sh&quot;, &quot;-redis&quot;]&#125;#orconsul watch -type=keyprefix -prefix=foo/ /usr/bin/my-prefix-handler.sh#services&#123; &quot;redis&quot;: []&#125;#nodes[ &#123; &quot;Node&quot;: &quot;node1&quot;, &quot;Address&quot;: &quot;192.168.1.11&quot; &#125;, &#123; &quot;Node&quot;: &quot;node2&quot;, &quot;Address&quot;: &quot;xxx&quot; &#125;]#service&#123; &quot;type&quot;: &quot;service&quot;, &quot;service&quot;: &quot;redis&quot;, &quot;args&quot;: [&quot;/usr/bin/my-service-handler.sh&quot;, &quot;-redis&quot;]&#125;#check[ &#123; &quot;Node&quot;: &quot;foobar&quot;, &quot;CheckID&quot;: &quot;service:redis&quot;, &quot;Name&quot;: &quot;Service &apos;redis&apos; check&quot;, &quot;Status&quot;: &quot;passing&quot;, &quot;Notes&quot;: &quot;&quot;, &quot;Output&quot;: &quot;&quot;, &quot;ServiceID&quot;: &quot;redis&quot;, &quot;ServiceName&quot;: &quot;redis&quot; &#125;]#event&#123; &quot;type&quot;: &quot;event&quot;, &quot;name&quot;: &quot;web-deploy&quot;, &quot;args&quot;: [&quot;/usr/bin/my-service-handler.sh&quot;, &quot;-web-deploy&quot;]&#125;#orconsul watch -type=event -name=web-deploy /usr/bin/my-deploy-handler.sh -web-deploy 指南Consul Guide 本节提供了Consul各种常见的操作指南。 如下： ACLsConsul访问控制列表，该功能用于控制对资源的访问。 Adding/Removing Servers从集群中安全地添加和删除Consul Server，这应该小心操作。 Autopilot为Consul Server提供自动友好操作的管理。 Bootstrapping引导新的数据中心，包括安全地添加初始化Consul Server。 Consul with Container在容器内运行Consul Cluster。 DNS Caching为DNS查询缓存启用TTLS DNS Forwarding从BIND转发DNS查询到Consul External Services注册外部服务。允许在Consul框架内使用第三方服务。 Federation配置Consul以支持多个数据中心。 Geo Failover用准备好的查询来实现服务的地理故障转移。 Leader Election使用Consul构建Client端的领导选举。 Network Segments配置Consul使用网段-支持部分LAN连接。 Outage Recovery恢复因Server故障而无法使用的集群。 Semaphore使用KV存储实现一个信号量 Sentinel使用哨兵模式在Consul中执行策略。 Server PerformanceConsul Server的最低要求以及生产环境中运行Consul Server的指南。 ACLsConsul提供可选的访问控制列表系统，用于控制对数据和API的访问。它依赖于规则的token. 访问控制列表旨在提供易于使用，快速执行和灵活的新策略。 概述ACL Tokens访问控制列表系统基于token(令牌)，由Consul操作者通过 Consul ACL API进行管理。如果没有提供token，则会自动关联与特殊的可配置匿名令牌(anonymous token)的规则。 每个token具有： ID name type client management rule set(规则集) ACL Rules and Scopetoken绑定到一组规则，用于控制令牌可以访问的Consul资源。可在白名单(whitelist)/黑名单(blacklist)下定义策略，这取决于默认策略acl_default_policy的值。 构建规则的ACL策略： agent用于Agent API event用于Event API key用于KV Store API keyring用于Keyring API node用于Catalog API, Health API, Prepare Query API, Network Coordinate API， Agent API operator用于Operator API query用于Prepared Query API serviceCatalog API, Health API, Prepared Query API, Agent API session用于Session API 由于Consul snapshots实际上包含ACL token，因此Snapshot API需要一个管理token进行快照操作。 ACL策略不包括如下资源： Status API Catalog API ACL Datacenter必须使用acl_datacenter配置所有节点(client/server)来启用ACL强制实施，但同时也是权威数据中心。Consul依靠RPC转发来支持多数据中心(multi-datacenter)。但是，由于可以跨数据中心边界发出请求，因此ACL令牌必须在全局范围内有效。为避免一致性问题，单个数据中心被视为具有权威性，并存储规范的令牌集。 配置ACLs使用多个配置项配置ACL： 配置项 Server Client 目的 acl_datacenter required required 为ACL定义权威Consul数据中心来启用ACL的主控制 acl_default_policy 可选 n/a 定义白名单或黑名单模式 acl_down_policy 可选 可选 定义ACL数据中心脱机时执行的操作 acl_ttl 可选 可选 定义缓存ACL的生存时间 配置特殊令牌，允许引导ACL系统或在特殊情况下访问Consul： 特殊令牌 Server Client 目的 acl_agent_master_token 可选 可选 当ACL数据中心不可用或Server脱机时，可用于访问Agent API acl_agent_token 可选 可选 用于Agent内部操作 acl_master_token required n/a 用于引导ACL系统 acl_token 可选 可选 用于未提供token的客户端请求的默认令牌。这通常配置为对服务的只读访问权限，以便在Agent上启用DNS发现 ACL Agent Master Token由于acl_agent_master_token旨在Consul Server不可用时使用，因此其策略在Agent本地管理，并且不需要通过ACL API在Consul Server上定义token。 123456agent &quot;&lt;node name of agent&gt;&quot; &#123; policy = &quot;write&quot;&#125;node &quot;&quot; &#123; policy = &quot;read&quot;&#125; ACL Agent Tokenacl_agent_token是一个特殊令牌，用于Agent的内部操作。用于Agent的如下操作： 使用Catalog API更新Agent的节点条目 执行反熵同步 执行consul_exec命令时，读写KV存储库的特殊_rexec部分 123456789node &quot;node1&quot; &#123; policy = &quot;write&quot;&#125;service &quot;&quot; &#123; policy = &quot;read&quot;&#125;key &quot;_rexec&quot; &#123; policy = &quot;write&quot;&#125; 任何一个可在Agent上注册的服务，service策略需要读访问权限。 引导ACLsBootstrapping ACLs 在新集群上引导ACLs需要几个步骤： Enable ACLs on the Consul Servers引导ACLs的第一步便是在ACL数据中心的Consul Server上启用ACLs，配置如下： 1234567&#123; &quot;acl_datacenter&quot;: &quot;dc1&quot;, &quot;acl_master_token&quot;: &quot;123abc!@#, &quot;acl_default_policy&quot;: &quot;deny&quot;, &quot;acl_down_policy&quot;: &quot;deny&quot;, &quot;acl_down_policy&quot;: &quot;extend-cache&quot;&#125; Create an Agent Token使用ACL API和上一步中设置的ACL Master Token创建令牌： 1234567891011curl --request PUT --header &quot;X-Consul-Token: 123abc!@#&quot; --data \&apos;&#123; &quot;Name&quot;: &quot;Agent Token&quot;, &quot;Type&quot;: &quot;client&quot;, &quot;Rules&quot;: &quot;node \&quot;\&quot; &#123; policy = \&quot;write\&quot;&#125; service \&quot;\&quot; &#123; policy = \&quot;read\&quot; &#125;&quot;&#125;&apos; http://127.0.0.1:8500/v1/acl/create返回的值便是新创建的token&#123;&quot;ID&quot;: &quot;xxxxxxxxxxxxxx&quot;&#125; 返回的值便是新创建的token。将这个值添加到Consul Server配置中，并重启Server： 12345678&#123; &quot;acl_datacenter&quot;: &quot;dc1&quot;, &quot;acl_master_token&quot;: &quot;123abc!@#, &quot;acl_default_policy&quot;: &quot;deny&quot;, &quot;acl_down_policy&quot;: &quot;deny&quot;, &quot;acl_down_policy&quot;: &quot;extend-cache&quot;, &quot;acl_agent_token&quot;: &quot;xxxxxxxxxxxxxxxx&quot;&#125; 或使用API导入token： 1234curl --request PUT --header &quot;X-Consul-Token: 123abc!@#&quot; --data \&apos;&#123; &quot;Token&quot;: &quot;xxxxxxxxxxxxx&quot;&#125;&apos; http://127.0.0.1:8500/v1/agent/token/acl_agent_token Enable ACLs on the Consul Clients还需再Agent上配置ACL 12345678910111213141516&#123; &quot;acl_datacenter&quot;: &quot;dc1&quot;, &quot;acl_down_policy&quot;: &quot;extend-cache&quot;, &quot;acl_agent_token&quot;: &quot;前面的acl_agent_token&quot;&#125;#或使用APIcurl \ --request PUT \ --header &quot;X-Consul-Token: abc123!@#&quot; \ --data \&apos;&#123; &quot;Token&quot;: &quot;xxxxxxxxxxxx&quot;&#125;&apos; http://127.0.0.1:8500/v1/agent/token/acl_agent_token 使用由Server创建的相同ACL Agent token，因为它不是特定于任何节点或前缀集。建议每个Client获取一个ACL agent token，该令牌具有对自己的节点名称前缀的节点有写入权限，以及针对预期在该Client上注册的服务前缀的读权限。 Set an Anonymous Policy (Optional)此时，ACL已通过配置的ACL agent token进行引导，但还没有配置其它策略。甚至像consul members这样的基本操作也会受到ACL默认策略deny的限制。 如果我们提供上面的Token，则能够看到具体信息： 1CONSUL_HTTP_TOKEN=xxxxxxxx consul members 匿名令牌： 123456789curl \ --request PUT \ --header &quot;X-Consul-Token: 123abc!@#&quot; \ --data \&apos;&#123; &quot;ID&quot;: &quot;anonymous&quot;, &quot;Type&quot;: &quot;client&quot;, &quot;Rules&quot;: &quot;node \&quot;\&quot; &#123; policy = \&quot;read\&quot; &#125;&quot;&#125;&apos; http://127.0.0.1:8500/v1/acl/update 某个服务：123456789curl \ --request PUT \ --header &quot;X-Consul-Token: 123abc!@#&quot; \ --data \&apos;&#123; &quot;ID&quot;: &quot;anonymous&quot;, &quot;Type&quot;: &quot;client&quot;, &quot;Rules&quot;: &quot;node \&quot;\&quot; &#123; policy = \&quot;read\&quot; &#125; service \&quot;consul\&quot; &#123; policy = \&quot;read\&quot; &#125;&quot;&#125;&apos; http://127.0.0.1:8500/v1/acl/update Set Agent-Specific Default Tokens (Optional)匿名令牌的替代方法是acl_token配置项。 Create Tokens for UI Use (Optional)如果你使用具有限制性ACL策略的Consul UI，UI将无法使用匿名ACL令牌完整运行。建议使用特定于UI的ACL令牌，可以在Web浏览器绘画期间在UI中设置该令牌对进口进行认证。 123456789curl \ --request PUT \ --header &quot;X-Consul-Token: 123abc!@#&quot; \ --data \&apos;&#123; &quot;Name&quot;: &quot;UI Token&quot;, &quot;Type&quot;: &quot;client&quot;, &quot;Rules&quot;: &quot;key \&quot;\&quot; &#123; policy = \&quot;write\&quot; &#125; node \&quot;\&quot; &#123; policy = \&quot;read\&quot; &#125; service \&quot;\&quot; &#123; policy = \&quot;read\&quot; &#125;&quot;&#125;&apos; http://127.0.0.1:8500/v1/acl/create 规则Rule Specification ACL系统的和核心部分是规则语言，用于描述必须强制执行的策略。使用基于前缀的规则，最具体的前缀匹配决定了操作。使用HCL配置语言来指定规则，规则可定义多个策略。ACL API运行使用HCL或JSON来定义规则部分的内容。 策略有以下集中处理方式： read write(读写) deny 栗子： 12345678910111213# These control access to the key/value store.key &quot;&quot; &#123; policy = &quot;read&quot;&#125;key &quot;foo/&quot; &#123; policy = &quot;write&quot;&#125;key &quot;foo/private/&quot; &#123; policy = &quot;deny&quot;&#125;# This controls access to cluster-wide Consul operator information.operator = &quot;read&quot; Agent RulesAgent策略控制对Agent API中实用程序操作的访问。Agent规则通过节点名称，使用欧冠最长前缀匹配规则。 Agent rules栗子： 123456789agent &quot;&quot; &#123; policy = &quot;read&quot;&#125;agent &quot;foo&quot; &#123; policy = &quot;write&quot;&#125;agent &quot;bar&quot; &#123; policy = &quot;deny&quot;&#125; 如上，对具有空前缀的任何节点可读，对以foo开头的节点名进行读写，拒绝以bar开头的节点名。 Event Rules事件策略控制对事件API中事件操作的访问。事件规则由它们事件名称的前缀，使用最长匹配规则。 Event rules栗子： 123456event &quot;&quot; &#123; policy = &quot;read&quot;&#125;event &quot;deploy&quot; &#123; policy = &quot;write&quot;&#125; Key/Value Rules键值策略控制对KV API中的键值存储操作的访问。 Key规则栗子： 123456789key &quot;&quot; &#123; policy = &quot;read&quot;&#125;key &quot;foo&quot; &#123; policy = &quot;write&quot;&#125;key &quot;bar&quot; &#123; policy = &quot;deny&quot;&#125; List Policy for Keys一个新的键列表策略，只有在通过布尔配置参数acl_enable_key_list_policy选择时才会强制执行。 1234567891011key &quot;&quot; &#123; policy = &quot;deny&quot;&#125;key &quot;bar&quot; &#123; policy = &quot;list&quot;&#125;key &quot;baz&quot; &#123; policy = &quot;read&quot;&#125; Kerring Rules 1keyring = &quot;write&quot; Node Rules 123456789node &quot;&quot; &#123; policy = &quot;read&quot;&#125;node &quot;app&quot; &#123; policy = &quot;write&quot;&#125;node &quot;admin&quot; &#123; policy = &quot;deny&quot;&#125; Operator Rules 1operator = &quot;read&quot; Prepared Query Rules 123456query &quot;&quot; &#123; policy = &quot;read&quot;&#125;query &quot;foo&quot; &#123; policy = &quot;write&quot;&#125; 引导数据中心Bootstrapping a Datacenter 在Consul集群可以开始为请求提供服务之前，必须选在Server节点作为leader。Bootstrapping是将这些初始Server节点加入集群的过程。 建议的引导方式是使用-bootstrap-expect配置项。此配置项告知Consul预期的Server节点数，并在有许多Server可用时自动引导。为了防止不一致和脑裂情况(多个Server认为自己是leader)，所有Server应该指定相同的-bootstrap-expect，或根本不指定任何值。只有指定值的Server才会尝试引导集群。为了防止脑裂情况，Server不会选举自己作为leader。 推荐每个数据中心使用3或5台Server。不建议使用单个服务器部署数据中心。 加入一个集群: 12#On NodeBconsul join NodeA 创建集群要触发选举leader，必须将这些机器连接在一起并创建一个集群。 使用-join和start_join选项手动指定机器列表 使用-retry-join选项手动指定机器列表 leader选举使用Consul构建客户端的领导选举。 有多种方式建立领导选举，我们将专注于Consul sessions。会话允许我们构建一个可以优雅地处理故障的系统。 协调节点Contending Nodes 假设一组节点试图称为给定服务的领导者，参与的所有节点应该就给定的键进行协调。 1servece/&lt;service name&gt;/leader 首先创建会话： 123curl -X PUT &apos;&#123; &quot;Name&quot;: &quot;dbservice&quot; &#125;&apos; http://localhost:8500/v1/session/create这回返回一个JSON对象的session ID 下一步是使用?acquirre=&lt;session&gt;查询参数的KV条目上的PUT方法从此节点获取给定键的会话。PUT的&lt;body&gt;应该是表示本地节点的JSON对象。 1234curl -X PUT -d &lt;body&gt; http://localhost:8500/v1/kv/&lt;key&gt;?acquire=&lt;session&gt;如果返回true，则已获得锁定，并且本地节点时领导者如果返回false，则某个其它节点已获取锁定 通过对&lt;key&gt;的阻塞查询来监视更改，如果注意到&lt;key&gt;的session是空白的，那么就没有领导者，我们应该重新锁定获取。如果领导是自愿下台，这应该通过简单地释放锁来完成： 1curl -X PUT http://localhost:8500/v1/kv/&lt;key&gt;?release=&lt;session&gt; 发现一个领导者Discovering a Leader 关于领导者选举的另一种常见做法是节点希望识别给定服务的领导者。与领导者选举一样，所有参与的节点都应该同意用于协调的密钥(key)。 Client有一个非常简单的角色，它们只需阅读&lt;key&gt;来发现当前的领导者是谁: 1curl http://localhost:8500/v1/kv/&lt;key&gt; 如果密钥没有关联的话，就没有领导者。你可查询/v1/session/info获取session详细信息： 1curl http://localhost:8500/v1/session/info/xxxxxxxxxxx Client还应使用阻塞查询来查看密钥的更改，如果领导者退出或失败将清除与密钥相关联的会话。当选出新的领导者时，密钥值也将更新。 API文档链接: https://www.consul.io/api/index.html Consul的主要接口是RESTful HTTP API。API可对node，service，check，configuration…执行基本的CRUD操作。 版本前缀Version Prefix 所有API路由都以/v1/为前缀，这适用于v1 API。 consul-templateConsul Template 查询consul instance，并更新文件系统上任意数量的指定模板。作为额外的奖励，Consul Template可以在模板更新完成时执行任意命令。 Consul Tempalte可以查询Consul中的服务条目，keys, key values。强大的抽象和模板查询语言是Consul Template非常适合创建动态配置。 如： Apache Nginx HAproxy 安装 下载地址: https://releases.hashicorp.com/consul-template/ 步骤： 下载 解压 添加PATH 1234567891011121314wget https://releases.hashicorp.com/consul-template/0.19.5/consul-template_0.19.5_linux_amd64.tgztar -xzvf ./consul-template_0.19.5_linux_amd64.tgzmv ./consul-template /bin/#ormv consul-template /usr/local/binvim /etc/profileexport PATH=$PATH:/usr/local/binconsul-template --versionconsul-template v0.19.5 (57b6c71) 用法官方栗子： https://github.com/hashicorp/consul-template/tree/master/examples 1consul-template -h 命令行查询demo.consul.io这个consul实例。 渲染模板： 1234consul-template \ -template &quot;/tmp/nginx.ctmpl:/var/nginx/nginx.conf:nginx -s reload&quot; \ -template &quot;/tmp/redis.ctmpl:/var/redis/redis.conf:service redis restart&quot; \ -template &quot;/tmp/haproxy.ctmpl:/var/haproxy/haproxy.conf&quot; 监听Consul： 1consul-template -consul-addr=&quot;consul1:8500&quot; -consul-addr=&quot;consul2:8500&quot; 配置文件配置文件使用 HashiCorp Configuration Language编写的。这意味着，配置也是JSON兼容的。 命令行指定的选项优先于配置文件！ 12345mkdir /etc/consul-templatevim consul-template.hclconsul-template -config=&apos;/etc/consul-template/consul-template.hcl&apos; 配置文件详情： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353# This denotes the start of the configuration section for Consul. All values# contained in this section pertain to Consul.consul &#123; # This block specifies the basic authentication information to pass with the # request. For more information on authentication, please see the Consul # documentation. auth &#123; enabled = true username = &quot;test&quot; password = &quot;test&quot; &#125; # This is the address of the Consul agent. By default, this is # 127.0.0.1:8500, which is the default bind and port for a local Consul # agent. It is not recommended that you communicate directly with a Consul # server, and instead communicate with the local Consul agent. There are many # reasons for this, most importantly the Consul agent is able to multiplex # connections to the Consul server and reduce the number of open HTTP # connections. Additionally, it provides a &quot;well-known&quot; IP address for which # clients can connect. address = &quot;127.0.0.1:8500&quot; # This is the ACL token to use when connecting to Consul. If you did not # enable ACLs on your Consul cluster, you do not need to set this option. # # This option is also available via the environment variable CONSUL_TOKEN. token = &quot;abcd1234&quot; # This controls the retry behavior when an error is returned from Consul. # Consul Template is highly fault tolerant, meaning it does not exit in the # face of failure. Instead, it uses exponential back-off and retry functions # to wait for the cluster to become available, as is customary in distributed # systems. retry &#123; # This enabled retries. Retries are enabled by default, so this is # redundant. enabled = true # This specifies the number of attempts to make before giving up. Each # attempt adds the exponential backoff sleep time. Setting this to # zero will implement an unlimited number of retries. attempts = 12 # This is the base amount of time to sleep between retry attempts. Each # retry sleeps for an exponent of 2 longer than this base. For 5 retries, # the sleep times would be: 250ms, 500ms, 1s, 2s, then 4s. backoff = &quot;250ms&quot; # This is the maximum amount of time to sleep between retry attempts. # When max_backoff is set to zero, there is no upper limit to the # exponential sleep between retry attempts. # If max_backoff is set to 10s and backoff is set to 1s, sleep times # would be: 1s, 2s, 4s, 8s, 10s, 10s, ... max_backoff = &quot;1m&quot; &#125; # This block configures the SSL options for connecting to the Consul server. ssl &#123; # This enables SSL. Specifying any option for SSL will also enable it. enabled = true # This enables SSL peer verification. The default value is &quot;true&quot;, which # will check the global CA chain to make sure the given certificates are # valid. If you are using a self-signed certificate that you have not added # to the CA chain, you may want to disable SSL verification. However, please # understand this is a potential security vulnerability. verify = false # This is the path to the certificate to use to authenticate. If just a # certificate is provided, it is assumed to contain both the certificate and # the key to convert to an X509 certificate. If both the certificate and # key are specified, Consul Template will automatically combine them into an # X509 certificate for you. cert = &quot;/path/to/client/cert&quot; key = &quot;/path/to/client/key&quot; # This is the path to the certificate authority to use as a CA. This is # useful for self-signed certificates or for organizations using their own # internal certificate authority. ca_cert = &quot;/path/to/ca&quot; # This is the path to a directory of PEM-encoded CA cert files. If both # `ca_cert` and `ca_path` is specified, `ca_cert` is preferred. ca_path = &quot;path/to/certs/&quot; # This sets the SNI server name to use for validation. server_name = &quot;my-server.com&quot; &#125;&#125;# This is the signal to listen for to trigger a reload event. The default# value is shown below. Setting this value to the empty string will cause CT# to not listen for any reload signals.reload_signal = &quot;SIGHUP&quot;# This is the signal to listen for to trigger a graceful stop. The default# value is shown below. Setting this value to the empty string will cause CT# to not listen for any graceful stop signals.kill_signal = &quot;SIGINT&quot;# This is the maximum interval to allow &quot;stale&quot; data. By default, only the# Consul leader will respond to queries; any requests to a follower will# forward to the leader. In large clusters with many requests, this is not as# scalable, so this option allows any follower to respond to a query, so long# as the last-replicated data is within these bounds. Higher values result in# less cluster load, but are more likely to have outdated data.max_stale = &quot;10m&quot;# This is the log level. If you find a bug in Consul Template, please enable# debug logs so we can help identify the issue. This is also available as a# command line flag.log_level = &quot;warn&quot;# This is the path to store a PID file which will contain the process ID of the# Consul Template process. This is useful if you plan to send custom signals# to the process.pid_file = &quot;/path/to/pid&quot;# This is the quiescence timers; it defines the minimum and maximum amount of# time to wait for the cluster to reach a consistent state before rendering a# template. This is useful to enable in systems that have a lot of flapping,# because it will reduce the the number of times a template is rendered.wait &#123; min = &quot;5s&quot; max = &quot;10s&quot;&#125;# This denotes the start of the configuration section for Vault. All values# contained in this section pertain to Vault.vault &#123; # This is the address of the Vault leader. The protocol (http(s)) portion # of the address is required. address = &quot;https://vault.service.consul:8200&quot; # This is the grace period between lease renewal of periodic secrets and secret # re-acquisition. When renewing a secret, if the remaining lease is less than or # equal to the configured grace, Consul Template will request a new credential. # This prevents Vault from revoking the credential at expiration and Consul # Template having a stale credential. # # Note: If you set this to a value that is higher than your default TTL or # max TTL, Consul Template will always read a new secret! # # This should also be less than or around 1/3 of your TTL for a predictable # behaviour. See https://github.com/hashicorp/vault/issues/3414 grace = &quot;5m&quot; # This is the token to use when communicating with the Vault server. # Like other tools that integrate with Vault, Consul Template makes the # assumption that you provide it with a Vault token; it does not have the # incorporated logic to generate tokens via Vault&apos;s auth methods. # # This value can also be specified via the environment variable VAULT_TOKEN. token = &quot;abcd1234&quot; # This tells Consul Template that the provided token is actually a wrapped # token that should be unwrapped using Vault&apos;s cubbyhole response wrapping # before being used. Please see Vault&apos;s cubbyhole response wrapping # documentation for more information. unwrap_token = true # This option tells Consul Template to automatically renew the Vault token # given. If you are unfamiliar with Vault&apos;s architecture, Vault requires # tokens be renewed at some regular interval or they will be revoked. Consul # Template will automatically renew the token at half the lease duration of # the token. The default value is true, but this option can be disabled if # you want to renew the Vault token using an out-of-band process. # # Note that secrets specified in a template (using &#123;&#123;secret&#125;&#125; for example) # are always renewed, even if this option is set to false. This option only # applies to the top-level Vault token itself. renew_token = true # This section details the retry options for connecting to Vault. Please see # the retry options in the Consul section for more information (they are the # same). retry &#123; # ... &#125; # This section details the SSL options for connecting to the Vault server. # Please see the SSL options in the Consul section for more information (they # are the same). ssl &#123; # ... &#125;&#125;# This block defines the configuration for connecting to a syslog server for# logging.syslog &#123; # This enables syslog logging. Specifying any other option also enables # syslog logging. enabled = true # This is the name of the syslog facility to log to. facility = &quot;LOCAL5&quot;&#125;# This block defines the configuration for de-duplication mode. Please see the# de-duplication mode documentation later in the README for more information# on how de-duplication mode operates.deduplicate &#123; # This enables de-duplication mode. Specifying any other options also enables # de-duplication mode. enabled = true # This is the prefix to the path in Consul&apos;s KV store where de-duplication # templates will be pre-rendered and stored. prefix = &quot;consul-template/dedup/&quot;&#125;# This block defines the configuration for exec mode. Please see the exec mode# documentation at the bottom of this README for more information on how exec# mode operates and the caveats of this mode.exec &#123; # This is the command to exec as a child process. There can be only one # command per Consul Template process. command = &quot;/usr/bin/app&quot; # This is a random splay to wait before killing the command. The default # value is 0 (no wait), but large clusters should consider setting a splay # value to prevent all child processes from reloading at the same time when # data changes occur. When this value is set to non-zero, Consul Template # will wait a random period of time up to the splay value before reloading # or killing the child process. This can be used to prevent the thundering # herd problem on applications that do not gracefully reload. splay = &quot;5s&quot; env &#123; # This specifies if the child process should not inherit the parent # process&apos;s environment. By default, the child will have full access to the # environment variables of the parent. Setting this to true will send only # the values specified in `custom_env` to the child process. pristine = false # This specifies additional custom environment variables in the form shown # below to inject into the child&apos;s runtime environment. If a custom # environment variable shares its name with a system environment variable, # the custom environment variable takes precedence. Even if pristine, # whitelist, or blacklist is specified, all values in this option # are given to the child process. custom = [&quot;PATH=$PATH:/etc/myapp/bin&quot;] # This specifies a list of environment variables to exclusively include in # the list of environment variables exposed to the child process. If # specified, only those environment variables matching the given patterns # are exposed to the child process. These strings are matched using Go&apos;s # glob function, so wildcards are permitted. whitelist = [&quot;CONSUL_*&quot;] # This specifies a list of environment variables to exclusively prohibit in # the list of environment variables exposed to the child process. If # specified, any environment variables matching the given patterns will not # be exposed to the child process, even if they are whitelisted. The values # in this option take precedence over the values in the whitelist. # These strings are matched using Go&apos;s glob function, so wildcards are # permitted. blacklist = [&quot;VAULT_*&quot;] &#125; # This defines the signal that will be sent to the child process when a # change occurs in a watched template. The signal will only be sent after the # process is started, and the process will only be started after all # dependent templates have been rendered at least once. The default value is # nil, which tells Consul Template to stop the child process and spawn a new # one instead of sending it a signal. This is useful for legacy applications # or applications that cannot properly reload their configuration without a # full reload. reload_signal = &quot;&quot; # This defines the signal sent to the child process when Consul Template is # gracefully shutting down. The application should begin a graceful cleanup. # If the application does not terminate before the `kill_timeout`, it will # be terminated (effectively &quot;kill -9&quot;). The default value is &quot;SIGTERM&quot;. kill_signal = &quot;SIGINT&quot; # This defines the amount of time to wait for the child process to gracefully # terminate when Consul Template exits. After this specified time, the child # process will be force-killed (effectively &quot;kill -9&quot;). The default value is # &quot;30s&quot;. kill_timeout = &quot;2s&quot;&#125;# This block defines the configuration for a template. Unlike other blocks,# this block may be specified multiple times to configure multiple templates.# It is also possible to configure templates via the CLI directly.template &#123; # This is the source file on disk to use as the input template. This is often # called the &quot;Consul Template template&quot;. This option is required if not using # the `contents` option. source = &quot;/path/on/disk/to/template.ctmpl&quot; # This is the destination path on disk where the source template will render. # If the parent directories do not exist, Consul Template will attempt to # create them, unless create_dest_dirs is false. destination = &quot;/path/on/disk/where/template/will/render.txt&quot; # This options tells Consul Template to create the parent directories of the # destination path if they do not exist. The default value is true. create_dest_dirs = true # This option allows embedding the contents of a template in the configuration # file rather then supplying the `source` path to the template file. This is # useful for short templates. This option is mutually exclusive with the # `source` option. contents = &quot;&#123;&#123; keyOrDefault \&quot;service/redis/maxconns@east-aws\&quot; \&quot;5\&quot; &#125;&#125;&quot; # This is the optional command to run when the template is rendered. The # command will only run if the resulting template changes. The command must # return within 30s (configurable), and it must have a successful exit code. # Consul Template is not a replacement for a process monitor or init system. command = &quot;restart service foo&quot; # This is the maximum amount of time to wait for the optional command to # return. Default is 30s. command_timeout = &quot;60s&quot; # Exit with an error when accessing a struct or map field/key that does not # exist. The default behavior will print &quot;&lt;no value&gt;&quot; when accessing a field # that does not exist. It is highly recommended you set this to &quot;true&quot; when # retrieving secrets from Vault. error_on_missing_key = false # This is the permission to render the file. If this option is left # unspecified, Consul Template will attempt to match the permissions of the # file that already exists at the destination path. If no file exists at that # path, the permissions are 0644. perms = 0600 # This option backs up the previously rendered template at the destination # path before writing a new one. It keeps exactly one backup. This option is # useful for preventing accidental changes to the data without having a # rollback strategy. backup = true # These are the delimiters to use in the template. The default is &quot;&#123;&#123;&quot; and # &quot;&#125;&#125;&quot;, but for some templates, it may be easier to use a different delimiter # that does not conflict with the output file itself. left_delimiter = &quot;&#123;&#123;&quot; right_delimiter = &quot;&#125;&#125;&quot; # This is the `minimum(:maximum)` to wait before rendering a new template to # disk and triggering a command, separated by a colon (`:`). If the optional # maximum value is omitted, it is assumed to be 4x the required minimum value. # This is a numeric time with a unit suffix (&quot;5s&quot;). There is no default value. # The wait value for a template takes precedence over any globally-configured # wait. wait &#123; min = &quot;2s&quot; max = &quot;10s&quot; &#125;&#125; 栗子： 123456789101112131415161718192021222324252627282930313233343536373839404142vim /etc/consul-template/consul.hclmax_stale = &apos;10m&apos;wait = &#123; min = &apos;1s&apos; max = &apos;3s&apos;&#125;template &#123; source = &apos;/etc/consul-template/ctmpl/a.ctmpl&apos; destination = &apos;/etc/nginx/conf.d/upstream-a.conf&apos; command = &apos;systemctl reload nginx&apos; perms = 0644&#125;#vim /etc/consul-template/ctmpl/a.ctmplupstream upstream-a &#123; &#123;&#123;range service &apos;a&apos;&#125;&#125; server &#123;&#123;.Address&#125;&#125;:&#123;&#123;.Port&#125;&#125;; &#123;&#123;else&#125;&#125; server 127.0.0.1:12345; &#123;&#123;end&#125;&#125;&#125;#nginxvim /etc/nginx/conf.d/upstream-a.confupstream upstream-a &#123; server 192.168.1.11:12345;&#125; 模板语法Consul Template解析文件以 Go Template创作。Consul Template提供了如下函数： API函数API函数与远程API进行交互，与Consul等外部服务进行通信。 datacenters查询Consul目录中的所有数据中心。 12345678910&#123;&#123; datacenters &#125;&#125;#栗子&#123;&#123; range datacenters &#125;&#125;&#123;&#123; . &#125;&#125;&#123;&#123; end &#125;&#125;#效果dc1dc2]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Consul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker]]></title>
    <url>%2F2018%2F03%2F27%2FDocker%2F</url>
    <content type="text"><![CDATA[参考： Docker文档: https://docs.docker.com/ https://blog.csdn.net/sD7O95O/article/details/78623697 https://www.zhihu.com/question/22969309/answer/34030581 环境： CentOS7x86_64 Docker v18.03 概述Docker是一个开发、shipping、运行应用程序的开放平台。Docker使你能够将应用程序与基础架构(infrastructure)分离开，从而可以快速交付软件。借助Docker，你可以像管理应用程序一样管理基础架构。利用Docker的方法快速进行运输、测试和部署代码，可以显著缩短编写代码和在生存环境中运行代码之间的延迟。 Docker平台Docker提供了在称为容器的松散隔离(isolated)环境中 打包和运行应用程序的能力。隔离性和安全性允许你在给定的主机上同时运行多个容器。容器是轻量级(lightweight)的，因为它们不需要hypervisor的额外负载，而是直接使用主机的内核运行。这意味着，与使用虚拟机相比，你可以在给定的硬件组合上运行更多的容器。你甚至可以在虚拟主机中运行Docker容器。 Docker提供了工具和平台来管理容器的生命周期(lifecycle)： 使用容器开发应用程序及其支持组件 容器成为分发和测试你应用程序的单元 准备好后，将你的应用程序部署到生产环境中，作为容器协调服 Docker引擎Docker引擎是一个包含如下部件的client-server应用程序： Server是称为守护进程的dockerd REST API是指定程序可用于与守护进程进行通信并指示其执行操作的接口 Client是command line interface(CLI) Docker的开源许可协议是Apache2.0 能用Docker做什么快速、一致的交付应用程序 通过允许开发人员在 提供应用程序和服务的本地容器 的标准化环境 下工作，Docker简化了开发生命周期。容器非常适合持续集成(continuous intergration,CI)和持续交付(continuous deliver,CD)工作流程。 考虑如下示例场景： 开发者在本地编写代码，并使用Docker容器分享工作给他们的同事 使用Docker将应用程序push到测试环境，并自动执行和手动测试 当开发人员发现bug，他们能在开发环境中修复bug，并重新部署应用程序到测试环境进行测试和验证 测试完成后，向客户提供修补的应用程序 与将更新的image push到生产环境一样简单 响应式部署和伸缩 Docker的基于容器的平台支持高度可移植的工作负载。Docker container可以运行在笔记本、物理机、虚拟机、云平台… Docker的可移植性和轻量化特性也使得动态管理工作负载非常容易，可以近乎实时地按业务需求扩展或拆分应用程序和服务 在同一硬件上运行更多的工作负载 Docker轻量且快速。它为基于hypersior的虚拟机提供了一种可行、经济高效的替代方案，因此你可以使用更多计算容量来实现业务目标。Docker是高密度环境和中小型部署的理想选择，你需要用更小的资源做更多的事情。 Docker架构Docker使用了client-server的体系架构。客户端向守护进程发送消息，守护进程负责构建、运行和分发 Docker容器。客户端和守护进程可以在同一系统上运行，也可将客户端连接到远程的Docker守护进程。客户端和守护进程使用REST API，通过Unix socket或network interface进程通信。 Docker daemonDocker daemon(dockerd)，监听Docker API请求并管理Docker对象——image、container、network、volume。docker daemon还可与其它docker daemon通信来管理docker service。 Docker clientDocker client(docker)是许多Docker用户与Docker进行交互的主要方式。客户端将命令发送给守护进程，守护进程执行命令。Docker命令使用Docker API，Docker客户端可与多个守护进程进行通信。 Docker registryDocker registry存储Docker image。Docker Hub和Docker Cloud是任何人都可使用的public registry，你可以创建private registry。 docker pull或docker run需要的image便是从配置的registry中提取。docker push推送image到你配置的registry。 Docker对象当你使用Docker时，你会创建和使用 image、container、network、volume、plugin和其它对象。 image镜像是一个只读模板，带有创建Docker容器的说明。通常，镜像基于其它镜像，并具有一些额外的自定义功能。例如，你可构建基于Ubuntu镜像的镜像，但会按照ApacheWeb服务器和应用程序，以及应用程序所需的配置。 你可能创建自己的镜像，或使用由别人创建并推送到registry上的镜像。构建自己的镜像，需要使用简单的语法创建一个Dockerfile，以定义创建镜像并运行它所需的步骤。 container容器是镜像的可运行实例。可将容器连接到一个或多个网络，将存储器连接到它，还可根据当前状态创建新镜像。 默认情况下，容器与其它容器以及主机是相对隔离的。你可以控制容器的网络、存储、其它底层子系统与其它容器或主机的隔离程度。 容器由镜像定义，以及你在创建或启动时提供给它的任何配置选项。当一个容器被移除时，其未被存储在永久存储器中的状态会消失。 栗子： 123#运行一个Ubuntu镜像，交互地连接到本地命令会话docker run -i -t ubuntu /bin/bash 以上命令会发生如下步骤: 如果本地没有Ubuntu镜像，docker会从registry拉取，就好像你手动运行 docker pull ubuntu Docker创建一个新容器，就好像你手动执行docker container create Docker分配一个读写文件系统给容器，作为它的最后一层 如果你没有指定任何网络选项，Docker会创建一个网络接口将容器连接到默认网络。 Docker开启容器并执行/bin/bash 发送exit到/bin/bash，容器停止但并未被移除 service服务允许你伸缩多个Docker守护进程的容器，这些守护进程可以作为一个swarm与多个manager和worker一起工作。默认情况下，该服务在所有node之间进行负载均衡。 底层技术Docker使用GO编写，利用Linux内核的几个特性来提供其功能。 namespace Docker使用一个称为namespace的技术来提供称为容器的独立工作空间。当你运行一个容器时，Docker会为该容器创建一组命名空间。命名空间提供了一个隔离层。容器的每个方面都在单独namespace中运行，并且其访问权限仅限于该单独的namespace。 Docker引擎在Linux上使用如下namespace： pid namespace： 进程隔离 net namespace： 管理网络接口 ipc namespace： 管理对IPC(InterProcess Communication)资源的访问 mnt namespace： 管理文件系统挂载点 ust namespace： 隔离内核和版本标识符(Unix Timesharing System) control groups Linux上的Docker Engine也依赖与另一种称为控制组(cgroups)的技术。cgroup将应用程序限制为一组特定的资源。控制组允许Docker引擎将可用的硬件资源共享给容器，并可选地强制实施限制和约束。例如，你可限制特定容器的内存是CPU使用率等。 union file systems union file systems(UnionFS)，是通过创建layer进行操作的文件系统，使得它们非常轻量和快速。Docker引擎使用UnioFS为容器提供构建block。Docker引擎可以使用多种UnionFS变体，包括AUFS, brrfs, vfs, DeviceMapper… container format Docker引擎将namespace、cgroup、UnionFS组合成一个名为容器格式的包装器。默认的容器格式为libcontainer。 安装Docker有两个可获取的版本： Community Edition(CE) 适合开始使用Docker并尝试基于容器的应用程序的开发人员和小型团队 Enterprise Edition(EE) 专为企业开发和IT团队而设计，可以在生产规模上构建，发布和运行关键业务应用程序 CentOS7安装Docker CEOS要求 CentOS7.x centos-extras repository 推荐使用overlay2存储驱动 安装新版本Docker需卸载老版本Docker Docker CE包被称为docker-ce 安装Docker CE https://download.docker.com/ 多种安装方法： Docker’s repository RPM package scripts 使用repository安装： 12345678910111213141516171819202122232425262728 #安装依赖yum install -y yum-utils device-mapper-persistent-data lvm2 #设置repositoryyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo #安装Docker CEyum install -y docker-ce #Docker安装但未启动，docker group会被创建，但没有用户添加到组中 #在生产环境中，你可能需要安装特定版本的Docker CE，而不是最新版yum list docker-ce --showduplicates | sort -ryum search docker-ce --showduplicates #开启dockersystemctl start docker #测试dockerdocker run hello-world #此命令下载一个测试image并将其运行到container中 #Hello from Docker! 使用package安装： 1234567891011 #下载rpm包https://download.docker.com/linux/centos/7/x86_64/stable/Packages/ #安装yum install -y /path/docker-cexxx.rpmsystemctl start dockerdocker run hello-world 使用scripts安装： 123456curl -fsSL get.docker.com -o get-docker.shsh get-docker.sh #手动添加group合userusermod -aG docker your-user 卸载Docker CE123456yum remove docker-ce #默认文件rm -rf /var/lib/docker #你还需要手动删除其它配置文件 开始 关于DockerDocker文档会有如下讲解： 设置你的Docker环境 在一个容器(container)中构建并运行一个镜像 延伸你的APP以便在多个容器中运行 在整个集群中分配你的APP 通过添加后端数据库来堆栈服务 将应用部署到生产 Docker的概念Docker是开发人员，系统管理员使用容器来开发、部署和运行APP的平台。使用Linux容器来部署APP被称为集装箱化(containerzation) 集装箱受欢迎的几点原因： 灵活(flexible) 轻量(lightweight) 通用(Interchangeable) 可移植(portable) 延伸(scalable) 堆栈(stackable) 镜像和容器通过运行镜像(image)启动容器(container)。镜像是一个可执行包，包含运行APP所需的所有内容：代码，库，环境变量，配置文件… 容器是镜像的运行时(runtime)实例。在Linux上使用docker ps命令查看运行的容器列表。 容器和虚拟机容器在Linux本地上运行，并与其它容器共享主机Kernel。它是一个独立的进程，不占其它可执行文件内存，使其轻量化。 虚拟机(VM)运行一个完整的访客操作系统，通过虚拟机管理程序访问主机资源。一般来说，虚拟机比大多数应用程序需要的资源更多。 准备Docker环境Docker版本： CE: Docker Community Edition EE: Docker Enterprise Edition Install Docker 测试Docker12345678910111213141516171819202122docker --version#查看详细信息docker info#测试安装工作是否正常docker run hello-world#查看镜像docker image ls#列出容器docker container ls -all#docker命令dockerdocker container --help 小结集装箱化使得CI/CD无缝： 持续集成(Continuous integration, CI) 持续部署(continuous deployment, CD) APP无系统依赖 更新能够推送到分布式APP的任何部分 资源密度可以被优化 使用Docker，扩展APP的过程就是启动新的可执行文件，而不是运行繁重的VM主机。 容器Container 先决条件1docker run hello-world 介绍是时候使用Docker方式来构建一个APP了。 从应用程序的层次结构底部开始，这是一个容器(container) 在此级别之上，是一个服务(service)，它定义了容器在生产中的表现 最后，顶层是堆栈(stack)，定义所有服务的交互(interaction) Like this: Stack Service Container 新开发环境在过去，如果你要开始编写一个Python APP，你的第一要务是在你的机器运行时安装Python。但是，这会造成你的计算机上的环境，需要如预期般完美适合你的APP，并且还需要与你的生产环境相匹配。 使用Docker，你可以将一个可移植的Python运行时作为一个image，无需安装。接着，你的构建可以将基础Python image与APP代码一起包含在内，确保你的APP，依赖项…都构建一起。 使用Dockerfile定义一个容器Dockerfile定义了容器内环境中发生的事情。访问的网络接口(network interface)和磁盘驱动(disk driver)等资源是在此环境中虚拟化的(virtualized)，与系统其余部分隔离。因此你需要将端口映射(map port)到外部世界，并明确指定要将哪些文件复制到此环境中。但是，在完成这些后，你完全可以将它们看做一致 —— 在Dockerfile中定义的构建的APP的行为与它运行时的行为完全相同。 Dockerfile 创建一个空目录，并创建一个名叫Dockerfile的文件，复制以下内容： 1234567891011121314151617181920# Use an official Python runtime as a parent imageFROM python:2.7-slim# Set the working directory to /appWORKDIR /app# Copy the current directory contents into the container at /appADD . /app# Install any needed packages specified in requirements.txtRUN pip install --trusted-host pypi.python.org -r requirements.txt# Make port 80 available to the world outside this containerEXPOSE 80# Define environment variableENV NAME World# Run app.py when the container launchesCMD [&quot;python&quot;, &quot;app.py&quot;] 注意代理服务器会阻断你与APP的连接！ 这个Dockerfile引用了一些我们还没有创建的文件，分别是app.py和requirements.txt。接下来创建它们。 APP自身创建另外的文件，如上面的app.py和requirements.txt，并将它们与Dockerfile放置于同一目录下。这就完成了我们的APP，这看起来非常简单。当这个Dockerfile被构建成一个image时，由于Dockerfile的ADD命令，app.py和requirements.txt仍然存在，而且由于使用了EXPOSE命令，app.py的输出仍可以通过HTTP访问。 requirements.txt: 12FlaskRedis app.py: 123456789101112131415161718192021222324from flask import Flaskfrom redis import Redis, RedisErrorimport osimport socket# Connect to Redisredis = Redis(host=&quot;redis&quot;, db=0, socket_connect_timeout=2, socket_timeout=2)app = Flask(__name__)@app.route(&quot;/&quot;)def hello(): try: visits = redis.incr(&quot;counter&quot;) except RedisError: visits = &quot;&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;&quot; html = &quot;&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;&quot; \ &quot;&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;&quot; \ &quot;&lt;b&gt;Visits:&lt;/b&gt; &#123;visits&#125;&quot; return html.format(name=os.getenv(&quot;NAME&quot;, &quot;world&quot;), hostname=socket.gethostname(), visits=visits)if __name__ == &quot;__main__&quot;: app.run(host=&apos;0.0.0.0&apos;, port=80) 在容器内访问主机的名称将检索容器ID，这进程ID类似。 仅此而已，在你的系统中，你不需要任何Python或requirements.txt文件，也不需要在你的系统上安装 构建或运行的image。看起来你并没有真正用Python和Flask建立一个环境，但是你确实已经拥有了。 构建APP我们准备去构建(build)APP。确保你仍在目录的顶层。 123456789101112131415161718192021222324252627282930313233343536373839404142#查看是否还在顶层lsDockerfile app.py requirements.txt#在此目录运行build命令，这将创建一个Docker image，用 -t 命名docker build -t friendlyhello .#查看你build的imagedocker image lsREPOSITORY TAG IMAGE ID CREATED SIZEfriendlyhello latest b24e21d7645f 13 minutes ago 150MB#运行APPdocker run -p 4000:80 friendlyhello#测试curl http://localhost:4000links http://localhost:4000#在后台运行docker run -d -p 4000:80 friendlyhello#查看容器docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES146662dca737 friendlyhello &quot;python app.py&quot; 16 seconds ago Up 16 seconds 0.0.0.0:4000-&gt;80/tcp goofy_chaplygin#停止Ctrl + Cdocker container stop docker-IDdocker container stop 146662dca737 端口重映射4000:80是为了证明Dockerfile中的EXPOSE与使用docker run -p发布的内容之间的区别。在后续步骤中，我们只需将主机的80端口映射到容器的80端口就好。 分享你的image为了演示刚才创建的image的可移植性(portability)，让我们上传build的image并在其它地方run它。毕竟，当你需要将container部署到生产环境时，你需要知道如何push注册。 注册表(registry)是一个repository的集合，而repository是image的集合——有点类似于GitHub repository，但代码是已经构建了的。注册表上的账户可以创建许多repository。docker CLI 默认使用Docker’s public registry。你也可以选择其它注册表，或创建自己的注册表。 使用Docker ID登录： 如果没有Docker账户，请先注册 。 1234567891011121314151617docker logindocker login -u zhang21#时候docker login认证过后，会有~/.docker/config.json文件，里面包含了docker认证信息#k8s可使用此信息添加secretcat ~/.docker/config.json&#123; &quot;auths&quot;: &#123; &quot;https://index.docker.io/v1/&quot;: &#123; &quot;auth&quot;: &quot;base64encoding&quot; &#125; &#125;, &quot;HttpHeaders&quot;: &#123; &quot;User-Agent&quot;: &quot;Docker-Client/18.03.1-ce (linux)&quot; &#125; 标记image： 使用username/repository:tag将本地image与registry中的repository相关联。tag是可选的，但推荐使用tag。因为它是注册管理机构用于为Docker image提供版本的机制。为该内容提供一个有意义的repository和tag，例如get-started:part2。 12345678docker tag image username/repository:tag#例子docker tag friendlyhello zhang/test:tag-test#查看tagdocker images ls 发布image： 123456#上传你标记了的image到repositorydocker push username/repository:tagdocker push zhang21/test:tag-test#完成后，此image便可以公开获取 从远处repository拉取并运行image： 无论在哪里执行docker run，它都会将你的image以及Python和所有依赖关系一起拉取下来，并运行你的代码。 123docker run -p 4000:80 username/repository:tagdocker run -p 80:80 zhang21/test:tag-test 本节基础命令123456789101112131415161718192021222324252627282930313233343536373839404142434445#从Dockerfile创建imagedocker build -t image-name .#运行imagedocker run -p 4000:80 image-name#后台运行docker run -d -p 4000:80 image-name#列出运行的容器docker container ls#列出所有容器，包括未运行docker container ls -a#优雅停止容器docker container stop 容器ID#强制停止docker container kill 容器ID#删除容器docker container rm 容器ID#删除所有容器docker container rm $(docker container ls -a -q)#列出镜像docker image ls#列出所有镜像docker image ls -a#删除镜像docker image rm 镜像ID#删除所有镜像docker image rm $(docker image ls -a -q)#登录docker login#标记docker tag 镜像 username/repository:tag#上传到注册表docker push username/repository:tag#从注册表拉取docker run username/repository:tag 服务service 先决条件 安装Docker 获取Docker Compose 阅读Orientation 阅读Container 确保已发布friendlyhello image到你的registry 确保你的image工作为一个部署的container。docker run -p 80:80 username/repo:tag 介绍在此，我们扩展(scale)APP并启用负载均衡(load balancing)。要做到这样，我们必须在分布式(distributed)应用程序的层次结构中升一级: 服务 Stack Service Container 关于服务在分布式应用程序中，应用程序的不同部分称为服务(service)。 例如，一个视频共享站点。那么它可能包含： 用于将应用程序数据 存储到数据库中的服务 用户上传后的视频转码服务 前端服务 … 服务是真正的生产环境中的容器。一个service只运行一个image，但它可修改image的运行方式 —— 哪个端口、容器应该运行多少个副本以便于服务所需的容量等.伸缩服务会更改运行该软件的容器实例数量，从而为进程中的服务分配更多的计算资源。 在Docker平台上定义、运行和伸缩服务都是很简单的 —— 只需修改docker-compose.yml文件。 你的第一个docker-compose.yml文件docker-compose.yml是一个YAML文件，它定义了Docker container在生产中的行为方式。 docker-compose.yml： 将如下信息保存为docker-compose.yml，确保你已经pushed the image到registry，并通过修改.yml文件的image detail来替换username/repo:tag。 12345678910111213141516171819version: "3"services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 resources: limits: cpus: "0.1" memory: 50M restart_policy: condition: on-failure ports: - "80:80" networks: - webnetnetworks: webnet: docker-compose.yml文件告诉Docker之下如下操作： pull the image Run 5 instances of that image as a service called web 限制每个实例最多使用10%的CPU和50MB的RAM 如果一个失败，马上重启container 映射主机的80端口到web的80端口 指示web container通过称为webnet的负载均衡网络共享80端口 使用默认设置定义webnet网络 运行你的负载均衡APP12345678910111213141516171819202122232425262728293031323334docker swarm init#运行并设置APP名字docker stack -c docker-compose.yml app-namedocker stack -c docker-compose.yml LoadBalance#在一个主机上，单个服务栈通过部署的image运行5个container instance#获取service IDdocker service lsID NAME MODE REPLICAS IMAGE PORTS3d1a48yse0t4 LoabBalance_web replicated 5/5 zhang21/test:tag-test *:80-&gt;80/tcp#查看服务中的任务docker service ps app-name_webdocker container ls -q#5个容器IDc7ce0075890e52ba026bf28c6d4381be438fbd297a42e89d357b05cc38eb#访问的时候容器ID会在此5个负载中变化 在服务中运行的单个container称为任务(task)。任务是具有数字增量的唯一ID，最大数量是在docker-compose.yml中定义的副本数量。 伸缩APP通过修改docker-compose.yml中replicas的值，并重新运行docker stack deploy -c xxx app-name来伸缩APP。 Docker执行就地更新，不需要stack down或kill any containers. 卸下APP和swarm： 12345678#appdocker stack rm app-namedocker stack rm LoadBalance#swarmdocker swarm leave --force 使用Docker扩展APP非常简单。 本节命令1234567891011121314151617181920212223#列出栈或APPdocker stack ls#运行指定配置文件docker stack deploy -c &lt;composefile&gt; &lt;appname&gt;#列出与APP相关联的服务docker service ls#列出与APP相关联的任务docker service ps &lt;service&gt;#检查任务docker inspect &lt;task or container&gt;#列出容器IDdocker container ls -q#除掉APPdocker stack rm &lt;appname&gt;#从管理中除掉一个单一节点swarmdocker swarm leave --force swarm 先决条件 前面几个小节的内容 介绍前面你将一个服务运行在生产环境，并扩展为5个副本进程。 在此，你将APP部署到到集群上，并在多台机器上运行它。通过将多台主机连接到成为swarm的Dockerized集群，使得多容器、多主机应用成为可能。 理解swarm集群swarm是一组运行Docker并加入到集群中的机器。这样以后，你可以在集群的swarm manager上执行Docker命令。swarm中的机器可以是物理的或虚拟的，当他们加入swarm后，他们便被成为node。 swarm manager可以使用多种策略来运行容器，你可在compose file中指定相应的策略。 swarm manager是swarm中唯一可以执行命令、授权其他机器作为工作者加入swarm的机器。工作者(worker)只能在那提供能力(capacity)，并没有权力告诉任何机器能够做什么。 但目前为止，你已经在本机机器上以单主机(single host)模式使用Docker。但Docker也可以切换为swarm(集群)模式，这就是使用swarm的原因。立即启用swarm模式使得当前机器成为swarm manager。从此，Docker将运行在你管理的swarm上执行命令，而不仅仅是在当前机器上执行。 建立swarm一个swarm由多个节点组成，不管它是虚拟机还是物理机。 基本概念很简单，运行docker swarm init来开启swarm模式并使得当前机器成为swarm manager 在其它机器上运行docker swarm join使他们作为worker加入swarm 栗子：使用VM快速创建两台机器的集群，并将其变为swarm。 使用docker-machine创建一对VM: 123456789101112131415161718192021#CentOS7#安装VirtualBoxwget https://download.virtualbox.org/virtualbox/5.2.8/VirtualBox-5.2-5.2.8_121009_el7-1.x86_64.rpm &amp;&amp; yum install -y Virtual.xx.rpm#安装docker-machine curl -L https://github.com/docker/machine/releases/download/v0.14.0/docker-machine-`uname -s`-`uname -m` &gt;/tmp/docker-machine &amp;&amp; install /tmp/docker-machine /usr/local/bin/docker-machine#在BIOS中开启虚拟化支持#在VMware中开启虚拟化支持(如果是VM)docker-machine create --driver virtual myvm1docker-machine create --driver virtual myvm2#列出虚拟机docker-machine ls 初始化swarm并添加node 第一台机器作为swarm manager，执行命令和join认证，后面的机器作为worker。 你可以使用docker-machine ssh发送命令到VM。在swarm mananger上执行docker swarm init初始化： 12345678docker-machine ssh &lt;swarm manager&gt; &quot;docker swarm init --advertise-assr &lt;mananger-IP&gt;&quot;#add workerdocker swarm jion --toker &lt;token&gt; &lt;wroker-ip&gt;:&lt;port&gt;#添加managerdocker swarm join-token manaer 由于我的虚拟的无法使用VT，因此我用的两台机器两个Docker来做swarm。 123456789101112131415161718#初始化这台机器默认为managerdocker swarm init#作为worker加入，ip是manager的#以下信息会在manager初始化时生成#注意防火墙，可能会阻碍加入docker swarm join --toker &lt;toker&gt; &lt;ip:port&gt;docker swarm join --token SWMTKN-1-3vrbnuneu0hyu41evxlhbn5fp04ad5jvg9v5rzvdaedg2bghkt-e24mjnni3hu7782t3gkz0ny39 172.16.129.150:2377#查看swarmdocker node ls#离开swarmdocker swarm leave 在swarm集群上部署APP主需要记住，只有swarm manager才能执行docker命令，worker仅仅是容量(capacity)。 在swarm manager上使用docker-composr.yml和docker stack deploy命令来部署APP。使用docker service ps &lt;service name&gt;来验证部署。 123456789101112131415161718192021222324#在manager部署docker stack deploy -c ./docker-compose.yml LoadBalancedocker service lsdocker stack ls#注意node名docker stack ps LoadBalanceID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS6nrn4mwc6pvt LoadBalance_web.1 zhang21/test:tag-test zhang22 Running Preparing 2 minutes agobpssrnzesl7n LoadBalance_web.2 zhang21/test:tag-test zhang22 Running Preparing 2 minutes agokmhd8p5wkc12 LoadBalance_web.3 zhang21/test:tag-test zhang21 Running Running 2 minutes agoi0pkf4foms87 LoadBalance_web.4 zhang21/test:tag-test zhang22 Running Preparing 2 minutes agorvtpjk781frn LoadBalance_web.5 zhang21/test:tag-test zhang21 Running Running 2 minutes ago#分别访问个主机的IP#创建的网络在它们之间共享并负载均衡links ip1links ip2 两个IP地址工作的原因是集群中的节点参与入口(ingress)路由网络(routing mesh)。这可以确保部署在swarm中某个端口的服务始终将该端口保留给自己，而不管实际运行容器的节点是什么。 清理并重启1docker stack rm LoadBalance stack先决条件，已完成前面的步骤。 介绍你已到达分布式应用程序层次结构的顶端——stack。堆栈是一组相互关联的服务，它们可以共享依赖关系，并可以进行协调和缩放。单个堆栈能够定义和协调整个应用程序的功能(尽管非常复杂的应用程序可能需要使用多个堆栈)。 在前面使用的docker deploy——是运行在单主机上的单个服务堆栈，这通常不会发生在生产环境中。在这里，你会使用学到的东西使多个服务相互关联，并在多台机器上运行它们。 添加一个新服务并部署docker-compose2.yml 12345678910111213141516171819202122232425262728293031version: &quot;3&quot;services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 restart_policy: condition: on-failure resources: limits: cpus: &quot;0.1&quot; memory: 50M ports: - &quot;80:80&quot; networks: - webnet #可视化 visualizer: image: dockersamples/visualizer:stable ports: - &quot;8080:8080&quot; volumes: - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; deploy: placement: constraints: [node.role == manager] networks: - webnetnetworks: webnet: 新增的东西使web对等服务，称为visualizer。注意两个事： volumes: 给予visualizer访问主机Docker的socket文件 placement： 确保服务运行在manager而不是worker上 123456789docker stack deploy -c ./docker-compose2.yml stack-testCreating network stack-test_webnetCreating service stack-test_visualizerCreating service stack-test_web#查看visualizer，要等一会才能正常访问，别着急访问 IP:8080 持久化数据让我们再次通过相同的工作流程来添加用于存储应用程序数据的Redis数据库。 docker-compose3.yml，添加一个Redis服务器： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253version: &quot;3&quot;services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 restart_policy: condition: on-failure resources: limits: cpus: &quot;0.1&quot; memory: 50M ports: - &quot;80:80&quot; networks: - webnet visualizer: image: dockersamples/visualizer:stable ports: - &quot;8080:8080&quot; volumes: - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; deploy: placement: constraints: [node.role == manager] networks: - webnet redis: image: redis ports: - &quot;6379:6379&quot; volumes: - &quot;/home/docker/data:/data&quot; deploy: placement: constraints: [node.role == manager] command: redis-server --appendonly yes networks: - webnetnetworks: webnet:#部署docker stack deploy -c docker-compose3.yml redis-test#测试访问 IP:port Redis是一个Docker library中的官方image，并被授予redis镜像名称。 redis规范中有几件事使数据在这个堆栈的部署之间持续存在： redis运行在manager，所以它总是使用相同的文件系统 redis将数据存储在上面的目录 确保redis服务始终使用相同的主机 确保存储的数据的连续性 如果没有创建，redis会将数据存储在容器文件系统的/data中，如果该容器被重新部署，则数据将被清除。 部署APP先决条件为前面的操作步骤。 介绍compose file在生产环境中的效果与在您的计算机上的效果相同。 选择版本我安装的是社区版(ce)。如果你在生产环境中使用docker-ce，则可以使用Docker Cloud帮助管理你的应用程序，如AWS、Aliyun、腾讯云。docker cloud： , 可注册后建立、上传、管理自己的repo。 设置和部署： 连接Docker Cloud并授权它自动为你配置Dockerize VM 使用Docker Cloud创建你的计算资源和swarm 部署应用程序 连接DockerCloud你可以标准模式或swarm模式运行Docker Cloud。 AWS配置指南 Aliyun配置指南 腾讯云配置指南 创建swarm你可在Docker Cloud UI创建你的node，或docker swarm init|join命令。 在云提供商上部署应用程序 我觉得阿里云和腾讯云也有对应的平台。 运行部署命令: docker stack deploy -c xxx.yml &lt;cus_appname&gt;，现在你的APP就运行在云提供商上。 运行swarm命令来验证部署 12345docker node lsdocker service lsdocker service ps &lt;service&gt; 在云提供商开放端口 service type protocol port web http tcp 80 visualizer http tcp 8080 redis tcp tcp 6379 具体操作参见各云提供商。 迭代和清理 改变*.yml文件伸缩应用程序 使用docker stack deploy部署应用程序 push和pull image 使用docker stack rm &lt;name&gt;清除stack 修改Docker默认路径docker默认的目录为/var/lib/docker，但很多时候/var目录并没有单独挂载，可能导致空间不够。前提是你已经把源配置目录对应的文件拷贝到替换的目录。 方法1： 123456789101112131415systemctl stop dockercd /etc/dockervim daemon.json&#123; &quot;graph&quot;: &quot;/opt/docker&quot;&#125;systemctl start docker#systemctl reload docker#查看变更docker info 方法2: 123456789101112systemctl stop dockercd /etc/sysconfig/vim docker-storageDOCKER_STORAGE_OPTIONS=--graph=/opt/dockersystemctl start docker#查看变更docker info 容器服务自启动在运行docker容器时可以加如下参数来保证每次docker服务重启后容器也自动重启: 1234docker run --restart=always -d -p 80:80 &lt;container-id&gt;#对于已启动的容器服务，更新它docker update --restart=always &lt;container-id&gt; 交互式容器进入Docker容器以获得交互式体验。 123docker exec -it &lt;container&gt; /bin/bashdocker exec -it &lt;container&gt; /bin/sh 使用systemd默认情况下，容器是不直接支持使用systemd的。可在运行容器时添加选项来使用systemd。 12#centos:7docker run -dit --privileged --name=centos7-systemd centos:7 init 日志 docker服务日志： journalctl -u docker.service docker容器日志： &lt;docker-graph&gt;/containers/&lt;container-id&gt;/&lt;container-id&gt;-json.log 由于容器ID会变化，请注意提取容器ID 可使用ELK在此收集容器日志 更新镜像使用docker commit从改变的容器中生成一个新镜像。 更新镜像步骤： 备份镜像: docker tag 运行镜像 修改容器 生成新镜像: docker commit 推送镜像: docker push 动态映射端口如何给运行中的容器添加映射端口。有两种方法: 将运行的容器生成一个新镜像，之后有这个镜像重新映射端口 通过iptables 第一种方法就相当于重新启动一个镜像，在启动时重新映射端口。实在是麻烦。 由于docker 命令设置端口映射其实也就是下发 iptables 规则，所以我们可以直接创建 iptables 规则进行端口流量转发。 123456789#查看本机docker iptabels rulesiptables-save#我的一个hexo镜像#-A DOCKER -d 172.17.0.2/32 ! -i docker0 -o docker0 -p tcp -m tcp --dport 4000 -j ACCEPT#再它在添加一个端口iptables -t nat -A DOCKER ! -i dokcer0 -p tcp -m tcp --dport 56789 -j DNAT --to-destination 172.17.0.2:56789 备份与恢复 备份容器 docker commit: 生成新镜像 docker save： 生成本地tar包 1234567891011121314Usage: docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]docker commit -m &quot;Just a test&quot; -p $&#123;container-id&#125; Zhang21/test:01docker image lsdocker logindocker pushUsage: docker save [OPTIONS] IMAGE [IMAGE...] [flags]docker save -o /path/$&#123;image&#125;.tar $&#123;image&#125;ls /path 恢复容器 docker run ${image} docker load: 载入本地.tar镜像 1234Usage: docker load [OPTIONS]docker load -i /path/$&#123;image&#125;.tardocker image ls 应用场景与注意事项 应用场景 本地依赖 搭建环境 微服务 自动测试 部署过程 CI/CD 多租户环境 一台机器的多个APP 弹性伸缩 资源隔离 注意事项 一个进程，一个容器不推荐在Docker容器中运行多个进程！ 不要将数据存放到容器内所以请使用挂在卷的方式映射到本地磁盘目录 使用磁盘进行数据存储 容器通信每当一个Docker容器需要与另一个容器通信时，传递信息最好使用名称或环境变量。 以non-root用户运行Docker默认情况下，Docker容器以root用户身份运行，众所周知，以root用户运行的容器完全可以控制主机系统。 注意容器的体积选择一个容器的主要原因之一是它的体积小。但是，如果你把它做得更大，它的主要优势就没了。 制定控策略开发和部署Docker容器不是你的工作的结束。您需要持续监控已部署的容器以及整个系统的运行状况。选择合适的工具并制定一个策略来有效地监控您的Docker容器，以确保最短的停机时间，从而使客户满意。 安全问题安全补丁、防火墙… Dockerfile参考: https://docs.docker.com/engine/reference/builder/ https://yeasy.gitbooks.io/docker_practice/content/image/build.html 将镜像每一层的修改、安装、配置、操作的命令写入Dockerfile，并用它来构建、定制镜像，那么镜像构建透明性问题便会得到解决。 Dockerfile是一个文本文件，包含了一条条指令(instrction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 使用Dockerfile定制镜像 FROM所谓指定镜像，就是以一个镜像为基础，在其上进行定制。基础镜像必须指定，而FROM就是指定基础镜像，因此一个Dockerfile中FROM是必备的指令，并且必须是第一条指令。 只有有可能，请使用当前官方repo作为你的基础镜像。我们推荐使用Alpine镜像，因为它严格控制，体积小(只有5MB)，同时也是完整的Linux发行版。 Docker Hub中有很多常用的官方镜像——常用软件、常用语言和常用系统镜像。 12345FROM nginx#特殊镜像，scratch，空白镜像FROM scratch RUN在多行中使用反斜杠\或复杂的RUN语句，使Dockerfile更具可读性、易理解性和可维护性。 RUN指令是用来执行命令行命令的。有两种格式： shell格式 RUN &lt;CMD&gt;，就像直接在命令行中输入命令一样 exec格式 RUN [&quot;可执行文件&quot;, &quot;参数&quot;]，这更像函数调用中的格式 12345678910FROM debian:jessieRUN apt-get updateRUN apt-get install -y gcc libc6-dev makeRUN wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot;RUN mkdir -p /usr/src/redisRUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1RUN make -C /usr/src/redisRUN make -C /usr/src/redis install Dockerfile中的每一个指令都会建立一层，RUN也不例外。每一个RUN的行为，就和手工建立镜像的过程一样 —— 新建立一层，在其上执行这些命令，执行结束后，commit这一层的修改，构成新的镜像。 上面这种写法，创建了7层镜像，这是完全没有意义的，而且很多运行时不需要的东西都被装进了镜像里，比如编译环境和更新的软件包等。结果就会产生非常臃肿、非常多层的镜像，不仅增加了构建部署的时间，也容易出错。这是很多初学Docker的人常犯的一个错误。 UnionFS是Linux、FreeBSD的文件系统服务，UnionFS是有最大层数限制的。 修改后的Dockerfile： 1234567891011121314FROM debian:jessieRUN buildDeps=&apos;gcc libc6-dev make&apos; \ &amp;&amp; apt-get update \ &amp;&amp; apt-get install -y $buildDeps \ &amp;&amp; wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot; \ &amp;&amp; mkdir -p /usr/src/redis \ &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \ &amp;&amp; make -C /usr/src/redis \ &amp;&amp; make -C /usr/src/redis install \ &amp;&amp; rm -rf /var/lib/apt/lists/* \ &amp;&amp; rm redis.tar.gz \ &amp;&amp; rm -r /usr/src/redis \ &amp;&amp; apt-get purge -y --auto-remove $buildDeps 仅仅使用一个RUN指令，并使用&amp;&amp;将各指令串联起来。将之前的7层简化为1层。在编写Dockerfile时，要经常提醒自己，这并不是在写shell脚本，而是在定义每一层该如何构建。 Dockerfile支持shell类的换行\、注释#等格式，良好的格式，如换行、缩进、注释等，会让维护、排障更为容易，这也是一个好习惯。 此外，还可看到命令最后添加了清理工作的命令，删除了为编译构建所需要的软件，清理了所有下载文件。这很重要，镜像是多层存储，每一层的东西并不会在下一层被删除，会一直跟随镜像。因此，构建镜像时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。很多人初学docker制作出了很臃肿的镜像，原因之一就是顽疾了每一层构建的最后一定要清理无关文件。 构建镜像在Dockerfile目录下执行： 1234567#docker build [OPTIONS] PATH | URL | - [flags]#Build an image from a Dockerfile#-t指定镜像名称#.指的是上下文目录docker build -t nginx:test . 构建上下文(content) 上面的.是在指定上下文路径。 当我们在进行镜像构建的时候，并非所有的定制都会通过RUN指令完成，经常会需要一些本地文件复制进镜像，比如通过COPY, ADD指令。而docker build命令并非是在本地构建镜像，而是在服务端，也就是Docker引擎dockerd中构建的。那么在这种C/S架构中，如何才能让服务端获得本地文件呢？ 这就引进了上下文的概念。当构建的时候，用户会指定构建镜像的上下文的路径，docker build命令得知这个路径后，会将路径下的所有内容打包，然后上传给Docker引擎。这样Docker引擎收到这个上下文包后，展开就会获得构建镜像所需的一切文件。 12#复制上下文目录下的package.jsonCOPY ./package.json /app/ 因此COPY这类指令中的源文件的路径都是相对路径，因为绝对路径已经超出了上下文的范围，Docker引擎无法获取这些位置的文件。如果真需要这些文件，请将它们复制到上下文目录中去。 理解构建上下文对于镜像构建很重要，避免犯一些不应该的错误。 一般来说，应将Dockerfile置于一个空目录下，或者项目根目录下。如果该目录下没有所需文件，则应该把所需文件复制一份过来。如果目录下有些东西不希望构建时传给Docker引擎，可以写一个.dockerignore文件，用于剔除不需要作为上下文传递给Docker引擎的。 实际上，Dockerfile的文件名并不要求必须为Dockerfile，也并不要求必须位于上下文目录中。可使用-f指定某个文件为Dockerfile。 其它docker build的用法 直接使用Git repo进行构建 1234#docker build URLdocker build https://github.com/twang2218/gitlab-ce-zh.git#:8.14#docker会自己去clone、切换分支、并进入指定目录开始构建 使用给定tar压缩包构建 123docker build http://server/context.tar.gz#自动下载/解压缩 压缩包，以其作为上下文，开始构建 从标准输入中读取Dockerfile进行构建 1234567docker build - &lt; Dockerfilecat Dockerfile | docker build -docker build - &lt; context.tar.gz Dockerfile指令Dockerfile提供了十多个指令供我们操作。 LABLE你可以为你的镜像添加标签，以助于通过项目来组织镜像，记录相关信息。 123456# Set multiple labels at once, using line-continuation characters to break long linesLABEL vendor=ACME\ Incorporated \ com.example.is-beta= \ com.example.is-production="" \ com.example.version="0.0.1-beta" \ com.example.release-date="2015-02-12" COPY尽管ADD和COPY在功能上相似，但一般来说，COPY是首选，因为它比ADD更透明。COPY只支持将本地文件复制到容器中，而ADD具有一些功能(如提取tar文件和远程URL支持) COPY,复制文件。从构建上下文目录中&lt;源路径&gt;的文件/目录复制到新的一层的镜像内的&lt;目标路径&gt;位置。 源路径可以是多个，或通配符(需满足Go的规则)目标路径可是容器内的绝对路径，也可是相对于工作目录(WORKDIR)的相对路径。目标路径不需要事先创建。使用COPY指令，源文件的各种元数据都会保留 —— 如读、写、执行权限、文件变更时间… 12345678910111213141516COPY &lt;sourch&gt; &lt;destination&gt;#或COPY [&quot;&lt;source1&gt;&quot;, ... &quot;&lt;destination&gt;&quot;]#栗子COPY package.json /usr/src/app/COPY hom* /mydir/COPY hom?.txt /mydir/#目录COPY dir/ /dir/#复制目录的错误用法#COPY dir/* /dir/ ADDADD是更高级的复制文件。ADD和COPY的格式和性质基本一致，但增加了一些功能。ADD支持通过URL从远程服务器读取资源，但对远程的压缩包没有解压缩功能。尽可能的使用COPY，因为COPY的语义很明确，就是复制文件而已，而ADD则包含了更复杂的功能，其行为也不一定很清晰。最适合ADD的场合，就是所提及的需要自动解压缩的场合。 因此在COPY和ADD指令中选择的时候，可以遵循这样的原则，所有的文件复制均使用COPY指令，仅在需要自动解压缩或远程资源的场合使用ADD。 12345678FROM scratchADD ADD http://foo.com/bar.go /tmp/main.goADD abc.tar.gz / &amp;&amp; \ http://example.com/big.tar.xz /usr/src/things/ &amp;&amp; \RUN tar -xJf /usr/src/things/big.tar.xz -C /usr/src/thingsRUN make -C /usr/src/things all CMDCMD，容器启动命令。用于运行镜像中包含的软件以及任何参数。 也有两个格式： shell格式： CMD &lt;command&gt; shell格式，在实际中会被包装成sh -c的参数形式进行执行： 123456789CMD echo $HOME#转变为CMD[&quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot;]#-c string If the -c option is present, then commands are read from string.#这就是为什么我们可以使用环境变量的原因，因为这些环境变量会被 shell 进行解析处理 exec格式： CMD [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot; ...]CMD几乎总是以此格式使用。 Docker不是虚拟机，容器就是进程。既然是进程，那么在启动容器的时候，需要指定所运行的程序及参数。CMD指令就是用于指定默认的容器主进程的启动命令的。`` 对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。 ENTRYPOINTENTRYPOINT，入口点。指令格式同样分为shell格式和exec两种。 ENTRYPOINT和CMD一样，都是在指定容器启动程序及参数。当指定了ENTRYPOINT后，CMD的含义就发生了改变，不再是直接的运行其命令，而是将CMD的内容作为参数传给ENTRYPOINT指令。即变为如下模式： 1&lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; 有几大好处： 让镜像变成像命令一样使用 12345678910111213#可以从腾讯上拉取，快一些#ccr.ccs.tencentyun.com/qcloud/ubuntuFROM ubuntu:16.04RUN apt-get update \ &amp;&amp; apt-get install -y curl \ &amp;&amp; rm -rf /var/lib/apt/lists/*CMD [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://ip.cn&quot; ]docker build -t myipdocker run myip#当前 IP：182.150.x.xx 来自：四川省成都市 电信 不过命令总有参数，例如我想查看HTTP header，使用-i参数 1234567docker run myip -i#这样会报错，-i替换了CMD命令，而不是-s参数，然而-i并不是命令#重新完整输入命令docker run myip curl -s http://ip.cn -i#这样又太麻烦 这时便可以使用ENTRYPOINT解决这个问题。 1234567891011121314FROM ubuntu:16.04RUN apt-get update \ &amp;&amp; apt-get install -y curl \ &amp;&amp; rm -rf /var/lib/apt/lists/*ENTRYPOINT [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://ip.cn&quot; ]docker build it myipdocker run myip#当前 IP：182.150.x.xx 来自：四川省成都市 电信docker run myip -i#成功 当存在ENTRYPOINT后，CMD的内容将作为参数传递给ENTRYPOINT，而-i就是新的CMD，因此会作为参数传递给curl，从而达到预期效果。 应用运行前的准备工作 有时，在启动前需要做一些准备工作。 如MySQL，需要一些配置文件、初始化工作，这些工作需要在MySQL server运行前解决 避免使用root用户去启动服务，从而提高安全性 这些准备工作和CMD无关 ENVENV，设置环境变量。为了使新软件更容易运行，使用此命令为你的容器内安装的软件更新环境变量。 两种格式： ENV &lt;key&gt; &lt;value&gt; ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 123ENV PATH $PATH:/root/bin \ EMAIL abc@zhang21.cn \ NAME=&quot;Zhang21&quot; 下列指令可以支持环境变量展开： ADD, COPY, ENV, EXPOSE, LABEL, USER, WORKDIR, VOLUME, STOPGIGNAL, ONBUILD。 通过环境变量，我们可以让一份Dockerfile制作更多的镜像，只需使用不同的环境变量即可。 ARGARG，构建参数 格式： ARG &lt;参数名&gt;[=&lt;默认值&gt;] 构建参数和ENV的效果一样，都是设置环境变量。所不同的是，ARG所设置的构建环境的环境变量，在将来容器运行时是不会存在这些环境变量的。 VOLUMEVOLUME，定义匿名卷。用于显示有docker容器创建的任何数据库存储区域，配置存储或文件/文件夹。强烈建议将VOLUME用于镜像的任何可变部分和用户可用部分。 格式： VOLUME [&quot;&lt;路径1&gt;&quot;, &quot;&lt;路径2&gt;&quot;...] VOLUME &lt;路径&gt; 容器运行时应该尽量保持容器存储层不发生写操作，对于数据库类需要保存动态数据的应用，其数据库文件应该保存于卷(volume)中。为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在Dockerfile中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会像容器存储层写入大量数据。 123456#在运行时自动挂载为匿名卷VOLUME /data#覆盖挂载docker run -d -v mydata:/data xxx EXPOSEEXPOSE，声明容器监听连接的端口。 格式： EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...] EXPOSE指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在Dockerfile中写入这个声明有两个好处： 一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便映射 另一个用处则是在运行时使用随机端口映射(未定义时) 要将EXPOSE和在运行时使用-p &lt;宿主端口&gt;:&lt;容器端口&gt;区分开。EXPOSE仅仅声明容器打算使用哪些端口，并未包含端口映射。 WORKDIRWORKDIR，指定工作目录。为了清晰可靠，请使用绝对路径。 使用WORKDIR指令可以来指定工作目录，以后各层的当前目录就被改为指定的目录，如目录不存在，WORKDIR会帮你建立目录。如果需要改变Dockerfile各层的工作目录的位置，那么应该使用WORKDIR指令。 格式： WORKDIR &lt;工作目录&gt; USERUSER，指定当前用户。如果服务可以在非特权模式下运行，请使用USER将其改为non-root用户。首先在Dockerfile中创建相应的用户和组: 12RUN groupadd -r group &amp;&amp; \ useradd -r -g group group USER和WORKDIR相似，都是改变环境状态并影响以后的层。WORKDIR是改变工作目录，USER则是改变之后的层执行RUN, CMD, ENTRYPOINT这类命令的身份。这个用户必须存在。 格式： USER &lt;用户名&gt; 12USER redisRUN [&quot;redis-server&quot;] HEALTHCHECKHEALTHCHECK，健康检查HEALTHCHECK指令告诉docker应该如何进行判断容器的状态是否正常。 格式： HEALTHCHECK [选项] CMD &lt;命令&gt;， 设置检查容器健康状况的命令 HEALTHCHECK NONE， 如果基础镜像有健康检查，使用这行可以屏蔽其健康检查指令 当在一个镜像指定了HEALTHCHECK指令后，用其启动容器，初始状态会为starting，在HEALTHCHECK指令检查成功后变为healthy，如果连续一定次数失败，则会变为unhealthy。和CMD, ENTRYPOINT一样，HEALTHCHECK 只可以出现一次，如果写了多个，只有最后一个生效。 ONBUILDONBUILD，为他人做嫁衣。 ONBUILD是一个特殊的指令，它后面跟的是其它指令。而这些指令，在当前镜像构建时不会被执行。只有当以当前镜像为基础镜像(父镜像)，去构建下一级镜像(子镜像)的时候才会被执行。ONBUILD命令在子镜像的Dockerfile中任何命令之前执行。Dockerfile中的其它指令都是为了定制当前镜像而准备的，唯有ONBUILD是为了帮助别人定制自己而准备的。 格式： ONBUILD &lt;其它指令&gt; Dockerfile多阶段构建全部放入一个Dockerfile 将所有的构建过程包含在一个Dockerfile中，包括项目及其依赖库的编译、测试、打包等流程。这可能会带来一些问题： Dockerfile特别长，可维护性降低 镜像层次多，镜像体积较大，部署时间变长 源代码存在泄漏的风险 分散到多个Dockerfile 事先在一个Dockerfile将项目及其依赖库编译测试打包好后，再将其拷贝到运行环境中。这种方式需要编写两个Dockerfile和一些编译脚本才能将两个阶段自动整合起来。这种方式虽然可以很好避免全部写入一个Dockerfile的风险，但明显部署过程较复杂。 多阶段构建 使用多阶段构建我们就可以很容易解决前面提到的问题，并且只需要编写一个Dockerfile。 Dockerfile最佳实践 一般性建议 容器应该是短暂的 使用.dockerignore文件 使用多阶段构建减少镜像大小 避免安装不必要的包 一个镜像只运行一个进程 镜像层数尽可能少 将多行参数排序 构建缓存 Dockerfile指令 FROM LABEL RUN CMD EXPOSE ENV ADD COPY ENTRYPOINT VOLUME USER WORKDIR Compose file参考: https://docs.docker.com/compose/compose-file/ 使用Docker进行开发Develop with Docker 在Docker上开发应用程序Develop new apps on Docker Learn to build an image from a Dockerfile Use multistage builds to keep your images lean Manage application data using volumes and bind mounts Scale your app as a swarm service Define your app stack using a compose file General application development best practices 了解有关Docker上特定语言的开发： Java node.js Ruby on Rails .Net ASP.Net Docker开发最佳实践Docker development best practices 如下开发模式已被证明有助于人么使用Docker构建应用程序。 如何保持较小的镜像How to keep your images small 在启动容器或服务时，小图像可以更快速通过网络pull镜像并加载到内存中。有几条经验法则可保持较小的镜像： 从适当的基础镜像开始例如，如果需要JDK，请考虑官方镜像，而不是从一个通用的Ubuntu/Centos镜像并将Openjdk作为Dockerfile的一部分安装开始。 使用多阶段构建例如，你可以使用maven镜像构建java程序，然后重置到tomcat镜像，并将java构件复制到正确位置以部署应用程序，所有这些都位于相同的Dockerfile。这意味着你的最终镜像不包含构建时所引入的所有库和依赖项，仅包含运行它们所需的构件和环境。 如果你有多个共同的镜像，请考虑使用共享组件创建你的基本镜像，并在其上创建独特的镜像Docker只要家在一次通用层，然后便会缓存。 保持生产环境镜像精简但允许调试(degub)，请考虑使用生产环境镜像作为调试镜像的基本镜像 在构建镜像时，应该始终使用有用的标签对其进行标记，如(test, prod)。不要依赖自动创建的latest标签 何处以及如何持久化应用程序数据Where and how to persist application data 避免使用存储驱动(storge drivers)将应用程序的数据存储在容器的可写层(writeable layer)中与使用卷(volume)或绑定挂载(bound mounts)相比，这增加了容器的大小，并且从I/O角度来看效率较低 使用卷存储数据 适合使用绑定挂载的一种情况是在开发过程中，对于生产环境，请改用卷 对于生产环境，使用secerts来存储服务使用的敏感的应用程序数据，使用config来存储不敏感的数据(如配置文件) 尽可能使用swarm服务Use swarm services when possible 在可能的情况下，使用swarm服务进行伸缩的能力来设计你的应用程序 即使你只需运行单个实例，swarm服务也比standalone容器提供更多的优势 网络和卷可使用swarm服务连接和断开，并且docker可以以不中断的方式重新部署各个服务容器。standalone容器需要手动停止/移除/重新创建 一些功能仅适用于服务而不适用于standalone容器 让docker stack deploy处理任意镜像，而不是使用docker pull。通过这种方式，你的部署不会尝试从down的节点进行pull。此外，当新节点添加到集群时，镜像会自动pull 使用CI/CD进行测试和部署Use CI/CD for testing and deployment CI(Continuous integration) CD(continuous deployment) 当更新源码库或创建拉取请求时，请使用CI/CD pipeline 自动构建并标记Docker镜像，并对其进行测试。也可将测试过的应用程序直接部署到生产环境中 Develop images编写Dockerfile的最佳实践Best practices for writing Dockerfiles Docker通过读取Dockerfile(一个包含命令的文本文件)中的命令来自动构建镜像。Dockerfile reference: https://docs.docker.com/engine/reference/builder/ Dockerfile由read-only layer组成，每层代表一个Dockerfile指令。如: 1234FROM ubuntu:15.04COPY . /appRUN make /appCMD python /app/app.py 每个命令创建一个层: FROM从ubuntu:15.04 Docker image创建一个层 COPY从Docker client的当前目录添加文件 RUN使用make构建你的应用程序 CMD指定在容器内运行的命令 当你运行镜像并生成容器时，会在基础层的顶部添加一个可写层(writable layer)，也称容器层(container layer)。对正在运行的容器所做的所有更改(增删改文件)都会写入此可写容器层。 一般准则和建议General guidelines and recommendations 创建临时(ephemeral)容器 Create ephemeral containers由Dockerfile定义的镜像应该生成尽可能临时的容器。临时的意思为容器可以被停止(stop)和销毁(destroy)，然后重建(rebuild)并使用绝对最小化的设置和配置来替代。 理解构建上下文 Understand build context当你发出docker build命令时，当前的工作目录被称为构建上下文(build context)。默认情况下，假设Dockerfile位于此，但你也可以使用文件标志(-f)指定位置。无论Dockerfile位于何处，当前目录内的所有内容(除了.dockerignore中忽略的内容)都将作为构建上下文发送给Docker守护进程。 从stdin读取Dockerfile Pipe Dockerfile through stdin 12345678910111213#local build-contextdocker build -t . -f-&lt;&lt;EOFFROM busyboxRUN echo &quot;hello world&quot;COPY . /my-copied-filesEOF#remotedocker build -t foo https://github.com/thajeztah/pgadmin4-docker.git -f-&lt;&lt;EOFFROM busyboxCOPY LICENSE config_local.py /usr/local/lib/python2.7/site-packages/pgadmin4/EOF 使用.dockerignore排除文件 Exclude with .dockerignore要排除与构建无关的文件，请使用.dockerignore文件，这与.gitignore类似。 12345vim ./dockerignorefile1dir2... 使用多阶段构建 Use multi-stage builds多阶段构建允许你大幅缩减镜像大小，而不需要减少中间层和文件数。由于镜像是在构建过程的最后阶段构建的，因此可以通过利用构建缓存(build cache)来最小化镜像层 例如，如果你的版本博涵包含多个层，你可以从 不经常改动的版本到频繁改动的版本进行排序: 安装构建应用程序需要的工具 安装或更新依赖库 生成应用程序 A Dockerfile for Go application: 123456789101112131415161718192021222324FROM golang:1.9.2-alpine3.6 AS build# Install tools required for project# Run `docker build --no-cache .` to update dependenciesRUN apk add --no-cache gitRUN go get github.com/golang/dep/cmd/dep# List project dependencies with Gopkg.toml and Gopkg.lock# These layers are only re-built when Gopkg files are updatedCOPY Gopkg.lock Gopkg.toml /go/src/project/WORKDIR /go/src/project/# Install library dependenciesRUN dep ensure -vendor-only# Copy the entire project and build it# This layer is rebuilt when a file changes in the project directoryCOPY . /go/src/project/RUN go build -o /bin/project# This results in a single layer imageFROM scratchCOPY --from=build /bin/project /bin/projectENTRYPOINT [&quot;/bin/project&quot;]CMD [&quot;--help&quot;] 不要安装不必要的包 Don’t install unnecessary packages为了减少复杂性、依赖性，文件大小和构建时间，避免安装额外的或不不必要的软件包。 分离应用程序 Decouple applications每个容器应该只有一个问题。将应用程序分离到多个容器中可以更轻松地水平伸缩和重新使用容器。例如，Web应用程序堆栈可能有三个独立的容器组成，每个容器都有其独特的镜像，以分离的方式管理Web应用程序、数据库和内存缓存。 将每个容器限制为一个进程是一个很好的经验法则，但不是硬性规定。(想想高可用和负载均衡)。 尽你最大的努力使容器干净和模块化。如果容器相互依赖，则可以使用Docker container network来确保容器间可进行通信。 最小化层数 Minimize the number of layers在老版本的docker中，重要的是减少镜像的层数，以确保它们的性能。 对多行参数排序 Sort multi-line arguments只要有可能，通过按字母数字排序多行参数来简化修改。这有助于避免软件包重复，并使列表更容易更新。 123456RUN apt-get update &amp;&amp; apt-get install -y \ bzr \ cvs \ git \ mercurial \ subversion Leverage build cache 在构建镜像时，Docker安装Dockerfile中的指令逐步执行，并按指定的顺序执行每个镜像。在检查每条指令时，docker会在其缓存中查找可重用的现有镜像，而不是创建新的(重复)镜像。 如果你不想使用缓存，可在docker build命令中使用--no-cache=true选项。如果让Docker使用了缓存，那么了解何时可以 找到/找不到 匹配的图像就很重要了。 Docker遵循的基本规则如下: 从已经在缓存中的父镜像开始，将下一条指令与该基本镜像派生的所有子镜像进行比较，以查看是否使用完全相同的指令构建了其中的一条。否则，缓存失效。 大多数情况下，只需将Dockerfile中的指令与其中一个子镜像进行比较久够了。但是，某些说明需要更多的检查和解释。 对于ADD和COPY指令，将检查镜像文件中的内容，并为每个文件计算校验和。在缓存查找过程中，将检验和与现有镜像中的校验和进行比较，如果文件中由任何内容已更改，如内容和元数据，则缓存将失效。 除了ADD和COPY指令，缓存检查将不会查看容器中的文件已确定缓存。 一旦缓存失效，所有后续的Dockerfile命令将生产新的镜像，并且不会使用缓存。 Dockerfile instruction 请参考: Dockerfile 创建一个基镜像Create a base image 大多数Dockerfile从父镜像开始，如果需要完全控制镜像的内容，则可能需要创建基镜像(base image)。区别: 父镜像是镜像的所基于的镜像 基镜像的Dockerfile中没有FROM行 使用多阶段构建Use multi-stage builds 多阶段构建需要Docker v17.05及以上版本。多阶段构建对于优化Dockerfile来说非常有用，同时让它易读和维护。 构建之前构建镜像最具挑战的事情是保持镜像的大小。Dockerfile中的每条指令都会为镜像添加一层，在移动到下一层前清理不需要的任何构件。为了编写一个高效的Dockerfile，需要尽可能减小图层，并确保每个层都具有上一层需要的构件，而不是其它东西。 使用多阶段构建使用多阶段构建，你可以在Dockerfile中使用多个FROM语句。每条FROM命令可以使用不同的基镜像，并且每个指令都可是构建的新阶段。 1234567891011FROM golang:1.7.3WORKDIR /go/src/github.com/alexellis/href-counter/RUN go get -d -v golang.org/x/net/htmlCOPY app.go .RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .FROM alpine:latestRUN apk --no-cache add ca-certificatesWORKDIR /root/COPY --from=0 /go/src/github.com/alexellis/href-counter/app .CMD [&quot;./app&quot;] COPY --from=0将前面构建的工作复制到这个新阶段。Go SDK和任何中间工作件都被留下，并未保存在最终镜像中 命名你的构建阶段默认情况下，构建阶段没有命名。你可以通过它们的整数来引用它们，第一个指令FROM从0开始。但你可以命名它。 1234567891011FROM golang:1.7.3 as builderWORKDIR /go/src/github.com/alexellis/href-counter/RUN go get -d -v golang.org/x/net/htmlCOPY app.go .RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .FROM alpine:latestRUN apk --no-cache add ca-certificatesWORKDIR /root/COPY --from=builder /go/src/github.com/alexellis/href-counter/app .CMD [&quot;./app&quot;] 停止一个特定的构建阶段构建镜像时，不一定需要构建包含每个阶段的整个Dockerfile。如下的栗子停在名为builder的阶段: 1docker build --target builder -t alexellis2/href-counter:latest . 使用外部镜像用作一个阶段多阶段构架可使用COPY --from指令从单独的镜像中进行复制，可以使用本机镜像、远程Registry的镜像和标记的ID。 1COPY --from=nginx:latest /etc/nginx/nginx.conf /nginx.conf 使用Docker Engine SDKs和API进行开发Develop with Docker Engine SDKs and API 综述Docker提供了一个用于与Docker daemon(称为Docker Engine API)交互的API，以及用于Go和Python的SDK。 SDK允许你款速轻松地构建和扩展Docker APP。如果Go或Python不适合你，你可以直接使用Docker Engine API——它是由HTTP客户端(curl, wget)访问的RESTful API，或者是大多数现代编程语言的一部分HTTP库。 安装SDKsGo SDK Go SDK参考：https://godoc.org/github.com/docker/docker/client 1go get github.com/docker/docker/client Python SDK Python SDK参考: https://docker-py.readthedocs.io/en/stable/ 1pip install docker 快速开始SDK和APIPython: 运行一个容器 123import dockerclient = docker.from_env()print (client.containers.run(&quot;alpine&quot;, [&quot;echo&quot;, &quot;hello&quot;, &quot;world&quot;])) HTTP: 123456789101112$ curl --unix-socket /var/run/docker.sock -H &quot;Content-Type: application/json&quot; \ -d &apos;&#123;&quot;Image&quot;: &quot;alpine&quot;, &quot;Cmd&quot;: [&quot;echo&quot;, &quot;hello world&quot;]&#125;&apos; \ -X POST http:/v1.24/containers/create&#123;&quot;Id&quot;:&quot;1c6594faf5&quot;,&quot;Warnings&quot;:null&#125;$ curl --unix-socket /var/run/docker.sock -X POST http:/v1.24/containers/1c6594faf5/start$ curl --unix-socket /var/run/docker.sock -X POST http:/v1.24/containers/1c6594faf5/wait&#123;&quot;StatusCode&quot;:0&#125;$ curl --unix-socket /var/run/docker.sock &quot;http:/v1.24/containers/1c6594faf5/logs?stdout=1&quot;hello world SDK和API栗子链接: https://docs.docker.com/develop/sdk/examples/ 网络配置Configure networking 综述Docker容器和服务如此强大的原因之一是——你可以将它们连接在一起，或将它们连接到non-docker工作负载。Docker容器和服务甚至不需要知道它们是否部署在Docker上，或它们的对等端是否也是Docker工作负载。都可以使用Docker方式管理它们。 网络驱动Network drivers 使用驱动程序，Docker的网络子系统是可插拔的(pluggable)。 集中驱动程序: brige默认网络驱动。桥接网络通常用于你的应用程序运行在需要通信的独立容器中。 host对于独立容器，删除容器和Docker主机之间的网络隔离，并直接使用主机的网络。 overlayoverlay网络将多个docker daemon连接在一起，并使集群服务能够无相互通信。 macvlanmacvlan网络允许你为容器分配MAC地址，使其成为你网络上的物理设备。docker daemon通过其MAC地址将流量路由到容器。 none对于此容器，禁用所有网络。 network plugins你可在Docker上安装和使用第三方网络插件，从Docker Store获取: https://store.docker.com 网络驱动总结 User-defined bridge networks当你需要多个容器在同一个Docker主机上进行通信时 Host networks当网络堆栈不应与Docker主机隔离时，但希望容器的其它方面被隔离 Overlay networks当你需要运行在不同Docker主机上的容器进行通信时，或多个应用程序使用集群服务进行工作时 Macvlan networks当你从虚拟机迁移或需要你的容器看起来像物理主机时，每个都具有唯一的MAC地址 Third-party network plugins允许你将Docker与专用网络堆栈集成 bridge就网络而言，桥接网络是一种链路层设备，用于转发网段之间的流量。桥接可以是硬件设备，或在主机内核中运行的软件设备。就Docker而言，桥接网络允许连接到统一桥接网络的容器进行通信，同时提供与未连接到桥接网络的容器的隔离。Docker桥接驱动程序自动在主机上安装桥接规则，以便于不同桥接网络上的容器不能直接相互通信。 桥接网络适用于在同一个Docker daemon上运行的容器之间的通信。 当你启动Docker时，除非另有定义，否则将自动创建默认桥接网络，并且新启动的容器将连接到它。你也可以创建用户自定义的桥接网络。 bridge与user-defined bridgesDifferences between user-defined bridges and the default bridge 两者的差别： 用户自定义的桥接在集装箱化的应用程序之间提供了更好的隔离和互操作性 用户自定义的桥接提供了容器之间的自动DNS解析 容器可以在运行中与用户定义的网络进行连接(attach)和分离(detach) 每个用户定义的网络会创建一个可配置的桥接网络 在默认桥接网络上链接的容器共享环境变量 管理user-defined bridgeManage a user-defined bridge 1234567891011docker network create --help#创建一个用户自定义桥接网络#你还可以指定子网，范围，网关...docker network creat $&#123;name&#125;docker network creat my-net#删除docker network rm $&#123;name&#125; 连接到自定义桥接网络Connect a container to a user-defined bridge 当你创建一个新的容器时，你可以指定一个或多个--network标志。 12345678910111213#创建时docker create --name my-nginx \ --network my-net \ --publish 8080:80 \ nginx:latest#运行中的容器docker network connect my-net my-nginx#断开连接docker network disconnect my-net my-nginx 使用IPv6需要修改docker daemon的配置项以支持使用IPv6，在创建自定义网络是指定--ipv6标志。你不能有选择地禁用默认桥接网络上的IPv6支持。 启用容器转发Enable forwarding from Docker containers to the outside world 默认情况下，使用默认桥接网络的连接的容器的流量不会转发到外部世界。启用操作如下： 1234567#配置Linux内核sysctl net.ipv4.conf.all.forwarding=1#修改iptables FORWARD默认策略iptables -P FORWARD ACCEPT#重启后无效，请写入配置文件 默认桥接网络Use the default bridge network 默认桥接网络被视为Docker的遗留细节，不建议用于生产环境。 连接容器到默认桥接网络如果未指定网络，则默认使用默认桥接网络。 配置默认桥接网络指定并配置daemon.json文件 123456789&#123; &quot;bip&quot;: &quot;192.168.1.5/24&quot;, &quot;fixed-cidr&quot;: &quot;192.168.1.5/25&quot;, &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;, &quot;mtu&quot;: 1500, &quot;default-gateway&quot;: &quot;10.20.1.1&quot;, &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;, &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]&#125; 使用IPv6修改配置文件以支持IPv6，则默认桥接网络自动支持IPv6。 overlayoverlay网络驱动在多个docker daemon主机之间创建分布式网络。该网络位于特定主机网络之上，允许容器连接到此并安全地进行通信。 当初始化集群或将docker主机加入现有集群时，将在docker主机上创建两个新网络： 称为ingress的overlay网络处理与集群服务相关的控制和数据流量。当你创建集群服务并且不将其连接到用户自定义的网络时，它默认连接到ingress网络。 称为docker_gwbridge的桥接网络将单独的docker daemon连接到集群的其它docker daemon。 与创建自定义桥接网络类似，你也可以使用docker network create来创建自动以的overlay网络。服务或容器一次可连接到多个网络，但只能通过连接的网络进行通信。 尽管可以将集群服务和独立容器连接到overlay网络，但默认行为和配置是不同的。 所有overlay网络的操作Operations for all overlay networks 创建overlay网络Create an overlay network 先决条件 使用overlay网络的docker daemon的防火墙规则 2377(tcp): 集群通信管理 7946(tcp/udp)： 节点通信 4789(udp)： overlay网络流量 创建overlay网络前，需要初始化docker daemon集群 12345678docker network create -d overlay my-overlay#创建可供集群服务或独立容器与其它docker daemon上的独立容器进行通信docker network create -d overlay --attachable my-attachable-overlay#你可以指定IP地址范围，子网，网关... 加密overlay网络上的流量Encrypt traffic on an overlay network Overlay network encryption is not supported on Windows！ 所有集群服务管理流量默认都是加密的，在GCM模式下使用AES算法。要加密应用程序数据，在创建overlay网络时添加--opt encrypted。这种加密带来了不可忽视的性能问题，所以应该在生产环境使用前对其进行测试。当启用overlay加密时，docker会在节点间创建IPsec tunnel，在这些节点上调度连接到overlay网络的服务的任务。 12#SWARM MODE OVERLAY NETWORKS AND STANDALONE CONTAINERS docker network create --opt encrypted --driver overlay --attachable my-attachable-multi-host-network 自定义默认ingress网络如果自动选择的子网与已存在的网络冲突，或需要自定义其它低级网络设置(如MTU)，这次功能非常有用。 1234567891011121314#显示详细信息docker network inspect ingress#移除现有网络docker network rm ingress#创建新网络 --ingressdocker network create \ --driver overlay \ --ingress \ --subnet=10.11.0.0/16 \ --gateway=10.11.0.2 \ --opt com.docker.network.driver.mtu=1200 \ my-ingress 自定义docker_gwbridgedocker_gwbridge是一个虚拟桥接网络，它将overlay网路连接到单独的docker daemon的物理网络。当初始化集群或将主机加入集群时，docker会自动创建它，但它不是docker设备。啊存在于docker主机的内核之中。如果你需要自定义其设置，则必须在主机加入集群之前或将主机临时从集群中删除之后才执行此操作。 12345678910111213141516171. 停止docker2. 删除已存在的docker_gwbridgeip link set docker_gwbridge doenip link del dev docker_gwbridge3. 启动docker，但不加入或初始化集群4. 创建docker_gwbridgedocker network create \--subnet 10.11.0.0/16 \--opt com.docker.network.bridge.name=docker_gwbridge \--opt com.docker.network.bridge.enable_icc=false \--opt com.docker.network.bridge.enable_ip_masquerade=true \docker_gwbridge5. 集群初始化或加入集群 swarm服务的操作Operations for swarm services 在overlay网络上发布端口Publish ports on an overlay network 连接到同一overlay网络的集群服务可有效地将所有端口暴露给对方。要是端口可在服务外可访问，必须使用-p或--publish标志暴露此端口。 两种方法： 传统的冒号:分隔语法 较新的逗号,分隔语法 Flag value Description -p 8080:80 or -p published=8080,target=80 Map TCP port 80 on the service to port 8080 on the routing mesh -p 8080:80/udp or -p published=8080,target=80,protocol=udp Map UDP port 80 on the service to port 8080 on the routing mesh -p 8080:80/tcp -p 8080:80/udp or -p published=8080,target=80,protocol=tcp -p published=8080,target=80,protocol=udp Map TCP port 80 on the service to TCP port 8080 on the routing mesh, and map UDP port 80 on the service to UDP port 8080 on the routine mesh 绕过swarm的路由网格Bypass the routing mesh for a swarm service 默认情况下，发布端口的集群服务使用路由网格来发布。当你连接到任何swarm节点上已发布的端口时，都会透明地将你重定向到正在运行服务的工作。实际上，docker充当集群服务的负载均衡器(Load-Balancer)。使用路由网格的服务以虚拟IP(vip)模式运行。即使在每个节点上运行服务也使用路由网格。使用路由网格时，不能保证那个docker node处理客户端请求。 要绕过路由网格，可使用DNS Round Robin(DNSRR)模式启动——--endpoint-mode dnsrr。你必须在服务前运行负载均衡器。docker主机上DNS查询服务名称会返回运行该服务的节点的IP地址列表。配置你的负载均衡器使用此列表并平衡各节点间的流量。 分离控制流量和数据流量默认情况下，尽管集群控制流量是加密的，但集群管理和应用程序之间的控制流量运行在同一个网络上。你可以配置docker来使用单独的网络接口来处理来种不同类型的流量。 overlay网络上独立容器的操作Operations for standalone containers on overlay networks 将独立容器连接到overlay网络Attach a standalone container to an overlay network 独立容器连接到ingress网络需添加--attachable标志。这使得运行在不同docker daemon上的独立容器能够进行通信，而无需在各个docker daemon主机上设置路由。 发布端口Publish ports Flag value Desciption -p 8080:80 Map TCP port 80 in the container to port 8080 on the overlay network -p 8080:80/udp Map UDP port 80 in the container to port 8080 on the overlay network -p 8080:80/sctp Map SCTP port 80 in the container to port 8080 on the overlay network -p 8080:80/tcp -p 8080:80/udp Map TCP port 80 in the container to TCP port 8080 on the overlay network, and map UDP port 80 in the container to UDP port 8080 on the overlay network 容器发现Container discovery 对于大多数情况，应该连接到服务名称——它是负载均衡的，并支持服务的所有容器处理。要获取支持该服务的所有任务的列表，请执行DNS查找服务——tasks.&lt;service-name&gt;。 host如果你对容器使用host网络驱动，则该容器的网络堆栈将不与docker主机隔离。例如，如果运行一个绑定在80端口并使用host网络的容器，则该容器的应用程序将在主机IP地址的80端口上可用。 host网络驱动只能运行在Linux主机上。 Macvlan一些应用程序，尤其是需要监视网络流量的应用程序，希望连接到物理网络上。在这种情况下，你可以使用macvlan驱动为容器的虚拟网络接口分配MAC地址，使其看起来像是直接连接到物理网络的物理网络接口。在这种情况下，你需要指定Docker主机上的物理接口用于macvlan，以及macvlan的子网和网关。 创建一个macvaln网络macvlan网络可处于 bridge mode 或 802.1q trunk mode: 在桥接模式下，macvlan流量通过主机上的物理设备 在802.1q主干桥接模式下，流量通过Docker在运行中创建的802.1q子接口。这使你可以更细粒度地控制路由和过滤。 bridge mode 创建bridge macvlan: 123456789101112docker networkcreate --driver macvlan \ --subnet=172.16.86.0/24 \ --gateway=172.16.86.1 \ -o parent=eth0 pub_net#--aux-addresses排除IP地址docker networkcreate --driver macvlan \ --subnet=172.16.86.0/24 \ --gateway=172.16.86.1 \ --aux-address=&quot;my-router=192.168.32.129&quot; \ -o parent=eth0 pub_net 802.1q truk bridge mode 如果你指定了包含点.的接口名——如eth0.50，则Docker将其解释为eth0的子接口，并自动创建子接口。 1234docker network create --driver macvlan \ --subnet=192.168.50.0/24 \ --gateway=192.168.50.1 \ -o parent=eth0.50 macvlan50 使用ipvlan替换macvlan 123456docker network create -d ipvlan \ --subnet=192.168.210.0/24 \ --subnet=192.168.212.0/24 \ --gateway=192.168.210.254 \ --gateway=192.168.212.254 \ -o ipvlan_mode=l2 ipvlan210 IPv6 123456docker network create -d macvlan \ --subnet=192.168.216.0/24 --subnet=192.168.218.0/24 \ --gateway=192.168.216.1 --gateway=192.168.218.1 \ --subnet=2001:db8:abc8::/64 --gateway=2001:db8:abc8::10 \ -o parent=eth0.218 \ -o macvlan_mode=bridge macvlan216 禁用容器网络在启动容器时加上`–network none来禁用容器的网络堆栈，这样在容器内便仅仅创建loopback设备。 12345$ docker run --rm -dit \ --network none \ --name no-net-alpine \ alpine:latest \ ash 网络教程Networking tutorials bridge network default bridge network user-defined bridge network default bridge network 基本docker网络 12345docker network lsNETWORK ID NAME DRIVER SCOPE8d3b84bfe5a0 bridge bridge local3579d63da633 host host localf766b990db47 none null local 以上列出了默认的桥接网络，主机网络(启动直接连接到docker daemon的主机的网络堆栈的容器)，none(启动一个没有网络设备的容器)。 启动一个容器 1docker run -dit --name alpine1 alpine ash 由于启动时没有指定网络，所以默认为桥接网络。 Inspect the bridge network，以查看哪个容器连接到它 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748docker network inspect bridge[ &#123; &quot;Name&quot;: &quot;bridge&quot;, &quot;Id&quot;: &quot;8d3b84bfe5a034c65d043af80976a1e6127011fc1ab312446252f562e221d351&quot;, &quot;Created&quot;: &quot;2018-05-24T18:38:35.538308064+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.17.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;893903129d869f384bd78d63a382f1c9527d6979be0a6cf3c13ea4f45a1554d6&quot;: &#123; &quot;Name&quot;: &quot;hardcore_rosalind&quot;, &quot;EndpointID&quot;: &quot;515d1435470c9f72d3b07680515d9c503457b8eb5bcaaaa915bb53901eac9424&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.17.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;, &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;, &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 连接到容器 123456789101112131415161718docker attach alpine1/ # ip addr show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever506: eth0@if507: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever/ # ping -c 2 www.baidu.comPING www.baidu.com (119.75.216.20): 56 data bytes64 bytes from 119.75.216.20: seq=0 ttl=55 time=46.521 ms64 bytes from 119.75.216.20: seq=1 ttl=55 time=45.189 ms ping其它容器 1234/ # ping -c 2 172.17.0.2PING 172.17.0.2 (172.17.0.2): 56 data bytes64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.125 ms64 bytes from 172.17.0.2: seq=1 ttl=64 time=0.075 ms user-defined bridge networks 创建名为apline-net用户自定义网络当然，你可以手动指定子网，网关这些。 123456789docker network create --driver bridge alpine-netdocket network lsNETWORK ID NAME DRIVER SCOPE810fb1e02000 alpine-net bridge local8d3b84bfe5a0 bridge bridge local3579d63da633 host host localf766b990db47 none null local 查看alpine-net网络详情注意网关和子网发生了变化。 1234567891011121314151617181920212223242526272829303132docker network inspect alpine-net[ &#123; &quot;Name&quot;: &quot;alpine-net&quot;, &quot;Id&quot;: &quot;810fb1e020008c7c6598f3b830ca25896dde638b1190d383ee6a5214d284e77d&quot;, &quot;Created&quot;: &quot;2018-06-14T15:45:19.43941906+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123;&#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 创建两种网络的容器 12345#alpine-netdocker run -dit --name alpine1 --network alpine-net alpine ash#default bridgedocker run -dit --name alpine2 alpine ash 显示两种网络情况 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596docker network inspect bridge[ &#123; &quot;Name&quot;: &quot;bridge&quot;, &quot;Id&quot;: &quot;8d3b84bfe5a034c65d043af80976a1e6127011fc1ab312446252f562e221d351&quot;, &quot;Created&quot;: &quot;2018-05-24T18:38:35.538308064+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.17.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;893903129d869f384bd78d63a382f1c9527d6979be0a6cf3c13ea4f45a1554d6&quot;: &#123; &quot;Name&quot;: &quot;hardcore_rosalind&quot;, &quot;EndpointID&quot;: &quot;515d1435470c9f72d3b07680515d9c503457b8eb5bcaaaa915bb53901eac9424&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.17.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125;, &quot;e7472c3ddda5043bc03868f4bf7ed59562220f05772f02f57ff589d086630562&quot;: &#123; &quot;Name&quot;: &quot;alpine2&quot;, &quot;EndpointID&quot;: &quot;ba565a247e347feb59713c188eb38e184d781da0489ae80e26ecad6d24e165c2&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:03&quot;, &quot;IPv4Address&quot;: &quot;172.17.0.3/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;, &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;, &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;]docker network inspect alpine-net[ &#123; &quot;Name&quot;: &quot;alpine-net&quot;, &quot;Id&quot;: &quot;810fb1e020008c7c6598f3b830ca25896dde638b1190d383ee6a5214d284e77d&quot;, &quot;Created&quot;: &quot;2018-06-14T15:45:19.43941906+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;264ccde8b1d5198551d689f0dd49ffbfb612255e0bf76c9543325d7c2e588acb&quot;: &#123; &quot;Name&quot;: &quot;alpine1&quot;, &quot;EndpointID&quot;: &quot;563c48cc6b936bcd9d3f57e9bb5e162a8cb52a23c8980346f288d42cc9b0a8fc&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 连接到容器 12345678910111213141516171819docker container attach alpine1#网段内通/ # ping -c 2 172.18.0.3PING 172.18.0.1 (172.18.0.3): 56 data bytes64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.097 ms64 bytes from 172.18.0.3: seq=1 ttl=64 time=0.070 ms--- 172.18.0.1 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.070/0.083/0.097 ms#网段外不通/ # ping -c 2 172.17.0.2PING 172.17.0.2 (172.16.0.1): 56 data bytes--- 172.17.0.2 ping statistics ---2 packets transmitted, 0 packets received, 100% packet loss 使容器连接到default bridge这样，此容器便连接到了两个网络中。 1234567docker network connect bridge apline1/ # ping -c 2 172.17.0.2PING 172.17.0.2 (172.17.0.2): 56 data bytes64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.102 ms64 bytes from 172.17.0.2: seq=1 ttl=64 time=0.071 ms host networkhost网络不存在隔离问题。 12345678910111213141516171819202122232425262728293031323334353637383940414243#默认主机上的80端口docker run -rm -dit --network host --name my_nginx nginx#访问http://localhost:80Welcome to nginx!docker network inspect host[ &#123; &quot;Name&quot;: &quot;host&quot;, &quot;Id&quot;: &quot;3579d63da633adcc497417d39b8b1d270cf329a68b9222f6a75fae72086509d6&quot;, &quot;Created&quot;: &quot;2018-04-27T11:31:17.900886126+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;host&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;f02a3b11fce7228ad6ee196771bd9cf0b64966bfc2aa7c27719bc120dbdc7189&quot;: &#123; &quot;Name&quot;: &quot;my_nginx&quot;, &quot;EndpointID&quot;: &quot;4ee67fb4d0a0c1a357b5fdd141f856a70c205fad5c49b1cb6a4f5245df0318a8&quot;, &quot;MacAddress&quot;: &quot;&quot;, &quot;IPv4Address&quot;: &quot;&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123;&#125; &#125;] overlay network default overlay network user-defined overlay network overlay network for standalone containers Communicate between a container and a swarm service default overlay依赖： swarm集群 集群节点 worker-1 worker-2 mananger 123456789docker network lsNETWORK ID NAME DRIVER SCOPE495c570066be bridge bridge local961c6cae9945 docker_gwbridge bridge localff35ceda3643 host host localtrtnl4tqnc3n ingress overlay swarmc8357deec9cb none null local 创建nginx-net的overlay的网络: 123456789docker network create -d overlay nginx-net$ docker service create \ --name my-nginx \ --publish target=80,published=80 \ --replicas=5 \ --network nginx-net \ nginx user-defined overlay123456789docker network create -d overlay my-overlay$ docker service create \ --name my-nginx \ --network my-overlay \ --replicas 1 \ --publish published=8080,target=80 \ nginx:latest overlay network for standalone containers Communicate between a container and a swarm service macvalan network假设主机网络接口为eth0。 bridge此模式下，流量通过eth0流动，docker使用其MAC地址就流量路由到容器。 创建名为my-macvlan-net的macvlan网络 12345$ docker network create -d macvlan \ --subnet=172.16.86.0/24 \ --gateway=172.16.86.1 \ -o parent=eth0 \ my-macvlan-net 查看网络 1234567docker network lsNETWORK ID NAME DRIVER SCOPE810fb1e02000 alpine-net bridge local8d3b84bfe5a0 bridge bridge local3579d63da633 host host local6be80655739d my-macvlan-net macvlan localf766b990db47 none null local 以此网络运行容器 12345$ docker run --rm -itd \ --network my-macvlan-net \ --name my-macvlan-alpine \ alpine:latest \ ash 查看my-macvlan-net 1234567891011121314151617181920212223242526272829303132333435363738394041docker network inspect my-macvlan-net[ &#123; &quot;Name&quot;: &quot;my-macvlan-net&quot;, &quot;Id&quot;: &quot;6be80655739deffe204e087d098f97fc75072d95f9818e129cfd7d5667ed01f3&quot;, &quot;Created&quot;: &quot;2018-06-14T16:52:30.507647877+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;macvlan&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.16.86.0/24&quot;, &quot;Gateway&quot;: &quot;172.16.86.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;8301b669b4b63afb20911b46243f11b70e5a9d0880beaafa922b52bcb8ab0477&quot;: &#123; &quot;Name&quot;: &quot;my-macvlan-alpine&quot;, &quot;EndpointID&quot;: &quot;4f2971ba4bd92c34e2a299d301f739867d2b1b65d35566aef07d7a26b079662c&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:10:56:02&quot;, &quot;IPv4Address&quot;: &quot;172.16.86.2/24&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;parent&quot;: &quot;ens160&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 查看容器网卡和路由 123456789docker exec my-macvlan-alpine ip addr show eth0517: eth0@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UNKNOWN link/ether 02:42:ac:10:56:02 brd ff:ff:ff:ff:ff:ff inet 172.16.86.2/24 brd 172.16.86.255 scope global eth0 valid_lft forever preferred_lft foreverdocker exec my-macvlan-alpine ip routedefault via 172.16.86.1 dev eth0172.16.86.0/24 dev eth0 scope link src 172.16.86.2 802.1q trunked bridge network此模式下，流量流经eth0的子接口(eth0.10)，docker使用其MAC地址将流量路由到容器。 创建名为my-8021q-macvlan-net的macvlan网络 12345docker network create -d macvlan \ --subnet=172.16.87.0/24 \ --gateway=172.16.87.1 \ -o parent=eth0.10 \ my-8021q-macvlan-net 查看此网络 123456789101112docker network lsNETWORK ID NAME DRIVER SCOPE2aeafd44fd67 my-8021q-macvlan-net macvlan local6be80655739d my-macvlan-net macvlan localifconfigeth0.10: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet6 fe80::20c:29ff:feaa:7e75 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:aa:7e:75 txqueuelen 0 (Ethernet) 用此网络启动一个容器 12345docker run --rm -itd \ --network my-8021q-macvlan-net \ --name my-second-macvlan-alpine \ alpine:latest \ ash 查看my-8021q-macvlan-net 1234567891011121314151617181920212223242526272829303132333435363738394041docker network inspect my-8021q-macvlan-net[ &#123; &quot;Name&quot;: &quot;my-8021q-macvlan-net&quot;, &quot;Id&quot;: &quot;2aeafd44fd67e6ee937c82788745b1d45fb291efd61f545537528eafdff94e3d&quot;, &quot;Created&quot;: &quot;2018-06-14T17:06:33.426800076+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;macvlan&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.16.87.0/24&quot;, &quot;Gateway&quot;: &quot;172.16.87.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;90103673d94915c3c7fb572eec8bd97b2aee1c3dab877c598d0a62e6d797b06d&quot;: &#123; &quot;Name&quot;: &quot;my-second-macvlan-alpine&quot;, &quot;EndpointID&quot;: &quot;5c93f2ea1d29150ee57f099d42fc8e04a571efd0d1273a4f6bed755dc34f2e54&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:10:57:02&quot;, &quot;IPv4Address&quot;: &quot;172.16.87.2/24&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;parent&quot;: &quot;ens160.10&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 查看容器网络接口 12345678910docker exec my-second-macvlan-alpine ip addr show eth0519: eth0@if518: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UNKNOWN link/ether 02:42:ac:10:57:02 brd ff:ff:ff:ff:ff:ff inet 172.16.87.2/24 brd 172.16.87.255 scope global eth0 valid_lft forever preferred_lft foreverdocker exec my-second-macvlan-alpine ip routedefault via 172.16.87.1 dev eth0172.16.87.0/24 dev eth0 scope link src 172.16.87.2 配置守护进程和容器启用IPv6启用IPv6前，请确保支持IPv6. 给docker daemon启用IPv6: 12345/etc/docker/daemon.json&#123; &quot;ipv6&quot;: true&#125; iptables所有Docker的iptables规则都被添加到DOKCER chain。不要手动操作此表。如果你需要添加Docker规则，请将其添加到DOCKER-USER chain 栗子： 1iptables -I DOCKER-USER -m iprange -i ext_if ! --src-range 192.168.1.1-192.168.1.3 -j DROP 容器网络容器使用的网络类型(无论是bridge，overlay，macvlan还是自定义网络)，在容器内都是透明的。从容器的角度来看，它有一个带有IP地址，网关，路由表，DNS服务和其它网络细节的网络接口。 publish port默认情况下，创建容器时，它不会将任何端口发布的外部世界。要是端口可用于docker之外的服务，请使用--publish或-p标志。 1234-p 8080:80-p 192.168.1.100:8080:80-p 8080:80/udp-p 8080:80/tcp -p 8080:80/udp ip add and hostname默认情况下，容器会为其连接的每个docker网络分配一个IP地址。IP地址是从分配给网络的地址池中分配的，因此docker daemon有效地充当了每个容器的DHCP服务器。每个网络也有一个默认的子网掩码和网关。同样，一个容器的主机名也有docker daemon指定。 12345678910111213141516#指定运行网络docker run xxx --network#运行的容器连接到其它网络docker network connect#--ip，指定IP地址docker network connect my-bridge --ip 172.18.0.111#--hostname，指定主机名docker run xxx --network xxx --hostname container-01docker network connect my-bridge --hostname container-02 DNS默认情况下，容器会继承docker daemon的DNS设置，包括/etc/hosts和/etc/resolv.conf。你也可以基于每个容器覆盖这些默认设置。 12345678910#DNS server--dns#DNS搜索域--dns-search#表示DNS选项值的键值对--dns-opt--hostname Docker使用代理服务器在启动docker容器的用户主目录下创建此文件： ~/.docker/config.json 12345678910&#123; &quot;proxies&quot;: &#123; &quot;default&quot;: &#123; &quot;httpProxy&quot;: &quot;http://127.0.0.1:3001&quot;, &quot;noProxy&quot;: &quot;*.test.example.com,.example2.com&quot; &#125; &#125;&#125; 应用程序数据Manage application data 存储综述Manage data in Docker 默认情况下，容器内创建的所有文件都被存储容器的可写层上： 当容器不在运行时，数据不是持续存在的。容器外的进程很难从容器中获取数据 容器的可写层与主机紧密耦合，你很难将数据移动到其他地方 向容器的可写入层写入数据，需要存储驱动(storage driver)管理文件系统才存储驱动使用Linux kernel来提供一个union filesystem。与直接写入主机文件系统的数据卷相比，这种额外的抽象会降低性能。 Docker容器有两种选项将文件存储到主机上，这样即使容器停止之后这些文件也会被保留: volumes bind mounts tmpfs mount(Docker on Linux) 选择正确的挂载方式Choose the right type of mount 无论你选用哪种挂载方式，数据在容器内看起来都是相同的。它被公开为容器文件系统中的目录或单个文件。 一个简单的方法——考虑数据在docker主机上的位置，可以看出volumes, bind mounts, temfs之间的差异： Volumesvolumes存储在由docker管理的主机文件系统的一部分中(如Linux上: /var/lib/docker/volumes/)。non-docker进程不应该修改这部分文件系统。Volume是Docker中保存数据的最佳方式。 Bind mountsbind mounts可存储在主机系统上的任何地方。它们可能是最要的系统文件或目录。docker主机或docker容器上的non-docker进程可以随时修改它们。 tmpfs仅存储在主机系统的内存中，不会写入主机系统的文件系统。 volumes的好栗子Good use cases for volumes Volemes是在docker容器和服务中持久化数据的首选方式: 在多个运行容器之间共享数据。如果你没有明确创建它，会在第一次挂载到容器时创建volume。当容器停止或删除时，volume仍然存在。多个容器可以挂载相同的volume，无论是read-write还是read-only。只有在你手动删除volume时它才会被删除。 当docker主机不能保证具有给定的目录或文件结构时，volume帮助你将docker主机的配置与运行时的容器进行分离。 当你想要将容器的数据存储在远程主机而不是本地的时候。 当你需要备份、还原或将数据从一台docker主机迁移到另一台时，volume时更好的选择。 bind mounts的好栗子一般来说，你应该尽量使用volumes。bind mounts适合以下案例： 从主机共享配置文件到容器这就是默认情况下，通过将主机的/etc/resolv.conf挂载到每个容器中，Docker为每个容器提供DNS解析。 在docker主机/容器的开发环境上共享源码或构建工件 当docker主机的文件或目录结构保证与容器所需的bind mounts一致时 tmpfs mounts的好栗子当你不希望数据在主机上或容器内持久存储时，tmpfs mounts最合适。这可能处于安全原因，或在应用于程序需要编写大量非持久性状态数据时保护容器的性能。 使用bind或volumes的提示如果你要使用bind mounts 或 volumes，牢记以下事项： 如果你挂载一个空卷(empty volume)到存在文件或目录的容器中的目录上，则会将这些文件或目录赋值到卷中。同样，如果你启动容器并制定了一个尚不存在的卷，则会为你创建一个空卷。 如果你挂载一个bind mount或non-empty volume到存在文件或目录的容器中的目录上，则这些文件或目录会被挂载所遮蔽。就像在Linux上挂载卷一样。 Volumesvolumes是持久化Docker数据的首选机制，卷由docker完全管理。另外，由于卷不会增加使用它的容器的大小，并且该卷的内容存在于给定容器的周期之外，因此卷通产是比将容器的可写入层中的数据持久化更好的选择。 1234567891011-v/--volume#此选项更详细和简单#如果你需要指定volume driver，请使用此flag--mountdocker service create \ --mount &apos;type=volume,src=&lt;VOLUME-NAME&gt;,dst=&lt;CONTAINER-PATH&gt;,volume-driver=local,volume-opt=type=nfs,volume-opt=device=&lt;nfs-server&gt;:&lt;nfs-path&gt;,&quot;volume-opt=o=addr=&lt;nfs-address&gt;,vers=4,soft,timeo=180,bg,tcp,rw&quot;&apos; --name myservice \ &lt;IMAGE&gt; --volume 由三个由冒号:分割的字段组成。这些字段必须按照正确的顺序排列，每个字段的含义并不明显。第一个字段是卷的名称，并且在给定主机上是唯一的。对于匿名卷，第一个字段被省略。第二个字段是文件或目录在容器中的挂载路径。第三个字段是可选的，是由一个逗号`,分隔的选项列表。 --mount 由多个键值对组成，以逗号,分隔。--mount的语法比--volume更冗长，但键的顺序并不重要，并且标志的值更易于理解。挂载的类型(type)有bind, volume, tmpfs。挂载的来源(source, src)为卷的名称，对于匿名卷该字段可被省略。目的地(destination, dst, target)的值是安装在容器中的文件或目录的路径。只读(readonly)选项将导致bind mount以只读方式挂载到容器中。volume-opt选项可以多次指定，它是由选项名称和值组成的键值对组成。 创建和管理卷1234567891011121314151617181920212223docker volume create my-voldocker volume lsDRIVER VOLUME NAMElocal my-voldocker volume inspect my-vol[ &#123; &quot;CreatedAt&quot;: &quot;2018-06-15T17:19:02+08:00&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: &#123;&#125;, &quot;Mountpoint&quot;: &quot;/opt/docker/volumes/my-vol/_data&quot;, &quot;Name&quot;: &quot;my-vol&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Scope&quot;: &quot;local&quot; &#125;]docker volume rm my-vol 启动用卷的容器Start a container with a volume 包括两种卷： 已存在的卷 未存在的卷会自动创建 123456789101112#--mountdocker run -d \ --name devtest \ --mount source=myvol2,target=/app \ nginx:latest#--volumedocker run -d \ --name devtest \ --volume myvol2:/app \ nginx:latest 1234567891011121314151617181920docker volume lsDRIVER VOLUME NAMElocal my-vollocal myvol2docker inspect devtest#找到挂载 &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;myvol2&quot;, &quot;Source&quot;: &quot;/opt/docker/volumes/myvol2/_data&quot;, &quot;Destination&quot;: &quot;/app&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;z&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; &#125; ] 启动用卷的服务Start a service with volumes docker服务不支持使用--volume标志，请使用--mount标志。 12345docker service create -d \ --replicas=4 \ --name devtest-service \ --mount source=myvol2,target=/app \ nginx:latest 在机器间共享数据Share data among machines 在构建容错应用程序时，可能需要配置同一服务的多个副本能访问相同的文件，而这些副本可能分布于不同的节点上。 卷驱动程序(volume driver)允许你从应用程序逻辑中抽象出底层存储系统。 使用卷驱动Use a volume driver 在创建卷或启动带卷的容器时，你可以指定卷驱动。如vieux/sshfs卷驱动程序。 初始化 1docker plugin install --grant-all-permissions vieux/sshfs 使用卷驱动创建卷 12345#操作node2docker volume create --driver vieux/sshfs \ -o sshcmd=test@node2:/home/test \ -o password=testpassword \ sshvolume 启动一个带用卷驱动程序创建的卷的容器 12345docker run -d \ --name sshfs-container \ --volume-driver vieux/sshfs \ --mount src=sshvolume,target=/app,volume-opt=sshcmd=test@node2:/home/test,volume-opt=password=testpassword \ nginx:latest 备份，还原或迁移数据卷 使用--volumes-from标志创建一个挂载该卷的新容器。 1234567#备份docker run --rm --volumes-from dbstore -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata#从备份还原docker run -v /dbdata --name dbstore2 ubuntu /bin/bashdocker run --rm --volumes-from dbstore2 -v $(pwd):/backup ubuntu bash -c &quot;cd /dbdata &amp;&amp; tar xvf /backup/backup.tar --strip 1&quot; bind mounts与volumes相比，bind mounts功能有限。当你使用bind mounts时，主机上的文件或目录(绝对路径或相对路径)被挂载到容器内。相比之下，当你使用volumes时，会在主机上的Docker存储目录中创建一个新目录，并且Docker会管理该目录的内容。该文件或目录不需要已经存在于Docker主机上。如果它尚未存在，它会根据需求创建。bind mounts非常高效，但是它们依赖于具有特定目录结构的主机文件系统。如果你正在开发新的Docker Application，请考虑使用volumes。你不能使用Docker CLI直接管理bind mounts。 你可以使用--volume或--mount(语法更详细)flag。具体区别参考volumes的介绍。 启动用bind mount的容器Start a container with a bind mount 1234567891011121314#--mountdocker run -d \ -it \ --name devtest \ --mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app \ nginx:latest#--volumedocker run -d \ -it \ --name devtest \ -v &quot;$(pwd)&quot;/target:/app \ nginx:latest 挂载到容器内非空目录如果挂载在容器内非空目录上，则该目录的已有内容将被隐藏。 1234567891011121314#--mountdocker run -d \ -it \ --name broken-container \ --mount type=bind,source=/tmp,target=/usr \ nginx:latest#--volumedocker run -d \ -it \ --name broken-container \ -v /tmp:/usr \ nginx:latest 只读bind mountUse a read-only bind mount 某些时候，容器可能只需要只读权限。 1234567891011121314#--mountdocker run -d \ -it \ --name devtest \ --mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app,readonly \ nginx:latest#--volumedocker run -d \ -it \ --name devtest \ -v &quot;$(pwd)&quot;/target:/app:ro \ nginx:latest bind propagation对于bind mounts和volumes，bind propagation(传播)默认为rprivate。它只能对Linux主机上的bind mounts进行配置。它是一个高级话题，许多用户并不需要配置它。 bind propagation(传播)是指在给定的bind-mounts或named volume中创建的挂载是否可以传播(propagation)到该挂载(mount)的副本(replicas)。考虑一个挂载点/mnt，挂载在/tmp上。传播设置控制/tmp/a上的挂载点是否也可用于/mnt/a。每个传播设置都有一个递归对应点。在递归的情况下，考虑/tmp/a也被挂载到/foo。传播设置控制是否存在/mnt/a和/tmp/a。 传播设置 描述 shared 原始mount的sub-mount会暴露给replica mounts，并且replica mounts的sub-mount同样传播给原始mount。也就是双向 slave 类似于shared，但仅限于单方向。 private 私有挂载 rshared 与shared相同，但传播也扩展到嵌套在任何原始或副本挂载点内的挂载点 rslave 与slave相同，但传播也扩展到嵌套在任何原始或副本挂载点内的挂载点 rprivate 默认值。与private相同，这意味着原始或副本挂载点内的任何位置的挂载点都不会沿任一方向传播 在设置bind propagation之前，主机文件系统需要已经支持bind propagatin: https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt 12345678910111213141516#--mountdocker run -d \ -it \ --name devtest \ --mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app \ --mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app2,readonly,bind-propagation=rslave \ nginx:latest#--volumedocker run -d \ -it \ --name devtest \ -v &quot;$(pwd)&quot;/target:/app \ -v &quot;$(pwd)&quot;/target:/app2:ro,rslave \ nginx:latest selinux label如果你使用selinux，你可以添加z或Z选项来修改挂载到容器内的主机文件或目录的selinux标签。这户影响主机本身的文件或目录，并可能导致Docker范围之外的后果。 zbind mount的内容在多个容器之间共享。 Zbind mount的内容是私有和非共享的。 123456#不支持--mountdocker run -d \ -it \ --name devtest \ -v &quot;$(pwd)&quot;/target:/app:z \ nginx:latest tmpfs mountstmpfs: https://docs.docker.com/storage/tmpfs/#limitations-of-tmpfs-mountstmpfs mounts只支持运行在Linux上的Docker。 Troubleshoottroubleshoot: https://docs.docker.com/storage/troubleshooting_volume_errors/ 将数据存储到容器内Store data within containers 关于存储驱动为了有效地使用存储驱动(storage driver)，了解Docker如何构建和存储镜像，以及容器如何使用镜像是很重要的。你可以使用这些信息作出明智的选择，以便找到应用程序数据持久化的最佳方式，并避免出现性能问题。 存储驱动允许你在容器的可写入层创建数据。在容器停止后，这些文件将不会被保留，并且读写速度都很低。 镜像和层Images and layers Docker镜像由一系列层(layer)构建而成。每个层代表镜像的Dockerfile中的指令，除最后一层外的每个层都是只读的。 考虑如下Dockerfile: 1234FROM ubuntu:15.04COPY . /appRUN make /appCMD python /app/app.py 此Dockerfile包含4个命令，每个命令创建一个层。当你创建一个新容器时，你在底层之上添加了一个新的可写入层——它通常被称为容器层(container layer)。对运行中的容器所做的所有更改(增删改文件)都会写入此可写容器层。 存储驱动处理有关这些层相互交互的详细信息。有几个不同的驱动程序，在不同的情况下具有相应的优点和缺点。 容器和层Container and layers 容器和镜像之间的主要区别是最高的可写入层。当容器删除时，可写入层也被删除。但底层镜像保持不变。 由于每个容器都有自己的可写入容器层，并且所有的更改都存储在此容器中，因此多个容器可以共享相同的基础镜像的访问权限，并拥有自己的数据状态。 Docker使用存储驱动来管理镜像层和可写入容器层的内容。每个存储驱动程序都已不同方式实现，但所有驱动程序都是用可堆叠(stackable)的镜像层和写入时复制(copy-on-write)策略。 容器大小Container size on disk 使用docker ps -s(--size)命令查看正在运行的容器的大小。有两个大小: size每个容器的可写入层的数据量(在磁盘上的) virtual size容器使用的只读镜像的数据量加上容器可写入层大小 写入时复制The copy-on-write (CoW) strategy 写入时复制是一种共享和复制文件以实现最高效率的策略。如果文件或目录存在于镜像的较低层中，而另外的层(包括可写入层)需要对其进行读取访问，则它只是用已有文件。第一次需要修改文件时，该文件将被复制到该层并进行修改。这最大限度减少了每个后续层的I/O和大小。 共享促进了较小的容器Sharing promotes smaller images 当你创建和拉取镜像时，它们通常存储于本机的/var/lib/docker下。每层都存储在主机存储区内的特定目录下/var/lib/docker/&lt;storage-driver&gt;/layers。 123456ls /var/lib/docker/aufs/layers1d6674ff835b10f76e354806e16b950f91a191d3b471236609ab13a930275e245dbb0cbe0148cf447b9464a358c1587be586058d9a4c9ce079320265e2bb94e7bef7199f2ed8e86fa4ada1309cfad3089e0542fec8894690529e4c04a7ca2d73ebf814eccfe98f2704660ca1d844e4348db3b5ccc637eb905d4818fbfb00a06a 复制使容器高效Copying makes containers efficient 容器不会更改的任何文件都不会被复制到此可写入层中。这意味着可写入层尽可能小。 当容器中存在的文件被修改时，存储驱动之赐你个写入时复制操作(CoW)。涉及的具体步骤取决于具体的存储驱动。 aufs, overlay, overlay2存储驱动 遵循的基本顺序: 通过镜像层搜索要更新的文件 对找到的文件的第一个副本执行copy_up操作，将文件复制到容器的可写入层 任何修改应用于此复制的文件，并且该容器不能看到存在于较低层中的文件的只读副本 选择存储驱动Select a storage driver 理想情况下，将很少的数据写入容器的可写入层，并且使用Docker volume写入数据。但某些工作负载要求你能够写入容器的可写入层，这就是存储驱动进来的地方。 存储驱动控制镜像和容器在Docker主机上的存储和管理方式。 考虑三个高层次因素： 如果你的Kernel支持多个存储驱动，在没有指定存储驱动的情况下，Docker会列出要使用拿个存储驱动程序的优先级列表 如果可能，将使用配置最少的存储驱动。如brrfs, zfs 否则，请尝试在最常见的情况下使用具有最佳整体性能和稳定性的存储驱动程序 overlay2是首选(Docker CE的默认选择)，其次是overlay。这些都不需要额外的配置。 devicemapper居次，但需要direc-lvm用于生产环境，因为loopback-lvm的性能很差。 你的选择会受限于Docker版本、操作系统和发行版 某些存储驱动要求你为文件系统使用特定格式 你的选择还取决于工作负载和所需的稳定级别 Linux发行版支持的存储驱动Docker CE Linux distribution Recommended storage drivers Docker CE on Ubuntu aufs, devicemapper, overlay2 (Ubuntu 14.04.4 or later, 16.04 or later), overlay, zfs, vfs Docker CE on Debian aufs, devicemapper, overlay2 (Debian Stretch), overlay, vfs Docker CE on CentOS devicemapper, vfs Docker CE on Fedora devicemapper, overlay2 (Fedora 26 or later, experimental), overlay (experimental), vfs 存储驱动支持的文件系统 Storage driver Supported backing filesystems overlay, overlay2 ext4, xfs aufs ext4, xfs devicemapper direct-lvm btrfs btrfs zfs zfs 查看存储驱动12345docker infoServer Version: 18.03.1-ceStorage Driver: overlay2 AUFS存储驱动AUFS is a union filesystem. aufs存储驱动用于管理Ubuntu上Docker的镜像和层。 我的发行版是Centos，此驱动针对Ubuntu。注意 使用aufs存储驱动配置Docker 判断kernel是否支持aufs 1grep aufs /proc/filesystems 查看Docker存储驱动 1docker info 配置存储驱动 1234vim /etc/docker/daemon.json#或--storage-driver aufs存储驱动如何工作AUFS是一个联合文件系统，这意味着它在单个Linux主机上对多个目录进行分层并将它们呈现为单个目录。这些目录在AUFS术语中称为分支，在Docker术语中称为层。统一过程被称为联合安装。 容器如何使用aufs进行读写读取文件 Btrfs存储驱动Use the BTRFS storage driver Device Mapper存储驱动Use the Device Mapper storage driver Device Mapper是基于kernel的框架，支持Linux上的许多高级卷管理技术。Docker的devicemapper存储驱动利用此框架的精简配置和快照功能进行镜像和容器管理。 对于支持它的系统，devicemapper支持包含在Linux内核中。但是，需要特定配置才能将其用于Docker。devicemapper驱动使用专用于Docker的块设备，并在块级(block level)而不是文件级(file level)运行。这些设备可通过在Docker主机添加物理设备来扩展，并且它们比咋子操作系统级别使用文件系统更好。 依赖 Docker EE Docker CE 更改存储驱动会使已创建的容器在本地系统上都无法访问 配置devicemapper存储驱动 loop-lvm 1234567891011#loop-lvm模式/etc/docker/daemon.json&#123; &quot;storage-driver&quot;: &quot;devicemapper&quot;&#125;#查看docker info direct-lvm生产环境的devicemapper存储驱动必须使用direct-lvm模式。此模式使用块设备创建精简池。这比使用loopback设备更快，更高效地使用系统资源，并且块设备可以根据需求进行扩展。 Option Description Required Default Example dm.directlvm_device The path to the block device to configure for direct-lvm. Yes - dm.directlvm_device=”/dev/xvdf” dm.thinp_percent The percentage of space to use for storage from the passed in block device. No 95 dm.thinp_percent=95 dm.thinp_metapercent The percentage of space to for metadata storage from the passed-in block device. No 1 dm.thinp_metapercent=1 dm.thinp_autoextend_threshold The threshold for when lvm should automatically extend the thin pool as a percentage of the total storage space. No 80 dm.thinp_autoextend_threshold=80 dm.thinp_autoextend_percent The percentage to increase the thin pool by when an autoextend is triggered. No 20 dm.thinp_autoextend_percent=20 dm.directlvm_device_force Whether to format the block device even if a filesystem already exists on it. If set to false and a filesystem is present, an error is logged and the filesystem is left intact. No false dm.directlvm_device_force=true 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#安装依赖RHEL / CentOS: device-mapper-persistent-data, lvm2, and all dependenciesUbuntu / Debian: thin-provisioning-tools, lvm2, and all dependencies#创建物理卷(physical volume)pvcreate /dev/cvdf#创建卷组(volume group)vgcreat docker /dev/xvdf#创建逻辑卷(logical volume)lvcreate --wipesignatures y -n thinpool docker -l 95%VGlvcreate --wipesignatures y -n thinpoolmeta docker -l 1%VG#转换卷为精简池lvconvert -y \--zero n \-c 512K \--thinpool docker/thinpool \--poolmetadata docker/thinpoolmeta#配置lvm配置文件精简池自动扩展/etc/lvm/profile/docker-thinpool.profile#指定thin_pool_autoextend_threshold 和 thin_pool_autoextend_percent的值activation &#123; thin_pool_autoextend_threshold=80 thin_pool_autoextend_percent=20&#125;#应用LVM profilelvchange --metadataprofile docker-thinpool docker/thinpool#启用监控LVlvs -o+seg_monitor#配置devicemapper存储驱动/etc/docker/daemon.json&#123; &quot;storage-driver&quot;: &quot;devicemapper&quot;, &quot;storage-opts&quot;: [ &quot;dm.thinpooldev=/dev/mapper/docker-thinpool&quot;, &quot;dm.use_deferred_removal=true&quot;, &quot;dm.use_deferred_deletion=true&quot; ]&#125;#查看docker info 管理devicemapper1234567#查看LVM logsjournalctl -fu dm-event.servicepvdisplayvgdisplay/vgextendlvdisplay/lvextend/lvchange OverlayFS存储驱动Use the OverlayFS storage driver ZFS存储驱动Use the ZFS storage driver VFS存储驱动Use the VFS storage driver VFS存储驱动不是联合文件系统，相反，每层都是磁盘上的一个目录，它不支持CoW。要创建一个新层，先前的层会进行深层复制(deep copy)。与其它驱动相比，这导致磁盘性能下降和占用更多磁盘空间。但是，它强大，稳定，适用于各种环境。 配置VFS存储驱动 1234567891011121314151617vim /etc/docker/daemon.json&#123; &quot;storage-driver&quot;: &quot;vfs&quot;&#125;#控制大小&#123; &quot;storage-opts&quot;: [&quot;size=256M&quot;]&#125;#查看docker info 在生产环境运行应用程序Run your app in production 配置对象Configure all objects 自定义原数据Apply custom metadata to objects Docker object label标签(label)是一种将原数据(metadata)应用于docker object的机制，包含: image container local daemon volume network node service label key and value标签是一组键值对，以字符串形式存储。可以为对象指定多个标签，但每个键值对必须唯一。如果一个键有多个值，则最新写入的值会覆盖以前的值。 key格式建议label key是可能包含字母，数字，.，-组成的字符串。 第三方工具的作者给每个label key加上前缀域，如com.example.some-label 未经允许，不得使用他人域 com.docker.*, io.docker.*, org.dockerproject.*命名空间保留给Docker内部使用 以小写字母开头和结尾 用.分割命令空间字段 value 指南label value可以包含任何可表示为字符串的数据类型，包括JSON, XML, CSV, YAML…唯一的要求是，首先使用特定于结构类型的机制将该值序列化为字符串。 清理未使用的对象Prune unused Docker objects Docker采取保守的方法来清理未使用的对象(通常称为垃圾回收)，通常它不会删除这些对象，除非你明确要求Docker这样做。对于每个类型的对象，docker提供了prune命令。你也可以使用docker system prune命令一次清理多种类型的对象。 1234567891011121314151617#prune imagedocker image prune docker image prune -a --filter &quot;until=24h&quot;#prune containerdocker container prune#prune volumedocker volume prunedocker volume prune --filter &quot;label!=keep&quot;#prune everythingdocker system prunedocker system prune --volumes 格式化输出Format command and log output 1234567891011121314151617181920212223242526#joindocker inspect --format &apos;&#123;&#123;join .Args &quot; , &quot;&#125;&#125;&apos; container#jsondocker inspect --format &apos;&#123;&#123;json .Mounts&#125;&#125;&apos; container#lowerdocker inspect --format &quot;&#123;&#123;lower .Name&#125;&#125;&quot; container#splitdocker inspect --format &apos;&#123;&#123;split .Image &quot;:&quot;&#125;&#125;&apos;#titledocker inspect --format &quot;&#123;&#123;title .Name&#125;&#125;&quot; container#upperdocker inspect --format &quot;&#123;&#123;upper .Name&#125;&#125;&quot; container#printIndocker inspect --format=&apos;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;println .IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&apos; container 配置daemonConfigure the daemon 配置和运行Docker配置docker daemon 使用json配置文件 使用dockerd --flag 1234567891011121314151617/etc/docker/daemon.json&#123; &quot;debug&quot;: true, &quot;tls&quot;: true, &quot;tlscert&quot;: &quot;/var/docker/server.pem&quot;, &quot;tlskey&quot;: &quot;/var/docker/serverkey.pem&quot;, &quot;hosts&quot;: [&quot;tcp://192.168.59.3:2376&quot;]&#125;#或dockerd --debug \ --tls=true \ --tlscert=/var/docker/server.pem \ --tlskey=/var/docker/serverkey.pem \ --host tcp://192.168.59.3:2376 docker daemon目录docker daemon将所有数据保存在一个目录中。你可以手动修改它。 默认目录: Linux： /var/lib/docker Windows: C:\ProgramData\docker 使用systemd控制dockerControl Docker with systemd 123456cat /usr/lib/systemd/system/docker.service#orcat /etc/systemd/system/docker.servicesystemctl enable/start/stop/status docker 自定义docker daemon选项 123456vim /etc/docker/daemon.json&#123; &quot;data-root&quot;: &quot;/mnt/docker-data&quot;, &quot;storage-driver&quot;: &quot;overlay&quot;&#125; http/https proxyDocker daemon使用HTTP_PROXY，HTTPS_PROXY和NO_PROXY环境变量来配置代理行为。无法使用daemon.json文件来配置环境变量。 123456789101112131415mkdir -p /etc/systemd/system/docker.service.d#/etc/systemd/system/docker.service.d/http-proxy.conf[Service]Environment=&quot;HTTP_PROXY=http://proxy.example.com:80/&quot;#/etc/systemd/system/docker.service.d/https-proxy.conf[Service]Environment=&quot;HTTPS_PROXY=https://proxy.example.com:443/&quot;systemctl daemon-reloadsystemctl restart dockersystemctl show --property=Environment docker 收集Docker指标Collect Docker metrics with Prometheus Promethus: https://prometheus.io/Prometheus是一个开源的系统监控和报警工具包。你可以将Docker配置为Prometheus target。设置Prometheus作为Docker容器运行，并使用Prometheus监控Docker实例。 配置Docker配置docker daemon作为Prometheus target，你需要指定metrics-address。最佳方式是通过daemon.json。 1234&#123; &quot;metrics-addr&quot; : &quot;127.0.0.1:9323&quot;, &quot;experimental&quot; : true&#125; 配置和运行Prometheus 12345678910111213141516171819202122232425262728293031323334353637/tmp/prometheus.yml# my global configglobal: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Attach these labels to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: monitor: &apos;codelab-monitor&apos;# Load rules once and periodically evaluate them according to the global &apos;evaluation_interval&apos;.rule_files: # - &quot;first.rules&quot; # - &quot;second.rules&quot;# A scrape configuration containing exactly one endpoint to scrape:# Here it&apos;s Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: &apos;prometheus&apos; # metrics_path defaults to &apos;/metrics&apos; # scheme defaults to &apos;http&apos;. static_configs: - targets: [&apos;localhost:9090&apos;] - job_name: &apos;docker&apos; # metrics_path defaults to &apos;/metrics&apos; # scheme defaults to &apos;http&apos;. static_configs: - targets: [&apos;localhost:9323&apos;] 1234docker service create --replicas 1 --name my-prometheus \ --mount type=bind,source=/tmp/prometheus.yml,destination=/etc/prometheus/prometheus.yml \ --publish published=9090,target=9090,protocol=tcp \ prom/prometheus 访问: http://localhost:9090/targets/ 配置容器Configure containers 自动启动容器Start containers automatically Docker提供了重启策略，以控制容器在退出或重启时自动启动。重启策略可确保链接的容器以正确的书序启动。Docker建议你使用重启策略，并避免使用进程管理器(如supervisor)来启动容器。重启策略与docker xxx --live-restart标志不同，后者可以让你在Docker upgrage期间保持容器运行。 重启策略使用docker run xxx --restart标志来配置重启策略，--restart的值如下： 标志 描述 no 不要自动重启容器(默认值) on-failure 如果容器由于错误(非零退出码)退出，则重启容器 unless-stopped 除非明确停止或docker本身停止或重启，则重启容器 always 如果停止，则始终重启容器 12#栗子docker run -dit --restart unless-stopped redis 重启策略注意事项 重启策略尽在容器成功启动后才生效——这意味着容器已启动至少10s，并且Docker已开始监视它。这可以防止根本不启动的容器进入重启循环。 如果你手动停止容器(状态码为0)，则在重启Docker daemon或手动启动容器之前，其重启策略将会被忽略。这是另一个防止重启循环的尝试。 重启策略仅适用于容器。集群服务的重启策略与此不同。 在daemon停机期间保持容器活着Keep containers alive during daemon downtime 默认情况下，当Docker daemon终止时，它会关闭正在运行的容器。从Docker Engine 1.12开始，你可配置守护进程，以便在守护进程不可用时容器保持运行。这个功能被称为实时恢复(live restore)。它不支持Windows container。 实时恢复有两种方式来启用live restore，只启用其中一个就好。实时恢复仅适用于独立容器，不适用于集群服务。 修改配置文件 12345/etc/docker/daemon.json&#123; &quot;live-restore&quot;: true&#125; --live-restore标志不推荐 1dockerd xxx --live-restore 在一个容器中运行多个服务Run multiple services in a container 容器的主要运行进程是Dockerfile末尾的ENTRYPOINT或CMD指令。通常建议你通过每个容器运行一项服务来分割关注区域。这些服务可能会分成多个进程(如Nginx的worker processe)。你可以使用用户定义的network和shared volumes来连接多个容器。 容器的主进程负责管理它启动的所有进程。在某些情况下，主进程设计不好，在容器退出时无法正常处理停止子进程。如果你的进程属于这个类别，你可在容器运行时使用--init选型。--init标志将一个微小的inti-process作为主进程插入到容器中，并在容器退出时处理所有进程的停止。以这种方式处理这些进程优于使用完整的初始化进程。 如果你需要在一个容器中运行多个服务，则可通过几种不同方式来完成此操作。 将所有命令封装进一个脚本中，并附带测试和调试信息。以封装脚本作为你的CMD 1234567891011121314vim my_wrapper.sh#!/bin/bashxxxxxxxxvim DockerfileFROM ubuntu:latestCOPY my_first_process my_first_processCOPY my_second_process my_second_processCOPY my_wrapper_script.sh my_wrapper_script.shCMD ./my_wrapper_script.sh 使用如supervisord这样的进程管理器 1234567FROM ubuntu:latestRUN apt-get update &amp;&amp; apt-get install -y supervisorRUN mkdir -p /var/log/supervisorCOPY supervisord.conf /etc/supervisor/conf.d/supervisord.confCOPY my_first_process my_first_processCOPY my_second_process my_second_processCMD [&quot;/usr/bin/supervisord&quot;] 容器运行指标Container runtime metrics docker stats 12345docker stats redis1 redis2CONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/Oredis1 0.07% 796 KB / 64 MB 1.21% 788 B / 648 B 3.568 MB / 512 KBredis2 0.07% 2.746 MB / 64 MB 4.29% 1.266 KB / 648 B 12.4 MB / 0 B Control groups Linux Container依赖于control group，这些组不仅跟踪进程组，还公开有关CPU，mem，block I/O的使用情况和度量标准。你可以访问这些指标并判断容器运行状况。control group通过为文件系统(pseudo-fs)公开，你应该可在/proc/fs/cgroup中找到它。 查看cgroup子系统： 1234567891011121314151617181920212223grep cgroup /proc/mounts#ormount -l | grep cgroup#进程/proc/&lt;pid&gt;/cgroup#/表示进程尚未分配给groupcat /proc/1/cgroup11:devices:/10:cpuset:/9:hugetlb:/8:memory:/7:blkio:/6:net_prio,net_cls:/5:pids:/4:perf_event:/3:cpuacct,cpu:/2:freezer:/1:name=systemd:/ 查找给定容器的cgroup对于每个容器，每个层次结构中创建一个cgroup。 123456789101112131415161718192021222324252627282930313233343536373839/sys/fs/cgroup/memory/docker/&lt;docker-longid&gt;/cd /sys/fs/cgroup/memory/docker/893903129d869f384bd78d63a382f1c9527d6979be0a6cf3c13ea4f45a1554d6cat memory.statcache 36282368rss 196608rss_huge 0mapped_file 1077248swap 0pgpgin 212904pgpgout 205531pgfault 314692pgmajfault 204inactive_anon 131072active_anon 65536inactive_file 18223104active_file 18059264unevictable 0hierarchical_memory_limit 9223372036854771712hierarchical_memsw_limit 9223372036854771712total_cache 36282368total_rss 196608total_rss_huge 0total_mapped_file 1077248total_swap 0total_pgpgin 212904total_pgpgout 205531total_pgfault 314692total_pgmajfault 204total_inactive_anon 131072total_active_anon 65536total_inactive_file 18223104total_active_file 18059264total_unevictable 0#其它信息类似 限制容器的资源Limit a container’s resources 默认情况下，容器没有资源限制，可以使用主机内核调度程序允许给定的资源。Docker提供了一些方法来控制容器可以使用的CPU、memory、block I/O。 许多这些功能需要内核的支持。使用docker info命令检查是否支持。如果内核禁用了某功能，则可能会有如下警告: WARNING: No swap limit support memory你需要了解内存耗尽(out of memory)的风险不要让正在运行的容器消耗太多的主机内存，这很重要。在Linux主机上，如果内核检测到没有足够的内存来执行重要的系统功能，它会抛出一个OOME(out of memory exception)，并开始killing process以释放进程。任何进程都会是killing objects，包括Docker和其它重要应用程序。 docker尝试通过调整docker daemon的OOM优先级来降低这些风险，从而使其比系统上的其它进程更小(less)可能的被killing。容器的OOM优先级不进行调整，这使得单个容器被killing的可能性要大于docker或其它进程。你不应该给docker daemon的--oom-score-adj或container的--oom-kill-disable标志来绕过这些安全措施。 你可以通过以下方式减轻由OOM引起的系统不稳定的风险: 在上线之前，进行测试以了解应用程序的内存需求 确保应用程序仅在拥有足够资源的主机上运行 限制容器可使用的内存量 在主机上配置swap时请注意。swap比内存更慢，性能更低，但可以提供缓冲区以防系统内存耗尽 考虑将容器转换为服务，并使用服务级别约束和节点标签来确保应用程序仅在具有足够内存的主机上运行 限制容器对内存的Limit a container’s access to memory Docker可以强制hard limit，允许容器使用不超过给定数量的用户/系统内存，或soft limit。这允许容器使用尽可能多的内存。 如下这些选项具有这样一些效果，注意内存单位b, k, m, g： 选项 描述 -m/--memory= 容器可使用的最大内存量。如果你设置此选项，则允许的最小值为4m --memory-swap 容器允许使用的swap量。只有在--momery设置时才有意义 --memory-swappiness 默认情况下，容器可使用的主机内核可交换的匿名页面的百分比 --memory-reservation 允许你指定一个小于--memory的soft limit。当docker检测到内存不足时，此会被激活 --kernel-memory 容器可以使用的最大kernel memory。内核内存不能够被swap out，因此内核内存不足的容器可能会阻塞主机资源，这会对主机和其它容器产生副作用 --oom-kill-disable 默认情况下，如果发生内存溢出(OOM)，内核会杀死容器中的进程。使用此选项改变此行为 cpu默认情况下，每个容器对主机CPU周期的访问是无限制的。你可以设置各种约束来限制给定容器访问主机的CPU周期。 CFS schedulerCFS是用于普通Linux进程的Linux kernel CPU调度器，一些运行时标志用于配置容器的CPU资源访问量。 选项 描述 --cpu=&lt;value&gt; 指定容器可以使用的CPU资源，如--cpu=&quot;1.6&quot; --cpu-period=&lt;value&gt; 指定CFS调度器周期，它与--cpu-quota一起使用。默认100ms。Docker1.13以后，使用--cpus替代 --cpu-quota=&lt;value&gt; 在容器上条件CFS配额。在Docker1.13以后，使用--cpus替代 --cpuset-cpus 限制容器可以使用的特定CPU或CORE。如果有多个CPU，请使用逗号,分割。如0,2 --cpu-shares 将此标志设置为大于/小于1024(默认值)的值，以增加或减少容器的重量，并使其能够访问更大或更小比例的主机CPU周期。这仅在CPU周期受到限制时才会执行。 如果你只有1 CPU，如下命令可保证容器每秒最多有50%的CPU——docker run -it --cpus=&quot;.5&quot; xxx realtime scheduler 在Docker1.13及更高版本，对于无法使用CFS的任务，你可以使用realtime scheduler。在你配置docker daemon和container之前，请正确地配置主机内核。 注意： CPU调度和优先级是高级内核功能。大多数用户不需要修改它。错误地设置将导致主机系统不稳定或不可用。 配置主机内核通过运行zcat /proc/config.gz | grep CONFIG_RT_GROUP_SCHED或检查/sys/fs/cgroup/cpu.rt_runtime_us来验证内核是否启用了CONFIG_RT_GROUP_SCHED。有关配置内核实时调度器的指导，请参考相关文档。 配置docker daemon运行docker daemon时使用--cpu-rt-runtime标志设置每个运行时间段的实时任务保留的最大微秒数。可使用systemd的docker.service进行配置。 配置独立容器当使用docker run启动容器时，可以传递多个标志来控制容器CPU的优先级。 选项 描述 --cap-add=sys_nice 授予容器CAP_SYS_NICE功能，允许容器提升进程的nice值，设置实时调度策略，设置CPU关联和其它操作 --cpu-rt-runtime=&lt;value&gt; Docker实时调度器期间，容器可以以实时优先级运行的最大微秒数。需要--cap-add=sys_nice标志 --ulimit rtprio=&lt;value&gt; 容器允许的最大实时优先级，需要--cap-add=sys_nice标志 栗子： 1234docker run --it --cpu-rt-runtime=950000 \ --ulimit rtprio=99 \ --cap-add=sys_nice \ debian:jessie Logging查看容器日志记录的信息和日志格式取决于容器的端点命令。docker logs命令显示正在运行的容器记录的信息。docker service logs命令显示参与服务的所有容器记录的信息。在swarm模式下。 在某些情况下，docker logs可能不会显示有用的信息，除非你采取其它措施。 如果将日志发送到文件、主机、数据库或其它日志驱动程序，则docker logs可能不会显示有用的信息 如果你的镜像运行non-interactive进程(如数据库)，则该应用程序可能会将output发送到日志文件而不是stdout/stderr 配置日志驱动Configure logging drivers docker提供了多种日志记录机制(logging mechanisms)来帮助你从运行的容器和服务中获取信息。这些机制被称为日志驱动(logging driver)。每个docker daemon都有一个默认日志驱动，每个容器也默认使用该驱动。除非你给容器配置了其它日志驱动。除了使用docker附带日志驱动，在Docker v17.05之后，你还可以使用日志驱动插件(logging driver plugin)。 配置默认日志驱动默认的日志驱动是json-flie。可在daemon.json文件里通过log-driver选项匹配置日志驱动。 123456/etc/docker/daemon.json#设置为syslog&#123; &quot;log-driver&quot;: &quot;syslog&quot;&#125; 如果日志驱动存在可配置选项： 1234567891011121314/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;labels&quot;: &quot;production_status&quot;, &quot;env&quot;: &quot;os,customer&quot; &#125;&#125;#查看docker info | grep &apos;Loggin Driver&apos;Logging Driver: json-file 为容器配置日志驱动启动容器时，可使用--log-driver标志为其配置不同于docker daemon的日志驱动。 12345docker run -it --log-driver none alpine ash#查看容器日志驱动docker inspect -f &apos;&#123;&#123;.HostConfig.LogConfig.Type&#125;&#125;&apos; &lt;CONTAINER&gt; 配置从容器到日志驱动的log message的交付模式Docker为从容器到日志驱动的日志消息提供了两种交付(delivery）模式： 直接阻塞(blocking)从容器到驱动的交付(默认) 非阻塞交付(non-blocking)，将日志消息存储在中间每个容器的环形缓冲区中供驱动使用非阻塞消息交付模式可防止应用程序因日志反压而被阻塞。当STDERR或STDOUT流阻塞时，应用程序可能会以意想不到的方式失败。 注意：当缓冲区已满且新消息排入队列时，内存中最早的消息将被丢弃。丢弃消息通常首选阻止应用程序的日志写入过程。 1docker run -it --log-opt mode=non-blocking --log-opt max-buffer-size=4m alpine ping 127.0.0.1 日志驱动使用环境变量或label一些日志驱动将容器的--env/-e或--label标签的值添加到容器的日志中。 1docker run -dit --label production_status=testing -e os=ubuntu alpine sh 支持的日志驱动如下是受支持的日志驱动。 驱动 描述 none No logs are available for the container and docker logs does not return any output. json-file The logs are formatted as JSON. The default logging driver for Docker. syslog Writes logging messages to the syslog facility. The syslog daemon must be running on the host machine. journald Writes log messages to journald. The journald daemon must be running on the host machine. gelf Writes log messages to a Graylog Extended Log Format (GELF) endpoint such as Graylog or Logstash. fluentd Writes log messages to fluentd (forward input). The fluentd daemon must be running on the host machine. splunk Writes log messages to splunk using the HTTP Event Collector. logentries Writes log messages to Rapid7 Logentries. 云日志系统 各类云服务商提供的云日志系统 docker logs命令不适用于除json-file和journald之外的其它日志驱动。 日志驱动插件日志驱动插件允许你扩展和定制docker的日志记录功能，超越了内置的日志驱动的功能。 安装日志驱动插件 123docker plugin install &lt;org/image&gt;docker plugin ls 将插件配置为docker daemon默认日志驱动 12345/etc/docker/daemon.josn#or--loggin-driver 将插件配置为容器日志驱动 1docker run xxx --log-driver 定制日志驱动输出Customize log driver output 日志选项tag指定如何格式化表示容器日志消息。默认情况下，系统使用容器ID的前12个字符。你可以指定tag选项来覆盖此行为： 123docker run --log-driver=fluentd \ --log-opt fluentd-address=myhost.local:24224 \ --log-opt tag="mailer" 在指定tag时，Docker支持的一些特殊模板标记： 1234567891011121314151617181920212223242526&#123;&#123;.ID&#125;&#125;The first 12 characters of the container ID&#123;&#123;.FullID&#125;&#125;The full container ID&#123;&#123;.Name&#125;&#125;The container name&#123;&#123;.ImageID&#125;&#125;The first 12 characters of the container’s image ID&#123;&#123;.ImageFullID&#125;&#125;The container’s full image ID&#123;&#123;.ImageName&#125;&#125;The name of the image used by the container&#123;&#123;.DaemonName&#125;&#125;The name of the docker program (docker) 123--log-opt tag=&quot;&#123;&#123;.ImageName&#125;&#125;/&#123;&#123;.Name&#125;&#125;/&#123;&#123;.ID&#125;&#125;&quot;Aug 7 18:33:19 HOSTNAME hello-world/foobar/5790672ab6a0[9103]: Hello from Docker. 日志驱动介绍如下日志驱动！ LogentriesLogentries日志驱动将容器日志发送到Logentries server。 --log-opt: logentries-token: 指定Logentries log设置的token line-only: 仅发送原始有效载荷 docker daemon: 123dockerd --log-driver=logentries#可在docker.service中设置 docker container: 1docker run --log-driver=logentries ... 在使用此日志驱动之前，你需要在Logentries web界面中创建一个新的日志集，并将该日志集的令牌传递给docker： 1docker run --log-driver=logentries --log-opt logentries-token=abcd1234-12ab-34cd-5678-0123456789ab json file默认情况下，docker捕获所有容器的STDOUT和STDERR，并使用json格式将它们写入文件。每个文件包含仅包含一个容器的信息。 123456789101112131415161718/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;10m&quot; &#125;&#125;#ordocker run \ --log-driver json-file --log-opt max-size=10m \ alpine echo hello world#栗子docker run -it --log-opt max-size=10m --log-opt max-file=3 alpine ash json-file支持的日志选项： 选项 描述 栗子 max-size The maximum size of the log before it is rolled. A positive integer plus a modifier representing the unit of measure (k, m, or g). Defaults to -1 (unlimited). –log-opt max-size=10m max-file The maximum number of log files that can be present. If rolling the logs creates excess files, the oldest file is removed. Only effective when max-size is also set. A positive integer. Defaults to 1. –log-opt max-file=3 labels Applies when starting the Docker daemon. A comma-separated list of logging-related labels this daemon accepts. Used for advanced log tag options. –log-opt labels=production_status,geo env Applies when starting the Docker daemon. A comma-separated list of logging-related environment variables this daemon accepts. Used for advanced log tag options. –log-opt env=os,customer env-regex Similar to and compatible with env. A regular expression to match logging-related environment variables. Used for advanced log tag options. –log-opt env-regex=^(os或customer). Graylog Extended Format(gelf)gelf日志驱动是一种方便的格式，可被Graylog, Logstash, Fluentd等工具所理解。许多工具使用这种格式。 在GELF中，每条日志消息都是带有一下字段的字典： version host timestamp short and long version of the message 自定义的字段 12345678910111213141516171819/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;gelf&quot;, &quot;log-opts&quot;: &#123; &quot;gelf-address&quot;: &quot;udp://1.2.3.4:12201&quot; &#125;&#125;#ordockerd --log-driver gelf –-log-opt gelf-address=udp://1.2.3.4:12201#容器docker run \ --log-driver gelf –-log-opt gelf-address=udp://1.2.3.4:12201 \ alpine echo hello world GELF选项： Option Required Description Example gelf-address required GELF服务器地址(tcp/udp) --log-opt gelf-address=udp://192.168.0.42:12201 gelf-compression-type optional 仅限于UDP。类型有gzip(default),zlib,none --log-opt gelf-compression-type=gzip gelf-compression-level optional -1/0 - 9,-1/0(禁用压缩)，1(BestSpeed)，9(BestCompress) --log-opt gelf-compression-level=2 gelf-tcp-max-reconnect optional 仅TCP，连接断开尝试的最大重连次数，默认3 --log-opt gelf-tcp-max-reconnect=3 gelf-tcp-reconnect-delay optinal 仅TCP，重连等待的秒数，默认1s --log-opt gelf-tcp-reconnect-delay=1 tag optional 默认使用Docker容器ID的前12位 --log-opt tag=mailer labels optional 以逗号分隔的日志相关标签 --log-opt labels=production_status,geo env optional 以逗号分隔的日志相关的环境变量 --log-opt env=os,customer evn-regex optional 匹配日志相关环境变量的正则表达式 --log-opt env-regex=^(os l customer) Syslogsyslog日志驱动将日志路由到系统日志服务器。系统日志必须以特定方式格式化才能生效。从有效的消息中，接收者可以提取以下消息： priority日志级别，debug, info, warning, error… timestamp hostname facility记录消息的子系统 process name pid 12345678910111213141516/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;syslog&quot;, &quot;log-opts&quot;: &#123; &quot;syslog-address&quot;: &quot;udp://1.2.3.4:1111&quot; &#125;&#125;#or#syslog-address支持tcp和udpdocker run \ -–log-driver syslog –-log-opt syslog-address=udp://1.2.3.4:1111 \ alpine echo hello world syslog日志驱动选项： 选项 描述 栗子 syslog-address [tcp l udp l tcp+tls]:host:port, unixgram://path, unix://path --log-opt syslog-address=tcp+tls://192.168.1.3:514, --log-opt syslog-address=unix:///tmp/syslog.sock syslog-facility 子系统 --log-opt syslog-facility=daemon syslog-tls-ca-cert CA --log-opt syslog-tls-ca-cert=/etc/ca-certificates/custom/ca.pem syslog-tls-cert TLS certificate --log-opt syslog-tls-key=/etc/ca-certificates/custom/key.pem syslog-tls-skip-verify 跳过tls验证 --log-opt syslog-tls-skip-verify=true tag 如前 如前 syslog-format 日志格式 --log-opt syslog-format=rfc5424micro lables 如前 如前 env 如前 如前 env-regex 如前 如前 ETWETW日志驱动将容器日志转发为ETW事件。每个ETW时间都包含一条日志及其上下文信息的消息，然后客户端可以创建一个ETW监听器来监听这些事件。 Fluentdfluentd日志驱动将容器日志作为结构化日志数据发送到fluentd收集器。接着，用户便可以使用任意一种Fluentd output plugin将这些日志写入不同的目的地。 fluentd发送一下这些元数据： 字段 描述 container_id 完整的64位容器ID container_ame 启动时的容器名 source stdout or stderr log 容器日志 docker logs命令不可用于此日志驱动。 fluentd-address指定fluentd daemon地址 tag 1234567891011121314/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;fluentd&quot;, &quot;log-opts&quot;: &#123; &quot;fluentd-address&quot;: &quot;fluentdhost:24224&quot; &#125;&#125;#ordocker run --log-driver=fluentd --log-opt fluentd-address=fluentdhost:24224docker run --log-driver=fluentd --log-opt fluentd-address=tcp://fluentdhost:24224docker run --log-driver=fluentd --log-opt fluentd-address=unix:///path/to/fluentd.sock Journaldjournald 日志驱动将容器日志发送给 systemd journal。可以通过journalctl命令，journal API，docker logs来检索日志条目。 journald日志驱动还提供如下元数据： CONTAINER_ID CONTAINER_ID_FULL CONTAINER_NAME CONTAINER_TAG CONTAINER_PARTIAL_MESSAGE 123456789/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;journald&quot;&#125;#ordocker run --log-driver=journald ... 几个选项： tag label env env-regex 123456docker run --log-driver=journald \ --log-opt labels=location \ --log-opt env=TEST \ --env &quot;TEST=false&quot; \ --label location=west \ your/application 使用journalctl命令查看日志： 12journalctl CONTAINER_NAME=webserverjournalctl -o json CONTAINER_NAME=webserver 使用journal API： 123456789#pythonimport systemd.journalreader = systemd.journal.Reader()reader.add_match('CONTAINER_NAME=web')for msg in reader: print '&#123;CONTAINER_ID_FULL&#125;: &#123;MESSAGE&#125;'.format(**msg) Splunksplunk日志驱动将容器日志发送到Splunk Enterprise和Splunk Clound的HTTP Event Collector。 安全]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《网站运维》读书笔记]]></title>
    <url>%2F2018%2F03%2F05%2F%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4%2F</url>
    <content type="text"><![CDATA[参考： 《网站运维：保持数据实时的秘籍》(Web Operations: Keeping the Data on Time) 作为职业的运维互联网变化如此之快，以至于几乎没有时间认真思考一下我们在做什么，以及为什么做。我们奋力拼搏，才避免被淘汰出局，哪里还敢谈论什么引领潮流呢！这种高压、过度刺激的环境使得所有努力都只是为了一份工作，而没有职业的概念了。 职业是指占去你人生大部分时光的事业，并能够逐步晋升。工作只是拿钱干活儿，换句话说，工作就只是工作而已。 为什么运维如此艰难运维对如下领域都有深入的理解：网络、路由、交换、防火墙、负载均衡、高可用性、灾难恢复、TCP与UDP服务、网络运维中心管理、硬件规范、各种Unix、各种Web服务器技术、高速缓存技术、数据库技术、存储基础架构、密码学、算法、趋势分析、容量规划… 运维要求广博，可以说几乎是不可接受的。 运维领域成为一个合格的人选，需要具备三点素质：扎实的计算背景、娴熟的决断力、沉稳的性格。 扎实的计算背景运维要求理解架构中的各个组成部分，在理解计算系统的来龙去脉时，扎实的计算背景对你会有莫大的帮助。具有扎实的基础，对于理解为什么及如何架构解决方案，以及识别出问题所在，是非常重要的。毕竟，计算是架构我们的智能系统的基础。此外，工程师的思维方式和对物理定律的基本理解，也是一个很大的优势。 运维会经常遇到随意的、不切实际的期望。运维，就是理解理论和实践在哪里发生冲突，并发明适当的方法，以便在发生事故时减少损失。 娴熟的决断力虽然优柔寡断在任何领域都不算是一个优点，但在运维中却几乎不能容忍。 沉稳的性格一个沉稳与可控的思维过程是非常关键的，需要保持自己是清醒的一方。 在运维领域，目标很简单，使所有事情在所有时间正常运转。一个简单的定义，但却是一个不可能的期望。或许在这个领域成为一名工程师的更大挑战是组织内的同事对你的不切实际的期望。 从学徒到师傅掌握任何知识领域都需要四项基本要求：知识、工具、经验和纪律。 知识互联网行业的一个独特之处就是几乎所有的东西都是公开的，事实上，有专有权的东西也是极少的，而更为独特的是，几乎所有规范文档都是免费的。 在你走在从从学徒到师傅的路途中，尽可能多滴占有信息是你的职责，这样你的大脑才能将那些细微之处进行排序、过滤、关联，使其成为一幅简明、精确的图画，从而有助于你的决策——不管是长期的架构设计的关键决策，还是临时的排除故障的决策。 工具虽然工具各有优缺点，然而人们使用这些工具都取得了成功。制造和使用工具使我们人类的本性。所有的工具归根结底都只是人类肢体和感觉器官的延长。 师傅不适用工具炼成的。在互联网应用的环境中，你会看得更清楚，五花八门的语言、平台、技术都能够成功地结合在一起，将这些成功地构建为一个架构的，不是Java或PHP，而是设计与实现它的工程师——那些师傅们。 工具上的一个真理是，不管在用的工具是什么，要了解你的工具，这是在这个行业登堂入室的前提。灵巧地运用工具的能力，比工具本身的质量要重要的多。话虽如此，有经验的工程师还是应该手边备一件合适的高质量的工具。 经验从最本质的意义上来说，经验意味着良好的判断力，而良好的判断力却是从很多失败中取得的。 经验与知识是紧密相关的，知识可以认为是他人经验的总结。经验既是一个名词，也是一个动词。获得经验与应用经验，同样容易也同样困难。 一名资深工程师最大的特点是其一致与可靠的良好判断力。很显然，这要在需要做出判断的场合经受锻炼。 对进入运维这个领域而没有什么经验的工程师，我的忠告是：耐心。 纪律通过尽可能正确而高效地做事，从而为解决同样问题，而尽可能地少做工作。 如何应用云计算(Elastic Compute)云服务器(ECS, Elastic Compute Service) 什么地方适合云计算灵活性和一定程度上的自由是云服务器的特点，当然，本地服务器同样有这个特点。 混合计算混合计算=云计算+本地计算 什么地方不适合云计算当然，最先考虑的肯定是经济层面。 服务层与数据库是紧密耦合的，所以使它们之间的网络延迟最小化是很重要的。这意味着它们要么全在云里，要么全在云外。 结语尽管有大量广告吹嘘完整托管在云里，但从运维角度来说，混合应用架构模式或许是最有趣的。有些事情在云里做的不一定好。脚踏两只船，你才会游刃有余。 混合应用还强调一点，就是传统运维中的最佳时间仍然是成功的公司的云应用所必须的。 基础架构与应用程序测量任何规模的运维，采集测量数据就像将服务器连接到网络上一样重要，对于一个规模不断增长的基础架构来说，或许更加重要。 我们不光讨论你要采集并监视的测量数据的种类，还要讨论为了应对各种情况，你能利用这些数据做些什么。 测量数据的采集和带有报警(alerting)功能的监控有明显的区别。 时间刷新率和存留时间的考虑随着采集的数据不断增长，确保这些数据能够一直可查询和移动，这是很明智的。 如Zabbix中——获取数据的时间刷新率和数据保存时间。历史数据保留时长和趋势数据存储时间。比如有的数据要30s获取一次，而有的信息只需要1h获取一次。 测量数据真正出彩的地方： 对于某个特定的资源，每天的峰值是哪些？每周的峰值日是哪些？每年的峰值月是哪些？ 有季节性模式吗？ 如夏时日和节假日会高一些 最大(波峰)值与最小(波谷)值比较起来怎么样？ 在用户分布广泛的情况下，波峰与波谷是否发生变化？ 测量数据采集与存储的地点无论使用什么采集工具，易于采集和便于得出结果都是必须要考虑的。 测量数据的层次不同层次的数据存储在不同的数据库中。 高层业务或功能特定的测量数据有了这些高层数据之后，面向产品的那些人对这些数据也抱有极大的兴趣，你一点都不用感到惊讶。 对于应用层面的数据，最有用的是能够跟踪用户的交互情况。 系统及服务层面的测量数据这些是在运维工程师电脑上以图形方式显示的数据。 测量数据的层次： - 例子 测量项目 应用层 网页或API 故障：类型、延迟、发生率… 服务层 Nginx, MySQL, MongoDB… Nginx: 请求频率、响应时间、忙碌的工作进程… MySQL/MongoDB：导致故障的查询类型、慢查询、连接数… 物理层 CPU、内存、网络、硬盘 内存：繁忙程度 内存：空闲内存 硬盘：可用空间，I/O速率 网络：网络I/O带宽情况 有了这些数据，就能够回答如下问题： 平均的Web请求时间 CPU时间 调用最多的数据库查询 数据库慢查询 文件系统缓存 最大的页面响应 … 为异常检测和报警提供环境在本地采集的测量数据的主要理由，就像油表一样，有了这些数据，就可以明白基础架构正在发生什么，以及正在驶向何方。知道哪里的资源在增长或缩减，能够进行预测。使用预测对基础架构的容量需求进行预报，称为容量规划。观察网站运行是否有异常时，测量数据就派上用场了。 发生异常是，测量数据回味报警提供相关信息。报警的信息要尽量简明，告知检测到了什么，以及何时检测到。而测量数据会告诉你报警都发生了什么。 日志记录也是测量数据应用程序的日志文件也提供了测量数据和使用情况的信息。这些信息用于追踪过去发生的事件。 将变化管理和事件的时间线建立关联更新生产系统会带来风险。记录更新发生的时间，从而保留更新的踪迹，这在发生问题需要进行追踪时是非常有价值的。 给测量数据加入报警机制Zabbix、Nagios等就是一个测量数据采集系统配合使用的监控/报警工具。 使用测量数据建立加载-反馈机制采集时序数据的另一个好处，就是能够通过编程使你的应用生成测量数据，从而可以建立安全、精密的反馈循环。 结语测量数据的采集、存储、显示，可以认为是web基础架构的关键部分。不论是及时排查错误，预测容量、规划产品的发布，还是建立应用的反馈机制，如果没有正确的测量数据为你提供一个基础架构运行的全景图的话，你会损失惨重。 设计数据如何经过系统时，要考虑安全问题，而且数据要易于导出到其它应用。一旦运维部门采集了测量数据，你会发现，追踪数据是一件多么有趣的事情，同时也能使工作更加轻松。 连续部署软件应该以小批量的方式进行设计、编写和部署。 批量大小是产品在开发过程的各个阶段转移的单位。对于软件而言，最容易看到的批量是代码。每次工程师检入代码，都是在提交一定量的工作。有很多技术用来控制这些批量，从连续部署所需的最小批量到更为传统的分支开发，在分支开发中，多个开发者工作数周或数月产生的所有代码将被成批处理，并集中到一起。 结果证明，以远小于传统做法的建议的批量工作，有极大的好处。 小批量意味着更快的反馈工作转移到下一阶段越快，则也就能越快地发现下一个阶段是如何接纳你的工作的。 小批量意味着问题即刻被本地化问题发现得越快，则解决的也越快。 每次部署，都只有少量代码有变化，所以导致回归或料想不到的性能问题的任何变化，都能够快速识别出来，并进行改正。当然，由于需要改正或回滚的变化数量不仅是确定的，也是很小的，所以解决问题的平均时间也就很低了。 小批量能够减少风险 小批量可以降低总开销大多数机构都会降低自己的批量大小，以降低总的开销。大批量导致的瓶颈经常是隐含的，是这些隐含的瓶颈显现出来，是需要开销的，甚至要投入更多的工作才能修正这些瓶颈。 连续部署的目标，是在减小批量的同时，帮助开发团队清除开发过程中的垃圾，加快工作步伐。这样就能使各个团队处于持续的流动状态，这种状态使得团队的创新、试验变得非常容易，从而形成可持续发展的良性循环。 质量卫士的挽歌产生开发过程中的垃圾的一个很大原因是重复检查。 连续集成，有助于加快缺陷反馈流程；故事卡和看板，用于降低批量大小；日站，有助于加快步伐；连续部署也是这样的技术，有能力是开发团队更有活力。 为什么连续部署能行连续部署区分了发布的两种不同的定义： 一个是工程师使用的，指的是将代码完全集成到生产环境中的过程； 另一个是市场部门使用的，指的是客户看到的东西 使用连续部署，代码一旦写完，就在去往生产环境的路上了。连续部署也起着速度调节器的作用。 这种速度调节，对于习惯于通过个体效率来度量其进步的团队来说，是一种技巧性的调整。在这种团队中，每个工程师的头等大事就是保持忙碌。不幸的是，这种观点忽略了团队的整体生产能力。对于有些情形，大家坐下来讨论，找出协调方法，从而不需要做重复工作，这时候才是有效率的。 让我们开始吧步骤1：连续集成服务器这是连续部署的脊梁。我们需要一个中心服务器，运行所有的自动化测试，并监控每一次的提交。 步骤2：源代码控制提交检查下一个需要的基础框架是源代码控制服务器，并带有能进行提交检查的甲苯。如CVS、SVN、Git等。 作为一个团队，我们的目标是在能够可靠地生产高质量代码的前提下，尽可能快地工作，但不要过快。 步骤3：简单的部署脚本建立一个关键的部署脚本，用于逐台机器进行增量备份，与此同时，监控集群和业务的运行情况。这样一旦出现异常，就可以快速恢复。 步骤4：实时报警无论部署过程多么完美，缺陷仍然会通过部署而进入生产环境。需要一个监控平台，以便事情一旦偏离正常，能够进行提醒，并找到人来调试。 步骤5：根本原因分析无论问题多小，都要做些投资，而且各个级别都要做。小的改进，经过经年累月，非常像复利。 连续部署用于关键应用连续部署要求的第一个心态转移是：如果一个更新假设是无副作用的，马上发布。不要再等着与其它相关的更新捆绑在一起，否则，一旦发生副作用，就很难确定到底是哪个更新产生的。 第二个是心态转移是把市场发布的概念和工程发布的概念区分开。 更快更好的反馈 更多的自动化 对真实环境测量数据的监控 更好地处理间歇性错误 更小的批量 作为代码的基础架构只需要源代码库、应用程序数据备份、硬件裸机就能够把整个业务重建起来。 理想情况下，重组业务的最大制约是还原应用程序数据所需要的时间，应用程序数据是真正的业务价值所在。 面向服务体系结构将系统的每个组件都分解为可通过网络访问的服务，这些服务集成在一起就构成了一个功能性应用程序。 通过将每个基本组件都呈现为服务、应用开发者可自由组装的新的应用，结果就是重用更为容易、封装更为清洁、错误排查更为简单。 应该是模块化的 做一件事，并且做好在SOA中，每个服务都很小——只做一件事，并允许其它服务调用。每个服务都很简单，但应用程序员要做很多集成工作。每个服务都专注于自己的狭小领域，则管理、开发、测试都会很容易。基础架构服务也是一样的，缩小每个服务的操作范围，就可以降低复杂性，从而他人也就易于理解其行为。 应该是协作的 让我们团结起来在构建通过网络API呈现的基本服务时，要鼓励别人和你协作，而不是重复实现相同的功能。每个服务都要设计成与其它服务协作的，尽量少假设服务的使用方式。服务的协作本性决定了用的人越多，则服务本身就越有用。对于基础架构服务而言，这种本性是至关重要的——随着基础架构的每个部分都成为可集成的服务，服务之间相互协作的方式会呈指数增长。 应该是可组合的 应该一切准备就绪理想情况下，每个服务都应该通过易于访问的网络API呈现自己的配置和功能，实际情况是：大部分都没有。 配置管理配置管理是一种管理活动，从技术和管理两个方面作用于产品和生命周期、配置项，以及相关的产品配置信息。 配置管理是指对所有那些事情的跟踪，那些事情是把一个系统从裸机(baremetal)转变成做自己的事时必须要做的。系统管理员手工配置系统，并将笔记贴到wiki上时，他就是在实践着最基本的配置管理。软件开发者写了一个脚本来自动部署自己的应用程序，她就是在实践着自动化的配置管理。 配置管理是策略驱动的 把问题和解决方案的最终结果记入文档(设立策略)； 写出在策略中要执行的代码(执行策略)； 确认最终结果是正确的(审计策略)； 重复这个过程，确保以后呢能够可靠的执行(测试策略) 系统自动化就是用代码实现配置管理策略自动化几乎总是使用高级语言，自动化方式展现了三个原则： 应该是灵活的 无论需要什么，都应该有能力做 应该是可扩展的 遇到新情况时，要易于扩展 应该是可重复的 不管重复做了多少次，结果都一样 系统管理中的配置管理配置管理工具应该有如下思想： 描述的 说明做什么，而不是怎么做 抽象的 让工具为你操心细节 幂等的 旨在需要时才采取行动 聚合的 只关心自己，并信赖其他服务亦然 系统集成系统集成是指将各个组件整合为一个功能正常的、完全自动化的系统。系统集成侧重于广度，能否成功则依赖于对两个方面的理解： 系统中的每个组件是如何工作的 这些组件是如何相关的 应该遵循这两个步骤将基础架构构建为代码，这两个恰好也是系统集成阶段使用的步骤。系统集成就是将所有的东西整合在一起。 将基础架构分解为可重用的，可通过网络访问的服务 良好基础架构的十大核心原则： 应该是模块化的 启动过程将只处理这样的任务：使资源成为网络可访问 应该是协作的 启动服务应该能够将启动后的工作传给其他服务 应该是可组合的 能够从不同的服务中调用启动服务 应该是灵活的 足够灵活以应付不同类型的物理系统 应该是可扩展的 易于扩展，义启动新的资源类型 应该是可重复的 每次启动，都要生产相同的系统 应该是描述的 应该描述需要的系统类型，而不是如何安装和构建这些系统的细节 应该是抽象的 应该隐藏底层机制 应该是幂等的 应该是聚合的 应该尽快将每个系统都启动起来，并为随后的操作系统做好准备，而不用担心其他系统的状态 将服务集成在一起 现在，你已经创建了一个如何引导和配置系统的策略，你知道接收标准是什么、能够列出实现步骤、能够对策略进行测试。这种做系统集成的方式类似于做一个多层蛋糕：每一层都建立在前一层的美味基础上，使得整个蛋糕更为诱人。 监控我以前假定服务器资源是无限的，实际情况却是服务器正在为获得必要的内存而努力挣扎着。操作系统开始进行交换，CPU开始过载，从而响应时间开始变糟。 技术人员的观点和最终用户/业务的观点并不一致。 监控并不是设置一个系统，它是用来支持业务运转的，是用来保证系统中各个部分都在各司其职地工作着。能够正常工作也可以表述为保持网站的可用性。 可用性(A)可表述为：A = Uptime/(Uptime + Downtime) 网站可用性受如下4个参数的影响： MTTD(平均故障诊断时间) 诊断该问题所花费的平均时间 MTTR(平均修复时间) 用于修复问题所花费的平均时间 MTTF(平均无故障时间) 正常运行的平均时间 MTBF(平均故障间隔时间) 两次故障间隔的平均时间 A = MTTF/MTBF = MTTF/(MTTF+MTTD+MTTR) 并不是说你的业务需要接近90%或更高的可用性，业务要求的可能性只是一种期望值，如果宕机发生在周末，即使发生在工作日，只要还能工作，用户也不会说什么。你的目标是应该通过降低MTTD和MTTR，以及增加MTTF来增加可用性。 理解你在监控什么技术组件的依赖项： 组件 依赖关系 应用程序 应用程序服务器、Web服务器、邮件服务器、缓存服务器、队列服务器 Mail服务器 Mail服务进程、网络、主机、存储 DNS服务器 DNS服务进程、网络、主机、存储 应用程序服务 应用程序服务进程、网络、主机、存储 Web服务器 Web服务器进程、网络、主机、存储 数据库 数据库服务进程、网络、主机、存储 主机 设备、OS设备进程 网络 设备、网络设备进程 存储 设备、磁盘、RAID控制器、接口 通用设备 磁盘、内存、CPU、接口、房屋 房屋 UPS、电源、温度 依赖项常常不受你控制，相反，它是由公司内不同的组管理的。从你自己的筒子里走出来，到其他部门获取相关信息，并不是很容易。正是因为你依赖于他们，所以更好地理解他们的就很关键了。这样你就不用在讯早问题的原因上浪费时间，在用户访问服务所依赖的那些组件上也就不会存在盲点。 不同部门之间的边界： 企业部门 依赖项 支援部门 能影响浏览器、桌面设置、防病毒/间谍软件 开发组 专注于应用程序更新 中间件组 经常运行数据库、Web服务器、应用程序服务器、邮件服务器、缓存服务器队列服务器 系统组 操作系统、DNS、DHCP、虚拟化、集群 网络组 交换机、路由器、VPN、代理服务器 存储组 SAN、NAS、备份、恢复 数据中心组 电缆、电力、UPS 安全小组 防火墙、安全策略 这样划分责任，在不清楚问题的真正原因时，会显著增加修复问题的时间。大量精力会花在努力证明自己部门的清白上面，从而延长了解决问题的时间。这份额外时间称为平均清白时间(Mean Time to Innocence)。为了减少这种相互推诿的时间，良好的合作与协调很重要。持续的知识共享有助于增加这种共同应对问题的责任感。 组织边界到防火墙哪里就停止了，但Internet服务比内部控制的服务有更多的依赖项，这些外部依赖项有ISP、广告商、RSS信息、Internet邮件、DNS服务器、ISP连接等，内部依赖项和外部依赖项的主要区别在于，对于外部依赖项，你不知道这些服务是如何提供的。即使如此，也不能在监控这些服务上止步不前，毕竟它们仍然是你的服务的依赖项。 在无冗余的系统中，一个组件失效，整个服务就会失效。当一个组件的失效会影响整个服务时，这种失效就称为单点故障。这种影响既指服务完全中断，也指对服务质量的影响。为了避免单点故障，通常是在架构中的多个位置增加冗余，这些冗余是你的环境的安全卫士，而不是对问题的某种补偿方式。通常，增加冗余会增加复杂性，所以不要掉进过度设计的陷阱。 一些冗余机制： 服务/组件 冗余机制 应用程序 负载均衡器、状态复制 Mail服务器 一个域名多条MX记录 DNS服务器 一个域名多条NS记录 应用程序服务器 会话复制、多实例安装 Web服务器 Web服务器服务进程 数据库 集群服务、水平区分 主机 虚拟化、集群 网络 多网关、BGP、VRRP、多ISP 存储 RAID、镜像、多重路径技术 通用设备 多网卡、CPU、内存 数据中心 BGP任播、GSLB 不要忘了检查监控服务的依赖项，如果监控都挂了，那还监控什么呢。 各种检查： 检查种类 例子 可用性 能访问80端口吗？HTTP进程在运行吗？数据库能访问吗？ 功能/既时 应用程序在请求数据库，OS在进行DNS查询，控制器在进行磁盘写入，负载均衡器在请求Web服务器 功能/模拟 模拟HTTP请求、DNS请求、发送邮件 质量/利用 CPU、内存、磁盘等硬件信息使用情况，可以知道机器是否有足够的处理能力 质量/效率 Squid缓存命中率 质量/吞吐 订阅数、登录数、请求数、进/出请求数，用户数，数据库连接数，活动连接数，实例数 环境 配置监控，安全监控，备份监控 可信性 邮件域的垃圾邮件防范级别，SSL证书 不同层级的检查： 层级 例子 业务 内部网管理站点 交易 登录、增加文档、分享链接、注销 服务 Mail、DNS、Web服务器、数据库、路由、防火墙 机器 服务器、CPU、内存、交换机 理解正常行为即使你了解所有依赖项，但设计一个好的监控解决方案仍是要花时间的。需要根据业务实际需求和变化对监控实施改变。 一些监控中的主要问题：如果多次报警基于同一个原因，应该只发送一次报警；夜间，备份可能会在生产网络上产生很高的负载，这样由于响应时间的变慢而导致多个ping失败和其它可能的误报，从而产生起起伏伏的报警；如果我们想要随时待命的支持人员，必须尽可能降低报警和误报的次数。 加入的检查越多，消耗的生产系统的资源也就越多，这些资源可以是传送数据的带宽、计算结果的CPU…你需要找到正确的平衡：监控太多只会浪费资源，从而降低对整个状况的了解；监控不足将导致不能及时报警。越靠近业务层的检查越有机会检测出问题，而越底层的检查越能够对发生的问题进行定位。 监控被认为是运维环境的一部分，通常是由系统或网络管理员来管理的。开始时是一个很小的系统，在后台运行。随着监控环境的扩大，需要执行更多的配置和定制。虽然运维人员常常是第一个对要部署的新软件进行仔细检查的人，他们的标准却往往并不应用到自己的监控系统上。监控系统是你的关键应用之一，请一视同仁。 监控的最佳实践： 实践 说明 版本 对你的检查进行版本华，并把他们放入版本控制库中 不同环境 使用不同环境开发、测试新的检查 测试 将检查作为通常代码对待，在代码功能中加入测试 可使用性 创建一个所有组件及其关系的可视化总览图，指出失效和组件的关系对工程师很有帮助，只需要看一下仪表板就能明白问题出在哪里 信息架构 使用不同的数据表示法，将数据组织为层次结构以便于导航，同时还要避免信息过载 代码重用 如果能够重用所监控的应用程序中的业务逻辑，就不要自己写 无硬编码 避免将参数编码在脚本中，使用配置文件，这也易于脚本在不同环境中的迁移 部署 要易于部署和分发新的检查 备份/还原 备份监控数据，并了解在什么情况下需要还原 监控 监控你的监控系统 冗余 在监控上，使用高可用性的功能做维护工作 应用的安全规则 监控账号与其它事务账号分开 是用最小特权级 不要将密码保存为明文 限制对系统的访问，不要将其用于其它的测试 将监控系统用防火墙或代理系统保护起来，避免来自易受攻击的主机的访问 所有信息一旦采集和存储，接下来做的就是分析检查结果。服务或系统的状态有可用(Up)和不可用(Down)，某些监控系统还增加了两个状态，一个用于系统不可达(Unreachable)，一个用于系统/服务尚未检查(Pending)。 有的时候，在位新服务建立环境时，预先定义的阈值很困难——实际使用可能会超过预期，或者相反。所以，对阈值进行不断的调优就有意义了。先根据理论上的假设定义一组阈值，然后在测试环境中模拟预期的行为，并翻译为技术化的组件使用情况。因为系统及使用情况的复杂性，对系统、应用程序、用户行为建立精确的模型是很困难的。所以，对阈值只能持续不断地研究与改进。趋势分析确实有助于定义阈值，大部分监控软件都可以让你对监控的值做趋势分析，而不产生报警，根据历史数据得出阈值之后，再启动报警设置。 管理报警并不仅仅是状态变化时发出报警信息。所有报警如果一直打开着的话，工程师将无法安心做系统支持，因为报警信息太多了，可能要被报警轰炸。同样，如果有太多假设报警，也会导致同样的问题，这可以看成是你的监控系统存在技术缺陷。警报应该产生行动。如果一条警报可以忽略或不需要人工干预，这条报警就是一种浪费。然而，消除噪音却是真正的挑战。警报太多会导致狼来了效应，由于警报过载而忽略了正在重要的警报。 为了使网站可以忍受而限制报警是好的，但假如与业务需求不一致的话，就不行了。反之也是对的，如果业务不需要的话，为了显示网站运行正常而发送很多报警信息，也是毫无意义的。使监控保持正确的平衡，这很重要。 有备而学一个人不可能在每个方面都是专家，有一个清晰定义的升级路径，从而把问题提交给更为专业的人员去处理是明智的。对紧急报警进行跟踪和趋势分析，有助于提出架构和过程的改进建议。 故障时间本身并不仅仅有功能失效引起的，也可能是由于维护活动产生的。维护活动产生的故障时间被描述为维护窗口。在这种情况下，业务部门是认可默写故障时间的。为了避免不必要的报警，监控系统可能会在这段时间关闭报警。这会导致丢失一些与此次维护无关的系统/服务故障。所以，应该只关掉与维护相关的报警，而不是整个报警系统。然后，一旦服务运行稳定了，就要打开报警。 结语监控并不是要保持服务器运行正常，也要保持业务运行正常。理解了技术组件和业务行为，你就会有相当的把握减少和修复问题上的时间。错误总是会发生的，但要为此做好准备。万一系统失效，一定要将反馈信息发送给每一个希望听到的人，并对事情做出改进，避免再发生新的错误。愿监控的力量与你同在。 复杂系统是如何失败的所有复杂系统失败时，都有共同点。Web运维就是这样一个领域。 复杂系统是如何失效的 复杂系统本质上都是灾难系统 复杂系统都被重重地然而也是成功地防护着 灾难要求多点失效——单点失效是不够的 复杂系统包含潜藏在其中的缺陷的变化混合物 复杂系统以降级模式运行 灾难随时会发生 事后归结为”根本原因“是错误的 幕后认识对人类行为的时候评估存在偏见 人类操作员有双重角色：作为生产者，以及作为失效防护者 所有操作者的行为都是赌博 最为困难的行动解决了所有的模糊性 人类操作者是复杂系统的可调整因素 复杂系统中人类专门处理知识处于不断变化中 变化会引入新的失效 “原因”观点限制了对未来事件的有效防护 安全是系统的特性，而不是系统的组件 持续创造安全的是人 无事故的运维需要经历事故的历练 针对Web运维而言： 了解系统失效很困难 了解哪部分失效很困难 有意义的响应会被延迟 沟通会产生紧张，而脾气会冒火 维护会成为新的失效的主要源头 从备份中恢复本身就很困难，而且还有潜在的危险 创建测试过程，一线人员用来验证系统状态 对运维进行例行的每日管理 控制维护 定期对性能进行评估 要成为(独一无二)的用户 社区管理与Web运维运行一个大型且广为人知的网站，意味着会有大批人依赖于网站快速而稳定的服务。这些人会形成一个社区，以各种有趣新颖的方式进行交流，并彼此关照。 社区起着一个交流、沟通、反馈的渠道作用。 处理非预期的访问量激增有些时候，因为某种原因，Web的访问量会急剧增加(是正常用户访问而不是遭受攻击)，我们的服务器就会遭受严重的考验。 一切是如何开始的开能由于某个原因，导致Web流量激增，而我们服务器却无法应付这么高的并发和流量，所以导致Web瘫痪。 警报连连监控软件(如nagios, zabbix)警报连连。Web请求太多导致响应很慢或奔溃。 扑灭烈火查找是哪些环节导致Web响应很慢或奔溃，对之做相应的优化。 未雨绸缪当我们经历了非预期的流量激增，并处理优化之后，下一步就需要对整个基础架构进行加固，或转向新的架构。 救命稻草CDN解决带宽问题要靠内容分发网络(CDN)——在多个地点存储文件，为客户提供最近最快的响应。大部分静态资源适合移动到CDN上，以减轻原始服务器的负担。 但CDN也有一些不足。对于移动到CDN上的数据，你就失去了控制。对于短时间的静态内容，CDN的效果并不好。 代理服务器代理服务器处于我们系统的最前沿，尽可能让代理服务器转发请求，而不使用任何其它资源。 围剿踩踏如何避免缓存踩踏？ 一个是对数据库进行优化 一个是搭建数据库集群 将代码基流水化 怎么知道它能否工作确保系统能够处理负载的唯一途径是在流量汹涌而来时，对其进行现场测试。 真实测试必须要在真实的生产环境中查看其负载效果，才能确保其能正常工作。 教训总要为未来几年做一个规划——问问你自己：“当前的架构方案能够用于未来几年吗？” 要测试生产环境，经过适当的测试规划，很多问题是可以避免的。 当一个架构方案已经明显不能工作的时候，必须要有重新考虑整个方案的勇气。重新思考代码、硬件、网络、数据库模式，为可见的未来创建一个伸缩性更好的系统。 改进针对遭受的问题，之后对系统的改进。 开发者与运维者的协调与合作很多网站都将其开发和运维分为两个独立的团队，开发负责开发新功能和对现有功能进行改进，运维负责网站的正常运行。两个团队有不同的目标，工作方式的要求也是迥然有别。 这种设置很常见，但也是保证网站稳定性或及时推出新功能的最糟糕的设置。 这在种情形下，开发人员没有动力将网站做得更易于运维支持，开发团队交付的代码通常是一个黑盒子，一旦发生意外，运维团队没有办法及时去修复问题。这种结构也抑制了新的功能的开发、构建和部署网站的新版本，不仅耗时，成本高，还涉及很多不同团队之间的协调。对运维来说，部署是存在风险的，而且也是造成很多宕机事故的原因。 传统的运维和开发，两者之间存在着很多对彼此很有用的信息。对很多网站来说，性能瓶颈都出在应用程序代码上：开发团队最适合修正这些问题，但运维团队有测量数据，要想找出问题出在哪，是需要这些数据的。关于什么地方可能会出问题，以及如何修复，开发团队有很多很好的想法，但这些却很少会记录在文档里面。 所以，重新评估运维跟开发之间的关系！ 部署以合适的方式进行移交，则不同团队之间就能更好地共同工作，而改变过程这是困难的，需要协助以及每个人的认可。 一项服务之所以受人欢迎，频繁部署也是重要原因之一。小批量代码更新。 用户报告问题后，极短时间内就得到修复，这一做法会彻底征服用户。有了这种响应凡是，则将来有了问题，用户也会很乐意报告给你，这样产品就会越做越好，特别是你能够一直这样快速反应的话。对关键的数据损失或安全缺陷能够在短时间内而不是几周响应的话，用户的数据就会安全得多。 然而最重要的是，频繁部署并不比周部署或月部署风险更大。很多小的更新，每个都单独测试和检查过，比起一次大的更新来说，导致严重宕机的事故的可能性要小很多。 这是因为小更新的影响能够提前单独进行复审和测试，从而错误造成的影响也易于量化及应对。定位代码中的缺陷，复审10行的更新比起10000行来，会容易得多，而且只测试那些受更新影响的功能，比起测试整个系统，也要快得多。而且能够确保每次部署都只是更新一个区域，从而避免同时更新的两个组件之间发生预料不到的交互作用。小部署意味着更容易预言更新对基础架构的影响，而这也就意味着未雨绸缪更加有的放矢。 如果只是部署30行代码，缺陷通常是自明的。如果缺陷不自明，其影响也会非常小，即使回滚也非常容易。 只有在遵循以下三条规则的情形下，频繁的小更新才起作用： 构建与部署系统必须能够完全重复且自动地工作 具有几近完美的预演环境 部署必须尽可能快，理想情况是小于5min 大多数构建和部署系统在某种程度上都是自动化的，少数团队走得更远，把构建和部署做成了一键操作。 共享、开放的基础架构很多情形下，运维和工程都分为不同的小组，你会发现支持的基础架构也会一分为二。 共享基础架构是在团队之间进行协作的最容易的方式。 为了有效地工作，你需要了解系统的其它方面目前是如何运转的。为了建立信任，你需要使你的工作变得透明。 信任信任是开发和运维之间最常见的紧张关系之一。多数运维团队对开发团队多少都有点怀疑，开发人员通常也好不到哪去。团队之间的不信任是不健康的，也是不合适的。 信任最终是建立在一种尊敬的感觉之上的。如果你尊敬某人，就很容易信任此人能够做好他的事情。反之，如此人交往便会带有偏见、不满等情绪。 运维和开发之间的许多问题都是由于对两个团队不同角色的重要性认识不同而造成的。 充分尊重你的同事，而不是事后指责他们。 随叫随到的开发人员只有在开发人员对修正生产系统代码中的问题肩负起责任的情况下，才是有意义的，而这就意味着开发人员随叫随到。 现场调试工具很多代码对于运维团队来说都是黑盒子。 要想办法在运行时调用额外的调试信息，技术团队的每个人在用管理账号登录系统之后，都可以开启额外的调试信息。 功能标识禁掉某些依赖于问题架构的功能，而保持网站的其他部分正常运行，功能标识能够实现这一点。 单个标识，用来禁掉每个非核心的基础架构 只要这些服务出现问题，我们都可以暂时并优雅地禁止掉这些功能 如果生产系统出现新的错误场景，也可增加新的标识 避免职责在很多团队中，没有人愿意成为搞坏所有事情的傻瓜。发生问题时，人们都会将责任推卸给别人。 每个人都有貌似合理的理由将指责转嫁给别人，却没有挺身而出，实实在在地修复问题，组织良好的团队深切地了解，在将问题修复之前，争论到底是谁的责任是没有意义的，为保护自己而浪费的每一分钟，由于问题没有修复，都会成为给用户带来损失的一分钟。用户会尝试各种可能性，知道他们发现系统出问题了。 多数生产环境都有足够的冗余，也足够复杂，任何问题都不太可能存在单一的根本问题。很多问题都是由两个或多个系统发生意料之外的交互作用而引起的。 结语网站的稳定性是每一个人的责任，而不仅仅是某种应该交给运维团队去处理的东西。 让人人都拥有对网站的主人翁感觉，确实意味着能够减轻运维团队的工作负担。他们不用再花费大量时间呼吁采取防护性措施，一旦发生问题，也能够花更小的时间修复。这非常了不起，因为这意味着网站的宕机时间会减少很多。这也释放了运维团队，让他们能够把精力放在更为重要的任务上，即对基础架构的长期增长进行管理。 你的访问者感觉怎么样：面向用户的测量对于网站的成功而言，终端用户的测量也就变得和后台测量一样至关重要。 为何要采集面向用户的测量数据采集数据，从而就可以对业务的健康状况进行分析。 如： 每秒请求数/发布数 带宽 响应时间 HTTP错误率 记入日志的异常数 进程重启次数 队列大小 服务器的平均负载和进程数 数据库负载 内存 成功的创业公司所学到的以及必须适应的创业公司的一大优势就是敏捷，即快速反应的能力。要真正做到敏捷，创业公司需要了解终端用户真正体验到的是什么。 任何网站想要成功，就必须向用户学习，而且必须适应用户的需求。很多Internet巨头，它们现在的业务，都与其当初设定的相比有很大的不同。 性能问题响应越快的应用程序越好！ 响应级别： 加入事情的响应时间在10ms内，我们的大脑就会认为这是真实的 如点击桌面系统上的按钮 如果谈话有100ms左右的延迟，我们不会感觉到这种延迟 如国际长途电话 如果应用程序的响应时间在1s之内，我们的感觉就是仍然在与应用程序互动，仍然在工作 应用程序的响应时间要是明显长于1s的话，我们就会抓狂 研究量化了这种关系Web应用的速度越快，其Web业务员的优势就越明显！ 如果你的网站很慢，你将得到： 更少的用户搜索 更少的精度搜索 更少的每访客收入 更少的点击，更低的满意度 更少的每日搜索 等待访客点击的时间更长 更低的搜索引擎排名 更差的用户体验 是什么使网站变得很慢简单来说，由以下三点原因造成： 服务器花在处理用户请求上的时间 网络花在传输请求和响应上的时间 用户花在组装并显示结果内容上的时间 服务发现开始访问网站，用户都需要先找到服务器。 对于带有很多组件的网站——这是一个日渐普遍的模式——都会迫使用户去解析很多网站，并且页面加载的时间也延长了。 发送请求网络再快，用户与服务器之间的往返也是需要时间的。 请求包含的内容越多，则网络用来传输的时间就越长。加入是一个安全页面的话，还会有另外的延迟，用来在客户与服务器之间进行加密协商。 响应请求到达服务器之后，另一个导致延迟的罪魁祸首就登场了——主机。不论是从内存中检索静态对象，还是利用后台的第三方服务来完成一个复杂的请求，主机延迟都会对性能造成影响。 发送响应响应内容一旦准备就绪，服务器就可以通过HTTP协议发送这些请求对象——大多数页面包含多个对象(如html,css,js,gif,png,jpg…)，正是这些对象的发送造成了访客体验到的延迟。 异步通信与刷新某些应用包括一些客户与服务器之间的通信，这些通信是独立于页面进行的。包含某种异步更新或刷新的应用，有不同的延迟测量指标。 渲染时间随着客户端越来越复杂，浏览器做的也就越来越多。有可能是启动富互联网应用(RIA)，这些RIAs都是构建在Flash、Flex、HTML5、Java、JS…之上的，也可能是运行QuickTime或Windows媒体播放器等这样的插件，甚至决定如何对复杂页面进行布局也是需要花费时间的。所以，对于大量依赖客户端进行渲染的网站，就必须考虑这种延迟。 测量延迟有两种测量方法： 综合监控 实际用户监控(RUM) 综合监控综合监控是通过从多个地点对网站进行一系列正规的校本化测试，对网站的性能进行监控。 要记住，综合测试也是要消耗服务器资源的。 真实用户监控RUM的工作名副其实：它观察的是网站的真实访客，记录访客打开页面的速度，然后生成报表。 从这点来看，RUM会告诉你系统是否出问题了，因为你可以通过RUM发现问题以及速度变慢的情况，这些情况你没有进行测试，从而也就不知道是否存在。 编写SLAWeb运维收集终端用户的数据的一个主要理由就是用来编写SLA，哪怕与客户之间没有正式的SLA，但对于正常工作时间及页面延迟，也应该有内部的目标，因为网站速度对用户体验有直接的影响。 访客结果：分析对于成功的Web运维来说，监控就是了解存在哪些不利因素。而当进入Web业务时，这些测量就要让位于Web分析了。 市场营销如何定义成功对市场营销的最好描述——“更经常、更有效地卖出更多的东西给更多的人，从而得到更多的钱。”或许应该将成功的在线营销更精确地定义为“让人们有效地去做你要他们做的事情。” 网站的四种类型 交易性网站 协作型网站 作为服务(saas)网站 媒体网站 很多流行网站都是上述模式的混合。 网站分析就是对每种类型网站的成功因素进行追踪，从中识别出使这些因素得以增长的背后动因——不管是广告活动、性能的提升、社会网络上的关注、特殊的定价模式还是某个引人注目的内容。 分析一个简单的模型有一个简单方式来考虑网站分析，就是做一次访问。 网站分析的目标，就是通过优化网站，将访客的转变最大化，通常是对网站进行试验，并针对各种内部和外部区段，对这些试验结果进行分析。 市场营销关心的其他测量数据Web交互分析分析查看的是用户对多个页面的整体访问情况，Web交互分析集中在单个页面的可用性交互上。 用户之声用户之声工具用来询问客户在想什么。这些工具从网站的访问性中征求反馈，通过请求客户参与调查，或者在页面上提供一个反馈按钮。 用户体验如何影响Web运维随着新建公司对终端用户体验的关注，Web运维的角色正在发生变化。对线上事务的兴趣越来越浓，而且通过追踪分析，网站的所有事情都能够和业绩联系起来。 将监控作为生命周期的一部分网站现在已经有了很大的变化，随着敏捷和精简产品开发的流行，监控也需要跟上。所以来的综合监控脚本以及RUM配置也需如此。 Web监控的未来终端用户体验的监控正在兴起，变化很快。这是业务中最能进行分析、量化的部分，每周都能涌现出新的技术。 从系统转向用户 以服务为中心的架构 云与监控 APIs与RSS消息 将关系数据库用于Web的战略战术如何为产品或应用程序设计一个良好的关系数据库架构，如何构建良好的互联网数据库架构？ Web数据库需求其实，大多数网站，相对而言，都只是小型数据库。一些大型公司，可能才是一个大型数据库。 一直在线数据库通常要7x24小时运行。一直在线意味着维护和运维任务是很难做的，你不能简单地等到人们回家了然后将服务器卸下来，给硬件升级或备份。必须在不停机的情况下做这些事，而且很多情况下还不能给应用程序增加额外的负载。 话虽这么说，还是极少看到没有峰值时间的数据库。所以，还是有很好的机会，在数据库活动的间歇期来做备份或对数据库产生干扰工作。 事务最多的工作负载很多互联网应用都匹配以下模式： 应用程序读远大于写 一次读一行和一次读多行是混合出现的 一般，写每次只影响一行 这就是称之为的事务型负荷。 简单数据，简单查询网站的流量很大程度上决定了数据库的流量。 查询通常会满足下面的模式： 读写用户表，一次一行 以区域或集合方式读取用户自己的数据 以区域或集合方式读取其他用户的数据 从该用户到其他用户的关联表中读取区域行 对该用户和其他用户的数据进行汇总与计数 特别低，很多数据可以分区存储的事实说明了为什么分片(sharded)架构是可能的。 可用性胜过一致性从业务的角度看，最重要的事情是应用程序对用户的可用性。 快速开发传统应用极少以天或周为周期构建和部署，但对于大量Web应用来说却是常态，这些Web应用是永远的Beta版。 在线部署模式和数据的更新都做成代码形式，而且也有这样的框架，部署这些代码或将其回滚都很容易。 由开发人员构建大量的应用程序都是由开发人员做的，都没有一个高水平的DBA。 典型的Web数据库是如何增长的大多数Web数据库的增长，都经历了一些列的架构变动。这些架构变动，在应用程序的整个生命周期中，相对而言都是可预知的。 单台服务器一般应用程序都是从单台服务器开始起步的。使用单台服务器有很多好处： 数据只有一份拷贝，不存在你的数据是否正确或不同的问题 易于配置 便宜 当然，缺点就是只有一台服务器！假如发生问题，没有冗余机器做故障转移。性能也会受影响。 主服务器与单复制从服务器各数据库的复制技术都不一样，但一般而言，发生在主服务器上的数据修改，都要在从服务器上重复一遍，所以从服务器是主服务器数据的只读拷贝。依赖于数据库、系统负载以及执行的查询类型，从服务器不一定时刻与主服务器的数据完全一致(异步复制)。 增加一个复制从服务器有很多好处。数据库读请求可以在主、从指间分担，这称为读写分离。可以在从服务器上执行那些效率不高的查询、备份以及其它有可能对网站造成破坏的任务。 主服务器与多复制从服务器大多数复制技术对两台或多台从服务器都没问题。这样确实不错，而且随着从服务器越来越多，系统的数据库读取能力也越来越强。但这种增长不是无限制的，在很多层面上都会遇到收益递减的拐点。 第一个层面就是应用程序中读对写的比例 第二个方式表示主服务器的写操作有多忙，其中你会看到收益递减的情况 第三个限制是操作成本和复杂性 管理一群服务器，比管理单台服务器，要难得多也昂贵得多 最后一个不足是应用的复杂性 从单一数据源走向两个数据源，对于大多数应用程序而言，都是一个重大转移。应用程序不得不连接多个位置来进行查询。连接池、负载均衡器以及类似技术会在一定程度上保护你不受这种复杂性的困扰，但最终应用程序仍然要面对某种程度的复杂性 复杂性的一个最大来源是异步复制。异步意味着写操作先在主服务器上完成，随后送往从服务器执行。结果就是，从服务器总是拖后于主服务器某段时间，即时这段时间很短，但由此而造成的问题却很大。这可能会导致用户体验的不一致到数据完整性等一系列问题。 一般而言，不存在修复这个问题的神奇方法，应用程序必须自己处理这种延迟复制。一种不错的简单技术是基于会话的分裂。用户做了更新之后，一段时间之内，该用户的所有查询都导向到主服务器。认为能够安全地查询从服务器所需的时间戳通常都存储在会话里。 功能分区复制只对读有伸缩，对写没有。随着应用的规模越来越大，写操作的负载最终会大到系统无法处理。 功能分区(functional partitioning)，假如将某些部分与其余部分分开，则这些部分可以独立增长。如，对于博客服务，可将评论功能分离到它自己的服务器中。 从运维角度来看，不同部分处在不同位置，则应用程序的功能也就能够单独对待。比起网站宕机，将评论改为只读模式，用户的反感可能要小得多。 这种做法的不利之处是增加了复杂性。应用程序需要从多个位置获取数据，而运维团队必须保持这些服务器正常运行。 分片分片(sharding)，是将单一逻辑数据划分为多个片段并发布在多台服务器上的一种方式。所有的片段在逻辑上和功能上都是相同的，虽然这些片段分别包含数据的不同子集。 分片架构的主要设计目标和优势都是双重的。第一是允许写伸缩，因为负值无法实现写伸缩，假如应用程序的写操作草果了任何单台服务器能承受的程度，就必须要分片以减少写操作的负载，写操作的负载必须分担到完全隔离的服务器上，对一个分片的服务器的写操作不能复制到另一个分片服务器上。第二个目标和优势是，随着数据集的增长，能够增加更多容量的能力。 在分片架构中，许多查询也变得困难或不可能了。例如，需要访问所有客户数据的查询，通常都要在每个分片上分别执行，然后在应用程序代码中在聚合在一起。 分片架构还存在很多其他的不足和复杂性。 缓存层缓存层的目的是阻止查询到达数据库。标准的例子是：memcached，redis 缓存层的主要优势是极为容易，并且简单。 从运维的立场来看，需要考虑缓存服务器的冗余和可用性，就像为其他服务器所做的一样。 对集群的渴望在应用程序出现某种问题，或关于可用性或伸缩性的困难问题来的时候，人们的思想就会转向集群(cluster)，就像年轻人的思想转向春天和爱情一样。 CAP定理以及ACID和BASECAP原理： 一致性(Consistency)、可用性(Availability)、分区容错性(Partition Tolerance)。你可以具有两者，但不能三者皆具备。 ACID： 原子性(Atomicity)、一致性(Consisitency)、分离性(Isolation)、持续性(Durability)。 BASE: 根本可用性(basically available)、软状态(soft state)、最终一致性(eventual consistency)。 MySQL集群的状态MySQL Cluster是将MySQL服务器作为一个完全不相干的、称为NDB的软件的前端。NDB的意思是网络数据库，这是一个极快、分布式、无共享、高可用的数据库。 DRDB和HeartbeatDRDB在服务器之间对块设备进行复制，将修改的块通过网络复制给备机。如果主服务器失效了，则Heartbear激活备机。 从运维的角度来说，DRDB非常棒，装上就能工作，但却不能满足在线用户的需求。它不是为满足典型Web应用的高可用性而设计的。相反，它非常适合用户保证你不丢失数据的情况，也就是说，它关注的焦点是一致性而不是可用性。 另一个问题就是基于DRDB的集群不能改进性能。Web应用需要的是正常工作时间和性能，而基于DRDB的集群是以性能为代价来提供一致性，而一旦失效，宕机时间就会很长。 主服务器到主服务器的复制管理器(MMM)MMM是一系列的Perl脚本，管理复制和虚拟IP地址，从而为MySQL提供一个伪集群(pseudocluster)。 应用程序连接到虚拟IP而不是服务器的真实IP。服务器发生问题时，MMM将该服务器的虚拟IP移动到另外的可用服务器上。它也可以将复制从服务器从失效的主服务器移动到正常的主服务器上。MMM允许手工将服务器离线执行维护任务。 带复制的Heartbeat如果MMM无法完美地管理复制和虚拟IP地址，heartbeat考虑以下？ 不管怎么说，复制延迟仍然是一个复杂的问题。必须在应用程序层解决这一部分问题。 基于代理的解决方案有一种可供选择的方案，基于代理(proxy)，需要人工介入，MySQL Proxy位于前端。HAProxy是另一个流行的方案。 MySQL Proxy，事实上能够理解MySQL的协议，并且拦截、解释以及传递消息 HAProxy，只是传递TCP流，并不对内部进行窥探 基于代理的解决方案仍然没有入人们所愿的那样解决复制延迟问题，而且还引入了单点故障，并且影响性能。 小结前面讨论这么多，简而言之，就是没有一个完美的、万能的答案。 最好的数据库架构是为了应用而建的，期待集群所承担的指责分布在数据库、网络以及应用程序上，有运维的适度介入，以及起粘合作用的软件，就能把各部分整合在一起。 数据库战略如何选择一个对于大量的互联网架构来说都能够运转良好的架构。 架构需求最好定义你的需求，特别是，把那些超出你的范围从而成为别人的问题的内容写成文档。 有把握的架构以下数据库架构，是比较有把握的。 单主服务器，多从服务器这种主-从架构很难自动实现主服务器的故障转移，因为主服务器和从服务器的配置是不一样的，所以，一旦主服务器失效，则必须手动进行失效转移。 主服务器-主服务器复制，外加从服务器这种方式实际上与一台主服务器加多台从服务器的架构一样，但有时候主服务器本身也成为从服务器。这种架构的优点是，在协同的主服务器之间更容易实现失效转移和失效转回。缺点是，向两台主服务器进行写入存在风险，会导致数据库存在某种不一致性，也很难解决。 功能分区随着应用的增长，将应用中某些部分转移到特定的服务器或特定集群上。 失效转移和负载均衡使用负载均衡器，或者浮动的虚拟IP地址。 ACID仍然是有意义的高可用性要求快速而可靠的灾难恢复。 使用正确的工具不要使数据库处于关键路径上，不要讲应用程序的静态信息放入数据库中。数据库应该存储数据，而非应用程序本身。将数据库简单化，因为这是最难于伸缩，也是最昂贵的资源。但是，对于Web应用，还是应该分离应用程序和数据库，将数据库仅用来存储和检索数据。 有风险的架构建议不要使用这些架构 分片除非不得已，不要分片。对于一个中等规模的应用，将其构建在数百台低档机器的分片架构上，试图提供无线伸缩能力，是非常愚蠢的。其实，只需购买几台足够好的机器，在工程上多做一些考虑就足够了。分片架构比你预想要昂贵的多，甚至在短期内也是如此，长期则一定如此分片问题设计过度设计的风险 写入多台主服务器不要将多台服务器配置为可写，这会造成数据一致性问题。非常麻烦。 多级复制尽量不要使用多级复制。使用一主多从而不是从的从的从服务器，要简单的多。孙子辈的从服务器和重孙辈的从服务器很难管理。 环形复制避免使用环形复制，其失效情形，不管是数量还是复杂度，都打得超乎想象。 依赖于DNSDNS很脆弱，依赖DNS最终会自食苦果。 数据库战术数据库战术，即为保持数据库基础架构的可靠性而做的日常运维任务。 在从服务器上做备份一些小提示： 在备份上不要拖延，做备份其实并不难 做事不要追求完美，而要追求可恢复 至少对于可接受的数据损失、可接受的宕机时间、数据持续策略以及安全需求要形成文档 对恢复过程要进行练习并形成文档，恢复比备份要重要的多 对于备份成功与否，要进行外部验证，不要依赖于作业自身对你的提示 可以专门配置一台复制(备份)从服务器，将复制延迟一段时间——如30min，以避免主服务器上的某些误操作——如DROP table。 在线模式修改将表做的小一点是很有好处的。 一般的想法是设置主-主复制对，但只有一台服务器可写。在只读上执行更新，但不要复制到可写服务器上。更新一旦完成，则用正常方式使应用程序实现失效转移。这样，读和写便实现了角色转换。然后在另一台服务器上重复执行风险。这就实现了对应用程序隐含宕机时间的目的。 监控和图示构建用于测量和监控的系统是很值得做的事情，这些系统是基础架构非常重要的核心内容。 性能分析一般步骤是，在产生麻烦的时间内手机详细的诊断数据，消除掉可能的原因，集中在问题的现象上。问题往往是服务器产生大量负载，而这通常是由于糟糕的查询产生的。 MySQL所谓的慢查询日志(slow query log)可以回答这个问题，不仅是因为日志收集了慢查询的信息，而且对于每个查询还有时间信息。 加入性能问题不是查询引起的，则需要对MySQL本身进行性能测试。 归档和删除数据从一开始就要规划归档和删除不活动或不需要的数据，这样有助于减小“工作集”的大小。 将极不活跃的用户数据移动到慢速服务器，或仅仅将用户设置为过期。当用户登录或重新激活时，在倒回到正常表中 另外一类可归档或删除的数据是陈旧的历史数据，或将历史数据移到另外的服务器上 结语尽最大可能将数据库架构建立在逻辑的基础上，而不是做一些看起来很酷的事情。 努力使系统保持小巧，不要大——而当不得不变大时，也要保持在能够掌控的范围内。要确定应用程序的真正需求，尽可能满足这些需求。要尽早及经常做缓存，但不要尽早及经常做分片。 最重要的，请记住：做备份。 如何优雅地失败：事后处理的艺术与科学宕机意味着实际的金钱损失。客户才不会管这些故障，他们要的就是可靠性。互联网已经变得非常重要，宕机成本也越来越高。 但正如一个刚毕业的年轻人一样，只是知道你需要成长，但并没有告诉你如何去成长。我们需要将失败转化为学习经验。 保证网站稳定的首要事情，就是建立一个系统化的事后分析过程。通过阻止事故的重现以及改进处理事故的方法，使得系统稳定之后，事后分析能够让你全面地理解事故的本性。 例行的时候分析，是对运维的复杂问题进行科学分析的最贴近的方法。通过收集实际证据，可将有限的资源集中于解决产生问题的实际原因上。 什么是事后分析事后分析至少要包含这些内容： 事故描述 根本原因描述 事件是如何修复的 用于解决事故的行动的时间表 事故是如何影响用户的 纠正或改正动作 事后分析时，与事故明显有关的人员都要同时到场，对事故的真实情况作出共同的描述，从而正确地采取行动。 减少事故的修复时间，就跟消除事故本身一样重要。 对问题赋予严重级别，将帮助你按照轻重缓急来处理纠正项，而且对于活跃事件的评估也是有用的。 事故严重级别： 严重影响大批用户 网站降级运行、性能问题或很难应对的功能故障 对客户影响不大或易于应对 什么时候引入事后分析在事故处理完成之后，就应该进行事故分析。事后分析过程应该最终使用户获益，而不应该在恢复服务的过程中进行。 进行事后分析开始事后分析时，要明确基本规则，要明确告知参与事后分析的相关各方，事后分析不是指责谁(人们害怕这样的会议变成政治迫害)，主要目的是为了使类似事件不在重复发生。问题不可避免，重要的是我们能够从错误中学到教训。事情一旦清楚之后，就可以开始讨论为了使类似事情不在发生，需要做些什么。确保相关各方对各自领域都能得出补救的办法。但切记不可矫枉过正！ 一旦有了一套纠正措施，要将其记录在案，包括执行人员和完成日期。 事后分析的后续工作对纠正措施必须进行追踪，直到执行完成。 一些网站可操作性： 消除单点故障 容量规划 监控 发布管理 运维架构复审 配置管理 随时待命和提升过程 不稳定的组件 结语最后，对于避免事故的发生，事后分析是最有用的方法。在一个快速变化的环境中，发生问题时可以理解的，但问题重复发生却是不能原谅的。花些时间高清楚问题的实质，从而确定、记录以及实施高强度的纠正措施，就可以避免事故的重复发生。 存储数据是一项最重要、不可替代的商业资产。 数据资产的库存在开始一项新的存储工作时，首要的事情是要知道数据存在哪里。对于不了解的数据，你是无法进行保护的。 数据的保护数据保护对所有系统都是很重要的。良好的数据保护实践有助于处理范围广泛的情形，从还原被用户偶然删除的文件，到从灾难事件中恢复。 为了对数据中心问题提供完全的防护，重要的是将关键数据复制到不同的地点。 如今大多数的存储系统都有某种类型的复制技术。复制通常有两种形式：同步和异步。 容量规划在确保有效的的数据保护之后，作为一名存储专业人员，容量规划就是第二项最重要的职责。规划在前，确保应用和服务有足够的资源来运行和成长，不至于碰到天花板，这是必须的。 总是确保有足够的空间以应对突然的爆炸性增长，以及软件开发方面出现的延迟。 存储大小的变化存储是很昂贵的，这是现代基础框架中成本最高的组件。正是由于这个原因，对于存储上的开支进行明智地规划是很重要的。 存储需求要点： 应用是什么 应用位于哪里 存储的是什么类型的数据 需要共享存储吗 是否需要特殊的访问协议 典型的文件大小是多少 数据是压缩的吗 如果描述工作负载 需要批处理操作吗 工作负荷是大部分用于读、写、读写 工作负荷是大部分顺序、还是大部分随机、还是两者 快照是怎么安排的 快照的一致性问题 存储容量在6个月、12个月、18个月的计划是什么 工作负荷在6个月、12个月、18个月的计划是什么 复制策略是什么 业务连续性规划是什么 可用性需求是什么 备份的频度是什么 备份保持的计划是什么样的 归档策略是什么 综合性需求是什么 加密需求是什么 … 结语数据是最宝贵的业务资产，且是不可替换的。 非关系数据库应用的数据存储层的伸缩是很难的。不管用的是什么数据库技术，随着数据量和事务数量的增长，就需要做出改变以适应新的负荷。 SQL数据库的可伸缩性通常归结为四件事：缓存、查询优化、购买新硬件、数据库分片。 NoSQL数据库概览NoSQL共生系统，可将数据库划分为5大类： 纯粹的键值 数据结构 图 面向文档 高度分布 每种类别的数据库都面向不同的应用情况，每个类别也都做了不同的这种。 纯粹的键值如： Tokyo Cabinet、 Kyoto Cabinet、MemcacheDB 正是它们的简单性定义了这组数据库。向数据库存入一个键和一个值，然后用同一个键查询数据库，则会得到相同的值。没有结构或类型系统——通常所处理的只是字节或字符串。因为这种简单性，这些数据库的开销极小，所以非常块。事实上，这些数据库通常都是实现为磁盘上的B树或哈希表。 数据结构数据结构数据库对键值数据库做了些修改，数据结构数据库将其存储为特定的数据结构，如列表、集合、哈希表等。有了这些附加的结构，就可以对值执行一些原子操作。可以对数据库执行在应用程序中对数据结构进行的各种操作。 Redis默认是在内存中(in memory)存储其全部内容，只是周期性地将内容的快照存储到磁盘。这使得Redis出奇的快，但假如数据库奔溃了，就会对数据造成一些损失，同时也意味着必须有足够的RAM存储这个数据库。 图图数据库几乎就是数据结构数据库的一个特定实现，因为图本就是一种数据库。区别是图数据库不再是基于键值，数据是作为图的节点和边存储的。图数据库不是用键来查询值，而是给出根节点的句柄，然后就可以遍历整个图以找到需要的节点或边。 图数据库的优势：存储图或树形的数据。如一个社交图(social graph)。 常见图数据库包含：Neo4j、HyperGraphDB、InfoGrid、VertexDB。 面向文档面向文档的数据库又类似于键值数据库，但值不再是字节、字符串、列表、集合，而是文档。文档作为JSON(BSON)对象存储，本质上是一种哈希表或字典。这些值都想相同的结构，意味着可以用查询来探测这种结构，并只返回所需要的文档。这种查询能力是建立在通过键来查找文档的能力之上的。 常见面向文档数据库： MongoDB、CouchDB。 高度分布高度分布的数据库多少有些不同——有些本质上更接近于键值存储，其它则像大型的多维哈希图。 HBase、Cassandra是高度分布式数据库。 某些细节注意这些数据库之间的一些相似性，以及所做决策是如何影响系统可操作性的。 CassandraCassandra是一个高度分布数据库。 它有一些关键概念： 认为写比读更难于伸缩，所以它专门为写操作做了大量优化 认为不应该存在单一故障点任何数据可以写入到集群内的任何一个节点，而且读也一样。任何接收到请求的节点都可以，并且将会吧请求转发到合适的节点。 HBaseHBase选择一致性和可用性作为自己的核心价值。这样的结果，导致了在某些网段、集群无法实现优雅的恢复。作为这种牺牲的补偿，HBase有很强的一致性，保证写入一结束，写入的值就立即可以读取。 RiakRiak实现了向量时钟(vector clocks)，一些高度分布的数据库都没有实现——这些数据库选择了依赖于更为简单的基于时间戳的技术。 向量时钟是一种分布式系统中的机制，用于生成偏序事件。使用向量时钟，解决发生在两个独立的不同节点中的相同值的冲突就变得非常简单。从Riak客户端的角度来看，每个客户实例在Riak集群中执行一个动作时，都应该有一个唯一的标识(token)(连同其接收到的向量时钟一起)。然后，客户读取数据时，就可以看到向量时钟和数据值，使用包含的信息连接两个结果，从而将正确的版本写会数据库。 Riak也不存在单一故障点。 CouchDBCouchDB对世界的看法是一致的：所有东西都是文档，而且都通过RESTful HTTP来访问。CouchDB可以在数据库中直接存储静态媒体，它实际上是允许将整个应用程序都存储在数据库中的。CouchDB的数据模型很新颖，即数据以一种只附加的B树进行存储。 MongoDBMongoDB是一个面向文档的数据库，文档格式使用BSON——一种类似于JSON对象的二进制规范。MongoDB是用C++写的，因而有很高的性能。 所有能用SQL做的事情也能用MongoDB查询表达式来做。MongoDB与以SQL数据库相同的方式支持索引，同时这些索引也强制了唯一性。 MongoDB有一个mongostat命令来查看数据库状态。 有好几种MongoDB备份方式： 停掉数据库，复制数据文件 锁定数据库写入，复制数据文件，解除锁定 使用mongodump，将数据库转存到一个二进制文件中 可以设置一个从服务器，在从服务器上进行备份，而不是主服务器上 RedisRedis(remote dictionary server)，远程字典服务器。通过INFO可查看相关信息。 不管你将Redis运行在快照模式(rdb)还是只附加模式(aof)上，都可以简单地调用rsync实现备份。 如何高枕无忧企业持续规划(Business Continuity Planning)BCP。BCP简单最简单来说，就是什么都是两份。当然，两套设备间的失效转移必须完全自动化。 术语集中于BCP计划的高可用部分：保证站点正常工作。即使在高可用性领域，也有各种各样的技术，从热/热(Hot/Hot)、热/暖(Hot/Warm)、热/冷(Hot/Cold)到灾难恢复。 热/热是高可用性的最高级别。用户可以从任意的数据中心使用全部的应用程序。读和写可以发生在任何地方。折让自动的故障转移变得非常简单，但它不是万能的。你想必须思考如何处理数据一致性的问题。 热/暖是一种很好的方式，如果你不能容忍数据的不一致性的话。很多应用有大量的读操作，仅偶尔写一下(但很重要)。在这种情况下，区别处理这两种操作是有意义的。 热/冷让我害怕。这种架构将读写流量送到单一地点，而让另一个相同的部署在遥远的地平线上闲置。它容易建立，但价值很低。 灾难恢复是最差的技术，本质上是雾件(vaporware)。它的本意不是在平常的时候保护你，而是在大的灾难发生时给你提供重建的选项。 影响持续时间对事件持续时间当灾难来袭时，所有你需要考虑的是将用户流量以最快速度转移，离开问题区域。你需要立即降低影响。不要过于担心根源问题的修复，一旦将影响制止住，会有很多时间来解决这次事故。 怎样才能将流量从问题站点转出呢？通常方案是使用全局负载均衡(Global Server Load Balancing)GSLB。这实际是一个动态的授权DNS服务器，他能够根据相关因素对同一域名给出不同的IP地址。 数据中心数量我们知道数据中心会失效，所以你至少需要两个。这就够了吗？三个或更多是不是会好一些？这取决于三个因素，成本、复杂性和性能。 逐渐失效当数据中心出现局部问题(partial problem)时，不要等它解决从而希望你不需要撤离，立即导出复制数据！ 不信赖任何人正如最可靠的数据中心也会时不时宕机，你可以预期即使最好的第三方供应商，偶尔也会有问题。就是你不能完全信赖一个服务提供商。 故障测试转移通过早期和经常的测试，获取经验，以便当灾难袭来时，不会手忙脚乱，而是立即做出正确的事情。 监控和历史模式你要知道日、周、月的流量模式。如果清楚正常流量中的不寻常处，你就不会在切换、迁移或升级时感到惊讶。确保监控包括周对周的图形和趋势。 高枕无忧如果你能够事先有计划，能够解决大的问题，并且在日常工作中操练故障转移，则平台任何部分的失效将会变成容易处理的事件，而不是危机。 March 25, 2018 11:32 AM]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>Operations</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《经济学原理》读书笔记]]></title>
    <url>%2F2018%2F02%2F23%2F%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[参考： 《经济学原理-微观/宏观》 曼昆： https://book.douban.com/subject/26435630/ 学习指南图微观经济学:第1篇到第7篇，即第1章到第22章。 第1篇： 导言 第1章： 经济学十大原理 第2章： 像经济学家一样思考 第3章： 相互依存性和贸易的好处 第2篇： 市场如何运行 第4章： 供给与需求的市场力量 第5章： 弹性及其应用 第6章： 供给、需求和政府策略 第3篇： 市场和福利 第7章： 消费者、生产者与市场效率 第8章： 应用： 赋税的代价 第9章： 应用： 国际贸易 第4篇： 公共部门经济学 第10章： 外部性 第11章： 公共物品和公共资源 第12章： 税制的设计 第5篇： 企业行为与产业组织 第13章： 生产成本 第14章： 竞争市场上的企业 第15章： 垄断 第16章： 垄断竞争 第17章： 寡头 第6篇： 劳动市场经济学 第18章： 生产要素市场 第19章： 收入与歧视 第20章： 收入不平等与贫困 第7篇： 深入研究的论题 第21章： 消费者选择理论 第22章： 微观经济学前沿 宏观经济学：从第8篇到第13篇，即第23章到第36章。 第8篇： 宏观经济学的数据 第23章： 一国收入的衡量 第24章： 生活费用的衡量 第9篇： 长期中的真实经济 第25章： 生产与增长 第26章： 储蓄、投资和金融体系 第27章： 金融学的基本工具 第28章： 失业 第10篇： 长期中的货币与物价 第29章： 货币制度 第30章： 货币增长与通货膨胀 第11篇： 开放经济的宏观经济学 第31章： 开放经济的宏观经济学基本概念 第32章：开放经济的宏观经济理论 第12篇： 短期经济波动 第33章： 总需求与总供给 第34章： 货币政策和财政政策对总需求的影响 第35章： 通货膨胀与失业之间的短期权衡和取舍 第13篇： 最后的思考 第36章： 宏观经济政策的六个争论问题 阿尔弗雷德·马歇尔在《经济学原理》中写道经济学是一门研究人类一般生活事务的学问。 应当学习经济学的原因如下： 有助于你理解你所生活在其中的世界 使你更加精明的参与经济 使你更好地理解经济政策的潜力与局限性 经济学原理可以运用到生活中的方方面面 经济学领域的伟大洞见，如亚当·斯密的看不见的手的概念、大卫·李嘉图的比较优势原理，以及约翰·梅纳德·凯恩斯的总需求理论 导言经济学十大原理经济(economy)这个词来源于希腊语oikonomos，意思是“管理一个家庭的人”。 一个家庭面临着许多决策，同样，一个社会也面临着许多决策。 由于资源是稀缺的，社会资源的管理就尤为重要。 稀缺性(scarcity):社会资源的有限性 经济学(economics):研究社会如何管理自己的稀缺资源 人们如何做出决策由于一个经济的行为反映了组成这个经济的个人的行为，所以个人就需要做出决策。 人们面临权衡取舍 效率(efficiency):社会能从其稀缺资源中得到最大利益的特性 平等(equlity):经济成果在社会成员中平均分配的特性 作出决策就是要求我们在一个目标与另一个目标之间进行权衡取舍。 当人们组成社会时，他们会面临不同的权衡取舍。经典的权衡取舍是在大炮与黄油之间。 社会面临的另一种权衡取舍是在效率与平等之间。 然而，认识到人们面临权衡取舍本身并没有告诉我们人们将会或应该做出什么决策。 某种东西的成本是为了得到这种东西所放弃的东西 机会成本(opportunity cost):为了得到某种东西所必须放弃的东西 由于人们面临着权衡取舍，所以做决策就需要比较可供选择的行动方案的成本与收益。 理性人考虑边际量 理性人(rational people):系统而有目的地尽最大努力实现其目标的人 边际变动(marginal change):对行动计划的微小增量调整 边际成本(marginal cose):对行动计划调整所带来的成本 边际收益(marginal benefit):对行动计划调整所带来的的收益 边际决策(marginal decision):选择哪种决策 人们会对激励做出反应 激励(incentive):引起一个人做出某种行为的某种东西 在经济学研究中，激励起着中心作用。 市场上的高价格提供了买者少消费而卖者多生产的激励。价格对消费者和生产者行为的影响对于市场经济如何配置稀缺资源是至关重要的。 政府决策者决不能忘记激励，因为许多政策改变了人们面临的成本或收益，从而也改变了人们的行为。 在分析任何一种政策时，我们不仅应该考虑它的直接影响，而且还应该考虑它通过激励产生的不太明显的间接影响。如果政策改变了激励，那就会使人们改变自己的行为。 人们如何互相影响我们的许多决策不仅影响了我们自己，还会影响其他人。 贸易可以使每个人的状况都变得更好思考国家之间的竞争的想法很容易产生误导。美国与中国之间的贸易并不像体育比赛一样，一方赢而另一方输。实际上，事实正好相反：两国之间的贸易可以使两个国家的状况都变得更好。 贸易使每个人都可以专门从事自己最擅长的活动，无论它是耕种、做衣服还是盖房子。通过与其他人的贸易，人们可以以较低的成本获得各种各样的物品和服务。 国家和家庭一样，也能从相互贸易中获益。贸易可以使各国可以专门从事自己最擅长的活动，并享有种类更多的物品与服务。美国人和英国人、法国人一样，在世界经济中既是我们的竞争对手，又是我们的伙伴。 市场通常是组织经济活动的一种好方法 市场经济(market economy):当许多企业和家庭在物品与服务市场上相互交易时，通过他们的分散决策配置资源的经济 看不见的手(invisible hand): 利己心(self-interest): 中央计划经济国家运行的前提假设是，政府官员能够最佳地配置经济中稀缺资源。这些中央计划者决定，生产什么物品与服务、生产多少，以及谁生产和消费这些物品与服务。支撑中央计划经济的理论是，只有政府才能以促进整个社会经济福利的方式组织经济活动。 大部分曾经是中央计划经济的国家已经放弃了这个制度，代之以发展市场经济。在市场经济中，中央计划者的决策被数千百万企业和家庭的决策所取代。 在市场经济中，没有一个人追求整个社会的经济福利。自由市场包括大量物品与服务的许多买者与卖者，而所有的人都主要关心自己的福利。 经济学家亚当·斯密在《国富论》中提出了全部经济学中最著名的观察结果：“家庭和企业在市场上相互交易，他们仿佛被一只看不见的手所指引，并导致了合意的市场结果。” 价格就是看不见的手用来指引经济活动的工具。作为买者与卖者决策的结果，市场价格既反映了一种物品的社会价值，也反映了生产该物品的社会成本。斯密的重要洞察是，价格会自发调整，指引这些单个买者和卖者达到某种结果，该结果在大多数情况下会实现整个社会福利的最大化。 斯密的观点有一个重要的推论：当政府阻止价格根据供求状况自发调整时，它就限制了看不见的手对组成经济的千百万家庭和企业的决策进行协调的能力。这个推论解释了为什么税收对资源配置有不利的影响：由于税收扭曲了价格，从而也扭曲了家庭和企业的决策。这个推论还解释了像租金控制这类直接控制价格的政策所引起的巨大危害。而且，这个推论解释了中央计划经济的失败。在中央计划经济国家，价格并不是在市场上决定的，而是由中央计划者规定的。这些计划者缺乏关于消费者爱好和生产者成本的必要信息，而在市场经济中这些信息都反映在价格上。中央计划者之所以失败，是因为他们在管理经济时把市场这只看不见的手绑起来了。 亚当·斯密描述了市场经济中人们如何相互影响： 人类几乎随时随地都需要同胞的协助，要想仅仅依赖他人的恩惠，那是绝对不行的。他如果能够刺激他人的利己心，使其有利于他，并告诉其他人，给他做事是对他们自己有利的，那么他要达到目的就容易得多了。··· ···请给我们我所要的东西吧，同时，你也可以获得你所要的东西：这句话是交易的通义。我们所需要的相互帮助，大部分是依照这个方法取得的。我们每天所需的食物和饮料，不是出自屠户、酿酒师或面包师的恩惠，而是出自他们利己的打算。我们不说唤起他们利他心的话，而说唤起他们利己心得话。我们不说自己有需要，而说对他们有利。社会上，除乞丐外，没有一个人愿意全然靠别人的恩惠过活… …每一个人··· ···既不打算促进公共的利益，也不知道自己是在何种程度上促进那种利益··· ···他所盘算的也只是他自己的利益。在这种场合下，像在其他许多场合一样，他受着一只看不见的手的引导，去尽力达到一个并非他本意想要达到的目的。也并不因为不是出于本意，就对社会有害。他追求自己的利益，往往使他能比在真正处于本意的情况下更有效地促进社会的利益。 斯密是说，经济参与者受利己心所驱动，而市场上这只看不见的手指引这种利己心去促进总体的经济福利。 政府有时可以改善市场结果 产权(property rights):个人拥有并控制稀缺资源的能力 市场失灵(market failure):市场本身不能有效的配置资源的情况 外部性(externality):一个人的行为对旁观者福利的影响外部性的经典例子是污染 市场势力(market power):单个经济活动者(或某个经济活动小群体)对市场价格有显著影响的能力 我们需要政府的原因之一是：只有在政府实施规则并维持对市场经济至关重要的制度时，看不见的手才能施展其魔力。最重要的是，市场经济需要实施产权制度，以便个人可以拥有和控制稀缺资源。我们都依靠政府提供的警察和法律来实施我们对自己生产出来的东西的权利——而看不见的手依靠我们实施自己权利的能力。 然而，我们需要政府的另一个原因是：看不见的手是强有力的，但并不是无所不能的。政府干预经济并改变人们自己选择的资源配置的原因有两类：促进效率和促进公平。这就是说，大多数政策的目标要么是把经济蛋糕做大，要么是改变这个蛋糕的分割方式。 在存在外部性或市场势力的情况下，设计良好的公共政策可以提高经济效率。 即使看不见的手带来了有效率的产出，他也不能消除经济福利上巨大的不对称。根据某种政治哲学，这种不平等要求政府进行干预。实际上，许多公共政策，例如所得税和福利制度的目标就是要实现更平等的经济福利分配。 我们说政府有时可以改善市场结果并不意味着它总会这样。公共政策并不是天使制定的，而是由不完善的政治程序制定的。有时所设计的政策只是为了有利于政治上有权势的人；有时政策是由动机良好但信息不充分的领导人制定的。 整体经济如何运行决策和相互影响共同组成了经济。 一国的生活水平取决于它生产物品与服务的能力 生产率(productivity):每单位劳动投入所生产的物品与服务数量 世界各国生活水平的差别是惊人的。随着时间的推移，生活水平的变化也是巨大的。 几乎所有的生活水平的差别都可以归因于各国生产率的差别。 生产率和生活水平之间的基本关系是简单的，但它的意义却是深远的。如果生产率是生活水平的首要决定因素，那么，其他因素就应该是次要的。 当政府发行了过多货币时，物价上升 通货膨胀(inflation):经济中物价总水平的上升 在大多数严重或持续通货膨胀的情况下，罪魁祸首是货币量的增长。 当一国政府发行了大量本国货币时，货币的价值就下降了。由于高通货膨胀会让社会付出各种成本，所以世界各国的经济政策制定者都把保持低通货膨胀作为目标之一。 社会面临通货膨胀与失业之间的短期权衡取舍 经济周期(business cycle):就业和经济生产的波动 虽然在长期中，物价水平上升主要是货币增加的结果，但短期中，问题就变得更为复杂更具争议性。 大多数经济学家这样描述货币注入的短期效应： 经济中货币量增加刺激了社会的整体支出水平，从而增加了对物品与服务的需求 需求的增量随着时间的推移，会引起企业提高物价，但同时，它也鼓励企业雇佣更多的工人，并生产更多的产品与服务 服用更多的工人意味着更少的失业 你知道，支出链将以乘数扩大，并带来更高的收入和就业。人们看到了发生了的活动，但他们没有看到本来会发生的活动。 结论经济学十大原理： 人们如何做出决策 人们面临权衡取舍 某种东西的成本是为了得到它所放弃的东西 理性人考虑边际量 人们会对激励做出反应 人们如何相互影响 贸易可以使每个人的状况都变得更好 市场通常是组织经济活动的一种好方法 政府有时可以改善市场结果 整体经济如何运行 一国的生活水平取决于它生产物品与服务的能力 当政府发行了过多的货币时，物价上升 社会面临通货膨胀与失业之间的短期权衡取舍 像经济学家一样思考每个研究领域都有自己的语言和思考方式。经济学家也一样。供给、需求、弹性、比较优势、消费者剩余和无谓损失——这些术语也是经济学家语言的一部分。 作为科学家的经济学家先提出理论，再收集数据，然后分析数据，以努力证明或否定他们的理论。 科学方法：观察、理论和进一步观察在经济学研究中，进行实验往往是不可能的。通常不得不使用这个世界向他们提供的数据。为了寻找实验室实验的替代品，经济学家十分关注历史所提供的自然实验。 假设的作用当我们在研究政策变动在长短不同时间中的影响时，就会做出不同的假设。 经济模型经济学家也用模型来了解世界，但不是塑料模型，而通常是由图形和方程组成的模型。 第一个模型：循环流量图 循环流量图(circular-flow diagram):一个说明货币如何通过市场在家庭与企业之间流动的直观经济模型 生产要素(production factors):劳动、土地、资本等投入品被称为生产要素 企业用生产要素来生产产品和服务，家庭则拥有生产要素并消费企业生产的物品与服务。家庭与企业之间相互交易。 第二个模型：生产可能性边界 生产可能性边界(production possibilities frontier)：表示在可得到的生产要素与生产技术既定时，一个经济所能生产的产品数量的各种组合的图形。 由于资源是稀缺的因此并不是每一种想象的结果都是可行的。生产可能性边界表明了社会所面临的一种权衡取舍。 生产可能性边界表明在某一特定时期内生产不同物品之间的权衡取舍，但随着时间的推移，这种权衡取舍可以改变。生产可能性边界简化了复杂的经济，以便强调一些基本但极为重要的思想： 稀缺性、效率、权衡取舍、机会成本和经济增长。 微观经济学与宏观经济学尽管微观经济学和宏观经济学之间存在固有的联系，但这两个领域仍然是不同的。 微观经济学(micro economics)：研究家庭和企业如何做出决策，以及它们如何在市场上相互交易的学科。 宏观经济学(macro economics)：研究整体经济现象，包括通货膨胀、失业和经济增长的学科。 作为政策顾问的经济学家当经济学家试图去解释世界时，他们是科学家；当经济学家试图去帮助改变世界时，他们是政策顾问。 实证分析与规范分析一般来说，关于世界的表述有两种类型： 实证表述(positive statements)：试图描述世界是什么样子的观点。 规范表述(normative statements)：试图描述世界应该是什么样子的观点。 确定什么是好策略或什么是坏策略不仅仅是一个科学问题，它还涉及我们对伦理、宗教和政治哲学的看法。 经济学家意见分歧有两个基本原因： 经济学家可能对世界如何运行的不同实证理论的正确性看法不一致 经济学家可能有不同的价值观，因此对政策应该努力实现的目标有不同的规范观点 相互依存性与贸易的好处人们向你和其他消费者提供他们生产的物品与服务，是因为他们也得到了某种回报。 一个现代经济寓言每个人都可以通过专门从事自己最擅长的活动并从相互叫中获益。但是，当某个人在生产每一种物品上都较为擅长时，贸易的好处就不那么明显了。 生产可能性专业化和贸易 比较优势： 专业化的动力绝对优势 绝对优势(absolute advantage)：一个生产者用比另一个生产者更少的投入生产某种物品的能力。 机会成本与比较优势 机会成本(opportunity cost)：为了得到某种东西所必须放弃的东西。 比较优势(comparative advantage)：一个生产者以低于另一个生产者的机会成本生产某种物品的能力。 尽管一个人有可能在两种物品的生产上都具有绝对优势，但一个人却不可能在两种物品的生产上都具有比较优势。 比较优势与贸易专业化和贸易的好处不是基于绝对优势，而是基于比较优势。当每个人专门生产自己有比较优势的物品时，经济的总产量就增加了，经济蛋糕的变大可用于改善每个人的状况。 贸易可以使社会上的每个人都获益，因为它使人们可以专门从事他们具有比较优势的活动。 贸易的价格对从贸易中获益的双方而言，他们进行贸易的价格在两种机会成本之间。 比较优势的应用美国应该与其他国家进行贸易吗 进口品(imports)：在国外生产而在国内销售的物品。 出口品(exports)：在国内生产而在国外销售的物品。 每个国家都有许多具有不同利益的居民。即使国际贸易可以使国家作为一个整体的状况变好，但也会使一些人的状况变坏。但国际贸易并不像战争，在战争中有些国家是胜利者，而其他国家是失败者。贸易使所有国家都可以实现更大的繁荣。 市场如何运行 供给与需求的市场力量供给与需求是经济学家最经常——而且有充分的理由使用的两个词。供给与需求是使市场经济运行的力量。它们决定了每种物品的产量及其出售的价格。 市场与竞争 市场(market)：由某种物品或服务的买者与卖者组成的一个群体。 竞争市场(competitive market)：有许多买者与卖者，以至于每个人对市场价格的影响都微乎其微的市场。 我们假设市场是完全竞争的。为了达到此竞争的最高形式，一个市场必须具备两个特征： 可供销售的物品时完全相同的 买者与卖者人数众多，以至于没有任何一个买者或卖者可以影响市场价格 但是，并不是所有物品与服务都在完全竞争市场上出售。一些市场可能只有一个买者，而且这个卖者决定价格。这样的卖者被称为垄断者还有一些市场介于完全竞争和垄断这两种极端形式之间。 需求 价格与需求量之间的关系 需求量(quantity demanded)：买者愿意斌企鹅能够购买的一种物品的数量。 需求定理(law of demand)：认为在其他条件不变时，一种物品的价格上升，对该物品的需求量减少的观点。 需求表(demand schedule)：表示一种物品的价格与需求之间的关系的表格。 需求曲线(demand curve)：表示一种物品的价格与需求量之间关系的图形。 正常物品(normal good)：在其他条件相同时，收入增加引起需求量增加的物品。 低档物品(inferior good)：在其他条件相同时，收入增加引起需求量减少的物品。 替代品(substitutes)：一种物品价格的上升引起另一种物品需求量的增加的两种物品。 互补品(complements)：一种物品价格的上升引起另一种物品需求量的减少的两种物品。 影响买者的变量： 收入 价格 爱好 预期 其它 供给 价格与供给量之间的关系 供给量(quantity supplied)：卖者愿意并且能够出售的一种物品的数量。 供给定理(law of supply)：认为在其他条件不变时，一种物品的价格上升，该物品的供给量增加的观点。 供给表(supply schedule)：表示一种物品的价格与供给量之间的关系的表格。 供给曲线(supply curve)：表示一种物品的价格与供给量之间关系的图形。 使供给曲线移动的一些变量： 价格 技术 预期 卖者的数量 其它 供给与需求的结合 均衡(equilibrium)：市场价格达到使供给量与需求量相等的水平时的状态。 均衡价格(equilibrium price)：使供给与需求平衡的价格。 均衡数量(equilibrium quantity)：均衡价格下的供给量与需求量。 过剩(surplus)：供给量大于需求量的状态。 短缺(shortage)：需求量大于供给量的状态。 供求定力(law of supply and demand)：认为任何一种物品的价格都会自发调整，使该物品的供给与需求达到平衡的观点。 价格如何配置资源在市场经济中，价格是配置稀缺资源的机制。 弹性假设某件事情使得汽油价格上升，那么消费者将少买汽油。那么汽油的消费量会减少多少呢？——这个问题可以用弹性的概念来回答。 需求弹性 弹性(elasticity)：衡量需求量或供给量对某种决定因素的变动的反应程度的指标。 需求价格弹性(price elasticity of demand)：衡量一种物品需求量对其价格变动反应程度的指标，用需求量变动百分比除以价格变动百分比来计算。 总收益(total revenue)：一种物品的买者支付而卖者得到的量，用该物品的价格乘以销售量来计算。 需求收入弹性(income elasticity of demand)：衡量一种物品需求量对消费者收入变动反应程度的指标，用需求量变动百分比除以收入变动百分比来计算。 需求交叉价格弹性(cross-price elasticity of demand)：衡量一种物品需求量对另一种物品价格变动的反应程度的指标，用第一种物品需求量变动百分比除以第二种物品价格变动百分比来计算。 富有弹性 缺乏弹性 单位弹性 完全无弹性 完全有弹性 替代品 必需品 奢侈品 市场的定义 时间范围 供给弹性 供给价格弹性(price elasticity of supply)：衡量一种物品供给量对其价格变动反应程度的指标，用供给量变动百分比除以价格变动百分比来计算。 供给、需求和弹性的应用 农业的好消息可能对农民来说是坏消息吗 为什么石油输出国组织不能保持石油的高价格 禁毒增加了还是减少了毒品相关的犯罪 供给、需求与政府政策当决策者认为一种物品或服务的市场价格对买者或卖者不公平时，通常会实施价格控制。但这些控制政策本身也会引起不公平。决策者用税收为公共目标筹集资金并影响市场结果。 价格控制 价格上限(price ceiling)：出售一种物品的法定最高价格 价格下限(price floor)：出售一种物品的法定最低价格 由于任何一种物品的买者总希望价格更低，而卖者总希望价格更高。所以，这两个群体的利益就会产生冲突 当政府对竞争市场实行限制性价格上限时，就产生了物品的短缺，而且，卖者必须在大量潜在买者中配给稀缺物品。与此相比，一个自由竞争市场中的配给机制既有效率又是客观的。 价格有平衡供求从而协调经济活动的关键作用。当决策者通过法令确定价格时，他们就模糊了正常情况下指引社会资源配置的信号。 价格控制的目标往往是帮助穷人。但价格控制往往损害了那些它本想要帮助的人。可以用除了控制价格以外的其他方法来帮助那些需要帮助的人(如补贴或减税)。但是，税收也是有成本的。 税收 税收归附(塔下 incidence)：税收负担在市场参与者之间进行分配的方式。 当政府对一种物品征税时，谁实际承担了税收负担？无论税收是向买者征税还是想卖者征税，这一买者价格与卖者价格之间的楔子都是相同的。在这两种情况下，这个楔子都使供给曲线和需求曲线的相对位置移动。在新均衡时，都是买者与卖者分摊税收负担。无论向谁征税，一旦市场达到新均衡，都是买者与卖者分摊税收负担。 经济受两种规则体系支配： 供求规律和政府制定的法规。 市场和福利消费者、生产者与市场效率买者总想少付些钱，而卖者总想多买些钱。 福利经济学(welfare economics)研究资源配置如何影响经济福利的一门学问。 消费者剩余 支付意愿(willingness to pay)买者愿意为某种物品支付的最高量。 消费者剩余(consumer surplus)买者愿意为一种物品支付的量减去其为此实际支付的量。 生产者剩余 成本(cost)卖者为了生产一种物品而必须放弃的所有东西的价值。 生产者剩余(producer surplus)卖者出售一种物品得到的量减去其生产成本。 市场效率 总剩余消费者剩余和生产者剩余的总和，称为总剩余。 效率(efficiency)资源配置使社会所有成员得到的总剩余最大化的性质。 平等(equality)在社会成员中平均地分配经济成果的性质。 市场势力影响价格的能力，如市场上一小群能够控制市场价格的买卖者。 外部性市场的副作用，如污染。 在本质上，从市场贸易中获取的利益就像一块要在市场参与者间分配的蛋糕。效率问题涉及的是蛋糕是否尽可能地做大了。平等问题涉及的是如何把这块蛋糕切成小块，以及如何在社会成员中进行分配。 市场失灵是指一些不受管制的市场不能有效地配置资源。当出现市场失灵时，公共政策有可能纠正这些问题并提高经济效率。 赋税的代价买者和买者因税收遭受的损失大于政府筹集到的收入。 赋税的无谓损失 无谓损失(deadweight loss)市场扭曲(如税收)引起的总剩余减少。 税收引起的无谓损失是因为它使买者和卖者不能实现某些贸易的好处。 决定无谓损失的因素供给和需求的价格弹性越大，税收的无谓损失也就越大。 税收变动时无谓损失和税收收入税收很少长期保持不变。 当政府对一种商品的买者或卖者征税时，社会就损失了某些市场效率的好处。税收给市场参与者带来了损失，不仅是因为税收将资源从市场参与者手中转到政府手中，还因为税收改变了激励，并扭曲了市场结果。 国际贸易许多企业发现，由于面临可以以低成本生产高质量物品的外国竞争者，要通过生产某种产品获得利润已经越来越困难了。因此，他们迁移或关闭了工厂。 决定贸易的因素 世界价格(world price)一种物品在世界市场上通行的价格。 如果某种物品的世界价格高于国内价格，那么，一旦允许贸易，此国就会变成此物品出口国；反之，则变为此物进口国。各国之间的贸易最终要建立在比较优势的基础之上。 贸易的赢家与输家 关税(tariff)对在国外生产而在国内销售的物品征收的一种税。 当一国允许贸易并成为一种物品的出口国时，国内该物品的生产者的状况变好了，而国内该物品消费者的状况变坏了。 从赢家收益超过了输家损失的意义上说，贸易使一国的经济福利增加了。 当一国允许贸易并成为一种物品的进口国时，国内该物品消费者的状况变好了，而国内该物品生产者的状况变坏了。 从赢家收益超过了输家损失的意义上说，贸易使一国的经济福利增加了。 国际贸易的其它好处： 增加了物品的多样性 通过规模经济降低了成本 增加了竞争 加强了思想交流 关税减少了进口量，并使国内市场向没有贸易时的均衡移动 各种限制贸易的观点 工作岗位论贸易反对者会说，与其他国家进行贸易消灭了国内的一些工作岗位。但自由贸易在消灭了一些工作岗位的同时，也创造了一些工作岗位。 国家安全论一些行业收到来自其他国家的竞争威胁时，贸易反对者会说，该行业对国家安全是至关重要的。处于对国家安全的合理考虑，保护关键行业可能是合理的。但也应该由国家机构所提出。 幼稚产业论会说，应实行暂时性贸易限制，以有助于该产业的成长。这也难以实施。如何确定哪个产业是新兴的幼稚产业？ 不公平竞争论一种常见的观点是，如果不同国家的企业服从于不同的法律和管制，那么，让企业在国际市场上进行竞争就是不公平的。 作为讨价还价筹码的保护论当与自己的贸易伙伴讨价还价时，贸易限制可能还是有用的。 大多数经济学家支持自由的国际贸易，他们认为自由贸易是一种有效配置生产的方法，并提高了两国的生活水平。 公共部门经济学 外部性 外部性(externality)一个人的行为对旁观者福利的无补偿的影响 正外部性这种影响是有利的 负外部性这种影响是不利的 栗子： 汽车尾气 修复历史建筑 狂吠的狗 新技术的研究 外部性和市场无效率 外部性内在化(internalizing the externality)改变激励，以使人们考虑到自己行为的外部效应 政府可以通过对负外部性的物品征税和给予有正外部性的物品补贴来使外部性内在化 针对外部性的公共政策 管制政府可以通过规定或禁止某些行为来解决外部性。 矫正税旨在引导私人决策者考虑负外部性引起的社会成本的税收 补贴 可交易的污染许可证 外部性的私人解决方法 科斯定理(Coase theorem)认为如果私人各方面可以无成本地就资源配置进行协商，那么，他们就可以自己解决外部性问题的观点 交易成本(transaction cost)各方在达成协议与遵守协议过程中所发生的成本 公共物品和公共资源 不同类型的物品 排他性(excludability)一种物品具有的可以阻止一个人使用该物品的特性 消费品中的竞争性(rivalry in consumption)一个人使用一种物品将减少其他人对该物品的使用的特性 私人物品(private goods)既有排他性又有消费竞争性的物品 公共物品(public goods)即无排他性又无消费竞争性的物品 公共资源(common resources)有消费竞争性但无排他性的物品 俱乐部物品(club goods)有排他性但无消费竞争性的物品 公共物品产权的重要性 搭便车者(free rider)得到一种物品的利益但避免为此付费的人 一些重要的公共物品 国防 基础研究 反贫困 成本收益分析(cost-benefit analysis)比较提供一种公共物品的社会成本与社会收益的研究 公共资源 公共悲剧(Tragedy of the Commons)一个说明从整个社会的角度看，为什么公共资源的使用大于合意的水平的寓言 一些重要的公共资源 清洁的空气和水 拥堵的道路 野生动物 税制的设计在这个世界上除了死亡和税收以外，没有什么事情是确定无疑的。 政府的财政状况政府的税收占国民收入的多少？ 预算赤字(budget deficit)政府支出大于政府收入 预算盈余(budget surplus)政府收入大于政府支出 税收和效率税收会引起两个成本，良好的税收政策正是要使其最小化： 当税收扭曲了人们做出的决策时引起的无谓损失 纳税人在遵照税法纳税时承担的管理负担 收入税 消费税 平均税率(average tax rate)支付的总税收除以总收入 边际税率(marginal tax rate)增加1美元收入所支付的额外税收 定额税(lump-sum tax)对每个人等量征收的税收 税收和平等 受益原则(benefit principle)认为人们应该根据他们从政府服务中得到的利益来纳税的思想 支付能力原则(ability-to-pay principle)认为应该根据一个人可以承当的负担来对这个人征税的思想 纵向平等(vertical equity)主张支付能力更强的纳税人应该缴纳更多税收的思想 横向平等(horizontal equity)主张有相似支付能力的纳税人应该缴纳等量税收的思想 比例税(proportional tax)高收入纳税人和低收入纳税人缴纳收入中相同比例的税收 累进税(progressive tax)高收入纳税人缴纳的税收在收入中的比例高于低收入纳税人的这一比例 累退税(regressive tax)高收入纳税人缴纳的税收在收入中的比例低于低收入纳税人的这一比例 企业行为与产业组织 生产成本经济是由成千上万个生产你每天享用的物品与服务的企业(大型或小型)组成的。 产业组织研究企业有关价格和数量的决策如何取决于它们所面临的市场条件。 企业成本是其生产和定价决策的一个关键决定因素。 生么是成本总收益、总成本和利润 总收益(total revenue)企业出售其产品所得到的货币量 总成本(total cost)企业用于生产的投入品和市场价值 利润(profit)总收益减去总成本 作为机会成本的成本 显性成本(explicit costs)需要企业支出货币的投入成本 隐性成本(implicit costs)不需要企业支出货币的投入成本 作为一种机会成本的资本成本 经济利润与会计利润 经济利润(economic profit)总收益减去总成本，包括显性成本与隐性成本 会计利润(accounting profit)总收益减总显性成本 生产与成本 生产函数 生产函数(production function)用于生产一种物品的投入量与该物品产量之间的关系 边际产量(marginal product)增加一单位投入所引起的产量增加 边际产量递减(diminishing marginal product)一种投入的边际产量随着投入量增加而减少的特征 从生产函数到总成本曲线 成本的各种衡量指标 固定成本与可变成本 固定成本(fixed costs)不随着产量变动而变动的成本 可变成本(variable costs)随着产量变动而变动的成本 平均成本与边际成本 平均总成本(average total cost)总成本除以产量 平均固定成本(average fixed cost)固定成本除以产量 平均可变成本(average variable cost)可变成本除以产量 边际成本(marginal cost)额外一单位产量所引起的总成本的增加 成本曲线及其形状 有效规模(efficient scale)使平均总成本最小的产量 只要边际成本小于平均总成本，平均总成本就下降；反之，则上升。边际成本曲线与平均总成本曲线在平均总成本曲线的最低点处相交。 典型的成本曲线 三个特征： 随着产量增加边际成本最终会上升 平均总成本曲线是U形的 边际成本曲线与平均总成本曲线在平均总成本曲线的最低点处相交 短期成本与长期成本 短期与长期平均总成本之间的关系 规模经济与规模不经济 规模经济(economics of scale)长期平均总成本随产量增加而减少的特性 规模不经济(diseconomics of scale)长期平均总成本随产量增加而增加的特性 规模收益不变(constant returns to scale)长期平均总成本在产量变动时保持不变的特性 实际上，运用专业化实现规模经济是现代社会之所以这样繁荣的原因之一。 竞争市场上的企业如果每个买者和卖者与市场规模相比都微不足道，从而没有什么能力影响市场价格那么该市场就是竞争性的。于此相反，如果一个企业可以影响它出售的物品的市场价格，我们就说该企业有市场势力。 什么是竞争市场 竞争市场的含义 竞争市场(competitive market)有时又称为完全竞争市场。有几个特征： 市场上有许多买者和许多卖者 各个卖者提供的物品大体上是相同的 企业可以自由地进入或退出市场 竞争企业的收益 平均收益(average revenue)总收益除以销售量对所有企业而言，平均收益等于物品的价格 边际收益(marginal revenue)增加一单位销售量引起的总收益变动对竞争企业而言，边际收益等于物品的价格 利润最大化与竞争企业的供给曲线 利润最大化 边际成本曲线和企业的供给决策 利润最大化的一般规律： 如果边际收益大于边际成本，企业应该增加其产量 如果边际成本大于边际效益，企业应该减少其产量 在利润最大化的产量水平时，边际收益和边际成本正好相等 企业的短期停止营业决策 如果生产能得到的收益小于生产的可变成本，企业就停止营业。 覆水难收和其他沉没成本 沉没成本(sunk cost)已经发生而且无法收回的成本 在做个人决策时，沉没成本的无关性也是很重要的。 企业退出或进入一个市场的长期决策 如果从生产中得到的收益小于它的总成本，企业就应该退出市场。竞争企业的长期供给曲线是边际成本曲线位于平均总成本曲线之上的那一部分。 竞争市场的供给曲线两种情况： 考察有固定数量企业的市场； 考察企业数量会随着老企业退出和新企业进入而变动的市场 垄断可以说微软在Windows软件市场上拥有垄断地位。像微软这样的垄断者没有与之相近的竞争者，因此，它拥有影响其产品的市场价格的力量。竞争企业是价格接受者，而垄断企业是价格决定者。 竞争企业接受市场给定的其产品的价格，并选择供给量，以使价格等于边际成本。与此相比，垄断者收取高于其边际成本的价格。 垄断者对其产品收取高价格并不令人奇怪。垄断者的顾客似乎除了一个支付垄断者收取的价格之外别无选择。一个垄断企业可以控制它出售的物品的价格，但由于高价格会减少其顾客的购买量，因此垄断利润并不是无限的。 由于垄断企业不受竞争限制，有垄断的市场结果往往不符合社会的最佳利益。但政府有时可以改善市场结果。 为什么会产生垄断 垄断企业(monopoly)作为一种没有相近替代品的产品的唯一卖者的企业。 有三个主要形成原因： 垄断资源： 生产所需要的关键资源由单个企业所拥有 政府管制： 政府给予单个企业排他性地生产某种物品或服务的权利 生产流程： 某个企业能以低于大量企业的成本生产产品 专利法或版权法是两个重要的例子。 自然垄断(natural monopoly)由于一个企业能以低于两个或更多企业的成本向整个市场供给一种物品或服务而产生的垄断 垄断者如何做出生产与定价策略 垄断与竞争 垄断者的收益 利润最大化 垄断者的利润 垄断的福利代价 无谓损失 可以在需求曲线与边际成本曲线相交之处找出社会有效率的产量。垄断者生产的产量小于社会有效率的产量。 垄断利润：是一种社会代价吗 价格歧视 价格歧视(price discrimination)以不同的价格向不同顾客出售同一种物品的经营做法。 套利在一个市场上以低价购买一种商品，而在另一个市场上以高价出售，以便从价格差中获利的过程。 价格歧视的例子 电影票 飞机票 折扣券 财务援助 数量折扣 针对垄断的公共政策政府决策者应对垄断： 努力使垄断行业更有竞争性用反托拉斯法增强竞争。反托拉斯法是一部全面的经济自由宪章，其目的在于维护作为贸易的自由和不受干预的竞争。 管制管制垄断者的行为 公有制政府自己经营自然垄断的企业 不作为do nothing 垄断竞争 在垄断和完全竞争之间很多行业介于完全竞争和垄断的极端情况之间的某个位置，经济学家称这种情况为不完全竞争。 寡头(oligopoly)只有少数几个提供相似或者相同产品的卖者的市场结构。 垄断竞争(monopolistic competition)存在许多出售相似但不相同的产品的企业的市场结构。 垄断竞争和寡头一样，也是介于竞争和垄断这两种极端情况之间的一种市场结构。 垄断竞争具有以下特征的市场： 许多卖者： 有许多企业争夺相同的顾客群体 产品存在差别： 每个企业生产的一种产品至少与其他企业生产的这种产品略有不同 自由进入和退出：企业可以无限制地进入或退出一个市场 差别产品的竞争 短期中的垄断竞争企业 长期均衡 垄断竞争与完全竞争 垄断竞争与社会福利 广告在现代经济中，几乎每一天都伴随着铺天盖地的广告。这种行为是垄断竞争(以及某些寡头企业)的一个自然特征。 关于广告的争论 作为质量信号的广告 品牌 垄断竞争，顾名思义，是垄断和竞争的混合。由于垄断竞争企业生产有差别的产品，因此，每个企业都要靠做广告打出自己的品牌来吸引顾客。在某种程度上，广告操纵了消费者的偏好，促成了非理性的品牌忠诚，并抑制了竞争。在更大程度上，广告提供了信息，建立了具有可靠质量的品牌，并促进了竞争。 寡头]]></content>
      <categories>
        <category>Economics</category>
      </categories>
      <tags>
        <tag>Zhang</tag>
        <tag>Economics</tag>
        <tag>经济学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2F2018%2F02%2F08%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[参考： 《鸟哥的Linux私房菜》 正则表达式维基百科 正则表达式介绍正则表达式，又称正规表示式、正规表示法、正规表达式、规则表达式、常规表示法(Regular Expression, 在代码中常简写为regex、regexp或RE）。是计算机科学的一个概念。正则表达式使用单个字符串来描述、匹配一系列匹配某个句法规则的字符串。在很多文本编辑器里，正则表达式通常被用来检索、替换那些匹配某个模式的文本。 正则表达式的POSIX规范，分为两大流派： 基本型正则表达式（Basic Regular Expression，BRE） grep、vi、sed都属于BRE，是历史最早的正则表达式，因此元字符必须转译之后才具有特殊含义 扩展型正则表达式（Extended Regular Express，ERE） egrep、awk则属于ERE，元字符不用转译 正则表达式基本语法一个正则表达式通常被称为一个模式（pattern），用来描述或者匹配一系列匹配某个句法规则的字符串。 大部分正则表达式有如下结构： 选择 |竖线符代表选择(或)，具有最低优先级 数量限定 字符后的数量限定符用来限定前面这个字符允许出现的个数 不加数量限定则代表仅出现一次 常见的数量限定符包括 +、?、* +加号代表前面的字符必须至少出现一次 ( $$$&gt;=1$$$ ) ?问号代表前面的字符最多只可出现一次 ( $$$1&gt;=?&gt;=0$$$ ) *星号代表前面的字符可不出现，也可出现一次或多次 ($$$&gt;=0$$$) 匹配 ()圆括号可以定义操作符的范围和优先度 PCRE表达式全集正则表达式有多种不同的风格。PCRE（Perl兼容正则表达式，Perl Compatible Regular Expression）。适用于Perl或者Python编程语言（grep或者egrep的正则表达式文法是PCRE的子集） 基础正则表达式 字符 描述 \ 转义字符 zhang 匹配文本字符串值zhang . 匹配除\r,\n之外的任何单个字符 竖线l 匹配竖线两边某一个 ^ 匹配输入字符串的开始位置 $ 匹配输入字符串的结束位置 * 匹配前面的子表达式零次或多次 + 匹配前面的子表达式一次或多次 ? 匹配前面的子表达式零次或一次 {n} n是一个非负整数。匹配n次 {n,} n是一个非负整数。至少匹配n次 {n,m} m和n均为非负整数，匹配n-m次 [xyz] 字符集合（character class）。匹配所包含的任意一个字符 [^xyz] 排除型字符集合（negated character classes）。匹配未列出的任意字符 [a-z] 字符范围。匹配指定范围内的任意字符 [^a-z] 排除型的字符范围。匹配任何不在指定范围内的任意字符 [:name:] 增加命名字符类（named character class） [=elt=] 增加当前locale下排序（collate）等价于字符“elt”的元素 [.elt.] 增加排序元素（collation element）elt到表达式中。这是因为某些排序元素由多个字符组成 元字符元字符(meta character)，是一种Perl风格的正则表达式，只有一部分文本处理工具支持它。 字符 描述 \b 匹配一个单词边界，也就是指单词和空格间的位置 \B 匹配非单词边界。“er\B”能匹配“verb”中的“er”，但不能匹配“never”中的“er” \cx 匹配由x指明的控制字符 \d 匹配一个数字字符。等价于[0-9]。注意Unicode正则表达式会匹配全角数字字符 \D 匹配一个非数字字符。等价于[^0-9] \f 匹配一个换页符。等价于\x0c和\cL \n 匹配一个换行符。等价于\x0a和\cJ \r 匹配一个回车符。等价于\x0d和\cM \s 匹配任何空白字符，包括空格、制表符、换页符等等 \S 匹配任何非空白字符。等价于[^ \f\n\r\t\v] \t 匹配一个制表符。等价于\x09和\cI \v 匹配一个垂直制表符。等价于\x0b和\cK \w 匹配包括下划线的任何单词字符。等价于“[A-Za-z0-9_]”。注意Unicode正则表达式会匹配中文字符 \W 匹配任何非单词字符。等价于“[^A-Za-z0-9_]” \ck 匹配控制转义字符。k代表一个字符。等价于“Ctrl-k”。用于ECMA语法 \xnn 十六进制转义字符序列。匹配两个十六进制数字nn表示的字符 \num 向后引用（back-reference）一个子字符串（substring），该子字符串与正则表达式的第num个用括号围起来的捕捉群（capture group）子表达式（subexpression）匹配。其中num是从1开始的十进制正整数，其上限可能是9[注 2]、31、[注 3]99甚至无限。[注 4]例如：“(.)\1”匹配两个连续的相同字符 \n 标识一个八进制转义值或一个向后引用。如果\n之前至少n个获取的子表达式，则n为向后引用。否则，如果n为八进制数字（0-7），则n为一个八进制转义值 \nm 3位八进制数字，标识一个八进制转义值或一个向后引用。如果\nm之前至少有nm个获得子表达式，则nm为向后引用。如果\nm之前至少有n个获取，则n为一个后跟文字m的向后引用。如果前面的条件都不满足，若n和m均为八进制数字（0-7），则\nm将匹配八进制转义值nm \nml 如果n为八进制数字（0-3），且m和l均为八进制数字（0-7），则匹配八进制转义值nml \un Unicode转义字符序列。其中n是一个用四个十六进制数字表示的Unicode字符 扩展正则表达式 字符 描述 ? 非贪心量化（Non-greedy quantifiers）：当该字符紧跟在任何一个其他重复修饰符（*,+,?，{n}，{n,}，{n,m}）后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串 (pattern) 匹配pattern并获取这一匹配的子字符串。该子字符串用于向后引用。所获取的匹配可以从产生的Matches集合得到，在VBScript中使用SubMatches集合，在JScript中则使用$0…$9属性。要匹配圆括号字符，请使用“(”或“)” (?:pattern) 匹配pattern但不获取匹配的子字符串（shy groups)，也就是说这是一个非获取匹配，不存储匹配的子字符串用于向后引用 (?=pattern) 正向肯定预查（look ahead positive assert），在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用 (?!pattern) 正向否定预查(negative assert)，在任何不匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用 (?&lt;=pattern) 反向(look behind)肯定预查，与正向肯定预查类似，只是方向相反 (?&lt;!pattern) 反向否定预查，与正向否定预查类似，只是方向相反 POSIX字符组POSIX字符类(POSIX character class),是一个形如[:…:]的特殊元序列，它用于匹配特定的字符范围。 POSIX字符组 说明 ASCII环境 Unicode环境 [:alnum:] 字母字符和数字字符 [a-zA-Z0-9] [\p{L&amp;}\p{Nd}] [:alpha:] 字母 [a-zA-Z] \p{L&amp;} [:ascii:] ASCII字符 [\x00-\x7F] \p{InBasicLatin} [:blank:] 空格字符和制表符 [ \t] [\p{Zs}\t] [:cntrl:] 控制字符 [\x00-\x1F\x7F] \p{Cc} [:digit:] 数字字符 [0-9] \p{Nd} [:graph:] 空白字符之外的字符 [\x21-\x7E] [^\p{Z}\p{C}] [:lower:] 小写字母字符 [a-z] \p{Ll} [:print:] 类似[:graph:]，但包括空白字符 [\x20-\x7E] \P{C} [:punct:] 标点符号 }~-] [\p{P}\p{S}] [:space:] 空白字符 [ \t\r\n\v\f] [\p{Z}\t\r\n\v\f] [:upper:] 大写字母字符 [A-Z] \p{Lu} [:word:] 字母字符 [A-Za-z0-9_] [\p{L}\p{N}\p{Pc}] [:xdigit:] 十六进制字符 [A-Fa-f0-9] [A-Fa-f0-9] 优先级 优先权 符号 最高 \ 高 ( )、(?: )、(?= )、[ ] 中 *、+、?、{n}、{n,}、{m,n} 低 ^、$、中介字符 次最低 串接，即相邻字符连接在一起 最低 l]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>RegularExpression</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis]]></title>
    <url>%2F2018%2F02%2F05%2FRedis%2F</url>
    <content type="text"><![CDATA[参考: 《Redis官方文档》: http://www.redis.cn/documentation.html 《Redis命令大全》: http://www.redis.cn/commands.html 环境: CentOS7x86_64 Redis 3.2 简介 Redis是什么Redis是一个使用ANSI C编写的开源、支持网络、基于内存、可选持久性的、非关系型,键值对存储数据库。Redis是一个开源(BSD许可)的,内存中的数据结构存储系统,它可以用作数据库、缓存和消息中间件。 毫无疑问,Redis开创了一种新的数据存储思路,使用Redis,我们不用在面对功能单调的数据库时,把精力放在如何把大象放进冰箱这样的问题上,而是利用Redis灵活多变的数据结构和数据操作,为不同的大象构建不同的冰箱。希望你喜欢这个比喻。 Remote Dictionary Server(Redis)是由一个Salvatore Sanfilippo写的key-value储存系统。Redis提供了一些丰富的数据结构,包括lists,sets,ordered sets,hashes,当然还有和Memcached一样的string结构,所以常被称为是一款数据结构服务器(data structure server)。Redis当然还包括了对这些数据结构的丰富操作。 你可以在这些类型上面运行原子操作,例如,追加字符串,增加哈希中的值,加入一个元素到列表,计算集合的交集、并集和差集,或者是从有序集合中获取最高排名的元素。 Redis的优点为了满足性能,Redis采用内存(in-memory)数据集(dataset)。根据你的使用场景,你可以通过每隔一段时间转储数据集到磁盘,或者追加每条命令到日志来持久化。持久化也可以被禁用,如果你只是需要一个功能丰富,网络化的内存缓存。 性能极高,Redis能支持超过100K+每秒的读写频率 丰富的数据类型,Redis支持二进制案例的Strings,Lists,Hashes,Sets及Ordered Sets数据类型操作 原子,Redis的所有操作都是原子性的,同时Redis还支持对几个操作全并后的原子性执行 丰富的特性,Redis还支持publish/sucscribe,通知,key过期等特性 Redis还支持主从异步复制,非常快的非阻塞初次同步、网络断开时自动重连局部重同步 安装直接通过yum安装: 1yum install -y redis 启动redis-server的两种方式: redis-server: standalone模式 systemctl redis start: daemon模式 需要在配置文件中开启daemonize 启动redis-cli: 12redis-cliredis-cli -a passwd 配置redis配置文件(/etc/redis.conf)常用参数: 参数 说明 daemonize 以守护进程启动,放置于后台 bind 监听地址,建议只对本地127.0.0.1开放 protect-mode redis的保护模式 requirepass 设置密码 timeout 超时 tcp-keepalive 在Linux上,指定值(秒)用于发送ACKs的时间,关闭连接需要双倍的时间,默认为0 loglevle 指定日志记录的级别。有四个级别:debug(记录很多信息,用于开发测试)、notice(常用于生产环境)、warning(严重的信息)、verbose(有用的信息) logfile 日志文件,默认为stdout databases 可用数据库,范围在0-(database-1) save 保存数据到磁盘(.rdb) stop-writes-on-bgsave-error 后台储存错误停止写 rdbcompression 储存到本地数据库时(持久化到rdb文件)是否压缩 dbfilename 本地持久化数据库文件名,默认dump.rdb dir 数据库文件路径,是目录 salveof 设置从库 masterauth 设置主库认证的密码 slave-read-only 设置slave是否只读 slave-serve-stale-data 从库同主库失去连接或复制正在进行时,从库是否继续响应客户端请求 repl-disable-tcp-nodelay tcp-nodelay slave-priority slave优先级,master不能工作后,从众多slave中选出优先值最小的slave提升为master,优先值为0表示不能为master appendonly 是否开启AOF数据备份,redis会把所接收到的每一次写操作请求都追加到appendonly.aof文件,当此文件很大 appendsync AOF文件同步策略,后台会进行大量I/O no-appendfsync-on-rewrite - auto-aof-rewrite-percentage aof自动重写 auto-aof-rewrite-min-size 指定最小大小用于aof重写 slowlog-log-slower-than 慢日志,记录超过特定执行时间的命令,不包括I/o slowlog-max-len 慢日志记录的长度,超过大小,最先进入队列的记录会被踢出 hash-max-zipmap-entries hash将以一种特殊的编码方式(大大减少内存使用)来储存,这是其中一个临界值 hash-max-zipmap-value 另一个临界值 list-max-ziplist-entries 多个list以特定的方式编码来节省空间 activerehashing Redis将在每100ms时使用1ms的CPU时间来对redis的hash表进行重新hash,可降低内存的使用 hz 不是所有任务都以相同的频率执行,但redis按照指定的“hz”值执行检查任务 aof-rewrite-incremental-fsync 当一个子节点重写AOF文件时,则文件每生产32m数据进行同步 官方文档对VM的使用建议: 当KEY很小而VALUE很大时,使用VM的效果会比较好,因为这样节约内存比较大 当key不小时,可以考虑使用一些非常方法将很大的key变成value,比如将key,value组合成一个新的value 数据类型Redis不仅仅是简单的key-value存储器,同时也是一种data structure server。传统的key-value是指支持使用一个key字符串来索引value字符串的储存。而Redis中,value不仅仅支持字符串,还支持更多的复杂结构,包括列表、集合、哈希表等。Redis采用二进制安全,这就意味着你可以使用任何二进制序列作为重点。 字符串(strings)字符串 是一种最基本的Redis值类型。Redis字符串是二进制安全的,这意味着一个Redis字符串能包含任意类型的数据。 只关心二进制化的字符串,不关心具体格式。只会严格的按照二进制的数据存取。不会妄图已某种特殊格式解析数据。 列表(lists)Redis列表是简单的字符串列表,按照插入顺序序列,你可以添加一个或多个元素到列表的头部或者尾部。 散列(hash)Redis Hashes是字符串字段和字符串值之间的映射,因此他们是展现对象的完美数据类型。如一个有姓、名、年龄等属性的用户。一个带有一些字段的hash仅仅需要一块很小的空间储存,因此你可以储存数以百万计的对象在一个小的Redis实例中。 哈希主要用来表现对象,他们有能力储存很多对象,因此你可以将哈希用于许多其他的任务。 无序集合(unorder set)Redis集合(Set)是一个无序的字符串集合。可以用O(1)的时间复杂度(无论集合中有多少元素时间复杂度都是常量)完成添加、删除、测试元素是否存在。 Redis集合拥有令人满意的不允许包含相同成员的属性。多次添加相同的元素,最终在集合里只会有一个元素。实际上就是添加元素时无序检测元素是否存在。 一个Redis集合有趣的事情是它支持一些服务端的命令从现有的集合出发去进行集合运算,因此你可以在非常短的时间内进行合并(unions)、交集(intersections)、找出不同的元素(difference of sets)。 有序集合(order set)Redis有序集合与普通集合非常相似,也是一个没有重复项的字符串集合。不同之处是有序集合的每一个成员都关联了一个评分,这个评分被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的,但是评分可以是重复了。 使用有序集合可以以非常快的速度(O(log(N)))添加,删除和更新元素。可以很快根据评分(score)或者次序(position)来获取一个范围的元素。访问有序集合的中间元素也是很快的,因此能够使用有序集合作为一个没有重复成员的智能列表。在有序集合中,你可以很快捷的访问一切你需要的东西。 简而言之,使用有序的集合你可以做完许多对性能有极端要求的任务,而那些任务使用其他类型的数据库真的是很难完成。 命令 常用命令123456789101112131415161718192021exists key #判断一个key是否存在del key #删除某个或一系列keytype key #返回某个key元素的数据类型,key不存在返回空keys key-pattern #返回匹配的key列表randomkey #随机获取一个已经存在的keyrename oldname newname #改key的名字,如果存在将会覆盖dbsize #返回当前数据库的key的总和expire key time #设置某个key的过期时间(秒),到期后自动删除ttl #查询key剩余存活时间flushdb #清空当前数据库中的所有键flushall #清空所有数据库中的键 设置相关12345config get #用来读取Redis服务器的配置参数config set #用于更改运行Redis服务器的配置参数config resetstat #重置数据统计报告,通常返回OK 连接操作12345quit #关闭连接auth #密码认证help command #帮助 持久化1234567save #将数据同步保存到磁盘bgsave #将数据异步保存到磁盘lastsave #返回上次成功将数据保存到磁盘的Unix时戳 远程服务1234567891011121314151617181920212223242526272829info #服务器信息统计,基本所有信息monitor #实时转储收到的请求slaveof #改变复制策略shutdown #将数据同步保存到磁盘,然后关闭服务server #Redis server的常规信息clients #Client的连接选项memory #存储占用相关信息persistence #RDB and AOF 相关信息stats #常规统计replication #Master/slave请求信息cpu #CPU占用信息统计cluster #Redis 集群信息keyspace #数据库信息统计all #返回所有信息default #返回常规设置信息 值(value)操作12345678910111213141516171819202122232425exists key #判断一个key是否存在del key #删除一个keytype key #返回值的类型keys pattern #返回满足给定模式的所有keyrandomkey #随机返回key空间的一个rename oldname newname #改key的名字,如果存在将会覆盖dbsize #返回当前数据库中key的数目expire #设定一个key的活动时间(s)ttl #获得一个key的活动时间select index #按索引查询move key dbindex #移动当前数据库中的key到dbindex数据库flushdb #删除当前选择的数据库中的所有keyflushall #删除所有数据库中的所有key 字符串(string)操作123456789101112131415161718192021222324252627set key value #给数据库中名称为key的string赋值valueget key #返回数据库中名为key的string的valuegetset key value #给名称为key的string赋予上一次的valuemget key1 key2 ... key N #返回库中多个string的valuesetnx key value #添加string 名称为key 值为valuesetex key time value #向库中添加string 设定过期时间timemset key 1 value 1 ... key N value N #批量设置多个string的值msetnx key 1 value 1 ... key N value N #如果所有名称为 key N的string都不存在 则向库中添加string 名称为 key N赋值value Nincr key #名称为key的string加 1 操作incrby key integer #名称为key的string增减integerdecr key #名称为key的string减1操作decrby key integer #名称为key的string的值附加valueappend key value #名称为key的值附加valuesubstr key start end #返回名称为key的string的value的子串 列表(list)操作12345678910111213141516171819rpush key value #在名称为key的list尾部添加一个值为value的元素lpush key value #在名称为key的list首部添加一个值为value的元素llen key #返回名称为key的list的长度lrange key start end #返回名称为key的list中start至end之间的元素 下表从0开始ltrim key start end #截取名称为key的list 保留start至end之间的元素lindex key index #返回名称为key的list中index位置的元素lset key index value #给名称为key的list中index位置的元素赋值valuelrem key count value #删除count个名称为key的list中值为value的元素brpop key1 key2 ... keyN #rpop的block版本rpoplpush srckey dstkey #返回并删除名为srckey的list尾元素 并将该元素添加到名为dstkey的list的头部 集合(set)操作123456789101112131415161718192021222324252627sadd key member #向名为key的set中添加元素membersrem key member #删除名为key的set中元素的memberspop key #随机返回并删除名为key的set中的一个元素smove srckey dstkey member #将member元素从名为srckey的集合移动到名为dstkey的集合scard key #返回名为key的set的基数sismember key member #测试member是否是名称为key的set的集合sinter key1 key2 ... key N #求交集sinterstore dstkey key1 ... key N #求交集并将交集保存到dstkey的集合sunion key1 ... key N #求并集sunionstore dstkey key 1 ... key N #求并集并将并集保存到dstkey的集合sdiff key1 ... key N #求差集sdiffstore dstkey key 1 ... key N #求差集并将差集保存到dstkey的集合smembers key #返回名为key的set的所有元素srandmember key #随机返回名为key的set的一个元素 有序集合(sorted set)操作12345678910111213141516zadd key score member #向名为key的zset中添加元素member score用于排序 如果该元素已经存在 则根据score更新该元素的顺序zrem key member #删除名为key的zset中的元素memberzincrby key increment member #如果在名为key的zset中已经存在元素member 则该元素的score增加increment 否则向集合中添加该元素 其score的值为incrementzrank key member #返回名为key的zset 顺序zrevrank key member #返回名为key的zset 倒序zrange key start end #返回名为key的zset score顺序按index从start到end返回所有元素zrevrange key start end #返回名为key的zset score倒序按index从start到end返回所有元素zrangebyscore key min max #返回名为key的zset中score大于等于min 小于等于max的所有元 hash操作123456789101112131415161718192021hset key field value #向名为key的hash中添加元素filed----valuehget key field #返回名为key的hash中field对应的valuehmset key field1 value1 ... field N value N #向名为key的hash中添加元素field----valuehmget key field1 ... field N #返回名为key的hash中filed对应的valuehincrby key field integer #将名为key的hash中field的value增加integerhexists key field #名为key的hash中是否存在键为field的域hdel key field #删除名为key的hash中键为field的域hlen key #返回名为key的hash中元素个数hkeys key #返回名为key的hash中所有键hvals key #返回名为key的hash中所有键对应的valuehgetall key #返回名为key的hash中所有的键 field 及其对应的value 高级应用Redis高级应用包括安全性设置、主从复制、事务处理、持久化机制和虚拟内存的使用。 安全性由于redis速度相当快，一秒钟可以150K次密码尝试，所以需要设置一个密码强度很强大的密码。 设置密码的两种方法： config set requirepass &quot;passwd&quot;，通过命令设置密码 直接在配置文件中requirepass属性后加上密码 认证登录的两种方式： redis-cli -a passwd redi-cli –&gt; auth passwd 主从复制Redis的主从复制的配置和使用都比较简单。 master server slave server Redis主从复制特点： 一主多从 当master宕机后，优先级值小的那台slave server自动转变为master 主从复制不同阻塞master，在同步数据时master可以继续处理client的请求 提高了系统的可伸缩性 Redis主从复制过程： slave与master建立连接，发送sync同步命令 master会启动一个后台进程，将数据库快照保存到文件中，同时master主进程会开始收集新的写命令并缓存 后台完成保存后，就将此文件发送给slave slave将文件保存在磁盘上 主从复制栗子Redis主从配置，一主多从。注意：由于redis吃内存，可能会由于内存过小而无法正常启动redis，可查看/var/log/message。 配置master： 123456789101112131415161718vim /etc/redis_master.confdaemon yesbind 127.0.0.1 ip1port 6379requirepass fuza_mimaprotect-mode yesdatebases 100logfile /var/log/redis/redis_master.logdir /var/lib/redis_mastermkdir /var/lib/redis_masterchown redis:redis /var/lib/redis_mastersystemctl start redis 配置slave： 123456789101112131415161718192021222324252627282930vim /etc/redis_slave.confdaemon yesbind 127.0.0.1port 6379protect-mode yeslogfile /var/log/redis/redis_slave.logdir /var/lib/redis_slaveslaveof &lt;master-ip&gt; &lt;master-port&gt;masterauth &lt;master-passwd&gt;slave-read-only yesslave-priority 100#master挂掉后，从slave中选出优先级最小的作为master······#其他具体主从参数自己配置mkdir /var/lib/redis_slavechown redis:redis /var/lib/redis_slavesystemctl start redis 测试master： 1234redis-cli -a xxxset name zhangget zhang 测试slave： 123456redis-cliauth(&apos;passwd&apos;)key *get zhang 注意： 由于Redis只是主从，并不像MongoDB的集群功能。当Redis master挂掉以后，虽然优先级较小的slave成为了master，但从库是无法更新数据的。这点也可以从Redis从的配置文件中看出，连接到Redis主的IP：PORT，并通过主的密码来认证。 高可用Redis的主从模式，并不支持高可用。不过，Redis引进了哨兵模式(sentinel)，提供Redis实时监控和故障检测恢复的功能。Redis Sentinel 是 Redis 的官方高可用解决方案，是设计用来帮助管理 Redis 实例的系统。 运行 Sentinel 强制使用配置文件，这个文件被系统用来保存当前状态，在重启时能重新加载。如果没有指定配置文件，或者配置文件的路径不可写，Sentinel 将拒绝启动。Sentinel 运行时默认监听 TCP 端口 26379，所以为了让 Sentinel 正常运行，你的服务器必须开放 26379 端口，以接受从其他 Sentinel 实例 IP 地址的连接。否则，Sentinel 间就没法通信，没法协调，也不会执行故障转移。 Redis Sentinel 是一个分布式系统，这意味着，你通常想要在你的基础设施中运行多个 Sentinel 进程，这些进程使用 gossip 协议来判断一台主服务器是否下线(down)，使用 agreement 协议来获得授权以执行故障转移，并更新相关配置。 1234The redis-sentinel command is a symbolic link to the redis-server command which imply the --sentionel option.redis-server [ configuration_file ] [ options ] --sentinelredis-sentinel [ configuration_file ] [ options ] Redis Sentinel用于完成如下4个任务： 监控(Monitoring)Sentinel 不断检查你的主从实例是否运转正常。 通知(Notification)Sentinel 可以通过 API 来通知系统管理员，或者其他计算机程序，被监控的Redis实例出了问题。 自动故障转移(Automatic failover)如果一台主服务器运行不正常，Sentinel 会开始一个故障转移过程，将从服务器提升为主服务器，配置其他的从服务器使用新的主服务器，使用 Redis 服务器的应用程序在连接时会收到新的服务器地址通知。 配置提供者(Configuration provider)Sentinel 充当客户端服务发现的权威来源：客户端连接到 Sentinel 来询问某个服务的当前 Redis 主服务器的地址。当故障转移发生时，Sentinel 会报告新地址。 配置文件Redis Sentinel示例配置文件： 只需要指定需要监控的主服务器，并给主服务器去一个名字；没有必要指定从服务器，因为它们会被自动发现；每一次故障转移时，将一台从服务器提升为主服务器都会重写配置文件；无论你指定多少个同意来检测实例是否正常工作，Sentinel 需要系统中已知的大多数 Sentinel 的投票才能开始故障转移，并且在故障转移之后获取一个新的配置纪元(configuration Epoch) 赋予新的配置； 1234567891011121314151617181920212223#默认26379端口#sentinel &lt;option_name&gt; &lt;master_name&gt; &lt;option_value&gt;#仲裁数为2sentinel monitor mymaster 127.0.0.1 6379 2#哨兵认为实例不可达的毫秒数sentinel down-after-milliseconds mymaster 60000#sentinel failover-timeout mymaster 180000#在一次故障转移之后，被配置为同时使用新主服务器的从服务器数量sentinel parallel-syncs mymaster 1# master 有密码就要使用,#sentinel auth-pass mymaster ****sentinel monitor resque 192.168.1.3 6380 4sentinel down-after-milliseconds resque 10000sentinel failover-timeout resque 180000sentinel parallel-syncs resque 5 事务处理Redis的事务处理比较简单。只能保证client发起的事务中的命令可以连续的执行，而且不会插入其他的client命令。 当一个client在连接中发出multi命令时，这个连接就进入一个事务的上下文，该连接后续的命令不会执行，而是存放在一个队列中，当执行exec命令时，redis会顺序的执行队列中的所有命令。如果其中执行出现错误，执行正确的不会回滚，不同于关系型数据库的事务。 持久化机制持久化就是把数据从内存保存到硬盘。 Redis是一个支持持久化的内存数据库，Redis需要经常将内存中的数据同步到磁盘来保证持久化。 Redis支持两种持久化方式： snapshotting(快照) 将数据存放到文件里，默认方式。默认写入dump.rdb二进制文件中 可配置redis在n秒内超过m个key被修改就自动做快照 save 500 10 –&gt; 500s内超过10个key被修改，则保存快照 由于快照方式在一定间隔时间做一次保存， 如果Redis意外down掉的话，就会丢失最后一次快照后的所有修改。AOF比快照方式有更好的持久化性，是由于使用aof时，redis会将每一个收到的写命令都通过write函数写入到文件中当redis启动时会通过重新执行文件中保存的写命令在内存中重新建立整个数据库的内容。 appendonly file(AOF) aof方式redis会将每一次的函数都追加到文件中，当redis重启时会重新执行文件中保存的命令 配置文件参数： 1234567891011#启用aof持久化方式appendonly yes#每秒写入磁盘一次，在性能和持久化方面做了很好的折中appendonly everysc#将数据写入磁盘save 900 1save 300 10save 60 10000 虚拟内存Redis的虚拟内存是暂时把不经常访问的数据从内存交换到磁盘中，从而腾出内存空间用于其它的访问数据。对于redis这样的内存数据库，内存总是不够用的。 在配置文件(/etc/redis.conf)中配置VM: 123456789101112131415161718#开启vm功能vm-enableyes#交换出来的value保存的文件路径vm-swap-file /tmp/redis.swap#redis使用的最大内存上线vm-max-memory 10000000#每个页面的大小32字节vm-page-size 32#最多使用多少个页面vm-pages 123217729#用于执行value对象换入的工作线程数量vm-max-threads 4 批量删除123456789101112131415161718192021#删除库中所有KeySELECT 0FLUSHDB#删除所有库中KeyFLUSHALL#默认为db0#批量删除keysredis-cli KEYS &quot;test&quot; | xargs redis-cli DEL#通配符redis-cli KEYS &quot;test*&quot; | xargs redis-cli DEL#指定数据库redis-cli -n 1 KEYS &quot;test*&quot; | xargs redis-cli -n 1 DEL#指定主机，密码redis-cli -h xxx -a xx KEYS &quot;test*&quot; | xargs redis-cli -h xxx -a xx DEL bigkeys1234#对redis中的key进行采样，寻找较大的Keyredis-cli --bigkeys#之后对结果进行分析 注意 Redis监听地址bind： x.x.x.x，强烈建议只对本地127.0.0.1开放。不建议对外网开放，有安全隐患 防火墙，最简单就是关闭防火墙，另一个就是开放redis的监听端口 开启守护进程，让redis可以在后台运行而不必通过redis-server的方式来启动，将配置文件里的deamonize no改为yes 关闭redis的保护模式(protect-mode)，这里的保护模式是指是否允许其他IP的设备访问redis。如果开启的话就只能允许本机访问。如果是生产开发的实际运行环境，请一定开启保护模式 设置redis数据库密码！不仅仅是redis，任何数据库都应该设置密码，否则对外网开放的数据库就成了活靶子。 多数据库 Redis支持多个数据库 类似于其它数据库，不同的数据存储在不同的数据库中 Redis下，数据库是由一个整数索引标识，而不是数据库名称。默认情况下，客户端连接到数据库0 Redis不支持自定义数据库名称，所以需要开发者记录那些数据库存储了哪些数据 Redis不支持为每个数据库设置不同的访问密码，因为密码是在配置文件中设置的。所以一个用户可对所有数据库进行访问 Redis默认支持16个数据库，但可在配置文件中修改 使用SELECT命令切换数据库 FLUSHALL命令或清除所有数据库，请注意 123456cat /etc/redis.conf# Set the number of databases. The default database is DB 0, you can select# a different one on a per-connection basis using SELECT &lt;dbid&gt; where# dbid is a number between 0 and &apos;databases&apos;-1databases 16]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机集群]]></title>
    <url>%2F2018%2F02%2F03%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[参考： 《老男孩Linux运维》 《服务器集群系统各概念》: https://segmentfault.com/a/1190000009923581 《WEB的负载均衡、集群、高可用解决方案》： https://zhuanlan.zhihu.com/p/23826048 计算机集群维基百科 计算机集群计算机集群简称集群(Clusters)，是一种计算机系统。它通过一组散列集成的软件或硬件 连接起来高度紧密地协作完成计算工作。在某种意义上，他们可以被看做是一台计算机。 集群就是指一组（若干）相互独立的计算机，利用高速通信网络组成的一个较大的计算机服务系统，每个集群结点都是运行各自服务的独立服务器。这些服务器之间可以彼此通信，协同向用户提供应用程序、系统资源和数据，并以单一系统的模式加以管理。 当客户机请求集群系统时，集群给用户的感觉就是一个单一独立的服务器，而实际上用户请求的是一组集群服务器。 集群系统中的单个计算机通常称为节点，通常通过内网连接，但也有其它的可能连接方式。集群计算机通常用来改进单个计算机的计算速度和可靠性。 服务器集群概念集群、冗余、负载均衡、主从复制、读写分离、分布式、分布式计算、分布式计算平台、并行计算…… 实际生产环境中常有的问题： 当数据库性能遇到问题时，是否能够横向扩展，通过添加服务器的方式达到更高的吞吐量，从而充分利用现有的硬件实现更好的投资回报率; 是否拥有实时同步的副本，当数据库面临灾难时，可以短时间内通过故障转移的方式保证数据库的可用性。此外，当数据丢失或损坏时，能否通过所谓的实时副本（热备）实现数据的零损失; 数据库的横向扩展是都对应用程序透明，如果数据库的横向扩展需要应用程序端进行大量修改，则所带来的后果不仅仅是高昂的开发成本，同时也会带来很多潜在和非潜在的风险. 集群和冗余集群和冗余并不对立，多台服务器做集群（不是主从），本身就有冗余和负载均衡的效果。狭义上来说，集群就是把多台服务器虚拟成一台服务器，而冗余的每台服务器都是独立的。 集群的侧重点在于协同，多台服务器系统分担工作，提升效率； 冗余的侧重点在于防止单点故障，一主多备的架构，也就是主从复制； 数据冗余==高可用性==主从 主从一定程度上起到了负载均衡的作用，但主要目的还是为了保证数据冗余和高可用性 主从只提供一种成本较低的数据备份方案加上不完美的灾难和负载均衡，由于复制存在时间差，不能同步读，所以只是不完善的负载均衡和有损灾备 主从显然达不到集群的严格度，不论是 HA 还是 AA（多活并行集群），主从都达不到数据一致性的集群要求 为什么要使用集群 高性能（Performance） 大型网站谷歌、淘宝、百度等，都不是几台大型机可以构建的，都是上万台服务器组成的高性能集群，分布于不同的地点。 只有当并发或总请求数量超过单台服务器的承受能力时，服务器集群的优势才会体现出来。 价格有效性（Cost-effectiveness） 在达到同样性能的需求下，采用计算机集群架构比采用同等运算能力的大型计算机具有更高的性价比。 可伸缩性（Scalability） 当服务负载、压力增长时，针对集群系统进行较简单的扩展即可满足需求，且不会降低服务质量。 高可用（Availability） 单一计算机发生故障时，就无法正常提供服务；而集群架构技术可以是得系统在若干硬件设备发生故障时仍可以继续工作。 集群系统在提高系统可靠性的同时，也大大减小了系统故障带来的业务损失，目前几乎100%的网站都要求7x24h提供服务。 透明性（Transparency） 多个独立计算机组成的耦合集群系统构成一个虚拟服务器。用户访问集群系统时，就像访问一台高性能、高可用的服务器一样，集群中一部分服务器的上线、下线不会中断整个系统服务，这对用户也是透明的。 可管理性（Manageability） 这个系统可能在物理上很大，但其实很容易管理，就像管理一个单一映像系统一样。 可编程性（Programmability） 在集群系统上，容易开发及修改各类应用程序。 集群分类集群分为同构和异构，他们区别在于 “组成集群系统的计算机之间的体系结构是否相同”。 集群计算机按功能和结构可以分为以下几类： 均衡集群（Load balancing clusters） 用性集群（High-availability clusters） 能计算集群（High-performance cluster） 计算集群（Grid computing） 负载均衡集群（LB）和高可用性集群（HA）是互联网行业常用的集群架构模式 负载均衡集群负载均衡集群用于抗并发。 负载均衡集群典型的开源软件包括：LVS、Nginx、Haproxy 等。 负载均衡集群可以把很多客户集中的访问请求负载压力尽可能平均分摊在计算机集群中处理。集群中每个节点都可以一定的访问请求负载压力，并且可以实现访问请求在各节点之间动态分配，以实现负载均衡。负载均衡集群运行时，一般是通过一个或多个前端负载均衡器（Director）将客户访问请求分发到后端的一组服务器上，从而达到整个系统的高性能和高可用性。一般高可用性集群和负载均衡集群会使用类似的技术，或同时具有高可用性与负载均衡的特点。 Linux虚拟服务器（LVS）项目 在Linux操作系统上提供最常用的负载均衡软件。 负载均衡的作用： 用户访问请求及数据流量（负载均衡） 业务连续性，即7x24h服务（高可用） 于Web业务及数据库从库等服务器的业务 高可用性集群高可用性集群用于避免单点故障。 高可用性集群常用开源软件包括：Keepalived、Heartbeat 等。 一般是指集群中任意一个节点失效的情况下，该节点上的所有任务会自动转移到其他正常的节点上。此过程不会影响整个集群的运行。 当集群中的一个节点系统发生故障时，运行着的集群服务器会迅速做出反应，将该系统的服务分配到集群中其他正在工作的系统上运行。考虑到计算机硬件和软件的容错性，高可用性集群的主要目的是使局群的整体服务尽可能可用。如果高可用集群中的主节点发生了故障，那么这段时间内将由备节点代替它。备节点通常是主节点的镜像。当它代替主节点时，它可以完全接管主节点（包括Ip和其他资源）提供服务，因此，使集群系统环境对系统环境来说是一致的，既不会影响用户的访问。 高可用性集群使服务器系统的运行速度和响应速度会尽可能的快。它们经常利用在多台机器上运行的冗余节点和服务来相互跟踪。如果某个节点失败，它的替补者将在几秒钟或更多时间内接管它的职责。因此，对于用户来说，集群里的任意一台机器宕机，业务都不会受影响。 高可用性集群的作用： 当一台机器宕机后，另外一台机器接管宕机的机器的Ip资源和服务资源，提供服务； 常用于不易实现负载均衡的应用，如负载均衡器、主数据库、主存储对之间； 高性能计算集群高性能计算集群也称并行计算。通常，高性能计算集群涉及为集群开发的并行应用程序，以解决复杂的科学问题。 高性能计算集群对外就好像一个超级计算机，这种超级计算机内部由数万个独立服务器组成，并且在公共消息传递层上进行通信以运行并行应用程序。 高可用与负载均衡有什么区别 HA偏重于备用资源，切机时会有业务的断开的，保证了数据的安全，但造成资源的浪费； LB侧重于资源的充分应用，没有主备的概念，只有资源的最大限度的加权平均应用，基本不会业务的中断； HA的目的是不中断服务，LB的目的是为了提高接入能力。虽然经常放一起用，但确实是两个不同的领域； HA在一条路不通的时候提供另一条路可走，而 LB 就类似于是春运时的多个窗口； 集群软硬件 企业运维中常见集群产品： 开源集群软件：+ Nginx, LVS, Haproxy, Keepalived, Heartbear... 商业集群硬件：+ F5， Netscaler,Radware, A10... 如何选择开源集群软件： 网站在并发访问和总访问量不是很大的情况下，建议首选Nginx负载均衡，Nginx配置简单使用方便安全稳定。 另一个实现负载均衡的产品为Haproxy 如果要考虑Nginx负载均衡的高可用功能，建议首选Keepalived软件，因为安装配置简单方便稳定。类似高可用软件还有Heartbeat，但比较复杂 如果是大型企业，负载均衡可以使用 LVS+Keepalived 在前端做四层转发，后端使用Nginx或Haproxy做七层转发，再后面是应用服务器。如果是数据库与存储的负载均衡和高可用，可选用LVS+Heartbeat 负载均衡所谓负载均衡，就是把大访问量分发给不同的服务器，也就是分流请求。 HTTP重定向协议实现负载均衡HTTP 重定向就是应用层的请求转发，用户的请求其实已经到了HTTP重定向负载均衡服务器，服务器根据算法要求用户重定向，用户收到重定向请求后，再次请求真正的集群. 优点：简单 缺点：性能较差 DNS域名解析负载均衡DNS域名解析负载均衡就是在用户请求DNS服务器，获取域名对应的IP地址时，DNS服务器直接给出负载均衡后的服务器IP。 优点：交给DNS，不用我们去维护负载均衡服务器 缺点：当一个应用服务器挂了，不能及时通知DNS，而且DNS负载均衡的控制权在域名服务商那里，网站无法做更多的改善和更强大的管理 反向代理负载均衡在用户的请求到达方向代理服务器时（已到达网站机房），由于反向代理服务器根据算法转发到具体的服务器，常用的Apache，Nginx都可以充当反向代理服务器。 优点：部署简单 缺点：代理服务器可能成为性能的瓶颈，特别是一次上传大文件 IP负载均衡(LVS-NAT)LVS集群中实现的三种IP负载均衡技术。 在请求到达负载均衡器后，负载均衡器通过修改请求的目的IP地址，从而实现请求的转发，做到负载均衡。 优点：性能更好 缺点：负载均衡器的带宽称为瓶颈 直接路由负载均衡(LVS-DR)数据链路层负载均衡，在请求到达负载均衡器后，负载均衡器通过修改请求的Mac地址，从而做到负载均衡，与IP负载均衡不一样的是，当请求访问完服务器之后，直接返回客户，而无需在经过负载均衡器。 IP隧道负载均衡(LVS-TUN) 主从复制主从是一种用于数据容错和灾备的高可用解决方案，而不是一种处理高并发压力的解决方案（负载均衡是用来抗并发的）。 如MySQL主从复制，MongoDB主从复制(副本集) 主机负责查询，从机负责增删改 可以在从机上执行备份，以避免备份期间影响主机的服务 主从复制后，也可以在从机上查询，以降低主机的访问压力。但是，只有更新不频繁的数据或者对实时性要求不高的数据可以通过从服务器查询，实时性要求高的数据仍需在主服务器查询（因为主从复制有同步延迟，所以不能保证强数据一致性） 主从复制和读写分离 主从复制是实现读写分离的技术之一，也是实现读写分离的前提条件 做读写分离时最重要的就是确保 读库 和 写库 的数据统一，而主从复制是实现数据统一最简单的方法（并不能够保证强数据的一致性） 读写分离，顾名思义，就是一个表只负责向前台页面展示数据，而后台管理人员对表的增删改在另一个表中，把两个表分开，就是读写分离 主从复制则是一个表数据 增删改 之后会及时更新到另一个表中，保证两个表的数据一致 主从类型 双机热备=主机+备机 主要应用运行在主机，备机即备用机器。备机不工作，主机出现故障时备机接管主机的所有工作 双机互备=主机（备机） + 备机（主机） 互为主备，部分应用运行于主机，部分应用运行于备机，主机备机同时工作 双机双工=主机+主机 两台主机同时运行应用，主机备机同时工作 分布式 广义上的分布式是指，将不同的服务分布在不同的服务器上 集群是指，将几台服务器集中在一起，实现同一业务 分布式中的每一个节点都可以做集群，而集群并不一定是分布式的]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>Cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[不成熟的小想法]]></title>
    <url>%2F2018%2F01%2F21%2F%E4%B8%8D%E6%88%90%E7%86%9F%E7%9A%84%E5%B0%8F%E6%83%B3%E6%B3%95%2F</url>
    <content type="text"><![CDATA[你在大学奋斗四年和你进入工作岗位后奋斗四年，这两者的质量是完全不同的。前者是一个人一生的黄金时代，他有绝对的选择权来决定自己要成为什么样子；而后者则不同，吃饱饭才是这些已经步入社会的人需要考虑的第一要务。 我想不明白，为什么非要把成都建设成为2/3个四川？(或许西部省份都是这样，省会便是这个省)2017年成都市GDP约为13800亿人民币，而第二名的绵阳，却连2000亿都不到。后来别人对我讲，资本都是逐利的。也许将壹万亿拆分成小蛋糕到各个地级市能使得各个地级市经济都得到一定的发展，但肯定没有将全部蛋糕投在成都的利润更好。这让我想起了滚雪球效应，相比滚出许多小雪球，所带来的的直观效应也没有大雪球突出，雪球越滚越大，给人的映像也就越来越明显。还有就是为政者都是需要政绩来突出自己，这是升迁的重要依据。GDP才是衡量你当政的重要依据，其它因素虽然也重要，但也比不过它。 我喜欢苹果，你却给了我一车梨，然后告诉全世界你花光了所有的钱给我买了一车梨。可是我却没有一点点感动，你说我是一个铁石心肠的人，可是我只是喜欢苹果而已。 任何人不是要你来教他如何做人的！ 难道真如马尔克斯所说——“上了年纪的人不是按照已经活了多少岁来衡量年龄的，而是通过距离死亡还有多远来衡量！” 我刚开上本田的时候，也是宋总这心情，把骑自行车的人贬个贼死，而且心里就会骂出口，大屁股晃什么晃，开个玛萨拉蒂得瑟呀，我那时就像我买得起玛萨拉蒂一样。哈哈，就是个工具，先上手再说。原来人都有这种心态，哈哈哈。 看着老一辈的逐渐老去，小一辈的逐渐长大，感叹时光过得真快呀！ 过年回家，任何人都会谈及一个字——“钱”。 全家人都想出去挣钱，关于老人赡养问题，儿子和女儿又该如何担责？ 儿媳妇也是一个严重的问题！我在想一个问题，儿媳妇在对待男方父母的时候，有没有想过如果以后她的儿媳也这样对待她，她作何感想？ 现在的亲戚关系如果隔代的话，基本上过年就只有上一辈的人才走动了，下一辈子女基本都不会去。想想我们这些娃儿，上辈是亲兄弟姐妹、堂兄弟姐妹或表兄弟姐妹，我们这些小辈娃儿从小一起玩耍长大，小时候的关系好的不得了，用俗话说就是“穿一条裤子”。可是长大以后、结婚成家以后关系就淡泊了，哎！可能我们这一辈情况以后会好一点，因为由于国家的计划生育政策，我们这一辈基本上都是独生子女。以后亲戚就这些，可能关系会好点，逢年过节走动会更频繁一点。其实计划生育使得我们这一辈人挺孤单的，长得后没什么亲戚、兄弟姊妹。以后我们的孩子也没有了舅舅、姨、叔伯、嬢嬢。所以可能以后非直系亲戚间的关系也会更紧密一些。现在国家放开了二胎其实挺好的，孩子们能有个哥哥姐姐弟弟妹妹真的挺好的。 过年回家经典问答：毕业了没有呀？毕业了，微笑；多少岁了呀？xxx岁了，微笑；在哪上班呀？在外上班，微笑；在成都哪个地方呀？南边，微笑；在哪个公司呀？小公司，微笑；是做啥子的呀？计算机，微笑；工资多少呀？不多不少，微笑；有没有女朋友呀？没有，微笑……我知道这些长辈本没有恶意，只是出于不知道说什么而问点问题。但是，你们就不能动动脑子吗，我的长辈些。 我只是一个农村里出来的怯弱书生，一定要找准自己的定位。上辈给不了我什么东西，这点和城里的孩子已经差了一步，所以只有靠自己好好努力奋斗。争取给小一辈创造一个好一点的环境。 人人都是有利己心，人人都是自私的，表面和内心就如同硬币的正反两面。底层人民毫不讲理的一套，做事情完全不看原则和对错，完全是斗谁的声音高谁的脾气大才是理。看见斗不过有立马哭闹装楞。农村人民并不是那么淳良朴实，一点点鸡毛蒜皮的事情都要争。 任何人际关系都需要维持的！ 我发觉我有一个问题。人对一个人、一件物、一件事产生一个误解(或称之为成见的东西)，是很难改变的，以后会一直存在于我们的潜意识里面。我们的潜意识会主动隔阂某人某事某物，几遍某人某物某事是对的，这样一个长期效应便是对于我们潜意识里面的思维，我们会主动用我们的成见来隔阂。不知道能不能用“一朝被蛇咬十年怕井绳”来表述。其实人与人、人与事是需要相互了解的，有了成见以后人就不愿意了解对方，而用自己潜意识的成见来判断人事物。这样隔阂也就难以消除而会一直延续小区。所以，对人对事，不能带着老旧的成见去看到。——“士别三日当刮目相待，已非吴下阿蒙”。 2018年国庆回家，我感觉微信、农药、吃鸡、短视频等已经了抓住了每个年龄阶层的中国人。下至三五岁的孩童，中间的青少年更不用提，上到我的长辈些。微信已经是长辈些拉家常的聊天室，吃鸡农药开黑也是孩子们愿意与感兴趣的交流话题。空了刷刷抖音、玩玩快手，不是一个人，而是一群人，一群人的交流圈子和认同圈子。感觉每个人都是这样过来的，只不过我(90后)小时候没有移动互联网，只能玩玩泥巴、打弹弓、弹珠子、拍板、铲陀螺、滚铁环、打摇杆、进网吧……只不过我那时候没有这些东西，其实本心都是一样贪玩，玩的东西从那些变成了这些，本质上没有区别。嗨，杞人忧天的小张。看着电视从黑白发展为了彩色，看着道路从泥泞修为水泥，看着村里通电通路通水通气通网，看着手机从2G发展为移动互联网时代，看着中国改革开放的发展，看着淘宝腾讯百度的兴衰，看着快递打车外卖等新兴互联网行业的起落，现在便要看着人工智能、云等行业的发展。社会在快速的发展，我也参与在其中，以后的社会会是什么样呢？反正是越来越智能化！ 现在感觉结婚也是一个严重的问题，我的同龄人们总是说结不起婚，女方要房要车要金银，男方家长拼命在外面打工存钱用于儿子结婚。哎，想想就痛苦的很。我也知道不是所有女方都是这样的想法，不过主流就是这样。但反过来想，如果我是女方家长，把女儿嫁好一点难道不对吗？同样人品长相下的男孩子，凭什么不选一个家庭条件更好的？这是一个悖论！虽然道理我都懂，感情是两个人的事，家庭条件也是夫妻两人共同努力慢慢发展而来。结婚并不是卖女儿，结婚也不是为了给儿子找个媳妇来传宗接代。我想不明白一些儿媳妇对南方家长很差，男方家长还拼命给他们存钱，这是为什么？我在想，某些儿媳妇对老人很差，她有没有想过如果以后她的儿媳妇这样对她，她是什么想法？我真是想不明白。]]></content>
      <categories>
        <category>Zhang</category>
      </categories>
      <tags>
        <tag>Zhang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL]]></title>
    <url>%2F2018%2F01%2F16%2FMySQL%2F</url>
    <content type="text"><![CDATA[参考： MySQL5.7参考文档： https://dev.mysql.com/doc/refman/5.7/en/ 环境： CentOS7.x86_64 MySQL5.7 序言MySQL官网： https://www.mysql.com/ 由于MySQL5.7和以前版本之间的许多功能和其他差异，因此此手册不太适用于之前的老版本。之前的版本请参考MySQL相关版本的手册。 综述General information MySQL™ software提供了一个快速、多线程、多任务和健壮的SQL(结构化查询语言)的数据库服务器。MySQL server是为关键服务(mission-critical)、重负荷(heavy-load)生产系统以及嵌入式(embedding)大规模部署的软件而设计。MySQL是Oracle Corporation的商标(trademark)。 MySQL software是双重许可的(dual license)： Open Source product of the GNU General Public License A Standard commercial License from Oracle 关于此手册 该手册作为一个参考，它不提供关于SQL或关系型数据库概念的一般指令； MySQL Database Software正在不断发展，所以参考手册也经常更新。可在此 &lt; http://dev.mysql.com/doc/&gt; 获取最新版的手册； 参考手册(Reference Manual)的源文件使用DocBook XML格式书写的，其他版本(如HTML)等是自动生成的； 如果在使用过程中有任何问题或建议，请发邮件给我们； 手册由MySQL Documentation Team维护。 MySQL数据库管理系统MySQL Database Management System MySQL介绍MySQL是最流行的开源的SQL数据库管理系统，由Oracle Corporation开发、分发和支持。 MySQL is a database management system数据库是一个结构化的数据集合。它可能是从简单的购物清单到图片库，或是公司网络中的大量信息。若要添加、访问和处理存储在计算机数据库中的数据，你需要一个像MySQL Server这样的数据库管理系统。由于计算机非常擅长处理大量的数据，数据库管理系统在计算机中扮演这一个重要的角色。 MySQL databases are relational关系型数据库将数据存储在单独的表(table)中，而不是将所有数据放入一个大的库房中。数据库结构被组织成针对速度优化的物理文件。具有数据库(database)，表(table)，视图(view)，行(row)，列(column)等物理对象的逻辑模型提供了灵活的编程环境。你设置了管理不同数据字段之间关系的规则，如一对一，一对多，唯一，必须和可选关系，以及不同表之间的指针(pointer)。数据库强制执行这些规则，这样在设计良好的数据库中，应用程序就不会看到不一致、重复、孤立、过时或丢失的数据。 MySQL也是代表SQL(Structure Query Language)的一部分。SQL是访问数据库最常用的标准化语言。你可以直接使用SQL语句，或者将SQL语法隐藏到语言特定的API中。 -MySQL software is Open SourceMySQL software使用GPL(GNU General Public License)，开源意味着任何人都可以下载、转发、使用和修改软件，而不需要支付任何费用。 MySQL database server is very fast,reliable,scalabe and easy to use MySQL server works in Client/Server or embedded systemMySQL Database Server是一个由多线程(multi-threaded)SQL Server组成的客户/服务器系统。它支持不同的后端，多个不同的客户程序和库、管理工具和广泛的APIs。还提供MySQL Server作为一个嵌入式多线程库以便链接到你的产品，以获得一个更小，更快，更容易管理的独立产品。 A large amount of contributed MySQL software is available MySQL主要特点Internals and Portability 由C和C++写成 适用于许多不同的平台 为了可移植性，使用CMake 采用独立(independent)模块的多层(layer)服务器设计 设计为使用内核线程的完全多线程，如果有多核CPU，能够轻松使用它们 提供了事务性(transactional)和非事务性(notransactional)存储引擎 使用非常快速的带有索引压缩的B-tree磁盘表 添加其他存储引擎相对容易 使用非常快速的基于线程的内存分配系统 使用优化的嵌套循环(nested-loop)连接执行非常快的联结 实现内存中的hash table，这些表用作临时表 使用高度优化的类库实现SQL函数 数据类型 1,2,3,4和8byte的有无符号(signed/unsigned)的整数(integers) FLOAT DOUBLE CHAR, VARCHAR BINARY, VARBINARY TEXT BLOB DATE, TIME, DATETIME TIMESTAMP YEAR SET ENUM OpenGIS 状态和功能statement and function SELECT和WHERT中包含了所有支持的操作符和函数 SQL中的GROUP BY和ORDER BY也全部支持 GROUP functions(COUNT(), AVG(), STD(), SUM(), MAX(), MIN(), GROUP_CONCAT()) 支持LEFT OUTER JOIN和ROGHT OUTER JOIN 按照SQL标准支持table和columns的别名 支持DELETE,INSERT,REPLACE,UPDATE，以返回受影响的行数 支持MySQL特定的SHOW显示语句 一个EXPLAIN语句显示优化器如何解析查询 安全security 权限(privilege)和密码系统，非常灵活和安全，并且支持基于主机的验证 当连接到Server时，通过加密(encryption)所有密码通信量来确保密码安全 扩展性和限制Scalability and Limits 支持大型数据库。包含五千万条记录，二十万个表，五十亿行 每个表最多支持64个索引，每个索引可以由1到16个列组成 #### 连通性 Conectivity 客户端使用如下几种协议连接到MySQL Server TCP/IP sockets –enable-named-pipe on Windows Unix domain socket files on UNIX MySQL客户端可用多种语言编写 APIs对于多数语言是可用的 本地化Localization Server可以向多种语言的客户端提供错误信息 完全支持几个不同的字符集(character sets) 所有数据都被保存在选取的字符集(chracter set) 排序和比较是根据默认的字符集和排序规则完成 服务器时区(time zone)可动态更改，个客户端也可修改自己的时区 客户端和工具Clients and Tools MySQL包含几个客户机和使用程序 command-line： mysqldump, mysqladmin graphical: MySQL Workbench MySQL Server内置了对SQL语句的支持来检查、优化和修复表 MySQL程序可使用--help或-?来获取帮助 MySQL历史History of MySQL MySQL is named after co-founder Monty Widenius’s daughter, My. The name of the MySQL Dolphin (our logo) is “Sakila,” which was chosen from a huge list of names suggested by users in our “Name the Dolphin” contest. MySQL5.7新特色What Is New in MySQL 5.7 MySQL5.7新功能Features Added in MySQL 5.7 MySQL5.7中过期的功能Features Deprecated in MySQL 5.7 MySQL5.7中移除的功能Features Removed in MySQL 5.7 Server and Status Variables and Options Added, Deprecated, or Removed in MySQL 5.7 MySQL信息源MySQL Information Sources 本章节将列出有关MySQL的帮助信息。 MySQL站点MySQL Websites MySQL Documentation is https://dev.mysql.com/doc 术语MySQL Glossary 这些术语通常用于有关MySQL的信息中。 .ARM文件ARCHIVE表的metadata。由MySQL Enterprise Backup产品的mysqlbackup命令生成的备份中。 .ARZ文件ARCHIVE表的数据。由MySQL Enterprise Backup产品的mysqlbackup命令生成的备份中。 ACID代表原子性(atomic)，一致性(consistency)，隔离性(isolation)和持久性(durability)的首字母缩略词。事务是可以提交(commit)或回滚(rollback)的原子工作单位。当事务对数据库进行多次更改时，要么在提交事务时所有更改都成功，要么在事务回滚时撤消所有更改。数据库始终保持一致性状态 - 每次提交或回滚后，以及事务正在进行中。如果跨多个表更新相关数据，查询将查看所有旧值或所有新值，而不是旧值和新值的混合。交易在进行过程中受到保护（隔离），它们不能互相干扰或看到彼此未提交的数据。这种隔离是通过锁定机制(locking mechanism)实现的。经验丰富的用户可以调整隔离级别，在保证事务确实不会相互干扰的情况下，减少保护，转而提高性能和并发。事务的结果是持久的：一旦提交操作成功，该事务所做的更改就可以避免电源故障，系统崩溃，竞争条件或许多非数据库应用程序易受攻击的其他潜在危险。耐用性通常涉及写入磁盘存储，具有一定的冗余以防止写入操作期间的电源故障或软件崩溃。 adaptive flushingAn algorithm for InnoDB tables that smooths out the I/O overhead introduced by checkpoints.MySQL不会一次将所有修改过的页面从缓冲池(buffer pool)刷新(flush)到数据文件，而是定期刷新一小组修改过的页面。自适应刷新(adaptive flushing)算法通过基于刷新率和生成重做信息的速度来估计执行这些周期性刷新的最佳速率来扩展该过程。 adaptive hash indexInnoDB表的优化，通过在内存中构造hash index，可使用=和IN操作符加速查找。MySQL监控InnoDB表的索引搜索，如果查询可从哈希索引中受益，它会自动为经常访问的索引页创建一个。从某种意义上来说，自适应哈希索引在运行时配置MySQL以利用充足的主内存，更接近主内存数据库的体系结构。此功能由innodb_adaptive_hash_index配置项控制。 AIO异步(asynchronous)I/O的缩写。 Antelope原始InnoDB文件格式的代码名称。它支持REDUNDANT和COMPACT行格式，但不支持较新的DYNAMIC和COMPRESSED行格式。 API一组功能或程序。 apply当MySQL Enterprise Backup产品生成的备份不包括备份进行时发生的最新更改时，更新备份文件以包含这些更改的过程称为apply步骤。 asynchronous I/O一种I/O操作，允许在I/O完成前继续进行其它处理。也称为非阻塞(nonblocking)I/O，缩写为AIO。 atomic在SQL上下文中，事务是完全成功(commited)或根本没有效果(rollback)的工作单元。 atomic DDLatomic DDL语句将数据字典更新，存储引擎操作和DDL操作关联的二进制日志写入组合到单个原子事务中。即使服务器在操作期间暂停，事务也可以完全提交或回滚。MySQL 8.0中添加了Atomic DDL支持。 atomic instructionCPU提供的特殊指令。确保关键的低级操作不会被中断。 auto-increment(自增)表的列的属性(由AUTO_INCREMENT关键字指定)，在自动在列中添加值的升序。 auto-increment locking自动增量主键的便利性涉及一些与并发的权衡。 autocommit在每个SQL语句之后导致COMMIT的设置。建议不要将此模式用于具有跨多个语句的事务的InnoDB表。它可以帮助InnoDB表上的只读事务的性能，从而最大限度地减少锁定和生成撤消数据的开销。 availability能够对应于主机上的故障，并在必要时从中恢复故障。 B-tree一种在数据库索引中很常用的树数据结构。结构始终保持排序，从而能够快速查找完全匹配(=)和让位(&gt;, &lt;, BETWEEN)。这种索引类型适用于大多数索引类型。因为B树有很多子节点(children)，所以B树与二叉树(binary tree)不同，二叉树每个节点限制为2个子节点。与哈希索引(hash index)形成对比，HASH仅在MEMORY存储引擎中可使用，MEMORY存储引擎中也可使用B树索引。如果某些查询使用范围运算符，则应为MEMORY表选择B树索引。 backticks(反引号)如果MySQL SQL语句中的标识符包含特殊字符或保留字，则必须使用反引号(```)。 backup从MySQL实例复制部分或全部表数据和原数据的过程，以便妥善保管。 BarracudaInnoDB文件格式的编码名称，它支持启用InnoDB表压缩的COMPRESSED行格式，以及改进长度可变长度列的存储布局的DYNAMIC行格式。 base column存储生成的列或虚拟生成列多所基于的非生成表列。换句话说，基本列是非生成的表列，它是生成的列定义的一部分。 binary log包含尝试更改表数据的所有语句的记录的文件。可以重播(replayed)这些语句，以便在副本集方案中是Slave Server保持最新，或者在从备份中还原表数据使数据库保持最新。建议开启此功能。你可使用mysqlbinlog命令检查二进制日志的内容，以及重播这些内容。 binlog二进制日志文件的非正式名称。 blind query expansion由WITH QUERY EXPANSION子句启用的特殊全文搜索(full-text search)模式。它执行两次搜索，其中第二次搜索的搜索短语是与第一次搜索的少数最高度相关的文档连接的原始搜索短语。该技术主要适用于短搜索短语，可能只有一个单词。它可以发现文档中未出现精确搜索词的相关匹配。 bottleneck(瓶颈)系统的一部分，其大小或容量受到限制，具有限制总吞吐量的效果。 bounce关机(shutdown)操作后立即重启(restart)。 buddy allocator一种管理InnoDB缓冲池(buffer pool)不同大小页面(pages)的机制。 buffer用于临时存储的内存或磁盘区域。 buffer pool保存表和索引的缓存InnoDB数据的内存区域。为了提高大容量读取操作的效率，缓冲池被分成可以容纳多行的页面。在具有大内存的系统上，可以通过将缓冲池划分为多个缓冲池实例来提高并发性。几个InnoDB状态变量，INFORMATION_SCHEMA和performance_schema有助于监视缓冲池的内部工作。 buffer pool instance可以划分缓冲池的多个区域中的任何一个，由innodb_buffer_pool_instances配置项控制。innodb_buffer_pool_size指定的总内存大小在所有缓冲池实例之间划分。通常，具有多个缓冲池实例适用于为InnoDB缓冲池分配多个GigaBytes的系统，每个实例为1GigaByte或更大。 built-inMySQL内置的InnoDB存储引擎是存储引擎的原始分发形式。 .cfg文件与InnoDB可传输表空间功能一起使用的元数据(metadata)文件。它由命令FLUSH TABLES...FOR EXPORT生成，将一个或多个表置于可以复制到另一个Server的一致状态。 cache存储区域的通用术语，用于存储频繁或高速检索的数据副本。在InnoDB中，主要的缓存结构就是缓冲池(buffer pool)。 cardinality表列中的不同值的数量。当查询引用具有关联索引的列时，每列的基数会影响哪种访问方法最有效。 change buffer一种特殊的数据结构，用于记录二级(secondary)索引中页面的更改。 change buffering涉及change buffer功能的通用术语，包括insert buffering, delete buffering, pure buffering。 checkpoint当对缓冲池(buffer pool)中缓存(cached)的数据也进行更改时，这些更改将在稍后某个时间写入数据文件，这个过程称为刷新(flushing)。检查点是已成功写入数据文件的最新更改(LSN值)的记录。 checksum在InnoDB中的一种验证机制，用于在将表空间中的页面从磁盘读入InnoDB缓冲池时检测损坏。 child table在外键(foreign key)中，子表是其行引用另一个表中具有相同值的特定列的行的表。这是包含FOREIGN KEY...REFERENCES子句和可选ON UPDATE和ON DELETE子句的表。子表创建之前，父表中的相应行必须存在。 clean pageInnoDB缓冲池中的一个页面，启用所有在内存中进行的更改也写入(flushed)到数据文件中。dirty page的反面。 clean shutdown关闭完成且没有错误，并在完成之前对InnoDB表应用所有的更改，而不是奔溃或快速关闭。slow shutdown的同义词。 client客户端。 clustered indexInnoDB术语表示主键索引(primary key index)。InnoDB表存储基于主键列的值进行组织，以加速涉及主键列的查询和排序。为获得最佳性能，请根据性能最关键的查询仔细选择主键列。 cold backup数据库关闭时进行的备份。 column行中的数据项，其存储和语义由数据类型定义。每个表格索引主要由它包含的列集合来定义。每个列都有一个基数值。列可以是其表的主键，也可以是主键的一部分。列可以是受唯一约束(unique constraint)，NOT NULL constraint或两者都有。不同列中的值，甚至跨不同的表，可以通过外键关系(foreign key relationship)链接。 column index单列的索引。 column prefix当使用长度规范创建索引时(如: CREATE INDEX idx ON t1 (c1(N));)，只有列值的前N个字符存储在索引中。保持索引前缀较小使索引紧凑，内存和磁盘I/0节省有助于提高性能。 commit结束事务的SQL语句，使事务所做的任何更改永久化。它与回滚(rollback)相反，回滚撤销了在事务中所做的任何更改。 compact row format它是MySQL 5.0.3 to MySQL 5.7.8的默认行格式。从MySQL 5.7.9开始，默认行格式由innodb_default_row_format配置选项定义，该选项的默认设置为DYNAMIC。 composite index包含多个列的索引。 compressed backupMySQL Enterprise Backup产品的压缩功能生成每个表空间的压缩副本. compressed row format一种行格式，可为InnoDB表启用数据和索引压缩。 compressed table以压缩形式存储数据的表。对于InnoDB，它是使用ROW_FORMAT=COMPRESSED创建的表。 compression具有广泛优势的功能,包括使用更少的磁盘空间，执行更少的I/O以及使用更少的内存进行缓存。InnoDB支持表级别和页级别的压缩。 compression failure实际上并不是错误，而是在将压缩与DML操作结合使用时可能发生的昂贵操作。 concurrency(并发)多个操作同时运行的能力，而不会相互干扰。并发性还涉及性能，因为理想情况下，使用有效的锁定(locking)机制，对多个并发事务的保护以最小的性能开销工作。 configuration file包含MySQL在启动时使用的选项的文件。一般来说，Unix/Linux上此文件为my.cnf，Windows上为my.ini。你可在[mysqld]部分下设置与InnoDB相关的许多选项。 consistent read(一致读)一种读取操作，它使用快照信息基于某个时间点显示查询结果，而不管同时运行的其它事务所执行的更改。 constraint一种自动测试，可以阻止数据库更改以防止数据变得不一致。 counter由特定类型的InnoDB操作递增的值。用于测量Server的繁忙程度，对性能问题的来源进行故障排除，以及测试更改是否具有所需的低级别效果。 covering index包含查询检索的所有列的索引。查询不是使用索引值作为指针来查找完整的表行，而是从索引结构返回值，从而节省磁盘I/O。 CPU-bound一种工作负载(workload)，其主要瓶颈是内存中的CPU操作。通常涉及读取密集型操作，其中结果都可以缓存在缓冲池中。 crashMySQL使用术语崩溃(crash)来指代Server无法正常清理的任何意外关机操作。 crash recovery崩溃后再次启动MySQL时发生的清理活动。 CRUDcreate, read, update, delete的缩写，使数据库应用程序中常见的操作序列。 cursor一种内部数据结构，用于表示查询的结果集合或使用SQL WHERE子句执行搜索的其它操作。它的工作方式类似于其它高级语言中的迭代器，根据请求从结果集合中生成每个值。 安装和升级 mysql-repo: http://repo.mysql.com/ yum-repo: http://repo.mysql.com/yum/ 安装MySQL一般遵循以下步骤： 确定MySQL是否支持你的平台(platform) Unix、Linux、FreeBSD Windows OS X 选择要安装的发行版(distribution) 下载你想要安装的发行版 安装发行版 执行任何必要的安装后设置 通用安装指南General Installation Guidance 安装哪个发行版和MySQL版本Which MySQL Version and Distribution to Install 在准备安装MySQL时，请决定使用哪种版本(version)和发行(distribution)格式(binary or source) 首先，决定安装开发版还是稳定版。 Development release 具有新功能，但不推荐用于生产环境 General Availability(GA) release 也称为稳定版(stable release)，推荐为生产环境使用 MySQL命名方案(naming scheme)， 例如MySQL5.7.1： 5为主版本号(major) 7为次版本号(minor) 1为发行(release)系列版本号 系列号描述了稳定的功能集。对于每个新的修补程序，这都会增加。 在选择要安装的MySQL版本之后，决定要为操作系统安装哪个发行版格式。 二进制(binary) RPM, DMG 源码(source) tar, zip 在某些情况下，最好使用源码安装MySQL： 想在某个明确的位置安装MySQL 希望使用二进制发行版中未包含的特性配置mysqld 希望配置mysqld，而不需要二进制发行版中包含的一些功能 你希望读取或修改组成MySQL的C、C++源代码 源码发行版比二进制发行版包含更多的测试和示例 如何获取MySQLHow to Get MySQL MySQL当前版本下载页： https://dev.mysql.com/downloads/ 完整的MySQL镜像： https://dev.mysql.com/downloads/mirrors/ 基于RPM的Linux平台，MySQL Yum Repository： https://dev.mysql.com/downloads/repo/yum/ 基于Debian的Linux平台，MySQL APT Repository： https://dev.mysql.com/downloads/repo/apt/ SUSE Linux平台，MySQL SUSE Repository： https://dev.mysql.com/downloads/repo/suse/ 使用MD5校验和或GnuPG验证程序完整性Verifying Package Integrity Using MD5 Checksums or GnuPG 下载好MySQL包并在安装它之前，请确保它是完整的并未被篡改。有如下三种方法： MD5 checksums Cryptographic signatures using GnuPG, the GNU Privacy Guard For RPM packages, the built-in RPM integrity verification mechanism 验证MD5校验和Verifying the MD5 Checksum 应确保下载的MySQL包的MD5校验和与MySQL官方提供的校验和相匹配。 12md5sum mysql-standard-5.7.22-linux-i686.tar.gz#aaab65abbec64d5e907dcd41b8699945 mysql-standard-5.7.22-linux-i686.tar.gz 使用GnuPG进行签名检查Signature Checking Using GnuPG 要验证软件包的签名，首先需要我们的公共GPG密钥的副本。可从http://pgp.mit.edu/下载。你想要获得的密钥名为mysql-build@oss.oracle.com，如下: 12345678-----BEGIN PGP PUBLIC KEY BLOCK-----Version: GnuPG v1.4.5 (GNU/Linux)mQGiBD4+owwRBAC14GIfUfCyEDSIePvEW3SAFUdJBtoQHH/nJKZyQT7h9bPlUWC3RODjQReyCITRrdwyrKUGku2FmeVGwn2u2WmDMNABLnpprWPkBdCk96+OmSLN9brZfw2vOUgCmYv2hW0hyDHuvYlQA/BThQoADgj8AW6/0Lo7V1W9/8VuHP0gQwCgvzV3BqOx后面还有很多，省略-----END PGP PUBLIC KEY BLOCK----- 使用gpg --import将密钥导入到个人公共GPG密钥环中。如公共密钥为mysql_pubkey.asc： 12345gpg --import ./mysql_pubkey.asc#或使用public key id下载公共密钥gpg --recv-keys $pub-key-id 在rpm包中验证: 1rpm --import ./mysql_pubkey.asc 确保两个文件都放置于同一目录下，然后运行命令验证签名： 12345gpg --verify package_name.ascgpg --verify mysql-standard-5.7.22-linux-i686.tar.gz.ascgpg: Signature made Tue 01 Feb 2011 02:38:30 AM CST using DSA key ID 5072E1F5gpg: Good signature from &quot;MySQL Release Engineering &lt;mysql-build@oss.oracle.com&gt;&quot; 使用RPM进行签名检查Signature Checking Using RPM 1234rpm --checksig package_name.rpm[zhang@zabbix ~]$ rpm --checksig mysql-community-server-5.7.20-1.el7.x86_64.rpmmysql-community-server-5.7.20-1.el7.x86_64.rpm: (sha1) dsa sha1 md5 gpg OK rpm还支持从URL加载密钥: 1rpm --import http://dev.mysql.com/doc/refman/5.7/en/checking-gpg-signature.html 安装布局Installation Layouts 不同的安装类型(native packages, binary tarballs, and source tarballs)有不同的安装布局，这样可能会导致混淆。 在Unix/Linux上使用通用二进制文件安装MySQLInstalling MySQL on Unix/Linux Using Generic Binaries 包括以压缩的tar文件形式的通用二进制发行版，以及针对特定平台封装格式的二进制文件。 MySQL压缩tar文件二进制发行版具有 mysql-VERSION-OS.tar.gz的文件格式。 MySQL依赖于libaio Library： 1yum install -y libaio 默认地，tar文件二进制发行版，解压后安装于/usr/local/mysql目录。会在目录下生产 通用Unix/Linux二进制包的MySQL安装布局目录 目录 内容 bin mysqld server, client and utility programs docs MySQL manual in Info format man Unix manual pages include Include (header) files lib Libraries share Error messages, dictionary, and SQL for database installation support-files Miscellaneous support files 大致命令如下： 12345678910111213141516171819shell&gt; groupadd mysqlshell&gt; useradd -r -g mysql -s /bin/false mysqlshell&gt; cd /usr/localshell&gt; tar zxvf /path/to/mysql-VERSION-OS.tar.gzshell&gt; ln -s full-path-to-mysql-VERSION-OS mysqlshell&gt; cd mysqlshell&gt; mkdir mysql-filesshell&gt; chown mysql:mysql mysql-filesshell&gt; chmod 750 mysql-filesshell&gt; bin/mysqld --initialize --user=mysqlshell&gt; bin/mysql_ssl_rsa_setupshell&gt; bin/mysqld_safe --user=mysql &amp;# Next command is optionalshell&gt; cp support-files/mysql.server /etc/init.d/mysql.server#添加环境变量export PATH=$PATH:/usr/local/mysql/bin 在Linux上安装MySQLInstalling MySQL on Linux Linux支持多种方法来安装MySQL。建议使用Oracle提供的一个发行版： Apt Yum Zypper RPM DEB Generic Source Docker Oracle Unbreakable Linux Network 作为一个选择，你可以使用系统中的包管理工具自动下载和安装MySQL。 在Linux上使用Yum Repository安装MySQLInstalling MySQL on Linux Using the MySQL Yum Repository 安装一个全新的MySQL的步骤： 添加MySQL Yum Repository 首先，添加MySQL Yum repository到你的系统仓库列表 选择和下载对应平台的release 或者 手动添加repository文件 安装release package 12345#yum localinstall platform-and-version-specific-package-name.rpmyun install http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql57-community-release-el7-10.noarch.rpmyum repolist enabled | grep "mysql.*-community.*" 选择一个release series 默认是最新的GA series，当前最新是MySQL5.7。 查看所有的MySQL Yum repository: yum repolist all | grep mysql 安装最新MySQL不需要配置，而安装先前的版本则需要指定GA series。disable最新的GA series并且enable需要的GA series。 123yum-config-manager --disable mysql57-communityyum-config-manager --enable mysql56-community 或者手动创建repo，可直接定义版本 123456[mysql57-community]name=MySQL 5.7 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.7-community/el/7/$basearch/enabled=1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 安装MySQL 在安装MySQL过程中出现错误，请务必查看日志文件。 123yum install -y mysql-community-server mysql-community-client#也可不安装客户端 开启MySQL Server 1234service mysqld start#Starting mysqld:[ OK ]service mysqld status 在服务器初始启动时，如果服务器的数据目录为空，则会发生一下情况： 服务器已初始化 SSL certificate and key files 在数据目录中生成 validate_password已安装并启用 超级用户账户’root’@’localhost’被创建，超级用户密码被设置并被存储在error log files 这一点和以前版本有很大区别，我被坑惨了 注意： ValidPassword的默认密码策略要求包含大写字母、小写字母、数字和特殊字符，并且密码长度至少为8个字符 123456789101112131415161718192021222324252627#查看初始密码grep &apos;temporary password&apos; /var/log/mysqld.log#无法使用mysqladmin修改密码，需要登录mysql后修改mysql -uroot -p#重置密码ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;NewPass4!;#如果找不到初始密码vim /etc/my.cnf#在[mysqld]最后行加上skip-grant-tables实现无认证登录#重启MySQLUPDATE mysql.user SET authentication_string =PASSWORD(&apos;新密码&apos;) WHERE USER=&apos;xxx&apos;;#修改默认密码策略#更改密码强度set global validate_password_policy=0;#设置密码最小长度set global validate_password_length=4; 使用Yum安装额外的MySQL产品和组件 你可使用Yum安装和管理MySQL的个别组件。 123456yum --disablerepo=\* --enablerepo='mysql*-community*' list availableyum install package-name#栗子yum install mysql-community-libs 在Linux上使用Oracle提供的RPM包安装MySQLInstalling MySQL on Linux Using RPM Packages from Oracle MySQL Community Edition的rpm包如下： 包名 描述 mysql-community-server Database server and related tools mysql-community-client MySQL client applications and tools mysql-community-common Common files for server and client libraries mysql-community-server-minimal Minimal installation of the database server and related tools mysql-community-devel Development header files and libraries for MySQL database client applications mysql-community-libs Shared libraries for MySQL database client applications mysql-community-libs-compat Shared compatibility libraries for previous MySQL installations mysql-community-embedded MySQL embedded library mysql-community-embedded-devel Development header files and libraries for MySQL as an embeddable library mysql-community-test Test suite for the MySQL server 123456789#rpm -qpl mysql-community-server-version-distribution-arch.rpm#yum install mysql-community-&#123;server,client,common,libs&#125;-*wget http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql-community-server-5.7.20-1.el7.x86_64.rpmwget http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql-community-client-5.7.20-1.el7.x86_64.rpmyum install -y mysql-community-server-5.7.20-1.el7.x86_64.rpm mysql-community-client-5.7.20-1.el7.x86_64.rpm Linux RPM包MySQL开发区的安装布局： 文件或资源 位置 Client programs and scripts /usr/bin mysqld server /usr/sbin configuration file /etc/my.cnf data directory /var/lib/mysql error log file /var/log/mysqld.log Value of secure_file_priv /var/lib/mysql-files System V init script /etc/init.d/mysqld Systemd service mysqld pid file /var/run/mysql/mysqld.pid socket /var/lib/mysql/mysql.sock Keyring directory /var/lib/mysql-keyring Unix manual pages /usr/share/man include (header) files /usr/include/mysql Libraries /usr/lib/mysql Miscellaneous support files (for example, error messages, and character set files) /usr/share/mysql The installation also creates a user named mysql and a group named mysql on the system. 注意安装MySQL会在系统上生成一个名为mysql的用户和群组安装以前的MySQL版本可能会创建my.cnf配置文件。强烈建议先将my.cnf进行迁移，然后删除它。之后才安装MySQL 用systemd管理MySQL ServerManaging MySQL Server with systemd systemd综述Overview of systemd systemd提供了MySQL Server的自动开启和关闭，使用systemctl命令进行管理。 或者，使用system V系统兼容的service命令。 123systemctl &#123;start|stop|restart|status&#125; mysqldservice mysqld &#123;start|stop|restart|status&#125; 对systemd的支持包括这些文佳： mysqld.service systemd服务单元配置文件，以及有关MySQL服务的详细信息 mysqld@.service 用于管理多个MySQL实例 mysqld.tmpfiles.d 包含支持临时文件功能的信息 mysqld_pre_systemd 支持单元文件的脚本 为MySQL配置systemdConfiguring systemd for MySQL 为MySQL添加或修改systemd选项，参考如下方法： 使用一个本地化的systemd配置文件 安排systemd为MySQL Server进程设置环境变量 设置MYSQLD_OPTS systemd变量 创建/etc/systemd/system/mysqld.service本地化systemd配置文件，这里讨论的是将此文件名作为override.conf： 1234567891011121314[Service]LimitNOFILE=max_open_filesPIDFile=/path/to/pid/fileNice=nice_levelLimitCore=core_file_limitEnvironment="LD_PRELOAD=/path/to/malloc/library"Environment="TZ=time_zone_setting"#LimitNOFILE: 文件描述符数量#LimitCore: 最大核心文件大小#Nice: 优先级#LD_PRELOAD: 特定内存分配库#TZ: 指定时区 修改mysqld: 1systemctl edit mysqld 重新加载systemd配置，然后重启MySQL service： 123systemctl daemon-reloadsystemctl restart mysqld 可在override.conf中设置如下参数： 1234[Service]PIDFile=/var/run/mysqld/mysqld-custom.pidExecStart=ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld-custom.pid $MYSQLD_OPTS 在/etc/sysconfig/mysql下指定值： 12345LD_PRELOAD=/path/to/malloc/libraryTZ=time_zone_settingsystemctl restart mysqld 使用systemd配置多个MySQL实例Configuring Multiple MySQL Instances Using systemd 由于systemd具有在平台上管理多个MySQL实例的能力，而不必须需要mysqld_multi和mysqld_multi.server。 若要使用多实例(multiple-instance)功能，请修改/etc/my.cnf文件以包含每个实例的关键选项配置。例如，管理replication01和replication02两个实例： 123456789101112131415vim /etc/my.cnf[mysqld@replica01]datadir=/var/lib/mysql-replica01socket=/var/lib/mysql-replica01/mysql.sockport=3307log-error=/var/log/mysqld-replica01.log[mysqld@replica02]datadir=/var/lib/mysql-replica02socket=/var/lib/mysql-replica02/mysql.sockport=3308log-error=/var/log/mysqld-replica02.log 这里的名称使用@作为分隔符(delimiter)，因为这个是systemd支持的唯一分隔符。 管理两个实例: 12345678910111213systemctl start mysqld@replica01systemctl start mysqld@replica02systemctl enable mysqld@replica01systemctl enable mysqld@replica02#使用通配符systemctl status &apos;mysqld@replica*&apos;systemctl stop mysqld@replica0&#123;1,2&#125; 对于同一个机器上的不同MySQL实例，systemd自动使用不同的单元文件。在unit file中，%I和%i用于@标记后传入参数，用于管理特定实例。 12345678910111213141516171819#像这样mysqld --defaults-group-suffix=@%I ...systemctl status mysqld@replica01# mysqld@replica01.service - MySQL Server# Loaded: loaded (/usr/lib/systemd/system/mysqld@.service; disabled; vendor preset: disabled)# Active: active (running) since Tue 2018-02-27 12:18:34 CST; 1min 6s ago# Docs: man:mysqld(8)# http://dev.mysql.com/doc/refman/en/using-systemd.html# Process: 3927 ExecStart=/usr/sbin/mysqld --defaults-group-suffix=@%I --daemonize --pid-file=/var/run/mysqld/mysqld-%i.pid $MYSQLD_OPTS (code=exited, status=0/SUCCESS)# Process: 3845 ExecStartPre=/usr/bin/mysqld_pre_systemd %I (code=exited, status=0/SUCCESS)#Main PID: 3930 (mysqld)# CGroup: /system.slice/system-mysqld.slice/mysqld@replica01.service# `-3930 /usr/sbin/mysqld --defaults-group-suffix=@replica01 --daemonize --pid-file=/var/run/mysqld/mysqld-replica01.pid##eb 27 12:18:27 zabbix.me systemd[1]: Starting MySQL Server...#eb 27 12:18:34 zabbix.me systemd[1]: Started MySQL Server. 从mysqld_safe迁移到systemdMigrating from mysqld_safe to systemd 因为mysqld_safe没有安装在使用systemd管理MySQL的平台上，所以以前需要为该程序指定选项：[mysqld_safe] 一些[mysqld_safe]的选项也能被[mysqld]支持 一些[mysqld_safe]的选项类似于[mysqld]选项 从源码安装MySQLInstalling MySQL from Source 从源代码构建MySQL使我们能够自定义构建参数(parameter)、编译器优化(compiler optimization)和安装位置(installation location)。 在使用源码安装前，请检查Oracle是否为你的平台生成预编译的二进制发行版，以及是否适合你。Oracle付出了很多努力确保提供的二进制文件具有最佳的性能选择。 源码安装系统需求：使用源码安装MySQL需要多种开发工具。 使用源码安装MySQL，必须满足一下系统需求： CMake, which is used as the build framework on all platforms A good make program A working ANSI C++ compiler The Boost C++ libraries are required to build MySQL The ncurses library Sufficient free memory Perl is needed if you intend to run test scripts 使用standard source distribution安装MySQL，需要以下工具来unpack分发文件： For a .tar.gz compressed tar file: tar For a .zip Zip archive: zip For an .rpm RPM package: rpmbuild 用于源码安装的MySQL布局MySQL Layout for Source Installation 默认地，再从源码编译后安装MySQL时，安装步骤会将文件安装在/usr/local/mysql下。 使用标准源码发行版安装MySQLInstalling MySQL Using a Standard Source Distribution 从一个标准源码发行版安装MySQL： 确保系统满足工具需求 获取发行文件 配置、构建和安装 执行安装后程序 如果是source RPM: 1rpmbuild --rebuild --clean MySQL-VERSION.src.rpm 如果是compressed tar file 或 zip archive source: 12345678910111213141516171819202122232425262728# Preconfiguration setupshell&gt; groupadd mysqlshell&gt; useradd -r -g mysql -s /bin/false mysql# Beginning of source-build specific instructionsshell&gt; tar zxvf mysql-VERSION.tar.gzshell&gt; cd mysql-VERSIONshell&gt; mkdir bldshell&gt; cd bldshell&gt; cmake ..shell&gt; makeshell&gt; make install# End of source-build specific instructions# Postinstallation setupshell&gt; cd /usr/local/mysqlshell&gt; mkdir mysql-filesshell&gt; chown mysql:mysql mysql-filesshell&gt; chmod 750 mysql-filesshell&gt; bin/mysqld --initialize --user=mysqlshell&gt; bin/mysql_ssl_rsa_setupshell&gt; bin/mysqld_safe --user=mysql &amp;# Next command is optionalshell&gt; cp support-files/mysql.server /etc/init.d/mysql.server /sbin/nologin和/bin/false的区别 /bin/false是最严格的禁止login选项，一切服务都不能用 mongod:x:996:994:mongod:/var/lib/mongo:/bin/false /sbin/nologin只是不允许系统login，可以使用其他服务 ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin 执行预配置(preconfiguration)设置 在Unix上，设置MySQL用户和组，用于运行和执行MySQL服务器和数据库目录。 获得和解包distribution 选择要解压分发的目录，并将位置更改到其中。 1234tar zxvf mysql-VERSION.tar.gz#gunzip &lt; mysql-VERSION.tar.gz | tar xvf -#cmake -E tar zxvf mysql-VERSION.tar.gz 使用开发源码树安装MySQLInstalling MySQL Using a Development Source Tree install MySQL from the latest development source codew hich is hosted on GitHub: https://github.com/mysql/mysql-server 设置一个MySQL git repository 克隆MySQL git repository到本机 1git clone https://github.com/mysql/mysql-server.git 查看 1cd mysql-server 使用git branch -r查看远程MySQL分支 123cd mysql-servergit branch -r 查看分支 123cd mysql-servergit branch 切换分支 123cd mysql-servergit checkout 5.7 获取远程MySQL git repository更新 123cd mysql-servergit pull 检查提交历史 12345cd mysql-servergit log#也可在MySQL GitHub上查看commit history 在克隆MySQL git repository并切换到需要的分支后，便可以从源代码构建MySQL Server。 在生产机器上从分发源码树安装构件时要小心，安装命令可能会覆盖您的实时发行版安装。 MySQL源码配置选项MySQL Source-Configuration Options CMake程序提供了一个强大的如何配置MySQL源码发行版的控制。 具体链接参考: https://dev.mysql.com/doc/refman/5.7/en/source-configuration-options.html 处理MySQL编译问题Dealing with Problems Compiling MySQL 如果CMake先前已经运行过，那么现在运行的CMake可能使用先前的调用过程中收集到的信息。这些信息存储在 CMakeCache.txt。在CMake启动时，它会寻找和读取此文件。 每次运行CMake，必须再次运行make才能重新编译。 防止使用old object file或配置文件: 12make cleanrm CMakeCache.txt 安装之后的设置和测试Postinstallation Setup and Testing 在安装MySQL后你应该做的事： 如有必要，初始化数据目录并创建MySQL授权表 开启Server并确保它可以正常访问 将密码分配给授权表中的root用户 可选地，设置Server自启动 可选地，填写时区表，以便识别时区 初始化数据目录Initializing the Data Directory 安装MySQL之后，必须初始化数据目录，包括mysql系统数据库中的表。有些安装方法会自动初始化，有些则需要手动初始化。当然，如果修改了默认数据目录位置，那么也是需要手动初始化的。 初始化数据库目录，主要是包含了初始MySQL授权表(grant table)的MySQL服务器，这些表确定了如何允许用户连接到服务器。但是，初始化数据目录是不会覆盖(overwrite)任何现有权限表，因此在任何情况下运行都是安全的。 数据目录初始化会在MySQL数据库汇总创建time zone，但不会填充它，所以它是空的。 123456789101112131415cd /usr/local/mysqlmkdir mysql-fileschown mysql:mysql ./mysql-fileschmod 750 ./mysql-files#--user#使数据库目录文件属于mysql用户，以确保Server有读取权限/usr/local/mysql/bin/mysqld --initialize --user=mysql#开启安全连接/usr/local/mysql/bin/mysql_ssl_rsa_setup 使用mysqld手动初始化数据目录Initializing the Data Directory Manually Using mysqld 1234567891011121314151617181920212223242526cd /usr/local/mysql/bin#使数据库目录文件属于mysql用户，以确保Server有读取权限#默认是secure，会生成root初始密码./mysqld --initialize --user=mysql#不生成root初始密码./bin/mysqld --initialize-insecure --user=mysql#指定目录--basedir=/usr/local/mysql--datadir=/var/lib/mysql#或者将其写入配置文件vim /etc/my.cnf[mysqld]basedir=/usr/local/mysqldatadir=/var/lib/mysql#指定配置文件初始化./mysqld --defaults-file=/etc/mysql.cnf --initialize --user=mysql 使用mysql_install_db初始化数据目录Initializing the Data Directory Manually Using mysql_install_db 1234567891011121314151617cd /usr/local/mysql/bin#mysql_install_db命令会创建数据目录，并在数据目录下创建mysql数据库和授权表./mysql_install_db --user=mysql#指定目录是必须的--basedir=/usr/local/mysql--datadir=/var/lib/mysql./mysqld_safe --user=mysql &amp;#systemctl start mysqldmysql -u root -p xxxmysql&gt;SET PASSWORD FOR 'root'@'localhost' = PASSWORD('new_password'); Starting the Server Start the MySQL server like this if your installation includes mysqld_safe /usr/local/mysql/binmysqld_safe --user=mysql &amp; Start the server like this if your installation includes systemd support systemctl start mysqld 使用non-root用户运行MySQL服务很重要 如有错误请查看日志 Testing the Server执行一些简单测试以保证Server正常工作。 1234567891011121314151617181920#使用mysqladmin验证Server正在运行mysqladmin --helpmysqladmin -uuser -ppasswd versionmysqladmin -uuser -ppasswd variablesmysqladmin -user -ppasswd shutdown# 使用mysqlshow查看数据库mysqlshow -uuser -ppasswd#查看指定数据库信息mysqlshow -uuser -ppasswd mysql#读取信息#-e,Execute command and quitmysql -uuser -ppasswd -e "SELECT user, host from mysql.user" 保护初始化MySQL账户Securing the Initial MySQL Accounts 在安装MySQL后，root账户密码可能已经被分配。 mysql.user授权表定义了初始化MySQL用户账户和它们的访问权限。MySQL5.7只创建了一个&#39;root&#39;@&#39;localhost&#39;账户，但早期的版本可能有多个用户。 请务必为每一个MySQL账户创建密码。 查看用户： 1234567891011121314#存储在authentication_string列中的密码可能包含无法正常显示的二进制数据#所以将其转换为十六进制mysql&gt; SELECT user, host, hex(authentication_string) FROM mysql.user;mysql&gt; SELECT user, host, authentication_string FROM mysql.user;#或mysql -uuser -ppasswd -e "SELECT user, host, hex(authentication_string) FROM mysql.user;"#5.7以前的版本mysql&gt; mysql&gt; SELECT user, host, password FROM mysql.user;#或mysql -uuser -ppasswd -e "SELECT user, host, password FROM mysql.user;" 为root账户分配密码 12345678910#5.7.6mysql&gt; ALTER USER user IDENTIFIED BY &apos;new_passwd&apos;;mysql&gt; ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;new_passwd&apos;;#5.7.6前mysql&gt; SET PASSWORD FOR username = PASSWORD(&apos;new_passwd&apos;);mysql&gt; SET PASSWORD FOR &apos;root&apos;@&apos;localhost&apos; = PASSWORD(&apos;new_passwd&apos;); 给anonymous账户分配密码 1mysql&gt; SET PASSWORD FOR &apos;&apos;@&apos;localhost&apos; = PASSWORD(&apos;new_passwd&apos;); 移除匿名账户 1mysql&gt; DROP USER &apos;&apos;@&apos;localhost&apos;; 升级或降级MySQLUpgrading or Downgrading MySQL 升级是一个常见的过程。请在测试系统上确保运行正常后再实施到生产环境 降级不太常见。一般是由于新版本在生产环境上发生某些兼容性或性能问题，并且是在测试环境中没有发现的情况下，从而需要降级。请现在测试系统上运行正常后再实施到生产环境。 升级MySQL请使用有管理权限的MySQL账户执行升级相关命令。(如root账户) MySQL升级策略MySQL Upgrade Strategies 升级方法 直接升级(In-Place Upgrade) 包含关闭旧版MySQL，替换为新的MySQL版本，在现有数据目录上重启MySQL，运行mysql_upgrade 逻辑升级(Logical Upgrade) 包含使用mysqldump导出现有数据文件，安装新版MySQL，导入数据文件到新版MySQL，运行mysql_upgrade 升级路径 只支持GA release之间 这是一个发行系列的升级 如5.6.x到5.6.y 升级到下一个版本之前，建议先升级到最新版本 如先升级到5.6最新版，再升级到5.7 不支持跳版本升级 如5.5到5.7 升级之前 升级之前，请一定备份数据 查看新版本的Release Note 删除和增加了什么功能 新版本依赖什么 如果在InnoDB中使用XA事务，则在升级之前运行XA恢复以检查未提交的XA事务 如果MySQL数据量很大，就地升级以后可能需要很长的时间才能进行转换 你可能会发现创建一个”dummy”数据库实例是很有用的，以及评估可能需要哪些转换以及执行这些转换所涉及的工作 无论在你安装或升级到一个MySQL新版本，建议重建和重装MySQL language interface 如PHP MySQL扩展 直接升级 配置MySQL执行slow shutdown innoDB在关闭前执行一个完整的清除和更改缓冲区合并，这确保数据文件在不同的版本的文件格式做好充分准备。 1mysql -u root -p --execute="SET GLOBAL innodb_fast_shutdown=0" 关闭MySQL Server 1mysql -uroot -p shutdown 升级MySQL 开启新版MySQL 运行mysql_upgrade mysql_upgrade检查所有数据库中的所有表与当前版本MySQL的不兼容性。 1234mysql_upgrade -uroot -p#Upgrade process completed successfully.#Checking if update is needed. 关闭和重启MySQL Server来确保改变生效 123mysqladmin -uroot -p shutdownsystemctl start mysqld 逻辑升级 导出所有数据 1234567mysqldump -uroot -p --all-databases --force &gt; mysqldb_backup.sql#-f, --force Continue even if we get an SQL error#Use the --routines and --events options if your databases include stored programs#--add-drop-database Add a DROP DATABASE before each create.mysqldump -uroot -p --add-drop-table --routines --events --all-databases --force &gt; mysqldb_backup.sql 关闭MySQL Server 1mysqladmin -uroot -p shutdown 安装新版MySQL 初始化MySQL并启动 载入数据文件 1mysql -uroot -p --force &lt; ./mysqldb_backup.sql 运行mysql_upgrade 1234mysql_upgrade -uroot -p#Upgrade process completed successfully.#Checking if update is needed. 关闭并重启MySQL Server以确保更改生效 通过MySQL Yum Repository进行升级Upgrading MySQL with the MySQL Yum Repository 选择一个target series 默认情况下，MySQL Yum Repository会将MySQL升级到该release系列的最新版本。如5.7.1升级到5.7.10。 如果要升级到其他release(如5.6到5.7)，就必须要先禁用此subrepository，并选择和启用新的subrepository。 As a general rule, to upgrade from one release series to another, go to the next series rather than skipping a series. 升级MySQL 1yum update mysql-server mysql-client 重启MySQL MySQL Server总是在Yum更新之后重启，一旦重启，请运行mysql_upgrade来检查旧数据与升级软件之间的任何不兼容问题。 1234mysql_upgrade -uroot -p#Upgrade process completed successfully.#Checking if update is needed. 升级Shared Client Libraries 所以说，用yum repository安装软件是很方便的。不管是在管理还是升级等方面… 通过直接下载RPM包升级MySQL直接下载mysql相应组件的rpm进行升级。建议备份好配置文件。 12345wget http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql-community-server-5.7.20-1.el7.x86_64.rpmwget http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql-community-client-5.7.20-1.el7.x86_64.rpmyum install mysql-community-server-5.7.20-1.el7.x86_64.rpm mysql-community-client-5.7.20-1.el7.x86_64.rpm mysql降级MySQL降级类似于MySQL升级。也包含有直接降级和逻辑降级。 重建或修复表或索引Rebuilding or Repairing Tables or Indexes MySQL处理数据类型和字符集的方式的更改 表维修或升级(mysqlcheck, mysql_upgrade) 重建表的方法： Dump and Reload ALTER TABLE REPAIR TABLE Dump and Reload Method 由于MySQL升级/降级之后，不同版本的MySQL无法处理这些表，则需要转储和重载的方法来重建表。 12345678910mysqldump -uroot -p --all-databases --force &gt; mysql_backdb.sqlmysql -uroot -p --force &lt; mysql_backdb.sql#某个库或表mysqldump -uroot -p --databases test --force &gt; db_test.sqlmysql -uroot -p test &lt; db_test.sqlmysqldump -uroot -p --databases test --tables table222 &gt; table222.sqlmysql -uroot -p test &lt; table222.sql ALTER TABLE Method 更改表以使用它已经拥有的存储引擎。 1ALTER TABLE test ENGINE = InnoDB; REPAIR TABLE Method REPAIR TABLE仅适用于MyISAM， ARCHIVE和 csv 表。 mysqlcheck --repair提供了对REPAIR TABLE的命令行访问。 12345REPAIR TABLE t1;mysqlcheck --repair --databases db_name ...mysqlcheck --repair --all-databases 复制MySQL数据库到其他机器Copying MySQL Databases to Another Machine 在需要为不同体系架构之间传输MySQL数据库时，可使用mysqldump创建包含SQL语句的.sql文件，然后复制到另外的计算机上，将其作为输入提供给MySQL客户端。 不要忘记复制mysql数据库，因为这个存储授权表的地方。 123456mysqldump --host &apos;remote-host&apos; -uxxx -p --compress --all-databases | mysql -uxxx -pmysqldump --host &apos;remote-host&apos; -uxxx -p --compress db_name | mysql -uxxx -p db_namemysqladmin -uxxx -p flush-privileges Tutorial如何使用MySQL client程序来创建和使用数据库。 连接和断开服务器Connecting to and Disconnecting from the Server Like this: 不建议把密码直接写在命令行上 host表示了MySQL Server运行在的机器 某些MySQL允许匿名用户连接 -ppassword, not as -p password 123456789101112131415mysql --host host --user username -p#maybe not default portmysql --host host --user username -p --port port#匿名用户连接mysql#退出mysql&gt; QUIT#Unixmysql&gt; Ctrl+D 输入查询Entering Queries 1234567891011121314151617#简单查询mysql&gt; SELECT VERSION(), CURRENT_DATE;#简单计算SELECT SIN(PI()/2), (4+1)*5;#一行中输入多个语句SELECT VERSION(); SELECT NOW();#多行输入一个命令mysql&gt; SELECT -&gt; USER() -&gt; , -&gt; CURRENT_DATE; 这QUERY说明了有关MySQL的几件事： MySQL查询通常由一个SQL statement和;组成 MySQL将查询发送给服务器并返回结果，然后打印下一个mysql&gt;提示 MySQL以表格形式(rows and columns)显示查询输出 MySQL显示返回多少行，以及执行查询花费了多长时间 MySQL查询不区分大小写，但建议使用大写 MySQL支持在一行中输入多个语句 MySQL支持一个命令多行输入 MySQL提示符： Prompt Meaning mysql&gt; 准备新查询 -&gt; 等待多行查询的下一行 &#39;&gt; 等待下一行，等待单引号开头的字符串的完成 &quot;&gt; 等待下一行，等待双引号字开头的字符串的完成 \&gt;` 等待下一行，等待以反引号开始的标识符的完成 /*&gt; 等待下一行，等待以/*开头的注释的完成–&gt;/*comments*/ 创建和使用数据库Creating and Using a Database 大致操作： Create a database Create a table Load data into the table Retrieve data from the table in various ways Use multiple tables 123456789101112131415161718#显示数据库#不能显示你没有权限的数据库mysql&gt; SHOW DATABASES;#mysql数据库描述用户访问权限#test数据库通常作为用户尝试使用工作区#访问数据库mysql&gt; USE test;#USE和QUIT一样可以不使用分号，使用也无妨#USE只能是一个单行#授权#GRANT ALL ON da_name.table TO 'username'@'host';mysql&gt; GRANT ALL ON test.* TO 'test'@'127.0.0.1'; 创建和选择数据库Creating and Selecting a Database Unix是区分大小写的(case-sensitive)，这与SQL keyword不一致。请注意。 12345678910mysql&gt; CREATE DATABASE db01;mysql&gt; USE db01;#也可在mysql连接时直接指定数据库mysql -u username -p db01#查看当前选择的数据库mysql&gt; SELECT DATABASE(); 创建表Creating a Table 困难的部分是决定数据库的结构应该是什么： 你需要哪些表以及每个表中应该包含哪些列。 VARCHAR对于name，owner，species来说是一个不错的选择，因为column值的长度有所不同。DATE对于出生和死亡column来说很不错。如果以后你发现你需要更长的字段，MySQL提供了一个ALTER TABLE语句来修改。 12345678910111213141516171819202122#创建一个宠物表mysql&gt; CREATE TABLE pet (name VARCHAR(20), owner VARCHAR(20), -&gt; species VARCHAR(20), sex CHAR(1), birth DATE, death DATE);mysql&gt; SHOW TABLES;#验证表格#如果你忘记了表中列的名称或类型，使用DESCRIBEmysql&gt; DECRIBE pet;+---------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+---------+-------------+------+-----+---------+-------+| name | varchar(20) | YES | | NULL | || owner | varchar(20) | YES | | NULL | || species | varchar(20) | YES | | NULL | || sex | char(1) | YES | | NULL | || birth | date | YES | | NULL | || death | date | YES | | NULL | |+---------+-------------+------+-----+---------+-------+6 rows in set (0.00 sec) 将数据载入表格Loading Data into a Table 假设pet表信息如下： name owner species sex birth death PetA Aa cat f 1993-02-04 PetB Bb cat m 1994-03-17 PetC Cc dog f 1989-05-13 PetD Aa dog m 1979-08-25 1995-02-21 PetE Cc bird 1991-02-17 你可以创建一个pet.txt文本文件，每行包含一个记录，值由制表符分割，并按照CREATE TABLE语句中列出的顺序给出。 12345678vim pet.txtPetA Aa cat f 1993-02-04 \NPetB Bb cat m 1994-03-17 \NPetC Cc dog f 1989-05-13 \NPetD Aa dog m 1979-08-25 1995-02-21PetE Cc bird \N 1991-02-17 \N 将pet.txt载入pet表中： 123456789101112131415161718192021222324252627mysql&gt; LOAD DATA LOCAL INFILE '/path/file.txt' INTO TABLE table_name;mysql&gt; LOAD DATA LOCAL INFILE '/home/zhang/pet.txt' INTO TABLE pet;Query OK, 5 rows affected, 0 warnings (0.00 sec)Records: 5 Deleted: 0 Skipped: 0 Warnings: 0mysql&gt; SELECT * FROM pet;+-------+-------+---------+------+------------+------------+| name | owner | species | sex | birth | death |+-------+-------+---------+------+------------+------------+| PetA | Aa | cat | f | 1993-02-04 | NULL || PetB | Bb | cat | m | 1994-03-17 | NULL || PetC | Cc | dog | f | 1989-05-13 | NULL || PetD | Aa | dog | m | 1979-08-25 | 1995-02-21 || PetE | Cc | bird | NULL | 1991-02-17 | NULL |+-------+-------+---------+------+------------+------------+5 rows in set (0.00 sec)#通过命令行载入mysql&gt; INSERT INTO pet -&gt; VALUES ('PetF', 'Ff', 'hamster', 'f', '1999-03-21', NULL) -&gt; ;Query OK, 1 row affected (0.00 sec) 从表中检索信息Retrieving Information from a Table SELECT语句用于从表中提取信息： 123SELECT what_to_selectFROM which_tableWHERE condition; 查询所有数据Selecting All Data 1234567mysql&gt; SELECT * FROM pet;mysql&gt; DELETE FROM pet;mysql&gt; UPDATE pet SET birth = '1989-06-17' WHERE name = 'PetC'; 查询特定行Selecting Particular Rows 当一个表很大时，你通常不想看到整个表。 123456789101112131415161718192021#条件查询mysql&gt; SELECT * FROM pet WHERE name = 'PetA';mysql&gt; SELECT * FROM pet WHERE owner = 'Cc';mysql&gt; SELECT * FROM pet WHERE birth &gt;= '1990-01-01';#ANDmysql&gt; SELECT * FROM pet WHERE species = 'dog' AND sex = 'f';#ORmysql&gt; SELECT * FROM pet WHERE species = 'dog' OR species = 'bird';#AND和OR也可以混合使用mysql&gt; SELECT * FROM pet WHERE (species = 'cat' AND sex = 'm') OR (species = 'dog' AND sex='f'); 查询特定列Selecting Particular Columns 12345678910111213141516171819mysql&gt; SELECT name FROM pet;mysql&gt; SELECT name, species FROM pet;#获取唯一结果mysql&gt; SELECT DISTINCT species FROM pet;+---------+| species |+---------+| cat || dog || bird |+---------+3 rows in set (0.00 sec)mysql&gt; SELECT name, species, birth FROM pet WHERE species = 'dog' OR species = 'cat'; 行排序Sorting Rows 使用ORDER BY语句对结果进行排序。默认排序顺序是升序。 123456789101112131415mysql&gt; SELECT name, birth FROM pet ORDER BY birth;+------+------------+| name | birth |+------+------------+| PetD | 1979-08-25 || PetC | 1989-06-17 || PetE | 1991-02-17 || PetA | 1993-02-04 || PetB | 1994-03-17 |+------+------------+5 rows in set (0.00 sec)#倒序mysql&gt; SELECT name, birth FROM pet ORDER BY birth DESC; 可对多列进行排序，也可按不同的方向对不同的列进行排序。 12345678910111213141516mysql&gt; SELECT name, species, birth FROM pet -&gt; ORDER BY species, birth DESC;+------+---------+------------+| name | species | birth |+------+---------+------------+| PetE | bird | 1991-02-17 || PetB | cat | 1994-03-17 || PetA | cat | 1993-02-04 || PetC | dog | 1989-06-17 || PetD | dog | 1979-08-25 |+------+---------+------------+5 rows in set (0.00 sec)mysql&gt; SELECT name, species, birth FROM pet -&gt; ORDER BY species DESC, birth DESC 日期计算Date Calculations MySQL提供了几个函数用于日期计算。如计算年龄或提取日期一部分等。 TIMESTAMPDIFF() 使用TIMESTAMPDIFF()函数计算pet的年龄。它的两个参数为两个相隔的日期 12345678910111213141516171819202122232425262728mysql&gt; SELECT name, species, birth, CURDATE(), -&gt; TIMESTAMPDIFF(YEAR, birth, CURDATE()) AS age -&gt; FROM pet -&gt; ORDER BY age DESC;+------+---------+------------+------------+------+| name | species | birth | CURDATE() | age |+------+---------+------------+------------+------+| PetD | dog | 1979-08-25 | 2018-03-01 | 38 || PetC | dog | 1989-06-17 | 2018-03-01 | 28 || PetE | bird | 1991-02-17 | 2018-03-01 | 27 || PetA | cat | 1993-02-04 | 2018-03-01 | 25 || PetB | cat | 1994-03-17 | 2018-03-01 | 23 |+------+---------+------------+------------+------+5 rows in set (0.00 sec)#死去的pet的agemysql&gt; SELECT name, species, birth, death, -&gt; TIMESTAMPDIFF(YEAR, birth, death) AS age -&gt; FROM pet -&gt; WHERE death IS NOT NULL -&gt; ORDER BY age;+------+---------+------------+------------+------+| name | species | birth | death | age |+------+---------+------------+------------+------+| PetD | dog | 1979-08-25 | 1995-02-21 | 15 |+------+---------+------------+------------+------+1 row in set (0.00 sec) YEAR() 年 MONTH() 月 DAYOFMONTH() 日 1234567891011121314151617181920212223242526mysql&gt; SELECT name, birth, -&gt; YEAR(birth) AS bir_year, -&gt; MONTH(birth) AS bir_month, -&gt; DAYOFMONTH(birth) AS bir_day -&gt; FROM pet;+------+------------+----------+-----------+---------+| name | birth | bir_year | bir_month | bir_day |+------+------------+----------+-----------+---------+| PetA | 1993-02-04 | 1993 | 2 | 4 || PetB | 1994-03-17 | 1994 | 3 | 17 || PetC | 1989-06-17 | 1989 | 6 | 17 || PetD | 1979-08-25 | 1979 | 8 | 25 || PetE | 1991-02-17 | 1991 | 2 | 17 |+------+------------+----------+-----------+---------+5 rows in set (0.00 sec)#查找生日是2月的petmysql&gt; SELECT name, birth FROM pet WHERE MONTH(birth) =2;+------+------------+| name | birth |+------+------------+| PetA | 1993-02-04 || PetE | 1991-02-17 |+------+------------+ DATE_ADD() 将日期间隔添加到给定日期 12mysql&gt; SELECT name, birth FROM pet -&gt; WHERE MONTH(birth) = MONTH(DATE_ADD(CURDATE(), INTERVAL 1 MONTH)); 使用NULL值Working with NULL Values 从概念上讲，NULL value意味着一个缺失的未知值，它与其它值在某种程度上是不同的。 使用IS NULL和IS NOT NULL操作符 不能对NULL value使用算术运算符(arithmetic cpmparison operators) 如：=, &lt;, &gt;, &lt;&gt; 任何对NULL value的算术运算符的结果也是NULL value，所以无法得到有意义的结果 在MySQL中，0或NULL表示false，其他任何值都意味着true 两个NULL在GROUP BY中被认为是相等的 NULL在ORDER BY正向排序中首先显示。反之，最后显示 123456mysql&gt; SELECT 1 IS NULL, 1 IS NOT NULL;+-----------+---------------+| 1 IS NULL | 1 IS NOT NULL |+-----------+---------------+| 0 | 1 |+-----------+---------------+ 因此，完全可以将一个zero或empty string插入到一个NOT NULL的column中，因为这些值NOT NULL。 模式匹配Pattern Matching MySQL提供标准的SQL模式匹配以及基于扩展正则表达式的模式匹配形式。类似于Unix实用程序(vi, grep, sed…) SQL模式匹配允许: 使用_来匹配可以使用的任意单字符(single character) 使用%来匹配可以使用的任意数目的字符(arbitrary number of characters) SQL模式不区分大小写 使用LIKE或NOT LIKE而不是=或&lt;&gt; 12345678910111213141516mysql&gt; SELECT * FROM pet WHERE name LIKE '%b';+------+-------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+------+-------+---------+------+------------+-------+| PetB | Bb | cat | m | 1994-03-17 | NULL |+------+-------+---------+------+------------+-------+mysql&gt; SELECT * FROM pet WHERE name LIkE '___A' or name LIKE '___C';+------+-------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+------+-------+---------+------+------------+-------+| PetA | Aa | cat | f | 1993-02-04 | NULL || PetC | Cc | dog | f | 1989-06-17 | NULL |+------+-------+---------+------+------------+-------+ MySQL提供的其它类型的模式匹配使用扩展的正则表达式： REGEXP 或 RLIKE NOT REGEXP 或 NOT RLIKE 了解正则表达式知识 123456789101112131415161718192021222324252627282930313233343536373839mysql&gt; SELECT * FROM pet WHERE name RLIKE '^pet[AB]';+------+-------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+------+-------+---------+------+------------+-------+| PetA | Aa | cat | f | 1993-02-04 | NULL || PetB | Bb | cat | m | 1994-03-17 | NULL |+------+-------+---------+------+------------+-------+mysql&gt; SELECT * FROM pet WHERE owner RLIKE 'c$';+------+-------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+------+-------+---------+------+------------+-------+| PetC | Cc | dog | f | 1989-06-17 | NULL || PetE | Cc | bird | NULL | 1991-02-17 | NULL |+------+-------+---------+------+------------+-------+#包含某个字符mysql&gt; SELECT * FROM pet WHERE name RLIKE 'ete';+------+-------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+------+-------+---------+------+------------+-------+| PetE | Cc | bird | NULL | 1991-02-17 | NULL |+------+-------+---------+------+------------+-------+#匹配字符个数mysql&gt; SELECT * FROM pet WHERE name RLIKE '^....$';mysql&gt; SELECT * FROM pet WHERE name RLIKE '^.&#123;4&#125;$';#强制区分大小写mysql&gt; SELECT * FROM pet WHERE name RLIKE BINARY '^Pet[AB]'; 行数计算Counting Rows 使用COUNT()计算行数 12345678910111213141516171819202122232425262728293031323334#总行数mysql&gt; SELECT COUNT(*) AS count FROM pet;+-------+| count |+-------+| 5 |+-------+#针对某个统计行数mysql&gt; SELECT owner, COUNT(*) FROM pet GROUP BY owner;+-------+----------+| owner | COUNT(*) |+-------+----------+| Aa | 2 || Bb | 1 || Cc | 2 |+-------+----------+#多个条件mysql&gt; SELECT species, sex, COUNT(*) FROM pet GROUP BY species, sex;+---------+------+----------+| species | sex | COUNT(*) |+---------+------+----------+| bird | NULL | 1 || cat | f | 1 || cat | m | 1 || dog | f | 1 || dog | m | 1 |+---------+------+----------+ 使用多个表Using More Than one Table 创建一个额外的宠物信息表： name date type remark Fluffy 1995-05-15 litter 4 kittens, 3 female, 1 male Buffy 1993-06-23 litter 5 puppies, 2 female, 3 male Buffy 1994-06-19 litter 3 puppies, 3 female Chirpy 1999-03-21 vet needed beak straightened Slim 1997-08-03 vet broken rib Bowser 1991-10-12 kennel Fang 1991-10-12 kennel Fang 1998-08-28 birthday Gave him a new chew toy Claws 1998-03-17 birthday Gave him a new flea collar Whistler 1998-12-09 birthday First birthday 12345mysql&gt; CREATE TABLE event ( name VARCHAR(20), date DATE, -&gt; type VARCHAR(15), remark VARCHAR(255) );mysql&gt; LOAD DATA INFILE '/path/event.txt' INTO TABLE event; 获取数据库和表的信息Getting Information About Databases and Tables 查看当前数据库 mysql&gt; SELECT DATABASE(); 查看当前数据库下的表 mysql&gt; SHOW TABLES; 查看表的结构 mysql&gt; DESCRIBE pet; 创建数据库 mysql&gt; CREATE DATABASE db_01; 创建表 mysql&gt; CREATE TABLE table_01 {c1 VARCHAR(10), c2 INT, ...}; 查看索引(如果存在) SHOW INDEX FROM table_01; 在批处理下使用mysqlUsing mysql in Batch Mode 在前面，我们都是使用MySQL交互式(interactively)输入命令并查看结果。但还可在批处理模式下运行MySQL。我们可以创建一个脚本文件，然后以这种方式执行脚本文件。 1234567mysql &lt; batch-filemsyql -h host -u user -p &lt; /path/batch-file#出现错误也继续运行msyql -h host -u user -p --force &lt; /path/batch-file 为什么要使用脚本： 如果需要反复(repeat)执行查询，将其写入脚本以避免每次执行时重新输入查询 通过复制和修改脚本文件从现有查询中生成新的查询 批处理模型在开发查询时也很有用，特别是对于多行语句。写错了直接修改脚本就好，而不必重新输入 如果查询产生大量输出，可通过传呼机而不是翻滚到屏幕的最上方 mysql &lt; batch-file | more 可以把输出捕获到一个文件中 mysql &lt; batch-file &gt; mysql.out 可将脚本文件分发给其他人 批处理模式下的MySQL输出更简洁 可使用mysql -t获得交互式数据格式 使用mysql -v将执行语句回显 在mysql命令行中载入脚本 mysql&gt; source filename; 或’mysql&gt; . filename; 常见查询Examples of Common Queries 在命令行使用mysql并选择数据库 1mysql db_name -u user -p 创建和填充表 12345678CREATE TABLE shop ( article INT(4) UNSIGNED ZEROFILL DEFAULT '0000' NOT NULL, dealer CHAR(20) DEFAULT '' NOT NULL, price DOUBLE(16,2) DEFAULT '0.00' NOT NULL, PRIMARY KEY(article, dealer));INSERT INTO shop VALUES (1,'A',3.45),(1,'B',3.99),(2,'A',10.99),(3,'B',1.45), (3,'C',1.69),(3,'D',1.25),(4,'D',19.95); 查看表内容 1SELECT * FROM shop; 列的最大值(maximum) 1234567SELECT MAX(article) AS article FROM shop;SELECT article, MAX(price) AS priceFROM shopGROUP BY article; 使用用户定义的变量(user-defined variables) 123mysql&gt; SELECT @min_price:=MIN(price),@max_price:=MAX(price) FROM shop;mysql&gt; SELECT * FROM shop WHERE price=@min_price OR price=@max_price; 使用外键(Foreign Keys) 在MySQL中，InnoDB表支持检查外键约束。外键约束不仅仅需要连接两个表。 123456789101112131415161718192021222324252627282930313233343536373839CREATE TABLE person ( id SMALLINT UNSIGNED NOT NULL AUTO_INCREMENT, name CHAR(60) NOT NULL, PRIMARY KEY (id));CREATE TABLE shirt ( id SMALLINT UNSIGNED NOT NULL AUTO_INCREMENT, style ENUM('t-shirt', 'polo', 'dress') NOT NULL, color ENUM('red', 'blue', 'orange', 'white', 'black') NOT NULL, owner SMALLINT UNSIGNED NOT NULL REFERENCES person(id), PRIMARY KEY (id));INSERT INTO person VALUES (NULL, 'Antonio Paz');SELECT @last := LAST_INSERT_ID();INSERT INTO shirt VALUES(NULL, 'polo', 'blue', @last),(NULL, 'dress', 'white', @last),(NULL, 't-shirt', 'blue', @last);INSERT INTO person VALUES (NULL, 'Lilliana Angelovska');SELECT @last := LAST_INSERT_ID();INSERT INTO shirt VALUES(NULL, 'dress', 'orange', @last),(NULL, 'polo', 'red', @last),(NULL, 'dress', 'blue', @last),(NULL, 't-shirt', 'white', @last); 在两个键上查找(Searching on Two Keys) 12SELECT field1_index, field2_index FROM test_tableWHERE field1_index = '1' OR field2_index = '1' 使用自动增量 AUTO_INCREMENT属性能够为新行生成一个唯一的标识符。 123456789101112131415CREATE TABLE animals ( id MEDIUMINT NOT NULL AUTO_INCREMENT, name CHAR(30) NOT NULL, PRIMARY KEY (id));INSERT INTO animals (name) VALUES ('dog'),('cat'),('penguin'), ('lax'),('whale'),('ostrich');#设置指定增量开始值mysql&gt; ALTER TABLE tbl AUTO_INCREMENT = 100; MySQL程序 MySQL程序概述Overview of MySQL Programs MySQL安装中有多个不同的程序： mysqldSQL daemon, MySQL Server, mysqld是执行大部分工作的主要程序 mysqld_safe服务器启动脚本mysqld_safe尝试去启动mysqld mysql.server服务器启动脚本此脚本用于System V系统，包含启动特定运行级别的系统服务脚本它调用mysqld_safe来启动MySQL Server mysql_multi可启动和关闭安装在系统上的多个服务器的启动脚本 comp_err在MySQL build/installation过程中使用从错误源文件中编译错误消息文件 mysql_install_db初始化MySQL(数据目录，授权表，并设置InnoDB系统表空间)通常用于首次安装MySQL时 mysql_plugin配置MySQL Server插件 mysql_secure_installation能够提高MySQL安装的安全性 mysql_ssl_rsa_setup如果这些文件丢失，该程序会创建支持安全连接所需的SSL证书和密钥文件以及RSA密钥对文件 mysql_tzinfo_to_sql从mysql数据库中加载时区表 mysql_upgrade在MySQL升级操作后使用它检查表的不兼容性并在必要时修复它们，并用更新版的MySQL的任何更改来更新授权表 mysql交互式输入SQL语句的命令行工具或执行一个批处理模式的文件 mysqladmin执行管理操作的客户端如创建或删除数据库，重新加载授权表，刷新表的磁盘…也可用获取服务器版本、状态、进程信息 mysqlcheck表格客户端用于检查、修复、分析和优化表格 mysqldump将MySQL数据库转储为SQL、文本或XML文件的客户端 mysqlimport使用LOAD DATA INFILE将文本文件导入各自表格的客户端 mysqlpump将MySQL数据库转转储为SQL文件的客户端 mysqlsh用于MySQL Server的高级命令行客户端和代码编辑器除了SQL外，MySQL Shell还为JS和Python提供了脚本功能 mysqlshow显示有关数据库、表、列和索引的信息的客户端 mysqlslap用于模拟MySQL Server的客户端负载并报告每个阶段的时间 MySQL管理和实用程序： innochecksumInnoDB脱机文件校验和程序 myisam_ftdump在MyISAM表中显示有关全文索信息 myisamchk描述，检查，优化和修复MyISAM表 myisamlog处理MyISAM日志文件 myisampack压缩MyISAM表以生成更小的只读表 mysql_config_editor能够将认证凭证存储在名为安全的加密登录路径文件中 mysqlbinlog从二进制日志中读取语句 mysqldumpslow读取和总结慢查询日志内容 MySQL程序开发实用程序： mysql_config一个shell脚本，用于在编译MySQL程序是生产所需的选项值 my_print_defaults：显示选项文件的选项组中存在哪些选项 resolve_stack_dump将数值堆栈跟踪转储解析为符号 杂项(Miscellaneous)工具： lz4_decompress解压缩使用LZ4压缩格式的mysqldump输出 perror显示系统或MySQL错误代码含义 replace再输入文本中执行字符串替换 resolveip将主机名解析为IP地址，反之亦然 zlib_decompress解压缩使用ZLIB压缩格式的mysqldump输出 Oracle公司还提供了MySQL Workbench GUI工具，用于管理、创建、知悉和评估查询，以及从其它关系数据库管理系统迁移到MySQL系统。 MySQL Client和Server间的通信使用如下环境变量： Environment Variable Meaning MYSQL_UNIX_PORT The default Unix socket file; used for connections to localhost MYSQL_TCP_PORT The default port number; used for TCP/IP connections MYSQL_PWD The default password, insecure MYSQL_DEBUG Debug trace options when debugging TMPDIR The directory where temporary tables and files are created 使用MySQL程序调用MySQL程序从命令行调用一个MySQL程序，输入程序名称和选项及参数。 1234$ mysql --user=root test$ mysqladmin extended-status variables$ mysqlshow --help$ mysqldump -u root personnel 连接到MySQL Server介绍如何连接到MySQL Server。 MySQL程序环境变量的优先级最低，命令行选项最高。你可在配置文件中指定程序的默认值，同时你又可以使用命令行选项覆盖它。MySQL选项按顺序处理，所以如果多次指定选型，则最后一个选项优先。 123mysql --hostname xx --port xx --user xx --password $&#123;dbname&#125; --protocol=TCPmysql -h -P -u -p $&#123;dbname&#125; --protocol值： TCP(all) SOCKET(Unix) PIPE(windows) MEMORY(windows) 你可以在选项文件的[client]部分指定连接参数: 12345[client]host=xxxport=xxxuser=xxxpassword=xxx 1234567mysqladmin -u user -p --count=1k --sleep=10 pingmysql -u user -pxxx --execute=&quot;DESCRIBE db.table&quot;#执行多个语句mysql -u root -p -e &apos;SELECT VERSION(); SELECT NOW()&apos; 配置文件大多数MySQL程序都可从选项文件中读取启动选项。 MySQL不保证配置文件的读取顺序。 Unix和Unix-Like平台的MySQL配置文件： 文件 描述 /etc/my.cnf 全局选项 /etc/mysql/my.cnf 全局选项 $SYSCONFDIR/my.cnf 全局选项 $MYSQL_HOME/my.cnf MySQL Server Only ~/.my.cnf 特定用户选项 ~/.mylogin.cnf 特定用户登录选项，Client Only default-extra-file 使用--defaults-extra-file指定的文件 配置文件解释： 空行被忽略 #号表示注释 前后空格将自动从选项名称和值中删除 [group]为其设置配置项的程序名或组名。在此之后，任何选项设置都会应用到指定组，知道给出结尾。选项组名称不区分大小写。 你可在选项值中使用转义序列\b, \t, \n, \r, \\, \s !include来包含其它配置文件 123456789101112131415161718192021DATADIRmysqld --datadir[mysqld]port=3306socket=/tmp/mysql.sockkey_buffer_size=16Mmax_allowed_packet=8M[mysql]port=3306socket=/tmp/mysql.sockno-auto-rehash[mysqldump]quick!include /home/mysql/myopt.cnf 影响配置文件的命令行选项 --print-defaults --defaults-extra-file --defaults-file --defaults-group-suffix --login-path --no-defaults 使用选项指定环境变量 1234567891011[mysql]max_allowed_packet=16M[mysqld]key_buffer_size=512Mmysql --max_allowed_packet=16Mshell&gt; mysql --max_allowed_packet=16*1024*1024mysql&gt; SET GLOBAL max_allowed_packet=16*1024*1024; MySQL Server mysqldThe MySQL Server mysql_safeMySQL Server Startup Script mysql.serverMySQL Server Startup Script mysqld_multiManage Multiple MySQL Servers mysqldmysqld，也被称为MySQL服务器，是执行MySQL大部分工作的主要程序。MySQL服务器管理对包含数据库和表的MySQL数据目录的访问。 查看帮助： mysqld --verbose --help mysql_safe对于某些Linux平台，从RPM或DBP包安装的MySQL包括了用于管理MySQL服务启动和管理的systemd支持。在这些平台上，mysqld_safe不会被安装，因为它不是必须的。 mysql_safe是Unix上启动mysqld服务器的推荐方式。它添加了一些安全特性，如发生错误是重启服务器并将运行时的错误记录到日志。 mysqld_safe尝试启动一个名为mysqld的可执行程序。它会读取配置文件中[mysqld], [server], [mysqld_safe]部分的所有选项。 mysqld_safe选项： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647--basedir--core-file-size--datadir--defaults-extra-file--defaults-file--ledir--log-error--mallocl-lib--mysqld--mysqld-safe-login-timestamps--mysql-version--nice--no-defaults--open-files-limit--pid-file--plugin-dir--plugin-dir--port--skip-kill-mysqld--skip-syslog--socket--syslog-tag--timezone--user mysql.server对于某些Linux平台，从RPM和DPG包安装的MySQL包括了用于管理MySQL Server启动和关闭的systemd支持。在这些平台上，没有安装mysql.server和mysqld_safe，因为它们不是必须的。 Unix和Unix-Like平台上的MySQL发行版包含一个名为mysql.server的脚本，该脚本使用mysqld_safe启动MySQL Server。 mysqld_multi对于某些Linux平台，从RPM和DPG包安装的MySQL包括了用于管理MySQL Server启动和关闭的systemd支持。在这些平台上，没有安装mysqld_multi，因为它们不是必须的。 mysqld_multi设计用于管理多个监听不同Unix socket文件和TCP/IP port上连接的mysqld进程。 MySQL安装相关程序这些程序用于安装或升级MySQL！ com_errCompile MySQL Error Message File mysql_install_dbInitialize MySQL Data Directory mysql_pluginConfigure MySQL Server Plugins mysql_secure_installationImprove MySQL Installation Security mysql_ssl_rsa_setupCreate SSL/RSA Files mysql_tzinfo_to_sqlLoad the Time Zone Tables mysql_upgradeCheck and Upgrade MySQL Tables com_errcomp_err创建errmsg.sys文件，mysqld使用此文件来确定为不同错误代码(error code)显示错误消息。通常，在构建MySQL时，comp_err会自动运行。它从位于MySQL源发行版sq;/share/errmsg-utf8.txt文本文件汇编errmsg.sys文件。 comp_err同样会生成mysqld_error.h, mysqld_ername.h, sql_state.h头文件。 mysql_install_db在MySQL5.7中，由于mysql_install_db的功能已经被集成到mysqld中，因此不推荐使用它。在MySQL5.7.5之前，mysql_install_db是一个Perl脚本并依赖于Perl。在此之后，它是由C++写的可执行二进制文件。还有一些选项的更迭。 1234mysqld --initailize#ormysqld --initialize-insecure mysql_install_db处理在MySQL Server(mysqld)准备好使用之前，必须执行的初始化任务： 初始化MySQL数据目录，创建它包含的系统表 初始化管理InnoDB表所需的system tablespace和相关数据结构 加载服务器端help表 安装sys schema 创建一个管理员账户老版本的mysql_install_db可能会创建匿名账户。 如果mysql_install_db生成了一个随机管理员密码，它将把此密码写入文件并显示此文件名。密码包含一个时间戳以指示它的写入时间。默认情况下，该文件是用户主目录中的.mysql_secret文件。 mysql_plugin从MySQL5.7.11开始，不推荐使用mysql_plugin，并会在MySQL8.0中移除此功能。使用如下命令替代： 123456--plugin-load--plugin-load-add#或mysql&gt; INSTALL PLUGINmysql&gt; UNINSTALL PLUGIN mysql_plugin功能允许MySQL管理员管理由MySQL Server载入的插件。 mysql_secure_installationmysql_secure_installation通过以下方式来提高MySQL安装的安全性： 为root用户设置密码 删除可从本机外部访问的root账户 删除匿名账户 删除test数据库(默认情况下可由任何用户访问，包括匿名用户) 删除允许任何人访问以test_开头的数据库的权限 mysql_ssl_rsa_setupmysql_ssl_rsa_setup创建SSL证书和key文件和RSA key-pair文件，用于支持使用SSL进行安全连接。它生成的整数是自签名的，不太安全。请考虑从注册机构申请CA证书。mysql_ssl_rsa_setup使用opensll命令，所以请安装OpenSSL。 mysql_tzinfo_to_sqlmysql_tzinfo_to_sql加载MySQL数据库中的zone table。它使用系统上的zoneinfo信息。 msyql_upgrademysql_upgrade检查数据库中的所有表与当前版本的MySQL Server的不兼容，它还升级系统表，以便你可以利用新权限和功能。如果mysql_upgrade发现表有可能的不兼容性，它会执行检查表，如果发现问题，则会尝试修复表。 每次升级MySQL时都应该执行mysql_upgrade。在执行upgrade之前，你应该始终备份你的MySQL。 MySQL客户端程序 mysqlThe MySQL Command-Line Tool mysqladminClient for Administering a MySQL Server mysqlcheckA Table Maintenance Program mysqldumpA Database Backup Program mysqlimportA Data Import Program mysqlpumpA Database Backup Program mysqlshThe MySQL Shell mysqlshowDisplay Database, Table, and Column Information mysqlslapLoad Emulation Client mysqlmysql是一个具有输入编辑功能的SQL shell。 123456mysql --host= --port= --user= --password db_name#SQL文件#SQL语句以 ;或\g或\G结束mysql db_name &lt; script.sql &gt; output.tab mysql选项MySQL支持很多选项。这些选项可以写入配置文件的[mysql]和[client]组中。 1mysql --help mysql命令mysql将你发出的每个SQL语句发送到要执行的Server。如下为mysql自己解释的命令： 123456789101112131415161718192021222324252627282930mysql&gt; help;List of all MySQL commands:Note that all text commands must be first on line and end with &apos;;&apos;? (\?) Synonym for `help&apos;.charsetclear (\c) Clear the current input statement.connect (\r) Reconnect to the server. Optional arguments are db and host.delimiter (\d) Set statement delimiter.edit (\e) Edit command with $EDITOR.ego (\G) Send command to mysql server, display result vertically.exit (\q) Exit mysql. Same as quit.go (\g) Send command to mysql server.help (\h) Display this help.nopager (\n) Disable pager, print to stdout.notee (\t) Don&apos;t write into outfile.pager (\P) Set PAGER [to_pager]. Print the query results via PAGER.print (\p) Print current command.prompt (\R) Change your mysql prompt.quit (\q) Quit mysql.rehash (\#) Rebuild completion hash.source (\.) Execute an SQL script file. Takes a file name as an argument.status (\s) Get status information from the server.system (\!) Execute a system shell command.tee (\T) Set outfile [to_outfile]. Append everything into given outfile.use (\u) Use another database. Takes database name as argument.charset (\C) Switch to another charset. Might be needed for processing binlog with multi-byte charsets.warnings (\W) Show warnings after every statement.nowarning (\w) Don&apos;t show warnings after every statement.resetconnection(\x) Clean session context. 修改MySQL提示符 123456789101112131415#shellexport MYSQL_PS1=&quot;(\u@\h) [\d]&gt; &quot;#mysqlmysql --prompt=&quot;(\u@\h) [\d]&gt; &quot;#配置文件[mysql]prompt=(\\u@\\h) [\\d]&gt;\\_#mysql promptmysql&gt; prompt (\u@\h) [\d]&gt;\_ mysql服务端帮助mysql Server-Side Help 如果给help命令提供一个参数，mysql将其用作搜索字符串，以从MySQL参考手册的内容访问服务端帮助。 12345678910mysql&gt; help memysql&gt; help contentsmysql&gt; help logsmysql&gt; help rep% 从文本文件执行SQL语句mysql忽略文件开头的Unicode字节顺序标记(BOM)字符。BOM的存在不会导致MySQL更改其默认字符集(charset)。因此，请使用--default-char-set选项。 12345678910#shellmysql db_name &lt; test_filemysql&gt; source file_namemysql&gt; \. file_name#显示进度信息SELECT &apos;&lt;info_to_display&gt;&apos; AS &apos; &apos;; MySQL管理和实用程序 inochecksumOffline InnoDB File Checksum Utility myisam_ftdumpDisplay Full-Text Index information myisamchkMyISAM Table-Maintenance Utility myisamlogDisplay MyISAM Log File Contents myisampackGenerate Compressed, Read-Only MyISAM Tables mysql_config_editorMySQL Configuration Utility mysqlbinlogUtility for Processing Binary Log Files mysqldumpslowSummarize Slow Query Log Files mysql开发实用程序 mysql_configDisplay Options for Compiling Clients my_print_defaultsDisplay Options from Option Files resolve_stack_dumpResolve Numeric Stack Trace Dump to Symbols 杂项程序Miscellaneous Programs lz4_decompressDecompress mysqlpump LZ4-Compressed Output perrorExplain Error Codes replaceA String-Replacement Utility resolveipResolve Host name to IP Address or Vice Versa zlib_decompressDecompress mysqlpump ZLIB-Compressed Output MySQL环境变量这些环境变量直接或间接的被MySQL使用。 Variable Description AUTHENTICATION_LDAP_CLIENT_LOG Client-side LDAP authentication logging level. AUTHENTICATION_PAM_LOG PAM authentication plugin debug logging settings. CC The name of your C compiler (for running CMake). CXX The name of your C++ compiler (for running CMake). CC The name of your C compiler (for running CMake). DBI_USER The default user name for Perl DBI. DBI_TRACE Trace options for Perl DBI. HOME The default path for the mysql history file is $HOME/.mysql_history. LD_RUN_PATH Used to specify the location of libmysqlclient.so. LIBMYSQL_ENABLE_CLEARTEXT_PLUGIN Enable mysql_clear_password authentication plugin; see Section 6.5.1.6, “Client-Side Cleartext Pluggable Authentication”. LIBMYSQL_PLUGIN_DIR Directory in which to look for client plugins. LIBMYSQL_PLUGINS Client plugins to preload. MYSQL_DEBUG Debug trace options when debugging. MYSQL_GROUP_SUFFIX Option group suffix value (like specifying –defaults-group-suffix). MYSQL_HISTFILE The path to the mysql history file. If this variable is set, its value overrides the default for $HOME/.mysql_history. MYSQL_HISTIGNORE Patterns specifying statements that mysql should not log to $HOME/.mysql_history, or syslog if –syslog is given. MYSQL_HOME The path to the directory in which the server-specific my.cnf file resides. MYSQL_HOST The default host name used by the mysql command-line client. MYSQL_OPENSSL_UDF_DH_BITS_THRESHOLD Maximum key length for CREATE_DH_PARAMETERS(). See Section 12.18.2, “Enterprise Encryption Usage and Examples”. MYSQL_OPENSSL_UDF_DSA_BITS_THRESHOLD Maximum DSA key length for CREATE_ASYMMETRIC_PRIV_KEY(). See Section 12.18.2, “Enterprise Encryption Usage and Examples”. MYSQL_OPENSSL_UDF_RSA_BITS_THRESHOLD Maximum RSA key length for CREATE_ASYMMETRIC_PRIV_KEY(). See Section 12.18.2, “Enterprise Encryption Usage and Examples”. MYSQL_PS1 The command prompt to use in the mysql command-line client. MYSQL_PWD The default password when connecting to mysqld. Using this is insecure. See Section 6.1.2.1, “End-User Guidelines for Password Security”. MYSQL_TCP_PORT The default TCP/IP port number. MYSQL_TEST_LOGIN_FILE The name of the .mylogin.cnf login path file. MYSQL_TEST_TRACE_CRASH Whether the test protocol trace plugin crashes clients. See note following table. MYSQL_TEST_TRACE_DEBUG Whether the test protocol trace plugin produces output. See note following table. MYSQL_UNIX_PORT The default Unix socket file name; used for connections to localhost. MYSQLX_TCP_PORT The X Plugin default TCP/IP port number. MYSQLX_UNIX_PORT The X Plugin default Unix socket file name; used for connections to localhost. PATH Used by the shell to find MySQL programs. PKG_CONFIG_PATH Location of mysqlclient.pc pkg-config file. See note following table. TMPDIR The directory in which temporary files are created. TZ This should be set to your local time zone. See Section B.5.3.7, “Time Zone Problems”. UMASK The user-file creation mode when creating files. See note following table. UMASK_DIR The user-directory creation mode when creating directories. See note following table. USER The default user name on Windows when connecting to mysqld. MySQL Server管理MySQL Servermysqld is the MySQL Server.并非所有的MySQL Server二进制文件和配置都支持所有的存储引擎。 12345678910#查看帮助mysqld --verbose --help#运行Server的环境变量mysql&gt; SHOW VARIABLES;#运行Server的状态mysql&gt; SHOW STATUS; MySQL数据目录由MySQL管理的信息存储在称为数据目录的目录下。 数据目录子目录：每个子目录都是数据库目录对应于Server管理的数据库 mysql performance_schema sys 数据库 日志文件由Server写入 innoDB表空间和日志文件 自动生成的SSL/RSA证书和密钥文件 Server PID mysql数据库The mysql System Database The mysql database is the system database.它的表中存储了MySQL Server运行时需要的信息。 授权系统表如下这些系统表包含了用户账户和权限的授权信息。 userUser accounts, global privileges, and other non-privilege columns. dbDatabase-level privileges. tables_privTable-level privileges. columns_privColumn-level privileges. procs_privStored procedure and function privileges. proxies_privProxy-user privileges. 对象信息系统表如下这些系统表包含了存储程序，用户定义函数和服务器端插件的信息。 event关于Event Scheduler事件的信息 func用户定义函数的信息 plugin服务器端的插件的信息 proc有关存储过程和函数的信息 日志系统表Server使用如下系统表记录日志。日志表使用CSV存储引擎。 general_log一般查询日志表 slow_log慢查询日志表 服务器端帮助系统表如下系统表包含了服务器端帮助信息。 help_categoryInformation about help categories. help_keywordKeywords associated with help topics. help_relationMappings between help keywords and topics. help_topicHelp topic contents. 时区系统表如下系统表包含了时区信息。 time_zoneTime zone IDs and whether they use leap seconds. time_zone_leap_secondWhen leap seconds occur. time_zone_nameMappings between time zone IDs and names. time_zone_transition, time_zone_tansition_typeTime zone descriptions. 副本系统表Server使用如下这些系统表来提供副本服务。这些表使用InnoDB存储引擎。 gtid_executedTable for storing GTID values. ndb_binlog_indexBinary log information for NDB Cluster replication. slave_master_info, slave_relay_log_info, slave_worker_infoUsed to store replication information on slave servers. 优化器系统表如下系统表用于优化。 innodb_index_stats, innodb_table_statsUsed for InnoDB persistent optimizer statistics server_cost, engine_costThe optimizer cost model uses tables that contain cost estimate information about operations that occur during query execution. 杂项系统表 audit_log_filter, audit_log_user firewall_users, firewall_whitelist servers MySQL Server LogsMySQL Server提供如下几种日志： Error log启动、运行或停止mysqld遇到的问题 General query log建立Client连接和从Client收到的语句 Binary log更改数据的语句 Relay log从replication master server收到的数据更改 Slow query log执行时间超过long_query_time秒的查询 DDL(Metadata) log由DDL语句执行的元数据操作 默认情况下，不启用任何日志。 如果启用了这些日志，MySQL Server可以灵活地控制一般查询日志和慢查询日志的输出目的地——它可为日志文件或mysql数据库中的general_log和slow_log表。 123456789101112131415#--log-output#它的值可为TABLE/FILE/NONE#--general-log, --slow-query-log#TABLE和FILEmysqld --log-output=TABLE,FILE --general-log=msyql.general_log --slow-query-log=mysql.slow_log#or[mysqld]log_output=general_log=slow_query_log= 查看两个日志表的标准格式： 12SHOW CREATE TABLE mysql.general_log;SHOW CREATE TABLE mysql.slow_log; 错误日志The Error Log 错误日志包含mysqld启动和关闭时间的记录。它还包含诊断信息。 Unix/Unix-Like OS使用mysqld --log-error选项来将错误日志写入控制台(stderr)或文件。 如果未指定文件名，则默认为数据目录下的host_name.err文件。YUM或APT包安装，则配置的错误日志文件为--log-error=/var/log/mysqld.log。 将错误日志记录到系统日志Error Logging to the System Log 使用如下系统变量： log_syslog启用此变量将错误日志发送到系统日志 log_syslog_facilitysyslog消息的默认设置时daemon。设置此变量以指定其它工具。 log_syslog_include_pid是否在syslog输出中包含Server的PID。 log_syslog_tag在syslog消息中添加一个tag。 1msyqld --log_syslog= 错误日志过滤Error Log Filtering log_error_verbosity变量控制错误日志的详细程度。值如下： 1error only 2errors, warning 3(默认)errors, warnings, notes 错误日志消息格式Error Log Message Format 错误日志中包含的ID是mysqld中负责编写消息的线程的ID。这表示Server的哪部分生成了消息。log_timestamps变量控制写入错误日志的时区和时间格式。 1mysqld --log-timestamps= 错误日志文件刷新Error Log File Flushing and Renaming 如果你使用FLUSH_ERROR_LOGS, FLUSH_LOGS或mysqladmin flush-logs刷新日志，Server将关闭并重新打开它正在写的任何错误日志文件。 12mv host_name.err host_name.err-oldmysqladmin flush-logs 一般查询日志The General Query Log 一般查询日志是mysqld执行操作的记录。当Client连接或断开时，Server将此信息写入日志，并记录从Client收到的每个SQL语句。mysqld按照接收的顺序而不是执行顺序将语句写入日志。 默认情况下，一般查询日志是禁用的。指定初始化查询日志状态--general_log={0|1}。1启用，0禁用。指定日志文件名--general-log-file=file-name.如果未指定，默认为数据目录下host_name.log，除非指定了其它路径。指定日志文件位置--log-output=. 12345mysqld --log-output=&apos;/var/log/mysql&apos; --general-log=1 --general-log-file=&apos;general.log&apos;shell&gt; mv host_name.log host_name-old.logshell&gt; mysqladmin flush-logs 二进制日志The Binary Log 安全Security 当考虑MySQL安装中的安全性时，你应该考虑各种可能的主题以及他们如何影响MySQL Server和相关应用程序的安全性: 影响安全性的一般因素。包括选择好的密码，不向用户授予不必要的权限，防止SQL注入和数据损坏来确保应用程序的安全性… 安装本身的安全性。应保护数据文件，日志文件和安装的所有应用程序文件，以确保未经授权方无法读写这些文件… 数据库系统本身的访问控制和安全性。包括允许访问数据库中使用的数据库，视图和存储应用程序的用户和数据库… 安全相关插件提供的功能… MySQL和你的系统的网络安全性。安全性还与用户的授权有关，但你可能希望限制MySQL，使其仅在本地主机上可用，或者在一组有限的其它主机上可用… 确保你备份了足够和适当的数据库文件，配置和日志文件。还要确保你已准备好恢复解决方案，并测试是否能够从备份种恢复信息… 一般安全问题General Security Issues 本节介绍了要注意的一般安全问题，以及如何使MySQL安装更安全，防止攻击或滥用。 安全指南Security Guidelines 在连接了Internet的计算机上使用MySQL的任何人都应阅读本节，以避免最常见的安全错误。在讨论安全性时，有必要考虑完全保护整个服务器主机免受所有类型的攻击：窃听，更改，拒绝服务… MySQL使用基于访问控制列表(ACL)的安全性，来处理用户可以尝试执行的所有连接、查询和其它操作。MySQL Client和Server之间SSL加密连接。 当运行MySQL时，遵循以下准则： 不要让任何人(root除外)访问mysql.user数据表，这很关键。 了解MySQL访问权限系统的工作原理。使用GRANT和REVOKE语句来控制对MySQL的访问。不要授予超出必要的权限，永远不要授予所有主机权限。如果你能够在不被要求输入密码的情况下成功连接到MySQL Server，则任何人都可以以具有完全权限的root用户身份连接到MySQL Server。请重新查看MySQL安装说明，特别注意有关设置root密码的信息。检查哪些账户拥有访问权限，并移除不必要的权限。 1234567891011#测试mysql -u root#访问权限SHOW GRANTS;#移除权限#help REVOKEREVOKE 不要在数据库中存储明文密码。如果计算机被攻击，入侵者可以获得完整的密码列表并使用他们。相反，使用一些HASH函数并存储散列值。 不要从字典中选择密码，即不要使用简单和常规密码。存在某些破解密码的程序能计算你的密码。 启用防火墙。这可以保护你免受大部分漏洞攻击。将MySQL放在防火墙后面或DMZ。使用端口扫描软件(如nmap)扫描主机端口。MySQL默认使用3306端口。不应从不受信任的主机访问此端口。测试你的端口安全性： 123456789101112131415[zhang@zhang21 ~]$ telnet zhang21 3306Trying 192.168.31.119...Connected to zhang21.Escape character is &apos;^]&apos;.@Host &apos;zhang21&apos; is not allowed to connect to this MySQL serverConnection closed by foreign host.[zhang@zhang21 ~]$ telnet localhost 3306Trying ::1...Connected to localhost.Escape character is &apos;^]&apos;.J5.7.22[cqo3I @kX@n#I\mysql_native_password 访问MySQL的应用程序不应该信任用户输入的任何数据，应该使用适当的防御性编程技术编写。 不要通过Internet传输普通数据(未加密)。请使用SSL或SSH加密协议。MySQL支持内部SSL连接；或是使用SSH端口转发为通信创建加密隧道。 学习使用tcpdump和strings使用程序。可使用如下命令来检查MySQL数据流是否加密: 1tcpdump -l -i eth0 -w - src or dst port 3306 | strings 密码安全Keeping Passwords Secure 密码出现在MySQL的多个上下文中。此解提供了一些准则，使用户和管理员能够保护这些密码的安全性，并避免暴露这些密码。还讨论了MySQL如何在内部使用密码散列以及可用来强制执行更严格密码的插件。 密码安全用户指南End-User Guidelines for Password Security MySQL用户应使用以下准则来保证密码安全。当运行Client连接到MySQL server时，不建议以公开的方式来指定你的密码。 使用mysql_config_editor实用程序，它可将身份认证凭据存储在名为.mylogin.cnf的加密登录路径文件中。 使用-pPASSWD或--password=PASSWD选项 使用-p或--password选项不指定值 将密码存储到配置文件 将密码存储到MYSQL_PWD环境变量 12345678910111213141516171819202122232425#强烈不推荐#这虽然方便却不安全mysql -u user -pPASSWD db_name#推荐#但这适用于交互式mysql -u user -p db_nameEnter password: xxx#写入配置文件chmod 600 ~/.my.cnfvim ~/.my.cnf[client]password=xxxmysql --defaults-file=~/.my.cnf#指定MySQL密码环境变量的方法非常不安全，不应该使用 在Unix上，MySQL Client将执行语句的记录写入历史文件。默认情况下，此文件为~/.mysql_history。密码可以在SQL语句中以纯文本形式写入(如CREATE USER, ALTER USER)，如果使用了这些语句，它们将被记录到历史文件中。要保证此文件的安全，请使用限制访问模式。 如果命令解释器程序配置为维护历史记录，则保存命令的任何文件都将包含在命令行中输入的MySQL密码。如bash下的~/.bash_history。 密码安全管理员指南Administrator Guidelines for Password Security MySQL数据库管理员应使用以下准则来保证密码安全： MySQL在mysql.user表中存储用户账户密码。永远不要向任何非管理账户授予此表的访问权限 账户密码可以过期，以便用户必须重置密码 validate_password插件可用于对可接受的密码强制实施策略 应该保护可能写入密码的日志文件等文件 密码和日志Passwords and Logging 密码可在SQL语句中以纯文本形式写入，如CREATE USET, GRANT, SET PASSWORD和调用PASSWORD()函数的语句。如果MySQL Server记录了这些语句，那么访问日志的任何人都可以看到密码。 语句记录避免以明文形式为以下语句编写密码： 1234567CREATE USER ... IDENTIFIED BY ...ALTER USER ... IDENTIFIED BY ...GRANT ... IDENTIFIED BY ...SET PASSWORD ...SLAVE START ... PASSWORD = ...CREATE SERVER ... OPTIONS(... PASSWORD ...)ALTER SERVER ... OPTIONS(... PASSWORD ...) 对于常规查询日志，可通过使用--log-raw选项启动Server来抑制密码重写。出于安全原因，此选项不建议用于生产环境。处于诊断目的，查看Server收到的语句的确切文本可能很有用。审计日志插件生成的审计日志文件的内容未加密。出于安全原因，应将此文件写入只有MySQL Server和用户才能访问的目录，并且有正当理由查看目录。只有在需要纯文本密码时才会进行密码重写，对于具有期望密码散列语法的语句，不会发生重写。要保护日志文件免受不必要的暴露，请将他们放在限制访问Server和管理员的目录中。副本集slave将复制副本集master的密码存储在主信息存储库中，它可以是文件或表。确保只能由管理员访问此库。 使用受限的访问模式来保护包含日志表或密码的日志文件的数据库备份。 密码散列Password Hashing in MySQL MySQL在mysql.user数据表中列出用户账户。可以为每个MySQL账户分配一个密码，尽管用户表不存储明文密码，而是存储密码的散列值。 MySQL在Client/Server通信的两个阶段中使用密码： 当客户端尝试连接到Server时，有一个初始身份认证步骤，其中客户端必须提供密码，该密码的散列值与mysql.user用户表中存储的散列值相匹配 客户端连接之后，它可以(如果有足够权限)设置或更改mysql.user用户表中账户的密码的散列值。客户端可通过使用PASSWORD()函数来生成密码散列，或使用密码生成语句(CREATE USER, GRANT, SET PASSWORD)来完成此操作。 换句话说，Server在客户端首次尝试连接时在身份认证期间检查散列值。如果连接的客户端调用PASSWORD()函数，或使用密码生成语句来设置/更改密码，则Server会生成散列值。 12345678910111213141516171819202122232425help PASSWORD;#This function is deprecated as of MySQL 5.7.6 and will be removed in a future MySQL release#The Original (Pre-4.1) Hashing Method#原始散列方法产生一个16Byte的字符串mysql&gt; SELECT PASSWORD(&apos;mypass&apos;);+--------------------+| PASSWORD(&apos;mypass&apos;) |+--------------------+| 6f8c114b58f2ce9e |+--------------------+#The 4.1 Hashing Method#MySQL4.1引入了密码散列，提供了更好的安全性并降低了密码被截获的风险#生成更长的41Byte的散列值mysql&gt; SELECT PASSWORD(&apos;mypass&apos;);+-------------------------------------------+| PASSWORD(&apos;mypass&apos;) |+-------------------------------------------+| *6C8989366EAF75BB670AD8EA7A7FC1176A95CEF4 |+-------------------------------------------+ 散列方法的兼容性问题Compatibility Issues Related to Hashing Methods 使MySQL安全抵御攻击者Making MySQL Secure Against Attackers 连接到MySQL server时，应使用密码。密码在连接时不会以明文形式传输。所有其它信息都以文本形式传输，对任何能够看到连接的人都可读。如果连接通过不信任的网络，则可以使用压缩协议使流量更难以解密。你还可以使用MySQL的内部SSL支持来使连接更安全。或者，使用SSH在MySQL server和client之间获得加密的TCP/IP连接。 要使得MySQL系统安全，你应该强烈考虑以下建议： 要求所有MySQL账户都有密码 确保只有Unix用户账户对数据库目录具有读写权限，它是用于运行mysqld的账户 永远不要以root用户运行MySQL server，应该使用普通的非特权用户运行 MySQL用户账户和Unix系统账户没有关联 不要对非管理员用户授予FILE权限，具有此权限的用户都可使用mysqld daemon的权限在文件系统的任何位置编写文件，同样也可读取文件，并将文件载入数据库 不要对非管理员用户授予PROCESS或SUPER权限(可用于终止连接，修改系统变量…) 不允许对表使用符号链接 安全地存储程序和视图 如果不信任DNS，则应在授权表中使用IP地址而非主机名 如果想要限制单个账户的连接数，可在mysqld中配置max_user_connection变量 如果插件目录对server可写，这可修改它为只读 12345678910111213141516171819202122232425262728#服务cat /usr/lib/systemd/system/mysqld.service[Service]User=mysqlGroup=mysql#或配置文件/etc/my.cnf[mysqld]user=mysql#查看当前正在执行的语句msyql&gt; SHOW PROCESSLIST;+----+------+-----------+-------+---------+------+----------+------------------+| Id | User | Host | db | Command | Time | State | Info |+----+------+-----------+-------+---------+------+----------+------------------+| 18 | root | localhost | mysql | Query | 0 | starting | SHOW PROCESSLIST |+----+------+-----------+-------+---------+------+----------+------------------+# Disabling symbolic-links is recommended to prevent assorted security riskscat /etc/my.cnfsymbolic-links=0 安全相关的mysqld选项和变量Security-Related mysqld Options and Variables 下表显示了影响安全性的mysqld的选项和系统变量: Name Cmd-Line Option File System Var Status Var Var Scope Dynamic allow-suspicious-udfs Yes Yes automatic_sp_privileges Yes Global Yes chroot Yes Yes des-key-file Yes Yes local_infile Yes Global Yes old_passwords Yes Both Yes safe-user-create Yes Yes secure-auth Yes Yes Global Yes - Variable: secure_auth Yes Global Yes secure-file-priv Yes Yes Global No - Variable: secure_file_priv Yes Global No skip-grant-tables Yes Yes skip-name-resolve Yes Yes Global No - Variable: skip_name_resolve Yes Global No skip-networking Yes Yes Global No - Variable: skip_networking Yes Global No skip-show-database Yes Yes Global No - Variable: skip_show_database Yes Global No 以普通用户运行MySQLHow to Run MySQL as a Normal User 在Linux上，使用MySQL-repo、RPM包、Debian包来安装MySQL。MySQL server mysqld默认是由操作系统的mysql用户来启动。 对于使用.tar.gz包进行的安装，你需要修改为non-root用户。 1234567chown -R user_name /path/to/mysql/datadirvim /etc/my.cnf[mysqld]user=user_name LOAD DATA LOCAL的安全问题LOAD DATA语句可以载入主机上的文件。 这有两个潜在的安全问题： 从Client到Server的文件传输是由MySQL server启动。理论上，server可告诉client传输server选择的文件而不是LOAD DATA语句中client指定的文件。这样，server可以访问client端用户可访问的任何文件。 在client从web server连接的Web环境中，用户可使用LOAD DATA LOCAL来读取Web server进程具有访问权限的任何文件。 为了避免LOAD DATA问题，客户端应该避免使用LOCAL。为避免连接到不受信任的Server，Client可通过--ssl-mode=xxx选项和相应的CA证书建立安全的连接。 要是管理员和应用程序能够管理本地数据加载功能，LOCAL配置的工作方式如下： On the server sidelocal_infile系统变量控制服务器端的LOCAL功能。默认启用local_infile。 On the client sideENABLED_LOCAL_INFILE CMake选项控制MySQL Client Library的已编译的默认LOCAL功能。使用C API的客户端程序可通过调用mysql_options()来启用/禁用MYSQL_OPT_LOCAL_INFILE。对于mysql Client，默认禁止本地数据载入。使用--local-infile=1/0对于mysqlimport client，默认禁用本地数据载入。使用--local=1/0 客户端程序安全指南Client Programming Security Guidelines 访问MySQL的应用程序不应该信任用户输入的任何数据，用户可以尝试通过在Web表单，URL或构建的任何应用程序中输入特殊字符序列来欺骗你。如果用户输入DROP DATABASE mysql;类似语句，请确保你的应用程序保持安全，这是一个极端栗子。有时人们会认为，如果数据库只包含公开可用的数据，则无需受到保护。这是不正确的。即使允许在数据库中显示任何行，你仍应该防止拒绝服务攻击。 检查清单： 启用更严格的SQL模式以告知server对其接收的数据做更多限制 注意单/双引号 通过添加%22(&quot;), %23(&quot;), %27(&#39;)来修改动态URLs 动态修改URL中的数据类型 尝试输入字符、空格和特殊符号，而不是 数字 将数据传递给MySQL前检查数据大小 使用不同于管理员的用户将应用程序连接到数据库 访问权限系统The MySQL Access Privilege System MySQL权限系统的主要功能就是对从给定主机连接的用户进行身份认证，并将用户与数据库的权限(SELECT, INSERT, UPDATE, DELETE)相关联。其它功能包含匿名用户(anonymous user)和MySQL特定功能的授权。 有些事情你无法使用MySQL权限系统： 你无法明确指定拒绝给定用户访问 你无法指定用户创建/删除表的权限，但不能指定创建/删除数据库自身 适用于账户全局性的密码 MySQL权限系统的用户接口(user interface)由： CREATE USER, GRANT, REVOKE语句组成。 在内部，Server将权限信息存储在mysql数据库的授权表中。MySQL server在启动时将这些表内容读入内存，并根据授权表的内存中的副本建立访问控制决策。MySQL权限系统确保所有用户只能执行允许的操作。作为用户，当你连接到MySQL server时，你的身份由你连接的主机和你指定的用户名决定。在连接后，系统会根据你的身份和要执行的操作授予权限。MySQL会识别你的主机名和用户名，因为没有理由认为给定的用户名属于所有主机上的同一个人。 1234SHOW GRANTS;SHOW GRANTS FOR &apos;joe&apos;@&apos;office.example.com&apos;;SHOW GRANTS FOR &apos;joe&apos;@&apos;home.example.com&apos;; 当运行客户端程序连接到server时，MySQL访问控制包含两个阶段： server根据你的身份来接受/拒绝连接，以及你是否可通过提供正确的密码来验证你的身份 假设你可以连接，server会检查你发出的每个语句，以确定是否有足够的权限来执行它 MySQL提供的权限Privileges Provided by MySQL 授予MySQL账户的权限决定了账户可以指定的操作。MySQL权限在它们适用的上下文和不同操作级别上有所不同： 管理员权限(Administrative privileges)允许用户管理MySQL Server的操作。这些权限是全局的，因为它们不是特定于特定数据库 数据库权限(privileges for database)适用于数据库及其中的所有对象。可以为特定数据库或全局赋予这些权限，以便它们适用于所有数据库 数据库对象权限(privileges for database object)，如表，索引，视图… 可用权限Summary of Available Privileges 下表显示了GRANT和REVOKE语句中使用的权限名称，以及每个权限关联的列名和权限适用的上下文: Privilege Grant Table Column Context ALL [PRIVILEGES] Synonym for “all privileges” Server administration ALTER Alter_priv Tables ALTER ROUTINE Alter_routine_priv Stored routines CREATE Create_priv Databases, tables, or indexes CREATE ROUTINE Create_routine_priv Stored routines CREATE TABLESPACE Create_tablespace_priv Server administration CREATE TEMPORARY TABLES Create_tmp_table_priv Tables CREATE USER Create_user_priv Server administration CREATE VIEW Create_view_priv Views DELETE Delete_priv Tables DROP Drop_priv Databases, tables, or views EVENT Event_priv Databases EXECUTE Execute_priv Stored routines FILE File_priv File access on server host GRANT OPTION Grant_priv Databases, tables, or stored routines INDEX Index_priv Tables INSERT Insert_priv Tables or columns LOCK TABLES Lock_tables_priv Databases PROCESS Process_priv Server administration PROXY See proxies_priv table Server administration REFERENCES References_priv Databases or tables RELOAD Reload_priv Server administration REPLICATION CLIENT Repl_client_priv Server administration REPLICATION SLAVE Repl_slave_priv Server administration SELECT Select_priv Tables or columns SHOW DATABASES Show_db_priv Server administration SHOW VIEW Show_view_priv Views SHUTDOWN Shutdown_priv Server administration SUPER Super_priv Server administration TRIGGER Trigger_priv Tables UPDATE Update_priv Tables or columns USAGE Synonym for “no privileges” Server administration 授权指南Privilege-Granting Guidelines 最好只向账户授权它所需要的权限，在授予FILE和管理权限时应特别小心: FILE： 可在MySQL Server主机上读取的任何文件读入数据库表 GRANT OPTION： 使用户能够将其权限授权其他用户。具有不同权限且具有GRANT OPTION权限的两个用户可以组合权限 ALTER: 可通过重命名表来破坏权限系统 SHUTDOWN： 通过终止Server完全拒绝向其它用户提供服务 PROCESS： 用于查看当前正在执行的语句的纯文本，包括设置和更改密码的语句 SUPER： 用于终止其它会话或更改服务器的运行方式 为mysql系统数据本自身授予的权限可用于更改密码和其它访问权限信息： 密码以加密方式存储，因此恶意用户无法简单地读取明文密码。然而，具有对mysql.user表authentication_string列具有写权限的用户可以更改账户密码，然后进行登录 为mysql系统数据库授予INSERT或UPDATE权限允许用户添加或修改现有权限 mysql系统数据库的DROP权限使用户能够访问远程权限表，甚至是数据库本身 授权表Grant Tables mysql系统数据库包含多个授权表，其中包含有关用户账户及其拥有的权限信息。mysql数据库表包含的授权信息： user: 用户账户，全局权限，其它非权限列 db: 数据库级别权限 tables_priv：表级别权限 columns_priv： 列级别权限 procs_priv： 存储过程和功能权限 proxies_priv： 代理用户权限 每个授权表包含的列范围和列权限： 列范围确定表中每行的范围 列权限指示表中行授予的权限 Server以下列方式使用授权表： user表范围列确定是拒绝还是允许传入连接 db表范围列确定哪些用户可以从哪些主机上访问数据库 tables_priv和columns_priv表更精细，它们适用于表级别和列级别 procs_priv表用于存储的例程 proxies_priv表指示哪些用户可以充当其它用户的代理，以及用户是否可以将PROXY权限授予其它用户 指定账户名Specifying Account Names MySQL账户名由用户名和主机名组成。这样可以为具有相同名称且可以从不同主机连接的用户创建账户。 在SQL语句中，账户名称遵循以下规则： 账户名语法为: username@hostname 仅包含用户名的账户相当于username@% 注意反引号、单引号、双引号 引号的正确用法: &#39;username&#39;@&#39;hostname&#39; MySQL使用单独的用户名和主机名部分将账户名称存储到mysql系统数据库的授权表中： user表包含每个账户的一行，user.User，user.Host列存储用户名和主机名，此表还指示了账户具有哪些全局权限 其它授权表指示账户对数据库和库中对象的权限，这些表也有User, Host列来存储用户名和主机名 处于访问检查的目的，User value区分大小写，Host value不区分大小写 用户名和主机名还具有某些特殊值或通配符约定，如下:账户名的用户名部分是非空白值，或者是与任何用户名匹配的空值。具有空白用户名的账户是匿名用户(anonymous user)。在SQL语句中指定一个匿名用户，使用带引号的空用户名，如&#39;&#39;@&#39;localhost&#39;。 账户名的主机名部分可以采用多种形式，并允许使用通配符： host value可以是主机名或IP地址(ipv4, ipv6) 主机名或IP地址值中允许使用%和_通配符。例如，主机值%匹配任何主机名，如%.mysql.com匹配mysql.com域中的任何主机。 对于IPv4地址，可以给出网络掩码以指示用于网络号的地址位数 1CREATE USER &apos;test&apos;@&apos;198.51.100.0/255.255.255.0； Server使用系统DNS解析程序为客户端主机名或IP地址返回的值，意味着你应该使用DNS使用的相同格式指定的账户主机值。 访问控制Access Control 连接验证Access Control, Stage 1: Connection Verification 当你连接到MySQL Server，它会根据以下条件接受或拒绝连接： 身份和密码 账户是否被锁定 Server首先检查凭据，然后检查账户锁定状态。任一步骤失败都会导致Server完全拒绝你的访问权限。使用mysql.user表中的三个范围列：Host, User, authentication_string执行凭据检查。 1234567891011121314151617181920SELECT User, Host FROM mysql.user;+-----------+----------+-| Host | User | ...+-----------+----------+-| % | root | ...| % | jeffrey | ...| localhost | root | ...| localhost | | ...+-----------+----------+-#内存中排序的表+-----------+----------+-| Host | User | ...+-----------+----------+-| localhost | root | ...| localhost | | ...| % | jeffrey | ...| % | root | ...+-----------+----------+- %： 表示任意主机 空用户名： 表示任意 当可能存在多个匹配时，Server必须确定要使用安歇匹配项： 只要Server将用户表读入内存，它就会对行进行排序 当用户尝试连接时，Server按排序顺序查看行 Server使用与客户端host和username匹配的第一行 请求认证Access Control, Stage 2: Request Verification 通过连接发出的每个请求，Server确定你要执行的操作，然后检查你是否具有足够的权限来执行此操作。这就是授权表中权限列生效的地方。这些权限可以来自任何user, db, table, column, procs。 全局权限(global)适用于全局范围内 数据库权限 空用户名匹配匿名用户，用户名中没有通配符 通配符%和_可在Host和Db列中使用，与LIKE操作符执行的模式匹配类似。如果要使用原字符，请使用反斜杠对其转义 %或空白Host值表示任意主机 %或空白Db值表示任意数据库 表、列、proc权限 通配符%, _ 以布尔术语表示，总结用户权限： 12345global privilegesOR (database privileges AND host privileges)OR table privilegesOR column privilegesOR routine privileges 权限更改生效时When Privilege Changes Take Effect 启动msyqld时，它读取所有授权表到内存中，内存中的表在此时对访问控制有效。如果使用GRANT, REVOKE, SET PASSWORD, RENAME USER账户管理语句间接修改了授权表，则Server会注意到这些更改并立即在此将授权表加载到内存中。如果直接使用INSERT, UPDATE, DELETE语句修改授权表，则在重启Server或指示重新加载表之前，对权限的更改没有影响。也就是说，直接修改授权表但没有重新加载它的话，更改时无效的。 告诉Server重新加载授权表，有几种方式： 1234567mysql&gt; FLUSH PRIVILEGES#或$ mysqladmin flush-privileges#或$ mysqladmin reload 如果使用--skip-grant-tables选项启动Server，则它不会读取授权表或实现任何访问控制。任何人都可以连接并做任何事情，这是不安全的。 连接MySQL的一些问题Troubleshooting Problems Connecting to MySQL 链接: https://dev.mysql.com/doc/refman/5.7/en/problems-connecting.html 用户账户管理MySQL User Account Management 本节介绍如何为MySQL Server的客户端设置账户： MySQL中使用的账户名和密码的含义，与操作系统使用的名称和密码的比较 如何设置新账户和删除现有账户 如何修改密码 密码使用安全指南 用户名和密码User Names and Passwords 有两种方式创建MySQL账户： 使用创建账户(CREATE USER)和建立权限(GRANT)的账户管理语句。这些语句使Server对基础授权表进行适当的修改 直接操作MySQL授权表，如INSERT, DELETE, UPDATE命令 推荐使用账户管理语句，因为它们比直接操作授权表更简洁，更不容易出错。 栗子： 1mysql --user=root mysql 创建账户： 1234567891011121314151617CREATE USER 'finley'@'localhost' IDENTIFIED BY 'passwd';GRANT ALL PRIVILEGES ON *.* TO 'finley'@'localhost' WITH GRANT OPTION;CREATE USER 'finley'@'%' IDENTIFIED BY 'passwd';GRANT ALL PRIVILEGES ON *.* TO 'finley'@'%' WITH GRANT OPTION;CREATE USER 'admin'@'localhost' IDENTIFIED BY 'password';GRANT RELOAD,PROCESS ON *.* TO 'admin'@'localhost';#查看SHOW GRANTS FOR 'admin'@'localhost';#特定权限CREATE USER 'reader'@'localhost' INDENTIFIED BY 'passwd';GRANT SELECT ON readdb.* TO 'reader'@'localhost'; 删除账户Removing User Accounts 使用DROP USER语句删除用户账户。 1DROP USER 'reader'@'localhost'; 保留账户Reserved User Accounts MySQL安装过程中的数据目录初始化期间，MySQL会创建应被视为保留的用户账户： &#39;root&#39;@&#39;localhost&#39;： 用于管理，拥有一切权限，可执行任何操作 &#39;mysql.sys&#39;@&#39;localhost&#39;： 用作sys模式对象的DEFINER。可避免DBA重命名或删除root账户时出现的问题 &#39;mysql.session@&#39;localhost&#39;：由插件在内部使用以访问Server 账户资源限制Setting Account Resource Limits 限制Client使用MySQL Server资源的一种方式是将全局max_user_connections系统变量设置为非零值。这限制了任何账户(缺乏单个用户)可以进行同时连接的数量，但是对连接后Client可以执行的操作没有限制。 为了解决这些问题，MySQL允许限制单个账户的资源： 账户每小时可以发出的查询数 账户每小时可以发出的更新数 账户每小时可以连接到Server的次数 账户与Server同时连接的数量 要在创建账户时设置资源限制，使用CREATE USER语句；要修改现有账户的限制，使用ALTER USER语句。使用WITH字句，命名每个要限制的资源。每个限制的默认值为零，即无限制。限制类型不必全部在WITH字句中命名，每个小时的限制值应该是一个整数。 Server在该账户对应的user表的行中存储账户的资源限制。当任何账户对其使用任何资源具有非零限制时，将进行资源使用计数。如果超过其连接次数，则Server会拒绝该账户的其它连接，直到该小时结束为止。在所有这些情况下，Server都会发出相应的错误消息。 12345678CREATE USER 'francis'@'localhost' IDENTIFIED BY 'frank' WITH MAX_QUERIES_PER_HOUR 20 MAX_UPDATES_PER_HOUR 10 MAX_CONNECTIONS_PER_HOUR 5 MAX_USER_CONNECTIONS 2;ALTER USER 'francis'@'localhost' WITH MAX_QUERIES_PER_HOUR 100; 假设全局变量max_user_connections值为10： 123ALTER USER 'user1'@'localhost' WITH MAX_USER_CONNECTIONS 0;ALTER USER 'user2'@'localhost' WITH MAX_USER_CONNECTIONS 5;ALTER USER 'user3'@'localhost' WITH MAX_USER_CONNECTIONS 20; 可以为单个账户、所有账户全局重置当前的计数： 使用FLUSH USER RESOURCES语句，将所有账户当前的计数重置为零 将单个账户的限制值重新设置，可以将账户的计数重置为零 每小时计数重置不会影响MAX_USER_CONNECTIONS限制。所有计数从零开始，计数不会通过Server重启而延续。 分配账户密码Assigning Account Passwords MySQL会自动散列(hash)指定的密码。 12345678910#在创建用户是使用INDENTIFIED BY字句分配密码CREATE USER 'jeffrey'@'localhost' IDENTIFIED BY 'password';#修改密码ALTER USER 'jeffrey'@'localhost' IDENTIFIED BY 'password';#修改连接账户的密码ALTER USER USER() IDENTIFIED BY 'password'; 或者使用mysqladmin修改密码，出于安全问题，不推荐使用。 1mysqladmin -u user_name -h host_name password "password" 密码管理Password Management MySQL使数据库管理员可以手动使帐户密码过期，并建立自动密码过期的策略。可以在全局建立到期策略，并且可以将个人帐户设置为遵循全局策略或使用特定的每帐户行为覆盖全局策略。 使用ALTER USER语句设置密码过期： 1ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE; 密码过期策略是自动的，并且基于密码的年龄和最近密码的更改日期和时间进行评估。mysql.user表上有上次更改密码的时间。要全局地建立自动密码过期策略，请使用default_password_lifetime系统变量。默认值为零，表示禁用自动密码过期。如果将值设置为正整数N，则表示允许的密码生存期，因此密码必须每N天更改一次。 栗子： 12345vim /etc/my.cnf[mysqld]default_password_lifetime=365 或者在MySQL中设置全局变量： 1SET GLOBAL default_password_lifetime = 365; 或者在创建账户时设置： 123456789101112CREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE INTERVAL 90 DAY;ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE INTERVAL 365 DAY;#禁用CREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE NEVER;ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE NEVER;#默认CREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE DEFAULT;ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE DEFAULT; Client成功连接后，Server将确定账户密码是否已过期： Server检查密码是否手动过期 否则，Server根据自动密码过期策略检查密码年龄是否大于其允许的生存期 密码过期和沙箱Password Expiration and Sandbox Mode 对于使用具有过期密码的账户的连接，Server要么断开连接，要么将Client限制为沙箱模式。 沙箱模式允许这些操作： Client可使用ALTER USER或SET PASSWORD重置账户密码。重置密码后，Server恢复回话的正常访问 代理用户Proxy Users MySQL Server使用身份验证插件验证客户端连接。验证给定连接的插件可以请求将外部连接用户视为不同的用户以进行特权检查。这就使外部用户成为第二个用户的代理。也就是说，假设第二个用户的权限： 外部用户是代理用户 第二个用户是被代理的用户 代理用户支持的要求Requirements for Proxy User Support 对于给定身份认证的插件的代理，必须满足一下条件： 必须通过插件本身或代表插件的MySQL Server服务器来支持代理 必须将代理用户账户设置为由插件进行身份验证(CREATE USER和ALTER USER语句) 必须创建代理用户账户并授予相关权限(CREATE USER和GRANT语句) 代理用户账户必须具有代理账户的proxy权限(GRANT语句) 对于连接到代理账户的Client将被视为代理用户，身份验证插件必须返回与客户端用户名不同的用户名，以指示代理账户的用户名，该用户名定义代理所承担的权限用户。 代理机制允许将客户端用户名映射到代理用户名，没有规定映射主机名。当连接Client与代理账户匹配时，Server会尝试使用身份验证插件返回的用户名和代理账户的主机名来查找账户的匹配项。 考虑如下账户定义： 1234567891011121314-- create proxy accountCREATE USER 'employee_ext'@'localhost' IDENTIFIED WITH my_auth_plugin AS 'my_auth_string';-- create proxied account and grant its privilegesCREATE USER 'employee'@'localhost' IDENTIFIED BY 'employee_pass';GRANT ALL ON employees.* TO 'employee'@'localhost';-- grant PROXY privilege to proxy account for proxied accountGRANT PROXY ON 'employee'@'localhost' TO 'employee_ext'@'localhost'; 当Client从localhost使用employee_ext连接时，MySQL使用名为my_auth_plugin的插件来执行身份验证。假设my_auth_plugin根据my_auth_string的内容向Server返回employee的用户名，并可能通过咨询某些外部身份验证系统。employee与employee_ext不同，因此返回employee作为请求，Server将employee_ext视为employee本地用户，以便进行权限检查。 Server通过检查employee_ext是否具有employee的PROXY权限来验证employee_ext是否可以对employee进行代理身份验证。 在此例中，employee_ext是代理用户，employee是被代理用户。 发生代理时，USER()和CURRENT_USER()函数可用于查看连接用户(代理用户)与当前会话账户(被代理的用户)之间的区别： 123456SELECT USER(), CURRENT_USER();+------------------------+--------------------+| USER() | CURRENT_USER() |+------------------------+--------------------+| employee_ext@localhost | employee@localhost |+------------------------+--------------------+ 授予代理权限Granting the Proxy Privilege 需要PROXY权限才能使外部用户连接并拥有其他用户的权限。要授予此权限，请使用GRANT语句。 1234567GRANT PROXY ON 'proxied_user' TO 'proxy_user';GRANT PROXY ON 'a' TO 'b', 'c', 'd';GRANT PROXY ON 'a' TO 'd' WITH GRANT OPTION;GRANT PROXY ON 'a' TO ''@'';REVOKE PROXY ON 'a' FROM 'b', 'c', 'd'; 默认代理用户Default Proxy Users 要制定某些或所有用户应使用给定的身份验证进行连接，请创建一个空白MySQL账户(&#39;&#39;@&#39;&#39;)，将其与该插件关联，然后让插件返回真实身份验证的用户名。 栗子： 12345678910-- create default proxy accountCREATE USER ''@'' IDENTIFIED WITH ldap_auth AS 'O=Oracle, OU=MySQL';-- create proxied accountsCREATE USER 'developer'@'localhost' IDENTIFIED BY 'developer_pass';CREATE USER 'manager'@'localhost' IDENTIFIED BY 'manager_pass';-- grant PROXY privilege to default proxy account for proxied accountsGRANT PROXY ON 'manager'@'localhost' TO ''@'';GRANT PROXY ON 'developer'@'localhost' TO ''@''; 默认代理用户和匿名用户冲突Default Proxy User and Anonymous User Conflicts 如果打算创建默认代理用户，请检查其他现有的匹配任何用户账户，这些账户优先于默认代理用户，因为他们可以阻止该用户按预期工作。 在前面的讨论中，默认代理账户在主机部分具有&#39;&#39;，与任何主机匹配。如果你设置了默认代理用户，请注意检查非代理账户是否存在相同的用户部分和主机部分中的%，因为%也匹配任何主机，但优先于&#39;&#39;，Server用于在内部对账户进行排序。 要避免此问题，请使用以下策略之一： 删除匿名用户，使其不与默认代理用户冲突 使用在匿名用户之前匹配的更具体的默认代理用户，如&#39;&#39;@localhost 创建多个代理用户。用于本地连接和远程连接 Server支持代理用户映射Server Support for Proxy User Mapping 一些身份验证插件为自身实现代理用户映射(如PAM)。默认情况下，其他身份验证插件不支持代理用户。如果启用了check_proxy_users系统变量，则Server会对发出此类请求的任何身份认证插件执行代理用户映射： 默认情况下，check_proxy_users被禁用。因此即使对请求Server支持代理用户的身份验证插件，Server也不执行用户代理映射。 如果启用了check_proxy_users，则可能还需要启用特定于插件的系统变量以利用Server代理用户映射支持： 对于mysql_native_password插件，请启用mysql_native_proxy_users 对于sha256_password插件，请启用sha256_password_proxy_users Server执行的代理用户映射受以下限制： 即使授权了关联的PROXY权限，Server也不会代理匿名用户(FROM)或从匿名用户代理(TO) 如果单个账户授予了多个代理账户的代理权限，则Server代理用户是不确定的。因此，不鼓励为多个被代理账户授予单个账户代理权限 代理用户系统变量Proxy User System Variables 两个系统变量有助于追踪代理登录过程： proxy_user如果未使用代理，则此值为NULL。否则，它表示代理用户账户。 external_user有时，身份验证插件可能会使用外部用户对MySQL Server进行身份验证。 用户账户User Account Locking 从MySQL v5.7.6开始，MySQL支持使用ACCOUNT LOCK和ACCOUNT UNLOCK子句为CREATE USER和ALTER USER语句锁定和解锁用户账户： 与CREATE USER一起使用时，这些子句指定新账户的初始锁定状态。如果没有任何一个子句，则账户将以未锁定状态创建。 与ALTER USER一起使用时，这些子句指定现有账户的新锁定状态。如果没有任何一个子句，则账户锁定状态保持不变。 账户锁定状态记录在mysql.user系统表的account_locked列中。使用SHOW CREATE USER显示账户锁定状态。 如果Client尝试连接到已锁定的账户，则会失败。返回错误消息，并将错误写入日志。 锁定账户不会影响能够使用承担锁定账户身份的代理用户进行连接。她也不会影响执行存储程序和试图的能力，这些程序或视图具有命名锁定账户的DEFINER子句。也就是说，锁定账户，不会影响使用代理账户或存储的程序或视图的能力。 要从旧版本升级到MySQL 5.7.6以及更高版本，请运行mysql_upgrade以确保此列存在。对于没有account_locked列的非升级安装，Server会将所有账户视为已解锁。 基于SQL的MySQL账户活动审计SQL-Based MySQL Account Activity Auditing 应用程序可以使用以下准则来执行基于SQL的审计，该审计将数据库活动与MySQL账户联系起来。 MySQL账户对应于mysql.user系统表中的行。当Client连接成功后，Server会将Client验证到此表中的特定行。此行中的User和Host列的值唯一标识该账号，并对应于user@host格式，其中账户名称在SQL语句中写入。 用于验证Client的账户确定Client具有哪些权限。通常，可以调用CURRENT_USER()函数来确定这对于Client用户来说是哪个账户。其值有账户的用户表行的User和Host列构成。但是，在某些情况下，CURRENT_USER()值不对应于客户端用户，而是对英语不同的账户。当权限检查不基于客户端账户时，会发生这种情况： 使用 SQL SECURITY DEFINER特性定义的存储例程 使用 SQL SECURITY DEFINER特性定义的视图 触发器和事件 在这些上下文中，权限检查是针对DEFINER账户完成的，而CURRENT_USER()是指该账户，而不是指调用存储例程或视图的Client或导致触发器激活的账户。 如果应用程序必须调用USER()进行用户审计，但是还必须能够将USER()值与用户表中的账户相关联，则必须避免使用在User或Host列中包含通配符。具体来说，不允许User为空，并且不允许Host值中使用模式字符或网络掩码表示法。所有账户必须具有非空用户值和文字主机值。 更改账户用户主机： 1234RENAME USER ''@'localhost' TO 'user1'@'localhost';RENAME USER 'user2'@'%.example.com' TO 'user2'@'remote.example.com';-- 如果user2必须能够从example.com域中的多个主机进行连接，则每个主机应该有一个独立的账户 要从CURRENT_USER()或USER()函数中提取用户名或主机名，请使用SUBSTRING_INDEX()函数： 1234567891011121314SELECT SUBSTRING_INDEX(CURRENT_USER(),'@',1);+---------------------------------------+| SUBSTRING_INDEX(CURRENT_USER(),'@',1) |+---------------------------------------+| user1 |+---------------------------------------+SELECT SUBSTRING_INDEX(CURRENT_USER(),'@',-1);+----------------------------------------+| SUBSTRING_INDEX(CURRENT_USER(),'@',-1) |+----------------------------------------+| localhost |+----------------------------------------+ 使用加密连接Using Encrypted Connections MySQL Client和Server之间的未加密连接，有权访问网络的人可以监视你的所有流量和C/S之间发送和接受的数据。要使任何类型的在网络中数据不可读，请使用加密。加密算法必须包含安全元素，以抵御多种已知的攻击。 MySQL支持使用TLS协议在C/S之间建立加密连接。TLS有时被称为SSL，但MySQL实际上并不使用SSL协议进行加密，因为它的加密很弱。TLS使用加密算法来确保可以信任通过公共网络接收的数据。它具有检测数据更改、丢失、重放的机制。TLS还包含使用X.509标准提供的身份验证的算法。X.509可以识别互联网上的某个人。在基本术语中，有一些被称为证书颁发机构(CA)的实体，它将电子证书分配给需要它们的任何人。证书依赖于两个加密密钥(公钥和私钥)的非对称加密算法。证书所有者可以将证书提供给另一方作为身份证明。证书由其所有者的公钥组成，使用该公钥加密的任何数据只能使用有该证书的私钥来解密。 可以使用OpenSSL和yaSSL编译MySQL以获得加密连接支持。默认情况下，如果Server支持加密连接，MySQL将尝试使用加密连接。如果无法建立加密连接，则会回退到未加密的连接。MySQL基于每个连接执行加密，并且对给定用户使用加密可以是可选的或强制的。这使你可以根据各个应用程序的要求选择加密或未加密的连接。 加密连接同样可用于Master和Slave的副本集之间。也可以通过MySQL C API获得加密连接。也可以使用SSH连接内的加密连接到MySQL Server。 配置MySQL以使用加密连接Configuring MySQL to Use Encrypted Connections 有几个选项用于指示是否使用加密连接，以及制定适当的证书和密钥文件。它包括： Server端 Client端 S端加密连接配置Server-Side Configuration for Encrypted Connections 在S端，--ssl选项指定Server允许但不需要加密连接。默认情况下启用此选项。Server端的这些选项标识了Server在允许Client建立加密连接时使用的证书和密钥文件： --ssl-caCA颁发的证书文件的路径名 ssl-certServer公钥证书文件的路径名。可以发送到Client端，并根据它具有的CA证书进行身份验证 ssl-keyServer私钥文件的路径名 启用加密连接，修改my.cnf的栗子： 1234[mysqld]ssl-ca=ca.pemssl-cert=server-cert.pemssl-key=server-key.pem C端加密连接配置Client-Side Configuration for Encrypted Connections 默认情况下，如果Server支持加密连接，MySQL Client将尝试建立加密连接，并通过--SSL-mode选项进一步控制： 如果没有ssl-mode选项Client将尝试使用加密连接，如果无法建立加密连接，则会回退到未加密的连接。这等同于--ssl-mode=PREFFERED --ssl-mode=REQUIREDClient需要加密连接，如果无法建立，则会失败 --ssl-mode=DISABLEDClient使用未加密连接 --ssl-mode=VERIFY_CA或--ssl-mode=VERIFY_IDENTITY客户端需要加密连接，并且还要针对Server CA证书和对其他证书中的Server主机名进行验证 Client以下几个选项类似于Server端的几个选项，标识C/S加密连接时使用的证书和密钥文件： --ssl-ca --ssl-cert --ssl-key 加密连接的命名选项Command Options for Encrypted Connections 本节介绍使用加密连接的选项。 123456789101112--skip-ssl Do not use encrypted connection --ssl Enable encrypted connection --ssl-ca File that contains list of trusted SSL Certificate Authorities --ssl-capath Directory that contains trusted SSL Certificate Authority certificate files --ssl-cert File that contains X.509 certificate --ssl-cipher List of permitted ciphers for connection encryption --ssl-crl File that contains certificate revocation lists --ssl-crlpath Directory that contains certificate revocation list files --ssl-key File that contains X.509 key --ssl-mode Security state of connection to server 5.7.11--ssl-verify-server-cert Verify host name against server certificate Common Name identity --tls-version Protocols permitted for encrypted connections 5.7.10 创建SSL/RSA证书和密钥Creating SSL and RSA Certificates and Keys 可以使用MySQL自身提供的工具或直接调用openssl命令来创建所需文件。 使用MySQL创建Creating SSL and RSA Certificates and Keys using MySQL MySQL提供了这些方法来创建SSL证书和密钥文件以及使用SSL支持加密连接所需的RSA密钥对文件，以及使用RSA通过未加密连接进行安全密码交换。如果缺少这些文件： 对于使用OpenSSL编译的MySQL发行版，Server可在启动时自动生成这些文件 用户可以手动调用mysql_ssl_rsa_setup实用程序 对于某些发行版(如RPM包)，在数据目录初始化期间会调用mysql_ssl_rsa_setup。在这种情况下，只要openssl命令可用，就不需要使用OpenSSL编译MySQL发行版 自动SSL和RSA文件生成 Automatic SSL and RSA File Generation 对于使用OpenSSL编译的MySQL发行版，MySQL Server能够在启动时自动生成缺少的SSL和RSA文件。auto_generate_certs和sha256_password_auto_generate_rsa_keys系统变量控制这些文件的自动生成。默认情况下启用这两个变量，它们可以在启动时启用并检查，但不能在运行时设置。 启动时，如果启用了auto_generate_certs系统变量，则Server会自动在数据目录中生成S端和C端的SSL证书和密钥文件。 Server检查数据目录下的SSL文件： 123ca.pemserver-cert.pemserver-key.pem 如果存在，则不创建。反之，则创建 123456ca.pem Self-signed CA certificateca-key.pem CA private keyserver-cert.pem Server certificateserver-key.pem Server private keyclient-cert.pem Client certificateclient-key.pem Client private key 如果Server自动生成了RSA文件，它将使用其名称来设置相应的系统变量 启动时，如果满足以下条件(sha256_password_auto_generate_rsa_keys系统变量已启用；没有指定RSA选项；数据目录中缺少RSA文件)，则Server会自动在数据目录中生成RSA私钥/公钥对文件。 Server检查数据目录下的RSA文件 12private_key.pem Private member of private/public key pairpublic_key.pem Public member of private/public key pair 如果存在，则不创建。反之，则创建 如果Server自动生成了RSA文件，它将使用其名称来设置相应的系统变量 手动生成 Manual SSL and RSA File Generation Using mysql_ssl_rsa_setup MySQL发行版包含此实用程序，但它需要openssl命令可用。 SSL/RSA文件特性 SSL and RSA File Characteristics 它们具有以下特性： SSL/RSA密钥大小为2048bits SSL CA证书是自签名的 SSL Server/Client的CA证书和密钥对，使用sha256WithRSAEncryption签名算法 创建的SSL文件自生成之日起有效期为十年 RSA文件不会过期 SSL文件对于每个证书/密钥对具有不同的序列号(1 for CA, 2 for Server, 3 for Client) 创建的文件由运行程序执行创建的用户拥有 Unix/Unix-Like上，证书文件权限为644，密钥文件权限为600 查看SSL证书内容： 123openssl x509 -text -in ca.pemopenssl x509 -text -in server-cert.pemopenssl x509 -text -in client-cert.pem 使用SQL语句查看SSL证书过期时间： 1234567SHOW STATUS LIKE 'Ssl_server_not%';+-----------------------+--------------------------+| Variable_name | Value |+-----------------------+--------------------------+| Ssl_server_not_after | Apr 28 14:16:39 2027 GMT || Ssl_server_not_before | May 1 14:16:39 2017 GMT |+-----------------------+--------------------------+ 使用openssl创建SSL证书和密钥Creating SSL Certificates and Keys Using openssl 创建栗子： 123456789101112131415161718192021222324# Create clean environmentrm -rf newcertsmkdir newcerts &amp;&amp; cd newcerts# Create CA certificateopenssl genrsa 2048 &gt; ca-key.pemopenssl req -new -x509 -nodes -days 3600 \ -key ca-key.pem -out ca.pem# Create server certificate, remove passphrase, and sign it# server-cert.pem = public key, server-key.pem = private keyopenssl req -newkey rsa:2048 -days 3600 \ -nodes -keyout server-key.pem -out server-req.pemopenssl rsa -in server-key.pem -out server-key.pemopenssl x509 -req -in server-req.pem -days 3600 \ -CA ca.pem -CAkey ca-key.pem -set_serial 01 -out server-cert.pem# Create client certificate, remove passphrase, and sign it# client-cert.pem = public key, client-key.pem = private keyopenssl req -newkey rsa:2048 -days 3600 \ -nodes -keyout client-key.pem -out client-req.pemopenssl rsa -in client-key.pem -out client-key.pemopenssl x509 -req -in client-req.pem -days 3600 \ -CA ca.pem -CAkey ca-key.pem -set_serial 01 -out client-cert.pem 验证： 1openssl verify -CAfile ca.pem server-cert.pem client-cert.pem 使用openssl创建RSA密钥Creating RSA Keys Using openssl 创建： 12345openssl genrsa -out private_key.pem 2048openssl rsa -in private_key.pem -pubout -out public_key.pemchmod 400 private_key.pemchmod 444 public_key.pem 安全插件Security Plugins MySQL包括几个实现安全功能的插件： 用于MySQL C/S 连接尝试的插件 用于实施密码强度策略和评估潜在密码强度的密码验证插件 用于敏感信息安全存储的密钥环(keyring)插件 MySQL企业版插件 身份认证插件Authentication Plugins 原生可插拔认证Native Pluggable Authentication MySQL包含两个实现原生身份认证的插件。在引入可插拔身份验证之前，基于密码散列的方法的身份验证。 本级密码验证的插件和库名称： Plugin or File Plugin or File Name Server-side plugin mysql_native_password Client-side plugin mysql_native_password Library file None (plugins are built in) 安装本机可插拔认证Installing Native Pluggable Authentication mysql_native_password插件存在于Server和Client的表单中： S端插件内置于Server，无需显式加载，也无法通过卸载来禁用 C端插件内置于libmysqlclient库中，可用于链接到此库的任何程序 使用本机可插拔认证Using Native Pluggable Authentication MySQL Client程序默认使用mysql_native_password。 旧的本机可插拔认证Old Native Pluggable Authentication MySQL version 4.1机之前。 从旧的插件迁移到新的插件Migrating Away from Pre-4.1 Password Hashing and the mysql_old_password Plugin SHA-256可插拔认证SHA-256 Pluggable Authentication 备份和恢复Backup and Recovery 数据备份非常重要！ MySQL提供了各种备份策略，你可以从中选择最适合安装要求的方法。本章讨论几个你应该熟悉的备份和恢复的主题： 备份类型： 逻辑与物理，全量和增量… 创建备份的方法 恢复方法，包括时间点(point-in-time)恢复 备份调度，压缩和加密 表维护，以便恢复损坏的表 备份和恢复类型Backup and Recovery Types 物理与逻辑备份Physical (Raw) Versus Logical Backups 物理备份由目录的原始副本和存储数据库内容的文件组成。此类备份适用于需要在出现问题时快速恢复的大型重要数据库。 逻辑备份保存表示为逻辑数据库结构的信息(CREATE DATABASE, CREATE TABLE语句)和内容(INSERT语句和分割文本文件)。此类备份适用于较少量的数据，你可以在其中编辑数据值或表结构，或在不同计算机体系结构上重新创建数据。 物理备份方法具有以下特征： 此备份包含数据库目录和文件的精确副本。通常，这是MySQL数据目录的全部或部分副本 物理备份比逻辑备份更快，因为它们只涉及文件复制而不进行转换 输出比逻辑备份更紧凑(compact) 由于备份速度和紧凑性对于繁忙、重要的数据库很重要，因此MySQL Enterprise执行物理备份 备份和还原粒度范围从整个数据目录的级别到单个文件的级别。这可能会/也可能不会提供表级别的粒度，具体取决于存储引擎 除数据库外，此备份还可以包括任何相关文件(如日志和配置) 来自MEMORY表的数据很难以这种方式备份，因为它们的内容不存储在磁盘上 备份仅可移植到具有相同或类似硬件特征的其它计算机 可以在MySQL Server未运行时执行备份。如果Server正在运行，则必须执行适当锁定(lock)，以便Server在备份期间不会更改数据库内容。MySQL Enterprise备份会自动为它需要的表执行锁定 物理备份工具包括用于InnoDB或任何其它表的mysqlbackup，或用于MyISAM表的文件系统级别命令(cp, scp, tar, rsync) 对于恢复 MySQL Enterprise备份恢复InnoDB和备份的其它表 ndb_restore恢复NDB表 可使用文件系统级别的命令将文件复制回其原始位置 逻辑备份方法具有以下特性： 通过查询MySQL Server来获取数据库结构和内容信心来完成备份 此备份比物理备份慢，因为Server必须访问数据库信息并将其转换为逻辑格式 输出大于物理备份，特别是以文本格式保存时 备份和还原可在Server级别，数据库级别或表级别，而无论存储引擎如何 备份不包括日志和配置文件，或其它不属于数据库的相关文件 以逻辑格式的备份与机器无关，请具有高度可移植性 在MySQL Server运行时执行逻辑备份 逻辑备份工具包括mysqldump程序和SELECT ... INTO OUTFILE语句。这适用于任何存储引擎，甚至是MEMORY 要恢复逻辑备份，可使用mysql客户端处理SQL格式转储文件。要加载分割文本文件，使用LOAD DATA INFILE语句或mysqlimport客户端 在线与离线备份Online Versus Offline Backups 在MySQL Server运行时进行在线备份，以便可以从Server获取数据库信息。Server停止时进行离线备份。这种区别也可描述为热备(hot)与冷备(cold)，热备是Server保持允许但在外部访问数据库时锁定表以防止修改数据 在线备份具有以下特性： 此备份对其它客户端的干扰较小，其它客户端可在备份期间连接到MySQL Server，并且可以根据需要执行的操作来访问数据库 必须小心施加适当的锁定，以便不会发生损害备份完整性的数据修改。MySQL Enterprise会自动执行锁表 脱机备份方法有以下特性： 客户端可能会受到不利影响，因为备份期间Server不可用。因此，此类备份通常发生于Slave Server，可以脱机而不会损害可用性 备份过程简单，因为不会受到客户端活动的干扰 在线和离线之间的区别适用于恢复操作，并且适用于类似的特征。但是，由于恢复需要更强的锁定，因此客户端更有可能受到在线恢复的影响而不是在线备份。在备份期间，客户端可能能够在备份时读取数据；而恢复数据不仅仅是读取数据，因此必须防止客户端在恢复数据时访问数据。 本地与远程备份Local Versus Remote Backups 本地备份是在运行MySQL Server的统一主机上执行，而远程备份则从其它主机执行。 mysqldump能连接到本地或远程Server。对于SQL输出，既可在本地也可在远程；对于分割文件输出，将在Server上创建数据文件 SELECT ... INTO OUTFILE可从本地或远程启动，但输出文件是在Server上创建 物理备份通常在Server上启动，以便Server可以脱机 快照备份Snapshot Backups 某些文件系统可以实现快照，它们在给定时间点提供文件系统的逻辑副本，而不需要整个文件系统的物理副本。MySQL本身并未提供此功能，可通过Veritas, LVM或ZFS… 全量与增量备份Full Versus Incremental Backups 全量备份包括MySQL Server在给定时间点管理的所有数据；增量备份包括在给定时间点跨度内（从一个时间点到另一个时间点）对数据所做的更改。 全量与增量恢复Full Versus Point-in-Time (Incremental) Recovery 全量恢复可从完整备份恢复所有数据。这会将Server实例还原到备份时的状态。增量恢复是恢复在给定时间点跨度内所做的更改，这也称为时间点恢复。它基于二进制日志，通常在备份文件完全恢复之后，将备份文件还原到备份时的状态。然后，在二进制日志文件中写入的数据更改将作为增量恢复应用于重做数据修改，并使Server达到所需的时间点。 表维护Table Maintenance 如果表损坏，数据完整性可能会受到影响。 备份调度，压缩和加密Backup Scheduling, Compression, and Encryption 备份调度对于自动化备份过程很有价值；压缩备份输出可减少空间需求；输出加密可提供更好的安全性，防止未经授权访问备份数据。MySQL本身不提供这些功能，可使用第三方方案。 数据库备份方法Database Backup Methods 使用MySQL Enterprise进行热备 使用mysqldump进行备份Making Backups with mysqldump mysqldump程序可以进行备份，它可以备份各种表。 通过复制表文件进行备份Making Backups by Copying Table Files 对于使用自己的文件表示每个表的存储引擎，可通过复制这些文件来备份表。要获得一致性的备份，请停止服务器或锁定并刷新相关表： 1FLUSH TABLES tbl_list WITH READ LOCK; 你只需要一个读锁，这使得其它客户端可以在你复制数据库目录中的文件时继续查询表。需要刷新以确保在开始备份之前将所有活动索引页写入磁盘。只要Server没有更新，你也可以通过复制所有表文件来创建二进制备份。 通过分隔文本文件备份Making Delimited-Text File Backups 要创建包含表数据的分隔文本文件，可使用SELECT * INTO OUTFILE ‘filename’ FROM tablename语句进行创建。此方法适用于任何类型的数据文件，但仅保存表数据，而不保存表结构。 要载入分隔文本文件，请使用LOAD DATA INFILE或mysqlimport。 通过启用二进制日志进行增量备份Making Incremental Backups by Enabling the Binary Log MySQL支持增量备份，必须使用--log-bin选项启动Server以支持二进制日志记录。二进制日志文件为你提供了在执行备份之后副本数据库所需的信息。目前，你希望进行增量备份，你应该使用FLUSH LOGS轮换二进制日志。完成此操作后，你需要将所有二进制日志复制到备份位置，这些日志的范围从上次完全备份或增量备份到最后一个备份之一。 通过使用副本集Slaves进行备份Making Backups Using Replication Slaves 如果在进行备份时Master Server出现性能问题，可在Slave Server上进行复制和备份。 恢复损坏的表Recovering Corrupt Tables 如果必须还原已损坏的MyISAM表，请尝试首先使用REPAIR TABLE或myisamchk -r恢复它们。这应该在99.9％的情况下有效。 使用文件系统快照进行备份Making Backups Using a File System Snapshot VXFS文件系统操作步骤，其它文件系统类似： 客户端程序执行FLUSH TABLES WITH READ LOCK 从shell执行mount vxfs snapshot 解锁UNLOCK TABLES 从快照复制文件 umount快照 备份和恢复栗子Example Backup and Recovery Strategy 请注意磁盘问题，万一是磁盘不可用那就… 建立备份策略Establishing a Backup Policy 为了有用，必须定期进行备份。可使用多种工具在MySQL中完成全量备份。 12#备份之前锁表mysqldump --single-transaction --all-databases &gt; bacup.sql 全量备份是必要的，但创建它们并不总是方便。生成大型备份文件要话费大量时间和空间，它并非最佳。所以，进行初始化全量备份，然后进行增量备份更有效。增量备份更小，时间更短。 要进行增量备份，需要保存增量更改。在MySQL中，这些更改在二进制日志中表示，因此应始终使用--log-bin选项启动MySQL Server已启动二进制日志。启用它之后，Server会在更新数据时将每个数据更改写入文件。每次重启时，MySQL Server都会使用序列中的下一个数字创建创建一个新的二进制日志文件。在Server运行时，你还可以告诉它关闭当前的二进制日志文件并通过FLUSH LOGS语句或mysqladmin flush-logs命令手动开始新的二进制日志文件。mysqldump还有一个刷新日志的选项，数据目录中的.index文件包含目录中所有MySQL二进制日志的列表。 12345xxx-bin.000001xxx-bin.000002xxx-bin.000003xxx-bin.000004xxx-bin.index MySQL二进制日志对于恢复非常重要，因为它们构成了一组增量备份。如果确保在进行全量备份时刷新日志，则之后创建的二进制日志文件将包含自备份以来所做的所有数据的更改。 123mysqldump --single-transaction --flush-logs --master-data=2 \ --all-databases &gt; backup.sql#之后便会创建一个新的二进制日志文件 MySQL二进制日志占用磁盘空间，可不时删除它们。 1234mysqldump --single-transaction --flush-logs --master-data=2 \ --all-databases --delete-master-logs &gt; backup.sql#在副本集中，使用mysqldump --delete-master-logs删除MySQL二进制日志可能会很危险，因为可能Slave Server尚未处理完二进制日志的内容#可使用 PURGE BINARY LOGS语句删除 使用备份进行恢复Using Backups for Recovery 123456#全量恢复mysql &lt; backup.sql#增量恢复mysqlbinlog xxx-bin.000007 xxx-bin.000008 | mysql 备份策略摘要Backup Strategy Summary 不怕一万，就怕万一。InnoDB本身可以完成恢复数据的所有工作。但为了确保高枕无忧，请遵守以下准则： 始终使用--log-bin选项运行MySQL Server 使用mysqldump定期进行全量备份 使用FLUSH LOGS或mysqladmin flush-logs刷新日志来定期进行增量备份 mysqldump备份Using mysqldump for Backups 本节介绍如何使用mysqldump生产转储文件，以及如何重新加载转储文件。转储文件可通过多种方式使用： 作为备份，在数据丢失的情况下启用数据恢复 作为设置副本集的数据源 作为实验数据源 mysqldump处理两种类型的输出，具体取决于有无-tab选项： 没有--tab选项，mysqldump将SQL语句写入标准输出。输出包含用于创建转储对象(db, table, sotred routines)的CREATE语句，以及用于将数据加载到表中的INSERT语句。输出可保存到文件中。 带有--tab选项，mysqldump为每个转储的表生成两个输出文件。Server将一个文件写为制表符(tab)分隔的文本，每个表的行(row)为文本的一行，输出名为table_name.txt。Server还将创建表的CREATE TABLE语句发送到mysqldump，mysqldump将其写为输出目录中名为table_name.sql的文件。 使用mysqldump以SQL格式转储数据Dumping Data in SQL Format with mysqldump 12345678910111213mysqldump [args] &gt; file_name#all dbmysqldump --all-databases &gt; dbs.sql#specific dbmysql --databases test &gt; testDB.sqlmysqldump test &gt; testDB.sqlmysqldump --databases db1 db2 db3 &gt; db123.sqlmysqldump db1 db2 db3 &gt; db123.sql 关于有无--databases选项的区别： 转储输出不包含CREATE DATABASE或USE语句 重新加载转储文件时，必须指定默认数据库名称，以便Server知道要重新加载的数据库 对于重新加载，你可以指定与原始名称不同的数据库名，这使你可将数据重新加载到其它数据库中 如果要重载的数据库不存在，则必须先创建它 由于输出不包含CREATE DATABASE语句，因此--add-drop-database选项无效 只备份数据库表结构mysqldump使用-d(--no-data)选项，可以只备份数据库中表结构，而不备份数据。 栗子： 12345678910#-d(--no-data)#某个库中的所有表的结构mysqldump -h xxx --port 3306 -u xxx -p -d 数据库名 &gt; 数据库名.sql#之后再导入#某个表的结构mysqldump -h xxx -u xxx -p -d --databases=xxx --tables xxx &gt; 表.sql 重载SQL格式备份Reloading SQL-Format Backups 要重载由mysqldump备份的包含SQL语句的转储文件，使用mysql客户端输入。如果使用了--databases选项，则它包含了CREATE DATABASE和USE语句，就没有必要指定默认数据库。 12345678mysql &lt; dump.sql#或mysql&gt; source dump.sql#未使用--databases选项mysqladmin create db1mysql db1 &lt; dump.sql 使用mysqladmin以分隔文本格式转储数据Dumping Data in Delimited-Text Format with mysqldump 本节介绍如何使用mysqldump创建分隔文本转储文件。 123456789101112131415mysqldump --tab=/tmp db1#db1.txt#其它选项：--fields-terminated-by=str--fields-enclosed-by=char--fields-optionally-enclosed-by=char--fields-escaped-by=char--lines-terminated-by=str#栗子mysqldump --tab=/tmp --fields-terminated-by=, --fields-enclosed-by=&apos;&quot;&apos; --lines-terminated-by=0x0d0a db1 重载分隔文本格式的备份Reloading Delimited-Text Format Backups 123mysql db1 &lt; t1.sqlmysqlimport db1 t1.txt 12USE db1;LOAD DATA INFILE `t1.txt` INTO TABLE t1; mysqldump小技巧本节介绍使用mysqldump解决特定问题的技术： 如何复制数据库 如何将数据库从一个Server复制到另一个Server 如何转储存储的程序 如何单独转储定义和数据 复制数据库Making a Copy of a Database 123mysqldump db1 &gt; dump.sqlmysqladmin create db2mysql db2 &lt; dump.sql 将数据库从一个Server复制到另一个ServerCopy a Database from one Server to Another 123456789101112#Server1mysqldump --databases db1 &gt; dump.sql#Server2mysql &lt; dump.sql#无--databasesmysqldump db1 &gt; dump.sqlmysqladmin create db1mysql db1 &lt; dump.sql 转储存储的程序Dumping Stored Programs 几个选项控制mysqldump如何处理存储的程序： 12345678--events: Dump Event Scheduler events--routines: Dump stored procedures and functions--triggers: Dump triggers for tables--skip-events--skip-routines--skip-triggers. 转储表定义和Dumping Table Definitions and Content Separately 1234567#--no-data，不转储表数据，导致转储文件只包含用于创建表的语句#--no-create-info, 从输出中抑制CREATE语句，以便转储文件包含表数据mysqldump --no-data test &gt; dump-defs.sqlmysqldump --no-create-info test &gt; dump-data.sqlmysqldump --no-data --routines --events test &gt; dump-defs.sql 使用mysqldump测试升级不兼容性Using mysqldump to Test for Upgrade Incompatibilities 123456#oldmysqldump --all-databases --no-data --routines --events &gt; dump-defs.sql#newmysql &lt; dump-defs.sql 使用二进制日志进行增量恢复Point-in-Time (Incremental) Recovery Using the Binary Log 时间点恢复是指恢复自给定时间点以来所做的数据更改。通常，在还原全量备份之后执行此类恢复。 时间点恢复基于以下原则： 时间点恢复的信息源是由全量备份操作之后生成的二进制日志文件表示增量备份集，请开启--bin-log选项要从二进制日志还原数据，你必须知道二进制日志文件的名称和位置，默认情况下，它在数据目录中。 12345SHOW BINARY LOGS;--确定当前binary log file名称SHOW MASTER STATUS; mysqlbinlog实用程序将二进制日志文件中的事件从二进制格式转换为文本，以便可以执行或查看它们mysqlbinlog具有根据日志中事件时间或事件位置选择二进制日志部分的选项。 从二进制日志执行事件会导致重做它们所代表的数据修改，这样可以恢复给定时间段内的数据更改。 12#从二进制日志中执行事件mysqlbinlog binlog_files | mysql -u root -p 当需要确定事件时间或位置以在执行事件之前选择部分日志内容时，查看日志内容很有用 12345#查看binary logmysqlbinlog binlog_file | more#或mysqlbinlog binlog_file &gt; tmpfile 将输出保存在文件中非常有用，可以在删除某些事件时执行日志内容 1mysql -u root -p &lt; tmpfile 如果要在MySQL Server上执行多个二进制日志，安全的方法是使用与Server的单个连接来处理它们 1234567891011121314#unsafe#可能导致某些问题mysqlbinlog binlog.000001 | mysql -u root -p # DANGER!!mysqlbinlog binlog.000002 | mysql -u root -p # DANGER!!#safemysqlbinlog binlog.000001 binlog.000002 | mysql -u root -p#或mysqlbinlog --skip-gtids binlog.000001 &gt; /tmp/statements.sqlmysqlbinlog --skip-gtids binlog.000002 &gt;&gt; /tmp/statements.sqlmysql -u root -p -e "source /tmp/statements.sql" 使用事件时间进行时间点恢复Point-in-Time Recovery Using Event Times 要指示恢复的开始和结束时间，请以DATATIME格式指定mysqlbinlog的--start-datetime和--stop-datetime选项。请先查看binary log的时间区间。 1234567#恢复数据直到停止时间mysqlbinlog --stop-datetime="2005-04-20 9:59:59" \ /var/log/mysql/bin.123456 | mysql -u root -p#恢复数据从开始时间mysqlbinlog --start-datetime="2005-04-20 10:01:00" \ /var/log/mysql/bin.123456 | mysql -u root -p 使用事件位置进行时间点恢复Point-in-Time Recovery Using Event Positions mysqlbinlog的--start-position和--stop-position选项可用于指定日志位置，它的工作方式与指定时间类似。使用位置可以更准确地了解要恢复的日志部分，尤其是在许多事务与破坏性语句同时发生的情况下。要确定位置编号，请在执行不需要的事物的时间附近运行mysqlbinlog一段时间，但将结果重定向到文本文件以供检查: 123mysqlbinlog --start-datetime="2005-04-20 9:55:00" \ --stop-datetime="2005-04-20 10:05:00" \ /var/log/mysql/bin.123456 &gt; /tmp/mysql_restore.sql 位置编号以log_pos数字进行标记，查看并找到相应的位置标号，之后便可使用它们。 123456mysqlbinlog --stop-position=368312 /var/log/mysql/bin.123456 \ | mysql -u root -pmysqlbinlog --start-position=368315 /var/log/mysql/bin.123456 \ | mysql -u root -p MyISAM表维护和崩溃恢复MyISAM Table Maintenance and Crash Recovery 本节讨论了如何使用myisamchk检查或修复MyISAM表——具有用于存储数据和索引的.MYD和.MYI文件。你可以使用myisamchk来检查、修复、优化数据库表。 尽管使用myisamchk进行表修复十分安全，但在进行修复或任何可能对表进行大量更改的维护操作之前进行备份总是一个好主意。 影响索引的myisamchk操作可能导致使用与MySQL Server使用的值不兼容的全文参数重建MyISAM FULLTEXT索引。 MyISAM表也可以使用类似于myisamchk操作的SQL语句来完成： 检查MyISAM表，CHECK TABLE 修复MyISAM表，REPAIR TABLE 优化MyISAM表，OPTIMIZE TABLE 分析MyISAM表，ANALYZE TABLE 这些语句可以直接使用，也可通过mysqlcheck客户端程序使用。这些语句相对于myisamchk的一个优点是Server可以完成所有工作。使用myisamchk，你必须确保Server不会同时使用这些表，以便myisamchk和Server之间不会发生不需要的交互。 使用myisamchk进行崩溃恢复Using myisamchk for Crash Recovery 如果在禁用外部锁定(default)的情况下运行mysqld，则当mysqld使用同一个表时，你无法可靠地使用myisamchk来检查表。如果你可以确定在运行myisamchk时没有人会通过mysql访问表，你只需要在开始检查表之前执行mysqladmin flush-tables。如果你不能保证这一点，你必须在检查表时停止mysqld。如果你运行myisamchk来检查mysqld同时更新的表，你可能会收到一个警告，即使表没有也如此。 如果Server启用了外部锁定(external locking)，则可以随时使用myisamchk检查表。在这种情况下，如果Server尝试更新myisamchk正在使用的表，Server将等待myisamchk完成后再继续。 如果要使用myisamchk来修复或优化表，则必须始终确保mysqldServer未使用该表(或外部锁定)。如果没有停止mysqld，你应该在运行myisamchk之前至少做一个mysqladmin flush-tables。如果Server和myisamchk同时访问表，你的表可能会损坏。 执行崩溃恢复时，请务必了解数据库中每个MyISAM表table_name都对应于下面现实的数据库目录中的三个文件: 1234#数据文件和索引文件最常出问题tbl_name.frm Definition (format) filetbl_name.MYD Data filetbl_name.MYI Index file myisamchk的工作原理时逐行创建.MYD数据文件的副本。它通过删除旧的.MYD文件并将新文件重命名为原始文件名来结束修复阶段。如果使用--quick选项，myisamchk不会创建临时的.MYD文件，而是假定.MYD文件正确并且只生成新的索引文件而不触及.MYD文件。这是安全的，因为myisamchk会自动检查.MYD文件是否已损坏，如果存在则终止修复。 如何检查MyISAM表是否存在错误How to Check MyISAM Tables for Errors 使用以下命令检查MyISAM表： myisamchk tbl_name这能发现99.99%的错误，它找不到的是仅涉及数据文件的损坏。 myisamchk -m tbl_name这能发现99.999%的错误。它首先检查所有索引条目是否有错，然后读取所有行。它计算行中所有键值的校验和，并验证校验和是否与索引树种键的校验和匹配。 myisamchk -e tbl_name这可以对所有数据进行全面彻底的检查。 myisamchk -e -i tbl_name打印更多统计信息 如何修复MyISAM表How to Repair MyISAM Tables 你同样可使用CHECK TABLE和REPAIR TABLE语句来检查和修复MyISAM表。 损坏的表的症状： tbl_name.frm被锁定以防止修改 找不到文件tbl_name.MYI(Errorcode: nnn) 意外的文件结束 记录文件崩溃 从表处理获得error nnn 获取更多有关错误的信息： 1234567891011#perror nnnperror 126 127 132 134 135 136 141 144 145MySQL error code 126 = Index file is crashedMySQL error code 127 = Record-file is crashedMySQL error code 132 = Old database fileMySQL error code 134 = Record was already deleted (or record file crashed)MySQL error code 135 = No more room in record fileMySQL error code 136 = No more room in index fileMySQL error code 141 = Duplicate unique key or constraint on write or updateMySQL error code 144 = Table is crashed and last repair failedMySQL error code 145 = Table was marked as crashed and should be repaired 如果要从命令行修复表，则必须先停止mysqld Server。请注意，当你在远程Server执行mysqladmin shutdown时，mysqld Server在mysqladmin返回后仍然可用一段时间，直到所有语句处理并已停止并且所有索引更改都已刷新到磁盘。 步骤1： 检查表 123456myisamchk *.MYI#myisamchk -e *.MYI#如果mysqld已停止，使用--update-state告诉myisamchk将表标记为已检查myisamchk --update-state *.MYI 步骤2： 简易修复表 123456789#尝试修复索引，而不触及数据myisamchk -r -q table_name#数据1. 数据备份2. myisamchk -r table_name #这将删除不正确的行和以排除的行，并重构索引文件3. 如果上一步失败，请使用 myisamchk --safe-recover tbl_name4. 如果遇到意外错误，查看第3步 步骤3： 难以修复 1234567891011#只有当索引文件中的第一个16KB块被销毁或包含不正确的信息，或索引文件丢失时，才应该到达此阶段。#这种情况系，需要创建一个新的索引文件1. 将数据移动到安全的地方2. 创建空数据和新索引mysql db_namemysql&gt; SET autocommit=1;mysql&gt; TRUNCATE TABLE table_name;mysql&gt; QUIT3. 将旧的数据文件复制回新创建的数据文件4. 重新执行步骤2 步骤4： 很难修复 1234#仅当.frm描述文件也崩溃时才应该到达此阶段#这应该永远不会发生，因为创建表后描述文件不会发生更改1. 从备份还原描述文件并回到步骤32. 如果没有备份，但确切知道如何创建表，请在另一个数据库中创建该表的副本。删除新数据文件，然后将.frm和.MYI移动到崩溃的数据库。返回步骤2尝试重建索引文件 优化MyISAM表MyISAM Table Optimization 要合并碎片行并消除因删除或更新行而导致的浪费空间，请在恢复模式下运行myisamchk: myisamchk -r table_name 你也可以通过OPTIMIZE TABLE的SQL语句进行表优化。此语句执行表修复和Key 分析，并对索引数进行排序，以便Key查找更快。 myisamchk有许多其它选项可用于提高表的性能： --analyze or -a执行Key分析。这可通过使连接优化器更好地选择连接表的顺序自己应该使用的索引来提高连接性能。 --sort-index or -S排序索引块。这可优化搜索并使表扫描更快地使用索引。 --sort-records=index_num or -R index_num根据给定索引对数据行进行排序。这可使数据更加本地化，并可以加速使用此索引的基于范围的SELECT和ORDER BY操作 配置MyISAM表维护计划Setting Up a MyISAM Table Maintenance Schedule 最好定期执行检查表，而不是等着问题发生。启用自动检查MyISAM表也是一个好主意。还应该在正常系统操作期间定期检查你的表。 1234#栗子35 0 * * 0 /path/to/myisamchk --fast --silent /path/to/datadir/*/*.MYImyisamchk -r -s --sort-index --myisam_sort_buffer_size=16M */*.MYI 优化Optimization 本章介绍如何优化MySQL性能并提供示例。优化涉及多个级别配置，调整和测量性能。根据你的工作角色(Developer、DBA、both)，你可在单个SQL语句、整个应用程序、单个数据库Server、多个网络数据库Server的级别进行优化。有时你可以主动并提前计划性能，而有时可能会在出现问题后解决配置或代码问题。优化CPU和内存使用还可以提供伸缩性，允许数据库处理更多负载而不会降低速度。 优化概述Optimization Overview 数据库性能取决于数据库级别的几个因素，如表、查询、配置设置。这些软件结构导致硬件级别的CPU和I/O操作，你必须尽可能降低这些操作并使其尽可能高效。在处理数据库性能时，首先要了解软件方面的高级规则和指南，并使用挂钟时间(wall-clock time)来衡量性能。当你成为专家后，你将了解更多内部发生的信息，并开始测量CPU周期和I/O操作… 典型用户的目标是从现有的软件和硬件配置中获取最佳的数据库性能；高级用户寻找改进MySQL软件本身的机会，或者开发自己的存储引擎或硬件设备来扩展MySQL生态系统。 数据库级别的优化Optimizing at the Database Level 使数据库应用程序快速运行的最重要的因素是其基本设计： 表结构是否合适？特别是，列(columns)是否具有正确的数据类型，并且每个表是否具有适合工作类型的列？例如，更新频繁的应用程序通常具有少量列的许多表；而分析大量数据的应用程序通常具有大量列的少量表。 是否有适当的索引来提高查询效率？ 是否为每个表使用了适当的存储引擎，并利用使用的每个存储引擎的优势和功能？特别是，诸如InnoDB之类的事务性(transactional)存储引擎或诸如MyISAM之列的非事务性(nontransactional)存储引擎的选择，对于性能和伸缩性非常重要。InnoDB是新表的默认存储引擎。实际上，先进的InnoDB性能特征意味着InnoDB表通常优于更简单的MyISAM表，尤其是对于繁忙的数据库。 是否每个表都使用了适当的行格式？这取决于表所使用的数据库。特别是，压缩的表使用较少的磁盘空间，因此需要较少的磁盘I/O来读取和写入数据。压缩适用于InnoDB表的各种工作负载，以及只读(read-only)MyISAM表。 是否应用程序使用了适当的锁定策略？例如，通过允许共享访问，以便数据库操作可以并发运行，并在适当时请求独占访问，以便关键操作成为首要任务。同样，存储引擎的选择也很重要。InnoDB存储引擎可以处理大多数锁定问题而无需你的参与，从而在数据库中实现更好的并发性，并减少代码的实验和调优。 是否正确使用了用于缓存的所有内存区域？也就是说，足够大以容纳频繁访问的数据，但不能太大以至于它们会超载物理内存并导致分页。要配置的主缓存区域是：InnoDb缓冲池，MyISAM key缓存、MySQL查询缓存。 硬件级别的优化Optimizing at the Hardware Level 随着数据库变得越来越繁忙，任何数据库应用程序最终都会达到硬件限制。DBA必须评估是否可以调整应用程序或重新配置Server以避免这些瓶颈(bottlenecks)，或者是否需要更多硬件资源？ 系统瓶颈通常来自于这些来源： 磁盘需求磁盘需要一段时间才能找到一段数据。对于现代磁盘，平均时间通常低于10ms。优化搜索时间的方法是将数据分发到多个磁盘上。 磁盘读写当磁盘位于正确位置时，我们需要读写数据。可以从多个磁盘并行读取。 CPU周期当数据在主存储器中时，我们必须处理它们以获得我们想要的结果。 内存带宽当CPU需要的数据量超过了CPU缓存容量时，主存带宽就成了瓶颈。 平衡移植性和性能Balancing Portability and Performance 要在可移植的MySQL程序中使用面向性能的SQL扩展，你可在语句中包含MySQL特定关键字/* ... */评论分隔符(或--注释) 优化SQL语句Optimizing SQL Statements 数据库应用程序的核心逻辑是通过SQL语句执行的，无论是直接通过解释器还是通过API在幕后提交。 优化SELECT语句Optimizing SELECT Statements 查询以SELECT语句的形式执行数据库中的所有查找操作。调整这些语句的首要任务就是缩短响应时间。除了SELECT语句外，查询的调优技术也适用于DELETE语句中的CREATE TABLE ... AS SELECT, INSERT INTO ... SELECT和WHERE等构造子句。这些语句具有额外的性能考虑因素，因为它们将写操作与面向读操作的查询相结合。 优化查询的主要考虑因素有： 要使一个慢的SELECT ... WHERE查询更快，首先要检查是否可以添加索引。在WHERE字句中使用的列上设置索引，以加快评估、过滤和结果的最终检索。为避免浪费磁盘空间，请构建一小组索引，以加速应用程序中使用的许多相关查询。索引对于引用不同表的查询尤其重要，使用连接(joins)和外键(foreign keys)等功能。 隔离并调整查询的任何部分，例如函数调用，这会占用过多时间。根据查询的结构，可以为结果集中的每一行调用一次函数，甚至可以为表中的每一行调用一次函数，从而大大减轻任何低效率。 最大限度地减少查询中的全表扫描次数，尤其是对于大型表。 定期使用ANALYZE TABLE语句使表统计信息保持最新，因此优化程序具有构建有效执行计划所需的信息。 了解特定于每个表的存储引擎的调优技术，索引技术和配置参数。InnoDB和MyISAM都有一套指导方针，可以在查询中实现和维持高性能。 你可以优化InnoDB表的单查询事务。 避免以难以理解的方式转换查询。 如果其中一个基本准则无法轻松解决性能问题，请通过阅读EXPLAIN计划并调整索引、WHERE子句、JOIN子句等来调查特定查询的内部详细信息。 调整MySQL用于缓存区域的大小和属性。通过有效使用InnoDB buffer pool、MyISAM key cache、MySQL query cache，重复查询运行的更快，因为在第二次及以后的时间内都是从内存中检索结果 即使对于使用高速缓存存储区快速运行的查询，你仍可以进一步优化，以便它们需要更少的高速缓存，从而使你的应用程序更具可伸缩性。可伸缩性意味着你的应用程序可以处理更多的并发用户，更大的请求…，而不会出现性能大幅下降的情况 处理锁定问题，其中查询的速度可能会受到同时访问表的其它回话的影响 WHERE子句优化WHERE Clause Optimization 你可能想要重写查询以更快地进行过算数运算，同时牺牲可读性。因为MySQL会自动执行类似的优化，所以通常可以避免这种工作，并使查询保持更容易理解和可维护的形式。 移除不必要的括号 12((a AND b) AND c OR (((a AND b) AND (c AND d))))--&gt; (a AND b AND c) OR (a AND b AND c AND d) 恒量折叠 12(a&lt;b AND b=c) AND a=5--&gt; b&gt;5 AND b=c AND a=5 恒量条件去除 12(B&gt;=5 AND B=5) OR (B=6 AND 5=5) OR (B=7 AND 5=6)--&gt; B=5 OR B=6 索引使用的常量表达式仅计算一次 早期检测无效常量表达式 如果不使用GROUP BY或聚合函数(COUNT(), MIN()...)，HAVING将与WHERE合并 对于连接中的每个表，构造一个更简单的WHERE以获得对表的快速平均，并且还尽快跳过行 在查询中的任何其它表之前，首先读取所有常量表： 一个空表或只有一行的表 与主键或唯一索引上的WHERE子句一起使用的表，其中所有索引部分都与常量表达式进行比较并定义为NOT NULL 以下所有表都用作常量表： 123SELECT * FROM t WHERE primary_key=1;SELECT * FROM t1,t2 WHERE t1.primary_key=1 AND t2.primary_key=t1.id; 通过尝试所有可能性，可以找到加入表格的最佳连接组合。如果ORFER BY和GROUP BY子句中的所有列都来自同一个表，则在加入时首先选择该表 如果存在ORDER BY子句和不同的GROUP BY子句，或者ORDER BY或GROUP BY包含连接队列中第一个表以外的表中的列，则会创建临时表 如果使用SQL_SMALL_RESULT修饰符，MySQL将使用内存中的临时表 查询每个表索引，并使用最佳索引，除非优化程序认为使用表扫描更有效。 在某些情况下，MySQL甚至无需查阅数据文件即可从索引中读取行。 在输出每一行之前，将跳过与HAVING子句不匹配的行。 一些非常快的查询示例： 123456789101112SELECT COUNT(*) FROM tbl_name;SELECT MIN(key_part1),MAX(key_part1) FROM tbl_name;SELECT MAX(key_part2) FROM tbl_name WHERE key_part1=constant;SELECT ... FROM tbl_name ORDER BY key_part1,key_part2,... LIMIT 10;SELECT ... FROM tbl_name ORDER BY key_part1 DESC, key_part2 DESC, ... LIMIT 10; MySQL使用索引数解析一下查询，假设索引列是数字： 123456SELECT key_part1,key_part2 FROM tbl_name WHERE key_part1=val;SELECT COUNT(*) FROM tbl_name WHERE key_part1=val1 AND key_part2=val2;SELECT key_part2 FROM tbl_name GROUP BY key_part1; 以下查询使用索引来按排序顺序检索行，而不使用单独的排序传递： 12345SELECT ... FROM tbl_name ORDER BY key_part1,key_part2,... ;SELECT ... FROM tbl_name ORDER BY key_part1 DESC, key_part2 DESC, ... ; 范围优化Range Optimization range访问方法使用单个索引来检索包含在一个或多个索引值间隔内的表行的子集。他可用于单部分(single-part)或多部分(multiple-part)索引。 单部分索引的范围访问方法Range Access Method for Single-Part Indexes 对于单部分索引，索引值间隔可以方便地由WHERE子句中相应条件表示，表示为范围条件而不是间隔。 单部分索引的范围索引条件的定义如下： 对于BTREE和HASH索引，使用=, &lt;=&gt;, IN(), IS NULL, IS NOT NULL运算符时，关键部分与常量值的比较是范围条件 另外，对于BTREE索引，关键部分与常量值的比较是使用&gt;, &lt;, &gt;=, &lt;= between, !=, &lt;&gt;运算符时的范围条件，或者LIKE比较时的LIKE比较是一个不以通配符开头的常量字符串 对于所有索引类型，多个范围条件与OR或AND组合形成范围条件 常量值表示一下之一： 来自查询字符串中的常量 来自同一连接(join)的const或system表的列 不相关子查询的结果 由前面类型的子表达式组成的任何表达式 WHERE子句中带有范围条件的查询的栗子： 1234567891011SELECT * FROM t1 WHERE key_col &gt; 1 AND key_col &lt; 10;SELECT * FROM t1 WHERE key_col = 1 OR key_col IN (15,18,20);SELECT * FROM t1 WHERE key_col LIKE 'ab%' OR key_col BETWEEN 'bar' AND 'foo'; MySQL尝试从每个可能索引的WHERE子句中提取范围条件。在提取过程期间，丢弃不能用于构建范围条件的条件，组合产生重叠范围的条件，并且去除产生空范围的条件。 通常，用于范围扫描的条件比WHERE子句的限制性更小。MySQL执行额外的检查以过滤掉满足范围条件但不满足完整WHERE子句的行。MySQL不支持合并空间索引的范围方法的多个范围。要解决此限制，可以使用具有相同SELECT语句的UNION，但将每个空间谓词放在不同的SELECT中。 多部分索引的范围访问方法Range Access Method for Multiple-Part Indexes 多部分索引的范围条件是单部分索引范围条件的扩展。多部分索引上的范围条件将索引行限制在一个或多个关键元组上定义关键元组间隔。 例如，考虑定义为key1(key_part1, key_part2, key_part3)的多部分索引： 12345678key_part1 key_part2 key_part3 NULL 1 &apos;abc&apos; NULL 1 &apos;xyz&apos; NULL 2 &apos;foo&apos; 1 1 &apos;abc&apos; 1 1 &apos;xyz&apos; 1 2 &apos;abc&apos; 2 1 &apos;aaa&apos; 条件key_part1 = 1定义此间隔：(1,-inf,-inf) &lt;= (key_part1,key_part2,key_part3) &lt; (1,+inf,+inf)此间隔覆盖前面数据集中的第4、第5、第6个元组，并且可以由范围访问方法使用。相反，条件key_part3 = &#39;abc&#39;不定义单个间隔，并且不能由方位访问方法使用。 以下描述详细地说明了范围条件如何适用于多部分索引： 对于HASH索引，可使用包含相同值的每个间隔。 1234567891011--const1, const2, ...都是常量---cmp指的是=, &lt;=&gt;, IS NULL比较运算符--条件涵盖所有索引部分 key_part1 cmp const1AND key_part2 cmp const2AND ...AND key_partN cmp constN;--栗子key_part1 = 1 AND key_part2 IS NULL AND key_part3 = 'foo' 对于BTREE索引，间隔可用于AND组合的条件，其中每个条件使用=, &lt;=&gt;, IS NULL, &gt;, &lt;, &gt;=, &lt;=, !=, &lt;&gt;, BETWEEN, LIKE &#39;pattern&#39;来比较关键部分和常量值。只要可以确定包含于条件匹配的所有行的单个key元组，就可以使用间隔。 如果覆盖区间中包含的行集的条件与OR组合，则它们形成一个条件，该条件覆盖其间隔的并集中包含的一组行。如果条件与AND组合，则它们形成一个条件，该条件覆盖其间隔交集中包含的一组行。 多值比较的等价范围优化Equality Range Optimization of Many-Valued Comparisons 行构造函数表达式的范围优化Range Optimization of Row Constructor Expressions 对范围优化限制内存使用Limiting Memory Use for Range Optimization 要控制范围优化程序可用的内存，请使用range_optimizer_max_mem_size系统变量： 0意味着不限制 大于零时，优化程序会在考虑范围访问方法时跟踪消耗的内存。如果要超过指定的限制，则放弃范围访问方法，并考虑其它方法。 对于UPDATE和DELETE语句，如果优化程序回退到完整表扫描并启用了sql_safe_updates系统变量，则会发生错误而不会警告，因为实际上没有使用任何key来确定要修改的行。 对于超出不可用范围优化内存并且优化程序回退到不太理想的计划的单个查询，增加range_optimizer_max_mem_size值可以提高性能。 优化和索引Optimization and Indexes 提高SELECT操作性能的最佳方法是在查询中测试的一个或多个列上创建索引。索引条目的作用类似于表行的指针，允许查询快速确定哪些行与WHERE字句中的条件匹配，并检索这些行的其它列值。所有MySQL数据类型都可被索引。 尽管为查询中每个可能使用的列创建索引很有诱惑力，但不必要的索引会浪费空间并浪费时间让MySQL确定要使用的索引。索引还会增加insert, update, delete的成本，因为必须更新每个索引。你必须找到适当的平衡，以使用最佳索引集实现快速查询。 MySQL如何使用索引How MySQL Uses Indexes 索引用于快速查找具有特定列值(column value)的行(row)。如果没有索引，MySQL必须从第一行开始，然后读取整个表以查找相关行。表越大，成本越高。如果表中有相关列的索引，MySQL可以快速确定要在数据文件中间寻找的位置，而无需查看所有数据。这比按顺序读取每一行要快得多。 大多数MySQL索引(PRIMARY KEY, UNIQUE, INDEX, FULLTEXT)都存储在B树(B-trees)中。有几个例外： 空间数据类型的索引使用R树(R-trees) MEMORY表同样支持hash索引 InnoDB对FULLTEXT使用反转列表(inverted lists) MySQL使用索引进行这些操作： 快速查找与WHERE子句匹配的行 出于消除行的考虑。如果在多个索引之间有选择，MySQL通常使用找到最小行数的索引 如果表具有多列索引，则优化程序可以使用索引的任何左前缀来查找行 在执行join时从其它表中检索行。如果声明它们的类型和大小相同，MySQL可以更有效地使用列上的索引。如VARCHAR(10)和CHAR(10)的大小相同。 对于非二进制字符串之间的比较，两列应使用相同的字符集。 查找特定索引列key_col的MIN()和MAX()值，这是由预处理器优化的，它检查是否在索引中key_col之前出现的所有关键部分上使用WHERE key_part_N = 常量。在这种情况下，MySQL对每个MIN()或MAX()表达式执行单个键查找，并用常量替换它。如果所有表达式都替换为常量，则查询立即返回。 12SELECT MIN(key_part2),MAX(key_part2) FROM tbl_name WHERE key_part1=10; 如果对可用索引的最左前缀进行排序或分组，则对表进行排序或分组。 在某些情况下，可以优化查询以在不咨询数据行的情况下检索值。 对于小型表的查询，或大型表所有行的查询，索引不太重要。当查询要访问大多数行时，顺序读取比通过索引更快。顺序读取可以最大限度地减少磁盘搜索，即使查询不需要所有行也是如此。 主键优化Primary Key Optimization 表的主键(primary key)表示你在最重要的查询中使用的列或列的集合。它具有关联的索引，以实现快速查询优化。查询性能受益于NOT NULL，因为它不能包含任何NULL值。使用InnoDB存储引擎，表格数据在物理化上进行组织，以根据主键或列进行超快速查找和排序。 如果你的表又大又重要，但没有明显的列或列的集合作为主键，则可创建一个单独的列，其中包含自动增量值以用作主键。当你使用外键(foreign key)联接(join)表时，这些唯一ID可用于指向其它表中相应行的指针。 外键优化Foreign Key Optimization 如果一个表有很多列，并且你查询了许多不同的列组合，那么将频率较低的数据拆分为每个都有几列的单独表可能会很有效，并通过从主表中复制数字ID列将它们与主表相关联。这样，每个小表都可以有一个主键来快速查找器数据，并且你可以使用连接操作仅查询所需的列集。根据数据的分布方式，查询可能会执行较少的I/O并占用较少的高速缓存，因为相关列在磁盘上打包在一起。为了最大限度地提高性能，查询尝试从磁盘中读取尽可能少的数据块；只有几列的表可以在每个数据块中容纳更多行。 列索引Column Indexes 最常见的索引类型涉及单个列，在数据结构中存储该列的值的副本，允许快速查找具有相应列值的行。B树(B-tree)数据结构允许索引在WHERE子句中快速查找特定值，一组值或一系列值。 索引前缀(Index Prefixes)使用字符串列的索引规范中的col_name(N)语法，可以创建使用列的前N个字符的索引。以这种方式仅索引列值的前缀，可以使索引文件更小。当索引BLOB或TEXT列，必须为索引指定前缀长度。前缀最长可达1000 Byte，InnoDB表为767Byte(除非你设置了innodb_larger_prefix) 1CREATE TABLE test (blob_col BLOB, INDEX(blob_col(10))) 全文索引(FULLTEXT Indexes)全文索引用于全文搜索。只有InnoDB和MyISAM存储引擎支持FULLTEXT索引，并且仅支持CHAR, VARCHAR, TEXT列。索引始终发生在整个列上，并且不支持前缀索引。 空间索引(Spatial Indexes)你可以在空间数据类型上创建索引。MyISAM和InnoDB支持空间类型的R树(R-trees)索引。其它存储引擎使用B树来索引空间类型。 MEMORY存储引擎中的索引MEMORY存储引擎默认使用HASH索引，但也支持B树索引。 多列索引Multiple-Column Indexes MySQL可以创建复合索引(composite indexes)——即多列上的索引，索引最多包含16列。对于某些数据类型，你可以索引列的前缀。 MySQL可以对测试索引中的所有列的查询使用多列索引，或者只测试第一列，前几列等的查询。如果在索引定义中以正确的顺序指定列，则单个复合索引可以加速同一表上的多种查询。多列索引可被视为排序数组，其行包含通过连接索引列的值创建的值。 假设某表如下： 1234567891011121314151617181920212223242526272829303132333435CREATE TABLE test ( id INT NOT NULL, last_name CHAR(30) NOT NULL, first_name CHAR(30) NOT NULL, PRIMARY KEY (id), INDEX name (last_name,first_name));/*name索引是一个包含两列的索引，它可用于查询中的查询。可组合last_name和first_name的值进行查询，还可仅指定该索引的最左前缀last_name的值进行查询*/--因此，name索引可用于以下查询SELECT * FROM test WHERE last_name='Widenius';SELECT * FROM test WHERE last_name='Widenius' AND first_name='Michael';SELECT * FROM test WHERE last_name='Widenius' AND (first_name='Michael' OR first_name='Monty');SELECT * FROM test WHERE last_name='Widenius' AND first_name &gt;='M' AND first_name &lt; 'N';--然而，name索引无法用于以下查找SELECT * FROM test WHERE first_name='Michael';SELECT * FROM test WHERE last_name='Widenius' OR first_name='Michael'; 验证索引使用Verifying Index Usage 始终检查所有查询是否确实使用你在表中创建的索引，使用EXPLAIN语句。 InnoDB和MyISAM索引统计InnoDB and MyISAM Index Statistics Collection 存储引擎收集有关表的统计信息，供优化器使用。表统计信息基于值组(value group)，其中值组是具有相同键(key)前缀值的一组行。优化器的目的，一个重要统计信息是值组大小的平均值。 MySQL使用值组大小的平均值的方式如下： 估计每个ref访问必须读取多少行 估计一个部分联接将产生多少行，即此表单的操作将产生的行数： (...) JOIN tbl_name ON tbl_name.key = expr B树和Hash索引的比较Comparison of B-Tree and Hash Indexes 了解 B树(B-Tree)和哈希(Hash)数据结构有助于预测不同查询在索引中使用这些数据结构的不同存储引擎上的执行情况，特别是MEMORY存储引擎。 B树索引B-Tree Index Characteristics B树索引可用于 =, &lt;, &gt;, &lt;=, &gt;=, BETWEEN运算符的表达式中的列比较。如果LIKE的参数是不以通配符开头的常量字符串，则它也可用于LIKE比较。 1234567891011121314151617181920212223242526272829303132# SELECT使用索引的栗子SELECT * FROM tbl_name WHERE key_col LIKE 'Patrick%';SELECT * FROM tbl_name WHERE key_col LIKE 'Pat%_ck%';# SELECT没有使用索引SELECT * FROM tbl_name WHERE key_col LIKE '%Patrick%';SELECT * FROM tbl_name WHERE key_col LIKE other_col;# WHERE使用索引... WHERE index_part1=1 AND index_part2=2 AND other_column=3 /* index = 1 OR index = 2 */... WHERE index=1 OR A=10 AND index=2 /* optimized like "index_part1='hello'" */... WHERE index_part1='hello' AND index_part3=5 /* Can use index on index1 but not on index2 or index3 */... WHERE index1=1 AND index2=2 OR index1=3 AND index3=3;# WHERE没有使用索引 /* index_part1 is not used */... WHERE index_part2=1 AND index_part3=2 /* Index is not used in both parts of the WHERE clause */... WHERE index=1 OR A=10 /* No index spans all rows */... WHERE index_part1=1 OR index_part2=10 有时MySQL不使用索引，及时有索引也是如此。发生这种情况的一种情况是，优化器估计使用索引将需要MySQL访问表中非常大比例的行。但是，如果此类查询使用LIMIT仅检索某些行，则MySQL仍会使用索引，因为它可以更快地找到要在结果中返回的几行。 哈希索引Hash Index Characteristics 哈希索引与B树索引的特征有些不同: 仅使用=,&lt;=&gt;运算符来比较(速度飞快)，不使用比较符找到一系列值。依赖于这种类型的单值查找的系统被称为键值存储。要将MySQL应用于此类应用程序，请尽可能使用哈希索引 优化器无法使用哈希索引来加速ORDER BY MySQL无法确定两个值之间大约有多少行。如果将MyISAM或InnoDB表更改为哈希索引的MEMORY表，则可能会影响某些查询 只有整个键可用于搜索行 索引扩展Use of Index Extensions InnoDB通过将主键列附加到它来自动扩展每个二级索引。考虑如下表定义: 1234567CREATE TABLE t1 ( i1 INT NOT NULL DEFAULT 0, i2 INT NOT NULL DEFAULT 0, d DATE DEFAULT NULL, PRIMARY KEY (i1, i2), INDEX k_d (d)) ENGINE = InnoDB; 此表定义了i1, i2两个主键。它还在列(d)上定义了二级索引k_d, 但内部InnoDB扩展了该索引并将其视为列(d, i1, i2)。 在确定如何以及是否使用该索引时，优化程序会考虑扩展二级索引的主键列。这可以带来更高效的查询执行计划和更好的性能。 优化器使用生成的列索引Optimizer Use of Generated Column Indexes MySQL支持生成列的索引: 1CREATE TABLE t1 (f1 INT, gc INT AS (f1 + 1) STORED, INDEX (gc)); 生成的列gc定义为表达式f1 + 1.该列也被索引，优化器可以在执行计划构建期间考虑该索引。 优化数据库结构Optimizing Database Structure 作为数据库设计者的角色中，寻找组织 schemas, tables, columns最有效的方法。在调整应用程序代码时，您可以最小化I/O，将相关项目保持在一起，并提前计划，以便在数据量增加时性能保持较高。从高效的数据库设计开始，团队成员可以更轻松地编写高性能的应用程序代码，并使数据库可以随着应用程序的发展和重写而持久。 优化数据大小Optimizing Data Size 设计表以最小化磁盘空间。这可以通过 减少磁盘写入和读取的数据量 来实现巨大的改进。当在查询执行期间被主动处理时，较小的表通常需要较少的内存。表数据的任何空间缩减也会导致较小的索引可以更快地处理。 MySQL支持许多不同的存储引擎(表类型)和行格式。对于每个表，你可以决定使用哪种存储和索引方法。为你的应用程序选择合适的表格式可以为你带来巨大的性能提升。 通过使用此处列出的技术，你可以获得更好的表性能并最大限度地减少存储空间: Table Columns Row Format Indexes Joins Normalization 列 尽可能使用最有效(最小)的数据类型。MySQL有许多专门的类型可以节省磁盘空间和内存。例如，如有可能，请使用较小的整数类型(integer types)来获取较小的表。MEDIUMINT 通常是比 INT 更好的选择，因为 MEDIUMINT 列使用的空间减少了 25%。 如果可能，将列声明为NOT NULL。它通过更好地使用索引并消除测试每个值是否为 NULL 的开销，使SQL操作更快。你同样节省了一些存储空间，每列1bit。如果你确实需要表中的 NULL 值，请使用它们。只需避免在每列中允许 NULL 值得默认设置。 行格式 默认情况下，使用 DYNAMIC 行格式创建 InnoDB 表。要使用 DYNAMIC 以外的行格式，请配置 innodb_default_row_format， 或在 CREATE TABLE 或 ALTER TABLE 语句中显示指定 ROW_FORMAT 选项。 要通过以压缩格式存储表数据来进一步减少空间，请在创建 InnoDB 表时指定 ROW_FORMAT=COMPRESSED，或在现有 MyISAM 表上运行 myisampack 命令。 对于 MyISAM 表，如果没有任何可变长度列(VARCHAR, TEXT, BLOB列)，则使用固定大小的行格式。这更快，等可能浪费一些空间。 索引 表的主索引应该尽可能短。这使得每行的识别变得简单有效。对于 InnoDB 表，主键列在每个辅助索引条目中都是重复的，因此如果你有许多辅助索引，则短主键可以节省大量空间。 仅创建你需要提高查询性能的索引。索引适用于检索，但会降低插入和更新操作的速度。如果你主要通过搜索列的组合来访问表，请在它们上创建单个复合索引，而不是为每列创建单独的索引。索引的第一部分应该是最常用的列。如果从表中选择时总是使用多列，则索引中的第一列应该是具有最多重复的列，以获得更好地索引压缩。 如果长字符串列很可能在第一个字符数上有唯一的前缀，那么最好只索引此前缀，使用MySQL支持在列的最左边部分创建索引。较短的索引更快，不仅因为它们需要更少的磁盘空间，而且因为它们还会在索引缓存中为你提供更多命中，从而减少磁盘搜索次数。 联结 在某些情况下，分成两个经常扫描的表可能是有益的。如果它是动态格式的表，则尤其如此，并且可以使用较小的静态格式表，该表可用于在扫描表时查找相关行 在具有相同数据类型的不同表中声明具有相同信息的列，以基于相应列加速连接。 保持列名简单，以便你可以在不同的表中使用相同的名称并简化联结查询。例如，在名为 customer 的表中，使用名称 name 而不是 customer_name。要使你的名称可以知道其它SQL服务器，请考虑将它们保持为小于18个字符。 规范化 通常，尽量保持所有数据不冗余重复(这不是指的高可用的冗余，而是不要重复存储数据)。为了取代重复的名称、地址和长值，为它们分配唯一的ID，在多个较小的表中根据需要重复这些ID，并通过 join 子句中的 ID 来联接查询中的表。 如果速度比磁盘空间更重要，并且保留多个数据副本的维护成本，你可以放宽规范化规则，复制信息或创建汇总表以获得更快的速度。 优化数据类型Optimizing MySQL Data Types 优化数字数据Optimizing for Numeric Data 对于唯一ID或可以表示为字符串或数字的其它值，首选数字列(prefer numeric columns to string columns)。由于较大的数值可以存储在比相应于字符串更少的字节中，因此传输和比较的速度更快，占用的内存更小。 如果你使用数字数据，在许多情况下从数据库访问信息比访问文本文件更快。数据库中的信息可能以比文本文件更紧凑的格式存储，因此访问它涉及更少的磁盘访问。您还可以在应用程序中保存代码，因为您可以避免解析文本文件以查找行和列边界。 优化字符和字符串类型Optimizing for Character and String Types 对于 character and string columns，请遵循一下准则: 当您不需要特定于语言的整理(collation)规则功能时，请使用二进制排序顺序进行快速比较和排序操作。你可以使用 BINARY 运算符在特定查询中使用二进制整理规则。 比较不同列的值时，请尽可能声明具有相同字符集和整理规则的列，以避免在运行查询时进行字符串转换。 对于小于8KB的列值，请使用二进制 VARCHAR 而不是 BLOB。GROUP BY 和 ORDER BY 子句可以生成临时表，如果原始表不包含任何 BLOB 列，这些临时表可以使用 MEMORY 存储引擎。 如果表中包含的字符串列(如名字和地址)，但许多查询不检索这些列，请考虑将字符串拆分为单独的表，并在必要时使用带有外键的连接查询。当MySQL从一行中检索任何值时，它会都包含改行的所有列的数据块。仅使用最常用的列保持每行较小，允许更多行适合每个数据块。这种紧凑的表减少了常见查询的磁盘I/O和内存使用。 当你使用随机生成的值作为 InnoDB 表中的主键时，请在其前面加上一个升序(asce)值，如当前的日期和时间。当连续的主值物理存储在彼此附近是，InnoDB可以更快地插入和检索它们。 优化BLOB类型Optimizing for BLOB Types 存储包含文本数据的大型 BLOB 时，请考虑先压缩它。当压缩整个表时，请勿使用此技术。 对于具有多个列的表，要减少不使用的 BLOB 列的查询的内存要求，请考虑将 BLOB 列拆分为单独的表，并在需要时使用连接查询它。 由于检索和显示 BLOB 值得性能要求可能与其它数据类型有很大不同，因此你可以将 特定的BLOB表放在不同的存储设备上，甚至是单独的数据库实例上。 可以讲列值的哈希值存储在单独的列中，索引该列，并在查询中测试哈希值，而不是针对非常长的文本字符串测试相等性。 优化表Optimizing for Many Tables 用于快速保持个别查询的一些技术设计在多个表之间拆分数据。当表的数量达到上万，甚至是上百万时，处理所有这些表的开销成为新的性能考虑问题。 如何打开和关闭表How MySQL Opens and Closes Tables 当你执行mysqladmin status命令时，你应该看到如下内容: 123Uptime: 426 Running threads: 1 Questions: 11082Reloads: 1 Open tables: 12# 如果你的表少于12个，则这个值会有些令人费解 MySQL是多线程，因此可能有许多C端同时为给定的表发出查询。为了最大限度地减少同一个表上具有不同状态的多个C端回话的问题，该表由每个并发回话独立打开。对于MyISAM表，每个打开表的C端数据文件都需要一个额外的文件描述符。 table_open_cache和max_connections系统变量会影响Server保持打开的最大文件数。如果增加这些值中的一个或两个，则可能会遇到操作系统对每个进程的打开文件描述符数量施加的限制。许多操作系统允许你增加打开文件限制，该方法因系统而异。table_open_cache与max_connections有关。例如，对于200个并发运行的连接，请指定表缓存大小至少为200 * N，其中N是执行的任何查询中每个连接的最大表数。你还必须为临时表和文件保留一些额外的文件描述符。请确保操作系统可以处理table_open_cache设置隐含的打开文件描述符的数量。如果table_open_cache设置的太高，MySQL可能会用完文件描述符(file descriptors)并出现拒绝连接或无法执行查询等症状。 还有考虑到MyISAM存储引擎需要为每个唯一打开的表提供两个文件描述符。对于分区的MyISAM表，打开的表的每个分区都需要两个文件描述符。 （当MyISAM打开分区表时，它会打开此表的每个分区，无论是否实际使用给定分区。要增加MySQL可用的文件描述符，请设置open_files_limit系统变量。 打开表的缓存保持在table_open_cache条目的级别上，Server在启动时自动调整缓存大小。要显式设置大小，请在启动时设置table_open_cache系统变量。MySQL可能临时打开许多表来执行查询。 在以下情况，MySQL会关闭一个未使用的表并将其从表缓存中删除: 当缓存已满并且线程尝试打开不在缓存中的表时 当缓存包含多个table_open_cache条目并且任何线程都不再使用缓存中的表时 当table-flushing操作发生。这有可能在FLUSH TABLES语句、执行mysqladmin flush-tables或mysqladmin refresh命令 当表缓存填满时，Server使用以下过程来定位要使用的缓存条目: 从最近最少使用的表开始，发布当前未使用的表 如果必须打开新表，但缓存已满且无法释放表，则会根据需要临时扩展缓存。当缓存处于临时扩展状态并且表从已使用状态变为未使用状态时，表将关闭并从缓存中释放。 为每个并发访问打开MyISAM表。这意味着如果两个线程访问同一个表，或一个线程在同一个查询中两次访问该表，则需要打开两次表。每个并发打开都需要表缓存中的条目。在任何MyISAM表的第一次打开都需要两个文件描述符: 一个用于数据文件，一个用于索引文件。对表的每次额外使用仅为数据文件提供一个文件描述符。索引文件描述符在所有线程之间共享。 如果要使用HANDER tbl_name OPEN语句打开表，则会为该线程分配专用的表对象。此表对象不由其它线程共享，并且在线程调用HANDLER tbl_name CLOSE或线程终止之前不会关闭。发生这种情况时，表将被放回表缓存中（如果缓存未满）。 要确定表缓存是否太小，请检查Opened_tables状态变量，该变量指示自Server启动以来的表的打开操作数: 123456SHOW GLOBAL STATUS LIKE 'Opened_tables';+---------------+-------+| Variable_name | Value |+---------------+-------+| Opened_tables | 2741 |+---------------+-------+ 如果值非常大或快速增加，及时你没有发出许多FLUSH TABLES语句，也请在Server启动时增加table_open_cache的值。 在同一数据库中创建多个表的缺点Disadvantages of Creating Many Tables in the Same Database 如果在同一个数据库目录中有许多MyISAM表，则打开(open)、关闭(close)和创建(create)操作很慢。如果在许多不同的表上执行SELECT语句，则表缓存已满时会有一些开销，因为对于每个必须打开的表，必须关闭另一个表。您可以通过增加表缓存中允许的条目数来减少此开销。 内部临时表Internal Temporary Table Use in MySQL 在某些情况下，Server在处理语句时创建内部临时表。用户无法直接控制何时发生这种情况。 Server在以下条件下创建临时表: 评估UNION语句，稍后描述一些异常 评估某些视图(view) 评估派生的表 为实现子查询或半连接创建的表 评估包含ORDER BY和GROUP BY子句的语句，或它们包含连接队列中第一个表以外的表中的列的语句 评估DISTINCT结合ORDER BY可能需要临时表 对于使用SQL_SMALL_RESULT修饰符的查询，MySQL使用内存临时表，除非查询还包含需要磁盘存储的元素 为了评估从同一个表中选择和插入的INSERT ... SELECT语句，MySQL创建一个临时表来保存SELECT中的行，然后将这些行插入到目标表中 评估多表UPDATE语句 评估GROUP_CONCAT()或COUNT (DISTNCT)表达式 要确定语句是否需要临时表，请使用EXPLAIN并检查Extra列以查看是否显示Using temporary。当Server创建内部临时表(无论是内存还是磁盘上)时，它会增加Created_tmp_tables状态变量。 某些查询条件会阻止使用内存中的临时表，在这种情况下，Server会使用磁盘上的表: 表中存在BLOB或TEXT列，这包括具有字符串值的用户定义的变量，因此它们被视为BLOB或TEXT列，具体取决于它们的值分别是二进制字符串还是非二进制 如果使用UNION或UNION ALL，则SELECT列表中存在最大长度大于512的字符串列 SHOW COLUMNS和DESCRIBE语句使用BLOB作为某些列的类型，因此用于结果的临时表是磁盘上的表 Server不对具有某些限定条件的UNION语句使用临时表。相反，它仅从临时表创建中执行结果列类型转换所必须的数据结构。该表未完全实例化，并且没有写入和读取行，行直接发送到C端。结果是减少了内存和磁盘要求，并且在第一行发送到客户端之前的延迟较小，因为Server不需要等到最后一个查询块执行。EXPLAIN和优化程序输出反映了此执行策略：UNION RESULT查询不存在，因此该块对应于从临时表中读取的部分。 这些条件使UNION无需临时表即可进行评估: The union is UNION ALL, not UNION or UNION DISTINCT 没有全局ORDER BY子句 The union is not the top-level query block of an {INSERT | REPLACE} … SELECT … statement 内部临时表存储引擎Internal Temporary Table Storage Engine 内部临时表可以保存在内存中(由MEMORY存储引擎处理)，或由InnoDB或MyISAM存储引擎存储在磁盘上。 如果将内部临时表创建在内存中，但变得很大，MySQL会自动将其转换为磁盘表。内存临时表的最大大小由tmp_table_size或max_heap_table_size的值定义，以较小者为准。这与使用CREATE TABLE显式创建的MEMORY表不同。对于此类表，只有max_heap_table_size变量确定表可以增长的大小，并且没有转换为磁盘格式。internal_tmp_disk_storage_engine变量定义Server用于管理磁盘内部临时表的存储引擎。允许的值是：INNODB(默认)和MyISAM。 内部临时表存储格式Internal Temporary Table Storage Format 内存临时表由MEMORY存储引擎管理，该引擎使用固定长度的行格式。VARCHAR和VARBINARY列值填充到最大列长度，实际上将它们存储为CHAR和BINARY列。 磁盘临时表由InnoDB或MyISAM存储引擎管理。两个存储引擎都使用动态宽度行格式存储临时表。与使用固定长度行的磁盘相比，列只占用所需的存储空间，从而减少磁盘I/O，空间要求和处理时间。 对于最初在内存中创建内部临时表的语句，然后将其转换为磁盘表，可以通过跳过转换步骤并在磁盘上创建表开始来实现更好的性能。big_tables变量可用于强制内部临时表的磁盘存储。 优化InnoDB表Optimizing for InnoDB Tables InnoDB是MySQL客户通常在生产环境中使用的存储引擎，其中可靠性和并发性非常重要。它是默认的MySQL存储引擎。本节介绍如何优化InnoDB表的数据库操作。 优化InnoDB表的存储布局Optimizing Storage Layout for InnoDB Tables 一旦数据达到稳定大小，或者增长的表增加到上百兆字节(MB)，请考虑使用OPTIMIZE TABLE语句重新组织并压缩任何浪费的空间。重组的表需要较少的磁盘I/O来执行全表扫描(full table scan)。这是一个简单的技术，可在其它技术不切实际时提高性能。OPTIMIZE TABLE复制表的数据部分并重建检索。其好处改进了索引中数据的打包，减少了表空间和磁盘上的碎片。好处取决于每个表中的数据。如果表很大或者正在重建的索引不适合缓冲池，则此操作可能很慢。向表中添加大量数据后的第一次运行通常比以后的运行慢得多。 在InnoDB中，具有long PRIMARY KEY(具有冗长值的单个列或形成长度复合值的多个列)浪费了大量磁盘空间。在指向同一行的所有辅助索引(secondary index)记录中，行的主键值重复。如果主键很长，则创建AUTO_INCREMENT列作为主键，或者索引long VARCHAR列的前缀而不是整个列。 使用VARCHAR数据类型而不是CHAR来存储可变长度(variable-length)字符串或具有许多NULL值的列。即使字符串较短或其值为NULL，CHAR(N)的列也始终使用N个字符(character)来存储数据。较小的表更适合缓冲池并减少磁盘I/O。当使用COMPACT行格式(默认的InnoDB格式)和可变长度字符串(如utf8)时，CHAR(N)列占用可变的空间量，但仍至少占用N个字节。 对于大型表或包含大量重复文本(repetitive text)或数字(nemeric)数据的表，情考虑使用COMPRESSED行格式。将数据放入缓冲池(buffer pool)或执行全表扫描需要较少的磁盘I/O。在作出永久性决策之前，请使用COMPRESSED与COMPACT行格式测量可以实现的压缩量。 优化InnoDB事务管理Optimizing InnoDB Transaction Management 要优化InnoDB事务处理，请在事务功能的性能开销(performance overhead)和Server的工作负载(workload)之间找到理想的平衡点。例如，如果应用程序每秒提交数千次，则可能会遇到性能问题， 默认的MySQL设置AUTOCOMMIT=1可以对繁忙的数据库Server施加性能限制。在可行的情况下，通过发出SET AUTOCOMMIT=0或START TRANSACTION语句，然后在进行所有更改后发出COMMIT语句，将多个相关数据更改操作包装到单个事务中。如果该事务对数据库进行了修改，InnoDB必须在每次事务提交时将日志刷新到磁盘。当每次更改后都提交时，存储设备的I/O吞吐量会限制每秒潜操作的数量。 对于仅包含单个SELECT语句的事务，启用AUTOCOMMIT可帮助InnoDB识别只读事务并对其进行优化。 INSERT, DELETE, UPDATE大量行后，避免执行行回滚。如果大型事务正在降低Server性能，则将其回滚可能会使问题变得更糟，可能需要花费几倍的时间来执行原始数据更改操作。杀死数据库进程没有帮助，因为Server启动时会再次启动回滚。为了尽量减少此问题发生的可能性： 增加缓冲池的大小，以便可以缓存所有数据更改，而不是立即写入磁盘 设置innodb_change_buffering=all，以便缓冲除INSERT之外的UPDATE, DELETE操作 考虑在大数据更改操作期间定期发出COMMIT语句，可能会破坏单个删除或更新为较少行数进行操作的多个语句要在发生失控回滚后摆脱它，请增加缓冲池使回滚变为CPU限制并快速运行，或杀死Server并使用innodb_force_recovery=3选项来启动它。预计此问题很少发生，默认设置innodb_change_buffering=all，他允许将UPDATE和DELETE操作缓存在内存中，从而使它们可在第一时间更快地执行，并且如果需要还可以更快地回滚。确保在处理具有许多INSERT, UPDATE, DELETE操作的长时间运行事务的Server上使用此参数设置。 如果发生奔溃时，如果你可以承受丢失一些最新提交的事务，则可以设置 innodb_flush_log_at_trx_commit=0。InnoDB无论如何都会尝试每秒刷新(FLUSH)一次日志，尽管无法保证。此外，设置innodb_support_xa=0将减少磁盘数据和BINLOG同步而导致到磁盘刷新次数。 修改或删除行时，不会立即删除行和关系链的undo log，甚至在事务提交后。旧数据将保留，直到先前或同时启动的事务完成，以便这些事务可以访问已修改或已删除的行的先前状态。因此，长时间运行的事务可以阻止InnoDB清除由不同事务更改的数据。 在长时间运行的事务中修改或删除行时，使用READ COMMITTED和REPEATABLE READ隔离级别的其它事务必须执行更多工作，以便在读取相同行时重建旧数据。 当长时间运行的事务修改表时，从其它事务对该表的查询不会使用covering index technique。通常可从二级索引检索所有结果列的查询，而不是从表数据中查找适当的值。如果发现二级索引页面的PAGE_MAX_TRX_ID太新，或二级索引中的记录被删除标记，则InnoDB可能需要使用clustered index来查找记录。 优化InnoDB只读事务Optimizing InnoDB Read-Only Transactions InnoDB可以避免与已知为只读的事务设置事务ID(TRX_ID字段)相关的开销。只有可能执行写操作或锁定读取的事务(如SELECT…FOR UPDATE)才需要事务ID。消除不必要的事务ID会减少每次查询或数据更改语句构造读取视图时所咨询的内部数据结构的大小。 语言结构Language Structure 本章讨论在使用MySQL时编写SQL语句的以下元素的规则： 文字值，如字符串和数字 标识符，如数据库、表和列名 关键词与保留词 用户定义变量和系统变量 评论 文字值Literal Values 本节描述如何在MySQL中写入文字值。这包含了字符串、数字、十六进制、位值、布尔值、NULL。还将介绍在MySQL中处理这些基本类型时可能遇到的各种细微差别。 字符串String Literals 字符串时字节(Byte)或字符(character)序列，包含在单引号(&#39;)或双引号(&quot;)中。 栗子： 123&apos;a string&apos;&apos;a&apos; &apos; &apos; &apos;string&apos;&quot;another string&quot; 注意如果启用了ANSI_QUOTES SQL模式，字符串只能在单引号中引用，因为双引号的字符串被解释为标识符。 二进制字符串(binary string)是一串字节(Bytes)。每个二进制字符串都有一个名为binary的字符集(character set)和排序规则。非二进制字符串是一串字符(characters)，它具有二进制以外的字符集和与字符集兼容的排序规则。 对于两种类型的字符串，比较是基于字符串单元的数值。对于二进制字符串，单位是字节(byte)，使用数字字节值比较；对于非二进制字符串，单位是字符(character)和支持多字节字符的字符集，使用数字字符码值比较。字符码排序是字符串排序的函数。 字符串文字可以有一个可选的字符集导入器和排序字句，将其指定为使用特定字符集和排序的字符串：[_charset_name]&#39;string&#39; [COLLATE collation_name]栗子: 12345678SELECT _latin1'string';SELECT _binary'string';SELECT _utf8'string' COLLATE utf8_danish_ci;SELECT N'some text';SELECT n'some text';SELECT _utf8'some text'; 在字符串中，某些序列具有特俗含义，除非启用了No_BACKSLASH_ESCAPES SQL模式。如转义字符每个序列都以反斜线(backslash)(\)开始。 特殊字符转义序列： Escape Sequence Character Represented by Sequence \0 An ASCII NUL (X’00’) character \&#39; A single quote (‘) character \&quot; A double quote (“) character \b A backspace character \n A newline (linefeed) character \r A carriage return character \t A tab character \Z ASCII 26 (Control+Z); see note following the table \\ A backslash () character \% A % character; see note following the table \_ A _ character; see note following the table 在字符串中包含引号字符有几种方法： 两个引号 引号包含引号 转义引号 栗子： 12345678910111213141516171819202122SELECT 'hello', '"hello"', '""hello""', 'hel''lo', '\'hello';+-------+---------+-----------+--------+--------+| hello | "hello" | ""hello"" | hel'lo | 'hello |+-------+---------+-----------+--------+--------+SELECT "hello", "'hello'", "''hello''", "hel""lo", "\"hello";+-------+---------+-----------+--------+--------+| hello | 'hello' | ''hello'' | hel"lo | "hello |+-------+---------+-----------+--------+--------+SELECT 'This\nIs\nFour\nLines';+--------------------+| ThisIsFourLines |+--------------------+SELECT 'disappearing\ backslash';+------------------------+| disappearing backslash |+------------------------+ 要将二进制数据插入字符串列中，应该使用转义序列表示某些字符。在某些特定的Client环境下，可能还需要转换NUL或Ctrl + Z。在编写应用程序时，必须将包含特殊字符正确的转义发送给MySQL。 数字Numeric Literals 数字包括精确值(整数和小数)和近似值(浮点数)。 整数用数字序列表示。数字可能包括., -, +，科学表示法E等。 12345#精确值，定点数2.34#近似值，浮点数2.34E0 日期和时间Date and Time Literals 日期和时间可以用几种格式表示。如&#39;2015-07-21&#39;, &#39;20150721&#39;, 20150721都可解释为日期。 标准SQL和ODBC日期和时间：标准SQL允许使用type关键字和字符串指定时态文字。 1234--空格可选DATE 'str'TIME 'str'TIMESTAMP 'str' ODBC语法： 123&#123; d &apos;str&apos; &#125;&#123; t &apos;str&apos; &#125;&#123; ts &apos;str&apos; &#125; MySQL使用type关键字，这些结构分别包含DATE, TIME, DATETIME值，如果指定的话，好包括后面的小数秒部分。TIMESTAMP语法在MySQL中生成一个DATETIME值，因为DATETIME的范围与标准SQL TIMESTAMP类型更接近，后者年限为0001-9999。而MySQL的TIMESTAMP范围是1970-2038年。 日期和时间上下文中的字符串和数字： MySQL可以识别以下格式的DATE值： &#39;YYYY-MM-DD&#39;或&#39;YY-MM-DD&#39;字符串格式。允许宽松的语法——即任何标点字符都可作为日期之间的分隔符。如&#39;2012-12-31&#39;, &#39;2012/12/31/&#39;, &#39;2012@12@31&#39;... &#39;YYYYMMDD&#39;或&#39;YYMMDD&#39;没有分隔符的字符串格式，前提是该字符作为日期有意义。如&#39;20121231&#39;, &#39;121231&#39;... YYYYMMDD或YYMMDD数字格式，前置是该数字作为日期有意义。如20121231, 121231... MySQL可以识别以下格式的DATETIME和TIMESTAMP： &#39;YYYY-MM-DD HH:MM:SS&#39;或&#39;YY-MM-DD HH:MM:SS&#39;字符串格式。允许宽松的语法。如2012/12/31 00*01*02...日期和时间部分可以用T分隔，而不是空格。如2012-12-31 00:01:02, 2012-12-31T01:02:03 &#39;YYYYMMDDHHMMSS&#39;或&#39;YYMMDDHHMMSS&#39;没有分隔符的字符串格式，前提是该字符作为日期有意义 YYYYMMDDHHMMSS或YYMMDDHHMMSS数字格式，前提是该数字作为日期有意义 DATETIME和TIMESTAMP值可以包含一个精度不超多微秒(6位)的小数部分。小数部分应该始终使用小数点.与其他部分跟开，无法识别分数秒分隔符。 MySQL使用以下规则解释两位数的年值： 70-99转换为1970-1999 00-69转换为2000-2069 MySQL可以识别以下格式的TIME值： &#39;D HH:MM:SS&#39;字符串格式，D表示天数(0-34)。可以使用放松的语法。 &#39;HHMMSS&#39;没有分隔符字符串格式，前提是作为时间有意义。 HHMMSS数字格式，前提是作为时间有意义。 小数秒部分在&#39;D HH:MM:SS.fraction&#39;时间格式中识别，其中小数是精度最高可达微秒(6位)的小数部分，小数部分使用小数点.与其它部分分隔开，无法识别其它小数秒分隔符。 十六进制Hexadecimal Literals 字符集和编码Character Sets, Collations, Unicode 数据类型Data Type MySQL支持多种类型的SQL数据类型： numeric date/time string character byte JSON 数据类型描述使用如下约定： M表示整数类型的最大显示宽度 D适用于浮点和定点类型，并指示小数点后面的位数 fsp适用于TIME, DATATIME, TIMESTAMP类型，表示小数点的秒精度 方括号[]表示类型定义的可选部分 数字Numberic type 如果为数字列指定ZEROFILL，MySQL会自动将UNSIGNED属性添加到列中。 数字数据类型允许UNSIGNED(无符号)属性，也允许SIGNED(符号)。默认情况下，这些数据类型是SIGNED，因此SINGED属性不起作用。 BITA bit-value type.(1-64) TINYINTA very small integer.有符号范围: -128 to 127, 无符号范围: 0-255 BOOL SMALLINTA small integer.有符号范围: -32768 to 32767, 无符号范围: 0-65535 MEDIUMINTA medium-sized integer.有符号范围: -8388608 to 8388607, 无符号范围: 0-16777215 INTA normal-size integer.有符号范围: -2147483648 to 2147483647, 无符号范围: 0- 4294967295 INTERGER此类型是INT的同义词。 BIGINTA large integer.符号范围: -9223372036854775808 to 9223372036854775807, 无符号范围: 0 to 18446744073709551615SERIAL是BIGINT UNSIGNED NOT NULL AUTO_INCREMENT UNIQUE的别名。 DECIMAL/DEC FLOATA small(单精度) floating-point number.允许的值为: -3.402823466E+38 to -1.175494351E-38, 0, and 1.175494351E-38 to 3.402823466E+38 DOUBLEA normal-size(双精度) floating-point number.允许值为: -1.7976931348623157E+308 to -2.2250738585072014E-308, 0, and 2.2250738585072014E-308 to 1.7976931348623157E+308 FLOATA floating-point number. 日期和时间Date and Time Type MySQL允许的TIME, DATETIME, TIMESTAMP值的小数，精度高达微秒(小数点后6位)。 DATEA date.支持范围: 1000-01-01到9999-12-31。MySQL以YYYY-MM-DD格式显示DATE值，但允许使用字符串或数字将值分配给DATE列。 DATETIMEA date and time combination.支持范围: 1001-01-01 00:00:00.000000到9999-12-31 23:59:59.999999。MySQL以YYYY-MM-DD HH:MM:SS.[fraction]的格式显示DATETIME值，同样允许字符串或数字将值分配给DATETIME列。 TIMESTAMPA timestamp.支持范围: 1970-01-01 00:00:01.000000UTC到2038-01-19 03:14:07.999999UTCTIMESTAMP值存储为自纪元1970-01-01 00:00:01.000000 UTC以来的秒数，这也叫原子时间。 TIMEA time.支持范围: -838:59:59.000000 to 838:59:59.000000MySQL以HH:MM:SS[.fraction]的格式显示TIME值，但允许使用字符串或数字将值分配给TIME列。 YEARA year in four-digit format.MySQL以YYYY格式显示YEAR值，但允许使用字符串或数字将值分配给YEAR列。 字符串String Type 在某些情况下，MySQL可能会使用CREATE TABLE或ALTER TABLE语句更改字符串的类型。 CHARACTER SET/CHARSET指定字符集 12345CREATE TABLE t( c1 VARCHAR(20) CHARACTER SET utf8, c2 TEXT CHARACTER SET latin1 COLLATE latin1_general_cs); CHAR一个固定长度的字符串，在存储时使用用空格填充指定长度。VARCHAR的有效最大长度取决于最大行大小(65535字节)和使用的字符集。 VARCHAR一个可变长度的字符串。 BINARYBINARY类似于CHAR，但存储二进制字节字符串而不是非二进制字符串。 VARBINARY TINYBLOBA BLOB column with a maximum length of 255 (2^8 − 1) bytes. TINYTEXTA TEXT column with a maximum length of 255 (2^8 − 1) characters. BLOBA BLOB column with a maximum length of 65,535 (2^16 − 1) bytes. TEXTA TEXT column with a maximum length of 65,535 (2^16 − 1) characters. MEDIUMBLOBA BLOB column with a maximum length of 16,777,215 (2^24 − 1) bytes. MEDIUMTEXTA TEXT column with a maximum length of 16,777,215 (2^24 − 1) characters. LONGBLOBA BLOB column with a maximum length of 4,294,967,295 or 4GB (2^32 − 1) bytes. LONGTEXTA TEXT column with a maximum length of 4,294,967,295 or 4GB (2^32 − 1) characters. ENUMAn enumeration. SETA set.]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018小计划]]></title>
    <url>%2F2018%2F01%2F15%2F2018%E5%B0%8F%E8%AE%A1%E5%88%92%2F</url>
    <content type="text"><![CDATA[工作 《MongoDB官方文档》： https://docs.mongodb.com 《SatlStack官方文档》： https://docs.saltstack.com 《MySQL官方文档》： https://dev.mysql.com/doc/ 《TCP/IP协议族》： https://book.douban.com/subject/5386194/ 《Linux性能调优指南》： https://lihz1990.gitbooks.io/transoflptg/content/ 《Docker官方文档》： https://docs.docker.com/ 《Consul官方文档》： https://www.consul.io/docs/index.html 《Python工作自动化》： https://book.douban.com/subject/26836700/ 《Elastic Stack》: https://www.elastic.co/guide/index.html 《Kubernetes官方文档》: https://kubernetes.io/cn/docs/ 《Python3文档/标准库》: https://docs.python.org/ 《Fluentd官方文档》： https://docs.fluentd.org 个人 《资本论》： https://book.douban.com/subject/1150503/ 《灵飞经小楷》： https://book.douban.com/subject/1115916/ 《经济学原理》： https://book.douban.com/subject/26435630/ 《行测/申论》 生活 沉得住气 培养一门兴趣爱好 找寻另一半]]></content>
      <categories>
        <category>Zhang</category>
      </categories>
      <tags>
        <tag>2018</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[海明威的《老人与海》]]></title>
    <url>%2F2018%2F01%2F13%2F%E8%80%81%E4%BA%BA%E4%B8%8E%E6%B5%B7%2F</url>
    <content type="text"><![CDATA[我不相信人会有所谓的“命运”，但是我相信对于任何人来说，“限度”总是存在的。再聪明再强悍的人，能够做到的事情也总是有限度的。老人桑地亚哥不是无能之辈，然而，尽管他是最好的渔夫，也不能让那些鱼来上他的钩。他遇到他的限度了，就象最好的农民遇上了大旱，最好的猎手久久碰不到猎物一般。每一个人都会遇到这样的限度，仿佛是命运在向你发出停止前行的命令。 可是老人没有沮丧，没有倦怠，他继续出海，向限度挑战。他终于钓到了一条鱼。如同那老人是人中的英雄一样，这条鱼也是鱼中的英雄。鱼把他拖到海上去，把他拖到远离陆地的地方，在海上与老人决战。在这场鱼与人的恶战中，鱼也有获胜的机会。鱼在水下坚持了几天几夜，使老人不能休息，穷于应付，它用酷刑来折磨老人，把他弄得血肉模糊。这时，只要老人割断钓绳，就能使自己摆脱困境，得到解放，但这也就意味着宣告自己是失败者。老人没有作这样得选择，甚至没有产生过放弃战斗的念头。他把那条鲨鱼当作一个可与之交战的敌手，一次又一次地做着限度之外的战斗，他战胜了。 老人载着他的鱼回家去，鲨鱼在路上抢劫他的猎物。他杀死了一条来袭的鲨鱼，但是折断了他的鱼叉。于是他用刀子绑在棍子上做武器。到刀子又折断的时候，似乎这场战斗已经结束了。他失去了继续战斗的武器，他又遇到了他的限度。这是，他又进行了限度之外的战斗：当夜幕降临，更多的鲨鱼包围了他的小船，他用木棍、用桨、甚至用舵和鲨鱼搏斗，直到他要保卫的东西失去了保卫的价值，直到这场搏斗已经变得毫无意义的时候他才住手。 老人回到岸边，只带回了一条白骨，只带回了残破不堪的小船和耗尽了精力的躯体。人们怎样看待这场斗争呢？ 有人说老人桑地亚哥是一个失败了得英雄。尽管他是条硬汉，但还是失败了。 什么叫失败？也许可以说，人去做一件事情，没有达到预期得目的，这就是失败。 但是，那些与命运斗争的人，那些做接近自己限度的斗争的人，却天生地接近这种失败。老人到海上去，不能期望天天有鱼来咬他的钩，于是他常常失败。一个常常在进行着接近自己限度的斗争的人总是会常常失败的，一个想探索自然奥秘的人也常常会失败，一个想改革社会的人更是会常常失败。只有那些安于自己限度之内的生活的人才总是“胜利”，这种“胜利者”之所以常胜不败，只是因为他的对手是早已降伏的，或者说，他根本没有投入斗争。 在人生的道路上，“失败“这个词还有另外的含义，即是指人失去了继续斗争的信心，放下了手中的武器。人类向限度屈服，这才是真正的失败。而没有放下手中武器，还在继续斗争，继续向限度挑战的人并没有失败。如此看来，老人没有失败，老人从未放下武器，只不过是丧失了武器。老人没有失去信心，因此不应当说他是“失败了的英雄”。 那么，什么也没有得到的老人竟是胜利的么？我确是这样看的。我认为，胜利就是战斗到最后的时刻。老人总怀着无比的勇气走向莫测的大海，他的信心是不可战胜的。 他和其他许多人一样，是强悍的人类的一员。我喜欢这样的人，也喜欢这样的人性。我发现，人们常常把这样的事情当作人性最可贵的表露：七尺男子汉坐在厨房里和三姑六婆磨嘴皮子，或者衣装笔挺的男女们坐在海滨，谈论着高尚的、别人不能理解的感情。我不喜欢人们像这样沉溺在人性软弱的部分之中，更不喜欢人们总是这样描写人性。 正像老人每天走向大海一样，很多人每天也走向与他们的限度斗争的战场，仿佛他们要与命运一比高低似的。他们是人中的强者。 人类本身也有自己的限度，但是当人们一再把手伸到限度之外，这个限度就一天一天地扩大了。人类在与限度的斗争中成长。他们把飞船送上太空，他们也用简陋的渔具在加勒比海捕捉巨大的马林鱼。这些事情是同样伟大的。做这样不可思议的事情的人都是英雄。而那些永远不肯或不能越出自己限度的人是平庸的人。 在人类前进的道路上，强者与弱者的命运是不同的。弱者不羡慕强者的命运，强者也讨厌弱者的命运。强者带有人性中强悍的一面，弱者带有人性中软弱的一面。强者为弱者开辟道路，但是强者往往为弱者所奴役，就像老人是为大腹便便的游客打鱼一样。 《老人与海》讲了一个老渔夫的故事，但是在这个故事里却揭示了人类共同的命运。我佩服老人的勇气，佩服他不屈不饶的斗争精神，也佩服海明威。]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>王小波</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sysctl,ulimit以及/proc]]></title>
    <url>%2F2018%2F01%2F09%2Fsysctl%E3%80%81ulimit%E5%92%8Cproc%2F</url>
    <content type="text"><![CDATA[参考： sysctl命令 ulimit命令 ulimit、limits.conf、sysctl和proc文件系统 sysctl.conf学习和调优 sysctlsysctl 命令被用于在内核运行时动态地修改内核的运行参数，可用的内核参数在目录 /proc/sys 中。它包含一些Tcp/Ip堆栈和虚拟内存系统的高级选项，可以通过修改某些值来提高系统性能。 sysctl可以读取和设置超过五百个系统变量。sysctl变量的设置通常是字符串、数字或布尔型（布尔型用1表示yes，0表示no）。 sysctl - configure kernel parameters at runtime. 语法： 123#sysctl [options] [variable[=value]] [...]sysctl -w net.ipv4.tcp_syncookies=1 可以通过sysctl命令修改系统变量，也可以通过编辑sysctl.conf配置文件来修改系统变量。 sysctl.conf - sysctl preload/configuration file. 举个栗子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124vim /etc/sysct.conf# Controls source route verification# Default should work for all interfaces net.ipv4.conf.default.rp_filter = 1# net.ipv4.conf.all.rp_filter = 1# net.ipv4.conf.lo.rp_filter = 1# net.ipv4.conf.eth0.rp_filter = 1# Disables IP source routing# Default should work for all interfaces net.ipv4.conf.default.accept_source_route = 0# net.ipv4.conf.all.accept_source_route = 0# net.ipv4.conf.lo.accept_source_route = 0# net.ipv4.conf.eth0.accept_source_route = 0# Controls the System Request debugging functionality of the kernelkernel.sysrq = 0# Controls whether core dumps will append the PID to the core filename# Useful for debugging multi-threaded applicationskernel.core_uses_pid = 1# Increase maximum amount of memory allocated to shm# Only uncomment if needed# kernel.shmmax = 67108864# Disable ICMP Redirect Acceptance# Default should work for all interfacesnet.ipv4.conf.default.accept_redirects = 0# net.ipv4.conf.all.accept_redirects = 0# net.ipv4.conf.lo.accept_redirects = 0# net.ipv4.conf.eth0.accept_redirects = 0# enable Log Spoofed Packets, Source Routed Packets, Redirect Packets# Default should work for all interfacesnet.ipv4.conf.default.log_martians = 1#net.ipv4.conf.all.log_martians = 1# net.ipv4.conf.lo.log_martians = 1# net.ipv4.conf.eth0.log_martians = 1# Decrease the time default value for tcp_fin_timeout connectionnet.ipv4.tcp_fin_timeout = 25# Decrease the time default value for tcp_keepalive_time connectionnet.ipv4.tcp_keepalive_time = 1200# Turn on the tcp_window_scalingnet.ipv4.tcp_window_scaling = 1# Turn on the tcp_sacknet.ipv4.tcp_sack = 1# tcp_fack should be on because of sacknet.ipv4.tcp_fack = 1# Turn on the tcp_timestampsnet.ipv4.tcp_timestamps = 1# Enable TCP SYN Cookie Protectionnet.ipv4.tcp_syncookies = 1# Enable ignoring broadcasts requestnet.ipv4.icmp_echo_ignore_broadcasts = 1# Disable ping requestsnet.ipv4.icmp_echo_ignore_all = 1# Enable bad error message Protectionnet.ipv4.icmp_ignore_bogus_error_responses = 1# make more local ports available# net.ipv4.ip_local_port_range = 1024 65000# set TCP Re-Ordering value in kernel to 5net.ipv4.tcp_reordering = 5# Lower syn retry ratesnet.ipv4.tcp_synack_retries = 2net.ipv4.tcp_syn_retries = 3# Set Max SYN Backlog to 2048net.ipv4.tcp_max_syn_backlog = 2048# Various Settingsnet.core.netdev_max_backlog = 1024# Increase the maximum number of skb-heads to be cachednet.core.hot_list_length = 256# Increase the tcp-time-wait buckets pool sizenet.ipv4.tcp_max_tw_buckets = 360000# This will increase the amount of memory available for socket input/output queuesnet.core.rmem_default = 65535net.core.rmem_max = 8388608net.ipv4.tcp_rmem = 4096 87380 8388608 net.core.wmem_default = 65535net.core.wmem_max = 8388608net.ipv4.tcp_wmem = 4096 65535 8388608net.ipv4.tcp_mem = 8388608 8388608 8388608net.core.optmem_max = 40960 重新加载内核参数： 12345#-p, read values from filesysctl -p#-a, display all variablessysctl -a ulimit大多Unix-Like系统，都提供了限制每个进程和每个基本用户使用线程，文件和网络连接等系统资源的一些方法。 假设有这样一种情况，当一台Linux主机上同时登陆了10人，在资源无限制的情况下，这10个用户同时打开了500个文件。假设每个文件的大小有10M，这是系统的内存资源就会收到巨大挑战。但是任何一台主机的资源都不可能是无限的。所以，资源的合理配置和分配，不仅仅是保证系统可用性的必要条件，也与系统上软件运行的性能有着密不可分的联系。 ulimit是指每个user使用各种资源的限制值。ulimit 命令用来限制系统用户对shell资源的访问，它是一种简单并且有效的实现资源限制的方式。 ulimit的设置值是 per-process的，也就是说，每个进程都有自己的limits值； 使用ulimit进行修改，是立即生效的； ulimit只影响shell进程及其子进程，用户登出后失效； 修改ulimit设置之后，要重启程序修改值才会有效。可通过/proc文件系统查看运行进程当前的限制值; 使用ulimit对系统限制的改变在系统重启后都会恢复到默认值; 可以在profile中加入ulimit的设置，便能做到永久生效。 ulimit 用于限制 shell 启动进程所占用的资源，支持以下各种类型的限制： 所创建的内核文件的大小； 进程数据块的大小； Shell进程创建文件的大小； 内存锁住的大小； 常驻内存集的大小； 打开文件描述符的数量； 分配堆栈的最大大小； CPU时间； 单个用户的最大线程数； Shell进程所能使用的最大虚拟内存； 它支持硬资源(hard)和软资源(soft)的限制。 sort和hard hard：是指用户在任何时候都可以活动的进程的最大数量，这是上限。没有任何non-root进程能够增加hard ulimit； soft：是对会话或进程实际执行的限制，但任何进程都可以将其增加到hard ulimit的最大值。 设置ulimit可以在以下位置进行ulimit的设置： /etc/profile，所有用户有效，永久生效； ~/.bash_profile,当前用户有效，永久生效； 直接在控制台修改，当前用户有效，临时生效； 永久生效： 123vim /etc/profilevim ~/.bash_profile 临时生效： 12345678910111213141516171819202122232425ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 7170max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 1024pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 7170virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited#修改限定值ulimit -n 201400ulimit -t ulimited limits.conflimits.conf - configuration file for the pam_limits module limits.conf是pam_limits.so的配置文件，Linux PAM(Pluggable Authentication Modules，插入式认证模块)。突破系统默认限制，对系统资源有一定保护作用。 pam_limits模块对用户的会话进行资源限制，然后/etc/pam.d/下的应用程序调用pam_***.so模块。 limits.conf是针对用户，而sysctl.conf是针对整个系统参数配置。 一个shell的初始limits就是由pam_limits设定的，用户登录后，pam_limits会给用户的shell设定在limits.conf定义的值； pam_limits的设定值也是per-process； pam_limits的设置是 永久生效的。 配置limits.conf： 1vim /etc/security/limits.conf 举个栗子： 123456789#&lt;domain&gt; &lt;type&gt; &lt;item&gt; &lt;value&gt;#* soft core 0#* hard rss 10000#@student hard nproc 20#@faculty soft nproc 20#@faculty hard nproc 50#ftp hard nproc 0#@student - maxlogins 4 domain： username @groupname type： soft hard - item： core，限制内核文件的大小 date，最大数据大小 fsize，最大文件大小 memlock，最大锁定内存地址空间 nofile，打开文件的最大数目 rss，最大持久设置大小 stack，最大栈大小 cpu，以分钟为单位的最多CPU时间 nproc，进程的最大数目 as，地址空间限制 maxlogins，此用户允许登录的最大数目 value： item值的大小 /proc什么是/proc文件系统Linux内核提供了一种通过/proc文件系统，在运行时访问内核内部数据结构，改变内核设置的机制。 proc文件系统是一个伪文件系统，它只存在内存当中，不占用外部空间。它以文件系统的方式为访问系统内核数据的操作提供接口。 对/proc中内核文件的修改，针对的是整个系统的内核参数，修改后立即生效，但修改是 临时的，重启后失效。 /proc与sysctl.conf的对应关系修改/proc文件系统中的参数是临时的，但修改sysctl.conf的参数确是永久有效的。 配置文件sysctl.conf变量在/proc/sys下，其对应关系如下： 123456789#将文件名的 . 变为 /#/proc/sys/net/ipv4/icmp_echo_ignore_all#net.ipv4.icmp_echo_ignore_allecho 0 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_allvim /etc/sysctl.confnet.ipv4.icmp_echo_ignore_all = 0 /proc文件系统几个常用的内核文件 /proc/meminfo #内存信息 /proc/cpuinfo #CPU信息 /proc/sys/fs/file-max #文件打开数 /proc/sys/fs/file-nr #整个系统目前使用的文件句柄数量 /proc文件系统中文件的权限proc中的每个文件都有一组分配给它的非常特殊的文件许可权，并且每个文件属于特定的用户标识。 只读：任何用户都不能更改该文件，它用于表示系统信息 root写 root读 对/proc进行读写123456cat /proc/sys/net/ipv4/icmp_echo_ignore_all#0echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all#当然,也可是用sysctl来配置 /proc内核文件详解 /proc/buddyinfo 每个内存区中的每个order有多少块可用，和内存碎片问题有关 /proc/cmdline 启动时传递给kernel的参数信息 /proc/cpuinfo cpu的信息 /proc/crypto 内核使用的所有已安装的加密密码及细节 /proc/devices 已经加载的设备并分类 /proc/dma 已注册使用的ISA DMA频道列表 /proc/execdomains Linux内核当前支持的execution domains /proc/fb 帧缓冲设备列表，包括数量和控制它的驱动 /proc/filesystems 内核当前支持的文件系统类型 /proc/interrupts x86架构中的每个IRQ中断数 /proc/iomem 每个物理设备当前在系统内存中的映射 /proc/ioports 一个设备的输入输出所使用的注册端口范围 /proc/kcore 代表系统的物理内存，存储为核心文件格式，里边显示的是字节数，等于RAM大小加上4kb /proc/kmsg 记录内核生成的信息，可以通过/sbin/klogd或/bin/dmesg来处理 /proc/loadavg 根据过去一段时间内CPU和IO的状态得出的负载状态，与uptime命令有关 /proc/locks 内核锁住的文件列表 /proc/mdstat 多硬盘，RAID配置信息(md=multiple disks) /proc/meminfo RAM使用的相关信息 /proc/misc 其他的主要设备(设备号为10)上注册的驱动 /proc/modules 所有加载到内核的模块列表 /proc/mounts 系统中使用的所有挂载 /proc/mtrr 系统使用的Memory Type Range Registers (MTRRs) /proc/partitions 分区中的块分配信息 /proc/pci 系统中的PCI设备列表 /proc/slabinfo 系统中所有活动的 slab 缓存信息 /proc/stat 所有的CPU活动信息 /proc/sysrq-trigger 使用echo命令来写这个文件的时候，远程root用户可以执行大多数的系统请求关键命令，就好- 像在本地终端执行一样。要写入这个文件，需要把/proc/sys/kernel/sysrq不能设置为0。这个文件对root也是不可- 读的 /proc/uptime 系统已经运行了多久 /proc/swaps 交换空间的使用情况 /proc/version Linux内核版本和gcc版本 /proc/bus 系统总线(Bus)信息，例如pci/usb等 /proc/driver 驱动信息 /proc/fs 文件系统信息 /proc/ide ide设备信息 /proc/irq 中断请求设备信息 /proc/net 网卡设备信息 /proc/scsi scsi设备信息 /proc/tty tty设备信息 /proc/net/dev 显示网络适配器及统计信息 /proc/vmstat 虚拟内存统计信息 /proc/vmcore 内核panic时的内存映像 /proc/diskstats 取得磁盘信息 /proc/schedstat kernel调度器的统计信息 /proc/zoneinfo 显示内存空间的统计信息，对分析虚拟内存行为很有用 以下是/proc目录中进程N的信息： /proc/N pid为N的进程信息 /proc/N/cmdline 进程启动命令 /proc/N/cwd 链接到进程当前工作目录 /proc/N/environ 进程环境变量列表 /proc/N/exe 链接到进程的执行命令文件 /proc/N/fd 包含进程相关的所有的文件描述符 /proc/N/maps 与进程相关的内存映射信息 /proc/N/mem 指代进程持有的内存，不可读 /proc/N/root 链接到进程的根目录 /proc/N/stat 进程的状态 /proc/N/statm 进程使用的内存的状态 /proc/N/status 进程状态信息，比stat/statm更具可读性 /proc/self 链接到当前正在运行的进程]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>系统优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开源许可协议]]></title>
    <url>%2F2018%2F01%2F09%2F%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[当你为你的产品签发许可，你就是在出让自己的权利。不过，你仍拥有版权和专利（如果申请了专利）。许可的目的，是向使用你产品的人提供一定的权利。 不管产品是免费分发，还是出售，指定一份许可协议都非常有用。否则，对于免费，你相当于放弃了自己的所有权利，任何人都没有义务表明你的原始作者身份。对于出售，你将不得不花费比开发更多的精力用来处理授权问题。 而开源许可协议是这些事情变得简单，开发者很容易向一个项目贡献自己的代码，它还可以保护你原始作者的身份，使你至少获得认可。开源许可协议还可以阻止其它人将某个产品据为己有。 几大开源许可协议 GNU Project GNU是“GNU’s Not Unix”的递归缩写，发音为 /‘gnu:’/； GNU Project，是一个由自由软件集体协作项目，它的目标是创建一套完全自由的操作系统，称为GNU； GNU是一个自由操作系统，其内容软件完全以 GPL 方式发布，它的设计类似于Unix，但它不包含具有著作权的Unix代码。 GPLGNU(General Public Licence)，GNU通用许可协议(简称GPL)是广泛使用的免费软件许可证，也称为 copyleft，与copyright相对应。GPL保证了所有开发者的权利，同时为使用者提供了足够的复制、分发、修改的权利。 需要注意的是，分发的时候，需要明确提供源代码和二进制文件。 可自由复制： 你可以将软件复制到你的电脑或任何地方，复制份数没有限制； 可自由分发： 可下载后拷贝分发； 可以用来盈利： 你可以在分发软件的时候收费，但必须在收费前向你的客户提供该软件的 GNU GPL许可协议，以便让他们知道，他们可以从别的渠道免费得到这份软件以及你收费的理由； 可自由修改： 你过你想添加或删除某个功能，没问题。如果你想在别的项目中使用部分代码，也没问题，唯一要求是使用了这段代码的项目也必须使用 GPL协议。 LGPLGNU还有另外一种协议，叫做LGPL（Lesser General Public License），它对产品所保留的权利比GPL少。总的来说，LGPL适合那些用于非GPL或非开源产品的开源类库或框架。因为GPL要求，使用了GPL代码的产品也必须使用GPL协议，开发者不允许将GPL代码用于商业产品。LGPL绕过了这一限制。 GPL和LGPL都属于GNU计划里面的许可证。 BSD伯克利软件套件（Berkeley Software Distribution，缩写BSD），也被称为伯克利Unix，是一个操作系统的名称，衍生自Unix，也被用来代表一整套软件发行版。 BSD许可证（Berkeley Software Distribution License），是自由软件中使用广泛的许可证。BSD软件就是遵照这个许可证来发布，该许可证也因此而得名。 BSD在软件分发方面的限制比别的开源协议要少，且和GPL兼容，并为开源组织所认可。 MITMIT（Massachusetts Institute of Technology），麻省理工学院。MIT许可协议（The MIT License）是许多软件授权条款中，被广泛使用的其中一种。与其他常见的软件许可协议相比，MIT是相对宽松的软件许可协议，除了必须包含许可声明外，再无任何限制。 MIT许可协议核心条款： 该软件及其相关文档对所有人免费，可以任意处置，包括使用、复制、修改、合并、发表、分发、再授权或销售； 唯一的限制，软件中必须包含上述版权和许可证。 ApacheApache许可证（Apache License），是一个由Apache软件基金会发布的自由软件许可证。Apache许可证要求被授权者保留版权和放弃权利的声明，但它不是一个反版权的许可证。兼容与GPL。 除了为用户提供版权许可之外，还有专利许可，对于那些涉及专利内容的开发者而言，该协议最适合。 永久权利：一旦被授权，永久拥有； 全球范围的权利：在一个国家获得授权，适用于所有国家； 授权免费，且无版税：前后期均无任何费用； 授权不可撤销：一旦获得授权，没有任何人可以取消。 分发代码方面，要在声明中对参与开发的人给予认可并包含一份许可协议原文。 MPLMPL是The Mozilla[mɔzilə] Public License的简写，是1998年初Netscape的 Mozilla小组为其开源软件项目设计的软件许可证。MPL许可证出现的最重要原因就是，Netscape公司认为GPL许可证没有很好地平衡开发者对源代码的需求和他们利用源代码获得的利益。 同著名的GPL许可证和BSD许可证相比，MPL在许多权利与义务的约定方面与它们相同（因为都是符合OSIA 认定的开源软件许可证）。 MPL几个特点： MPL虽然要求对于经MPL许可证发布的源代码的修改也要以MPL许可证的方式再许可出来，以保证其他人可以在MPL的条款下共享源代码。但是，在MPL 许可证中对“发布”的定义是“以源代码方式发布的文件”，这就意味着MPL允许一个企业在自己已有的源代码库上加一个接口，除了接口程序的源代码以MPL 许可证的形式对外许可外，源代码库中的源代码就可以不用MPL许可证的方式强制对外许可。这些，就为借鉴别人的源代码用做自己商业软件开发的行为留了一个豁口； MPL许可证第三条第7款中允许被许可人将经过MPL许可证获得的源代码同自己其他类型的代码混合得到自己的软件程序； 对软件专利的态度，MPL许可证不像GPL许可证那样明确表示反对软件专利，但是却明确要求源代码的提供者不能提供已经受专利保护的源代码（除非他本人是专利权人，并书面向公众免费许可这些源代码），也不能在将这些源代码以开放源代码许可证形式许可后再去申请与这些源代码有关的专利； 对源代码的定义，MPL许可证第3条有专门的一款是关于对源代码修改进行描述的规定，就是要求所有再发布者都得有一个专门的文件就对源代码程序修改的时间和修改的方式有描述。 CC知识共享许可协议(Creative Commons License，简称CC)，并非严格意义上的开源许可，是一种公共版权许可协议。它主要用于设计，其允许分发受版权保护的作品。 CC协议主要包含4种基本形式： 署名权：必须为原始作业署名，然后才可以修改、分发、复制； 保持一致：作品同样可以在CC协议的基础上修改、分发、复制； 非商业：不能用于商业用途； 不能衍生新作品：你可以复制、分发、但不能修改，也不能以此为基础创作自己的作品。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>开源许可协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yum源]]></title>
    <url>%2F2018%2F01%2F09%2FYum%E6%BA%90%2F</url>
    <content type="text"><![CDATA[参考： CentOS 7下配置本地yum源及yum客户端 Centos7 配置本地源+阿里yum源/epel-yum+修改优先级 调整CentOS 7中yum仓库的优先级 国内开源站点 国内开源镜像站点 网易开源镜像站：http://mirrors.163.com/ 阿里云开源镜像站：http://mirrors.aliyun.com 清华大学开源镜像站：https://mirrors.tuna.tsinghua.edu.cn/ 浙江大学开源镜像站： http://mirrors.zju.edu.cn/ 中国科技大学开源镜像站：http://mirrors.ustc.edu.cn/ CentOS自带源rpm包管理方式，对于安装、升级、卸载却难以处理包之间的依赖关系。而yum作为一个rpm包前端管理工具，可以自动处理依赖性，并支持在线现在、安装、升级、卸载rpm软件包。 CentOS默认自带CentOS-Base.repo源，但官方源在国外，连接速度令人心痛。并且有很多软件在默认源里面是找不到的。 配置网络yun源配置aliyun.repo： 12345678910#先备份默认源mv CentOS-Base.repo&#123;,.bak&#125;#下载阿里云源替换默认源wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repoyum clean allyum makecache #重构yum缓存yum repolist #查看yum仓库 配置本地yum源配置本地yum源，考虑到优先使用本地安装包，所以会涉及到一个优先级的概念。 安装完毕后，就可以在yum源中添加一个优先级priority。 安装yum优先级插件： 1234567yum install -y yum-plugin-priorities#检查安装完成后配置vim /etc/yum/pluginconf.d/priorities.confenable=1#enable=0 创建本地yum源： 123456789101112131415161718192021222324mv /etc/yum.repos.d/CentOS-Base.repo&#123;,.bak&#125;vim /etc/yum.repos.d/CentOS-Local.repo[base-Local]name=Centos- Localbaseurl=file:///mnt/xxxgpgcheck=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7priority=1 #优先级为1[updates-Local]name=CentOS- Localgpgcheck=0baseurl=file:///dir/path/gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7priority=1······#具体可参考CentOS-Base.repo#可将aliyun源优先级写成2yum clean allyum makecache 配置ftp方式源1234567891011vim /etc/yum.repos.d/ftp.repo[ftp-media]name=name=CentOS-$releasever - mediabaseurl=ftp://ipgpgcheck=0enable=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7yum clean allyum makecache 其他常见YUM源官方的默认yum源提供的软件包往往是很滞后的，(可能为了服务器版本的稳定性和安全性)。并且官方默认源提供的RPM包也不够丰富。 EPEL源EPEL的全称叫 Extra Packages for Enterprise Linux 。EPEL是由 Fedora 社区打造，为 RHEL 及衍生发行版如 CentOS、Scientific Linux 等提供高质量软件包的项目。装上了 EPEL之后，就相当于添加了一个第三方源。 EPEL源为服务器提供了大量的rpm包(这些包可能有很多在默认源中没有)，并且绝大多数rpm包比官方默认源版本要新。 添加epel源：epel下载地址：http://download.fedora.redhat.com/pub/epel/123rpm -vih http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-9.noarch.rpm#yum install -y epel-release remi源Remi源大家或许很少听说，不过Remi源GoFace强烈推荐，尤其对于不想编译最新版的linux使用者，因为Remi源中的软件几乎都是最新稳定版。或许您会怀疑稳定不？放心，这些都是Linux骨灰级的玩家编译好放进源里的，他们对于系统环境和软件编译参数的熟悉程度毋庸置疑。 添加remi源：Remi下载地址：http://rpms.famillecollet.com123rpm -ivh http://rpms.famillecollet.com/enterprise/remi-release-7.rpm#yum install -y http://rpms.famillecollet.com/enterprise/remi-release-7.rpm RPMForge源RPMForge是CentOS系统下的软件仓库，拥有4000多种的软件包, 被CentOS社区认为是最安全也是最稳定的一个软件仓库。 添加RPMForge源：RPMForge下载地址：http://repository.it4i.cz/mirrors/repoforge/redhat/el7/en/x86_64/rpmforge/RPMS/GitHub:https://github.com/repoforge 123rpm -ivh http://repository.it4i.cz/mirrors/repoforge/redhat/el7/en/x86_64/rpmforge/RPMS/rpmforge-release-0.5.3-1.el7.rf.x86_64.rpm#yum localinstall --nogpgcheckhttp://repository.it4i.cz/mirrors/repoforge/redhat/el7/en/x86_64/rpmforge/RPMS/rpmforge-release-0.5.3-1.el7.rf.x86_64.rpm]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[写给2017]]></title>
    <url>%2F2018%2F01%2F01%2F%E5%86%99%E7%BB%992017%2F</url>
    <content type="text"><![CDATA[2017大事件 Feb.27.2017，开始工作； May.27.2017，工作转正； Jun.25.2017，大学毕业； Aug.27.2017，工作半年； Aug.30.2017，搭建博客。 记得大四下期的时候，在学校实在是想出来工作，以为这样就可以有工资有点钱可以实现财务自由。Naive x3! 记得刚去面试的时候，公司的HR问我期待的薪资是多少。我这个老实人也不敢往高了说，以为能解决温饱就不错。这就导致后面日子过得紧巴巴，生活基本上处于没钱不敢消费不敢出去的惨状。Naive x3! 记得那天是星期四，从学校收拾了一箱子的衣物加上自己的笔记本就来了成都。还要感谢强对我的帮助，在他那借宿了两天。这两天跑到公司附近找房子，这打个电话，那去看看…结果看了看自己兜里不到三千，再看看房租，还是算了吧！后来由于周一就要开始去公司报道了，实在没办法，硬着头皮找了一个750的单间。我现在觉得，人在生活面前真的没有办法。借用张主任的一句话——“是生活，生活强奸了所有人。”一个套三的屋子，硬是被房主改造成了七间房，住了11人。我想各位住户都迫于无奈吧，有谁想和别人挤在一起了，况且还要忍受上厕所的艰难时光。还是说说我住的那间房屋吧。是客厅使用木板隔得房间，手指随便敲几下都铛铛作响，况且隔壁还住了一对情侣。一张床，一个烂小衣柜，一张摆放电脑的桌子。客厅的后面有一个阳台，所以就会有一个大窗户间隔阳台。然而这个阳台是和隔壁公用的，也就是说，这个大窗户是可以互通的。哎！阳台风大，还好我只住到了夏天。五月二十号，和我强一起搬到了中和。也是没有做好十足打算，说搬就搬了。虽说住宿条件好了一些，可这面修路是真的堵，公家车是真的挤，真的是挤得怀疑人生的那种，还是走路吧。由于搬过来中和，房租和其他开支多了一些，刚开始没什么钱的时候，自己带饭去公司。我都佩服自己，那么挤得车上还能坚持带饭几个月，看来还是穷吧。冬天到了，太冷了就没有带饭到公司了。但公司楼下吃饭真的好贵，吃不起吃不起。由于住宿条件好了一些，晚上回来可以自己做饭，还是不错。并且晚上基本有两个小时干干工作之外的事情，看看小说、看看电视、发发呆什么也挺好的！ 记得才开始工作的时候，好像每天都很闲，没有事做。心里担忧的不行，这样怎么有提升呢？每天都急躁不安，这不会那不会，又腼腆害羞…后来慢慢理解，任何事情都不能操之过急，不能带着情绪上班。不喜欢某个同事也不能表现出来，更不能带到工作上。工作是工作，生活是生活，一定要分开。被骂也没有办法，骂吧，你骂高兴。任何人都不会听你的理由，理由对于别人来说只是你没有完成的狡辩。踏踏实实上班，做好自己的事情才是正解！千万不要好为人师，人都是有嫉妒心得，不要太招摇！也不要羡慕别人工作轻松之类，那是人家的工作，和你没有半毛钱关系。上班好好上班，不要搞东搞西。我个人比较看重效率，怀着为了加班而加班的目的真的没有必要。那时由于住单间，条件差，愿意在公司多呆一会，多学习知识。越到后面，觉得自己越得努力学习新知识，需要了解的知识就在那，就等我把它们一个个打上勾，撸起袖子加油干。 自我批评: 心胸不够宽广，容易嫉妒别人； 害羞爱面子，拉不下面子做事情； 由于自卑心理导致的不敢说不敢争。 以前我以为自己是讨厌某种方式、讨厌别人炫耀、讨厌别人秀恩爱，现在才知道是由于自己没有，就用自己的不屑和厌恶来突出自己，让自己心安理得。说白了还不是自己嫉妒人家，嫉妒人家比我好，有女票。这点是真的要改，一定要改。千万别用别人的缺点来突出自己，这很SB，切记切记。如同小波所说：“人的一切痛苦，本质都是对于自己无能的愤怒。” 在学校总幻想自己能成为英雄，总想做一番事业，像历史上的英雄那般。不屑考个老师公务员职位，以为一辈子就那样，混吃等死的咸鱼。其实其它工作不也同样是这样吗。混吃等死的不是任何工作岗位，而是人！任何岗位都可以有所成就。自己也不过只是凡人一个。不过凡人却也可以有自己的一片天地。就像小波说的：“井底之蛙也能拥有自己的一片天地。” 工作没有高低贵贱之分，不要带着要面子的心情而不愿意做些打杂的活。没有基础的积累，哪来平地起的万丈高楼。不要看不起自己也不要看不起他人。三十年河东三十年河西，此一时彼一时。 ”中国的君子独善其身，这样就没有了尊严。这是因为尊严是属于个人的、不可压缩的空间，这块空间要靠自己来捍卫——捍卫的意思是指敢争、敢打官司、敢动手（勇斗歹徒）。我觉得人还是有点尊严的好，假如个人连个待的地方都没有，就无法为人做事，更不要说做别人的典范。“这句话同样适合我，该说该争该做的时候就应该大胆站出来，有一个男子汉的样子。要敢于亮剑！ 我现在还不太明白我的人生目标是什么，名利？我不知道。我只想做一个懂点道理的人。上班以后感觉也变得世俗化了，不经意间都会主动被动地谈及任何关于钱的话题。我对钱有一些兴趣，但不愿为之受罪。我不想把自己的下半生绑在房子上，虽然我也买不起。找不到人同我谈谈诗歌、文学、历史、足球，谈谈理想和爱情。但正如小波所言：”和我志趣相投的人总不会一个人都没有吧。“我也不顾影自怜了。 展望2018 最重要的事情当然是涨工资啦，哈哈。加油加油，为了涨工资可得好好奋斗； 如果能找一个离家近一点的工作当然是最好； 一个人总是孤独寂寞的，能找到一个能相互扶持的人当然最好； 改善自己的不同，提升自己的优点。扬长避短，向优秀的人多学习。 不成熟的想法 成都这地方什么都要争，连坐个公交地铁也得积极地抢位置，哎； 人太多，太拥挤，随便去哪都是拥挤的要命。但另一方面却是人越多机会越多； 原来工作才是一生的主题。但到底图个啥——名？利？ 上班以后认识的人也变少了，圈子也基本没什么了。曾经的同学们也各奔东西了； 我发觉任何一件事都是矛盾的。正面想是这样，反面想却又是那样，但都有道理。让我想起了一个故事，“一个农夫和一个老板在海边的对话。问：这么努力工作干嘛？答：为了以后能过更轻松的日子。那你看我现在不是挺轻松自在的吗？” 现在的自媒体为了流量真的是无所不用其极。各种大噱头的标题，完全不负责任的报道，只为吸引流量。到最后都不知道该相信谁，会不会被带节奏…； 一天24小时。8小时睡觉，8小时上班，3小时上下班，2小时吃饭及其他。It means that I only have 3 hours a day without Rest Day; 一个人只拥有此生此世是不够的，他还应该拥有诗意的世界。]]></content>
      <categories>
        <category>Zhang</category>
      </categories>
      <tags>
        <tag>2017</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[君子的尊严]]></title>
    <url>%2F2017%2F12%2F28%2F%E5%90%9B%E5%AD%90%E7%9A%84%E5%B0%8A%E4%B8%A5%2F</url>
    <content type="text"><![CDATA[笔者是个学究，待人也算谦和有礼，自以为算个君子——当然，实际上是不是，还要别人来评判。总的来说，君子是有文化有道德的人，是士人或称知识分子。按照中国的传统，君子是做人的典范。君子不言利。君子忍让不争。君子动口不动手。君子独善其身。这都是老辈子传下来的规矩，时至今日，以君子自居的人还是如此行事。我是宁做君子不做小人的，但我还是以为，君子身上有些缺点，不配作为人的典范；因为他太文弱、太窝囊、太受人欺。 君子既不肯与人争利，就要安于清贫。但有时不是钱的问题，是尊严的问题。前些时候在电视上看到北京的一位人大代表发言，说儿童医院的挂号费是一毛钱，公厕的收费是两毛钱。很显然，这样的收费标准有损医务工作的尊严。当然，发言的结尾是呼吁有关领导注意这个问题，有关领导也点点头说：是呀是呀，这个问题要重视。我总觉得这位代表太君子，没把话讲清楚——直截了当的说法是：我们要收两块钱。别人要是觉得太贵，那你就还个价来——这样三下五除二就切入了正题。这样说话比较能解决问题。 君子不与人争，就要受气。举例来说，我乘地铁时排队购票，总有些不三不四的人到前面加塞。说实在的，我有很多话要说：我排队，你为什么不排队？你忙，难道我就没有事？但是碍于君子的规范，讲不出口来。话憋在肚子里，难免要生气。有时气不过，就嚷嚷几句：排队，排队啊。这种表达方式不够清晰，人家也不知是在说他。正确的方式是：指住加塞者的鼻子，口齿清楚地说道：先生，大家都在排队，请你也排队。但这样一来，就陷入与人争论的境地，肯定不是君子了。 常在报纸上看到这样的消息：流氓横行不法，围观者如堵，无人上前制止。我敢断定，围观的都是君子，也很想制止，但怎么制止呢？难道上前和他打架吗？须知君子动口不动手啊。我知道英国有句俗话：绅士动拳头，小人动刀子。假如在场的是英国绅士，就可以上前用拳头打流氓了。 既然扯到了绅士，就可以多说几句。从前有个英国人到澳大利亚去旅行，过海关时，当地官员问他是干什么的。他答道：我是一个绅士。因为历史的原因，澳大利亚人不喜欢听到这句话，尤其不喜欢听到这句话从一个英国人嘴里说出来。那官员又问：我问你的职业是什么？英国人答道：职业就是绅士。难道你们这里没有绅士吗？这下澳大利亚人可火了，差点揍他，幸亏有人拉开了。在英美，说某人不是绅士，就是句骂人话。当然，在我们这里说谁不是君子，等于说他是小人，也是句骂人话。但君子和绅士不是一个概念。从字面上看，绅士（gentleman）是指温文有礼之人，其实远不止此。绅士要保持个人的荣誉和尊严，甚至可以说是这方面的专业户。坦白地说，他们有点狂傲自大。但也有一种好处：真正的绅士决不在危险面前止步。大战期间，英国绅士大批开赴前线为国捐躯，甚至死在了一般人前面。君子的标准里就不包括这一条。 中国的君子独善其身，这样就没有了尊严。这是因为尊严是属于个人的、不可压缩的空间，这块空间要靠自己来捍卫——捍卫的意思是指敢争、敢打官司、敢动手（勇斗歹徒）。我觉得人还是有点尊严的好，假如个人连个待的地方都没有，就无法为人做事，更不要说做别人的典范。]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>王小波</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人尊严]]></title>
    <url>%2F2017%2F12%2F28%2F%E4%B8%AA%E4%BA%BA%E5%B0%8A%E4%B8%A5%2F</url>
    <content type="text"><![CDATA[在国外时看到，人们对时事做出价值评判时，总是从两个独立的方面来进行：一个方面是国家或者社会的尊严，这像是时事的经线；另一个方面是个人的尊严，这像是时事的纬线。回到国内，一条纬线就像是没有，连尊严这个字眼也感到陌生了。提到尊严这个概念，我首先想到的英文词＂dignity＂，然后才想到相应的中文词。在英文中，这个词不仅有尊严之义，还有体面、身份的意思。尊严不但指人受到尊重，它还是人价值之所在。从上古到现代，数以亿万计的中国人里，没有几个人有过属于个人的尊严。举个大点的例子，中国历史上有过皇上对大臣施廷杖的事，无论是多大的官，一言不和，就可能受到如此当众羞辱，高官尚且如此，遑论百姓。除了皇上一人，没有一个人能有尊严。有一件最怪的事是，按照传统道德，挨皇帝的板子倒是一种光荣，文死谏嘛。说白了就是：无尊严就是有尊严。此话如有任何古怪之处，罪不在我。到了现代以后，人与人的关系、个人与集体的关系，仍有这种遗风──我们就不必细说文革中、文革前都发生过什么样的事情。到了现在，已经不用见官下跪，也不会在屁股上挨板子，但还是缺少个人的尊严。环境就是这样，公共场所的秩序就是这样，人对人的态度就是这样，不容你有任何自尊。 举个小点的例子，每到春运高潮，大家就会在传媒上看到一辆硬座车厢里挤了三四百人，厕所里也挤了十几人。谈到这件事，大家会说国家的铁路需要建设，说到铁路工人的工作难做，提到安全问题，提到所有的方面，就是不提这些民工这样挤在一起，好像一个团，完全没有了个人的尊严──仿佛这件事很不重要似的。当然，只要民工都在过年时回家，火车总是要挤的；谁也想不出好办法。但个人的尊严毕竟大受损害；这件事总该有人提一提才对。另一件事现在已是老生常谈，人走在街上感到内急，就不得不上公共厕所。一进去就觉得自己的尊严一点都没了。现在北京的公厕正在改观，这是因为外国人到了中国也会内急，所以北京的公厕已经臭名远扬。假如外国人不来，厕所就要臭下去；而且大街上改了，小胡同里还没有改。我认识的一位美国留学生说，有一次他在小胡同里内急，走进公厕撒了一泡尿，出来以后，猛然想到自己刚才满眼都对黄白之物，居然能站住了不倒，觉得自己很了不起，就急忙来告诉我。北京的某些街道很脏很乱，总要到某个国际会议时才能改观，这叫借某某会的东风。不光老百姓这样讲，领导上也这样讲。这话听起来很有点不对味。不雅的景象外人看了丢脸，没有外人时，自己住在里面也不体面──这后一点总是被人忘掉。 作为一个知识分子，我发现自己曾有一种特别的虚伪之处，虽然一句话说不清，但可以举些例子来说明。假如我看到火车上特别挤，就感慨一声道：这种事居然可以发生在中华人民共和国的土地上！假如我看到厕所特脏，又长叹一声：唉！北京市这是怎么搞的嘛！这其中有点幽默的成份，也有点当真。我的确觉得国家和政府的尊严受到了损失，并为此焦虑着。当然，我自己也想要点个人尊严，但以个人名义提出就过于直露，不够体面──言必称天下，不以个人面目出现，是知识分子的尊严所在。当然，现在我把这做为虚伪提出，已经自外于知识分子。但也有种好处，我找到了自己的个人面目。有关尊严问题，不必引经据典，我个人就是这么看。但中国忽视个人尊严，却不是我的新发现。从大智者到通俗作家，有不少人注意到一个有中国特色的现象：罗素说，中国文化里只重家族内的私德，不重社会的公德公益，这一点造成了很要命的景象；费孝通说，中国社会里有所谓＂差序格局＂，与己关系近的就关心，关系远的就不关心或少关心；结果有些事从来就没人关心。龙应台为这类事而愤怒过，三毛也大发过一通感慨。读者可能注意到了，所有指出这个现象的人，或则是外国人，或则曾在国外生活过，又回到了国内。没有这层关系的中国人，对此浑然不觉。笔者自己曾在外国居住四年，假如没有这种经历，恐怕也发不出这种议论──但这一点并不让我感到开心。环境脏乱的问题，火车拥挤的问题，社会秩序的问题，人们倒是看到了。但总从总体方面提出问题，讲国家的尊严、民族的尊严。其实这些事就发生在我们身边，削我们每个人的面子──对此能够浑然无觉，倒是咄咄怪事。 人有无尊严，有一个简单的判据，是看他被当作一个人还是一个东西来对待。这件事有点两重性，其一是别人把你当做人还是东西，是你尊严之所在。其二是你把自己看成人还是东西，也是你的尊严所在。挤火车和上公共厕所时，人只被当身体来看待。这里既有其一的成份，也有其二的成份；而且归根结蒂，和我们的文化传统有关。 说来也奇怪，中华礼仪之邦，一切尊严，都从整体和人与人的关系上定义，就是没有个人的位置。一个人不在单位里、不在家里，不代表国家、民族，单独存在时，居然不算一个人，就算是一块肉。这种算法当然是有问题。我的算法是：一个人独处荒岛而且谁也不代表，就像鲁滨孙那样，也有尊严，可以很好的活着。这就是说，个人是尊严的基本单位。知道了这一点，火车上太挤了之后，我就不会再挤进去而且浑然无觉。]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>王小波</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible]]></title>
    <url>%2F2017%2F12%2F26%2FAnsible%2F</url>
    <content type="text"><![CDATA[参考: Wikipedia Ansible docs: https://docs.ansible.com 环境: RHELx86_64 Ansible v2.7 介绍Ansible是一种通用语言，揭开了工作如何完成的神秘面纱。将棘手的任务变成可重复的剧本。只需按一下按钮即可推出企业级协议。为您的团队提供自动化，解决和共享的工具。 Automate Accelerate Collaborate Integrate 词汇表Glossary Action动作(action)是任务的一部分，用于指定要运行的模块和传递给该模块的参数。每个任务只能有一个动作，但也可能有其它参数。 Ad Hoc指使用/usr/bin/ansible运行Ansible执行一些快速命令，而不是编排语言，即/usr/bin/ansible-play-book。ad hoc命令的示例可能是重新启动基础结构中的50台计算机。你可以通过编写playbook来完成你可以做的任何事情，而playbook也可以将许多其它操作粘合在一起。 Async指配置为在后台运行而不是等待完成的任务。如果你的进程时间长度超过了SSH超时时间，那么以异步(async)模式启动该任务是有意义的。异步模式可以每隔很多秒轮询完成，或者可配置为’fire and forget’，在这种情况下，Ansible甚至不会再次检查任务，它将开始并继续进行未来的步骤。异步模式使用/usr/bin/ansible和/usr/bin/ansible-playbook。 Callback Plugin指一些用户编写的代码，可拦截Ansible的结构并对它们执行某些操作。GitHub中提供的一些示例执行自定义日志记录，发送电子邮件… Check Mode值运行带有--check选项的Ansible，它不会对远程系统进行任何更改，但仅输出在没有此标志的情况下运行时才有可能发生的更改。 Connection Plugin默认情况下，Ansible通过pluggable libraries与远程计算机通信。Ansible支持原生OpenSSH或称为paramiko的Python实现。如果您使用的是最新版本，则首选OpenSSH，并启用Kerberos和jump host等功能。还有其它连接类型，如accelerate模式，必须通过一种基于SSH的连接类型进行引导，但速度非常快，而本地模式则作用于本地系统。用户还可以编写自己的连接插件。 Conditionals条件是一个表达式，其计算结果为true或false，用于决定给定任务是否在给定计算机上执行。 Declarative实现使用最终状态描述的任务的方法，而不是实现该状态所需的步骤序列的描述。对于真实世界的栗子，任务的声明规范将是: “put me in California”。根据你当前的位置，前往加州的步骤顺序可能会有所不同，如果你已在加州，则根本不需要做任何事情。Ansible的资源是声明性的；它确定了实现最终状态所需的步骤。它还可让你知道是否需要采取任何步骤才能到达最终状态。 Diff Mode将--diff标志传递给Ansible，以显示支持它的模块。 ExecutorAnsible的核心软件组件，它是/usr/bin/ansible背后的力量——并且对应于剧本中每个任务的调用。 Facts事实是发现的有关远程节点的事情。通过在远程节点上执行内部设置模块来运行，Ansible会自动发现事实。 Filter Plugin这允许创建新的Jinja2过滤器，这只适用于知道Jinja2过滤器的人。 ForkAnsible并行地与远程节点通信，并且可通过传递--forks或编辑配置文件中的默认值来设置并行级别。 Gather Facts (Boolean)有时，当运行多重playbook时，如果不需要利用任何这些值，则希望有一些不打扰事实计算的playbook。 Globbing通配符是一种选择大量主机，或它们所在组的名称的方法 Group一组主机 Group Vars这是将提供给指定组的变量，尤其是复杂的数据结构，这样这些变量就不必嵌入到库存文件或playbook中。 Handlers处理程序就像Ansible playbook中的常规任务，但只有在任务包含notify指定并且还指示它已更改某些内容时才会运行。 Host主机是Ansible管理的远程机器。 Host SpecifierAnsible中的每个play都将一系列任务映射到一组系统。每个play中的hosts:指令通常称为主机说明符。它可以选择一个或多个系统，一个或多个组，甚至一个组中的一些主机，而不是另一个组中的主机。 Host Vars主机变量类似与组变量。 Idempotency如果执行一次的结果与在没有任何干预动作的情况下重复执行它的结果完全相同，则操作是幂等的。 Includesplaybook文件可以包括其它play list，任务列表可以外部化其它文件中的任务列表，类似于处理程序。 Inventory用于描述Ansible中的主机和组的文件。 Inventory Script一个程序，用于查找主机，主机的组关系以及外部资源的变量信息——无论是SQL数据库，CMDB方案，还是LDAP等。 Jinja2Jinja2是Ansible模板模块的首选语言。它是一种非常简单的Python模板语言，可读且易于编写。 JSONAnsible使用JSON从远程模块返回数据。这允许用任何语言编写。 Lazy Evaluation通常，Ansible会在最后一秒评估playbook内容中的任何变量。 LibraryAnsible的模块集合。 Limit Groups通过将--limit somegroup传递给Ansible或ansible-playbook可以限制主机的子集。 Local Action针对远程计算机的playbook中的本地活动指令意味着给定的步骤实际上将在本地计算机上发生，但是可以传入变量以引用该步骤中引用的远程主机名。 Local Connection通过在playbook中使用connection: local，或将-c local传递给/usr/bin/ansible，这表明我们正在管理本地主机而不是远程主机。 Lookup Plugin查找插件是一种从外部获取数据到Ansible的方法。 Loops通常，Ansible不是一种编程语言。它更喜欢声明性，尽管循环这样的各种结构允许对列表中的多个项重复特定任务。 Modules模块是Ansible发送到远程机器的工作单元。 Multi-TierIT系统不是一次管理一个系统的概念，而是通过明确定义的订单中多个系统和系统组之间的交互。 Notify任务注册更改事件并通知处理程序任务需要在play结束时运行另一个操作的行为。 Orchestration许多软件自动化系统使用这个词来表示不同的东西。Ansible使用它作为编排的指挥。 paramiko默认情况下，Ansible通过SSH管理机器。Ansible默认使用的库是一个名为paramiko的Python驱动库。 Playbooksplaybook是Ansible编排，配置，管理或部署系统的语言。它被称为剧本，部分原因在于它是一种运动类比，并且使用它们应该很有趣。 PlaysA playbook is a list of plays。剧本最小是由主机说明符选择的一组主机之间的映射，以及在这些主机上运行定义这些系统将执行的角色的任务。 Pull Mode默认情况下，Ansible以push模式运行，这使得它可以在与每个系统进行通信时进行非常精细的控制。当你希望在特定计划时间点检查节点时，可以使用pull模式。 Push Mode Register Variable在Ansible中运行任何任务的结果可以存储在变量中，以便在模板或条件语句中使用。 Resource ModelAnsible模块在资源方面起作用。 Roles角色是Ansible的组织单位。 Rolling Update一次解决组中的多个节点的行为，以避免一次更新所有节点并使系统脱机。 Sudo SSH (Native) TagsAnsible允许使用任意关键字标记剧本中的资源，然后仅运行与这些关键字对应的剧本部分。 Task任务将操作(模块及其参数)与名称和可选的其他关键字(如循环指令)组合在一起。 TemplatesAnsible可以轻松地将文件传输到远程系统，但通常需要在其它文件中替换变量。 TransportAnsible使用term:连接插件来定以可用传输的类型。 When一个可选的条件语句。 Vars (Variables)与事实相反，变量是值的名称(int, bool, string)或复杂的数据(dict, hash, lists)。它是声明的东西，而不是从远程系统获取的东西。 YAMLAnsible不想强迫人们编写程序代码来自动化基础设施，因此使用YAML来定义剧本配置语言和变量文件。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
        <tag>Automation</tag>
        <tag>DevOps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SaltStack]]></title>
    <url>%2F2017%2F12%2F25%2FSaltStack%2F</url>
    <content type="text"><![CDATA[参考： SaltStack官网：https://saltstack.com SaltStack文档：https://docs.saltstack.com/en/latest/topics SaltStack-GitHub：https://github.com/saltstack Salt-repo：https://repo.saltstack.com/ Salt TOC: https://docs.saltstack.com/en/latest/contents.html Salt Modules: https://docs.saltstack.com/en/latest/salt-modindex.html Salt Index: https://docs.saltstack.com/en/latest/genindex.html 环境： CentOS7_x64; Salt-2018.02 说明SaltStack是一种革命性的用速度(speed)取代复杂性(complexity)的基础设施(infrastucture)管理方法。 简单(Simple)，可以在几分钟内运行； 可伸缩性(Scalable)，足以管理数以万计的Server； 快速(Fast)，能在几秒内与各系统间进行通信。 You’ll learn how to: 安装和配置SaltStack； 在所有托管系统上远程执行命令(Remotely execute commands)； 设计、开发和部署系统配置； 使用Salt Reactor是基础设施自动化(automate)； 使用Salt Orchestration协调复杂管理操作。 Salt是建立在动态通信总线(dynamic communication bus)上的基础设施管理的一种新方法。Salt可以用于数据驱动(data-driven)业务，远程执行(remote execution)任何基础设施，配置管理(configuration management)任意应用堆栈… REMOTE EXECUTION; CONFIGURATION MANAGEMENT; EVENT-DRIVEN INFRASTRUCTURE; SALT ESSENTIALS. 词汇表GLOSSARY Auto-Order: 按照在SLS文件中定义的顺序评估状态 Bootstrap: 下载和安装Salt的一个项目 Compound Matcher: 可以与布尔运算符组合的许多目标定义的组合 EAuth: 外部认证(external authentication)的简写 Environment: 包含可应用于minions的状态文件的目录树 Execution Function: 执行模块中的Python函数，可以接受参数并执行特定的系统管理任务 Execution Module: 包含执行功能的Python模块，可直接在服务器上执行各种系统管理任务。 Salt附带了许多执行模块，但用户也可以编写自己的执行模块来执行专门的任务 External Job Cache: 外部数据存储，可以存档有关已运行作业的信息 External Pillar: 一个接受任意参数并返回字典的模块 Event: 发送到事件总线的通知 File Server: 用于存储Salt特定文件的本地或远程位置 Grain: 包含系统信息的键值对 Highdata: SLS文件中的数据结构表示一组状态声明 Highstate: 要应用于系统的状态集合 Idempotent：在应用操作之前，无论系统状态如何，都确保系统处于已知状态的操作 Jinja: 一种模板语言，允许变量和简单逻辑在呈现时动态插入到静态文本文件中 Job: Salt命令要执行的完整任务集是单个作业 Job Cache: 作业结果的存储位置，然后可由salt runner或外部系统查询 Job ID: 作业的唯一标识符 Low State: 评估requirements和order的已处理状态的集合 Master: salt daemon，可向minions发出命令 Masterless: 不需要Salt Master操作的minion，所有配置都是本地的 Master Tops: 允许hook进入外部系统以生成顶级文件数据的系统 Mine: 从minion收集任意数据并将数据存储在master上。这些数据可供其它 minions 使用 Minion: Salt Minion daemon Minion ID: minion的全局标识符 Multi-Master: 在高可用环境下，minion可以同时主动连接到多个Salt Master Node Group: 为minion进行逻辑分组 Outputter: 定义Salt命令的输出数据格式的程序 Peer Communication: minion与minion直接进行沟通，而不通过salt master Pillar: 为使用者提供用户定义的数据的键值对，通常用于存储敏感数据并将其分发给minion Proxy Minion: 可控制无法再本地运行salt minion的minion PyDSL: 用作Salt渲染器的Pythonic域特定语言 Reactor: 一个接口，用于侦听事件和定义Salt在收到给定事件时应采取的操作 Render Pipe: 将给定数据格式(yaml/json…)转换为可由salt使用的Python数据结构 Returner: 允许将Salt命令的结果发送到给定的数据存储（例如数据库或日志文件）以进行存档 Roster: 目标主机的文件列表 Runner Module: 包含一组runner功能的模块 Runner Function: 由salt-run命令调用并在master上(not minion)执行的函数 Salt Cloud: 用于托管的云环境 Salt SSH: 配置管理和远程编排系统，只需要SSH Salt Thin: 是salt发行版的一个子集，不包含任何传输例程 Salt Virt: 用于管理虚拟机在一组主机上的创建和部署。通常用于创建和部署私有云 SLS Module: 包含一组状态声明 State Compiler: 将highdata转换为lowdata State Declaration: 一种数据结构，包含唯一ID并描述系统的一个或多个状态 State Function: 包含在状态模块内的函数，该函数可以管理特定状态对系统的应用 State Module: 包含一组状态函数的模块 State Run: 在一组系统上应用一组状态 Syndic: 一个转发器，可以在分层主服务器之间中继消息 Target: 将要应用给定salt命令的minion Top File: 确定应将哪些SLS文件应用于各种系统，并将这些系统组织到环境中 virtual: 模块负载上调用的模块中的函数，用于确定模块是否应该对minion可用 Worker: 一个Master process， 可以发送通知并接收来自minion的回复 介绍INTRODUCTION TO SALT We’re not just talking about NaCl. 30s摘要 Salt是： 配置管理系统，能够将远程节点维护在已定义的状态 分布式远程执行系统，用于在远程节点上单独或通过任意选择标准执行命令和查询数据 它的开发是为了将远程执行领域中发现的最佳解决方案结合在一起，使其更好，更快，更具可塑性。Salt通过简单易用的界面快速处理大量信息，而不仅仅是数十个甚至数千个单独的服务器。 简单理解 在大规模部署和较小系统之间提供多功能性似乎令人生畏，但无论项目规模如何，Salt的设置和维护都非常简单。Salt的体系结构旨在与任意数量的服务器协同工作，从少数本地网络系统到跨不同数据中心的国际部署。拓扑结构是一个简单的C/S模型，其中所需的功能内置于一组守护进程中。虽然默认配置几乎不需要修改，但可以对Salt进行微调以满足特定需求。 并行执行(PARALLEL EXECUTION) Salt的核心功能: 使命令能够并行而不是串行地调用远程系统 使用安全和加密的协议 尽可能使用最小和最快的网络负载 Salt还为远程执行领域引入了更精细的控件，允许系统不仅可以通过主机名进行定位，还可以通过系统属性进行定位。 建立在经过验证的技术上 Salt使用了许多技术： 网络层使用优秀的 ZeroMQ 网络库构建，因此Salt守护程序包含一个可行且透明的AMQ代理。 使用公钥对Master Daemon进行身份验证，然后使用更快的AES加密进行负载通信。身份验证和加密是Salt的组成部分。 利用 msgpack 的通信功能，实现快速，轻便的网络流量。 Python客户端接口 为了允许简单的扩展，Salt执行例程可以编写为普通的Python模块。从Salt执行中收集的数据可以发送回Master或任意程序。可从简单的Python API或CLI调用Salt，这样Salt可用于执行一次性(one-off)命令以及作为更大应用程序的组成部分。 快速、灵活、可扩展 结果是一个系统可以在从一个服务器到很多服务器的目标服务器组上高速执行命令。Salt非常快速，易于设置，具有惊人的可塑性，并提供单一的远程执行架构，可以管理任意数量服务器的各种需求。Salt基础设施汇集了最佳的远程执行世界，扩大了其功能并扩展了其范围，从而使系统具有实用性，适用于任何网络。 开放 Salt是在Apache License 下开发的，可用于开放和专有项目。请将您的扩展提交回Salt项目，以便我们可以随着Salt的发展一起受益。 社区 加入Salt，有很多方法可参与Salt社区并进行沟通。Salt有一个活跃的IRC频道和邮件列表。 GitHub Salt: https://github.com/saltstack/salt Blog Salt Blogs: https://www.saltstack.com/blog/ SALT STATES salt-states 官方库: https://github.com/saltstack/salt-states 安装Installation 如果是第一次设置环境，你应该在专用的管理服务器上安装Salt master，然后在每个使用Salt管理的系统上安装Salt minion。现在不需要担心你的系统架构(architecture)，你可以在以后轻易添加组件(componet)和修改配置(configuration)而不需要重新安装任何东西。 The general installation process is as follows: 安装Salt master，通过各平台说明安装或通过Salt bootstrap.sh脚本来安装； 确保你的Salt minion能够找到Salt master； 在想要管理的每个系统上安装Salt minion； 在Salt minion连接后接受Salt minion key。 在此之后，就可以运行一个简单命令，并从所有的Salt minion接收返回。 1234#salt &lt;minion-id&gt; &lt;cmd&gt;salt minion1 test.pingsalt * test.ping 快速安装Quick install 在绝大多数发行版本上，可以使用Salt Bootstrap脚本进行快速安装。 参考：Salt Bootstrap 1234567#wgetwget https://bootstrap.saltstack.com -O bootstrap-salt.shsh bootstrap-salt.sh#curlcurl -o bootstrap-salt.sh -L https://bootstrap.saltstack.comsh bootstrap-salt.sh 指定平台Platform-Specific Installation 选择发行版本安装 CentOS7repo: https://repo.saltstack.com/#rhel 1. 下载SaltStack-Repository进行安装： systemd和systemd-python是Salt必须的，在安装Salt前需装好。 12345678910111213#安装salt-repoyum install -y https://repo.saltstack.com/yum/redhat/salt-repo-latest-2.el7.noarch.rpmyum clean expire-cache#安装salt组件yum install -y salt-master salt-minion salt-ssh salt-syndic salt-cloud salt-api#开启systemctl start salt-master 2. 自建salt-repo： 123456789vim /etc/yum.repos.d/saltstack.repo[saltstack-repo]name=SaltStack repo for Cent0S7baseurl=https://repo.saltstack.com/yum/redhat/$releasever/$basearch/latestenalbed=1gpgcheck=1gpgkey=https://repo.saltstack.com/yum/redhat/$releasever/$basearch/latest/SALTSTACK-GPG-KEY.pub 初始化Initial Configuration 配置saltConfiguration Salt salt-master 的默认配置会为安装而工作，唯一要求是在salt-minion的配置文件中设置salt-master的位置。 salt-master默认的，salt-master配置文件位于/etc/salt/master，在all interfaces(0.0.0.0)上监听4505和4506端口。 123vim /etc/salt/masterinterface: 0.0.0.0 salt-minion默认，一个salt-minion会尝试连接到DNS名称为salt。如果salt-minion能够正确解析(resolve)这个名称，则可以不需要配置文件。如果DNS名称salt未能解析为salt-master的正确位置，那么可在/etc/salt/minion配置文件下重新定义salt。 1234567vim /etc/salt/minion#master: salt#如果是默认的salt,需要在本地hosts下解析salt#此处我们修改为salt-master的IP地址master: 192.168.1.9 修改配置文件后，请重启服务。 minion代理配置PROXY MINION CONFIGURATION A Proxy Minion模仿一个规律的行为和继承(inherit)他们的选项。类似地，它的配置文件存放于/etc/salt/proxy，proxy也将尝试连接DNS名为salt的主机。 除了salt-minion有规律的选型，proxy还有一些特定的选项。参考:Proxy minion 运行Salt以salt命令运行: 1234567891011121314151617salt-master#开启守护进程salt-master -d#systemdsystemctl start salt-mastersalt-minionsalt-minion -dsystemctl start salt-minion#日志信息salt-master --log-level=debug 以non-root运行salt 确保此用户有相应的权限； 可能需要修改相应目录的权限： /etc/salt /var/cache/salt /var/log/salt /var/run/salt 密钥识别Key Identity 在initial key交换之前，Salt会提供命令来验证(validate)salt-master和salt-minion的身份。验证身份有助于避免疏忽地连接到错误的salt-master，并且在建立初始化连接的阻止MiTM攻击。 Master Key Fingerprint复制master.pub的值，并将其作为salt-minion配置文件/etc/salt/minion中master_finger的值。 1234567891011121314#salt-key is used to manage Salt authentication keys#查看master的keysalt-key -F masterLocal Keys:master.pem: 60:87:25:6a:68:28:4a:bf:5e:87:ee:4f:3f:46:d4:8e:38:8b:58:d9:8a:f4:44:b6:64:67:d9:da:0f:5d:f3:b4master.pub: 46:52:c1:36:f2:6f:33:c0:72:a1:18:5e:99:36:04:ea:1a:9b:ea:e7:61:3b:d9:30:34:c1:f1:3b:65:08:f8:42#将公钥写入salt-minion配置文件#查看minion的finger#salt-key --finger &lt;minion_id&gt;salt-key --finger '192.168.1.7' Minion Key Fingerprint 123456#salt-call is used to execute module functions locally on a Salt Minion#查看minion key fingerprint#可在master上查看，比对两者是否相同salt-call --local key.finger 密钥管理Key Management Salt使用AES Encryption加密salt-master与salt-minion间的所有通信。这确保了发送到Minion的命令不会被篡改(tamper)，并保证了master与minion间是认证的和受信任的。 当命令发送到salt-minion之前，salt-minion的key必须要被salt-master所接受。 12#列出salt-master上已知的keyssalt-key -L 其中包含四项: Accepted Keys: Denied Keys: Unaccepted keys: Rejected keys: 让salt-master接收key，并允许salt-minion被salt-master控制 1234#-a 192.168.1.7, --accept=192.168.1.7#-A, --accept-allsalt-key -A 发送命令Sending Commands salt-master和salt-minion之间通过运行test.ping命令来证实(verified)。 123salt 192.168.1.7 test.pingsalt * test.ping 其它安装指南Additional Installation Guides Salt BootstrapSalt Bootstrap脚本允许用户在各种系统和版本上安装salt-minion和salt-master。shell脚本为bootstrap-salt.sh，运行一系列的检查来确定操作系统的类型和版本，然后通过适当的方法安装salt二进制文件。salt-bootstrap脚本安装运行salt的最小化安装包，如Git便不会安装。 Salt Bootstrap’s GitHub: https://github.com/saltstack/salt-bootstrap 栗子Satl Bootstrap脚本有多种可以传递的选项，以及获取引导脚本本身的方法。 1. 使用curl 12curl -o bootstrap-salt.sh -L https://bootstrap.saltstack.comsh bootstrap-salt.sh git develop 2. 使用wget 12wget -O bootstrap-salt.sh https://bootstrap.saltstack.comsh bootstrap-salt.sh 3. An Insecure one-liner 12345curl -L https://bootstrap.saltstack.com | shwget -O - https://bootstrap.saltstack.com | shcurl -L https://bootstrap.saltstack.com | sh -s -- git develop 4. cmd line options 12#查看帮助sh bootstrap-salt.sh -h 防火墙salt-master和salt-minion间的通信使用AES加密的ZeroMQ，它使用TCP的4505和4506端口，仅需要在salt-master上可访问就行。 下面概述了关于salt-master的防火墙规则： RHEL7/CENTOS7 12firewall-cmd --permanent --zone=&lt;zone&gt; --add-port=4505-4506/tcpfirewall-cmd --reload Preseed minion with accepted key某些情况下，在salt-master上接受minion-key之前等待salt-minion启动是不方便的。比如，你可能希望minion一上线(online)就引导。 有多种方式生成minion-key，下面是一般生成minion-key的四个步骤： 在master上生成key： 12#请给key取个名字salt-key --gen-keys=[key_name] 把公钥(publick key)添加到已接受的minion文件夹中: 公钥文件和 minion_id 有相同的名字是很有必要的，这就是Salt如何通过key与minions匹配。还有，由于不同操作系统或特定的master配置文件，pki 文件夹可能位于不同的位置。 1cp &lt;key_name&gt;.pub /etc/salt/pkimaster/minions/&lt;minion_id&gt; 分配minion-key： 对于minion来说，没有单一方法去得到密钥对，难点是找到一种安全的分配方法。 由于master已经接受了minion-key，因此分发私钥(private key)会有潜在的安全风险。 配置带key的minion： 你可能希望在启动salt-miniont daemon之前取得minion-key的位置。 12/etc/salt/pki/minion/minion.pem/etc/salt/pki/minion/minion.pub 以普通用户运行rootRunning salt as normal user tutorial 以普通用户(non-root)运行salt function 如果你不想使用root用户安装或运行salt，你可以在你的工作目录中创建一个虚拟根目录(virtual root dir)来配置它。salt system使用salt.syspathmodule来查找变量。 如果你运行salt-build，它会生成在: ./build/lib.linux-x86_64-2.7/salt/_syspaths.py； 运行python setup.py build命令来生成它； 复制生成的module到你的salt dir，cp ./build/lib.linux-x86_64-2.7/salt/_syspaths.py ./salt/_syspaths.py 修改它，并加入需要的变量和新路径： 1234567891011121314151617# you need to edit thisROOT_DIR = *your current dir* + '/salt/root'# you need to edit thisINSTALL_DIR = *location of source code*CONFIG_DIR = ROOT_DIR + '/etc/salt'CACHE_DIR = ROOT_DIR + '/var/cache/salt'SOCK_DIR = ROOT_DIR + '/var/run/salt'SRV_ROOT_DIR= ROOT_DIR + '/srv'BASE_FILE_ROOTS_DIR = ROOT_DIR + '/srv/salt'BASE_PILLAR_ROOTS_DIR = ROOT_DIR + '/srv/pillar'BASE_MASTER_ROOTS_DIR = ROOT_DIR + '/srv/salt-master'LOGS_DIR = ROOT_DIR + '/var/log/salt'PIDFILE_DIR = ROOT_DIR + '/var/run'CLOUD_DIR = INSTALL_DIR + '/cloud'BOOTSTRAP = CLOUD_DIR + '/deploy/bootstrap-salt.sh' 创建目录结构： 12mkdir -p root/etc/salt root/var/cache/run root/run/salt root/srvroot/srv/salt root/srv/pillar root/srv/salt-master root/var/log/salt root/var/run 填充配置文件： 123456cp -r conf/* /etc/salt/vi /etc/salt/masteruser: *your user name* 运行： 1PYTHONPATH=`pwd` scripts/salt-cloud minion独立运行Standalone minion 因为salt-minion包含了如此广泛的功能，它可以独立运行。一个独立的minion可以用来做很多事情: 在没有连接到master的系统上使用salt-call命令； 无主状态(masterless states)。 当以无主模式运行salt时，不要运行salt-minion daemon。否则，它将尝试连接到master并失败。salt-call命令是独立的，不需要salt-minion daemon。 minion配置有几个参考方法来设置不同的选项来配置masterless minion，salt-minion很容易通过配置文件(默认位于:/etc/salt/minion)进行配置。 告诉salt运行masterless salt-call命令用于在salt-minion本地运行模块功能，而不是在salt-master执行他们。通常，salt-call命令检查主机检索文件服务器和支柱数据，当时当运行standalone salt-call时，需要指示不要检查master的这些数据。为了指示minion不要查找master，需要在运行salt-call时设置file_client配置选项。默认情况下，file_client被设置为remote让minion知道将从master中收集文件服务器和支柱数据。当设置file_client为local时，minion将不会从master收集这些数据。 1234file_client: local#这样，salt-call命令将不会查找master#并认为本地系统拥有所有的文件文支柱资源 masterless运行状态 the state system在所有需要的文件都在minion本地，轻易地在没有salt-master的情况下运行。为了达到此效果，需要配置minion配置文件，以了解如何像master一样返回file_roots信息。 123file_roots: base: - /srv/salt 现在设置salt state tree, top file和SLS modules，就像在master上设置它们一样。将file_client设置为local，并且一个可用的state tree会调用state module中的function，将使用minion上的file_roots中的信息而不是master。 当在一个minion上创建一个state tree时，不需要语法或路径的更改。master上的SLS modules不需要进行任何修改就可以与minion一起工作。这就使得salt scrit不需要设置一个master就能轻易部署，并允许这些SLS modules随着部署发展而容易转移到master。 123456#以声明的状态可以执行salt-call state.apply#无需修改配置文件salt-call state.apply --local Salt无主模式Salt masterless quickstart 运行一个无主模式的minion可以允许你在单一主机上使用salt配置管理，而不用在另一台主机上调用master。在无主模式下运行salt时，请勿运行salt daemon。否则，它将尝试连接到master并失败。salt-call命令时独立的 bootstrap salt minion 12curl -L https://bootstrap.saltstack.com -o bootstrap_salt.shsudo sh bootstrap_salt.sh 告诉salt运行masterless模式在minion配置文件中配置此，表示不去寻找master，并假设本地系统拥有所有文件和资源。 123vim /etc/salt/minionfile_client: local 创建状态树(state tree) 创建top.sls文件 12345vim /srv/salt/top.slsbase: &apos;*&apos;: - webserver 创建webserver状态树 123456vim /srv/salt/webserver.sls#这是基于Debianapache: # ID declaration pkg: # state declaration - installed # function declaration salt-callsalt-call命令在minion本地运行远程执行功能，而不是在master执行。 1234#--local,在本地文件系统查找状态树salt-call --local state.apply#minion首先检查top.sls，然后应用webserver.sls 配置Configuring Salt 本节介绍如何配置用户访问，查看，存储作业结果，安全，疑难解答以及如何执行其它管理任务。 masterCONFIGURING THE SALT MASTER master config: https://docs.saltstack.com/en/latest/ref/configuration/master.html salt系统的两个组件都有相应的配置文件: /etc/salt/master /etc/salt/minion master配置项PRIMARY MASTER CONFIGURATION 基础配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339#INTERFACE，默认值0.0.0.0interface: 0.0.0.0#IPv6，默认值Falseipv6: False#PUBLISH_PORT，默认值4505publish_port: 4505#MASTER_ID，默认值Nonemaster_id: Master#USER，默认值rootuser: root#ENALBE_SSH_MINIONS，默认值Falseenable_ssh_minions: True#RET_PORT，默认值4506#接收命令执行返回的端口ret_prot: 4506#PIDFILE，默认值/var/run/salt-master.pidpidfile: /var/run/salt-master.pid#ROOT_DIR，默认值/root_dir: /#CONF_FILE，默认值/etc/salt/masterconf_file: /etc/salt/master#PKI_DIR，默认值/etc/salt/pki/master#存储pki认证密钥的目录pki_dir: /etc/salt/pki/master#EXTENSION_MODULES，默认值/var/cache/salt/master/extmodsextension_modules: /root/salt_extmods#EXTMOD_WHITELIST/EXTMOD_BLACKLIST#有效的选项: modules, states, grains, renderers, returners, output, proxy, runners,#wheel, engines, queues, utils, pillar, sdb, cache, clouds, tops, roster, tokensextmod_whitelist: modules: - custom_module engines: - custom_engine pillars: []extmod_blacklist: modules: - specific_module#MODULE_DIRS，默认值[]module_dirs: - /var/cache/salt/minion/extmods#CACHEDIR，默认值/var/cache/salt/mastercachedir: /var/cache/salt/master#VERIFY_ENV，默认值True#在启动时验证并设置目录权限verify_env: True#KEEP_JOBS，默认值24#设置保留旧作业信息的小时数，0表示禁用缓存清理keep_jobs: 24#GATHER_JOB_TIMEOUT，默认10#客户端请求正在运行的作业信息是等待的秒数gather_job_timeout: 10#TIMEOUT，默认值5#salt命令和api默认超时值timeout: 5#LOOP_INTERVAL，默认值60#维护过程检查周期的秒数loop_interval: 60#OUTPUT，默认值nested#设置命令使用的默认输出器output: nested#OUTPUTTER_DIRS，默认值[]#salt输出器附加目录列表outputter_dirs: []#OUTPUT_FILE，默认值None#salt命令使用的默认输出文件output_file: /path/output/file#SHOW_TIMEOUT，默认值True#告诉client已超时的minionshow_timeout: True#SHOW_JID，默认值False#告诉client在工作发布时显示jidshow_jid: False#COLOR，默认值True#彩色输出color: False#COLOR_THEME，默认值&quot;&quot;color_theme: /etc/salt/color_theme#CLI_SUMMARY，默认False#显示目标minion数量的摘要cli_summary: False#SOCK_DIR#Default: /var/run/salt/master#创建Unix socket的位置sock_dir: /var/run/salt/master#ENABLE_GPU_GRAINS#Default: True#启用GPU硬件数据#JOB_CACHE#Default: True#维护一个临时作业缓存job_cache: True#MINION_DATA_CACHE#Default: True#存储在master端的minion数据缓存minion_data_cache: True#CACHE#Default: localfs#缓存子系统模块用于minion数据缓存cache: consul#MEMCACHE_EXPIRE_SECONDS#Default: 0，禁用#内存缓存数据过期时间memcache_expire_seconds: 30#MEMCACHE_MAX_ITEMS#Default: 1024#缓存项限制memcache_max_items: 1024#MEMCACHE_FULL_CLEANUP#Default: False#如果缓存已满(超过max_literms)，则项目将清除其存储memcache_full_cleanup: True#MEMCACHE_DEBUG#Default: False#收集缓存统计信息并记入调试日志级别memcache_debug: True#EXT_JOB_CACHE#Default: &apos;&apos;#指定所有minion的默认returnerext_job_cache: redis#EVENT_RETURN#Default: &apos;&apos;#指定用于记录时间的returnerevent_return: - syslog - splunk#EVENT_RETURN_QUEUE#Default: 0#在繁忙的系统上，启用event_returns可能会给存储系统造成相当大的负载。事件可以在master使用队列排队，并以批处理方式使用单个事务存储多个事件event_return_queue: 0#EVENT_RETURN_WHITELIST#Default: []event_return_whitelist: - salt/master/a_tag - salt/run/*/ret#EVENT_RETURN_BLACKLIST#Default: []event_return_blacklist: - salt/master/not_this_tag - salt/wheel/*/ret#MAX_EVENT_SIZE#Default: 1048576，单位为Byte#传递非常大的事件可能导致minion消耗大量的内存max_event_size: 1048576#PING_ON_ROTATE#Default: False#告知master在AES密钥刷新后立即ping所有minionping_on_rotate: False#MASTER_JOB_CACHE#Default: local_cachemaster_job_cache: redis#ENFORCE_MINE_CACHE#Default: Falseenforce_mine_cache: False#MAX_MINIONS#Default: 0，表示不限制#master允许连接的最大minion数max_minions: 100#CON_CACHE#Default: False#为所有连接提供缓存con_cache: True#PRESENCE_EVENTS#Default: False#master周期性地寻找主动连接的minion#PING_ON_ROTATE，默认False#默认情况下，master AES key每24h轮换一次#要告诉master在AES key刷新后立即Ping所有minions，请设置为True。但这样可能在刷新后立即导致Master的高负载，因为它管理着大量的minion，请注意#如果禁用，建议使用密钥标记监听`aes_key_rotate`ping_on_rotate: False#TRANSPORT#Default: zeromq#修改底层传输层，支持的值有zeromq, raet, tcptransport: zeromq#TRANSPORT_OPTS#Default: &#123;&#125;#启用多个传输transport_opts: tcp: publish_port: 4605 ret_port: 4606 zeromq: []#MASTER_STATS#Default: False#Master统计信息#MASTER_STATS_EVENT_ITER#Default: 60#SOCK_POOL_SIZE#Default: 1#为了避免将数据写入套接字时阻塞等待，启用salt应用程序的套接字池sock_pool_size: 15#IPC_MODE#Default: ipc#windows default: tcpipc_mode: ipc#TCP_MASTER_PUB_PORT#Default: 4512#ipc_mode的tcp端口tcp_master_pub_port: 4512#TCP_MASTER_PULL_PORT#Default: 4513#ipc_mode的tcp端口tcp_master_pull_port: 4513#TCP_MASTER_PUBLISH_PULL#Default: 4514tcp_master_publish_pull: 4514#TCP_MASTER_WORKERS#Default: 4515# mworkers连接到master的端口tcp_master_workers: 4515#AUTH_EVENTS#Default: Trueauth_events: True#MINION_DATA_CACHE_EVENTS#Default: Trueminion_data_cache_events: True salt-sshSALT-SSH CONFIGURATION 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104#ROSTER#Default: flat#定义默认ROSTER模块roster: cache#ROSTER_DEFAULTS#所有rosters都能继承的设置roster_defaults: user: daniel sudo: True priv: /root/.ssh/id_rsa tty: True#ROSTER_FILE#Default: /etc/salt/rosterroster_file: /root/roster#ROSTERS#Default: None#定义roster的位置，以便在使用salt api时选择他们rosters: - /etc/salt/roster.d - /opt/salt/some/more/rosters#SSH_PASSWD#Default: ''#用于登录的ssh密码ssh_passwd: abc@123#SSH_PORT#Default: 22#目标系统的ssh端口ssh_port: 22#SSH_SCAN_PORTS#Default: 22#多个值以逗号(,)分隔ssh_scan_ports: 22#SSH_SCAN_TIMEOUT#Default: 0.01ssh_scan_timeout: 0.01#SSH_SUDO#Default: Falsessh_sudo: False#SSH_TIMEOUT#Default: 60ssh_timeout: 60#SSH_USER#Default: rootssh_user: root#SSH_LOG_FILE#Default: /var/log/salt/ssh#salt-ssh命令的日志文件ssh_log_file: /var/log/salt/ssh#SSH_MINION_OPTS#Default: Nonessh_minion_opts: gpg_keydir: /root/gpg#SSH_USE_HOME_KEY#Default: False#使用~/.ssh/id_rsa对salt-ssh身份验证ssh_use_home_key: False#SSH_IDENTITIES_ONLY#Default: False#设置为True表示为salt-ssh -o IdentitiesOnly=yesssh_identities_only: False#SSH_LIST_NODEGROUPS#Default: &#123;&#125;ssh_list_nodegroups: groupA: minion1,minion2 groupB: minion1,minion3#THIN_EXTRA_MODS#Default: None#包含在salt thin中的附加模块#MIN_EXTRA_MODS#Default: None 安全配置MASTER SECURITY SETTINGS 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157#OPEN_MODE#Default: False#open mode关闭认证并通知master接受所有身份认证open_mode: False#AUTO_ACCEPT#Default: False#自动接收所有来自minion的public keyauto_accept: False#KEYSIZE#Default: 2048#创建新Key时生成的Key大小keysize: 2048#AUTOSIGN_TIMEOUT#Default: 120#AUTOSIGN_FILE#Default: not defined#此文件中指定的传入key将自动被接受#AUTOREJECT_FILE#Default: not defined#此文件中指定的传入key将自动被拒绝#AUTOSIGN_GRAINS_DIR#Default: not definedautosign_grains_dir: /etc/salt/autosign_grains#PERMISSIVE_PKI_ACCESS#Default: Falsepermissive_pki_access: False#PUBLISHER_ACL#Default: &#123;&#125;#允许master上用户执行特定模块publisher_acl: fred: - test.ping - pkg.*#PUBLISHER_ACL_BLACKLIST#Default: &#123;&#125;publisher_acl_blacklist: users: - root - '^(?!sudo_).*$' # all non sudo users modules: - cmd.* - test.echo#SUDO_ACL#Default: Falsesudo_acl: False#EXTERNAL_AUTH#Default: &#123;&#125;external_auth: pam: fred: - test.*#TOKEN_EXPIRE#Default: 43200(12h)token_expire: 43200#TOKEN_EXPIRE_USER_OVERRIDE#Default: Falsetoken_expire_user_override: pam: - fred - tom ldap: - gary#KEEP_ACL_IN_TOKEN#Default: Falsekeep_acl_in_token: False#EAUTH_ACL_MODULE#Default: ''eauth_acl_module: django#FILE_RECV#Default: False#允许minion将文件推送给masterfile_recv: False#FILE_RECV_MAX_SIZE#Default: 100file_recv_max_size: 100#MASTER_SIGN_PUBKEY#Default: False#使用master公钥的加密签名来签署master认证回复master_sign_pubkey: True#MASTER_SIGN_KEY_NAME#Default: master_sign#自定义签名密钥的名称master_sign_key_name: &lt;filename_without_suffix&gt;#MASTER_PUBKEY_SIGNATURE#Default: master_pubkey_signaturemaster_pubkey_signature: &lt;filename&gt;#MASTER_USE_PUBKEY_SIGNATURE#Default: Falsemaster_use_pubkey_signature: True#ROTATE_AES_KEY#Default: True#当salt-key删除一个minion-public时，轮询salt-master的AES-keyrotate_aes_key: True#PUBLISH_SESSION#Default: 86400#master上AES key轮询之间的秒数publish_session: Default: 86400#SSL#Default: None#TLS/SSL连接项ssl: keyfile: &lt;path_to_keyfile&gt; certfile: &lt;path_to_certfile&gt; ssl_version: PROTOCOL_TLSv1_2#ALLOW_MINION_KEY_REVOKE#Default: False#默认情况下，当minion key被移除时，master会删除它的缓存数据 大规模调整设置MASTER LARGE SCALE TUNING SETTINGS 12345678910111213141516171819202122232425#MAX_OPEN_FILES#Default: 100000#请注意ulimitmax_open_files: 100000#WORKER_THREADS#Default: 5worker_threads: 5#PUB_HWM#Default: 1000pub_hwm: 1000#ZMQ_BACKLOG#Default: 1000#zeromq backlog的监听队列大小zmq_backlog: 1000#SALT_EVENT_PUB_HWM AND EVENT_PUBLISHER_PUB_HWMsalt_event_pub_hwm: 20000event_publisher_pub_hwm: 10000 模块管理MASTER MODULE MANAGEMENT 123456789101112131415#RUNNER_DIRS#Default: []runner_dirs: - /var/lib/salt/runners#UTILS_DIRS#Default: []utils_dirs: - /var/lib/salt/utils#CYTHON_ENABLE#Default: Falsecython_enable: False 系统状态设置MASTER STATE SYSTEM SETTINGS 123456789101112131415161718192021#STATE_TOP#Default: top.slsstate_top: top.sls#STATE_TOP_SALTENV#无默认值state_top_saltenv: dev#TOP_FILE_MERGING_STRATEGY#Default: mergetop_file_merging_strategy: same#ENV_ORDER#Default: []env_order: - base - dev - qa 文件服务器设置MASTER FILE SERVER SETTINGS 12 本地文件服务器ROOTS: MASTER’S LOCAL FILE SERVER 12 git远程文件服务器后端GITFS: GIT REMOTE FILE SERVER BACKEND 12 gitfs认证项GITFS AUTHENTICATION OPTIONS 12 hgfs远程文件服务器后端HGFS: MERCURIAL REMOTE FILE SERVER BACKEND 12 svnfs远程文件服务器后端SVNFS: SUBVERSION REMOTE FILE SERVER BACKEND 12 minions远程文件服务器后端MINIONFS: MINIONFS REMOTE FILE SERVER BACKEND 12 azurefs文件服务器后端AZUREFS: AZURE FILE SERVER BACKEND S3文件服务器后端S3FS: S3 FILE SERVER BACKEND pillar配置PILLAR CONFIGURATION 12 reactor设置MASTER REACTOR SETTINGS salt-api设置SALT-API MASTER SETTINGS syndic服务器SYNDIC SERVER SETTINGS peer publishPEER PUBLISH SETTINGS 日志MASTER LOGGING SETTINGS 1234567891011121314151617181920212223242526272829303132333435363738#LOG_FILE#Default: /var/log/salt/masterlog_file: /var/log/salt/master#LOG_LEVEL#Default: warninglog_level: notice#LOG_LEVEL_LOGFILE#Default: warninglog_level_logfile: warning#LOG_DATEFMT#Default: %H:%M:%Slog_datefmt: '%H:%M:%S'#LOG_DATEFMT_LOGFILE#Default: %Y-%m-%d %H:%M:%Slog_datefmt_logfile: '%Y-%m-%d %H:%M:%S'#LOG_FMT_CONSOLE#Default: [%(levelname)-8s] %(message)slog_fmt_console: '%(colorlevel)s %(colormsg)s'log_fmt_console: '[%(levelname)-8s] %(message)s'#LOG_FMT_LOGFILE#Default: %(asctime)s,%(msecs)03d [%(name)-17s][%(levelname)-8s] %(message)slog_fmt_logfile: '%(asctime)s,%(msecs)03d [%(name)-17s][%(levelname)-8s] %(message)s'#LOG_GRANULAR_LEVELS#Default: &#123;&#125; NODE GROUPS将minion进行逻辑分组 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#NODE GROUPS#Default: &#123;&#125;nodegroups: group1: 'L@foo.domain.com,bar.domain.com,baz.domain.com or bl*.domain.com' group2: 'G@os:Debian and foo.domain.com' group3: 'G@os:Debian and N@group1' group4: - 'G@foo:bar' - 'or' - 'G@foo:baz'#RANGE_SERVER#Default: 'range:80'range_server: range:80#INCLUDE CONFIGURATION#DEFAULT_INCLUDE#Default: master.d/*.conf#INCLUDE#Default: not defined# Include files from a master.d directory in the same# directory as the master config fileinclude: master.d/*# Include a single extra file into the configurationinclude: /etc/roles/webserver# Include several files and the master.d directoryinclude: - extra_config - master.d/* - /etc/roles/webserver#KEEPALIVE#TCP_KEEPALIVE#Default: Truetcp_keepalive: True#TCP_KEEPALIVE_CNT#Default: -1#Sets the ZeroMQ TCP keepalive counttcp_keepalive_cnt: -1#TCP_KEEPALIVE_IDLE#Default: 300#TCP_KEEPALIVE_INTVL#Default: -1 文件路径 Linux Windows 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#Linux#pathconf_file: /etc/salt/masterlog_file: /var/log/salt/masterpidfile: /var/run/salt-master.pid#dircachedir: /var/cache/salt/masterextension_modules: /var/cache/salt/master/extmodspki_dir: /etc/salt/pki/masterroot_dir: /sock_dir: /var/run/salt/master#file_roots/srv/salt/srv/spm/salt#pillar_roots/srv/pillar/srv/spm/pillar#win repowinrepo_dir: /srv/salt/win/repowinrepo_dir_ng: /srv/salt/win/repo-ng#Windows#pathconf_file: c:\salt\conf\masterlog_file: c:\salt\var\log\salt\masterpidfile: c:\salt\var\run\salt-master.pid#dircachedir: c:\salt\var\cache\salt\masterc:\salt\var\cache\salt\master\extmodspki_dir: c:\salt\conf\pki\masterroot_dir: c:\saltsock_dir: c:\salt\var\run\salt\master#file_rootsc:\salt\srv\saltc:\salt\srv\spm\salt#pillar_rootsc:\salt\srv\pillarc:\salt\srv\spm\pillar#win-repowinrepo_dir: c:\salt\srv\salt\win\repowinrepo_dir_ng: c:\salt\srv\salt\win\repo-ng minionCONFIGURING THE SALT MINION minion config: https://docs.saltstack.com/en/latest/ref/configuration/minion.html Salt Minion配置非常简单。通常，需要设置的唯一值是master value，因此minion知道在哪里找到其Master Server。 proxy minionCONFIGURING THE SALT PROXY MINION 12345678910111213141516171819202122232425262728293031323334353637383940#ADD_PROXYMODULE_TO_OPTS#Default: Falseadd_proxymodule_to_opts: True#PROXY_MERGE_GRAINS_IN_MODULE#Default: True#PROXY_KEEP_ALIVE#Default: True#死亡时是否重启与远程设备的连接proxy_keep_alive: False#PROXY_KEEP_ALIVE_INTERVA#Default: 1(min)#keepalive检查频率proxy_keep_alive_interval: 5#PROXY_ALWAYS_ALIVE#Default: Trueproxy_always_alive: False#PROXY_MERGE_PILLAR_IN_OPTS#Default: False#PROXY_DEEP_MERGE_PILLAR_IN_OPTS#Default: False#PROXY_MERGE_PILLAR_IN_OPTS_STRATEGY#Default: smart#PROXY_MINES_PILLAR#Default: True 栗子配置文件 config file examples: https://docs.saltstack.com/en/latest/ref/configuration/examples.html minion blackoutMINION BLACKOUT CONFIGURATION Salt支持minion blackouts。当一个minion处于blackout mode时，所有远程执行命令都被禁用。 minion blackout mode通过pillar key——minion_blackout进行配置。如果此为True，则minion将拒绝除saltutil.refresh_pillar命令外的所有传入命令。它也支持whitelist: 123minion_blackout_whitelist: - test.ping - pillar.get 访问控制系统ACCESS CONTROL SYSTEM Salt维护一个标准系统，用于向非管理用户开放粒度控制以执行Salt命令。访问控制系统已应用于所有用于配置对Salt中非管理控制接口的访问的系统。访问控制系统强制要求在所有三个系统中使用的标准配置语法。 这个接口包括: peer system external auth system publisher acl system 什么时候使用每个认证系统publisher_acl 对于允许本地系统用户运行Salt命令而不给予root访问权限非常有用。如果您可以直接登录Salt master，那么 publisher_acl允许您在没有root权限的情况下使用Salt。如果本地系统配置为针对远程系统（如LDAP或Active Directory）进行身份验证，则 publisher_acl 将透明地与远程系统进行交互。 external_auth 对于 salt-api 或者使用Salt Python API创建自己的脚本非常有用。它可以在CLI上使用（with the -a flag），但由于涉及更多步骤，因此更麻烦。在CLI中唯一有用的是本地系统未配置为针对外部服务进行身份验证，但您仍希望Salt对外部服务进行身份验证。 Publisher ACLPUBLISHER ACL SYSTEM Salt Publisher ACL 系统，允许除root之外的系统用户有权在master上访问在minion上执行的salt命令。它在master的配置文件中的 publisher_acl 部分进行配置。在此配置项下，指定用户打开发送命令，然后指定将对特定用户可用的minion函数列表。用户和函数都可以通过完全匹配、shell glob、正则表达式来指定。 栗子： 12345678910111213141516171819202122publisher_acl: # Allow thatch to execute anything. thatch: - .* # Allow fred to use test and pkg, but only on "web*" minions. fred: - web*: - test.* - pkg.* # Allow admin and managers to use saltutil module functions admin|manager_.*: - saltutil.* # Allow users to use only my_mod functions on "web*" minions with specific arguments. user_.*: - web*: - 'my_mod.*': args: - 'a.*' - 'b.*' kwargs: 'kwa': 'kwa.*' 'kwb': 'kwb' PERMISSION ISSUES必须修改 publisher_acl 所需的目录，以便指定的用户可以读取: 123chmod 755 /var/cache/salt /var/cache/salt/master /var/cache/salt/master/jobs /var/run/salt /var/run/salt/master#还要更改日志文件有对应的写入权限 白/黑名单WHITELIST AND BLACKLIST 在Salt身份认证配置系统中，可以通过使用白名单指定允许的内容，使用黑名单指定不允许的内容。 123456789101112131415#白名单publisher_acl: fred: - test.ping - pkg.*#黑名单publisher_acl_blacklist: users: - root - &apos;^(?!sudo_).*$&apos; # all non sudo users modules: - cmd.* - test.echo External AuthenticationEXTERNAL AUTHENTICATION SYSTEM Salt’s External Authentication System (eAuth)，允许Salt将命令授权传递给任何外部身份验证系统(PAM、LDAP)。 eAuth如果使用PAM，则需要以root身份来运行 slat-master eAuth配置eAuth 允许特定用户被授予访问权限在特权minion上执行特定功能。它在master中配置。 123456789101112131415161718192021222324external_auth: pam: thatch: - 'web*': - test.* - network.* steve|admin.*: - .*#用户thatch在web*的minions上执行test和network模块#用户steve和adminxxx被授予不受限制的访问权限#PAM模块不允许以root身份进行身份验证#wheel modules/runner modulesexternal_auth: pam: thatch: - '@wheel' # to allow access to all wheel modules - '@runner' # to allow access to all runner modules - '@jobs' # to allow access to the jobs runner and/or wheel module#runner/wheel的标记是不同的，因为没有minions来限定ACL 注意:所有具有外部身份验证权限的用户允许运行 saltutil.findjob。请注意，这可能会无意中暴露一些数据，例如minion ID。 匹配语法MATCHING SYNTAX external_auth 字典的结构可以采用以下形状: user, function 是完全匹配 shell 是glob pattern或 RE minions 是复合目标 1234567891011121314151617181920212223242526272829#By userexternal_auth: &lt;eauth backend&gt;: &lt;user or group%&gt;: - &lt;regex to match function&gt;#By user, by minionexternal_auth: &lt;eauth backend&gt;: &lt;user or group%&gt;: &lt;minion compound target&gt;: - &lt;regex to match function&gt;#By user, by runner/wheelexternal_auth: &lt;eauth backend&gt;: &lt;user or group%&gt;: &lt;@runner or @wheel&gt;: - &lt;regex to match function&gt;#By user, by runner+wheel moduleexternal_auth: &lt;eauth backend&gt;: &lt;user or group%&gt;: &lt;@module_name&gt;: - &lt;regex to match function without module_name&gt; GROUPS要将权限应用于eAuth中的一组用户，请在ID中附加％: 12345external_auth: pam: admins%: - '*': - 'pkg.*' 通过函数参数来限制LIMITING BY FUNCTION ARGUMENTS 函数的位置参数或关键字参数也可以列入白名单: 12345678910111213141516171819external_auth: pam: my_user: - '*': - 'my_mod.*': args: - 'a.*' - 'b.*' kwargs: 'kwa': 'kwa.*' 'kwb': 'kwb' - '@runner': - 'runner_mod.*': args: - 'a.*' - 'b.*' kwargs: 'kwa': 'kwa.*' 'kwb': 'kwb' 用法任何用户在master上可以使用 -a 选项在同一系统从命令行使用 eAu: 1salt -a pam web\* test.ping TOKENS仅使用外部身份验证，每次调用Salt时都需要身份验证凭据。这可以通过Salt Token 来缓解。令牌是短期授权，只需在验证时添加-T选项即可轻松创建： 12345salt -T -a pam web\* test.ping#现在将创建一个有效期为12小时（默认）的令牌，此令牌存储在活动用户主目录中名为 `salt_token` 的文件中#创建令牌后，将与所有后续通信一起发送令牌。在令牌过期之前，不需要再次输入用户身份验证#令牌的过期时间可在master config中修改 LDAP和ADLDAP AND ACTIVE DIRECTORY LDAP要求安装python-ldap Salt支持LDAP的和组身份验证。 OPENLDAP和类似的系统LDAP配置发生在 Salt Master配置文件中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# Server to auth againstauth.ldap.server: localhost# Port to connect viaauth.ldap.port: 389# Use TLS when connectingauth.ldap.tls: False# LDAP scope level, almost always 2auth.ldap.scope: 2# Server specified in URI formatauth.ldap.uri: '' # Overrides .ldap.server, .ldap.port, .ldap.tls above# Verify server's TLS certificateauth.ldap.no_verify: False# Bind to LDAP anonymously to determine group membership# Active Directory does not allow anonymous binds without special configuration# In addition, if auth.ldap.anonymous is True, empty bind passwords are not permitted.auth.ldap.anonymous: False# FOR TESTING ONLY, this is a VERY insecure setting.# If this is True, the LDAP bind password will be ignored and# access will be determined by group membership alone with# the group memberships being retrieved via anonymous bindauth.ldap.auth_by_group_membership_only: False# Require authenticating user to be part of this Organizational Unit# This can be blank if your LDAP schema does not use this kind of OUauth.ldap.groupou: 'Groups'# Object Class for groups. An LDAP search will be done to find all groups of this# class to which the authenticating user belongs.auth.ldap.groupclass: 'posixGroup'# Unique ID attribute name for the userauth.ldap.accountattributename: 'memberUid'# These are only for Active Directoryauth.ldap.activedirectory: Falseauth.ldap.persontype: 'person'auth.ldap.minion_stripdomains: []# Redhat Identity Policy Auditauth.ldap.freeipa: False 验证LDAP服务器 LDAP身份验证有两个阶段: 首先，Salt进行身份验证以搜索用户的专有名称(DN)和组成员 Salt搜索目录以确定实际用户的DN和组后，它将以运行Salt命令的用户重新进行身份验证 如果您已经了解DN的结构，并且LDAP存储中的权限已设置为用户可以查找自己的组成员身份，则第一个和第二个用户可以相同。要告诉Salt这种情况，请省略 auth.ldap.bindpw 参数。 123456789101112#binddnauth.ldap.basedn: dc=saltstack,dc=comauth.ldap.binddn: uid=&#123;&#123; username &#125;&#125;,cn=users,cn=accounts,dc=saltstack,dc=com#auth.ldap.binddn: uid=ldaplookup,cn=sysaccounts,cn=etc,dc=saltstack,dc=comauth.ldap.bindpw: mypassword#auth.ldap.filter: uid=&#123;&#123; username &#125;&#125; 确定组成员 对于OpenLDAP，要确定组成员身份，可以指定包含组数据的OU。对于AD，以不同方式处理组成员身份，并且不使用groupou配置变量。 Peer Communication此功能的目的不是让Salt minions作为另一个独立的中间商，而是让 Salt Minions 将命令传递给另外的 Salt Minion。peer interface 通过主配置文件中的两个选项进行配置： 对于从 master 发送命令的minion来说，使用 peer 对于从 master 执行 runners 的minion来说，使用 peer_run 由于这可以通过允许minions访问master publisher，可能存在安全风险，因此默认情况下关闭该功能。根据正则表达式，可以允许 minions 基于每个 minion 访问 master publisher。根据minion的ID可以允许ID访问某些Salt模块和功能。 配置PEER CONFIGURATION 它在 master config 的 peer 部分进行配置: 12345678910111213141516171819202122232425#最简单方法是为 allminions 启用 all communication，仅限于很安全的环境下peer: .*: - .*#以 example.com 结尾的IDpeer: .*example.com: - test.* - ps.* - pkg.*peer: .*example.com: - test.* - ps.* - pkg.* .*foo.org: - test.* - ps.* - pkg.*#使用正则表达式匹配函数 PEER RUNNER1234567891011#all to allpeer_run: .*: - .*#peer_run: .*example.com: - manage.* - jobs.* 使用对等通信USING PEER COMMUNICATION publish module 被创建来管理 peer communication。它有多种方式来执行对等通信，目前，此模块有三个functions: 1234567salt-call publish.publish \* test.pingsalt-call publish.runner manage.upsalt-call publish.publish 'webserv* and not G@os:Ubuntu' test.ping tgt_type='compound' 作业管理JOB MANAGEMENT 由于Salt执行在许多系统上运行的作业，因此Salt需要能够管理在许多系统上运行的作业。 Minion Proc系统THE MINION PROC SYSTEM Salt Minions 在 Salt cachedir 中维护一个 proc 目录(默认/var/cache/salt/proc)，proc 目录维护以执行的作业的ID命名的文件。这些文件包含有关minion上当前正在运行的作业的信息，并允许查找作业。 saltutil模块中的函数FUNCTIONS IN THE SALTUTIL MODULE saltutil模块中的函数用于管理作业，它们有: running: 返回 proc 目录中找到的所有正在运行的作业的数据 find_job: 根据 Job ID 返回有关特定作业的特定数据 signal_job: 允许给定的 JID 发送信号 term_job: Sends a termination signal (SIGTERM, 15)到指定作业进程 kill_job: Sends a kill signal (SIGKILL, 9)到指定作业进程 这些函数构成了后端的核心，用于管理minion级别的工作。 JOB RUNNERjobs runner 包含使查看数据更简单，更清晰的功能。它包含许多功能: ACTIVE acrive函数对所有minions运行 saltutil.running，并以更加可用和紧凑的格式格式化有关所有正在运行的作业返回的数据。它还将比较已返回的作业和仍在运行的作业，从而更容易查看系统已完成作业以及系统仍在等待的作业。 1salt-run jobs.active LOOKUP_JID 执行作业时，返回数据将发送回 Master 并进行缓存。默认缓存24小时，但可以通过 master config 中的 keep_jobs 选项进行配置。使用 lookup_jid runner 将显示与salt命令初始作业调用相同的返回数据。 1salt-run jobs.lookup_jid &lt;job id number&gt; LIST_JOBS 在找到历史性工作之前，可能需要找到 JID。list_jobs 将解析缓存的执行数据，并显示已经或部分返回的作业的所有作业数据。 1salt-run jobs.list_jobs 调度作业SCHEDULING JOBS Salt调度系统允许对 Minion/Master 进行增量执行。调度系统公开了对 Minion/Runner on Master 的任何执行函数的执行。 有多种方法启用调度: 在 master/minion 配置文件中的 schedule 选项，修改之后重启生效 Minion pillar data. 通过刷新minion pillar data来实现(saltutil.refresh_pillar) schedule state/schedule module 注意:调度器在 minion 和 master 上执行不同的函数。runner func on master; specify execution func on minino. 调度在 minion 上是没有输出的，除非设置 minion 的日志级别。 States 在 minion 上执行，所有的都是如此。您可以传递位置参数并提供命名参数的YAML dict。 1234567891011121314151617181920212223#每3600s调度一次 state.sls httpd test=Trueschedule: job1: function: state.sls seconds: 3600 args: - httpd kwargs: test: True#延长10s-15sschedule: job1: function: state.sls seconds: 3600 args: - httpd kwargs: test: True splay: start: 10 end: 15 按时间和日期调度SCHEDULE BY DATE AND TIME 可以使用Python dateutil 库支持的日期字符串指定作业频率。当然，你需要安装此库。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364schedule: job1: function: state.sls args: - httpd kwargs: test: True when: - Monday 5:00pm - Tuesday 3:00pm - Wednesday 5:00pm - Thursday 3:00pm - Friday 5:00pm#调度程序自定义短语用于whenwhens: tea time: 1:40pm deployment time: Friday 5:00pmschedule: job1: function: state.sls args: - httpd kwargs: test: True when: - 'tea time'#时间区间schedule: job1: function: state.sls seconds: 3600 args: - httpd kwargs: test: True range: invert: True start: 8:00am end: 5:00pm#指定时间#默认日期格式为ISO 8601schedule: job1: function: pkg.install kwargs: pkgs: [&#123;'bar': '&gt;1.2.3'&#125;] refresh: true once: '2016-01-07T14:30:00'#指定日期格式schedule: job1: function: test.ping once: 2015-04-22T20:21:00 once_fmt: '%Y-%m-%dT%H:%M:%S' 最大并行工作MAXIMUM PARALLEL JOBS RUNNING 调度程序还支持确保运行特定例程的副本不超过N个。将此用于可能长时间运行的、发生基础设施中断可能会相互踩踏或堆积在一起的作业。 123456#maxrunning默认值1schedule: long_running_job: function: big_file_transfer jid_include: True maxrunning: 1 类似定时任务的调度CRON-LIKE SCHEDULE 调度器支持使用定时任务格式来调度作业。当然，需要安装Python croniter 库。 12345678schedule: job1: function: state.sls cron: '*/15 * * * *' args: - httpd kwargs: test: True 作业数据返回JOB DATA RETURN 默认情况下，有关从Salt Scheduler 运行的作业的数据将返回到 Master。可在 master config 的 return_job 配置项进行修改。 1234schedule: job1: function: scheduled_job_function return_job: False JOB METADATA包含特定数据用以区分一个作业与其他作业可能很有用。使用元数据(metadata)参数，特殊值可以与调度作业相关联。这些值不用于作业的执行，但如果与 return_job 参数结合使用，可用于稍后搜索特定作业。元数据参数必须指定为 字典数据格式，否则将会被忽略。 12345schedule: job1: function: scheduled_job_function metadata: foo: bar 启动时运行RUN ON START 默认情况下，根据minion的启动时间安排的任何作业将在minion启动时运行预定作业。有时这不是理想的情况。将 run_on_start参数 设置为 False 将导致调度程序跳过此第一次运行并等待下一次计划运行： 123456789schedule: job1: function: state.sls seconds: 3600 run_on_start: False args: - httpd kwargs: test: True UNTIL/AFTER12345678910111213141516171819202122232425#until参数，允许指定调度作业的结束时间#在此时间过后，作业将不在运行schedule: job1: function: state.sls seconds: 15 until: '12/31/2015 11:59pm' args: - httpd kwargs: test: True#after参数，允许指定调度作业的开始时间#在此时间过后，作业将不在运行schedule: job1: function: state.sls seconds: 15 after: '12/31/2015 11:59pm' args: - httpd kwargs: test: True 调度状态SCHEDULING STATES 123456789101112131415schedule: log-loadavg: function: cmd.run seconds: 3660 args: - 'logger -t salt &lt; /proc/loadavg' kwargs: stateful: False shell: /bin/sh#'&gt; 高峰调度SCHEDULING HIGHSTATES 12345#highstateschedule: highstate: function: state.highstate minutes: 60 #### 调度runner SCHEDULING RUNNERS 也在在master上指定runner的运行: 1234567schedule: run_my_orch: function: state.orchestrate hours: 6 splay: 600 args: - orchestration.my_orch #### SCHEDULER WITH RETURNER 调度程序对于收集有关minion的监视数据等任务也很有用，此调度选项将收集状态数据并将其发送到MySQL返回者数据库： 123456789schedule: uptime: function: status.uptime seconds: 60 returner: mysql meminfo: function: status.meminfo minutes: 5 returner: mysql 管理作业缓存MANAGING THE JOB CACHE Salt Maste r维护所有作业执行的作业缓存，可以通过 Job Runner查询。此作业缓存称为默认作业缓存。 默认作业缓存DEFAULT JOB CACHE 默认缓存系统使用Salt Master上的本地存储，可以在作业缓存目录(默认: /var/cache/salt/master/jobs)中找到。默认缓存系统适用于大多数部署，因为它通常不需要任何进一步的配置或管理。 默认作业缓存是临时缓存，作业将存储24小时。可在 master config 文件中的 keep_jobs 参数来调整它: 12#请勿将此值设置为0，因为这意味着缓存清理程序永远不会运行keep_jobs: 24 减小默认缓存的大小 REDUCING THE SIZE OF THE DEFAULT JOB CACHE 默认作业缓存有时会成为大型部署(minions &gt; 5000的负担。禁用作业缓存将使以前执行的作业对作业系统不可用，通常不建议这样做。通常，确保 Master 可以访问更快的IO系统或者将tmpfs安装到jobs目录是明智的。但是，您可以通过在Salt Master配置文件中将job_cache 设置为 False 来禁用它。这意味着Salt Master将不再缓存minion的返回信息，但仍将创建每个作业的JID目录和jid文件。此JID目录是检查和防止JID冲突所必需的。 在外部系统中存储作业结果STORING JOB RESULTS IN AN EXTERNAL SYSTEM 作业执行后，每个Salt Minion将作业结果返回给Salt Master。这些结果存储在默认作业缓存中。除了默认作业缓存之外，Salt还提供了两种额外的机制来将作业结果发送到其它系统(databases, local syslog, others): External Job Cache Master Job Cache EXTERNAL JOB CACHE - MINION-SIDE RETURNER配置外部作业缓存后，数据会像往常一样返回Salt Master上的默认作业缓存，然后使用Salt Minion上运行的Salt ruturner module 将结果发送到外部作业缓存。 MASTER JOB CACHE - MASTER-SIDE RETURNER在此配置中，Salt Minions 像往常一样将数据发送到默认作业缓存，然后 Salt Master 使用在 Salt Master 上运行的Salt Returner Module 将数据发送到外部系统。 配置两种机制 了解SALT RETURNERS 在配置作业缓存之前，必须了解 Salt Returner Module。Returner 是可插拔的 Salt Modules，它接收作业返回的数据，然后执行任何必要的步骤将数据发送到外部系统。Salt Returner 为 External Job Cache 和 Master Job Cache 提供了许多核心功能。 Salt目前提供许多不同的 Returner ，以便让您连接到各种系统。各种 Returner Module: https://docs.saltstack.com/en/latest/ref/returners/all/index.html#all-salt-returners 配置它们 EXTERNAL JOB CACHE，可在如下选项中配置: Minion configuration file Minion’s grains Minion’s pillar data MASTER JOB CACHE，在 Master config 中进行配置。 栗子: 123456789101112#mysqlmysql.host: 'salt'mysql.user: 'salt'mysql.pass: 'salt'mysql.db: 'salt'mysql.port: 3306#slackslack.channel: 'channel'slack.api_key: 'key'slack.from_name: 'name' 启用它们 123456789101112#EXTERNAL JOB CACHE#ext_job_cache: mysqlext_job_cache: &lt;returner&gt;#MASTER JOB CACHE#master_job_cache: mysqlmaster_job_cache: &lt;returner&gt;#重启服务 日志LOGGING Salt 尽力让日志工作为您工作，并帮助我们解决您可能在此过程中发现的任何问题。 日志级别LOG LEVELS 日志级别按数字顺序排列，以便将日志级别设置为特定级别将记录该级别及更高级别的所有日志语句。例如，log_level: error 将会记录 error, critical, quiet 级别的日志。 大多数日志记录级别在Python logging lib 中默认定义，Salt 使用了更多日志级别。 Level Numeric value Description quiet 1000 Nothing should be logged at this level critical 50 Critical errors error 40 Errors warning 30 Warnings info 20 Normal log information profile 15 Profiling information on salt performance debug 10 Information useful for debugging both salt implementations and salt code trace 5 More detailed code debugging information garbage 1 Even more debugging information all 0 Everything 日志配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#LOG_FILE#日志记录可以发送到常规文件，本地路径名或网络位置，配置为使用rsyslogd时，远程日志记录效果最佳#远程地址格式: &lt;file|udp|tcp&gt;://&lt;host|socketpath&gt;:&lt;port-if-required&gt;/&lt;log-facility&gt;#栗子log_file: /var/log/salt/masterlog_file: /var/log/salt/minionlog_file: file:///dev/loglog_file: file:///dev/log/LOG_DAEMONlog_file: udp://loghost:10514#LOG_LEVEL#Default: warning#发送到控制台的日志记录消息的级别log_level: warning#LOG_LEVEL_LOGFILE#Default: info#要发送到日志文件的消息级别log_level_logfile: warning#LOG_DATEFMT#Default: %H:%M:%S#控制台日志消息中使用的日期和时间格式log_datefmt: '%H:%M:%S'#LOG_DATEFMT_LOGFILE#Default: %Y-%m-%d %H:%M:%S#日志文件消息中使用的日期和时间格式#LOG_FMT_CONSOLE#Default: [%(levelname)-8s] %(message)s#控制台日志消息的格式log_fmt_console: '[%(levelname)-8s] %(message)s'#可使用所有标准python日志记录LogRecord属性。 Salt还提供自定义LogRecord属性自定义控制台显示的颜色'%(colorlevel)s' # log level name colorized by level'%(colorname)s' # colorized module name'%(colorprocess)s' # colorized process number'%(colormsg)s' # log message colorized by level#LOG_FMT_LOGFILE#Default: %(asctime)s,%(msecs)03d [%(name)-17s][%(levelname)-8s] %(message)s#日志文件记录消息的格式log_fmt_logfile: '%(asctime)s,%(msecs)03d [%(name)-17s][%(levelname)-8s] %(message)s'#也可通过对 LogRecord 自定义控制台显示颜色'%(bracketlevel)s' # equivalent to [%(levelname)-8s]'%(bracketname)s' # equivalent to [%(name)-17s]'%(bracketprocess)s' # equivalent to [%(process)5s]#LOG_GRANULAR_LEVELS#Default: &#123;&#125;#用于根据日志调用名称更具体地控制日志记录级别log_granular_levels: 'salt': 'warning' 'salt.modules': 'debug' 'salt.loader.saltmaster.ext.module.custom_module': 'all' 外部日志处理器EXTERNAL LOGGING HANDLERS 除了salt使用的内部日志处理程序外，还有一些可以使用的外部日志处理程序: fluent_mod log4mongo_mod logstash_mod sentry_mod 文件服务器Salt File Server Salt 附带了一个简单的文件服务器，适合将文件分发给 Salt minions，它是内置在 Salt Master 中的无状态 ZeroMQ Server。 Salt文件服务器的主要目的是提供在 Salt state system 中使用的文件。有了这个说法，Salt文件服务器可用于从Master到minions的任何常规文件传输。 文件系统后端FILE SERVER BACKENDS 此功能增加了Salt Master集成不同文件服务器后端的能力。文件服务器后端允许Salt文件服务器充当外部资源的透明桥。一个很好的例子是git后端，它允许Salt提供来自一个或多个git存储库的文件，但也有其他几个。 File Server Module: azurefs gitfs hgfs minionfs roots s3fs svnfs 1234567891011121314151617181920212223242526272829#启用fileserver_backend: - git#使用多个后端fileserver_backend: - roots - git#定义环境变量#在文件服务器环境中定义不同源的顺序也很重要file_roots: base: - /srv/salt/prod qa: - /srv/salt/qa - /srv/salt/prod dev: - /srv/salt/dev - /srv/salt/qa - /srv/salt/prod#栗子gitfs_remotes: - https://mydomain.tld/repos/first.git - https://mydomain.tld/repos/second.git 从特定环境请求文件REQUESTING FILES FROM SPECIFIC ENVIRONMENTS Salt文件服务器支持多种环境，允许隔离SLS文件和其他文件以便更好地组织。对于默认后端(root)，使用 roots 选项定义环境。其它后端以它们自己的方式定义环境。 QUERYSTRING SYNTAX 任何 salt:// 文件URL都可以使用查询字符串语法指定其文件服务器环境 1salt://path/to/file?saltenv=foo IN STATES 可以指示Minions在全局和单个状态下使用哪个环境，并且每个环境都有多种方法: GLOBALLY 使用minion配置文件中的 environment 选项将minion固定到环境中。此外，可以将环境设置为单次调用以下函数。 1234state.applystate.highstatestate.slsstate.top ON A PER-STATE BASIS 在单个状态中，有两种指定环境的方法。 123456789101112131415#第一个是向 state 添加 saltenv 参数/etc/foo/bar.conf: file.managed: - source: salt://foo/bar.conf - user: foo - mode: 600 - saltenv: config#另一种是使用查询字符串语法/etc/foo/bar.conf: file.managed: - source: salt://foo/bar.conf?saltenv=config - user: foo - mode: 600 文件系统配置FILE SERVER CONFIGURATION Salt文件服务器是用ZeroMQ编写的高性能文件服务器。它可以快速管理大型文件，而且开销很小，并且已经过优化，可以非常有效地处理小文件。 Salt文件服务器是一个环境感知文件服务器。这意味着可以在许多根目录中分配文件，并通过指定文件路径和要搜索的环境来访问这些文件。各个环境可以跨多个目录根来创建叠加，并允许以多种灵活的方式组织文件。 环境Salt文件服务器默认为强制 base 环境。必须定义这个环境，并在未指定环境时用于下载文件。 环境允许 file 和 sls data 在逻辑上分开，但环境不会相互隔离。这允许工程师使用Salt对环境进行逻辑隔离，但也允许在多个环境中使用信息。 目录覆盖DIRECTORY OVERLAY 环境设置是用于发布文件的目录列表。搜索这些目录以查找指定的文件并返回找到的第一个文件。这意味着目录数据的优先级基于它们的列出顺序。这允许根据在配置中定义的顺序来覆盖目录并确定其优先级。 1234567file_roots: base: - /srv/salt/base - /srv/salt/failover#如果一个文件的URI是 salt://httpd/httpd.conf，它会首先在 /srv/salt/base/httpd/httpd.conf 搜索文件，找到则返回#如果未找到，那么使用 /srv/salt/failover/httpd/httpd.conf 本地文件服务器LOCAL FILE SERVER 可以重新路由文件服务器以从minion运行。这主要是为了在没有Salt master的情况下运行Salt State。要使用本地文件服务器接口，请将文件服务器数据复制到minion，并将minion上的 file_roots 选项设置为指向从 Master 复制的目录。一旦设置了minion file_roots 选项，将 file_client选项更改为本地以确保使用本地文件服务器接口。 CP模块THE CP MODULE cp模块是minion端文件服务器操作的主页。cp模块由Salt State system, salt-cp 使用，可用于分发Salt文件服务器提供的文件。 ESCAPING SPECIAL CHARACTERS satl:// url格式可能包含查询字符串，例如 salt://dir/file.txt?saltenv=base。通过带有satl://-的引用文件作为查询字符串的初始标记，你可阻止?的解释。 1234/etc/marathon/conf/?checkpoint: file.managed: - source: salt://|hw/config/?checkpoint - makedirs: True ENVIRONMENTS 由于文件服务器可以与Salt State system 一起使用，因此它支持环境。如前所述，环境在master配置文件中定义。 GET_FILE 可以在minion上使用 cp.get_file 函数从 master 下载文件。对于较大的文件，此函数支持gzip压缩，由于gzip是CPU密集型的，因此仅应在压缩率非常高的情况下使用。 12345678910111213salt '*' cp.get_file salt://vimrc /etc/vimrc#启用模板salt '*' cp.get_file "salt://&#123;&#123;grains.os&#125;&#125;/vimrc" /etc/vimrc template=jinja#gzip范围: 1-9salt '*' cp.get_file salt://vimrc /etc/vimrc gzip=5#默认情况下不会创建新的目标目录，如果有需要，请使用`makedirs`参数salt '*' cp.get_file salt://vimrc /etc/vim/vimrc makedirs=True GET_DIR 可以在minion上使用 cp.get_dir 函数从master下载整个目录。 12345salt '*' cp.get_dir salt://etc/apache2 /etc#同样支持模板和压缩salt '*' cp.get_dir salt://etc/&#123;&#123;pillar.webserver&#125;&#125; /etc gzip=5 template=jinja 客户端实例FILE SERVER CLIENT INSTANCE 允许编写模块和应用程序的客户端实例来使用Salt文件系统。文件服务器使用与Salt系统其余部分相同的身份验证和加密进行网络通信。 FILECLIENT MODULE salt/fileclient.py 模块用于设置从minion到master的通信。使用 fileclient 模块创建客户端实例时，需要传入minion配置。 1234567891011121314151617181920212223242526272829303132#在minion模块中使用fileclient模块时，可以传递内置的__opts__数据import salt.minionimport salt.fileclientdef get_file(path, dest, saltenv='base'): ''' Used to get a single file from the Salt master CLI Example: salt '*' cp.get_file salt://vimrc /etc/vimrc ''' # Get the fileclient object client = salt.fileclient.get_file_client(__opts__) # Call get_file return client.get_file(path, dest, False, saltenv)#__opts__数据不可用的minion模块之外创建一个fileclient实例import salt.fileclientimport salt.configdef get_file(path, dest, saltenv='base'): ''' Used to get a single file from the Salt master ''' # Get the configuration data opts = salt.config.minion_config('/etc/salt/minion') # Get the fileclient object client = salt.fileclient.get_file_client(opts) # Call get_file return client.get_file(path, dest, False, saltenv) 包管理SALT PACKAGE MANAGER Status: Technical Review The Salt Package Manager(SPM)，使Salt formulas 得以打包，以简化向Salt Master 的分发。SPM的设计受到其他现有包系统的影响，包括RPM, Yum, Pacman。 SPM包构建BUILDING SPM PACKAGES Status: Technical Review 使用SPM的第一步是为要分发的每个方案构建包。可以在任何可以安装Salt的系统上构建软件包。 包构建概述PACKAGE BUILD OVERVIEW saltstack-formulas: https://github.com/saltstack-formulas 构建程序包，方案使用的所有 state, pillar, jinja, and file templates 都将组装到构建系统上的文件夹中。这些文件可以从GitHub 存储库克隆。 包安装概述PACKAGE INSTALLATION OVERVIEW 构建包时，了解Salt master上文件的安装位置很有用。在安装过程中，除了 pillar.example 和 FORMULA 之外的所有文件都被直接复制到Salt master上的 spm state tree(\srv\spm\salt)。如果根目录中存在 pillar.example 文件，则将其重命名为 formula_name.sls.orig 并放在 pillar_path 中。 构建一个SPM formula包BUILDING AN SPM FORMULA PACKAGE 将方案(formula)文件组装到构建系统上的文件夹中 创建一个FORMULA文件并将其放在包文件夹的根目录中 运行spm build folder_name，此包是构建并放在 /srv/spm_build 文件夹中: spm build /path/to/salt-packages-source/myapp-formula 将 .spm 文件复制到存储库系统上的文件夹 包类型TYPES OF PACKAGES SPM支持不同类型的包，每个包的功能由其名称表示。 FORMULA: 默认情况下，此类包的大多数文件都位于 /srv/spm/salt/ 目录中，上面说的pillar.example文件例外 REACTOR: 默认情况下，此类包的文件位于 /srv/spm/reactor/ 目录 CONF: 此类软件包中的文件是Salt的配置文件，通常位于 /etc/salt/ 目录 技术信息TECHNICAL INFORMATION 软件包使用BZ2压缩的tar包构建，默认情况下，使用 sqlite3 驱动存储包数据库。这些内容的支持是内置于Python中的，因此不需要外部依赖项。 属于SPM的所有其它文件都使用YAML，以实现可移植性，易用性和可维护性。 特定SPM装载器模块SPM-SPECIFIC LOADER MODULES SPM的设计与传统的包管理器相似，后者将文件应用于文件系统并将包元数据存储在本地数据库中。但是，由于现代基础架构通常超出了这些用例，因此SPM的某些部分已经分解为它们自己的模块集。 PACKAGE DATABASE: 默认使用 sqlite3模块 PACKAGE FILES: 默认使用local模块 分发SPM包DISTRIBUTING SPM PACKAGES Status: Technical Review SPM包可以通过HTTP(S), FTP, FS 分发给Salt Master。SPM Repo 可以托管在可以安装Salt的任何系统上。安装Salt后，您可以在更新包或向存储库添加包时运行 spm create_repo 命令。 设置一个包的Repo 构建包后，生成的SPM文件将放在 srv/spm_build 文件夹中。 添加一个包到Repo 只需将SPM文件复制到repo文件夹，然后生成repo元数据即可添加新软件包。 生成Repo Metadata 每次更新或向存储库添加SPM包时，请发出 spm create_repo 命令: 1spm create_repo /srv/spm_build 安装SPM包INSTALLING SPM PACKAGES Status: Technical Review SPM软件包安装在Salt master中，使用Salt的所有包管理功能可以使用它们。 配置远程REPOCONFIGURING REMOTE REPOSITORIES 在SPM可以使用存储库之前，需要做两件事。首先，Salt master 需要通过配置过程知道存储库的位置。然后它需要 pull down 存储库元数据。 Repo配置文件 通过将每个存储库添加到每个 Salt Master 的 /etc/salt/spm.repos.d/spm.repo 文件来配置存储库，它包含Repo的名称和链接: 1234567891011121314my_repo: url: https://spm.example.com/#https，请注意文件权限my_repo: url: https://spm.example.com/ username: user password: pass#http(s), ftp, filemy_repo: url: file:///srv/spm_build 更新本地Repo Metadata 使用 spm update_repo 命令下载 Repo 元数据。运行命令后，每个repo的文件都放在Salt master上的 /var/cache/salt/spm 中，如果添加存储库但它似乎没有显示，请检查此路径以验证是否找到了存储库。 1spm update_repo 更新文件根UPDATE FILE ROOTS SPM软件包安装在Salt master上的 srv/spm/salt 文件夹中，需要手动将此路径添加到Salt master上的文件根目录中。 1234file_roots: base: 1. /srv/salt 2. /srv/spm/salt 安装包 警告:目前，SPM在安装之前不会检查文件是否已就位。这意味着现有文件将被覆盖而不会发出警告。 使用 spm install 命令来安装包: 1234spm install apache#使用spm local install命令使用本地SPM文件安装SPM软件包spm local install /srv/spm/apache-201506-1.spm PILLARS如果已安装的软件包包含Pillar数据，确保使用 pillar Top file 将安装的pillar用于必要的系统。 删除包安装包之后，使用 spm remove 命令来删除包: 1234#如果文件已被修改，则不会删除它们。空目录也将被删除spm remove apache` SPM配置有许多特定的SPM配置，可在Salt Master中配置，也可在SPM自己的配置文件(通常: /etc/salt/spm)中配置。如果在两个地方都进行了配置，则SPM配置文件优先。通常，不需要更改这些默认值。 12345678910111213141516171819202122232425262728293031323334353637#SPM_LOGFILE#Default: /var/log/salt/spm#SPM_REPOS_CONFIG#Default: /etc/salt/spm.repos#SPM_CACHE_DIR#Default: /var/cache/salt/spm#SPM_DB#Default: /var/cache/salt/spm/packages.db#SPM_BUILD_DIR#Default: /srv/spm_build#SPM_BUILD_EXCLUDE#Default: ['.git']spm_build_exclude: - .git - .svn#FORMULA#Default dir: /srv/spm/salt/#REACTOR#Default dir: /srv/spm/reactor/#CONF#Default dir: /etc/salt/ FORMULA File除了FORMULA本身，还必须存在描述包的FORMULA文件。栗子: 1234567name: apacheos: RedHat, Debian, Ubuntu, SUSE, FreeBSDos_family: RedHat, Debian, Suse, FreeBSDversion: 201506release: 2summary: Formula for installing Apachedescription: Formula for installing Apache 需要的字段REQUIRED FIELDS 这个文件必须包含以下字段: NAME: 包名 OS: 支持的操作系统 OS_FAMILY: 支持的os_family VERSION: 包版本，建议使用YYYYMM格式 MINIMUM_VERSION: Salt最低推荐版本 RELEASE: 发行版 SUMMARY: 简短描述 DESCRIPTION: 详细描述 可选字段OPTIONAL FIELDS 如下字段也可能存在: TOP_LEVEL_DIR DEPENDENCIES OPTIONAL RECOMMENDED FILES LOCAL STATES TGT STATES TEMPLATING STATES LOADER MODULES REMOVING PACKAGES TECHNICAL INFORMATION SPM-SPECIFIC LOADER MODULES PACKAGE DATABASE PACKAGE FILES TYPES OF PACKAGES FORMULA REACTOR CONF SPM开发指南docs: https://docs.saltstack.com/en/latest/topics/spm/dev.html 先放着，后面有需要再来学习。 在其它数据库中存储数据STORING DATA IN OTHER DATABASES SDB接口用于存储和检索数据，这些数据与 pillars and grains 不同，不一定是特定于特定部分的数据。最初的设计目标是允许将密码存储在安全数据库中，而不是纯文本文件。但是，作为通用数据库接口，它可以在概念上用于许多其它目的。 SDB CONF要使用SDB接口，必须设置配置文件。要对Salt Master Command 可用，需在master配置文件中定义；对于在 Salt Minion 上执行的模块，可在 minion配置文件和 pillar 中进行配置。 栗子: 1234#建议使用简单的名字，因为它在BSD URI中使用mykeyring: driver: keyring service: system SDB URISSDB旨在使用紧凑的URL进行小型数据库查询。这允许用户在多个Salt配置区域内快速引用数据库值，而不会产生大量开销。 SDB URI 基本格式: 1234567891011#profile指的是master/minion配置中定义的profilesdb://&lt;profile&gt;/&lt;args&gt;#profile look likekevinopenstack: driver: keyring service: salt.cloud.openstack.kevin#URI look likesdb://kevinopenstack/password 获取、配置和删除SDB值GETTING, SETTING AND DELETING SDB VALUES 配置SDB驱动后，您可以使用sdb执行模块从中获取、设置和删除值。 SDB Modules: get set delete 123456789salt-call sdb.get sdb://kevinopenstack/passwordsalt-call sdb.set 'sdb://myvault/secret/salt/saltstack' 'super awesome'salt-call sdb.delete 'sdb://mykvstore/foobar'#runner system也可用salt-run sdb.get 'sdb://myvault/secret/salt/saltstack'salt-run sdb.set 'sdb://myvault/secret/salt/saltstack' 'super awesome'salt-run sdb.delete 'sdb://mykvstore/foobar' 在文件中使用SDB URISUSING SDB URIS IN FILES SDB URI可用于配置文件和由渲染器系统（jinja，mako…）处理的文件。 栗子: 12345678910mykey: sdb://myetcd/mykey#使用模块检索值mykey = __salt__[&apos;config.get&apos;](&apos;mykey&apos;)#Templating renderers&#123;&#123; salt[&apos;config.get&apos;](&apos;mykey&apos;) &#125;&#125;&#123;&#123; salt[&apos;sdb.get&apos;](&apos;sdb://myetcd/mykey&apos;) &#125;&#125; 非特权用户运行RUNNING THE SALT MASTER/MINION AS AN UNPRIVILEGED USER 当master未以root用户身份运行时，某些Salt的操作无法正确执行。特别是PAM外部认证系统，因为它需要root访问权来检查身份验证。 默认使用root用户运行，有些人认为使用 non-root 用户运行更安全。使用non-root 用户并不会改变master访问minion的能力。由于许多人认为以 non-root 用于运行它们不会体现真正的安全优势，因此这就是默认使用root运行的原因。 通过在master配置文件中设置用户参数来启用非特权用户。minion也有自己的用户参数，但是作为非特权用户运行minion将阻止它对用户，已安装的软件包等进行更改，除非在minion上设置访问控制（sudo等）以允许非root用户进行所需的更改。 还应该更改Salt使用到的目录和文件对于此用户的权限: 1234567#/etc/salt#/var/cache/salt#/var/log/salt#/var/run/salt#...chown -R user /etc/salt /var/cache/salt /var/log/salt /var/run/salt 由于 salt-minion 要执行由 Salt-Master 的 salt &#39;minion&#39; xxx 命令，出于安全考虑，应该使用非特权用户执行，对此用户添加 sudo 权限。 123456789101112131415161718192021222324252627282930313233343536373839404142434445# 添加普通用户, salt# 使用 /sbin/nologin 可以连接Salt Master，但是无法执行 cmd.run。 会报错: This account is currently not available.# 空密码用户是处于锁定状态，也就是无法进行登录，所以不必要担心安全问题。可以使用su saltuseradd -M -s /bin/sh salt# 查看是否锁定# passwd -S salt# salt LK 2019-02-14 0 99999 7 -1 (密码已被锁定。)# passwd -S zhang# zhang PS 1969-12-31 0 99999 7 -1 (密码已设置，使用 SHA512 算法。)# 修改对应文件夹权限# 可能之前以root运行还存在未修改到的文件，请注意日志报错chown -R salt /etc/salt /var/cache/salt /var/log/salt /var/run/salt# 添加sudovisudosalt ALL=(ALL) NOPASSWD:ALL# 修改 Master Configvim /etc/salt/masteruser: salt# 修改 Minion Configvim /etc/salt/minionuser: saltsudo_user: salt# 重启服务systemcrt restart salt-mastersystemctl restart salt-minion# 测试# 执行特权命令使用sudosalt &apos;minion-xxx&apos; cmd.run &apos;ls -l /root&apos;salt &apos;minion-xxx&apos; cmd.run &apos;sudo ls -l /root&apos; 使用CRONUSING CRON WITH SALT Salt Minion可以使用 salt-call命令启动自己的highstate: 12#minion检查与master的状态salt-call state.apply 123#USE CRON TO INITIATE A HIGHSTATE#如果希望minion定期检查master0 0 * * * salt-call state.apply HARDENING SALT本主题包含可用于保护和强化Salt环境的提示。如何最好地保护和加强您的Salt环境在很大程度上取决于您如何使用Salt，您在哪里使用Salt，您的团队结构，从何处获取数据以及您需要什么类型的访问（内部和外部）。 一般强化技巧: 限制谁可登录到Salt Master 使用SSH Key登录Salt Master 保护好SSH Key 使用堡垒机或VPN限制从Internet直接访问Salt Master 不要将Salt Master暴露在范围之外 强化系统 更新系统补丁 使用严密的防火墙规则 Salt强化技巧: 了解Salt版本可用性和补丁 使用Salt Client ACL，避免必须使用root才能执行Salt命令 使用Salt Client ACL，限制哪些用户可以使用什么命令 使用 External Pillar 将数据从外部源拉取到Salt中，以便非系统管理员可以提供配置数据，而无需访问Salt Master 使用版本控制的SLS文件，并在部署到生产环境前进行同行评审/代码审查流程 如果将Salt Master公开给外服服务，使用salt-api, SSL等来认证外部系统 利用Salt事件系统和 Reactor，允许minion向master发送信号，而无需直接访问 以non-root用户运行salt-master Daemon 使用 disable_modules 设置禁用将哪些模块加载到minions上 查看完整注释的示例master和minion配置文件 在特别敏感的minino上运行 masterless-mode， SALT TRANSPORTSalt的基本功能之一是远程执行。Salt有两个基本的信道与minion进行沟通，每个信道都需要C端(minion)和S端(master)的实现才能在Salt中工作。这些信道对将一起工作以实现通道接口所需的特定消息传递。 PUB CHANNELpub(publish) channel ，是master如何将job发送给minion。遍历发布系统的所有数据都应加密，以便只有Salt集群的成员才能解密发布。 REQ CHANNELreq channel ，是minion如何将数据发送给master。此接口主要用于获取文件和返回作业信息。在与master通信时，req channel有两个基本的接口: send: 保证消息至少被加密的基本方法，只有连接到同一个master的minions才能读取它，但不保证 minion-master 的机密性 crypted_transfer_decode_dictentry: 此方法保证 minion-master 的机密性 ZEROMQ传输 zeromq是Salt当前的默认传输 zeromq 是一种可绑定多种语言的消息库(message lib)，Zeromq实现了一个用于消息传递的套接字接口，它具有套接字类型的特定语义。 PUB CHANNEL使用zeromq pub/sub socket，默认不使用zeromq的过滤，这意味着所有发布作业都被发送到所有minions和过滤的minion端。zeromq有一个发布端过滤，可在Salt中使用 zmq_filtering 来启用。 REQ CHANNEL使用zeromq req/rep sockets，这些套接字强制执行 send/recv 模式，强制salt通过这些套接字对序列化消息。这意味着虽然接口在minion上是异步的，但是在收到第一条消息的回复之前，我们不能发送第二条消息。 TCP传输tcp transport 是使用原始tcp套接字实现Salt的通道。由于这不是使用预定义的消息库，因此将在本文档中描述协议、消息语义等。 在master和minion上将transport修改为tcp来启用tcp传输。 1transport: tcp 警告:建议在使用Syndics时，所有Masters和Minions都使用相同的传输，在高负载时，混合使用传输类型可能会导致错误。 WIRE PROTOCOLTCP上的这种实现侧重于绝对效率的灵活性，这意味着我们可以花费几个字节的线路空间来提高未来的灵活性。看起来如下: 1msgpack(&#123;&apos;head&apos;: SOMEHEADER, &apos;body&apos;: SOMEBODY&#125;) 通过这种灵活的有线协议，我们可以实现我们想要的任何消息语义，包括在单个套接字上传递的多路复用消息。 TLS支持tcp transport 允许 master/minion 通信可选地包装在TLS连接中。启用它很简单，master和minion只需先启用tcp传输，然后启用ssl。ssl选项作为dict传递，对应于传递给Python ssl.wrap_socket 函数的对应项。 简单栗子: 12345678910ssl: keyfile: &lt;path_to_keyfile&gt; certfile: &lt;path_to_certfile&gt; ssl_version: PROTOCOL_TLSv1_2#最小化配置ssl: True# Versions below 2016.11.4:ssl: &#123;&#125; CRYPTO当前实现使用与zeromq传输相同的加密。 PUB CHANNEL对于pub信道，我们发送没有 message id 的消息，远程端将其解释为单向发送。 REQ CHANNEL对于req信道，我们发送带有 message id 的消息，它允许我们在套接字上多路复用消息。 RAET传输此处先跳过，后面有需要再来学习。 docs: https://docs.saltstack.com/en/latest/topics/transports/raet/index.html 注意：RAET传输处于早期开发阶段，虽然功能齐全，但尚未就其可靠性或安全性做出承诺。至于可靠性和安全性，使用的加密已经通过审核，我们的测试显示raet是可靠的。据此，我们仍在进行更多的安全审计并提高可靠性。 MASTER TOPSdocs: https://docs.saltstack.com/en/latest/topics/master_tops/index.html 先跳过，后面有需要再来学习。 RETURNERS默认情况下，发送给Salt minions的命令的返回值将返回到Salt master，但是任何事情都可以使用结果数据完成。通过使用 Salt Returner，可以将结果数据重定向到外部数据存储以进行分析和归档。 returner interface 允许将返回数据发送到可以接收数据的任何系统(如MySQL, MongoDB, Redis…) RETURNER MODULESReturner: https://docs.saltstack.com/en/latest/ref/returners/all/index.html#all-salt-returners 当然，你也可以自己编写Returner。 docs: https://docs.saltstack.com/en/latest/ref/returners/index.html RENDERERSdocs: https://docs.saltstack.com/en/latest/ref/renderers/index.html Salt State System 通过从常用数据类型（如列表，字典和字符串）收集信息来运行。 SLS文件从它们写入的任何数据模板格式转换回要由Salt使用的Python数据类型。默认情况下，SLS文件呈现为Jinja模板，然后解析为YAML文档。由于状态系统唯一关心的是原始数据，因此SLS文件可以是任何可以设想的结构化格式。 目前支持: Jinja + YAML Mako + YAML Wempy + YAML Jinja + json Mako + json Wempy + json 可以编写渲染器以支持任何模板类型。这意味着Salt状态可以由XML、HTML、Puppet文件或任何可以转换为状态系统使用的Pythonic数据结构的格式管理。 RENDERER MODULESRenderer: https://docs.saltstack.com/en/latest/ref/renderers/all/index.html 使用USING SALT 本节介绍使用Salt时需要了解的基本组件和概念。 GRAINS 注意:Grains解析为小写字母grains 是静态的，是不经常变动的数据。在更新它之后需要刷新，可调用此模块: salt minion saltutil.refresh_modules Salt附带了一个用于获取有关底层系统的信息接口，这被称为 grains interface 。Grains 收集操作系统、域名、IP地址、kernel、OS类型、许多其它系统信息。 Grain 模块和组件可以使用 grain interface，以便在正确的系统上自动获得正确的salt minion命令。 Grains 数据是相对静态的，但如果系统信息发生变化，或者如果将新值分配给它，则 Grain数据将被刷新。 LISTING GRAINS123456#可使用 grains.ls 模块列出 grainssalt '*' grains.ls#可使用 grains.item 模块列出 grains datasalt '*' grains.items GRAINS IN THE MINION CONFIGGrains 也可在 minion 配置文件中静态配置。 1234567grains: roles: - webserver - memcache deployment: datacenter4 cabinet: 13 cab_u: 14-15 然后，可以通过Salt检索特定于服务器的状态数据，或者在State系统内部使用以进行匹配。 GRAINS IN /ETC/SALT/GRAINS 注意:如果在 minion 配置文件中指定了grains, 则忽略 /etc/salt/grains 如果你不想将自定义 grains 放置在 minion 的配置文件中，你可将它放置于 minion 端的 /etc/salt/grains 下。 1234567#注意，没有顶级项 grainsroles: - webserver - memcachedeployment: datacenter4cabinet: 13cab_u: 14-15 MATCHING GRAINS IN THE TOP FILE使用Minion上正确配置的 Grains，Pillar/Highstate 中使用的 top file 可以非常高效。 123456789#你需为此 grains 定义 role'roles:webserver': - match: grain - state0'roles:memcache': - match: grain - state1 - state2 编写grains通过执行Salt core grains code 模块中的所有公共函数（即不以下划线开头的函数），然后是任何自定义 grains 模块中的函数，得到 grain 。grain 模块中的函数必须返回一个Python字典，其中字典键是grain的名称，每个键的值是该grain的值。 自定义 grain 模块应放在名为 _grains 的子目录中，该子目录位于 master 配置文件指定的 file_roots 下(默认路径 /srv/salt/_grains)。通过 saltutil.sync_grains 或 saltutil.sync_all 将自定义 grains 分发到 minions 。 12345678#grains容易编写，只需要返回一个字典即可def yourfunction(): # initialize a grains dictionary grains = &#123;&#125; # Some code for logic that sets grains like grains['yourcustomgrain'] = True grains['anothergrain'] = 'somevalue' return grains 什么时候使用自定义的GRAIN 在添加新 grain 的时候，请考虑数据是什么，大部分 grains 数据都应该是静态数据。 如果数据可能会发生变化，请考虑使用 Pillar 或 执行模块。如果它是一组简单的键/值对，那么pillar 是一个很好的匹配。如果编译信息需要运行系统命令，那么将此信息放在执行模块中可能更好。 载入自定义的GRAIN 如果您有多个函数指定从 main 函数调用的GRAIN，请确保使用下划线添加粒度函数名称。 1234567891011#!/usr/bin/env pythondef _my_custom_grain(): my_grain = &#123;'foo': 'bar', 'hello': 'world'&#125; return my_graindef main(): # initialize a grains dictionary grains = &#123;&#125; grains['my_grains'] = _my_custom_grain() return grains 事例输出: 12345678910# salt-call --local grains.itemslocal: ---------- &lt;Snipped for brevity&gt; my_grains: ---------- foo: bar hello: world 但是，如果你没有在 my_custom_grain 函数前面添加下划线，那么该函数将在items输出中由Salt呈现两次：一次用于 my_custom_grain 调用本身，另一次用于在 main 函数中调用它。 12345678910111213141516# salt-call --local grains.itemslocal:---------- &lt;Snipped for brevity&gt; foo: bar &lt;Snipped for brevity&gt; hello: world &lt;Snipped for brevity&gt; my_grains: ---------- foo: bar hello: world 优先权PRECEDENCE Core grain 可被 custom grain所覆盖，因此应该记住它们的优先顺序： Core grains Custom grains in /etc/salt/grains Custom grains in /etc/salt/minion Custom grain modules in _grains directory, synced to minions GRAINS栗子示例: https://github.com/saltstack/salt/blob/develop/salt/grains/core.py PILLARSTORING STATIC DATA IN THE PILLAR 注意:Pillar用来存储敏感数据Pillar data 在 master 上进行编译。此外，给定minion 的 pillar data 只能由配置文件中定义的 目标minion 来访问。这使得 pillar data 可用于存储特定minion的敏感信息很有用。我觉得 salt pillar 有点类似于 K8S seceret Pillar 是一个Salt接口，用来为分布式 minions 提供 全局值(global value)。 声明Master PillarDECLARING THE MASTER PILLAR Salt Master 维护一个 pillar_roots 设置，该设置与Salt文件服务器中使用的 file_roots 的结构相匹配。然后根据 top file 中的匹配器将 pillar data 映射到minions。 master配置文件中的例子: 1234#它不能是 state tree 下的子目录pillar_roots: base: - /srv/pillar 123456#/srv/pillar/top.sls#此 top file 声明在 base 环境中，匹配所有minions的glob将具有在 `package` 中找到的 pillar data 可用于它#假设pillar_root使用上面的值，则如下packages将定位到/srv/pillar/packages.slsbase: '*': - packages 1234567#可将任意数量的匹配器添加到base环境中#/srv/pillar/top.slsbase: '*': - packages 'web*': - vim 示例显示了如何使用其它标准顶部匹配类型将特定 salt pillar data 传递给具有不同属性的minions: 12345#grains matcherdev: 'os:Debian': - match: grain - servers /srv/pillar/packages.sls, 所有minions都具有company这个键值对 123456789&#123;% if grains['os'] == 'RedHat' %&#125;apache: httpdgit: git&#123;% elif grains['os'] == 'Debian' %&#125;apache: apache2git: git-core&#123;% endif %&#125;company: Foo Industries 123456apache: pkg.installed: - name: &#123;&#123; pillar['apache'] &#125;&#125;git: pkg.installed: - name: &#123;&#123; pillar['git'] &#125;&#125; 动态Pillar环境DYNAMIC PILLAR ENVIRONMENTS 如果在 pillar_roots 中指定了环境 __env__，在 pillar_roots 中未明确指定的所有环境都将映射到 __env__ 中的目录。这使得人们可以使用基于 dynamic git branch 的环境来处理 state/pillar 文件，并使用相同的基于文件的pillar应用于所有环境。 1234567pillar_roots: __env__: - /srv/pillarext_pillar: - git: - __env__ https://example.com/git-pillar.git PILLAR NAMESPACE FLATTENING单独的 pillar SLS 文件全部合并为单个键值对字典。当在多个SLS文件中定义相同的Key时，如果不注意 pillar SLS 文件的布局方式，可能会导致意外情况发生。 栗子： 12345678910111213141516171819202122232425#top.slsbase: '*': - packages - services# packages.sls包含bind: bind9#services.sls包含bind: named#此二者相同，package之后会评估 services，所以bind9这个值会丢失#在请求 pillar bind key时，将返回 named#使用多层次的pillar文件可能会更好#packages.slspackages: bind: bind9 pillar 文件按照它们在 top file 中列出的顺序应用。因此，冲突的Key将以最后一次胜利的方式的值覆盖！ pillar字典合并PILLAR DICTIONARY MERGING 如果在多个 pillar SLS 文件中定义了相同的 pillar key，并且两个文件中的key都引用了嵌套的字典，则将以递归方式合并这些字典中的内容。 12345678910111213#top.sls与上面相同#packages.slsbind: package-name: bind9 version: 9.9.5#services.slsbind: port: 53 listen-on: any pillar字典结果如下: 1234567891011salt-call pillar.get bindlocal: ---------- listen-on: any package-name: bind9 port: 53 version: 9.9.5 包含其它pillarsINCLUDING OTHER PILLARS 与state文件类似，pillar SLS 文件可能包含其它 pillar 文件。有两种语法可实现此目的： 简单包含表单 12include: - users 完整包含表单 12345include: - users: defaults: sudo: ['bob', 'paul'] key: users 内存中的pillar数据与一经请求的pillar数据IN-MEMORY PILLAR DATA VS. ON-DEMAND PILLAR DATA 由于编译pillar数据在计算上是昂贵的，因此minion将在内存中维护pillar数据的副本，以避免在每次请求pillar数据时要求master重新编译并向其发送pillar数据的副本。这个内存中(in-mem)的pillar数据是 pillar.item, pillar.get,pillar.raw 函数返回的内容。 对于自定义编写的可执行模块，内存中的pillar数据在 __pillar__ 字典下可用。 内存中的pillar是在minion启动时生成的，可使用 saltutil.refresh_pillar 函数进行刷新。此函数触发minion异步刷新内存中的pillar数据，并始终返回None。 1salt '*' saltutil.refresh_pillar 与内存中pillar数据相反，某些动作会触发pillar数据的编译，以确保最新的pillar数据可用。这些动作包括: 运行 states 运行 pillar.items 执行这些操作不会刷新内存中的pillar数据。因此，如果pillar数据被修改，然后运行state，状态将看到更新后的pillar数据，但是pillar.item, pillar.get, pillar.raw 将不会看到更新，除非使用 saltutil.refresh_pillar 函数进行刷新。 如何处理pillar环境HOW PILLAR ENVIRONMENTS ARE HANDLED 当使用多个pillar环境时，默认行为是将来自所有环境的pillar数据合并在一起。 minion配置项 pillarenv 可用于强制minion仅考虑来自单个环境的pillar配置。这对于需要在 test/QA 环境中运行具有备用pillar数据的状态或在推送pillar数据之前测试pillar数据的更改的情况非常有用。 1234#minion config 栗子pillarenv: base#在编译内存中的pillar数据时，这将导致minion忽略除base之外的所有其它pillar环境 12#pillarenv命令行参数 可以覆盖 配置文件中的值salt '*' state.apply mystates pillarenv=testing 可以使用minion配置选项 pillarenv_from_saltenv 将 pillarenv 固定到有效的 saltenv。当此参数设置为True时，如果在运行状态时指定了特定的 saltenv，则 pillarenv将与之相同。如果指定了 pillarenv，它将覆盖此行为。 12345salt '*' state.apply mystates saltenv=devsalt '*' state.apply mystates saltenv=dev pillarenv=devsalt '*' state.apply mystates saltenv=dev pillarenv=qa 查看pillar数据VIEWING PILLAR DATA 要查看pillar数据 ，使用 pillar 执行模块。此模块包含如下函数: pillar.item: 从内存中的pillar daj中检索一个或多个key的值 pillar.items: 编译一个新的pillar数据并返回它，保持内存中的pillar数据不变。但是，如果将 pillar key 传递给此函数，则此函数的作用类似于 pillar.item pillar.raw: 从内存中返回整个pillar dictionary pillar.get: 与Python dict中的get方法相同，但有一个增强功能，可以使用冒号:作为分隔符遍历嵌套的dicts 1234#pillar嵌套栗子foo: bar: baz: qux 从SLS公式或模板中提取是这样的: 1&#123;&#123; pillar['foo']['bar']['baz'] &#125;&#125; 使用新的 pillar.get 函数可以安全地收集数据并设置默认值，如果值不可用，则允许模板回退。这使得处理嵌套结构变得更加容易。 1&#123;&#123; salt['pillar.get']('foo:bar:baz', 'qux') &#125;&#125; 在CLI设置pillar数据SETTING PILLAR DATA AT THE COMMAND LINE 注意:当通过命令行中的pillar发送敏感数据时，所有minions都将收到包含该数据的发布，并且不会限制为目标minion在某些情况下，这可能存在安全问题 pillar数据可在命令行设置: 1salt '*' state.apply pillar='&#123;"cheese": "spam"&#125;' Pillar加密PILLAR ENCRYPTION Salt的渲染器系统可用于解密pillar数据。这允许pillar项目以加密状态存储，并在编译期间解密。 加密pillar SLS 考虑如下 pillar SLS 文件: 1234567891011121314151617181920212223242526272829303132333435363738394041424344secrets: vault: foo: | -----BEGIN PGP MESSAGE----- hQEMAw2B674HRhwSAQgAhTrN8NizwUv/VunVrqa4/X8t6EUulrnhKcSeb8sZS4th W1Qz3K2NjL4lkUHCQHKZVx/VoZY7zsddBIFvvoGGfj8+2wjkEDwFmFjGE4DEsS74 ZLRFIFJC1iB/O0AiQ+oU745skQkU6OEKxqavmKMrKo3rvJ8ZCXDC470+i2/Hqrp7 +KWGmaDOO422JaSKRm5D9bQZr9oX7KqnrPG9I1+UbJyQSJdsdtquPWmeIpamEVHb VMDNQRjSezZ1yKC4kCWm3YQbBF76qTHzG1VlLF5qOzuGI9VkyvlMaLfMibriqY73 zBbPzf6Bkp2+Y9qyzuveYMmwS4sEOuZL/PetqisWe9JGAWD/O+slQ2KRu9hNww06 KMDPJRdyj5bRuBVE4hHkkP23KrYr7SuhW2vpe7O/MvWEJ9uDNegpMLhTWruGngJh iFndxegN9w== =bAuo -----END PGP MESSAGE----- bar: this was unencrypted already baz: | -----BEGIN PGP MESSAGE----- hQEMAw2B674HRhwSAQf+Ne+IfsP2IcPDrUWct8sTJrga47jQvlPCmO+7zJjOVcqz gLjUKvMajrbI/jorBWxyAbF+5E7WdG9WHHVnuoywsyTB9rbmzuPqYCJCe+ZVyqWf 9qgJ+oUjcvYIFmH3h7H68ldqbxaAUkAOQbTRHdr253wwaTIC91ZeX0SCj64HfTg7 Izwk383CRWonEktXJpientApQFSUWNeLUWagEr/YPNFA3vzpPF5/Ia9X8/z/6oO2 q+D5W5mVsns3i2HHbg2A8Y+pm4TWnH6mTSh/gdxPqssi9qIrzGQ6H1tEoFFOEq1V kJBe0izlfudqMq62XswzuRB4CYT5Iqw1c97T+1RqENJCASG0Wz8AGhinTdlU5iQl JkLKqBxcBz4L70LYWyHhYwYROJWjHgKAywX5T67ftq0wi8APuZl9olnOkwSK+wrY 1OZi =7epf -----END PGP MESSAGE----- qux: - foo - bar - | -----BEGIN PGP MESSAGE----- hQEMAw2B674HRhwSAQgAg1YCmokrweoOI1c9HO0BLamWBaFPTMblOaTo0WJLZoTS ksbQ3OJAMkrkn3BnnM/djJc5C7vNs86ZfSJ+pvE8Sp1Rhtuxh25EKMqGOn/SBedI gR6N5vGUNiIpG5Tf3DuYAMNFDUqw8uY0MyDJI+ZW3o3xrMUABzTH0ew+Piz85FDA YrVgwZfqyL+9OQuu6T66jOIdwQNRX2NPFZqvon8liZUPus5VzD8E5cAL9OPxQ3sF f7/zE91YIXUTimrv3L7eCgU1dSxKhhfvA2bEUi+AskMWFXFuETYVrIhFJAKnkFmE uZx+O9R9hADW3hM5hWHKH9/CRtb0/cC84I9oCWIQPdI+AaPtICxtsD2N8Q98hhhd 4M7I0sLZhV+4ZJqzpUsOnSpaGyfh1Zy/1d3ijJi99/l+uVHuvmMllsNmgR+ZTj0= =LrCQ -----END PGP MESSAGE----- 编译pillar数据时，结果将被解密: 1234567891011121314151617# salt myminion pillar.itemsmyminion: ---------- secrets: ---------- vault: ---------- bar: this was unencrypted already baz: rosebud foo: supersecret qux: - foo - bar - baz 必须告诉Salt要解密的pillar数据的哪部分。这使用 decrypt_pillar 配置选项完成的: 123456789decrypt_pillar: - 'secrets:vault': gpg#可以使用 ` decrypt_pillar_delimiter` 配置项指定分隔符decrypt_pillar: - 'secrets|vault': gpgdecrypt_pillar_delimiter: '|' 在CLI加密pillar数据 以下函数支持通过pillar参数在CLI上传递pillar数据: pillar.items state.apply state.highstate state.sls MASTER CONFIG IN PILLAR为方便起见，存储在Master配置文件中的数据可以在所有minion的pillar中使用。这使得服务和系统的全局配置非常容易。但如果敏感数据存储在Master配置中，则可能不需要。默认情况下禁用此选项。 12#在minion config 启用它pillar_opts: True MINION CONFIG IN PILLAR可在pillar上设置Minion配置选项。您要修改的任何选项都应位于pillar的第一级，与配置文件中的选项相同。例如，要配置MySQL Salt执行模块使用的MySQL root密码，请设置以下pillar变量: 1mysql.pass: hardtoguesspassword TARGETING MINIONS目标minions 指定哪些minions应该运行命令，或通过匹配主机名、系统信息、定义的组、甚至其组合来执行状态。 123#栗子#重新启动指定目标为web1的机器的 apache httpd，并且命令将仅在此一个minion上运行salt web1 apache.signal restart 在State的 top file 中情况也类似，如webserver.sls: 123base: 'web1': - webserver TARGETING WITH GRAINSGrains Interface 内置于Salt中，用于收集系统属性。因此，可以调用在 特定操作系统/特定内核 上运行的minions来执行函数。 12345678salt &apos;*&apos; grains.items#查看对应的grains信息#-G, Grains#使用上面的grains信息匹配目标salt -G &apos;os:Fedora&apos; test.pingsalt -G &apos;host:xxx&apos; test.ping 复合条件COMPOUND TARGETING 可以结合使用多个目标接口来确定命令目标，通过使用 and 和 or语句: 12345#默认类型为 glob#可通过 类型字母@ 来指定类型#G@, 表示Grains#E@, 表示REsalt -C &apos;G@os:Debian and webser* or E@db.*&apos; test.ping 节点组目标NODE GROUP TARGETING 对于某些情况，可以方便地使用预定义的一组minions来执行命令。这可以使用所谓的 节点组(nodegroups) 来完成。节点组允许在Master配置文件中声明预定义的复合目标，作为必须键入复杂复合表达式的一种简写。 1234nodegroups: group1: 'L@foo.domain.com,bar.domain.com,baz.domain.com and bl*.domain.com' group2: 'G@os:Debian and foo.domain.com' group3: 'G@os:Debian and N@group1' 高级的目标方法ADVANCED TARGETING METHODS url: https://docs.saltstack.com/en/latest/topics/targeting/index.html#advanced-targeting-methods 后面再来学习。 MINETHE SALT MINE Salt Mine 用于从Minions收集任意数据(arbitrary data)并将其存储在Master上，它只维护最新数据。通过 salt.modules.mine 模块将所有数据提供给所有Minions。 MINE VS GRAINS Mine数据要比Grains数据更新。Grains在非常有限的基础上更新数据，主要是静态数据。当Minions需要来自其它Minions的数据时，Mines旨在取代慢速对等发布调用。Salt Mine 运行在 Master，而不是让一个minion与其它minions联系以获取数据。可从所有minion的每个 Minion Interval 收集它，在任何给定时间产生几乎新鲜的数据，而且开销更少。 Mine函数要启用Salt Mine，需要将 mine_functions 选项应用于Minion。此选项可通过 minion config/minion pillar 来应用。它指示正在执行的函数，并传入参数。salt.module中提供了函数列表。如果没有传递参数，则必须添加一个空列表。 123456mine_functions: test.ping: [] network.ip_addrs: interface: eth0 cidr: '10.0.0.0/8'#做了网络范围限制 Mine函数别名 函数别名可用于提供友好地名称、使用意图、允许使用不同参数多次调用相同函数。传递位置参数和KV参数有不同的语法，不支持混合位置参数和KV参数。 123456789mine_functions: network.ip_addrs: [eth0] networkplus.internal_ip_addrs: [] internal_ip_addrs: mine_function: network.ip_addrs cidr: 192.168.0.0/16 ip_list: - mine_function: grains.get - ip_interfaces MINE INTERVALMine Interval 函数在Minion启动时执行，并由调度程序以给定间隔(interval)执行。 123#minion config#默认60mmine_interval: 60 MINE IN SALT-SSH由于Minions不能提供它们自己的 mine_functions 配置，所以在三个地方之一中检索指定的mine函数的参数，按以下顺序搜索: Roster data Pillar Master config RUNNERSSalt runners 是使用 salt-run 命令执行的便捷应用程序。Salt runners 与 Salt execution modules 的工作方式类似。但是，它在 Salt master本身 而不是 远程Salt minions 上执行。 Salt runner 可以是 一个简单的客户调用 或 一个复杂的应用程序。 RUNNER MODULESThe full list of runners: https://docs.saltstack.com/en/latest/ref/runners/all/index.html#all-salt-runners 编写RunnerWRITING SALT RUNNERS Salt runner 的编写方式也与 Salt execution module 类似。两者都是包含函数的Python模块，每个公共函数都是一个可以通过 salt-run 命令执行的 Runner。 1234#栗子#在runners目录中创建了名为test.py的Python模块，此模块包含一个名为foo的函数#则runner可以这样调用它salt-run test.foo runner有几种控制输出的选项: 1234#runner上的任何print语句会自动触发到master的事件总线上def a_runner(outputter=None, display_progress=False): print('Hello world') ... runner 还可以发送进度事件，该进度事件在runner执行期间显示给用户。并且如果runner的 display_progress 参数设置为 True，则也通过事件总线传递。 自定义的runner可以通过 __jid_event_.fire_event() 方法 发送自己的进程事件: 12if display_progress: __jid_event__.fire_event(&#123;'message': 'A progress message'&#125;, 'progress') 同步/异步SYNCHRONOUS VS. ASYNCHRONOUS 可以异步触发runner，这将立即返回控制。在这种情况下，如果从命令行使用 salt-run，则不会向用户显示任何输出。如果以编程方式使用，则不会返回任何结果。如果需要结果，则必须从runner到事件总线，或通过其它方式收集。 在异步模式下运行运行程序时，--progress 标志不会将输出传递给 salt-run 的CLI。但是，依然会在总线上触发进程事件。 在同步模式（默认情况），在runner完成执行之前，不会返回控制。 要添加自定义的runner，将它们放置到master config 中的 runner_dirs 配置项的位置里去。 栗子Salt 发行版的runner栗子: https://github.com/saltstack/salt/blob/develop/salt/runners SALT ENGINESSalt Engines are long-running, external system processes that leverage Salt. Engines 可以访问Salt配置，执行modules和runner(__opts__, __salt__, __runners__) Engines 在由Salt监视的单独进程中执行。如果引擎停止，会自动重启它 Engines 可运行在 Master 和Minions 上 SaltEngines 增强并取代了 外部进程(external processes) 功能。 配置Salt Engines 可在 master/minion config 中的 engines 部分进行配置: 12345engines: - logstash: host: log.my_network.com port: 5959 proto: tcp Salt Engine 必须位于 Salt path 下，或者，你可以在 master config 中添加 engines_dirs 选项让Salt去查找引擎，它的值为要搜索的目录列表。 12engines_dirs: - /home/bob/engines 编写引擎Salt source 提供了一个栗子引擎: https://github.com/saltstack/salt/blob/develop/salt/engines/test.py 要开发一个引擎，唯一的要求是你的模块实现了start()函数。 YAMLdocs: https://docs.saltstack.com/en/latest/topics/yaml/index.html SLS文件的默认渲染器是YAML渲染器。Salt使用一小部分YAML来映射非常常用的数据结构(如list/dict)。YAML渲染器的工作是采用YAML数据结构并将其编译为Python数据结构以供Salt使用。 JINJAdocs: https://docs.saltstack.com/en/latest/topics/jinja/index.html Jinja 是SLS文件中的默认模板语言。 教程索引TUTORIALS INDEX docs: https://docs.saltstack.com/en/latest/topics/tutorials/index.html TROUBLESHOOTINGdocs: https://docs.saltstack.com/en/latest/topics/troubleshooting/index.html FAQfaq: https://docs.saltstack.com/en/latest/faq.html 最佳实践SALT BEST PRACTICES docs: https://docs.saltstack.com/en/latest/topics/best_practices.html Salt的极端灵活性导致许多关于配置文件结构的问题。本节旨在通过示例和代码阐明这些要点。 通用规则GENERAL RULES 应尽可能强调模块性和清晰度 在Pillars和States之间建立明确的关系 在有意义的情况下使用变量，但不要过度使用变量 将敏感数据存储在 Pillar 中 不要在 pillar top file 中使用 grains 匹配任何敏感pillar 构造STATES和FORMULAS在构造Salt States和Formulas时，重要的是从目录结构开始。恰当的目录结构通过可视查状态名称清楚地为用户定义每个状态的功能。 构造PillarPillar 用于存储于Minions有关的安全的和不安全的数据。在设计 /srv/pillar 目录的结构时，其中包含的 Pillar 应该再次专注于清晰简洁的数据，用户可以轻松查看、修改、理解这些数据。 变量的灵活性VARIABLE FLEXIBILITY Salt允许用户在SLS文件中定义变量。创建状态变量时应为用户提供尽可能多的灵活性。这意味着应该清楚地定义变量并且易于操作，并且在未正确定义变量的情况下应该存在合理的默认值。 状态模块化MODULARITY WITHIN STATES 确保状态是模块化的是理解Salt的关键概念之一。在创建状态时，用户必须考虑重新使用状态的次数，以及它依赖于操作的次数。 存储安全数据STORING SECURE DATA 安全数据是指您不希望与访问服务器的任何人分享的任何信息，这可能包括密码、密钥… 由于连接的每个服务器都可以访问状态中的所有数据，因此将安全数据存储在Pillar中非常重要。这将确保只有那些需要此安全数据的服务器才能访问它。 远程执行REMOTE EXECUTION 在远程主机上运行 预定义的 或 任意命令 —— 也称为远程执行，是Salt的核心功能。modules 和 returners 是远程执行的两个关键要素。 Salt Execution Modules远程执行系统调用Salt执行模块来执行各种任务。这些模块提供了各种各样的功能。 执行模块EXECUTION MODULES Full list of execution modules: https://docs.saltstack.com/en/latest/ref/modules/all/index.html#all-salt-modules 编写执行模块WRITING EXECUTION MODULES Writing execution modules: https://docs.saltstack.com/en/latest/ref/modules/index.html#writing-execution-modules 教程REMOTE EXECUTION TUTORIAL Salt调用由三个主要组件组成: 1salt '&lt;target&gt;' &lt;function&gt; [arguments] TARGET 目标组件允许您过滤哪些minions应运行以下函数，默认的过滤器是glob的minion.id。 123456789101112131415161718salt '*' test.pingsalt '*.example.org' test.ping#基于Grainssalt -G 'os:Ubuntu' test.ping#基于REsalt -E 'virtmach[0-9]' test.ping#指定一个列表salt -L 'foo,bar,baz,quo' test.ping#复合目标salt -C 'G@os:Ubuntu and webser* or E@database.*' test.ping FUNCTION 函数是模块提供的一些功能。Salt附带了大量可用的功能。 1234567891011#列出minion上可用的所有函数salt '*' sys.doc#显示当前可用的minionssalt '*' test.ping#运行任意shell命令salt '*' cmd.run 'uname -a' ARGUMENTS 使用空格分割函数的参数，也支持关键字参数。 12345salt '*' cmd.exec_code python 'import sys; print sys.version'#关键字参数, kwarg=argumentsalt '*' pip.install salt timeout=5 upgrade=True 在minions上运行命令RUNNING COMMANDS ON SALT MINIONS Salt Master 上的root用户可以通过 CLI Client 控制Salt。 Salt CLI Client 使用 Salt Client API 与 Salt Master Server 进行通信。Salt Client 简单易用。使用 Salt Client 命令可以轻松发送给 minions。 使用Salt命令USING THE SALT COMMAND Salt command 需要一些组件来向 Salt minions 发送信息。需要定义目标minions，调用函数和函数需要的任何参数。 1234567891011121314151617181920212223242526272829303132333435#DEFINING THE TARGET MINIONSsalt '*foo.com' sys.docsalt -E '.*' cmd.run 'ls -l | grep foo'salt -L foo.bar.baz,quo.qux cmd.run 'ps aux | grep foo'#CALLING THE FUNCTIONsalt '*' cmd.exec_code python 'import sys; print sys.version'salt '*' pip.install salt timeout=5 upgrade=Truesalt '*' cmd.run 'echo "Hello: $FIRST_NAME"' saltenv='&#123;FIRST_NAME: "Joe"&#125;'salt '*' test.arg_repr 'echo "Hello: $FIRST_NAME"' saltenv='&#123;FIRST_NAME: "Joe"&#125;'#FINDING AVAILABLE MINION FUNCTIONSsalt '*' sys.doc#COMPOUND COMMAND EXECUTION#将一系列命令发送到单个目标，可以在单个发布中发送命令。这可以更快地收集信息组，并降低网络对重复命令的压力#复合命令执行的工作原理是发送函数和参数列表，而不是发送单个函数和参数#这些函数按照它们在命令行中定义的顺序在minion上执行，然后所有命令中的数据都在字典中返回salt '*' cmd.run,test.ping,test.echo 'cat /proc/cpuinfo',,foo#cmd.run的参数为'cat /proc/cpuinfo'#test.ping的参数为空#test.echo的参数为foo#传递的命令包含参数salt '*' cmd.run,test.ping,test.echo 'echo "1,2,3"' , , foo#还可指定参数分割符salt --args-separator=:: '*' some.fun,test.echo params with , comma :: foo EXECUTORSminion使用 执行程序(executor) 来执行模块函数(module func)。执行程序可用于修改函数行为，执行任何执行前的步骤或以特定方式执行，如 sudo执行器 。 执行程序可以作为列表传递，它们将在指令中逐个使用。如果执行程序返回 None ，则将调用下一个执行程序；如果执行程序返回非None ，则终止执行序列，并将返回的值用作结果。这是一种执行器可以控制模块执行作为过滤器的方式。 执行器列表可以通过如下方式在 minion config 中传递: 1234module_executors: - splay - direct_callsplaytime: 30 也可在CLI中操作: 1salt -t 40 --module-executors='[splay, direct_call]' --executor-opts='&#123;splaytime: 30&#125;' '*' test.ping 通过netapi调用的相同命令将如下所示: 1234567891011curl -sSk https://localhost:8000 \ -H 'Accept: application/x-yaml' \ -H 'X-Auth-Token: 697adbdc8fe971d09ae4c2a3add7248859c87079' \ -H 'Content-type: application/json' \ -d '[&#123; "client": "local", "tgt": "*", "fun": "test.ping", "module_executors": ["splay", "direct_call"], "executor_opts": &#123;"splaytime": 10&#125; &#125;]' 编写执行器WRITING SALT EXECUTORS Salt Executor 的编写方式与 Salt Execution Module 类似。执行器是一个 python 模块，放在 executors 文件夹中，包含带有如下签名的 execute 函数: 1def execute(opts, data, func, args, kwargs) 参数: opts: 包含minion配置选项的字典 data: 包含载入数据(通过 CLI/API 传递给 executor_opts )的字典 func, args, kwargs: 要执行的函数及其参数 Returns: 如果必须使用下一个执行器继续执行序列，则为 None 配置管理CONFIGURATION MANAGEMENT Salt包含一个强大而灵活的配置管理框架，该框架构建在远程执行核心之上。该框架在minions上执行，通过呈现特定于语言的状态文件，允许同时配置数万台主机。 Salt State 系统的核心是 SLS(SaLt State File)。SLS表示系统应处于的状态，并设置为以简单格式包含此数据。这通常称为配置管理(Configuration Management)。 State: Full list of states: https://docs.saltstack.com/en/latest/ref/states/all/index.html#all-salt-states Pillar System: https://docs.saltstack.com/en/latest/topics/pillar/index.html#pillar Highstate data structure: https://docs.saltstack.com/en/latest/ref/states/highstate.html#states-highstate Writing states: https://docs.saltstack.com/en/latest/ref/states/writing.html#state-modules Salt执行模块与状态模块不同，不能在SLS文件中作为状态调用。 Renderers:渲染器使用以各种语言、模板引擎、文件编写的状态配置文件。Salt的配置管理系统与语言无关。 Full list of renderers: https://docs.saltstack.com/en/latest/ref/renderers/all/index.html#all-salt-renderers Renderers: https://docs.saltstack.com/en/latest/ref/renderers/index.html#renderers Salt StatesHOW DO I USE SALT STATES? 注意:这仅仅是使用State的开始，请确保阅读了Pillar Salt State 系统的核心是 SLS(SaLt State File)。SLS表示系统应处于的状态，并设置为以简单格式包含此数据。这通常称为配置管理(Configuration Management)。 一切都是数据IT IS ALL JUST DATA 在深入研究细节之前，有助于理解SLS文件只是一个数据结构。虽然理解SLS只是一种数据结构对于理解和利用Salt States并不重要，但它应该有助于增强对实际力量所在位置的了解。 因此，SLS文件实际上只是 dictionaries, lists, strings, numbers 。通过使用这种方法，Salt可以更加灵活。当一个人写了更多的状态文件时，它就会更清楚地写出正在编写的内容。随着管理员或开发人员的需求而增长。结果便是一个易于理解的系统。 THE TOP FILE可以使用名为 top.sls 的文件将以下部分中的示例SLS文件分配给主机。 介绍大多数基础架构都是由一组机器组成，组中的每台机器都扮演着与其它机器相似的角色。这些机器组彼此协同工作以创建应用程序堆栈。为了有效地管理这些机器组，管理员需要能够为这些组创建角色。 在Salt中，包含网络上的机器组之间的映射以及应该应用于它们的配置角色的文件 称为 顶级文件 (top file)。 顶级文件(top file) 默认名为 top.sls ，之所以如此命名，是因为它们始终存在于包含状态文件的目录层次结构的顶部。该目录结构被称为 状态树(state tree)。 栗子顶级文件有三个部件: Environment: 状态树目录，包含一组用于配置系统的状态文件 Target: 一组机器，它们将应用一组状态 State files: 应用于目标的状态文件列表。每个状态文件都描述了要在目标机器上配置和强制执行的一个或多个状态 三个组件之间的关系: Environments contain targets Targets contain states 123base: # Apply SLS files from the directory root for the 'base' environment 'web*': # All minions with a minion_id that begins with 'web' - apache # Apply the state file named 'apache.sls' ENVIRONMENTS环境是包含顶级文件和一组状态文件的目录层次结构。环境可以以多种方式使用，但是并不要求它们被使用。事实上，部署Salt的最常见方式是使用一个名为 base 的环境。如果用户具有专门调用多个版本状态树的用例时，才建议用户仅创建多个环境。 入门GETTING STARTED WITH TOP FILES 每个环境都在名为 file_roots 的 salt master config 变量中定义。 1234#在常见的单一环境中，只定义了一个base环境，并且只有一个目录路径用于状态文件file_roots: base: - /srv/salt 123456#对于base环境，所有minions都会将名为core.sls和edit.sls的状态文件应用于它们#core.sls, edit.slsbase: '*': - core - edit 多环境MULTIPLE ENVIRONMENTS 在某些情况下，团队可能希望创建版本化状态树，这些树可用于在将状态部署到生产环境之前在隔离的系统集中测试Salt配置。 12345678#每个环境一个目录file_roots: dev: - /srv/salt/dev qa: - /srv/salt/qa prod: - /srv/salt/prod 顶级文件引用这些环境: 123456789101112131415dev: 'webserver*': - webserver 'db*': - dbqa: 'webserver*': - webserver 'db*': - dbprod: 'webserver*': - webserver 'db*': - db 给目标选择一个环境CHOOSING AN ENVIRONMENT TO TARGET 顶级文件用于将minion分配给环境，除非使用下面描述的方法覆盖。顶级文件中的环境必须与有效的文件服务器环境匹配，以便将任何状态应用于minion。当使用默认文件服务器后端时，环境在 file_roots 中定义。 可以使用 state.show_top 函数查看将在给定环境中应用于minion的状态。 通过在 minion config 中设置环境值(environment)，可以将Minions固定到特定环境。这样做时，minion将仅从其分配的环境中请求文件。 Note:Changed in version 2018.3.0: Renamed from environment to saltenv.If environment is used, saltenv will take its value. If both are used, environment will be ignored and saltenv will be used. 也可在运行命令(salt, salt-ssh, salt-call...)时动态传递环境值，但也并不是所有函数都接收此参数。例如: salt &#39;*&#39; state.highstate saltenv=prod 高级的minion目标ADVANCED MINION TARGETING 顶层文件中为目标表达式设置的可用匹配类型: Type Description glob Full minion ID or glob expression to match multiple minions (e.g. minion123 or minion*) pcre Perl-compatible regular expression (PCRE) matching a minion ID (e.g. web[0-3].domain.com) grain Match a grain, optionally using globbing (e.g. kernel:Linux or kernel:*BSD) grain_pcre Match a grain using PCRE (e.g. `kernel:(Free Open)BSD`) list Comma-separated list of minions (e.g. minion1,minion2,minion3) pillar Pillar match, optionally using globbing (e.g. role:webserver or role:web*) pillar_pcre Pillar match using PCRE (e.g. `role:web(server proxy)` pillar_exact Pillar match with no globbing or PCRE (e.g. role:webserver) ipcidr Subnet or IP address (e.g. 172.17.0.0/16 or 10.2.9.80) data Match values kept in the minion’s datastore (created using the data execution module) range Range cluster compound Complex expression combining multiple match types nodegroup Pre-defined compound expressions in the master config file 如何编译顶级文件HOW TOP FILES ARE COMPILED 当执行 highstate 并指定环境时，那么该环境的顶级文件是用于将状态分配给minions的唯一顶级文件，只有来自此环境的状态才会被运行。 如果没有指定环境，minion将在每个环境中查找顶级文件，并且将处理每个顶级文件以确定要在minions上运行的SLS文件。默认情况下，每个环境中的顶级文件将被合并在一起。在具有多个环境的配置中，可能会导致意外结果。所以，你可能需要修改策略使得每个环境使用其自己的顶级文件，另一种选择是将 state_top_saltenv 设置为特定环境。 123456#修改合并策略top_file_merging_strategy: same#修改环境state_top_saltenv: base 顶级文件编译栗子TOP FILE COMPILATION EXAMPLES 12345678#/etc/salt/masterfile_roots: base: - /srv/salt/base dev: - /srv/salt/dev qa: - /srv/salt/qa 12345678910#/srv/salt/base/top.slsbase: '*': - base1dev: '*': - dev1qa: '*': - qa1 1234567891011#/srv/salt/dev/top.slsbase: 'minion1': - base2dev: 'minion2': - dev2qa: '*': - qa1 - qa2 YAML格式的SLSDEFAULT DATA - YAML 默认情况下，Salt使用YAML格式来代表SLS文件。 12345678910111213# 典型的YAML格式的SLS文件# 不同Linux发行版的包管理方式不一样# 此SLS文件将确保安装名为apache的程序包，并确保apache服务正在运行apache: pkg.installed: [] service.running: - require: - pkg: apache# 第一行是一组数据的ID，称为ID声明。此ID设置需要操作的事物的名称。# 第二行和第三行包含要运行的状态模块函数，格式为: &lt;state_module&gt;.&lt;function&gt;# require为必要的声明(Requisite Statement)，确保在安装Apache包之后启动它 添加配置和用户ADDING CONFIGS AND USERS 在设置Apache之类的服务时，可能需要添加更多组件。很可能会管理Apache配置文件，并且可能需要设置用户和组。 12345678910111213141516171819202122232425262728# 使用必须的声明: watch，观察状态# require确保安装Apache后创建组，创建组之后创建用户apache: pkg.installed: [] service.running: - watch: - pkg: apache - file: /etc/httpd/conf/httpd.conf - user: apache user.present: - uid: 87 - gid: 87 - home: /var/www/html - shell: /bin/nologin - require: - group: apache group.present: - gid: 87 - require: - pkg: apache/etc/httpd/conf/httpd.conf: file.managed: - source: salt://apache/httpd.conf - user: root - group: root - mode: 644 MOVING BEYOND A SINGLE SLS以可伸缩的方式设置Salt States时，需要使用多个SLS。 上面的示例位于单个SLS文件中，但可以组合两个或多个SLS文件来构建状态树。上面的SLS文件还引用了一个奇怪的source(source: salt://apache/httpd.conf)，此文件也需要提供。SLS文件布局在Salt master的目录结构中，SLS是一个文件，要下载的文件也是一个文件。 不要再SLS名字中使用点(.) 123#salt file serverapache/init.slsapache/httpd.conf 但是，当使用多个单个SLS文件时，可以将更多组件添加到工具箱中。include语句包含其它的SLS文件，以便在其中找到的组件可以被 required, watched, demonstrated - extended。include 语句允许状态交叉链接。当SLS具有 include 语句时，它实际上扩展为包括所包含的SLS文件的内容。 考虑如下SSH示例: 123456789101112# ssh/init.slsopenssh-client: pkg.installed/etc/ssh/ssh_config: file.managed: - user: root - group: root - mode: 644 - source: salt://ssh/ssh_config - require: - pkg: openssh-client 123456789101112131415161718192021222324252627282930313233#ssh/server.sls:include: - sshopenssh-server: pkg.installedsshd: service.running: - require: - pkg: openssh-client - pkg: openssh-server - file: /etc/ssh/banner - file: /etc/ssh/sshd_config/etc/ssh/sshd_config: file.managed: - user: root - group: root - mode: 644 - source: salt://ssh/sshd_config - require: - pkg: openssh-server/etc/ssh/banner: file: - managed - user: root - group: root - mode: 644 - source: salt://ssh/banner - require: - pkg: openssh-server 状态树看起来可能是下面这个样子: 1234567apache/init.slsapache/httpd.confssh/init.slsssh/server.slsssh/bannerssh/ssh_configssh/sshd_config EXTENDINGEXTENDING INCLUDED SLS DATA 有时，需要扩展(extend) SLS。也许apache服务需要观察(watch)额外的资源，或者在某些情况下需要放置不同的文件。extend 语句不是必须的声明，它是附加的。 考虑如下栗子: 12345678910#ssh/custom-server.sls:#使用extend语句覆盖下载的banner文件，而使用新的文件include: - ssh.serverextend: /etc/ssh/banner: file: - source: salt://ssh/custom-banner 12345678910111213#python/mod_python.sls:include: - apacheextend: apache: service: - watch: - pkg: mod_pythonmod_python: pkg.installed 渲染系统UNDERSTANDING THE RENDER SYSTEM 由于SLS数据只是简单的数据，因此不需要用YAML表示。 Salt默认为YAML，因为它非常简单易学，易于使用。但是，只要提供了渲染器模块，就可以从几乎任何可以想象的介质渲染SLS文件。 默认渲染系统是 yaml_jinja 渲染器，此渲染器首先通过Jinja2模板系统传递模板，然后通过YAML解析器。这样做的好处是在创建SLS文件时可以使用完整的编程结构。其它可用的渲染器有 yaml_mako 和 yaml_wempy，纯Python的pydsl, pyobjects 渲染器。 DEBUG SALT STATESRUNNING AND DEBUGGING SALT STATES 一旦SLS中的规则准备就绪，就应对其进行测试以确保它们正常工作。使用salt &#39;*&#39; state.apply命令调用这些规则。 123456#minion#这有助于解决问题salt-call state.apply -l debugsalt-minion -l debug STATES TUTORIAL本节的目的是演示如何快速配置由Salt States管理的系统。 基本用法BASIC USAGE 本节将引导您使用Salt配置minion以运行 Apache HTTP Server 并确保服务器正在运行。 我的Salt Minions有两个跑在Docker里: centos ubuntu apache 在 ubuntu 中包名为 apache2， 在 centos 下包名为 httpd。下面的SLS文件中，可能我并没有修改，但我在测试的时候是修改了的，请大家注意。 配置状态树SETTING UP THE SALT STATE TREE States 是存储在 Master 的文本文件中，并通过 Master FileServer 按需发送给 Minions。状态文件的集合构成了 状态树(state tree) 。 要在Salt中开始使用中央状态系统，必须首先设置Salt 文件服务器。 1234#编辑 master config，并取消 file_roots 的注释file_roots: base: - /srv/salt 12#修改之后重启mastersystemctl restart salt-master 准备顶级文件PREPARING THE TOP FILE 在Master上的file_roots目录(/srv/salt)下创建顶级文件(top.sls)。 12345678#/srv/top.slsbase: '*': - webserver#env: base#target: '*'#state file: webserver.sls 创建sls文件CREATE AN SLS FILE 在顶级文件相同的目录下，创建sls文件。 12345#/srv/salt/webserver.sls#ubuntu下叫apache2, Fedora下叫httpdapache2: # ID declaration，定义要安装的包名称 pkg: # state declaration，定义要使用的Salt State - installed # function declaration，声明要调用的函数 安装软件包INSTALL THE PACKAGE 在Master上执行命令，完成之后，Minion将报告所有采取的行动和所做的所有更改的摘要。 1234567891011#salt '*' state.applysalt 'ubuntu' state.apply# salt 'ubuntu' state.apply -l debug# salt 'ubuntu' state.apply -t 60#之后便可看到状态------------Succeeded: 1 (changed=1)Failed: 0------------ SLS File Namespace 注意上面的栗子，SLS文件 webserver.sls 简称为 webserver。在 top.sls 或 include 声明中引用时，SLS文件的命名空间遵循一些简单的规则: .sls 被丢弃了(如 webserver.sls 变为 webserver) 子目录可用于更好的组织 每个子目录在Salt状态和命令行中用点(., 遵循 python import 模型）表示。如文件系统中的 webserver/dev.sls 在Salt中称为 webserver.dev 所以，不要在状态文件名中使用点(.)，否则便无法匹配 子目录中名为 init.sls 的文件指由目录路径引用。如 webserver/init.sls 指的是 webserver 如果 webserver.sls 和 webserver/init.sls 都存在，那么 webserver/init.sls 会被忽略，webserver.sls 将指的是 webserver ubuntu和centos两台minion前面我只用了Ubuntu，现在我加一台Centos，现在便有两台Minion。则现在就需要修改状态文件。 123456789101112131415161718#/srv/salt/top.slsbase: 'ubuntu': - webserver-ubuntu 'centos': - webserver-centos#/srv/salt/webserver-ubuntu.slsapache2: # ID declaration pkg: # state declaration - installed # function declaration#/srv/salt/webserver-centos.slshttpd: # ID declaration pkg: # state declaration - installed # function declaration 12345#执行# salt &apos;centos&apos; state.apply# salt &apos;ubuntu&apos; state.apply# salt &apos;*&apos; state.apply -l debugsalt &apos;*&apos; state.apply 复杂的状态和要求MORE COMPLEX STATES, REQUISITES 前面介绍了安装软件包的基础知识。现在将修改我们的 webserver.sls 文件以满足要求，并使用更多的Salt State。 调用多个状态CALL MULTIPLE STATES 你可以在ID声明下指定多个状态声明。 12345678910#webserver.sls#注意Ubuntu下和Centos下的包名不同，请记得修改#如果apache没有运行，则启动它apache: pkg.installed: [] service.running: - require: - pkg: apache#尝试在执行state.apply之前停止apache 要求其它状态REQUIRE OTHER STATES 现在Apache已经跑起来了，我们需要添加一些HTML文件来定制网站。但我们不希望在Salt安装和运行Apache之前添加HTML文件。 1234567891011121314#/srv/salt/webserver/init.sls#注意，根据前面的规则，webserver.sls还存在的话会忽略 webserver/init.sls，所以需要注释它，之后才会生效apache: pkg.installed: [] service.running: - require: - pkg: apache/var/www/index.html: # ID declaration，此栗中为自定义的HTML文件位置 file: # state declaration - managed # function - source: salt://webserver/index.html # function arg - require: # requisite declaration - pkg: apache # requisite reference /srv/salt/webserver/index.html 文件内容: 1234567&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;Salt rocks&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;This file brought to you by Salt&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt; 123456789101112#执行salt '*' state.apply------------Succeeded: 3 (changed=1)Failed: 0------------Total states#之后可在minion上进行验证，我测试是没有问题#只不过apache的Web目录为 /var/www/html require vs watch 有两个非必要的声明: require watch 并非每个state都支持 watch ，service state 支持 watch 并且将根据监控的情况重启服务。 1234567891011/etc/httpd/extra/httpd-vhosts.conf: file.managed: - source: salt://webserver/httpd-vhosts.confapache: pkg.installed: [] service.running: - watch: - file: /etc/httpd/extra/httpd-vhosts.conf - require: - pkg: apache 模板、包含、扩展TEMPLATING, INCLUDES, EXTENDS 本节将介绍sls文件的更高级模板和配置技术。 SLS模块模板TEMPLATING SLS MODULES SLS模块可能需要编程逻辑或内联执行，这通过模块模板实现。默认使用的模块模板系统是Jinja2，可修改 master config 里的 renderer 来更改它。 所有状态在初始化读取时都通过模板系统，要使用模板系统，只需添加一些模板标记即可。 带模板标记的sls模块的栗子如下: 1234&#123;% for usr in ['moe','larry','curly'] %&#125;&#123;&#123; usr &#125;&#125;: user.present&#123;% endfor %&#125; 这个模板化的sls文件一旦生成将如下所示: 123456moe: user.presentlarry: user.presentcurly: user.present 在SLS模块中使用GRAINSUSING GRAINS IN SLS MODULES 通常，需要对不同的系统应用不同的状态。Salt Grains 在模板上下文中可用。Grains可在SLS模板中使用: 1234567apache: pkg.installed: &#123;% if grains['os'] == 'RedHat' %&#125; - name: httpd &#123;% elif grains['os'] == 'Ubuntu' %&#125; - name: apache2 &#123;% endif %&#125; 在SLS模板中使用环境变量USING ENVIRONMENT VARIABLES IN SLS MODULES 你可使用 salt[&#39;environ.get&#39;](&#39;VARNAME&#39;) 在Salt State 中使用环境变量。 1MYENVVAR="world" salt-call state.template test.sls 1234Create a file with contents from an environment variable: file.managed: - name: /tmp/hello - contents: &#123;&#123; salt['environ.get']('MYENVVAR') &#125;&#125; 错误检查: 1234567891011121314&#123;% set myenvvar = salt['environ.get']('MYENVVAR') %&#125;&#123;% if myenvvar %&#125;Create a file with contents from an environment variable: file.managed: - name: /tmp/hello - contents: &#123;&#123; salt['environ.get']('MYENVVAR') &#125;&#125;&#123;% else %&#125;Fail - no environment passed in: test.fail_without_changes&#123;% endif %&#125; 从模板调用模块CALLING SALT MODULES FROM TEMPLATES 由minion加载的所有Salt模块都可在模板系统中使用。这允许在目标系统上实时收集数据。它还允许从sls模块中轻松运行shell命令。 Salt模块函数也可以在模板上下文中以salt形式提供，考虑如下栗子: 123moe: user.present: - gid: &#123;&#123; salt['file.group_to_gid']('some_group_that_exists') &#125;&#125; 12345import salt.modules.filefile.group_to_gid('some_group_that_exists')salt['network.hw_addr']('eth0') SLS模块高级语法ADVANCED SLS MODULE SYNTAX 最后，我们将介绍一些非常有用的技术，用于更复杂的状态树。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# INCLUDE DECLARATION# 使用 include 声明跨越多个文件#python/python-libs.sls:python-dateutil: pkg.installed#python/django.sls:include: - python.python-libsdjango: pkg.installed: - require: - pkg: python-dateutil# EXTEND DECLARATION# 您可以使用 extend 声明修改以前的声明# extend 与 require, watch 的工作方式不同，它附加，而不是替换必须的组件#apache/apache.sls:apache: pkg.installed#apache/mywebsite.sls:include: - apache.apacheextend: apache: service: - running - watch: - file: /etc/httpd/extra/httpd-vhosts.conf/etc/httpd/extra/httpd-vhosts.conf: file.managed: - source: salt://apache/httpd-vhosts.conf# NAME DECLARATION# 您可以使用Name声明覆盖ID声明#apache/mywebsite.sls:include: - apache.apacheextend: apache: service: - running - watch: - file: mywebsitemywebsite: file.managed: - name: /etc/httpd/extra/httpd-vhosts.conf - source: salt://apache/httpd-vhosts.conf# NAMES DECLARATION# 更强大的是使用Names声明一次覆盖多个状态的ID声明。这通常可以消除模板中循环的需要stooges: user.present: - names: - moe - larry - curly 状态工作流本节将展示如何使用salt的 file_roots 来设置工作流。在该工作流中，状态可以从 dev, 到 QA, 到 Prod 。 Salt文件服务器路径继承SALT FILESERVER PATH INHERITANCE 注意:使用多个文件服务器后端时，它们在 master config 中的 fileserver_backend 参数中列出的顺序也很重要 Salt FileServer 允许每个环境有多个根目录。Salt FileServer 将根目录列表折叠到包含每个根的所有文件的单个虚拟环境中。如果同一文件存在于多个根目录中的相同相对路径中，则最顶级匹配成功。 12345# In the master config file (/etc/salt/master)file_roots: base: - /srv/salt - /mnt/salt-nfs/base 12345#如以下两者都存在/srv/salt/foo.txt/mnt/salt-nfs/base/foo.txt#则 salt://foo.txt 将指向 /srv/salt/foo.txt 环境配置ENVIRONMENT CONFIGURATION 配置多个环境: 12345678910file_roots: base: - /srv/salt/prod qa: - /srv/salt/qa - /srv/salt/prod dev: - /srv/salt/dev - /srv/salt/qa - /srv/salt/prod 栗子1234567891011#/srv/salt/prod/top.sls:base: 'web*prod*': - webserver.foobarcomqa: 'web*qa*': - webserver.foobarcomdev: 'web*dev*': - webserver.foobarcom 状态系统参考STATE SYSTEM REFERENCE url: https://docs.saltstack.com/en/latest/ref/states/index.html Salt提供了一个接口来管理Salt minions的配置或状态，此接口是一个功能完备的机制，用于从中央管理器强制执行系统状态。 实用程序模块UTILITY MODULES - CODE REUSE IN CUSTOM MODULES 当通过编写自定义(state module, execution module) 来扩展Salt时，有时需要一种功能不仅仅适用于一种自定义模块。对于这些情况，Salt支持所谓的 实用程序模块(Utility Module)。这些模块与普通执行模块类似，但不是使用 __salt__ 在Salt代码中调用，而是使用 __utils__ 前缀。 例如，假设有以下简单实用程序模块 salt://_utils/foo.py 12345678910# -*- coding: utf-8 -*-'''My utils module---------------This module contains common functions for use in my other custom types.'''def bar(): return 'baz' 一旦同步到一个minion，这个函数将可用于其他自定义Salt类型，如下所示: 1234567891011121314151617# -*- coding: utf-8 -*-'''My awesome execution module---------------------------'''def observe_the_awesomeness(): ''' Prints information from my utility module CLI Example: .. code-block:: bash salt '*' mymodule.observe_the_awesomeness ''' return __utils__['foo.bar']() 与任何其它类型的Salt扩展一样，实用程序模块支持使用 __virtual__ 函数有条件地加载它们，或者在不同的命名空间下加载它们。例如，在 salt://_utils/ 下有一个实用程序模块。 12345678910111213141516# -*- coding: utf-8 -*-'''My utils module---------------This module contains common functions for use in my other custom types.'''def __virtual__(): ''' Load as a different name ''' return 'foo'def bar(): return 'baz' 您甚至可以以面向对象的方式编写实用程序模块: 123456789101112131415# -*- coding: utf-8 -*-'''My OOP-style utils module-------------------------This module contains common functions for use in my other custom types.'''class Foo(object): def __init__(self): pass def bar(self): return 'baz' 将它们导入其它自定义模块: 1234567891011121314151617181920# -*- coding: utf-8 -*-'''My awesome execution module---------------------------'''import mymoduledef observe_the_awesomeness(): ''' Prints information from my utility module CLI Example: .. code-block:: bash salt '*' mymodule.observe_the_awesomeness ''' foo = mymodule.Foo() return foo.bar() 当然，这些都是人为的例子，但它们应该用来展示通过编写实用程序模块开辟的一些可能性。请记住，虽然状态仍然可以访问所有执行模块，因此没有必要编写实用程序模块来使函数可用于状态和执行模块。实用程序模块的一个很好的用例是需要从自定义 输出器/返回器(outputter/returner) 以及执行模块调用相同功能的用例。 放置在 salt://_utils/ 中的实用程序模块将在运行 HighStage 时以及在调用以下任何Salt函数时同步到minions: saltutil.sync_utils saltutil.sync_all 事件和反应器EVENTS and REACTOR 事件系统Event System Salt Event System(事件系统) 用于触发事件，使第三方应用程序或外部进程能够对Salt内的行为做出反应。事件系统使用 发布-订阅模式(publish-subscribe)。 事件总线EVENT BUS 事件系统由两个主要组件组成，它们构成了事件总线的概念: Event Socket, 用于发布事件 Event Library, 可以监听事件并将事件发送到salt系统 事件发布到事件总线上，事件总线订阅者监听已发布的事件。事件总线用于进程间通信(IPC)以及Salt中的网络传输。通过 UNIX Domain Sockets 提供进程间通信。 Salt Master 和 每个Salt Minion 都有自己的 Event Bus。 事件类型EVENT TYPES SALT MASTER EVENTS这些事件是在Salt Master Event Bus 上发生的。 Salt Master Events: Authentication events Start events Key events Job events Runner Events Presence Events Cloud Events 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122#AUTHENTICATION EVENTS#salt/auth#Fired when a minion performs an authentication check with the master.Variables: id -- The minion ID. act -- The current status of the minion key: accept, pend, reject. pub -- The minion public key.#START EVENTS#salt/minion/&lt;MID&gt;/start#Fired every time a minion connects to the Salt master.Variables: id -- The minion ID.#KEY EVENTS#salt/key#Fired when accepting and rejecting minions keys on the Salt master. These happen as a result of actions undertaken by the salt-key command.Variables: id -- The minion ID. act -- The new status of the minion key: accept, delete,# JOB EVENTS# salt/job/&lt;JID&gt;/new# Fired as a new job is sent out to minions.Variables: jid -- The job ID. tgt -- The target of the job: *, a minion ID, G@os_family:RedHat, etc. tgt_type -- The type of targeting used: glob, grain, compound, etc. fun -- The function to run on minions: test.ping, network.interfaces, etc. arg -- A list of arguments to pass to the function that will be called. minions -- A list of minion IDs that Salt expects will return data for this job. user -- The name of the user that ran the command as defined in Salt&apos;s Publisher ACL or external auth.# salt/job/&lt;JID&gt;/ret/&lt;MID&gt;# Fired each time a minion returns data for a job.Variables: id -- The minion ID. jid -- The job ID. retcode -- The return code for the job. fun -- The function the minion ran. E.g., test.ping. return -- The data returned from the execution module.# salt/job/&lt;JID&gt;/prog/&lt;MID&gt;/&lt;RUN NUM&gt;# Fired each time a each function in a state run completes execution. Must be enabled using the state_events option.Variables: data -- The data returned from the state module function. id -- The minion ID. jid -- The job ID.# RUNNER EVENTS# salt/run/&lt;JID&gt;/new# Fired as a runner begins executionVariables: jid -- The job ID. fun -- The name of the runner function, with runner. prepended to it (e.g. runner.jobs.lookup_jid) fun_args -- The arguments passed to the runner function (e.g. [&apos;20160829225914848058&apos;]) user -- The user who executed the runner (e.g. root)# salt/run/&lt;JID&gt;/ret# Fired when a runner function returnsVariables: jid -- The job ID. fun -- The name of the runner function, with runner. prepended to it (e.g. runner.jobs.lookup_jid) fun_args -- The arguments passed to the runner function (e.g. [&apos;20160829225914848058&apos;]) return -- The data returned by the runner function# salt/run/&lt;JID&gt;/args# New in version 2016.11.0.# Fired by the state.orchestrate runnerVariables: name -- The ID declaration for the orchestration job (i.e. the line above salt.state, salt.function, salt.runner, etc.) type -- The type of orchestration job being run (e.g. state) tgt -- The target expression (e.g. *). Included for state and function types only. args -- The args passed to the orchestration job. Note: for state and function types, also includes a tgt_type value which shows what kind of match (glob, pcre, etc.) was used. This value was named expr_form in the 2016.11 release cycle but has been renamed to tgt_type in 2017.7.0 for consistency with other events.# PRESENCE EVENTS# salt/presence/present# Events fired on a regular interval about currently connected, newly connected, or recently disconnected minions. Requires the presence_events setting to be enabled.Variables: present -- A list of minions that are currently connected to the Salt master.# salt/presence/change# Fired when the Presence system detects new minions connect or disconnect.Variables: new -- A list of minions that have connected since the last presence event. lost -- A list of minions that have disconnected since the last presence event.# CLOUD EVENTS 监听事件LISTENING FOR EVENTS Salt事件系统在Salt中大量使用，它也被编写为与现有工具和脚本大量集成。有多种方法可以消费它: CLI REST API Python 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# FROM THE CLI# 查看事件总线的最快方法是调用 state.event runner# 此Runner旨在通过外部工具和shell脚本与事件总线进行交互salt-run state.event pretty=True# REMOTELY VIA THE REST API# Salt事件总线可使用 salt.netapi.rest_cherrypy.app.Events 作为来自外部工具或服务的 HTTP streamcurl -SsNk https://salt-api.example.com:8000/events?token=05A3# FROM PYTHON# Python脚本只能作为运行Salt的同一系统用户访问事件总线# 要监听事件，需要创建SaltEvent对象，然后需要运行 get_event 函数。它的默认轮询时间分配为5秒，可使用 wait 选项更改# SaltEvent对象需要知道 Salt Unix Socket 的保存位置，它在配置文件的 sock_dir 选项中配置，默认为 /var/run/salt/master# 如下代码将检查单一事件import salt.configimport salt.utils.eventopts = salt.config.client_config(&apos;/etc/salt/master&apos;)event = salt.utils.event.get_event( &apos;master&apos;, sock_dir=opts[&apos;sock_dir&apos;], transport=opts[&apos;transport&apos;], opts=opts)data = event.get_event()# 事件也将使用标签(tag)，标签允许通过前缀过滤事件。默认情况下，将返回所有事件。如果只需要认证标签，则只需要传递 salt/auth 标签。# 栗子data = event.get_event(wait=10, tag=&apos;salt/auth&apos;)# 检索标记以及事件数据，请传递 full=Trueevdata = event.get_event(wait=10, tag=&apos;salt/job&apos;, full=True)tag, data = evdata[&apos;tag&apos;], evdata[&apos;data&apos;]# 事件标签是可以全局的，如可在Reactor中使用fnmatch库import fnmatchimport salt.configimport salt.utils.eventopts = salt.config.client_config(&apos;/etc/salt/master&apos;)sevent = salt.utils.event.get_event( &apos;master&apos;, sock_dir=opts[&apos;sock_dir&apos;], transport=opts[&apos;transport&apos;], opts=opts)while True: ret = sevent.get_event(full=True) if ret is None: continue if fnmatch.fnmatch(ret[&apos;tag&apos;], &apos;salt/job/*/ret/*&apos;): do_something_with_job_return(ret[&apos;data&apos;]) 引发事件FIRING EVENTS 可以在Minion的本地总线上引发事件或引发用于Master的事件。 12345678910111213141516171819# 要在命令行上从Minion引发本地事件，请调用 event.fire 执行函数salt-call event.fire &apos;&#123;&quot;data&quot;: &quot;message to be sent in the event&quot;&#125;&apos; &apos;tag&apos;# 要从Minion发送一个要发送给Master的事件，请调用 event.send 执行函数。记住YAML可以在函数参数的CLI中使用salt-call event.send &apos;myco/mytag/success&apos; &apos;&#123;success: True, message: &quot;It works!&quot;&#125;&apos;# 如果一个进程正在监听Minion，那么Master上的用户可以向它发出一个事件# Job on minionimport salt.utils.eventevent = salt.utils.event.MinionEvent(**__opts__)for evdata in event.iter_events(tag=&apos;customtag/&apos;): return evdata # do your processing here...# Bashsalt minionname event.fire &apos;&#123;&quot;data&quot;: &quot;message for the minion&quot;&#125;&apos; &apos;customtag/african/unladen&apos; 从Python引发事件FIRING EVENTS FROM PYTHON 12345678910111213141516171819202122232425262728293031323334# FROM SALT EXECUTION MODULES# 在编写执行模块时，事件非常有用，以便在发生特定任务时通知Master上的各个进程# /srv/salt/_modules/my_custom_module.pydef do_something(): ''' Do something and fire an event to the master when finished CLI Example:: salt '*' my_custom_module:do_something ''' # do something! __salt__['event.send']('myco/my_custom_module/finished', &#123; 'finished': True, 'message': "The something is finished!", &#125;)# FROM CUSTOM PYTHON SCRIPTS# 从自定义Python代码中触发事件import salt.clientcaller = salt.client.Caller()caller.sminion.functions['event.send']( 'myco/myevent/success', &#123; 'success': True, 'message': "It works!", &#125;) Beacons 注意:Salt beacons 是一种事件生成机制。当信标事件(beacons events)发生时，信标利用Salt Reactor System 进行更改。 Beacons 允许您使用 Salt event system 来监控 non-Salt 进程。Beacon system 允许minion挂钩到各种系统进程并持续监视这些进程。当在系统进程中发生受监视的活动时，将在 Salt event bus 上发送可用于触发反应器(reactor)的事件。 Salt beacons 当前可以监控和发送Salt事件，用于许多系统活动，包括: 文件系统更改(file system changes) 系统负载(system load) 服务状态(service status) shell activity, such as user login 网络和磁盘使用情况(network and disk usage) BEACON MODULESBEACON MODULES LISTS: https://docs.saltstack.com/en/latest/ref/beacons/all/index.html#all-salt-beacons BEACONS 配置Salt Beacons 不需要对正在监视的系统组件进行任何更改，所有内容都使用Salt进行配置。 Beacons 通常在Minio config 中的 beacons: 段进行配置，或在 /etc/salt/minion.d/ 下的任意文件，如 /etc/salt/minion.d/beacons.conf。 123456# inotify信标仅适用于具有inotify内核支持的操作系统beacons: inotify: - files: /etc/important_file: &#123;&#125; /opt: &#123;&#125; 与Salt中的许多其它系统一样，信标系统也可以通过 Minion Pillar，Grains 或 本地配置文件进行配置。 Beacons监控间隔BEACON MONITORING INTERVAL 默认情况下，信标以1秒的间隔监控。要设置不同的间隔，请为信标提供 interval 参数。 12345678910111213141516171819beacons: inotify: - files: /etc/important_file: &#123;&#125; /opt: &#123;&#125; - interval: 5 - disable_during_state_run: True load: - averages: 1m: - 0.0 - 2.0 5m: - 0.0 - 1.5 15m: - 0.1 - 1.0 - interval: 10 避免事件循环AVOIDING EVENT LOOPS 仔细考虑在 Reactor 和 Beacons 之间创建循环的可能性非常重要。例如，可以设置一个信标，该信标监视是否读取文件，该文件又触发反应器以运行状态，该状态又反过来读取文件并重新激活信标。为了避免这些类型的场景，可以设置 disable_during_state_run 参数。 12345beacons: inotify: - files: /etc/important_file: &#123;&#125; - disable_during_state_run: True 栗子BEACON EXAMPLE 栗子配置 inotify 信标以监视文件以进行更改，然后在进行更改时将文件还原为其原始内容。 inotify 信标需要在 minion 上使用 Pyinotify，使用 salt myminion pkg.install python-inotify 进行安装。 1234567891011121314151617181920212223242526272829303132333435363738394041# 安装Pyinotifysalt &apos;centos&apos; pkg.install python-inotify# CREATE WATCHED FILEecho &apos;important_config: True&apos; &gt; /etc/salt/important_file# ADD BEACON CONFIGS TO MINION# Salt Minion /etc/salt/minion.d/beacons.confbeacons: inotify: - files: /etc/salt/important_file: mask: - modify - disable_during_state_run: True# 保存配置文件，并重新启动Minion服务# VIEW EVENTS ON THE MASTER# Salt Mastersalt-run state.event pretty=true# 此Runner显示Master在Salt事件总线上接收的事件# 要测试您在上一节中设置的信标，请对 /etc/salt/important_file 进行修改并保存# Salt Minionecho &apos;name: zhang&apos; &gt;&gt; /etc/salt/important_file# 此时Master上的Runner会显示修改信息salt/beacon/centos/inotify//etc/salt/important_file &#123; &quot;_stamp&quot;: &quot;2019-02-11T06:36:06.282180&quot;, &quot;change&quot;: &quot;IN_MODIFY&quot;, &quot;id&quot;: &quot;centos&quot; &quot;path&quot;: &quot;/etc/salt/important_file&quot;&#125; 现在，您可以创建一个反应器(Reactor)，以便在发生此事件时采取措施。 12345678910111213141516171819202122232425262728293031323334353637383940# CREATE A REACTOR# 每次修改时，此反应器都会监视的文件恢复为salt提供的内容mkdir -p /srv/reactor# /srv/reactor/revert.slsrevert-file: local.state.apply: - tgt: &#123;&#123; data[&apos;data&apos;][&apos;id&apos;] &#125;&#125; - arg: - maintain_important_file# STATE SLS# /srv/salt/maintain_important_file.slsimportant_file: file.managed: - name: /etc/important_file - contents: | important_config: True# MASTER CONFIG# 配置master以将inotify信标事件映射到 /etc/salt/master.d/reactor.conf 中的还原反应reactor: - salt/beacon/*/inotify//etc/important_file: - /srv/reactor/revert.sls# START THE SALT MASTER IN DEBUG MODE# 启用调试后，你可以在日志中看到Reactor和Event相关信息service salt-master stopsalt-master -l debug# TRIGGER THE REACTOR 编写Beacon插件WRITING BEACON PLUGINS Beacon Plugin 使用标准的 Salt Loader System，这意味着来自其它插件系统的许多构造都是正确的，例如 __virtual__ 函数。Beacon Plugin 中的重要的函数是 beacon 函数。当beacon配置为运行时，该功能将由minion重复执行。因此，beacon 功能不能阻止，并且应尽可能轻。信标还必须返回一个dicts列表，列表中的每个dict将被转换为master上的事件。 THE BEACON FUNCTION 信标系统将在模块中寻找名为 beacon 的函数。如果此函数不存在，则不会触发信标。定期调用此函数，默认情况下在minion的每次迭代时调用，每秒迭代次数可达数十至数百次。这意味着信标功能不能阻止，不应该是 CPU/IO 密集型。 信标功能将在执行的信标的配置中传递。这使得为每个被调用的信标建立灵活配置变得容易。这也是摄取信标配置的首选方式，因为它允许在 Minion 运行时通过配置 Minion Pillar 中的信标来动态更新配置。 THE BEACON RETURN 从信标返回的信息预计遵循预定义的结构。返回的值必须是字典列表（首选标准python字典，不需要有序的字典）。 这些字典代表了对Minion和Master 事件总线的个别事件。每个字典都是一个单一的事件。 dict可以包含任意键，但是tag键将被提取并添加到被触发事件的标签中。 CALLING EXECUTION MODULES 执行模块仍然是Salt中所有工作和系统交互的首选位置。因此，__salt__ 变量在信标内可用。在 __salt__ 中调用函数时要小心，虽然这是在Salt中执行复杂例程的首选方法，但并不是所有的执行模块都是用信标编写的。注意可能是CPU密集或IO限制的执行模块。请随意添加新的执行模块和功能以支持特定的信标。 反应器系统Reactor System Salt’s Reactor system 使Salt能够触发操作以响应事件。这是一个简单的接口，用于监视Salt的事件总线，以查找与给定模式匹配的事件标记，然后运行一个或多个命令作为响应。 该系统将sls文件绑定到Master上的事件标记。这些sls文件然后定义反应(reactions)。这意味着反应器系统有两个部分。首先，需要在主配置文件中设置reactor选项。 reactor选项允许事件标记与sls反应文件相关联。其次，这些反应文件使用highdata（如状态系统）来定义要执行的反应。 事件系统EVENT SYSTEM 理解反应器需要对事件系统有基本的了解。事件系统是一个本地ZeroMQ PUB接口，用于引发Salt事件。此事件总线是一个开放系统，用于发送通知Salt和其它系统有关操作的信息。 事件系统使用非常特定的标准引发事件。每个事件都有一个tag。事件标记允许对事件进行快速顶级过滤。除了标记之外，每个事件都有一个数据结构。此数据结构是一个字典，其中包含有关该事件的信息。 将事件映射到反应器SLS文件MAPPING EVENTS TO REACTOR SLS FILES Reactor SLS Files 和 Event Tag 在 Master config 中关联。默认为/etc/salt/master，也可以是/etc/salt/master.d/reactor.conf。 例如: 1234567891011reactor: # Master config section "reactor" - 'salt/minion/*/start': # Match tag "salt/minion/*/start" - /srv/reactor/start.sls # Things to do when a minion starts - /srv/reactor/monitor.sls # Other things to do - 'salt/cloud/*/destroyed': # Globs can be used to match tags - /srv/reactor/destroy/*.sls # Globs can be used to match file names - 'myco/custom/event/tag': # React to custom event tags - salt://reactor/mycustom.sls # Reactor files can come from the salt fileserver Reactor SLS文件类似于State和Pillar SLS文件。它们默认为 YAML + Jinja 模板，并传递熟悉的上下文变量。 反应类型TYPES OF REACTIONS 注意:The local and caller reaction types will likely be renamed in a future release. Name Description local Runs a remote-execution function on targeted minions runner Executes a runner function wheel Executes a wheel function on the master caller Runs a remote-execution function on a masterless minion 哪里放置反应器SLS文件WHERE TO PUT REACTOR SLS FILES Reactor SLS文件既可以来自master的本地文件，也可以来自通过 fileserver_backend 配置项启用的任何后端。可以使用 salt:// URL引用放置在Salt文件服务器中的文件，就像它们可以在状态SLS文件中一样。 建议将reactor和orchestrator SLS文件放在它们自己唯一命名的子目录中。如 orch/, orchestrate/, react/, reactor/… 编写反应器SLSWRITING REACTOR SLS 不同的反应类型是分开开发的，历史上有不同的传递参数的方法。对于 2017.7.2 release，引入了一种新的统一配置模式，该模式适用于所有反应类型。 将继续支持旧的配置架构，并且目前没有计划弃用它。 LOCAL REACTIONS 旧的配置架构要求用户在 arg 和 kwarg 参数下手动分隔位置和关键字参数。但是，这不是很用户友好，因为它强制用户区分哪种类型的参数，并确保正确排序位置参数。因此，如果主服务器正在运行受支持的版本，则建议使用新的配置模式。 以下两个例子等效:12345678910111213141516171819202122# Supported in 2017.7.2 and laterinstall_zsh: local.state.single: - tgt: 'kernel:Linux' - tgt_type: grain - args: - fun: pkg.installed - name: zsh - fromrepo: updates# Supported in all releasesinstall_zsh: local.state.single: - tgt: 'kernel:Linux' - tgt_type: grain - arg: - pkg.installed - zsh - kwarg: fromrepo: updates 这个反应等同于运行以下Salt命令: 1salt -G 'kernel:Linux' state.single pkg.installed name=zsh fromrepo=updates RUNNER REACTIONS 新旧两个例子: 123456789101112131415161718# Supported in 2017.7.2 and laterdeploy_app: runner.state.orchestrate: - args: - mods: orchestrate.deploy_app - pillar: event_tag: &#123;&#123; tag &#125;&#125; event_data: &#123;&#123; data['data']|json &#125;&#125;# Supported in all releasesdeploy_app: runner.state.orchestrate: - mods: orchestrate.deploy_app - kwarg: pillar: event_tag: &#123;&#123; tag &#125;&#125; event_data: &#123;&#123; data['data']|json &#125;&#125; 假设事件标记是foo，并且传递给事件的数据是 {&#39;bar&#39;：&#39;baz&#39;} ，那么这个反应等同于运行以下Salt命令: 1salt-run state.orchestrate mods=orchestrate.deploy_app pillar='&#123;"event_tag": "foo", "event_data": &#123;"bar": "baz"&#125;&#125;' WHEEL REACTIONS 新旧两种栗子: 123456789101112# Supported in 2017.7.2 and laterremove_key: wheel.key.delete: - args: - match: &#123;&#123; data['id'] &#125;&#125;# Supported in all releasesremove_key: wheel.key.delete: - match: &#123;&#123; data['id'] &#125;&#125; CALLER REACTIONS 注意:Masterless Minions use this Reactor 新旧两种栗子: 12345678910111213# Supported in 2017.7.2 and latertouch_file: caller.file.touch: - args: - name: /tmp/foo# Supported in all releasestouch_file: caller.file.touch: - args: - /tmp/foo 此反应等同于运行以下Salt命令: 1salt-call file.touch name=/tmp/foo 编写反应器SLS的最佳实践BEST PRACTICES FOR WRITING REACTOR SLS FILES Reactor的工作原理如下: The Salt Reactor watches Salt’s event bus for new events. Each event’s tag is matched against the list of event tags configured under the reactor section in the Salt Master config. The SLS files for any matches are rendered into a data structure that represents one or more function calls. That data structure is given to a pool of worker threads for execution. BEACONS AND REACTORSAn event initiated by a beacon, when it arrives at the master will be wrapped inside a second event, such that the data object containing the beacon information will be data[‘data’], rather than data. 手动引发事件MANUALLY FIRING AN EVENT 1234567891011121314151617# FROM THE MASTER# Use the event.send runnersalt-run event.send foo '&#123;orchestrate: refresh&#125;'# FROM THE MINION# To fire an event to the master from a minion, call event.sendsalt-call event.send foo '&#123;orchestrate: refresh&#125;'# To fire an event to the minion's local event bus, call event.fire:salt-call event.fire '&#123;orchestrate: refresh&#125;' foo# REFERENCING DATA PASSED IN EVENTS# any reactor SLS files triggered by watching the event tag foo will execute with &#123;&#123; data['data']['orchestrate'] &#125;&#125; equal to 'refresh'. 获取事件信息GETTING INFORMATION ABOUT EVENTS 确切地查看已触发的事件以及每个事件中可用的数据的最佳方法是使用 state.event runner。 123salt-run state.event pretty=True#一有变动，就会触发你所定义的动作。就会显示变动信息。 编排ORCHESTRATION ORCHESTRATE RUNNER当你想确保minion按照你想要的方式配置和运行时，对minion执行State或Highstate是完美的。但有时你想同时配置一组minions。 例如，如果要在Web服务器集群前设置负载均衡器，可以确保首先设置负载均衡器，然后在整个集群中一致地应用相同的匹配配置。编排(Orchestration) 是实现此目的的方法。 THE ORCHESTRATE RUNNER 注意:Orchestrate弃用了OverState在 Salt 2015.8.0, Orchestrate Runner 取代了 OverState system Orchestrate Runner(最初称为 state.sls runner) 提供OverState的所有功能，但有以下优点: 可以使用State中可用的所有requisites 和其它全局参数 states/functions 也适用于 salt-ssh minions Orchestrate Runner 将 Salt State system 概括为 Salt Master Context。而 state.sls, state.highstate 在每个Salt Minion上同时独立执行，state.orchestrate runner 在Master上执行。给它一个 master-level 视图并控制必要条件，如状态排序和条件。这允许了Minion的必要条件，例如在不同的Minion上排序这些应用的状态，这些状态不能够同时发生，或者如果Minion失去其中一个状态，则停止所有Minion的状态。 state.sls, state.highstate 允许你有状态地管理每个Minion，state.orchestrate runner 允许你有状态的管理整个基础结构。 编写SLS文件Orchestrate SLS 文件与 State SLS 文件存储在相同的位置。这意味着 file_roots 和 gitfs_remotes 都会影响 Reactor 和 Orchestrator 可用的SLS文件。 建议将 reactor和orchestrator SLS文件保存在各自唯一命名的子目录中，如 _orch/, orch/, _orchestrate/, react/, _reactor …这样可以避免重复命名，有助于防止混淆。 执行编排运行器EXECUTING THE ORCHESTRATE RUNNER Orchestrate Runner命令格式与 state.sls 函数相同，除了因为它是一个Runner，它是用 salt-run 而不是 salt 来执行。假设你有一个名为 /srv/salt/orch/webserver.sls 的 state.sls 文件，则在Master上运行以下命令将该应用该文件中定义的状态。 12# state.orch 是 state.orchestrate 的同义词salt-run state.orchestrate orch.webserver 无主编排MASTERLESS ORCHESTRATION 注意:无主模式编排仅支持SLS文件中的 salt.state 命令，它当前不支持 salt.function 命令。 要在 MasterLess Minions 上支持 Salt Orchetration, Orchestrate Runner 可用作执行模块。无主编排的语法完全相同，但是它使用 salt-call 命令，并且Minion Config 必须包含 file_mode: local 选项。(或者，在命令行使用 salt-call --local) 1salt-call --local state.orchestrate orch.webserver 栗子FUNCTION 要执行函数，使用 salt.function: 123456# /srv/salt/orch/cleanfoo.slscmd.run: salt.function: - tgt: '*' - arg: - rm -rf /tmp/foo 1salt-run state.orchestrate orch.cleanfoo 如果省略了 name 参数，则状态的ID将是默认名称，或者在 salt.function 的情况下，执行模块函数运行。你可以指定 name 参数以避免ID冲突: 123456789copy_some_file: salt.function: - name: file.copy - tgt: '*' - arg: - /path/to/file - /tmp/copy_of_file - kwarg: remove_existing: true FAIL FUNCTIONS 重要:Fail Function 运行在Master上，因此必须使用 salt-run saltutil.sync_modules 同步。 在编排中运行远程执行功能时，这些功能的某些返回值可能表示失败，而函数本身并未设置返回码。对于这些情况，使用 FAIL FUNCTION 允许更灵活的评估成功或失败的方法。 失败函数可以编写为自定义执行模块的一部分。该函数接受一个参数，并返回一个布尔结果。例如: 12345def check_func_result(retval): if some_condition: return True else: return False 可以在编排SLS中引用此函数，如下所示: 12345do_stuff: salt.function: - name: modname.funcname - tgt: '*' - fail_function: mymod.check_func_result STATE 要执行一个状态，使用 salt.state. 123456# /srv/salt/orch/webserver.slsinstall_nginx: salt.state: - tgt: 'web*' - sls: - nginx 1salt-run state.orchestrate orch.webserver HIGHSTATE 要运行highstate，在状态配置中设置 highstate: True。 12345# /srv/salt/orch/web_setup.slswebserver_setup: salt.state: - tgt: 'web*' - highstate: True 1salt-run state.orchestrate orch.web_setup RUNNER 要使用其它RUNNER，使用salt.runner 1234567891011# /srv/salt/orch/deploy.slscreate_instance: salt.runner: - name: cloud.profile - prof: cloud-centos - provider: cloud - instances: - server1 - opts: minion: master: master1 使用Pillar数据执行: 1salt-run state.orch orch.deploy pillar='&#123;"servers": "newsystem1", "master": "mymaster"&#125;' RETURN CODES IN RUNNER/WHEEL JOBS 状态作业(salt.state)能够通过状态返回字典(state return dictionary)上报失败。运城执行(salt.function)作业能够通过在__context__字典中设置retcode 键 来上报失败。然而，Runner(salt.runner)和 Wheel(salt.wheel)作业才会上报 False 结果。从 2018.3.0 版本开始，现在可以像在远程执行功能中一样在 Runner 和 Wheel 功能中设置 Retcode。 12345678# 自定义 Runner/Wheel 函数上报其失败，以便准确地告知作业失败def myrunner(): ... do stuff ... if some_error_condition: __context__['retcode'] = 1 return result MORE COMPLEX ORCHESTRATION 可以在单个文件中配置许多 状态/函数 ，当与完整的Requisites 和其它全局状态参数组合时，可以使用它们轻松配置复杂的编排任务。此外，状态/函数将按照定义它们的顺序执行，除非你做了配置。 1234567891011121314151617181920bootstrap_servers: salt.function: - name: cmd.run - tgt: 10.0.0.0/24 - tgt_type: ipcidr - arg: - bootstrapstorage_setup: salt.state: - tgt: 'role:storage' - tgt_type: grain - sls: ceph - require: - salt: webserver_setupwebserver_setup: salt.state: - tgt: 'web*' - highstate: True 鉴于上述配置，编排将按照如下方式执行: bootstrap将在 cidr 中的所有minion上执行 由于 storage_setup state require，因此将在ID以web开头的minion上运行Highstate 最后，ceph SLS 目标将在匹配 Grains的minion上执行 程序化解析结果PARSING RESULTS PROGRAMMATICALLY 编排作业返回一个特定数据结构的输出。根据使用的输出器，该数据结构的表示方式不同。使用编排的默认输出器，你将获得一个很好的人类可读输出。 假设以下 Orchestration SLS: 12345678910111213141516171819good_state: salt.state: - tgt: myminion - sls: - succeed_with_changesbad_state: salt.state: - tgt: myminion - sls: - fail_with_changesmymod.myfunc: salt.function: - tgt: myminionmymod.myfunc_false_result: salt.function: - tgt: myminion 默认输出器输出结果太多，这里给出链接: https://docs.saltstack.com/en/latest/topics/orchestrate/orchestrate_runner.html#parsing-results-programmatically 在没有Minion的Master上运行STATERUNNING STATES ON THE MASTER WITHOUT A MINION Orchestrate runner可用于在不使用minion的情况下在master上执行状态。 假设有 salt://foo.sls SLS文件: 1234/etc/foo.conf: file.managed: - source: salt://files/foo.conf - mode: 0600 在这种情况下，运行 salt-run state.orchestrate foo 将等同于运行 state.sls foo，但它只在Master上执行，并且不需要在Master上运行Minion个的守护进程。 这不是技术上的编排，但它在某些用例中很有用。 LIMITATIONS 使用此方法一次只能运行一个SLS目标，而使用 state.sls 允许在逗号分隔列表中传递多个SLS文件。 SALT PROXY MINIONProxy Minion 是一种开发中的Salt功能，可以控制无论出于何种原因无法运行标准 salt-minion 的设备。例如，具有API但运行专有操作系统的网络设备，具有有限的CPU或MEM的设备，可以运行Minion的设备，但出于安全原因，并不会运行。 proxy minion 不是一个 开箱即用(out of the box) 的功能。由于存爱无限数量的可控设备，因此你很可能必须自己编写接口(interface)。幸运的是，这与代理设备的实际接口一样困难。设备具有现有Python模块(如: PyUSB)的接口相对简单。用于控制具有 HTML REST接口的代码设备应该很容易。 Salt Proxy-Minion 提供了 ，允许设备 枚举(enumeration) 和 发现(discovery)， 控制(control)， 状态(status)， 远程执行(remote execution) 和 状态管理(state management) 的 管道(plumbing)。 入门下图可能有助于理解包含 Proxy-Minions 的 Salt 结构: 网络自动化NETWORK AUTOMATION Network Automation 是自动化计算机网络的 配置，管理，操作的连续过程。虽然抽象(abstraction)可以与服务器端的操作进行比较，但是存在许多特殊的挑战，最重要的是网络设备传统上是封闭的硬件，只能运行专有软件。换句话说，用户无法直接在传统网络设备上安装 salt-minion 包。由于这些原因，大多数网络设备只能通 Proxy-Minion 或使用 Salt-SSH 进行远程控制。但也有一些供应商生产了专门的设备。 命令参考COMMAND LINE REFERENCE SALT-CALL 注意:salt-call 命令从当前用户的shell上下文执行，而salt命令从系统的默认上下文执行。 salt-call 命令用于在 Minion 上本地运行模块函数(module functions)，而不是从 Master 执行它们。除非指定了 --local 选项，否则将联系Salt Master以在执行期间检索状态文件和其他资源。 123456# salt-call - salt-call Documentation#语法salt-call [options] SALTSalt允许命令在一系列远程系统上并行执行。这意味着可以轻松地控制和查询远程系统。 12345678910111213#语法salt [options] '&lt;target&gt;' &lt;function&gt; [arguments]#栗子salt '*' [ options ] sys.docsalt -E '.*' [ options ] sys.doc cmdsalt -G 'os:Arch.*' [ options ] test.pingsalt -C 'G@os:Arch.* and webserv* or G@kernel:FreeBSD' [ options ] test.ping SALT-CLOUD使用Salt在云中配置虚拟机。 1234567# salt-cloud - Salt Cloud Command# Provision virtual machines in the cloud with Salt# 语法salt-cloud [options] &lt;-m MAP | -p PROFILE&gt; &lt;NAME&gt; [NAME2 ...] SALT-CP复制文件到一个/多个 Minions。 12345678910111213141516# salt-cp - salt-cp Documentation# Copy a file or files to one or more minions# 语法salt-cp [options] '&lt;target&gt;' SOURCE DEST# 栗子salt-cp '*' [ options ] SOURCE [SOURCE2 SOURCE3 ...] DESTsalt-cp -E '.*' [ options ] SOURCE [SOURCE2 SOURCE3 ...] DESTsalt-cp -G 'os:Arch.*' [ options ] SOURCE [SOURCE2 SOURCE3 ...] DEST SALT-EXTEND用于生成Salt源代码扩展的实用程序。这用于: 添加新的执行模块，状态模块 添加单元测试到现有模块 添加集成测试到现有模块 SALT-KEYSalt-key执行用于身份验证的 salt server public keys 的简单管理。 在初始连接时，Salt Minion 将其公钥发送给 Salt Master。必须使用 Salt Master 上的 salt-key 命令接受此密钥。 Salt Minion Key 可处于以下状态: unaccepted: key正在等待被接受 accepted: key已被接受。Minion可与Master通信 rejected: 使用 salt-key 命令拒绝了key。在这种状态下，Minion 不接受 Master 的任何通信 denied: key被Master自动拒绝。当minion有重复的ID，或minion被重建或生成了新的密钥并且之前的密钥没有从Master中删除时，会发生这种情况。在这种状态下，Minion 不接受 Master 的任何通信 出现上述情况，删除对应的key，之后在接受就行了。 123456789101112131415161718# salt-key - salt-key Documentation# 语法salt-key [ options ]#常用选项-a ACCEPT, --accept=ACCEPT-A, --accept-all Accept all pending keys-r REJECT, --reject=REJECT-R, --reject-all Reject all pending keys-f FINGER, --finger=FINGER-F, --finger-all SALT-MASTERSalt master守护进程，用于控制Salt minions。 1234567# salt-master - salt-master Documentation# The Salt master daemon, used to control the Salt minions# 语法salt-master [ options ] SALT-MINIONSalt minion 守护程序，从远程Salt master接收命令。Salt minion 接收来自 Salt Master 的命令并回复所述命令的结果。 1234567# salt-minion - salt-minion Documentation# The Salt minion daemon, receives commands from a remote Salt master.# 用法salt-minion [options] SALT-PROXY从 Salt Master 接收命令，并将这些命令代理到无法运行完整 Minion 的设备。Salt Proxy Minion 从 Salt Master 接收命令，将适当的命令发送到无法运行 Minion 的设备，并回复所述命令的结果。 1234567# salt-proxy - salt-proxy Documentation# Receives commands from a Salt master and proxies these commands to devices that are unable to run a full minion.# 语法salt-proxy [ options ] SALT-RUN执行一个 Salt runner。salt-run 是执行 Salt Runners 的前端命令。 Salt Runners 是用于在 Master 上执行便捷功能的简单模块。 1234567# salt-run - salt-run Documentation# Execute a Salt runner# 语法salt-run RUNNER SALT-SSHSalt SSH允许仅使用SSH进行传输来执行salt例程。通过ssh执行salt命令和状态而不安装salt-minion。 12345678910111213# Execute salt commands and states over ssh without installing a salt-minion.# 语法salt-ssh [options] '&lt;target&gt;' &lt;function&gt; [arguments]# 栗子salt-ssh '*' [ options ] sys.docsalt-ssh -E '.*' [ options ] sys.doc cmd 入门GETTING STARTED Salt SSH使用简单，只需设置系统的基本 Roster(目标主机名册) 文件，以与标准的 salt 命令类似的方式连接并运行 salt-ssh 命令。 远程系统上需要Python（除非使用 -r 选项发送原始 ssh 命令） 在许多系统上，salt-ssh 可执行文件将位于自己的包中，通常名为 salt-ssh Salt SSH系统不会取代标准的Salt通信系统，它只提供基于SSH的替代方案，不需要ZeroMQ和远程Agent。(请注意，由于所有与Salt SSH的通信都是通过SSH执行的，因此它比使用ZeroMQ的标准Salt慢得多) 目前必须包装文件服务器操作以确保使用 salt-ssh 命令传递相关文件。However, needed fileserver wrappers are still under development ROSTERSALT SSH ROSTER Salt中的 Roster(名册) System 允许轻松定义远程minion。它是Salt中添加的可插拔系统，以促进 salt-ssh 系统。名册系统的创建是因为 salt-ssh 需要一种方法来确定哪些系统需要作为执行目标。 由于名册系统是可插拔的，因此可以轻松扩充到任何现有系统，以收集有关当前可用的服务器信息，并且通过 salt-ssh 附件。默认情况下，名册文件位于 /etc/salt/roster。 标准的Salt系统中不需要或不使用名册系统，因为Master了解目标Minion。 Roster模块链接: https://docs.saltstack.com/en/latest/ref/roster/all/index.html 如何工作HOW ROSTERS WORK 名册系统编译内部称为 targets(目标) 的数据结构。目标是关于如何连接到所述系统的目标的系统和属性的列表。Salt 名册系统的唯一要求是返回 targets 数据结构。 TARGETS DATA 可以存储在 Roster target 中的信息: 123456789101112131415161718192021222324&lt;Salt ID&gt;: # The id to reference the target system with host: # The IP address or DNS name of the remote host user: # The user to log in as passwd: # The password to use for login, if omitted, keys are used # Optional parameters port: # The target system's ssh port number sudo: # Boolean to run command via sudo sudo_user: # Str: Set this to execute Salt as a sudo user other than root. # This user must be in the same system group as the remote user # that is used to login and is specified above. Alternatively, # the user must be a super-user. tty: # Boolean: Set this option to True if sudo is also set to # True and requiretty is also set on the target system priv: # File path to ssh private key, defaults to salt-ssh.rsa # The priv can also be set to agent-forwarding to not specify # a key, but use ssh agent forwarding timeout: # Number of seconds to wait for response when establishing # an SSH connection minion_opts: # Dictionary of minion opts thin_dir: # The target system's storage directory for Salt # components. Defaults to /tmp/salt-&lt;hash&gt;. cmd_umask: # umask to enforce for the salt-call command. Should be in # octal (so for 0o077 in YAML you would do 0077, or 63) TARGET DEFAULTS master配置中的 roster_defaults 字典用于为名单中的minion上设置默认登录变量，以便不需要使用命令行参数传递相同的参数。 12345roster_defaults: user: daniel sudo: True priv: /root/.ssh/id_rsa tty: True THIN_DIR Salt 需要将独立环境上载到目标系统，默认为 /tmp/salt-&lt;hash&gt;。每个正常的系统操作都将清理此目录。 如果你需要持久化的Salt环境，如设置持久化的grains，请记得修改此值。 简单栗子12345678910111213# /etc/salt/roster# sudo NOPASSWD /etc/sudoers: fred ALL=(ALL) NOPASSWD: ALLdocker-ubuntu: host: 172.17.0.5 user: ubuntu passwd: ubuntu sudo: True thin_dir: /etc/salt/roster-thindocker-centos: host: user: xxx 部署SSH KEYDEPLOY SSH KEY FOR SALT-SSH 默认情况下，salt-ssh 将为SSH生成秘钥对，默认路径为 /etc/salt/pki/master/ssh/salt-ssh.rsa。密钥生成发生在你第一次运行 salt-ssh 时。 你可以使用 ssh-copy-id (OpenSSH密钥部署工具) 将密钥部署到Server。 123#ssh-copy-id -i /etc/salt/pki/master/ssh/salt-ssh.rsa.pub user@server.demo.comssh-copy-id -i /etc/salt/pki/master/ssh/salt-ssh.rsa.pub ubuntu@172.17.0.5 你也可以写一个简单的脚本: 123456#!/bin/bashif [ -z $1 ]; then echo $0 user@host.com exit 0fissh-copy-id -i /etc/salt/pki/master/ssh/salt-ssh.rsa.pub $1 调用SALT SSHCALLING SALT SSH salt-ssh 命令可以像 salt 命令一样轻松执行: 1salt-ssh '*' test.ping RAW SHELL CALLS 默认情况下，salt-ssh 在远程系统上运行 Salt 模块，但 salt-ssh 也可以执行 raw(原始) shell 命令: 1salt-ssh '*' -r 'ifconfig' STATES VIA SALT SSHSalt State System也可以与 salt-ssh 一起使用。状态系统在 salt-ssh 中向用户提取与使用标准 salt 时相同的接口。目的是两者(salt, salt-ssh)可以无缝配合。 TARGETING WITH SALT SSH由于 salt-ssh 中的定位方法不同，因此在撰写本文时仅支持 glob 和 regex 目标，其余的目标系统仍然需要实现。默认情况下，可以通过 salt-ssh设置 Grains。默认情况下，这些 grains 不会在重新启动后持续存在。 配置SALT SSHSalt SSH 在 Master Config 中配置。如果要使用自定义的配置文件，请使用 -c 选项传递。 非特权用户运行RUNNING SALT SSH AS NON-ROOT USER 默认情况下，Salt 从 /etc/salt/ 读取所有配置。如果使用 普通用户运行 Salt SSH，则可能报 Permission denied 错误，因此需要修改文件权限。 不建议对 Salt SSH 修改 /etc/salt/ 的权限，而是复制它们作为副本，通过 -c 来指定。当然，如果你的SaltStack本就以普通用户运行，则可以直接使用这个用户。 定义CLI选项DEFINE CLI OPTIONS WITH SALTFILE 如果您通常将CLI选项传递给 salt-ssh，则可以创建Saltfile以自动使用这些选项。因此，你可在Saltfile目录中编写内容: 1234salt-ssh: config_dir: path/to/config/dir ssh_max_procs: 30 ssh_wipe: True SALT-SYNDICSalt syndic 守护进程，一个通过高级Master的命令的特殊Minion。 12# 语法salt-syndic [ options ] SALT-UNITY围绕其它 Salt CLI 脚本的统一调用包装器。此脚本接受一个参数，该参数是其它 Salt CLI 脚本之一并调用该脚本。 12# 语法salt-unity salt '*' test.ping SALT-API用于远程连接 Salt Master 的接口。Salt API系统管理Salt Master的网络API连接器。 12345678# salt-api - salt-api Command# Start interfaces used to remotely connect to the salt master# The Salt API system manages network API connectors for the Salt Master# 语法salt-api [options] SPMSalt Package Managerspm是用于管理Salt包的前端命令。软件包通常只包含公式，表示安装在 Salt Master 上的 file_roots 中的一组SLS文件，但也可以安装Salt模块。 123456# spm - Salt Package Manager Command# 语法spm [options] &lt;function&gt; &lt;argument&gt; 模块参考SALT MODULE REFERENCE 以下包含用于扩展Salt中各种子系统的Python Module 的列表。 auth modules: https://docs.saltstack.com/en/latest/ref/auth/all/index.html beacon modules: https://docs.saltstack.com/en/latest/ref/beacons/all/index.html Cache Modules: https://docs.saltstack.com/en/latest/ref/cache/all/index.html cloud modules: https://docs.saltstack.com/en/latest/ref/clouds/all/index.html engine modules: https://docs.saltstack.com/en/latest/ref/engines/all/index.html executors modules: https://docs.saltstack.com/en/latest/ref/executors/all/index.html fileserver modules: https://docs.saltstack.com/en/latest/ref/file_server/all/index.html grains modules: https://docs.saltstack.com/en/latest/ref/grains/all/index.html execution modules: https://docs.saltstack.com/en/latest/ref/modules/all/index.html netapi modules: https://docs.saltstack.com/en/latest/ref/netapi/all/index.html output modules: https://docs.saltstack.com/en/latest/ref/output/all/index.html pillar modules: https://docs.saltstack.com/en/latest/ref/pillar/all/index.html proxy modules: https://docs.saltstack.com/en/latest/ref/proxy/all/index.html queue modules: https://docs.saltstack.com/en/latest/ref/queues/all/index.html renderer modules: https://docs.saltstack.com/en/latest/ref/renderers/all/index.html returner modules: https://docs.saltstack.com/en/latest/ref/returners/all/index.html roster modules: https://docs.saltstack.com/en/latest/ref/roster/all/index.html runner modules: https://docs.saltstack.com/en/latest/ref/runners/all/index.html sdb modules: https://docs.saltstack.com/en/latest/ref/sdb/all/index.html serializer modules: https://docs.saltstack.com/en/latest/ref/serializers/all/index.html state modules: https://docs.saltstack.com/en/latest/ref/states/all/index.html thorium modules: https://docs.saltstack.com/en/latest/ref/thorium/all/index.html master tops modules: https://docs.saltstack.com/en/latest/ref/tops/all/index.html wheel modules: https://docs.saltstack.com/en/latest/ref/wheel/all/index.html APIs 客户端APIPython client API docs: https://docs.saltstack.com/en/latest/ref/clients/index.html netapi模块docs: https://docs.saltstack.com/en/latest/topics/netapi/index.html 架构ARCHITECTURE 如果你习惯于在安装任何内容之前规划一个细节的配置管理工具。使用Salt，你可以随时切换到高可用系统结构，并田间其它组件以随时扩展部署。 由于 Single Salt Master 可以管理成千上万个系统，因此我们通常建议您首先部署 Single Salt Master，然后根据需要修改部署以实现 冗余，地理分布和扩展。 高可用功能HIGH AVAILABILITY FEATURES IN SALT Salt支持多种功能，可实现高可用性和容错性。 MULTIMASTER通过将 minion config 中的 master配置项配置为所有可用Master设备的YAML 列表，Salt Minion可以一次性连接到多个主设备。 在多主配置中，每个Master必须具有相同的加密秘钥(cryptographic keys)，并且必须分别在所有Master上接受 Minion Keys。file_roots 和 pillar_roots 的内容也需要与Salt外部的进程保持同步，这个可使用网络挂载。 MULTIMASTER WITH FAILOVER将 master_type 参数从 str 修改为 failover(故障转移) 将导致 Minion 连接到Master列表中的第一个响应的 Master Server。每个 master_alive_interval 的秒数都会检查 Minion 以确保当前的Master仍在响应。如果Master没有响应，则Minion将尝试连接到列表中的下一个Master。如果列表中的Master都用尽了，那么该列表将被回收，以防止之前响应故障的Master又恢复。请注意，master_alive_interval 必须存在于minion配置中，否则将无法调度检查主状态的定期作业。 master_type: failover 可与 master_shuffle: True 结合使用，以在所有Master上传播Minion连接。 将 Salt Syndic 添加到混合中可以创建负载均衡的Salt基础架构。如果一个Master失败，Minion会注意到并从可用列中表选择另一个Master。 SYNDICSalt Syndic 功能是一种创建不同基础架构拓扑的方法。它不是严格意义上的HA功能，但可以这样看待它。 使用 Syndic， Salt基础架构可以以某种方式进行分区，使得主控制器控制基础结构的某些部分。 SYNDIC WITH MULTIMASTERSyndic with Multimaster 允许您连接一个 Syndic 到多个主，以便在syndic配置中提供额外的冗余层。 SALT SYNDIC最基本的Salt拓扑结构由控制一组Minion节点的单个Master节点组成。使用称为Syndic的中间节点类型在构建Salt拓扑时提供了比仅由Master和Minion节点类型构造的拓扑更大的结构灵活性和可伸缩性。 一个 Syndic 节点可被认为是一个特殊的直通(passthrough)Minion节点。Syndic 节点是由 salt-syndic 守护进程和在同一系统上运行的 salt-master 守护进程组成。在 Syndic 节点上运行的 salt-master 用于控制一组较低级别的Minion节点，salt-syndic 连接较高级别的Master节点。有时称之为 Master of Master。 salt-syndic 守护进程在Master节点和本地 salt-mastr 守护进程之间中继(relay) 发布和事件。这使Master节点可以控制连接到Syndic节点上运行的 salt-master 守护程序的Minion节点。 这个功能我个人感觉有点像 多级Salt-Master-Minion。多级情况下，salt-syndic去控制下级Master，salt-master控制Minion。 配置Syndic要配置 Salt Syndic，您需要告诉 Syndic节点 及其 Master节点 关于它们彼此。每个Syndic都必须提供自己的 file_roots 目录。文件不会自动从主节点传输。 假如您的Master几点位于10.10.0.1: 123456789# /etc/salt/master# If this master will be running a salt syndic daemon, syndic_master tells# this master where to receive commands from.syndic_master: 10.10.0.1 # may be either an IP address or a hostname# Set the order_masters setting to True if this master will command lower# masters' syndic interfaces.order_masters: True 12345# /etc/salt/minion# id is shared by the salt-syndic daemon and a possible salt-minion daemon# on the Syndic nodeid: my_syndic 多主Syndic配置CONFIGURING THE SYNDIC WITH MULTIMASTER 使用 MultiMaster 的 Syndic 可以将 Syndic连接到多个Master，以便提供额外的冗余层。 首先应该在多主配置中配置更高级的Master。在Syndic上， syndic_master选项提供了更高级别的Master的列表。 由于每个Syndic都连接到每个Master，因此从任何Master发送的作业都会转发给连接到每个Syndic的Minions。 运行salt-syndic 守护进程是一个单独的进程，除了在Syndic节点上运行的 salt-master 守护进程之外，还需要启动它。Master节点在许多方面将Syndic视为普通的Minion节点。尤其是，Master需要去接受Syndic的Minion Key，就像其它Minion一样。 12345678910111213141516171819systemctl start salt-syndic# 或service salt-syndic start# 接受keysalt-key -a my_syndic# 测试salt '*' test.pingminion_1: Trueminion_2: True... Master节点现在可以控制连接到Syndic的Minion节点。 拓扑TOPOLOGY Master节点必须运行salt-master守护进程 Syndic节点必须运行salt-master, salt-syndic守护进程 Minion节点必须运行salt-minion守护进程 salt-master 守护进程发出命令时，它将被直接连接到它的Syndic和Minion节点接收 Minion节点将以通常的方式处理命令 在Syndic节点上，salt-syndic守护进程将该命令中继到salt-master守护进程，然后该节点将命令传播到与其连接的Minion和Syndic 当salt-master守护进程生成事件和作业返回数据时，它们由它们所连接的salt-master守护进程聚合，然后salt-master通过其salt-syndic守护进程将数据中继回来，直到数据到达Master节点或发出命令的Syndic节点 SYNDIC WAITsyndic_wait 是一个master config设置，它指定Salt Client 在放弃之前应等待其它Syndic检查其预期的minions列表的秒数。这个值默认为5s。 syndic_wait 是必要的，因为 Higher-Level Mater 没有办法知道 Syndic 下面的 Minions。更高级别的Master有自己的Minion列表，它们下面的Master也有自己的列表，所以Salt Client没有等待所有返回的时间。syndic_wait 选项允许所有Minion返回Salt Client的时间。 Syndic配置项除了id之外，所有配置项都在Syndic节点的Master config中: id: Syndic id (shared by the salt-syndic daemon with a potential salt-minion daemon on the same system) syndic_master: Master node IP address or hostname syndic_master_port: Master node ret_port syndic_log_file: path to the logfile (absolute or not) syndic_pidfile: path to the pidfile (absolute or not) syndic_wait: time in seconds to wait on returns from this syndic Minion数据缓存MINION DATA CACHE Minion数据缓存 包含Salt Master数据，Minion Grains 和 缓存在Master上的Minion Pillars。默认情况下，Salt使用localfs缓存模块，但可使用其它外部数据存储。 有规模的使用saltUSING SALT AT SCALE 本节的重点是构建一个Salt基础架构来处理大量的Minions。 注意:本章节适用于大型安装，虽然这些相同的设置并不会有伤害，但小型安装可能并不值得。当与Minions一起使用时，术语许多(many)指的是至少一千个；术语少数(a few)总是指500个。为简单起见，本章节将默认使用Salt使用的标准端口。 The MasterSalt Master最常见的问题是: too many minions authing at once too many minions re-authing at once too many minions re-connecting at once too many minions returning at once too few resources (CPU/DISK) 前三个问题是雷鸣般的一群(thundering herd)。为了缓解这些问题，我们必须配置在Master高负载时适当地退回Minion。第四个问题是有拥有少量硬件资源的Master和ZeroMQ中可能存在的Bug引起的。 要理解每个问题，重要的是要了解Salt的工作原理。简而言之，Salt Master为Minion提供两种服务: 作业发布者(job publisher)在端口4505上 开放端口4506接受Minion的返回 所有Minion始终在端口4505上连接到Publisher，并且如果需要，仅连接到打开的返回端口4506。在空闲的Master上，端口4505上只有连接。 TOO MANY MINIONS AUTHING 当Minion服务首次启动时，它将通过端口4505连接到Master的Publisher。如果同时启动 too many minions，这可能会导致thundering herd。这可以通过不同时启动 too many minions 来避免。 连接本身通常不是罪魁祸首，主要问题的原因更可能是Master端关于使用Master对Minion进行认证。如果Master负载过重而无法处理身份认证请求，则将其计时。然后Minion将等待 acceptance_wait_time 时间进行重试。如果设置了 acceptance_wait_time_max， 那么Minion将在每次后续重试之前通过 acceptance_wait_time 增加其等待时间，知道达到 acceptance_wait_time_max。 TOO MANY MINIONS RE-AUTHING 这很有可能发生在Salt部署的测试阶段，当所有Minion keys 都已被接受，但框架正在测试，并且参数在Salt Master Config 中经常更改。 Salt Master生成一个新的 AES key，用于某些事件加密其发布。如果遇到此问题，请删除(salt-key -d)对应 minion key 之后重新接受(salt-key -a)它。 当Master生成新的 AES key时，不会通知Minion，但会在它们收到下一个 发布作业(pub job) 中发现它。当Minion收到这样的作业后，它将与Master重新认证。由于Salt进行了Minion过滤(也就是未认证的不行)，这意味所有的Minion都会在Master下发布的下一个命令上重新认证——这就导致了另一个 thundering herd 。这可以通过以下设置来避免: 12# 在 minion config 中配置更高的值并错开重新认证尝试的数量random_reauth_delay: 60 TOO MANY MINIONS RE-CONNECTING 例如: 123456salt * disk.usage# 使用salt batch模式可避免此问题# 以下限制为50个minionsalt * disk.usage -b 50 它可能导致成千上万的Minion试图将它们的结果返回到Master的开放端口4506.如果Master无法立即处理那么多返回，也会导致大量的 syn flood。 资源太少TOO FEW RESOURCES Master资源总是应该与Master运行的环境相匹配。所以，随着Minion的不断增加，也要考虑Master的资源问题。 THE MASTER IS CPU BOUND THE MASTER IS DISK IO BOUND USE AND EXTERNAL JOB CACHE DISABLE THE JOB CACHE(非常不建议) Multi Master多主(Multi Master) 允许Salt Minion连接到冗余，并促进多个通信点的Minion。当使用多主设置时，所有Master都在热状态，并且任何活跃的Master都可用于向Minion发送命令。 如果你需要多主的故障转移(failover)，还可使用 MultiMaster-PKI配置。 Master间不共享信息，并且需要在多个Master接受keys。并且需要共享文件或使用git fileserver后端/网络文件系统来保持 file_roots 的一致性。使用可插入的minion cache modules允许存储在Master上的关于Minion的数据被复制到Minion所连接的其它Master上。 步骤概要 Create a redundant master server Copy primary master key to redundant master Start redundant master Configure minions to connect to redundant master Restart minions Accept keys on redundant master 准备冗余MasterPREPPING A REDUNDANT MASTER 注意:并没有冗余Master的逻辑上的限制 第一项任务是准备冗余Master。如果冗余Mater已在运行，请停止它。只要一个要求，即Master间共享相同的私钥。创建第一个Master时，会生成Master的key pair并放置在Master端的pki_dir目录下(默认为: /etc/salt/pki/master/)。请保持各个Master秘钥相同。 master.pem，私钥 master.pub，公钥 配置Minion由于Minion需要掌握Master相关信息，因此需要将新的Master添加到Minion Config中。 123master: - saltmaster1.example.com - saltmaster2.example.com 之后，重启Minion服务。 在Master间共享文件SHARING FILES BETWEEN MASTERS Salt不会自动在Master之间共享文件。不建议各个Master之间存在差异，强烈建议共享这些文件，解决一致性问题。者可以使用网络文件系统或git fileserver后端。 minion key file_roots pillar_roots master config 具有故障转移的Multi-PKI-MasterMULTI-MASTER-PKI TUTORIAL WITH FAILOVER 请注意，建议先熟悉salt-authentication和communication以了解本节。此处描述的所有设置都在默认的身份认证/通信过程之上。 本节将解释如何运行salt-environment，当Minion当前Master失败时在它们之间进行故障转移。 各个步骤是: setup the master(s) to sign its auth-replies setup minion(s) to verify master-public-keys enable multiple masters on minion(s) enable master-check on minion(s) Minion数据缓存MINION DATA CACHE Minion数据缓存在Salt Master上包含了 Salt Mine data， Minion grains， Minion Pillar。默认情况下，Salt使用 localfs 缓存模块将数据保存在Salt Master上的msgpack文件中。 缓存模块CACHE MODULES 缓存模块如下: consul Minion data cache plugin for Consul key/value data store. etcd_cache Minion data cache plugin for Etcd key/value data store. localfs Cache data in filesystem. mysql_cache Minion data cache plugin for MySQL database. redis_cache Redis 可插拔数据缓存PLUGGABLE DATA CACHE 虽然默认的Minion数据缓存是 localfs 缓存，但其它外部数据存储也可用于存储此数据，如 consul 模块。Salt Master 配置如下: 1cache: consul 配置Minion数据缓存CONFIGURING THE MINION DATA CACHE 默认的 localfs Minion数据缓存不需要任何配置。具有外部数据缓存模块需要在Master上进行配置。 这是一个Consul的栗子: 123456789consul.host: 127.0.0.1consul.port: 8500consul.token: Noneconsul.scheme: httpconsul.consistency: defaultconsul.dc: dc1consul.verify: Truecache: consul Salt开发DEVELOPING SALT docs: https://docs.saltstack.com/en/latest/topics/development/index.html]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>SaltStack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构]]></title>
    <url>%2F2017%2F12%2F11%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[数据结构在计算机科学中，数据结构(data structure)是计算机中存储、组织数据的方式。大多数数据结构都有数列、记录、可辨识联合、引用等基本类型构成。 数据结构意味着结构和封装，一个数据结构可被视为两个函数之间的接口，或是由数据类型联合组成的存储内容的访问方法和封装。数据结构可通过程序语言所提供的数据类型、引用及其它操作加以实现。不同种类的数据结构适合不同种类的应用，部分数据结构甚至是为了解决特定问题而设计。一个涉及良好的数据结构，应该尽可能使用较少的时间与空间资源的前提下，支持各种程序运行。 正确选择数据结构可以提高算法的效率，在计算机程序设计里，选择适当的数据结构是一项重要工作。 常见数据结构 数组(Array); 栈(Stack): 后进先出，线性表； 队列(Queue): 先进先出，线性表； 链表(Linked List): 每个节点包括两部分，一个存储数据元素的数据域，另一个存储下一个节点地址的指针域； 树(Tree)； 图(Graph)； 堆(Heap): 一种动态树形结构； 散列表(Hash)； 数组(Array)数组数据结构，是由相同类型的元素的集合所组成，分配一块连续的内存来存储。利用数组元素的索引(index)可计算出元素对应存储地址。 数组有 一维数组、二维数组、多维数组、可变长数组…。 栈(Stack)堆栈又称为栈，是计算机科学中一种特殊的串列形式的抽象资料类别。其特殊之处在于只能允许在链接串列或阵列的一端(栈顶指标:top)，进行加入数据(push)和取出数据(pop)。 由于栈数据结构只允许在一端进行操作，因为按照后进先出(LIFO, last-in-first-out)的原理运行。 队列(Queue)队列，是先进先出(FIFO, first-in-first-out)的线性表。在具体应用中通常用链表或数组来实现。队列只允许在后端(Rear)进行插入操作，在前端(Front)进行删除操作。 链表(Linked List)链表是一种线性表，但并不按线性的顺序存储数据，而是在每一个节点里存到下一个节点的指针(Pointer)。由于不必须按顺序存储，链表再插入的时候可以达到 O(1)的时间复杂度，比另一种线性表顺序表快得多。但查找一个节点或访问特定节点则需要 O(n)的时间，而顺序表相应的时间复杂度分别是 O(logn)和O(1)。 是用链表结构可以克服数组链表需要预先知道数据大小的缺点，链表可以充分利用计算机内存空间，实现灵活的内存动态管理。但是链表失去了数组随机读取的优点，同时链表由于增加了节点的指针域，空间开销比较大。 链表有单向链表、双向链表、循环链表…。链表用来构建许多其它数据结构，如栈，队列和他们的派生。 树(Tree)树是一种抽象数据类型，用来模拟具有树状结构性质的数据集合。 树有有序树、无序树（二叉树，B树，霍夫曼树）。 图(Graph)在数学上，一个图是表示物体与物体之间的关系的方法，是图论的基本研究对象。 图有：有向图、无向图、简单图、多重图。 堆(Heap)堆是计算机科学中一类特殊的数据结构的统称。堆通常是一个可以被看做一棵树的数组对象。在队列中，调度程序反复提取队列中的第一个作业并运行，因为实际情况中某些时间较短的任务将等待很长时间才能结束，或者某些不短小，但具有重要性的作业，同样应当具有优先权。堆即为解决此类问题设计的一种数据结构。 堆常用于排序，这种算法称作堆排序。 散列表(Hash)散列表也叫哈希表，是根据键(key)而直接访问在内存存储位置的数据结构。它通过计算一个关于键值的函数，将所需查询的数据映射到表中的一个位置来访问记录，这加快了查找速度。这种映射函数称为散列函数，存放记录的数组称为散列表。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB]]></title>
    <url>%2F2017%2F12%2F11%2FMongoDB%2F</url>
    <content type="text"><![CDATA[参考： MongoDB官方文档 MongoDB中文文档 https://zh.wikipedia.org/wiki/MongoDB http://www.ywnds.com/?p=5635 https://www.centos.bz/2017/08/mongodb-secure-intro-user-auth/ http://www.03sec.com/3176.shtml http://www.ywnds.com/?p=6502 http://wiki.jikexueyuan.com/project/the-little-mongodb-book/ 环境： CentOS7_x64； MongoDB3.4； NoSQLNoSQL(Not Only SQL)是对不同于传统的关系型数据库的数据库管理系统(DBMS)的统称。NoSQL不使用SQL作为查询语言，其数据结构可以不需要固定的表格模式，有横向可扩展性的特征。NoSQL用于超大规模数据的存储，这些类型的数据存储不需要固定的模式，无序多余操作就可以横向扩展。 关系型数据库的典型实现主要被调整用于执行规模小而读写频繁，或大批量极少写访问的事务。当代典型的关系型数据库在一些数据敏感的应用中表现了糟糕的性能。例如： 为巨量文档创建索引 高流量网站的网页服务 发送流媒体 NoSQL数据库分类： 类型 栗子 特点 文档存储 MongoDB 用类似json的格式存储，存储的内容是文档型的。这样就有机会对某些字段建立索引，实现关系数据库的某些功能 图形关系存储 Neo4j 图形关系的最佳存储 键-值(key-value)存储 最终一致性的键-值存储 架构性键-值存储 xxx 主机式服务 key-value硬盘存储 key-value RAM存储 MemcacheDB Redis 多数据库 OpenQM xxx 时序型数据库 Graphite xxx 对象数据库 ObjecStore 通过类似面向对象语言的语法操作数据库，通过对象的方式存取数据 列存储 HBase 顾名思义，按列存储数据。方便存储结构化和半结构化数据，方便做数据压缩，针对某一列或某几列的查询有很大的IO优势。 MongoDB简介 MongoDB(https://www.mongodb.com/)，是一种文档导向的数据库管理系统，由C++撰写而成，以此来解决应用程序开发社区中的大量现实问题。它是一种NoSQL。MongoDB支持的数据结构非常松散，是类似于json的bson格式，因此可以存储比较复杂的数据类型。MongoDB是一个开源文档数据库，提供高性能，高可用性和自动扩展。 预备知识： MongoDB中的database有和数据库一样的概念。一个MongoDB实例中，可以有零个或多个数据库，每个都作为一个高等容器，用于存储数据； MongoDB数据库中有零个或多个collections(集合)。集合类似于传统意义上的table(表)； MongoDB的集合是由零个或多个documents(文档)组成。文档类似于row(行)； MongoDB的文档由零个或多个fields(字段)组成。字段类似于columns(列)； MongoDB中Indexes(索引)扮演的角色与RDMS中一样； MongoDB中的Cursors(游标)很重要，当你向MongoDB取数据的时候，它会给你返回一个结果集的指针而不是真正的数据，这个指针我们叫它游标。我们可以用游标做任何事情，比如计数或跨行之类。 MongoDB特点不如这样认为，MongoDB是关系型数据库的一个代替案。比如用Lucene作为关系型数据库的全文检索索引的加强，或者是Redis作为持久性key-value存储。 无模式(Flexible Schema)：它不需要一个固定的模式，这使得他们比传统的数据库表要灵活更多。 写操作(Writes)：MongoDB可以胜任的一个特殊角色是在日志领域。有两点使得MongoDB的写操作非常快： 可以选择发送了写操作之后立刻返回，而无需等到操作完成； 可以控制数据持久性的写行为。 高性能(High Performance)：MongoDB提供了高性能的数据持久性。尤其是： 对嵌入式数据模型的支持减少了数据库系统上的I/O活动； 索引支持更快的查询，并且可以包含来自嵌入式文档和数组的键。 高可用(High Availability)：MongoDB的复制工具，称为副本集。提供：自动故障转移和数据冗余。 持久性(Durability)：在MongoDB中，日志(Journaling)是默认启动的，该功能允许快速恢复服务器，比如遭遇到了服务器奔溃或停电的问题。 丰富的查询语言(Rich Query Language)：MongoDB支持丰富的查询语言来支持读写操作(CRUD)，数据聚合(Data Aggregation)，全文搜索(Text Search)。 水平可伸缩性(Horizontal Scalability)：MongoDB提供了横向可伸缩性。 支持多个存储引擎(Support for Multiple Storage Engines)：在MongoDB3.2以后默认引擎为: WiredTiger Storage Engine，允许第三方为MongoDB开发存储引擎。 database和collectionMongoDB stores BSON documents. databasesIn MongoDB,databases hold collections of documents.如果一个数据库不存在，当你第一次存储数据时，MongoDB会自动创建数据库。这意味着可以切换到不存在的数据库。 默认情况下，集合不要求其文档具有相同的模式；文档不要求具有相同的字段集；字段的数据类型在集合的文档间可以有所不同。 123456789#select a dbuse &lt;db&gt;#create a dbuse newdbdb.newcoll.insert(&#123;name:'zhang'&#125;)db.newcoll.insert(&#123;filed01:'filed01', filed02:'filed02', filed03:'filed03', filed04:'filed04'&#125;)db.newcoll.insert(&#123;groups: ['A', 'B', 'C']&#125;)db.newcoll.find().pretty() collectionMongoDB stores documents in collections.collection类似于关系型数据库中的table。 12db.coll02.insert(&#123;x:1&#125;)db.coll03.createIndex(&#123;y:1&#125;) 显式创建(explicit creation)MongoDB提供了db.createCollection()方法来显式创建一个附带各种选项的集合。如设置document最大大小，文件验证规则等选项。如果不需要指定这些选项，就不需要使用显式创建集合，而直接向集合中插入数据即可。修改collection选项，使用collMod方法。 视图(View)视图的定义是公开的，视图的解释操作将包括定义视图的管道。因此，避免直接引用视图定义中的敏感字段和值。 创建/删除视图： 12345678910db.runCommand(&#123; crete: &lt;view&gt;, viewOn: &lt;source&gt;, pipeline: &lt;pipeline&gt;&#125;)db.createView(&lt;view&gt;, &lt;source&gt;, &lt;pipeline&gt;, &lt;collation&gt;)db.collection.drop() 视图行为： 视图存在以下行为： 视图只读，视图上的写操作将会出错； 视图使用底层集合的索引； 如果视图的基础集合被分割，视图也被认为可分割； 不能重命名视图； 视图上的字符串使用视图的默认排序规则。 限制集限制集是固定大小的集合支持基于文档插入顺序的高吞吐率的插入、检索、删除操作。限制集工作在某种程度上类似于循环缓冲区：一旦一个文档填满分配给它的空间，它将通过在限制集中重写老文档来给新文档让出空间。 行为插入顺序限制集合能够保留插入顺序。因此，查询并不需要索引来保证以插入顺序来返回文档。减少了索引的消耗，限制集可以支持更高的插入吞吐量。 最旧文档的自动删除为了给新文档腾出空间，再不需要脚本或显示删除操作的前提下，限制集自动删除集合中最旧的文档。 例如replication set中的oplog.rs集合。考虑潜在用于集合封顶的用例： 存储高容量系统生成的日志信息。没有索引的情况下向限制集中插入文档的速度接近于直接在文件系统中写日志的速度； 在限制集中缓存少量的数据。 _id索引限制集合有一个_id字段并且默认在_id字段上创建索引。 限制和建议更新更新限制集中的文档，创建一个索引保证这些更新操作不需要进行集合扫描。 文档大小一个更新或替换操作改变了文档大小，操作将会失败。 文档删除不能从一个限制集中删除文档！为了从一个集合中删除所有文档，使用drop()方法来删除集合然后重新创建限制集。 分片不能对限制集分片。 查询效率用自然顺序监视限制集中大部分最近插入的文档。 程序创建一个限制集必须使用db.createCollection()方法创建限制集。且必须指定以字节为单位的最大集合大小。MongoDB将会预先分配集合。另外，可为限制集指定最大文档数据，用max字段。 大小参数是必须的。MongoDB会在达到最大限制前删除旧的文件。 1234567use &lt;db&gt;#限制集大小db.createCollection("log", &#123;capped: true, size: 1000000&#125;)#限制集和文档大小db.createCollection("log", &#123;capped: true, size: 5242880, max: 5000&#125;) 查询一个限制集如果没有对限制集指定排序，则MongoDB的结果顺序和插入顺序相同。 检查一个集合是否是限制集isCapped()方法 123db.collection.isCapped()#db.coll01.isCapped()#false 将集合转换为限制集convertToCapped()方法 123db.runCommand(&#123;"covertToCapped": "coll01", size: 1000000&#125;);#db.coll01.isCapped()#true 在规定的时间周期之后将自动移除数据通过设置MongoDB的TTL时集合中的数据过期。TTL collection与限制集不兼容。 Tailable游标类似于Unix中的taif -f documentMongoDB存储数据记录为BSON文档。BSON是JSON文档的二进制表示，因此它包含比JSON更多的数据类型。 document structureMongoDB字段由key-value对组成。字段值可以是任一BSON数据类型，包括其他文档，数组，阵列。 1234567891011121314151617181920212223&#123; filed1: value1; filed2: value2; ... filedN: valueN&#125;#data typevar mydoc =&#123; _id: ObjectId("5099803df3f4948bd2f98391"), name: &#123; first: "Alan", last: "Turing" &#125;, birth: new Date('Jun 23, 1912'), death: new Date('Jun 07, 1954'), contribs: [ "Turing machine", "Turing test", "Turingery" ], views : NumberLong(1250000)&#125;_id是ObjectID；name是嵌入式文档；birth是日期类型；contribs是字符串数组；view是NumberLong类型。 字段名(field name)字段名是字符串。document对field name有以下限制: 字段名称_id保留用作主键(primary key)，它的值在collection中必须唯一，不可变。它的类型可以是数组外的任何类型； 字段名称不能以$字符开头； 字段名称不能包含.字符； 字段名称不能包含null字符。 BSON documents 可能有多个字段名称相同的字段。然而，大多数的MongoDB Interface，MongoDB结构（如hash表），并不支持重复字段名称。如果需要操作具有多个相同名称字段的文档，请参考 mongo driver。 一些由内部MongoDB进程创建的documents可能会有重复的字段，但是没有MongoDB进程会向一个已经存在的user document中添加重复字段。 字段值限制(field value limit)For indexed collections，indexed fields的值有一个最大索引值长度限制(maximum index key length)。 圆点表示法(dot notation)MongoDB使用圆点表示法来访问数组中的元素，访问嵌套文档中的字段。 数组(array)通过基于0的索引位置来指定或访问数组中的元素。 123456789&lt;array&gt;.&lt;index&gt;&#123; contribs: [ 'Turing machine', 'Turing test', 'Turingery' ]&#125;#contribs.0 == 'Turing machine'#contribs.1 == 'Turing test'#contribs.2 == 'Turingery' 嵌套文档(embedded documents)通过圆点表示法来指定或访问嵌套文档中的字段。 123456789&lt;embedded document&gt;.&lt;field&gt;&#123; name: &#123; first: 'AAA', last: 'ZZZ'&#125;, contact: &#123; phone: &#123; type: 'cell', number: '1-22-333' &#125;&#125;&#125;#name.first == 'AAA'#contact.phone.number == '1-22-333' 文档限制(document limitation)文档大小限制(size limit)BSON document最大size为：16MB。 最大document size确保一个单一document不能使用过量的RAM，或是传输期间的过量带宽。MongoDB提供了GridFS API，用来保存超过最大size的文档。 文档字段序列(field order)MongoDB用write operation来作为document的序列，除了一下情况： _id字段总是document中的第一个field； 包含重命名的update操作，会导致document中的field重新排序。 _id字段在MongoDB中，每个保存在collection中的document都要求一个唯一的_id，用以担任主键(primary key)。如果向document中insert数据是忽略的_id字段，则MongoDB driver会为_id字段自动生成一个ObjectID。 1234567#默认生成_iddb.coll01.insert(&#123;name: 'zhang', sex: 'man', hobby: 'woman'&#125;)# "_id" : ObjectId("5a32166ebf2c986e8106f891")#自定义_iddb.coll01.insert(&#123;_id:'ZhangCustomDefine', name:'zhang', sex: 'man', arr: [0, 1, 2, 3], emmdoc: &#123;emm01:'Emm01', emm02: 'Emm02', emm03: 'Emmo3'&#125;&#125;)#"_id" : "ZhangCustomDefine" _id字段有以下行为和约束： 默认情况下，MongoDB在collection创建document时，会创建一个唯一的_id作为索引； _id字段总是document中的第一个字段。如果server接受的document中_id不在第一个字段，那么Server会移动_id到第一个字段； _id字段的数据类型除了数组外的任意BSON 数据类型； 不要存储BSON正则表达式的类型在_id字段中。 _id字段值的常用选项： 使用ObjectId； 使用了自然唯一的标识符，节省了空间并避免了额外的索引； 生成一个自动递增的数字； 在应用程序代码中生成UUID； 文档结构的其他用途查询过滤文档(query filter)使用:表达式来指定条件。 12345&#123; &lt;field1&gt;: &lt;value1&gt; &lt;field2&gt;: &lt;value2&gt; ...&#125; 更新特定文档(update)使用db.collection.update()操作更新数据。 BSON类型BSON是一个用来存储document和MongoDB进行远程调用的二进制序列化格式。BSON支持以下数据类型作为文档中的值。每个数据类型都有一个相应的数字和字符串别名，可与$type操作符一起使用，以便按照bson类型查询文档。 Type Number Alias double 1 “double” 字符串 2 “string” 对象 3 “object” 数组 4 “array” 二进制数据 5 “binData” 未定义 6 “undefined” ObjectId 7 “objectId” Boolean 8 “bool” 日期 9 “date” 空 10 “null” 正则表达式 11 “regex” DBPointer 12 “dbPointer” JavaScript 13 “javascript” 符号 14 “symbol” JavaScript(带范围) 15 “javascriptWithScope” 32位整数 16 “int” 时间戳 17 “timestamp” 64位整数 18 “long” Decimal128 19 “decimal” Min key -1 “minKey” Max key 127 — 如果你想要将BSON转换为JSON，参考Extended JSON。 ObjectIdObjcetIds are small, likely unique, fast to generate, and ordered.ObjectIds由12个字节组成，其中前4个字节是反映ObjectId创建的时间戳(timestamp)。 一个4字节的值，代表从Unix纪元开始的秒数； 一个3字节的机器标识符； 日期对象排在时间戳对象之前； MongoDB在比较过程中，会把一些类型看成相等。 栗子：{ &quot;_id&quot; : ObjectId(&quot;5a33354068b6c5e5fb6f213f&quot;), &quot;name&quot; : &quot;ZHANG&quot; }。 在mongo shell中，可以访问ObjectId的创建时间，使用ObjectId.getTimestamp()方法。在_id字段中存储的ObjectId值的排序，大致相当于按其创建时间排序。ObjectId的值顺序与生成时间之间并不严格。 字符串BSON字符串都是UTF-8编码。一般来说，每种编程语言的驱动程序在序列化和反序列化BSON的时候，都会从语言的字符串形式转化为UTF-8。这就使得使用BSON字符串简单存储大多数国际字符变为可能。 时间戳BSON有一个特殊的时间戳类型用于MongoDB内部使用，与普通的日期类型无关。而在应用开发中可使用BSON日期类型。时间戳值是一个64位的值： 前32位是与Unix纪元相差的秒数，后32位是在某秒总操作的一个递增的序列数。 在MongoDB复制集中，oplog有一个ts字段。这个字段的值使用BSON时间戳表示了操作时间。 1234db.coll02.insert( &#123; ts: new Timestamp() &#125; )db.coll02.find()#&#123; "_id" : ObjectId("5a333e3f68b6c5e5fb6f2141"), "ts" : Timestamp(1513307711, 1) &#125; 日期BSON日期是一个64位整数，表示利当前Unix新纪元(1970.01.01)的毫秒数，可到未来的2.9亿年。BSON日期类型是有符号的，负数表示1970年之前的时间。 123456var date1 = new Date()var date2 = ISODate()#date1#date2#ISODate(&quot;2017-12-15T03:28:08.227Z&quot;) MongoDB Extended JSONJSON只能表示BSON类型的一个子集。为了保留类型信息，MongoDB对JSON格式添加了如下扩展性： Strict mode： Any JSON parser can parse these strict mode representations as key/value pairs; mongo shell mode： The MongoDB internal JSON parser and the mongo shell can parse this mode. 多种数据类型的表示取决于JSON解析的上下文！ 解析器(parser)和支持的格式(format)Input in Strict mode如下可在严格模式下被解析并识别类型信息。 REST Interface; mongo import; –query; MongoDB Compass. Input in mongo shell mode如下可在严格模式下被解析并识别类型信息。 REST Interface; mongo import; --query; MongoDB Compass Output in Strict modemongoexport, REST, HTTP Interfaces. Output in mongo shell modebsondump BSON数据类型和关联表示Binary Strict mode mongo shell mode { “$binary”: ““, “$type”: ““ } BinData ( , ) 12&lt;bindata&gt;是二进制base64表示；&lt;t&gt;是由单字节的数据类型表示。 Date Strict mode mongo shell mode { “$date”: ““ } new Date ( ) 12In Strict mode, &lt;date&gt;是 ISO-8601的日期格式的时区字段，类型如**YYYY-MM-DDTHH:mm:ss.mm&lt;+/-offset&gt;;MongoDb JSON解析器目前暂不支持载入ISO-8601日期类型。 Timestamp Strict mode mongo shell mode { “$timestamp” ; { “t”: , “i” } } Timestamp( , ) 12&lt;t&gt;是32位无符号整数的JSON表现形式；&lt;i&gt;是增量的32位无符号整数。 Regular Expression Strict mode mongo shell mode { “$regex”: , “$options”: ““ } // 1234&lt;sRegex&gt;是有效地JSON字符串；&lt;jRegex&gt;是一个可能包含有效的JSON字符和未转义的双引号(&quot;)，但可能不包括未转义的斜杠(/)字符；&lt;sOptions&gt;是一个正则表达式选项；&lt;jOptions&gt;是一个只能包含字符&quot;g&quot;, &quot;i&quot;, &quot;m&quot;, &quot;s&quot;的字符串。 OID Strict mode mongo shell mode { “$oid”: ““ } ObjectId( ““ ) &lt;id&gt;是一个24字符的十六进制(hexadecimal)字符串 DB Reference strict mode mongo shell mode { “$ref”: ““, “$id”: ““ } DBRef(““, ““) 12&lt;name&gt;是一个有效的JSON字符；&lt;id&gt;是任一extended JSON type。 Undefined Type strict mode mongo shell mode { “$undefined”: true } undefined MinKey/MaxKey strict mode mongo shell mode { “$minkey”: 1 } MinKey { “$maxkey”: 1 } MaxKey NumberLong strict mode mongo shell mode { “$numberLong”: ““ } NumberLong( ““ ) 12Number是一个64位有符号整数。必须使用&quot;，否则它将被解释为浮点数，从而导致损失精度；db.json.insert&#123;&#123; longquoted: NumberLong(&quot;12345678901234345&quot;) &#125;) MongoDB安装参考: https://docs.mongodb.com/manual/administration/install-on-linux/; https://docs.mongodb.com/manual/tutorial/install-mongodb-on-red-hat/; MongoDB有社区版(Community)和企业版(Enterprise)。社区版免费，企业版在商业方面收费。 MongoDB在仓库中提供官方支持的包，包含以下软件包： Package Description monogdb-org 将自动安装下面四个组件包 mongodb-org-server 包含mongod守护进程和相关配置和init脚本 mongodb-org-mongos 包含mongos守护进程 mongodb-org-shell 包含mongo-shell mongodb-org-tools 包含相关MongoDB工具，如mongoimport,mongoexport,mongodump,mongorestore… mongodb-org-server包提供了一个/etc/mongod.conf配置文件来开始和初始化mongod。默认配置文件默认bind_ip为 127.0.0.1，当你有需要和副本集时请修改它。 自建mongodb.repo仓库安装仓库地址：https://repo.mongodb.org 12345678910111213vim /etc/yum.repos.d/mongodb34.repo#编辑仓库[mongodb34]name=MongoDB34 Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.4/x86_64/gpgcheck=0enabled=1#安装mongodbyum install -y mongodb-org 下载rpm包安装1234567cd /root/mongodbwget https://repo.mongodb.org/yum/redhat/7/mongodb-org/3.4/x86_64/RPMS/mongodb-org-3.4.10-1.el7.x86_64.rpmwget https://repo.mongodb.org/yum/redhat/7/mongodb-org/3.4/x86_64/RPMS/mongodb-xxx-3.4.10-1.el7.x86_64.rpm#共五个包yum ./mongo-org* 源码安装1234567wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-3.6.0.tgztar -axvf mongodb-linux-x86_64-rhel70-3.6.0.tgz -C ./#默认路径/usr/localmake &amp;&amp; make install 开启mongodb123456789101112131415161718192021#默认启动方式systemctl start mongod#指定配置文件启动#注意修改配置文件里面的某些路径和名称，不然会和默认配置文件冲突mongod -f /etc/mongo_27018.confmongod -f /etc/mongo_27019.conf``&lt;br&gt;## 卸载mongodb```shsystemctl stop mongodyum remove $(rpm -qa | grep mongodb-org)rm -rf /var/log/mongodbrm -rf /var/dbpath/mongo mongodb异常关闭后12345#首先查看日志文件tail /var/log/mongodb/mongod.log#删除rm /var/run/mongodb/mongod.pid /var/db/mongodb/mongod.lock MongoDB配置文件MongoDB的配置文件格式使用了YAML格式。YAML维基百科，Yet Another Markup Language。强调以数据为中心，而不是标记语言为重点，用方向缩略语重命名。 默认配置文件/etc/mongod.conf 的几个大块： 123456789101112131415161718192021systemLog: #日志storage: #存储processManagement: #进程管理net: #网络security: #安全operationProfiling: #性能分析器replication: #主从复制sharding: #架构setParameter: #自定义变量auditLog: #检测日志snmp: #简单网络管理协议 systemLog日志相关参数： 123456789101112131415systemLog: verbosity: &lt;int&gt; #日志级别，默认0,1-5均会包含debug信息 quiet: &lt;boolean&gt; #安静，true时mongod将会减少日志的输出量 traceAllExceptions: &lt;boolean&gt; #打印异常详细信息 syslogFacility: &lt;string&gt; #指定用于登录时信息到syslog Facility水平，前提是启用syslog path: &lt;string&gt; #日志路径，默认情况下，MongoDB将覆盖现有的日志文件 logAppend: &lt;boolean&gt; #mongod重启后，在现有日志后继续添加日志，否则备份当前日志，然后创建新日志 logRotate: rename|reopen #日志轮询，防止一个日志文件特别大。rename重命名日志文件，默认值；reopen使用Linuxrotate特性，关闭并重新打开日志文件，前提为logAppend: true destination: &lt;string&gt; #日志输出目的地，可为file或syslog，若不指定，则会输出到 std out timeStampFormat: &lt;string&gt; #指定日志格式的时间戳，有 ctime, Iso869-utc, iso8691-local component: #为不同的组件指定各自的日志信息级别 accessControl: verbosity: &lt;int&gt; command: verbosity: &lt;int&gt; storage存储引擎相关参数: 123456789101112131415161718192021222324252627282930313233storage: dbPath: &lt;string&gt; #mongodb进程存储数据目录，此配置进队此mongod进程有效，你使用配置文件开启的mongod就可以指定额外的数据目录 indexBuildRetry: &lt;boolean&gt; #当构件索引时mongod意外关闭，那么在此启动是否重建索引，默认true repairPath: &lt;string&gt; #在repair期间使用此目录存储临时数据，repair结束后此目录下数据将被删除 journal: enabled: &lt;boolean&gt; #journal日志持久存储，journal日志用来数据恢复，通常用于故障恢复，建议开启 commitIntervalMs: &lt;num&gt; #mongod日志刷新值，范围1-500毫秒，默认100，不建议修改 directoryPerDB: &lt;boolean&gt; #是否将不同的数据存储在不同的目录中，dbPath子目录 syncPeriodSecs: &lt;int&gt; #fsync操作将数据flush到磁盘的时间间隔，默认为60秒，不建议修改 engine: &lt;string&gt; #存储引擎 mmapv1: #mmapv1存储引擎，3.2前默认 preallocDataFiles: &lt;boolean&gt; nsSize: &lt;int&gt; quota: enforced: &lt;boolean&gt; maxFilesPerDB: &lt;int&gt; smallFiles: &lt;boolean&gt; journal: debugFlags: &lt;int&gt; commitIntervalMs: &lt;num&gt; wiredTiger: #WiredTiger存储引擎，3.2后默认 engineConfig: cacheSizeGB: &lt;number&gt; #最大缓存大小 journalCompressor: &lt;string&gt; #日志压缩算法，可选值有 none，snappy(默认)，zlib directoryForIndexes: &lt;boolean&gt; #是否将索引和collections数据分别存储在dbPath单独的目录中 collectionConfig: blockCompressor: &lt;string&gt; #collection数据压缩算法，可选none, snappy，zlib indexConfig: prefixCompression: &lt;boolean&gt; #是否对索引数据使用前缀压缩。对那些经过排序的值存储有很大帮助，可有效减少索引数据的内存使用量。 inMemory: #inMemory内存存储引擎，bate版 engineConfig: inMemorySizeGB: &lt;number&gt; processManagement进程相关参数: 123processManagement: fork: &lt;boolean&gt; #是否以fork模式运行mongod进程，默认情况下，mongod不作为守护进程运行 pidFilePath: &lt;string&gt; #将mongod进程ID写入指定文件，如未指定，将不会创建PID文件 net网络相关参数: 123456789101112131415161718192021222324252627282930net: prot: &lt;int&gt; #监听端口，默认27017 bindIp: &lt;string&gt; #绑定IP，如果此值是“0.0.0.0”则绑定所有接口 maxIncomingConnections: &lt;int&gt; #mongod进程允许的最大连接数，如果此值超过系统配置的连接数阈值，将不会生效(ulimit) wireObjectCheck: &lt;boolean&gt; #当客户端写入数据时，检查数据的有效性（BSON）。如果数据格式不良，update,insert等操作将会被拒绝 ipv6: &lt;boolean&gt; #是否支持多实例之间使用ipv6 unixDomainSocker: #适用于Unix系统 enabled: &lt;boolean&gt; pathPrefix: &lt;string&gt; filePermissions: &lt;int&gt; http: # enabled: &lt;boolean&gt; JSONEnabled: &lt;boolean&gt; RESTInterfaceEnabled: &lt;boolean&gt; ssl: sslOnNormalPorts: &lt;boolean&gt; mode: &lt;string&gt; PEMKeyFile: &lt;string&gt; PEMKeyPassword: &lt;string&gt; clusterFile: &lt;string&gt; clusterPassword: &lt;string&gt; CAFile: &lt;string&gt; CRLFile: &lt;string&gt; allowConnectionsWithoutCertificates: &lt;boolean&gt; allowInvalidCertificates: &lt;boolean&gt; allowInvalidHostnames: &lt;boolean&gt; disabledProtocols: &lt;string&gt; FIPSMode: &lt;boolean&gt; compression: compressors: &lt;string&gt; security安全相关参数: 1234567891011121314151617181920212223242526272829303132333435security: authorization: enabled #MondoDB认证功能 keyFile: /path/mongo.key #MongoDB副本集节点身份验证密钥文件 clusterAuthMode: &lt;string&gt; #集群members间的认证模式 transitionToAuth: &lt;boolean&gt; javascriptEnabled: &lt;boolean&gt; #是否允许执行JavaScript脚本 redactClientLogData: &lt;boolean&gt; sasl: hostName: &lt;string&gt; serviceName: &lt;string&gt; saslauthdSocketPath: &lt;string&gt; enableEncryption: &lt;boolean&gt; encryptionCipherMode: &lt;string&gt; encryptionKeyFile: &lt;string&gt; kmip: keyIdentifier: &lt;string&gt; rotateMasterKey: &lt;boolean&gt; serverName: &lt;string&gt; port: &lt;string&gt; clientCertificateFile: &lt;string&gt; clientCertificatePassword: &lt;string&gt; serverCAFile: &lt;string&gt; ldap: servers: &lt;string&gt; bind: method: &lt;string&gt; saslMechanism: &lt;string&gt; queryUser: &lt;string&gt; queryPassword: &lt;string&gt; useOSDefaults: &lt;boolean&gt; transportSecurity: &lt;string&gt; timeoutMS: &lt;int&gt; userToDNMapping: &lt;string&gt; authz: queryTemplate: &lt;string&gt; operationProfiling慢查询相关参数： 1234operationProfiling: slowOpThresholdMs: &lt;int&gt; #数据库profiler判定一个操作是“慢查询”的时间阈值，单位毫秒。mongod会把慢查询记录到日志中，默认100ms mode: &lt;string&gt; #数据库profiler级别，操作的性能信息将会被写入日志文件中，可选值“off”--关闭profiling，“slowOp”--只包包含慢操作，“all”--记录所有操作 #数据库profiling会影响性能，建议只在性能调试阶段开启 replication副本集： 12345replication: oplogSizeMB: &lt;int&gt; #replication操作日志的最大尺寸，如果太小，secondary将不能通过oplog来同步数据，只能全量同步 replSetName: &lt;string&gt; #副本集名称，副本集中所有的mongod实例都必须有相同的名字，Sharding分布式下，不同的sharding应该使用不同的repSetName secondaryIndexPrefetch: &lt;string&gt; #副本集中的secondary，从oplog中应用变更操作之前，将会先把索引加载到内存 enalbeMajorityReadConcern: &lt;boolean&gt; #允许readConcern的级别为“majority” sharding分片相关参数： 123sharding: clusterRole: &lt;string&gt; #在sharding集群中，此mongod实例可选的角色。configsvr,默认监听27019端口 和 shardsvr,默认监听27018端口 archiveMovedChunks: &lt;boolean&gt; #当chunks因为“负载均衡”而迁移到其他节点时，mongod是否将这些chunks归档，并保存在dbPath/movechunk目录下，mongod不会删除moveChunk下的文件 setParameter自定义变量： 1234setParameter: &lt;parameter1&gt;: &lt;value1&gt; &lt;parameter2&gt;: &lt;value2&gt; enableLocalhostAuthBypass: false #栗子 auditLog审计相关参数： 12345auditLog: destination: &lt;string&gt; #指定审计记录的输出方式，有syslog, console, file format: &lt;string&gt; #输出格式，有JSON 和 BSON path: &lt;string&gt; #如果审计时间输入为文件，那么就需要指定文件完整路径及文件名 filter: &lt;string&gt; #过滤器，可限制审计系统记录的操作类型，该选项需要一个表单的查询文档的字符串表示形式 Mongo Shellmongo shell是一个交互式的JavaScript结构的MongoDB。使用mongo shell来查询和更新数据以及执行管理操作。 mongo shell基础知识启动monso shell启动mongo shell前确保MongoDB实例正在运行。 1234567891011121314mongo [option] [db address] [.js]#以默认配置启动mongo#以特定配置启动mongo --port 27018#连接远程mongo shellmongo --host $host --port $port -u $user -p $passwdmongo &lt;db&gt;mongo &lt;host&gt;/&lt;db&gt;mongo &lt;hsot:port&gt;/&lt;db&gt; .mongorc.js文件mongo shell开始运行时，mongo将在用户主目录下检查.mongorc.js的js文件。如果找到，mongo将在首次命令行之前解释执行.mongorc.js的内容。如果你使用mongo shell执行一个js或表达式，无论是通过mongo --eval，或指定一个.js文件，mongo都将在js处理完成之后读取.mongorc.js文件。可使用 --norc选项禁止加载.mongorc.js。 12ll /root/.mongorc.js# -rw------- 1 root root 0 Dec 27 2016 /root/.mongorc.js 使用mongo shell可能在启动mongo shell的时候会警告: WARNING: /sys/kernel/mm/transparent_hugepage/defrag is ‘always’. We suggest setting it to ‘never’. WARNING: /sys/kernel/mm/transparent_hugepage/defrag is ‘always’. We suggest setting it to ‘never’ WARNING: Access control is not enabled for the database. hugepage(大内存页面)，是Linux操作系统一种管理内存的方式。和通常方式相比，hugepage模式下内存分配管理会有所差异。MongoDB显然不希望这个特定被启用。新版MongoDB增加了安全性设计，推荐用户创建使用数据库时进行验证。所以我们需要创建用户认证。 关闭hugepage: 123456vim /etc/rc.d/rc.localecho never &gt; /sys/kernel/mm/transparent_hugepage/enabledecho never &gt; /sys/kernel/mm/transparent_hugepage/defragchmox a+x /etc/rc.d/rc.local 创建用户认证: 1234567891011121314&gt;use admin&gt;db.createUser(&#123; user: "zhang", pwd: "zhang", roles: [&#123; role: "root", db: "admin"&#125;]&#125;)mongo -u zhang -p zhang --authenticationDatabase admin#或mongouse admindb.auth("zhang", "1314520") 12345678910mongo#显示当前使用数据库&gt;db#切换数据库&gt;use &lt;database&gt;#查看所有数据库&gt;show dbs 你可以切换到一个并不存在的数据库。当你第一次向数据库存储数据，如创建一个集合，MongoDB将自动创建数据库。 123use nodbdb.nocollestion.insert(&#123;x:1&#125;); 格式化打印结果db.collection.find()方法返回一个cursor(游标)。如果返回的游标未使用var关键字指定变量，则游标将自动迭代最多20次，以打印出与查询匹配的前20个documents 1234567#在操作中添加`.pretty()`，以格式化打印结果#使用.pretty显示结果很舒服db.collection.find().pretty()print() #无格式打印printjson() #用JSON打印 mongo shell中的多行操作mongo shell中如果你以( , { , [开始，那么知道你输入了对应的) , } , ]才算结束命令。 Tab命令补全和键盘快捷键mongo shell支持键盘快捷键，例如： 使用 上/下箭头 进行历史命令切换； 使用 Tab键 自动补全命令。 mongo shell批量操作123456mongo -u xxx -p xxx --authenticationDatabase=xxx &lt;&lt; EOFshow dbsuse zhangdb.coll01.drop()db.coll02.update( &#123; _id: "xxx" &#125;, &#123; name: "zhang" &#125;)EOF 退出mongo shell12345quit()exitCtrl+c 配置mongo shell可在mongo shell中设置变量prompt的值来修改提示符内容。prompt变量可以存储字符串以及JavaScript代码。 也可以在.mongorc.js文件中增加提示符的逻辑操作来设置每次启动mongo shell的提示符。 自定义提示符自定义提示符展示操作符： 在mongo shell中定义一下变量。 12345678910cmdCount = 1;prompt = function() &#123; return (cmdCount++) + '&gt; ';&#125;#效果1&gt;2&gt;... 自定义提示符显示数据库和主机名： 形式为：@$ 12345678host = db.serverStatus().host;prompt = function() &#123; return db+'@'+host+'$'&#125;#效果test@localhost$ 自定义提示符展示服务器启动时间和文档数： 1234567prompt = function() &#123; return 'Uptime:' + db.serverStatus().uptime + 'Documents:' + db.stats().objects + '&gt; ';&#125;#效果Uptime:1234 Documents:5 &gt; 注意：在mongo shell里面定义的prompt变量知识临时生效的，退出shell后便没有。如果想要当前用户永久生效，可写入~/.mongorc.js文件。则此用户每次启动mongo shell前都会执行这个文件。 123456vim ~/.mongorc.jshost = db.serverStatus().host;prompt = function() &#123; return db+"@"+host+"&gt; "; &#125; 在mongo shell中使用外部编辑器可在启动mongo shell之前设置EDITOR环境变量来在mongo shell中使用自己的编辑器。 12345678910111213export EDITOR=vimmongo#edit &lt;variable&gt;|&lt;function&gt;function myfunc()&#123;&#125;edit myfunc#此时是edit使用vim编辑myfuncfunction myfunc()&#123; print("It was edited by vim!")&#125;myfunc() 修改mongo shell批处理大小db.collection.find()是一种JavaScript方法，返回一个cursor(游标)。如果返回的游标未使用var关键字指定变量，则游标将自动迭代最多20次，以打印出与查询匹配的前20个documents。可以设置DBQuery.shellBatchSize属性来修改默认20篇文档。 1DBQuery.shellBatchSize = 10; 获取mongo shell帮助合理运用Tab键补全命令！ 1234567891011121314151617181920212223242526###命令行帮助mongo --help###mongo shell里查看帮助列表help###数据库帮助#db.&lt;method&gt;show dbsdb.help()###集合帮助#db.&lt;collection&gt;.&lt;method&gt;show collectionsdb.collections.help()###游标帮助db.collection.find().help()###封装对象帮助help misc 给mongo shell写脚本可使用JavaScript为mongo shell编写脚本，用于处理MongoDB中的数据或执行管理操作。 打开新连接在mongo shell或JavaScript文件中，可使用Mongo()构造函数来实例化数据库连接： 12345678910111213141516171819new Mongo()new Mongo(&lt;host&gt;)new Mongo(&lt;host:port&gt;)#栗子conn = new Mongo();db = conn.getDB('mydb'); #将全局db变量设置为mydb#连接db = connect('localhost:27017/mydb');#认证db.auth(&lt;user&gt;, &lt;passwd&gt;)db.auth(&#123; user: &lt;user&gt;, pwd: &lt;passed&gt;&#125;) 交互式和脚本化mongo的区别mongo shell中的帮助与JavaScript中帮助不一样！ mongo shell帮助 JavaScript等量 show dbs db.adminCommand(‘listDatabases’) use db = db.getSiblingDB(‘‘) show collections db.getCollectionNames() show users db.getUsers() show log db.adminCommand({‘getLog’ : ‘‘}) 脚本使用mongo shell来计算JavaScript的值。 –eval mongo执行 --eval后的js命令 1mongo test --eval &quot;printjson(db.getCollectionNames())&quot; 执行JavaScript文件 12345mongo localhost:27017/test myjs.js#在shell中执行.js&gt;load("myjs.js")&gt;loca("/root/mongo/myjs.js") mongo shell中的数据类型MongoDB BSON提供了除JSON之外的其它数据类型的支持。Driver提供了对这些数据类型在主机语言的本地化支持，mongo shell也提供了一些帮助类来支持这些数据类型在mongo javascript shell中的使用。 日期mongo shell提供了多种方法返回日期: Date() 方法返回当前日期为一个字符串； new Date() 构造函数返回一个使用ISODate()包装返回的Date对象； ISODate() 构造函数返回一个使用ISODate()包装返回的Date对象。 返回一个日期为字符串： 123var myDateString = Date();#查看变量值myDateString 验证类型： 12typeof myDateString()#string 返回Date： 123456var myDate = new Date();myDate#ISODate(&quot;2017-12-12T08:43:31.405Z&quot;)#验证myDate instanceof Date ObjectIdmongo shell对objectid数据类型提供objectId()包装类。 new ObjectId NumberLongmongo shell默认将所有数字处理为浮点值。 用numberlong()包装来处理64位整数。 1NumberLong("2090845886852") NumberInt用NumberInt()构造函数来显式指定32位整数。 NumberDecimalmongo shell默认将所有的数字处理为64位浮点的double值。mongo shell提供了NumberDecimal()构造函数限制指定128位基于十进制的浮点值，能够以精确的精度仿效十进制近似值。这个功能在金融、税务以及科学计算等方面应用。 12&gt;NumberDecimal('1000.55')#强烈建议加上引号，没加引号可能会存在精度丢失的情况 ### 在mongo shell中检查类型 instanceof返回一个bool值来验证一个值是否为某些类型的实例。 12mydoc._id instanceof ObjectId#true typeof返回一个字段的类型。 12typeof mydoc._id#object mongo shell快速参考mongo shell 历史命令mongo shell历史命令保存在~/.dbshell文件中，cat ~/.dbshell。也可以使用上/下键切换历史命令。 命令行选项 option description --help 显示命令行选项 --nodb 启动mongo shell而不连接到数据库 --shell 执行文件后运行mongo shell mongo shell命令助手 help methods and commands description help 显示帮助 db.help 显示数据库方法的帮助 db.collection.help() 显示集合方法的帮助 show dbs 打印服务器上的所有数据库列表 show databases 打印所有可获取的数据库列表 use &lt;db&gt; 切换数据库 show collections 打印当前数据库上的所有集合列表 show users 打印当前数据库的用户列表 show roles 打印当前数据库的所有角色(user-define and built-in)列表 show profile 打印花费1ms或更多时间的五个最近的操作 load() 在shell中执行一个JavaScript文件，建议使用绝对路径 mongo shell的基本JavaScript操作mongo shell为数据库操作提供了一个JavaScript API。db引用当的是前数据库的变量。 JavaScript db-operation description db.auth() 在安全模式下认证用户 coll = db.&lt;collection&gt; 将当前db中的特定collection设置为coll，可在此变量上执行操作，如coll.find(); db.collection.find() 查找集合中的所有文档，并返回一个游标 db.collection.insert() 插入一个新文档到集合中 db.collection.update() 更新集合中一个存在的文档 db.collection.save() 插入或更新 集合中的文档 db.collection.remove() 从集合中删除文档 db.collection.drop() 删除整个集合 db.collection.createIndex() 在集合中创建索引 db.getSiblingDB() 跨数据库查询 键盘快捷键 keysrtoke function Up/Down arrow 前/后 历史命令 Left/Right arrow 左右移动 Home/End 行首/行尾 Tab 自动补全 ctrl+c 退出 ctrl+L 清屏 mongo shell查询方法在mongo shell中，使用find()和findOne()方法执行读操作。 read-operations description db.collection.find(&lt;query&gt;) 查找集合中与匹配的文档，如果未指定或为空，则读取操作会选择集合中的所有文档 db.collection.find(&lt;query&gt;, &lt;projection&gt;) 查找与匹配的文档，返回特定字段 db.collection.find().sort(&lt;sort order&gt;) 返回排序结果 db.collection.find(&lt;query&gt;).sort(&lt;sort order&gt;) 返回匹配和排序结果 db.collection.find(...).limit(&lt;n&gt;) 限制输出结果为行 db.collection.find().pretty().limit() 匹配，格式化，限制输出 db.collection.find().limit().pretty() 同上 db.collection.find(...).skip(&lt;n&gt;) 跳过前行 db.collection.count() 返回集合中文档总数 db.collection.find().count() 返回匹配文档总数 db.collection.findOne(&lt;query&gt;) 查找并返回单一的文档，null表示未找到 管理命令助手 js db-administrative-methods description db.cloneDatabase(&lt;host&gt;) 从指定主机克隆当前数据库，noauth mode db.copyDatabase(&lt;from&gt;, &lt;to&gt;, &lt;host&gt;) copy db to db db.fromColl.renameCollection(&lt;toColl&gt;) rename collection db.repairDatabase() 修复当前db db.dropDatabases() 删除当前数据库 打开附加连接可以在mongo shell中创建一个新连接。 12345&gt;db = connect("&lt;host&gt;:&lt;port&gt;/&lt;db&gt;")#db = connect("192.168.1.11/admin")&gt;conn = new Mongo()&gt;db = conn.getDB("dbname") MongoDB CRUD操作CRUD操作就是创建(create)，读取(read)，更新(update)，删除(delete)文档(document)! 创建(create)操作创建或插入， 即是向 collection 添加新的 document。如果插入时集合不存在，插入操作会创建该集合。 123db.collection.insert()db.collection.insertOne()db.collection.insertMany() 读取(read)操作读操作，获取 collection 中的 document。 1db.collection.find() 更新(update)操作更新操作，修改 collection 中已经存在的 document。 1234db.collection.update()db.collection.updateOne()db.collection.updateMany()db.collection.replaceOne() 删除(delete)操作删除操作，是从一个 collection 中删除 document 的操作。 123db.collection.remove()db.collection.deleteOne()db.collection.deleteMany() 插入文档(Insert) 插入方法MongoDB提供了如下插入方法向collection中插入document： db.collection.insert(), 向集合中插入一个或多个文档; db.collection.insertOne(), 向集合中插入一个文档; db.collection.insertMany(), 向集合中插入多个文档. db.collection.insert()db.collection.insert(),向collection中插入一个或多个document。要想插入一个document，传递一个文档给该方法；要想插入多个documents，传递文档数组给该方法。 12345678910111213141516171819#插入一个文档db.user.insert( &#123; _id: "ZhangTest", name: "zhang", age: 2017, sex: "man" &#125;)#插入多个文档db.user.insert( [ &#123; name: "AAA", age: 20, status: "A" &#125;, &#123; name: "BBB", age: 21, status: "B" &#125;, &#123; name: "CCC", age: 22, status: "C" &#125; ]) db.collection.insertOne()db.collection.insertOne(),向collection中插入单个document。 12345678910db.user.insertOne( &#123; name: "zhang", age: "2017", sex: "man", education: "bachelor" &#125;)#此处并未自定义_id字段，因此它会自动添加_id字段 db.collection.insertMany()db.collection.insertMany(),向collection插入多个documents。 123456789db.user.insertMany( [ &#123; name: "AAA", age: "20", status: "A" &#125;, &#123; name: "BBB", age: "21", status: "B" &#125;, &#123; name: "CCC", age: "22", status: "C" &#125; ])#自动生成3个document的_id字段 插入操作的行为表现创建集合插入的时候如果collection不存在，那么插入操作会创建collection。 _id字段在MongoDB中，存储于collection中的每一个document都需要一个唯一的_id字段作为primary_key。如果一个插入的document操作遗漏了_id字段，则MongoDB driver会自动生成一个ObjectId。 原子性MongoDB中所有的写操作在单一文档层级上是原子的。 查询文档(Read)MongoDB提供了db.collection.find()方法从collection中读取document。 1234db.collection.find( &lt;query filter&gt;, &lt;projection&gt; )#&lt;query filter&gt;指明返回哪些document#&lt;projection&gt;指明返回匹配document的那些filed 示例12345678910111213141516171819202122232425db.user.insertMany( [ &#123; _id: 1, name: "A", favorites: &#123; artist: "Picasso", food: "pizza" &#125;, finished: [ 11, "AA" ], points: [ &#123; points: 85, bonus: 30 &#125;, &#123; points: 85, bonus: 10 &#125; ] &#125;, &#123; _id: 2, name: "B", favorites: &#123; artist: "Miro", food: "merigue" &#125;, finished: [ 22, "BB" ], points: [ &#123; points: 85, bonus: 20 &#125;, &#123; points: 64, bonus: 12 &#125; ] &#125;, &#123; _id: 3, name: "C", favorites: &#123; artist: "Gaogeng", food: "cake" &#125;, finished: [ 33, "CC" ], points: [ &#123; points: 67, bonus: 8 &#125;, &#123; points: 55, bonus: 21 &#125; ] &#125; ]) 查询和规划操作符Comparison: 1234567$eq$gt$gte$lt$ne$in$nin Logical： 1234$or$and$not$nor Element: 12$exists$type Evaluation: 1234$mod$regex$text$where Geospatial: 1234$geoWithin$geoIntersects$near$nearSphere Array: 123$all$eleMatch$size Bitwise: 1234$bitsAllSet$bitsAnySet$bitsAllClear$bitsAnyClear Comments: 1$comment Projection Operators: 1234$$eleMatch$meta$slice 选择collectino中所有document一个空的query filter会选择集合汇总所有文档。 12db.users.find(&#123;&#125;)db.user.find() 指定查询过滤条件1. 指定等于条件 1234&#123; &lt;field1&gt;: &lt;value1&gt;, ...&#125;#栗子db.user.find( &#123; name: &quot;C&quot; &#125; ) 2. 使用查询操作符指定条件 1234&#123; &lt;field1&gt;: &#123; &lt;operator1&gt;: &lt;value1&gt; &#125;, ... &#125;#栗子db.user.find( &#123; name: &#123; $in: [ &quot;A&quot;, &quot;B&quot; ] &#125; &#125; ) 3. 指定逻辑查询条件条件逻辑查询(AND, OR, NOT)。符合查询可以在集合文档的多个字段上指定条件。 123456789101112131415#ANDdb.user.find( &#123; name: &quot;A&quot;, age: &#123; $lt: 30&#125; &#125; )#ORdb.user.find( &#123; $or: [ &#123; name: &quot;A&quot; &#125;, &#123; age: &#123; $lt: 30 &#125; &#125; ]&#125; )#AND和ORdb.user.find( &#123; name: &quot;A&quot;, $or: [ &#123;age: &#123; $lt: 30 &#125; &#125;, &#123; type: 1 &#125; ]&#125; ) 嵌入式文档的查询当字段中包含嵌入文档时，查询可以指定嵌入文档中的精确匹配或使用圆点(.)表示法对嵌入文档的单个字段指定匹配。 12345678#精确匹配db.user.find(&#123; favorites: &#123; artist: &quot;Picasso&quot;, food: &quot;pizza&quot; &#125;&#125;)#圆点.表示法，记得加引号db.user.find( &#123; &quot;favorites.artist&quot;: &quot;Picasso&quot; &#125; ) 数组上的查询当字段包含数组，可查询精确的匹配数组或数组中特定的值。如果数组包含嵌入文档，可使用圆点表示法查询内嵌文档中特定的字段。 123456789101112131415161718192021222324252627#精确匹配db.user.find(&#123; finished: [ 11, &quot;AA&quot; ] &#125;)#匹配一个数组元素，会显示整个文档db.user.find(&#123; finished: &quot;BB&quot; &#125;)#匹配数组中指定元素，会返回整个文档db.user.find(&#123; &quot;finished.1&quot;: &quot;CC&quot; &#125;)#指定数组中的多个查询条件db.user.find(&#123; finished: &#123; $elemMatch: &#123;$gte: 11, $lt: 33&#125; &#125; &#125;)db.user.find(&#123; finished: &#123; $gt: 11, $lt: 33 &#125; &#125;)#嵌入文档数组db.user.find(&#123; &apos;points.points&apos;: &#123;$lte: 80 &#125; &#125;)db.user.find(&#123; &quot;points.0.points&quot;: &#123;$lte: 80&#125; &#125;)#元素组合满足查询条件db.user.find(&#123; &quot;points.points&quot;: &#123;$lte: 80&#125;, &quot;points.bouns&quot;: 20&#125;) 返回查询的映射字段默认地，MongoDB中的查询返回匹配文档中的所有字段。为了限制MongoDB发送给应用的数据量，我们可以在查询操作中包括一个projection文档。 映射文档映射文档限制了返回所有匹配文档的字段。映射文档可以致命包括哪些字段或排除哪些字段。这个就很不错了，可以过滤掉我们不需要的信息。 12345db.users.find( &#123;name: &quot;AAA&quot;&#125; ,&#123;_id: 0, name: 1, age: ture&#125; )db.user.find( &#123; name: &quot;BBB&quot;&#125;, &#123;_id: false&#125; )1或true，表示在返回的文档中包含字段；0或false，排除该字段； 更新文档(Update)更新方法： db.collection.updateOne(), 更新一个文档 db.collection.updateMany(), 更新多个文档 db.replaceOne(), 替换一个文档 db.collection.update(), 更新或替换一个文档 更新的行为表现 原子性：MongoDB中所有的写操作在单一文档层级上是原子的。 _id字段：不能更新_id字段的值，也不能用不同_id字段值的替换文档来替换已存在的文档。 文档大小：当执行更新操作增加的文档大小超过了为该文档分配的空间时，更新操作会在磁盘上重定位该文档。 字段顺序：MongoDB按照文档写入的顺序整理文档字段。但_id字段始终是文档中第一个字段；renaming操作可能会导致文档中的字段重新排序。 Update OperatorFields name description $currentDate 将字段值设置为当前日期(date or timestamp) $inc 按指定的数字递增字段的值 $min 指定的值小于字段的值时才更新 $max 指定的值大于字段的值时才更新 $mul 将字段的值乘以指定的数字 $rename 重命名一个字段 $set 设置文档中字段的值 $setOnInsert 如果更新导致文档插入，则设置字段的值 $unset 从文档中删除指定的字段， Array name description $ 用作更新与查询条件匹配的第一个元素的占位符 $[] 用作更新与查询条件匹配的文档的数组的所有元素的占位符 $[] xxx $addToSet 在集合中不存在元素时添加元素到数组 $pop 移除数组中的第一项或最后一项 $pull 删除所有匹配指定查询的数组元素 $push 向数组中添加项 $pullAll 从数组中删除所有匹配的值 Modifiers name description $each 修饰$push and $addToSet， 向数组中添加多个项 $position 修饰$push，在数组中指定位置添加元素 $slice 修饰$push，限制更新数组的大小 $sort 修饰$push，重新排列存储在数组中的文档 BitWise 1$bit 执行按位AND,OR,XOR更新 更新文档字段中指定字段为了修改文档中的字段，MongoDB提供了update operators，如用来修改值的$set。 1234567891011121314151617181920212223&#123; &lt;update operator&gt;: &#123; &lt;field&gt;: &lt;value&gt;, ...&#125;&#125;#更改指定字段的值db.user.update( &#123; _id: 1 &#125;, &#123; $set: &#123;name: &quot;SET&quot;&#125; &#125;)#删除指定字段，文档中其他字段还在db.user.update( &#123; _id: 1 &#125;, &#123; $unset: &#123;name: &quot;SET&quot;&#125; &#125;)#db.user.updateMany( &#123; _id: 2&#125;, &#123; $set: &#123;name: &quot;AAA&quot;, age: 222&#125; &#125;) 文档替换(Replace)当替换文档时，替换的文档必须仅仅有 &lt;field&gt;: &lt;value&gt;组成。替换文档可以有不同于源文档的字段，但_id字段是不变的。 **建议使用_id作为过滤条件，因为它是唯一的。 123456789101112db.collection.replaceOne()db.user.replaceOne( &#123; name: &quot;AAA&quot; &#125;, &#123; name: &quot;A&quot;, age: 2, sex: &quot;man&quot;, favorites: &#123; artist: &quot;Dali&quot;, food: &quot;banana&quot; &#125; &#125;)db.user.update( &#123; _id: 1&#125;, &#123; name: &quot;A&quot;, age: 2, sex: &quot;man&quot;, favorites: &#123; artist: &quot;Dali&quot;, food: &quot;banana&quot; &#125; &#125;) 删除文档(Delete)方法： db.collection.remove(), 删除一个文档，或所有满足匹配的文档; db.collection.deleteOne(), 删除匹配最多条件的单个文档，即使可能有多个文档可能与指定过滤条件匹配; db.collection.deleteMany(), 删除所有匹配指定过滤条件的文档。 删除的行为表现 Indexes删除操作不会删除索引，即使从集合中删除了所有的文档。 原子性MongoDB中所有的写操作在单一文档层级上是原子的。 删除1234567891011121314#删除所有文档db.collectin.deleteMany(&#123;&#125;)db.collection.remove(&#123;&#125;)#删除所有满足条件的文档db.user.remove( &#123; name: &quot;A&quot; &#125; )db.user.deleteMany( &#123; name: &quot;A: &#125; )#仅删除一个满足条件最多的文档db.user.deleteOne( &#123; name: &quot;A&quot; &#125; )db.users.remove( &#123; name: &quot;A&quot;&#125;, 1) 聚合(Agrregation)聚合操作处理数据记录并返回计算的结果。聚合操作将多个文档中的值(value)分组，并对分组的数据进行各类操作以返回单个结果。 MongoDB提供了三种方式进行聚合： aggregation pipeline(聚合管道); map-reduce function(映射化简); single aggregation methods(聚合指南) Aggregation Pipeline(聚合管道) MongoDB的聚合框架(aggregation framework)是仿照数据处理管道的概念(concept)。Document输入多级管道，它将Document转换为聚合结果。 最基本的pipeline stage提供了：类似查询(query)操作的过滤器(filter)和类似修改(modify)输出文档格式的文档转换。 其他pipeline operation提供了按特定字段对文档进行分组和排序的工具，以及聚合数组内容(包括文档数组)的字段或工具。此外，pipeline stage可以使用运算符(operators)来处理任务。(如计算平均值和连接等…) pipeline通过在MongoDB中使用本地操作，从而提供了高效的数据聚合。所以也是MongoDB中数据聚合的首选方法。 aggregation pipeline能够在一个共享的集合上操作。 aggregation pipeline可以使用索引来提高某些阶段的性能(performance)。另外，管道聚合还有一个内部优化阶段(optimization phase)。 Map-Reduce(映射化简) 一般来说，map-reduce操作有两个阶段： map stage: 处理每个文档并未每个输入文档发出一个或多个对象(object)； reduce stage: 结合映射操作的输出。 可选地，map-reduce有一个对结果做最后修改的最后阶段。与aggregation-operation类似，map-reduce可以指定查询条件来选择一个输入文档，以及对结果进行排序和限制。 map-reduce使用自定义的JavaScript函数执行映射和化简操作，以及可选的最终操作。与聚合管线相比，自定义的JavaScript提供了很大的灵活性。一般来说，map-reduce比aggregation pipeline效率更低，更复杂。 map-reduce能够在一个共享的集合上操作，同样也可以输出到共享集合。 Single Purpose Aggregation Operations(聚合指南) MongoDB同样提供了db.collection.count()和db.collection.distinct()。 所有这些操作都从单个集合中聚合文档，虽然这些操作提供了对常见聚合过程的简单访问，但它们缺少aggregation pipeline和map-reduce的灵活性和功能。 Aggregation Pipeline(聚合管道)MongoDB的聚合框架是仿照数据处理管道的概念。文档输入多级管道，它将文档转换为聚合结果。 当map-reduce的复杂性可能是没有保证的，aggregation pipeline为map-reduce提供了一个可选也可能是聚合任务的首选解决方案。aggregation pipeline对key value和result size有一些限制。 映射化简 聚合指南 MongoDB文本索引MongoDB支持在字符串内容上执行文本检索(text search)的查询操作。视图不支持文本检索。为了执行文本检索，MongoDB使用text index和$text操作符。text索引可以包括任何值为字符串或字符串元素数组的字段。 栗子： 1234567db.sample.insert( [ &#123; _id: 1, name: "A", description: "AAA" &#125;, &#123; _id: 2, name: "B", description: "BBB" &#125;, &#123; _id: 3, name: "C", description: "CCC" &#125; ]) 为了执行文本检索查询，你必须在集合有一个text索引，一个集合只能有一个文本检索索引，但是这个索引可以覆盖多个字段。 启动在name和description字段上的文本检索： 123db.sample.createIndex( &#123; name: "text", description: "text" &#125;) 使用$text查询操作符在一个有text index的集合上执行文本检索 123456789101112131415db.sample.find(&#123; $text: &#123; $search: &quot;A B&quot; &#125;&#125;)#精确检索db.sample.find(&#123; $text: &#123; $search: &quot;A \&quot;B\&quot;&quot; &#125;&#125;)#词语排除db.sample.find(&#123; $text: &#123; $search: &quot;A B -AAA&quot; &#125;&#125;) MongoDB默认返回没排序的结果。然而文本检索将会对每个文档计算一个相关性分数，表明该文档与查询的匹配程度。为了使用相关性分数进行排序，你必须使用 $meta textScore字段进行映射然后基于该字段进行排序。 1234db.sample.find( &#123; $text: &#123; $search: &quot;A AAA B&quot; &#125; &#125;, &#123; score: &#123; $meta: &quot;textScore&quot; &#125; &#125;).sort( &#123; score: &#123; $meta: &quot;textScore&quot; &#125; &#125;) 文本检索可以在聚合管道中使用。 文本索引 文本检索操作符 在管道聚合中使用文本索引 使用基本技术Rosette语义平台的文本索引 文本检索语言 MongoDB数据模型MongoDB的数据具有灵活的模式，集合本身没有对文档结构的规则性校验。 数据模型设计介绍关系型数据库要求你再插入数据之前必须先定义好一个表的模式结构，而MongoDB的集合并不限制文档结构。这种灵活性让对象和数据库文档之间的映射变得很容易。即使数据记录之间有很大的变化，每个文档也可以很好的映射到各条不同的记录。当然，在实际使用中，同一个集合中的文档往往都有一个比较类似的结构。 数据模型设计中最具挑战性的是在应用程序需求，数据库引擎性能要求和数据读写模式之间的权衡考量。 文档结构引用(reference)引用方式通过存储链接或引用信息来实现两个不同文档之间的关联。应用程序可以通过解析这些数据库引用来访问相关数据。简单来讲，这就是规范化的数据模型。 内嵌(embedded data)内嵌方式指把相关联的数据保存在同一个文档之内。MongoDB的文档结构允许一个字段或一个数组内的值为一个嵌套的文档。这种冗余的数据模型可以让应用程序在一个数据库内完成对相关数据的读取或修改。 写操作的原子性在MongoDB中，写操作在文档级别是原子的(atomic)，没有一个单独的写操作可以原子地影响多个文档或多个集合。但，对原子性写操作利好的内嵌数据模型会限制应用程序对数据的使用场景。 嵌入(embdded)数据的非规格化(denormalized)数据模型将单个文档所表示的实体(entity)的所有相关数据组合在一起。这有利于原子写操作，因为单个写操作可以插入或更新实体的数据； 规格化(normalizing)数据通过多个集合拆分数据，并需要多个不是原子集合的写操作。 文档的增长如果文档的大小超出分配给文档的原空间大小，那么MongoDB就需要把文档从磁盘上的现有位置移动到一个新的位置以存放更多的数据。这种数据增长的情况也会影响到是否要使用规范化或非规范化。 数据的使用和性能设计文档模型时，一定要考虑应用程序会如何使用你的数据。 例如： 假如应用程序通常只会使用最近插入的文档，那么可以考虑使用限制集； 假如应用会做大量的读操作，那么可以加多一些索引的方法来提升常见查询的性能。 文档验证MongoDB提供了在更新和插入期间验证(validate)文档的功能(capability)。验证规则是在每个集合中指定使用验证符(validator)选项，利用一个文档指定验证堆栈或表达式。 通过collMod命令附带验证符选项向一个已经存在的集合添加文档验证； 利用db.createCollection()命令附带验证符选项来创建文档验证规则。 123456789db.createCollection( "contacts", &#123; validator: &#123; $or: [ &#123; phone: &#123; $type: "string" &#125; &#125;, &#123; email: &#123; $regex: /@mongodb\.com$/ &#125; &#125;, &#123; status: &#123; $in: [ "Unknown", "Incomplete" ] &#125; &#125; ] &#125;&#125; ) MongoDb同样提供了validationLevel选项，它确定了MongoDb在更新期间如何将验证规则应用到已有文档，以及验证操作选项。它确定MongoDB是否错误并拒绝违反验证规则的文档，或者警告日志中的违规，但允许无效的文档。 行为验证发生在更新和插入期间。当向一个文档添加验证，在修改之前，现有文档不会进行验证检查。 现有文档 可使用validationLevel选项来控制MongoDB怎样处理现有文档。 默认情况下，MongoDB是严格的，并且将验证规则应用于所有插入和更新操作。 12345678#moderate level#在中等级别下，对不符合验证标准的现有文档更新将不会检查有效性db.runCommand(&#123; collMod: "contacts", validator: &#123; $or: [ &#123; phone: &#123; $exists: true &#125; &#125;, &#123; email: &#123; $exists: true&#125;&#125; ] &#125;, validationLevel: "moderate"&#125;) 设置validationLevel为off以禁用验证功能。 接受或拒绝无效文档 validationAction选项决定了MongoDB如何处理违反(violate)验证规则的文档。 默认情况下，validationAction是错误的，并且拒绝任何违反验证条件的插入和更新操作。 123456789101112131415161718#当validationAction为warn时，MongoDB记录所有违反行为，但允许插入或更新操作。db.createCollection( "contacts", &#123; validator: &#123; $or: [ &#123; phone: &#123; $type: "string" &#125; &#125;, &#123; email: &#123; $regex: /@mongodb\.com$/ &#125; &#125;, &#123; status: &#123; $in: [ "Unknown", "Incomplete" ] &#125; &#125; ] &#125;, validationAction: "warn" &#125;)#如下违规操作将会报警，并由于是warn，所以写入成功db.contacts.insert( &#123; name: "Amanda", status: "Updated" &#125; ) 约束(restriction) 无法在admin,local,config数据库的集合 和 system.*集合 里面指定验证符(validator)。 绕过文档验证 通过bypassDocumentValidation选项来绕过文档验证。 数据建模理论数据模型设计一个高效的数据模型能够很好的满足应用程序的需求。设计一个文档数据结构最关键的考量就是决定是使用嵌套(embdded)还是引用(reference)。 内嵌式数据模型(非规范化)在MongoDB里面，可以把相关的数据包括在一个单个的结构或者文档下面。这样的数据模型也叫作非规范化模式。 内嵌数据可以让应用程序把相关的数据保存在同一条数据记录里面，这样，应用程序就可以发送较少的请求给MongoDB来完成常用的查询和更新请求。 一般来说，下述情况建议使用内嵌数据模型： 数据对象之间有包含(contain)关系； 数据对象间有一对多的关系。 通常情况下，内嵌数据会对读操作有比较好的性能提高，可以使应用程序在一个单个操作就可以完成对数据的读取。同时，内嵌数据也对更新相关数据提供了一个原子性写操作。 规范化数据模型一般来说，下述情况可以使用规范化模型： 内嵌数据会导致很多数据的重复，并且读性能的优势又不足与盖过数据重复的弊端时； 需要表达比较复杂的多对多关系时； 大型多层次结构数据集。 MongoDB特性和数据模型的关系MongoDB的数据建模不仅仅取决于应用程序的数据需求，也要考虑MongoDB本身的一些特性。 文档增长性(increase)如果更新操作导致文档大小增加，那么可能需要重新设计数据模型，在不同文档之间使用引用的方式而非内嵌、冗余的数据结构。MongoDB会自动调整空白填充的大小以尽可能的减小文档迁移。你也可以使用一个预分配策略来防止文档的增长。 原子性(atomic)在MongoDB中，所有在文档级别的操作都具有原子性。一个单个写操作最多只可以修改一个文档。即使是一个会改变同一个集合中多个文档的命令，在同一时间也只会操作一个文档。即便是涉及多个子文档的多个操作，只要是在同一文档之内，这些操作仍旧是有原子性的。 尽可能保证那些需要在一个原子操作内进行修改的字段定义在同一个文档里面。如果你的应用程序允许对两个数据的非原子性更新操作，那么可把这些数据定义在不同的文档内。 把相关数据定义到同一个文档里的内嵌方式有利于这种原子性操作。对于那些使用引用来关联相关数据的数据模型，应用程序必须再用额外的读和写操作去取回和修改相关的数据。 分片(sharding)MongoDB使用分片来实现水平扩展。使用分片的集群可以支持海量的数据和高并发读写。使用分片技术把一个数据库内的某一个集合的数据进行分区，从而达到把数据分到多个mongod实例(或分片上)的目的。 MongoDB依据分片键分发数据和应用程序的事务请求。选择一个合适的分片键对性能有很大的影响，也会促进或阻碍MongoDB的定向分片查询和增强的写性能。所以在选择分片键的时候要仔细考量分片键所用的字段。 索引(index)对常用操作可以使用索引来提高性能。对查询条件中常见的字段，以及需要排序的字段创建索引。MongoDB会对_id自动创建唯一索引。 创建索引时，需要考虑索引的下述特征： 每个索引要求至少8KB的数据空间； 每增加一个索引，就会对写操作性能有一些影响。对于一个写多读少的集合，索引会变得很费时。因为每个插入必须要更新所有索引； 每个索引都会占一定的硬盘空间和内存(对于活跃的索引)。索引可能会用到很多这样的资源，因此对这些资源要进行管理和规划，特别是在计算热点数据大小的时候。 集合的数量某些情况下，可能需要把相关的数据保存到多个集合里面。比如： 12&#123; log: &quot;dev&quot;, ts:..., info: ... &#125;&#123; log: &quot;debug&quot;, ts:..., info: ... &#125; 一般来说，很大的集合数量对性能没有什么影响，反而在某些场景下有不错的性能。使用不同的集合在高并发批处理场景下会有很好的帮助。 当使用有大量集合的数据模型时，请注意： 每个集合有几KB的额外开销； 每个索引(包含_id)，需要至少8KB的数据空间； 每个MongoDB的数据库有且仅有一个命名文件(namespace file)(.ns)。这个命名文件保存了数据库的所有元数据，每个索引和集合在这个文件里都有一条记录； MongoDB的命名文件有大小的限制(默认16MB)。利用db.system.namespaces.count()查看。 包含大量小文档的集合如果你有一个包含大量小文档的集合，则应该考虑为了性能而嵌入。如果你可以通过一些逻辑关系将这些小文档分组，并且你经常通过这个分组来检索文档，那么你应该考虑将小文档”卷起来”成为包含一系列嵌入式文档的大文档。 将这些小文档“卷起来”成为逻辑分组，意味着检索一组文档的查询设计顺序读取和较少的随机磁盘访问。此外，将文档“卷起”并将公共字段移动到较大的文档会使字段上的索引受益。公共字段的副本将会减少，并且相应索引中的关联键条目也会减少。 然而，如果你通常只需要检索分组中的一个文档的子集，那么“滚动”文档可能无法提供更好的性能。此外，如果晓得，独立的文档代表数据的自然模型，那你应该维护改模型。 小文档的存储优化(storage optimization)每个MongoDB文档都包含一定的开销(overhead)，这些开销通常是无关紧要的。但如果文档只有几个字节，那就相当重要了。 考虑以下有关优化这些集合的存储利用率的建议： 显示地使用_id字段； 使用较短的字段名称； 嵌套文档。 数据生命周期管理数据模型决策应考虑数据生命周期管理。 集合的*TTL功能在一段时间后标识文档到期。如果应用程序需要一些数据才能在数据库中持久化一段有限的时间，请考虑使用TTL特性。 此外，你的应用程序仅使用最近插入的文档，请考虑限制集。 数据模型例子与范式文档关系建模一对一关系建模：内嵌文档模型用内嵌文档方式实现一对一关系。 一对多关系建模：内嵌文档模型用内嵌文档方式实现一对多关系。 一对多关系建模：文档引用模式用文档引用实现一对多关系。 树结构建模父文档引用父文档引用模式用一个文档来表示树的一个节点。每一个文档除了存储节点的信息，同时也保存该节点父节点文档的id值。 1234567891011121314db.test.insert(&#123; _id: "MongoDB", parent: "Databases" &#125;)db.test.insert(&#123; _id: "Databases", parent: "Programming" &#125;)db.test.insert(&#123; _id: "Programming", parent: "Books" &#125;)db.test.insert(&#123; _id: "Books", parent: null &#125;)#查询父节点db.test.findOne(&#123; _id: "MongoDB" &#125;).parent#对parent字段创建索引，这样可以快速的按照父节点查找db.test.createIndex(&#123; parent: 1 &#125;)#查询一个父节点的所有子节点db.test.find(&#123; parent: "Databases" &#125;) 子文档引用子文档引用模式用一个文档来表示树的一个节点。每一个文档除了存储节点信息外，同时也用一个数组来保存该节点的所有子节点的id值。 1234567891011121314db.test.insert(&#123; _id: "MongoDB", children: [] &#125;)db.test.insert(&#123; _id: "Databases", children: [ "MongoDB", "dbm" ]&#125;)db.test.insert(&#123; _id: "Programming", children: [ "Languages", "Databases" ]&#125;)db.test.insert(&#123; _id: "Books", children: [ "Programming" ]&#125;)#查询子节点db.test.findOne(&#123; _id: "Databases"&#125;).children#对children字段创建索引，这样就可以快速按照子节点查找db.test.createIndex(&#123; children: 1 &#125;)#查找一个子节点的父节点和同级节点db.test.find(&#123; children: "MongoDB" &#125;) 祖先数组(ancestors array)祖先数组模式用一个文档来表示树的一个节点。每一个文档除了存储节点的信息，同时也存储了对父文档及祖先文档的id值。 1234567891011121314db.test.insert(&#123; _id: "MongoDB", ancestors: [ "Books", "Programming", "Databases" ], parent: "Databases" &#125;)db.test.insert(&#123; _id: "Databases", ancestors: [ "Books", Programming" ], parent: [ "MongoDB", "dbm" ]&#125;)db.test.insert(&#123; _id: "Programming", ancestors: [ "Books" ], parent: "Books" &#125;)db.test.insert(&#123; _id: "Books", ancestors: [ ], parent: null &#125;)#查询一个节点的祖先节点db.test.findOne(&#123; _id: "MongoDB" &#125;).ancestors#对ancestors创建索引db.test.createIndex(&#123; ancestors: 1 &#125;)#利用ancestors字段来查找某个节点的所有子代节点db.test.find(&#123; ancetors: "Programmming" &#125;) 物化路径(materialized path)物化路径模式将每个树节点存储在文档中。除了存储节点信息外，同时也存储了祖先文档或路径的id值。 123456789101112131415db.test.insert(&#123; _id: "Books", path: null &#125;)db.test.insert(&#123; _id: "Programming", path: ",Books," &#125;)db.test.insert(&#123; _id: "Databases", path: ",Books,Programming," &#125;)db.test.insert(&#123; _id: "MongoDB", path: ",Books,Programming,Databases," &#125;)#查询整个树的所有节点并按path排序db.test.find().sort(&#123; path: 1 &#125;)#可以在path字段上使用re来查询db.test.find(&#123; path: /,Programming,/ &#125;)db.test.find(&#123; path: /^,Books,/ &#125;)#在path字段上创建索引db.test.createIndex(&#123; path: 1 &#125;) 嵌套集合(nested set)嵌套集合模式对整个树结构进行一次深度优先的遍历。遍历时候对每个节点的压栈和出栈作为两个不同的步骤记录下来。每一个节点就是一个文档，除了节点信息外，文档还保存父节点的id以及遍历的两个步骤编号。压栈是的步骤保存到left字段里，而出栈时的步骤编号则保存到right字段里。 12345678db.test.insert(&#123; _id: "Books", parent: 0, left: 1, right: 12 &#125;)db.test.insert(&#123; _id: "Programming", parent: "Books", left: 2, right: 11 &#125;)db.test.insert(&#123; _id: "Databases", parent: "Programming", left: 5, right: 10 &#125;)db.test.insert(&#123; _id: "MongoDB", parent: "Databases", left: 6, right: 7 &#125;)#查询摸个节点的子代节点db.test.find(&#123; left: &#123; $gt: db.test.findOne(&#123; _id: "Databases" &#125;), right: &#123; $lt: db.test.findOne(&#123;"_id: "Databases"&#125;) &#125; &#125;) 具体应用模型举例原子性事务建模如何使用内嵌技术来保证同一文档内相关字段更新操作的原子性。 举例来说，假设你在设计一个图书馆的借书系统，你需要管理书的库存量以及出借记录。一本书的可借数量加上借出数量的和必须等于总的保有量，那么对这两个字段的更新必须是原子性的。 关键词搜索建模描述了一种把关键词保存在数组里并使用多键索引来实现关键词搜索功能的方法。 为实现关键词搜索，在文档内增加一个数组字段并把每一个关键词加到数组里。然后你可以对该字段建一个 多键索引。这样你就可以对数组里面的关键词进行查询了。 货币数据建模处理货币数据的应用程序通常需要捕获小数(franctional)货币单位，并在执行算术时需要精确地模拟十进制四舍五入。许多现代系统(float,double)使用的基于二级制的浮点运算不能精确地表示小数，而且需要某种程度的近似，因而不适合于货币运算。因此，在货币数据建模时，这一约束是一个重要的考虑因素。 数字模型如果需要查询数据库中精确、数学书有效匹配或需要执行Server端算术，则数字模型可能是适合的。 非数字模型如果需要在Server端做一些对货币数值的数学计算，那么严格精度可能会更合适一些。 时间数据模型MongoDB默认存储UTC时间，并将任何本地时间转换成这种形式。 MongoDB管理administration The administration 文档说明了MongoDB实例和部署正在进行的操作和维护。本文档包括这些问题的高级概述，以及涵盖操作MongoDB的特定过程的教程。 操作清单(operation checklist)如下清单，提供了帮助你避免在MongoDB部署中出现问题的建议。 文件系统(file system) 将磁盘分区与RAID配置对齐； 避免对dbpath使用NFS。使用NFS会导致性能下降和不稳定； 针对Linux/Unix的文件格式，建议使用XFS或EXT4。如果可能的话，对MongoDB使用XFS性能会更好； 对于WiredTiger存储引擎，强烈建议使用XFS来避免使用EXT4时发现的性能问题； 针对Windows，不要使用FAT(FAT16/32/exFAT)文件系统，请使用NTFS文件系统。 复制(replication) 验证所有非隐藏副本集成员的RAM, CPU, 磁盘, 网络设置, 配置等方面是否相同； 配置oplog的大小来适合你的用例； 确保副本集包好至少3个以journaling方式运行的数据承载节点； 在配置副本集成员时使用主机名(hostname)，而不是IP地址； 确保所有的mongod实例之间使用全双工网络； 确保每台主机都能解析它自己； 确保副本集包含奇数个投票的成员(voting members)，确保票数不会相等则一定会有主被选举出来； 确保mongod实例有0或1票； 为了高可用(high availability)，副本集集群最少部署3台数据中心。 分片(sharding) 将配置服务器放置于专用硬件，以便在大型集群中实现最佳性能。确保硬件有足够的RAM来讲数据文件完全存储到内存中，并且有专门的存储； 使用NTP同步分片集群上所有组件的时钟； 确保Mongod, mongos和配置服务器之间的全双工网络连接； 使用CNAME将配置服务器标识到集群中，以便可以在不停机的情况下重命名和重新编号配置服务器。 Journaling 确保所有实例都使用journaling； 将journal放置于低延迟(low-latency)磁盘上，用于编写密集的工作负载。注意，这将影响快照式备份(snapshot)，因为构成数据库状态的文件将驻留在单独的volume上。 硬件(hardware) 使用RAID10和SSD能够获得最佳性能； 确保每个mongod为它的dbpath提供了IOPS； 在虚拟环境中运行时，避免动态内存功能； 避免将所有副本集成员放置于相同的SAN(存储区网络)中。 部署到云上 AWS; Azure; Aliyun; Tencent. 操作系统配置Linux 关闭hugepages和defrag； 调整存储数据库文件设备上的readahead设置，以适应用例； 在虚拟环境中的RHEL7/CENTOS7上禁用优化工具； 为SSD驱动使用noop或deadline磁盘调度； 禁用NUMA或将vm.zone_reclaim_mode设置为0，并运行node interleaving的mongod实例； 调整硬件的ulimit值以适应实例； 对dbpath挂载点使用noatime； 对你的部署配置足够的文件句柄(fs.file-max value of 98000)，内核pid限制(kernel.pid_max value of 64000)，每个进程的最大线程数(kernel.threads-max value 0f 64000)； 确保你的系统配置有swap交换分区； 确保系统默认TCP keepalived设置正确。 Windows 考虑禁用NTFS的最后访问时间更新。这类似与在Unix-like系统上禁用atime。 备份(backup) 安排备份和恢复过程的定期测试，以便手头有时间估计，并恢复其功能。 监控(monitor) 监视Server的硬件统计信息(磁盘使用，CPU，可用磁盘空间…) 监视mongodb的状态。 负载均衡(load balance) 配置负载均衡启用”sticky session”或“client affinity”，对现有连接有足够的超时时间； 避免放置负载均衡器在MongoDb集群或副本集组件。 开发清单(development checklist)如下清单，提供了帮助你避免在MongoDB部署期间出现的问题的建议。 数据持久性(data durability) 确保副本集至少包含3个(带有w:majority)数据承载节点，这3个数据承载节点需要为副本集的高数据持久性； 确保所有实例都是用了journaling。 架构设计(schema design)MongoDB中的数据具有动态结构。collection并不要求document结构。这有助于迭代开发和多态性。然而，集合中的文档通常具有高度的同类结构。 确保你需要的集合集中的索引(indexes)支持你的查询(query)。除了_id索引，你必须显式的创建所有索引； 确保你的架构设计支持你的开发类型； 确保你的架构设计不依赖于长度不受绑定的索引数组； 再架构设计时考虑文档大小限制。 复制(replication) 使用奇数个副本集成员以确保选举顺利进行。如果有偶数个成员，请使用仲裁者(arbiter)以确保级数的选票； 确保使用监控工具和适当的写关注来保持从库数据最新； 不要使用从库读取来扩展整体读取吞吐量。 分片(sharding) 确保你的sharded key将负载均匀地分配到分片上； 对需要按分片数进行缩放的工作负载(workload)使用有针对性的操作； 对非目标(non-targeted)查询，总是从主节点读取可能对陈旧或孤立的数据很敏感； 当向新的非散列(hash)分片集合中插入大数据集时，Pre-split and manually balance chunks。 驱动(drivers) 使用连接池(connection pooling)； 确保你的应用程序在复制集选举期间还能够处理瞬时写入(transient write)和错误读取； 确保你的应用程序处理失败的请求并适时地重试它们； 使用指数退避逻辑重试数据库请求； 如果需要计算数据库操作的编译执行时间，对读操作使用cursor.maxTimeMS()，对写操作使用wtimeout。 性能(MongoDB Perfomance) 当遇到性能下降时，通常与数据库的访问策略、硬件可用性和开放的数据库连接数相关； 一些用户可能由于不适当的索引策略或结果不足而经历性能限制，或由于架构设计模式差； 性能问题可能表明数据库正以最大限度运行，是时候给数据库添加额外的容量(capacity)了。尤其是，应用程序的工作集应该有足够的物理内存。 锁紧性能(lock performance) MongoDB使用锁系统来确保数据集的一致性。如果某些操作需要长时间运行(long-running)，或队列窗体，随着请求和操作等待lock，性能将会下降； 锁相关的减速是可以间歇的，可查看lock部分是否影响了性能； locak.deadlockCount提供了遭遇死锁(deadlocks)的次数； 如果globalLock.currentQueue.total很高，则可能有大量的请求在等待lock。这表明并发问题(concurrency issue)可能影响性能； 如果globalLock.totalTime时间比uptime高，那么数据库在锁定状态中存在了大量时间； 长查询(long query)可能会导致索引无效使用、非最佳(non-optimal)建构设计、差的查询结构、系统体系结构问题、RAM不足导致页面错误(page fault)和磁盘读取。 连接数(number of connections)在某些情况下，应用程序和数据库之间的连接数量可能超出服务器处理请求的能力。serverStatus文档中的以下字段可以提供观察： globalLock.activeClients包含正在进行或排队的活动操作的客户端总数； connnections由以下两个字段组成： 1，connections.current连接到数据库实例的当前客户端总数； 2，connections.available可用的连接总数。 如果有大量的并发程序请求，则数据库可能无法满足需求。那么就需要增加部署的容量。 对于读操作巨大(read-heavy)的应用程序，增加你的副本集大小并将读操作分发给SECONDARY。对于写操作巨大(write-heavy)的应用程序，部署分片并将一个或多个分片添加到分片集群中，以便在mongod实例之间分配负载。 连接数到达峰值也可能是应用程序或驱动错误所导致的结果。 除非收到系统范围的限制，否则MongoDB对传入连接没有限制。在基于Unix系统上，可使用ulimit命令或修改/etc/sysctl系统文件来修改系统限制。 数据库性能分析(database profiling)MongoDB的profiler是一种数据库分析系统，可以帮助识别低效的查询和操作。 有如下分析级别(profiling-level)可用： Level Settiing 0 Off.No profiling 1 On.Only includes “slow” operations 2 On.Includes all operations 在mongo shell中运行如下命令来配置性能分析器： 123#dbsetProfilingLever()db.setProfilingLevel(1) slowOpThresholdMs的设置定义了什么是一个slow操作，要设置一个慢操作的阈值(threshold)，可以在运行时作为db.setProfilingLevel()操作的一个参数来配置slowOpThresholdMs。 默认情况下，mongod将会把所有的慢查询(slow query)记录到日志，这是由slowOpThresholdMs定义的。 通过在mongo shell中使用show profile，你可以在数据库中的system.profile集合中查看性能分析器的输出。或者执行如下操作： 12345#返回超过100ms的所有操作，这个值请高于阈值`slowOpThresholdMs`db.system.profile.find( &#123; millis: &#123; $gt: 100 &#125; &#125;) 你必须使用查询操作符去访问system.profile文档中的查询字段。 数据库性能分析器(databases profiler)数据库性能分析器(db profiler)收集有关MongoDB的写操作、游标和运行在mongod实例上的命令的细微数据，你可以在每个数据库或每个实例基础上启用性能分析(profiling)。默认情况系，分析器是关闭的。启用profiling的时候需要配置profiling leverl。 The database profiler将所有的数据收集到system.profile集合中，它是一个限制集(capped collection)。 分析等级(Profiling levels) 0， 关闭分析器，不收集任何数据。mongod总是将操作时间长于slowOpThresholdMs的值写入日志。这是默认分析器级别； 1， 只收集慢操作的分析数据。默认是以100ms； 2， 收集所有数据库操作的分析数据。 启用分析器(profiling)和设置分析级别(profiling level)当启用profiling，也要设置profiling level，分析器将数据记录到system.profile集合。当你在数据库中启用profiling后，MongoDB会在数据库中创建system.profile集合。 使用db.setProfilingLevel()来设置profiling level和启用profiling。 1db.setProfilingLevel(1) 指定慢操作的阈值(the Threshold for slow operations) 慢操作的阈值(threshold)应用于整个mongod实例。当你修改了阈值，那你就对所有的数据库实例进行了修改。修改了数据库慢操作的阈值同样也会影响整个mongod实例性能分析子系统的慢操作阈值。默认情况下，慢操作的阈值为100ms。性能分析level-1将会记录长于阈值的慢操作到日志。 要更改阈值，请将两个参数(parameter)在mongo shell传递给db.setProfilingLevel()。第一个参数是为当前的数据库设置profiling level，第二个参数是为整个mongod实例设置默认的慢操作阈值。 栗子： 123456mongo&gt;use zhang&gt;db.serProfilingLevel(1,100)#会在zhang数据库下生产system.profile集合 检查分析等级(check profiling level) 1234567db.getProfilingStatus()#default#&#123; &quot;was&quot; : 0, &quot;slowms&quot; : 100 &#125;db.getProfilingLevel()#0 为一个完整的mongod实例启用profiling 在测试环境中，处于开发目的，你可以为一个完整的mongod实例启用profiling功能。性能分析等级应用于mongod实例中的所有数据库。 12#设置level：1，slowOpThresholdMs: 50mongod --profile 1 --slowms 50 数据库分析和分片 无法对mongos实例启用profiling。要对分片集群启用profiling功能，你必须对分片集群中的每个mongod实例启用profiling功能才行。 查看性能分析器的数据(profiler data)数据库性能分析器关于数据库操作的日志信息放置于system.profile集合中。如需查看性能信息，请查询该集合。 栗子： 1234567891011121314151617db.system.profile.find()db.system.profile.find().limit(10).sort(&#123; ts: -1 &#125;).pretty()#指定时间db.system.profile.find( &#123; millis: &#123; $gt: 5 &#125; &#125; ).pretty()#除了某个命令外db.system.profile.find(&#123; op: &#123; $ne: &apos;cmd&apos; &#125; &#125;).pretty#某个特定集合db.system.profile.find( &#123; ns: &apos;db.collection&apos; &#125; ).pretty()#显示最近的事件show profile 分析器开销(profiler overhead)分析器对性能影响很小。system.profile集合是一个默认大小为1MB的限制集。这样大小的集合通常可以存储上千份分析文档，但一些应用程序可能在每次操作中只使用或多或少的分析数据。 在Primary上面修改system.profile集合的大小 停止profiling； 删除(drop)system.profile集合； 新建一个system.profile集合； 重启profiling。 12345use dbdb.serProfilingLevel(0)db.system.profile.drop()db.createCollection( &quot;system.profile&quot;, &#123; capped: true, size: 4000000 &#125; )db.setProfilingLevel(1) 在Secondary上修改system.profile集合的大小 在Secondary上修改system.profile集合的大小，你必须停止Secondary，然后以standalone模式运行它，之后执行修改步骤。当做完上述步骤之后，以一个副本集成员的方式使用standalone模式重启它。 禁用显见的大页面(Disable Transparent Huge Pages)Transpatent Huge Pages(THP)是一个Linux的内存管理系统，通过使用更大的内存页，减少了在具有大量内存的机器上进行Translation Lookaside Buffer(TLB)查找的开销。 然而，数据库工作负载(workload)在THP中的性能往往很差，因为它们往往具有稀疏的(sparse)而不是连续的(contiguous)内存访问模式。你应该在Linux机器上禁用THP来确保MongoDB获得最佳的性能。 1. 创建init.d脚本 12345678910111213141516171819202122232425262728293031323334353637383940#!/bin/bash### BEGIN INIT INFO# Provides: disable-transparent-hugepages# Required-Start: $local_fs# Required-Stop:# X-Start-Before: mongod mongodb-mms-automation-agent# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Disable Linux transparent huge pages# Description: Disable Linux transparent huge pages, to improve# database performance.### END INIT INFOcase $1 in start) if [ -d /sys/kernel/mm/transparent_hugepage ]; then thp_path=/sys/kernel/mm/transparent_hugepage elif [ -d /sys/kernel/mm/redhat_transparent_hugepage ]; then thp_path=/sys/kernel/mm/redhat_transparent_hugepage else return 0 fi echo 'never' &gt; $&#123;thp_path&#125;/enabled echo 'never' &gt; $&#123;thp_path&#125;/defrag re='^[0-1]+$' if [[ $(cat $&#123;thp_path&#125;/khugepaged/defrag) =~ $re ]] then # RHEL 7 echo 0 &gt; $&#123;thp_path&#125;/khugepaged/defrag else # RHEL 6 echo 'no' &gt; $&#123;thp_path&#125;/khugepaged/defrag fi unset re unset thp_path ;;esac 2. 使之可执行 1chmod 755 /etc/init.d/disable-transparent-hugepages 3. 配置操作系统以在开机的时候运行它 12345678910#Debian系列update-rc.d disable-transparent-hugepages defaults#RedHat系列chkconfig --add disable-transparent-hugepages#SUSEinsserv /etc/init.d/disable-transparent-hugepages 4. 如果适用，覆盖(override)tuned和ktune 12345678910111213#RedHat/CentOS7mkdir /etc/tuned/no-thpvim /etc/tuned/no-thp/tuned.conf[main]include=virtual-guest[vm]transparent_hugepages=nevertuned-adm profile no-thp 5. 测试你做的改变 1234cat /sys/kernel/mm/redhat_transparent_hugepage/enabledcat /sys/kernel/mm/redhat_transparent_hugepage/defrag#always madvise [never] 另一种简便的方式来禁用THP 123456vim /etc/rc.d/rc.localecho 'never' &gt; /sys/kernel/mm/transparent_hugepage/enabledecho 'never' &gt; /sys/kernel/mm/transparent_hugepage/defragchmod u+x /etc/rc.d/rc.local Unix系统下的ulimit的设置大多Unix-Like系统，都提供了限制每个进程和每个基本用户使用线程，文件和网络连接等系统资源的一些方法。ulimits防止单个用户使用太多的系统资源。有时，这些限制的默认值太小，这会导致MongoDB操作过程中出现一系列问题。 123#限制文件#/etc/security/limits.conf#/etc/security/limits.d/ 资源利用mongod和mongos每次使用线程和文件描述符来跟踪连接和管理内部操作。 通常情况下，所有的mongod和mongos实例： 利用每一个文件描述符和线程来跟踪每个即将到来的连接； 将每个内部线程或pthread作为一个系统进程来跟踪。 mongod mongod实例使用的每个数据文件都有一个文件描述符； 当storage.journal.enabled为true是，mongod进程实例使用的每个日志文件都有一个文件描述符； 在复制集中，每个mongod保持一个连接复制集中所有其他集合成员的连接。 mongos mongos实例与每个分片都保持一个连接池，所有mongos可以重用连接，这样因为不用建立新连接，从而能快速的满足请求； 通过限制连接数，可以防止mongos因在mongod实例上创建太多连接而产生级联效应。 资源限制的设置ulimit是指每个user使用各种资源的限制值。因此，无论你的mongod实例是以单个用户多进程执行还是以多mongod进程执行，都可以看到对这些资源的连接。 ulimits有hard和soft两个方式。 hard：是指用户在任何时候都可以活动的进程的最大数量，这是上限。没有任何non-root进程能够增加hard ulimit； soft：是对会话或进程实际执行的限制，但任何进程都可以将其增加到hard ulimit的最大值。 较低的soft limit可能无法创建新线程(thread)，如果连接数太高，则关闭错误连接。因此，将soft和hard的值都设置为推荐值是非常重要的。 修改ulimit设置之后，要重启程序修改值才会有效。可通过/proc文件系统查看运行进程当前的限制值。 使用ulimit对系统限制的改变在系统重启后都会恢复到默认值。需要修改其它文件来确保修改一直生效。 ulimit 123456789101112131415161718ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 7170max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 1024pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 7170virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited 修改ulimit 123456789#-f (文件大小)#-t (cpu 时间)#-v (虚拟内存)#-n (单个进程文件打开数)#-m (memory size)#-u (可打开的进程/线程)ulimit -t unlimitedulimit -u 64000 配置和维护(maintenance)Run-time databases configurationcommand line和configuration file interfaces为MongoDB管理员提供了控制数据库系统操作的大量选项和设置。 使用配置文件启动MongoDB实例： 12mongod --config /etc/mongod.confmongod -f /etc/mongod.conf 配置数据库mongodb的配置文件从MongoDB3.0以后使用YAML格式。 1234567891011121314151617vim /etc/mongod.confprocessManagement: fork: truenet: bindIp: 127.0.0.1 port: 27017storage: dbPath: /var/lib/mongodbsystemLog: destination: file path: "/var/log/mongodb/mongod.log" logAppend: truestorage: journal: enabled: true 对于大多数以standalone模式运行的servers，以上是一个足够的基本配置。Unix-Like操作系统需要以超级用户(root)权限才能运行端口小于1024的程序。 安全考虑(security consideration)下面的配置选项集合对于限制对于mongod实例的访问非常有用。 123456net: port: 27017 bindIp: 127.0.0.1,192.168.1.11security: authorization: enabled 复制集和分片配置(replication and sharding configuration)复制集的配置非常简单，只需要replSetName在集合中的所有成员具有一致的副本集名字。 12replication: replSetName: zhang 开启副本集认证： 12345678910#利用openssl生成keyFileopenssl rand -base64 256 &gt; /dir/path/mongodb/keyFilesecurity: replSetName: zhang keyFile: /dir/path/mongodb/keyfilechown -R mongod:mongod /dir/path/mongodb 设置keyFile启用身份认证，并为复制集成员在相互身份认证时使用的认证文件指定一个密钥文件。密钥文件的内容是任意的，但在复制集中的所有成员和连接到该集合的mongos实例之间必须相同。不然怎么能认证通过呢。秘钥文件的大小必须小于1KB，并且只能包含base64集中的字符，并且此密钥文件在Unix系统上必须not have group或not have world permissions。 分片配置(sharding configuration)分片要求配置服务器和分片服务器的Mongod实例具有不同的mongod配置文件。配置服务器存储集群的元数据(metadata)，而分片服务器存储数据(data)。 在配置文件中给mongod实例配置配置服务器(config-server)，给sharding.clusterRole指定配置服务器。 12345678910#配置config-servernet: bindIp: 192.168.1.11 port:27001replication: replSetName: zhangsharding: clusterRole: configserver#configserver必须要是一个部署的副本集 在同一个系统上运行多个数据库实例(multiple database instances)在许多情况下，在单个系统(single system)上运行多个数据库实例是不推荐的。 但可能由于一些部署或者测试的目的，你需要在单个系统上运行多个mongod实例。在这些情况下，请为每一个mongod实例使用一个基本的配置文件，但要额外配置如下值： dbpath(必须); pidFilePath(必须); systemLog(非必须，但建议开启); 栗子： 1234567891011121314151617181920212223242526#mongod_27017实例vim /etc/mongod_27017.confsystemLog: path: /var/log/mongod_27017.logstorage: dbPath: /var/lib/mongodb27017processManagement: pidFilePath: /var/lib/mongodb27017/mongod_27017.pid#mongod_27018实例vim /etc/mongod_27018.confsystemLog: path: /var/log/mongod_27018.logstorage: dbPath: /var/lib/mongodb27018processManagement: pidFilePath: /var/lib/mongodb27018/mongod_27018.pid##启动实例mongod -f /etc/mongod_27017.confmongod -f /etc/mongod_27018.conf 诊断配置(diagnostic configuration)以下配置选项可控制各种mongod行为，用以诊断的目的： operationProfiling.mode设置database profiler level。profiler在默认情况下不处于活动状态，因为它本身可能会影响性能。除非启用它，否则不会对查询进行分析； operationProfiling.slowOpThresholdMs配置慢操作的阈值以确定查询是否慢，用以作为分析器记录日志的目的。默认阈值是100ms； systemLog.verbosity控制mongod写入日志的日志输出量。只有在遇到未在正常日志记录级别中反映的问题是才启用此选项。 升级(upgrade)到最新的MongoDB修订(revisions)提供了security patches、bug fixes以及不包含任何反向破坏更改的新的或更改的功能。但是，最新版本也可能存在一些兼容性问题，请注意。 升级之前(before upgrading) 确保备份了最新的数据集； 有关特定MongoDb版本的特殊事项和兼容性问题，请注意查看； 如果你的安装包包括了复制集，在升级期间预定维护窗口(maintanence window)。 升级程序(upgrade procedure)在升级之前请一定要备份所有数据！ 按照如下步骤升级： 对于使用认证的部署，首先升级所有的MongoDB drivers； 升级分片集群； 升级任一standalone实例； 升级不属于分片集群的任一副本集。 升级一个MongoDB实例要升级mongod或mongos实例，使用如下方法之一： 使用操作系统的包管理工具和官方MongoDB包进行升级(推荐的方法)； 使用新二进制文件替换现有二进制文件来升级实例。 替换现有二级制文件(replace the existing binaries)在升级MongoDB前请一定备份你的所有数据！ 首选的升级方式是使用包管理工具和官方的MongoDB包。 通过替换现有二进制文件来升级mongod或mongos实例，执行如下操作： 下载最新MongoDB二进制文件到本地，并解压缩到MongoDB安装目录； 关闭实例； 替换二进制文件； 重启实例。 升级分片集群 禁用分片集群的平衡器(blancer)； 升级配置服务器(config-server)； 升级每个分片； 升级每个mongos实例； 重新启用平衡器。 升级复制集若要升级复制集，请单独升级每个副本集成员。从Secondary开始，最后以Primary结束。 升级SECONDARY 升级SECONDARY的mongod实例； 升级一个Secondary之后，在升级下一个实例之前，请等待Secondary恢复(recover)到SECONDARY state。使用rs.status()命令来检查复制集成员的状态。 升级PRIMARY 使用rs.stepDown命令来退出primary，以启动正常的故障转移过程； 查看是否有另外的SECONDARY节点成为了PRIMARY节点； 关闭并升级实例。 管理mongod进程开启mongod进程1234567891011121314151617mongod#指定数据目录mongod --dbpath /dir/mongodb/#指定TCP端口mondod --port 12345#将mongod以守护进程的方式启动mongod --fork --logpath /var/log/mongod.log#其他选项mongod --help 停止mongod进程1234567891011121314151617#使用shutdownServer()use admindb.shutdownServer()#使用--shutdownmongod --shutdown#使用ctrl+cctrl+c#使用kill#千万不要使用kill -9(SIGKILL)来终止mongodkill mongod_pidkill -2 mongod_pid 停止一个复制集步骤： 检查SECONDARY的oplog的时间戳； 如果从节点的时间戳落后于主节点10s内，mongod将会返回不会被关闭的消息。你可以传递一个timeoutSecs参数给shutdown命令来等待从节点追上主节点； 一旦从节点追上进度或60s后，主节点将会关闭。 强制关闭复制集：db.adminCommand( { shutdown: 1, force: true } ) 如果没有节点能立刻更新到最新的数据，发送shutdown加上timeoutSecs参数来在指定的时间内保持对从节点的检查。如果在分配的时间内有任意的一个从节点追上，主节点将会关闭。反之，主节点不会关闭。 1234db.adminCommand(&#123; shutdown: 1, timeoutSecs: 5 &#125;)#或db.shutdownServer(&#123; timeoutSecs: 5&#125;) 终止(Terminate)运行的操作MongoDB提供了两种方法来终止正在运行的操作。 maxTimeMS() db.killOp() maxTimeMS()maxTimeMS()方法给一个操作(operation)设置了时间限制(time limit)。这个时间单位默认是毫秒(ms)。当这个操作达到了指定的时间限制时，MongoDB将在下一个中断点(interrupt point)中断这个操作。 栗子： 123456789101112131415db.location.find( &#123; "town": &#123; "$regex": "(Pine Lumber)", "$options": 'i' &#125; &#125; ).maxTimeMS(30)db.runCommand( &#123; distinct: "collection", key: "city", maxTimeMS: 45 &#125;) killOpkillOp()方法将在下一个中断节点中断正在运行的操作。killOp()方法通过操作ID(operation ID)来标识目标操作。 栗子： 12345db.killOp(&lt;opID&gt;)#查看正在运行的操作db.currentOp() 注意：终止正在运行的操作时一定要谨慎！只使用db.killOp()方法来终止由客户端发起的操作，而不要终止内部数据库(internal database)的操作。 轮询(rotate)日志文件当使用--logpath选项或systemLog.path设置时，mongod或mongos实例会将所有活动和操作的实时账户报告给日志文件。默认情况下，只有当使用了logRotate命令，或者mongod或mongos进程从操作系统接收到一个SIGUSR1信号时，才会进行日志轮询响应。 MongoDB的标准日志轮询方法会存档当前日志文件并启动一个新的日志文件。为此，mongod或mongos实例将通过ISODate日期格式的UTC时间戳来重命名当前日志文件。然后它会打开一个新的日志文件，关闭旧的日志文件，并将所有新的日志发送到新的日志文件。 你也可以通过配置MongoDB的systemLog.logRatate或--logRotate选项，来支持Unix/Linux的日志轮询功能。最后，你可以使用--syslog选项来配置mongod发送日志数据到系统日志。在这种情况下，你可以选用其他的日志轮询工具。 默认日志轮询行为在mongo shell中轮询日志： 123456789101112131415#开启一个实例mongod -v --logpath /var/log/mongodb/test01.log#列出日志文件ls /var/log/mongodb/test01.log*#轮询日志文件mongo&gt;use admin&gt;db.runCommand(&#123; logRotate: 1 &#125;)#查看新的日志文件ls /var/log/mongodb/test01.log*#new: test01.log#old: test01.log-2018-01-11T08-22-50 使用--logRotate reopen选项轮询日志： 1234567mongod -v --logpath /var/log/mongodb/test01.log --logRotate reopen --logapendls /var/log/mongodb/test01.log*mongo&gt;use admin&gt;db.runCommand(&#123; logRotate: 1 &#125;) 系统日志轮询(Syslog log rotate)1mongod --syslog 使用SIGUSR1强制日志轮询对于基于Unix/Linux的系统，可以使用SIGUSR1信号来轮询单个进程的日志。 1kill -SIGUSR1 &lt;mongod-pid&gt; 数据中心意识(data center awareness)MongoDB部署中的分离(segregation)操作MongoDB拥有许多特性，包括允许数据库管理员和开发者在部署数据库的过程中通过一些功能或地理组群对数据库应用进行分割操作。 MongoDB支持跨越不同维度的操作的分段，这可能包括了在单个数据中心(single data center)的部署中的多数据中心(multi-date center)部署、机架、网络或电源电路的多个数据中心和地理区域。 MongoDB还支持基于功能或操作参数的数据库分离操作，以确保某些mongod实例仅用于报告工作负载，或只在特定的分片上分离集合的某些高频部分。 特别是在MongoDB中你可以： 确保写操作传播到复制集的特定成员； 确保复制集中的特定成员响应了查询操作； 确保分片键在具体范围上的平衡，并且驻留在特定的分片上。 区域(zone)管理分片区域(manage shard zones) 按位置分割数据(segementing data by location) 为SLA或SLO改变分层硬件 按应用程序或客户分割数据 Distributed Local Writes for Insert Only Workloads 管理分片区域 MongoDB备份方案(backup methods)在生存中部署MongoDB时，如果发生数据丢失的事件，你应该指定一个捕获和恢复备份的策略(strategy)。 back up with MongoDB cloud manager or Ops manager MongoDB Cloud Manager Ops Manager 复制底层数据文件进行备份(back up by copying underlying data files) 使用文件系统快照备份(back up with filesystem snapshots) 你可以通过复制MongoDB的底层数据文件来创建MongoDB部署的备份。如果MongoDB储存其数据文件的卷(volume)支持时间点快照(point-in-time snapshots)，则可以使用这些快照在某个时刻创建MongoDB系统的备份。文件系统的快照是一个操作系统的卷管理器的功能，并没有具体到MongoDB。通过文件系统快照，操作系统将卷的快照用作数据备份的基准。快照的机制取决于底层的存储系统。例如，在Linux上，逻辑卷管理器(LVM)可以创建快照。 要获得运行中的MongoDB进程的正确快照，必须启用日志记录(jorunaling)，并且日志必须与其它MongoDB数据文件存储在相同的逻辑卷上。如果没有启用日志记录，则无法保证快照将是一致有效地。 为了获得分片集群一致的快照，你必须禁用平衡器(balancer)和捕捉每一个分片的快照以及大约在同一时刻的配置服务器。 使用cp或scp备份 如果你的系统不支持快照功能，则可以使用cp，rsync或类似的工具直接复制文件。由于复制多个文件不是原子操作，因此你必须在复制文件之前停止对mongod的所有写入。否则，你将复制处于无效状态的文件。 复制底层数据而产生的备份不支持复制集的时间恢复节点，并且难以管理更大的共享集群。此外，这些备份很大。因为它们包括索引和复制底层存储填充和分片。相反，mongodump会创建较小的备份。 使用mongodump备份 如果在mongodump创建备份的同时，应用程序对数据进行修改，那么mongodump将会与这些应用竞争资源。 mongodump从一个MongoDB数据库中读取数据，并创建高保真度(high fidelity)的BSON文件。mongorestore工具可使用这个文件来进行MongoDB数据库恢复。mongodump和mongorestore是用于备份和恢复小型MongoDB部署的简单和高效的工具，但对于捕获较大的系统并不理想。 mongodump和mongorestore针对正在运行的mongod进程进行操作，可以直接操纵底层的数据文件。默认情况下，mongodump不会捕获local database数据库的内容。 mongodump只捕获数据库中的文档(documents)，用以给备份节省空间，但mongorestore或mongod必须在恢复数据之后重建索引。 当连接到MongoDB实例时，mongodump可能会对MongoDB的性能产生不利影响。如果你的数据大小大于系统内存，查询可能会将工作单元从内存中推开，从而导致页面错误。 当mongodump在捕获输出时，应用程序可以继续修改数据。对于复制集来说，mongodump提供了--oplog选项来用以在mongodump操作期间包含数据的oplog条目。这允许相应的mongorestore操作去还原所捕获的oplog。 然而，对于复制集来说，请考虑使用MongoDB Cloud Manager 或 Ops Manager来备份。 使用文件系统快照进行备份和恢复(back up and restore with filesystem snapshots)使用系统工具创建MongoDB系统的备份，诸如LVM，或block-level备份方法。使用系统工具来创建MongoDB数据文件的设备的副本。这些方法完成迅速、工作可靠，但是需要在MongoDB之外进行额外的系统配置。 快照综述(snapshots overview)快照的工作方式是在实时数据(live data)和一个特定快照卷之间创建指针(pointer)。这个指针在理论上等同于硬链接(hard link)。作为工作数据偏离的快照，快照过程使用写时复制(copy-on-write)策略。结果，快照又只存储修改的数据。 创建快照后，在文件系统上挂载(mount)快照镜像，并从中复制数据。生成的备份包含所有数据的完整副本。 Valid database at the time of snapshot 当快照生成时数据库必须有效。这就意味着数据库所接收的所有写入(write)都需要完整的写入磁盘————无论是journal还是数据文件。如果备份发生时磁盘上没有写入(write)，备份将不反映这些更改。 对于WiredTiger storage engine，数据文件反映了最后一个检查点(last checkpoint)的一致状态。每2GB的数据或每分钟就会出现检查点。 Entire disk image 快照创建一个整个磁盘镜像的镜像。除非你需要备份你的整个系统，否则考虑隔离(isolate)你的MongoDB数据文件、journal，并配置一个不包含任何其他数据的逻辑磁盘。或者，将所有的MongoDB数据文件保存在一个专用的设备上，这样你就可以在没有重复(duplicating)和无关(extraneous)数据的情况下进行备份。 Site failure precaution 确保将数据从快照复制到其他系统。这确保了在站点故障(site failure)的时候数据是安全的。 No incremental backups 本教程不包含增量备份(incremental backups)的过程。虽然不同的快照方法提供了不同的功能，但下面列出的LVM方法不提供捕获增量备份的任何容量。 Snapshots with journaling 如果你的mongod实例启用了journaling，则可以使用任何类型的文件系统和volume/block level快照工具来创建备份。 如果你在基于Linux的系统上管理你自己的基础架构，请使用LVM配置你的系统以提供磁盘包并提供快照功能。 在Linux上使用LVM进行备份和还原生产备份系统必须考虑一些特定环境的应用程序特定需求和因素。 Crete a snapshot 确保你创建的快照具有足够的空间来考虑数据的增长； 如果快照超出了空间，快照镜像将无法使用。请放弃这个逻辑卷并创建另外一个； 命令执行完毕时快照将存在。你可以随时直接从快照进行还原，也可以创建新的逻辑卷并从此快照还原到备用镜像； 虽然快照对于快速创建高质量的备份非常好，但它们并不是理想的作为存储备份数据的格式； 快照通常取决于并位于与原始磁盘镜像相同的存储基础架构上。因此，将这些快照存档并将其存储在别处至关重要。 12345#下面的这个vg-name指卷组名，这个卷组首先需要建立#系统卷组和设备的位置和路径可能因LVM的配置二略有不同#此大小不反映数据大小lvcreate --size 1G --snapshot --name mongodb-snap20180111 /dev/vg-name/mongodb Archive a snapshot 创建好snapshot之后，挂载mount快照并将数据复制到单独的存储中。 压缩快照： 12umount /dev/vg-name/mongodb-snap01dd if=/dev/vg-name/mongodb-snap01 | gzip &gt; mongodb-snap01.gz Restore a snapshot 同样适用LVM进行还原。 12345#lv-mongodb, vg0-vgnamelvcreate --size 1G --name mongodb vg0gzip -d -c mongodb-snap01.gz | dd of=/dev/vg0/mongodbmount /dev/bg0/mongodb /dir/path 还原的快照中有一个陈旧的mongo.lock文件，如果你没有从快照中删除此文件，那么MongoDB可能会认为锁文件指示的是不正常的关闭。如果你开启了storage.journal.enabled，但没有使用db.fsyncLock()的话，那不需要删除mongo.lock文件，反之，删除它。 Restore directly form a snapshot 不使用gz压缩文件下还原备份。 1234umount /dev/vg-name/mongodb-snap01lvcreate --size 1G --name mongodb vg0dd if=/dev/vg0/mongodb-snap01 of=/dev/vg0/mongodbmount /dev/vg0/mongodb /dir/path Remote backup storage 可以使用组合的进程和SSH实施离线备份。 12345umount /dev/vg-name/mongodb-snap01dd if=/dev/vg0/mongodb-snap01 | ssh user@host gzip &gt; /dir/path/mongodb-snap01.gzlvcreate --size 1G --name mongodb vg0ssh user@host gzip -d -c /dir/path/mongodb-snap-01.gz | dd of =/dev/vg0/mongodbmount /dev/vg0/mongodb /dir/path 使用单独卷上的Journal日志文件或没有Journal日志文件进行备份实例从MongoDB3.2开始，为了使用WiredTiger对MongoDB实例进行volume-level备份，数据文件和Journal日志文件不再要求驻留在一个卷上。 如果你的mongod实例没有使用Journal，或者启用了将Journal志文件放置于一个单独的卷上，则必须刷新(flush)对磁盘的所有写入，并在备份期间锁住数据库用以阻止写操作。如果有复制集(replica set)配置，那么你可以在SECONDARY上不接收读取用以备份数据。 1. 刷新写入磁盘并锁定数据库以防止进一步的写入： 12#锁住数据库db.fsyncLock(); 2. 使用快照备份数据库： 3. 解锁数据库： 12#解锁数据库db.fsyncUnlock(); 使用MongoDB工具进行备份和恢复(back up and restore with MongoDB tools)使用MongoDB提供的备份还原工具——mongodump和mongorestore来处理BSON data，对于创建小型部署的备份是很有用的。对于弹性(resilient)备份和非破坏性(non-disruptive)备份，使用文件系统或块级磁盘快照。 因为mongodump和mongorestore操作通过与正在运行中的mongod实例进行交互(interacting)，它们会影响正在运行的数据库的性能(performance)。这些工具不仅会为正在运行的数据库实例创建流量，还会强制数据库通过内存读取所有的数据。当MongoDB读取不经常(infrequently)使用的数据时，它会驱逐(evict)频繁(frequently)访问的数据，导致数据库正常工作负载的性能下降。 当使用MongoDB’s tools 来备份你的数据时，考虑如下建议： 标签文件(label file)，以便你可以识别备份的内容以及备份所反映的时间点 如果对你来说，mongodump和mongorestore对性能的影响是不可接受的，请使用替代备份策略——filesystem snapshot或MongoDB CloudManager 使用--oplog去捕获在mongodump期间的传入写(write)操作，以确保备份一致性的数据状态 通过将备份文件还原到测试环境中，以确认备份是可用的 MongoDB toolsMongoDB工具介绍及区别： mongoexportmongoexport is a utility that produces a JSON or CSV export of data stored in a MongoDB instance. mongoimportThe mongoimport tool imports content from an Extended JSON, CSV, or TSV export created by mongoexport, or potentially, another third-party export tool. mongodumpmongodump is a utility for creating a binary export of the contents of a database. mongodump can export data from either mongod or mongos instances.mongodump excludes the content of the local database in its output.The mongodump utility backs up data by connecting to a running mongod or mongos instance. mongorestoreThe mongorestore program writes data from a binary database dump created by mongodump to a MongoDB instance. 步骤(Procedures)使用mongodump备份 `mongodump·备份数据库，如果数据库启用了访问控制，则必须拥有每个备份的数据库查询的权限。内置的备份角色提供了执行任何和数据库备份有关所需的权限。 这就意味着你使用mongodump的user必须要对所备份的数据库有读取权限。 mongodump能够为整个服务器、数据库或集合创建备份，或者使用查询仅备份集合的一部分。 mongodump默认排除local数据库。 mongodump必须要能够连接到正在运行的mongod或mongos实例。默认连接为127.0.0.1:27017。 mongodump默认创建在当前目录下创建./dump备份文件。 如果mongodump备份目录中已经存在备份数据目录，那么mongodump将会覆盖它们。 指定认证库来认证你的用户名和密码。 使用oplog进行时间点操作 在mongodump中使用--oplog选项来收集oplog条目，用以在副本集中构建数据库的实时快照。 使用--oplog，mongodump会从源数据库复制所有的数据，包括备份开始到结束这段时间所有的oplog记录。 在mongorestore还原时使用--oplogReplay选项，允许你还原特定时间节点的备份。这就对应在mongodump期间oplog的记录。 123456789101112131415161718192021#127.0.0.1:27017 ./dumpmongodump#--host,-h --portmongodump -h mongodb.example.net --port 27107mongudump -h 127.0.0.1 --port 27018#-o, --outmongoodump -o /var/mongodb_backup/mongodump --host 127.0.0.1 --port 27017 --out /var/mongodb_backup/#--collection, --dbmongodump --db zhang --out /var/mongodb_backup/zhangmongodump --db zhang --collection test#--authenticationDatabasemongodump --port 27018 -u zhang -p "passwd" --authenticationDatabase admin -d zhang -o /var/mongodb_backup/zhang 使用mongorestore还原若要将数据还原到启用了访问控制的MongoDB部署，如果备份数据不包括system.profile集合数据，则restore角色提供了对数据库的访问权限。 如果备份数据包含了system.profile集合并且目标数据库不包含system.profile集合，那么mongorestore会去创建这个集合即使mongorestore并没有还原system.profile文档。因此，用户就需要额外的权限才能在system.profile集合中上执行createCollection和convertToCapped。 如果使用--oplogReplay，这个restore角色还不足以重放oplog。所以如果需要重放oplog，请使用一个能够重放oplog的角色。 1234567mongorestore /var/mnogodb_backupmongorestore /var/mnogodb_backup --oplogReplaymongorestore --port 27018 -u zhang -p "passwd" --authecticationDatabase admin -d zhang /var/mongodb_back/zhang 批量化操作mongo shell(EOF)1234567for coll in &#123;collection1,collection2,...&#125;do mongo host:port/db -u x -p xx &lt;&lt; EOF use db db.$coll.drop() EOFdone 从MongoDB备份中还原副本集你不能将单个数据集(data set)还原为三个新的mongod实例，然后为此创建一个副本集(replication set)。如果你将数据集复制到每个mongod实例，然后创建副本集，则MongoDB将强制SECONDARY执行initial sync。 向一个单一副本集节点中还原数据(Restore Database into a Single Node Replica Set) 获取备份数据库文件 使用备份数据库文件作为数据库路径启动一个mongod实例 1234567891011#方法1，直接启动mongod --dbpath /dir/path/mongodump --replSet &lt;replName&gt;#方法2，使用配置文件启动，推荐vim /etc/mongod.confstorage: dbPath: /dir/path/mongodumpreplication: replSetName: zhang 连接到mongo shell 初始化这个新的副本集 12#对于有且仅有一个成员的副本集使用rs.initiate()rs.initiate() 向副本集中添加成员(Add Members to the Replica Set)MongoDB对于还原副本集SECONDARY节点提供了两种选择： 手动复制数据库文件到数据目录 允许initial sync 建议： 如果备份的数据库文件很大，那么initial sync可能需要很长的时间才能完成。对于大型数据库，最好将数据库文件复制到每台主机上。 Copy Database File and Restart mongod Instance Shut down the mongod instance that you restored 使用 --shutdown 或 db.shutdownServer()来确保一个正常干净的关闭 复制Primary的数据目录到每个从节点 Start the mongod instance that you restorerd Add the secondaries to the replica set 1PRIMARY&gt;rs.add() Update Secondaries using Initial Sync 确保副本集成员的数据目录为空 将每个潜在成员添加到副本集 备份和还原分片集群(sharded cluster) 通过文件系统快照(fs snapshots)备份一个分片集群 通过Database Dumps备份一个分片集群 Schedule Backup Window for Sharded Clusters 还原一个分片集群 从意外关闭中恢复(Recover a standalone after an unexpected shutdow)当一个standalone模式的mongod实例关闭了journaling功能后，一个unclean的shutdown可能会导致数据处于不一致的状态。当unclean shutdown之后，如果在dbPath下存在一个非空的mongod.lock文件，则mongod实例会记录如下信息： Dectected unclean shutdown - mongod.lock is not empty 这样的话你必须要修复你的数据库，才能正常的启动mongod。 警告：不要用如下方法处理副本集 unclean shutdown。相反，你应该从备份或者从另一个副本集的成员恢复。 默认情况下，MongoDB在启用journaling的情况下运行，以防止发生unclean shutdown时数据不一致的问题。 使用运行mongod实例的那个用户来进行修复，避免由权限不一致而导致的新问题。 Create a backup of the data files Start mongod with –repair 监控(Monitoring)MongoDB监控是数据库管理的重要组成部分，充分了解MongoDB的运行状态，并在没有危机的情况下维护和部署。此外，了解MongoDB的正常操作参数将允许你在问题升级成为故障前诊断他们。 Monitoring for MongoDB Monitoring Strategies(策略)有三种方法可以从运行中的MongoDB实例中收集状态信息： MongoDB提供的一组实时上报程序，提供数据库活动的实时报告； 数据库命令以更大的保真度返回有关当前数据库状态的统计信息； MongoDB Atlas，MongoDB Cloud Manager； 每个策略在不同的情况下都是很有用的，所以它们能够很好地进行互补。 MongoDB Reporting ToolsUtilities MongoDB提供了许多可以返回活动统计信息的实用工具，这对于诊断问题和评估操作非常有用。 mongostat mongostat按类型捕获并返回数据库操作的计数(insert,query,update,delete…) mongotop mongotop通过类型捕获和返回数据库操作(insert,query,update,delete) CommandsMongoDB包含了许多上报数据库状态的命令。这些命令可以提供比上面的实用程序更精细的粒度级别。考虑在脚本和程序中使用它们的输出来开发自定义警报。db.currentOp方法是一个识别当前数据库实例正在进行的操作。 db.serverStatus() db.serverStatus()，返回数据库状态的一般概述，详细的磁盘使用，内存使用，连接，journaling日志和索引访问。它返回快速并不影响MongoDB性能。 db.stats() db.stats()，提供了database上的统计信息。返回使用的存储量，数据库包含的数据量及对象，collection和索引计数器。 db.collection.stats() db.collection.stats()，提供了collection上的统计信息。包含集合中的对象数量，结合大小，集合磁盘空间用量，索引信息。 rs.status() rs.status()，返回一个复制集状态的概述。 第三方工具许多第三方(third party)工具支持对MongoDB的监控。 Nagios Zabbix Ganglia Motop … Monitor MongoDB with SNMP on LinuxSNMP is only available in MongoDB Enterprise Monitor MongoDB Windows with SNMP MongoDB索引Indexes 索引支持在MongoDB中高效地(effecient)执行查询。没有索引，MongoDB就必须采取collection scan。扫描每个集合中的每个文档，用以匹配查询。如果查询存在适当的索引，则MongoDB可以使用该索引来限制它必须检查的文档数量。 索引是特殊的数据结构，将集合数据集中的一小部分以易于遍历(traverse)的形式存储。索引存储特定字段或字段集的值，按字段值排序。索引条目的排序支持高效的相等匹配和基于范围的查询操作。除此之外，MongoDB可以使用索引中的排序返回排序后的结果。 从根本上来说(fundamentally)，MongoDB中的索引类似于其他数据库的索引。MongoDB在collection级别定义索引，并支持集合的文档的任何字段或子字段上的索引。 默认_id索引 在创建一个collection期间，MongoDB在_id字段上创建一个唯一的索引。你也可以自定义_id的值。你不能在_id字段上删除此索引。 创建一个索引 db.collection.createIndex方法只有在同一规范不存在时才创建索引。 1db.collection.createIndex(&lt;key and index type&gt;, option) 索引类型MongoDB提供了许多不同的索引类型来支持特定类型的数据和查询。 Single Field 除了MongoDB定义的_id索引，MongoDB还支持在文档的单个字段上创建用户自定义的升序(ascending)/降序(descending)索引。 对于单字段索引和排序操作，MongoDB可以在任何方向遍历索引。 Compound(复合) Index MongoDB也支持多个字段的用户自定义索引。 Multikey Index MongoDB使用多键索引来索引存储在数组中的内容。 Geospatial(地理空间) Index 为了支持对地理空间坐标数据的有效查询，MongoDB提供了两个特殊的索引：2d index返回平面几何的2D索引；2dsphere index返回球形几何结果。 Text Index MongoDB提供了一个文本(text)类型索引，用以支持搜索集合中的字符串内容(string content)。 Hashed(散列) Index 为了支持基于散列的分片，MongoDB提供了散列索引类型，它索引字段值的散列值。但只支持相等的匹配，而不能支持基于范围的查询。 Index Properties(特性) Unique Index 索引的唯一性是MongoDB拒绝索引字段的重复值。 Partial Index 部分索引仅索引复合指定过滤器表达式的集合中的文档。 Sparse(稀疏) Index 索引的稀疏属性确保索引仅包含具有索引字段的文档的条目，跳过没有索引字段的文档。 TTL Index TTL索引是MongoDB可以用来在一定时间后自动从集合中删除文档的特殊索引。对于某些类型的消息，如机器生成的事件数据，日志和会话信息等，只需在数据库库中保存有限的时间，这是非常理想的。 Index Use索引能够提高读操作的效率。 Index and Collation要使用索引进行字符串比较，操作还必须指定相同的排序规则。 Coverd Query当查询条件和查询投影仅包含索引字段时，MongoDB将直接从索引返回结果，而不扫描任何文档或将文档带入内存。 Single Filed Index Compound Index Multikey Index Text Index 2dsphere Index 2d Index geoHaystack Index Hashed Index Index Property Index Build Operation on a Populated Collection Index Intersection Manage Index Measure Index Use Indexing Strategy Index Reference MongoDB存储Storage FAQ: MongoDB Storage: https://docs.mongodb.com/v3.4/faq/storage/ 存储引擎(storage engine)是MongoDB管理数据库主要的组件。 journal日志，用于数据库不正常关闭时修复数据库。有几种可选的配置项，用以平衡数据库的性能和可用性。 GridFS是一个适合处理大文件的多功能的存储系统，例如那些超过16MB文档大小限制的文件。 Storage Engine存储引擎是数据库的组件，负责管理数据库在内存(in-memory)和磁盘中(on-disk)两种存储方式。由于不同的存储引擎在特定的工作负载下有更好的性能，所以，为你的应用程序选择一个适当的存储引擎会提高性能。 WiredTiger是从MongoDB3.2开始的默认存储引擎。它非常适合大多数工作负载，并推荐使用它来进行部署。WiredTiger提供了文档级并发模型，检查点和要说等特性。 MMAPv1是一个原始的MongoDB存储引擎，它是MongoDB3.2以前的默认存储引擎。它在大量读取和写入以及更新方面的工作负载表现良好。 In-Memory要在MongoDB Enterprise中才能获取。它不是将文档保存在磁盘上，而是将它们保留在内存中，以获得可预测的数据延迟。 WiredTiger存储引擎MongoDB3.2以后使用WiredTiger存储引擎作为默认存储引擎。 12345678mongod --storageEngine wiredTiger#或vim /etc/mongod.confstorage: engine: wriedTiger 文档级别并发(currency)WiredTiger使用文档级并发来控制写操作。因此，多个客户端可以同时修改一个集合中的不同文档。 对于大多数读写操作，WiredTiger使用乐观的并发控制。WiredTiger仅在global、database和collection-levels使用intent lock。当存储引擎检测到两个操作之间的冲突时，其中一个操作将引发写冲突，从而导致MongoDB透明地重试该操作。 快照和检查点WiredTiger users multiVersion Concurrency Control(MVCC).在操作开始时，WiredTiger向事务提供数据的实时快照。快照显示内存中数据的一致性视图。 当写入磁盘时，WiredTiger将快照中的所有数据以一致性的方式跨越所有数据文件写入磁盘。持久(durable)的数据充当数据文件中的检查点。检查点确保数据文件与最后一个检查点保持一致性，并包括最后一个检查点。 MongoDB配置WiredTiger来创建检查点(即将快照数据写入磁盘)，间隔时间为60s，或2G日志数据。 在写入新检查点期间，前一个检查点仍然有效。 当WiredTiger的元数据表被原子地更新以引用新的检查点，新的检查点将变得可访问和永久。一旦新检查点可以访问，WiredTiger就会从旧的检查点这种释放页面(free page)。 JournalWiredTiger采用预写事务日志联合检查点，用以确保数据的持久性(durability)。你也可以关闭journal功能来减少维护日志的开销。 WiredTiger日志坚持在检查点之间修改所有数据。如果MongoDB在检查点之间退出，它将使用日志重放自上一个检查点以来修改的所有数据。 WiredTiger journal使用snappy compression Library来进行压缩。 WiredTiger最小日志记录的大小是128Byte，如果日志记录小于等于128Byte，则WiredTiger不会压缩日志文件。 对于以standalone模式运行的mongo实例，关闭journal日志功能意味着当MongoDB意外地在检查点之前退出时，你将丢失一些数据修改。对于复制集成员，复制过程和恒提供足够的持久性保证。 Compression使用WiredTiger，MongoDB支持压缩所有的collections和indexes。通过使用CPU进行压缩，减少了储存空间的使用。 默认地，WiredTiger使用snappy compression library对所有的collections进行block压缩，对所有索引进行前缀(prefix)压缩。 对于collection，也可以使用zlib进行block压缩。可通过storage.wiredTiger.collectionConfig.blockCompressor设置压缩方法。对于index，使用storage.wiredTiger.indexConfig.prefixCompression关闭prefix压缩。 对于大多数工作负载，默认压缩设置平衡了存储效率和处理要求。 Memory Use对于WiredTiger，MongodB使用WiredTiger内部缓存和文件缓存。 从MongoDB3.4开始，WiredTiger内部缓存将使用一下两种类型中更大的一种： 50% of RAM minus 1GB 256MB WiredTiger内部缓存中的数据与磁盘上格式的数据使用不同的表现形式： 文件系统缓存的数据与磁盘上的格式相同，包括了对数据文件进行压缩的好处。操作系统使用文件系统缓存来减少磁盘I/O 指标加载在WiredTiger内部缓存有一个不同的磁盘上的数据表示格式，但仍然可利用 prefix index compression来减少内存使用。索引前缀压缩重复数据删除常用前缀的索引字段。 WiredTiger内存缓存的collection数据是未压缩的，并使用与磁盘格式不同的表现形式。block compression能够节省大量磁盘空间，但必须解压缩数据后服务器才能操作。 通过文件系统缓存，MongoDB自动使用 (WiredTiger缓存或其他进程不使用)空闲内存。 调整WiredTiger内部缓存的大小，避免将WiredTiger的内初缓存值增加到默认值之上。 1234567#命令行--wiredTigerCacheSizeGB#配置文件storage.wiredTiger.engineConfig.cacheSizeGB Change Standalone to wiredTigerMongoDB version 3.0 or later in order to use wiredTiger storage engine! 过程： mongod is running export data using mongodump create a data directory for the new mongod running with wiredTiger start mongod with wiredTiger upload the dumpdata using mongorestore Change Replica Set to wiredTigerReplica sets can have members with different storage engines.因此，你可以把所有成员的存储引擎更换为WiredTiger。MongoDB version 3.0 or later in order to use wiredTiger storage engine! 过程： shutdown the secondary member.–db.shutdownServer prepare a data directory for the new mongod running with wiredTiger start mongod with wiredTiger repeat the procedure for other replica set secodaries you wish to upgrade Change Sharded Cluster to wiredTigerif the shard is a standalone, see Change Standalone to wiredTiger;if the shard is a replica set, see Change Replica Set to wiredTiger. Change config server to wriedTiger如果你打算更新config server使用WiredTiger，那么必须全部更新！ 过程： disable the balancer–sh.disableBalancer() shutdown the third config server to ensure read-only metadata.–db.shutdownServer() export the data of the second config server with mongodump For the second config server, create a new data directory for use with WiredTiger. Stop the second config server.–db.shutdownServer() Start the second config server mongod with the WiredTiger storage engine option. Upload the exported data using mongorestore to the second config server. Shut down the second config server to ensure read-only metadata.–db.shutdownServer() Restart the third config server to prepare for its upgrade. Export the data of the third config server with mongodump For the third config server, create a new data directory for use with WiredTiger. Stop the third config server. Start the third config server with the WiredTiger storage engine option. Upload the exported data using mongorestore to the third config server. Export data of the first config server with mongodump. For the first config server, create a new data directory for use with WiredTiger. Stop the first config server. Start the first config server with the WiredTiger storage engine option. Upload the exported data using mongorestore to the first config server. Restart the second config server to enable writes to the sharded cluster’s metadata Re-enable the balancer.–sh.startBalancer() MMAPv1存储引擎 In-Memory存储引擎 Journaling为了在发生故障时提供持久性，MongoDB使用了县写日志记录到磁盘的日志文件。To provide durability in the event of a failure, MongoDB uses write ahead logging to on-disk journal files. journaling and the wiredTiger storage engine本节所指的log指的是WiredTiger的 write-ahead log(journal)，而不是MongoDB日志文件。 WiredTiger使用checkpoints在磁盘上提供一致的数据视图，并允许MongoDB从上一个checkpoint修复。然而，如果MongoDB在检查点之间以外退出，则需要使用journaling来修复上次检查点之后发生的信息。 使用journaling的修复过程： 在数据文件中查找上一个检查点的标识符(identifier) 在journaling文件中搜索与上一个检查点标识符匹配的记录 应用自上一个检查节点依赖journal文件中的操作 journal process通过journaling，WiredTiger为每个客户端启动的写操作创建一个journal记录。journal record包括有初始写入引起的任何内部写入操作。 例如，集合中文档的更新可能导致对index的修改，WiredTiger创建一个包含update操作及其相关index修改的单独的journal record。 MongoDB将WiredTiger配置为in-memory的buffering来存储日志记录。线程坐标来分配和复制到他们的缓冲区的一部分。所有日志记录高达128KB是缓存的。WiredTiger根据如下条件将journal record同步到磁盘。 每50ms MongoDB在WiredTiger中设置60s为间隔的用户数据检查点或2GBjournal数据已被写入，以先发生为准。 如果写操作包含有j:true的写关注点，则WiredTiger强制对journal文件进行同步。 MongoDB限制了journal文件大小为100MB，因此WiredTiger每100MB就会创建一个新的journal文件。当创建了一个新的journal文件时，WiredTiger会同步上一个journal文件。 在写操作之间，虽然日志记录保留在WiredTiger缓冲区中，但在mongod实例hard shutdown之后可能会丢失更新。 Journal FileMongoDB在数据库目录下创建一个journal子目录存放journal文件。名字为WiredTigerLog.&lt;sequence&gt;，从0000000001开始。如上图所示。 Journal文件包含对每一个写操作的记录。每个记录都有唯一的标识符。 MongoDB将WiredTiger配置为对journal数据使用快速压缩。最小日志大小为128KB，如果小于此，WiredTiger不会压缩此记录。最大大小为100MB，超过此，WiredTiger会创建一个新的journal文件。 MongoDB自动删除旧日志文件，以维护从上一个检查点恢复所需的文件。 Journaling and the MMAPv1 Storage Engine Journaling and the In-Memory Storage Engine Manage JournalingMongoDB uses write ahead logging to an on-disk journal to guarantee write operation durability. 启用journal后，如果MongodB意外退出，则程序可以恢复写入了journal日志文件的所有内容。MongoDB将在重启时重新应用写操作，并保持一致性。 过程 Enable journaling123456789mongod --jouranl##或vim /etc/mongod.confstorage: journal: enabled: true Disable journaling12345mongod --noJournal###或修改配置文件 警告不要在生产系统上禁用日记功能。如果在一个副本集上使用--noJournal关闭了journal日志，则还应该修改副本集配置文件。 Monitor journal status serverStatus Recover data after unexpected shutdown在奔溃后重启时，MongoDB会在服务器可用之前replay journal日志记录中的所有日志文件。 GridFSGridFS是一种用于存储和检索超过BSON文档大小限制值16MB的文件规范。 GridFS没有将单个文件存储到单个的文档中，而是将文件分割成部分(parts)或块(chunks)，并将每个块存储到单独的文档中。默认情况下，GridFS的块大小为255KB。也就是说，GridFS将文件分成255KB的块，最后一块大小就不确定了。 GridFS使用两个集合来存储文件。一个存储文件块(chunks)，另一个存储文件元数据(metadata)。 当你查询(query)GridFS文件时，驱动程序会根据需要重新组装这些块。你可对通过GridFS存储的文件执行范围查询。还可以从任意文件部分访问信息。 GridFS不仅可用于存储超过16MB的文件，还可用于存储需要访问的任何文件，而不必将整个文件加载到内存中。 何时使用GridFS在MongoDB中，使用GridFS存储大于16MB的文件。 某些情况下，在MongoDB数据库中存储大文件可能比在系统级文件系统上更有效。 如果文件系统限制了一个目录中的文件数量，则可使用GridFS存储所需的文件 当你想要访问大文件的部分信息时而不想将整个文件加载到内存中时，可使用GridFS收回文件的各个部分，而不必将整个文件读入内存 当你希望文件和元数据自动同步并部署在多个系统和设施中时，可使用GridFS 如果需要原子地(atomically)更新整个文件的内容，请不要使用GridFS。作为一种选择，你可以为每个文件存储多个版本，并在元数据中指定该文件的当前版本。 此外，如果文件都是小于16MB的BSON文件大小限制，则考虑手动存储在一个单文档中，而不必使用GridFS。 使用GridFS使用GridFS存储和检索文件，请使用如下任何一项： A MongoDB Driver The mongofile cmd-line tool GridFS集合GridFS把文件存储在两个集合里： chunks collection stores the binary chunks files collection stores the file’s metadata GridFS将这些集合放在一个普通的存储区(bucket)中，每个存储区前面加上名称。默认地，GridFS使用两个名为fs的存储区集合： fs.files fs.chunks 币可以选择一个不同的存储区名字，也可以在一个数据库中创建多个存储区。 The chunks collection块集合中的每个文档都表示一个独立的文件块。格式如下： 123456&#123; &quot;_id&quot;: &lt;ObjectId&gt;, &quot;files_id&quot;: &lt;ObjectId&gt;, &quot;n&quot;: &lt;num&gt;, &quot;data&quot;: &lt;binary&gt;&#125; 块集合中的文档包含如下字段： chunks._id The unique ObjectId of the chunk chunks.files_id The _id of the “parent” document chunks.n The sequence number of the chunk，GridFS从0开始标号所有块 chunks.data BSON Binary type file集合GridFS的file集合，格式如下： 1234567891011&#123; &quot;_id&quot;: &lt;ObjectId&gt;, &quot;length&quot;: &lt;num&gt;, &quot;chunkSize&quot;: &lt;num&gt;, &quot;uploadData&quot;: &lt;timestamp&gt;, &quot;md5&quot;: &lt;hash&gt;, &quot;filename&quot;: &lt;string&gt;, &quot;contentType&quot;: &lt;string&gt;, &quot;aliases&quot;: &lt;string array&gt;, &quot;metadata&quot;: &lt;any&gt;&#125; files._id The unique identifier for this document files.length The size of the document in bytes files.chunSize The size of each chunk in bytes files.uploadDate The date the document was first stored by GridFS files.md5 An MD5 hash of the complete file file.filename Optional. A human-readable name for the GridFS file file.contentType Optional. A valid MIME type for the GridFS file files.aliases Optional. An array of alias strings files.metadata Optional. The metadata field may be of any data type and can hold any additional information you want to store GridFS索引为了提高效率，GridFS在每个chunks and files collections上使用索引。 chunks索引GridFS使用一个唯一的、混合的索引。在chunks集合上使用files_id和n字段。 12345db.fs.chunks.find( &#123; files_id: myFileID &#125; ).sort( &#123; n:1 &#125;)#创建索引db.fs.chunks.createIndex(&#123; files_id: 1, n:1 &#125;, &#123; unique: true &#125;); files索引GridFS使用索引，在files集合上使用filename和uploadDate字段。 12345db.fs.files.find(&#123; filename: myFileName &#125;).sort(&#123; uploadDate: 1 &#125;)#创建索引db.fs.files.createIndex(&#123; filename:1, uploadDate: 1 &#125;); 分片GridFS如果需要分片GridFS数据存储，使用chunks集合设置: { files_id: 1, n:1} or { files_id: 1 }作为分片key索引。 不能对chunks集合使用hash分片。 files_id是一个ObjectId。 MongoDB安全Security MongoDB提供了各种特性(features)，如身份认证(authentication)、访问控制(access control)、加密(encryption)，以保护MongoDB部署。 Security Checklist 启用访问控制和强制认证 Enable Access Control and Enforce Authentication 可使用默认的MongoDB认证机制或现有的外部框架 配置基于角色的访问控制 Configure Role-Based Access Control 首先创建administrator，接着在创建其他用户 创建角色，定义一组用户所需的确切访问权限 加密通信 Encrypt Communication 配置MongoDB使用TLS/SSL加密连接 加密和保护数据 Encrypt and Protect Data 限制网络曝光 Limit Network Exposure 确保MongoDB运行在一个受信任的网络环境上，并限制MongoDB的监听接口 审计系统活动 Audit System Activity 跟踪对数据库配置和数据的访问和更改 使用专用用户运行MongoDB Run MongoDB with a Dedicated User 使用专用的操作系统用户账户运行MongoDB进程 使用安全配置选项运行MongoDB Run MongoDB with Secure Configuration Options MongoDB为了支持某些服务端操作执行：mapReduce,group,$where 如果你不使用这些操作，请关闭服务器端脚本执行--noscripting 请求一个安全技术执行指南 Request a Security Technical Implementation Guide 考虑安全标准合格性 Consider Security Standards Compliance 认证Authentication 要作为用户进行身份认证，必须提供用户名(username)，密码(password)和与用户关联的身份验证数据库(authentication database)。 1234567mongo --host --username --password --authenticationDatabase#Ormongo&gt;use &lt;authenticationDatabase&gt;&gt;db.auth(&apos;username&apos;,&apos;password&apos;) 认证机制 Authentication Mechanisms MongoDB支持多种认证机制 SCRAM-SHA-1 MongoDB Challenge and Response (MONGODB-CR) x.509 Certificate Authentication LDAP proxy authentication(MongoDB Enterprise) Kerberos authentication(MongoDB Enterprise) 内部认证 Internal Authentication 除了验证客户端的身份外。MongoDB还可以要求副本集和分片集的成员对其各自的成员进行认证 用户Users 要在MongoDB中验证客户端，必须向MongoDB添加相应的用户。 用户管理接口 User Management Interface 使用db.createUser()方法创建用户 添加用户时，可为用户分配角色以授予权限 在数据库管理中创建的第一个用户应该是具有管理其他用户权限的administrator 也可以更新/删除一个已经存在的用户的权限 认证数据库 Authentication Database 在特定的数据库中创建用户，这个数据库是用户的认证库 用户名和认证库充当该用户的唯一标识符。如果两个用户具有相同的用户名，但是在不同的数据库中创建，则它们是两个单独的用户 用户可拥有不同数据库的权限，而不限于认证库 通过数据库角色给用户分配相应的权限 认证一个用户 Authentication Database 使用用户名、密码、认证库验证一个用户 集中的用户数据 Centralized User Data MongoDB将所有的用户名、密码和认证库信息，保存到admin库的syste.users集合中 使用用户管理命令而不要直接访问这个集合 分片集群用户 Sharded Cluster Users 添加用户Add Users MongoDB使用基于角色的访问控制(RBAC)来确定用户的访问权限。用户被授予一个或多个角色，这些角色确定用户对MongoDB资源的访问或权限，以及用户可以执行的操作。用户应该只具有确保系统最小权限所需要的最小权限。 前提(Prerequisites) 对于用户创建，你必须拥有以下权限 在数据库中创建一个新用户，必须在数据库资源上有createUser操作 对一个用户授权角色，必须在角色数据库中有grantRole操作 栗子 123456789101112131415161718use admindb.createUser( &#123; user: &apos;zhang&apos;, pwd: &apos;passwd123&apos;, roles: [ &#123; role: &apos;root&apos; &#125;, &#123; db: &apos;admin&apos; &#125; ] &#125;)#在配置文件中开启用户认证vim /etc/mongod.confsecurity: authorization: enabled 认证机制Authentication Mechanisms SCRAM-SHA-1 MONGODB-CR x.509MongoDB对于客户端身份认证和副本集、分片集成员的内部认证支持x.509证书认证。 x.509证书认证需要安全的TLS/SSL连接。 证书授权(Certificate Authority) 在生产使用中，MongoDB的部署应该使用由认证机构签名和生成的有效证书。 Client x.509 Certificates 要想服务器验证身份，客户端可以使用x.509证书而不是用户名和密码。 Client Certificate Requirements： 单个证书颁发机构(CA)必须同时为客户端和服务器颁发证书 客户端证书必须包含如下字段： 12keyUsage = digitalSignatureextendedKeyUsage = clientAuth 每个唯一的MongoDB用户必须有一个唯一的证书 一个客户端x.509证书的主题，包含了可辨识名称(DN)。必须不同于成员x.509证书 MongoDB user and $external database 若要使用客户端证书进行认证，必须先将客户端证书中的subject值添加为MongoDB用户。每个唯一的x.509客户端证书对因孤独一个MongoDB用户。 在$external database中添加用户，认证库便是外部数据库。 Authenticate 使用x.509客户端进行身份验证，请通过TLS/SSL连接到MongoDB。--ssl and --sslPEMKeyFile Member x.509 Certificates 对于内部认证，分片集和副本集的成员可以使用x.509证书来代替使用SCRAM-SHA-1认证机制的keyfile。 Member Certificate Requirements CA必须为所有分片集，副本集成员颁发x.509证书 成员证书的主题中找到Distinguished Name(DN)必须为以下至少一个属性指定非空值：Organization(O)，Organization Unit(OU)，Domain Component(DC) 组织属性，组织单元属性和域组件必须与其他集群成员的证书相匹配。12CN=host1,OU=Dept1,O=MongoDB,ST=NY,C=USC=US, ST=CA, O=MongoDB, OU=Dept1, CN=host2 MongoDB Configuration 配置文件：security.clusterAuthMode and net.ssl.clusterFile cmd-line options: –clusterAuthMode and –sslClusterFile Member Certificate and PEMKeyFile 配置文件： net.ssl.PEMKeyFile cmd-line option: –sslPEMKeyFile Enterprise Authentication Mechanisms MongoDB认证和角色要想了解MongoDB的权限必须先了解如下一些关键字： user 用户，用于提供客户端连接MongoDB的认证账户 role 角色，数据权限的集合，创建用户的时候必须要指定对应的角色，否则用户无法操作数据库 resource 资源，包括database或collection 也可以是database和collection的组合 actions 权限操作，定义了 user 能够对 resource document 执行的操作。如 增、删、改、查 privilege 权限，privilege 是一组 resource 和 action的组合，对资源拥有什么操作称为权限 authenticationDatabase 认证库，即创建角色或用户时所在的库 角色管理MondoDB支持基于角色的访问控制（RBAC）来管理对MongoDB系统的访问。一个用户可以被授权一个或多个角色以决定该用户对数据库资源和操作的访问权限。在权限以外，用户是无法访问系统的。 数据库角色在创建用户的role参数中设置。角色分为內建角色和自定义角色。 内建角色 数据库用户角色 read：允许用户读取指定数据库 readWrite：允许用户读写指定数据库 数据库管理员角色 dbAdmin：允许用户进行索引创建、删除，查看统计或访问system.profile，但没有角色和用户管理的权限 userAdmin：提供了在当前数据库中创建和修改角色和用户的能力 dbOwner：提供对数据库执行任何操作的能力。这个角色组合了readWrite、dbAdmin和userAdmin角色授权的特权 集群管理角色 hostManager：提供监视和管理服务器的能力 clusterManager：在集群上提供管理和监视操作。可以访问配置和本地数据库，这些数据库分别用于分片和复制 clusterMonitor：提供对监控工具的只读访问 clusterAdmin：提供最强大的集群管理访问(副本集、分片、主从等)。组合了clusterManager、clusterMonitor和hostManager角色的能力，还提供了dropDatabase操作 备份恢复角色 backup：提供备份数据所需的能力 restore： 提供使用mongorestore恢复数据的能力 所有数据库角色 readAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读权限 readWriteAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读写权限 userAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的userAdmin权限 dbAdminAnyDataBase：只在admin数据库中可用，赋予用户所有数据库的adAdmin权限 超级用户角色 root：超级权限，只能针对admin库 内部角色 __system：提供对数据库中任何对象的任何操作的特权 自定义角色 MongoDB内置角色一般来说都是够用的，但当内置角色不满足需求时就可以自定义角色了。使用 db.createRole() 方法来自定义角色。 只能在admin库中创建角色： 123456789101112use admindb.createRole( &#123; role:&lt;role_name&gt;, #定义角色名称 privilege:[ #权限集 &#123; resource:&#123;cluster:true, actions:[&lt;action_name&gt;] &#125;, &#123; resource: &#123;db:&lt;db_name&gt;, collection:&lt;coll_name&gt; &#125;, &#123; actions:[&lt;action_name&gt;] &#125; #定义对这个库或集合可进行的权限操作，这是一个数组 ], roles:[ &#123; role:&lt;role_name&gt;, db:&lt;db_name&gt; &#125; ] #是否继承其他的角色 &#125;) 角色创建完毕后MongoDB会在系统库admin下创建一个collection名叫 system.roles，里面存储的即是角色相关的信息。 1db.system.roles.find() 操作角色1234567891011#查看角色db.getRole()#角色继承#角色授权db.grantRolesToRole()#角色移权db.revokeRolesfromRole() 用户管理创建用户： 123456db.createUser(&#123; user:&quot;xxx&quot;, pwd:&quot;xxxx&quot;, customDate:&quot;xxx&quot;, roles:[&#123; #指定角色名称以及认证库 role:&quot;xxx&quot;, db:&quot;xxxx&quot; &#125;]&#125;) 开启认证： 1234567891011vim /etc/mongo.confsecurity: authorization：enableddb.auth(&quot;user&quot;,&quot;passwd&quot;) #在use db后或mongo -u user -p passwd --authenticationDatabase xxx#在哪个库创建的用户就需要使用哪个库进行认证 查看用户： 12db.getUser(&quot;user&quot;)db.system.users.find() 删除用户： 12db.dropUser(&quot;user&quot;)db.dropAllUsers() 添加用权限： 1db.grantRolesToUser() 修改用户密码： 1db.changeUserPassword(&quot;user&quot;,&quot;new_passwd&quot;) 在MongoDB中删除库和集合并不会级联删除对应的角色和用户。因此如果想彻底删除对应的业务应该先删除库与其对应的角色和用户。 如果既想实现精细化权限控制又想简化用户管理，原则上建议只给开发创建一个账户，并且使用admin做认证库，这样可以避免清理过期业务库而导致无法登陆的问题。 内部认证Internal Authentication 可以对副本集和分片集成员进行验证。对于成员的内部认证，MongoDB可以使用keyfile或x.509证书。 KeyFile keyfiles的内容作为成员的共享密码，其长度必须在6-1024个字符之间，只能包含base64 set中的字符。 1234567891011121314openssl rand -base64 512 &gt; /etc/mongodb.keyfilechmod 600 /etc/mongodb.keyfilechown mongod:mongod /etc/mongodb.keyfile#配置文件：security.keyFile#cmd-line option: --keyFilevim /etc/mongod.confsecurity: authorization: enabled keyFile: &quot;/etc/mongodb.keyfile&quot; clusterAuthMode: &quot;keyFile&quot; x.509 内部认证使用x.509进行验证。 CA必须为所有分片集，副本集成员颁发x.509证书 成员证书的主题中找到Distinguished Name(DN)必须为以下至少一个属性指定非空值：Organization(O)，Organization Unit(OU)，Domain Component(DC) 组织属性，组织单元属性和域组件必须与其他集群成员的证书相匹配。12CN=host1,OU=Dept1,O=MongoDB,ST=NY,C=USC=US, ST=CA, O=MongoDB, OU=Dept1, CN=host2 MongoDB Configuration 配置文件：security.clusterAuthMode and net.ssl.clusterFile cmd-line options: –clusterAuthMode and –sslClusterFile 在副本集中强制秘钥文件访问控制Enforce Keyfile Access Control in a Replica Set 对副本集执行访问控制需要配置： 使用内部身份验证副本集成员之间的安全性 使用用户访问控制连接客户端和副本集间的安全性 步骤： 创建一个密钥文件 Create a keyfile 通过密钥文件进行身份验证，副本集中的每个mongod实例都使用密钥文件的内容作为共享密码，用于验证部署中的其它成员。 12345#yum install -y opensslopenssl rand -base64 756 &gt; &lt;path-to-keyfile&gt;chmod 400 &lt;path-to-keyfile&gt;chown &lt;owner&gt;:&lt;owner&gt; 复制密钥文件到每个副本集成员 Copy the keyfile to each replica set member 将密钥文件复制到每一台主机的副本集成员中。确保运行mongod实例的用户就是keyfile的所有者，并可以访问密钥文件。 关闭所有的副本集成员 Shut down all members of the replica set 关闭每个副本集中的mongod，从Secondary开始。知道所有的成员都脱机为止，包括任何仲裁者(Arbiter)。Primary是最后一个关闭的成员。 12use admindb.shutdownServer() 启动访问控制并重启副本集成员 123456789101112vim /etc/mongod.confsecurity: keyFile: &lt;path-to-keyfile&gt; clusterAuthMode: keyfilereplication: replSetName: &lt;replcaSetName&gt;#cmd-linemongod --keyFile &lt;path-to-keyfile&gt; --clusterAuthMode keyfile --replSet &lt;replicaSetName&gt; 连接到mongo shell 在Primary上使用rs.status()来标识副本集成员。 创建一个administrator Create the user administrator 必须在Primary上创建用户。 12345678admin = db.getSiblingDB(&quot;admin&quot;)admin.createUser( &#123; user: &apos;zhang&apos;, pwd: &apos;password&apos;, roles: [&#123; role: &apos;userAdminAnyDatabase&apos;, db: &apos;admin&apos; &#125;] &#125;) 开启用户认证 12345678vim /etc/mongod.confsecurity: authorization: enabled keyFile: &lt;path-to-keyfile&gt; clusterAuthMode: keyfilereplication: replSetName: &lt;replcaSetName&gt; 以管理员身份进行认证 Authenticate as the User Administrator 123456mogno&gt;db.getSiblingDB(&quot;admin&quot;).auth(&apos;zhang&apos;,&apos;password&apos;)#ormongo -u &apos;zhang&apos; -p &apos;password&apos; --authenticationDatabase &apos;admin&apos; 创建集群管理员(可选) Create the cluster administrator (Optional) 1234567db.getSiblingDB(&quot;admin&quot;).createUser( &#123; &quot;user&quot; : &quot;ravi&quot;, &quot;pwd&quot; : &quot;changeme2&quot;, roles: [ &#123; &quot;role&quot; : &quot;clusterAdmin&quot;, &quot;db&quot; : &quot;admin&quot; &#125; ] &#125;) 在不停机的副本集中强制实施keyfile访问控制]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP请求方法和状态码]]></title>
    <url>%2F2017%2F12%2F01%2FHTTP-method-status%2F</url>
    <content type="text"><![CDATA[常见HTTP请求方法HTTP协议的请求方法有：GET, POST, HEAD PUT DELETE, OPTIONS, TRACE, CONNECT Method Description GET 向Server请求文件 POST 向Server发送数据并让Server进行处理 PUT 向Server发送数据并存储在Server端 HEAD 检查一个对象是否存在 DELETE 从Server上删除一个文件 CONNECT 对通道提供支持 TRACE 跟踪到Server的路径 OPTION 查询Server的性能 HTTP Status Code当我们从Client向Server发送请求时，Server会向我们返回StatusCode。StatusCode会告诉我们Server的响应的状态，通过它，我们就可以知道当前请求是成功还是出现了问题。 HTTP StatusCode放置在HTTP Response报文中。 StatusCode由三位数字组成，第一个数字定义了响应类型，有五种可能值： 状态码 响应类别 描述 1xx 指示信息 服务器正在处理请求 2xx 成功 请求以正常处理完毕 3xx 重定向 需要进行额外操作以完成请求 4xx 客户端错误 客户端原因导致服务器无法处理请求 5xx 服务器错误 服务器原因导致处理请求出错 常见HTTP状态码 状态码 描述 200-OK 服务器成功返回网页，这是成功的HTTP请求返回的标准状态码 301 - Moved Permanently 永久跳转，所有请求的网页将永久跳转到被设定的新位置 400 - Bad Request 客户端请求有语法错误，不能被服务器理解 403 - Forbidden 禁止访问，这个请求时合法的，但是服务器端因为匹配了预先设置的规则而拒绝响应客户端的请求，此类问题一般为服务器权限配置不当所致 404 - Not Found 服务器找不到客户端请求的指定页面，可能是客户端请求了服务器不存在的资源所导致 500 - Internal Server Error 内部服务器错误，服务器遇到了意料不到的情况，不能完成客户的请求。这是一个较为笼统的报错，一般为服务器的设置或内部程序问题所致 502 - Bad Gateway 坏的网关，一般是代理服务器请求后端服务器时，后端服务不可用或没有完成响应网关服务器。一般为代理服务器下面的节点出了问题 503 - Service Unavailable 服务当前不可用，可能为服务器超载或停机维护所致，或者是代理服务器后面没有可以提供服务的节点 504 - Gateway Timeout 网关超时，一般是网关代理服务器请求后端服务时，后端服务没有在特定的时间内完成处理请求，一般为服务器过载所致，没有在指定的时间内返回数据给代理服务器 1xx1xx（临时响应），表示临时响应并需要请求者继续执行操作。 状态码 描述 100 - Continue 请求者应当继续提出请求 101 - Switching Protocols 请求者要求服务器更换协议，服务器已确认并准备更换 2xx2xx（成功），表示成功处理了请求。 状态码 描述 200 - OK Server已成功处理了请求 201 - Created 请求成功并且Server创建了新的资源 202 - Accepted Server以接受请求，但尚未处理 203 - Non-Authoritative Information Server已成功处理了请求，但返回的信息可能来自另一个来源 204 - No Content Server成功处理了请求，但没有返回任何内容 205 - Reset Content 没有新的内容，但浏览器应该重置它所显示的内容 206 - Partial Content 服务器成功处理了部分GET请求 3xx3xx（重定向），表示要完成请求需要进一步操作。 状态码 描述 300 - Multiple Choices 针对请求，Server可执行多种操作 301 - Moved Permanently 请求的网页已移动到新位置 302 - Found Server目前从不同位置的网页响应请求 303 - See Other 请求者对不同位置使用单独的GET请求来检索时 304 - Not Modified 自从上次请求后，请求的网页内容未修改过 305 - Use Proxy 请求者只能使用代理访问请求的网页 307 - Temporary Redirect Server从不同位置的网页响应请求，但请求者继续使用原有位置进行请求 4xx4xx（请求错误），表示请求可能出错，妨碍了Server的处理。 状态码 描述 400 - Bad Request Server不理解请求的语法 401 - Unauthorized 请求要求身份认证 403 - Forbidden Server拒绝请求 404 - Not Found Server找不到请求的网页 405 - Method Not Allowed 请求方法不被允许 406 - Not Acceptable 无法使用请求的恩日工特性响应请求的网页 407 - Proxy Authentication Required 请求需要代理授权 408 - Request Timeout Server等候请求时超时 409 - Conflict Server在完成请求时发生冲突 410 - Gone 请求的资源以永久删除 411 - Length Required Server不接受不含有效内容长度Header的请求 412 - Precondition Failed Server为满足请求者在请求中设置的一个前提条件 413 – Request Entity Too Large 请求实体太大，Server无法处理 414 - Request URI Too Long 请求的URI过长，Server无法处理 415 – 不支持的媒体类型 请求的格式不受支持 416 – Requested Range Not Satisfiable 页面无法提供请求的范围 417 – 执行失败 Server未满足期望请求Header的要求 451 基于法律上的的原因，不能像请求者展示网页内容 5xx5xx（服务器错误），表示服务器在尝试处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是请求出错。 状态码 描述 500 - Internal Server Error Server遇到错误，无法完成请求 501 - Not Implemented Server不具备完成请求的功能 502 - Bad Gateway Server作为网关或代理时，从upstream收到无效响应 503 - Service Unavailable Server暂时无法使用 504 - Gateway Timeout Server作为网关或代理时，没有及时从upstream收到请求 505 - HTTP Version Not Supported Server不支持请求中所用的HTTP版本]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Filesystem Hierarchy Standard]]></title>
    <url>%2F2017%2F11%2F27%2FFHS%2F</url>
    <content type="text"><![CDATA[FHS介绍FHS(Filesystem Hierarchy Standard)，文件系统层次化标准：http://www.pathname.com/fhs FHS主要目的是希望让用户了解安装文件通常放置的目录。所以希望软件开发商、系统制定者以及维护系统的用户，都能够遵循FHS的标准。 FHS-compliant system： - 可分享的(shareable) 不可分享的(unshareable) 不变的(static) /usr /opt /etc /boot 可变的(variable) /var/mail /var/spool/news /var/run /var/lock shareable： 可分享给其他系统(主机)挂载使用； unshareable： 不适合分享给其他主机； static： 有些数据基本是不会变化的； variable： 进程变更的数据。 FHS针对目录树架构仅定义出三层目录下应该放置什么数据，这三个目录下所应该放置的目录也都有特定规定。 /： The root filesystem, 与开机系统有关； /usr: The /usr hierarchy, Unix software resource； /var: The /var hierarchy, 与系统运行过程有关。 The Root Filesystem根目录(/)是系统最重要的一个目录。不但所有目录都是由根目录衍生出来，同时根目录还与系统的启动、还原、修复等操作相关。若系统出现问题，根目录必须要包含能够修复文件系统的程序才行。破坏根文件系统上的数据的错误比破坏其他任何分区都要严重！ 为了平衡这些考虑，建议尽可能保持根分区小。应用程序不应在根目录中创建特殊文件或子目录！ The following dirs or symbolic-links, are required in / 目录 描述 /bin 必要的二进制命令 /boot boot-loader的静态文件 /dev 设备文件 /etc 主机特定的系统配置文件 /lib 基本的共享库(shared libraries)和内核模块(kernel modules) /media 可移除媒体的挂载点 /mnt 临时挂载文件系统的挂载点 /opt 第三方软件包放置目录 /sbin 必要的系统二进制命令 /srv 系统提供的服务数据 /tmp 临时文件 /usr /usr层次结构 /var /var层次结构 除了上面列出必须存在的目录，下面这些目录很也很重要。 目录 描述 /lost+found 在ext文件系统里，当文件系统发生错误时，将一些遗失的片段放置到此目录下 /home 用户家目录 /root root用户家目录 /proc 虚拟文件系统，放置的数据都在内存当中，不占磁盘空间 /sys 虚拟文件系统，记录内核相关信息，不占磁盘空间 另外需要注意的是，因为根目录与开机有关，开机过程中仅有根目录被挂载。其他分区则是在开机完成后才会持续进行挂载。因此，根目录下与开机过程有关的目录就不能放到不同的分区中去。 如： /etc /bin /sbin /dev /lib /bin/bin, 基本用户二进制命令文件，供所有用户（系统管理员和用户）使用。 /bin下不能有子目录(subdirectory)。 The following commands or symbolic-links to commands, are required in /bin 命令 描述 cat 将文件连接到stdout的实用程序(Utility) chgrp 更改文件所有权 chmod 更改文件访问权限 chown 更改文件所有者和和组 cp 复制文件和目录 date 打印或设置系统数据和时间 dd 转换和复制文件 df 磁盘使用情况 dmesg 打印或控制kernel消息缓冲区 echo 显示一行文本 false do nothing, 不成功 true do nothing, 成功 hostname 系统主机名 kill 发送信号到进程 ln 在文件之间创建链接 login 在系统上开始会话 ls 列出目录内容 mkdir 创建目录 mknod 创建block或character特殊文件 more 文本翻页 mount 挂载文件系统 umount 解挂文件系统 mv move/rename文件 ps 报告进程状态 pwd 打印当前工作目录 rm remove文件或目录 sed sed流编辑器 sh Bourne command shell stty 更改或打印终端设置 su change uid sync 刷新文件系统缓冲区 uname 打印系统信息 The following programs or symbolic-links to programs, must be in /bin if the corresponding-system is installed: 命令 描述 csh The C shell(可选) ed 编辑器(可选) tar tar归档(可选) cpio cpio归档(可选) gzip GNU压缩工具(可选) gunzip GNU解压缩工具(可选) netstat 网络统计(可选) ping ICMP网络测试(可选) /boot/boot :static file of the boot-loader 该目录包含引导过程所需所有内容，处理引导是不需要的配置文件和映射安装文件外。因此，/boot储存kernel开始执行用户模式之前使用的数据。 操作系统kernel必须位于 / or /boot /dev/dev :device files /dev 目录是特殊或设备文件的位置。 /etc/etc :host-specific system configuration 配置文件是用来控制程序操作的本地静态文件，不能是可执行的二进制文件。 The following files or symbolic-links to files, must be in /etc if the corresponding-subsystem is installed. 文件 描述 备注 csh.login C shell登录的系统范围初始化文件 Optional exports NFS文件系统访问控制列表 Optional fstab 文件系统静态信息 Optional ftpusers FTP守护进程用户访问控制列表 Optional gateways 路由网关文件 Optional gettydefs getty终端设置 Optional group 用户组文件 Optional passwd 密码文件 Optional host.conf 解析器配置文件 Optional hosts 主机域名的静态信息 Optional hosts.allow Tcp-wrapper的主机访问文件 Optional hosts.deny Tcp-wrapper的主机禁止文件 Optional hosts.equiv rlogin, rsh, rcp的可信主机列表 Optional hosts.lpd lpd的可信主机列表 Optional inetd.conf inetd配置文件 Optional inittab init配置文件 inittab is no longer used when using systemd id.so.conf 搜索共享库的额外目录 Optional issue 预登录消息和 CentOS Linux 7(core) kernel \r on an \m motd 登录后信息 Welcome to $host mtab 文件系统动态信息 Optional mtools.conf mtools配置文件 Optional networks 网络名称的静态信息 Optional printcap lpd打印机功能数据库 Optional profile sh shell login的系统范围初始化文件 Optional protocols IP协议列表 Optional resolv.conf 域名服务器解析文件 Optional rpc RPC协议列表 Optional securetty root登录的TTY访问控制 Optional shells 有效登录shell的路径名 Optional syslog.conf syslogd配置文件 Optional /etc/opt/etc/opt :/opt的配置文件 第三方应用程序软件的特定主机配置文件，必须安装在/etc/opt/ 中。 /etc/xml/etc/xml :XML的配置文件 这里安装和定义XML系统的高级参数同通用配置文件。 /home (Optional)/home :用户主目录 /home是一个相当标准的概念，但它显然是一个特定于站点的文件系统。设置会因主机而异。因此，任何程序都不应该依赖这个目录。 /lib/lib :基本的共享库和内核模块 /lib目录中包含引导系统和运行在根文件系统的命令，即/bin和/sbin中的命令。 至少需要包含以下文件(链接)： 文件 描述 libc.so.* 动态链接C库 ld* 执行时间 链接器/加载器 /lib (Optional)/lib&lt;qual&gt; : 不同格式的基本共享函数库如：64位的/lib64; 32位的/lib32。 用来存放与/lib不同格式的二进制函数库，如支持64位的/lib64函数库等。 /media/media :可移除媒体的挂载点 此目录包含的子目录，可作为各移动介质(USB,cdrom,floppy…)的挂载点。 尽管在 /mnt 中使用子目录作为挂载点已经很常见了，但与直接使用/mnt作为临时挂载点的传统相去甚远。 /mnt/mnt :临时挂载文件系统的挂载点 /opt/opt :为第三方软件包保留的目录 要安装在/opt中的软件包必须将其静态文件放置在单独的/opt/&lt;packge&gt;目录树中。 目录/opt/bin, /opt/doc, /opt/include, /opt/info, /opt/lib, /opt/man 是保留给本地系统管理员使用。如果第三方软件包含Unix手册，而手册必须放置于/opt//share/man/，必须使用与/usr/share/man相同的子结构。 /root (Optional)/root :root用户的主目录 /sbin/sbin :系统二进制文件 系统管理的实用程序(命令)，存储在/sbin, /usr/sbin, /usr/local/sbin中。/sbin包含启动，恢复，修复系统，以及/bin中二进制文件所必须的二进制文件。本地安装的系统管理程序应放置在/usr/local/sbin中。 The following commands or symbolic-links to commands are required in /sbin1shutdown #关闭系统 The following files or symbolic-links to files，must be in /sbin if the corresponding subsystem is installed 命令 描述 备注 fastboot 重启系统而不检查磁盘 Optional fasthalt 停止系统而不检查磁盘 Optional fdisk 分区表操作器 Optional fsck 文件系统检查和修理工具 Optional fsck.* 针对特定文件系统检查和修复 Optionaleg：fsck.ext3 getty getty程序 Optional half 停止系统 Optional ifconfig 配置网络接口 Optional init 初始化进程 Optional mkfs 创建文件系统 Optional mkfs.* 创建特定文件系统 OPtionaleg: mkfs.ext4 mkswap 设置swap分区 OPtional reboot 重启系统 OPtional route IP路由表实用程序 OPtional swapon 启用分页和交换 OPtional swapoff Disable paging and swapping Optional update 守护进程定期刷新文件系统缓冲区 Optional /srv/srv :系统提供的服务(service)的数据 /tmp/tmp :临时文件 /tmp目录为临时需要文件的程序提供。程序不能在程序的调用之间保留/tmp中的任何文件或目录。尽管/tmp中数据可能会以某种特定方式删除，但建议在系统启动时删除/tmp中所有文件。 The /usr Hierarchy/usr 里面放置的数据是可分享与不可变动的。这就意味着可在各种符合FHS的主机之间共享，但不能写入。大型软件包不应在/usr层次结构下使用直接子目录。 The following dirs of symbolic-links to dirs are required in /usr 目录 描述 /usr/bin 大多数用户命令 /usr/include C程序包含的头文件 /usr/lib 库文件 /usr/local 本地层次结构 /usr/sbin 非重要的系统二进制文件 /usr/share 独立于架构的数据 其他选项： 目录 描述 备注 /usr/lib&lt;qual&gt; 可选格式库 Optional /usr/src 源代码 OPtional /usr/games 游戏和教育二进制文件 OPtional /usr/bin/usr/bin :大多数用户命令这是系统上可执行命令的主要目录。 The following files or symbolic-links to files must be in /usr/bin, if the corresponding subsystem is installed 命令 描述 备注 perl 实用提取和报告语言 OPtional python python解释语言 Optional tclsh tcl解释器的简单shell OPtional wish 简单 tcl/tk windowing shell Optional expect 程序交互式对话 Optional 因为shell script解释器(在shell script脚本的第一行 #!)不能依赖路径，所以标准化它们的位置是有利的。Bourne shell 和 C-shell解释器已经被固定在/bin中，但 perl,python,tcl经常在许多不同的地方。 /usr/include/usr/include :标准C包含文件的目录 这是C语言所有系统的通用包含文件应该被放置的地方。 /usr/lib/usr/lib :编程和包的所需要的库 /usr/lib包括 不打算由用户或shell script直接执行的目标文件、库和内部二进制文件。 /usr/lib (Optional)/usr/lib&lt;qual&gt; :可选格式库 /usr/local/usr/local :本地层次结构 /usr/local是给系统管理员安装本地软件使用。当系统软件更新时，需保证安全。它可以用于在一组主机之间共享，但在 usr中找不到的程序和数据。 本地安装软件必须放在 /usr/local 而不是 /usr，除非安装它来升级或替换usr的软件 The following dirs or symbolic-links to dis must be in /usr/local 目录 描述 /usr/local/bin 本地二进制文件 /usr/local/etc 本地二进制文件的特定配置文件 /usr/local/games 本地游戏二进制文件 /usr/local/include 本地C头文件 /usr/local/lib 本地库 /usr/local/man 本地在线手册 /usr/local/sbin 本地系统二进制文件 /usr/local/share 本地独立架构层次结构 /usr/local/src 本地源码 /usr/local/share目录内容的要求应与/usr/share相同，唯一附加约束是/usr/local/share/man和/usr/local/man目录必须是同步的。（基本上就是符号链接了！） /usr/sbin/usr/sbin :非必要的标准系统二进制文件 该目录包含系统管理员专门使用的任何非必要的二进制文件。系统修复、恢复、挂载/usr等其他重要必要功能必须放在/sbin中。 /usr/share/usr/share :独立于架构的数据 /usr/share层次 是为了所有只读架构独立数据。该层次可以在给定OS的所有体系架构平台之间共享。如具有i386和PPC平台站点可能会维护一个集中安装的/usr/share目录。但/usr/share一般不打算由不同的操作系统共享，或由同一操作系统的不同版本共享。 The following dis or symbolic-links to dirs must be in /usr/share 目录 描述 man 在线手册 misc 其他独立于架构的数据 The following dis or symbolic-links to dirs must be in /usr/share, if the corresponding subsystem is installed 目录 描述 备注 dict 单词列表 Optional doc 各种文档 Optional games /usr/games的静态文件 Optional info GNU Info system’s primary dir Optional locale 支持的区域信息 Optional zoneinfo Timezone info and conf Optional NLS Native language support Optional sgml SGML数据 Optional terminfo terminfo数据库目录 Optional xml xml数据 Optional /usr/share/dict/usr/share/dict :单词列表这个目录是系统上单词列表的家目录，只包含英文单词，它们由look和各种拼写程序使用。它们是所有拼写检查器唯一通用的文件。 文件 描述 备注 words 单词列表 Optional linu.words linux可用单词列表 Optional /usr/share/man/usr/share/man :手册页它包含了/, /usr文件系统下的命令和数据的手册信息 手册页存储在 /usr/share/man/&lt;locale&gt;/man&lt;section&gt;/&lt;arch&gt;中。 每个部分的描述： man1: 可公开访问的命令的手册页，用户需要使用的大多数程序文档放置于此； man2: 系统调用部分，描述所有的系统调用(请求内核执行操作)； man3: 函数库和子例程部分，描述不直接调用内核服务的程序库例程； man4: 特定文件部分，描述系统中特定文件，相关驱动程序和网络支持。通常，这包含/dev中找到的设备以及网络协议支持的内核接口； man5: 文件格式部分，许多数据文件的格式记录在此； man6: 游戏，演示和一般小程序； man7: 各种难以分类的手册页； man8: 系统管理员用于操作和维护系统的程序记录在这。 The following dirs or symboli-link to dirs must be in /usr/share/man/&lt;locale&gt;, unless they are empty 目录 描述 备注 man1 用户程序 Optional man2 系统调用 Optional man3 函数库调用 Optional man4 特定文件 Optional man5 文件格式 Optional man6 游戏 Optional man7 混杂的手册页 Optional man8 系统管理 Optional 必须在/usr/share/man结构中作出规定，以支持用不同语言编写的手册页。这些规定必须考虑到手册页的存储和参考，相关因素包括语言和字符编码集。 栗子： Language Country CharacterSet Dir English - ASCII /usr/share/man/en English United Kingdom ISO 8859-15 /usr/share/man/en_GB English United States ASCII /usr/share/man/en_US /usr/share/misc/usr/share/misc :与架构无关的数据 /usr/share/sgml/usr/share/sgml :SGML数据 /usr/share/xml/usr/share/xml :XML数据 /usr/src/usr/src :源代码Source Code可能放置在此目录的子目录中，仅供参考。 /var Hierarchy/var 包含可变数据文件，包括假脱机目录和文件，系统管理和登录数据，以及临时文件。 如果/var不能成为一个单独的分区，最好将/var移出/分区并移入/usr分区。（为了减小根分区大小或当根分区空间不足时）也可将/var链接到/usr/var。 The following dirs or symbolic-link to dirs are required in /var. 目录 描述 /var/cache 应用程序缓存数据 /var/lib 可变状态信息 /var/local /usr/local的可变数据 /var/lock 锁文件 /var/log 日志文件 /var/opt /opt的可变数据 /var/run 与运行进程相关的数据 /var/spool 应用程序队列数据 /var/tmp 为系统重启保留的临时文件 The following dirs or symbolic-link to dir must be in /var,if the corresponding subsystem is installed. 目录 描述 备注 /var/account 进程账户日志 可选 /var/crash 系统奔溃转储 可选 /var/games 可变游戏数据 可选 /var/mail 用户邮箱文件 可选 /var/yp 网络信息服务数据库文件 /var/account/var/account :该目录保存当前活动的进程记账日志和复合进程数据。 /var/cache/var/cache :保存应用程序缓存的数据。应用程序必须能够重新生成或回复数据。与/var/spool不同，删除了缓存文件不会丢失数据。数据必须在应用程序调用和系统重启间保持有效。缓存目录的数据格式没有其他要求。 对于缓存数据单独存在的目录，系统管理员可从/var下其他目录设备不同的磁盘和备份策略。 目录 描述 备注 /var/cache/fonts 本地生成的字体 可选 /var/cache/man 本地格式化的手册页 可选 /var/cache/www www代理或缓存数据 可选 /var/cache/&lt;package&gt; 特定包缓存数据 可选 /var/lib/var/lib :可变状态信息。目录保存于应用程序或系统有关的状态信息。状态信息(state infofmation)，是程序在运行时修改的数据，属于一个特定的主机。 应用程序必须为其数据使用/var/lib/&lt;subdir&gt;，有一个必须的子目录/var/lib/misc用于不需要子目录的状态文件。 /var/lock/var/lock :锁文件，锁文件应该存储在此目录中。锁文件锁定多个应用程序共享的设备和其他资源。 这种锁文件内容的格式必须是HDB UUCP锁文件格式。HDB格式是将进程标识符(PID)存储为ASCII十进制数，并带有换行符。 /var/log/var/log :日志文件和目录，大多数日志必须写入此目录或适当子目录。 The following file or symbolic-link to file must be in /var/log. 文件 描述 lastlog 每个用户上次登录信息的记录 message syslogd的系统信息 wtmp 所有登录和注销的记录 /var/mail邮件缓存区必须通过/var/mail访问，邮件缓冲区文件必须采用的形式。 /var/run/var/run :运行时变化数据，此目录包含系统信息数据，描述系统启动以来的情况。此目录下的文件必须在引导过程开始时被清除。进程标识符(PID)文件放置于此目录或下的子目录里面。 /var/spool/var/spool :应用程序队列数据。此目录包含正在等待某种稍后处理的数据，/var/spool中的数据表示工作将在将来执行(通过程序，用户或管理员)，数据通常会在工作处理后被删除。 The following dirs or symbolic-link to dirs must be in /var/spool,if the corresponding subsystem is installed. 目录 描述 备注 lpd 打印机队列目录 可选 mqueue 发送邮件队列 可选 news 新闻假脱机目录 可选 rwho rwhod文件 可选 uucp uucp的假脱机目录 可选 /var/tmp/var/tmp :在系统重启之间保存的临时文件。存储在/var/tmp的数据比/tmp中的数据更持久。 OS Specific Annex本节是针对仅适用于特定OS的其他建议和要求。 LinuxLinux操作系统的附件 / :根目录在Linux系统上，如果内核位于/，建议使用Linux内核源代码包中使用的名称vmlinux或vmlinuz。 我的CentOS7中，内核文件默认是/boot/vmlinuz-$kernel-version.$arch /bin :基本用户命令二进制文件(供多有用户使用) /dev :设备和特殊文件 /dev/null : 写入该设备的所有数据都被丢弃。从这个设备读取将返回一个EOF条件。 /dev/zero : 该设备是归零数据的来源，写入该设备的所有数据被丢弃。从这个设备读取将返回包含zero的请求的字节数。 /dev/tty : 该设备类似于进程控制终端。一旦这个设备被打开，所有读写操作就好像实际的控制终端以及被打开一样。 /etc :主机的特定系统配置Linux系统要将附件文件放置到/etc中。 /lib64 和 /lib32 :64/32位库(依赖于体系结构)64位体系结构PPC64,AMD64,x86_64必须将64位库放置于/lib64中，将32位库放置于/lib中；64位体系结构IA64必须将64位库放置于/lib中。 /proc :内核和进程信息虚拟文件系统PROC文件系统是用于处理进程和系统信息的标准Linux方法，而不是/dev/kmem和其它类似方法。强烈建议使用PROC文件系统获取 存储，进程，内存，内核等信息。 /sbin :基本系统二进制文件Linux系统将这些附加文件放置于/sbin中： 第二扩展文件系统命令（可选）： 123456badblocksdumpe2fse2fsckmke2fsmklost+foundtune2fs boot-loader 映射安装程序（可选）：lilo 静态二进制文件： 123ldconfigsln(static ln)ssync(static sync) 出现问题时，sln（静态ln）和ssync（静态同步）非常有用；idconfig程序可以作为升级知道的手段；sln的主要用途，修复不良协调升级后/lib中不正确的符号链接动态库。 对于/sbin, idconfig二进制文件是可选的。因为站点可能会在启动时选择运行idconfig而不是仅在升级共享库时。以下是一些常见问题： 我刚刚删除了/lib/； 我无法找到库的名称，因为ls是动态链接。我使用的shell没有内置ls，我也不知道使用echo *作为替换； 我有一个静态ln，但我不知道怎么称呼这个链接。 杂项： 12345#ctrl+alt+delctrlaltdel#keyboard ratekbdrate 为了应对某些键盘出现如此高的重复速率一致无法使用,kbdrate可以安装在某些系统上的/sbin中； 由于ctrl+alt+del组合键在内核中的默认操作是硬重启，因此通常建议在将根文件系统挂在到读写模式之前禁用该行为。这就可能需要ctrlaltdel程序，它可以安装在系统的/sbin中。 /usr/include :C程序包含的头文件如果安装了C或C++编译器，则只有非 基于glibc的系统才需要这些链接符号。 12/usr/include/asm -&gt; /usr/src/linux/include/asm-&lt;arch&gt;/usr/include/linux -&gt; /usr/src/linux/include/linux /usr/src :源代码对于基于glibc的系统，此目录没有具体指导。 对于glibc之前基于linux libc修订版的系统： /usr/src/linux是唯一放置Linux内核源代码的位置。 /usr/spool/cron :cron和jobs此目录包含了cron和程序的可变数据。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>FHS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix]]></title>
    <url>%2F2017%2F11%2F14%2FZabbix%2F</url>
    <content type="text"><![CDATA[参考： Zabbix官方网站 Zabbix中文文档 Zabbix-repo仓库: http://repo.zabbix.com 阿里云镜像: https://mirrors.aliyun.com/zabbix/zabbix/ . 环境： CentOS7x86_64 Zabbix 3.4 Zabbix简介Zabbix （音同 zæbix），是由 Alexei Vladishev 开发的一种网络监视、管理系统，基于 Server-Client 架构。Zabbix 的授权是属于 GPLv2。Zabbix可用于监视各种网络服务、服务器和网络机器等状态。是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案。Zabbix也可经由SNMP、TCP、ICMP、SSH等对目标进行监视。 Zabbix的系统构成Zabbix系统由以下各独立模块组成： Zabbix Server，服务端(以C开发)。Server端通过收集SNMP和Agent发送的数据，写入数据库，再通过PHP+Apache在Web端展示； Zabbix Agent，客户端(基本支持所有操作系统)，并将监控主机数据发送给Server； Zabbix Frontend，Web管理端(以PHP和JavaScript构成)； Zabbix Proxy(可选组件)。用于分布式监控。 Zabbix的特点Zabbix是一个高度集成的网络监控解决方案，一个简单的安装包中提供多样性功能。 数据收集； 灵活的阀值(触发器)定义； 高度可配置化的告警； 实现图表绘制； Web监控功能； 丰富的可视化选项； 历史数据存储； 配置简单； 使用模板； 网络发现； Zabbix API； 权限管理系统； 功能强大并易于扩展的监控代理。 定义Zabbix的常用术语含义。 主机(host)： 一台你想监控的网络设备，用IP或域名表示。主机名不能使用中文创建，会报错。 主机组(host group):主机的逻辑组，它包含主机和模板。组名可以使用中文。 监控项(item):你想要接收的主机的特定数据，一个度量数据。 触发器(trigger):一个被用于定义问题阀值和评估监控项接收到的数据的逻辑表达式。 事件(event):单次发生的需要注意的事情。 异常(problem):一个处在异常状态的触发器。 动作(action):一个对事件作出反应的预定义的操作。 升级(escalation):一个在动作内执行操作的自定义场景。 媒介(media):发送报警通知的手段。 通知(notification):利用已选择的媒体途径把事情相关信息发送给用户。 远程命令(remote command):预先定义好的，满足一定条件后，可在被监控主机上自动执行的命令。 模板(template):一组可以被应用到一个或多个主机上的实体的集合。 应用(application):一组监控项组成的逻辑分组。 Web场景(Web scenario):利用一个或多个HTTP请求来检查网站的可用性。 前端(frontend):Zabbix提供的Web界面。 Zabbix API:Zabbix API允许你使用JSON RPC协议来创建、更新和获取Zabbix对象信息或执行任何其他的自定义的任务。 Zabbix server:Zabbix软件监控的核心程序，主要功能是与Zabbix proxies和agent进行交互、触发器计算、发送告警通知，并将数据集中保存等。 Zabbix agent:部署在监控对象上，能够主动监控本地资源和应用。 Zabbix proxy:帮助Zabbix server收集数据，分担Zabbix server的负载。 Zabbix进程Agentzabbix agent部署在监控的目标上，主动监测本地的资源和应用（硬件驱动，内存，处理器统计等）。zabbix agent手机本地的操作信息并将数据报告给zabbix server用于进一步处理。 zabbix agent有被动(passive)和主动(active)两种检查方式。 Serverzabbix server是zabbix软件的核心程序。它通过轮询和捕获数据，计算是否满足触发器条件，向用户发送通知。它是zabbix监控代理和Proxy代理报告系统可用性和完整性数据的核心组件。zabbix server自身可以通过简单远程检查网络服务(如Web服务器和邮件服务器)。 server是一个包含了被存储了所有配置，统计方面的和可操作数据的中央仓库，它是监控系统问题升级以致于激活警告管理器的zabbix中的实体。 基本的zabbix server分三个不同的组件：zabbix server，web前端，数据库存储。zabbix的所有配置信息都存储在服务器和web前端进行交互的数据库中。 zabbix server进程是以守护进程（Daemon）运行的。 Proxyzabbix proxy是一个可以从一个或多个受监控的设备设备收集监控数据，并将信息发送到zabbix server的进程，基本上是代表server工作。所有收集的数据都在本地进行缓存，然后传送到proxy所属的zabbix server。 zabbix proxy是完成远程区域、分支机构、没有本地管理员的网络的集中监控的理想解决方案。 zabbix proxy需要使用独立的数据库，以守护进程的方式运行。 Java gatewayzabbix守护进程原生支持监控JMX程序，它被称为zabbix java gateway。zabbix gateway是用Java语言写成。 要查得一台主机特定的JMX计数器值，zabbix server向zabbix java gateway发送请求，后者使用JMX管理API去请求远程的有关应用。应用不许额外安装软件，只需要启动时在命令行指定 -Dcom.sun.management.jmxremote即可（是在java程序）。 每个zabbix server或zabbix agent只能配置一个java gateway。 Senderzabbix sender是一种命令行应用，它可以将性能数据发送到zabbix server进行处理。该应用通常用在长时间运行的用户脚本，用于定期发送可用性和性能数据。 123456zabbix_sender -z zabbix -s &quot;xxx&quot; -k db.connections -0 43-z :server主机-s :受监控主机的技术名称-k :监控项的键-o :要发送的值 Getzabbix get也是一种命令行应用，用于与zabbix agent进行通信，并从agent那里获取所需的信息。该应用通常被用于zabbix agent故障排除 12345678zabbix_get -s $host -p xxx -k system.cpu.load[all,avg15]-s --host-p --port-I --source-address-k --key-h --help-V --version 安装ZabbixZabbix安装要求硬件： 内存，最小128MB； 磁盘，最小256MB； CPU，可能需要大量CPU资源； SMS(短信)通知服务，串行通讯口(serial communication port)和串口GSM调制解调器(serial GSM modem)。可选项。 支持平台： Linux; IBM AIX; FreeBSD; NetBSD; OpenBSD; Mac OS X; Solaris; Windows(Only Agent). 软件：Zabbix基于Apache Web服务器、领先的数据库引擎和PHP脚本语言进行构建。 数据库管理系统： MySQL 5.0.3 及以上； Oracle 10g 及以上； PostgreSQL 8.1 及以上； SQLite 3.5及以上； IBM DB2 9.7 及以上。 前端： Apache 1.3.12 及以上； PHP 5.4.0及以上； PHP-Extension: 软件 版本 备注 gd 2.0及以上 PHP GD扩展包必须支持PNG图片 bcmatch php-bcmatch ctype php-ctype libXML 2.6.15及以上 php-xml xmlreader php-xmlreader xmlwrite php-xmlwriter session php-session sockets php-net-socket mbstring php-mbstring gettext php-gettext ldap php-ldap mysqli 使用MySQL作为Zabbix后端数据库所需的组件 pgsql 使用PostgreSQL作为Zabbix后端数据库所需的组件 sqlite3 使用SQLite作为Zabbix后端数据库所需的组件 客户端浏览器：必须启用Cookie和JavaScript功能。 服务器： 要求 描述 OpenlPMI 支持IPMI功能所需组件 libssh2 支持SSH功能 fping 支持ICMP ping功能 libcurl 支持Web监控，VMware监控及SMTP认证 libiksemel 支持Jabber功能 libxml2 支持VMware监控 net-snmp 支持SNMP监控 Java网关：Java gateway编译和运行在Java 1.6 及以上版本。 数据库容量：Zabbix配置数据需要使用固定的磁盘空间，而这个空间不会过多增长。 Zabbix数据库容量主要依赖于以下参数： 每秒处理值的数量(Number of processed values per second); 历史(History)数据的回收清理设置(Housekeeper); 趋势(Trends)数据的回收清理设置(Housekeeper); 事件(Events)数据的回收清理设置(Housekeeper)。 时钟同步：对于Zabbix稳定运行而言，服务获取精确的系统时间是非常重要的。对于所有运行Zabbix组件的系统，强烈建议这些系统的时间保持同步。ntpd是一个临幸的用于同步主机和其他服务器之间的时间的后台程序。 安装、启动、配置ZabbixZabbix-repo仓库：repo.zabbix.com该仓库服务器同时提供yum和apt源码库。 配置源码库1. 从官方下载源码库 1234567#rpm -ivh http://repo.zabbix.com/zabbix/$version/rhel/7/$arch/$zabbix-release.rpmrpm -ivh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.centos.noarch.rpm#阿里云镜像#rpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.noarch.rpm#镜像失效的话自己去官网找 2. 手动配置zabbix.repo 1234567vim /etc/yum.repos.d/zabbix.repo[zabbix]name=Zabbix-Repobaseurl=http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/gpgcheck=0enable=1 安装Zabbix部署包使用MySQL数据库安装Zabbix Server、Web前端：1yum install -y zabbix-server-mysql zabbix-get 注意：此处Zabbix数据库使用MySQL，请自行安装MySQL。 安装Zabbix Agent：1yum install -y zabbix-agent 安装初始化数据库查看刚刚安装的 zabbix-server-mysql：解压得到的sql脚本create.sql只会在对应的数据库中初始化zabbix所需要的数据库表，但是不会创建zabbix数据库。所以后面我们还需要手动创建zabbix数据库。1234567rpm -ql zabbix-server-mysqlcd /usr/share/doc/zabbix-server-mysql-3.x.xx/#有一个create.sql.gz的压缩文件gunzip create.sql.gz#得到create.sql 在MySQL中创建zabbix数据库：12345678910111213141516171819msyql -uxxx -pmysql&gt;CREATE DATABASE 'zabbix' DEFAULT CHARACTER SET 'utf8';mysql&gt;SHOW DATABASES;mysql&gt;GRANT ALL ON zabbix.* TO 'zabbix'@'localhost' identified by 'zabbix';mysql&gt;FLUSH PRIVILEGES;#导入sql脚本mysql -uroot -p -Dzabbix &lt; ./create.sqlUSE zabbix;SHOW TABLES;#mysql限制IPvim /etc/my.cnf[mysqld]bind-address=127.0.0.1 配置zabbix server并启动编辑zabbix server配置文件：123456789101112131415161718192021vim /etc/zabbix/zabbix_server.conf#常会修改的参数#数据库配置DBHost=localhostDBName=zabbixDBUser=zabbixDBPassword=zabbixDBPort=3306DBSocket=/var/lib/mysql/mysql.sock#服务监听端口ListenPort=10051#服务端源IPSourceIP=#日志记录方式，file使用指定文件作为日志文件，system将日志发往syslog，console将日志发送控制台LogType=fileLogFile=/var/log/zabbix/zabbix_server.log 启动zabbix服务端：1234567891011121314systemctl start zabbix-server#此处可能由于没有关闭SELinux而报错tail /var/log/zabbix/zabbix_server.logcannot set resource limit: [13] Permission denied#关闭SELinuxsetenforce=0vim /etc/selinux/configSELINUX=disabled#查看zabbix-server默认监听的10051端口netstat -nltp 安装zabbix webzabbix web可以安装在单独的主机上，只要能连接到zabbix database所在数据库就行。但为了方便，都安装在了server上。 zabbix web需要LAMP环境：12345#可能需要自己配置PHP remi源，注意PHP及扩展版本问题yum install -y httpd php php-mysql php-mbstring php-gd php-bcmatch php-ldap php-xml#指定php版本#yum --enablerepo=remi-php56 install php-mysql php-mbstring php-gd php-bcmatch php-ldap php-xml 安装zabbix web所需的两个包：123456789yum install -y zabbix-web zabbix-web-mysql#此处默认使用php5.4#因为我的环境是php5.6,会报错#此时就需要指定php版本来安装yum --enablerepo=remi-php56 install zabbix-web zabbix-web-mysqlrpm -ql zabbix-web#zabbix-web位于/usr/share/zabbix/ 编辑zabbix的前端Apach-PHP配置文件zabbix前端的Apache配置文件位于 /etc/httpd/conf.d/zabbix.conf:1234567891011121314151617181920212223242526272829vim /etc/httpd/conf.d/zabbix.conf#需修改时区php_value max_execution_time 300php_value memory_limit 128Mphp_value post_max_size 16Mphp_value upload_max_filesize 2Mphp_value max_input_time 300php_value always_populate_raw_post_data -1php_value date.timezone Asia/Shanghai#建议顺便修改/etc/php.ini的时区vim /etc/php.inidate.timezone = Asia/Shanghai#添加httpd的虚拟主机访问zabbix web&lt;VirtualHost IP:80&gt;servername zabbix.medocumentroot /usr/share/zabbix默认数据&lt;/VirtualHost&gt;#开启httpd服务systemctl start httpd 添加hosts后就可以利用域名访问zabbix-web端了。 1echo -e "192.168.1.9 \t zabbix.me" &gt;&gt; /etc/hosts 在web端配置zabbix在浏览器访问 http://zabbix.me 初始化zabbix配置。配置好后就需要用账号密码进行登录zabbix-web端dashboard。 默认用户名是：admin，密码是配置文件里面设置的。 登录进Dashboard后，可修改语言为中文。 如果你的Zabbix无法看到中文选项，那么可能需要如下操作：1234vim /usr/share/zabbix/include/locales.inc.php#修改'zh_CN' =&gt; ['name' =&gt; _('Chinese (zh_CN)'), 'display' =&gt; true], 如果又遇到中文乱码的问题，则可以从windows中挑选一些好看的中文字体，将对应字体文件放置到zabbix web的字体目录中。windows中字体后缀.TTF，Linux中为.ttf。注意修改大小写。123456789101112131415cd /usr/share/zabbix/fonts#只有一个默认字体 graphfont.ttf#将新字体放置到此目录下#修改配置文件中对应字体名称vim /usr/share/zabbix/include/define.inc.php#将默认字体名字修改为字体目录下 你需要的字体名define('ZBX_FONT_NAME', 'graphfont');define('ZBX_GRAPH_FONT_NAME', 'graphfont'); // font file name#栗子，如perpetua字图PER.ttfdefine('ZBX_FONT_NAME', 'PER');define('ZBX_GRAPH_FONT_NAME', 'PER'); // font file name 图形显示乱码，同样是用以上方法。在windowss上找一个中文字体上传到zabbix字体目录，并修改配置文件就可以了。 Zabbix Web界面菜单： 管理菜单，用于管理zabbix自身及zabbix相关设置； 配置菜单，用于配置监控相关设置； 报表菜单，为管理员生成一段时间内的监控统计信息； 检测中菜单，用于查看被监控的相关数据； 资产记录菜单，查看被监控的主机有哪些，以及相关的资产信息。 安装zabbix agentAgent端安装也非常方便，直接在Client上安装两个包即可。 123456789101112#配置zabbix源rpm -ivh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.centos.noarch.rpm#aliyun镜像#rpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.noarch.rpm#安装yum install -y zabbix-agent zabbix-senderrpm -ql zabbix-agent#/etc/zabbix/zabbix_agentd.conf zabbix的“主动模式”与“被动模式”都在/etc/zabbix/zabbix_agentd.conf中定义。配置最常用的agent端：12345678910111213141516171819202122232425262728293031vim /etc/zabbix/zabbix_agentd.conf####GENERAL PARAMETERS 通用配置PidFile=LogFile=####Passive checks related 被动模式配置#指定允许哪台服务器拉取本机数据Server=#指定agent端工作于被动模式时监听的端口号ListenPort=10050(默认)#指定agent端工作与被动模式时所监听的IP地址ListenIP=0.0.0.0(默认)#指定预生成的agent进程数量StartAgents=####Active checks related#agent工作于主动模式时，将消息推送到哪台Server上ServerActive=IP1,IP2...#指定当前主机主机名，Server端通过对应的主机名识别主机Hostname=#指明agent端每隔多少秒将采集的数据发往Server端RefreshActiveChecks=#栗子Server=192.168.1.9ServerActive=192.168.1.9Hostname=zabbix.me 启动zabbix-agent1234systemctl zabbix-agent start#查看状态,默认端口10050netstat -nltp 快速开始zabbix-web菜单zabbix-web界面中包含有监测中、资产记录、报表、配置、管理五项菜单。 登录和配置用户在浏览器输入 zabbix.me (修改hosts)，登录zabbix-web后台。 默认用户名：Admin，密码：zabbix。它是超级管理员。 为了防止暴力破解和词典攻击，连续尝试五次登录失败，zabbix界面将暂停30秒。 可以通过管理(Management)菜单下的用户(User)，新建、查看、管理用户信息。 zabbix在安装后自定义了两个用户： Admin用户是zabbix的超级管理员，拥有所有权限； Guest用户是一个特殊的默认用户。如果你没有登录，你访问zabbix的时候其实就是“guest”权限。guest默认没有任何权限。 你可以创建一个用户(user)并将其加入特定的用户组(Group)以提升用户权限。 可以仅用用户信息里面-报警媒介里面，自定义严重性的报警。只有勾选部分的报警信息才会发送过来。这也很棒！ 如果存在严重性则使用： Not classified Information Warning Average High Disaster 新建主机zabbix中的主机(host)是一个你想要监控的网络实体(物理的、虚拟的)。对于主机的定义非常灵活。它可以是一台物理服务器，一个网络交换机，一个虚拟机或一些应用。 可以通过配置(Configuration)菜单下的主机(Host)，查看已配置主机相关信息。默认有一个“Zabbix Server”的定义好的主机。 点击创建主机(Create host)后，填写对应的主机名称、添加对应的主机群组，zabbix-agent的IP地址和端口，以及其它信息。 新建监控项监控项是zabbix中获得数据的基础。没有监控项，就没有数据。因为一个主机中只有监控项定义了”单一的指标“或者”需要获得的数据“。 可以通过配置(Configuration)菜单下的主机(Item)，找到需要配置监控项(Item)的主机，然后创建监控项。主机默认是没有定义任何监控项的。 填写对应的监控名称、类型、键值、主机接口、信息类型等等信息。 可在监控(Monitoring)菜单中最新数据(Latest data)查看之前定义的监控项和获得的值。还可选择以图形(Graph)或值来查看监控项的相关信息。 同样也还以在Zabbix-Server端获得数据信息：12#zabbix_get -s $ip -k $valuezabbix_get -s 192.168.1.9 -k system.cpu.load 新建触发器监控项只用于收集数据。如果要自动评估收到的数据，我们则需要定义触发器(trigger)。触发器包含了一个表达式，这个表达式定义了数据的可接受的阈值级别。 如果收到的数据超过了定义好的级别，触发器将被触发，或者进入异常状态(problem)。从而引起我们的注意，让我们知道有问题发生。如果数据再次恢复到合理范围，触发器将会转到正常状态(OK)。 可以通过配置(Configuration)菜单下的主机(Hosts)选项，找到某主机的触发器(Triggers)创建触发器。 填写对应的触发器名称、表达式、描述等信息。 获取问题通知当监控项收集了数据后，触发器会根据异常状态触发报警。根据一些报警机制，它也会通知我们一些重要的事情，而不是直接在zabbix-web端进行查看。这就是通知(Notification)的功能。E-mail是最常用的异常通知发送方式。当然还有SMS（短信），脚本等媒体类型。 可以通过管理(Administration)菜单中的报警媒体类型(Media types)，点击预定义媒体类型列表中的Email，来配置Email。 为了建立一个通知，我们需要在配置菜单下动作中，创建动作(Create action)。 一旦满足了触发器的条件，变回触发执行动作。如收到E-mail等… 新建模板如果我们配置上前台主机，一些自动化操作会带来更多便利性。没错，模板(templates)功能就可以实现。模板允许对有用的监控项、触发器和其他对象进行分组，只需要一步就可以对监控主机应用模板，已达到反复重用的目的。 当一个模板链接到一个主机后，主机会继承这个模板中的所有对象。简单而言，一组预先定义好的检查会被快速应用到主机上。 Zabbix为各种操作系统、设备以及应用准备好了一些预定义的模板。你可以快速部署使用他们。但是请注意，一些模板需要根据你的实际情况和使用环境进行适当俄调整。 比如，一些检查项是不需要的，一些轮询周期过于频繁等。 在配置菜单下的模板(Templates)下，点击创建模板(Create template)。填写对应的模板名称，群组等信息。 创建模板完毕后，可将模板链接到主机。之后，模板及其所有对象被添加到了主机。 配置(Configuration) 主机和主机组(Hosts and groups)一般来讲，zabbix主机是指你希望监控的那些设备。如服务器、工作站、交换机等。创建主机是使用zabbix过程的首要任务。 我们可以把主机组想象成项目组。根据不同的功能将主机划分到主机组是非常重要的，这样可以对以后创建的用户和用户组在定义权限的时候，不用给他们zabbix admin权限，而只需要根据主机组(项目组)给予用户和用户组对应项目(主机组)的权限即可。这样很大程度上方便了Zabbix监控多个项目，也利于管理。同样，报警的时候也只会收到权限内的相关报警信息。 配置一台主机配置–主机–创建主机–填写相关参数信息。 可以在已经存在的主机上使用 Clone或Full Clone创建一个新主机。 Clone将保留所有的主机参数和模板链接；Full Clone将额外保留指数实体(应用集、监控项、触发器、视图、规则、Web场景)。 新建主机下： 主机(Host)：包含了通用的主机属性； 模板(Template)：允许将模板链接诶到主机，所有实体将从模板继承； IPMI：包含IPMI管理属性； 宏(Macros)：允许定义主机级别的用户宏； 主机资产记录(Host inventory)：允许为主机收工输入库存信息； 允许你请求与主机的加密的连接。 资产管理(Inventory)你可以将联网设备的资产信息保存在zabbix里。资产信息实在配置主机时人工录入建立的资产信息数据，或者通过使用某些自动填充选项完成的录入。 构建资产库： 手动模式： 在配置一台主机的时候，手动输入资产信息； 自动模式： 在配置主机的时候，选择自动。 之后便可以在资产记录菜单中的概述，主机项中查看相关信息。 批量更新(Mass update)有时候可能需要一次更改多个主机的某些属性，使用批量更新(mass update)功能来代替打开每个主机进行编辑。 可批量处理主机、模板、IPMI、资产、加密相关信息。 监控项(Items)监控项是从主机收集的数据信息。配置主机后，需要添加一些监控项以开始获取数据。快速添加多个监控项的一种方法是将预定义的模板附加到主机。 在单个监控项中，可指定从主机收集哪些数据信息。为此，可使用监控项key。 如system.cpu.load将收集处理器负载的数据。要给 key 指定更过参数，请在后面添加方括号[]。 如system.cpu.load[avg5]， 返回最近5分钟的CPU负载平均值。 创建一个监控项可在主机中新建一个监控项。不支持的监控项：如果由于某种原因无法检索该值，则该监控项可能不被支持。这些监控项仍然以固定的间隔重新检查。 监控项的key: key名称允许使用字符： 0-9a-zA-Z_-. key参数，用 逗,号 分隔： xxx[par1,par2…] key参数也可以为空，此时使用默认值： key key参数带引号，则允许任何Unicode字符，如果包含双引号则需要 \反斜杠 转义 key参数是一个数组，它需要包含在方括号中 自定义间隔(Custom intervals) 创建关于监控项的自定义时间规则。灵活间隔被设计为重新定义默认监控项的的更新间隔，但调度间隔用于指定独立执行的检查计划。 灵活的间隔(Flexible intervals)：允许重定义特定时间段的默认间隔。 间隔(Interval)： 指定时间段的更新间隔； 期间(Period)： 灵活间隔有效的时间段； 举个栗子： 60(interval), 1-7,00-24(period)。监控项每隔60s检查一次。 调度间隔(Scheduling intervals)：用于在特定时间检查监控项。 调度间隔定义为， md&lt;filter&gt;wd&lt;filter&gt;h&lt;filter&gt;m&lt;filter&gt;s&lt;filter&gt;。 md: month days(1-31) wd: week days(1-7) h: hours(0-23) m: minutes(0-59) s: seconds(0-58) : 指定其前缀的值—-[from-to/step]。 其实类似于Linux中定时任务的写法，只不过这里把单位(md,wd,h,m,s)写在了数值的前面。 举个栗子： 123456789101112md1-15 #1-15号wd3 #星期三h0-12 #上半天m1,3,5,7,9 #每个1,3,5,7,9分钟s/10 #每个10s#组合体wd1-5h9-18m/10 #每个工作日的上班时间每个10分钟 监控项类型(Items type)监控项类型包含从系统获取数据的多种方式。每个监控项类型都有一组自己支持的监控项key和所需的参数。 zabbix提供的监控项类型： zabbix代理检查(agent checks) SNMP代理检查 SNMP traps IPMI检查 简单检查(simple checks) VMware监控(monitoring) 日志文件监控 计算监控项(Calculated items) zabbix内部检查(internal checks) SSH检查 Telnet检查 外部检查(External checks) 汇总检查(Aggregate checks) 捕捉器监控项(Trapper items) JMX监控 ODBC监控 zabbix代理(zabbix agent)：这些检查与zabbix代理进行通信实现数据的采集。 zabbix agent-passive： 被动模式，Server向Agent索要数据； zabbix agent-active： 主动模式，Agent主动上报数据给Server。 可支持的监控项，可在新建监控项是在键值里面查看。 SNMP代理(SNMP agent)： 在启用SNMP的设备(如打印机，交换机，路由器…)上使用SNMP监控，为了能够监控SNMP代理在这些设备上提供的数据，zabbix服务器初始化配置时必须具有SNMP支持。仅通过UDP协议执行SNMP检查。 配置SNMP监控： 使用SNMP接口为设备创建一个主机； 找出要监控项目的SNMP字符串； 创建一个监控项。 IPMI检查： 你可以在zabbix中监控 智能平台管理接口(IPMI) 设备的运行状况和可用性。要执行IPMI检查，zabbix服务器必须首先配置IPMI支持。 简单检查： 简单检查通常用于远程无代理监控服务。 日志文件监控： zabbix可用于集中监控和分析 具有/不具有 日志转动能力的日志文件。当日志文件包含某些字符串或字符串模式时，通知信息可用于警告用户。 计算监控项： 计算监控项是创建虚拟数据源的一种方式。这些值将根据算术表达式定期计算。所有计算都由Server完成。 内部检查：内部检查可以监控zabbix的内部检查。即Server或Agent Server的运行情况。 SSH检查： 运行SSH检查是作为无代理监控的，SSH检查不需要zabbix代理。执行SSH检查zabbix服务器必须初始化配置为SSH2支持。 SSH检查提供两种身份验证方法，一种是用户/密码，另一种是基于密钥文件。 zabbix SSH 密钥配置: 1234567891011vim /etc/zabbix/zabbix_server.conf#SSHKeyLocation=SSHKeyLocation=/home/zabbix/.sshusermod -m -d /home/zabbix zabbixchown zabbix:zabbix /home/zabbixchmod 700 /home/zabbixcd /home/zabbix &amp;&amp; su zabbixssh-keygen -t rsa 外部检查： 外部检查是由zabbix Server通过运行shell脚本或二进制的检查。外部检查不需要再被监控的主机上运行任何代理。 汇总检查： 在汇总检查中，zabbix通过直接从数据库中查询监控信息，然后进行信息聚合。聚合检查不需要再被监控的主机上运行任何代理。 捕捉器监控项： 捕捉器监控项接收传入的数据，而不是查询它。对于想要推送到zabbix的任何数据都是适用的。 要使用捕捉器监控项，需要在zabbix中建立一个捕捉器监控项，将数据送给zabbix。 JMX监控项： JMX监控可用于监视Java应用程序的JMX计数器。JMX监视器以zabbix守护进程方式运行，名为zabbix java gateway。 ODBC监控： ODBC监控对应于zabbix web管理端中的数据库监控器监控项类型。ODBC是用于访问 数据库管理系统(DBMS) 的C语言中间件API。 zabbix可以查询ODBC支持的任何数据库。为了实现监控，zabbix不直接连接到数据库，而是使用ODBC中设置的ODBC接口和驱动。该功能允许为多个目的更加有效地监控不同的数据库。 历史与趋势(history and trends)历史与趋势是zabbix中存储数据的两种方式。历史保持每个收集的值，而趋势是每小时的平均信息。 建议保持的历史数据尽可能少，但可以保留更多的趋势数据。 用户自定义参数(user parameter)有时你想运行一个代理检查，但它不是zabbix预定义的。这时就能用到用户参数。用户参数是由zabbix代理之星的命令，最多可以返回512KB的数据。key 是唯一的。 用户参数用法： 12345678910111213141516171819202122UserParameter=&lt;key&gt;,&lt;command&gt;#栗子UserParameter=ping,echo 1#使用ping键为一个监控项返回 1#复杂栗子UserParameter=mysql.ping,mysqladmin -uroot -ppwd ping | grep -c 'alive'#mysqld状态为alive返回1，否则0#灵活的用户参数UserParameter=key[*],command#[*]定义该key接受括号内的参数#栗子UserParameter=ping[*],echo $1UserParameter=mysql.ping[*],mysqladmin -u$1 -p$2 ping | grep -c 'alive'#mysql.ping[zabbix,passwd]UserParameter=wc[*],grep -c "$2" $1#wc[/etc/passwd,root] 用户自定义参数扩展zabbix代理：是将key添加到被监控的主机哦！123456789101112131415161718#编写命令--SQL查询总数mysqladmin -uxxx -pxxx status | cut -f4 -d":" | cut -f1 -d"S"#将命令添加到zabbix_agentd.confvim /etc/zabbix/zabbix_agentd.conf#找到如下字段### Option: UserParameterUserParameter=mysql.totalquery,mysqladmin -uroot -pxxx status | cut -f4 -d":" | cut -f1 -d"S"#mysql.totalquery这个key是唯一的标识符#测试此参数##测试参数可用与否很重要哈zabbix_agentd -t mysql.totalquery#重启zabbix-agent，将重新加载配置zabbix_get -s $host -k mysql.totalquery 可加载模块(loadable modules)可加载模块提供了一种关于zabbix性能扩展的选项。 可加载模块基本上只zabbix守护程序使用的共享库，并在启动时加载。可加载模块具有很多优点，卓越的性能和可实现任何逻辑的能力，更重要的是使用和共享了zabbix模块的开发能力。 windows性能计数器(windows perfomance counter)使用perf_counter[]key有效的监控windows性能计数器 批量更新(mass update)使用批量更新功能，可一次更改多个监控属性。 值映射(value mapping)对于接收值更人性化的表示，可以使用包含数值和字符串之间的映射的值映射。 如： 0 —&gt; error 1 —&gt; true F —&gt; Full D —&gt; Differential I —&gt; Incremental … 应用集(Application)应用集对逻辑组中的监控项进行分组。 如，对MongoDB的可用性，空间，负载，慢查询，执行命令…，可归于 MongoDB应用于中。 队列(queue)队列显示正在等待刷新的监控项。队列只是一个逻辑表达的数据。 队列显示的统计信息是zabbix服务器性能是否健康的指标。在 管理–队列 下对去队列。 值缓存(value cache)为了计算触发表达式，以及让计算/聚合监控项和一些宏更快，zabbix服务器支持值的缓存选项。 在内存中的缓存可用于访问历史数据，而不用之间调用数据库。如果缓存中不存在历史值，则从数据库请求缺少的值，并相应地跟新缓存。 要启用值缓存功能，修改zabbix_server.conf中可选的ValueCacheSize参数。 触发器(Trigger)触发器是评估有项目采集的数据并表示当前系统状况的逻辑表达式。触发器表达式允许定义一个什么状况的数据是“可接受”的阈值。如果超过了可接受状态，则触发器会被触发。 配置一个触发器(configuring a trigger)在主机里面配置触发器。 触发器表达式(trigger expression)一个简单有效的表达式看起来像： 1234&#123;&lt;server&gt;:&lt;key&gt;.&lt;function&gt;(&lt;parameter&gt;)&#125;&lt;operator&gt;&lt;constant&gt;#如&#123;192.168.1.7:agent.ping.time()&#125;=0 函数参数(function parameters)： 大多数数字型的函数接受秒数来作为参数。 1234567891011121314#600s内所有值的总和sum(600)#随后5个值总和sum(#5)avg()count()last()min()max()#5m 可被 300s 代替#1k 代表 1024bytes 运算符(operators)： 优先级 运算符 定义 1 - 负号(minus) 2 not 逻辑非(NOT) 3 *, / 乘，除 4 +, - 加，减 5 &lt;, &lt;=, &gt;, &gt;= - 6 =, &lt;&gt; 相等，不等于 7 and 逻辑与 8 or 逻辑或 触发器示例： 12345678910111213&#123;www.zabbix.com:system.cpu.load[all,avg1].last()&#125;&gt;5&#123;www.zabbix.com:system.cpu.load[all,avg1].last()&#125;&gt;5 or &#123;www.zabbix.com:system.cpu.load[all,avg1].min(10m)&#125;&gt;2&#123;www.zabbix.com:net.if.in[eth0,bytes].min(5m)&#125;&gt;100k&#123;$url1:net.tcp.service[smtp].last()&#125;=0 and &#123;$url2:net.tcp.service[smtp].last()&#125;=0&#123;$host:icmpping.count(30m,0)&#125;&gt;5&#123;$host:system.cpu.load[all,avg1].min(5m)&#125;&gt;2 and &#123;$hsot:system.cpu.load[all,avg1].time()&#125;&gt;000000 and &#123;$host:system.cpu.load[all,avg1].time)()&#125;&lt;060000... 滞后(Hysteresis): 有时候需要一个触发器状态OK和PROBLEM之间的间隔，而不是简单的阈值。 要做到这一点，我们首先定义一个PROBLEM事件的触发器表达式，然后为OK选择 ‘Recovery expression’，并未OK事件书如不同的表达式 如： 1234567#Problem expression&#123;server:temp.last()&#125;&gt;20#Recovery expression&#123;server:temp.last()&#125;&lt;=15#两者之间便有了几个滞后值 触发器依赖(trigger dependency)有时候，一台主机的可用性取决于另一台主机。如一台路由器后的上网设备。这就是主机之间某些依赖关系可能有用的地方，依赖关系设置的通知可能会被抑制，而只发送根本问题的通知。 zabbix中触发器的依赖，一个触发器可能有多个依赖于它的触发器。 路由器和路由器后的Server同时宕机，如果有依赖关系，则zabbix不会执行服务器的触发动作。值得注意的是，如果触发器所依赖的触发器被禁用，则次触发器的事件和动作将不会被抑制。 批量更新使用批量更新，可一次更改一些触发器的某些属性。 触发器严重性(trigger severity)触发器严重性定义了触发器的重要程度: 未分类(not classified), 灰色 信息(information), 淡蓝 警告(warning), 黄色 一般严重(average), 橙色 严重(High), 淡红 灾难(disaster), 红色 自定义触发器严重性(customising trigger)在 管理 – 一般 – 触发器严重性，里面自定义触发器严重性。 预测触发功能(predictive trigger function)有时候有即将到来的问题的迹象。可以发现这些迹象，以便提前采取行动，以减小影响。 zabbix具有基于历史数据预测受监视系统的未来行为的工具，这些工具通过预测触发功能实现。 事件标签(event tag)在zabbix中可以自定义事件标签，在触发器级别上定义事件标签。在事件标签定以后，相应的新事件被标记为时间标签数据。在拥有自定义时间标签的情况下，可以变得更加灵活。 例如： 识别日志文件中的问题并单独关闭他们； 用它来过滤通知； 查看前端的事件标签信息； 从项目值中提取的信息作为标签值； 在通知中更好地识别问题； 通过使用模板级别的标签来建华配置任务； 使用低级别发现的标签创建触发器。 事件(Events)zabbix可以生成一下几种类型的事件： trigger events-触发器事件； discovery events-发现事件； auto registration events-自动注册事件； internal events-内部事件； 事件以时间戳，并可以发送Email等基础动作。在 监控-问题 里面查看信息信息。 触发器事件生成(trigger events generation)触发器状态的变化是事件最常见和最重要的来源。每次触发器的状态改变时，都会生成一个事件。改时间包含了触发器状态变更的详细信息、发生时间以及信息的状态。 触发器会创建两种类型的事件：问题(problem)和正常(OK) 手动关闭问题事件(manual closing of problems)当触发器状态从“问题(problem)”变成“正常(OK)”时，很难判断是通过触发器表达式的方式解决。这时就需要手动解决。 只有在触发器中启用 “允许手动关闭” 选项，问题事件才可以被手动关闭。 其他事件来源(other event source)zabbix定期扫描网络发现规则中定义的IP范围，可以为每个规则单独配置检查频率。一旦发现主机或服务，就会生成一个发现事件。 zabbix可以生成以下事件： 1234Service Up/DownHost Up/DownService Discovered/LostHost Discovered/Lost 事件关联(event correlation)通常，在zabbix中正常事件会关闭所有的问题事件，但在某些情况下需要更细致的方法。可以根据事件标签关联问题事件。如，当监控日志文件时，在日志文件中想要发现某些问题，并将它们单独关闭，而不是一起关闭。 可视化(visualisation)图形(graphs)大量的监控数据被采集到zabbix中，如果能用可视化的表现形式来查看，那就直观和容易多了。 zabbix为用户提供了如下图形： 监控项数据的内置简单图形 “simple graphs”； 创建更复杂的自定义图形 “customised graphs”； 特定图形 “ad-hosc graphs”快速访问几个监控项的数据比较。 简单图形(simple graphs)：zabbix提供的简单图形，用来可视化显示监控项采集到的数据。并不需要配置就可以查看。 通过 监控-最新数据-图形 来展示图形。 自定义图形(customised graphs)：自定义图形，提供定制功能。这就有点厉害了。这个是手动配置的。可以为单个主机、多个主机、单个模板、多个模板创建自定义图形。 在 配置-主机-图形-创建图形 里编辑图形属性；图形编辑后可点击预览。 特设图形(ad-hoc graphs)：简单图形和自定义图形都不允许快速创建多个监控项目数据的比较图形，工作量小且没有维护。 在 检测-最新数据-旋转监控项前复选框-显示数据图(显示堆叠数据图) 下， 里面也包含了 正常和层积 的图形风格。 拓扑图(networking maps)运维人员如果想要了解网络环境的基础设施状况，可以在zabbix中创建网络拓扑图。 配置拓扑图(configurating network maps): 在 监控-拓扑图 下，可以创建拓扑图。点击拓扑图中的 构造函数 选项，来打开编辑区域。然后在编辑区域中添加元素和链接元素。 链接指示器(link indicators):可以为网络拓扑图中的元素之间的链接分配一些触发器，当这些触发器状况为“Problem”时，可以在链接上体现出来。如果多个触发器进入”Problem”状态，则严重程度最高的将决定链接的颜色和样式。 聚合图形(screen)在zabbix的聚合图形页面上，你可把各种来源的信息聚集到一起，一边在单个屏幕上快速查看。在 监测-图形聚合 下，对其进行创建、配置、管理和查看。 基本上，聚合图形是一个表格，你选择把每个表格有多少单元格以及其中要显示的元素。元素如下： 简单图形； 简单图形原型； 用户自定义图形； 自定义图形原型； 拓扑图； 其他聚合图形； 纯文本信息； 服务器信息； 触发器信息； 主机/主机组信息； 系统状态； 数据概述； 时钟； 事件历史； 动作历史； URL。 幻灯片演示(slide shows)在幻灯片演示中，可以配置多个聚合图形以设定的间隔逐个显示。在 监测-聚合图形-幻灯片演示 下。 模板(template)模板是可以方便地应用于多个主机的一组实体。 配置模板(configuring a template)：配置模板需要首先通过定义一些参数来创建模板，然后添加实例。在 配置-模板-创建模板 链接模板(linking)：链接是将模板应用于主机的过程，之后主机将拥有模板的所有实体。 嵌套(nesting)：嵌套是一种包含一个或多个其它模板的模板方式。可以在一个嵌套模板中奖一些模板链接在一起。 嵌套的好处在于，您只需要讲一个模板链接到主机，并且主机会自动继承链接的模板的所有实体。 事件通知(notifications upon events)当配置了一些项目和触发器，并且由于触发器改变状态，现在正在发生一些事件，之后就要考虑 action。发送通知是zabbix提供的主要操作之一。 为了能够发送和接收通知，必须： 定义一些media； 配置action，向指定的media发送消息。 action由condition和operation组成。当条件满足是，执行操作。操作主要是 发送消息和执行远程命令。 media类型媒体是zabbix中发送通知和警报的传送通道。 E-mail: 在 管理-媒体类型 下，配置Email。 SMS： zabbix支持使用连接到zabbix-server的串行端口的串行GSM调制解调器发送SMS消息。 确保： 串行设备的速度(在Linux下通常为/dev/ttyS0) 与 GSM调制解调器的速度相匹配。zabbix没有设置串行链路的速度，它使用默认设置。 zabbix用户对串行设备有读写访问权限。 GSM调制解调器输入PIN码，并在电源复位后保留PIN码。或者在SIM卡上禁用PIN。 管理-媒体类型下要为用户分配电话号码：管理-用户-报警媒介，添加报警媒介(如电话号码等) Jabber： zabbix支持发送jabber消息。 Ez Texting： 可以使用 zabbix技术合作伙伴 Ez Texting发送信息。 脚本： 警报脚本在zabbix服务器上执行，这些脚本位于服务器配置文件中定义的目录中(AlertScriptsPath)。123456789101112131415161718cat /etc/zabbix/zabbix_server.confAlertScriptsPath=/usr/lib/zabbix/alertscripts#创建报警脚本vim /usr/lib/zabbix/alertscripts/zabbix_test.sh#!/bin/bashto=$1subject=$2body=$3#可以同时给多个用户发送，用空格隔开cat &lt;&lt;EOF | mail -s &quot;$subject&quot; &quot;to&quot;$bodyEOF 然后我们在创建脚本媒体的时候，写入相关参数。 actions可以根据所有支持的类型的时间定义操作： 触发事件：当trigger的状态从OK转到Problem或回转时； 发现事件； 自动注册事件； 内部事件； 配置-动作-创建动作 条件(condition)只有在事件与定义的条件匹配的情况下才执行操作。 注意运算类型：似与非似 操作(operation)操作：发送信息，执行远程命令。 发送消息远程命令(不支持在zabbix-agent上执行远程命令，需要在zabbix-server到代理的命令才能直接连接。远程命令限制255字符，可以将过个命令放置于新行上来执行过个命令。及时目标主机处于维护状态，也会执行远程命令). 配置-动作-操作，在操作细节中修改操作类型为远程命令。 在Zabbix代理（自定义脚本）上执行的那些远程命令必须首先在相应的命令中启用 zabbix_agentd.conf.确保 EnableRemoteCommands 参数设置为 1 并取消注释。 如果更改此参数，请重新启动代理守护程序。 123456789101112vim /etc/zabbix/zabbix_agentd.confEnableRemoteCommands=1cd /usr/lib/zabbix/alertscripts#或修改zabbix-server.conf中的文件位置vi sendmail.shchown zabbix.zabbix ./sendmail.sh &amp;&amp; chmod a+x ./sendmail.sh 接下来在动作中选择为执行远程命令，并在相应位置输入命令。 支持自定义脚本、SSH、Telnet等方式。 在信息中使用宏(using macros in messages)：在消息主题和消息文本中，可使用宏来更有效的问题报告。 恢复操作(recovery operation):恢复操作允许在问题解决时通知我们。恢复操作支持消息和远程命令。 宏(macros)官方支持的宏的完整列表：https://www.zabbix.com/documentation/3.4/manual/appendix/macros/supported_by_location zabbix支持许多在多种情况下使用的宏。宏是一个变量，由如下特殊语法标识。 宏类似于全局变量，宏是特别有用的，特别是在报警动作中。对于不同的细节加上特定的宏，能够使报警信息更加详细。 {MACRO} 根据在上下文汇总，宏解析为一个特殊的值。有效地使用宏可以节省时间，并使zabbix更加高效。 宏可以在监控项键值参数中使用。宏只能用在监控项键值参数的一部分中。如item.key[server_{HOST.HOST}_local] 。 宏函数(macro function)宏函数能提供自定义宏值的功能。 宏函数语法：12345678&#123;&lt;macro&gt;.&lt;func&gt;(&lt;params&gt;)&#125;#&lt;macro&gt;, 要定义的宏#&lt;func&gt;, 要应用的函数#&lt;params&gt;, 以逗号分隔的函数参数列表#栗子&#123;&#123;ITEM.VALUE&#125;.regsub&#123;pattern, output&#125;&#125; 用户宏(user macro)除了支持开箱即用的宏之外，zabbix还支持更灵活的用户宏。 用户宏可在全局、模板和主机级别进行定义。有一个特殊语法：1&#123;$MACRO&#125; 用户宏可用于： 监控项名称； 监控项键值参数； 触发器名称和描述； 触发器表达式参数和常量； 许多其他位置。 自动发现宏(LLD)有一种自动发现(LLD)函数中使用的宏类型，可用于创建监控项、触发器和图形原型。然后，当发现真实的文件系统、网络接口等，这些宏将替换为真实的值，并且以这些值来创建真实的监控项、触发器和图形。1&#123;#MACRO&#125; 用户和用户组(user and group)zabbix中所有用户都通过web前端去访问zabbix应用程序。并为每一个用户分配唯一的登录名和密码，被加密储存于zabbix数据库中。 配置用户(configuring user)管理-用户，创建和管理用户。 权限(permission)可定义相应的用户类型，如用户，管理员和超级管理员。 用户组(groups)管理-用户组，创建和配置用户组。 服务监控(service monitoring)服务监控，旨在帮助那些想要高级业务监控的人。在很多情况下，我们关注的不是底层细节，而是提供的可用性服务。 服务是分层表示监控数据。 IT Workstations workstation1workstation2 Services 配置-服务，最高节点的服务是’root’。你可以通过添加低级服务节点和各个节点服务创建下层层次结构。 Web监控(web monitoring)配置-主机-web监测，创建或修改web监测信息。可使用zabbix检查几个网站可用性方面。(zabbix中包含libcurl库才行) 要使用web监控，需要定义web场景。包括一个或多个HTTP请求或步骤。Zabbix-Server根据预定义的命令周期性的执行这些步骤。 Web监测中的要求的字段(required string)支持正则表达式，所以这对于检索页面信息很有用。这个真的很有用！ 所有web场景会收集下列数据： 整个场景中所有步骤的平均下载速度； 失败的步骤数量； 最后一次错误信息 web场景的所有步骤，都会收集下列数据： 平均下载速度； 响应时间 HTTP状态吗 Web监控项(web monitoring items)在创建web场景时，会自动添加一些新监控项进行监控。 创建场景后，zabbix会自动添加以下监控项进行监控，将它们链接到所选的应用程序。 场景的下载速度； 场景的失败步骤； 场景的最后一个错误消息； 举个栗子：1234567891011121314151617181920212223242526272829303132333435363738394041##创建Web监测#配置-主机-Web监测-创建web监测URL：web.zabbix.me/monitor.php要求的状态码：200超时：20s##创建web监测触发器#配置-主机-触发器-创建触发器严重性：一般严重#触发条件：状态码!=200表达式：N&lt;&gt;200##创建触发报警对应的动作#配置-动作-创建动作#触发条件触发器示警度=一般严重 or 触发器=web.zabbix.me#操作：发送Email发送给zabbix administrator用户群组仅送到Email默认信息/自定义信息##在媒体类型中定义Email相关信息#管理-报警媒体类型-EmailSMTP服务器：smtp.xxx.comsmtp端口：465SMTP电邮：发件人Email安全链接：SSL/TLS认证：Usernameand passwd用户名：xxx密码： xxx##接下来就可以测试接收报警Email了 虚拟机监控(VM monitoring)zabbix支持对VMware的监控，使用low-levle-discovery(LLD)自动发现VMware hypervisors和虚拟机，并根据事先定义的主机原型，为这些虚拟机建立主机，添加监控。 zabbix中提供了几个模板，可以直接用来解控VMware vCenter 或 ESX hypervisor。 虚拟机监控分为两个步骤： 首先，zabbix是通过VMware collector进程来监控虚拟机。这些进程通过SOAP协议从VMware服务获取必要的信息，对其进行预处理并储存到zabbix-server共享内存中； 然后，zabbix-pollers通过zabbix简单检查VMware keys来检索这些数据。 要使虚拟机监控正常工作，需要libxml2库和libcurl库的支持。 配置-自动发现-创建自动发现配置-主机-自动发现 维护(maintenance)可在zabbix中为主机和主机组定义维护周期。有两种维护类型：“继续对目标进行监控数据的收集” 和 “停止对目标进行监控数据的收集” 要在维护期间正常接收问题通知，必须在动作配置中的选项中取消选择暂停操作。为了确保定期维护按照预期的时间进行，需要对zabbix的所有部分使用通用时区。 配置-维护-创建维护期 维护期的主机显示的是橙色背景！ 事件确认(event acknowledgment)zabbix中的问题事件可以由用户确认。 如果用户获得了有关问题时间的通知，可以访问zabbix前端，从时间导航到确认屏幕并确认问题。当他们确认时，可输入评论或其他一些相关描述。这样其他系统用户同样的问题，他们便会立即看到是否已被解决和目前的评论。 以这种方式，可以更协调的进行解决多个系统用户的问题的工作流程。 要确认事件，用户必须至少要有对相应触发器的读取权限。 在Dashboard下，在出现的问题里，点击确认，进入确认事件。也可在监控-问题下查看问题详细信息。 配置导出/导入(Configuration export/import)zabbix导入/导出功能，使得可以在一个zabbix系统与另一个zabbix系统之间交换各种配置实体。类似于数据库的导入导出。即也可以对zabbix做备份。 可导出/导入的对象有：主机组； 模板； 主机； 拓扑； 图片； 聚合图形； 值映射。 数据也可导出： XML - 在前端 XML or JSON - 在zabbix API 导出的详细信息： 所有支持的元素都导出到一个文件中； 不导出从连链接模板继承的主机和模板实体； 由低级别发现创建的实体依赖于他们的任何实体不会导出。 导入详细信息： 第一次遇到错误停止导入； 导入支持XML和JSON文件； 使用“删除缺失”选项导入主机/模板时，导入的XML文件中不存在主机/模板宏也将被删除。 将Zabbix展现在Nginx上毕竟现在Nginx用的多，那就把Apache换成Nginx吧！ Nginx仓库:http://nginx.org/packages/ 自己安装Nginx: 下载nginx-release-xx.rmp仓库源来安装； 手动创建/etc/yum.repo.d/nginx.repo； 直接下载ngix.rpm来安装； 直接下载源码来安装。 相较于Apache，Nginx也只是配置个server就行了。优化什么的自己弄。12345678910111213141516171819202122232425262728293031vim /etc/nginx/conf.d/zabbix.confserver &#123; listen 80; server_name zabbix.me; root /usr/share/zabbix; access_log /var/log/nginx/zabbix.access.log main; allow 127.0.0.1; allow Your-IP; deny all; location / &#123; if (!-f $request_filename) &#123; rewrite ^([^\?]+)$ /index.php?1=$1 last; &#125; &#125; location ~ \.php$ &#123; root /usr/share/zabbix; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; &#125;&#125;nginx -tsystemctl start nginx 下载就可以正常访问zabbix-web端了! Zabbix监控Zabbix自带的templates基本涵盖了大部分监控信息。 大部分操作系统： OS Linux; OS AIx; OS FreeBSD; OS Solaris; OS Windows; … 大部分服务： CPU; Filesystems; HTTP/HTTPS service; Memory; Network interfaces; Processes; Secutity; Zabbix server/agent/Proxy; SMTP,POP,SSH,NTP, service; ICMP Ping; SNMP; … 虚拟机： VM VMware; VM WMware Hypervisor; … 网络设备： Cisco; Huawei; TPLink; HP; … 除了Zabbix自带的templates，你还可以下载templates并导入zabbix-server。 例如PHP-FPM, MongoDB, Apache, Nginx, Redis等额外软件的监控就需要下载额外templates。 监控MySQL使用Zabbix自带模板监控MySQLZabbix默认带有MySQL的监控和模板，所以无需再去下载。不过需要配置用户，密码，主机，端口等信息。 123456789101112131415161718192021222324vim /etc/zabbix/zabbix-agentd.d/userparameter_mysql.conf#For all the following commands HOME should be set to the directory that has .my.cnf file with password information.#这句话叫我们新建一个带有mysql密码信息的.my.cnf文件#并把此配置文件里面的HOME改为.my.cnf所的在目录#.my.cnf文件里面的用户要对MySQL数据库有权限才行，没有权限请记得加[mysql]host=localhostuser=zabbixpassword=zabiixsocket=/var/lib/mysql/mysql.sock[mysqladmin]host=localhostuser=rootpassword=passwordsocket=/var/lib/mysql/mysql.sock#测试zabbix_get -s 127.0.0.1 -k mysql.ping#1 使用Percona插件监控MySQLZabbix默认带有MySQL的监控和模板，所以无需再去下载。不过需要配置用户，密码，主机，端口等信息。但是Zabbix自带的MySQL监控太简陋了。所以使用Percona提供的模板及监控。 Percona Monitoring Plugins-URL: https://www.percona.com/downloads/percona-monitoring-plugins/LATEST/Percona Monitoring Plugins for Zabbix- Instructions: https://www.percona.com/doc/percona-monitoring-plugins/LATEST/zabbix/index.html 此插件地址需要我们选择Percona-Version和Software平台。 选择平台后，我们只需安装zabbix的rpm包就好： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#安装rpm包yum install -y https://www.percona.com/downloads/percona-monitoring-plugins/percona-monitoring-plugins-1.1.7/binary/redhat/7/x86_64/percona-zabbix-templates-1.1.7-2.noarch.rpm#安装软件#注意php版本问题yum install -y percona-zabbix-templatesls /var/lib/zabbix/percona#scripts目录有.sh脚本文件#templates目录有配置文件和模板文件#复制配置文件cp /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf /etc/zabbix/zabbix_agentd.d/#我看了一下，这个配置文件和zabbix自带的MySQL配置文件一样#添加MySQL的相关信息vim /var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php$mysql_user = 'root';$mysql_pass = 'password';$mysql_port = 3306;$mysql_socket = '/var/lib/mysql/mysql.sock';$mysql_flags = 0;#测试脚本/var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh gg#10#创建.my.cnf文件vim /etc/zabbix/zabbix_agentd.d/.my.cnf[mysql]host=localhostuser=rootpassword=passwordsocket=/var/lib/mysql/mysql.sock[mysqladmin]host=localhostuser=rootpassword=passwordsocket=/var/lib/mysql/mysql.sock[client]host=localhostuser=rootpassword=passwordsocker=/var/lib/mysql/mysql.sock#重启服务systemctl restart zabbix-agent#测试sudo -u zabbix -H /var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh running-slave#0/1 导入模板，模板文件位于：/var/lib/zabbix/percona/templates/zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.7.xml 但我直接导入模板时报错——标签无效 “/zabbix_export/date”: “YYYY-MM-DDThh:mm:ssZ” 预计。此模板需要先导入Zabbix2.4后再导出，然后再导入到Zabbix3.4。太麻烦。 所以需要下载修改过的模板： http://jaminzhang.github.io/soft-conf/Zabbix/zbx_percona_mysql_template.xml 1wget http://jaminzhang.github.io/soft-conf/Zabbix/zbx_percona_mysql_template.xml 下载之后导入模板，然后链接主机。链接之后可以部分监控可能显示不支持的。 如：Received value [rm: 无法删除”/tmp/localhost-mysql_cacti_stats.txt”: 不允许的操作0] is not suitable for value type [Numeric (float)]没有权限。 解决办法： 1234cd /tmpchown -R zabbix:zabbix localhost-mysql_cacti_stats.txtsystemcet restart zabbix-agent 监控MongoDB感谢大神： MongoDB-templates: https://share.zabbix.com/databases/mongodb/mongodb-for-zabbix-3-2 ; GitHub: https://github.com/oscm/zabbix/tree/master/mongodb 此github-repo中还包含了Oracle, php-fpm, postfix, redis, Nginx。可参看README.md来配置zabbix对它们的监控。 安装步骤1. 在zabbix-agent安装jqjq - Command-line JSON processor; 1yum install -y jq 2. 在zabbix-agent的MongoDB中创建用于监控的账号创建用于读取MongoDB相关信息的账户及其权限。 12345678910111213mongo&gt;use admin&gt;db.createUser( &#123; user:'zabbix', pwd:'zabbix', roles:[&#123; role:'clusterMonitor', db:'admin'&#125;] &#125;) 3. 在agent下载github仓库的MongoDB模板等文件 12345678910111213wget https://codeload.github.com/oscm/zabbix/zip/master -O master.zip#这里面不仅仅有mongodb，还有redis,php等。#我们只需要进入mongodb目录就好unzip master.zipcd ./zabbix-master/mongodbls#mongodb.sh , 执行脚本#userparameter_mongodb.conf ，配置脚本#zbx_export_templates.xml，zabbix模板文件 4. 移动并配置mongodb.sh 123456789101112cp ./mongodb.sh /etc/zabbixchmod a+x /etc/zabbix/mongodb.shvi mongodb.sh#如果HOST,PORT不是默认，请修改DB_HOST=127.0.0.1DB_PORT=27017DB_USERNAME=zabbixDB_PASSWORD=zabbix 5. 移动并修改userparameter_mongodb.conf 1234567cp ./zabbix-master/userparameter_mongodb.conf /etc/zabbix/zabbix_agentd.dvi ./userparameter_mongodb.confUserParameter=mongodb.status[*],/etc/zabbix/mongodb.sh $1 $2 $3 $4 $5#修改为mongdb.sh真实位置#这个是用户自定义的参数，可以之间写入到zabbix_agent.conf里面 6. 重启zabbix-agent 1systemctl restart zabbix-agent 7. 在zabbix-web导入mongodb模板 配置-模板-导入模板； 选择./master/mongodb/zbx_export_templates.xml模板文件，并导入； 接下来便可以在 templates中看到”Template App MongoDB”这个模板； 可将此模板链接到某个主机上监控，并到最新数据里查看相关MongoDB信息； 如果相对此模板就行修改，可编辑zbx_export_templates.xml文件。 监控一台主机上的额外mongod实例由于可能一台主机上运行的mongod实例不止一个，所以我们需要修改一下前面下载的配置文件，用以监控其它端口的mongod实例。 此处假设默认的mongod实例运行在27017端口上 另外还有一个mongod实例运行在27018端口上 此处假设我们已经完成了前面对27017mongodb的监控了 操作： 12345678910111213141516171819202122232425262728cd /etc/zabbixcp mongodb.sh mongodb_27018.shvim ./mongodb_27018.sh#配置监控的mongodb账号和端口DB_HOST=127.0.0.1DB_PORT=27018DB_USERNAME=zabbixDB_PASSWORD=zabbix#现在就有了提取27017/27018两个mongodb实例的脚本#mongodb.sh#mongodb_27018.shcd ./zabbxi-agentd.dvim userparameter_mongodb.conf#在默认的27017下面添加一行提取mongodb_27018信息的脚本UserParameter=mongodb.status[*],/etc/zabbix/mongodb.sh $1 $2 $3 $4 $5UserParameter=mongodb_27018.status[*],/etc/zabbix/mongodb_27018.sh $1 $2 $3 $4 $5#现在zabbix-server端就可以同时获取27017/27018两个mongodb实例的信息#但是Web界面还不能直接显示出来，因为27018的键值和默认不相同#没错，就是上面我们修改的 mongodb_27018.status[*] 接下来要在Zabbix-Web端配置监控项用以提取信息 我们先找到一个默认的MongoDB自带的配置模板，如MongoDB Connections current，点进去查看它的键值对为mongodb.status[connections,current] 因此我们只需要修改为我们配置文件里面的mongodb_27018.status[*]就可以了。 其余个监控项以此类推，我觉得其他服务也应该可以如此。 你也可以对此建立一个单独的模板，如MongoDB_27108 templates。在此监控模板下创建上面的监控项。这样就可以对所有主机生效了。也可以批量化操作，更方便一些。 下面是我的参考Template App MongoDB模板建立的Template App MongoDB_27018 监控PHP-FPM同样使用上面大神的模板。 步骤和监控MongoDB类似： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687#进入下载的文件目录cd ./zabbix-master/php-fpmcp ./php-fpm.xml.sh /etc/zabbixchmod a+x /etc/zabbix/php-fpm.xml.shvim /etc/zabbix/php-fpm.xml.sh#如果这三个参数修改了，请修改#因为是使用culr，所以请允许此IP能够访问此页面#另外还要Nginx允许Server-IP访问哦，不然无法读取数据#我测试的时候用IP无法获取数据，所以用的域名#如果没做域名解析，请加本地hosts#php-fpm_status使用我修改的HOST="localhost"PORT="80"#status="status"status="php-fpm_status"cp ./userparameter_php-fpm.conf /etc/zabbix/zabbix_agent.d/#当然也可以把这个用户自定义参数写入zabbix_agent.conf#修改自定义参数里面的文件位置vim /etc/zabbix/zabbix_agent.d/userparameter_php-fpm.confUserParameter=php-fpm.status[*],/etc/zabbix/php-fpm.xml.sh $1#php-fpm，nginx的状态必须用Nginx展现，Zabbix-Server是使用curl提取状态页面的信息vim /etc/nginx/conf.d/zabbix.confserver &#123; listen 80; server_name zabbix.me localhost;#如果localhost与其他配置文件冲突，那就用IP#server_name zabbix.me 127.0.0.1 Private-IP Public-IP; root /usr/share/zabbix; access_log /var/log/nginx/zabbix.access.log main;#allow无法使用localhost，所有内外网要分开写 allow 127.0.0.1; allow Private-IP; allow Public-IP; allow Zabbix-Server-IP; allow Remote-View-IP; deny all; location / &#123; if (!-f $request_filename) &#123; rewrite ^([^\?]+)$ /index.php?1=$1 last; &#125; &#125;#Nignx_Status location /nginx_status &#123; stub_status on; #开启nginx自带的状态检查功能 access_log off; &#125;#php-fpm_Status#php-fpm的默认状态页面是/status,/ping。我修改了一下。 location ~ ^/php-fpm_(status|ping)$ &#123; access_log off; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; &#125; location ~ \.php$ &#123; root /usr/share/zabbix; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; &#125;&#125; php-fpm状态页面的配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163vim /etc/php-fpm.d/www.conf#说明和用法如下，我做简单修改#修改默认值;pm.status_path = /statuspm.status_path = /php-fpm_status;ping.path = /pingping.path = /php-fpm_ping;ping.response = pongping.response = 200#用法zabbix.me/php-fpm_statuszabbix.me/php-fpm_ping#配置文件提供了格式化输出zabbix.me/php-fpm_status?htmlzabbix.me/php-fpm_status?html&amp;full; output syntax. Example:; http://www.foo.bar/status; http://www.foo.bar/status?json; http://www.foo.bar/status?html; http://www.foo.bar/status?xml; http://www.foo.bar/status?full; http://www.foo.bar/status?json&amp;full; http://www.foo.bar/status?html&amp;full; http://www.foo.bar/status?xml&amp;full#修改完毕后重启服务systemctl restart php-fpm nginx#具体看下面描述##这下面是说明; The URI to view the FPM status page. If this value is not set, no URI will be; recognized as a status page. It shows the following informations:; pool - the name of the pool;; process manager - static, dynamic or ondemand;; start time - the date and time FPM has started;; start since - number of seconds since FPM has started;; accepted conn - the number of request accepted by the pool;; listen queue - the number of request in the queue of pending; connections (see backlog in listen(2));; max listen queue - the maximum number of requests in the queue; of pending connections since FPM has started;; listen queue len - the size of the socket queue of pending connections;; idle processes - the number of idle processes;; active processes - the number of active processes;; total processes - the number of idle + active processes;; max active processes - the maximum number of active processes since FPM; has started;; max children reached - number of times, the process limit has been reached,; when pm tries to start more children (works only for; pm 'dynamic' and 'ondemand');; Value are updated in real time.; Example output:; pool: www; process manager: static; start time: 01/Jul/2011:17:53:49 +0200; start since: 62636; accepted conn: 190460; listen queue: 0; max listen queue: 1; listen queue len: 42; idle processes: 4; active processes: 11; total processes: 15; max active processes: 12; max children reached: 0;; By default the status page output is formatted as text/plain. Passing either; 'html', 'xml' or 'json' in the query string will return the corresponding; output syntax. Example:; http://www.foo.bar/status; http://www.foo.bar/status?json; http://www.foo.bar/status?html; http://www.foo.bar/status?xml;; By default the status page only outputs short status. Passing 'full' in the; query string will also return status for each pool process.; Example:; http://www.foo.bar/status?full; http://www.foo.bar/status?json&amp;full; http://www.foo.bar/status?html&amp;full; http://www.foo.bar/status?xml&amp;full; The Full status returns for each process:; pid - the PID of the process;; state - the state of the process (Idle, Running, ...);; start time - the date and time the process has started;; start since - the number of seconds since the process has started;; requests - the number of requests the process has served;; request duration - the duration in µs of the requests;; request method - the request method (GET, POST, ...);; request URI - the request URI with the query string;; content length - the content length of the request (only with POST);; user - the user (PHP_AUTH_USER) (or '-' if not set);; script - the main script called (or '-' if not set);; last request cpu - the %cpu the last request consumed; it's always 0 if the process is not in Idle state; because CPU calculation is done when the request; processing has terminated;; last request memory - the max amount of memory the last request consumed; it's always 0 if the process is not in Idle state; because memory calculation is done when the request; processing has terminated;; If the process is in Idle state, then informations are related to the; last request the process has served. Otherwise informations are related to; the current request being served.; Example output:; ************************; pid: 31330; state: Running; start time: 01/Jul/2011:17:53:49 +0200; start since: 63087; requests: 12808; request duration: 1250261; request method: GET; request URI: /test_mem.php?N=10000; content length: 0; user: -; script: /home/fat/web/docs/php/test_mem.php; last request cpu: 0.00; last request memory: 0;; Note: There is a real-time FPM status monitoring sample web page available; It's available in: @EXPANDED_DATADIR@/fpm/status.html;; Note: The value must start with a leading slash (/). The value can be; anything, but it may not be a good idea to use the .php extension or it; may conflict with a real PHP file.; Default Value: not set;pm.status_path = /statuspm.status_path = /php-fpm_status; The ping URI to call the monitoring page of FPM. If this value is not set, no; URI will be recognized as a ping page. This could be used to test from outside; that FPM is alive and responding, or to; - create a graph of FPM availability (rrd or such);; - remove a server from a group if it is not responding (load balancing);; - trigger alerts for the operating team (24/7).; Note: The value must start with a leading slash (/). The value can be; anything, but it may not be a good idea to use the .php extension or it; may conflict with a real PHP file.; Default Value: not set;ping.path = /pingping.path = /php-fpm_ping; This directive may be used to customize the response of a ping request. The; response is formatted as text/plain with a 200 response code.; Default Value: pong;ping.response = pongping.response = 200 效果图： 展现的话是在Agent端的Nginx上，这个更直观一些。而Zabbix-Server就是通过curl -s zabbix.me来获取数据的，并通过对数据的提取来返回给Zabbix-Server。所以收集php-fpm，nginx的信息状态，都是基于这个页面的。 现在导入PHP-FPM模板，导入操作同MongoDB。 12#就是这个文件zbx_export_templates.xml 导入模板后，直接链接模板就可以啦。然后就可以使用了。 监控NginxZabbix是通过stub_status模块实现对Nginx的监控。Nginx的ngx_http_stub_status_module模块提供了基本的Nginx状态信息，源码安装的话需要加上–with-http_stub_status_module编译参数，如果是epel源yum安装的话，已经默认启用该模块。 在Nginx配置文件中加入如下配置： 1234567891011121314location /nginx_status &#123; allow IP; deny all; stub_status on; access_log off;&#125;#栗子Active connections: 14server accepts handled requests 22889 22889 72510Reading: 0 Writing: 2 Waiting: 12 一些状态信息 Active connections当前active client的连接数，包括Wating accepts接受的客户端连接总数 handled已处理的连接总数。通常，handled与accepts相同，除非已达到了资源限制(如worker_connections限制) requests客户端请求总数 Reading当前nginx正在读取request header的连接数 Writing当前Nginx将reponse写回客户端的连接数 Waiting当前等待请求的空闲客户端的连接数 上面的结果还可通过命令来查看 1netstat -n | awk &apos;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a,S[a]&#125;&apos; 以上数据是通过Web端查看。但，我们需要把数据收集到Zabbix-Server。还需要使用之前下载同MongoDB，php-fpm一起的那个包。 操作，基本还是类似MongoDB，php-fpm。只是个别参数需要修改一下。 1234567891011121314151617181920cd ./zabbix-master/nginx/cp ./nginx.sh /etc/zabbix/chmod a+x /etc/zabbix/nginx.shcp ./userparameter_nginx.conf /etc/zabbix/zabbix_agentd.dvim /etc/zabbix/nginx.sh#HOST=&quot;localhost&quot;PORT=&quot;80&quot;#stub_status=stub_statusstub_status=nginx_statusvim /etc/zabbix/zabbix_agentd.d/userparameter_nginx.conf#修改成脚本对应的位置UserParameter=nginx.status[*],/etc/zabbix/nginx.sh $1 现在想以前一样导入模板。然后在链接模板就可以了。 监控Redis监控Redis，也是把包里面对应的文件复制过去就行。 123456789101112131415cd ./zabbix-master/rediscp ./userparameter_redis.conf /etc/zabbix/zabbix_agentd.d/#如果redis设置有密码，请加上密码#如果是不同的端口，请修改UserParameter=redis.local[*],redis-cli -h 127.0.0.1 -p 6379 info|grep $1|grep -v _human|cut -d : -f2#UserParameter=redis.local[*],redis-cli -h 127.0.0.1 -p 6379 -a Password info|grep $1|grep -v _human|cut -d : -f2UserParameter=redis.status[*],redis-cli -h $1 -p $2 -a Password info|grep $3|grep -v _human|cut -d : -f2UserParameter=redis.proc,pidof redis-server | wc -l#重启服务systemctl restart redis 导入模板，链接主机，OK。 系统监控 CPUCPU的性能状态信息： 简写 描述 说明 us user cpu tim 用户使用CPU时间 sy system cpu time 系统使用CPU时间 id idle cpu time CPU的空闲时间 wa io wait cpu time CPU等待IO时间 ni user nice cpu time 用nice调整进程优先级的CPU时间 st steal time 虚拟机偷取的CPU时间比，被强制等待虚拟CPU的时间 si softirq time 系统处理软件中断所花费的CPU时间 hi hard time 系统硬中断所花费的CPU时间 interrupt 中断 被处理过的中断数 cs Context switches 上下文切换 ql processor queue length 队列长度 processor load processor load 处理器负载，几核乘以几 Tips 当我们要监控并报警CPU使用率时，我们可以反过来用CPU空闲时间来定义 cpu idle tiem% + cpu usage time% = 1 (CPU usage time% gt 80%) == (CPU idel time% lt 20%) (CPU usage time% gt 90%) == (CPU idel time% &lt; 10%) 所以监控CPU使用率就可以监控CPU空闲时间，并依据这个报警 内存Zabbix中自带的Linux OS模板提供了Total memory和Available memory选项，这两者直接用模板就可以了。但没有提供内存使用率的选项，因此需要我们自定义。 内存使用率 = 可用内存 / 总内存 ast(vm.memory.size[available])/last(vm.memory.size[total]) 自定义内存使用率我们只需要在Linux OS模板下配置内存使用率，就可以一劳永逸。 配置(Configuration) 模板(Templates) OS Linux模板的监控项(Items) 创建监控项 监控项名称: Available memory percent 类型： 可计算的 键值： vm.memory.size[percent] 公式： 100*last(vm.memory.size[available])/last(vm.memory.size[total]) 记得将其加入Memory应用集，这样便于查找和管理 可加入单位： % 添加触发器 配置 模板 OS Linux模板 触发器 创建触发器，当可用内存率在三分钟内的平均值小于20%时报警 名字：Available memory percent lt 20% on {HOST.NAME} 严重性：一般严重 表达式： {Template OS Linux:vm.memory.size[percent].avg(3)}&lt;20 磁盘由于Zabbix-Server自带的Linux OS模板中的filesystem的监控是一个自动发现规则，而在应用集中的filesystem是没有监控项的。所有对于磁盘的监控和触发要在自动发现规则中去定义。 进程和端口Zabbix-Server自带有检测进程和端口的键值对。 检测进程数proc.num[&lt;name&gt;,&lt;user&gt;,&lt;state&gt;,&lt;cmdline&gt;] name: 进程名； user: 运行该进程的用户； state: run sleep zomb cmdline: ps -ef的最后那项，如/usr/bin/mongod -f /etc/mongod.conf 现在Zabbix-Server端测试： 1234567891011#zabbix-get --host hostname --key proc.num[&lt;name&gt;,&lt;user&gt;,&lt;state&gt;,&lt;cmdline&gt;]#检测mongd进程数量zabbix-get --host 192.168.1.11 --key proc.num[mongod,,,]#2，因为我开了两个mongd实例zabbix-get --host 192.168.1.11 --key proc.num[mongod,root,,]#1，只有一个是以root运行的，有一个是以mongod运行的 由于我们上面使用的MongoDB监控模板没有判断mongod进程存活与否的判断，此处我们在MongoDB模板中增加一个检查mongod进程的监控项，并创建对应的触发器。 端口net.tcp.listen[port] 检查 TCP 端口 是否处于侦听状态。返回 0 - 未侦听；1 - 正在侦听 此处我也用Mongod举例。我的两个mongod实例分别监听在27017,27018/tcp。 在Zabbix-Server端先测试： 123456#net.tcp.listen[port]zabbix-get --host 192.168.1.11 --key net.tcp.listen[27017]#1zabbix-get --host 192.168.1.11 --key net.tcp.listen[27018]#1 在Web端创建监控项和触发器与上面类似。 用户自定义参数(user parameter)我也是参考了上述大神的脚本，进行参考而来。 由于公司需要监控大量的Web页面和API接口的状态，并通过页面判断相关key-value的正确性，用以判断状态。此处可能由模拟登录等操作，Zabbix自带的Web监控不太够用，所以此处自定义用户参数来实现。 此处，我叫公司开发人员帮忙将全部接口以及Web页面内容都生成到一个json文件里，如 http://zhang21.cn/test.json。然后用jq命令解析json文件，里面key一一对应value，这样取值就很方便了。 jqjq 是一款命令行下处理 JSON 数据的工具。真的很好用！ jq官网：https://stedolan.github.io/jq/GitHub: https://github.com/stedolan/jq 安装jq 1yum install -y jq 使用jq 123456789101112131415161718192021222324252627282930313233jq --help#查看所有键键值curl --silent http://zhang21.cn/test.json | jq .###栗子&#123; "collapsectimes": 130, "collapsectimes": 0, "bootfailtimes": 23, "failrate": 0.3623, "bootrate": 0.3324, "time": "2018-01-25 15:03:30", "db_error": false&#125;#查看某个键值curl --silent http://zhang21.cn/test.json | jq '.time'curl --silent http://zhang21.cn/test.json | jq '.bootrate'###2018-01-25 15:03:300.3324#查看某个不存在的值，会返回nullcurl --silent http://zhang21.cn/test.json | jq '.zhang'###null json嵌套解析 1234cat test.json | jq '.location.city'###"Chengdu" json解析数组 1234cat test.json | jq '.array[1].name'###"Zhang" 内建函数 jq还有一些内建函数，如key,hss。 key用来获取json中的key元素： 123456789101112curl --silent http://zhang21.cn/test.json | jq 'keys'###[ collapsectimes, collapsectimes, bootfailtimes, failrate, bootrate, time, db_error] has用来判断是否存在某个key: 1234curl --silent http://zhang21.cn/test.json | jq 'has("time")'###true jq的select语句使用select函数来完成jq的过滤操作。jq的select语句太好了! select 接受一个条件表达式作为参数。其输入可以是迭代器，或者和 map 函数配合使用来处理数组。当输入中的某个元素使 select 参数中的条件表达式结果为真时，则在结果中保留该元素，否则不保留该元素。 对json文件的值是数组的，根据数据里面的key在取值，厉害厉害。 123456789101112131415161718192021222324252627cat zhang.json"array": [&#123; "ip": "192.168.1.11", "loads": 1234&#125;,&#123; "ip": "192.168.1.22", "loads": 567&#125;]####栗子cat /etc/zabbix/zhang.json | jq ".array[] | select(.ip == \"192.168.1.11\")"&#123; "ip": "192.168.1.11", "loads": 1234&#125;cat /etc/zabbix/zhang.json | jq ".array[] | select(.ip == \"192.168.1.11\").loads"1234我们在自定义用户参数的时候便可以将ip作为参数传入cat /etc/zabbix/zhang.json | jq ".array[] | select(.ip == \"$1\").loads" 编写自定义参数和脚本将脚本放置于/etc/zabbix，可将自定义参数写入zabbix-agentd.conf文件，也可单独写入/etc/zabbix/zabbix_agentd.d/(推荐)，这样修改更方便。 编写脚本文件123456789101112131415161718192021222324252627282930cd /etc/zabbixvim xbreport.sh########### Zabbix3.4# Zhang21# Thu Jan 25 15:20:44 CST 2018###########url="http://zhang21.cn/test.json"JQ=`which jq`CURL=`which curl`function XBREPORT() &#123; $CURL --silent $url | $JQ ".$1"&#125;if [ $# == 0 ]; then echo $"Usage $0 &#123;browsercollapsectimes|servercollapsectimes|xiaobaibootfailtimes|terminaldesktopfailrate|competebootrate|db_error&#125;" exitelse XBREPORT "$1"fi 编写自定义参数文件123456789101112cd /etc/zabbix/zabbix_agentd.dvim userparameter_XBreport.conf########### Zabbix3.4# Zhang21# Thu Jan 25 15:45:19 CST 2018##########UserParameter=XBreport[*],/etc/zabbix/xbreport.sh $1 测试自定义参数1234zabbix_get --host host --key XBreport[time]###"2018-01-25 17:03:18" 自定义用户参数额外由于我的json文件key对应的value中内嵌有数组，所以我需要再提取数组内的值。 12345678910111213141516171819curl http://zhang21.cn/test.json | jq &apos;.array&apos;###[ &#123; &quot;ip&quot;: &quot;1.1.1.1&quot;, &quot;loads&quot;: 1051 &#125;, &#123; &quot;ip&quot;: &quot;2.2.2.2&quot;, &quot;loads&quot;: 356 &#125;]#array[],array[1],array[2],array[n]#array[].ip, array[1].ip#array[].loads, array[2].loads 上面的数据中包含有zabbix无法解析的特殊符号，所以需要改变策略。 由于zabbix对UserParameter中包含\’”`*?[]{}~$?&amp;;()&lt;&gt;|#@这些特殊字符无法进行处理，此处有两种方法来解决。 在zabbix_agentd.conf中开启参数UnsafeUserParameters，将其值设置为1 或者，使用多个变量$1 $2 $3...来解决我这个数组值的问题 我是使用多个变量来解决我这个情况的。看下脚本。 1234567891011121314151617181920212223242526272829303132cd /etc/zabbixvim ./zhang.shurl=&apos;http://www.zhang21.cn/test.json&apos;JQ=`which jq`CURL=`which curl`function ZHANG() &#123; $CURL --silent $url | $JQ &quot;.$1&quot;&#125;if [ $# == 0 ]; then echo $&quot;Usage $0 &#123;aaa|bbb|ccc|...&#125;&quot; exitelif [ $# ==1 ]; then ZHANG &quot;$1&quot;elif [ $# == 2 ]; then ZHANG &quot;$1[$2]&quot;else ZHANG &quot;$1[$2].$3&quot;ficd /etc/zabbix/zabbix_agentd.d/userparameter_Zhang.confUserParameter=Zhangxx[*],/etc/zabbix/zhang.sh $1 $2 $3 测试： 123456systemctl restart zabbix-agentdzabbix_get --host host --key Zhangxx[array]zabbix_get --host host --key Zhangxx[array,0]zabbix_get --host host --key Zhangxx[array,0,loads]zabbix_get --host host --key Zhangxx[array,1,ip] 测试正确能取到值的话，在Web端设置相对应的监控项。注意自己定义的key不要写错了。 数组的key栗子： Zhangxx[array] Zhangxx[array,0]或Zhangxx[array,1] Zhangxx[array,0,ip], Zhangxx[array,0,loads] 在Web端添加监控项由于这个参数是我们自定义的，所以在填写监控项key的时候需要我们手动填写自己定义的参数。注意监控项的参数和信息类型。 这里我遇到一个问题，我自定义key的执行脚本在Web端报超时问题，无法取值。这是由于zabbix默认的脚本执行超时时间为3s，所以我们需要修改超时时间30s(最大值)。 12vim /etc/zabbix/zabbix_server.confvim /etc/zabbix/zabbix_agentd.conf 设置触发器和报警这个就根据你个人项目实际情况设置对于的触发器和报警。 短信报警腾讯短信服务由于公司使用的是腾讯企业邮箱，可以将邮箱直接与微信绑定，从而在微信中实时显示邮件消息，所以不用微信报警！ 此处使用的腾讯短信SMS服务： https://cloud.tencent.com/product/sms 短信文档： https://cloud.tencent.com/document/product/382/13445 API文档： https://cloud.tencent.com/document/product/382/13297 SDK文档： https://cloud.tencent.com/document/product/382/5804 Python SDK: https://cloud.tencent.com/document/product/382/11672 由于腾讯提供了程序SDK，所以我选择了linux自带的Python SDK。这里面有详细的Python使用方法，做一些小修改就可以使用了。 配置获取Python SDK获取Python SDK 申请SDK AppID和App Key申请SDK AppID以及APP Key。 申请完毕后，效果如下： 申请短信签名下发短信必须携带短信签名。短信签名需要上传公司证件进行认证，大概十分钟左右！ 效果如下： 申请短信模板下发短信内容必须经过审核。在此短信模板中，我们必须要定义相关变量{n}，其他都是不会变化的常量。此处我定义了五个变量，分别为了带入Zabbix中的宏： 问题名，{TRIGGER.NAME} 主机名，{HOST.NAME} 事件事件，{EVENT.TIME} 事件日期，{EVENT.DATE} URL，{TRIGGER.URL} SDK配置1234yum install -y eple-realseyum install -y python-pippip install qcloudsms Python代码配置腾讯文档：https://cloud.tencent.com/document/product/382/11672 由于我是向多人发送短信，所以做了小修改： 12345678910111213141516171819202122232425262728293031323334#zabbix-servercd /usr/lib/zabbis/alartscriptsvim sendSms.py#!/bin/python#coding: utf-8from qcloudsms_py import SmsSingleSenderfrom qcloudsms_py.httpclient import HTTPErrorimport sysappid = App IDappkey = App Keyphone_numbers = ["12345", "1234567"]#params = ["Problem", "Hostname", "Time", "Date","Url"]params = [sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4], sys.argv[5]]msender = SmsSingleSender(appid, appkey)for i in phone_numbers: try: result = msender.send_with_param(86, i, 短信内容模板ID, params) except HTTPError as e: print(e) except Exception as e: print(e) print(result) 要给sendSms.py加上可执行权限哈！chmod a+x ./sendSms.py。 sys.argv变量是一个字符串的列表。特别地，sys.argv包含了命令行参数 的列表，即使用命令行传递给你的程序的参数。使用Python的sys.argv[n]可以像shell一样将放在文件后的变量传入文件执行。此处对于在Zabbix-Web端将宏放在脚本后，作为变量传入，非常重要。 sys.argv[0]代表sendSms.py文件 sys.argv[1]才代表第一个参数。 Zabbix Web端配置配置-动作-创建动作-操作 注意事项： 建议针对触发器示警度最高就行短信报警，其它交给Email 操作类型，选择远程命令 目标列表，选择当前主机 类型，自定义脚本 执行在，这个一定是放在Zabbix-Server上来执行哈 命令，文件名SendSms.py后面接的宏一定要加上双引号(“”) 最后根据不同的内容，设置不同的报警机制。后台的脚本也修改为对应的名称，修改里面对应的手机号码。 首先根据不同报警设置不同的触发条件 运维组，SendSms_dev.py，修改运维对应的号码 开发组，SendSms_develop.py，修改对于的号码 其实这个发送短信，就是在执行远程命令。 你命令里是发送短信就发送短信，你命令里是发送邮件就发送邮件。这个还是挺不错的。 针对不同业务向不同人员报警有时候我们只需要关心我们自己那部分就可以了，没必要所有报警都发送给所有人，这样很不方便。 所以，我们可以根据业务相关，组别权限等，分别向不同的人报警不同的信息。 如下我的一个栗子图：]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git]]></title>
    <url>%2F2017%2F11%2F07%2FGit%2F</url>
    <content type="text"><![CDATA[参考： 廖雪峰Git教程 Git内部原理 Git内部原理-伯乐在线 介绍git(/ɡɪt/)是一个分布式版本控制软件,最初由林纳斯·托瓦兹（Linus Torvalds）创作，于2005年以GPL发布。Git是免费的。 林纳斯·托瓦兹自嘲地取了这个名字“git”，该词源自英国俚语，意思大约是“混账”。 集中式与分布式集中式版本控制系统，版本库是集中存放在中央服务器的，而干活的时候，用的都是自己的电脑，所以要先从中央服务器取得最新的版本，然后开始干活，干完活了，再把自己的活推送给中央服务器。集中式版本控制系统最大的毛病就是必须联网才能工作。常用集中式版本控制系统有：CVS、SVN。 分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。既然每个人电脑上都有一个完整的版本库，那多个人如何协作呢？比方说你在自己电脑上改了文件A，你的同事也在他的电脑上改了文件A，这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。常用分布式版本控制系统有：Git。 和集中式版本控制系统相比，分布式版本控制系统的安全性要高很多，因为每个人电脑里都有完整的版本库，某一个人的电脑坏掉了不要紧，随便从其他人那里复制一个就可以了。而集中式版本控制系统的中央服务器要是出了问题，所有人都没法干活了。 常用命令 几个专用名词: Workspace：工作区 Index/Stage：暂存区 Repository：仓库区（或本地仓库） Remote：远程仓库 常用命令： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186#配置#Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下#--global全局配置git config --global user.name "Username"git config --globla user.email "Email"#创建版本库#虽然在任意目录下都可创建git-repo，但还是建议在一个空目录下创建git-repomkdir gitest&amp;&amp;cd gitest#init, Create an empty Git repository or reinitialize an existing onegit init#生成了一个.git目录，这个目录是git用来追踪管理版本库的，不要随意修改此目录的内容echo "First Git test" &gt; README#增加/删除文件#所有的版本控制系统，只能跟踪文本文件的改动#把文件添加到暂存区#git add file#git add dir#当前目录#git add .git add README#删除#git rm file#改名#git move file#提交#把暂存区提交到仓库区#-m, 为本次提交的说明信息git commit -m "Update Readme"#为什么Git添加文件需要add, commit一共两步呢？#因为commit可以一次提交很多文件，所以你可以多次add不同的文件。git add file1 file2 file3git commit -m "add 3files"#分支#查看分支git branchgit branch -a# 新建一个分支，但依然停留在当前分支git branch [branch-name]# 新建一个分支，并切换到该分支git checkout -b [branch]# 新建一个分支，与指定的远程分支建立追踪关系git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区git checkout [branch-name]# 建立追踪关系，在现有分支与指定的远程分支之间git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支git merge [branch]# 删除分支git branch -d [branch-name]# 删除远程分支git push origin --delete [branch-name]git branch -dr [remote/branch]#标签git tag#远程同步# 下载远程仓库的所有变动git fetch [remote]# 显示所有远程仓库git remote -v# 显示某个远程仓库的信息git remote show [remote]# 增加一个新的远程仓库，并命名git remote add [shortname] [url]# 取回远程仓库的变化，并与本地分支合并git pull [remote] [branch]# 上传本地指定分支到远程仓库git push [remote] [branch]# 强行推送当前分支到远程仓库，即使有冲突git push [remote] --force# 推送所有分支到远程仓库git push [remote] --all#撤销# 恢复暂存区的指定文件到工作区git checkout [file]# 恢复某个commit的指定文件到暂存区和工作区git checkout [commit] [file]# 恢复暂存区的所有文件到工作区git checkout .# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变git reset [file]# 重置暂存区与工作区，与上一次commit保持一致git reset --hard# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变git reset [commit]# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致git reset --hard [commit]# 重置当前HEAD为指定commit，但保持暂存区和工作区不变git reset --keep [commit]# 新建一个commit，用来撤销指定commit# 后者的所有变化都将被前者抵消，并且应用到当前分支git revert [commit]# 暂时将未提交的变化移除，稍后再移入git stashgit stash pop#其它# 生成一个可供发布的压缩包$ git archive 内部原理Git 的内部工作原理和实现方式，学习这些内容对于理解 Git 的用处和强大功能是非常重要的。首先要弄明白一点，从根本上来讲 Git 是一套内容寻址(content-addressable) 文件系统——它是一个相当酷的东西，在此之上提供了一个 版本控制系统(VCS)用户界面。 底层命令和高层命令由于 Git 最初是一套面向版本控制系统的工具集，而不是一个完整的、用户友好的版本控制系统，所以它还包含了一部分用于完成底层工作的命令。 这些命令被设计成能以 UNIX 命令行的风格连接在一起，抑或藉由脚本调用，来完成工作。 这部分命令一般被称作底层命令（plumbing），而那些更友好的命令则被称作高层命令（porcelain）。 Git Repo下有一个.git目录，几乎所有 Git 存储和操作的内容都位于该目录下。如果你要备份或复制一个库，基本上将这一目录拷贝至其他地方就可以了。 .git内容: branches/ config: 包含项目特有的配置选项 description: 仅供 GitWeb 程序使用 HEAD： Git核心部分，指向当前分支 hooks/： 客户端或服务端钩子脚本 index： Git核心部分，保存了暂存区域信息 info/: 保存了一份不希望在.gitignore文件中管理的忽略模式的全局性排除文件 objects/： Git核心部分，存储所有数据内容 refs/： Git核心部分，存储指向数据 (分支) 的提交对象的指针 #可能还有其它文件 COMMIT_EDITMSG FETCH_HEAD logs/ ORIG_HEAD Git对象Git 是一套内容寻址文件系统。从内部来看，Git 是简单的 key-value 数据存储。它允许插入任意类型的内容，并会返回一个键值，通过该键值可以在任何时候再取出该内容。可以通过底层命令 hash-object 来示范这点，传一些数据给该命令，它会将数据保存在 .git 目录并返回表示这些数据的键值。Git 初始化了 objects 目录，同时在该目录下创建了 pack 和 info 子目录。 新建文件后，此目录中会出现新目录(目录内容为哈希值)。 1234567891011121314echo &amp;#039;test content&amp;#039; | git hash-object -w --stdind670460b4b4aece5915caf5c68d12f560a9fe3e4#也可以直接添加文件#git hash-object -w test.txtfind .git/objects -type f.git/objects/d6/70460b4b4aece5915caf5c68d12f560a9fe3e4#使用git cat-file取回对象内容git cat-file -p d670460b4b4aece5915caf5c68d12f560a9fe3e4test content 树对象tree object tree 对象可以存储文件名，同时也允许存储一组文件。Git 以一种类似 UNIX 文件系统但更简单的方式来存储内容。所有内容以 tree 或 blob 对象存储，其中 tree 对象对应于 UNIX 中的目录，blob 对象则大致对应于 inodes 或文件内容。 123456789101112131415git cat-file -p master^&#123;tree&#125;100644 blob a38f463bb1bdb05ce38cf7d9cfd4ed11286a708c README.md040000 tree f7cda840304ce5729444dd60904a0bbdf95fa0b5 test#master^&#123;tree&#125; 表示 branch 分支上最新提交指向的 tree 对象#请注意 test 子目录并非一个 blob 对象，而是一个指向别一个 tree 对象的指针git cat-file -p f7cda840304ce5729444dd60904a0bbdf95fa0b5040000 tree 02e9e8af4ae37db0fcd1943fdc832b27ad03ea03 2018#这才是两个blob对象git cat-file -p 02e9e8af4ae37db0fcd1943fdc832b27ad03ea03100644 blob 7066d2a8d6f8e3c6c44bdbf3a775c96cc9d0a3b9 2018-12-14.md100644 blob c0a915bf91f77db873a425058391e500c1504bae 2018-12-21.md 你可以自己创建 tree 。通常 Git 根据你的暂存区域或 index 来创建并写入一个 tree 。因此要创建一个 tree 对象的话首先要通过将一些文件暂存从而创建一个 index 。 123#指定了文件模式为 100644，表明这是一个普通文件git update-index --add --cacheinfo 100644 \83baae61804e65cc73a7201a7252750c76066a30 test.txt 提交对象commit object 1234567#创建commit 对象echo &amp;#039;first commit&amp;#039; | git commit-tree d8329ffdf4fc3344e67ab068f836878b6c4951e3b15f3d#查看git cat-file -p fdf4fc3 Git References引用(references, refs)，可在.git/refs下查看相关内容。 123#有三个目录ls .git/refsheads remotes tags HEAD当你执行 git branch &lt;branch-name&gt; 这条命令的时候，Git 怎么知道最后一次提交的散列值呢？答案就是 HEAD 文件。HEAD 文件是一个指向你当前所在分支的引用标识符。 12345678910111213141516171819#这就是上面.git/refs目录下cat .git/HEADref: refs/heads/testgit checkout mastercat .git/HEADref: refs/heads/master#你也可以设置它的值#但不能设置为refs以外的值，会报错git symbolic-ref HEAD refs/heads/testcat .git/HEADref: refs/heads/test TagsTag 对象指向一个 commit 而不是一个 tree。它就像是一个分支引用，但是不会变化——永远指向同一个 commit，仅仅是提供一个更加友好的名字。Tag 有两种类型：annotated 和 lightweight 。 Remotes如果你添加了一个 remote 然后推送代码过去，Git 会把你最后一次推送到这个 remote 的每个分支的值都记录在refs/remotes 目录下。 12345678910111213141516git logcommit 1deea62fa622d00db113abe136e9b22e1f3eac4cxxxxxxxxxcat .git/refs/heads/origin/master1deea62fa622d00db113abe136e9b22e1f3eac4c#切换分支git checkout testgit logcommit 3e1fcc1f8c035320d985b0202e18a6a00fe068c0cat .gt/refs/heads/origin/test3e1fcc1f8c035320d985b0202e18a6a00fe068c0 PackfilesGit 往磁盘保存对象时默认使用的格式叫松散对象 (loose object) 格式。Git 时不时地将这些对象打包至一个叫 packfile 的二进制文件以节省空间并提高效率。当仓库中有太多的松散对象，或是手工调用git gc 命令，或推送至远程服务器时，Git 都会这样做。Git 打包对象时，会查找命名及尺寸相近的文件，并只保存文件不同版本之间的差异内容。Git 自动定期对仓库进行重新打包以节省空间。当然也可以手工运行 git gc 命令来这么做。 1234567891011121314#举个栗子find .git/objects -type f.git/objects/01/55eb4229851634a0f03eb265b69f5a2d56f341 # tree 2.git/objects/1a/410efbd13591db07496601ebc7a059dd55cfe9 # commit 3.git/objects/1f/7a7a472abf3dd9643fd615f6da379c4acb3e3a # test.txt v2.git/objects/3c/4e9cd789d88d8d89c1073707c3585e41b0e614 # tree 3.git/objects/83/baae61804e65cc73a7201a7252750c76066a30 # test.txt v1.git/objects/95/85191f37f7b0fb9444f35a9bf50de191beadc2 # tag.git/objects/ca/c0cab538b970a37ea1e769cbbde608743bc96d # commit 2.git/objects/d6/70460b4b4aece5915caf5c68d12f560a9fe3e4 # &amp;#039;test content&amp;#039;.git/objects/d8/329fc1cc938780ffdd9f94e0d364e0ea74f579 # tree 1.git/objects/fa/49b077972391ad58037050f2a75f74e3671e92 # new.txt.git/objects/fd/f4fc3344e67ab068f836878b6c4951e3b15f3d # commit 1 Refspec1234#假设添加了一个远程Repogit remote add origin git@ github.com:schacon/simplegit-progit.git#之后可在.git/config中查看 缺省情况下 refspec 会被 git remote add 命令所自动生成， Git 会获取远端上 refs/heads/ 下面的所有引用，并将它写入到本地的 refs/remotes/origin/: 12345git log origin/mastergit log remotes/origin/mastergit log refs/remotes/origin/master#它们全是等价的，因为 Git 把它们都扩展成 refs/remotes/origin/master 如果你想让 Git 每次只拉取远程的 master 分支，而不是远程的所有分支，你可以把 fetch 这一行修改成这样： 123#默认#fetch = +refs/heads/*:refs/remotes/origin/*fetch = +refs/heads/master:refs/remotes/origin/master 你可以使用命名空间来达到这个目的。如你有一个QA组，他们推送一系列分支，你想每次获取 master 分支和QA组的所有分支，你可以使用这样的配置段落： 1234[remote &amp;quot;origin&amp;quot;] url = git@ github.com:schacon/simplegit-progit.git fetch = +refs/heads/master:refs/remotes/origin/master fetch = +refs/heads/qa/*:refs/remotes/origin/qa/* push Refspec 如果QA组成员想把他们的 master 分支推送到远程的 qa/master 分支上，可以这样运行： 1git push origin master:refs/heads/qa/master 删除 Refspec 以使用 refspec 来删除远程的引用，是通过运行这样的命令： 123#因为 refspec 的格式是 : #通过把 部分留空的方式，这个意思是是把远程的topic 分支变成空，也就是删除它git push origin :topic 传输协议Git 可以通过两种主要的方式在版本库之间传输数据：dumb Protocol 和 smart protocol Dumb protocolGit 基于HTTP之上传输通常被称为 dump protocol，这是因为它在服务端不需要有针对 Git 特有的代码。这个获取过程仅仅是一系列 GET 请求，客户端可以假定服务端的Git仓库中的布局。 12#栗子git clone http://github.com/schacon/simplegit-progit.git Smart protocoldump procotol 虽然很简单但效率略低，且它不能从客户端向服务端发送数据。智能协议是更常用的传送数据的方法，但它需要在服务端运行一个进程，而这也是 Git 的智能之处——它可以读取本地数据，理解客户端有什么和需要什么，并为它生成合适的包文件。 总共有两组进程用于传输数据，它们分别负责上传和下载数据。为了上传数据至远端， Git 使用 send-pack 和 receive-pack 进程。这个 send-pack 进程运行在客户端上，它连接至远端运行的 receive-pack 进程。当你在下载数据时， fetch-pack 和 upload-pack 进程就起作用了。客户端启动 fetch-pack 进程，连接至远端的 upload-pack 进程，以协商后续数据传输过程。 举例来说，在项目中使用命令 git push origin master 时, origin 是由基于 SSH 协议的 URL 所定义的。 Git 会运行 send-pack 进程，它会通过 SSH 连接你的服务器。 它会尝试通过 SSH 在服务端执行命令 维护和恢复有的时候，你需要对仓库进行清理 - 使它的结构变得更紧凑，或是对导入的仓库进行清理，或是恢复丢失的内容。 维护Git 会不定时地自动运行一个叫做 auto gc 的命令。 大多数时候，这个命令并不会产生效果。 然而，如果有太多松散对象（不在包文件中的对象）或者太多包文件，Git 会运行一个完整的 git gc 命令。这个命令通常并不会产生效果。 大约需要 7000 个以上的松散对象或超过 50 个的包文件才能让 Git 启动一次真正的 gc 命令。 你可以通过修改 gc.auto 与 gc.autopacklimit 的设置来改动这些数值。 12#栗子git gc --auto 数据恢复在你使用 Git 的时候，你可能会意外丢失一次提交。 通常这是因为你强制删除了正在工作的分支，但是最后却发现你还需要这个分支；亦或者硬重置了一个分支，放弃了你想要的提交。 如果这些事情已经发生，该如何找回你的提交呢？ 首先需要判断当前处于什么位置，然后恢复到之前某个位置。 12345678910111213141516171819202122232425262728293031#查看commitgit log --pretty=oneline3e1fcc1f8c035320d985b0202e18a6a00fe068c0 update 1.txta3f3bdd9cf22ce499d1b3cdff5bb26c94032a15d add 2.txtf4c90e173ef18e738f0287af71ae0878beec9316 add 1.txt748d8d3152b3a9a81068e29ae00fa797c2223520 add README#重置git reset --hard $&#123;commit-id&#125;#也可以使用git reflog1a410ef HEAD@&#123;0&#125;: reset: moving to 1a410efab1afef HEAD@&#123;1&#125;: commit: modified repo.rb a bit484a592 HEAD@&#123;2&#125;: commit: added repo.rb#查看loggit log -gcommit 1a410efbd13591db07496601ebc7a059dd55cfe9Reflog: HEAD@&#123;0&#125; (Scott Chacon &lt;schacon@gmail.com&gt;)Reflog message: updating HEADAuthor: Scott Chacon &lt;schacon@gmail.com&gt;Date: Fri May 22 18:22:37 2009 -0700 third commit 你可以通过创建一个新的分支指向这个提交来恢复它： 12345678910111213#748d8d3152b3a9a81068e29ae00fa797c2223520 add READMEgit branch test 748d8d3152b3a9a81068e29ae00fa797c2223520git checkout testlsREADME.md#删除分支git checkout mastergit branch -D test 移除对象Git 有许多过人之处，不过有一个功能有时却会带来问题：git clone 会将包含每一个文件的所有历史版本的整个项目下载下来。如果项目包含的仅仅是源代码的话这并没有什么坏处，毕竟 Git 可以非常高效地压缩此类数据。不过如果有人在某个时刻往项目中添加了一个非常大的文件，那们即便他在后来的提交中将此文件删掉了，所有的签出都会下载这个 大文件。因为历史记录中引用了这个文件，它会一直存在着。 警告：这个操作对提交历史的修改是破坏性的。 它会从你必须修改或移除一个大文件引用最早的树对象开始重写每一次提交。 如果你在导入仓库后，在任何人开始基于这些提交工作前执行这个操作，那么将不会有任何问题 - 否则，你必须通知所有的贡献者他们需要将他们的成果变基到你的新提交上。 1234567git rm bigfiles.tar.gzgit commit -m "remove big files"#查看清理了多少空间git gc#git count-objects -v 环境变量Git 总是在一个 bash shell 中运行，并借助一些 shell 环境变量来决定它的运行方式。 全局行为 GIT_EXEC_PATH: 决定 Git 到哪找它的子程序 PREFIX: 也类似，除了用于系统级别的配置 GIT_PAGER: 控制在命令行上显示多页输出的程序 GIT_EDITOR: 当用户需要编辑一些文本（比如提交信息）时， Git 会启动这个编辑器 版本库位置 GIT_DIR: 是 .git 目录的位置 GIT_CEILING_DIRECTORIES: 控制查找 .git 目录的行为 GIT_WORK_TREE: 是非空版本库的工作目录的根路径 如果没指定，就使用 $GIT_DIR 的父目录 GIT_INDEX_FILE: 是索引文件的路径 GIT_OBJECT_DIRECTORY: 用来指定 .git/objects 目录的位置 GIT_ALTERNATE_OBJECT_DIRECTORIES: 一个冒号分割的列表 (格式类似/dir/one:/dir/two:…) 用来告诉 Git 到哪里去找不在 GIT_OBJECT_DIRECTORY 目录中的对象. 如果你有很多项目有相同内容的大文件，这个可以用来避免存储过多备份。 路径规则 GIT_GLOB_PATHSPECS, GIT_NOGLOB_PATHSPECS: 控制通配符在路径规则中的默认行为 GIT_LITERAL_PATHSPECS: 禁用上面的两种行为；通配符将不能用，前缀覆盖也不能用 GIT_ICASE_PATHSPECS: 让所有的路径规格忽略大小写 提交 `GIT_AUTHOR_NAME: 是 “author” 字段的可读的名字 GIT_AUTHOR_EMAIL: 是 “author” 字段的邮件 GIT_AUTHOR_DATE: 是 “author” 字段的时间戳 GIT_COMMITTER_NAME: 是 “committer” 字段的可读的名字 GIT_COMMITTER_EMAIL: 是 “committer” 字段的邮件 GIT_COMMITTER_DATE: 是 “committer” 字段的时间戳 网络 GIT_SSL_NO_VERIFY: 告诉 Git 不用验证 SSL 证书。 这在有些时候是需要的， 例如你用一个自己签名的证书通过 HTTPS 来提供 Git 服务， 或者你正在搭建 Git 服务器，还没有安装完全的证书 GIT_HTTP_USER_AGENT: 设置 Git 在通过 HTTP 通讯时用到的 user-agent 比较与合并 GIT_DIFF_OPTS: 这个有点起错名字了 有效值仅支持 -u 或 –unified=，用来控制在 git diff 命令中显示的内容行数 GIT_EXTERNAL_DIFF: 用来覆盖 diff.external 配置的值。 如果设置了这个值， 当执行Gitgit diff 时，Git 会调用该程序 GIT_DIFF_PATH_COUNTER 和 GIT_DIFF_PATH_TOTAL: 对于 GIT_EXTERNAL_DIFF 或diff.external 指定的程序有用。 前者表示在一系列文件中哪个是被比较的（从 1 开始），后者表示每批文件的总数。 GIT_MERGE_VERBOSITY: 控制递归合并策略的输出。 允许的值有下面这些： 0: 什么都不输出，除了可能会有一个错误信息 1: 只显示冲突 2: 还显示文件改变(默认值) 3: 显示因为没有改变被跳过的文件 4: 显示处理的所有路径 5: 显示详细的调试信息 调试 GIT_TRACE: 控制常规跟踪，它并不适用于特殊情况。 它跟踪的范围包括别名的展开和其他子程序的委托 GIT_TRACE_PACK_ACCESS: 控制访问打包文件的跟踪信息 GIT_TRACE_PACKET: 打开网络操作包级别的跟踪信息 GIT_TRACE_PERFORMANCE: 控制性能数据的日志打印 GIT_TRACE_SETUP: 显示 Git 发现的关于版本库和交互环境的信息 其它 GIT_SSH GIT_ASKPASS GIT_NAMESPACE GIT_FLUSH GIT_REFLOG_ACTION fetch与pullGit中从远程的分支获取最新的版本到本地有两个命令: fetch: 当于是从远程获取最新版本到本地，不会自动merge pull: 相当于是从远程获取最新版本并merge到本地 几个概念： FETCH_HEAD: 是一个版本链接，记录在本地的一个文件中，指向着目前已经从远程仓库取下来的分支的末端版本 commit-id git fetch: 这将更新git remote中所有的远程仓库所包含分支的最新commit-id, 将其记录到.git/FETCH_HEAD文件中 git pull: 基于本地的FETCH_HEAD记录，比对本地的FETCH_HEAD记录与远程仓库的版本号，然后git fetch获得当前指向的远程分支的后续版本的数据，然后再利用git merge将其与本地的当前分支合并。 首先，你的每一个操作都是要指明来源和目标，对于pull来说，目标就是当前分支。其次，你得清楚git是有tracking的概念的，所谓tracking就是把来源和目标绑定在一起，节省一些操作是需要输入的参数。默认是在当前分支，平时养成好习惯，没谱的时候把来源和目标都带上。 12345678910111213141516171819202122232425262728293031323334#直接使用git fetch#创建并更新本 地远程分支git fetch#只是手动指定了要fetch的remote。在不指定分支时通常默认为master#git fetch origin [branch]git fetch origin#指定远程remote和FETCH_HEAD，并且只拉取该分支的提交git fetch origin dev#git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;#取回远程主机某个分支的更新，再与本地的指定分支合并。#当你在 master 下git pull#等于 fetch origin，然后 merge origin/master#当你在 develop 下git pull#等于 fetch origin，然后 merge origin/develop#多个分支#切换到devgit checkout dev#这会在当前分支合并testgit pull origin test 123456789101112#查看 .git/config[remote &quot;origin&quot;] url = git@xxx:xxx/xxx.git fetch = +refs/heads/*:refs/remotes/origin/*#它指明了 fetch 动作的来源#也就是说， git fetch 的操作就是取下上述目标的更新#但是——取下的东西到底在哪儿？#查看 .git/FETCH_HEAD 可以简单的这样理解： 123456789101112#fetch 从另外一个版本库下载对象和引用#pull 获取并合并另外的版本库或一个本地分支git pull = git fetch + merge to local#git fetch origin master#git merge FETCH_HEAD#如果搞不清楚，指明源和目标是最稳当的git pull [remote] [branch] 时光穿梭机12345678#查看repo当前状态git status#查看改变git diff 版本回退每当文件修改到一定程度的时候，就可以提交一次。这样即使误操作后，还可以从最近的commit中恢复，而不是把工作成果全部丢失。 123456789101112131415161718192021222324252627282930313233343536#查看提交记录#git的commit id是一个SHA1的16进制散列git log Update README.mdcommit e89d28373c19321466f99e15cd3cdcc5fffe868fAuthor: zhang21 &lt;elite_zhang21@163.com&gt;Date: Thu Apr 5 23:40:13 2018 +0800#版本回退，如果文件误删，可以从commit中恢复#查看提交记录，能看到Commit ID(sha1sum散列值)#在Git中，用HEAD表示当前版本，也就是最新的Commit ID#上一版本HEAD^, 上上版本HEAD^^, 倒数第十个版本HEAD~100#HEAD指的是当前版本#重置当前HEAD到指定状态git reset --hard HEAD^#也可以利用commit id回退git reset --hard $commit_id#查看历史命令git reflog#在本地回退之后，是无法push到远程的#必须强制pushgit push origin master --force 工作区和暂存区 git add实质是吧文件修改添加到暂存区 git commit实质是把暂存区的所有内容提交到当前分支 管理修改为什么git比其它版本控制系统设计的更优秀，因为它跟踪并管理的是修改，而非文件。如果修改后的文件没有使用git add放入暂存区的话，那么git commit也不会生效的。 撤销修改如果要纠正文件，可以手动修改文件并恢复到上一版本状态。但也可以使用git命令。 12345678910#丢弃工作区的修改#--很重要，没有--就变成了切换分支的命令git checkout -- filename#当你不但改乱了工作区某个文件的内容，还添加到了暂存区时。想丢弃修改，分两步。#第一步用命令git reset HEAD file，就回到了场景1，第二步git checkout --file。git reset HEAD file &amp;&amp; git checkout -- file 删除文件在git中，删除也是一个修改操作。 有两种情况： 误删除 真删除 12345678#rm，从工作区和索引中删除文件#如果一个文件已经被提交到版本库，那么你永远不用担心误删git rm README#误删某文件，需要恢复git checkout -- README 远程仓库用于验证推送，GitHub与本地仓库使用SSH加密传输，所以这需要创建一对密钥。 12345#生成SSH Keyssh-keygen -t rsa -C &quot;email-address&quot;#会生成.ssh目录，里面包含公私钥#将公钥id_ras.pub填入GitHub 添加远程仓库12345678910111213#origin是默认的远程仓库名，你可以修改git remote add origin git@xxx.com:username/xxx.git#推动本地仓库到远程#实际上是推动本地的master分支到远程#-u关联了本地master和远程mastergit push -u origin master#之后git push origin master 从远程库克隆1234567#将远程仓库克隆到本地#如果是多人协作开发，那么每个人各自从远程克隆一份就可以了#可以使用ssh协议或https协议(每次都要输入口令)git clone git@xxx.com:username/xxx.git#克隆指定分支git clone -b test URL 分支管理你可以创建一个自己的分支，别人看不到，还继续在原来的分支上正常工作。而你在自己的分支上干活，想提交就提交，而不会影响到其他人。 创建于合并分支HEAD严格来说不是指向提交，而是指向分支(如master)，分支才是指向提交。 当工作完成后，便可合并分支，然后删除额外的分支。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#查看分支#*代表当前工作分支git branch#创建分支git branch &lt;branch-name&gt;#切换分支git checkout &lt;branch-name&gt;#创建并切换分支，等于上面的创建和切换分支git checkout -b &lt;branch-name&gt;#在test分支下新建test.txtgit checkout testecho &apos;Just a test&apos; &gt; ./test.txtgit add test.txtgit commit -m &apos;Just a test branch&apos;#回到mastergit checkout master#此分支下并没有test.txt#也就是说并没有其它分支提交的内容#合并分支到当前分支git merge &lt;branch-name&gt;#合并test分支到当前的master分支git merge test#删除分支git branch -d &lt;branch-name&gt;#合并完成后删除test分支git brancd -d test 解决冲突合并分支玩玩也不是一帆风顺的！ 可能在你创建了新分支后，master分支又进行了提交，而你的新分支也做了提交，这是合并分支便会带了问题。当git分支无法合并时，就必须首先要解决冲突。解决冲突后，再提交和合并。 123#查看分支合并图git log --graph 分支管理策略 在实际开发中，master分支应该是非常稳定的。也就是只用来发布新版本，不能在上面干活 干活应在其它分支上(如dev)，干完后合并到master 工作人员都在dev上干活，每个人都有自己的分支，然后将自己的分支合并到dev就可以了 合并分支时，加上--no-ff参数就可以用普通模式合并，合并后的历史有分支，能看出来曾经做过合并，而fast forward合并就看不出来曾经做过合并。 Bug分支Git提供了一个stash功能，可以把工作现场储藏起来，等以后恢复现场后继续工作。 1234567891011121314151617181920git stash#创建debug分支git checkout -b &apos;issue-25&apos;git checkout mastergit merge --no-ff -m &quot;debug 25&quot; &apos;issue-25&apos;#切回工作区git stash listgit stash apply stash@xxx#手动删除stashgit stash drop#恢复同时也删除stashgit stash pop Feature分支添加一个新功能时，你肯定不希望因为一些实验性质的代码，把主分支搞乱了，所以，每添加一个新功能，最好新建一个feature分支，在上面开发，完成后，合并，最后，删除该feature分支。 丢弃一个没有被合并过得分支，可通过git branch -D &lt;branch-name&gt;强行删除。 多人协作123456789101112131415161718192021222324#查看远程仓库git remote#显示远程仓库详细信息git remote -v#推送指定分支git push origin test#抓取分支git clone#更新分支git pull#合并分支git merge#推送分支git push 版本库（Repository）隐藏目录.git是Git的版本库。Git版本库里面存放了很多东西，其中最重要的就是 stage(或index)的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。 用git add把文件添加进去，实际是把文件添加到暂存区； 用git commit提交更改，实际是把暂存区的所有内容提交到当前分支。默认git commit就是往master上提交更改。 SSHKey 创建SSHKey并在本地关联多个SSH 123#把你的github邮箱地址ssh-keygen -t rsa -C &quot;email@example.com&quot;#会生成 ~/.ssh，包含 私钥：id_rsa，公钥：id_rsa.pub 将公钥写入Github在Github–Account settings–SSH Keys–Add SSH Key里面，添加你的id_rsa.pub公钥文件。当然，你可以添加多个Key哦，毕竟可能你有多台登陆设备。这个就相当于SSH无密钥认证。 在主机上关联多个git 12345678910111213141516171819202122232425262728293031vim ~/.ssh/config#OneHost git.xxx.com IdentityFile ~/.ssh/id_rsa Hostname IP User git Port 10022#twoHost github IdentityFile ~/.ssh/id_rsa Hostname github.com User git Port 22#three#这样可用于ssh登录Host zhang21 Hostname ip User username Port 22 IdentityFile ~/.ssh/id_rsa#一定要记着修改权限chmoe 600 ~/.ssh/*#测试连接ssh -T git@github.com 标签管理发布一个新版本时，通常先在版本库中打一个标签(tag)，这样，就唯一确定了打标签时刻的版本。将来无论什么时候，取某个标签的版本，就是把那个打标签的时刻的历史版本取出来。所以，标签也是版本库的一个快照。 tag其实是指向 commit id的。git有commit，为什么还要引入tag? commit id 是一串散列值，并不简单明了。但是tag,我可以写为”v1.0”,”v1.2”…让tag，”v1.0”指向对应的commit id，很方便明了。 创建标签12345678910111213141516171819202122232425262728293031323334353637383940414243#切换到需要打tag的分支上git brach test#创建tag默认tag是打在最新提交的commit上#git tag &lt;tag-name&gt;git tag v1.0#查看所有taggit tag#指定tag对应的commit#git tag &lt;tag-name&gt; &lt;commit_id&gt;git tag v1.0 65432ba#标签不是按时间顺序列出的，而是按照字母排序git show $tag-namegit show v1.0#创建带有说明的标签#git tag -a &lt;tag-name&gt; -m &quot;v1.1 released&quot; &lt;commit-id&gt;git tag -a v1.1 -m &quot;V1.1&quot; 6543bb#查看标签说明git show &lt;tag-name&gt;#用私钥签名一个标签#依赖GPG#git tag -s &lt;tag-name&gt; -m &quot;pri-key&quot; &lt;commit-id&gt;git tag -s v1.2 -m &quot;pri-key v1.2&quot; 6543bc 操作标签1234567891011121314151617181920#删除标签#git tag -d &lt;tag-name&gt;git tag -d v1.2#推送某个标签到远程#git pust origin &lt;tag-name&gt;git push origin v1.0#推送全部标签git push origin --tags#删除远程标签git push origin :refs/tags/&lt;tag-name&gt; 忽略特殊文件创建一个.gitignore特殊文件，然后把要忽略的文件名填进去，Git就会自动忽略这些文件。 各种模板： https://github.com/github/gitignore 检查.gitignore文件: git check-ignore .gitignore 搭建Git服务器常见的Git服务器有： GitLab: https://gitlab.com/ Gogs（go git service）: https://gogs.io/]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Love at First Sight]]></title>
    <url>%2F2017%2F11%2F06%2FLove-at-First-Sight%2F</url>
    <content type="text"><![CDATA[——波兰诗人维斯拉瓦·辛波丝卡(Wislawa Szymborska) They’re both convincedthat a sudden passion joined them. Such certainty is beautiful,but uncertainty is more beautiful still. Since they’d never met before,they’re sure that there’d been nothing between them. But what’s the word from the streets, staircases, hallways –perhaps they’ve passed each other a million times? I want to ask themif they don’t remembera moment face to facein some revolving door?perhaps a “sorry” muttered in a crowd?a curt “wrong number” caught in the receiver?but I know the answer. No, they don’t rememberThey’d be amazed to hearthat Chance has been toying with themnow for years. Not quite ready yetto become their Destiny,it pushed them close, drove them apart,it barred their path, stifling a laugh,and then leaped aside. There were signs and signals,even if they couldn’t read them yet. Perhaps three years agoor just last Tuesdaya certain leaf flutteredfrom one shoulder to another? Something was dropped and then picked up.Who knows, maybe the ball that vanished into childhood’s thicket? There were doorknobs and doorbellswhere one touch had covered another beforehand. Suitcases checked and standing side by side.One night, perhaps, the same dream,grown hazy by morning. Every beginning is only a sequel,after all,and the book of eventsis always open halfway through.]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>Poetry</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Wireshark]]></title>
    <url>%2F2017%2F10%2F25%2FWireshark%2F</url>
    <content type="text"><![CDATA[过滤语法wireshark过滤分为两种: 抓包过滤 显示过滤 尽量避免使用抓包过滤。即便多看几个报文，也比漏掉一个报文要好。 抓包过滤类型 host net port 方向 src dst 协议 ether ip/arp tcp/udp http/dns/ftp/icmp … 逻辑运算符 &amp;&amp; || ! 栗子： 1234567891011121314151617181920212223242526272829303132333435#主机host www.xx.comsrc host 192.168.1.1 &amp;&amp; dst port 80host 193.168.1.1 || host 192.168.1.2#广播包!broadcast#MACether host 00:88:ab:56:12:0dsrc ether host 00:88:ab:56:12:0d#IPhost 192.168.1.1dst host 192.168.1.1#netnet 192.168.1.0/24src net 192.168.1.0/24#vlanvlan 11#Portport 80! port 443dst port 80udp dst port 5678portrange 1-80 显示过滤比较操作符 == != &gt; &lt; &gt;= &lt;= 逻辑操作符 and or xor not IP ip.addr ip.src ip.dst Port tcp.port tcp.srcport tcp.dstport tcp.flag.syn tcp.flag.ack Protocol arp ip icmp udp tcp dns … 栗子： 1234567891011121314#ipip.addr == 1.1.1.1ip.src == 1.1.1.1 and ip.dst == 2.2.2.2#porttcp.port == 80tcp.dstport == 80tcp.flag.syn == 1#proarpnot icmp HTTPSWireshark也可以分析HTTPS加密的包，但你需要用证书将包先解密。在Edit-&gt;Preferences-&gt;Protocol-&gt;SSL选项填写相关信息进行解密。]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Wireshark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell]]></title>
    <url>%2F2017%2F10%2F24%2FLinuxShell%2F</url>
    <content type="text"><![CDATA[参考： 《Linux Shell脚本攻略》 《鸟哥的Linux私房菜》 vim在Linux中使用文本编辑器来编辑你的Linux参数配置文件是一件很重要的事情，因此系统管理员至少应该熟悉一种文本编辑器。 在Linux中，绝大部分的配置文件都是以ASCII(键盘上可找到)的纯文本形式。因此利用简单的文本编辑器就能修改。 ASCII（发音：/ˈæski/ ass-kee[1]，American Standard Code for Information Interchange，美国信息交换标准代码）是基于拉丁字母的一套电脑编码系统。从[0000 0000 - 0111 1111]共128个字符。 vi文本编辑器 所有的Unix Like系统都会内置vi文本编辑器，其他的文本编辑器则不一定存在 很多软件的编辑接口都会主动调用vi(如 crontab等命令) vim是vi的高级版本 vim具有程序编辑的能力，可以主动以字体颜色辨别语法的正确性，方便程序设计 程序简单，编辑速度相当快速 vi中的tab键所得结果与空格符不一样 vi中，数字是很有意义的 数字通常代表重复做几次，或去到第几个的意思 vim保存、恢复与打开文件时的警告信息当我们使用vim时，vim会在当前目录下再创建一个名为filename.swp的暂存文件。 由于vim的工作被不正常中断，导致暂存盘无法通过正常流程来结束，所以暂存文件就不会消失。此时编辑文件就会出现某些异常情况。 可能有其他人或程序同时在编辑这个文件 在前一个vim的环境中，可能因为某些不明原因导致vim中断(crashed) vim的三种模式vim包括三种模式： 一般模式 编辑模式 命令行模式 一般模式 命令 说明 x 向后删除一个字符 X 向前删除一个字符 nx,nX 向前/后 删除n个字符 dd 删除当前行 D 删除当前行所有字符，使之成为空行 ndd 删除光标所在行的向下n行 d1G 删除光标所在行到第一行 dG 删除光标所在行到最后一行 yy 复制光标所在行 y1G 复制光标所在行到第一行 yG 复制光标所在行到最后一行 ynj 复制光标所在行和向下n行 dnj 删除光标所在行和向下n行 p 将复制的数据粘贴到光标下一行 P 将复制的数据粘贴到光标上一行 J 将光标所在行与下一行结合成一行 u undo,恢复前一个操作 ctrl+r 重做上一个操作 . 重复前一个操作 编辑模式 命令 说明 i 在当前光标所在处插入文字 I 在光标所在行第一个非空字符插入文字 a 在当前光标后插入文字 A 在当前光标所在行最后插入文字 o 在光标所在行的下一行行首插入字符 O 在光标所在行的上一行行首插入字符 r 替换光标所在那一个字符 R 一直替换光标所指的文字，直到退出 Esc 退出，回到一般模式 命令模式 命令 说明 h 方向左 j 方向下 k 方向上 l 方向右 + 光标移到下一行的第一个非空字符 - 光标移到当前行的第一个非空字符 0 光标移到当前行的第一个字符 $ 光标移到当前行的最后一个字符 n空格 光标在当前行向右移动n个字符 G 光标移到最后一行的第一个非空字符 gg 光标移到第一行的第一个非空字符，相当于1G nG 光标移到第n行的第一个非空字符 /word 在光标之后查找word字符串 ?word 在光标之前查找word字符串 n/N 重复前一个查找 :s/word1/word2 在光标当前行将word1替换成word2 :n1,n2s/word1/word2/g 在n1行-n2行间将word1替换成word2 %s/word1/word2/gc 全局将word1替换成word2，在替换前让用户确认(confirm) :w 保存到文件 :w file2 保存到file2文件 :r file3 从file3文件读取数据并写入 :wq/:x 保存并退出 :q 退出 :q! 强制退出 :!cmd 执行命令 :r!cmd 将执行命令写入 :set nu 显示行号 :set nonu 取消行号 :n1,n2w file4 将n1行-n2行的内容保存到file4文件 vim环境设置与记录因为vim会主动将你曾经的行为记录下来，好方便下次操作。这个文件是自动生成的。 ~/.vim.info ~/.vim.rc 整体vim设置 /etc/vimrc 此外，每个Distribution对vim的默认环境都不太相同。所以你可能需要设置成你自己的工作方式。 参数 说明 :set nu :set nonu 行号设定 :set hlsearch :set nohlsearch 高亮设定 :set autoindent :set noautoindent 自动缩排设定 :set backup 自动备份设定 :set ruler 状态栏设定 :set showmode 模式显示设定，如INSERT :set backspace=(012) 设定退格(backspace)值 :set all 显示所有环境参数 :set 显示与系统默认值不同的参数 :syntax on/off 程序语法显示 :set bg=dark/light 设定背景颜色 栗子： 123456789vim /root/.vimrc"这是注释"set nuset rulerset bg=darksyntax onset hlsearch vim注意事项 中文编码问题修改语系编码： LANG=zh_CN.utf-8 Linux与Dos的换行字符 Linux的换行(Enter)为LF符号($) Dos的换行(Enter)为CRLF符号(^M$) 不同系统之间复制纯文本文件可能会有问题，此时可以转换： unix2dos file newfile dos2unix file newfile 语系编码转换iconv - convert text from one character encoding to another 1234#iconv -f 源编码 -t 新编码 filename [-o newfile]#-o，转换到新文件iconf -f big4 -t utf8 old.big5 -o new.utf8 vim插件插件是一种扩展VIM功能的方法。VIM将插件分为： 全局插件(global)：无条件加载和操作 文件类型插件(filetype)：仅为特定文件类型加载和操作，参阅vim --&gt; :help filetype VIM默认会在特定位置查找插件： Linux/OS X： ~/.vim/plugin Windows： $HOME/vimfiles/plugin 文件类型插件为ftplugin 插件只是VIM脚本，因此你可以使用它们来定义函数、映射和命令，就像在.vimrc中一样。插件通常不仅仅是位于相应目录中的单个.vim文件。它们通常还包括自动加载脚本(:help autoload)，语法脚本(:help syntax)和缩进处理脚本。将这些脚本中的所有代码打包在一起，提供强大的钩子来增强VIM。 VIM內建的帮助(:help plugin)包含各种详细信息。有一些优秀资源: Learn Vimscript the Hard Way Writing Vim Plugins 可使用放在适当的目录的插件并启动VIM。当然，有些插件可能有比较复杂的安装过程(比如YouCompleteMe插件)。目前，像Pathogen和Vundle这样的插件管理器是手动安装插件文件的流行替代品，特别是因为插件通常带有多个文件。 vim插件管理器当没有插件管理器时，Vim 用户必须手动下载 tarball 包形式的插件，并将它们解压到 ~/.vim 目录中。在少量插件的时候可以。但当他们安装更多的插件时，就会变得一团糟。所有插件文件分散在单个目录中，用户无法找到哪个文件属于哪个插件。此外，他们无法找到他们应该删除哪个文件来卸载插件。这时 Vim 插件管理器就可以派上用场。插件管理器将安装插件的文件保存在单独的目录中，因此管理所有插件变得非常容易。 介绍几个常见的VIM插件管理器: Pathogen: https://github.com/tpope/vim-pathogen Vundle: https://github.com/VundleVim/Vundle.vim Plug: https://github.com/junegunn/vim-plug Vundle安装Vundle前请先安装vim和git。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384sudo yum install -y vim git# 下载Vundlegit clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim# 配置vundlevim ~/.vimrc#加入以下内容set nocompatible " requiredfiletype off " requiredset rtp+=~/.vim/bundle/Vundle.vimcall vundle#begin()Plugin 'gmarik/Vundle.vim'call vundle#end() " requiredfiletype plugin indent on " required" 设置包括vundle和初始化相关的runtime pathset rtp+=~/.vim/bundle/Vundle.vimcall vundle#begin()" 另一种选择, 指定一个vundle安装插件的路径"call vundle#begin('~/some/path/here')" 让vundle管理插件版本,必须Plugin 'VundleVim/Vundle.vim'" 以下范例用来支持不同格式的插件安装." 请将安装插件的命令放在vundle#begin和vundle#end之间." Github上的插件" 格式为 Plugin '用户名/插件仓库名'Plugin 'tpope/vim-fugitive'" 来自 http://vim-scripts.org/vim/scripts.html 的插件" Plugin '插件名称' 实际上是 Plugin 'vim-scripts/插件仓库名' 只是此处的用户名可以省略Plugin 'L9'" 由Git支持但不再github上的插件仓库 Plugin 'git clone 后面的地址'Plugin 'git://git.wincent.com/command-t.git'" 本地的Git仓库(例如自己的插件) Plugin 'file:///+本地插件仓库绝对路径'Plugin 'file:///home/gmarik/path/to/plugin'" 插件在仓库的子目录中." 正确指定路径用以设置runtimepath. 以下范例插件在sparkup/vim目录下Plugin 'rstacruz/sparkup', &#123;'rtp': 'vim/'&#125;" 安装L9，如果已经安装过这个插件，可利用以下格式避免命名冲突Plugin 'ascenator/L9', &#123;'name': 'newL9'&#125;" 你的所有插件需要在下面这行之前call vundle#end() " 必须filetype plugin indent on " 必须 加载vim自带和插件相应的语法和文件类型相关脚本" 忽视插件改变缩进,可以使用以下替代:"filetype plugin on"" 简要帮助文档" :PluginList - 列出所有已配置的插件" :PluginInstall - 安装插件,追加 `!` 用以更新或使用 :PluginUpdate" :PluginSearch foo - 搜索 foo ; 追加 `!` 清除本地缓存" :PluginClean - 清除未使用插件,需要确认; 追加 `!` 自动批准移除未使用插件"" 查阅 :h vundle 获取更多细节和wiki以及FAQ" 将你自己对非插件片段放在这行之后# 安装插件# vim中:PluginInstall# bashvim _PluginInstall +qall# 查找插件# vim:PluginSearch# 要从vimscripts网站刷新本地的列表:PluginSearch!# 查看已安装插件# vim:PluginList# 更新插件# vim:PluginUpdate Plug它是一个速度非常快的、极简的 vim 插件管理器。它可以并行地安装或更新插件。你还可以回滚更新。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# 下载安装curl -fLo ~/.vim/autoload/plug.vim --create-dirs \ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim# 配置vim ~/.vimrc# 以 call plug#begin(PLUGIN_DIRECTORY) 开始，并以 call plug#end() 结束# 栗子" Specify a directory for plugins" - For Neovim: ~/.local/share/nvim/plugged" - Avoid using standard Vim directory names like 'plugin'call plug#begin('~/.vim/plugged')" Make sure you use single quotes" Shorthand notation; fetches https://github.com/junegunn/vim-easy-alignPlug 'junegunn/vim-easy-align'" Any valid git URL is allowedPlug 'https://github.com/junegunn/vim-github-dashboard.git'" Multiple Plug commands can be written in a single line using | separatorsPlug 'SirVer/ultisnips' | Plug 'honza/vim-snippets'" On-demand loadingPlug 'scrooloose/nerdtree', &#123; 'on': 'NERDTreeToggle' &#125;Plug 'tpope/vim-fireplace', &#123; 'for': 'clojure' &#125;" Using a non-master branchPlug 'rdnetto/YCM-Generator', &#123; 'branch': 'stable' &#125;" Using a tagged release; wildcard allowed (requires git 1.9.2 or above)Plug 'fatih/vim-go', &#123; 'tag': '*' &#125;" Plugin optionsPlug 'nsf/gocode', &#123; 'tag': 'v.20150303', 'rtp': 'vim' &#125;" Plugin outside ~/.vim/plugged with post-update hookPlug 'junegunn/fzf', &#123; 'dir': '~/.fzf', 'do': './install --all' &#125;" Unmanaged plugin (manually installed and updated)Plug '~/my-prototype-plugin'" Initialize plugin systemcall plug#end()# 重载.vimrc以使用vimsource ~/.vimrc# vim:PlugInstall:PlugUpdate:PlugClean# 升级plug# vim:PlugUpgrade vim常见插件 NERDTree： 文档树 YouCompleteMe： 代码补全 Rainbow： 彩虹括号 UndoTree： 关闭vim后也可代码撤回 vim-gitgutter：显示git信息 ctrlp： tagbar：浏览当前文件的标签并获得其结构的概述 Vim使用技巧有一个很好的配置好的vimrc: https://github.com/wklken/k-vim 12345&quot; 参考知乎&quot; 这个是我喜欢的，一旦一行的字符超出80个的话就把那些字符的背景设为红色&quot; 这个对于Python遵守PEP8很有用highlight OverLength ctermbg=red ctermfg=white guibg=#592929match OverLength /\%81v.\+/ Unicode/UTF-8/ASCII参考： ASCII: https://zh.wikipedia.org/wiki/ASCII Unicode: https://zh.wikipedia.org/wiki/Unicode Unicode计算机处理的是数字(二进制文件)。他们在存储字符时要给每个字符分配一个数值。 早期的编码系统称为 ASCII（美国信息交换标准码）， 一共有128（0-127）个值，每个值用7bit 保存。ASCII可以满足小写、大写、数字标点符号和一些控制字符的处理。 人们曾尝试将ASCII字符扩展到8bit，这种新的被称为“扩充ASCII”的编码一直没有成为国际性标准。 为了克服ASCII和扩充ASCII先天上的不足，Unicode Consortiun（多语言软件生产商群体）创建了一种能够提供广泛字符集的通用编码系统，称为Unicode。 Unicode最初设置为2Byte的字符集。但版本3的Unicode用的是4Byte编码，并且与ASCII与扩充的ASCII完全兼容。 现在被称为Basic Latin（基本拉丁文）的ASCII字符集就是前25位全部置零的Unicode码。现在被称为 Latin-1（拉丁文1）的扩充ASCII字符集就是前24位全部置零的Unicode码。 Unicode中的每个字符或符号由一个32bit数来定义，因此这种编码可以定义高达2的32次方(4 294 067 296)个字符或符号。它的记法使用了十六进制数字，格式如下： 1234U-XXXXXXXX#每个 X 都是一个十六进制的数字#因此，它的数值从U-00000000到U-FFFFFFFF ASCII美国信息交换码（American Standard Code of Information Internet，ASCII）是一种7bit码，设计来为128个大多数是美国英语里使用的符号提供编码。今天的ASCII码已成为Unicode的一部分，它占据了Unicode中的前128个码（00000000-0000007F）。 ASCII的一些特点： space(20-sp)字符，是一个可打印的字符，打印出一个空格 大写字母从(41-A)开始，小写字母从(61-a)开始。按ASCII比较时，大写字母的数值会小于小写字母 大写字母与小写字母在他们的7bit编码中只有1bit不同，A(1000001)，a(1100001)，两者相差(20)十六进制 小写字母并没有紧跟在大写字母后面，这两者之间还有几个标点符号(5B-60) 数字从(30-0)开始 从00到1F这最开始的32个字符加上最后一个字符(7F)全都是非打印字符。字符(00)被用作定界符，已定义字符串的结束。字符(7F)是删除字符，它被某些编程语言用来删除前一个字符。剩下的非打印字符称为控制字符，用于数据通信 ASCII控制字符： 二进制 十进制 十六进制 缩写 Unicode表示法 脱出字符表示法 名称/意义 0000 0000 0 00 NUL ␀ ^@ 空字符（Null） 0000 0001 1 01 SOH ␁ ^A 标题开始 0000 0010 2 02 STX ␂ ^B 本文开始 0000 0011 3 03 ETX ␃ ^C 本文结束 0000 0100 4 04 EOT ␄ ^D 传输结束 0000 0101 5 05 ENQ ␅ ^E 请求 0000 0110 6 06 ACK ␆ ^F 确认回应 0000 0111 7 07 BEL ␇ ^G 响铃 0000 1000 8 08 BS ␈ ^H 退格 0000 1001 9 09 HT ␉ ^I 水平定位符号 0000 1010 10 0A LF ␊ ^J 换行键 0000 1011 11 0B VT ␋ ^K 垂直定位符号 0000 1100 12 0C FF ␌ ^L 换页键 0000 1101 13 0D CR ␍ ^M Enter键 0000 1110 14 0E SO ␎ ^N 取消变换（Shift out） 0000 1111 15 0F SI ␏ ^O 启用变换（Shift in） 0001 0000 16 10 DLE ␐ ^P 跳出数据通讯 0001 0001 17 11 DC1 ␑ ^Q 设备控制一（XON 激活软件速度控制） 0001 0010 18 12 DC2 ␒ ^R 设备控制二 0001 0011 19 13 DC3 ␓ ^S 设备控制三（XOFF 停用软件速度控制） 0001 0100 20 14 DC4 ␔ ^T 设备控制四 0001 0101 21 15 NAK ␕ ^U 确认失败回应 0001 0110 22 16 SYN ␖ ^V 同步用暂停 0001 0111 23 17 ETB ␗ ^W 区块传输结束 0001 1000 24 18 CAN ␘ ^X 取消 0001 1001 25 19 EM ␙ ^Y 连接介质中断 0001 1010 26 1A SUB ␚ ^Z 替换 0001 1011 27 1B ESC ␛ ^[ 退出键 0001 1100 28 1C FS ␜ ^\ 文件分区符 0001 1101 29 1D GS ␝ ^] 组群分隔符 0001 1110 30 1E RS ␞ ^^ 记录分隔符 0001 1111 31 1F US ␟ ^_ 单元分隔符 0111 1111 127 7F DEL ␡ ^? 删除 ASCII可显示字符: 进制 十进制 十六进制 图形 0010 0000 32 20 (space) 0010 0001 33 21 ! 0010 0010 34 22 “ 0010 0011 35 23 # 0010 0100 36 24 $ 0010 0101 37 25 % 0010 0110 38 26 &amp; 0010 0111 39 27 ‘ 0010 1000 40 28 ( 0010 1001 41 29 ) 0010 1010 42 2A * 0010 1011 43 2B + 0010 1100 44 2C , 0010 1101 45 2D - 0010 1110 46 2E . 0010 1111 47 2F / 0011 0000 48 30 0 0011 0001 49 31 1 0011 0010 50 32 2 0011 0011 51 33 3 0011 0100 52 34 4 0011 0101 53 35 5 0011 0110 54 36 6 0011 0111 55 37 7 0011 1000 56 38 8 0011 1001 57 39 9 0011 1010 58 3A : 0011 1011 59 3B ; 0011 1100 60 3C &lt; 0011 1101 61 3D = 0011 1110 62 3E &gt; 0011 1111 63 3F ? 0100 0000 64 40 @ 0100 0001 65 41 A 0100 0010 66 42 B 0100 0011 67 43 C 0100 0100 68 44 D 0100 0101 69 45 E 0100 0110 70 46 F 0100 0111 71 47 G 0100 1000 72 48 H 0100 1001 73 49 I 0100 1010 74 4A J 0100 1011 75 4B K 0100 1100 76 4C L 0100 1101 77 4D M 0100 1110 78 4E N 0100 1111 79 4F O 0101 0000 80 50 P 0101 0001 81 51 Q 0101 0010 82 52 R 0101 0011 83 53 S 0101 0100 84 54 T 0101 0101 85 55 U 0101 0110 86 56 V 0101 0111 87 57 W 0101 1000 88 58 X 0101 1001 89 59 Y 0101 1010 90 5A Z 0101 1011 91 5B [ 0101 1100 92 5C \ 0101 1101 93 5D ] 0101 1110 94 5E ^ 0101 1111 95 5F _ 0110 0000 96 60 ` 0110 0001 97 61 a 0110 0010 98 62 b 0110 0011 99 63 c 0110 0100 100 64 d 0110 0101 101 65 e 0110 0110 102 66 f 0110 0111 103 67 g 0110 1000 104 68 h 0110 1001 105 69 i 0110 1010 106 6A j 0110 1011 107 6B k 0110 1100 108 6C l 0110 1101 109 6D m 0110 1110 110 6E n 0110 1111 111 6F o 0111 0000 112 70 p 0111 0001 113 71 q 0111 0010 114 72 r 0111 0011 115 73 s 0111 0100 116 74 t 0111 0101 117 75 u 0111 0110 118 76 v 0111 0111 119 77 w 0111 1000 120 78 x 0111 1001 121 79 y 0111 1010 122 7A z 0111 1011 123 7B { 0111 1100 124 7C l(管道线) 0111 1101 125 7D } 0111 1110 126 7E ~ ASCII缺点：ASCII的局限在于只能显示26个基本拉丁字母、阿拉伯数目字和英式标点符号。因此现在的软件系统大多采用Unicode。 UTF-8UTF-8（8-bit Unicode Transformation Format）是一种针对Unicode的可变长度字符编码，也是一种前缀码。它可以用来表示Unicode标准中的任何字符，且其编码中的第一个字节仍与ASCII兼容，这使得原来处理ASCII字符的软件无须或只须做少部分修改，即可继续使用。 UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。 UTF-8的编码规则很简单，只有二条: 对于单字节的符号，字节的第一位设为0，后面7位为这个符号的unicode码。因此对于英语字母，UTF-8编码和ASCII码是相同的 对于n字节的符号（n&gt;1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的unicode码 Bash bash与shell管理整个计算机硬件的其实是操作系统的内核(kernel)。这个内核是需要被保护的，所以一般用户就只能通过shell来跟内核通信，让内核达到我们想要达到的工作。 硬件、内核与shell我们必须通过shell，将我们输入的命令与内核通信，让内核可以控制硬件正确无误的工作。 操作系统其实是一组软件。由于这组软件在控制整个硬件与管理系统的活动监测，如果这组软件能被用户随意操作，若用户应用不当，将会使得整个系统奔溃。因为操纵系统管理的就是整个硬件功能，所以当然不能够被随便一些没有管理能力的终端用户随意使用。但我们总是需要让用户操作系统的，所以就有了在操作系统上面发展的应用程序。用户可以通过应用程序来指挥内核，让内核达到我们所需要的硬件任务。 也就是说，只要能够操作应用程序的接口都能够称为shell。狭义的shell指的是命令行方面的软件，包括bash等。广义的shell则包括图形界面的软件。 命令行shell 各Distribution的命令行界面都一样 远程管理非常快速 Linux的任督二脉 系统合法shell与/etc/shells由于shell依据发布者的不同就有许多版本，例如Bourne SHell（sh）、C SHell、K SHell、TCSH等。 Linux默认使用的这一版本就是Bourne Again SHell(bash)，这个shell是Bourne SHell的增强版，也是基于GNU框架下发展出来的。 检查系统可用shell: cat /etc/shells合法shell要写入/etc/shells，系统某些服务在运行过程中，会去检查用户能够使用的shell。 查看用户shell权限： cat /etc/passwd，最后一行便是默认shell。 bash shellbash是GNU计划中重要的工具软件之一，目前也是Linux distributions 的标准shell。bash主要兼容于sh，并且依据一些用户的需求而加强shell 版本。 bash的优点： 命令记忆能力history 命令与文件补全功能tab 命令别名设置功能alias 作业控制、前台、后台控制(job control, foreground, background) 使用前台、后台的控制可以让作业进行得更为顺利。至于作业控制(jobs)的用途更广，可以让我们随时将工作丢到后台中执行，而不怕不小心使用ctrl+c来中断该进程 程序脚本shell script 通配符(Wildcard) type命令type命令用于判断一个命令是內建命令还是外部命令(非bash提供)。 1234567type lstype -t ls#file，外部命令#alias，别名#builtin，內建命令 shell变量变量就是以一组文字或符号等，来替代一些设置或者是一串保留的数据。 变量显示与设置 echo: 显示变量 echo $PATH unset: 取消变量 unset $ZHANG 变量设置规则 变量与变量内容以一个等号=连接，如myname=zhang 等号两边不能有空格符，否则错误 变量名称只能是英文字母和数字，开头字符不能是数字 变量内容若有空格，可使用双引号或单引号 双引号内的特殊符号，保有原本的特性 单引号内的特殊字符则仅为一般字符 转义字符\\，将特殊符号变成一般字符 在一串命令中，还需要使用其他命令，使用反单引号 反引号``内的命令将被优先执行，而其执行结果将作为外部的输入信息 若该变量为了增加变量内容时，可用$变量名称 或${变量}累加内容 myname=${myname}xxx 若该变量需要在其他子进程执行，请以export来使变量变成环境变量 通常大写字符为系统默认变量，自行设置变量可以使用小写字符，方便判断 什么是子进程？在我目前这个shell下，去打开另一个新的shell。新的那个shell就是子进程。在一般状态下，父进程定义的变量是无法在子进程内使用的，要通过export将变量变成环境变量后才可以。 注意单引号、双引号和反引号。 环境变量环境变量可以帮我们达到很多功能，包括主文件夹的变换、提示符的显示、执行文件查找的路径等。 env: 显示环境变量 set: 查看所有变量 包括环境变量和自定义变量 1234567#HOME，用户主目录#SHELL，当前环境使用的shell#HISTSIZE，历史命令#PATH，执行文件查找路径#LANG，语系#$PS1，命令提示符#PS2，第二行提示符 设置$PS1，$PS2: 12345678910111213141516171819202122232425\d #可显示出『星期 月 日』的日期格式，如：&quot;Mon Feb 2&quot;\H #完整的主机名\h #仅取主机名在第一个小数点之前的名字\t #显示时间，24小时格式的『HH:MM:SS』\T #显示时间，为12小时格式的『HH:MM:SS』\A #显示时间，为24小时格式的『HH:MM』\@ #显示时间，为12小时格式的『am/pm』\u #目前使用者的账号名称，如『root』\v #BASH的版本信息\w #完整工作路径名，由根目录写起的目录名称。但家目录会以 ~ 取代\W #利用basename函数取得工作目录名称，所以仅会列出最后一个目录名。\# #下达的第几个命令\$ #提示字符，root时，提示字符为#；否则就是$ $钱字号本身也是变量，代表当前shell的PID –&gt; echo $$ ?问号也是一个特殊变量，代表上一个运行命令的回传值 –&gt; echo $? 0 命令运行成功 errorcode 命令运行错误 语系变量locale - get locale-specific information. 设置LANG的时候，其他的语系变量就会被这个变量所替代。 变量键盘读取、数组与声明 read： 读取来自键盘输入的变量 declare,typeset: 声明变量类型 变量的默认类型为字符串 若不指定变量类型，则1+2就是一个字符串而不是计算式 数组变量类型 var[1]=’varray1’ var[2]=’varray2’ echo “${${var[1]}, ${var[2]}}” bash shell操作环境自定义我们登录主机的时候屏幕上面会有一些说明文字，并且登录的时候还可以给用户提供一些信息或者欢迎文字，或环境变量和命令别名等。 路径与命令查找顺序命令的运行顺序： 以绝对/相对路径执行命令 由alias找到该命令来执行 由bash内置的（builtin）命令来执行 通过$PATH这个变量的顺序找到的第一个命令来执行 bash登录与欢迎消息 /etc/issue –&gt; 终端登录消息 CentOS Linux 7 (core)….. /etc/motd –&gt; 用户登录后取得一些消息 Welcome to aliyun ECS bash环境配置文件操作系统有一些环境配置文件的存在，让bash在启动时直接读取这些配置文件，以规划好bash的操作环境。这些配置文件又可以分为全体系统的配置文件以及用户个人偏好配置文件。 命令别名、自定义的变量在你注销bash后就会失效。所以你想要保留你的设置，就得要将这些设置写入配置文件才行。 login shell 取得bash需要完整的登录流程 non-login shell 取得bash接口的方法不需要登录 bash shell快捷键 Ctrl+C –&gt; 终止当前命令 Ctri+D –&gt; 输入结束(EOF) Ctri+M –&gt; Enter Ctrl+S –&gt; 暂停屏幕输出 Ctrl+Q –&gt; 恢复屏幕输出 Ctrl+U –&gt; 在提示字符下，将整列命令删除 Ctrl+Z –&gt; 暂停目前命令 通配符与特殊符号通配符： 符号 说明 * 代表0-∞个 任意字符 ? 代表一定有一个 任意字符 [-] 中括号内任一字符 [^] 非中括号内字符 bash常见特殊符号，理论上文件名不要用到上述字符。 符号 说明 # 注释 \ 转义字符 1 管道线 ; 连续命令分隔符 ~ 用户主目录 $ 取变量前导符 &amp; 将命令放入后台 ! 逻辑非 / 目录符号 &gt;, &gt;&gt; 输出定向 &lt;, &lt;&lt; 输入定向 ‘’ 单引号 “” 双引号 () 子shell {} 命令区块混合 重定向数据流重定向就是将某个命令执行后应该要出现在屏幕上的数据传输到其他的地方，如文件或设备。 标准输入(stdin)，代码为0，使用&lt;或者&lt;&lt; 标准输出(stdout)，代码为1，使用&gt;或者&gt;&gt; 标准错误(stderr)，代码为2，使用2&gt;或者2&gt;&gt; &gt;表示以覆盖方式写入，&gt;&gt;表示以追加方式写入 管道管道命令使用 “ | “ 这个界定符号。管道命令” | “ 仅能处理经由前面一个命令传来的正确信息。所以对stderror没有直接处理能力。 在每个管道后面接的第一个数据必定是命令，而且这个命令必须要能够接收standard input的数据才行，这样的命令才可以是管道命令。 Bash特殊符号在编写shellscripts的时候，特殊符号也有其重要的功能。 符号 描述 栗子 #! shellban，申明脚本所使用的shell #!/bin/bash \ 转义字符 \n l 管道 stdout l grep &gt;,&gt;&gt; 输出定向 &gt; 1.txt &lt;,&lt;&lt; 输入定向 &lt; 1.txt 2&gt; 错误定向 2&gt; error.txt ; 连续命令分隔符 cmd1;cmd2 &amp;&amp; 与，只有当前命令完成后才执行后一个命令 cmd1 &amp;&amp; cmd2 ll 或，或此或彼 cmd1 ll cmd2 ~ 用户家目录 cd ~ # 注释符 #comments $ 取用变量前导符 $PATH或${PATH} &amp; 工作控制，将命令放入后台(bg) command&amp; * ? [] [-] [^] 通配符 .sh ?.sh [a-z].txt [^zhang].txt ! 逻辑非 != = 两边无空格 赋值符号 name=zhang = 两边有空格 比较符号 if [ $name = zhang ] $0 执行文件脚本名 /root/zhang.sh $1, $2 第1,2个…变量 ./zhang.sh start $# 参数个数 if [ $# -ne 2 ]；then echo &#39;Usage: $0 arg1 arg2&#39; $@ 代表$1,$2,$3…之意 每个变量是独立的 $* 代表$1c$2c$3…之意 c为分割字符，默认为空格键 $? 命令状态码，成功为0 $? $$ 当前shell的PID echo $$ ‘单引号’ 单引号内特殊字符仅为一般字符 echo &#39;$host&#39;--$host “双引号” 双引号内特殊符号，可保有原本特性 echo &quot;$host&quot; --localhost `反引号` 运行命令 反引号内命令先执行 () 以子shell方式执行 $(date) {} 命令区块的组合 PS1 命令提示符 $PS1 PS2 第二行以后的提示字符 $PS2 shift 移动参数 shift后面可以接数字，代表拿掉最前面的几个参数 set 查看所有变量 set unset 取消变量 unset name，没有$符号 export 使某变量成为环境变量 export name，没有$符号 source source命令通常用于重新执行刚修改的初始化文件，使之立即生效，而不必注销并重新登录 source file shell scriptshell script 有点像早期的批处理程序，即将一些命令汇整起来一次执行.但shell script拥有更强大的功能，可以进行类似程序(program)的编写，并且不需要经过编译(compile)就能执行。 shell script介绍shell script是利用shell的功能写的一个程序(program)。这个程序是使用纯文本文件，将一些shell的语法与命令(含外部命令)写在里面，搭配正则表达式、命令管道与数据流重定向等功能，还提供了数组、循环、条件与逻辑判断等重要功能， 以达到我们所想要的处理目的。 shell script用在系统管理上面是很好的一项工具，但用在处理大量数值运算上就不够好。因为shell script的速度较慢，且使用的cpu资源较多，造成主机资源的分配不良。 使用shell script的优势： 自动化管理的重要依据 追踪与管理系统的重要工具 简单入侵检测功能 连续命令单一化 简单的数据处理 跨平台支持与学习历程较短 shell script注意事项： 命令的执行是从上到下从左到右，分析与执行 命令的执行中：命令、参数间的多个空白都会被忽略掉 空白行也将被忽略，tab按键所得的空白同样视为空格键 读取到一个Enter符号(CR)，就尝试开始执行该行命令 一行内容太多，则可以使用\[Enter]来扩展到下一行 任何加在#后面的内容都将被视为注释而被忽略 shell script文件的执行方式： 直接命令执行 .sh文件必须具有可读和可执行权限，使用绝对路径或相对路径来执行 以bash进程来执行 bash xx.sh sh xx.sh shell script执行方式的区别： 直接执行，script是在子进程的bash中执行的。当子进程完成后，子进程内的各项变量或操作将会结束而不会传回到父进程中。 source来执行，在父进程中执行 编写一个shell script一个良好的shell script应该纪录好如下信息： script的功能 script的版本信息 script的作者 script的版权声明方式 script的History（历史记录） script内较特殊的命令，使用绝对路径的方式来执行 script执行时需要的环境变量预先声明与设置 在较为特殊的程序代码部分，建议务必要加上批注说明 shell script判断式当我要检测系统上某些文件或相关属性时，使用test命令。 1test -e /root/test.txt &amp;&amp; echo 'Exist' || 'Not exist' 文件类型判断： 选项 说明 -e 是否存在 -f 是否存在文件 -d 是否存在目录 -b 是否存在block device -c 是否存在character device -S 是否存在Socket文件 -p 是否存在pipe文件 -L 是否存在链接文件 文件权限判断： 选项 说明 -r 是否可读 -w 是否可写 -x 是否可执行 -u 是否具有SUID -g 是够具有SGID -k 是否具有Sticky bit -s 是否为非空白文件 文件之间的比较： 选项 说明 -nt newer than -ot old than -ef 是否为同一个文件 整数之间的比较： 选项 说明 -eq equal -ne not equal -gt greater than -lt less than -ge greater or equal -le less or equal 字符串之间的比较： 选项 说明 -z 是否为空 -n 非空 str1 = str2 是否相等 != 不等于 多重条件判断： 选项 说明 -a and -o or ! 非 判断符号[]: 如果需要在bash中使用中括号来作为shell的判断式时，必须要注意中括号的两端需要有空格符来分隔。 中括号内的变量，每个最好都用双引号括起来 中括号内的常量，最好都以单或双引号括起来 shell script的默认变量: $0,$1…12/root/test.sh opt1 opt2 opt3 $0 $1 $2 $3 执行文件的脚本名就是$0 文件后接的第一个参数就是$1，以此类推 $#，表示参数个数 $@，表示”$1”, “$2”… shift，参数变量号码偏移 shift n，代表拿掉前面几个参数的意思 条件判断语句 if…then语句if…then 是最常见的条件判断式。 单层条件判断： 123if [ confition ]; then xxxfi 多层条件判断： 12345if [ condition ]; then xxx;else xxx;fi 1234567if [ confition1 ]; then xxx;elif [ condition2 ]; then xxx;else xxx;fi case…esac语句有多个既定变量内容，那么只需要针对这几个变量来设置状况就好。 12345678910111213141516171819202122232425262728293031case $变量名 in"$var1") xxx ;;"$var2") xxx ;;"...") xxx ;;esac####栗子#/etc/init.d/networkcase "$1" instart) xxx ;;stop) xxx ;;restart) xxx ;;status) xxx ;;esac function功能什么是函数？函数可以在shell script 当中做出一个类似自定义执行命令的东西。最大的动能是，可以简化很多的程序代码。 因为shell script的执行方式是由上而下、由左而右。因此在shell script当中，function的定义一定要在程序的最前面，这样才能够在执行时被找到可用的程序段。 1234567891011121314151617181920vim func.shfunction fname () &#123;&#125;####栗子function Zhang() &#123; echo $1 $2&#125;Zhang "$1" "$2"#执行sh func.sh aaa bbb 循环(loop)语句 while do done(不定循环)while是当condition条件成立时，就进行循环，condition条件不成立就停止。 1234while [ condition1 ]do xxxdone until do done(不定循环)until是当condition条件成立时，终止循环；否则就持续进行循环的循环。 1234until [ condition ]do xxxdone for do done(固定循环)1234567891011for i in con1 con2 con3 ...do xxxdone####栗子for i in 192.168.1.&#123;1,2,3&#125;do ping -c 1 $idone for do done的数值处理： 1234567891011for ((初始值;限制值；步长))do xxxdone####栗子for ((i=0;i&lt;10;i++))do echo $idone shell script的追踪与调试(debug)最好在shell script执行之前先行调试。 123456789sh [-nvx] xxx.sh#-v 运行脚本前，先将脚本内容输入到屏幕#-n 仅查询语法问题#-x 边显示边执行当然也可以把这几个调试参数写到shellbang中#!/bin/bash -x 小试牛刀简介123456789101112#bash(Bourne Again Shell)，shell环境使得用户能与操作系统的内核进行交互操作#!/bin/bash#date#descriptioncmd1; cmd2cmd3#sh /path/xx.sh#Bash还有一个历史记录文件 ~/.bash_history 终端打印(echo)12345678910111213141516171819202122#终端作为交互式工具，用户可以通过它与shell环境进行交互echo '$var'echo $varecho -e "1\t2\t3"echo -e '\e[1;31m Red color \e[0m' #彩色echo &#123;1..10&#125; #输出1到10echo &#123;A..H&#125; #for i in &#123;a..z&#125;cat &lt;&lt; EOF112233EOF# \转义字符printf "%-5s %-10s $-4.2f\n" 001 Zhang 56.789#格式替代符%s %d %c %f, -左对齐 玩转变量和环境变量123456789101112131415161718192021#Bash中，每一个变量默认值值都是字符串形式#环境变量和自定义变量echo $SHELLecho $UIDvar=value #这是赋值#var = value这是相等操作echo $varecho $&#123;var&#125;echo $&#123;#var&#125; #字符数#export用来设置环境变量，此后，任何shell中的程序都会继承环境变量ZHANG=Gentlemanexport ZHANGPATH="$PATH:/home/zhang/bin"export $PATH 通过shell进行数学运算1234567891011121314151617181920212223242526272829303132#let, expr, bc, [], (())#要注意默认是字符串类型哦n1=1;n2=2let sum=n1+n2let n1++;let n2-=1sum=$[ n1 + n2 ]sum2=$(( sum + 3 ))sum=`expr 3 + 4`#浮点计算 bcecho "8 * 1.1" | bc#设置小数点精度echo "scale=2; 3/8" | bc#进制转换num=100echo "obase=2; $num" | bcnum=1100100echo "obase=10; ibase=2; $num" | bc#平方和平方根echo "sqrt(100)" | bcecho "10^2" | bc 文件描述符重定向12345678910111213141516#最常用的文件描述符是 stdin(0), stdout(1), stderr(2); 通过内容过滤将输出重定向到文件echo "This is a sample text 1" &gt; temp.txt #覆盖echo "This is sample text 2" &gt;&gt; temp.txt #追加ls + &gt;stdout.txt 2&gt;stderr.txtcmd 2&gt;&amp;1 /dev/null == com &amp;&gt; /dev/null #null设备也被称为黑洞#当一个command发生错误并退回时，它会返回一个非0的状态码echo $?#tee命令，一方面可将数据重定向到文件，另一方面还可提供一份重定向数据的副本作为后续命令的stdin#tee默认覆盖文件，-a选项追加cat temp.txt | tee tee.txt | cat -n 数组和关联数组123456789101112131415161718192021#数组借助索引将多个独立的数据存储为一个集合#普通数组只能使用整数作为数组索引，而关联数组可以使用字符串作为数组索引#还可将数组定义成一组索引-值(index-value)arr=(1 two 3 four 5)echo $&#123;arr[0]&#125;arr[0]=Oneindex=3echo $&#123;arr[$index] #arr[3]echo $&#123;arr[*]&#125;echo $&#123;#arr[*]&#125; #arr-length#关联数组可用任意文本作为数组索引declare -A ass_arrass_arr=([index1]=val1 [index2]=val2 ...) #内嵌索引-值ass_arr[index3]=val3 #独立索引-值echo $&#123;!ass_arr[*]&#125; #列出数组索引 别名(alias)123456789101112#alias作用是暂时的，关闭终端后别名就失效；#为使别名一直保持，可将其写入 ~/.bashrc，因为每一个新的shell都会执行~/.bashrc中的命令#新设置的别名将取代已有别名alias vi=vim;unalias viecho "alias ll='ls -l --color=auto'" &gt;&gt; ~/.bashrc#\对别名命令进行转义，执行原本的命令。避免攻击者利用别名将某些特权命令替换成别有用心的命令\vi test.sh 获取、设置日期和延时(date)12345678910111213141516171819202122232425262728293031#很多应用程序需要以不同的格式打印日期，设置日期和时间，以及根据日期和时间执行操作;#延时通常用于在程序执行过程中提供一段等待时间;#在Unix-like系统中，日期被存储为一个整数，其大小为世界标准时间1970年1月1日0时0分0秒起所流逝的秒数；#这种计时方式被称之为 纪元时或Unix时间；#通过纪元时间，可知道两个日期之间相隔了多少秒#编写以循环方式运行的监视脚本时，设置时间间隔是必不可少的date +%s#!/bin/bashstart=$(date +%s)commandssleep 1end=$(date +%s)diff=$((end - start))echo "$diff seconds"#显示指定时间date +%F -d -1daysdate +%H -d -3hours#将标准时间转换为原子时间date -d '2018-02-07 14:05:53' +%s1517983553#将原子时间转换为标准时间date --date='@1517983553'Wed Feb 7 14:05:53 CST 2018 调试脚本(sh)12345#调试功能能在出现一些异常情况时生成运行信息#!/bin/bash -xvsh -xsh -n 函数和参数(function)123456789101112131415161718192021function fname()&#123;statements&#125;fname()&#123;echo $1, $2 #访问第参数1和参数2,$n第n个参数echo "$@" #以列表的形式一次性打印所有参数echo "$*" #类似于$@，但参数被作为单个实体return 0 #f返回值&#125;fname 1 22 333 #返回上面定义的变量#递归函数，能够调用自身，不断地生成新的进程，最终会造成xx#导出函数，使用export导出，这样函数作用域就可以扩展到子进程export -f fname#读取命令返回值echo $? 读取命令序列输出(` `, $() )12345678910#输入通常是stdin，输出stderr或stdout,这些命令称为 过滤器(filter)。我们使用 管道(pipe) 来连接每一个过滤器cmd1 | cmd2 | cmd3#子shell，子shell生成独立的进程，不会对当前shell有任何影响，所做改变仅限于子shell内zhang=$(ls | cat -n)#反引用zhang=`ls | cat -n` 读取字符(read)123456789101112131415161718#read是一个重要的从标准输入中读取文本的命令#可以使用read以交互的形式来读取用户的输入read -n 5 zhang #读取字符数echo $zhangread -s passwd #不回显echo $passwdread -t 5 zhang #超时时间echo $zhangread -p zhang #显示提示信息echo $zhangread -d ":" zhang #定界符结束输入123：echo $zhang 字段分隔符和迭代器12345678910111213141516171819#内部字段分隔符(Internal Field Separator, IFS)是shell中的一个重要概念#IFS的默认值为空白字符(换行符、制表符、空格)awk -F: '&#123;print $1,$3&#125;' /etc/passwd #IFS=":"#对一些列值进行迭代，循环非常有用for i in &#123;1..10&#125;docmddonewhile conditiondocmddoneuntil conditiondocmddone 比较与测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#程序中的流程控制是由比较和测试语句来处理的if condition1 || condition2then cmd1elif condition3 &amp;&amp; condition4then cmd2else cmd3fi#算术比较if [ $num -ge 10 -a $num -lt 20 ]-eq-gt-ge-lt-le-a-o#文件系统相关if [ -f $file1 -o -x $file2]-x-w-r-f-d-e-b #block-l#字符串比较[[ $str1 = $str2]]= #=号旁有空格--是比较关系；=号旁没空格，是赋值语句!=&gt;&lt;-z #空字符-n #非空字符#使用test命令来执行条件检测if [ $num -eq 0 ] -- if test $num -eq 0 命令之乐简介各种命令可谓Unix-Like系统中优美的部分，它能帮我们搞定各种繁杂的任务。一旦你尝试过Linux提供的这些利器，你一定会感到惊讶：以前没有这些命令的时候，自己是什么熬过来的。最钟爱的莫过于 grep, awk, sed, find 命令了！ 本章将会为你介绍一些最有趣同时也是最实用的命令。 用cat进行拼接12345678#cat命令通常用于读取、显示或拼接文件内容，不过它所具备的能力远不止此#cat(concatenate, 拼接)cat file1 file2 ···echo "Ahaha" | cat - file1 file2 #-指stdin文本文件名cat -s file3 -- cat file3 | tr -s '\n' #压缩空白行cat -T test.py #将制表符显示为 ^I, 避免制表符和连续空格误用, 产生错误缩进cat -n file4 #显示行号 录制与回放终端会话(script)当你需要准备一个命令行教程时，如果将我们输入命令后的一切按照先后次序记录下来，再进行回放，是不是很nice！通过 script, scriptreplay 命令, 把终端会话记录到文件，并回放。 123456789#-t,将时间数据输出到标准错误； -a,追加输出script -t 2&gt; timing.log -a output.session #两个文件随意取名, 如不将错误重定向会显示在屏幕上导致很乱输入命令cmd2···exit #退出录制scriptreplay -t timing.log output.session #播放 文件查找与文件列表(find)find 是Unix/Linux命令行工具箱中最棒的工具之一。find 命令沿着文件层次结构向下遍历，匹配符合条件的文件，并执行相应的操作。 find - search for files in a directory hierarchy 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#基于文件名及正则表达式搜索find /home/zhang #列出/home/zhang目录及其子目录线所有文件和文件夹find /home/zhang -name "*.txt"find . -name "*.sh" -o -iname "zhang*" #匹配多个find /home/zhang -path "201710*" #-path将文件路径作为一个整体进行匹配find . -regex ".*\(\.txt|\.[0-9]+\)$" #匹配以.txt或数字结尾的文件#使用-maxdepth, -mindepth参数，来限制find的遍历深度#-type, 根据文件类型搜索。 f(普通文件)，d(目录)，b(块设备)，l(符号链接)，s(套接字)等find /home -maxdepth 1 -type f(d) #参数顺序也会影响find的查找效率#根据文件类型搜索find /dev -type b #查看/dev及其子目录下设备文件find / -maxdepth 1 -type l #查找/下链接文件#根据文件时间进行搜索#Unix/Linux文件系统中的每一个文件都有三种时间戳(timestamp),-表示小于，+表示大于#Unix中并没有所谓的 "创建时间" 的概念#访问时间(-atime,以天为单位； -amin,以分钟为单位):用户最近一次访问文件时间；#修改时间(-mtime,以天为单位； -mmin,以分钟为单位):文件最后一次修改时间；#变化时间(-ctime,以天为单位； -cmin,以分钟为单位):文件元数据(如权限，所有权)最后一次变化时间；find /home/zhang -type f -mtime 7 #7天前被修改的普通文件find /home/zhang -type f -amin -10 #搜索10分钟内被修改的普通文件find . -type f -newer file1.txt #找出比file1.txt新的文件#基于文件大小的搜索#b(块，512字节), c(字节), w(字，2字节), k(千字节), M(兆字节), G(吉字节)find . -type -f -size +100k#删除匹配的文件find . -type f -name "*.swp" -delete#基于文件权限和所有权的匹配find . -type f -perm 644find /var/apache -type f -name "*.php" -perm 644 #搜索基于权限的文件find /var -maxdepth 2 -type f -user zhang #搜索基于用户的文件#执行命令或动作#find命令可以借助-exec与其他命令进行结合#&#123;&#125;是一个特殊字符串，将替换为相应文件名find . -type f -perm 764 -user zhang -exec chmod 644 &#123;&#125; \; #将所属用户zhang，权限764的文件权限修改为644find . -type f -mmin +30 -name "*.txt" -exec cp &#123;&#125; &#123;&#125;.old \; #复制最近30内修改的名字为.txt的文件#-exec结合多个命令#我们无法在-exec参数中直接使用多个命令，不过我们可以把多个命令写到一个shellscript中，然后执行-exec ./test.sh &#123;&#125; \;find . -type f -name "*.sh" -mmin -10 -exec sh &#123;&#125; \;#让find跳过特定目录-prune#利用find搭配tar打包#查找7天内的文件并打包#建议使用绝对路径，管道无效，所有要定向到文件find /dir/path/zhang -type -f -mmtime -7 &gt; /dir/path/zhang/zhang.list &amp;&amp; tar -T /dir/path/zhang/zhang.list -czvf /dir/path/zhang123.tar.gz#检查是否正确tar -tf /dir/path/zhang123.tar.gz#不能使用find -exec tar，这样打包以后只有最后一个文件 利用stat命令查看atime, mtime, ctimestat - display file or file system status 12345stat 1.txt#Access:#Modify:#Change: 利用touch命令修改atime, mtime, ctimetouch - change file timestamps 1234#-a change only the access time#-m change only the modification time#-d instead of current time#-t instead of current time 玩转xargsxargs - build and execute command lines from standard input 1234567891011121314151617181920212223242526272829303132#xargs能够处理stdin并将其转换为特定命令的命令行参数#也可以将单行或多行输入文本转换成其他格式(如多行变单行)cmd | xargs#将多行输入转换为单行输出echo -e "1\n2\n3" | xargs #将换行符替换为空格#将单行输入转换成多行输出echo "1 2 3" | xargs -n 1 #每行一个参数echo "hahaZhahaZhahaZhaha" | xargs -n 2 -d Z #-d指定分隔符#读取stdin，将格式化参数传递给命令cat test.txt | xargs -n 1 ./zhang.sh #zhang.sh arg1; zhang.sh arg2... 每次提供一个参数cat test.txt | xargs -n X ./zhang.sh #X为参数个数，一次提供全部参数#指定替换字符串cat test.txt | xargs -I &#123;&#125; ./zhang.sh &#123;&#125;#结合find使用xargsfind . -type f -name "*.txt" -print0 | xargs -0 ls #-print0无换行输出, -0将\0作为输入界定符#统计某文件行数find /path -type f -name "*.c" -print0 | xargs -0 wc -l#结合stdin，运用while和子shellcat file.txt | while read arg; do cat $arg; done == cat file.txt | xargs - &#123;&#125; cat &#123;&#125;cmd0 | (cmd1; cmd2; cmd3) | cmd4 #子shell 用tr进行转换tr - translate or delete characters 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#tr命令经常用来编写优美的单行命令#tr可对来自stdin的字符 进行替换、删除以及压缩echo "AH WONDERFUL" | tr 'A-Z' 'a-z' #转换大小写echo "AH WONDERFUL" | tr 'A-Z' 'a-b' --&gt; ab bbbbbbbbb#tr [option] set1 set2#如果两个字符集长度不相等，那么set2会不断重复其最后一个字符，直到长度与set1相同echo 12345 | tr '0-9' '9876543210' #数字加密echo 87654 | tr '9876543210' '0-9' #数字解密echo 'He is a cool boy, and she is a beautiful girl' | tr 'A-Za-z' 'NOPQRSRUVWXYZABCDEFGHIJKLMnopqrstuvwxyzabcdefghijklm' #加密echo 'Ur vf n pbby obl, naq fur' | tr 'NOPQRSRUVWXYZABCDEFGHIJKLMnopqrstuvwxyzabcdefghijklm' 'A-Za-z' #解密cat 1.txt | tr '\t' ' ' #将制表符转换为空格#删除字符echo "Hello 530 World" | tr -d '0-9' #-d删除，删除数字Hello Worldecho "Hello 520 World" | tr -d -c '0-9' #-c补集 520#压缩字符，将连续的重复字符压缩为单个字符echo "GNU's not Unix" | tr -s ' ' #-s压缩，压缩空格GNU's not Unixecho -e "1\n2\n3\n4\n5" &gt; sum.txtcat sum.txt | echo $[ $(tr '\n' '+') 0 ] -- echo $[1+2+3+4+5+0]#tr字符类\a 终端鸣响\b 退格\f 换页\n 换行\r 回车\t 水平制表符\v 垂直制表符string1-stringN #从字符1到字符N升序过程中的所有字符[字符*次数][:alnum:] #所有字母和数字[:alpha:] #所有字母[:digit:] #所有数字[:lower:] #所有小写字母[:upper:] #所有大写字母[:graph:] #所有可打印字符，不含空格[:print:] #所有可打印字符，包含空格[:blank:] #所有水平排列的空白字符[:cntrl:] #所有控制字符[:punct:] #所有标点字符[:space:] #所有空白字符[:xdigit:] #所有十六进制数[=字符] #指定字符 校验和 与 核实文件完整性(md5sum)12345678910111213141516171819202122#校验和(checksum)程序从文件中生成校验和密钥，然后利用校验和密钥核实文件的完整性#校验和对于编写备份脚本或系统维护脚本非常重要，因为它们都会涉及通过网络传输文件#通过使用校验和核实，我们就可以识别那些在网络传输过程中出现损坏的文件，并重传，从而确保数据完整性#校验和对于核实数据完整性非常有用#广泛使用的校验和技术有：md5sum, sha1sum#对单个文件进行校验md5sum sum.txt &gt; sum.md5#302c28003d487124d97c242de94da856 sum.txtmd5sum -c sum.md5 #-c检查#sum.txt: 确定#对目录进行校验#对目录计算校验和意味着我们需要对目录中的所有文件以递归的方式进行计算yum install -y md5deepmd5deep -r ./dir &gt; dir.md5 #recursive递归md5sum -c dir.md5#可以将测试dir下某个文件更改一下，校验的时候会报错 排序、单一、重复(sort,uniq)12345678910111213141516171819202122232425262728293031#sort - 对文本文件进行行排序#uniq - 删除排序文件中的重复行echo -e "333\n1" &gt; 1.txt; echo -e "22\n22" &gt; 2.txtsort 1.txt 2.txt -o ./sorted.txt#1#22#22#333cat sortec.txt | uniq#1#22#333sort -n #按数字进行排序sort -r #逆向排序sort -M #按月份排序sort -C #检查是否排序sort -b #忽略空白#依据键或列进行排序sort -k 2 data.txt #依据第二列来排序#uniq要么使用管道，要么使用排过序的文件作文输入uniq -u sorted.txt #只显示唯一的行(即没有重复出现的行)uniq -d sorted.txt #只显示重复的行uniq -s 2 -w 2 sorted.txt #-s忽略前2个字符，-w指定用于比较的最大字符数 临时文件命名、随机数123456#在编写shell脚本时，我们经常需要存储临时文件。最适合存储临时数据的位置是 /tmp#/tmp目录中的内容会在系统重启后被清空filename=$RANDOM #RANDOM返回一个随机数filename2=$$ #当前shell的PIDfilename3=$((date +%F)) #通过日期命令 分割文件和数据(split)123456789101112131415161718192021#某些情况下，需要把文件分割成多个更小的片段dd if=/dev/zero bs=100k count=1 of=./data.file #生成一个大小100k内容全是0的文件split -b 20k data.file #-d指定分割大小#data.file xaa xab xac xad xae,这五个文件都为20k#我测试了一下，几个文件加起来数据没变，几个文件总行数没变#单位有 k, m, G, c(byte), w(word)#-d以数字为后缀， -a指定后缀长度split data.file -b 20k -d -a 2 spt #增加前缀名'spt'#data.file spt00 spt01 spt02 spt03 spt04split -l 10 data.file #-l按行数来分割文件#split只能根据大小或行数分割文件#csplit可以根据文件本身特点进行分割-f #指定分割后文件前缀-n #指定分割后文件后缀数字个数-b #指定后缀格式 根据扩展名切分文件名12345678910111213141516171819202122232425262728#借助%操作符将名称从 “名称.扩展名” 格式中提取出来file="zhang.txt"name1=$&#123;file%.*&#125; #删除位于%右侧的通配符(.*)所匹配的字符串，通配符从右向左进行匹配#zhang#*号通配符，.号#%属于非贪婪匹配(non-greedy),它会匹配通配符最短结果#%%属于贪婪匹配(greedy)，它会匹配符号条件的最长字符串name2=$&#123;file#*.&#125; #删除位于#右侧的通配符(*.)所匹配的字符串，通配符从左向右进行匹配#txt# #属于非贪婪匹配# ##属于贪婪匹配#栗子URL=“www.google.com”echo $&#123;URL%.*&#125; #非贪婪匹配，移除最右边.及其后面内容www.googleecho $&#123;URL%%.*&#125; #贪婪匹配wwwecho $&#123;URL#*.&#125; #非贪婪匹配，移除最左边.及其前面内容google.comecho $&#123;URL##*.&#125; #贪婪匹配com 批量重命名和移动综合运用find、rename、mv命令。 拼写检查与词典操作123456#Linux大多数发行版都含有一份词典文件，另外还有一个被称为aspell的拼写检查命令#words --&gt; /usr/share/dict/linux.wordsgrep "^good" /usr/share/dict/linux.wordsaspell 交互输入自动化1234567891011121314151617181920212223242526272829303132#写一个读取交互式输入脚本vi jiaohu.sh#!/bin/bashread -p "Input a number:" numread -p "Input name:" nameecho "You have enterd number:$num, name:$name"echo -e "1\nzhang" | ./jiaohu.shYou have entered number:1, name:hello#orecho -e "1\nzhang" &gt; input.txt./jiaohu.sh &lt; input.txt#交互式输入自动化#用expect实现自动化yum install -y expectvim auto_expect.sh#!/bin/expectspawn ./jiaohu.sh #spawn指定需要自动化哪一个命令expect "Input a number:" #expect提供需要等待的消息send "1\n" #send是要发送的消息expect "Input name:"send "zhang"expect eof #expect eof指明命令交互结束./auto_expect.sh 以文件之名简介Unix将操作系统中的一切都视为文件。 生成任意大小的文件(dd)由于各种原因，可能需要生成一个包含随机数据的文件。 12345#dd命令会克隆给定的输入内容，然后将一模一样的副本写到输出#如果不指定if，dd会从stdin中读取输入；如果不指定of，dd会输出到stdout#/dev/zero是一个字符设备，它会不断返回0值字节(\0)dd if=/dev/zero of=junk.data bs=1M count=1 文本文件的交集与差集12345678910111213#comm命令用于两个文件之间的比较#交集(intersection),差集(set difference), 求差#comm必须使用排过序的文件作为输入echo -e "1\n2\n3" &gt; A.txt &amp;&amp; echo -e "3\n2\n3" &gt; B.txtsort -n A.txt -o A.txt &amp;&amp; sort -n B.txt -o B.txtcomm A.txt B.txt#输出第一列为A独有，第二列为B独有，第三列为交集comm A.txt B.txt -1 -2#-1从输出中删除第一列，-2删除第二列，-3删除第三列 查找并删除重复文件1234#重复文件指的是那些虽然名字不同但内容却一模一样的文件ls -lS #以文件大小排序，识别大小相等的文件md5sum #接下来计算这些文件的校验和 创建长路径目录1mkdir -p /home/zhang/1/22/333 2&gt;/dev/null 文件权限、所有权和粘滞位123456789101112131415161718192021222324252627282930313233343536373839404142#用户(user)，用户组(group)，其他用户(other)ll ./*#d目录，c字符设备，b块设备，l符号链接，s套接字，p管道，-普通文件#用户还有一个称为setuid(S)的特殊权限，它出现在用户的x位置#setuid权限允许用户以其拥有者的权限来执行可执行文件，即便这个文件是由其他用户运行的-rwSrw-r--#组也拥有一个setgid(S)权限，它出现在组的x位置#它允许以同该目录拥有者所在组相同的有效组权限来运行可执行文件-rwxrwSr--#目录有一个特殊权限，叫做粘滞位(sticky bit)(T或t)，出现在其他用户的x位置#当一个目录设置了粘滞位，只有创建该目录的用户才能删除目录中的文件,即便group和other有w权限-rwxr--rwTchmod u=rwx g=rw o=r file1chmod u+x g-w file2chmod 744 file3chmod a+x . -R #以递归方式设置权限chown user.group . -R #以递归方式设置所有权chmod a+t dir1 #设置粘滞位chmod +s fiel4chown root.root file4chmod +s file4./file4 #每次file4都是以root运行#setuid的使用不是无限制的，它只能应用在Linux ELF格式二进制，而不能用于脚本文件。 创建不可修改文件123456#不可修改(immutable),是保护文件不被修改的安全手段之一。#一旦文件被设置为不可修改，任何用户(包括root)都不能修改，除非将其不可修改属性移除chattr #修改文件在Linux第二扩展文件系统(E2fs)上的特有属性chattr +i file1 #这样就无法删除file1chattr -i file1 批量生成空白文件123456789#touch命令可用来生成空白文件，如果文件存在，则可以用它修改文件的时间戳for name in &#123;1..100&#125;.txt;dotouch $namedonetouch -a/-m #更改文件访问/修改时间touch -d "Thu Oct 31 14:20:13 CST 2017" file1 #指定特定时间戳 查找符号链接及其指向目标1234567#符号链接(软链接)只不过是指向其他文件的指针ln -s /usr/bin /binls -l / | grep "^l"find / -maxdepth 1 -type lreadlink /bin #找出链接目标 列举文件类型统计信息1234#在Unix/Linux系统中，文件类型并不是由文件扩展名决定的file /etc/passwdfile -b /etc/passwd 环回文件与挂载(mount)1234567891011#环回文件系统是指那些在文件中而非物理设备中创建的文件系统dd if=/dev/zero of=loopback.file bs=1G count=1mkfs.ext4 loopback.filemount -o loop loopback.file /mnt/loopback #-o loop来挂载环回文件df -humount /mnt/loopback#将ISO文件作为环回文件挂载mount -o loop linux.iso /mnt/iso 生成ISO文件以及混合ISO12345678#可引导光盘自身具备引导能力，也可以运行操作系统或其他软件。不可引导光盘则做不到这些。cat /dev/cdrom &gt; /dev/sdc #sdc指U盘dd if=/dev/cdrom of=/dev/sdc #将ISO写入usb存储设备mkisofs -V "Label" -o /dev/sdc /dev/cdromcdrecord -v dev=/dev/cdrom image.iso 查找文件差异并进行修补diff - compare files line by line 1234567891011121314#补丁文件(patch file)#diff命令可以生成差异文件diff -u file1 file2 #一体化形式输出diff -u file1 file2 &gt; diff.patchpatch -p1 file1 &lt; diff.patch #得到file2patch -p1 file2 &lt; diff.patch #得到file1patch -R file1 &lt; diff.patch; patch -R file2 &lt; diff.patch #还原#diff也能够以递归的形式作用于目录，它对目录中所有内容生成差异输出diff -Naur dir1 dir2#-N将所有确实文件视为空文件， -a将所有文件视为文本文件#-u生成一体化输出， -r遍历目录下所有文件 栗子： 1234567891011121314151617181920212223242526272829303132333435363738echo -e '1\n1\n1\n1' &gt; /tmp/1.txtecho -e '1\n1\n0\n1' &gt; /tmp/2.txt#比较diff -u 1.txt 2.txt--- 1.txt 2018-12-14 16:08:36.457495835 +0800+++ 2.txt 2018-12-14 16:08:37.574495820 +0800@@ -1,4 +1,4 @@ 1 1-1+0 1#解释--- 1.txt 2018-12-14 16:08:36.457495835 +0800+++ 2.txt 2018-12-14 16:08:37.574495820 +0800#第一部分，是文件的基本信息#---表示变动前的文件#+++表示变动后的文件@@ -1,4 +1,4 @@#第二部分，变动的位置用两个@作为起首和结束。#-号表示第一个文件(1.txt), 1表示第一行，4表示连续四行。也就是第一个文件从第一行开始连续四行#+号表示第二个文件(2.txt), 1表示第一行，4表示连续四行。 1 1-1+0 1#第三部分表示变动的具体内容#除了有变动的那些行以外，也是上下文各显示3行。它将两个文件的上下文合并显示在一起，所以称为合并显示#每一行最前面的标志位，空表示无变动，减号表示第一个文件删除的行，加号表示第二个文件新增的行 head与tail123456head file1; tail file1 #head与tail默认打印10行head -n 5 file1; tail -n 6 file1 #指定行数head -n -5 file1 #打印除了最后5行外所有行tail -n +(5+1) file1 #打印除了开始5行外所有行tail -f /var/log/nginx/access.log #--follow，动态关注文件 只列出目录的其他方法1234ls -d .ls -l . | grep &quot;^d&quot;ls -F . | grep &quot;/$&quot;find . -maxdepth 1 -type d pushd和popd1234567891011121314#在命令行中使用pushd和popd快速定位，pushd和popd以栈的方式运作#当没有鼠标时，复制粘贴就不怎么实用了#pushd和popd可以用于在多个目录之间进行切换而无需复制并粘贴目录路径pushd /home/user1; pushd /home/user2; pushd /home/user3 #将路径添加到栈pushd +2 #切换到/home/user3popd #移除最近添加入栈的目录cd /root; cd /home/usercd - #回到上次的目录cd .. #切换到上一级目录cd ~ #切换到用户主目录 统计文件的行数、单词数、字符数1234567#wc(word count)，是一个统计工具wc -l file1 #统计行数wc -w file1 #统计单词数wc -c file #统计字符数wc -L file #打印最长行长度wc file1 #行、单词、字符数 目录树123456789#tree命令是以图形化的树状结构打印文件和目录,在Linux发行版中默认未安装yum install -y treetree /home/zhangtree /home/zhang -P "*.sh" #只标记出.sh文件tree /home/zhang -I "*.sh" #标记出除.sh文件外所有文件tree /home/zhang -h #显示大小tree /home/zhang -H http://localhost -o tree.html #以html形式输出目录树 让文本飞简介shell脚本可以将sed, awk, grep, cut等这类优美的工具组合在一起，用于解决文本处理相关问题。 正则表达式(RE)正则表达式是一种用于文本匹配的形式小巧、具有高度针对性的编程语言。只依靠通配符技术，能够匹配的文本范围相当有限。 正则表达式基本组成 正则表达式 描述 ^ 行起始标记 $ 行尾标记 . 匹配任意一个字符 [] 匹配包含在[]中的任意一个字符 [^] 匹配出[^]之外任意一个字符 [-] 匹配[]中范围内的任意一个字符 ？ 重复0或1次 + 重复&gt;=1次 * 重复&gt;=0次 () 创建一个用于匹配的子串 {n} 重复n次 {n, } 重复&gt;=n次 {n,m} 重复n到m次 \ 转义字符 竖线l 匹配竖线l两边任意一项 POSIX字符类 POSIX字符类(POSIX character class),是一个形如[:…:]的特殊元序列，它用于匹配特定的字符范围。 正则表达式 描述 [:alnum:] 字母与数字字符 [:alpha:] 字母字符 [:blank:] 空格与制表符 [:digit:] 数字字符 [:lower:] 小写字母 [:upper:] 大写字母 [:punct:] 标点符号 [:space:] 所有空白字符 元字符 元字符(meta character)，是一种Perl风格的正则表达式，只有一部分文本处理工具支持它。 正则表达式 描述 \b 单词边界 \B 非单词边界 \d 单个数字字符 \D 单个非数字字符 \w 单个单词字符(数字，字母和_) \W 单个非单词字符 \s 单个空白字符 \S 单个非空白字符 \n 换行符 \r 回车 123456#匹配一个ipv4地址[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;#匹配一个邮箱地址[\w]+@[\w]\.com 用grep在文件中搜索文本grep命令是Unix中用于文本搜索的工具，它能够接受正则表达式和通配符。 12345678910111213141516171819202122grep "匹配文本/通配符" file1 file2... --color=auto #重点标记匹配grep -E "正则表达式" fileegrep "正则" filegrep -v #反向匹配grep -c #统计匹配行数grep -n #打印出匹配的行号grep -o #唯一匹配grep -l "匹配" file1 file2 #返回匹配的文件名grep -R #递归匹配grep -i #忽略大小写grep -e "匹配1" -e "匹配2" #匹配多个样式grep -f match.txt file1 #从match.txt文件读取匹配grep "匹配" --include=*.&#123;sh,txt&#125; --exclude=*.log --exclude-dir=/home/user -r /home #包括或排除文件-A/-B n #输出匹配 之后/之前 n行-c n #输出匹配 前后 n行#正则匹配多个egerep "(a|b)" 用cut按列切分文件cut是一个将文本按列进行切分的小工具，它也可以指定每列定界符。在cut的术语中，每列都是一个字段。 1234567#制表符'\t' 是cut默认的定界符cut -d' ' -f1 1.txt #-d指定分隔符，-f打印第几个字段cut -f1,2,3 #打印1,2，3列-c字符； -b字节；cut -c 1-5 1.txt #打印1-5字符cut -c -2 1.txt #打印前2个字符cut -c 3- #打印第3个字符到行尾 统计特定文件词频1234#单词解析可以用 关联数组,正则表达式配合sed,awk,grep等工具来完成#关联数组中，将单词作为数组索引，单词次数作为数组值egrep -o "\b[:alpha:]+\b" #匹配单词 sed入门sed是stream editor(流编辑器)的缩写，它是文本处理中非常重要的工具。能够完美地配合正则表达式使用。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#sed - stream editor for filtering and transforming text#字符/在sed中最为定界符使用#替换#sed 's/匹配样式/替代字符串/'sed 's/pattern/repalce/' file #替换sed -i 's/pattern/repalce/' file #将替换应用于fileecho "1.txt" &gt; 1.txt &amp;&amp; sed 's/txt/haha' 1.txt #在输出中用haha替换txtsed -i 's/txt/haha/' 1.txt #将1.txt文件中的txt用haha替换掉#-i选项替换原文件echo "hahaha" | sed 's/ha/HA/g' #全部替换echo "hahaha" | sed 's/ha/HA/2g' #指定位置替换，从第2处开替换全局#移除匹配样式的行sed '/pattern/dsed '/^$/d' ##移除空白行#在sed中用&amp;标记已匹配字符串echo "A wonderful goal" | sed 's/\w\+/[&amp;]/g' #\w\+匹配每一个单词#子串匹配标记\1,\2...echo "1st 2nd 3rd" | sed 's/\(\w\+\) \(\w\+\) \(\w\+\)/\2 \1 \3/'2nd 1st 3rd#将\2和\1交换次序，(),+等在sed中要转义，否则要报错#组合多个表达式sed 'expression1; expression2; ...echo "aabbcc" | sed 's/a/A/; s/b/B/; s/c/C/g'AaBbCC#双引号 " " 内的特殊符号（如$等），可以保有原本的特性#单引号 ' ' 内的特殊字符则仅为一般字符（纯文本）#引用text=helloecho 'hello world' | sed "s/$text/HELLO/"HELLO world awk入门awk被设计用于数据流，它可以对列和行进行操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#awk ‘begin&#123;print "start"&#125; pattern &#123;command&#125; end&#123;print "end"&#125;’ fileawk '&#123;sum += $1&#125;; &#123;print sum&#125;'#awk脚本由:begin块、end块和能使用模式(pattern)匹配的通用语句块 组成#3个部分都是可选的#awk也可以从stdin中读取内容cat /etc/passwd | awk -F: '&#123;print $1&#125;' #-F指定界定符#awk中的特殊变量#NR：记录数量(number of records)，对应于当前行号#NF：字段数量(number of fields)，对应于当前行的字段数#$0：执行过程中当前行的文本内容#$1,$2...$NF：第1个/2个.../最后一个 字段的内容echo -e "L1 1\nL2 22\nL3 333" | awk '&#123;print NR NF $0 $1 $2&#125;'# NR NF $0 $1 $2 $NF=最后一个=$2 1 2 L1 1 L1 1 1 2 2 L2 2 L2 2 2 3 2 L3 3 L3 3 3#将外部变量传递给awk#-v选项可将外部值传递给awk# -v var=val --assign=var=valvar='12345'echo | awk -v v1=$var '&#123;print v1&#125;'#多个变量var1=111; var2=222echo | awk '&#123;print v1,v2&#125;' v1=$var1 v2=$var2#变量来自文件而非标准输入awk '&#123;print v1,v2&#125;' v1=$var1 v2=$var2 file#用样式对awk进行过滤处理awk 'NR &lt; 3,NR==4' 1.txt #行号&lt;5的行awk '/linux/' 1.txt #匹配带有linux的行（可用re）awk '!/linux/' 1.txt #!匹配不带linux的行#设置定界符awk -F: '&#123;print $1&#125;' /etc/passwdawk '&#123;FS=":"&#125; &#123;print $1&#125;' /etc/passwdawk '&#123;FS=":"; print $1&#125;' /etc/passwd#从awk中读取命令输出，用getline读取行echo | awk '&#123;"grep root /etc/passwd" | getlin out; print out&#125;'root:x:0:0:root:/root:/bin/bash#在awk中使用循环awk '&#123;for(i=1;i&lt;4;i++) &#123;print $i&#125;&#125;' 2.txt #输出第1,2,3列#使用awk删除某列awk -F' ' '&#123;$1=null;$2=null;print&#125;' ./file 对文件中的行、单词、字符进行迭代123456789101112131415161718192021222324252627282930313233#迭代文件中的每一行echo -e "1\n22\n333" | while read line;do echo $line;donegrep "bash" /etc/passwd | while read line;do echo $line;done#1#22#333#迭代一行中的每一个单词echo "1 22 333" | while read line;do for word in $line;do echo $word;done;done#1#22#333#迭代一个单词中的每一个字符echo "abc" | while read line;do for word in $line; do for((i=0;i&lt;$&#123;#word&#125;;i++)); do echo $&#123;word:i:1&#125;; done; done;done#写成一行echo "abc" | while read line; do for word in $line; do for((i=0;i&lt;$&#123;#word&#125;;i++)); do echo $&#123;word:i:1&#125;; done; done; done#a#b#c#$&#123;#word&#125;返回变量word的长度 按列合并文件(paste)可以使用paste命令实现列拼接12345678#paste - merge(整合) lines of filesecho -e "1\n2\n3" &gt; 1.txt &amp;&amp; echo -e "Line1\nLine2\nLine3" &gt; 2.txtpaste 1.txt 2.txt1 Line12 Line23 Line3#默认定界符是制表符，用-d指定paste 1.txt 2.txt -d',' 打印文件或行中的第n个单词或n列12awk -F':' '&#123;print $1,$3&#125;' file1cut -d':' -f 1,3 file1 打印不同行或样式之间的文本123456awk 'NR==1,NR==10' /etc/passwdawk 'NR==1,NR==10' /etc/passwd | awk -F":" '&#123;print $1,$NF&#125;' #打印特定行内的特定列awk '/start_pattern/, /end_pattern/' file #打印start到end之间的内容,可使用reawk '/root/, /zhang/' /etc/passwd #打印root到zhang之间内容awk '/^ro.?t'/, /bash$/' /etc/pass 以逆序形式打印行可以使用awk, tac完成。tac就是反过来的cat。 123#tac - 反转显示文件中的行，行内的内容无法用tac反向排列tac 1.txtawk '&#123;lifo[NR]=$0; lno=NR&#125; END&#123; for(;lno&gt;-1;lno--) &#123;print lifo[lno]&#125;;&#125;' 1.txt 解析文本中的电子邮件和URL从给定的文件中解析出所需要的文本是我们从事文本处理时的一项任务。 grep, egrep, fgrep - print lines matching a pattern 123456789#egrep#匹配一个邮箱地址egrep -o '[a-zA-Z0-9.]+@[0-9a-zA-Z.]+\.[a-zA-Z]&#123;2,4&#125;' emails.txt#匹配一个URL地址egrep -o "http://[a-zA-Z0-9.]+\.[a-zA-Z]&#123;2,3&#125;" urls.txt 打印某个样式之前/之后n行(grep)123grep "zhang" /etc/passwd -A 5 #Atergrep "zhang" /etc/passwd -B 5 #Beforegrep "zhang" /etc/passwd -C 5 #前后五行都打印 在文件中移除包含某个单词的句子只要能写出正确的正则表达式(Regular Expression)，那就手到擒来 1sed 's/[^.]*handsome boy[^.]*\.//g' file.txt #句子以.结束 文本切片与参数操作12345678910111213141516#替换变量内容中的部分文字var="One two three"echo $&#123;var/t/T&#125; #只替换了一个#One Two three#指定字符串起始位置和长度#$&#123;变量:开始部分:长度&#125;$&#123;vari:start:length&#125;echo &#123;var:0:2&#125; #Onecho &#123;var:1:6&#125; #ne two#起始字符的索引是0,将最后一个字符索引记为-1echo $&#123;var:(-1)&#125; #eecho $&#123;var:(-3):3&#125; #ree 一团乱麻？没这回事入门本章会研究一些用于解析网站内容、下载数据、发送数据表单以及网站颇为任务自动化之类的实例。我们可以仅用几行脚本就将很多原本需要通过浏览器交互进行的活动管理自动化。通过命令行工具利用HTTP协议所提供的功能，我们可以用脚本解决大部分Web自动化的问题。 网站下载(wget,curl)使用一些命令行下载工具，从给定的URL中下载文件或网页。 wget是一个用于文件下载的命令行工具，选项多且用法灵活。 123456789101112131415161718192021222324252627282930313233343536373839#Wget - The non-interactive(非交互式) network downloaderwget URL1 URL2...wget http://xxx.com/nginx-1.12.0.tag.gzwget https://xxx/a.rpm http://xxxx/bb.rpm#指定文件名，指定信息输出(wget默认是stdout)wget http://mirrors.aliyun.com/repo/Centos-7.repo -O aliyun.repo -o ./wget.logwget URL -t 5 #-t，重试次数#下载限速wget --limit-rate=10m URL #下载限速wget -Q 100m URL #指定下载配额#端点续传#wget进行的下载在完成前被中断，从断点开始下载wget -c URL#用cURL下载#cURL是一个比wget更强大的高级命令工具#和wget不同，curl并不将下载数据写入文件，而是写入stdout，因此必须重定向到文件#复制或镜像整个网站#wget有一个选项可以使其像爬虫一样以递归方式手机网页上所有URL链接，并逐个下载#这样一来就可以下载一个网站的所有页面wget --mirror URL#-m(--mirror) -N -r -l inf --no-remove-listing 的缩写形式。或 wget -r -N -l DEPTH URL#-r递归下载，-l指定递归深度，-N(timestamp)只获取比本地时间新的文件#访问需要认证的HTTP或FTP页面wget --user "username" --password "pass" URL#如未在命令行内输入密码，则会由网页提示手动输入 以格式化纯文本下载网页(links)网页其实就是包含HTML标记和其他诸如Javascript，CSS等元素的HTML页面。HTML标记是网页的基础，也许需要解析网页来查找特定的内容。 links,是一个基于命令行的Web浏览器 123456789101112#links - lynx-like alternative character mode WWW browser#在命令行中浏览一个网页links www.baidu.com#以ASCII形式下载网页links --dump URL &gt; URL.txt#打开本地html文件links 1.html cURL入门cURL支持包括HTTP、HTTPS、FTP在内的众多协议。它还支持POST、cookie、认证、从指定偏移处下载部分文件、参照页(referer)、用户代理字符串、扩展头部(extra header)、限速、文件大小限制、进度条等特性。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#curl - transfer a URL#cURL通常将下载文件输出到stdout，将进度信息输出到stderr#要想避免显示进度信息，可使用--silent#curl可用来下载、发送各种HTTP请求、指定HTTP头部等操作curl URL --silent #输出到stdout#-O写入文件，文件名从URL中解析curl http://www.baidu.com/index.html -O --silent #创建index.html#-o将数据写入指定文件curl URL -o baidu.html --progress #--progress显示进度条links baidu.html#端点续传#和wget不同，cURL包含更高级的下载恢复特性，能够从特定的文件偏移处继续下载#curl可以通过指定一个偏移量来下载部分文件手动：curl URL/file -C offset #偏移量以Byte为单位的整数自动：curl -C -URL #自动续传#用cURL设置参照页字符串, --referer#参照页(referer)是位于HTTP头部中的一个字符串，用来标识用户从哪个页面到达当前页面的#如果用户点击网页A中某个链接，转到了网页B。那么网页B头部的referer会包含网页A的URLcurl --referer Referer_URL target_URLcurl --referer http://www.baidu.com http://jianshu.com#用cURL设置cookie, --cookie#可以用curl来存储HTTP操作过程中使用到的cookie#cookie用key=value形式，指定多个用 分号 分隔curl URL --cookie "user=AAA;name=bbb"curl URL --cookie-jar cookie.txt #将cookie另存为#用cURL设置用户代理字符串, --user-agent#如果不指定代理，一些需要用户代理的网页就无法显示curl URL --user-agent(-A) "Mozilla"#用-H "头部信息"传递多个头部信息curl -H "Host:www.haha.com" -H "Accept-language: en" URL#限定cURL可占用的带宽curl URL --limit-rate 10m#指定最大下载量curl URL --max-filesize 大小(Bytes)#用cURL进行认证，-u username:password指定用户名和密码curl -u user:pass URLcurl -u user URL #手动输入密码#只打印响应头部信息(无数据部分), -Icurl -I URL 从命令行访问163邮箱12curl -u user http://mail.163.com#手动输入密码 制作图片抓取器及下载工具可以用脚本解析图像文件并将图片自动下载下来。 1234567curl -s URL | grep -o "&lt;img src=[^&gt;]*&gt;" | sed 's/&lt;img src=//g; s/&gt;//g' &gt; img.list#匹配图片的URL，可能还需要细化修改#不同的URL可能有不同的规则，根据实际情况取出img的URL#下载图片wget $URL 或 curl -s -O $URL 查找网站中的无效链接(lynx)将查找无效链接的工作自动化，那就比纯手动厉害多了！ 123456789lynx -traversal URL #会将URL中所有链接生成到reject.dat文件中sort -u reject.dat | while read linkdo output=`curl -I $link -s | grep "HTTP/.*OK"` if [[ -z $output ]] then echo $link fidone &lt; links.txt 跟踪网站变更(curl+diff)可以编写一个定期运行的变更跟踪器(change tracker)，一旦发生变更，跟踪器便会发出声音或发送提示信息。在不同时间检索网站，然后利用 diff 命令进行比对。 123curl URL --silent -o `date +%F`.html #第一次curl URL --silent -o `date +%F`.html #第二次diff -u 第一次 第二次 以POST方式发送网页并读取响应POST 和 GET 是HTTP协议中用于发送或检索信息的两种请求类型。在GET请求方式中，利用网页的URL来发送参数(“键-值”)；而POST方式用于提交表单，如提交用户名、密码以及检索登录页面等。 1234curl URL -d “postarg=AABBCC” #-d,http post datacurl URL -d "post1=key1&amp;post2=key2&amp;post3..." #指定多个数据wget URL -post-data "post1=key1" Plan B 简介提取快照和备份数据都是重要的工作，我们可以通过shell脚本来实现备份自动化。归档和压缩对于SA来说同样很重要，有多种压缩格式。加密是一种保护数据的方法，为了减少加密数据的大小，文件在加密前通常需要先归档和压缩。 用tar归档tar命令可以用来归档文件(tar archives tar)。可以将多个文件和文件夹打包为单个文件，同时还能保留所有的文件属性。由tar命令创建的文件通常称为tarball。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#归档文件，-c(create file)tar -cf 1.tar [sources] #-f(specify filename)指定文件名#文件名必须紧跟在-f之后tar -cvf txt.tar *.txt #-v(verbose)详细信息#向已归档文件中添加文件，-rtar -rvf txt.tar *.html#列出归档文件中的内容，-ttar -tf txt.tar #列出归档内容tar -tvf txt.tar #列出内容详细信息#从归档文件中提取文件或文件夹，-x(exact)tar -xf txt.tar #默认提取到当前目录#-C指定提取目录tar -xvf txt.tar -C /dir/path#只提取归档中特定文件tar -xf txt.tar 1.txt 1.html -C /tmp #只会提取1.txt和1.html文件#在tar中使用stdin和stdouttar -cvf - *.text | tar -xvf - -C /tmp#拼接两个归档文件，-Atar -Af txt.tar html.tartar -tvf txt.tat #验证是否成功#添加选项，可以将指定的任意文件加入到归档文件中。如果同名文件已存在，不会覆盖源文件，那么结果就是归档中包含了多个同名文件#通过检查时间戳来更新对党文件中的内容，-u#只有比归档文件中同名文件 更新(newer) 才添加tar -uvf html.tar 1.html#比较归档文件与文件系统中的内容，-dtar -df txt.tar 1.txt 2.txt#从归档文件中删除文件，--deletetar -f txt.tar --delete 1.txt 2.txt#从归档文件中排除部分文件,--excludetar -cf all.tar ./* --exclude="*.html" #排除.html文件tar -cvf txt.tar *.txt --exclude="1.txt"#打印总字节数,--totalstar -cf all.txt ./* --totals#压缩tar归档文件，指定不同压缩格式#-z, .tar.gz#-j, .tar.bz2#--lzma, .tar.lzma,#.tar.lzotar -czvf txt.tar.gzip *.txttar -xzvf txt.tar -C /dir/path#tar后删除原文件tar -czvf txt.tar.gz ./txt --remove-files 用cpio归档cpio是类似于tar的另一种归档格式。它多用于RPM软件包、Linux内核和initramfs文件等。cpio通过stdin获取输入，并将归档写入stdout。 12345678touch file&#123;1..4&#125;echo file1 file2 file3 file4 | cpio -ov file.cpio#-o指定输出，-v打印归档文件列表#-i指定输入，-t列出归档中文件cpio -it &lt; file.cpio 用gunzip或gzip压缩gzip是GNU/Linux下常用压缩格式。gzip,gunzip都可处理gzip压缩文件类型。gzip只能够压缩单个文件，而无法对目录和多个文件进行归档。因此需要先交给tar，然后再用gzip压缩 12345678910111213141516171819202122232425gzip file #file.gz，会覆盖原文件gunzip file.gz #file，也会删除原文件#列出压缩文件的属性信息，-lgzip -l file.gz#指定gzip的压缩级别，--fast或--best--fast 最低压缩比，最快速度完成--best 最高压缩比，最慢速度完成#将gzip与归档文件结合，-ztar -czvf txt.tar.gzip ./*.txt#-a指定从文件扩展名自动判断压缩格式tar -cavf txt.tar.gzip ./*.txt#tar只能从命令行中接收有限个文件，要解决这个问题，可以写一个循环并添加-r选项#解压缩，-xtar -xzvf txt.tar.gziptar -xavf txt.tar.gzip -C /dir/path 用bunzip或bzip压缩bzip2通常能够生成比gzip更小(压缩比更高)的文件。 1234567891011121314151617181920212223bzip2 file #file.bz2,同理会覆盖原文件bzip2 file -k #保留原文件bunzip2 file.bz2 #解压缩bunzip file.bz2 -k#从stdin读入并写到stdoutcat file | bzip2 -c &gt; file.bz2#将bzip2与归档文件结合，-jtar -cvjf 1.tar.bz2 ./1.*tar -cavf 1.tar.bz2 ./1.* #-a根据文件扩展名自动判断压缩格式tar -xjvf 1.tar.bz2tar -xavf 1.tar.bz2 -C /tmp#压缩比#从1级(速度最快，压缩率最低)到9级bzip -9 -k file#对成千上万的文件进行归档，需要借助 循环和-r选项 lzma压缩lzma是一个较新的压缩工具，它提供了比gzip或bzip2更好的压缩率。xz, unxz, xzcat, lzma, unlzma, lzcat - Compress or decompress .xz and .lzma files 1234567891011121314151617lzma file #file.lzma,同样也会删除原文件lzma file -k #保留原文件unlzma file.lzma#从stdin读入并写入stdoutcat file | lzma -C &gt; file.lzma#与tar相结合,--lzmatar -cvf 1.tar.lzma ./1.* --lzmatar -cavf 1.tat.lzma ./1.* #自动判断tar -xvf 1.tar.lzma --lzmatar -xavf 1.tar.lzma -C /tmp#压缩率#从1级到9级(压缩级别最高，速度最慢)#对成千上万的文件，需要使用循环和-r选项 zip归档和压缩zip在Linux下不如gzip,bzip2那么广泛，但在Internet上的文件通常都采用这种格式。zip - package and compress (archive) files 12345678910111213141516171819zip file.zip fileunzip file.zip#与lzma,gzip,bzip2相比，zip完成后不会删除原文件#对目录和文件进行递归操作,-rzip -r dir.zip /root/test ./file#向归档文件中增加内容，-uzip dir.zip -u newfile#从压缩文件中删除内容，-dzip -d dir.zip file#列出归档文件中内容unzip -l dir.zip 超高压缩率的squashfs文件系统squashfs是一种只读型的超高压缩率文件系统。这种文件系统能够将 2GB-3GB的数据压缩成一个700MB的文件。你有没有想过Linux Live CD是怎样运行的？当Live CD启动后，它会加载一个完整的Linux环境。这就是利用了一种被称为squashfs的只读型压缩文件系统。它将根文件系统保存在一个压缩过的文件系统文件中。这个文件可以使用环回的形式来挂载并对其中的文件进行访问。一次当进程需要某些文件，可以将它们解压，然后载入内存中使用。如果需要构建一个定制的Live OS，或是需要超高压缩率的文件并且无需解压就可以访问文件，那么squashfs的相关知识就能派上用场。要解压个头较大的压缩文件，需要花费不少时间。但如果将文件以环回形式挂载，速度就飞快，因为只有出现访问请求的时候，对应的那部分压缩文件才会被解压缩。而普通的解压缩方式是首先解压缩所有的数据。 环回文件系统就是指那些在文件中而非物理设备中创建的文件系统。比如我们可以创建一个文件，然后把这个文件格式化为我们常见ntfs、exfat或者ext4等文件系统格式，然后把它挂载在一个目录上使用。 如果你有一张Ubuntu CD，可以在CDRom Root/casper/filesystem.squashfs中找到文件.squashfs。squashfs在内部采用了gzip和lzma这类压缩算法。 mksquashfs - tool to create and append to squashfs filesystems 1234567891011121314151617181920yum install squashfs-tools -y#创建squashfs文件mksquashfs source compressfile.squashfsmksquashfs /etc etc.squashfs#/etc(67M) --&gt; etc.suqashfs(18M)#要挂载squashfs文件，利用环回形式进行挂载mkdir /mnt/squashmount -o loop etc.squashfs /mnt/squash#此处挂载使用etc.squashfs文件系统#如果直接查看etc.squashfs，就是一个普通文件，但是挂载以后所有文件都出现了umount /mnt/squash#在创建squashfs文件时排除指定文件，-emksquashfs /etc etc.squashfs -e /etc/passwd /etc/shadow /etc/*.txt#在挂载之后就没有相关文件了 加密工具与散列加密技术主要用于防止数据遭受未经授权的访问。Linux下某些工具用于执行加密和解密，使用加密算法散列值来验证数据完整性。 crypt, gpg, base64, md5sum, sha1sum, openssl的用法 ccyptccrypt是为了取代UNIX crypt而设计的，这个实用工具可用于文件和数据流加密及解密。 ccrypt - encrypt and decrypt files and streams 12345678910ccrypt 1.txt #会要求输入口令(encryption key)#之后会生成1.txt.cpt覆盖原文件#更改key,-xccrypt -x 1.txt.cpt #输入old key和new key#解密，-d(--decrypt)ccrypt -d 1.txt.cpt #输入key解密 gpggpg(GNU privacy guard,GNU隐私保护)，是一种应用广泛的加密方案。它采用签名密钥技术保护文件内容，只有经过认证的用户才能访问数据。我们对gpg签名早已耳熟能详。 gpg - OpenPGP encryption and signing tool 12345#加密，-c(--symmetric)对称加密gpg -c file #会要求输入口令(Passphrase)，生成file.gpg#解密gpg file.gpg base64base64是一组类似的编码方案(encoding scheme)，它通过将ASCII字符转换成以64为基数的形式(radix-64 representation)来用ASCII字符串描述二进制数据。base64可用来对 编码和解码 base64字符串。 base64 - base64 encode/decode data and print to standard output 123456#将文件编码为base64格式base64 file &gt; outputfilecat file | base64 &gt; outputfile#解码,-dbase64 -d outputfile &gt; file md5sum与sha1summd5sum 和 sha1sum 都是单向散列算法(unidirecrional hash algorithm)，均无法逆推出原始数据。它们通常用于验证数据完整性或为特定数据生成唯一的密钥，因为通过分析文件内容，它们可以为每个文件生成一个唯一的密钥。 这种类型的散列算法是存储密码的理想方案。密码使用其对应的散列值来存储。如果某个用户需要认证，读取该用户提供的密码并转换成散列值，然后将其与之前存储的散列值进行比对。将密码以明文的形式存储是非常危险的事情，它面临密码泄露的危险。而因为 md5sum和sha1sum 是单向散列算法，所以密码使用散列值存储是很安全的。 123456789101112echo "1.txt" &gt; 1.txtmd5sum 1.txt #生成密钥到stdout#39061daa34ca3de20df03a88c52530ea 1.txtsha1sum file #生成密钥到stdout#659fcbc505db207c03b5c4c0b6981d63286abe21 1.txt#查看/etc/shadow中密码的散列值awk 'NR==1' /etc/shadow | awk -F: '&#123;print $2&#125;' #root密码散列#$6$BxpV48gPsjuq6.pF$wE7pUDwtOI.v64kd5folG68yUt2UAQDTUGgKa5Iz69GaupEoRAdCeerP8nRKXo48c4azutUCGhnDgzd1qe8YX0 shadowlike散列(salted散列)shadow密码通常都是salted密码，所谓SALT就是额外的一个字符串，用来起一个混淆的作用，使加密更加不同里被破解。salt由一些随机位组成，被用作密钥生成函数的输入之一，以生成密码的salted散列值。 12345678910111213#/etc/passwd里面的密码散列类型就是salted散列#查看root密码对应的散列值head -1 /etc/shadowroot:$6$ZlHRCZG2iRwQUXAu$RAEDH97nPdZB2RK20npua6Qf6jB7osatoC99ow3LtPQ6aORdLISYC7/4iTYU162emkQLt4ZafdgjyAeoSB7IU0::0:99999:7:::#openssl - OpenSSL command line tool#shadow密码是使用openssl生成#将SALT_STRING替换为随机字符串，同时将pass替换成你想测试的密码openssl -1 -salt SALT_STRING passwd 用rsync备份系统rsync借助差异计算以及压缩技术来最小化数据传输量。相较于cp命令，它的优势在于使用了高效的差异算法(difference algorithm)。它还支持网络数据传输。在进行复制的同时，rsync会比较源端和目的端的文件，只有当文件有更新是才进行复制。默认情况下，rsync并不会在目的端删除源端已不存在的文件。 rsync - a fast, versatile, remote (and local) file-copying toolinotifywait - wait for changes to files using inotify 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#-a进行归档，-v详细信息rsync -av source destinationrsync -av /etc /tmp#异地cprsync -av source username@host:PATHrsync -av username@host:PATH destination#rsync借助于ssh，可以使用ssh无秘钥认证rsync -av /etc zhang@192.168.1.11:~#-z, --compress compress file data during the transferrsync -avz zhang@192.168.1.11:/etc /tmp#注意，路径格式rsync /etc /tmp #整个/etc目录rsync /etc/ /tmp #/etc目录下所有内容#显示进度，--progressrsync -avz --progress /etc /tmp#排除部分文件，--excludersync -avz /etc /tmp --exclude=/etc/nginx --exclude "*.txt"#更新rsync时，删除不存在的文件，--delete#默认情况下，rsync并不会在目的端删除源端已不存在的文件rsync -avz /etc zhang@192.168.1.1:~ --delete#定期调度crontab -e0 */10 * * * rsync -avz /etc user@host:PATH#实时同步，inotifywait+rsyncyum install inotify-tools -y#-m(monitor),-r(recursive),-q(--quiet)静默模式，-e(event)vi inotify_rsync.shinotifywait -mrq -e creat,delete,modify,move --exclude "^.*\.filepart$" /etc | while read filedorsync -az --exclude=".*" --exclude="*.swp" --exclude=".filepart" --delete /etc /tmp &gt; /dev/null 2&gt;$1done 用Git备份版本控制维护和恢复变更最好的方法是使用版本控制系统。由于代码变更频繁，版本控制系统多用于软件开发和代码维护。Git(GNU it)是有名气也是最高效的版本控制系统。我们可在非编程环境下用Git备份普通文件。 git - the stupid content tracker 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354mkdir /home/zhang/gittestcd /home/zhang/gittest#在源主机中添加用户信息git config --global user.name "username" #设置用户名git config --global user.email "someone@example.com" #设置邮箱#创建一个空的Git版本库或初始化一个老版本git init#记录变更到版本库git commit#添加远程git目录并同步备份git remote add origin user@host:/home/zhang/gittest#为git跟踪(git tracking)添加或删除文件#add,添加内容至索引git add *#git add *.txt; git add *.ph #添加部分文件#删除不需要跟踪的文件和文件夹#rm,从工作去和索引删除文件git rm file#git rm *.txt#检查点或创建备份点(check point)git commit -m "Commit Message"#push,更新远程git push#用Git恢复数据#log,显示提交日志git log#返回之前某个版本或状态git checkout xxxxxxxx(Commit ID)#clone,克隆一个版本库到本地git clone URLgit clone user@host:PATH 用dd克隆磁盘dd命令能用于克隆任何类型的磁盘，如硬盘、闪存、CD、DVD及软盘。可能需要创建所有分区的副本而不仅仅是复制内容，包括硬盘分区、引导记录、分区表等信息。 使用dd的时候，要留意参数的顺序。错误的参数会损毁全部数据。dd基本上算是一个比特流复制器(bitstream duplicator),它可以将来自磁盘的比特流写入文件，也可以将来自文件的比特流写入硬盘。 dd - convert and copy a file 123456789101112dd if=source of=target bs=block_size count=count#bs块大小，count块数dd if=/tmp/centos7.iso of=/dev/sdc#/dev/zero是一个字符设备，它总是返回字符'\0'dd if=/dev/zero of=./file bs=10m count=100#用环回(loop back)方法可将任何由dd生产的文件镜像进行挂载mount -o loop file /mnt 无网不利简介网络是计算机系统中重要的部分。我们以Tcp/Ip为协议栈，所有操作都是基于它进行的。 一些使用网络的应用通过打开并连接到防火墙端口进行运作，而有的管理任务可以通过网络进行。 网络小知识网络接口(Interface)用来连接网络。在每个系统中，默认都有一个称之为环回接口的lo，这个接口指向当前主机本身。操作系统维护者一个被称为路由表(routing table)的表格，它包含了分组如何转发以及通过网络中的哪些节点转发的消息。metric是路由算法用以确定到达目的地的最佳路径的计量标准，如路径长度。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#显示网络接口、子网掩码等详细信息ifconfig #/sbin/ifconfig#显示某个特定接口ifconfig eth0#提取IP地址ifconfig eth0 | egrep -o "inet [^ ]*" | grep -o "[0-9.]*"#设置网络接口的IP地址和子网掩码ifconfig eht0 192.168.1.11ifconfig eth0 192.168.1.11 netmask 255.255.255.0#远程的时候，千万别乱改IP，不然连不上你就要去机房了#MAC地址欺骗ifoconfig eth0 hw ether 11:22:33:44:55:66#域名服务器与DNScat /etc/resolv.conf#添加域名服务器echo "name 114.114.114.114" &gt;&gt; /etc/resolv.conf#nameserver 114.114.114.114#一个域名可以分配多个地址，DNS只会返回其中一个#要想获得域名所有IP地址，需要使用DNS查找工具#DNS查找工具host www.baidu.comnslookup www.baidu.com#自定义解析cat /etc/hostsecho "192.168.1.11 www.zhang.me" &gt;&gt; /etc/hosts#设置默认网关，显示路由表信息#路由表routeroute -n #以数字形式显示地址#设置默认网关route add default gw $ip $interfaceroute add default gw 192.168.1.1 eht0#显示分组途经的所有网关地址traceroute www.baidu.com pingping使用 网际控制报文协议(Internet Control Message Protocol,ICMP)的echo分组。如果分组能够送达且该主机为活动主机，那它就会发送一条回应。一旦主机不可到达，ping返回错误信息”Destination Host Unreachable”。 123456ping 192.168.1.1#往返时间(Round Trip Time,RTT)#发送分组数量ping $URL -c 6 列出网络上所有活动主机当涉及大型局域网时，可能需要检查网络上的其他主机的活动状态。一台非活动主机可能是：没有开机；网络连接有问题；主机禁ping；防火墙问题。 当我们要检测ip时，在一个脚本中，每一次ping都是依次执行。即使所有的ip地址都是彼此独立，由于编写的是顺式程序(sequential program)，ping命令也只能按顺序执行。每次执行一个ping命令。都要经历一段延迟——“发送echo分组，并接收或等待回应超时”。 要是处理几百个ip地址的话，这个延时就真不短了。我们可以使用并行方式来加速所有ping命令的执行。可以将ping命令中的循环体放入( )&amp; 中，( ) 使其中的命令可作为子shell来执行，&amp; 使之在后台继续运行。 1234567891011121314151617181920#编写G一个并行方式的ping脚本fo ip in 192.168.1.&#123;1..255&#125;do ( ping $ip -c2 &amp;&gt; /dev/null; if[ $? -eq 0 ] then echo "$ip is alive" fi )&amp;waitdone#wait命令是脚本只有在所有子进程或后台进程全部终止或完成后才能结束#使用fping,-a显示活动主机，-g生成目标列表,-u显示无法到达主机fping -a 192.168.0.0/24 -g 2&gt; /dev/nullfping -a 192.168.0.1 192.168.3.255 -g 2&gt; ./unreach.txt#将unreach主机找出cat unreach.txt | egrep -o "to [0-9.]+$" | grep -o "[0-9.]*" 传输文件有很多不同的方法可以在网络节点上传输文件，常见的协议有FTP, SFTP, RSYNC, SCP。 通过FTP传输文件可使用lftp命令；通过SSH传输文件可使用sftp；RSYNC使用SSH与rsync命令；scp通过SSH进行传输。 文件传输协议(File Transfer Protocol, FTP)，使用21端口。FTP是明文传输，So…需要远程主机上启用了FTP服务器才能使用FTP。 1234567lftp user@ftp-host#输入密码后便可以操作如下命令cd -- lcd(本地)mkdirget filename #下载文件put filename #上传文件quit #退出 SFTP(Secure FTP,安全FTP)，运行在SSH连接之上。利用SSH连接模拟FTP接口。它不需要源端运行FTP服务器，不要运行OpenSSH。SFTP是一个交互式命令，提供了命令提示符。 rsync广泛用于网络文件与系统快照的备份。 SCP(Secure Copy,安全复制)，远程文件复制工具。通过SSH加密通过进行传输。123456789scp SOURCE DESTINATIONscp /path/file user@host:PATHscp usr@host:/dir/file /home/zhang#需要输入密码，可以用SSH无秘钥认证#-r递归复制,-p保持文件权限和模式scp -r /etc user@host:/tmpscp -rp user@host:/var/www /var SSH无秘钥认证特别是在定时任务传输备份文件时，无秘钥认证就很方便了。SSH服务默认在22端口，你可以在配置文件中修改。 具体步骤： 创建SSH密钥(公钥和私钥)； 将客户端公钥上传给需要连接的主机，并写入~/.ssh/authorized_keys文件； 修改相关目录(700)和文件权限(600)； 1234567ssh-keygen -t rsa#后续操作默认即可#生成~/.ssh/id_rsa.pub和id_rsa#写入远程主机ssh user@host "cat &gt;&gt; ~/.ssh/authorized_keys" &lt; ~/.ssh/id_rsa.pub 用SSH在远程主机上运行命令1234567891011121314151617#连接远程主机ssh user@host#非默认端口ssh user@host -p 2211#在远程主机中运行命令ssh user@host 'command'ssh user@host 'cmd1'; 'com2'...ssh user@host 'whoami'#-C压缩功能，当带宽有限时ssh -C user@host 'cmd' 在本地挂载远程驱动器(sshfs)在执行读写数据操作时，通过本地挂载远程主机文件系统。利用SSH和sshfs来实现这一功能。sshfs是FUSE文件系统的一个扩展，FUSE允许其支持的操作系统像使用本地文件系统一样挂载各类数据。sshfs允许将远程文件系统挂载到本地挂载点上。 相当于便捷的NFS，但并不需要搭建NFS服务。 SSHFS - filesystem client based on ssh 1234#挂载远程文件到本地ssh user@host:PATH /mnt/sshfsumout /mnt/sshfs 网络流量和端口分析应用程序在主机上打开端口，然后与远程主机中打开的端口实现通信。出于安全方面的考虑，必须留意系统中打开及关闭的端口。 恶意软件和rootkit可能会利用特定的端口及服务运行在系统之中，从而进行攻击。通过分析开放端口列表以及运行在端口上的服务，我们便可以分析并检查恶意软件，保证主机安全。 了解及使用各种端口分析工具。 lsof - list open fileslsof列出系统中开放端口以及运行在端口上的服务的详细信息，文件被哪个程序使用。 1234567891011121314151617-a：列出打开文件存在的进程-c&lt;进程名&gt;：列出指定进程所打开的文件-g：列出GID号进程详情-d&lt;文件号&gt;：列出占用该文件号的进程+d&lt;目录&gt;：列出目录下被打开的文件+D&lt;目录&gt;：递归列出目录下被打开的文件-n&lt;目录&gt;：列出使用NFS的文件-i&lt;条件&gt;：列出符合条件的进程（4、6、协议、:端口、 @ip ）-p&lt;进程号&gt;：列出指定进程号所打开的文件-u：列出UID号进程详情-h：显示帮助信息-v：显示版本信息lsof /var/log/messagesCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMErsyslogd 12231 root 5w REG 253,0 539973467 68539162 /var/log/messages netstat查看开放端口与服务netstat - 显示网络连接，路由表，接口状态，伪装连接，网络链路信息和组播成员组; iftop - display bandwidth usage on an interface by hostiftop - 展示带宽使用情况； ifstat - handy utility to read network interface statisticsifstat - 展示某时刻网络状态； nload - displays the current network usagenload - 可查看系统总带宽； nethogs - Net top tool grouping bandwidth per processnethogs- 可查看每个进程流量情况；ethtool - query or control network driver and hardware settingsethtool - 检查网卡支持的带宽 12345678910111213141516171819202122#lsof的每一项都对应着一个打开了特定端口的服务lsof -i:port#查看开放端口和服务netstat -nltp#查看网络实时状态iftop#查看当前网络状态ifstat#查看系统带宽nload#查看进程流量nethogs tcpdumptcpdump是一款嗅探工具，也就是命令行格式的wireshark。 1234tcpdump - dump traffic on a networktcpdump [options]` 12345678910111213141516171819202122232425-a：尝试将网络和广播地址转换成名称；-c&lt;数据包数目&gt;：收到指定的数据包数目后，就停止进行倾倒操作；-d：把编译过的数据包编码转换成可阅读的格式，并倾倒到标准输出；-dd：把编译过的数据包编码转换成C语言的格式，并倾倒到标准输出；-ddd：把编译过的数据包编码转换成十进制数字的格式，并倾倒到标准输出；-e：在每列倾倒资料上显示连接层级的文件头；-f：用数字显示网际网络地址；-F&lt;表达文件&gt;：指定内含表达方式的文件；-i&lt;网络界面&gt;：使用指定的网络截面送出数据包；-l：使用标准输出列的缓冲区；-n：不把主机的网络地址转换成名字；-N：不列出域名；-O：不将数据包编码最佳化；-p：不让网络界面进入混杂模式；-q ：快速输出，仅列出少数的传输协议信息；-r&lt;数据包文件&gt;：从指定的文件读取数据包数据；-s&lt;数据包大小&gt;：设置每个数据包的大小；-S：用绝对而非相对数值列出TCP关联数；-t：在每列倾倒资料上不显示时间戳记；-tt： 在每列倾倒资料上显示未经格式化的时间戳记；-T&lt;数据包类型&gt;：强制将表达方式所指定的数据包转译成设置的数据包类型；-v：详细显示指令执行过程；-vv：更详细显示指令执行过程；-x：用十六进制字码列出数据包资料；-w&lt;数据包文件&gt;：把数据包数据写入指定的文件。 栗子： 123456789101112131415161718192021#tcpdump默认将监视第一个网络接口上流过的数据包tcpdump#指定网络接口tcpdump -i eth1 -w /tmp/1.cap#指定主机tcpdump host $hostnametcpdump host $hostname1 and $hostname2#指定源和目标主机tcpdump -i eth0 src host $hostnametcpdump -i eth0 dst host $hostname#指定主机和端口tcpdump tcp port 22 host 192.168.1.11tcpdump udp port 53 当个好管家简介操作系统(Operation System,OS)，是由一系列用于不同目的、服务于不同任务的系统软件组成。日志记录(logging)和监视是很重要的，能帮助我们从大量数据中收集信息。 监视系统活动的各种命令，日志技术及其使用方法。 统计磁盘使用情况(df+du+fdisk)磁盘空间是一种有限资源，我们需要了解磁盘的可用空间。 df, du, fdisk是Linux中的磁盘管理三板斧df(disk free): 报告文件系统磁盘空间的使用情况;du(disk usage): 报告磁盘空间使用情况; 使用du时，要确保对其遍历的目录和文件拥有适合的读权限。fdisk: Linux分区表操作工具软件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748du file1 #默认以字节为单位#-a,显示目录下所有文件大小du -a /home/zhangdu /home/zhang #只显示目录大小#-h,以可读形式打印du -h /home/zhang#-c,显示使用总量du -c file1 /dir2du -c *.txt *.sh#-s，打印摘要du -s /dirdu -sh /home/zhang#-b,-k,-m,-B，用特定单位打印du -k file1du -m file2#--exclude,从磁盘统计中排除部分文件du --exclude="*.swap" -sh /home/zhang#--max-depth,指定最大遍历深度du -h --max-depth n /dirdu -h --max-depth=2 /home/zhang#-x,将/mnt中所有挂载点排除在磁盘统计之外du -xh /dir#找出目录中最大的文件du -ak /dir | sort -nrk 1 | head -n 5#此输出包含了目录大小，需要细化#利用find替du过滤文件find /dir -type f --exec du -ak &#123;&#125; \; | sort -nrk 1 | head#df,磁盘可用空间信息df -h 计算命令执行时间当测试一个应用程序或比较不同的算法时，程序的执行时间非常重要。所以需要计算命令执行时间。 所有的Unix-Like操作系统都包含time命令，可将time放在需要计算执行时间的命令前。 time命令有个可执行二进制文件位于/usr/bin/time，还有一个shell built-in命令也叫作time；当运行time时，默认调用的是shell built-in命令。內建time命令选项有限；因此，如果我们需要使用另外的功能，就应该使用/usr/bin/time命令。 123456789101112131415161718192021222324#计算命令执行时间time commandtime ls#real,挂钟时间(wall clock time),命令从开始执行到结束的时间；#user,指进程花费在用户模式(user-mode)中的CPU时间。这是唯一用于执行进程所花费的时间；#sys，指进程花费在内核模式(in the kernel)中的CPU时间。它代表在内核中执行系统调用所使用的时间。#-o,将命令执行时间写入文件/usr/bin/time -o exetime.txt ls /#-a,不影响原文件/usr/bin/time -a -o exetime.txt ls /home#-f,格式化时间输出#时间格式字符串#real %e#user %U#sys %S/usr/bin/time -f "FORMAT STRING" command/usr/bin/time -f "Rtme: %e" -a -o timing.log uname/usr/bin/time -f "Rtime: %e\nUtime: %U\nStime: %S" -ao timing.log uname 当前登录用户、启动日志、启动故障的相关信息(w+who+lastb+last)收集与操作系统、当前登录用户、主机运行时间、启动故障等相关信息很有用处。 1234567891011121314151617181920#获取当前登录用户who #显示已经登录的用户w #显示已经登录的用户以及他们在做什么#会显示用户使用的伪终端(pseudo TTY)，对应设备文件出现在/dev/pts/n#列出登录主机的用户列表users#查看系统运行时间uptime#显示用户登录列表last#获取某个用户登录信息last zhang#获取重启会话信息last reboot#获取失败的用户登录信息lastb 打印10条最常使用的命令(history)终端是用来访问shell的工具，在shell中我们可以输入并执行命令。我们可以找出在shell中运行最多的命令。 ~/.bash_history，默认保留1000个最近执行命令。或者history命令。 1cat .bash_history | sort -n | uniq -c | sorn -nr | head 列出占用CPU最多的进程CPU时间是一项重要资源，有时需要跟踪占用CPU周期最多的进程。对于需要处理大量请求的服务器来说，CPU是极其重要的资源。通过监视某个时期内CPU的使用情况，可以找出长期占用CPU的进程并对其进行优化，或是调试其他问题。 用ps命令收集系统中进程的详细信息。ps - report a snapshot of the current processes 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#-e,以标准语法显示每个进程ps -eps -ef#ax,以BSD语法显示每个进程ps axpa axu#获取安全信息#ps -eo euser,ruser,suser,fuser,f,comm,pcpu,label#comm显示命令，pcpu显示CPU使用率ps -eo comm,pcpu#监视并计算一小时内CPU使用情况的shell脚本secs=3600unit_time=60steps=$(($secs / $unit_time))echo "Whatching CPU usage..."for((i=0; i&lt;steps; i++))do ps -eo comm,pcpu | tail -n +2 &gt;&gt; /tmp/cpu_usage.$$ sleep $unit_timedoneecho "CPU eaters: "cat /tmp/cpu_usage.$$ | \awk '&#123;process[$1]+=$2&#125;END&#123; for (i in process) &#123; printf("%-20s %s",i,process[i]); &#125;&#125;' | sort -nrk 2 | head#tail -n +K，从第K行开始输出。上面输出第一行是 COMAND 和 %CPU#$1,command; $2,%CPU#process[$1]是一个关联函数，相当于arr[command]#arr[command]=arr[command]+ $2，计算同一命令的累积时间#i指命令，process[i]指命令运行时间 用watch监视命令输出可能需要在在某段时期内以固定的间隔时间不短监视某个命令的输出。可利用watch命令。 watch - execute a program periodically, showing output fullscreen 123456789101112131415#watch命令可以用来在终端以固定的间隔监视命令输出，默认2秒间隔watch commandwatch 'command'watch lswatch 'ls -l'#-n,指定时间间隔watch -n 5 'yum update -y'#-d，突出(highlighting)watch输出中的差异watch -d -n 1'dd if=/dev/zero of=/tmp/zero.test' 对文件及目录访问进行记录(inotifywait)记录重要文件及目录访问，对于追踪文件和目录的变化很有帮助。inotifywait命令可以用来收集有关文件访问的信息。inotifywait和rsync用户实时同步哦！ inotifywait - wait for changes to files using inotify 1234567891011yum install -y inotify-tools#-q,减少冗余信息inotifywait -m -r -q -e create,move,delete /dirinotifywait -m -r -q -e create,move,modify,delete /home/zhang &gt;&gt; inotifywait.log#利用inotifywait检测，rsync同步inotifywait -mrq -e create,move,modify,delete /dir --exclude="*.swap" | while read filedorsync -av --exclude="*.swqp" --delete /dir user@host:PATH &gt; /dev/null 2&gt;&amp;1done 用logrotate管理日志文件日志文件是Linux系统维护中必不可少的组成部分。日志文件可以帮助跟踪系统中多种服务所发生的事件，这有助于排除系统问题。但随着时间推移，日志文件会变得越来越大。因而必须对日志文件进行管理。 我们可以利用一种称为“轮询(rotation)”的技术来限制日志文件的体积。一旦日志文件超过了限定大小，就要对它的内容进行抽取(strip)，同时将日志文件的旧条目归档到文件中。 logratate是每一位Linux系统管理员都应该了解的命令。它能够将日志文件大大小限制在给定的SIZE内。logrotate配置文件位于/etc/logrotate.d logrotate ‐ rotates, compresses, and mails system logs 123456789101112vim /etc/logrotated.d/custom/var/log/custom.log &#123; missingok #日志文件丢失，则忽略 notifempty #仅当源日志文件非空时才进行轮替 size 30k #限制实施轮替的日志文件大小 compress #压缩旧日志 weekly #轮询时间，daily,weekly,yearly rotate 7 #保留旧日志数量 create 0600 root root #创建的日志文件模式，用户和用户组#还有一些其他选项&#125; 用sys记录日志在Linux系统中，在/var/log中创建并写入日志信息的是由被称为syslog的协议处理的。它由守护进程syslogd负责执行。每一个标准应用进程都可以用syslog记录日志信息。 syslog处理/var/log下的多个日志文件。但是当logger发送消息时，它用标记字符串来确定应该纪录到哪一个日志文件中。syslogd使用与日志相关联的TAG来决定应该将其记录到哪一个文件中。可以从/etc/rsyslog.d/目录的配置文件中看到与日志文件相关联的标记字符串。 Linux中一些重要日志文件： /var/log/boot.log， 系统启动信息；/var/log/message， 内核启动信息；/var/log/auth.log， 用户认证日志；/var/log/dmesg， 系统启动信息；/var/log/mail.log， 邮件服务器日志。 logger - a shell command interface to the syslog 123456#logger命令，默认记录日志信息到/var/log/messageslogger "test log message to messages"tail -n 1 /var/log/message#-t，指定特定TAGlogger -t TAG "test log message to messages" 管理重任简介GNU/Linux的生态系统是由运行的程序、服务、连接的设备、文件系统、用户等组成。按照我们需要的方式对整个系统有一个微观并对操作系统进行整体上的管理，这就是系统管理的主要目的。 收集进程信息(top+ps+pgrep)进程是程序运行实例(runing instance)。同一程序的多个实例可以同时运行，但他们的进程ID却互不相同。 进程管理相关的重要命令是： top, display Linux processes; ps, report a snapshot of the current processes; pgrep, look up or signal processes based on name and other attributes. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#ps命令#-f, 显示更多进程信息ps -f#-e,every; -a,allps -efps -ax#-o, 指定想要的列ps -e -o parameter1,parameter2...ps -eo comm,pcpu,pmem#pccpu CPU占用率#pid 进程ID#ppid 父进程ID#pmem 内存使用率#comm 命令名#cmd 简单命令#user 启动进程的用户#nice 优先级#time 累积的CPU时间#etime 进程启动后度过的时间#tty 所关联的TTY设备#euid 有效用户ID#stat 进程状态#--sort,根据参数对ps输出进行排序#+升序，-降序ps -eo comm,pcpu,pmem --sort -pcpups -eo comm,pcpu,pmem --sort -pcpu,+pmem#-C, 给定命令全名找出PIDps -C cmd -o comm,pid#-u, 指定有效用户列表#-U, 指定真实用户列表ps -u root -U zhang -o user,pcpu#-t, 用TTY过滤输出ps -t TTY1,TTY2...ps -t pts/0,pts/1 -ef#-L, 显示进程相关信息#LWP线程ID， NLWP线程数量ps -efL#pgrep命令, 获得一个特定命令的PID列表#它只需要命令的一部分即可pgrep cmdpgre inotifpgrep bas#-d, 指定定界符pgrep rsync -d ":"#-u, 指定进程的用户pgrep -u root,zhang rsync#-c, 返回匹配的进程数量pgrep -c rsync#top命令top 杀死进程以及发送响应信息(kill+killall+trap)在Unix-Like环境中与进程有关的一个重要概念就是信号。信号是一种进程间通信机制，它用来中断运行的进程以执行某些操作。终止程序也是通过使用信号技术来实现的。 像ctrl+C,ctrl+Z这种作业都属于信号。 kill 命令可用来向进程发送信号; trap 命令用来处理所接收的信号; killall 以名字方式来杀死进程. 123456789101112131415161718192021222324252627#列出所有可用信号kill -l#-s, 发送信号#信号名称和信号数都可以kill -信号数 PIDkill -s SIGNAL PID#常用信号#SIGHUP 1 终端断线(对控制进程或终端进行挂起检测(hangup detection))#SIGINT 2 中断(当按下Ctrl+C时发送该信号)#SIGQUIT 3 退出(同Ctrl+\)#SIGKILL 9 强制终止(强行杀死进程)#SIGTERM 15 终止进程#SIGCONT 18 继续(与STOP相反，fg/bg命令)#SIGTST0P 19 暂停(当按下crtl+z时发送该信号)#killall, 通过命令名终止进程killall -s SIGNAL PNamekillall -信号数 PName#trap, 捕捉并响应信号trap 'signal-handler-func' SIGNAL LIST kill信号详解参考: https://www.imooc.com/article/48534 1234567891011121314$ kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR111) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+338) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+843) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+1348) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-1253) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-758) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-263) SIGRTMAX-1 64) SIGRTMAX Linux信号列表： SIGHUP 1: A 终端挂起或者控制进程终止 SIGINT 2: A 键盘中断（如break键被按下） SIGQUIT 3: C 键盘的退出键被按下 SIGILL 4: C 非法指令 SIGABRT 6: C 由abort(3)发出的退出指令 SIGFPE 8: C 浮点异常 SIGKILL 9: AEF Kill信号 SIGSEGV 11: C 无效的内存引用 SIGPIPE 13: A 管道破裂: 写一个没有读端口的管道 SIGALRM 14: A 由alarm(2)发出的信号 SIGTERM 15: A 终止信号 SIGUSR1 30,10,16: A 用户自定义信号1 SIGUSR2 31,12,17: A 用户自定义信号2 SIGCHLD 20,17,18: B 子进程结束信号 SIGCONT 19,18,25: 进程继续（曾被停止的进程） SIGSTOP 17,19,23: DEF 终止进程 SIGTSTP 18,20,24: D 控制终端（tty）上按下停止键 SIGTTIN 21,21,26: D 后台进程企图从控制终端读 SIGTTOU 22,22,27: D 后台进程企图从控制终端写 处理动作中的字母含义： A: 缺省的动作是终止进程 B: 缺省的动作是忽略此信号，将该信号丢弃，不做处理 C: 缺省的动作是终止进程并进行内核映像转储（dump core），内核映像转储是指将进程数据在内存的映像和进程在内核结构中的部分内容以一定格式转储到文件系统，并且进程退出执行，这样做的好处是为程序员 提供了方便，使得他们可以得到进程当时执行时的数据值，允许他们确定转储的原因，并且可以调试他们的程序。 D: 缺省的动作是停止进程，进入停止状况以后还能重新进行下去，一般是在调试的过程中（例如ptrace系统调用） E: 信号不能被捕获 F: 信号不能被忽略 which, whereis, file, whatis与平均负载which hows the full path of (shell) commands。找出某个命令的位置;whereis locate the binary, source, and manual page files for a command。不仅返回命令路径，还能打印命令手册的位置以及命令源代码路径;file determine file type。用来确定文件类型;whatis display manual page descriptions。输出简短描述信息;平均负载(load average),是系统运行总负载量的一个重要参数。它指明了系统中可运行进程总量的平均值。平均负载由三个值来指定，第一个指明1分钟内的平均值，第二个指明5分钟内的平均值，第三个指明15分钟内的平均值。 单核CPU，类似于单车道，负载在 0.00-1.00 之间正常； 多核CPU，类似于多车道，负载在 核数*(0.00-1.00) 之间正常； 安全的系统负载，单核应该在 0.7 以下； 12345#查看平均负载uptimecat /proc/loadavg#0.00 0.01 0.05 1/355 44955#分母355表示系统进程总数, 分子表示正在运行的进程数, 最后一个数字表示最近运行进程ID 向用户终端发送消息系统管理员可能需要向网络中所有主机上的所有用户或特定用户的终端发送消息。`wallrsync -av –exclude=”*.s命令用来向所有当前登录用户的终端写入消息。 在Linux系统中，终端是作为设备存在的。因此那些打开的终端在dev/pts/中都会与对应的设备节点文件。向特定设备写入数据将会在对应的终端显示出消息。 12345echo "It's just a test" | wall#查看用户对应的/dev/pts/, 并向某一个用户终端发送信息ll /dev/pts | awk '&#123;print $3,$6&#125;'echo"Haha" &gt; /dev/pts/[1,2,3...] 收集系统信息包括主机名、内核版本、Linux发行版本、CPU信息、内存信息、磁盘分区信息等。 123456789101112131415161718192021222324252627#主机名hostnameuname -n#内核版本，架构uname -runame -muname -a#Linux发行版本cat /etc/redhat-release#CPU相关信息lscpucat /proc/cpuinfocat /proc/cpuinfo | grep 'model name'#内存详细信息free -hcat /proc/meminfo#分区信息cat /proc/partitionsfdisk -l#系统详细信息lshw 用/proc收集信息在GNU/Linux操作系统中，/proc是一个位于内存中的伪文件系统(in-memory pseudo filesystem)。它的引用是为了提供一个可以从用户空间(user space)读取系统参数的接口。 可以对/proc中的文件和子目录进行cat来获取信息，所有内容都是易读的格式化文本。 /proc/下的数字目录，包含了对应进程的相关信息；/proc/environ，包含于进程相关联的环境变量；/proc/cwd，是一个到进程工作目录的符号链接；/proc/fbcat，包含了由进程所使用的文件描述符。 用cron进行调度GNU/Linux系统包含了各种用于调度任务的工具。cron就是其中之一，它通过守护进程crond使得任务能够以固定的时间间隔在系统后台自动运行。cron利用的是一个被称为“cron表(cron table)”的文件，这个文件中存储了需要执行的脚本或命令的调度列表以及执行时间。 12345678910111213141516171819202122232425262728#分 时 日 月 周#* * * * * cmd#分钟(0-59)#小时(0-23)#天(1-31)#月(1-12)#工作日(0-7)，0和7都代表周天#命令#*号,所有值#,号,范围。1,3,5,7,9#-号,连续范文。1-10#/号,*/10;0-8/20#栗子crontab -e* 0-6 * * * /home/zhang/test.sh1,3,5,7,9 * * * * /home/zhang/test.sh*/5 * * * * /home/zhang/test.sh#-l,查看cron表crontab -l#-r,移除cron表crontab -r cron的高级写法栗子： 1234567891011121314151617181920@reboot #在启动的时候运行一次#其实@reboot类似于rc.local，开机启动@yearly == @annually == 0 0 1 1 * #一年一次@monthly == 0 0 1 * * #每月一次@weekly == 0 0 * * 0 #每周一次@daily == @midnight == 0 0 * * * #每天一次@hourly == 0 * * * * #每小时一次crontab -e@reboot /bin/mongod -f /etc/mongod_27018.confvim /etc/rc.d/rc.local/bin/mongod -f /etc/mongod_27018.confchmod a+x /etc/rc.d/rc.local 用户管理常用命令123456789101112131415161718192021222324252627282930313233343536#添加用户useradd#删除用户userdel--remove-all-file删除与用户相关的所有文件#修改shellchsh#修改用户属性usermod#修改密码过期时间chage#修改密码passwd#登录到一个新组newgrp#添加、删除组groupaddgroupdel#指纹finger iptables和firewalldfirewalld与iptables比较: iptables与firewalld都不是真正的防火墙，它们都只是用来定义防火墙策略的防火墙管理工具而已。或者说，它们只是一种服务 firewalld可以动态修改单条规则，动态管理规则集，允许更新规则而不破坏现有会话和连接；iptables在修改了规则后必须得全部刷新才可以生效 firewalld使用区域和服务而不是链式规则 firewalld默认是拒绝的，需要设置以后才能放行；iptables默认是允许，需要拒绝的才去限制 firewalld自身并不具备防火墙的功能，而是和iptables一样需要通过内核的netfilter来实现。真正使用规则干活的是内核的netfilter firewalld是iptables的一个封装，可以让你更容易地管理iptables规则。它并不是iptables的替代品 firewalld拥有CLI和GUI的两种管理方式 firewalld区域管理通过将网络划分成不同的区域，制定出不同区域之间的访问控制策略来控制不同程序区域间传送数据流。firewalld的默认区域是public区域。 九大区域： 阻塞区域（block）任何传入的网络数据包都将被阻止 工作区域（work）相信网络上的其他计算机，不会损害你的计算机 家庭区域（home）相信网络上的其他计算机，不会损害你的计算机 公共区域（public）不相信网络上的任何计算机，只有选择接受传入的网络连接 隔离区域（DMZ）隔离区域也称为非军事区域，内外网络之间增加的一层网络，起到缓冲作用。对于隔离区域，只有选择接受传入的网络连接 信任区域（trusted）所有的网络连接都可以接受 丢弃区域（drop）任何传入的网络连接都被拒绝 内部区域（internal）信任网络上的其他计算机，不会损害你的计算机。只有选择接受传入的网络连接 外部区域（external）不相信网络上的其他计算机，不会损害你的计算机。只有选择接受传入的网络连接 firewalld有三种配置方法： firewll-config(GUI) firewall-cmd(CLI) 编辑XML配置文件 firewalld默认提供了九个区域的配置文件，它们位于/usr/lib/firewalld/zones: 123ls /usr/lib/firewalld/zonesblock.xml dmz.xml drop.xml external.xml home.xml internal.xml public.xml trusted.xml work.xml 常用命令: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162yum install firewalld firewall-configsystemctl start firewalldfirewall-cmd --versionfirewall-cmd --help#永久生效需加上 --permannentfirewall-cmd xxx --permannentfirewall-cmd --state#查看网络接口使用的区域firewall-cmd --get-active-zones#查看指定区域的所有配置firewall-cmd --zone=public --list-all#查看所有区域配置firewall-cmd --list-all-zones#查看默认区域firewall-cmd --get-default-zone#设置默认区域firewall-cmd --set-default-zone=internal#查看指定接口所属区域firewall-cmd --get-zone-of-interface=eth0#将接口添加到区域，默认接口都在publicfirewall-cmd --zone=public --add-interface=eth0#拒绝|开启 所有包firewall-cmd --panic-on|off#查看是否拒绝firewall-cmd --query-panic#无需断开连接更新防火墙规则firewall-cmd --reload#类似于重启更新规则firewall-cmd --complete-reload#查看所有打开的端口firewall-cmd --zone=dmz --list-ports#加入一个端口的区域firewall-cmd --zone=dmz --add-port=8080/tcp 与服务一起使用firewalld可以根据特定网络服务的预定义规则来允许相关流量。你可以自定义系统规则，并将它们添加到任何区域。 默认支持的服务的配置文件位置: /usr/lib/firewalld/services 创建的服务文件位置: /etc/firewalld/services 123456789cat /usr/lib/firewalld/service/elasticsearch.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;service&gt; &lt;short&gt;Elasticsearch&lt;/short&gt; &lt;description&gt;Elasticsearch is a distributed, open source search and analytics engine, designed for horizontal scalability, reliability, and easy management.&lt;/description&gt; &lt;port protocol=&quot;tcp&quot; port=&quot;9300&quot;/&gt; &lt;port protocol=&quot;tcp&quot; port=&quot;9200&quot;/&gt;&lt;/service&gt; 常用命令: 1234567891011121314#查看默认可用服务firewall-cmd --get-services#永久启用或禁用HTTP服务firewall-cmd --zone=区域 --(add|remove)-service=http --permanent#添加123456端口的tcp流量firewall-cmd --zone=public --add-port=123456/tcp --permanent#将80端口的流量转发到123456端口firewall-cmd --zone=public --add-forward-port=port=80:proto=tcp:toport=123456 iptablesiptables/ip6tables — administration tool for IPv4/IPv6 packet filtering and NAT 切记谨慎使用iptables命令，特别是在远程连接的时候。规则是有顺序的，规则的顺序很重要。当规则顺序排列错误时，会产生很严重的错误。 12345678910111213141516171819202122232425262728293031iptables --help-t&lt;表&gt;： 指定要操纵的表，默认为filter-P： 设置默认策略-A &lt;链&gt;： 在规则链的末尾中添加条目-I &lt;链&gt;： 在规则链的头部中插入条目#请注意-A与-I，这两者的插入顺序是不一致的，-I顺序更高-D &lt;链&gt;： 从规则链中删除条目-R： 替换规则链中的条目-L： 显示规则链中已有的条目-F： 清楚规则链中已有的条目-Z： 清空规则链中的数据包计算器和字节计数器-X： 删除用户定义的链-N： 创建新的用户自定义规则链-p： 指定要匹配的数据包协议类型(tcp, udp, icmp...)-s： 指定要匹配的数据包源ip地址(ip/mask, !ip)-d： 匹配 目标地址--sport： 匹配源端口号--dport： 匹配目的端口号-i&lt;网络接口&gt;： 指定数据包进入本机的网络接口-o&lt;网络接口&gt;： 指定数据包要离开本机所使用的网络接口-j target： 指定要跳转的目标-m match： 扩展匹配-g chain： jump to chain with no return 表格/链/动作为什么称为iptables? 因为此软件里面有多个表格(table)，每个表格定义了自己的默认策略和规则，且每个表格的用途都不相同。 表(Table) raw: 高级功能 mangle: 数据包修改 nat: 网络地址转换 PREROUTING POSTROUTING OUTPUT filter: 包过滤，是默认表 INPUT OUTPUT FORWARD 链(Chain) INPUT：处理输入数据包 OUTPUT：处理输出数据包 FORWARD：处理转发数据包 PREROUTING：用于目标地址转换(DNAT) POSTOUTING：用于源地址转换(SNAT) 动作(Action) ACCEPT： 接收数据包 DROP： 丢弃数据包 REJECT: 拒绝 REDIRECT： 重定向、映射、透明代理 SNAT： 源地址转换 DNAT： 目标地址转换 MASQUERADE： IP伪装（NAT），用于ADSL LOG： 日志记录 常用命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#格式iptables -t 表名 &lt;-A/I/D/R&gt; 规则链名 [规则号] &lt;-i/o 网卡名&gt; -p 协议名 &lt;-s 源IP/源子网&gt; --sport 源端口 &lt;-d 目标IP/目标子网&gt; --dport 目标端口 -j 动作-A: 新增一条规则，在最后面-I: 插入一条规则，如果没有指定顺序，默认变成第一条规则--line-numbers： 显示规则行号-i: 包所进入的那个网络接口-o: 包所传出的那个网络接口-p: 指定网络协议-p tcp --syn(ack, rst)-p udp-p icmp-p all-s: 源IP或网段-d: 目标IP或网段-s 192.168.1.11-d 192.168.1.0/24(192.168.1.0/255.255.255.0)-s !192.168.2.0/24-j: 后接动作#记录，此日志默认追加到messages-j LOG --log-prefix=‘IPTABLES-’#端口号可以是连续的--sport 1026:65535--dport 80-m: 一些iptables外部模块-m state: 状态模块-m mac: 网卡地址--state: 数据包状态--state INVALID： 无效的数据包--state ESTABLISHED: 已建立连接--state NEW: 想要新建连接的数据包--state RELATED: 表示这个数据包是我们主机发送出去的--mac-source: 源主机的硬件地址 清除防火墙规则: 12345678910111213iptables [ -t tables ] [ -FXZ ]#清除所有已制定的规则iptables -F#清除用户 "自定义"iptables -X#将所有链表的计数与流量统计都归零iptables -Z#这三个命令会将本机防火墙的所有规则都清除，但却不会改变 默认策略 定义默认策略 12345--policy, -Piptables -P INPUT DROPiptables -P OUTPUT ACCESSiptables -P FORWARD ACCEPT 开放某个端口 1234567891011121314151617181920212223#允许本地回环接口(即运行本机访问本机)iptables -A INPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT#允许已建立的或相关连的通行iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT#针对网卡执行的放行和防御iptables -A INPUT -m mac --mac--source aa:bb:cc:11:22:33 -j DROP#允许所有本机向外的访问iptables -A OUTPUT -j ACCEPT#允许访问22端口iptables -A INPUT -p tcp --dport 22 -j ACCEPT#允许访问80端口iptables -A INPUT -p tcp --dport 80 -j ACCEPT# #禁止其他未允许的规则访问iptables -A INPUT -j reject#禁止其他未允许的规则访问iptables -A FORWARD -j REJECT 屏蔽IP 12345#屏蔽单个IP的命令iptables -I INPUT -s 123.45.6.7 -j DROP#封整个段即从123.0.0.1到123.255.255.254的命令iptables -I INPUT -s 123.0.0.0/8 -j DROP 查看规则 12345678910#推荐使用iptables-saveiptables-save#备份和恢复iptables-save &gt;/etc/sysconfig/iptablesiptables-restore &lt;/etc/sysconfig/iptablesiptables -L -niptables -L -n --line-numbers 删除已添加规则 1234iptables -L -n --line-numbersiptables -D INPUT 5iptables -D OUTPUT 3 解决重启失效1234iptables-save &gt;/etc/sysconfig/iptables#把此加入开机启动iptables-restore &lt;/etc/sysconfig/iptables 分屏显示tmux命令 — terminal multiplexer 上下分屏: ctrl+b -&gt; &quot; 左右分屏： ctrl_b -&gt; % 切换屏幕： ctrl+b -&gt; o 关闭终端： ctrl+b -&gt; x 上下屏与左右屏切换： ctrl+b -&gt; 空格 帮助： ctrl+b -&gt; ? 命令模式： ctrl+b -&gt; :]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
        <tag>Bash</tag>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作与人生]]></title>
    <url>%2F2017%2F09%2F04%2F%E5%B7%A5%E4%BD%9C%E4%B8%8E%E4%BA%BA%E7%94%9F%2F</url>
    <content type="text"><![CDATA[我现在已经活到了人生的中途，拿一日来比喻人的一生，现在正是中午。人在童年时从朦胧中醒来．需要一些时间来克服清晨的软弱，然后就要投入工作；在正午时分，他的精力最为充沛，但已隐隐感到疲惫；到了黄昏时节，就要总结一日的工作，准备沉入永恒的休息。按我这种说法，工作是人一生的主题。这个想法不是人人都能同意的。我知道在中国，农村的人把生儿育女看作是一生的主题。把儿女养大，自己就死掉，给他们空出地方来——这是很流行的想法。在城市里则另有一种想法，但不知是不是很流行：它把取得社会地位看作一生的主题。站在北京八宝山的骨灰墙前，可以体会到这种想法。我在那里看到一位已故的大叔墓上写着：副系主任、支部副书记、副教授、某某教研室副主任，等等。假如能把这些“副”字去掉个把，对这位大叔当然更好一些，但这些“副”字最能证明有这样一种想法。顺便说一句，我到美国的公墓里看过，发现他们的墓碑上只写两件事：一是生卒年月。二是某年至某年服兵役；这就是说，他们以为人的一生只有这两件事值得记述：这位上帝的子民曾经来到尘世，以及这位公民曾去为国尽忠，写别的都是多余的，我觉得这种想法比较质朴……恐怕在一份青年刊物上写这些墓前的景物是太过伤感，还是及早回到正题上来罢。 我想要把自己对人生的看法推荐给青年朋友们：人从工作中可以得到乐趣，这是一种巨大的好处。相比之下，从金钱、权力、生育子女方面可以得到的快乐，总要受到制约。举例来说，现在把生育作为生活的主题，首先是不合时宜；其次，人在生育力方面比兔子大为不如，更不要说和黄花鱼相比较；在这方面很难取得无穷无尽的成就。我对权力没有兴趣，对钱有一些兴趣，但也不愿为它去受罪——做我想做的事(这件事对我来说，就是写小说)，并且把它做好，这就是我的目标。我想，和我志趣相投的人总不会是一个都没有。 根据我的经验，人在年轻时，最头疼的一件事就是决定自己这一生要做什么。在这方面，我倒没有什么具体的建议：干什么都可以，但最好不要写小说，这是和我抢饭碗。当然，假如你执意要写，我也没理由反对。总而言之，干什么都是好的；但要干出个样子来，这才是人的价值和尊严所在。人在工作时，不单要用到手、腿和腰，还要用脑子和自己的心胸。我总觉得国人对这后一方面不够重视，这样就会把工作看成是受罪。失掉了快乐最主要的源泉，对生活的态度也会因之变得灰暗…… 人活在世上，不但有身体，还有头脑和心胸——对此请勿从解剖学上理解。人脑是怎样的一种东西，科学还不能说清楚。心胸是怎么回事就更难说清。对我自己来说，心胸是我在生活中想要达到的最低目标。某件事有悖于我的心胸，我就认为它不值得一做；某个人有悖于我的心胸，我就觉得他不值得一交；某种生活有悖于我的心胸，我就会以为它不值得一过。罗素先生曾言，对人来说，不加检点的生活，确实不值得一过。我同意他的意见：不加检点的生活，属于不能接受的生活之一种。人必须过他可以接受的生活，这恰恰是他改变一切的动力。人有了心胸，就可以用它来改变自己的生活。 中国人喜欢接受这样的想法：只要能活着就是好的，活成什么样子无所谓。从一些电影的名字就可以看出来：《活着》、《找乐》……我对这种想法是断然地不赞成。因为抱有这种想法的人就可能活成任何一种糟糕的样子，从而使生活本身失去意义。高尚、清洁、充满乐趣的生活是好的，人们很容易得到共识。卑下、肮脏、贫乏的生活是不好的，这也能得到共识。但只有这两条远远不够。我以写作为生，我知道某种文章好，也知道某种文章坏。仅知道这两条尚不足以开始写作。还有更加重要的一条，那就是：某种样子的文章对我来说不可取，绝不能让它从我笔下写出来，冠以我的名字登在报刊上。以小喻大，这也是我对生活的态度。]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>王小波</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[告别信]]></title>
    <url>%2F2017%2F09%2F04%2F%E5%91%8A%E5%88%AB%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[1999年，72岁的马尔克斯患上淋巴癌后，写了一封信向读者告别。如果有一刹那，上帝忘记我是一只布偶并赋予我片刻生命，我可能不会说出我心中的一切所想，但我必定会思考我所说的一切。 我会评价事物，按其意义大小而非价值多少。 我会少睡觉，多思考。因为我知道，每当我们闭上一分钟眼睛，我们也就同时失去了60秒。当他人停滞时我会前行，当他人入梦时我会清醒，当他人讲话时我会倾听，就像享受一支美味的巧克力冰激凌！ 如果上帝赏我一段生命，我会简单装束，伏在阳光下，袒露的不仅是身体，还有我的魂灵。 上帝呀，如果我有一颗心，我会将仇恨写在冰上，然后期待太阳的升起；我会用凡高的梦在星星上画一首贝内德第的诗，而塞莱特的歌会是将是我献给月亮的小夜曲。我会用泪水浇灌玫瑰，以此体味花刺的痛苦和花瓣的亲吻…… 上帝呀，如果我有一段生命……我不会放过哪怕是一天，而不对我所爱的人说我爱他们。我会使每个男人和女人都了解他们皆我所爱，我要怀着爱而生活。 对于大人，我会向他们证明，那种认为因衰老而失去爱的想法是多么错误，我们是因为失去爱而衰老而不是与之相反。对于孩子，我会给他们插上翅膀而让他们自己学会飞翔；对于老人，我会教给他们死亡的来临不是因为衰老而是因为遗忘。 人呀，我从你们身上学会了太多的东西… …我知道，人们都想伫立在颠峰上，殊不知，真正的幸福恰恰就在于攀登险阻的过程。我懂得，当婴儿用小拳头第一次抓住爸爸的手指时，他也就永远地抓住了它。 我明白，一个人只有在帮助他人站起时才有权利俯视他。我能够从你们身上学到的东西是如此之多，可事实上已经意义寥寥，因为当人们将我敛入棺木时，我正在死去。 永远说你感到的，做你想到的吧！如果我知道今天是我最后一次看你入睡，我会热烈地拥抱你，祈求上帝守护你的灵魂。如果我知道这是最后一次看你离开家门，我会给你一个拥抱一个吻，然后重新叫住你，再度拥抱亲吻。如果我知道这是最后一次听到你的声音，我会录下你的每个字句，以便可以一遍又一遍永无穷尽地倾听。如果我知道这是看到你的最后几分钟，我会说”我爱你”，而不是傻傻地以为你早已知道。 永远有一个明天，生活给我们另一个机会将事情做好，可是如果我搞错了，今天就是我们所剩的全部，我会对你说我多么爱你，我永远不会忘记你。 明天从不向任何人作保证，无论青年或老人，今天可能就是你最后一次看到你所爱的人。因此，别再等待了，今天就开始！因为如果明天永远不来，你也许会遗憾今天没来得及微笑，拥抱，亲吻，会遗憾自己忙碌得只能把它们归为一个最后的愿望。保护周围你爱的人吧，告诉他们你多么需要他们。爱他们，善待他们，用些时间对他们说：”对不起”，”原谅我”，”劳驾”，”谢谢”，以及你知道的所有爱的话语。 没有人会因为你秘而不宣的思想而记住你。向上帝祈求力量和智慧来表达它们吧，向你的朋友证明，他们对你来说是多么的重要。]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>马尔克斯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yaml]]></title>
    <url>%2F2017%2F09%2F02%2FYaml%2F</url>
    <content type="text"><![CDATA[参考: 维基百科: https://zh.wikipedia.org/wiki/YAML YAML: https://yaml.org/ YAML语法检测: http://www.yamllint.com 概述YAML: YAML Ain’t Markup Language.YAML is a human friendly data serialization standard for all programming languages. YAML（/ˈjæməl/，尾音类似camel骆驼）是一个可读性高，用来表达数据序列的格式。YAML是”YAML Ain’t a Markup Language”(YAML不是一种标记语言)的递归缩写。在开发的这种语言时，YAML的意思其实是：”Yet Another Markup Language”（仍是一种标记语言，但为了强调这种语言以数据做为中心，而不是以标记语言为重点，而用反向缩略语重命名。 YAML是专门用来写配置文件的语言，非常简洁和强大，远比JSON格式方便。 YAML的特点: YAML数据可在编程语言之间移植 包括数据一致的数据模型 人类易于阅读 支持单向处理 易于实现和使用 语法规则基本语法规则如下： 大小写敏感 使用缩进表示层级关系 缩进时不允许使用Tab键，只允许使用空格 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可(一般2个或4个) #表示单行注释，不支持多行注释。多行注释请使用多个# 具有单个流的多个文档用3个连字符(---)分隔 阻止列表项包括与周围块级相同的缩进，因为-符号被视为缩进的一部分 格式YAML支持三种格式： 对象：键值对的集合，又称为映射(mapping)/哈希(hashes)/字典(dictionary) 数组：一组按次序排列的值，又称为序列(sequence)/列表(list) 纯量值（scalars）：单个的、不可再分的值 1234567#栗子- key1: value1- key2: value2#一个列表，两个对象，四个纯量 对象对象是一组键值对，使用冒号结构表示。 12345key: vaule#Yaml也允许另一种写法，将所有键值对写成一个行内对象。hash: &#123; name: Steve, foo: bar &#125; 数组又称为列表或序列。 1234567- list- sequence- array#数组也可以采用行内表示法。animal: [list, sequence, array] 数据结构的子成员是一个数组，则可以在该项下面缩进一个空格。 1234- - Cat - Dog - Goldfish 纯量值纯量是最基本的、不可再分的值。 － 字符串－ 布尔值－ 整数－ 浮点数－ Null－ 时间－ 日期 复合结构对象和数组可以结合使用，形成复合结构。 123456789languages: - Ruby - Perl - Pythonwebsites: YAML: yaml.org Ruby: ruby-lang.org Python: python.org Perl: use.perl.org 特殊符号 ---: 表示文档开始；分割不同内容 ...和---的配合使用: 在一个配置文件中代表一个文件的结束 !!: 类型强行转换 &gt;: 在字符串中折叠换行 |: 保留换行符 引用 &amp;: 完成锚点定义 *: 完成锚点引用 合并内容: 主要和锚点配合使用，可以将一个锚点内容直接合并到一个对象中 123456789101112#栗子---Time: 2018-07-17T15:02:31+08:00User: edWarning: This is an error message for the log file---Time: 2018-07-17T15:05:21+08:00User: edWarning: A slightly different error message. 1234567891011#栗子---time: 20:03:20player: Sammy Sosaaction: strike (miss)...---time: 20:03:47player: Sammy Sosaaction: grand slam... 123string: - !!str 54321 - !!str true]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Yaml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown]]></title>
    <url>%2F2017%2F09%2F01%2FMarkdown%2F</url>
    <content type="text"><![CDATA[参考: Markdown-wiki Markdown官网 Markdown中文文档 Markdown语法 果冻虾仁 关于Markdown 是一种轻量级标记语言。它允许人们使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML(或者HTML)文档。 语法 首行缩进12345678#一个空格&amp;ensp;#两个空格&amp;emsp;#不断行空白格&amp;nbsp; 栗子： &ensp;一个空格； &emsp;两个空格； &nbsp;不断行空白格； 段落与换行 段落的前后必须是空行 空行是指行内什么都没有，或者只有空白符（空格或制表符） 相邻两行文本，如果中间没有空行，会显示在一行中（换行符被转换为空格） 如果需要在段内加入换行 可以在前一行的末尾加入至少两个空格，然后换行写其它的文字 Markdown中的多数区块都需要在两个空行之间 粗体和斜体语法： 1234*斜体*, _斜体_**粗体*****粗斜体***~~删除线~~ 显示效果： 斜体, 斜体 粗体 粗斜体 删除线 分级标题Setext形式大标题： 123456一级大标题========二级大标题-------- atx形式普通标题： 12345# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题 超链接MarkDown支持两种形式的链接语法：行内式和参考式。 行内式语法说明：[ ] 里面写链接文字，( ) 里面写链接地址，()中的” “可以指定title属性。 代码： 欢迎来到 [简书](www.jianshu.com &quot;Jianshu&quot;) 效果： 欢迎来到 简书 参考式参考式超链接一般用在学术论文上面，或某一个链接在文章中多处使用，那么引用的方式创建链接将非常好，它可以让你对链接进行统一的管理。 语法说明： 123参考式链接分为两部分，文中的写法[链接文字][链接标记]，在文本任意位置添加[链接标记]:链接地址 “链接标题”，链接地址与链接标题前有一个空格如果链接文字本身可以作为链接标记，也可以写成[链接文字][][链接文字]：链接地址的形式 代码： 123456简书里面有 [简书早报][1]、[简书晚报][2]以及 [简黛玉][3][简黛玉 美人][3] 是一个[才女][][1]:http://www.jianshu.com &quot;Jianshu&quot;[2]:http://www.jianshu.com &quot;EveningPaper&quot;[3]:http://www.jianshu.com[才女]:http://www.jianshu.com 效果： 简书里面有 简书早报、简书晚报以及简黛玉简黛玉 美人 是一个才女 自动链接MarkDown支持以比较简短的自动链接形式来处理网址和电子邮件，只要用&lt;&gt;包起来，MarkDown就会自动把它转成链接。 代码： 12&lt;http://example.com&gt;&lt;address@example.com&gt; 锚点MarkDown Extra只支持在标题后插入锚点，其他地方无效。锚点中的标题如果有空格，则锚点无效。现在的锚点支持中文标题。 代码： 12345678910锚点连接页内标题[标题一](#Title1)[标题二](#Title2)[标题三](#标题3)# Title1## Title2### 标题3 列表无序列表使用 * ，+ ，- 表示无序列表 代码： 123- 无序列表1- 无序列表2- 无序列表3 效果： 无序列表1 无序列表2 无序列表3 有序列表有序列表使用数字接着英文点 代码： 1231. 有序列表12. 有序列表23. 有序列表3 效果： 有序列表1 有序列表2 有序列表3 定义型列表定义型列表由名词和解释组成。一行写上定义，紧跟一行写上解释。解释的写法：紧跟一个缩进（Tab） 列表缩进列表项目标记通常是放在最左边，但是其实也可以缩进，最多3个空格，项目标记后则一定要接着至少一个空格或制表符。 代码： 123* 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。* 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 效果： 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 引用引用需要在被引用的文本前加上&gt;符号 代码： 12&gt; 引用1&gt; 引用2 效果： 引用1引用2 引用的多层嵌套区块引用可以嵌套（如引用的引用），只要根据层次加上不同数量的 &gt;符号 代码： 123&gt;&gt;&gt; 请问MarkDown怎么用？&gt;&gt; 自己看教程！&gt; 教程在哪里？ 效果： 请问MarkDown怎么用？ 自己看教程！ 教程在哪里？ 插入图像图片的创建方式与超链接类似。 代码： ![](http://zhangxx5678.lofter.com/post/39b969_df4f526#) 内容目录在段落中填写 [TOC] 以显示全文内容结构目录 注脚在需要添加注脚的文字后加上注脚名字 [^注脚名字]，称为加注。然后在文中的任意位置（一般最后）添加脚注，脚注前必须有对应的脚注名字。注脚与注脚间必须空一行！注脚自动被搬运到最后面，请到文章末尾查看，并且脚注后的链接可以直接跳转会到加注的地方 代码： 123使用 MarkDown[^1]可以提高书写效率，直接转换成 HTML[^2][^1]:MarkDown是一种纯文本标记语言[^2]:HTML超文本标记语言 效果： 使用 MarkDown^1可以提高书写效率，直接转换成 HTML^2 分割线可以在一行中用 三个以上的 *,-,_ 建立一个分割线，行内不能有其他东西。 代码： 12345671. * * *2.3. ***4.5. - - -6.7. --- 效果： GitHub中的表情Github的Markdown语法支持添加emoji表情，输入不同的符号码（两个冒号包围的字符）可以显示出不同的表情。 比如:blush:,显示效果为 :blush: 每个表情对应的符号码：https://www.webpagefx.com/tools/emoji-cheat-sheet/ 或者，果冻虾仁的整理：https://github.com/guodongxiaren/README/blob/master/emoji.md Diff语法版本控制系统中都少不了diff功能——展示一个文件内容的增加与删除。 绿色(+)表示新增 红色(-)表示删除 语法效果与代码高亮类似，在三个反引号后面写上diff。在内容中+表示新增，-表示删除。 123456+ 111+ 11+ 1- 222- 22- 2 扩展语法Markdown标准 本身所包含的功能有限，所以产生了许多第三方扩展语法，如 GFW, GitHub Flavored Markdown Tasklist代码： 12345- [ ] Monday- [ ] Tuesday- [ ] Wednesday- [ ] Tuesday- [ ] Friday 效果： Monday Tuesday Wednesday Tuesday Friday 表格 不管是哪种方式，第一行为表头，第二行为分割表头和主体部分，第三行开始每一行为一个表格行 列与列之间用管道符号 | 隔开 还可设置对齐方式 左对齐 :| 右对齐 |: 中对齐 :|: 代码： 12345学号 | 姓名 | 分数- | - | -001 | 张三 | 78002 | 李四 | 67003 | 王五 | 99 学号 姓名 分数 001 张三 78 002 李四 67 003 王五 99 GitHub上的表格GitHub上的表格与上有一点不同。 12345| 学号 | 姓名 | 分数| - | - | -| 001 | 张三 | 78| 002 | 李四 | 67| 003 | 王五 | 99 学号 姓名 分数 001 张三 78 002 李四 67 003 王五 99 代码块和高亮代码块插入代码的方式有两种，一种是利用缩进(Tab)，另一种是利用反引号 `` 和 ``` ``` 代码： 1Python语言的输出函数 `Print()` 怎么使用？ 效果： Python语言的输出函数 Print() 怎么使用？ 123import osfrom flask import Flaskapp = Flask(app) 高亮在 ``` 之后添加代码的语言 代码： ```pythonimport osfrom flask import Flaskapp = Flask(app)``` 效果： 123import osfrom flask import Flaskapp = Flask(app) 流程图flow chart/flow diagram，需要安装额外的插件才能支持流程图。 流程图语法参考: https://mermaidjs.github.io/Hexo Plugins: https://hexo.io/plugins/ hexo默认好像不支持流程图，需要在hexo Plugins去查找此类插件，安装此类插件，然后修改hexo配置文件。具体的使用方法请参考插件说明。 数学公式参考: https://blog.csdn.net/lanxuezaipiao/article/details/44341645 https://juejin.im/post/5a6721bd518825733201c4a2 LaTex数学符号表 LaTEX: https://zh.wikipedia.org/wiki/LaTeX是一种跨平台的基于TEX的排版系统，对于生成复杂表格和数学公式，这一点表现得尤为突出。因此它非常适用于生成高印刷质量的科技和数学、化学类文档。 MathJax: https://en.wikipedia.org/wiki/MathJaxMathJax是一种跨浏览器JavaScript库，它使用MathML，LaTeX和ASCIIMathML 标记在Web浏览器中显示数学符号。MathJax作为Apache License下的开源软件。 MathJax语法: https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference 由于许多支持markdown的都不会显示LaTeX公式，所以有一个加载链接来显示的效果。 参考知乎: https://www.zhihu.com/question/26887527 1234#如![](http://latex.codecogs.com/gif.latex?\\frac&#123;1&#125;&#123;1+sin(x)&#125;)#后接具体的公司，注意转移 公式许多扩展的Markdown编辑器支持基于Mathjax编写的数学公式。 LaTeX有两种数学公式： 行内式与其它文字混杂。这是一个$行内式$栗子 块级公式单独成行。$$块级公式$$ 栗子： 12345678这是一个$E=mc^2$公式$$\sum_&#123;i=1&#125;^n a_i=0$$$$f(x_1,x_x,\ldots,x_n) = x_1^2 + x_2^2 + \cdots + x_n^2 $$$$\sum^&#123;j-1&#125;_&#123;k=0&#125;&#123;\widehat&#123;\gamma&#125;_&#123;kj&#125; z_k&#125;$$ 基本类型 上/下标 分式 根式 求和 积分 矩阵 数组 空格 省略号 矢量 括号 希腊字母 上下标 上标(superscript): ^ 下标(subscript): _ 如果上小标内容大于一个字符，要用{}虽然空格和顺序对公式没有影响，但建议使用统一的风格，不用混用： 先下标后上标 先上标后下标 12345678910111213141516171819#上标$$E=mc^2$$#下标$$x_2$$#上下标$$x_&#123;subscript&#125; ^&#123;superscript&#125;$$#左右上下标$$&#123;&#125;_&#123;a&#125; ^&#123;b&#125; x ^&#123;c&#125; _&#123;d&#125;$$$$&#123;&#125;_&#123;左下&#125; ^&#123;左上&#125; x ^&#123;右上&#125; _&#123;右下&#125;$$#空格和顺序其实没影响` 分式分式(fraction)为了区分frac是函数不是公式，使用\frac进行转义 1234567#用法$$\frac&#123;分子&#125;&#123;分母&#125;$$$$\frac&#123;x+y&#125; &#123;2&#125;$$$$\frac&#123;1&#125; &#123;1+\frac&#123;1&#125; &#123;2&#125;&#125; 根式开方(sqrt)使用\sqrt转义 123456789#默认为开平方$$\sqrt[开方次数]&#123;开方因子&#125;$$$$\sqrt &#123;x&#125;$$$$\sqrt[3] &#123;\frac&#123;x&#125; &#123;y&#125;&#125;$$$$\sqrt[x] &#123;1+\sqrt[y] &#123;1+a^2&#125;&#125;$$ 求和求和(summation)使用\sum转义 1234567#用法$$\sum_&#123;起点&#125;^&#123;终点&#125;表达式$$$$\sum_&#123;i=0&#125; ^&#123;n&#125; \frac&#123;1&#125; &#123;k&#125;$$$$\sum_&#123;i=0&#125;^&#123;n&#125; i^2=\frac&#123;(n^2+n)(2n+1)&#125; &#123;6&#125;$$ 积分积分(integral)使用\int转义 12345#用法$$\int_&#123;下限&#125;^&#123;上限&#125; 被积函数d被积量$$$$\int_&#123;a&#125;^&#123;b&#125; f(x)dx$$ 矩阵矩阵(matrix) 1234567891011121314151617181920212223242526#&amp;区分行间元素#\\\\代表换行#无括号矩阵$$\begin&#123;matrix&#125;1 &amp; 2 \\\\ 3 &amp; 4 \end&#123;matrix&#125;$$#花括号矩阵$$\begin&#123;pmatrix&#125; 1&amp;2 \\\ 3&amp;4 \end&#123;pmatrix&#125;$$#中括号矩阵$$\begin&#123;bmatrix&#125; 1&amp;2 \\\\ 3&amp;4 \end&#123;bmatrix&#125;$$#大括号矩阵$$\begin&#123;Bmatrix&#125; 1&amp;2 \\\\ 3&amp;4 \end&#123;Bmatrix&#125;$$#竖线矩阵$$\begin&#123;vmatrix&#125; 1&amp;2 \\\\ 3&amp;4 \end&#123;vmatrix&#125;$$#双竖线矩阵$$\begin&#123;Vmatrix&#125; 1&amp;2 \\\\ 3&amp;4 \end&#123;Vmatrix&#125;$$ 数组数组(array) 空格空格(space/blank) 12345678910111213141516171819202122232425#紧贴$$a\!b$$#正常$$ab$$#小空格$$a\,b$$#中空格$$a\;b$$#大空格$$a\ b$$#quad空格$$a\quad b$$#两个quad空格$$a\qquad b$$ 省略号省略号(ellipsis) \ldots与文本底线对齐的省略号 cdots与文本中线对齐的省略号 1234#\ldot, \cdot可表示单个点，对齐方式不变$$f(x_1,x_2,\ldots,x_n) = x_1^2 + x_2^2 + \cdots + x_n^2$$ 矢量矢量(vector) 1234567#用法$$\vec&#123;矢量值&#125;$$$$\vec&#123;a&#125;$$$$\vec&#123;a&#125; \cdot \vec&#123;b&#125;=0$$ 括号括号(bracket) (), [], |可以直接表示，而{}本来是用于分组，因此需要转义\{\}来表示，也可使用\lbrace, \rbrace来表示。 原始括号并不会随着公式大小缩放，需要使用\left和\right标记实现自适应调整，它两必须成对出现。 12345678910111213141516171819202122232425262728293031323334#小括号()$$(\frac&#123;1&#125;&#123;2&#125;)$$$$\left( \frac&#123;1&#125;&#123;2&#125; \right)$$#中括号[]$$[\frac&#123;1&#125;&#123;2&#125;]$$$$\left[ \frac&#123;1&#125;&#123;2&#125; \right]$$#绝对值|$$|\frac&#123;1&#125;&#123;2&#125;|$$$$\left| \frac&#123;1&#125;&#123;2&#125; \right|$$#大括号&#123;&#125;$$\&#123; \frac&#123;1&#125;&#123;2&#125; \&#125;$$$$\left\&#123; \frac&#123;1&#125;&#123;2&#125; \right\&#125;$$#尖括号&lt;&gt;#\langle \rangle$$\langle \frac&#123;1&#125;&#123;2&#125; \rangle$$$$\left\langle \frac&#123;1&#125;&#123;2&#125; \right\rangle$$#向正无穷大取整(ceil)$$\lceil \frac&#123;1&#125;&#123;2&#125; \rceil$$$$\left\lceil \frac&#123;1&#125;&#123;2&#125; \right\rceil$$#向下取整$$\lfloor \frac&#123;1&#125;&#123;2&#125; \rfloor$$$$\left\lfloor \frac&#123;1&#125;&#123;2&#125; \right\rfloor$$ 希腊字母 大写 LaTex代码 小写 LaTex代码 中文名称 A A α \alpha 阿尔法 B B β \beta 贝塔 Γ Γ γ \gamma 伽马 D D δ \delta 德尔塔 E E ϵ \epsilon 伊普西隆 Z Z ζ \zeta 泽塔 H H η \eta 伊塔 Θ Θ θ \theta 西塔 I I ι \iota 约塔 K K κ \kappa 卡帕 Λ Λ λ \lambda 兰姆达 M M μ \mu 缪 N N ν \nu 纽 X X ξ \xi 克西 O O ο \omicron 欧米克隆 P P π \pi 派 R R ρ \rho 柔 Σ Σ σ \sigma 西格玛 T T τ \tau 陶 Υ Υ υ \upsilon 宇普西隆 Φ Φ ϕ \phi 弗爱 X X χ \chi 卡 Ψ Ψ ψ \psi 普赛 Ω Ω ω \omega 欧米伽 1234567$$\alpha$$$$\beta$$$$\gamma$$$$\delta$$ 特殊符号 关系运算符 集合运算符 对数运算符 三角运算符 微积分运算符 逻辑运算符 带帽符号 连线符号 箭头符号 关系运算符12345678910111213141516171819±：\pm ×：\times ÷：\div ∣：\mid ∤：\nmid ⋅⋅：\cdot ∘：\circ ∗：\ast ⨀：\bigodot ⨂：\bigotimes ⨁：\bigoplus ≤：\leq ≥：\geq ≠：\neq ≈：\approx ≡：\equiv ∑：\sum ∏：\prod ∐：\coprod 集合运算符12345678910111213∅ ：\emptyset ∈：\in ∉：\notin ⊂：\subset ⊃：\supset ⊆：\subseteq ⊇：\supseteq ⊇：\bigcap ⋃：\bigcup ⋁：\bigvee ⋀：\bigwedge ⨄：\biguplus ⨆：\bigsqcup 对数运算符123log：\log lg：\lg ln：\ln 三角运算符123456789⊥ ：\bot ∠：\angle 30∘：30^\circ sin：\sin cos：\cos tan：\tan cot：\cot sec：\sec csc：\csc 微积分运算符123456789′：\prime ∫：\int ∬：\iint ∭：\iiint ∬∬：\iiiint ∮：\oint lim：\lim ∞：\infty ∇：\nabla 逻辑运算符1234567∵ ：\because ∴：\therefore ∀：\forall ∃：\exists ≠：\not= ≯：\not&gt; ⊄：\not\subset 戴帽符号123y^ ：\hat&#123;y&#125; yˇ：\check&#123;y&#125; y˘：\breve&#123;y&#125; 箭头符号123456789101112↑ ：\uparrow ↓：\downarrow ⇑：\Uparrow ⇓：\Downarrow →：\rightarrow ←：\leftarrow ⇒：\Rightarrow ⇐：\Leftarrow ⟶：\longrightarrow ⟵：\longleftarrow ⟹：\Longrightarrow ⟸：\Longleftarrow 生成GitHub上的徽章 生成徽章: https://shields.io/ 生成进度： https://github.com/fehmicansaglam/progressed.io 进入徽章(Badge)网站，找到如下部分生成徽章。之后会得到一个徽章地址，在GitHub中插入此徽章地址就好。 进入进度(Progress)网站，找到某个格式的链接，在GitHub中插入此链接。 编辑器介绍一些常用的书写、编辑Markdown的工具。 MarkdownPad Windows (windows); Texts (Windows, osX); MarkPad (Windows); Haroopad (Windows, osX, Linux); ReText (Linux); 等等 格式转换Markdown文档可以方便地转换为 HTML, Word, PDF 等文件格式。可以利用 软件 或者 命令 转换文件。 转换为 HTML 转换为 PDF 转换为 Word]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx]]></title>
    <url>%2F2017%2F09%2F01%2FNginx%2F</url>
    <content type="text"><![CDATA[参考： Nginx官方文档 Nginx-Wikipedia Nginx-repo 环境： CentOS7x86_64; Nginx1.12.1 Nginx介绍Nginx（发音同engine x）是一个 Web服务器，也可以用作反向代理，负载平衡器和 HTTP缓存。它能反向代理 HTTP, HTTPS, SMTP, POP3, IMAP 的协议连接。基于BSD-like协议发行，支持多种操作系统。 作为HTTP服务软件的后起之秀，Nginx有很多优点： 在性能上，Nginx占用的系统资源更少，支持更多的并发连接（特别是小静态文件场景下），达到更高的访问效率； 在功能上，Nginx不仅是一个优秀的Web服务软件，还可以作为反向代理 负载均衡及缓存使用。它类似于LVS负载均衡及HAProxy等专业代理软件，又类似于Squid等专业缓存服务软件； 在安装配置上，Nginx方便、简单、灵活。 Nginx功能丰富，可作为HTTP服务器、反向代理服务器、邮件服务器。支持FastCGI, SSL, Virtual Host, URL Rewrite, Gzip等功能，并支持很多第三方模块扩展。 与PHP的集成自PHP-5.3.3起，PHP-FPM加入到了PHP核心，编译时加上–enable-fpm即可提供支持。PHP-FPM以守护进程在后台运行，Nginx响应请求后，自行处理静态请求，PHP请求则经过fastcgi_pass交由PHP-FPM处理，处理完毕后返回。Nginx和PHP-FPM的组合，是一种稳定、高效的PHP运行方式，效率要比传统的Apache和mod_php高出不少。 Nginx的重要特性： 可针对静态资源高速高并发访问及缓存；可使用反向代理加速，并且可进行数据缓存；具有简单负载均衡、节点健康检查和容错功能；支持远程FastCGI、Uwsgi、SCGI、Memcached Servers的加速和缓存；支持SSL、TLS、SNI；具有模块化的架构：过滤器包括gzip压缩、ranges支持、chunked响应、XSLT、SSI及图像缩放等功能。在SSI过滤器中，一个包含多个SSI的页面，如果FastCGI或反向代理处理，可被并行处理；它具备的其他WWW服务特性：支持基于名字、端口及IP的多虚拟主机站点；支持Keep-alived和pipelined连接；可进行修改Nginx配置，并且在代码上线时，可平滑重启，不中断业务访问；可自定义访问日志格式，临时缓冲些日志操作，快速日志轮询及通过rsyslog处理日志；可利用信号控制Nginx进程；支持 3xx-5xx HTTP状态码重定向；支持rewrite模块，支持URI重写及正则表达式匹配；支持基于客户端IP地址和HTTP基本认证的访问控制；支持PUT、DELETE、MKCOL、COPY及MOVE等较特殊的HTTP请求方法；支持FLV流和MP4流技术产品应用；支持HTTP响应速率限制；支持同一IP地址的并发连接或请求数连接；支持邮件服务器代理； Nginx常用功能http代理于反向代理Nginx在做反向代理时，提供性能稳定，并且能够提供配置灵活的转发功能。Nginx可以根据不同的正则匹配，采取不同的转发策略，比如图片文件结尾的走文件服务器，动态页面走web服务器，只要你正则写的没问题，又有相对应的服务器解决方案，你就可以随心所欲的玩。并且Nginx对返回结果进行错误页跳转，异常判断等。如果被分发的服务器存在异常，他可以将请求重新转发给另外一台服务器，然后自动去除异常服务器。 负载均衡Nginx提供的负载均衡策略有2种：内置策略和扩展策略。内置策略为轮询，加权轮询，Ip hash。扩展策略，就天马行空，只有你想不到的没有他做不到的啦，你可以参照所有的负载均衡算法，给他一一找出来做下实现。 web缓存Nginx可以对不同的文件做不同的缓存处理，配置灵活，并且支持FastCGI_Cache，主要用于对FastCGI的动态程序进行缓存。配合着第三方的ngx_cache_purge，对制定的URL缓存内容可以的进行增删管理。 web服务Nginx作为Web服务器的主要应用场景包括： 使用Nginx运行HTML、JS、CSS、小图片等静态数据； 结合FastCGI运行PHP等动态程序（如fastcgi_pass）； 结合Tomcat/Resin等支持Java动态程序（如proxy_pass）。 Nginx安装RPM源安装:12345678yum install -y gcc gcc-c++ make libtool zlib zlib-devel openssl openssl-devel pcre pcre-devel 安装依赖rpm -ivm http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm 安装RPM源#安装Nginxyum install -y nginx#查询安装rpm -q nginx 添加Nginx yum repository安装12345678910vim /etc/yum.repos.d/nginx.repo#必须唯一[nginx]name=nginx-repobaseurl=http://nginx.org/packages/$OS/$OSRELEASE/$basearch/gpgcheck=0enabled=1 源码安装12345678910#建议解压于此目录cd /usr/local/srcwget http://xxx.xx.com/nginx.tar.gztar -zxvf nginx.tar.gzcd ./nginx./configure --prefix=/usr/localmake&amp;&amp;make install Nginx配置*.confNginx配置文件主要分为四部分： main(全局设置)； server(主机设置)； upstream(上游服务器设置)，用于反向代理和负载均衡； location(URL匹配特定位置)。 栗子：运行nginx -t检查配置文件有误错误，这很重要! 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#main块user nginx;worker_processes 4;client_max_body_size 10Merror_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 102400;&#125;#http块http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - ...'; access_log /var/log/nginx/access.log main; sendfile on; gzip on; keepalive_timeout 60; include /etc/nginx/conf.d/*.conf; #upstream块 upstream up_name&#123; server ip1; server ip2:port; server domain; &#125; server &#123; server_name www.zhang21.cn; listen 80; listen 443; ssl on; ssl_certificate /dir/path/xxx.crt; ssl_certificate_key /dir/path/xxx.key; location / &#123; root /var/www/zhang; index index.php index.html index.htm; allow 192.168.1.0/22; deny all; &#125; location ~ \.php$ &#123; root /var/www/zhang; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; &#125; &#125;&#125; 全局块：配置影响Nginx全局的指令。一般由运行Nginx服务器的用户组，Nginx进程pid存放路径，日志存放路径，允许生成的worker_processes等。 events块：配置影响Nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网络连接，开启多个网络连接序列化等。 http块：可以嵌套多个server，配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，链接超时时间，单连接请求数等。 server块：配置虚拟主机的相关参数，一个http中可以有多个server。 location块：配置请求的路由，以及各种页面的处理情况。 Nginx http功能模块 模块说明 ngx_http_core_module 一些核心的http参数配置，对应Nginx的配置中的http块 ngx_http_access_module 访问控制模块，用来控制网站用户对Nginx的访问 ngx_http_gzip_module 压缩模块，对Nginx返回的数据压缩，属于性能优化模块 ngx_http_fastcgi_module FastCGI模块，和动态应用相关的模块，如PHP ngx_http_proxy_module proxy代理模块 ngx_http_upstream_module 负载均衡模块，可实现网站的负载均衡及节点的监控检查 ngx_http_rewrite_module URL重写模块 ngx_http_limit_conn_module 限制用户并发连接数及请求数模块 ngx_http_limit_req_module 根据定义的key限制Nginx请求过程的速率 ngx_http_log_module 访问日志模块，以指定的格式记录Nginx访问信息 ngx_http_auth_basic_module web认证模块，设置通过账号，密码访问Nginx ngx_http_ssl_module ssl模块 ngx_http_stub_status_module 记录Nginx基本访问状态信息扥的模块 Nginx的日志时自动切割，并且一行可以记录多个日志格式。 Nginx日志格式 说明 $remote_addr 客户端ip地址 $http_x_forward_for 当前端有代理服务器时，设置web节点记录web节点记录客户端地址的配置 $remote_user 客户端用户名称 $time_local 访问时间和时区 $request 请求的http协议和URL $status 请求状态，如200 $body_bytes_sent 发送给客户端文件主体内容大小 $http_referer 从哪个页面链接访问过来 $http_user_agent 客户端浏览器信息 serverhttp服务上支持若干虚拟主机。每个虚拟主机对应一个server配置项，配置项里面包含该虚拟主机的相关配置。每个server里面可同时有多个server_name。 在提供mail代理服务时，也可建立若干server，每个server通过监听地址或端口来区分。 12345#监听端口，默认80listen 80;listern 443;#listen 88server_name www.zhang21.cn locationlocation是http服务中，某些特定的URL对应的一系列配置项。 root 定义此location的根目录位置，一般放置在server里 index 定义路径下的默认访问的文件名 12345location / &#123; root /dir/path; index index.html index.htm;&#125; location的正则写法location的使用方法： 符号 含义 优先级 用法 = 精确匹配 最高 location = ~ 区分大小写的正则匹配 次次之 location ~ ~* 不区分大小写的正则匹配 次次之 location ~* ^~ 常规字符串匹配 次之 location ^~ / 通用匹配 最低 location / 优先级： = &gt; 完整路径 &gt; ^~ &gt; ~, ~* &gt; 部分路径 &gt; / location使用建议location的使用根据实际情况来定。 但个人觉得至少应该有三个匹配规则： 直接匹配网站跟，通过域名访问网站首页比较频繁 处理静态文件请求，这是Nginx作为http服务器的强项 通用规则，用来转发动态请求到后端的应用服务器(符php-fpm) 根据实际情况的自定义需求 1234567891011121314151617181920212223242526272829303132333435363738394041server &#123; listen 80; listen 443; server_name zhang21.cn www.zhang21.cn; root /dir/path/zhang; ssl on; ssl_certificate /etc/nginx/ssl/zhang.crt; ssl_certificate_key /etc/nginx/ssl/zhang.key; #rewtire ^(.*)$ https://zhang21.cn/$1 permanent; return 301 https://zhang21.cn/$requets_uri location = / &#123; rewrite .*? /index.html last; &#125; location ^~ /static/ &#123; root /dir/path/zhang/static; &#125; location ~* \.(gif|jpg|png|css|js)$ &#123; root /dir/path/zhang/static; &#125; location / &#123; if (!-f $request_filename) &#123; rewrite ^([^\?]+)$ /index.php?q=$1 last; &#125; location ~ \.php$ &#123; root /dir/path; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; &#125;&#125; RewriteNginx的主要功能是实现URL地址重写。Nginx的rewrite规则需要PCRE软件的支持，即通过Perl兼容正则表达式语法进行规则匹配。 Nginx rewrite语法： 123server, location, ifrewrite regex replacement [flag] rewrite的功能就是，使用Nginx提供的全局变量或自定义变量，结合正则表达式(re)和标志位实现URL重写以及重定向 rewrite只能放在server，location，if中，并且只能对域名后边的除去传递的参数外的字符串起作用 如果相对域名或参数字符串起作用，可以使用全局变量匹配，也可使用proxy_pass反向代理 表面看rewrite和location功能有点像，都能实现跳转。主要区别在于： rewrite实在同一域名内更改获取资源的路径 location是对一类路径做访问控制或反向代理，可proxy_pass到其它机器 循环超多10次，返回500 Internal Server Error! flag last 表示完成rewrite，继续向下匹配新的规则 break 停止执行当前虚拟主机的后续rewrite指令集 redirect 返回302临时重定向，地址栏会显示跳转后的地址 permanent 返回301永久重定向，地址栏会显示跳转后的地址 last和break用来实现URL重写，浏览器地址栏的URL地址不变，但在服务器端访问的程序及路径发生了变化 redirect和permanent用来实现URL跳转，浏览器地址栏会显示跳转后的URL地址 Nginx的rewrite功能应用非常广泛： 可调整用户浏览的URL，使其看起来更规范 将动态URL地址伪装成静态地址提供服务 让旧域名跳转到新域名上 根据特殊变量、目录、客户端的信息进行URL跳转 if指令if语法： 123if (condition) &#123; xxx;&#125; if的条件可以是如下内容： 当表达式只是一个变量时，如果值为空或任何以0开头的字符串都会被当作false 直接比较变量和内容时，使用=或!= ~正则表达式匹配，~*不区分大小写的正则匹配，!~不匹配 -f和!-f，用来判断是否存在文件 -d和!-d，用来判断是否存在目录 -e和!-e，用来判断时都存在文件或目录 -x和!-x，用来判断文件是否可执行 栗子： 123456789101112131415161718192021222324if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break;&#125;if ($http_cookie ~* "id=([^;])(?:;|$)") &#123; set $id $1;&#125;if ($http_method = POST) &#123; return 405;&#125;if (!-f $request_filename) &#123; break; proxy_pass http://zhang;&#125;if ($invalid_referer) &#123; return 403;&#125; Nginx全局变量常用作if判断的全局变量： 变量 描述 备注 $args 等于请求行中的参数 同$query_string $body_bytes_sent 响应是发送的body字节数 xxx $content_length Request Header中的Content-Length字段 内容长度 $content_type Request Header中的Content-Type字段 内容类型 $document_root 当前根路径 xxx $host 请求主机头字段，否则为服务器名称 xxx $hostname 主机名 xxx $http_user_agent 客户端agent信息 xxx $http_cookie 客户端cookie信息 xxx $is_args 如果有$args参数，这个变量等于”?”，否则等于空 xxx $limit_rate 限制连接数度 xxx $remote_addr 客户端IP地址 xxx $remote_port 客户端端口 xxx $remote_user 经过Auth Basic Module验证的用户名 要先开启Nginx认证 $request 用户请求信息 xxx $request_method 客户端请求方法 通常为POST或GET $request_body 记录POST过来的数据信息 xxx $request_filename 当前请求的文件路径 由root或alias指令与URI请求生成 $request_completion 如果请求结束，设置为OK。否则为空 xxx $scheme HTTP方法 如http, https $server_protocol 请求使用的协议 通常为HTTP/1.0或HTTP/1.1 $server_addr 服务器地址 在完成一次系统调用后可以确定这个值 $server_name 服务器名称 xxx $server_port 请求到达服务器的端口号 xxx $status 请求的响应状态码 如200 $request_uri 包含请求参数的原始URI，不包含主机名 如”/foo/bar.php?arg=abc” $uri 不带请求参数的当前URI，不包含主机名 如”/foo/bar.html” 栗子： 12345678http://localhost:88/test1/test2/test.php$hsot: localhost$server_port: 88$request_uri: http://localhost:88/test1/test2/test.php$document_uri: /test1/test2/test.php$document_root: /var/www/test$request_filename: /var/www/test/test1/test2/test.php rewrite实例12345678910111213141516171819202122232425http &#123; log_format main xxxx; rewrite_log on; server &#123; root /var/www/zhang; location / &#123; error_log logs/rewrite.log notice; rewrite '^/images/([a-z]&#123;2&#125;)/([a-z0-9]&#123;5&#125;)/(.*)\.(png|jpg|gif)'/data?file=$3.$4; set $image_file $3; set $image_type $4; &#125; location /data &#123; access_log logs/images.log main; root /data/images; type_file /$arg_file /images404.html; &#125; location = /image404.html &#123; return 404 "Image Not Found\n"; &#125; &#125;&#125; 访问控制 添加用户密码验证 参考: https://docs.nginx.com/nginx/admin-guide/security-controls/configuring-http-basic-authentication/ 有时需要为我们的网站设置访问账号和密码权限。注意，此密码需要使用加密软件生成，直接写入密码的明文无效。 具体为这两个参数： auth_basic 默认值： auth_basic off; 使用位置：http, server, location, limit_except auth_basic_user_file 使用位置： http, server, location, limit_except 栗子： 12345678cd /etc/nginx/conf.dvim test.conflocation / &#123; auth_basic "nginx auth test"; auth_basic_user_file /etc/nginx/.auth;&#125; 配置用户密码 123456789101112#Verify that apache2-utils (Debian, Ubuntu) or httpd-tools (RHEL/CentOS/Oracle Linux) is installed.yum install -y httpd-tools#htpasswd file usernamehtpasswd .auth user1New password:Re-type new password:Adding password for user user1#查看加密密码cat .authuser1:$apr1$NIOeayen$hTAvJ5ZTwUHE6Hm1MiF920 限制IP访问 allow deny 1234567891011server &#123; ... allow IP1 allow IP2; deny all; location / &#123; allow IP 1; deny all; &#125;&#125; 注意： deny一定要加一个IP，否则会直接跳转403，不在往下执行。如果403默认页是在同一域名下，会造成死循环访问 对于allow的IP短，从允许访问的IP段位从小到大排列，如127.0.0.0/24， 10.10.0.0/16 以deny all结尾，表示除了上面允许的，其它都禁止 语法检查在启动或重启Nginx服务前检查语法非常重要，可以防止因配置错误导致网站重启或重载配置对用户的影响。 每次更改Nginx配置文件后都需要重新加载，将配置信息加载到内存中。这样设计的目的是大幅度提升Nginx的访问性。 123nginx -tnginx -s reload Nginx优化 常用优化 隐藏Nginx版本号一般来说，软件漏洞都和版本有关。因此要尽量隐藏对访问用户显示各类敏感信息。 123456789vim /etc/nginc/nginx.conf#nginx版本号默认是开启的#位置：http, server, locationhttp &#123; server_tokens off|on;&#125; 更改Nginx服务默认用户 修改配置文件 123vim /etc/nginx/nginx.confuser nginx; 如果是编译安装，直接在编译的时候指定用户和组 1./configure --user=nginx --group=nginx 优化Nginx进程对应的配置123456789101112vim /etc/nginx/nginx.confworker_process n;#建议n为CPU核数#高并发场合可考虑为核数*2#查看CPU核数cat /proc/cpuinfo | grep processor | wc -llscputop命令，按1显示所有CPU核数 优化绑定不同的Nginx进程到不同的CPU上默认情况下，Nginx的多个进程有可能跑在某一个CPU或CPU的某一核上，导致Nginx进程使用硬件资源不均。所以，要尽可能地分配不同的Nginx进程给不同的CPU处理，达到充分有效利用硬件的多CPU多核资源的目的。 4核CPU配置举例： 12345vim /etc/nginx/nginx.confworker_processes 4;#CPU亲和力参数worker_cpu_affinity 0001 0010 0100 1000; Nginx事件处理模型优化Nginx的连接处理机制在不同的操作系统会采用不同的I/O模型，在Linux下，Nginx使用epoll的I/O多路复用模型，在FreeBSD中使用kqueue的I/O多路复用模型，在solaris中使用/dev/poll方式的I/O多路复用模型，在Windows中使用的是icop。 配置： 12345678#对于linux内核，推荐使用epoll工作模式#Linux下默认epollvim /etc/nginx/nginx.confevents &#123; use epoll;&#125; Nginx单个进程允许的客户端最大连接数请根据服务器性能和程序的内存使用量来合理制定最大连接数。这个连接数包括了所有连接，如代理服务器连接、客户端的连接、实际的并发连接。 Nginx总并发连接数=worker*worker_connections 123456vim /etc/nginx/nginx.confevents &#123; worker_connections 10240;&#125; 仅仅修改了nginx最大连接数可能还不行，由于Linux系统有ulimit限制，所以可能还要做额外操作。 如：nginx: [warn] 10240 worker_connections exceed open file resource limit: 1024。 配置： 123ulimit -aulimit -n 10240 注意，使用ulimit命令修改的值并不是永久生效的。 Nginx worker进程最大打开文件数可能也要注意ulimit系统限制！ 12345vim /etc/nginx/nginx.confevents &#123; worker_rlimit_nofile 65535;&#125; 开启高效文件传输sendfilesendfile()是作用于两个文件描述符之间的数据拷贝，这个拷贝是在内核之中的，被称为零拷贝。sendfile（）比read和write函数要高效很多，因为write和read函数要把数据拷贝到应用层再进行操作。 12#位置：http, server, location, if in locationsendfile on; tcp_nopush激活或禁用Linux上的TCP_CORK socket选项，仅当开启sendfile生效。允许把 http response和文件的开始部分放在一个文件里发布，其积极作用是减少网络报文段的数量。 12位置： http, server, locationtcp_nopush on; Nginx连接参数，连接超时时间keep-alive可以使客户端到服务器端已经建立的连接一致工作不退出，当服务器有持续请求时，keep-alive会使用已经建立的连接提供服务，从而避免服务器重新建立新连接请求处理。 连接超时的作用： 将无用的连接设置为尽快超时，可保护系统资源（CPU、内存、磁盘）连接很多时，及时断掉那些已经建立好但又长时间不做事的连接，以减少其占用的服务器资源。因为服务器维护连接也是消耗资源的黑客和恶意用户攻击网站，也会不断地和服务器建立多个连接，消耗连接数但啥也不干，大量消耗服务器的资源，此时就应该及时断掉这些恶意占用资源的连接LNMP环境中，如果用户请求了动态服务，则Nginx就会建立连接，请求FastCGI服务以及后端的MySQL服务，此时这个Nginx连接就要设置一个超时时间，在用户容忍的时间内返回数据，或者再多等一会后端服务返回数据，具体策略根据具体业务进行具体分析后端的FastCGI服务及MySQL服务也有对连接的超时控制 12位置： http, server, locationkeepalive_timeout 60; 默认情况下当数据发送时，内核并不会马上发送，可能会等待更多的字节组成一个数据包，这样可以提高I/O性能。但是，在每次只发送很少字节的业务场景中，不使用tcp_nodelay功能，等待时间会比较长。 12位置： http, server, locationtcp_nodelay on; 读取客户端请求头数据的超时时间，如果超过这个时间，客户端还没有发送完整的header数据，服务器端将返回“Request time out（408）”错误。 12位置： http, serverclient_header_timeout 20; 读取客户端请求主体的超时时间，如果在这个超时时间内，客户端没有发送任何数据，Nginx将返回“Request time out（408）”错误。 12位置： http, server, locationclient_body_timeout 60; 指定响应客户端的超时时间，为握手后的一个超时。如果超过这个时间，客户端没有任何活动，Nginx将会关闭连接。 12位置： http, server, locationsend_timeout 60; 上传文件大小限制(动态应用)设置为0，表示禁止检查客户端请求主体的大小。 12位置： http, server, locationclient_max_body_size 20m; gzip压缩Nginx gzip压缩模块提供了压缩文件内容的功能，用户请求的内容在发送到用户客户端之前，Nginx服务器会根据一些具体的策略实施压缩，以节约网络出口带宽，同时加快数据传输效率，提升用户体验。 压缩对象： 纯文本内容压缩比很高，如 html, js, css, xml等 被压缩的纯文本文件必须要大于1KB，由于压缩算法的特殊原因，极小的文件压缩后可能反而变大 图片、媒体等文件尽量不要压缩，因为这些文件大都经过压缩，再压缩很可能不会减小很多，或有可能增大，同时还要消耗系统资源 配置： 1234567891011121314151617181920212223242526#压缩功能gzip on;#允许压缩的页面最小字节数gzip_min_length 1K;#申请4个单位为16K的内存作为压缩结果流缓存gzip_buffers 4 16K;#http协议版本gzip_http_version 1.1;#指定压缩比，1压缩比最小，处理速度最快；9压缩比最大，传输速度最快，处理最慢gzip_comp_level 5;#指定压缩类型，对应文件类型参考mime.typesgzip_types text/html text/css;#vary header支持gzip_vary on; 在response header中查看效果： Content-Encofing: gzip expires缓存Nginx expires的功能就是为用户访问的网站内容设定一个过期时间。 当用户第一次访问这些内容时，会把这些内容储存在用户浏览器本地，这样用户第二次及以后继续访问该网站时，浏览器会检查加载已经缓存在用户浏览器本地的内容，而不用去服务器下载，直到缓存的内容过期或被清除为止。 缓存也要根据业务！当网站数据更新时，用户端看到的可能还是旧的已经缓存的内容。 配置： 根据文件扩展名进行判断 12345678location ~ .*\.(gif|png|jpg|swf)$ &#123; expires 10d;&#125;location ~ .*\.(css|js)$ &#123; expires 20d;&#125; 根据目录进行判断 123location ~ ^/(images|static|media)/ &#123; expires 50d;&#125; 在response header中查看： Expires: 缓存过期时间Cache-Control： 缓存总时间 FastCGI相关参数FastCGI参数是配合Nginx向后请求PHP动态引擎服务的相关参数，这里指的是Nginx中的配置参数。 Module ngx_http_fastcgi_module： https://nginx.org/en/docs/http/ngx_http_fastcgi_module.html 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#给FastCGI服务器设置地址fastcgi_pass#设置一个将在 $fastcgi_scripts_name 变量结尾的URI之后添加的文件名fastcgi_index#设置一个应该传递给FastCGI服务器的参数，当且仅当fastcgi_param在当前级别上没有定义指令时，这些指令将从上一级继承fastcgi_param#指定在哪种情况下将请求传递给下一个服务器；fastcgi_next_upsteam#表示Nginx服务器和后端FastCGI服务器连接的超时时间，默认值为60秒，这个参数通常不要超过75秒fastcgi_connect_timeout#设置Nginx允许FastCGI服务器端返回数据的超时时间，即在规定时间之内后端服务器必须传完所有的数据。否则，Nginx将断开这个连接fastcgi_send_timeout#设置Nginx从FastCGI服务器端读取响应信息的超时时间，表示连接建立成功后，Nginx等待后端服务器的响应时间，是Nginx已经进入后端的排队之中等候处理的时间fastcgi_read_timeout#这是Nginx FastCGI的缓冲区大小参数，设定用来读取从FastCGI服务器端收到的第一部分响应信息的缓冲区大小，这里的第一部分通常会包含一个小的响应头部fastcgi_buffer_size#设定用来读取从FastCGI服务器端收到的响应信息的缓冲区大小和缓冲区数量fastcgi_buffers#用于设置系统很忙时可以使用的proxy_buffers大小，官方推荐大小为proxy_buffers * 2proxy_busy_buffers_size #用于设置系统很忙时可以使用的fastcgi_buffers大小，官方推荐为 fastcgi_buffers * 2fastcgi_busy_buffers_size#FastCGI临时文件大小fastcgi_temp_file_write_size#表示开启FastCGI缓存并为其指定一个名称fastcgi_cache cachename_nginx#fastcgi_cache缓存目录fastcgi_cache_path#用来指定应答代码的缓存时间fastcgi_cache_valid#设置请求几次之后响应将被缓存fastcgi_cache_min_uses#定义在哪些情况下使用过期缓存fastcgi_cache_use_stale#定义fastcgi_cache的keyfastcgi_cache_key 日志与安全现在Nginx 日志已经自动轮询了，所以感觉没有必要自己切割日志！ 不记录不需要的日志日志写入太频繁会消耗大量的磁盘I/O，降低服务性能。 123location ~ .*\.(js|png|css|gif|jpg) &#123; access_log off;&#125; 日志权限因为nginx master process的UID是root，所以可以修改日志权限。不需要在日志目录上给Nginx用户读或写许可，很多人没注意这个问题，把权限直接给了Nginx用户，这就存在安全隐患。 12chown -R root:root /path/log/nginxchmod -R 700 /path/log/nginx 站点目录及URL访问控制根据扩展名限制程序或文件访问利用Nginx配置禁止访问上传资源目录下的PHP、Shell、Perl、Python程序文件，这样用户即使上传了木马文件也没法执行，从而加强了网站的安全。 对这些的限制必须放在Nginx处理.php, .py, .sh等文件的前面！ 1234567891011121314151617#禁止解析指定目录下的程序location ~ ^/images/.*\.(php|py|sh|pl)$ &#123; deny all;&#125;location ~ ^/static/.*\.(py|php|pl|sh) &#123; deny all;&#125;#禁止访问某些文件location ~* \.(txt|doc)$ &#123; root /var/www/file; deny all;&#125; 禁止访问指定目录123456789101112131415location ~ ^/test/ &#123; deny all;&#125;#禁止访问多个目录location ~ ^/(test|zhang) &#123; deny all;&#125;#返回状态码location ~ ^/haha/ &#123; return 403 "Hahaha";&#125; 禁止非法域名解析访问网站防止用户恶意域名解析。 1234567891011121314151617181920cd /etc/nginx/conf.dvim default.conf#返回HTTP状态码server &#123; listen 80 default_server; server_name _; return 403;&#125;#重定向server &#123; listen 80 default_server; server_name _; rewrite ^(.*) https://www.baidu.com permanent;&#125; 利用default_server，将网站所有请求定向到维护页面。 1234567891011121314151617181920212223242526272829303132333435server &#123; listen 80 default_server; server_name _; root /var/www; location / &#123; rewrite ^(.*) /maintance.html break; &#125;&#125;cd /var/wwwvim maintance.html&lt;html&gt;&lt;head&gt;&lt;meta charset="UTF-8"&gt;&lt;style type="text/css"&gt; h1&#123;text-align: center; color: red;&#125;&lt;/style&gt;&lt;/head&gt;&lt;br&gt;&lt;br&gt;&lt;body&gt;&lt;h1&gt;网站维护中！&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 图片及目录防盗链 什么是资源盗链简单地说，就是某些不法网站未经许可，通过在其自身网站程序里非法调用其他网站的资源，然后在自己的网站上显示这些调用的资源，达到填充自身网站的效果。 这一举动不仅浪费了调用资源网站的网络流量，还造成其他网站的带宽及服务压力吃紧。 问题： 某公司CDN源站流量没有变化，但CDN加速那边流量超了很多。这么大异常流量，全都是钱呀！ 常见防盗链解决方案 根据HTTP referer 实现防盗链在HTTP 协议中，有一个表头字段叫 referer，使用URL格式来表示是哪里的链接用了当前网页的资源。 通过referer可以检测访问的来源网页，如果是资源文件，可以跟踪到显示它的网页地址，一旦检测出来不是本站，马上进行阻止。 HTTP referer 是header的一部分，当浏览器向web服务器发送请求时，一般会带上referer，告诉服务器我是从哪个页面过来的，服务器借此获得一些信息用于处理。 根据cookie防盗链通过加密技术变换访问路径实现防盗链 Nginx实现防盗链利用referer，针对指定扩展名进行rewrite或其他操作。 请根据实际情况进行域名防盗链！ 123456location ~* \.(jpg|png|gif|wav|mp3|zip|rar)$ &#123; valid_referers none blocked *.zhang.com; if ($invalid_regerer) &#123; rewrite https://www.baidu.com; &#125;&#125; 或者在产品设计上解决防盗链，如为资源加上水印等措施。 错误页面优雅展示我们可以将404、403等错误信息重定向到其他指定的页面，提升网站的用户访问体验！ 123456789101112location / &#123; xxxx; error_page 403 /403.html; error_page 404 /404.jpg; error_page 500 503 504 /50x.html; location = /50x.html &#123; root /var/www/50x.html; &#125;&#125; 目录及文件权限优化为了保证网站安全，所有站点的目录和用户组都为root，所有目录权限是755，所有文件权限是644。虽然这样的全线可以防止黑客上传修改站点的文件，但这样合法的用户便也没有了上传权限。 比较好的方法是将用户上传文件的服务器与读取服务器进行分离，这样就可以进行安全授权。不同的服务所在的目录的权限依据业务功能而不同。 严格控制Nginx目录的访问才能降低网站被入侵的风险！ 反爬虫优化 robots.txt机器人协议robots协议(维基百科)，也称为机器人协议，全称是网络爬虫排除标准（Robots Exclusion Protocol）。网站通过Robots协议告诉搜索引擎那些页面可以抓取，那些页面不能抓取。 robots.txt协议并不是一个规范，而只是约定俗成的，所以并不能保证网站的隐私。 123User-Agent: *Allow: /zhangDisallow: / Nginx反爬虫配置123456789if ($http_user_agent ~* LWP::Simple|BBBike|wget) &#123; return 403;&#125;if （$http_user_agent ~* (Firefox|MSIE) &#123;rewrite ^（.*） http://www.baidu.com:&#125; 限制HTTP请求方法123if ( $request_method !~ ^(GET|POST|HEAD)$ ) &#123; return 501;&#125; CDNCDN的全称是 Content Delivery Network，中文意思是内容分发网络。我们可以利用CDN做网站内容加速。 简单地讲，通过现有的Internet中增加一层新的网络架构，将网站的内容发布到最接近用户的Cache服务器内，通过智能DNS负载均衡技术，判断用户的来源，让用户就近使用与服务器相同线路的带宽访问Cache服务器，取得所需的内容。 例如，北京电信用户访问北京电信Cache服务器上的内容，四川网通用户访问成都网通Cache服务器上的内容。这样可以有效减少数据在网络上传输的时间，提高访问速度。CDN是一套全国或全球的风不是缓存集群，其实质是通过职能DNS判断用户的来源地域及上网线路，为用户选择一个最接近用户地域，以及和用户上网线路相同的服务器节点。因为低于近，线路相同，所以可以大幅度提升用户浏览网站的体验。 CDN的价值： 提升用户体验 阻挡大部分流量攻击 CDN的特点： 通过服务器内存缓存网站数据，提高了企业站点（尤其是含有大量图片、视频等的站点）的访问速度，并大大提高企业站点的稳定性； 用户根据智能DNS技术自动选择最适合的Cache服务器，降低不同运营商之间互联瓶颈造成的影响，实现了跨运营商的网络加速，保证不同网络中的用户都能得到良好的访问速度； 加快了访问速度，减少了原站点的带宽； 用户访问时从服务器的内存中读取数据，分担了网络流量，同时减轻了原站点负载压力； 使用CDN可以分担源站的网络流量，同时减轻源站的负载压力，并降低黑客入侵及各种DDOS攻击对网站的影响，保证网站有较好的服务质量； 使用CDN的要求首先要说的是，不是所有的网站都可以一上来就能用CDN的。要加速的业务数据应该存在独立的域名。如 pub.zhang21.com，业务内容图片、附件、JS、CSS等静态元素，这样的静态网站域名才能使用CDN。 将域名做CNAME(别名)将如上的pub.zhang21.com配置成CDN的域名。 程序架构优化解耦 是开发人员中流行的一个名词，简单地说就是把一堆程序代码按照业务用途分开，然后提供服务。 例如，注册登录、上传、下载、浏览、商品页信息等都应该是独立的程序服务，只不过在客户端看来是一个整体而已。 分离的最佳方式是分别使用独立的服务器，可以选择改动程序或者在负载均衡器上配置（如Nginx），过滤请求，然后抛给后面对应的服务器。 根据扩展名分发，请求图片就抛给图片服务器； 根据URL路径转发，请求下载就交给下载服务器； 请求动态PHP处理的就交给动态处理器； 不符合以上要求的就交给默认服务器； 使用no-root用户启动Nginx默认情况下，Nginx的Master进程使用的是root用户，worker进程使用的是Nginx指定的普通用户。 使用root用户跑Nginx的Master进程有两个最大问题： 管理权限必须是root，这就使得最小化分配权限原则遇到困难 使用root跑Nginx服务，一旦网站出现漏洞，用户就可以很容易地获取服务器的root权限 控制Nginx并发连接数ngx_http_limit_conn_module这个模块用于限制每个定义的Key值的连接数，特别是单IP的连接数。 不是所有的连接数都会被计数，一个符合要求的连接是整个请求头已经被读取的连接。 用法： 1234567#位置： httplimit_conn_zone key zone=name:size;#位置： http, server, locationlimit_conn zone number; 栗子： 123456789101112http &#123; limit_conn_zone $binary_remote_addr zone=addr:10m; xxx;&#125;server &#123; xxx; location /download/ &#123; limit_conn addr 3; #限制单IP并发连接为3 &#125;&#125; 控制客户端请求Nginx的速率ngx_http_limit_req_module被用来限制每个IP访问没法key的请求速率。 用法： 1234567#位置： httplimit_req_zone key zone=name:size rate=rate;#位置： http, server, locationlimit_req zone=name; 栗子： 123456789http &#123;limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; server &#123; location /search/ &#123; limit_req zone=one burst=5; &#125; &#125;&#125; upstream模块 反向代理与负载均衡严格地说，Nginx仅仅是作为Nginx Proxy反向代理使用的，因为这个反向代理功能表现的效果是负载均衡集群的效果，所以本文称之为Nginx负载均衡。 普通的负载均衡软件，如LVS，其实现的功能只是对请求数据包的转发、传递，从负载均衡下的节点服务器来看，接收到的请求还是来自访问负载均衡器的客户端的真实用户 反向代理服务器在接收访问用户请求后，会代理用户 重新发起请求代理下的节点服务器，最后把数据返回给客户端用户。在节点服务器看来，访问的节点服务器的客户端用户就是反向代理服务器，而非真实的网站访问用户 即，LVS等负载均衡是转发用户请求的数据包，而Nginx反向代理是接收用户请求后重新发起请求后端节点 这里我去看了一下Nginx的access.log，客户端的访问日志全在代理节点上（Nginx-upstream），而后端节点的access.log的来源是前端代理节点的IP Nginx负载均衡的组件实现Nginx负载均衡的组件主要有两个: proyx upstream Nginx_http模块 模块说明 ngx_http_proxy_module proxy代理模块，用于把请求后抛给服务器节点或upstream服务器池 ngx_http_upstream_module 负载均衡模块，可以实现网站的负载均衡功能即节点的健康检查 nginx upstream模块 upstream模块介绍Module ngx_http_upstream_module: https://nginx.org/en/docs/http/ngx_http_upstream_module.html upstream主要是用于七层上的负载均衡和转发。 123Syntax： upstream name &#123; ... &#125;Default: —Context: http Nginx的负载均衡功能依赖于ngx_http_upstream_module模。所支持的代理方式包括： proxy_pass fastcgi_pass memcached_pass uwsgi_pass scgi_pass upstream模块允许Nginx定义一组或多组节点服务器组，使用时可通过proxy_pass代理方式把网站的请求发送到事先定义好的对应upstream组的名字上。 upstream模块内容放置于http{}内: 12345678910111213141516171819202122232425262728293031323334upstream upstream_name &#123; server address [ parameters ]&#125;####栗子http &#123; upstream zhang &#123; server 192.168.1.22:8080 weight=5; server www.zhang.cn weigh=5 max_conns=102400; server 192.168.33 max_fails=2 fail_timeout=20s; server backup.zhang.cn backup; &#125;&#125;server &#123; location / &#123; proxy_pass http://zhang; &#125;&#125;####reslovehttp &#123; resolver 10.0.0.1; upstream u &#123; zone ...; ... server example.com resolve; &#125;&#125; address可以是主机名、域名、ip或Unix Socket，也可以指定端口号 域名时需要解析的哦 parameters代表可选参数, 有如下： backup，表示当前server是备用服务器，只有其它非backup后端服务器都挂掉了或很忙才会分配请求给它 max_conns，限制同时连接到代理服务器的最大数量。默认值为0，表示没有限制。 weight，表示当前server负载权重，权重越大几率愈高 max_fails和fail_timeout一般会关联使用，如果某台server在fail_timeout时间内出现了max_fails次连接失败，那么Nginx会认为其已经挂掉，从而在 fail_timeout 时间内不再去请求它，fail_timeout默认是 10s，max_fails默认是1，即默认情况只要是发生错误就认为服务器挂了，如果将max_fails设置为0，则表示取消这项检查 down，标志服务器永远不可用，可配合ip_hash使用 resolve，监视与服务器域名相对应的ip地址的变化，并自动地修改上游配置，而不用重启Nginx route，设置服务器路由名称 service slow_start，设置服务器将其weight从零恢复到正常值的时间 drain，使服务器进入drain模式，在此模式下，只有绑定到服务器的请求才会被代理 upstream模块参数 说明 weight 服务器权重 max_fails Nginx尝试连接后端主机失败的次数，这个值是配合proxy_next_upstream、fastcgi_next_upstream和memcached_next_upstream这三个参数来使用的。当Nginx接收后端服务器返回这三个参数定义的状态码时，会将这个请求转发给正常工作的的后端服务器。如404、503、503、max_files=1 fail_timeout max_fails和fail_timeout一般会关联使用，如果某台server在fail_timeout时间内出现了max_fails次连接失败，那么Nginx会认为其已经挂掉，从而在fail_timeout时间内不再去请求它，fail_timeout默认是10s，max_fails默认是1，即默认情况只要是发生错误就认为服务器挂了，如果将max_fails设置为0，则表示取消这项检查 backup 表示当前server是备用服务器，只有其它非backup后端服务器都挂掉了或很忙才会分配请求给它 down 标志服务器永远不可用，可配合ip_hash使用 如果是两台Web服务器做高可用，可能就需要Keepalived配合。那使用backup参数通过负载均衡功能就可以实现Web服务器集群了。 upstream模块调度算法调度算法一般分为： 静态调度算法: 即负载均衡器根据自身设置的规则进行分配，不需要考虑后端节点服务器的情况 轮询 权重 ip_hash 动态调度算法: 即负载均衡器会根据后端节点的当前状态来决定是否分发请求，如连接数少或响应时间短的优先获得请求 fair least_conn url_hash 一致性hash 轮询(rr)默认调度算法。按照客户端请求顺序把请求逐一分配到不同的后端节点服务器，相当于LVS中的rr算法。如果后端服务器宕机，宕机的服务器会被自动从节点服务器池中剔除，以使客户端的用户访问不受影响，新的请求分配给正常的服务器。 权重轮询(wrr)权重越大，被转发的请求也就越多。可以根据服务器的配置和性能指定权重大小，有效解决新旧服务器性能不均带来的请求分配问题。 1234upstream weight &#123; server 191.168.1.11 weight=1; server 192.168.1.22 weight=2;&#125; ip_hash每个请求按客户端IP的hash结果分配，当新的请求到达时，先将其客户端ip通过哈希算法得出一个值，在随后的客户端请求中，客户IP的哈希值只要相同，就会被分配到同一台服务器。 该调度算法可以解决动态网页的session共享问题，但有时会导致请求分配不均，因为国内大多数都是NAT上网模式，多个客户端对应一个外部IP，所以这些客户端都会被分配到同一个节点服务器，从而导致请求分配不均。 ip_hash中，后端服务器在负载均衡调度中的状态不能有 weight和backup，有也不会生效 12345upstream iphash &#123; ip_hash; server 192.168.1.11; server 192.168.1.22:8080;&#125; fair根据后端节点服务器的响应时间来分配请求，响应时间短的优先分配。这是更加智能的调度算法。 Nginx本身不支持这种算法，需要upstream_fair模块: https://github.com/gnosek/nginx-upstream-fair 12345upstream fair &#123; server 192.168.1.11; server 192.168.1.22; fair;&#125; least_conn根据后端节点的连接数来决定分配情况，哪个机器少就分发给它。 url_hash根据访问URL的hash结果来分配请求的，让每个URL定向到同一个后端服务器，后端服务器为缓存服务器时效果显著。 Nginx本身不支持url_hash，需要hash。 1234567upstream urlhash &#123; server hahaha1:5678; server hahaha2:5678; hash $request_uri; hash_method md5; #同样不能使用 weight、backup&#125; 一致性hash一致性hash算法一般用于代理后端业务为缓存服务器（如Memcached）的场景，通过将用户请求的URI或者指定字符串进行计算，然后调度到后端的服务器上，此后任何用户查找同一个URI货值指定字符串都会被调度到这一台服务器上，因此后端的每个节点缓存的内容都是不同的。 12345upstream &#123; consistent_hash $request_uri; server xxx; server xxx;&#125; nginx proxy模块 proxy_pass介绍123Syntax: proxy_pass URL;Default: —Context: location, if in location, limit_except proxy_pass指令属于ngx_http_proxy_module模块，此模块可以将请求转发到另一台服务器，在实际的反向代理工作中，会通过location功能匹配指定的URI，然后把接收到服务匹配URI的请求通过proyx_pass抛给定义好的upstream节点池。 12345678910location /download/ &#123; proxy_pass http://download/vedio/;&#125;#这是前端代理节点的设置#交给后端upstream为download的节点location /name/ &#123; rewrite /name/([^/]+) /users?name=$1 break; proyx_pass http://127.0.0.1;&#125; http_proyx模块参数ngx_http_proxy_module: https://nginx.org/en/docs/http/ngx_http_proxy_module.html Nginx的代理功能是通过http_proxy模块来实现的。 proxy模块 说明 proxy_next_upstream 什么情况下将请求传递到下一个upstream proxy_limite_rate 限制从后端服务器读取响应的速率 proyx_set_header 设置http请求header传给后端服务器节点，如：可实现让代理后端的服务器节点获取访问客户端的这是ip client_body_buffer_size 客户端请求主体缓冲区大小 proxy_connect_timeout 代理与后端节点服务器连接的超时时间 proxy_send_timeout 后端节点数据回传的超时时间 proxy_read_timeout 设置Nginx从代理的后端服务器获取信息的时间，表示连接成功建立后，Nginx等待后端服务器的响应时间 proxy_buffer_size 设置缓冲区大小 proxy_buffers 设置缓冲区的数量和大小 proyx_busy_buffers_size 用于设置系统很忙时可以使用的proxy_buffers大小，推荐为proxy_buffers*2 proxy_temp_file_write_size 指定proxy缓存临时文件的大小 Nginx负载均衡配置 配置后端节点12345678910vi /etc/nginx/nginx.confserver &#123; listen 80; root /path/xxx; location / &#123; xxxx; &#125;&#125; 配置反向代理节点12345upstream test &#123; server test1 weight=5; server test2 weight=5; server 192.168.1.33;&#125; 1234567891011121314151617181920vi /etc/nginx/nginx.confserver &#123; listen 8888; server_name www.test.com www.xx.com; location / &#123; proxy_read_timeout 10s; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_404; proyx_pass http://test;#把用户的请求反向代理定义的upstream服务器池 #proyx_set_header Host $host;在代理后端服务器发送的http请求头中加入host字段信息 #proxy_set_header X-Real-IP $remote_addr;后端节点服务器日志获取客户端真实ip，否则全都是代理节点的ip #proyx_connect_timeout 30s; #proxy_buffers 4m; #xxx&#125; xxxxx&#125; 与反向代理配置相关的参数除了具有多虚拟主机代理以及节点服务器记录真实用户ip的功能外，Nginx还提供了相当多的作为反向代理和后端节点服务器对话的相关控制参数。 由于参数众多，建议把这些参数都写到另外一个配置文件里，然后用 include 方式包含到虚拟主机配置文件里。其他Nginx参数也同样可以使用此方法。 12345678910111213vim /etc/nginx/proxy.confproxy_set_header Host $host;proxy_set_header $remote_addr;proxy_connect_timeout 60s;proxy_read_timeout 20s;proxy_send_timeout 20s;proxy_buffer_size 64k;proxy_buffers 4 64k;proxy_busy_buffers_size 128k;proxy_temp_file_write_size 2m;proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_404 12345678910vim /etc/nginx/conf.d/test.confserver &#123; listen 80; server_name www.test.com www.xxx.com; location / &#123; include /etc/nginx/proxy.conf; &#125;&#125; proxy_next_upstream参数补充当Nginx接收后端服务器发返回的proxy_next_upstream参数定义的状态码时，会将这个请求转发给正常工作的后端服务器，如500、502、503，此参数可以提升用户访问体验。 1proyx_next_upstream error timeout invalid_header http_500 http_503 http_502 http_504; 根据URL中的目录地址实现代理转发通过Nginx实现动静分离，即通过Nginx反向代理配置规则实现让动态资源和静态资源及其他业务分别由不同的服务器解析，已解决网站性能、安全、用户体验等重要问题。 动静态分离配置upstream.conf 123456789101112131415161718upstream static &#123; server 192.168.1.11; #或server static.com----hosts:static.com 192.168.1.11&#125;upstream upload &#123; server 192.168.1.22;&#125;upstream default &#123; server 192.168.1.33;&#125;#在http中加入,注意位置http &#123; include upstream.conf;&#125; 配置virtual.conf 12345678910111213141516171819202122232425262728293031323334353637#方案1：利用location实现location /static/ &#123; proyx_pass http://static; include proyx.conf;&#125;location /upload/ &#123; proxy_pass http://upload; include proxy.conf;&#125;location / &#123; proxy_pass http://default; include proxy.conf;&#125;========================================#方案2：利用if语句实现if ($request_uri ~* "^/static/(.*)$")&#123; proxy_pass http://static/$1;&#125;if ($request_uri ~* "^/upload/(.*)$")&#123; proxy_pass http://upload/$1;&#125;location / &#123; proxy_pass http://default; include proyx.conf;&#125; URL目录地址转发的应用场景根据HTTP的URL进行转发的应用情况，被称为 第7层（应用层）的负载均衡；而LVS的负载均衡一般用于TCP等的转发，因此被称为第四层（传输层）的负载均衡 。 有时因为需求，需要在代理服务器上通过配置规则，使得匹配不同规则的请求会交给不同的服务器池处理。 根据客户端的设备(user_agent)转发为了让不同客户端设备用户有更好的访问体验，需要在后端架设不同服务器来满足不同的客户端访问。如PC端和移动端，移动端又有安卓、苹果、Pad等。 常规4层负载均衡解决方案架构 在常规4层负载均衡架构下，可以使用不同的域名来实现这个需求。 如，分配移动端访问 wap.xxx.com，PC端访问www.xxx.com。 通过不同域名来引导用户到指定后端服务器，但是这样就分别得记住不同的域名。 第7层负载均衡解决方案 在7层负载均衡架构下，对外只需要用一个域名，如www.xxx.com，然后通过获取用户请求中的设备信息$http_user_agent，根据此信息转给后端合适的服务器处理。 根据$user_agent转发 123456789101112location / &#123; if ($http_user_agent ~* "android") &#123; proxy_pass http://android; &#125;if ($http_user_agent ~* "iphone") &#123; proxy_pass http://iphone; &#125;proxy_pass http://default;include proyx.conf; 根据文件扩展名实现代理转发 1234567891011121314location ~* .*\.(gif|jpg|png|css|js)$ &#123; proyx_pass http://static; include proxy.conf;&#125;#ifif ($request_uri ~* ".*\.php$") &#123; proxy_pass http://php; &#125;if ($request_uri ~* ".*\.(jpg|png|css|js)$") &#123; proxy_pass http://static; &#125; 在开发无法通过程序实现动静分离的时候，运维可以根据资源实体进行动静分离，根据不同实现策略制定后端服务器不同的组。在前端代理服务器上通过路径、扩展名等进行规则匹配，从而实现请求的动态分离。 Nginx负载均衡检测节点状态淘宝技术团队开发了一个Tengine（Nginx分支）模块nginx_upstream_check_module: https://github.com/yaoweibin/nginx_upstream_check_module，用于提供主动式后端服务器健康检查。通过它检测后端realserver的健康状态，如果后端节点不可用，则所有的请求就不会转发到该节点上。 Nginx需要通过打补丁的方式将该模块添加进去。 123456789101112131415161718192021222324252627282930wget https://codeload.github.com/yaoweibin/nginx_upstream_check_module/zip/masterunzip mastercd nginx_upstream_check_module-master #解压后的文件夹cd nginx源码安装包（我是 /usr/local/nginx-1.12.1）patch -p1 &lt; ../nginx_upstream_check_module-master/check_1.12.1+.patch #选择对应的Nginx版本号，我的是1.12.1 #打补丁#编译，注意以前的编译参数./configure --prefix=/usr/local/nginx \--user=nginx --group=nginx \--with-http_ssl_module \--with-http_realip_module \--with-http_addition_module \--with-http_gzip_static_module \--with-http_stub_status_module \--with-http_sub_module \--with-pcre \--add-module=../nginx_upstream_check_module-mastermake#给已经安装的Nginx系统打补丁不用执行make install#make是重新生成Nginx二进制启动命令#备份mv /usr/local/nginx/sbin/nginx&#123;,.bak&#125;#经打过补丁的Nginx二进制程序复制到/usr/local/nginx/sbin/ 下cp /usr/local/nginx-1.12.1/objs/nginx /usr/local/nginx/sbin/nginx -t 配置nginx_upstream_check 配置upstream.conf 12345678upstream zhang &#123; server 192.168.1.7:5678 weight=1; server 192.168.0.99:5678 weight=1; check interval=3000 rise=2 fall=5 timeout=1000 type=http; #每个3秒对负载均衡中所有节点检测一次，请求2次正常标记realserver状态为up； #如果检测5次都失败，则标记realserver状态为down，超时时间为1秒； #检查的协议为HTTP；&#125; 配置/status： 123456location /status &#123; check_status; access_log off; allow 192.168.1.0/24; deny all;&#125; stream模块Module ngx_stream_core_module: http://nginx.org/en/docs/stream/ngx_stream_core_module.html nginx从1.9.0开始，新增加了一个stream模块，用来实现四层协议(tcp/udp)的转发、代理和负载均衡。这个模块不是默认构建的，需要使用--with-stream参数。 1yum install -y nginx-mod-stream 这个实现四层反向代理和转发的功能真的是很强大，只需一台反向代理服务器，转发给所有后端机器。 栗子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495vim /etc/nginx/nginx.confstream&#123; include /etc/nginx/stream.d/*.conf&#125;##########################cd /etc/nginx/stream.d#转发Elasticsearchvim elastic.confupstream elastic-cluster &#123; server ip1:9200; server ip2:9200; xxx;&#125;server &#123; listen 9200; proxy_pass elastic-cluster;&#125;#dnsvim dns.confupsetrem dns-cluster &#123; server ip:5353; server dns.example.com:53; xxx&#125;#tcpserver &#123; listen port; proxy_pass dns-cluster;&#125;#udpserver &#123; listen 53 udp; proxy_pass dns-cluster;&#125;#ipv6server &#123; listen [::1]:53; proxy_pass unix:/xxx/xx.socket&#125;#MySQLvim mysql.confupstream mysql-cluster &#123; server ip:3306; server ip2:3306; xxx;&#125;server &#123; listen 3306; proxy_pass mysql-cluster;&#125;#SSH转发upstream ssh &#123; server ip:22;&#125;server &#123; listen port; proxy_pass ssh;&#125; 错误信息Nginx错误日志的详细说明。 错误信息 描述 (13: Permission denied) while reading upstream xxx (98: Address already in use) while connecting to upstream xxx (99: Cannot assign requested address) while connecting to upstream xxx (104: Connection reset by peer) while reading response header from upstream upstream-fastcgi超时时间request_terminate_timeout过小 (104: Connection reset by peer) 1: 服务器的并发连接数超过其承载量，服务器会将其中一些连接Down掉; 2: 客户关掉了浏览器，而服务器还在给客户端发送数据; 3: 浏览器端按了Stop (104: Connection reset by peer) while connecting to upstream upstream发送了RST，将连接重置 send() failed (111: Connection refused) xxx (111: Connection refued) while connecting to upstream 用户在连接时，若遇到后端upstream挂掉或不通，会收到该错误 (111: Connection refused) while reading response header from upstream 用户在连接成功后读取数据时，若遇到后端upstream挂掉或者不通，会收到此错误 (111: Connection refused) while sending request to upstream Nginx和upstream连接成功后发送数据时，若遇到后端upstream挂掉或不通，会收到该错误 (110: Connection timed out) while connecting to upstream Nginx连接upstream时超时 (110: Connection rimed out) while reading upstream Nginx读取来自upstream的响应时超时 (110: Connection timed out) while reading response header from upstream Nginx读取来自upstream的响应头时超时 (110: Connection timed out) while reading upstream Nginx读取来自upstream的响应时超时 upstream prematurely closed connection 请求URI的时候出现异常，是由于upstream还未返回应答给用户时，用户断掉连接造成。对系统没有影响。 upstream sent invalid header while reading response header from upstream upstream发送的响应头无效 upstream sent no valid HTTP/1.0 header while reading response header from upstream upstream发送的响应头无效 client intended to send too large body 用于设置允许接受的客户端请求内容的最大值，Client发送的body超过了设置 reopening logs 用户发送kill -USR1命令 gracefully shutting down 用户发送kill -WINCH命令 no servers are inside upstream upstream下未配置server no live upstreams while connecting to upstream upstream下的server全都挂了 SSL_do_handshake() failed SSL握手失败 SSL_write() failed(SSL) while sending to client xxx ngx_slab_alloc() failed: no memory in SSL session shared cache ssl_session_cache大小不够 could not add new SSL session to the session cache while SSL hanshaking ssl_session_cache大小不够]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[I Like For You To Be Still]]></title>
    <url>%2F2017%2F09%2F01%2FI-Like-For-You-To-Be-Still%2F</url>
    <content type="text"><![CDATA[《I Like For You To Be Still》 出自聂努达诗集：《二十首情诗和一首绝望的歌》。 I like for you to be stillIt is as though you are absentAnd you hear me from far awayAnd my voice does not touch youIt seems as though your eyes had flown awayAnd it seems that a kiss had sealed your mouthAs all things are filled with my soulYou emerge from the thingsFilled with my soulYou are like my soulA butterfly of dreamAnd you are like the word: Melancholy I like for you to be stillAnd you seem far awayIt sounds as though you are lamentingA butterfly cooing like a doveAnd you hear me from far awayAnd my voice does not reach youLet me come to be still in your silenceAnd let me talk to you with your silenceThat is bright as a lampSimple, as a ringYou are like the nightWith its stillness and constellationsYour silence is that of a starAs remote and candid I like for you to be stillIt is as though you are absentDistant and full of sorrowSo you would’ve diedOne word then, One smile is enoughAnd I’m happy;Happy that it’s not true]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>Pablo Neruda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Test-My-Site]]></title>
    <url>%2F2017%2F08%2F30%2FTest-My-Site%2F</url>
    <content type="text"><![CDATA[Monday Tuesday Wednesday Thursday Friday Saturday Sunday $$\sideset{^1_2}{^3_4}A$$ $E=mc^2$ $$\sum_{i=1}^n a_i=0$$ $$f(x_1,x_x,\ldots,x_n) = x_1^2 + x_2^2 + \cdots + x_n^2 $$ $$\sum^{j-1}{k=0}{\widehat{\gamma}{kj} z_k}$$]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>Test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F08%2F30%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
