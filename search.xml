<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[一战二战武器]]></title>
    <url>%2F2018%2F11%2F18%2F%E4%B8%80%E6%88%98%E4%BA%8C%E6%88%98%E6%AD%A6%E5%99%A8%2F</url>
    <content type="text"><![CDATA[参考： 各国一战武器，维基百科 第一次世界大战武器装备，维基百科 各国二战武器，维基百科 第二次世界大战武器装备，维基百科 最近玩battlefield I(一战)有感，一时兴起，顺带在battlefield V(二战)发布前夕做一个一战二战各国使用的武器装备归纳总结。 玩了战地1，才体会到战争的残酷性，使我对战争的感觉从光辉转变为厌恶。没有什么英雄在我心中，你不知道自己何时会死去，或即将死去。战场上每个人都一样，都是一条鲜活的生命，有家人有朋友。从战争游戏来反思战争，这点DICE studio做的不错。 衷心祝愿世界和平！ 一战第一次世界大战（简称一次大战、一战，或称欧战；英语：World War I、WWI、Great War、First World War；法语：la première Guerre Mondiale、la Grande Guerre）是一场于1914年7月28日至1918年11月11日主要发生在欧洲的大战，然而战火最终延烧至全球，当时世界上大多数国家都被卷入这场战争，史称“第一次世界大战”。 主要介绍国家： 德国 法国 俄国 英国 美国 主要武器分类： 枪械 大炮 坦克 飞机 船舰 德国第一次世界大战德国主要武器 手榴弹hand grenade 柄式手榴弹 柄式手榴弹（德语：Stielhandgranate）为德国陆军自第一次世界大战中期至第二次世界大战末期所使用之手榴弹。 12345重量 595克长度 365毫米直径 70毫米填充 三硝基甲苯（TNT）引爆机制 5秒 手枪pistol 毛瑟C96(Mauser C96) 由毛瑟在1896年推出的手枪，在中国还有驳壳枪、快慢机、自来得、大镜面等别称。毛瑟（德语：Mauser）是一个德国的枪械制造商。 1234567891011121314151617重量 1.130公斤（空枪）长度 288毫米枪管长度 140毫米子弹 7.63×25mm毛瑟弹 9×19mm鲁格弹 .45 ACP 9×25mm毛瑟弹枪机 枪管短行程后座作用 单动发射模式 C96：半自动 M712速射型：半自动、全自动枪口初速 425米/秒有效射程 100米最大射程 200米供弹方式 C96：10发内置弹仓M712速射型：10发或20发弹匣瞄具 V型照门上刻度最大可调至1000米 鲁格手枪（Pistole 08 Luger) 简称P08该枪由奥地利人格奥尔格·鲁格于1898年设计，并由以德国武器及弹药兵工厂及毛瑟为首等多间工厂于1900年投入生产。 1234567891011重量 1.92磅（871克）长度 8.75英寸（222毫米）枪管长度 98毫米–203毫米 （3.9 -8.02英寸）子弹 7.65×21毫米帕拉贝伦弹 9毫米鲁格弹 .45 ACP（相当罕见）枪机 枪管短行程后座作用，肘节式起落闭锁（Toggle Lock）枪口初速 350 - 400米/秒有效射程 50米供弹方式 8发弹匣、32发弹鼓 帝国转轮手枪（Reichsrevolver） 该枪后来被著名的鲁格P08半自动手枪所取代。 12345678重量 1040克长度 310毫米子弹 10.6×25mmR口径 10.6mm射速 单动式枪口初速 205米/秒供弹方式 6发弹巢瞄具 V型缺口及准星 贝格曼1896型手枪 12345678910重量 1.13 kg长度 254 mm枪管长度 102 mm子弹 5毫米贝格曼弹6.5毫米贝格曼弹8×22毫米贝格曼弹枪机 反冲作用枪口初速 380米/秒供弹方式 5发载入内置弹仓内瞄具 固定式瞄具 费罗梅尔停止手枪()Frommer Stop 12345678重量 610 g（22 oz）长度 165 mm（6.5英寸）枪管长度 95毫米（3.7英寸）子弹 .32 ACP.380 ACP枪机 长行程后座作用枪口初速 280 m/s（919 ft/s）供弹方式 7发弹匣 冲锋枪Submachine Guns MP18 MP18冲锋枪是第一次世界大战时期由德国的胡戈·施梅瑟所开发的冲锋枪。MP18冲锋枪因其生产厂Bergmann也被称为伯格曼冲锋枪。 1234567891011重量 4.18公斤长度 832毫米枪管长度 200 毫米子弹 9毫米鲁格弹7.63×25毫米毛瑟弹枪机 反冲作用、开放式枪机发射模式 MP18：全自动MP28：半自动、全自动射速 500发/分枪口初速 380米/秒供弹方式 32发弹匣 TM 08 （一战）；20，30 和 50 发弹匣（二战前） 机枪machine gun MG08重机枪 Maschinengewehr 08（也称MG08，Maschinengewehr意为机枪）由海勒姆·马克沁1884年开发的马克沁机枪发展而来。 1234567891011121314重量 连冷却水一共 69 kg ，除去冷却水65 kg 枪身26.5 kg 4 kg水 三脚架38.5 kg MG08/15：连同两脚架17.8kg 水 3KG MG08/18：不含两脚架14.5KG长度 1175 mm MG08/15、MG08/18：1445 mm枪管长度 720mm操作人数 4人班组子弹 7.92×57毫米毛瑟枪机 枪管短后座，肘节式起落闭锁射速 450-500 发/分枪口初速 900米每秒（3,000英尺每秒）有效射程 2,000米（2,200码）最大射程 3,500米（3,800码）供弹方式 250 发弹链 麦德森轻机枪(Madsen machine gun) 这也是全世界上第一种大量生产的真正实用化的轻机枪。 123456789101112131415161718重量 空枪：9.07 千克（20 磅）长度 1,143 毫米（45 英寸）枪管长度 584.2 毫米（23 英寸）子弹6.5×55毫米瑞典子弹7×57毫米毛瑟子弹7.65×53毫米阿根廷子弹7.62×51毫米NATO7.62×54毫米R.303英式子弹[1]7.92×57毫米毛瑟子弹枪管 1 根，膛线4 条，右旋，枪管装上风冷式枪管套和消焰器枪机 枪管长行程后座作用发射模式 全自动射速 450发／分钟枪口初速 6.5×55毫米瑞典子弹：700—870米／秒（2,296.59—2,854.33英尺／秒）供弹方式 25、30、40发可拆卸式弹匣瞄具 机械瞄具：Ｖ型缺口式照门及柱状准星 步枪rifle Gewehr 98步枪 Gewehr 98步枪（又称：G98、Gew 98、毛瑟M1898或M98）是德国毛瑟枪厂在德国军方采用Gewehr 88步枪后，为了夺回在德国枪械市场的地位而研制的步枪。Gew 98在1898年到1935年间为德国军队的制式步枪，直到它在1935年被毛瑟Kar98k步枪取代为止。 12345678910111213重量 4.09千克（9.0磅） Gewehr 98（空枪） 3.50千克（7.7磅） Karabiner 98a长度 1,250 mm（49.2英寸） Gewehr 98 1,090 mm（42.9英寸） Karabiner 98a枪管长度 740 mm（29.1英寸） Gewehr 98 590 mm（23.2英寸） Karabiner 98a子弹 7.92×57mm毛瑟枪机 旋转后拉式枪机枪口初速 878 m/s（2,881 ft/s）有效射程 500米（550 yd） （机械瞄具） ≥800米（870 yd）（瞄准镜）供弹方式 5发内置弹仓（能够以弹夹条压入）瞄具 机械瞄具 蒙德拉贡步枪 蒙德拉贡步枪（西班牙语：Fusil Mondragón）是一种由墨西哥上将曼努埃尔·蒙德拉贡(Manuel Mondragón)设计，瑞士工业公司（SIG）生产的半自动步枪。 123456789101112重量 4.18 公斤长度 1105 毫米枪管长度 577 毫米子弹 7 × 57 毫米毛瑟弹/7.92 × 57 毫米毛瑟弹枪机 气动式 转拴式枪机枪口初速 760 米/秒有效射程 800 米最大射程 2,000 米供弹方式 8、10、20、30 发可拆式弹匣 100 发弹鼓瞄具 机械瞄具 毛瑟13.2毫米反坦克步枪 毛瑟13.2毫米反坦克步枪为德意志帝国陆军于第一次世界大战中针对协约国（主要是英国）的装甲车辆所研发生产的反装甲武器，初次登场时间是1918年2月。 12345678重量 15.8公斤长度 1.68米枪管长度 0.98米子弹 13.2mm TuF枪机 旋转后拉式枪机枪口初速 805米/秒供弹方式 单发装填瞄具 传统铁制照门 装甲车 埃尔哈特E-V/4装甲车 埃尔哈特E-V/4装甲车是德国二战前研发用于轻度战斗和警务的装甲车。 12345678910111213重量 7.12 - 7.75 吨长度 5.3 m宽度 2 m高度 2.85 m操作人数 8 - 9人装甲 约9 mm主武器 三挺机枪发动机 汽油80 hp (59 kw)功率/重量 10.3 hp/tonne悬挂 四轮驱动作战范围 250 km速度 61.3 km/h 坦克Tank A7V坦克 A7V（Sturmpanzerwagen A7V）是德意志帝国在第一次世界大战时开发的坦克。 1234567891011121314重量 30 至33 吨长度 7.34 米（24 尺 1 寸）宽度 3.1 米（10 尺）高度 3.3 米（10 尺 10 寸）操作人数 18人装甲 侧面20 毫米，正面50 毫米主武器 57 毫米主炮副武器 6挺7.92毫米机枪发动机 2具戴姆勒4汽缸汽油引擎100匹／800-900转（149 千瓦）x2功率/重量 6.5 匹／吨悬挂 履带、立式弹簧作战范围 30-80 公里（20-50 英里）速度 9 公里／小时 LK I Leichter Kampfwagen (中文：轻型战斗车辆) 或“LK I”是第一次世界大战期间德国制造的原型轻型坦克。 123456789101112重量 6.9 吨长度 5.1 米宽度 1.9 米高度 2.5 米操作人数 3 人装甲 8-14 毫米主武器 7.92 毫米 机枪发动机 戴姆勒-奔驰4缸发动机60 匹/44.7 千瓦悬挂 非悬挂作战范围 70 千米速度 14-18 千米/小时 飞机aircraft AEG B.I侦察机 AEG B.I侦察机是德国的双座双翼侦察机，于1914年小批量生产。它为AEG公司更成功的后继机型——B型和C型的设计提供了基础。 J.I攻击机 J.I攻击机（制造厂商将其定为“J 4”，以防止与1915年开发的“J 1”机混淆）是德意志帝国陆军航空队于第一次世界大战所使用的一款地面攻击机、侦察机和连络机，由容克斯所研制，属德国“J系列”装甲航空机之一。 信天翁C侦察机 信天翁C侦察机是由信天翁飞机公司研制的双翼侦察机，在第一次世界大战期间不单作为侦察机，还以其机载机枪件为战斗机和对地攻击机，信天翁飞机公司以此为基础推出信天翁D战斗机。 信天翁D战斗机 信天翁D战斗机是由信天翁飞机公司以信天翁C侦察机的基础和参考了法国纽波特11战斗机而研制的双翼战斗机，在第一次世界大战期间是继福克E单翼战斗机后德国空军的主力战斗机。 戈塔G轰炸机 戈塔G轰炸机是德国在第一次世界大战时的重型轰炸机，在大战期间主要用于轰炸英国，把死亡和恐惧带给英国民众。 巨人机 巨人机（德语：Riesenflugzeug，複數時寫作：Riesenflugzeuge），英语有时简称为R型飞机，是指一次世界大战中德意志帝国所使用的重型轰炸机。 柏法茨战斗机 柏法茨双翼战斗机是在第一次世界大战时由德国柏法茨飞机公司(德文:Pfalz Flugzeugwerke)研制的双翼战斗机。 汉诺威CL攻击机 汉诺威CL攻击机是在第一次世界大战时由德国汉诺威飞机公司(德文:Hannoversche Waggonfabrik)研制的双翼攻击机，CL原本是指比一般侦察机（代号为C）轻巧的双座机，原本是用作为侦察机提供直接的护航，但后来发展成为对地攻击机尤其以其后座机枪作为居高临下的机枪火力点。 福克战斗机 是福克飞机公司为了参加德国空军的“新型战斗机比赛”而提出的战斗机设计。 罗兰C-II侦察机 罗兰C-II侦察机是由LFG公司（Luft-Fahrzeug-Gesellschaft）研制的双翼侦察机，它被誉为第一次世界大战当中最漂亮的德国侦察机，它也因此被称为“鲸鱼”。 齐柏林-斯塔肯R-VI轰炸机 齐柏林-斯塔肯R-VI轰炸机是德国在第一次世界大战时的重型轰炸机，在大战期间主要和戈塔G轰炸机一起轰炸英国，把死亡和恐惧带给英国民众。 鸽式单翼机 鸽式单翼机是由奥地利(当时的“奥匈帝国)飞机工程师埃高．艾垂奇发明的，在第一次世界大战期间除了奥匈帝国，其同盟国盟友德意志帝国也大量采用作为侦察机、轰炸机和教练机等多种用途，虽然在1914年此机已算落伍，但毫无疑问的此后德国所有震惊世界的优秀军用飞机都是从鸽式单翼机开始的。 巡洋舰一次世界大战德国巡洋舰： https://zh.wikipedia.org/wiki/Category:%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%B8%96%E7%95%8C%E5%A4%A7%E6%88%B0%E5%BE%B7%E5%9C%8B%E5%B7%A1%E6%B4%8B%E8%89%A6 巡洋舰（英语：Cruiser）指在排水量、火力、装甲防护等方面仅次于战列舰的大型水面舰艇，拥有同时对付多个作战目标的能力，以及能胜任多种任务的多样性。历史上，巡洋舰由于吨位大、火力强、性能佳，一开始是指可以独立行动的战舰 ; 而与此相对的驱逐舰则需要其它船只（比如补给船只）的协助，才能执行任务。不过随着现今驱逐舰被大型化后的综合作战能力的提升，何潬吨位其实超过早年的巡洋舰，所以这个区分已经不明显了，很多新式的大型军舰都不再冠以巡洋舰之名了。 巡洋舰的用途顾名思义确实是用来巡逻的。 战列舰一次大战德国战列舰: https://zh.wikipedia.org/wiki/Category:%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%B8%96%E7%95%8C%E5%A4%A7%E6%88%98%E5%BE%B7%E5%9B%BD%E6%88%98%E5%88%97%E8%88%B0 战列舰（英语：Battleship），是装有厚重装甲和大口径主炮的大型军舰，是人类创造的最庞大和复杂的武器系统之一，大舰巨炮主义时代的极致产物。 法国手枪 FN M1900手枪(勃朗宁) FN M1900是一款由著名枪械设计师约翰·勃朗宁于1896年设计，交由比利时Fabrique Nationale生产的单动式半自动手枪。该枪亦是史上第一款使用套筒设计的手枪。 1234567重量 625克（空枪）长度 172亳米枪管长度 102亳米子弹 .32 ACP（7.65×17亳米）枪机 反冲作用，单动供弹方式 7 + 1发弹匣瞄具 固定式瞄具 M1892转轮手枪 M1892转轮手枪（或称：勒贝尔转轮手枪或圣埃蒂安8毫米）是法国采用的一种制式手枪。 12345678重量 0.85公斤（空枪）长度 24厘米子弹 8毫米法国军械弹口径 8毫米枪机 双动式枪口初速 220米/秒供弹方式 6发弹巢瞄具 机械瞄具 M1911手枪 M1911（45手枪）是一种在1911年起生产的.45 ACP口径半自动手枪，由约翰·勃朗宁设计。 123456789101112重量 空枪连弹匣：2.437磅（1,105克）[1]长度 8.25吋（210毫米）枪管长度政府型：5.03吋（127毫米）指挥官型：4.25吋（108毫米）军官ACP型：3.5吋（89毫米）子弹 .45 ACP枪机 枪管短行程后座作用、单动式板机枪口初速 251.46米/秒、〔825英尺/秒〕有效射程 50米供弹方式 7发（标准弹匣），膛室1发瞄具 机械瞄具：金属缺口式照门及准星 MAS 1873转轮手枪 MAS 1873（或称：Chamelot-Delvigne）是法国军队采用的第一种双动式转轮手枪，此枪不久便被更新的M1892转轮手枪所取代。 12345678910重量 1.04 kg长度 240 mm枪管长度 115 mm子弹 11毫米M1873口径 11 mm枪机 双动式射速 20 - 30发/分钟最大射程 50米供弹方式 6发弹巢瞄具 V型缺口及准星 冲锋枪 机枪 圣艾蒂安M1907中型机枪 圣艾蒂安M1907（法语：St. Étienne Mle 1907）是法国军队于第一次世界大战及第二次世界大战期间所装备的一种中型机枪。 1234567891011重量 26公斤长度 1,180毫米枪管长度 710毫米子弹 8×50毫米勒贝尔弹枪管 1根枪机 气动式射速 可调整：8 - 650发/分钟枪口初速 724米/秒供弹方式 25、30发金属弹链300发布制弹链（1916年）瞄具 机械瞄具 绍沙轻机枪 绍沙轻机枪，是在一战（1914年–1918年）时法国军队装备的制式轻机枪。官方名”Fusil Mitrailleur Modele 1915 CSRG”（机关步枪1915年型CSRG）。 12345678910111213重量 9.07千克（20.0英磅）长度 1,143毫米（45.0英寸）枪管长度 470毫米（19英寸）子弹 8×50毫米勒贝尔弹其他枪机 长行程后座作用、气动式、开放式枪机发射模式 半自动、全自动射速 约240发/分钟枪口初速 630米/秒有效射程 200米最大射程 2,000米供弹方式 20发弹匣瞄具 机械瞄具 刘易斯机枪 刘易斯机枪（Lewis Gun）由美国陆军上校艾萨克·牛顿·刘易斯发明，但美国陆军并未采用，而是在英国发扬光大。 12345678910111213重量 12公斤（空枪）长度 1,125 mm枪管长度 660 mm子弹 .303英式弹口径 7.7 mm枪机 气动式、开放式枪机发射模式 半自动、全自动射速 500 - 600发/分钟枪口初速 747米/秒有效射程 800 m最大射程 3,200 m供弹方式 47发、97发弹鼓瞄具 刀片式瞄具 霍奇克斯M1914重机枪 霍奇克斯M1914重机枪（法语：Hotchkiss Mle 1914）由美国人班杰明·霍奇克斯所开设的霍奇克斯公司研发。 123456789101112131415重量 24.4公斤46.8公斤（连三脚架）长度 1,390毫米枪管长度 800毫米子弹 8×50毫米勒贝尔子弹7×57毫米毛瑟子弹6.5×50毫米有坂子弹11毫米Gras子弹6.5×55毫米枪机 导气式射速 450发/分钟枪口初速 724米/秒供弹方式 24发保弹板250发铰接式弹链瞄具 机械瞄具 步枪 M1917RSC半自动步枪 M1917式RSC半自动步枪（法语：Fusil Automatique Modèle 1917，别名RSC M1917）是一种半自动气动式军用步枪，于第一次世界大战末期（1918年）装备法国军队。 123456789重量 5,25公斤（11,6磅）长度 1331毫米（52,4英寸）枪管长度 798毫米（31,4英寸）子弹 8×50mm勒贝尔弹枪机 长行程导气式活塞，滚转式枪机枪口初速 701米/秒有效射程 标尺最低射程250米，最大有效1200米供弹方式 5发内装漏夹供弹瞄具 铁质标尺，标尺直立射程2400米 Mle 1918 全自动卡宾枪 Mle 1918 利贝罗勒全自动卡宾枪（英语：Ribeyrolles 1918 automatic carbine ，法语：Carabine Mitrailleuse 1918）是法国的一款自动步枪，亦是世界首型应用突击步枪概念的枪械。 1234567891011重量 5.1公斤（空枪）长度 1090毫米枪管长度 450毫米子弹 8 × 35 毫米利贝罗勒弹口径 8 毫米枪机 直接反冲射速 550~600发/分钟枪口初速 570 米/秒有效射程 400 米供弹方式 25 发弹匣瞄具 机械瞄具 勒贝尔M1886步枪 勒贝尔M1886（法语：Fusil Lebel Modèle 1886）或勒贝尔步枪（法语：Fusil Lebel）是法国于1886年推出的栓式步枪，由尼古拉斯·勒贝尔上校研制。 123456789101112重量 4.41 kg（上弹）4.18 kg（空枪）长度 130 cm枪管长度 80 cm子弹 8×50毫米勒贝尔弹口径 8 mm枪机 旋转后拉式枪机枪口初速 610 - 700米/秒有效射程 400米最大射程 1,800米供弹方式 8发管状弹仓（若算上托弹板上和膛室内的额外两发子弹为10发）瞄具 机械瞄具 温彻斯特1907型半自动步枪 温彻斯特1907型是由美国枪械设计师托马斯·克罗斯利.约翰逊设计的一种半自动步枪，它在1906年到1958年期间由温彻斯特连发武器公司生产。 12345678重量 3.6 kg - 4.1 kg长度 1,000 mm枪管长度 510 mm子弹 .351 Winchester Self-Loading口径 .351枪机 后座作用供弹方式 5 发、10 发弹匣瞄具 机械瞄具 双管霰弹枪 双管霰弹枪（英语：Double-barreled shotgun，或称双管猎枪），是一种有两根枪管的猎枪，可分为水平排列或上下排列，可算是最早期的猎枪之一，前身为镇暴枪。 炮 皮托SA-18坦克炮 皮托SA-18坦克炮是法国在一战期间由设计的一种战车炮，主要装备于雷诺FT-17坦克上。 坦克 2C超级重战车 2C超重型坦克，又名Char 2C，是法国于一战时设计的超重型坦克。但是，它并没有参加一战。不过，这辆坦克是所有被正式量产的坦克中吨位第二大的，仅次于猎虎式驱逐战车。 123456789101112重量 69 t（68 long ton；76 short ton）长度 10.27米（33英尺8英寸）宽度 3米（9英尺10英寸）高度 4.09米（13英尺5英寸）操作人数 11人[注 1]装甲 45 mm（1.8英寸） max.主武器 75 mm 火炮副武器 4挺8 mm 机枪 (有一门在后炮塔上)发动机 双引擎 2 x 250 马力作战范围 150 km（93 mi）速度 15 km/h（9.3 mph） 施耐德CA1坦克 施耐德CA1坦克（法语：Char Schneider CA1）是法国研制的第一种坦克，研发的主要目的是破坏战场上的铁丝网。 123456789101112重量 13.6 吨长度 6.32 米宽度 2.05 米高度 2.30 米操作人数 6人装甲 5.5-11毫米钢板主武器 施耐德75mm迫击炮副武器 2门8mm霍奇基斯M1914机枪发动机 施耐德4缸55hp汽油引擎悬挂 弹簧作战范围 45 公里速度 8.1 公里／小时 雷诺FT-17坦克 雷诺FT-17，是一款法国轻型坦克。它于一战时由法国研发，是世界上第一款安装旋转炮塔的坦克。截至一战结束时，一共生产了3187辆。甚至在二战爆发时，还有1800辆FT-17坦克在法国军队中服役。 123456789101112131415重量 7吨长度 5米宽度 1.74米高度 2.14米操作人数 2（车长及驾驶员）装甲 6-22毫米主武器 皮托SA-18 37mmL/21战车炮或8mm哈奇开斯M1914机枪发动机 雷诺直立式4缸水冷汽油机35匹功率/重量 6马力/吨变速 机械式（4前进档，1倒车档）悬挂 垂直弹簧作战范围 35公里速度 7.7公里/时 飞机 纽波特战斗机 纽波特11战斗机是法国在第一次世界大战早期推出的双翼战斗机，因其机体细小而被称为“婴儿”，它是由纽波特飞机公司研制的，成立于1902年的纽波特飞机公司由1909年开始造飞机，该公司由纽波特兄弟创立但两兄弟后来都在飞行事故当中死去，公司由他人接手，而在推出纽波特11战斗机后该公司才在航空界打响名堂并开创了“纽波特皇朝”。 莫兰-索尼耶L单翼机** 莫兰-索尼耶L单翼机是法国莫兰-索尼耶飞机公司在1913年研制的单翼多用途飞机，该型机在当年12月的就在巴黎的航空展览上公开，在第一次世界大战爆发后就成为法国空军的侦察机，也是第一种在螺旋桨上加上钢铁制子弹偏导片而实现机枪安装在机头并开火，估计这样有大约1/4的子弹会被它挡住不伤到螺旋桨，其余3/4可穿过螺旋桨射击目标，此种做法是在同步射击系统出现前唯一的可行办法。莫兰-索尼耶L单翼机也因此被称为“历史上第一种战斗机”。 俄国 M1911手枪 毛瑟C96手枪 纳甘M1895转轮手枪 纳甘M1895（俄语：Револьвер системы Нагана，意为：纳甘系统转轮手枪）是由比利时工业家莱昂·纳甘为俄罗斯帝国所研发的7发双动式转轮手枪，发射7.62×38mmR弹药。 1234567891011重量 0.8 kg（空枪）长度 235 mm枪管长度 114 mm子弹 7.62×38mmR口径 7.62 mm枪机 单动式、双动式射速 14 - 21发/分钟枪口初速 272米/秒有效射程 22米供弹方式 7发转轮式弹巢瞄具 V型照门及准星 三八式步枪 三八式步枪（日语：三八式歩兵銃；さんぱちしきほへいじゅう，Sanpachi-shiki hohei-juu）为手动步枪，日本陆军于日俄战争同年（1905年，明治38年）正式采用为制式武器，一直到第二次世界大战。三八式步枪在中国一向俗称为三八大盖，由于其枪机上有一个随枪机连动的防尘盖以及机匣上刻有“三八式”字样而得名。 12345678910重量 3,730g（加上刺刀重4,100g）长度 127.6cm（上刺刀可达166.3cm）枪管长度 797毫米子弹 6.5×50mm有阪（Arisaka）口径 6.5毫米枪机 旋转后拉式枪机枪口初速 765米／秒有效射程 460米供弹方式 5发弹匣，内置弹仓瞄具 铁制直立式表尺 温彻斯特步枪 温彻斯特步枪（Winchester Rifle），有时亦称温彻斯特连发步枪（Winchester Repeating Rifle），是由美国温彻斯特连发武器公司研制及生产的一系列步枪。 123456789101112重量 4.3 kg长度 125.2 cm枪管长度 76.2 cm子弹 .44-40温彻斯特.38-40温彻斯特.32-20温彻斯特.30-30温彻斯特.22 LR其他枪机 杠杆式供弹方式 8（M1894）、10（M1866）、13（M1866）、15发内置管状弹仓瞄具 后方缺口及前准星 莫辛-纳甘步枪 莫辛-纳甘（法文：Mosin-Nagant）步枪是由设计者俄国陆军上校谢尔盖·伊凡诺维奇·莫辛和比利时枪械设计师李昂·纳甘共同命名的手动步枪，在俄语圈国家也被普遍的称为莫辛步枪 （俄文：Винтовка Мосина），官方名称为”三线M1891步枪”。 1234567891011121314重量 4.22公斤（空枪），各型号不同长度 1306毫米，各型号不同枪管长度 800毫米，各型号不同子弹 7.62×54毫米R枪弹口径 7.62毫米枪机 旋转后拉式枪机枪口初速 615米/秒（M1891）860米/秒（M1891/30）有效射程 548.64米（600码）最大射程 1828.8米（2000码）供弹方式 5发内置弹仓10发可拆式弹匣（现代化改版限定）瞄具 机械瞄具：后方可调式缺口表尺及前方柱状准星PU 3.5倍光学瞄准镜 费德洛夫M1916自动步枪 费德洛夫M1916 （俄语：Автомат Фёдорова）是一种战斗步枪，由弗拉基米尔·格里高利耶维奇·费德洛夫（Vladimir Grigoryevich Fyodorov）设计，1916年在沙俄境内生产。 1234567891011重量 4.4公斤 (全重：5.2公斤)长度 1,045毫米枪管长度 520 毫米子弹 6.5×50毫米有坂子弹口径 6.5毫米枪机 枪管短行程后座作用发射模式 半自动、全自动射速 600发/分钟[1]枪口初速 654米每秒（2,150英尺每秒）[1]供弹方式 25发可拆卸式弹匣瞄具 机械瞄具 绍沙轻机枪 麦德森轻机枪 刘易斯机枪 维克斯机枪 维克斯机枪（Vickers），是第一次世界大战与第二次世界大战期间英国军队所使用的中型机枪。基于维克斯机枪优异的设计，使它成为世界上著名的战争武器之一。 12345678910111213重量 15 kg长度 1,100 mm枪管长度 720 mm操作人数 3人子弹 .303英式弹口径 7.7毫米枪机 后坐式，水冷却射速 450 - 500发/分钟枪口初速 744米/秒有效射程 2,000米最大射程 4,100米供弹方式 250发布制弹链瞄具 机械瞄具 马克沁M1910重机枪 马克沁M1910重机枪（Пулемёт Максима на станке Соколова）又名PM M1910马克沁，是海勒姆·马克沁开发的马克沁机枪之衍生型，发射7.62×54毫米R弹药，配有轮式射架。 123456789重量 64.3公斤（139.6磅）长度 1067毫米枪管长度 721毫米子弹 7.62×54毫米R口径 7.62毫米枪机 后座作用射速 600发/分枪口初速 740米/秒（2,427.2尺/秒）供弹方式 250发布制弹链 英国 M1911手槍 毛瑟C96手槍 M1917左轮手枪 M1917左轮手枪（M1917 Revolver），官方正式名称为M1917 .45英寸美国左轮手枪（英语：United States Revolver, Caliber .45, M1917）是一把美国六发式左轮手枪，主要发射.45 ACP口径手枪子弹。 史密斯威森军警型左轮手枪 史密斯威森军警型（Smith &amp; Wesson Military &amp; Police，缩写：S&amp;W MP；简称：点三八），是一种.38口径的美国制左轮手枪。 韦伯利转轮手枪 韦伯利转轮手枪（英语：Webley Revolver）是由英国生产的一系列军用和警用转轮手枪。当中最著名的版本为韦伯利MK VI， 它在一次大战期间成为了英国军队以及其殖民地军队的制式手枪。 123456789101112重量 1.1公斤（空枪）长度 286毫米枪管长度 106毫米子弹 .455韦伯利.38/200口径 .455英寸（11.6×19毫米）、.38英寸枪机 单/双动式板机射速 20-30发/分钟枪口初速 190米/秒有效射程 50码供弹方式 6发弹巢瞄具 缺口式机械瞄具 三八步枪 温彻斯特步枪 恩菲尔德M1917步枪 恩菲尔德M1917步枪（M1917 Enfield，又名P17、P1917或Pattern 1917）是“美国恩菲尔德”（American Enfield）于1917至1918年间生产的.30-06口径手动步枪。 1234567重量 4.17 公斤（9磅3安士）长度 1175 毫米（3尺10.25寸）枪管长度 26 寸（660毫米）子弹 .30-06（7.62 x 63毫米）枪机 旋转后拉式枪机枪口初速 823 米/秒（2700尺/秒）供弹方式 5发弹夹、6发内置弹仓 李-恩菲尔德步枪 李-恩菲尔德步枪（Lee-Enfield）也译李恩飞步枪是1895年至1956年英军的制式手动步枪。 1234567891011121314重量 4.19公斤（MLE Mk.I）3.96公斤（SMLE No.1 Mk.III）长度 1257毫米（MLE Mk.I） 1138毫米（SMLE No.1 Mk.III） 1130毫米（No.4 Mk.I）枪管长度 767毫米（MLE Mk.I） 640毫米（SMLE No.1 Mk.III）子弹 .303 British（7.7×56mm R） 7.92×57毫米尖头弹(为适应中国战场所改膛的)枪机 旋转后拉式枪机枪口初速 744米／秒有效射程 914米（1000码）最大射程 1828米（2000码）供弹方式 10发内置弹仓（两个5发弹夹） 马提尼-亨利步枪 马提尼-亨利”（Martini-Henry）是一种英国陆军曾经装备的起落式枪机步枪。它于1871年首度投入服役，最终取代了原有的史奈德步枪，一款改良至发射定装弹的前装枪。马提尼-亨利的衍生型在大英帝国中一共服役了三十年。它采用了由亨利·O·皮博迪为其皮博迪步枪设计的起落式枪机，并由瑞士设计师里德里希·冯·马提尼进行改良，结合由苏格兰人亚历山大·亨利设计的多边形膛线。 123456789101112131415重量 3.827 kg（空枪）长度 1245 mm子弹 .577/450 Boxer-Henry .577/450马提尼-亨利 .303英式弹 11.43×55R（奥斯曼帝国） 11.43×59R（罗马尼亚） 7.65×53毫米（奥斯曼帝国）枪机 起落式枪机（Martini Falling Block）射速 12发/分钟枪口初速 400米/秒有效射程 370米最大射程 1,700米供弹方式 1发装在膛室内瞄具 可滑动式表尺及准星 维克斯机枪 刘易斯机枪 马克沁机枪 双管霰弹枪 勃朗宁M1917重机枪 M1917重机枪是由约翰·勃朗宁设计，美军在一战，二战及韩战中采用的重机枪，并有限延伸至越战，同时它也被其他国家使用。这是一种班组操作，弹链供弹的水冷重机枪，与同时期的M1919风冷中型机枪共同服役。该型机枪以营为单位配发同时也经常装备于各种载具之上。 123456789101112重量 47公斤长度 980毫米枪管长度 609毫米子弹 .30-06春田口径 7.62毫米枪机 短行程后座作用式射速 450发/分钟 600发/分钟（M1917A1）枪口初速 853.6米/秒最大射程 900米供弹方式 250发布制弹链瞄具 机械瞄具 Template:V及W級驱逐舰 步行者号驱逐舰 步行者号驱逐舰（舷号D27）是一艘英国皇家海军建造的驱逐舰，为W级驱逐舰的3号舰。她是英军第一艘以步行者（Walker）为名的军舰。 12345678标准排水量 设计：1,100吨全长 整体：300呎全宽 水线：26.75呎吃水 9呎最高速度 34节武器装备 4门4吋Mk V速射炮 2门单装2磅砰砰炮 2座3联装鱼雷发射管 范诺克号驱逐舰 范诺克号驱逐舰（舷号H33）是一艘英国皇家海军建造的驱逐舰，为V级驱逐舰的1号舰。她是英军第一艘以范诺克（Vanoc）为名的军舰，舰名取自圆桌骑士团的范诺克骑士。 12345678标准排水量 设计：1,272吨至1,339吨全长 整体：300呎全宽 水线：26呎9吋吃水 9呎最高速度 34节武器装备 4门4吋Mk V速射炮 2门单装2磅砰砰炮 2座双联装鱼雷发射管 Mark I 坦克 Mark I 坦克由英国研制并在第一次世界大战于英国军队服役，是世界上第一种正式参与战争的坦克。[1] Mark I 坦克在1916年8月开始服役，并于1916年9月15日首次应用在索姆河战役上。它的主要作用是破坏战场上的铁丝网、越过战壕、亦能抵御小型武器的射击。 123456789101112131415161718重量 雄性：28.4公吨（28.0长吨）雌性：27.4公吨（27.0长吨）长度 9.94米（32英尺7英寸）宽度 4.33米（14英尺2英寸）高度 2.44米（8英尺0英寸）操作人数 8人装甲 6-12 毫米主武器 雄性：2 × 霍奇基斯QF 6磅炮 雌性：4 × 维克斯机枪副武器 雄性：3 × 霍奇基斯轻机枪 雌性：1 × 霍奇基斯轻机枪发动机 戴姆勒-奈特6缸 13升 汽油引擎 105匹马力（78千瓦特）功率/重量 雄性：3.7匹马力每公吨（2.8千瓦每公吨） 雌性：4.0匹马力每公吨（3.0千瓦每公吨）悬挂 履带作战范围 23.6英里（38.0千米），巡航6.2小时速度 5.9千米每小时（3.7英里每小时） 美国 Mk 2手榴弹 Mk 2手榴弹（或写作Mk II）是一种反人员破片手榴弹，美军于1918年导入，用以取代Mk 1手榴弹，在二战、韩战至越战中所使用。由于外型相似凤梨又名凤梨手榴弹，因保险片的形状被称为“鸭嘴手榴弹”，因外观被称为“卵形手榴弹”、“凤梨手榴弹”或“癞瓜手榴弹”。 12345重量 595克长度 111毫米填充 TNT填充量 2安士引爆机制 4-5秒 M1911手枪 M1917左轮手枪 史密斯威森军警型左轮手枪 恩菲尔德M1917步枪 李-恩菲尔德步枪 温彻斯特步枪 温彻斯特1907型半自动步枪 莫辛-纳甘步枪 M1903春田步枪 M1903春田步枪是一种旋转后拉式枪机弹仓式手动步枪，1903年定型称为“0.30口径M1903式步枪”，因其由春田（Springfield）兵工厂研制而得名M1903春田步枪（Springfield rifle）。 1234567891011重量 3.95公斤长度 1,098毫米（44.9寸）枪管长度 610毫米（24寸）子弹 .30-03 .30-06（7.62×63毫米） 7.92×57毫米尖头弹(为适应中国与欧洲战场所改膛的)枪机 旋转后拉式枪机枪口初速 823 - 853米／秒有效射程 550米供弹方式 5发弹夹，内置弹仓瞄具 片状准星；带&quot;U&quot;形缺口折叠式框形表尺 温彻斯特M1897泵动式霰弹枪 温彻斯特M1897（英语：Winchester Model (M) 1897，俗称：Model 97或M97）是一枝由著名的美国枪械设计师约翰·勃朗宁设计、美国温彻斯特连发武器公司生产的泵动式及外置击锤型设计霰弹枪。 温彻斯特M1912泵动式霰弹枪 温彻斯特M1912（英语：Winchester Model（M） 1912，俗称：Model 12或M12）是一枝由美国温彻斯特连发武器公司生产的泵动式、内置式击锤设计及外部管式弹仓供弹的霰弹枪。此枪在推出后不久被流行地命名为完美的连发枪（英语：Perfect Repeater），基本奠定了此枪对泵动霰弹枪超过51年的高效率生产的生涯的标准。 勃朗宁Auto-5半自动霰彈槍 勃朗宁Auto-5（英语：Browning Automatic 5，简称：Auto-5、A-5，意为：勃朗宁自动五发式霰弹枪）是一枝由美国著名轻兵器设计家约翰·勃朗宁所研制、后座作用操作的半自动霰弹枪，可发射12铅径霰弹、16铅径霰弹或20铅径霰弹。 勃朗宁自动步枪 勃朗宁自动步枪（英语：Browning Automatic Rifle，简称：BAR），是美军在20世纪上半叶使用的一种自动步枪。 123456789101112131415重量 空枪重：7.2公斤（A1）空枪重：8.8公斤（A2）长度 1,214毫米（47.8寸）枪管长度 610毫米（24寸）子弹 .30-06 Springfield （7.62×63毫米） 7.92×57毫米尖头弹(为适应中国战场所改膛的)口径 7.62毫米（.30寸）枪机 长行程导气式活塞、开放式枪机发射模式 半自动、全自动射速 300-450发/分； 500-650发/分（A2）枪口初速 805米/秒有效射程 548米供弹方式 20发弹匣 刘易斯机枪 勃朗宁机枪 绍沙轻机枪 霍奇科斯重机枪 勃朗宁M1919中型机枪 勃朗宁M1919（M1919 Browning machine gun），俗称（Browning Machine Gun，30 Cal ），是由约翰·勃朗宁在一战后设计的机枪，主要是把水冷式M1917改为风冷式，采用.30-06 Springfield 步枪弹药。 12345678910111213重量 14公斤长度 964毫米（37.94英寸）操作人数 2至3名子弹 .30-06 Springfield（U.S.） 7.62×51mm NATO（U.S.） .303 British口径 7.62毫米/7.7毫米枪机 后坐作用射速 400–600发／分枪口初速 853米／秒有效射程 1,400米供弹方式 M9弹链供弹瞄具 可调机械照门 D级潜艇 D级潜艇是美国海军一战中建造的潜艇级，子合约由格罗昆的电船公司签订，由昆西的佛尔河船厂建造。 123456789101112131415舰型 Submarine排水量 288 long ton（293 t） surfaced 337 long ton（342 t） submerged全长 134英尺10英寸（41.10米）全宽 13英尺11英寸（4.24米）吃水 11英尺8英寸（3.56米）动力来源 2 x NELSECO gasoline engines, 600 hp（450 kW） total[1] 2 x electric motors, 260 hp（190 kW） total 2 x 60-cell batteries 2 shafts速度 12节（22千米每小时；14英里每小时） surfaced, 9.5节（17.6千米每小时；10.9英里每小时） submerged续航距离 1,240海里（2,300千米；1,430英里） (surfaced)潜航深度 200英尺（61米）乘员 15 officers and men武器装备 4 × 18 inch (457 mm) bow torpedo tubes, (4 torpedoes)[3] 美国一战驱逐舰 维基百科： https://zh.wikipedia.org/wiki/Category:%E7%BE%8E%E5%9B%BD%E4%B8%80%E6%88%98%E9%A9%B1%E9%80%90%E8%88%B0 驱逐舰（英语：destroyer）是一种多用途的军舰。驱逐舰的用途是保护舰队，驱逐和消灭鱼雷艇和潜艇等以鱼雷为主要武器的舰只，为舰队提供保护。 化学武器 三氯硝基甲烷 三氯硝基甲烷，俗称氯化苦（英语：Chloropicrin），是一种化学式为Cl3CNO2的有机氯化合物。这种高毒性的物质曾被用作代号为PS的化学武器；现在则主要用作熏蒸剂和杀线虫剂。 二氯甲基胂 二氯甲基胂，亦可简写为MD，是一种有机化合物，化学式为CH3AsCl2。它是一种无色、易挥发的液体，具有很强的毒性，是一种糜烂性毒剂，可作为化学武器使用。 氯丙酮 氯丙酮，结构式ClCH2COCH3。无色有极强刺激性臭味液体，对生物体有强刺激性，在日光下分解产生强催泪性气体。见光变为暗黄的琥珀色。 溴乙酸乙酯 溴乙酸乙酯是一种有机化合物，化学式为CH2BrCO2C2H5。它可由乙酸为原料合成。它是一种催泪剂，具有果味和刺激性气味。它是毒性很高的烷基化试剂。吸入、吞咽或与皮肤接触可能致命。 绿十字毒气 绿十字毒气（德语：Grünkreuz)是在第一次世界大战时使用的化学武器，属于窒息性毒剂，是由三氯硝基甲烷，光气或/和双光气的混合物。 芥子毒气 芥子毒气（英语：mustard gas），亦简称为芥子气，学名二氯二乙硫醚，是一种重要的糜烂性毒剂，因味道与芥末相似而得名。 二战第二次世界大战（又简称二次大战、二战、WWII等；英语：World War II；法语：Seconde Guerre mondiale；德语：Zweiter Weltkrieg；俄语：Вторая мировая война；日语：第二次世界大戰）是一次自1939年至1945年所爆发的全球军事冲突，整场战争涉及到全球绝大多数的国家，包括所有的大国，并最终分成两个彼此对立的军事同盟─同盟国和轴心国。这次战争是人类史上最大的战争，动员了1亿多名军人参与这次军事冲突。主要的参战国纷纷宣布进入总体战状态，几乎将自身国家的全部经济、工业和科学技术用于战争之上，同时将民用和军用的资源合并以便规划。包括有犹太人大屠杀、南京大屠杀、战争中日军对中国军民进行细菌战、以及最终美国对日本首次使用原子弹等事件，使第二次世界大战也是有纪录以来最多大规模民众死亡的军事冲突，全部将近有5,000万至7,000万人因而死亡，这让第二次世界大战成了人类历史上死伤人数最多的战争[2]。第二次世界大战改变了世界局势，英国、法国等欧洲殖民帝国衰落，美国和苏联取代了欧洲殖民帝国的地位成了新的超级大国并在战后形成了两极格局直到1991年。 二战装备比一战更加多样化，如坦克、飞机、潜艇、航空母舰… 德国此列表将列出所有纳粹德国在二次大战中使用过的武器（包括在占领地生产和缴获的武器，但从盟军缴获的武器除外）。 坦克德国第二次世界大战装甲战斗车辆: 1234567輕型坦克 一号坦克 二号坦克 35(t)坦克 38(t)坦克中型坦克 三号坦克 四号坦克 五号坦克豹式重型坦克 六号坦克 虎I 虎II突击炮 三号突击炮 四号突击炮 10.5厘米突击榴弹炮42 33B突击步兵炮 灰熊式 突击虎式驅逐戰車／坦克驱逐车 一号反坦克自走炮 黄鼠狼I式／II式／III式 追猎者式 四号驅逐戰車 犀牛式 猎豹式 猎虎式 象式自走炮 一号自走重步兵炮 二号自走重步兵炮 黄蜂式 野蜂式 蟋蟀式 装甲机动车 40型发射架 卡尔自走臼炮防空坦克 38(t)防空坦克 一号防空坦克 四号防空坦克 家具车式 旋风式 东风式 球状闪电 LT-35坦克 LT-35或LT vz. 35是捷克斯洛伐克制造的轻型坦克，在二战中被纳粹德国采用，德军称为Panzerkampfwagen 35(t)（Pz.Kpfw. 35(t)）或Panzer 35(t)。 123456789101112131415乘员 4人长度 4.9米宽度 2.16米高度 2.2米重量 11吨发动机 斯科达汽油T11功率 120匹 ( 89千瓦)功率重量比 10.9匹/吨悬挂系统 leaf spring bogie速度 34公里/小时最大行程 193公里装甲 25毫米主要武器 1 x Skoda 37毫米M1934炮辅助武器 2 x 7.92毫米MG34机枪 LT-38坦克 LT-38是捷克斯洛伐克斯柯达厂制造的LTvz-38轻型坦克，德军编号Sd.Kfz140 Pz.38(t)，由著名的斯科达（Skoda）兵工厂所制造，于1938年末起服役于捷军，1939年3月德国并吞捷克之后，鉴于此车设计优良，遂以Pz.38(t)的名号继续使用，一直到大战后期都还能看到此车的变种继续为德国在各地奋战。 1234567891011121314151617乘员 4人长度 4.61 米宽度 2.14 米高度 2.40 米重量 9.5吨发动机 汽油Praga EPA 6-cylinder功率 126匹 ( 95千瓦)功率重量比 13匹/吨悬挂系统 钢板弹簧速度 42公里/小时（公路） 15公里/小时（非公路）最大行程 160至250公里装甲 A-D型：8-30毫米E型：50毫米主要武器 1 x 37毫米 L/47.8炮辅助武器 2 x 7.92毫米ZB53机枪 一号坦克 一号坦克（德语：Panzerkampfwagen I，意为一号装甲战斗车辆）是德国于1930年代研制的一款轻型坦克，缩写为“PzKpfw I”，其官方军械署赋予的编号为SdKfz 101（“第101号特殊用途车辆”）。一号坦克自1932年开始设计，并于1934年开始大量生产，它原先仅作为德军建构新一代的装甲战斗与技术时所使用的训练车辆，但后来将其投入了西班牙内战、二战的波兰、法国、苏联、北非战场以及中国在抗日战争中使用。 1234567891011121314151617重量 5.4(A型)/5.8(B型)吨长度 4.02(A型)/4.42(B型)米宽度 2.06米高度 1.72米操作人数 2人；车长及驾驶员装甲 7至13毫米主武器 两门7.92毫米MG13机枪（A型和B型）发动机 克虏伯M 305 4汽缸气冷汽油引擎（A型） 梅巴赫NL 38 TR 6汽缸液冷汽油引擎（B型以后） 60PS（59匹，44千瓦） 100PS（98匹马力、73千瓦）功率/重量 11.1PS／吨悬挂 椭圆钢板弹簧作战范围 140千米（A型） 170千米（B型）速度 37千米／小时（A型） 40千米／小时（B型） 二号坦克 二号坦克（德语：Panzer II）是第二次世界大战纳粹德国的坦克，这型坦克是用来填补其他设计中坦克的空隙, 它在第二次世界大战中的波兰战役与法国战役扮演了一个很重要的角色。到1942年底前绝大多数二号坦克已经离开第一线单位，生产线到1943年终止，然而车体继续被改良回其他种类装甲车辆。 1234567891011121314151617乘员 3人(车长/炮手、装填手、驾驶)长度 4.8米宽度 2.2米高度 2.0米重量 7.2吨发动机 6-cyl汽油梅巴赫HL功率 140匹 (105千瓦)功率重量比 15匹/吨悬挂系统 钢板弹簧速度 40千米/小时最大行程 200千米装甲 5-14.5毫米主要武器 20毫米 KwK 30 L/55 Ausf.A-f 20毫米 KwK 38 L/55 Ausf.J-L辅助武器 7.92毫米MG34机枪 三号坦克 三号坦克（德语：Panzerkampfwagen III），是一款德军二战坦克。三号坦克拥有多种衍生及改进型，并由德军在二战中广泛使用，其改进和衍生型号一直服役到二战结束。 123456789101112131415161718192021重量 19.5 吨长度 5.38米 17ft 8in宽度 2.91米 9ft 7in高度 2.59米 8ft操作人数 5名装甲 30mm主武器 37mm KwK L/46.5（A、B、C、D、E型、部分F、G型） 50mm KwK L/42（部分F、G、J型，H型） 50mm KwK L/60（部分J型、L型） 75mm L/24（部分L型，M型，N型）副武器 3挺MG34（A-H型）2挺MG34（G型以后）发动机 迈巴赫HL108TR（A、B、C、D型） 迈巴赫HL120TR V形12缸（E型以后） 320匹（迈巴赫HL120TR） 变速 SRG 328-145型（E-G型） 迈巴赫SSG77（H型）悬挂 扭力杆悬挂[2]作战范围 200公里[6]速度 42公里/时[6] 四号坦克 四号坦克（德语：Panzerkampfwagen IV，或称IV号坦克）为纳粹德国在第二次世界大战中生产的一款中型坦克。它原本设计目的是支援步兵，并且与专门执行反坦克任务的三号坦克协同作战。在三号坦克的整体性能逐渐不敷二次大战中期装甲战斗需要时，四号坦克因所使用的技术较为成熟而比三号坦克有更大的改良空间，因此在不断改进的过程中，四号坦克逐渐成为装甲师装备的主力车种。四号坦克较大的改良空间亦使其较为容易改装，既有改造为突击炮、自行反坦克炮，也有改造为弹药运送车、架桥坦克等，成为用途最广泛的坦克。从投产至二战结束，德国共制造了逾8,800辆四号坦克或其改造型。四号坦克参加了几乎所有战役，而且表现出相当的可靠性，没有像豹式坦克初期型号有大量的技术问题，就数量、服役时间来看，这型坦克才是德国装甲兵的主力，因此被德军装甲兵昵称为“军马”。 1234567891011121314151617181920212223242526272829乘员 5人（车长、炮手、装填手、驾驶员及无线电操作员）长度 7.02米宽度 2.88米高度 2.68米重量 B型：16吨；C型：18.14吨 D型：20吨；F型：22.3吨 G型：23.6吨；H型：25吨发动机 梅巴赫A型：HL108TR 12缸汽油引擎 B型：HL120TR 12缸汽油引擎 C型：HL120TRM 12缸汽油引擎功率 A型：250hp；B型：300hp功率重量比 12匹/吨悬挂系统 弹簧悬挂（C型开始使用板簧悬挂系统）速度 A型：31公里/小时〔道路〕 B型：39公里/小时〔道路〕 42公里/小时（道路） 16公里/小时（越野）最大行程 200公里J型：320公里装甲 炮塔正面50毫米/10° 炮塔两侧30毫米/26° 炮塔后方30毫米/10° 炮塔顶10毫米 车体正面80毫米/11° 车体侧面30毫米（后期型号加5毫米裙甲） 车体后面20毫米主要武器 坦克炮-KwK40 75毫米43倍径炮（KwK-40 75mm）辅助武器 2×7.92毫米MG34 五号坦克 五号坦克 黑豹式（德语：Panzerkampfwagen V Panther）是第二次世界大战中纳粹德国所制造的中型坦克。制式编号为Sd.Kfz.171。其后，由于“五号坦克（V号坦克）”这个名称被废除，所以在后来以“黑豹式坦克（Pz.Kpfw. Panther）”作为制式名称。 1234567891011121314151617181920乘员 5人车长、炮手、驾驶、通讯员、装填手[3]长度 6.87米（车身） 8.66米（全长）宽度 3.27米高度 2.995米重量 44.8吨（战斗重量）发动机 梅巴赫230P30 水冷V型12汽缸汽油引擎功率 700匹功率重量比 15.625匹／吨悬挂系统 双扭力杆速度 55公里／小时（平地） 30公里／小时（越野）最大行程 250公里（平地）、100公里（越野）装甲 前方80毫米，倾斜装甲139.48毫米侧面及后方40毫米主要武器 7.5厘米Kwk42L/70炮（炮弹79发后期81发）辅助武器 7.92毫米MG34机枪 ×2 六号坦克 六号坦克（德语：Panzerkampfwagen VI）是纳粹德国在第二次世界大战期间所使用的重坦克。被称为六号坦克的坦克共有2款，分别是I型与II型，即为“虎I”与“虎II”。在当时被评为其中一系列世界上最强的坦克。一般称其为“虎式坦克”，或者以英文“Tiger Tank”来称呼。 虎I坦克 虎I坦克（德语：Panzerkampfwagen VI Ausf. E (Sd Kfz 181) Tiger），是第二次世界大战中德意志国防军及武装党卫队所使用的坦克，正式名称为六号坦克（VI号坦克）。一般称为虎式坦克，简称“虎式”或“Tiger”。从1942年下半年服役起至1945年纳粹德国投降为止，一直是活跃于第一线的重型坦克。 123456789101112131415161718192021乘员 5人车长、炮手、装填手、驾驶员、通讯员长度 8.45米（全长） 6.316米（车身）宽度 3.705米高度 3米重量 57吨（战斗重量）发动机 梅巴赫HL230 P45 水冷4冲程V型12汽缸汽油引擎[2]功率 700匹功率重量比 12.3匹／吨悬挂系统 扭力杆速度 40公里／小时（平地） 20-25公里／小时（越野）最大行程 100公里（平地）、60公里（越野）装甲 前方100毫米 侧面及后方80毫米 车顶25毫米主要武器 8.8厘米Kwk 36 L/56炮（炮弹92发）辅助武器 7.92毫米MG34机枪 ×2 虎II坦克 六号坦克B型 （德语：Panzerkampfwagen VI Ausf.B Tiger II，通称“虎王坦克”或“虎II坦克”），是一款纳粹德国在二战期间研发的重型坦克。虎王坦克是虎I坦克的继任者，它继承了虎I坦克的重装甲风格，还有着豹式坦克那样的倾斜装甲。虎王坦克重达70公吨，前装甲有100到180毫米厚，装配一门88毫米KwK 43 L/71式坦克炮。没有炮塔的猎虎式坦克歼击车与虎王坦克共用同一种底盘。 12345678910111213141516171819202122232425重量 68.5公吨（装备保时捷炮塔）69.8公吨（装备亨舍尔炮塔）长度 7.38米（车体） 10.286米（33英尺9英寸）（炮向前）宽度 3.755米高度 3.09米操作人数 五人（车长、炮手、装填手、通信兵、驾驶员）装甲 25～185毫米（1～7英寸）主武器 1门KwK43 88毫米坦克炮 保时捷型炮塔可携带80发炮弹 亨舍尔型炮塔可携带86发炮弹副武器 2挺7.92毫米MG 34 携带5850发弹药发动机 V-12 迈巴赫HL 230 P30汽油机 690匹功率/重量 8.97匹/公吨变速 迈巴赫OLVAR EG 40 12 16 B（8个前进档、4个倒车档）悬挂 扭力杆悬挂底盘高度 495至510毫米燃料容量 860升（190英制加仑）作战范围 于公路上行驶：170千米 越野时：120千米速度 公路上最大速度：41.5千米/时 能允许持续行进：38千米/时 越野时：15-20千米/时 !()[/images/Weapons/Tiger-II.png] 七号狮式坦克 七号狮式超重型坦克（Panzerkampfwagen VII Löwe）为二战纳粹德国研发的一款超重型坦克。制造数量 从未被制造出来。 八号坦克鼠式 八号坦克鼠式（Panzerkampfwagen VIII Maus），是德国在第二次世界大战设计并制造的超重型坦克。产量 2（原型车，其中只有一台完工）。 九/十号坦克 九号坦克（Panzerkampfwagen IX）及十号坦克（Panzerkampfwagen X），为纳粹德国在第二次世界大战晚期故意散布欺敌的虚构坦克开发计划。 陆地巡航者P. 1000老鼠 P. 1000 巨鼠重型巡航坦克（Landkreuzer P. 1000 Ratte）是纳粹德国计划开发的一种重量达1000吨的超重型坦克，由德国的克虏伯公司研制，但计划在1943年被放弃，没有一辆P-1000被生产出来。此超重型坦克非常巨大，高度有11米，炮台也有两个平常人的高度。制造数量 0（完全从未实际投产） 陆地巡航者P.1500怪物 P. 1500 怪物陆行舰（Landkreuzer P. 1500 Monster）外型和古斯塔夫超重型铁道炮相似，是纳粹德国计划开发的一种重量达1,500吨的超重型坦克。制造数量 0（完全从未实际投产） 潜艇submarine U-47潜艇 U-47号潜艇是一艘于第二次世界大战时于纳粹德国海军服役的VIIB型U-潜艇。它在1937年2月25日开始建造并于1938年10月29日在基尔的克虏伯造船厂下水。 1234567891011121314151617舰型 VIIB型排水量 761吨 865吨（潜入海底）全长 66.6米（219英尺）全宽 6.2米（20英尺）深度 220米（720英尺）动力来源 2 × 1400 马力的柴油机 2 × 375 PS （280 kW） 的电动马达速度 最大17.7节（海面） 最大7.6节（潜入海底）续航距离 6,500海里（12,000千米）乘员 44-48船员 47武器装备鱼雷发射管：前4后1，共5个533mm发射管 8.8厘米 SK C/35舰炮（虽同为88毫米口径但是与8.8 cm Flak 18/36/37高射炮不同），2厘米 MG C/30 机炮 U-2365 U-2365号潜艇为纳粹德国海军XXIII级潜艇（德语：Klasse XXIII、或称Typ XXIII）的一艘，属于近海小型攻击潜艇。U-2365号潜艇于1945年3月2日服役。由于服役时已临近战争尾声，该艇并未取得任何战果，最终于1945年5月8日中被凿沉在卡特加特海峡。 火炮第二次世界大战期间德国陆军所用火炮: 1234567891011121314151617181920212223242526272829坦克主炮 2厘米KwK 30炮 3.7厘米KwK 36炮 3.7厘米KwK 38炮(t) 5厘米KwK 38炮 5厘米KwK 39炮 7.5厘米KwK 37炮 7.5厘米KwK 40炮 7.5厘米KwK 42炮 8.8厘米 KwK 36炮 8.8厘米 KwK 43炮反坦克炮 sPzB 41反坦克炮 PaK 36反坦克炮 4.2厘米Pak 41反坦克炮 Pak 38反坦克炮 Pak 97/38反坦克炮 Pak 39反坦克炮 Pak 40反坦克炮 7.5厘米Pak 41反坦克炮 7.5厘米Pak 42反坦克炮 7.62厘米PaK 36反坦克炮(r) 8公分PAW 600反坦克炮 Pak 43反坦克炮 PaK 44反坦克炮步兵支援火炮 le.IG 1步兵支援火炮 IG 37步兵支援火炮 IG 42步兵支援火炮 sIG 33步兵支援火炮 GebH 34步兵支援火炮 GebG 36步兵支援火炮 GebH 40步兵支援火炮无后座力炮 7.5厘米LG 40无后座力炮 105毫米LG 40无后座力炮 LG 42无后座力炮重型迫击炮 10公分35年式喷烟者 10公分40年式喷烟者 leLdgW迫击炮 GrW 69迫击炮 schwerer Ladungswerfer迫击炮火箭炮 7.3厘米Föhn-Gerät 7.3厘米41年式Propagandawerfer 8厘米Raketen-Vielfachwerfer 15厘米Do-Gerät 15公分41年式喷烟者 21公分42年式喷烟者 28/32公分41年式喷烟者 30公分42年式喷烟者 30 cm Raketenwerfer 56 Wurfrahmen 40多管火箭炮中重型野战炮 FK 16 nA野战炮 FK 18野战炮 FK 38野战炮 FK 7M85野战炮 10 cm K 17野战炮 sK 18野战炮 leFH 16榴弹炮 leFH 18榴弹炮 leFH 18M榴弹炮 leFH 18/40榴弹炮 sK 18/40野战炮 sFH 13榴弹炮 SFH 18榴弹炮 K 16野战炮 K 18重炮 K 39重炮 SK C/28重炮 K 18重榴弹炮 Mrs 16重榴弹炮 Mrs 18重榴弹炮超重炮及攻城武器 K 38重炮 K 39重炮 H 39攻城榴弹炮 K(t)超重型攻城炮 Kanone L/46 K 3重型攻城炮 H L/12重型攻城榴弹炮 Haubitze M1攻城榴弹炮 Gamma Mörser攻城榴弹炮 卡尔臼炮 古斯塔夫超重型铁道炮列车炮15厘米K列车炮 17厘米K列车炮 20.3厘米K列车炮 21厘米K 12列车炮 24厘米Th K列车炮 24厘米ThBr K列车炮 28厘米kzBr K列车炮 28厘米lgBr K列车炮 28厘米sBr K列车炮 28厘米Br NK列车炮 K5列车炮 38厘米Siegfried K列车炮 古斯塔夫超重型铁道炮防空炮2厘米30/38年式高射炮 2厘米Gebirgsflak 38高射炮 3.7厘米18/36/37/43年式高射炮 5厘米41年式高射炮 8.8厘米18/36/37年式高射炮 8.8厘米41年式高射炮 10.5厘米38年式高射炮 12.8厘米40年式高射炮 Mrs 18重榴弹炮 Mrs 18重榴弹炮（21公分Mrs 18式）是纳粹德国于第二次世界大战中所使用的一种重型榴弹炮。 12345678910111213重量 16,700 公斤（36,817 磅）枪管长度 6.51米L/30（30倍径）炮弹 分离装填式弹药炮弹重量 113公斤（高爆弹）口径 211 毫米后膛 水平滑契式炮栓后坐力 液压机械复合式载具 box trail射击仰角 -6° to +70°回旋角度 16°（于轮上） 360°（于平台上）枪口初速 550 米/秒有效射程 14,500 米 3.7厘米KwK 36炮 3.7 cm KwK 36 L/45 (3.7 公分战车炮36 45倍径)是第二次世界大战时由德国所生产的3.7cm火炮，主要用做三号战车的主炮，亦见于其他德军装甲车辆上。 5厘米KwK 38炮 5 cm KwK 38 L/42(5公分战车炮 42倍径)是二战时德军所用的50毫米火炮，仅见于三号战车上使用。 5厘米KwK 39炮 5 cm KwK 39 L/60 (5公分战车炮 60倍径)是二战时德军所用的50毫米火炮，主要作为1941年以后，三号战车后续型号的主炮。 7.5厘米KwK 37炮 7.5 cm KwK 37 L/24(7.5公分战车炮24倍径)是一种二战时，德军所使用的75mm，类似榴弹炮的短管战车炮。主要用于四号战车的早期型号和三号突击炮的早期型号。 7.5厘米KwK 40炮 7.5 cm KwK 40是在二战时，德军所使用的战车炮。主要搭载于于四号战车（F2型以后）、三号突击炮以及四号突击炮上。 7.5厘米LG 40无后座力炮 7.5厘米LG 40无后座力炮是由德国军队在第二次世界大战期间使用的无后座力炮。 7.5厘米Pak 41反坦克炮 7.5 cm Pak 41是第二次世界大战后期进入服役，由德国制造的反坦克炮。 7.5厘米 Pak 39炮 7.5厘米Pak39(L/48)（德语：7.5 cm Panzerjägerkanone 39），是一款德国于第二次世界大战期间所使用的反坦克火炮。该火炮于1942年1月开始装备于四号驱逐战车和追猎者式驱逐战车等驱逐战车。 KwK36 88毫米战车炮 88 mm KwK 36 L/56 (德语：8.8 cm KampfwagenKanone 36 L/56) 是在第二次世界大战中德意志国防军所使用的88毫米坦克炮。由克鲁伯所研制，是虎I坦克的主武器。 KwK43 88毫米战车炮 8.8 cm KwK 43 L/71 (德语：KampfWagenKanone—坦克炮) 是在第二次世界大战中，克鲁伯公司所设计，德意志国防军所使用的一门坦克炮。它是虎II坦克的主武器，并且是在第二次世界大战中作为放在拥有可转动炮塔的战车上最具威力的一门炮。 装甲战斗车 飞机 船舰 武器 39型卵状手榴弹 39型卵状手榴弹（德语：Eihandgranate 39）是第二次世界大战期间德军所产的手榴弹。 柄式手榴弹 柄式手榴弹（德语：Stielhandgranate）为德国陆军自第一次世界大战中期至第二次世界大战末期所使用之手榴弹。 铁拳 铁拳（德语：Panzerfaust）又称作装甲拳或反坦克榴弹发射器，是第二次世界大战时由德国研发与制造的火药推进无后座力反装甲武器。 防空铁拳 防空铁拳(德文:Fliegerfaust)是第二次世界大战末期德国士兵使用的手提防空火箭弹，由于在二战末期，德军失去制空权(尤其在西线)，而研制出来的步兵手提防空火箭弹。 装甲投掷雷 装甲投掷雷（德语：Panzerwurfmine，也缩写为PWM）是一种由纳粹德国开发并在二战中生产使用的反坦克碰炸手榴弹。 坦克杀手 Panzerschreck（德语）是二战中，纳粹德国的Raketenpanzerbüchse（“反战车火箭步枪”，缩写为RPzB）的昵称，它是一种口径为88毫米，可重复使用的反战车火箭发射器。 LeGrW 36型50毫米迫击炮 LeGrW 36型50毫米迫击炮（德语：5cm leichter Granatenwerfer 36 ）是纳粹德国在第二次世界大战中使用的一种轻型迫击炮。 123456789101112重量 14 kg (31 lb)枪管长度 465 mm (18 in)操作人数 2炮弹 0.9 kg (2 lb) TNT 装药口径 50 mm (1.97 in)射击仰角 42°到 90°回旋角度 33°到 45°射速 15-25 发/每分钟枪口初速 75 m/s (246 ft/s)有效射程 50 m (54.7 yd) 最小 510 m (557.7 yd) 最大最大射程 520 m (568.7 yd) GrW 34型81毫米迫击炮 GrW 34型81毫米迫击炮（德语：8 cm Granatwerfer 34）是纳粹德国陆军在第二次世界大战使用的一种迫击炮，这种迫击炮的射速和射程都颇为优秀，在训练有素的士兵手中可以发挥出更大的威力。在单兵携带时，这种迫击炮可以分解为炮筒、底座和支架三个部分。 1234567891011重量 62 kg (136.6 lbs) 钢炮筒 57 kg (125.6 lbs) 合金炮筒枪管长度 1,143 mm (45 in)操作人数 8炮弹 3.5 kg (7.71 lbs)口径 81.4 mm (3.20 in)射击仰角 45°到90°回旋角度 10°到23°射速 15-25 发/每分钟枪口初速 174 m/s (571 ft/s)最大射程 2,400 m (2,624 yds) GrW 42型81毫米迫击炮 GrW 42型81毫米迫击炮（德语：kurzer 8 cm Granatwerfer 42 ）是纳粹德国在第二次世界大战中使用的一种前装式滑膛迫击炮。是GrW 34型81毫米迫击炮使用短炮筒后的轻量化版本，最初计划是供伞兵使用的。然而由于50毫米口径的LeGrW 36型50毫米迫击炮射程太近，此款迫击炮也常被用来替换前者。GrW 42发射的炮弹重量是前者的3.5倍，射程则为两倍，迫击炮的重量则不到前者两倍，同时还可分解为三个部分携带。 鲁格手枪 M1879帝国转轮手枪 毛瑟C96手枪 瓦尔特P38手枪 瓦尔特P38（德语：Walther P38）是由德国瓦尔特武器公司在1930年代为德意志国防军研制的一种9毫米口径半自动手枪，此枪在二战期间被广泛采用。尽管该枪的出现原先是为了取代成本昂贵的鲁格P08手枪，然而直到二战结束时也没有完全取代。 12345678910重量 800克长度 216毫米枪管长度 125毫米子弹 9毫米鲁格弹枪机 短行程后座单动/双动枪口初速 365米/秒有效射程 50米供弹方式 8发可拆式单排弹匣瞄具 凹形照门，刀片形准星 ViS wz. 35手枪 Pistolet ViS wz. 35是由波兰枪工Piotr Wilniewczyc研制的一款半自动手枪，于1935年成为波兰军队的制式手枪。ViS wz. 35一直都被认为是有史以来最好的手枪之一，更是一些枪械收藏家的珍藏之一。 12345678910重量 1.123 kg（上弹） 0.950 kg（空枪）长度 205 mm枪管长度 115 mm子弹 9毫米鲁格弹口径 9×19毫米枪机 枪管短行程后座作用、单动枪口初速 345米/秒供弹方式 8发弹匣瞄具 金属缺口式照门及准星 MP18冲锋枪 MP28冲锋枪 MP3008冲锋枪 MP 3008是纳粹德国在1945年二战末期制造的冲锋枪。主要目的是提供给在战争末期扩编的国民突击队使用。 12345678910重量 3.18公斤长度 760毫米枪管长度 196毫米子弹 9×19毫米口径 9毫米枪机 反冲作用，开放式枪机发射模式 全自动射速 450发/分锺枪口初速 365米/秒供弹方式 32发MP40可拆卸式弹匣 MP34冲锋枪 MP34（德语：Maschinenpistole 34，意为：34型冲锋枪）是一枝由奥地利斯泰尔兵工厂生产的冲锋枪，在1930年代至二战期间被奥地利警察以及随后的德国国防军和武装党卫队所采用。 MP35冲锋枪 MP35（德语：Maschinenpistole 35，意为：35型冲锋枪）是一枝由纳粹德国生产的冲锋枪，在二战以前和期间被德国国防军、武装党卫队和德国警察所采用。 MP40冲锋枪 MP40冲锋枪（Maschinenpistole 40），常被称为“施迈瑟冲锋枪”，是一种为方便大量生产而设计，与传统枪械制造观念不同的冲锋枪，亦是第二次世界大战期间德国军队使用最广泛、性能最优良的冲锋枪。 123456789101112重量 4公斤（8.82磅）长度 收起枪托：630毫米 展开枪托：833毫米枪管长度 251毫米子弹 9×19毫米鲁格弹枪机 提前击发底火式反冲作用及开放式枪机发射模式 全自动射速 500发／分钟枪口初速 约380米／秒有效射程 约100米供弹方式 32发弹匣瞄具 机械瞄具 MP41冲锋枪 MP41（德语：Maschinenpistole 41，意为：41型冲锋枪）是一款由纳粹德国枪械设计师胡戈·施迈瑟所研发、黑内尔公司生产的冲锋枪，外观而言是MP40冲锋枪改用MP28冲锋枪的木制枪托的修改型，发射9×19毫米鲁格手枪子弹。MP41是专门为出口和警察部门而生产。]]></content>
      <categories>
        <category>Weapon</category>
      </categories>
      <tags>
        <tag>武器</tag>
        <tag>战争</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一战二战武器]]></title>
    <url>%2F2018%2F11%2F18%2F%E4%B8%80%E6%88%98%E4%BA%8C%E6%88%98%E6%AD%A6%E5%99%A8%E8%A3%85%E5%A4%87%2F</url>
    <content type="text"><![CDATA[参考： 各国一战武器，维基百科 第一次世界大战武器装备，维基百科 各国二战武器，维基百科 第二次世界大战武器装备，维基百科 最近玩battlefield I(一战)有感，一时兴起，顺带在battlefield V(二战)发布前夕做一个一战二战各国使用的武器装备归纳总结。 玩了战地1，才体会到战争的残酷性，使我对战争的感觉从光辉转变为厌恶。没有什么英雄在我心中，你不知道自己何时会死去，或即将死去。战场上每个人都一样，都是一条鲜活的生命，有家人有朋友。从战争游戏来反思战争，这点DICE studio做的不错。 衷心祝愿世界和平！ 一战第一次世界大战（简称一次大战、一战，或称欧战；英语：World War I、WWI、Great War、First World War；法语：la première Guerre Mondiale、la Grande Guerre）是一场于1914年7月28日至1918年11月11日主要发生在欧洲的大战，然而战火最终延烧至全球，当时世界上大多数国家都被卷入这场战争，史称“第一次世界大战”。 主要介绍国家： 德国 法国 俄国 英国 美国 主要武器分类： 枪械 大炮 坦克 飞机 船舰 德国第一次世界大战德国主要武器 手榴弹hand grenade 柄式手榴弹 柄式手榴弹（德语：Stielhandgranate）为德国陆军自第一次世界大战中期至第二次世界大战末期所使用之手榴弹。 12345重量 595克长度 365毫米直径 70毫米填充 三硝基甲苯（TNT）引爆机制 5秒 手枪pistol 毛瑟C96(Mauser C96) 由毛瑟在1896年推出的手枪，在中国还有驳壳枪、快慢机、自来得、大镜面等别称。毛瑟（德语：Mauser）是一个德国的枪械制造商。 1234567891011121314151617重量 1.130公斤（空枪）长度 288毫米枪管长度 140毫米子弹 7.63×25mm毛瑟弹 9×19mm鲁格弹 .45 ACP 9×25mm毛瑟弹枪机 枪管短行程后座作用 单动发射模式 C96：半自动 M712速射型：半自动、全自动枪口初速 425米/秒有效射程 100米最大射程 200米供弹方式 C96：10发内置弹仓M712速射型：10发或20发弹匣瞄具 V型照门上刻度最大可调至1000米 鲁格手枪（Pistole 08 Luger) 简称P08该枪由奥地利人格奥尔格·鲁格于1898年设计，并由以德国武器及弹药兵工厂及毛瑟为首等多间工厂于1900年投入生产。 1234567891011重量 1.92磅（871克）长度 8.75英寸（222毫米）枪管长度 98毫米–203毫米 （3.9 -8.02英寸）子弹 7.65×21毫米帕拉贝伦弹 9毫米鲁格弹 .45 ACP（相当罕见）枪机 枪管短行程后座作用，肘节式起落闭锁（Toggle Lock）枪口初速 350 - 400米/秒有效射程 50米供弹方式 8发弹匣、32发弹鼓 帝国转轮手枪（Reichsrevolver） 该枪后来被著名的鲁格P08半自动手枪所取代。 12345678重量 1040克长度 310毫米子弹 10.6×25mmR口径 10.6mm射速 单动式枪口初速 205米/秒供弹方式 6发弹巢瞄具 V型缺口及准星 贝格曼1896型手枪 12345678910重量 1.13 kg长度 254 mm枪管长度 102 mm子弹 5毫米贝格曼弹6.5毫米贝格曼弹8×22毫米贝格曼弹枪机 反冲作用枪口初速 380米/秒供弹方式 5发载入内置弹仓内瞄具 固定式瞄具 费罗梅尔停止手枪()Frommer Stop 12345678重量 610 g（22 oz）长度 165 mm（6.5英寸）枪管长度 95毫米（3.7英寸）子弹 .32 ACP.380 ACP枪机 长行程后座作用枪口初速 280 m/s（919 ft/s）供弹方式 7发弹匣 冲锋枪Submachine Guns MP18 MP18冲锋枪是第一次世界大战时期由德国的胡戈·施梅瑟所开发的冲锋枪。MP18冲锋枪因其生产厂Bergmann也被称为伯格曼冲锋枪。 1234567891011重量 4.18公斤长度 832毫米枪管长度 200 毫米子弹 9毫米鲁格弹7.63×25毫米毛瑟弹枪机 反冲作用、开放式枪机发射模式 MP18：全自动MP28：半自动、全自动射速 500发/分枪口初速 380米/秒供弹方式 32发弹匣 TM 08 （一战）；20，30 和 50 发弹匣（二战前） 机枪machine gun MG08重机枪 Maschinengewehr 08（也称MG08，Maschinengewehr意为机枪）由海勒姆·马克沁1884年开发的马克沁机枪发展而来。 1234567891011121314重量 连冷却水一共 69 kg ，除去冷却水65 kg 枪身26.5 kg 4 kg水 三脚架38.5 kg MG08/15：连同两脚架17.8kg 水 3KG MG08/18：不含两脚架14.5KG长度 1175 mm MG08/15、MG08/18：1445 mm枪管长度 720mm操作人数 4人班组子弹 7.92×57毫米毛瑟枪机 枪管短后座，肘节式起落闭锁射速 450-500 发/分枪口初速 900米每秒（3,000英尺每秒）有效射程 2,000米（2,200码）最大射程 3,500米（3,800码）供弹方式 250 发弹链 麦德森轻机枪(Madsen machine gun) 这也是全世界上第一种大量生产的真正实用化的轻机枪。 123456789101112131415161718重量 空枪：9.07 千克（20 磅）长度 1,143 毫米（45 英寸）枪管长度 584.2 毫米（23 英寸）子弹6.5×55毫米瑞典子弹7×57毫米毛瑟子弹7.65×53毫米阿根廷子弹7.62×51毫米NATO7.62×54毫米R.303英式子弹[1]7.92×57毫米毛瑟子弹枪管 1 根，膛线4 条，右旋，枪管装上风冷式枪管套和消焰器枪机 枪管长行程后座作用发射模式 全自动射速 450发／分钟枪口初速 6.5×55毫米瑞典子弹：700—870米／秒（2,296.59—2,854.33英尺／秒）供弹方式 25、30、40发可拆卸式弹匣瞄具 机械瞄具：Ｖ型缺口式照门及柱状准星 步枪rifle Gewehr 98步枪 Gewehr 98步枪（又称：G98、Gew 98、毛瑟M1898或M98）是德国毛瑟枪厂在德国军方采用Gewehr 88步枪后，为了夺回在德国枪械市场的地位而研制的步枪。Gew 98在1898年到1935年间为德国军队的制式步枪，直到它在1935年被毛瑟Kar98k步枪取代为止。 12345678910111213重量 4.09千克（9.0磅） Gewehr 98（空枪） 3.50千克（7.7磅） Karabiner 98a长度 1,250 mm（49.2英寸） Gewehr 98 1,090 mm（42.9英寸） Karabiner 98a枪管长度 740 mm（29.1英寸） Gewehr 98 590 mm（23.2英寸） Karabiner 98a子弹 7.92×57mm毛瑟枪机 旋转后拉式枪机枪口初速 878 m/s（2,881 ft/s）有效射程 500米（550 yd） （机械瞄具） ≥800米（870 yd）（瞄准镜）供弹方式 5发内置弹仓（能够以弹夹条压入）瞄具 机械瞄具 蒙德拉贡步枪 蒙德拉贡步枪（西班牙语：Fusil Mondragón）是一种由墨西哥上将曼努埃尔·蒙德拉贡(Manuel Mondragón)设计，瑞士工业公司（SIG）生产的半自动步枪。 123456789101112重量 4.18 公斤长度 1105 毫米枪管长度 577 毫米子弹 7 × 57 毫米毛瑟弹/7.92 × 57 毫米毛瑟弹枪机 气动式 转拴式枪机枪口初速 760 米/秒有效射程 800 米最大射程 2,000 米供弹方式 8、10、20、30 发可拆式弹匣 100 发弹鼓瞄具 机械瞄具 毛瑟13.2毫米反坦克步枪 毛瑟13.2毫米反坦克步枪为德意志帝国陆军于第一次世界大战中针对协约国（主要是英国）的装甲车辆所研发生产的反装甲武器，初次登场时间是1918年2月。 12345678重量 15.8公斤长度 1.68米枪管长度 0.98米子弹 13.2mm TuF枪机 旋转后拉式枪机枪口初速 805米/秒供弹方式 单发装填瞄具 传统铁制照门 装甲车 埃尔哈特E-V/4装甲车 埃尔哈特E-V/4装甲车是德国二战前研发用于轻度战斗和警务的装甲车。 12345678910111213重量 7.12 - 7.75 吨长度 5.3 m宽度 2 m高度 2.85 m操作人数 8 - 9人装甲 约9 mm主武器 三挺机枪发动机 汽油80 hp (59 kw)功率/重量 10.3 hp/tonne悬挂 四轮驱动作战范围 250 km速度 61.3 km/h 坦克Tank A7V坦克 A7V（Sturmpanzerwagen A7V）是德意志帝国在第一次世界大战时开发的坦克。 1234567891011121314重量 30 至33 吨长度 7.34 米（24 尺 1 寸）宽度 3.1 米（10 尺）高度 3.3 米（10 尺 10 寸）操作人数 18人装甲 侧面20 毫米，正面50 毫米主武器 57 毫米主炮副武器 6挺7.92毫米机枪发动机 2具戴姆勒4汽缸汽油引擎100匹／800-900转（149 千瓦）x2功率/重量 6.5 匹／吨悬挂 履带、立式弹簧作战范围 30-80 公里（20-50 英里）速度 9 公里／小时 LK I Leichter Kampfwagen (中文：轻型战斗车辆) 或“LK I”是第一次世界大战期间德国制造的原型轻型坦克。 123456789101112重量 6.9 吨长度 5.1 米宽度 1.9 米高度 2.5 米操作人数 3 人装甲 8-14 毫米主武器 7.92 毫米 机枪发动机 戴姆勒-奔驰4缸发动机60 匹/44.7 千瓦悬挂 非悬挂作战范围 70 千米速度 14-18 千米/小时 飞机aircraft AEG B.I侦察机 AEG B.I侦察机是德国的双座双翼侦察机，于1914年小批量生产。它为AEG公司更成功的后继机型——B型和C型的设计提供了基础。 J.I攻击机 J.I攻击机（制造厂商将其定为“J 4”，以防止与1915年开发的“J 1”机混淆）是德意志帝国陆军航空队于第一次世界大战所使用的一款地面攻击机、侦察机和连络机，由容克斯所研制，属德国“J系列”装甲航空机之一。 信天翁C侦察机 信天翁C侦察机是由信天翁飞机公司研制的双翼侦察机，在第一次世界大战期间不单作为侦察机，还以其机载机枪件为战斗机和对地攻击机，信天翁飞机公司以此为基础推出信天翁D战斗机。 信天翁D战斗机 信天翁D战斗机是由信天翁飞机公司以信天翁C侦察机的基础和参考了法国纽波特11战斗机而研制的双翼战斗机，在第一次世界大战期间是继福克E单翼战斗机后德国空军的主力战斗机。 戈塔G轰炸机 戈塔G轰炸机是德国在第一次世界大战时的重型轰炸机，在大战期间主要用于轰炸英国，把死亡和恐惧带给英国民众。 巨人机 巨人机（德语：Riesenflugzeug，複數時寫作：Riesenflugzeuge），英语有时简称为R型飞机，是指一次世界大战中德意志帝国所使用的重型轰炸机。 柏法茨战斗机 柏法茨双翼战斗机是在第一次世界大战时由德国柏法茨飞机公司(德文:Pfalz Flugzeugwerke)研制的双翼战斗机。 汉诺威CL攻击机 汉诺威CL攻击机是在第一次世界大战时由德国汉诺威飞机公司(德文:Hannoversche Waggonfabrik)研制的双翼攻击机，CL原本是指比一般侦察机（代号为C）轻巧的双座机，原本是用作为侦察机提供直接的护航，但后来发展成为对地攻击机尤其以其后座机枪作为居高临下的机枪火力点。 福克战斗机 是福克飞机公司为了参加德国空军的“新型战斗机比赛”而提出的战斗机设计。 罗兰C-II侦察机 罗兰C-II侦察机是由LFG公司（Luft-Fahrzeug-Gesellschaft）研制的双翼侦察机，它被誉为第一次世界大战当中最漂亮的德国侦察机，它也因此被称为“鲸鱼”。 齐柏林-斯塔肯R-VI轰炸机 齐柏林-斯塔肯R-VI轰炸机是德国在第一次世界大战时的重型轰炸机，在大战期间主要和戈塔G轰炸机一起轰炸英国，把死亡和恐惧带给英国民众。 鸽式单翼机 鸽式单翼机是由奥地利(当时的“奥匈帝国)飞机工程师埃高．艾垂奇发明的，在第一次世界大战期间除了奥匈帝国，其同盟国盟友德意志帝国也大量采用作为侦察机、轰炸机和教练机等多种用途，虽然在1914年此机已算落伍，但毫无疑问的此后德国所有震惊世界的优秀军用飞机都是从鸽式单翼机开始的。 巡洋舰一次世界大战德国巡洋舰： https://zh.wikipedia.org/wiki/Category:%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%B8%96%E7%95%8C%E5%A4%A7%E6%88%B0%E5%BE%B7%E5%9C%8B%E5%B7%A1%E6%B4%8B%E8%89%A6 巡洋舰（英语：Cruiser）指在排水量、火力、装甲防护等方面仅次于战列舰的大型水面舰艇，拥有同时对付多个作战目标的能力，以及能胜任多种任务的多样性。历史上，巡洋舰由于吨位大、火力强、性能佳，一开始是指可以独立行动的战舰 ; 而与此相对的驱逐舰则需要其它船只（比如补给船只）的协助，才能执行任务。不过随着现今驱逐舰被大型化后的综合作战能力的提升，何潬吨位其实超过早年的巡洋舰，所以这个区分已经不明显了，很多新式的大型军舰都不再冠以巡洋舰之名了。 巡洋舰的用途顾名思义确实是用来巡逻的。 战列舰一次大战德国战列舰: https://zh.wikipedia.org/wiki/Category:%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%B8%96%E7%95%8C%E5%A4%A7%E6%88%98%E5%BE%B7%E5%9B%BD%E6%88%98%E5%88%97%E8%88%B0 战列舰（英语：Battleship），是装有厚重装甲和大口径主炮的大型军舰，是人类创造的最庞大和复杂的武器系统之一，大舰巨炮主义时代的极致产物。 法国手枪 FN M1900手枪(勃朗宁) FN M1900是一款由著名枪械设计师约翰·勃朗宁于1896年设计，交由比利时Fabrique Nationale生产的单动式半自动手枪。该枪亦是史上第一款使用套筒设计的手枪。 1234567重量 625克（空枪）长度 172亳米枪管长度 102亳米子弹 .32 ACP（7.65×17亳米）枪机 反冲作用，单动供弹方式 7 + 1发弹匣瞄具 固定式瞄具 M1892转轮手枪 M1892转轮手枪（或称：勒贝尔转轮手枪或圣埃蒂安8毫米）是法国采用的一种制式手枪。 12345678重量 0.85公斤（空枪）长度 24厘米子弹 8毫米法国军械弹口径 8毫米枪机 双动式枪口初速 220米/秒供弹方式 6发弹巢瞄具 机械瞄具 M1911手枪 M1911（45手枪）是一种在1911年起生产的.45 ACP口径半自动手枪，由约翰·勃朗宁设计。 123456789101112重量 空枪连弹匣：2.437磅（1,105克）[1]长度 8.25吋（210毫米）枪管长度政府型：5.03吋（127毫米）指挥官型：4.25吋（108毫米）军官ACP型：3.5吋（89毫米）子弹 .45 ACP枪机 枪管短行程后座作用、单动式板机枪口初速 251.46米/秒、〔825英尺/秒〕有效射程 50米供弹方式 7发（标准弹匣），膛室1发瞄具 机械瞄具：金属缺口式照门及准星 MAS 1873转轮手枪 MAS 1873（或称：Chamelot-Delvigne）是法国军队采用的第一种双动式转轮手枪，此枪不久便被更新的M1892转轮手枪所取代。 12345678910重量 1.04 kg长度 240 mm枪管长度 115 mm子弹 11毫米M1873口径 11 mm枪机 双动式射速 20 - 30发/分钟最大射程 50米供弹方式 6发弹巢瞄具 V型缺口及准星 冲锋枪 机枪 圣艾蒂安M1907中型机枪 圣艾蒂安M1907（法语：St. Étienne Mle 1907）是法国军队于第一次世界大战及第二次世界大战期间所装备的一种中型机枪。 1234567891011重量 26公斤长度 1,180毫米枪管长度 710毫米子弹 8×50毫米勒贝尔弹枪管 1根枪机 气动式射速 可调整：8 - 650发/分钟枪口初速 724米/秒供弹方式 25、30发金属弹链300发布制弹链（1916年）瞄具 机械瞄具 绍沙轻机枪 绍沙轻机枪，是在一战（1914年–1918年）时法国军队装备的制式轻机枪。官方名”Fusil Mitrailleur Modele 1915 CSRG”（机关步枪1915年型CSRG）。 12345678910111213重量 9.07千克（20.0英磅）长度 1,143毫米（45.0英寸）枪管长度 470毫米（19英寸）子弹 8×50毫米勒贝尔弹其他枪机 长行程后座作用、气动式、开放式枪机发射模式 半自动、全自动射速 约240发/分钟枪口初速 630米/秒有效射程 200米最大射程 2,000米供弹方式 20发弹匣瞄具 机械瞄具 刘易斯机枪 刘易斯机枪（Lewis Gun）由美国陆军上校艾萨克·牛顿·刘易斯发明，但美国陆军并未采用，而是在英国发扬光大。 12345678910111213重量 12公斤（空枪）长度 1,125 mm枪管长度 660 mm子弹 .303英式弹口径 7.7 mm枪机 气动式、开放式枪机发射模式 半自动、全自动射速 500 - 600发/分钟枪口初速 747米/秒有效射程 800 m最大射程 3,200 m供弹方式 47发、97发弹鼓瞄具 刀片式瞄具 霍奇克斯M1914重机枪 霍奇克斯M1914重机枪（法语：Hotchkiss Mle 1914）由美国人班杰明·霍奇克斯所开设的霍奇克斯公司研发。 123456789101112131415重量 24.4公斤46.8公斤（连三脚架）长度 1,390毫米枪管长度 800毫米子弹 8×50毫米勒贝尔子弹7×57毫米毛瑟子弹6.5×50毫米有坂子弹11毫米Gras子弹6.5×55毫米枪机 导气式射速 450发/分钟枪口初速 724米/秒供弹方式 24发保弹板250发铰接式弹链瞄具 机械瞄具 步枪 M1917RSC半自动步枪 M1917式RSC半自动步枪（法语：Fusil Automatique Modèle 1917，别名RSC M1917）是一种半自动气动式军用步枪，于第一次世界大战末期（1918年）装备法国军队。 123456789重量 5,25公斤（11,6磅）长度 1331毫米（52,4英寸）枪管长度 798毫米（31,4英寸）子弹 8×50mm勒贝尔弹枪机 长行程导气式活塞，滚转式枪机枪口初速 701米/秒有效射程 标尺最低射程250米，最大有效1200米供弹方式 5发内装漏夹供弹瞄具 铁质标尺，标尺直立射程2400米 Mle 1918 全自动卡宾枪 Mle 1918 利贝罗勒全自动卡宾枪（英语：Ribeyrolles 1918 automatic carbine ，法语：Carabine Mitrailleuse 1918）是法国的一款自动步枪，亦是世界首型应用突击步枪概念的枪械。 1234567891011重量 5.1公斤（空枪）长度 1090毫米枪管长度 450毫米子弹 8 × 35 毫米利贝罗勒弹口径 8 毫米枪机 直接反冲射速 550~600发/分钟枪口初速 570 米/秒有效射程 400 米供弹方式 25 发弹匣瞄具 机械瞄具 勒贝尔M1886步枪 勒贝尔M1886（法语：Fusil Lebel Modèle 1886）或勒贝尔步枪（法语：Fusil Lebel）是法国于1886年推出的栓式步枪，由尼古拉斯·勒贝尔上校研制。 123456789101112重量 4.41 kg（上弹）4.18 kg（空枪）长度 130 cm枪管长度 80 cm子弹 8×50毫米勒贝尔弹口径 8 mm枪机 旋转后拉式枪机枪口初速 610 - 700米/秒有效射程 400米最大射程 1,800米供弹方式 8发管状弹仓（若算上托弹板上和膛室内的额外两发子弹为10发）瞄具 机械瞄具 温彻斯特1907型半自动步枪 温彻斯特1907型是由美国枪械设计师托马斯·克罗斯利.约翰逊设计的一种半自动步枪，它在1906年到1958年期间由温彻斯特连发武器公司生产。 12345678重量 3.6 kg - 4.1 kg长度 1,000 mm枪管长度 510 mm子弹 .351 Winchester Self-Loading口径 .351枪机 后座作用供弹方式 5 发、10 发弹匣瞄具 机械瞄具 双管霰弹枪 双管霰弹枪（英语：Double-barreled shotgun，或称双管猎枪），是一种有两根枪管的猎枪，可分为水平排列或上下排列，可算是最早期的猎枪之一，前身为镇暴枪。 炮 皮托SA-18坦克炮 皮托SA-18坦克炮是法国在一战期间由设计的一种战车炮，主要装备于雷诺FT-17坦克上。 坦克 2C超级重战车 2C超重型坦克，又名Char 2C，是法国于一战时设计的超重型坦克。但是，它并没有参加一战。不过，这辆坦克是所有被正式量产的坦克中吨位第二大的，仅次于猎虎式驱逐战车。 123456789101112重量 69 t（68 long ton；76 short ton）长度 10.27米（33英尺8英寸）宽度 3米（9英尺10英寸）高度 4.09米（13英尺5英寸）操作人数 11人[注 1]装甲 45 mm（1.8英寸） max.主武器 75 mm 火炮副武器 4挺8 mm 机枪 (有一门在后炮塔上)发动机 双引擎 2 x 250 马力作战范围 150 km（93 mi）速度 15 km/h（9.3 mph） 施耐德CA1坦克 施耐德CA1坦克（法语：Char Schneider CA1）是法国研制的第一种坦克，研发的主要目的是破坏战场上的铁丝网。 123456789101112重量 13.6 吨长度 6.32 米宽度 2.05 米高度 2.30 米操作人数 6人装甲 5.5-11毫米钢板主武器 施耐德75mm迫击炮副武器 2门8mm霍奇基斯M1914机枪发动机 施耐德4缸55hp汽油引擎悬挂 弹簧作战范围 45 公里速度 8.1 公里／小时 雷诺FT-17坦克 雷诺FT-17，是一款法国轻型坦克。它于一战时由法国研发，是世界上第一款安装旋转炮塔的坦克。截至一战结束时，一共生产了3187辆。甚至在二战爆发时，还有1800辆FT-17坦克在法国军队中服役。 123456789101112131415重量 7吨长度 5米宽度 1.74米高度 2.14米操作人数 2（车长及驾驶员）装甲 6-22毫米主武器 皮托SA-18 37mmL/21战车炮或8mm哈奇开斯M1914机枪发动机 雷诺直立式4缸水冷汽油机35匹功率/重量 6马力/吨变速 机械式（4前进档，1倒车档）悬挂 垂直弹簧作战范围 35公里速度 7.7公里/时 飞机 纽波特战斗机 纽波特11战斗机是法国在第一次世界大战早期推出的双翼战斗机，因其机体细小而被称为“婴儿”，它是由纽波特飞机公司研制的，成立于1902年的纽波特飞机公司由1909年开始造飞机，该公司由纽波特兄弟创立但两兄弟后来都在飞行事故当中死去，公司由他人接手，而在推出纽波特11战斗机后该公司才在航空界打响名堂并开创了“纽波特皇朝”。 莫兰-索尼耶L单翼机** 莫兰-索尼耶L单翼机是法国莫兰-索尼耶飞机公司在1913年研制的单翼多用途飞机，该型机在当年12月的就在巴黎的航空展览上公开，在第一次世界大战爆发后就成为法国空军的侦察机，也是第一种在螺旋桨上加上钢铁制子弹偏导片而实现机枪安装在机头并开火，估计这样有大约1/4的子弹会被它挡住不伤到螺旋桨，其余3/4可穿过螺旋桨射击目标，此种做法是在同步射击系统出现前唯一的可行办法。莫兰-索尼耶L单翼机也因此被称为“历史上第一种战斗机”。 俄国 M1911手枪 毛瑟C96手枪 纳甘M1895转轮手枪 纳甘M1895（俄语：Револьвер системы Нагана，意为：纳甘系统转轮手枪）是由比利时工业家莱昂·纳甘为俄罗斯帝国所研发的7发双动式转轮手枪，发射7.62×38mmR弹药。 1234567891011重量 0.8 kg（空枪）长度 235 mm枪管长度 114 mm子弹 7.62×38mmR口径 7.62 mm枪机 单动式、双动式射速 14 - 21发/分钟枪口初速 272米/秒有效射程 22米供弹方式 7发转轮式弹巢瞄具 V型照门及准星 三八式步枪 三八式步枪（日语：三八式歩兵銃；さんぱちしきほへいじゅう，Sanpachi-shiki hohei-juu）为手动步枪，日本陆军于日俄战争同年（1905年，明治38年）正式采用为制式武器，一直到第二次世界大战。三八式步枪在中国一向俗称为三八大盖，由于其枪机上有一个随枪机连动的防尘盖以及机匣上刻有“三八式”字样而得名。 12345678910重量 3,730g（加上刺刀重4,100g）长度 127.6cm（上刺刀可达166.3cm）枪管长度 797毫米子弹 6.5×50mm有阪（Arisaka）口径 6.5毫米枪机 旋转后拉式枪机枪口初速 765米／秒有效射程 460米供弹方式 5发弹匣，内置弹仓瞄具 铁制直立式表尺 温彻斯特步枪 温彻斯特步枪（Winchester Rifle），有时亦称温彻斯特连发步枪（Winchester Repeating Rifle），是由美国温彻斯特连发武器公司研制及生产的一系列步枪。 123456789101112重量 4.3 kg长度 125.2 cm枪管长度 76.2 cm子弹 .44-40温彻斯特.38-40温彻斯特.32-20温彻斯特.30-30温彻斯特.22 LR其他枪机 杠杆式供弹方式 8（M1894）、10（M1866）、13（M1866）、15发内置管状弹仓瞄具 后方缺口及前准星 莫辛-纳甘步枪 莫辛-纳甘（法文：Mosin-Nagant）步枪是由设计者俄国陆军上校谢尔盖·伊凡诺维奇·莫辛和比利时枪械设计师李昂·纳甘共同命名的手动步枪，在俄语圈国家也被普遍的称为莫辛步枪 （俄文：Винтовка Мосина），官方名称为”三线M1891步枪”。 1234567891011121314重量 4.22公斤（空枪），各型号不同长度 1306毫米，各型号不同枪管长度 800毫米，各型号不同子弹 7.62×54毫米R枪弹口径 7.62毫米枪机 旋转后拉式枪机枪口初速 615米/秒（M1891）860米/秒（M1891/30）有效射程 548.64米（600码）最大射程 1828.8米（2000码）供弹方式 5发内置弹仓10发可拆式弹匣（现代化改版限定）瞄具 机械瞄具：后方可调式缺口表尺及前方柱状准星PU 3.5倍光学瞄准镜 费德洛夫M1916自动步枪 费德洛夫M1916 （俄语：Автомат Фёдорова）是一种战斗步枪，由弗拉基米尔·格里高利耶维奇·费德洛夫（Vladimir Grigoryevich Fyodorov）设计，1916年在沙俄境内生产。 1234567891011重量 4.4公斤 (全重：5.2公斤)长度 1,045毫米枪管长度 520 毫米子弹 6.5×50毫米有坂子弹口径 6.5毫米枪机 枪管短行程后座作用发射模式 半自动、全自动射速 600发/分钟[1]枪口初速 654米每秒（2,150英尺每秒）[1]供弹方式 25发可拆卸式弹匣瞄具 机械瞄具 绍沙轻机枪 麦德森轻机枪 刘易斯机枪 维克斯机枪 维克斯机枪（Vickers），是第一次世界大战与第二次世界大战期间英国军队所使用的中型机枪。基于维克斯机枪优异的设计，使它成为世界上著名的战争武器之一。 12345678910111213重量 15 kg长度 1,100 mm枪管长度 720 mm操作人数 3人子弹 .303英式弹口径 7.7毫米枪机 后坐式，水冷却射速 450 - 500发/分钟枪口初速 744米/秒有效射程 2,000米最大射程 4,100米供弹方式 250发布制弹链瞄具 机械瞄具 马克沁M1910重机枪 马克沁M1910重机枪（Пулемёт Максима на станке Соколова）又名PM M1910马克沁，是海勒姆·马克沁开发的马克沁机枪之衍生型，发射7.62×54毫米R弹药，配有轮式射架。 123456789重量 64.3公斤（139.6磅）长度 1067毫米枪管长度 721毫米子弹 7.62×54毫米R口径 7.62毫米枪机 后座作用射速 600发/分枪口初速 740米/秒（2,427.2尺/秒）供弹方式 250发布制弹链 英国 M1911手槍 毛瑟C96手槍 M1917左轮手枪 M1917左轮手枪（M1917 Revolver），官方正式名称为M1917 .45英寸美国左轮手枪（英语：United States Revolver, Caliber .45, M1917）是一把美国六发式左轮手枪，主要发射.45 ACP口径手枪子弹。 史密斯威森军警型左轮手枪 史密斯威森军警型（Smith &amp; Wesson Military &amp; Police，缩写：S&amp;W MP；简称：点三八），是一种.38口径的美国制左轮手枪。 韦伯利转轮手枪 韦伯利转轮手枪（英语：Webley Revolver）是由英国生产的一系列军用和警用转轮手枪。当中最著名的版本为韦伯利MK VI， 它在一次大战期间成为了英国军队以及其殖民地军队的制式手枪。 123456789101112重量 1.1公斤（空枪）长度 286毫米枪管长度 106毫米子弹 .455韦伯利.38/200口径 .455英寸（11.6×19毫米）、.38英寸枪机 单/双动式板机射速 20-30发/分钟枪口初速 190米/秒有效射程 50码供弹方式 6发弹巢瞄具 缺口式机械瞄具 三八步枪 温彻斯特步枪 恩菲尔德M1917步枪 恩菲尔德M1917步枪（M1917 Enfield，又名P17、P1917或Pattern 1917）是“美国恩菲尔德”（American Enfield）于1917至1918年间生产的.30-06口径手动步枪。 1234567重量 4.17 公斤（9磅3安士）长度 1175 毫米（3尺10.25寸）枪管长度 26 寸（660毫米）子弹 .30-06（7.62 x 63毫米）枪机 旋转后拉式枪机枪口初速 823 米/秒（2700尺/秒）供弹方式 5发弹夹、6发内置弹仓 李-恩菲尔德步枪 李-恩菲尔德步枪（Lee-Enfield）也译李恩飞步枪是1895年至1956年英军的制式手动步枪。 1234567891011121314重量 4.19公斤（MLE Mk.I）3.96公斤（SMLE No.1 Mk.III）长度 1257毫米（MLE Mk.I） 1138毫米（SMLE No.1 Mk.III） 1130毫米（No.4 Mk.I）枪管长度 767毫米（MLE Mk.I） 640毫米（SMLE No.1 Mk.III）子弹 .303 British（7.7×56mm R） 7.92×57毫米尖头弹(为适应中国战场所改膛的)枪机 旋转后拉式枪机枪口初速 744米／秒有效射程 914米（1000码）最大射程 1828米（2000码）供弹方式 10发内置弹仓（两个5发弹夹） 马提尼-亨利步枪 马提尼-亨利”（Martini-Henry）是一种英国陆军曾经装备的起落式枪机步枪。它于1871年首度投入服役，最终取代了原有的史奈德步枪，一款改良至发射定装弹的前装枪。马提尼-亨利的衍生型在大英帝国中一共服役了三十年。它采用了由亨利·O·皮博迪为其皮博迪步枪设计的起落式枪机，并由瑞士设计师里德里希·冯·马提尼进行改良，结合由苏格兰人亚历山大·亨利设计的多边形膛线。 123456789101112131415重量 3.827 kg（空枪）长度 1245 mm子弹 .577/450 Boxer-Henry .577/450马提尼-亨利 .303英式弹 11.43×55R（奥斯曼帝国） 11.43×59R（罗马尼亚） 7.65×53毫米（奥斯曼帝国）枪机 起落式枪机（Martini Falling Block）射速 12发/分钟枪口初速 400米/秒有效射程 370米最大射程 1,700米供弹方式 1发装在膛室内瞄具 可滑动式表尺及准星 维克斯机枪 刘易斯机枪 马克沁机枪 双管霰弹枪 勃朗宁M1917重机枪 M1917重机枪是由约翰·勃朗宁设计，美军在一战，二战及韩战中采用的重机枪，并有限延伸至越战，同时它也被其他国家使用。这是一种班组操作，弹链供弹的水冷重机枪，与同时期的M1919风冷中型机枪共同服役。该型机枪以营为单位配发同时也经常装备于各种载具之上。 123456789101112重量 47公斤长度 980毫米枪管长度 609毫米子弹 .30-06春田口径 7.62毫米枪机 短行程后座作用式射速 450发/分钟 600发/分钟（M1917A1）枪口初速 853.6米/秒最大射程 900米供弹方式 250发布制弹链瞄具 机械瞄具 Template:V及W級驱逐舰 步行者号驱逐舰 步行者号驱逐舰（舷号D27）是一艘英国皇家海军建造的驱逐舰，为W级驱逐舰的3号舰。她是英军第一艘以步行者（Walker）为名的军舰。 12345678标准排水量 设计：1,100吨全长 整体：300呎全宽 水线：26.75呎吃水 9呎最高速度 34节武器装备 4门4吋Mk V速射炮 2门单装2磅砰砰炮 2座3联装鱼雷发射管 范诺克号驱逐舰 范诺克号驱逐舰（舷号H33）是一艘英国皇家海军建造的驱逐舰，为V级驱逐舰的1号舰。她是英军第一艘以范诺克（Vanoc）为名的军舰，舰名取自圆桌骑士团的范诺克骑士。 12345678标准排水量 设计：1,272吨至1,339吨全长 整体：300呎全宽 水线：26呎9吋吃水 9呎最高速度 34节武器装备 4门4吋Mk V速射炮 2门单装2磅砰砰炮 2座双联装鱼雷发射管 Mark I 坦克 Mark I 坦克由英国研制并在第一次世界大战于英国军队服役，是世界上第一种正式参与战争的坦克。[1] Mark I 坦克在1916年8月开始服役，并于1916年9月15日首次应用在索姆河战役上。它的主要作用是破坏战场上的铁丝网、越过战壕、亦能抵御小型武器的射击。 123456789101112131415161718重量 雄性：28.4公吨（28.0长吨）雌性：27.4公吨（27.0长吨）长度 9.94米（32英尺7英寸）宽度 4.33米（14英尺2英寸）高度 2.44米（8英尺0英寸）操作人数 8人装甲 6-12 毫米主武器 雄性：2 × 霍奇基斯QF 6磅炮 雌性：4 × 维克斯机枪副武器 雄性：3 × 霍奇基斯轻机枪 雌性：1 × 霍奇基斯轻机枪发动机 戴姆勒-奈特6缸 13升 汽油引擎 105匹马力（78千瓦特）功率/重量 雄性：3.7匹马力每公吨（2.8千瓦每公吨） 雌性：4.0匹马力每公吨（3.0千瓦每公吨）悬挂 履带作战范围 23.6英里（38.0千米），巡航6.2小时速度 5.9千米每小时（3.7英里每小时） 美国 Mk 2手榴弹 Mk 2手榴弹（或写作Mk II）是一种反人员破片手榴弹，美军于1918年导入，用以取代Mk 1手榴弹，在二战、韩战至越战中所使用。由于外型相似凤梨又名凤梨手榴弹，因保险片的形状被称为“鸭嘴手榴弹”，因外观被称为“卵形手榴弹”、“凤梨手榴弹”或“癞瓜手榴弹”。 12345重量 595克长度 111毫米填充 TNT填充量 2安士引爆机制 4-5秒 M1911手枪 M1917左轮手枪 史密斯威森军警型左轮手枪 恩菲尔德M1917步枪 李-恩菲尔德步枪 温彻斯特步枪 温彻斯特1907型半自动步枪 莫辛-纳甘步枪 M1903春田步枪 M1903春田步枪是一种旋转后拉式枪机弹仓式手动步枪，1903年定型称为“0.30口径M1903式步枪”，因其由春田（Springfield）兵工厂研制而得名M1903春田步枪（Springfield rifle）。 1234567891011重量 3.95公斤长度 1,098毫米（44.9寸）枪管长度 610毫米（24寸）子弹 .30-03 .30-06（7.62×63毫米） 7.92×57毫米尖头弹(为适应中国与欧洲战场所改膛的)枪机 旋转后拉式枪机枪口初速 823 - 853米／秒有效射程 550米供弹方式 5发弹夹，内置弹仓瞄具 片状准星；带&quot;U&quot;形缺口折叠式框形表尺 温彻斯特M1897泵动式霰弹枪 温彻斯特M1897（英语：Winchester Model (M) 1897，俗称：Model 97或M97）是一枝由著名的美国枪械设计师约翰·勃朗宁设计、美国温彻斯特连发武器公司生产的泵动式及外置击锤型设计霰弹枪。 温彻斯特M1912泵动式霰弹枪 温彻斯特M1912（英语：Winchester Model（M） 1912，俗称：Model 12或M12）是一枝由美国温彻斯特连发武器公司生产的泵动式、内置式击锤设计及外部管式弹仓供弹的霰弹枪。此枪在推出后不久被流行地命名为完美的连发枪（英语：Perfect Repeater），基本奠定了此枪对泵动霰弹枪超过51年的高效率生产的生涯的标准。 勃朗宁Auto-5半自动霰彈槍 勃朗宁Auto-5（英语：Browning Automatic 5，简称：Auto-5、A-5，意为：勃朗宁自动五发式霰弹枪）是一枝由美国著名轻兵器设计家约翰·勃朗宁所研制、后座作用操作的半自动霰弹枪，可发射12铅径霰弹、16铅径霰弹或20铅径霰弹。 勃朗宁自动步枪 勃朗宁自动步枪（英语：Browning Automatic Rifle，简称：BAR），是美军在20世纪上半叶使用的一种自动步枪。 123456789101112131415重量 空枪重：7.2公斤（A1）空枪重：8.8公斤（A2）长度 1,214毫米（47.8寸）枪管长度 610毫米（24寸）子弹 .30-06 Springfield （7.62×63毫米） 7.92×57毫米尖头弹(为适应中国战场所改膛的)口径 7.62毫米（.30寸）枪机 长行程导气式活塞、开放式枪机发射模式 半自动、全自动射速 300-450发/分； 500-650发/分（A2）枪口初速 805米/秒有效射程 548米供弹方式 20发弹匣 刘易斯机枪 勃朗宁机枪 绍沙轻机枪 霍奇科斯重机枪 勃朗宁M1919中型机枪 勃朗宁M1919（M1919 Browning machine gun），俗称（Browning Machine Gun，30 Cal ），是由约翰·勃朗宁在一战后设计的机枪，主要是把水冷式M1917改为风冷式，采用.30-06 Springfield 步枪弹药。 12345678910111213重量 14公斤长度 964毫米（37.94英寸）操作人数 2至3名子弹 .30-06 Springfield（U.S.） 7.62×51mm NATO（U.S.） .303 British口径 7.62毫米/7.7毫米枪机 后坐作用射速 400–600发／分枪口初速 853米／秒有效射程 1,400米供弹方式 M9弹链供弹瞄具 可调机械照门 D级潜艇 D级潜艇是美国海军一战中建造的潜艇级，子合约由格罗昆的电船公司签订，由昆西的佛尔河船厂建造。 123456789101112131415舰型 Submarine排水量 288 long ton（293 t） surfaced 337 long ton（342 t） submerged全长 134英尺10英寸（41.10米）全宽 13英尺11英寸（4.24米）吃水 11英尺8英寸（3.56米）动力来源 2 x NELSECO gasoline engines, 600 hp（450 kW） total[1] 2 x electric motors, 260 hp（190 kW） total 2 x 60-cell batteries 2 shafts速度 12节（22千米每小时；14英里每小时） surfaced, 9.5节（17.6千米每小时；10.9英里每小时） submerged续航距离 1,240海里（2,300千米；1,430英里） (surfaced)潜航深度 200英尺（61米）乘员 15 officers and men武器装备 4 × 18 inch (457 mm) bow torpedo tubes, (4 torpedoes)[3] 美国一战驱逐舰 维基百科： https://zh.wikipedia.org/wiki/Category:%E7%BE%8E%E5%9B%BD%E4%B8%80%E6%88%98%E9%A9%B1%E9%80%90%E8%88%B0 驱逐舰（英语：destroyer）是一种多用途的军舰。驱逐舰的用途是保护舰队，驱逐和消灭鱼雷艇和潜艇等以鱼雷为主要武器的舰只，为舰队提供保护。 化学武器 三氯硝基甲烷 三氯硝基甲烷，俗称氯化苦（英语：Chloropicrin），是一种化学式为Cl3CNO2的有机氯化合物。这种高毒性的物质曾被用作代号为PS的化学武器；现在则主要用作熏蒸剂和杀线虫剂。 二氯甲基胂 二氯甲基胂，亦可简写为MD，是一种有机化合物，化学式为CH3AsCl2。它是一种无色、易挥发的液体，具有很强的毒性，是一种糜烂性毒剂，可作为化学武器使用。 氯丙酮 氯丙酮，结构式ClCH2COCH3。无色有极强刺激性臭味液体，对生物体有强刺激性，在日光下分解产生强催泪性气体。见光变为暗黄的琥珀色。 溴乙酸乙酯 溴乙酸乙酯是一种有机化合物，化学式为CH2BrCO2C2H5。它可由乙酸为原料合成。它是一种催泪剂，具有果味和刺激性气味。它是毒性很高的烷基化试剂。吸入、吞咽或与皮肤接触可能致命。 绿十字毒气 绿十字毒气（德语：Grünkreuz)是在第一次世界大战时使用的化学武器，属于窒息性毒剂，是由三氯硝基甲烷，光气或/和双光气的混合物。 芥子毒气 芥子毒气（英语：mustard gas），亦简称为芥子气，学名二氯二乙硫醚，是一种重要的糜烂性毒剂，因味道与芥末相似而得名。 二战第二次世界大战（又简称二次大战、二战、WWII等；英语：World War II；法语：Seconde Guerre mondiale；德语：Zweiter Weltkrieg；俄语：Вторая мировая война；日语：第二次世界大戰）是一次自1939年至1945年所爆发的全球军事冲突，整场战争涉及到全球绝大多数的国家，包括所有的大国，并最终分成两个彼此对立的军事同盟─同盟国和轴心国。这次战争是人类史上最大的战争，动员了1亿多名军人参与这次军事冲突。主要的参战国纷纷宣布进入总体战状态，几乎将自身国家的全部经济、工业和科学技术用于战争之上，同时将民用和军用的资源合并以便规划。包括有犹太人大屠杀、南京大屠杀、战争中日军对中国军民进行细菌战、以及最终美国对日本首次使用原子弹等事件，使第二次世界大战也是有纪录以来最多大规模民众死亡的军事冲突，全部将近有5,000万至7,000万人因而死亡，这让第二次世界大战成了人类历史上死伤人数最多的战争[2]。第二次世界大战改变了世界局势，英国、法国等欧洲殖民帝国衰落，美国和苏联取代了欧洲殖民帝国的地位成了新的超级大国并在战后形成了两极格局直到1991年。]]></content>
      <categories>
        <category>Weapon</category>
      </categories>
      <tags>
        <tag>武器</tag>
        <tag>战争</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[国际音标]]></title>
    <url>%2F2018%2F11%2F13%2F%E5%9B%BD%E9%99%85%E9%9F%B3%E6%A0%87%2F</url>
    <content type="text"><![CDATA[参考： 国际音标维基 巴士英语网: https://en-yinbiao.xiao84.com/yinbiaofayin/ 知乎@姜枣茶茶母的回答: https://www.zhihu.com/question/19913374 介绍英语发音有多个国家的区别，我们重点了解两个： 公认发音，英国标准（Received pronunciation, RP） 通用美式英语（General American, GA） 国际音标(International Phonetic Alphabet，缩写：IPA)旁边的分隔号和括号并非音标的一部分，它们是语言专家用以分辨两个主要标音方法：音位标音和语音学标音。 48个国际音标通常是国内学生学习英语、学好英语发音必须掌握的发音基础，48个国际音标表也被称作48个音标表、48个英语音标表、48个英语国际英标表，48个国际英语音标表，这些称呼通常都是指48个英语国际英标表。48个国际音标中有20个元音、28个辅音。 元音，又称母音。 元音是在发音过程中由气流通过口腔而不受阻碍发出的音。按前后分类为高 、中、低元音。按音节分，可分为单元音和双元音。 气流在口腔或咽头受到阻碍而形成的音叫做辅音，辅音又叫子音。 共分为清辅音、浊辅音、鼻音、舌侧音 、半元音五种不同类型。其中鼻音、舌侧音 、半元音为浊辅音。 英语元音和辅音在英语发音中扮演着重要的角色，英语元音和辅音组合起来就成为英语音标，共48个音位，是英语发音的基础。 发音与技巧巴士英语网有每个音标的发音: https://en-yinbiao.xiao84.com/yinbiaofayin/ 国际音标： 1 2 3 4 元音 单元音 双元音 前元音 中元音 后元音 开合双元音 集中双元音 /iː/, /ɪ/, /e/, /æ/ /ɜː/, /ə/, /ʌ/ /uː/, /ʊ/, /ɔː/, /ɒ/, /ɑː/ /eɪ/, /aɪ/, /ɔɪ/, /aʊ/, /əʊ/ /ɪə/, /eə/, /ʊə/ 辅音 爆破音 摩擦音 破擦音 鼻音 舌则音 半元音 清辅音 浊辅音 清辅音 浊辅音 清辅音 浊辅音 浊辅音 浊辅音 浊辅音 /p/, /t/, /k/ /b/, /d/, /ɡ/ /f/, /s/, /ʃ/, /θ/, /h/ /v/, /z/, /ʒ/, /ð/, /r/ /tʃ/, /tr/, /ts/ /dʒ/, /dr/, /dz/ /m/, /n/, /ŋ/ /l/ /j/, /w/ 1 2 3 元音20个 长元音 短元音 双元音 /iː/, /ɑː/, /ɔː/, /uː/, /ɜː/ /ɪ/, /ʌ/, /ɒ/, /ʊ/, /ə/, /æ/, /e/ /eɪ/, /aɪ/, /ɔɪ/, /ɪə/, /eə/, /ʊə/, /aʊ/, /əʊ/ 辅音28个 轻辅音 浊辅音 轻辅音 浊辅音 鼻音 半元音 边音 /p/, /t/, /k/, /f/, /θ/, /s/ /b/, /d/, /ɡ/, /v/, /ð/, /z/ /ʃ/, /h/, /ts/, /tʃ/, /tr/ /ʒ/, /r/, /dz/, /dʒ/, /dr/ /m/, /n/, /ŋ/ /j/, /w/ /l/ 知识点讲解长短元音的区别在于——是否有: 有，则拖长音节 无，则短促音结尾 双元音就是把两个单元音拼到一起 发音也是两个拼到一起的，如： 12345/iə/= /i/ + /ə//uə/= /u/ + /ə//εə/= /e/ + /ə/ 清浊辅音的区别在于——喉结是否震动 震动，浊辅音 不震动，清辅音 鼻音–鼻腔发出 难读的音标易出问题的地方： 核心技巧： 用中文的音近字代替 用简单的英文字母或单词进行备注 中文字很挫，两种方法结合使用，哪个好记用哪个。 元音部分发音讲解： 12345678/ei/ ：A/ai/ ：I/ɔi/ ：“噢一”/iə/ : /i/ + /ə/ = ear/eə/ : /e/ + /ə/ = air/uə/ : /u/ + /ə/ = 污饿/əu/ ：O/au/ ：嗷（张大嘴） 辅音部分发音讲解： 第一组：/s/, /z/ 和 /θ/, /ð/这两组发音听起来差不多，唯一的区别在于：舌头是否看得见 看不见，/s/, /z/ 看得见，/θ/, /ð/ 第二组：/ʃ/, /ʒ/ “屎” “日” 第三组：/h/, /r/ “喝” “弱” 第四组：/ts/, /dz/ “此” “滋” 第五组：/tʃ/, /dʒ/ “尺” “之” 第六组：/tr/, /dr/ “戳” “捉” 第七组：/m/, /n/, /ŋ/ 都是发“嗯”的音，只是嘴型大小不一样。 /m/, 闭紧 /n/, 半张开 /ŋ/, 张大嘴 第八组：/l/这个音最难发，因为声音有点奇怪，像大舌头。发音技巧在于，把舌尖抵在上门牙底端，然后自然发出声音，就是这个音标啦。 知识点讲解 /m/, /n/, /l/ 分别有两个发音，一个是上面讲解的发音，另一个是他们的本来音，即英文字母m/n/l的发音（么，讷，勒）。 本身发音： 出现在每个音节的开头 奇怪音： 出现在每个音节的中间 练习自己找单词书进行测试和练习。]]></content>
      <categories>
        <category>English</category>
      </categories>
      <tags>
        <tag>English</tag>
        <tag>国际音标</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[劳动法]]></title>
    <url>%2F2018%2F10%2F26%2F%E5%8A%B3%E5%8A%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[参考： 中华人民共和国劳动法（2009年修正本） 《中华人民共和国劳动法》是为了保护劳动者的合法权益，调整劳动关系，建立和维护适应社会主义市场经济的劳动制度，促进经济发展和社会进步，根据宪法，制定本法。1994年7月5日第八届全国人民代表大会常务委员会第八次会议通过，自1995年1月1日起施行。 （1994年7年5日第八届全国人民代表大会常务委员会第八次会议通过 1994年7月5日中华人民共和国主席令第28号公布 根据2009年8月27日中华人民共和国主席令第18号《全国人民代表大会常务委员会关于修改部分法律的决定》修正 自公布之日起施行） 总则第一条： 为了保护劳动者的合法权益，调整劳动关系，建立和维护适应社会主义市场经济的劳动制度，促进经济发展和社会进步，根据宪法，制定本法。 第二条： 在中华人民共和国境内的企业、个体经济组织（以下统称用人单位）和与之形成劳动关系的劳动者，适用本法。 国家机关、事业组织、社会团体和与之建立劳动合同关系的劳动者，依照本法执行。 第三条: 劳动者享有平等就业和选择职业的权利、取得劳动报酬的权利、休息休假的权利、获得劳动安全卫生保护的权利、接受职业技能培训的权利、享受社会保险和福利的权利、提请劳动争议处理的权利以及法律规定的其他劳动权利。 劳动者应当完成劳动任务，提高职业技能，执行劳动安全卫生规程，遵守劳动纪律和职业道德。 第四条: 用人单位应当依法建立和完善规章制度，保障劳动者享有劳动权利和履行劳动义务。 第五条: 国家采取各种措施，促进劳动就业，发展职业教育，制定劳动标准，调节社会收人，完善社会保险，协调劳动关系，逐步提高劳动者的生活水平。 第六条: 国家提倡劳动者参加社会义务劳动，开展劳动竞赛和合理化建议活动，鼓励和保护劳动者进行科学研究、技术革新和发明创造，表彰和奖励劳动模范和先进工作者。 第七条: 劳动者有权依法参加和组织工会。 工会代表和维护劳动者的合法权益，依法独立自主地开展活动。 第八条: 劳动者依照法律规定，通过职工大会、职工代表大会或者其他形式，参与民主管理或者就保护劳动者合法权益与用人单位进行平等协商。 第九条: 国务院劳动行政部门主管全国劳动工作。 县级以上地方人民政府劳动行政部门主管本行政区域内的劳动工作。 促进就业第十条: 国家通过促进经济和社会发展，创造就业条件，扩大就业机会。 国家鼓励企业、事业组织、社会团体在法律、行政法规规定的范围内兴办产业或者拓展经营，增加就业。国家支持劳动者自愿组织起来就业和从事个体经营实现就业。 第十一条: 地方各级人民政府应当采取措施，发展多种类型的职业介绍机构，提供就业服务。 第十二条: 劳动者就业，不因民族、种族、性别、宗教信仰不同而受歧视。 第十三条: 妇女享有与男子平等的就业权利，在录用职工时，除国家规定的不适合妇女的工种或者岗位外，不得以性别为由拒绝录用妇女或者提高对妇女的录用标准。 第十四条: 残疾人、少数民族人员、退出现役的军人的就业，法律、法规有特别规定的，从其规定。 第十五条: 禁止用人单位招用未满十六周岁的未成年人。 文艺、体育和特种工艺单位招用未满十六周岁的未成年人，必须依照国家有关规定，履行审批手续，并保障其接受义务教育的权利。 劳动合同和集体合同第十六条: 劳动合同是劳动者与用人单位确立劳动关系、明确双方权利和义务的协议。 建立劳动关系应当订立劳动合同。 第十七条: 订立和变更劳动合同，应当遵循平等自愿、协商一致的原则，不得违反法律、行政法规的规定。 劳动合同依法订立即具有法律约束力，当事人必须履行劳动合同规定的义务。 第十八条: 下列劳动合同无效：（一）违反法律、行政法规的劳动合同；（二）采取欺诈、威胁等手段订立的劳动合同。 无效的劳动合同，从订立的时候起，就没有法律约束力。确认劳动合同部分无效的，如果不影响其余部分的效力，其余部分仍然有效。劳动合同的无效，由劳动争仪仲裁委员会或者人民法院确认。 第十九条: 劳动合同应当以书面形式订立，并具备以下条款：（一）劳动合同期限；（二）工作内容；（三）劳动保护和劳动条件；（四）劳动报酬；（五）劳动纪律；（六）劳动合同终止的条件；（七）违反劳动合同的责任。 劳动合同除前款规定的必备条款外，当事人可以协商约定其他内容。 第二十条: 劳动合同的期限分为有固定期限、无固定期限和以完成一定的工作为期限。 劳动者在同一用人单位连续工作满十年以上，当事人双方同意续延劳动合同的，如果劳动者提出订立无固定期限的劳动合同，应当订立无固定期限的劳动合同。 第二十一条: 劳动合同可以约定试用期。试用期最长不得超过六个月。 第二十二条: 劳动合同当事人可以在劳动合同中约定保守用人单位商业秘密的有关事项。 第二十三条: 劳动合同期满或者当事人约定的劳动合同终止条件出现，劳动合同即行终止。 第二十四条: 经劳动合同当事人协商一致，劳动合同可以解除。 第二十五条: 劳动者有下列情形之一的，用人单位可以解除劳动合同：（一）试用期间被证明不符合录用条件的；（二）严重违反劳动纪律或者用人单位规章制度的；（三）严重失职，营私舞弊，对用人单位利益造成重大损害的；（四）被依法追究刑事责任的。 第二十六条： 有下列情形之一的，用人单位可以解除劳动合同，但是应当提前三十日以书面形式通知劳动者本人：（一）劳动者患病或者非因工负伤，医疗期满后，不能从事原工作也不能从事由用人单位另行安排的工作的；（二）劳动者不能胜任工作，经过培训或者调整工作岗位，仍不能胜任工作的。（三）劳动合同订立时所依据的客观情况发生重大变化，致使原劳动合同无法履行，经当事人协商不能就变更劳动合同达成协议的。 第二十七条: 用人单位濒临破产进行法定整顿期间或者生产经营状况发生严重困难，确需裁减人员的，应当提前三十日向工会或者全体职工说明情况，听取工会或者职工的意见，经向劳动行政部门报告后，可以裁减人员。 用人单位依据本条规定裁减人员，在六个月内录用人员的，应当优先录用被裁减的人员。 第二十八条: 用人单位依据本法第二十四条、第二十六条、第二十七条的规定解除劳动合同的，应当依照国家有关规定给予经济补偿。 第二十九条: 劳动者有下列情形之一的，用人单位不得依据本法第二十六条、第二十七条的规定解除劳动合同：（一）患职业病或者因工负伤并被确认丧失或者部分丧失劳动能力的；（二）患病或者负伤，在规定的医疗期内的；（三）女职工在孕期、产期、哺乳期内的；（四）法律、行政法规规定的其他情形。 第三十条: 用人单位解除劳动合同，工会认为不适当的，有权提出意见。如果用人单位违反法律、法规或者劳动合同，工会有权要求重新处理；劳动者申请仲裁或者提起诉讼的，工会应当依法给予支持和帮助。 第三十一条: 劳动者解除劳动合同，应当提前三十日以书面形式通知用人单位。 第三十二条: 有下列情形之一的，劳动者可以随时通知用人单位解除劳动合同：（一）在试用期内的；（二）用人单位以暴力、威胁或者非法限制人身自由的手段强迫劳动的；（三）用人单位未按照劳动合同约定支付劳动报酬或者提供劳动条件的。 第三十三条: 企业职工一方与企业可以就劳动报酬、工作时间、休息休假、劳动安全卫生、保险福利等事项，签订集体合同。集体合同草案应当提交职工代表大会或者全体职工讨论通过。 集体合同由工会代表职工与企业签订；没有建立工会的企业，由职工推举的代表与企业签订。 第三十四条: 集体合同签订后应当报送劳动行政部门；劳动行政部门自收到集体合同文本之日起十五日内未提出异议的，集体合同即行生效。 第三十五条: 依法签订的集体合同对企业和企业全体职工具有约束力，职工个人与企业订立的劳动合同中劳动条件和劳动报酬等标准不得低于集体合同的规定。 工资第三十六条: 国家实行劳动者每日工作时间不超过八小时、平均每周工作时间不超过四十四小时的工时制度。 第三十七条: 对实行计件工作的劳动者，用人单位应当根据本法第三十六条规定的工时制度合理确定其劳动定额和计件报酬标准。 第三十八条: 用人单位应当保证劳动者每周至少休息一日。 第三十九条: 企业因生产特点不能实行本法第三十六条、第三十八条规定的，经劳动部门批准，可以实行其他工作和休息办法。 第四十条: 用人单位在下列节日期间应当依法安排劳动者休假：（一）元旦；（二）春节；（三）国际劳动节；（四）国庆节；（五）法律、法规规定的其他休假节日。 第四十一条: 用人单位由于生产经营需要，经与工会和劳动者协商后可以延长工作时间，一般每日不得超过一小时；因特殊原因需要延长工作时间的，在保障劳动者身体健康的条件下延长工作时间每日不得超过三小时，但是每月不得超过三十六小时。 第四十二条: 有下列情形之一的，延长工作时间不受本法第四十一条规定的限制：（一）发生自然灾害、事故或者因其他原因，威胁劳动者生命健康和财产安全，需要紧急处理的；（二）生产设备、交通运输线路、公共设施发生故障，影响生产和公众利益，必须及时抢修的；（三）法律、行政法规规定的其他情形。 第四十三条: 用人单位不得违反本法规定延长劳动者的工作时间。 第四十四条: 有下列情形之一的，用人单位应当按照下列标准支付高于劳动者正常工作时间工资的工资报酬；（一）安排劳动者延长工作时间的，支付不低于工资的百分之一百五十的工资报酬；（二）休息日安排劳动者工作又不能安排补休的，支付不低于工资的百分之二百的工资报酬；（三）法定休假日安排劳动者工作的，支付不低于工资的百分之三百的工资报酬。 第四十五条: 国家实行带薪年休假制度。 劳动者连续工作一年以上的，享受带薪年休假。具体办法由国务院规定。 第四十六条: 工资分配应当遵循按劳分配原则，实行同工同酬。 工资水平在经济发展的基础上逐步提高。国家对工资总量实行宏观调控。 第四十七条: 用人单位根据本单位的生产经营特点和经济效益，依法自主确定本单位的工资分配方式和工资水平。 第四十八条: 国家实行最低工资保障制度。最低工资的具体标准由各省、自治区直辖市人民政府规定，报国务院备案。 用人单位支付劳动者的工资不得低于当地最低工资标准。 第四十九条: 确定和调整最低工资标准应当综合参考下列因素：（一）劳动者本人及平均赡养人口的最低生活费用；（二）社会平均工资水平；（三）劳动生产率；（四）就业状况；（五）地区之间经济发展水平的差异。 第五十条: 工资应当以货币形式按月支付给劳动者本人。不得克扣或者无故拖欠劳动者的工资。 第五十一条: 劳动者在法定休假日和婚丧假期间以及依法参加社会活动期间，用人单位应当依法支付工资。 劳动安全卫生第五十二条: 用人单位必须建立、健全劳动安全卫生制度，严格执行国家劳动安全卫生规程和标准，对劳动者进行劳动安全卫生教育，防止劳动过程中的事故，减少职业危害。 第五十三条: 劳动安全卫生设施必须符合国家规定的标准。 新建、改建、扩建工程的劳动安全卫生设施必须与主体工程同时设计、同时施工、同时投入生产和使用。 第五十四条: 用人单位必须为劳动者提供符合国家规定的劳动安全卫生条件和必要的劳动防护用品，对从事有职业危害作业的劳动者应当定期进行健康检查。 第五十五条: 从事特种作业的劳动者必须经过专门培训并取得特种作业资格。 第五十六条: 劳动者在劳动过程中必须严格遵守安全操作规程。 劳动者对用人单位管理人员违章指挥、强令冒险作业，有权拒绝执行；对危害生命安全和身体健康的行为，有权提出批评、检举和控告。 第五十七条: 国家建立伤亡事故和职业病统计报告和处理制度。县级以上各级人民政府劳动行政部门、有关部门和用人单位应当依法对劳动者在劳动过程中发生的伤亡事故和劳动者 的职业病状况，进行统计、报告和处理。 女职工和未成年工特殊保护第五十八条: 国家对女职工和未成年工实行特殊劳动保护。 未成年工是指年满十六周岁未满十八周岁的劳动者。 第五十九条: 禁止安排女职工从事矿山井下、国家规定的第四级体力劳动强度的劳动和其他禁忌从事的劳动。 第六十条: 不得安排女职工在经期从事高处、低温、冷水作业和国家规定的第三级体力劳动强度的劳动。 第六十一条: 不得安排女职工在怀孕期间从事国家规定的第三级体力劳动强度的劳动和孕期禁忌从事的劳动，对怀孕七个月以上的女职工，不得安排其延长工作时间和夜班劳动。 第六十二条: 女职工生育享受不少于九十天的产假。 第六十三条: 不得安排女职工在哺乳未满一周岁的婴儿期间从事国家规定的第三级体力劳动强度的劳动和哺乳期禁忌从事的其他劳动，不得安排其延长工作时间和夜班劳动。 第六十四条: 不得安排未成年工从事矿山井下、有毒有害、国家规定的第四级体力劳动强度的劳动和其他禁忌从事的劳动。 第六十五条: 用人单位应当对未成年工定期进行健康检查。 职业培训第六十六条: 国家通过各种途径，采取各种措施，发展职业培训事业，开发劳动者的职业技能，提高劳动者素质，增强劳动者的就业能力和工作能力。 第六十七条: 各级人民政府应当把发展职业培训纳入社会经济发展的规划，鼓励和支持有条件的企业、事业组织、社会团体和个人进行各种形式的职业培训。 第六十八条: 用人单位应建立职业培训制度，按照国家规定提取和使用职业培训经费，根据本单位实际，有计划地对劳动者进行职业培训。 从事技术工种的劳动者，上岗前必须经过培训。 第六十九条: 国家确定职业分类，对规定的职业制定职业技能标准，实行职业资格证书制度，由经过政府批准的考核鉴定机构负责对劳动者实施职业技能考核鉴定。 社会保险和福利第七十条: 国家发展社会保险事业，建立社会保险制度，设立社会保险基金，使劳动者在年老、患病、工伤、失业、生育等情况下获得帮助和补偿。 第七十一条: 社会保险水平应当与社会经济发展水平和社会承受能力相适应。 第七十二条: 社会保险基金按照保险类型确定资金来源，逐步实行社会统筹。用人单位和劳动者必须依法参加社会保险，缴纳社会保险费。 第七十三条: 劳动者在下列情形下，依法享受社会保险待遇：（一）退休；（二）患病、负伤；（三）因工伤残或者患职业病；（四）失业；（五）生育。 劳动者死亡后，其遗属依法享受遗属津贴。劳动者享受社会保险待遇的条件和标准由法律、法规规定。劳动者享受的社会保险金必须按时足额支付。 第七十四条: 社会保险基金经办机构依照法律规定收支、管理和运营社会保险基金，并负有使社会保险基金保值增值的责任。 社会保险基金监督机构依照法律规定、对社会保险基金的收支、管理和运营实施监督。社会保险基金经办机构和社会保险基金监督机构的设立和职能由法律规定。任何组织和个人不得挪用社会保险基金。 第七十五条: 国家鼓励用人单位根据本单位实际情况为劳动者建立补充保险。 国家提倡劳动者个人进行储蓄性保险。 第七十六条: 国家发展社会福利事业，兴建公共福利设施、为劳动者休息、休养和疗养提供条件。 用人单位应当创造条件，改善集体福利，提高劳动者的福利待遇。 劳动争议第七十七条: 用人单位与劳动者发生劳动争议，当事人可以依法申请调解、仲裁、提起诉讼，也可以协商解决。 调解原则适用于仲裁和诉讼程序。 第七十八条: 解决劳动争议、应当根据合法、公正、及时处理的原则，依法维护劳动争议当事人的合法权益。 第七十九条: 劳动争议发生后，当事人可以向本单位劳动争议调解委员会申请调解；调解不成，当事人一方要求仲裁的，可以向劳动争议仲裁委员会申请仲裁。当事人一方也可以直接向劳动争议仲裁委员会申请仲裁。对仲裁裁决不服的，可以向人民法院提起诉讼。 第八十条: 在用人单位内，可以设立劳动争议调解委员会。劳动争议调解委员会由职工代表、用人单位代表和工会代表组成。劳动争议调解委员会主任由工会代表担任。 劳动争议经调解达成协议的，当事人应当履行。 第八十一条: 劳动争议仲裁委员会由劳动行政部门代表、同级工会代表、用人单位方面的代表组成，劳动争议仲裁委员会主任由劳动行政部门代表担任。 第八十二条: 提出仲裁要求的一方应当自劳动争议发生之日起六十日内向劳动争议仲裁委员会提出书面申请。仲裁裁决一般应在收到仲裁申请的六十日内作出。对仲裁裁决无异议的，当事人必须履行。 第八十三条: 劳动争议当事人对仲裁裁决不服的，可以自收到仲裁裁决书之日起十五日内向人民法院提起诉讼。一方当事人在法定期限内不起诉又不履行仲裁裁决的，另一方当事人可以申请人民法院强制执行。 第八十四条: 因签订集体合同发生争议，当事人协商解决不成的，当地人民政府劳动行政部门可以组织有关各方协调处理。 因履行集体合同发生争议，当事人协商解决不成的，可以向劳动争议仲裁委员会申请仲裁；对仲裁裁决不服的，可以自收到仲裁裁决书之日起十五日内向人民法院提起诉讼。 监督检查第八十五条: 县级以上各级人民政府劳动行政部门依法对用人单位遵守劳动法律、法规的情况进行监督检查，对违反劳动法律、法规的行为有权制止，并责令改正。 第八十六条: 县级以上各级人民政府劳动行政部门监督检查人员执行公务，有权进入用人单位了解执行劳动法律、法规的情况，查阅必要的资料，并对劳动场所进行检查。 县级以上各级人民政府劳动行政部门监督检查人员执行公务，必须出示证件，秉公执法并遵守有关规定。 第八十七条: 县级以上各级人民政府有关部门在各自职责范围内，对用人单位遵守劳动法律、法规的情况进行监督。 第八十八条: 各级工会依法维护劳动者的合法权益，对用人单位遵守劳动法律、法规的情况进行监督。 任何组织和个人对于违反劳动法律、法规的行为有权检举和控告。 法律责任第八十九条: 用人单位制定的劳动规章制度违反法律、法规规定的，由劳动行政部门给予警告，责令改正；对劳动者造成损害的，应当承担赔偿责任。 第九十条: 用人单位违反本法规定，延长劳动者工作时间的，由劳动行政部门给予警告，责令改正，并可以处以罚款。 第九十一条: 用人单位有下列侵害劳动者合法权益情形之一的，由劳动行政部门责令支付劳动者的工资报酬、经济补偿，并可以责令支付赔偿金：（一）克扣或者无故拖欠劳动者工资的；（二）拒不支付劳动者延长工作时间工资报酬的；（三）低于当地最低工资标准支付劳动者工资的；（四）解除劳动合同后，未依照本法规定给予劳动者经济补偿的。 第九十二条: 用人单位的劳动安全设施和劳动卫生条件不符合国家规定或者未向劳动者提供必要的劳动防护用品和劳动保护设施的，由劳动行政部门或者有关部门责令改正，可以处以罚款；情节严重的，提请县级以上人民政府决定责令停产整顿；对事故隐患不采取措施，致使发生重大事故，造成劳动者生命和财产损失的，对责任人员比照刑法第一百八十七条的规定追究刑事责任。 第九十三条: 用人单位强令劳动者违章冒险作业、发生重大伤亡事故，造成严重后果的，对责任人员依法追究刑事责任。 第九十四条: 用人单位非法招用未满十六周岁的未成年人的，由劳动行政部门责令改正，处以罚款；情节严重的，由工商行政管理部门吊销营业执照。 第九十五条: 用人单位违反本法对女职工和未成年工的保护规定，侵害其合法权益的，由劳动行政部门责令改正，处以罚款；对女职工或者未成年工造成损害的，应当承担赔偿责任。 第九十六条: 用人单位有下列行为之一，由公安机关对责任人员处以十五日以下拘留、罚款或者警告；构成犯罪的，对责任人员依法追究刑事责任： （一）以暴力、威胁或者非法限制人身自由的手段强迫劳动的。（二）侮辱、体罚、殴打、非法搜查和拘禁劳动者的。 第九十七条: 由于用人单位的原因订立的无效合同，对劳动者造成损害的，应当承担赔偿责任。 第九十八条: 用人单位违反本法规定的条件解除劳动合同或者故意拖延不订立劳动合同的，由劳动行政部门责令改正；对劳动者造成损害的，应当承担赔偿责任。 第九十九条: 用人单位招用尚未解除劳动合同的劳动者，对原用人单位造成经济损失的，该用人单位应当依法承担连带赔偿责任。 第一百条: 用人单位无故不缴纳社会保险费的，由劳动行政部门责令其限期缴纳，逾期不缴的，可以加收滞纳金。 第一百零一条: 用人单位无理阻挠劳动行政部门、有关部门及其工作人员行使监督检查权，打击报复举报人员的，由劳动行政部门或者有关部门处以罚款；构成犯罪的，对责任人员依法追究刑事责任。 第一百零二条: 劳动者违反本法规定的条件解除劳动合同或者违反劳动合同中约定的保密事项，对用人单位造成经济损失的，应当依法承担赔偿责任。 第一百零三条: 劳动行政部门或者有关部门的工作人员滥用职权、玩忽职守、徇私舞弊、构成犯罪的，依法追究刑事责任；不构成犯罪的，给予行政处分。 第一百零四条:国家工作人员和社会保险基金经办机构的工作人员挪用社会保险基金，构成犯罪的，依法追究刑事责任。 第一百零五条: 违反本法规定侵害劳动者合法权益，其他法律、行政法规已规定处罚的，依照该法律、行政法规的规定处罚。 附则第一百零六条: 省、自治区、直辖市人民政府根据本法和本地区的实际情况，规定劳动合同制度的实施步骤，报国务院备案。 第一百零七条: 本法自1995年1月1日起施行。]]></content>
      <categories>
        <category>法律</category>
      </categories>
      <tags>
        <tag>劳动法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[劳动合同法]]></title>
    <url>%2F2018%2F10%2F26%2F%E5%8A%B3%E5%8A%A8%E5%90%88%E5%90%8C%E6%B3%95%2F</url>
    <content type="text"><![CDATA[参考： 全国人民代表大会常务委员会关于修改《中华人民共和国劳动合同法》的决定（附2012年修正本） 网址： 中华人民共和国中央人民政府： http://www.gov.cn/ 中国政府法制信息网： http://www.chinalaw.gov.cn 百度百科 《中华人民共和国劳动合同法》是为了完善劳动合同制度，明确劳动合同双方当事人的权利和义务，保护劳动者的合法权益，构建和发展和谐稳定的劳动关系，制定本法。由第十届全国人民代表大会常务委员会第二十八次会议于2007年6月29日修订通过，自2008年1月1日起施行。（2012年12月28日第十一届全国人民代表大会常务委员会第三十次会议通过 2012年12月28日中华人民共和国主席令第73号公布 自2013年7月1日起施行） 总则第一条： 为了完善劳动合同制度，明确劳动合同双方当事人的权利和义务，保护劳动者的合法权益，构建和发展和谐稳定的劳动关系，制定本法。 第二条： 中华人民共和国境内的企业、个体经济组织、民办非企业单位等组织（以下称用人单位）与劳动者建立劳动关系，订立、履行、变更、解除或者终止劳动合同，适用本法。 国家机关、事业单位、社会团体和与其建立劳动关系的劳动者，订立、履行、变更、解除或者终止劳动合同，依照本法执行。 第三条： 订立劳动合同，应当遵循合法、公平、平等自愿、协商一致、诚实信用的原则。 依法订立的劳动合同具有约束力，用人单位与劳动者应当履行劳动合同约定的义务。 第四条 用人单位应当依法建立和完善劳动规章制度，保障劳动者享有劳动权利、履行劳动义务。 用人单位在制定、修改或者决定有关劳动报酬、工作时间、休息休假、劳动安全卫生、保险福利、职工培训、劳动纪律以及劳动定额管理等直接涉及劳动者切身利益的规章制度或者重大事项时，应当经职工代表大会或者全体职工讨论，提出方案和意见，与工会或者职工代表平等协商确定。在规章制度和重大事项决定实施过程中，工会或者职工认为不适当的，有权向用人单位提出，通过协商予以修改完善。用人单位应当将直接涉及劳动者切身利益的规章制度和重大事项决定公示，或者告知劳动者。 第五条： 县级以上人民政府劳动行政部门会同工会和企业方面代表，建立健全协调劳动关系三方机制，共同研究解决有关劳动关系的重大问题。 第六条： 工会应当帮助、指导劳动者与用人单位依法订立和履行劳动合同，并与用人单位建立集体协商机制，维护劳动者的合法权益。 劳动合同的订立第七条: 用人单位自用工之日起即与劳动者建立劳动关系。用人单位应当建立职工名册备查。 第八条: 用人单位招用劳动者时，应当如实告知劳动者工作内容、工作条件、工作地点、职业危害、安全生产状况、劳动报酬，以及劳动者要求了解的其他情况；用人单位有权了解劳动者与劳动合同直接相关的基本情况，劳动者应当如实说明。 第九条： 用人单位招用劳动者，不得扣押劳动者的居民身份证和其他证件，不得要求劳动者提供担保或者以其他名义向劳动者收取财物。 第十条： 建立劳动关系，应当订立书面劳动合同。 已建立劳动关系，未同时订立书面劳动合同的，应当自用工之日起一个月内订立书面劳动合同。用人单位与劳动者在用工前订立劳动合同的，劳动关系自用工之日起建立。 第十一条： 用人单位未在用工的同时订立书面劳动合同，与劳动者约定的劳动报酬不明确的，新招用的劳动者的劳动报酬按照集体合同规定的标准执行；没有集体合同或者集体合同未规定的，实行同工同酬。 第十二条 劳动合同分为固定期限劳动合同、无固定期限劳动合同和以完成一定工作任务为期限的劳动合同。 第十三条 固定期限劳动合同，是指用人单位与劳动者约定合同终止时间的劳动合同。 用人单位与劳动者协商一致，可以订立固定期限劳动合同。 第十四条 无固定期限劳动合同，是指用人单位与劳动者约定无确定终止时间的劳动合同。 用人单位与劳动者协商一致，可以订立无固定期限劳动合同。有下列情形之一，劳动者提出或者同意续订、订立劳动合同的，除劳动者提出订立固定期限劳动合同外，应当订立无固定期限劳动合同：（一）劳动者在该用人单位连续工作满十年的；（二）用人单位初次实行劳动合同制度或者国有企业改制重新订立劳动合同时，劳动者在该用人单位连续工作满十年且距法定退休年龄不足十年的；（三）连续订立二次固定期限劳动合同，且劳动者没有本法第三十九条和第四十条第一项、第二项规定的情形，续订劳动合同的。 用人单位自用工之日起满一年不与劳动者订立书面劳动合同的，视为用人单位与劳动者已订立无固定期限劳动合同。 第十五条： 以完成一定工作任务为期限的劳动合同，是指用人单位与劳动者约定以某项工作的完成为合同期限的劳动合同。 用人单位与劳动者协商一致，可以订立以完成一定工作任务为期限的劳动合同。 第十六条： 劳动合同由用人单位与劳动者协商一致，并经用人单位与劳动者在劳动合同文本上签字或者盖章生效。 劳动合同文本由用人单位和劳动者各执一份。 第十七条： 劳动合同应当具备以下条款：（一）用人单位的名称、住所和法定代表人或者主要负责人；（二）劳动者的姓名、住址和居民身份证或者其他有效身份证件号码；（三）劳动合同期限；（四）工作内容和工作地点；（五）工作时间和休息休假；（六）劳动报酬；（七）社会保险；（八）劳动保护、劳动条件和职业危害防护；（九）法律、法规规定应当纳入劳动合同的其他事项。 劳动合同除前款规定的必备条款外，用人单位与劳动者可以约定试用期、培训、保守秘密、补充保险和福利待遇等其他事项。 第十八条： 劳动合同对劳动报酬和劳动条件等标准约定不明确，引发争议的，用人单位与劳动者可以重新协商；协商不成的，适用集体合同规定；没有集体合同或者集体合同未规定劳动报酬的，实行同工同酬；没有集体合同或者集体合同未规定劳动条件等标准的，适用国家有关规定。 第十九条： 劳动合同期限三个月以上不满一年的，试用期不得超过一个月；劳动合同期限一年以上不满三年的，试用期不得超过二个月；三年以上固定期限和无固定期限的劳动合同，试用期不得超过六个月。 同一用人单位与同一劳动者只能约定一次试用期。以完成一定工作任务为期限的劳动合同或者劳动合同期限不满三个月的，不得约定试用期。试用期包含在劳动合同期限内。劳动合同仅约定试用期的，试用期不成立，该期限为劳动合同期限。 第二十条： 劳动者在试用期的工资不得低于本单位相同岗位最低档工资或者劳动合同约定工资的百分之八十，并不得低于用人单位所在地的最低工资标准。 第二十一条： 在试用期中，除劳动者有本法第三十九条和第四十条第一项、第二项规定的情形外，用人单位不得解除劳动合同。用人单位在试用期解除劳动合同的，应当向劳动者说明理由。 第二十二条： 用人单位为劳动者提供专项培训费用，对其进行专业技术培训的，可以与该劳动者订立协议，约定服务期。 劳动者违反服务期约定的，应当按照约定向用人单位支付违约金。违约金的数额不得超过用人单位提供的培训费用。用人单位要求劳动者支付的违约金不得超过服务期尚未履行部分所应分摊的培训费用。用人单位与劳动者约定服务期的，不影响按照正常的工资调整机制提高劳动者在服务期期间的劳动报酬。 第二十三条： 用人单位与劳动者可以在劳动合同中约定保守用人单位的商业秘密和与知识产权相关的保密事项。 对负有保密义务的劳动者，用人单位可以在劳动合同或者保密协议中与劳动者约定竞业限制条款，并约定在解除或者终止劳动合同后，在竞业限制期限内按月给予劳动者经济补偿。劳动者违反竞业限制约定的，应当按照约定向用人单位支付违约金。 第二十四条： 竞业限制的人员限于用人单位的高级管理人员、高级技术人员和其他负有保密义务的人员。竞业限制的范围、地域、期限由用人单位与劳动者约定，竞业限制的约定不得违反法律、法规的规定。 在解除或者终止劳动合同后，前款规定的人员到与本单位生产或者经营同类产品、从事同类业务的有竞争关系的其他用人单位，或者自己开业生产或者经营同类产品、从事同类业务的竞业限制期限，不得超过二年。 第二十五条： 除本法第二十二条和第二十三条规定的情形外，用人单位不得与劳动者约定由劳动者承担违约金。 第二十六条： 下列劳动合同无效或者部分无效： （一）以欺诈、胁迫的手段或者乘人之危，使对方在违背真实意思的情况下订立或者变更劳动合同的；（二）用人单位免除自己的法定责任、排除劳动者权利的；（三）违反法律、行政法规强制性规定的。 对劳动合同的无效或者部分无效有争议的，由劳动争议仲裁机构或者人民法院确认。 第二十七条： 劳动合同部分无效，不影响其他部分效力的，其他部分仍然有效。 第二十八条： 劳动合同被确认无效，劳动者已付出劳动的，用人单位应当向劳动者支付劳动报酬。劳动报酬的数额，参照本单位相同或者相近岗位劳动者的劳动报酬确定。 劳动合同的履行和变更第二十九条： 用人单位与劳动者应当按照劳动合同的约定，全面履行各自的义务。 第三十条： 用人单位应当按照劳动合同约定和国家规定，向劳动者及时足额支付劳动报酬。 用人单位拖欠或者未足额支付劳动报酬的，劳动者可以依法向当地人民法院申请支付令，人民法院应当依法发出支付令。 第三十一条： 用人单位应当严格执行劳动定额标准，不得强迫或者变相强迫劳动者加班。用人单位安排加班的，应当按照国家有关规定向劳动者支付加班费。 第三十二条： 劳动者拒绝用人单位管理人员违章指挥、强令冒险作业的，不视为违反劳动合同。 劳动者对危害生命安全和身体健康的劳动条件，有权对用人单位提出批评、检举和控告。 第三十三条： 用人单位变更名称、法定代表人、主要负责人或者投资人等事项，不影响劳动合同的履行。 第三十四条： 用人单位发生合并或者分立等情况，原劳动合同继续有效，劳动合同由承继其权利和义务的用人单位继续履行。 第三十五条： 用人单位与劳动者协商一致，可以变更劳动合同约定的内容。变更劳动合同，应当采用书面形式。 变更后的劳动合同文本由用人单位和劳动者各执一份。 劳动合同的解除和终止第三十六条： 用人单位与劳动者协商一致，可以解除劳动合同。 第三十七条： 劳动者提前三十日以书面形式通知用人单位，可以解除劳动合同。劳动者在试用期内提前三日通知用人单位，可以解除劳动合同。 第三十八条： 用人单位有下列情形之一的，劳动者可以解除劳动合同：（一）未按照劳动合同约定提供劳动保护或者劳动条件的；（二）未及时足额支付劳动报酬的；（三）未依法为劳动者缴纳社会保险费的；（四）用人单位的规章制度违反法律、法规的规定，损害劳动者权益的；（五）因本法第二十六条第一款规定的情形致使劳动合同无效的；（六）法律、行政法规规定劳动者可以解除劳动合同的其他情形。 用人单位以暴力、威胁或者非法限制人身自由的手段强迫劳动者劳动的，或者用人单位违章指挥、强令冒险作业危及劳动者人身安全的，劳动者可以立即解除劳动合同，不需事先告知用人单位。 第三十九条： 劳动者有下列情形之一的，用人单位可以解除劳动合同：（一）在试用期间被证明不符合录用条件的；（二）严重违反用人单位的规章制度的；（三）严重失职，营私舞弊，给用人单位造成重大损害的；（四）劳动者同时与其他用人单位建立劳动关系，对完成本单位的工作任务造成严重影响，或者经用人单位提出，拒不改正的；（五）因本法第二十六条第一款第一项规定的情形致使劳动合同无效的；（六）被依法追究刑事责任的。 第四十条： 有下列情形之一的，用人单位提前三十日以书面形式通知劳动者本人或者额外支付劳动者一个月工资后，可以解除劳动合同：（一）劳动者患病或者非因工负伤，在规定的医疗期满后不能从事原工作，也不能从事由用人单位另行安排的工作的；（二）劳动者不能胜任工作，经过培训或者调整工作岗位，仍不能胜任工作的；（三）劳动合同订立时所依据的客观情况发生重大变化，致使劳动合同无法履行，经用人单位与劳动者协商，未能就变更劳动合同内容达成协议的。 第四十一条： 有下列情形之一，需要裁减人员二十人以上或者裁减不足二十人但占企业职工总数百分之十以上的，用人单位提前三十日向工会或者全体职工说明情况，听取工会或者职工的意见后，裁减人员方案经向劳动行政部门报告，可以裁减人员：（一）依照企业破产法规定进行重整的；（二）生产经营发生严重困难的；（三）企业转产、重大技术革新或者经营方式调整，经变更劳动合同后，仍需裁减人员的；（四）其他因劳动合同订立时所依据的客观经济情况发生重大变化，致使劳动合同无法履行的。 裁减人员时，应当优先留用下列人员：（一）与本单位订立较长期限的固定期限劳动合同的；（二）与本单位订立无固定期限劳动合同的；（三）家庭无其他就业人员，有需要扶养的老人或者未成年人的。 用人单位依照本条第一款规定裁减人员，在六个月内重新招用人员的，应当通知被裁减的人员，并在同等条件下优先招用被裁减的人员。 第四十二条： 劳动者有下列情形之一的，用人单位不得依照本法第四十条、第四十一条的规定解除劳动合同：（一）从事接触职业病危害作业的劳动者未进行离岗前职业健康检查，或者疑似职业病病人在诊断或者医学观察期间的；（二）在本单位患职业病或者因工负伤并被确认丧失或者部分丧失劳动能力的；（三）患病或者非因工负伤，在规定的医疗期内的；（四）女职工在孕期、产期、哺乳期的；（五）在本单位连续工作满十五年，且距法定退休年龄不足五年的；（六）法律、行政法规规定的其他情形。 第四十三条： 用人单位单方解除劳动合同，应当事先将理由通知工会。用人单位违反法律、行政法规规定或者劳动合同约定的，工会有权要求用人单位纠正。用人单位应当研究工会的意见，并将处理结果书面通知工会。 第四十四条： 有下列情形之一的，劳动合同终止：（一）劳动合同期满的；（二）劳动者开始依法享受基本养老保险待遇的；（三）劳动者死亡，或者被人民法院宣告死亡或者宣告失踪的；（四）用人单位被依法宣告破产的；（五）用人单位被吊销营业执照、责令关闭、撤销或者用人单位决定提前解散的；（六）法律、行政法规规定的其他情形。 第四十五条： 劳动合同期满，有本法第四十二条规定情形之一的，劳动合同应当续延至相应的情形消失时终止。但是，本法第四十二条第二项规定丧失或者部分丧失劳动能力劳动者的劳动合同的终止，按照国家有关工伤保险的规定执行。 第四十六条： 有下列情形之一的，用人单位应当向劳动者支付经济补偿：（一）劳动者依照本法第三十八条规定解除劳动合同的；（二）用人单位依照本法第三十六条规定向劳动者提出解除劳动合同并与劳动者协商一致解除劳动合同的；（三）用人单位依照本法第四十条规定解除劳动合同的；（四）用人单位依照本法第四十一条第一款规定解除劳动合同的；（五）除用人单位维持或者提高劳动合同约定条件续订劳动合同，劳动者不同意续订的情形外，依照本法第四十四条第一项规定终止固定期限劳动合同的；（六）依照本法第四十四条第四项、第五项规定终止劳动合同的；（七）法律、行政法规规定的其他情形。 第四十七条： 经济补偿按劳动者在本单位工作的年限，每满一年支付一个月工资的标准向劳动者支付。六个月以上不满一年的，按一年计算；不满六个月的，向劳动者支付半个月工资的经济补偿。 劳动者月工资高于用人单位所在直辖市、设区的市级人民政府公布的本地区上年度职工月平均工资三倍的，向其支付经济补偿的标准按职工月平均工资三倍的数额支付，向其支付经济补偿的年限最高不超过十二年。本条所称月工资是指劳动者在劳动合同解除或者终止前十二个月的平均工资。 第四十八条： 用人单位违反本法规定解除或者终止劳动合同，劳动者要求继续履行劳动合同的，用人单位应当继续履行；劳动者不要求继续履行劳动合同或者劳动合同已经不能继续履行的，用人单位应当依照本法第八十七条规定支付赔偿金。 第四十九条： 国家采取措施，建立健全劳动者社会保险关系跨地区转移接续制度。 第五十条： 用人单位应当在解除或者终止劳动合同时出具解除或者终止劳动合同的证明，并在十五日内为劳动者办理档案和社会保险关系转移手续。 劳动者应当按照双方约定，办理工作交接。用人单位依照本法有关规定应当向劳动者支付经济补偿的，在办结工作交接时支付。用人单位对已经解除或者终止的劳动合同的文本，至少保存二年备查。 特别规定第一节 集体合同第五十一条： 企业职工一方与用人单位通过平等协商，可以就劳动报酬、工作时间、休息休假、劳动安全卫生、保险福利等事项订立集体合同。集体合同草案应当提交职工代表大会或者全体职工讨论通过。 集体合同由工会代表企业职工一方与用人单位订立；尚未建立工会的用人单位，由上级工会指导劳动者推举的代表与用人单位订立。 第五十二条： 企业职工一方与用人单位可以订立劳动安全卫生、女职工权益保护、工资调整机制等专项集体合同。 第五十三条： 在县级以下区域内，建筑业、采矿业、餐饮服务业等行业可以由工会与企业方面代表订立行业性集体合同，或者订立区域性集体合同。 第五十四条： 集体合同订立后，应当报送劳动行政部门；劳动行政部门自收到集体合同文本之日起十五日内未提出异议的，集体合同即行生效。 依法订立的集体合同对用人单位和劳动者具有约束力。行业性、区域性集体合同对当地本行业、本区域的用人单位和劳动者具有约束力。 第五十五条： 集体合同中劳动报酬和劳动条件等标准不得低于当地人民政府规定的最低标准；用人单位与劳动者订立的劳动合同中劳动报酬和劳动条件等标准不得低于集体合同规定的标准。 第五十六条： 用人单位违反集体合同，侵犯职工劳动权益的，工会可以依法要求用人单位承担责任；因履行集体合同发生争议，经协商解决不成的，工会可以依法申请仲裁、提起诉讼。 ## 第二节 劳务派遣 第五十七条： 经营劳务派遣业务应当具备下列条件：（一）注册资本不得少于人民币二百万元；（二）有与开展业务相适应的固定的经营场所和设施；（三）有符合法律、行政法规规定的劳务派遣管理制度；（四）法律、行政法规规定的其他条件。 经营劳务派遣业务，应当向劳动行政部门依法申请行政许可；经许可的，依法办理相应的公司登记。未经许可，任何单位和个人不得经营劳务派遣业务。 第五十八条： 劳务派遣单位是本法所称用人单位，应当履行用人单位对劳动者的义务。劳务派遣单位与被派遣劳动者订立的劳动合同，除应当载明本法第十七条规定的事项外，还应当载明被派遣劳动者的用工单位以及派遣期限、工作岗位等情况。 劳务派遣单位应当与被派遣劳动者订立二年以上的固定期限劳动合同，按月支付劳动报酬；被派遣劳动者在无工作期间，劳务派遣单位应当按照所在地人民政府规定的最低工资标准，向其按月支付报酬。 第五十九条： 劳务派遣单位派遣劳动者应当与接受以劳务派遣形式用工的单位（以下称用工单位）订立劳务派遣协议。劳务派遣协议应当约定派遣岗位和人员数量、派遣期限、劳动报酬和社会保险费的数额与支付方式以及违反协议的责任。 用工单位应当根据工作岗位的实际需要与劳务派遣单位确定派遣期限，不得将连续用工期限分割订立数个短期劳务派遣协议。 第六十条： 劳务派遣单位应当将劳务派遣协议的内容告知被派遣劳动者。 劳务派遣单位不得克扣用工单位按照劳务派遣协议支付给被派遣劳动者的劳动报酬。劳务派遣单位和用工单位不得向被派遣劳动者收取费用。 第六十一条： 劳务派遣单位跨地区派遣劳动者的，被派遣劳动者享有的劳动报酬和劳动条件，按照用工单位所在地的标准执行。 第六十二条 用工单位应当履行下列义务：（一）执行国家劳动标准，提供相应的劳动条件和劳动保护；（二）告知被派遣劳动者的工作要求和劳动报酬；（三）支付加班费、绩效奖金，提供与工作岗位相关的福利待遇；（四）对在岗被派遣劳动者进行工作岗位所必需的培训；（五）连续用工的，实行正常的工资调整机制。 用工单位不得将被派遣劳动者再派遣到其他用人单位。 第六十三条： 被派遣劳动者享有与用工单位的劳动者同工同酬的权利。用工单位应当按照同工同酬原则，对被派遣劳动者与本单位同类岗位的劳动者实行相同的劳动报酬分配办法。用工单位无同类岗位劳动者的，参照用工单位所在地相同或者相近岗位劳动者的劳动报酬确定。 劳务派遣单位与被派遣劳动者订立的劳动合同和与用工单位订立的劳务派遣协议，载明或者约定的向被派遣劳动者支付的劳动报酬应当符合前款规定。 第六十四条： 被派遣劳动者有权在劳务派遣单位或者用工单位依法参加或者组织工会，维护自身的合法权益。 第六十五条： 被派遣劳动者可以依照本法第三十六条、第三十八条的规定与劳务派遣单位解除劳动合同。 被派遣劳动者有本法第三十九条和第四十条第一项、第二项规定情形的，用工单位可以将劳动者退回劳务派遣单位，劳务派遣单位依照本法有关规定，可以与劳动者解除劳动合同。 第六十六条： 劳动合同用工是我国的企业基本用工形式。劳务派遣用工是补充形式，只能在临时性、辅助性或者替代性的工作岗位上实施。 前款规定的临时性工作岗位是指存续时间不超过六个月的岗位；辅助性工作岗位是指为主营业务岗位提供服务的非主营业务岗位；替代性工作岗位是指用工单位的劳动者因脱产学习、休假等原因无法工作的一定期间内，可以由其他劳动者替代工作的岗位。用工单位应当严格控制劳务派遣用工数量，不得超过其用工总量的一定比例，具体比例由国务院劳动行政部门规定。 第六十七条： 用人单位不得设立劳务派遣单位向本单位或者所属单位派遣劳动者。 ## 第三节 非全日制用工 第六十八条: 非全日制用工，是指以小时计酬为主，劳动者在同一用人单位一般平均每日工作时间不超过四小时，每周工作时间累计不超过二十四小时的用工形式。 第六十九条: 非全日制用工双方当事人可以订立口头协议。 从事非全日制用工的劳动者可以与一个或者一个以上用人单位订立劳动合同；但是，后订立的劳动合同不得影响先订立的劳动合同的履行。 第七十条: 非全日制用工双方当事人不得约定试用期。 第七十一条: 非全日制用工双方当事人任何一方都可以随时通知对方终止用工。终止用工，用人单位不向劳动者支付经济补偿。 第七十二条: 非全日制用工小时计酬标准不得低于用人单位所在地人民政府规定的最低小时工资标准。 非全日制用工劳动报酬结算支付周期最长不得超过十五日。 # 监督检查 第七十三条： 国务院劳动行政部门负责全国劳动合同制度实施的监督管理。 县级以上地方人民政府劳动行政部门负责本行政区域内劳动合同制度实施的监督管理。县级以上各级人民政府劳动行政部门在劳动合同制度实施的监督管理工作中，应当听取工会、企业方面代表以及有关行业主管部门的意见。 第七十四条： 县级以上地方人民政府劳动行政部门依法对下列实施劳动合同制度的情况进行监督检查：（一）用人单位制定直接涉及劳动者切身利益的规章制度及其执行的情况；（二）用人单位与劳动者订立和解除劳动合同的情况；（三）劳务派遣单位和用工单位遵守劳务派遣有关规定的情况；（四）用人单位遵守国家关于劳动者工作时间和休息休假规定的情况；（五）用人单位支付劳动合同约定的劳动报酬和执行最低工资标准的情况；（六）用人单位参加各项社会保险和缴纳社会保险费的情况；（七）法律、法规规定的其他劳动监察事项。 第七十五条： 县级以上地方人民政府劳动行政部门实施监督检查时，有权查阅与劳动合同、集体合同有关的材料，有权对劳动场所进行实地检查，用人单位和劳动者都应当如实提供有关情况和材料。 劳动行政部门的工作人员进行监督检查，应当出示证件，依法行使职权，文明执法。 第七十六条： 县级以上人民政府建设、卫生、安全生产监督管理等有关主管部门在各自职责范围内，对用人单位执行劳动合同制度的情况进行监督管理。 第七十七条： 劳动者合法权益受到侵害的，有权要求有关部门依法处理，或者依法申请仲裁、提起诉讼。 第七十八条： 工会依法维护劳动者的合法权益，对用人单位履行劳动合同、集体合同的情况进行监督。用人单位违反劳动法律、法规和劳动合同、集体合同的，工会有权提出意见或者要求纠正；劳动者申请仲裁、提起诉讼的，工会依法给予支持和帮助。 第七十九条： 任何组织或者个人对违反本法的行为都有权举报，县级以上人民政府劳动行政部门应当及时核实、处理，并对举报有功人员给予奖励。 # 法律责任 第八十条： 用人单位直接涉及劳动者切身利益的规章制度违反法律、法规规定的，由劳动行政部门责令改正，给予警告；给劳动者造成损害的，应当承担赔偿责任。 第八十一条： 用人单位提供的劳动合同文本未载明本法规定的劳动合同必备条款或者用人单位未将劳动合同文本交付劳动者的，由劳动行政部门责令改正；给劳动者造成损害的，应当承担赔偿责任。 第八十二条： 用人单位自用工之日起超过一个月不满一年未与劳动者订立书面劳动合同的，应当向劳动者每月支付二倍的工资。 用人单位违反本法规定不与劳动者订立无固定期限劳动合同的，自应当订立无固定期限劳动合同之日起向劳动者每月支付二倍的工资。 第八十三条： 用人单位违反本法规定与劳动者约定试用期的，由劳动行政部门责令改正；违法约定的试用期已经履行的，由用人单位以劳动者试用期满月工资为标准，按已经履行的超过法定试用期的期间向劳动者支付赔偿金。 第八十四条： 用人单位违反本法规定，扣押劳动者居民身份证等证件的，由劳动行政部门责令限期退还劳动者本人，并依照有关法律规定给予处罚。 用人单位违反本法规定，以担保或者其他名义向劳动者收取财物的，由劳动行政部门责令限期退还劳动者本人，并以每人五百元以上二千元以下的标准处以罚款；给劳动者造成损害的，应当承担赔偿责任。劳动者依法解除或者终止劳动合同，用人单位扣押劳动者档案或者其他物品的，依照前款规定处罚。 第八十五条： 用人单位有下列情形之一的，由劳动行政部门责令限期支付劳动报酬、加班费或者经济补偿；劳动报酬低于当地最低工资标准的，应当支付其差额部分；逾期不支付的，责令用人单位按应付金额百分之五十以上百分之一百以下的标准向劳动者加付赔偿金：（一）未按照劳动合同的约定或者国家规定及时足额支付劳动者劳动报酬的；（二）低于当地最低工资标准支付劳动者工资的；（三）安排加班不支付加班费的；（四）解除或者终止劳动合同，未依照本法规定向劳动者支付经济补偿的。 第八十六条： 劳动合同依照本法第二十六条规定被确认无效，给对方造成损害的，有过错的一方应当承担赔偿责任。 第八十七条： 用人单位违反本法规定解除或者终止劳动合同的，应当依照本法第四十七条规定的经济补偿标准的二倍向劳动者支付赔偿金。 第八十八条： 用人单位有下列情形之一的，依法给予行政处罚；构成犯罪的，依法追究刑事责任；给劳动者造成损害的，应当承担赔偿责任：（一）以暴力、威胁或者非法限制人身自由的手段强迫劳动的；（二）违章指挥或者强令冒险作业危及劳动者人身安全的；（三）侮辱、体罚、殴打、非法搜查或者拘禁劳动者的；（四）劳动条件恶劣、环境污染严重，给劳动者身心健康造成严重损害的。 第八十九条： 用人单位违反本法规定未向劳动者出具解除或者终止劳动合同的书面证明，由劳动行政部门责令改正；给劳动者造成损害的，应当承担赔偿责任。 第九十条： 劳动者违反本法规定解除劳动合同，或者违反劳动合同中约定的保密义务或者竞业限制，给用人单位造成损失的，应当承担赔偿责任。 第九十一条： 用人单位招用与其他用人单位尚未解除或者终止劳动合同的劳动者，给其他用人单位造成损失的，应当承担连带赔偿责任。 第九十二条： 违反本法规定，未经许可，擅自经营劳务派遣业务的，由劳动行政部门责令停止违法行为，没收违法所得，并处违法所得一倍以上五倍以下的罚款；没有违法所得的，可以处五万元以下的罚款。 劳务派遣单位、用工单位违反本法有关劳务派遣规定的，由劳动行政部门责令限期改正；逾期不改正的，以每人五千元以上一万元以下的标准处以罚款，对劳务派遣单位，吊销其劳务派遣业务经营许可证。用工单位给被派遣劳动者造成损害的，劳务派遣单位与用工单位承担连带赔偿责任。 第九十三条： 对不具备合法经营资格的用人单位的违法犯罪行为，依法追究法律责任；劳动者已经付出劳动的，该单位或者其出资人应当依照本法有关规定向劳动者支付劳动报酬、经济补偿、赔偿金；给劳动者造成损害的，应当承担赔偿责任。 第九十四条： 个人承包经营违反本法规定招用劳动者，给劳动者造成损害的，发包的组织与个人承包经营者承担连带赔偿责任。 第九十五条： 劳动行政部门和其他有关主管部门及其工作人员玩忽职守、不履行法定职责，或者违法行使职权，给劳动者或者用人单位造成损害的，应当承担赔偿责任；对直接负责的主管人员和其他直接责任人员，依法给予行政处分；构成犯罪的，依法追究刑事责任。 # 附则 第九十六条： 事业单位与实行聘用制的工作人员订立、履行、变更、解除或者终止劳动合同，法律、行政法规或者国务院另有规定的，依照其规定；未作规定的，依照本法有关规定执行。 第九十七条： 本法施行前已依法订立且在本法施行之日存续的劳动合同，继续履行；本法第十四条第二款第三项规定连续订立固定期限劳动合同的次数，自本法施行后续订固定期限劳动合同时开始计算。 本法施行前已建立劳动关系，尚未订立书面劳动合同的，应当自本法施行之日起一个月内订立。本法施行之日存续的劳动合同在本法施行后解除或者终止，依照本法第四十六条规定应当支付经济补偿的，经济补偿年限自本法施行之日起计算；本法施行前按照当时有关规定，用人单位应当向劳动者支付经济补偿的，按照当时有关规定执行。 第九十八条： 本法自2008年1月1日起施行。]]></content>
      <categories>
        <category>法律</category>
      </categories>
      <tags>
        <tag>劳动合同法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文体格式]]></title>
    <url>%2F2018%2F10%2F12%2F%E6%96%87%E4%BD%93%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Grafana]]></title>
    <url>%2F2018%2F09%2F13%2FGrafana%2F</url>
    <content type="text"><![CDATA[参考： Grafana 文档: http://docs.grafana.org/ GitHub: https://github.com/grafana/ 环境： CentOS7x86_64 Grafana v5.2]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Grafana</tag>
        <tag>Monitoring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Prometheus]]></title>
    <url>%2F2018%2F09%2F11%2FPrometheus%2F</url>
    <content type="text"><![CDATA[参考： Prometheus文档： https://prometheus.io/docs GitHub: https://github.com/prometheus/ 环境： CentOS7x86_64 Prometheus v2.3 介绍Introduction 概述 Prometheus是什么What is Prometheus? Prometheus是一个最初在SoundCloud上构建的开源监控系统和报警工具包。现在是一个独立的开源项目，由社区进行维护。 功能(Features)Prometheus的主要特点： 具有由度量名称(metric name)和键值对(key-value)标识的时间序列(time series)数据的多维(multi-dimensional)数据模型 灵活的查询语言，以利用此维度 不依赖分布式存储(distributed storage)，单个服务器节点是自治的(autonomous) 时间序列集合通过HTPP的pull model发生 push时间序列通过中间网关(intermediary gateway)的支持 通过服务发现或静态配置来发现目标 图形和仪表盘支持多种模式 组件(Components)Prometheus系统由多个组件构成，其中某些组件是可选的： 主要的Prometheus Server，用于存储时间序列数据 client libraries，用于检测应用程序代码 push gateway，用于支持短暂的(short-lived)工作 exporters，用于服务的特殊目的 alertmanager，用于处理报警 各种支持工具 架构(Architecture)Prometheus的体系结构和系统组件图： 什么时候适合When does it fit? Prometheus适用于记录任何纯数字时间序列。它既适用于以机器为中心的监控，也适用于高度动态的面向服务架构的监控。在微服务的世界中，它对多维数据收集和查询的支持是一种特殊的优势。Prometheus专为提高可靠性而设计，是你在断电期间可以快速诊断问题的系统。每个Prometheus Server都是独立的，不依赖于网络存储或其它远程服务。当基础架构其它部分损坏时，你仍可以依赖它，并且你不需要设置大量的基础架构来使用它。 什么时候不适合When does it not fit? Prometheus重视可靠性。即使在系统故障情况下，你也可以随时查看有关系统的可用统计信息。如果你需要100%的准确度，Prometheus不是一个好的选择，你可能需要使用其它系统。 第一步步骤： 下载 配置 运行 使用表达式浏览器 使用图形接口 监控其它目标 术语GLOSSARY Alert是Prometheus正在开火的警报规则的结果。警报从Prometheus发送到AlterManger。 Alertmanager接收警报，将它们聚合成组，删除重复数据，应用静音、限制，然后发送电子邮件等通知。 Bridge是一个从Client Library中获取样本并将它们暴露给 non-Prometheus 监控系统的组件。例如，Python、Java、Go…客户端可将指标导出到Graphite。 Client library是某种语言的库(Go, Java, Python…)，可以直接检测代码，编写自定义收集器以从其它系统中收集指标并将指标公开给Prometheus。 Collector是表示一组度量标准的 exporter 的一部分。如果它是直接检测的一部分，则可以是单个度量，如果是从另一个系统提取度量，则可以是许多度量。 Direct instrumentation作为源代码程序的一部分内联添加的检测。 Endpoint Exporter是一个公开Prometheus指标的程序，通常将 non-prometheus 格式的指标转换为 Prometheus 支持的格式。 Instance唯一标识作业中目标的标签 Job具有相同目的的目标集合 Notification代表一组多个警报 Promdash原生Prometheus仪表盘构建器。它已被弃用，并被 Grafana 取代 Prometheus通常指的是Prometheus System的核心程序，也可指整个监控系统。 PromQLPrometheus Query Language Pushgateway持续从批量作业中最新推出的指标 Remote Read允许从其它系统透明读取时间序列作为查询的一部分 Remote Read Adapter并非所有系统都支持远程读取。远程读取适配器便是用于此。 Remote Read EndpointPrometheus进行远程读取时的对象 Remote Write允许动态地将采集的样本发送到其它系统 Remote Write Adapter Remote Write Endpoint Sample时间序列中某个时间点的单个值，Prometheus中，每个样本都包含一个float64和ms精度的时间戳。 Silence防止报警 Target抓取对象的定义 FAQfaq: https://prometheus.io/docs/introduction/faq/ 概念CONCEPTS 数据模型Data model Prometheus从根本上将所有数据存储为时间序列(time series): 属于同一指标和同一标记维度的带时间戳值的流。除了存储时间序列，Prometheus还可以临时生成时间序列作为查询的结果。 指标名称和标签Metric names and labels 每个时间序列都是有指标名称(metric name)和一组键值对(也称为标签(label))来唯一标识。 指标名称： 可能包含ASCII字母，下划线，冒号。它必须匹配正则: [a-zA-Z_:][a-zA-Z0-9_:]*。标签启用Prometheus的维度数据模型： 指标类型metric types 工作和实例Job and Instance Prometheus 入门GETTING STARTED 本节介绍如何安装，配置，使用Prometheus的简单例子。你将在本地安装和运行Prometheus，将其配置为自我填充和示例应用程序，然后使用查询，规则和图表来使用收集的序列数据。 下载 下载地址: https://prometheus.io/download/ 123tar xvfz prometheus-*.tar.gzcd prometheus-* 配置和监控Prometheus通过在目标上通过HTTP endPoints来抓取指标，来收集受监控目标的指标。由于Prometheus也以相同的方式公开自身数据，它也可以获取和监测自身的健康状况。虽然Prometheus Server只收集有关自身的数据在实践中不是很有用，但它是一个很好的示例。如prometheus.yml示例配置文件： 12345678910111213141516171819global: scrape_interval: 15s # By default, scrape targets every 15 seconds. # Attach these labels to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: monitor: 'codelab-monitor'# A scrape configuration containing exactly one endpoint to scrape:# Here it's Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: 'prometheus' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:9090'] 启动启动后，可访问9090端口查看状态。可访问localhost:9090/metrics查看有关自身的相关指标。 12cd prometheus-2.3.2.linux-amd64./prometheus --config.file=&quot;prometheus.yml&quot; 使用表达式浏览器让我们看一下Prometheus收集的一些数据。要使用Prometheus的内建表达式浏览器(expression browser)，请跳转到http://localhost:9090/graph并选择Graph -&gt; Console，在其中输入表达式。绘制表达式图形同样在此操作。 12345678910#表达式prometheus_target_interval_length_seconds#表达式prometheus_target_interval_length_seconds&#123;quantile=&quot;0.99&quot;&#125;#计算返回的时间序列数count(prometheus_target_interval_length_seconds) 启动简单的目标启动一些示例目标让Prometheus获取。确保已安装Go表一起并设置了正常的GO PATH。 123456789101112131415161718mkdir ./sample &amp;&amp; cd samplegit clone https://github.com/prometheus/client_golang.gitcd client_golang/examples/randomgo get -dgo build# Start 3 example targets in separate terminals:./random -listen-address=:9091./random -listen-address=:9092./random -listen-address=:9093#访问http://localhost:9091/metriceshttp://localhost:9092/metriceshttp://localhost:9093/metrices 监控示例目标现在需要配置Prometheus来抓取目标。 1234567891011121314scrape_configs: - job_name: 'example-random' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:8080', 'localhost:8081'] labels: group: 'production' - targets: ['localhost:8082'] labels: group: 'canary' 重启Prometheus，检测rpc_durations_seconds metric来验证。 配置规则Configure rules for aggregating scraped data into new time series 聚合超过数千个时间序列的查询在计算ad-hoc时会变慢。为了提高效率，Prometheus允许你通过配置的规则将预录表达式预先记录到全新的持久时间序列中。 创建规则文件prometheus.rules.yml：123456#job_service:rpc_durations_seconds_count:avg_rate5mgroups:- name: example rules: - record: job_service:rpc_durations_seconds_count:avg_rate5m expr: avg(rate(rpc_durations_seconds_count[5m])) by (job, service) 要是Prometheus选择此新规则，需要修改Prometheus配置： 123456789101112131415161718192021222324252627282930313233global: scrape_interval: 15s # By default, scrape targets every 15 seconds. evaluation_interval: 15s # Evaluate rules every 15 seconds. # Attach these extra labels to all timeseries collected by this Prometheus instance. external_labels: monitor: &apos;codelab-monitor&apos;rule_files: - &apos;prometheus.rules.yml&apos;scrape_configs: - job_name: &apos;prometheus&apos; # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: [&apos;localhost:9090&apos;] - job_name: &apos;example-random&apos; # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: [&apos;localhost:8091&apos;, &apos;localhost:8092&apos;] labels: group: &apos;production&apos; - targets: [&apos;localhost:9093&apos;] labels: group: &apos;canary&apos; 重启Prometheus，使用job_service:rpc_durations_seconds_count:avg_rate5m metric验证。 安装 使用预编译的二进制文件 使用源码 使用Docker所有的Prometheus服务都可以作为 Docker image 来使用。Prometheus image 使用 volume 来存储实际的指标。对于生产部署，强烈建议使用 Data Volume Container 来升级数据的管理。 栗子： 123456#bind-mountdocker run -p 9090:9090 -v /tmp/prometheus.yml:/etc/prometheus.yml prom/prometheus#volumedocker run -p 9090:9090 -v /promethe-data prom/prometheus --config.file=/prometheus-data/prometheus.yml 自定义镜像 Dockerfile: 123FROM prom/prometheusADD prometheus.yml /etc/prometheus/xxx 构建： 1docker build -t my-prometheus . 使用配置管理系统 Ansible Chef Puppet SaltStack 配置Configuration Prometheus通过命令行标志(flag)和配置文件进行配置。使用./prometheus -h查看所有命令行标志。Prometheus可在运行时重新加载配置。 配置文件configuration file: https://prometheus.io/docs/prometheus/latest/configuration/configuration/ 使用--config.file标志指定配置文件。配置文件使用YAML格式。 一个配置文件栗子: 1234567891011121314151617181920212223242526272829303132333435363738global: # How frequently to scrape targets by default. [ scrape_interval: &lt;duration&gt; | default = 1m ] # How long until a scrape request times out. [ scrape_timeout: &lt;duration&gt; | default = 10s ] # How frequently to evaluate rules. [ evaluation_interval: &lt;duration&gt; | default = 1m ] # The labels to add to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: [ &lt;labelname&gt;: &lt;labelvalue&gt; ... ]# Rule files specifies a list of globs. Rules and alerts are read from# all matching files.rule_files: [ - &lt;filepath_glob&gt; ... ]# A list of scrape configurations.scrape_configs: [ - &lt;scrape_config&gt; ... ]# Alerting specifies settings related to the Alertmanager.alerting: alert_relabel_configs: [ - &lt;relabel_config&gt; ... ] alertmanagers: [ - &lt;alertmanager_config&gt; ... ]# Settings related to the remote write feature.remote_write: [ - &lt;remote_write&gt; ... ]# Settings related to the remote read feature.remote_read: [ - &lt;remote_read&gt; ... ] 各个配置项： scrape_config tls_config azure_sd_config consul_sd_config dns_sd_config ec2_sd_config openstack_sd_config file_sd_config gce_sd_config kubernetes_sd_config marathon_sd_config nerve_sd_config serverset_sd_config triton_sd_config static_config relabel_config metric_relabel_configs alert_relabel_configs alertmanager_config remote_write remote_read 可视化Visualization 表达式浏览器Expression browser 表达其浏览器在 Prometheus Server 的 /graph 处。对于图形，请使用 Grafana 或 Console template。 GrafanaGrafana: https://grafana.com/ Grafana，美丽的分析和监控的开放平台，时序分析的开源那软件。 Grafana 支持查询 Prometheus。如下是一个Grafana仪表盘，用于查询Prometheus的数据： 安装完整的安装说明，请查看Grafana Docs。 CentOSRPM 12#sudo yum install &lt;rpm package url&gt;sudo yum install https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-5.1.4-1.x86_64.rpm repo 1234567891011121314151617181920[grafana]name=grafanabaseurl=https://packagecloud.io/grafana/stable/el/7/$basearchrepo_gpgcheck=1enabled=1gpgcheck=1gpgkey=https://packagecloud.io/gpg.key https://grafanarel.s3.amazonaws.com/RPM-GPG-KEY-grafanasslverify=1sslcacert=/etc/pki/tls/certs/ca-bundle.crtsudo yum install -y grafana#启动systemctl start grafana-server#命令行工具grafana-cli 包详情 Installs binary to /usr/sbin/grafana-server Copies init.d script to /etc/init.d/grafana-server Installs default file (environment vars) to /etc/sysconfig/grafana-server Copies configuration file to /etc/grafana/grafana.ini Installs systemd service (if systemd is available) name grafana-server.service The default configuration uses a log file at /var/log/grafana/grafana.log The default configuration specifies an sqlite3 database at /var/lib/grafana/grafana.db 二进制tar文件 1234567# Download and unpack Grafana from binary tar (adjust version as appropriate).curl -L -O https://grafanarel.s3.amazonaws.com/builds/grafana-2.5.0.linux-x64.tar.gztar zxf grafana-2.5.0.linux-x64.tar.gz# Start Grafana.cd grafana-2.5.0/./bin/grafana-server web Docker123456789101112131415161718192021#基础栗子docker run -d -p 3000:3000 grafana/grafana#配置化docker run \ -d \ -p 3000:3000 \ --name=grafana \ -e &quot;GF_SERVER_ROOT_URL=http://grafana.server.name&quot; \ -e &quot;GF_SECURITY_ADMIN_PASSWORD=secret&quot; \ grafana/grafana:version#默认环境变量值GF_PATHS_CONFIG /etc/grafana/grafana.iniGF_PATHS_DATA /var/lib/grafanaGF_PATHS_HOME /usr/share/grafanaGF_PATHS_LOGS /var/log/grafanaGF_PATHS_PLUGINS /var/lib/grafana/pluginsGF_PATHS_PROVISIONING /etc/grafana/provisioning 使用默认情况下，访问http://localhost:3000来访问Grafana。默认登录的用户名和密码： admin/admin。 创建Prometheus数据源 创建Prometheus图表 Console template控制台模板允许使用Go templating language创建任意控制台。这些都是从Prometheus Server提供的。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Monitoring</tag>
        <tag>Prometheus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fluentd]]></title>
    <url>%2F2018%2F07%2F19%2FFluentd%2F</url>
    <content type="text"><![CDATA[参考： Fluentd文档: https://docs.fluentd.org/v1.0/articles/quickstart 环境： CentOS7x86_64 Fluentd v1.0 综述 入门getting started Fluentd是一个完全免费且开源的日志收集器，支持多种事件类型。Fluentd将日志视为JSON(一种机器可读格式)，它主要用C语言编写，扩展部分使用Ruby。 安装由于我使用CentOS7，所以查看了此平台文档。 安装前在安装Fluentd前，请配置环境，避免一些问题。 设置ntp 增加max file descriptors 优化网络内核参数 123456789101112131415161718192021222324252627282930#ntp/sbin/ntpdate 1.cn.pool.ntp.org#文件描述符ulimit -n#1024#LimitNOFILE=65536vim /etc/security/limits.confroot soft nofile 65536root hard nofile 65536* soft nofile 65536* hard nofile 65536#之后重启机器#优化网络内核参数vim /etc/sysctl.confnet.core.somaxconn = 1024net.core.netdev_max_backlog = 5000net.core.rmem_max = 16777216net.core.wmem_max = 16777216net.ipv4.tcp_wmem = 4096 12582912 16777216net.ipv4.tcp_rmem = 4096 12582912 16777216net.ipv4.tcp_max_syn_backlog = 8096net.ipv4.tcp_slow_start_after_idle = 0net.ipv4.tcp_tw_reuse = 1net.ipv4.ip_local_port_range = 10240 65535sysctl -p rpm安装12345#此脚本会自动安装td.repo，并安装td-agent#non-rootcurl -L https://toolbelt.treasuredata.com/sh/install-redhat-td-agent3.sh | sh#你也可以将脚本内容复制下来执行 启动daemon自动支持systemd: 1234567ls /usr/lib/systemd/system/td-agent.service#默认配置文件ls /etc/td-agent/td-agent.confsystemctl start|stop|status td-agent 通过HTTP发送示例日志我们可通过POST发送日志栗子。 1curl -X POST -d 'json=&#123;"json": "message"&#125;' http://localhost:8888/debug.txt 安装后 系统管理 配置文件 日志 连接到其它服务 如何工作 插件管理 配置语法 数据源 输出点 系统管理 123456#配置文件ls /etc/td-agent/td-agent.conf#日志ls /var/log/td-agent/td-agent.log 连接到其它服务在Fluentd中，数据 input/output 最重要的部分由插件来管理。每个插件都知道如何与外部端点连接，并负责管理传输数据流的通道。插件以某种约定命名。如in_kafka, out_mongo。 配置栗子：in_forward插件作为输入源，out_file插件作为输出点。 123456789&lt;source&gt; @type forward port 9999&lt;/source&gt;&lt;match app.**&gt; @type file path /var/log/app/data.log compress gzip&lt;/match&gt; 插件管理：Fluentd将插件作为Ruby gems来管理。所以你需要使用td-agent-gem来管理Fluentd插件。 123#安装s3插件#查看插件: &lt;https://www.fluentd.org/plugins&gt;sudo /usr/sbin/td-agent-gem install fluent-plugin-s3 配置语法配置文件由许多块组成，每个块包含一组特定数据端点设置。 数据源: 1234567&lt;source&gt; @type syslog port 5140 tag system&lt;/source&gt;#@type确定要使用的插件，你就不需要再去加上前缀in 输出点：添加一个数据流输出端点，你需要定义一个&lt;match&gt;块。你可在过滤器汇表达式中使用通配符*来匹配多个。 12345&lt;match debug.log&gt; @type syslog prot 5140 tag system&lt;/source&gt; Fluentd事件的生命Life of a Fluentd event 基础设置使用in_http和out_stdout插件作为示例，来描述事件周期。 12345678910111213141516&lt;source&gt; @type http port 8888 bind 0.0.0.0&lt;/source&gt;&lt;match test.cycle&gt; @type stdout&lt;/match&gt;curl -i -X POST -d &apos;json=&#123;&apos;action&apos;: &apos;login&apos;, &apos;user&apos;: 2&#125;&apos; http://localhost:8888/test.cycleHTTP/1.1 200 OKContent-Type: text/plainConnection: Keep-AliveContent-Length: 0 事件结构Event structure Fluentd事件结构： tag: 事件来自何处 time: 事件发生事件(原子时间) record: log内容(json) 事件处理Processing Events Filters Labels Buffers 定义好配置时，路由引擎对输入数据应用配置规则。 Filters过滤的目的在于传递(pass)或拒绝(reject)事件。 12345678910111213141516171819202122232425#栗子过滤 排除任何logout操作&lt;source&gt; @type http port 8888 bind 0.0.0.0&lt;/source&gt;&lt;filter test.cycle&gt; @type grep &lt;exclude&gt; key action pattern ^logout$ &lt;/exclude&gt;&lt;/filter&gt;&lt;match test.cycle&gt; @type stdout&lt;/match&gt;curl -i -X POST -d &apos;json=&#123;&quot;action&quot;:&quot;login&quot;,&quot;user&quot;:2&#125;&apos; http://localhost:8888/test.cyclecurl -i -X POST -d &apos;json=&#123;&quot;action&quot;:&quot;logout&quot;,&quot;user&quot;:2&#125;&apos; http://localhost:8888/test.cycle#查看fluentd日志的过滤情况vim /var/log/td-agent/td-agent.log Fluentd允许继承许多过滤器，同时考虑到配置文件的增长会让读者觉得有点复杂。所以添加了一个Label功能，用于解决这个问题。 LabelsLabel这个功能，用于解决配置文件的复杂性，并允许定义不遵循从上到下的新路由部分，而是像链接引用一样。 栗子: 12345678910111213141516171819202122232425262728&lt;source&gt; @type http bind 0.0.0.0 port 8888 @label @STAGING&lt;/source&gt;&lt;filter test.cycle&gt; @type grep &lt;exclude&gt; key action pattern ^login$ &lt;/exclude&gt;&lt;/filter&gt;&lt;label @STAGING&gt; &lt;filter test.cycle&gt; @type grep &lt;exclude&gt; key action pattern ^logout$ &lt;/exclude&gt; &lt;/filter&gt; &lt;match test.cycle&gt; @type stdout &lt;/match&gt;&lt;/label&gt; Buffers前面的栗子中，我们使用non-buffered stdout。但是在生产环境中，会使用outputs in buffered。缓冲模式下的输出插件首先将接收到的事件存储到缓冲区，并通过满足刷新条件将缓冲区写入目标。 缓冲区对可靠性和吞吐量都很重要。 结论一旦事件由源上的Fluentd引擎所上报，就可逐步处理或引用Label内部处理，任何事件都有可能被过滤。新的路由引擎旨在提供更多灵活性，并在输出前使处理更容易。 使用案例Use cases 集中式应用程序日志Centralized App Logging Java Ruby Python PHP Perl Node.js Scala 监控服务日志Monitoring Service Logs FEKSplunk是一个检索日志的好工具，但它的高成本对很对团队来说便不可取了。我们通过结合三个开源项目: Elasticsearch， Kiban， Fluentd来免费替代Splunk。 请自行安装Elasticsearch和Kibana。 安装Fluentd的Elasticsearch插件:fluent-plugin-elasticsearch: https://github.com/uken/fluent-plugin-elasticsearch 123td-agent-gem install fluent-plugin-elasticsearch --no-documenttd-agent-gem list 修改配置文件: /etc/td-agent/td-agent.conf 1234567891011121314151617181920# get logs from syslog&lt;source&gt; @type syslog port 42185 tag syslog&lt;/source&gt;# get logs from fluent-logger, fluent-cat or other fluentd instances&lt;source&gt; @type forward&lt;/source&gt;&lt;match syslog.**&gt; @type elasticsearch logstash_format true &lt;buffer&gt; flush_interval 10s # for testing &lt;/buffer&gt;&lt;/match&gt;#fluent-plugin-elasticsearch插件附带一个logstash_format选项 Elasticsearch用户和密码: 1234567891011&lt;match my.logs&gt; @type elasticsearch host localhost port 9200 user elastic password xxxxx index_name fluentd type_name fluentd&lt;/match&gt;#hosts host1:port1,host2:port2... 具体详情请参考GitHub的README。 配置rsyslogd:将日志从rsyslogd转发到Fluentd。修改/etc/syslog.conf并重启rsyslogd。这将本地syslog转发到Fluentd，而Fluentd会将日志转发给Elasticsearch。 1234*.* @127.0.0.1:42185systemcrl restart rsyslog 存储和查询事件日志：访问Kibana配置索引logstash-*进行查看日志。 使用logger命令手动发送日志到Elasticsearch。1234#logger - a shell command interface to the syslog(3) system log modulelogger -t test foobar#之后可在kibana索引中查看到ident为test, message为foobar的两个文档 邮件报警Splunk-like Grep-and-Alert-Email System Using Fluentd Splunk的一个主要功能便是能够满足日志在某些条件时发送报警电子邮件。我们将使用Fluentd构建一个类似的系统。例如，当检测到Apache日志中的5xx HTTP status code时编发送报警邮件。 安装依赖安装两个插件 12td-agent-gem install fluent-plugin-grepcountertd-agent-gem install fluent-plugin-mail 配置 12345678910111213141516171819202122232425262728293031323334353637383940/etc/td-agent/td-agent.conf&lt;source&gt; @type tail path /var/log/apache2/access.log &lt;parse&gt; @type apache2 &lt;/parse&gt; tag apache.access&lt;/source&gt;&lt;match apache.access&gt; @type grepcounter count_interval 3 # The time window for counting errors (in secs) input_key code # The field to apply the regular expression regexp ^5\d\d$ # The regular expression to be applied threshold 1 # The minimum number of erros to trigger an alert add_tag_prefix error_5xx # Generate tags like &quot;error_5xx.apache.access&quot;&lt;/match&gt;&lt;match error_5xx.apache.access&gt; @type copy &lt;store&gt; @type stdout # Print to stdout for debugging &lt;/store&gt; &lt;store&gt; @type mail host smtp.gmail.com # Change this to your SMTP server host port 587 # Normally 25/587/465 are used for submission user USERNAME # Use your username to log in password PASSWORD # Use your login password enable_starttls_auto true # Use this option to enable STARTTLS from example@gmail.com # Set the sender address to alert@example.com # Set the recipient address subject &apos;HTTP SERVER ERROR&apos; message Total 5xx error count: %s\n\nPlease check your Apache webserver ASAP message_out_keys count # Use the &quot;count&quot; field to replace &quot;%s&quot; above &lt;/store&gt;&lt;/match&gt; 请确认： smtp配置正确 td-agent daemon具有适当权限访问log 测试配置 12345systemctl restart td-agent#如果安装了standalone的Fluentdfluentd -c alert-email.conf 数据分析Data Analytics 将数据收集到HadoopFluentd + HDFS: Instant Big Data Collection 背景Fluentd专门用于解决大数据日志收集问题。 HDFS(Hadoop)是一个存储和处理大量数据的选择，但直到最近它才拥有了除Java库之外的可访问的API。本节将展示如何使用Fluentd从HTTP接收数据流并传输到HDFS。 架构 安装本节配置一个单节点用于示例。请在同一节点安装如下软件： Fluentd WebHDFS Output Plug HDFS 12345678#安装插件sudo td-agent-gem install fluent-plugin-webhdfstd-agent-gem list#安装Hadoop#http://hadoop.apache.org/releases.html#在官网上下载对应二进制 Fluentd配置 http input: 1234&lt;source&gt; @type http port 8888&lt;/source&gt; webHDFS output: 123456789&lt;match hdfs.*.*&gt; @type webhdfs host namenode.your.cluster.local port 50070 path &quot;/log/%Y%m%d_%H/access.log.#&#123;Socket.gethostname&#125;&quot; &lt;buffer&gt; flush_interval 10s &lt;/buffer&gt;&lt;/match&gt; HDFS 配置 hdfs-site.xml: 1234567891011121314&lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.support.append&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.support.broken.append&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; 测试 12345curl -X POST -d &apos;json=&#123;&quot;action&quot;:&quot;login&quot;,&quot;user&quot;:2&#125;&apos; \ http://localhost:8888/hdfs.access.testkill -USR1 `cat /var/run/td-agent/td-agent.pid`sudo -u hdfs hadoop fs -lsr /log/ 连接到数据存储Connecting to Data Storages 将Apache logs存储到MongoDB本节使用Fluentd MongoDB Output plugin实时聚合半结构化日志。 安装插件 12sudo td-agent-gem install fluent-plugin-mongotd-agent list 配置 tail input: 123456789&lt;source&gt; @type tail path /var/log/apache2/access_log pos_file /var/log/td-agent/apache2.access_log.pos &lt;parse&gt; @type apache2 &lt;/parse&gt; tag mongo.apache.access&lt;/source&gt; mongodb output: 12345678910111213141516171819202122&lt;match mongo.**&gt; # plugin type @type mongo # mongodb db + collection database apache collection access # mongodb host + port host localhost port 27017 # interval &lt;buffer&gt; flush_interval 10s &lt;/buffer&gt; # make sure to include the time key &lt;inject&gt; time_key time &lt;/inject&gt;&lt;/match&gt; 流处理Stream Processing]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Fluentd</tag>
        <tag>日志处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes]]></title>
    <url>%2F2018%2F06%2F26%2FKubernetes%2F</url>
    <content type="text"><![CDATA[参考： Kubernetes: https://zh.wikipedia.org/wiki/Kubernetes 官方文档: https://kubernetes.io/docs/ 中文文档: http://docs.kubernetes.org.cn/ GitHub: https://github.com/kubernetes/kubernetes etcd: https://coreos.com/etcd/docs/latest/ flannel: https://coreos.com/flannel/docs/latest/ 环境： CentOS7x86_64 Kubernetes v1.11 配置此章节提供了有关安装k8s和配置k8s集群的相关说明。 安装有几种方式创建k8s集群： minikube(自动部署) kubeadm(自动部署) 软件包(建议初学者使用此方式) 使用minikube创建集群Using Minikube to Create a Cluster 目标： 了解k8s集群是什么 了解Minikube是什么 启动一个k8s集群 k8s 集群k8s协调一个高度可用的计算机集群，它们连接起来作为一个单元工作 。k8s以更有效的方式自动化跨集群分发和调整应用程序容器。 k8s集群包含两种类型的资源： Master Nodes Master负责管理集群。它协调集群中的所有活动。Node是工作主机。每个节点有一个Kubelet的Agent，负责管理节点并与Master(API)通信。此外，节点上还应有处理容器操作的工具(如Docker)。生成环境的k8s集群至少有三个节点。用户可通过k8s API直接与集群进行交互。 使用Minikube部署集群: https://github.com/kubernetes/minikubeMinikube是一个工具，它运行一个单节点的k8s集群供开发用户使用。 Linux平台 12345678910111213141516curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 &amp;&amp; \chmod +x minikube &amp;&amp; \sudo mv minikube /usr/local/bin/##安装kubectlcurl -Lo kubectl https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubectl &amp;&amp; \chmod +x kubectl &amp;&amp; \sudo mv kubectl /usr/local/bin/minikube versionminikube startkubectl versionkubectl cluster-infokubectl get nodes kubeadm创建集群安装kubeadm本节介绍了如何安装kubeadm工具。 安装前 2GB RAM+ 2 cpus+ 集群主机网络互通 node上唯一的主机名，MAC，UUID 开放特定端口(防火墙) Swap disabled。必须关闭swap才能使kubelet正常工作。 验证MAC或UUID对每个node都是唯一的 ifconfig -a获取MAC cat /sys/class/dmi/id/product_uuid查看UUID 检查网络适配器 如果k8s组件不可达，请手动添加路由。 检查需要的端口 12345678910111213#masterProtocol Direction Port Range Purpose Used ByTCP Inbound 6443* Kubernetes API server AllTCP Inbound 2379-2380 etcd server client API kube-apiserver, etcdTCP Inbound 10250 Kubelet API Self, Control planeTCP Inbound 10251 kube-scheduler SelfTCP Inbound 10252 kube-controller-manager Self#workerProtocol Direction Port Range Purpose Used ByTCP Inbound 10250 Kubelet API Self, Control planeTCP Inbound 30000-32767 NodePort Services** All 安装docker使用阿里云镜像。kubeadm v1.11.1最高支持Docker 17.03，请注意。 123456789wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repomv docker-ce.repo /etc/yum.repos.dyum install -y docker-ce.x84_64#由于kubeadm不支持最新版的docker，所以需要安装指定版本yum list docker-ce --showduplicatesyum install -y docker-ce-17.03.2.ce 安装kubeadm, kubelet, kubectl kubeadm: 引导集群 kubelet: k8s agent kubectl: command line 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#创建repocat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpgEOF#国外镜像凉凉，所以换用阿里云cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF#禁用防火墙systemctl stop firewalldsystemctl disable firewalld#关闭selinuxsetenforce 0sed -i "s/^SELINUX=permissive/SELINUX=disabled/g" /etc/selinux/config#关闭swap，否则kubelet无法正常使用swapoff -a#将/etc/fstab中swap注释掉sed -i 's/.*swap.*/#&amp;/' /etc/fstab#安装yum install -y epel-release ebtables ethtoolyum install -y kubelet kubeadm kubectlsystemctl enable kubelet &amp;&amp; systemctl start kubelet#系统配置，开启网络桥接cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOF#生效sysctl -p /etc/sysctl.d/k8s.confsysctl --systemsystemctl daemon-reload#各主机时区，时间同步timedatectl set-timezone Asia/Shanghai#crontab -e#ntp*/30 * * * * /sbin/ntpdate 1.cn.pool.ntp.org &gt; /dev/null 2&gt;&amp;1#hosts&lt;master-ip&gt; master&lt;node-ip&gt; node 配置cgroup driver使用docker时，kubelet会将其驱动设置与Docker相同。kubeadm会自动检查kubelet的cgroup驱动，并在运行时将其设置到/var/lib/kubelet/kubeadm-flags.env文件。 12345678910111213docker info | grep -i 'cgroup driver'Cgroup Driver: systemd#此文件是kubeadm init生成的cat /var/lib/kubelet/kubeadm-flags.envKUBELET_KUBEADM_ARGS=--cgroup-driver=systemd --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni#如果此文件未配置此信息，我们手动添加cd /etc/systemd/system/kubelet.service.dvim 10-kubeadm.confKUBELET_KUBEADM_ARGS=--cgroup-driver=systemd --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni 拉取k8s.gcr.io镜像链接: https://console.cloud.google.com/gcr/images/google-containers/GLOBAL?location=GLOBAL&amp;project=google-containers 利用某台能上网的主机，拉取Google上kubeadm需要的k8s.gcr.io/image镜像。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193#查看kubeadm需要使用的imagekubeadm config images listk8s.gcr.io/kube-apiserver-amd64:v1.11.1k8s.gcr.io/kube-controller-manager-amd64:v1.11.1k8s.gcr.io/kube-scheduler-amd64:v1.11.1k8s.gcr.io/kube-proxy-amd64:v1.11.1k8s.gcr.io/pause-amd64:3.1k8s.gcr.io/etcd-amd64:3.2.18k8s.gcr.io/coredns:1.1.3#最好把所有镜像都拉下来，否则后面初始化的时候容易报错#在gcr.io上查找镜像#浏览器访问: &lt;https://console.cloud.google.com/gcr/images/google-containers/GLOBAL?location=GLOBAL&amp;project=google-containers&gt;#找一台能用的服务器，将这些image拉下来，推到自己的repo上再在kubeadm机器上拉取镜像，之后tag成kubeadm需要的格式#写一个脚本自动拉取镜像，更名镜像，推送镜像#我基本上把全部镜像都拉了vim k8sImages.shimages=(coredns:1.1.3etcd-amd64:3.1.15etcd-amd64:3.1.16etcd-amd64:3.1.17etcd-amd64:3.2.17etcd-amd64:3.2.18flannel-amd64:0.5.5heapster-amd64:v1.4.0heapster-amd64:v1.4.1heapster-amd64:v1.4.2heapster-amd64:v1.4.3heapster-amd64:v1.5.0heapster-amd64:v1.5.1heapster-amd64:v1.5.2heapster-amd64:v1.5.3heapster-amd64:v1.5.4heapster-grafana-amd64:v4.4.3heapster-grafana-amd64:v5.0.4heapster-influxdb-amd64:v1.3.3heapster-influxdb-amd64:v1.5.2k8s-dns-dnsmasq-nanny-amd64:1.14.10k8s-dns-dnsmasq-nanny-amd64:1.14.6k8s-dns-dnsmasq-nanny-amd64:1.14.7k8s-dns-dnsmasq-nanny-amd64:1.14.8k8s-dns-dnsmasq-nanny-amd64:1.14.9k8s-dns-kube-dns-amd64:1.14.10k8s-dns-kube-dns-amd64:1.14.5k8s-dns-kube-dns-amd64:1.14.6k8s-dns-kube-dns-amd64:1.14.7k8s-dns-kube-dns-amd64:1.14.8k8s-dns-kube-dns-amd64:1.14.9k8s-dns-sidecar-amd64:1.14.10k8s-dns-sidecar-amd64:1.14.5k8s-dns-sidecar-amd64:1.14.6k8s-dns-sidecar-amd64:1.14.7k8s-dns-sidecar-amd64:1.14.8k8s-dns-sidecar-amd64:1.14.9kube-apiserver-amd64:v1.10.5kube-apiserver-amd64:v1.10.6kube-apiserver-amd64:v1.11.0kube-apiserver-amd64:v1.11.1kube-apiserver-amd64:v1.9.10kube-controller-manager-amd64:v1.10.5kube-controller-manager-amd64:v1.10.6kube-controller-manager-amd64:v1.11.0kube-controller-manager-amd64:v1.11.1kube-controller-manager-amd64:v1.9.10kube-proxy-amd64:v1.10.6kube-proxy-amd64:v1.11.0kube-proxy-amd64:v1.11.1kube-proxy-amd64:v1.9.10kubernetes-dashboard-amd64:v1.6.2kubernetes-dashboard-amd64:v1.6.3kubernetes-dashboard-amd64:v1.7.0kubernetes-dashboard-amd64:v1.7.1kubernetes-dashboard-amd64:v1.8.0kubernetes-dashboard-amd64:v1.8.1kubernetes-dashboard-amd64:v1.8.2kubernetes-dashboard-amd64:v1.8.3kube-scheduler-amd64:v1.10.6kube-scheduler-amd64:v1.11.0kube-scheduler-amd64:v1.11.1kube-scheduler-amd64:v1.9.10pause-amd64:3.0pause-amd64:3.1pause:3.1)#可能pause与pause-amd64是一个，到时只需拉一个，然后tagfor image in $&#123;images[@]&#125;do docker pull k8s.gcr.io/$&#123;image&#125; docker tag k8s.gcr.io/$&#123;image&#125; zhang21/$&#123;image&#125; docker image rm k8s.gcr.io/$&#123;image&#125; docker push zhang21/$&#123;image&#125;done#查看docker image ls#到我的docker-hub中查看#https://hub.docker.com/u/zhang21/#现在在kubeadm集群机器上操作#还是写一个脚本来拉取镜像，更名镜像，删除镜像vim k8sImage.shimages=(coredns:1.1.3etcd-amd64:3.1.15etcd-amd64:3.1.16etcd-amd64:3.1.17etcd-amd64:3.2.17etcd-amd64:3.2.18flannel-amd64:0.5.5heapster-amd64:v1.4.0heapster-amd64:v1.4.1heapster-amd64:v1.4.2heapster-amd64:v1.4.3heapster-amd64:v1.5.0heapster-amd64:v1.5.1heapster-amd64:v1.5.2heapster-amd64:v1.5.3heapster-amd64:v1.5.4heapster-grafana-amd64:v4.4.3heapster-grafana-amd64:v5.0.4heapster-influxdb-amd64:v1.3.3heapster-influxdb-amd64:v1.5.2k8s-dns-dnsmasq-nanny-amd64:1.14.10k8s-dns-dnsmasq-nanny-amd64:1.14.6k8s-dns-dnsmasq-nanny-amd64:1.14.7k8s-dns-dnsmasq-nanny-amd64:1.14.8k8s-dns-dnsmasq-nanny-amd64:1.14.9k8s-dns-kube-dns-amd64:1.14.10k8s-dns-kube-dns-amd64:1.14.5k8s-dns-kube-dns-amd64:1.14.6k8s-dns-kube-dns-amd64:1.14.7k8s-dns-kube-dns-amd64:1.14.8k8s-dns-kube-dns-amd64:1.14.9k8s-dns-sidecar-amd64:1.14.10k8s-dns-sidecar-amd64:1.14.5k8s-dns-sidecar-amd64:1.14.6k8s-dns-sidecar-amd64:1.14.7k8s-dns-sidecar-amd64:1.14.8k8s-dns-sidecar-amd64:1.14.9kube-apiserver-amd64:v1.10.5kube-apiserver-amd64:v1.10.6kube-apiserver-amd64:v1.11.0kube-apiserver-amd64:v1.11.1kube-apiserver-amd64:v1.9.10kube-controller-manager-amd64:v1.10.5kube-controller-manager-amd64:v1.10.6kube-controller-manager-amd64:v1.11.0kube-controller-manager-amd64:v1.11.1kube-controller-manager-amd64:v1.9.10kube-proxy-amd64:v1.10.6kube-proxy-amd64:v1.11.0kube-proxy-amd64:v1.11.1kube-proxy-amd64:v1.9.10kubernetes-dashboard-amd64:v1.6.2kubernetes-dashboard-amd64:v1.6.3kubernetes-dashboard-amd64:v1.7.0kubernetes-dashboard-amd64:v1.7.1kubernetes-dashboard-amd64:v1.8.0kubernetes-dashboard-amd64:v1.8.1kubernetes-dashboard-amd64:v1.8.2kubernetes-dashboard-amd64:v1.8.3kube-scheduler-amd64:v1.10.6kube-scheduler-amd64:v1.11.0kube-scheduler-amd64:v1.11.1kube-scheduler-amd64:v1.9.10pause-amd64:3.0pause-amd64:3.1pause:3.1)for image in $&#123;images[@]&#125;do docker pull zhang21/$&#123;image&#125; docker tag zhang21/$&#123;image&#125; k8s.gcr.io/$&#123;image&#125; docker image rm zhang21/$&#123;image&#125;done#查看docker image ls 创建单master集群kubeadm可帮助你引导符合最佳实践的最小化可行的k8s集群。使用kubeadm，你的集群应通过k8s一致性测试。kubeadm还支持其它集群生命周期功能，如升级、降级和管理引导令牌(bootstrap token)。kubeadm旨在成为新用户开始尝试k8s的一种简单方法。可使用deb/rpm软件包在系统上轻松安装kubeadm。因为你可在各种类型的机器上安装kubeadm，所以它非常适合于Ansible/Salt等配置系统集成。 kubeadm的简单性意味着它可以服务于各种用例： 新用户可以从kubeadm开始，第一次尝试k8s 熟悉k8s的用户可以使用kubeadm启动集群，并测试他们的应用程序 较大的项目可以包括kubeadm作为更复杂系统中的构件，也可以包括其它安装程序工具 kubeadm Maturity(成熟度) Area Maturity Level Command line UX beta Implementation beta Config file API alpha Self-hosting alpha kubeadm alpha subcommands alpha CoreDNS GA DynamicKubeletConfig alpha kubeadm的整体功能状态为Beta，并将很快添加到GA(General Availability)。一些子功能，如自托管(self-hosting)和配置文件API仍在积极开发中。 k8s版本通常支持九个月，这也适用于kubeadm。 Kubernetes version Release month End-of-life-month v1.6.x March 2017 December 2017 v1.7.x June 2017 March 2018 v1.8.x September 2017 June 2018 v1.9.x December 2017 September 2018 v1.10.x March 2018 December 2018 v1.11.x June 2018 March 2019 开始前 一台或多台主机 2GB+ RAM(每台机器) 2CPUs+(master) 网络互通 目标 安装 单master/高可用性 的k8s集群 在集群上安装pod-network，以便pod间可互相通信 组件 123456789101112131415#Masteretcdkube-apiseverkube-controller-managerkube-schedulerkube-flannelkube-proxykube-dnskubectl#Nodekube-flannelkube-proxykubectl 说明 安装kubeadm如已安装，可升级到最新版。 初始化集群master主机是控制组件运行的地方，包括etcd, API server… 1234567891011121314151617#1#选择一个 pod network add-on，并验证是够需要将任何参数传递给kubeadm初始化。你可以使用--pod-network-cidr来指定特定值#这里使用flannel#2，可选#除非另有说明，否则kubeadm使用与默认网关关联的网络接口来通告master#使用kubeadm init --apiserver-advertise-address=&lt;ip-addr&gt;来使用不同网络接口#3，可选#在kubeadm init之前运行kubeadm config images pull以验证与gcr.io的连接#或kubeadm config images list查看需要的镜像#运行kubeadm init &lt;args&gt; 更多信息kubeadm init首先运行一系列检查，以确保机器 已准备好运行k8s。这些预检查会显示警告并退出错误。然后kubeadm init下载并安装集群控制组件。这可能需要一些时间。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171kubeadm --helpkubeadm init --help#k8s底层环境依赖于Docker#on mastersystemctl enable docker kubelet &amp;&amp; systemctl start dockerkubeadm initI0806 14:04:54.415853 2191 feature_gate.go:230] feature gates: &amp;&#123;map[]&#125;[init] using Kubernetes version: v1.11.1[preflight] running pre-flight checks [WARNING Service-Docker]: docker service is not enabled, please run &apos;systemctl enable docker.service&apos;I0806 14:04:54.433879 2191 kernel_validator.go:81] Validating kernel versionI0806 14:04:54.433934 2191 kernel_validator.go:96] Validating kernel config[preflight/images] Pulling images required for setting up a Kubernetes cluster[preflight/images] This might take a minute or two, depending on the speed of your internet connection[preflight/images] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;[preflight] Some fatal errors occurred: [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-apiserver-amd64:v1.11.1]: exit status 1 [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-controller-manager-amd64:v1.11.1]: exit status 1 [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-scheduler-amd64:v1.11.1]: exit status 1 [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-proxy-amd64:v1.11.1]: exit status 1 [ERROR ImagePull]: failed to pull image [k8s.gcr.io/pause-amd64:3.1]: exit status 1 [ERROR ImagePull]: failed to pull image [k8s.gcr.io/etcd-amd64:3.2.18]: exit status 1 [ERROR ImagePull]: failed to pull image [k8s.gcr.io/coredns:1.1.3]: exit status 1[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`#此处错误，由于镜像在Google，国内访问会超时。因此需要额外准备镜像。#需要做上面一步操作来拉取镜像#初始化#请确保资源满足条件，我就是由于VM内存为1GB而导致初始化失败，找了很久才找到这个错误kubeadm init --kubernetes-version=v1.11.1 --pod-network-cidr=10.244.0.0/16[init] using Kubernetes version: v1.11.1[preflight] running pre-flight checksI0807 14:47:10.658405 10612 kernel_validator.go:81] Validating kernel versionI0807 14:47:10.658484 10612 kernel_validator.go:96] Validating kernel config[preflight/images] Pulling images required for setting up a Kubernetes cluster[preflight/images] This might take a minute or two, depending on the speed of your internet connection[preflight/images] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;[kubelet] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;[kubelet] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;[preflight] Activating the kubelet service[certificates] Generated ca certificate and key.[certificates] Generated apiserver certificate and key.[certificates] apiserver serving cert is signed for DNS names [master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.31.49][certificates] Generated apiserver-kubelet-client certificate and key.[certificates] Generated sa key and public key.[certificates] Generated front-proxy-ca certificate and key.[certificates] Generated front-proxy-client certificate and key.[certificates] Generated etcd/ca certificate and key.[certificates] Generated etcd/server certificate and key.[certificates] etcd/server serving cert is signed for DNS names [master localhost] and IPs [127.0.0.1 ::1][certificates] Generated etcd/peer certificate and key.[certificates] etcd/peer serving cert is signed for DNS names [master localhost] and IPs [192.168.31.49 127.0.0.1 ::1][certificates] Generated etcd/healthcheck-client certificate and key.[certificates] Generated apiserver-etcd-client certificate and key.[certificates] valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/admin.conf&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/kubelet.conf&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/controller-manager.conf&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/scheduler.conf&quot;[controlplane] wrote Static Pod manifest for component kube-apiserver to &quot;/etc/kubernetes/manifests/kube-apiserver.yaml&quot;[controlplane] wrote Static Pod manifest for component kube-controller-manager to &quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&quot;[controlplane] wrote Static Pod manifest for component kube-scheduler to &quot;/etc/kubernetes/manifests/kube-scheduler.yaml&quot;[etcd] Wrote Static Pod manifest for a local etcd instance to &quot;/etc/kubernetes/manifests/etcd.yaml&quot;[init] waiting for the kubelet to boot up the control plane as Static Pods from directory &quot;/etc/kubernetes/manifests&quot; [init] this might take a minute or longer if the control plane images have to be pulled[apiclient] All control plane components are healthy after 42.001662 seconds[uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace[kubelet] Creating a ConfigMap &quot;kubelet-config-1.11&quot; in namespace kube-system with the configuration for the kubelets in the cluster[markmaster] Marking the node master as master by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;[markmaster] Marking the node master as master by adding the taints [node-role.kubernetes.io/master:NoSchedule][patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;master&quot; as an annotation[bootstraptoken] using token: uzdl9x.91uu2p155jczkgb3[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes master has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/You can now join any number of machines by running the following on each nodeas root: kubeadm join 192.168.31.49:6443 --token uzdl9x.91uu2p155jczkgb3 --discovery-token-ca-cert-hash sha256:bc5af0f4fbee0d0500c9d6782a279ee172ed45547a006136bfbad93d61ad39c7#root用户#一定要记得做此步骤，由于kubeadm设置的apiserver的监听端口为6443，而不是8080，所以执行会报错。export KUBECONFIG=/etc/kubernetes/admin.conf#之后，可将其写入/etc/profile#安装pod-network#你必须先安装pod network add-on，才能和pod相互通信。#必须在应用程序之前部署网络。#配置flannelkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.10.0/Documentation/kube-flannel.yml#如果无法访问，可将此文件下载到本地#kubectl apply -f /etc/kubernetes/kube-flannel.ymlclusterrole.rbac.authorization.k8s.io/flannel createdclusterrolebinding.rbac.authorization.k8s.io/flannel createdserviceaccount/flannel createdconfigmap/kube-flannel-cfg createddaemonset.extensions/kube-flannel-ds created#token用于master与node之间相互认证，它是加密的。#使用kubeadm token列出、创建和删除token#kubeadm token create#kubeadm token list#on node#kubeadm join#kubeadm join --token xxxxxxxxxxx host:portsystemctl enable kubelet docker &amp;&amp; systemctl start dockerkubeadm join 192.168.31.49:6443 --token uzdl9x.91uu2p155jczkgb3 --discovery-token-ca-cert-hash sha256:bc5af0f4fbee0d0500c9d6782a279ee172ed45547a006136bfbad93d61ad39c7#测试kubectl get nodeNAME STATUS ROLES AGE VERSIONmaster Ready master 48m v1.11.1node Ready &lt;none&gt; 15m v1.11.1#查看kubectl get pods --all-namespaces -o wideNAMESPACE NAME READY STATUS RESTARTS AGE IP NODEkube-system coredns-78fcdf6894-hn46d 1/1 Running 0 52m 10.244.0.3 masterkube-system coredns-78fcdf6894-wqxbx 1/1 Running 0 52m 10.244.0.2 masterkube-system etcd-master 1/1 Running 0 41m 192.168.31.49 masterkube-system kube-apiserver-master 1/1 Running 0 41m 192.168.31.49 masterkube-system kube-controller-manager-master 1/1 Running 0 41m 192.168.31.49 masterkube-system kube-flannel-ds-7gbvd 1/1 Running 0 41m 192.168.31.49 masterkube-system kube-flannel-ds-ktkxp 1/1 Running 0 19m 192.168.31.174 nodekube-system kube-proxy-pw7gz 1/1 Running 0 19m 192.168.31.174 nodekube-system kube-proxy-rhrks 1/1 Running 0 52m 192.168.31.49 masterkube-system kube-scheduler-master 1/1 Running 0 41m 192.168.31.49 master master isolation默认情况下，出于安全原因，你的集群不会在master上调度pod。如果你想在master上调度pod，对于单master的k8s集群，执行如下命令： 12#从拥有它的节点删除node-role.kubernetes.io/master污染kubectl taint nodes --all node-role.kubernetes.io/master- 加入节点要向集群添加新节点，请为每台计算机执行以下操作： 1234567#node#root/sudo#kubeadm init后执行下命令#kubeadm token listkubeadm join --token &lt;token&gt; &lt;master-ip&gt;:&lt;master-port&gt; --discovery-token-ca-cert-hash sha256:&lt;hash&gt; 从master之外控制集群(可选) 12scp root@&lt;master-ip&gt;:/etc/kubernetes/admin.conf .kubeclt --kubeconfig ./admin.conf get nodes 局限性此处创建的集群只有一个master，其上运行一个etcd数据库。这意味着如果master出现故障，你的集群可能会丢失数据。可考虑向k8s添加高可用支持。 使用kubeadm配置kubeletConfiguring each kubelet in your cluster using kubeadm kubeadm CLI工具的生命周期与Kubernetes Node Agent(kubelet)相分离，kubelet是运行在k8s集群master/node上的守护进程，它始终在后台运行。而kubeadm CLI工具由用户执行。由于kubelet是一个守护进程，它需要由init system或服务管理器来维护。Redhat7上使用systemd来进行管理。在集群设计的kubelet中，一些kubelet配置细节需相同；而其它方面则需要在每台机器的kubelet上单独配置。你可以手动管理kubelet配置，但kubeadm现在提供了一个MaterConfig API来集中管理kubelet配置。 注意，本节是利用kubeadm来配置kubelet，而不是手动配置kubelet。 kubelet配置模式 将集群级别配置传播到每个kubeletkubelet提供了一个版本化、结构化的API对象，可配置kubelet中大多数参数，并将此配置推送到集群中所有正在运行的kubelet。它被称为 the kubelet’s ComponentConfig(组件配置) 12345678910111213141516171819#为kubelet提供默认值。kubeadm initkubeadm join#修改服务默认子网kubeadm init --service-cidr 10.96.0.0/12#现在服务的VIP由此子网分配#还需要设置kubelet使用的DNS地址，每个kubelet必须相同--cluster-dns#componentConfigapiVersion: kubelet.config.k8s.io/v1beta1kind: KubeletConfigurationclusterDNS: - 10.96.0.10 提供特定实例的配置细节由于不同硬件、操作系统、网络…，一些主机需要特定的kubelet配置。由于我是使用systemd管理kubelet，所以可相应的修改对应的值。 1234567891011121314151617181920212223242526272829303132#DNS解析文件路径，如果路径错误，则在kubelet配置错误的节点上DNS将解析失败--resolve-conf#节点API对象，默认被设置为主机名.metadata.name#使用如下标志指定节点名来服务默认值--hostname-overide#目前，kubelet无法自动检查CRI runtime的cgroup driver#指定的驱动请与docker保持一致--cgroup-driver#根据集群使用的CRI runtime，可能需要为kubelet指定不同的标志#如，当使用Docker时，你需要指定如 --network-plugin=cni#但，当使用额外runtime，你需要指定 --container-runtime=remote, --container-runtime-path-endpoint=&lt;path&gt;#systemdcd /etc/systemd/system/kubelet.service.d/vim 10-kubeadm.conf#修改具体配置项#EnvFilevim /var/lib/kubelet/kubeadm-flags.envsystemctl daemon-reload &amp;&amp; systemctl restart kubelet 使用kubeadm配置kubeletkubeadm config API的MasterConfiguration类型，嵌入了kubelet&#39;s ComponentConfig到.kubeletConfiguration.baseConfig键下面。任何用户都可编写MasterConfiguration文件使用此配置键为集群中的所有kubelet设置基本配置。 使用kubeadm init的工作流程(workflow)当调用kubeadm init时，.kubeletConfiguration.baseConfig结构被整理到磁盘/var/lib/kubelet/config.yaml，并且上传到集群中的ConfigMap。ConfigMap名为kubelet-config-1.x，.x表示k8s的次要版本。kubelet配置文件同样被写入/etc/kubernetes/kubelet.conf。此配置文件指向允许kubelet与API server通信的客户端证书。 为了解决特定实例的配置细节的模式，kubeadm将环境文件写入/var/lib/kubelet/kubeadm-flags.env，它包含了在启动时传递给kubelet的许多标志。它还包含许多动态参数(如cgroup driver)。 12345678#标志栗子KUBELET_KUBEADM_ARGS=&quot;--flag1=value1, --flag2=value2 ...&quot;#在将这两个文件整理到磁盘后，kubeadm会尝试运行如下两个命令systemctl daemon-reload &amp;&amp; systemctl restart kubelet#在上面两个命令执行成功后，初始化会继续 使用kubeadm join的工作流程当运行kubeadm join命令时，kubeadm使用Bootstrap Token凭据执行TLS bootstrap，它下载kubelet-config-1.x ConfigMap并将其写入/var/lib/kubelet/config.yaml。动态环境文件/vat/lib/kubelet/kubeadm-flags.env的生成方式与kubeadm init完成相同。 12#同样，执行这两条命令systemctl daemon-reload &amp;&amp; systemctl restart kubelet 在kubelet载入新的配置文件后，kubeadm会写入/etc/kubernetes/bootstrap-kubelet.conf KubeConfig文件，该文件包含CA证书和Bootstrap Token。这些由kubelet用于执行TLS Bootstrap并获得唯一的凭证，该凭证存储在/etc/kubernetes/kubelet.conf中。写入文件后，kubelet完成执行TLS Bootstrap. systemd的kubelet管理文件此配置文件在RPM包安装的时候写入/etc/systemd/system/kubelet.service.d/10-kubeadm.conf，它由systemd使用。 123456789101112131415161718192021222324252627282930313233cat /etc/systemd/system/kubelet.service.d/10-kubeadm.conf# Note: This dropin only works with kubeadm and kubelet v1.11+[Service]Environment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf&quot;Environment=&quot;KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml&quot;# This is a file that &quot;kubeadm init&quot; and &quot;kubeadm join&quot; generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamicallyEnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env# This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use# the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file.EnvironmentFile=-/etc/sysconfig/kubeletExecStart=ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS#此文件指定kubeadm为kubelet管理的所有文件的默认位置#TLS Bootstrap/etc/kubernetes/bootstrap-kubelet.conf#unique kubelet identity/etc/kubernetes/kubelet.conf#kubelet&apos;s ComponentConfig/var/lib/kubelet/config.yaml#dynamic env file, KUBELET_KUBEADM_ARGS/var/lib/kubelt/kubeadm-flags.env#user-specified flag overrides, KUBELET_EXTRA_ARGS, 它具有最高优先级/etc/sysconfig/kubelet k8s 二进制文件和包内容 k8s release附带的DEB和RPM包： Package name Description kubeadm Installs the /usr/bin/kubeadm CLI tool and [The kubelet drop-in file(#the-kubelet-drop-in-file-for-systemd) for the kubelet. kubelet Installs the /usr/bin/kubelet binary. kubectl Installs the /usr/bin/kubectl binary. kubernetes-cni Installs the official CNI binaries into the /opt/cni/bin directory. cri-tools Installs the /usr/bin/crictl binary from https://github.com/kubernetes-incubator/cri-tools. 使用kubeadm自定义控制面板配置Customizing control plane configuration with kubeadm kubeadm配置公开以下字段，这些字段可覆盖传递给控制面板组件的默认标志： APIServerExtraArgs ControllerManagerExtraArgs SchedulerExtraArgs 1234567891011121314151617181920212223242526272829303132333435363738#apiserver#栗子apiVersion: kubeadm.k8s.io/v1alpha2kind: MasterConfigurationkubernetesVersion: v1.11.0metadata: name: 1.11-sampleapiServerExtraArgs: advertise-address: 192.168.0.103 anonymous-auth: false enable-admission-plugins: AlwaysPullImages,DefaultStorageClass audit-log-path: /home/johndoe/audit.log#controllermanager#栗子apiVersion: kubeadm.k8s.io/v1alpha2kind: MasterConfigurationkubernetesVersion: v1.11.0metadata: name: 1.11-samplecontrollerManagerExtraArgs: cluster-signing-key-file: /home/johndoe/keys/ca.key bind-address: 0.0.0.0 deployment-controller-sync-period: 50#scheduler#栗子apiVersion: kubeadm.k8s.io/v1alpha2kind: MasterConfigurationkubernetesVersion: v1.11.0metadata: name: 1.11-sampleschedulerExtraArgs: address: 0.0.0.0 config: /home/johndoe/schedconfig.yaml kubeconfig: /home/johndoe/kubeconfig.yaml 使用kubeadm创建高可用集群Creating Highly Available Clusters with kubeadm 使用kubeadm配置etcd高可用集群Set up a Highly Availabile etcd Cluster With kubeadm Troubleshooting kubeadm官方Troubleshooting: https://kubernetes.io/docs/setup/independent/troubleshooting-kubeadm/ 此外，在我启动kubelet之后，kubelet频繁出现一个错误信息： 12345678910111213141516#错误信息#journal -u kubeletkubelet[10720]: E0810 14:32:14.748713 10720 summary.go:102] Failed to get system container stats for &quot;/system.slice/kubelet.service&quot;: failed to get cgroup stats for &quot;/system.slice/kubelet.service&quot;: failed to get container info for &quot;/system.slice/kubelet.service&quot;: unknown container &quot;/system.slice/kubelet.service&quot;#解决方法vim /etc/sysconfig/kubelet#添加额外参数KUBELET_EXTRA_ARGS=&quot;--runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice&quot;#重启服务systemctl restart kubelet 使用软件包创建集群请定义相应的防火墙规则！ 我是CentOS7x86_64，所以只包含了RPM包。 自带的源安装的k8s可能版本比较老，如需较新版本，可以在网上搜索kubernetes rpm包进行手动安装。Rpmfind: https://rpmfind.net/ k8s集群组件 etcd flannel kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy kube-dns kubectl Master etcd flannel kube-apiserver kube-controller-manager kube-scheduler kubectl 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#默认镜像源安装yum install -y etcd flannel kubernetes-master kubernetes-client#配置kubernetes-master#cd /etc/kubernetes#apiserver config controller-manager scheduler#修改监听地址vim apiserverKUBE_API_ADDRESS="--insecure-bind-address=0.0.0.0"#生成环境一定要加上认证，我由于是测试，并未做认证#未添加认证，去掉 KUBE_ADMISSION_CONTROL中的SecurityContextDeny,ServiceAccount#Flag --admission-control has been deprecated, Use --enable-admission-plugins or --disable-admission-plugins instead.#KUBE_ADMISSION_CONTROL="--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota"KUBE_ADMISSION_CONTROL="--enable-admission-plugins=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota"#此处我修改了cidrKUBE_SERVICE_ADDRESSES="--service-cluster-ip-range=172.16.0.0/16"#配置etcd，可先使用默认值#后面可创建etcd-clustervim /etc/etcd/etcd.conf#修改监听地址ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:2379"#创建pod-network，cidr为kube-apiserver中的配置项#/atomic.io/network为flannel_etcd前缀,之后再启动flanneletcdctl mk /atomic.io/network/config '&#123;"Network":"172.16.0.0/16"&#125;'etcdctl lsetcdctl get '/atomic.io/network/config'#配置flannelvim /etc/sysconfig/flanneld#配置后启动systemctl start etcd flannel kube-apiserver kube-controller-manager kube-scheduler#查看[root@master kubernetes]# kubectl get allNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 172.16.0.1 &lt;none&gt; 443/TCP 4m#具体参数请根据实际情况来配置 Node flannel kubelet kube-porxy kubectl 123456789101112131415161718192021222324252627#epelyum install -y flannel kubernetes-node kubernetes-client#ls /etc/kubertes#config kubelet proxy#配置etcd的地址vim /etc/sysconfig/flanneldFLANNEL_ETCD_ENDPOINTS="http://master:2379vim /etc/kubernertes/configKUBE_MASTER="--master=http://master:8080"#修改kubelet地址KUBELET_ADDRESS="--address=node_addr"KUBELET_HOSTNAME="--hostname-override=node_addr"KUBELET_API_SERVER="--api-servers=http://master:8080"#配置后启动systemctl start flanneld kube-proxy kubelet#具体参数请根据实际情况来配置 验证集群 123#Master#kubectl安装如前kubectl get nodes 安装较新的k8s由于自带的源k8s版本比较低，可能我们需要较新的k8s版本。 12345678910111213141516171819202122#安装较新的Kubernetes浏览器访问 https://rpmfind.net/搜索：kubernetes-master(x86-64)kubernetes-node(x86-64)kubernetes-client(x86-64)选择合适的版本进行下载，三者版本请一致安装步骤和下面类似请注意，k8s组件安装好后，还需要安装额外组件。如docker, flannel, etcd...#masteryum install -y k8s-master k8s-client#nodeyum install -y k8s-node k8s-client k8s-release生成rpm包kubernetes-release: https://github.com/kubernetes/release 使用k8s-release手动生成rpm/dep包。由于yum源更不上k8s的更新速度，所以才需要我们手动制作。 需要安装并运行Docker，它要运行一个rpm-builder容器。 它生成一下rpm包： kubeadm kubelet kubectl 官方说明： 12345678910111213141516171819202122232425262728293031323334353637git clone https://github.com/kubernetes/release.gitcd ./release/rpm./docker-build.sh#此处如果连接google下载超时的话，可以在其它主机上下载，然后复制到此目录下#成功----------------------------------------RPMs written to:cri-tools-1.11.0-0.x86_64.rpm kubectl-1.11.0-0.x86_64.rpm kubernetes-cni-0.6.0-0.x86_64.rpmkubeadm-1.11.0-0.x86_64.rpm kubelet-1.11.0-0.x86_64.rpm repodataYum repodata written to:5e470d3c1c28cdd798237a48172b46f753655edee30988f4fde7000fde859d5a-primary.xml.gz9497c84e5650b15bf6edcffb68900b4f59f7271fa6318d3c0336386c99afd2d8-other.xml.gz94da9da6abd2dc8364ef51b4ca135b804deef0a37f1f13e4abeee455a8b0e897-primary.sqlite.bz2971e5af9d861f5ba85b12bad481749aa26546051090fa4e21c2393c21590dd5a-filelists.xml.gzb752df67070ff5552bd3137f00fb217578f1d810084a3e42579a53eee2a26085-other.sqlite.bz2f0ec7692c0654c1ec5ad9c8576ebe5b8f135c45b5d5242066df6e2d631a3ef6f-filelists.sqlite.bz2repomd.xml#会在./release/rpm/output/x86_64下生成特定版本的rpm包pwd#/root/release/rpm/output/x86_64ls -ltotal 47056-rw-r--r-- 1 root root 4383318 Aug 3 10:25 cri-tools-1.11.0-0.x86_64.rpm-rw-r--r-- 1 root root 7906382 Aug 3 10:25 kubeadm-1.11.0-0.x86_64.rpm-rw-r--r-- 1 root root 7859238 Aug 3 10:25 kubectl-1.11.0-0.x86_64.rpm-rw-r--r-- 1 root root 19012182 Aug 3 10:25 kubelet-1.11.0-0.x86_64.rpm-rw-r--r-- 1 root root 9008530 Aug 3 10:25 kubernetes-cni-0.6.0-0.x86_64.rpmdrwxr-xr-x 2 root root 4096 Aug 3 10:25 repodata 请注意，默认会自动编译所有平台。如果只需要x84_64，可以更改entry.sh文件，将其它平台去掉，以加快编译速度。 123456789vim ./release/rpm/entry.sh ARCHS=( amd64/x86_64 #arm/armhfp #arm64/aarch64 #ppc64le/ppc64le #s390x/s390x ) 后面还是需要使用kubeadm来进行引导！ 编译源码生成rpm包参考： How to build Kubernetes RPM: https://mritd.me/2017/07/12/how-to-build-kubernetes-rpm/ 由于墙的原因，使用kubeadm进行引导还是会timeout。使用自带的yum源或网上下载的k8s rpm可能也不是最新的版本。因此需要手动编译源码以生成rpm包。 生成如下rpm包： kubernetes-master kubernetes-client kubernetes-node k8s Dashboard说明: GitHub: https://github.com/kubernetes/dashboard image: kubernetes-dashboard-amd64:v1.8.3 FAQ: https://github.com/kubernetes/dashboard/wiki/FAQ Let’s Encrypt: https://letsencrypt.org/ Let’s Encrypt是一个免费，自动化和开放的证书颁发机构。 快速配置Quick setup 快速部署kubernetes-dashboard的方法请参考README。它适用于k8s新手并希望快速开始使用Dashboard的人。其它配置适用于有一定经验的用户，详情在以下章节。 k8s Dashboard是k8s集群的基于Web的通用UI。它允许用户管理运行在集群中的应用程序，并对应用程序进行故障排除，以及管理集群本身。 请注意，Dashboard使用了安全设置。这意味着，默认情况下它具有最小的权限集，并且只能通过https访问。建议在安装和执行Dashboard之前，先阅读Access Control指南。 1234567891011121314151617181920212223242526272829303132333435363738kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml#或#wget https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml#kubectl apply -f /path/kubernetes-dashboard.yamlsecret/kubernetes-dashboard-certs createdserviceaccount/kubernetes-dashboard createdrole.rbac.authorization.k8s.io/kubernetes-dashboard-minimal createdrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard-minimal createddeployment.apps/kubernetes-dashboard createdservice/kubernetes-dashboard created#查看kubectl get pods -n kube-system -o wide |grep dashboardkubernetes-dashboard-6948bdb78-rnnjp 1/1 Running 1 1d 10.244.1.2 node kubectl get service -n kube-system -o wide |grep dashboardkubernetes-dashboard ClusterIP 10.110.83.129 &lt;none&gt; 443/TCP 13m k8s-app=kubernetes-dashboard#要从本地访问Dashboard，必须为k8s集群创建安全通道kubectl applyStarting to serve on 127.0.0.1:8001#访问Dashboardhttp://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#http://localhost:8001/ui已弃用#&lt;h3&gt;Unauthorized&lt;/h3&gt;#会直接报403，还需要做前面所说的操作。#Heapster必须在集群中运行才能使metric, graphs可用#Heapster已被弃用，请考虑使用metrics-server和第三方metrics pipeline收集Prometheus格式的指标 安装Installation 官方版当从旧版Dashboard升级到 v1.7+，请确保删除kubernetes-dashboard服务账户的集群角色绑定，否则Dashboard将具有对集群的完全管理权限。 快速配置快速部署kubernetes-dashboard的方法请参考README。它适用于k8s新手并希望快速开始使用Dashboard的人。 推荐配置直接访问Dashboard(不是kubectl proxy)，应该使用有效的证书来建立安全的HTTPS连接。它们可由公共可信证书颁发机构(如Let’s Encrypt)生成，使用它们替代Dashboard自动生成的证书。 此配置要求证书存储在kube-system命名空间中名为kubernetes-dashboard-certs的证书中。假设你有存储在$HOME/certs目录下的dashboard.crt和dashboard.key文件。你应该使用这些文件创建secret。之后，便可以开始配置Dashboard。 123456789101112131415161718192021#查看kubectl get secret -n kube-system | grep dashboard#查看kubectl describe secret/kubernetes-dashboard-certs -n kube-systemName: kubernetes-dashboard-certsNamespace: kube-systemLabels: k8s-app=kubernetes-dashboardAnnotations:Type: OpaqueData====#创建kubectl create secret generic kubernetes-dashboard-certs --from-file=$HOME/certs -n kube-system#部署Dashboardkubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml 替代配置此配置并不安全。不使用证书，仅通过HTTP公开Dashboard。在此配置中，只能通过使用Authorization Header功能来确保访问控制。 12#配置kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/alternative/kubernetes-dashboard.yaml 开发版不建议在线上环境使用开发版，请使用稳定的正式版。 12#部署kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard-head.yaml 升级安装后，Deployment不会自动更新。为了更新它，你需要删除部署的pod并等待它重新创建。重新创建之后，它会使用最新的镜像image:latest. 12#删除podkubectl -n kube-system delete $(kubectl -n kube-system get pod -o name | grep dashboard) 证书管理Certificate management 本节简短介绍了如何获取可在Dashboard中启用HTTPS的证书。有两个步骤要做： 生成证书 证书认证机构(Certificate Authority) 自签名证书(Self-signed certificate) 将证书传递给Dashboard 按照前面的推荐配置方法 其它情况，你需要修改Dashboard的YAML部署文件，并将--tls-key-file, --tls-cert-file传递给Dashboard 公众信任的证书认证机构Public trusted Certificate Authority 有许多公共和免费的证书提供商可供选择。如前面提到的Let’s encrypt，具体操作查看此网站说明。 自签名证书Self-signed certificate 如果你打算自己生成证书，你需要像OpenSSL这样的库来帮助你。 生成私钥(private key)和证书签名请求(certificate signing request) 生成SSL证书 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#Generate private key and certificate signing request#创建SSL证书需要私钥和证书签名请求openssl genrsa -des3 -passout pass:x -out dashboard.pass.key 2048openssl rsa -passin pass:x -in dashboard.pass.key -out dashboard.keyrm dashboard.pass.key#需要填写一些信息#A challenge password []请直接按回车，不要填写内容openssl req -new -key dashboard.key -out dashboard.csrCountry Name (2 letter code) [XX]:CNState or Province Name (full name) []:SCLocality Name (eg, city) [Default City]:CDOrganization Name (eg, company) [Default Company Ltd]:StudentOrganizational Unit Name (eg, section) []:HTCommon Name (eg, your name or your server&apos;s hostname) []:Zhang21Email Address []:reds@zhang21.cnPlease enter the following &apos;extra&apos; attributesto be sent with your certificate requestA challenge password []:An optional company name []:#Generate SSL certificate#自签名SSL证书由 .key私钥 和 .csr生成openssl x509 -req -sha256 -days 1000 -in dashboard.csr -signkey dashboard.key -out dashboard.crtSignature oksubject=/C=CN/ST=SC/L=CD/O=Student/OU=HT/CN=Zhang21/emailAddress=reds@zhang21.cnGetting Private key#查看lsdashboard.crt dashboard.csr dashboard.key#将密钥和证书移动到需要的目录下mv ./dashboard.* /etc/kubernetes/pki/dashboard#接下来便可以创建secret了 访问DashboardAccessing Dashboard 在集群上安装Dashboard后，可通过几种不同的方式访问它。遇到什么问题，可查看FAQ。 1.6.x and below 1.7.x and above 1.7.x and aboveAccessing Dashboard 1.7.X and above 我的Dashboard v1.8.5. 前面的HTTP/HTTPs都不说了。但请注意，不要把Dashboard使用HTTP公开展示。 kubectl proxykubectl proxy在你的计算机和k8s APIserver之间创建代理服务器。默认情况下它只能在本地访问。 注意，不应该使用kubectl proxy命令公开Dashboard，因为它只允许HTTP连接。对于localhost和127.0.0.1以外的域，将无法登录。 首先让我们检查kubectl是否已正确配置并是否可访问集群: 123456789101112131415kubectl cluster-info#Kubernetes master is running at https://192.168.31.49:6443#KubeDNS is running at https://192.168.31.49:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy#启动代理服务器kubectl proxy#Starting to serve on 127.0.0.1:8001#之后你便可以从浏览器访问Dashboard#http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#但我访问还是403，应该还需要创建Service Token之类。 NodePort这种访问Dashboard的方式，建议用于单节点设置的开发环境中。请注意，此HTTPS方式需要安装前面生成的证书。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#编辑 kubernetes-dashboard服务kubectl -n kube-system edit service/kubernetes-dashboard# Please edit the object below. Lines beginning with a '#' will be ignored,# and an empty file will abort the edit. If an error occurs while saving this file will be# reopened with the relevant failures.#apiVersion: v1kind: Servicemetadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"v1","kind":"Service","metadata":&#123;"annotations":&#123;&#125;,"labels":&#123;"k8s-app":"kubernetes-dashboard"&#125;,"name":"kubernetes-dashboard","namespace":"kube-system"&#125;,"spec":&#123;"ports":[&#123;"port":443,"targetPort":8443&#125;],"selector":&#123;"k8s-app":"kubernetes-dashboard"&#125;&#125;&#125; creationTimestamp: 2018-08-09T01:14:01Z labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kube-system resourceVersion: "200618" selfLink: /api/v1/namespaces/kube-system/services/kubernetes-dashboard uid: 80091845-9b71-11e8-a08a-000c298ee39fspec: clusterIP: 10.110.83.129 ports: - port: 443 protocol: TCP targetPort: 8443 selector: k8s-app: kubernetes-dashboard sessionAffinity: None type: ClusterIPstatus: loadBalancer: &#123;&#125;#将 type: ClusterIP 修改为 type: NodePorttype: NodePort#直接保存退出(:wq)#service/kubernetes-dashboard edited#查看kubectl -n kube-system get service/kubernetes-dashboardNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes-dashboard NodePort 10.110.83.129 &lt;none&gt; 443:31965/TCP 6h#查看端口netstat -nltup | grep 31965tcp6 0 0 :::31965 :::* LISTEN 11280/kube-proxy#Dashboard展示在 31965(HTTPS) 端口上。#现在可在浏览器访问 &lt;master-ip&gt;:31965#可使用Nginx做前端代理#此处注意，需要将dashboard.crt证书安装到你的电脑上#不然浏览器会拒绝#如果你尝试在多节点集群上使用`NodePort`公开Dashboard，则必须找到运行Dashboard的节点的IP才能访问它。https://&lt;node-ip&gt;:&lt;nodeport&gt; 由图可看出，还需要配置权限才能够正常访问Dashboard！ API Server如果公开k8s API server并可以从外部访问，则你可直接访问url。Dashboard: https://master-ip:apiserver-port/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/ 注意，只有在浏览器中安装证书时，才能使用这用访问方式。 IngressDashboard可以使用 ingress 进行公开。详情: https://kubernetes.io/docs/concepts/services-networking/ingress/ Nginx反向代理直接使用NodePort方式访问比较麻烦，所以配置使用Nginx反向代理来访问。 Nginx配置文件: 1234567891011121314151617181920212223242526272829303132333435vim /etc/nginx/conf.d/k8sUI.confserver &#123; listen 443 ssl; server_name k8s.ui; ssl_certificate /etc/kubernetes/pki/dashboard/dashboard.crt; ssl_certificate_key /etc/kubernetes/pki/dashboard/dashboard.key; location / &#123; proxy_pass https://127.0.0.1:31965; proxy_read_timeout 60s; proxy_send_timeout 60s; proxy_connect_timeout 60s; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_404; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &apos;upgrade&apos;; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto https; proxy_buffer_size 64k; proxy_buffers 4 64k; proxy_busy_buffers_size 128k; proxy_temp_file_write_size 128k; &#125;&#125;nginx -tnginx -s reload 之后解析DNS，就可直接通过域名访问了。 访问控制Access Control 安装Dashboard后，我们便可以专注于为用户配置对集群资源的访问控制。从 v1.7 开始，Dashboard默认不再具有完全管理权限(admin privilige)，所有权限都被撤销，并且只授予了Dashboard工作所需的最小权限。所以下面的介绍都只针对于 v1.7+ 版本。如果Dashboard只能由受信任的人员访问，你可能希望授予他们完全管理权限，则所有人都具有完全管理的权限。请注意，其它应用程序不应直接访问Dashboard，因为它可能导致权限升级。确保集群内的流量仅限于命名空间，或者只是撤销集群内应用程序对Dashboard的访问权限。 可查看kubernetst-dashboard.yaml配置文件，里面有minimal的权限。 介绍k8s支持几种方法来认证(authenticating)和授权(authorizing)用户。授权由k8s API server处理。Dashboard仅充当代理并将所有认证信息传递给API server。在禁止访问的情况下，相应的警告信息会显示到Dashboard上。 默认Dashboard权限 v1.7 create and watch permissions for secrets in kube-system namespace required to create and watch for changes of kubernetes-dashboard-key-holder secret. get, update and delete permissions for secrets named kubernetes-dashboard-key-holder and kubernetes-dashboard-certs in kube-system namespace. proxy permission to heapster service in kube-system namespace required to allow getting metrics from heapster. v1.8 create permission for secrets in kube-system namespace required to create kubernetes-dashboard-key-holder secret. get, update and delete permissions for secrets named kubernetes-dashboard-key-holder and kubernetes-dashboard-certs in kube-system namespace. get and update permissions for config map named kubernetes-dashboard-settings in kube-system namespace. proxy permission to heapster service in kube-system namespace required to allow getting metrics from heapster. Authentication从v1.7版本开始，Dashboard支持的用户认证基于： Authorization: Bearer &lt;token&gt; Bearer Token Username/password Kubeconfig Login view要使其显示在Dashboard中，你需要启用HTTPS访问Dashboard。 使用跳过选项将使Dashboard使用Service Account权限。 Authorization header在通过HTTP访问Dashboard时，使用 authorization header 是使Dashboard充当用户的唯一方法。 要使Dashboard使用authorization header，你只需将每个请求中的Authorization: Bearer &lt;token&gt;传递给Dashboard。这可以通过在Dashboard前端配置反向代理来实现。代理将负责身份提供者的身份验证，并将请求头部中生成的token传递给Dashboard。注意，需要正确配置k8s API server才能接受这些token。 注意： 如果通过API server proxy访问Dashboard，则authorization header将不起作用。这是因为一旦请求到达API server，所有其它header都将被删除。 Bearer Token建议先熟悉k8s authentication doc，以了解如何获取可用于登录的token。例如，每个Service Account都有一个具有有效Bearer token，用于登录Dashboard。 推荐讲座，了解如何创建服务账户并对其进行授权： Service Account Tokens Role and ClusterRole Service Account Permissions 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#使用kubectl获取token#默认情况下，k8s创建了许多服务账号。所有都具有不同的访问权限kubectl -n kube-system get secretNAME TYPE DATA AGEattachdetach-controller-token-bszq5 kubernetes.io/service-account-token 3 2dbootstrap-signer-token-bqv44 kubernetes.io/service-account-token 3 2dbootstrap-token-uzdl9x bootstrap.kubernetes.io/token 7 2dcertificate-controller-token-rsftn kubernetes.io/service-account-token 3 2dclusterrole-aggregation-controller-token-x64f5 kubernetes.io/service-account-token 3 2dcoredns-token-dfmpb kubernetes.io/service-account-token 3 2dcronjob-controller-token-xwtkc kubernetes.io/service-account-token 3 2ddaemon-set-controller-token-vxzp4 kubernetes.io/service-account-token 3 2ddefault-token-5868t kubernetes.io/service-account-token 3 2ddeployment-controller-token-jc6bs kubernetes.io/service-account-token 3 2ddisruption-controller-token-znghk kubernetes.io/service-account-token 3 2dendpoint-controller-token-mnxfh kubernetes.io/service-account-token 3 2dexpand-controller-token-6srzj kubernetes.io/service-account-token 3 2dflannel-token-7548k kubernetes.io/service-account-token 3 2dgeneric-garbage-collector-token-22qd2 kubernetes.io/service-account-token 3 2dhorizontal-pod-autoscaler-token-zs8pj kubernetes.io/service-account-token 3 2djob-controller-token-zbfhd kubernetes.io/service-account-token 3 2dkube-proxy-token-xxp9h kubernetes.io/service-account-token 3 2dkubernetes-dashboard-certs Opaque 3 1hkubernetes-dashboard-key-holder Opaque 2 2dkubernetes-dashboard-token-sgq5t kubernetes.io/service-account-token 3 2dnamespace-controller-token-25n2k kubernetes.io/service-account-token 3 2dnode-controller-token-289v8 kubernetes.io/service-account-token 3 2dpersistent-volume-binder-token-x7t7x kubernetes.io/service-account-token 3 2dpod-garbage-collector-token-xxjqp kubernetes.io/service-account-token 3 2dpv-protection-controller-token-9s4x7 kubernetes.io/service-account-token 3 2dpvc-protection-controller-token-l7m7j kubernetes.io/service-account-token 3 2dreplicaset-controller-token-mszv9 kubernetes.io/service-account-token 3 2dreplication-controller-token-8gl9s kubernetes.io/service-account-token 3 2dresourcequota-controller-token-whljw kubernetes.io/service-account-token 3 2dservice-account-controller-token-h87wp kubernetes.io/service-account-token 3 2dservice-controller-token-qn5jz kubernetes.io/service-account-token 3 2dstatefulset-controller-token-zps2l kubernetes.io/service-account-token 3 2dtoken-cleaner-token-nccrw kubernetes.io/service-account-token 3 2dttl-controller-token-dmmb9 kubernetes.io/service-account-token 3 2dkubectl -n kube-system describe secret/replicaset-controller-token-mszv9Name: replicaset-controller-token-mszv9Namespace: kube-systemLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name=replicaset-controller kubernetes.io/service-account.uid=d18a5f8f-9a0d-11e8-a08a-000c298ee39fType: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 11 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJyZXBsaWNhc2V0LWNvbnRyb2xsZXItdG9rZW4tbXN6djkiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoicmVwbGljYXNldC1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZDE4YTVmOGYtOWEwZC0xMWU4LWEwOGEtMDAwYzI5OGVlMzlmIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOnJlcGxpY2FzZXQtY29udHJvbGxlciJ9.O6hXQwsXdSXREsaao_V7pmeQkfWGEd4QLDxczxNZVcrT2yN9F1KFJ9IklYVlGSTo1cKA4OxkYqjKWzWPBEn6wVLhVbf6_WqTrFi4qEtj_nmhXwqcwkpioJzyXu7x7wljpH-H32bEaLW1l-y5kQBUztF9fAHZZyv0f9vaRK4u4zVzuq4JzauLB9aVBrgt6rSaOENdr8OGm1yjM_--gQtc1qoF8mLo3RK6qLpFjT70EZKgyys_GXpFrrnhG5maUmlFqCPZ6P0cl8d6SuDfkQIlFxNHxtJmOPSCIE6wjgkOncRtgWHRRVsRPnhDGOp0kbmdLTfpOx2zZEiCD5btXL0OkA#我们可以使用显示的token登录Dashboard Basic默认情况下，禁用基本身份认证，也就是用户密码认证。原因是需要使用授权模式RBAC和--basic-auth-file标志配置k8s API server。没有的话，API server会自动回退到匿名用户(anonymous user)，并且无法检查提供的凭据是否有效。 修改--authentication-mode=basic标志在Dashboard中启用基本身份认证，默认值为--authentication-mode=token。 kubeconfig这种登录方法是为了方便起见而提供的。kubeconfig file仅支持--authentication-mode标志指定认证选项。如果它配置为其它方式，Dashboard中将显示错误消息。 Admin privileges注意： 在操作之前，请确保你知道自己在做什么。向Dashboard的服务账号赋予管理权限可能会存在安全风险。 你可以通过创建ClusterRoleBinding来授权Dashboard的服务账号完全的管理权限。 123456789101112131415161718192021222324252627282930313233343536#栗子dashboard-admin.yaml#官方文档版apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: kubernetes-dashboard labels: k8s-app: kubernetes-dashboardroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: kubernetes-dashboard namespace: kube-system#开发版apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: kubernetes-dashboard-head labels: k8s-app: kubernetes-dashboard-headroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: kubernetes-dashboard-head namespace: kube-system 创建示例用户Creating sample user 在本节中，我们将了解如何使用k8s Service Account机制创建新用户，授权用户管理权限并使用与此用户关联的Bearer Token进行登录。关于grant/deny权限，请查看文档authentication和authorization以了解详情。 创建xxx.yaml文件，并使用kubectl create -f xxx.yaml命令创建它们。 创建 Service Account在kube-system命名空间中创建名为admin-user的服务账户: 12345apiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kube-system 12345678#创建kubectl create -f /etc/kubernetes/auth/admin-user_SA.yaml#serviceaccount/admin-user created#查看kubectl -n kube-system get secret | grep admin-user#admin-user-token-qj8hj kubernetes.io/service-account-token 3 56s 创建 ClusterRoleBinding在大多数情况下，在使用kops, kubeadm等管理配置集群后，Role都已存在于集群中。我们可使用它为ServiceAccount仅创建RoleBinding。 注意: ClusterRoleBinding的apiVersion资源可能不同于k8s version。从v1.8开始，它被提升为rbac.authorization.k8s.io/v1。 123456789101112apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kube-system 123#创建kubectl create -f /etc/kubernetes/Auth/cluster-admin_CRB.yaml #clusterrolebinding.rbac.authorization.k8s.io/admin-user created Bearer Token现在我们需要去找到用于登录的Token。 123456789101112131415kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk &apos;&#123;print $1&#125;&apos;)Name: admin-user-token-qj8hjNamespace: kube-systemLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name=admin-user kubernetes.io/service-account.uid=58d39b31-9c40-11e8-a08a-000c298ee39fType: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 11 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLXFqOGhqIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI1OGQzOWIzMS05YzQwLTExZTgtYTA4YS0wMDBjMjk4ZWUzOWYiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.4hCqFj7R7CwAewnFxsy5QC91v6288T7aOCZXae7AbqXECiFb2yB5x7VQs0GjnUj8jbSZamBpI_D6D7p8PoRUmPZg2NOF46TEztsR9wcsEywUr6EHdXMGy6HUtvedy45K1j9h8oFp9nAqvxa6M7hrfV_yy-XlJdqTo7J06VlT_czpWNScCkjejIOlZXFvYL5f5ha0V4L5XCdlFkf7DYbsNV6odquIKavg270g4nAr1ZAJ14SjeFdfRVvimS4N-W7pb9vmOeZBnAmGuotKoqU1OlzZrMfpsPGIXy5GW3zD8PvsbGU9Xn6lyPHH08X0kXCUACQHx4UiaMFzlnhaC2XIMQ 现在复制Token来登录. HeapsterGitHub: https://github.com/kubernetes/heapster 注意: Heapster已被启用，考虑使用metric-server和第三方metric pipeline来收集Prometheus格式的指标。 Heapster 启用时间轴 Kubernetes Release Action Policy/Support Kubernetes 1.11 Initial Deprecation No new features or sinks are added. Bugfixes may be made. Kubernetes 1.12 Setup Removal The optional to install Heapster via the Kubernetes setup script is removed. Kubernetes 1.13 Removal No new bugfixes will be made. Move to kubernetes-retired organization. metric-serverGitHub: https://github.com/kubernetes-incubator/metrics-server 具体详情可参考README。 12345678910111213141516171819202122232425262728293031323334353637383940414243#下载到本地git clone https://github.com/kubernetes-incubator/metrics-server.git#移动到管理目录mv metrics-server/ /etc/kubernetes/#k8s v1.8+ls /etc/kubernetes/metrics-server/deploy/v1.8+/auth-delegator.yaml auth-reader.yaml metrics-apiservice.yaml metrics-server-deployment.yaml metrics-server-service.yaml resource-reader.yaml#注意metrics-server-deployment.yaml文件，需要一个镜像，请准备#gcr.io/google_containers/metrics-server-amd64:v0.2.1docker pull zhang21/metrics-server-amd64:v0.2.1docker tag zhang21/metrics-server-amd64:v0.2.1 gcr.io/google_containers/metrics-server-amd64:v0.2.1#创建#注意，在顶层进行创建cd /etc/kubernetes/metrics-serverkubectl create -f deploy/v1.8+/clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator createdrolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader createdapiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io createdserviceaccount/metrics-server createddeployment.extensions/metrics-server createdservice/metrics-server createdclusterrole.rbac.authorization.k8s.io/system:metrics-server createdclusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created#查看kubectl -n kube-system get deploymentNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEcoredns 2 2 2 2 2dkubernetes-dashboard 1 1 1 1 19hmetrics-server 1 1 1 0 39s pause容器参考: 《Kubernetes之“暂停”容器》: http://dockone.io/article/2785 《Pause容器》: https://jimmysong.io/kubernetes-handbook/concepts/pause-container.html GitHub: https://github.com/kubernetes/kubernetes/tree/master/build/pause Pause容器，又叫Infra容器。它不是pod，而是一个容器。 123456789101112131415161718192021docker ps | grep pause35c9aaa68a06 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_coredns-78fcdf6894-hn46d_kube-system_daab8e60-9a0d-11e8-a08a-000c298ee39f_0d22a1baac736 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_coredns-78fcdf6894-wqxbx_kube-system_daac5838-9a0d-11e8-a08a-000c298ee39f_04d0cdc392629 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_kube-flannel-ds-7gbvd_kube-system_59129dff-9a0f-11e8-a08a-000c298ee39f_04f28747a2044 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_kube-proxy-rhrks_kube-system_da990e28-9a0d-11e8-a08a-000c298ee39f_0f2bd7bd47eb4 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_kube-scheduler-master_kube-system_537879acc30dd5eff5497cb2720a6d64_0d732ffba5530 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_kube-controller-manager-master_kube-system_01c36146e2c80849d7b6993e68aa5e67_0cd7636bac6df k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_kube-apiserver-master_kube-system_1bd24cc043a06bf7e71b96167946c220_0d4adb3504543 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_etcd-master_kube-system_2cc1c8a24b68ab9b46bca47e153e74c6_0#或者是这样#registry.access.redhat.com/rhel7/pod-infrastructure:latest#rpm包安装kubelet的默认配置KUBELET_POD_INFRA_CONTAINER=&quot;--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest&quot;#kubeadm安装kubelet的默认配置KUBELET_POD_INFRA_CONTAINER=--pod-infra-container-image=k8s.gcr.io/pause:3.1 pause容器的作用k8s中的pause容器主要为每个业务提供以下功能： 在pod中担任Linux命名空间共享的基础 启用pid命名空间，开启init进程 使用pause容器和共享命名空间创建pod示例： 123456789101112131415161718192021222324252627#启动pause，以便可以将容器添加到pod中docker run -d --name pause k8s.gcr.io/pause-amd64:3.1#nginxcat &lt;&lt;EOF &gt;&gt; /tmp/nginx.conf&gt; error_log stderr;&gt; events &#123; worker_connections 1024; &#125;&gt; http &#123;&gt; access_log /dev/stdout combined;&gt; server &#123;&gt; listen 80 default_server;&gt; server_name example.com www.example.com;&gt; location / &#123;&gt; proxy_pass http://127.0.0.1:2368;&gt; &#125;&gt; &#125;&gt; &#125;&gt; EOF#指定网络和命名空间docker run -d --name nginx -v /tmp/nginx.conf:/etc/nginc/nginx.conf -p 8880:80 --net=container:pause --ipc=container:pause --pid=container:pause docker.io/nginx:lates#ghost博客docker run -d --name ghost --net=container:pause --ipc=container:pause --pid=container:pause docker.io/ghost:latest 在这两种情况下，我们将pasue容器指定为我们要加入的命名空间容器。这将有效地创建我们的pod。 访问可以看到ghost通过nginx代理运行。因为网络命名空间在pause, nginx, ghost容器之间共享。而这两个容器的init进程都是pause这个容器。 123456789101112131415161718192021222324252627docker logs -f nginx192.168.31.28 - - [08/Aug/2018:02:00:49 +0000] &quot;GET / HTTP/1.1&quot; 200 3195 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36&quot;192.168.31.28 - - [08/Aug/2018:02:00:49 +0000] &quot;GET /assets/built/screen.css?v=0bf822a279 HTTP/1.1&quot; 200 7360 &quot;http://node:8880/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36&quot;......docker logs -f ghost[2018-08-08 02:00:30] INFO Creating table: posts[2018-08-08 02:00:30] INFO Creating table: users[2018-08-08 02:00:30] INFO Creating table: posts_authors......#查看initdocker exec -it ghost /bin/bashroot@f12a374141a7:/var/lib/ghost# ps -efUID PID PPID C STIME TTY TIME CMDroot 1 0 0 01:55 ? 00:00:00 /pauseroot 5 0 0 01:58 ? 00:00:00 nginx: master process nginx -g daemon off;systemd+ 9 5 0 01:58 ? 00:00:00 nginx: worker processnode 10 0 0 02:00 ? 00:00:03 node current/index.jsroot 127 0 0 02:37 ? 00:00:00 /bin/bashroot 131 127 0 02:37 ? 00:00:00 ps -ef 构建大型集群Building Large Clusters 在k8s v1.11，k8s支持做多5 000个节点的集群。更具体地说，支持满足以下条件的配置： 不超过5 000个node 总量不超过150 000个pod 总量不超过300 000个container 每个节点不超过100个pod 使用salt配置k8sConfiguring Kubernetes with Salt k8s集群能够使用salt进行配置。 验证节点配置Validate Node Setup 节点一致性测试Node Conformance Test 节点一致性测试是一种容器化测试框架，为节点提供系统验证和功能测试。该测试验证节点是够满足k8s的最低要求，通过测试的节点有资格加入k8s集群。 局限Limitations 在k8s v1.5中，节点一致性测试具有如下限制： 节点一致性测试仅支持Docker作为容器runtime 节点先决条件Node Prerequisite 要运行节点一致性测试，节点必须满足与标准k8s节点相同的先决条件。该节点至少要安装一下守护进程: Container Runtime(Docker) Kubelet 运行节点一致性测试Running Node Conformance Test 执行如下步骤： 12345678910111213141516171. 将kubelet执行localhost，测试框架启动一个master来测试kubelet#可使用 --pod-cidr, --cloud-provide标志--api-servers=&quot;http://localhost:8080&quot;2. 运行节点一致性测试# $CONFIG_DIR is the pod manifest path of your Kubelet.# $LOG_DIR is the test output path.sudo docker run -it --rm --privileged --net=host \ -v /:/rootfs -v $CONFIG_DIR:$CONFIG_DIR -v $LOG_DIR:/var/result \ k8s.gcr.io/node-test:0.2#一致性测试的架构支持node-test-adm64node-test-armnode-test-arm64 运行选定测试Running Selected Test 123456789101112#运行指定测试，使用你想要运行的测试的正则表达式 覆盖环境变量FOCUSsudo docker run -it --rm --privileged --net=host \ -v /:/rootfs:ro -v $CONFIG_DIR:$CONFIG_DIR -v $LOG_DIR:/var/result \ -e FOCUS=MirrorPod \ # Only run MirrorPod test k8s.gcr.io/node-test:0.2#跳过指定测试，覆盖环境变量SKIPsudo docker run -it --rm --privileged --net=host \ -v /:/rootfs:ro -v $CONFIG_DIR:$CONFIG_DIR -v $LOG_DIR:/var/result \ -e SKIP=MirrorPod \ # Run all conformance tests but skip MirrorPod test k8s.gcr.io/node-test:0.2 强烈建议仅运行一致性测试，因为它需要更复杂的配置来运行不一致性测试。 概念concepts 概念部分可帮助你了解k8s系统的各个部分以及k8s用于表示集群的抽象，并帮助你更深入地了解k8s的工作原理。 标准词汇Standardized Glossary Annotation用于将任意非标识元数据(metadata)附加到随想的键值对。 Application Architect负责程序高级设计的人员。 Application Developer编写在Kubernetes集群中运行的应用程序的人。 Approver可以审批Kubernetes代码贡献的人。 CLA(Contributor License Agreement)贡献者向开源项目授予其贡献许可的条款。 Certificate一个加密安全文件，用于验证对Kubernetes集群的访问的加密。 Cloud Controller Manager Cloud Provider Cluster一组称为节点(node)的机器，运行着由Kubernetes管理的容器化的应用程序。 Cluster Architect设计一个或多个Kubernetes集群的基础架构的人。 Cluster Operator配置，控制和监控集群的人。 Code Contributor为Kubernetes开源代码库开发和共享代码的人。 ConfigMap一个API对象，用于在键值对中存储非机密的数据。可认为是环境变量，命令行参数… Container一个轻量化和可移植的包含应用程序及其依赖项的可执行的镜像。 Container Environment Variables容器环境变量是name/value对，为Pod中运行的容器提供有用的信息。 Contributor捐赠代码，文档或时间来帮助Kubernetes项目或社区的人。 Controller一个控制循环，通过APIServer监视集群的共享状态，并进行修改，尝试将当前状态移至理想(desired)状态。 CronJob管理一个定期运行的工作。 CustomResourceDefinition自定义码，用于定义要添加到Kubernetes APIServer的资源，而无需构建完整的自定义服务器。 DaemonSet确保Pod的副本在集群的一组节点上运行。 Deployment一个管理副本应用程序的API对象 Dynamic Volume Provision允许用户请求自动创建存储卷。 etcd一致且高度可用的键值存储，用作Kubernetes所有集群数据的备份存储。 Helm Chart可以使用Helm工具管理的预配置Kubernetes资源包。 Horizontal Pod Autoscaler一个API资源，可根据目标CPU利用率或自定义的指标自动调整Pod副本数。 Image一个容器的存储实例，其中包含运行一个应用程序需要的一组软件。 Ingress一个管理集群中服务的外部访问的API对象，通常是HTTP。 Init Container一个或多个初始化容器，必须在任意应用程序容器运行之前完成运行。 Istio一个开放平台，提供统一的方式来继承微服务，管理流量，实施策略和聚合遥测数据。 Job运行完成的 有限/一批 任务。 Kops一个命令行工具，可帮助你创建，销毁，升级和维护生产级、高可用性的Kubernetes集群。(仅支持AWS) Kubeadm一个快速安装Kubernetes和设置安全集群的工具。 Kubectl用于与Kubernetes APIServer通信的命令行工具。 Kubelet在集群的每个节点上运行的Agent。它确保容器运行在Pod中。 Kubernetes API通过RESTful接口提供Kubernetes功能的应用程序，用于存储集群的状态。 Label标记与用户有意义且相关的标识属性的对象。 Minikube一个在本地运行Kubernetes的工具。 Name客户端提供的字符串，用于引用资源URL中的对象。如/api/vi/pods/some-name. Namespace一个抽象概念，用于Kubernetes支持同一物理集群上的多个虚拟集群。 Network Policy允许Pod组如何与其它网络端点进行通信的规范。 Node节点是Kubernetes中的一个工作机器。 Persistent Volume一个表示集群中一块存储的API对象。 Persistent Volume Claim声明定义在一个PersistentVolume中的存储资源，以便可以作为一个volume挂载到容器中。 Pod最小和最简单的Kubernetes对象。Pod表示集群上一组正在运行的容器。 Pod Security Policy启用Pod创建和更新的细粒度授权。 PodPreset一个API对象，在创建时将信息(secrets, volume, env var…)注入到Pod中。 RBAC（role-basesd access control)管理授权决策，允许管理员通过Kubernetes API动态配置访问策略。 ReplicaSet副本集是下一代副本控制器。 Resource Quotas提供限制每个命名空间的聚合资源消耗的约束。 Reviemer在项目的某些部分检查代码质量和正确性的人。 Secret存储敏感信息，如密码，token… Security ContextsecurityContext字段定义Pod或容器的权限和访问控制设置，包括运行时UID和GID。 Selector允许用户根据label过滤资源列表。 Service一个API对象，描述如何访问应用程序，并可以描述端口和负载均衡器。 Service Account为运行在Pod中的进程提供一个标识。 Service Catalog一个扩展API，允许Kubernetes集群中运行的应用程序能够轻松使用外部托管软件，如数据库存储服务。 StatefulSet管理一组Pods的部署和伸缩，并提供有关这些Pod的排序和唯一性的保证。 UIDKubernetes系统生成的一个字符串，用于唯一标识对象。 Volume一个包含数据的目录，可供Pod中的容器访问。 Volume Plugin卷插件可在Pod中集成存储。 kube-apiserver一个Master组件，用于暴露Kubernetes API。它是Kubernetes控制面的前端。 kube-controller-manager一个Master组件，用于运行控制器。 kube-proxy运行在集群中的每一个节点上的网络代理。 kube-schedulerMaster上的组件，用于监测未创建节点新创建的Pod，并选择一个节点供其运行。 概述K8s是什么Kubernetes（常简称为K8s），Kubernetes的名字来自希腊语，意思是“舵手”或“领航员”。K8s是将8个字母“ubernete”替换为“8”的缩写。它用于自动部署、扩展和管理容器化（containerized）应用程序的开源系统。它旨在提供“跨主机集群的自动部署、扩展以及运行应用程序容器的平台”。它支持一系列容器工具, 包括Docker等。 通过Kubernetes你可以： 快速部署应用 快速扩展应用 无缝对接新的应用功能 优化硬件资源，降低成本 Kubernetes特点： 可移植(portable) 可扩展( extensible) 自动化(automatic) 容器优点： 快速创建/部署应用 持续开发、集成和部署(CI/CD) 开发和运维相分离 开发、测试、生产环境的一致性 可移植性 松耦合、分布式、弹性伸缩、微服务化 资源隔离 资源利用 Kubernetes能做什么Kubernetes还允许开发人员从物理和虚拟机脱离，从以主机为中心的基础架构转移到以容器为中心的基础架构。这样可以使用容器固有的全部优点。 Kubernetes满足的应用程序常见需求： Pod 挂载外部存储 分布式secrets 应用健康检查 副本应用实例 横向自动伸缩 服务发现 负载均衡 滚动更新 资源监控 日志采集和存储 自检和调试 认证和授权 这提供了平台即服务(PAAS)的简单性以及基础架构即服务(IAAS)的灵活性，并促进基础设施供应商的可移植性。 Kubernetes不是什么Kubernetes 不是一个传统意义上，包罗万象的PaaS(平台即服务)系统。 不限制支持的应用程序类型，不限制应用程序框架 不提供中间件(如消息中间件)、数据处理框架(如spark)，数据库或集群存储系统 不提供点击即部署的服务市场 不部署代码不构建应用 允许用户选择日志、监控和报警 不提供或授权一个全面的应用程序配置系统/语言 不提供任何机器配置、维护、管理或自我修复系统 你可以自定义你的PAAS，与你选择的CI系统集成，或与Kubernetes一起使用，将你的容器镜像部署到Kubernetes。由于Kubernetes在应用级别而不仅仅在硬件级别上运行，因此它提供了PAAS产品通用的一些功能。如部署、扩展、负载均衡、日志记录、监控等。 k8s组件Kubernetes Components Kubernetes 所需的各种二进制组件, 用于提供齐全的功能。 Master组件Master组件提供的集群控制面(control plane)。Master作出集群的全局决策，以及检测和相应集群事件。Master组件可在集群中任何节点上运行。然而，为了简单，通常在一台机器上启动所有Master组件，并且不会在此机器上运行用户容器。可使用多个机器的设置来构建高可用性能集群。 kube-apiserverkube-apiserver对外展示Kubernetes API。它是Kubernetes前端控制层，任何的资源请求/调用都是通过它提供的接口进行。它被设计为水平扩展，即通过部署更多实例来扩展。 etcd持久化和高可用的K/V存储，用于Kubernetes所有集群数据的后端存储。请始终为k8s集群的etcd数据做备份。 kube-controller-managerMaster上运行的控制器组件，它们是集群中处理常规任务的后台线程。逻辑上讲，每个控制器都是一个单独的进程，但为了降低复杂性，它们都被编译为单个二进制文件并在单个进程中运行。 这些控制器包含： 节点控制器(Node Controller): 负责在节点故障时通知和响应 副本控制器(Replication Controller): 负责维护系统中每个副本控制器对象正确的pod数 端点控制器(Endpoints Controller): 填入端点对象 服务账户(service accoute)和令牌控制器(token controller): 为新的命名空间(namespace)创建默认账户和API访问令牌 cloud-controller-manager云控制器管理器用于与底层云提供商进行交互。它仅运行云提供商特定的控制器循环。你必须在kube-controller-manager中禁用这些controller loops，将--cloud-provider标志设置为external来禁用。 以下控制器具有云提供商依赖关系： 节点控制器: 用于检查云服务商提供的程序 路由控制器: 用于在底层云基础架构中设置路由 服务控制器: 用于创建，更新，删除云服务商提供的负载均衡器 数据卷控制器: 用于创建，附件和挂载卷，以及与云服务商提供的卷进行交互 kube-scheduler监视还未分配节点的新创建的pod，选择一个节点供pod运行。调度决策所考虑的因素包括： 个体/集体的资源需求，硬件/软件/策略的约束，亲和力/反亲和性的规范，工作负载和期限。 Node组件节点(node)组件运行在每个节点，维护运行的pod并提供Kubernetes运行时环境。 kubelet在集群中每个节点上运行的Agent，它确保container运行在pod中。kubelet采用通过各种机制提供的一组PodSpecs，并确保这些PodSpecs中描述的容器运行且健康。kubelet不管理不是由k8s创建的容器。 提供如下功能： 挂载pod所需的数据卷 下载pod的secrets pod中运行docker容器 周期性的容器健康检查 如有需要，通过创建mirror pod将pod的状态报告回系统的其余部分 将节点的状态报告回系统的其余部分 kube-proxy通过维护主机上的网络规则并执行连接转发，来实现Kubernetes服务抽象。 container runtime负责运行容器的软件。k8s支持多种runtimes： docker, rkt, runc… docker, rkt, supervisord, fluentd… Addons扩展是实现集群功能的Pod和Service。pod可由Deployment， Replication等管理。命名空间扩展对象在kube-system命名空间中创建。 DNS虽然其它插件并非严格要求，但所有k8s集群都应具有集群DNS，因为许多示例都依赖于它。集群DNS是一个DNS服务器，除了你环境中的DNS服务器，它还为k8s服务提供DNS记录。由k8s启动的容器会在DNS搜索中自动包含此DNS服务器。 Web UI(dashboard)仪表盘。 container resource monitoring记录有关中央数据库中容器的通用时间序列度量标准，并提供用于浏览该数据的UI。 cluster-level logging集群级别的日志记录机制，复制将容器日志保存到具有search/browse界面的中央日志存储。 k8s APIk8s API还可作为系统声明性配置架构的基础。kubectl命令行工具可用于创建，更新，删除和获取API对象。k8s还根据API资源存储其序列化状态(etcd中)。k8s自身被分解为多个组件，这些组件通过其API进行交互。 OpenAPI和Swagger定义完整的API详细信息记录在Swagger v1.2和OpenAPI。k8s apiserver(master)公开了一个API，可用于检索位于/swaggerapi的Swagger v1.2 k8s API.从k8s 1.10开始，OpenAPI规范在单个/openapi/v2端点中提供。单独格式的端点(如swagger.json...)已被弃用，后面会被移除。 通过设置HTTP header指定请求格式: Header Possible Values Accept application/json, application/com.github.proto-openapi.spec.v2@v1.0+protobuf (the default content-type is application/json for / or not passing this header) Accept-Encoding gzip (not passing this header is acceptable) 栗子： Before 1.10 Starting with Kubernetes 1.10 GET /swagger.json GET /openapi/v2 Accept: application/json GET /swagger-2.0.0.pb-v1 GET /openapi/v2 Accept: application/com.github.proto-openapi.spec.v2@v1.0+protobuf GET /swagger-2.0.0.pb-v1.gz GET /openapi/v2 Accept: application/com.github.proto-openapi.spec.v2@v1.0+protobuf Accept-Encoding: gzip 123456789101112131415161718192021222324252627282930313233343536373839#查看curl localhost:8080&#123; &quot;paths&quot;: [ &quot;/api&quot;, &quot;/api/v1&quot;, &quot;/apis&quot;, &quot;/apis/apps&quot;, &quot;/apis/apps/v1beta1&quot;, &quot;/apis/authentication.k8s.io&quot;, &quot;/apis/authentication.k8s.io/v1beta1&quot;, &quot;/apis/authorization.k8s.io&quot;, &quot;/apis/authorization.k8s.io/v1beta1&quot;, &quot;/apis/autoscaling&quot;, &quot;/apis/autoscaling/v1&quot;, &quot;/apis/batch&quot;, &quot;/apis/batch/v1&quot;, &quot;/apis/batch/v2alpha1&quot;, &quot;/apis/certificates.k8s.io&quot;, &quot;/apis/certificates.k8s.io/v1alpha1&quot;, &quot;/apis/extensions&quot;, &quot;/apis/extensions/v1beta1&quot;, &quot;/apis/policy&quot;, &quot;/apis/policy/v1beta1&quot;, &quot;/apis/rbac.authorization.k8s.io&quot;, &quot;/apis/rbac.authorization.k8s.io/v1alpha1&quot;, &quot;/apis/storage.k8s.io&quot;, &quot;/apis/storage.k8s.io/v1beta1&quot;, &quot;/healthz&quot;, &quot;/healthz/ping&quot;, &quot;/healthz/poststarthook/bootstrap-controller&quot;, &quot;/healthz/poststarthook/extensions/third-party-resources&quot;, &quot;/healthz/poststarthook/rbac/bootstrap-roles&quot;, &quot;/logs&quot;, &quot;/metrics&quot;, &quot;/swaggerapi/&quot;, &quot;/ui/&quot;, &quot;/version&quot; ] API 版本为了更容易消除字段或重构资源表示，k8s支持多个API版本，每个版本位于不同的API路径。如/api/vi或/apis/extensions/v1beta1. 我们选择在API级别，而不是资源级别/字段级别进行版本控制，以确保API提供干净、一致的系统资源和行为视图，并允许控制对生命末端和实验性API的访问。json和protobuf序列化模式都遵循相同的模式更改指南。请注意，API版本和软件版本仅间接相关。 不同的API版本意味着不同级别的稳定性和支持： Alpha level 版本名包含alpha(如 v1aplha1) 启用该功能可能会暴露bug，默认禁用 可随时删除对功能的支持，恕不另行通知 可能会在以后软件版本中以不兼容的方式更改，恕不另行通知 由于错误风险和缺乏长期支持，建议仅在短期测试集群中使用 Beta level 版本名包含beta(如 v2beta3) 代码经过充分测试，启用该功能被认为是安全的。默认启用 虽然细节会有所变化，但不会删除对整体功能的支持 建议仅用于非关键业务，因为后续版本可能会发生不兼容的更改 请尝试我们测试版功能并提供反馈 Stable level 版本名是vx，x为整数 许多后续版本的软件将出现稳定版的功能 API groups为了更容易扩展k8s API，我们实施了API Groups，它在REST path和序列化对象的apiVersion字段中指定。 目前在使用的几个API groups: 核心组(core group)，又称遗留组，位于REST path的/api/v1，并使用apiVersion: v1 命名组(named group)，位于REST path的/apis/$GROUP_NAME/$VERSION，并使用apiVersion: $GROUP_NAME/$VERSION 两种受支持的自定义资源扩展API的路径： 自定义资源(CustomResourceDefiniton) 适用于具有非常基本CRUD需求的用户 需要完整k8s API语义的用户可以实现自己的apiserver，并使用聚合器使其无缝连接到客户端 启用 API groups默认情况下启用某些资源和API groups。通过在apiserver设置--runtime-config可启用/禁用它。此配置接收逗号分隔的KV，描述了apiserver运行时配置。 在API groups中启用资源默认情况下启动 DeamonSets, Deployments, HorizontalPodAutoscalers, Ingress, Jobs, ReplicaSets。其它扩展资源可通过在apiserver上设置--runtime-config启用或禁用。 k8s 对象本节解释了如何在k8s API中表示k8s对象，以及如何以.yaml格式表示它们。 理解k8s对象在k8s系统中，k8s对象是持久化的实体。k8s使用这些实体来表示整个集群的状态。特别地，它们描述了如下信息： 哪些容器化应用程序正在运行(以及运行在哪个节点上) 可以被这些应用程序使用的资源 应用程序行为方式的策略(重启、升级、容错) k8s 对象是一个意图记录(record of intent) —— 一旦创建了对象，k8s系统将持续工作以确保对象存在。通过创建一个对象，你可以有效地告诉k8s系统你希望集群的工作负载看起来像什么，这是你的集群的期望状态(desired state)。要使用k8s对象(创建, 修改, 删除)，需要使用k8s API。当你使用kubectl命令行接口时，CLI会为你进行必要的k8s API调用。 对象规约与状态Object Spec and Status 每个k8s 对象都包含了两个嵌套的对象字段，用于控制对象的配置：对象规约和对象状态。在任何时刻，k8s controller plane都会主动管理对象的实际状态，以匹配你提供的期望状态。 规约(spec)，必须提供。描述了对象的期望状态(diresed state)——你希望对象具有的特征。 状态(status)，描述对象的实际状态，由k8s系统提供和更新。 例如，k8s Deployment是一个可以表示你集群上运行的应用程序的对象。当你创建一个Deployment，你可以设置部署规约以指定你希望应用程序运行三个副本。k8s系统读取部署规约并启动应用程序所需的三个实例——更新状态以符合你的规范。如果这些事例中的任何一个失败(状态改变)，k8s系统通过进行校正来响应规约和状态之间的差异。在这种情况下，启动替换实例。 描述k8s 对象在k8s中创建对象时，必须提供描述其期望状态的对象规约，以及有关对象的一些基本信息(如 名称)。当你使用k8s API来创建对象时，API请求必须在请求正文中将信息作为JSON格式。通常，你在.yaml文件中向kubectl提供信息，kubectl在发出API请求时将信息转换为JSON格式。 栗子： 1234567891011121314151617181920# for versions before 1.9.0 use apps/v1beta2apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 使用类似上面的.yaml文件创建部署的方法，是在kubectl命令行工具中使用kubectl create命令，将.yaml文件作为参数传递。 12kubectl create -f https://k8s.io/examples/application/deployment.yaml --record#deployment &quot;nginx-deployment&quot; created 必填字段在要创建k8s 对象的.yaml文件中，必须配置一下字段： apiVersion： 创建对象的k8s API版本 kind： 创建的对象类型 metadata： 有助于识别对象唯一性的数据，包括name, uid, namespace… 你还需要提供spec字段。对于每个k8s对象，对象规约的精确格式是不同的，并且包含特定于该对象的嵌套字段。 NamesKubernetes REST API中所有对象都用Name和UID来明确标识。对于用户提供的非唯一的属性，k8s提供labels和annotations。 Names客户端提供的字符串，用于引用资源URL中的对象。如/api/v1/pods/some-name.一个给定kind的对象同时只能有一个name。但如果你删除了此对象，便可以为新对象赋予此名字。按照惯例，k8s资源的名称的最大长度应为253个字符，并由小写字母,数字, -, .字符组成。但某些资源可能具有更过限制。 UIDsk8s 系统生成的字符串，用于唯一标识对象。在k8s集群的整个生命周期中创建的每个对象都具有一个唯一的UID。它旨在区分类似实体的历史事件。 Namespacek8s支持在物理集群中创建多个虚拟集群，这些虚拟机群称为namespaces。命名空间是一种将集群资源划分为多个用途的方法。命名空间名称满足正则表达式，最大长度为63位。 什么时候使用多个命名空间命名空间旨在用于多个用户分布在多个团队/多个项目的环境中。对于具有几个到几十个用户的集群，你根本不需要创建和考虑命名空间。命名空间提供名称范围。资源名称在命名空间中必须唯一，但不能跨命名空间。命名空间是一种在多个用户之间划分集群资源的方法。在k8s的未来版本中，默认情况下，同一命名空间中的对象将具有相同的访问控制策略(ACP)。没有必要使用多个命名空间仅来分隔略有不同的资源。如同一软件的不同版本，使用labels来区分同一命名空间内的资源。 操作命名空间 12345678910111213141516171819202122232425262728293031323334353637383940#查看kubectl get nsNAME STATUS AGEdefault Active 13dkube-system Active 13d#通过命令创建kubectl create namespace my-namespace#或通过文件创建vim my-namespace.yamlapiVersion: v1kind: Namespacemetadata: name: my-namespacekubectl create -f ./my-namespace.yaml#查看kubectl get namespaceNAME STATUS AGEdefault Active 13dkube-system Active 13dmy-namespace Active 4s#删除kubectl delete namespace my-namespace#设置请求的命名空间#使用--namespace标志临时设置请求的命名空间kubectl kubectl get pods --namespace=default#设置命名空间首选项kubectl config set-context $(kubectl config current-context) --namespace=my-namespacekubectl config view Kubernetes有三个初始的命名空间： default: 没有其它命名空间时，对象的默认命名空间 kube-system: k8s系统创建的对象的命名空间 kube-public: 此命名空间是自动创建的，可供所有用户读取(包括未认证用户)。此命名空间主要用于集群使用，以防止某些资源在整个集群中可见且可公开读取。此命名空间的公共方面只是一个约定，而非要求。 注意： 删除一个命名空间会自动删除所有属于该命名空间的资源 k8s初始化的两个命名空间无法删除 持久化卷(persistent volume)不属于任何命名空间，但持久化卷声明(persistent volume claim)是属于某个特定命名空间的 事件(event)是否属于命名空间取决于产生事件的对象 命名空间和DNS当你创建一个服务(service)，它会创建相应的DNS条目(dns entry)。此条目的格式为&lt;service-name&gt;.&lt;namespace-name&gt;.svc.cluster.local，这表示如果一个容器只是用&lt;service-name&gt;，它将会解析为命名空间本地的服务。这对于在多个命名空间(如 开发/测试/生产)中使用相同的配置非常有用。如果想要扩命名空间访问，则需要使用完全限定的域名(fully qualified domain name)。 不是所有对象都在命名空间中大多数k8s资源(pods, services, replication controller…)都在某些命名空间中。然而，命名空间资源本身并不在命名空间中。并且，低级资源(node, persistentVolumes)并不在任何命名空间中。 查看k8s资源是否在命名空间中： 12kubectl api-resources --namespaced=truekubectl api-resources --namespaced=false Labels和Selectors标签是被关联到对象上的key/value对。标签旨在用于指定对用户有意义且相关的对象的标识属性，但不直接按时核心系统的语义。标签可用于组织和选择对象的子集。标签可在创建时附加到对象，随时可以添加和修改。每个对象可拥有多个标签，对于给定的对象，key必须唯一。 123456789101112131415"metadata": &#123; "labels": &#123; "key1" : "value1", "key2" : "value2", "keyN" : "valueN" &#125;&#125;#栗子"labels": &#123; "release" : "stable", "environment" : "dev", "track" : "daily"&#125; 我们最终将索引(index)和反向索引(reverse-index)标签，用于高效查询和监视，使用它们在UI和CLI中进行排序和分组。我们不希望对非标识(non-identifying)信息使用标签，特别是大型结构化数据。非标识信息应该记录到annorations。 标签使用户能够以松散耦合的方式将自己的组织结构映射到系统对象中，而无需客户端存储这些映射。 语法和字符集有效的label key有两个字段: 可选前缀和名称，用斜杆分隔。名字字段是必须的，小于等于63个字符，以字母数字开头和结尾，还可使用-, _, .三个字符。前缀可选。如果指定，前缀必须是DNS子域，不超过253个字符，后跟斜杆/。如果省略，则假定label key对用户是私有的。向最终用户对象添加标签的自动系统组件(kube-scheduler, kube-apserver…)必须制定前缀。kuberneter.io/前缀保留个k8s核心组件。 有效的label value必须小于等于63个字符，可为空，或以字母数字开头和结尾，还可使用-, _, .三个字符。 label selectors标签不提供唯一性。通常，我们希望许多对象携带相同的标签。通过label selector，客户端/用户 可以识别一组对象。标签选择器是k8s中的核心分组原语。 API目前支持两种类型的选择器: equality-based和set-based。标签选择器可由逗号,分隔的多个要求组成。一个空(empty)标签选择器(zero requirements)，选择集合中的每个对象。一个空(null)标签选择器(仅可用于选择器字段)不选择任何对象。 equality-based requirement基于平等/不平等的要求允许按标签键和值进行过滤。匹配对象必须满足所有指定的标签约束，尽管它们也可能具有其它标签。允许三种运算符:=, ==, !=。 12environment = productiontier != frontend set-based requirement基于集合的标签的要求允许根据一组值过滤键。支持三种操作符: in, notin, exists。 1234environment in (production, qa)tier notin (frontend, backend)partition!partition API LIST and WATCH filteringLIST和WATCH操作可以指定标签选择器来过滤使用查询参数返回的对象集。两个要求都是允许的。两种标签选择器的样式都可使用通过TEST客户端列出或查看资源。 equality-based requirements: ?labelSelector=environment%3Dproduction,tier%3Dfrontend set-based requirements: ?labelSelector=environment+in+%28production%2Cqa%29%2Ctier+in+%28frontend%29 12345678#equality-basedkubectl get pods -l environment=production,tier=frontend#set-basedkubectl get pods -l 'environment in (production),tier in (frontend)'kubectl get pods -l 'environment in (production, qa)'kubectl get pods -l 'environment,environment notin (frontend)' Service and ReplicationController服务所针对的一组pod使用标签选择器进行定义。类似地，副本控制器应该管理的pod数量也使用标签选择器定义。 123456789#json格式&quot;selector&quot;: &#123; &quot;component&quot;: &quot;redis&quot;&#125;#yaml格式selector: component: redis Annotation你可使用k8s annotation(注释)将任意非标识(non-identifying)元数据附加到对象。工具和库等客户端可以检索此元数据。它也是key/value对。Annotations不会被k8s直接使用，其主要目的是方便用户阅读查找。 将元数据追加到对象你可使用label或annotations将原数据追加到k8s对象。标签用于选择对象和查找满足特定条件的对象集合。相反，注释不用于识别和选择对象。 123456"metadata": &#123; "annotations": &#123; "key1" : "value1", "key2" : "value2" &#125;&#125; Field Selectors字段选择器允许你根据一个或多个资源字段的值选择k8s资源。 栗子： 123456789101112131415161718192021222324252627#三种操作符=, ==, !=metadata.name=my-servicemetadata.namespace!=defaultstatus.phase=Pending#kubectl get pods --field-selector status.phase=RunningNAME READY STATUS RESTARTS AGEhello-world-3198537413-138pg 1/1 Running 0 5dhello-world-3198537413-67g6d 1/1 Running 0 5dhello-world-3198537413-bf73l 1/1 Running 0 5dhello-world-3198537413-ddgb3 1/1 Running 0 5dhello-world-3198537413-ffj90 1/1 Running 0 5d#kubectl get ingress --field-selector foo.bar=baz#kubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always#kubectl get statefulsets,services --field-selector metadata.namespace!=default Recommended Labels你可以使用比kubectl和dashboard更多的工具来可视化和管理k8s对象。一组通用的标签允许工具以互操作的方式工作，以所有工具都能理解的通用方式描述对象。除了支持工具之外，推荐的标签还以可查询的方式描述应用程序。 shared labels and annotations共享一个通用的前缀: app.kubernetes.io。没有前缀的标签对用户是私有的。共享前缀可确保共享标签不会干扰自定义用户标签。 为了充分利用这些标签，应将它们应用于每个资源对象。 Key Description Example Type app.kubernetes.io/name The name of the application mysql string app.kubernetes.io/instance A unique name identifying the instance of an application wordpress-abcxzy string app.kubernetes.io/version The current version of the application (e.g., a semantic version, revision hash, etc.) 5.7.21 string app.kubernetes.io/component The component within the architecture database string app.kubernetes.io/part-of The name of a higher level application this one is part of wordpress string app.kubernetes.io/managed-by The tool being used to manage the operation of an application helm string 要说明这些标签的运行情况，请考虑一下StatefulSet对象: 12345678910apiVersion: apps/v1kind: StatefulSetmetadata: labels: app.kubernetes.io/name: mysql app.kubernetes.io/instance: wordpress-abcxzy app.kubernetes.io/version: "5.7.21" app.kubernetes.io/component: database app.kubernetes.io/part-of: wordpress app.kubernetes.io/managed-by: helm 使用kubectl进行对象管理kubectl命令行工具支持多种方式来创建和管理k8s对象。应该只使用一种技术来管理k8s对象。对同一个对象的混合和匹配技术会导致未定义的行为。 Management technique Operates on Recommended environment Supported writers Learning curve Imperative commands Live objects Development projects 1+ Lowest Imperative object configuration Individual files Production projects 1 Moderate Declarative object configuration Directories of files Production projects 1+ Highest 必要的命令Managing Kubernetes Objects Using Imperative Commands 使用k8s命令行工具内置的必要命令，可直接快速创建、更新、删除k8s对象。 权衡kubectl工具支持三种对象管理： Imperative commands(必要的命令) Imperative object configuration(必要的对象配置) Declarative object configuration(声明的对象配置) 创建对象kubectl工具支持动词驱动的命令，用以创建一些最常见的对象类型。这些命令被命名为即使不熟悉k8s对象类型的用户也能够识别。 12345678910#创建一个新的Deployment对象，以在一个或多个pod中运行containerrun#创建一个新的Service对象，以在pod间对流量进行负载均衡expose#创建一个新的Autoscaler对象，用以自动水平伸缩控制器autoscale kubectl工具还支持由对象类型驱动的创建命令。这些命令支持更多对象类型，并且更明确地表达了它们的意图，但要求用户知道他们打算创建的对象类型。 1234create &lt;objecttype&gt; [&lt;subtype&gt;] &lt;instancename&gt;#栗子kubectl create service nodeport &lt;service-name&gt; 更新对象kubectl命令支持动词驱动的命令，用于一些常见的更新操作。 12345678910#通过更新控制器的副本数，水平伸缩控制器，以添加或删除podscale#在对象中添加或删除注释annotate#在对象中添加或删除标签label kubectl工具还支持由对象的某个驱动的更新命令: 12#设置对象的一个方面set kubectl工具支持这些直接地更新实时对象的额外方法，但他们需要更好地裂解k8s对象模式。 123456#通过在编辑器中打开其配置，直接编辑实时对象的原始配置文件edit#使用补丁字符串，直接修改实时对象的特定字段patch 删除对象1234#从集群中删除对象delete &lt;type&gt;/&lt;name&gt;kubectl delete deployment/nginx 查看对象如下这些命令可用于打印除对象信息: 12345678910#打印有关匹配对象的基本信息get#打印有关匹配对象的详细信息describe#打印运行在pod中容器的stdout和stderrlogs 创建对象前修改对象有些对象字段没有可在create命令汇总使用的标志。在某些情况下，你可使用set和create的组合在对象创建之前为字段指定值。 12345678910#set命令kubectl create service clusterip my-svc --clusterip="None" -o yaml --dry-run \| kubectl set selector --local -f - 'environment=qa' -o yaml \| kubectl create -f -#--edit标志kubectl create service clusterip my-svc --clusterip="None" -o yaml --dry-run &gt; /tmp/srv.yamlkubectl create --edit -f /tmp/srv.yaml 配置文件Imperative Management of Kubernetes Objects Using Configuration Files 1234567891011121314#创建对象kubectl create -f &lt;file | url&gt;#更新kubectl replace -f &lt;file | url&gt;#删除kubectl delete -f &lt;file | url&gt;#查看kubectl get -f &lt;file | url&gt; -o yaml 使用配置文件声明管理的k8s对象Declarative Management of Kubernetes Objects Using Configuration Files 可通过在目录中存储多个对象配置文件来创建、更新、删除k8s对象，并使用kubectl apply根据递归创建和更新这些对象。kubectl apply不支持对象配置命令create和replace。 开始前声明性对象配置需要深入理解k8s对象定义和配置。 创建对象使用kubectl apply创建除指定目录中的配置文件定义的已存在的所有对象。 1kubectl apply -f &lt;directory&gt;/ 栗子： 12345678910111213141516171819202122232425apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx minReadySeconds: 5 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80#创建kubectl apply -f https://k8s.io/examples/application/simple_deployment.yaml#查看kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml 更新对象使用kubectl apply更新目录中定义的所有对象，即使这些对象已经存在。 1kubectl apply -f &lt;directory&gt;/ 栗子： 12345678910111213141516171819202122232425262728293031#伸缩kubectl scale deployment/nginx-deployment --replicas=2#更新nginx版本，从1.7.9升级到1.11.9#删除minReadySeconds字段apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.11.9 ports: - containerPort: 80#应用更新kubectl apply -f https://k8s.io/examples/application/update_deployment.yaml#查看kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml 删除对象有两种方法: 12345#推荐kubectl delete -f &lt;filename&gt;#选择kubectl apply -f &lt;directory/&gt; --prune -l &lt;labels&gt; 查看对象1kubectl get -f &lt;file | url&gt; -o yaml 计算,存储和网络Compute, Storage, and Networking Extensions 集群管理Cluster Administration 规划集群 管理集群 保护集群 集群服务 详情见配置章节。 证书Certificates 当使用客户端证书认证时，你可以通过easyras, openssl, cfssl手动生成证书。 openssl123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#Generate a ca.key with 2048bitopenssl genrsa -out ca.key 2048#According to the ca.key generate a ca.crtopenssl req -x509 -new -nodes -key ca.key -subj "/CN=$&#123;MASTER_IP&#125;" -days 10000 -out ca.crt#Generate a server.key with 2048bitopenssl genrsa -out server.key 2048#reate a config file for generating a Certificate Signing Request (CSR)[ req ]default_bits = 2048prompt = nodefault_md = sha256req_extensions = req_extdistinguished_name = dn[ dn ]C = &lt;country&gt;ST = &lt;state&gt;L = &lt;city&gt;O = &lt;organization&gt;OU = &lt;organization unit&gt;CN = &lt;MASTER_IP&gt;[ req_ext ]subjectAltName = @alt_names[ alt_names ]DNS.1 = kubernetesDNS.2 = kubernetes.defaultDNS.3 = kubernetes.default.svcDNS.4 = kubernetes.default.svc.clusterDNS.5 = kubernetes.default.svc.cluster.localIP.1 = &lt;MASTER_IP&gt;IP.2 = &lt;MASTER_CLUSTER_IP&gt;[ v3_ext ]authorityKeyIdentifier=keyid,issuer:alwaysbasicConstraints=CA:FALSEkeyUsage=keyEncipherment,dataEnciphermentextendedKeyUsage=serverAuth,clientAuthsubjectAltName=@alt_names#Generate the certificate signing request based on the config fileopenssl req -new -key server.key -out server.csr -config csr.conf#Generate the server certificate using the ca.key, ca.crt and server.csropenssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key \-CAcreateserial -out server.crt -days 10000 \-extensions v3_ext -extfile csr.conf#View the certificateopenssl x509 -noout -text -in ./server.crt easyrsa cfssl 分发自签名CA证书客户端节点可以拒绝将自签名(self-signed)CA 证书识别为有效。对于非生产环境火灾防火墙后面运行的部署，你可以将自签名CA证书分发给客户端，并刷新本地列表以获取有效证书。 1234567sudo cp ca.crt /usr/local/share/ca-certificates/kubernetes.crtsudo update-ca-certificatesUpdating certificates in /etc/ssl/certs...1 added, 0 removed; done.Running hooks in /etc/ca-certificates/update.d....done. 云提供商跳过！ 管理资源可能，你已经部署应用程序并通过服务公开它。接下来怎么办？k8s提供了许多工具来帮助你管理应用程序部署(包括伸缩和更新)。我们将更深入讨论配置文件和标签。 组织资源配置Organizing resource configurations 许多应用程序需要创建多个资源，如Deployment和Service。通过将多个资源组合在同一个文件中(在yaml中以---分隔)，可以简化多个资源的管理。 栗子：nginx-app.yaml 12345678910111213141516171819202122232425262728293031323334apiVersion: v1kind: Servicemetadata: name: my-nginx-svc labels: app: nginxspec: type: LoadBalancer ports: - port: 80 selector: app: nginx---apiVersion: apps/v1kind: Deploymentmetadata: name: my-nginx labels: app: nginxspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 使用与单个资源相同的方式创建多个资源。资源将按照它们在文件中出现的顺序创建。因此，最好首先指定Service，因为这将确保Scheduler可以扩展与服务关联的pod，因为它们是由Controller创建的。 1234567891011121314151617kubectl create -f https://k8s.io/examples/application/nginx-app.yaml#service "my-nginx-svc" created#deployment "my-nginx" created#同样也支持多个-fkubectl create -f https://k8s.io/examples/application/nginx/nginx-svc.yaml -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml#或者指定一个目录，读取yaml, yml, json文件kubectl create -f https://k8s.io/examples/application/nginx/#urlkubectl create -f https://raw.githubusercontent.com/kubernetes/website/master/content/en/examples/application/nginx/nginx-deployment.yaml 建议的做法是，将与同一微服务或应用程序相关的资源放入同一配置文件中，或将相关联的配置文件分组到同一目录下。 kubectl批量操作Bulk operations in kubectl 资源创建并不是kubectl可执行的唯一操作。 1234567891011121314151617181920kubectl delete -f https://k8s.io/examples/application/nginx-app.yaml#deployment "my-nginx" deleted#service "my-nginx-svc" deleted#分开的资源kubectl delete deployments/my-nginx services/my-nginx-svc#指定label(selector)删除kubectl delete deployment,services -l app=nginx#deployment "my-nginx" deleted#service "my-nginx-svc" deleted#递归删除--recursive -Rkubectl create -f project/k8s/development --recursivekubectl create -f project/k8s/namespaces -f project/k8s/development --recursive 高效使用labelUsing labels effectively 到目前为止，我们使用的示例最多只能将一个标签应用于任意资源。在许多情况下，应该使用多个标签来区分集合。 12345678910 labels: app: guestbook tier: backend role: master#查看kubectl get pods -Lapp -Ltier -Lrolekubectl get pods -l app=guestbook,role=master Canary deployments需要多个标签的另一种情况是区分不同版本的部署，或同一组件的配置。通常的做法是将新应用程序版本的canary与先前版本并排部署，以便新版本可以在完全推出前接收实时生产流量。 例如，你可以使用track标签来区分不同的版本: 12345678910111213141516171819202122232425262728#stable version name: frontend replicas: 3 ... labels: app: guestbook tier: frontend track: stable ... image: gb-frontend:v3#new version name: frontend-canary replicas: 1 ... labels: app: guestbook tier: frontend track: canary ... image: gb-frontend:v4#前端服务将通过选择其标签的公共子集(`track`)来跨越两组副本，以便将流量定向到两个应用程序。 selector: app: guestbook tier: frontend 更新标签Updating labels 有时，在创建新资源之前，需要重新标记现有的pod和其它资源。这可使用kubectl label来完成。 12345#更新kubectl label pods -l app=nginx tier=fe#查看kubectl get pods -l app=nginx -L tier 更新注释Updating annotations 有时，你会想要将注释附加到资源。这个使用kubectl annotatie来完成。 1234kubectl annotate pods my-nginx-v4-9gw19 description=&apos;my frontend running nginx&apos;#查看kubectl get pod my-nginx-v4-9gw19 -o yaml 伸缩应用程序Scaling your application 当应用程序上的负载增大或缩小时，可以使用kubectl轻松扩展。 1234567kubectl scale deployment/my-nginx --replicas=2kubectl get pods -l app=nginx#自动伸缩kubectl autoscale deployment/my-nginx --min=1 --max=3 就地更新资源In-place updates of resources 有时，需要对创建的资源进行简单，无中断(non-disruptive)的更新。 kubectl apply建议在源代码管理中维护一组配置文件，以便可以对它们配置的资源的代码进行维护和版本化。这样，你可以使用kubectl apply将更改的配置推送的集群。kubectl apply会将注释附加到资源，以便确定自上次调用以来对配置所做的更改。在调用它是，kubectl apply会在先前的配置，提供的输入和资源的当前配置之间进行差异比较，已确定如何修改资源。 kubectl edit或者，你可使用kubectl edit来更新资源。 12kubectl edit deployment/my-nginx#这样就和vim差不多，可修改此部署 kubectl patch你可使用kubectl patch来更新API对象。此命令支持JSON patch, JSON merge patch和 strategic merge patch。 破坏性更新Disruptive updates 在某些情况下，你可能需要更新初始化后无法更新的资源字段，或者你可能只想立即进行递归更改，例如修复部署创建的损坏的pod。要更改此类资源，请使用replace --force——它将删除并重新创建资源。 123kubectl replace -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml --forcedeployment &quot;my-nginx&quot; deleteddeployment &quot;my-nginx&quot; replaced 在服务没有中断的情况下更新应用程序Updating your application without a service outage 在某些时候，你最终需要更新已部署的应用程序，通常是指定新的image或image tag。kubectl支持多种更新操作，每种操作都适用于不同的场景。 123456kubectl run my-nginx --image=nginx:1.7.9 --replicas=3#deployment &quot;my-nginx&quot; created#更新nginx版本为: 1.9.1kubectl edit deployment/my-nginx#修改镜像那一行 部署将以声明的方式逐步更新已部署的nginx应用程序。它确保在更新时只有一定数量的旧副本可能会关闭，并且在所需数量的pod之上只能创建一定数量的新副本。 集群网络Cluster Networking 默认情况下，k8s与docker的网络方式有所不同。有4个网络问题需要解决： 高度耦合的容器到容器的通信: 这通过pod和localhost通信解决 pod到pod的通信： 这是侧重点 pod到service的通信： 这包含在Service中 external到service的通信： 这包含在service中 k8s假设pod与pod间是可以通信的，无论它们位于哪个主机。每个pod都有自己的IP地址，因此你无需在pod之间明确创建链接，也几乎不需要处理映射容器端口到主机端口。这创建了一个干净的向后兼容的模型，从端口分配、命名、服务发现、负载均衡、应用程序配置和迁移的角度来看，pod可以像VM或物理主机一样。 为实现此目的，你需要设置集群网络。 Docker模型在讨论k8s网络方法之前，有必要回顾Docker网络方式。默认情况下，Docker使用host-private网络。它创建一个虚拟网桥(称为docker0)，并从RFC1918中为该网桥定义的一个专用地址块中分配一个子网。对于Docker创建的每个容器，它分配一个连接到网桥的虚拟以太网设备(称为veth)。使用Linux命名空间将veth映射为容器中的eth0。容器内的eth0网口从桥接器的地址范围获取IP地址。为了使Docker容器跨节点进行通信，必须在计算机自己的IP地址上分配端口，然后将这些端口转发/代理到容器。这意味着容器必须小心地使用端口，或动态分配端口。 k8s模型跨多开发者协调端口非常难以大规模地进行，并使用户暴露在他们无法控制的集群级别问题之外。动态端口分配给系统带来了很多复杂性——每个应用程序都必须将端口作为标志，API server必须知道如何将动态端口号插入配置块，服务必须知道如何找到彼此。与此相关，k8s采取了不同的方法。 k8s对任何网络实施都强加了一下基本要求： 容器间可互相通信而无需NAT 所有节点都可与所有容器通信而无需NAT 容器看到的IP与其他人看到的IP相同 实际上，k8s在pod范围应用IP地址，pod中的容器共享其网络命名空间(包括IP地址)。这意味着pod中的容器都可以在localhost上彼此通信。这被称为ip-per-pod模型。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#在Docker中查看docker network inspect bridge#可看到副本集的容器，都是pod，而非container#这也证明container共享pod的网络空间#注意它的网关便是docker0[ &#123; &quot;Name&quot;: &quot;bridge&quot;, &quot;Id&quot;: &quot;68bc0cf07a4d7666e1d35f2c1cf179ae8605b431353ba93446abc898de086a9c&quot;, &quot;Created&quot;: &quot;2018-07-23T17:45:54.42038221+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;10.254.76.0/24&quot;, &quot;Gateway&quot;: &quot;10.254.76.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Containers&quot;: &#123; &quot;7d2e6561fa81730ae05743f78871666df75cf5e6f483b71da33137823c172333&quot;: &#123; &quot;Name&quot;: &quot;k8s_POD.24f70ba9_hello-world-3198537413-138pg_default_adb8f0fe-8fea-11e8-b10b-000c29aa7e75_785c4a84&quot;, &quot;EndpointID&quot;: &quot;bf50c5a71ad26531a370a73ce8da5903d32b9e2f8b8397d7405b914203071c45&quot;, &quot;MacAddress&quot;: &quot;02:42:0a:fe:4c:06&quot;, &quot;IPv4Address&quot;: &quot;10.254.76.6/24&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125;, &quot;ea9fbf660f27943b866759a084dc26457474d73c50082939f157ed1dfe0bc806&quot;: &#123; &quot;Name&quot;: &quot;k8s_POD.24f70ba9_hello-world-3198537413-ddgb3_default_adb90c8c-8fea-11e8-b10b-000c29aa7e75_0452e1f4&quot;, &quot;EndpointID&quot;: &quot;e83401827e0e6d2896eb46c7b252594c1694ca119d0cbd74c29383209b80a128&quot;, &quot;MacAddress&quot;: &quot;02:42:0a:fe:4c:02&quot;, &quot;IPv4Address&quot;: &quot;10.254.76.2/24&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;, &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;, &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 如何实现k8s网络模型How to implement the Kubernetes networking model 有多种方式实现此网络模型，以下做一个概述。 ACI AOS from Apstra Big Cloud Fabric from Big Switch Networks Cilium CNI-Genie from Huawei Contiv Contrail Flannel Google Compute Engine Kube-router L2 networks and linux bridging Multus NSX-T Nuage Networks VCS OpenVSwitch OVN Project Calico Romana Weave Net from Weaveworks 日志架构Logging Architecture 应用程序和系统日志可以帮助你了解集群内部发生的情况。大多数现代应用程序都有某种日志机制，因此，大多数容器化引擎同样设计来支持多种日志。容器化应用程序最简单、最受欢迎的日志方法是写入stdout和stderr。 但是，容器引擎或runtime提供的本地(native)功能通常不足以构建完整的日志解决方案。例如，如果container crashe、pod evicted、node dies，你通常仍然希望访问应用程序的日志。因此，日志应独立于container、pod、node，并具有单独存储(separate storage)和生命周期(lifecycle)。这个概念称为集群级日志(cluster-level-loggin)。集群级日志需要单独的后端来存储(store)、分析(analyze)、查询(query)日志。k8s不提供日志数据的本地存储解决方案，但你可以将许多现有的日志解决方案集成到k8s集群中。 集群级日志架构假设在集群内部或外部存在日志记录后端。 k8s基本日志Basic logging in Kubernetes 本节中，k8s将日志记录到到标准输出。 123456789101112131415161718192021222324252627282930313233343536vim /etc/k8s/test/counter-pod.yaml#此pod每秒输出一条信息apiVersion: v1kind: Podmetadata: name: counterspec: containers: - name: count image: busybox args: [/bin/sh, -c, &apos;i=0; while true; do echo &quot;$i: $(date)&quot;; i=$((i+1)); sleep 1; done&apos;]#创建#kubectl create -f /etc/k8s/test/counter-pod#不指定命名空间，则默认default#也可在配置文件里指定命名空间#kubectl create -f /etc/k8s/test/counter-pod --namespace=test#查看#如果pod有多个容器，则应该指定容器名称kubectl logs counter0: Fri Aug 10 07:43:09 UTC 20181: Fri Aug 10 07:43:10 UTC 20182: Fri Aug 10 07:43:11 UTC 20183: Fri Aug 10 07:43:12 UTC 20184: Fri Aug 10 07:43:13 UTC 20185: Fri Aug 10 07:43:14 UTC 20186: Fri Aug 10 07:43:15 UTC 20187: Fri Aug 10 07:43:16 UTC 20188: Fri Aug 10 07:43:17 UTC 20189: Fri Aug 10 07:43:18 UTC 2018...... 节点级日志记录Logging at the node level 容器化应用程序写入stdout, stderr的所有内容，都由容器引擎处理并重定向到某处。Docker容器引擎可修改日志驱动程序，将日志写入到其它地方(file, json, fluent…)。 注意Docker json日志驱动将每一行视为单独的消息，它没有直接支持多行消息，你需要使用更高级别来处理它。 默认情况下，如果容器重启，kubelet会使用其日志保留一个已终止(terminated)的容器。如果从节点上驱逐pod，则所有相应的容器也会被驱逐(包括日志)。 节点级日志记录中，一个重要考虑因素是实现日志轮询(log rotation)，以便日志不会占用节点所有可用存储。k8s目前不负责轮询日志，但部署工具应该配置方案来解决日志轮询问题。例如，在k8s集群中，部署一个脚本程序，用于日志轮询。或设置Docker container runtime的log-opt标志已自动轮询应用程序日志。 当在基本日志记录中运行kubectl logs命令时，节点上的kubelet会处理请求直接从日志文件读取，返回响应的内容。注意： 如果某个外部系统已执行轮询，则kubectl logs只能获取到最新的日志文件。 system component logs有两种类型的系统组件: run in container: 如kube-proxy not run in container: 如kubelet, Docker 在使用systemd的机器上，kubelet和container runtime将日志写到journald。如果没有systemd，则写到/var/log/下。容器内的系统组件始终将日志写入/var/log目录下，绕过默认的日志机制。与容器日志类似，在/var/log/目录下的系统组件日志也应该被轮询。 集群级日志架构Cluster-level logging architectures k8s官方没有提供原生的集群级日志记录，但你可以考虑集中常见方法： 在每个节点上使用node-level logging agent 用于记录应用程序pod的专用sidecar container 将日志直接从应用程序推送到后端 Using a node logging agent 你可以通过在每个节点上包含一个 节点级日志记录代理 来实现集群级日志记录。它是一个用于公开日志或将日志推送到后端的专用工具。通常，此日志代理是一个容器，它可以访问该节点上所有应用程序容器的日志文件的目录。 由于日志记录代理必须在每个节点上运行，因此，将其实现为节点上的DaemonSet replica, manifest pod, dedicated native process是很常见的。然后，后两种方法已被弃用，并且非常不建议。 对于k8s集群，使用节点级日志代理是最常见和鼓励的方法，因为它在每个节点上只创建一个Agent，并且不需要对节点上运行的应用程序进行任何更改。然而，节点级日志仅适用于应用程序的stdout和stderr。 k8s并未指定logging Agent，但有两个可选的日志代理与k8s一同打包。两者都使用fluentd的自定义配置作为节点上的代理。 Stackdriver Logging: 用于Google Cloud Platform Elasticsearch Using a sidecar container with the logging agent你可通过以下方式使用sidecar container: sidecar container将应用程序的日志传输到自己的stdout sidecar container容器运行一个Logging Agent，此代理从应用程序容器中获取日志 通过让sidecar container的stream流向他们自己的stdout/stderr，你可利用已经在每个节点上运行的kubelet和logging agent。sidecat container从file、socket、journald读取日志。每个单独的sidecar container将日志打印到自己的stdout/stderr。此方法允许你从应用程序的不同部分分离多个日志流，其中一些可能缺乏对写入stdout/stderr的支持。重定向日志背后的逻辑是最小的，因此它几乎不是一个重要的开销。此外，因为stdout/stderr由kubelet处理，所以你可以使用如kubectl logs这样的内置工具。 考虑如下栗子，pod运行单个容器，此容器使用两种不同的日志格式写入两个不同的日志。 two-files-counter-pod.yaml 1234567891011121314151617181920212223242526apiVersion: v1kind: Podmetadata: name: counterspec: containers: - name: count image: busybox args: - /bin/sh - -c - &gt; i=0; while true; do echo "$i: $(date)" &gt;&gt; /var/log/1.log; echo "$(date) INFO $i" &gt;&gt; /var/log/2.log; i=$((i+1)); sleep 1; done volumeMounts: - name: varlog mountPath: /var/log volumes: - name: varlog emptyDir: &#123;&#125; 即使你设法将两个组件重定向到容器的stdout，在同一个日志流中包含不同格式的日志条目也会很麻烦。相反，你可以引入两个sidecar container。每个sidecar container可以从共享卷(shared volume)中tail特定的日志文件，然后将日志重定向到自己的stdout。 这是pod运行两个sidecat container的配置文件。三个容器共享了/var/log。 two-file-counter-pod-streaming-sidecar.yaml 1234567891011121314151617181920212223242526272829303132333435363738apiVersion: v1kind: Podmetadata: name: counterspec: containers: - name: count image: busybox args: - /bin/sh - -c - &gt; i=0; while true; do echo "$i: $(date)" &gt;&gt; /var/log/1.log; echo "$(date) INFO $i" &gt;&gt; /var/log/2.log; i=$((i+1)); sleep 1; done volumeMounts: - name: varlog mountPath: /var/log - name: count-log-1 image: busybox args: [/bin/sh, -c, 'tail -n+1 -f /var/log/1.log'] volumeMounts: - name: varlog mountPath: /var/log - name: count-log-2 image: busybox args: [/bin/sh, -c, 'tail -n+1 -f /var/log/2.log'] volumeMounts: - name: varlog mountPath: /var/log volumes: - name: varlog emptyDir: &#123;&#125; 现在运行此pod，并单独访问每个日志流: 123456789101112131415161718192021222324252627282930313233#runkubectl create -f /etc/k8s/test/two-file-counter-pod-streaming-sidecar.yaml#getkubectl get pod/counter -o wideNAME READY STATUS RESTARTS AGE IP NODEcounter 3/3 Running 0 9m 10.244.2.9 salt01#kubectl logs counterError from server (BadRequest): a container name must be specified for pod counter, choose one of: [count count-log-1 count-log-2]#logskubectl logs counter count-log-10: Tue Aug 14 02:58:29 UTC 20181: Tue Aug 14 02:58:30 UTC 20182: Tue Aug 14 02:58:31 UTC 20183: Tue Aug 14 02:58:32 UTC 2018kubectl logs counter count-log-2Tue Aug 14 02:58:29 UTC 2018 INFO 0Tue Aug 14 02:58:30 UTC 2018 INFO 1Tue Aug 14 02:58:31 UTC 2018 INFO 2Tue Aug 14 02:58:32 UTC 2018 INFO 3 集群中安装的节点级代理会自动获取这些日志流，而无需进一步配置。如果愿意，可将代理配置为根据源容器解析日志行。 注意，进错CPU和内存使用率很低，将日志写入文件然后将它们流式传输到stdout会使磁盘使用量增加一倍。如果你有一个应用程序将日志写到单个文件，通常最好将/dev/stdout设置为目标，而不是实现流式sidecar container方法。 sidecar container还可用于应用程序本身日志轮询。然而，建议直接使用stdout/stderr并将日志的轮询和保留交给kubelet。 Sidecar container wiht a logging agent 如果节点级日志记录代理对你来说不够灵活，你可以创建一个带有单独日志记录代理程序的sidecar container，该代理可专门配置来与你的程序一起运行。 注意：在sidecar container使用日志记录代理将会消耗大量资源。此外，你将无法使用kubectl logs命令访问这些日志，因为它们不受kubelet控制。 栗子使用fluentd作为logging agent。有两个可用于实现此方法的配置文件： ConfigMap使用ConfigMap来配置fluentd。具体配置参考fluentd官方文档。 fluentd-sidecat-config.yaml 12345678910111213141516171819202122232425apiVersion: v1kind: ConfigMapmetadata: name: fluentd-configdata: fluentd.conf: | &lt;source&gt; type tail format none path /var/log/1.log pos_file /var/log/1.log.pos tag count.format1 &lt;/source&gt; &lt;source&gt; type tail format none path /var/log/2.log pos_file /var/log/2.log.pos tag count.format2 &lt;/source&gt; &lt;match **&gt; type google_cloud &lt;/match&gt; pod运行fluentd的sidecat container的pod。它挂载一个volume让fluentd获取配置数据。下面需要用到k8s.gcr.io/fluentd-gcp:1.30镜像，请提前准备。要挂载目录，请创建。 two-files-counter-pod-agent-sidecar.yaml 123456789101112131415161718192021222324252627282930313233343536373839apiVersion: v1kind: Podmetadata: name: counterspec: containers: - name: count image: busybox args: - /bin/sh - -c - &gt; i=0; while true; do echo &quot;$i: $(date)&quot; &gt;&gt; /var/log/1.log; echo &quot;$(date) INFO $i&quot; &gt;&gt; /var/log/2.log; i=$((i+1)); sleep 1; done volumeMounts: - name: varlog mountPath: /var/log - name: count-agent image: k8s.gcr.io/fluentd-gcp:1.30 env: - name: FLUENTD_ARGS value: -c /etc/fluentd-config/fluentd.conf volumeMounts: - name: varlog mountPath: /var/log - name: config-volume mountPath: /etc/fluentd-config volumes: - name: varlog emptyDir: &#123;&#125; - name: config-volume configMap: name: fluentd-config 这仅仅是一个栗子。你可以使用其它logging agent取代fluentd，如filebeat, logstash… Exposing logs directly from the application 你可以通过直接公开每个应用程序的日志或push日志来实现集群级日志记录。就相当于在写得程序中加入日志收集和处理。但是，这种日志记录机制超出了k8s的范围。 kubelet垃圾回收Configuring kubelet Garbage Collection 垃圾回收是一个有用的kubelet功能，它将清理未使用的镜像和容器。每分钟对容器执行垃圾回收，每五分钟对镜像进行垃圾回收。不推荐使用额外的垃圾回收工具，因为这可能会破坏kubelet的行为。 镜像回收Image Collection k8s在cadvisor的配合下，通过imageManager管理所有镜像的生命周期。镜像垃圾回收策略考虑了两个要素： HighThresholdPercent LowThresholdPercent 磁盘使用率高于高阈值将触发垃圾回收，垃圾回收将删除最近最少使用的镜像，直到满足低阈值。 镜像垃圾回收的kubelet flag: 123456789#触发镜像垃圾回收的磁盘使用率百分比#默认值 90%image-gc-high-threshold#镜像垃圾回收尝试释放磁盘使用的百分比#默认值 80%image-gc-low-threshold 容器回收Container Collection 容器垃圾回收策略考虑了三个用户定义的变量： MinAge MaxPerPodContainer MaxContainers MinAge是容器可以被垃圾回收的最小年龄。设置为0可禁用。MaxPerPodContainer是允许每个pod对允许拥有的最大死容器数。设置小于0可禁用。MaxContainers是总死亡容器的最大数量。设置小于0可禁用。 kubelet将对未识别、删除或标志设置的边界之外的容器起作用。通常首先移除最旧的容器。不受kubelet管理的容器不受容器垃圾回收的限制。 容器垃圾回收的kubelet flag: 1234567891011121314151617#完成的容器在垃圾回收之前的最低年龄#默认值 0min，意味着每个完成的容器都将被垃圾回收minimum-container-ttl-duration#每个容器要保留的最大旧实例数#默认值 1#强烈建议使用足够大的值，以允许每个预期容器保留至少1个死亡容器maximum-dead-containers-per-container#全局要保留的最大容器实例数#默认值 -1，意味着禁用#处于类似的原因，同样建议使用较大的值maximum-dead-containers 启用一些kubelet垃圾回收标志未来将被启用或取代。 Existing Flag New Flag Rationale –image-gc-high-threshold –eviction-hard or –eviction-soft existing eviction signals can trigger image garbage collection –image-gc-low-threshold –eviction-minimum-reclaim eviction reclaims achieve the same behavior –maximum-dead-containers xxx deprecated once old logs are stored outside of container’s context –maximum-dead-containers-per-container xxx deprecated once old logs are stored outside of container’s context –minimum-container-ttl-duration xxx deprecated once old logs are stored outside of container’s context –low-diskspace-threshold-mb –eviction-hard or eviction-soft eviction generalizes disk thresholds to other resources –outofdisk-transition-frequency –eviction-pressure-transition-period eviction generalizes disk pressure transition to other resources Federation先跳过，后面来学习。 ProxyProxies in Kubernetes 使用Kubernetes时可能会遇到几种不同的代理。代理已经取代了重定向功能，重定向已被弃用。 kubectl proxy runs on a user’s desktop or in a pod proxies from a localhost address to the Kubernetes apiserver client to proxy uses HTTP proxy to apiserver uses HTTPS locates apiserver adds authentication headers apiserver proxy is a bastion built into the apiserver connects a user outside of the cluster to cluster IPs which otherwise might not be reachable runs in the apiserver processes client to proxy uses HTTPS (or http if apiserver so configured) proxy to target may use HTTP or HTTPS as chosen by proxy using available information can be used to reach a Node, Pod, or Service does load balancing when used to reach a Service kube proxy runs on each node proxies UDP and TCP does not understand HTTP provides load balancing is just used to reach services A Proxy/Load-balancer in front of apiserver existence and implementation varies from cluster to cluster(e.g. nginx) sits between all clients and one or more apiservers acts as load balancer if there are several apiservers 云负载均衡器 由云服务商提供 当k8s服务有LoadBalancer类型时自动创建 仅使用udp/tcp 具体详情因云服务商而异 控制器管理器指标Controller manager metrics 控制器管理器指标，提供有关控制器管理器性能和运行状况的重要信息。 这些指标包括常见的Go语言运行时指标、控制器特定指标。可用于衡量集群的运行状况。 在集群中，当控制器管理器运行时，可从http://localhost:10252/metrics获取控制器管理器指标。 12345netstat -nltup | grep 10252tcp 0 0 127.0.0.1:10252 0.0.0.0:* LISTEN 11088/kube-controll curl http://localhost:10252/metrics 这些指标以prometheus format格式发出，并且是人类可读的。 附加组件Installing Addons 附加组件扩展了k8s的功能。 网络和网络策略Networking and Network Policy ACI： 通过 Cisco ACI提供集成的容器网络和网络完全 Calico： 是一个安全的L3网络和网络策略提供商 Canal: 将Flannel和Calico联合起来，提供网络和网络策略 Cilium： 是一个L3网络和网络策略插件 CNI-Genie： 使k8s能够无缝连接到各种CNI插件 Contiv： 提供可配置的网络，用于各种用例和丰富的策略框架 Flannel： 是一个可以与k8s一起使用的overlay网络提供商 Knitter： 是一个支持k8s多个网络的网络解决方案 Multus： 是一个用于k8s中多个网络支持，以支持所有CNI插件的多插件 NSX-T： 提供VMware NSX-T与容器协调器之间的集成 Nuage： 是一个SDN平台，可在k8s Pod和non-k8s环境之间提供基于策略的网络，并提供可见性和安全性监控 Romana： 用于Pod网络的L3网络解决方案 Weave Net： 提供网络和网络策略，将在网络分区的两侧进行工作，而不需要外部数据库 服务发现Service Discovery CoreDNS： 是一个灵活，可扩展的DNS服务器，可作为用于pod的集群DNS。 可视化，控制Visualization, Control Dashboard： k8s的Dashboard Web Interface Weave Scope： 是一个用于以图形可视化显示container, pod, service… k8s架构Kubernetes Architecture Nodenode是k8s中的工作机器，以前称为minion。也就是集群中的一台主机。节点可以是VM或物理机。每个节点都具有用于运行pod所需的服务，并由master组件管理。节点上的服务包括docker, kubelet, kube-proxy。 节点状态Node Status 节点的状态包含以下信息： 地址(Address) 条件(Condition) 容量(Capacity) 信息(Info) 地址这些字段的使用取决于机器配置。 HostName： 节点内核报告的主机名 ExternalIP： 通常是可从外部路由的节点IP地址 InternalIP： 通常是仅在集群内可路由的节点IP地址 123456789101112kubectl get node -o wideNAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIMEmaster Ready master 7d v1.11.1 192.168.31.49 &lt;none&gt; CentOS Linux 7 (Core) 3.10.0-862.9.1.el7.x86_64 docker://1.13.1node Ready &lt;none&gt; 7d v1.11.1 192.168.31.174 &lt;none&gt; CentOS Linux 7 (Core) 3.10.0-862.9.1.el7.x86_64 docker://1.13.1salt01 Ready &lt;none&gt; 1d v1.11.1 192.168.31.159 &lt;none&gt; CentOS Linux 7 (Core) 3.10.0-862.9.1.el7.x86_64 docker://1.13.1kubectl describe node/salt01Addresses: InternalIP: 192.168.31.159 Hostname: salt01 条件该字段描述了所有运行中节点的状态。节点条件使用JSON对象表示。 条件 描述 OutOfDisk True(节点上的可用空间不足以添加新pod), 否则为False Ready True(节点健康并准备好接受pod) False(节点不健康且不接受pod) Unknown(节点控制器在最后一个node-monitor-grace-period期限内没有从节点收到消息。默认40s) MemoryPressure True(节点内存有压力，即内存不足)，否则为False PIDPressure True(进程存在压力，即节点上有太多进程)，否则为False DiskPressure True(磁盘大小存在压力，即磁盘容量较低), 否则为False NetworkUnavailable True(节点网络配置错误)，否则为False ConfigOK True(kubelet配置正确)，否则为False 123456789kubectl describe node/salt01Conditions: Type Status LastHeartbeatTime LastTransitionTime Reason Message ---- ------ ----------------- ------------------ ------ ------- OutOfDisk False Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:51:40 +0800 KubeletHasSufficientDisk kubelet has sufficient disk space available MemoryPressure False Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:51:40 +0800 KubeletHasSufficientMemory kubelet has sufficient memory available DiskPressure False Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:51:40 +0800 KubeletHasNoDiskPressure kubelet has no disk pressure PIDPressure False Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:51:40 +0800 KubeletHasSufficientPID kubelet has sufficient PID available Ready True Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:53:00 +0800 KubeletReady kubelet is posting ready status 容量描述节点上的可用资源：CPU，内存，可调度到节点上的最大pods数。 1234567kubectl describe node/salt01Capacity: cpu: 2 ephemeral-storage: 49250820Ki hugepages-2Mi: 0 memory: 3881332Ki pods: 110 信息关于节点的一般信息，如Kernel版本，Kubernetes版本，Docker版本，OS… 123456789101112kubectl describe node/salt01System Info: Machine ID: e48d6bf22f9b4c8da5cb1a07b2fec730 System UUID: 564D1413-905B-64D6-E9A2-92E37F9B5BDA Boot ID: 1df89a81-77a4-44a0-9241-e6d766795e32 Kernel Version: 3.10.0-862.9.1.el7.x86_64 OS Image: CentOS Linux 7 (Core) Operating System: linux Architecture: amd64 Container Runtime Version: docker://1.13.1 Kubelet Version: v1.11.1 Kube-Proxy Version: v1.11.1 管理Management 与Pod与Service不同，k8s本身并不创建节点： 它由云服务商创建，或存在于物理机/虚拟机的pool中。当k8s创建节点时，它实际上只是创建了一个表示节点的对象。创建之后，k8s将检查节点是否有效。 栗子： 12345678910&#123; "kind": "Node", "apiVersion": "v1", "metadata": &#123; "name": "10.240.79.157", "labels": &#123; "name": "my-first-k8s-node" &#125; &#125;&#125; k8s将在内部创建节点对象，并通过基于metadata.name字段的运行状况检查来验证节点。如果节点有效(valid)，即所有必要的服务都已运行，它就符合了运行pod的条件。否则它将被所有的集群动作忽略，直到它变为有效。请注意，Kubernetes将保持无效(invalide)节点的对象，除非它被手动删除。Kubernetes将持续检查节点是否变得可用。 目前，有3个组件与k8s节点接口交互： Node Controller kubelet kubectl 节点控制器节点控制器是一个k8s Master组件，用于管理节点的各个方面。 节点控制器在节点的生命周期中具有多个角色(role)。第一个便是在节点注册时为其分配CIDR地址块。第二个是使节点控制器的内部节点列表与可用机器保持一致。只要节点不健康，节点控制器就会询问该节点是否仍然可用。如果不是，则节点控制器从其节点列表中删除该节点。第三个是监控节点的健康状况。当节点不可达时，节点控制器负责更新节点的条件(condition)状态，从Ready变为Unknown。如果节点继续无法访问，则稍后从节点中驱逐(evict)所有pod(graceful termination)。默认超时时间为40s开始上报Unknown，然后5min之后开始驱逐pods。节点控制器通过--node-nonitor-period秒检查每个节点的状态。 在大多数情况下，节点控制器将驱逐率(evication rate)限制为--node-eviction-rate(默认值 0.1)每秒。这意味着它将不会每10s从超过1个节点驱逐pod。 当给定可用区域中的节点变得不健康时，节点驱逐行为会发生变化。同时，节点控制器检查此区域中不健康节点的百分比。如果节点不健康比例至少为--unhealthy-zone-threshold(默认值 0.55)，那么驱逐率会降低；如果集群很小，小于或等于--large-cluster-size-threshold(默认值 50)，则停止驱逐；否则，驱逐率减小到每秒--secondary-node-eviction-rate(默认值 0.01)。每个可用区域实施这些策略的原因是，一个可用区域可能与其它可用区域保持连接。 在可用区域之间传播节点的一个关键原因是，当整个区域出现故障时，工作负载可以转移到健康区域。因此，如果区域中的全部节点都不健康，则节点控制器以正常速率--node-eviction-rate驱逐。The corner case是当所有区域都不健康时。在这种情况下，节点控制器假定Master连接存在一些问题，并在某些连接恢复之前停止所有驱逐。 节点自注册Self-Registration of Nodes 当kubelet标志--register-node为true(默认)时，它会尝试向API server注册自己。这是大多数发行版使用的首选模式。 对于自注册，kubelet使用如下选项： 12345678910111213141516171819202122#向API server验证自身的凭据路径--kubeconfig#r如何与云服务商交流--cloud-provider#向API server自动注册--register-node#节点IP地址--node-ip#集群中注册节点时要添加的标签--node-labels#指定kubelet将节点状态发送到master的频率--node-status-update-frequency 目前，任何kubelet都有权 create/modify 任何节点资源，但实际上它只 创建/修改 自己的节点资源。(将来，k8s打算只允许kubelet修改自己的节点资源) 手动管理节点 如果希望手动创建节点对象，请设置kubelet标志--register-node=false。修改包括在节点上设置标签(label)并将其标记为不可调度(unschedulable)。 节点容量Node Capacity 节点容量(cpu, memory)是节点对象的一部分。通常，当创建节点对象时，节点注册自己并上报其容量。如果是手动管理节点，则需要你在添加节点时设置节点容量。k8s调度器确保节点上的所有pod都有足够的资源。它检查节点上容器请求的总和不大于节点容量。它包括由kubelet启动的所有容器，但不包括由容器运行时直接启动的容器，也不包括容器外部的任何进程。所以，尽量不要在k8s集群节点上运行额外进程。 如果要为non-pod进程保留资源，你可以创建保留(placeholder)pod。将内存和CPU的值设置为要保留的资源量。 123456789101112apiVersion: v1kind: Podmetadata: name: resource-reserverspec: containers: - name: sleep-forever - image: k8s.gcr.io/pause:0.8.0 - resources: requests: cpu: 100m memory: 100Mi API对象Node is a top-level resource in the Kubernetes REST API. 节点通信Master-Node communication Master(APIserver)与k8s cluster之间的通信。目的是允许用户自定义其安装以强化网络配置，以便集群可在不受信任的网络上运行。 Cluster-&gt;Master从Cluster到Master的所有通信路径都终止于API server。在典型部署中，API server配置为在安全的HTTPS(443)端口上监听远程连接，并启用一种或多种形式的Client认证。应该为节点配置集群的公共根证书，以便他们可以使用有效证书安全地连接到API server。希望连接到API server的Pod可以利用Service Account安全地执行此操作，这样k8s在实例化时自动将公共根证书和有效bearer token注入到Pod中。the kubernetes service配置了一个虚拟IP地址，该地址被重定向到API server的HTTPS endpoint。Master组件还通过安全端口与Cluster API server通信。 123kubectl get serviceNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 8d 因此，默认情况下，从Cluster到Master的连接的默认操作模式是安全的，可在不受信任网络/公共网络上运行。 Master-&gt;Cluster从Master(API server)到Cluster有两条主要通信路径： API server -&gt; kubelet API server -&gt; node, pod, service API server -&gt; kubelet从API server到kubelet(它运行在集群中的每个节点上)。 从API server到kubelet的连接用于： 获取Pod的日志 附加到运行的Pod 提供kubelet的端口转发功能 这些连接终止于kubelet的HTTPS endpoint。默认情况下，API server不会验证kubelet的证书，这会使连接可能受到中间人工具，并且不安全地运行在不受信任/公共的网络上。要验证此连接，使用--kubelet-certificate-authority标志位API server提供根证书，用于验证kubelet的证书。 如果无法做到，请在API server和kubelet之间使用SSH隧道保障连接安全。 API server -&gt; node, pod, service从API server到node, pod, service的连接默认为纯HTTP，因此既不需要认证也未加密。他们可以通过在API URI的前缀使用https://来运行安全的HTTPS，但他们不会验证HTTPS endpoint提供的证书，也不会提供客户端凭据。因此连接将被加密，它不会提供任何完整性保证。 云控制器管理器Cloud Controller Manager 暂时跳过！ 扩展k8s 扩展k8s集群Extending your Kubernetes Cluster k8s具有高度可配置化和可扩展化。 定制方法可大致分为配置，只涉及更改标志，本地配置文件或API资源；扩展，设计运行其它程序或服务。 扩展模式Extensions Patterns k8s旨在通过编写客户端程序实现自动化。任意 read/write k8s API的程序都可以提供有用的自动化。自动化可在集群上启用或关闭。自动化通常适用于k8s集群，包括托管集群和管理安装。 有一种编写与k8s一起使用的称为控制器模式(Controller Pattern)客户端程序的特定模式。控制器通常读取对象的.spec，可能做些事情，然后更新对象的.status。控制器(Controller)是一个k8s client。当k8s为client并调用远程服务时，它被称为Webhook。远程服务被称为Webhook Backend。与控制器一样，Webhook确实增加了一个失败点。 在webhook模式中，k8s 向远程服务发出网络请求。在二进制插件模型中，k8s执行二进制程序。二进制插件由kubelet和kubectl使用。 扩展点Extension Points k8s 系统的扩展点: 用户使用kubectl与k8s API进行交互 API server处理所有请求 API server提供各种资源 k8s调度器决定将pod放在哪个节点上 k8s大部分行为都是由控制器实现的 kubelet帮助pod在集群网络上显示为具有自己IP的虚拟服务 kubelet还可挂载和解挂容器的卷 如果你不确定如何开始，查看如下流程图： API扩展API Extensions User-Defined Types如果想要定义新的控制器、应用程序配置对象、声明性API并管理他们，请考虑向k8s添加自定义资源。不要讲自定义资源用作应用程序、用户、监控数据的数据存储。 Combining New APIs with Automation通常，当添加新API时，还会添加一个 read/write 新API的控制循环。当自定义API和控制循环的组合用于管理特定的，通常是有状态的应用程序时，这被称为操作者模式(Operator Pattern)。 Changing Built-in Resources通过自定义资源添加扩展k8s API时，添加的资源始终属于新的API组。你无法替换或修改已经存在的API组。添加API不会直接影响现有API的行为，但API Access Extensions会影响现有API的行为。 API Access Extensions当请求到达k8s API server时，它首先进行身份验证，然后授权，然后进行各种准入控制。每个步骤都提供了扩展点。 Authentication身份验证将所有请求中的Header或证书映射到发出请求的客户端的用户名中。 Authorization授权确定特定用户是否可以对API资源进行读写和其它操作。它只是在整个资源的层面上工作，不基于任意对象字段进行区分。 Dynamic Admission Control当请求授权之后，如果它是一个写操作，它还需要通过Admission Control步骤。除了内建步骤之外，还有其它扩展： Image Policy webhook限制可在容器中运行的镜像 为了做出任意的admission control决策，可使用普通admission webhook 初始化程序可在创建对象之前修改对象的控制器 基础设施扩展Infrastructure Extensions Storage PluginsFlex Volumes允许用户通过kubelet调用二进制插件来安装卷，来安装没有内置支持的卷类型 Device Plugins设备插件允许节点通过设备发现插件发现新的节点资源 Network Plugins支持不同的网络结构 Scheduler Extensions调度器是一种特殊类型的控制器，用于监视Pod，并将Pod分配给节点。 扩展k8s APIExtending the Kubernetes API 在聚合层扩展k8s APIExtending the Kubernetes API with the aggregation layer 聚合层允许在集群中安装其它k8s-style的API。 自定义资源Custom Resources 自定义资源是k8s API的扩展，包括何时向k8s集群添加自定义资源以及何时使用独立服务。 资源是k8s API中的端点(endpoint)，用于存储某种API对象的集合。如，内建的pods资源包含了Pod对象的集合。自定义资源是k8s API的扩展，不一定在每个k8s集群上都可用。换句话说，它代表了特定k8s的定制安装。自定义资源可通过动态注册在正在运行的集群中出现和消失，集群管理员可独立于集群本身更新自定义资源。安装自定义资源后，用户可使用kubectl创建和访问其对象。 Custom controllers 自定义字段本身可让你存储和检索结构化数据。只有与控制器结合使用才能成为真正的声明性API。declare API允许你声明或指定资源的所需状态，并尝试将实际状态与此期望状态相匹配。这里，控制器将结构化的数据解释为用户期望状态的记录，并且不断采取行动以实现和维护该状态。自定义控制器是一种用户可在正在运行的集群上进行部署和更新，而与集群自身的生命周期无关的控制器。自定义控制器可使用任何类型的资源，但与自定义资源结合使用时，它们更有效。 Should I add a custom resource to my Kubernetes Cluster? 当创建新的API时，考虑是使用k8s cluster API还是让API独立运行。 Consider API aggregation if: Prefer a stand-alone API if: Your API is Declarative. Your API does not fit the Declarative model. You want your new types to be readable and writable using kubectl. kubectl support is not required You want to view your new types in a Kubernetes UI, such as dashboard, alongside built-in types. Kubernetes UI support is not required. You are developing a new API. You already have a program that serves your API and works well. You are willing to accept the format restriction that Kubernetes puts on REST resource paths, such as API Groups and Namespaces. (See the API Overview.) You need to have specific REST paths to be compatible with an already defined REST API. Your resources are naturally scoped to a cluster or to namespaces of a cluster. Cluster or namespace scoped resources are a poor fit; you need control over the specifics of resource paths. You want to reuse Kubernetes API support features. You don’t need those features 声明性APIDeclarative APIs 在一个声明性API中，通常： 你的API由相对较少的相对较小的对象组成 应用程序或基础结构的对象定义配置 对象很少更新 人们通常需要读写对象 对象的主要操作时CRUD 跨对象的事务不是必需的：API表示期望状态，而不是精确的状态 imperative API不是声明性的，你的API可能不是声明性的标志包括： 客户端说执行此操作，完成后获得同步响应 客户端说执行此操作，然后获取操作ID，并且必须检查单独的Operation对象以确定请求的完成 谈论Remote Procedure Calls(RPCs) 直接存储大量数据 需要高带宽访问 存储最终用户数据，或应用程序处理的其它大规模数据 对象非CRUD的自然操作 API不容易建模为对象 使用操作ID或操作对象表示挂起的操作 Should I use a configMap or a custom resource? 如果符合以下任意条件，请使用ConfigMap: 存在现有的，记录完备的配置文件格式 你希望将整个配置文件放入ConfigMap的一个key中 配置文件的主要用途是在集群上的Pod中运行的程序使用该文件来配置自身 文件的消费者更喜欢使用Pod中的文件或环境变量，而不是k8s API 你希望在文件更新时通过部署执行滚动升级 如果符合以下大部分情况，请使用自定义资源： 你希望使用k8s client library和CLI来创建和更新新资源 你希望来自kubectl的顶级支持 你希望构建新的自动化，监视新对象的更新，然后CRUD其它对象 你希望编写处理对象更新的自动化 你希望使用k8s API约定，如.spec, .status, .metadata 你希望对象是受控资源集合的抽象，或其它资源的汇总 添加自定义资源k8s提供了两种方式来向你的集群中添加自定义资源： CRD很简单，无需任何编程即可创建 API聚合需要编程，但允许更多控制API行为，如数据的存储方式和API版本间的转换 聚合API是位于主API server后面的从属API server，它充当代理。这种安排称为API聚合(AA, API Aggregation)。CRD允许用户添加新类型的资源，而无需添加其它API server，你无需了解API聚合即可使用CRD。无论如何安装，新资源都成为自定义资源，以区别于内置的k8s 资源。 自定义资源定义自定义资源定义 API资源允许你去定义自定义资源。定义CRD对象会创建一个新的自定义资源，其中包含指定的名称和架构。k8s API提供并处理自定义资源的存储。这使你无需编写自己的API server来处理自定义资源，但实现的一般特性意味着你的灵活性低于API server聚合。 API server aggregation通常，k8s API中的每个资源都需要处理REST 请求的代码并管理对象的持久化存储。k8s API server处理pod等内建资源，还可通过CRD处理自定义资源。聚合层允许你通过编写和部署自己的独立API server为自定义资源提供专门的实现。API server将请求委托给你处理的自定义资源，使其对所有客户端可用。 为添加自定义资源选择一个方法通常情况下，CRD很适合，如果： 你有少数几个领域 你正在使用公司内的资源，或作为小型开源项目的一部分 易用性比较： CRDs Aggregated API Do not require programming. Users can choose any language for a CRD controller. Requires programming in Go and building binary and image. Users can choose any language for a CRD controller. No additional service to run; CRs are handled by API Server. An additional service to create and that could fail. No ongoing support once the CRD is created. Any bug fixes are picked up as part of normal Kubernetes Master upgrades. May need to periodically pickup bug fixes from upstream and rebuild and update the Aggregated APIserver. No need to handle multiple versions of your API. For example: when you control the client for this resource, you can upgrade it in sync with the API. You need to handle multiple versions of your API, for example: when developing an extension to share with the world. 高级功能和灵活性： Feature Description CRDs Aggregated API Validation Help users prevent errors and allow you to evolve your API independently of your clients. These features are most useful when there are many clients who can’t all update at the same time. Yes. Most validation can be specified in the CRD using OpenAPI v3.0 validation. Any other validations supported by addition of a Validating Webhook. Yes, arbitrary validation checks Defaulting See above Yes, via a Mutating Webhook; Planned, via CRD OpenAPI schema. Yes Multi-versioning Allows serving the same object through two API versions. Can help ease API changes like renaming fields. Less important if you control your client versions. No, but planned Yes Custom Storage If you need storage with a different performance mode (for example, time-series database instead of key-value store) or isolation for security (for example, encryption secrets or different No Yes Custom Business Logic Perform arbitrary checks or actions when creating, reading, updating or deleting an object Yes, using Webhooks. Yes Scale Subresource Allows systems like HorizontalPodAutoscaler and PodDisruptionBudget interact with your new resource Yes Yes Status Subresource Finer-grained access control: user writes spec section, controller writes status section. Allows incrementing object Generation on custom resource data mutation (requires separate spec and status sections in the resource) Yes Yes Other Subresources Add operations other than CRUD, such as “logs” or “exec”. No Yes strategic-merge-patch The new endpoints support PATCH with Content-Type: application/strategic-merge-patch+json. Useful for updating objects that may be modified both locally, and by the server. For more information, see “Update API Objects in Place Using kubectl patch” No, but similar functionality planned Yes Protocol Buffers The new resource supports clients that want to use Protocol Buffers No Yes OpenAPI Schema Is there an OpenAPI (swagger) schema for the types that can be dynamically fetched from the server? Is the user protected from misspelling field names by ensuring only allowed fields are set? Are types enforced (in other words, don’t put an int in a string field?) No, but planned Yes 一般功能： Feature What it does CRUD The new endpoints support CRUD basic operations via HTTP and kubectl Watch The new endpoints support Kubernetes Watch operations via HTTP Discovery Clients like kubectl and dashboard automatically offer list, display, and field edit operations on your resources json-patch The new endpoints support PATCH with Content-Type: application/json-patch+json merge-patch The new endpoints support PATCH with Content-Type: application/merge-patch+json HTTPS The new endpoints uses HTTPS Built-in Authentication Access to the extension uses the core apiserver (aggregation layer) for authentication Built-in Authorization Access to the extension can reuse the authorization used by the core apiserver (e.g. RBAC) Finalizers Block deletion of extension resources until external cleanup happens. Admission Webhooks Set default values and validate extension resources during any create/update/delete operation. UI/CLI Display Kubectl, dashboard can display extension resources. Unset vs Empty Clients can distinguish unset fields from zero-valued fields. Client Libraries Generation Kubernetes provides generic client libraries, as well as tools to generate type-specific client libraries. Labels and annotations Common metadata across objects that tools know how to edit for core and custom resources 安装自定义资源在向集群添加自定义资源之前，需要注意几点 第三方代码和新的失败点 存储 认证，授权，审计 访问自定义资源k8s client library可用于访问自定义资源。并非所有client library都支持自定义资源，但go和python client library可以。 当你添加一个自定义资源时，你可以使用如下方式访问： kubectl k8s dynamic client REST client 由k8s client 生成工具生成的client 计算，存储和网络插件Compute, Storage, and Networking Extensions 网络插件Network Plugins Notice:FEATURE STATE: Kubernetes v1.11 alphaAlpha features change rapidly k8s中的网络插件有几种风格： CNI plugins: 遵守appc/CNI规范，旨在实现互操作性 Kubenet plugin: 使用bridge和host-local CNI plugins实现基本的cbr0 安装kubelet有一个默认的网络插件，以及整个集群的默认网络。它在启动时探测插件，记住它找到的内容，并在pod声明周期中的适当时间执行所选插件。使用插件时，请记住两个kubelet命令行参数： cni-bin-dir: kubelet在启动时检测此目录以获取插件 network-plugin： 从cni-bin-dir使用的网络插件 123ps -ef | grep kubelet/usr/bin/kubelet xxx --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni 网络插件需求除了提供网络插件接口来配置和清理pod网络外，该插件还可能需要对kube-proxy提供特定支持。iptables proxy依赖于iptables，插件可能需要确保容器流量可用于iptables。默认情况下，如果未指定kubelet网络插件，则使用noop插件，它设置net/bridge-nf-call-iptables=1来确保简单配置与iptables proxy正常工作。 CNI通过kubelet传递--network-plugin=cni选项来选择CNI插件。kubelet从cni-conf-dir(默认/etc/cni/net.d)中读取文件，并使用该文件中的CNI配置来设置每个pod的网络。引用的插件必须存在于--cni-bin-dir(默认/opt/cni/bin)中。如果目录中有多个CNI配置文件，则使用文件名的词典顺序的第一个。除了配置文件指定的CNI插件外，k8s还需要标准的CNI lo插件(loopback)，最低版本 v0.2.0 kubenetkubelet是一个仅使用与Linux的基本和简单的网络插件。它本身并不实现高级的功能，如跨节点网络或网络策略。kubenet创建一个名为cbr0的Linux bridge，并为每个pod创建一个veth对，每对的主机端连接到连接到cbr0。通过配置或控制器管理器为该对的pod端分配范围内的IP地址。为cbr0分配一个MTU，该MTU与主机上启用的普通接口的最小MTU相匹配。 此插件需要一些东西： 需要标准的CNI bridge, lo, host-local插件，最小版本 v0.2.0。首先从/opt/cni/bin查找。 kubelet必须使用--network-plugin=kubenet参数来启用此插件 kubelet应该指定--non-masquerade-cidr=&lt;clusterCidr&gt;参数确保超出范围的IP流量将使用IP masquerade。 必须通过kubelet的--pod-cidr选项或控制器管理器的--allocate-node-cidrs=true --cluster-cidr=&lt;cidr&gt;选项来为节点分配IP子网 自定义MTU(kubenet)应该始终正确配置MTU以获得最佳网络性能。网络插件通常会推断合理的MTU，但有时不会产生最佳的MTU。如果需要，你可使用kubenet的network-plugin-mtu选项来明确指定MTU，仅有kubenet插件支持此选项。 使用摘要 123--network-plugin=cni--network-plugin=kubenet--network-plugin-mtu=9001 设备插件Device Plugins 从v1.8开始，k8s为Vendors提供了设备插件框架，以便在不更改k8s核心代码的情况下将资源通知到kubelet，Vendor可实现手动部署或作为DaemonSet部署的设备插件，而不是编写自定义的k8s插件。目标设备包括GPU，高性能NIC， FPGA， InfiniBand和其它计算资源。 设备插件注册设备插件功能由DevicePlugins功能控制，默认在 v1.10之前禁用。当启用设备插件功能，kubelet将导出Registration gRPC服务: 123service Registration &#123; rpc Register(RegisterRequest) returns (Empty) &#123;&#125;&#125; 设备插件可通过gRPC服务向kubelet注册自己。在注册中，它需要发送： Unix socket名 设备插件API版本 想要告知的ResourceName 栗子： 1234567891011apiVersion: v1kind: Podmetadata: name: demo-podspec: containers: - name: demo-container-1 image: k8s.gcr.io/pause:2.0 resources: limits: vendor-domain/resource: 2 # requesting 2 vendor-domain/resource 设备插件实现设备插件的一般工作流包括如下步骤： 初始化 插件启动gRPC服务 插件使用kubelet的Unix socket注册自己 注册成功之后，设备插件以服务模式运行，在此期间，它会持续监控设备运行状况，并在任何设备状况发生变化时向kubelet报告 设备插件部署设备插件可手动或作为DaemonSet来部署。k8s 设备插件的支持人处于alpha状态。 服务目录Service Catalog 服务目录是一种扩展API，它使在k8s集群中运行的应用程序能够轻松使用外部托管软件。它提供了从Service Broker 列出，配置和绑定外部托管服务的方法，而无需详细了解如何创建或管理这些服务。使用服务目录，集群操作人员可以浏览服务代理提供的托管服务列表，配置托管服务的实例，并与其绑定以使其可供k8s集群中应用程序使用。 Containers Images你创建Docker image并将其push到registry，然后在k8s pod中引用它。容器的镜像属性支持与Docker命令相同的语法，包括私有注册表和标记。 更新镜像默认的拉取策略是ifNotPresent，这会导致kubelet跳过拉取镜像(如果镜像已存在)。所以在网络不好时，我们可以首先将镜像拉取下来。如果你总想强制拉取镜像，可以执行如下操作： 设置容器imagePullPolicy为Always 使用:latest作为镜像的标记 启用AlwaysPullImages准入控制器 如果没有对镜像指定标记，则假定为:latest标记。 使用私有注册表Using a Private Registry 私有注册表有： Docker Hub Aliyun Tencent yun Google Container Registry AWS Container Registry Azure Container Registry … 以下是配置节点已使用私有注册表的推荐步骤： 12345678910111213141516171819202122232425261. 运行 docker login2. 查看 ~/.docker/config.json&#123; &quot;auths&quot;: &#123; &quot;https://index.docker.io/v1/&quot;: &#123; &quot;auth&quot;: &quot;xxxxxxxxxxxxxxx&quot; &#125; &#125;, &quot;HttpHeaders&quot;: &#123; &quot;User-Agent&quot;: &quot;Docker-Client/18.03.1-ce (linux)&quot; &#125;3. 获取节点列表#namenodes=$(kubectl get nodes -o jsonpath=&apos;&#123;range.items[*].metadata&#125;&#123;.name&#125; &#123;end&#125;&apos;)#IPsnodes=$(kubectl get nodes -o jsonpath=&apos;&#123;range .items[*].status.addresses[?(@.type==&quot;ExternalIP&quot;)]&#125;&#123;.address&#125; &#123;end&#125;&apos;)4. 复制 .docker/config.json 到上面的搜索路径列表for n in $nodes; do scp ~/.docker/config.json root@$n:/var/lib/kubelet/config.json; done 通过创建pod来验证私有镜像： 12345678910111213kubectl create -f - &lt;&lt;EOFapiVersion: v1kind: Podmetadata: name: private-image-test-1spec: containers: - name: uses-private-image image: $PRIVATE_IMAGE_NAME imagePullPolicy: Always command: [ &quot;echo&quot;, &quot;SUCCESS&quot; ]EOFpod &quot;private-image-test-1&quot; created 预拉取镜像Pre-pulling Images 默认情况下，kubelet将尝试从指定的注册表中拉取镜像。但是，如果容器的imagePullPolicy属性为ifNotPresent或Never，则会使用本地镜像。如果你希望依赖于预先拉取的镜像作为注册表身份验证的替代，则必须确保集群中的所有节点都具有相同的预拉取镜像。这可以用于预加载某些镜像以提高速度，或者作为对私有注册表进行身份认证的替代方法。请确保所有的pods都对预拉取的镜像由访问权限。 Specifying ImagePullSecrets on a Podk8s支持在pod上指定registry keys。 123456789101112131415#使用Docker config创建secretkubectl create secret docker-registry -h#Create a new secret for use with Docker registries.kubectl create secret docker-registry zhang21-secret --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAILsecret &quot;myregistrykey&quot; created.kubectl get secretNAME TYPE DATA AGEzhang21-secret kubernetes.io/dockerconfigjson 1 22s#查看和修改kubectl edit secret/zhang21-secret 如果需要访问多个注册表，你可以为每个注册表创建一个secret。当为pod来取镜像时，kubelet会将imagePullSecret合并到 一个虚拟的.docker/config.json文件中。pod只能在自己的命名空间中引用image pull secret，因此每个命名空间都需要执行一次此过程。 pod上的imagePullSecret 12345678apiVersion:kind: Podxxxspec: container: xxx imagePullSecretes: name: zhang21-secret 容器环境变量Container Environment Variables k8s容器环境为容器提供了几个重要资源： 文件系统(是镜像和卷的组合) 容器自身信息 集群中对象的信息 容器生命周期钩子Container Lifecycle Hooks 本节描述了kubelet如何使用容器生命周期钩子框架来运行在管理生命周期中由事件触发的代码。与许多具有组件生命周期钩子的编程语言框架类似，k8s为容器提供了生命周期钩子。钩子使容器能够了解其生命周期中的事件，并在执行相应的生命周期钩子时运行在处理程序中实现的代码。 容器钩子有两个公开给容器的钩子： PostStart此钩子在容器创建后立即执行。但是，无法保证钩子将在容器ENTRYPOINT之前执行。没有参数传递给处理程序。 PreStop此钩子在容器终止前立即调用。它是阻塞的，意味着它是同步的。所以它必须在调用删除容器之前完成才能发送。没有参数传递给处理程序。 Hook handler implementations容器可以通过实施和注册该钩子的处理程序来访问钩子。可为容器实施两种类型的钩子处理程序： Exec： 在cgroup和namespace内执行特定的命令 HTTP： 在容器的特定端点上执行一个HTTP请求 Hook handler exection调用容器生命周期管理钩子时，k8s管理系统会在为钩子注册的容器中执行处理程序。 钩子处理程序调用包含在容器的Pod的上下文中是同步的。这意味着对PostStart钩子，容器ENTRYPOINT和钩子异步启动。但是，如果钩子 运行/挂起 太长时间，则容器无法达到running state。PreStop钩子的行为类似。如果钩子在执行期间挂起，则pod阶段将保持在Terminating state，并在pod结束的terminationGracePeriodSeconds之后被杀掉。如果PostStart或PreStop钩子失败，则会杀掉容器。 用户应该使他们的钩子处理程序尽可能的轻量化。 Hook delivery guarantees钩子交付至少是一次，这意味着对于任何给定的事件可以多次调用钩子。由钩子实现来正确处理这个问题。通常，只进行当次交付。在一些罕见的情况下，可能会发生双重交付。 Debugging Hook handlers钩子处理程序的日志并不会在Pod事件中公开。如果处理程序由于某种原因失败，它会广播这个事件。 工作负载Workloads PodsPod是k8s的基本构建块，是你创建和部署k8s对象模型中最小和最简单的单元。Pod代表了集群上正在运行的进程。Pod封装了(encapsulates) 一个/多个 应用程序容器，存储资源，唯一的IP地址(集群内)以及控制容器运行需要的选项。Pod代表了一个部署单元，k8s中的单个应用程序实例可能包含单个或少量紧密耦合且共享资源的容器。Docker是k8s Pod中最常使用的容器运行环境(runtime)，Pod同样也支持其它容器运行环境。 k8s 集群中的Pods可以用两种主要方法来使用： 运行单个容器的PodPods that run a single containerone-container-per-pod模型时最常见的k8s用例。在这种情况下，你可将Pod视为单个容器的包装，而k8s直接管理Pod而不是容器。 运行多个需要协同工作的容器的PodPods that run multiple containers that need to work togetherPod可能封装了由多个协同定位(co-located)容器组成的应用程序，这些容器紧密耦合并且需要共享资源。这些协同的容器可能形成一个统一的服务单元——一个容器从共享卷向公众提供文件，而一个单独的sidecar容器刷新或更新这些文件。Pod将这些容器和资源作为单个可管理的实体包装在一起。 每个Pod都用于运行给定应用程序的单个实例。如果你想要水平扩展应用程序，你可以使用多个Pods(每个实例一个)。在k8s中，这通常称为副本(replication)。 Replicated Pods通常通过称为控制器(Controller)的抽象来创建和管理。 Pod如何管理多个容器Pods旨在支持多个协作进程(as container)，形成一个具有凝聚力的服务单元。Pod中的容器将自动协同定位(co-located)，并在集群中的同一主机上协同调度(co-scheduled)。容器可以共享资源和依赖，彼此通信，并协调它们何时以及如何终止。 注意，将多个协同定位和协同管理的容器分组到一个Pod中是一个相对高级的栗子。你应该仅在容器紧密耦合的特定实例中使用此模式。例如，你可能有一个容器充当共享卷中文件的Web Server，以及一个单独的sidecat容器——用于从远程更新这个文件： Pod共享资源Pod为其组成容器提供了两种共享资源： Networking每个Pod都被分配了一个唯一的IP地址(within cluster)。Pod中的每个容器都共享网络命名空间，包括IP地址和网络端口。Pod内的容器可使用localhost相互通信。当Pod内的容器与Pod外的实体通信时，它们必须协调如何使用共享网络资源。 StoragePod可以指定一组共享存储卷。Pod中的所有容器都可以访问这个共享卷，允许这些容器共享数据。还是关于数据持久化的卷。 使用Pods你很少直接在k8s(甚至是单例Pod)中创建单独的Pod。这是因为Pod被设计为相对短暂的一次性实体，即用后即焚。当Pod被创建后，都会被调度到集群中的节点上运行。Pod保留在该节点上，知道进程终止，Pod对象被删除，Pod因资源不足而被驱逐，或节点失效。Pod不会自愈。注意： 重启Pod中的容器与重启Pod不是一回事。Pod本身不运行，它只提供容器的运行环境并保持容器的运行状态。但是容器运行的环境会持续存在，直到删除为止。 Pod本身不提供自我修复(self-heal)。如果将Pod调度到一个失败的节点，或调度操作本身失败，则会删除Pod。同样，由于缺乏资源或节点维护中，Pod将无法在驱逐中存活。k8s使用一个高更级别的抽象，称为控制器(Controller)。它管理相对可处理的Pod实例的工作。因此，尽管可以直接使用Pod，但在k8s中使用控制器管理Pod更为常见。控制器可为你创建和管理多个Pod，处理副本和上线，并在集群范围内提供自我修复功能。例如，如果节点故障，控制器可能会通过在不同节点上安排相同的替换来自动替换Pod。通常，控制器使用你提供的Pod模板来创建它负责的Pod。 Pod TemplatesPod模板是Pod规范，包含在其它对象中。控制器使用Pod模板制作实际的Pod。 栗子： 1234567891011apiVersion: v1kind: Podmetadata: name: myapp-pod labels: app: myappspec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo Hello Kubernetes! &amp;&amp; sleep 3600'] Pod模板不是指定所有副本的当前所需状态，而是像饼干切割器。饼干被切割后，饼干与切割器无关。 PodPod是可在k8s中创建和管理的最小可部署的计算单元。 Pod是什么Pod是一组 一个/多个容器，具有共享存储/网络，以及如何运行容器的规范。Pod中的容器总是co-located和co-scheduler，并在共享上下文中运行。一个pod模拟特定应用程序的逻辑主机，它包含一个/多个紧密耦合的应用程序容器。Pod的共享上下文十一组Linux namespace， cgroup，以及隔离方面。在Pod的上下文中，各个应用程序科恩能够回应用进一步的子隔离。Pod中的容器共享IP地址和端口空间，并且可通过localhsot找到彼此。它们还可使用IPC相互通信。不同Pod中的容器具有不同的IP地址，默认情况下无法通信，需要进行额外配置。Pod中的应用程序还可访问共享卷，共享卷被定义为Pod的一部分，可挂载到每个应用程序的文件系统中。就Docker构造而言，Pod被建模为一组具有共享命名空间和共享卷的Docker容器。与单个应用程序容器类似，Pod被认为是相对短暂(非持久)的实体。 Pod动机 管理(Management)Pod是多个协作过程进程模式的模型，形成了一个有凝聚力的服务单元。它们通过提供更高级别的抽象来简化应用程序部署和管理。Pod提供用于部署，水平扩展，副本的单元。对于Pod中的容器，它们将自动处理协同调度， 共享命运， 协同副本，资源共享和依赖管理… 资源共享和交流Pod可以实现成员之间的数据共享和通信。Pod中的应用程序都是用相同的网络命名空间，因此可通过localhost进行通信。因此，Pod中的应用程序必须协调对端口的使用。主机名设置为Pod中应用程序容器的Pod名。除了定义在Pod中运行的应用程序容器，Pod还制定了一组共享存储卷(持久化)。 123456789101112131415kubectl -n kube-system get pod -o wideNAME READY STATUS RESTARTS AGE IP NODEkubernetes-dashboard-6948bdb78-tdh5v 1/1 Running 0 8d 10.244.2.3 salt01metrics-server-85ff8f7b84-72rd4 1/1 Running 0 9d 10.244.2.2 salt01kubectl -n kube-system exec -it metrics-server-85ff8f7b84-72rd4 /bin/sh/ # hostnamemetrics-server-85ff8f7b84-72rd4/ # ifconfigeth0 10.244.2.2/ # ping 10.244.2.3PING 10.244.2.3 (10.244.2.3): 56 data bytes64 bytes from 10.244.2.3: seq=0 ttl=64 time=0.115 ms64 bytes from 10.244.2.3: seq=1 ttl=64 time=0.062 ms Pod使用Pod可用于托管垂直集成的应用程序栈，但主要动机是用于支持协同共处，协同管理的应用程序。如： 内容管理系统，文件和数据加载器，本地缓存管理器 日志和检查点的备份、压缩、轮询、快照 数据变更观察器，日志和监控适配器，事件发布器 代理，网桥和适配器 控制器，管理器，配置器和更新器 通常，单个Pod不用于运行同一程序的多个实例。 替代考虑为什么不在单个容器中运行多个程序？ 透明度 解耦软件依赖关系 使用方便 效率 Pod耐久性Pod不应被视为耐用实体。它们不会在 调度失败，节点故障，驱逐，节点维护等情况下存活。通常，用户不需要直接创建Pod。而应该(几乎总是)使用控制器。控制器提供了集群范围内的自修复(self-healing)，副本和上线管理。 Pod公开为一个原语以便于使用： 调度器和控制器可插拔 支持Pod级操作，而无需通过控制器API代理 将Pod寿命与控制器寿命分离 控制器和服务的分离 kubelet实际是Pod控制器 高可用应用程序 Pod终止由于Pod表示集群中节点上正在运行的进程，因此允许这些进程在不需要时优雅地终止(gracefully terminate)非常重要。用户应该能够请求并指导进程何时终止，但也要确保删除最终完成。当用户请求删除Pod时，系统会在允许Pod强制终止之前记录预期的宽限期(grace period)，并将TERM信号(-15)发送到每个容器的主进程中。宽限期到期后，KILL信号(-9)发送到这些进程，然后从API server中删除该Pod。如果在等待进程终止时Kubelet或容器管理器重启了，则将在完整的宽限期内重试终止。 流程： 用户发送删除Pod的命令，默认宽限期(30s) API server中的Pod随着时间的推移而更新，在此之后，除了宽限期外，Pod被认为死亡 列出客户端命令时，Pod显示为Terminating 当Kubelet发现Pod被标记为Terminating，它将开始Pod关闭过程 4.1 如果Pod定义了preStop hook，则会在Pod内调用 4.2 Pod中的进程发送TERM信号 Pod将从端点列表中删除，并且不再被视为副本控制器中运行的Pod的一部分。缓慢关闭的Pod无法继续为流量提供服务，因为负载均衡器会将其从轮询中删除 当宽限期到期后，仍在Pod中运行的任何进程都将被KILL信号杀死 Kubelet通过设置宽限期0（立即删除）完成删除API server上的Pod。Pod从API中消失，客户端不在可见 默认情况下，所有删除都有30s的宽限期。kubectl delete命令支持指定--grace-period=选项。设置为0表示强制删除Pod。--force --grace-period=0强制删除。 强制删除Pod强制删除Pod被定义为立即从集群状态和etcd中删除Pod。当执行强制删除时，API server不会等待来自Kubelet的确认——确认该Pod已在运行的节点上终止。它会立即删除API中的Pod，以便可使用相同的名称创建新的Pod。在节点上，设置为立即终止的Pod在被强制终止之前仍被授予一个小的宽限期。强制删除可能会对某些Pod有潜在危险，请谨慎执行。 Pod容器的特权模式(Privileged mode)在容器 spec的SecurityContext中使用privileged标志，来启用Pod中容器的特权模式。这对于想要使用Linux功能的容器非常有用。容器内的进程获得与可访问的容器外进程几乎相同的权限。使用特权模式，可以更容易的编写网络和卷插件，而不需要编译到kubelet。 API对象Pod是k8s REST API中的顶级资源, /pod/xxx。 Pod生命周期Pod Lifecycle 阶段(phase)Pod的status字段是一个PodStatus对象，它有一个phase字段。 阶段可能的值： Value Description Pending The Pod has been accepted by the Kubernetes system, but one or more of the Container images has not been created. This includes time before being scheduled as well as time spent downloading images over the network, which could take a while. Running The Pod has been bound to a node, and all of the Containers have been created. At least one Container is still running, or is in the process of starting or restarting. Succeeded All Containers in the Pod have terminated in success, and will not be restarted. Failed All Containers in the Pod have terminated, and at least one Container has terminated in failure. That is, the Container either exited with non-zero status or was terminated by the system. Unknown For some reason the state of the Pod could not be obtained, typically due to an error in communicating with the host of the Pod. 状况(conditions)Pod有一个PodStatus，它有一个PodConditions数组，表示Pod是否通过。每个PodCondition数字的每个元素都有六个可能的字段： lastProbeTime: 最后一次探测Pod状况的字段 lastTransitionTime: Pod最后从一个状态转换到另一个状态的时间戳的字段 message: 有关转换的人类可读的详细信息的字段 reason: 一个独特的，单字的最后转换的原因的字段 status: 字段值可能为True, False, Unknown type: 字段可能有如下值: PodScheduled: Pod已被调度到一个节点 Ready: Pod能提供请求，并应该添加到所有匹配服务的负载均衡池中 Initialized: 所有的初始化容器已成功启动 Unschedulable: 调度器现在无法调度Pod，如缺乏资源… ContainersReady: Pod中的所有容器都已准备好了 探测(probes)探测是由容器上的kubelet定期执行的诊断。为了执行诊断，kubelet调用容器执行处理器(Handler)。有三种类型的处理器: ExecAction: 在容器内执行指定命令。如果状态码为0，则认为诊断成功 TCPSocketAction: 在指定端口的容器IP地址执行TCP检查。如果端口打开，则认为诊断成功 HTTPGetAction: 在容器IP的特定端口的路径下执行HTTP GET请求。如果请求成功，则认为诊断成功 每个探测可能有三种结果: Success Failure Unknown kubelet可选择在运行容器上执行两种探测并对其作出反应: livenessProbe: 确定容器是否正在运行 readinessProbe: 确定容器是否准备好为请求提供服务 什么时候使用这两中探测？When should you use liveness or readiness probes? 如果容器中的进程在遇到问题或变得不健康时会自行崩溃(crash)，则你不一定需要livenessProbe。kubelet将根据Pod的restartPolicy自动执行正确的操作。如果希望在探测失败时杀死并重启容器，则请指定livenessPorbe和指定restartPolicy为Always 如果只想在探测成功时向Pod发送流量，请指定readinessProbe。如果容器需要在启动期间除了大型数据，配置文件或迁移，请指定readnessProbe。如果你希望容器能够自行维护，你可指定一个readnessProbe，它检查特定端点。 注意，如果你只想在删除Pod时排除请求，则不一定需要readnessProbe。无论是否存在readnessProbe，Pod都会自动将其置于未准备状态。Pod在等待Pod中容器停止时仍处于未准备状态。 Pod readiness gateFEATURE STATE: Kubernetes v1.11 alpha 为了通过向PodStatus调价额外的反馈或信号来增加Pod readness的可扩展性，k8s v1.11引入了一个名为Pod ready++的功能。你可在PodSpec中使用新字段ReadinessGate来指定要为Pod准备情况评估的其它条件。如果k8s在Pod的status.conditions字段找不到这样的状况，则状况的状态默认为False。 12345678910111213141516171819Kind: Pod...spec: readinessGates: - conditionType: &quot;www.example.com/feature-1&quot;status: conditions: - type: Ready # this is a builtin PodCondition status: &quot;True&quot; lastProbeTime: null lastTransitionTime: 2018-01-01T00:00:00Z - type: &quot;www.example.com/feature-1&quot; # an extra PodCondition status: &quot;False&quot; lastProbeTIme: null lastTransitionTime: 2018-01-01T00:00:00Z containerStatuses: - containerID: docker://abcd... ready: true... 重启策略PodSpec有一个restartPolicy字段，其值可能是Always(默认值), OnFailure, Never。此策略应用于Pod中的所有容器，它仅指由同一节点上的kubelet重启的容器。退出的容器将由kubelet以指定退避延迟(10s, 20s, 40s…)重新启动，上限5分钟，并在成功执行十分钟后重置。 寿命(lifetime)一般来说，Pod不会消失，直到有人摧毁它们。唯一的例外是，具有成功或失败超过一段时间的阶段的Pod将过期并自动销毁。 有三种类型的控制器可用： Use a Job for Pod Use a ReplicationController/ReplicaSet/Deployment for Pod Use a DaemonSet for Pod 所有三种类型的控制器都包含了PodTemplate。推荐创建适当的控制器并让它创建Pod，而不是自己直接创建Pod。这是因为Pod单独对机器故障没有弹性，但控制器不会。如果节点死亡或与集群的其余部分断开连接，k8s会应用策略将丢失节点上的所有Pod的阶段设置为Failed。 Init Containers本节提供了初始容器(init container)的概述，它是在应用程序容器运行之前的专用容器，可包含应用程序镜像中不存在的实用程序或脚本设置。 理解初始容器Pod可以有多个容器在其中运行应用程序，但它同样可以有一个或多个初始容器——它在应用程序容器启动前运行。初始容器与常规容器一样，除了： They always run to completion. 每一个必须在下一个启动之前成功完成 如果Pod的初始容器失败，则k8s会重复重启直到初始容器成功。但是，如果Pod的restartPolicy为Never，则不会重启。要将容器指定为初始容器，请将PodSpec上的initContainers字段添加为应用程序container数组旁边的容器类型对象的JSON数组。初始容器的状态在.status.initContainerStatuses字段中作为容器状态数据返回。 与常规容器的不同初始容器支持应用程序容器的所有字段和功能，包括资源限制，卷和安全设置。但资源请求和处理方式略有不同。此外，初始容器不支持readiness probes，因为它必须在Pod准备好之前运行完成。如果为Pod指定了多个初始容器，则按顺序依次运行一个容器。每个必须在下一个运行之前完成。当所有初始容器都运行完毕时，k8s会初始化Pod并像往常一样运行应用程序容器。 初始容器可用于什么由于初始容器具有来自应用程序容器的单独镜像，因此它们对于启动相关代码具有一些优势： 出于安全原因，它们可以包含并运行不希望包含在应用程序容器镜像中的使用程序 它可以包含应用程序镜像中不存在的实用程序或自定义代码。例如，在配置过程中，无需为了使用其他工具(sed, awk, dig…)而专门使用FROM创建一个镜像 应用程序镜像构建器和部署器角色可独立工作，而无需共同构建单个应用程序镜像 它们使用Linux命名空间，以便从应用程序容器中获得不同的文件系统视图。因此，它们可以访问应用程序容器无法访问的Secrets 它们在应用程序容器启动前运行完成，因此初始容器提供了一种简单的方法来阻止或延迟应用程序容器的启动，知道满足一组前置条件。 栗子这有些初始容器的使用案例: 等待使用shell命令创建服务: for in in {1..100}; do sleep 1; if dig myservice; then exit 0; fi; done; exit 1 使用API从远程服务器注册此Pod: curl -XPOST http://host:port/register -d &#39;instance=$()&amp;ip=$()&#39; 在启动应用程序之前等待一段时间: sleep 60 克隆一个git repo到某个卷 替换配置文件中的值并运行模板来动态生成应用程序容器的配置文件 使用初始容器两个初始容器。第一个等待myservice，第二个等待mydb。一旦两个容器完成，Pod将开始。 123456789101112131415161718apiVersion: v1kind: Podmetadata: name: myapp-pod labels: app: myappspec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo The app is running! &amp;&amp; sleep 3600'] initContainers: - name: init-myservice image: busybox command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;'] - name: init-mydb image: busybox command: ['sh', '-c', 'until nslookup mydb; do echo waiting for mydb; sleep 2; done;'] 创建: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970kubectl create -f /etc/k8s/test/init-container.yamlpod/myapp-pod createdkubectl get podNAME READY STATUS RESTARTS AGEinit-container 0/1 Init:0/2 0 6skubectl describe -f /etc/k8s/test/init-container.yamlInit Containers: init-myservice: Container ID: docker://f9ca73d4d2c8903a1fe84937e34ae27b909a691d2e524254b8f4aec9d5cc754c Image: busybox Image ID: docker-pullable://docker.io/busybox@sha256:cb63aa0641a885f54de20f61d152187419e8f6b159ed11a251a09d115fdff9bd Port: &lt;none&gt; Host Port: &lt;none&gt; Command: sh -c until nslookup myservice; do echo waiting for myservice; sleep 2; done; State: Terminated Reason: Completed Exit Code: 0 Started: Fri, 24 Aug 2018 16:31:13 +0800 Finished: Fri, 24 Aug 2018 16:31:18 +0800 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-69vgk (ro) init-mydb: Container ID: docker://a9946122976ff70ff1dd874299e3e63f4b07f2758f5e6518b84343c58daa3506 Image: busybox Image ID: docker-pullable://docker.io/busybox@sha256:cb63aa0641a885f54de20f61d152187419e8f6b159ed11a251a09d115fdff9bd Port: &lt;none&gt; Host Port: &lt;none&gt; Command: sh -c until nslookup mydb; do echo waiting for mydb; sleep 2; done; State: Terminated Reason: Completed Exit Code: 0 Started: Fri, 24 Aug 2018 16:31:24 +0800 Finished: Fri, 24 Aug 2018 16:31:29 +0800 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-69vgk (ro)Containers: myapp-container: Container ID: docker://b2c7a1f32d65dd41fa439d1f6879824b40c3014b32b15d61fed0cda171144a1b Image: busybox Image ID: docker-pullable://docker.io/busybox@sha256:cb63aa0641a885f54de20f61d152187419e8f6b159ed11a251a09d115fdff9bd Port: &lt;none&gt; Host Port: &lt;none&gt; Command: sh -c echo The app is running! &amp;&amp; sleep 3600 State: Running Started: Fri, 24 Aug 2018 16:31:34 +0800 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-69vgk (ro) 详细行为在Pod启动期间，初始化网络和卷后，初始容器将按顺序启动。每个容器必须在下一个容器启动前成功退出。如果容器由于运行环境未能启动或失败退出而启动失败，则它根据Pod的restartPolicy重试。如果Pod的restartPolicy为Always(默认)，则初始容器使用restartPolicy为OnFailure。在所有初始容器都成功之前，Pod无法变为Ready。初始容器上的端口无法聚合到服务下。正在初始化的Pod处于Pending状态，但应该具有Initializing设置为true的条件。如果Pod重启，则所有初始都要执行一遍。init container spec的更改仅限于容器镜像字段。更改初始容器镜像字段相当于重启Pod。由于初始容器可重启，重试或重新执行，因此初始容器代码应该是幂等的。In particular, code that writes to files on EmptyDirs should be prepared for the possibility that an output file already exists.在Pod上使用activeDeadlineSeconds，在容器上使用livenessProbe，以防止初始容器永远失败。Pod中每个应用程序和初始容器的名称必须是唯一的，否则会引发验证错误。 资源给定初始容器的排序和执行，适用一下资源使用规则： 在所有初始容器上定义的任何特定资源请求或限制的最高值是有效的初始 请求/限制 Pod对资源的有效请求/限制是以下值中的较高者: 所有的应用程序容器对资源请求/限制的总和 对资源的有效初始请求/限制 调度是基于有效请求/限制完成的，这意味着初始容器可以保留在Pod生命周期内未使用的初始化资源 Pod的有效QoS层与初始容器和应用程序容器一样 Pod级别的cgroup基于有效的Pod请求和限制，与调度程序相同。 Pod重启原因由于以下原因，Pod可重新启动，导致重新执行初始容器： 用户更新了PodSpec，导致初始容器镜像发生噶变。应用程序容器镜像的更改仅重启应用程序容器 Pod的基础架构容器重启 Pod的所有容器都终止，而restartPolicy设置为Always，强制重启，并且初始容器完成记录由于垃圾回收而丢失 Pod预设Pod Preset Pod Presets是对象，在创建时将特定信息注入Pod。Pod Preset是一种API资源，用于在创建时将其它运行时的需求写入到Pod。你可使用label selectors指定应用于Pod的给定Pod Preset。使用Pod Preset允许pod template作者不必显示提供每个pod的所有信息。这样，作者不需要知道有关该服务的所有详细信息。 它如何工作k8s提供了一个admission controller(Pod Preset)，启用后，会将Pod Preset应用于传入的pod创建请求。当Pod创建请求发生时，系统会执行一下操作： 检索所有可供使用的Pod Preset 检查任何Pod Preset的label selector是否与正在创建的Pod上的标签匹配 尝试将Pod Preset定义的各种资源合并到正在创建的Pod中 出错时，抛出一个记录Pod 合并错误的事件，然后创建不从Pod Preset写入任何资源的pod 注释生成的修改后的Pod spec，以表明它已被Pod Preset修改——podpreset.admission.kubernetes.io/podpreset-&lt;pod-preset name&gt;: &quot;&lt;resource version&gt;&quot; 每个Pod能够被零个或多个PodPreset匹配，每个PodPreset可以被应用到零个或多个Pod。当PodPreset应用于一个或多个Pod时，k8s会修改Pod spec。对于Env, EnvFrom, VolumeMounts，k8s修改Pod中所有容器的container spce；对于Volume的更改，k8s修改Pod spec。 为指定Pod禁用PodPreset在某些情况下，你希望Pod不被任何PodPreset修改。你可修改: podpreset.admission.kubernetes.io/exclude: &quot;true&quot; 启用PodPreset要在集群中使用PodPreset，你必须确保以下内容： 你已启用API类型: settings.k8s.io/v1alpha1/podpreset 你已经启动admission controller PodPreset 你已通过在将使用的命名空间中创建PodPreset对象来定义PodPreset 中断Disruptions 本节适用于想要构建高可用性应用程序的用户，因此需要了解Pod可能发生的中断类型。这同样适用于希望执行自动化集群操作的集群管理员，例如升级或自动伸缩集群。 自愿和非自愿中断Voluntary and Involuntary Disruptions Controller ReplicaSet副本集是下一个副本控制器。现在副本集和副本控制器之间的唯一区别是selector的支持。副本集支持labels user guide中描述的新的基于集合selector的要求，而副本控制器仅支持基于等同selector的要求。 如何使用副本集大多数支持副本控制器的kubectl命令也支持副本集。一个例外是rolling-update命令。如果你想要滚动更新功能，请考虑使用Deployments代替。虽然副本集可独立使用，但它主要被Deployment用作协调Pod创建，删除和更新的机制。使用部署时，你不必担心管理它们创建的副本集，部署拥有并管理其副本集。 何时使用副本集副本集确保在任何给定时间运行指定数量的Pod副本。但是，部署是一个更高级别的概念，它管理副本集并为Pod提供声明性更新以及许多其它有用的功能。因此，除非你需要自定义更新或无需更新，否则建议你使用部署而不是直接使用副本集。这实际上意味着，你不需要操作副本集对象：改为使用部署，并在spec部分定义你的应用程序。 栗子 1234567891011121314151617181920212223242526272829303132333435363738apiVersion: apps/v1kind: ReplicaSetmetadata: name: frontend labels: app: guestbook tier: frontendspec: # modify replicas according to your case replicas: 3 selector: matchLabels: tier: frontend matchExpressions: - &#123;key: tier, operator: In, values: [frontend]&#125; template: metadata: labels: app: guestbook tier: frontend spec: containers: - name: php-redis image: gcr.io/google_samples/gb-frontend:v3 resources: requests: cpu: 100m memory: 100Mi env: - name: GET_HOSTS_FROM value: dns # If your cluster config does not include a dns service, then to # instead access environment variables to find service host # info, comment out the 'value: dns' line above, and uncomment the # line below. # value: env ports: - containerPort: 80 1kubectl create -f /etc/k8s/test/frontend.yaml 编写副本集spec与所有其它k8s API对象一样，副本集需要apiVersion, kind, metadata字段，副本集还需要一个.spce部分。 123456789101112131415161718#Pod Template.spec.template是.spec唯一必需的字段除了pod的必须字段，副本集中的Pod模板还必须指定适当的`label`和`restart policy`#Pod Selector.spec.selector字段是一个label selector。副本集使用与selector匹配的label来管理所有pod。它不区分创建或删除的Pod以及人或进程创建或删除的pod。这允许替换副本集而不会影响正在运行的Pod。.spec.template.metadata.labels 必须匹配 .spec.selector，否则它将被API拒绝。此外，你通常不应创建任何label与selector匹配的pod。如果你这样做了，副本集会认为它创建了其它pod，k8s并没有阻止你这样做。#Labels on a ReplicaSet副本集本身可以有标签(.metadata.labels)。通常，你可将其设置为与 .spec.template.metadata.labels 一致。但，允许他们不同，并且 .metadata.labels 不会影响副本集的行为#Replicas你可通过设置 .spec.replicas 来指定应同时运行的pod数量。如果未指定，默认为1 使用副本集 1234567891011121314151617181920212223242526272829303132333435363738394041424344#删除副本集和它的podskubectl delete replicaset/xxx#或kubectl proxy --port=8080curl -XDELETE &apos;localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend \-d &apos;&#123;&quot;kind&quot;:&quot;DeleteOptions&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;propagationPolicy&quot;:&quot;Foreground&quot;&#125;&apos; \-H &quot;Content-Type: application/json&quot;#仅删除副本集kubectl delete rs/xxx --cascade=false#或kubectl proxy --port=8080curl -X DELETE &apos;localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend&apos; \-d &apos;&#123;&quot;kind&quot;:&quot;DeleteOptions&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;propagationPolicy&quot;:&quot;Foreground&quot;&#125;&apos; \-H &quot;Content-Type: application/json&quot;#从副本隔离pods可通过更改label从副本集的目标中删除Pod。此技术可用于从服务中删除pod以进行调试，数据恢复等。以这种方式删除的pod将自动替换#伸缩副本集只需更新副本集的 .spec.replicas 字段轻松伸缩副本集。副本集控制器确保具有匹配 label selector 所需数量的pod可用且可操作。#作为水平pod自动伸缩目标的副本集Horizontal Pod Autoscalers(HPA)，意味着副本集可通过HPA自动伸缩。#栗子apiVersion: autoscaling/v1kind: HorizontalPodAutoscalermetadata: name: frontend-scalerspec: scaleTargetRef: kind: ReplicaSet name: frontend minReplicas: 3 maxReplicas: 10 targetCPUUtilizationPercentage: 50kubectl create -f /path/xx/hpa.rs.yaml#此外，可使用kubectl命令来自动伸缩#kubectl autoscale rs frontend 替代副本集 Deployment(推荐) Bare Pods Job DaemonSet ReplicationController注意：现在，配置副本集的推荐方法是使用部署。 副本控制器确保一次运行指定数量的Pod副本。换言之，副本控制器确保一个Pod或一组同类Pod总是可用。 Deployments部署控制器为Pod和ReplicaSet提供了声明性更新。在部署对象中描述所需的状态，部署控制器以受控速率将实际状态更改为所需状态。你可定义部署来创建新的副本集，或删除现有的部署并使用新的部署收纳所有资源。你不应该直接管理部署所拥有的副本集，应该通过操作部署对象来涵盖所有用例。 栗子以下是部署的典型案例： 创建部署来上线副本集 声明Pod的新状态 回滚到早期的部署版本 伸缩部署 暂定部署 使用部署的状态 清理旧的副本集 创建一个部署下面的栗子，创建一个3个Nginx pods的副本集: 123456789101112131415161718192021apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment labels: app: nginxspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 12345kubectl create -f ./nginx-deployment.yamlkubectl get deploymentkubectl get rskubectl get pod --show-labels 更新部署当且仅当部署的pod template发生更改时，才会触发部署更新上线。假如我们要更新Nginx的版本为1.9.1: 12345678910111213141516171819202122232425kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1deployment.extensions/nginx-deployment image updated#或者kubectl edit deployment/nginx-deploymentdeployment.extensions/nginx-deployment edited#查看上线状态kubectl rollout status deployment/nginx-deploymentWaiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 old replicas are pending termination...Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 old replicas are pending termination...deployment &quot;nginx-deployment&quot; successfully rolled out#新旧副本集副本数kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deployment-67594d6bf6 0 0 0 16mnginx-deployment-d78fcfc84 3 3 3 3m 部署可以确保在更新时只有一定数量的Pod可能会关闭。默认情况下，它确保最大不可用率25%。部署确保在所需数量的Pod之上只能创建一定数量的Pod。默认情况下，它确保比最大数多25%。例如，如果仔细查看上面的部署，你将看到它首先创建了一个新的Pod，然后删除了一些旧的Pod并创建新的Pod。在有足够数量的新Pod出现之前，它不会杀死旧的Pod，并且在足够数量的旧Pod被杀死之前不会创建新的Pod。 通常不鼓励进行label selector的更改，建议你事先规划好selector。 回滚(rolling back)部署有时可能需要回滚部署，当部署不稳定时，如崩溃循环(crash looping)。默认情况下，所有的部署上线历史都保留在系统中，以便可以随时回滚。 假设我之间将nginx:1.7.1更新到nginx:1.9.1的时候错误的写成了nginx:1.91: 1234567891011121314kubectl set image deployment/nginx-deployment nginx=nginx:1.91#上线就会卡在此处kubectl rollout status deployments nginx-deploymentWaiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...error: deployment &quot;nginx-deployment&quot; exceeded its progress deadline#查看容器错误，它会报镜像拉取错误kubectl get podnginx-deployment-58c7645486-s5t6t 0/1 ImagePullBackOff 0 3m &lt;none&gt; node#UI里面的报错#Failed to pull image &quot;nginx:1.91&quot;: rpc error: code = Unknown desc = manifest for docker.io/nginx:1.91 not found 部署控制器将自动停止错误的rollout，并将停止扩展新的副本集。这取决于滚动升级的参数(maxUnavailable)。默认情况下，k8s将值设置为1，将.spec.replicas设置为1，因此你无需关心设置这些参数。你的部署可能具有100%的不可用性。 要修复它，你需要回滚到先前稳定的部署版本。 1234567891011121314151617181920212223242526272829#检查上线历史kubectl rollout history deployment/nginx-deploymentdeployments &quot;nginx-deployment&quot;REVISION CHANGE-CAUSE1 kubectl create -f ./nginx-deployment.yaml --record2 kubectl set image deployment/nginx-deployment nginx=nginx:1.9.13 kubectl set image deployment/nginx-deployment nginx=nginx:1.91#查看某个上线历史rollout history deployment/nginx-deployment --revision=2#回滚#回滚到前一个版本kubectl rollout undo deployment/nginx-deploymentdeployment.extensions/nginx-deployment#回滚到指定版本kubectl rollout undo deployment/nginx-deployment --to-revision=2#查看事件kubectl describe deployment/nginx-deploymentEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal DeploymentRollback 2m deployment-controller Rolled back deployment &quot;nginx-deployment&quot; to revision 3 Normal ScalingReplicaSet 2m deployment-controller Scaled down replica set nginx-deployment-58c7645486 to 0 伸缩副本 1234567891011#扩展部署kubectl scale deployment nginx-deployment --replicas=5#水平伸缩kubectl autoscale deployment nginx-deployment --min=3 --max=6 --cpu-percent=80#查看kubectl get horizontalpodautoscaler.autoscalingNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGEnginx-deployment Deployment/nginx-deployment &lt;unknown&gt;/80% 3 6 5 1m 比例伸缩(proportional scaling)滚动升级部署支持同时运行多个版本的应用程序。当你或自动伸缩器正在上线滚动更新的部署时，部署控制器将平衡现有活动的副本集中的其它副本，以降低风险。这称为比例缩放。 1234567891011121314151617kubectl get deployNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx-deployment 5 5 5 5 1h#更新一个错误镜像，它会卡住kubectl set image deploy/nginx-deployment nginx=nginx:sometagkubectl get rs -o wideNAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTORnginx-deployment-895bd59bc 3 3 0 1m nginx nginx:sometag app=nginx,pod-template-hash=451681567nginx-deployment-d78fcfc84 5 5 5 1h nginx nginx:1.7.1 app=nginx,pod-template-hash=834979740kubectl get deploy -o wideNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTORnginx-deployment 6 8 3 5 1h nginx nginx:sometag app=nginx 暂停和恢复部署你可以在触发一个或多个更新之前暂停(pause)部署，然后恢复(resume)它。这允许你在暂停和恢复之间应用多个修复，而不会触发不必要的上线。注意： 在恢复暂停部署之前，无法执行回滚操作。 123456789101112131415#暂停kubectl rollout pause deployment/nginx-deploymentdeployment.extensions/nginx-deployment pausedkubectl set image deploy/nginx-deployment nginx=nginx:1.9.1deployment.extensions/nginx-deployment image updatedkubectl set resources deployment nginx-deployment -c=nginx --limits=cpu=200m,memory=128Mideployment.extensions/nginx-deployment resource requirements updated#恢复kubectl rollout resume deployment/nginx-deploymentdeployment.extensions/nginx-deployment resumed 部署状态部署在其生命周期内会进入各种状态–kubectl rollout status Progessing Deployment 部署创建一个新的副本集 部署伸缩到新的/旧的副本集 新的Pod可用 Complete Deployment 所有与部署关联的副本都已完成 所有与部署关联的副本都可用 没有正在运行的旧的部署副本 Failed Deployment 配额不足 准备探针失败 镜像拉取失败 权限不足 限制范围 应用程序运行时配置错误 Operating on a failed deployment Clean up Policy可在部署中设置.spec.revisionHistoryLimit字段来指定需要保留的旧副本集数。其余的将在后台被垃圾回收，默认为10。 注意：将此字段设置为0会导致清理部署的所有历史记录，从而部署将无法回滚。 Deployment Spec与其它k8s配置一样，Deployment需要apiVersion, kind, metadata字段。但部署还需要.spec 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#pod template#必填字段.spec.template#Replicas.spec.replicas#Selector#它必须匹配.spec.template.metadata.labels，否则会被API拒绝.spec.selector#Strategy.spec.strategy#Recreate deployment.spec.strategy.type==Recreate#Rolling Update Deployment.spce.stratefy.type==RollingUpdate#Max Unavailable.spec.strategy.rollingUpdate.maxUnavailable#Max Surge.specstrategy.rollingUpdate.maxSurge#Progress Deadline Seconds.spec.progressDeadlineSeconds#Min Ready Seconds.spec.minReadySeconds#Rollback To.spec.rollbackTo#Revision History Limit.spec.revisionHistoryLimit#Paused.spec.paused 替代方案 kubectl rolling updatekubetl rolling update以类似的方式更新Pod和副本集控制器。但建议使用部署，因为它是声明性的。 StatefulSetsStatefulSet是用于管理有状态应用程序的工作负载的API对象。Note: StatefulSets are stable (GA) in 1.9. 管理一组Pod的部署和伸缩，并提供有关这些Pod的序列和唯一性的保证。与部署类似，有状态集管理基于相同容器规范(spec)的Pod；与部署不同，有状态集为其每个Pod维护一个粘性(sticky)标识。这些Pod根据相同的规范创建，但不可互换，每个Pod都有一个持久的标识符，它可在任何重新调度时保留。有状态集与任何其它控制器相同的模式运行。你在有状态集对象中定义所需的状态，有状态集控制器进行任何必要的更新以从当前状态到达期望状态。 使用有状态集有状态集对于需要以下一个或多个应用程序非常有用： 稳定，唯一的网络标识 稳定，持久存储 有序，优雅的部署和伸缩 有序，优雅的删除和终止 有序，自动的滚动更新 如果应用程序不需要任何稳定标识或有序部署、删除、伸缩，则应该使用提供一组无状态副本的控制器来部署你的应用程序。如部署或副本集这样的控制器可能更适合无状态需求。 局限(limitations) k8s v1.9+ 给定Pod的存储必须由PersistentVolume Provisioner根据请求的存储类进行配置，或由管理员预先配置 删除/伸缩有状态集将不会删除与有状态集相关联的卷。这是为了确保数据安 有状态集目前要求headless service负责Pod的网络身份，你有责任创建此服务 组件(components) headless service，用于控制网络域 StatefulSet volumeClaimTemplates，使用持久化卷提供稳定存储 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748apiVersion: v1kind: Servicemetadata: name: nginx labels: app: nginxspec: ports: - port: 80 name: web clusterIP: None selector: app: nginx---apiVersion: apps/v1kind: StatefulSetmetadata: name: webspec: selector: matchLabels: app: nginx # has to match .spec.template.metadata.labels serviceName: "nginx" replicas: 3 # by default is 1 template: metadata: labels: app: nginx # has to match .spec.selector.matchLabels spec: terminationGracePeriodSeconds: 10 containers: - name: nginx image: k8s.gcr.io/nginx-slim:0.8 ports: - containerPort: 80 name: web volumeMounts: - name: www mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: www spec: accessModes: [ "ReadWriteOnce" ] storageClassName: "my-storage-class" resources: requests: storage: 1Gi Pod Selector必须设置有状态集的.spec.selector字段以匹配.spec.template.metadata.labels的标签。 Pod Identity有状态集Pod有一个唯一的标识，由序数、稳定的网络表示和稳定的网络存储组成。 Ordinal Index对于有多个副本的有状态集，有状态集中的每个Pod将被分配一个唯一的整数序数(ordinal)，从0–(N-1)。 Stable Network ID有状态集中的每个Pod都从有状态集的名称和Pod的序号中派生其主机名。构造的主机名的模式时$(statefulset name)-$(ordinal)。 Stable Storagek8s为每个VolumeClaimTemplate创建一个PersistentVolume。 Pod Name Label当有状态集控制器创建Pod时，它会添加一个标签statefulset.kubernetes.io/pod-name，该标签设置为Pod的名称。该标签允许你将服务附加到有状态集中的特定Pod。 部署和伸缩保证(guarantees) 对于有多个副本的有状态集，当Pod被部署时，它们按顺序从{0…N-1}被创建 但Pod被删除，它们将以{N-1…0}的相反顺序终止 在伸缩操作应用于Pod之前，所有的前置任务(predecessors)必须是Running和Ready 在终止Pod之前，其所有后继者(successors)必须完全关闭 有状态集不应该指定pod.Spec.TerminationGracePeriodSeconds为0，这很不安全，强烈建议不要这么做。 k8s v1.7+，有状态集允许你放宽Pod管理策略的排序保证，同时通过其.spec.podManagementPolicy字段保留期唯一性和身份保证。OrderedReady pod管理是有状态集的默认设置。Parallel pod管理告诉有状态集控制器并行(parallel)启动或终止所有Pod，并且在启动或终止另一个Pod之前不等待Pod变为Running、Ready或完全终止。 更新策略有状态集的.spec.updateStrategy字段允许你为有状态集中的Pod配置和禁用容器、标签、资源请求/限制、注释的自动更新。 DaemonSet守护进程集确保所有(或某些)节点运行Pod的副本。随着节点添加到集群中，会将Pod添加到集群中。随着节点从集群中移除，Pod将被垃圾回收。删除一个守护进程集会清除它创建的Pod。 守护进程集的一些典型用法： 在每个节点上运行集群存储守护进程 在每个节点上运行日志收集守护进程 在每个节点上运行一个节点监控守护进程 Writing a DaemonSet Spec 123456789101112131415161718192021222324252627282930313233343536373839404142apiVersion: apps/v1kind: DaemonSetmetadata: name: fluentd-elasticsearch namespace: kube-system labels: k8s-app: fluentd-loggingspec: selector: matchLabels: name: fluentd-elasticsearch template: metadata: labels: name: fluentd-elasticsearch spec: tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule containers: - name: fluentd-elasticsearch image: k8s.gcr.io/fluentd-elasticsearch:1.20 resources: limits: memory: 200Mi requests: cpu: 100m memory: 200Mi volumeMounts: - name: varlog mountPath: /var/log - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true terminationGracePeriodSeconds: 30 volumes: - name: varlog hostPath: path: /var/log - name: varlibdockercontainers hostPath: path: /var/lib/docker/containers 12#创建守护进程集kubectl create -f ./daemonset.yaml Required Fields与其它k8s配置一样，守护进程集需要apiVersion, kind, metadata, .spec字段。 Pod Template.spec.template是.spec的必要字段。守护进程集中的人Pod模板必须要RestartPolicy: Always(默认)。 Pod Selector 仅在某些节点上运行Pod如果指定了.spec.template.spce.nodeSelector，则守护进程控制器将在node selector匹配的节点上创建Pod。同样，如果指定了.spec.template.spec.affinity，则守护进程控制器将在与该节点关联匹配的节点上创建Pod。如果未指定任何一个，则守护进程控制器将在所有节点上创建Pod。 Daemon Pods如何调度 由守护进程集控制器调度（默认）通常，Pod运行的机器由k8s调度程序选择。然而，由守护进程集控制器创建的Pod已经选择了机器(.spec.nodeName)。 由默认调度器调度功能阶段： k8s v1.11 alpha守护进程集确保所有符合条件的节点都运行Pod的副本。 Taints and Tolerations Daemon Pods间通信守护进程集中Pod通信的一些可能模式： Push NodeIP and Known Port DNS Service 更新DaemonSet如果更改了节点标签，守护进程集会立即将Pod添加到新匹配的节点，并从新匹配的节点中删除Pod。可以修改守护进程集创建的Pod。然而，Pod不允许更新所有字段。同样，守护进程集控制器在下次创建节点时使用原始模板。你也可以删除守护进程集，若指定了--cascade=false，则会在节点上保留Pod。 守护进程集的替代方案 Init Scripts Bare Pods Static Pods Deployments 垃圾回收Garbage Collection k8s垃圾回收的作用是删除曾经拥有所有者，但不再拥有所有者的某些对象。 Owners and dependents一些k8s对象是其它对象的所有者。如副本集是一组Pod的所有者。拥有的对象称为所有者的依赖项(dependents)。每个依赖对象都有一个metadata.ownerReferences字段来指向所有者。 控制垃圾回收器如何删除依赖项删除对象时，可以指定是否也自动删除对象的依赖项。删除对象而不自动删除依赖项，则称依赖项为孤立对象(orphaned)。自动删除依赖项被称为级联删除(cascading deletion)，这有两种级联删除模式： Foreground Background 设置级联删除策略删除对象时，设置deleteOptions参数的propagationPolicy字段来控制级联删除策略。 JobsJobs - Run to Completion 作业创建一个或多个Pod，并确保指定数量的Pod成功终止。随着Pod成功完成，作业跟踪也成功完成。删除作业将清除它创建的Pod。作业还可用于并行运行多个Pod。 栗子 12345678910111213apiVersion: batch/v1kind: Jobmetadata: name: pispec: template: spec: containers: - name: pi image: perl command: ["perl", "-Mbignum=bpi", "-wle", "print bpi(2000)"] restartPolicy: Never backoffLimit: 4 123456789kubectl create -f ./job.yamljob.batch/pi createdkubectl get jobkubectl describe job/pikubectl get podkubectl logs pi-xxx Job Spec与其它k8s配置一样，Job也需要apiVersion, kind, metadata, .spec字段。 Pod Template.spec.template是.spce字段的必要项。 Pod Selector.spec.selector字段可选。 Parallel Jobs: 有三种主要类型作业 Non-parallel Jobs 通常指启动一个Pod，除非Pod失败 Pod成功终止后，作业即告完成 Parallel Jobs with a fixed completion count 为.spec.completions指定非零正值 当1-.spec.completions范围内的每个值都有一个成功的Pod时，作业就完成了 尚未实施，每个Pod都传递了1-.spec.completions范围内不同的索引 Parallel Jobs with a work queue 每个Pod独立地确定是否所有对等都完成，因此整个Job完成 当任何Pod成功终止，不会创建新的Pod 一旦至少一个Pod成功终止并且所有Pod终止，则作业成功完成 一旦任意Pod已成功退出，其它任何Pod都不应该做任何工作或输出 控制并行Controlling Parallelism 请求的并行性(.spec.parallelism)可以设置为任何非负值。如果未指定，则默认为1.如果指定为0，则作业将暂停，直至其增加。由于各种原因，实际并行性(在任何时刻运行的Pod数量)可能多于或少于请求的并行度： 对于固定完成计数的作业，并行运行的实际Pod数不会超过剩余的Pod数 对于工作多列作业，任何Pod成功后都不会启动新的Pod，但允许剩余的Pod完成 如果控制器没有时间做出反应 如果控制器因任何原因无法创建Pod 由于同一作业中过多的先前Pod故障，控制器可能会限制新的Pod创建 当Pod正常关闭时，停止需要一些时间 处理Pod和Container失败Pod中的容器可能由于多种原因而失败，如果发生此情况，并且.spec.template.spec.restartPolicy = &quot;OnFailure&quot;，那么Pod会留在节点上，但容器会重新运行。因此，你的程序需要在本地处理此情况，或指定.spec.template.spec.restartPolicy = &quot;Never&quot;。 一个完整的Pod也可能由于多种原因而失败。当Pod失败时，作业控制器启动一个新的Pod。因此，你的程序需要在新Pod重启时处理此情况。 Pod Backoff failure policy在某些情况下，由于配置中的逻辑错误等原因，你需要在重试一段时间后使作业失败。为此，可设置.spec.backoffLimit将作为视为失败前的重试次数。默认值为6s。与作业关联的失败的Pod由作业控制器重新创建，指数退避延迟(10s, 20s, 40s…)，上限6分钟。如果在作业的下一次状态检查之前没有出现新的故障Pod，则重置退避计数。 作业终止和清理Job Termination and Cleanup 作业完成后，不会再创建Pod，也不会删除Pod。保持它们可让你仍然能查看已完成的Pod的日志以检查error, warning, 或其它诊断性输出。作业对象在完成后也会保留，以便可查看其状态。在注意到其状态后，用户可删除旧的作业。 12345#一并删除作业创建的Podkubectl delete jobs/xxx#不删除作业创建的Podkubectl delete jobs/xxx -- 默认情况下，除非Pod失败，否则作业将不间断运行，此时作业将延迟到上述的.spec.backoffLimit。终止作业的另一种方法是设置活动截止日期，通过设置.spec.activateDeadlineSeconds字段来执行此操作。请注意，作业的.spec.activateDeadlineSeconds优先于.spec.backoffLimit。因此，重试一个或多个失败的Pod的作业在达到activeDeadlineSeconds指定的时间限制后将不会重置其它Pod，即使尚未达到backoffLimit也是如此。 作业模式Job Patterns 作业对象可用于支持Pod的可靠并行执行，它不是为了支持紧密通信的并行进程而设计。在复杂系统中，可能存在多组不同的工作项。这里只考虑一组工作项——批处理作业 并行计算有几种不同的模式，每种模式都有有点和缺点： 一个工作项一个作业对象 vs 所有工作项一个作业对象 创建的Pod数等于工作项数 vs 每个Pod可以处理多个工作项 多个方法使用一个工作队列 高级用法Advanced Usage 指定自己的Pod selector通常，创建作业对象时，不会指定.spec.selector。系统默认在创建作业时添加此字段。然而，在某些情况下，你可能需要设置它。这样做的时候要非常小心，如果你指定的label selector不是该作业的Pod所独有，并且与不想关的Pod匹配，则可能会删除不相关作业的Pod。如果选择了non-unique selector，则其它控制器及其Pod也可能以不可预测的方式进行。在指定.spec.selector时，k8s不会阻止你犯错误。 替代方案Alternatives Bare Pods Replication Controller Single Job starts Controller Pod Cron Jobs在指定的时间/日期创建作业。 CronJobCron Job基于时间调度创建作业。一个定时任务对象类似于crontab中的一行。它以给定的时间周期性运行作业。 注意： 所有定时作业调度， 时间以UTC表示。 定时作业局限Cron Job Limitations 定时作业在其计划的每个执行时间创建一个作业对象。如果startingDeadlineSeconds被设置为较大值或未设置(默认值)，并且concurrencyPolicy设置为Allow，则作业将始终至少运行一次。如果设置了startDeadlineSeconds字段，则控制器会计算从startingDeadlineSeconds的值到现在发生的错过的作业数，而不是从上一个计划时间到现在。如果定时作业未能在其预定时间创建，则将其视为未命中。 定时作业仅负责创建与其计划相匹配的作业，而作业则负责管理它所代表的Pod。 配置Configuration 配置最佳实践Configuration Best Practices 一般配置技巧General Configuration Tips 定义配置时，请指定最新的稳定的API版本 在推送到集群之前，配置文件应存储在版本控制系统中。这允许你在必要时快速回滚配置，有助于集群重建和恢复 使用YMAL而不是JSON来编写配置文件，YAML格式更用户友好 只要有意义，就将相关对象分组到一个文件中。管理一个文件比管理一堆文件更便捷 可以在目录上调用许多kubectl命令。例如，你可在配置文件目录上调用kubectl create 不要不必要地指定默认值 将对象描述写在注释中，以便更好进行内省 Naked Pod vs 副本集，部署和作业“Naked” Pods vs ReplicaSets, Deployments, and Jobs 不要使用Naked Pods(即未绑定到副本集或部署的Pod)如果节点发生故障，裸Pod将不会被重新调度。 服务Service 在相应的后端工作负载(部署或副本集)访问它之前创建服务当k8s启动容器时，它提供指向启动容器时正在运行的所有服务的环境变量。 除非绝对必要，否则不要为Pod指定hostPort将Pod绑定到hostPort时，它会限制Pod可调度的位置数。因为每个hostIP, hostPort, protocol的组合必须是独特的。如果没有指定hostIp和protocol，k8s将使用0.0.0.0作为默认的hostIP，使用TCP作为默认协议。 如果你只需要访问端口以进行调试，可使用apiserver proxy或kubectl port-forward。如果你需要公开节点上Pod的端口，考虑使用NodePort服务。 避免使用hostNetwork， 原因与hostPort类似 当不需要kube-proxy负载均衡时，使用 headless Services可轻松服务发现 使用标签Using Labels 为你的应用程序或部署定义和使用标签你可使用这些标签为其它资源筛选合适的Pod 容器镜像Container Images 默认的镜像拉取策略。对于容器是ifNotPresent，kubelet只有在本地镜像不存在时才拉取镜像。如果希望每次k8s启动容器时都拉取镜像，请指定imagePullPolicy: Always。一个已弃用的替代方案。设置k8s总是拉取镜像的:latest标记，它会隐式地将imagePullPolicy设置为Always。 注意： 在生产环境中部署容器时，你应该避免使用:latest标记，因为这使得正在运行的镜像版本难以回滚。如果镜像使用:latest标记，回滚的话其实需要回滚代码，然后打包上线，然后触发动态更新，之后就还原成了之前的版本。这样确实要复杂很缓慢一些。 确保容器使用使用相同版本的镜像 使用kubectl 使用kubectl apply -f &lt;directory&gt; 或 kubectl create -f &lt;directory&gt;它在此目录中所有.yaml, .yml, .json文件汇总寻找k8s配置配置文件，并将其传递给kubectl。 使用label selectors进行get和delete操作，而不是特定的对象名称 使用kubectl run和kubectl expose快速创建单容器部署和服务 管理容器的计算资源Managing Compute Resources for Containers 指定Pod时，可以选择指定每个容器需要多少CPU和MEM。当容器指定了请求(requests)的资源时，调度器可以更好地决定将Pod放在哪个节点上。当容器指定了限制(limit)时，可以以指定的方式处理节点上资源的争用。 资源类型Resource types CPU和MEM都是资源类型。资源类型具有基本单元(unix)。CPU以核(cores)为指定单位，MEM以字节(Byte)为指定单位。CPU和MEM统称为计算资源，或资源。计算资源是可以请求，分配和使用的可测量数据。它们与API资源不同。API资源(如Pod和Service)，是可通过k8s APIserver读取和修改的对象。 资源的请求和限制Resource requests and limits of Pod and Container Pod中的容器都可指定一个或多个限制： spec.containers[].resources.limits.cpu spec.containers[].resources.limits.memory spec.containers[].resources.requests.cpu spec.containers[].resources.requests.memory 虽然只能在单独的容器上指定请求和限制，但是讨论Pod资源的请求和限制很方便。特定资源类型的Pod资源 请求/限制 是Pod中每个容器的该类型的资源 请求/限制 的总和。 CPUMeaning of CPU CPU资源的限制和请求以CPU单位进行测量。在k8s中，1 cpu等于： 1 AWS vCPU 1 GCP Core 1 Azure vCore 1 IBM vCPU 1 Hyperthread on a bare-metal Intel processor with Hyperthreading 允许分数请求。如spec.containers[].resources.requests.cpu: 0.5。表达式0.1相当于表达式100m。具有小数点的请求资源(如0.1)由API转换为100m，不允许精度小于1m。始终要求CPU作为绝对数量，而不是相对数量。因此，0.1单元对于单核，双核，八核机器上的CPU资源时相同的。 MemoryMeaning of memory 内存的限制和请求以字节为单位。你可使用以下后缀来表示整数内存: E, P, T, G, M, K；你还还可以使用2的幂等: Ei, Pi, Ti, Gi, Mi, Ki。 12345#相同值的不同表达128974848129e6129M123Mi 栗子： 123456789101112131415161718192021222324252627apiVersion: v1kind: Podmetadata: name: frontendspec: containers: - name: db image: mysql env: - name: MYSQL_ROOT_PASSWORD value: &quot;password&quot; resources: requests: memory: &quot;64Mi&quot; cpu: &quot;250m&quot; limits: memory: &quot;128Mi&quot; cpu: &quot;500m&quot; - name: wp image: wordpress resources: requests: memory: &quot;64Mi&quot; cpu: &quot;250m&quot; limits: memory: &quot;128Mi&quot; cpu: &quot;500m&quot; 如何调度具有资源请求的PodHow Pods with resource requests are scheduled 创建Pod时，k8s调度器会选择要运行Pod的节点。每个节点都具有每种资源类型的最大容量，它可为Pod提供CPU和MEM。调度程序确保对于每种资源类型，调度的容器的资源请求总和小于节点的容量。请注意，即使节点上的实际内存或CPU资源使用率非常低，但如果容量检查失败，调度器扔拒绝在节点上放置Pod。当资源使用随后增加时，这可以防止节点上的资源短缺。 如何运行具有资源限制的PodHow Pods with resource limits are run 当kubelet启动Pod中的容器时，它会将CPU和MEM限制传递给容器运行环境。 当使用Docker时： spec.container[].resources.requests.cpu被转换成core value，分数的话会乘以1024。此数字中的较大值用作docker run命令中--cpu-shares标志的值 spec.container[].resources.limits.cpu被转换为millicore value并乘以100。结果值代表容器每100ms可以使用的CPU时间总量。在此间隔期间，容器不能使用超过其CPU时间的份额。默认配额时间是100ms，CPU配额的最小解析为1ms。 spec.containers[].resources.limits.memory被转换为整数，并用作docker run命令中--memory标志的值 如果容器超出其内存限制(mem limit)，则容器可能会终止。如果它可以重启，则kubelet将重启它；如果容器超出其内存请求(mem request)，当节点内存不足时，它的Pod可能会被驱逐；容器可能会/可能不会被允许在较长时间内超过其CPU限制。但是，它不会因CPU使用率过高而被杀死。 监控计算资源使用Monitoring compute resource usage Pod的资源使用情况将作为Pod Status的一部分进行上报。 本地短暂存储Local ephemeral storage FEATURE STATE: Kubernetes v1.11 beta k8s v1.8介绍了一种新资源，用于管理本地短暂存储的短暂存储(ephemeral-storage)。在每个k8s 节点上，kubelet的根目录(默认/var/lib/kubelet)和日志目录(/var/log)存储在节点的根分区上。Pod还通过emptyDir volume，容器日志，镜像层，容器可写层共享和使用此分区。此分区是短暂的，应用程序不能指望来自此分区的任何SLA(如磁盘IO)。本地临时存储仅适用于根分区，镜像层和可写层的可选分区超出了范围。 本地短暂存储的请求和限制设置Requests and limits setting for local ephemeral storage Pod中的容器可指定一个或多个短暂存储： spec.containers[].resources.limits.ephemeral-storage spec.containers[].resources.requests.ephemeral-storage 短暂存储的限制和请求以字节(Byte)为单位。你可以使用一下后缀表示整数存储: E, P, T, G, M, K；你也可以使用2的幂等: Ei, Pi, Ti, Gi, Mi, Ki。 1234128974848129e6129M123Mi 栗子： Pod由两个容器，每个容器都有2GiB的本地短暂存储请求，4GiB的本地短暂存储限制。因此，总共是4GiB请求，8GiB限制。 1234567891011121314151617181920212223apiVersion: v1kind: Podmetadata: name: frontendspec: containers: - name: db image: mysql env: - name: MYSQL_ROOT_PASSWORD value: &quot;password&quot; resources: requests: ephemeral-storage: &quot;2Gi&quot; limits: ephemeral-storage: &quot;4Gi&quot; - name: wp image: wordpress resources: requests: ephemeral-storage: &quot;2Gi&quot; limits: ephemeral-storage: &quot;4Gi&quot; 如何调度具有本地短暂存储的PodHow Pods with ephemeral-storage requests are scheduled 对于容器级的隔离，如果容器的可写层和日志使用量超过其存储限制，则Pod将被驱逐。对于Pod级别的隔离，如果所有容器的本地短暂存储使用量与Pod的emptyDir volume的总和超过了限制，则Pod将被驱逐。 扩展的资源Extended resources 扩展资源是kubernetes.io域之外的完全限定资源名称。它们允许集群操作者通告和用户使用非k8s内置资源。使用扩展资源需要两个步骤，首先，集群操作者必须通告扩展资源；其次，用户必须在Pod中请求扩展资源。 节点级扩展资源节点级扩展资源与节点相关联。 集群级扩展资源集群级扩展资源不依赖与节点。它们通常由调度器扩展程序管理——它处理资源消耗和资源配额。 使用扩展资源用户可以在pod spec中项CPU和MEM一样使用扩展资源。调度程序负责资源核算，以便不会同时为Pod分配可用的数量。API server将扩展资源的数量限制为整数。 要在Pod中使用扩展资源，在container spec中的spec.container[].resources.limits映射中包含资源名称作为键。只有满足所有请求资源时，才会调度Pod。只要无法满足资源请求，Pod就会保持在PENDING status。 1234567891011121314apiVersion: v1kind: Podmetadata: name: my-podspec: containers: - name: my-container image: myimage resources: requests: cpu: 2 example.com/foo: 1 limits: example.com/foo: 1 分配Pod到节点Assigning Pods to Nodes 你可以将Pod约束为只能在特定节点上运行，或更喜欢在特定节点上运行。有几种方法做到这一点，它们都使用label selector来进行选择。通常这种约束是不必要的，因为调度程序将自动进行合理的放置。但在某些情况下，你可能希望对Pod放置的节点进行更多控制。如确保Pod放置在安装有SSD的计算机上… 节点选择器nodeSelector 节点选择器是最简单的约束形式。nodeSelector是PodSpecs的一个字段，它指定了一个键值对的映射。要使Pod有资格在节点上运行，该节点必须将每个指示的的键值对作为标签。最常见的用法是一个键值对。 Prerequisitesk8s 集群 Attach label to the node 12345678910111213#获取节点名kubectl get nodeNAME STATUS ROLES AGE VERSIONmaster Ready master 33d v1.11.1node Ready &lt;none&gt; 33d v1.11.1salt01 Ready &lt;none&gt; 27d v1.11.1#打标签kubectl label nodes &lt;node-name&gt; &lt;label-key&gt;=&lt;label-value&gt;#查看标签kubectl get node --show-labels Add a nodeSelector field to your pod configuration 12345678910111213apiVersion: v1kind: Podmetadata: name: nginx labels: env: testspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent nodeSelector: &lt;label-key&gt;: &lt;label-value&gt; 当创建这个资源时，Pod将调度到附加此标签的节点上。 内置节点标签built-in node labels 除了你附加的标签之外，节点还有一些预先填充的标准标签。 kubernetes.io/hostname failure-domain.beta.kubernetes.io/zone failure-domain.beta.kubernetes.io/region beta.kubernetes.io/instance-type beta.kubernetes.io/os beta.kubernetes.io/arch 亲和力和反亲和力Affinity and anti-affinity 节点选择器提供了一种非常简单的方法，使用特定标签约束Pod到特定节点。目前处于测试阶段的亲和力/反亲和力功能，极大地扩展了你可以表达的约束类型。关键的改进有： 语言更具表达性 你可以指示规则是soft/preference而不是硬性要求，因此如果调度程序不能满足，也仍然会调度Pod 你可以约束运行在节点上的其它Pod的标签，而不是对节点本身的标签进行约束 亲和力有两种类型： node-affinity inter-pod affinity/anti-affinity 节点亲和力节点亲和力在概念上类似于nodeSelector，它允许你根据节点标签约束pod调度的节点。目前有两种类型的节点亲和力： requiredDuringSchedulingIgnoredDuringExecution preferredDuringSchedulingIgnoredDuringExecution 你可将它们分别是为hard和soft，前者指定了将Pod调度到节点上必须满足的规则，后者指定调度程序将尝试执行但不保证的首选项。名称的IgnoredDuringExecution部分意味着，与节点选择器的工作方式类似，如果节点标签在运行时更改，而不再满足Pod的亲和力规则，则Pod将继续在节点上运行。未来，我们计划提供requiredDuringSchedulingRequiredDuringExecution，就像Ignored一样，它将从不再满足Pod的亲和力要求的节点中驱逐Pod。 节点亲和力在spec.affinity.nodeAffinity字段中指定： 1234567891011121314151617181920212223242526apiVersion: v1kind: Podmetadata: name: with-node-affinityspec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/e2e-az-name operator: In values: - e2e-az1 - e2e-az2 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: another-node-label-key operator: In values: - another-node-label-value containers: - name: with-node-affinity image: k8s.gcr.io/pause:2.0 此节点亲和力规则表示，Pod只能防止在kubernetes.io/e2e-az-name标签键，值为e2e-az1或e2e-az2的节点上。此外，在满足条件的节点中，应优先选择具有another-node-label-key键，值为another-node-label-value的节点。节点亲和力语法支持如下操作符: In, NotIn, Exists, DoesNotExist, Gt, Lt。 如果你同时指定了nodeSelector和nodeAffinity，则必须满足两者以将Pod调度到候选节点上；如果你指定了与nodeAffinity类型关联的多个nodeSelectorTerms。那么，如果满足其中一个nodeSelectorTerms，则可以将Pod调度到节点上；如果你指定了与nodeSelectorTerms关联的多个matchExpressions。那么，只有满足所有matchExpressions的情况下，才能将Pod安排到节点上；如果删除或更改调度Pod的节点标签，则Pod不会被删除。换句话说，亲和力仅在调度Pod时起作用。 Pod间亲和力和反亲和力Pod间亲和力和反亲和力，你可以根据已在节点上运行的Pod上的标签(而不是节点标签)，来约束Pod可以调度的节点。与节点不同，Pod有命名空间，Pod标签的标签选择器必须指定选择器应该应用于哪些命名空间。 注意： Pod间亲和力和反亲和力需要大量的处理，可会显著减慢大型集群中的调度。因此，不建议在大于几百个节点的集群中使用；注意： Pod反亲和力要求节点一致地标签节点，即集群中的每个节点都必须具有匹配的topologyKey标签，如果某些节点缺少，可能会导致意外情况。 目前有两种类型的Pod亲和力和反亲和力: requiredDuringSchedulingIgnoredDuringExecution preferredDuringSchedulingIgnoredDuringExecution 同样表示hard和soft要求。 1234567891011121314151617181920212223242526272829apiVersion: v1kind: Podmetadata: name: with-pod-affinityspec: affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: security operator: In values: - S1 topologyKey: failure-domain.beta.kubernetes.io/zone podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: security operator: In values: - S2 topologyKey: kubernetes.io/hostname containers: - name: with-pod-affinity image: k8s.gcr.io/pause:2.0 Pod亲和力和反亲和力的有效操作符有: In, NotIn, Exists, DoesNotExist原则上，topologyKey可以是任一合法的label-key。但是，出于性能和安全的原因，它也有一些限制： 对于亲和力和requiredDuringSchedulingIgnoredDuringExecution的Pod的反亲和力，不允许使用空的topologykey 对于requiredDuringSchedulingIgnoredDuringExecution的Pod的反亲和力，引入控制器LimitPodHardAntiAffinityTopology是为了将topologyKey限制为kubernetes.io/hostname。如果要使其可用于自定义，可修改控制器，或禁用它 对于preferredDuringSchedulingIgnoredDuringExecution的Pod的反亲和力，空的topologyKey被解释为all topologies 除了上面提到的，topologyKey可以是任一合法的label-key 除了labelSelector和topologyKey之外，你还可以选择指定labelSelector应匹配的命名空间。如果为空或省略，则默认为Pod的亲和力/反亲和力的命名空间。 污点和容忍Taints and Tolerations 节点亲和力是Pod的属性，它将它们吸引到节点；Taints则相反——它允许节点排斥Pod。Taints 和 Tolerations 一起工作以确保Pod不被安排的不适当的节点上。将一个或多个污点(taints)应用于节点，这标志着节点不应该接受任何不能容忍污点的Pod。容忍(tolerations)应用于Pod，并允许Pod安排到具有匹配污点的节点上。 概念使用kubectl taint命令对节点添加污染: 123456#除非具有匹配的容忍，否则不会将Pod调度到此节点上kubectl taint nodes &lt;node-name&gt; key=value:NoSchedule#删除kubectl taint nodes &lt;node-name&gt; key:NoSchedule- 你可以在PodSpec的指定Pod的容忍度： 12345tolerations:- key: &quot;key&quot; operator: &quot;Equal&quot; #default value: &quot;value&quot; effect: &quot;NoSchedule&quot; 1234tolerations:- key: &quot;key&quot; operator: &quot;Exists&quot; effect: &quot;NoSchedule&quot; effect的三个选项： NoSchedule PreferNoSchedule: soft of NoSchedule NoExecute 你可在同一个节点上放置多个污点，并在同一个Pod上放置多个容忍。k8s处理多个污点和容忍的方式就像一个过滤器：从节点的所有污点开始，忽略Pod匹配的容忍度的那些，剩下的未被忽略的污点对Pod有明显的影响。尤其是： 如果至少有一个未被忽略的effect为NoSchedule的污点，则k8s将不会调度Pod到该节点 如果没有effect为NoSchedule，但至少有一个未被忽略的effect为PreferNoSchedule的污点，则k8s将尝试不将Pod调度到该节点 如果至少有一个未被忽略的effect为NoExecute的污点，则Pod将从节点驱逐(如果它已经在节点上运行)，并且不会被调度到该节点上 栗子： 123kubectl taint nodes node1 key1=value1:NoSchedulekubectl taint nodes node1 key1=value1:NoExecutekubectl taint nodes node1 key2=value2:NoSchedule 有两个容忍度的Pod： 123456789tolerations:- key: "key1" operator: "Equal" value: "value1" effect: "NoSchedule"- key: "key1" operator: "Equal" value: "value1" effect: "NoExecute" 对于NoExecute的容忍度可以指定一个可选tolerationSeconds字段，它指示在添加污点后Pod将保持绑定到节点的时间： 123456tolerations:- key: "key1" operator: "Equal" value: "value1" effect: "NoExecute" tolerationSeconds: 3600 使用案例Example Use Cases 污点和容忍是一种灵活的方式来引导Pod远离节点或驱逐不应该运行的Pod。一些栗子： 专用节点(Dedicated Nodes) 特殊硬件的节点(Nodes with Special Hardware) 基于污点的驱逐(Taint based Evictions) Taint based Evictions内置的污点： node.kubernetes.io/not-ready node.kubernetes.io/unreachable node.kubernetes.io/out-of-disk node.kubernetes.io/memory-pressure node.kubernetes.io/disk-pressure node.kubernetes.io/network-unavailable node.kubernetes.io/unschedulable node.cloudprovider.kubernetes.io/uninitialized 使用NoExecute容忍的DaemonSet Pod为以下污点创建，没有tolerationSeconds： node.alpha.kubernetes.io/unreachable node.kubernetes.io/not-ready 这可确保DaemonSet Pod永远不会因为这个问题而被驱逐，这与禁用此功能时的行为相匹配。 按条件污染节点Taint Nodes by Condition 节点控制器创建对应于节点条件的污点。当启用此功能，调度程序不检查节点条件，调度程序检查污点。这可确保节点条件不会影响节点上的调度。用户可以通过添加适当的Pod容忍来选择忽略节点的一些问题。 DaemonSet controller自动将一下NoSchedule的容忍度添加到所有的守护进程，以防止守护进程破坏： node.kubernetes.io/memory-pressure node.kubernetes.io/disk-pressure node.kubernetes.io/out-of-disk (only for critical pods) node.kubernetes.io/unschedulable (1.10 or later) node.kubernetes.io/network-unavailable (host network only) 添加这些容忍度可确保向后兼容，你还可以向DaemonSet添加任意容忍度。 SecretsSecrets类型的对象旨在保存敏感信息，如密码、OAuth token、ssh keys。把这些敏感信息放在Secrets中比将其放在Pod中或image中更安全、更灵活。 概述用户和系统都可以创建一些秘密(Secrets)。要使用秘密，Pod需要引用该秘密。秘密可以通过两种方式与Pod一起使用： 作为挂载到容器中的卷中的文件 为Pod拉取镜像时由kubelet使用的文件 内建的秘密Built-in Secrets Service Accounts Automatically Create and Attach Secrets with API Credentialsk8s会自动创建包含用于访问API的证书的秘密，并自动修改Pod以使用此类秘密。你可禁用它，但不推荐。 创建自己的秘密Creating your own Secrets 使用kubectl创建秘密(Creating a Secret Using kubectl create secret)假设一些Pod需要访问数据库： 12345678910111213141516171819202122232425$ echo -n &apos;admin&apos; &gt; ./username.txt$ echo -n &apos;1f2d1e2e67df&apos; &gt; ./password.txt#创建秘密$ kubectl create secret generic db-user-pass --from-file=./username.txt --from-file=./password.txtsecret/db-user-pass created#查看#默认都不会显示文件内容，为了安全kubectl get secretskubectl describe secrets/db-user-passName: db-user-passNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Type: OpaqueData====password.txt: 12 bytesusername.txt: 5 bytes 手动创建秘密(Creating a Secret Manually)每项必须是base64编码： 123456789101112131415161718192021$ echo -n &apos;admin&apos; | base64YWRtaW4=$ echo -n &apos;1f2d1e2e67df&apos; | base64MWYyZDFlMmU2N2Rm#现在编写一个秘密对象文件#db-user-pass.yamlapiVersion: v1kind: Secretmetadata: name: mysecrettype: Opaquedata: username: YWRtaW4= password: MWYyZDFlMmU2N2Rm#创建它$ kubectl create -f ./secret.yamlsecret &quot;mysecret&quot; created 解码秘密(Decoding a Secret) 12345678910111213141516171819kubectl get secret mysecret -o yamlapiVersion: v1data: username: YWRtaW4= password: MWYyZDFlMmU2N2Rmkind: Secretmetadata: creationTimestamp: 2016-01-22T18:41:56Z name: mysecret namespace: default resourceVersion: &quot;164619&quot; selfLink: /api/v1/namespaces/default/secrets/mysecret uid: cfee02d6-c137-11e5-8d73-42010af00002type: Opaque#解码$ echo &apos;MWYyZDFlMmU2N2Rm&apos; | base64 --decode1f2d1e2e67df 使用秘密Using Secrets秘密可以作为数据卷来挂载，也可作为环境变量公开，以供Pod中的容器使用。它们也可以由系统的其它部分使用，而不是直接暴露在Pod中。 将秘密用作Pod中的文件(Using Secrets as Files from a Pod)在Pod中的卷中使用秘密： 创建或使用已有的秘密。多个Pod可以引用相同的秘密 修改Pod定义以添加卷和挂载卷 修改镜像或命令行，以便程序在该挂载目录中查找文件 栗子： 12345678910111213141516apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: mypod image: redis volumeMounts: - name: foo mountPath: "/etc/foo" readOnly: true volumes: - name: foo secret: secretName: mysecret 向指定路径投射密钥(Projection of secret keys to specific paths)栗子： 123456789101112131415161718192021apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: mypod image: redis volumeMounts: - name: foo mountPath: "/etc/foo" readOnly: true volumes: - name: foo secret: secretName: mysecret items: - key: username path: my-group/my-username#username秘密存储在/etc/foo/my-group/my-username而不是/etc/foo/username#password秘密没有投射 **秘密文件权限(Secret files permissions)你还可以指定秘密所具有的的权限: 12345678910111213141516apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: mypod image: redis volumeMounts: - name: foo mountPath: "/etc/foo" volumes: - name: foo secret: secretName: mysecret defaultMode: 256 #0400(八进制) 12345678910111213141516171819apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: mypod image: redis volumeMounts: - name: foo mountPath: "/etc/foo" volumes: - name: foo secret: secretName: mysecret items: - key: username path: my-group/my-username mode: 511 #0777 从卷中使用秘密值(Consuming Secret Values from Volumes)在挂载秘密卷的容器内，密钥显示为文件，秘密值基于base64进行解码并存储在这些文件中。 1234567$ ls /etc/foo/usernamepassword$ cat /etc/foo/usernameadmin$ cat /etc/foo/password1f2d1e2e67df 挂载的秘密会自动更新(Mounted Secrets are updated automatically) 当更新卷中已经使用的秘密时，最终也会更新投射的密钥。 使用秘密作为环境变量(Using Secrets as Environment Variables)要在Pod中的环境变量中使用秘密： 创建或使用已有的秘密。多个Pod可引用同一个秘密 修改Pod定义 修改Image或命令行，以便程序在指定的环境变量中查找值 栗子： 1234567891011121314151617181920apiVersion: v1kind: Podmetadata: name: secret-env-podspec: containers: - name: mycontainer image: redis env: - name: SECRET_USERNAME valueFrom: secretKeyRef: name: mysecret key: username - name: SECRET_PASSWORD valueFrom: secretKeyRef: name: mysecret key: password restartPolicy: Never 从环境变量中使用秘密值Consuming Secret Values from Environment Variables 容器内使用的环境变量的秘密值，它显示为base64的解码值。 1234$ echo $SECRET_USERNAMEadmin$ echo $SECRET_PASSWORD1f2d1e2e67df Using imagePullSecretsimagePullSecret是一种包含docker image registry password的秘密传递给kubelet的方法，因此它可以用于Pod拉取你的私有镜像。 细节 限制Restrictions 验证密钥卷源以确保指定的对象引用实际指向的秘密类型对象。因此，需要在任何Pod依赖它之前先创建秘密。Secret API对象驻留在命名空间中，它们只能由同一命名空间中的Pod引用。单个秘密的大小被限制为1MB。这是为了阻止创建非常大的秘密，这会耗尽apiserver和kubelet的内存。然而，创建许多小的秘密也可能耗尽内存。更多关于限制秘密对内存的使用是未来的计划功能。kubelet仅支持使用从apiserver获取的Pod秘密。这包含由kubectl创建的秘密，不包含通过--manifest-url标志或REST API创建的秘密。 Secret和Pod的终生交互Secret and Pod Lifetime interaction 通过API创建Pod时，不会检查引用的秘密是否存在。一旦调度了Pod，kubelet将尝试获取秘密值。如果由于该秘密不存在或暂时缺少与apiserver的连接而无法获取该秘密，则kubelet将定期重试。它将报告有关Pod的事件，说明它尚未启动的原因。一旦获取到秘密，kubelet将创建并挂载包含它的卷，在挂载所有Pod的卷之前，Pod的容器都不会启动。 使用案例 Pod with ssh keys 1234567891011121314151617181920212223#创建包含ssh keys的秘密kubectl create secret generic ssh-key-secret --from-file=ssh-privatekey=/path/to/.ssh/id_rsa --from-file=ssh-publickey=/path/to/.ssh/id_rsa.pub#创建引用此秘密的Podkind: PodapiVersion: v1metadata: name: secret-test-pod labels: name: secret-testspec: volumes: - name: secret-volume secret: secretName: ssh-key-secret containers: - name: ssh-test-container image: mySshImage volumeMounts: - name: secret-volume readOnly: true mountPath: &quot;/etc/secret-volume&quot; Pods with prod / test credentials 12345678910111213141516171819202122232425262728293031323334353637383940414243444546$ kubectl create secret generic prod-db-secret --from-literal=username=produser --from-literal=password=Y4nys7f11secret &quot;prod-db-secret&quot; created$ kubectl create secret generic test-db-secret --from-literal=username=testuser --from-literal=password=iluvtestssecret &quot;test-db-secret&quot; created#Pod中引用apiVersion: v1kind: Listitems:- kind: Pod apiVersion: v1 metadata: name: prod-db-client-pod labels: name: prod-db-client spec: volumes: - name: secret-volume secret: secretName: prod-db-secret containers: - name: db-client-container image: myClientImage volumeMounts: - name: secret-volume readOnly: true mountPath: &quot;/etc/secret-volume&quot;- kind: Pod apiVersion: v1 metadata: name: test-db-client-pod labels: name: test-db-client spec: volumes: - name: secret-volume secret: secretName: test-db-secret containers: - name: db-client-container image: myClientImage volumeMounts: - name: secret-volume readOnly: true mountPath: &quot;/etc/secret-volume&quot; Dotfiles in secret volume隐藏文件 123456789101112131415161718192021222324252627kind: SecretapiVersion: v1metadata: name: dotfile-secretdata: .secret-file: dmFsdWUtMg0KDQo=---kind: PodapiVersion: v1metadata: name: secret-dotfiles-podspec: volumes: - name: secret-volume secret: secretName: dotfile-secret containers: - name: dotfile-test-container image: k8s.gcr.io/busybox command: - ls - &quot;-l&quot; - &quot;/etc/secret-volume&quot; volumeMounts: - name: secret-volume readOnly: true mountPath: &quot;/etc/secret-volume&quot; Secret visible to one container in a pod考虑一个需要处理HTTP请求，执行一些复杂业务逻辑，然后使用HMAC签署一些消息的程序。由于它具有复杂的逻辑，因此可能存在未被注意的文件读取漏洞，这可能会将私钥暴露给攻击者。 这可以分为两个容器中的两个进程： 前端容器处理用户交互和业务逻辑，但无法看到私钥 后端容器可查看签名的私钥，并相应来自前端的签名请求 最佳做法Clients that use the secrets API 在部署与Secret API交互的应用程序时，应使用RBAC等授权策略限制访问。 安全属性保护由于可以独立于P使用秘密的Pod来创建秘密，因此在创建、查看、编辑Pod的工作流程中泄露秘密的风险较小。系统还可以对秘密对象采取额外的预防措施，如尽可能避免将其写入磁盘。如果节点上的Pod需要秘密，则仅将秘密发送到节点。它不会写入磁盘，而是存储在tmpfs中(RAM)。一旦删除依赖它的Pod，它就会被删除。节点上的秘密数据存储在tmpfs volume中，因此不会停留在节点上。在大多数k8s项目维护的发行版中，用于与apiserver之间的通信，以及apiserver到kubelet的通信受到SSL/TLS保护。同一节点上可能存在多个Pod的秘密，但是，只有Pod请求的密码可能在其容器中可见。因此，一个Pod无法访问另一个Pod的秘密。同一个Pod中可能有几个容器，但是，Pod中的每个容器都必须在其volumeMounts中请求秘密卷，以使其在容器中可见。 风险 apiserver中，秘密数据以明文形式存储在etcd中。因此： 管理员应该限制用户对etcd的访问权限 apiserver中的秘密数据在etcd使用的磁盘上处于静止状态；管理员可能想要在不再使用时擦除etcd使用的磁盘 如果通过json/yaml文件配置秘密，该文件的秘密数据的编码为base64，则该秘密可能被泄露。base64编码不是加密方法，被认为与纯文本相同 应用程序仍然需要在从卷读取秘密值后保护它 可创建使用秘密的Pod的用户也可看到秘密的值 如果运行了etcd的多个副本，则它们之间将共享秘密 目前，任何在节点上具有root权限的用户都可以模拟kubelet从apiserver中读取任何秘密 使用kubeconfig文件组织集群访问Organizing Cluster Access Using kubeconfig Files 使用kubeconfig文件来组织有关集群、用户、命名空间、身份验证机制的信息。kubectl使用kubeconfig文件来查找选择集群并与集群apiserver通信所需的信息。用于配置对集群的访问的文件称为kubeconfig。这是引用配置文件的普通方法，这并不意味着有一个名为kubeconfig的文件。 默认情况下，kubectl从$HOME/.kube目录下查找名为config的文件。你可以通过--kubeconfig标志设置KUBECONFIG环境变量来指定kubeconfig文件。 支持多集群、用户、认证机制Supporting multiple clusters, users, and authentication mechanisms 假设你有多个集群，并且用户和组件以各种方式进行认证： 正在运行的kubelet可能使用证书进行认证 用户可能使用令牌认证 管理员可能拥有他为用户提供的证书集 使用kubeconfig，你可以组织集群、用户和命名空间。你还可以定义上下文，以便在集群和命名空间之间快速进行切换。 上下文kubeconfig文件中的上下文元素用于在方便的名称下对访问参数进行分组。每个上下文都有三个参数：集群、命名空间、用户。默认情况下，kubectl使用从当前上下文的参数与集群通信。 12#Modify kubeconfig fileskubectl config -h KUBECONFIG环境变量$KUBECONFIG环境变量包含kubeconfig文件列表，它不是必须的。如果不存在，则kubectl使用默认的$HOME/.kube/config；如果存在，则kubectl使用有效配置。在Linux/Mac上使用冒号分隔，Windows使用分号分隔。 12echo $KUBECONFIG/etc/kubernetes/admin.conf 合并kubeconfig文件Merging kubeconfig files 12#查看配置kubectl config view 如果设置了--kubeconfig标志，则仅使用指定的文件。不合并，只允许此标志的一个实例。 否则，如果设置了$KUBECONFIG环境变量，将其应用于合并的文件列表。遵循以下规则： 忽略空文件名 对包含无法反序列化内容的文件生成错误 设置成特定值或映射见的第一个文件获胜 切勿修改值或映射键 否则，使用默认的$HOME/.kube/config文件，不做合并 Pod优先级和抢占Pod Priority and Preemption FEATURE STATE: Kubernetes 1.8 alphaFEATURE STATE: Kubernetes 1.11 beta Pod也有优先级，优先级表示Pod相对于其它Pod的重要性。如果无法调度Pod，则调度程序会尝试抢占(驱逐)较低优先级的Pod，以便可以处理待调度(Pending)的Pod。优先级还会影响Pod的调度顺序和节点上的资源驱逐顺序。 使用优先级和抢占How to use priority and preemption 要在k8s v1.11+使用优先级和抢占，遵循以下步骤： 添加一个或多个优先级类(PriorityClassed) 创建带有priorityClassName的Pod设置为添加的优先级类之一。当然，你不需要直接创建Pod，通常你只需要将priorityClassName添加到对象的Pod模板(如deployment) 禁用抢占How to disable preemption 禁用Pod优先级和抢占要禁用Pod优先级，请为apiserver、调度程序、kubelet将该功能设置false——--feature-gates=PodPriority=false 仅禁用抢占在k8s v1.11+，抢占由kube-scheduler的disablePreemption标志控制，默认设置为fasle。 12345678apiVersion: componentconfig/v1alpha1kind: KubeSchedulerConfigurationalgorithmSource: provider: DefaultProvider...disablePreemption: true PriorityClass优先级类(priorityClass)是一个非命名空间的对象，它定义从优先级类名到优先级的整数值的映射。该名称在PriorityClass对象的metadata的name字段中指定，必须的值在value字段中定义。值越高，优先级越高。优先级类对象可以具有小于等于10亿的任何32位整数值。较大的数字保留给通常不会被抢占或驱逐的系统Pod。集群管理员应为他们想要的每个这样的映射创建一个优先级类对象。优先级类有两个可选字段： globalDefault： 表示该优先级类的值应该用于没有priorityClassName的Pod，系统中只能有一个globalDefault为true的Pod。如果没有设置为globalDefault的优先级类，则Pod的优先级为零。 description： 旨在告诉用户何时应该使用此优先级类 有关PodPriority和现有集群的说明： 如果升级现有集群并启用此功能，则现有的Pod的优先级实际上为零 将globalDefault设置为true的优先级类添加将不会更改现有Pod的优先级。它的值仅用于添加优先级类之后创建的Pod 如果删除优先级类，则使用已删除的优先级类名称的现有Pod保持不变，但无法创建使用已删除的优先级类名称的Pod 栗子： 1234567apiVersion: scheduling.k8s.io/v1beta1kind: PriorityClassmetadata: name: high-priorityvalue: 1000000globalDefault: falsedescription: &quot;This priority class should be used for XYZ service pods only.&quot; Pod priority当有一个或多个优先级类之后，你就可以创建在spec中指定priority class name的Pod。优先级许可控制器使用priorityClassName字段并填充优先级的整数值。如果为找到优先级，则决绝Pod。 栗子： 123456789101112apiVersion: v1kind: Podmetadata: name: nginx labels: env: testspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent priorityClassName: high-priority Pod优先级对调度顺序的影响启用Pod优先级后，调度程序按其优先级对挂起的Pod进行排序，并将挂起的Pod置于调度队列中优先级较低的其它挂起Pod之前。因此，如果满足调度要求，则优先级较低的Pod可以更快地安排具有较低优先级的Pod。如果无法调度此类Pod，则调度程序将继续并尝试安排其它较低优先级的Pod。 Preemption创建Pod时，它们会进入队列并等待调度。调度程序从队列中选择一个Pod并尝试在节点上调度它。如果未找到满足Pod的所有指定要求的节点，则会为挂起的Pod触发抢占逻辑。抢占逻辑试图找到一个节点，其中删除优先级低于Pod P的一个或多个Pod，使得能够在该节点上调度Pod P。如果找到了此节点，则会删除那些Pod，在他们消失后，可在节点上调度Pod P。 用户公开的信息User exposed information 当Pod P在节点上抢占一个或多个Pod时，Pod P的状态的nominatedNodeName字段被设置为节点的名称。该字段帮助调度器追踪为Pod P保留的资源，并且还向用户提供关于其集群中的抢占信息。请注意，Pod P不一定安排到nominated node。在受害Pod被抢占后，它们将获得优雅的终止期。如果在调度程序等待受害Pod终止时另一个节点可用，则调度程序将使用另一个节点来调度Pod P。因此，Pod spec中的nominatedNodeName和nodeName并不总是相同。此外，如果调度程序在节点上抢占Pod，然后有比Pod P更高优先级的Pod到达，则调度程序可以将节点提供给新的更高优先级的Pod。 抢占的局限性Limitations of preemption Graceful termination of preemption victims PodDisruptionBudget is supported, but not guaranteed! Inter-Pod affinity on lower-priority Pods Cross node preemption 调试Pod优先级和抢占优先级和抢占可能会引起潜在的问题： Pods are preempted unnecessarily Pods are preempted, but the preemptor is not scheduled Higher priority Pods are preempted before lower priority pods Pod优先级和QoS的交互Interactions of Pod priority and QoS 调度程序的抢占逻辑在选择抢占目标是会考虑QoS。考虑QoS和Pod优先级的唯一组件kubelet out of resource驱逐。kubelet首先根据他们对饥饿资源的使用是否超过请求，然后按优先级，通过相对于Pod的调度请求消耗的计算资源来排除Pod的驱逐。kubelet资源溢出驱逐不会驱逐资源使用不超过其请求的Pod。如果 优先级较低的未超过其请求，则不会被驱逐。另一个优先级高高于其请求的Pod可能被驱逐。 服务，负载均衡和网络Services, Load Balancing, and Networking Servicesk8s Pod是会死的，从出生到死亡，它们没有复活(resurrected)。副本集特别地动态创建和销毁Pod。虽然每个Pod都有自己的IP，但即使是那些IP也不能依赖它们随时间变得稳定。这导致一个问题，如果某些Pod为k8s集群内的其它Pod提供功能，那么它们如何找出并追踪它们呢？这就需要用到服务了。 k8s 服务是一个抽象，它定义了一组逻辑Pod和一个访问它们的策略，有时称为微服务(micro-service)。服务目标的Pod由Label Selector来确定。 对于原生k8s应用程序，k8s提供了提供了一个简单的Endpoints API，只要服务中的Pod集发生变化，它就会更新。对于非原生k8s应用程序，k8s提供了一个基于虚拟IP的服务桥接器，可以重定向到后端的Pod。 定义服务Defining a service k8s中的服务是一个REST对象，类似于Pod。与所有REST对象一样，可以将服务定义POST到apiserver以创建实例。 例如： 1234567891011kind: ServiceapiVersion: v1metadata: name: my-servicespec: selector: app: MyApp ports: - protocol: TCP port: 80 targetPort: 9376 此规范会创建一个名为my-service的服务对象，该对象使用app=MyApp的标签定位任何Pod上的TCP协议9376端口。服务还将分配一个IP地址(称为cluster IP)，由服务代理(service proxy)使用。将连续评估服务的selector，并将结果POST到名为my-service的Endpoints对象。请注意，服务可以将传入端口映射到任何targetPort。默认情况下，targetPort将设置为与port字段相同的值。也许更有趣的是targetPort可以是一个字符串，指的是后端Pod中端口的名称。分配给该名称的实际端口号在每个后端Pod中可以不同。这为部署和发展你的服务提供了很大的灵活性。例如，你可以更改Pod的后端软件中公开的端口号，而不会破坏客户端。k8s 服务支持TCP和UDP协议，默认是TCP。 Services without selectors服务通常抽象访问k8s Pods，但它们也可以抽象访问其它类型的后端。例如： 你希望在生产环境中拥有外部数据库集群，但在测试环境中你使用自己的数据库 你希望将服务指向另外的命名空间或集群 你正在将工作负载迁移到k8s，并且你的一些后端运行在k8s之外 在任何方案中，你都可以定义不带选择器(selector)的服务： 123456789kind: ServiceapiVersion: v1metadata: name: my-servicespec: ports: - protocol: TCP port: 80 targetPort: 9376 由于此服务没有选择器(selector)，因此不会创建相应的Endpoints对象。你可以手动将服务映射到你自己的特定端点： 123456789kind: EndpointsapiVersion: v1metadata: name: my-servicesubsets: - addresses: - ip: 1.2.3.4 ports: - port: 9376 在没有选择器的情况下访问服务的工作方式与使用选择器的方式相同。流量都会被路由到定义的端点。 ExternalName service是一种特殊的服务案例，它没有选择器并且使用DNS名称代替。 虚拟IP和服务代理Virtual IPs and service proxies 在k8s v1.0中，服务是四层构造(tcp/udp)，代理纯粹实在用户空间中。在k8s v1.1中，添加了Ingress API来表示七层服务(HTTP)，也添加了iptables proxy。并成为k8s v1.2的默认操作模式。在k8s v1.8.0中，添加了ipvs proxy。 k8s 集群中的每个节点都运行一个kube-proxy——它负责为ExternalName以外类型的服务实现一种形式的虚拟IP。在任何这些代理模式中，绑定到服务的ip:port的任何流量都将代理到适当的后端，而客户端不知道有关k8s或服务或Pod的任何信息。 Proxy-mode: userspace 在userspace模式下，kube-proxy会监视k8s master以添加和删除Service和Endpoints对象。对于每个服务，它在本地节点上打开一个端口(随机选择)。与此proxy port的任何连接都将代理到服务后端的Pod之一，并根据服务的SessionAffinity决定使用哪个后端Pod。最后，它将安装iptables规则，捕获流量到服务的cluster IP(虚拟IP)，并将流量重定向到代理后端Pod的代理端口。默认情况下，后端的选择是轮询(round robin)。 Proxy-mode: iptables 在iptables模式下，kube-proxy会监视k8s master以添加和删除Service和Endpoint对象。对于每个服务，它将安装iptables规则，捕获流量到服务的cluster IP和端口，并将流量重定向到服务的后端集之一。对于每个Endpoint对象，它会按照选择后端Pod的iptables规则。默认情况下，后端的选择是随机的。显然，iptables不需要再用户空间(userspace)和内核空间(kernelspace)之间切换，它应该比用户空间代理更快更可靠。然而，与用户空间代理不同，如果最初选择的Pod没有响应，则iptables代理无法自动重试另一个Pod，因此它依赖于readiness probes的工作。 Proxy-mode： ipvs FEATURE STATE: Kubernetes v1.9 beta 在ipvs模式下，kube-proxy监视k8s的Service和Endpoints，调用netlink接口以相应地创建ipvs规则，并定期与k8s的Service和Endpoint同步ipvs规则，以确保ipvs转台与期望一致。访问服务时，流量将被重定向到其中一个后端Pod。与iptables类似，ipvs基于netfilter hook函数，但是用hash table作为底层数据结构，并在内核空间中工作。这意味着ipvs可以更快地重定向流量，并且再同步代理规则时具有更好的性能。此外，ipvs为负载均衡算法提供了更多选项： rr： round-robin lc： least connection dh： destination hashing sh： source hashing sed： shortest expected delay nq： never queue 注意：ipvs模式假设在运行kube-proxy之前便已在节点上安装了IPVS内核模块。当kube-proxy以ipvs代理模式启动时，kube-proxy将验证节点上是否安装了IPVS模块，如果未安装，则kube-proxy将回退到iptables代理模式。 多端口服务Multi-Port Services 许多服务可能需要公开多个端口。对于此情况，k8s支持服务对象上的多个端口定义。当使用多个端口时，必须提供所有端口名称，以便消除端点(Endpoint)的歧义。请注意，端口名称只能包含小写字母数字和横杠-，并须以字母数字结尾。 12345678910111213141516kind: ServiceapiVersion: v1metadata: name: my-servicespec: selector: app: MyApp ports: - name: http protocol: TCP port: 80 targetPort: 9376 - name: https protocol: TCP port: 443 targetPort: 9377 选择自己的IPChoosing your own IP address 你可以将自己的cluster ip指定为服务创建请求的一部分。为此，请设置.spec.clusterIP字段。用户选择的IP地址必须是有效的IP地址，并且在apiserver的标志指定的service-cluster-ip-range CIDR范围内。如果IP地址无效，则apiserver返回422 HTTP statuscode以指示该值无效。 为什么不适用DNS轮询？Why not use round-robin DNS? 为什么我们使用虚拟IP来完成所有这些工作，而不仅仅是标准的DNS轮询。原因如下： DNS libraries的历史悠久，不尊重DNS TTL并缓存名称的查找结果 许多应用程序执行一次DNS查找并缓存结果 即使应用程序和库进行了适当的重新解析，每个客户算反复重新解析DNS的负载也是难以管理的 我们试图阻止用户做出伤害自己的事情。也就是说，如果有足够的人要求这样做，我们可以将其作为替代方案来实施。 服务发现Discovering services k8s支持两种寻找服务的主要模式： enviroment variables和DNS。 Environment variables当Pod在节点上运行时，kubelet为每个活跃的服务添加一组环境变量。它支持Docker links compatible变量和更简单的{SVCNAME}_SERVICE_HOST和{SVCNAME}_SERVICE_PORT变量。 栗子，如redis-master服务公开TCP6379端口，并分配了10.0.0.11的cluster ip以生成如下环境变量： 1234567REDIS_MASTER_SERVICE_HOST=10.0.0.11REDIS_MASTER_SERVICE_PORT=6379REDIS_MASTER_PORT=tcp://10.0.0.11:6379REDIS_MASTER_PORT_6379_TCP=tcp://10.0.0.11:6379REDIS_MASTER_PORT_6379_TCP_PROTO=tcpREDIS_MASTER_PORT_6379_TCP_PORT=6379REDIS_MASTER_PORT_6379_TCP_ADDR=10.0.0.11 这有一个要求——必须在Pod本身之前创建它想要访问的任何服务，否则将不会填充环境变量。DNS没有此限制。 DNS可选的集群加载项是DNS server(强烈推荐)。DNS server监视k8s API以获取新服务，并为每个服务创建一组DNS 记录。如果已在集群中启用DNS，则所有Pod应该能够自动对服务进行名称解析。 例如，如果你在k8s命名空间my-ns中创建一个服务my-service，则会创建my-service.my-ns的DNS记录。存在于my-ns命名空间中的Pod应该能够通过简单地对my-service服务进行名称查找来找到它。存在于其它命名空间的Pod必须将名称限定为my-service.my-ns。这些名称查找的结果是cluster ip。k8s还支持命名端口的DNS SRV(service)记录。如果my-service.my-ns服务具有带有TCP协议的名为http的端口，则可以对_http._tcp.my-service.my-ns执行DNS SRV查询以发现http的端口号。k8s DNS server是访问ExternalName类型的服务的唯一方法。 Headless services有时你不需要或不想要负载均衡和单个服务IP。在这种情况下，你可以通过将clusterIP(.spec.clusterIP)指定为None来创建一个headless服务。此选项允许开发人员通过允许他们自由地以自己的方式进行发现来减少与k8s系统的耦合。应用程序仍然可以使用自注册(self-registration)模式，并且可以轻松地在API上构建适用于其它发现系统的适配器。 对于此类服务，并未分配clusterIP，kube-proxy也不处理这些服务，并且平台没有为它们执行负载均衡和代理。如何自动配置DNS取决于服务是否已定义选择器(selector)： With selectors对于定义了选择器的headless服务，端点控制器(endpoints controller)在API中创建端点记录(Endpoint records)，并修改DNS配置以返回直接指向支持服务的Pod的A记录(地址)。 Without selectors对于没有定义选择器的headless服务，端点控制器不会创建端点记录。但是，DNS系统会查找并配置下面任一项； ExternalName类型的服务的CNAME记录 所有其它类型的，与服务共享名称的任何端点记录 发布服务和服务类型Publishing services - service types 对于应用程序的某些部分(如前端)，你可能希望将服务公开到外部IP地址(集群外)。k8s ServiceTypes允许你指定所需的服务类型，默认为ClusterIP。 类型如下： ClusterIp在集群内部IP上公开服务，选择此值使服务只能从集群内访问。这是默认的服务类型。 NodePort在每个节点IP的静态端口上公开服务。将自动创建cluster ip服务(NodePort服务将路由到此服务)。你可以在集群外部通过请求&lt;NodeIP&gt;:&lt;NodePort&gt;来联系NodePort服务 LoadBalancer使用云提供商的负载均衡器在外部公开服务。将自动创建外部负载均衡器路由到NodePort服务和ClusterIP服务。 ExternalName通过返回CNAME记录的值，将服务映射到externalName字段的内容。没有设置任何类型的代理。这需要kube-dns v1.7+。 NodePortNodePort类型下，k8s master将从--service-node-port-range标志指定的范围(默认 30000-32767)分配端口，(当然，你也可以在此范围了自定义)，并且每个节点将代理进入服务的端口(每个节点上的端口号相同)。服务中的.spec.ports[].nodePort字段。 如果要制定代理端口的特定IP，可将kube-proxy中的--nodeport-addresses标志 设置为特定IP块(从k8s v1.10+支持)。使用逗号,分隔IP块列表(如10.0.0.0/8,1.2.3.4/31)用于过滤此节点的本地地址。例如，如果你使用--nodeport-address=127.0.0.0/8标志启动kube-proxy，则kube-proxy将仅为NodePort服务选择环回地址接口(loopback)。--nodeport-address默认为空，这意味着选择所有可用的接口并符合当前的NodePort行为。 如果你需要特定的端口号，可以在nodePort字段中指定一个值，系统将为你分配该端口。请注意，指定的端口值必须在默认范围内，且没有端口冲突。 请注意，服务将同时显示&lt;NodeIP&gt;:spec.ports[*].nodePort和.spec.clusterIP:spec.ports[*].port。 LoadBalancer在支持外部负载均衡器的云提供商上，将type字段设置为LoadBalancer将为服务配置负载均衡器。负载均衡器的实际创建是异步(asynchronously)发生的，有关已配置的均衡器的信息将发布在服务的.status.loadBalancer字段。 栗子： 123456789101112131415161718kind: ServiceapiVersion: v1metadata: name: my-servicespec: selector: app: MyApp ports: - protocol: TCP port: 80 targetPort: 9376 clusterIP: 10.0.171.239 loadBalancerIP: 78.11.24.19 type: LoadBalancerstatus: loadBalancer: ingress: - ip: 146.148.47.155 来自外部负载均衡器的流量将指向后端Pod，但具体如何工作取决于云提供商。某些云提供商允许指定loaBalancerIP。在这些情况下，将使用用户指定的loadBalancerIP创建负载均衡器。如果未指定loadBalancerIP字段，则将为负载均衡器分配临时IP。如果指定了loadBalancerIP字段，但云提供商不支持该功能，则该字段被忽略。 一些云提供商： AWS Azure GCP Aliyun TencentCloud ExternalName NOTE: ExternalName Services are available only with kube-dns version 1.7 and later. ExternalName类型的服务将服务映射到DNS名称(使用spec.externalName)，而不是映射到传统的选择器(如my-service)。 栗子： 12345678kind: ServiceapiVersion: v1metadata: name: my-service namespace: prodspec: type: ExternalName externalName: my.database.example.com 查找主机my-service.prod.svc.CLUSTER时，集群DNS服务将返回my.database.example.com的CNAME记录。访问my-service服务的工作方式与其它服务的工作方式相同，但重要的区别在于重定向发生在DNS级别，而不是通过代理或转发。 External IPs如果有外部IP路由到一个或多个集群节点，则可以在这些externalIPs上公开k8s 服务。在服务端口上使用外部IP，进入集群的流量将路由到其中一个服务端点。外部IP不由k8s管理，它是集群管理员的责任。 栗子； 1234567891011121314kind: ServiceapiVersion: v1metadata: name: my-servicespec: selector: app: MyApp ports: - name: http protocol: TCP port: 80 targetPort: 9376 externalIPs: - 80.11.12.10 不足Shortcomings 使用虚拟IP(VIP)的用户空间(userspace)将在中小规模(small to medium scale)上工作，但不会扩展到具有成千上万个服务的大集群中。 使用用户空间代理会模糊访问服务的数据包的源IP，这使得某些类型的防火墙变得不可能。iptabels代理不会掩盖集群内源IP，但它仍然会影响通过负载均衡器或节点端口的客户端。 Type字段设置为嵌套功能——每个级别都添加到前一个级别。并非所有云服务商都严格要求这样做，但目前的API需要它。 VIP细节The gory details of virtual IPs 避免冲突(Avoiding collisions)k8s的主要哲学之一是用户不应该暴露可能导致他们的行为失败的情况，而不是他们自己的过错。在这种情况下，我们查看网络端口——用户不应该选择可能与另一个用户发生冲突的网络端口。这叫隔离失败。为了允许用户为服务选择端口号，我们必须确保没有服务间的冲突。我们通过为每个服务分配IP地址来做到这一点。 为了确保每个服务都接收到一个唯一的IP，内部分配器会在创建每个服务之前以原子方式更新etcd中的全局分配映射。映射对象必须存在于映射表中以获取IP，否则创建将失败并显示一条消息，指示无法分配IP。后台控制器负责创建该映射以及由于管理员的干预而检查无效的分配，并清除已分配但当前没有服务使用的任何IP。 IPs和VIPs与实际路由到目的地的Pod IP不同，Service IP实际上并未由单个主机应答。相反，我们使用iptables来定义根据需要透明重定向的虚拟IP。当客户端连接到VIP时，其流量会自动传输到适当的端点。服务的环境变量和DNS实际上是根据服务的VIP和端口填充的。支持三种代理模式： userspace、iptables、ipvs，它们的操作略有不同。 API对象服务在k8s REST API中是顶级资源。 DNSDNS for Services and Pods 介绍k8s DNS在集群上调度DNS Pod和Service，并配置kubelet以告知各个容器使用DNS Service’s IP 来解析DNS名称。集群中定义的每个服务(包括DNS服务自身)，都会分配一个DNS名称。默认情况下，客户端Pod的DNS搜索列表将包含Pod自己的命名空间和集群的默认域。 栗子：假设在k8s的bar命名空间中有一个foo服务，运行在bar命名空间中的Pod可通过简单地为foo执行DNS查询来查找此服务。运行在quux命名空间中的Pod可通过foo.bar执行DNS查询来查找此服务。 ServicesA records正常的服务(非headless)都分配了一个名为my-svc.my-namespace.svc.cluster.local形式的DNS A记录，这将解析为服务的cluster ip。Headless服务同样分配了一个名为my-svc.my-namespace.svc.cluster.local形式的DNS A记录。与服务不同，这将解析为服务选择的Pod的IP。 SRV records为命名端口创建SRV记录，这些端口是普通服务或headless服务的一部分。对于每个命名端口，SRV记录的格式为_my-port-name._my-port-protocol.my-svc.my-namespace.svc.cluster.local；对于常规的服务，这将解析为端口号和域名：my-svc.my-namespace.svc.cluster.local；对于headless服务，这将解析为多个答案。一个用于支持服务的每个Pod，并且包含Pod形式的端口号和域名:auto-generated-name.my-svc.my-namespace.svc.cluster.local。 PodsA records启用后，将以pod-ip-address.my-namespace.pod.cluster.local的形式为Pod分配DNS A记录。如10-0-1-11.default.pod.cluster.local。 Pod’s hostname and subdomain fields目前，当创建Pod时，其主机名时Pod的metadata.name值。Pod spec有一个可选的hostname字段，可用于指定Pod的主机名。指定后，它优先于Pod的名称作为Pod的主机名。Pod spec同样有一个可选的subdomain字段，可用于指定其子域。 栗子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344apiVersion: v1kind: Servicemetadata: name: default-subdomainspec: selector: name: busybox clusterIP: None ports: - name: foo port: 1234 targetPort: 1234---apiVersion: v1kind: Podmetadata: nam: busybox1 labels: name: busyboxspec: hostname: busybox-1 subdomain: default-subdomain containers: - image: busybox command: - sleep - '3600' name: busybox---apiVersion: v1kind: Podmetadata: name: busybox2 labels: name: busyboxspec: hostname: busybox-2 subdomain: default-subdomain containers: - image: busybox command: - sleep - "3600" name: busybox Pod’s DNS Policy可以基于每个Pod设置DNS策略。目前，k8s支持以下特定于Pod的DNS策略。这些策略在Pod spec中的dnsPolicy字段中指定。 DefaultPod从Pod的节点继承名称解析配置。 ClusterFirst任何与配置的集群域后缀名称不匹配的DNS查询，都会转发到从该节点继承的上游名称服务器。集群管理员可能配置了额外的存根域和上游DNS server。注意Default不是默认的DNS策略，如果未指定DNS策略，则使用ClusterFirst。 ClusterFirstWithHostNet对于使用hostNetwork运行的Pod，你应该明确设置其DNS策略为ClusterFirstWithHostNet。 Nonek8s v1.9+中引入的新功能。它允许Pod忽略k8s环境中的DNS设置。应该使用DNS spec中的dnsConfig字段提供所有的DNS设置。 Pod’s DNS Config要启用此功能，集群管理员需要在apiserver和kubelet上启用--feature-gates=CustomPodDNS=true,...。之后，用户便可以将Pod的dnsPolicy字段设置为None，并可以将新字段dnsConfig添加到Pod spec中。 dnsConfig字段是可选的，它可与任何dnsPolicy设置一起使用。但是，当Pod的dnsPolicy字段设置为None时，必须指定dnsConfig字段。 用户可在dnsConfig字段中指定的属性： nameservers用作Pod的DNS服务器的IP地址列表，最多可以指定3个IP地址。当dnsPolicy设置为None时，必须至少包含一个IP地址，否则此属性是可选的。 searchesPod中主机名查找的DNS搜索域列表，此属性是可选的。k8s最多允许6个搜索域。 options一个可选的对象属性，其中每个对象有name(必须): value(可选)。 栗子： 1234567891011121314151617181920apiVersion: v1kind: Podmetadata: namespace: default name: dns-examplespec: containers: - name: test image: nginx dnsPolicy: "None" dnsConfig: nameservers: - 1.2.3.4 searches: - ns1.svc.cluster.local - my.dns.search.suffix options: - name: ndots value: "2" - name: edns0 查看: 1234kubectl exec -it -- cat /etc/resolv.confnameserver 1.2.3.4search ns1.svc.cluster.local my.dns.search.suffixoptions ndots:2 edns0 连接应用与服务Connecting Applications with Services 现在你拥有了一个连续运行的副本应用程序，你可以在网络上公开它。在讨论k8s网络方法之前，值得将它与Docker的方式进行对比。默认情况下，Docker使用host-private网络，因此只有当容器位于同一台主机上时，容器才能与其它容器进行通信。为了使Docker容器能够跨节点通信，必须在主机的IP地址上分配端口，然后将这些端口转发或代理到容器。这意味着容器要小心协调它们使用的端口。k8s假设Pod可与其它Pod通信，无论它们着落在哪个主机。我们为每个Pod提供了集群专用IP，因此无需在Pod之间明确创建链接，或将容器端口映射到主机端口。这意味着Pod中的容器都可以在localhost上到达彼此的端口，并且集群中的所有Pod都可以在没有NAT的情况下看到对方。 将Pod公开给集群Exposing pods to the cluster 12345678910111213141516171819apiVersion: apps/v1kind: Deploymentmetadata: name: my-nginxspec: selector: matchLabels: run: my-nginx replicas: 2 template: metadata: labels: run: my-nginx spec: containers: - name: my-nginx image: nginx ports: - containerPort: 80 创建服务Creating a Service 123456789101112apiVersion: v1kind: Servicemetadata: name: my-nginx labels: run: my-nginxspec: ports: - port: 80 protocol: TCP selector: run: my-nginx 访问服务Accessing the Service Environment Variables DNS 1234kubectl exec &lt;pod&gt; -- printenvkubectl get services kube-dns --namespace=kube-system 服务安全Securing the Service 在将服务公开到因特网之前，你需要确保通信渠道是安全的。你需要： https签名证书 使用证书的nginx server 使证书可供Pod访问的secret 公开服务Exposing the Service NodePort LoadBalancer Ingress管理集群中外部访问服务的API对象，通常是HTTP。Ingress(入口)可以提供负载均衡，SSL终止和基于名称的虚拟主机。 术语Terminology Node Cluster Edge router Cluster network Service Ingress是什么通常，服务和Pod具有的IP仅可在集群网络路由。最终在边缘路由器上的所有流量都被丢弃或转发到其它地方。从概念上讲，这可能看起来像： 1234 internet |------------[ Services ] Ingress是一组允许访问连接到达集群服务的一组规则： 12345 internet |[ Ingress ]--|-----|--[ Services ] 它可以配置为微服务提供外部可访问的URL，负载均衡流量、ssl terminate、基于名称的虚拟主机等。用户通过POST ingress资源到api-server来请求ingress。Ingress Controller负责完成ingress，通常使用负载均衡器(loadbalancer)，但也可配置为edge router或其它前端以帮助以HA方式处理流量。 先决条件Prerequisites 在开始使用ingress资源之前，你应该了解一些事项。Ingress是beta resource，在k8s v1.1 之前的版本中都没有。你需要一个ingress controller来满足Ingress，简单地创建资源将无法生效。GCE/Google Kubernetes Engine在master上部署ingress controller。你可以在Pod中部署任意数量的自定义入口控制器。你必须使用适当的class对每个入口进行注释。在GCE/google kubernetes engine以外的环境中，你需要将ingress controller部署为Pod。 Ingress资源一个最小化的Ingress看起来如下： 123456789101112131415apiVersion: extensions/v1beta1kind: Ingressmetadata: name: test-ingress annotations: nginx.ingress.kubernetes.io/rewrite-target: /#ingress spec需要配置负载均衡器或代理服务器所需的信息spec: rules: - http: paths: - path: /testpath backend: serviceName: test servicePort: 80 如果尚未配置ingress controller，则将此操作发送到api-verser将不起作用。 和其它k8s配置一样，Ingress也需要apiVersion, kind, metadata, spec字段。Ingress spec字段需要配置负载均衡器和代理服务器所需的所有信息。最重要的是，它包含与所有传入请求匹配的规则列表。目前，Ingress仅支持http规则。每个http rule都包含如下信息： a host，默认值为*；与后端挂念的一组path列表。在负载均衡器将流量定向到后端之前，host和path都必须与传入请求的内容匹配。后端(backend)是一个service:port的组合。入口流量通常直接发送到与后端匹配的端点(endpoint)。实例中没有包含Ingress的全局参数(global patameters)，详情请查看文档。 Ingress controllers为了使ingress资源正常工作，集群必须运行ingress controller——这与其它类型的控制器不同，后者通常为kube-controller-manager程序的一部分，并且通常作为集群创建的一部分而自启动。选择最适合你的集群的ingress controller。 k8s目前支持和维护GCE和Nginx控制器GCE: https://github.com/kubernetes/ingress-gce/blob/master/README.md F5 BIG-IP Controller for Kubernetes链接： http://clouddocs.f5.com/products/connectors/k8s-bigip-ctlr/latest Kong Ingress Controller for Kubernetes链接： https://konghq.com/blog/kubernetes-ingress-controller-for-kong/ TraefikTraefik: https://github.com/containous/traefikContainous: https://containo.us/services NGINX Ingress Controller for Kubernetes链接: https://www.nginx.com/products/nginx/kubernetes-ingress-controller/github: https://github.com/jcmoraisjr/haproxy-ingress HAProxy Ingress Controller for Kubernetes链接： https://www.haproxy.com/blog/haproxy_ingress_controller_for_kubernetes/ 基于istio的Control Ingress Trafficistio: https://istio.io/链接: https://istio.io/docs/tasks/traffic-management/ingress/ ####Ingress的类型 Single Service Ingress现有的k8s概念允许你公开单个服务，但你也可以通过Ingress指定不使用规则的默认后端。 12345678apiVersion: extensions/v1beta1kind: Ingressmetadata: name: test-ingressspec: backend: serviceName: testsvc servicePort: 80 12345678#创建kubectl create -f#查看kubectl get ingress test-ingressNAME HOSTS ADDRESS PORTS AGEtest-ingress * 107.178.254.228 80 59s#107.178.254.228是ingress controller为满足此Ingress而分配的IP Simple fanout如前所述，k8s中Pod只能在集群内网络上看到IP，因此我们需要在边缘处接收入口流量并将其代理到正确的端点。该组件通常是高可用的负载均衡器。Ingress允许你将负载均衡器的数量将至最低。例如： 12foo.bar.com -&gt; 178.91.123.132 -&gt; / foo s1:80 / bar s2:80 需要一个Ingress，例如： 12345678910111213141516171819apiVersion: extensions/v1beta1kind: Ingressmetadata: name: test annotations: nginx.ingress.kubernetes.io/rewrite-target: /spec: rules: - host: foo.bar.com http: paths: - path: /foo backend: serviceName: s1 servicePort: 80 - path: /bar backend: serviceName: s2 servicePort: 80 12345678910111213141516171819kubectl create -f xxxkubectl describe ingress testName: testNamespace: defaultAddress: 178.91.123.132Default backend: default-http-backend:80 (10.8.2.3:8080)Rules: Host Path Backends ---- ---- -------- foo.bar.com /foo s1:80 (10.8.0.90:80) /bar s2:80 (10.8.0.91:80)Annotations: nginx.ingress.kubernetes.io/rewrite-target: /Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ADD 22s loadbalancer-controller default/test Name based virtual hosting基于名称的虚拟主机对同一IP地址使用多个主机名。 123foo.bar.com --| |-&gt; foo.bar.com s1:80 | 178.91.123.132 |bar.foo.com --| |-&gt; bar.foo.com s2:80 如下的Ingress告诉后端负载均衡器根据Host Header来路由请求： 123456789101112131415161718apiVersion: extensions/v1beta1kind: Ingressmetadata: name: testspec: rules: - host: foo.bar.com http: paths: - backend: serviceName: s1 servicePort: 80 - host: bar.foo.com http: paths: - backend: serviceName: s2 servicePort: 80 default backend： 没有指定规则的Ingress将所有流量发送到单个默认后端。你可以使用相同的技术来指定一组规则和默认后端来告诉负载均衡器在哪里找到网站的404页面。如果Ingress中的所有主机都与请求Header中的主机不匹配，并且没有任何路径与请求的URL匹配，则流量将路由到你的默认后端。 TLS可以通过指定包含TSL私钥和证书的机密来保护Ingress。目前，Ingress仅支持单个TLS 443端口。TLS Secret必须包含名为tls.crt和tls.key的证书和密钥： 123456789apiVersion: v1data: tls.crt: base64 encoded cert tls.key: base64 encoded keykind: Secretmetadata: name: testsecret namespace: defaulttype: Opaque 在Ingress中引用secret将此告知ingress controller： 12345678910apiVersion: extensions/v1beta1kind: Ingressmetadata: name: no-rules-mapspec: tls: - secretName: testsecret backend: serviceName: s1 servicePort: 80 请注意，各种ingress controller支持的TLS功能存在差异性。 Loadbalancingingress controller通过一些适用于所有Ingress的负载均衡策略设置进行引导(bootstrapped)，一些高级 的负载均衡概念(持久会话、动态权重)尚未通过Ingress进行公开。但你仍然可以通过服务负载均衡器获得这些功能。 更新Ingress 直接更新资源 更新配置文件 123456#直接更新资源kubectl edit ingress test#更新修改的配置文件kubectl replace -f xxx 未来计划 各种模式的HTTPS/TLS支持 通过声明请求IP或Hostname 结合L4和L7 Ingress 更多ingress controller Alternatives有多种方式公开服务： LoadBalancer NodePort Port Proxy LoadBalancer/NodePort/Ingress比较参考: Kubernetes NodePort vs LoadBalancer vs Ingress? When should I use what? 这几种服务类型的优缺点，以及什么时候使用它们。 Cluster IPCluster IP是默认的k8s服务，它提供集群内部的访问，外部无法访问。但你可以使用kubernetes proxy来访问它。 什么时候使用： 调试服务 内部访问就可 12345#开启proxykubectl proxy --port=8080#访问资源http://localhost:8080/api/v1/proxy/namespaces/&lt;NAMESPACE&gt;/services/&lt;SERVICE-NAME&gt;:&lt;PORT-NAME&gt;/ NodePortNodePort是公开服务的最原始的方式。 什么时候使用？此方法有许多缺点： 每个端口只能有一个服务 默认端口范文30000-32767 如果节点IP地址发生更改，则需要处理该问题 由于这些原因，不建议在生产环境使用这种方法 LoadBalancerLoadBalancer是公开服务的标准方式。 什么时候用： 指定端口上的所有流量都被转发到该服务，没有过滤、路由等。这意味着你可以发送任何类型的流量，如HTTP, TCP, UDP, Websocket, gRPC… 最大的缺点，你必须为每一个公开的服务使用一个负载均衡器，这个负载均衡器公开的服务都将获得自己的IP，这可能会付出比较大的代价 Ingress与以上方式不同，Ingress不是一种服务。相反，它位于多个服务之前，充当集群中的入口。你可以使用Ingress做很多不同的事，并且有许多类型的 ingress controller，具有不同的功能。 什么时候用： Ingress可能是公开服务最强大的方式，但也可能是最复杂的 如果你希望在相同的IP下公开多个服务，则Ingress是最有用的 网络策略Network Policies 网络策略是允许容器组如何与彼此以及其它网络端点通信的规范。NetworkPolicy资源使用labels选择Pod并定义规则，这些规则指定允许选定的Pod的流量。 先决条件网络策略由网络插件来实现，因此你必须使用支持NetworkPolicy的网络解决方案——简单地创建资源而没有控制器来实现它将不起作用。 Isolated and Non-isolated Pods默认情况下，Pod是非隔离的(non-isolated)。它们接受任何来源的流量。可选择NetworkPolicy来隔离Pod，一旦命名空间中任何NetworkPolicy选择了特定的Pod，该Pod将拒绝网络策略不允许的任何连接。 NetworkPolicy资源The NetworkPolicy Resource 栗子： 12345678910111213141516171819202122232425262728293031323334apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: test-network-policy namespace: defaultspec: podSelector: matchLabels: role: db policyTypes: - Ingress - Egress ingress: - from: - ipBlock: cidr: 172.17.0.0/16 except: - 172.17.1.0/24 - namespaceSelector: matchLabels: project: myproject - podSelector: matchLabels: role: frontend ports: - protocol: TCP port: 6379 egress: - to: - ipBlock: cidr: 10.0.0.0/24 ports: - protocol: TCP port: 5978 必填字段： NetworkPolicy, apiVersion, kind, metadata spec: 网络策略所需的所有信息 podSelector： 选择策略适用的Pod分组。(如果为空，则表示此命名空间下的所有Pod) policyTypes： 可能包含Ingress, Egress。指示给定策略是否适用于入口流量和出口流量。(如果为空，默认为Ingress) ingress： 允许配置from和ports部分的流量。ipBlock, namespaceSelector, podSelector指定具体信息 egress： 允许配置to和ports部分的流量 默认策略Default policies 默认情况下，如果命名空间中不存在任何策略，则允许所有入口(ingress)和出口(egress)流量进出该命名空间中的Pod。 默认拒绝所有入口流量(Default deny all ingress traffic)你可以通过创建NetworkPolicy来为命名空间创建默认的隔离策略，该策略选择所有Pod但不允许任何入口流量到这些Pod。 12345678apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: default-denyspec: podSelector: &#123;&#125; policyTypes: - Ingress 默认允许所有入口流量(Default allow all ingress traffic)如果要允许所有流量到命名空间的所有Pod，你可以创建一个明确允许该命名空间中所有流量的策略。 12345678apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: allow-allspec: podSelector: &#123;&#125; ingress: - &#123;&#125; 默认拒绝所有出口流量(Default deny all egress traffic)可通过创建NetworkPolicy来为命名空间创建默认的出口隔离策略，该策略选择所有Pod但不允许来自这些Pod的出口流量。 12345678apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: default-denyspec: podSelector: &#123;&#125; policyTypes: - Egress 默认允许所有出口流量(Default allow all egress traffic) 12345678910apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: allow-allspec: podSelector: &#123;&#125; egress: - &#123;&#125; policyTypes: - Egress 默认拒绝所有入口/出口流量(Default deny all ingress and all egress traffic) 123456789apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: default-denyspec: podSelector: &#123;&#125; policyTypes: - Ingress - Egress 使用HostAliases向Pod的hosts添加条目Adding entries to Pod /etc/hosts with HostAliases 当DNS和其它选项不适用时，向Pod的/etc/hosts文件添加条目可提供主机名解析的Pod级别的覆盖。在 v1.7 中，用户可以使用pod spec中的HostAliases字段来添加这些自定义条目。不建议不使用HostAliases进行修改，因为该文件由Kubelet管理，并且可以在Pod 创建/重启 期间覆盖。 默认hosts文件Default Hosts File Content 查看Pod hosts文件： 123456789101112131415kubectl get pod -o=wideNAME READY STATUS RESTARTS AGE IP NODEnginx-deployment-597549df56-chjps 1/1 Running 0 26d 10.244.2.52 salt01#kubectl exec POD [-c CONTAINER] -- COMMAND [args...] [options]kubectl exec nginx-deployment-597549df56-chjps -- cat /etc/hosts# Kubernetes-managed hosts file.127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetfe00::0 ip6-mcastprefixfe00::1 ip6-allnodesfe00::2 ip6-allrouters10.244.2.52 nginx-deployment-597549df56-chjps 使用HostAliases添加额外条目Adding Additional Entries with HostAliases hostaliases-pod.yaml: 123456789101112131415161718192021apiVersion: v1kind: Podmetadata: name: hostaliases-podspec: restartPolicy: Never hostAliases: - ip: "127.0.0.1" hostnames: - "foo.local" - "bar.local" - ip: "192.168.31.119" hostnames: - zhang21 containers: - name: cat-hosts image: busybox command: - cat args: - "/etc/hosts" 123456789101112131415kubectl apply -f hostaliases-pod.yamlkubeclt logs hostaliases-pod# Kubernetes-managed hosts file.127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetfe00::0 ip6-mcastprefixfe00::1 ip6-allnodesfe00::2 ip6-allrouters10.244.1.69 hostaliases-pod# Entries added by HostAliases.127.0.0.1 foo.local127.0.0.1 bar.local192.168.31.119 zhang21 为什么kubelet管理hostsWhy Does Kubelet Manage the Hosts File? Kubelet管理Pod中每个容器的hosts文件，以防止Docker在容器已启动后修改文件。由于文件的托管性质，只要在容器重启或Pod重新调度的情况下由Kubelet重新挂载hosts文件，因此用户编写的内容都将被覆盖。因此，不建议直接修改文件的内容。 存储Storage Volumes容器中的磁盘文件是短暂的，这在容器中运行时会给重大的应用程序带来一些问题。首先，当一个容器奔溃时，kubelet将重启它，但文件会丢失，容器将以干净的状态启动。其次，在Pod中一起运行容器时，通常需要在这些容器间共享文件。k8s volume抽象解决这些问题。 BackgroundDocker也有关于卷的概念，虽然它有点宽松和管理较少。在Docker中，卷是磁盘上或其它容器中的目录，声明周期不受管理。Docker提供了卷驱动，但目前功能非常有限。 另一方面，k8s的卷具有明确的生命周期。因此，卷可以比Pod中运行的任何容器活得更久，并且可在容器重启之间保留数据。当然，当Pod不再存在时，卷也将不复存在。更重要的是，k8s支持多种类型的卷，Pod可以同时使用任意数量的卷。从本质上讲，卷只是一个目录，可能包含一些数据，Pod中的容器可以访问它。该目录如何形成，支持它的介质以及它的内容都由所用特定卷的类型决定。要使用卷，Pod Spec要指定提供的卷(.spec.volumes字段)，以及将这些卷挂载到容器中的位置(.spec.containers.volumeMounts字段)。 容器中的进程可以看到由Docker镜像和卷组成的文件系统视图。Docker镜像位于文件系统层次结构的根下，任何卷都挂载到镜像中的指定路径。卷不能挂载到其它卷或其它卷的硬链接上，Pod中的每个容器必须独立的指定每个卷的挂载位置。 卷类型k8s支持如下卷类型。注意，这些卷并非全部都是持久化的(如emptyDir)，它们会随着Pod的消亡而消亡。 awsElasticBlockStore azureDisk azureFile cephfs configMap csi downwardAPI emptyDir fc (fibre channel) flocker gcePersistentDisk gitRepo (deprecated) glusterfs hostPath iscsi local nfs persistentVolumeClaim projected portworxVolume quobyte rbd scaleIO secret storageos vsphereVolume 具体例子请参考: https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes configMapconfigMap资源提供了一种将配置数据注入Pod的方法。存储在configMap对象中的数据可以在configMap类型的卷中引用，然后由Pod中运行的应用程序使用。引用configMap对象时，只需在卷中提供其名称即可引用它。你还可以自定义configMap中的特定条路的路径。 例如，要将log-config的ConfigMap挂载到名为configmap-pod的Pod上，你可以这样操作：注意，在使用之前你先得创建ConfigMap使用ConfigMap作为subPath的卷挂载将不会收到ConfigMap的更新 12345678910111213141516171819apiVersion: v1kind: Podmetadata: name: configmap-podspec: containers: - name: test image: busybox volumeMounts: - name: config-vol mountPath: /etc/config volumes: - name: config-vol configMap: name: log-config items: - key: log_level path: log_level#log-config configMap作为卷挂载，存储在`log_level`的所有内容都挂载到路径`/etc/config/log_level`的Pod中 emptyDir将Pod分配给节点时，首先会创建一个emptyDir卷。只要节点还在该节点上运行，它就会存在。就如同它的名称一样，它最初是空的。Pod中的容器都可以在emptyDir卷中读取和写入相同的文件，尽管改卷可以安装在每个容器中相同或不同的路径上。当从节点上删除Pod时，将永久删除emptyDir中的数据。注意：容器奔溃不会从节点中删除Pod，因此emptyDir卷中的数据在容器奔溃时是安全的。 emptyDir的一些用途： 临时空间 检查从崩溃中恢复的长计算 保存内容管理器容器在Web服务器提供数据时提取的文件 默认情况下，emptyDir卷存储在节点的任何介质上(磁盘、SSD、网络存储…)，取决于你的环境。但是，你可以将emptyDir.medium字段设置为Memory，以告诉k8s为你安装tmpfs(RAM支持的文件系统)。tmpfs非常快，但请注意断电就没有了，并且你编写的任何文件都将计入容器的内存限制。 栗子： 1234567891011121314apiVersion: v1kind: Podmetadata: name: test-pdspec: containers: - image: k8s.gcr.io/test-webserver name: test-container volumeMounts: - mountPath: /cache name: cache-volume volumes: - name: cache-volume emptyDir: &#123;&#125; hostPathhostPath卷将文件或目录从主机节点的文件系统挂载到Pod中。这不是大多数Pod需要的东西，但它为某些应用程序提供了强大的逃生舱。 hostPath的一些用途： 运行需要访问Docker内部的容器，使用/var/lib/docker的hostPath 在容器中运行cAdvisor 允许Pod指定在Pod运行之前是否应该存在给定的hostPath，是否应该创建它以及它应该存在的内容 三个字段: hostPath path type 支持的type的值： Value Behavior 空 Empty string (default) is for backward compatibility, which means that no checks will be performed before mounting the hostPath volume. DirectoryOrCreate If nothing exists at the given path, an empty directory will be created there as needed with permission set to 0755, having the same group and ownership with Kubelet. Directory A directory must exist at the given path FileOrCreate If nothing exists at the given path, an empty file will be created there as needed with permission set to 0644, having the same group and ownership with Kubelet. File A file must exist at the given path Socket A UNIX socket must exist at the given path CharDevice A character device must exist at the given path BlockDevice A block device must exist at the given path 请注意何时使用此类型的卷，因为： 由于节点上的文件不同，具有相同配置的Pod在不同节点上的行为可能有所不同 当k8s按计划添加资源，它将无法考虑hostPath使用的资源 在底层主机上创建的文件或目录只能由root写入 栗子: 123456789101112131415161718apiVersion: v1kind: Podmetadata: name: test-pdspec: containers: - image: k8s.gcr.io/test-webserver name: test-container volumeMounts: - mountPath: /test-pd name: test-volume volumes: - name: test-volume hostPath: # directory location on host path: /data # this field is optional type: Directory locallocal卷表示已挂载的本地存储设备，如磁盘，分区或目录。它只能用作静态创建的持久化卷，尚不支持动态配置。与hostPath卷相比，可以以持久且可移植的方式使用lobal卷，而无需手动将Pod调度到节点。然而，local卷仍受基础节点可用性的限制，并不适用于所有应用程序。如果节点变得不健康，则local卷也将变得不可访问，并且使用它的Pod将无法运行。使用local volume的应用程序必须能够容忍这种降低的可用性以及潜在的数据丢失，具体取决于底层磁盘的持久性特征。 栗子： 1234567891011121314151617181920212223apiVersion: v1kind: PersistentVolumemetadata: name: example-pvspec: capacity: storage: 100Gi # volumeMode field requires BlockVolume Alpha feature gate to be enabled. volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Delete storageClassName: local-storage local: path: /mnt/disks/ssd1 nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - example-node NFS栗子： 123456volumes:- name: nfs nfs: # FIXME: use the right hostname server: 10.254.234.223 path: "/" persistentVolumeClaimpersistentVolumeClaim卷用于将持久化卷挂载到Pod中。 使用子路径Using subPath 有时，在单个Pod中共享一个卷用于多个用途是很有用的。volumeMounts.subPath属性可用于指定引用卷内的子路径，而不是根路径。 使用单个共享卷的Pod与LAMP Stack的示例，HTML内容被映射到html目录中，数据库存储在mysql目录中： 12345678910111213141516171819202122232425apiVersion: v1kind: Podmetadata: name: my-lamp-sitespec: containers: - name: mysql image: mysql env: - name: MYSQL_ROOT_PASSWORD value: &quot;rootpasswd&quot; volumeMounts: - mountPath: /var/lib/mysql name: site-data subPath: mysql - name: php image: php:7.0-apache volumeMounts: - mountPath: /var/www/html name: site-data subPath: html volumes: - name: site-data persistentVolumeClaim: claimName: my-lamp-site-data 使用带有扩展环境变量的子路径Using subPath with expanded environment variables FEATURE STATE: k8s v1.11 alpha subPath目录名也可从Downward API环境变量构造。在使用此功能之前，必须启用VolumeSubpathEnvExpansion。下例中，Pod使用subPath在主机路径卷/var/log/pods中创建pod1目录，使用Downward API中的Pod名。主机目录/var/log/pods/pod1被挂载到容器中的/logs目录。 123456789101112131415161718192021222324apiVersion: v1kind: Podmetadata: name: pod1spec: containers: - name: container1 env: - name: POD_NAME valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.name image: busybox command: [ &quot;sh&quot;, &quot;-c&quot;, &quot;while [ true ]; do echo &apos;Hello&apos;; sleep 10; done | tee -a /logs/hello.txt&quot; ] volumeMounts: - name: workdir1 mountPath: /logs subPath: $(POD_NAME) restartPolicy: Never volumes: - name: workdir1 hostPath: path: /var/log/pods 资源emptyDir卷的存储介质(磁盘，SSD…)由kubelet根目录的文件系统的介质确定。emptyDir或hostPath卷可以占用多少空间没有限制，容器之间或Pod之间没有隔离。 ####挂载传播 Mount propagation FEATURE STATE: k8s v1.10 beta 挂载传播允许将容器挂载的卷共享到同一Pod的其它容器，或同一节点的其它Pod。如果MountPropagation功能被禁用，或Pod未指明特定的挂载环境，则不会传播Pod的容器中的挂载卷。卷的挂载传播由Container.volumeMounts中的mountPropagation字段控制。它的值为： None此卷的挂载不会接收主机挂载到此卷或任何子目录的任何后续挂载。此模式等同于于Linux kernel中描述的private挂载传播。 HostToContainer此卷的挂载将接收安装到此卷或其任何子目录的所有后续挂载。换句话说，如果主机在卷挂载中挂载任何内容，则容器将看到它挂载在那里。类似地，如果任何具有双向挂载传播的Pod挂载到同一个卷中，那么具有HostToContainer挂载传播的容器将看到它。此模式等同于Linux Kernel中描述的rslave挂载传播。 Bidirectional此卷的挂载行为与HostToContainer相同。此外，容器创建的所有卷 挂载都将传播会主机和所有使用相同卷的Pod中的容器。此模式等同于Linux kernel中描述的rshared挂载传播。 配置在挂载传播可以在某些部署上正常工作之前，必须在Docker中正确配置挂载共享，修改docker systemd服务文件，设置MountFlags： 1MountFlags=shared 重启Docker： 12systemctl daemon-reloadsystemctl restart docker 持久化卷Persistent Volumes 垃圾收集Kubernetes 垃圾收集器的角色是删除指定的对象，这些对象曾经有但以后不再拥有 Owner 了。 某些Kubernetes对象是其它一些对象的Owner。如，一个副本集是一组pod的Owner。具有Owner的对象被称为是Owner的Dependent。每个Dependent对象具有一个执行所属对象的metadata.ownerReference字段。 有时，Kubernetes会自动设置ownerReference的值。也可以手动设置ownerReference的值，来指定Owner和Dependent之间的关系。 控制垃圾收集器删除Dependent 级联删除 background foreground删除对象时自动删除Dependent。在bg级联删除模式下，k8s会立即删除Owner对象，然后垃圾收集器会在后台删除这些Dependent。在fg级联删除模式下，根对象首先进入删除中状态。一旦对象被设置为删除中状态，垃圾收集器会删除对象的所有Dependent。 孤儿删除对象时，不自动删除它的Dependent。这些Dependent就被称作孤儿。垃圾收集器在删除了所有 “Blocking” 状态的 Dependent（对象的 ownerReference.blockOwnerDeletion=true）之后，它会删除 Owner 对象。 教程Tutorials 教程展示了如何实现比单个任务更大的目标(task)。 一个栗子栗子里面包含一个Service和Deployment，请一定要注意yaml的语法格式，不使用-的话可能会报错。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#注意yaml语法错误apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginx-deployment-test namespace: default labels: k8s-app: nginx env: test annotations: des: A k8s-deployment test author: Zhang21 date: 2018-09-13spec: replicas: 1 selector: matchLabels: k8s-app: nginx template: metadata: labels: k8s-app: nginx spec: dnsPolicy: ClusterFirst restartPolicy: Always volumes: - name: test01 emptyDir: &#123;&#125; - name: test02 hostPath: path: /tmp/k8s/volume/test02 containers: - name: nginx image: nginx:1.12.2 imagePullPolicy: Always workingDir: /usr/share/nginx/html ports: - containerPort: 80 env: - name: AUTHOR value: Zhang21 - name: EMAIL value: me@zhang21.cn volumeMounts: - name: test01 mountPath: /usr/share/nginx/html/test01 - name: test02 mountPath: /usr/share/nginx/html/test02 resources: requests: cpu: 100m memory: 100Mi limits: cpu: 0.3 memory: 300Mi---apiVersion: v1kind: Servicemetadata: name: nginx-service-test namespace: default labels: k8s-app: nginx annotations: des: A k8s Service test author: Zhang21 date: 2018-09-13spec: #记得指定应用，不然服务无法找到后端端点和容器组 selector: k8s-app: nginx type: NodePort ports: - name: http nodePort: 31234 #The range of valid ports is 30000-32767 protocol: TCP port: 80 targetPort: 80status: loadBalancer: &#123;&#125; 执行: 123456789kubectl apply -f ./nginx.yaml#apply可修改后更新kubectl apply -f ./nginx.yaml#之后在dashboard中查看成功与否#访问master 31234 portcurl master:31234 k8s基本 综述本教程提供了Kubernetes集群编排系统基础知识的介绍。 你将学到： 在集群上部署容器化服务 伸缩部署 使用新软件版本更新容器化应用程序 调试容器化应用程序 k8s能为你做什么？容器化有助于打包软件以实现这些目标，是应用程序能够以简单快速的方式发布和更新，而无需停机。k8s可帮助你确保这些容器化应用程序随时随地运行，并帮助它们找到运行所需的资源。 k8s 基础模块 创建(create)一个k8s集群 部署(deploy)应用程序 探索(explore)应用程序 公开(expose)展示应用程序 伸缩(scale)应用程序 升级(update)应用程序 创建集群Create a Cluseter 详情见安装部分。 部署应用程序Deploy an APP 使用kubectl创建部署Using kubectl to create a Deployment 目标： 了解应用程序部署 在k8s上使用kubectl部署你的第一个应用程序 k8s Deployments一旦运行了k8s集群，就可在其上部署容器化应用程序。为此，你需要创建Kubernetes Deployment configuration。它指示k8s 如何创建和更新应用程序实例。创建部署后，k8s master将应用程序实例调度到各个node上。创建应用程序实例后，Kubernetes Deployment Controller会持续监控这些实例。如果主机节点上的实例关闭或删除，Deployment Controller会替换它。这提供了一种自我修复(self-healing)机制来解决机器故障或维护。 部署应用程序可使用kubectl(使用k8s api与集群交互)来创建和管理Deployment。下面有一些关于使用kubectl在k8s集群上创建和管理Deployment的基础命令。 创建部署时，你需要指定应用程序的容器镜像(image)，以及要运行的副本数(replicas)。你可在以后改变这些信息来更新你的部署。 栗子：第一个部署，k8s使用一个Docker容器的Node.js应用程序包。 12345678910111213141516171819202122kubectl version#client#serverkubectl get nodes#创建名为k8s-bootcamp的deploymentkubectl run kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1 --port=8080#这是国内镜像: docker.io/jocatalin/kubernetes-bootcamp:v1kubectl get deploymentsNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEkubenetes-bootcamp 1 1 1 1 1h#表示 希望副本数，当前副本数，最新副本数，可用副本数#由于pod被封装在集群私网，没有对外开放#proxy将通信转发到集群内私网kubectl proxycurl http://localhost:8081/versioncurl http://localhost:8001/api/v1/namespaces/default/pods/$POD_NAME/proxy/#Hello Kubernetes bootcamp! 此处我遇到一个错误，replicats unavailable:原因是拉取的镜像在谷歌云上，无法访问，拉取失败所以导致部署失败。gcr(google container Registry) 12345678910111213141516171819#查看部署信息 kubectl get deployment kubernetes-bootcamp -o yaml message: &apos;unable to create pods: No API token found for service account &quot;default&quot;, retry after the token is automatically created and added to the service account&apos; reason: FailedCreate status: &quot;True&quot; type: ReplicaFailurekubectl get deploymentsNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEkubernetes-bootcamp 1 0 0 0 33mkubectl describe deployments kubernetes-bootcampReplicas: 1 desired | 0 updated | 0 total | 0 available | 1 unavailableStrategyType: RollingUpdateReplicaFailure True FailedCreate 针对unable to create pods: No API token found for service account “default”这个问题，需要修改kube-apiserver配置文件： 123456789101112131415161718192021222324252627282930313233343536#去掉 KUBE_ADMISSION_CONTROL中的SecurityContextDeny,ServiceAccountKUBE_ADMISSION_CONTROL=&quot;--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota&quot;#重启kube-apiserversystemctl restart kube-apiserver#之后查看副本数就正常了kubectl get deploymentsNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEkubernetes-bootcamp 1 1 1 0 8m#这里available还是0kubectl get podsNAME READY STATUS RESTARTS AGEkubernetes-bootcamp-390780338-6x48n 0/1 ContainerCreating 0 21h#pod处于创建状态#查看详情kubectl describe pods#错误信息 Warning FailedSync 4m (x258 over 21h) kubelet, 192.168.31.159 Error syncing pod, skipping: failed to &quot;StartContainer&quot; for &quot;POD&quot; with ErrImagePull: &quot;image pull failed for registry.access.redhat.com/rhel7/pod-infrastructure:latest, this may be because there are no credentials on this request. details: (open /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt: no such file or directory)&quot; Warning FailedSync 9s (x5728 over 21h) kubelet, 192.168.31.159 Error syncing pod, skipping: failed to &quot;StartContainer&quot; for &quot;POD&quot; with ImagePullBackOff: &quot;Back-off pulling image \&quot;registry.access.redhat.com/rhel7/pod-infrastructure:latest\&quot;&quot;#在node上查看此文件，发现它指向了一个空链接#并不存在/etc/rhsm目录ll /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crtlrwxrwxrwx. 1 root root 27 7月 16 16:58 /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt -&gt; /etc/rhsm/ca/redhat-uep.pem#在node安装此rhsmyum search rhsm#python-rhsm-certificates.x86_64#python-rhsm.x86_64yum install -y python-rhsm.x86_64 python-rhsm-certificates.x86_64#之后在node上手动拉取下image便可看到pod正常运行 探索应用程序Explore Your App 查看Pods和Nodes目标： 了解k8s Pods 了解k8s Nodes 部署应用的故障解决(troubleshoot) k8s Pods当你创建一个部署时，k8s创建了一个pod来托管你的应用程序实例。pod是k8s的一个抽象，表示一组(一个/多个)应用程序容器，以及这些容器的共享资源。pod有一个唯一的IP地址，甚至是同一节点上的pod。pod中的容器共享IP地址和端口，始终位于同一位置并共同调度，并在同一节点上共享上下文中运行。这些资源包括： 共享存储(volumes) 网络(唯一的集群内ip) 运行容器的相关信息 Nodespod总是运行在node上，一个node上可运行多个pod。每个node由master管理，master自动处理在node上调度pod。node至少运行如下组件： kubelet container runtime(如docker) Troubleshooting with kubectl最常用的kubectl命令： 12345678910111213141516171819#列出资源kubectl get#kubectl get nodes#某个资源的详细信息kubectl describe#kubectl describe deployments kubernetes-bootcamp#pod中容器日志kubectl logs#kubectl logs $pod --since=1h#在pod的容器执行命令kubectl exec#kubectl ecec $pod env#kubectl exec -it $pod /bin/bash 公开展示应用程序Expose Your App Publicly 使用服务来展示应用程序Using a Service to Expose Your App 目标： 了解k8s中的服务(service) 理解labels和LabelSelector对象如何关联服务 使用服务将应用程序展示在集群外部 k8s Service事实上，pods有一个生命周期。当工作node死亡，node上运行的pods也会丢失。ReplicationController可以通过创建新的Pod来动态地将集群驱动会所需状态，以使应用程序保持运行。k8s的服务是一个抽象概念，它定义了一组逻辑Pod和一个访问pods的策略。服务使用YAML或JSON来定义。由一组pods所构成的服务通常由LabelSelector来确定。尽管每个Pod都有一个唯一的IP地址，但如果没有服务，这些IP就不会在集群外公开。通过指定ServeceSpec中的type，可以不同方式公开服务: ClusterIP(默认方式)在集群内部IP公开服务，只可内部访问 NodePort使用NAT在集群的指定节点上公开服务 LoadBalancer创建一个外部负载均衡器，并给服务分配一个外部IP ExternalName通过返回带有名称的CNAME(k8s-dns)记录，使用任意名称公开服务 Services和Labels服务使用labels和selectors匹配一组pod这是一个允许对k8s的对象进行逻辑操作的分组原语。Label是附件到对象的键/值对，随时随地可修改。有多种方式可使用： 指定用于开发(development)、测试(test)、生产(procuct)的对象 嵌入版本tag 使用tag对对象进行分类 栗子： 1234567891011121314151617181920212223242526272829303132333435kubectl get pods#NAME READY STATUS RESTARTS AGE#kubernetes-bootcamp-390780338-6x48n 1/1 Running 0 22hkubectl get services#NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE#kubernetes ClusterIP 10.254.0.1 &lt;none&gt; 443/TCP 1d#公开展示应用程序kubectl expose deployment/kubernetes-bootcamp --type=&quot;NodePort&quot; --port 8080#service &quot;kubernetes-bootcamp&quot; exposedkubectl get services#NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE#kubernetes ClusterIP 10.254.0.1 &lt;none&gt; 443/TCP 1d#kubernetes-bootcamp NodePort 10.254.11.76 &lt;none&gt; 8080:31514/TCP 2mkubectl describe services/kubernetes-bootcampkubectl describe deployment#Labels: run=kubernetes-bootcamp#使用label查询kubectl get pods -l run=kubernetes-bootcampkubectl get services -l run=kubernetes-bootcamp#使用label删除kubectl delete service -l run=kubernetes-bootcampkubectl describe pods kubernetes-bootcamp-390780338-6x48nkubectl exec -it kubernetes-bootcamp-390780338-6x48n /bin/bash 扩展应用程序Scale Your App Running Multiple Instances of Your App 目标： 使用kubectl伸缩应用程序 伸缩应用程序前面通过部署创建的服务仅有一个pod，当遇到流量激增，我们便需要扩展应用程序。通过更改部署中的副本数来完成扩展。 扩展部署将确保使用可用资源(available resource)创建新的pod并将其调度到node。k8s支持Pod的自动伸缩，缩放到0(也就是没有pod)也是可能的，它将终止指定部署的所有Pod。对应用程序运行多个实例需要一种方法将流量分配给所有这些实例。服务有集成的负载均衡器(load-blancer)，可将网络流量分配到公开部署的所有Pod。服务将使用endpoint持续监控运行的Pod，以确保网络流量发送到可用的Pods。 一旦运行的应用程序有了多个实例，你就可以在不停机(downtime)的情况下执行滚动更新(rolling update)。 12345678910111213141516171819202122232425262728293031323334353637383940kubectl get deployments#1个#扩展实例kubectl scale deployments/kubernetes-bootcamp --replicas=4#deployment.extensions &quot;kubernetes-bootcamp&quot; scaledkubectl get deployments#4个kubectl get pods -o wide#4个kubectl describe deployment/kubernetes-bootcampkubectl describe services/kubernetes-bootcamp#缩放实例kubectl scale deployments/kubernetes-bootcamp --replicas=2#deployment.extensions &quot;kubernetes-bootcamp&quot; scaledkubectl get deployments#2个#有两个pods正在关闭中kubectl get pods -o wideNAME READY STATUS RESTARTS AGE IP NODEkubernetes-bootcamp-390780338-1zgvs 1/1 Terminating 0 7m 10.254.76.5 192.168.31.159kubernetes-bootcamp-390780338-6x48n 1/1 Running 0 2d 10.254.76.2 192.168.31.159kubernetes-bootcamp-390780338-bqztg 1/1 Running 0 7m 10.254.76.4 192.168.31.159kubernetes-bootcamp-390780338-hkwfd 1/1 Terminating 0 7m 10.254.76.3 192.168.31.159#关闭完成kubectl get pods -o wideNAME READY STATUS RESTARTS AGE IP NODEkubernetes-bootcamp-390780338-6x48n 1/1 Running 0 2d 10.254.76.2 192.168.31.159kubernetes-bootcamp-390780338-bqztg 1/1 Running 0 15m 10.254.76.4 192.168.31.159 升级应用程序Update your AppPerforming a Rolling Update 目标： 使用kubectl执行滚动升级 滚动更新用户希望应用程序始终可用，可发人员可能会多次部署新版本应用程序。在k8s中，这都可以通过滚动更新(rolling update)完成。滚动更新允许通过使用新的实例逐步更新Pod来实现部署的更新，而不需停机(downtime)。新的Pod将在具有可用资源的node上进行调度。在k8s中，更新是版本化的，任何部署更新都可以恢复到以前的版本。 与应用程序扩展类似，服务在更新期间仅会将流量负载均衡到可用的Pod(应用实例)。 滚动更新允许以下操作： 将应用程序从一个环境推到另一个环境 回滚(rollback)到之前的版本 无需停机的持续集成(CI)和持续交付(CD) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263kubectl get deploymentskubectl get pods#2个#更新镜像kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=docker.io/jocatalin/kubernetes-bootcamp:v2deployment.apps &quot;kubernetes-bootcamp&quot; image updated#kubectl get podsNAME READY STATUS RESTARTS AGEkubernetes-bootcamp-390780338-6x48n 1/1 Terminating 0 3dkubernetes-bootcamp-390780338-bqztg 1/1 Terminating 0 38mkubernetes-bootcamp-472176051-m6h1q 1/1 Running 0 29skubernetes-bootcamp-472176051-z4wqs 1/1 Running 0 29s#kubectl get podsNAME READY STATUS RESTARTS AGEkubernetes-bootcamp-472176051-m6h1q 1/1 Running 0 42skubernetes-bootcamp-472176051-z4wqs 1/1 Running 0 42s#检查回滚状态kubectl rollout status deployments/kubernetes-bootcampdeployment &quot;kubernetes-bootcamp&quot; successfully rolled out#更新kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=docker.io/jocatalin/kubernetes-bootcamp:v10deployment.apps &quot;kubernetes-bootcamp&quot; image updated#有错kubectl get deploymentsNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEkubernetes-bootcamp 2 3 2 1 3d#有错kubectl get podsNAME READY STATUS RESTARTS AGEkubernetes-bootcamp-384357858-7kjx1 0/1 ErrImagePull 0 2mkubernetes-bootcamp-384357858-t0wmt 0/1 ImagePullBackOff 0 2mkubernetes-bootcamp-472176051-m6h1q 1/1 Running 0 9m#kubectl describe pods#回滚kubectl rollout undo deployments/kubernetes-bootcampdeployment.apps &quot;kubernetes-bootcamp&quot;#查看kubectl get podskubectl decribe pods#Image: docker.io/jocatalin/kubernetes-bootcamp:v2#回到了V2版 配置Configuration 使用ConfigMap配置Redis目标(Objective) 创建ConfigMap 使用ConfigMap创建Pod规范 创建Pod 验证配置是否正确应用 开始之前需要有k8s集群，并且安装了kubectl命令行工具。 栗子：使用ConfigMap配置Redis 12345678910111213141516171819202122232425262728293031323334353637383940414243#Master#创建redis的ConfigMapkubectl create configmap redis-config --from-file=xxx/redis-configkubectl get configmap redis-config -o yaml#创建redis-pod.yaml文件apiVersion: v1kind: Podmetadata: name: redisspec: containers: - name: redis image: kubernetes/redis:v1 env: - name: MASTER value: &quot;true&quot; ports: - containerPort: 6379 resources: limits: cpu: &quot;0.1&quot; volumeMounts: - mountPath: /redis-master-data name: data - mountPath: /redis-master name: config volumes: - name: data emptyDir: &#123;&#125; - name: config configMap: name: redis-config items: - key: redis-config path: redis.conf#创建podkubectl create -f /etc/k8s/pods/config/redis-pod.yamlkubectl exec -it redis redis-cli 无状态应用程序Stateless Applications 公开外物IP以访问集群中的应用程序Exposing an External IP Address to Access an Application in a Cluster 目标 为一个Hello World应用程序运行五个实例 创建一个展示外部IP的服务对象 使用服务对象去访问运行的应用程序 为运行五个pods的应用程序创建一个服务 12345678910111213141516171819202122232425262728#运行hello worldkubectl run hello-world --replicas=5 --labels=&quot;run=load-balancer-example&quot; --image=gcr.io/google-samples/node-hello:1.0 --port=8080#--image=docker.io/jocatalin/hellonode:v1#查看信息kubectl get deployments hello-worldkubectl describe deployments hello-worldkubectl get replicasetskubectl describe replicasets#创建展示部署的服务对象kubectl expose deployment hello-world --type=LoadBalancer --name=my-service#如果外部地址显示为pending，请等待几分钟#查看信息kubectl get services my-servicekubectl describe services my-service#可看到LoanBlancer Ingresskubectl get pods --output=wide#访问外部地址(LoadBalancer Ingress)curl http://&lt;external-ip&gt;:&lt;port&gt; 清理 123456#删除服务kubectl delete services my-service#删除正在运行的程序的Deployment，ReplicaSet，Podskubectl delete deployment hello-world 状态集应用程序StatefulSet Basics]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[性能分析]]></title>
    <url>%2F2018%2F05%2F14%2F%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[环境： CentOS7.x84_64 参考: strace命令: http://man.linuxde.net/strace pstack命令: http://man.linuxde.net/pstack lsof命令: http://man.linuxde.net/lsof 系统调用: https://zh.wikipedia.org/wiki/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8 Linux系统调用列表: https://www.ibm.com/developerworks/cn/linux/kernel/syscall/part1/appendix.html#8 高CPU分析: http://blog.51cto.com/yaocoder/1543352 系统调用系统调用(system call)，指运行在用户态的程序向操作系统内核请求需要更高权限运行的服务。系统调用提供用户程序与操作系统之间的接口。操作系统的进程空间可分为用户态和内核态，它们需要不同的执行权限。其中系统调用运行在内核态。 大多数系统交互式操作需求在内核态运行。如设备I/O或进程间通信。 内核态(kernel space)内核、核心扩充、驱动程序运行在内核空间上。 用户态(user space)其它的应用程序，则运行在用户空间上。所有运行在用户空间的应用程序，都被统称为用户级(userland)。 库函数系统调用和普通库函数调用非常相似，只是系统调用由操作系统内核提供，运行于内核核心态；而普通的库函数调用由函数库或用户自己提供，运行于用户态。 系统调用的意义 内核提供用户空间程序与内核空间进行交互的一套标准接口，这些接口让用户态程序能受限访问硬件设备，比如申请系统资源，操作设备读写，创建新进程等。用户空间发生请求，内核空间负责执行，这些接口便是用户空间和内核空间共同识别的桥梁，这里提到两个字“受限”，是由于为了保证内核稳定性，而不能让用户空间程序随意更改系统，必须是内核对外开放的且满足权限的程序才能调用相应接口。 在用户空间和内核空间之间，有一个叫做Syscall(系统调用, system call)的中间层，是连接用户态和内核态的桥梁。这样即提高了内核的安全型，也便于移植，只需实现同一套接口即可。Linux系统，用户空间通过向内核空间发出Syscall，产生软中断，从而让程序陷入内核态，执行相应的操作。对于每个系统调用都会有一个对应的系统调用号，比很多操作系统要少很多。 安全性与稳定性：内核驻留在受保护的地址空间，用户空间程序无法直接执行内核代码，也无法访问内核数据，通过系统调用 性能：Linux上下文切换时间很短，以及系统调用处理过程非常精简，内核优化得好，所以性能上往往比很多其他操作系统执行要好。 Linux系统调用方法 futexFutex 是fast userspace mutex的缩写，意思是快速用户空间互斥体。Linux内核把它们作为快速的用户空间的锁和信号量的预制构件提供给开发者。 selectselect系统调用允许程序同时在多个底层文件表述符上，等待输入的到达或输出的完成。 进程控制 函数 描述 fork 创建一个新进程 clone 按指定条件创建子进程 execve 运行可执行文件 exit 中止进程 _exit 立即中止当前进程 getdtablesize 进程所能打开的最大文件数 getpgid 获取指定进程组标识号 setpgid 设置指定进程组标志号 getpgrp 获取当前进程组标识号 setpgrp 设置当前进程组标志号 getpid 获取进程标识号 getppid 获取父进程标识号 getpriority 获取调度优先级 setpriority 设置调度优先级 modify_ldt 读写进程的本地描述表 nanosleep 使进程睡眠指定的时间 nice 改变分时进程的优先级 pause 挂起进程，等待信号 personality 设置进程运行域 prctl 对进程进行特定操作 ptrace 进程跟踪 sched_get_priority_max 取得静态优先级的上限 sched_get_priority_min 取得静态优先级的下限 sched_getparam 取得进程的调度参数 sched_getscheduler 取得指定进程的调度策略 sched_rr_get_interval 取得按RR算法调度的实时进程的时间片长度 sched_setparam 设置进程的调度参数 sched_setscheduler 设置指定进程的调度策略和参数 sched_yield 进程主动让出处理器,并将自己等候调度队列队尾 vfork 创建一个子进程，以供执行新程序，常与execve等同时使用 wait 等待子进程终止 wait3 参见wait waitpid 等待指定子进程终止 wait4 参见waitpid capget 获取进程权限 capset 设置进程权限 getsid 获取会晤标识号 setsid 设置会晤标识号 文件系统控制： 文件读写操作 fcntl 文件控制 open 打开文件 creat 创建新文件 close 关闭文件描述字 read 读文件 write 写文件 readv 从文件读入数据到缓冲数组中 writev 将缓冲数组里的数据写入文件 pread 对文件随机读 pwrite 对文件随机写 lseek 移动文件指针 _llseek 在64位地址空间里移动文件指针 dup 复制已打开的文件描述字 dup2 按指定条件复制文件描述字 flock 文件加/解锁 poll I/O多路转换 truncate 截断文件 ftruncate 参见truncate umask 设置文件权限掩码 fsync 把文件在内存中的部分写回磁盘 文件系统操作 access 确定文件的可存取性 chdir 改变当前工作目录 fchdir 参见chdir chmod 改变文件方式 fchmod 参见chmod chown 改变文件的属主或用户组 fchown 参见chown lchown 参见chown chroot 改变根目录 stat 取文件状态信息 lstat 参见stat fstat 参见stat statfs 取文件系统信息 fstatfs 参见statfs readdir 读取目录项 getdents 读取目录项 mkdir 创建目录 mknod 创建索引节点 rmdir 删除目录 rename 文件改名 link 创建链接 symlink 创建符号链接 unlink 删除链接 readlink 读符号链接的值 mount 安装文件系统 umount 卸下文件系统 ustat 取文件系统信息 utime 改变文件的访问修改时间 utimes 参见utime quotactl 控制磁盘配额 系统控制： ioctl I/O总控制函数 _sysctl 读/写系统参数 acct 启用或禁止进程记账 getrlimit 获取系统资源上限 setrlimit 设置系统资源上限 getrusage 获取系统资源使用情况 uselib 选择要使用的二进制函数库 ioperm 设置端口I/O权限 iopl 改变进程I/O权限级别 outb 低级端口操作 reboot 重新启动 swapon 打开交换文件和设备 swapoff 关闭交换文件和设备 bdflush 控制bdflush守护进程 sysfs 取核心支持的文件系统类型 sysinfo 取得系统信息 adjtimex 调整系统时钟 alarm 设置进程的闹钟 getitimer 获取计时器值 setitimer 设置计时器值 gettimeofday 取时间和时区 settimeofday 设置时间和时区 stime 设置系统日期和时间 time 取得系统时间 times 取进程运行时间 uname 获取当前UNIX系统的名称、版本和主机等信息 vhangup 挂起当前终端 nfsservctl 对NFS守护进程进行控制 vm86 进入模拟8086模式 create_module 创建可装载的模块项 delete_module 删除可装载的模块项 init_module 初始化模块 query_module 查询模块信息 *get_kernel_syms 取得核心符号,已被query_module代替 ioctl I/O总控制函数 _sysctl 读/写系统参数 acct 启用或禁止进程记账 getrlimit 获取系统资源上限 setrlimit 设置系统资源上限 getrusage 获取系统资源使用情况 uselib 选择要使用的二进制函数库 ioperm 设置端口I/O权限 iopl 改变进程I/O权限级别 outb 低级端口操作 reboot 重新启动 swapon 打开交换文件和设备 swapoff 关闭交换文件和设备 bdflush 控制bdflush守护进程 sysfs 取核心支持的文件系统类型 sysinfo 取得系统信息 adjtimex 调整系统时钟 alarm 设置进程的闹钟 getitimer 获取计时器值 setitimer 设置计时器值 gettimeofday 取时间和时区 settimeofday 设置时间和时区 stime 设置系统日期和时间 time 取得系统时间 times 取进程运行时间 uname 获取当前UNIX系统的名称、版本和主机等信息 vhangup 挂起当前终端 nfsservctl 对NFS守护进程进行控制 vm86 进入模拟8086模式 create_module 创建可装载的模块项 delete_module 删除可装载的模块项 init_module 初始化模块 query_module 查询模块信息 *get_kernel_syms 取得核心符号,已被query_module代替 内存管理： brk 改变数据段空间的分配 sbrk 参见brk mlock 内存页面加锁 munlock 内存页面解锁 mlockall 调用进程所有内存页面加锁 munlockall 调用进程所有内存页面解锁 mmap 映射虚拟内存页 munmap 去除内存页映射 mremap 重新映射虚拟内存地址 msync 将映射内存中的数据写回磁盘 mprotect 设置内存映像保护 getpagesize 获取页面大小 sync 将内存缓冲区数据写回硬盘 cacheflush 将指定缓冲区中的内容写回磁盘 网络管理： getdomainname 取域名 setdomainname 设置域名 gethostid 获取主机标识号 sethostid 设置主机标识号 gethostname 获取本主机名称 sethostname 设置主机名称 socket控制： socketcall socket系统调用 socket 建立socket bind 绑定socket到端口 connect 连接远程主机 accept 响应socket连接请求 send 通过socket发送信息 sendto 发送UDP信息 sendmsg 参见send recv 通过socket接收信息 recvfrom 接收UDP信息 recvmsg 参见recv listen 监听socket端口 select 对多路同步I/O进行轮询 shutdown 关闭socket上的连接 getsockname 取得本地socket名字 getpeername 获取通信对方的socket名字 getsockopt 取端口设置 setsockopt 设置端口参数 sendfile 在文件或端口间传输数据 socketpair 创建一对已联接的无名socket 用户管理： getuid 获取用户标识号 setuid 设置用户标志号 getgid 获取组标识号 setgid 设置组标志号 getegid 获取有效组标识号 setegid 设置有效组标识号 geteuid 获取有效用户标识号 seteuid 设置有效用户标识号 setregid 分别设置真实和有效的的组标识号 setreuid 分别设置真实和有效的用户标识号 getresgid 分别获取真实的,有效的和保存过的组标识号 setresgid 分别设置真实的,有效的和保存过的组标识号 getresuid 分别获取真实的,有效的和保存过的用户标识号 setresuid 分别设置真实的,有效的和保存过的用户标识号 setfsgid 设置文件系统检查时使用的组标识号 setfsuid 设置文件系统检查时使用的用户标识号 getgroups 获取后补组标志清单 setgroups 设置后补组标志清单 进程间通信： ipc, 进程间通信总控制调用 信号 sigaction 设置对指定信号的处理方法 sigprocmask 根据参数对信号集中的信号执行阻塞/解除阻塞等操作 sigpending 为指定的被阻塞信号设置队列 sigsuspend 挂起进程等待特定信号 signal 参见signal kill 向进程或进程组发信号 *sigblock 向被阻塞信号掩码中添加信号,已被sigprocmask代替 *siggetmask 取得现有阻塞信号掩码,已被sigprocmask代替 *sigsetmask 用给定信号掩码替换现有阻塞信号掩码,已被sigprocmask代替 *sigmask 将给定的信号转化为掩码,已被sigprocmask代替 *sigpause 作用同sigsuspend,已被sigsuspend代替 sigvec 为兼容BSD而设的信号处理函数,作用类似sigaction ssetmask ANSI-C的信号处理函数,作用类似sigaction 消息 msgctl 消息控制操作 msgget 获取消息队列 msgsnd 发消息 msgrcv 取消息 管道 pipe, 创建管道 信号量 shmctl 控制共享内存 shmget 获取共享内存 shmat 连接共享内存 shmdt 拆卸共享内存 共享内存 shmctl 控制共享内存 shmget 获取共享内存 shmat 连接共享内存 shmdt 拆卸共享内存 strace命令strace命令是一个集诊断、调试、统计与一体的工具，我们可以使用strace对应用的系统调用和信号传递的跟踪结果来对应用进行分析，以达到解决问题或者是了解应用工作过程的目的。当然strace与专业的调试工具比如说gdb之类的是没法相比的，因为它不是一个专业的调试器。 strace的最简单的用法就是执行一个指定的命令，在指定的命令结束之后它也就退出了。在命令执行的过程中，strace会记录和解析命令进程的所有系统调用以及这个进程所接收到的所有的信号值。 strace可跟踪一个命令或进程。 123strace - trace system calls and signalsstrace --help 问题案例当发现进程或服务异常时，我们可以通过strace来跟踪其系统调用，“看看它在干啥”，进而找到异常的原因。熟悉常用系统调用，能够更好地理解和使用strace。当然，万能的strace也不是真正的万能。当目标进程卡死在用户态时，strace就没有输出了。 定位进程异常退出 定位共享内存异常 性能分析 pstack命令pstack命令可显示每个进程(线程)的栈跟踪。 123yum install -y gdbpstack $PID lsof命令lsof命令用于查看你进程开打的文件，打开文件的进程，进程打开的端口(TCP、UDP)。 123456789101112-a：列出打开文件存在的进程-c&lt;进程名&gt;：列出指定进程所打开的文件-g：列出GID号进程详情-d&lt;文件号&gt;：列出占用该文件号的进程+d&lt;目录&gt;：列出目录下被打开的文件+D&lt;目录&gt;：递归列出目录下被打开的文件-n&lt;目录&gt;：列出使用NFS的文件-i&lt;条件&gt;：列出符合条件的进程（4、6、协议、:端口、 @ip ）-p&lt;进程号&gt;：列出指定进程号所打开的文件-u：列出UID号进程详情-h：显示帮助信息-v：显示版本信息 高CPU占用分析步骤： 查看进程 top 查看线程 top -H -p $pid 查看进程打开连接数 lsof -p ${pid} 追踪 strace -T -r -c -p $pid 栈 pstack $pid]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>系统调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python]]></title>
    <url>%2F2018%2F05%2F06%2FPython%2F</url>
    <content type="text"><![CDATA[环境: CentOS7x86_64 Python3.5 参考: Python教程: https://docs.python.org/3.5/tutorial/index.html Python词汇表: https://docs.python.org/3.5/glossary.html Python语言参考: https://docs.python.org/3.5/reference/index.html Python HOWTOs: https://docs.python.org/3.5/howto/index.html Python标准库: https://docs.python.org/3.5/library/ PyPI: https://pypi.org/ Awesome-Python https://github.com/vinta/awesome-python https://github.com/jobbole/awesome-python-cn 词汇表 &gt;&gt;&gt;交互式shell的默认Python提示符 ...在为缩进代码块输入代码时，或在一对匹配的左右分隔符中，交互式shell的默认Python提示符 2to3将Python2.x代码转换为Python3.x代码的工具 抽象基类(abstract base class) 参数(argument)调用函数时传递给(或方法)的值: 关键字参数/可选参数 异步上下文管理器(asynchronous context manager)控制在异步语句中看到的环境对象 异步生成器(asynchronous generator)返回一个生成器迭代器的函数 异步生成器迭代器(asynchronous generator iterator)由异步生成器创建的对象 异步可迭代(asynchronous iterable)一个对象 异步迭代器(asynchronous iterator)一个对象 属性(attribute)按名称引用的对象关联的值 awaitable一个对象 二进制文件(binary file)能读写bytes-like对象的文件对象 bytes-like对象支持Buffer Protocol并可以导出C-contiguous buffer的对象 字节码(bytecode)Python源代码被编译成字节码 类(class)用于创建用户对象的模板 coercion在涉及两个相同类型参数的操作中，将一个类型的实例隐式转换为另一个类型的实例 复数(complex number) 上下文管理器(context manager) contiguous 协程(coroutine) coroutine function CPythonPython语言的规范实现 修饰器(decorator)返回另一个函数的函数 描述(descriptor) 字典(dictionary) 字典视图(dictionary view)从dict.keys(), dict.values(), dict.items()返回的对象称为字典视图 文档字符串(docstring)在类，函数，或模块中的第一个表达式出现的字符串文字 duck-typing一种编程风格 表达式(expression) 扩展模块(extension module)由C/C++编写，通过Python API与核心和用户代码交互 f-string 文件对象(file object) finder为正在导入的模块查找加载程序的对象 地板除(floor division) 函数(function) 函数注释(function annotation) __future__可使用伪模块来启用与当前解释器不兼容的新语言功能 垃圾回收(garbage collection)不再使用时释放内存的过程 生成器(generator) generator iterator 生成器表达式(generator expression)返回迭代器的表达式 通用函数(generic function)由多个函数组成的函数 global interpreter lock确保一次只有一个线程执行Python字节码的机制 hashable如果一个对象具有在其生命周期内从不改变的hash值，并且可与其它对象相比，那么这个对象就是可hash的 IDLEPython的集成开发环境 一成不变的(immutable)具有固定值的对象 易变的(mutable)可改变它们值得对象 import path importing一个模块中的Python代码在另一个Python代码中可获取 importer既能找到又能加载模块的对象 交互式(interactive) 解释型(interpreted)Python是一种解释型语言，与编译型语言相反 interpreter shutdown 迭代(iterable)一次能够返回其成员的对象 迭代器(iterator)表示数据流的对象 关键函数(key function)关键函数或整理函数是一个可调用函数，它返回用于排序的值 关键字参数(keyword argument) lambda一个匿名内联函数，由调用该函数时评估的单个表达式组成 LBYL三思而后行(Look before you leap) 列表(list)一个内建Python序列 list comprehension一种紧凑的方式来处理序列中的全部或部分元素，并返回列表和结果 loader加载模块的对象 映射(mapping)支持任意键查找并实现映射中指定方法的容器对象 meta path finder metaclassThe class of a class 方法(method)类里面定义的函数 method resolution order 模块(module)Python代码的组织单元的对象 module spec named tuple 命名空间(namespace)变量存储的地方 namespace package仅用作子包的包 嵌套范围(nested scope)能够在封闭变量中引用变量 new-style class 对象(object)具有状态和定义行为的任一数据 包(package)可包含子模块或递归子模块的Python模块 参数(parameter)函数或方法定义中的一个命名实体，用于指定该函数可接受的参数。有5中参数: positional-or-keyword: positional-only keyword-only var-positional var-keyword path entry path entry finder path entry hook path based finder path-like object portion单目录中的一组文件 positional argument provisional API provisional package Python 3000Python3.x发行版的昵称 Python化(Pythonic)与Python语言最常见的习惯用法密切相关的想法或代码片段，而不是使用其它语言通用的概念来实现该代码 合格的名字(qualified name) 引用计数(reference count)对某个对象的引用次数 regular package __slots__类中的声明，通过预先声明实例属性的空间并消除实例字典来节省内存 序列(sequence) 单一调度(single dispatch)通用函数调度的一种形式 切片(slice)通常包含一部分序列的对象 special method一种由Python隐式调用的方法 声明(statement) struct sequence具有命名元素的元组 text encoding text file 三重引号(triple-quoted string) type 通用换行符(universal newlines)Unix: \n; Windows: \r\n 变量注释(variable annotation)与模块全局变量或类属性关联的类型元数据值 虚拟环境(virtual environment) 虚拟机(virtual machine) Zen of PythonPythono的设计原理和哲学 教程官网: https://www.python.org/ Python教程非正式地向读者介绍了Python语言和系统的基本概念和功能。Python是一种易于学习，功能强大的编程语言。它具有高效的高级数据结构以及面向对象(object-oriented)编程的简单而有效的方法。优雅的语法和动态类型以及其解释的特性，使其成为大多数平台上许多领域脚本编写(scripting)和快速应用程序开发的理想语言。Python解释器很容易用C或C++实现新功能和数据类型进行扩展。Python也适合作为定制程序的扩展语言。 本教程非正式地向读者介绍了Python语言和系统的基本概念和功能，不会涵盖每个功能。相反，它引入了许多Python最值得注意的功能和语言风格。 激起你的胃口Whetting Your Appetite 将一些工作自动化，或编写一个小程序。 C/C++/Java，编写/编译/测试/重编译周期太慢，但你又不想为你的应用程序开发和设计一门全新的语言。 这样的话，Python就是适合你的语言！ 为一些任务编写Unix shell script或Windows batch file，但它们只适合文本数据，而不适合GUI应用程序…你可以编写C/C++/Java程序，但需要很长的开发时间。Python简单易用，可帮助你更快完成工作。 Python为大型程序提供更多的结构和支持，它提供了更多的错误检查。作为一种非常高级的语言，它有内建的高级数据类型(如灵活的数组和字典)。由于其更通用的数据类型，Python适用于比awk甚至Perl更大的问题域，但Python中的许多事情至少与这些语言一样容易。 Python允许你将你的程序拆分成模块，使其它Python程序能重用。它附带了大量的标准模块，你可将它们作为学习Python编程的基础。包括了: 文件I/O；系统调用；socket；GUI… Python是一种解释型语言，在程序开发中节省大量时间，因为不需要编译和链接。 Python可以使程序紧凑而易读，由Python编写的程序通常比等效的C/C++/Java程序代码少得多。原因如下: 高级数据类型允许你在单个语句中表达复杂的操作 语句分组通过缩进(4个空格)来完成，而不是开始和结束 无需声明变量和参数 Python是可扩展的，如果你会C编程的话，很容易为解释器添加一个新的内置函数或模块，或将Python程序链接到可用库的二进制形式。也可将Python解释器链接到C编写的应用程序中。 顺便说一句，该语言是根据BBC节目Monty Python’s Flying Circus命名，与爬行动物无关。 学习语言的最好方法就是使用它，以工代练！ 解释器Python Interpreter My Linux: /usr/bin/python3 /lib64/python3.5/ 交互模式Interactive Mode 1234python3&gt;&gt;&gt;for i in range(4):... 参数传递Argument Passing 使用sys模块的argv变量给脚本传递参数。 12345678910111213141516171819import sysnum = len(sys.argv)if num != 3: print('Usage: xxx.py argv1 argv2')else: print('argu[0] is ' + sys.argv[0]) print('argu[1] is ' + sys.argv[1]) print('argu[2] is ' + sys.argv[2])chmod u+x xxx.py./argvPass.py 1 22argu[0] is ./argvPass.pyargu[1] is 1argu[2] is 22 编码格式Source Code Encoding 12#!/usr/bin/python3# -*- coding: utf-8 -*- 介绍An Informal Introduction to Python 注意Python的两个默认提示符: &gt;&gt;&gt; ... 作为计算器Using Python as a Calculator Numbers12345678910111213+ -*///(取商)%(取余)**intfloatdecimalfraction(分数)comlex number(复数) Strings123456789101112131415'(single quote)"(double quote)\(转义)r(元字符)'''"""+*indexstring[-1]string[0:2]len() Lists1234567891011list = [xx, x, ...]indexlist[index]list[start:stop]methodappend()pop()del()... 编程第一步First Steps Towards Programming 斐波那契数列(Fibonacci series) 1234567a, b = 0, 1while b &lt; 10: print(b, end=',') a, b = b, a+b #多重赋值(multiple assignment) #关键字参数(keyword argument) 控制流Control Flow Tools whilewhile Statements 123456a = input(int('Please input an int: '))whiel a &lt; 50: a += 1print(a) ifif Statements 1234567891011x = int(input("please input an int: "))if x &lt; 0: x = 0 print('Negative changed to zero')elif x == 0: print('Zero')elif x == 1: print('Single')else: print('More') forfor Statements 12345678910111213141516words = ['a', 'bb', 'ccc']for w in words: print(w, len(w))'''如果需要修改迭代中的序列，建议先制作副本，遍历一个序列并不会隐式地创建一个副本'''words = ['a', 22, 'ccc']for w in words[:]: if type(w) is int: words.insert(0, w)words[22, 'a', 22, 'ccc'] rangeThe range() Function遍历一系列数字 1234567891011121314for i in range(5): print(i)for i in range(0, 101, 10): print(i)a = [1, 22, 'A', 'AA']for i in range(len(a)) print(i, a[i])list(range(5))[0, 1, 2, 3, 4] 注意在许多方面，由range()返回的对象的行为就好像它是一个列表，但事实并非如此。它是一个对象，在你迭代时才返回所需序列，但它并不真正生成列表，从而节省空间。我们说这样一个对象是可迭代的(iterable)。 12print(range(10))range(0, 10) break/continuebreak and continue Statements, and else Clauses on Loops break 结束循环 continue 结束本次循环 passpass Statementspass语句什么也不做！当语句需要语法而程序不需要任何操作时，可使用它。 12345while True: passclass emptyClass: pass 函数定义Defining Functions关键字def引入一个函数定义，必须跟随函数名称和形式参数。函数主体语句必须缩进 函数主体的第一个语句是可选的字符串文字(sting literal)，用于描述函数。在编写的代码中包含文档字符串是一种很好的做法，请养成此习惯。 函数中的所有变量赋值都将值存储在本地符号表中，而变量引用首先在本地符号表中查找，然后是封闭函数的本地符号表，然后是全局符号表，最后是内置名称表。因此，全局变量不能直接在函数内赋值(除非是global语句)，尽管它们可能被引用。 事实上即使是没有return语句的函数也会返回一个值，它被称为None(一个内建名) 1234567891011121314151617def fib(n): """function's documentation print a Fibonacci series up to n. """ a, b = 0, 1 while a &lt; n: print(a, end=' ') a, b = b, a+b print()fib(100)f = fibf(100)print(fib())None 也可以使用可变数量的参数来定会函数。 默认参数值Default Argument Values 最有用的形式是为一个或多个参数指定默认值。 1234567891011def ask_ok(prompt, retries=4, reminder='Please try again!'): while True: ok = input(prompt) if ok in ('y', 'ye', 'yes'): return True if ok in ('n', 'no', 'nop', 'nope'): return False retries = retries - 1 if retries &lt; 0: raise ValueError('invalid user response') print(reminder) 函数可通过如下方法调用: 只给出必须的参数: ask_os(&#39;Prompt xxx&#39;) 给出可选参数: ask_ok(&#39;Prompt xx&#39;, 3) 给出所有参数: ask_ok(agr1, arg2, arg3) 关键字参数Keyword Arguments 也可使用kwarg = value来调用函数。 1234567891011121314def parrot(voltage, state='a stiff', action='voom', type='Norwegian Blue'): print("-- This parrot wouldn't", action, end=' ') print("if you put", voltage, "volts through it.") print("-- Lovely plumage, the", type) print("-- It's", state, "!")parrot(1000) # 1 positional argumentparrot(voltage=1000) # 1 keyword argumentparrot(voltage=1000000, action='VOOOOOM') # 2 keyword argumentsparrot(action='VOOOOOM', voltage=1000000) # 2 keyword argumentsparrot('a million', 'bereft of life', 'jump') # 3 positional argumentsparrot('a thousand', state='pushing up the daisies') # 1 positional, 1 keyword *name/**name**name，它接收一个字典(keyword=value)。可能与*name结合使用。*name必须出现在**name之前。 123456789101112131415161718192021222324def shop(kind, *arguments, **keywords): print("-- Do you have any ", kind, "?") print("-- I'm sorry, we're all out of ", kind) for arg in arguments: print(arg) print('\n-----\n') for kw in keywords: print(kw, ':', keywords[kw])shop('Kind', 'arg1', 'arg2', kw1='KW1', kw2='KW2', kw3='KW3')"""-- Do you have any Kind ?-- I'm sorry, we're all out of Kindarg1arg2-----kw3 : KW3kw1 : KW1kw2 : KW2""" 任意参数列表Arbitrary Argument Lists 最不经常使用的选项是指定可以用任意数量的参数调用一个函数，这些参数将被封装在一个元组中。 12345def arb(*args): for arg in args: print(arg)art(1, 22, 'CCC') 解包参数Unpacking Argument Lists 当参数已经在一个列表或元组中时，会出现相反的情况。需要对单独的位置参数的函数调用进行解包。 123456list(range(5))[0, 1, 2, 3, 4]args = [5]list(range(*args))[0, 1, 2, 3, 4] Lambda表达式可以使用lambda关键字创建小的匿名函数。Lambda函数可用于需要函数对象的任何地方，它在语法上受限于单个表达式。 123456789def lambdaTest(n): return lambda x: x + nf = lambdaTest(10)f(1)11f(5)15 文档字符串Documentation Strings 以下是关于文档字符串内容和格式的一些约定: 第一行应该始终是对象目的的简短摘要 第二行应该是空白，如果有多行的话 以下几行应该是描述 12345678910111213def func(): """Document it. This func just print one argument. """ print(sys.argv[1])print(func.__doc__)Document it. This func just print one argument. 函数注释Function Annotations 函数注释完全是关于用户定义函数使用的类型的可选元数据信息。 Annotations以字典的形式存储在函数的__annotations__属性中，并且不影响函数的其它部分。参数注释由参数名称后面的冒号:定义，后跟表达式评估注释的值。注释由参数列表和def语句结束的冒号之间的-&gt;定义，后跟一个表达式。 123456def f(name: str, age: int = 18) -&gt; str: print("Annotations: ", f.__annotations__) print("Arguments: ", name, age) return name + 'and' + str(age)f('Zhang21') 编码风格不同的语言有不同的编码风格。但是，让别人很轻松便能阅读你的代码总是一个好主意！ 对于Python而言，PEP(Python Enhanced Proposals) 8 已成为大多数项目遵循的风格指南。它促进了非常可读和令人喜爱的编码风格，每个Python开发者都应该阅读它。以下是最重要的几点： 使用4空格缩进，而不是tab 自动换行，不要超过79个字符 使用空白行来分割函数和类，以及函数内的更大快代码 如有可能，请将注释放在它们的上一行 使用文档字符串 在运算符和逗号后面使用空格，但不要直接在包围结构中使用空格 -&gt; (a + b) 一致地命名函数和类 建议使用UTF-8编码方式 建议不要在标识符中使用non-ASCII字符，如果有其它语言的人会去维护代码 数据结构Data Structures 列表More on Lists 列表数据类型有多种方法： list.append(x)添加一个项到列表的末尾 list.extend(iterable)通过添加迭代中的所有项来扩展列表 list.insert(i, x)在列表中给定位置插入一个项 list.remove(x)删除列表中给定值的第一项 list.pop()返回并删除列表中给定位置的项如果未指定index，则默认为最后一项 list.clear()删除列表中的所有项 list.index(x)返回指定值的第一个索引如果没有此值，返回ValueError list.count(x)返回列表中指定值出现的次数 list.sort()对列表中的项进行排序 list.reverse()反转列表中的元素 list.copy()返回列表的shallow copy 列表用处： Stack Queue 列表解析List Comprehensions 12345678910111213 #列表解析提供了一个简洁的方式来创建列表l = []for i in range(10): l.append(i**2) #lambdal = list(map(lambda i: i**2, range(10))) #orl = [x**2 for i in range(10)][(x, y) for x in [1, 2, 3] for y in [3, 2, 1] if x != y] 嵌套列表解析Nested List Comprehensions 列表解析中的初始表达式可以是任意表达式，包括另一个列表解析。 1234567l = [ [1, 2, 3, 4], [5, 6, 7, 8], [9, 10 ,11, 12]][[row[i] for row in l] for i in range(4)] del语句del语句可从列表中删除切片或整个列表。 123456789a = [1, 2, 3, 4]del a[0]del a[1:3]del a[:]del a 元组和序列Tuples and Sequences 列表和字符串由许多共同属性，如索引和切片操作。列表是可变的，它们的元素通常是同类，并且通过遍历列表可访问。 元组是不可变的！无法对元组项赋值，但可创建包含可变对象的元组。 1234567891011121314151617181920212223t = (123, 321, 'hello')tt = t, ('a', 'bb')(123, 321, 'hello), ('a', 'bb') #对元组赋值会出错t[0] = 888TypeError: 'tuple' object does not support item assignment #序列拆包(unpacking) #要求变量数量等于元素数量x, y, z = tx123y321z'hello' 集合Sets Python中的集合是没有重复元素的无序集合，并支持数学操作: 并集 a | b 交集 a &amp; b 差集 a - b 异或 a ^ b 使用大(花)括号{}或set()创建集合，但创建一个空集合使用set()，而不是{}——后者创建一个空字典。 集合也支持集合解析。 123456789101112131415161718192021alpha = &#123;'a', 'b', 'c', 'a'&#125;alpha&#123;'c', 'b', 'a'&#125;'c' in alphaTrue #数学运算a = set('abracadabra')b = set('alacazam')a | ba &amp; ba - ba ^ b #集合解析&#123;x for x in 'abcdefgabc' if x not in 'abc'&#125; 字典Dictionaries 字典数据类型在其它语言中被称为“associative memories” or “associative arrays”。与由数字索引的序列不同，字典由key索引(可以是任何不可变类型)，字符串和数字都可作为key。如果元组只包含字符串，数字或元组，则可作为key。若包含任何可变对象，则不能作为key。你不能使用列表作为key。 可将字典视为无序的键:值对，并要求键是唯一！花括号{}创建一个空字典。 字典的主要操作是用某个key存储value，并提取给定key的value。使用del语句删除一个键值对；新键值对会替换旧键值对。 1234567891011121314151617181920info = &#123;'name': 'AA', 'id': 1, 'tel': 155&#125;info['addr'] = 'Chengdu'infoinfo['name']del info['id']list(info.keys())print(info.values())print(info.items()) #dict()构造函数dict([('name', 'A'), ('age', 11)])dict(&#123;'name': 'A', 'age': 11&#125;)dict(name='zhang', age=11) #字典解析&#123;x: x**2 for x in (2, 4, 6)&#125; 循环技巧Looping Techniques 字典循环 123456info = &#123;'name': 'AA', 'age': 11&#125;for k, v in info.items(): print(k, v, sep=':')name:AAage:11 序列循环可使用enumerate()函数同时检索位置索引和相应值 123456for i, v in enumerate(['a', 'b', 'c']): print(i, v)0 a1 b2 c 同时循环多个序列要同时循环多个序列，可将这些条目与zip()函数配对 123456789aa = [1, 2, 3]bb = ['a', 'b', 'c']for a, b in zip(aa, bb): print('&#123;0&#125;, &#123;1&#125;'.format(a, b))1, a2, b3, c 反向循环序列 1234for i in reversed(range(6)): print(i, end=',')5,4,3,2,1,0, 循环排序 123456789101112131415161718l = ['ac', 'fb', 'nx', 'by']for i in sorted(l): print(i)acbyfbnxll = ['ac', 'fb', 'nx', 'by', 'ac', 'by']for i in sorted(set(ll)): print(i)acbyfbnx 关于条件More on Conditions while和if语句中使用的条件可以包含任何运算符，而不仅仅是比较。 比较操作符in和not in检查值是否在序列中操作符is和is not比较两个对象是否相同，这适用于可变对象(如list) 比较操作可以使用布尔运算符and和or进行组合，结果可用not。它们的优先级低于比较操作所有的比较操作符(comparison operators)具有相同的优先级，都低于数值运算符 模块Modules 如果你从Python解释器中退出并重新进入，你所做的定义(函数和变量)将会丢失。因此，如果编写一个稍长的程序，最好使用文本编辑器，然后将代码文件作文输入来运行它。这就被称为创建一个脚本。随着程序变长，可能需要将其分割为便于维护的多个文件。你可能还想使用你在多个程序中编写的某个功能(函数)，而不是将其定义复制到每个程序中。 为了支持此，Python有一种方法可将定义(definition)放入一个文件中，并在脚本或交互式实例中使用它们。这样的文件被称为模块(module)。来自模块的定义可以被导入到其它模块或主模块中。 模块是一个包含Python定义和语句的文件。文件名是带有.py的模块名。在模块中，模块的名称(string)用作全局变量__name__的值。 编写一个模块：vim /path/fibo.py 12345678910111213141516 #Fibonacci numbers moduledef fib(n): a, b = 0, 1 while b &lt; n: print(b, end=' , ') a, b = b, a+b print()def fib2(n): result = [] a, b = 0, 1 while b &lt; n: result.appen(b) a, b = b, a+b return result 载入此模块：如果没有将此模块放入Python默认lib目录(如/usr/lib64/python3.5/)的话，则需要进入模块所在目录打开Python解释器。 12345678910111213cd /pathpython3&gt;&gt;&gt; import fibo&gt;&gt;&gt; fibo.fb(100)1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89,&gt;&gt;&gt; fibo.fib2(100)[1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89]&gt;&gt;&gt; fibo.__name__'fibo'&gt;&gt;&gt; fibo.__str__()module 'fibo' from '/path/fibo.py' 更多模块信息More on Modules 一个模块可以包含可执行语句以及函数定义。这些语句旨在初始化模块，它们仅在import语句中第一次遇到模块名称时执行。 每个模块都有自己的私人符号表(private symbol table)，它被模块中定义的所有函数(functions)用作全局符号表(global symbol talbe)。因此，模块的作者可以在模块中使用全局变量(global variable)，而不用担心与用户的全局变量发生意外冲突。 模块可以导入其它模块。习惯上(但不是硬性要求)，将import语句放在模块(脚本)的开头。导入模块的名称被放置在导入模块的全局符号表中。 将模块名称直接导入到导入模块的符号表中，这不会在本地符号表中引入导入模块的名称 12 #fibo模块名并没有被定义from fibo import fib, fib2 导入模块中定义的所有名称在大多数情况下，Python程序员不会使用这个工具。因为它会向解释器引入一组未知的名称，可能会隐藏你已经定义的一些东西。注意，通常从模块或包中import *的做法是不被接受的，因为它经常会导致代码可读性很差。但是，可以使用它来保存交互式会话中的输入。 12 #这会导入除了以下划线开头的所有名称from fibo import * 将导入模块名称绑定到指定名称 123456789import fibo as fibfib.fib(100)fib.fib2(100)from fibo import fib2 as fibonaccifibonacci(100) 把模块作为脚本来执行Executing modules as scripts 如果你将模块中的__name__设置为__main__，模块中的代码就会被执行，就像导入它一样。这意味着你需要在你的模块的末尾添加它们。如果模块被导入，代码也不会执行。 这通常用于为模块提供用户接口，或测试。 123456if __name__ == "__main__": import sys fib(int(sys.argv[1]))python3 fibo.py &#123;args&#125; 模块的搜索路径The Module Search Path 当import fibo模块时，解释器首先在内建模块中搜索此名称。如果找不到，它会在sys.path给出的目录列表中搜索fibo.py文件。 sys.path从以下位置初始化： 包含输入脚本的目录(未指定文件时的当前目录) PYTHONPATH 依赖于安装的默认值 包含符号链接的目录不会被添加到模块的搜索路径中 编译的Python文件“Compiled” Python files 为了加速载入模块，Python将每个模块的编译版本缓存在名为module.version.pyc的__pycache__目录下，对编译文件的格式进行编码，它通常包含Python版本号。Python根据编译后的版本检查源代码的修改日期，看它是否过期并需要重新编译。这是一个完全自动的过程。另外，编译后的模块时独立于平台的，因此可以在不同体系结构的系统之间共享相同的库。 有两种情况，Python不会检查缓存： 总是重新编译并且不存储从命令行直接加载的模块的结果 没有源模块 专家提示： 可以Python命令中使用-0或-00来减少已编译模块的大小 读取.pyc文件不会比.py文件快，唯一更快的事情是它们被加载的速度 模块compileall可以为目录中的所有模块创建.pyc文件 更多细节，参见PEP 3147 标准模块Standard Modules Python提供了一个标准模块库。 一些模块被内置到解释器中，提供了对操作的访问。这些操作不属于语言核心的一部分，但是为了提高效率或提供对操作系统的访问权限。 12345678910111213141516import syssys.ps1'&gt;&gt;&gt;'sys.ps2'...'sys.ps1 = '&lt;&lt;&lt;'sys.ps1'&lt;&lt;&lt;' #查看PYTHONPATHsys.path.__str__ #添加PYTHONPATHsys.path.append('/home/zhang/venv/python') dir()函数内建函数dir()用于找出模块定义的名称。它列出所有类型的名称： 变量，模块，函数… 123456789101112131415import fibo, sysdir(fibo)['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'fib', 'fib2']dir(sys)['__displayhook__', '__doc__', '__excepthook__', '__interactivehook__', '__loader__', '__name__', '__package__', '__spec__', '__stderr__', '__stdin__', '__stdout__', '_clear_type_cache', '_current_frames', '_debugmallocstats', '_getframe', '_home', '_mercurial', '_xoptions', 'abiflags', 'api_version', 'argv', 'base_exec_prefix', 'base_prefix', 'builtin_module_names', 'byteorder', 'call_tracing', 'callstats', 'copyright', 'displayhook', 'dont_write_bytecode', 'exc_info', 'excepthook', 'exec_prefix', 'executable', 'exit', 'flags', 'float_info', 'float_repr_style', 'getallocatedblocks', 'getcheckinterval', 'getdefaultencoding', 'getdlopenflags', 'getfilesystemencoding', 'getprofile', 'getrecursionlimit', 'getrefcount', 'getsizeof', 'getswitchinterval', 'gettrace', 'hash_info', 'hexversion', 'implementation', 'int_info', 'intern', 'last_traceback', 'last_type', 'last_value', 'maxsize', 'maxunicode', 'meta_path', 'modules', 'path', 'path_hooks', 'path_importer_cache', 'platform', 'prefix', 'ps1', 'ps2', 'setcheckinterval', 'setdlopenflags', 'setprofile', 'setrecursionlimit', 'setswitchinterval', 'settrace', 'stderr', 'stdin', 'stdout', 'thread_info', 'version', 'version_info', 'warnoptions'] #它不会列出内建函数和变量的名称，除非如下操作import builtinsdir(builtins)['ArithmeticError', 'AssertionError', 'AttributeError', 'BaseException', 'BlockingIOError', 'BrokenPipeError', 'BufferError', 'BytesWarning', 'ChildProcessError', 'ConnectionAbortedError', 'ConnectionError', 'ConnectionRefusedError', 'ConnectionResetError', 'DeprecationWarning', 'EOFError', 'Ellipsis', 'EnvironmentError', 'Exception', 'False', 'FileExistsError', 'FileNotFoundError', 'FloatingPointError', 'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError', 'ImportWarning', 'IndentationError', 'IndexError', 'InterruptedError', 'IsADirectoryError', 'KeyError', 'KeyboardInterrupt', 'LookupError', 'MemoryError', 'NameError', 'None', 'NotADirectoryError', 'NotImplemented', 'NotImplementedError', 'OSError', 'OverflowError', 'PendingDeprecationWarning', 'PermissionError', 'ProcessLookupError', 'ReferenceError', 'ResourceWarning', 'RuntimeError', 'RuntimeWarning', 'StopIteration', 'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit', 'TabError', 'TimeoutError', 'True', 'TypeError', 'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning', 'ValueError', 'Warning', 'ZeroDivisionError', '_', '__build_class__', '__debug__', '__doc__', '__import__', '__loader__', '__name__', '__package__', '__spec__', 'abs', 'all', 'any', 'ascii', 'bin', 'bool', 'bytearray', 'bytes', 'callable', 'chr', 'classmethod', 'compile', 'complex', 'copyright', 'credits', 'delattr', 'dict', 'dir', 'divmod', 'enumerate', 'eval', 'exec', 'exit', 'filter', 'float', 'format', 'frozenset', 'getattr', 'globals', 'hasattr', 'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', 'issubclass', 'iter', 'len', 'license', 'list', 'locals', 'map', 'max', 'memoryview', 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow', 'print', 'property', 'quit', 'range', 'repr', 'reversed', 'round', 'set', 'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type', 'vars', 'zip'] 包Packages 包是通过”dotted(.) module names“，来构造Python模块命名空间的一种方式。 假设你想设计一个模块集(包)来统一处理声音文件和声音数据。有许多不同的声音文件格式。因此你需要创建和维护不断增长的模块集合，以便在各种文件格式之间进行转换。你还可能需要对声音数据执行各种不同的操作，因此你还需要编写无止境的模块流以执行这些操作。 这可能是一个包结构: 1234567891011121314151617181920212223sound/ Top-level package __init__.py Initialize the sound package formats/ Subpackage for file format conversions __init__.py wavread.py wavwrite.py aiffread.py aiffwrite.py auread.py auwrite.py ... effects/ Subpackage for sound effects __init__.py echo.py surround.py reverse.py ... filters/ Subpackage for filters __init__.py equalizer.py vocoder.py karaoke.py ... 当导入包时，Python将搜索sys.path，并查找包的子目录。需要__init__.py文件才能使Python将目录视为包含包。这是为了防止具有通用名称的目录(如字符串)无意中隐藏稍后在模块搜索路径中发生的有效模块。在最简单的情况下，__init__.py可以是一个空文件，但它也可以执行包的初始化代码。 导入包: from package import itemitem可以是子模块，子包，函数，类，变量import语句首先测试项目是否在包中定义。 如果不在，它假定它是一个模块并尝试加载它。如果找不到它，则会引发ImportError异常 import item.subitem.subsubitem相反，当使用这种语法时，除最后一项外必须都是一个包，最后一项可以是模块或包，但不能是类或函数或变量 123import sound.effects.echofrom sound.effects import echo importing * from a package当输入from sound.effects import *会发生什么？理想情况下，人们会希望以某种方式进入文件系统，查找包中存在哪些子模块，然后将它们全部导入。这可能需要很长时间，并且导入子模块可能具有不希望的副作用，这些副作用在明确导入子模块时才会发生。 唯一的解决方案是软件包作者提供包的明确索引。import使用以下声明: 如果某个包的__init__.py定义了一个名为__all__的列表，则它将成为from package import *时应该导入的模块名称列表。当软件包新版本发布时，软件包作者需要保持该列表是最新版本。 栗子sound/effects/__init__.py: 12 #这意味着from sound.effects import *只会导入以下子模块__all__ = [&quot;echo&quot;, &quot;surround&quot;, &quot;reverse&quot;] 如果__all__没有被定义，则from sound.effcts import *语句不会将包sound.effects中所有子模块导入到当前命名空间。它只能确保包sound.effects被导入，然后导入包中定义的任何名称。这包括__init__.py定义的任何名称，还包括由以前的导入语句显示加载的软件包的任何子模块。 请记住，使用from packagee import submodule没有任何问题。事实上，这也是推荐的方法。除非导入模块需要使用不同包中具有相同名称的子模块。 内部包装Intra-package References 当包被构建为子包时，可以使用绝对导入来引用邻包中的模块。同样，也可以使用相对导入来导入邻包中的模块。 12345678 #Absolutefrom sound.effects import echo #Relativefrom . import echofrom .. import formatsfrom ..filter import equalizer 多个目录中的包Packages in Multiple Directories 包还支持一个特殊的属性__path__。在执行该文件中的代码之前，它被初始化为一个包含__init__.py的目录名称的列表。这个变量可以修改，这样做会影响将对包中包含的模块和子包的搜索。 虽然此功能通常不是必需的，但它可用于扩展包中找到的一组模块。 输入和输出Input and Output有多种方式来呈现程序的输出；数据也可以打印成人类可读的形式，或写入文件供将来使用。 幻想的输出格式Fancier Output Formatting 到目前为止，我们知晓两种写入值的方法: 表达式语句 print()函数 有两种方法可以格式化输出： 自己完成所有的字符串处理(使用切片和连接操作，你可创建任何你能想到的布局) 格式化字符串文字或str.format()方法 string模块提供了一个Template类，它提供了另一种将值替换为字符串的方法。Python有办法将任何值转换为字符串：将它传递给repr()或str()函数。 str()函数，用于返回相当可读(human-readable)的值的表示repr()函数，用于生成可由解释器读取的表示对于没有人定义的特定表示的对象，str()将返回与repr()相同的值 1234567891011121314for x in range(1, 6): print(repr(x).rjust(2), repr(x**2).rjust(3), end=' ') print(repr(x**3).rjust(4)) #Orfor x in range(1, 6): print('&#123;0:2d&#125; &#123;1:3d&#125; &#123;2:4d&#125;'.format(x, x**2, x**3)) 1 1 1 2 4 8 3 9 27 4 16 64 5 25 125 字符串对象的str.rjust()方法，它在给定宽度的字段中通过填充左边的空格来右对齐字符串。类似方法还有: str.ljust(), str.center()。这些方法不写入任何东西，它们只是返回一个新的字符串。 还有一种str.zfill()方法，它在数字字符串的左边填充数字0，它能识别加号和减号： 12345678&gt;&gt;&gt; '12'.zfill(5)'00012'&gt;&gt;&gt;&gt;&gt;&gt; '-3.14'.zfill(7)'-003.14'&gt;&gt;&gt;&gt;&gt;&gt; '3.1415678'.zfill(5)'3.1415678' str.format()方法: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152 #&#123;&#125;print('We are &#123;&#125; who say &#123;&#125; is "&#123;&#125;!".format('A', 'BB', 'WONDERFUL'))We are A who say BB is "WONDERFUL!" #括号中的数字用来指向传入的位置 #&#123;index&#125;,从0开始print('&#123;0&#125; and &#123;1&#125;'.format('A', 'BB'))A and BBprint('&#123;1&#125; and &#123;0&#125;'.format('A', 'BB'))BB and A #关键字参数print('My name is &#123;name&#125;, I\'m &#123;age&#125; years old!'.format(name='Zhang21', age=21))My name is Zhang21, I'm 21 years old! #位置参数和关键字参数的组合print('The story of &#123;0&#125;, &#123;1&#125;, and &#123;other&#125;'.format('A', 'BB', other='CCC'))The story of A, BB, and CCC'''!a, 应用ascii()!s, 应用str()!r, 应用repr():, 更好的控制格式:5:7d:.3f'''print('My full name is &#123;!s&#125;'.format('Zhang21'))My full name is Zhang21print('My full name is &#123;!r&#125;'.format('Zhang21'))My full name is 'Zhang21'print('The value of &#123;&#125; is approximately &#123;:.3f&#125;'.format('PI', 3.141567))The value of PI is approximately 3.142info = &#123;'A': 68, 'BB': 79, 'CCC': 89&#125;for k, v in info.items(): print('&#123;0:5&#125; ==&gt; &#123;1:6d&#125;'.format(k, v))A ==&gt; 68BB ==&gt; 79CCC ==&gt; 89print('A: &#123;A:d&#125;; B: &#123;BB:d&#125;, C: &#123;CCC:d&#125;'.format(**info))A: 68; B: 79, C: 89 %操作符同样可用于字符格式化: 12print('The value of %s is approximately %5.3f' % ('PI', 3.1415678))The value of PI is approximately 3.142 读写文件Reading and Writing Files open()返回一个文件对象，它最常用的两个参数：open(filename, mode) 12345678910f = open('/tmp/1.txt, 'r')f.readline()'1\n'f.closedFaslef.close()f.closedTrue mode: r: read only，未指定模式时的默认模式 w: only writing a: appending r+: reading and writing b: binary mode 通常情况下，文件以文本模式打开，这意味着你可读写文件中的字符串，并以特定编码方式进行编码(如UTF-8)。如果未指定编码，则默认值取决于平台。b以二进制模式打开文件，数据以字节对象的形式读写，该模式应该用于所有不包含文本的文件。在读写文件时要非常小心的使用二进制模式。 推荐使用with关键字处理文件对象，优点是，即使在某个时间点出现异常，文件在其套件结束后也能正常关闭。也比try-finally块短得多。如果没有使用with关键字，则你需要调用f.close()来关闭文件，并立即释放它使用的系统资源。如果你没有明确关闭一个文件，Python的垃圾回收器最终会摧毁这个对象并为你关闭吧这个打开的文件，但这个文件可能会保持打开一段时间。在关闭文件对象之后，尝试使用文件对象将会自动失败。 1234567891011with open('/tmp/1.txt') as f: read_Data = f.read()f.closedTruef.read()Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;ValueError: I/O operation on closed file. 文件对象方法Methods of File Objects f.read(size)读取文件内容，以字符串或字节对象的形式返回。size是一个可选的数值参数，当size被忽略或为负数时，文件的全部内容被读取并返回。如果超过内存限制，那就是你的问题了。f.readline()从文件读取一行，换行符Unix\n，Windows\r\nf.readlines(), list(f)读取文件的所有行f.write(string)向文件中写入字符内容，并返回写入的字符数f.tell()返回一个整数，表示二进制模式下文件开头的字节数f.seek(offset, from_what)改变文件对象的位置 1234567891011121314151617f = open('/tmp/1.txt', 'r+')f.write('Line4\n')6string = ('AAA', 11)s = str(string)f.write(s)11f = open('/tmp/1.txt', 'rb+')f.write(b'0123456789abcde')f.seek(1)1f.read(1)b'1' 使用json保存结构化数据Saving structured data with json 字符串可以很容易地读写文件和从文件读取。当你想要保存更复杂的数据类型——如嵌套列表和字典，手动解析和序列化将变得很复杂。 JSON格式通常被现代应用程序用于数据交换。Python允许你使用名为JSON的流行数据交换格式。称为json的标准模块可采用Python数据层次结构，并将其转换为字符串表示形式，这个过程被称为序列化(serializing)。重建字符串表示中的数据称为反序列化(deserializing)。 123456import jsonjson.dumps([1, 'simple', 'list'])'[1, "simple", "list"]'json.dump(x, f)x = json.load(f) 错误和异常Errors and Exceptions 至少有两种可区分的错误: syntax errors exceptions 语法错误Syntax Errors语法错误，也称为解析错误。这是最常见的语法问题错误。 异常Exceptions即使语法是正确的，但在执行时也可能导致错误。执行过程中检查到的错误称为异常。Built-in Exceptions列出了内置的异常及其含义。 1234567891011121314 &gt;&gt;&gt; 10 * (1/0)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;ZeroDivisionError: division by zero &gt;&gt;&gt; 4 + spam*3Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;NameError: name 'spam' is not defined &gt;&gt;&gt; '2' + 2Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: Can't convert 'int' object to str implicitly 处理异常Handling Exceptions编写处理选定异常的程序是可能的。 1234567891011while True: try: x = int(input("Please enter a number: ")) break except ValueError: print("Oops! That was no valid number. Try again...") #多个异常放入一个元组except (RuntimeError, TypeError, NameError): pass try语句工作原理： 首先，try子句(try...except之间的语句)被执行 如果没有异常发生，则执行try语句并跳过except子句后便结束 如果在执行try子句时发生异常，则跳过子句的其余部分。然后，如果异常类型匹配execpt后面的异常名称，则except子句被执行，然后在try语句后继续执行 如果产生的异常与except的异常名称不匹配，它将传递给外部try语句。如果没有找到处理程序，则它是一个未处理的异常，执行停止并显示错误消息 try语句可能有多个except子句，用于处理不同的异常。最多只有一个处理程序被执行 处理程序只处理发生在相应try子句中的异常，而不处理相同try语句的其它处理程序 except子句可将多个异常名放入一个元组 如果是相同的类或其基类，则except子句中的类与异常兼容 未使用异常名称的except子句作为通配符 请谨慎使用此功能，因为以这种方式很容易掩盖真正的编程错误 try...except语句还有一个可选的else子句。当存在时，它必须遵循所有except子句。如果try子句不引发异常，则必须执行该代码 12345678910111213import systry: f = open('/tmp/1.txt') s = f.readline() i = int(s.strip())except OSError as err: print('OS error: &#123;&#125;'.format(err))except ValueError: print("Could not convert data to an integer.")except: print("Unexpected erros", sys.exc_info()[0]) raise 123456try: sum = 'a' + 1except TypeError: print('TypeError')else: print('else: ', sum) 引发异常Raising Exceptions raise语句允许程序员强制执行指定的异常。 1234567891011121314151617&gt;&gt;&gt; raise NameError('HiThere')Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;NameError: HiThere&gt;&gt;&gt; try:... raise NameError('HiThere')... except NameError:... print('An exception flew by!')... raise...An exception flew by!Traceback (most recent call last): File "&lt;stdin&gt;", line 2, in &lt;module&gt;NameError: HiThere 用户定义的异常User-defined Exceptions 程序可以通过创建一个新的异常类(exception class)来为自己的异常命名。异常通常应该直接或间接地从 Exception class 派生。 可以定义异常类，它可以执行任何其它类可以执行的任何操作，但通常很简单，通常只提供一些属性，以便处理程序为异常提取有关错误的信息。创建可引发多个不同错误的模块时，通常的做法是为该模块定义的异常创建基类，并创建用于为不同错误条件创建特定异常类的子类: 123456789101112131415161718192021222324252627282930class Error(Exception): """Base class for exceptions in this module.""" passclass InputError(Error): """Exception raised for errors in the input. Attributes: expression -- input expression in which the error occurred message -- explanation of the error """ def __init__(self, expression, message): self.expression = expression self.message = messageclass TransitionError(Error): """Raised when an operation attempts a state transition that's not allowed. Attributes: previous -- state at beginning of transition next -- attempted new state message -- explanation of why the specific transition is not allowed """ def __init__(self, previous, next, message): self.previous = previous self.next = next self.message = message 大多数异常的名称都以Error结尾来定义，类似于标准异常的命名。许多标准模块定义了它们自己的异常，用于在其定义的功能中可能发生的错误。 定义清理行为Defining Clean-up Actions try语句还有一个可选的子句，用于定义在任何情况下都必须执行的清理操作(clean-up actions). finally子句总是在离开try语句之前执行，无论是否发生异常。 123456789&gt;&gt;&gt; try:... raise KeyboardInterrupt... finally:... print('Goodbye, world!')...Goodbye, world!KeyboardInterruptTraceback (most recent call last): File "&lt;stdin&gt;", line 2, in &lt;module&gt; 预定义的清理操作Predefined Clean-up Actions 某些对象定义了在不再需要对象是要执行的标准清楚操作，而不管使用对象的操作是成功还是失败。 123with open("myfile.txt") as f: for line in f: print(line, end="") 类Classes 类提供了将数据和功能捆绑在一起的手段。每个类实例都可附加属性以保持其状态。类实例也可以有方法来修改其状态。 与其它编程语言相比，Python的类机制为其添加了最少量的新语法和语义。Python类 提供了面向对象编程的所有标准功能: 类继承机制(inheritance mechanism)允许多个基类(base class)，派生类(derived class)可以重写其基类或类的任何方法，并且方法(method)可以调用具有相同名称的基类的方法。对象(object)可以包含任意数量和种类的数据。与模块一样，类也具有Python的动态特性: 它们是在运行时创建的，并且可以在创建后进一步修改。 关于名称和对象A Word About Names and Objects Objects have individuality, 并且可以将多个名称(在多作用域中)绑定到同一个对象。这在其它语言中被称为别名。别名在不可变类型中被安全地忽略。但对涉及可变对象(dict, list…)的Python代码的语义可能会有惊人的影响。这通常有利于程序，因为别名在某些方面表现得像指针。 作用域和命名空间Python Scopes and Namespaces 类定义在命名空间中扮演一些巧妙的技巧，并且你需要知道作用域和命名空间如何工作才能完全理解正在发生的事情。顺便一提，有关此主题的知识对于任何高级Python程序员都很有用。 让我们从一些定义开始: 命名空间是名称到对象的映射。大多数命名空间目前都是作为Python字典实现的，但通常不会以任何方式显示。命名空间的例子： 内建名称的集合；模块中的全局名称；函数调用中的本地名称。从某种意义上说，对象的一组属性也构成一个命名空间。了解命名空间的重要之处在于，不同命名空间中的名称之间没有绝对的关系。 顺便一提，使用单词属性来表示任意一个点.后面的名称——z.real，real是对象z的属性。严格地说，对模块中的名称引用是属性引用——modname.funcname，modname是一个模块对象，并且funcname是它的一个属性。在这种情况下，模块的属性和模块中定义的全局名称之间会有一个直接的映射关系: 它们共享相同的命名空间。 属性可以是只读或可写。 命名空间是在不同的时刻创建的，并且具有不同的生命周期。包含内建名称的命名空间是在Python解释器启动时创建的，并且永远不会被删除。读取模块定义时创建模块的全局命名空间，通常，模块命名空间也会持续到解释器退出。由解释器的顶层调用执行的语句，无论是从脚本文件读取还是交互式读取，都被视为名为__main__模块的一部分，因此它们具有其自己的全局命名空间。 函数的本地命名空间是在调用函数时创建，并在函数返回时删除或引发(raise)不在函数内处理的异常。当然，递归调用每个都有自己的本地命名空间。 作用域(scope)是Python程序的文本区域，可以直接访问命名空间(namespace)。这意味着对名称的非限定引用(unqualified reference)会尝试在命名空间中查找名称。 尽管作用域是静态确定的，但它们是动态使用的。在执行期间的任何时候，至少有三个作用域的命名空间都可以直接访问: 最先搜索的最内层作用域，包含本地名称 从最近封闭作用域开始搜索的任何封闭函数的作用域，包含非本地名称，也包含非全局名称 倒数第二个作用域包含当前模块的全局名称 最外层的作用域是包含内建名称的命名空间 如果某个名称被声明为全局(global)，则所有的引用(reference)和赋值(assignment)都将直接转到包含模块全局名称的中间作用域。要重新绑定(rebind)最内层作用域外发现的变量，可以使用nonlocal语句；如果没有声明nonlocal，那些变量是只读的。 通常，本地作用域引用当前函数的本地名称。在外部函数中，本地作用域引用与全局作用域相同的命名空间:模块的命名空间。类定义在本地作用域中放置另一个命名空间。 认识到作用域是以文本方式确定是很重要的: 模块中定义的函数的全局作用域是该模块的命名空间，无论从何处调用函数或调用函数的别名。另一方面，名称的实际搜索是在运行时动态完成的——但是，在编译时间，语言定义正在向静态名称解析发展，因此不要依赖动态名称解析。 Python的特殊之处在于——如果global语句没有生效，对名称的赋值总是进入最内层的范围。赋值不会分配数据——它们只是将名称绑定到对象。删除操作也是如此: 语句del x从本地作用域引用的命名空间中删除x的绑定。实际上，所有引用新名称的操作都是用本地作用域: 特别是，import语句和函数定义将模块或函数名称绑定到本地作用域。 global声明可以用来表明特定变量存在于全局作用域内，应该在此rebound(反弹)。nonlocal声明表明特定变量存在于封闭作用域内，应该在那里rebound. 作用域和命名空间的栗子 123456789101112131415161718192021222324252627282930313233def scope_test(): def do_local(): spam = "local spam" def do_nonlocal(): nonlocal spam spam = "nonlocal spam" def do_global(): global spam spam = "global spam" spam = "test spam" do_local() print("After local assignment: ", spam) do_nonlocal() print("After nonlocal assignment: ", spam) do_global() print("After global assignment: ", spam)scope_test()print("In global scope: ", spam)#输出After local assignment: test spamAfter nonlocal assignment: nonlocal spamAfter global assignment: nonlocal spamIn global scope: global spam 首先看类A first look at class 类引入了一些新的语法，三种新的对象类型和一些新的语义。 类定义语法Class Definition Syntax 类定义，像函数定义，必须在它们有效之前被执行。 123456class ClassName: &lt;statement-1&gt; . . . &lt;statement-N&gt; 实际上，类定义中的语句通常是函数定义，但其他语句是允许的，有时也是有用的。类中的函数定义通常有一个特殊形式的参数列表，由方法的调用约定决定。 当输入一个类定义时，会创建一个新的命名空间，并将其用作本地作用域——因此，所有对局部变量的赋值都会进入这个新的命名空间。特别是，函数定义在此绑定新函数的名称。 当类定义保持正常时，会创建一个类对象。这基本上是由类定义创建的命名空间的内容的一个包装。最初的本地作用域被恢复，并且类对象在这里被绑定到类定义头中给出的类名。 类对象Class Objects 类对象支持两种操作: 属性引用(attribute reference)和实例化(instantiation). 属性引用使用 用于Python中所有属性引用的标准语法: obj.name. 有效的属性名称在创建类对象时时位于类命名空间中的所有名称。 123456class MyClass: """A simple example class""" i = 12345 def f(self): return 'hello world' MyClass.i和MyClass.f是有效的属性引用，分别返回一个整数和函数对象。类属性也可以被分配，所以也可以通过赋值来改变MyClass.i的值。__doc__也是一个有效的属性，返回该类的文档字符串”A simple example class”. 类实例化使用函数表示法。假设类对象是一个返回类的新实例的无参数函数。 12#创建类的新实例，并将该对象分配给局部变量xx = MyClass() 实例化操作(“调用”一个类对象)创建一个空对象。许多类喜欢创建具有定制(customized)到特定初始状态(initial state)的实例对象。因此，类可以定义一个名为__init__()的特殊方法。 12def __init__(self): self.data = [] 当一个类定义了一个__init__()方法时，类实例化会自动为新创建的类实例调用__init__(). 当然，__init__()方法可能有更多灵活的参数。在这种情况下，给类实例化操作符的参数被传递给__init__(). 123456789class Complex: def __init__(self, realpart, imagpart): self.r = realpart self.i = imagpartx = Complex(3.0, -4.5)x.r, x.i3.0, -4.5 实例对象Instance Objects 实例对象理解的唯一操作是属性引用。有两种有效的属性名称，数据属性和方法。 数据属性不需要声明，像局部变量一样，当它们在第一次分配时就会弹出。另一种实力属性引用是一种方法。方法是属于对象的函数。 实例对象的有效方法名称取决于它的类。根据定义，作为函数对象的类的所有属性都定义其实例的相应方法。 方法对象Method Objects 关于方法的特殊之处在于 实例对象作为函数的第一个参数传递。一般来说，调用带有n个参数列表的方法相当于使用通过在第一个参数之前插入方法实例对象创建的参数列表来调用相应的函数。 当引用不是数据属性的实例属性时，将搜索类。如果名称表示一个有效的类属性，它是一个函数对象，则通过打包实例对象和在抽象对象中一起找到的函数对象来创建方法对象，这就是方法对象。当使用参数列表调用方法对象时，会从实例对象和参数列表构造一个新参数列表，并使用此新参数列表调用函数对象。 类变量和实例变量Class and Instance Variables 一般来说，实例变量是针对每个实例唯一的数据，而类变量是针对类的所有实例共享的属性和方法。 1234567891011121314151617class Dog: kind = 'canine' # class variable shared by all instances def __init__(self, name): self.name = name # instance variable unique to each instance&gt;&gt;&gt; d = Dog('Fido')&gt;&gt;&gt; e = Dog('Buddy')&gt;&gt;&gt; d.kind # shared by all dogs'canine'&gt;&gt;&gt; e.kind # shared by all dogs'canine'&gt;&gt;&gt; d.name # unique to d'Fido'&gt;&gt;&gt; e.name # unique to e'Buddy' 共享数据可能会带来令人惊讶的影响，涉及列表和字典等可变对象: 1234567891011121314151617class Dog: tricks = [] # mistaken use of a class variable def __init__(self, name): self.name = name def add_trick(self, trick): self.tricks.append(trick)&gt;&gt;&gt; d = Dog('Fido')&gt;&gt;&gt; e = Dog('Buddy')&gt;&gt;&gt; d.add_trick('roll over')&gt;&gt;&gt; e.add_trick('play dead')&gt;&gt;&gt; d.tricks # unexpectedly shared by all dogs['roll over', 'play dead'] 正确的类设计应该使用实例变量: 1234567891011121314151617class Dog: def __init__(self, name): self.name = name self.tricks = [] # creates a new empty list for each dog def add_trick(self, trick): self.tricks.append(trick)&gt;&gt;&gt; d = Dog('Fido')&gt;&gt;&gt; e = Dog('Buddy')&gt;&gt;&gt; d.add_trick('roll over')&gt;&gt;&gt; e.add_trick('play dead')&gt;&gt;&gt; d.tricks['roll over']&gt;&gt;&gt; e.tricks['play dead'] 随机备注Random Remarks 数据属性覆盖具有相同名称的方法属性；为了避免意外的名称冲突，这可能会在大型程序中导致难以发现的错误，使用某种最小化冲突几率的约定是明智的。可能的约定(convention)包括: 大写的方法名称，小唯一字符串(可能只是下划线)为数据属性名称加前缀，或者为方法和名词使用动词来表示数据属性。 数据属性可由方法及对象的普通用户引用。换句话说，累不可用于实现纯粹的抽象数据类型。事实上，Python中没有任何东西可以强制执行数据隐藏——它都基于约定。 客户端应该小心使用数据属性。请注意，客户端可以将自己的数据属性添加到实例对象，而不会影响方法的有效性，只要避免名称冲突——再次注意，命名约定可在此节省大量令人头痛的问题。 从方法中引用数据类型没有简写，这增加了方法的可读性: 在浏览方法时，不会混淆局部变量和实例变量。 通常，方法的第一个参数称为self。这只不过是一个约定: 名字self对Python来说绝对没有特殊含义。但是，请注意，不遵循约定的Python代码对于Python程序员来说可能不易读取。 任何作为类属性的函数对象都为该类的实例定义了一个方法 1234567891011121314# Function defined outside the classdef f1(self, x, y): return min(x, x+y)class C: f = f1 def g(self): return 'hello world' h = g#f, g, h都是类C的所有属性，它们都是指向函数对象的，因此它们都是C实例的所有方法。 方法可以通过使用self参数的方法属性来调用其它方法: 12345678910class Bag: def __init__(self): self.data = [] def add(self, x): self.data.append(x) def addtwice(self, x): self.add(x) self.add(x) 方法可以像普通函数一样引用全局名称。与方法关联的全局作用域是包含其定义的模块。(一个类永远不会被用作全局作用域) 虽然很少有人在方法中使用全局数据，但全局作用域有许多合法用途: 首先，导入全局作用域的函数和模块可以被方法使用，以及在其中定义的函数和类。通常，包含该方法的类本身是在全局作用域内定义的。 每个值都是一个对象，因此有一个类(类型)。它被存储为object.__class__ 继承Inheritance 当然，如果不支持继承，语言特性就不值得称为”类”。 1234567#派生(derived)class DerivedClassName(BaseClassName): &lt;statement-1&gt; . . . &lt;statement-N&gt; 基类(BaseClassName)必须在包含派生类(derived class)定义的作用域中定义。代替基类名称，其它表达式也是允许的。 12#当基类在另一个模块中被定义class DerivedClassName(modname.BaseClassName): 派生类(derived class)定义的执行过程与基类(base class)相同。当构造(constructed)类对象时，基类将被记住。这用于解析属性引用: 如果在类中未找到请求的属性，则搜索继续查找基类。如果基类本身是从其它类派生的，则此规则将递归应用。 派生类的实例化么有什么特别的: DerivedXlassName()创建一个新的类实例。方法解析如下: 如果需要，搜索相应的类属性，沿着基类链降序排列，如果产生函数对象，则方法引用是有效的。 派生类可以覆盖(override)基类的方法。由于方法在调用同一对象的其它方法时没有特殊的权限，因此调用另一个在同一基类中定义的方法的基类方法可能最终会调用派生类的方法来覆盖它。 派生类的覆盖(override)方法事实上可能需要扩展而不是简单地替换同名的基类方法。有一种简单的方法可以直接调用基类方法: 只需调用BaseClassName.methodname(self, arguments)即可。 Python有两个与继承有关的内建函数: isinstance()检查一个实例的类型。isinstance(obj, int)只有在obj.__class__是int或从int派生的某个类时才为true issubclass()检查类继承。 多重继承Multiple Inheritance Python支持多重继承的形式。 123456class DerivedClassName(Base1, Base2, Base3): &lt;statement-1&gt; . . . &lt;statement-N&gt; 在最简单的情况下，你可以将从父类继承的属性视为深度优先(depth first)，从左到右搜索，而不是在同一个类中进行两次搜索，其中层次结构中存在重叠。因此，如果在DerivedClassName中找不到属性，则在Base1中搜索该属性，然后(递归)在Base1的基类中搜索该属性。如果未找到，则在Base2中搜索该属性，依此类推。 动态排序是必要的，因为多重继承的情况都表现出一个或多个菱形关系。例如，所有类都从对象继承，所以任何多重继承的情况都会提供多条路径来达到对象。为了避免基类被多次访问，动态算法使搜索顺序线性化，以保留没各类众指定的从左到右的顺序，每个父类只调用一次，这是单调的。 私有变量Private Variables Python中不存在私有(private)实例变量，这些变量除了在对象内部以外不能访问。不过，大多数Python代码都有一个约定，以下划线_spam为前缀的名称应被视为API的非公共部分(无论是函数，方法或数据成员)。 由于私有类(class-private)成员有一个有效的用例(即为了避免名称与由子类定义的名称的冲突)，所以对这种称为name mangling的机制的支持有限。任何__spam形式的标识符在文本上用_classname__spam替换，其中classname是当前类名称，前导下划线被去除。只要它在类的定义类发生，就不会考虑标识符位置。 Name mangling 有助于让子类重写方法而不会破坏intraclass方法调用: 123456789101112131415161718class Mapping: def __init__(self, iterable): self.items_list = [] self.__update(iterable) def update(self, iterable): for item in iterable: self.items_list.append(item) __update = update # private copy of original update() methodclass MappingSubclass(Mapping): def update(self, keys, values): # provides new signature for update() # but does not break __init__() for item in zip(keys, values): self.items_list.append(item) 请注意，强化规则的设计主要是为了避免事故；它仍然可以访问或修改被认为是私有的变量。注意传递给exec()或eval()的代码并不认为调用类的类名是当前类；这与global语句的效果类似，其效果同样局限于一起进行字节编译的代码。getattr(), setattr()和delattr()以及直接使用__dict__时也有相同的限制。 Odds and Ends123456789class Employee: passjohn = Employee() # Create an empty employee record# Fill the fields of the recordjohn.name = 'John Doe'john.dept = 'computer lab'john.salary = 1000 一段期望特定抽象数据类型的Python代码通常通常可以传递一个模拟该数据类型方法的类。例如，如果你有一个函数可以格式化文件对象中的某些数据，则可以使用方法read()和readline()来定义一个类，以便从字符串缓冲区总获取数据，然后将其作为参数传递。 迭代器Iterators 你可能注意到大多数容器对象可以使用for语句循环遍历: 12345678910for element in [1, 2, 3]: print(element)for element in (1, 2, 3): print(element)for key in &#123;'one':1, 'two':2&#125;: print(key)for char in "123": print(char)for line in open("myfile.txt"): print(line, end='') 这种访问方式清晰，简洁，方便。迭代器的使用贯穿并统一了Python。for语句在容器对象上调用iter()。该函数返回一个迭代器对象，该对象定义一次访问容器中元素的方法__next__()。当没有更多元素是，__next__()引发一个StopIteration异常，它告诉for循环终止。你可使用next()内置函数调用__next__()方法: 123456789101112131415&gt;&gt;&gt; s = 'abc'&gt;&gt;&gt; it = iter(s)&gt;&gt;&gt; it&lt;iterator object at 0x00A1DB50&gt;&gt;&gt;&gt; next(it)'a'&gt;&gt;&gt; next(it)'b'&gt;&gt;&gt; next(it)'c'&gt;&gt;&gt; next(it)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; next(it)StopIteration 看到了迭代器协议背后的机制，很容易将迭代器行为添加到类中。定义一个__iter__()方法，该方法使用__next__()方法返回一个对象。 1234567891011121314class Reverse: """Iterator for looping over a sequence backwards.""" def __init__(self, data): self.data = data self.index = len(data) def __iter__(self): return self def __next__(self): if self.index == 0: raise StopIteration self.index = self.index - 1 return self.data[self.index] 12345678910&gt;&gt;&gt; rev = Reverse('spam')&gt;&gt;&gt; iter(rev)&lt;__main__.Reverse object at 0x00A1DB50&gt;&gt;&gt;&gt; for char in rev:... print(char)...maps 生成器Generators 生成器是创建迭代器的简单而强大的工具。它们像常规函数一样编写，但只要它们想返回数据就是用yield语句。每次next()被调用时，生成器都会从停止的地方恢复(它记住所有的数据值以上次执行的代码)。 123456789101112def reverse(data): for index in range(len(data)-1, -1, -1): yield data[index]&gt;&gt;&gt; for char in reverse('golf'):... print(char)...flog 任何可用生成器完成的事情也可用前面的基于类的迭代器完成。使生成器如此紧凑的原因是__iter__()和__next__()方法时自动创建的。 另一个关键特性是本地变量和执行状态在调用之间自动保存。这使得该函数更容易编写，并且比使用self.index和self.data等实例变量的方法更加清晰。除了自动方法创建和保存程序状态之外，当生成器终止时，它们会自动产生StopIteration。结合起来，这些功能可以轻松创建迭代器，而无需编写常规函数。 生成器表达式Generator Expressions 一些简单的生成器可以使用与列表解析类似的语法简洁地编码为表达式，带括号而不是方括号。这些表达式适用于通过封闭函数立即使用生成器的情况。生成器表达式比完整的生成器定义更紧凑但功能更少，并且倾向于比等效的列表解析更具有内存友好性。 123456789101112131415161718&gt;&gt;&gt; sum(i*i for i in range(10)) # sum of squares285&gt;&gt;&gt; xvec = [10, 20, 30]&gt;&gt;&gt; yvec = [7, 5, 3]&gt;&gt;&gt; sum(x*y for x,y in zip(xvec, yvec)) # dot product260&gt;&gt;&gt; from math import pi, sin&gt;&gt;&gt; sine_table = &#123;x: sin(x*pi/180) for x in range(0, 91)&#125;&gt;&gt;&gt; unique_words = set(word for line in page for word in line.split())&gt;&gt;&gt; valedictorian = max((student.gpa, student.name) for student in graduates)&gt;&gt;&gt; data = 'golf'&gt;&gt;&gt; list(data[i] for i in range(len(data)-1, -1, -1))['f', 'l', 'o', 'g'] 虚拟环境Virtual Environments and Packages 应用程序有时候需要特定的模块版本，或者某个模块只支持特定Python版本。这就意味着一个Python安装版本可能无法满足每个应用程序的要求。(如某个应用程序支持Python2.7，而某个应用程序支持Python3.x) 此问题的解决方案是创建一个虚拟环境(virtual environment)——一个包含特定Python安装包和软件包的目录树。这样，不同的应用程序就可以使用不同的虚拟环境。 创建虚拟环境Creating Virtual Environments 用于创建和管理虚拟环境额模块称为venv.它通常会为你安装最新版本的Python，你也可以选择Python版本。 激活虚拟环境后，会改变提示符并修改环境，以便提供特定的Python版本。 123456789101112131415#创建虚拟环境python3 -m venv /tmp/pythonVenv#激活source /tmp/pythonVenv/bin/activate(pythonVenv) [zhang@zhang21 ~]$(pythonVenv) [zhang@zhang21 ~]$ python&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.path[&apos;&apos;, &apos;/usr/lib64/python34.zip&apos;, &apos;/usr/lib64/python3.4&apos;, &apos;/usr/lib64/python3.4/plat-linux&apos;, &apos;/usr/lib64/python3.4/lib-dynload&apos;, &apos;/tmp/pythonVenv/lib64/python3.4/site-packages&apos;, &apos;/tmp/pythonVenv/lib/python3.4/site-packages&apos;]#退出deactivate pip包管理你可以使用pip程序进行搜索、安装、升级和移除软件包。pip程序默认从安装软件包。 pip freeze 以requirements的格式输出已安装软件包。这很重要。 12345678910111213141516171819202122pip search sh#默认安装最新版本pip install sh#安装指定版本pip install sh=1.10.2pip install --upgrade shpip uninstall sh#显示已安装的模块的详细信息pip show sh#列出已安装模块pip listpip freeze &gt; requirements.txt#安装依赖pip install -r ./requirements.txt 下划线参考: https://shahriar.svbtle.com/underscores-in-python https://segmentfault.com/a/1190000002611411 https://zhuanlan.zhihu.com/p/36173202 本节讨论Python中下划线(_)的使用，它的大部分用法都是一种惯例约定。 模式 栗子 含义 单下划线前缀 _var 命名约定，仅供内部使用。通常不会有Python解释器强制执行，只作为对程序员的提示 单下划线后缀 var_ 按约定使用以避免与Python关键字的命名冲突 双下划线前缀 __var 当在类上下文中使用时，触发名称修饰 双下划线前后缀 __var__ 表示Python语言定义的特殊方法 单个下划线 _ 三个情况 单个下划线单下划线(_)主要有三种情况: 解释器中下划线(_)符号指交互式解释器中最后一次执行语句的返回结果。 12345678910&gt;&gt;&gt; _Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;NameError: name &apos;_&apos; is not defined&gt;&gt;&gt;&gt;&gt;&gt; 111111&gt;&gt;&gt;&gt;&gt;&gt; _111 作为名称使用下划线(_)用作被丢弃的名称。这样可以让阅读你代码的人知道，这是个不会被使用的特定名称。 国际化下划线(_)用作函数名。这种情况下，单下划线经常被用作国际化和本地化字符串翻译查询的函数名。在Django中，你可能会看到: 123456from django.utils.translation import ugettext as _from django.http import HttpResponsedef my_view(request): output = _("Welcome to my site.") return HttpResponse(output) 单下划线前缀的名称以单下划线做前缀的名称(如_shahriar)，指定了这个名称是私有的。在有些import *的场景中，下一个使用你代码的人会明白这个名称仅供内部使用。下划线前缀的含义是告知其他程序员：以单个下划线开头的变量或方法仅供内部使用。 该约定在PEP 8中有定义。 如果你写了from module import *，那么以单下划线开头的名称都不会被导入，除非模块或包中的__all__列表显式地包含了它们。 单下划线后缀的名称以单下划线后缀的名称(如var_)，有时，一个变量的最合适的名称已被一个关键字所占用。在这种情况下，你可以附加一个下划线来解决命名冲突。 12345&gt;&gt;&gt; def make_object(name, class):SyntaxError: &quot;invalid syntax&quot;&gt;&gt;&gt; def make_object(name, class_):... pass 双下划线前缀的名称以双下划线做前缀的名称(如__shahriar)，它对解释器有特定含义。Python中的这种用法是为了避免与子类定义的名称冲突。 前后都有双下划线的名称前后都有双下划线的名称(如__init__)，是Python的特殊方法名，这是一种惯例，一种确保Python系统中的名称不会跟用户自定义的名称发生冲突的方式。 语言参考The Python Language Reference Python参考手册描述了Python语言的语法(syntax)和核心语义(core semantics)。 介绍Introduction 此参考手册描述了Python编程语言，它并不是一个教程。如果你正在使用Python并且想知道关于改语言的特定区域的精确规则是什么，那么你绝对应该能够在这里找到它们。 词法分析Lexical analysis 解析器(parser)读取Python程序。解析器的输入是由词法分析器生成的令牌流(stream of tokens)。本章描述了词法解析器如何将文件分解为令牌。 Python将程序文本读作Unicode code point，源文件的编码可以通过编码声明给出，默认为UTF-8，具体请参阅PEP 320。如果源文件无法被编码，则抛出语法错误。 行结构Line structure Python程序分为许多逻辑行。 逻辑行Logical lines 逻辑行的结尾由token NEWLINE表示。语句不能跨过逻辑行边界，除非语法允许NEWLINE。通过遵循显式或隐式的行连接规则，从一个或多个物理行构造逻辑行。 物理行Physical lines 物理行是由行尾序列终止的字符序列。在源文件和字符串中，可使用任何标准平台的行终止序列。Unix格式使用ASCII的LF，Windows格式使用ASCII的CR LF，或使用旧的Macintosh格式ASCII CR字符。无论平台如何，所有这些格式都可以平等使用。输入的结尾也充当最终物理行的隐式终止符。嵌入Python时，应使用标准C约定的换行符将源代码字符传递给Python API。 注释Comments 注释以哈希字符(#)开头，以物理行的末尾结束。注释表示逻辑行的结束，除非调用隐式行连接规则。语法会直接忽略注释。 编码声明Encoding declarations 如果Python脚本中的第一行或第二行中的注释与正则表达式coding[=:]\s*([-\w.]+)相匹配，则此注释将作为编码声明处理。编码声明必须出现在它自己的一行上。若果是第二行，则第一行也必须是仅注释行。编码表达式的推荐格式: 1# -*- coding: &lt;encoding-name&gt; -*- 如果未发现编码声明，默认编码为UTF-8。如果声明了编码，则必须有Python识别编码名称。编码用于所有词法分析，包括字符串文字，注释和标识符。 显式行连接Explicit line joining 可使用反斜杠(\)将两个或多个物理行连接到逻辑行中。 1234if 1900 &lt; year &lt; 2100 and 1 &lt;= month &lt;= 12 \ and 1 &lt;= day &lt;= 31 and 0 &lt;= hour &lt; 24 \ and 0 &lt;= minute &lt; 60 and 0 &lt;= secod &lt; 60: #Look like a valid date return 1 以反斜杠结尾的行不能编写注释。反斜杠在字符串文字外的一行上的其他位置是非法的。 隐式行连接Implicit line joining 括号，方括号，花括号中的表达式可以在不使用反斜杠的情况下分割为多个物理行。 1234month_names = ['January', ‘February', 'March', #comments 'April', 'May', 'June', #comments 'July', 'Auguest', 'September', #comments 'October, 'November', 'December'] 隐式的连续行可以带有注释，连续行的缩进并不重要。允许空白的连续行。 空白行Blank lines 包含空格，制表符，换页符，注释的逻辑行会被忽略。在标准的交互式解释器中，完全空白的逻辑行终止多行语句。 缩进Indentation 逻辑行开头的前导空白(空格和制表符)用于计算行的缩进级别，而后者又用于语句的分组。 tabs被1-8个空格替换(从左到右)，使得包括被替换的字节数总是八的倍数。第一个非空白字符前面的空格总数确定行的缩进。缩进不能够使用反斜杠在多个物理行上分隔。如果源文件以一种方式混合制表符(tab)和空格，使得含义取决于空格中制表符的价值，则缩进被拒绝为不一致。会抛出TabError异常。 跨平台兼容性说明： 由于non_Unix平台上文本编辑器的性质，在源文件中使用制表符和空格的混合来缩进是不明智的。还应注意，不同平台可以明确地限制最大缩进级别。 标识符和关键字Identifiers and keywords 标识符也称为名称，标识符的长度不受限制。Python中标识符的语法基于Unicode标准附件UAX-31，详情请参考PEP 3131在ASCII范围内(U+0001...U+007F)，有效的字符与Python2相同。大小写字母A-z，除第一个字符外的下划线(_)，数字0-9。Python3引入了ASCII范围外的其它字符，对于这些字符，分类使用unicodedata模块中包含的Unicode Character Database的版本。 Unicode类别代码表示： Lu： uppercase letters Ll： lowercase letters Lt： titlecase letters Lm： modifier letters Lo： other letters Nl： letter numbers Mn： nonspacing marks Mc： spacing combining marks Nd： decimal numbers Pc： connector punctuations Other_ID_Start： explicit list of characters in PropList.txt to support backwards compatibility Other_ID_Continue： likewise 关键字Keywords 以下标识符用作保留字或关键字，不能用作普通标识符。 123456789help(keywords)False class finally is returnNone continue for lambda tryTrue def from nonlocal whileand del global not withas elif if or yieldassert else import passbreak except in raise 保留的类标识符Reserved classes of identifiers 某些类标识符(除了关键字)具有特殊含义。这些类由前导/后置下划线(_)字符标识： _*特殊标识符_，用于交互式解释器中存储上次评估的结果，它保存在内建模块中。当不处于交互式模式时，下划线_没有特殊含义，也没有定义。名称_通常与国际化一起使用，这是一种约定。 __*__系统定义的名称。这些名称由解释器及其实现(包括标准库)来定义。在任何情况下，任何使用__*__名称都不会明确记录，在没有任何警告的情况下会受到破坏。 __*私有类(class-private)名称。在类定义的上下文中使用中使用此目录中的名称，名称将被重写，以使用损坏的格式来帮助避免基类和派生类(base and derived class)的私有属性之间的名称冲突。 文字值Literals 文字值是一些内建类型的常量值的符号。 字符串和字节文字值String and Bytes literals 字符串文字值和字节文字值描述： 12345678910111213141516171819202122stringliteral ::= [stringprefix](shortstring | longstring)stringprefix ::= &quot;r&quot; | &quot;u&quot; | &quot;R&quot; | &quot;U&quot; | &quot;f&quot; | &quot;F&quot; | &quot;fr&quot; | &quot;Fr&quot; | &quot;fR&quot; | &quot;FR&quot; | &quot;rf&quot; | &quot;rF&quot; | &quot;Rf&quot; | &quot;RF&quot;shortstring ::= &quot;&apos;&quot; shortstringitem* &quot;&apos;&quot; | &apos;&quot;&apos; shortstringitem* &apos;&quot;&apos;longstring ::= &quot;&apos;&apos;&apos;&quot; longstringitem* &quot;&apos;&apos;&apos;&quot; | &apos;&quot;&quot;&quot;&apos; longstringitem* &apos;&quot;&quot;&quot;&apos;shortstringitem ::= shortstringchar | stringescapeseqlongstringitem ::= longstringchar | stringescapeseqshortstringchar ::= &lt;any source character except &quot;\&quot; or newline or the quote&gt;longstringchar ::= &lt;any source character except &quot;\&quot;&gt;stringescapeseq ::= &quot;\&quot; &lt;any source character&gt;bytesliteral ::= bytesprefix(shortbytes | longbytes)bytesprefix ::= &quot;b&quot; | &quot;B&quot; | &quot;br&quot; | &quot;Br&quot; | &quot;bR&quot; | &quot;BR&quot; | &quot;rb&quot; | &quot;rB&quot; | &quot;Rb&quot; | &quot;RB&quot;shortbytes ::= &quot;&apos;&quot; shortbytesitem* &quot;&apos;&quot; | &apos;&quot;&apos; shortbytesitem* &apos;&quot;&apos;longbytes ::= &quot;&apos;&apos;&apos;&quot; longbytesitem* &quot;&apos;&apos;&apos;&quot; | &apos;&quot;&quot;&quot;&apos; longbytesitem* &apos;&quot;&quot;&quot;&apos;shortbytesitem ::= shortbyteschar | bytesescapeseqlongbytesitem ::= longbyteschar | bytesescapeseqshortbyteschar ::= &lt;any ASCII character except &quot;\&quot; or newline or the quote&gt;longbyteschar ::= &lt;any ASCII character except &quot;\&quot;&gt;bytesescapeseq ::= &quot;\&quot; &lt;any ASCII character&gt; 两种类型的文字值都可用单引号(&#39;)或双引号(&quot;)括起来，也能包含在三个引号中。反斜杠(\)字符用于转义好友特殊含义的字符。字节文字值总是以b或B为前缀，它们生成byte类型的实例，而不是str类型。它们可能只包含ASCII字符(128)，更大的字节必须转义。字符串和字节文字值都可以选择以字母r或R为前缀，如原始字符串将反斜杠视为文字字符。因此，在字符串文字值中，原始字符串中的\u和\U不会被特殊处理。 公认的转义序列： Escape Sequence Meaning \newline Backslash and newline ignored \\ Backslash () \&#39; Single quote (‘) \&quot; Double quote (“) \a ASCII Bell (BEL) \b ASCII Backspace (BS) \f ASCII Formfeed (FF) \n ASCII Linefeed (LF) \r ASCII Carriage Return (CR) \t ASCII Horizontal Tab (TAB) \v ASCII Vertical Tab (VT) \ooo Character with octal value ooo \xhh Character with hex value hh 仅在字符串文字值中识别的转义序列： Escape Sequence Meaning \N{name} Character named name in the Unicode database \uxxxx Character with 16-bit hex value xxxx \Uxxxxxxxx Character with 32-bit hex value xxxxxxxx 字符串文字串联String literal concatenation 多个相邻的字符串或字节文字值(由空格分隔)，可能使用不同的引用约定，并且它们的含义与它们的串联相同。因此，&quot;hello&quot; &#39;world&#39;等同于&quot;helloworld&quot;。此功能可用于减少反斜杠的数量，方便地跨长行分隔长字符串，甚至可以为字符串的某些部分添加注释。 123re.compile(&quot;[A-Za-z]&quot; #letter or underscore &quot;[A-Za-z0-9_]*&quot; #letter, digit or underscore ) 注意，此功能在语法级别上定义，但在编译时实现。必须使用+操作符在运行时连接字符串表达式。 格式化的字符串文字值Formatted string literals 格式化的字符串文字值是以f或F为前缀的字符串文字，这些字符串可能包含替换字段——由{}分隔的表达式。 12345678f_string ::= (literal_char | &quot;&#123;&#123;&quot; | &quot;&#125;&#125;&quot; | replacement_field)*replacement_field ::= &quot;&#123;&quot; f_expression [&quot;!&quot; conversion] [&quot;:&quot; format_spec] &quot;&#125;&quot;f_expression ::= (conditional_expression | &quot;*&quot; or_expr) (&quot;,&quot; conditional_expression | &quot;,&quot; &quot;*&quot; or_expr)* [&quot;,&quot;] | yield_expressionconversion ::= &quot;s&quot; | &quot;r&quot; | &quot;a&quot;format_spec ::= (literal_char | NULL | replacement_field)*literal_char ::= &lt;any code point except &quot;&#123;&quot;, &quot;&#125;&quot; or NULL&gt; 栗子： 12345678910111213141516&gt;&gt;&gt; name = &quot;Fred&quot;&gt;&gt;&gt; f&quot;He said his name is &#123;name!r&#125;.&quot;&quot;He said his name is &apos;Fred&apos;.&quot;&gt;&gt;&gt; f&quot;He said his name is &#123;repr(name)&#125;.&quot; # repr() is equivalent to !r&quot;He said his name is &apos;Fred&apos;.&quot;&gt;&gt;&gt; width = 10&gt;&gt;&gt; precision = 4&gt;&gt;&gt; value = decimal.Decimal(&quot;12.34567&quot;)&gt;&gt;&gt; f&quot;result: &#123;value:&#123;width&#125;.&#123;precision&#125;&#125;&quot; # nested fields&apos;result: 12.35&apos;&gt;&gt;&gt; today = datetime(year=2017, month=1, day=27)&gt;&gt;&gt; f&quot;&#123;today:%B %d, %Y&#125;&quot; # using date format specifier&apos;January 27, 2017&apos;&gt;&gt;&gt; number = 1024&gt;&gt;&gt; f&quot;&#123;number:#0x&#125;&quot; # using integer format specifier&apos;0x400&apos; 数字文字值Numeric literals 有三种类型的数字文字值： integers floating point numbers imaginary numbers 没有复数文字值。请注意，数字文字值不包含符号。像-1实际是由一元运算符-和文字值1组成的表达式。 整数文字值除了可以存储在可用内存中之外，整数文字值的长度没有限制。 12345678910integer ::= decinteger | bininteger | octinteger | hexintegerdecinteger ::= nonzerodigit ([&quot;_&quot;] digit)* | &quot;0&quot;+ ([&quot;_&quot;] &quot;0&quot;)*bininteger ::= &quot;0&quot; (&quot;b&quot; | &quot;B&quot;) ([&quot;_&quot;] bindigit)+octinteger ::= &quot;0&quot; (&quot;o&quot; | &quot;O&quot;) ([&quot;_&quot;] octdigit)+hexinteger ::= &quot;0&quot; (&quot;x&quot; | &quot;X&quot;) ([&quot;_&quot;] hexdigit)+nonzerodigit ::= &quot;1&quot;...&quot;9&quot;digit ::= &quot;0&quot;...&quot;9&quot;bindigit ::= &quot;0&quot; | &quot;1&quot;octdigit ::= &quot;0&quot;...&quot;7&quot;hexdigit ::= digit | &quot;a&quot;...&quot;f&quot; | &quot;A&quot;...&quot;F&quot; 浮点数文字值 123456floatnumber ::= pointfloat | exponentfloatpointfloat ::= [digitpart] fraction | digitpart &quot;.&quot;exponentfloat ::= (digitpart | pointfloat) exponentdigitpart ::= digit ([&quot;_&quot;] digit)*fraction ::= &quot;.&quot; digitpartexponent ::= (&quot;e&quot; | &quot;E&quot;) [&quot;+&quot; | &quot;-&quot;] digitpart 虚数文字值 1imagnumber ::= (floatnumber | digitpart) (&quot;j&quot; | &quot;J&quot;) 运算符Operators 123+ - * ** / // % @&lt;&lt; &gt;&gt; &amp; | ^ ~&lt; &gt; &lt;= &gt;= == != 分隔符Delimiters 1234( ) [ ] &#123; &#125;, : . ; @ = -&gt;+= -= *= /= //= %= @=&amp;= |= ^= &gt;&gt;= &lt;&lt;= **= Python中以下ASCII字符有重要意义： 1&apos; &quot; # \ Python中不使用以下ASCII字符: 1$ ? 数据模型Data model HOWTOsPython HOWTOs是覆盖单个特定主机的文档，并尝试完全包含它。此文档比Python参考库更详细。 标准库 介绍Python标准库包含了各种不同类型的组件。 一些模块提供了特定于Python的接口；一些提供特定于特定操作系统的接口，一些提供特定于特定应用程序的接口。一些模块适用于所有Python版本和端口；一些只有在底层系统支持或需要它们是才可用；还有一些只有在编译和安装Python特定配置时才可用。 内建函数Python解释器内置了许多功能和类型，它们始终可用。 内建函数 abs() dict() help() min() setattr() all() dir() hex() next() slice() any() divmod() id() object() sorted() ascii() enumerate() input() oct() staticmethod() bin() eval() int() open() str() bool() exec() isinstance() ord() sum() bytearray() filter() issubclass() pow() super() bytes() float() iter() print() tuple() callable() format() len() property() type() chr() frozenset() list() range() vars() classmethod() getattr() locals() repr() zip() compile() globals() map() reversed() __import__() complex() hasattr() max() round() delattr() hash() memoryview() set() abs(x)返回一个数字的绝对值 all(iterable)如果迭代的所有元素均为真(或为空)，返回True any(iterable)如果迭代的任一元素为真，返回True；为空返回False ascii(object) bin(x)将整数转换为二进制字符串 bool([x])返回一个布尔值，True或False bytearray()返回一个新的字节数组 byte()返回一个新的字节对象，它是一个在0&lt;=x&lt;256范围内的不可变整数序列 callable(object)如果对象参数显示为可调用，返回True；否则返回False chr(i)返回代表Unicode编码为整数i的字符的字符串 classmethod(function)为函数返回一个类方法 compile()将源编译为代码或AST对象 complex()返回一个复数，或将字符串或数字转换为复数 delattr(object, name)这是setattr()的相对值 dict(kwarg)创建一个新的字典 dir(object)无参数，返回当前本地作用域中的名称列表有参数，尝试返回该对象的有效属性列表 divmod(a, b)以两个数字(非复数)为参数，使用整数除法时返回由它们的商和余数组成的一对数字 enumerate(iterable, start=0)返回一个枚举对象 eval(expression, globals, locals) exec()动态执行Python代码 filter(function, iterable)从函数返回true的可迭代元素构造一个迭代器 float()返回由数字或字符串构造的浮点数 format()将值转换为特定格式 frozenset()返回一个新的frozenset对象，可选用来自迭代的元素 getattr()返回对象命名属性的值 globals()返回表示当前全局符号表的字典 hasattr(obj, name)参数是一个对象和一份字符串，如果字符串是对象属性之一的名称，结果为True，否则False hash(obj)返回对象的hash值 help()调用内建的帮助系统 hex(x)将整数转换为十六进制数 id(obj)返回一个对象的标识 input()从标准输入中读取一行，转换为字符串，然后返回该行 int(x)返回一个整数对象，如果没有参数，则返回0 isinstance(obj, classinfo)如果对象参数是classinfo参数的实例或其子类的实例，返回true issubclass(class, classinfo)如果class是类信息的子类，返回true iter(obj)返回一个迭代器对象 len()返回对象的长度 list()列表实际上是一个可变的序列类型，而不是一个函数 locals()更新并返回表示当前本地符号表的字典 map()返回一个将函数应用于每个迭代项的迭代器，从而产生结果 max()返回最大项 memoryview(obj)从给定参数返回内存视图对象 min()返回最小项 next()从迭代器中检索下一项 object()返回一个新的无特征的对象 oct()将整数转换为八进制字符串 open()打开文件并返回相应的文件对象 ord()给定一个表示一个Unicode编码的字符，返回一个表示该字符的Unicode编码的整数 pow() print()将对象打印到流文件 property()返回一个property属性 range()范围一个不可变的序列类型，而不是函数 repr()返回一个包含对象可打印表示的字符串 reversed()返回一个反向迭代器 round()返回数字小数点后ndigits精度 set()返回一个新的集合对象，可选来自迭代的元素 setattr()getattr的对应部分 slice()返回由范围指定的一组索引的切片(slice)对象 sorted()从迭代项中返回一个新的排序列表 staticmethod()为函数返回一个静态方法 str()返回一个字符串对象 sum()对迭代项求和 super()返回将方法调用委托个父类或同类的代理对象 tuple()元组是一个不可变的序列类型，而不是函数 vars()返回对象的__dict__属性 zip()制作一个迭代器，用于聚合来自每个迭代器的元素 __import__这个函数被import语句调用 内建常量少量常量存在于命名空间中。 False True None NotImplemented Ellipsis __debug__ 内建类型主要的内建类型有： 数字(numeric) 序列(sequence) 映射(mapping) 类(class) 实例(instance) 异常(exception) 真值测试任何对象都可进行真值测试。 布尔操作 and or not 比较操作Python中有8个比较操作： &lt; &lt;= &gt; &gt;= == != is isnot 数字类型 int float complex 迭代器类型Python支持对容器进行迭代的概念。 序列类型 list 列表是可变序列，通常用于存储同类项目的集合 tuple 元组是不可变序列，通常用于存储异构数据的集合 range 范围表示一个不可变的数字序列，通常用于for循环 range(start, stop, step) 通用序列操作 in not in + * [i] [i:j] [i:j:k] len() min() max() count() index() 不可变序列类型 可变序列类型可变定义类型的操作： [i] [i:j] del [i:j:k] append() clear() copy() += *= insert() pop remove() reverse() 文本序列类型Python中的文本数据由str对象处理，字符串是Unicode编码点的不可变序列。 字符串以各种方式书写： 单引号 双引号 三引号 字符串方法 https://docs.python.org/3.5/library/stdtypes.html#string-methods 样式字符串格式字符串对象有一个唯一的内建操作: %操作符，也称为字符串格式化操作符。 转换类型： % s i x f c 二进制序列类型 bytes 字节对象是单字节的不可变序列 bytearray 是字节对象的可变对象 memoryview 运行Python代码访问支持缓冲区协议的对象的内部数据，而无需复制 字节和字节数组对象操作符都支持普通序列操作符，同样也支持字节格式。 集合类型 set frozenset 集合对象是不同可散列对象的无序集合。常见用途包含成员测试、删除重复项，数学计算(交集，并集，差集) 映射类型 dict 映射对象可将散列值映射到任意对象，它是可变对象。 字典视图对象 dict.keys() dict.values() dict.items() 上下文管理类型Python的with语句支持由上下文管理器定义的运行时上下文的概念。 其它内建类型模块类和类实例函数方法代码对象类型对象null对象ellipsis对象notImplimented对象布尔值内部对象 特殊属性一些特殊的只读属性： object.__dict__ instance.__class__ class.__bases__ definition.__name__ definition.__qualname__ class.__mro__ class.__subclasses__() 内建异常在Python中，所有异常(exception)都必须是派生自Baseexception的类的实例。 基类 BaseException Exception ArithmeticError bufferError LookupError 具体异常 AssertionError AttributeError EOFError FloatingPointError GeneratorExit ImportError IndexError KeyError KerboardInterrupt MemoryError NameError NotImplementedError OSError OverflowError RecursionError ReferenceError RuntimeError StopAsyncIteration SyntaxError IndentationError TabError SystemError SystemExit TypeError UnboundLocalError UnicodeError UnicodeEncodeError UnicodeDecodeError UnicodeTranslateError ValueError ZeroDivisionError EnvironmentError IOError 文本处理stringstring模块，字符串操作 rere模块，提供了正则表达式匹配操作。 字符串模式匹配 12345678&gt;&gt;&gt; import re&gt;&gt;&gt; re.findall(r'f[a-z]*', 'which foot or hand fell fastest')['foot', 'fell', 'fastest']#替换&gt;&gt;&gt; 'aaa and bbb'.replace('bbb', 'BBB')'aaa and BBB' difflibdifflib，助手计算三角洲。该模块提供用于比较序列的类和函数。 textwraptextwrap模块，文本环绕和填充。将段落文本格式化以适应给定的屏幕宽度。 12345678&gt;&gt;&gt; import textwrap&gt;&gt;&gt; doc = """ 1111 1111 1111 1111 1111 1111... 2222 2222 2222 2222 2222 2222... 3333 3333 3333 3333 3333 3333"""&gt;&gt;&gt; print(textwrap.fill(doc, width=50)) 1111 1111 1111 1111 1111 1111 2222 2222 2222 22222222 2222 3333 3333 3333 3333 3333 3333 unicodedataunicodedata，Unicode数据库。该模块提供对Unicode字符数据库(UCD)的访问，此数据库为所有Unicode字符定义字符属性。 stringprepstringprep，因特网字符串准备。 readlinereadline，GNU读行接口。该模块定义了许多方便Python解释器完成和读写历史文件的函数。 rlcompleterrlcompleter，GNU读行的完成函数。该模块通过完成有效的Python标识符合关键字来定义适用于readline模块的完成函数。 二进制数据structstruct模块，将字节解释为打包的二进制数据。提供了pack()和unpack()函数来处理可变长度的二进制记录格式。 codecscodes，编解码注册和基类。 数据和时间timetime模块，提供了许多操作时间值(time value)的函数，用于取得Unix纪元时间戳。 123456789import time#Unix时间time.time()#1531364576.3187952#delay for a number of seconds given as a floattime.sleep()time.time();time.sleep(10);time.time() datetimedatetime模块，基本日期和时间类型。支持日期和时间计算，并对输出做格式化处理。 1234567891011121314151617181920212223242526import datetimedatetime.datetime.now()#datetime.datetime(2018, 7, 12, 13, 45, 43, 127838)datetime.datetime.now().year, datetime.datetime.now().month, datetime.datetime.now().hour#Unix纪元转换datetime.datetime.fromtimestamp(1531374507.8268566)#datetime.datetime.fromtimestamp(time.time())#datetime.datetime(2018, 7, 12, 13, 48, 27, 826857)#日期比较yesterday = datetime.datetime(2018, 7, 11, 00, 00, 00, 00000)today = datetime.datetime.now()future = datetime.datetime(2018, 8, 12, 00, 00, 00, 00000)today &gt; yesterdaywhile future &gt; today: time.sleep(1)#timedelta表示一段时间#周，时，分，秒，毫秒，微秒period = datetime.timedelta(days=7, hours=6, minutes=20, seconds=55)str(period)#'7 days, 6:20:55' datetime.datetime.strftime()将datetime对象转换为字符串datetime.datetime.strptime()将字符串转换为datetime对象格式栗子: %Y: 2018 %y: 18 %m: 07 %B: July %b: Jul %d: 一月中的第几天 %j: 一年中的第几天 %w: 一周中的第几天(0-6) %A: Thursday %a: Thu %H: 14(00-23) %I: 2(0-12) %M: 分(00-59) %S: 秒(00-59) %p: AM/PM 12345datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')#'2018-07-12 14:11:20'datetime.datetime.strptime(2018-07-12 14:11:20', '%Y-%m-%d %H:%M:%S')#datetime.datetime(2018, 7, 12, 14, 11, 20) calendarcalendar，日历相关函数。 collectionscollections，容器数据类型。 collections.abccollections.abc，容器的抽象基类 heapqheapq，堆队列算法。 bisectbisect，数组二等分算法。 arrayarray模块，有效的数值数组。它提供了一个array()对象，就像一个只存储同质数据并将其存储更紧凑的列表。 weakrefweakref，弱引用。weakref模块提供了用于跟踪对象而不创建参考的工具。当不再需要该对象时，它将自动从弱参考表中移除，并为弱参考对象触发回调。 Python支持自动内存管理，内存在最后一次被删除后不久就被释放。 copycopy，浅层和深层操作。 pprintpprint模块，漂亮打印。 12345678&gt;&gt;&gt; import pprint&gt;&gt;&gt; t =[[[['black', 'cyan'], 'white', ['green', 'red']], [['magenta','yellow'], 'blue']]]&gt;&gt;&gt; pprint.pprint(t, width=30)[[[['black', 'cyan'], 'white', ['green', 'red']], [['magenta', 'yellow'], 'blue']]] reprlibreprlib模块，提供repr自定义显示 enumenum，支持枚举。 数字和数学numbersnumbers，数字抽象基类。 round按指定精度四舍五入一个浮点数。 12round(1.23456, 4)#1.236 mathmath模块，数学函数。 12345&gt;&gt;&gt; import math&gt;&gt;&gt; math.sin(math.pi / 2)1.0&gt;&gt;&gt; math.log(256, 2)8.0 cmathcmath，复数数学函数。 decimaldecimal，十进制定点和浮点运算。 fractionsfractions，有理数。 randomrandom，生成伪随机数。 123456789&gt;&gt;&gt; import random&gt;&gt;&gt; random.choice(['a', 'b', 'c'])'a'&gt;&gt;&gt; random.sample(range(10), 2)[2, 6]&gt;&gt;&gt; random.random()0.9714711378164909&gt;&gt;&gt; random.randrange(10)5 statisticsstatistics模块，数学统计函数。计算基本的统计属性： 平均数(mean) 中位数(median) 方差(variance) 12345678&gt;&gt;&gt; import statistics&gt;&gt;&gt; num = [1, 2, 3, 4, 5]&gt;&gt;&gt; statistics.mean(num)3&gt;&gt;&gt; statistics.median(num)3&gt;&gt;&gt; statistics.variance(num)2.5 函数式编程模块本章模块提供了支持函数式编程风格的函数和类，以及可调用函数的一般操作。 itertoolsitertools，为高校循环创建迭代器。 functoolsfunctools，可调用对象的高阶函数和操作 operatoroperator，作为函数的标准操作符 文件和目录本章介绍的模块处理磁盘文件和目录。 pathlibpathlib，面向对象的文件系统路径此模块提供了代表文件系统路径的类，其语义适用于不同的操作系统。 os.pathos.path，通用路径名操作该模块在路径名上实现了一些有用的功能。 fileinputfileinput，迭代来自多个输入流的行该模块实现了从一个帮助类和函数，可在标准输入或文件列表上快速编写循环。 statstat，解释stat()结果此模块定义用于解释os.stat(),os.fstat(),os.lstat()的结果的常量和函数。 filecmpfilecmp，文件和目录比较此模块定义了比较文件和目录的函数，以及各种可选的时间和权衡。 tempfiletempfile，生成临时文件和目录此模块创建临时文件和目录。 globglob，Unix样式路径名称模式扩展此模块根据Unix shell使用的规则查找与指定模式匹配的所有路径名，结果以任意顺序返回。 fnmatchfnmatch，Unix文件名模式匹配此模块提供了对Unix shell风格的通配符的支持，它与正则表达式不同。 通配符: * ? [seq] [!seq] linecachelinecache，随机访问文本行此模块允许从Python源文件中获取任意行，同时尝试使用缓存进行内部优化，这是一种从单个文件中读取多行的常见情况。 shutilshutil，高级文件操作此模块提供了许多关于文件和文件集合的高级操作。 目录和文件操作 copytree rmtree 归档操作 12345&gt;&gt;&gt; shutil.copyfile('/tmp/1.txt', '/tmp/111.txt')'/tmp/111.txt'&gt;&gt;&gt; shutil.move('/tmp/today', '/tmp/TODAY')'/tmp/TODAY globglob模块，从通配符中搜索创建文件列表 123&gt;&gt;&gt; import glob&gt;&gt;&gt; glob.glob('/tmp/*.txt')['/tmp/1.txt', '/tmp/2.txt', '/tmp/111.txt'] 数据持久化本章介绍的模块支持将Python数据持久化存储到磁盘上。 picklepickle，Python对象序列化此模块用于实现序列化(serializing)和反序列化Python对象结构的二进制协议。 copyregcopyreg，注册pickle支持函数该模块提供了一种定义胭脂(pickle)特定对象时使用的函数方法。 shelveshelve，Python对象持久化shelf是一个持久的，类似字典的对象。 marshalmarshal，内部Python对象序列化此模块包含了可以以二进制格式读写Python值得函数。 dbmdbm，到Unix数据库的接口dbm是DBM数据库变体的通用接口。 sqlite3sqlite3，SQLite数据库的DB-API 2.0接口SQLite是一个C库，它提供了一个轻量级的基于磁盘的数据库，它不需要单独的服务器进程，并允许使用SQL查询语言的非标准变体访问数据库。 数据压缩和归档本章介绍的模块，支持使用zlib, gzip, bzip2, lzma算法进行数据压缩，以及创建zip和tar格式的归档文件。 zlibzlib，兼容gzip的压缩对于需要数据压缩的应用程序，此模块中的功能允许使用zlib库进行压缩(compression)和解压缩(decompression)。 gzipgzip，支持gzip文件此模块提供了一个简单的接口来压缩和解压缩文件，就行GNU程序gzip和gunzip一样。 bz2bz2，支持bz2压缩该模块提供了一个全面的接口，用于使用bzip2压缩算法进行压缩和解压缩数据。 lzmalzma，使用lzma算法进行压缩该模块提供了类和函数，用于使用lzma进行压缩和解压缩数据。 zipfilezipfile，使用zip归档zip文件格式是一个常用的归档和压缩标准。此模块提供了工具，用于创建，读写，追加和列出zip文件的工具。 tarfiletarfile，读写tar归档文件该模块可读写tar归档文件，包括使用gzip，bz2和lzma压缩。 文件格式本章描述的模块，解析各种各样的文件格式，不包含标记语言和e-mail。 csvcsv，读写CSV文件 所谓的CSV(comma separated values)逗号分隔值，它是一种简化的电子表格，保存为纯文本文件。是电子表格和数据库最常用的导入和导出格式。该模块实现了以CSV格式读写表格数据。 CSV文件很简单，缺少了Excel表格的许多功能： 值没有类型，都是字符串 没有字体大小或颜色 没有多个工作表 不能指定单元格的宽度和高度 不能合并单元格 不能签入图像和图标 1234567891011import csvfile = open(&apos;/tmp/test.csv&apos;)reader = csv.reader(file)data = list(reder)#写file = open(&apos;/tmp/test.csv&apos;, &apos;w&apos;, newline=&apos;&apos;)writer = csv.writer(file)writer.writerow(&apos;[1, 11, 111]&apos;)file.close() configparserconfigparser，配置文件解析器此模块提供了ConfigParser类，它实现了一种基本配置，你可以使用它来编写可由最终用户轻松定制的Python程序。 netrcnetrc文件处理netrc类解析和封装Unix FTP程序和其它FTP客户端使用的netrc文件格式。 xdrlibxdrlib，编码(encode)和解码(decode)XDR数据该模块支持外部数据表示标准(External Data Representation Standard)。此模块定义了两个类，一个将变量打包(packing)到XDR，另一个从XDR中解包(unpack)。 加密服务本章描述的模块，实现了各种加密(cryptographic)算法 hashlibhashlib，安全散列和消息摘要(digest)该模块为许多不同安全散列和消息摘要算法实现了通用接口。 SHA1 SHA224 SHA256 SHA384 MD5 hmachmac，用于消息认证的键控散列 操作系统接口本章介绍的模块，提供了操作系统功能的接口。 osos，各种操作系统接口该模块为使用操作系统相关的功能提供了一种便携方式。 文件名，命令行参数，环境变量 进程参数 文件对象创建 文件描述符操作 文件和目录的Linux扩展属性 进程管理 调度程序的接口 各种各样的系统信息 各种各样的功能 12345678&gt;&gt;&gt; import os&gt;&gt;&gt; os.getcwd()'/home/zhang'&gt;&gt;&gt; os.chdir('/tmp')#在shell中运行命令&gt;&gt;&gt; os.system('mkdir /tmp/today')0 ioio，流处理的核心工具该模块提供了Python用于处理各种类型I/O的主要工具。 text i/o binary i/o raw i/o timetime，访问和转换时间此模块提供了各种与时间相关的函数 argparseargparse，解析命令行选项、参数和子命令该模块可以轻松编写用户友好的命令行接口。 getoptgetopt，用于命令行选项的C风格解析器该模块帮助脚本解析sys.argv中的命令行参数。 logginglogging，Python的日志工具该模块定义了函数和类，为应用程序和库实现灵活事件记录系统 log level: DEBUG最低级别。用于小细节，通常只有在诊断问题时，才需要关心这些信息。 INFO用于记录程序中的一般事件的信息。 WARNING用于表示可能的问题 ERROR用于记录错误 CRITICAL最高级别，用于表示致命的错误 日志级别是一种建议。归根到底，还是由你来决定日志消息属于哪一种类型。 12345678910111213141516import logginglogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(lineno)d - %(message)s')logging.debug('Debugging information')logging.info('Informational message')logging.warning('Warning:config file %s not found', 'server.conf')logging.error('Error occurred')logging.critical('Critical error -- shutting down')#输出2018-07-10 14:50:13,060 - INFO - 6 - Informational message2018-07-10 14:50:13,061 - WARNING - 7 - Warning:config file server.conf not found2018-07-10 14:50:13,061 - ERROR - 8 - Error occurred2018-07-10 14:50:13,061 - CRITICAL - 9 - Critical error -- shutting down log format: 12345678910111213141516| %(name)s Name of the logger (logging channel)| %(levelno)s Numeric logging level for the message (DEBUG, INFO, WARNING, ERROR, CRITICAL)| %(levelname)s Text logging level for the message (&quot;DEBUG&quot;, &quot;INFO&quot;, &quot;WARNING&quot;, &quot;ERROR&quot;, &quot;CRITICAL&quot;)| %(pathname)s Full pathname of the source file where the logging call was issued (if available)| %(filename)s Filename portion of pathname| %(module)s Module (name portion of filename)| %(lineno)d Source line number where the logging call was issued (if available)| %(funcName)s Function name| %(created)f Time when the LogRecord was created (time.time() return value)| %(asctime)s Textual time when the LogRecord was created| %(msecs)d Millisecond portion of the creation time| %(relativeCreated)d Time in milliseconds when the LogRecord was created, relative to the time the logging module was loaded (typically at application startup time)| %(thread)d Thread ID (if available)| %(threadName)s Thread name (if available)| %(process)d Process ID (if available)| %(message)s The result of record.getMessage(), computed just as the record is emitted logging.configlogging.config，日志配置 logging.handlerslogging.handlers，日志处理程序 getpassgetpass，便携式密码输入 cursescurses，字符单元显示的终端处理 curses.textpadcurses.textpad，用于curses程序的文本输入小部件此模块提供了一个Textbox类，他在curses窗口中处理基本的文本编辑。 curses.asciicurses.ascii，用于ASCII字符的使用程序该模块为ASCII字符提供名称常量，并为各种ASCII字符类中的成员测试函数。 curses.panelcurses.panel，curses的面板堆栈扩展面板是具有深度附加功能的窗口，因此它可堆叠在彼此的顶部，并且只显示每个窗口的可见部分。 platformplatform，访问底层平台的识别数据 errnoerrno，标准的errno系统符号 ctypesctypes，一个Python的外部函数库该模块提供了C兼容的数据类型，并允许在DLL或共享中调用函数。 并发执行本章介绍的模块，为并发执行(consurrent execution)代码提供了支持。 threadingthreading，基于线程的并行此模块在较低级别的_thread模块之上构建较高级别的线程接口。 如果多线程同时读写变量，导致互相干扰，就会发生所谓的并发问题。 1234567891011121314import time, threadingprint('thread start.')def wakeup(times): time.sleep(5) n = times for i in range(n): print('Wake Up!')thread01 = threading.Thread(target=wakeup, args=[3])#thread01 = threading.Thread(target=wakeup, kwargs=&#123;'times': 3&#125;)thread01.start()print('End of program!') multiprocessingmultiprocessing，基于进程的并行它是一个使用类似线程模块的API来支持产生进程的包。 concurrentconcurrent包中只有一个模块concurrent.futures，启动并行任务该模块为异步(asynchronously)执行可调用提供了一个高级的接口。 subprocesssubprocess，子进程管理该模块允许你生成新的进程，连接到它们的input/output/error pipes，并获得它们返回的代码。每个进程可以有多个线程。 1234567891011import subprocess#在Python脚本中启动一个外部程序subprocess.Popen(‘/tmp/hello.py’)#hello world!#用Popen传递参数，这需要传递一个列表subprocess.Popen([‘/tmp/hello.py’, 'argv1'])#它还有许多参数help(subprocess.Popen) schedsched，事件调度程序(scheduler)该模块定义了一个实现通用时间调度器的类。 queuequeue，一个同步队列类该模块实现了多生产者、多消费者队列。当信息必须在多线程之间安全地交换时，它在线程编程中特别有用。 进程间的通信和网络本章介绍的模块，提供了不同进程进行通信的机制。 socketsocket，低级网络接口该模块提供了对BSD socket的访问。 Socket是网络编程的一个抽象概念。通常我们用一个Socket表示“打开了一个网络链接”，而打开一个Socket需要知道目标计算机的IP地址和端口号，再指定协议类型即可。tcp需要建立连接，udp不需要建立连接，因此udp每次需要指定发送地址。 socket类型： socket.AF_UNIX本机通信 socket.AF_INET服务器间的网络通信 socket.AF_INET6IPv6的服务器间的通信 socket.SOCK_STREAM基于TCP的流式socket通信 socket.SOCK_DGRAM基于UDP数据包的socket通信 socket.SOCK_RAM原始套接字 socket.SOCK_SEQPACKET可靠的连续数据包服务 123456789101112131415161718192021#服务端socket函数：bind() 在AF_INET下，以tuple(host, port)的方式传入，如s.bind((host, port))listen() 可设置挂起的最大连接数accept() 接收tcp连接并返回(conn, address), conn是新的套接字对象, address是客户端地址#客户端socket函数：connect()connect_ex()#公共socket函数#tcprecv() 接受TCP套接字的数据，数据以字符串形式返回，buffsize指定要接受的最大数据量send()sendall() 完整发送tcp数据#udprecvfrom()sendto()close() socket编程思想： 12345678910111213#Server-side1. 创建socket2. 监听3. 接收client请求4. 接收C端数据5. 关闭头街子#Client-side1. 创建socket2. 连接到S端3. 发送数据4. 关闭套接字 注意在Python3.x中，byte strings 和 unicodestrings是两种不同的类型，相互之间需要进行decode()和encode()send()和recv()都是bytes类型，需要与str类型进行转换。 1234567891011121314151617181920212223242526272829303132333435363738394041424344#tcp#S端import sockethost = 'localhost'port = 5678bf = 1024maxConn = 3tcpS = socket.socket(socket.AF_INET, socket.SOCK_STREAM)tcpS.bind((host, port))tcpS.listen(maxConn)print('Server start at &#123;host&#125;:&#123;port&#125;'.format(host=host, port=port))print('Waiting for connection...')while True: conn, addr = tcpS.accept() print('Connected by: &#123;addr&#125;'.format(addr=addr)) while True: data = conn.recv(bf) print(data.decode('utf-8')) conn.send('server received message.'.encode('utf-8')) tcpS.close()#C端import sockethost = 'localhost'port = 5678bf = 1024tcpC = socket.socket(socket.AF_INET, socket.SOCK_STREAM)tcpC.connect((host, port))while True: msg = input('Please input message: \n') tcpC.send(msg.encode('utf-8')) data = tcpC.recv(bf) print(data.decode('utf-8')) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#udp#S端from pymongo import MongoClientimport socket, datetimehost = 'localhost'port = 5679bf = 1024mongoPort = 27017mongoUser = 'zhang'mongoPw = 'password'mongoDb = 'zhang'mongoColl = 'udpS'udpS = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)udpS.bind((host, port))collection = MongoClient(host=host, port=mongoPort, \ username=mongoUser, password=mongoPw).zhang.udpSprint('udp socket on &#123;host&#125;:&#123;port&#125;...'.format(host=host, port=port))while True: data, addr = udpS.recvfrom(bf) print('Received from &#123;addr&#125;'.format(addr=addr)) print(data.decode('utf-8')) print('\n') msg = 'Server has recived!\n' udpS.sendto(msg.encode('utf-8'), addr) dateTime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') post = &#123; 'author': 'Server', 'date': dateTime, 'message': data.decode('utf-8') &#125; collection.insert_one(post)#C端from pymongo import MongoClientimport socket, datetimehost = 'localhost'port = 5679bf = 1024mongoPort = 27017mongoUser = 'zhang'mongoPw = 'password'mongoDb = 'zhang'mongoColl = 'udpC'udpC = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)collection = MongoClient(host=host, port=mongoPort, \ username=mongoUser, password=mongoPw).zhang.udpCwhile True: msg = str(input('Please input message: \n')) udpC.sendto(msg.encode('utf-8'), (host, port)) data = udpC.recv(bf) print(data.decode('utf-8')) dateTime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') post = &#123; 'author': 'Client', 'date': dateTime, 'message': data.decode('utf-8') collection.insert_one(post) udpC.close() sslssl，套接字对象的TLS/SSL封装此模块提供了对网络套接字的传输层安全(通常称为安全套接字层)的加密和对等身份验证功能。 selectselect，等待I/O完成该模块提供对大多数操作系统中可用的select()和poll()函数的访问。 selectorselector，高级I/O复用该模块基于select()模块构建，有序高级和高效的I/O复用。 asyncioasyncio，异步I/O，事件循环，协同程序和任务该模块提供了使用协同程序编写单线程并发代码的基础结构，在套接字和其它资源上多路复用I/O访问，运行网络客户端和服务器以及其它相关基元。 asyncoreasyncore，异步套接字处理器该模块为编写异步套接字服务(客户端和服务端)提供了基本的基础结构。 asynchatasynchat，异步套接字命令/响应处理器该模块构建在asyncore之上，简化了异步客户端和服务端，并更容易处理其元素被任何字符串终止和长度可变的协议。 signalsignal，为异步事件设置处理器该模块提供了在Python中使用信号处理程序的机制。 mmapmmap，内存映射文件支持内存映射文件对象的行为与bytearray和文件对象类似。 网络数据处理本章介绍的模块，支持处理常用网络数据格式。 emailemail，一个email和MIME处理包该包是用于管理电子邮件信息的库，包含MIME和其它基于RFC 2822的消息文档。 MIME(Multipurpose Internet Mail Extensions)多用途互联网邮件扩展，是一种标准化的方式来标识文档的性质和格式。浏览器通常使用MIME类型(而不是文件扩展名)来确定如何处理文档。 栗子： 12345678910111213type/subtypetext/plaintext/htmlimage/jpegimage/pngaudio/mpegaudio/oggaudio/*video/mp4application/octet-stream… email.message表示一个电子邮件信息 email.parser解析电子邮件信息 email.generator生成MIME文档 email.policy政策对象 email.headerregistry自定义头对象 email.contentmanager管理MIME内容 email.mime从抓挠中创建电子邮件和MIME对象。 email.headerInternationalized headers email.charset表示字符集 email.encoders编码器 email.errors异常和缺陷类 email.utils各种各样的功能 email.iterators迭代器 jsonjson，JSON编码器和解码器JSON(JavaScript Object Notation)，是一个受JavaScript对象语法启发的轻量级的数据交换格式。 json只能包含如下Python数据类型的值： 字符串 整型 浮点数 布尔型 列表 字典 NoneType 123456import jsonJSONDATA = &apos;&#123;&quot;name&quot;: &quot;zhang&quot;, &quot;age&quot;: 21, &quot;likeFootball&quot;: true&#125;loadData = json.loads(JSONDATA)dumpData = json.dumps(jsonData) mailcapmailcap，mailcap文件处理mailcap文件用于配置感知MIME的应用程序(如邮件阅读器和Web浏览器)，如何对具有不同MIME类型的文件做出反应。 mailboxmailbox，以各种格式操作邮箱该模块定义了两个类: Mailbox和Message，用于访问和操作磁盘邮箱及其包含的邮件。 mimetypesmimetypes，将文件名映射到MIME类型该模块在文件名或URL和MIME类型之间进行转换。 base64base64，base16、base32，base64，base85数据编码该模块提供了将二进制数据编码为可打印的ASCII字符，并将这些编码解码回二进制数据的函数。 binhexbinhex，编码和解码binhex4文件 binasciibinascii，在二进制和ASCII之间进行转换该模块包含了许多方法，用于转换在二进制和各种ASCII编码的二进制表示之进行转换的方法。 quopriquopri，编码和解码MIME引用打印数据 uuuu，编码和解码uuencode文件该模块以uuencode格式对文件进行编码和解码，允许任意二进制数据仅通过ASCII连接进行传输。 结构化标记处理工具Python支持用以处理各种形式的结构化数据标记的模块。 标准通用标记语言，SGML() 超文本标记语言，HTML 扩展标记语言，XML htmlhtml，支持超文本标记语言该模块定义了用以操作HTML的实用程序。 html.parserhtml.parser，简单HTML和XHTML解析器该模块提供了一个类，用来解析HTML和XHTML格式的文本文件的基础。 html.entitieshtml.entities，HTML一般实体的定义 XML处理模块用于处理XML的Python接口被分组到xml包 网络协议本章介绍的模块，实现了网络协议并支持相关技术。 webbrowserwebbrowser - Interfaces for launching and remotely controlling Web browsers.webbrowser，便利的web浏览器控制器该模块提供了一个高级interface，允许向用户显示基于web的文档。 123import webbrowserwebbrowser.open(&apos;https://www.baidu.com&apos;) cgicgi，通用网关接口支持CGI 脚本的支持模块；该模块定义了许多用Python编写的CGI脚本的实用功能。 cgitbcgitb，CGI脚本的追溯管理器此模块为Python脚本提供了一个特殊的异常处理程序。 wsgirefwsgiref，WSGI功能和参考实现Web服务器网关接口(WSGI)，是Web服务器软件和Web应用程序(Python编写)之间的标准接口。拥有标准接口可以轻松使用支持WSGI和多个不同Web服务器的应用程序。 urllburllib模块，处理URL urllib.requesturllib.request模块，用于打开URL的可扩展库该模块定义了函数和类，用于在复杂的世界中打开URL——基本和身份认证，重定向，cookie等 urllib.responseurllib.response，响应类该模块定义了向接口这样的最小文件的函数和类。 urllib.parseurllib.parse，将URL解析为组件此模块定义了一个标准接口，用于在组件中分解统一资源定位符(URL)字符串，将组件重新组合为URL，并将相对URL转换为基本URL的绝对URL。 urlllib.errorurllib.error，由urllib.request引起的异常类该模块定义了由urllib.request引发的异常类。 urllib.robotparserurllib.robotparser，解析robot.txt此模块提供了一个RobotFileParser类，它回答了有关特定用户代理是否可以在发布robots.txt文件的Web站点上获取URL的问题。 httphttp，HTTP模块 http.clienthttp.client，HTTP协议客户端该模块定义了实现HTTP和HTTPS协议客户端的类。 ftplibftplib，FTP协议客户端此模块定义了FTP类和一些相关项。FTP类实现了FTP协议的客户端。 poplibpoplib，POP3协议客户端此模块定义了POP3类，它封装了一个到POP3服务器的连接，并实现了该协议。 imaplibimaplib，IMAP4协议客户端此模块定义了三个类，封装一个到IMAP服务器的连接，并实现IAP4客户端协议的大部分子集。 nntplibnntplib，NNTP协议客户端此模块定义了NNTP类，它实现网络新闻传输协议(NNTP)客户端。 smtplibsmtplib模块，SMTP协议客户端此模块定义了一个SMTP客户端会话对象，可使用SMTP守护进程发送邮件给任一互联网计算机。 12345678910111213import smtplib#send = smtplib.STMP('smtp.example.com', port=xxx)send = smtplib.SMTP_SSL(‘smpt.exmail.qq.com’, 465)send.helo()#(250, b'smtp.qq.com')#登录需要提前设置邮箱授权码，使用授权码作为密码登录send.login(user, passed)send.sendmail(from, to, message)send.quti() smtpdsmtpd，SMTP服务器该模块提供了几个类来实现SMTP服务器。 telnetlibtelnetlib，Telnet客户端此模块提供了一个telnet类，用于执行Telnet协议。 uuiduuid，UUID对象此模块提供了不可修改的UUID对象和uuid[1-5]函数。 socketserversocketserver，一个网络服务器的框架此模块简化了编写网络服务器的任务。 http.serverhttp.server，HTTP服务器此模块定义了类，用于实现HTTP服务器。 http.cookiehttp.cookie，HTTP状态管理此模块定义了类，用于抽象cookie概念(HTTP状态管理机制)。 http.cookiejarhttp.cookiejar，HTTP客户端的cookie处理此模块定义了类，用于自动处理HTTPcookie。 xmlrpcxmlrpc，XMLRPC服务器和客户端模块XML-RPC是一种远程过程调用方法，它使用通过HTTP传递的XML传输。 xmlrpc.clientxmlrpc.client，XML-RPC客户端访问 xmlrpc.serverxmlrpc.server，基本的XML-RPC服务器 ipaddressipaddress，IPv4/IPv6操作库此模块提供了创建、修改和操作IPv4和IPv6和网络的功能。 多媒体服务本章介绍的模块，实现了用于多媒体应用的各种算法和接口。 audioopaudioop，操作原始音频数据此模块包含一些对声音片段有用的操作。 aifcaifc，读写AIFF和AIFC文件此模块提供了对读写AIFF和AIFC文件的支持。 AIFF is Audio Interchange File Format 一种用于将数字音频样本存储在文件中的格式 AIFC是一种更新的格式，包括压缩音频数据 sunausunau，读写Sun AU文件此模块为Sun AU声音格式提供了一个便利的接口。 wavewave，读写WAV文件此模块为WAV声音格式提供了一个便利的接口。 chunkchunk，读取IFF分块数据此模块为读取使用EA IFF块的文件提供了接口。 colorsyscolorsys，颜色系统之家的转换此模块定义了计算机显示器RGB和其它三个坐标系统：YIQ, HLS, HSV中使用的RGB颜色空间中表示的颜色之间的颜色值的双向转换。 imghdrimghdr，确定图像类型此模块确定文件或字节流中包含的图像类型。 sndhdrsndhdr，确定声音文件类型此模块提供了实用功能，视图确定文件中的声音数据类型。 ossaudiodevossaudiodev，访问与OSS兼容的音频设备此模块允许你访问OSS(open sound system)音频接口。OSS是Linux和FreeBSD的标准音频接口。 语言环境本章介绍的模块，可帮助你编写独立于语言和语言环境的软件。 gettextgettext，多语言国际化服务此模块为你的Python模块和应用程序提供了国际化和本地化服务。 localelocale语言环境模块，打开对POSIX语言环境数据库和功能的访问。 程序框架本章介绍的模块，是基本上决定程序结构的框架。 turtleturtle，乌龟图形乌龟图形是向孩子们介绍编程的一种流行方式。 cmdcmd，支持面向行的命令解释器此类为编写面向行的命令解释器提供了一个简单的框架。 shlexshlex，简单的词法分析此类可以容易地编写词法分析器，以获得类似Unix shell的简单语法。 带有Tk的图形用户界面Tk/Tcl是Python的一部分。它提供了一个强大且独立于平台的窗口工具包，可供Python程序员使用的tkinter包。 Tcl(Tool Command Language)，是一种脚本语言 Tk，是基于Tcl的图形界面开发工具箱 tkintertkinter，与Tcl/Tk的Python接口此包是到Tk GUI工具箱的标准Python接口。 tkinter.ttktkinter.ttk，Tk主题小部件此模块提供了对Tk主题小部件集的访问。 tkinter.tixtkinter，Tk扩展小工具此模块提供了一组额外的小工具。 tkinter.scrolledtext滚动(scrolled)文本工具此模块提供了一个相同名称的类，它实现了基本的文本小部件，具有一个垂直滚动条，用于执行正确的事情。 IDELIDEL是Python的集成开发和学习环境。 其它GUI包 PyGObject PyGTK PyQt PySide wxPython 开发工具本章介绍的模块可帮助你你编写软件。 开发高质量软件的一种方法是在开发过程中为每个函数编写测试，并在开发过程中频繁运行这些测试。 typingtyping，支持类型提示此模块支持PEP 484指定的类型提示。 pydocpydoc，文档生成器和在线帮助系统此模块从Python模块自动生成文档，文档可作为控制台上的文本页面呈现，提供个Web浏览器或保存到HTML文件。 doctestdoctest模块，测试交互式Python示例此模块搜索类似于交互式Python会话的文本片段，然后执行这些会话以验证它们是否完全安装所示工作。 unittestunittest，单元测试框架 2to32to3，自动翻译Python2-3代码获取Python2源代码并应用一系列修复程序将其转换为有效的Python3代码。 testtest，用于Python的回归测试包此包包含了Python的所有回归测试。 test.supporttest.support，Python测试套件功能 调试和分析 调试器(Debugger)使你能遍历代码，分析堆栈并设置断点 分析器(Profiler)运行代码并给出执行时间的详细分类，使你识别程序中的瓶颈 bdbbdb，调试器框架此模块处理基本的调试器功能。 faulthandlerfaulthandler，转储Python回溯(traceback) pdbpdb，Python调试器此模块为Python程序定义了一个交互式源代码调试器。 Python分析器cProfile和profile提供了Python程序的确定性分析。 timeittimeit模块，测量小代码片段的执行时间此模块提供了一个简单的方法类计算一小段Python代码的时间。 123&gt;&gt;&gt; from timeit import Timer&gt;&gt;&gt; Timer('a,b = b,a', 'a=1; b=2').timeit()0.020318730967119336 tracetrace，追踪Python语句的执行此模块允许你追踪程序执行，生成带注释的语句覆盖列表，打印调用关系和在程序运行期间执行的函数列表。 tracemalloctracemalloc，追踪内存分配此模块是一个追踪由Python分配的内存块的调试工具。 软件打包和分发这些库可帮助你发布和安装Python软件。这些模块被设计来与PyPi结合使用，但它们也可以与本地索引服务器一起使用，或根本不需要任何索引服务器。 distutilsdistutils，构建和安装Python模块此软件包为构建和安装其它模块到Python提供支持。 ensurepipensurepip，引导pip安装程序此软件包支持将pip安装程序引导到现有的Python或虚拟环境中。 venvvenv，创建虚拟环境此模块为创建轻量虚拟环境提供支持，可选地域系统目录隔离。 zipappzipapp，管理可执行的python zip归档Python提供了管理创建包含Python代码的zip文件的工具。 Python服务组件本章介绍的模块，提供了与Python解释器及其与环境交互相关的各种服务。 syssys模块，系统特定的参数和功能此模块提供了对解释器使用或维护的一些变量以及与解释器交互的函数非访问。 命令行参数 12import sysprint(sys.argv) 错误输出重定向和程序终止(termination)sys模块还具有stdin, stdout, stderr属性。 12&gt;&gt;&gt; sys.stderr.write('Warning, log file not found starting a new one\n')Warning, log file not found starting a new one sysconfigsysconfig，提供对Python配置信息的访问此模块提供对Python配置信息的访问，如安装路径列表和当前平台相关的配置变量。 builtinsbuiltins，内建对象此模块提供了对Python所有内置标识符的直接访问。例如，builtins.open是内建函数open()的全名。 __main____main__，顶级脚本环境__main__是顶级代码执行的范围的名称。从标准输入、脚本或交互式提示读取时，模块的__name__设置为等于__main__ warningswarnings，警告控制警告信息通常在有用的情况下发出，以提醒用户程序中的某些条件，该条件不能保证引发异常并终止程序。Python程序员通过调用此模块中的warn()函数来发出警告。 contextlibcontextlib，with语句上下文实用程序此模块为涉及with语句的常见任务提供使用程序。 abcabc，抽象基类(Abstract Base Classes)此模块提供了在Python中定义抽象基类的基础结构。 atexitatexit，退出处理程序此模块定义了注册和注销清理函数的函数。 tracebacktraceback，打印或取回堆栈回溯该模块提供了一个标准接口，用来提取、格式化和打印Python程序的堆栈追踪。 __future____future__，未来的声明定义 gcgc，垃圾收集器接口(Garbage Collector interface)此模块为可选的垃圾收集器提供了一个接口。 inspectinspect，检查活对象(Inspect live objects)此模块提供了几个有用的功能来帮助获取有关活动对象的信息，如模块、类、函数、回溯、框架对象和代码对象。 sitesite，Site-specific configuration hook fpectlfpectl，浮点异常控制(Floating point exception control) 自定义Python解释器本章介绍的模块，允许编写类似于Python的交互式解释器接口。 codecode，解释器基本类此模块提供了一些工具，来实现Python的read-eval-print循环。 codeopcodeop，编译Python代码此模块提供了实用程序，用于模拟Python read-eval-print循环，像code模块中做的那样 导入模块本章介绍的模块，提供了导入其它Python模块和以自定义导入进程的hook的新方法。 zipimportzipimport，从zip归档文件导入模块此模块增加了从Zip格式的归档中导入Python模块和软件包的功能。通常不需要明确使用zipimport模块，内置导入机制将自动使用zip归档文件的路径(sys.path)。 pkgutilpkgutil，包扩展程序此模块为导入system提供实用程序，尤其是软件包的支持。 modulefindermodulefinder，查找脚本使用的模块此模块可用于确定脚本导入的模块集。 runpyrunpy，定位和执行Python模块此模块用于定位和运行Python模块，而不必先导入它们。 importlibimportlib，执行import此软件包有两个目的： 在Python源代码中提供import语句的实现(__import__函数) 实现import组件暴露在此软件包中，使用户更容易创建它们自己的定制对象参与导入过程 Python语言服务Python提供了许多模块来协助处理Python语言。包括： 标记 解析 语法分析 字节码反汇编 … parserparser，访问Python解析树此模块为python内部解析器和字节码编译器提供了一个接口。 astast，抽象语法树(Abstract Syntax Trees)此模块帮助Python应用程序处理Python抽象语法的树。 symtablesymtable，访问编译器的符号符号表由AST编译器在字节码生成之前生成。 symbolsymbol，用于Python解析的常量该模块提供了，表示解析树内部节点数值的常量。 tokentoken，与Python解析树一起使用的常量此模块提供了，表示解析树(终端令牌)的叶子节点数值的常量。 keywordkeyword，测试Python关键字此模块允许Python程序确定字符串是否为关键字。 tokenizetokenize，用于Python源代码的令牌器此模块为Python源代码提供了一个用Python实现的语言扫描器。 tabnannytabnanny，检查不明确的缩进(Detection of ambiguous indentation) pyclbrpyclbr，Python类浏览器支持此模块可用于，确定有关模块中定义的类、方法和顶级函数的一些限制信息。 py_compilepy_compile，编译Python源文件此模块提供了功能，从源文件生成字节码文件，以及当模块源文件作为脚本被调用时使用。 compileallcompileall，字节编译Python库此模块提供了实用功能来支持安装Python库。 disdis，用于Python字节码的反汇编器此模块支持通过反汇编来支持CPython字节码的分析。 pickletoolspickletools，pickle开发者的工具此模块包含了各种常量，涉及到pickle模块的细节，一些关于实现的冗长的评论，一些用于分析pickle数据的有用函数。 杂项服务本章介绍的模块，提供了在所有Python版本中可用的杂项(miscellaneous)服务。 formatterformatter，通用输出格式此模块支持两种接口定义，每种都有多种实现方式： 格式化接口 格式化接口所需的写入接口 Windows特定服务本章介绍的模块仅可在MS windows平台上可获取。 msilibmsillib，读写微软安装程序文件此模块支持创建Microsoft Installer (.msi) 文件。 msvcrtmsvcrt，MS VC++运行时的有用例程此函数可访问Windows平台上的一些有用功能。 winregwinreg，Windows注册表访问此模块将Windows注册表的API暴露给Python。 winsoundwinsound，Windows的声音播放接口此模块提供了对Windows平台提供的基本声音播放机器的访问。 Unix特定服务本章介绍的模块，提供了Unix操作系统(Unix-Like)特有的功能的接口。 posixposix，最基本的POSIX系统调用此模块提供了对由C标准和POSIX标准 标准化的操作系统功能的访问。 pwdpwd， The password database此模块提供了对Unix用户账户和密码数据库的访问。 1234import pwdpwd.getpwdnam('zhang')pwd.struct_passwd(pw_name='zhang', pw_passwd='x', pw_uid=1000, pw_gid=1000, pw_gecos='zhang', pw_dir='/home/zhang', pw_shell='/bin/bash') spwdspwd，The shadow password database此模块提供了对Unix shadow password database的访问。 grpgrp，The group database此模块提供了对Unix group database的访问。 cryptcrypt，Function to check Unix passwords此模块实现crypt(3)例程的接口，该例程是基于修改的DES算法的单向散列函数。 termiostermios，POSIX风格的tty控件此模块提供了一个接口，用于I/O控制的POSIX调用。 ttytty，终端控制函数此模块定义了将tty置入cbreak和raw模式的函数。 ptypty，伪(Pseudo)终端程序此模块定义了处理伪终端概念的操作： 启动另一个进程并以编程方式写入和读取其控制终端。 fcntlfcntl，The fcntl and ioctl system calls此模块对文件描述符执行文件控制和I/O控制。 pipespipes，shell pipelines的接口此模块定义了一个类来抽象管道的概念——从一个文件到另一个文件的一系列转换器。 resourceresource，资源使用信息此模块提供了测量和控制程序使用系统资源的基本机制。 syslogsyslog，Unix syslog library routines此模块为Unix系统日志库例程提供了一个接口。 第三方库基本上可将第三方库理解为开源库！ Awesome-Python: https://github.com/jobbole/awesome-python-cnPyPI: https://pypi.org/ 系统管理 sh Watchdog 数据库 PyMySQL pymongo redis PyMySQLPyMySQL：https://pypi.org/project/PyMySQL/ 首先创建数据库 1234567CREATE TABLE `users` ( `id` int(11) NOT NULL AUTO_INCREMENT, `email` varchar(255) COLLATE utf8_bin NOT NULL, `password` varchar(255) COLLATE utf8_bin NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_binAUTO_INCREMENT=1 ; 连接 1234567891011121314151617181920212223242526import pymysqlconnection = pymysql.connect( host='localhost', user='username', password='password', port=3306, db='DBname', charset='utf8', cursorclass=pymysql.cursors.DictCursor)try: with connection.cursor() as cursor: sql = "INSERT INTO `users` (`email`, `password`) VALUES (%s, %s)" cursor.execute(sql, ('webmaster@python.org', 'very-secret')) #commit to save connection.commit() with connection.cursor() as cursor: sql = "SELECT `id`, `password` FROM `users` WHERE `email`=%s" cursor.execute(sql, ('webmaster@python.org',)) result = cursor.fetchone() print(result)finally: connection.close() pyMongopyMongo Docs: https://api.mongodb.com/python/current/ pyMongo是一个用于使用MongoDB的工具的Python发行版，并且是从Python工作于MongoDB的推荐方式。 依赖 mongodb pyMongo 连接 1234567891011from pymongo import MongoClient#host and portclient = MongoClient('localhost', 27017)#url formatclient = MongoClient('mongodb://localhost:27017')#认证client = MongoClient(host='localhost', port=27017, username='user', password='pass') 获取数据库 12345db = client.$&#123;database&#125;#ordb = client['$&#123;database&#125;'] 获取集合 1234collection = db.$&#123;collection&#125;#orcollection = db['$&#123;collection&#125;'] 文档 123456789import datetimepost = &#123; '_id': 'post01', 'author': 'Zhang21', 'text': 'My first post!', 'tags': [ 'mongodb', 'python', 'pymongo' ], 'date': datetime.datetime.now()&#125; 插入文档 123456#新建集合$&#123;collection&#125; = db.posts$&#123;collection&#125;.insert_one(post)#已有集合collection.insert_one(post) 批量插入 123456789101112131415161718new_post = [ &#123; '_id': 'post02', 'author': 'Zhang02', 'text': '2nd post', 'tags': ['bulk', 'insert'], 'date': datetime.datetime.now() &#125;, &#123; '_id': 'post03', 'author': 'Zhang03', 'text': '3rd post', 'tags': ['bulk', 'insert'], 'date': datetime.datetime.now() &#125;]collection.insert_many(new_post) 获取文档 12345678910collection.find_one()collection.find_one(&#123; '_id': 'post01'&#125;)#orcollection.find_one(&#123;'author': 'Zhang21'&#125;)import pprintpprint.pprint(collection.find_one(&#123; '_id': 'post01'&#125;)) 查询多个文档 12345678910111213141516171819202122232425262728293031323334for post in collection.find(): pprint.pprint(post)&#123;'_id': 'post01', 'author': 'Zhang21', 'date': datetime.datetime(2018, 6, 14, 11, 13, 11, 372000), 'tags': ['mongodb', 'python', 'pymongo'], 'text': 'My first post!'&#125;&#123;'_id': 'post02', 'author': 'Zhang02', 'date': datetime.datetime(2018, 6, 14, 11, 34, 47, 93000), 'tags': ['bulk', 'insert'], 'text': '2nd post'&#125;&#123;'_id': 'post03', 'author': 'Zhang03', 'date': datetime.datetime(2018, 6, 14, 11, 34, 47, 93000), 'tags': ['bulk', 'insert'], 'text': '3rd post'&#125;#orfor post in collection.find(&#123;'tags': ['bulk', 'insert']&#125;): pprint.pprint(post)&#123;'_id': 'post02', 'author': 'Zhang02', 'date': datetime.datetime(2018, 6, 14, 11, 34, 47, 93000), 'tags': ['bulk', 'insert'], 'text': '2nd post'&#125;&#123;'_id': 'post03', 'author': 'Zhang03', 'date': datetime.datetime(2018, 6, 14, 11, 34, 47, 93000), 'tags': ['bulk', 'insert'], 'text': '3rd post'&#125; 删除文档 12345collection.delete_one(&#123;"_id" : "post01"&#125;)#删除多个collection.delete_many(&#123;"_id" : "post02", "_id" : "post03"&#125;) 计数 12345collection.count()3collection.count(&#123;'tags': ['bulk', 'insert']&#125;)2 **索引 1234result = db.profiles.create_index([('user_id', pymongo.ASCENDING)], unique=True)sorted(list(db.profiles.index_information()))[u'_id_', u'user_id_1'] redisThe Python interface to the Redis key-value store.redis模块: https://pypi.org/project/redis/ redis模块提供两个类Redis和StrictRedis用于实现Redis的命令: redis.Strictredis(推荐)StrictRedis用于实现大部分官方的命令，并使用官方的语法和命令 123help(redis.StrictRedis)__init__(self, host=&apos;localhost&apos;, port=6379, db=0, password=None, socket_timeout=None, socket_connect_timeout=None, socket_keepalive=None, socket_keepalive_options=None, connection_pool=None, unix_socket_path=None, encoding=&apos;utf-8&apos;, encoding_errors=&apos;strict&apos;, charset=None, errors=None, decode_responses=False, retry_on_timeout=False, ssl=False, ssl_keyfile=None, ssl_certfile=None, ssl_cert_reqs=None, ssl_ca_certs=None, max_connections=None) redis.Redis(不推荐)Redis是StrictRedis的子类，用于向后兼容旧版本的redis模块 连接 12345678910111213141516171819202122232425import redisr = redis.StrictRedis()#orr = redis.StrictRedis(host='localhost', port=6379, db=0, password='password')#字符串操作r.set('name', 'Zhang21')r.get('name')r.type('name')r.delete('name')#列表操作r.rpush('LIST', 'list-01', 'list-02')r.type('LIST')r.llen('LIST')#help(r.lrane)#lrange(name, start, end)lrange('LIST', 0, -1)#其它redis数据类型操作方法类同 Connection Pools假设Redis服务器与客户端分处在异地，虽然基于内存的Redis数据库有着超高的性能，但是底层的网络通信却占用了一次数据请求的大量时间，因为每次数据交互都需要先建立连接，假设一次数据交互总共用时30ms，超高性能的Redis数据库处理数据所花的时间可能不到1ms，也即是说前期的连接占用了29ms，连接池则可以实现在客户端建立多个链接并且不释放，当需要使用连接的时候通过一定的算法获取已经建立的连接，使用完了以后则还给连接池，这就免去了数据库连接所占用的时间。 1234567#help(redis.ConnectionPool)pool = redis.ConnectionPool()#orpool = redis.ConnectionPool(host='localhost', port=6379, db=0, passeord='password')r = redis.StrictRedis(connection_pool=pool) Web抓取 request BeautifulSoup selenium requests从Internet上下载文件和网页。 12345678910import requests, pprint#help(requests)r = request.get(&apos;https://www.baidu.com&apos;)r.status_coder.headersr.urlr.textpprint.pprint(r.text) beautifulsoup解析HTML 123pip3 install beautifulsoup4import bs4 栗子：12345678import requests, bs4r = request.get(&apos;https://www.baidu.com&apos;)soup = bs4.BeautifulSoup(r.text)type(soup)#soup.select()#soup.find() selenium启动并控制一个Web浏览器。selenium能够填写表单，并模拟鼠标在此浏览器找那个点击 1234from selenium import webdriverbrowser = webdriver.Firefox()browser.get(&apos;https://www.baidu.com&apos;) 文档处理 openpyxl PyPDF2 pytho-docx openpyxlopenpyxl is a Python library to read/write Excel 2010 xlsx/xlsm/xltx/xltm files. 关于Excel电子表格：一个Excel电子表格文档称为一个工作簿。一个工作簿保存在扩展名为.xlsx的文件中。每个工作簿可以包含多个表(工作表)。用户当前查看的表被称为活动表。每个表有一些列(地址为从A开始的字母)，一些行(地址从1开始的数字)。在特定行和列的方格被称为单元格。单元格形成的网格和数据构成了表。 1234567891011121314151617181920212223242526272829pip3 install openpyxlimport openpyxlworkbook = openpyxl.load_workbook(&apos;/tmp/test.xlsx&apos;)type(workbook)#&lt;class &apos;openpyxl.workbook.workbook.Workbook&apos;&gt;workbook.get_sheet_names()#[&apos;Sheet1&apos;, &apos;Sheet2&apos;, &apos;Sheet3&apos;]sheet1 = workbook.get_sheet_by_name(&apos;Sheet1&apos;)type(sheet1)sheet1.title#&apos;Sheet1&apos;workbook.get_active_sheet()#&lt;Worksheet &quot;Sheet1&quot;&gt;sheet1[&apos;A1&apos;].value#&apos;1A&apos;sheet1[&apos;A1&apos;].row#1sheet1[&apos;A1&apos;].colume#Asheet1.cell(row=2, column=2).value#2B PyPDF2PDF和Word文档是二进制文件，它们比文本文件要复制得多。 1234567891011pip3 install PyPDF2import PyPDF2pdfFile = open(&apos;/tmp/test.pdf&apos;, &apos;rb&apos;)pdfReader = PyPDF2.pdfFileReader(pdfFile)pdfWriter = PyPDF2.pdfFileWriter()page = pdfReader.getPage()page.extractText() python-docx利用python-docx模块，Python可创建和修改Word文档，它带有.docx文件扩展名。 1234567891011121314151617181920212223242526pip3 insntall python-docximport docxdoc = docx.Document(&apos;/tmp/test.docx&apos;)len(doc.paragraphs)#paragraphs和run属性doc.paragraphs[0].textdoc.paragraphs[0].run[0].text#写入doc.add_paragraph(&apos;Add line01&apos;)doc.add_paragraph(&apos;Add line02&apos;).add_run(&apos;tail !&apos;)doc.save(&apos;/tmp/test.docx&apos;)#标题doc.add_heading(&apos;Header 0&apos;, 0)doc.add_heading(&apos;Header 4&apos;, 4)#分页doc.add_page_broke()#图像doc.add_picture(xxx) 图像处理 pillow(PIL) pillowPIL - the Python Imaging Library. 请了解RGB和CMYK颜色方式。 123pip3 install pillowimport PIL 日志处理 elasticsearch elasticsearchPython Elasticsearch Client pypi: https://pypi.org/project/elasticsearchgithub: https://github.com/elastic/elasticsearch-pydocs: https://elasticsearch-py.readthedocs.io 几个ES概念： index document type id 安装: 1pip3 install elasticsearch 栗子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475from datetime import datetimefrom elasticsearch import Elasticsearch#curl localhost:9200/?pretty#default http://localhost:9200es=Elasticsearch()es.info()#auth#es=Elasticsearch('https://url:port', http_auth=('elastic', 'passwd'))#es.info#sslfrom ssl import create_default_contextes = Elasticsearch('https://url:port', ssl_context=context, http_auth=('ealstic', 'passwd'))#es.index#es.create#es.update#es.delete#创建索引es.indices.create(index='my-index')#&#123;'acknowledged': True, 'shards_acknowledged': True, 'index': 'my-index'&#125;#curl localhost:9200/_cat/indices#添加或修改某个索引的文档格式es.index(index='my-index', doc_type='test-type', id=2018, body=&#123;'any': 'data', 'timestamp': datetime.now()&#125;)#es.create(index='my-index', doc_type='test-type', id=2018, body=&#123;'any': 'data', 'timestamp': datetime.now()&#125;)#&#123;'result': 'created', '_primary_term': 1, '_index': 'my-index', '_shards': &#123;'total': 2, 'failed': 0, 'successful': 1&#125;, '_type': 'test-type', '_id': '2018', '_version': 1, '_seq_no': 0&#125;#查看索引es.get(index='my-index', doc_type='test-type', id=2018)#&#123;'_index': 'my-index', '_source': &#123;'timestamp': '2018-07-18T11:34:49.573721', 'any': 'data'&#125;, '_type': 'test-type', 'found': True, '_id': '2018', '_version': 1&#125;#不指定id，es会自动生成，但查询时候需要iddata=&#123; 'timestamp': datetime.now(), 'name': 'zhang21', 'msg': 'Hello'&#125;es.index(index='my-index', doc_type='test-type', body=data)#&#123;'result': 'created', '_primary_term': 1, '_index': 'my-index', '_shards': &#123;'total': 2, 'failed': 0, 'successful': 1&#125;, '_type': 'test-type', '_id': 'C_vnq2QBmuTERb-Wz39W', '_version': 1, '_seq_no': 0&#125;es.get(index='my-index', doc_type='test-type', id='C_vnq2QBmuTERb-Wz39W')#&#123;'_index': 'my-index', '_source': &#123;'name': 'Zhang21', 'timestamp': '2018-07-18T13:40:04.005192', 'msg': 'Hello'&#125;, '_type': 'test-type', 'found': True, '_id': 'C_vnq2QBmuTERb-Wz39W', '_version': 1&#125;#查询es.search(index='my-index')#批量操作from elasticsearch import helperhelp(helper.bulk)#bulk()支持index, create, delete, upsate动作package=[]for i in range(5): rom=&#123; 'count': i, 'timestamp': datetime.now() &#125; package.append(row)actions=[ &#123; '_op_type': 'index', '_index': 'my-index', '_type': 'test-type', '_source': i &#125; for i in package]pprint(actions)helpers.bulk(es, actions)pprint(es.search(index='my-index')) 具体信息请查看文档！ 数据分析基于《Python Data Analysis》一书！强烈建议使用Anaconda安装Python和Jupyter。 ipython jupyter pandas numpy statsmodels matplotlib Anaconda site: doc: 参考: Anaconda 是一种Python语言的免费增值开源发行版，用于进行大规模数据处理, 预测分析, 和科学计算, 致力于简化包的管理和部署。Anaconda使用软件包管理系统Conda进行包管理。你可能已经安装了Python，那为什么还需要Anaconda？ Anaconda附带了一大批常用的数据科学包 Conda管理包 管理环境 安装到官网下载不同平台的包进行安装。 1234567891011wget https://repo.anaconda.com/archive/Anaconda3-5.2.0-Linux-x86_64.shbash ./Anaconda3-5.2.0-Linux-x86_64.sh#之后可设置安装路径和环境变量#查看conda --version#更新所有包conda upgrade --all 包管理conda is a tool for managing and deploying applications, environments and packages. 123456789101112131415161718192021#它会自动安装依赖#其实和pip差不多conda install &lt;package&gt;conda install requests=1.10.0conda install pandas numpy#卸载conda remove &lt;package&gt;#更新conda update &lt;package&gt;conda update &lt;package&gt; --all#列出conda list#搜索conda search 环境管理为不同项目创建不同的运行环境。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#conda create -h#创建环境#默认为 ~/.conda/envs/&lt;evn_name&gt;conda create -n &lt;env_name&gt; &lt;package_names&gt;conda create -n py3 pandas#指定Python版本conda create -n py3 python=3conda create -n py2 python=2conda create -n py36 python=3.6#使用环境source activate &lt;env_name&gt;#或conda activeate &lt;env_name&gt;#关闭环境source deactivate#或conda deactivate#自定义目录conda create -p /path/py2 python=2.7#删除环境conda env remove -n &lt;env_name&gt;#列出环境conda env list#查看环境库conda list -n &lt;env_name&gt;#环境变量#导出cond env export &gt; envName.yaml#或pip freeze &gt; evnName.txt#导入conda env update -f=/path/envName.yaml#或pip install -r /path/envName.txt#列出conda env list ipython site: github: pypi: Python Shell有很多弊端，所以使用功能更强大的ipython。ipython提供了丰富的工具包，可帮助你以交互的方式充分利用Python: 强大的交互式Shell Jupyter的内核 支持交互式数据可视化和GUI工具箱 灵活，可嵌入式的解释器，可加载到自己的项目中 使用方便，高性能的并行计算工具 安装: 1234567891011#bashsudo pip3 install ipython#使用Anacondaconda install ipython#启动ipythonPython 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 17:14:51)Type 'copyright', 'credits' or 'license' for more informationIPython 6.5.0 -- An enhanced Interactive Python. Type '?' for help jupyter site: github: pypi: Jupyter notebook是一种Web应用，能让用户将说明文本、数学方程、代码和可视化内容全部组合到一个易于共享的文档中。 安装 1234567891011121314#bashsudo pip3 install jupyter#Anacondaconda install jupyter#运行jupyter notebook --no-browser --ip=0.0.0.0#建议先设置密码jupyter notebook passwordjupyter notebook --no-browser --ip=192.168.31.119 --notebook-dir=/tmp/notebook 打开浏览器访问，输入密码： Anaconda虚拟环境目录： 栗子：]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elatic Stack]]></title>
    <url>%2F2018%2F04%2F15%2FElastic%2F</url>
    <content type="text"><![CDATA[参考： Elastic指南: https://www.elastic.co/guide/index.html Elasticsearch文档: https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html Logstash文档: https://www.elastic.co/guide/en/logstash/current/index.html Kibana文档: https://www.elastic.co/guide/en/kibana/current/index.html Filebeat文档: https://www.elastic.co/guide/en/beats/filebeat/index.html Metricbeat文档: https://www.elastic.co/guide/en/beats/metricbeat/current/index.html Lucence查询语法: https://wizardforcel.gitbooks.io/mastering-elasticsearch/content/chapter-1/114_README.html 环境： CentOS7.x86_64 Elastcisearch v6.2.3 Kibana v6.2.3 Logstash v6.2.3 Beats v6.2.3 综述开源的 Elastic Stack:能够安全可靠地获取任何来源、任何格式的数据，并且能够实时地对数据进行搜索、分析和可视化。 Elastic指的是elastic公司下的几款产品： Elasticsearch Logstash Kibana Beats X-Pack Elasticsearch 开放源码且自由使用 License: Apache License 2.0 GitHub: https://github.com/elastic/elasticsearch Doc: https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html 搜索、分析和存储您的数据。Elasticsearch 是基于 JSON 的分布式搜索和分析引擎，专为实现水平扩展、高可用和管理便捷性而设计。Elasticsearch 是一个分布式的 RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为 Elastic Stack 的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况。 基于Lucene。Lucene是一套用于全文检索和搜寻的开放源码程式库，由Apache软件基金会支持和提供。Lucene提供了一个简单却强大的应用程式介面，能够做全文索引和搜寻，在Java开发环境里Lucene是一个成熟的免费开放原始码工具；就其本身而论，Lucene是现在并且是这几年，最受欢迎的免费Java资讯检索程式库。 Logstash 开放源码且自由使用 GitHub: https://github.com/elastic/logstash Doc: https://www.elastic.co/guide/en/logstash/current/index.html 集中、转换和存储数据Logstash 是动态数据收集管道，拥有可扩展的插件生态系统，能够与 Elasticsearch 产生强大的协同作用。Logstash 是开源的服务器端数据处理管道，能够同时 从多个来源采集数据、转换数据，然后将数据发送到您最喜欢的 “存储库” 中。（我们的存储库当然是 Elasticsearch。） Kibana 开放源码且自由使用 GitHub: https://github.com/elastic/kibana Doc: https://www.elastic.co/guide/en/kibana/current/index.html 实现数据可视化Kibana 让您能够可视化 Elasticsearch 中的数据并操作 Elastic Stack，因此您可以在这里解开任何疑问：例如，为何会在凌晨 2:00 被传呼，雨水会对季度数据造成怎样的影响。 Beats 开放源码且自由使用 GitHub: https://github.com/elastic/beats Doc: https://www.elastic.co/guide/en/beats/libbeat/current/index.html Beats 是轻量型采集器的平台，从边缘机器向 Logstash 和 Elasticsearch 发送数据。Beats 平台集合了多种单一用途数据采集器。这些采集器安装后可用作轻量型代理，从成百上千或成千上万台机器向 Logstash 或 Elasticsearch 发送数据。 X-Pack Doc: https://www.elastic.co/guide/en/x-pack/current/index.html 一个程序包，带来丰富的可能性单就其自身而言，Elastic Stack 就是一款值得考虑的强大工具。X-Pack 将诸多强大功能集合到一个单独的程序包中，更将它带上了一个新的层次。X-Pack 是集成了多种便捷功能的单个插件 — security、alerting、monitoring、reporting、graph 探索和 machine learning — 您可以在 Elastic Stack 中放心地使用这些功能。 使用Dockerdocker hub里面有ELK的镜像，可以直接拉取使用。推荐使用官方ELK镜像。 我自己做了一个ELK的image，上传到了我的docker hub里。我自己做这个镜像不推荐，因为使用了centos7，导致了镜像很大，这应该避免。 在docker中运行centos7 直接拉取的centos没有systemd的权限，需要在运行添加docker run -id --privileged &lt;image-id&gt; /usr/sbin/init选项。 或者使用Docker Hub上CentOS提供的支持systemd的Dockerfile来构建centos: https://hub.docker.com/_/centos/其实Dockfile就是有这条命令CMD [&quot;/usr/sbin/init 123456789101112131415161718192021222324252627282930313233docker pull centosdocker image lsREPOSITORY TAG IMAGE ID CREATED SIZEcentos latest e934aafc2206 2 weeks ago 199MB#运行docker#此处如果没有/bin/bash的话，生成的container立马就停止了#端口映射什么的后面再弄docker run -d -i &lt;image-id&gt; /bin/bash#查看容器docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES27b10f5015be e934aafc2206 "/bin/bash" About an hour ago Up About an hour ecstatic_boyd#进入dockerdocke exec -it &lt;container-id&gt; /bin/bash#当然，你也可以运行SSHD，通过端口映射，连接到docker内#[root@27b10f5015be /]##在docker中安装各类需要的软件了#可能需要设置一下/etc/resolv.conf 将安装了各类软件的容器构建为一个新的镜像 12345678910111213141516171819202122232425262728293031323334#从运行的容器中重构镜像#docker commit -m "centos7+elk" &lt;container-id&gt; user/repo:tagdocker commit -m 'centos7+elk' 27b10f5015be zhang21/centos7:elk#查看新镜像docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEzhang21/centos7 elk 0b22d93f7353 16 minutes ago 1.04GBcentos latest e934aafc2206 2 weeks ago 199MB#运行新镜像docker run -id -p 80:80 9200:9200 &lt;image-id&gt; /bin/bash#此处遇到一个错，因为docker的网络是通过iptables来转发的，因此主机上不能关闭firewalld，不能无法启动容器#进入新容器docker exec -it &lt;container-id&gt; /bin/bash#此处无法使用systemctl，原因已写到前面#Failed to get D-Bus connection: Operation not permitted#获得systemd权限启动docker run -id --privileged -p 80:80 &lt;image-id&gt; /usr/sbin/init#进入docker exec -it &lt;container-id&gt; /bin/bash#启动Nginxsystemctl start nginx 将新镜像上传到Hub 我用的是Docker Hub免费版，当然线上的话可能是阿里云或腾讯云。 12345678docker login -u zhang21#上传镜像到我的Hubdocker push zhang21/centos7:elk#拉取镜像docker pull zhang21/centos7:elk 安装安装步骤： Elasticsearch Kibana Logstash Install X-Pack into Elasticsearch Install X-Pack into Kibana 安装ELKF需要依赖JDK（java），请先安装。我是直接使用的RPM包安装。 12345678910111213141516171819202122#安装Javayum install java-1.8.0-openjdk-headless-1.8.0.161-0.b14.el7_4.x86_64 -y#编写repovim /etc/yum.repo.d/elk.repo[elasticsearch-6.x]name=Elasticsearch repository for 6.x packagesbaseurl=https://artifacts.elastic.co/packages/6.x/yumgpgcheck=1gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearchenabled=1autorefresh=1type=rpm-md#安装yum install -y elasticsearch logstash kibana filebeat 由于elk默认将软件安装到/usr/share/下，因此我把它们的bin路径加入PATH。 123456789vim /etc/profileexport PATH=$PATH:/usr/share/elasticsearch/bin:/usr/share/kibana/bin:/usr/share/logstash/bin:/usr/share/elasticsearch/bin/x-pack:/usr/share/filebeat/bin#执行source /etc/profile ELKF使用RPM安装的布局说明： 主目录 /usr/share/elasticsearch /usr/share/kibana /usr/share/logstash /usr/share/filebeat 二进制文件 /usr/share/elasticsearch/bin /usr/share/kibana/bin /usr/share/logstash/bin /usr/share/filebeat/bin 配置文件 /etc/elastcisearch /etc/kibana /etc/logstash /etc/filebeat 环境变量 /etc/sysconfig/elasticsearch 插件 /usr/share/elastcisearch/plugins /usr/share/kibana/plugins 安装X-Pack 注意由于自动升级到Elastic v6.3自带了X-Pack，不需要额外安装。之前安装的一些插件会导致Elastic无法运行，请卸载这些插件。 123456elasticsearch-plugin listelasticsearch-plugin remove x-packkibana-plugin remove x-packlogstash-plugin remove x-pack 安装X-Pack前，请先安装ELK。请安装匹配版本的X-Pack。 Install X-Pack on Elasticsearch Install X-Pack on Kibana Install X-Pack on Logstash 启用或禁用X-Pack功能 有些功能默认开启，有些默认关闭。请在配置文件中查看详情。添加某些功能可能导致软件无法启动，请注意查看日志。 在以下文件中配置它们： elasticsearch.yml kibana.yml logstash.yml filebeat.yml X-Pack功能： 功能 描述 xpack.graph.enabled X-Pack图形功能 xpack.ml.enabled X-Pack机器学习功能 xpack.monitoring.enabled X-Pack监视功能 xpack.reporting.enabled X-Pack报告功能 xpack.security.enabled X-Pack安全功能 xpack.watcher.enabled X-Pack观察器 在ELK中启动X-Pack monitoring功能 123456789101112131415161718192021222324252627282930#xpack.graph.enabled#xpack.ml.enabled#xpack.monitoring.enabled#xpack.reporting.enabled#xpack.security.enabled#xpack.watcher.enabled#在Elasticsearch和kibana中禁用验证后，不用在logstash中输入，否则会报错。xpack.security.enabled: false#启用验证#具体可参考官方文档#在logstash.yml中配置xpack.monitoringxpack.monitoring.enabled: true#xpack.monitoring.elasticsearch.url: &quot;http://127.0.0.1:9200&quot;#xpack.monitoring.elasticsearch.username: logstash_system#xpack.monitoring.elasticsearch.password: logstash#在Filebeat中添加monitoringxpack.monitoring: enabled: true #elasticsearch: #url: &quot;http://localhost:9200&quot; #usernaem: &quot;elastic&quot; #password: &quot;elastic&quot; 安装：建议使用密码！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#Elastcisearch安装X-Packelasticsearch-plugin install x-pack#启动#9200, 9300端口#elasticsearch不能使用root启动，所以我把elastic用户修改为/bin/bashsu elasticsearchelasticsearch -d#elasticsearch#生成默认用户密码，此密码针对elastic和kibana用户#/usr/share/elasticsearch/bin/x-pack#将此加入PATHsetup-passwords auto#或手动输入密码setup-passwords interactiveelastic#elastickibana#kibanalogstash_system#logstash#Kibana安装X-Packkibana-plugin install x-pack#对kibana.yml添加用户和密码#此密码是前面默认生成的vim /etc/kibana/kibana.yml`elasticsearch.username: &quot;elastic&quot;elasticsearch.password: &quot;elastic&quot;#修改监听地址server.host: &quot;0.0.0.0&quot;logging.dest: /var/log/kibana/kibana.log#kibana日志默认是stdout#修改为/var/log/kibana/kibana.logmkdir /var/log/kibana#启动kibana#5601端口#kibana可用root启动kibana#或systemctl start kibana#Logstash安装X-Packlogstash-plugin install x-pack 启动ELK建议给他们加上密码！不知道为什么，我的ElasticStack都能用systemd来管理了！ 12#最便捷systemctl start elasticsearch logstash filebeat metricbeat heartbeat packetbeat auditbeat 123456789101112131415161718192021#Elasticsearchsu elasticsearch#elasticsearch，查看输出elasticsearch -d#kill -15 pid &amp;&amp; elasticsearch -d#Kibanakibana&amp;systemctl start kibana#kill -15 pid &amp;&amp; kibana&amp;#Logstash#logstash -f xxx.confsystemctl start logstash#Filebeat#filebeat -e -c filebeat.yml，查看输出信息systemctl start filebeat 启动时可能遇到的问题 can not run elasticsearch as root 专门建立一个管理ELK的用户，切换到此用户后运行，注意修改ELK相关目录权限 或者修改ELK各自用户的/etc/passwd，切换到对应用户后运行。注意权限 – su elasticsearch &amp;&amp; elasticsearch elasticsearch process is too low, increase to at least [65536] 12345678vim /etc/security/limits.conf* soft nofile 655350* hard nofile 655350ulimit -a 访问elasticsearch 123456$ip:9200#此处访问是需要用户名和密码的#使用前面X-Pack生成的默认用户名和密码elastic elastic#登录之后便可看到node，cluster相关信息 访问kibana 12#5601端口http://0.0.0.0:5601 启用xpack注意事项启用X-PACK后，请注意在kibana配置文件中认证Elasticsearch用户和密码，并且使用Elasticsearch的用户和密码登录Kibana的前端界面。 由于我使用kibana用户登录，导致很多地方访问Elasticsearch都没有权限。请注意。 这样使用Elasticsearch登录后，便可以之间在Dev Tools中通过REST API获取和更新相关信息，并且创建和管理相关用户和角色。 安装Filebeat由于前面我们添加了ELK-repo，所以这里我们可以直接安装。 12345678yum install -y filebeat#开启X-Pack monitor#默认关闭vim /etc/filebeat/filebeat.ymlxpack.monitoring.enabled: true 修改ELK jvm内存大小在此版本中，可直接在配置文件目录下的jvm.options里修改JVM 内存大小。 12345678910111213#最小-Xms#最大-Xmxvim /etc/elasticsearch/jvm.options-Xms4g-Xmx4g#其它如此 与Nginx结合使用将Kibana展现到Nginx上的话，便可以不对Kibana开放外网访问。 1234567891011121314151617181920212223242526272829303132333435363738#安装Nginxvim /etc/yum.repo.d/nginx.repo[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=0enabled=1yum install -y nginx nginx-mod-stream#配置vim /etc/nginx/conf.d/kibana.conf#可把IP换成kibana相应的域名#再将域名解析到此IPserver &#123; listen 80; server_name 172.16.129.150;#Kibana location / &#123; proxy_pass http://127.0.0.1:5601; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &apos;upgrade&apos;; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; &#125;&#125; 可能会遇到的问题 Nignx错误日志: Permission denied) while connecting to upstream 1234567891011sudo cat /var/log/audit/audit.log | grep nginx | grep denied#后来判断是SELinux的问题getenforcesetenforce 0#修改SELinuxvim /etc/selinux/configSELINUX=disabled Logstash文档 Logstash的pipeline有两个必须的元素： input 消耗来自source的数据 output 将修改后的数据写入destination 以及一个可选元素： filter 根据你的定义来修改数据 介绍Logstash是一个具有实时流水线(pipeling)功能的开源数据收集引擎。它可以动态统一来自不同source的数据，并将数据正常化的你的destination。 任何类型的事件都可以通过大量的输入、过滤和输出插件进行丰富和转换，通过本地编解码器进一步简化了摄取过程。 Logstash的能量具有强大的Elasticsearch和Kibana系统的水平可伸缩数据处理流水线。 Logstash喜欢的数据所有数据来者不拒！ Logs and Metrics 处理所有类型的日志数据 Apache Nginx Syslog 使用Filebeat享受互补的安全日志转发功能 从Ganglia, JMx, NetFlow和TCP,UDP收集metrics Web 将http request转换为events 分析Web服务 支持Webhook 通过轮询HTTP endpoint创建事件 通过Web API捕获健康状况、性能和其它类型的数据 数据存储和流从你已经拥有的数据中发现更多价值。 Sensors and IoT探索广泛的其它数据。 轻松丰富一切在摄取过程中清理并转换数据，以便在index或output时立即获得实时信息。Logstash具有许多聚合和突变以及模式匹配，地理映射和动态查找功能。 Grok是Logstash filter的金刚钻，用于从非结构化数据中派生出结构化数据 通过解析来自IP的地理坐标，标准化提起复杂性，简单K-V对和CSV数据，并通过本地查找或Elasticsearch查询进一步丰富你的数据，从而扩展你的视野 编解码器通常用于缓解JSON和多行事件等常见事件结构的处理 选择你的储藏室将数据放在最重要的位置。通过存储，分析和对数据采取行动，解锁各种downstream分析和操作用例。 Analysis Elasticsearch Data stores(MongoDB, Redis) Archiving HDFS S3 Monitoring Nagios Zabbix Ganglia Alerting Watcher(Elasticsearch) Email 入门安装，储藏，解析，汇聚多个Input/Output。 储藏第一个事件测试Logstash和运行一个基本的pipeline 12345logstash -e &apos;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123;&#125; &#125;&apos;#等待启动，输入hello world#Logstash将时间戳和主机名添加到message#2018-04-13T08:17:51.702Z zhang22 helloworld 启动logstsh时的一个问题： WARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash 虽然通过RPM安装Logstash存在/etc/logstash文件，但是还是会报错。 123cd /usr/share/logstash/binln -s /etc/logstash ./config 通过Logstash解析Logs前面我们创建了一个基本的Logstash pipeline来测试Logstash，但真正处理logs的Logstash pipeline不会这么简单，它可能会有多个input, filter, output。 本节利用一个Filebeat，将Nginx Web Logs作为Logstash pipeline的input，解析这些logs中创建的特定命名字段，并将解析的数据写入Elasticsearch集群。 配置Filebeat以发送Log Lines到Logstash 在创建Logstash pipeline之前，你将配置Filebeat以发送Log lines到Logstash。Filebeat从服务器上的文件收集日志，并将这些日志转发给Logstash实例进行处理。Filebeat专为可靠性和低延迟而设计。它占用的资源极少，beats input插件(默认安装)最大限度地减少了Logstash实例的资源需求。任何Beat框架编写的beat都可以讲事件数据发送到Logstash。 在你的data source主机上安装Filebeat。安装之后，配置filebeat.yml文件: 12345678910111213141516171819vim /etc/filebeat/filebeat.ymlfilebeat.prospectors:- type: log#需要处理的日志的路径，如Nginx paths: - /var/log/nginx/*.logoutput.logstash: hosts: [&quot;localhost:5044&quot;]#运行FilebeatFilebeat -e -c filebeat.yml -d &quot;publish&quot;#Filebeat将会尝试连接到5044端口，在Logstash以一个活动的beats plugin开始前，不会有任何应答。 为Filebeat Input配置Logstash 配置一个Logstash pipeline，使用beat input plugin接受来自beats的事件。格式如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455cd /etc/logstash/conf.dvim ./first-pipeline.confinput &#123;&#125;#filter部分可选filter &#123;&#125;output &#123;&#125;#实例input &#123; beats &#123; port =&gt; &quot;5044&quot; &#125;&#125;output &#123; stdout &#123; codec =&gt; dubydebug &#125;&#125;#验证配置logstash -f first-pipe.conf --config.tst_and_exit#消息2018-04-17T14:15:46.187+0800 ERROR pipeline/output.go:74 Failed to connect: dial tcp [::1]:5044: getsockopt: connection refused2018-04-17T14:15:46.607+0800 INFO log/harvester.go:241 File is inactive: /var/log/nginx/access.log. Closing because close_inactive of 5m0s reached.2018-04-17T14:15:46.607+0800 INFO log/harvester.go:241 File is inactive: /var/log/nginx/error.log. Closing because close_inactive of 5m0s reached.2018-04-17T14:15:46.923+0800 INFO log/harvester.go:241 File is inactive: /var/log/secure-20180409. Closing because close_inactive of 5m0s reached.2018-04-17T14:15:51.096+0800 INFO log/harvester.go:241 File is inactive: /var/log/secure-20180401. Closing because close_inactive of 5m0s reached.2018-04-17T14:15:52.687+0800 INFO log/harvester.go:241 File is inactive: /var/log/secure-20180415. Closing because close_inactive of 5m0s reached.#启动Logstash#修改配置后可动态载入logstash -f first-pipe.conf --config.reload.automatic#消息2018-04-17T14:18:41.542+0800 INFO [monitoring] log/log.go:124 Non-zero metrics in the last 30s &#123;&quot;monitoring&quot;: &#123;&quot;metrics&quot;: &#123;&quot;beat&quot;:&#123;&quot;cpu&quot;:&#123;&quot;system&quot;:&#123;&quot;ticks&quot;:150,&quot;time&quot;:159&#125;,&quot;total&quot;:&#123;&quot;ticks&quot;:450,&quot;time&quot;:468,&quot;value&quot;:450&#125;,&quot;user&quot;:&#123;&quot;ticks&quot;:300,&quot;time&quot;:309&#125;&#125;,&quot;info&quot;:&#123;&quot;ephemeral_id&quot;:&quot;84cbf5cd-dfff-4391-9631-2b8e77329696&quot;,&quot;uptime&quot;:&#123;&quot;ms&quot;:480009&#125;&#125;,&quot;memstats&quot;:&#123;&quot;gc_next&quot;:11030992,&quot;memory_alloc&quot;:6588088,&quot;memory_total&quot;:40882600&#125;&#125;,&quot;filebeat&quot;:&#123;&quot;harvester&quot;:&#123;&quot;open_files&quot;:5,&quot;running&quot;:8&#125;&#125;,&quot;libbeat&quot;:&#123;&quot;config&quot;:&#123;&quot;module&quot;:&#123;&quot;running&quot;:2&#125;&#125;,&quot;pipeline&quot;:&#123;&quot;clients&quot;:8,&quot;events&quot;:&#123;&quot;active&quot;:4118&#125;&#125;&#125;,&quot;registrar&quot;:&#123;&quot;states&quot;:&#123;&quot;current&quot;:10&#125;&#125;,&quot;system&quot;:&#123;&quot;load&quot;:&#123;&quot;1&quot;:4.86,&quot;15&quot;:4.41,&quot;5&quot;:4.53,&quot;norm&quot;:&#123;&quot;1&quot;:2.43,&quot;15&quot;:2.205,&quot;5&quot;:2.265&#125;&#125;&#125;&#125;&#125;&#125; 使用Grok filter plugin解析Web Logs 在某些时候，可能输出的日志信息的格式并不理想。你想要解析log以创建特定的命名字段。 grok过滤插件使你能够将非结构化的日志数据解析为结构化和可查询的内容。由于grok过滤器插件在传入的日志数据中查找模式，因此配置插件需要你作出关于如何识别你的用例。 你可以使用%{COMBINEDAPACHELOG} grok模式，它从如下模式的日志中构建行： 信息 Field Name IP Add clientip User ID ident User Auth auth timestamp timestamp HTTP Verb verb Request body request HTTP Status code respone Referer URL referer User agent agent 12345678910111213141516171819202122232425vim first-pipline.confinput &#123; beats &#123; port =&gt; &quot;5044&quot; &#125;&#125;filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot; &#125; &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125;&#125;#启动查看效果 通过Geoip过滤插件增强数据 除了解析日志数据以获得更好的搜索外，过滤插件还可从现有的数据中后去补充信息。geoip插件查找IP地址，从IP地址获取地理位置信息，并将该位置信息添加到日志中。 配置Logstash实例来使用geoip过滤插件: 12345678910111213141516171819202122vim first-pipeline.confinput &#123; beats &#123; port =&gt; &quot;5044&quot; &#125;&#125; filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot;&#125; &#125; geoip &#123; source =&gt; &quot;clientip&quot; &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125;&#125;#重启服务 索引数据到Elasticsearch 现在Web log已经被处理为指定的字段，现在Logstash pipeline便可以索引数据到一个Elasticsearch集群中。 1234567891011121314151617181920212223vim first-pipeline.confinput &#123; beats &#123; port =&gt; &quot;5044&quot; &#125;&#125; filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot;&#125; &#125; geoip &#123; source =&gt; &quot;clientip&quot; &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [ &quot;localhost:9200&quot; ] &#125;&#125;#重启服务 验证： 这里遇到一个错误： index_not_found_exception 这里要将logstash-$DATE反映索引的实际名称，也就是在通过下面的命令得到的logstash-2018.04.13。把我坑惨了！ 123456789101112131415curl -XGET &apos;localhost:9200/logstash-$DATE/_search?pretty&amp;q=response=200&apos;#索引名称使用的日期基于UTC，而不是Logstash正在运行的timezone#查看可用索引列表curl &apos;localhost:9200/_cat/indices?v&apos;health status index uuid pri rep docs.count docs.deleted store.size pri.store.sizeyellow open logstash-2018.04.13 dRW2veUgS2ObZmP3lepqsQ 5 1 154 0 266.6kb 266.6kbcurl -XGET &apos;localhost:9200/logstash-2018.04.13/_search?pretty&amp;q=response=200&apos; Kibana中的可视化效果： 拼接多个输入和输出插件你需要管理的信息通常来自多个不同的source，并且可能需要多个不同的destination来存储数据。Lostash pipeline可以使用多个输入和输出插件来处理这些需求。 官方文档中使用Twitter and Filebeat这两者作为Logstash input，并将信息输出到Elasticsearch和file。 配置Logstash实例使用Filebeat input plugin 配置Logstash实例写入Elasticsearch多节点(cluster) 配置Logstash pipeline将数据写入file 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#配置Filebeat发送Log Line到Logstashvim /etc/filebeat/filebeat.ymlfilebeat.prospectors:- type: log paths: - /var/log/*.log fields: type: syslogoutput.logstash: hosts: [&quot;localhost:5044&quot;]########################cd /etc/logstash/conf.dvim 2nd-pipeline.confinput &#123; twitter &#123; consumer_key =&gt; &quot;enter_your_consumer_key_here&quot; consumer_secret =&gt; &quot;enter_your_secret_here&quot; keywords =&gt; [&quot;cloud&quot;] oauth_token =&gt; &quot;enter_your_access_token_here&quot; oauth_token_secret =&gt; &quot;enter_your_access_token_secret_here&quot; &#125; beats &#123; prot =&gt; &quot;5044&quot; &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;hosts1:port1&quot;, &quot;host2:port2&quot;...] &#125; file &#123; path =&gt; &quot;/path/to/target/file&quot; &#125;&#125;#重启服务#测试，Replace $DATE with the current date, in YYYY.MM.DD format.curl -XGET &apos;localhost:9200/logstash-$DATE/_search?pretty&amp;q=fields.type:syslog&apos; Input输入插件可以使特定的事件源由Logstash读取。 可用的输入插件：我只列出了常见的，具体请参考: https://www.elastic.co/guide/en/logstash/current/input-plugins.html 插件 描述 beats 从Elastic框架接收事件 couchdb_changes 从CouchDB的_changesURI流式传输事件 dead_letter_queue 从Logstash的dead letter queue读取事件 elasticsearch 从Elasticsearch集群中读取查询结果 exec 抓取shell命令的输出作为事件 file 来自文件的流事件 github 从GitHub webhook读取事件 heartbeat 为测试生成心跳事件 http 通过HTTP/HTTPS接收事件 http_poller 解码HTTP API输出为事件 imap 从IMAP服务器读取邮件 jmx 通过JVM从java程序检索标准 kafka 从kafka中读取事件 log4j 通过TCP socket从Log4j对象读取事件 pipe 从长时间运行的命令管道中获取流事件 rabbitmq 从Redis实例读取事件 sqlite 基于SQLite数据库中的行创建事件 stdin 从标准输入中读取事件 syslog 读取系统日志作为事件 tcp 从TCP socket读取事件 udp 从UDP读取事件 unix 通过Unix socket读取事件 websocket 从一个websocket读取事件 input filter通用选项: Setting Input type Required add_field hash No codec codec No enable_metric boolean No id string No tags array No type string No add_field添加一个字段到一个事件，默认值为{} codec用于输入数据的编解码器。默认值是plain enable_metric为特定插件实例禁用或启用度量标准日志记录，默认值为true id为插件配置添加一个唯一的ID，如果未指定，Logstash会自动生成一个 tags为事件添加任意数量的任意标签 type为所有input处理的事件添加一个type beats此插件使Logstash能够从Elasticsearch框架中接收事件。 栗子： 123456789101112131415input &#123; beats &#123; port =&gt; 5044 &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; &quot;localhost:9200&quot; #hosts =&gt; [&quot;hosts1&quot;, &quot;hosts2&quot;, ...] manage_template =&gt; false index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;[@metadata][version]&#125;-%&#123;+YYYY.MM.dd&#125;&quot; document_type =&gt; &quot;%&#123;[@metadata][type]&#125;&quot; &#125;&#125; Beats Input配置项： Setting Input_type Required cipher_suites array No client_inactivity_timeout number No host string No include_codec_tag boolean No port number Yes ssl boolean No ssl_certificate a valid filesystem path No ssl_certificate_authorities array No ssl_handshake_timeout number No ssl_key a valid filesystem path No ssl_key_passphrase password No ssl_verify_mode string, one of [none, peer,force_peer] No tls_max_version number No tls_min_version number No elasticsearchElasticsearch Input配置项： Setting Input_type Required ca_file a valid filesystem path No docinfo boolean No docinfo_fields array No docinfo_target string No hosts array No index string No password password No query string No schedule string No scroll string No size number No ssl boolean No user string No 栗子： 1234567891011121314151617input &#123; elasticsearch &#123; hosts =&gt; &quot;es.production.mysite.org&quot; index =&gt; &quot;mydata-2018.09.*&quot; query =&gt; &apos;&#123; &quot;query&quot;: &#123; &quot;query_string&quot;: &#123; &quot;query&quot;: &quot;*&quot; &#125; &#125; &#125;&apos; size =&gt; 500 scroll =&gt; &quot;5m&quot; docinfo =&gt; true &#125;&#125;output &#123; elasticsearch &#123; index =&gt; &quot;copy-of-production.%&#123;[@metadata][_index]&#125;&quot; document_type =&gt; &quot;%&#123;[@metadata][_type]&#125;&quot; document_id =&gt; &quot;%&#123;[@metadata][_id]&#125;&quot; &#125;&#125; exec定期运行shell命令，并抓取整个输出为事件。 栗子： 123456input &#123; exec &#123; command =&gt; &quot;ls&quot; interval =&gt; 30 &#125;&#125; exec Input配置项： Setting Input_type Required command string Yes interval number No schedule string No 此调度表示方法如同Linux中定时任务* 5 * 1-3 *。 file从文件读取流事件。 file input配置项： Setting Input_type Required close_older number No delimiter string No discover_interval number No exclude array No ignore_older number No max_open_files number No path array Yes sincedb_path string No sincedb_write_interval number No start_position string, one of [“beginning”, “end”] No stat_interval number No githubgithub input配置项： Setting Input_type Required drop_invalid boolean No ip string No port number Yes secret_token string No kafkahttps://www.elastic.co/guide/en/logstash/current/plugins-inputs-kafka.html redis从redis实例读取事件，它支持redis的channel和list类型。 redis input配置项： Setting Input_type Required batch_count number No data_type string, one of [list,channel,pattern_channel] Yes db number No host string No path string No key string Yes password password No port number No ssl boolean No threads number No timeout number No sqlite栗子： 1234567891011input &#123; sqlite &#123; path =&gt; &quot;/tmp/example.db&quot; type =&gt; weblogs &#125;&#125;output &#123; stdout &#123; debug =&gt; true &#125;&#125; sqlite input配置项： Setting Input_type Required batch number No exclude_tables array No path string Yes stdin syslog栗子： 12345678input &#123; syslog &#123; port =&gt; 12345 codec =&gt; cef syslog_field =&gt; &quot;syslog&quot; grok_pattern =&gt; &quot;&lt;%&#123;POSINT:priority&#125;&gt;%&#123;SYSLOGTIMESTAMP:timestamp&#125; CUSTOM GROK HERE&quot; &#125;&#125; syslog input配置项： Setting Input_type Required facility_labels array No grok_pattern string No host string No locale string No port number No proxy_protocol boolean No severity_labels array No syslog_field string No timezone string No use_labels boolean No tcp栗子： 123456input &#123; tcp &#123; port =&gt; 12345 codec =&gt; json &#125;&#125; tcp input配置项： Setting Input_type Required host string No mode string, one of [server, client] No port number Yes proxy_protocol boolean No ssl_cert a valid file system path No ssl_enable boolean No ssl_extra_chain_certs array No ssl_key a valid file system path No ssl_key_passphrase password No ssl_verify boolean No udp unix websocket Output输出将事件数据发送到特定的目标。输出是事件管道的最后阶段。 输出列表： boundary circonus CSV datadog Elasticsearch email exec file gelf ganglia http/https influxdb irc kafka librato loggly lumberjack metriccatcher mongodb nagios opentsdb pipe rabbitmq redis redmine stdout syslog tcp udp websocket zabbix output通用配置项： Setting Input type Required codec codec No enable_metric boolean No id string No codec用于输出数据的编解码器，默认值是json_lines enable_metric为特定插件实例启用或禁用度量日志记录，默认值是true id为插件配置添加一个唯一的ID，如果未指定ID，Logstash会自动生成。 csvcsv output配置选项： Setting Input_type Required create_if_deleted boolean No csv_options hash No dir_mode number No fields array Yes file_mode number No filename_failure string No flush_interval number No gzip boolean No path string Yes spreadsheet_safe boolean No elasticsearchElasticsearch output配置项： Setting Input type Required action string No bulk_path string No cacert a valid filesystem path No doc_as upsert boolean No document_id string No document_type string No failure_type logging whitelist array No healthcheck_path string No hosts uri No http_compression boolean No index string No keystore a valid filesystem path No keystore_password password No manage_template boolean No parameters hash No parent string No password password No path string No pipeline string No pool_max number No pool_max per route number No proxy uri No resurrect_delay number No retry_initial interval number No retry_max_interval number No retry_on_conflict number No routing string No script string No script_lang string No script_type string, one of [inline, indexed, file] No script_var_name string No scripted_upsert boolean No sniffing boolean No sniffing_delay number No sniffing_path string No ssl boolean No ssl_certificate verification boolean No template a valid filesystem path No template_name string No template_overwrite boolean No timeout number No truststore a valid filesystem path No truststore_password password No upsert string No user string No validate_after inactivity number No version string No version_type string, one of [internal, external, external gt, external gte, force] No exec栗子： 1234567output &#123; if [type] == &quot;abuse&quot; &#123; exec &#123; command =&gt; &quot;iptables -A INPUT -s %&#123;clientip&#125; -j DROP&quot; &#125; &#125;&#125; exec output配置项： Setting Input type Required command string Yes quiet boolean No file栗子： 123456output &#123; file &#123; path =&gt; ... codec =&gt; line &#123; format =&gt; &quot;custom format: %&#123;message&#125;&quot;&#125; &#125;&#125; file output配置项： Setting Input type Required create_if_deleted boolean No dir_mode number No file_mode number No filename_failure string No flush_interval number No gzip boolean No path string Yes write_behavior string No kafka栗子： 123456output &#123; kafka &#123; codec =&gt; json topic_id =&gt; &quot;mytopic&quot; &#125;&#125; kafka output配置项： Setting Input type Required acks string, one of [0, 1, all] No batch_size number No bootstrap_servers string No buffer_memory number No client_id string No compression_type string, one of [none, gzip, snappy, lz4] No jaas_path a valid filesystem path No kerberos_config a valid filesystem path No key_serializer string No linger_ms number No max_request size number No message_key string No metadata_fetch_timeout_ms number No metadata_max_age_ms number No receive_buffer_bytes number No reconnect_backoff_ms number No request_timeout_ms string No retries number No retry_backoff_ms number No sasl_kerberos_service name string No sasl_mechanism string No security_protocol string, one of [PLAINTEXT, SSL, SASL PLAINTEXT, SASL SSL] No send_buffer_bytes number No ssl_key_password password No ssl_keystore_location a valid filesystem path No ssl_keystore_password password No ssl_keystore_type string No ssl_truststore_location a valid filesystem path No ssl_truststore_password password No ssl_truststore_type string No topic_id string Yes value_serializer string No mongodbmongodb output配置项： Setting Input type Required bulk boolean No bulk_interval number No bulk_size number No collection string Yes database string Yes generateId boolean No isodate boolean No retry_delay number No uri string Yes redis将Redis作为消息队列缓存能极大降低系统负载，减轻系统压力。 redis output配置项： Setting Input type Required batch boolean No batch_events number No batch_timeout number No congestion_interval number No congestion_threshold number No data_type string, one of [list, channel] No db number No host array No key string No password password No port number No reconnect_interval number No shuffle_hosts boolean No timeout number No redmine栗子： 1234567891011output &#123; redmine &#123; url =&gt; &quot;http://redmineserver.tld&quot; token =&gt; &apos;token&apos; project_id =&gt; 200 tracker_id =&gt; 1 status_id =&gt; 3 priority_id =&gt; 2 subject =&gt; &quot;Error ... detected&quot; &#125;&#125; redmine output配置项： Setting Input type Required assigned_to_id number No categorie_id number No description string No fixed_version_id number No parent_issue_id number No priority_id number Yes project_id number Yes ssl boolean No status_id number Yes subject string No token string Yes tracker_id number Yes url string Yes output栗子： 123output &#123; stdout &#123; codec =&gt; json &#125;&#125; syslogsyslog output配置： Setting Input type Required appname string No facility string No host string Yes message string No msgid string No port number Yes priority string No procid string No protocol string, one of [tcp, udp, ssl-tcp] No reconnect interval number No rfc string, one of [rfc3164, rfc5424] No severity string No sourcehost string No ssl_cacert a valid filesystem path No ssl_cert a valid filesystem path No ssl_key a valid filesystem path No ssl_key passphrase password No ssl_verify boolean No use_labels boolean No zabbixzabbix output配置项： Setting Input type Required multi_value array No timeout number No zabbix_host string Yes zabbix_key string No zabbix_server host string No zabbix_server port number No zabbix_value string No Filter https://www.elastic.co/guide/en/logstash/current/filter-plugins.html 过滤器插件对事件执行中介(intermediary)处理，过滤器通常根据事件的特征有条件的应用。 下面是Elastic支持的插件列表: 插件 描述 aggregate 汇总来自单个任务的多个事件的信息 alter 对mutate过滤器无法处理的字段进行常规更改 cidr 根据网络块列表检查IP地址 cipher 对事件应用或移除cipher(密码) clone 重复事件 csv 将csv(comma separated value)解析为单个字段 date 解析字段中的日期，以用作事件的Logstash timestamp de_dot Computationally expensive filter that removes dots from a field name dissect 使用分隔符将非结构化事件数据提取到字段中 dns 执行标准或反向DNS查询 drop 删除所有事件 elapsed 计算一对事件之间的经过时间 elasticsearch 将Elasticsearch中以前的日志事件的字段复制到当前事件中 environment 将环境变量存储为元数据子字段 extractnumbers 从字符串中提取数字 fingerprint 由一致的散列值的替换值的指纹字段 geoip 添加有关IP地址的地理信息 grok 将非结构化事件数据解析到字段中 i18n 从字段中删除特定字符 jdbc_static 使用从远程数据库预加载的数据来丰富事件 jdbc_streaming 用你的数据库数据丰富事件 json 解析JSON事件 json_encode 将字段序列化为JSON kv 解析键值对 metricize 处理包含多个度量标准的复杂事件并将它们分成多个事件，每个事件都包含一个度量标准 metrics 汇总指标(Aggregates metrics) mutate 对字段执行突变 prune 将基于字段列表的事件数据精简为黑名单或白名单 range 检查指定的字段是否在给定的大小或长度限制内 ruby 执行任意Ruby代码 sleep 休息一段指定的时间 split 将多行消息拆分成不同的事件 syslog_pri 解析syslog消息的优先字段 throttle 限制事件的数量 tld 用你在配置中指定的任何内容替换默认消息字段的内容 translate 根据散列或YAML文件，替换字段内容 truncate 截断长度超过给定长度的字段 urldecode 解码URL编码的字段 useragent 将用户代理字符串解析到字段中 uuid 为事件添加UUID xml 将XML解析到字段 所有过滤器都支持的配置选项： Setting Input_type Required add_field hash No add_tag array No enable_metric boolean No id string No periodic_flush boolean No remove_field array No remove_tag array No add_field如果此过滤器成功，添加任意字段到此事件。字段名称可以是动态的，并使用%{field}包含事件的部分内容 add_tag如果此过滤器成功，添加任意标签到此事件。标签可以是动态的，并使用%{field}语法包含事件的部分内容 enable_metric为特定插件实例启用/禁用度量标准日志记录 id为插件配置添加一个唯一的ID，如果没有指定ID，Logstash会生成一个。强烈建议在配置中设置此ID当你有多个相同类型的插件时，这特别有用 periodic_flush定期调用过滤器flush方法 remove_field如果此过滤器成功，从事件中移除任意字段 remove_tag如果此过滤器成功，从事件中移除任意标签 Aggregate此过滤器的目的是聚合属于同一任务的多个事件(通常是日志行)中可用的信息，并将最终聚合信息推送到最终任务事件中。 Aggregate Filter Configuration Options: Setting Input_type Required aggregate_maps_path string, a valid filesystem path No code string Yes end_of_task boolean No inactivity_timeout number No map_action string, one of [“create”, “update”, “create_or_update”] No push_map_as_event_on_timeout boolean No push_previous_map_as_event boolean No task_id string Yes timeout number No timeout_code string No timeout_tags array No timeout_task_id_field string No timeout_timestamp_field string No aggregate_maps_pathLogstash停止时存储聚合地图的文件路径，以及Logstash启动时加载的路径。如果未定义，聚合映射将不会存储在Logstash中，并且会丢失。 code使用当前事件执行更新map的代码；或使用当前的map执行更新事件的代码你将有一个可用的map variable 和 event variable end_of_task告诉过滤器该任务已结束，因此在代码执行后删除聚合map inactivity_timeout一个任务被认为已到期的秒数当某个任务超时时，其聚合map将被逐出必须小于timeout map_action create update create_or_update告诉过滤器如何处理聚合map push_map_as_event_on_timeout每次检测到任务超时时，它都会将任务集合映射推送为新的Logstash事件 push_previous_map_as_event每次聚合插件检测到新任务ID时，它会将先前的聚合映射推送为新的Logstash事件，然后为下一个任务创建新的空映射 task_id定义了关联日志的任务ID的表达式该值必须唯一标识任务 timeout time_code timeout_tags在生成超时事件添加的标记 timeout_task_id_field timeout_timestamp_field默认情况下，使用系统时间计算超时 栗子： 给定日志: 1234INFO - 12345 - TASK_START - startINFO - 12345 - SQL - sqlQuery1 - 12INFO - 12345 - SQL - sqlQuery2 - 34INFO - 12345 - TASK_END - end 过滤器: 12345678910111213141516171819202122232425262728293031filter &#123; grok &#123; match =&gt; [ &quot;message&quot;, &quot;%&#123;LOGLEVEL:loglevel&#125; - %&#123;NOTSPACE:taskid&#125; - %&#123;NOTSPACE:logger&#125; - %&#123;WORD:label&#125;( - %&#123;INT:duration:int&#125;)?&quot; ] &#125; if [logger] == &quot;TASK_START&quot; &#123; aggregate &#123; task_id =&gt; &quot;%&#123;taskid&#125;&quot; code =&gt; &quot;map[&apos;sql_duration&apos;] = 0&quot; map_action =&gt; &quot;create&quot; &#125; &#125; if [logger] == &quot;SQL&quot; &#123; aggregate &#123; task_id =&gt; &quot;%&#123;taskid&#125;&quot; code =&gt; &quot;map[&apos;sql_duration&apos;] += event.get(&apos;duration&apos;)&quot; map_action =&gt; &quot;update&quot; &#125; &#125; if [logger] == &quot;TASK_END&quot; &#123; aggregate &#123; task_id =&gt; &quot;%&#123;taskid&#125;&quot; code =&gt; &quot;event.set(&apos;sql_duration&apos;, map[&apos;sql_duration&apos;])&quot; map_action =&gt; &quot;update&quot; end_of_task =&gt; true timeout =&gt; 120 &#125; &#125;&#125; Alteralter filter允许对未包含在正常变异过滤器中的字段进行一般更改。 安装: 1logstash-plugin install logstash-filter-alter 配置项: Setting Input type Required coalesce array No condrewrite array No condrewriteother array No coalesce将file_name的值设置为其参数的第一个非空表达式 condrewrite如果实际内容等于预期内容，则将字段内容更改为指定值 condrewriteother如果另一个字段内容等于预期内容，则将字段内容更改为指定值 cidrCIDR filter用于检查时间中的IP地址与可能包含它的网络块列表。可以针对多个网络检查多个地址，任何匹配都可以成功。成功后，可将其它标记/字段添加到事件中。 配置项: Setting Input_type Required address array No network array No network_path a valid filesystem path No refresh_interval number No separator string No address要检查的IP地址 network要检查的IP网络 network_path包含过滤器应检查的网络的外部文件的完整路径 refresh_interval检查外部文件的更新频率 seperator从network_path指定的外部文件解析网络的分隔符 csvcsv filter处理包含csv数据的事件字段，解析它，并将其存储为单个字段此过滤器还可解析使用任何分隔符的数据，而不仅仅是逗号 配置项: Setting Input_type Required autodetect_column_names boolean No autogenerate_column_names boolean No columns array No convert hash No quote_char string No separator string No skip_empty_columns boolean No skip_empty_rows boolean No skip_header boolean No source string No target string No autodetect_column_names是否应该从标题列自动检测列名称，默认false autogenerate_column_names是否应该自动生成列名，默认true。如果设置为false，那么没有指定header的列将不会被解析 columns列名称的列表 convert应用于列的数据类型转换的集合，可能的转换: integer, float, date, date_time, boolean quote_char用于引用csv字段的字符，默认&quot; separator列分隔符值。默认值comma, skip_empty_columns是否应该跳过空列，默认false skip_empty_rows是否应该跳过空行，默认false skip_header是否应该跳过header，默认false source源字段值中的csv数据将被扩展为数据结构 target放置数据的目标字段 datedate filter从字段中解析日期，然后使用该日期或时间戳作为事件的Logstash时间戳。它对事件排序和回填旧数据尤其重要。在没有此过滤器的情况下，如果timestamp尚未在事件中设置，则Logstash将根据首次查看事件是(input time)选择一个时间戳。 date filter配置项： Setting Input_type Required locale string No match array No tag_on_failure array No target string No timezone string No locale使用POSIX语言标记指定用于日期解析的环境(locale)，如en,en_US如果未指定，则将使用平台默认值 match有字段名称和格式模式的数组，[ field, formats…] 如果时间字段有多种格式，你可这样做: 12345match =&gt; [ &quot;filed-name&quot;, &quot;MMM dd yyyy HH:mm:ss&quot;, &quot;MMM d yyyy HH:mm:ss&quot;, &quot;ISO8601&quot; ]嵌套字段表示[foo][bar] 有几个例外: ISO8601: 解析任何有效的ISO8601时间戳，如2011-04-19T03:44:01.103Z UNIX: 解析float/int Unix原子时间(s) UNIX_MS: 解析int Unix原子时间 TAI64N: 解析tai64n时间值 语法细节:用于解析日期和时间文本的语法使用字母来指示时间值的种类，以及重复的字母来指示该值的形式。 以下是可用于解析日期和时间的内容： y year yyyy完整年号，如2018 yy 两位数年份，如18 M month of the year M最小数字月份,1-12 MM两位数字月份，01-12 MMM缩写的月份文本，Jan, Feb... MMMM完整的月份文本，January, February... d day of the month d最小数字日，1, 2... dd两位数字日，01, 02... H hour of the day H最小数字小时，0, 1... HH两位数字小时，00, 01... m minutes of the hour m最小数字分钟，0, 1... mm两位数字分钟，00, 01... s seconds of the minute s最小数字秒数，0, 1... ss两位数字秒数，00, 01... S 秒的最大精度(毫秒)，附加零 S十分之一秒 SS百分之一秒 SSS千分之一秒 Z time zone offset or identity Z时区偏移量结构为HHmm(如上海)，+0800 ZZ时区偏移量结构为HH:mm，+08:00 ZZZ时区身份(如上海)，Asia/Shanghai z time zone names. Time zone names (z) cannot be parsed w week of the year w最小数字周数，1, 2... ww两位数字周数，01, 02... D day of the year e day of the week(number) E day of the week(text) E, EE, EEE星期几的缩写，Mon, Tue, Wed, Thu, Fri, Sat, Sun EEEE星期几的全文，Monday, Tuesday... 对于非格式化的语法，你需要在值的周围放置单引号字符。如”yyyy-MM-dd’T’HH:mm:ss” tag_on_failure没有成功匹配时，将值附加到tag字段，默认值[&quot;_dateparsefailure&quot;] target将匹配的timestamp存储到给定目标字段中。如果未提供，则默认更新事件的@timestamp字段 timezone指定用于日期分析的时区标准ID，如Asia/Shanghai dissectdissect filter是一种拆分操作。与对整个字符串应用一个分隔符的常规拆分操作不同，此操作将一组分隔符应用于字符串值。dissect不使用正则表达式，所以速度非常快。但是，如果文本结构因行而异，则Grok更适合。有一种混合的情况，dissect可用来结构可靠地重复部分，然后Grok用于余下的字段值，并具有更多的正则表达式可预测性和更少的整体工作。 一组字段和分隔符被称为dissection，它使用一组%来描述: 123field: %&#123;a&#125;delimiter: -%&#123;a&#125; - %&#123;b&#125; - %&#123;c&#125; dissect filter配置项 Setting Input type Required convert_datatype hash No mapping hash No tag_on_failure array No convert_datatype可以指定int, float数据类型转换。这些将在mapping发生后完成，如果没有mapping部分，请自由使用此设置。 12345678filter &#123; dissect &#123; convert_datatype =&gt; &#123; cpu =&gt; &quot;float&quot; code =&gt; &quot;int&quot; &#125; &#125;&#125; mappingA hash of dissections of field =&gt; value不要在值中使用具有转移的\n，它会被看做两个字符\+n+而不是实际的换行符。 12345678910filter &#123; dissect &#123; mapping =&gt; &#123; # using an actual line break &quot;message&quot; =&gt; &apos;&quot;%&#123;field1&#125;&quot; &quot;%&#123;field2&#125;&quot; &quot;%&#123;description&#125;&quot;&apos; &quot;description&quot; =&gt; &quot;%&#123;field3&#125; %&#123;field4&#125; %&#123;field5&#125;&quot; &#125; &#125;&#125; tag_on_failuredissection失败时，将值添加到tag字段。默认值为[&quot;_dissectfailure&quot;] geoipgeoip filter根据Maxmind GeoLite2数据库的数据，添加有关IP地址的地理位置信息。 此插件与GeoLite City Database数据库捆绑在一起。GeoLite2是免费的IP地址位置数据库，与MaxMind的GeoIP2数据库相比，不如其精确。如果需要使用捆绑的DeoLite之外的数据库，可从MaxMind下载它: https://dev.maxmind.com/geoip/geoip2/geolite2/ 如果GeoIP返回查找到的经度(latitude)和纬度(longitude)，则会创建[geoip][location]字段。 Geoip Filter配置项 Setting Inpu_type Required cache_size number No database a valid filesystem path No default_database_type City or ASN No fields array No source string Yes tag_on_failure array No target string No cache_size默认值为1000。GeoIP查询的成本非常高昂。缓存设置的越高，项目在缓存中的可能性就越大，并且此filter运行的越快。但是，如果设置得太高，则会耗费太多内存。如果缓存已满，则无法添加更多记录。尝试使用此选项的不同值来为数据集找到最佳性能。这个值必须大于0。 database地理数据库的文件路径，如果未指定，则默认为logstash自带的GeoLite2-City数据库。 default_database_type默认值是City。唯一可接受的值是City和ASN。 fields包含在事件中的geoip字段数组。可能的字段取决于数据库类型。 source包含要通过geoip映射的IP地址或主机名的字段。 tag_on_failure默认值为[&quot;_geoip_lookup_failure&quot;]. target默认值为geoip.指定Logstash应该存储的geoip数据的字段。 grokParse arbitrary text and structure it.Grok是将非结构化日志数据解析为结构化和可查询的好方法。 它非常适用于syslog, apache or webserver logs, mysql logs以及通常为人类而不是计算机编写的任何日志格式。 默认情况下，Logstash ship附带了大约120种模式。它们在这: https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns要grok某类日志文件的时候，可以先到上面的地址查看有无对应的模式。然后复制对应内容到patterns_dir下，再在filter中使用。当然，你也可以自定义模式来匹配你的日志。在这测试: http://grokdebug.herokuapp.com Grok filter配置项 Setting Input_type Required break_on_match boolean No keep_empty_captures boolean No match hash No named_captures_only boolean No overwrite array No pattern_definitions hash No patterns_dir array No patterns_files_glob string No tag_on_failure array No tag_on_timeout string No timeout_millis number No break_on_matchBreak on first match. grok的第一个成功的匹配将导致filter结束。如果你想grok尝试所有的模式，请将其设置为false。默认值为true。 keep_empty_captures默认值为false。如果为true，则将空捕获保留为事件字段。 matchfield ⇒ value的散列匹配，默认值为{} 123filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; [ &quot;Duration: %&#123;NUMBER:duration&#125;&quot;, &quot;Speed: %&#123;NUMBER:speed&#125;&quot; ] &#125; &#125;&#125; named_captures_only默认值为true。如果为true，只保存来自grok的命名捕获。 overwrite要覆盖的字段，这使你可覆盖已存在的字段中的值。 123456filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;SYSLOGBASE&#125; %&#123;DATA:message&#125;&quot; &#125; overwrite =&gt; [ &quot;message&quot; ] &#125;&#125; pattern_definitions默认值为{}模式名称和模式元组的散列，用于定义当前过滤器要使用的自定义模式。匹配现用名称的模式将覆盖预先存在的定义。 patterns_dir默认值为[]logstash默认提供了一堆模式，除非添加额外模式，否则不需要自定义模式。你可以使用此设置指向多个模式目录。grok将读取与patterns_files_glob匹配的目录汇总的所有文件，并假定它为模式文件。 1patterns_dir =&gt; [&quot;/opt/logstash/patterns&quot;, &quot;/opt/logstash/extra_patterns&quot;] patterns_files_glob默认值为&quot;*&quot;Glob模式，用于从patterns_dir目录中选择模式文件。 tag_on_failure默认值为[&quot;_grokparsefailure&quot;]匹配没有成功时，将值添加到tags字段。 tag_on_timeout默认值为&quot;_groktimeout&quot;如果grok正则表达式超时，则应用此tag. timeout_millis默认值为30000尝试在这段时间后终止正则表达式。设置为0以禁用超时。 基础知识Grok工作方式，将文本模式组合成与你的日志模式相匹配的内容。 Grok模式的语法为 %{SYNTAX:SEMANTIC} SYNTAX, 文本匹配的模式的名称 SEMANTIC, 正在匹配的文本的标识符 1%&#123;NUMBER:duration&#125; %&#123;IP:client&#125; 你也可以将数据类型转换添加到Grok模式。默认情况下，所有的语义(semantic)都保存为字符串(strings)。如果你想转换语义的数据类型，如将string转换为int。例如%{NUMBER:num:int}将num语义从string转换为integer。当前情况下，只支持转换为int和float. 12345678910111213141516日志格式55.3.244.1 GET /index.html 15824 0.043grok pattern grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;IP:client&#125; %&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; %&#123;NUMBER:bytes&#125; %&#123;NUMBER:duration&#125;&quot; &#125; &#125;grok filter之后的格式client: 55.3.244.1method: GETrequest: /index.htmlbytes: 15824duration: 0.043 正则表达式Grok位于正则表达式之上，所以任何正则表达式在grok中都是有效的。Regular Expression Library: https://github.com/kkos/oniguruma/blob/master/doc/RE 示例grok处理nginx/access.log日志:首先针对nginx.conf中日志格式来决定如何写logstash pattern 1234567891011121314mkdir /etc/logstash/patternsvim nginxNGINX_ACCESS %&#123;IPORHOST:clientip&#125; (?:-|(%&#123;WORD&#125;.%&#123;WORD&#125;)) %&#123;USER:ident&#125; \[%&#123;HTTPDATE:timestamp&#125;\] &quot;(?:%&#123;WORD:verb&#125; %&#123;NOTSPACE:request&#125;(?: HTTP/%&#123;NUMBER:httpversion&#125;)?|%&#123;DATA:rawrequest&#125;)&quot; %&#123;NUMBER:response&#125; (?:%&#123;NUMBER:bytes&#125;|-) %&#123;QS:referrer&#125; %&#123;QS:agent&#125; %&#123;QS:forwarder&#125;grok &#123; patterns_dir =&gt; &quot;/etc/logstash/patterns&quot; match =&gt; &#123; &quot;message&quot; =&gt; %&#123;NGINX_ACCESS&#125;&#125;&#125; grok debugger grok-patterns这是grok官方写得patterns，当然，你也可以自己写。就像Nginx日志那样！ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495USERNAME [a-zA-Z0-9._-]+USER %&#123;USERNAME&#125;EMAILLOCALPART [a-zA-Z][a-zA-Z0-9_.+-=:]+EMAILADDRESS %&#123;EMAILLOCALPART&#125;@%&#123;HOSTNAME&#125;INT (?:[+-]?(?:[0-9]+))BASE10NUM (?&lt;![0-9.+-])(?&gt;[+-]?(?:(?:[0-9]+(?:\.[0-9]+)?)|(?:\.[0-9]+)))NUMBER (?:%&#123;BASE10NUM&#125;)BASE16NUM (?&lt;![0-9A-Fa-f])(?:[+-]?(?:0x)?(?:[0-9A-Fa-f]+))BASE16FLOAT \b(?&lt;![0-9A-Fa-f.])(?:[+-]?(?:0x)?(?:(?:[0-9A-Fa-f]+(?:\.[0-9A-Fa-f]*)?)|(?:\.[0-9A-Fa-f]+)))\bPOSINT \b(?:[1-9][0-9]*)\bNONNEGINT \b(?:[0-9]+)\bWORD \b\w+\bNOTSPACE \S+SPACE \s*DATA .*?GREEDYDATA .*QUOTEDSTRING (?&gt;(?&lt;!\\)(?&gt;&quot;(?&gt;\\.|[^\\&quot;]+)+&quot;|&quot;&quot;|(?&gt;&apos;(?&gt;\\.|[^\\&apos;]+)+&apos;)|&apos;&apos;|(?&gt;`(?&gt;\\.|[^\\`]+)+`)|``))UUID [A-Fa-f0-9]&#123;8&#125;-(?:[A-Fa-f0-9]&#123;4&#125;-)&#123;3&#125;[A-Fa-f0-9]&#123;12&#125;# URN, allowing use of RFC 2141 section 2.3 reserved charactersURN urn:[0-9A-Za-z][0-9A-Za-z-]&#123;0,31&#125;:(?:%[0-9a-fA-F]&#123;2&#125;|[0-9A-Za-z()+,.:=@;$_!*&apos;/?#-])+# NetworkingMAC (?:%&#123;CISCOMAC&#125;|%&#123;WINDOWSMAC&#125;|%&#123;COMMONMAC&#125;)CISCOMAC (?:(?:[A-Fa-f0-9]&#123;4&#125;\.)&#123;2&#125;[A-Fa-f0-9]&#123;4&#125;)WINDOWSMAC (?:(?:[A-Fa-f0-9]&#123;2&#125;-)&#123;5&#125;[A-Fa-f0-9]&#123;2&#125;)COMMONMAC (?:(?:[A-Fa-f0-9]&#123;2&#125;:)&#123;5&#125;[A-Fa-f0-9]&#123;2&#125;)IPV6 ((([0-9A-Fa-f]&#123;1,4&#125;:)&#123;7&#125;([0-9A-Fa-f]&#123;1,4&#125;|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;6&#125;(:[0-9A-Fa-f]&#123;1,4&#125;|((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;)|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;5&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,2&#125;)|:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;)|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;4&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,3&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)?:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;3&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,4&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,2&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;2&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,5&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,3&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;1&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,6&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,4&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(:(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,7&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,5&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:)))(%.+)?IPV4 (?&lt;![0-9])(?:(?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5]))(?![0-9])IP (?:%&#123;IPV6&#125;|%&#123;IPV4&#125;)HOSTNAME \b(?:[0-9A-Za-z][0-9A-Za-z-]&#123;0,62&#125;)(?:\.(?:[0-9A-Za-z][0-9A-Za-z-]&#123;0,62&#125;))*(\.?|\b)IPORHOST (?:%&#123;IP&#125;|%&#123;HOSTNAME&#125;)HOSTPORT %&#123;IPORHOST&#125;:%&#123;POSINT&#125;# pathsPATH (?:%&#123;UNIXPATH&#125;|%&#123;WINPATH&#125;)UNIXPATH (/([\w_%!$@:.,+~-]+|\\.)*)+TTY (?:/dev/(pts|tty([pq])?)(\w+)?/?(?:[0-9]+))WINPATH (?&gt;[A-Za-z]+:|\\)(?:\\[^\\?*]*)+URIPROTO [A-Za-z]([A-Za-z0-9+\-.]+)+URIHOST %&#123;IPORHOST&#125;(?::%&#123;POSINT:port&#125;)?# uripath comes loosely from RFC1738, but mostly from what Firefox# doesn&apos;t turn into %XXURIPATH (?:/[A-Za-z0-9$.+!*&apos;()&#123;&#125;,~:;=@#%&amp;_\-]*)+#URIPARAM \?(?:[A-Za-z0-9]+(?:=(?:[^&amp;]*))?(?:&amp;(?:[A-Za-z0-9]+(?:=(?:[^&amp;]*))?)?)*)?URIPARAM \?[A-Za-z0-9$.+!*&apos;|()&#123;&#125;,~@#%&amp;/=:;_?\-\[\]&lt;&gt;]*URIPATHPARAM %&#123;URIPATH&#125;(?:%&#123;URIPARAM&#125;)?URI %&#123;URIPROTO&#125;://(?:%&#123;USER&#125;(?::[^@]*)?@)?(?:%&#123;URIHOST&#125;)?(?:%&#123;URIPATHPARAM&#125;)?# Months: January, Feb, 3, 03, 12, DecemberMONTH \b(?:[Jj]an(?:uary|uar)?|[Ff]eb(?:ruary|ruar)?|[Mm](?:a|ä)?r(?:ch|z)?|[Aa]pr(?:il)?|[Mm]a(?:y|i)?|[Jj]un(?:e|i)?|[Jj]ul(?:y)?|[Aa]ug(?:ust)?|[Ss]ep(?:tember)?|[Oo](?:c|k)?t(?:ober)?|[Nn]ov(?:ember)?|[Dd]e(?:c|z)(?:ember)?)\bMONTHNUM (?:0?[1-9]|1[0-2])MONTHNUM2 (?:0[1-9]|1[0-2])MONTHDAY (?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9])# Days: Monday, Tue, Thu, etc...DAY (?:Mon(?:day)?|Tue(?:sday)?|Wed(?:nesday)?|Thu(?:rsday)?|Fri(?:day)?|Sat(?:urday)?|Sun(?:day)?)# Years?YEAR (?&gt;\d\d)&#123;1,2&#125;HOUR (?:2[0123]|[01]?[0-9])MINUTE (?:[0-5][0-9])# &apos;60&apos; is a leap second in most time standards and thus is valid.SECOND (?:(?:[0-5]?[0-9]|60)(?:[:.,][0-9]+)?)TIME (?!&lt;[0-9])%&#123;HOUR&#125;:%&#123;MINUTE&#125;(?::%&#123;SECOND&#125;)(?![0-9])# datestamp is YYYY/MM/DD-HH:MM:SS.UUUU (or something like it)DATE_US %&#123;MONTHNUM&#125;[/-]%&#123;MONTHDAY&#125;[/-]%&#123;YEAR&#125;DATE_EU %&#123;MONTHDAY&#125;[./-]%&#123;MONTHNUM&#125;[./-]%&#123;YEAR&#125;ISO8601_TIMEZONE (?:Z|[+-]%&#123;HOUR&#125;(?::?%&#123;MINUTE&#125;))ISO8601_SECOND (?:%&#123;SECOND&#125;|60)TIMESTAMP_ISO8601 %&#123;YEAR&#125;-%&#123;MONTHNUM&#125;-%&#123;MONTHDAY&#125;[T ]%&#123;HOUR&#125;:?%&#123;MINUTE&#125;(?::?%&#123;SECOND&#125;)?%&#123;ISO8601_TIMEZONE&#125;?DATE %&#123;DATE_US&#125;|%&#123;DATE_EU&#125;DATESTAMP %&#123;DATE&#125;[- ]%&#123;TIME&#125;TZ (?:[APMCE][SD]T|UTC)DATESTAMP_RFC822 %&#123;DAY&#125; %&#123;MONTH&#125; %&#123;MONTHDAY&#125; %&#123;YEAR&#125; %&#123;TIME&#125; %&#123;TZ&#125;DATESTAMP_RFC2822 %&#123;DAY&#125;, %&#123;MONTHDAY&#125; %&#123;MONTH&#125; %&#123;YEAR&#125; %&#123;TIME&#125; %&#123;ISO8601_TIMEZONE&#125;DATESTAMP_OTHER %&#123;DAY&#125; %&#123;MONTH&#125; %&#123;MONTHDAY&#125; %&#123;TIME&#125; %&#123;TZ&#125; %&#123;YEAR&#125;DATESTAMP_EVENTLOG %&#123;YEAR&#125;%&#123;MONTHNUM2&#125;%&#123;MONTHDAY&#125;%&#123;HOUR&#125;%&#123;MINUTE&#125;%&#123;SECOND&#125;# Syslog Dates: Month Day HH:MM:SSSYSLOGTIMESTAMP %&#123;MONTH&#125; +%&#123;MONTHDAY&#125; %&#123;TIME&#125;PROG [\x21-\x5a\x5c\x5e-\x7e]+SYSLOGPROG %&#123;PROG:program&#125;(?:\[%&#123;POSINT:pid&#125;\])?SYSLOGHOST %&#123;IPORHOST&#125;SYSLOGFACILITY &lt;%&#123;NONNEGINT:facility&#125;.%&#123;NONNEGINT:priority&#125;&gt;HTTPDATE %&#123;MONTHDAY&#125;/%&#123;MONTH&#125;/%&#123;YEAR&#125;:%&#123;TIME&#125; %&#123;INT&#125;# ShortcutsQS %&#123;QUOTEDSTRING&#125;# Log formatsSYSLOGBASE %&#123;SYSLOGTIMESTAMP:timestamp&#125; (?:%&#123;SYSLOGFACILITY&#125; )?%&#123;SYSLOGHOST:logsource&#125; %&#123;SYSLOGPROG&#125;:# Log LevelsLOGLEVEL ([Aa]lert|ALERT|[Tt]race|TRACE|[Dd]ebug|DEBUG|[Nn]otice|NOTICE|[Ii]nfo|INFO|[Ww]arn?(?:ing)?|WARN?(?:ING)?|[Ee]rr?(?:or)?|ERR?(?:OR)?|[Cc]rit?(?:ical)?|CRIT?(?:ICAL)?|[Ff]atal|FATAL|[Ss]evere|SEVERE|EMERG(?:ENCY)?|[Ee]merg(?:ency)?) json这是一个json解析过滤器。 Json Filter配置项 Setting Input_type Required skip_on_invalid_json boolean No source string Yes tag_on_failure array No target string No skip_on_invalid_json默认值是false.允许跳过无效json上的过滤器。 sourcejson filter的配置如，从message字段中解析json 12345filter &#123; json &#123; source =&gt; &quot;message&quot; &#125;&#125; target定义放置解析数据的目标字段。如果目标字段已存在，则它会被覆盖。 12345filter &#123; json &#123; target =&gt; &quot;doc&quot; &#125;&#125; kv此过滤器有助于自动解析key=value类型的消息。这对于postfix, iptables和倾向于key=value语法类型的日志非常有用。 123456789101112#beforeip=1.2.3.4 error=REFUSEDfilter &#123; kv &#123;&#125;&#125;#afterip: 1.2.3.4error: REFUSED kv filter配置项 Setting Input_type Required allow_duplicate_values boolean No default_keys hash No exclude_keys array No field_split string No include_brackets boolean No include_keys array No prefix string No recursive boolean No remove_char_key string No remove_char_value string No source string No target string No transform_key string, one of [“lowercase”, “uppercase”, “capitalize”] No transform_value string, one of [“lowercase”, “uppercase”, “capitalize”] No trim_key string No trim_value string No value_split string No allow_duplicate_values默认值为true.用于删除重复 键/值对的布尔选项。 default_keys默认值为{}.一个散列，用于指定在解析源字段中不存在的键时应添加到事件中的默认值及其值。 exclude_keys默认值为[].一个数组，用于指定不应添加到事件中的解析键。默认情况下，没有键被排除。 field_split默认值为&quot; &quot;.用作解析出键值对后的单字符字段分隔符的字符串。 12345678#栗子name=zhang21&amp;age=25&amp;email=ab123@gamil.comfilter &#123; kv &#123; field_split =&gt; &quot;&amp;&quot; &#125;&#125; field_split_pattern一个正则表达式，用作字段分隔符来解析键值对。用于定义多字符字段分隔符。它优先于field_split选项。 12345678#栗子k1=v1:k2=v2:::k3=v3::k4=v4filter &#123; kv &#123; field_split_pattern =&gt; &quot;:+&quot; &#125;&#125; include_brackets默认值为true.一个布尔值，指定是否将 方括号[square bracket]，尖括号和括号(bracket) 视为的包装器(wrapper)，是否应该从值中删除。 12345678910111213#栗子one=(o n e) two=[t w o] three=&lt;t h r e e&gt;filter &#123; kv &#123; include_brackets =&gt; tree &#125;&#125;#afterone: o n etwo: t w othree: t h r e e include_keys默认值为[].一个数字，用于指定应该添加到解析的键。默认情况下，所有的键都会被添加。 prefix默认值为空。预先添加到所有提取的键的字符串。 recursive默认值为false.一个布尔值，执行是否向下提取值并递归获取更多的键值对。 remove_char_key要从键中移除的字符串。 remove_char_value要从值中移除的字符串。 source默认值为message.要在其上执行key=value搜索的字段。 target将所有键值对放入的容器的名称。 transform_key将键转换为大写，小写。 transform_value将值转换为大写，小写 trim_key从键中修建的字符串。如果键包含在括号中或以空格开头，这很有用。 trim_value从值中修建的字符串。如果你的值包含在括号中或以逗号结尾。这很有用。 value_split默认值为=.一个非空字符串，用作解析出键值对的单字符分隔符。 value_split_pattern用作值分隔符来解析出键值对的正则表达式。优先级高于value_split。 metricsmetrics filter用于聚合度量(aggregating metrics). 12345678#计算每种http响应吗filter &#123; metrics &#123; meter =&gt; [ &quot;http_%&#123;response&#125;&quot; ] add_tag =&gt; &quot;metric&quot; &#125;&#125; metrics filter配置项 Setting Input_type Required clear_interval number No flush_interval number No ignore_older_than number No meter array No percentiles array No rates array No timer hash No clear_interval默认值为-1.清理间隔，所有的计数器都被重置。 flush_interval默认值为5.刷新间隔，当metrics事件被创建时。此值必须是5的倍数。 ignore_older_than默认值为0.不要跟着@timestamp超过某个秒数的事件。 meter语法: meter =&gt; [ &quot;name of metric&quot;, &quot;name of metric&quot; ] percentiles默认值为percentiles.计时器值应该测量和发出的百分位数。 rates默认值为[1, 5, 15].应该按分钟测量的比率。 timer语法: timer =&gt; [ &quot;name of metric&quot;, &quot;%{time_value}&quot; ] meter valuesmeter =&gt; &quot;something&quot;, 会收到如下字段: “[thing][count]” - the total count of events “[thing][rate_1m]” - the per-second event rate in a 1-minute sliding window “[thing][rate_5m]” - the per-second event rate in a 5-minute sliding window “[thing][rate_15m]” - the per-second event rate in a 15-minute sliding window timer valuestimer =&gt; { &quot;thing&quot; =&gt; &quot;%{duration}&quot;}, 会收到如下字段: “[thing][count]” - the total count of events “[thing][rate_1m]” - the per-second average value in a 1-minute sliding window “[thing][rate_5m]” - the per-second average value in a 5-minute sliding window “[thing][rate_15m]” - the per-second average value in a 15-minute sliding window “[thing][min]” - the minimum value seen for this metric “[thing][max]” - the maximum value seen for this metric “[thing][stddev]” - the standard deviation for this metric “[thing][mean]” - the mean for this metric “[thing][pXX]” - the XXth percentile for this metric (see percentiles) mutatemutate filter允许你在字段上执行常规突变。你可以重命名，删除，替换和修改事件中的字段。 mutate filter配置项 Setting Input_type Required convert hash No copy hash No gsub array No join hash No lowercase array No merge hash No coerce hash No rename hash No replace hash No split hash No strip array No update hash No uppercase array No capitalize array No convert将字段的值转换为其它类型，如将string转换为int.如果只为数组，则所有成员都将转换；如果是散列，则不处理。 copy将现有字段复制到另一个字段(会覆盖)。 gsub将正则表达式与字段值进行匹配，并用替换字符替换所有匹配项。只支持string或string array. 1234567filter &#123; mutate &#123; gsub =&gt; [ &quot;field1&quot;, &quot;value&quot;, &quot;replacement string&quot;, ] &#125;&#125; join加入一个带分隔符的数组。对非数组字段没有任何作用。 lowercase将字符串转换为小写 merge合并数组或散列的两个字段。字符串字段将被自动转换为数组。 12345filter &#123; mutate &#123; merge =&gt; &#123; &quot;dest_field&quot; =&gt; &quot;added_field&quot;&#125; &#125;&#125; coerce为已存在但为空的字段设置默认值。 rename重命名一个或多个字段。 replace用新值替换一个字段。新值可以包含%{foo}字符串，以帮助你从事件的其它部分创建新值。 1234567filter &#123; mutate &#123; replace =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;source_host&#125;: My new message&quot; &#125; &#125;&#125; split使用分隔符将字段拆分为数组。只适用于字符串字段。 strip从字段剥离空白符。 update用新值更新现有字段。 xmlXML filter.获取包含XML的字段并将其展开为实际的数据结构。 XML Filter配置项 Setting Input_type Required force_array boolean No force_content boolean No namespaces hash No remove_namespaces boolean No source string Yes store_xml boolean No suppress_empty boolean No target string No xpath hash No force_array默认值为true.过滤器强制单个元素为数组。将其设置为false防止在数组中存储单个元素。 force_content默认值为false.过滤器将以不同于标签内的内容的方式展开属性。 namespace默认值为{}.这允许配置所有命名空间声明来解析XML文档。 12345678filter &#123; xml &#123; namespaces =&gt; &#123; &quot;xsl&quot; =&gt; &quot;http://www.w3.org/1999/XSL/Transform&quot; &quot;xhtml&quot; =&gt; &quot;http://www.w3.org/1999/xhtml&quot; &#125; &#125;&#125; remove_namespaces从文档中的所有节点中删除所有命名空间。 source store_xml默认为true.过滤器会将整个解析的XML存储在目标字段中。 suppress_empty默认值为true.默认情况下，如果元素为空，这不输出。如果设置为false,则空元素将产生一个空的散列对象。 target定义放置数据的目标。 条件判断使用条件判断决定filter和output处理特定的事件。 Logstash条件类似于编程语言，条件语句，可以嵌套： if else if else 比较操作： == != &lt; &gt; &lt;= &gt;= =~ 匹配正则 !~ 不匹配正则 in 包含 not in 不包含 布尔操作： and or nand xor 一元运算符： ! 取反 () 复合表达式 栗子： 1234567891011121314151617181920output &#123; if [path] == &quot;/var/nginx/access.log&quot; &#123; elasticsearch &#123; hosts =&gt; user =&gt; password =&gt; index =&gt; &quot;nginx-access-%&#123;+YYYY.MM.dd&#125;&quot; &#125; &#125; else if [path] == &quot;/var/nginx/error.log&quot; &#123; elasticsearch &#123; hosts =&gt; user =&gt; password =&gt; index =&gt; &quot;nginx-error-%&#123;+YYYY.MM.dd&#125;&quot; &#125; &#125; else &#123; &#125;&#125; Filebeat文档 概述filebeat是一个beat，它基于libbeat框架。 Filebeat是一个本地文件的日志数据搬运(shipper)。作为Agent安装，filebeat监视日志目录或指定的日志文件，并将它们转发给Elasticsearch或logstash进行索引。启动filebeat时，它会启动一个或多个prospectors(勘探者)，查看为日志指定的本地路径。对于prospectors所在的每个日志文件，filebeat启动harvester。每个harvester为新内容读取单一日志文件，并将新日志发送到filebeat配置的输出。 入门开始filebeat前，请确保安装和配置了如下产品： Elasticsearch(存储和索引数据) Kibana(UI) Logstash(可选) 配置filebeat module为常用日志格式提供了入门体验。 123456789101112131415161718vim /etc/filebeat/filebeat.ymlfilebeat.prospectors: -type: log enabled: true paths: - /var/log/*.logoutput.elasticsearch: hosts: [ &quot;ip:9200&quot; ] #username #passwordsetup.kibana: host: &quot;localhost:5601&quot; #username #password 配置filebeat使用logstash123456vim /etc/filebeat/filebeat.ymloutput.logstash: hosts: [ &quot;127.0.0.1:5044&quot; ]#logstash需要配置监听beats 在Elasticsearch中载入索引模板在Elasticsearch中，索引模板用于定义设置(setting)和映射(mapping)，以确定如何分析字段(fields)。 filebeat推荐的索引模板文件有filebeat软件包安装。在成功连接到Elasticsearch后，它会默认自动载入索引模板(fields.yml)。如果模板存在，它不会覆盖除，除非你配置要覆盖。通过修改配置文件，你也可以禁用自动载入模板，或者载入你自己的模板。 配置模板载入 1234567891011vim /etc/filebeat/filebeat.ymlsetup.template.name: &quot;template-name&quot;setup.template.fields: &quot;/path/xxx/xxx.yml&quot;#强制覆盖已存在模板setup.template.overwrite: true#关闭自动载入模板setup.template.enabled: false 修改索引名 filebeat的默认索引名为 filebeat-&lt;version&gt;-yyyy.MM.dd 在output.elasticsearch设置选项 你指定的索引名称应该包含索引的根名、索引版本和日期信息 1234output.elasticsearch.index: &quot;customname-%&#123;[version]&#125;-%&#123;+yyyy.MM.dd&#125;&quot;setup.template.name: &quot;customname&quot;setup.template.pattern: &quot;customname-*&quot;setup.dashboards.index: &quot;customname-*&quot; 手动载入模板 1filebeat setup --template 强制Kibana查看最新文件 1curl -XDELETE &apos;http://localhost:9200/filebeat-*&apos; 设置Kibana面板Filebeat附带了实例的Kibana dashboards, visualization和可视化搜索。在使用仪表板前，你需要创建索引filebeat-*，并将仪表板加载到Kibana中。你可使用setup命令或配置文件加载它。 启动Filebeat1234systemctl start filebeat#前台启动并查看相关信息filebeat -e -c filebeat.yml 查看示例Kibana仪表板访问你的kibana web端(localhost:5601)，可用Nginx做反向代理，再加上域名解析。 快速开始常见日志格式filebeat提供了一套预构建模块，可使用它快速实施和部署日志监视方案。 先决条件： 安装和配置Elastic Stack 安装filebeat 安装Ingest Node GeoIP和User Agent plugins 验证Elasticsearch和Kibana能从filebeat接收数据 12elasticsearch-plugin install ingest-geoipelasticsearch-plugin install ingest-user-agent 运行filebeat模块 12345678#启用模块filebeat modules enable nginx system#配置pathcd /etc/filebeat/modules.dvim nginx.ymlvim system.yml 最后就可以在Kibana中可视化查看日志。 查看dashboard时，遇到一个错误: Could not locate that index-pattern (id: filebeat-*) 解决办法： 12#重新载入索引模板filebeat setup output我们可根据系统的负载情况将Filebeat的output到合适的地方，output只能有一个！如果有时候系统负载过高的话，可以考虑output到Redis或Elasticsearch。 redis和logstash都还需要logstash的pipeline转交给Elasticsearch，但你可以filter。而直接使用Elasticsearch便不能过滤。 Logstash Elasticsearch Redis 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556vim /etc/filebeat/filebeat.yml#找到output#redisoutput.redis: hosts: &quot;localhost&quot; port: 6379 key: &quot;filebeat&quot; #自定义key-name #password: #db: #data_type: &apos;list&apos;#logstashoutput.logstash: hosts: [ &quot;localhost:5044&quot; ]#Elasticsearchelasticsearch.output: hosts: [ &quot;localhost:9200&quot; ] #username: #name:==================#redis对应的pipelinevim /etc/logstash/conf.d/redis-pipeline.confinput &#123; redis &#123; data_type =&gt; &quot;list&quot; key =&gt; &quot;filebeat&quot; host =&gt; &quot;localhost&quot; port =&gt; 6379 #password =&gt; #db =&gt; &#125;&#125;#filter&#123; &#125;output &#123; elasticsearch &#123; hosts =&gt; [ &quot;localhost:9200&quot; ] #user #password index =&gt; &quot;filebeat-%&#123;+YYYY.MM.dd&#125;&quot; &#125;&#125; 定义索引为filebeat定义index: 123456789101112131415161718192021222324vim /etc/filebeat/filebeat.yml# Optional index name. The default is &quot;filebeat&quot; plus date# and generates [filebeat-]YYYY.MM.DD keys.# In case you modify this pattern you must update setup.template.name and setup.template.pattern accordingly.#index: &quot;filebeat-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;&quot;#写到事件中的索引名，默认 &quot;filebeat-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;&quot;#如果更改此设置，还需要配置setup.template.name和setup.template.pattern选项#如果使用的是预先构建的kibana dashboard，还需要配置setup.dashboards.index选项#定义索引output.elasticsearch: hosts: [&quot;10.0.1.8:9002&quot;, &quot;10.0.1.7:9002&quot;, &quot;10.0.1.9:9002&quot;] loadbalance: true username: &quot;elastic&quot; password: xxx index: &quot;filebeat-publish-%&#123;+yyyy.MM.dd&#125;&quot;#添加这几项setup.template.name: &quot;filebeat&quot;setup.template.pattern: &quot;filebeat-*&quot;setup.template.fields: &quot;fields.yml&quot;setup.template.overwrite: false 配置RPM安装的配置文件默认是/etc/filebeat/filebeat.yml，还有一个完整的示例配置文件/etc/filebeat/filebeat.reference.yml，显示了所有未弃用的选项。配置文件使用YAML语法。 指定运行moduleSpecify which modules to run Filebeat module提供了一种快速处理常见日志格式的方法。它包含默认配置。 有几种不同方法来启用modules: 配置modules.d目录 filebeat命令启动 配置filebeat.yml文件 1234567891011121314#modules.dfilebeat modules listfilebeat modules enable nginx#filebeat modules disable nginx#filebeat命令./filebeat -e --modules nginx#filebeat.ymlfilebeat.modules:- module: nginx- module: system 指定变量设置Specify variable settings 每个模块和文件集合都有变量，你可以设置这些变量来更改木块的默认行为。 12345678- module: nginx access: var.path: [&quot;/var/log/nginx/access.log*&quot;]#orfilebeat -M &quot;nginx.access.var.paths=[/var/log/access.log*]&quot;filebeat --modules nginx -M &quot;nginx.access.var.paths=[/var/log/nginx/access.log*]&quot; -M &quot;nginx.error.var.paths=[/var/log/nginx/error.log*]&quot; 高级设置在幕后，每个木块都会启动filebeat input。高级用户可以添加或覆盖任何input设置。 12345678910- module: nginx access: input: close_eof: true#orfilebeat -M &quot;nginx.access.input.close_eof=true&quot;filebeat --modules nginx -M &quot;nginx.access.input.close_eof=true&quot; 读取动态文件名filbeat配置文件虽然可以将索引设置为: indexname-%{+yyyy.MM.dd} 的日志格式，但这个是发送给ES的，ES可以处理此配置，但filebeat是无法直接处理的，它会把它当做普通字符。假如我要读取一个按日期取名的日志文件，如service_20180808.log，filebeat配置文件中是无法直接配置和处理。后来想到，可以用sh写一个脚本来做此操作。 1234567891011yesterday=`/bin/date +%Y%m%d --date='-1days'`today=`/bin/date +%Y%m%d`/bin/sed -i "s/service_err_$&#123;yesterday&#125;/service_err_$&#123;today&#125;/" /etc/filebeat/filebeat.yml/bin/filebeat test configif [ $? -eq 0 ] ;then /bin/systemctl restart filebeatelse exit 0fi inputDEPRECATED: prospectors are deprecated, Use inputs instead. Will be removed in version: 7.0.0要手动配置filebeat(而不是使用modules)，需要在filebeat.yml的filebeat.inputs部分指定输入列表(一个YAML 数据)。你可指定多个输入，并可多次指定相同的输入类型。 input types log stdin redis udp docker tcp syslog input 通用选项： 12345678910111213141516171819202122232425262728#启用/禁用inputsenabled#增加tags字段tags#向输出添加其他信息fieldsfilebeat.inputs:- type: log fields: author: zhang21#自定义字段存储为输出文档中的顶级字段，而不是在字段子字典下分组。如果与filebeat冲突，则会覆盖源字段fields_under_root#应用于inputs的处理器列表#已被弃用processors#为input生成的事件设置ingest node pipeline idpipeline log使用log input从日志文件中读取行。 12345filebeat.inputs:- type: log paths: - /var/log/messages - /var/log/*.log 你可以将其它配置设置(fields, include_lines, exclude_lines, mutiline)应用于从日志文件获取的行。这里指定的选项将应用于input的所有文件。将不同的配置应用于不同的文件，需要定义多个input sections: 1234567891011filebeat.inputs:- type: log paths: - /var/log/1.log - /var/log/2.log- type: log paths: - "/var/log/appache/*" fields: apache: true fields_under_root: true log input 配置项 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123paths#将读取的基于全局路径的列表recursive_glob.enabled#true允许扩展为递归模式encoding#读取数据的文件编码exclude_lines#正则表达式列表，用于匹配你希望filebeat排除的行filebeat.inputs:- type: log ... exclude_lines: ['^debug']include_lines#正则表达式列表，用于匹配你希望filebeat包含的行。#如果`exclude_lines`和`include_lines`都定义了，filebeat首先执行`include_lines`，之后才执行`exclude_lines`。filebeat.inputs:- type: log ... include_lines: ['^ERR', '^WARN']harvester_buffer_size#每个收集器在获取文件时使用的buffer大小，默认 16 384Byte。max_bytes#单日志消息可以具有的最大字节数。默认 10MBjson#此选项使filebeat解码日志结构为json消息。filebeat逐行处理日志，因此每一行要有json对象才有效。json.keys_under_rootjson.overwrite_keysjson.add_error_keyjson.message_keyjson.ignore_decoding_errormutiline#控制filebeat如果处理跨越多行的日志消息。exclude_files#正则表达式列表，用于匹配你希望filebeat忽略的文件。默认无。filebeat.inputs:- type: log ... exclude_files: ['\.gz$']ignore_older#如果启用此选项，filebeat将忽略在指定的事件跨度之前修改的所有文件。close_*#用于在某个标准或时间后关闭收集器。close_inactive#如果文件尚未在指定的时间内收获，则filebeat将关闭文件句柄。close_renamed#filebeat会在重命名文件时关闭文件处理程序，请注意日志轮询。close_removed#删除文件后，filebeat会关闭收集器。close_eof#一旦到达文件末尾，filebeat就会关闭文件。clean_*#用于清理注册表文件中的状态条目。clean_inactive#filebeat在指定的不活动事件段过去后删除文件的状态。clean_removed#如果在最后一个已知名称下无法在磁盘上找到文件，则filebeat会清除注册表中的文件。scan_frequency#filebeat检查指定路径文件的频率。官方不建议将此值设置为小于1s。默认 10s。tail_files#filebeat开始在每个文件的末尾而不是开头读取新文件。默认 falsesymlinks#允许filebeat收集符号链接，它读取符号链接的原始文件。由于此选项可能会导致数据丢失，默认 disabledbackoff#指定filebeat如何积极地抓取打开的文件以进行更新。max_backoff#在到达eof后再次检查文件之间filebeat等待的最长时间。backoff_factor#指定等待时间增加的速度。harvester_limit#限制一个input并行启动的收集器数量。 stdin使用stdin input从标准输入读取事件。此输入不可与其它输入类型同时运行。 12filebeat.inputs:- type: stdin stdin input 配置项： 123456789101112encodingexclude_linesinclude_linesharvester_buffer_sizemax_bytesjsonmultiline udp使用 udp input通过udp读取事件。 1234filebeat.inputs:- type: udp max_message_size: 10KB host: "localhost:5678" udp input 配置项： 123456#通过udp接收的最大消息大小，默认 10KBmax_message_size#udp hosthost tcp使用 tcp input 通过tcp读取事件。 1234filebeat.inputs:- type: tcp max_message_size: 10MB host: "localhost:5679" tcp input 配置项： 1234567891011121314max_message_size#通过tcp接收的最大消息大小， 默认 10MB#host and tcp porthost#指定用于拆分事件的字符，默认 \nline_delimiter#关闭连接前不活动的秒数， 默认 300stimeout docker使用docker input从docker container读取日志。 12345678filebeat.inputs:- type: docke containers: path: "/var/lib/docker/containers" stream: "all" ids: - 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'#必须填写容器ID docker input 配置项： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960container.ids#默认 /var/lib/docker/containerscontainer.path#从指定stream读取: all/stdout/stderr，默认 allcontainer.streamencodingexclude_lineinclude_lineharvester_buffer_sizemax_bytesjsonmultilineexclude_filesignore_olderclose_*close_inactiveclose_renamedclose_removedclose_eofclose_timeoutclean_*clean_inactiveclean_removedsacn_frequencytail_filessymlinksbackoffmax_backoffbackoff_factorharvester_limit syslog使用 syslog input通过tcp/udp/读取事件。 修改syslog配置： 123456vim /etc/rsyslog.d/filebeat.conf*.* @127.0.0.1:5678#重启服务systemctl restart rsyslog 123456789101112131415filebeat.inputs:- type: syslog protocol.udp: host: "localhost:5678" max_message_size: 100KB#定义索引setup.template.name: "filebeat"setup.template.pattern: "filebeat-*"setup.template.fields: "fields.yml"setup.template.overwrite: falseout.elastisearch： hosts: ["localhost:9200"] index: "syslog-%&#123;+yyyy.MM.dd&#125;" 它的配置项就是tcp/udp的配置项。 之后查看主机端口情况： 123netstat -nltup | grep 5678udp 0 0 127.0.0.1:5678 0.0.0.0:* 12434/filebeat output你可以通过在filebet.yml配置文件的output部分设置选项来配置filebeat以特定方式输出。只能定义一个输出。 filebeat支持如下输出： Elasticsearch Logstash Kafka Redis File Console elasticsearchfilebeat使用es http api将事务发送到es。 12345678output.elasticsearch: hosts: [&quot;https://localhost:9200&quot;] username: &quot;filebeat_internal&quot; password: &quot;YOUR_PASSWORD&quot; index: &quot;filebeat-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;&quot; #ssl.certificate_authorities: [&quot;/etc/pki/root/ca.pem&quot;] #ssl.certificate: &quot;/etc/pki/client/cert.pem&quot; #ssl.key: &quot;/etc/pki/client/cert.key&quot; 配置项： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103#启用/禁用output，默认 trueenabledhosts#["hsot1:port1", "host2:port2", "host3:port3"]username#建议为filebeat创建一个专门的用户用于发送事件，而不是使用es的用户passwordcompression_level#gzip压缩等级, 0-9，默认 0worker#每个配置主机向es发布事件的worker数，默认 1parameters#http 参数字典protocol#网络协议, http/httpspath#http api调用前面的http路径前缀headers#定义headersproxy_url#代理的urlindex#写到事件中的索引名，默认 "filebeat-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;"#如果更改此设置，还需要配置setup.template.name和setup.template.pattern选项#如果使用的是预先构建的kibana dashboard，还需要配置setup.dashboards.index选项indices#支持条件的索引选择器规则数组，基于格式字符串的字段访问和名称映射。indices.index: 要使用的索引格式字符串indices.mapping： 映射indices.default： 如果映射找不到匹配项的默认字符串值indices.when： 成功的条件才执行当前规则output.elasticsearch: hosts: ["http://localhost:9200"] index: "logs-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;" indices: - index: "critical-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;" when.contains: message: "CRITICAL" - index: "error-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;" when.contains: message: "ERR"pipeline#与indices类似，管道选择器配置数组filebeat.inputs:- type: log paths: ["/var/log/app/normal/*.log"] fields: type: "normal"- type: log paths: ["/var/log/app/critical/*.log"] fields: type: "critical"output.elasticsearch: hosts: ["http://localhost:9200"] index: "filebeat-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;" pipelines: - pipeline: critical_pipeline when.equals: fields.type: "critical" - pipeline: normal_pipeline when.equals: fields.type: "normal"max_retriesbulk_max_size#单个es批量挨批索引请求中要批量处理的最大事件数，默认 50backoff.init#在网络错误之后尝试重连到es之前等待的秒数，默认 1sbackoff.max#在网络错误后尝试连接到es之前等待的最大秒数，默认 60stimeout#超时时间ssl logstash kafka redisredis output将事件插入redis list或redis channel。 12345678output.redis: hosts: "localhost" port: 6379 key: "filebeat" #自定义key-name #password: #db: #data_type: 'list' 配置项： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#启用/禁用outputenabledhostsport#可将端口写在hosts里，默认6379usernamepassworddbkeydatatype#默认 listcodeckeyskeys.keykeys.mappingkeys.defaultkeys.whenoutput.redis: hosts: ["localhost"] key: "default_list" keys: - key: "info_list" # send to info_list if `message` field contains INFO when.contains: message: "INFO" - key: "debug_list" # send to debug_list if `message` field contains DEBUG when.contains: message: "DEBUG" - key: "%&#123;[fields.list]&#125;" mapping: "http": "frontend_list" "nginx": "frontend_list" "mysql": "backend_list"loadbalance#如果配置了多个主机，则输出插件会将已发布的事件负载均衡到所有redis主机上timeoutmax_retriesbulk_max_sizesslproxy_urlproxy_use_local_resolver filefile output将事务转储到文件中，每个事务都是json格式。 123output.file: path: "/tmp/filebeat" filename: filebeat 配置项： 12345678910111213141516enabledpathfilenamerotate_every_kb#默认 10 240KBnumber_of_files#路径下要保存的最大文件数permissions#创建的文件权限， 默认 0600codec consoleconsole output将事件以json格式输出到标准输出。 12output.console: pretty: true 配置项： 12345678pretty#美化输出， 默认 falsecodecenabledbulk_max_size loadbalancefilebeat提供配置项，用于将事件发送到多个主机时微调负载均衡。loadbalance对redis, logstash, es output可用。 123output.logstash: hosts: ["localhost:5044", "localhost:5045"] loadbalance: true Kibana文档Kibana是一个开源分析和可视化平台，旨在与Elasticsearch合作。你可使用Kibana来检索(search)，查看(view)存储在Elasticsearch索引中的数据并与其进行交互(interact)。你可以很轻松地执行高级数据分析，并在各种图表、表格和地图中可视化你的数据。Kibana可以很容易地理解大量的数据。基于浏览器的接口能够快速创建和分享动态仪表盘，实时显示Elasticsearch查询的变化。 入门在开始前，请确保已安装Kibana并与Elasticsearch建立了连接。 载入示例数据本节依赖如下示例数据： shakespeare.json: https://download.elastic.co/demos/kibana/gettingstarted/shakespeare_6.0.json accounts.zip: https://download.elastic.co/demos/kibana/gettingstarted/accounts.zip uzip accounts.zip logs.jsonl.gz: https://download.elastic.co/demos/kibana/gettingstarted/logs.jsonl.gz gunzip logs.jsonl.gz shakespeare按以下模式组织： 12345678&#123; "line_id": INT, "play_name": "String", "speech_number": INT, "line_number": "String", "speaker": "String", "text_entry": "String"&#125; accounts按以下模式组织： 12345678910111213&#123; "account_number": INT, "balance": INT, "firstname": "String", "lastname": "String", "age": INT, "gender": "M or F", "address": "String", "employer": "String", "email": "String", "city": "String", "state": "String"&#125; 日志数据的模式有许多不同的字段，此例使用字段如下： 12345&#123; "memory": INT, "geo.coordinates": "geo_point", "@timestamp": "date"&#125; 载入数据前，需要为字段设置映射。映射将索引中的文档分成逻辑组，并指定字段特性。如可搜索性、标记化、分解为单独的单词。 在Kibana界面中的Dev Tools中输入如下命令，为shakespeare数据设置映射。 12345678910111213PUT /shakespeare&#123; "mappings": &#123; "doc": &#123; "properties": &#123; "speaker": &#123;"type": "keyword"&#125;, "play_name": &#123;"type": "keyword"&#125;, "line_id": &#123;"type": "integer"&#125;, "speech_number": &#123;"type": "integer"&#125; &#125; &#125; &#125;&#125; 日志数据集logs.jsonl需要映射才能将日志中的经纬度标记为地理位置。 12345678910111213141516PUT /logstash-2015.05.18&#123; &quot;mappings&quot;: &#123; &quot;log&quot;: &#123; &quot;properties&quot;: &#123; &quot;geo&quot;: &#123; &quot;properties&quot;: &#123; &quot;coordinates&quot;: &#123; &quot;type&quot;: &quot;geo_point&quot; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 12345678910111213141516PUT /logstash-2015.05.19&#123; &quot;mappings&quot;: &#123; &quot;log&quot;: &#123; &quot;properties&quot;: &#123; &quot;geo&quot;: &#123; &quot;properties&quot;: &#123; &quot;coordinates&quot;: &#123; &quot;type&quot;: &quot;geo_point&quot; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 12345678910111213141516PUT /logstash-2015.05.20&#123; &quot;mappings&quot;: &#123; &quot;log&quot;: &#123; &quot;properties&quot;: &#123; &quot;geo&quot;: &#123; &quot;properties&quot;: &#123; &quot;coordinates&quot;: &#123; &quot;type&quot;: &quot;geo_point&quot; &#125; &#125; &#125; &#125; &#125; &#125;&#125; accounts数据集不需要映射，这一点上使用Elasticsearch的bulk API去载入数据集： 12345678910#这些命令要花一些时间curl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/bank/account/_bulk?pretty' --data-binary @accounts.jsoncurl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/shakespeare/doc/_bulk?pretty' --data-binary @shakespeare_6.0.jsoncurl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/_bulk?pretty' --data-binary @logs.jsonl#验证#在Kibana中的DevTools中运行GET /_cat/indices?v 定义你的索引模式加载到Elasticsearch的每组数据集都有一个索引模式(index pattern)。索引模式是一个带有可匹配多个索引的可使用通配符的字符串。 在前面，Shakespeare数据集有一个名为: shakespeare 的索引；Account数据集有一个名为：bank 的索引。如，在常见的日志文件中，一个典型的索引包含YYYY.MM.DD日期格式，类似于logstash-2015.05.*。 进入Kibana界面，点击Management， Index Patterns， Create Index Pattern 来创建一个索引模式。 shakespeare和account数据集不包含 time-series data。确保为此数据集创建索引模式时，不包含基于时间的事件。logs数据集包含了时序数据，因此索引需要包含基于时间的事件。 shakes* ba* logstash-2015* 定义索引模式时，与Elasticsearch匹配的索引必须存在。 在Kibana的DevTools中输入: GET _cat/indices 来查看索引。 数据发现点击Kibana界面中的Discover以显示数据发现功能。 可视化Visualize Visualize允许你在Elasticsearch索引中创建数据的可视化。然后可以构建显示相关可视化的仪表盘。 Kibana的可视化基于Elasticsearch查询。通过使用一系列Elasticsearch聚合来提取和处理你的数据。你可以创建图标来显示你需要了解的趋势。 创建可视化 Elasticsearch文档入门Elasticsearch是一个高度可扩展的开源全文搜索和分析引擎。它允许你快速、近乎实时地存储、搜索和分析大量数据。 Elasticsearch的几个例子： 使用Elasticsearch来存储产品目录和库存，并为其提供搜索和建议 收集日志或交易数据，并分析和挖掘数据以便于查找趋势、统计数据、汇总或异常信息 价格提醒平台，允许顾客制定规则，收到相应规则信息 分析智能需求，快速调查、分析、可视化并对大量数据提出特别的问题 基本概念Near Realtime(NRT)Elasticsearch是一个近乎实时的搜索平台。这意味着从索引文档到可搜索之间存在轻微的延迟(通常为1s) Cluster集群是一个或多个节点(服务器)的集合，它们一起保存所有数据，并提供跨节点的联合索引和搜索功能。集群由默认名为elasticsearch的唯一名称标识，它很重要。确保不要在不同的环境中重复使用相同集群名称，否则可能会导致节点加入错误的集群。集群可以只有一个节点！你也可以拥有多个独立的集群，每个集群有自己唯一的集群名称。 Node节点是属于集群一部分的单个服务器，存储数据并参与集群的索引和索引。与集群一样，一个节点由一个名称来标识，启动时随机分配的UUID。你也可以自定义节点名。配置节点通过集群名称加入特定的集群，默认加入elasticsearch集群。在单集群中，你可以拥有任意数量的节点。 Index索引是一些具有相似特征的文档集合。例如，客户数据的索引，产品目录的索引，订单数据的索引……索引由名称标识(必须全小写)，文档执行索引、搜索、更新和删除操作时引用索引。在一个单集群中，你可以定义任何你想要的索引。 Document文档是可被索引的基本信息单位。例如，单个客户的文档，单个产品的文档，单个订单的文档…文档以JSON格式表示。一条记录就是一个文档。 Shards和Replicas索引可潜在地存储大量数据，这些数据可能会超多单个节点的硬件限制。例如，占用1TB磁盘空间的十亿文档的单个索引可能不适合单个节点的磁盘，或者可能太慢而无法单独向单个节点提供搜索请求。为了解决这个问题，Elasticsearch提供了将索引细分为称为分片的多个碎片上。当你创建索引时，你可以简单定义所需的分片数量。每个分片本身都是一个功能齐全且独立的索引，可以在集群中的任何节点上进行托管。 分片重要的两个原因： 允许你水平分割/缩放内容量 允许分布和并行操作跨分片，从而提高性能和吞吐量(throughput) 在任何时候都可能出现的网络环境中，强烈建议使用故障切换机制，以防止分片/节点因任何原因而消失。为此，Elasticsearch允许你将索引分片制作为一个或多个称为副本分片的副本集。副本集分片永远不会分配到与原始分片相同的节点上。 副本集重要的原因： 在分片/节点失效的情况下提供高可用性 因为搜索可以在所有副本上并行执行，它允许你扩展搜索量和吞吐量 总而言之，每个索引都可以分成多个分片，索引也可以被复制。一旦复制，每个索引将具有主分片和副本分片。在创建索引时，可为每个索引定义分片和副本数量。在索引创建之后，你可以动态更改副本的数量，但无法更改分片的数量。 默认情况下，Elasticsearch中的每个索引都分配了5个主分片和副本。 每个Elasticsearch分片都是一个Lucene索引。单个Lucene索引有最大文档数量限制。 探索你的集群The REST APIREST(Representational State Transfer)表现层状态转换，是一种万维网软件架构风格，目的是便于不同程序在网络中互相传递信息。REST通常使用HTTP, URI, XML和HTML这些协议和标准。 启动节点，下一步便是理解如何与它通信。幸运的是，Elasticsearch提供了一个非常全面(comprehensive)和强大的REST API，可以使用它与集群进行交互。 使用API可以完成如下几件事： 检查集群、节点和索引的健康、状态和统计信息 管理集群、节点、索引数据和元数据 执行CRUD(create, read, update, delete) 执行高级搜索操作(分页、排序、过滤、脚本、聚合…) 集群健康基本健康检查，看看集群正在做什么。使用_catAPI检查集群健康。可使用Kibana Console或curl等工具。 12345678910#KibanaGET /_cat/health?v#cmdcurl -X GET &quot;localhost:9200/_cat/health?v&quot; -u elasticepoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent1525330981 15:03:01 docker-elk yellow 1 1 32 32 0 0 6 0 - 84.2% 集群健康： green: 万事OK(集群功能齐全) yellow: 所有数据可用，但一些副本尚未分配(集群功能齐全) red: 一些数据因某种原因不可用(集群部分功能) 集群名称： 集群名称被修改为docker-elk 列出集群中的节点： 12345GET /_cat/nodes?vip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name127.0.0.1 47 74 93 3.18 3.13 2.90 mdi * LGrAIE5 随机节点名： LGrAIE5 列出所有索引123456789GET /_cat/indicies?vhealth status index uuid pri rep docs.count docs.deleted store.size pri.store.sizegreen open .monitoring-kibana-6-2018.04.27 bsKsurh7TKaCsnekwHs3yg 1 0 870 0 328.1kb 328.1kbgreen open .watcher-history-7-2018.04.28 zuq3rjI8S0OSS7vcZl7kSQ 1 0 954 0 1.4mb 1.4mbgreen open .kibana 8t_7lqq4TFSfelA7phgv5g 1 0 142 18 191.8kb 191.8kbgreen open .monitoring-es-6-2018.04.28 vtUSjqaITT28CMHArpfNoA 1 0 20436 0 9.6mb 9.6mbyellow open filebeat-6.2.4-2018.05.03 sK3lIvMXS8GoRbWYCjdgzg 3 1 568 0 348.6kb 348.6kb 创建索引创建一个名为customer的索引，然后列出索引 1234567891011121314#pretty漂亮JSON显示PUT /customer?pretty#或curl -X PUT &quot;localhost:9200/zhang&quot; -u elastic:elasticGET /_cat/indices?v#pri主分片，rep副本health status index uuid pri rep docs.count docs.deleted store.size pri.store.sizeyellow open customer WQ3qEnPQRW6FpVIHYVJ7yA 5 1 0 0 1.1kb 1.1kbyellow open zhang nkOUPOWERsS1PT_wEui67g 5 1 0 0 1.1kb 1.1kb 你可能注意到了，索引的健康状态是yellow，表明有一些副本尚未分配。这个索引发生这种情况的原因是Elasticsearch默认为这个索引创建了一个副本。由于此刻我们只有一个节点在运行，因此只有在其它几点加入集群后才能分配一个副本。一旦副本分配到另外的节点，健康状态会变成green。 索引和查询文档现在让我们把一些东西放入customer索引中。讲一个简单的customer文档放入customer索引中，ID为1： 12345678910111213141516171819202122232425262728293031323334353637383940414243PUT /customer/_doc/1?pretty&#123; &quot;name&quot;: &quot;John Doe&quot;&#125;#或curl -X PUT -u elastic:elastic &quot;localhost:9200/customer/_doc/1?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;name&quot;: &quot;John Doe&quot;&#125;&apos;&#123; &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 0, &quot;_primary_term&quot; : 1&#125;GET /customer/_doc/1?pretty&#123; &quot;_index&quot;: &quot;customer&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;John Doe&quot; &#125;&#125;#name:John Doe _id:1 _type:_doc _index:customer _score:1 删除索引12345678DELETE /customer?prettycurl -X DELETE &quot;localhost:9200/customer?pretty&quot; -u elastic:elastic&#123; &quot;acknowledged&quot;: true&#125; 修改数据Elasticsearch几乎提示提供数据操作和搜索功能。从索引、更新、删除数据时可能会有1s延迟。数据在事物完成后立即可用。 索引/替换 文档 12345678910111213141516171819202122PUT /customer/_doc/1?pretty&#123; &quot;name&quot;: &quot;John Doe&quot;&#125;#如果我修改此处文档信息，则Elasticsearch会替换之前的文档PUT /customer/_doc/1?pretty&#123; &quot;name&quot;: &quot;Zhang&quot;&#125;#name:Zhang _id:1 _type:_doc _index:customer _score:1#或者新增一个文档PUT /customer/_doc/2?pretty&#123; &quot;name&quot;: &quot;Zhang&quot;&#125;#name:Zhang _id:2 _type:_doc _index:customer _score:1 未指定ID：ID是可选的。如果未指定ID，Elasticsearch会生成随机ID。注意，此时使用POST方法。 123456POST /customer/_doc?pretty&#123; &quot;name&quot;: &quot;Zhang&quot;&#125;#name:Zhang _id:76xJJWMBddhqcmsO07A_ _type:_doc _index:customer _score:1 更新文档除了能够索引和替换文档，我们还可以更新文档。Elasticsearch实际上并没有在原地就地更新，它是先删除旧文档，然后一次性更新索引新文档。 更新同样能够使用简单的脚本。Elasticsearch提供了通过查询条件(类似于SQL-UPDATE-WHERE)更细多个文档的能力。 1234567891011121314151617181920POST /customer/_doc/1/_update?pretty&#123; &quot;doc&quot;: &#123; &quot;name&quot;: &quot;Jane Doe&quot; &#125;&#125;#继续更新POST /customer/_doc/1/_update?pretty&#123; &quot;doc&quot;: &#123; &quot;name&quot;: &quot;Jane Doe&quot;, &quot;age&quot;: 20&#125;&#125;#简单脚本#ctx._source指即将更新的当前源文档POST /customer/_doc/1/_update?pretty&#123; &quot;script&quot;: &quot;ctx._source.age += 5&quot;&#125; 删除文档也可通过API匹配查询，删除所匹配的文档。 1DELETE /customer/_doc/2?pretty 批量处理Elasticsearch同样提供了使用_bulkAPI批量执行上述任何操作的功能。这是一种高效的机制，尽可能快地完成多项操作。 Bulk API不会因其中一个操作失败而停止，它将继续处理后面的动作。当它完成是，它会返回每个操作的状态，以便你可以检查是否失败。 123456789101112POST /customer/_doc/_bulk?pretty&#123; &quot;index&quot;: &#123; &quot;_id&quot;: &quot;1&quot; &#125; &#125;&#123; &quot;name&quot;: &quot;John Doe&quot; &#125;&#123; &quot;index&quot;: &#123; &quot;_id&quot;: &quot;2&quot; &#125; &#125;&#123; &quot;name&quot;: &quot;Jane Doe&quot; &#125;#更新POST /customer/_doc/_bulk?pretty&#123;&quot;update&quot;: &#123; &quot;_id&quot;: &quot;1&quot; &#125; &#125;&#123; &quot;doc&quot;: &#123; &quot;name&quot;: &quot;John Doe becomes Jane Doe&quot; &#125; &#125;&#123; &quot;delete&quot;: &#123; &quot;_id&quot;: &quot;2&quot; &#125; &#125; 探索你的数据简单数据集准备一个更加真实的数据集。如下生成的JSON文档，每个文档都有如下要点： 12345678910111213&#123; &quot;account_number&quot;: 0, &quot;balance&quot;: 16623, &quot;firstname&quot;: &quot;Bradshaw&quot;, &quot;lastname&quot;: &quot;Mckenzie&quot;, &quot;age&quot;: 29, &quot;gender&quot;: &quot;F&quot;, &quot;address&quot;: &quot;244 Columbus Place&quot;, &quot;employer&quot;: &quot;Euron&quot;, &quot;email&quot;: &quot;bradshawmckenzie@euron.com&quot;, &quot;city&quot;: &quot;Hobucken&quot;, &quot;state&quot;: &quot;CO&quot;&#125; 载入这个数据集下载Elasticsearch提供的accounts.json 123456curl -H &quot;Content-Type: application/json&quot; -u elastic:elastic -XPOST &quot;localhost:9200/bank/_doc/_bulk?pretty&amp;refresh&quot; --data-binary &quot;@accounts.json&quot;curl &quot;localhost:9200/_cat/indices?v&quot;health status index uuid pri rep docs.count docs.deleted store.size pri.store.sizeyellow open bank PGSvNwQwQIOhMDr1nmXIuw 5 1 1000 0 474.7kb 474.7kb 这样我们成功批量索引了1000个文档到bank索引。 Search API现在让我们做一些简单的搜索(search)。有两种基本搜索方式： REST request URI REST request body 以可读的JSON格式定义你的搜索，推荐方式 搜索的REST API可从_search端点访问: 12345678910111213141516171819202122232425262728293031323334353637#在bank索引下的_search端点搜索#匹配所有文档，并以账户字段顺序排列#最后以可读的JSON格式输出结果GET /bank/_search?q=*&amp;sort=account_number:asc&amp;pretty&#123; &quot;took&quot; : 63, &quot;timed_out&quot; : false, &quot;_shards&quot; : &#123; &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 &#125;, &quot;hits&quot; : &#123; &quot;total&quot; : 1000, &quot;max_score&quot; : null, &quot;hits&quot; : [ &#123; &quot;_index&quot; : &quot;bank&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;0&quot;, &quot;sort&quot;: [0], &quot;_score&quot; : null, &quot;_source&quot; : &#123;&quot;account_number&quot;:0,&quot;balance&quot;:16623,&quot;firstname&quot;:&quot;Bradshaw&quot;,&quot;lastname&quot;:&quot;Mckenzie&quot;,&quot;age&quot;:29,&quot;gender&quot;:&quot;F&quot;,&quot;address&quot;:&quot;244 Columbus Place&quot;,&quot;employer&quot;:&quot;Euron&quot;,&quot;email&quot;:&quot;bradshawmckenzie@euron.com&quot;,&quot;city&quot;:&quot;Hobucken&quot;,&quot;state&quot;:&quot;CO&quot;&#125; &#125;, &#123; &quot;_index&quot; : &quot;bank&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;sort&quot;: [1], &quot;_score&quot; : null, &quot;_source&quot; : &#123;&quot;account_number&quot;:1,&quot;balance&quot;:39225,&quot;firstname&quot;:&quot;Amber&quot;,&quot;lastname&quot;:&quot;Duke&quot;,&quot;age&quot;:32,&quot;gender&quot;:&quot;M&quot;,&quot;address&quot;:&quot;880 Holmes Lane&quot;,&quot;employer&quot;:&quot;Pyrami&quot;,&quot;email&quot;:&quot;amberduke@pyrami.com&quot;,&quot;city&quot;:&quot;Brogan&quot;,&quot;state&quot;:&quot;IL&quot;&#125; &#125;, ... ] &#125;&#125; took: Elasticsearch执行搜索花费的事件(ms) timed_out: 查询超时与否 _shards: 搜索了多少分片，包含成功和失败的次数 hits: 搜索结果 hits.total: 匹配搜索的文档数 hits.hits: 搜索结果数组(默认前十个文档) hits.sort: 结果的排序键 hits._score, max_score: 忽略的字段 REST request body方法 1234567GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;sort&quot;: [ &#123; &quot;account_number&quot;: &quot;asc&quot; &#125; ]&#125; 查询语法Elasticsearch提供了可用于执行查询的JSON格式语言，这被称为 Query DSL 12345#上一个查询栗子GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;&#125; 处理query参数，我们还可以传递其它参数来搜索结果: 123456789101112131415161718192021222324#size参数，返回从from开始多少个文档#from未指定，就默认为0GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;size&quot;: 1&#125;#from参数，指定从哪个文档索引开始GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;from&quot;: 10, &quot;size&quot;: 10&#125;#sort参数GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;sort&quot;: &#123; &quot;balance&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125; &#125;&#125; 执行搜索搜索某些字段： 12345GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;_source&quot;: [&quot;account_number&quot;, &quot;balance&quot;]&#125; 匹配查询： 12345678910111213141516GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;account_number&quot;: 20 &#125; &#125;&#125;GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;&#125;GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123; &quot;address&quot;: &quot;mill lane&quot; &#125; &#125;&#125; 布尔查询： must should must_not 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#mustGET /bank/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;lane&quot; &#125; &#125; ] &#125; &#125;&#125;#shouldGET /bank/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;should&quot;: [ &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;lane&quot; &#125; &#125; ] &#125; &#125;&#125;#must_notGET /bank/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must_not&quot;: [ &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;lane&quot; &#125; &#125; ] &#125; &#125;&#125;#组合使用must,must_not,shouldGET /bank/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;age&quot;: &quot;40&quot; &#125; &#125; ], &quot;must_not&quot;: [ &#123; &quot;match&quot;: &#123; &quot;state&quot;: &quot;ID&quot; &#125; &#125; ] &#125; &#125;&#125; 过滤前面我们跳过了称为文档分数的_score字段。它是文档与搜索查询匹配度相度量的一个数值。数值越大，与文档越相关。 但查询并不总是需要产生分数，特别是当它们仅用于过滤时。Elasticsearch检测这些情况并自动优化查询执行，以便不计算无用的分数。 range query: 通过一系列值来过滤文档 12345678910111213141516GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;balance&quot;: &#123; &quot;gte&quot;: 20000, &quot;lte&quot;: 30000 &#125; &#125; &#125; &#125; &#125;&#125; 除了前面这些查询类型，还有很多其它类型。由于只是入门章节，所以并不会涉及太多太难。 聚合聚合(Aggregation)提供了从数据中分组和提取统计的功能。考虑聚合最简单方法是将其大致等同于SQL GROUP BY和SQL聚合函数。 在Elasticsearch中，你可以执行返回匹配的搜索，同时还可以在一个响应中返回与匹配不同的聚合结果。你可以运行查询和多个聚合，并一次性获得多个操作的结果。 1234567891011121314GET /bank/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_state&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;state.keyword&quot; &#125; &#125; &#125;&#125;#类似的SQLSELECT state, COUNT(*) FROM bank GROUP BY state ORDER BY COUNT(*) DESC 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#group, averageGET /bank/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_state&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;state.keyword&quot; &#125;, &quot;aggs&quot;: &#123; &quot;average_balance&quot;: &#123; &quot;avg&quot;: &#123; &quot;field&quot;: &quot;balance&quot; &#125; &#125; &#125; &#125; &#125;&#125;GET /bank/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_age&quot;: &#123; &quot;range&quot;: &#123; &quot;field&quot;: &quot;age&quot;, &quot;ranges&quot;: [ &#123; &quot;from&quot;: 20, &quot;to&quot;: 30 &#125;, &#123; &quot;from&quot;: 30, &quot;to&quot;: 40 &#125;, &#123; &quot;from&quot;: 40, &quot;to&quot;: 50 &#125; ] &#125;, &quot;aggs&quot;: &#123; &quot;group_by_gender&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;gender.keyword&quot; &#125;, &quot;aggs&quot;: &#123; &quot;average_balance&quot;: &#123; &quot;avg&quot;: &#123; &quot;field&quot;: &quot;balance&quot; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 还有很多其它聚合方法，请参考https://www.elastic.co/guide/en/elasticsearch/reference/6.2/search-aggregations.html。 elasticsearch-pyPython可使用elasticsearch-py模块来操作Elasticsearch，具体文档请查看Python这篇文章的elasticsearch第三方模块。 Lucene查询ElasticSearch提供的一些查询方式(query types)能够被Lucene的查询解析器(query parser)语法所支持。可直接在Kibana的发现面板上直接使用。 全文搜索 string “string1 string2” Kibana会匹配和展示对应的string。 键值对 key:value: 全文搜索 &quot;key:value&quot;： 精确搜索 _exists_:key: 返回结果中需要有key字段 _missing__:key: 不能含有key字段 如:http.code:502，log-levle:warn 通配符 ? * 这两者都不能用作第一个字符，如?.txt, *.txt 正则表达式它也支持性能较差的正则表达式。 模糊搜索 ~: 在一个单词后面加上~启用模糊搜索 ~n： 设置编辑距离(整数)，指定需要多少相似度，越大越接近原始值 在短语后面加~，可以搜索到被隔开或顺序不同的单词 first~也可以匹配到frist&quot;hello world&quot;~5表示两者之间可以隔着5个单词 范围搜索数值/时间/IP/字符串 类型的字段可以对某一范围进行查询 1234567891011length:[100 TO 200]sip:[&quot;172.24.20.110&quot; TO &quot;172.24.20.140&quot;]date:&#123;&quot;now-6h&quot; TO &quot;now&quot;&#125;tag:&#123;b TO e&#125; 搜索b到e中间的字符count:[10 TO *] * 表示一端不限制范围count:[1 TO 5&#125; [ ] 表示端点数值包含在范围内，&#123; &#125; 表示端点数值不包含在范围内，可以混合使用，此语句为1到5，包括1，不包括5可以简化成以下写法：age:&gt;10age:&lt;=10age:(&gt;=10 AND &lt;20) 优先级使用^使一个词语比另一个搜索优先级更高，默认为1。可以为0~1之间的浮点数，来降低优先级 逻辑操作 AND OR NOT +: 搜索结果中必须包含此项 -: 不能包含此项 123(a OR b) AND chost:(baidu OR qq OR google) AND host:(com OR cn) 转义字符 \：使用转义字符来转移特殊字符 MetricbeatMetricbeat是一个轻量级的托运器(lightweight shipper), 你可从安装该软件的操作系统和服务器上定期收集指标信息。它可将收集到的指标信息或统计信息发送到指定的输出(如elasticsearch/Logstash)。 具体使用方法也和Filebeat差不多！ Metricbeat通过从服务器上运行的系统和服务收集指标来帮助你监控服务器。如： Apache Docker Kafka Kubernets HAProxy MongoDB MySQL Nginx PHP-FPM PostgreSQL Redis RabbitMQ System Zookeeper … PacketbeatPacketbeat是一个实时网络数据包分析器，可与Elasticsearch一起提供应用程序监控和性能分析。 Packetbeat通过捕获应用服务器之间的网络流量，解码应用层协议(HTTP, MySQL, Redis…)，将请求与响应关联起来，并记录每个事务感兴趣的字段。Packetbeat可以帮助你轻松地注意到后端应用程序的问题，例如错误或性能问题，并且可以更快地排除故障并进行修复。Packetbeat捕获服务器之间的流量，即时分析应用层协议，并将这些消息关联到事务中。并将这些事务插入到Elasticsearch或使用Redis和Logstash的队列中。 Packetbeat支持的协议如下: ICMP DNS HTTP AMQP Cassandra MySQL PostgreSQL Redis MongoDB Thrift-RPC TLS HeartbeatHeartbeat是一个轻量级守护进程，用以定期检查服务的状态并确定它们是否可用。与Metricbeat不同，Metricbeat只会告诉你服务器是down/up，而Heartbeat会告诉你服务是否可以访问(reached)。 当你需要验证是否满足服务级别协议的服务正常运行时间时，Heartbeat非常有用。当需要验证外部没有人能访问企私有服务器上的服务时，这也很有用。你可以配置Heartbeat来ping指定主机名的所有DNS可解析的IP地址。这样，你可以检查所有负载均衡的服务，看他们是否可用。配置Heartbeat时，你可以指定用于表示要检查的主机名的监视器(monitor)。每台监视器都根据你指定的时间表运行。 Heartbeat目前支持通过通过如下方式监控主机： ICMP当你指向检查服务是否可用时，请使用icmp监视器。此功能需要root权限 TCP支持SSL/TLS/proxy你可以选择配置此监视器，通过发送 and/or 接收自定义有效内容来验证端点 HTTP支持SSL/TLS/proxy你可以选择配置此监视器，来验证该服务是否会返回预期的响应。如特定状态码，响应header或内容 AuditbeatAuditbeat是一个轻量化的托运器(shipper)，在系统上安装它，以审核(audit)系统上用户和进程的活动。 例如，你可以使用Auditbeat从Linux Audit Framework收集和集中审计事件。你还可以使用它来检查关键文件的改动，并识别潜在的安全策略违规。 Topbeat在v5.0, Topbeat被Metricbeat取代！ Topbeat的版本与其它Elastic Stack组件不同步，ES是v6.2.4， 而Topbeat是v1.3。所以需要额外安装repo. Topbeat是一个轻量化的托运器(shipper)，来定期读取系统和每个进程的CPU和内存统计信息，然后为Elasticsearch中的统计信息编制索引。 Topbeat通过收集如下指标来帮助你监控你的服务器: ystem-wide statistics system load 1, 5, 15 system wide CPU usage user, system, idle, IOWait system wide memory uusage total, used, free system wide swap usage total, used, free Per-process statistics process name process parent pid process state process pid process CPU usage process Memory usage File system statistics avaliable disks name, type, mounted total, used, free, available APMAPM(Application Performance Monitoring)应用程序性能监控，自动收集应用程序内部的深入性能指标和错误。 它由三个组件组成: Agents Node.js Django Flask Ruby on Rails Rack JS Server UI ElastAlert GitHub: https://github.com/Yelp/elastalert Docs: https://elastalert.readthedocs.io ElastAlert是一个简单灵活的用于Elasticsearch中数据异常的告警框架。它使用Python2.x编写，不支持Python3。ElastAlert功能与Watcher类似，只不过Watcher是Elastic Enterprise中才支持，而ElastAlert是一个开源软件。 Kibana非常适合可视化和查询数据，但它需要一个配套工具来对数据进行告警，出于这种需要，ElastAlert诞生了。如果你几乎实时地将数据写入Elasticsearch，并希望在数据与某些模式匹配时收到告警，则ElastAlert就是适合你的工具。 综述ElastAlert被设计为可靠、高度模块化、易于设置和配置。它使用两种类型的组件与Elasticsearch进行结合： rule type alerts 定期检查Elasticsearch并将数据传递给规则类型，它确定了何时找到匹配项。当匹配发生时，它触发一个或多个报警，而这些报警便采取具体行动。 每组规则定义了一个查询、一个规则类型和一组警报。 ElasAlert几种通用规则类型： frequencyMatch where there are X events in Y time spikeMatch when the rate of events increases or decreases flatlineMatch when there are less than X events in Y time blacklist/whitelistMatch when a certain field matches a blacklist/whitelist anyMatch on any event matching a given filter changeMatch when a field has two different values within some time ElasAlert几种内建报警类型： Command Email JIRA OpsGenie SNS HipChat Slack Telegram Debug Stomp 你也可以导入和编写规则类型和报警类型。 除了这些基础用法外，还有许多其它功能: Alerts link to Kibana dashboards Aggregate counts for arbitrary fields Combine alerts into periodic reports Separate alerts by using a unique key field Intercept and enhance match data 可靠性Reliability ElasAlert有多种功能，可在restart或Elasticsearch不可用时使其更可靠: ElastAlert将其状态保存到Elasticsearch，并在启动时先恢复先前停止的状态 如果Elasticsearch没有响应，ElastAlert将等待它恢复，然后再继续 抛出错误的警报可能会在一段时间内自动重试 模块性Modularity ElastAlert有3个主要组件，可作为模块导入或自定义。 rule types规则类型负责处理从Elasticsearch返回的数据。 alerts警报负责根据匹配采取行动。 enhancements增强功能是一种拦截警报并以某种方式修改或增强警报的方法。 配置配置项ElastAlert有一个全局配置文件config.yaml，它定义了几个操作方面: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#ElastAlert将持续查询熊当前到buffer_time前的窗口buffer_time#ESes_hostes_port#可选es_usernamees_password#URL prefix for the Elasticsearch endpointes_url_prefix#Method for querying Elasticsearch，默认GETes_send_get_body_as#默认20es_conn_timeout#可选配置use_sslverify_certsclient_certclient_keyca_certs#规则配置文件目录rules_folder#递归，默认truescan_subdirectories#查询频率，如 minutes: 5run_every#elastalert将存储数据的索引名称writeback_index#报警失败的重试窗口alert_time_limit#单个查询中从es下载的最大文档数，默认10 000max_query_sizescroll_keepalive#聚合在一起的最大警报数，默认10 000max_aggregation#ElastAlert从最近开始运行的查询开始的最长时间old_query_limit#当抛出未知异常时，禁用rule。 默认truedisable_rules_on_error#Email#接收通知的邮件nottify_email#默认值ElastAlertfrom_addrsmpt_hostemail_reply_to#Amazon Elasticsearch Serviceaws_regionboto_profileprofile#在将文档写入Elasticsearch前，ElastAlert使用下划线替换字段名中的任意一个点(.)。默认值Falsereplace_dots_in_field_names#es中用于字符串多字段的子字段的后缀string_multi_field_name 运行ElastAlert运行： 1python elastalert/elastalert.py 一些参数： 1234567891011121314151617--config--debug--verbose--start--end--rule--slience--es_debug--es_debug_trace--pin_rules 首次运行ElastAlertRunning ElastAlert for the First Time 依赖Requirements: es ISO8601 or Unxi timestamped data Python 2.7 python2-pip python-dev libffi-dev libssl-dev 安装12345678910111213141516#依赖yum install python2-pip python-dev#setuptools &gt;= 11.3pip2 install --upgrade setuptools#elasticsearch &gt;= 5.0pip2 install elasticsearchpip2 install elastalert#or#git clone https://github.com/Yelp/elastalert.git#cd elastalert#python2 setup.py install 之后修改配置文件，我将ElastAlert目录移动到了/etc/下。修改配置文件，并将ElastAlert的config.yaml.example配置保存为config.yaml。 设置esSetting Up Elasticsearch ElastAlert将有关其查询及报警的信息和元数据报错到Elasticsearch。这虽然不是必须的，但却强烈建议使用。 12345678910111213141516#创建一个用于ElastAlert写入的indexelastalert-create-index#会有es主机，端口，用户，密码和索引相关信息Enter Elasticsearch host: zhang21Enter Elasticsearch port: 9200Use SSL? t/f: fEnter optional basic-auth username (or leave blank):Enter optional basic-auth password (or leave blank):Enter optional Elasticsearch URL prefix (prepends a string to the URL of every request): New index name? (Default elastalert_status)Name of existing index to copy? (Default None)Elastic Version:6Mapping used for string:&#123;&apos;type&apos;: &apos;keyword&apos;&#125;New index elastalert_status createdDone! 创建一个规则Creating a Rule 每个规则定义要执行的查询，触发匹配的参数以及每个匹配要触发的报警列表。cat ./example_rules/example_frequency.yaml 1234567891011121314151617181920212223242526272829303132333435es_host: elasticsearch.example.comes_port: 14900#唯一的规则名name: Example rule#规则类型type: frequency#要查询的索引index: logstash-*#触发报警的阈值num_events: 50#阈值的时间区间timeframe: hours: 4#过滤列表filter:- term: some_field: &quot;some_value&quot;#报警列表alert:- &quot;email&quot;#报警地址列表email:- &quot;elastalert@example.com&quot; 栗子elastalert: 12345678910111213141516171819vim /etc/elastalert/example_rules/example_frequency.yamles_host: &quot;192.168.1.11&quot;es_port: 9200name: &quot;test rule&quot;type: &quot;frequency&quot;#此处我用python新建一个索引，用于测试index: &quot;my-index&quot;num_events: 3timeframe: hours: 1filter:- term: name: &quot;zhang21&quot;alert:- &quot;email&quot;email:- &quot;elastalert@example.com&quot; 测试规则运行elasticalert-test-rule工具将测试你的配置文件是否成功加载并在过去24h内以调试模式运行： 1elastalert-test-rule ./example_frequency.yaml 配置首选项将按如下方式加载： yaml文件中指定的配置 配置文件中指定的配置 默认配置 运行ElastAlert有两种方式来调用ElastAlert： Supervisor Python 为了便于调试，下面将直接调用。 123456789python2 -m elastalert.elastalert --verbose --rule /etc/elastalert/example_rules/example_frequency.yamlINFO:elastalert:Starting up#这里遇到一个错误ERROR:root:Error running query: TransportError(400, u'search_phase_execution_exception', u'No mapping found for [@timestamp] in order to sort on')#解决方法，在规则文件example_frequency.yaml中添加timestamp_field: timestamp 使用Python3创建索引： 123456789101112131415from datetime import datetimefrom elasticsearch import Elasticsearches=Elasticsearch('http://192.168.1.11:9200')es.info()#写入文档data = &#123; 'timestamp': datetime.now(), 'name': 'zhang21'&#125;for i in range(1, 21): es.index(index='my-index', doc_type='test-type', id=i, body=data) 规则类型和配置项Rule Types and Configuration Options 规则配置项Rule Configuration Cheat Sheet 选项太多，自己去看: https://elastalert.readthedocs.io/en/latest/ruletypes.html 通用配置项每个在rules_folder下的.yaml文件默认都会被执行。 必须的配置 es_host es_port index name type alert 可选配置自己去看。 规则类型Rule Types 在elastalert/ruletypes.py中定义的各种RuleType class构成了ElastAlert的主要逻辑。每个规则都在内存中保存一个实例，传递通过给定过滤器查询es返回的所有数据，并根据该数据生成匹配。 any任意规则都将匹配所有内容。查询返回的每个匹配都会生成一个警报。 blacklist黑名单规则根据黑名单检查某个字段，如果它存在于黑名单中，则匹配。 黑名单规则需要两个额外项：compare_key——与黑名单进行比较的字段。如果为空，事件将被忽略。blacklist——黑名单列表值或黑名单文件列表(&quot;!file ./blacklist.txt&quot;) 栗子： 1234blacklist: - value1 - value2 - &quot;!file /tmp/blacklist1.txt&quot; whitelist白名单规则根据白名单检查某个字段，如果列表中不包含此字段，则匹配。 白名单规则需要三个额外项：compare_key——与白名单进行比较的字段ignore_null——如果为true，则没有compare_key字段的事件将不匹配whitelist——白名单列表值或白名单文件列表 栗子: 12345whitelist: - value1 - value2 - &quot;!file /tmp/whitelist1.txt&quot; - &quot;!file /tmp/whitelist2.txt&quot; change此规则将监视某个字段，如果此字段改变就匹配。 此规则需要三个额外项：compare_key——监控要改变的字段名。可以是一个列表，如果任意字段发生标号，都将触发警报。ignore_null——如果为true，则没有compare_key字段的事件将不计为已更改。query_key——此规则基于每个查询键应用。 一个可选字段：timeframe——改变之间的最大时间 frequency此规则匹配在给定时间范围内至少一定数量的事件。 此规则需要两个额外项：num_events——将会触发报警的事件数timeframe——上面事件的时间范围 spike(突增)当给定时间段内的事件量的spike_height次数大于或小于前一个时间段时，此规则匹配。它使用两个滑动窗口(引用和当前)来比较。 此规则需要三个额外项：spike_height——上次时间段时间数与前时间段事件数的比率，将处罚告警spike_type——up/down/bothtimeframe：时间段 flatline(脉波)当一段时间内事件总数匹配给定阈值时，此规则匹配。 此规则需要两个额外项：threshold——不触发警报的最小事件数timeframe——时间段 new term(术语)当一个以前从未见过的新值出现在字段中时，此规则匹配。 此规则需要一个额外项：fields——要监控的新术语的字段列表 cardinality(基数)在一个时间范围内，当某个字段的唯一值的总数高于或低于阈值时，此规则匹配。 此规则需要：timeframe——时间段cardinality_field——计算基数的字段 最大或最小基数取一个max_cardinality——数据的基数大于此报警min_cardinality——数据基数小于此报警 metric aggregation当计算窗口中的度量值高于或低于阈值时，此规则匹配。默认值为buffer_time。 此规则需要：metric_agg_key——计算度量标准的字段metric_agg_type——字段的类型doc_type——指定要搜索的文档类型 最大和最小至少需要一个max_threshold——计算的度量标准大与此，报警min_threshold——计算的度量标准小于此，报警 percentage match当计算窗口内匹配桶(bucket)中的文档百分比高于或低于阈值时，此规则匹配。默认情况下，计算窗口为buffer_time。 此规则需要：match_bucket_filter—— ES filter DSL。为匹配桶定义了一个过滤器，它应用匹配查询过滤器并返回文档的子集。doc_type——指定查询文档类型 最大和最小至少需要一个min_percentage——匹配文档的百分比小于此，报警max_percentage——匹配文档的百分比大于此，报警 Alerts每条规则都可以附加任意数量的报警。Alerts是Alerter的子类，并从ElastAlert传递包含相关信息的字典或字典列表。与规则配置类似，它们在规则配置文件中配置。 1234alert:- email- jira- xxx 多个邮件：12345alert:- emailfrom_addr: &quot;no-reply@example.com&quot;email: &quot;someone@example.com&quot; 1234567alert:- email: from_addr: &quot;no-reply@example.com&quot; email: &quot;someone@example.com&quot;- email: from_addr: &quot;xx&quot; email: &quot;xxx&quot; Alert Subject可通过添加包含自定义摘要的alert_subject来自定义电子邮件主题。 1alert_subject: &quot;Issue &#123;0&#125; ouccurreda at &#123;1&#125;&quot; 123alert_subject_args:- issue.name- &quot;@timestamp&quot; 如果规则匹配索引中的多个对象，则仅使用第一个匹配来填充格式化程序的参数。 Alert Content有几种方法可以格式化给种类型事件的正文： 1234567rule_name = namealert_text = alert_textruletype_text = Depends on typetop_counts_header = top_count_key, &quot;:&quot;top_counts_value = Value, &quot;: &quot;, Counttop_counts = top_counts_header, LF, top_counts_valuefield_values = Field, &quot;: &quot;, Value 默认：123456789body = rule_name [alert_text] ruletype_text &#123;top_counts&#125; &#123;field_values&#125; command命令报警允许你执行任意命令并从匹配中传递参数或stdin。该命令的参数可以使用Python格式的字符串语法来访问匹配的部分内容。报警器将打开一个子进程并可选地传递匹配，或在聚合报警的情况下，将其作为json阿虎组匹配到进程的stdin。 此报警需要一个选项：command——要执行的参数列表或要执行的字符串。如果是列表格式，则第一个参数是要执行的程序名。如果传递了一个字符串，则该命令通过shell执行。 字符串可使用%或.format()进行格式化。这是Python的替换。如果在命令中使用格式化数据，清泪建议使用args列表格式而不是shell字符串。 12345alert:- commandcommand: [&quot;/bin/send_alert&quot;, &quot;--username&quot;, &quot;%(username)s&quot;]#command: [&quot;/bin/send_alert&quot;, &quot;--username&quot;, &quot;&#123;match[username]&#125;&quot;] Email此报警将会发送电子邮件。它默认连接到smtp_host服务器。 它需要一个选项：email——接收报警的地址 Jira Debug调试报警器经使用Python logger的info level记录报警信息。它被记录到名为elastalert的Python logger对象中，可以使用getLogger命令轻松访问该对象。 HTTP POST此报警类型使用HTTP POST将结果发送到JSON ENDPOINT。默认情况下，json会包含所有匹配，除非你指定http_post_payload。 需要：http_post_url 123456alert: posthttp_post_url: &quot;http://example.com/api&quot;http_post_payload: ip: clientiphttp_post_static_payload: apikey: abc123 ElastAlert元数据索引ElastAlert Metadata Index ElastAlert使用Elasticsearch存储有关其状态的各种信息。这不仅允许对ElastAlert操作进行某种程度的审计和调试，而且还可以在ElastAlert关闭、重启或崩溃时避免数据丢失或重复报警。此集群和索引信息在全局配置文件中使用es_host, es_port, writeback_index定义。ElastAlert必须能够写入到此索引。elastalert-create-index将为你创建具有正确映射的索引，并可选择从现有的ElastAlert写回索引中复制文档。 ElastAlert将会在writeback index中创建三种不同类型的文档： elastalert_status elastalert elastalert_error elastalert_statuselastalert_status是为给定规则执行查询的日志，包含： @timestamp rule_name starttime endtime hits： 查询的结果数 matches： 匹配数 time_taken： 查询所用秒数 elastalertelastalert是有关触发的每个报警的日志信息，包含： @timestamp rule_name alert_info alert_sent alert_time match_body alert_exception aggregate_id elastalert_error当ElastAlert发生错误时，它将写入Elasticsearch和stderr。elastalert_error类型包含： @timestamp message traceback data silencesilence是指由于重新设置或使用-silence而抑制给定规则的警报的记录。 @timestamp rule_name until：警报在此开始发送的时间戳 exponent：除非设置了exponential_realert，否则它将为0 添加一个新规则类型Adding a New Rule Type 添加一个新报警器Adding a New Alerter 为规则编写过滤器Writing Filters For Rules 增强功能Enhancements 增强功能是一些模板，可让你在发送警报之前修改匹配项。 kibana-pluginelastalert kibana-plugin是一个第三方插件。ElastAlert Kibana plugin repository: https://github.com/bitsensor/elastalert-kibana-plugin 注意，安装的时候要注意kibana的版本。具体信息见README。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>Logstash</tag>
        <tag>Kibana</tag>
        <tag>Filebeat</tag>
        <tag>Metricbeat</tag>
        <tag>Heartbeat</tag>
        <tag>Packetbeat</tag>
        <tag>Auditbeat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Beanstalkd]]></title>
    <url>%2F2018%2F04%2F10%2FBeanstalkd%2F</url>
    <content type="text"><![CDATA[环境： CentOS7.x86_64 Beanstalkd v1.10 Beanstalkd介绍Beanstalk，一个高性能、轻量级的分布式内存队列系统。高性能离不开异步，异步离不开队列，而其内部都是Producer-Comsumer模式的原理。 Beanstalkd核心概念： job(任务)一个需要异步处理的任务，是beanstalkd中的基本单元，需要放在一个tube中。 tube(管道)一个有名的任务队列，用来存储同一类型的job。是producer和consumer操作的对象。 producer(生产者)job的生产者，通过put命令将一个job放到一个tube中。 consumer(消费者)job的消费者，通过reserve/release/bury/delete命令来获取或改变job的状态。 beanstalkd官方状态图： Beanstalkd特性 优先级支持0-2^32的优先级。值越小，优先级越高，默认是1024。 持久化可通过binlog将job及其状态记录到文件里面。在Beanstalkd下次启动时，可通过读取binlog来恢复之前的job及状态。 分布式容错分布式设计和Memcached类似，beanstalkd个server之间并不知道彼此的存在，都是通过client来实现分布式以及根据tube名称到特定server获取job。 超时控制为了防止某个consumer长时间占用任务但不能处理的情况，beanstalkd为reserve操作设置了timeout。如果该consumer不能在指定时间内完成job，job将被迁移会READY状态，供其它consumer执行。 安装Beanstalkd由于epel源可直接安装beanstalkd，So: 123456789101112yum install -y beanstalkd#配置文件/etc/sysconfig/beanstalkd#启动systemctl start beanstalkd#等同于#/usr/bin/beanstalkd -l 0.0.0.0 -p 11300 -u beanstalkd Beanstalk的客户端和管理端官方没有推出客户端和管理端，GitHub上有一些第三方插件，请自己选择使用。 客户端 pheanstalkd: https://github.com/pda/pheanstalk/ pheanstalk是一个在PHP中操作beanstalkd的客户端。具体使用方法参考README。 管理端 beanstalk_console： https://github.com/ptrofimov/beanstalk_console aurora: https://github.com/xuri/auroraaurora 是一个基于 Web 的 Beanstalk 消息队列服务器管理工具，单文件无需依赖其他组件，支持管理本地和远程多个队列服务器。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Beanstalkd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Supervisor]]></title>
    <url>%2F2018%2F04%2F08%2FSupervisor%2F</url>
    <content type="text"><![CDATA[参考： http://www.supervisord.org 环境： Supervisor 3.3.4 CentOS7.x86_64 介绍 综述Supervisor是一个C/S系统，允许用户在Unix-Like操作系统上控制许多进程。它受如下启发： Convenience Accuracy Delegation Process Group 特点 Simple Centralized(统一) Efficient Extensible Compatible Proven(久经考验) Supervisor组件 supervisord Supervisor的服务器部分被命名为supervisord。负责启动子进程，响应客户端的子进程，重启奔溃或退出的子进程，记录其stderr和stdout，以及生成对应的事件 默认使用的配置文件为/etc/supervisord.conf——Windows-INI格式的文件，由于它包含了未加密的username和password，请保证它安全 supervisorctl Supervisor的客户端部分被命名为supervisorctl。用户可连接到不同的supervisord，status/stop/start子进程，获取supervisord中正在运行的进程列表 通过Unix domain socket或TCP socket与server通信，客户端在执行命令前应该先提供认证。客户端和服务端使用同一个配置文件 Web server Web界面，可通过它查看或控制进程状态 XML-RPC接口 用于询问和控制管理程序及其运行的程序 平台要求 在Unix-Like系统上运行良好 不支持Windows系统 Supervisor运行在Python2.4或之后的版本，不支持Python3 安装安装方法取决于你的操作系统。 通过网络安装 推荐使用setuptools的easy_install 下载Supervisor包并调用一个命令 使用Setuptools的网络安装如果Python解释器安装了Setuptools: 1easy_install supervisor 不使用Setuptools的网络安装如果系统上未安装Setuptools，那么你需要手动去下载Supervisor发行套件和安装它。 PYPI： https://pypi.python.org/pypi/supervisor 123456wget https://pypi.python.org/pypi/supervisor/xxx.tar.gztar -xzf xxx.tar.gzpython setup.py install#它会自动通过网络下载依赖 安装一个分发包一些Linux发行版提供了可通过系统包管理工具安装Supervisor。这些包由第三方制作，包含了对特定发行版的一些修改。 1234yum info supervisoryum search supervisoryum install -y supervisor 通过pip安装1pip install supervisor 创建一个配置文件由于我是通过yum安装，所以supervisor配置文件自动在/etc下自动生成： 默认配置文件： /etc/supervisord.conf建议在此配置文件中加入[include]，默认已包含此配置 目录： /etc/supervisord.d建议将每个配置单独写在此目录下 运行Supervisor 添加一个程序在supervisord为你做任何有用的事情之前，你至少需要在配置文件中添加一个程序部分。program部分将定义在调用supervisord命令时如何运行和管理一个程序。 一个最简单的栗子： 12[program:foo]command=/bin/cat 上面的栗子只命名了一个命令，还有很多其它关于程序部分的设置。 运行supervisord使用supervisord命令启动supervisord，进程将自我守护，并从终端分离。并将操作日志默认放于$CWD/supervisor.log。你可传递-n/--nodaemon标志来将进程放置于前台，这样对于debug很有帮助。 要更改supervisord控制的程序集，请编辑配置文件并kill- HUP，或以其它方式重新启动supervisord进程。 supervisord命令接受许多命令行选项。这些命令行选项中的每一个都会覆盖配置文件中的任何等效值。 详细选项： http://www.supervisord.org/running.html#supervisord-command-line-options 运行supervisorctl使用supervisorclt命令启动supervisorctl客户端。如果需要验证supervisord调用，则系统会要求您提供验证凭据。 123supervisorctl status allsupervisorctl stop all supervisorctl Actions如果在命令行中指定了-i或未指定任何操作(action)，则将启动交互式输入的shell解释操作。 12345678supervisorctl help#查看可操作的actiondefault commands (type help &lt;topic&gt;):=====================================add clear fg open quit remove restart start stop updateavail exit maintail pid reload reread shutdown status tail version Signalssupervisord程序可能会发送某些actions，让它在运行时执行某些操作。你可将这些信号发送到一个单一的supervisord的PID。 信号处理程序 SIGTERM supervisord及其所有子进程都将关闭 SIGINT supervisord及其所有子进程都将关闭 SIGQUIT supervisord及其所有子进程都将关闭 SIGHUP supervisord将关闭所有进程，重新载入配置文件并启动所有进程 SIGUSR2 supervisord将关闭并重新打开主要活动日志和所有子日志文件 运行安全开发人员尽力确保以root身份运行的supervisord进程不会导致意外的权限升级。但supervisord允许在其配置文件中的任意路径规范写入数据，允许任意路径选择可能会造成符号链接工具的漏洞。确保supervisord配置文件的权限安全，除此之外，确保Python PATH和标准库都有足够的文件权限保护。 开机自启由于我是yum安装，所以能够直接使用系统服务管理来设置开机自启。 配置文件Supervisor的配置文件通常命名为supervisord.conf。如果没有指定-c配置文件，应用程序会从以下位置去寻找配置文件： $CWD/supervisord.conf $CWD/etc/supervisord.conf /etc/supervisord.conf /etc/supervisor/supervisord.conf (since Supervisor 3.3.0) ../etc/supervisord.conf (Relative to the executable) ../supervisord.conf (Relative to the executable) 文件格式supervisord.conf is a Windows-INI-style (Python ConfigParser) file.它包含section（[header]）和section中的key/value对。 环境变量使用Python字符串表达式语法%(ENV_X)%，可以在配置文件中使用环境中存在的环境变量 12[program:example]command=/usr/bin/example --loglevel=%(ENV_LOGLEVEL)s [unix_http_server]在此section中应该插入在Unix domain socket上监听的HTTP server的配置参数。如果没有配置此section，则Unix domain socket HTTP server将不会启动。 123456789101112131415161718192021[unix_http_server]#supervisor监听HTTP/XML-RPC请求的Unix domain socket的路径file#socket文件的权限模式chmod#socket的用户和组chown#访问HTTP server需要的认证username#密码可以是明文，或使用SHA加密的字符串password [inet_http_server]监听TCP(internet) socket 的HTTP server的配置参数。如果此section未配置，inet HTTP server将不会启动。 12345678910#tcp host:port，supervisor监听HTTP/XML-RPC请求的地址port#HTTP server认证username#密码可以是明文，或SHA加密passwd [supervisord]与supervisord进程有关的全局设置。 123456789101112131415161718192021222324252627282930313233logfilelogfile_maxbyteslogfile_backps#critical, error, warn, info, debug, tracelogevelpidfileumasknodaemonminfdsminprocs#防止supervisord在启动时清除任何现有子日志文件nocleanupchildlogdiruserdirectorystrip_ansienviromentidentifier [supervisorctl]supervisorctl交互式shell程序。 123456789serverurl#与前面设置的验证账户一致usernamepasswordprompthistory_file [program:x]supervisord知道的应该启动和控制的程序。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566 #该程序启动时将运行的命令command #进程名称process_name #多个实例numproc #用于计算numprocs开始的数量numprocs_start #程序在启动和关闭顺序中的相对优先级priority #当supervisord启动时，改程序将自动启动autostart #程序在启动后需要保持运行以考虑启动成功的总秒数，设置为0表示不需要再任何特定的事件内保持运行startsecs #允许失败的尝试次数，然后放弃并将进程置入fatal状态startretries #自动重启进程autorestart #异常退出码exitcodes #请求停止时用于杀死程序的信号stopsignal #发送停止信号后，等待系统将信号返回给supervisord的秒数stopwaitsecs #将停止信号发送给整个进程组stopagroup #killasgroup #以哪个用户运行该程序userredirect_stderrstdout_logfilestdout_logfile_maxbytesstdout_logfile_backupsstdout_capture_maxbytesstdout_events_enabledstderr_logfilestderr_logfile_maxbytesstderr_logfile_backupsstderr_capture_maxbytesstderr_events_enabledenvironmentdirectoryumaskserverurl [include]如果配置文件包含[include]部分，则它必须包含一个名为files的key。该key中的值包含了其它配置文件。 12#文件空间的空格分隔序列，路径可以是相对或绝对。files [group:x]将同质进程组组合成一个异质进程组通常很有用，所以它们可以作为supervisor各种控制器接口的一个单元进行控制。 12345#程序的逗号分隔列表programs#优先级priority [fcgi-program:x]12345678910#程序的fastCGI socket或TCP或Unix domain socketsocket#为socket指定特定user或groupsocket_owner#指定permission模式socket_mode [eventlistener:x]supervisor允许在配置文件中定义专门的同质进程组(event listener pools)。 12345buffer_sizeeventsresult_handler [rpcinterface:x][rpcinterface:x]适用于希望通过自定义行为扩展supervisor的人们。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Consul]]></title>
    <url>%2F2018%2F04%2F05%2FConsul%2F</url>
    <content type="text"><![CDATA[参考： https://www.consul.io/intro/index.html https://www.consul.io/docs/ Consul Template: https://www.hashicorp.com/blog/introducing-consul-template 环境： CentOS7x86_64 Consul v1.2.0 简介介绍consul是什么，它可以解决哪些问题，以及如何开始使用它。 Consul是什么Consule有多个组件，但总体而言，它是发现(discovery)和配置(config)基础架构(infrastructure)服务的工具。它提供几个关键特点： 服务发现(service discovery) Consul客户端可提供一个服务，如API或mysql，其它客户端能够使用Consul来发现给定服务的提供者。使用DNS或HTTP，应用程序可以轻松找到他们所依赖的服务 健康检查(health checking) Consul可以提供任何数量的健康检查，既可以与给定服务相关联(webserver return 200)，也可与本地节点(内存使用率小于90%)相关联。操作人员可用此信息来监视集群运行状况，服务发现组件使用此信息将流量(traffic)从不健康的主机中引导出去 KV store 应用程序可将Consul的分层Key/Value用于存储任何目的，包括动态配置(dynamic configuration)、功能标记(feature flagging)、协调(coordination)、领导选举(leader election)…简单的HTTP API使其易于使用 多数据中心(Multi Datacenter) Consul支持多数据中心，这意味着Consul的用户不必担心构建额外的抽象层以扩展到多个区域 Consul旨在与DevOps和应用程序开发者保持友好，使其成为现代化 ，弹性基础架构的完美选择。 Consul用例 服务发现(service )服务注册，集成健康检查，使用DNS或HTTP接口使得任何服务都能被其它服务发现。 服务分割(service segmentation)通过自动TLS加密和基于身份的授权实现安全的服务到服务通信。 服务配置(service configuration)功能丰富的 key/value 可轻易配置服务。 Consul基础架构Consul是一个分布式、高可用的系统。 每一个向Consul提供服务的节点都运行一个Consul agent。运行agent对于服务发现或get/set Key/Value不是必需的。agent负责健康检查节点上的服务和节点自身。 agent可与一个或多个Consul server交流。Consul server是数据存储和复制集所在之地。server之间选出一个leader。虽然Consul可以使用一台服务器，但推荐使用3-5台以避免数据丢失的故障情况。对每一个数据中心都推荐使用Consul server cluster。 需要发现其它服务或节点的基础架构组件 可以查询任何Consul server或Consul agent。agent自动将查询发送到server。 每个数据中心运行一组consul server cluster。当发生cross-datacenter服务发现或配置请求时，本地consul server将请求转发给远程数据中心并返回结果。 快速开始安装Consul 二进制包: https://www.consul.io/downloads.html 解压缩，得到一个consul二进制可执行文件，可将其放入系统路径 验证安装: consul 运行consul-agent安装consul后请务必运行agent，agent可运行在server或client模式。每个datacenter必须至少有一台server，推荐3-5台做一个集群。单一server部署非常不安全，在故障情况下数据丢失就不可避免了。 所有其它agents都以client模式运行。client是一个非常轻量化的进程——它注册服务、运行健康检查、转发查询给server。agent必须运行在集群的每个节点上。 启动agent测试consul development模式，不建议在生产环境使用此方法，此处做测试。 12345consul agent -devnetstat -nltp#可根据日志看出agent已成为server，并成为集群leader Consul成员members命令基于gossip protocol并最终保持一致。 12345678910111213consul members#节点名称、监听地址、健康状态、集群角色、版本信息Node Address Status Type Build Protocol DC Segmentzhang22 127.0.0.1:8301 alive server 1.0.6 2 dc1 &lt;all&gt;#使用HTTP API将请求转发给server以获取一致的view of worldculr localhost:8500/v1/catalog/nodes#DNS interface也可以查询节点，默认端口8600dig @127.0.0.1 -p 8600 zhang22.node.consul 停止agent可使用Ctrl + C优雅地终止agent，你可以看到它离开集群并关闭。 优雅关闭，Consul会通知集群其它节点此节点的离开。如果你强制kill agent，则集群的其它节点将检测该节点失败。当成员离开时，其服务和健康检查将从catalog中移除。当成员失败时，其健康状态被标记为critical，但不会从catalog中移除。Consul会自动尝试重连失败的节点，允许它从当前网络条件中修复，知道离开的节点不在联系。 此外，如果agent正作为server在运行，那么优雅地离开对避免造成严重的影响有帮助。 注册服务注册(register)服务并查询(query)服务。 定义一个服务服务可以通过以下两种方法注册： 服务定义(service definition) 调用HTTP API 服务定义是注册服务最常见的方式，我们将构建前面agent的配置。 1234567891011#创建一个consul配置目录mkdir /etc/consul.d#编写服务定义配置文件#假设有一个web服务运行在80端口，添加一个便于query的tagecho &apos;&#123;&quot;service&quot;: &#123;&quot;name: &quot;web&quot;, &quot;tag&quot;: [&quot;rails&quot;], &quot;port&quot;: 80 &#125;&#125;&apos; | tee /etc/consul.d/web.json#重启agent，指定配置目录consul agent -dev -config-dir=/etc/consul.d 如果你想注册多个服务，你可以在配置目录下创建多个服务定义文件。 查询服务一旦agent启动并且服务已同步，我们可通过HTTP API或DNS查询(query)服务。 DNS API使用DNS API(默认8600)查询服务 12345678#DNS name(默认) -- NAME.service.consul#只有IPdig @127.0.0.1 -p 8600 web.service.consul#返回IP/Portdig @127.0.0.1 -p 8600 web.service.consul SRV 我们还可以用DNS API按tag来过滤service。基于标签的查询格式为tag.name.service.consul。 1dig @127.0.0.1 -p 8600 rails.web.service.consul HTTP API除了DNS API，HTTP API(默认8500)同样可用于查询服务。 12#前面定义了web这个servicecurl http://localhost:8500/v1/catalog/service/web catalog API提供了给定服务的所有节点。 12#仅仅健康实例的查询 curl &apos;http://localhost:8500/v1/health/service/web?passing&apos; 更新服务服务定义可以通过更改配置文件并向agent发送SIGHUP来更新。这使得更新服务不会出现任何停机或查询服务不可达的情况。 另外，HTTP API能够用来动态地添加、移除、修改服务。 Consul集群具有多个成员的consul集群。 当consul节点启动时，它不知道任何其它节点，它是一个孤立的集群。为了了解到集群中的其它成员，agent必须要加入一个存在的集群。要加入一个现有的集群，只需知道一个现有成员。当加入集群后，agent将于其此成员闲聊，并迅速发现集群中的其它成员。一个agent可以加入任何其它agent，而不仅仅是server模式的agent。 启动agents123456789101112131415#node1consul agent -server -bootstrap-expect=1 \ -data-dir=/tmp/consul -node=agent-one -bind=ip1 \ -enable-script-checks=true -config-dir=/etc/consul.d#node2consul agent -data-dir=/tmp/consul -node=agent-two \ -bind=ip2 -enable-script-checks=true -config-dir=/etc/consul.d#两个独立的node#现在，我们有两个agent在运行中：一个server，一个client。但是他们两者并不知道对方，并仍然是一个单一节点的集群。#查看节点consul member 加入集群由于我们在启动agent的时候便已指定server，所以从哪个节点加入都一样。 12345678consul join ip#Successfully joined cluster by contacting 1 nodes.consul membersNode Address Status Type Build Protocol DC Segmentagent-one 172.16.129.141:8301 alive server 1.0.6 2 dc1 &lt;all&gt;agent-two 172.16.129.150:8301 alive client 1.0.6 2 dc1 &lt;default&gt; 在启动时自动加入集群理想情况下，每当一个新节点出现在数据中心时，它应该自动加入集群而不需要人工干预。 查询节点就像查询服务，consul有一个API用于查询节点。 123#NAME.node.consul或NAME.node.DATACENTER.conosuldig @localhost -p 8600 agent-one.node.consuldig @127.0.0.1 -p 8600 agent-two.node.consul 离开集群 优雅的退出: Ctrl+C 强制kill 健康检查对节点和服务添加健康检查(health check)。健康检查是服务发现的关键组件，可以防止使用不健康的服务。 定义检查与服务类似，一个检查能够通过定义检查或适当调用HTTP API来两种方式来注册。 定义检查是一个最基本和推荐的方法。 在consul配置目录中创建检查定义文件： 123456789#在基于脚本的健康检查上，它与consul进程使用同样的用户#如果命令以非0状态码退出，则该节点会被标记为unhealthyecho &apos;&#123;&quot;check&quot;: &#123;&quot;name&quot;: &quot;ping&quot;, &quot;args&quot;: [&quot;ping&quot;, &quot;-c1&quot;, &quot;baidu.com&quot;], &quot;interval&quot;: &quot;30s&quot;&#125;&#125;&apos; &gt;/etc/consul.d/ping.jsonecho &apos;&#123;&quot;service&quot;: &#123;&quot;name&quot;: &quot;web&quot;, &quot;tags&quot;: [&quot;rails&quot;], &quot;port&quot;: 80, &quot;check&quot;: &#123;&quot;args&quot;: [&quot;curl&quot;, &quot;localhost&quot;], &quot;interval&quot;: &quot;10s&quot;&#125;&#125;&#125;&apos; &gt;/etc/consul.d/web.jsonconsul reload 检查健康状态123curl http://localhost:8500/v1/health/state/criticaldig @127.0.0.1 -p 8600 web.service.consul KV数据Consul提供了一个易于使用的KV存储。这可以用来保存动态配置，协助服务协调，构建leader选举，并启用开发人员可以考虑构建的任何其它内容。 用法有两种方法与Consul K/V交互的方式： HTTP API Consul KV CLI 123456789101112131415161718192021222324252627282930#CLIconsul kv --helpconsul kv put name zhangconsul kv get name#zhangconsul kv get -detailed nameconsul kv puut -flags=42 who zhang21#所有key都支持设置一个64位的整数标志值#列出所有kvconsul kv get -recurse#删除consul kv delete name#使用 Check-And-Set 进行原子更新consul kv put -cas -modify-index=112 NAME zhang#导出与导入consul kv export &gt; xxx.jsonconsul kv import $xxx.json Web界面Consul支持美观的Web界面。用户界面可以查看所有的服务和节点，查看所有健康检查和当前状态，读取和设置kv数据，并自动支持多数据中心。 123consul agent -ui#localhost:8500/ui 内部详情Consul Internals 介绍Consul内部详情。 架构Architecture 词汇表Glossary Agent Client Server Datacenter Consensus Gossip LAN Geossip WAN Geossip RPC Consensus协议Consul使用consensus(共识) protocol来提供一致性(consistency)，它基于Raft(In search of an Understandable Consensus Algorithm) Raft协议Raft是基于Paxos的共识算法。 Raft的一些关键术语： LogThe primary unit of work in a Raft system is a log entry. FSM(Finite State Machine)An FSM(有限状态机) is a collection of finite states with transitions between them. Peer setThe peer set(对等集) is the set of all members participating in log replication. QuorumA quorum(仲裁) is a majority of members from a peer set: for a set of size n, quorum requires at least (n/2)+1 members. Committed EntryAn entry is considered committed when it is durably stored on a quorum of nodes. LeaderAt any given time, the peer set elects a single node to be the leader. Raft节点总是处于如下三种状态之一： follower(追随者) candidate(候选者) leader(领导者) 所有节点最初都是作为follower开始的。在这种状态下，节点可接受leader的日志条目并投票。如果一段时间内没有收到任何条目，则节点会自我提升到candidate。在candidate状态下，节点请求来自对等节点的投票。如果候选人获得仲裁(quorum)的票数，那么它将被提升为leader。leader必须接受新的日志条目并复制给其它所有follower。另外，如果陈旧读取不可接受，则所有查询也必须在leader上执行。 一旦集群具有leader，它就能够接受新的日志条目。Client可以请求leader添加新的日志条目。然后，leader将条目持久化，并尝试复制到仲裁的follower。一旦日志条目被认为提交(committed)，它就可以应用于有限状态机(FSM)。显然，允许复制日志以无限制的方式增长是不可取的。Raft提供了一种机制，可通过快照(snapshot)当前状态并压缩日志。达成共识是容错的，直到法定人数可用。建议为每个数据中心配置3-5台Consul Server。3个节点的Raft集群可以容忍单个节点故障，5个节点的Raft集群可以容忍2个节点故障。这可最大限制提高可用性。 Raft in Consul只有Consul Server节点参与Raft，并且是对等集的一部分。所有的Client节点都将请求转发给Server。 当启动的时候，单个Consul Server进入bootstrap模式，此模式允许它进行自我选举为leader。leader选出后，可以以一致性和安全性的方式将其它Server添加到对等集，之后，就可以禁用bootstrap模式。由于所有的Server作为对等集的一部分参与，因此他们都知道当前的leader。当一个RPC请求到达了non-leader Server时，请求被转发给leader。 如果RPC是查询(query)类型，意味着它是只读的，则leader根据FSM的当前状态生成结果 如果RPC是事务(transaction)类型，意味着它是可修改的，则leader生成新的日志条目并使用Raft应用它 提交日志条目并将其应用于FSM后，事务就完成了。 由于Raft副本的性质，性能对网络延迟很敏感。因此，每个数据中心选择一个独立的leader并维护一个不相交的对等集。数据由数据中心分区，每个leader仅负责其数据中心中的数据。 一致性模式Consistency Modes 虽然对副本日志的所有写入都通过Raft，但读取却更加灵活。Consul支持3种不同的读取一致性模式： default consistent stale 部署表 Servers Quorum Size Failere Tolerance 1 1 0 2 2 0 3 2 1 4 3 1 5 3 2 6 4 2 7 4 3 Gossip协议Consul 使用gossip协议来管理成员并向集群发送广播信息。所有这些都通过Serf Library提供。 Goossip in ConsulConsul使用两个不同的gossip pools: LAN pool WAN pool 网络坐标Network Coordinates Consul使用网络层层析系统来计算集群中节点的网络坐标。这些坐标允许使用非常简单的计算在任意两个节点之间估计网络往返时间。所有这些都通过使用Serf Library。 Consul中的网络坐标Network Coordinates in Consul 网络坐标在Consul中有多种表现方式： consul rtt Catalog/Health endpoints Prepared query Coordinate endpoint 使用坐标一旦你有了两个节点的坐标，则计算它们间的往返时间是很简单的： 123456&quot;Coord&quot;: &#123; &quot;Adjustment&quot;: 0.1, &quot;Error&quot;: 1.5, &quot;Height&quot;: 0.02, &quot;Vec&quot;: [0.34,0.68,0.003,0.01,0.05,0.1,0.34,0.06]&#125; 会话Sessions consul提供了一个用于构建分布式锁的会话机制。会话充当节点、健康检查和K/V数据之间的监听层。 会话设计 Agent启动和停止Consul Agent是Consul的核心进程。它维护成员关系信息，注册服务，运行检查，响应查询…Consul Agent必须运行在在Consul集群的每个节点上。 Agent有两种运行模式： server client Server节点承担了作为consensus quorum(共识法人)的额外责任，这些节点参与Raft，并在出现故障时提供强大的一致性和可用性。Client节点构成了集群的大部分，它们非常轻便。因为它们与Server进行大部分操作，保持自己的状态则很少。 运行Agent以下是一些重要信息： Node name Datacenter Server Client addr Cluster addr 123456789#直接指定配置项运行consul agent -options#将配置项写入文件，指定配置目录运行mkdir /etc/consul.dvim /etc/consul.d/consul.jsonconsul agent -config-dir=/etc/consul.d 停止Agent有两种停止方式： gracefully发送中断信号ctrl+c或运行kill -INT。优雅地退出，Agent首先通知集群它要离开集群。这样，集群便会通知其它成员该节点已离开。 forcefully通过kill signal来强制杀掉Consul。集群的其余部分最终会检测到该节点已死亡并通知集群节点已失效。 特别重要的是允许Server节点优雅地离开，以便对可用性产生最小的影响。对于Client Agent来说，节点失效和节点离开的区别对用例并不是那么重要。 生命周期Consul集群中的每个Agent都会经历一个生命周期(lifecycle)。当Agent首次启动时，他并不知道集群中的其它任何节点。要发现它的同伴，它必须加入集群。这使用join命令或在配置文件中配置。一旦一个节点加入，这个信息就会传递给整个集群，这意味着所有节点最终都会意识到对方。如果Agent是一个Server，则已经存在的Server就会开始复制(replicating)到新节点。 在网络故障的情况下，某些节点可能无法被其它节点访问。在这种情况下，无法访问的节点被标记为失败(failed)。无法区分网络故障和Agent崩溃，因此两种情况的处理方式都是相同的。该信息将在service catalog中被更新。 当一个节点离开时，它指定了它的意图，并且集群将该节点标记为已离开。与失败(failed)不同，节点提供的所有服务都立即注销(deregistered)。如果Agent是Server，则对其的复制(replication)将停止。 为了防止死亡(failed/left)节点的堆积，Consul会自动将死亡节点从目录中移除。这个过程被称为收割(reaping)。 DNS接口DNS接口允许应用程序利用服务发现，而无需与Consul进行高度整合。 有几个重要的配置项： client_addr ports.dns recursors domain dns_config 数据中心部分是可选的，如果没有提供，则默认为Agent自身的数据中心。 节点查找为了解析名称(name)，Consul依赖于特定的查询格式。基本上有两种类型的查询： node lookup service lookup 1234567#node lookup&lt;node&gt;.node[.datacenter].&lt;domain&gt;node1.node.dc1.consulnode1.node.consuldig @127.0.0.1 -p 8600 node1.node.consul 服务查找服务查找用于查询你服务提供者。 有两种查询方式： 标准查询DNS查询系统利用健康检查信息来防止路由到不健康的节点。为了实现简单的负载均衡，每次返回的节点集都是随机的。 123456[tag.]&lt;service&gt;.service[.datacenter].&lt;domain&gt;redis.service.consulpostgresql.service.dc2.consuldig @127.0.0.1 -p 8600 redis.service.consul SRV RFC 2782查询RFC 2782使用_下划线作为查询中服务和协议值的前缀，以防止DNS冲突。 123_&lt;service&gt;._&lt;protocol&gt;[.service][.datacenter][.domain]dig @127.0.0.1 -p 8600 _rabbitmq._amqp.service.consul SRV Prepared Query LookupsThe query or name is the ID or given name of an existing Prepared Query. 1&lt;query or name&gt;.query[.datacenter].&lt;domain&gt; 可连接的服务查找Connect-Capable Service Lookups. 1&lt;service&gt;.connect.&lt;domain&gt; Caching默认情况下，Consul服务的所有DNS结果都会设置一个为0的TTL。这会禁用DNS结果的缓存。但，很多情况下，缓存对性能和伸缩性都是可取的。 WAN地址转换默认情况下，Consul DNS查询将会返回一个节点的本地地址。如果你需要外部地址，则可使用advertise-wan和translate_wan_addrs选项来配置此行为。 配置Agent有许多通过命令行或配置文件配置的配置项。配置优先级如下： 命令行参数 环境变量 配置文件 配置文件可以是HCL或JSON格式。Consul可通过reload命令重新载入配置文件。 端口Consul默认使用的端口： 8300(tcp)Server RPC. Server用于处理来自其它Agent的传入请求。 8301(tcp/udp)Serf LAN. 用于处理LAN中的gossip，所有Agent都需要。 8302(tcp/udp)Serf WAN. Server用于处理WAN上gossip到其它Server。 8500(tcp)HTTP API. 8600(tcp/udp)DNS Interface. 可重新加载的配置Reloadable Configuration 重新加载配置文件不会加载所有配置项，如下这些配置项是可重新载入的： log level checks services watches http client address node metadata metric prefix filter discard check output rpc rate limiting 配置文件配置文件不仅用于设置代理，还用于提供检查和服务定义。 配置文件选项和命令行参数稍微有点不一样。使用consul agent -h查看具体配置项。 栗子： 12345678910111213141516#开始栗子vim /etc/consul.d/single.json&#123;&quot;bind_addr&quot;: &quot;192.168.1.11&quot;,&quot;bootstrap&quot;: true,&quot;client_addr&quot;: &quot;0.0.0.0&quot;,&quot;datacenter&quot;: &quot;zhang&quot;,&quot;data_dir&quot;: &quot;/var/lib/consul&quot;,&quot;log_level&quot;: &quot;WARN&quot;,&quot;node_name&quot;: &quot;zhang21&quot;,&quot;server&quot;: true,&quot;enable_syslog&quot;: true,&quot;ui&quot;: true&#125; 123456789101112131415161718192021222324#集群配置vim /etc/consul.d/cluster.json&#123; &quot;bind_addr&quot;: &quot;xxx&quot;, &quot;bootstrap_expect&quot;: 2, &quot;client_addr&quot;: &quot;0.0.0.0&quot;, &quot;datacenter&quot;: &quot;zhang&quot;, &quot;data_dir&quot;: &quot;/var/lib/consul&quot;, &quot;encrypt&quot;: &quot;a1b8vAA2==@xyz&quot;, &quot;log_level&quot;: &quot;WARN&quot;, &quot;node_name&quot;: &quot;zhang21&quot;, &quot;node_id&quot;: &quot;zhang21&quot;, &quot;server&quot;: true, &quot;enable_syslog&quot;: true, &quot;ui&quot;: true, &quot;retry_interval&quot;: 20s, &quot;retry_join&quot;: [ &quot;consul.domain.internal&quot;, &quot;10.0.1.2:8301&quot;, &quot;[::1]:8301&quot; ]&#125; 服务定义服务发现的主要目标之一是提供可用服务的目录(catalog)。为此，Agent提供了一种简单的服务定义格式来声明服务的可用性，并可能将其与健康检查相关联。如果健康检查与服务关联，则认为它是应用程序级别。 服务定义服务定义方式： 配置文件(推荐) HTTP API 一个服务定义包含的字段： name(必须) id(可选) tags(可选) address(可选) port(可选) check(可选) meta(可选) enable_tag_override(可选) token(可选) id必须唯一，如果未设置id，默认使用name。 服务可以关联健康检查，这是一个强大的功能。检查必须是脚本、HTTP、TCP或TTL类型。 脚本类型，必须提供参数和间隔 HTTP类型，必须提供http和interval TCP类型，必须提供tcp和interval TTL类型，只能提供ttl 检查名称自动生成为: service:&lt;service-id&gt;，如果有多个服务检查注册，生成的id为： service:&lt;service:-id&gt;:&lt;num&gt;，num是从1开始递增的数字。 栗子： 1234567891011121314151617181920212223242526vim /etc/consul.d/redis.json&#123; &quot;service&quot;: &#123; &quot;name&quot;: &quot;redis&quot;, &quot;id&quot;: &quot;redis01&quot;, &quot;tags&quot;: [ &quot;master&quot; ], &quot;address&quot;: &quot;127.0.0.1&quot;, &quot;port&quot;: 6379, &quot;meta&quot;: &#123; &quot;meta&quot;: &quot;service definition for redis&quot; &#125;, &quot;enable_tag_override&quot;: false, &quot;check&quot;: &#123; &quot;id&quot;: &quot;redisTCP&quot;, &quot;name&quot;: &quot;redis service check&quot;, &quot;tcp&quot;: &quot;localhost:6379&quot;, &quot;interval&quot;: &quot;10s&quot;, &quot;timeout&quot;: &quot;1s&quot; &#125; &#125;&#125; 多个服务定义1234567891011121314151617181920212223242526272829303132333435363738&#123; &quot;services&quot;: [ &#123; &quot;id&quot;: &quot;red0&quot;, &quot;name&quot;: &quot;redis&quot;, &quot;tags&quot;: [ &quot;primary&quot; ], &quot;address&quot;: &quot;&quot;, &quot;port&quot;: 6000, &quot;checks&quot;: [ &#123; &quot;args&quot;: [&quot;/bin/check_redis&quot;, &quot;-p&quot;, &quot;6000&quot;], &quot;interval&quot;: &quot;5s&quot;, &quot;ttl&quot;: &quot;20s&quot; &#125; ] &#125;, &#123; &quot;id&quot;: &quot;red1&quot;, &quot;name&quot;: &quot;redis&quot;, &quot;tags&quot;: [ &quot;delayed&quot;, &quot;secondary&quot; ], &quot;address&quot;: &quot;&quot;, &quot;port&quot;: 7000, &quot;checks&quot;: [ &#123; &quot;args&quot;: [&quot;/bin/check_redis&quot;, &quot;-p&quot;, &quot;7000&quot;], &quot;interval&quot;: &quot;30s&quot;, &quot;ttl&quot;: &quot;60s&quot; &#125; ] &#125;, ... ]&#125; 检查定义Agent的主要角色便是管理系统级和应用级的健康检查。一个检查的定义有两种方式： 配置文件 HTTP API 检查方式： Script + Interval HTTP + Interval TCP + Interval TTL Docker + Interval gRPC + Interval 定义检查A script check: 123456789&#123; &quot;check&quot;: &#123; &quot;id&quot;: &quot;mem-util&quot;, &quot;name&quot;: &quot;Memory utilization&quot;, &quot;args&quot;: [&quot;/usr/local/bin/check_mem.py&quot;, &quot;-limit&quot;, &quot;256MB&quot;], &quot;interval&quot;: &quot;10s&quot;, &quot;timeout&quot;: &quot;1s&quot; &#125;&#125; A HTTP check: 123456789101112&#123; &quot;check&quot;: &#123; &quot;id&quot;: &quot;api&quot;, &quot;name&quot;: &quot;HTTP API on port 5000&quot;, &quot;http&quot;: &quot;https://localhost:5000/health&quot;, &quot;tls_skip_verify&quot;: false, &quot;method&quot;: &quot;POST&quot;, &quot;header&quot;: &#123;&quot;x-foo&quot;:[&quot;bar&quot;, &quot;baz&quot;]&#125;, &quot;interval&quot;: &quot;10s&quot;, &quot;timeout&quot;: &quot;1s&quot; &#125;&#125; A TCP check: 123456789&#123; &quot;check&quot;: &#123; &quot;id&quot;: &quot;ssh&quot;, &quot;name&quot;: &quot;SSH TCP on port 22&quot;, &quot;tcp&quot;: &quot;localhost:22&quot;, &quot;interval&quot;: &quot;10s&quot;, &quot;timeout&quot;: &quot;1s&quot; &#125;&#125; A TTL check: 12345678&#123; &quot;check&quot;: &#123; &quot;id&quot;: &quot;web-app&quot;, &quot;name&quot;: &quot;Web App Status&quot;, &quot;notes&quot;: &quot;Web app does a curl internally every 10 seconds&quot;, &quot;ttl&quot;: &quot;30s&quot; &#125;&#125; A Docker check: 12345678910&#123;&quot;check&quot;: &#123; &quot;id&quot;: &quot;mem-util&quot;, &quot;name&quot;: &quot;Memory utilization&quot;, &quot;docker_container_id&quot;: &quot;f972c95ebf0e&quot;, &quot;shell&quot;: &quot;/bin/bash&quot;, &quot;args&quot;: [&quot;/usr/local/bin/check_mem.py&quot;], &quot;interval&quot;: &quot;10s&quot; &#125;&#125; A gRPC check: 123456789&#123;&quot;check&quot;: &#123; &quot;id&quot;: &quot;mem-util&quot;, &quot;name&quot;: &quot;Service health status&quot;, &quot;grpc&quot;: &quot;127.0.0.1:12345&quot;, &quot;grpc_use_tls&quot;: true, &quot;interval&quot;: &quot;10s&quot; &#125;&#125; 检查脚本使用enable_script_checks选项来启用脚本检查。 检查脚本的退出码(exit code)必须遵循如下约定： exit code o检查通过 exit code 1检查警告 any exit code检查失败 初始化健康检查状态在某些情况下，可能需要指定健康检查的初始状态。 12345678&#123; &quot;check&quot;: &#123; &quot;id&quot;: &quot;mem&quot;, &quot;args&quot;: [&quot;/bin/check_mem&quot;, &quot;-limit&quot;, &quot;256MB&quot;], &quot;interval&quot;: &quot;10s&quot;, &quot;status&quot;: &quot;passing&quot; &#125;&#125; 绑定服务检查健康检查可以选择性地绑定到特定服务。这可以确保健康检查的状态只会影响给定服务的健康状态，而不会影响整个节点。服务绑定检查需要添加一个service_id字段： 12345678&#123; &quot;check&quot;: &#123; &quot;id&quot;: &quot;web-app&quot;, &quot;name&quot;: &quot;Web App Status&quot;, &quot;service_id&quot;: &quot;web-app&quot;, &quot;ttl&quot;: &quot;30s&quot; &#125;&#125; 定义多个检查使用checks来定义多个服务检查。 1234567891011121314151617181920212223&#123; &quot;checks&quot;: [ &#123; &quot;id&quot;: &quot;chk1&quot;, &quot;name&quot;: &quot;mem&quot;, &quot;args&quot;: [&quot;/bin/check_mem&quot;, &quot;-limit&quot;, &quot;256MB&quot;], &quot;interval&quot;: &quot;5s&quot; &#125;, &#123; &quot;id&quot;: &quot;chk2&quot;, &quot;name&quot;: &quot;/health&quot;, &quot;http&quot;: &quot;http://localhost:5000/health&quot;, &quot;interval&quot;: &quot;15s&quot; &#125;, &#123; &quot;id&quot;: &quot;chk3&quot;, &quot;name&quot;: &quot;cpu&quot;, &quot;script&quot;: &quot;/bin/check_cpu&quot;, &quot;interval&quot;: &quot;10s&quot; &#125;, ... ]&#125; 加密Encryption Consul Agent支持加密所有流量。有两个独立的加密系统： gossip流量 RPC gossip加密启用geossip加密只需要你在启动Consul Agent时设置加密密钥(encryption key)。密钥是16Bytes的Base64编码。 123456789consul keygenFDGDpW55oCYJlh555Es1gA==vim /etc/consul.d/cluster.json&#123; &quot;encrypt&quot;: &quot;FDGDpW55oCYJlh555Es1gA==&quot;,&#125; consul集群的所有节点必须共享相同的加密密钥！ RPC加密Consul支持使用TLS来验证Server和Client之间的真实性。它们之间使用由证书机构颁发的密钥对，你可以自己生成CA。 TelemetryConsul Agent收集有关不同库和子系统的各种运行时指标。这些指标以10s为间隔进行汇总，并保留1min。查看这些数据，你需要向Consul进程发送信号： Unix: USR1 Windows: BREAK Consul收到信号后，它将当前的遥测(telemetry)信息转储到Agent’s STDERR。 12#USR1 10kill -10 $&#123;consul-pid&#125; 详情: https://www.consul.io/docs/agent/telemetry.html Watcheswatches是一种指定检测更新的数据视图的方式。检测到更新，将调用外部处理程序。watch使用HTTP API中的blocking query，Agent自动进行适当的API调用已检测更新，并在数据视图更新时通知处理程序。watch可以配置为Agent configuration的一部分，watch也可以在Agent之外启动。 处理程序监测配置指定要监测的数据视图，更新视图后，将调用指定的处理程序(Handler)。外部程序可为可执行程序(executable)或HTTP endpoint。 可执行程序可执行处理程序从stdin读取json信息，此外CONSUL_INDEX环境变量将被设置为Consul Index写入stdout。 12345678&#123; &quot;type&quot;: &quot;key&quot;, &quot;key&quot;: &quot;foo/bar/baz&quot;, &quot;handler_type&quot;: &quot;script&quot;, &quot;args&quot;: [&quot;/usr/bin/my-service-handler.sh&quot;, &quot;-redis&quot;]&#125;#在consul v1.0以后，args数组被添加，以便可在没有shell的情况下运行处理程序 HTTP endpoint当watch被调用时发送HTTP请求给HTTP处理程序。 123456789101112&#123; &quot;type&quot;: &quot;key&quot;, &quot;key&quot;: &quot;foo/bar/baz&quot;, &quot;handler_type&quot;: &quot;http&quot;, &quot;http_handler_config&quot;: &#123; &quot;path&quot;:&quot;https://localhost:8000/watch&quot;, &quot;method&quot;: &quot;POST&quot;, &quot;header&quot;: &#123;&quot;x-foo&quot;:[&quot;bar&quot;, &quot;baz&quot;]&#125;, &quot;timeout&quot;: &quot;10s&quot;, &quot;tls_skip_verify&quot;: false &#125;&#125; 全局参数Global Parameters datacenter token args handler Watch类型 key keyprefix services nodes service checks event 栗子： 123consul watch -type service -service redisconsul watch -type checks -service redis 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#key&#123; &quot;type&quot;: &quot;key&quot;, &quot;key&quot;: &quot;foo/bar/baz&quot;, &quot;args&quot;: [&quot;/usr/bin/my-service-handler.sh&quot;, &quot;-redis&quot;]&#125;#orconsul watch -type=key -key=foo/bar/baz /usr/bin/my-key-handler.sh#keyprefix&#123; &quot;type&quot;: &quot;keyprefix&quot;, &quot;prefix&quot;: &quot;foo/&quot;, &quot;args&quot;: [&quot;/usr/bin/my-service-handler.sh&quot;, &quot;-redis&quot;]&#125;#orconsul watch -type=keyprefix -prefix=foo/ /usr/bin/my-prefix-handler.sh#services&#123; &quot;redis&quot;: []&#125;#nodes[ &#123; &quot;Node&quot;: &quot;node1&quot;, &quot;Address&quot;: &quot;192.168.1.11&quot; &#125;, &#123; &quot;Node&quot;: &quot;node2&quot;, &quot;Address&quot;: &quot;xxx&quot; &#125;]#service&#123; &quot;type&quot;: &quot;service&quot;, &quot;service&quot;: &quot;redis&quot;, &quot;args&quot;: [&quot;/usr/bin/my-service-handler.sh&quot;, &quot;-redis&quot;]&#125;#check[ &#123; &quot;Node&quot;: &quot;foobar&quot;, &quot;CheckID&quot;: &quot;service:redis&quot;, &quot;Name&quot;: &quot;Service &apos;redis&apos; check&quot;, &quot;Status&quot;: &quot;passing&quot;, &quot;Notes&quot;: &quot;&quot;, &quot;Output&quot;: &quot;&quot;, &quot;ServiceID&quot;: &quot;redis&quot;, &quot;ServiceName&quot;: &quot;redis&quot; &#125;]#event&#123; &quot;type&quot;: &quot;event&quot;, &quot;name&quot;: &quot;web-deploy&quot;, &quot;args&quot;: [&quot;/usr/bin/my-service-handler.sh&quot;, &quot;-web-deploy&quot;]&#125;#orconsul watch -type=event -name=web-deploy /usr/bin/my-deploy-handler.sh -web-deploy 指南Consul Guide 本节提供了Consul各种常见的操作指南。 如下： ACLsConsul访问控制列表，该功能用于控制对资源的访问。 Adding/Removing Servers从集群中安全地添加和删除Consul Server，这应该小心操作。 Autopilot为Consul Server提供自动友好操作的管理。 Bootstrapping引导新的数据中心，包括安全地添加初始化Consul Server。 Consul with Container在容器内运行Consul Cluster。 DNS Caching为DNS查询缓存启用TTLS DNS Forwarding从BIND转发DNS查询到Consul External Services注册外部服务。允许在Consul框架内使用第三方服务。 Federation配置Consul以支持多个数据中心。 Geo Failover用准备好的查询来实现服务的地理故障转移。 Leader Election使用Consul构建Client端的领导选举。 Network Segments配置Consul使用网段-支持部分LAN连接。 Outage Recovery恢复因Server故障而无法使用的集群。 Semaphore使用KV存储实现一个信号量 Sentinel使用哨兵模式在Consul中执行策略。 Server PerformanceConsul Server的最低要求以及生产环境中运行Consul Server的指南。 ACLsConsul提供可选的访问控制列表系统，用于控制对数据和API的访问。它依赖于规则的token. 访问控制列表旨在提供易于使用，快速执行和灵活的新策略。 概述ACL Tokens访问控制列表系统基于token(令牌)，由Consul操作者通过 Consul ACL API进行管理。如果没有提供token，则会自动关联与特殊的可配置匿名令牌(anonymous token)的规则。 每个token具有： ID name type client management rule set(规则集) ACL Rules and Scopetoken绑定到一组规则，用于控制令牌可以访问的Consul资源。可在白名单(whitelist)/黑名单(blacklist)下定义策略，这取决于默认策略acl_default_policy的值。 构建规则的ACL策略： agent用于Agent API event用于Event API key用于KV Store API keyring用于Keyring API node用于Catalog API, Health API, Prepare Query API, Network Coordinate API， Agent API operator用于Operator API query用于Prepared Query API serviceCatalog API, Health API, Prepared Query API, Agent API session用于Session API 由于Consul snapshots实际上包含ACL token，因此Snapshot API需要一个管理token进行快照操作。 ACL策略不包括如下资源： Status API Catalog API ACL Datacenter必须使用acl_datacenter配置所有节点(client/server)来启用ACL强制实施，但同时也是权威数据中心。Consul依靠RPC转发来支持多数据中心(multi-datacenter)。但是，由于可以跨数据中心边界发出请求，因此ACL令牌必须在全局范围内有效。为避免一致性问题，单个数据中心被视为具有权威性，并存储规范的令牌集。 配置ACLs使用多个配置项配置ACL： 配置项 Server Client 目的 acl_datacenter required required 为ACL定义权威Consul数据中心来启用ACL的主控制 acl_default_policy 可选 n/a 定义白名单或黑名单模式 acl_down_policy 可选 可选 定义ACL数据中心脱机时执行的操作 acl_ttl 可选 可选 定义缓存ACL的生存时间 配置特殊令牌，允许引导ACL系统或在特殊情况下访问Consul： 特殊令牌 Server Client 目的 acl_agent_master_token 可选 可选 当ACL数据中心不可用或Server脱机时，可用于访问Agent API acl_agent_token 可选 可选 用于Agent内部操作 acl_master_token required n/a 用于引导ACL系统 acl_token 可选 可选 用于未提供token的客户端请求的默认令牌。这通常配置为对服务的只读访问权限，以便在Agent上启用DNS发现 ACL Agent Master Token由于acl_agent_master_token旨在Consul Server不可用时使用，因此其策略在Agent本地管理，并且不需要通过ACL API在Consul Server上定义token。 123456agent &quot;&lt;node name of agent&gt;&quot; &#123; policy = &quot;write&quot;&#125;node &quot;&quot; &#123; policy = &quot;read&quot;&#125; ACL Agent Tokenacl_agent_token是一个特殊令牌，用于Agent的内部操作。用于Agent的如下操作： 使用Catalog API更新Agent的节点条目 执行反熵同步 执行consul_exec命令时，读写KV存储库的特殊_rexec部分 123456789node &quot;node1&quot; &#123; policy = &quot;write&quot;&#125;service &quot;&quot; &#123; policy = &quot;read&quot;&#125;key &quot;_rexec&quot; &#123; policy = &quot;write&quot;&#125; 任何一个可在Agent上注册的服务，service策略需要读访问权限。 引导ACLsBootstrapping ACLs 在新集群上引导ACLs需要几个步骤： Enable ACLs on the Consul Servers引导ACLs的第一步便是在ACL数据中心的Consul Server上启用ACLs，配置如下： 1234567&#123; &quot;acl_datacenter&quot;: &quot;dc1&quot;, &quot;acl_master_token&quot;: &quot;123abc!@#, &quot;acl_default_policy&quot;: &quot;deny&quot;, &quot;acl_down_policy&quot;: &quot;deny&quot;, &quot;acl_down_policy&quot;: &quot;extend-cache&quot;&#125; Create an Agent Token使用ACL API和上一步中设置的ACL Master Token创建令牌： 1234567891011curl --request PUT --header &quot;X-Consul-Token: 123abc!@#&quot; --data \&apos;&#123; &quot;Name&quot;: &quot;Agent Token&quot;, &quot;Type&quot;: &quot;client&quot;, &quot;Rules&quot;: &quot;node \&quot;\&quot; &#123; policy = \&quot;write\&quot;&#125; service \&quot;\&quot; &#123; policy = \&quot;read\&quot; &#125;&quot;&#125;&apos; http://127.0.0.1:8500/v1/acl/create返回的值便是新创建的token&#123;&quot;ID&quot;: &quot;xxxxxxxxxxxxxx&quot;&#125; 返回的值便是新创建的token。将这个值添加到Consul Server配置中，并重启Server： 12345678&#123; &quot;acl_datacenter&quot;: &quot;dc1&quot;, &quot;acl_master_token&quot;: &quot;123abc!@#, &quot;acl_default_policy&quot;: &quot;deny&quot;, &quot;acl_down_policy&quot;: &quot;deny&quot;, &quot;acl_down_policy&quot;: &quot;extend-cache&quot;, &quot;acl_agent_token&quot;: &quot;xxxxxxxxxxxxxxxx&quot;&#125; 或使用API导入token： 1234curl --request PUT --header &quot;X-Consul-Token: 123abc!@#&quot; --data \&apos;&#123; &quot;Token&quot;: &quot;xxxxxxxxxxxxx&quot;&#125;&apos; http://127.0.0.1:8500/v1/agent/token/acl_agent_token Enable ACLs on the Consul Clients还需再Agent上配置ACL 12345678910111213141516&#123; &quot;acl_datacenter&quot;: &quot;dc1&quot;, &quot;acl_down_policy&quot;: &quot;extend-cache&quot;, &quot;acl_agent_token&quot;: &quot;前面的acl_agent_token&quot;&#125;#或使用APIcurl \ --request PUT \ --header &quot;X-Consul-Token: abc123!@#&quot; \ --data \&apos;&#123; &quot;Token&quot;: &quot;xxxxxxxxxxxx&quot;&#125;&apos; http://127.0.0.1:8500/v1/agent/token/acl_agent_token 使用由Server创建的相同ACL Agent token，因为它不是特定于任何节点或前缀集。建议每个Client获取一个ACL agent token，该令牌具有对自己的节点名称前缀的节点有写入权限，以及针对预期在该Client上注册的服务前缀的读权限。 Set an Anonymous Policy (Optional)此时，ACL已通过配置的ACL agent token进行引导，但还没有配置其它策略。甚至像consul members这样的基本操作也会受到ACL默认策略deny的限制。 如果我们提供上面的Token，则能够看到具体信息： 1CONSUL_HTTP_TOKEN=xxxxxxxx consul members 匿名令牌： 123456789curl \ --request PUT \ --header &quot;X-Consul-Token: 123abc!@#&quot; \ --data \&apos;&#123; &quot;ID&quot;: &quot;anonymous&quot;, &quot;Type&quot;: &quot;client&quot;, &quot;Rules&quot;: &quot;node \&quot;\&quot; &#123; policy = \&quot;read\&quot; &#125;&quot;&#125;&apos; http://127.0.0.1:8500/v1/acl/update 某个服务：123456789curl \ --request PUT \ --header &quot;X-Consul-Token: 123abc!@#&quot; \ --data \&apos;&#123; &quot;ID&quot;: &quot;anonymous&quot;, &quot;Type&quot;: &quot;client&quot;, &quot;Rules&quot;: &quot;node \&quot;\&quot; &#123; policy = \&quot;read\&quot; &#125; service \&quot;consul\&quot; &#123; policy = \&quot;read\&quot; &#125;&quot;&#125;&apos; http://127.0.0.1:8500/v1/acl/update Set Agent-Specific Default Tokens (Optional)匿名令牌的替代方法是acl_token配置项。 Create Tokens for UI Use (Optional)如果你使用具有限制性ACL策略的Consul UI，UI将无法使用匿名ACL令牌完整运行。建议使用特定于UI的ACL令牌，可以在Web浏览器绘画期间在UI中设置该令牌对进口进行认证。 123456789curl \ --request PUT \ --header &quot;X-Consul-Token: 123abc!@#&quot; \ --data \&apos;&#123; &quot;Name&quot;: &quot;UI Token&quot;, &quot;Type&quot;: &quot;client&quot;, &quot;Rules&quot;: &quot;key \&quot;\&quot; &#123; policy = \&quot;write\&quot; &#125; node \&quot;\&quot; &#123; policy = \&quot;read\&quot; &#125; service \&quot;\&quot; &#123; policy = \&quot;read\&quot; &#125;&quot;&#125;&apos; http://127.0.0.1:8500/v1/acl/create 规则Rule Specification ACL系统的和核心部分是规则语言，用于描述必须强制执行的策略。使用基于前缀的规则，最具体的前缀匹配决定了操作。使用HCL配置语言来指定规则，规则可定义多个策略。ACL API运行使用HCL或JSON来定义规则部分的内容。 策略有以下集中处理方式： read write(读写) deny 栗子： 12345678910111213# These control access to the key/value store.key &quot;&quot; &#123; policy = &quot;read&quot;&#125;key &quot;foo/&quot; &#123; policy = &quot;write&quot;&#125;key &quot;foo/private/&quot; &#123; policy = &quot;deny&quot;&#125;# This controls access to cluster-wide Consul operator information.operator = &quot;read&quot; Agent RulesAgent策略控制对Agent API中实用程序操作的访问。Agent规则通过节点名称，使用欧冠最长前缀匹配规则。 Agent rules栗子： 123456789agent &quot;&quot; &#123; policy = &quot;read&quot;&#125;agent &quot;foo&quot; &#123; policy = &quot;write&quot;&#125;agent &quot;bar&quot; &#123; policy = &quot;deny&quot;&#125; 如上，对具有空前缀的任何节点可读，对以foo开头的节点名进行读写，拒绝以bar开头的节点名。 Event Rules事件策略控制对事件API中事件操作的访问。事件规则由它们事件名称的前缀，使用最长匹配规则。 Event rules栗子： 123456event &quot;&quot; &#123; policy = &quot;read&quot;&#125;event &quot;deploy&quot; &#123; policy = &quot;write&quot;&#125; Key/Value Rules键值策略控制对KV API中的键值存储操作的访问。 Key规则栗子： 123456789key &quot;&quot; &#123; policy = &quot;read&quot;&#125;key &quot;foo&quot; &#123; policy = &quot;write&quot;&#125;key &quot;bar&quot; &#123; policy = &quot;deny&quot;&#125; List Policy for Keys一个新的键列表策略，只有在通过布尔配置参数acl_enable_key_list_policy选择时才会强制执行。 1234567891011key &quot;&quot; &#123; policy = &quot;deny&quot;&#125;key &quot;bar&quot; &#123; policy = &quot;list&quot;&#125;key &quot;baz&quot; &#123; policy = &quot;read&quot;&#125; Kerring Rules 1keyring = &quot;write&quot; Node Rules 123456789node &quot;&quot; &#123; policy = &quot;read&quot;&#125;node &quot;app&quot; &#123; policy = &quot;write&quot;&#125;node &quot;admin&quot; &#123; policy = &quot;deny&quot;&#125; Operator Rules 1operator = &quot;read&quot; Prepared Query Rules 123456query &quot;&quot; &#123; policy = &quot;read&quot;&#125;query &quot;foo&quot; &#123; policy = &quot;write&quot;&#125; 引导数据中心Bootstrapping a Datacenter 在Consul集群可以开始为请求提供服务之前，必须选在Server节点作为leader。Bootstrapping是将这些初始Server节点加入集群的过程。 建议的引导方式是使用-bootstrap-expect配置项。此配置项告知Consul预期的Server节点数，并在有许多Server可用时自动引导。为了防止不一致和脑裂情况(多个Server认为自己是leader)，所有Server应该指定相同的-bootstrap-expect，或根本不指定任何值。只有指定值的Server才会尝试引导集群。为了防止脑裂情况，Server不会选举自己作为leader。 推荐每个数据中心使用3或5台Server。不建议使用单个服务器部署数据中心。 加入一个集群: 12#On NodeBconsul join NodeA 创建集群要触发选举leader，必须将这些机器连接在一起并创建一个集群。 使用-join和start_join选项手动指定机器列表 使用-retry-join选项手动指定机器列表 leader选举使用Consul构建客户端的领导选举。 有多种方式建立领导选举，我们将专注于Consul sessions。会话允许我们构建一个可以优雅地处理故障的系统。 协调节点Contending Nodes 假设一组节点试图称为给定服务的领导者，参与的所有节点应该就给定的键进行协调。 1servece/&lt;service name&gt;/leader 首先创建会话： 123curl -X PUT &apos;&#123; &quot;Name&quot;: &quot;dbservice&quot; &#125;&apos; http://localhost:8500/v1/session/create这回返回一个JSON对象的session ID 下一步是使用?acquirre=&lt;session&gt;查询参数的KV条目上的PUT方法从此节点获取给定键的会话。PUT的&lt;body&gt;应该是表示本地节点的JSON对象。 1234curl -X PUT -d &lt;body&gt; http://localhost:8500/v1/kv/&lt;key&gt;?acquire=&lt;session&gt;如果返回true，则已获得锁定，并且本地节点时领导者如果返回false，则某个其它节点已获取锁定 通过对&lt;key&gt;的阻塞查询来监视更改，如果注意到&lt;key&gt;的session是空白的，那么就没有领导者，我们应该重新锁定获取。如果领导是自愿下台，这应该通过简单地释放锁来完成： 1curl -X PUT http://localhost:8500/v1/kv/&lt;key&gt;?release=&lt;session&gt; 发现一个领导者Discovering a Leader 关于领导者选举的另一种常见做法是节点希望识别给定服务的领导者。与领导者选举一样，所有参与的节点都应该同意用于协调的密钥(key)。 Client有一个非常简单的角色，它们只需阅读&lt;key&gt;来发现当前的领导者是谁: 1curl http://localhost:8500/v1/kv/&lt;key&gt; 如果密钥没有关联的话，就没有领导者。你可查询/v1/session/info获取session详细信息： 1curl http://localhost:8500/v1/session/info/xxxxxxxxxxx Client还应使用阻塞查询来查看密钥的更改，如果领导者退出或失败将清除与密钥相关联的会话。当选出新的领导者时，密钥值也将更新。 API文档链接: https://www.consul.io/api/index.html Consul的主要接口是RESTful HTTP API。API可对node，service，check，configuration…执行基本的CRUD操作。 版本前缀Version Prefix 所有API路由都以/v1/为前缀，这适用于v1 API。 consul-templateConsul Template 查询consul instance，并更新文件系统上任意数量的指定模板。作为额外的奖励，Consul Template可以在模板更新完成时执行任意命令。 Consul Tempalte可以查询Consul中的服务条目，keys, key values。强大的抽象和模板查询语言是Consul Template非常适合创建动态配置。 如： Apache Nginx HAproxy 安装 下载地址: https://releases.hashicorp.com/consul-template/ 步骤： 下载 解压 添加PATH 1234567891011121314wget https://releases.hashicorp.com/consul-template/0.19.5/consul-template_0.19.5_linux_amd64.tgztar -xzvf ./consul-template_0.19.5_linux_amd64.tgzmv ./consul-template /bin/#ormv consul-template /usr/local/binvim /etc/profileexport PATH=$PATH:/usr/local/binconsul-template --versionconsul-template v0.19.5 (57b6c71) 用法官方栗子： https://github.com/hashicorp/consul-template/tree/master/examples 1consul-template -h 命令行查询demo.consul.io这个consul实例。 渲染模板： 1234consul-template \ -template &quot;/tmp/nginx.ctmpl:/var/nginx/nginx.conf:nginx -s reload&quot; \ -template &quot;/tmp/redis.ctmpl:/var/redis/redis.conf:service redis restart&quot; \ -template &quot;/tmp/haproxy.ctmpl:/var/haproxy/haproxy.conf&quot; 监听Consul： 1consul-template -consul-addr=&quot;consul1:8500&quot; -consul-addr=&quot;consul2:8500&quot; 配置文件配置文件使用 HashiCorp Configuration Language编写的。这意味着，配置也是JSON兼容的。 命令行指定的选项优先于配置文件！ 12345mkdir /etc/consul-templatevim consul-template.hclconsul-template -config=&apos;/etc/consul-template/consul-template.hcl&apos; 配置文件详情： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353# This denotes the start of the configuration section for Consul. All values# contained in this section pertain to Consul.consul &#123; # This block specifies the basic authentication information to pass with the # request. For more information on authentication, please see the Consul # documentation. auth &#123; enabled = true username = &quot;test&quot; password = &quot;test&quot; &#125; # This is the address of the Consul agent. By default, this is # 127.0.0.1:8500, which is the default bind and port for a local Consul # agent. It is not recommended that you communicate directly with a Consul # server, and instead communicate with the local Consul agent. There are many # reasons for this, most importantly the Consul agent is able to multiplex # connections to the Consul server and reduce the number of open HTTP # connections. Additionally, it provides a &quot;well-known&quot; IP address for which # clients can connect. address = &quot;127.0.0.1:8500&quot; # This is the ACL token to use when connecting to Consul. If you did not # enable ACLs on your Consul cluster, you do not need to set this option. # # This option is also available via the environment variable CONSUL_TOKEN. token = &quot;abcd1234&quot; # This controls the retry behavior when an error is returned from Consul. # Consul Template is highly fault tolerant, meaning it does not exit in the # face of failure. Instead, it uses exponential back-off and retry functions # to wait for the cluster to become available, as is customary in distributed # systems. retry &#123; # This enabled retries. Retries are enabled by default, so this is # redundant. enabled = true # This specifies the number of attempts to make before giving up. Each # attempt adds the exponential backoff sleep time. Setting this to # zero will implement an unlimited number of retries. attempts = 12 # This is the base amount of time to sleep between retry attempts. Each # retry sleeps for an exponent of 2 longer than this base. For 5 retries, # the sleep times would be: 250ms, 500ms, 1s, 2s, then 4s. backoff = &quot;250ms&quot; # This is the maximum amount of time to sleep between retry attempts. # When max_backoff is set to zero, there is no upper limit to the # exponential sleep between retry attempts. # If max_backoff is set to 10s and backoff is set to 1s, sleep times # would be: 1s, 2s, 4s, 8s, 10s, 10s, ... max_backoff = &quot;1m&quot; &#125; # This block configures the SSL options for connecting to the Consul server. ssl &#123; # This enables SSL. Specifying any option for SSL will also enable it. enabled = true # This enables SSL peer verification. The default value is &quot;true&quot;, which # will check the global CA chain to make sure the given certificates are # valid. If you are using a self-signed certificate that you have not added # to the CA chain, you may want to disable SSL verification. However, please # understand this is a potential security vulnerability. verify = false # This is the path to the certificate to use to authenticate. If just a # certificate is provided, it is assumed to contain both the certificate and # the key to convert to an X509 certificate. If both the certificate and # key are specified, Consul Template will automatically combine them into an # X509 certificate for you. cert = &quot;/path/to/client/cert&quot; key = &quot;/path/to/client/key&quot; # This is the path to the certificate authority to use as a CA. This is # useful for self-signed certificates or for organizations using their own # internal certificate authority. ca_cert = &quot;/path/to/ca&quot; # This is the path to a directory of PEM-encoded CA cert files. If both # `ca_cert` and `ca_path` is specified, `ca_cert` is preferred. ca_path = &quot;path/to/certs/&quot; # This sets the SNI server name to use for validation. server_name = &quot;my-server.com&quot; &#125;&#125;# This is the signal to listen for to trigger a reload event. The default# value is shown below. Setting this value to the empty string will cause CT# to not listen for any reload signals.reload_signal = &quot;SIGHUP&quot;# This is the signal to listen for to trigger a graceful stop. The default# value is shown below. Setting this value to the empty string will cause CT# to not listen for any graceful stop signals.kill_signal = &quot;SIGINT&quot;# This is the maximum interval to allow &quot;stale&quot; data. By default, only the# Consul leader will respond to queries; any requests to a follower will# forward to the leader. In large clusters with many requests, this is not as# scalable, so this option allows any follower to respond to a query, so long# as the last-replicated data is within these bounds. Higher values result in# less cluster load, but are more likely to have outdated data.max_stale = &quot;10m&quot;# This is the log level. If you find a bug in Consul Template, please enable# debug logs so we can help identify the issue. This is also available as a# command line flag.log_level = &quot;warn&quot;# This is the path to store a PID file which will contain the process ID of the# Consul Template process. This is useful if you plan to send custom signals# to the process.pid_file = &quot;/path/to/pid&quot;# This is the quiescence timers; it defines the minimum and maximum amount of# time to wait for the cluster to reach a consistent state before rendering a# template. This is useful to enable in systems that have a lot of flapping,# because it will reduce the the number of times a template is rendered.wait &#123; min = &quot;5s&quot; max = &quot;10s&quot;&#125;# This denotes the start of the configuration section for Vault. All values# contained in this section pertain to Vault.vault &#123; # This is the address of the Vault leader. The protocol (http(s)) portion # of the address is required. address = &quot;https://vault.service.consul:8200&quot; # This is the grace period between lease renewal of periodic secrets and secret # re-acquisition. When renewing a secret, if the remaining lease is less than or # equal to the configured grace, Consul Template will request a new credential. # This prevents Vault from revoking the credential at expiration and Consul # Template having a stale credential. # # Note: If you set this to a value that is higher than your default TTL or # max TTL, Consul Template will always read a new secret! # # This should also be less than or around 1/3 of your TTL for a predictable # behaviour. See https://github.com/hashicorp/vault/issues/3414 grace = &quot;5m&quot; # This is the token to use when communicating with the Vault server. # Like other tools that integrate with Vault, Consul Template makes the # assumption that you provide it with a Vault token; it does not have the # incorporated logic to generate tokens via Vault&apos;s auth methods. # # This value can also be specified via the environment variable VAULT_TOKEN. token = &quot;abcd1234&quot; # This tells Consul Template that the provided token is actually a wrapped # token that should be unwrapped using Vault&apos;s cubbyhole response wrapping # before being used. Please see Vault&apos;s cubbyhole response wrapping # documentation for more information. unwrap_token = true # This option tells Consul Template to automatically renew the Vault token # given. If you are unfamiliar with Vault&apos;s architecture, Vault requires # tokens be renewed at some regular interval or they will be revoked. Consul # Template will automatically renew the token at half the lease duration of # the token. The default value is true, but this option can be disabled if # you want to renew the Vault token using an out-of-band process. # # Note that secrets specified in a template (using &#123;&#123;secret&#125;&#125; for example) # are always renewed, even if this option is set to false. This option only # applies to the top-level Vault token itself. renew_token = true # This section details the retry options for connecting to Vault. Please see # the retry options in the Consul section for more information (they are the # same). retry &#123; # ... &#125; # This section details the SSL options for connecting to the Vault server. # Please see the SSL options in the Consul section for more information (they # are the same). ssl &#123; # ... &#125;&#125;# This block defines the configuration for connecting to a syslog server for# logging.syslog &#123; # This enables syslog logging. Specifying any other option also enables # syslog logging. enabled = true # This is the name of the syslog facility to log to. facility = &quot;LOCAL5&quot;&#125;# This block defines the configuration for de-duplication mode. Please see the# de-duplication mode documentation later in the README for more information# on how de-duplication mode operates.deduplicate &#123; # This enables de-duplication mode. Specifying any other options also enables # de-duplication mode. enabled = true # This is the prefix to the path in Consul&apos;s KV store where de-duplication # templates will be pre-rendered and stored. prefix = &quot;consul-template/dedup/&quot;&#125;# This block defines the configuration for exec mode. Please see the exec mode# documentation at the bottom of this README for more information on how exec# mode operates and the caveats of this mode.exec &#123; # This is the command to exec as a child process. There can be only one # command per Consul Template process. command = &quot;/usr/bin/app&quot; # This is a random splay to wait before killing the command. The default # value is 0 (no wait), but large clusters should consider setting a splay # value to prevent all child processes from reloading at the same time when # data changes occur. When this value is set to non-zero, Consul Template # will wait a random period of time up to the splay value before reloading # or killing the child process. This can be used to prevent the thundering # herd problem on applications that do not gracefully reload. splay = &quot;5s&quot; env &#123; # This specifies if the child process should not inherit the parent # process&apos;s environment. By default, the child will have full access to the # environment variables of the parent. Setting this to true will send only # the values specified in `custom_env` to the child process. pristine = false # This specifies additional custom environment variables in the form shown # below to inject into the child&apos;s runtime environment. If a custom # environment variable shares its name with a system environment variable, # the custom environment variable takes precedence. Even if pristine, # whitelist, or blacklist is specified, all values in this option # are given to the child process. custom = [&quot;PATH=$PATH:/etc/myapp/bin&quot;] # This specifies a list of environment variables to exclusively include in # the list of environment variables exposed to the child process. If # specified, only those environment variables matching the given patterns # are exposed to the child process. These strings are matched using Go&apos;s # glob function, so wildcards are permitted. whitelist = [&quot;CONSUL_*&quot;] # This specifies a list of environment variables to exclusively prohibit in # the list of environment variables exposed to the child process. If # specified, any environment variables matching the given patterns will not # be exposed to the child process, even if they are whitelisted. The values # in this option take precedence over the values in the whitelist. # These strings are matched using Go&apos;s glob function, so wildcards are # permitted. blacklist = [&quot;VAULT_*&quot;] &#125; # This defines the signal that will be sent to the child process when a # change occurs in a watched template. The signal will only be sent after the # process is started, and the process will only be started after all # dependent templates have been rendered at least once. The default value is # nil, which tells Consul Template to stop the child process and spawn a new # one instead of sending it a signal. This is useful for legacy applications # or applications that cannot properly reload their configuration without a # full reload. reload_signal = &quot;&quot; # This defines the signal sent to the child process when Consul Template is # gracefully shutting down. The application should begin a graceful cleanup. # If the application does not terminate before the `kill_timeout`, it will # be terminated (effectively &quot;kill -9&quot;). The default value is &quot;SIGTERM&quot;. kill_signal = &quot;SIGINT&quot; # This defines the amount of time to wait for the child process to gracefully # terminate when Consul Template exits. After this specified time, the child # process will be force-killed (effectively &quot;kill -9&quot;). The default value is # &quot;30s&quot;. kill_timeout = &quot;2s&quot;&#125;# This block defines the configuration for a template. Unlike other blocks,# this block may be specified multiple times to configure multiple templates.# It is also possible to configure templates via the CLI directly.template &#123; # This is the source file on disk to use as the input template. This is often # called the &quot;Consul Template template&quot;. This option is required if not using # the `contents` option. source = &quot;/path/on/disk/to/template.ctmpl&quot; # This is the destination path on disk where the source template will render. # If the parent directories do not exist, Consul Template will attempt to # create them, unless create_dest_dirs is false. destination = &quot;/path/on/disk/where/template/will/render.txt&quot; # This options tells Consul Template to create the parent directories of the # destination path if they do not exist. The default value is true. create_dest_dirs = true # This option allows embedding the contents of a template in the configuration # file rather then supplying the `source` path to the template file. This is # useful for short templates. This option is mutually exclusive with the # `source` option. contents = &quot;&#123;&#123; keyOrDefault \&quot;service/redis/maxconns@east-aws\&quot; \&quot;5\&quot; &#125;&#125;&quot; # This is the optional command to run when the template is rendered. The # command will only run if the resulting template changes. The command must # return within 30s (configurable), and it must have a successful exit code. # Consul Template is not a replacement for a process monitor or init system. command = &quot;restart service foo&quot; # This is the maximum amount of time to wait for the optional command to # return. Default is 30s. command_timeout = &quot;60s&quot; # Exit with an error when accessing a struct or map field/key that does not # exist. The default behavior will print &quot;&lt;no value&gt;&quot; when accessing a field # that does not exist. It is highly recommended you set this to &quot;true&quot; when # retrieving secrets from Vault. error_on_missing_key = false # This is the permission to render the file. If this option is left # unspecified, Consul Template will attempt to match the permissions of the # file that already exists at the destination path. If no file exists at that # path, the permissions are 0644. perms = 0600 # This option backs up the previously rendered template at the destination # path before writing a new one. It keeps exactly one backup. This option is # useful for preventing accidental changes to the data without having a # rollback strategy. backup = true # These are the delimiters to use in the template. The default is &quot;&#123;&#123;&quot; and # &quot;&#125;&#125;&quot;, but for some templates, it may be easier to use a different delimiter # that does not conflict with the output file itself. left_delimiter = &quot;&#123;&#123;&quot; right_delimiter = &quot;&#125;&#125;&quot; # This is the `minimum(:maximum)` to wait before rendering a new template to # disk and triggering a command, separated by a colon (`:`). If the optional # maximum value is omitted, it is assumed to be 4x the required minimum value. # This is a numeric time with a unit suffix (&quot;5s&quot;). There is no default value. # The wait value for a template takes precedence over any globally-configured # wait. wait &#123; min = &quot;2s&quot; max = &quot;10s&quot; &#125;&#125; 栗子： 123456789101112131415161718192021222324252627282930313233343536373839404142vim /etc/consul-template/consul.hclmax_stale = &apos;10m&apos;wait = &#123; min = &apos;1s&apos; max = &apos;3s&apos;&#125;template &#123; source = &apos;/etc/consul-template/ctmpl/a.ctmpl&apos; destination = &apos;/etc/nginx/conf.d/upstream-a.conf&apos; command = &apos;systemctl reload nginx&apos; perms = 0644&#125;#vim /etc/consul-template/ctmpl/a.ctmplupstream upstream-a &#123; &#123;&#123;range service &apos;a&apos;&#125;&#125; server &#123;&#123;.Address&#125;&#125;:&#123;&#123;.Port&#125;&#125;; &#123;&#123;else&#125;&#125; server 127.0.0.1:12345; &#123;&#123;end&#125;&#125;&#125;#nginxvim /etc/nginx/conf.d/upstream-a.confupstream upstream-a &#123; server 192.168.1.11:12345;&#125; 模板语法Consul Template解析文件以 Go Template创作。Consul Template提供了如下函数： API函数API函数与远程API进行交互，与Consul等外部服务进行通信。 datacenters查询Consul目录中的所有数据中心。 12345678910&#123;&#123; datacenters &#125;&#125;#栗子&#123;&#123; range datacenters &#125;&#125;&#123;&#123; . &#125;&#125;&#123;&#123; end &#125;&#125;#效果dc1dc2]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Consul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker]]></title>
    <url>%2F2018%2F03%2F27%2FDocker%2F</url>
    <content type="text"><![CDATA[参考： Docker文档: https://docs.docker.com/ https://blog.csdn.net/sD7O95O/article/details/78623697 https://www.zhihu.com/question/22969309/answer/34030581 环境： CentOS7x86_64 Docker v18.03 概述Docker是一个开发、shipping、运行应用程序的开放平台。Docker使你能够将应用程序与基础架构(infrastructure)分离开，从而可以快速交付软件。借助Docker，你可以像管理应用程序一样管理基础架构。利用Docker的方法快速进行运输、测试和部署代码，可以显著缩短编写代码和在生存环境中运行代码之间的延迟。 Docker平台Docker提供了在称为容器的松散隔离(isolated)环境中 打包和运行应用程序的能力。隔离性和安全性允许你在给定的主机上同时运行多个容器。容器是轻量级(lightweight)的，因为它们不需要hypervisor的额外负载，而是直接使用主机的内核运行。这意味着，与使用虚拟机相比，你可以在给定的硬件组合上运行更多的容器。你甚至可以在虚拟主机中运行Docker容器。 Docker提供了工具和平台来管理容器的生命周期(lifecycle)： 使用容器开发应用程序及其支持组件 容器成为分发和测试你应用程序的单元 准备好后，将你的应用程序部署到生产环境中，作为容器协调服 Docker引擎Docker引擎是一个包含如下部件的client-server应用程序： Server是称为守护进程的dockerd REST API是指定程序可用于与守护进程进行通信并指示其执行操作的接口 Client是command line interface(CLI) Docker的开源许可协议是Apache2.0 能用Docker做什么快速、一致的交付应用程序 通过允许开发人员在 提供应用程序和服务的本地容器 的标准化环境 下工作，Docker简化了开发生命周期。容器非常适合持续集成(continuous intergration,CI)和持续交付(continuous deliver,CD)工作流程。 考虑如下示例场景： 开发者在本地编写代码，并使用Docker容器分享工作给他们的同事 使用Docker将应用程序push到测试环境，并自动执行和手动测试 当开发人员发现bug，他们能在开发环境中修复bug，并重新部署应用程序到测试环境进行测试和验证 测试完成后，向客户提供修补的应用程序 与将更新的image push到生产环境一样简单 响应式部署和伸缩 Docker的基于容器的平台支持高度可移植的工作负载。Docker container可以运行在笔记本、物理机、虚拟机、云平台… Docker的可移植性和轻量化特性也使得动态管理工作负载非常容易，可以近乎实时地按业务需求扩展或拆分应用程序和服务 在同一硬件上运行更多的工作负载 Docker轻量且快速。它为基于hypersior的虚拟机提供了一种可行、经济高效的替代方案，因此你可以使用更多计算容量来实现业务目标。Docker是高密度环境和中小型部署的理想选择，你需要用更小的资源做更多的事情。 Docker架构Docker使用了client-server的体系架构。客户端向守护进程发送消息，守护进程负责构建、运行和分发 Docker容器。客户端和守护进程可以在同一系统上运行，也可将客户端连接到远程的Docker守护进程。客户端和守护进程使用REST API，通过Unix socket或network interface进程通信。 Docker daemonDocker daemon(dockerd)，监听Docker API请求并管理Docker对象——image、container、network、volume。docker daemon还可与其它docker daemon通信来管理docker service。 Docker clientDocker client(docker)是许多Docker用户与Docker进行交互的主要方式。客户端将命令发送给守护进程，守护进程执行命令。Docker命令使用Docker API，Docker客户端可与多个守护进程进行通信。 Docker registryDocker registry存储Docker image。Docker Hub和Docker Cloud是任何人都可使用的public registry，你可以创建private registry。 docker pull或docker run需要的image便是从配置的registry中提取。docker push推送image到你配置的registry。 Docker对象当你使用Docker时，你会创建和使用 image、container、network、volume、plugin和其它对象。 image镜像是一个只读模板，带有创建Docker容器的说明。通常，镜像基于其它镜像，并具有一些额外的自定义功能。例如，你可构建基于Ubuntu镜像的镜像，但会按照ApacheWeb服务器和应用程序，以及应用程序所需的配置。 你可能创建自己的镜像，或使用由别人创建并推送到registry上的镜像。构建自己的镜像，需要使用简单的语法创建一个Dockerfile，以定义创建镜像并运行它所需的步骤。 container容器是镜像的可运行实例。可将容器连接到一个或多个网络，将存储器连接到它，还可根据当前状态创建新镜像。 默认情况下，容器与其它容器以及主机是相对隔离的。你可以控制容器的网络、存储、其它底层子系统与其它容器或主机的隔离程度。 容器由镜像定义，以及你在创建或启动时提供给它的任何配置选项。当一个容器被移除时，其未被存储在永久存储器中的状态会消失。 栗子： 123#运行一个Ubuntu镜像，交互地连接到本地命令会话docker run -i -t ubuntu /bin/bash 以上命令会发生如下步骤: 如果本地没有Ubuntu镜像，docker会从registry拉取，就好像你手动运行 docker pull ubuntu Docker创建一个新容器，就好像你手动执行docker container create Docker分配一个读写文件系统给容器，作为它的最后一层 如果你没有指定任何网络选项，Docker会创建一个网络接口将容器连接到默认网络。 Docker开启容器并执行/bin/bash 发送exit到/bin/bash，容器停止但并未被移除 service服务允许你伸缩多个Docker守护进程的容器，这些守护进程可以作为一个swarm与多个manager和worker一起工作。默认情况下，该服务在所有node之间进行负载均衡。 底层技术Docker使用GO编写，利用Linux内核的几个特性来提供其功能。 namespace Docker使用一个称为namespace的技术来提供称为容器的独立工作空间。当你运行一个容器时，Docker会为该容器创建一组命名空间。命名空间提供了一个隔离层。容器的每个方面都在单独namespace中运行，并且其访问权限仅限于该单独的namespace。 Docker引擎在Linux上使用如下namespace： pid namespace： 进程隔离 net namespace： 管理网络接口 ipc namespace： 管理对IPC(InterProcess Communication)资源的访问 mnt namespace： 管理文件系统挂载点 ust namespace： 隔离内核和版本标识符(Unix Timesharing System) control groups Linux上的Docker Engine也依赖与另一种称为控制组(cgroups)的技术。cgroup将应用程序限制为一组特定的资源。控制组允许Docker引擎将可用的硬件资源共享给容器，并可选地强制实施限制和约束。例如，你可限制特定容器的内存是CPU使用率等。 union file systems union file systems(UnionFS)，是通过创建layer进行操作的文件系统，使得它们非常轻量和快速。Docker引擎使用UnioFS为容器提供构建block。Docker引擎可以使用多种UnionFS变体，包括AUFS, brrfs, vfs, DeviceMapper… container format Docker引擎将namespace、cgroup、UnionFS组合成一个名为容器格式的包装器。默认的容器格式为libcontainer。 安装Docker有两个可获取的版本： Community Edition(CE) 适合开始使用Docker并尝试基于容器的应用程序的开发人员和小型团队 Enterprise Edition(EE) 专为企业开发和IT团队而设计，可以在生产规模上构建，发布和运行关键业务应用程序 CentOS7安装Docker CEOS要求 CentOS7.x centos-extras repository 推荐使用overlay2存储驱动 安装新版本Docker需卸载老版本Docker Docker CE包被称为docker-ce 安装Docker CE https://download.docker.com/ 多种安装方法： Docker’s repository RPM package scripts 使用repository安装： 12345678910111213141516171819202122232425262728 #安装依赖yum install -y yum-utils device-mapper-persistent-data lvm2 #设置repositoryyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo #安装Docker CEyum install -y docker-ce #Docker安装但未启动，docker group会被创建，但没有用户添加到组中 #在生产环境中，你可能需要安装特定版本的Docker CE，而不是最新版yum list docker-ce --showduplicates | sort -ryum search docker-ce --showduplicates #开启dockersystemctl start docker #测试dockerdocker run hello-world #此命令下载一个测试image并将其运行到container中 #Hello from Docker! 使用package安装： 1234567891011 #下载rpm包https://download.docker.com/linux/centos/7/x86_64/stable/Packages/ #安装yum install -y /path/docker-cexxx.rpmsystemctl start dockerdocker run hello-world 使用scripts安装： 123456curl -fsSL get.docker.com -o get-docker.shsh get-docker.sh #手动添加group合userusermod -aG docker your-user 卸载Docker CE123456yum remove docker-ce #默认文件rm -rf /var/lib/docker #你还需要手动删除其它配置文件 开始 关于DockerDocker文档会有如下讲解： 设置你的Docker环境 在一个容器(container)中构建并运行一个镜像 延伸你的APP以便在多个容器中运行 在整个集群中分配你的APP 通过添加后端数据库来堆栈服务 将应用部署到生产 Docker的概念Docker是开发人员，系统管理员使用容器来开发、部署和运行APP的平台。使用Linux容器来部署APP被称为集装箱化(containerzation) 集装箱受欢迎的几点原因： 灵活(flexible) 轻量(lightweight) 通用(Interchangeable) 可移植(portable) 延伸(scalable) 堆栈(stackable) 镜像和容器通过运行镜像(image)启动容器(container)。镜像是一个可执行包，包含运行APP所需的所有内容：代码，库，环境变量，配置文件… 容器是镜像的运行时(runtime)实例。在Linux上使用docker ps命令查看运行的容器列表。 容器和虚拟机容器在Linux本地上运行，并与其它容器共享主机Kernel。它是一个独立的进程，不占其它可执行文件内存，使其轻量化。 虚拟机(VM)运行一个完整的访客操作系统，通过虚拟机管理程序访问主机资源。一般来说，虚拟机比大多数应用程序需要的资源更多。 准备Docker环境Docker版本： CE: Docker Community Edition EE: Docker Enterprise Edition Install Docker 测试Docker12345678910111213141516171819202122docker --version#查看详细信息docker info#测试安装工作是否正常docker run hello-world#查看镜像docker image ls#列出容器docker container ls -all#docker命令dockerdocker container --help 小结集装箱化使得CI/CD无缝： 持续集成(Continuous integration, CI) 持续部署(continuous deployment, CD) APP无系统依赖 更新能够推送到分布式APP的任何部分 资源密度可以被优化 使用Docker，扩展APP的过程就是启动新的可执行文件，而不是运行繁重的VM主机。 容器Container 先决条件1docker run hello-world 介绍是时候使用Docker方式来构建一个APP了。 从应用程序的层次结构底部开始，这是一个容器(container) 在此级别之上，是一个服务(service)，它定义了容器在生产中的表现 最后，顶层是堆栈(stack)，定义所有服务的交互(interaction) Like this: Stack Service Container 新开发环境在过去，如果你要开始编写一个Python APP，你的第一要务是在你的机器运行时安装Python。但是，这会造成你的计算机上的环境，需要如预期般完美适合你的APP，并且还需要与你的生产环境相匹配。 使用Docker，你可以将一个可移植的Python运行时作为一个image，无需安装。接着，你的构建可以将基础Python image与APP代码一起包含在内，确保你的APP，依赖项…都构建一起。 使用Dockerfile定义一个容器Dockerfile定义了容器内环境中发生的事情。访问的网络接口(network interface)和磁盘驱动(disk driver)等资源是在此环境中虚拟化的(virtualized)，与系统其余部分隔离。因此你需要将端口映射(map port)到外部世界，并明确指定要将哪些文件复制到此环境中。但是，在完成这些后，你完全可以将它们看做一致 —— 在Dockerfile中定义的构建的APP的行为与它运行时的行为完全相同。 Dockerfile 创建一个空目录，并创建一个名叫Dockerfile的文件，复制以下内容： 1234567891011121314151617181920# Use an official Python runtime as a parent imageFROM python:2.7-slim# Set the working directory to /appWORKDIR /app# Copy the current directory contents into the container at /appADD . /app# Install any needed packages specified in requirements.txtRUN pip install --trusted-host pypi.python.org -r requirements.txt# Make port 80 available to the world outside this containerEXPOSE 80# Define environment variableENV NAME World# Run app.py when the container launchesCMD [&quot;python&quot;, &quot;app.py&quot;] 注意代理服务器会阻断你与APP的连接！ 这个Dockerfile引用了一些我们还没有创建的文件，分别是app.py和requirements.txt。接下来创建它们。 APP自身创建另外的文件，如上面的app.py和requirements.txt，并将它们与Dockerfile放置于同一目录下。这就完成了我们的APP，这看起来非常简单。当这个Dockerfile被构建成一个image时，由于Dockerfile的ADD命令，app.py和requirements.txt仍然存在，而且由于使用了EXPOSE命令，app.py的输出仍可以通过HTTP访问。 requirements.txt: 12FlaskRedis app.py: 123456789101112131415161718192021222324from flask import Flaskfrom redis import Redis, RedisErrorimport osimport socket# Connect to Redisredis = Redis(host=&quot;redis&quot;, db=0, socket_connect_timeout=2, socket_timeout=2)app = Flask(__name__)@app.route(&quot;/&quot;)def hello(): try: visits = redis.incr(&quot;counter&quot;) except RedisError: visits = &quot;&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;&quot; html = &quot;&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;&quot; \ &quot;&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;&quot; \ &quot;&lt;b&gt;Visits:&lt;/b&gt; &#123;visits&#125;&quot; return html.format(name=os.getenv(&quot;NAME&quot;, &quot;world&quot;), hostname=socket.gethostname(), visits=visits)if __name__ == &quot;__main__&quot;: app.run(host=&apos;0.0.0.0&apos;, port=80) 在容器内访问主机的名称将检索容器ID，这进程ID类似。 仅此而已，在你的系统中，你不需要任何Python或requirements.txt文件，也不需要在你的系统上安装 构建或运行的image。看起来你并没有真正用Python和Flask建立一个环境，但是你确实已经拥有了。 构建APP我们准备去构建(build)APP。确保你仍在目录的顶层。 123456789101112131415161718192021222324252627282930313233343536373839404142#查看是否还在顶层lsDockerfile app.py requirements.txt#在此目录运行build命令，这将创建一个Docker image，用 -t 命名docker build -t friendlyhello .#查看你build的imagedocker image lsREPOSITORY TAG IMAGE ID CREATED SIZEfriendlyhello latest b24e21d7645f 13 minutes ago 150MB#运行APPdocker run -p 4000:80 friendlyhello#测试curl http://localhost:4000links http://localhost:4000#在后台运行docker run -d -p 4000:80 friendlyhello#查看容器docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES146662dca737 friendlyhello &quot;python app.py&quot; 16 seconds ago Up 16 seconds 0.0.0.0:4000-&gt;80/tcp goofy_chaplygin#停止Ctrl + Cdocker container stop docker-IDdocker container stop 146662dca737 端口重映射4000:80是为了证明Dockerfile中的EXPOSE与使用docker run -p发布的内容之间的区别。在后续步骤中，我们只需将主机的80端口映射到容器的80端口就好。 分享你的image为了演示刚才创建的image的可移植性(portability)，让我们上传build的image并在其它地方run它。毕竟，当你需要将container部署到生产环境时，你需要知道如何push注册。 注册表(registry)是一个repository的集合，而repository是image的集合——有点类似于GitHub repository，但代码是已经构建了的。注册表上的账户可以创建许多repository。docker CLI 默认使用Docker’s public registry。你也可以选择其它注册表，或创建自己的注册表。 使用Docker ID登录： 如果没有Docker账户，请先注册 。 1234567891011121314151617docker logindocker login -u zhang21#时候docker login认证过后，会有~/.docker/config.json文件，里面包含了docker认证信息#k8s可使用此信息添加secretcat ~/.docker/config.json&#123; &quot;auths&quot;: &#123; &quot;https://index.docker.io/v1/&quot;: &#123; &quot;auth&quot;: &quot;base64encoding&quot; &#125; &#125;, &quot;HttpHeaders&quot;: &#123; &quot;User-Agent&quot;: &quot;Docker-Client/18.03.1-ce (linux)&quot; &#125; 标记image： 使用username/repository:tag将本地image与registry中的repository相关联。tag是可选的，但推荐使用tag。因为它是注册管理机构用于为Docker image提供版本的机制。为该内容提供一个有意义的repository和tag，例如get-started:part2。 12345678docker tag image username/repository:tag#例子docker tag friendlyhello zhang/test:tag-test#查看tagdocker images ls 发布image： 123456#上传你标记了的image到repositorydocker push username/repository:tagdocker push zhang21/test:tag-test#完成后，此image便可以公开获取 从远处repository拉取并运行image： 无论在哪里执行docker run，它都会将你的image以及Python和所有依赖关系一起拉取下来，并运行你的代码。 123docker run -p 4000:80 username/repository:tagdocker run -p 80:80 zhang21/test:tag-test 本节基础命令123456789101112131415161718192021222324252627282930313233343536373839404142434445#从Dockerfile创建imagedocker build -t image-name .#运行imagedocker run -p 4000:80 image-name#后台运行docker run -d -p 4000:80 image-name#列出运行的容器docker container ls#列出所有容器，包括未运行docker container ls -a#优雅停止容器docker container stop 容器ID#强制停止docker container kill 容器ID#删除容器docker container rm 容器ID#删除所有容器docker container rm $(docker container ls -a -q)#列出镜像docker image ls#列出所有镜像docker image ls -a#删除镜像docker image rm 镜像ID#删除所有镜像docker image rm $(docker image ls -a -q)#登录docker login#标记docker tag 镜像 username/repository:tag#上传到注册表docker push username/repository:tag#从注册表拉取docker run username/repository:tag 服务service 先决条件 安装Docker 获取Docker Compose 阅读Orientation 阅读Container 确保已发布friendlyhello image到你的registry 确保你的image工作为一个部署的container。docker run -p 80:80 username/repo:tag 介绍在此，我们扩展(scale)APP并启用负载均衡(load balancing)。要做到这样，我们必须在分布式(distributed)应用程序的层次结构中升一级: 服务 Stack Service Container 关于服务在分布式应用程序中，应用程序的不同部分称为服务(service)。 例如，一个视频共享站点。那么它可能包含： 用于将应用程序数据 存储到数据库中的服务 用户上传后的视频转码服务 前端服务 … 服务是真正的生产环境中的容器。一个service只运行一个image，但它可修改image的运行方式 —— 哪个端口、容器应该运行多少个副本以便于服务所需的容量等.伸缩服务会更改运行该软件的容器实例数量，从而为进程中的服务分配更多的计算资源。 在Docker平台上定义、运行和伸缩服务都是很简单的 —— 只需修改docker-compose.yml文件。 你的第一个docker-compose.yml文件docker-compose.yml是一个YAML文件，它定义了Docker container在生产中的行为方式。 docker-compose.yml： 将如下信息保存为docker-compose.yml，确保你已经pushed the image到registry，并通过修改.yml文件的image detail来替换username/repo:tag。 12345678910111213141516171819version: "3"services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 resources: limits: cpus: "0.1" memory: 50M restart_policy: condition: on-failure ports: - "80:80" networks: - webnetnetworks: webnet: docker-compose.yml文件告诉Docker之下如下操作： pull the image Run 5 instances of that image as a service called web 限制每个实例最多使用10%的CPU和50MB的RAM 如果一个失败，马上重启container 映射主机的80端口到web的80端口 指示web container通过称为webnet的负载均衡网络共享80端口 使用默认设置定义webnet网络 运行你的负载均衡APP12345678910111213141516171819202122232425262728293031323334docker swarm init#运行并设置APP名字docker stack -c docker-compose.yml app-namedocker stack -c docker-compose.yml LoadBalance#在一个主机上，单个服务栈通过部署的image运行5个container instance#获取service IDdocker service lsID NAME MODE REPLICAS IMAGE PORTS3d1a48yse0t4 LoabBalance_web replicated 5/5 zhang21/test:tag-test *:80-&gt;80/tcp#查看服务中的任务docker service ps app-name_webdocker container ls -q#5个容器IDc7ce0075890e52ba026bf28c6d4381be438fbd297a42e89d357b05cc38eb#访问的时候容器ID会在此5个负载中变化 在服务中运行的单个container称为任务(task)。任务是具有数字增量的唯一ID，最大数量是在docker-compose.yml中定义的副本数量。 伸缩APP通过修改docker-compose.yml中replicas的值，并重新运行docker stack deploy -c xxx app-name来伸缩APP。 Docker执行就地更新，不需要stack down或kill any containers. 卸下APP和swarm： 12345678#appdocker stack rm app-namedocker stack rm LoadBalance#swarmdocker swarm leave --force 使用Docker扩展APP非常简单。 本节命令1234567891011121314151617181920212223#列出栈或APPdocker stack ls#运行指定配置文件docker stack deploy -c &lt;composefile&gt; &lt;appname&gt;#列出与APP相关联的服务docker service ls#列出与APP相关联的任务docker service ps &lt;service&gt;#检查任务docker inspect &lt;task or container&gt;#列出容器IDdocker container ls -q#除掉APPdocker stack rm &lt;appname&gt;#从管理中除掉一个单一节点swarmdocker swarm leave --force swarm 先决条件 前面几个小节的内容 介绍前面你将一个服务运行在生产环境，并扩展为5个副本进程。 在此，你将APP部署到到集群上，并在多台机器上运行它。通过将多台主机连接到成为swarm的Dockerized集群，使得多容器、多主机应用成为可能。 理解swarm集群swarm是一组运行Docker并加入到集群中的机器。这样以后，你可以在集群的swarm manager上执行Docker命令。swarm中的机器可以是物理的或虚拟的，当他们加入swarm后，他们便被成为node。 swarm manager可以使用多种策略来运行容器，你可在compose file中指定相应的策略。 swarm manager是swarm中唯一可以执行命令、授权其他机器作为工作者加入swarm的机器。工作者(worker)只能在那提供能力(capacity)，并没有权力告诉任何机器能够做什么。 但目前为止，你已经在本机机器上以单主机(single host)模式使用Docker。但Docker也可以切换为swarm(集群)模式，这就是使用swarm的原因。立即启用swarm模式使得当前机器成为swarm manager。从此，Docker将运行在你管理的swarm上执行命令，而不仅仅是在当前机器上执行。 建立swarm一个swarm由多个节点组成，不管它是虚拟机还是物理机。 基本概念很简单，运行docker swarm init来开启swarm模式并使得当前机器成为swarm manager 在其它机器上运行docker swarm join使他们作为worker加入swarm 栗子：使用VM快速创建两台机器的集群，并将其变为swarm。 使用docker-machine创建一对VM: 123456789101112131415161718192021#CentOS7#安装VirtualBoxwget https://download.virtualbox.org/virtualbox/5.2.8/VirtualBox-5.2-5.2.8_121009_el7-1.x86_64.rpm &amp;&amp; yum install -y Virtual.xx.rpm#安装docker-machine curl -L https://github.com/docker/machine/releases/download/v0.14.0/docker-machine-`uname -s`-`uname -m` &gt;/tmp/docker-machine &amp;&amp; install /tmp/docker-machine /usr/local/bin/docker-machine#在BIOS中开启虚拟化支持#在VMware中开启虚拟化支持(如果是VM)docker-machine create --driver virtual myvm1docker-machine create --driver virtual myvm2#列出虚拟机docker-machine ls 初始化swarm并添加node 第一台机器作为swarm manager，执行命令和join认证，后面的机器作为worker。 你可以使用docker-machine ssh发送命令到VM。在swarm mananger上执行docker swarm init初始化： 12345678docker-machine ssh &lt;swarm manager&gt; &quot;docker swarm init --advertise-assr &lt;mananger-IP&gt;&quot;#add workerdocker swarm jion --toker &lt;token&gt; &lt;wroker-ip&gt;:&lt;port&gt;#添加managerdocker swarm join-token manaer 由于我的虚拟的无法使用VT，因此我用的两台机器两个Docker来做swarm。 123456789101112131415161718#初始化这台机器默认为managerdocker swarm init#作为worker加入，ip是manager的#以下信息会在manager初始化时生成#注意防火墙，可能会阻碍加入docker swarm join --toker &lt;toker&gt; &lt;ip:port&gt;docker swarm join --token SWMTKN-1-3vrbnuneu0hyu41evxlhbn5fp04ad5jvg9v5rzvdaedg2bghkt-e24mjnni3hu7782t3gkz0ny39 172.16.129.150:2377#查看swarmdocker node ls#离开swarmdocker swarm leave 在swarm集群上部署APP主需要记住，只有swarm manager才能执行docker命令，worker仅仅是容量(capacity)。 在swarm manager上使用docker-composr.yml和docker stack deploy命令来部署APP。使用docker service ps &lt;service name&gt;来验证部署。 123456789101112131415161718192021222324#在manager部署docker stack deploy -c ./docker-compose.yml LoadBalancedocker service lsdocker stack ls#注意node名docker stack ps LoadBalanceID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS6nrn4mwc6pvt LoadBalance_web.1 zhang21/test:tag-test zhang22 Running Preparing 2 minutes agobpssrnzesl7n LoadBalance_web.2 zhang21/test:tag-test zhang22 Running Preparing 2 minutes agokmhd8p5wkc12 LoadBalance_web.3 zhang21/test:tag-test zhang21 Running Running 2 minutes agoi0pkf4foms87 LoadBalance_web.4 zhang21/test:tag-test zhang22 Running Preparing 2 minutes agorvtpjk781frn LoadBalance_web.5 zhang21/test:tag-test zhang21 Running Running 2 minutes ago#分别访问个主机的IP#创建的网络在它们之间共享并负载均衡links ip1links ip2 两个IP地址工作的原因是集群中的节点参与入口(ingress)路由网络(routing mesh)。这可以确保部署在swarm中某个端口的服务始终将该端口保留给自己，而不管实际运行容器的节点是什么。 清理并重启1docker stack rm LoadBalance stack先决条件，已完成前面的步骤。 介绍你已到达分布式应用程序层次结构的顶端——stack。堆栈是一组相互关联的服务，它们可以共享依赖关系，并可以进行协调和缩放。单个堆栈能够定义和协调整个应用程序的功能(尽管非常复杂的应用程序可能需要使用多个堆栈)。 在前面使用的docker deploy——是运行在单主机上的单个服务堆栈，这通常不会发生在生产环境中。在这里，你会使用学到的东西使多个服务相互关联，并在多台机器上运行它们。 添加一个新服务并部署docker-compose2.yml 12345678910111213141516171819202122232425262728293031version: &quot;3&quot;services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 restart_policy: condition: on-failure resources: limits: cpus: &quot;0.1&quot; memory: 50M ports: - &quot;80:80&quot; networks: - webnet #可视化 visualizer: image: dockersamples/visualizer:stable ports: - &quot;8080:8080&quot; volumes: - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; deploy: placement: constraints: [node.role == manager] networks: - webnetnetworks: webnet: 新增的东西使web对等服务，称为visualizer。注意两个事： volumes: 给予visualizer访问主机Docker的socket文件 placement： 确保服务运行在manager而不是worker上 123456789docker stack deploy -c ./docker-compose2.yml stack-testCreating network stack-test_webnetCreating service stack-test_visualizerCreating service stack-test_web#查看visualizer，要等一会才能正常访问，别着急访问 IP:8080 持久化数据让我们再次通过相同的工作流程来添加用于存储应用程序数据的Redis数据库。 docker-compose3.yml，添加一个Redis服务器： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253version: &quot;3&quot;services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 restart_policy: condition: on-failure resources: limits: cpus: &quot;0.1&quot; memory: 50M ports: - &quot;80:80&quot; networks: - webnet visualizer: image: dockersamples/visualizer:stable ports: - &quot;8080:8080&quot; volumes: - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; deploy: placement: constraints: [node.role == manager] networks: - webnet redis: image: redis ports: - &quot;6379:6379&quot; volumes: - &quot;/home/docker/data:/data&quot; deploy: placement: constraints: [node.role == manager] command: redis-server --appendonly yes networks: - webnetnetworks: webnet:#部署docker stack deploy -c docker-compose3.yml redis-test#测试访问 IP:port Redis是一个Docker library中的官方image，并被授予redis镜像名称。 redis规范中有几件事使数据在这个堆栈的部署之间持续存在： redis运行在manager，所以它总是使用相同的文件系统 redis将数据存储在上面的目录 确保redis服务始终使用相同的主机 确保存储的数据的连续性 如果没有创建，redis会将数据存储在容器文件系统的/data中，如果该容器被重新部署，则数据将被清除。 部署APP先决条件为前面的操作步骤。 介绍compose file在生产环境中的效果与在您的计算机上的效果相同。 选择版本我安装的是社区版(ce)。如果你在生产环境中使用docker-ce，则可以使用Docker Cloud帮助管理你的应用程序，如AWS、Aliyun、腾讯云。docker cloud： , 可注册后建立、上传、管理自己的repo。 设置和部署： 连接Docker Cloud并授权它自动为你配置Dockerize VM 使用Docker Cloud创建你的计算资源和swarm 部署应用程序 连接DockerCloud你可以标准模式或swarm模式运行Docker Cloud。 AWS配置指南 Aliyun配置指南 腾讯云配置指南 创建swarm你可在Docker Cloud UI创建你的node，或docker swarm init|join命令。 在云提供商上部署应用程序 我觉得阿里云和腾讯云也有对应的平台。 运行部署命令: docker stack deploy -c xxx.yml &lt;cus_appname&gt;，现在你的APP就运行在云提供商上。 运行swarm命令来验证部署 12345docker node lsdocker service lsdocker service ps &lt;service&gt; 在云提供商开放端口 service type protocol port web http tcp 80 visualizer http tcp 8080 redis tcp tcp 6379 具体操作参见各云提供商。 迭代和清理 改变*.yml文件伸缩应用程序 使用docker stack deploy部署应用程序 push和pull image 使用docker stack rm &lt;name&gt;清除stack 修改Docker默认路径docker默认的目录为/var/lib/docker，但很多时候/var目录并没有单独挂载，可能导致空间不够。前提是你已经把源配置目录对应的文件拷贝到替换的目录。 方法1： 123456789101112131415systemctl stop dockercd /etc/dockervim daemon.json&#123; &quot;graph&quot;: &quot;/opt/docker&quot;&#125;systemctl start docker#systemctl reload docker#查看变更docker info 方法2: 123456789101112systemctl stop dockercd /etc/sysconfig/vim docker-storageDOCKER_STORAGE_OPTIONS=--graph=/opt/dockersystemctl start docker#查看变更docker info 容器服务自启动在运行docker容器时可以加如下参数来保证每次docker服务重启后容器也自动重启: 1234docker run --restart=always -d -p 80:80 &lt;container-id&gt;#对于已启动的容器服务，更新它docker update --restart=always &lt;container-id&gt; 交互式容器进入Docker容器以获得交互式体验。 1docker exec -it &lt;container-id&gt; /bin/bash Docker日志 docker服务日志： journalctl -u docker.service docker容器日志： &lt;docker-graph&gt;/containers/&lt;container-id&gt;/&lt;container-id&gt;-json.log 由于容器ID会变化，请注意提取容器ID 可使用ELK在此收集容器日志 更新镜像使用docker commit从改变的容器中生成一个新镜像。 更新镜像步骤： 备份镜像: docker tag 运行镜像 修改容器 生成新镜像: docker commit 推送镜像: docker push 备份与恢复 备份容器 docker commit: 生成新镜像 docker save： 生成本地tar包 1234567891011121314Usage: docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]docker commit -m &quot;Just a test&quot; -p $&#123;container-id&#125; Zhang21/test:01docker image lsdocker logindocker pushUsage: docker save [OPTIONS] IMAGE [IMAGE...] [flags]docker save -o /path/$&#123;image&#125;.tar $&#123;image&#125;ls /path 恢复容器 docker run ${image} docker load: 载入本地.tar镜像 1234Usage: docker load [OPTIONS]docker load -i /path/$&#123;image&#125;.tardocker image ls 应用场景与注意事项 应用场景 本地依赖 搭建环境 微服务 自动测试 部署过程 CI/CD 多租户环境 一台机器的多个APP 弹性伸缩 资源隔离 注意事项 一个进程，一个容器不推荐在Docker容器中运行多个进程！ 不要将数据存放到容器内所以请使用挂在卷的方式映射到本地磁盘目录 使用磁盘进行数据存储 容器通信每当一个Docker容器需要与另一个容器通信时，传递信息最好使用名称或环境变量。 以non-root用户运行Docker默认情况下，Docker容器以root用户身份运行，众所周知，以root用户运行的容器完全可以控制主机系统。 注意容器的体积选择一个容器的主要原因之一是它的体积小。但是，如果你把它做得更大，它的主要优势就没了。 制定控策略开发和部署Docker容器不是你的工作的结束。您需要持续监控已部署的容器以及整个系统的运行状况。选择合适的工具并制定一个策略来有效地监控您的Docker容器，以确保最短的停机时间，从而使客户满意。 安全问题安全补丁、防火墙… Dockerfile参考: https://docs.docker.com/engine/reference/builder/ https://yeasy.gitbooks.io/docker_practice/content/image/build.html 将镜像每一层的修改、安装、配置、操作的命令写入Dockerfile，并用它来构建、定制镜像，那么镜像构建透明性问题便会得到解决。 Dockerfile是一个文本文件，包含了一条条指令(instrction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 使用Dockerfile定制镜像 FROM所谓指定镜像，就是以一个镜像为基础，在其上进行定制。基础镜像必须指定，而FROM就是指定基础镜像，因此一个Dockerfile中FROM是必备的指令，并且必须是第一条指令。 只有有可能，请使用当前官方repo作为你的基础镜像。我们推荐使用Alpine镜像，因为它严格控制，体积小(只有5MB)，同时也是完整的Linux发行版。 Docker Hub中有很多常用的官方镜像——常用软件、常用语言和常用系统镜像。 12345FROM nginx#特殊镜像，scratch，空白镜像FROM scratch RUN在多行中使用反斜杠\或复杂的RUN语句，使Dockerfile更具可读性、易理解性和可维护性。 RUN指令是用来执行命令行命令的。有两种格式： shell格式 RUN &lt;CMD&gt;，就像直接在命令行中输入命令一样 exec格式 RUN [&quot;可执行文件&quot;, &quot;参数&quot;]，这更像函数调用中的格式 12345678910FROM debian:jessieRUN apt-get updateRUN apt-get install -y gcc libc6-dev makeRUN wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot;RUN mkdir -p /usr/src/redisRUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1RUN make -C /usr/src/redisRUN make -C /usr/src/redis install Dockerfile中的每一个指令都会建立一层，RUN也不例外。每一个RUN的行为，就和手工建立镜像的过程一样 —— 新建立一层，在其上执行这些命令，执行结束后，commit这一层的修改，构成新的镜像。 上面这种写法，创建了7层镜像，这是完全没有意义的，而且很多运行时不需要的东西都被装进了镜像里，比如编译环境和更新的软件包等。结果就会产生非常臃肿、非常多层的镜像，不仅增加了构建部署的时间，也容易出错。这是很多初学Docker的人常犯的一个错误。 UnionFS是Linux、FreeBSD的文件系统服务，UnionFS是有最大层数限制的。 修改后的Dockerfile： 1234567891011121314FROM debian:jessieRUN buildDeps=&apos;gcc libc6-dev make&apos; \ &amp;&amp; apt-get update \ &amp;&amp; apt-get install -y $buildDeps \ &amp;&amp; wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot; \ &amp;&amp; mkdir -p /usr/src/redis \ &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \ &amp;&amp; make -C /usr/src/redis \ &amp;&amp; make -C /usr/src/redis install \ &amp;&amp; rm -rf /var/lib/apt/lists/* \ &amp;&amp; rm redis.tar.gz \ &amp;&amp; rm -r /usr/src/redis \ &amp;&amp; apt-get purge -y --auto-remove $buildDeps 仅仅使用一个RUN指令，并使用&amp;&amp;将各指令串联起来。将之前的7层简化为1层。在编写Dockerfile时，要经常提醒自己，这并不是在写shell脚本，而是在定义每一层该如何构建。 Dockerfile支持shell类的换行\、注释#等格式，良好的格式，如换行、缩进、注释等，会让维护、排障更为容易，这也是一个好习惯。 此外，还可看到命令最后添加了清理工作的命令，删除了为编译构建所需要的软件，清理了所有下载文件。这很重要，镜像是多层存储，每一层的东西并不会在下一层被删除，会一直跟随镜像。因此，构建镜像时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。很多人初学docker制作出了很臃肿的镜像，原因之一就是顽疾了每一层构建的最后一定要清理无关文件。 构建镜像在Dockerfile目录下执行： 1234567#docker build [OPTIONS] PATH | URL | - [flags]#Build an image from a Dockerfile#-t指定镜像名称#.指的是上下文目录docker build -t nginx:test . 构建上下文(content) 上面的.是在指定上下文路径。 当我们在进行镜像构建的时候，并非所有的定制都会通过RUN指令完成，经常会需要一些本地文件复制进镜像，比如通过COPY, ADD指令。而docker build命令并非是在本地构建镜像，而是在服务端，也就是Docker引擎dockerd中构建的。那么在这种C/S架构中，如何才能让服务端获得本地文件呢？ 这就引进了上下文的概念。当构建的时候，用户会指定构建镜像的上下文的路径，docker build命令得知这个路径后，会将路径下的所有内容打包，然后上传给Docker引擎。这样Docker引擎收到这个上下文包后，展开就会获得构建镜像所需的一切文件。 12#复制上下文目录下的package.jsonCOPY ./package.json /app/ 因此COPY这类指令中的源文件的路径都是相对路径，因为绝对路径已经超出了上下文的范围，Docker引擎无法获取这些位置的文件。如果真需要这些文件，请将它们复制到上下文目录中去。 理解构建上下文对于镜像构建很重要，避免犯一些不应该的错误。 一般来说，应将Dockerfile置于一个空目录下，或者项目根目录下。如果该目录下没有所需文件，则应该把所需文件复制一份过来。如果目录下有些东西不希望构建时传给Docker引擎，可以写一个.dockerignore文件，用于剔除不需要作为上下文传递给Docker引擎的。 实际上，Dockerfile的文件名并不要求必须为Dockerfile，也并不要求必须位于上下文目录中。可使用-f指定某个文件为Dockerfile。 其它docker build的用法 直接使用Git repo进行构建 1234#docker build URLdocker build https://github.com/twang2218/gitlab-ce-zh.git#:8.14#docker会自己去clone、切换分支、并进入指定目录开始构建 使用给定tar压缩包构建 123docker build http://server/context.tar.gz#自动下载/解压缩 压缩包，以其作为上下文，开始构建 从标准输入中读取Dockerfile进行构建 1234567docker build - &lt; Dockerfilecat Dockerfile | docker build -docker build - &lt; context.tar.gz Dockerfile指令Dockerfile提供了十多个指令供我们操作。 LABLE你可以为你的镜像添加标签，以助于通过项目来组织镜像，记录相关信息。 123456# Set multiple labels at once, using line-continuation characters to break long linesLABEL vendor=ACME\ Incorporated \ com.example.is-beta= \ com.example.is-production="" \ com.example.version="0.0.1-beta" \ com.example.release-date="2015-02-12" COPY尽管ADD和COPY在功能上相似，但一般来说，COPY是首选，因为它比COPY更透明。COPY只支持将本地文件复制到容器中，而ADD具有一些功能(如提取tar文件和远程URL支持) COPY,复制文件。从构建上下文目录中&lt;源路径&gt;的文件/目录复制到新的一层的镜像内的&lt;目标路径&gt;位置。 源路径可以是多个，或通配符(需满足Go的规则)目标路径可是容器内的绝对路径，也可是相对于工作目录(WORKDIR)的相对路径。目标路径不需要事先创建。使用COPY指令，源文件的各种元数据都会保留 —— 如读、写、执行权限、文件变更时间… 12345678910COPY &lt;sourch&gt; &lt;destination&gt;#或COPY [&quot;&lt;source1&gt;&quot;, ... &quot;&lt;destination&gt;&quot;]#栗子COPY package.json /usr/src/app/COPY hom* /mydir/COPY hom?.txt /mydir/ ADDADD,更高级的复制文件。ADD和COPY的格式和性质基本一致，但增加了一些功能。尽可能的使用COPY，因为COPY的语义很明确，就是复制文件而已，而ADD则包含了更复杂的功能，其行为也不一定很清晰。最适合ADD的场合，就是所提及的需要自动解压缩的场合。 因此在COPY和ADD指令中选择的时候，可以遵循这样的原则，所有的文件复制均使用COPY指令，仅在需要自动解压缩的场合使用ADD。 123456FROM scratchADD abc.tar.gz / &amp;&amp; \ http://example.com/big.tar.xz /usr/src/things/ &amp;&amp; \RUN tar -xJf /usr/src/things/big.tar.xz -C /usr/src/thingsRUN make -C /usr/src/things all CMDCMD，容器启动命令。用于运行镜像中包含的软件以及任何参数。 也有两个格式： shell格式： CMD &lt;command&gt; shell格式，在实际中会被包装成sh -c的参数形式进行执行： 123456789CMD echo $HOME#转变为CMD[&quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot;]#-c string If the -c option is present, then commands are read from string.#这就是为什么我们可以使用环境变量的原因，因为这些环境变量会被 shell 进行解析处理 exec格式： CMD [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot; ...]CMD几乎总是以此格式使用。 Docker不是虚拟机，容器就是进程。既然是进程，那么在启动容器的时候，需要指定所运行的程序及参数。CMD指令就是用于指定默认的容器主进程的启动命令的。`` 对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。 ENTRYPOINTENTRYPOINT，入口点。指令格式同样分为shell格式和exec两种。 ENTRYPOINT和CMD一样，都是在指定容器启动程序及参数。当指定了ENTRYPOINT后，CMD的含义就发生了改变，不再是直接的运行其命令，而是将CMD的内容作为参数传给ENTRYPOINT指令。即变为如下模式： 1&lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; 有几大好处： 让镜像变成像命令一样使用 12345678910111213#可以从腾讯上拉取，快一些#ccr.ccs.tencentyun.com/qcloud/ubuntuFROM ubuntu:16.04RUN apt-get update \ &amp;&amp; apt-get install -y curl \ &amp;&amp; rm -rf /var/lib/apt/lists/*CMD [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://ip.cn&quot; ]docker build -t myipdocker run myip#当前 IP：182.150.x.xx 来自：四川省成都市 电信 不过命令总有参数，例如我想查看HTTP header，使用-i参数 1234567docker run myip -i#这样会报错，-i替换了CMD命令，而不是-s参数，然而-i并不是命令#重新完整输入命令docker run myip curl -s http://ip.cn -i#这样又太麻烦 这时便可以使用ENTRYPOINT解决这个问题。 1234567891011121314FROM ubuntu:16.04RUN apt-get update \ &amp;&amp; apt-get install -y curl \ &amp;&amp; rm -rf /var/lib/apt/lists/*ENTRYPOINT [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://ip.cn&quot; ]docker build it myipdocker run myip#当前 IP：182.150.x.xx 来自：四川省成都市 电信docker run myip -i#成功 当存在ENTRYPOINT后，CMD的内容将作为参数传递给ENTRYPOINT，而-i就是新的CMD，因此会作为参数传递给curl，从而达到预期效果。 应用运行前的准备工作 有时，在启动前需要做一些准备工作。 如MySQL，需要一些配置文件、初始化工作，这些工作需要在MySQL server运行前解决 避免使用root用户去启动服务，从而提高安全性 这些准备工作和CMD无关 ENVENV，设置环境变量。为了使新软件更容易运行，使用此命令为你的容器内安装的软件更新环境变量。 两种格式： ENV &lt;key&gt; &lt;value&gt; ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 123ENV PATH $PATH:/root/bin \ EMAIL abc@zhang21.cn \ NAME=&quot;Zhang21&quot; 下列指令可以支持环境变量展开： ADD, COPY, ENV, EXPOSE, LABEL, USER, WORKDIR, VOLUME, STOPGIGNAL, ONBUILD。 通过环境变量，我们可以让一份Dockerfile制作更多的镜像，只需使用不同的环境变量即可。 ARGARG，构建参数 格式： ARG &lt;参数名&gt;[=&lt;默认值&gt;] 构建参数和ENV的效果一样，都是设置环境变量。所不同的是，ARG所设置的构建环境的环境变量，在将来容器运行时是不会存在这些环境变量的。 VOLUMEVOLUME，定义匿名卷。用于显示有docker容器创建的任何数据库存储区域，配置存储或文件/文件夹。强烈建议将VOLUME用于镜像的任何可变部分和用户可用部分。 格式： VOLUME [&quot;&lt;路径1&gt;&quot;, &quot;&lt;路径2&gt;&quot;...] VOLUME &lt;路径&gt; 容器运行时应该尽量保持容器存储层不发生写操作，对于数据库类需要保存动态数据的应用，其数据库文件应该保存于卷(volume)中。为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在Dockerfile中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会像容器存储层写入大量数据。 123456#在运行时自动挂载为匿名卷VOLUME /data#覆盖挂载docker run -d -v mydata:/data xxx EXPOSEEXPOSE，声明容器监听连接的端口。 格式： EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...] EXPOSE指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在Dockerfile中写入这个声明有两个好处： 一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便映射 另一个用处则是在运行时使用随机端口映射(未定义时) 要将EXPOSE和在运行时使用-p &lt;宿主端口&gt;:&lt;容器端口&gt;区分开。EXPOSE仅仅声明容器打算使用哪些端口，并未包含端口映射。 WORKDIRWORKDIR，指定工作目录。为了清晰可靠，请使用绝对路径。 使用WORKDIR指令可以来指定工作目录，以后各层的当前目录就被改为指定的目录，如目录不存在，WORKDIR会帮你建立目录。如果需要改变Dockerfile各层的工作目录的位置，那么应该使用WORKDIR指令。 格式： WORKDIR &lt;工作目录&gt; USERUSER，指定当前用户。如果服务可以在非特权模式下运行，请使用USER将其改为non-root用户。首先在Dockerfile中创建相应的用户和组: 12RUN groupadd -r group &amp;&amp; \ useradd -r -g group group USER和WORKDIR相似，都是改变环境状态并影响以后的层。WORKDIR是改变工作目录，USER则是改变之后的层执行RUN, CMD, ENTRYPOINT这类命令的身份。这个用户必须存在。 格式： USER &lt;用户名&gt; 12USER redisRUN [&quot;redis-server&quot;] HEALTHCHECKHEALTHCHECK，健康检查HEALTHCHECK指令告诉docker应该如何进行判断容器的状态是否正常。 格式： HEALTHCHECK [选项] CMD &lt;命令&gt;， 设置检查容器健康状况的命令 HEALTHCHECK NONE， 如果基础镜像有健康检查，使用这行可以屏蔽其健康检查指令 当在一个镜像指定了HEALTHCHECK指令后，用其启动容器，初始状态会为starting，在HEALTHCHECK指令检查成功后变为healthy，如果连续一定次数失败，则会变为unhealthy。和CMD, ENTRYPOINT一样，HEALTHCHECK 只可以出现一次，如果写了多个，只有最后一个生效。 ONBUILDONBUILD，为他人做嫁衣。 ONBUILD是一个特殊的指令，它后面跟的是其它指令。而这些指令，在当前镜像构建时不会被执行。只有当以当前镜像为基础镜像(父镜像)，去构建下一级镜像(子镜像)的时候才会被执行。ONBUILD命令在子镜像的Dockerfile中任何命令之前执行。Dockerfile中的其它指令都是为了定制当前镜像而准备的，唯有ONBUILD是为了帮助别人定制自己而准备的。 格式： ONBUILD &lt;其它指令&gt; Dockerfile多阶段构建全部放入一个Dockerfile 将所有的构建过程包含在一个Dockerfile中，包括项目及其依赖库的编译、测试、打包等流程。这可能会带来一些问题： Dockerfile特别长，可维护性降低 镜像层次多，镜像体积较大，部署时间变长 源代码存在泄漏的风险 分散到多个Dockerfile 事先在一个Dockerfile将项目及其依赖库编译测试打包好后，再将其拷贝到运行环境中。这种方式需要编写两个Dockerfile和一些编译脚本才能将两个阶段自动整合起来。这种方式虽然可以很好避免全部写入一个Dockerfile的风险，但明显部署过程较复杂。 多阶段构建 使用多阶段构建我们就可以很容易解决前面提到的问题，并且只需要编写一个Dockerfile。 Dockerfile最佳实践 一般性建议 容器应该是短暂的 使用.dockerignore文件 使用多阶段构建减少镜像大小 避免安装不必要的包 一个镜像只运行一个进程 镜像层数尽可能少 将多行参数排序 构建缓存 Dockerfile指令 FROM LABEL RUN CMD EXPOSE ENV ADD COPY ENTRYPOINT VOLUME USER WORKDIR Compose file参考: https://docs.docker.com/compose/compose-file/ 使用Docker进行开发Develop with Docker 在Docker上开发应用程序Develop new apps on Docker Learn to build an image from a Dockerfile Use multistage builds to keep your images lean Manage application data using volumes and bind mounts Scale your app as a swarm service Define your app stack using a compose file General application development best practices 了解有关Docker上特定语言的开发： Java node.js Ruby on Rails .Net ASP.Net Docker开发最佳实践Docker development best practices 如下开发模式已被证明有助于人么使用Docker构建应用程序。 如何保持较小的镜像How to keep your images small 在启动容器或服务时，小图像可以更快速通过网络pull镜像并加载到内存中。有几条经验法则可保持较小的镜像： 从适当的基础镜像开始例如，如果需要JDK，请考虑官方镜像，而不是从一个通用的Ubuntu/Centos镜像并将Openjdk作为Dockerfile的一部分安装开始。 使用多阶段构建例如，你可以使用maven镜像构建java程序，然后重置到tomcat镜像，并将java构件复制到正确位置以部署应用程序，所有这些都位于相同的Dockerfile。这意味着你的最终镜像不包含构建时所引入的所有库和依赖项，仅包含运行它们所需的构件和环境。 如果你有多个共同的镜像，请考虑使用共享组件创建你的基本镜像，并在其上创建独特的镜像Docker只要家在一次通用层，然后便会缓存。 保持生产环境镜像精简但允许调试(degub)，请考虑使用生产环境镜像作为调试镜像的基本镜像 在构建镜像时，应该始终使用有用的标签对其进行标记，如(test, prod)。不要依赖自动创建的latest标签 何处以及如何持久化应用程序数据Where and how to persist application data 避免使用存储驱动(storge drivers)将应用程序的数据存储在容器的可写层(writeable layer)中与使用卷(volume)或绑定挂载(bound mounts)相比，这增加了容器的大小，并且从I/O角度来看效率较低 使用卷存储数据 适合使用绑定挂载的一种情况是在开发过程中，对于生产环境，请改用卷 对于生产环境，使用secerts来存储服务使用的敏感的应用程序数据，使用config来存储不敏感的数据(如配置文件) 尽可能使用swarm服务Use swarm services when possible 在可能的情况下，使用swarm服务进行伸缩的能力来设计你的应用程序 即使你只需运行单个实例，swarm服务也比standalone容器提供更多的优势 网络和卷可使用swarm服务连接和断开，并且docker可以以不中断的方式重新部署各个服务容器。standalone容器需要手动停止/移除/重新创建 一些功能仅适用于服务而不适用于standalone容器 让docker stack deploy处理任意镜像，而不是使用docker pull。通过这种方式，你的部署不会尝试从down的节点进行pull。此外，当新节点添加到集群时，镜像会自动pull 使用CI/CD进行测试和部署Use CI/CD for testing and deployment CI(Continuous integration) CD(continuous deployment) 当更新源码库或创建拉取请求时，请使用CI/CD pipeline 自动构建并标记Docker镜像，并对其进行测试。也可将测试过的应用程序直接部署到生产环境中 Develop images编写Dockerfile的最佳实践Best practices for writing Dockerfiles Docker通过读取Dockerfile(一个包含命令的文本文件)中的命令来自动构建镜像。Dockerfile reference: https://docs.docker.com/engine/reference/builder/ Dockerfile由read-only layer组成，每层代表一个Dockerfile指令。如: 1234FROM ubuntu:15.04COPY . /appRUN make /appCMD python /app/app.py 每个命令创建一个层: FROM从ubuntu:15.04 Docker image创建一个层 COPY从Docker client的当前目录添加文件 RUN使用make构建你的应用程序 CMD指定在容器内运行的命令 当你运行镜像并生成容器时，会在基础层的顶部添加一个可写层(writable layer)，也称容器层(container layer)。对正在运行的容器所做的所有更改(增删改文件)都会写入此可写容器层。 一般准则和建议General guidelines and recommendations 创建临时(ephemeral)容器 Create ephemeral containers由Dockerfile定义的镜像应该生成尽可能临时的容器。临时的意思为容器可以被停止(stop)和销毁(destroy)，然后重建(rebuild)并使用绝对最小化的设置和配置来替代。 理解构建上下文 Understand build context当你发出docker build命令时，当前的工作目录被称为构建上下文(build context)。默认情况下，假设Dockerfile位于此，但你也可以使用文件标志(-f)指定位置。无论Dockerfile位于何处，当前目录内的所有内容(除了.dockerignore中忽略的内容)都将作为构建上下文发送给Docker守护进程。 从stdin读取Dockerfile Pipe Dockerfile through stdin 12345678910111213#local build-contextdocker build -t . -f-&lt;&lt;EOFFROM busyboxRUN echo &quot;hello world&quot;COPY . /my-copied-filesEOF#remotedocker build -t foo https://github.com/thajeztah/pgadmin4-docker.git -f-&lt;&lt;EOFFROM busyboxCOPY LICENSE config_local.py /usr/local/lib/python2.7/site-packages/pgadmin4/EOF 使用.dockerignore排除文件 Exclude with .dockerignore要排除与构建无关的文件，请使用.dockerignore文件，这与.gitignore类似。 12345vim ./dockerignorefile1dir2... 使用多阶段构建 Use multi-stage builds多阶段构建允许你大幅缩减镜像大小，而不需要减少中间层和文件数。由于镜像是在构建过程的最后阶段构建的，因此可以通过利用构建缓存(build cache)来最小化镜像层 例如，如果你的版本博涵包含多个层，你可以从 不经常改动的版本到频繁改动的版本进行排序: 安装构建应用程序需要的工具 安装或更新依赖库 生成应用程序 A Dockerfile for Go application: 123456789101112131415161718192021222324FROM golang:1.9.2-alpine3.6 AS build# Install tools required for project# Run `docker build --no-cache .` to update dependenciesRUN apk add --no-cache gitRUN go get github.com/golang/dep/cmd/dep# List project dependencies with Gopkg.toml and Gopkg.lock# These layers are only re-built when Gopkg files are updatedCOPY Gopkg.lock Gopkg.toml /go/src/project/WORKDIR /go/src/project/# Install library dependenciesRUN dep ensure -vendor-only# Copy the entire project and build it# This layer is rebuilt when a file changes in the project directoryCOPY . /go/src/project/RUN go build -o /bin/project# This results in a single layer imageFROM scratchCOPY --from=build /bin/project /bin/projectENTRYPOINT [&quot;/bin/project&quot;]CMD [&quot;--help&quot;] 不要安装不必要的包 Don’t install unnecessary packages为了减少复杂性、依赖性，文件大小和构建时间，避免安装额外的或不不必要的软件包。 分离应用程序 Decouple applications每个容器应该只有一个问题。将应用程序分离到多个容器中可以更轻松地水平伸缩和重新使用容器。例如，Web应用程序堆栈可能有三个独立的容器组成，每个容器都有其独特的镜像，以分离的方式管理Web应用程序、数据库和内存缓存。 将每个容器限制为一个进程是一个很好的经验法则，但不是硬性规定。(想想高可用和负载均衡)。 尽你最大的努力使容器干净和模块化。如果容器相互依赖，则可以使用Docker container network来确保容器间可进行通信。 最小化层数 Minimize the number of layers在老版本的docker中，重要的是减少镜像的层数，以确保它们的性能。 对多行参数排序 Sort multi-line arguments只要有可能，通过按字母数字排序多行参数来简化修改。这有助于避免软件包重复，并使列表更容易更新。 123456RUN apt-get update &amp;&amp; apt-get install -y \ bzr \ cvs \ git \ mercurial \ subversion Leverage build cache 在构建镜像时，Docker安装Dockerfile中的指令逐步执行，并按指定的顺序执行每个镜像。在检查每条指令时，docker会在其缓存中查找可重用的现有镜像，而不是创建新的(重复)镜像。 如果你不想使用缓存，可在docker build命令中使用--no-cache=true选项。如果让Docker使用了缓存，那么了解何时可以 找到/找不到 匹配的图像就很重要了。 Docker遵循的基本规则如下: 从已经在缓存中的父镜像开始，将下一条指令与该基本镜像派生的所有子镜像进行比较，以查看是否使用完全相同的指令构建了其中的一条。否则，缓存失效。 大多数情况下，只需将Dockerfile中的指令与其中一个子镜像进行比较久够了。但是，某些说明需要更多的检查和解释。 对于ADD和COPY指令，将检查镜像文件中的内容，并为每个文件计算校验和。在缓存查找过程中，将检验和与现有镜像中的校验和进行比较，如果文件中由任何内容已更改，如内容和元数据，则缓存将失效。 除了ADD和COPY指令，缓存检查将不会查看容器中的文件已确定缓存。 一旦缓存失效，所有后续的Dockerfile命令将生产新的镜像，并且不会使用缓存。 Dockerfile instruction 请参考: Dockerfile 创建一个基镜像Create a base image 大多数Dockerfile从父镜像开始，如果需要完全控制镜像的内容，则可能需要创建基镜像(base image)。区别: 父镜像是镜像的所基于的镜像 基镜像的Dockerfile中没有FROM行 使用多阶段构建Use multi-stage builds 多阶段构建需要Docker v17.05及以上版本。多阶段构建对于优化Dockerfile来说非常有用，同时让它易读和维护。 构建之前构建镜像最具挑战的事情是保持镜像的大小。Dockerfile中的每条指令都会为镜像添加一层，在移动到下一层前清理不需要的任何构件。为了编写一个高效的Dockerfile，需要尽可能减小图层，并确保每个层都具有上一层需要的构件，而不是其它东西。 使用多阶段构建使用多阶段构建，你可以在Dockerfile中使用多个FROM语句。每条FROM命令可以使用不同的基镜像，并且每个指令都可是构建的新阶段。 1234567891011FROM golang:1.7.3WORKDIR /go/src/github.com/alexellis/href-counter/RUN go get -d -v golang.org/x/net/htmlCOPY app.go .RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .FROM alpine:latestRUN apk --no-cache add ca-certificatesWORKDIR /root/COPY --from=0 /go/src/github.com/alexellis/href-counter/app .CMD [&quot;./app&quot;] COPY --from=0将前面构建的工作复制到这个新阶段。Go SDK和任何中间工作件都被留下，并未保存在最终镜像中 命名你的构建阶段默认情况下，构建阶段没有命名。你可以通过它们的整数来引用它们，第一个指令FROM从0开始。但你可以命名它。 1234567891011FROM golang:1.7.3 as builderWORKDIR /go/src/github.com/alexellis/href-counter/RUN go get -d -v golang.org/x/net/htmlCOPY app.go .RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .FROM alpine:latestRUN apk --no-cache add ca-certificatesWORKDIR /root/COPY --from=builder /go/src/github.com/alexellis/href-counter/app .CMD [&quot;./app&quot;] 停止一个特定的构建阶段构建镜像时，不一定需要构建包含每个阶段的整个Dockerfile。如下的栗子停在名为builder的阶段: 1docker build --target builder -t alexellis2/href-counter:latest . 使用外部镜像用作一个阶段多阶段构架可使用COPY --from指令从单独的镜像中进行复制，可以使用本机镜像、远程Registry的镜像和标记的ID。 1COPY --from=nginx:latest /etc/nginx/nginx.conf /nginx.conf 使用Docker Engine SDKs和API进行开发Develop with Docker Engine SDKs and API 综述Docker提供了一个用于与Docker daemon(称为Docker Engine API)交互的API，以及用于Go和Python的SDK。 SDK允许你款速轻松地构建和扩展Docker APP。如果Go或Python不适合你，你可以直接使用Docker Engine API——它是由HTTP客户端(curl, wget)访问的RESTful API，或者是大多数现代编程语言的一部分HTTP库。 安装SDKsGo SDK Go SDK参考：https://godoc.org/github.com/docker/docker/client 1go get github.com/docker/docker/client Python SDK Python SDK参考: https://docker-py.readthedocs.io/en/stable/ 1pip install docker 快速开始SDK和APIPython: 运行一个容器 123import dockerclient = docker.from_env()print (client.containers.run(&quot;alpine&quot;, [&quot;echo&quot;, &quot;hello&quot;, &quot;world&quot;])) HTTP: 123456789101112$ curl --unix-socket /var/run/docker.sock -H &quot;Content-Type: application/json&quot; \ -d &apos;&#123;&quot;Image&quot;: &quot;alpine&quot;, &quot;Cmd&quot;: [&quot;echo&quot;, &quot;hello world&quot;]&#125;&apos; \ -X POST http:/v1.24/containers/create&#123;&quot;Id&quot;:&quot;1c6594faf5&quot;,&quot;Warnings&quot;:null&#125;$ curl --unix-socket /var/run/docker.sock -X POST http:/v1.24/containers/1c6594faf5/start$ curl --unix-socket /var/run/docker.sock -X POST http:/v1.24/containers/1c6594faf5/wait&#123;&quot;StatusCode&quot;:0&#125;$ curl --unix-socket /var/run/docker.sock &quot;http:/v1.24/containers/1c6594faf5/logs?stdout=1&quot;hello world SDK和API栗子链接: https://docs.docker.com/develop/sdk/examples/ 网络配置Configure networking 综述Docker容器和服务如此强大的原因之一是——你可以将它们连接在一起，或将它们连接到non-docker工作负载。Docker容器和服务甚至不需要知道它们是否部署在Docker上，或它们的对等端是否也是Docker工作负载。都可以使用Docker方式管理它们。 网络驱动Network drivers 使用驱动程序，Docker的网络子系统是可插拔的(pluggable)。 集中驱动程序: brige默认网络驱动。桥接网络通常用于你的应用程序运行在需要通信的独立容器中。 host对于独立容器，删除容器和Docker主机之间的网络隔离，并直接使用主机的网络。 overlayoverlay网络将多个docker daemon连接在一起，并使集群服务能够无相互通信。 macvlanmacvlan网络允许你为容器分配MAC地址，使其成为你网络上的物理设备。docker daemon通过其MAC地址将流量路由到容器。 none对于此容器，禁用所有网络。 network plugins你可在Docker上安装和使用第三方网络插件，从Docker Store获取: https://store.docker.com 网络驱动总结 User-defined bridge networks当你需要多个容器在同一个Docker主机上进行通信时 Host networks当网络堆栈不应与Docker主机隔离时，但希望容器的其它方面被隔离 Overlay networks当你需要运行在不同Docker主机上的容器进行通信时，或多个应用程序使用集群服务进行工作时 Macvlan networks当你从虚拟机迁移或需要你的容器看起来像物理主机时，每个都具有唯一的MAC地址 Third-party network plugins允许你将Docker与专用网络堆栈集成 bridge就网络而言，桥接网络是一种链路层设备，用于转发网段之间的流量。桥接可以是硬件设备，或在主机内核中运行的软件设备。就Docker而言，桥接网络允许连接到统一桥接网络的容器进行通信，同时提供与未连接到桥接网络的容器的隔离。Docker桥接驱动程序自动在主机上安装桥接规则，以便于不同桥接网络上的容器不能直接相互通信。 桥接网络适用于在同一个Docker daemon上运行的容器之间的通信。 当你启动Docker时，除非另有定义，否则将自动创建默认桥接网络，并且新启动的容器将连接到它。你也可以创建用户自定义的桥接网络。 bridge与user-defined bridgesDifferences between user-defined bridges and the default bridge 两者的差别： 用户自定义的桥接在集装箱化的应用程序之间提供了更好的隔离和互操作性 用户自定义的桥接提供了容器之间的自动DNS解析 容器可以在运行中与用户定义的网络进行连接(attach)和分离(detach) 每个用户定义的网络会创建一个可配置的桥接网络 在默认桥接网络上链接的容器共享环境变量 管理user-defined bridgeManage a user-defined bridge 1234567891011docker network create --help#创建一个用户自定义桥接网络#你还可以指定子网，范围，网关...docker network creat $&#123;name&#125;docker network creat my-net#删除docker network rm $&#123;name&#125; 连接到自定义桥接网络Connect a container to a user-defined bridge 当你创建一个新的容器时，你可以指定一个或多个--network标志。 12345678910111213#创建时docker create --name my-nginx \ --network my-net \ --publish 8080:80 \ nginx:latest#运行中的容器docker network connect my-net my-nginx#断开连接docker network disconnect my-net my-nginx 使用IPv6需要修改docker daemon的配置项以支持使用IPv6，在创建自定义网络是指定--ipv6标志。你不能有选择地禁用默认桥接网络上的IPv6支持。 启用容器转发Enable forwarding from Docker containers to the outside world 默认情况下，使用默认桥接网络的连接的容器的流量不会转发到外部世界。启用操作如下： 1234567#配置Linux内核sysctl net.ipv4.conf.all.forwarding=1#修改iptables FORWARD默认策略iptables -P FORWARD ACCEPT#重启后无效，请写入配置文件 默认桥接网络Use the default bridge network 默认桥接网络被视为Docker的遗留细节，不建议用于生产环境。 连接容器到默认桥接网络如果未指定网络，则默认使用默认桥接网络。 配置默认桥接网络指定并配置daemon.json文件 123456789&#123; &quot;bip&quot;: &quot;192.168.1.5/24&quot;, &quot;fixed-cidr&quot;: &quot;192.168.1.5/25&quot;, &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;, &quot;mtu&quot;: 1500, &quot;default-gateway&quot;: &quot;10.20.1.1&quot;, &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;, &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]&#125; 使用IPv6修改配置文件以支持IPv6，则默认桥接网络自动支持IPv6。 overlayoverlay网络驱动在多个docker daemon主机之间创建分布式网络。该网络位于特定主机网络之上，允许容器连接到此并安全地进行通信。 当初始化集群或将docker主机加入现有集群时，将在docker主机上创建两个新网络： 称为ingress的overlay网络处理与集群服务相关的控制和数据流量。当你创建集群服务并且不将其连接到用户自定义的网络时，它默认连接到ingress网络。 称为docker_gwbridge的桥接网络将单独的docker daemon连接到集群的其它docker daemon。 与创建自定义桥接网络类似，你也可以使用docker network create来创建自动以的overlay网络。服务或容器一次可连接到多个网络，但只能通过连接的网络进行通信。 尽管可以将集群服务和独立容器连接到overlay网络，但默认行为和配置是不同的。 所有overlay网络的操作Operations for all overlay networks 创建overlay网络Create an overlay network 先决条件 使用overlay网络的docker daemon的防火墙规则 2377(tcp): 集群通信管理 7946(tcp/udp)： 节点通信 4789(udp)： overlay网络流量 创建overlay网络前，需要初始化docker daemon集群 12345678docker network create -d overlay my-overlay#创建可供集群服务或独立容器与其它docker daemon上的独立容器进行通信docker network create -d overlay --attachable my-attachable-overlay#你可以指定IP地址范围，子网，网关... 加密overlay网络上的流量Encrypt traffic on an overlay network Overlay network encryption is not supported on Windows！ 所有集群服务管理流量默认都是加密的，在GCM模式下使用AES算法。要加密应用程序数据，在创建overlay网络时添加--opt encrypted。这种加密带来了不可忽视的性能问题，所以应该在生产环境使用前对其进行测试。当启用overlay加密时，docker会在节点间创建IPsec tunnel，在这些节点上调度连接到overlay网络的服务的任务。 12#SWARM MODE OVERLAY NETWORKS AND STANDALONE CONTAINERS docker network create --opt encrypted --driver overlay --attachable my-attachable-multi-host-network 自定义默认ingress网络如果自动选择的子网与已存在的网络冲突，或需要自定义其它低级网络设置(如MTU)，这次功能非常有用。 1234567891011121314#显示详细信息docker network inspect ingress#移除现有网络docker network rm ingress#创建新网络 --ingressdocker network create \ --driver overlay \ --ingress \ --subnet=10.11.0.0/16 \ --gateway=10.11.0.2 \ --opt com.docker.network.driver.mtu=1200 \ my-ingress 自定义docker_gwbridgedocker_gwbridge是一个虚拟桥接网络，它将overlay网路连接到单独的docker daemon的物理网络。当初始化集群或将主机加入集群时，docker会自动创建它，但它不是docker设备。啊存在于docker主机的内核之中。如果你需要自定义其设置，则必须在主机加入集群之前或将主机临时从集群中删除之后才执行此操作。 12345678910111213141516171. 停止docker2. 删除已存在的docker_gwbridgeip link set docker_gwbridge doenip link del dev docker_gwbridge3. 启动docker，但不加入或初始化集群4. 创建docker_gwbridgedocker network create \--subnet 10.11.0.0/16 \--opt com.docker.network.bridge.name=docker_gwbridge \--opt com.docker.network.bridge.enable_icc=false \--opt com.docker.network.bridge.enable_ip_masquerade=true \docker_gwbridge5. 集群初始化或加入集群 swarm服务的操作Operations for swarm services 在overlay网络上发布端口Publish ports on an overlay network 连接到同一overlay网络的集群服务可有效地将所有端口暴露给对方。要是端口可在服务外可访问，必须使用-p或--publish标志暴露此端口。 两种方法： 传统的冒号:分隔语法 较新的逗号,分隔语法 Flag value Description -p 8080:80 or -p published=8080,target=80 Map TCP port 80 on the service to port 8080 on the routing mesh -p 8080:80/udp or -p published=8080,target=80,protocol=udp Map UDP port 80 on the service to port 8080 on the routing mesh -p 8080:80/tcp -p 8080:80/udp or -p published=8080,target=80,protocol=tcp -p published=8080,target=80,protocol=udp Map TCP port 80 on the service to TCP port 8080 on the routing mesh, and map UDP port 80 on the service to UDP port 8080 on the routine mesh 绕过swarm的路由网格Bypass the routing mesh for a swarm service 默认情况下，发布端口的集群服务使用路由网格来发布。当你连接到任何swarm节点上已发布的端口时，都会透明地将你重定向到正在运行服务的工作。实际上，docker充当集群服务的负载均衡器(Load-Balancer)。使用路由网格的服务以虚拟IP(vip)模式运行。即使在每个节点上运行服务也使用路由网格。使用路由网格时，不能保证那个docker node处理客户端请求。 要绕过路由网格，可使用DNS Round Robin(DNSRR)模式启动——--endpoint-mode dnsrr。你必须在服务前运行负载均衡器。docker主机上DNS查询服务名称会返回运行该服务的节点的IP地址列表。配置你的负载均衡器使用此列表并平衡各节点间的流量。 分离控制流量和数据流量默认情况下，尽管集群控制流量是加密的，但集群管理和应用程序之间的控制流量运行在同一个网络上。你可以配置docker来使用单独的网络接口来处理来种不同类型的流量。 overlay网络上独立容器的操作Operations for standalone containers on overlay networks 将独立容器连接到overlay网络Attach a standalone container to an overlay network 独立容器连接到ingress网络需添加--attachable标志。这使得运行在不同docker daemon上的独立容器能够进行通信，而无需在各个docker daemon主机上设置路由。 发布端口Publish ports Flag value Desciption -p 8080:80 Map TCP port 80 in the container to port 8080 on the overlay network -p 8080:80/udp Map UDP port 80 in the container to port 8080 on the overlay network -p 8080:80/sctp Map SCTP port 80 in the container to port 8080 on the overlay network -p 8080:80/tcp -p 8080:80/udp Map TCP port 80 in the container to TCP port 8080 on the overlay network, and map UDP port 80 in the container to UDP port 8080 on the overlay network 容器发现Container discovery 对于大多数情况，应该连接到服务名称——它是负载均衡的，并支持服务的所有容器处理。要获取支持该服务的所有任务的列表，请执行DNS查找服务——tasks.&lt;service-name&gt;。 host如果你对容器使用host网络驱动，则该容器的网络堆栈将不与docker主机隔离。例如，如果运行一个绑定在80端口并使用host网络的容器，则该容器的应用程序将在主机IP地址的80端口上可用。 host网络驱动只能运行在Linux主机上。 Macvlan一些应用程序，尤其是需要监视网络流量的应用程序，希望连接到物理网络上。在这种情况下，你可以使用macvlan驱动为容器的虚拟网络接口分配MAC地址，使其看起来像是直接连接到物理网络的物理网络接口。在这种情况下，你需要指定Docker主机上的物理接口用于macvlan，以及macvlan的子网和网关。 创建一个macvaln网络macvlan网络可处于 bridge mode 或 802.1q trunk mode: 在桥接模式下，macvlan流量通过主机上的物理设备 在802.1q主干桥接模式下，流量通过Docker在运行中创建的802.1q子接口。这使你可以更细粒度地控制路由和过滤。 bridge mode 创建bridge macvlan: 123456789101112docker networkcreate --driver macvlan \ --subnet=172.16.86.0/24 \ --gateway=172.16.86.1 \ -o parent=eth0 pub_net#--aux-addresses排除IP地址docker networkcreate --driver macvlan \ --subnet=172.16.86.0/24 \ --gateway=172.16.86.1 \ --aux-address=&quot;my-router=192.168.32.129&quot; \ -o parent=eth0 pub_net 802.1q truk bridge mode 如果你指定了包含点.的接口名——如eth0.50，则Docker将其解释为eth0的子接口，并自动创建子接口。 1234docker network create --driver macvlan \ --subnet=192.168.50.0/24 \ --gateway=192.168.50.1 \ -o parent=eth0.50 macvlan50 使用ipvlan替换macvlan 123456docker network create -d ipvlan \ --subnet=192.168.210.0/24 \ --subnet=192.168.212.0/24 \ --gateway=192.168.210.254 \ --gateway=192.168.212.254 \ -o ipvlan_mode=l2 ipvlan210 IPv6 123456docker network create -d macvlan \ --subnet=192.168.216.0/24 --subnet=192.168.218.0/24 \ --gateway=192.168.216.1 --gateway=192.168.218.1 \ --subnet=2001:db8:abc8::/64 --gateway=2001:db8:abc8::10 \ -o parent=eth0.218 \ -o macvlan_mode=bridge macvlan216 禁用容器网络在启动容器时加上`–network none来禁用容器的网络堆栈，这样在容器内便仅仅创建loopback设备。 12345$ docker run --rm -dit \ --network none \ --name no-net-alpine \ alpine:latest \ ash 网络教程Networking tutorials bridge network default bridge network user-defined bridge network default bridge network 基本docker网络 12345docker network lsNETWORK ID NAME DRIVER SCOPE8d3b84bfe5a0 bridge bridge local3579d63da633 host host localf766b990db47 none null local 以上列出了默认的桥接网络，主机网络(启动直接连接到docker daemon的主机的网络堆栈的容器)，none(启动一个没有网络设备的容器)。 启动一个容器 1docker run -dit --name alpine1 alpine ash 由于启动时没有指定网络，所以默认为桥接网络。 Inspect the bridge network，以查看哪个容器连接到它 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748docker network inspect bridge[ &#123; &quot;Name&quot;: &quot;bridge&quot;, &quot;Id&quot;: &quot;8d3b84bfe5a034c65d043af80976a1e6127011fc1ab312446252f562e221d351&quot;, &quot;Created&quot;: &quot;2018-05-24T18:38:35.538308064+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.17.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;893903129d869f384bd78d63a382f1c9527d6979be0a6cf3c13ea4f45a1554d6&quot;: &#123; &quot;Name&quot;: &quot;hardcore_rosalind&quot;, &quot;EndpointID&quot;: &quot;515d1435470c9f72d3b07680515d9c503457b8eb5bcaaaa915bb53901eac9424&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.17.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;, &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;, &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 连接到容器 123456789101112131415161718docker attach alpine1/ # ip addr show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever506: eth0@if507: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever/ # ping -c 2 www.baidu.comPING www.baidu.com (119.75.216.20): 56 data bytes64 bytes from 119.75.216.20: seq=0 ttl=55 time=46.521 ms64 bytes from 119.75.216.20: seq=1 ttl=55 time=45.189 ms ping其它容器 1234/ # ping -c 2 172.17.0.2PING 172.17.0.2 (172.17.0.2): 56 data bytes64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.125 ms64 bytes from 172.17.0.2: seq=1 ttl=64 time=0.075 ms user-defined bridge networks 创建名为apline-net用户自定义网络当然，你可以手动指定子网，网关这些。 123456789docker network create --driver bridge alpine-netdocket network lsNETWORK ID NAME DRIVER SCOPE810fb1e02000 alpine-net bridge local8d3b84bfe5a0 bridge bridge local3579d63da633 host host localf766b990db47 none null local 查看alpine-net网络详情注意网关和子网发生了变化。 1234567891011121314151617181920212223242526272829303132docker network inspect alpine-net[ &#123; &quot;Name&quot;: &quot;alpine-net&quot;, &quot;Id&quot;: &quot;810fb1e020008c7c6598f3b830ca25896dde638b1190d383ee6a5214d284e77d&quot;, &quot;Created&quot;: &quot;2018-06-14T15:45:19.43941906+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123;&#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 创建两种网络的容器 12345#alpine-netdocker run -dit --name alpine1 --network alpine-net alpine ash#default bridgedocker run -dit --name alpine2 alpine ash 显示两种网络情况 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596docker network inspect bridge[ &#123; &quot;Name&quot;: &quot;bridge&quot;, &quot;Id&quot;: &quot;8d3b84bfe5a034c65d043af80976a1e6127011fc1ab312446252f562e221d351&quot;, &quot;Created&quot;: &quot;2018-05-24T18:38:35.538308064+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.17.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;893903129d869f384bd78d63a382f1c9527d6979be0a6cf3c13ea4f45a1554d6&quot;: &#123; &quot;Name&quot;: &quot;hardcore_rosalind&quot;, &quot;EndpointID&quot;: &quot;515d1435470c9f72d3b07680515d9c503457b8eb5bcaaaa915bb53901eac9424&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.17.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125;, &quot;e7472c3ddda5043bc03868f4bf7ed59562220f05772f02f57ff589d086630562&quot;: &#123; &quot;Name&quot;: &quot;alpine2&quot;, &quot;EndpointID&quot;: &quot;ba565a247e347feb59713c188eb38e184d781da0489ae80e26ecad6d24e165c2&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:03&quot;, &quot;IPv4Address&quot;: &quot;172.17.0.3/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;, &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;, &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;]docker network inspect alpine-net[ &#123; &quot;Name&quot;: &quot;alpine-net&quot;, &quot;Id&quot;: &quot;810fb1e020008c7c6598f3b830ca25896dde638b1190d383ee6a5214d284e77d&quot;, &quot;Created&quot;: &quot;2018-06-14T15:45:19.43941906+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;264ccde8b1d5198551d689f0dd49ffbfb612255e0bf76c9543325d7c2e588acb&quot;: &#123; &quot;Name&quot;: &quot;alpine1&quot;, &quot;EndpointID&quot;: &quot;563c48cc6b936bcd9d3f57e9bb5e162a8cb52a23c8980346f288d42cc9b0a8fc&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 连接到容器 12345678910111213141516171819docker container attach alpine1#网段内通/ # ping -c 2 172.18.0.3PING 172.18.0.1 (172.18.0.3): 56 data bytes64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.097 ms64 bytes from 172.18.0.3: seq=1 ttl=64 time=0.070 ms--- 172.18.0.1 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.070/0.083/0.097 ms#网段外不通/ # ping -c 2 172.17.0.2PING 172.17.0.2 (172.16.0.1): 56 data bytes--- 172.17.0.2 ping statistics ---2 packets transmitted, 0 packets received, 100% packet loss 使容器连接到default bridge这样，此容器便连接到了两个网络中。 1234567docker network connect bridge apline1/ # ping -c 2 172.17.0.2PING 172.17.0.2 (172.17.0.2): 56 data bytes64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.102 ms64 bytes from 172.17.0.2: seq=1 ttl=64 time=0.071 ms host networkhost网络不存在隔离问题。 12345678910111213141516171819202122232425262728293031323334353637383940414243#默认主机上的80端口docker run -rm -dit --network host --name my_nginx nginx#访问http://localhost:80Welcome to nginx!docker network inspect host[ &#123; &quot;Name&quot;: &quot;host&quot;, &quot;Id&quot;: &quot;3579d63da633adcc497417d39b8b1d270cf329a68b9222f6a75fae72086509d6&quot;, &quot;Created&quot;: &quot;2018-04-27T11:31:17.900886126+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;host&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;f02a3b11fce7228ad6ee196771bd9cf0b64966bfc2aa7c27719bc120dbdc7189&quot;: &#123; &quot;Name&quot;: &quot;my_nginx&quot;, &quot;EndpointID&quot;: &quot;4ee67fb4d0a0c1a357b5fdd141f856a70c205fad5c49b1cb6a4f5245df0318a8&quot;, &quot;MacAddress&quot;: &quot;&quot;, &quot;IPv4Address&quot;: &quot;&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123;&#125; &#125;] overlay network default overlay network user-defined overlay network overlay network for standalone containers Communicate between a container and a swarm service default overlay依赖： swarm集群 集群节点 worker-1 worker-2 mananger 123456789docker network lsNETWORK ID NAME DRIVER SCOPE495c570066be bridge bridge local961c6cae9945 docker_gwbridge bridge localff35ceda3643 host host localtrtnl4tqnc3n ingress overlay swarmc8357deec9cb none null local 创建nginx-net的overlay的网络: 123456789docker network create -d overlay nginx-net$ docker service create \ --name my-nginx \ --publish target=80,published=80 \ --replicas=5 \ --network nginx-net \ nginx user-defined overlay123456789docker network create -d overlay my-overlay$ docker service create \ --name my-nginx \ --network my-overlay \ --replicas 1 \ --publish published=8080,target=80 \ nginx:latest overlay network for standalone containers Communicate between a container and a swarm service macvalan network假设主机网络接口为eth0。 bridge此模式下，流量通过eth0流动，docker使用其MAC地址就流量路由到容器。 创建名为my-macvlan-net的macvlan网络 12345$ docker network create -d macvlan \ --subnet=172.16.86.0/24 \ --gateway=172.16.86.1 \ -o parent=eth0 \ my-macvlan-net 查看网络 1234567docker network lsNETWORK ID NAME DRIVER SCOPE810fb1e02000 alpine-net bridge local8d3b84bfe5a0 bridge bridge local3579d63da633 host host local6be80655739d my-macvlan-net macvlan localf766b990db47 none null local 以此网络运行容器 12345$ docker run --rm -itd \ --network my-macvlan-net \ --name my-macvlan-alpine \ alpine:latest \ ash 查看my-macvlan-net 1234567891011121314151617181920212223242526272829303132333435363738394041docker network inspect my-macvlan-net[ &#123; &quot;Name&quot;: &quot;my-macvlan-net&quot;, &quot;Id&quot;: &quot;6be80655739deffe204e087d098f97fc75072d95f9818e129cfd7d5667ed01f3&quot;, &quot;Created&quot;: &quot;2018-06-14T16:52:30.507647877+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;macvlan&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.16.86.0/24&quot;, &quot;Gateway&quot;: &quot;172.16.86.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;8301b669b4b63afb20911b46243f11b70e5a9d0880beaafa922b52bcb8ab0477&quot;: &#123; &quot;Name&quot;: &quot;my-macvlan-alpine&quot;, &quot;EndpointID&quot;: &quot;4f2971ba4bd92c34e2a299d301f739867d2b1b65d35566aef07d7a26b079662c&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:10:56:02&quot;, &quot;IPv4Address&quot;: &quot;172.16.86.2/24&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;parent&quot;: &quot;ens160&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 查看容器网卡和路由 123456789docker exec my-macvlan-alpine ip addr show eth0517: eth0@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UNKNOWN link/ether 02:42:ac:10:56:02 brd ff:ff:ff:ff:ff:ff inet 172.16.86.2/24 brd 172.16.86.255 scope global eth0 valid_lft forever preferred_lft foreverdocker exec my-macvlan-alpine ip routedefault via 172.16.86.1 dev eth0172.16.86.0/24 dev eth0 scope link src 172.16.86.2 802.1q trunked bridge network此模式下，流量流经eth0的子接口(eth0.10)，docker使用其MAC地址将流量路由到容器。 创建名为my-8021q-macvlan-net的macvlan网络 12345docker network create -d macvlan \ --subnet=172.16.87.0/24 \ --gateway=172.16.87.1 \ -o parent=eth0.10 \ my-8021q-macvlan-net 查看此网络 123456789101112docker network lsNETWORK ID NAME DRIVER SCOPE2aeafd44fd67 my-8021q-macvlan-net macvlan local6be80655739d my-macvlan-net macvlan localifconfigeth0.10: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet6 fe80::20c:29ff:feaa:7e75 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:aa:7e:75 txqueuelen 0 (Ethernet) 用此网络启动一个容器 12345docker run --rm -itd \ --network my-8021q-macvlan-net \ --name my-second-macvlan-alpine \ alpine:latest \ ash 查看my-8021q-macvlan-net 1234567891011121314151617181920212223242526272829303132333435363738394041docker network inspect my-8021q-macvlan-net[ &#123; &quot;Name&quot;: &quot;my-8021q-macvlan-net&quot;, &quot;Id&quot;: &quot;2aeafd44fd67e6ee937c82788745b1d45fb291efd61f545537528eafdff94e3d&quot;, &quot;Created&quot;: &quot;2018-06-14T17:06:33.426800076+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;macvlan&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.16.87.0/24&quot;, &quot;Gateway&quot;: &quot;172.16.87.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;90103673d94915c3c7fb572eec8bd97b2aee1c3dab877c598d0a62e6d797b06d&quot;: &#123; &quot;Name&quot;: &quot;my-second-macvlan-alpine&quot;, &quot;EndpointID&quot;: &quot;5c93f2ea1d29150ee57f099d42fc8e04a571efd0d1273a4f6bed755dc34f2e54&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:10:57:02&quot;, &quot;IPv4Address&quot;: &quot;172.16.87.2/24&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;parent&quot;: &quot;ens160.10&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 查看容器网络接口 12345678910docker exec my-second-macvlan-alpine ip addr show eth0519: eth0@if518: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UNKNOWN link/ether 02:42:ac:10:57:02 brd ff:ff:ff:ff:ff:ff inet 172.16.87.2/24 brd 172.16.87.255 scope global eth0 valid_lft forever preferred_lft foreverdocker exec my-second-macvlan-alpine ip routedefault via 172.16.87.1 dev eth0172.16.87.0/24 dev eth0 scope link src 172.16.87.2 配置守护进程和容器启用IPv6启用IPv6前，请确保支持IPv6. 给docker daemon启用IPv6: 12345/etc/docker/daemon.json&#123; &quot;ipv6&quot;: true&#125; iptables所有Docker的iptables规则都被添加到DOKCER chain。不要手动操作此表。如果你需要添加Docker规则，请将其添加到DOCKER-USER chain 栗子： 1iptables -I DOCKER-USER -m iprange -i ext_if ! --src-range 192.168.1.1-192.168.1.3 -j DROP 容器网络容器使用的网络类型(无论是bridge，overlay，macvlan还是自定义网络)，在容器内都是透明的。从容器的角度来看，它有一个带有IP地址，网关，路由表，DNS服务和其它网络细节的网络接口。 publish port默认情况下，创建容器时，它不会将任何端口发布的外部世界。要是端口可用于docker之外的服务，请使用--publish或-p标志。 1234-p 8080:80-p 192.168.1.100:8080:80-p 8080:80/udp-p 8080:80/tcp -p 8080:80/udp ip add and hostname默认情况下，容器会为其连接的每个docker网络分配一个IP地址。IP地址是从分配给网络的地址池中分配的，因此docker daemon有效地充当了每个容器的DHCP服务器。每个网络也有一个默认的子网掩码和网关。同样，一个容器的主机名也有docker daemon指定。 12345678910111213141516#指定运行网络docker run xxx --network#运行的容器连接到其它网络docker network connect#--ip，指定IP地址docker network connect my-bridge --ip 172.18.0.111#--hostname，指定主机名docker run xxx --network xxx --hostname container-01docker network connect my-bridge --hostname container-02 DNS默认情况下，容器会继承docker daemon的DNS设置，包括/etc/hosts和/etc/resolv.conf。你也可以基于每个容器覆盖这些默认设置。 12345678910#DNS server--dns#DNS搜索域--dns-search#表示DNS选项值的键值对--dns-opt--hostname Docker使用代理服务器在启动docker容器的用户主目录下创建此文件： ~/.docker/config.json 12345678910&#123; &quot;proxies&quot;: &#123; &quot;default&quot;: &#123; &quot;httpProxy&quot;: &quot;http://127.0.0.1:3001&quot;, &quot;noProxy&quot;: &quot;*.test.example.com,.example2.com&quot; &#125; &#125;&#125; 应用程序数据Manage application data 存储综述Manage data in Docker 默认情况下，容器内创建的所有文件都被存储容器的可写层上： 当容器不在运行时，数据不是持续存在的。容器外的进程很难从容器中获取数据 容器的可写层与主机紧密耦合，你很难将数据移动到其他地方 向容器的可写入层写入数据，需要存储驱动(storage driver)管理文件系统才存储驱动使用Linux kernel来提供一个union filesystem。与直接写入主机文件系统的数据卷相比，这种额外的抽象会降低性能。 Docker容器有两种选项将文件存储到主机上，这样即使容器停止之后这些文件也会被保留: volumes bind mounts tmpfs mount(Docker on Linux) 选择正确的挂载方式Choose the right type of mount 无论你选用哪种挂载方式，数据在容器内看起来都是相同的。它被公开为容器文件系统中的目录或单个文件。 一个简单的方法——考虑数据在docker主机上的位置，可以看出volumes, bind mounts, temfs之间的差异： Volumesvolumes存储在由docker管理的主机文件系统的一部分中(如Linux上: /var/lib/docker/volumes/)。non-docker进程不应该修改这部分文件系统。Volume是Docker中保存数据的最佳方式。 Bind mountsbind mounts可存储在主机系统上的任何地方。它们可能是最要的系统文件或目录。docker主机或docker容器上的non-docker进程可以随时修改它们。 tmpfs仅存储在主机系统的内存中，不会写入主机系统的文件系统。 volumes的好栗子Good use cases for volumes Volemes是在docker容器和服务中持久化数据的首选方式: 在多个运行容器之间共享数据。如果你没有明确创建它，会在第一次挂载到容器时创建volume。当容器停止或删除时，volume仍然存在。多个容器可以挂载相同的volume，无论是read-write还是read-only。只有在你手动删除volume时它才会被删除。 当docker主机不能保证具有给定的目录或文件结构时，volume帮助你将docker主机的配置与运行时的容器进行分离。 当你想要将容器的数据存储在远程主机而不是本地的时候。 当你需要备份、还原或将数据从一台docker主机迁移到另一台时，volume时更好的选择。 bind mounts的好栗子一般来说，你应该尽量使用volumes。bind mounts适合以下案例： 从主机共享配置文件到容器这就是默认情况下，通过将主机的/etc/resolv.conf挂载到每个容器中，Docker为每个容器提供DNS解析。 在docker主机/容器的开发环境上共享源码或构建工件 当docker主机的文件或目录结构保证与容器所需的bind mounts一致时 tmpfs mounts的好栗子当你不希望数据在主机上或容器内持久存储时，tmpfs mounts最合适。这可能处于安全原因，或在应用于程序需要编写大量非持久性状态数据时保护容器的性能。 使用bind或volumes的提示如果你要使用bind mounts 或 volumes，牢记以下事项： 如果你挂载一个空卷(empty volume)到存在文件或目录的容器中的目录上，则会将这些文件或目录赋值到卷中。同样，如果你启动容器并制定了一个尚不存在的卷，则会为你创建一个空卷。 如果你挂载一个bind mount或non-empty volume到存在文件或目录的容器中的目录上，则这些文件或目录会被挂载所遮蔽。就像在Linux上挂载卷一样。 Volumesvolumes是持久化Docker数据的首选机制，卷由docker完全管理。另外，由于卷不会增加使用它的容器的大小，并且该卷的内容存在于给定容器的周期之外，因此卷通产是比将容器的可写入层中的数据持久化更好的选择。 1234567891011-v/--volume#此选项更详细和简单#如果你需要指定volume driver，请使用此flag--mountdocker service create \ --mount &apos;type=volume,src=&lt;VOLUME-NAME&gt;,dst=&lt;CONTAINER-PATH&gt;,volume-driver=local,volume-opt=type=nfs,volume-opt=device=&lt;nfs-server&gt;:&lt;nfs-path&gt;,&quot;volume-opt=o=addr=&lt;nfs-address&gt;,vers=4,soft,timeo=180,bg,tcp,rw&quot;&apos; --name myservice \ &lt;IMAGE&gt; --volume 由三个由冒号:分割的字段组成。这些字段必须按照正确的顺序排列，每个字段的含义并不明显。第一个字段是卷的名称，并且在给定主机上是唯一的。对于匿名卷，第一个字段被省略。第二个字段是文件或目录在容器中的挂载路径。第三个字段是可选的，是由一个逗号`,分隔的选项列表。 --mount 由多个键值对组成，以逗号,分隔。--mount的语法比--volume更冗长，但键的顺序并不重要，并且标志的值更易于理解。挂载的类型(type)有bind, volume, tmpfs。挂载的来源(source, src)为卷的名称，对于匿名卷该字段可被省略。目的地(destination, dst, target)的值是安装在容器中的文件或目录的路径。只读(readonly)选项将导致bind mount以只读方式挂载到容器中。volume-opt选项可以多次指定，它是由选项名称和值组成的键值对组成。 创建和管理卷1234567891011121314151617181920212223docker volume create my-voldocker volume lsDRIVER VOLUME NAMElocal my-voldocker volume inspect my-vol[ &#123; &quot;CreatedAt&quot;: &quot;2018-06-15T17:19:02+08:00&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: &#123;&#125;, &quot;Mountpoint&quot;: &quot;/opt/docker/volumes/my-vol/_data&quot;, &quot;Name&quot;: &quot;my-vol&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Scope&quot;: &quot;local&quot; &#125;]docker volume rm my-vol 启动用卷的容器Start a container with a volume 包括两种卷： 已存在的卷 未存在的卷会自动创建 123456789101112#--mountdocker run -d \ --name devtest \ --mount source=myvol2,target=/app \ nginx:latest#--volumedocker run -d \ --name devtest \ --volume myvol2:/app \ nginx:latest 1234567891011121314151617181920docker volume lsDRIVER VOLUME NAMElocal my-vollocal myvol2docker inspect devtest#找到挂载 &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;myvol2&quot;, &quot;Source&quot;: &quot;/opt/docker/volumes/myvol2/_data&quot;, &quot;Destination&quot;: &quot;/app&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;z&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; &#125; ] 启动用卷的服务Start a service with volumes docker服务不支持使用--volume标志，请使用--mount标志。 12345docker service create -d \ --replicas=4 \ --name devtest-service \ --mount source=myvol2,target=/app \ nginx:latest 在机器间共享数据Share data among machines 在构建容错应用程序时，可能需要配置同一服务的多个副本能访问相同的文件，而这些副本可能分布于不同的节点上。 卷驱动程序(volume driver)允许你从应用程序逻辑中抽象出底层存储系统。 使用卷驱动Use a volume driver 在创建卷或启动带卷的容器时，你可以指定卷驱动。如vieux/sshfs卷驱动程序。 初始化 1docker plugin install --grant-all-permissions vieux/sshfs 使用卷驱动创建卷 12345#操作node2docker volume create --driver vieux/sshfs \ -o sshcmd=test@node2:/home/test \ -o password=testpassword \ sshvolume 启动一个带用卷驱动程序创建的卷的容器 12345docker run -d \ --name sshfs-container \ --volume-driver vieux/sshfs \ --mount src=sshvolume,target=/app,volume-opt=sshcmd=test@node2:/home/test,volume-opt=password=testpassword \ nginx:latest 备份，还原或迁移数据卷 使用--volumes-from标志创建一个挂载该卷的新容器。 1234567#备份docker run --rm --volumes-from dbstore -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata#从备份还原docker run -v /dbdata --name dbstore2 ubuntu /bin/bashdocker run --rm --volumes-from dbstore2 -v $(pwd):/backup ubuntu bash -c &quot;cd /dbdata &amp;&amp; tar xvf /backup/backup.tar --strip 1&quot; bind mounts与volumes相比，bind mounts功能有限。当你使用bind mounts时，主机上的文件或目录(绝对路径或相对路径)被挂载到容器内。相比之下，当你使用volumes时，会在主机上的Docker存储目录中创建一个新目录，并且Docker会管理该目录的内容。该文件或目录不需要已经存在于Docker主机上。如果它尚未存在，它会根据需求创建。bind mounts非常高效，但是它们依赖于具有特定目录结构的主机文件系统。如果你正在开发新的Docker Application，请考虑使用volumes。你不能使用Docker CLI直接管理bind mounts。 你可以使用--volume或--mount(语法更详细)flag。具体区别参考volumes的介绍。 启动用bind mount的容器Start a container with a bind mount 1234567891011121314#--mountdocker run -d \ -it \ --name devtest \ --mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app \ nginx:latest#--volumedocker run -d \ -it \ --name devtest \ -v &quot;$(pwd)&quot;/target:/app \ nginx:latest 挂载到容器内非空目录如果挂载在容器内非空目录上，则该目录的已有内容将被隐藏。 1234567891011121314#--mountdocker run -d \ -it \ --name broken-container \ --mount type=bind,source=/tmp,target=/usr \ nginx:latest#--volumedocker run -d \ -it \ --name broken-container \ -v /tmp:/usr \ nginx:latest 只读bind mountUse a read-only bind mount 某些时候，容器可能只需要只读权限。 1234567891011121314#--mountdocker run -d \ -it \ --name devtest \ --mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app,readonly \ nginx:latest#--volumedocker run -d \ -it \ --name devtest \ -v &quot;$(pwd)&quot;/target:/app:ro \ nginx:latest bind propagation对于bind mounts和volumes，bind propagation(传播)默认为rprivate。它只能对Linux主机上的bind mounts进行配置。它是一个高级话题，许多用户并不需要配置它。 bind propagation(传播)是指在给定的bind-mounts或named volume中创建的挂载是否可以传播(propagation)到该挂载(mount)的副本(replicas)。考虑一个挂载点/mnt，挂载在/tmp上。传播设置控制/tmp/a上的挂载点是否也可用于/mnt/a。每个传播设置都有一个递归对应点。在递归的情况下，考虑/tmp/a也被挂载到/foo。传播设置控制是否存在/mnt/a和/tmp/a。 传播设置 描述 shared 原始mount的sub-mount会暴露给replica mounts，并且replica mounts的sub-mount同样传播给原始mount。也就是双向 slave 类似于shared，但仅限于单方向。 private 私有挂载 rshared 与shared相同，但传播也扩展到嵌套在任何原始或副本挂载点内的挂载点 rslave 与slave相同，但传播也扩展到嵌套在任何原始或副本挂载点内的挂载点 rprivate 默认值。与private相同，这意味着原始或副本挂载点内的任何位置的挂载点都不会沿任一方向传播 在设置bind propagation之前，主机文件系统需要已经支持bind propagatin: https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt 12345678910111213141516#--mountdocker run -d \ -it \ --name devtest \ --mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app \ --mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app2,readonly,bind-propagation=rslave \ nginx:latest#--volumedocker run -d \ -it \ --name devtest \ -v &quot;$(pwd)&quot;/target:/app \ -v &quot;$(pwd)&quot;/target:/app2:ro,rslave \ nginx:latest selinux label如果你使用selinux，你可以添加z或Z选项来修改挂载到容器内的主机文件或目录的selinux标签。这户影响主机本身的文件或目录，并可能导致Docker范围之外的后果。 zbind mount的内容在多个容器之间共享。 Zbind mount的内容是私有和非共享的。 123456#不支持--mountdocker run -d \ -it \ --name devtest \ -v &quot;$(pwd)&quot;/target:/app:z \ nginx:latest tmpfs mountstmpfs: https://docs.docker.com/storage/tmpfs/#limitations-of-tmpfs-mountstmpfs mounts只支持运行在Linux上的Docker。 Troubleshoottroubleshoot: https://docs.docker.com/storage/troubleshooting_volume_errors/ 将数据存储到容器内Store data within containers 关于存储驱动为了有效地使用存储驱动(storage driver)，了解Docker如何构建和存储镜像，以及容器如何使用镜像是很重要的。你可以使用这些信息作出明智的选择，以便找到应用程序数据持久化的最佳方式，并避免出现性能问题。 存储驱动允许你在容器的可写入层创建数据。在容器停止后，这些文件将不会被保留，并且读写速度都很低。 镜像和层Images and layers Docker镜像由一系列层(layer)构建而成。每个层代表镜像的Dockerfile中的指令，除最后一层外的每个层都是只读的。 考虑如下Dockerfile: 1234FROM ubuntu:15.04COPY . /appRUN make /appCMD python /app/app.py 此Dockerfile包含4个命令，每个命令创建一个层。当你创建一个新容器时，你在底层之上添加了一个新的可写入层——它通常被称为容器层(container layer)。对运行中的容器所做的所有更改(增删改文件)都会写入此可写容器层。 存储驱动处理有关这些层相互交互的详细信息。有几个不同的驱动程序，在不同的情况下具有相应的优点和缺点。 容器和层Container and layers 容器和镜像之间的主要区别是最高的可写入层。当容器删除时，可写入层也被删除。但底层镜像保持不变。 由于每个容器都有自己的可写入容器层，并且所有的更改都存储在此容器中，因此多个容器可以共享相同的基础镜像的访问权限，并拥有自己的数据状态。 Docker使用存储驱动来管理镜像层和可写入容器层的内容。每个存储驱动程序都已不同方式实现，但所有驱动程序都是用可堆叠(stackable)的镜像层和写入时复制(copy-on-write)策略。 容器大小Container size on disk 使用docker ps -s(--size)命令查看正在运行的容器的大小。有两个大小: size每个容器的可写入层的数据量(在磁盘上的) virtual size容器使用的只读镜像的数据量加上容器可写入层大小 写入时复制The copy-on-write (CoW) strategy 写入时复制是一种共享和复制文件以实现最高效率的策略。如果文件或目录存在于镜像的较低层中，而另外的层(包括可写入层)需要对其进行读取访问，则它只是用已有文件。第一次需要修改文件时，该文件将被复制到该层并进行修改。这最大限度减少了每个后续层的I/O和大小。 共享促进了较小的容器Sharing promotes smaller images 当你创建和拉取镜像时，它们通常存储于本机的/var/lib/docker下。每层都存储在主机存储区内的特定目录下/var/lib/docker/&lt;storage-driver&gt;/layers。 123456ls /var/lib/docker/aufs/layers1d6674ff835b10f76e354806e16b950f91a191d3b471236609ab13a930275e245dbb0cbe0148cf447b9464a358c1587be586058d9a4c9ce079320265e2bb94e7bef7199f2ed8e86fa4ada1309cfad3089e0542fec8894690529e4c04a7ca2d73ebf814eccfe98f2704660ca1d844e4348db3b5ccc637eb905d4818fbfb00a06a 复制使容器高效Copying makes containers efficient 容器不会更改的任何文件都不会被复制到此可写入层中。这意味着可写入层尽可能小。 当容器中存在的文件被修改时，存储驱动之赐你个写入时复制操作(CoW)。涉及的具体步骤取决于具体的存储驱动。 aufs, overlay, overlay2存储驱动 遵循的基本顺序: 通过镜像层搜索要更新的文件 对找到的文件的第一个副本执行copy_up操作，将文件复制到容器的可写入层 任何修改应用于此复制的文件，并且该容器不能看到存在于较低层中的文件的只读副本 选择存储驱动Select a storage driver 理想情况下，将很少的数据写入容器的可写入层，并且使用Docker volume写入数据。但某些工作负载要求你能够写入容器的可写入层，这就是存储驱动进来的地方。 存储驱动控制镜像和容器在Docker主机上的存储和管理方式。 考虑三个高层次因素： 如果你的Kernel支持多个存储驱动，在没有指定存储驱动的情况下，Docker会列出要使用拿个存储驱动程序的优先级列表 如果可能，将使用配置最少的存储驱动。如brrfs, zfs 否则，请尝试在最常见的情况下使用具有最佳整体性能和稳定性的存储驱动程序 overlay2是首选(Docker CE的默认选择)，其次是overlay。这些都不需要额外的配置。 devicemapper居次，但需要direc-lvm用于生产环境，因为loopback-lvm的性能很差。 你的选择会受限于Docker版本、操作系统和发行版 某些存储驱动要求你为文件系统使用特定格式 你的选择还取决于工作负载和所需的稳定级别 Linux发行版支持的存储驱动Docker CE Linux distribution Recommended storage drivers Docker CE on Ubuntu aufs, devicemapper, overlay2 (Ubuntu 14.04.4 or later, 16.04 or later), overlay, zfs, vfs Docker CE on Debian aufs, devicemapper, overlay2 (Debian Stretch), overlay, vfs Docker CE on CentOS devicemapper, vfs Docker CE on Fedora devicemapper, overlay2 (Fedora 26 or later, experimental), overlay (experimental), vfs 存储驱动支持的文件系统 Storage driver Supported backing filesystems overlay, overlay2 ext4, xfs aufs ext4, xfs devicemapper direct-lvm btrfs btrfs zfs zfs 查看存储驱动12345docker infoServer Version: 18.03.1-ceStorage Driver: overlay2 AUFS存储驱动AUFS is a union filesystem. aufs存储驱动用于管理Ubuntu上Docker的镜像和层。 我的发行版是Centos，此驱动针对Ubuntu。注意 使用aufs存储驱动配置Docker 判断kernel是否支持aufs 1grep aufs /proc/filesystems 查看Docker存储驱动 1docker info 配置存储驱动 1234vim /etc/docker/daemon.json#或--storage-driver aufs存储驱动如何工作AUFS是一个联合文件系统，这意味着它在单个Linux主机上对多个目录进行分层并将它们呈现为单个目录。这些目录在AUFS术语中称为分支，在Docker术语中称为层。统一过程被称为联合安装。 容器如何使用aufs进行读写读取文件 Btrfs存储驱动Use the BTRFS storage driver Device Mapper存储驱动Use the Device Mapper storage driver Device Mapper是基于kernel的框架，支持Linux上的许多高级卷管理技术。Docker的devicemapper存储驱动利用此框架的精简配置和快照功能进行镜像和容器管理。 对于支持它的系统，devicemapper支持包含在Linux内核中。但是，需要特定配置才能将其用于Docker。devicemapper驱动使用专用于Docker的块设备，并在块级(block level)而不是文件级(file level)运行。这些设备可通过在Docker主机添加物理设备来扩展，并且它们比咋子操作系统级别使用文件系统更好。 依赖 Docker EE Docker CE 更改存储驱动会使已创建的容器在本地系统上都无法访问 配置devicemapper存储驱动 loop-lvm 1234567891011#loop-lvm模式/etc/docker/daemon.json&#123; &quot;storage-driver&quot;: &quot;devicemapper&quot;&#125;#查看docker info direct-lvm生产环境的devicemapper存储驱动必须使用direct-lvm模式。此模式使用块设备创建精简池。这比使用loopback设备更快，更高效地使用系统资源，并且块设备可以根据需求进行扩展。 Option Description Required Default Example dm.directlvm_device The path to the block device to configure for direct-lvm. Yes - dm.directlvm_device=”/dev/xvdf” dm.thinp_percent The percentage of space to use for storage from the passed in block device. No 95 dm.thinp_percent=95 dm.thinp_metapercent The percentage of space to for metadata storage from the passed-in block device. No 1 dm.thinp_metapercent=1 dm.thinp_autoextend_threshold The threshold for when lvm should automatically extend the thin pool as a percentage of the total storage space. No 80 dm.thinp_autoextend_threshold=80 dm.thinp_autoextend_percent The percentage to increase the thin pool by when an autoextend is triggered. No 20 dm.thinp_autoextend_percent=20 dm.directlvm_device_force Whether to format the block device even if a filesystem already exists on it. If set to false and a filesystem is present, an error is logged and the filesystem is left intact. No false dm.directlvm_device_force=true 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#安装依赖RHEL / CentOS: device-mapper-persistent-data, lvm2, and all dependenciesUbuntu / Debian: thin-provisioning-tools, lvm2, and all dependencies#创建物理卷(physical volume)pvcreate /dev/cvdf#创建卷组(volume group)vgcreat docker /dev/xvdf#创建逻辑卷(logical volume)lvcreate --wipesignatures y -n thinpool docker -l 95%VGlvcreate --wipesignatures y -n thinpoolmeta docker -l 1%VG#转换卷为精简池lvconvert -y \--zero n \-c 512K \--thinpool docker/thinpool \--poolmetadata docker/thinpoolmeta#配置lvm配置文件精简池自动扩展/etc/lvm/profile/docker-thinpool.profile#指定thin_pool_autoextend_threshold 和 thin_pool_autoextend_percent的值activation &#123; thin_pool_autoextend_threshold=80 thin_pool_autoextend_percent=20&#125;#应用LVM profilelvchange --metadataprofile docker-thinpool docker/thinpool#启用监控LVlvs -o+seg_monitor#配置devicemapper存储驱动/etc/docker/daemon.json&#123; &quot;storage-driver&quot;: &quot;devicemapper&quot;, &quot;storage-opts&quot;: [ &quot;dm.thinpooldev=/dev/mapper/docker-thinpool&quot;, &quot;dm.use_deferred_removal=true&quot;, &quot;dm.use_deferred_deletion=true&quot; ]&#125;#查看docker info 管理devicemapper1234567#查看LVM logsjournalctl -fu dm-event.servicepvdisplayvgdisplay/vgextendlvdisplay/lvextend/lvchange OverlayFS存储驱动Use the OverlayFS storage driver ZFS存储驱动Use the ZFS storage driver VFS存储驱动Use the VFS storage driver VFS存储驱动不是联合文件系统，相反，每层都是磁盘上的一个目录，它不支持CoW。要创建一个新层，先前的层会进行深层复制(deep copy)。与其它驱动相比，这导致磁盘性能下降和占用更多磁盘空间。但是，它强大，稳定，适用于各种环境。 配置VFS存储驱动 1234567891011121314151617vim /etc/docker/daemon.json&#123; &quot;storage-driver&quot;: &quot;vfs&quot;&#125;#控制大小&#123; &quot;storage-opts&quot;: [&quot;size=256M&quot;]&#125;#查看docker info 在生产环境运行应用程序Run your app in production 配置对象Configure all objects 自定义原数据Apply custom metadata to objects Docker object label标签(label)是一种将原数据(metadata)应用于docker object的机制，包含: image container local daemon volume network node service label key and value标签是一组键值对，以字符串形式存储。可以为对象指定多个标签，但每个键值对必须唯一。如果一个键有多个值，则最新写入的值会覆盖以前的值。 key格式建议label key是可能包含字母，数字，.，-组成的字符串。 第三方工具的作者给每个label key加上前缀域，如com.example.some-label 未经允许，不得使用他人域 com.docker.*, io.docker.*, org.dockerproject.*命名空间保留给Docker内部使用 以小写字母开头和结尾 用.分割命令空间字段 value 指南label value可以包含任何可表示为字符串的数据类型，包括JSON, XML, CSV, YAML…唯一的要求是，首先使用特定于结构类型的机制将该值序列化为字符串。 清理未使用的对象Prune unused Docker objects Docker采取保守的方法来清理未使用的对象(通常称为垃圾回收)，通常它不会删除这些对象，除非你明确要求Docker这样做。对于每个类型的对象，docker提供了prune命令。你也可以使用docker system prune命令一次清理多种类型的对象。 1234567891011121314151617#prune imagedocker image prune docker image prune -a --filter &quot;until=24h&quot;#prune containerdocker container prune#prune volumedocker volume prunedocker volume prune --filter &quot;label!=keep&quot;#prune everythingdocker system prunedocker system prune --volumes 格式化输出Format command and log output 1234567891011121314151617181920212223242526#joindocker inspect --format &apos;&#123;&#123;join .Args &quot; , &quot;&#125;&#125;&apos; container#jsondocker inspect --format &apos;&#123;&#123;json .Mounts&#125;&#125;&apos; container#lowerdocker inspect --format &quot;&#123;&#123;lower .Name&#125;&#125;&quot; container#splitdocker inspect --format &apos;&#123;&#123;split .Image &quot;:&quot;&#125;&#125;&apos;#titledocker inspect --format &quot;&#123;&#123;title .Name&#125;&#125;&quot; container#upperdocker inspect --format &quot;&#123;&#123;upper .Name&#125;&#125;&quot; container#printIndocker inspect --format=&apos;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;println .IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&apos; container 配置daemonConfigure the daemon 配置和运行Docker配置docker daemon 使用json配置文件 使用dockerd --flag 1234567891011121314151617/etc/docker/daemon.json&#123; &quot;debug&quot;: true, &quot;tls&quot;: true, &quot;tlscert&quot;: &quot;/var/docker/server.pem&quot;, &quot;tlskey&quot;: &quot;/var/docker/serverkey.pem&quot;, &quot;hosts&quot;: [&quot;tcp://192.168.59.3:2376&quot;]&#125;#或dockerd --debug \ --tls=true \ --tlscert=/var/docker/server.pem \ --tlskey=/var/docker/serverkey.pem \ --host tcp://192.168.59.3:2376 docker daemon目录docker daemon将所有数据保存在一个目录中。你可以手动修改它。 默认目录: Linux： /var/lib/docker Windows: C:\ProgramData\docker 使用systemd控制dockerControl Docker with systemd 123456cat /usr/lib/systemd/system/docker.service#orcat /etc/systemd/system/docker.servicesystemctl enable/start/stop/status docker 自定义docker daemon选项 123456vim /etc/docker/daemon.json&#123; &quot;data-root&quot;: &quot;/mnt/docker-data&quot;, &quot;storage-driver&quot;: &quot;overlay&quot;&#125; http/https proxyDocker daemon使用HTTP_PROXY，HTTPS_PROXY和NO_PROXY环境变量来配置代理行为。无法使用daemon.json文件来配置环境变量。 123456789101112131415mkdir -p /etc/systemd/system/docker.service.d#/etc/systemd/system/docker.service.d/http-proxy.conf[Service]Environment=&quot;HTTP_PROXY=http://proxy.example.com:80/&quot;#/etc/systemd/system/docker.service.d/https-proxy.conf[Service]Environment=&quot;HTTPS_PROXY=https://proxy.example.com:443/&quot;systemctl daemon-reloadsystemctl restart dockersystemctl show --property=Environment docker 收集Docker指标Collect Docker metrics with Prometheus Promethus: https://prometheus.io/Prometheus是一个开源的系统监控和报警工具包。你可以将Docker配置为Prometheus target。设置Prometheus作为Docker容器运行，并使用Prometheus监控Docker实例。 配置Docker配置docker daemon作为Prometheus target，你需要指定metrics-address。最佳方式是通过daemon.json。 1234&#123; &quot;metrics-addr&quot; : &quot;127.0.0.1:9323&quot;, &quot;experimental&quot; : true&#125; 配置和运行Prometheus 12345678910111213141516171819202122232425262728293031323334353637/tmp/prometheus.yml# my global configglobal: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Attach these labels to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: monitor: &apos;codelab-monitor&apos;# Load rules once and periodically evaluate them according to the global &apos;evaluation_interval&apos;.rule_files: # - &quot;first.rules&quot; # - &quot;second.rules&quot;# A scrape configuration containing exactly one endpoint to scrape:# Here it&apos;s Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: &apos;prometheus&apos; # metrics_path defaults to &apos;/metrics&apos; # scheme defaults to &apos;http&apos;. static_configs: - targets: [&apos;localhost:9090&apos;] - job_name: &apos;docker&apos; # metrics_path defaults to &apos;/metrics&apos; # scheme defaults to &apos;http&apos;. static_configs: - targets: [&apos;localhost:9323&apos;] 1234docker service create --replicas 1 --name my-prometheus \ --mount type=bind,source=/tmp/prometheus.yml,destination=/etc/prometheus/prometheus.yml \ --publish published=9090,target=9090,protocol=tcp \ prom/prometheus 访问: http://localhost:9090/targets/ 配置容器Configure containers 自动启动容器Start containers automatically Docker提供了重启策略，以控制容器在退出或重启时自动启动。重启策略可确保链接的容器以正确的书序启动。Docker建议你使用重启策略，并避免使用进程管理器(如supervisor)来启动容器。重启策略与docker xxx --live-restart标志不同，后者可以让你在Docker upgrage期间保持容器运行。 重启策略使用docker run xxx --restart标志来配置重启策略，--restart的值如下： 标志 描述 no 不要自动重启容器(默认值) on-failure 如果容器由于错误(非零退出码)退出，则重启容器 unless-stopped 除非明确停止或docker本身停止或重启，则重启容器 always 如果停止，则始终重启容器 12#栗子docker run -dit --restart unless-stopped redis 重启策略注意事项 重启策略尽在容器成功启动后才生效——这意味着容器已启动至少10s，并且Docker已开始监视它。这可以防止根本不启动的容器进入重启循环。 如果你手动停止容器(状态码为0)，则在重启Docker daemon或手动启动容器之前，其重启策略将会被忽略。这是另一个防止重启循环的尝试。 重启策略仅适用于容器。集群服务的重启策略与此不同。 在daemon停机期间保持容器活着Keep containers alive during daemon downtime 默认情况下，当Docker daemon终止时，它会关闭正在运行的容器。从Docker Engine 1.12开始，你可配置守护进程，以便在守护进程不可用时容器保持运行。这个功能被称为实时恢复(live restore)。它不支持Windows container。 实时恢复有两种方式来启用live restore，只启用其中一个就好。实时恢复仅适用于独立容器，不适用于集群服务。 修改配置文件 12345/etc/docker/daemon.json&#123; &quot;live-restore&quot;: true&#125; --live-restore标志不推荐 1dockerd xxx --live-restore 在一个容器中运行多个服务Run multiple services in a container 容器的主要运行进程是Dockerfile末尾的ENTRYPOINT或CMD指令。通常建议你通过每个容器运行一项服务来分割关注区域。这些服务可能会分成多个进程(如Nginx的worker processe)。你可以使用用户定义的network和shared volumes来连接多个容器。 容器的主进程负责管理它启动的所有进程。在某些情况下，主进程设计不好，在容器退出时无法正常处理停止子进程。如果你的进程属于这个类别，你可在容器运行时使用--init选型。--init标志将一个微小的inti-process作为主进程插入到容器中，并在容器退出时处理所有进程的停止。以这种方式处理这些进程优于使用完整的初始化进程。 如果你需要在一个容器中运行多个服务，则可通过几种不同方式来完成此操作。 将所有命令封装进一个脚本中，并附带测试和调试信息。以封装脚本作为你的CMD 1234567891011121314vim my_wrapper.sh#!/bin/bashxxxxxxxxvim DockerfileFROM ubuntu:latestCOPY my_first_process my_first_processCOPY my_second_process my_second_processCOPY my_wrapper_script.sh my_wrapper_script.shCMD ./my_wrapper_script.sh 使用如supervisord这样的进程管理器 1234567FROM ubuntu:latestRUN apt-get update &amp;&amp; apt-get install -y supervisorRUN mkdir -p /var/log/supervisorCOPY supervisord.conf /etc/supervisor/conf.d/supervisord.confCOPY my_first_process my_first_processCOPY my_second_process my_second_processCMD [&quot;/usr/bin/supervisord&quot;] 容器运行指标Container runtime metrics docker stats 12345docker stats redis1 redis2CONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/Oredis1 0.07% 796 KB / 64 MB 1.21% 788 B / 648 B 3.568 MB / 512 KBredis2 0.07% 2.746 MB / 64 MB 4.29% 1.266 KB / 648 B 12.4 MB / 0 B Control groups Linux Container依赖于control group，这些组不仅跟踪进程组，还公开有关CPU，mem，block I/O的使用情况和度量标准。你可以访问这些指标并判断容器运行状况。control group通过为文件系统(pseudo-fs)公开，你应该可在/proc/fs/cgroup中找到它。 查看cgroup子系统： 1234567891011121314151617181920212223grep cgroup /proc/mounts#ormount -l | grep cgroup#进程/proc/&lt;pid&gt;/cgroup#/表示进程尚未分配给groupcat /proc/1/cgroup11:devices:/10:cpuset:/9:hugetlb:/8:memory:/7:blkio:/6:net_prio,net_cls:/5:pids:/4:perf_event:/3:cpuacct,cpu:/2:freezer:/1:name=systemd:/ 查找给定容器的cgroup对于每个容器，每个层次结构中创建一个cgroup。 123456789101112131415161718192021222324252627282930313233343536373839/sys/fs/cgroup/memory/docker/&lt;docker-longid&gt;/cd /sys/fs/cgroup/memory/docker/893903129d869f384bd78d63a382f1c9527d6979be0a6cf3c13ea4f45a1554d6cat memory.statcache 36282368rss 196608rss_huge 0mapped_file 1077248swap 0pgpgin 212904pgpgout 205531pgfault 314692pgmajfault 204inactive_anon 131072active_anon 65536inactive_file 18223104active_file 18059264unevictable 0hierarchical_memory_limit 9223372036854771712hierarchical_memsw_limit 9223372036854771712total_cache 36282368total_rss 196608total_rss_huge 0total_mapped_file 1077248total_swap 0total_pgpgin 212904total_pgpgout 205531total_pgfault 314692total_pgmajfault 204total_inactive_anon 131072total_active_anon 65536total_inactive_file 18223104total_active_file 18059264total_unevictable 0#其它信息类似 限制容器的资源Limit a container’s resources 默认情况下，容器没有资源限制，可以使用主机内核调度程序允许给定的资源。Docker提供了一些方法来控制容器可以使用的CPU、memory、block I/O。 许多这些功能需要内核的支持。使用docker info命令检查是否支持。如果内核禁用了某功能，则可能会有如下警告: WARNING: No swap limit support memory你需要了解内存耗尽(out of memory)的风险不要让正在运行的容器消耗太多的主机内存，这很重要。在Linux主机上，如果内核检测到没有足够的内存来执行重要的系统功能，它会抛出一个OOME(out of memory exception)，并开始killing process以释放进程。任何进程都会是killing objects，包括Docker和其它重要应用程序。 docker尝试通过调整docker daemon的OOM优先级来降低这些风险，从而使其比系统上的其它进程更小(less)可能的被killing。容器的OOM优先级不进行调整，这使得单个容器被killing的可能性要大于docker或其它进程。你不应该给docker daemon的--oom-score-adj或container的--oom-kill-disable标志来绕过这些安全措施。 你可以通过以下方式减轻由OOM引起的系统不稳定的风险: 在上线之前，进行测试以了解应用程序的内存需求 确保应用程序仅在拥有足够资源的主机上运行 限制容器可使用的内存量 在主机上配置swap时请注意。swap比内存更慢，性能更低，但可以提供缓冲区以防系统内存耗尽 考虑将容器转换为服务，并使用服务级别约束和节点标签来确保应用程序仅在具有足够内存的主机上运行 限制容器对内存的Limit a container’s access to memory Docker可以强制hard limit，允许容器使用不超过给定数量的用户/系统内存，或soft limit。这允许容器使用尽可能多的内存。 如下这些选项具有这样一些效果，注意内存单位b, k, m, g： 选项 描述 -m/--memory= 容器可使用的最大内存量。如果你设置此选项，则允许的最小值为4m --memory-swap 容器允许使用的swap量。只有在--momery设置时才有意义 --memory-swappiness 默认情况下，容器可使用的主机内核可交换的匿名页面的百分比 --memory-reservation 允许你指定一个小于--memory的soft limit。当docker检测到内存不足时，此会被激活 --kernel-memory 容器可以使用的最大kernel memory。内核内存不能够被swap out，因此内核内存不足的容器可能会阻塞主机资源，这会对主机和其它容器产生副作用 --oom-kill-disable 默认情况下，如果发生内存溢出(OOM)，内核会杀死容器中的进程。使用此选项改变此行为 cpu默认情况下，每个容器对主机CPU周期的访问是无限制的。你可以设置各种约束来限制给定容器访问主机的CPU周期。 CFS schedulerCFS是用于普通Linux进程的Linux kernel CPU调度器，一些运行时标志用于配置容器的CPU资源访问量。 选项 描述 --cpu=&lt;value&gt; 指定容器可以使用的CPU资源，如--cpu=&quot;1.6&quot; --cpu-period=&lt;value&gt; 指定CFS调度器周期，它与--cpu-quota一起使用。默认100ms。Docker1.13以后，使用--cpus替代 --cpu-quota=&lt;value&gt; 在容器上条件CFS配额。在Docker1.13以后，使用--cpus替代 --cpuset-cpus 限制容器可以使用的特定CPU或CORE。如果有多个CPU，请使用逗号,分割。如0,2 --cpu-shares 将此标志设置为大于/小于1024(默认值)的值，以增加或减少容器的重量，并使其能够访问更大或更小比例的主机CPU周期。这仅在CPU周期受到限制时才会执行。 如果你只有1 CPU，如下命令可保证容器每秒最多有50%的CPU——docker run -it --cpus=&quot;.5&quot; xxx realtime scheduler 在Docker1.13及更高版本，对于无法使用CFS的任务，你可以使用realtime scheduler。在你配置docker daemon和container之前，请正确地配置主机内核。 注意： CPU调度和优先级是高级内核功能。大多数用户不需要修改它。错误地设置将导致主机系统不稳定或不可用。 配置主机内核通过运行zcat /proc/config.gz | grep CONFIG_RT_GROUP_SCHED或检查/sys/fs/cgroup/cpu.rt_runtime_us来验证内核是否启用了CONFIG_RT_GROUP_SCHED。有关配置内核实时调度器的指导，请参考相关文档。 配置docker daemon运行docker daemon时使用--cpu-rt-runtime标志设置每个运行时间段的实时任务保留的最大微秒数。可使用systemd的docker.service进行配置。 配置独立容器当使用docker run启动容器时，可以传递多个标志来控制容器CPU的优先级。 选项 描述 --cap-add=sys_nice 授予容器CAP_SYS_NICE功能，允许容器提升进程的nice值，设置实时调度策略，设置CPU关联和其它操作 --cpu-rt-runtime=&lt;value&gt; Docker实时调度器期间，容器可以以实时优先级运行的最大微秒数。需要--cap-add=sys_nice标志 --ulimit rtprio=&lt;value&gt; 容器允许的最大实时优先级，需要--cap-add=sys_nice标志 栗子： 1234docker run --it --cpu-rt-runtime=950000 \ --ulimit rtprio=99 \ --cap-add=sys_nice \ debian:jessie Logging查看容器日志记录的信息和日志格式取决于容器的端点命令。docker logs命令显示正在运行的容器记录的信息。docker service logs命令显示参与服务的所有容器记录的信息。在swarm模式下。 在某些情况下，docker logs可能不会显示有用的信息，除非你采取其它措施。 如果将日志发送到文件、主机、数据库或其它日志驱动程序，则docker logs可能不会显示有用的信息 如果你的镜像运行non-interactive进程(如数据库)，则该应用程序可能会将output发送到日志文件而不是stdout/stderr 配置日志驱动Configure logging drivers docker提供了多种日志记录机制(logging mechanisms)来帮助你从运行的容器和服务中获取信息。这些机制被称为日志驱动(logging driver)。每个docker daemon都有一个默认日志驱动，每个容器也默认使用该驱动。除非你给容器配置了其它日志驱动。除了使用docker附带日志驱动，在Docker v17.05之后，你还可以使用日志驱动插件(logging driver plugin)。 配置默认日志驱动默认的日志驱动是json-flie。可在daemon.json文件里通过log-driver选项匹配置日志驱动。 123456/etc/docker/daemon.json#设置为syslog&#123; &quot;log-driver&quot;: &quot;syslog&quot;&#125; 如果日志驱动存在可配置选项： 1234567891011121314/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;labels&quot;: &quot;production_status&quot;, &quot;env&quot;: &quot;os,customer&quot; &#125;&#125;#查看docker info | grep &apos;Loggin Driver&apos;Logging Driver: json-file 为容器配置日志驱动启动容器时，可使用--log-driver标志为其配置不同于docker daemon的日志驱动。 12345docker run -it --log-driver none alpine ash#查看容器日志驱动docker inspect -f &apos;&#123;&#123;.HostConfig.LogConfig.Type&#125;&#125;&apos; &lt;CONTAINER&gt; 配置从容器到日志驱动的log message的交付模式Docker为从容器到日志驱动的日志消息提供了两种交付(delivery）模式： 直接阻塞(blocking)从容器到驱动的交付(默认) 非阻塞交付(non-blocking)，将日志消息存储在中间每个容器的环形缓冲区中供驱动使用非阻塞消息交付模式可防止应用程序因日志反压而被阻塞。当STDERR或STDOUT流阻塞时，应用程序可能会以意想不到的方式失败。 注意：当缓冲区已满且新消息排入队列时，内存中最早的消息将被丢弃。丢弃消息通常首选阻止应用程序的日志写入过程。 1docker run -it --log-opt mode=non-blocking --log-opt max-buffer-size=4m alpine ping 127.0.0.1 日志驱动使用环境变量或label一些日志驱动将容器的--env/-e或--label标签的值添加到容器的日志中。 1docker run -dit --label production_status=testing -e os=ubuntu alpine sh 支持的日志驱动如下是受支持的日志驱动。 驱动 描述 none No logs are available for the container and docker logs does not return any output. json-file The logs are formatted as JSON. The default logging driver for Docker. syslog Writes logging messages to the syslog facility. The syslog daemon must be running on the host machine. journald Writes log messages to journald. The journald daemon must be running on the host machine. gelf Writes log messages to a Graylog Extended Log Format (GELF) endpoint such as Graylog or Logstash. fluentd Writes log messages to fluentd (forward input). The fluentd daemon must be running on the host machine. splunk Writes log messages to splunk using the HTTP Event Collector. logentries Writes log messages to Rapid7 Logentries. 云日志系统 各类云服务商提供的云日志系统 docker logs命令不适用于除json-file和journald之外的其它日志驱动。 日志驱动插件日志驱动插件允许你扩展和定制docker的日志记录功能，超越了内置的日志驱动的功能。 安装日志驱动插件 123docker plugin install &lt;org/image&gt;docker plugin ls 将插件配置为docker daemon默认日志驱动 12345/etc/docker/daemon.josn#or--loggin-driver 将插件配置为容器日志驱动 1docker run xxx --log-driver 定制日志驱动输出Customize log driver output 日志选项tag指定如何格式化表示容器日志消息。默认情况下，系统使用容器ID的前12个字符。你可以指定tag选项来覆盖此行为： 123docker run --log-driver=fluentd \ --log-opt fluentd-address=myhost.local:24224 \ --log-opt tag="mailer" 在指定tag时，Docker支持的一些特殊模板标记： 1234567891011121314151617181920212223242526&#123;&#123;.ID&#125;&#125;The first 12 characters of the container ID&#123;&#123;.FullID&#125;&#125;The full container ID&#123;&#123;.Name&#125;&#125;The container name&#123;&#123;.ImageID&#125;&#125;The first 12 characters of the container’s image ID&#123;&#123;.ImageFullID&#125;&#125;The container’s full image ID&#123;&#123;.ImageName&#125;&#125;The name of the image used by the container&#123;&#123;.DaemonName&#125;&#125;The name of the docker program (docker) 123--log-opt tag=&quot;&#123;&#123;.ImageName&#125;&#125;/&#123;&#123;.Name&#125;&#125;/&#123;&#123;.ID&#125;&#125;&quot;Aug 7 18:33:19 HOSTNAME hello-world/foobar/5790672ab6a0[9103]: Hello from Docker. 日志驱动介绍如下日志驱动！ LogentriesLogentries日志驱动将容器日志发送到Logentries server。 --log-opt: logentries-token: 指定Logentries log设置的token line-only: 仅发送原始有效载荷 docker daemon: 123dockerd --log-driver=logentries#可在docker.service中设置 docker container: 1docker run --log-driver=logentries ... 在使用此日志驱动之前，你需要在Logentries web界面中创建一个新的日志集，并将该日志集的令牌传递给docker： 1docker run --log-driver=logentries --log-opt logentries-token=abcd1234-12ab-34cd-5678-0123456789ab json file默认情况下，docker捕获所有容器的STDOUT和STDERR，并使用json格式将它们写入文件。每个文件包含仅包含一个容器的信息。 123456789101112131415161718/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;10m&quot; &#125;&#125;#ordocker run \ --log-driver json-file --log-opt max-size=10m \ alpine echo hello world#栗子docker run -it --log-opt max-size=10m --log-opt max-file=3 alpine ash json-file支持的日志选项： 选项 描述 栗子 max-size The maximum size of the log before it is rolled. A positive integer plus a modifier representing the unit of measure (k, m, or g). Defaults to -1 (unlimited). –log-opt max-size=10m max-file The maximum number of log files that can be present. If rolling the logs creates excess files, the oldest file is removed. Only effective when max-size is also set. A positive integer. Defaults to 1. –log-opt max-file=3 labels Applies when starting the Docker daemon. A comma-separated list of logging-related labels this daemon accepts. Used for advanced log tag options. –log-opt labels=production_status,geo env Applies when starting the Docker daemon. A comma-separated list of logging-related environment variables this daemon accepts. Used for advanced log tag options. –log-opt env=os,customer env-regex Similar to and compatible with env. A regular expression to match logging-related environment variables. Used for advanced log tag options. –log-opt env-regex=^(os或customer). Graylog Extended Format(gelf)gelf日志驱动是一种方便的格式，可被Graylog, Logstash, Fluentd等工具所理解。许多工具使用这种格式。 在GELF中，每条日志消息都是带有一下字段的字典： version host timestamp short and long version of the message 自定义的字段 12345678910111213141516171819/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;gelf&quot;, &quot;log-opts&quot;: &#123; &quot;gelf-address&quot;: &quot;udp://1.2.3.4:12201&quot; &#125;&#125;#ordockerd --log-driver gelf –-log-opt gelf-address=udp://1.2.3.4:12201#容器docker run \ --log-driver gelf –-log-opt gelf-address=udp://1.2.3.4:12201 \ alpine echo hello world GELF选项： Option Required Description Example gelf-address required GELF服务器地址(tcp/udp) --log-opt gelf-address=udp://192.168.0.42:12201 gelf-compression-type optional 仅限于UDP。类型有gzip(default),zlib,none --log-opt gelf-compression-type=gzip gelf-compression-level optional -1/0 - 9,-1/0(禁用压缩)，1(BestSpeed)，9(BestCompress) --log-opt gelf-compression-level=2 gelf-tcp-max-reconnect optional 仅TCP，连接断开尝试的最大重连次数，默认3 --log-opt gelf-tcp-max-reconnect=3 gelf-tcp-reconnect-delay optinal 仅TCP，重连等待的秒数，默认1s --log-opt gelf-tcp-reconnect-delay=1 tag optional 默认使用Docker容器ID的前12位 --log-opt tag=mailer labels optional 以逗号分隔的日志相关标签 --log-opt labels=production_status,geo env optional 以逗号分隔的日志相关的环境变量 --log-opt env=os,customer evn-regex optional 匹配日志相关环境变量的正则表达式 --log-opt env-regex=^(os l customer) Syslogsyslog日志驱动将日志路由到系统日志服务器。系统日志必须以特定方式格式化才能生效。从有效的消息中，接收者可以提取以下消息： priority日志级别，debug, info, warning, error… timestamp hostname facility记录消息的子系统 process name pid 12345678910111213141516/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;syslog&quot;, &quot;log-opts&quot;: &#123; &quot;syslog-address&quot;: &quot;udp://1.2.3.4:1111&quot; &#125;&#125;#or#syslog-address支持tcp和udpdocker run \ -–log-driver syslog –-log-opt syslog-address=udp://1.2.3.4:1111 \ alpine echo hello world syslog日志驱动选项： 选项 描述 栗子 syslog-address [tcp l udp l tcp+tls]:host:port, unixgram://path, unix://path --log-opt syslog-address=tcp+tls://192.168.1.3:514, --log-opt syslog-address=unix:///tmp/syslog.sock syslog-facility 子系统 --log-opt syslog-facility=daemon syslog-tls-ca-cert CA --log-opt syslog-tls-ca-cert=/etc/ca-certificates/custom/ca.pem syslog-tls-cert TLS certificate --log-opt syslog-tls-key=/etc/ca-certificates/custom/key.pem syslog-tls-skip-verify 跳过tls验证 --log-opt syslog-tls-skip-verify=true tag 如前 如前 syslog-format 日志格式 --log-opt syslog-format=rfc5424micro lables 如前 如前 env 如前 如前 env-regex 如前 如前 ETWETW日志驱动将容器日志转发为ETW事件。每个ETW时间都包含一条日志及其上下文信息的消息，然后客户端可以创建一个ETW监听器来监听这些事件。 Fluentdfluentd日志驱动将容器日志作为结构化日志数据发送到fluentd收集器。接着，用户便可以使用任意一种Fluentd output plugin将这些日志写入不同的目的地。 fluentd发送一下这些元数据： 字段 描述 container_id 完整的64位容器ID container_ame 启动时的容器名 source stdout or stderr log 容器日志 docker logs命令不可用于此日志驱动。 fluentd-address指定fluentd daemon地址 tag 1234567891011121314/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;fluentd&quot;, &quot;log-opts&quot;: &#123; &quot;fluentd-address&quot;: &quot;fluentdhost:24224&quot; &#125;&#125;#ordocker run --log-driver=fluentd --log-opt fluentd-address=fluentdhost:24224docker run --log-driver=fluentd --log-opt fluentd-address=tcp://fluentdhost:24224docker run --log-driver=fluentd --log-opt fluentd-address=unix:///path/to/fluentd.sock Journaldjournald 日志驱动将容器日志发送给 systemd journal。可以通过journalctl命令，journal API，docker logs来检索日志条目。 journald日志驱动还提供如下元数据： CONTAINER_ID CONTAINER_ID_FULL CONTAINER_NAME CONTAINER_TAG CONTAINER_PARTIAL_MESSAGE 123456789/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;journald&quot;&#125;#ordocker run --log-driver=journald ... 几个选项： tag label env env-regex 123456docker run --log-driver=journald \ --log-opt labels=location \ --log-opt env=TEST \ --env &quot;TEST=false&quot; \ --label location=west \ your/application 使用journalctl命令查看日志： 12journalctl CONTAINER_NAME=webserverjournalctl -o json CONTAINER_NAME=webserver 使用journal API： 123456789#pythonimport systemd.journalreader = systemd.journal.Reader()reader.add_match('CONTAINER_NAME=web')for msg in reader: print '&#123;CONTAINER_ID_FULL&#125;: &#123;MESSAGE&#125;'.format(**msg) Splunksplunk日志驱动将容器日志发送到Splunk Enterprise和Splunk Clound的HTTP Event Collector。 安全]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《网站运维》读书笔记]]></title>
    <url>%2F2018%2F03%2F05%2F%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4%2F</url>
    <content type="text"><![CDATA[参考： 《网站运维：保持数据实时的秘籍》(Web Operations: Keeping the Data on Time) 作为职业的运维互联网变化如此之快，以至于几乎没有时间认真思考一下我们在做什么，以及为什么做。我们奋力拼搏，才避免被淘汰出局，哪里还敢谈论什么引领潮流呢！这种高压、过度刺激的环境使得所有努力都只是为了一份工作，而没有职业的概念了。 职业是指占去你人生大部分时光的事业，并能够逐步晋升。工作只是拿钱干活儿，换句话说，工作就只是工作而已。 为什么运维如此艰难运维对如下领域都有深入的理解：网络、路由、交换、防火墙、负载均衡、高可用性、灾难恢复、TCP与UDP服务、网络运维中心管理、硬件规范、各种Unix、各种Web服务器技术、高速缓存技术、数据库技术、存储基础架构、密码学、算法、趋势分析、容量规划… 运维要求广博，可以说几乎是不可接受的。 运维领域成为一个合格的人选，需要具备三点素质：扎实的计算背景、娴熟的决断力、沉稳的性格。 扎实的计算背景运维要求理解架构中的各个组成部分，在理解计算系统的来龙去脉时，扎实的计算背景对你会有莫大的帮助。具有扎实的基础，对于理解为什么及如何架构解决方案，以及识别出问题所在，是非常重要的。毕竟，计算是架构我们的智能系统的基础。此外，工程师的思维方式和对物理定律的基本理解，也是一个很大的优势。 运维会经常遇到随意的、不切实际的期望。运维，就是理解理论和实践在哪里发生冲突，并发明适当的方法，以便在发生事故时减少损失。 娴熟的决断力虽然优柔寡断在任何领域都不算是一个优点，但在运维中却几乎不能容忍。 沉稳的性格一个沉稳与可控的思维过程是非常关键的，需要保持自己是清醒的一方。 在运维领域，目标很简单，使所有事情在所有时间正常运转。一个简单的定义，但却是一个不可能的期望。或许在这个领域成为一名工程师的更大挑战是组织内的同事对你的不切实际的期望。 从学徒到师傅掌握任何知识领域都需要四项基本要求：知识、工具、经验和纪律。 知识互联网行业的一个独特之处就是几乎所有的东西都是公开的，事实上，有专有权的东西也是极少的，而更为独特的是，几乎所有规范文档都是免费的。 在你走在从从学徒到师傅的路途中，尽可能多滴占有信息是你的职责，这样你的大脑才能将那些细微之处进行排序、过滤、关联，使其成为一幅简明、精确的图画，从而有助于你的决策——不管是长期的架构设计的关键决策，还是临时的排除故障的决策。 工具虽然工具各有优缺点，然而人们使用这些工具都取得了成功。制造和使用工具使我们人类的本性。所有的工具归根结底都只是人类肢体和感觉器官的延长。 师傅不适用工具炼成的。在互联网应用的环境中，你会看得更清楚，五花八门的语言、平台、技术都能够成功地结合在一起，将这些成功地构建为一个架构的，不是Java或PHP，而是设计与实现它的工程师——那些师傅们。 工具上的一个真理是，不管在用的工具是什么，要了解你的工具，这是在这个行业登堂入室的前提。灵巧地运用工具的能力，比工具本身的质量要重要的多。话虽如此，有经验的工程师还是应该手边备一件合适的高质量的工具。 经验从最本质的意义上来说，经验意味着良好的判断力，而良好的判断力却是从很多失败中取得的。 经验与知识是紧密相关的，知识可以认为是他人经验的总结。经验既是一个名词，也是一个动词。获得经验与应用经验，同样容易也同样困难。 一名资深工程师最大的特点是其一致与可靠的良好判断力。很显然，这要在需要做出判断的场合经受锻炼。 对进入运维这个领域而没有什么经验的工程师，我的忠告是：耐心。 纪律通过尽可能正确而高效地做事，从而为解决同样问题，而尽可能地少做工作。 如何应用云计算(Elastic Compute)云服务器(ECS, Elastic Compute Service) 什么地方适合云计算灵活性和一定程度上的自由是云服务器的特点，当然，本地服务器同样有这个特点。 混合计算混合计算=云计算+本地计算 什么地方不适合云计算当然，最先考虑的肯定是经济层面。 服务层与数据库是紧密耦合的，所以使它们之间的网络延迟最小化是很重要的。这意味着它们要么全在云里，要么全在云外。 结语尽管有大量广告吹嘘完整托管在云里，但从运维角度来说，混合应用架构模式或许是最有趣的。有些事情在云里做的不一定好。脚踏两只船，你才会游刃有余。 混合应用还强调一点，就是传统运维中的最佳时间仍然是成功的公司的云应用所必须的。 基础架构与应用程序测量任何规模的运维，采集测量数据就像将服务器连接到网络上一样重要，对于一个规模不断增长的基础架构来说，或许更加重要。 我们不光讨论你要采集并监视的测量数据的种类，还要讨论为了应对各种情况，你能利用这些数据做些什么。 测量数据的采集和带有报警(alerting)功能的监控有明显的区别。 时间刷新率和存留时间的考虑随着采集的数据不断增长，确保这些数据能够一直可查询和移动，这是很明智的。 如Zabbix中——获取数据的时间刷新率和数据保存时间。历史数据保留时长和趋势数据存储时间。比如有的数据要30s获取一次，而有的信息只需要1h获取一次。 测量数据真正出彩的地方： 对于某个特定的资源，每天的峰值是哪些？每周的峰值日是哪些？每年的峰值月是哪些？ 有季节性模式吗？ 如夏时日和节假日会高一些 最大(波峰)值与最小(波谷)值比较起来怎么样？ 在用户分布广泛的情况下，波峰与波谷是否发生变化？ 测量数据采集与存储的地点无论使用什么采集工具，易于采集和便于得出结果都是必须要考虑的。 测量数据的层次不同层次的数据存储在不同的数据库中。 高层业务或功能特定的测量数据有了这些高层数据之后，面向产品的那些人对这些数据也抱有极大的兴趣，你一点都不用感到惊讶。 对于应用层面的数据，最有用的是能够跟踪用户的交互情况。 系统及服务层面的测量数据这些是在运维工程师电脑上以图形方式显示的数据。 测量数据的层次： - 例子 测量项目 应用层 网页或API 故障：类型、延迟、发生率… 服务层 Nginx, MySQL, MongoDB… Nginx: 请求频率、响应时间、忙碌的工作进程… MySQL/MongoDB：导致故障的查询类型、慢查询、连接数… 物理层 CPU、内存、网络、硬盘 内存：繁忙程度 内存：空闲内存 硬盘：可用空间，I/O速率 网络：网络I/O带宽情况 有了这些数据，就能够回答如下问题： 平均的Web请求时间 CPU时间 调用最多的数据库查询 数据库慢查询 文件系统缓存 最大的页面响应 … 为异常检测和报警提供环境在本地采集的测量数据的主要理由，就像油表一样，有了这些数据，就可以明白基础架构正在发生什么，以及正在驶向何方。知道哪里的资源在增长或缩减，能够进行预测。使用预测对基础架构的容量需求进行预报，称为容量规划。观察网站运行是否有异常时，测量数据就派上用场了。 发生异常是，测量数据回味报警提供相关信息。报警的信息要尽量简明，告知检测到了什么，以及何时检测到。而测量数据会告诉你报警都发生了什么。 日志记录也是测量数据应用程序的日志文件也提供了测量数据和使用情况的信息。这些信息用于追踪过去发生的事件。 将变化管理和事件的时间线建立关联更新生产系统会带来风险。记录更新发生的时间，从而保留更新的踪迹，这在发生问题需要进行追踪时是非常有价值的。 给测量数据加入报警机制Zabbix、Nagios等就是一个测量数据采集系统配合使用的监控/报警工具。 使用测量数据建立加载-反馈机制采集时序数据的另一个好处，就是能够通过编程使你的应用生成测量数据，从而可以建立安全、精密的反馈循环。 结语测量数据的采集、存储、显示，可以认为是web基础架构的关键部分。不论是及时排查错误，预测容量、规划产品的发布，还是建立应用的反馈机制，如果没有正确的测量数据为你提供一个基础架构运行的全景图的话，你会损失惨重。 设计数据如何经过系统时，要考虑安全问题，而且数据要易于导出到其它应用。一旦运维部门采集了测量数据，你会发现，追踪数据是一件多么有趣的事情，同时也能使工作更加轻松。 连续部署软件应该以小批量的方式进行设计、编写和部署。 批量大小是产品在开发过程的各个阶段转移的单位。对于软件而言，最容易看到的批量是代码。每次工程师检入代码，都是在提交一定量的工作。有很多技术用来控制这些批量，从连续部署所需的最小批量到更为传统的分支开发，在分支开发中，多个开发者工作数周或数月产生的所有代码将被成批处理，并集中到一起。 结果证明，以远小于传统做法的建议的批量工作，有极大的好处。 小批量意味着更快的反馈工作转移到下一阶段越快，则也就能越快地发现下一个阶段是如何接纳你的工作的。 小批量意味着问题即刻被本地化问题发现得越快，则解决的也越快。 每次部署，都只有少量代码有变化，所以导致回归或料想不到的性能问题的任何变化，都能够快速识别出来，并进行改正。当然，由于需要改正或回滚的变化数量不仅是确定的，也是很小的，所以解决问题的平均时间也就很低了。 小批量能够减少风险 小批量可以降低总开销大多数机构都会降低自己的批量大小，以降低总的开销。大批量导致的瓶颈经常是隐含的，是这些隐含的瓶颈显现出来，是需要开销的，甚至要投入更多的工作才能修正这些瓶颈。 连续部署的目标，是在减小批量的同时，帮助开发团队清除开发过程中的垃圾，加快工作步伐。这样就能使各个团队处于持续的流动状态，这种状态使得团队的创新、试验变得非常容易，从而形成可持续发展的良性循环。 质量卫士的挽歌产生开发过程中的垃圾的一个很大原因是重复检查。 连续集成，有助于加快缺陷反馈流程；故事卡和看板，用于降低批量大小；日站，有助于加快步伐；连续部署也是这样的技术，有能力是开发团队更有活力。 为什么连续部署能行连续部署区分了发布的两种不同的定义： 一个是工程师使用的，指的是将代码完全集成到生产环境中的过程； 另一个是市场部门使用的，指的是客户看到的东西 使用连续部署，代码一旦写完，就在去往生产环境的路上了。连续部署也起着速度调节器的作用。 这种速度调节，对于习惯于通过个体效率来度量其进步的团队来说，是一种技巧性的调整。在这种团队中，每个工程师的头等大事就是保持忙碌。不幸的是，这种观点忽略了团队的整体生产能力。对于有些情形，大家坐下来讨论，找出协调方法，从而不需要做重复工作，这时候才是有效率的。 让我们开始吧步骤1：连续集成服务器这是连续部署的脊梁。我们需要一个中心服务器，运行所有的自动化测试，并监控每一次的提交。 步骤2：源代码控制提交检查下一个需要的基础框架是源代码控制服务器，并带有能进行提交检查的甲苯。如CVS、SVN、Git等。 作为一个团队，我们的目标是在能够可靠地生产高质量代码的前提下，尽可能快地工作，但不要过快。 步骤3：简单的部署脚本建立一个关键的部署脚本，用于逐台机器进行增量备份，与此同时，监控集群和业务的运行情况。这样一旦出现异常，就可以快速恢复。 步骤4：实时报警无论部署过程多么完美，缺陷仍然会通过部署而进入生产环境。需要一个监控平台，以便事情一旦偏离正常，能够进行提醒，并找到人来调试。 步骤5：根本原因分析无论问题多小，都要做些投资，而且各个级别都要做。小的改进，经过经年累月，非常像复利。 连续部署用于关键应用连续部署要求的第一个心态转移是：如果一个更新假设是无副作用的，马上发布。不要再等着与其它相关的更新捆绑在一起，否则，一旦发生副作用，就很难确定到底是哪个更新产生的。 第二个是心态转移是把市场发布的概念和工程发布的概念区分开。 更快更好的反馈 更多的自动化 对真实环境测量数据的监控 更好地处理间歇性错误 更小的批量 作为代码的基础架构只需要源代码库、应用程序数据备份、硬件裸机就能够把整个业务重建起来。 理想情况下，重组业务的最大制约是还原应用程序数据所需要的时间，应用程序数据是真正的业务价值所在。 面向服务体系结构将系统的每个组件都分解为可通过网络访问的服务，这些服务集成在一起就构成了一个功能性应用程序。 通过将每个基本组件都呈现为服务、应用开发者可自由组装的新的应用，结果就是重用更为容易、封装更为清洁、错误排查更为简单。 应该是模块化的 做一件事，并且做好在SOA中，每个服务都很小——只做一件事，并允许其它服务调用。每个服务都很简单，但应用程序员要做很多集成工作。每个服务都专注于自己的狭小领域，则管理、开发、测试都会很容易。基础架构服务也是一样的，缩小每个服务的操作范围，就可以降低复杂性，从而他人也就易于理解其行为。 应该是协作的 让我们团结起来在构建通过网络API呈现的基本服务时，要鼓励别人和你协作，而不是重复实现相同的功能。每个服务都要设计成与其它服务协作的，尽量少假设服务的使用方式。服务的协作本性决定了用的人越多，则服务本身就越有用。对于基础架构服务而言，这种本性是至关重要的——随着基础架构的每个部分都成为可集成的服务，服务之间相互协作的方式会呈指数增长。 应该是可组合的 应该一切准备就绪理想情况下，每个服务都应该通过易于访问的网络API呈现自己的配置和功能，实际情况是：大部分都没有。 配置管理配置管理是一种管理活动，从技术和管理两个方面作用于产品和生命周期、配置项，以及相关的产品配置信息。 配置管理是指对所有那些事情的跟踪，那些事情是把一个系统从裸机(baremetal)转变成做自己的事时必须要做的。系统管理员手工配置系统，并将笔记贴到wiki上时，他就是在实践着最基本的配置管理。软件开发者写了一个脚本来自动部署自己的应用程序，她就是在实践着自动化的配置管理。 配置管理是策略驱动的 把问题和解决方案的最终结果记入文档(设立策略)； 写出在策略中要执行的代码(执行策略)； 确认最终结果是正确的(审计策略)； 重复这个过程，确保以后呢能够可靠的执行(测试策略) 系统自动化就是用代码实现配置管理策略自动化几乎总是使用高级语言，自动化方式展现了三个原则： 应该是灵活的 无论需要什么，都应该有能力做 应该是可扩展的 遇到新情况时，要易于扩展 应该是可重复的 不管重复做了多少次，结果都一样 系统管理中的配置管理配置管理工具应该有如下思想： 描述的 说明做什么，而不是怎么做 抽象的 让工具为你操心细节 幂等的 旨在需要时才采取行动 聚合的 只关心自己，并信赖其他服务亦然 系统集成系统集成是指将各个组件整合为一个功能正常的、完全自动化的系统。系统集成侧重于广度，能否成功则依赖于对两个方面的理解： 系统中的每个组件是如何工作的 这些组件是如何相关的 应该遵循这两个步骤将基础架构构建为代码，这两个恰好也是系统集成阶段使用的步骤。系统集成就是将所有的东西整合在一起。 将基础架构分解为可重用的，可通过网络访问的服务 良好基础架构的十大核心原则： 应该是模块化的 启动过程将只处理这样的任务：使资源成为网络可访问 应该是协作的 启动服务应该能够将启动后的工作传给其他服务 应该是可组合的 能够从不同的服务中调用启动服务 应该是灵活的 足够灵活以应付不同类型的物理系统 应该是可扩展的 易于扩展，义启动新的资源类型 应该是可重复的 每次启动，都要生产相同的系统 应该是描述的 应该描述需要的系统类型，而不是如何安装和构建这些系统的细节 应该是抽象的 应该隐藏底层机制 应该是幂等的 应该是聚合的 应该尽快将每个系统都启动起来，并为随后的操作系统做好准备，而不用担心其他系统的状态 将服务集成在一起 现在，你已经创建了一个如何引导和配置系统的策略，你知道接收标准是什么、能够列出实现步骤、能够对策略进行测试。这种做系统集成的方式类似于做一个多层蛋糕：每一层都建立在前一层的美味基础上，使得整个蛋糕更为诱人。 监控我以前假定服务器资源是无限的，实际情况却是服务器正在为获得必要的内存而努力挣扎着。操作系统开始进行交换，CPU开始过载，从而响应时间开始变糟。 技术人员的观点和最终用户/业务的观点并不一致。 监控并不是设置一个系统，它是用来支持业务运转的，是用来保证系统中各个部分都在各司其职地工作着。能够正常工作也可以表述为保持网站的可用性。 可用性(A)可表述为：A = Uptime/(Uptime + Downtime) 网站可用性受如下4个参数的影响： MTTD(平均故障诊断时间) 诊断该问题所花费的平均时间 MTTR(平均修复时间) 用于修复问题所花费的平均时间 MTTF(平均无故障时间) 正常运行的平均时间 MTBF(平均故障间隔时间) 两次故障间隔的平均时间 A = MTTF/MTBF = MTTF/(MTTF+MTTD+MTTR) 并不是说你的业务需要接近90%或更高的可用性，业务要求的可能性只是一种期望值，如果宕机发生在周末，即使发生在工作日，只要还能工作，用户也不会说什么。你的目标是应该通过降低MTTD和MTTR，以及增加MTTF来增加可用性。 理解你在监控什么技术组件的依赖项： 组件 依赖关系 应用程序 应用程序服务器、Web服务器、邮件服务器、缓存服务器、队列服务器 Mail服务器 Mail服务进程、网络、主机、存储 DNS服务器 DNS服务进程、网络、主机、存储 应用程序服务 应用程序服务进程、网络、主机、存储 Web服务器 Web服务器进程、网络、主机、存储 数据库 数据库服务进程、网络、主机、存储 主机 设备、OS设备进程 网络 设备、网络设备进程 存储 设备、磁盘、RAID控制器、接口 通用设备 磁盘、内存、CPU、接口、房屋 房屋 UPS、电源、温度 依赖项常常不受你控制，相反，它是由公司内不同的组管理的。从你自己的筒子里走出来，到其他部门获取相关信息，并不是很容易。正是因为你依赖于他们，所以更好地理解他们的就很关键了。这样你就不用在讯早问题的原因上浪费时间，在用户访问服务所依赖的那些组件上也就不会存在盲点。 不同部门之间的边界： 企业部门 依赖项 支援部门 能影响浏览器、桌面设置、防病毒/间谍软件 开发组 专注于应用程序更新 中间件组 经常运行数据库、Web服务器、应用程序服务器、邮件服务器、缓存服务器队列服务器 系统组 操作系统、DNS、DHCP、虚拟化、集群 网络组 交换机、路由器、VPN、代理服务器 存储组 SAN、NAS、备份、恢复 数据中心组 电缆、电力、UPS 安全小组 防火墙、安全策略 这样划分责任，在不清楚问题的真正原因时，会显著增加修复问题的时间。大量精力会花在努力证明自己部门的清白上面，从而延长了解决问题的时间。这份额外时间称为平均清白时间(Mean Time to Innocence)。为了减少这种相互推诿的时间，良好的合作与协调很重要。持续的知识共享有助于增加这种共同应对问题的责任感。 组织边界到防火墙哪里就停止了，但Internet服务比内部控制的服务有更多的依赖项，这些外部依赖项有ISP、广告商、RSS信息、Internet邮件、DNS服务器、ISP连接等，内部依赖项和外部依赖项的主要区别在于，对于外部依赖项，你不知道这些服务是如何提供的。即使如此，也不能在监控这些服务上止步不前，毕竟它们仍然是你的服务的依赖项。 在无冗余的系统中，一个组件失效，整个服务就会失效。当一个组件的失效会影响整个服务时，这种失效就称为单点故障。这种影响既指服务完全中断，也指对服务质量的影响。为了避免单点故障，通常是在架构中的多个位置增加冗余，这些冗余是你的环境的安全卫士，而不是对问题的某种补偿方式。通常，增加冗余会增加复杂性，所以不要掉进过度设计的陷阱。 一些冗余机制： 服务/组件 冗余机制 应用程序 负载均衡器、状态复制 Mail服务器 一个域名多条MX记录 DNS服务器 一个域名多条NS记录 应用程序服务器 会话复制、多实例安装 Web服务器 Web服务器服务进程 数据库 集群服务、水平区分 主机 虚拟化、集群 网络 多网关、BGP、VRRP、多ISP 存储 RAID、镜像、多重路径技术 通用设备 多网卡、CPU、内存 数据中心 BGP任播、GSLB 不要忘了检查监控服务的依赖项，如果监控都挂了，那还监控什么呢。 各种检查： 检查种类 例子 可用性 能访问80端口吗？HTTP进程在运行吗？数据库能访问吗？ 功能/既时 应用程序在请求数据库，OS在进行DNS查询，控制器在进行磁盘写入，负载均衡器在请求Web服务器 功能/模拟 模拟HTTP请求、DNS请求、发送邮件 质量/利用 CPU、内存、磁盘等硬件信息使用情况，可以知道机器是否有足够的处理能力 质量/效率 Squid缓存命中率 质量/吞吐 订阅数、登录数、请求数、进/出请求数，用户数，数据库连接数，活动连接数，实例数 环境 配置监控，安全监控，备份监控 可信性 邮件域的垃圾邮件防范级别，SSL证书 不同层级的检查： 层级 例子 业务 内部网管理站点 交易 登录、增加文档、分享链接、注销 服务 Mail、DNS、Web服务器、数据库、路由、防火墙 机器 服务器、CPU、内存、交换机 理解正常行为即使你了解所有依赖项，但设计一个好的监控解决方案仍是要花时间的。需要根据业务实际需求和变化对监控实施改变。 一些监控中的主要问题：如果多次报警基于同一个原因，应该只发送一次报警；夜间，备份可能会在生产网络上产生很高的负载，这样由于响应时间的变慢而导致多个ping失败和其它可能的误报，从而产生起起伏伏的报警；如果我们想要随时待命的支持人员，必须尽可能降低报警和误报的次数。 加入的检查越多，消耗的生产系统的资源也就越多，这些资源可以是传送数据的带宽、计算结果的CPU…你需要找到正确的平衡：监控太多只会浪费资源，从而降低对整个状况的了解；监控不足将导致不能及时报警。越靠近业务层的检查越有机会检测出问题，而越底层的检查越能够对发生的问题进行定位。 监控被认为是运维环境的一部分，通常是由系统或网络管理员来管理的。开始时是一个很小的系统，在后台运行。随着监控环境的扩大，需要执行更多的配置和定制。虽然运维人员常常是第一个对要部署的新软件进行仔细检查的人，他们的标准却往往并不应用到自己的监控系统上。监控系统是你的关键应用之一，请一视同仁。 监控的最佳实践： 实践 说明 版本 对你的检查进行版本华，并把他们放入版本控制库中 不同环境 使用不同环境开发、测试新的检查 测试 将检查作为通常代码对待，在代码功能中加入测试 可使用性 创建一个所有组件及其关系的可视化总览图，指出失效和组件的关系对工程师很有帮助，只需要看一下仪表板就能明白问题出在哪里 信息架构 使用不同的数据表示法，将数据组织为层次结构以便于导航，同时还要避免信息过载 代码重用 如果能够重用所监控的应用程序中的业务逻辑，就不要自己写 无硬编码 避免将参数编码在脚本中，使用配置文件，这也易于脚本在不同环境中的迁移 部署 要易于部署和分发新的检查 备份/还原 备份监控数据，并了解在什么情况下需要还原 监控 监控你的监控系统 冗余 在监控上，使用高可用性的功能做维护工作 应用的安全规则 监控账号与其它事务账号分开 是用最小特权级 不要将密码保存为明文 限制对系统的访问，不要将其用于其它的测试 将监控系统用防火墙或代理系统保护起来，避免来自易受攻击的主机的访问 所有信息一旦采集和存储，接下来做的就是分析检查结果。服务或系统的状态有可用(Up)和不可用(Down)，某些监控系统还增加了两个状态，一个用于系统不可达(Unreachable)，一个用于系统/服务尚未检查(Pending)。 有的时候，在位新服务建立环境时，预先定义的阈值很困难——实际使用可能会超过预期，或者相反。所以，对阈值进行不断的调优就有意义了。先根据理论上的假设定义一组阈值，然后在测试环境中模拟预期的行为，并翻译为技术化的组件使用情况。因为系统及使用情况的复杂性，对系统、应用程序、用户行为建立精确的模型是很困难的。所以，对阈值只能持续不断地研究与改进。趋势分析确实有助于定义阈值，大部分监控软件都可以让你对监控的值做趋势分析，而不产生报警，根据历史数据得出阈值之后，再启动报警设置。 管理报警并不仅仅是状态变化时发出报警信息。所有报警如果一直打开着的话，工程师将无法安心做系统支持，因为报警信息太多了，可能要被报警轰炸。同样，如果有太多假设报警，也会导致同样的问题，这可以看成是你的监控系统存在技术缺陷。警报应该产生行动。如果一条警报可以忽略或不需要人工干预，这条报警就是一种浪费。然而，消除噪音却是真正的挑战。警报太多会导致狼来了效应，由于警报过载而忽略了正在重要的警报。 为了使网站可以忍受而限制报警是好的，但假如与业务需求不一致的话，就不行了。反之也是对的，如果业务不需要的话，为了显示网站运行正常而发送很多报警信息，也是毫无意义的。使监控保持正确的平衡，这很重要。 有备而学一个人不可能在每个方面都是专家，有一个清晰定义的升级路径，从而把问题提交给更为专业的人员去处理是明智的。对紧急报警进行跟踪和趋势分析，有助于提出架构和过程的改进建议。 故障时间本身并不仅仅有功能失效引起的，也可能是由于维护活动产生的。维护活动产生的故障时间被描述为维护窗口。在这种情况下，业务部门是认可默写故障时间的。为了避免不必要的报警，监控系统可能会在这段时间关闭报警。这会导致丢失一些与此次维护无关的系统/服务故障。所以，应该只关掉与维护相关的报警，而不是整个报警系统。然后，一旦服务运行稳定了，就要打开报警。 结语监控并不是要保持服务器运行正常，也要保持业务运行正常。理解了技术组件和业务行为，你就会有相当的把握减少和修复问题上的时间。错误总是会发生的，但要为此做好准备。万一系统失效，一定要将反馈信息发送给每一个希望听到的人，并对事情做出改进，避免再发生新的错误。愿监控的力量与你同在。 复杂系统是如何失败的所有复杂系统失败时，都有共同点。Web运维就是这样一个领域。 复杂系统是如何失效的 复杂系统本质上都是灾难系统 复杂系统都被重重地然而也是成功地防护着 灾难要求多点失效——单点失效是不够的 复杂系统包含潜藏在其中的缺陷的变化混合物 复杂系统以降级模式运行 灾难随时会发生 事后归结为”根本原因“是错误的 幕后认识对人类行为的时候评估存在偏见 人类操作员有双重角色：作为生产者，以及作为失效防护者 所有操作者的行为都是赌博 最为困难的行动解决了所有的模糊性 人类操作者是复杂系统的可调整因素 复杂系统中人类专门处理知识处于不断变化中 变化会引入新的失效 “原因”观点限制了对未来事件的有效防护 安全是系统的特性，而不是系统的组件 持续创造安全的是人 无事故的运维需要经历事故的历练 针对Web运维而言： 了解系统失效很困难 了解哪部分失效很困难 有意义的响应会被延迟 沟通会产生紧张，而脾气会冒火 维护会成为新的失效的主要源头 从备份中恢复本身就很困难，而且还有潜在的危险 创建测试过程，一线人员用来验证系统状态 对运维进行例行的每日管理 控制维护 定期对性能进行评估 要成为(独一无二)的用户 社区管理与Web运维运行一个大型且广为人知的网站，意味着会有大批人依赖于网站快速而稳定的服务。这些人会形成一个社区，以各种有趣新颖的方式进行交流，并彼此关照。 社区起着一个交流、沟通、反馈的渠道作用。 处理非预期的访问量激增有些时候，因为某种原因，Web的访问量会急剧增加(是正常用户访问而不是遭受攻击)，我们的服务器就会遭受严重的考验。 一切是如何开始的开能由于某个原因，导致Web流量激增，而我们服务器却无法应付这么高的并发和流量，所以导致Web瘫痪。 警报连连监控软件(如nagios, zabbix)警报连连。Web请求太多导致响应很慢或奔溃。 扑灭烈火查找是哪些环节导致Web响应很慢或奔溃，对之做相应的优化。 未雨绸缪当我们经历了非预期的流量激增，并处理优化之后，下一步就需要对整个基础架构进行加固，或转向新的架构。 救命稻草CDN解决带宽问题要靠内容分发网络(CDN)——在多个地点存储文件，为客户提供最近最快的响应。大部分静态资源适合移动到CDN上，以减轻原始服务器的负担。 但CDN也有一些不足。对于移动到CDN上的数据，你就失去了控制。对于短时间的静态内容，CDN的效果并不好。 代理服务器代理服务器处于我们系统的最前沿，尽可能让代理服务器转发请求，而不使用任何其它资源。 围剿踩踏如何避免缓存踩踏？ 一个是对数据库进行优化 一个是搭建数据库集群 将代码基流水化 怎么知道它能否工作确保系统能够处理负载的唯一途径是在流量汹涌而来时，对其进行现场测试。 真实测试必须要在真实的生产环境中查看其负载效果，才能确保其能正常工作。 教训总要为未来几年做一个规划——问问你自己：“当前的架构方案能够用于未来几年吗？” 要测试生产环境，经过适当的测试规划，很多问题是可以避免的。 当一个架构方案已经明显不能工作的时候，必须要有重新考虑整个方案的勇气。重新思考代码、硬件、网络、数据库模式，为可见的未来创建一个伸缩性更好的系统。 改进针对遭受的问题，之后对系统的改进。 开发者与运维者的协调与合作很多网站都将其开发和运维分为两个独立的团队，开发负责开发新功能和对现有功能进行改进，运维负责网站的正常运行。两个团队有不同的目标，工作方式的要求也是迥然有别。 这种设置很常见，但也是保证网站稳定性或及时推出新功能的最糟糕的设置。 这在种情形下，开发人员没有动力将网站做得更易于运维支持，开发团队交付的代码通常是一个黑盒子，一旦发生意外，运维团队没有办法及时去修复问题。这种结构也抑制了新的功能的开发、构建和部署网站的新版本，不仅耗时，成本高，还涉及很多不同团队之间的协调。对运维来说，部署是存在风险的，而且也是造成很多宕机事故的原因。 传统的运维和开发，两者之间存在着很多对彼此很有用的信息。对很多网站来说，性能瓶颈都出在应用程序代码上：开发团队最适合修正这些问题，但运维团队有测量数据，要想找出问题出在哪，是需要这些数据的。关于什么地方可能会出问题，以及如何修复，开发团队有很多很好的想法，但这些却很少会记录在文档里面。 所以，重新评估运维跟开发之间的关系！ 部署以合适的方式进行移交，则不同团队之间就能更好地共同工作，而改变过程这是困难的，需要协助以及每个人的认可。 一项服务之所以受人欢迎，频繁部署也是重要原因之一。小批量代码更新。 用户报告问题后，极短时间内就得到修复，这一做法会彻底征服用户。有了这种响应凡是，则将来有了问题，用户也会很乐意报告给你，这样产品就会越做越好，特别是你能够一直这样快速反应的话。对关键的数据损失或安全缺陷能够在短时间内而不是几周响应的话，用户的数据就会安全得多。 然而最重要的是，频繁部署并不比周部署或月部署风险更大。很多小的更新，每个都单独测试和检查过，比起一次大的更新来说，导致严重宕机的事故的可能性要小很多。 这是因为小更新的影响能够提前单独进行复审和测试，从而错误造成的影响也易于量化及应对。定位代码中的缺陷，复审10行的更新比起10000行来，会容易得多，而且只测试那些受更新影响的功能，比起测试整个系统，也要快得多。而且能够确保每次部署都只是更新一个区域，从而避免同时更新的两个组件之间发生预料不到的交互作用。小部署意味着更容易预言更新对基础架构的影响，而这也就意味着未雨绸缪更加有的放矢。 如果只是部署30行代码，缺陷通常是自明的。如果缺陷不自明，其影响也会非常小，即使回滚也非常容易。 只有在遵循以下三条规则的情形下，频繁的小更新才起作用： 构建与部署系统必须能够完全重复且自动地工作 具有几近完美的预演环境 部署必须尽可能快，理想情况是小于5min 大多数构建和部署系统在某种程度上都是自动化的，少数团队走得更远，把构建和部署做成了一键操作。 共享、开放的基础架构很多情形下，运维和工程都分为不同的小组，你会发现支持的基础架构也会一分为二。 共享基础架构是在团队之间进行协作的最容易的方式。 为了有效地工作，你需要了解系统的其它方面目前是如何运转的。为了建立信任，你需要使你的工作变得透明。 信任信任是开发和运维之间最常见的紧张关系之一。多数运维团队对开发团队多少都有点怀疑，开发人员通常也好不到哪去。团队之间的不信任是不健康的，也是不合适的。 信任最终是建立在一种尊敬的感觉之上的。如果你尊敬某人，就很容易信任此人能够做好他的事情。反之，如此人交往便会带有偏见、不满等情绪。 运维和开发之间的许多问题都是由于对两个团队不同角色的重要性认识不同而造成的。 充分尊重你的同事，而不是事后指责他们。 随叫随到的开发人员只有在开发人员对修正生产系统代码中的问题肩负起责任的情况下，才是有意义的，而这就意味着开发人员随叫随到。 现场调试工具很多代码对于运维团队来说都是黑盒子。 要想办法在运行时调用额外的调试信息，技术团队的每个人在用管理账号登录系统之后，都可以开启额外的调试信息。 功能标识禁掉某些依赖于问题架构的功能，而保持网站的其他部分正常运行，功能标识能够实现这一点。 单个标识，用来禁掉每个非核心的基础架构 只要这些服务出现问题，我们都可以暂时并优雅地禁止掉这些功能 如果生产系统出现新的错误场景，也可增加新的标识 避免职责在很多团队中，没有人愿意成为搞坏所有事情的傻瓜。发生问题时，人们都会将责任推卸给别人。 每个人都有貌似合理的理由将指责转嫁给别人，却没有挺身而出，实实在在地修复问题，组织良好的团队深切地了解，在将问题修复之前，争论到底是谁的责任是没有意义的，为保护自己而浪费的每一分钟，由于问题没有修复，都会成为给用户带来损失的一分钟。用户会尝试各种可能性，知道他们发现系统出问题了。 多数生产环境都有足够的冗余，也足够复杂，任何问题都不太可能存在单一的根本问题。很多问题都是由两个或多个系统发生意料之外的交互作用而引起的。 结语网站的稳定性是每一个人的责任，而不仅仅是某种应该交给运维团队去处理的东西。 让人人都拥有对网站的主人翁感觉，确实意味着能够减轻运维团队的工作负担。他们不用再花费大量时间呼吁采取防护性措施，一旦发生问题，也能够花更小的时间修复。这非常了不起，因为这意味着网站的宕机时间会减少很多。这也释放了运维团队，让他们能够把精力放在更为重要的任务上，即对基础架构的长期增长进行管理。 你的访问者感觉怎么样：面向用户的测量对于网站的成功而言，终端用户的测量也就变得和后台测量一样至关重要。 为何要采集面向用户的测量数据采集数据，从而就可以对业务的健康状况进行分析。 如： 每秒请求数/发布数 带宽 响应时间 HTTP错误率 记入日志的异常数 进程重启次数 队列大小 服务器的平均负载和进程数 数据库负载 内存 成功的创业公司所学到的以及必须适应的创业公司的一大优势就是敏捷，即快速反应的能力。要真正做到敏捷，创业公司需要了解终端用户真正体验到的是什么。 任何网站想要成功，就必须向用户学习，而且必须适应用户的需求。很多Internet巨头，它们现在的业务，都与其当初设定的相比有很大的不同。 性能问题响应越快的应用程序越好！ 响应级别： 加入事情的响应时间在10ms内，我们的大脑就会认为这是真实的 如点击桌面系统上的按钮 如果谈话有100ms左右的延迟，我们不会感觉到这种延迟 如国际长途电话 如果应用程序的响应时间在1s之内，我们的感觉就是仍然在与应用程序互动，仍然在工作 应用程序的响应时间要是明显长于1s的话，我们就会抓狂 研究量化了这种关系Web应用的速度越快，其Web业务员的优势就越明显！ 如果你的网站很慢，你将得到： 更少的用户搜索 更少的精度搜索 更少的每访客收入 更少的点击，更低的满意度 更少的每日搜索 等待访客点击的时间更长 更低的搜索引擎排名 更差的用户体验 是什么使网站变得很慢简单来说，由以下三点原因造成： 服务器花在处理用户请求上的时间 网络花在传输请求和响应上的时间 用户花在组装并显示结果内容上的时间 服务发现开始访问网站，用户都需要先找到服务器。 对于带有很多组件的网站——这是一个日渐普遍的模式——都会迫使用户去解析很多网站，并且页面加载的时间也延长了。 发送请求网络再快，用户与服务器之间的往返也是需要时间的。 请求包含的内容越多，则网络用来传输的时间就越长。加入是一个安全页面的话，还会有另外的延迟，用来在客户与服务器之间进行加密协商。 响应请求到达服务器之后，另一个导致延迟的罪魁祸首就登场了——主机。不论是从内存中检索静态对象，还是利用后台的第三方服务来完成一个复杂的请求，主机延迟都会对性能造成影响。 发送响应响应内容一旦准备就绪，服务器就可以通过HTTP协议发送这些请求对象——大多数页面包含多个对象(如html,css,js,gif,png,jpg…)，正是这些对象的发送造成了访客体验到的延迟。 异步通信与刷新某些应用包括一些客户与服务器之间的通信，这些通信是独立于页面进行的。包含某种异步更新或刷新的应用，有不同的延迟测量指标。 渲染时间随着客户端越来越复杂，浏览器做的也就越来越多。有可能是启动富互联网应用(RIA)，这些RIAs都是构建在Flash、Flex、HTML5、Java、JS…之上的，也可能是运行QuickTime或Windows媒体播放器等这样的插件，甚至决定如何对复杂页面进行布局也是需要花费时间的。所以，对于大量依赖客户端进行渲染的网站，就必须考虑这种延迟。 测量延迟有两种测量方法： 综合监控 实际用户监控(RUM) 综合监控综合监控是通过从多个地点对网站进行一系列正规的校本化测试，对网站的性能进行监控。 要记住，综合测试也是要消耗服务器资源的。 真实用户监控RUM的工作名副其实：它观察的是网站的真实访客，记录访客打开页面的速度，然后生成报表。 从这点来看，RUM会告诉你系统是否出问题了，因为你可以通过RUM发现问题以及速度变慢的情况，这些情况你没有进行测试，从而也就不知道是否存在。 编写SLAWeb运维收集终端用户的数据的一个主要理由就是用来编写SLA，哪怕与客户之间没有正式的SLA，但对于正常工作时间及页面延迟，也应该有内部的目标，因为网站速度对用户体验有直接的影响。 访客结果：分析对于成功的Web运维来说，监控就是了解存在哪些不利因素。而当进入Web业务时，这些测量就要让位于Web分析了。 市场营销如何定义成功对市场营销的最好描述——“更经常、更有效地卖出更多的东西给更多的人，从而得到更多的钱。”或许应该将成功的在线营销更精确地定义为“让人们有效地去做你要他们做的事情。” 网站的四种类型 交易性网站 协作型网站 作为服务(saas)网站 媒体网站 很多流行网站都是上述模式的混合。 网站分析就是对每种类型网站的成功因素进行追踪，从中识别出使这些因素得以增长的背后动因——不管是广告活动、性能的提升、社会网络上的关注、特殊的定价模式还是某个引人注目的内容。 分析一个简单的模型有一个简单方式来考虑网站分析，就是做一次访问。 网站分析的目标，就是通过优化网站，将访客的转变最大化，通常是对网站进行试验，并针对各种内部和外部区段，对这些试验结果进行分析。 市场营销关心的其他测量数据Web交互分析分析查看的是用户对多个页面的整体访问情况，Web交互分析集中在单个页面的可用性交互上。 用户之声用户之声工具用来询问客户在想什么。这些工具从网站的访问性中征求反馈，通过请求客户参与调查，或者在页面上提供一个反馈按钮。 用户体验如何影响Web运维随着新建公司对终端用户体验的关注，Web运维的角色正在发生变化。对线上事务的兴趣越来越浓，而且通过追踪分析，网站的所有事情都能够和业绩联系起来。 将监控作为生命周期的一部分网站现在已经有了很大的变化，随着敏捷和精简产品开发的流行，监控也需要跟上。所以来的综合监控脚本以及RUM配置也需如此。 Web监控的未来终端用户体验的监控正在兴起，变化很快。这是业务中最能进行分析、量化的部分，每周都能涌现出新的技术。 从系统转向用户 以服务为中心的架构 云与监控 APIs与RSS消息 将关系数据库用于Web的战略战术如何为产品或应用程序设计一个良好的关系数据库架构，如何构建良好的互联网数据库架构？ Web数据库需求其实，大多数网站，相对而言，都只是小型数据库。一些大型公司，可能才是一个大型数据库。 一直在线数据库通常要7x24小时运行。一直在线意味着维护和运维任务是很难做的，你不能简单地等到人们回家了然后将服务器卸下来，给硬件升级或备份。必须在不停机的情况下做这些事，而且很多情况下还不能给应用程序增加额外的负载。 话虽这么说，还是极少看到没有峰值时间的数据库。所以，还是有很好的机会，在数据库活动的间歇期来做备份或对数据库产生干扰工作。 事务最多的工作负载很多互联网应用都匹配以下模式： 应用程序读远大于写 一次读一行和一次读多行是混合出现的 一般，写每次只影响一行 这就是称之为的事务型负荷。 简单数据，简单查询网站的流量很大程度上决定了数据库的流量。 查询通常会满足下面的模式： 读写用户表，一次一行 以区域或集合方式读取用户自己的数据 以区域或集合方式读取其他用户的数据 从该用户到其他用户的关联表中读取区域行 对该用户和其他用户的数据进行汇总与计数 特别低，很多数据可以分区存储的事实说明了为什么分片(sharded)架构是可能的。 可用性胜过一致性从业务的角度看，最重要的事情是应用程序对用户的可用性。 快速开发传统应用极少以天或周为周期构建和部署，但对于大量Web应用来说却是常态，这些Web应用是永远的Beta版。 在线部署模式和数据的更新都做成代码形式，而且也有这样的框架，部署这些代码或将其回滚都很容易。 由开发人员构建大量的应用程序都是由开发人员做的，都没有一个高水平的DBA。 典型的Web数据库是如何增长的大多数Web数据库的增长，都经历了一些列的架构变动。这些架构变动，在应用程序的整个生命周期中，相对而言都是可预知的。 单台服务器一般应用程序都是从单台服务器开始起步的。使用单台服务器有很多好处： 数据只有一份拷贝，不存在你的数据是否正确或不同的问题 易于配置 便宜 当然，缺点就是只有一台服务器！假如发生问题，没有冗余机器做故障转移。性能也会受影响。 主服务器与单复制从服务器各数据库的复制技术都不一样，但一般而言，发生在主服务器上的数据修改，都要在从服务器上重复一遍，所以从服务器是主服务器数据的只读拷贝。依赖于数据库、系统负载以及执行的查询类型，从服务器不一定时刻与主服务器的数据完全一致(异步复制)。 增加一个复制从服务器有很多好处。数据库读请求可以在主、从指间分担，这称为读写分离。可以在从服务器上执行那些效率不高的查询、备份以及其它有可能对网站造成破坏的任务。 主服务器与多复制从服务器大多数复制技术对两台或多台从服务器都没问题。这样确实不错，而且随着从服务器越来越多，系统的数据库读取能力也越来越强。但这种增长不是无限制的，在很多层面上都会遇到收益递减的拐点。 第一个层面就是应用程序中读对写的比例 第二个方式表示主服务器的写操作有多忙，其中你会看到收益递减的情况 第三个限制是操作成本和复杂性 管理一群服务器，比管理单台服务器，要难得多也昂贵得多 最后一个不足是应用的复杂性 从单一数据源走向两个数据源，对于大多数应用程序而言，都是一个重大转移。应用程序不得不连接多个位置来进行查询。连接池、负载均衡器以及类似技术会在一定程度上保护你不受这种复杂性的困扰，但最终应用程序仍然要面对某种程度的复杂性 复杂性的一个最大来源是异步复制。异步意味着写操作先在主服务器上完成，随后送往从服务器执行。结果就是，从服务器总是拖后于主服务器某段时间，即时这段时间很短，但由此而造成的问题却很大。这可能会导致用户体验的不一致到数据完整性等一系列问题。 一般而言，不存在修复这个问题的神奇方法，应用程序必须自己处理这种延迟复制。一种不错的简单技术是基于会话的分裂。用户做了更新之后，一段时间之内，该用户的所有查询都导向到主服务器。认为能够安全地查询从服务器所需的时间戳通常都存储在会话里。 功能分区复制只对读有伸缩，对写没有。随着应用的规模越来越大，写操作的负载最终会大到系统无法处理。 功能分区(functional partitioning)，假如将某些部分与其余部分分开，则这些部分可以独立增长。如，对于博客服务，可将评论功能分离到它自己的服务器中。 从运维角度来看，不同部分处在不同位置，则应用程序的功能也就能够单独对待。比起网站宕机，将评论改为只读模式，用户的反感可能要小得多。 这种做法的不利之处是增加了复杂性。应用程序需要从多个位置获取数据，而运维团队必须保持这些服务器正常运行。 分片分片(sharding)，是将单一逻辑数据划分为多个片段并发布在多台服务器上的一种方式。所有的片段在逻辑上和功能上都是相同的，虽然这些片段分别包含数据的不同子集。 分片架构的主要设计目标和优势都是双重的。第一是允许写伸缩，因为负值无法实现写伸缩，假如应用程序的写操作草果了任何单台服务器能承受的程度，就必须要分片以减少写操作的负载，写操作的负载必须分担到完全隔离的服务器上，对一个分片的服务器的写操作不能复制到另一个分片服务器上。第二个目标和优势是，随着数据集的增长，能够增加更多容量的能力。 在分片架构中，许多查询也变得困难或不可能了。例如，需要访问所有客户数据的查询，通常都要在每个分片上分别执行，然后在应用程序代码中在聚合在一起。 分片架构还存在很多其他的不足和复杂性。 缓存层缓存层的目的是阻止查询到达数据库。标准的例子是：memcached，redis 缓存层的主要优势是极为容易，并且简单。 从运维的立场来看，需要考虑缓存服务器的冗余和可用性，就像为其他服务器所做的一样。 对集群的渴望在应用程序出现某种问题，或关于可用性或伸缩性的困难问题来的时候，人们的思想就会转向集群(cluster)，就像年轻人的思想转向春天和爱情一样。 CAP定理以及ACID和BASECAP原理： 一致性(Consistency)、可用性(Availability)、分区容错性(Partition Tolerance)。你可以具有两者，但不能三者皆具备。 ACID： 原子性(Atomicity)、一致性(Consisitency)、分离性(Isolation)、持续性(Durability)。 BASE: 根本可用性(basically available)、软状态(soft state)、最终一致性(eventual consistency)。 MySQL集群的状态MySQL Cluster是将MySQL服务器作为一个完全不相干的、称为NDB的软件的前端。NDB的意思是网络数据库，这是一个极快、分布式、无共享、高可用的数据库。 DRDB和HeartbeatDRDB在服务器之间对块设备进行复制，将修改的块通过网络复制给备机。如果主服务器失效了，则Heartbear激活备机。 从运维的角度来说，DRDB非常棒，装上就能工作，但却不能满足在线用户的需求。它不是为满足典型Web应用的高可用性而设计的。相反，它非常适合用户保证你不丢失数据的情况，也就是说，它关注的焦点是一致性而不是可用性。 另一个问题就是基于DRDB的集群不能改进性能。Web应用需要的是正常工作时间和性能，而基于DRDB的集群是以性能为代价来提供一致性，而一旦失效，宕机时间就会很长。 主服务器到主服务器的复制管理器(MMM)MMM是一系列的Perl脚本，管理复制和虚拟IP地址，从而为MySQL提供一个伪集群(pseudocluster)。 应用程序连接到虚拟IP而不是服务器的真实IP。服务器发生问题时，MMM将该服务器的虚拟IP移动到另外的可用服务器上。它也可以将复制从服务器从失效的主服务器移动到正常的主服务器上。MMM允许手工将服务器离线执行维护任务。 带复制的Heartbeat如果MMM无法完美地管理复制和虚拟IP地址，heartbeat考虑以下？ 不管怎么说，复制延迟仍然是一个复杂的问题。必须在应用程序层解决这一部分问题。 基于代理的解决方案有一种可供选择的方案，基于代理(proxy)，需要人工介入，MySQL Proxy位于前端。HAProxy是另一个流行的方案。 MySQL Proxy，事实上能够理解MySQL的协议，并且拦截、解释以及传递消息 HAProxy，只是传递TCP流，并不对内部进行窥探 基于代理的解决方案仍然没有入人们所愿的那样解决复制延迟问题，而且还引入了单点故障，并且影响性能。 小结前面讨论这么多，简而言之，就是没有一个完美的、万能的答案。 最好的数据库架构是为了应用而建的，期待集群所承担的指责分布在数据库、网络以及应用程序上，有运维的适度介入，以及起粘合作用的软件，就能把各部分整合在一起。 数据库战略如何选择一个对于大量的互联网架构来说都能够运转良好的架构。 架构需求最好定义你的需求，特别是，把那些超出你的范围从而成为别人的问题的内容写成文档。 有把握的架构以下数据库架构，是比较有把握的。 单主服务器，多从服务器这种主-从架构很难自动实现主服务器的故障转移，因为主服务器和从服务器的配置是不一样的，所以，一旦主服务器失效，则必须手动进行失效转移。 主服务器-主服务器复制，外加从服务器这种方式实际上与一台主服务器加多台从服务器的架构一样，但有时候主服务器本身也成为从服务器。这种架构的优点是，在协同的主服务器之间更容易实现失效转移和失效转回。缺点是，向两台主服务器进行写入存在风险，会导致数据库存在某种不一致性，也很难解决。 功能分区随着应用的增长，将应用中某些部分转移到特定的服务器或特定集群上。 失效转移和负载均衡使用负载均衡器，或者浮动的虚拟IP地址。 ACID仍然是有意义的高可用性要求快速而可靠的灾难恢复。 使用正确的工具不要使数据库处于关键路径上，不要讲应用程序的静态信息放入数据库中。数据库应该存储数据，而非应用程序本身。将数据库简单化，因为这是最难于伸缩，也是最昂贵的资源。但是，对于Web应用，还是应该分离应用程序和数据库，将数据库仅用来存储和检索数据。 有风险的架构建议不要使用这些架构 分片除非不得已，不要分片。对于一个中等规模的应用，将其构建在数百台低档机器的分片架构上，试图提供无线伸缩能力，是非常愚蠢的。其实，只需购买几台足够好的机器，在工程上多做一些考虑就足够了。分片架构比你预想要昂贵的多，甚至在短期内也是如此，长期则一定如此分片问题设计过度设计的风险 写入多台主服务器不要将多台服务器配置为可写，这会造成数据一致性问题。非常麻烦。 多级复制尽量不要使用多级复制。使用一主多从而不是从的从的从服务器，要简单的多。孙子辈的从服务器和重孙辈的从服务器很难管理。 环形复制避免使用环形复制，其失效情形，不管是数量还是复杂度，都打得超乎想象。 依赖于DNSDNS很脆弱，依赖DNS最终会自食苦果。 数据库战术数据库战术，即为保持数据库基础架构的可靠性而做的日常运维任务。 在从服务器上做备份一些小提示： 在备份上不要拖延，做备份其实并不难 做事不要追求完美，而要追求可恢复 至少对于可接受的数据损失、可接受的宕机时间、数据持续策略以及安全需求要形成文档 对恢复过程要进行练习并形成文档，恢复比备份要重要的多 对于备份成功与否，要进行外部验证，不要依赖于作业自身对你的提示 可以专门配置一台复制(备份)从服务器，将复制延迟一段时间——如30min，以避免主服务器上的某些误操作——如DROP table。 在线模式修改将表做的小一点是很有好处的。 一般的想法是设置主-主复制对，但只有一台服务器可写。在只读上执行更新，但不要复制到可写服务器上。更新一旦完成，则用正常方式使应用程序实现失效转移。这样，读和写便实现了角色转换。然后在另一台服务器上重复执行风险。这就实现了对应用程序隐含宕机时间的目的。 监控和图示构建用于测量和监控的系统是很值得做的事情，这些系统是基础架构非常重要的核心内容。 性能分析一般步骤是，在产生麻烦的时间内手机详细的诊断数据，消除掉可能的原因，集中在问题的现象上。问题往往是服务器产生大量负载，而这通常是由于糟糕的查询产生的。 MySQL所谓的慢查询日志(slow query log)可以回答这个问题，不仅是因为日志收集了慢查询的信息，而且对于每个查询还有时间信息。 加入性能问题不是查询引起的，则需要对MySQL本身进行性能测试。 归档和删除数据从一开始就要规划归档和删除不活动或不需要的数据，这样有助于减小“工作集”的大小。 将极不活跃的用户数据移动到慢速服务器，或仅仅将用户设置为过期。当用户登录或重新激活时，在倒回到正常表中 另外一类可归档或删除的数据是陈旧的历史数据，或将历史数据移到另外的服务器上 结语尽最大可能将数据库架构建立在逻辑的基础上，而不是做一些看起来很酷的事情。 努力使系统保持小巧，不要大——而当不得不变大时，也要保持在能够掌控的范围内。要确定应用程序的真正需求，尽可能满足这些需求。要尽早及经常做缓存，但不要尽早及经常做分片。 最重要的，请记住：做备份。 如何优雅地失败：事后处理的艺术与科学宕机意味着实际的金钱损失。客户才不会管这些故障，他们要的就是可靠性。互联网已经变得非常重要，宕机成本也越来越高。 但正如一个刚毕业的年轻人一样，只是知道你需要成长，但并没有告诉你如何去成长。我们需要将失败转化为学习经验。 保证网站稳定的首要事情，就是建立一个系统化的事后分析过程。通过阻止事故的重现以及改进处理事故的方法，使得系统稳定之后，事后分析能够让你全面地理解事故的本性。 例行的时候分析，是对运维的复杂问题进行科学分析的最贴近的方法。通过收集实际证据，可将有限的资源集中于解决产生问题的实际原因上。 什么是事后分析事后分析至少要包含这些内容： 事故描述 根本原因描述 事件是如何修复的 用于解决事故的行动的时间表 事故是如何影响用户的 纠正或改正动作 事后分析时，与事故明显有关的人员都要同时到场，对事故的真实情况作出共同的描述，从而正确地采取行动。 减少事故的修复时间，就跟消除事故本身一样重要。 对问题赋予严重级别，将帮助你按照轻重缓急来处理纠正项，而且对于活跃事件的评估也是有用的。 事故严重级别： 严重影响大批用户 网站降级运行、性能问题或很难应对的功能故障 对客户影响不大或易于应对 什么时候引入事后分析在事故处理完成之后，就应该进行事故分析。事后分析过程应该最终使用户获益，而不应该在恢复服务的过程中进行。 进行事后分析开始事后分析时，要明确基本规则，要明确告知参与事后分析的相关各方，事后分析不是指责谁(人们害怕这样的会议变成政治迫害)，主要目的是为了使类似事件不在重复发生。问题不可避免，重要的是我们能够从错误中学到教训。事情一旦清楚之后，就可以开始讨论为了使类似事情不在发生，需要做些什么。确保相关各方对各自领域都能得出补救的办法。但切记不可矫枉过正！ 一旦有了一套纠正措施，要将其记录在案，包括执行人员和完成日期。 事后分析的后续工作对纠正措施必须进行追踪，直到执行完成。 一些网站可操作性： 消除单点故障 容量规划 监控 发布管理 运维架构复审 配置管理 随时待命和提升过程 不稳定的组件 结语最后，对于避免事故的发生，事后分析是最有用的方法。在一个快速变化的环境中，发生问题时可以理解的，但问题重复发生却是不能原谅的。花些时间高清楚问题的实质，从而确定、记录以及实施高强度的纠正措施，就可以避免事故的重复发生。 存储数据是一项最重要、不可替代的商业资产。 数据资产的库存在开始一项新的存储工作时，首要的事情是要知道数据存在哪里。对于不了解的数据，你是无法进行保护的。 数据的保护数据保护对所有系统都是很重要的。良好的数据保护实践有助于处理范围广泛的情形，从还原被用户偶然删除的文件，到从灾难事件中恢复。 为了对数据中心问题提供完全的防护，重要的是将关键数据复制到不同的地点。 如今大多数的存储系统都有某种类型的复制技术。复制通常有两种形式：同步和异步。 容量规划在确保有效的的数据保护之后，作为一名存储专业人员，容量规划就是第二项最重要的职责。规划在前，确保应用和服务有足够的资源来运行和成长，不至于碰到天花板，这是必须的。 总是确保有足够的空间以应对突然的爆炸性增长，以及软件开发方面出现的延迟。 存储大小的变化存储是很昂贵的，这是现代基础框架中成本最高的组件。正是由于这个原因，对于存储上的开支进行明智地规划是很重要的。 存储需求要点： 应用是什么 应用位于哪里 存储的是什么类型的数据 需要共享存储吗 是否需要特殊的访问协议 典型的文件大小是多少 数据是压缩的吗 如果描述工作负载 需要批处理操作吗 工作负荷是大部分用于读、写、读写 工作负荷是大部分顺序、还是大部分随机、还是两者 快照是怎么安排的 快照的一致性问题 存储容量在6个月、12个月、18个月的计划是什么 工作负荷在6个月、12个月、18个月的计划是什么 复制策略是什么 业务连续性规划是什么 可用性需求是什么 备份的频度是什么 备份保持的计划是什么样的 归档策略是什么 综合性需求是什么 加密需求是什么 … 结语数据是最宝贵的业务资产，且是不可替换的。 非关系数据库应用的数据存储层的伸缩是很难的。不管用的是什么数据库技术，随着数据量和事务数量的增长，就需要做出改变以适应新的负荷。 SQL数据库的可伸缩性通常归结为四件事：缓存、查询优化、购买新硬件、数据库分片。 NoSQL数据库概览NoSQL共生系统，可将数据库划分为5大类： 纯粹的键值 数据结构 图 面向文档 高度分布 每种类别的数据库都面向不同的应用情况，每个类别也都做了不同的这种。 纯粹的键值如： Tokyo Cabinet、 Kyoto Cabinet、MemcacheDB 正是它们的简单性定义了这组数据库。向数据库存入一个键和一个值，然后用同一个键查询数据库，则会得到相同的值。没有结构或类型系统——通常所处理的只是字节或字符串。因为这种简单性，这些数据库的开销极小，所以非常块。事实上，这些数据库通常都是实现为磁盘上的B树或哈希表。 数据结构数据结构数据库对键值数据库做了些修改，数据结构数据库将其存储为特定的数据结构，如列表、集合、哈希表等。有了这些附加的结构，就可以对值执行一些原子操作。可以对数据库执行在应用程序中对数据结构进行的各种操作。 Redis默认是在内存中(in memory)存储其全部内容，只是周期性地将内容的快照存储到磁盘。这使得Redis出奇的快，但假如数据库奔溃了，就会对数据造成一些损失，同时也意味着必须有足够的RAM存储这个数据库。 图图数据库几乎就是数据结构数据库的一个特定实现，因为图本就是一种数据库。区别是图数据库不再是基于键值，数据是作为图的节点和边存储的。图数据库不是用键来查询值，而是给出根节点的句柄，然后就可以遍历整个图以找到需要的节点或边。 图数据库的优势：存储图或树形的数据。如一个社交图(social graph)。 常见图数据库包含：Neo4j、HyperGraphDB、InfoGrid、VertexDB。 面向文档面向文档的数据库又类似于键值数据库，但值不再是字节、字符串、列表、集合，而是文档。文档作为JSON(BSON)对象存储，本质上是一种哈希表或字典。这些值都想相同的结构，意味着可以用查询来探测这种结构，并只返回所需要的文档。这种查询能力是建立在通过键来查找文档的能力之上的。 常见面向文档数据库： MongoDB、CouchDB。 高度分布高度分布的数据库多少有些不同——有些本质上更接近于键值存储，其它则像大型的多维哈希图。 HBase、Cassandra是高度分布式数据库。 某些细节注意这些数据库之间的一些相似性，以及所做决策是如何影响系统可操作性的。 CassandraCassandra是一个高度分布数据库。 它有一些关键概念： 认为写比读更难于伸缩，所以它专门为写操作做了大量优化 认为不应该存在单一故障点任何数据可以写入到集群内的任何一个节点，而且读也一样。任何接收到请求的节点都可以，并且将会吧请求转发到合适的节点。 HBaseHBase选择一致性和可用性作为自己的核心价值。这样的结果，导致了在某些网段、集群无法实现优雅的恢复。作为这种牺牲的补偿，HBase有很强的一致性，保证写入一结束，写入的值就立即可以读取。 RiakRiak实现了向量时钟(vector clocks)，一些高度分布的数据库都没有实现——这些数据库选择了依赖于更为简单的基于时间戳的技术。 向量时钟是一种分布式系统中的机制，用于生成偏序事件。使用向量时钟，解决发生在两个独立的不同节点中的相同值的冲突就变得非常简单。从Riak客户端的角度来看，每个客户实例在Riak集群中执行一个动作时，都应该有一个唯一的标识(token)(连同其接收到的向量时钟一起)。然后，客户读取数据时，就可以看到向量时钟和数据值，使用包含的信息连接两个结果，从而将正确的版本写会数据库。 Riak也不存在单一故障点。 CouchDBCouchDB对世界的看法是一致的：所有东西都是文档，而且都通过RESTful HTTP来访问。CouchDB可以在数据库中直接存储静态媒体，它实际上是允许将整个应用程序都存储在数据库中的。CouchDB的数据模型很新颖，即数据以一种只附加的B树进行存储。 MongoDBMongoDB是一个面向文档的数据库，文档格式使用BSON——一种类似于JSON对象的二进制规范。MongoDB是用C++写的，因而有很高的性能。 所有能用SQL做的事情也能用MongoDB查询表达式来做。MongoDB与以SQL数据库相同的方式支持索引，同时这些索引也强制了唯一性。 MongoDB有一个mongostat命令来查看数据库状态。 有好几种MongoDB备份方式： 停掉数据库，复制数据文件 锁定数据库写入，复制数据文件，解除锁定 使用mongodump，将数据库转存到一个二进制文件中 可以设置一个从服务器，在从服务器上进行备份，而不是主服务器上 RedisRedis(remote dictionary server)，远程字典服务器。通过INFO可查看相关信息。 不管你将Redis运行在快照模式(rdb)还是只附加模式(aof)上，都可以简单地调用rsync实现备份。 如何高枕无忧企业持续规划(Business Continuity Planning)BCP。BCP简单最简单来说，就是什么都是两份。当然，两套设备间的失效转移必须完全自动化。 术语集中于BCP计划的高可用部分：保证站点正常工作。即使在高可用性领域，也有各种各样的技术，从热/热(Hot/Hot)、热/暖(Hot/Warm)、热/冷(Hot/Cold)到灾难恢复。 热/热是高可用性的最高级别。用户可以从任意的数据中心使用全部的应用程序。读和写可以发生在任何地方。折让自动的故障转移变得非常简单，但它不是万能的。你想必须思考如何处理数据一致性的问题。 热/暖是一种很好的方式，如果你不能容忍数据的不一致性的话。很多应用有大量的读操作，仅偶尔写一下(但很重要)。在这种情况下，区别处理这两种操作是有意义的。 热/冷让我害怕。这种架构将读写流量送到单一地点，而让另一个相同的部署在遥远的地平线上闲置。它容易建立，但价值很低。 灾难恢复是最差的技术，本质上是雾件(vaporware)。它的本意不是在平常的时候保护你，而是在大的灾难发生时给你提供重建的选项。 影响持续时间对事件持续时间当灾难来袭时，所有你需要考虑的是将用户流量以最快速度转移，离开问题区域。你需要立即降低影响。不要过于担心根源问题的修复，一旦将影响制止住，会有很多时间来解决这次事故。 怎样才能将流量从问题站点转出呢？通常方案是使用全局负载均衡(Global Server Load Balancing)GSLB。这实际是一个动态的授权DNS服务器，他能够根据相关因素对同一域名给出不同的IP地址。 数据中心数量我们知道数据中心会失效，所以你至少需要两个。这就够了吗？三个或更多是不是会好一些？这取决于三个因素，成本、复杂性和性能。 逐渐失效当数据中心出现局部问题(partial problem)时，不要等它解决从而希望你不需要撤离，立即导出复制数据！ 不信赖任何人正如最可靠的数据中心也会时不时宕机，你可以预期即使最好的第三方供应商，偶尔也会有问题。就是你不能完全信赖一个服务提供商。 故障测试转移通过早期和经常的测试，获取经验，以便当灾难袭来时，不会手忙脚乱，而是立即做出正确的事情。 监控和历史模式你要知道日、周、月的流量模式。如果清楚正常流量中的不寻常处，你就不会在切换、迁移或升级时感到惊讶。确保监控包括周对周的图形和趋势。 高枕无忧如果你能够事先有计划，能够解决大的问题，并且在日常工作中操练故障转移，则平台任何部分的失效将会变成容易处理的事件，而不是危机。 March 25, 2018 11:32 AM]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>Operations</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《经济学原理》读书笔记]]></title>
    <url>%2F2018%2F02%2F23%2F%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[参考： 《经济学原理-微观/宏观》 曼昆： https://book.douban.com/subject/26435630/ 学习指南图微观经济学:第1篇到第7篇，即第1章到第22章。 第1篇： 导言 第1章： 经济学十大原理 第2章： 像经济学家一样思考 第3章： 相互依存性和贸易的好处 第2篇： 市场如何运行 第4章： 供给与需求的市场力量 第5章： 弹性及其应用 第6章： 供给、需求和政府策略 第3篇： 市场和福利 第7章： 消费者、生产者与市场效率 第8章： 应用： 赋税的代价 第9章： 应用： 国际贸易 第4篇： 公共部门经济学 第10章： 外部性 第11章： 公共物品和公共资源 第12章： 税制的设计 第5篇： 企业行为与产业组织 第13章： 生产成本 第14章： 竞争市场上的企业 第15章： 垄断 第16章： 垄断竞争 第17章： 寡头 第6篇： 劳动市场经济学 第18章： 生产要素市场 第19章： 收入与歧视 第20章： 收入不平等与贫困 第7篇： 深入研究的论题 第21章： 消费者选择理论 第22章： 微观经济学前沿 宏观经济学：从第8篇到第13篇，即第23章到第36章。 第8篇： 宏观经济学的数据 第23章： 一国收入的衡量 第24章： 生活费用的衡量 第9篇： 长期中的真实经济 第25章： 生产与增长 第26章： 储蓄、投资和金融体系 第27章： 金融学的基本工具 第28章： 失业 第10篇： 长期中的货币与物价 第29章： 货币制度 第30章： 货币增长与通货膨胀 第11篇： 开放经济的宏观经济学 第31章： 开放经济的宏观经济学基本概念 第32章：开放经济的宏观经济理论 第12篇： 短期经济波动 第33章： 总需求与总供给 第34章： 货币政策和财政政策对总需求的影响 第35章： 通货膨胀与失业之间的短期权衡和取舍 第13篇： 最后的思考 第36章： 宏观经济政策的六个争论问题 阿尔弗雷德·马歇尔在《经济学原理》中写道经济学是一门研究人类一般生活事务的学问。 应当学习经济学的原因如下： 有助于你理解你所生活在其中的世界 使你更加精明的参与经济 使你更好地理解经济政策的潜力与局限性 经济学原理可以运用到生活中的方方面面 经济学领域的伟大洞见，如亚当·斯密的看不见的手的概念、大卫·李嘉图的比较优势原理，以及约翰·梅纳德·凯恩斯的总需求理论 导言经济学十大原理经济(economy)这个词来源于希腊语oikonomos，意思是“管理一个家庭的人”。 一个家庭面临着许多决策，同样，一个社会也面临着许多决策。 由于资源是稀缺的，社会资源的管理就尤为重要。 稀缺性(scarcity):社会资源的有限性 经济学(economics):研究社会如何管理自己的稀缺资源 人们如何做出决策由于一个经济的行为反映了组成这个经济的个人的行为，所以个人就需要做出决策。 人们面临权衡取舍 效率(efficiency):社会能从其稀缺资源中得到最大利益的特性 平等(equlity):经济成果在社会成员中平均分配的特性 作出决策就是要求我们在一个目标与另一个目标之间进行权衡取舍。 当人们组成社会时，他们会面临不同的权衡取舍。经典的权衡取舍是在大炮与黄油之间。 社会面临的另一种权衡取舍是在效率与平等之间。 然而，认识到人们面临权衡取舍本身并没有告诉我们人们将会或应该做出什么决策。 某种东西的成本是为了得到这种东西所放弃的东西 机会成本(opportunity cost):为了得到某种东西所必须放弃的东西 由于人们面临着权衡取舍，所以做决策就需要比较可供选择的行动方案的成本与收益。 理性人考虑边际量 理性人(rational people):系统而有目的地尽最大努力实现其目标的人 边际变动(marginal change):对行动计划的微小增量调整 边际成本(marginal cose):对行动计划调整所带来的成本 边际收益(marginal benefit):对行动计划调整所带来的的收益 边际决策(marginal decision):选择哪种决策 人们会对激励做出反应 激励(incentive):引起一个人做出某种行为的某种东西 在经济学研究中，激励起着中心作用。 市场上的高价格提供了买者少消费而卖者多生产的激励。价格对消费者和生产者行为的影响对于市场经济如何配置稀缺资源是至关重要的。 政府决策者决不能忘记激励，因为许多政策改变了人们面临的成本或收益，从而也改变了人们的行为。 在分析任何一种政策时，我们不仅应该考虑它的直接影响，而且还应该考虑它通过激励产生的不太明显的间接影响。如果政策改变了激励，那就会使人们改变自己的行为。 人们如何互相影响我们的许多决策不仅影响了我们自己，还会影响其他人。 贸易可以使每个人的状况都变得更好思考国家之间的竞争的想法很容易产生误导。美国与中国之间的贸易并不像体育比赛一样，一方赢而另一方输。实际上，事实正好相反：两国之间的贸易可以使两个国家的状况都变得更好。 贸易使每个人都可以专门从事自己最擅长的活动，无论它是耕种、做衣服还是盖房子。通过与其他人的贸易，人们可以以较低的成本获得各种各样的物品和服务。 国家和家庭一样，也能从相互贸易中获益。贸易可以使各国可以专门从事自己最擅长的活动，并享有种类更多的物品与服务。美国人和英国人、法国人一样，在世界经济中既是我们的竞争对手，又是我们的伙伴。 市场通常是组织经济活动的一种好方法 市场经济(market economy):当许多企业和家庭在物品与服务市场上相互交易时，通过他们的分散决策配置资源的经济 看不见的手(invisible hand): 利己心(self-interest): 中央计划经济国家运行的前提假设是，政府官员能够最佳地配置经济中稀缺资源。这些中央计划者决定，生产什么物品与服务、生产多少，以及谁生产和消费这些物品与服务。支撑中央计划经济的理论是，只有政府才能以促进整个社会经济福利的方式组织经济活动。 大部分曾经是中央计划经济的国家已经放弃了这个制度，代之以发展市场经济。在市场经济中，中央计划者的决策被数千百万企业和家庭的决策所取代。 在市场经济中，没有一个人追求整个社会的经济福利。自由市场包括大量物品与服务的许多买者与卖者，而所有的人都主要关心自己的福利。 经济学家亚当·斯密在《国富论》中提出了全部经济学中最著名的观察结果：“家庭和企业在市场上相互交易，他们仿佛被一只看不见的手所指引，并导致了合意的市场结果。” 价格就是看不见的手用来指引经济活动的工具。作为买者与卖者决策的结果，市场价格既反映了一种物品的社会价值，也反映了生产该物品的社会成本。斯密的重要洞察是，价格会自发调整，指引这些单个买者和卖者达到某种结果，该结果在大多数情况下会实现整个社会福利的最大化。 斯密的观点有一个重要的推论：当政府阻止价格根据供求状况自发调整时，它就限制了看不见的手对组成经济的千百万家庭和企业的决策进行协调的能力。这个推论解释了为什么税收对资源配置有不利的影响：由于税收扭曲了价格，从而也扭曲了家庭和企业的决策。这个推论还解释了像租金控制这类直接控制价格的政策所引起的巨大危害。而且，这个推论解释了中央计划经济的失败。在中央计划经济国家，价格并不是在市场上决定的，而是由中央计划者规定的。这些计划者缺乏关于消费者爱好和生产者成本的必要信息，而在市场经济中这些信息都反映在价格上。中央计划者之所以失败，是因为他们在管理经济时把市场这只看不见的手绑起来了。 亚当·斯密描述了市场经济中人们如何相互影响： 人类几乎随时随地都需要同胞的协助，要想仅仅依赖他人的恩惠，那是绝对不行的。他如果能够刺激他人的利己心，使其有利于他，并告诉其他人，给他做事是对他们自己有利的，那么他要达到目的就容易得多了。··· ···请给我们我所要的东西吧，同时，你也可以获得你所要的东西：这句话是交易的通义。我们所需要的相互帮助，大部分是依照这个方法取得的。我们每天所需的食物和饮料，不是出自屠户、酿酒师或面包师的恩惠，而是出自他们利己的打算。我们不说唤起他们利他心的话，而说唤起他们利己心得话。我们不说自己有需要，而说对他们有利。社会上，除乞丐外，没有一个人愿意全然靠别人的恩惠过活… …每一个人··· ···既不打算促进公共的利益，也不知道自己是在何种程度上促进那种利益··· ···他所盘算的也只是他自己的利益。在这种场合下，像在其他许多场合一样，他受着一只看不见的手的引导，去尽力达到一个并非他本意想要达到的目的。也并不因为不是出于本意，就对社会有害。他追求自己的利益，往往使他能比在真正处于本意的情况下更有效地促进社会的利益。 斯密是说，经济参与者受利己心所驱动，而市场上这只看不见的手指引这种利己心去促进总体的经济福利。 政府有时可以改善市场结果 产权(property rights):个人拥有并控制稀缺资源的能力 市场失灵(market failure):市场本身不能有效的配置资源的情况 外部性(externality):一个人的行为对旁观者福利的影响外部性的经典例子是污染 市场势力(market power):单个经济活动者(或某个经济活动小群体)对市场价格有显著影响的能力 我们需要政府的原因之一是：只有在政府实施规则并维持对市场经济至关重要的制度时，看不见的手才能施展其魔力。最重要的是，市场经济需要实施产权制度，以便个人可以拥有和控制稀缺资源。我们都依靠政府提供的警察和法律来实施我们对自己生产出来的东西的权利——而看不见的手依靠我们实施自己权利的能力。 然而，我们需要政府的另一个原因是：看不见的手是强有力的，但并不是无所不能的。政府干预经济并改变人们自己选择的资源配置的原因有两类：促进效率和促进公平。这就是说，大多数政策的目标要么是把经济蛋糕做大，要么是改变这个蛋糕的分割方式。 在存在外部性或市场势力的情况下，设计良好的公共政策可以提高经济效率。 即使看不见的手带来了有效率的产出，他也不能消除经济福利上巨大的不对称。根据某种政治哲学，这种不平等要求政府进行干预。实际上，许多公共政策，例如所得税和福利制度的目标就是要实现更平等的经济福利分配。 我们说政府有时可以改善市场结果并不意味着它总会这样。公共政策并不是天使制定的，而是由不完善的政治程序制定的。有时所设计的政策只是为了有利于政治上有权势的人；有时政策是由动机良好但信息不充分的领导人制定的。 整体经济如何运行决策和相互影响共同组成了经济。 一国的生活水平取决于它生产物品与服务的能力 生产率(productivity):每单位劳动投入所生产的物品与服务数量 世界各国生活水平的差别是惊人的。随着时间的推移，生活水平的变化也是巨大的。 几乎所有的生活水平的差别都可以归因于各国生产率的差别。 生产率和生活水平之间的基本关系是简单的，但它的意义却是深远的。如果生产率是生活水平的首要决定因素，那么，其他因素就应该是次要的。 当政府发行了过多货币时，物价上升 通货膨胀(inflation):经济中物价总水平的上升 在大多数严重或持续通货膨胀的情况下，罪魁祸首是货币量的增长。 当一国政府发行了大量本国货币时，货币的价值就下降了。由于高通货膨胀会让社会付出各种成本，所以世界各国的经济政策制定者都把保持低通货膨胀作为目标之一。 社会面临通货膨胀与失业之间的短期权衡取舍 经济周期(business cycle):就业和经济生产的波动 虽然在长期中，物价水平上升主要是货币增加的结果，但短期中，问题就变得更为复杂更具争议性。 大多数经济学家这样描述货币注入的短期效应： 经济中货币量增加刺激了社会的整体支出水平，从而增加了对物品与服务的需求 需求的增量随着时间的推移，会引起企业提高物价，但同时，它也鼓励企业雇佣更多的工人，并生产更多的产品与服务 服用更多的工人意味着更少的失业 你知道，支出链将以乘数扩大，并带来更高的收入和就业。人们看到了发生了的活动，但他们没有看到本来会发生的活动。 结论经济学十大原理： 人们如何做出决策 人们面临权衡取舍 某种东西的成本是为了得到它所放弃的东西 理性人考虑边际量 人们会对激励做出反应 人们如何相互影响 贸易可以使每个人的状况都变得更好 市场通常是组织经济活动的一种好方法 政府有时可以改善市场结果 整体经济如何运行 一国的生活水平取决于它生产物品与服务的能力 当政府发行了过多的货币时，物价上升 社会面临通货膨胀与失业之间的短期权衡取舍 像经济学家一样思考每个研究领域都有自己的语言和思考方式。经济学家也一样。供给、需求、弹性、比较优势、消费者剩余和无谓损失——这些术语也是经济学家语言的一部分。 作为科学家的经济学家先提出理论，再收集数据，然后分析数据，以努力证明或否定他们的理论。 科学方法：观察、理论和进一步观察在经济学研究中，进行实验往往是不可能的。通常不得不使用这个世界向他们提供的数据。为了寻找实验室实验的替代品，经济学家十分关注历史所提供的自然实验。 假设的作用当我们在研究政策变动在长短不同时间中的影响时，就会做出不同的假设。 经济模型经济学家也用模型来了解世界，但不是塑料模型，而通常是由图形和方程组成的模型。 第一个模型：循环流量图 循环流量图(circular-flow diagram):一个说明货币如何通过市场在家庭与企业之间流动的直观经济模型 生产要素(production factors):劳动、土地、资本等投入品被称为生产要素 企业用生产要素来生产产品和服务，家庭则拥有生产要素并消费企业生产的物品与服务。家庭与企业之间相互交易。 第二个模型：生产可能性边界 生产可能性边界(production possibilities frontier)：表示在可得到的生产要素与生产技术既定时，一个经济所能生产的产品数量的各种组合的图形。 由于资源是稀缺的因此并不是每一种想象的结果都是可行的。生产可能性边界表明了社会所面临的一种权衡取舍。 生产可能性边界表明在某一特定时期内生产不同物品之间的权衡取舍，但随着时间的推移，这种权衡取舍可以改变。生产可能性边界简化了复杂的经济，以便强调一些基本但极为重要的思想： 稀缺性、效率、权衡取舍、机会成本和经济增长。 微观经济学与宏观经济学尽管微观经济学和宏观经济学之间存在固有的联系，但这两个领域仍然是不同的。 微观经济学(micro economics)：研究家庭和企业如何做出决策，以及它们如何在市场上相互交易的学科。 宏观经济学(macro economics)：研究整体经济现象，包括通货膨胀、失业和经济增长的学科。 作为政策顾问的经济学家当经济学家试图去解释世界时，他们是科学家；当经济学家试图去帮助改变世界时，他们是政策顾问。 实证分析与规范分析一般来说，关于世界的表述有两种类型： 实证表述(positive statements)：试图描述世界是什么样子的观点。 规范表述(normative statements)：试图描述世界应该是什么样子的观点。 确定什么是好策略或什么是坏策略不仅仅是一个科学问题，它还涉及我们对伦理、宗教和政治哲学的看法。 经济学家意见分歧有两个基本原因： 经济学家可能对世界如何运行的不同实证理论的正确性看法不一致 经济学家可能有不同的价值观，因此对政策应该努力实现的目标有不同的规范观点 相互依存性与贸易的好处人们向你和其他消费者提供他们生产的物品与服务，是因为他们也得到了某种回报。 一个现代经济寓言每个人都可以通过专门从事自己最擅长的活动并从相互叫中获益。但是，当某个人在生产每一种物品上都较为擅长时，贸易的好处就不那么明显了。 生产可能性专业化和贸易 比较优势： 专业化的动力绝对优势 绝对优势(absolute advantage)：一个生产者用比另一个生产者更少的投入生产某种物品的能力。 机会成本与比较优势 机会成本(opportunity cost)：为了得到某种东西所必须放弃的东西。 比较优势(comparative advantage)：一个生产者以低于另一个生产者的机会成本生产某种物品的能力。 尽管一个人有可能在两种物品的生产上都具有绝对优势，但一个人却不可能在两种物品的生产上都具有比较优势。 比较优势与贸易专业化和贸易的好处不是基于绝对优势，而是基于比较优势。当每个人专门生产自己有比较优势的物品时，经济的总产量就增加了，经济蛋糕的变大可用于改善每个人的状况。 贸易可以使社会上的每个人都获益，因为它使人们可以专门从事他们具有比较优势的活动。 贸易的价格对从贸易中获益的双方而言，他们进行贸易的价格在两种机会成本之间。 比较优势的应用美国应该与其他国家进行贸易吗 进口品(imports)：在国外生产而在国内销售的物品。 出口品(exports)：在国内生产而在国外销售的物品。 每个国家都有许多具有不同利益的居民。即使国际贸易可以使国家作为一个整体的状况变好，但也会使一些人的状况变坏。但国际贸易并不像战争，在战争中有些国家是胜利者，而其他国家是失败者。贸易使所有国家都可以实现更大的繁荣。 市场如何运行 供给与需求的市场力量供给与需求是经济学家最经常——而且有充分的理由使用的两个词。供给与需求是使市场经济运行的力量。它们决定了每种物品的产量及其出售的价格。 市场与竞争 市场(market)：由某种物品或服务的买者与卖者组成的一个群体。 竞争市场(competitive market)：有许多买者与卖者，以至于每个人对市场价格的影响都微乎其微的市场。 我们假设市场是完全竞争的。为了达到此竞争的最高形式，一个市场必须具备两个特征： 可供销售的物品时完全相同的 买者与卖者人数众多，以至于没有任何一个买者或卖者可以影响市场价格 但是，并不是所有物品与服务都在完全竞争市场上出售。一些市场可能只有一个买者，而且这个卖者决定价格。这样的卖者被称为垄断者还有一些市场介于完全竞争和垄断这两种极端形式之间。 需求 价格与需求量之间的关系 需求量(quantity demanded)：买者愿意斌企鹅能够购买的一种物品的数量。 需求定理(law of demand)：认为在其他条件不变时，一种物品的价格上升，对该物品的需求量减少的观点。 需求表(demand schedule)：表示一种物品的价格与需求之间的关系的表格。 需求曲线(demand curve)：表示一种物品的价格与需求量之间关系的图形。 正常物品(normal good)：在其他条件相同时，收入增加引起需求量增加的物品。 低档物品(inferior good)：在其他条件相同时，收入增加引起需求量减少的物品。 替代品(substitutes)：一种物品价格的上升引起另一种物品需求量的增加的两种物品。 互补品(complements)：一种物品价格的上升引起另一种物品需求量的减少的两种物品。 影响买者的变量： 收入 价格 爱好 预期 其它 供给 价格与供给量之间的关系 供给量(quantity supplied)：卖者愿意并且能够出售的一种物品的数量。 供给定理(law of supply)：认为在其他条件不变时，一种物品的价格上升，该物品的供给量增加的观点。 供给表(supply schedule)：表示一种物品的价格与供给量之间的关系的表格。 供给曲线(supply curve)：表示一种物品的价格与供给量之间关系的图形。 使供给曲线移动的一些变量： 价格 技术 预期 卖者的数量 其它 供给与需求的结合 均衡(equilibrium)：市场价格达到使供给量与需求量相等的水平时的状态。 均衡价格(equilibrium price)：使供给与需求平衡的价格。 均衡数量(equilibrium quantity)：均衡价格下的供给量与需求量。 过剩(surplus)：供给量大于需求量的状态。 短缺(shortage)：需求量大于供给量的状态。 供求定力(law of supply and demand)：认为任何一种物品的价格都会自发调整，使该物品的供给与需求达到平衡的观点。 价格如何配置资源在市场经济中，价格是配置稀缺资源的机制。 弹性假设某件事情使得汽油价格上升，那么消费者将少买汽油。那么汽油的消费量会减少多少呢？——这个问题可以用弹性的概念来回答。 需求弹性 弹性(elasticity)：衡量需求量或供给量对某种决定因素的变动的反应程度的指标。 需求价格弹性(price elasticity of demand)：衡量一种物品需求量对其价格变动反应程度的指标，用需求量变动百分比除以价格变动百分比来计算。 总收益(total revenue)：一种物品的买者支付而卖者得到的量，用该物品的价格乘以销售量来计算。 需求收入弹性(income elasticity of demand)：衡量一种物品需求量对消费者收入变动反应程度的指标，用需求量变动百分比除以收入变动百分比来计算。 需求交叉价格弹性(cross-price elasticity of demand)：衡量一种物品需求量对另一种物品价格变动的反应程度的指标，用第一种物品需求量变动百分比除以第二种物品价格变动百分比来计算。 富有弹性 缺乏弹性 单位弹性 完全无弹性 完全有弹性 替代品 必需品 奢侈品 市场的定义 时间范围 供给弹性 供给价格弹性(price elasticity of supply)：衡量一种物品供给量对其价格变动反应程度的指标，用供给量变动百分比除以价格变动百分比来计算。 供给、需求和弹性的应用 农业的好消息可能对农民来说是坏消息吗 为什么石油输出国组织不能保持石油的高价格 禁毒增加了还是减少了毒品相关的犯罪 供给、需求与政府政策当决策者认为一种物品或服务的市场价格对买者或卖者不公平时，通常会实施价格控制。但这些控制政策本身也会引起不公平。决策者用税收为公共目标筹集资金并影响市场结果。 价格控制 价格上限(price ceiling)：出售一种物品的法定最高价格 价格下限(price floor)：出售一种物品的法定最低价格 由于任何一种物品的买者总希望价格更低，而卖者总希望价格更高。所以，这两个群体的利益就会产生冲突 当政府对竞争市场实行限制性价格上限时，就产生了物品的短缺，而且，卖者必须在大量潜在买者中配给稀缺物品。与此相比，一个自由竞争市场中的配给机制既有效率又是客观的。 价格有平衡供求从而协调经济活动的关键作用。当决策者通过法令确定价格时，他们就模糊了正常情况下指引社会资源配置的信号。 价格控制的目标往往是帮助穷人。但价格控制往往损害了那些它本想要帮助的人。可以用除了控制价格以外的其他方法来帮助那些需要帮助的人(如补贴或减税)。但是，税收也是有成本的。 税收 税收归附(塔下 incidence)：税收负担在市场参与者之间进行分配的方式。 当政府对一种物品征税时，谁实际承担了税收负担？无论税收是向买者征税还是想卖者征税，这一买者价格与卖者价格之间的楔子都是相同的。在这两种情况下，这个楔子都使供给曲线和需求曲线的相对位置移动。在新均衡时，都是买者与卖者分摊税收负担。无论向谁征税，一旦市场达到新均衡，都是买者与卖者分摊税收负担。 经济受两种规则体系支配： 供求规律和政府制定的法规。 市场和福利消费者、生产者与市场效率买者总想少付些钱，而卖者总想多买些钱。 福利经济学(welfare economics)研究资源配置如何影响经济福利的一门学问。 消费者剩余 支付意愿(willingness to pay)买者愿意为某种物品支付的最高量。 消费者剩余(consumer surplus)买者愿意为一种物品支付的量减去其为此实际支付的量。 生产者剩余 成本(cost)卖者为了生产一种物品而必须放弃的所有东西的价值。 生产者剩余(producer surplus)卖者出售一种物品得到的量减去其生产成本。 市场效率 总剩余消费者剩余和生产者剩余的总和，称为总剩余。 效率(efficiency)资源配置使社会所有成员得到的总剩余最大化的性质。 平等(equality)在社会成员中平均地分配经济成果的性质。 市场势力影响价格的能力，如市场上一小群能够控制市场价格的买卖者。 外部性市场的副作用，如污染。 在本质上，从市场贸易中获取的利益就像一块要在市场参与者间分配的蛋糕。效率问题涉及的是蛋糕是否尽可能地做大了。平等问题涉及的是如何把这块蛋糕切成小块，以及如何在社会成员中进行分配。 市场失灵是指一些不受管制的市场不能有效地配置资源。当出现市场失灵时，公共政策有可能纠正这些问题并提高经济效率。 赋税的代价买者和买者因税收遭受的损失大于政府筹集到的收入。 赋税的无谓损失 无谓损失(deadweight loss)市场扭曲(如税收)引起的总剩余减少。 税收引起的无谓损失是因为它使买者和卖者不能实现某些贸易的好处。 决定无谓损失的因素供给和需求的价格弹性越大，税收的无谓损失也就越大。 税收变动时无谓损失和税收收入税收很少长期保持不变。 当政府对一种商品的买者或卖者征税时，社会就损失了某些市场效率的好处。税收给市场参与者带来了损失，不仅是因为税收将资源从市场参与者手中转到政府手中，还因为税收改变了激励，并扭曲了市场结果。 国际贸易许多企业发现，由于面临可以以低成本生产高质量物品的外国竞争者，要通过生产某种产品获得利润已经越来越困难了。因此，他们迁移或关闭了工厂。 决定贸易的因素 世界价格(world price)一种物品在世界市场上通行的价格。 如果某种物品的世界价格高于国内价格，那么，一旦允许贸易，此国就会变成此物品出口国；反之，则变为此物进口国。各国之间的贸易最终要建立在比较优势的基础之上。 贸易的赢家与输家 关税(tariff)对在国外生产而在国内销售的物品征收的一种税。 当一国允许贸易并成为一种物品的出口国时，国内该物品的生产者的状况变好了，而国内该物品消费者的状况变坏了。 从赢家收益超过了输家损失的意义上说，贸易使一国的经济福利增加了。 当一国允许贸易并成为一种物品的进口国时，国内该物品消费者的状况变好了，而国内该物品生产者的状况变坏了。 从赢家收益超过了输家损失的意义上说，贸易使一国的经济福利增加了。 国际贸易的其它好处： 增加了物品的多样性 通过规模经济降低了成本 增加了竞争 加强了思想交流 关税减少了进口量，并使国内市场向没有贸易时的均衡移动 各种限制贸易的观点 工作岗位论贸易反对者会说，与其他国家进行贸易消灭了国内的一些工作岗位。但自由贸易在消灭了一些工作岗位的同时，也创造了一些工作岗位。 国家安全论一些行业收到来自其他国家的竞争威胁时，贸易反对者会说，该行业对国家安全是至关重要的。处于对国家安全的合理考虑，保护关键行业可能是合理的。但也应该由国家机构所提出。 幼稚产业论会说，应实行暂时性贸易限制，以有助于该产业的成长。这也难以实施。如何确定哪个产业是新兴的幼稚产业？ 不公平竞争论一种常见的观点是，如果不同国家的企业服从于不同的法律和管制，那么，让企业在国际市场上进行竞争就是不公平的。 作为讨价还价筹码的保护论当与自己的贸易伙伴讨价还价时，贸易限制可能还是有用的。 大多数经济学家支持自由的国际贸易，他们认为自由贸易是一种有效配置生产的方法，并提高了两国的生活水平。 公共部门经济学 外部性 外部性(externality)一个人的行为对旁观者福利的无补偿的影响 正外部性这种影响是有利的 负外部性这种影响是不利的 栗子： 汽车尾气 修复历史建筑 狂吠的狗 新技术的研究 外部性和市场无效率 外部性内在化(internalizing the externality)改变激励，以使人们考虑到自己行为的外部效应 政府可以通过对负外部性的物品征税和给予有正外部性的物品补贴来使外部性内在化 针对外部性的公共政策 管制政府可以通过规定或禁止某些行为来解决外部性。 矫正税旨在引导私人决策者考虑负外部性引起的社会成本的税收 补贴 可交易的污染许可证 外部性的私人解决方法 科斯定理(Coase theorem)认为如果私人各方面可以无成本地就资源配置进行协商，那么，他们就可以自己解决外部性问题的观点 交易成本(transaction cost)各方在达成协议与遵守协议过程中所发生的成本 公共物品和公共资源 不同类型的物品 排他性(excludability)一种物品具有的可以阻止一个人使用该物品的特性 消费品中的竞争性(rivalry in consumption)一个人使用一种物品将减少其他人对该物品的使用的特性 私人物品(private goods)既有排他性又有消费竞争性的物品 公共物品(public goods)即无排他性又无消费竞争性的物品 公共资源(common resources)有消费竞争性但无排他性的物品 俱乐部物品(club goods)有排他性但无消费竞争性的物品 公共物品产权的重要性 搭便车者(free rider)得到一种物品的利益但避免为此付费的人 一些重要的公共物品 国防 基础研究 反贫困 成本收益分析(cost-benefit analysis)比较提供一种公共物品的社会成本与社会收益的研究 公共资源 公共悲剧(Tragedy of the Commons)一个说明从整个社会的角度看，为什么公共资源的使用大于合意的水平的寓言 一些重要的公共资源 清洁的空气和水 拥堵的道路 野生动物 税制的设计在这个世界上除了死亡和税收以外，没有什么事情是确定无疑的。 政府的财政状况政府的税收占国民收入的多少？ 预算赤字(budget deficit)政府支出大于政府收入 预算盈余(budget surplus)政府收入大于政府支出 税收和效率税收会引起两个成本，良好的税收政策正是要使其最小化： 当税收扭曲了人们做出的决策时引起的无谓损失 纳税人在遵照税法纳税时承担的管理负担 收入税 消费税 平均税率(average tax rate)支付的总税收除以总收入 边际税率(marginal tax rate)增加1美元收入所支付的额外税收 定额税(lump-sum tax)对每个人等量征收的税收 税收和平等 受益原则(benefit principle)认为人们应该根据他们从政府服务中得到的利益来纳税的思想 支付能力原则(ability-to-pay principle)认为应该根据一个人可以承当的负担来对这个人征税的思想 纵向平等(vertical equity)主张支付能力更强的纳税人应该缴纳更多税收的思想 横向平等(horizontal equity)主张有相似支付能力的纳税人应该缴纳等量税收的思想 比例税(proportional tax)高收入纳税人和低收入纳税人缴纳收入中相同比例的税收 累进税(progressive tax)高收入纳税人缴纳的税收在收入中的比例高于低收入纳税人的这一比例 累退税(regressive tax)高收入纳税人缴纳的税收在收入中的比例低于低收入纳税人的这一比例 企业行为与产业组织 生产成本经济是由成千上万个生产你每天享用的物品与服务的企业(大型或小型)组成的。 产业组织研究企业有关价格和数量的决策如何取决于它们所面临的市场条件。 企业成本是其生产和定价决策的一个关键决定因素。 生么是成本总收益、总成本和利润 总收益(total revenue)企业出售其产品所得到的货币量 总成本(total cost)企业用于生产的投入品和市场价值 利润(profit)总收益减去总成本 作为机会成本的成本 显性成本(explicit costs)需要企业支出货币的投入成本 隐性成本(implicit costs)不需要企业支出货币的投入成本 作为一种机会成本的资本成本 经济利润与会计利润 经济利润(economic profit)总收益减去总成本，包括显性成本与隐性成本 会计利润(accounting profit)总收益减总显性成本 生产与成本 生产函数 生产函数(production function)用于生产一种物品的投入量与该物品产量之间的关系 边际产量(marginal product)增加一单位投入所引起的产量增加 边际产量递减(diminishing marginal product)一种投入的边际产量随着投入量增加而减少的特征 从生产函数到总成本曲线 成本的各种衡量指标 固定成本与可变成本 固定成本(fixed costs)不随着产量变动而变动的成本 可变成本(variable costs)随着产量变动而变动的成本 平均成本与边际成本 平均总成本(average total cost)总成本除以产量 平均固定成本(average fixed cost)固定成本除以产量 平均可变成本(average variable cost)可变成本除以产量 边际成本(marginal cost)额外一单位产量所引起的总成本的增加 成本曲线及其形状 有效规模(efficient scale)使平均总成本最小的产量 只要边际成本小于平均总成本，平均总成本就下降；反之，则上升。边际成本曲线与平均总成本曲线在平均总成本曲线的最低点处相交。 典型的成本曲线 三个特征： 随着产量增加边际成本最终会上升 平均总成本曲线是U形的 边际成本曲线与平均总成本曲线在平均总成本曲线的最低点处相交 短期成本与长期成本 短期与长期平均总成本之间的关系 规模经济与规模不经济 规模经济(economics of scale)长期平均总成本随产量增加而减少的特性 规模不经济(diseconomics of scale)长期平均总成本随产量增加而增加的特性 规模收益不变(constant returns to scale)长期平均总成本在产量变动时保持不变的特性 实际上，运用专业化实现规模经济是现代社会之所以这样繁荣的原因之一。 竞争市场上的企业如果每个买者和卖者与市场规模相比都微不足道，从而没有什么能力影响市场价格那么该市场就是竞争性的。于此相反，如果一个企业可以影响它出售的物品的市场价格，我们就说该企业有市场势力。 什么是竞争市场 竞争市场的含义 竞争市场(competitive market)有时又称为完全竞争市场。有几个特征： 市场上有许多买者和许多卖者 各个卖者提供的物品大体上是相同的 企业可以自由地进入或退出市场 竞争企业的收益 平均收益(average revenue)总收益除以销售量对所有企业而言，平均收益等于物品的价格 边际收益(marginal revenue)增加一单位销售量引起的总收益变动对竞争企业而言，边际收益等于物品的价格 利润最大化与竞争企业的供给曲线 利润最大化 边际成本曲线和企业的供给决策 利润最大化的一般规律： 如果边际收益大于边际成本，企业应该增加其产量 如果边际成本大于边际效益，企业应该减少其产量 在利润最大化的产量水平时，边际收益和边际成本正好相等 企业的短期停止营业决策 如果生产能得到的收益小于生产的可变成本，企业就停止营业。 覆水难收和其他沉没成本 沉没成本(sunk cost)已经发生而且无法收回的成本 在做个人决策时，沉没成本的无关性也是很重要的。 企业退出或进入一个市场的长期决策 如果从生产中得到的收益小于它的总成本，企业就应该退出市场。竞争企业的长期供给曲线是边际成本曲线位于平均总成本曲线之上的那一部分。 竞争市场的供给曲线两种情况： 考察有固定数量企业的市场； 考察企业数量会随着老企业退出和新企业进入而变动的市场 垄断可以说微软在Windows软件市场上拥有垄断地位。像微软这样的垄断者没有与之相近的竞争者，因此，它拥有影响其产品的市场价格的力量。竞争企业是价格接受者，而垄断企业是价格决定者。 竞争企业接受市场给定的其产品的价格，并选择供给量，以使价格等于边际成本。与此相比，垄断者收取高于其边际成本的价格。 垄断者对其产品收取高价格并不令人奇怪。垄断者的顾客似乎除了一个支付垄断者收取的价格之外别无选择。一个垄断企业可以控制它出售的物品的价格，但由于高价格会减少其顾客的购买量，因此垄断利润并不是无限的。 由于垄断企业不受竞争限制，有垄断的市场结果往往不符合社会的最佳利益。但政府有时可以改善市场结果。 为什么会产生垄断 垄断企业(monopoly)作为一种没有相近替代品的产品的唯一卖者的企业。 有三个主要形成原因： 垄断资源： 生产所需要的关键资源由单个企业所拥有 政府管制： 政府给予单个企业排他性地生产某种物品或服务的权利 生产流程： 某个企业能以低于大量企业的成本生产产品 专利法或版权法是两个重要的例子。 自然垄断(natural monopoly)由于一个企业能以低于两个或更多企业的成本向整个市场供给一种物品或服务而产生的垄断 垄断者如何做出生产与定价策略 垄断与竞争 垄断者的收益 利润最大化 垄断者的利润 垄断的福利代价 无谓损失 可以在需求曲线与边际成本曲线相交之处找出社会有效率的产量。垄断者生产的产量小于社会有效率的产量。 垄断利润：是一种社会代价吗 价格歧视 价格歧视(price discrimination)以不同的价格向不同顾客出售同一种物品的经营做法。 套利在一个市场上以低价购买一种商品，而在另一个市场上以高价出售，以便从价格差中获利的过程。 价格歧视的例子 电影票 飞机票 折扣券 财务援助 数量折扣 针对垄断的公共政策政府决策者应对垄断： 努力使垄断行业更有竞争性用反托拉斯法增强竞争。反托拉斯法是一部全面的经济自由宪章，其目的在于维护作为贸易的自由和不受干预的竞争。 管制管制垄断者的行为 公有制政府自己经营自然垄断的企业 不作为do nothing 垄断竞争 在垄断和完全竞争之间很多行业介于完全竞争和垄断的极端情况之间的某个位置，经济学家称这种情况为不完全竞争。 寡头(oligopoly)只有少数几个提供相似或者相同产品的卖者的市场结构。 垄断竞争(monopolistic competition)存在许多出售相似但不相同的产品的企业的市场结构。 垄断竞争和寡头一样，也是介于竞争和垄断这两种极端情况之间的一种市场结构。 垄断竞争具有以下特征的市场： 许多卖者： 有许多企业争夺相同的顾客群体 产品存在差别： 每个企业生产的一种产品至少与其他企业生产的这种产品略有不同 自由进入和退出：企业可以无限制地进入或退出一个市场 差别产品的竞争 短期中的垄断竞争企业 长期均衡 垄断竞争与完全竞争 垄断竞争与社会福利 广告在现代经济中，几乎每一天都伴随着铺天盖地的广告。这种行为是垄断竞争(以及某些寡头企业)的一个自然特征。 关于广告的争论 作为质量信号的广告 品牌 垄断竞争，顾名思义，是垄断和竞争的混合。由于垄断竞争企业生产有差别的产品，因此，每个企业都要靠做广告打出自己的品牌来吸引顾客。在某种程度上，广告操纵了消费者的偏好，促成了非理性的品牌忠诚，并抑制了竞争。在更大程度上，广告提供了信息，建立了具有可靠质量的品牌，并促进了竞争。 寡头]]></content>
      <categories>
        <category>Economics</category>
      </categories>
      <tags>
        <tag>Zhang</tag>
        <tag>Economics</tag>
        <tag>经济学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2F2018%2F02%2F08%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[参考： 《鸟哥的Linux私房菜》 正则表达式维基百科 正则表达式介绍正则表达式，又称正规表示式、正规表示法、正规表达式、规则表达式、常规表示法(Regular Expression, 在代码中常简写为regex、regexp或RE）。是计算机科学的一个概念。正则表达式使用单个字符串来描述、匹配一系列匹配某个句法规则的字符串。在很多文本编辑器里，正则表达式通常被用来检索、替换那些匹配某个模式的文本。 正则表达式的POSIX规范，分为两大流派： 基本型正则表达式（Basic Regular Expression，BRE） grep、vi、sed都属于BRE，是历史最早的正则表达式，因此元字符必须转译之后才具有特殊含义 扩展型正则表达式（Extended Regular Express，ERE） egrep、awk则属于ERE，元字符不用转译 正则表达式基本语法一个正则表达式通常被称为一个模式（pattern），用来描述或者匹配一系列匹配某个句法规则的字符串。 大部分正则表达式有如下结构： 选择 |竖线符代表选择(或)，具有最低优先级 数量限定 字符后的数量限定符用来限定前面这个字符允许出现的个数 不加数量限定则代表仅出现一次 常见的数量限定符包括 +、?、* +加号代表前面的字符必须至少出现一次 ( $$$&gt;=1$$$ ) ?问号代表前面的字符最多只可出现一次 ( $$$1&gt;=?&gt;=0$$$ ) *星号代表前面的字符可不出现，也可出现一次或多次 ($$$&gt;=0$$$) 匹配 ()圆括号可以定义操作符的范围和优先度 PCRE表达式全集正则表达式有多种不同的风格。PCRE（Perl兼容正则表达式，Perl Compatible Regular Expression）。适用于Perl或者Python编程语言（grep或者egrep的正则表达式文法是PCRE的子集） 基础正则表达式 字符 描述 \ 转义字符 zhang 匹配文本字符串值zhang . 匹配除\r,\n之外的任何单个字符 竖线l 匹配竖线两边某一个 ^ 匹配输入字符串的开始位置 $ 匹配输入字符串的结束位置 * 匹配前面的子表达式零次或多次 + 匹配前面的子表达式一次或多次 ? 匹配前面的子表达式零次或一次 {n} n是一个非负整数。匹配n次 {n,} n是一个非负整数。至少匹配n次 {n,m} m和n均为非负整数，匹配n-m次 [xyz] 字符集合（character class）。匹配所包含的任意一个字符 [^xyz] 排除型字符集合（negated character classes）。匹配未列出的任意字符 [a-z] 字符范围。匹配指定范围内的任意字符 [^a-z] 排除型的字符范围。匹配任何不在指定范围内的任意字符 [:name:] 增加命名字符类（named character class） [=elt=] 增加当前locale下排序（collate）等价于字符“elt”的元素 [.elt.] 增加排序元素（collation element）elt到表达式中。这是因为某些排序元素由多个字符组成 元字符元字符(meta character)，是一种Perl风格的正则表达式，只有一部分文本处理工具支持它。 字符 描述 \b 匹配一个单词边界，也就是指单词和空格间的位置 \B 匹配非单词边界。“er\B”能匹配“verb”中的“er”，但不能匹配“never”中的“er” \cx 匹配由x指明的控制字符 \d 匹配一个数字字符。等价于[0-9]。注意Unicode正则表达式会匹配全角数字字符 \D 匹配一个非数字字符。等价于[^0-9] \f 匹配一个换页符。等价于\x0c和\cL \n 匹配一个换行符。等价于\x0a和\cJ \r 匹配一个回车符。等价于\x0d和\cM \s 匹配任何空白字符，包括空格、制表符、换页符等等 \S 匹配任何非空白字符。等价于[^ \f\n\r\t\v] \t 匹配一个制表符。等价于\x09和\cI \v 匹配一个垂直制表符。等价于\x0b和\cK \w 匹配包括下划线的任何单词字符。等价于“[A-Za-z0-9_]”。注意Unicode正则表达式会匹配中文字符 \W 匹配任何非单词字符。等价于“[^A-Za-z0-9_]” \ck 匹配控制转义字符。k代表一个字符。等价于“Ctrl-k”。用于ECMA语法 \xnn 十六进制转义字符序列。匹配两个十六进制数字nn表示的字符 \num 向后引用（back-reference）一个子字符串（substring），该子字符串与正则表达式的第num个用括号围起来的捕捉群（capture group）子表达式（subexpression）匹配。其中num是从1开始的十进制正整数，其上限可能是9[注 2]、31、[注 3]99甚至无限。[注 4]例如：“(.)\1”匹配两个连续的相同字符 \n 标识一个八进制转义值或一个向后引用。如果\n之前至少n个获取的子表达式，则n为向后引用。否则，如果n为八进制数字（0-7），则n为一个八进制转义值 \nm 3位八进制数字，标识一个八进制转义值或一个向后引用。如果\nm之前至少有nm个获得子表达式，则nm为向后引用。如果\nm之前至少有n个获取，则n为一个后跟文字m的向后引用。如果前面的条件都不满足，若n和m均为八进制数字（0-7），则\nm将匹配八进制转义值nm \nml 如果n为八进制数字（0-3），且m和l均为八进制数字（0-7），则匹配八进制转义值nml \un Unicode转义字符序列。其中n是一个用四个十六进制数字表示的Unicode字符 扩展正则表达式 字符 描述 ? 非贪心量化（Non-greedy quantifiers）：当该字符紧跟在任何一个其他重复修饰符（*,+,?，{n}，{n,}，{n,m}）后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串 (pattern) 匹配pattern并获取这一匹配的子字符串。该子字符串用于向后引用。所获取的匹配可以从产生的Matches集合得到，在VBScript中使用SubMatches集合，在JScript中则使用$0…$9属性。要匹配圆括号字符，请使用“(”或“)” (?:pattern) 匹配pattern但不获取匹配的子字符串（shy groups)，也就是说这是一个非获取匹配，不存储匹配的子字符串用于向后引用 (?=pattern) 正向肯定预查（look ahead positive assert），在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用 (?!pattern) 正向否定预查(negative assert)，在任何不匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用 (?&lt;=pattern) 反向(look behind)肯定预查，与正向肯定预查类似，只是方向相反 (?&lt;!pattern) 反向否定预查，与正向否定预查类似，只是方向相反 POSIX字符组POSIX字符类(POSIX character class),是一个形如[:…:]的特殊元序列，它用于匹配特定的字符范围。 POSIX字符组 说明 ASCII环境 Unicode环境 [:alnum:] 字母字符和数字字符 [a-zA-Z0-9] [\p{L&amp;}\p{Nd}] [:alpha:] 字母 [a-zA-Z] \p{L&amp;} [:ascii:] ASCII字符 [\x00-\x7F] \p{InBasicLatin} [:blank:] 空格字符和制表符 [ \t] [\p{Zs}\t] [:cntrl:] 控制字符 [\x00-\x1F\x7F] \p{Cc} [:digit:] 数字字符 [0-9] \p{Nd} [:graph:] 空白字符之外的字符 [\x21-\x7E] [^\p{Z}\p{C}] [:lower:] 小写字母字符 [a-z] \p{Ll} [:print:] 类似[:graph:]，但包括空白字符 [\x20-\x7E] \P{C} [:punct:] 标点符号 }~-] [\p{P}\p{S}] [:space:] 空白字符 [ \t\r\n\v\f] [\p{Z}\t\r\n\v\f] [:upper:] 大写字母字符 [A-Z] \p{Lu} [:word:] 字母字符 [A-Za-z0-9_] [\p{L}\p{N}\p{Pc}] [:xdigit:] 十六进制字符 [A-Fa-f0-9] [A-Fa-f0-9] 优先级 优先权 符号 最高 \ 高 ( )、(?: )、(?= )、[ ] 中 *、+、?、{n}、{n,}、{m,n} 低 ^、$、中介字符 次最低 串接，即相邻字符连接在一起 最低 l]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>RegularExpression</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis]]></title>
    <url>%2F2018%2F02%2F05%2FRedis%2F</url>
    <content type="text"><![CDATA[参考: 《Redis官方文档》: http://www.redis.cn/documentation.html 《Redis命令大全》: http://www.redis.cn/commands.html 环境: CentOS7x86_64 Redis 3.2 简介 Redis是什么Redis是一个使用ANSI C编写的开源、支持网络、基于内存、可选持久性的、非关系型,键值对存储数据库。Redis是一个开源(BSD许可)的,内存中的数据结构存储系统,它可以用作数据库、缓存和消息中间件。 毫无疑问,Redis开创了一种新的数据存储思路,使用Redis,我们不用在面对功能单调的数据库时,把精力放在如何把大象放进冰箱这样的问题上,而是利用Redis灵活多变的数据结构和数据操作,为不同的大象构建不同的冰箱。希望你喜欢这个比喻。 Remote Dictionary Server(Redis)是由一个Salvatore Sanfilippo写的key-value储存系统。Redis提供了一些丰富的数据结构,包括lists,sets,ordered sets,hashes,当然还有和Memcached一样的string结构,所以常被称为是一款数据结构服务器(data structure server)。Redis当然还包括了对这些数据结构的丰富操作。 你可以在这些类型上面运行原子操作,例如,追加字符串,增加哈希中的值,加入一个元素到列表,计算集合的交集、并集和差集,或者是从有序集合中获取最高排名的元素。 Redis的优点为了满足性能,Redis采用内存(in-memory)数据集(dataset)。根据你的使用场景,你可以通过每隔一段时间转储数据集到磁盘,或者追加每条命令到日志来持久化。持久化也可以被禁用,如果你只是需要一个功能丰富,网络化的内存缓存。 性能极高,Redis能支持超过100K+每秒的读写频率 丰富的数据类型,Redis支持二进制案例的Strings,Lists,Hashes,Sets及Ordered Sets数据类型操作 原子,Redis的所有操作都是原子性的,同时Redis还支持对几个操作全并后的原子性执行 丰富的特性,Redis还支持publish/sucscribe,通知,key过期等特性 Redis还支持主从异步复制,非常快的非阻塞初次同步、网络断开时自动重连局部重同步 安装直接通过yum安装: 1yum install -y redis 启动redis-server的两种方式: redis-server: standalone模式 systemctl redis start: daemon模式 需要在配置文件中开启daemonize 启动redis-cli: 12redis-cliredis-cli -a passwd 配置redis配置文件(/etc/redis.conf)常用参数: 参数 说明 daemonize 以守护进程启动,放置于后台 bind 监听地址,建议只对本地127.0.0.1开放 protect-mode redis的保护模式 requirepass 设置密码 timeout 超时 tcp-keepalive 在Linux上,指定值(秒)用于发送ACKs的时间,关闭连接需要双倍的时间,默认为0 loglevle 指定日志记录的级别。有四个级别:debug(记录很多信息,用于开发测试)、notice(常用于生产环境)、warning(严重的信息)、verbose(有用的信息) logfile 日志文件,默认为stdout databases 可用数据库,范围在0-(database-1) save 保存数据到磁盘(.rdb) stop-writes-on-bgsave-error 后台储存错误停止写 rdbcompression 储存到本地数据库时(持久化到rdb文件)是否压缩 dbfilename 本地持久化数据库文件名,默认dump.rdb dir 数据库文件路径,是目录 salveof 设置从库 masterauth 设置主库认证的密码 slave-read-only 设置slave是否只读 slave-serve-stale-data 从库同主库失去连接或复制正在进行时,从库是否继续响应客户端请求 repl-disable-tcp-nodelay tcp-nodelay slave-priority slave优先级,master不能工作后,从众多slave中选出优先值最小的slave提升为master,优先值为0表示不能为master appendonly 是否开启AOF数据备份,redis会把所接收到的每一次写操作请求都追加到appendonly.aof文件,当此文件很大 appendsync AOF文件同步策略,后台会进行大量I/O no-appendfsync-on-rewrite - auto-aof-rewrite-percentage aof自动重写 auto-aof-rewrite-min-size 指定最小大小用于aof重写 slowlog-log-slower-than 慢日志,记录超过特定执行时间的命令,不包括I/o slowlog-max-len 慢日志记录的长度,超过大小,最先进入队列的记录会被踢出 hash-max-zipmap-entries hash将以一种特殊的编码方式(大大减少内存使用)来储存,这是其中一个临界值 hash-max-zipmap-value 另一个临界值 list-max-ziplist-entries 多个list以特定的方式编码来节省空间 activerehashing Redis将在每100ms时使用1ms的CPU时间来对redis的hash表进行重新hash,可降低内存的使用 hz 不是所有任务都以相同的频率执行,但redis按照指定的“hz”值执行检查任务 aof-rewrite-incremental-fsync 当一个子节点重写AOF文件时,则文件每生产32m数据进行同步 官方文档对VM的使用建议: 当KEY很小而VALUE很大时,使用VM的效果会比较好,因为这样节约内存比较大 当key不小时,可以考虑使用一些非常方法将很大的key变成value,比如将key,value组合成一个新的value 数据类型Redis不仅仅是简单的key-value存储器,同时也是一种data structure server。传统的key-value是指支持使用一个key字符串来索引value字符串的储存。而Redis中,value不仅仅支持字符串,还支持更多的复杂结构,包括列表、集合、哈希表等。Redis采用二进制安全,这就意味着你可以使用任何二进制序列作为重点。 字符串(strings)字符串 是一种最基本的Redis值类型。Redis字符串是二进制安全的,这意味着一个Redis字符串能包含任意类型的数据。 只关心二进制化的字符串,不关心具体格式。只会严格的按照二进制的数据存取。不会妄图已某种特殊格式解析数据。 列表(lists)Redis列表是简单的字符串列表,按照插入顺序序列,你可以添加一个或多个元素到列表的头部或者尾部。 散列(hash)Redis Hashes是字符串字段和字符串值之间的映射,因此他们是展现对象的完美数据类型。如一个有姓、名、年龄等属性的用户。一个带有一些字段的hash仅仅需要一块很小的空间储存,因此你可以储存数以百万计的对象在一个小的Redis实例中。 哈希主要用来表现对象,他们有能力储存很多对象,因此你可以将哈希用于许多其他的任务。 无序集合(unorder set)Redis集合(Set)是一个无序的字符串集合。可以用O(1)的时间复杂度(无论集合中有多少元素时间复杂度都是常量)完成添加、删除、测试元素是否存在。 Redis集合拥有令人满意的不允许包含相同成员的属性。多次添加相同的元素,最终在集合里只会有一个元素。实际上就是添加元素时无序检测元素是否存在。 一个Redis集合有趣的事情是它支持一些服务端的命令从现有的集合出发去进行集合运算,因此你可以在非常短的时间内进行合并(unions)、交集(intersections)、找出不同的元素(difference of sets)。 有序集合(order set)Redis有序集合与普通集合非常相似,也是一个没有重复项的字符串集合。不同之处是有序集合的每一个成员都关联了一个评分,这个评分被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的,但是评分可以是重复了。 使用有序集合可以以非常快的速度(O(log(N)))添加,删除和更新元素。可以很快根据评分(score)或者次序(position)来获取一个范围的元素。访问有序集合的中间元素也是很快的,因此能够使用有序集合作为一个没有重复成员的智能列表。在有序集合中,你可以很快捷的访问一切你需要的东西。 简而言之,使用有序的集合你可以做完许多对性能有极端要求的任务,而那些任务使用其他类型的数据库真的是很难完成。 命令 常用命令123456789101112131415161718192021exists key #判断一个key是否存在del key #删除某个或一系列keytype key #返回某个key元素的数据类型,key不存在返回空keys key-pattern #返回匹配的key列表randomkey #随机获取一个已经存在的keyrename oldname newname #改key的名字,如果存在将会覆盖dbsize #返回当前数据库的key的总和expire key time #设置某个key的过期时间(秒),到期后自动删除ttl #查询key剩余存活时间flushdb #清空当前数据库中的所有键flushall #清空所有数据库中的键 设置相关12345config get #用来读取Redis服务器的配置参数config set #用于更改运行Redis服务器的配置参数config resetstat #重置数据统计报告,通常返回OK 连接操作12345quit #关闭连接auth #密码认证help command #帮助 持久化1234567save #将数据同步保存到磁盘bgsave #将数据异步保存到磁盘lastsave #返回上次成功将数据保存到磁盘的Unix时戳 远程服务1234567891011121314151617181920212223242526272829info #服务器信息统计,基本所有信息monitor #实时转储收到的请求slaveof #改变复制策略shutdown #将数据同步保存到磁盘,然后关闭服务server #Redis server的常规信息clients #Client的连接选项memory #存储占用相关信息persistence #RDB and AOF 相关信息stats #常规统计replication #Master/slave请求信息cpu #CPU占用信息统计cluster #Redis 集群信息keyspace #数据库信息统计all #返回所有信息default #返回常规设置信息 值(value)操作12345678910111213141516171819202122232425exists key #判断一个key是否存在del key #删除一个keytype key #返回值的类型keys pattern #返回满足给定模式的所有keyrandomkey #随机返回key空间的一个rename oldname newname #改key的名字,如果存在将会覆盖dbsize #返回当前数据库中key的数目expire #设定一个key的活动时间(s)ttl #获得一个key的活动时间select index #按索引查询move key dbindex #移动当前数据库中的key到dbindex数据库flushdb #删除当前选择的数据库中的所有keyflushall #删除所有数据库中的所有key 字符串(string)操作123456789101112131415161718192021222324252627set key value #给数据库中名称为key的string赋值valueget key #返回数据库中名为key的string的valuegetset key value #给名称为key的string赋予上一次的valuemget key1 key2 ... key N #返回库中多个string的valuesetnx key value #添加string 名称为key 值为valuesetex key time value #向库中添加string 设定过期时间timemset key 1 value 1 ... key N value N #批量设置多个string的值msetnx key 1 value 1 ... key N value N #如果所有名称为 key N的string都不存在 则向库中添加string 名称为 key N赋值value Nincr key #名称为key的string加 1 操作incrby key integer #名称为key的string增减integerdecr key #名称为key的string减1操作decrby key integer #名称为key的string的值附加valueappend key value #名称为key的值附加valuesubstr key start end #返回名称为key的string的value的子串 列表(list)操作12345678910111213141516171819rpush key value #在名称为key的list尾部添加一个值为value的元素lpush key value #在名称为key的list首部添加一个值为value的元素llen key #返回名称为key的list的长度lrange key start end #返回名称为key的list中start至end之间的元素 下表从0开始ltrim key start end #截取名称为key的list 保留start至end之间的元素lindex key index #返回名称为key的list中index位置的元素lset key index value #给名称为key的list中index位置的元素赋值valuelrem key count value #删除count个名称为key的list中值为value的元素brpop key1 key2 ... keyN #rpop的block版本rpoplpush srckey dstkey #返回并删除名为srckey的list尾元素 并将该元素添加到名为dstkey的list的头部 集合(set)操作123456789101112131415161718192021222324252627sadd key member #向名为key的set中添加元素membersrem key member #删除名为key的set中元素的memberspop key #随机返回并删除名为key的set中的一个元素smove srckey dstkey member #将member元素从名为srckey的集合移动到名为dstkey的集合scard key #返回名为key的set的基数sismember key member #测试member是否是名称为key的set的集合sinter key1 key2 ... key N #求交集sinterstore dstkey key1 ... key N #求交集并将交集保存到dstkey的集合sunion key1 ... key N #求并集sunionstore dstkey key 1 ... key N #求并集并将并集保存到dstkey的集合sdiff key1 ... key N #求差集sdiffstore dstkey key 1 ... key N #求差集并将差集保存到dstkey的集合smembers key #返回名为key的set的所有元素srandmember key #随机返回名为key的set的一个元素 有序集合(sorted set)操作12345678910111213141516zadd key score member #向名为key的zset中添加元素member score用于排序 如果该元素已经存在 则根据score更新该元素的顺序zrem key member #删除名为key的zset中的元素memberzincrby key increment member #如果在名为key的zset中已经存在元素member 则该元素的score增加increment 否则向集合中添加该元素 其score的值为incrementzrank key member #返回名为key的zset 顺序zrevrank key member #返回名为key的zset 倒序zrange key start end #返回名为key的zset score顺序按index从start到end返回所有元素zrevrange key start end #返回名为key的zset score倒序按index从start到end返回所有元素zrangebyscore key min max #返回名为key的zset中score大于等于min 小于等于max的所有元 hash操作123456789101112131415161718192021hset key field value #向名为key的hash中添加元素filed----valuehget key field #返回名为key的hash中field对应的valuehmset key field1 value1 ... field N value N #向名为key的hash中添加元素field----valuehmget key field1 ... field N #返回名为key的hash中filed对应的valuehincrby key field integer #将名为key的hash中field的value增加integerhexists key field #名为key的hash中是否存在键为field的域hdel key field #删除名为key的hash中键为field的域hlen key #返回名为key的hash中元素个数hkeys key #返回名为key的hash中所有键hvals key #返回名为key的hash中所有键对应的valuehgetall key #返回名为key的hash中所有的键 field 及其对应的value 高级应用Redis高级应用包括安全性设置、主从复制、事务处理、持久化机制和虚拟内存的使用。 安全性由于redis速度相当快，一秒钟可以150K次密码尝试，所以需要设置一个密码强度很强大的密码。 设置密码的两种方法： config set requirepass &quot;passwd&quot;，通过命令设置密码 直接在配置文件中requirepass属性后加上密码 认证登录的两种方式： redis-cli -a passwd redi-cli –&gt; auth passwd 主从复制Redis的主从复制的配置和使用都比较简单。 master server slave server Redis主从复制特点： 一主多从 当master宕机后，优先级值小的那台slave server自动转变为master 主从复制不同阻塞master，在同步数据时master可以继续处理client的请求 提高了系统的可伸缩性 Redis主从复制过程： slave与master建立连接，发送sync同步命令 master会启动一个后台进程，将数据库快照保存到文件中，同时master主进程会开始收集新的写命令并缓存 后台完成保存后，就将此文件发送给slave slave将文件保存在磁盘上 主从复制栗子Redis主从配置，一主多从。注意：由于redis吃内存，可能会由于内存过小而无法正常启动redis，可查看/var/log/message。 配置master： 123456789101112131415161718vim /etc/redis_master.confdaemon yesbind 127.0.0.1 ip1port 6379requirepass fuza_mimaprotect-mode yesdatebases 100logfile /var/log/redis/redis_master.logdir /var/lib/redis_mastermkdir /var/lib/redis_masterchown redis:redis /var/lib/redis_mastersystemctl start redis 配置slave： 123456789101112131415161718192021222324252627282930vim /etc/redis_slave.confdaemon yesbind 127.0.0.1port 6379protect-mode yeslogfile /var/log/redis/redis_slave.logdir /var/lib/redis_slaveslaveof &lt;master-ip&gt; &lt;master-port&gt;masterauth &lt;master-passwd&gt;slave-read-only yesslave-priority 100#master挂掉后，从slave中选出优先级最小的作为master······#其他具体主从参数自己配置mkdir /var/lib/redis_slavechown redis:redis /var/lib/redis_slavesystemctl start redis 测试master： 1234redis-cli -a xxxset name zhangget zhang 测试slave： 123456redis-cliauth(&apos;passwd&apos;)key *get zhang 注意： 由于Redis只是主从，并不像MongoDB的集群功能。当Redis master挂掉以后，虽然优先级较小的slave成为了master，但从库是无法更新数据的。这点也可以从Redis从的配置文件中看出，连接到Redis主的IP：PORT，并通过主的密码来认证。 高可用Redis的主从模式，并不支持高可用。不过，Redis引进了哨兵模式(sentinel)，提供Redis实时监控和故障检测恢复的功能。Redis Sentinel 是 Redis 的官方高可用解决方案，是设计用来帮助管理 Redis 实例的系统。 运行 Sentinel 强制使用配置文件，这个文件被系统用来保存当前状态，在重启时能重新加载。如果没有指定配置文件，或者配置文件的路径不可写，Sentinel 将拒绝启动。Sentinel 运行时默认监听 TCP 端口 26379，所以为了让 Sentinel 正常运行，你的服务器必须开放 26379 端口，以接受从其他 Sentinel 实例 IP 地址的连接。否则，Sentinel 间就没法通信，没法协调，也不会执行故障转移。 Redis Sentinel 是一个分布式系统，这意味着，你通常想要在你的基础设施中运行多个 Sentinel 进程，这些进程使用 gossip 协议来判断一台主服务器是否下线(down)，使用 agreement 协议来获得授权以执行故障转移，并更新相关配置。 1234The redis-sentinel command is a symbolic link to the redis-server command which imply the --sentionel option.redis-server [ configuration_file ] [ options ] --sentinelredis-sentinel [ configuration_file ] [ options ] Redis Sentinel用于完成如下4个任务： 监控(Monitoring)Sentinel 不断检查你的主从实例是否运转正常。 通知(Notification)Sentinel 可以通过 API 来通知系统管理员，或者其他计算机程序，被监控的Redis实例出了问题。 自动故障转移(Automatic failover)如果一台主服务器运行不正常，Sentinel 会开始一个故障转移过程，将从服务器提升为主服务器，配置其他的从服务器使用新的主服务器，使用 Redis 服务器的应用程序在连接时会收到新的服务器地址通知。 配置提供者(Configuration provider)Sentinel 充当客户端服务发现的权威来源：客户端连接到 Sentinel 来询问某个服务的当前 Redis 主服务器的地址。当故障转移发生时，Sentinel 会报告新地址。 配置文件Redis Sentinel示例配置文件： 只需要指定需要监控的主服务器，并给主服务器去一个名字；没有必要指定从服务器，因为它们会被自动发现；每一次故障转移时，将一台从服务器提升为主服务器都会重写配置文件；无论你指定多少个同意来检测实例是否正常工作，Sentinel 需要系统中已知的大多数 Sentinel 的投票才能开始故障转移，并且在故障转移之后获取一个新的配置纪元(configuration Epoch) 赋予新的配置； 1234567891011121314151617181920212223#默认26379端口#sentinel &lt;option_name&gt; &lt;master_name&gt; &lt;option_value&gt;#仲裁数为2sentinel monitor mymaster 127.0.0.1 6379 2#哨兵认为实例不可达的毫秒数sentinel down-after-milliseconds mymaster 60000#sentinel failover-timeout mymaster 180000#在一次故障转移之后，被配置为同时使用新主服务器的从服务器数量sentinel parallel-syncs mymaster 1# master 有密码就要使用,#sentinel auth-pass mymaster ****sentinel monitor resque 192.168.1.3 6380 4sentinel down-after-milliseconds resque 10000sentinel failover-timeout resque 180000sentinel parallel-syncs resque 5 事务处理Redis的事务处理比较简单。只能保证client发起的事务中的命令可以连续的执行，而且不会插入其他的client命令。 当一个client在连接中发出multi命令时，这个连接就进入一个事务的上下文，该连接后续的命令不会执行，而是存放在一个队列中，当执行exec命令时，redis会顺序的执行队列中的所有命令。如果其中执行出现错误，执行正确的不会回滚，不同于关系型数据库的事务。 持久化机制持久化就是把数据从内存保存到硬盘。 Redis是一个支持持久化的内存数据库，Redis需要经常将内存中的数据同步到磁盘来保证持久化。 Redis支持两种持久化方式： snapshotting(快照) 将数据存放到文件里，默认方式。默认写入dump.rdb二进制文件中 可配置redis在n秒内超过m个key被修改就自动做快照 save 500 10 –&gt; 500s内超过10个key被修改，则保存快照 由于快照方式在一定间隔时间做一次保存， 如果Redis意外down掉的话，就会丢失最后一次快照后的所有修改。AOF比快照方式有更好的持久化性，是由于使用aof时，redis会将每一个收到的写命令都通过write函数写入到文件中当redis启动时会通过重新执行文件中保存的写命令在内存中重新建立整个数据库的内容。 appendonly file(AOF) aof方式redis会将每一次的函数都追加到文件中，当redis重启时会重新执行文件中保存的命令 配置文件参数： 1234567891011#启用aof持久化方式appendonly yes#每秒写入磁盘一次，在性能和持久化方面做了很好的折中appendonly everysc#将数据写入磁盘save 900 1save 300 10save 60 10000 虚拟内存Redis的虚拟内存是暂时把不经常访问的数据从内存交换到磁盘中，从而腾出内存空间用于其它的访问数据。对于redis这样的内存数据库，内存总是不够用的。 在配置文件(/etc/redis.conf)中配置VM: 123456789101112131415161718#开启vm功能vm-enableyes#交换出来的value保存的文件路径vm-swap-file /tmp/redis.swap#redis使用的最大内存上线vm-max-memory 10000000#每个页面的大小32字节vm-page-size 32#最多使用多少个页面vm-pages 123217729#用于执行value对象换入的工作线程数量vm-max-threads 4 批量删除123456789101112131415161718192021#删除库中所有KeySELECT 0FLUSHDB#删除所有库中KeyFLUSHALL#默认为db0#批量删除keysredis-cli KEYS &quot;test&quot; | xargs redis-cli DEL#通配符redis-cli KEYS &quot;test*&quot; | xargs redis-cli DEL#指定数据库redis-cli -n 1 KEYS &quot;test*&quot; | xargs redis-cli -n 1 DEL#指定主机，密码redis-cli -h xxx -a xx KEYS &quot;test*&quot; | xargs redis-cli -h xxx -a xx DEL bigkeys1234#对redis中的key进行采样，寻找较大的Keyredis-cli --bigkeys#之后对结果进行分析 注意 Redis监听地址bind： x.x.x.x，强烈建议只对本地127.0.0.1开放。不建议对外网开放，有安全隐患 防火墙，最简单就是关闭防火墙，另一个就是开放redis的监听端口 开启守护进程，让redis可以在后台运行而不必通过redis-server的方式来启动，将配置文件里的deamonize no改为yes 关闭redis的保护模式(protect-mode)，这里的保护模式是指是否允许其他IP的设备访问redis。如果开启的话就只能允许本机访问。如果是生产开发的实际运行环境，请一定开启保护模式 设置redis数据库密码！不仅仅是redis，任何数据库都应该设置密码，否则对外网开放的数据库就成了活靶子。 多数据库 Redis支持多个数据库 类似于其它数据库，不同的数据存储在不同的数据库中 Redis下，数据库是由一个整数索引标识，而不是数据库名称。默认情况下，客户端连接到数据库0 Redis不支持自定义数据库名称，所以需要开发者记录那些数据库存储了哪些数据 Redis不支持为每个数据库设置不同的访问密码，因为密码是在配置文件中设置的。所以一个用户可对所有数据库进行访问 Redis默认支持16个数据库，但可在配置文件中修改 使用SELECT命令切换数据库 FLUSHALL命令或清除所有数据库，请注意 123456cat /etc/redis.conf# Set the number of databases. The default database is DB 0, you can select# a different one on a per-connection basis using SELECT &lt;dbid&gt; where# dbid is a number between 0 and &apos;databases&apos;-1databases 16]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机集群]]></title>
    <url>%2F2018%2F02%2F03%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[参考： 《老男孩Linux运维》 《服务器集群系统各概念》: https://segmentfault.com/a/1190000009923581 《WEB的负载均衡、集群、高可用解决方案》： https://zhuanlan.zhihu.com/p/23826048 计算机集群维基百科 计算机集群计算机集群简称集群(Clusters)，是一种计算机系统。它通过一组散列集成的软件或硬件 连接起来高度紧密地协作完成计算工作。在某种意义上，他们可以被看做是一台计算机。 集群就是指一组（若干）相互独立的计算机，利用高速通信网络组成的一个较大的计算机服务系统，每个集群结点都是运行各自服务的独立服务器。这些服务器之间可以彼此通信，协同向用户提供应用程序、系统资源和数据，并以单一系统的模式加以管理。 当客户机请求集群系统时，集群给用户的感觉就是一个单一独立的服务器，而实际上用户请求的是一组集群服务器。 集群系统中的单个计算机通常称为节点，通常通过内网连接，但也有其它的可能连接方式。集群计算机通常用来改进单个计算机的计算速度和可靠性。 服务器集群概念集群、冗余、负载均衡、主从复制、读写分离、分布式、分布式计算、分布式计算平台、并行计算…… 实际生产环境中常有的问题： 当数据库性能遇到问题时，是否能够横向扩展，通过添加服务器的方式达到更高的吞吐量，从而充分利用现有的硬件实现更好的投资回报率; 是否拥有实时同步的副本，当数据库面临灾难时，可以短时间内通过故障转移的方式保证数据库的可用性。此外，当数据丢失或损坏时，能否通过所谓的实时副本（热备）实现数据的零损失; 数据库的横向扩展是都对应用程序透明，如果数据库的横向扩展需要应用程序端进行大量修改，则所带来的后果不仅仅是高昂的开发成本，同时也会带来很多潜在和非潜在的风险. 集群和冗余集群和冗余并不对立，多台服务器做集群（不是主从），本身就有冗余和负载均衡的效果。狭义上来说，集群就是把多台服务器虚拟成一台服务器，而冗余的每台服务器都是独立的。 集群的侧重点在于协同，多台服务器系统分担工作，提升效率； 冗余的侧重点在于防止单点故障，一主多备的架构，也就是主从复制； 数据冗余==高可用性==主从 主从一定程度上起到了负载均衡的作用，但主要目的还是为了保证数据冗余和高可用性 主从只提供一种成本较低的数据备份方案加上不完美的灾难和负载均衡，由于复制存在时间差，不能同步读，所以只是不完善的负载均衡和有损灾备 主从显然达不到集群的严格度，不论是 HA 还是 AA（多活并行集群），主从都达不到数据一致性的集群要求 为什么要使用集群 高性能（Performance） 大型网站谷歌、淘宝、百度等，都不是几台大型机可以构建的，都是上万台服务器组成的高性能集群，分布于不同的地点。 只有当并发或总请求数量超过单台服务器的承受能力时，服务器集群的优势才会体现出来。 价格有效性（Cost-effectiveness） 在达到同样性能的需求下，采用计算机集群架构比采用同等运算能力的大型计算机具有更高的性价比。 可伸缩性（Scalability） 当服务负载、压力增长时，针对集群系统进行较简单的扩展即可满足需求，且不会降低服务质量。 高可用（Availability） 单一计算机发生故障时，就无法正常提供服务；而集群架构技术可以是得系统在若干硬件设备发生故障时仍可以继续工作。 集群系统在提高系统可靠性的同时，也大大减小了系统故障带来的业务损失，目前几乎100%的网站都要求7x24h提供服务。 透明性（Transparency） 多个独立计算机组成的耦合集群系统构成一个虚拟服务器。用户访问集群系统时，就像访问一台高性能、高可用的服务器一样，集群中一部分服务器的上线、下线不会中断整个系统服务，这对用户也是透明的。 可管理性（Manageability） 这个系统可能在物理上很大，但其实很容易管理，就像管理一个单一映像系统一样。 可编程性（Programmability） 在集群系统上，容易开发及修改各类应用程序。 集群分类集群分为同构和异构，他们区别在于 “组成集群系统的计算机之间的体系结构是否相同”。 集群计算机按功能和结构可以分为以下几类： 均衡集群（Load balancing clusters） 用性集群（High-availability clusters） 能计算集群（High-performance cluster） 计算集群（Grid computing） 负载均衡集群（LB）和高可用性集群（HA）是互联网行业常用的集群架构模式 负载均衡集群负载均衡集群用于抗并发。 负载均衡集群典型的开源软件包括：LVS、Nginx、Haproxy 等。 负载均衡集群可以把很多客户集中的访问请求负载压力尽可能平均分摊在计算机集群中处理。集群中每个节点都可以一定的访问请求负载压力，并且可以实现访问请求在各节点之间动态分配，以实现负载均衡。负载均衡集群运行时，一般是通过一个或多个前端负载均衡器（Director）将客户访问请求分发到后端的一组服务器上，从而达到整个系统的高性能和高可用性。一般高可用性集群和负载均衡集群会使用类似的技术，或同时具有高可用性与负载均衡的特点。 Linux虚拟服务器（LVS）项目 在Linux操作系统上提供最常用的负载均衡软件。 负载均衡的作用： 用户访问请求及数据流量（负载均衡） 业务连续性，即7x24h服务（高可用） 于Web业务及数据库从库等服务器的业务 高可用性集群高可用性集群用于避免单点故障。 高可用性集群常用开源软件包括：Keepalived、Heartbeat 等。 一般是指集群中任意一个节点失效的情况下，该节点上的所有任务会自动转移到其他正常的节点上。此过程不会影响整个集群的运行。 当集群中的一个节点系统发生故障时，运行着的集群服务器会迅速做出反应，将该系统的服务分配到集群中其他正在工作的系统上运行。考虑到计算机硬件和软件的容错性，高可用性集群的主要目的是使局群的整体服务尽可能可用。如果高可用集群中的主节点发生了故障，那么这段时间内将由备节点代替它。备节点通常是主节点的镜像。当它代替主节点时，它可以完全接管主节点（包括Ip和其他资源）提供服务，因此，使集群系统环境对系统环境来说是一致的，既不会影响用户的访问。 高可用性集群使服务器系统的运行速度和响应速度会尽可能的快。它们经常利用在多台机器上运行的冗余节点和服务来相互跟踪。如果某个节点失败，它的替补者将在几秒钟或更多时间内接管它的职责。因此，对于用户来说，集群里的任意一台机器宕机，业务都不会受影响。 高可用性集群的作用： 当一台机器宕机后，另外一台机器接管宕机的机器的Ip资源和服务资源，提供服务； 常用于不易实现负载均衡的应用，如负载均衡器、主数据库、主存储对之间； 高性能计算集群高性能计算集群也称并行计算。通常，高性能计算集群涉及为集群开发的并行应用程序，以解决复杂的科学问题。 高性能计算集群对外就好像一个超级计算机，这种超级计算机内部由数万个独立服务器组成，并且在公共消息传递层上进行通信以运行并行应用程序。 高可用与负载均衡有什么区别 HA偏重于备用资源，切机时会有业务的断开的，保证了数据的安全，但造成资源的浪费； LB侧重于资源的充分应用，没有主备的概念，只有资源的最大限度的加权平均应用，基本不会业务的中断； HA的目的是不中断服务，LB的目的是为了提高接入能力。虽然经常放一起用，但确实是两个不同的领域； HA在一条路不通的时候提供另一条路可走，而 LB 就类似于是春运时的多个窗口； 集群软硬件 企业运维中常见集群产品： 开源集群软件：+ Nginx, LVS, Haproxy, Keepalived, Heartbear... 商业集群硬件：+ F5， Netscaler,Radware, A10... 如何选择开源集群软件： 网站在并发访问和总访问量不是很大的情况下，建议首选Nginx负载均衡，Nginx配置简单使用方便安全稳定。 另一个实现负载均衡的产品为Haproxy 如果要考虑Nginx负载均衡的高可用功能，建议首选Keepalived软件，因为安装配置简单方便稳定。类似高可用软件还有Heartbeat，但比较复杂 如果是大型企业，负载均衡可以使用 LVS+Keepalived 在前端做四层转发，后端使用Nginx或Haproxy做七层转发，再后面是应用服务器。如果是数据库与存储的负载均衡和高可用，可选用LVS+Heartbeat 负载均衡所谓负载均衡，就是把大访问量分发给不同的服务器，也就是分流请求。 HTTP重定向协议实现负载均衡HTTP 重定向就是应用层的请求转发，用户的请求其实已经到了HTTP重定向负载均衡服务器，服务器根据算法要求用户重定向，用户收到重定向请求后，再次请求真正的集群. 优点：简单 缺点：性能较差 DNS域名解析负载均衡DNS域名解析负载均衡就是在用户请求DNS服务器，获取域名对应的IP地址时，DNS服务器直接给出负载均衡后的服务器IP。 优点：交给DNS，不用我们去维护负载均衡服务器 缺点：当一个应用服务器挂了，不能及时通知DNS，而且DNS负载均衡的控制权在域名服务商那里，网站无法做更多的改善和更强大的管理 反向代理负载均衡在用户的请求到达方向代理服务器时（已到达网站机房），由于反向代理服务器根据算法转发到具体的服务器，常用的Apache，Nginx都可以充当反向代理服务器。 优点：部署简单 缺点：代理服务器可能成为性能的瓶颈，特别是一次上传大文件 IP负载均衡(LVS-NAT)LVS集群中实现的三种IP负载均衡技术。 在请求到达负载均衡器后，负载均衡器通过修改请求的目的IP地址，从而实现请求的转发，做到负载均衡。 优点：性能更好 缺点：负载均衡器的带宽称为瓶颈 直接路由负载均衡(LVS-DR)数据链路层负载均衡，在请求到达负载均衡器后，负载均衡器通过修改请求的Mac地址，从而做到负载均衡，与IP负载均衡不一样的是，当请求访问完服务器之后，直接返回客户，而无需在经过负载均衡器。 IP隧道负载均衡(LVS-TUN) 主从复制主从是一种用于数据容错和灾备的高可用解决方案，而不是一种处理高并发压力的解决方案（负载均衡是用来抗并发的）。 如MySQL主从复制，MongoDB主从复制(副本集) 主机负责查询，从机负责增删改 可以在从机上执行备份，以避免备份期间影响主机的服务 主从复制后，也可以在从机上查询，以降低主机的访问压力。但是，只有更新不频繁的数据或者对实时性要求不高的数据可以通过从服务器查询，实时性要求高的数据仍需在主服务器查询（因为主从复制有同步延迟，所以不能保证强数据一致性） 主从复制和读写分离 主从复制是实现读写分离的技术之一，也是实现读写分离的前提条件 做读写分离时最重要的就是确保 读库 和 写库 的数据统一，而主从复制是实现数据统一最简单的方法（并不能够保证强数据的一致性） 读写分离，顾名思义，就是一个表只负责向前台页面展示数据，而后台管理人员对表的增删改在另一个表中，把两个表分开，就是读写分离 主从复制则是一个表数据 增删改 之后会及时更新到另一个表中，保证两个表的数据一致 主从类型 双机热备=主机+备机 主要应用运行在主机，备机即备用机器。备机不工作，主机出现故障时备机接管主机的所有工作 双机互备=主机（备机） + 备机（主机） 互为主备，部分应用运行于主机，部分应用运行于备机，主机备机同时工作 双机双工=主机+主机 两台主机同时运行应用，主机备机同时工作 分布式 广义上的分布式是指，将不同的服务分布在不同的服务器上 集群是指，将几台服务器集中在一起，实现同一业务 分布式中的每一个节点都可以做集群，而集群并不一定是分布式的]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>Cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[不成熟的小想法]]></title>
    <url>%2F2018%2F01%2F21%2F%E4%B8%8D%E6%88%90%E7%86%9F%E7%9A%84%E5%B0%8F%E6%83%B3%E6%B3%95%2F</url>
    <content type="text"><![CDATA[你在大学奋斗四年和你进入工作岗位后奋斗四年，这两者的质量是完全不同的。前者是一个人一生的黄金时代，他有绝对的选择权来决定自己要成为什么样子；而后者则不同，吃饱饭才是这些已经步入社会的人需要考虑的第一要务。 我想不明白，为什么非要把成都建设成为2/3个四川？(或许西部省份都是这样，省会便是这个省)2017年成都市GDP约为13800亿人民币，而第二名的绵阳，却连2000亿都不到。后来别人对我讲，资本都是逐利的。也许将壹万亿拆分成小蛋糕到各个地级市能使得各个地级市经济都得到一定的发展，但肯定没有将全部蛋糕投在成都的利润更好。这让我想起了滚雪球效应，相比滚出许多小雪球，所带来的的直观效应也没有大雪球突出，雪球越滚越大，给人的映像也就越来越明显。还有就是为政者都是需要政绩来突出自己，这是升迁的重要依据。GDP才是衡量你当政的重要依据，其它因素虽然也重要，但也比不过它。 我喜欢苹果，你却给了我一车梨，然后告诉全世界你花光了所有的钱给我买了一车梨。可是我却没有一点点感动，你说我是一个铁石心肠的人，可是我只是喜欢苹果而已。 任何人不是要你来教他如何做人的！ 难道真如马尔克斯所说——“上了年纪的人不是按照已经活了多少岁来衡量年龄的，而是通过距离死亡还有多远来衡量！” 我刚开上本田的时候，也是宋总这心情，把骑自行车的人贬个贼死，而且心里就会骂出口，大屁股晃什么晃，开个玛萨拉蒂得瑟呀，我那时就像我买得起玛萨拉蒂一样。哈哈，就是个工具，先上手再说。原来人都有这种心态，哈哈哈。 看着老一辈的逐渐老去，小一辈的逐渐长大，感叹时光过得真快呀！ 过年回家，任何人都会谈及一个字——“钱”。 全家人都想出去挣钱，关于老人赡养问题，儿子和女儿又该如何担责？ 儿媳妇也是一个严重的问题！我在想一个问题，儿媳妇在对待男方父母的时候，有没有想过如果以后她的儿媳也这样对待她，她作何感想？ 现在的亲戚关系如果隔代的话，基本上过年就只有上一辈的人才走动了，下一辈子女基本都不会去。想想我们这些娃儿，上辈是亲兄弟姐妹、堂兄弟姐妹或表兄弟姐妹，我们这些小辈娃儿从小一起玩耍长大，小时候的关系好的不得了，用俗话说就是“穿一条裤子”。可是长大以后、结婚成家以后关系就淡泊了，哎！可能我们这一辈情况以后会好一点，因为由于国家的计划生育政策，我们这一辈基本上都是独生子女。以后亲戚就这些，可能关系会好点，逢年过节走动会更频繁一点。其实计划生育使得我们这一辈人挺孤单的，长得后没什么亲戚、兄弟姊妹。以后我们的孩子也没有了舅舅、姨、叔伯、嬢嬢。所以可能以后非直系亲戚间的关系也会更紧密一些。现在国家放开了二胎其实挺好的，孩子们能有个哥哥姐姐弟弟妹妹真的挺好的。 过年回家经典问答：毕业了没有呀？毕业了，微笑；多少岁了呀？xxx岁了，微笑；在哪上班呀？在外上班，微笑；在成都哪个地方呀？南边，微笑；在哪个公司呀？小公司，微笑；是做啥子的呀？计算机，微笑；工资多少呀？不多不少，微笑；有没有女朋友呀？没有，微笑……我知道这些长辈本没有恶意，只是出于不知道说什么而问点问题。但是，你们就不能动动脑子吗，我的长辈些。 我只是一个农村里出来的怯弱书生，一定要找准自己的定位。上辈给不了我什么东西，这点和城里的孩子已经差了一步，所以只有靠自己好好努力奋斗。争取给小一辈创造一个好一点的环境。 人人都是有利己心，人人都是自私的，表面和内心就如同硬币的正反两面。底层人民毫不讲理的一套，做事情完全不看原则和对错，完全是斗谁的声音高谁的脾气大才是理。看见斗不过有立马哭闹装楞。农村人民并不是那么淳良朴实，一点点鸡毛蒜皮的事情都要争。 任何人际关系都需要维持的！ 我发觉我有一个问题。人对一个人、一件物、一件事产生一个误解(或称之为成见的东西)，是很难改变的，以后会一直存在于我们的潜意识里面。我们的潜意识会主动隔阂某人某事某物，几遍某人某物某事是对的，这样一个长期效应便是对于我们潜意识里面的思维，我们会主动用我们的成见来隔阂。不知道能不能用“一朝被蛇咬十年怕井绳”来表述。其实人与人、人与事是需要相互了解的，有了成见以后人就不愿意了解对方，而用自己潜意识的成见来判断人事物。这样隔阂也就难以消除而会一直延续小区。所以，对人对事，不能带着老旧的成见去看到。——“士别三日当刮目相待，已非吴下阿蒙”。 2018年国庆回家，我感觉微信、农药、吃鸡、短视频等已经了抓住了每个年龄阶层的中国人。下至三五岁的孩童，中间的青少年更不用提，上到我的长辈些。微信已经是长辈些拉家常的聊天室，吃鸡农药开黑也是孩子们愿意与感兴趣的交流话题。空了刷刷抖音、玩玩快手，不是一个人，而是一群人，一群人的交流圈子和认同圈子。感觉每个人都是这样过来的，只不过我(90后)小时候没有移动互联网，只能玩玩泥巴、打弹弓、弹珠子、拍板、铲陀螺、滚铁环、打摇杆、进网吧……只不过我那时候没有这些东西，其实本心都是一样贪玩，玩的东西从那些变成了这些，本质上没有区别。嗨，杞人忧天的小张。看着电视从黑白发展为了彩色，看着道路从泥泞修为水泥，看着村里通电通路通水通气通网，看着手机从2G发展为移动互联网时代，看着中国改革开放的发展，看着淘宝腾讯百度的兴衰，看着快递打车外卖等新兴互联网行业的起落，现在便要看着人工智能、云等行业的发展。社会在快速的发展，我也参与在其中，以后的社会会是什么样呢？反正是越来越智能化！ 现在感觉结婚也是一个严重的问题，我的同龄人们总是说结不起婚，女方要房要车要金银，男方家长拼命在外面打工存钱用于儿子结婚。哎，想想就痛苦的很。我也知道不是所有女方都是这样的想法，不过主流就是这样。但反过来想，如果我是女方家长，把女儿嫁好一点难道不对吗？同样人品长相下的男孩子，凭什么不选一个家庭条件更好的？这是一个悖论！虽然道理我都懂，感情是两个人的事，家庭条件也是夫妻两人共同努力慢慢发展而来。结婚并不是卖女儿，结婚也不是为了给儿子找个媳妇来传宗接代。我想不明白一些儿媳妇对南方家长很差，男方家长还拼命给他们存钱，这是为什么？我在想，某些儿媳妇对老人很差，她有没有想过如果以后她的儿媳妇这样对她，她是什么想法？我真是想不明白。]]></content>
      <categories>
        <category>Zhang</category>
      </categories>
      <tags>
        <tag>Zhang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL]]></title>
    <url>%2F2018%2F01%2F16%2FMySQL%2F</url>
    <content type="text"><![CDATA[参考： MySQL5.7参考文档： https://dev.mysql.com/doc/refman/5.7/en/ 环境： CentOS7.x86_64 MySQL5.7 序言MySQL官网： https://www.mysql.com/ 由于MySQL5.7和以前版本之间的许多功能和其他差异，因此此手册不太适用于之前的老版本。之前的版本请参考MySQL相关版本的手册。 综述General information MySQL™ software提供了一个快速、多线程、多任务和健壮的SQL(结构化查询语言)的数据库服务器。MySQL server是为关键服务(mission-critical)、重负荷(heavy-load)生产系统以及嵌入式(embedding)大规模部署的软件而设计。MySQL是Oracle Corporation的商标(trademark)。 MySQL software是双重许可的(dual license)： Open Source product of the GNU General Public License A Standard commercial License from Oracle 关于此手册 该手册作为一个参考，它不提供关于SQL或关系型数据库概念的一般指令； MySQL Database Software正在不断发展，所以参考手册也经常更新。可在此 &lt; http://dev.mysql.com/doc/&gt; 获取最新版的手册； 参考手册(Reference Manual)的源文件使用DocBook XML格式书写的，其他版本(如HTML)等是自动生成的； 如果在使用过程中有任何问题或建议，请发邮件给我们； 手册由MySQL Documentation Team维护。 MySQL数据库管理系统MySQL Database Management System MySQL介绍MySQL是最流行的开源的SQL数据库管理系统，由Oracle Corporation开发、分发和支持。 MySQL is a database management system数据库是一个结构化的数据集合。它可能是从简单的购物清单到图片库，或是公司网络中的大量信息。若要添加、访问和处理存储在计算机数据库中的数据，你需要一个像MySQL Server这样的数据库管理系统。由于计算机非常擅长处理大量的数据，数据库管理系统在计算机中扮演这一个重要的角色。 MySQL databases are relational关系型数据库将数据存储在单独的表(table)中，而不是将所有数据放入一个大的库房中。数据库结构被组织成针对速度优化的物理文件。具有数据库(database)，表(table)，视图(view)，行(row)，列(column)等物理对象的逻辑模型提供了灵活的编程环境。你设置了管理不同数据字段之间关系的规则，如一对一，一对多，唯一，必须和可选关系，以及不同表之间的指针(pointer)。数据库强制执行这些规则，这样在设计良好的数据库中，应用程序就不会看到不一致、重复、孤立、过时或丢失的数据。 MySQL也是代表SQL(Structure Query Language)的一部分。SQL是访问数据库最常用的标准化语言。你可以直接使用SQL语句，或者将SQL语法隐藏到语言特定的API中。 -MySQL software is Open SourceMySQL software使用GPL(GNU General Public License)，开源意味着任何人都可以下载、转发、使用和修改软件，而不需要支付任何费用。 MySQL database server is very fast,reliable,scalabe and easy to use MySQL server works in Client/Server or embedded systemMySQL Database Server是一个由多线程(multi-threaded)SQL Server组成的客户/服务器系统。它支持不同的后端，多个不同的客户程序和库、管理工具和广泛的APIs。还提供MySQL Server作为一个嵌入式多线程库以便链接到你的产品，以获得一个更小，更快，更容易管理的独立产品。 A large amount of contributed MySQL software is available MySQL主要特点Internals and Portability 由C和C++写成 适用于许多不同的平台 为了可移植性，使用CMake 采用独立(independent)模块的多层(layer)服务器设计 设计为使用内核线程的完全多线程，如果有多核CPU，能够轻松使用它们 提供了事务性(transactional)和非事务性(notransactional)存储引擎 使用非常快速的带有索引压缩的B-tree磁盘表 添加其他存储引擎相对容易 使用非常快速的基于线程的内存分配系统 使用优化的嵌套循环(nested-loop)连接执行非常快的联结 实现内存中的hash table，这些表用作临时表 使用高度优化的类库实现SQL函数 数据类型 1,2,3,4和8byte的有无符号(signed/unsigned)的整数(integers) FLOAT DOUBLE CHAR, VARCHAR BINARY, VARBINARY TEXT BLOB DATE, TIME, DATETIME TIMESTAMP YEAR SET ENUM OpenGIS 状态和功能statement and function SELECT和WHERT中包含了所有支持的操作符和函数 SQL中的GROUP BY和ORDER BY也全部支持 GROUP functions(COUNT(), AVG(), STD(), SUM(), MAX(), MIN(), GROUP_CONCAT()) 支持LEFT OUTER JOIN和ROGHT OUTER JOIN 按照SQL标准支持table和columns的别名 支持DELETE,INSERT,REPLACE,UPDATE，以返回受影响的行数 支持MySQL特定的SHOW显示语句 一个EXPLAIN语句显示优化器如何解析查询 安全security 权限(privilege)和密码系统，非常灵活和安全，并且支持基于主机的验证 当连接到Server时，通过加密(encryption)所有密码通信量来确保密码安全 扩展性和限制Scalability and Limits 支持大型数据库。包含五千万条记录，二十万个表，五十亿行 每个表最多支持64个索引，每个索引可以由1到16个列组成 #### 连通性 Conectivity 客户端使用如下几种协议连接到MySQL Server TCP/IP sockets –enable-named-pipe on Windows Unix domain socket files on UNIX MySQL客户端可用多种语言编写 APIs对于多数语言是可用的 本地化Localization Server可以向多种语言的客户端提供错误信息 完全支持几个不同的字符集(character sets) 所有数据都被保存在选取的字符集(chracter set) 排序和比较是根据默认的字符集和排序规则完成 服务器时区(time zone)可动态更改，个客户端也可修改自己的时区 客户端和工具Clients and Tools MySQL包含几个客户机和使用程序 command-line： mysqldump, mysqladmin graphical: MySQL Workbench MySQL Server内置了对SQL语句的支持来检查、优化和修复表 MySQL程序可使用--help或-?来获取帮助 MySQL历史History of MySQL MySQL is named after co-founder Monty Widenius’s daughter, My. The name of the MySQL Dolphin (our logo) is “Sakila,” which was chosen from a huge list of names suggested by users in our “Name the Dolphin” contest. MySQL5.7新特色What Is New in MySQL 5.7 MySQL5.7新功能Features Added in MySQL 5.7 MySQL5.7中过期的功能Features Deprecated in MySQL 5.7 MySQL5.7中移除的功能Features Removed in MySQL 5.7 Server and Status Variables and Options Added, Deprecated, or Removed in MySQL 5.7 MySQL信息源MySQL Information Sources 本章节将列出有关MySQL的帮助信息。 MySQL站点MySQL Websites MySQL Documentation is https://dev.mysql.com/doc 安装和升级 mysql-repo: http://repo.mysql.com/ yum-repo: http://repo.mysql.com/yum/ 安装MySQL一般遵循以下步骤： 确定MySQL是否支持你的平台(platform) Unix、Linux、FreeBSD Windows OS X 选择要安装的发行版(distribution) 下载你想要安装的发行版 安装发行版 执行任何必要的安装后设置 通用安装指南General Installation Guidance 安装哪个发行版和MySQL版本Which MySQL Version and Distribution to Install 在准备安装MySQL时，请决定使用哪种版本(version)和发行(distribution)格式(binary or source) 首先，决定安装开发版还是稳定版。 Development release 具有新功能，但不推荐用于生产环境 General Availability(GA) release 也称为稳定版(stable release)，推荐为生产环境使用 MySQL命名方案(naming scheme)， 例如MySQL5.7.1： 5为主版本号(major) 7为次版本号(minor) 1为发行(release)系列版本号 系列号描述了稳定的功能集。对于每个新的修补程序，这都会增加。 在选择要安装的MySQL版本之后，决定要为操作系统安装哪个发行版格式。 二进制(binary) RPM, DMG 源码(source) tar, zip 在某些情况下，最好使用源码安装MySQL： 想在某个明确的位置安装MySQL 希望使用二进制发行版中未包含的特性配置mysqld 希望配置mysqld，而不需要二进制发行版中包含的一些功能 你希望读取或修改组成MySQL的C、C++源代码 源码发行版比二进制发行版包含更多的测试和示例 如何获取MySQLHow to Get MySQL MySQL当前版本下载页： https://dev.mysql.com/downloads/ 完整的MySQL镜像： https://dev.mysql.com/downloads/mirrors/ 基于RPM的Linux平台，MySQL Yum Repository： https://dev.mysql.com/downloads/repo/yum/ 基于Debian的Linux平台，MySQL APT Repository： https://dev.mysql.com/downloads/repo/apt/ SUSE Linux平台，MySQL SUSE Repository： https://dev.mysql.com/downloads/repo/suse/ 使用MD5校验和或GnuPG验证程序完整性Verifying Package Integrity Using MD5 Checksums or GnuPG 下载好MySQL包并在安装它之前，请确保它是完整的并未被篡改。有如下三种方法： MD5 checksums Cryptographic signatures using GnuPG, the GNU Privacy Guard For RPM packages, the built-in RPM integrity verification mechanism 验证MD5校验和Verifying the MD5 Checksum 应确保下载的MySQL包的MD5校验和与MySQL官方提供的校验和相匹配。 12md5sum mysql-standard-5.7.22-linux-i686.tar.gz#aaab65abbec64d5e907dcd41b8699945 mysql-standard-5.7.22-linux-i686.tar.gz 使用GnuPG进行签名检查Signature Checking Using GnuPG 要验证软件包的签名，首先需要我们的公共GPG密钥的副本。可从http://pgp.mit.edu/下载。你想要获得的密钥名为mysql-build@oss.oracle.com，如下: 12345678-----BEGIN PGP PUBLIC KEY BLOCK-----Version: GnuPG v1.4.5 (GNU/Linux)mQGiBD4+owwRBAC14GIfUfCyEDSIePvEW3SAFUdJBtoQHH/nJKZyQT7h9bPlUWC3RODjQReyCITRrdwyrKUGku2FmeVGwn2u2WmDMNABLnpprWPkBdCk96+OmSLN9brZfw2vOUgCmYv2hW0hyDHuvYlQA/BThQoADgj8AW6/0Lo7V1W9/8VuHP0gQwCgvzV3BqOx后面还有很多，省略-----END PGP PUBLIC KEY BLOCK----- 使用gpg --import将密钥导入到个人公共GPG密钥环中。如公共密钥为mysql_pubkey.asc： 12345gpg --import ./mysql_pubkey.asc#或使用public key id下载公共密钥gpg --recv-keys $pub-key-id 在rpm包中验证: 1rpm --import ./mysql_pubkey.asc 确保两个文件都放置于同一目录下，然后运行命令验证签名： 12345gpg --verify package_name.ascgpg --verify mysql-standard-5.7.22-linux-i686.tar.gz.ascgpg: Signature made Tue 01 Feb 2011 02:38:30 AM CST using DSA key ID 5072E1F5gpg: Good signature from &quot;MySQL Release Engineering &lt;mysql-build@oss.oracle.com&gt;&quot; 使用RPM进行签名检查Signature Checking Using RPM 1234rpm --checksig package_name.rpm[zhang@zabbix ~]$ rpm --checksig mysql-community-server-5.7.20-1.el7.x86_64.rpmmysql-community-server-5.7.20-1.el7.x86_64.rpm: (sha1) dsa sha1 md5 gpg OK rpm还支持从URL加载密钥: 1rpm --import http://dev.mysql.com/doc/refman/5.7/en/checking-gpg-signature.html 安装布局Installation Layouts 不同的安装类型(native packages, binary tarballs, and source tarballs)有不同的安装布局，这样可能会导致混淆。 在Unix/Linux上使用通用二进制文件安装MySQLInstalling MySQL on Unix/Linux Using Generic Binaries 包括以压缩的tar文件形式的通用二进制发行版，以及针对特定平台封装格式的二进制文件。 MySQL压缩tar文件二进制发行版具有 mysql-VERSION-OS.tar.gz的文件格式。 MySQL依赖于libaio Library： 1yum install -y libaio 默认地，tar文件二进制发行版，解压后安装于/usr/local/mysql目录。会在目录下生产 通用Unix/Linux二进制包的MySQL安装布局目录 目录 内容 bin mysqld server, client and utility programs docs MySQL manual in Info format man Unix manual pages include Include (header) files lib Libraries share Error messages, dictionary, and SQL for database installation support-files Miscellaneous support files 大致命令如下： 12345678910111213141516171819shell&gt; groupadd mysqlshell&gt; useradd -r -g mysql -s /bin/false mysqlshell&gt; cd /usr/localshell&gt; tar zxvf /path/to/mysql-VERSION-OS.tar.gzshell&gt; ln -s full-path-to-mysql-VERSION-OS mysqlshell&gt; cd mysqlshell&gt; mkdir mysql-filesshell&gt; chown mysql:mysql mysql-filesshell&gt; chmod 750 mysql-filesshell&gt; bin/mysqld --initialize --user=mysqlshell&gt; bin/mysql_ssl_rsa_setupshell&gt; bin/mysqld_safe --user=mysql &amp;# Next command is optionalshell&gt; cp support-files/mysql.server /etc/init.d/mysql.server#添加环境变量export PATH=$PATH:/usr/local/mysql/bin 在Linux上安装MySQLInstalling MySQL on Linux Linux支持多种方法来安装MySQL。建议使用Oracle提供的一个发行版： Apt Yum Zypper RPM DEB Generic Source Docker Oracle Unbreakable Linux Network 作为一个选择，你可以使用系统中的包管理工具自动下载和安装MySQL。 在Linux上使用Yum Repository安装MySQLInstalling MySQL on Linux Using the MySQL Yum Repository 安装一个全新的MySQL的步骤： 添加MySQL Yum Repository 首先，添加MySQL Yum repository到你的系统仓库列表 选择和下载对应平台的release 或者 手动添加repository文件 安装release package 12345#yum localinstall platform-and-version-specific-package-name.rpmyun install http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql57-community-release-el7-10.noarch.rpmyum repolist enabled | grep "mysql.*-community.*" 选择一个release series 默认是最新的GA series，当前最新是MySQL5.7。 查看所有的MySQL Yum repository: yum repolist all | grep mysql 安装最新MySQL不需要配置，而安装先前的版本则需要指定GA series。disable最新的GA series并且enable需要的GA series。 123yum-config-manager --disable mysql57-communityyum-config-manager --enable mysql56-community 或者手动创建repo，可直接定义版本 123456[mysql57-community]name=MySQL 5.7 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.7-community/el/7/$basearch/enabled=1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 安装MySQL 在安装MySQL过程中出现错误，请务必查看日志文件。 123yum install -y mysql-community-server mysql-community-client#也可不安装客户端 开启MySQL Server 1234service mysqld start#Starting mysqld:[ OK ]service mysqld status 在服务器初始启动时，如果服务器的数据目录为空，则会发生一下情况： 服务器已初始化 SSL certificate and key files 在数据目录中生成 validate_password已安装并启用 超级用户账户’root’@’localhost’被创建，超级用户密码被设置并被存储在error log files 这一点和以前版本有很大区别，我被坑惨了 注意： ValidPassword的默认密码策略要求包含大写字母、小写字母、数字和特殊字符，并且密码长度至少为8个字符 123456789101112131415161718192021222324252627#查看初始密码grep &apos;temporary password&apos; /var/log/mysqld.log#无法使用mysqladmin修改密码，需要登录mysql后修改mysql -uroot -p#重置密码ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;NewPass4!;#如果找不到初始密码vim /etc/my.cnf#在[mysqld]最后行加上skip-grant-tables实现无认证登录#重启MySQLUPDATE mysql.user SET authentication_string =PASSWORD(&apos;新密码&apos;) WHERE USER=&apos;xxx&apos;;#修改默认密码策略#更改密码强度set global validate_password_policy=0;#设置密码最小长度set global validate_password_length=4; 使用Yum安装额外的MySQL产品和组件 你可使用Yum安装和管理MySQL的个别组件。 123456yum --disablerepo=\* --enablerepo='mysql*-community*' list availableyum install package-name#栗子yum install mysql-community-libs 在Linux上使用Oracle提供的RPM包安装MySQLInstalling MySQL on Linux Using RPM Packages from Oracle MySQL Community Edition的rpm包如下： 包名 描述 mysql-community-server Database server and related tools mysql-community-client MySQL client applications and tools mysql-community-common Common files for server and client libraries mysql-community-server-minimal Minimal installation of the database server and related tools mysql-community-devel Development header files and libraries for MySQL database client applications mysql-community-libs Shared libraries for MySQL database client applications mysql-community-libs-compat Shared compatibility libraries for previous MySQL installations mysql-community-embedded MySQL embedded library mysql-community-embedded-devel Development header files and libraries for MySQL as an embeddable library mysql-community-test Test suite for the MySQL server 123456789#rpm -qpl mysql-community-server-version-distribution-arch.rpm#yum install mysql-community-&#123;server,client,common,libs&#125;-*wget http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql-community-server-5.7.20-1.el7.x86_64.rpmwget http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql-community-client-5.7.20-1.el7.x86_64.rpmyum install -y mysql-community-server-5.7.20-1.el7.x86_64.rpm mysql-community-client-5.7.20-1.el7.x86_64.rpm Linux RPM包MySQL开发区的安装布局： 文件或资源 位置 Client programs and scripts /usr/bin mysqld server /usr/sbin configuration file /etc/my.cnf data directory /var/lib/mysql error log file /var/log/mysqld.log Value of secure_file_priv /var/lib/mysql-files System V init script /etc/init.d/mysqld Systemd service mysqld pid file /var/run/mysql/mysqld.pid socket /var/lib/mysql/mysql.sock Keyring directory /var/lib/mysql-keyring Unix manual pages /usr/share/man include (header) files /usr/include/mysql Libraries /usr/lib/mysql Miscellaneous support files (for example, error messages, and character set files) /usr/share/mysql The installation also creates a user named mysql and a group named mysql on the system. 注意安装MySQL会在系统上生成一个名为mysql的用户和群组安装以前的MySQL版本可能会创建my.cnf配置文件。强烈建议先将my.cnf进行迁移，然后删除它。之后才安装MySQL 用systemd管理MySQL ServerManaging MySQL Server with systemd systemd综述Overview of systemd systemd提供了MySQL Server的自动开启和关闭，使用systemctl命令进行管理。 或者，使用system V系统兼容的service命令。 123systemctl &#123;start|stop|restart|status&#125; mysqldservice mysqld &#123;start|stop|restart|status&#125; 对systemd的支持包括这些文佳： mysqld.service systemd服务单元配置文件，以及有关MySQL服务的详细信息 mysqld@.service 用于管理多个MySQL实例 mysqld.tmpfiles.d 包含支持临时文件功能的信息 mysqld_pre_systemd 支持单元文件的脚本 为MySQL配置systemdConfiguring systemd for MySQL 为MySQL添加或修改systemd选项，参考如下方法： 使用一个本地化的systemd配置文件 安排systemd为MySQL Server进程设置环境变量 设置MYSQLD_OPTS systemd变量 创建/etc/systemd/system/mysqld.service本地化systemd配置文件，这里讨论的是将此文件名作为override.conf： 1234567891011121314[Service]LimitNOFILE=max_open_filesPIDFile=/path/to/pid/fileNice=nice_levelLimitCore=core_file_limitEnvironment="LD_PRELOAD=/path/to/malloc/library"Environment="TZ=time_zone_setting"#LimitNOFILE: 文件描述符数量#LimitCore: 最大核心文件大小#Nice: 优先级#LD_PRELOAD: 特定内存分配库#TZ: 指定时区 修改mysqld: 1systemctl edit mysqld 重新加载systemd配置，然后重启MySQL service： 123systemctl daemon-reloadsystemctl restart mysqld 可在override.conf中设置如下参数： 1234[Service]PIDFile=/var/run/mysqld/mysqld-custom.pidExecStart=ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld-custom.pid $MYSQLD_OPTS 在/etc/sysconfig/mysql下指定值： 12345LD_PRELOAD=/path/to/malloc/libraryTZ=time_zone_settingsystemctl restart mysqld 使用systemd配置多个MySQL实例Configuring Multiple MySQL Instances Using systemd 由于systemd具有在平台上管理多个MySQL实例的能力，而不必须需要mysqld_multi和mysqld_multi.server。 若要使用多实例(multiple-instance)功能，请修改/etc/my.cnf文件以包含每个实例的关键选项配置。例如，管理replication01和replication02两个实例： 123456789101112131415vim /etc/my.cnf[mysqld@replica01]datadir=/var/lib/mysql-replica01socket=/var/lib/mysql-replica01/mysql.sockport=3307log-error=/var/log/mysqld-replica01.log[mysqld@replica02]datadir=/var/lib/mysql-replica02socket=/var/lib/mysql-replica02/mysql.sockport=3308log-error=/var/log/mysqld-replica02.log 这里的名称使用@作为分隔符(delimiter)，因为这个是systemd支持的唯一分隔符。 管理两个实例: 12345678910111213systemctl start mysqld@replica01systemctl start mysqld@replica02systemctl enable mysqld@replica01systemctl enable mysqld@replica02#使用通配符systemctl status &apos;mysqld@replica*&apos;systemctl stop mysqld@replica0&#123;1,2&#125; 对于同一个机器上的不同MySQL实例，systemd自动使用不同的单元文件。在unit file中，%I和%i用于@标记后传入参数，用于管理特定实例。 12345678910111213141516171819#像这样mysqld --defaults-group-suffix=@%I ...systemctl status mysqld@replica01# mysqld@replica01.service - MySQL Server# Loaded: loaded (/usr/lib/systemd/system/mysqld@.service; disabled; vendor preset: disabled)# Active: active (running) since Tue 2018-02-27 12:18:34 CST; 1min 6s ago# Docs: man:mysqld(8)# http://dev.mysql.com/doc/refman/en/using-systemd.html# Process: 3927 ExecStart=/usr/sbin/mysqld --defaults-group-suffix=@%I --daemonize --pid-file=/var/run/mysqld/mysqld-%i.pid $MYSQLD_OPTS (code=exited, status=0/SUCCESS)# Process: 3845 ExecStartPre=/usr/bin/mysqld_pre_systemd %I (code=exited, status=0/SUCCESS)#Main PID: 3930 (mysqld)# CGroup: /system.slice/system-mysqld.slice/mysqld@replica01.service# `-3930 /usr/sbin/mysqld --defaults-group-suffix=@replica01 --daemonize --pid-file=/var/run/mysqld/mysqld-replica01.pid##eb 27 12:18:27 zabbix.me systemd[1]: Starting MySQL Server...#eb 27 12:18:34 zabbix.me systemd[1]: Started MySQL Server. 从mysqld_safe迁移到systemdMigrating from mysqld_safe to systemd 因为mysqld_safe没有安装在使用systemd管理MySQL的平台上，所以以前需要为该程序指定选项：[mysqld_safe] 一些[mysqld_safe]的选项也能被[mysqld]支持 一些[mysqld_safe]的选项类似于[mysqld]选项 从源码安装MySQLInstalling MySQL from Source 从源代码构建MySQL使我们能够自定义构建参数(parameter)、编译器优化(compiler optimization)和安装位置(installation location)。 在使用源码安装前，请检查Oracle是否为你的平台生成预编译的二进制发行版，以及是否适合你。Oracle付出了很多努力确保提供的二进制文件具有最佳的性能选择。 源码安装系统需求：使用源码安装MySQL需要多种开发工具。 使用源码安装MySQL，必须满足一下系统需求： CMake, which is used as the build framework on all platforms A good make program A working ANSI C++ compiler The Boost C++ libraries are required to build MySQL The ncurses library Sufficient free memory Perl is needed if you intend to run test scripts 使用standard source distribution安装MySQL，需要以下工具来unpack分发文件： For a .tar.gz compressed tar file: tar For a .zip Zip archive: zip For an .rpm RPM package: rpmbuild 用于源码安装的MySQL布局MySQL Layout for Source Installation 默认地，再从源码编译后安装MySQL时，安装步骤会将文件安装在/usr/local/mysql下。 使用标准源码发行版安装MySQLInstalling MySQL Using a Standard Source Distribution 从一个标准源码发行版安装MySQL： 确保系统满足工具需求 获取发行文件 配置、构建和安装 执行安装后程序 如果是source RPM: 1rpmbuild --rebuild --clean MySQL-VERSION.src.rpm 如果是compressed tar file 或 zip archive source: 12345678910111213141516171819202122232425262728# Preconfiguration setupshell&gt; groupadd mysqlshell&gt; useradd -r -g mysql -s /bin/false mysql# Beginning of source-build specific instructionsshell&gt; tar zxvf mysql-VERSION.tar.gzshell&gt; cd mysql-VERSIONshell&gt; mkdir bldshell&gt; cd bldshell&gt; cmake ..shell&gt; makeshell&gt; make install# End of source-build specific instructions# Postinstallation setupshell&gt; cd /usr/local/mysqlshell&gt; mkdir mysql-filesshell&gt; chown mysql:mysql mysql-filesshell&gt; chmod 750 mysql-filesshell&gt; bin/mysqld --initialize --user=mysqlshell&gt; bin/mysql_ssl_rsa_setupshell&gt; bin/mysqld_safe --user=mysql &amp;# Next command is optionalshell&gt; cp support-files/mysql.server /etc/init.d/mysql.server /sbin/nologin和/bin/false的区别 /bin/false是最严格的禁止login选项，一切服务都不能用 mongod:x:996:994:mongod:/var/lib/mongo:/bin/false /sbin/nologin只是不允许系统login，可以使用其他服务 ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin 执行预配置(preconfiguration)设置 在Unix上，设置MySQL用户和组，用于运行和执行MySQL服务器和数据库目录。 获得和解包distribution 选择要解压分发的目录，并将位置更改到其中。 1234tar zxvf mysql-VERSION.tar.gz#gunzip &lt; mysql-VERSION.tar.gz | tar xvf -#cmake -E tar zxvf mysql-VERSION.tar.gz 使用开发源码树安装MySQLInstalling MySQL Using a Development Source Tree install MySQL from the latest development source codew hich is hosted on GitHub: https://github.com/mysql/mysql-server 设置一个MySQL git repository 克隆MySQL git repository到本机 1git clone https://github.com/mysql/mysql-server.git 查看 1cd mysql-server 使用git branch -r查看远程MySQL分支 123cd mysql-servergit branch -r 查看分支 123cd mysql-servergit branch 切换分支 123cd mysql-servergit checkout 5.7 获取远程MySQL git repository更新 123cd mysql-servergit pull 检查提交历史 12345cd mysql-servergit log#也可在MySQL GitHub上查看commit history 在克隆MySQL git repository并切换到需要的分支后，便可以从源代码构建MySQL Server。 在生产机器上从分发源码树安装构件时要小心，安装命令可能会覆盖您的实时发行版安装。 MySQL源码配置选项MySQL Source-Configuration Options CMake程序提供了一个强大的如何配置MySQL源码发行版的控制。 具体链接参考: https://dev.mysql.com/doc/refman/5.7/en/source-configuration-options.html 处理MySQL编译问题Dealing with Problems Compiling MySQL 如果CMake先前已经运行过，那么现在运行的CMake可能使用先前的调用过程中收集到的信息。这些信息存储在 CMakeCache.txt。在CMake启动时，它会寻找和读取此文件。 每次运行CMake，必须再次运行make才能重新编译。 防止使用old object file或配置文件: 12make cleanrm CMakeCache.txt 安装之后的设置和测试Postinstallation Setup and Testing 在安装MySQL后你应该做的事： 如有必要，初始化数据目录并创建MySQL授权表 开启Server并确保它可以正常访问 将密码分配给授权表中的root用户 可选地，设置Server自启动 可选地，填写时区表，以便识别时区 初始化数据目录Initializing the Data Directory 安装MySQL之后，必须初始化数据目录，包括mysql系统数据库中的表。有些安装方法会自动初始化，有些则需要手动初始化。当然，如果修改了默认数据目录位置，那么也是需要手动初始化的。 初始化数据库目录，主要是包含了初始MySQL授权表(grant table)的MySQL服务器，这些表确定了如何允许用户连接到服务器。但是，初始化数据目录是不会覆盖(overwrite)任何现有权限表，因此在任何情况下运行都是安全的。 数据目录初始化会在MySQL数据库汇总创建time zone，但不会填充它，所以它是空的。 123456789101112131415cd /usr/local/mysqlmkdir mysql-fileschown mysql:mysql ./mysql-fileschmod 750 ./mysql-files#--user#使数据库目录文件属于mysql用户，以确保Server有读取权限/usr/local/mysql/bin/mysqld --initialize --user=mysql#开启安全连接/usr/local/mysql/bin/mysql_ssl_rsa_setup 使用mysqld手动初始化数据目录Initializing the Data Directory Manually Using mysqld 1234567891011121314151617181920212223242526cd /usr/local/mysql/bin#使数据库目录文件属于mysql用户，以确保Server有读取权限#默认是secure，会生成root初始密码./mysqld --initialize --user=mysql#不生成root初始密码./bin/mysqld --initialize-insecure --user=mysql#指定目录--basedir=/usr/local/mysql--datadir=/var/lib/mysql#或者将其写入配置文件vim /etc/my.cnf[mysqld]basedir=/usr/local/mysqldatadir=/var/lib/mysql#指定配置文件初始化./mysqld --defaults-file=/etc/mysql.cnf --initialize --user=mysql 使用mysql_install_db初始化数据目录Initializing the Data Directory Manually Using mysql_install_db 1234567891011121314151617cd /usr/local/mysql/bin#mysql_install_db命令会创建数据目录，并在数据目录下创建mysql数据库和授权表./mysql_install_db --user=mysql#指定目录是必须的--basedir=/usr/local/mysql--datadir=/var/lib/mysql./mysqld_safe --user=mysql &amp;#systemctl start mysqldmysql -u root -p xxxmysql&gt;SET PASSWORD FOR 'root'@'localhost' = PASSWORD('new_password'); Starting the Server Start the MySQL server like this if your installation includes mysqld_safe /usr/local/mysql/binmysqld_safe --user=mysql &amp; Start the server like this if your installation includes systemd support systemctl start mysqld 使用non-root用户运行MySQL服务很重要 如有错误请查看日志 Testing the Server执行一些简单测试以保证Server正常工作。 1234567891011121314151617181920#使用mysqladmin验证Server正在运行mysqladmin --helpmysqladmin -uuser -ppasswd versionmysqladmin -uuser -ppasswd variablesmysqladmin -user -ppasswd shutdown# 使用mysqlshow查看数据库mysqlshow -uuser -ppasswd#查看指定数据库信息mysqlshow -uuser -ppasswd mysql#读取信息#-e,Execute command and quitmysql -uuser -ppasswd -e "SELECT user, host from mysql.user" 保护初始化MySQL账户Securing the Initial MySQL Accounts 在安装MySQL后，root账户密码可能已经被分配。 mysql.user授权表定义了初始化MySQL用户账户和它们的访问权限。MySQL5.7只创建了一个&#39;root&#39;@&#39;localhost&#39;账户，但早期的版本可能有多个用户。 请务必为每一个MySQL账户创建密码。 查看用户： 1234567891011121314#存储在authentication_string列中的密码可能包含无法正常显示的二进制数据#所以将其转换为十六进制mysql&gt; SELECT user, host, hex(authentication_string) FROM mysql.user;mysql&gt; SELECT user, host, authentication_string FROM mysql.user;#或mysql -uuser -ppasswd -e "SELECT user, host, hex(authentication_string) FROM mysql.user;"#5.7以前的版本mysql&gt; mysql&gt; SELECT user, host, password FROM mysql.user;#或mysql -uuser -ppasswd -e "SELECT user, host, password FROM mysql.user;" 为root账户分配密码 12345678910#5.7.6mysql&gt; ALTER USER user IDENTIFIED BY &apos;new_passwd&apos;;mysql&gt; ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;new_passwd&apos;;#5.7.6前mysql&gt; SET PASSWORD FOR username = PASSWORD(&apos;new_passwd&apos;);mysql&gt; SET PASSWORD FOR &apos;root&apos;@&apos;localhost&apos; = PASSWORD(&apos;new_passwd&apos;); 给anonymous账户分配密码 1mysql&gt; SET PASSWORD FOR &apos;&apos;@&apos;localhost&apos; = PASSWORD(&apos;new_passwd&apos;); 移除匿名账户 1mysql&gt; DROP USER &apos;&apos;@&apos;localhost&apos;; 升级或降级MySQLUpgrading or Downgrading MySQL 升级是一个常见的过程。请在测试系统上确保运行正常后再实施到生产环境 降级不太常见。一般是由于新版本在生产环境上发生某些兼容性或性能问题，并且是在测试环境中没有发现的情况下，从而需要降级。请现在测试系统上运行正常后再实施到生产环境。 升级MySQL请使用有管理权限的MySQL账户执行升级相关命令。(如root账户) MySQL升级策略MySQL Upgrade Strategies 升级方法 直接升级(In-Place Upgrade) 包含关闭旧版MySQL，替换为新的MySQL版本，在现有数据目录上重启MySQL，运行mysql_upgrade 逻辑升级(Logical Upgrade) 包含使用mysqldump导出现有数据文件，安装新版MySQL，导入数据文件到新版MySQL，运行mysql_upgrade 升级路径 只支持GA release之间 这是一个发行系列的升级 如5.6.x到5.6.y 升级到下一个版本之前，建议先升级到最新版本 如先升级到5.6最新版，再升级到5.7 不支持跳版本升级 如5.5到5.7 升级之前 升级之前，请一定备份数据 查看新版本的Release Note 删除和增加了什么功能 新版本依赖什么 如果在InnoDB中使用XA事务，则在升级之前运行XA恢复以检查未提交的XA事务 如果MySQL数据量很大，就地升级以后可能需要很长的时间才能进行转换 你可能会发现创建一个”dummy”数据库实例是很有用的，以及评估可能需要哪些转换以及执行这些转换所涉及的工作 无论在你安装或升级到一个MySQL新版本，建议重建和重装MySQL language interface 如PHP MySQL扩展 直接升级 配置MySQL执行slow shutdown innoDB在关闭前执行一个完整的清除和更改缓冲区合并，这确保数据文件在不同的版本的文件格式做好充分准备。 1mysql -u root -p --execute="SET GLOBAL innodb_fast_shutdown=0" 关闭MySQL Server 1mysql -uroot -p shutdown 升级MySQL 开启新版MySQL 运行mysql_upgrade mysql_upgrade检查所有数据库中的所有表与当前版本MySQL的不兼容性。 1234mysql_upgrade -uroot -p#Upgrade process completed successfully.#Checking if update is needed. 关闭和重启MySQL Server来确保改变生效 123mysqladmin -uroot -p shutdownsystemctl start mysqld 逻辑升级 导出所有数据 1234567mysqldump -uroot -p --all-databases --force &gt; mysqldb_backup.sql#-f, --force Continue even if we get an SQL error#Use the --routines and --events options if your databases include stored programs#--add-drop-database Add a DROP DATABASE before each create.mysqldump -uroot -p --add-drop-table --routines --events --all-databases --force &gt; mysqldb_backup.sql 关闭MySQL Server 1mysqladmin -uroot -p shutdown 安装新版MySQL 初始化MySQL并启动 载入数据文件 1mysql -uroot -p --force &lt; ./mysqldb_backup.sql 运行mysql_upgrade 1234mysql_upgrade -uroot -p#Upgrade process completed successfully.#Checking if update is needed. 关闭并重启MySQL Server以确保更改生效 通过MySQL Yum Repository进行升级Upgrading MySQL with the MySQL Yum Repository 选择一个target series 默认情况下，MySQL Yum Repository会将MySQL升级到该release系列的最新版本。如5.7.1升级到5.7.10。 如果要升级到其他release(如5.6到5.7)，就必须要先禁用此subrepository，并选择和启用新的subrepository。 As a general rule, to upgrade from one release series to another, go to the next series rather than skipping a series. 升级MySQL 1yum update mysql-server mysql-client 重启MySQL MySQL Server总是在Yum更新之后重启，一旦重启，请运行mysql_upgrade来检查旧数据与升级软件之间的任何不兼容问题。 1234mysql_upgrade -uroot -p#Upgrade process completed successfully.#Checking if update is needed. 升级Shared Client Libraries 所以说，用yum repository安装软件是很方便的。不管是在管理还是升级等方面… 通过直接下载RPM包升级MySQL直接下载mysql相应组件的rpm进行升级。建议备份好配置文件。 12345wget http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql-community-server-5.7.20-1.el7.x86_64.rpmwget http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql-community-client-5.7.20-1.el7.x86_64.rpmyum install mysql-community-server-5.7.20-1.el7.x86_64.rpm mysql-community-client-5.7.20-1.el7.x86_64.rpm mysql降级MySQL降级类似于MySQL升级。也包含有直接降级和逻辑降级。 重建或修复表或索引Rebuilding or Repairing Tables or Indexes MySQL处理数据类型和字符集的方式的更改 表维修或升级(mysqlcheck, mysql_upgrade) 重建表的方法： Dump and Reload ALTER TABLE REPAIR TABLE Dump and Reload Method 由于MySQL升级/降级之后，不同版本的MySQL无法处理这些表，则需要转储和重载的方法来重建表。 12345678910mysqldump -uroot -p --all-databases --force &gt; mysql_backdb.sqlmysql -uroot -p --force &lt; mysql_backdb.sql#某个库或表mysqldump -uroot -p --databases test --force &gt; db_test.sqlmysql -uroot -p test &lt; db_test.sqlmysqldump -uroot -p --databases test --tables table222 &gt; table222.sqlmysql -uroot -p test &lt; table222.sql ALTER TABLE Method 更改表以使用它已经拥有的存储引擎。 1ALTER TABLE test ENGINE = InnoDB; REPAIR TABLE Method REPAIR TABLE仅适用于MyISAM， ARCHIVE和 csv 表。 mysqlcheck --repair提供了对REPAIR TABLE的命令行访问。 12345REPAIR TABLE t1;mysqlcheck --repair --databases db_name ...mysqlcheck --repair --all-databases 复制MySQL数据库到其他机器Copying MySQL Databases to Another Machine 在需要为不同体系架构之间传输MySQL数据库时，可使用mysqldump创建包含SQL语句的.sql文件，然后复制到另外的计算机上，将其作为输入提供给MySQL客户端。 不要忘记复制mysql数据库，因为这个存储授权表的地方。 123456mysqldump --host &apos;remote-host&apos; -uxxx -p --compress --all-databases | mysql -uxxx -pmysqldump --host &apos;remote-host&apos; -uxxx -p --compress db_name | mysql -uxxx -p db_namemysqladmin -uxxx -p flush-privileges Tutorial如何使用MySQL client程序来创建和使用数据库。 连接和断开服务器Connecting to and Disconnecting from the Server Like this: 不建议把密码直接写在命令行上 host表示了MySQL Server运行在的机器 某些MySQL允许匿名用户连接 -ppassword, not as -p password 123456789101112131415mysql --host host --user username -p#maybe not default portmysql --host host --user username -p --port port#匿名用户连接mysql#退出mysql&gt; QUIT#Unixmysql&gt; Ctrl+D 输入查询Entering Queries 1234567891011121314151617#简单查询mysql&gt; SELECT VERSION(), CURRENT_DATE;#简单计算SELECT SIN(PI()/2), (4+1)*5;#一行中输入多个语句SELECT VERSION(); SELECT NOW();#多行输入一个命令mysql&gt; SELECT -&gt; USER() -&gt; , -&gt; CURRENT_DATE; 这QUERY说明了有关MySQL的几件事： MySQL查询通常由一个SQL statement和;组成 MySQL将查询发送给服务器并返回结果，然后打印下一个mysql&gt;提示 MySQL以表格形式(rows and columns)显示查询输出 MySQL显示返回多少行，以及执行查询花费了多长时间 MySQL查询不区分大小写，但建议使用大写 MySQL支持在一行中输入多个语句 MySQL支持一个命令多行输入 MySQL提示符： Prompt Meaning mysql&gt; 准备新查询 -&gt; 等待多行查询的下一行 &#39;&gt; 等待下一行，等待单引号开头的字符串的完成 &quot;&gt; 等待下一行，等待双引号字开头的字符串的完成 \&gt;` 等待下一行，等待以反引号开始的标识符的完成 /*&gt; 等待下一行，等待以/*开头的注释的完成–&gt;/*comments*/ 创建和使用数据库Creating and Using a Database 大致操作： Create a database Create a table Load data into the table Retrieve data from the table in various ways Use multiple tables 123456789101112131415161718#显示数据库#不能显示你没有权限的数据库mysql&gt; SHOW DATABASES;#mysql数据库描述用户访问权限#test数据库通常作为用户尝试使用工作区#访问数据库mysql&gt; USE test;#USE和QUIT一样可以不使用分号，使用也无妨#USE只能是一个单行#授权#GRANT ALL ON da_name.table TO 'username'@'host';mysql&gt; GRANT ALL ON test.* TO 'test'@'127.0.0.1'; 创建和选择数据库Creating and Selecting a Database Unix是区分大小写的(case-sensitive)，这与SQL keyword不一致。请注意。 12345678910mysql&gt; CREATE DATABASE db01;mysql&gt; USE db01;#也可在mysql连接时直接指定数据库mysql -u username -p db01#查看当前选择的数据库mysql&gt; SELECT DATABASE(); 创建表Creating a Table 困难的部分是决定数据库的结构应该是什么： 你需要哪些表以及每个表中应该包含哪些列。 VARCHAR对于name，owner，species来说是一个不错的选择，因为column值的长度有所不同。DATE对于出生和死亡column来说很不错。如果以后你发现你需要更长的字段，MySQL提供了一个ALTER TABLE语句来修改。 12345678910111213141516171819202122#创建一个宠物表mysql&gt; CREATE TABLE pet (name VARCHAR(20), owner VARCHAR(20), -&gt; species VARCHAR(20), sex CHAR(1), birth DATE, death DATE);mysql&gt; SHOW TABLES;#验证表格#如果你忘记了表中列的名称或类型，使用DESCRIBEmysql&gt; DECRIBE pet;+---------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+---------+-------------+------+-----+---------+-------+| name | varchar(20) | YES | | NULL | || owner | varchar(20) | YES | | NULL | || species | varchar(20) | YES | | NULL | || sex | char(1) | YES | | NULL | || birth | date | YES | | NULL | || death | date | YES | | NULL | |+---------+-------------+------+-----+---------+-------+6 rows in set (0.00 sec) 将数据载入表格Loading Data into a Table 假设pet表信息如下： name owner species sex birth death PetA Aa cat f 1993-02-04 PetB Bb cat m 1994-03-17 PetC Cc dog f 1989-05-13 PetD Aa dog m 1979-08-25 1995-02-21 PetE Cc bird 1991-02-17 你可以创建一个pet.txt文本文件，每行包含一个记录，值由制表符分割，并按照CREATE TABLE语句中列出的顺序给出。 12345678vim pet.txtPetA Aa cat f 1993-02-04 \NPetB Bb cat m 1994-03-17 \NPetC Cc dog f 1989-05-13 \NPetD Aa dog m 1979-08-25 1995-02-21PetE Cc bird \N 1991-02-17 \N 将pet.txt载入pet表中： 123456789101112131415161718192021222324252627mysql&gt; LOAD DATA LOCAL INFILE '/path/file.txt' INTO TABLE table_name;mysql&gt; LOAD DATA LOCAL INFILE '/home/zhang/pet.txt' INTO TABLE pet;Query OK, 5 rows affected, 0 warnings (0.00 sec)Records: 5 Deleted: 0 Skipped: 0 Warnings: 0mysql&gt; SELECT * FROM pet;+-------+-------+---------+------+------------+------------+| name | owner | species | sex | birth | death |+-------+-------+---------+------+------------+------------+| PetA | Aa | cat | f | 1993-02-04 | NULL || PetB | Bb | cat | m | 1994-03-17 | NULL || PetC | Cc | dog | f | 1989-05-13 | NULL || PetD | Aa | dog | m | 1979-08-25 | 1995-02-21 || PetE | Cc | bird | NULL | 1991-02-17 | NULL |+-------+-------+---------+------+------------+------------+5 rows in set (0.00 sec)#通过命令行载入mysql&gt; INSERT INTO pet -&gt; VALUES ('PetF', 'Ff', 'hamster', 'f', '1999-03-21', NULL) -&gt; ;Query OK, 1 row affected (0.00 sec) 从表中检索信息Retrieving Information from a Table SELECT语句用于从表中提取信息： 123SELECT what_to_selectFROM which_tableWHERE condition; 查询所有数据Selecting All Data 1234567mysql&gt; SELECT * FROM pet;mysql&gt; DELETE FROM pet;mysql&gt; UPDATE pet SET birth = '1989-06-17' WHERE name = 'PetC'; 查询特定行Selecting Particular Rows 当一个表很大时，你通常不想看到整个表。 123456789101112131415161718192021#条件查询mysql&gt; SELECT * FROM pet WHERE name = 'PetA';mysql&gt; SELECT * FROM pet WHERE owner = 'Cc';mysql&gt; SELECT * FROM pet WHERE birth &gt;= '1990-01-01';#ANDmysql&gt; SELECT * FROM pet WHERE species = 'dog' AND sex = 'f';#ORmysql&gt; SELECT * FROM pet WHERE species = 'dog' OR species = 'bird';#AND和OR也可以混合使用mysql&gt; SELECT * FROM pet WHERE (species = 'cat' AND sex = 'm') OR (species = 'dog' AND sex='f'); 查询特定列Selecting Particular Columns 12345678910111213141516171819mysql&gt; SELECT name FROM pet;mysql&gt; SELECT name, species FROM pet;#获取唯一结果mysql&gt; SELECT DISTINCT species FROM pet;+---------+| species |+---------+| cat || dog || bird |+---------+3 rows in set (0.00 sec)mysql&gt; SELECT name, species, birth FROM pet WHERE species = 'dog' OR species = 'cat'; 行排序Sorting Rows 使用ORDER BY语句对结果进行排序。默认排序顺序是升序。 123456789101112131415mysql&gt; SELECT name, birth FROM pet ORDER BY birth;+------+------------+| name | birth |+------+------------+| PetD | 1979-08-25 || PetC | 1989-06-17 || PetE | 1991-02-17 || PetA | 1993-02-04 || PetB | 1994-03-17 |+------+------------+5 rows in set (0.00 sec)#倒序mysql&gt; SELECT name, birth FROM pet ORDER BY birth DESC; 可对多列进行排序，也可按不同的方向对不同的列进行排序。 12345678910111213141516mysql&gt; SELECT name, species, birth FROM pet -&gt; ORDER BY species, birth DESC;+------+---------+------------+| name | species | birth |+------+---------+------------+| PetE | bird | 1991-02-17 || PetB | cat | 1994-03-17 || PetA | cat | 1993-02-04 || PetC | dog | 1989-06-17 || PetD | dog | 1979-08-25 |+------+---------+------------+5 rows in set (0.00 sec)mysql&gt; SELECT name, species, birth FROM pet -&gt; ORDER BY species DESC, birth DESC 日期计算Date Calculations MySQL提供了几个函数用于日期计算。如计算年龄或提取日期一部分等。 TIMESTAMPDIFF() 使用TIMESTAMPDIFF()函数计算pet的年龄。它的两个参数为两个相隔的日期 12345678910111213141516171819202122232425262728mysql&gt; SELECT name, species, birth, CURDATE(), -&gt; TIMESTAMPDIFF(YEAR, birth, CURDATE()) AS age -&gt; FROM pet -&gt; ORDER BY age DESC;+------+---------+------------+------------+------+| name | species | birth | CURDATE() | age |+------+---------+------------+------------+------+| PetD | dog | 1979-08-25 | 2018-03-01 | 38 || PetC | dog | 1989-06-17 | 2018-03-01 | 28 || PetE | bird | 1991-02-17 | 2018-03-01 | 27 || PetA | cat | 1993-02-04 | 2018-03-01 | 25 || PetB | cat | 1994-03-17 | 2018-03-01 | 23 |+------+---------+------------+------------+------+5 rows in set (0.00 sec)#死去的pet的agemysql&gt; SELECT name, species, birth, death, -&gt; TIMESTAMPDIFF(YEAR, birth, death) AS age -&gt; FROM pet -&gt; WHERE death IS NOT NULL -&gt; ORDER BY age;+------+---------+------------+------------+------+| name | species | birth | death | age |+------+---------+------------+------------+------+| PetD | dog | 1979-08-25 | 1995-02-21 | 15 |+------+---------+------------+------------+------+1 row in set (0.00 sec) YEAR() 年 MONTH() 月 DAYOFMONTH() 日 1234567891011121314151617181920212223242526mysql&gt; SELECT name, birth, -&gt; YEAR(birth) AS bir_year, -&gt; MONTH(birth) AS bir_month, -&gt; DAYOFMONTH(birth) AS bir_day -&gt; FROM pet;+------+------------+----------+-----------+---------+| name | birth | bir_year | bir_month | bir_day |+------+------------+----------+-----------+---------+| PetA | 1993-02-04 | 1993 | 2 | 4 || PetB | 1994-03-17 | 1994 | 3 | 17 || PetC | 1989-06-17 | 1989 | 6 | 17 || PetD | 1979-08-25 | 1979 | 8 | 25 || PetE | 1991-02-17 | 1991 | 2 | 17 |+------+------------+----------+-----------+---------+5 rows in set (0.00 sec)#查找生日是2月的petmysql&gt; SELECT name, birth FROM pet WHERE MONTH(birth) =2;+------+------------+| name | birth |+------+------------+| PetA | 1993-02-04 || PetE | 1991-02-17 |+------+------------+ DATE_ADD() 将日期间隔添加到给定日期 12mysql&gt; SELECT name, birth FROM pet -&gt; WHERE MONTH(birth) = MONTH(DATE_ADD(CURDATE(), INTERVAL 1 MONTH)); 使用NULL值Working with NULL Values 从概念上讲，NULL value意味着一个缺失的未知值，它与其它值在某种程度上是不同的。 使用IS NULL和IS NOT NULL操作符 不能对NULL value使用算术运算符(arithmetic cpmparison operators) 如：=, &lt;, &gt;, &lt;&gt; 任何对NULL value的算术运算符的结果也是NULL value，所以无法得到有意义的结果 在MySQL中，0或NULL表示false，其他任何值都意味着true 两个NULL在GROUP BY中被认为是相等的 NULL在ORDER BY正向排序中首先显示。反之，最后显示 123456mysql&gt; SELECT 1 IS NULL, 1 IS NOT NULL;+-----------+---------------+| 1 IS NULL | 1 IS NOT NULL |+-----------+---------------+| 0 | 1 |+-----------+---------------+ 因此，完全可以将一个zero或empty string插入到一个NOT NULL的column中，因为这些值NOT NULL。 模式匹配Pattern Matching MySQL提供标准的SQL模式匹配以及基于扩展正则表达式的模式匹配形式。类似于Unix实用程序(vi, grep, sed…) SQL模式匹配允许: 使用_来匹配可以使用的任意单字符(single character) 使用%来匹配可以使用的任意数目的字符(arbitrary number of characters) SQL模式不区分大小写 使用LIKE或NOT LIKE而不是=或&lt;&gt; 12345678910111213141516mysql&gt; SELECT * FROM pet WHERE name LIKE '%b';+------+-------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+------+-------+---------+------+------------+-------+| PetB | Bb | cat | m | 1994-03-17 | NULL |+------+-------+---------+------+------------+-------+mysql&gt; SELECT * FROM pet WHERE name LIkE '___A' or name LIKE '___C';+------+-------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+------+-------+---------+------+------------+-------+| PetA | Aa | cat | f | 1993-02-04 | NULL || PetC | Cc | dog | f | 1989-06-17 | NULL |+------+-------+---------+------+------------+-------+ MySQL提供的其它类型的模式匹配使用扩展的正则表达式： REGEXP 或 RLIKE NOT REGEXP 或 NOT RLIKE 了解正则表达式知识 123456789101112131415161718192021222324252627282930313233343536373839mysql&gt; SELECT * FROM pet WHERE name RLIKE '^pet[AB]';+------+-------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+------+-------+---------+------+------------+-------+| PetA | Aa | cat | f | 1993-02-04 | NULL || PetB | Bb | cat | m | 1994-03-17 | NULL |+------+-------+---------+------+------------+-------+mysql&gt; SELECT * FROM pet WHERE owner RLIKE 'c$';+------+-------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+------+-------+---------+------+------------+-------+| PetC | Cc | dog | f | 1989-06-17 | NULL || PetE | Cc | bird | NULL | 1991-02-17 | NULL |+------+-------+---------+------+------------+-------+#包含某个字符mysql&gt; SELECT * FROM pet WHERE name RLIKE 'ete';+------+-------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+------+-------+---------+------+------------+-------+| PetE | Cc | bird | NULL | 1991-02-17 | NULL |+------+-------+---------+------+------------+-------+#匹配字符个数mysql&gt; SELECT * FROM pet WHERE name RLIKE '^....$';mysql&gt; SELECT * FROM pet WHERE name RLIKE '^.&#123;4&#125;$';#强制区分大小写mysql&gt; SELECT * FROM pet WHERE name RLIKE BINARY '^Pet[AB]'; 行数计算Counting Rows 使用COUNT()计算行数 12345678910111213141516171819202122232425262728293031323334#总行数mysql&gt; SELECT COUNT(*) AS count FROM pet;+-------+| count |+-------+| 5 |+-------+#针对某个统计行数mysql&gt; SELECT owner, COUNT(*) FROM pet GROUP BY owner;+-------+----------+| owner | COUNT(*) |+-------+----------+| Aa | 2 || Bb | 1 || Cc | 2 |+-------+----------+#多个条件mysql&gt; SELECT species, sex, COUNT(*) FROM pet GROUP BY species, sex;+---------+------+----------+| species | sex | COUNT(*) |+---------+------+----------+| bird | NULL | 1 || cat | f | 1 || cat | m | 1 || dog | f | 1 || dog | m | 1 |+---------+------+----------+ 使用多个表Using More Than one Table 创建一个额外的宠物信息表： name date type remark Fluffy 1995-05-15 litter 4 kittens, 3 female, 1 male Buffy 1993-06-23 litter 5 puppies, 2 female, 3 male Buffy 1994-06-19 litter 3 puppies, 3 female Chirpy 1999-03-21 vet needed beak straightened Slim 1997-08-03 vet broken rib Bowser 1991-10-12 kennel Fang 1991-10-12 kennel Fang 1998-08-28 birthday Gave him a new chew toy Claws 1998-03-17 birthday Gave him a new flea collar Whistler 1998-12-09 birthday First birthday 12345mysql&gt; CREATE TABLE event ( name VARCHAR(20), date DATE, -&gt; type VARCHAR(15), remark VARCHAR(255) );mysql&gt; LOAD DATA INFILE '/path/event.txt' INTO TABLE event; 获取数据库和表的信息Getting Information About Databases and Tables 查看当前数据库 mysql&gt; SELECT DATABASE(); 查看当前数据库下的表 mysql&gt; SHOW TABLES; 查看表的结构 mysql&gt; DESCRIBE pet; 创建数据库 mysql&gt; CREATE DATABASE db_01; 创建表 mysql&gt; CREATE TABLE table_01 {c1 VARCHAR(10), c2 INT, ...}; 查看索引(如果存在) SHOW INDEX FROM table_01; 在批处理下使用mysqlUsing mysql in Batch Mode 在前面，我们都是使用MySQL交互式(interactively)输入命令并查看结果。但还可在批处理模式下运行MySQL。我们可以创建一个脚本文件，然后以这种方式执行脚本文件。 1234567mysql &lt; batch-filemsyql -h host -u user -p &lt; /path/batch-file#出现错误也继续运行msyql -h host -u user -p --force &lt; /path/batch-file 为什么要使用脚本： 如果需要反复(repeat)执行查询，将其写入脚本以避免每次执行时重新输入查询 通过复制和修改脚本文件从现有查询中生成新的查询 批处理模型在开发查询时也很有用，特别是对于多行语句。写错了直接修改脚本就好，而不必重新输入 如果查询产生大量输出，可通过传呼机而不是翻滚到屏幕的最上方 mysql &lt; batch-file | more 可以把输出捕获到一个文件中 mysql &lt; batch-file &gt; mysql.out 可将脚本文件分发给其他人 批处理模式下的MySQL输出更简洁 可使用mysql -t获得交互式数据格式 使用mysql -v将执行语句回显 在mysql命令行中载入脚本 mysql&gt; source filename; 或’mysql&gt; . filename; 常见查询Examples of Common Queries 在命令行使用mysql并选择数据库 1mysql db_name -u user -p 创建和填充表 12345678CREATE TABLE shop ( article INT(4) UNSIGNED ZEROFILL DEFAULT '0000' NOT NULL, dealer CHAR(20) DEFAULT '' NOT NULL, price DOUBLE(16,2) DEFAULT '0.00' NOT NULL, PRIMARY KEY(article, dealer));INSERT INTO shop VALUES (1,'A',3.45),(1,'B',3.99),(2,'A',10.99),(3,'B',1.45), (3,'C',1.69),(3,'D',1.25),(4,'D',19.95); 查看表内容 1SELECT * FROM shop; 列的最大值(maximum) 1234567SELECT MAX(article) AS article FROM shop;SELECT article, MAX(price) AS priceFROM shopGROUP BY article; 使用用户定义的变量(user-defined variables) 123mysql&gt; SELECT @min_price:=MIN(price),@max_price:=MAX(price) FROM shop;mysql&gt; SELECT * FROM shop WHERE price=@min_price OR price=@max_price; 使用外键(Foreign Keys) 在MySQL中，InnoDB表支持检查外键约束。外键约束不仅仅需要连接两个表。 123456789101112131415161718192021222324252627282930313233343536373839CREATE TABLE person ( id SMALLINT UNSIGNED NOT NULL AUTO_INCREMENT, name CHAR(60) NOT NULL, PRIMARY KEY (id));CREATE TABLE shirt ( id SMALLINT UNSIGNED NOT NULL AUTO_INCREMENT, style ENUM('t-shirt', 'polo', 'dress') NOT NULL, color ENUM('red', 'blue', 'orange', 'white', 'black') NOT NULL, owner SMALLINT UNSIGNED NOT NULL REFERENCES person(id), PRIMARY KEY (id));INSERT INTO person VALUES (NULL, 'Antonio Paz');SELECT @last := LAST_INSERT_ID();INSERT INTO shirt VALUES(NULL, 'polo', 'blue', @last),(NULL, 'dress', 'white', @last),(NULL, 't-shirt', 'blue', @last);INSERT INTO person VALUES (NULL, 'Lilliana Angelovska');SELECT @last := LAST_INSERT_ID();INSERT INTO shirt VALUES(NULL, 'dress', 'orange', @last),(NULL, 'polo', 'red', @last),(NULL, 'dress', 'blue', @last),(NULL, 't-shirt', 'white', @last); 在两个键上查找(Searching on Two Keys) 12SELECT field1_index, field2_index FROM test_tableWHERE field1_index = '1' OR field2_index = '1' 使用自动增量 AUTO_INCREMENT属性能够为新行生成一个唯一的标识符。 123456789101112131415CREATE TABLE animals ( id MEDIUMINT NOT NULL AUTO_INCREMENT, name CHAR(30) NOT NULL, PRIMARY KEY (id));INSERT INTO animals (name) VALUES ('dog'),('cat'),('penguin'), ('lax'),('whale'),('ostrich');#设置指定增量开始值mysql&gt; ALTER TABLE tbl AUTO_INCREMENT = 100; MySQL程序 MySQL程序概述Overview of MySQL Programs MySQL安装中有多个不同的程序： mysqldSQL daemon, MySQL Server, mysqld是执行大部分工作的主要程序 mysqld_safe服务器启动脚本mysqld_safe尝试去启动mysqld mysql.server服务器启动脚本此脚本用于System V系统，包含启动特定运行级别的系统服务脚本它调用mysqld_safe来启动MySQL Server mysql_multi可启动和关闭安装在系统上的多个服务器的启动脚本 comp_err在MySQL build/installation过程中使用从错误源文件中编译错误消息文件 mysql_install_db初始化MySQL(数据目录，授权表，并设置InnoDB系统表空间)通常用于首次安装MySQL时 mysql_plugin配置MySQL Server插件 mysql_secure_installation能够提高MySQL安装的安全性 mysql_ssl_rsa_setup如果这些文件丢失，该程序会创建支持安全连接所需的SSL证书和密钥文件以及RSA密钥对文件 mysql_tzinfo_to_sql从mysql数据库中加载时区表 mysql_upgrade在MySQL升级操作后使用它检查表的不兼容性并在必要时修复它们，并用更新版的MySQL的任何更改来更新授权表 mysql交互式输入SQL语句的命令行工具或执行一个批处理模式的文件 mysqladmin执行管理操作的客户端如创建或删除数据库，重新加载授权表，刷新表的磁盘…也可用获取服务器版本、状态、进程信息 mysqlcheck表格客户端用于检查、修复、分析和优化表格 mysqldump将MySQL数据库转储为SQL、文本或XML文件的客户端 mysqlimport使用LOAD DATA INFILE将文本文件导入各自表格的客户端 mysqlpump将MySQL数据库转转储为SQL文件的客户端 mysqlsh用于MySQL Server的高级命令行客户端和代码编辑器除了SQL外，MySQL Shell还为JS和Python提供了脚本功能 mysqlshow显示有关数据库、表、列和索引的信息的客户端 mysqlslap用于模拟MySQL Server的客户端负载并报告每个阶段的时间 MySQL管理和实用程序： innochecksumInnoDB脱机文件校验和程序 myisam_ftdump在MyISAM表中显示有关全文索信息 myisamchk描述，检查，优化和修复MyISAM表 myisamlog处理MyISAM日志文件 myisampack压缩MyISAM表以生成更小的只读表 mysql_config_editor能够将认证凭证存储在名为安全的加密登录路径文件中 mysqlbinlog从二进制日志中读取语句 mysqldumpslow读取和总结慢查询日志内容 MySQL程序开发实用程序： mysql_config一个shell脚本，用于在编译MySQL程序是生产所需的选项值 my_print_defaults：显示选项文件的选项组中存在哪些选项 resolve_stack_dump将数值堆栈跟踪转储解析为符号 杂项(Miscellaneous)工具： lz4_decompress解压缩使用LZ4压缩格式的mysqldump输出 perror显示系统或MySQL错误代码含义 replace再输入文本中执行字符串替换 resolveip将主机名解析为IP地址，反之亦然 zlib_decompress解压缩使用ZLIB压缩格式的mysqldump输出 Oracle公司还提供了MySQL Workbench GUI工具，用于管理、创建、知悉和评估查询，以及从其它关系数据库管理系统迁移到MySQL系统。 MySQL Client和Server间的通信使用如下环境变量： Environment Variable Meaning MYSQL_UNIX_PORT The default Unix socket file; used for connections to localhost MYSQL_TCP_PORT The default port number; used for TCP/IP connections MYSQL_PWD The default password, insecure MYSQL_DEBUG Debug trace options when debugging TMPDIR The directory where temporary tables and files are created 使用MySQL程序调用MySQL程序从命令行调用一个MySQL程序，输入程序名称和选项及参数。 1234$ mysql --user=root test$ mysqladmin extended-status variables$ mysqlshow --help$ mysqldump -u root personnel 连接到MySQL Server介绍如何连接到MySQL Server。 MySQL程序环境变量的优先级最低，命令行选项最高。你可在配置文件中指定程序的默认值，同时你又可以使用命令行选项覆盖它。MySQL选项按顺序处理，所以如果多次指定选型，则最后一个选项优先。 123mysql --hostname xx --port xx --user xx --password $&#123;dbname&#125; --protocol=TCPmysql -h -P -u -p $&#123;dbname&#125; --protocol值： TCP(all) SOCKET(Unix) PIPE(windows) MEMORY(windows) 你可以在选项文件的[client]部分指定连接参数: 12345[client]host=xxxport=xxxuser=xxxpassword=xxx 1234567mysqladmin -u user -p --count=1k --sleep=10 pingmysql -u user -pxxx --execute=&quot;DESCRIBE db.table&quot;#执行多个语句mysql -u root -p -e &apos;SELECT VERSION(); SELECT NOW()&apos; 配置文件大多数MySQL程序都可从选项文件中读取启动选项。 MySQL不保证配置文件的读取顺序。 Unix和Unix-Like平台的MySQL配置文件： 文件 描述 /etc/my.cnf 全局选项 /etc/mysql/my.cnf 全局选项 $SYSCONFDIR/my.cnf 全局选项 $MYSQL_HOME/my.cnf MySQL Server Only ~/.my.cnf 特定用户选项 ~/.mylogin.cnf 特定用户登录选项，Client Only default-extra-file 使用--defaults-extra-file指定的文件 配置文件解释： 空行被忽略 #号表示注释 前后空格将自动从选项名称和值中删除 [group]为其设置配置项的程序名或组名。在此之后，任何选项设置都会应用到指定组，知道给出结尾。选项组名称不区分大小写。 你可在选项值中使用转义序列\b, \t, \n, \r, \\, \s !include来包含其它配置文件 123456789101112131415161718192021DATADIRmysqld --datadir[mysqld]port=3306socket=/tmp/mysql.sockkey_buffer_size=16Mmax_allowed_packet=8M[mysql]port=3306socket=/tmp/mysql.sockno-auto-rehash[mysqldump]quick!include /home/mysql/myopt.cnf 影响配置文件的命令行选项 --print-defaults --defaults-extra-file --defaults-file --defaults-group-suffix --login-path --no-defaults 使用选项指定环境变量 1234567891011[mysql]max_allowed_packet=16M[mysqld]key_buffer_size=512Mmysql --max_allowed_packet=16Mshell&gt; mysql --max_allowed_packet=16*1024*1024mysql&gt; SET GLOBAL max_allowed_packet=16*1024*1024; MySQL Server mysqldThe MySQL Server mysql_safeMySQL Server Startup Script mysql.serverMySQL Server Startup Script mysqld_multiManage Multiple MySQL Servers mysqldmysqld，也被称为MySQL服务器，是执行MySQL大部分工作的主要程序。MySQL服务器管理对包含数据库和表的MySQL数据目录的访问。 查看帮助： mysqld --verbose --help mysql_safe对于某些Linux平台，从RPM或DBP包安装的MySQL包括了用于管理MySQL服务启动和管理的systemd支持。在这些平台上，mysqld_safe不会被安装，因为它不是必须的。 mysql_safe是Unix上启动mysqld服务器的推荐方式。它添加了一些安全特性，如发生错误是重启服务器并将运行时的错误记录到日志。 mysqld_safe尝试启动一个名为mysqld的可执行程序。它会读取配置文件中[mysqld], [server], [mysqld_safe]部分的所有选项。 mysqld_safe选项： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647--basedir--core-file-size--datadir--defaults-extra-file--defaults-file--ledir--log-error--mallocl-lib--mysqld--mysqld-safe-login-timestamps--mysql-version--nice--no-defaults--open-files-limit--pid-file--plugin-dir--plugin-dir--port--skip-kill-mysqld--skip-syslog--socket--syslog-tag--timezone--user mysql.server对于某些Linux平台，从RPM和DPG包安装的MySQL包括了用于管理MySQL Server启动和关闭的systemd支持。在这些平台上，没有安装mysql.server和mysqld_safe，因为它们不是必须的。 Unix和Unix-Like平台上的MySQL发行版包含一个名为mysql.server的脚本，该脚本使用mysqld_safe启动MySQL Server。 mysqld_multi对于某些Linux平台，从RPM和DPG包安装的MySQL包括了用于管理MySQL Server启动和关闭的systemd支持。在这些平台上，没有安装mysqld_multi，因为它们不是必须的。 mysqld_multi设计用于管理多个监听不同Unix socket文件和TCP/IP port上连接的mysqld进程。 MySQL安装相关程序这些程序用于安装或升级MySQL！ com_errCompile MySQL Error Message File mysql_install_dbInitialize MySQL Data Directory mysql_pluginConfigure MySQL Server Plugins mysql_secure_installationImprove MySQL Installation Security mysql_ssl_rsa_setupCreate SSL/RSA Files mysql_tzinfo_to_sqlLoad the Time Zone Tables mysql_upgradeCheck and Upgrade MySQL Tables com_errcomp_err创建errmsg.sys文件，mysqld使用此文件来确定为不同错误代码(error code)显示错误消息。通常，在构建MySQL时，comp_err会自动运行。它从位于MySQL源发行版sq;/share/errmsg-utf8.txt文本文件汇编errmsg.sys文件。 comp_err同样会生成mysqld_error.h, mysqld_ername.h, sql_state.h头文件。 mysql_install_db在MySQL5.7中，由于mysql_install_db的功能已经被集成到mysqld中，因此不推荐使用它。在MySQL5.7.5之前，mysql_install_db是一个Perl脚本并依赖于Perl。在此之后，它是由C++写的可执行二进制文件。还有一些选项的更迭。 1234mysqld --initailize#ormysqld --initialize-insecure mysql_install_db处理在MySQL Server(mysqld)准备好使用之前，必须执行的初始化任务： 初始化MySQL数据目录，创建它包含的系统表 初始化管理InnoDB表所需的system tablespace和相关数据结构 加载服务器端help表 安装sys schema 创建一个管理员账户老版本的mysql_install_db可能会创建匿名账户。 如果mysql_install_db生成了一个随机管理员密码，它将把此密码写入文件并显示此文件名。密码包含一个时间戳以指示它的写入时间。默认情况下，该文件是用户主目录中的.mysql_secret文件。 mysql_plugin从MySQL5.7.11开始，不推荐使用mysql_plugin，并会在MySQL8.0中移除此功能。使用如下命令替代： 123456--plugin-load--plugin-load-add#或mysql&gt; INSTALL PLUGINmysql&gt; UNINSTALL PLUGIN mysql_plugin功能允许MySQL管理员管理由MySQL Server载入的插件。 mysql_secure_installationmysql_secure_installation通过以下方式来提高MySQL安装的安全性： 为root用户设置密码 删除可从本机外部访问的root账户 删除匿名账户 删除test数据库(默认情况下可由任何用户访问，包括匿名用户) 删除允许任何人访问以test_开头的数据库的权限 mysql_ssl_rsa_setupmysql_ssl_rsa_setup创建SSL证书和key文件和RSA key-pair文件，用于支持使用SSL进行安全连接。它生成的整数是自签名的，不太安全。请考虑从注册机构申请CA证书。mysql_ssl_rsa_setup使用opensll命令，所以请安装OpenSSL。 mysql_tzinfo_to_sqlmysql_tzinfo_to_sql加载MySQL数据库中的zone table。它使用系统上的zoneinfo信息。 msyql_upgrademysql_upgrade检查数据库中的所有表与当前版本的MySQL Server的不兼容，它还升级系统表，以便你可以利用新权限和功能。如果mysql_upgrade发现表有可能的不兼容性，它会执行检查表，如果发现问题，则会尝试修复表。 每次升级MySQL时都应该执行mysql_upgrade。在执行upgrade之前，你应该始终备份你的MySQL。 MySQL客户端程序 mysqlThe MySQL Command-Line Tool mysqladminClient for Administering a MySQL Server mysqlcheckA Table Maintenance Program mysqldumpA Database Backup Program mysqlimportA Data Import Program mysqlpumpA Database Backup Program mysqlshThe MySQL Shell mysqlshowDisplay Database, Table, and Column Information mysqlslapLoad Emulation Client mysqlmysql是一个具有输入编辑功能的SQL shell。 123456mysql --host= --port= --user= --password db_name#SQL文件#SQL语句以 ;或\g或\G结束mysql db_name &lt; script.sql &gt; output.tab mysql选项MySQL支持很多选项。这些选项可以写入配置文件的[mysql]和[client]组中。 1mysql --help mysql命令mysql将你发出的每个SQL语句发送到要执行的Server。如下为mysql自己解释的命令： 123456789101112131415161718192021222324252627282930mysql&gt; help;List of all MySQL commands:Note that all text commands must be first on line and end with &apos;;&apos;? (\?) Synonym for `help&apos;.charsetclear (\c) Clear the current input statement.connect (\r) Reconnect to the server. Optional arguments are db and host.delimiter (\d) Set statement delimiter.edit (\e) Edit command with $EDITOR.ego (\G) Send command to mysql server, display result vertically.exit (\q) Exit mysql. Same as quit.go (\g) Send command to mysql server.help (\h) Display this help.nopager (\n) Disable pager, print to stdout.notee (\t) Don&apos;t write into outfile.pager (\P) Set PAGER [to_pager]. Print the query results via PAGER.print (\p) Print current command.prompt (\R) Change your mysql prompt.quit (\q) Quit mysql.rehash (\#) Rebuild completion hash.source (\.) Execute an SQL script file. Takes a file name as an argument.status (\s) Get status information from the server.system (\!) Execute a system shell command.tee (\T) Set outfile [to_outfile]. Append everything into given outfile.use (\u) Use another database. Takes database name as argument.charset (\C) Switch to another charset. Might be needed for processing binlog with multi-byte charsets.warnings (\W) Show warnings after every statement.nowarning (\w) Don&apos;t show warnings after every statement.resetconnection(\x) Clean session context. 修改MySQL提示符 123456789101112131415#shellexport MYSQL_PS1=&quot;(\u@\h) [\d]&gt; &quot;#mysqlmysql --prompt=&quot;(\u@\h) [\d]&gt; &quot;#配置文件[mysql]prompt=(\\u@\\h) [\\d]&gt;\\_#mysql promptmysql&gt; prompt (\u@\h) [\d]&gt;\_ mysql服务端帮助mysql Server-Side Help 如果给help命令提供一个参数，mysql将其用作搜索字符串，以从MySQL参考手册的内容访问服务端帮助。 12345678910mysql&gt; help memysql&gt; help contentsmysql&gt; help logsmysql&gt; help rep% 从文本文件执行SQL语句mysql忽略文件开头的Unicode字节顺序标记(BOM)字符。BOM的存在不会导致MySQL更改其默认字符集(charset)。因此，请使用--default-char-set选项。 12345678910#shellmysql db_name &lt; test_filemysql&gt; source file_namemysql&gt; \. file_name#显示进度信息SELECT &apos;&lt;info_to_display&gt;&apos; AS &apos; &apos;; MySQL管理和实用程序 inochecksumOffline InnoDB File Checksum Utility myisam_ftdumpDisplay Full-Text Index information myisamchkMyISAM Table-Maintenance Utility myisamlogDisplay MyISAM Log File Contents myisampackGenerate Compressed, Read-Only MyISAM Tables mysql_config_editorMySQL Configuration Utility mysqlbinlogUtility for Processing Binary Log Files mysqldumpslowSummarize Slow Query Log Files mysql开发实用程序 mysql_configDisplay Options for Compiling Clients my_print_defaultsDisplay Options from Option Files resolve_stack_dumpResolve Numeric Stack Trace Dump to Symbols 杂项程序Miscellaneous Programs lz4_decompressDecompress mysqlpump LZ4-Compressed Output perrorExplain Error Codes replaceA String-Replacement Utility resolveipResolve Host name to IP Address or Vice Versa zlib_decompressDecompress mysqlpump ZLIB-Compressed Output MySQL环境变量这些环境变量直接或间接的被MySQL使用。 Variable Description AUTHENTICATION_LDAP_CLIENT_LOG Client-side LDAP authentication logging level. AUTHENTICATION_PAM_LOG PAM authentication plugin debug logging settings. CC The name of your C compiler (for running CMake). CXX The name of your C++ compiler (for running CMake). CC The name of your C compiler (for running CMake). DBI_USER The default user name for Perl DBI. DBI_TRACE Trace options for Perl DBI. HOME The default path for the mysql history file is $HOME/.mysql_history. LD_RUN_PATH Used to specify the location of libmysqlclient.so. LIBMYSQL_ENABLE_CLEARTEXT_PLUGIN Enable mysql_clear_password authentication plugin; see Section 6.5.1.6, “Client-Side Cleartext Pluggable Authentication”. LIBMYSQL_PLUGIN_DIR Directory in which to look for client plugins. LIBMYSQL_PLUGINS Client plugins to preload. MYSQL_DEBUG Debug trace options when debugging. MYSQL_GROUP_SUFFIX Option group suffix value (like specifying –defaults-group-suffix). MYSQL_HISTFILE The path to the mysql history file. If this variable is set, its value overrides the default for $HOME/.mysql_history. MYSQL_HISTIGNORE Patterns specifying statements that mysql should not log to $HOME/.mysql_history, or syslog if –syslog is given. MYSQL_HOME The path to the directory in which the server-specific my.cnf file resides. MYSQL_HOST The default host name used by the mysql command-line client. MYSQL_OPENSSL_UDF_DH_BITS_THRESHOLD Maximum key length for CREATE_DH_PARAMETERS(). See Section 12.18.2, “Enterprise Encryption Usage and Examples”. MYSQL_OPENSSL_UDF_DSA_BITS_THRESHOLD Maximum DSA key length for CREATE_ASYMMETRIC_PRIV_KEY(). See Section 12.18.2, “Enterprise Encryption Usage and Examples”. MYSQL_OPENSSL_UDF_RSA_BITS_THRESHOLD Maximum RSA key length for CREATE_ASYMMETRIC_PRIV_KEY(). See Section 12.18.2, “Enterprise Encryption Usage and Examples”. MYSQL_PS1 The command prompt to use in the mysql command-line client. MYSQL_PWD The default password when connecting to mysqld. Using this is insecure. See Section 6.1.2.1, “End-User Guidelines for Password Security”. MYSQL_TCP_PORT The default TCP/IP port number. MYSQL_TEST_LOGIN_FILE The name of the .mylogin.cnf login path file. MYSQL_TEST_TRACE_CRASH Whether the test protocol trace plugin crashes clients. See note following table. MYSQL_TEST_TRACE_DEBUG Whether the test protocol trace plugin produces output. See note following table. MYSQL_UNIX_PORT The default Unix socket file name; used for connections to localhost. MYSQLX_TCP_PORT The X Plugin default TCP/IP port number. MYSQLX_UNIX_PORT The X Plugin default Unix socket file name; used for connections to localhost. PATH Used by the shell to find MySQL programs. PKG_CONFIG_PATH Location of mysqlclient.pc pkg-config file. See note following table. TMPDIR The directory in which temporary files are created. TZ This should be set to your local time zone. See Section B.5.3.7, “Time Zone Problems”. UMASK The user-file creation mode when creating files. See note following table. UMASK_DIR The user-directory creation mode when creating directories. See note following table. USER The default user name on Windows when connecting to mysqld. MySQL Server管理MySQL Servermysqld is the MySQL Server.并非所有的MySQL Server二进制文件和配置都支持所有的存储引擎。 12345678910#查看帮助mysqld --verbose --help#运行Server的环境变量mysql&gt; SHOW VARIABLES;#运行Server的状态mysql&gt; SHOW STATUS; MySQL数据目录由MySQL管理的信息存储在称为数据目录的目录下。 数据目录子目录：每个子目录都是数据库目录对应于Server管理的数据库 mysql performance_schema sys 数据库 日志文件由Server写入 innoDB表空间和日志文件 自动生成的SSL/RSA证书和密钥文件 Server PID mysql数据库The mysql System Database The mysql database is the system database.它的表中存储了MySQL Server运行时需要的信息。 授权系统表如下这些系统表包含了用户账户和权限的授权信息。 userUser accounts, global privileges, and other non-privilege columns. dbDatabase-level privileges. tables_privTable-level privileges. columns_privColumn-level privileges. procs_privStored procedure and function privileges. proxies_privProxy-user privileges. 对象信息系统表如下这些系统表包含了存储程序，用户定义函数和服务器端插件的信息。 event关于Event Scheduler事件的信息 func用户定义函数的信息 plugin服务器端的插件的信息 proc有关存储过程和函数的信息 日志系统表Server使用如下系统表记录日志。日志表使用CSV存储引擎。 general_log一般查询日志表 slow_log慢查询日志表 服务器端帮助系统表如下系统表包含了服务器端帮助信息。 help_categoryInformation about help categories. help_keywordKeywords associated with help topics. help_relationMappings between help keywords and topics. help_topicHelp topic contents. 时区系统表如下系统表包含了时区信息。 time_zoneTime zone IDs and whether they use leap seconds. time_zone_leap_secondWhen leap seconds occur. time_zone_nameMappings between time zone IDs and names. time_zone_transition, time_zone_tansition_typeTime zone descriptions. 副本系统表Server使用如下这些系统表来提供副本服务。这些表使用InnoDB存储引擎。 gtid_executedTable for storing GTID values. ndb_binlog_indexBinary log information for NDB Cluster replication. slave_master_info, slave_relay_log_info, slave_worker_infoUsed to store replication information on slave servers. 优化器系统表如下系统表用于优化。 innodb_index_stats, innodb_table_statsUsed for InnoDB persistent optimizer statistics server_cost, engine_costThe optimizer cost model uses tables that contain cost estimate information about operations that occur during query execution. 杂项系统表 audit_log_filter, audit_log_user firewall_users, firewall_whitelist servers MySQL Server LogsMySQL Server提供如下几种日志： Error log启动、运行或停止mysqld遇到的问题 General query log建立Client连接和从Client收到的语句 Binary log更改数据的语句 Relay log从replication master server收到的数据更改 Slow query log执行时间超过long_query_time秒的查询 DDL(Metadata) log由DDL语句执行的元数据操作 默认情况下，不启用任何日志。 如果启用了这些日志，MySQL Server可以灵活地控制一般查询日志和慢查询日志的输出目的地——它可为日志文件或mysql数据库中的general_log和slow_log表。 123456789101112131415#--log-output#它的值可为TABLE/FILE/NONE#--general-log, --slow-query-log#TABLE和FILEmysqld --log-output=TABLE,FILE --general-log=msyql.general_log --slow-query-log=mysql.slow_log#or[mysqld]log_output=general_log=slow_query_log= 查看两个日志表的标准格式： 12SHOW CREATE TABLE mysql.general_log;SHOW CREATE TABLE mysql.slow_log; 错误日志The Error Log 错误日志包含mysqld启动和关闭时间的记录。它还包含诊断信息。 Unix/Unix-Like OS使用mysqld --log-error选项来将错误日志写入控制台(stderr)或文件。 如果未指定文件名，则默认为数据目录下的host_name.err文件。YUM或APT包安装，则配置的错误日志文件为--log-error=/var/log/mysqld.log。 将错误日志记录到系统日志Error Logging to the System Log 使用如下系统变量： log_syslog启用此变量将错误日志发送到系统日志 log_syslog_facilitysyslog消息的默认设置时daemon。设置此变量以指定其它工具。 log_syslog_include_pid是否在syslog输出中包含Server的PID。 log_syslog_tag在syslog消息中添加一个tag。 1msyqld --log_syslog= 错误日志过滤Error Log Filtering log_error_verbosity变量控制错误日志的详细程度。值如下： 1error only 2errors, warning 3(默认)errors, warnings, notes 错误日志消息格式Error Log Message Format 错误日志中包含的ID是mysqld中负责编写消息的线程的ID。这表示Server的哪部分生成了消息。log_timestamps变量控制写入错误日志的时区和时间格式。 1mysqld --log-timestamps= 错误日志文件刷新Error Log File Flushing and Renaming 如果你使用FLUSH_ERROR_LOGS, FLUSH_LOGS或mysqladmin flush-logs刷新日志，Server将关闭并重新打开它正在写的任何错误日志文件。 12mv host_name.err host_name.err-oldmysqladmin flush-logs 一般查询日志The General Query Log 一般查询日志是mysqld执行操作的记录。当Client连接或断开时，Server将此信息写入日志，并记录从Client收到的每个SQL语句。mysqld按照接收的顺序而不是执行顺序将语句写入日志。 默认情况下，一般查询日志是禁用的。指定初始化查询日志状态--general_log={0|1}。1启用，0禁用。指定日志文件名--general-log-file=file-name.如果未指定，默认为数据目录下host_name.log，除非指定了其它路径。指定日志文件位置--log-output=. 12345mysqld --log-output=&apos;/var/log/mysql&apos; --general-log=1 --general-log-file=&apos;general.log&apos;shell&gt; mv host_name.log host_name-old.logshell&gt; mysqladmin flush-logs 二进制日志The Binary Log 安全Security 当考虑MySQL安装中的安全性时，你应该考虑各种可能的主题以及他们如何影响MySQL Server和相关应用程序的安全性: 影响安全性的一般因素。包括选择好的密码，不向用户授予不必要的权限，防止SQL注入和数据损坏来确保应用程序的安全性… 安装本身的安全性。应保护数据文件，日志文件和安装的所有应用程序文件，以确保未经授权方无法读写这些文件… 数据库系统本身的访问控制和安全性。包括允许访问数据库中使用的数据库，视图和存储应用程序的用户和数据库… 安全相关插件提供的功能… MySQL和你的系统的网络安全性。安全性还与用户的授权有关，但你可能希望限制MySQL，使其仅在本地主机上可用，或者在一组有限的其它主机上可用… 确保你备份了足够和适当的数据库文件，配置和日志文件。还要确保你已准备好恢复解决方案，并测试是否能够从备份种恢复信息… 一般安全问题General Security Issues 本节介绍了要注意的一般安全问题，以及如何使MySQL安装更安全，防止攻击或滥用。 安全指南Security Guidelines 在连接了Internet的计算机上使用MySQL的任何人都应阅读本节，以避免最常见的安全错误。在讨论安全性时，有必要考虑完全保护整个服务器主机免受所有类型的攻击：窃听，更改，拒绝服务… MySQL使用基于访问控制列表(ACL)的安全性，来处理用户可以尝试执行的所有连接、查询和其它操作。MySQL Client和Server之间SSL加密连接。 当运行MySQL时，遵循以下准则： 不要让任何人(root除外)访问mysql.user数据表，这很关键。 了解MySQL访问权限系统的工作原理。使用GRANT和REVOKE语句来控制对MySQL的访问。不要授予超出必要的权限，永远不要授予所有主机权限。如果你能够在不被要求输入密码的情况下成功连接到MySQL Server，则任何人都可以以具有完全权限的root用户身份连接到MySQL Server。请重新查看MySQL安装说明，特别注意有关设置root密码的信息。检查哪些账户拥有访问权限，并移除不必要的权限。 1234567891011#测试mysql -u root#访问权限SHOW GRANTS;#移除权限#help REVOKEREVOKE 不要在数据库中存储明文密码。如果计算机被攻击，入侵者可以获得完整的密码列表并使用他们。相反，使用一些HASH函数并存储散列值。 不要从字典中选择密码，即不要使用简单和常规密码。存在某些破解密码的程序能计算你的密码。 启用防火墙。这可以保护你免受大部分漏洞攻击。将MySQL放在防火墙后面或DMZ。使用端口扫描软件(如nmap)扫描主机端口。MySQL默认使用3306端口。不应从不受信任的主机访问此端口。测试你的端口安全性： 123456789101112131415[zhang@zhang21 ~]$ telnet zhang21 3306Trying 192.168.31.119...Connected to zhang21.Escape character is &apos;^]&apos;.@Host &apos;zhang21&apos; is not allowed to connect to this MySQL serverConnection closed by foreign host.[zhang@zhang21 ~]$ telnet localhost 3306Trying ::1...Connected to localhost.Escape character is &apos;^]&apos;.J5.7.22[cqo3I @kX@n#I\mysql_native_password 访问MySQL的应用程序不应该信任用户输入的任何数据，应该使用适当的防御性编程技术编写。 不要通过Internet传输普通数据(未加密)。请使用SSL或SSH加密协议。MySQL支持内部SSL连接；或是使用SSH端口转发为通信创建加密隧道。 学习使用tcpdump和strings使用程序。可使用如下命令来检查MySQL数据流是否加密: 1tcpdump -l -i eth0 -w - src or dst port 3306 | strings 密码安全Keeping Passwords Secure 密码出现在MySQL的多个上下文中。此解提供了一些准则，使用户和管理员能够保护这些密码的安全性，并避免暴露这些密码。还讨论了MySQL如何在内部使用密码散列以及可用来强制执行更严格密码的插件。 密码安全用户指南End-User Guidelines for Password Security MySQL用户应使用以下准则来保证密码安全。当运行Client连接到MySQL server时，不建议以公开的方式来指定你的密码。 使用mysql_config_editor实用程序，它可将身份认证凭据存储在名为.mylogin.cnf的加密登录路径文件中。 使用-pPASSWD或--password=PASSWD选项 使用-p或--password选项不指定值 将密码存储到配置文件 将密码存储到MYSQL_PWD环境变量 12345678910111213141516171819202122232425#强烈不推荐#这虽然方便却不安全mysql -u user -pPASSWD db_name#推荐#但这适用于交互式mysql -u user -p db_nameEnter password: xxx#写入配置文件chmod 600 ~/.my.cnfvim ~/.my.cnf[client]password=xxxmysql --defaults-file=~/.my.cnf#指定MySQL密码环境变量的方法非常不安全，不应该使用 在Unix上，MySQL Client将执行语句的记录写入历史文件。默认情况下，此文件为~/.mysql_history。密码可以在SQL语句中以纯文本形式写入(如CREATE USER, ALTER USER)，如果使用了这些语句，它们将被记录到历史文件中。要保证此文件的安全，请使用限制访问模式。 如果命令解释器程序配置为维护历史记录，则保存命令的任何文件都将包含在命令行中输入的MySQL密码。如bash下的~/.bash_history。 密码安全管理员指南Administrator Guidelines for Password Security MySQL数据库管理员应使用以下准则来保证密码安全： MySQL在mysql.user表中存储用户账户密码。永远不要向任何非管理账户授予此表的访问权限 账户密码可以过期，以便用户必须重置密码 validate_password插件可用于对可接受的密码强制实施策略 应该保护可能写入密码的日志文件等文件 密码和日志Passwords and Logging 密码可在SQL语句中以纯文本形式写入，如CREATE USET, GRANT, SET PASSWORD和调用PASSWORD()函数的语句。如果MySQL Server记录了这些语句，那么访问日志的任何人都可以看到密码。 语句记录避免以明文形式为以下语句编写密码： 1234567CREATE USER ... IDENTIFIED BY ...ALTER USER ... IDENTIFIED BY ...GRANT ... IDENTIFIED BY ...SET PASSWORD ...SLAVE START ... PASSWORD = ...CREATE SERVER ... OPTIONS(... PASSWORD ...)ALTER SERVER ... OPTIONS(... PASSWORD ...) 对于常规查询日志，可通过使用--log-raw选项启动Server来抑制密码重写。出于安全原因，此选项不建议用于生产环境。处于诊断目的，查看Server收到的语句的确切文本可能很有用。审计日志插件生成的审计日志文件的内容未加密。出于安全原因，应将此文件写入只有MySQL Server和用户才能访问的目录，并且有正当理由查看目录。只有在需要纯文本密码时才会进行密码重写，对于具有期望密码散列语法的语句，不会发生重写。要保护日志文件免受不必要的暴露，请将他们放在限制访问Server和管理员的目录中。副本集slave将复制副本集master的密码存储在主信息存储库中，它可以是文件或表。确保只能由管理员访问此库。 使用受限的访问模式来保护包含日志表或密码的日志文件的数据库备份。 密码散列Password Hashing in MySQL MySQL在mysql.user数据表中列出用户账户。可以为每个MySQL账户分配一个密码，尽管用户表不存储明文密码，而是存储密码的散列值。 MySQL在Client/Server通信的两个阶段中使用密码： 当客户端尝试连接到Server时，有一个初始身份认证步骤，其中客户端必须提供密码，该密码的散列值与mysql.user用户表中存储的散列值相匹配 客户端连接之后，它可以(如果有足够权限)设置或更改mysql.user用户表中账户的密码的散列值。客户端可通过使用PASSWORD()函数来生成密码散列，或使用密码生成语句(CREATE USER, GRANT, SET PASSWORD)来完成此操作。 换句话说，Server在客户端首次尝试连接时在身份认证期间检查散列值。如果连接的客户端调用PASSWORD()函数，或使用密码生成语句来设置/更改密码，则Server会生成散列值。 12345678910111213141516171819202122232425help PASSWORD;#This function is deprecated as of MySQL 5.7.6 and will be removed in a future MySQL release#The Original (Pre-4.1) Hashing Method#原始散列方法产生一个16Byte的字符串mysql&gt; SELECT PASSWORD(&apos;mypass&apos;);+--------------------+| PASSWORD(&apos;mypass&apos;) |+--------------------+| 6f8c114b58f2ce9e |+--------------------+#The 4.1 Hashing Method#MySQL4.1引入了密码散列，提供了更好的安全性并降低了密码被截获的风险#生成更长的41Byte的散列值mysql&gt; SELECT PASSWORD(&apos;mypass&apos;);+-------------------------------------------+| PASSWORD(&apos;mypass&apos;) |+-------------------------------------------+| *6C8989366EAF75BB670AD8EA7A7FC1176A95CEF4 |+-------------------------------------------+ 散列方法的兼容性问题Compatibility Issues Related to Hashing Methods 使MySQL安全抵御攻击者Making MySQL Secure Against Attackers 连接到MySQL server时，应使用密码。密码在连接时不会以明文形式传输。所有其它信息都以文本形式传输，对任何能够看到连接的人都可读。如果连接通过不信任的网络，则可以使用压缩协议使流量更难以解密。你还可以使用MySQL的内部SSL支持来使连接更安全。或者，使用SSH在MySQL server和client之间获得加密的TCP/IP连接。 要使得MySQL系统安全，你应该强烈考虑以下建议： 要求所有MySQL账户都有密码 确保只有Unix用户账户对数据库目录具有读写权限，它是用于运行mysqld的账户 永远不要以root用户运行MySQL server，应该使用普通的非特权用户运行 MySQL用户账户和Unix系统账户没有关联 不要对非管理员用户授予FILE权限，具有此权限的用户都可使用mysqld daemon的权限在文件系统的任何位置编写文件，同样也可读取文件，并将文件载入数据库 不要对非管理员用户授予PROCESS或SUPER权限(可用于终止连接，修改系统变量…) 不允许对表使用符号链接 安全地存储程序和视图 如果不信任DNS，则应在授权表中使用IP地址而非主机名 如果想要限制单个账户的连接数，可在mysqld中配置max_user_connection变量 如果插件目录对server可写，这可修改它为只读 12345678910111213141516171819202122232425262728#服务cat /usr/lib/systemd/system/mysqld.service[Service]User=mysqlGroup=mysql#或配置文件/etc/my.cnf[mysqld]user=mysql#查看当前正在执行的语句msyql&gt; SHOW PROCESSLIST;+----+------+-----------+-------+---------+------+----------+------------------+| Id | User | Host | db | Command | Time | State | Info |+----+------+-----------+-------+---------+------+----------+------------------+| 18 | root | localhost | mysql | Query | 0 | starting | SHOW PROCESSLIST |+----+------+-----------+-------+---------+------+----------+------------------+# Disabling symbolic-links is recommended to prevent assorted security riskscat /etc/my.cnfsymbolic-links=0 安全相关的mysqld选项和变量Security-Related mysqld Options and Variables 下表显示了影响安全性的mysqld的选项和系统变量: Name Cmd-Line Option File System Var Status Var Var Scope Dynamic allow-suspicious-udfs Yes Yes automatic_sp_privileges Yes Global Yes chroot Yes Yes des-key-file Yes Yes local_infile Yes Global Yes old_passwords Yes Both Yes safe-user-create Yes Yes secure-auth Yes Yes Global Yes - Variable: secure_auth Yes Global Yes secure-file-priv Yes Yes Global No - Variable: secure_file_priv Yes Global No skip-grant-tables Yes Yes skip-name-resolve Yes Yes Global No - Variable: skip_name_resolve Yes Global No skip-networking Yes Yes Global No - Variable: skip_networking Yes Global No skip-show-database Yes Yes Global No - Variable: skip_show_database Yes Global No 以普通用户运行MySQLHow to Run MySQL as a Normal User 在Linux上，使用MySQL-repo、RPM包、Debian包来安装MySQL。MySQL server mysqld默认是由操作系统的mysql用户来启动。 对于使用.tar.gz包进行的安装，你需要修改为non-root用户。 1234567chown -R user_name /path/to/mysql/datadirvim /etc/my.cnf[mysqld]user=user_name LOAD DATA LOCAL的安全问题LOAD DATA语句可以载入主机上的文件。 这有两个潜在的安全问题： 从Client到Server的文件传输是由MySQL server启动。理论上，server可告诉client传输server选择的文件而不是LOAD DATA语句中client指定的文件。这样，server可以访问client端用户可访问的任何文件。 在client从web server连接的Web环境中，用户可使用LOAD DATA LOCAL来读取Web server进程具有访问权限的任何文件。 为了避免LOAD DATA问题，客户端应该避免使用LOCAL。为避免连接到不受信任的Server，Client可通过--ssl-mode=xxx选项和相应的CA证书建立安全的连接。 要是管理员和应用程序能够管理本地数据加载功能，LOCAL配置的工作方式如下： On the server sidelocal_infile系统变量控制服务器端的LOCAL功能。默认启用local_infile。 On the client sideENABLED_LOCAL_INFILE CMake选项控制MySQL Client Library的已编译的默认LOCAL功能。使用C API的客户端程序可通过调用mysql_options()来启用/禁用MYSQL_OPT_LOCAL_INFILE。对于mysql Client，默认禁止本地数据载入。使用--local-infile=1/0对于mysqlimport client，默认禁用本地数据载入。使用--local=1/0 客户端程序安全指南Client Programming Security Guidelines 访问MySQL的应用程序不应该信任用户输入的任何数据，用户可以尝试通过在Web表单，URL或构建的任何应用程序中输入特殊字符序列来欺骗你。如果用户输入DROP DATABASE mysql;类似语句，请确保你的应用程序保持安全，这是一个极端栗子。有时人们会认为，如果数据库只包含公开可用的数据，则无需受到保护。这是不正确的。即使允许在数据库中显示任何行，你仍应该防止拒绝服务攻击。 检查清单： 启用更严格的SQL模式以告知server对其接收的数据做更多限制 注意单/双引号 通过添加%22(&quot;), %23(&quot;), %27(&#39;)来修改动态URLs 动态修改URL中的数据类型 尝试输入字符、空格和特殊符号，而不是 数字 将数据传递给MySQL前检查数据大小 使用不同于管理员的用户将应用程序连接到数据库 访问权限系统The MySQL Access Privilege System MySQL权限系统的主要功能就是对从给定主机连接的用户进行身份认证，并将用户与数据库的权限(SELECT, INSERT, UPDATE, DELETE)相关联。其它功能包含匿名用户(anonymous user)和MySQL特定功能的授权。 有些事情你无法使用MySQL权限系统： 你无法明确指定拒绝给定用户访问 你无法指定用户创建/删除表的权限，但不能指定创建/删除数据库自身 适用于账户全局性的密码 MySQL权限系统的用户接口(user interface)由： CREATE USER, GRANT, REVOKE语句组成。 在内部，Server将权限信息存储在mysql数据库的授权表中。MySQL server在启动时将这些表内容读入内存，并根据授权表的内存中的副本建立访问控制决策。MySQL权限系统确保所有用户只能执行允许的操作。作为用户，当你连接到MySQL server时，你的身份由你连接的主机和你指定的用户名决定。在连接后，系统会根据你的身份和要执行的操作授予权限。MySQL会识别你的主机名和用户名，因为没有理由认为给定的用户名属于所有主机上的同一个人。 1234SHOW GRANTS;SHOW GRANTS FOR &apos;joe&apos;@&apos;office.example.com&apos;;SHOW GRANTS FOR &apos;joe&apos;@&apos;home.example.com&apos;; 当运行客户端程序连接到server时，MySQL访问控制包含两个阶段： server根据你的身份来接受/拒绝连接，以及你是否可通过提供正确的密码来验证你的身份 假设你可以连接，server会检查你发出的每个语句，以确定是否有足够的权限来执行它 MySQL提供的权限Privileges Provided by MySQL 授予MySQL账户的权限决定了账户可以指定的操作。MySQL权限在它们适用的上下文和不同操作级别上有所不同： 管理员权限(Administrative privileges)允许用户管理MySQL Server的操作。这些权限是全局的，因为它们不是特定于特定数据库 数据库权限(privileges for database)适用于数据库及其中的所有对象。可以为特定数据库或全局赋予这些权限，以便它们适用于所有数据库 数据库对象权限(privileges for database object)，如表，索引，视图… 可用权限Summary of Available Privileges 下表显示了GRANT和REVOKE语句中使用的权限名称，以及每个权限关联的列名和权限适用的上下文: Privilege Grant Table Column Context ALL [PRIVILEGES] Synonym for “all privileges” Server administration ALTER Alter_priv Tables ALTER ROUTINE Alter_routine_priv Stored routines CREATE Create_priv Databases, tables, or indexes CREATE ROUTINE Create_routine_priv Stored routines CREATE TABLESPACE Create_tablespace_priv Server administration CREATE TEMPORARY TABLES Create_tmp_table_priv Tables CREATE USER Create_user_priv Server administration CREATE VIEW Create_view_priv Views DELETE Delete_priv Tables DROP Drop_priv Databases, tables, or views EVENT Event_priv Databases EXECUTE Execute_priv Stored routines FILE File_priv File access on server host GRANT OPTION Grant_priv Databases, tables, or stored routines INDEX Index_priv Tables INSERT Insert_priv Tables or columns LOCK TABLES Lock_tables_priv Databases PROCESS Process_priv Server administration PROXY See proxies_priv table Server administration REFERENCES References_priv Databases or tables RELOAD Reload_priv Server administration REPLICATION CLIENT Repl_client_priv Server administration REPLICATION SLAVE Repl_slave_priv Server administration SELECT Select_priv Tables or columns SHOW DATABASES Show_db_priv Server administration SHOW VIEW Show_view_priv Views SHUTDOWN Shutdown_priv Server administration SUPER Super_priv Server administration TRIGGER Trigger_priv Tables UPDATE Update_priv Tables or columns USAGE Synonym for “no privileges” Server administration 授权指南Privilege-Granting Guidelines 最好只向账户授权它所需要的权限，在授予FILE和管理权限时应特别小心: FILE： 可在MySQL Server主机上读取的任何文件读入数据库表 GRANT OPTION： 使用户能够将其权限授权其他用户。具有不同权限且具有GRANT OPTION权限的两个用户可以组合权限 ALTER: 可通过重命名表来破坏权限系统 SHUTDOWN： 通过终止Server完全拒绝向其它用户提供服务 PROCESS： 用于查看当前正在执行的语句的纯文本，包括设置和更改密码的语句 SUPER： 用于终止其它会话或更改服务器的运行方式 为mysql系统数据本自身授予的权限可用于更改密码和其它访问权限信息： 密码以加密方式存储，因此恶意用户无法简单地读取明文密码。然而，具有对mysql.user表authentication_string列具有写权限的用户可以更改账户密码，然后进行登录 为mysql系统数据库授予INSERT或UPDATE权限允许用户添加或修改现有权限 mysql系统数据库的DROP权限使用户能够访问远程权限表，甚至是数据库本身 授权表Grant Tables mysql系统数据库包含多个授权表，其中包含有关用户账户及其拥有的权限信息。mysql数据库表包含的授权信息： user: 用户账户，全局权限，其它非权限列 db: 数据库级别权限 tables_priv：表级别权限 columns_priv： 列级别权限 procs_priv： 存储过程和功能权限 proxies_priv： 代理用户权限 每个授权表包含的列范围和列权限： 列范围确定表中每行的范围 列权限指示表中行授予的权限 Server以下列方式使用授权表： user表范围列确定是拒绝还是允许传入连接 db表范围列确定哪些用户可以从哪些主机上访问数据库 tables_priv和columns_priv表更精细，它们适用于表级别和列级别 procs_priv表用于存储的例程 proxies_priv表指示哪些用户可以充当其它用户的代理，以及用户是否可以将PROXY权限授予其它用户 指定账户名Specifying Account Names MySQL账户名由用户名和主机名组成。这样可以为具有相同名称且可以从不同主机连接的用户创建账户。 在SQL语句中，账户名称遵循以下规则： 账户名语法为: username@hostname 仅包含用户名的账户相当于username@% 注意反引号、单引号、双引号 引号的正确用法: &#39;username&#39;@&#39;hostname&#39; MySQL使用单独的用户名和主机名部分将账户名称存储到mysql系统数据库的授权表中： user表包含每个账户的一行，user.User，user.Host列存储用户名和主机名，此表还指示了账户具有哪些全局权限 其它授权表指示账户对数据库和库中对象的权限，这些表也有User, Host列来存储用户名和主机名 处于访问检查的目的，User value区分大小写，Host value不区分大小写 用户名和主机名还具有某些特殊值或通配符约定，如下:账户名的用户名部分是非空白值，或者是与任何用户名匹配的空值。具有空白用户名的账户是匿名用户(anonymous user)。在SQL语句中指定一个匿名用户，使用带引号的空用户名，如&#39;&#39;@&#39;localhost&#39;。 账户名的主机名部分可以采用多种形式，并允许使用通配符： host value可以是主机名或IP地址(ipv4, ipv6) 主机名或IP地址值中允许使用%和_通配符。例如，主机值%匹配任何主机名，如%.mysql.com匹配mysql.com域中的任何主机。 对于IPv4地址，可以给出网络掩码以指示用于网络号的地址位数 1CREATE USER &apos;test&apos;@&apos;198.51.100.0/255.255.255.0； Server使用系统DNS解析程序为客户端主机名或IP地址返回的值，意味着你应该使用DNS使用的相同格式指定的账户主机值。 访问控制Access Control 连接验证Access Control, Stage 1: Connection Verification 当你连接到MySQL Server，它会根据以下条件接受或拒绝连接： 身份和密码 账户是否被锁定 Server首先检查凭据，然后检查账户锁定状态。任一步骤失败都会导致Server完全拒绝你的访问权限。使用mysql.user表中的三个范围列：Host, User, authentication_string执行凭据检查。 1234567891011121314151617181920SELECT User, Host FROM mysql.user;+-----------+----------+-| Host | User | ...+-----------+----------+-| % | root | ...| % | jeffrey | ...| localhost | root | ...| localhost | | ...+-----------+----------+-#内存中排序的表+-----------+----------+-| Host | User | ...+-----------+----------+-| localhost | root | ...| localhost | | ...| % | jeffrey | ...| % | root | ...+-----------+----------+- %： 表示任意主机 空用户名： 表示任意 当可能存在多个匹配时，Server必须确定要使用安歇匹配项： 只要Server将用户表读入内存，它就会对行进行排序 当用户尝试连接时，Server按排序顺序查看行 Server使用与客户端host和username匹配的第一行 请求认证Access Control, Stage 2: Request Verification 通过连接发出的每个请求，Server确定你要执行的操作，然后检查你是否具有足够的权限来执行此操作。这就是授权表中权限列生效的地方。这些权限可以来自任何user, db, table, column, procs。 全局权限(global)适用于全局范围内 数据库权限 空用户名匹配匿名用户，用户名中没有通配符 通配符%和_可在Host和Db列中使用，与LIKE操作符执行的模式匹配类似。如果要使用原字符，请使用反斜杠对其转义 %或空白Host值表示任意主机 %或空白Db值表示任意数据库 表、列、proc权限 通配符%, _ 以布尔术语表示，总结用户权限： 12345global privilegesOR (database privileges AND host privileges)OR table privilegesOR column privilegesOR routine privileges 权限更改生效时When Privilege Changes Take Effect 启动msyqld时，它读取所有授权表到内存中，内存中的表在此时对访问控制有效。如果使用GRANT, REVOKE, SET PASSWORD, RENAME USER账户管理语句间接修改了授权表，则Server会注意到这些更改并立即在此将授权表加载到内存中。如果直接使用INSERT, UPDATE, DELETE语句修改授权表，则在重启Server或指示重新加载表之前，对权限的更改没有影响。也就是说，直接修改授权表但没有重新加载它的话，更改时无效的。 告诉Server重新加载授权表，有几种方式： 1234567mysql&gt; FLUSH PRIVILEGES#或$ mysqladmin flush-privileges#或$ mysqladmin reload 如果使用--skip-grant-tables选项启动Server，则它不会读取授权表或实现任何访问控制。任何人都可以连接并做任何事情，这是不安全的。 连接MySQL的一些问题Troubleshooting Problems Connecting to MySQL 链接: https://dev.mysql.com/doc/refman/5.7/en/problems-connecting.html 用户账户管理MySQL User Account Management 本节介绍如何为MySQL Server的客户端设置账户： MySQL中使用的账户名和密码的含义，与操作系统使用的名称和密码的比较 如何设置新账户和删除现有账户 如何修改密码 密码使用安全指南 用户名和密码User Names and Passwords 有两种方式创建MySQL账户： 使用创建账户(CREATE USER)和建立权限(GRANT)的账户管理语句。这些语句使Server对基础授权表进行适当的修改 直接操作MySQL授权表，如INSERT, DELETE, UPDATE命令 推荐使用账户管理语句，因为它们比直接操作授权表更简洁，更不容易出错。 栗子： 1mysql --user=root mysql 创建账户： 1234567891011121314151617CREATE USER 'finley'@'localhost' IDENTIFIED BY 'passwd';GRANT ALL PRIVILEGES ON *.* TO 'finley'@'localhost' WITH GRANT OPTION;CREATE USER 'finley'@'%' IDENTIFIED BY 'passwd';GRANT ALL PRIVILEGES ON *.* TO 'finley'@'%' WITH GRANT OPTION;CREATE USER 'admin'@'localhost' IDENTIFIED BY 'password';GRANT RELOAD,PROCESS ON *.* TO 'admin'@'localhost';#查看SHOW GRANTS FOR 'admin'@'localhost';#特定权限CREATE USER 'reader'@'localhost' INDENTIFIED BY 'passwd';GRANT SELECT ON readdb.* TO 'reader'@'localhost'; 删除账户Removing User Accounts 使用DROP USER语句删除用户账户。 1DROP USER 'reader'@'localhost'; 保留账户Reserved User Accounts MySQL安装过程中的数据目录初始化期间，MySQL会创建应被视为保留的用户账户： &#39;root&#39;@&#39;localhost&#39;： 用于管理，拥有一切权限，可执行任何操作 &#39;mysql.sys&#39;@&#39;localhost&#39;： 用作sys模式对象的DEFINER。可避免DBA重命名或删除root账户时出现的问题 &#39;mysql.session@&#39;localhost&#39;：由插件在内部使用以访问Server 账户资源限制Setting Account Resource Limits 限制Client使用MySQL Server资源的一种方式是将全局max_user_connections系统变量设置为非零值。这限制了任何账户(缺乏单个用户)可以进行同时连接的数量，但是对连接后Client可以执行的操作没有限制。 为了解决这些问题，MySQL允许限制单个账户的资源： 账户每小时可以发出的查询数 账户每小时可以发出的更新数 账户每小时可以连接到Server的次数 账户与Server同时连接的数量 要在创建账户时设置资源限制，使用CREATE USER语句；要修改现有账户的限制，使用ALTER USER语句。使用WITH字句，命名每个要限制的资源。每个限制的默认值为零，即无限制。限制类型不必全部在WITH字句中命名，每个小时的限制值应该是一个整数。 Server在该账户对应的user表的行中存储账户的资源限制。当任何账户对其使用任何资源具有非零限制时，将进行资源使用计数。如果超过其连接次数，则Server会拒绝该账户的其它连接，直到该小时结束为止。在所有这些情况下，Server都会发出相应的错误消息。 12345678CREATE USER 'francis'@'localhost' IDENTIFIED BY 'frank' WITH MAX_QUERIES_PER_HOUR 20 MAX_UPDATES_PER_HOUR 10 MAX_CONNECTIONS_PER_HOUR 5 MAX_USER_CONNECTIONS 2;ALTER USER 'francis'@'localhost' WITH MAX_QUERIES_PER_HOUR 100; 假设全局变量max_user_connections值为10： 123ALTER USER 'user1'@'localhost' WITH MAX_USER_CONNECTIONS 0;ALTER USER 'user2'@'localhost' WITH MAX_USER_CONNECTIONS 5;ALTER USER 'user3'@'localhost' WITH MAX_USER_CONNECTIONS 20; 可以为单个账户、所有账户全局重置当前的计数： 使用FLUSH USER RESOURCES语句，将所有账户当前的计数重置为零 将单个账户的限制值重新设置，可以将账户的计数重置为零 每小时计数重置不会影响MAX_USER_CONNECTIONS限制。所有计数从零开始，计数不会通过Server重启而延续。 分配账户密码Assigning Account Passwords MySQL会自动散列(hash)指定的密码。 12345678910#在创建用户是使用INDENTIFIED BY字句分配密码CREATE USER 'jeffrey'@'localhost' IDENTIFIED BY 'password';#修改密码ALTER USER 'jeffrey'@'localhost' IDENTIFIED BY 'password';#修改连接账户的密码ALTER USER USER() IDENTIFIED BY 'password'; 或者使用mysqladmin修改密码，出于安全问题，不推荐使用。 1mysqladmin -u user_name -h host_name password "password" 密码管理Password Management MySQL使数据库管理员可以手动使帐户密码过期，并建立自动密码过期的策略。可以在全局建立到期策略，并且可以将个人帐户设置为遵循全局策略或使用特定的每帐户行为覆盖全局策略。 使用ALTER USER语句设置密码过期： 1ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE; 密码过期策略是自动的，并且基于密码的年龄和最近密码的更改日期和时间进行评估。mysql.user表上有上次更改密码的时间。要全局地建立自动密码过期策略，请使用default_password_lifetime系统变量。默认值为零，表示禁用自动密码过期。如果将值设置为正整数N，则表示允许的密码生存期，因此密码必须每N天更改一次。 栗子： 12345vim /etc/my.cnf[mysqld]default_password_lifetime=365 或者在MySQL中设置全局变量： 1SET GLOBAL default_password_lifetime = 365; 或者在创建账户时设置： 123456789101112CREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE INTERVAL 90 DAY;ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE INTERVAL 365 DAY;#禁用CREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE NEVER;ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE NEVER;#默认CREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE DEFAULT;ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE DEFAULT; Client成功连接后，Server将确定账户密码是否已过期： Server检查密码是否手动过期 否则，Server根据自动密码过期策略检查密码年龄是否大于其允许的生存期 密码过期和沙箱Password Expiration and Sandbox Mode 对于使用具有过期密码的账户的连接，Server要么断开连接，要么将Client限制为沙箱模式。 沙箱模式允许这些操作： Client可使用ALTER USER或SET PASSWORD重置账户密码。重置密码后，Server恢复回话的正常访问 代理用户Proxy Users MySQL Server使用身份验证插件验证客户端连接。验证给定连接的插件可以请求将外部连接用户视为不同的用户以进行特权检查。这就使外部用户成为第二个用户的代理。也就是说，假设第二个用户的权限： 外部用户是代理用户 第二个用户是被代理的用户 代理用户支持的要求Requirements for Proxy User Support 对于给定身份认证的插件的代理，必须满足一下条件： 必须通过插件本身或代表插件的MySQL Server服务器来支持代理 必须将代理用户账户设置为由插件进行身份验证(CREATE USER和ALTER USER语句) 必须创建代理用户账户并授予相关权限(CREATE USER和GRANT语句) 代理用户账户必须具有代理账户的proxy权限(GRANT语句) 对于连接到代理账户的Client将被视为代理用户，身份验证插件必须返回与客户端用户名不同的用户名，以指示代理账户的用户名，该用户名定义代理所承担的权限用户。 代理机制允许将客户端用户名映射到代理用户名，没有规定映射主机名。当连接Client与代理账户匹配时，Server会尝试使用身份验证插件返回的用户名和代理账户的主机名来查找账户的匹配项。 考虑如下账户定义： 1234567891011121314-- create proxy accountCREATE USER 'employee_ext'@'localhost' IDENTIFIED WITH my_auth_plugin AS 'my_auth_string';-- create proxied account and grant its privilegesCREATE USER 'employee'@'localhost' IDENTIFIED BY 'employee_pass';GRANT ALL ON employees.* TO 'employee'@'localhost';-- grant PROXY privilege to proxy account for proxied accountGRANT PROXY ON 'employee'@'localhost' TO 'employee_ext'@'localhost'; 当Client从localhost使用employee_ext连接时，MySQL使用名为my_auth_plugin的插件来执行身份验证。假设my_auth_plugin根据my_auth_string的内容向Server返回employee的用户名，并可能通过咨询某些外部身份验证系统。employee与employee_ext不同，因此返回employee作为请求，Server将employee_ext视为employee本地用户，以便进行权限检查。 Server通过检查employee_ext是否具有employee的PROXY权限来验证employee_ext是否可以对employee进行代理身份验证。 在此例中，employee_ext是代理用户，employee是被代理用户。 发生代理时，USER()和CURRENT_USER()函数可用于查看连接用户(代理用户)与当前会话账户(被代理的用户)之间的区别： 123456SELECT USER(), CURRENT_USER();+------------------------+--------------------+| USER() | CURRENT_USER() |+------------------------+--------------------+| employee_ext@localhost | employee@localhost |+------------------------+--------------------+ 授予代理权限Granting the Proxy Privilege 需要PROXY权限才能使外部用户连接并拥有其他用户的权限。要授予此权限，请使用GRANT语句。 1234567GRANT PROXY ON 'proxied_user' TO 'proxy_user';GRANT PROXY ON 'a' TO 'b', 'c', 'd';GRANT PROXY ON 'a' TO 'd' WITH GRANT OPTION;GRANT PROXY ON 'a' TO ''@'';REVOKE PROXY ON 'a' FROM 'b', 'c', 'd'; 默认代理用户Default Proxy Users 要制定某些或所有用户应使用给定的身份验证进行连接，请创建一个空白MySQL账户(&#39;&#39;@&#39;&#39;)，将其与该插件关联，然后让插件返回真实身份验证的用户名。 栗子： 12345678910-- create default proxy accountCREATE USER ''@'' IDENTIFIED WITH ldap_auth AS 'O=Oracle, OU=MySQL';-- create proxied accountsCREATE USER 'developer'@'localhost' IDENTIFIED BY 'developer_pass';CREATE USER 'manager'@'localhost' IDENTIFIED BY 'manager_pass';-- grant PROXY privilege to default proxy account for proxied accountsGRANT PROXY ON 'manager'@'localhost' TO ''@'';GRANT PROXY ON 'developer'@'localhost' TO ''@''; 默认代理用户和匿名用户冲突Default Proxy User and Anonymous User Conflicts 如果打算创建默认代理用户，请检查其他现有的匹配任何用户账户，这些账户优先于默认代理用户，因为他们可以阻止该用户按预期工作。 在前面的讨论中，默认代理账户在主机部分具有&#39;&#39;，与任何主机匹配。如果你设置了默认代理用户，请注意检查非代理账户是否存在相同的用户部分和主机部分中的%，因为%也匹配任何主机，但优先于&#39;&#39;，Server用于在内部对账户进行排序。 要避免此问题，请使用以下策略之一： 删除匿名用户，使其不与默认代理用户冲突 使用在匿名用户之前匹配的更具体的默认代理用户，如&#39;&#39;@localhost 创建多个代理用户。用于本地连接和远程连接 Server支持代理用户映射Server Support for Proxy User Mapping 一些身份验证插件为自身实现代理用户映射(如PAM)。默认情况下，其他身份验证插件不支持代理用户。如果启用了check_proxy_users系统变量，则Server会对发出此类请求的任何身份认证插件执行代理用户映射： 默认情况下，check_proxy_users被禁用。因此即使对请求Server支持代理用户的身份验证插件，Server也不执行用户代理映射。 如果启用了check_proxy_users，则可能还需要启用特定于插件的系统变量以利用Server代理用户映射支持： 对于mysql_native_password插件，请启用mysql_native_proxy_users 对于sha256_password插件，请启用sha256_password_proxy_users Server执行的代理用户映射受以下限制： 即使授权了关联的PROXY权限，Server也不会代理匿名用户(FROM)或从匿名用户代理(TO) 如果单个账户授予了多个代理账户的代理权限，则Server代理用户是不确定的。因此，不鼓励为多个被代理账户授予单个账户代理权限 代理用户系统变量Proxy User System Variables 两个系统变量有助于追踪代理登录过程： proxy_user如果未使用代理，则此值为NULL。否则，它表示代理用户账户。 external_user有时，身份验证插件可能会使用外部用户对MySQL Server进行身份验证。 用户账户User Account Locking 从MySQL v5.7.6开始，MySQL支持使用ACCOUNT LOCK和ACCOUNT UNLOCK子句为CREATE USER和ALTER USER语句锁定和解锁用户账户： 与CREATE USER一起使用时，这些子句指定新账户的初始锁定状态。如果没有任何一个子句，则账户将以未锁定状态创建。 与ALTER USER一起使用时，这些子句指定现有账户的新锁定状态。如果没有任何一个子句，则账户锁定状态保持不变。 账户锁定状态记录在mysql.user系统表的account_locked列中。使用SHOW CREATE USER显示账户锁定状态。 如果Client尝试连接到已锁定的账户，则会失败。返回错误消息，并将错误写入日志。 锁定账户不会影响能够使用承担锁定账户身份的代理用户进行连接。她也不会影响执行存储程序和试图的能力，这些程序或视图具有命名锁定账户的DEFINER子句。也就是说，锁定账户，不会影响使用代理账户或存储的程序或视图的能力。 要从旧版本升级到MySQL 5.7.6以及更高版本，请运行mysql_upgrade以确保此列存在。对于没有account_locked列的非升级安装，Server会将所有账户视为已解锁。 基于SQL的MySQL账户活动审计SQL-Based MySQL Account Activity Auditing 应用程序可以使用以下准则来执行基于SQL的审计，该审计将数据库活动与MySQL账户联系起来。 MySQL账户对应于mysql.user系统表中的行。当Client连接成功后，Server会将Client验证到此表中的特定行。此行中的User和Host列的值唯一标识该账号，并对应于user@host格式，其中账户名称在SQL语句中写入。 用于验证Client的账户确定Client具有哪些权限。通常，可以调用CURRENT_USER()函数来确定这对于Client用户来说是哪个账户。其值有账户的用户表行的User和Host列构成。但是，在某些情况下，CURRENT_USER()值不对应于客户端用户，而是对英语不同的账户。当权限检查不基于客户端账户时，会发生这种情况： 使用 SQL SECURITY DEFINER特性定义的存储例程 使用 SQL SECURITY DEFINER特性定义的视图 触发器和事件 在这些上下文中，权限检查是针对DEFINER账户完成的，而CURRENT_USER()是指该账户，而不是指调用存储例程或视图的Client或导致触发器激活的账户。 如果应用程序必须调用USER()进行用户审计，但是还必须能够将USER()值与用户表中的账户相关联，则必须避免使用在User或Host列中包含通配符。具体来说，不允许User为空，并且不允许Host值中使用模式字符或网络掩码表示法。所有账户必须具有非空用户值和文字主机值。 更改账户用户主机： 1234RENAME USER ''@'localhost' TO 'user1'@'localhost';RENAME USER 'user2'@'%.example.com' TO 'user2'@'remote.example.com';-- 如果user2必须能够从example.com域中的多个主机进行连接，则每个主机应该有一个独立的账户 要从CURRENT_USER()或USER()函数中提取用户名或主机名，请使用SUBSTRING_INDEX()函数： 1234567891011121314SELECT SUBSTRING_INDEX(CURRENT_USER(),'@',1);+---------------------------------------+| SUBSTRING_INDEX(CURRENT_USER(),'@',1) |+---------------------------------------+| user1 |+---------------------------------------+SELECT SUBSTRING_INDEX(CURRENT_USER(),'@',-1);+----------------------------------------+| SUBSTRING_INDEX(CURRENT_USER(),'@',-1) |+----------------------------------------+| localhost |+----------------------------------------+ 使用加密连接Using Encrypted Connections MySQL Client和Server之间的未加密连接，有权访问网络的人可以监视你的所有流量和C/S之间发送和接受的数据。要使任何类型的在网络中数据不可读，请使用加密。加密算法必须包含安全元素，以抵御多种已知的攻击。 MySQL支持使用TLS协议在C/S之间建立加密连接。TLS有时被称为SSL，但MySQL实际上并不使用SSL协议进行加密，因为它的加密很弱。TLS使用加密算法来确保可以信任通过公共网络接收的数据。它具有检测数据更改、丢失、重放的机制。TLS还包含使用X.509标准提供的身份验证的算法。X.509可以识别互联网上的某个人。在基本术语中，有一些被称为证书颁发机构(CA)的实体，它将电子证书分配给需要它们的任何人。证书依赖于两个加密密钥(公钥和私钥)的非对称加密算法。证书所有者可以将证书提供给另一方作为身份证明。证书由其所有者的公钥组成，使用该公钥加密的任何数据只能使用有该证书的私钥来解密。 可以使用OpenSSL和yaSSL编译MySQL以获得加密连接支持。默认情况下，如果Server支持加密连接，MySQL将尝试使用加密连接。如果无法建立加密连接，则会回退到未加密的连接。MySQL基于每个连接执行加密，并且对给定用户使用加密可以是可选的或强制的。这使你可以根据各个应用程序的要求选择加密或未加密的连接。 加密连接同样可用于Master和Slave的副本集之间。也可以通过MySQL C API获得加密连接。也可以使用SSH连接内的加密连接到MySQL Server。 配置MySQL以使用加密连接Configuring MySQL to Use Encrypted Connections 有几个选项用于指示是否使用加密连接，以及制定适当的证书和密钥文件。它包括： Server端 Client端 S端加密连接配置Server-Side Configuration for Encrypted Connections 在S端，--ssl选项指定Server允许但不需要加密连接。默认情况下启用此选项。Server端的这些选项标识了Server在允许Client建立加密连接时使用的证书和密钥文件： --ssl-caCA颁发的证书文件的路径名 ssl-certServer公钥证书文件的路径名。可以发送到Client端，并根据它具有的CA证书进行身份验证 ssl-keyServer私钥文件的路径名 启用加密连接，修改my.cnf的栗子： 1234[mysqld]ssl-ca=ca.pemssl-cert=server-cert.pemssl-key=server-key.pem C端加密连接配置Client-Side Configuration for Encrypted Connections 默认情况下，如果Server支持加密连接，MySQL Client将尝试建立加密连接，并通过--SSL-mode选项进一步控制： 如果没有ssl-mode选项Client将尝试使用加密连接，如果无法建立加密连接，则会回退到未加密的连接。这等同于--ssl-mode=PREFFERED --ssl-mode=REQUIREDClient需要加密连接，如果无法建立，则会失败 --ssl-mode=DISABLEDClient使用未加密连接 --ssl-mode=VERIFY_CA或--ssl-mode=VERIFY_IDENTITY客户端需要加密连接，并且还要针对Server CA证书和对其他证书中的Server主机名进行验证 Client以下几个选项类似于Server端的几个选项，标识C/S加密连接时使用的证书和密钥文件： --ssl-ca --ssl-cert --ssl-key 加密连接的命名选项Command Options for Encrypted Connections 本节介绍使用加密连接的选项。 123456789101112--skip-ssl Do not use encrypted connection --ssl Enable encrypted connection --ssl-ca File that contains list of trusted SSL Certificate Authorities --ssl-capath Directory that contains trusted SSL Certificate Authority certificate files --ssl-cert File that contains X.509 certificate --ssl-cipher List of permitted ciphers for connection encryption --ssl-crl File that contains certificate revocation lists --ssl-crlpath Directory that contains certificate revocation list files --ssl-key File that contains X.509 key --ssl-mode Security state of connection to server 5.7.11--ssl-verify-server-cert Verify host name against server certificate Common Name identity --tls-version Protocols permitted for encrypted connections 5.7.10 创建SSL/RSA证书和密钥Creating SSL and RSA Certificates and Keys 可以使用MySQL自身提供的工具或直接调用openssl命令来创建所需文件。 使用MySQL创建Creating SSL and RSA Certificates and Keys using MySQL MySQL提供了这些方法来创建SSL证书和密钥文件以及使用SSL支持加密连接所需的RSA密钥对文件，以及使用RSA通过未加密连接进行安全密码交换。如果缺少这些文件： 对于使用OpenSSL编译的MySQL发行版，Server可在启动时自动生成这些文件 用户可以手动调用mysql_ssl_rsa_setup实用程序 对于某些发行版(如RPM包)，在数据目录初始化期间会调用mysql_ssl_rsa_setup。在这种情况下，只要openssl命令可用，就不需要使用OpenSSL编译MySQL发行版 自动SSL和RSA文件生成 Automatic SSL and RSA File Generation 对于使用OpenSSL编译的MySQL发行版，MySQL Server能够在启动时自动生成缺少的SSL和RSA文件。auto_generate_certs和sha256_password_auto_generate_rsa_keys系统变量控制这些文件的自动生成。默认情况下启用这两个变量，它们可以在启动时启用并检查，但不能在运行时设置。 启动时，如果启用了auto_generate_certs系统变量，则Server会自动在数据目录中生成S端和C端的SSL证书和密钥文件。 Server检查数据目录下的SSL文件： 123ca.pemserver-cert.pemserver-key.pem 如果存在，则不创建。反之，则创建 123456ca.pem Self-signed CA certificateca-key.pem CA private keyserver-cert.pem Server certificateserver-key.pem Server private keyclient-cert.pem Client certificateclient-key.pem Client private key 如果Server自动生成了RSA文件，它将使用其名称来设置相应的系统变量 启动时，如果满足以下条件(sha256_password_auto_generate_rsa_keys系统变量已启用；没有指定RSA选项；数据目录中缺少RSA文件)，则Server会自动在数据目录中生成RSA私钥/公钥对文件。 Server检查数据目录下的RSA文件 12private_key.pem Private member of private/public key pairpublic_key.pem Public member of private/public key pair 如果存在，则不创建。反之，则创建 如果Server自动生成了RSA文件，它将使用其名称来设置相应的系统变量 手动生成 Manual SSL and RSA File Generation Using mysql_ssl_rsa_setup MySQL发行版包含此实用程序，但它需要openssl命令可用。 SSL/RSA文件特性 SSL and RSA File Characteristics 它们具有以下特性： SSL/RSA密钥大小为2048bits SSL CA证书是自签名的 SSL Server/Client的CA证书和密钥对，使用sha256WithRSAEncryption签名算法 创建的SSL文件自生成之日起有效期为十年 RSA文件不会过期 SSL文件对于每个证书/密钥对具有不同的序列号(1 for CA, 2 for Server, 3 for Client) 创建的文件由运行程序执行创建的用户拥有 Unix/Unix-Like上，证书文件权限为644，密钥文件权限为600 查看SSL证书内容： 123openssl x509 -text -in ca.pemopenssl x509 -text -in server-cert.pemopenssl x509 -text -in client-cert.pem 使用SQL语句查看SSL证书过期时间： 1234567SHOW STATUS LIKE 'Ssl_server_not%';+-----------------------+--------------------------+| Variable_name | Value |+-----------------------+--------------------------+| Ssl_server_not_after | Apr 28 14:16:39 2027 GMT || Ssl_server_not_before | May 1 14:16:39 2017 GMT |+-----------------------+--------------------------+ 使用openssl创建SSL证书和密钥Creating SSL Certificates and Keys Using openssl 创建栗子： 123456789101112131415161718192021222324# Create clean environmentrm -rf newcertsmkdir newcerts &amp;&amp; cd newcerts# Create CA certificateopenssl genrsa 2048 &gt; ca-key.pemopenssl req -new -x509 -nodes -days 3600 \ -key ca-key.pem -out ca.pem# Create server certificate, remove passphrase, and sign it# server-cert.pem = public key, server-key.pem = private keyopenssl req -newkey rsa:2048 -days 3600 \ -nodes -keyout server-key.pem -out server-req.pemopenssl rsa -in server-key.pem -out server-key.pemopenssl x509 -req -in server-req.pem -days 3600 \ -CA ca.pem -CAkey ca-key.pem -set_serial 01 -out server-cert.pem# Create client certificate, remove passphrase, and sign it# client-cert.pem = public key, client-key.pem = private keyopenssl req -newkey rsa:2048 -days 3600 \ -nodes -keyout client-key.pem -out client-req.pemopenssl rsa -in client-key.pem -out client-key.pemopenssl x509 -req -in client-req.pem -days 3600 \ -CA ca.pem -CAkey ca-key.pem -set_serial 01 -out client-cert.pem 验证： 1openssl verify -CAfile ca.pem server-cert.pem client-cert.pem 使用openssl创建RSA密钥Creating RSA Keys Using openssl 创建： 12345openssl genrsa -out private_key.pem 2048openssl rsa -in private_key.pem -pubout -out public_key.pemchmod 400 private_key.pemchmod 444 public_key.pem 安全插件Security Plugins MySQL包括几个实现安全功能的插件： 用于MySQL C/S 连接尝试的插件 用于实施密码强度策略和评估潜在密码强度的密码验证插件 用于敏感信息安全存储的密钥环(keyring)插件 MySQL企业版插件 身份认证插件Authentication Plugins 原生可插拔认证Native Pluggable Authentication MySQL包含两个实现原生身份认证的插件。在引入可插拔身份验证之前，基于密码散列的方法的身份验证。 本级密码验证的插件和库名称： Plugin or File Plugin or File Name Server-side plugin mysql_native_password Client-side plugin mysql_native_password Library file None (plugins are built in) 安装本机可插拔认证Installing Native Pluggable Authentication mysql_native_password插件存在于Server和Client的表单中： S端插件内置于Server，无需显式加载，也无法通过卸载来禁用 C端插件内置于libmysqlclient库中，可用于链接到此库的任何程序 使用本机可插拔认证Using Native Pluggable Authentication MySQL Client程序默认使用mysql_native_password。 旧的本机可插拔认证Old Native Pluggable Authentication MySQL version 4.1机之前。 从旧的插件迁移到新的插件Migrating Away from Pre-4.1 Password Hashing and the mysql_old_password Plugin SHA-256可插拔认证SHA-256 Pluggable Authentication 备份和恢复Backup and Recovery 数据备份非常重要！ MySQL提供了各种备份策略，你可以从中选择最适合安装要求的方法。本章讨论几个你应该熟悉的备份和恢复的主题： 备份类型： 逻辑与物理，全量和增量… 创建备份的方法 恢复方法，包括时间点(point-in-time)恢复 备份调度，压缩和加密 表维护，以便恢复损坏的表 备份和恢复类型Backup and Recovery Types 物理与逻辑备份Physical (Raw) Versus Logical Backups 物理备份由目录的原始副本和存储数据库内容的文件组成。此类备份适用于需要在出现问题时快速恢复的大型重要数据库。 逻辑备份保存表示为逻辑数据库结构的信息(CREATE DATABASE, CREATE TABLE语句)和内容(INSERT语句和分割文本文件)。此类备份适用于较少量的数据，你可以在其中编辑数据值或表结构，或在不同计算机体系结构上重新创建数据。 物理备份方法具有以下特征： 此备份包含数据库目录和文件的精确副本。通常，这是MySQL数据目录的全部或部分副本 物理备份比逻辑备份更快，因为它们只涉及文件复制而不进行转换 输出比逻辑备份更紧凑(compact) 由于备份速度和紧凑性对于繁忙、重要的数据库很重要，因此MySQL Enterprise执行物理备份 备份和还原粒度范围从整个数据目录的级别到单个文件的级别。这可能会/也可能不会提供表级别的粒度，具体取决于存储引擎 除数据库外，此备份还可以包括任何相关文件(如日志和配置) 来自MEMORY表的数据很难以这种方式备份，因为它们的内容不存储在磁盘上 备份仅可移植到具有相同或类似硬件特征的其它计算机 可以在MySQL Server未运行时执行备份。如果Server正在运行，则必须执行适当锁定(lock)，以便Server在备份期间不会更改数据库内容。MySQL Enterprise备份会自动为它需要的表执行锁定 物理备份工具包括用于InnoDB或任何其它表的mysqlbackup，或用于MyISAM表的文件系统级别命令(cp, scp, tar, rsync) 对于恢复 MySQL Enterprise备份恢复InnoDB和备份的其它表 ndb_restore恢复NDB表 可使用文件系统级别的命令将文件复制回其原始位置 逻辑备份方法具有以下特性： 通过查询MySQL Server来获取数据库结构和内容信心来完成备份 此备份比物理备份慢，因为Server必须访问数据库信息并将其转换为逻辑格式 输出大于物理备份，特别是以文本格式保存时 备份和还原可在Server级别，数据库级别或表级别，而无论存储引擎如何 备份不包括日志和配置文件，或其它不属于数据库的相关文件 以逻辑格式的备份与机器无关，请具有高度可移植性 在MySQL Server运行时执行逻辑备份 逻辑备份工具包括mysqldump程序和SELECT ... INTO OUTFILE语句。这适用于任何存储引擎，甚至是MEMORY 要恢复逻辑备份，可使用mysql客户端处理SQL格式转储文件。要加载分割文本文件，使用LOAD DATA INFILE语句或mysqlimport客户端 在线与离线备份Online Versus Offline Backups 在MySQL Server运行时进行在线备份，以便可以从Server获取数据库信息。Server停止时进行离线备份。这种区别也可描述为热备(hot)与冷备(cold)，热备是Server保持允许但在外部访问数据库时锁定表以防止修改数据 在线备份具有以下特性： 此备份对其它客户端的干扰较小，其它客户端可在备份期间连接到MySQL Server，并且可以根据需要执行的操作来访问数据库 必须小心施加适当的锁定，以便不会发生损害备份完整性的数据修改。MySQL Enterprise会自动执行锁表 脱机备份方法有以下特性： 客户端可能会受到不利影响，因为备份期间Server不可用。因此，此类备份通常发生于Slave Server，可以脱机而不会损害可用性 备份过程简单，因为不会受到客户端活动的干扰 在线和离线之间的区别适用于恢复操作，并且适用于类似的特征。但是，由于恢复需要更强的锁定，因此客户端更有可能受到在线恢复的影响而不是在线备份。在备份期间，客户端可能能够在备份时读取数据；而恢复数据不仅仅是读取数据，因此必须防止客户端在恢复数据时访问数据。 本地与远程备份Local Versus Remote Backups 本地备份是在运行MySQL Server的统一主机上执行，而远程备份则从其它主机执行。 mysqldump能连接到本地或远程Server。对于SQL输出，既可在本地也可在远程；对于分割文件输出，将在Server上创建数据文件 SELECT ... INTO OUTFILE可从本地或远程启动，但输出文件是在Server上创建 物理备份通常在Server上启动，以便Server可以脱机 快照备份Snapshot Backups 某些文件系统可以实现快照，它们在给定时间点提供文件系统的逻辑副本，而不需要整个文件系统的物理副本。MySQL本身并未提供此功能，可通过Veritas, LVM或ZFS… 全量与增量备份Full Versus Incremental Backups 全量备份包括MySQL Server在给定时间点管理的所有数据；增量备份包括在给定时间点跨度内（从一个时间点到另一个时间点）对数据所做的更改。 全量与增量恢复Full Versus Point-in-Time (Incremental) Recovery 全量恢复可从完整备份恢复所有数据。这会将Server实例还原到备份时的状态。增量恢复是恢复在给定时间点跨度内所做的更改，这也称为时间点恢复。它基于二进制日志，通常在备份文件完全恢复之后，将备份文件还原到备份时的状态。然后，在二进制日志文件中写入的数据更改将作为增量恢复应用于重做数据修改，并使Server达到所需的时间点。 表维护Table Maintenance 如果表损坏，数据完整性可能会受到影响。 备份调度，压缩和加密Backup Scheduling, Compression, and Encryption 备份调度对于自动化备份过程很有价值；压缩备份输出可减少空间需求；输出加密可提供更好的安全性，防止未经授权访问备份数据。MySQL本身不提供这些功能，可使用第三方方案。 数据库备份方法Database Backup Methods 使用MySQL Enterprise进行热备 使用mysqldump进行备份Making Backups with mysqldump mysqldump程序可以进行备份，它可以备份各种表。 通过复制表文件进行备份Making Backups by Copying Table Files 对于使用自己的文件表示每个表的存储引擎，可通过复制这些文件来备份表。要获得一致性的备份，请停止服务器或锁定并刷新相关表： 1FLUSH TABLES tbl_list WITH READ LOCK; 你只需要一个读锁，这使得其它客户端可以在你复制数据库目录中的文件时继续查询表。需要刷新以确保在开始备份之前将所有活动索引页写入磁盘。只要Server没有更新，你也可以通过复制所有表文件来创建二进制备份。 通过分隔文本文件备份Making Delimited-Text File Backups 要创建包含表数据的分隔文本文件，可使用SELECT * INTO OUTFILE ‘filename’ FROM tablename语句进行创建。此方法适用于任何类型的数据文件，但仅保存表数据，而不保存表结构。 要载入分隔文本文件，请使用LOAD DATA INFILE或mysqlimport。 通过启用二进制日志进行增量备份Making Incremental Backups by Enabling the Binary Log MySQL支持增量备份，必须使用--log-bin选项启动Server以支持二进制日志记录。二进制日志文件为你提供了在执行备份之后副本数据库所需的信息。目前，你希望进行增量备份，你应该使用FLUSH LOGS轮换二进制日志。完成此操作后，你需要将所有二进制日志复制到备份位置，这些日志的范围从上次完全备份或增量备份到最后一个备份之一。 通过使用副本集Slaves进行备份Making Backups Using Replication Slaves 如果在进行备份时Master Server出现性能问题，可在Slave Server上进行复制和备份。 恢复损坏的表Recovering Corrupt Tables 如果必须还原已损坏的MyISAM表，请尝试首先使用REPAIR TABLE或myisamchk -r恢复它们。这应该在99.9％的情况下有效。 使用文件系统快照进行备份Making Backups Using a File System Snapshot VXFS文件系统操作步骤，其它文件系统类似： 客户端程序执行FLUSH TABLES WITH READ LOCK 从shell执行mount vxfs snapshot 解锁UNLOCK TABLES 从快照复制文件 umount快照 备份和恢复栗子Example Backup and Recovery Strategy 请注意磁盘问题，万一是磁盘不可用那就… 建立备份策略Establishing a Backup Policy 为了有用，必须定期进行备份。可使用多种工具在MySQL中完成全量备份。 12#备份之前锁表mysqldump --single-transaction --all-databases &gt; bacup.sql 全量备份是必要的，但创建它们并不总是方便。生成大型备份文件要话费大量时间和空间，它并非最佳。所以，进行初始化全量备份，然后进行增量备份更有效。增量备份更小，时间更短。 要进行增量备份，需要保存增量更改。在MySQL中，这些更改在二进制日志中表示，因此应始终使用--log-bin选项启动MySQL Server已启动二进制日志。启用它之后，Server会在更新数据时将每个数据更改写入文件。每次重启时，MySQL Server都会使用序列中的下一个数字创建创建一个新的二进制日志文件。在Server运行时，你还可以告诉它关闭当前的二进制日志文件并通过FLUSH LOGS语句或mysqladmin flush-logs命令手动开始新的二进制日志文件。mysqldump还有一个刷新日志的选项，数据目录中的.index文件包含目录中所有MySQL二进制日志的列表。 12345xxx-bin.000001xxx-bin.000002xxx-bin.000003xxx-bin.000004xxx-bin.index MySQL二进制日志对于恢复非常重要，因为它们构成了一组增量备份。如果确保在进行全量备份时刷新日志，则之后创建的二进制日志文件将包含自备份以来所做的所有数据的更改。 123mysqldump --single-transaction --flush-logs --master-data=2 \ --all-databases &gt; backup.sql#之后便会创建一个新的二进制日志文件 MySQL二进制日志占用磁盘空间，可不时删除它们。 1234mysqldump --single-transaction --flush-logs --master-data=2 \ --all-databases --delete-master-logs &gt; backup.sql#在副本集中，使用mysqldump --delete-master-logs删除MySQL二进制日志可能会很危险，因为可能Slave Server尚未处理完二进制日志的内容#可使用 PURGE BINARY LOGS语句删除 使用备份进行恢复Using Backups for Recovery 123456#全量恢复mysql &lt; backup.sql#增量恢复mysqlbinlog xxx-bin.000007 xxx-bin.000008 | mysql 备份策略摘要Backup Strategy Summary 不怕一万，就怕万一。InnoDB本身可以完成恢复数据的所有工作。但为了确保高枕无忧，请遵守以下准则： 始终使用--log-bin选项运行MySQL Server 使用mysqldump定期进行全量备份 使用FLUSH LOGS或mysqladmin flush-logs刷新日志来定期进行增量备份 mysqldump备份Using mysqldump for Backups 本节介绍如何使用mysqldump生产转储文件，以及如何重新加载转储文件。转储文件可通过多种方式使用： 作为备份，在数据丢失的情况下启用数据恢复 作为设置副本集的数据源 作为实验数据源 mysqldump处理两种类型的输出，具体取决于有无-tab选项： 没有--tab选项，mysqldump将SQL语句写入标准输出。输出包含用于创建转储对象(db, table, sotred routines)的CREATE语句，以及用于将数据加载到表中的INSERT语句。输出可保存到文件中。 带有--tab选项，mysqldump为每个转储的表生成两个输出文件。Server将一个文件写为制表符(tab)分隔的文本，每个表的行(row)为文本的一行，输出名为table_name.txt。Server还将创建表的CREATE TABLE语句发送到mysqldump，mysqldump将其写为输出目录中名为table_name.sql的文件。 使用mysqldump以SQL格式转储数据Dumping Data in SQL Format with mysqldump 12345678910111213mysqldump [args] &gt; file_name#all dbmysqldump --all-databases &gt; dbs.sql#specific dbmysql --databases test &gt; testDB.sqlmysqldump test &gt; testDB.sqlmysqldump --databases db1 db2 db3 &gt; db123.sqlmysqldump db1 db2 db3 &gt; db123.sql 关于有无--databases选项的区别： 转储输出不包含CREATE DATABASE或USE语句 重新加载转储文件时，必须指定默认数据库名称，以便Server知道要重新加载的数据库 对于重新加载，你可以指定与原始名称不同的数据库名，这使你可将数据重新加载到其它数据库中 如果要重载的数据库不存在，则必须先创建它 由于输出不包含CREATE DATABASE语句，因此--add-drop-database选项无效 重载SQL格式备份Reloading SQL-Format Backups 要重载由mysqldump备份的包含SQL语句的转储文件，使用mysql客户端输入。如果使用了--databases选项，则它包含了CREATE DATABASE和USE语句，就没有必要指定默认数据库。 12345678mysql &lt; dump.sql#或mysql&gt; source dump.sql#未使用--databases选项mysqladmin create db1mysql db1 &lt; dump.sql 使用mysqladmin以分隔文本格式转储数据Dumping Data in Delimited-Text Format with mysqldump 本节介绍如何使用mysqldump创建分隔文本转储文件。 123456789101112131415mysqldump --tab=/tmp db1#db1.txt#其它选项：--fields-terminated-by=str--fields-enclosed-by=char--fields-optionally-enclosed-by=char--fields-escaped-by=char--lines-terminated-by=str#栗子mysqldump --tab=/tmp --fields-terminated-by=, --fields-enclosed-by=&apos;&quot;&apos; --lines-terminated-by=0x0d0a db1 重载分隔文本格式的备份Reloading Delimited-Text Format Backups 123mysql db1 &lt; t1.sqlmysqlimport db1 t1.txt 12USE db1;LOAD DATA INFILE `t1.txt` INTO TABLE t1; mysqldump小技巧本节介绍使用mysqldump解决特定问题的技术： 如何复制数据库 如何将数据库从一个Server复制到另一个Server 如何转储存储的程序 如何单独转储定义和数据 复制数据库Making a Copy of a Database 123mysqldump db1 &gt; dump.sqlmysqladmin create db2mysql db2 &lt; dump.sql 将数据库从一个Server复制到另一个ServerCopy a Database from one Server to Another 123456789101112#Server1mysqldump --databases db1 &gt; dump.sql#Server2mysql &lt; dump.sql#无--databasesmysqldump db1 &gt; dump.sqlmysqladmin create db1mysql db1 &lt; dump.sql 转储存储的程序Dumping Stored Programs 几个选项控制mysqldump如何处理存储的程序： 12345678--events: Dump Event Scheduler events--routines: Dump stored procedures and functions--triggers: Dump triggers for tables--skip-events--skip-routines--skip-triggers. 转储表定义和Dumping Table Definitions and Content Separately 1234567#--no-data，不转储表数据，导致转储文件只包含用于创建表的语句#--no-create-info, 从输出中抑制CREATE语句，以便转储文件包含表数据mysqldump --no-data test &gt; dump-defs.sqlmysqldump --no-create-info test &gt; dump-data.sqlmysqldump --no-data --routines --events test &gt; dump-defs.sql 使用mysqldump测试升级不兼容性Using mysqldump to Test for Upgrade Incompatibilities 123456#oldmysqldump --all-databases --no-data --routines --events &gt; dump-defs.sql#newmysql &lt; dump-defs.sql 使用二进制日志进行增量恢复Point-in-Time (Incremental) Recovery Using the Binary Log 时间点恢复是指恢复自给定时间点以来所做的数据更改。通常，在还原全量备份之后执行此类恢复。 时间点恢复基于以下原则： 时间点恢复的信息源是由全量备份操作之后生成的二进制日志文件表示增量备份集，请开启--bin-log选项要从二进制日志还原数据，你必须知道二进制日志文件的名称和位置，默认情况下，它在数据目录中。 12345SHOW BINARY LOGS;--确定当前binary log file名称SHOW MASTER STATUS; mysqlbinlog实用程序将二进制日志文件中的事件从二进制格式转换为文本，以便可以执行或查看它们mysqlbinlog具有根据日志中事件时间或事件位置选择二进制日志部分的选项。 从二进制日志执行事件会导致重做它们所代表的数据修改，这样可以恢复给定时间段内的数据更改。 12#从二进制日志中执行事件mysqlbinlog binlog_files | mysql -u root -p 当需要确定事件时间或位置以在执行事件之前选择部分日志内容时，查看日志内容很有用 12345#查看binary logmysqlbinlog binlog_file | more#或mysqlbinlog binlog_file &gt; tmpfile 将输出保存在文件中非常有用，可以在删除某些事件时执行日志内容 1mysql -u root -p &lt; tmpfile 如果要在MySQL Server上执行多个二进制日志，安全的方法是使用与Server的单个连接来处理它们 1234567891011121314#unsafe#可能导致某些问题mysqlbinlog binlog.000001 | mysql -u root -p # DANGER!!mysqlbinlog binlog.000002 | mysql -u root -p # DANGER!!#safemysqlbinlog binlog.000001 binlog.000002 | mysql -u root -p#或mysqlbinlog --skip-gtids binlog.000001 &gt; /tmp/statements.sqlmysqlbinlog --skip-gtids binlog.000002 &gt;&gt; /tmp/statements.sqlmysql -u root -p -e "source /tmp/statements.sql" 使用事件时间进行时间点恢复Point-in-Time Recovery Using Event Times 要指示恢复的开始和结束时间，请以DATATIME格式指定mysqlbinlog的--start-datetime和--stop-datetime选项。请先查看binary log的时间区间。 1234567#恢复数据直到停止时间mysqlbinlog --stop-datetime="2005-04-20 9:59:59" \ /var/log/mysql/bin.123456 | mysql -u root -p#恢复数据从开始时间mysqlbinlog --start-datetime="2005-04-20 10:01:00" \ /var/log/mysql/bin.123456 | mysql -u root -p 使用事件位置进行时间点恢复Point-in-Time Recovery Using Event Positions mysqlbinlog的--start-position和--stop-position选项可用于指定日志位置，它的工作方式与指定时间类似。使用位置可以更准确地了解要恢复的日志部分，尤其是在许多事务与破坏性语句同时发生的情况下。要确定位置编号，请在执行不需要的事物的时间附近运行mysqlbinlog一段时间，但将结果重定向到文本文件以供检查: 123mysqlbinlog --start-datetime="2005-04-20 9:55:00" \ --stop-datetime="2005-04-20 10:05:00" \ /var/log/mysql/bin.123456 &gt; /tmp/mysql_restore.sql 位置编号以log_pos数字进行标记，查看并找到相应的位置标号，之后便可使用它们。 123456mysqlbinlog --stop-position=368312 /var/log/mysql/bin.123456 \ | mysql -u root -pmysqlbinlog --start-position=368315 /var/log/mysql/bin.123456 \ | mysql -u root -p MyISAM表维护和崩溃恢复MyISAM Table Maintenance and Crash Recovery 本节讨论了如何使用myisamchk检查或修复MyISAM表——具有用于存储数据和索引的.MYD和.MYI文件。你可以使用myisamchk来检查、修复、优化数据库表。 尽管使用myisamchk进行表修复十分安全，但在进行修复或任何可能对表进行大量更改的维护操作之前进行备份总是一个好主意。 影响索引的myisamchk操作可能导致使用与MySQL Server使用的值不兼容的全文参数重建MyISAM FULLTEXT索引。 MyISAM表也可以使用类似于myisamchk操作的SQL语句来完成： 检查MyISAM表，CHECK TABLE 修复MyISAM表，REPAIR TABLE 优化MyISAM表，OPTIMIZE TABLE 分析MyISAM表，ANALYZE TABLE 这些语句可以直接使用，也可通过mysqlcheck客户端程序使用。这些语句相对于myisamchk的一个优点是Server可以完成所有工作。使用myisamchk，你必须确保Server不会同时使用这些表，以便myisamchk和Server之间不会发生不需要的交互。 使用myisamchk进行崩溃恢复Using myisamchk for Crash Recovery 如果在禁用外部锁定(default)的情况下运行mysqld，则当mysqld使用同一个表时，你无法可靠地使用myisamchk来检查表。如果你可以确定在运行myisamchk时没有人会通过mysql访问表，你只需要在开始检查表之前执行mysqladmin flush-tables。如果你不能保证这一点，你必须在检查表时停止mysqld。如果你运行myisamchk来检查mysqld同时更新的表，你可能会收到一个警告，即使表没有也如此。 如果Server启用了外部锁定(external locking)，则可以随时使用myisamchk检查表。在这种情况下，如果Server尝试更新myisamchk正在使用的表，Server将等待myisamchk完成后再继续。 如果要使用myisamchk来修复或优化表，则必须始终确保mysqldServer未使用该表(或外部锁定)。如果没有停止mysqld，你应该在运行myisamchk之前至少做一个mysqladmin flush-tables。如果Server和myisamchk同时访问表，你的表可能会损坏。 执行崩溃恢复时，请务必了解数据库中每个MyISAM表table_name都对应于下面现实的数据库目录中的三个文件: 1234#数据文件和索引文件最常出问题tbl_name.frm Definition (format) filetbl_name.MYD Data filetbl_name.MYI Index file myisamchk的工作原理时逐行创建.MYD数据文件的副本。它通过删除旧的.MYD文件并将新文件重命名为原始文件名来结束修复阶段。如果使用--quick选项，myisamchk不会创建临时的.MYD文件，而是假定.MYD文件正确并且只生成新的索引文件而不触及.MYD文件。这是安全的，因为myisamchk会自动检查.MYD文件是否已损坏，如果存在则终止修复。 如何检查MyISAM表是否存在错误How to Check MyISAM Tables for Errors 使用以下命令检查MyISAM表： myisamchk tbl_name这能发现99.99%的错误，它找不到的是仅涉及数据文件的损坏。 myisamchk -m tbl_name这能发现99.999%的错误。它首先检查所有索引条目是否有错，然后读取所有行。它计算行中所有键值的校验和，并验证校验和是否与索引树种键的校验和匹配。 myisamchk -e tbl_name这可以对所有数据进行全面彻底的检查。 myisamchk -e -i tbl_name打印更多统计信息 如何修复MyISAM表How to Repair MyISAM Tables 你同样可使用CHECK TABLE和REPAIR TABLE语句来检查和修复MyISAM表。 损坏的表的症状： tbl_name.frm被锁定以防止修改 找不到文件tbl_name.MYI(Errorcode: nnn) 意外的文件结束 记录文件崩溃 从表处理获得error nnn 获取更多有关错误的信息： 1234567891011#perror nnnperror 126 127 132 134 135 136 141 144 145MySQL error code 126 = Index file is crashedMySQL error code 127 = Record-file is crashedMySQL error code 132 = Old database fileMySQL error code 134 = Record was already deleted (or record file crashed)MySQL error code 135 = No more room in record fileMySQL error code 136 = No more room in index fileMySQL error code 141 = Duplicate unique key or constraint on write or updateMySQL error code 144 = Table is crashed and last repair failedMySQL error code 145 = Table was marked as crashed and should be repaired 如果要从命令行修复表，则必须先停止mysqld Server。请注意，当你在远程Server执行mysqladmin shutdown时，mysqld Server在mysqladmin返回后仍然可用一段时间，直到所有语句处理并已停止并且所有索引更改都已刷新到磁盘。 步骤1： 检查表 123456myisamchk *.MYI#myisamchk -e *.MYI#如果mysqld已停止，使用--update-state告诉myisamchk将表标记为已检查myisamchk --update-state *.MYI 步骤2： 简易修复表 123456789#尝试修复索引，而不触及数据myisamchk -r -q table_name#数据1. 数据备份2. myisamchk -r table_name #这将删除不正确的行和以排除的行，并重构索引文件3. 如果上一步失败，请使用 myisamchk --safe-recover tbl_name4. 如果遇到意外错误，查看第3步 步骤3： 难以修复 1234567891011#只有当索引文件中的第一个16KB块被销毁或包含不正确的信息，或索引文件丢失时，才应该到达此阶段。#这种情况系，需要创建一个新的索引文件1. 将数据移动到安全的地方2. 创建空数据和新索引mysql db_namemysql&gt; SET autocommit=1;mysql&gt; TRUNCATE TABLE table_name;mysql&gt; QUIT3. 将旧的数据文件复制回新创建的数据文件4. 重新执行步骤2 步骤4： 很难修复 1234#仅当.frm描述文件也崩溃时才应该到达此阶段#这应该永远不会发生，因为创建表后描述文件不会发生更改1. 从备份还原描述文件并回到步骤32. 如果没有备份，但确切知道如何创建表，请在另一个数据库中创建该表的副本。删除新数据文件，然后将.frm和.MYI移动到崩溃的数据库。返回步骤2尝试重建索引文件 优化MyISAM表MyISAM Table Optimization 要合并碎片行并消除因删除或更新行而导致的浪费空间，请在恢复模式下运行myisamchk: myisamchk -r table_name 你也可以通过OPTIMIZE TABLE的SQL语句进行表优化。此语句执行表修复和Key 分析，并对索引数进行排序，以便Key查找更快。 myisamchk有许多其它选项可用于提高表的性能： --analyze or -a执行Key分析。这可通过使连接优化器更好地选择连接表的顺序自己应该使用的索引来提高连接性能。 --sort-index or -S排序索引块。这可优化搜索并使表扫描更快地使用索引。 --sort-records=index_num or -R index_num根据给定索引对数据行进行排序。这可使数据更加本地化，并可以加速使用此索引的基于范围的SELECT和ORDER BY操作 配置MyISAM表维护计划Setting Up a MyISAM Table Maintenance Schedule 最好定期执行检查表，而不是等着问题发生。启用自动检查MyISAM表也是一个好主意。还应该在正常系统操作期间定期检查你的表。 1234#栗子35 0 * * 0 /path/to/myisamchk --fast --silent /path/to/datadir/*/*.MYImyisamchk -r -s --sort-index --myisam_sort_buffer_size=16M */*.MYI 优化Optimization 本章介绍如何优化MySQL性能并提供示例。优化涉及多个级别配置，调整和测量性能。根据你的工作角色(Developer、DBA、both)，你可在单个SQL语句、整个应用程序、单个数据库Server、多个网络数据库Server的级别进行优化。有时你可以主动并提前计划性能，而有时可能会在出现问题后解决配置或代码问题。优化CPU和内存使用还可以提供伸缩性，允许数据库处理更多负载而不会降低速度。 优化概述Optimization Overview 数据库性能取决于数据库级别的几个因素，如表、查询、配置设置。这些软件结构导致硬件级别的CPU和I/O操作，你必须尽可能降低这些操作并使其尽可能高效。在处理数据库性能时，首先要了解软件方面的高级规则和指南，并使用挂钟时间(wall-clock time)来衡量性能。当你成为专家后，你将了解更多内部发生的信息，并开始测量CPU周期和I/O操作… 典型用户的目标是从现有的软件和硬件配置中获取最佳的数据库性能；高级用户寻找改进MySQL软件本身的机会，或者开发自己的存储引擎或硬件设备来扩展MySQL生态系统。 数据库级别的优化Optimizing at the Database Level 使数据库应用程序快速运行的最重要的因素是其基本设计： 表结构是否合适？特别是，列(columns)是否具有正确的数据类型，并且每个表是否具有适合工作类型的列？例如，更新频繁的应用程序通常具有具有少量列的许多表；而分析大量数据的应用程序通常具有大量列的少量表。 是否有适当的索引来提高查询效率？ 是否为每个表使用了适当的存储引擎，并利用使用的每个存储引擎的优势和功能？特别是，诸如InnoDB之类的事务性(transactional)存储引擎或诸如MyISAM之列的非事务性(nontransactional)存储引擎的选择，对于性能和伸缩性非常重要。InnoDB是新表的默认存储引擎。实际上，先进的InnoDB性能特征意味着InnoDB表通常优于更简单的MyISAM表，尤其是对于繁忙的数据库。 是否每个表都使用了适当的行格式？这取决于表所使用的数据库。特别是，压缩的表使用较少的磁盘空间，因此需要较少的磁盘I/O来读取和写入数据。压缩适用于InnoDB表的各种工作负载，以及只读(read-only)MyISAM表。 是否应用程序使用了适当的锁定策略？例如，通过允许共享访问，以便数据库操作可以并发运行，并在适当时请求独占访问，以便关键操作成为首要任务。同样，存储引擎的选择也很重要。InnoDB存储引擎可以处理大多数锁定问题而无需你的参与，从而在数据库中实现更好的并发性，并减少代码的实验和调优。 是否正确使用了用于缓存的所有内存区域？也就是说，足够大以容纳频繁访问的数据，但不能太大以至于它们会超载物理内存并导致分页。要配置的主缓存区域是：InnoDb缓冲池，MyISAM key缓存、MySQL查询缓存。 硬件级别的优化Optimizing at the Hardware Level 随着数据库变得越来越繁忙，任何数据库应用程序最终都会达到硬件限制。DBA必须评估是否可以调整应用程序或重新配置Server以避免这些瓶颈(bottlenecks)，或者是否需要更多硬件资源？ 系统瓶颈通常来自于这些来源： 磁盘寻求磁盘需要一段时间才能找到一段数据。对于现代磁盘，平均时间通常低于10ms。优化搜索时间的方法是将数据分发到多个磁盘上。 磁盘读写当磁盘位于正确位置时，我们需要读写数据。可以从多个磁盘并行读取。 CPU周期当数据在主存储器中时，我们必须处理它们以获得我们想要的结果。 内存带宽当CPU需要的数据量超过了CPU缓存容量时，主存带宽就成了瓶颈。 平衡移植性和性能Balancing Portability and Performance 要在可移植的MySQL程序中使用面向性能的SQL扩展，你可在语句中包含MySQL特定关键字/* ... */评论分隔符(或--注释) 优化SQL语句Optimizing SQL Statements 数据库应用程序的核心逻辑是通过SQL语句执行的，无论是直接通过解释器还是通过API在幕后提交。 优化SELECT语句Optimizing SELECT Statements 查询以SELECT语句的形式执行数据库中的所有查找操作。调整这些语句的首要任务就是缩短响应时间。除了SELECT语句外，查询的调优技术也适用于DELETE语句中的CREATE TABLE ... AS SELECT, INSERT INTO ... SELECT和WHERE等构造子句。这些语句具有额外的性能考虑因素，因为它们将写操作与面向读操作的查询相结合。 优化查询的主要考虑因素有： 要使一个慢的SELECT ... WHERE查询更快，首先要检查是否可以添加索引。在WHERE字句中使用的列上设置索引，以加快评估、过滤和结果的最终检索。为避免浪费磁盘空间，请构建一小组索引，以加速应用程序中使用的许多相关查询。索引对于引用不同表的查询尤其重要，使用连接(joins)和外键(foreign keys)等功能。 隔离并调整查询的任何部分，例如函数调用，这会占用过多时间。根据查询的结构，可以为结果集中的每一行调用一次函数，甚至可以为表中的每一行调用一次函数，从而大大减轻任何低效率。 最大限度地减少查询中的全表扫描次数，尤其是对于大型表。 定期使用ANALYZE TABLE语句使表统计信息保持最新，因此优化程序具有构建有效执行计划所需的信息。 了解特定于每个表的存储引擎的调优技术，索引技术和配置参数。InnoDB和MyISAM都有一套指导方针，可以在查询中实现和维持高性能。 你可以优化InnoDb表的单查询事务。 避免以难以理解的方式转换查询。 如果其中一个基本准则无法轻松解决性能问题，请通过阅读EXPLAIN计划并调整索引、WHERE子句、join子句等来调查特定查询的内部详细信息。 调整MySQL用于缓存区域的大小和属性。通过有效使用InnoDB buffer pool、MyISAM key cache、MySQL query cache，重复查询运行的更快，因为在第二次及以后的时间内都是从内存中检索结果 即使对于使用高速缓存存储区快速运行的查询，你仍可以进一步优化，以便它们需要更少的高速缓存，从而使你的应用程序更具可伸缩性。可伸缩性意味着你的应用程序可以处理更多的并发用户，更大的请求…，而不会出现性能大幅下降的情况 处理锁定问题，其中查询的速度可能会受到同时访问表的其它回话的影响 WHERE子句优化WHERE Clause Optimization 你可能想要重写查询以更快地进行过算数运算，同时牺牲可读性。因为MySQL会自动执行类似的优化，所以通常可以避免这种工作，并使查询保持更容易理解和可维护的形式。 移除不必要的括号 12((a AND b) AND c OR (((a AND b) AND (c AND d))))--&gt; (a AND b AND c) OR (a AND b AND c AND d) 恒量折叠 12(a&lt;b AND b=c) AND a=5--&gt; b&gt;5 AND b=c AND a=5 恒量条件去除 12(B&gt;=5 AND B=5) OR (B=6 AND 5=5) OR (B=7 AND 5=6)--&gt; B=5 OR B=6 索引使用的常量表达式仅计算一次 早期检测无效常量表达式 如果不使用GROUP BY或聚合函数(COUNT(), MIN()...)，HAVING将与WHERE合并 对于连接中的每个表，构造一个更简单的WHERE以获得对表的快速平均，并且还尽快跳过行 在查询中的任何其它表之前，首先读取所有常量表： 一个空表或只有一行的表 与主键或唯一索引上的WHERE子句一起使用的表，其中所有索引部分都与常量表达式进行比较并定义为NOT NULL 以下所有表都用作常量表： 123SELECT * FROM t WHERE primary_key=1;SELECT * FROM t1,t2 WHERE t1.primary_key=1 AND t2.primary_key=t1.id; 通过尝试所有可能性，可以找到加入表格的最佳连接组合。如果ORFER BY和GROUP BY子句中的所有列都来自同一个表，则在加入时首先选择该表 如果存在ORDER BY子句和不同的GROUP BY子句，或者ORDER BY或GROUP BY包含连接队列中第一个表以外的表中的列，则会创建临时表 如果使用SQL_SMALL_RESULT修饰符，MySQL将使用内存中的临时表 查询每个表索引，并使用最佳索引，除非优化程序认为使用表扫描更有效。 在某些情况下，MySQL甚至无需查阅数据文件即可从索引中读取行。 在输出每一行之前，将跳过与HAVING子句不匹配的行。 一些非常快的查询示例： 123456789101112SELECT COUNT(*) FROM tbl_name;SELECT MIN(key_part1),MAX(key_part1) FROM tbl_name;SELECT MAX(key_part2) FROM tbl_name WHERE key_part1=constant;SELECT ... FROM tbl_name ORDER BY key_part1,key_part2,... LIMIT 10;SELECT ... FROM tbl_name ORDER BY key_part1 DESC, key_part2 DESC, ... LIMIT 10; MySQL使用索引数解析一下查询，假设索引列是数字： 123456SELECT key_part1,key_part2 FROM tbl_name WHERE key_part1=val;SELECT COUNT(*) FROM tbl_name WHERE key_part1=val1 AND key_part2=val2;SELECT key_part2 FROM tbl_name GROUP BY key_part1; 以下查询使用索引来按排序顺序检索行，而不使用单独的排序传递： 12345SELECT ... FROM tbl_name ORDER BY key_part1,key_part2,... ;SELECT ... FROM tbl_name ORDER BY key_part1 DESC, key_part2 DESC, ... ; 范围优化Range Optimization range访问方法使用单个索引来检索包含在一个或多个索引值间隔内的表行的子集。他可用于单部分(single-part)或多部分(multiple-part)索引。 语言结构Language Structure 字符集和编码Character Sets, Collations, Unicode 数据类型Data Type MySQL支持多种类型的SQL数据类型： numeric date/time string character byte JSON 数据类型描述使用如下约定： M表示整数类型的最大显示宽度 D适用于浮点和定点类型，并指示小数点后面的位数 fsp适用于TIME, DATATIME, TIMESTAMP类型，表示小数点的秒精度 方括号[]表示类型定义的可选部分 数字Numberic type 如果为数字列指定ZEROFILL，MySQL会自动将UNSIGNED属性添加到列中。 数字数据类型允许UNSIGNED(无符号)属性，也允许SIGNED(符号)。默认情况下，这些数据类型是SIGNED，因此SINGED属性不起作用。 BITA bit-value type.(1-64) TINYINTA very small integer.有符号范围: -128 to 127, 无符号范围: 0-255 BOOL SMALLINTA small integer.有符号范围: -32768 to 32767, 无符号范围: 0-65535 MEDIUMINTA medium-sized integer.有符号范围: -8388608 to 8388607, 无符号范围: 0-16777215 INTA normal-size integer.有符号范围: -2147483648 to 2147483647, 无符号范围: 0- 4294967295 INTERGER此类型是INT的同义词。 BIGINTA large integer.符号范围: -9223372036854775808 to 9223372036854775807, 无符号范围: 0 to 18446744073709551615SERIAL是BIGINT UNSIGNED NOT NULL AUTO_INCREMENT UNIQUE的别名。 DECIMAL/DEC FLOATA small(单精度) floating-point number.允许的值为: -3.402823466E+38 to -1.175494351E-38, 0, and 1.175494351E-38 to 3.402823466E+38 DOUBLEA normal-size(双精度) floating-point number.允许值为: -1.7976931348623157E+308 to -2.2250738585072014E-308, 0, and 2.2250738585072014E-308 to 1.7976931348623157E+308 FLOATA floating-point number. 日期和时间Date and Time Type MySQL允许的TIME, DATETIME, TIMESTAMP值的小数，精度高达微秒(小数点后6位)。 DATEA date.支持范围: 1000-01-01到9999-12-31。MySQL以YYYY-MM-DD格式显示DATE值，但允许使用字符串或数字将值分配给DATE列。 DATETIMEA date and time combination.支持范围: 1001-01-01 00:00:00.000000到9999-12-31 23:59:59.999999。MySQL以YYYY-MM-DD HH:MM:SS.[fraction]的格式显示DATETIME值，同样允许字符串或数字将值分配给DATETIME列。 TIMESTAMPA timestamp.支持范围: 1970-01-01 00:00:01.000000UTC到2038-01-19 03:14:07.999999UTCTIMESTAMP值存储为自纪元1970-01-01 00:00:01.000000 UTC以来的秒数，这也叫原子时间。 TIMEA time.支持范围: -838:59:59.000000 to 838:59:59.000000MySQL以HH:MM:SS[.fraction]的格式显示TIME值，但允许使用字符串或数字将值分配给TIME列。 YEARA year in four-digit format.MySQL以YYYY格式显示YEAR值，但允许使用字符串或数字将值分配给YEAR列。 字符串String Type 在某些情况下，MySQL可能会使用CREATE TABLE或ALTER TABLE语句更改字符串的类型。 CHARACTER SET/CHARSET指定字符集 12345CREATE TABLE t( c1 VARCHAR(20) CHARACTER SET utf8, c2 TEXT CHARACTER SET latin1 COLLATE latin1_general_cs); CHAR一个固定长度的字符串，在存储时使用用空格填充指定长度。VARCHAR的有效最大长度取决于最大行大小(65535字节)和使用的字符集。 VARCHAR一个可变长度的字符串。 BINARYBINARY类似于CHAR，但存储二进制字节字符串而不是非二进制字符串。 VARBINARY TINYBLOBA BLOB column with a maximum length of 255 (2^8 − 1) bytes. TINYTEXTA TEXT column with a maximum length of 255 (2^8 − 1) characters. BLOBA BLOB column with a maximum length of 65,535 (2^16 − 1) bytes. TEXTA TEXT column with a maximum length of 65,535 (2^16 − 1) characters. MEDIUMBLOBA BLOB column with a maximum length of 16,777,215 (2^24 − 1) bytes. MEDIUMTEXTA TEXT column with a maximum length of 16,777,215 (2^24 − 1) characters. LONGBLOBA BLOB column with a maximum length of 4,294,967,295 or 4GB (2^32 − 1) bytes. LONGTEXTA TEXT column with a maximum length of 4,294,967,295 or 4GB (2^32 − 1) characters. ENUMAn enumeration. SETA set.]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018小计划]]></title>
    <url>%2F2018%2F01%2F15%2F2018%E5%B0%8F%E8%AE%A1%E5%88%92%2F</url>
    <content type="text"><![CDATA[工作 《MongoDB官方文档》： https://docs.mongodb.com 《SatlStack官方文档》： https://docs.saltstack.com 《MySQL官方文档》： https://dev.mysql.com/doc/ 《TCP/IP协议族》： https://book.douban.com/subject/5386194/ 《Linux性能调优指南》： https://lihz1990.gitbooks.io/transoflptg/content/ 《Docker官方文档》： https://docs.docker.com/ 《Consul官方文档》： https://www.consul.io/docs/index.html 《Python工作自动化》： https://book.douban.com/subject/26836700/ 《Elastic Stack》: https://www.elastic.co/guide/index.html 《Kubernetes官方文档》: https://kubernetes.io/cn/docs/ 《Python3文档/标准库》: https://docs.python.org/ 《Fluentd官方文档》： https://docs.fluentd.org 个人 《资本论》： https://book.douban.com/subject/1150503/ 《灵飞经小楷》： https://book.douban.com/subject/1115916/ 《经济学原理》： https://book.douban.com/subject/26435630/ 《行测/申论》 生活 沉得住气 培养一门兴趣爱好 找寻另一半]]></content>
      <categories>
        <category>Zhang</category>
      </categories>
      <tags>
        <tag>2018</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[海明威的《老人与海》]]></title>
    <url>%2F2018%2F01%2F13%2F%E8%80%81%E4%BA%BA%E4%B8%8E%E6%B5%B7%2F</url>
    <content type="text"><![CDATA[我不相信人会有所谓的“命运”，但是我相信对于任何人来说，“限度”总是存在的。再聪明再强悍的人，能够做到的事情也总是有限度的。老人桑地亚哥不是无能之辈，然而，尽管他是最好的渔夫，也不能让那些鱼来上他的钩。他遇到他的限度了，就象最好的农民遇上了大旱，最好的猎手久久碰不到猎物一般。每一个人都会遇到这样的限度，仿佛是命运在向你发出停止前行的命令。 可是老人没有沮丧，没有倦怠，他继续出海，向限度挑战。他终于钓到了一条鱼。如同那老人是人中的英雄一样，这条鱼也是鱼中的英雄。鱼把他拖到海上去，把他拖到远离陆地的地方，在海上与老人决战。在这场鱼与人的恶战中，鱼也有获胜的机会。鱼在水下坚持了几天几夜，使老人不能休息，穷于应付，它用酷刑来折磨老人，把他弄得血肉模糊。这时，只要老人割断钓绳，就能使自己摆脱困境，得到解放，但这也就意味着宣告自己是失败者。老人没有作这样得选择，甚至没有产生过放弃战斗的念头。他把那条鲨鱼当作一个可与之交战的敌手，一次又一次地做着限度之外的战斗，他战胜了。 老人载着他的鱼回家去，鲨鱼在路上抢劫他的猎物。他杀死了一条来袭的鲨鱼，但是折断了他的鱼叉。于是他用刀子绑在棍子上做武器。到刀子又折断的时候，似乎这场战斗已经结束了。他失去了继续战斗的武器，他又遇到了他的限度。这是，他又进行了限度之外的战斗：当夜幕降临，更多的鲨鱼包围了他的小船，他用木棍、用桨、甚至用舵和鲨鱼搏斗，直到他要保卫的东西失去了保卫的价值，直到这场搏斗已经变得毫无意义的时候他才住手。 老人回到岸边，只带回了一条白骨，只带回了残破不堪的小船和耗尽了精力的躯体。人们怎样看待这场斗争呢？ 有人说老人桑地亚哥是一个失败了得英雄。尽管他是条硬汉，但还是失败了。 什么叫失败？也许可以说，人去做一件事情，没有达到预期得目的，这就是失败。 但是，那些与命运斗争的人，那些做接近自己限度的斗争的人，却天生地接近这种失败。老人到海上去，不能期望天天有鱼来咬他的钩，于是他常常失败。一个常常在进行着接近自己限度的斗争的人总是会常常失败的，一个想探索自然奥秘的人也常常会失败，一个想改革社会的人更是会常常失败。只有那些安于自己限度之内的生活的人才总是“胜利”，这种“胜利者”之所以常胜不败，只是因为他的对手是早已降伏的，或者说，他根本没有投入斗争。 在人生的道路上，“失败“这个词还有另外的含义，即是指人失去了继续斗争的信心，放下了手中的武器。人类向限度屈服，这才是真正的失败。而没有放下手中武器，还在继续斗争，继续向限度挑战的人并没有失败。如此看来，老人没有失败，老人从未放下武器，只不过是丧失了武器。老人没有失去信心，因此不应当说他是“失败了的英雄”。 那么，什么也没有得到的老人竟是胜利的么？我确是这样看的。我认为，胜利就是战斗到最后的时刻。老人总怀着无比的勇气走向莫测的大海，他的信心是不可战胜的。 他和其他许多人一样，是强悍的人类的一员。我喜欢这样的人，也喜欢这样的人性。我发现，人们常常把这样的事情当作人性最可贵的表露：七尺男子汉坐在厨房里和三姑六婆磨嘴皮子，或者衣装笔挺的男女们坐在海滨，谈论着高尚的、别人不能理解的感情。我不喜欢人们像这样沉溺在人性软弱的部分之中，更不喜欢人们总是这样描写人性。 正像老人每天走向大海一样，很多人每天也走向与他们的限度斗争的战场，仿佛他们要与命运一比高低似的。他们是人中的强者。 人类本身也有自己的限度，但是当人们一再把手伸到限度之外，这个限度就一天一天地扩大了。人类在与限度的斗争中成长。他们把飞船送上太空，他们也用简陋的渔具在加勒比海捕捉巨大的马林鱼。这些事情是同样伟大的。做这样不可思议的事情的人都是英雄。而那些永远不肯或不能越出自己限度的人是平庸的人。 在人类前进的道路上，强者与弱者的命运是不同的。弱者不羡慕强者的命运，强者也讨厌弱者的命运。强者带有人性中强悍的一面，弱者带有人性中软弱的一面。强者为弱者开辟道路，但是强者往往为弱者所奴役，就像老人是为大腹便便的游客打鱼一样。 《老人与海》讲了一个老渔夫的故事，但是在这个故事里却揭示了人类共同的命运。我佩服老人的勇气，佩服他不屈不饶的斗争精神，也佩服海明威。]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>王小波</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sysctl,ulimit以及/proc]]></title>
    <url>%2F2018%2F01%2F09%2Fsysctl%E3%80%81ulimit%E5%92%8Cproc%2F</url>
    <content type="text"><![CDATA[参考： sysctl命令 ulimit命令 ulimit、limits.conf、sysctl和proc文件系统 sysctl.conf学习和调优 sysctlsysctl 命令被用于在内核运行时动态地修改内核的运行参数，可用的内核参数在目录 /proc/sys 中。它包含一些Tcp/Ip堆栈和虚拟内存系统的高级选项，可以通过修改某些值来提高系统性能。 sysctl可以读取和设置超过五百个系统变量。sysctl变量的设置通常是字符串、数字或布尔型（布尔型用1表示yes，0表示no）。 sysctl - configure kernel parameters at runtime. 语法： 123#sysctl [options] [variable[=value]] [...]sysctl -w net.ipv4.tcp_syncookies=1 可以通过sysctl命令修改系统变量，也可以通过编辑sysctl.conf配置文件来修改系统变量。 sysctl.conf - sysctl preload/configuration file. 举个栗子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124vim /etc/sysct.conf# Controls source route verification# Default should work for all interfaces net.ipv4.conf.default.rp_filter = 1# net.ipv4.conf.all.rp_filter = 1# net.ipv4.conf.lo.rp_filter = 1# net.ipv4.conf.eth0.rp_filter = 1# Disables IP source routing# Default should work for all interfaces net.ipv4.conf.default.accept_source_route = 0# net.ipv4.conf.all.accept_source_route = 0# net.ipv4.conf.lo.accept_source_route = 0# net.ipv4.conf.eth0.accept_source_route = 0# Controls the System Request debugging functionality of the kernelkernel.sysrq = 0# Controls whether core dumps will append the PID to the core filename# Useful for debugging multi-threaded applicationskernel.core_uses_pid = 1# Increase maximum amount of memory allocated to shm# Only uncomment if needed# kernel.shmmax = 67108864# Disable ICMP Redirect Acceptance# Default should work for all interfacesnet.ipv4.conf.default.accept_redirects = 0# net.ipv4.conf.all.accept_redirects = 0# net.ipv4.conf.lo.accept_redirects = 0# net.ipv4.conf.eth0.accept_redirects = 0# enable Log Spoofed Packets, Source Routed Packets, Redirect Packets# Default should work for all interfacesnet.ipv4.conf.default.log_martians = 1#net.ipv4.conf.all.log_martians = 1# net.ipv4.conf.lo.log_martians = 1# net.ipv4.conf.eth0.log_martians = 1# Decrease the time default value for tcp_fin_timeout connectionnet.ipv4.tcp_fin_timeout = 25# Decrease the time default value for tcp_keepalive_time connectionnet.ipv4.tcp_keepalive_time = 1200# Turn on the tcp_window_scalingnet.ipv4.tcp_window_scaling = 1# Turn on the tcp_sacknet.ipv4.tcp_sack = 1# tcp_fack should be on because of sacknet.ipv4.tcp_fack = 1# Turn on the tcp_timestampsnet.ipv4.tcp_timestamps = 1# Enable TCP SYN Cookie Protectionnet.ipv4.tcp_syncookies = 1# Enable ignoring broadcasts requestnet.ipv4.icmp_echo_ignore_broadcasts = 1# Disable ping requestsnet.ipv4.icmp_echo_ignore_all = 1# Enable bad error message Protectionnet.ipv4.icmp_ignore_bogus_error_responses = 1# make more local ports available# net.ipv4.ip_local_port_range = 1024 65000# set TCP Re-Ordering value in kernel to 5net.ipv4.tcp_reordering = 5# Lower syn retry ratesnet.ipv4.tcp_synack_retries = 2net.ipv4.tcp_syn_retries = 3# Set Max SYN Backlog to 2048net.ipv4.tcp_max_syn_backlog = 2048# Various Settingsnet.core.netdev_max_backlog = 1024# Increase the maximum number of skb-heads to be cachednet.core.hot_list_length = 256# Increase the tcp-time-wait buckets pool sizenet.ipv4.tcp_max_tw_buckets = 360000# This will increase the amount of memory available for socket input/output queuesnet.core.rmem_default = 65535net.core.rmem_max = 8388608net.ipv4.tcp_rmem = 4096 87380 8388608 net.core.wmem_default = 65535net.core.wmem_max = 8388608net.ipv4.tcp_wmem = 4096 65535 8388608net.ipv4.tcp_mem = 8388608 8388608 8388608net.core.optmem_max = 40960 重新加载内核参数： 12345#-p, read values from filesysctl -p#-a, display all variablessysctl -a ulimit大多Unix-Like系统，都提供了限制每个进程和每个基本用户使用线程，文件和网络连接等系统资源的一些方法。 假设有这样一种情况，当一台Linux主机上同时登陆了10人，在资源无限制的情况下，这10个用户同时打开了500个文件。假设每个文件的大小有10M，这是系统的内存资源就会收到巨大挑战。但是任何一台主机的资源都不可能是无限的。所以，资源的合理配置和分配，不仅仅是保证系统可用性的必要条件，也与系统上软件运行的性能有着密不可分的联系。 ulimit是指每个user使用各种资源的限制值。ulimit 命令用来限制系统用户对shell资源的访问，它是一种简单并且有效的实现资源限制的方式。 ulimit的设置值是 per-process的，也就是说，每个进程都有自己的limits值； 使用ulimit进行修改，是立即生效的； ulimit只影响shell进程及其子进程，用户登出后失效； 修改ulimit设置之后，要重启程序修改值才会有效。可通过/proc文件系统查看运行进程当前的限制值; 使用ulimit对系统限制的改变在系统重启后都会恢复到默认值; 可以在profile中加入ulimit的设置，便能做到永久生效。 ulimit 用于限制 shell 启动进程所占用的资源，支持以下各种类型的限制： 所创建的内核文件的大小； 进程数据块的大小； Shell进程创建文件的大小； 内存锁住的大小； 常驻内存集的大小； 打开文件描述符的数量； 分配堆栈的最大大小； CPU时间； 单个用户的最大线程数； Shell进程所能使用的最大虚拟内存； 它支持硬资源(hard)和软资源(soft)的限制。 sort和hard hard：是指用户在任何时候都可以活动的进程的最大数量，这是上限。没有任何non-root进程能够增加hard ulimit； soft：是对会话或进程实际执行的限制，但任何进程都可以将其增加到hard ulimit的最大值。 设置ulimit可以在以下位置进行ulimit的设置： /etc/profile，所有用户有效，永久生效； ~/.bash_profile,当前用户有效，永久生效； 直接在控制台修改，当前用户有效，临时生效； 永久生效： 123vim /etc/profilevim ~/.bash_profile 临时生效： 12345678910111213141516171819202122232425ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 7170max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 1024pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 7170virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited#修改限定值ulimit -n 201400ulimit -t ulimited limits.conflimits.conf - configuration file for the pam_limits module limits.conf是pam_limits.so的配置文件，Linux PAM(Pluggable Authentication Modules，插入式认证模块)。突破系统默认限制，对系统资源有一定保护作用。 pam_limits模块对用户的会话进行资源限制，然后/etc/pam.d/下的应用程序调用pam_***.so模块。 limits.conf是针对用户，而sysctl.conf是针对整个系统参数配置。 一个shell的初始limits就是由pam_limits设定的，用户登录后，pam_limits会给用户的shell设定在limits.conf定义的值； pam_limits的设定值也是per-process； pam_limits的设置是 永久生效的。 配置limits.conf： 1vim /etc/security/limits.conf 举个栗子： 123456789#&lt;domain&gt; &lt;type&gt; &lt;item&gt; &lt;value&gt;#* soft core 0#* hard rss 10000#@student hard nproc 20#@faculty soft nproc 20#@faculty hard nproc 50#ftp hard nproc 0#@student - maxlogins 4 domain： username @groupname type： soft hard - item： core，限制内核文件的大小 date，最大数据大小 fsize，最大文件大小 memlock，最大锁定内存地址空间 nofile，打开文件的最大数目 rss，最大持久设置大小 stack，最大栈大小 cpu，以分钟为单位的最多CPU时间 nproc，进程的最大数目 as，地址空间限制 maxlogins，此用户允许登录的最大数目 value： item值的大小 /proc什么是/proc文件系统Linux内核提供了一种通过/proc文件系统，在运行时访问内核内部数据结构，改变内核设置的机制。 proc文件系统是一个伪文件系统，它只存在内存当中，不占用外部空间。它以文件系统的方式为访问系统内核数据的操作提供接口。 对/proc中内核文件的修改，针对的是整个系统的内核参数，修改后立即生效，但修改是 临时的，重启后失效。 /proc与sysctl.conf的对应关系修改/proc文件系统中的参数是临时的，但修改sysctl.conf的参数确是永久有效的。 配置文件sysctl.conf变量在/proc/sys下，其对应关系如下： 123456789#将文件名的 . 变为 /#/proc/sys/net/ipv4/icmp_echo_ignore_all#net.ipv4.icmp_echo_ignore_allecho 0 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_allvim /etc/sysctl.confnet.ipv4.icmp_echo_ignore_all = 0 /proc文件系统几个常用的内核文件 /proc/meminfo #内存信息 /proc/cpuinfo #CPU信息 /proc/sys/fs/file-max #文件打开数 /proc/sys/fs/file-nr #整个系统目前使用的文件句柄数量 /proc文件系统中文件的权限proc中的每个文件都有一组分配给它的非常特殊的文件许可权，并且每个文件属于特定的用户标识。 只读：任何用户都不能更改该文件，它用于表示系统信息 root写 root读 对/proc进行读写123456cat /proc/sys/net/ipv4/icmp_echo_ignore_all#0echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all#当然,也可是用sysctl来配置 /proc内核文件详解 /proc/buddyinfo 每个内存区中的每个order有多少块可用，和内存碎片问题有关 /proc/cmdline 启动时传递给kernel的参数信息 /proc/cpuinfo cpu的信息 /proc/crypto 内核使用的所有已安装的加密密码及细节 /proc/devices 已经加载的设备并分类 /proc/dma 已注册使用的ISA DMA频道列表 /proc/execdomains Linux内核当前支持的execution domains /proc/fb 帧缓冲设备列表，包括数量和控制它的驱动 /proc/filesystems 内核当前支持的文件系统类型 /proc/interrupts x86架构中的每个IRQ中断数 /proc/iomem 每个物理设备当前在系统内存中的映射 /proc/ioports 一个设备的输入输出所使用的注册端口范围 /proc/kcore 代表系统的物理内存，存储为核心文件格式，里边显示的是字节数，等于RAM大小加上4kb /proc/kmsg 记录内核生成的信息，可以通过/sbin/klogd或/bin/dmesg来处理 /proc/loadavg 根据过去一段时间内CPU和IO的状态得出的负载状态，与uptime命令有关 /proc/locks 内核锁住的文件列表 /proc/mdstat 多硬盘，RAID配置信息(md=multiple disks) /proc/meminfo RAM使用的相关信息 /proc/misc 其他的主要设备(设备号为10)上注册的驱动 /proc/modules 所有加载到内核的模块列表 /proc/mounts 系统中使用的所有挂载 /proc/mtrr 系统使用的Memory Type Range Registers (MTRRs) /proc/partitions 分区中的块分配信息 /proc/pci 系统中的PCI设备列表 /proc/slabinfo 系统中所有活动的 slab 缓存信息 /proc/stat 所有的CPU活动信息 /proc/sysrq-trigger 使用echo命令来写这个文件的时候，远程root用户可以执行大多数的系统请求关键命令，就好- 像在本地终端执行一样。要写入这个文件，需要把/proc/sys/kernel/sysrq不能设置为0。这个文件对root也是不可- 读的 /proc/uptime 系统已经运行了多久 /proc/swaps 交换空间的使用情况 /proc/version Linux内核版本和gcc版本 /proc/bus 系统总线(Bus)信息，例如pci/usb等 /proc/driver 驱动信息 /proc/fs 文件系统信息 /proc/ide ide设备信息 /proc/irq 中断请求设备信息 /proc/net 网卡设备信息 /proc/scsi scsi设备信息 /proc/tty tty设备信息 /proc/net/dev 显示网络适配器及统计信息 /proc/vmstat 虚拟内存统计信息 /proc/vmcore 内核panic时的内存映像 /proc/diskstats 取得磁盘信息 /proc/schedstat kernel调度器的统计信息 /proc/zoneinfo 显示内存空间的统计信息，对分析虚拟内存行为很有用 以下是/proc目录中进程N的信息： /proc/N pid为N的进程信息 /proc/N/cmdline 进程启动命令 /proc/N/cwd 链接到进程当前工作目录 /proc/N/environ 进程环境变量列表 /proc/N/exe 链接到进程的执行命令文件 /proc/N/fd 包含进程相关的所有的文件描述符 /proc/N/maps 与进程相关的内存映射信息 /proc/N/mem 指代进程持有的内存，不可读 /proc/N/root 链接到进程的根目录 /proc/N/stat 进程的状态 /proc/N/statm 进程使用的内存的状态 /proc/N/status 进程状态信息，比stat/statm更具可读性 /proc/self 链接到当前正在运行的进程]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>系统优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开源许可协议]]></title>
    <url>%2F2018%2F01%2F09%2F%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[当你为你的产品签发许可，你就是在出让自己的权利。不过，你仍拥有版权和专利（如果申请了专利）。许可的目的，是向使用你产品的人提供一定的权利。 不管产品是免费分发，还是出售，指定一份许可协议都非常有用。否则，对于免费，你相当于放弃了自己的所有权利，任何人都没有义务表明你的原始作者身份。对于出售，你将不得不花费比开发更多的精力用来处理授权问题。 而开源许可协议是这些事情变得简单，开发者很容易向一个项目贡献自己的代码，它还可以保护你原始作者的身份，使你至少获得认可。开源许可协议还可以阻止其它人将某个产品据为己有。 几大开源许可协议 GNU Project GNU是“GNU’s Not Unix”的递归缩写，发音为 /‘gnu:’/； GNU Project，是一个由自由软件集体协作项目，它的目标是创建一套完全自由的操作系统，称为GNU； GNU是一个自由操作系统，其内容软件完全以 GPL 方式发布，它的设计类似于Unix，但它不包含具有著作权的Unix代码。 GPLGNU(General Public Licence)，GNU通用许可协议(简称GPL)是广泛使用的免费软件许可证，也称为 copyleft，与copyright相对应。GPL保证了所有开发者的权利，同时为使用者提供了足够的复制、分发、修改的权利。 需要注意的是，分发的时候，需要明确提供源代码和二进制文件。 可自由复制： 你可以将软件复制到你的电脑或任何地方，复制份数没有限制； 可自由分发： 可下载后拷贝分发； 可以用来盈利： 你可以在分发软件的时候收费，但必须在收费前向你的客户提供该软件的 GNU GPL许可协议，以便让他们知道，他们可以从别的渠道免费得到这份软件以及你收费的理由； 可自由修改： 你过你想添加或删除某个功能，没问题。如果你想在别的项目中使用部分代码，也没问题，唯一要求是使用了这段代码的项目也必须使用 GPL协议。 LGPLGNU还有另外一种协议，叫做LGPL（Lesser General Public License），它对产品所保留的权利比GPL少。总的来说，LGPL适合那些用于非GPL或非开源产品的开源类库或框架。因为GPL要求，使用了GPL代码的产品也必须使用GPL协议，开发者不允许将GPL代码用于商业产品。LGPL绕过了这一限制。 GPL和LGPL都属于GNU计划里面的许可证。 BSD伯克利软件套件（Berkeley Software Distribution，缩写BSD），也被称为伯克利Unix，是一个操作系统的名称，衍生自Unix，也被用来代表一整套软件发行版。 BSD许可证（Berkeley Software Distribution License），是自由软件中使用广泛的许可证。BSD软件就是遵照这个许可证来发布，该许可证也因此而得名。 BSD在软件分发方面的限制比别的开源协议要少，且和GPL兼容，并为开源组织所认可。 MITMIT（Massachusetts Institute of Technology），麻省理工学院。MIT许可协议（The MIT License）是许多软件授权条款中，被广泛使用的其中一种。与其他常见的软件许可协议相比，MIT是相对宽松的软件许可协议，除了必须包含许可声明外，再无任何限制。 MIT许可协议核心条款： 该软件及其相关文档对所有人免费，可以任意处置，包括使用、复制、修改、合并、发表、分发、再授权或销售； 唯一的限制，软件中必须包含上述版权和许可证。 ApacheApache许可证（Apache License），是一个由Apache软件基金会发布的自由软件许可证。Apache许可证要求被授权者保留版权和放弃权利的声明，但它不是一个反版权的许可证。兼容与GPL。 除了为用户提供版权许可之外，还有专利许可，对于那些涉及专利内容的开发者而言，该协议最适合。 永久权利：一旦被授权，永久拥有； 全球范围的权利：在一个国家获得授权，适用于所有国家； 授权免费，且无版税：前后期均无任何费用； 授权不可撤销：一旦获得授权，没有任何人可以取消。 分发代码方面，要在声明中对参与开发的人给予认可并包含一份许可协议原文。 MPLMPL是The Mozilla[mɔzilə] Public License的简写，是1998年初Netscape的 Mozilla小组为其开源软件项目设计的软件许可证。MPL许可证出现的最重要原因就是，Netscape公司认为GPL许可证没有很好地平衡开发者对源代码的需求和他们利用源代码获得的利益。 同著名的GPL许可证和BSD许可证相比，MPL在许多权利与义务的约定方面与它们相同（因为都是符合OSIA 认定的开源软件许可证）。 MPL几个特点： MPL虽然要求对于经MPL许可证发布的源代码的修改也要以MPL许可证的方式再许可出来，以保证其他人可以在MPL的条款下共享源代码。但是，在MPL 许可证中对“发布”的定义是“以源代码方式发布的文件”，这就意味着MPL允许一个企业在自己已有的源代码库上加一个接口，除了接口程序的源代码以MPL 许可证的形式对外许可外，源代码库中的源代码就可以不用MPL许可证的方式强制对外许可。这些，就为借鉴别人的源代码用做自己商业软件开发的行为留了一个豁口； MPL许可证第三条第7款中允许被许可人将经过MPL许可证获得的源代码同自己其他类型的代码混合得到自己的软件程序； 对软件专利的态度，MPL许可证不像GPL许可证那样明确表示反对软件专利，但是却明确要求源代码的提供者不能提供已经受专利保护的源代码（除非他本人是专利权人，并书面向公众免费许可这些源代码），也不能在将这些源代码以开放源代码许可证形式许可后再去申请与这些源代码有关的专利； 对源代码的定义，MPL许可证第3条有专门的一款是关于对源代码修改进行描述的规定，就是要求所有再发布者都得有一个专门的文件就对源代码程序修改的时间和修改的方式有描述。 CC知识共享许可协议(Creative Commons License，简称CC)，并非严格意义上的开源许可，是一种公共版权许可协议。它主要用于设计，其允许分发受版权保护的作品。 CC协议主要包含4种基本形式： 署名权：必须为原始作业署名，然后才可以修改、分发、复制； 保持一致：作品同样可以在CC协议的基础上修改、分发、复制； 非商业：不能用于商业用途； 不能衍生新作品：你可以复制、分发、但不能修改，也不能以此为基础创作自己的作品。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>开源许可协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yum源]]></title>
    <url>%2F2018%2F01%2F09%2FYum%E6%BA%90%2F</url>
    <content type="text"><![CDATA[参考： CentOS 7下配置本地yum源及yum客户端 Centos7 配置本地源+阿里yum源/epel-yum+修改优先级 调整CentOS 7中yum仓库的优先级 国内开源站点 国内开源镜像站点 网易开源镜像站：http://mirrors.163.com/ 阿里云开源镜像站：http://mirrors.aliyun.com 清华大学开源镜像站：https://mirrors.tuna.tsinghua.edu.cn/ 浙江大学开源镜像站： http://mirrors.zju.edu.cn/ 中国科技大学开源镜像站：http://mirrors.ustc.edu.cn/ CentOS自带源rpm包管理方式，对于安装、升级、卸载却难以处理包之间的依赖关系。而yum作为一个rpm包前端管理工具，可以自动处理依赖性，并支持在线现在、安装、升级、卸载rpm软件包。 CentOS默认自带CentOS-Base.repo源，但官方源在国外，连接速度令人心痛。并且有很多软件在默认源里面是找不到的。 配置网络yun源配置aliyun.repo： 12345678910#先备份默认源mv CentOS-Base.repo&#123;,.bak&#125;#下载阿里云源替换默认源wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repoyum clean allyum makecache #重构yum缓存yum repolist #查看yum仓库 配置本地yum源配置本地yum源，考虑到优先使用本地安装包，所以会涉及到一个优先级的概念。 安装完毕后，就可以在yum源中添加一个优先级priority。 安装yum优先级插件： 1234567yum install -y yum-plugin-priorities#检查安装完成后配置vim /etc/yum/pluginconf.d/priorities.confenable=1#enable=0 创建本地yum源： 123456789101112131415161718192021222324mv /etc/yum.repos.d/CentOS-Base.repo&#123;,.bak&#125;vim /etc/yum.repos.d/CentOS-Local.repo[base-Local]name=Centos- Localbaseurl=file:///mnt/xxxgpgcheck=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7priority=1 #优先级为1[updates-Local]name=CentOS- Localgpgcheck=0baseurl=file:///dir/path/gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7priority=1······#具体可参考CentOS-Base.repo#可将aliyun源优先级写成2yum clean allyum makecache 配置ftp方式源1234567891011vim /etc/yum.repos.d/ftp.repo[ftp-media]name=name=CentOS-$releasever - mediabaseurl=ftp://ipgpgcheck=0enable=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7yum clean allyum makecache 其他常见YUM源官方的默认yum源提供的软件包往往是很滞后的，(可能为了服务器版本的稳定性和安全性)。并且官方默认源提供的RPM包也不够丰富。 EPEL源EPEL的全称叫 Extra Packages for Enterprise Linux 。EPEL是由 Fedora 社区打造，为 RHEL 及衍生发行版如 CentOS、Scientific Linux 等提供高质量软件包的项目。装上了 EPEL之后，就相当于添加了一个第三方源。 EPEL源为服务器提供了大量的rpm包(这些包可能有很多在默认源中没有)，并且绝大多数rpm包比官方默认源版本要新。 添加epel源：epel下载地址：http://download.fedora.redhat.com/pub/epel/123rpm -vih http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-9.noarch.rpm#yum install -y epel-release remi源Remi源大家或许很少听说，不过Remi源GoFace强烈推荐，尤其对于不想编译最新版的linux使用者，因为Remi源中的软件几乎都是最新稳定版。或许您会怀疑稳定不？放心，这些都是Linux骨灰级的玩家编译好放进源里的，他们对于系统环境和软件编译参数的熟悉程度毋庸置疑。 添加remi源：Remi下载地址：http://rpms.famillecollet.com123rpm -ivh http://rpms.famillecollet.com/enterprise/remi-release-7.rpm#yum install -y http://rpms.famillecollet.com/enterprise/remi-release-7.rpm RPMForge源RPMForge是CentOS系统下的软件仓库，拥有4000多种的软件包, 被CentOS社区认为是最安全也是最稳定的一个软件仓库。 添加RPMForge源：RPMForge下载地址：http://repository.it4i.cz/mirrors/repoforge/redhat/el7/en/x86_64/rpmforge/RPMS/GitHub:https://github.com/repoforge 123rpm -ivh http://repository.it4i.cz/mirrors/repoforge/redhat/el7/en/x86_64/rpmforge/RPMS/rpmforge-release-0.5.3-1.el7.rf.x86_64.rpm#yum localinstall --nogpgcheckhttp://repository.it4i.cz/mirrors/repoforge/redhat/el7/en/x86_64/rpmforge/RPMS/rpmforge-release-0.5.3-1.el7.rf.x86_64.rpm]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[写给2017]]></title>
    <url>%2F2018%2F01%2F01%2F%E5%86%99%E7%BB%992017%2F</url>
    <content type="text"><![CDATA[2017大事件 Feb.27.2017，开始工作； May.27.2017，工作转正； Jun.25.2017，大学毕业； Aug.27.2017，工作半年； Aug.30.2017，搭建博客。 记得大四下期的时候，在学校实在是想出来工作，以为这样就可以有工资有点钱可以实现财务自由。Naive x3! 记得刚去面试的时候，公司的HR问我期待的薪资是多少。我这个老实人也不敢往高了说，以为能解决温饱就不错。这就导致后面日子过得紧巴巴，生活基本上处于没钱不敢消费不敢出去的惨状。Naive x3! 记得那天是星期四，从学校收拾了一箱子的衣物加上自己的笔记本就来了成都。还要感谢强对我的帮助，在他那借宿了两天。这两天跑到公司附近找房子，这打个电话，那去看看…结果看了看自己兜里不到三千，再看看房租，还是算了吧！后来由于周一就要开始去公司报道了，实在没办法，硬着头皮找了一个750的单间。我现在觉得，人在生活面前真的没有办法。借用张主任的一句话——“是生活，生活强奸了所有人。”一个套三的屋子，硬是被房主改造成了七间房，住了11人。我想各位住户都迫于无奈吧，有谁想和别人挤在一起了，况且还要忍受上厕所的艰难时光。还是说说我住的那间房屋吧。是客厅使用木板隔得房间，手指随便敲几下都铛铛作响，况且隔壁还住了一对情侣。一张床，一个烂小衣柜，一张摆放电脑的桌子。客厅的后面有一个阳台，所以就会有一个大窗户间隔阳台。然而这个阳台是和隔壁公用的，也就是说，这个大窗户是可以互通的。哎！阳台风大，还好我只住到了夏天。五月二十号，和我强一起搬到了中和。也是没有做好十足打算，说搬就搬了。虽说住宿条件好了一些，可这面修路是真的堵，公家车是真的挤，真的是挤得怀疑人生的那种，还是走路吧。由于搬过来中和，房租和其他开支多了一些，刚开始没什么钱的时候，自己带饭去公司。我都佩服自己，那么挤得车上还能坚持带饭几个月，看来还是穷吧。冬天到了，太冷了就没有带饭到公司了。但公司楼下吃饭真的好贵，吃不起吃不起。由于住宿条件好了一些，晚上回来可以自己做饭，还是不错。并且晚上基本有两个小时干干工作之外的事情，看看小说、看看电视、发发呆什么也挺好的！ 记得才开始工作的时候，好像每天都很闲，没有事做。心里担忧的不行，这样怎么有提升呢？每天都急躁不安，这不会那不会，又腼腆害羞…后来慢慢理解，任何事情都不能操之过急，不能带着情绪上班。不喜欢某个同事也不能表现出来，更不能带到工作上。工作是工作，生活是生活，一定要分开。被骂也没有办法，骂吧，你骂高兴。任何人都不会听你的理由，理由对于别人来说只是你没有完成的狡辩。踏踏实实上班，做好自己的事情才是正解！千万不要好为人师，人都是有嫉妒心得，不要太招摇！也不要羡慕别人工作轻松之类，那是人家的工作，和你没有半毛钱关系。上班好好上班，不要搞东搞西。我个人比较看重效率，怀着为了加班而加班的目的真的没有必要。那时由于住单间，条件差，愿意在公司多呆一会，多学习知识。越到后面，觉得自己越得努力学习新知识，需要了解的知识就在那，就等我把它们一个个打上勾，撸起袖子加油干。 自我批评: 心胸不够宽广，容易嫉妒别人； 害羞爱面子，拉不下面子做事情； 由于自卑心理导致的不敢说不敢争。 以前我以为自己是讨厌某种方式、讨厌别人炫耀、讨厌别人秀恩爱，现在才知道是由于自己没有，就用自己的不屑和厌恶来突出自己，让自己心安理得。说白了还不是自己嫉妒人家，嫉妒人家比我好，有女票。这点是真的要改，一定要改。千万别用别人的缺点来突出自己，这很SB，切记切记。如同小波所说：“人的一切痛苦，本质都是对于自己无能的愤怒。” 在学校总幻想自己能成为英雄，总想做一番事业，像历史上的英雄那般。不屑考个老师公务员职位，以为一辈子就那样，混吃等死的咸鱼。其实其它工作不也同样是这样吗。混吃等死的不是任何工作岗位，而是人！任何岗位都可以有所成就。自己也不过只是凡人一个。不过凡人却也可以有自己的一片天地。就像小波说的：“井底之蛙也能拥有自己的一片天地。” 工作没有高低贵贱之分，不要带着要面子的心情而不愿意做些打杂的活。没有基础的积累，哪来平地起的万丈高楼。不要看不起自己也不要看不起他人。三十年河东三十年河西，此一时彼一时。 ”中国的君子独善其身，这样就没有了尊严。这是因为尊严是属于个人的、不可压缩的空间，这块空间要靠自己来捍卫——捍卫的意思是指敢争、敢打官司、敢动手（勇斗歹徒）。我觉得人还是有点尊严的好，假如个人连个待的地方都没有，就无法为人做事，更不要说做别人的典范。“这句话同样适合我，该说该争该做的时候就应该大胆站出来，有一个男子汉的样子。要敢于亮剑！ 我现在还不太明白我的人生目标是什么，名利？我不知道。我只想做一个懂点道理的人。上班以后感觉也变得世俗化了，不经意间都会主动被动地谈及任何关于钱的话题。我对钱有一些兴趣，但不愿为之受罪。我不想把自己的下半生绑在房子上，虽然我也买不起。找不到人同我谈谈诗歌、文学、历史、足球，谈谈理想和爱情。但正如小波所言：”和我志趣相投的人总不会一个人都没有吧。“我也不顾影自怜了。 展望2018 最重要的事情当然是涨工资啦，哈哈。加油加油，为了涨工资可得好好奋斗； 如果能找一个离家近一点的工作当然是最好； 一个人总是孤独寂寞的，能找到一个能相互扶持的人当然最好； 改善自己的不同，提升自己的优点。扬长避短，向优秀的人多学习。 不成熟的想法 成都这地方什么都要争，连坐个公交地铁也得积极地抢位置，哎； 人太多，太拥挤，随便去哪都是拥挤的要命。但另一方面却是人越多机会越多； 原来工作才是一生的主题。但到底图个啥——名？利？ 上班以后认识的人也变少了，圈子也基本没什么了。曾经的同学们也各奔东西了； 我发觉任何一件事都是矛盾的。正面想是这样，反面想却又是那样，但都有道理。让我想起了一个故事，“一个农夫和一个老板在海边的对话。问：这么努力工作干嘛？答：为了以后能过更轻松的日子。那你看我现在不是挺轻松自在的吗？” 现在的自媒体为了流量真的是无所不用其极。各种大噱头的标题，完全不负责任的报道，只为吸引流量。到最后都不知道该相信谁，会不会被带节奏…； 一天24小时。8小时睡觉，8小时上班，3小时上下班，2小时吃饭及其他。It means that I only have 3 hours a day without Rest Day; 一个人只拥有此生此世是不够的，他还应该拥有诗意的世界。]]></content>
      <categories>
        <category>Zhang</category>
      </categories>
      <tags>
        <tag>2017</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[君子的尊严]]></title>
    <url>%2F2017%2F12%2F28%2F%E5%90%9B%E5%AD%90%E7%9A%84%E5%B0%8A%E4%B8%A5%2F</url>
    <content type="text"><![CDATA[笔者是个学究，待人也算谦和有礼，自以为算个君子——当然，实际上是不是，还要别人来评判。总的来说，君子是有文化有道德的人，是士人或称知识分子。按照中国的传统，君子是做人的典范。君子不言利。君子忍让不争。君子动口不动手。君子独善其身。这都是老辈子传下来的规矩，时至今日，以君子自居的人还是如此行事。我是宁做君子不做小人的，但我还是以为，君子身上有些缺点，不配作为人的典范；因为他太文弱、太窝囊、太受人欺。 君子既不肯与人争利，就要安于清贫。但有时不是钱的问题，是尊严的问题。前些时候在电视上看到北京的一位人大代表发言，说儿童医院的挂号费是一毛钱，公厕的收费是两毛钱。很显然，这样的收费标准有损医务工作的尊严。当然，发言的结尾是呼吁有关领导注意这个问题，有关领导也点点头说：是呀是呀，这个问题要重视。我总觉得这位代表太君子，没把话讲清楚——直截了当的说法是：我们要收两块钱。别人要是觉得太贵，那你就还个价来——这样三下五除二就切入了正题。这样说话比较能解决问题。 君子不与人争，就要受气。举例来说，我乘地铁时排队购票，总有些不三不四的人到前面加塞。说实在的，我有很多话要说：我排队，你为什么不排队？你忙，难道我就没有事？但是碍于君子的规范，讲不出口来。话憋在肚子里，难免要生气。有时气不过，就嚷嚷几句：排队，排队啊。这种表达方式不够清晰，人家也不知是在说他。正确的方式是：指住加塞者的鼻子，口齿清楚地说道：先生，大家都在排队，请你也排队。但这样一来，就陷入与人争论的境地，肯定不是君子了。 常在报纸上看到这样的消息：流氓横行不法，围观者如堵，无人上前制止。我敢断定，围观的都是君子，也很想制止，但怎么制止呢？难道上前和他打架吗？须知君子动口不动手啊。我知道英国有句俗话：绅士动拳头，小人动刀子。假如在场的是英国绅士，就可以上前用拳头打流氓了。 既然扯到了绅士，就可以多说几句。从前有个英国人到澳大利亚去旅行，过海关时，当地官员问他是干什么的。他答道：我是一个绅士。因为历史的原因，澳大利亚人不喜欢听到这句话，尤其不喜欢听到这句话从一个英国人嘴里说出来。那官员又问：我问你的职业是什么？英国人答道：职业就是绅士。难道你们这里没有绅士吗？这下澳大利亚人可火了，差点揍他，幸亏有人拉开了。在英美，说某人不是绅士，就是句骂人话。当然，在我们这里说谁不是君子，等于说他是小人，也是句骂人话。但君子和绅士不是一个概念。从字面上看，绅士（gentleman）是指温文有礼之人，其实远不止此。绅士要保持个人的荣誉和尊严，甚至可以说是这方面的专业户。坦白地说，他们有点狂傲自大。但也有一种好处：真正的绅士决不在危险面前止步。大战期间，英国绅士大批开赴前线为国捐躯，甚至死在了一般人前面。君子的标准里就不包括这一条。 中国的君子独善其身，这样就没有了尊严。这是因为尊严是属于个人的、不可压缩的空间，这块空间要靠自己来捍卫——捍卫的意思是指敢争、敢打官司、敢动手（勇斗歹徒）。我觉得人还是有点尊严的好，假如个人连个待的地方都没有，就无法为人做事，更不要说做别人的典范。]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>王小波</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人尊严]]></title>
    <url>%2F2017%2F12%2F28%2F%E4%B8%AA%E4%BA%BA%E5%B0%8A%E4%B8%A5%2F</url>
    <content type="text"><![CDATA[在国外时看到，人们对时事做出价值评判时，总是从两个独立的方面来进行：一个方面是国家或者社会的尊严，这像是时事的经线；另一个方面是个人的尊严，这像是时事的纬线。回到国内，一条纬线就像是没有，连尊严这个字眼也感到陌生了。提到尊严这个概念，我首先想到的英文词＂dignity＂，然后才想到相应的中文词。在英文中，这个词不仅有尊严之义，还有体面、身份的意思。尊严不但指人受到尊重，它还是人价值之所在。从上古到现代，数以亿万计的中国人里，没有几个人有过属于个人的尊严。举个大点的例子，中国历史上有过皇上对大臣施廷杖的事，无论是多大的官，一言不和，就可能受到如此当众羞辱，高官尚且如此，遑论百姓。除了皇上一人，没有一个人能有尊严。有一件最怪的事是，按照传统道德，挨皇帝的板子倒是一种光荣，文死谏嘛。说白了就是：无尊严就是有尊严。此话如有任何古怪之处，罪不在我。到了现代以后，人与人的关系、个人与集体的关系，仍有这种遗风──我们就不必细说文革中、文革前都发生过什么样的事情。到了现在，已经不用见官下跪，也不会在屁股上挨板子，但还是缺少个人的尊严。环境就是这样，公共场所的秩序就是这样，人对人的态度就是这样，不容你有任何自尊。 举个小点的例子，每到春运高潮，大家就会在传媒上看到一辆硬座车厢里挤了三四百人，厕所里也挤了十几人。谈到这件事，大家会说国家的铁路需要建设，说到铁路工人的工作难做，提到安全问题，提到所有的方面，就是不提这些民工这样挤在一起，好像一个团，完全没有了个人的尊严──仿佛这件事很不重要似的。当然，只要民工都在过年时回家，火车总是要挤的；谁也想不出好办法。但个人的尊严毕竟大受损害；这件事总该有人提一提才对。另一件事现在已是老生常谈，人走在街上感到内急，就不得不上公共厕所。一进去就觉得自己的尊严一点都没了。现在北京的公厕正在改观，这是因为外国人到了中国也会内急，所以北京的公厕已经臭名远扬。假如外国人不来，厕所就要臭下去；而且大街上改了，小胡同里还没有改。我认识的一位美国留学生说，有一次他在小胡同里内急，走进公厕撒了一泡尿，出来以后，猛然想到自己刚才满眼都对黄白之物，居然能站住了不倒，觉得自己很了不起，就急忙来告诉我。北京的某些街道很脏很乱，总要到某个国际会议时才能改观，这叫借某某会的东风。不光老百姓这样讲，领导上也这样讲。这话听起来很有点不对味。不雅的景象外人看了丢脸，没有外人时，自己住在里面也不体面──这后一点总是被人忘掉。 作为一个知识分子，我发现自己曾有一种特别的虚伪之处，虽然一句话说不清，但可以举些例子来说明。假如我看到火车上特别挤，就感慨一声道：这种事居然可以发生在中华人民共和国的土地上！假如我看到厕所特脏，又长叹一声：唉！北京市这是怎么搞的嘛！这其中有点幽默的成份，也有点当真。我的确觉得国家和政府的尊严受到了损失，并为此焦虑着。当然，我自己也想要点个人尊严，但以个人名义提出就过于直露，不够体面──言必称天下，不以个人面目出现，是知识分子的尊严所在。当然，现在我把这做为虚伪提出，已经自外于知识分子。但也有种好处，我找到了自己的个人面目。有关尊严问题，不必引经据典，我个人就是这么看。但中国忽视个人尊严，却不是我的新发现。从大智者到通俗作家，有不少人注意到一个有中国特色的现象：罗素说，中国文化里只重家族内的私德，不重社会的公德公益，这一点造成了很要命的景象；费孝通说，中国社会里有所谓＂差序格局＂，与己关系近的就关心，关系远的就不关心或少关心；结果有些事从来就没人关心。龙应台为这类事而愤怒过，三毛也大发过一通感慨。读者可能注意到了，所有指出这个现象的人，或则是外国人，或则曾在国外生活过，又回到了国内。没有这层关系的中国人，对此浑然不觉。笔者自己曾在外国居住四年，假如没有这种经历，恐怕也发不出这种议论──但这一点并不让我感到开心。环境脏乱的问题，火车拥挤的问题，社会秩序的问题，人们倒是看到了。但总从总体方面提出问题，讲国家的尊严、民族的尊严。其实这些事就发生在我们身边，削我们每个人的面子──对此能够浑然无觉，倒是咄咄怪事。 人有无尊严，有一个简单的判据，是看他被当作一个人还是一个东西来对待。这件事有点两重性，其一是别人把你当做人还是东西，是你尊严之所在。其二是你把自己看成人还是东西，也是你的尊严所在。挤火车和上公共厕所时，人只被当身体来看待。这里既有其一的成份，也有其二的成份；而且归根结蒂，和我们的文化传统有关。 说来也奇怪，中华礼仪之邦，一切尊严，都从整体和人与人的关系上定义，就是没有个人的位置。一个人不在单位里、不在家里，不代表国家、民族，单独存在时，居然不算一个人，就算是一块肉。这种算法当然是有问题。我的算法是：一个人独处荒岛而且谁也不代表，就像鲁滨孙那样，也有尊严，可以很好的活着。这就是说，个人是尊严的基本单位。知道了这一点，火车上太挤了之后，我就不会再挤进去而且浑然无觉。]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>王小波</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SaltStack]]></title>
    <url>%2F2017%2F12%2F25%2FSaltStack%2F</url>
    <content type="text"><![CDATA[参考： SaltStack官网：https://saltstack.com SaltStack文档：https://docs.saltstack.com/en/latest/topics SaltStack-GitHub：https://github.com/saltstack Salt-repo：https://repo.saltstack.com/ 环境： CentOS7_x64; Salt-2018.02 说明SaltStack是一种革命性的用速度(speed)取代复杂性(complexity)的基础设施(infrastucture)管理方法。 简单(Simple)，可以在几分钟内运行； 可伸缩性(Scalable)，足以管理数以万计的Server； 快速(Fast)，能在几秒内与各系统间进行通信。 You’ll learn how to: 安装和配置SaltStack； 在所有托管系统上远程执行命令(Remotely execute commands)； 设计、开发和部署系统配置； 使用Salt Reactor是基础设施自动化(automate)； 使用Salt Orchestration协调复杂管理操作。 Salt是建立在动态通信总线(dynamic communication bus)上的基础设施管理的一种新方法。Salt可以用于数据驱动(data-driven)业务，远程执行(remote execution)任何基础设施，配置管理(configuration management)任意应用堆栈… REMOTE EXECUTION; CONFIGURATION MANAGEMENT; EVENT-DRIVEN INFRASTRUCTURE; SALT ESSENTIALS. 安装Installation 如果是第一次设置环境，你应该在专用的管理服务器上安装Salt master，然后在每个使用Salt管理的系统上安装Salt minion。现在不需要担心你的系统架构(architecture)，你可以在以后轻易添加组件(componet)和修改配置(configuration)而不需要重新安装任何东西。 The general installation process is as follows: 安装Salt master，通过各平台说明安装或通过Salt bootstrap.sh脚本来安装； 确保你的Salt minion能够找到Salt master； 在想要管理的每个系统上安装Salt minion； 在Salt minion连接后接受Salt minion key。 在此之后，就可以运行一个简单命令，并从所有的Salt minion接收返回。 1234#salt &lt;minion-id&gt; &lt;cmd&gt;salt minion1 test.pingsalt * test.ping 快速安装Quick install 在绝大多数发行版本上，可以使用Salt Bootstrap脚本进行快速安装。 参考：Salt Bootstrap 1234567#wgetwget https://bootstrap.saltstack.com -O bootstrap-salt.shsh bootstrap-salt.sh#curlcurl -o bootstrap-salt.sh -L https://bootstrap.saltstack.comsh bootstrap-salt.sh 指定平台Platform-Specific Installation 选择发行版本安装 CentOS7repo: https://repo.saltstack.com/#rhel 1. 下载SaltStack-Repository进行安装： systemd和systemd-python是Salt必须的，在安装Salt前需装好。 12345678910111213#安装salt-repoyum install -y https://repo.saltstack.com/yum/redhat/salt-repo-latest-2.el7.noarch.rpmyum clean expire-cache#安装salt组件yum install -y salt-master salt-minion salt-ssh salt-syndic salt-cloud salt-api#开启systemctl start salt-master 2. 自建salt-repo： 123456789vim /etc/yum.repos.d/saltstack.repo[saltstack-repo]name=SaltStack repo for Cent0S7baseurl=https://repo.saltstack.com/yum/redhat/$releasever/$basearch/latestenalbed=1gpgcheck=1gpgkey=https://repo.saltstack.com/yum/redhat/$releasever/$basearch/latest/SALTSTACK-GPG-KEY.pub 初始化Initial Configuration 配置saltConfiguration Salt salt-master 的默认配置会为安装而工作，唯一要求是在salt-minion的配置文件中设置salt-master的位置。 salt-master默认的，salt-master配置文件位于/etc/salt/master，在all interfaces(0.0.0.0)上监听4505和4506端口。 123vim /etc/salt/masterinterface: 0.0.0.0 salt-minion默认，一个salt-minion会尝试连接到DNS名称为salt。如果salt-minion能够正确解析(resolve)这个名称，则可以不需要配置文件。如果DNS名称salt未能解析为salt-master的正确位置，那么可在/etc/salt/minion配置文件下重新定义salt。 1234567vim /etc/salt/minion#master: salt#如果是默认的salt,需要在本地hosts下解析salt#此处我们修改为salt-master的IP地址master: 192.168.1.9 修改配置文件后，请重启服务。 minion代理配置PROXY MINION CONFIGURATION A Proxy Minion模仿一个规律的行为和继承(inherit)他们的选项。类似地，它的配置文件存放于/etc/salt/proxy，proxy也将尝试连接DNS名为salt的主机。 除了salt-minion有规律的选型，proxy还有一些特定的选项。参考:Proxy minion 运行Salt以salt命令运行: 1234567891011121314151617salt-master#开启守护进程salt-master -d#systemdsystemctl start salt-mastersalt-minionsalt-minion -dsystemctl start salt-minion#日志信息salt-master --log-level=debug 以non-root运行salt 确保此用户有相应的权限； 可能需要修改相应目录的权限： /etc/salt /var/cache/salt /var/log/salt /var/run/salt 密钥识别Key Identity 在initial key交换之前，Salt会提供命令来验证(validate)salt-master和salt-minion的身份。验证身份有助于避免疏忽地连接到错误的salt-master，并且在建立初始化连接的阻止MiTM攻击。 Master Key Fingerprint复制master.pub的值，并将其作为salt-minion配置文件/etc/salt/minion中master_finger的值。 1234567891011121314#salt-key is used to manage Salt authentication keys#查看master的keysalt-key -F masterLocal Keys:master.pem: 60:87:25:6a:68:28:4a:bf:5e:87:ee:4f:3f:46:d4:8e:38:8b:58:d9:8a:f4:44:b6:64:67:d9:da:0f:5d:f3:b4master.pub: 46:52:c1:36:f2:6f:33:c0:72:a1:18:5e:99:36:04:ea:1a:9b:ea:e7:61:3b:d9:30:34:c1:f1:3b:65:08:f8:42#将公钥写入salt-minion配置文件#查看minion的finger#salt-key --finger &lt;minion_id&gt;salt-key --finger '192.168.1.7' Minion Key Fingerprint 123456#salt-call is used to execute module functions locally on a Salt Minion#查看minion key fingerprint#可在master上查看，比对两者是否相同salt-call --local key.finger 密钥管理Key Management Salt使用AES Encryption加密salt-master与salt-minion间的所有通信。这确保了发送到Minion的命令不会被篡改(tamper)，并保证了master与minion间是认证的和受信任的。 当命令发送到salt-minion之前，salt-minion的key必须要被salt-master所接受。 12#列出salt-master上已知的keyssalt-key -L 其中包含四项: Accepted Keys: Denied Keys: Unaccepted keys: Rejected keys: 让salt-master接收key，并允许salt-minion被salt-master控制 1234#-a 192.168.1.7, --accept=192.168.1.7#-A, --accept-allsalt-key -A 发送命令Sending Commands salt-master和salt-minion之间通过运行test.ping命令来证实(verified)。 123salt 192.168.1.7 test.pingsalt * test.ping 其它安装指南Additional Installation Guides Salt BootstrapSalt Bootstrap脚本允许用户在各种系统和版本上安装salt-minion和salt-master。shell脚本为bootstrap-salt.sh，运行一系列的检查来确定操作系统的类型和版本，然后通过适当的方法安装salt二进制文件。salt-bootstrap脚本安装运行salt的最小化安装包，如Git便不会安装。 Salt Bootstrap’s GitHub: https://github.com/saltstack/salt-bootstrap 栗子Satl Bootstrap脚本有多种可以传递的选项，以及获取引导脚本本身的方法。 1. 使用curl 12curl -o bootstrap-salt.sh -L https://bootstrap.saltstack.comsh bootstrap-salt.sh git develop 2. 使用wget 12wget -O bootstrap-salt.sh https://bootstrap.saltstack.comsh bootstrap-salt.sh 3. An Insecure one-liner 12345curl -L https://bootstrap.saltstack.com | shwget -O - https://bootstrap.saltstack.com | shcurl -L https://bootstrap.saltstack.com | sh -s -- git develop 4. cmd line options 12#查看帮助sh bootstrap-salt.sh -h 防火墙salt-master和salt-minion间的通信使用AES加密的ZeroMQ，它使用TCP的4505和4506端口，仅需要在salt-master上可访问就行。 下面概述了关于salt-master的防火墙规则： RHEL7/CENTOS7 12firewall-cmd --permanent --zone=&lt;zone&gt; --add-port=4505-4506/tcpfirewall-cmd --reload Preseed minion with accepted key某些情况下，在salt-master上接受minion-key之前等待salt-minion启动是不方便的。比如，你可能希望minion一上线(online)就引导。 有多种方式生成minion-key，下面是一般生成minion-key的四个步骤： 在master上生成key： 12#请给key取个名字salt-key --gen-keys=[key_name] 把公钥(publick key)添加到已接受的minion文件夹中: 公钥文件和 minion_id 有相同的名字是很有必要的，这就是Salt如何通过key与minions匹配。还有，由于不同操作系统或特定的master配置文件，pki 文件夹可能位于不同的位置。 1cp &lt;key_name&gt;.pub /etc/salt/pkimaster/minions/&lt;minion_id&gt; 分配minion-key： 对于minion来说，没有单一方法去得到密钥对，难点是找到一种安全的分配方法。 由于master已经接受了minion-key，因此分发私钥(private key)会有潜在的安全风险。 配置带key的minion： 你可能希望在启动salt-miniont daemon之前取得minion-key的位置。 12/etc/salt/pki/minion/minion.pem/etc/salt/pki/minion/minion.pub 以普通用户运行rootRunning salt as normal user tutorial 以普通用户(non-root)运行salt function 如果你不想使用root用户安装或运行salt，你可以在你的工作目录中创建一个虚拟根目录(virtual root dir)来配置它。salt system使用salt.syspathmodule来查找变量。 如果你运行salt-build，它会生成在: ./build/lib.linux-x86_64-2.7/salt/_syspaths.py； 运行python setup.py build命令来生成它； 复制生成的module到你的salt dir，cp ./build/lib.linux-x86_64-2.7/salt/_syspaths.py ./salt/_syspaths.py 修改它，并加入需要的变量和新路径： 1234567891011121314151617# you need to edit thisROOT_DIR = *your current dir* + '/salt/root'# you need to edit thisINSTALL_DIR = *location of source code*CONFIG_DIR = ROOT_DIR + '/etc/salt'CACHE_DIR = ROOT_DIR + '/var/cache/salt'SOCK_DIR = ROOT_DIR + '/var/run/salt'SRV_ROOT_DIR= ROOT_DIR + '/srv'BASE_FILE_ROOTS_DIR = ROOT_DIR + '/srv/salt'BASE_PILLAR_ROOTS_DIR = ROOT_DIR + '/srv/pillar'BASE_MASTER_ROOTS_DIR = ROOT_DIR + '/srv/salt-master'LOGS_DIR = ROOT_DIR + '/var/log/salt'PIDFILE_DIR = ROOT_DIR + '/var/run'CLOUD_DIR = INSTALL_DIR + '/cloud'BOOTSTRAP = CLOUD_DIR + '/deploy/bootstrap-salt.sh' 创建目录结构： 12mkdir -p root/etc/salt root/var/cache/run root/run/salt root/srvroot/srv/salt root/srv/pillar root/srv/salt-master root/var/log/salt root/var/run 填充配置文件： 123456cp -r conf/* /etc/salt/vi /etc/salt/masteruser: *your user name* 运行： 1PYTHONPATH=`pwd` scripts/salt-cloud minion独立运行Standalone minion 因为salt-minion包含了如此广泛的功能，它可以独立运行。一个独立的minion可以用来做很多事情: 在没有连接到master的系统上使用salt-call命令； 无主状态(masterless states)。 当以无主模式运行salt时，不要运行salt-minion daemon。否则，它将尝试连接到master并失败。salt-call命令是独立的，不需要salt-minion daemon。 minion配置有几个参考方法来设置不同的选项来配置masterless minion，salt-minion很容易通过配置文件(默认位于:/etc/salt/minion)进行配置。 告诉salt运行masterless salt-call命令用于在salt-minion本地运行模块功能，而不是在salt-master执行他们。通常，salt-call命令检查主机检索文件服务器和支柱数据，当时当运行standalone salt-call时，需要指示不要检查master的这些数据。为了指示minion不要查找master，需要在运行salt-call时设置file_client配置选项。默认情况下，file_client被设置为remote让minion知道将从master中收集文件服务器和支柱数据。当设置file_client为local时，minion将不会从master收集这些数据。 1234file_client: local#这样，salt-call命令将不会查找master#并认为本地系统拥有所有的文件文支柱资源 masterless运行状态 the state system在所有需要的文件都在minion本地，轻易地在没有salt-master的情况下运行。为了达到此效果，需要配置minion配置文件，以了解如何像master一样返回file_roots信息。 123file_roots: base: - /srv/salt 现在设置salt state tree, top file和SLS modules，就像在master上设置它们一样。将file_client设置为local，并且一个可用的state tree会调用state module中的function，将使用minion上的file_roots中的信息而不是master。 当在一个minion上创建一个state tree时，不需要语法或路径的更改。master上的SLS modules不需要进行任何修改就可以与minion一起工作。这就使得salt scrit不需要设置一个master就能轻易部署，并允许这些SLS modules随着部署发展而容易转移到master。 123456#以声明的状态可以执行salt-call state.apply#无需修改配置文件salt-call state.apply --local Salt无主模式Salt masterless quickstart 运行一个无主模式的minion可以允许你在单一主机上使用salt配置管理，而不用在另一台主机上调用master。在无主模式下运行salt时，请勿运行salt daemon。否则，它将尝试连接到master并失败。salt-call命令时独立的 bootstrap salt minion 12curl -L https://bootstrap.saltstack.com -o bootstrap_salt.shsudo sh bootstrap_salt.sh 告诉salt运行masterless模式在minion配置文件中配置此，表示不去寻找master，并假设本地系统拥有所有文件和资源。 123vim /etc/salt/minionfile_client: local 创建状态树(state tree) 创建top.sls文件 12345vim /srv/salt/top.slsbase: &apos;*&apos;: - webserver 创建webserver状态树 123456vim /srv/salt/webserver.sls#这是基于Debianapache: # ID declaration pkg: # state declaration - installed # function declaration salt-callsalt-call命令在minion本地运行远程执行功能，而不是在master执行。 1234#--local,在本地文件系统查找状态树salt-call --local state.apply#minion首先检查top.sls，然后应用webserver.sls 配置salt本节介绍如何配置用户访问，查看，存储作业结果，安全，疑难解答以及如何执行其它管理任务。 配置mastersalt系统的两个组件都有相应的配置文件: master，minion。 master配置项基础配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329#INTERFACE，默认值0.0.0.0interface: 0.0.0.0#IPv6，默认值Falseipv6: False#PUBLISH_PORT，默认值4505publish_port: 4505#MASTER_ID，默认值Nonemaster_id: Master#USER，默认值rootuser: root#ENALBE_SSH_MINIONS，默认值Falseenable_ssh_minions: True#RET_PORT，默认值4506#接收命令执行返回的端口ret_prot: 4506#PIDFILE，默认值/var/run/salt-master.pidpidfile: /var/run/salt-master.pid#ROOT_DIR，默认值/root_dir: /#CONF_FILE，默认值/etc/salt/masterconf_file: /etc/salt/master#PKI_DIR，默认值/etc/salt/pki/master#存储pki认证密钥的目录pki_dir: /etc/salt/pki/master#EXTENSION_MODULES，默认值/var/cache/salt/master/extmodsextension_modules: /root/salt_extmods#EXTMOD_WHITELIST/EXTMOD_BLACKLIST#有效的选项: modules, states, grains, renderers, returners, output, proxy, runners,#wheel, engines, queues, utils, pillar, sdb, cache, clouds, tops, roster, tokensextmod_whitelist: modules: - custom_module engines: - custom_engine pillars: []extmod_blacklist: modules: - specific_module#MODULE_DIRS，默认值[]module_dirs: - /var/cache/salt/minion/extmods#CACHEDIR，默认值/var/cache/salt/mastercachedir: /var/cache/salt/master#VERIFY_ENV，默认值True#在启动时验证并设置目录权限verify_env: True#KEEP_JOBS，默认值24#设置保留旧作业信息的小时数，0表示禁用缓存清理keep_jobs: 24#GATHER_JOB_TIMEOUT，默认10#客户端请求正在运行的作业信息是等待的秒数gather_job_timeout: 10#TIMEOUT，默认值5#salt命令和api默认超时值timeout: 5#LOOP_INTERVAL，默认值60#维护过程检查周期的秒数loop_interval: 60#OUTPUT，默认值nested#设置命令使用的默认输出器output: nested#OUTPUTTER_DIRS，默认值[]#salt输出器附加目录列表outputter_dirs: []#OUTPUT_FILE，默认值None#salt命令使用的默认输出文件output_file: /path/output/file#SHOW_TIMEOUT，默认值True#告诉client已超时的minionshow_timeout: True#SHOW_JID，默认值False#告诉client在工作发布时显示jidshow_jid: False#COLOR，默认值Truecolor: False#COLOR_THEME，默认值&quot;&quot;color_theme: /etc/salt/color_theme#CLI_SUMMARY，默认False#显示目标minion数量的摘要cli_summary: False#SOCK_DIR#Default: /var/run/salt/master#创建Unix socket的位置sock_dir: /var/run/salt/master#ENABLE_GPU_GRAINS#Default: True#启用GPU硬件数据#JOB_CACHE#Default: True#维护一个临时作业缓存job_cache: True#MINION_DATA_CACHE#Default: True#存储在master端的minion数据缓存minion_data_cache: True#CACHE#Default: localfs#缓存子系统模块用于minion数据缓存cache: consul#MEMCACHE_EXPIRE_SECONDS#Default: 0，禁用#内存缓存数据过期时间memcache_expire_seconds: 30#MEMCACHE_MAX_ITEMS#Default: 1024#缓存项限制memcache_max_items: 1024#MEMCACHE_FULL_CLEANUP#Default: False#如果缓存已满(超过max_literms)，则项目将清除其存储memcache_full_cleanup: True#MEMCACHE_DEBUG#Default: False#收集缓存统计信息并记入调试日志级别memcache_debug: True#EXT_JOB_CACHE#Default: &apos;&apos;#指定所有minion的默认returnerext_job_cache: redis#EVENT_RETURN#Default: &apos;&apos;#指定用于记录时间的returnerevent_return: - syslog - splunk#EVENT_RETURN_QUEUE#Default: 0#在繁忙的系统上，启用event_returns可能会给存储系统造成相当大的负载。事件可以在master使用队列排队，并以批处理方式使用单个事务存储多个事件event_return_queue: 0#EVENT_RETURN_WHITELIST#Default: []event_return_whitelist: - salt/master/a_tag - salt/run/*/ret#EVENT_RETURN_BLACKLIST#Default: []event_return_blacklist: - salt/master/not_this_tag - salt/wheel/*/ret#MAX_EVENT_SIZE#Default: 1048576，单位为Byte#传递非常大的事件可能导致minion消耗大量的内存max_event_size: 1048576#PING_ON_ROTATE#Default: False#告知master在AES密钥刷新后立即ping所有minionping_on_rotate: False#MASTER_JOB_CACHE#Default: local_cachemaster_job_cache: redis#ENFORCE_MINE_CACHE#Default: Falseenforce_mine_cache: False#MAX_MINIONS#Default: 0，表示不限制#master允许连接的最大minion数max_minions: 100#CON_CACHE#Default: False#为所有连接提供缓存con_cache: True#PRESENCE_EVENTS#Default: False#master周期性地寻找主动连接的minion#TRANSPORT#Default: zeromq#修改底层传输层transport: zeromq#TRANSPORT_OPTS#Default: &#123;&#125;#启用多个传输transport_opts: tcp: publish_port: 4605 ret_port: 4606 zeromq: []#MASTER_STATS#Default: False#MASTER_STATS_EVENT_ITER#Default: 60#SOCK_POOL_SIZE#Default: 1#为了避免将数据写入套接字是阻塞等待，启用salt应用程序的套接字池sock_pool_size: 15#IPC_MODE#Default: ipcipc_mode: ipc#TCP_MASTER_PUB_PORT#Default: 4512#ipc_mode的tcp端口tcp_master_pub_port: 4512#TCP_MASTER_PULL_PORT#Default: 4513#ipc_mode的tcp端口tcp_master_pull_port: 4513#TCP_MASTER_PUBLISH_PULL#Default: 4514tcp_master_publish_pull: 4514#TCP_MASTER_WORKERS#Default: 4515# mworkers连接到master的端口tcp_master_workers: 4515#AUTH_EVENTS#Default: Trueauth_events: True#MINION_DATA_CACHE_EVENTS#Default: Trueminion_data_cache_events: True salt-ssh配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990#ROSTER#Default: flat#定义默认ROSTER模块roster: cache#ROSTER_FILE#Default: /etc/salt/rosterroster_file: /root/roster#ROSTERS#Default: Nonerosters: - /etc/salt/roster.d - /opt/salt/some/more/rosters#SSH_PASSWD#Default: &apos;&apos;ssh_passwd: abc@123#SSH_PORT#Default: 22ssh_port: 22#SSH_SCAN_PORTS#Default: 22#多个值以逗号(,)分隔ssh_scan_ports: 22#SSH_SCAN_TIMEOUT#Default: 0.01ssh_scan_timeout: 0.01#SSH_SUDO#Default: Falsessh_sudo: False#SSH_TIMEOUT#Default: 60ssh_timeout: 60#SSH_USER#Default: rootssh_user: root#SSH_LOG_FILE#Default: /var/log/salt/sshssh_log_file: /var/log/salt/ssh#SSH_MINION_OPTS#Default: Nonessh_minion_opts: gpg_keydir: /root/gpg#SSH_USE_HOME_KEY#Default: False#使用~/.ssh/id_rsa对salt-ssh身份验证ssh_use_home_key: False#SSH_IDENTITIES_ONLY#Default: Falsessh_identities_only: False#SSH_LIST_NODEGROUPS#Default: &#123;&#125;ssh_list_nodegroups: groupA: minion1,minion2 groupB: minion1,minion3#THIN_EXTRA_MODS#Default: None#包含在salt thin中的附加模块#MIN_EXTRA_MODS#Default: None SECURITY 配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156#OPEN_MODE#Default: False#open mode关闭认证并通知master接受所有身份认证open_mode: False#AUTO_ACCEPT#Default: False#自动接收所有来自minion的public keyauto_accept: False#KEYSIZE#Default: 2048keysize: 2048#AUTOSIGN_TIMEOUT#Default: 120#AUTOSIGN_FILE#Default: not defined#此文件中指定的传入key将自动被接受#AUTOREJECT_FILE#Default: not defined#此文件中指定的传入key将自动被拒绝#AUTOSIGN_GRAINS_DIR#Default: not definedautosign_grains_dir: /etc/salt/autosign_grains#PERMISSIVE_PKI_ACCESS#Default: Falsepermissive_pki_access: False#PUBLISHER_ACL#Default: &#123;&#125;#允许master上用户执行特定模块publisher_acl: fred: - test.ping - pkg.*#PUBLISHER_ACL_BLACKLIST#Default: &#123;&#125;publisher_acl_blacklist: users: - root - &apos;^(?!sudo_).*$&apos; # all non sudo users modules: - cmd.* - test.echo#SUDO_ACL#Default: Falsesudo_acl: False#EXTERNAL_AUTH#Default: &#123;&#125;external_auth: pam: fred: - test.*#TOKEN_EXPIRE#Default: 43200(12h)token_expire: 43200#TOKEN_EXPIRE_USER_OVERRIDE#Default: Falsetoken_expire_user_override: pam: - fred - tom ldap: - gary#KEEP_ACL_IN_TOKEN#Default: Falsekeep_acl_in_token: False#EAUTH_ACL_MODULE#Default: &apos;&apos;eauth_acl_module: django#FILE_RECV#Default: False#允许minion将文件推送给masterfile_recv: False#FILE_RECV_MAX_SIZE#Default: 100file_recv_max_size: 100#MASTER_SIGN_PUBKEY#Default: False#使用master公钥的加密签名来签署master认证回复master_sign_pubkey: True#MASTER_SIGN_KEY_NAME#Default: master_sign#自定义签名密钥的名称master_sign_key_name: &lt;filename_without_suffix&gt;#MASTER_PUBKEY_SIGNATURE#Default: master_pubkey_signaturemaster_pubkey_signature: &lt;filename&gt;#MASTER_USE_PUBKEY_SIGNATURE#Default: Falsemaster_use_pubkey_signature: True#ROTATE_AES_KEY#Default: True#当salt-key删除一个minion-public时，轮询salt-master的AES-keyrotate_aes_key: True#PUBLISH_SESSION#Default: 86400#master上AES key轮询之间的秒数publish_session: Default: 86400#SSL#Default: None#TLS/SSL连接项ssl: keyfile: &lt;path_to_keyfile&gt; certfile: &lt;path_to_certfile&gt; ssl_version: PROTOCOL_TLSv1_2#ALLOW_MINION_KEY_REVOKE#Default: False#默认情况下，当minion key被移除时，master会删除它的缓存数据 大规模调整设置 MASTER LARGE SCALE TUNING SETTINGS 12345678910111213141516171819202122232425#MAX_OPEN_FILES#Default: 100000#请注意ulimitmax_open_files: 100000#WORKER_THREADS#Default: 5worker_threads: 5#PUB_HWM#Default: 1000pub_hwm: 1000#ZMQ_BACKLOG#Default: 1000#zeromq backlog的监听队列大小zmq_backlog: 1000#SALT_EVENT_PUB_HWM AND EVENT_PUBLISHER_PUB_HWMsalt_event_pub_hwm: 20000event_publisher_pub_hwm: 10000 模块管理 123456789101112131415#RUNNER_DIRS#Default: []runner_dirs: - /var/lib/salt/runners#UTILS_DIRS#Default: []utils_dirs: - /var/lib/salt/utils#CYTHON_ENABLE#Default: Falsecython_enable: False 状态系统设置STATE SYSTEM 123456789101112131415161718192021#STATE_TOP#Default: top.slsstate_top: top.sls#STATE_TOP_SALTENV#无默认值state_top_saltenv: dev#TOP_FILE_MERGING_STRATEGY#Default: mergetop_file_merging_strategy: same#ENV_ORDER#Default: []env_order: - base - dev - qa 文件服务器设置FILE SERVER 12 PILLAR 12 REACTOR 12 SYNDIC SERVER 12 PEER PUBLISH 12 LOGGING 1234567891011121314151617181920212223242526272829303132333435363738#LOG_FILE#Default: /var/log/salt/masterlog_file: /var/log/salt/master#LOG_LEVEL#Default: warninglog_level: notice#LOG_LEVEL_LOGFILE#Default: warninglog_level_logfile: warning#LOG_DATEFMT#Default: %H:%M:%Slog_datefmt: &apos;%H:%M:%S&apos;#LOG_DATEFMT_LOGFILE#Default: %Y-%m-%d %H:%M:%Slog_datefmt_logfile: &apos;%Y-%m-%d %H:%M:%S&apos;#LOG_FMT_CONSOLE#Default: [%(levelname)-8s] %(message)slog_fmt_console: &apos;%(colorlevel)s %(colormsg)s&apos;log_fmt_console: &apos;[%(levelname)-8s] %(message)s&apos;#LOG_FMT_LOGFILE#Default: %(asctime)s,%(msecs)03d [%(name)-17s][%(levelname)-8s] %(message)slog_fmt_logfile: &apos;%(asctime)s,%(msecs)03d [%(name)-17s][%(levelname)-8s] %(message)s&apos;#LOG_GRANULAR_LEVELS#Default: &#123;&#125; NODE GROUPS雨荨minion进行逻辑分组 12345678910#NODE GROUPS#Default: &#123;&#125;nodegroups: group1: &apos;L@foo.domain.com,bar.domain.com,baz.domain.com or bl*.domain.com&apos; group2: &apos;G@os:Debian and foo.domain.com&apos; group3: &apos;G@os:Debian and N@group1&apos; group4: - &apos;G@foo:bar&apos; - &apos;or&apos; - &apos;G@foo:baz&apos; RANGE CLUSTER 123#RANGE_SERVER#Default: &apos;range:80&apos;range_server: range:80 INCLUDE CONFIGURATION 123456789101112131415161718#DEFAULT_INCLUDE#Default: master.d/*.conf#INCLUDE#Default: not defined# Include files from a master.d directory in the same# directory as the master config fileinclude: master.d/*# Include a single extra file into the configurationinclude: /etc/roles/webserver# Include several files and the master.d directoryinclude: - extra_config - master.d/* - /etc/roles/webserver KEEPALIVE 1234567891011121314151617#TCP_KEEPALIVE#Default: Truetcp_keepalive: True#TCP_KEEPALIVE_CNT#Default: -1#Sets the ZeroMQ TCP keepalive counttcp_keepalive_cnt: -1#TCP_KEEPALIVE_IDLE#Default: 300#TCP_KEEPALIVE_INTVL#Default: -1 minion配置基础配置 123456789101112131415#MASTER#Default: saltmaster: salt#MASTER:PORT SYNTAX#master: localhost:1234#master: &apos;[2001:db8:85a3:8d3:1319:8a2e:370:7348]:1234&apos;#LIST OF MASTERS SYNTAX#需启用multi-master模式master: - address1 - address2master_type: failover EXECUTION MODULE 12 TOP FILE 12 STATE 12 FILE DIRECTORY 12 PILLAR 12 SECURITY 12 REACTOR 12 THREAD 12 LOGGING 12 INCLUDE 123456#DEFAULT_INCLUDE#Default: minion.d/*.conf#INCLUDE#Default: not defined KEEPALIVE 12 FROZEN BUILD UPDATE 12 proxy minion配置/etc/salt/minion 12345678910111213141516171819202122232425262728293031323334353637383940#ADD_PROXYMODULE_TO_OPTS#Default: Falseadd_proxymodule_to_opts: True#PROXY_MERGE_GRAINS_IN_MODULE#Default: True#PROXY_KEEP_ALIVE#Default: True#死亡时是否重启与远程设备的连接proxy_keep_alive: False#PROXY_KEEP_ALIVE_INTERVA#Default: 1(min)#keepalive检查频率proxy_keep_alive_interval: 5#PROXY_ALWAYS_ALIVE#Default: Trueproxy_always_alive: False#PROXY_MERGE_PILLAR_IN_OPTS#Default: False#PROXY_DEEP_MERGE_PILLAR_IN_OPTS#Default: False#PROXY_MERGE_PILLAR_IN_OPTS_STRATEGY#Default: smart#PROXY_MINES_PILLAR#Default: True minion blackout配置当一个minion处于blackout mode时，所有远程执行命令都被禁用。 minion blackout mode通过pillar key——minion_blackout进行配置。如果此为True，则minion将拒绝除saltutil.refresh_pillar命令外的所有传入命令。它也支持whitelist: 123minion_blackout_whitelist: - test.ping - pillar.get 访问控制系统ACCESS CONTROL SYSTEM]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>SaltStack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构]]></title>
    <url>%2F2017%2F12%2F11%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[数据结构在计算机科学中，数据结构(data structure)是计算机中存储、组织数据的方式。大多数数据结构都有数列、记录、可辨识联合、引用等基本类型构成。 数据结构意味着结构和封装，一个数据结构可被视为两个函数之间的接口，或是由数据类型联合组成的存储内容的访问方法和封装。数据结构可通过程序语言所提供的数据类型、引用及其它操作加以实现。不同种类的数据结构适合不同种类的应用，部分数据结构甚至是为了解决特定问题而设计。一个涉及良好的数据结构，应该尽可能使用较少的时间与空间资源的前提下，支持各种程序运行。 正确选择数据结构可以提高算法的效率，在计算机程序设计里，选择适当的数据结构是一项重要工作。 常见数据结构 数组(Array); 栈(Stack): 后进先出，线性表； 队列(Queue): 先进先出，线性表； 链表(Linked List): 每个节点包括两部分，一个存储数据元素的数据域，另一个存储下一个节点地址的指针域； 树(Tree)； 图(Graph)； 堆(Heap): 一种动态树形结构； 散列表(Hash)； 数组(Array)数组数据结构，是由相同类型的元素的集合所组成，分配一块连续的内存来存储。利用数组元素的索引(index)可计算出元素对应存储地址。 数组有 一维数组、二维数组、多维数组、可变长数组…。 栈(Stack)堆栈又称为栈，是计算机科学中一种特殊的串列形式的抽象资料类别。其特殊之处在于只能允许在链接串列或阵列的一端(栈顶指标:top)，进行加入数据(push)和取出数据(pop)。 由于栈数据结构只允许在一端进行操作，因为按照后进先出(LIFO, last-in-first-out)的原理运行。 队列(Queue)队列，是先进先出(FIFO, first-in-first-out)的线性表。在具体应用中通常用链表或数组来实现。队列只允许在后端(Rear)进行插入操作，在前端(Front)进行删除操作。 链表(Linked List)链表是一种线性表，但并不按线性的顺序存储数据，而是在每一个节点里存到下一个节点的指针(Pointer)。由于不必须按顺序存储，链表再插入的时候可以达到 O(1)的时间复杂度，比另一种线性表顺序表快得多。但查找一个节点或访问特定节点则需要 O(n)的时间，而顺序表相应的时间复杂度分别是 O(logn)和O(1)。 是用链表结构可以克服数组链表需要预先知道数据大小的缺点，链表可以充分利用计算机内存空间，实现灵活的内存动态管理。但是链表失去了数组随机读取的优点，同时链表由于增加了节点的指针域，空间开销比较大。 链表有单向链表、双向链表、循环链表…。链表用来构建许多其它数据结构，如栈，队列和他们的派生。 树(Tree)树是一种抽象数据类型，用来模拟具有树状结构性质的数据集合。 树有有序树、无序树（二叉树，B树，霍夫曼树）。 图(Graph)在数学上，一个图是表示物体与物体之间的关系的方法，是图论的基本研究对象。 图有：有向图、无向图、简单图、多重图。 堆(Heap)堆是计算机科学中一类特殊的数据结构的统称。堆通常是一个可以被看做一棵树的数组对象。在队列中，调度程序反复提取队列中的第一个作业并运行，因为实际情况中某些时间较短的任务将等待很长时间才能结束，或者某些不短小，但具有重要性的作业，同样应当具有优先权。堆即为解决此类问题设计的一种数据结构。 堆常用于排序，这种算法称作堆排序。 散列表(Hash)散列表也叫哈希表，是根据键(key)而直接访问在内存存储位置的数据结构。它通过计算一个关于键值的函数，将所需查询的数据映射到表中的一个位置来访问记录，这加快了查找速度。这种映射函数称为散列函数，存放记录的数组称为散列表。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB]]></title>
    <url>%2F2017%2F12%2F11%2FMongoDB%2F</url>
    <content type="text"><![CDATA[参考： MongoDB官方文档 MongoDB中文文档 https://zh.wikipedia.org/wiki/MongoDB http://www.ywnds.com/?p=5635 https://www.centos.bz/2017/08/mongodb-secure-intro-user-auth/ http://www.03sec.com/3176.shtml http://www.ywnds.com/?p=6502 http://wiki.jikexueyuan.com/project/the-little-mongodb-book/ 环境： CentOS7_x64； MongoDB3.4； NoSQLNoSQL(Not Only SQL)是对不同于传统的关系型数据库的数据库管理系统(DBMS)的统称。NoSQL不使用SQL作为查询语言，其数据结构可以不需要固定的表格模式，有横向可扩展性的特征。NoSQL用于超大规模数据的存储，这些类型的数据存储不需要固定的模式，无序多余操作就可以横向扩展。 关系型数据库的典型实现主要被调整用于执行规模小而读写频繁，或大批量极少写访问的事务。当代典型的关系型数据库在一些数据敏感的应用中表现了糟糕的性能。例如： 为巨量文档创建索引 高流量网站的网页服务 发送流媒体 NoSQL数据库分类： 类型 栗子 特点 文档存储 MongoDB 用类似json的格式存储，存储的内容是文档型的。这样就有机会对某些字段建立索引，实现关系数据库的某些功能 图形关系存储 Neo4j 图形关系的最佳存储 键-值(key-value)存储 最终一致性的键-值存储 架构性键-值存储 xxx 主机式服务 key-value硬盘存储 key-value RAM存储 MemcacheDB Redis 多数据库 OpenQM xxx 时序型数据库 Graphite xxx 对象数据库 ObjecStore 通过类似面向对象语言的语法操作数据库，通过对象的方式存取数据 列存储 HBase 顾名思义，按列存储数据。方便存储结构化和半结构化数据，方便做数据压缩，针对某一列或某几列的查询有很大的IO优势。 MongoDB简介 MongoDB(https://www.mongodb.com/)，是一种文档导向的数据库管理系统，由C++撰写而成，以此来解决应用程序开发社区中的大量现实问题。它是一种NoSQL。MongoDB支持的数据结构非常松散，是类似于json的bson格式，因此可以存储比较复杂的数据类型。MongoDB是一个开源文档数据库，提供高性能，高可用性和自动扩展。 预备知识： MongoDB中的database有和数据库一样的概念。一个MongoDB实例中，可以有零个或多个数据库，每个都作为一个高等容器，用于存储数据； MongoDB数据库中有零个或多个collections(集合)。集合类似于传统意义上的table(表)； MongoDB的集合是由零个或多个documents(文档)组成。文档类似于row(行)； MongoDB的文档由零个或多个fields(字段)组成。字段类似于columns(列)； MongoDB中Indexes(索引)扮演的角色与RDMS中一样； MongoDB中的Cursors(游标)很重要，当你向MongoDB取数据的时候，它会给你返回一个结果集的指针而不是真正的数据，这个指针我们叫它游标。我们可以用游标做任何事情，比如计数或跨行之类。 MongoDB特点不如这样认为，MongoDB是关系型数据库的一个代替案。比如用Lucene作为关系型数据库的全文检索索引的加强，或者是Redis作为持久性key-value存储。 无模式(Flexible Schema)：它不需要一个固定的模式，这使得他们比传统的数据库表要灵活更多。 写操作(Writes)：MongoDB可以胜任的一个特殊角色是在日志领域。有两点使得MongoDB的写操作非常快： 可以选择发送了写操作之后立刻返回，而无需等到操作完成； 可以控制数据持久性的写行为。 高性能(High Performance)：MongoDB提供了高性能的数据持久性。尤其是： 对嵌入式数据模型的支持减少了数据库系统上的I/O活动； 索引支持更快的查询，并且可以包含来自嵌入式文档和数组的键。 高可用(High Availability)：MongoDB的复制工具，称为副本集。提供：自动故障转移和数据冗余。 持久性(Durability)：在MongoDB中，日志(Journaling)是默认启动的，该功能允许快速恢复服务器，比如遭遇到了服务器奔溃或停电的问题。 丰富的查询语言(Rich Query Language)：MongoDB支持丰富的查询语言来支持读写操作(CRUD)，数据聚合(Data Aggregation)，全文搜索(Text Search)。 水平可伸缩性(Horizontal Scalability)：MongoDB提供了横向可伸缩性。 支持多个存储引擎(Support for Multiple Storage Engines)：在MongoDB3.2以后默认引擎为: WiredTiger Storage Engine，允许第三方为MongoDB开发存储引擎。 database和collectionMongoDB stores BSON documents. databasesIn MongoDB,databases hold collections of documents.如果一个数据库不存在，当你第一次存储数据时，MongoDB会自动创建数据库。这意味着可以切换到不存在的数据库。 默认情况下，集合不要求其文档具有相同的模式；文档不要求具有相同的字段集；字段的数据类型在集合的文档间可以有所不同。 123456789#select a dbuse &lt;db&gt;#create a dbuse newdbdb.newcoll.insert(&#123;name:'zhang'&#125;)db.newcoll.insert(&#123;filed01:'filed01', filed02:'filed02', filed03:'filed03', filed04:'filed04'&#125;)db.newcoll.insert(&#123;groups: ['A', 'B', 'C']&#125;)db.newcoll.find().pretty() collectionMongoDB stores documents in collections.collection类似于关系型数据库中的table。 12db.coll02.insert(&#123;x:1&#125;)db.coll03.createIndex(&#123;y:1&#125;) 显式创建(explicit creation)MongoDB提供了db.createCollection()方法来显式创建一个附带各种选项的集合。如设置document最大大小，文件验证规则等选项。如果不需要指定这些选项，就不需要使用显式创建集合，而直接向集合中插入数据即可。修改collection选项，使用collMod方法。 视图(View)视图的定义是公开的，视图的解释操作将包括定义视图的管道。因此，避免直接引用视图定义中的敏感字段和值。 创建/删除视图： 12345678910db.runCommand(&#123; crete: &lt;view&gt;, viewOn: &lt;source&gt;, pipeline: &lt;pipeline&gt;&#125;)db.createView(&lt;view&gt;, &lt;source&gt;, &lt;pipeline&gt;, &lt;collation&gt;)db.collection.drop() 视图行为： 视图存在以下行为： 视图只读，视图上的写操作将会出错； 视图使用底层集合的索引； 如果视图的基础集合被分割，视图也被认为可分割； 不能重命名视图； 视图上的字符串使用视图的默认排序规则。 限制集限制集是固定大小的集合支持基于文档插入顺序的高吞吐率的插入、检索、删除操作。限制集工作在某种程度上类似于循环缓冲区：一旦一个文档填满分配给它的空间，它将通过在限制集中重写老文档来给新文档让出空间。 行为插入顺序限制集合能够保留插入顺序。因此，查询并不需要索引来保证以插入顺序来返回文档。减少了索引的消耗，限制集可以支持更高的插入吞吐量。 最旧文档的自动删除为了给新文档腾出空间，再不需要脚本或显示删除操作的前提下，限制集自动删除集合中最旧的文档。 例如replication set中的oplog.rs集合。考虑潜在用于集合封顶的用例： 存储高容量系统生成的日志信息。没有索引的情况下向限制集中插入文档的速度接近于直接在文件系统中写日志的速度； 在限制集中缓存少量的数据。 _id索引限制集合有一个_id字段并且默认在_id字段上创建索引。 限制和建议更新更新限制集中的文档，创建一个索引保证这些更新操作不需要进行集合扫描。 文档大小一个更新或替换操作改变了文档大小，操作将会失败。 文档删除不能从一个限制集中删除文档！为了从一个集合中删除所有文档，使用drop()方法来删除集合然后重新创建限制集。 分片不能对限制集分片。 查询效率用自然顺序监视限制集中大部分最近插入的文档。 程序创建一个限制集必须使用db.createCollection()方法创建限制集。且必须指定以字节为单位的最大集合大小。MongoDB将会预先分配集合。另外，可为限制集指定最大文档数据，用max字段。 大小参数是必须的。MongoDB会在达到最大限制前删除旧的文件。 1234567use &lt;db&gt;#限制集大小db.createCollection("log", &#123;capped: true, size: 1000000&#125;)#限制集和文档大小db.createCollection("log", &#123;capped: true, size: 5242880, max: 5000&#125;) 查询一个限制集如果没有对限制集指定排序，则MongoDB的结果顺序和插入顺序相同。 检查一个集合是否是限制集isCapped()方法 123db.collection.isCapped()#db.coll01.isCapped()#false 将集合转换为限制集convertToCapped()方法 123db.runCommand(&#123;"covertToCapped": "coll01", size: 1000000&#125;);#db.coll01.isCapped()#true 在规定的时间周期之后将自动移除数据通过设置MongoDB的TTL时集合中的数据过期。TTL collection与限制集不兼容。 Tailable游标类似于Unix中的taif -f documentMongoDB存储数据记录为BSON文档。BSON是JSON文档的二进制表示，因此它包含比JSON更多的数据类型。 document structureMongoDB字段由key-value对组成。字段值可以是任一BSON数据类型，包括其他文档，数组，阵列。 1234567891011121314151617181920212223&#123; filed1: value1; filed2: value2; ... filedN: valueN&#125;#data typevar mydoc =&#123; _id: ObjectId("5099803df3f4948bd2f98391"), name: &#123; first: "Alan", last: "Turing" &#125;, birth: new Date('Jun 23, 1912'), death: new Date('Jun 07, 1954'), contribs: [ "Turing machine", "Turing test", "Turingery" ], views : NumberLong(1250000)&#125;_id是ObjectID；name是嵌入式文档；birth是日期类型；contribs是字符串数组；view是NumberLong类型。 字段名(field name)字段名是字符串。document对field name有以下限制: 字段名称_id保留用作主键(primary key)，它的值在collection中必须唯一，不可变。它的类型可以是数组外的任何类型； 字段名称不能以$字符开头； 字段名称不能包含.字符； 字段名称不能包含null字符。 BSON documents 可能有多个字段名称相同的字段。然而，大多数的MongoDB Interface，MongoDB结构（如hash表），并不支持重复字段名称。如果需要操作具有多个相同名称字段的文档，请参考 mongo driver。 一些由内部MongoDB进程创建的documents可能会有重复的字段，但是没有MongoDB进程会向一个已经存在的user document中添加重复字段。 字段值限制(field value limit)For indexed collections，indexed fields的值有一个最大索引值长度限制(maximum index key length)。 圆点表示法(dot notation)MongoDB使用圆点表示法来访问数组中的元素，访问嵌套文档中的字段。 数组(array)通过基于0的索引位置来指定或访问数组中的元素。 123456789&lt;array&gt;.&lt;index&gt;&#123; contribs: [ 'Turing machine', 'Turing test', 'Turingery' ]&#125;#contribs.0 == 'Turing machine'#contribs.1 == 'Turing test'#contribs.2 == 'Turingery' 嵌套文档(embedded documents)通过圆点表示法来指定或访问嵌套文档中的字段。 123456789&lt;embedded document&gt;.&lt;field&gt;&#123; name: &#123; first: 'AAA', last: 'ZZZ'&#125;, contact: &#123; phone: &#123; type: 'cell', number: '1-22-333' &#125;&#125;&#125;#name.first == 'AAA'#contact.phone.number == '1-22-333' 文档限制(document limitation)文档大小限制(size limit)BSON document最大size为：16MB。 最大document size确保一个单一document不能使用过量的RAM，或是传输期间的过量带宽。MongoDB提供了GridFS API，用来保存超过最大size的文档。 文档字段序列(field order)MongoDB用write operation来作为document的序列，除了一下情况： _id字段总是document中的第一个field； 包含重命名的update操作，会导致document中的field重新排序。 _id字段在MongoDB中，每个保存在collection中的document都要求一个唯一的_id，用以担任主键(primary key)。如果向document中insert数据是忽略的_id字段，则MongoDB driver会为_id字段自动生成一个ObjectID。 1234567#默认生成_iddb.coll01.insert(&#123;name: 'zhang', sex: 'man', hobby: 'woman'&#125;)# "_id" : ObjectId("5a32166ebf2c986e8106f891")#自定义_iddb.coll01.insert(&#123;_id:'ZhangCustomDefine', name:'zhang', sex: 'man', arr: [0, 1, 2, 3], emmdoc: &#123;emm01:'Emm01', emm02: 'Emm02', emm03: 'Emmo3'&#125;&#125;)#"_id" : "ZhangCustomDefine" _id字段有以下行为和约束： 默认情况下，MongoDB在collection创建document时，会创建一个唯一的_id作为索引； _id字段总是document中的第一个字段。如果server接受的document中_id不在第一个字段，那么Server会移动_id到第一个字段； _id字段的数据类型除了数组外的任意BSON 数据类型； 不要存储BSON正则表达式的类型在_id字段中。 _id字段值的常用选项： 使用ObjectId； 使用了自然唯一的标识符，节省了空间并避免了额外的索引； 生成一个自动递增的数字； 在应用程序代码中生成UUID； 文档结构的其他用途查询过滤文档(query filter)使用:表达式来指定条件。 12345&#123; &lt;field1&gt;: &lt;value1&gt; &lt;field2&gt;: &lt;value2&gt; ...&#125; 更新特定文档(update)使用db.collection.update()操作更新数据。 BSON类型BSON是一个用来存储document和MongoDB进行远程调用的二进制序列化格式。BSON支持以下数据类型作为文档中的值。每个数据类型都有一个相应的数字和字符串别名，可与$type操作符一起使用，以便按照bson类型查询文档。 Type Number Alias double 1 “double” 字符串 2 “string” 对象 3 “object” 数组 4 “array” 二进制数据 5 “binData” 未定义 6 “undefined” ObjectId 7 “objectId” Boolean 8 “bool” 日期 9 “date” 空 10 “null” 正则表达式 11 “regex” DBPointer 12 “dbPointer” JavaScript 13 “javascript” 符号 14 “symbol” JavaScript(带范围) 15 “javascriptWithScope” 32位整数 16 “int” 时间戳 17 “timestamp” 64位整数 18 “long” Decimal128 19 “decimal” Min key -1 “minKey” Max key 127 — 如果你想要将BSON转换为JSON，参考Extended JSON。 ObjectIdObjcetIds are small, likely unique, fast to generate, and ordered.ObjectIds由12个字节组成，其中前4个字节是反映ObjectId创建的时间戳(timestamp)。 一个4字节的值，代表从Unix纪元开始的秒数； 一个3字节的机器标识符； 日期对象排在时间戳对象之前； MongoDB在比较过程中，会把一些类型看成相等。 栗子：{ &quot;_id&quot; : ObjectId(&quot;5a33354068b6c5e5fb6f213f&quot;), &quot;name&quot; : &quot;ZHANG&quot; }。 在mongo shell中，可以访问ObjectId的创建时间，使用ObjectId.getTimestamp()方法。在_id字段中存储的ObjectId值的排序，大致相当于按其创建时间排序。ObjectId的值顺序与生成时间之间并不严格。 字符串BSON字符串都是UTF-8编码。一般来说，每种编程语言的驱动程序在序列化和反序列化BSON的时候，都会从语言的字符串形式转化为UTF-8。这就使得使用BSON字符串简单存储大多数国际字符变为可能。 时间戳BSON有一个特殊的时间戳类型用于MongoDB内部使用，与普通的日期类型无关。而在应用开发中可使用BSON日期类型。时间戳值是一个64位的值： 前32位是与Unix纪元相差的秒数，后32位是在某秒总操作的一个递增的序列数。 在MongoDB复制集中，oplog有一个ts字段。这个字段的值使用BSON时间戳表示了操作时间。 1234db.coll02.insert( &#123; ts: new Timestamp() &#125; )db.coll02.find()#&#123; "_id" : ObjectId("5a333e3f68b6c5e5fb6f2141"), "ts" : Timestamp(1513307711, 1) &#125; 日期BSON日期是一个64位整数，表示利当前Unix新纪元(1970.01.01)的毫秒数，可到未来的2.9亿年。BSON日期类型是有符号的，负数表示1970年之前的时间。 123456var date1 = new Date()var date2 = ISODate()#date1#date2#ISODate(&quot;2017-12-15T03:28:08.227Z&quot;) MongoDB Extended JSONJSON只能表示BSON类型的一个子集。为了保留类型信息，MongoDB对JSON格式添加了如下扩展性： Strict mode： Any JSON parser can parse these strict mode representations as key/value pairs; mongo shell mode： The MongoDB internal JSON parser and the mongo shell can parse this mode. 多种数据类型的表示取决于JSON解析的上下文！ 解析器(parser)和支持的格式(format)Input in Strict mode如下可在严格模式下被解析并识别类型信息。 REST Interface; mongo import; –query; MongoDB Compass. Input in mongo shell mode如下可在严格模式下被解析并识别类型信息。 REST Interface; mongo import; --query; MongoDB Compass Output in Strict modemongoexport, REST, HTTP Interfaces. Output in mongo shell modebsondump BSON数据类型和关联表示Binary Strict mode mongo shell mode { “$binary”: ““, “$type”: ““ } BinData ( , ) 12&lt;bindata&gt;是二进制base64表示；&lt;t&gt;是由单字节的数据类型表示。 Date Strict mode mongo shell mode { “$date”: ““ } new Date ( ) 12In Strict mode, &lt;date&gt;是 ISO-8601的日期格式的时区字段，类型如**YYYY-MM-DDTHH:mm:ss.mm&lt;+/-offset&gt;;MongoDb JSON解析器目前暂不支持载入ISO-8601日期类型。 Timestamp Strict mode mongo shell mode { “$timestamp” ; { “t”: , “i” } } Timestamp( , ) 12&lt;t&gt;是32位无符号整数的JSON表现形式；&lt;i&gt;是增量的32位无符号整数。 Regular Expression Strict mode mongo shell mode { “$regex”: , “$options”: ““ } // 1234&lt;sRegex&gt;是有效地JSON字符串；&lt;jRegex&gt;是一个可能包含有效的JSON字符和未转义的双引号(&quot;)，但可能不包括未转义的斜杠(/)字符；&lt;sOptions&gt;是一个正则表达式选项；&lt;jOptions&gt;是一个只能包含字符&quot;g&quot;, &quot;i&quot;, &quot;m&quot;, &quot;s&quot;的字符串。 OID Strict mode mongo shell mode { “$oid”: ““ } ObjectId( ““ ) &lt;id&gt;是一个24字符的十六进制(hexadecimal)字符串 DB Reference strict mode mongo shell mode { “$ref”: ““, “$id”: ““ } DBRef(““, ““) 12&lt;name&gt;是一个有效的JSON字符；&lt;id&gt;是任一extended JSON type。 Undefined Type strict mode mongo shell mode { “$undefined”: true } undefined MinKey/MaxKey strict mode mongo shell mode { “$minkey”: 1 } MinKey { “$maxkey”: 1 } MaxKey NumberLong strict mode mongo shell mode { “$numberLong”: ““ } NumberLong( ““ ) 12Number是一个64位有符号整数。必须使用&quot;，否则它将被解释为浮点数，从而导致损失精度；db.json.insert&#123;&#123; longquoted: NumberLong(&quot;12345678901234345&quot;) &#125;) MongoDB安装参考: https://docs.mongodb.com/manual/administration/install-on-linux/; https://docs.mongodb.com/manual/tutorial/install-mongodb-on-red-hat/; MongoDB有社区版(Community)和企业版(Enterprise)。社区版免费，企业版在商业方面收费。 MongoDB在仓库中提供官方支持的包，包含以下软件包： Package Description monogdb-org 将自动安装下面四个组件包 mongodb-org-server 包含mongod守护进程和相关配置和init脚本 mongodb-org-mongos 包含mongos守护进程 mongodb-org-shell 包含mongo-shell mongodb-org-tools 包含相关MongoDB工具，如mongoimport,mongoexport,mongodump,mongorestore… mongodb-org-server包提供了一个/etc/mongod.conf配置文件来开始和初始化mongod。默认配置文件默认bind_ip为 127.0.0.1，当你有需要和副本集时请修改它。 自建mongodb.repo仓库安装仓库地址：https://repo.mongodb.org 12345678910111213vim /etc/yum.repos.d/mongodb34.repo#编辑仓库[mongodb34]name=MongoDB34 Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.4/x86_64/gpgcheck=0enabled=1#安装mongodbyum install -y mongodb-org 下载rpm包安装1234567cd /root/mongodbwget https://repo.mongodb.org/yum/redhat/7/mongodb-org/3.4/x86_64/RPMS/mongodb-org-3.4.10-1.el7.x86_64.rpmwget https://repo.mongodb.org/yum/redhat/7/mongodb-org/3.4/x86_64/RPMS/mongodb-xxx-3.4.10-1.el7.x86_64.rpm#共五个包yum ./mongo-org* 源码安装1234567wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-3.6.0.tgztar -axvf mongodb-linux-x86_64-rhel70-3.6.0.tgz -C ./#默认路径/usr/localmake &amp;&amp; make install 开启mongodb123456789101112131415161718192021#默认启动方式systemctl start mongod#指定配置文件启动#注意修改配置文件里面的某些路径和名称，不然会和默认配置文件冲突mongod -f /etc/mongo_27018.confmongod -f /etc/mongo_27019.conf``&lt;br&gt;## 卸载mongodb```shsystemctl stop mongodyum remove $(rpm -qa | grep mongodb-org)rm -rf /var/log/mongodbrm -rf /var/dbpath/mongo mongodb异常关闭后12345#首先查看日志文件tail /var/log/mongodb/mongod.log#删除rm /var/run/mongodb/mongod.pid /var/db/mongodb/mongod.lock MongoDB配置文件MongoDB的配置文件格式使用了YAML格式。YAML维基百科，Yet Another Markup Language。强调以数据为中心，而不是标记语言为重点，用方向缩略语重命名。 默认配置文件/etc/mongod.conf 的几个大块： 123456789101112131415161718192021systemLog: #日志storage: #存储processManagement: #进程管理net: #网络security: #安全operationProfiling: #性能分析器replication: #主从复制sharding: #架构setParameter: #自定义变量auditLog: #检测日志snmp: #简单网络管理协议 systemLog日志相关参数： 123456789101112131415systemLog: verbosity: &lt;int&gt; #日志级别，默认0,1-5均会包含debug信息 quiet: &lt;boolean&gt; #安静，true时mongod将会减少日志的输出量 traceAllExceptions: &lt;boolean&gt; #打印异常详细信息 syslogFacility: &lt;string&gt; #指定用于登录时信息到syslog Facility水平，前提是启用syslog path: &lt;string&gt; #日志路径，默认情况下，MongoDB将覆盖现有的日志文件 logAppend: &lt;boolean&gt; #mongod重启后，在现有日志后继续添加日志，否则备份当前日志，然后创建新日志 logRotate: rename|reopen #日志轮询，防止一个日志文件特别大。rename重命名日志文件，默认值；reopen使用Linuxrotate特性，关闭并重新打开日志文件，前提为logAppend: true destination: &lt;string&gt; #日志输出目的地，可为file或syslog，若不指定，则会输出到 std out timeStampFormat: &lt;string&gt; #指定日志格式的时间戳，有 ctime, Iso869-utc, iso8691-local component: #为不同的组件指定各自的日志信息级别 accessControl: verbosity: &lt;int&gt; command: verbosity: &lt;int&gt; storage存储引擎相关参数: 123456789101112131415161718192021222324252627282930313233storage: dbPath: &lt;string&gt; #mongodb进程存储数据目录，此配置进队此mongod进程有效，你使用配置文件开启的mongod就可以指定额外的数据目录 indexBuildRetry: &lt;boolean&gt; #当构件索引时mongod意外关闭，那么在此启动是否重建索引，默认true repairPath: &lt;string&gt; #在repair期间使用此目录存储临时数据，repair结束后此目录下数据将被删除 journal: enabled: &lt;boolean&gt; #journal日志持久存储，journal日志用来数据恢复，通常用于故障恢复，建议开启 commitIntervalMs: &lt;num&gt; #mongod日志刷新值，范围1-500毫秒，默认100，不建议修改 directoryPerDB: &lt;boolean&gt; #是否将不同的数据存储在不同的目录中，dbPath子目录 syncPeriodSecs: &lt;int&gt; #fsync操作将数据flush到磁盘的时间间隔，默认为60秒，不建议修改 engine: &lt;string&gt; #存储引擎 mmapv1: #mmapv1存储引擎，3.2前默认 preallocDataFiles: &lt;boolean&gt; nsSize: &lt;int&gt; quota: enforced: &lt;boolean&gt; maxFilesPerDB: &lt;int&gt; smallFiles: &lt;boolean&gt; journal: debugFlags: &lt;int&gt; commitIntervalMs: &lt;num&gt; wiredTiger: #WiredTiger存储引擎，3.2后默认 engineConfig: cacheSizeGB: &lt;number&gt; #最大缓存大小 journalCompressor: &lt;string&gt; #日志压缩算法，可选值有 none，snappy(默认)，zlib directoryForIndexes: &lt;boolean&gt; #是否将索引和collections数据分别存储在dbPath单独的目录中 collectionConfig: blockCompressor: &lt;string&gt; #collection数据压缩算法，可选none, snappy，zlib indexConfig: prefixCompression: &lt;boolean&gt; #是否对索引数据使用前缀压缩。对那些经过排序的值存储有很大帮助，可有效减少索引数据的内存使用量。 inMemory: #inMemory内存存储引擎，bate版 engineConfig: inMemorySizeGB: &lt;number&gt; processManagement进程相关参数: 123processManagement: fork: &lt;boolean&gt; #是否以fork模式运行mongod进程，默认情况下，mongod不作为守护进程运行 pidFilePath: &lt;string&gt; #将mongod进程ID写入指定文件，如未指定，将不会创建PID文件 net网络相关参数: 123456789101112131415161718192021222324252627282930net: prot: &lt;int&gt; #监听端口，默认27017 bindIp: &lt;string&gt; #绑定IP，如果此值是“0.0.0.0”则绑定所有接口 maxIncomingConnections: &lt;int&gt; #mongod进程允许的最大连接数，如果此值超过系统配置的连接数阈值，将不会生效(ulimit) wireObjectCheck: &lt;boolean&gt; #当客户端写入数据时，检查数据的有效性（BSON）。如果数据格式不良，update,insert等操作将会被拒绝 ipv6: &lt;boolean&gt; #是否支持多实例之间使用ipv6 unixDomainSocker: #适用于Unix系统 enabled: &lt;boolean&gt; pathPrefix: &lt;string&gt; filePermissions: &lt;int&gt; http: # enabled: &lt;boolean&gt; JSONEnabled: &lt;boolean&gt; RESTInterfaceEnabled: &lt;boolean&gt; ssl: sslOnNormalPorts: &lt;boolean&gt; mode: &lt;string&gt; PEMKeyFile: &lt;string&gt; PEMKeyPassword: &lt;string&gt; clusterFile: &lt;string&gt; clusterPassword: &lt;string&gt; CAFile: &lt;string&gt; CRLFile: &lt;string&gt; allowConnectionsWithoutCertificates: &lt;boolean&gt; allowInvalidCertificates: &lt;boolean&gt; allowInvalidHostnames: &lt;boolean&gt; disabledProtocols: &lt;string&gt; FIPSMode: &lt;boolean&gt; compression: compressors: &lt;string&gt; security安全相关参数: 1234567891011121314151617181920212223242526272829303132333435security: authorization: enabled #MondoDB认证功能 keyFile: /path/mongo.key #MongoDB副本集节点身份验证密钥文件 clusterAuthMode: &lt;string&gt; #集群members间的认证模式 transitionToAuth: &lt;boolean&gt; javascriptEnabled: &lt;boolean&gt; #是否允许执行JavaScript脚本 redactClientLogData: &lt;boolean&gt; sasl: hostName: &lt;string&gt; serviceName: &lt;string&gt; saslauthdSocketPath: &lt;string&gt; enableEncryption: &lt;boolean&gt; encryptionCipherMode: &lt;string&gt; encryptionKeyFile: &lt;string&gt; kmip: keyIdentifier: &lt;string&gt; rotateMasterKey: &lt;boolean&gt; serverName: &lt;string&gt; port: &lt;string&gt; clientCertificateFile: &lt;string&gt; clientCertificatePassword: &lt;string&gt; serverCAFile: &lt;string&gt; ldap: servers: &lt;string&gt; bind: method: &lt;string&gt; saslMechanism: &lt;string&gt; queryUser: &lt;string&gt; queryPassword: &lt;string&gt; useOSDefaults: &lt;boolean&gt; transportSecurity: &lt;string&gt; timeoutMS: &lt;int&gt; userToDNMapping: &lt;string&gt; authz: queryTemplate: &lt;string&gt; operationProfiling慢查询相关参数： 1234operationProfiling: slowOpThresholdMs: &lt;int&gt; #数据库profiler判定一个操作是“慢查询”的时间阈值，单位毫秒。mongod会把慢查询记录到日志中，默认100ms mode: &lt;string&gt; #数据库profiler级别，操作的性能信息将会被写入日志文件中，可选值“off”--关闭profiling，“slowOp”--只包包含慢操作，“all”--记录所有操作 #数据库profiling会影响性能，建议只在性能调试阶段开启 replication副本集： 12345replication: oplogSizeMB: &lt;int&gt; #replication操作日志的最大尺寸，如果太小，secondary将不能通过oplog来同步数据，只能全量同步 replSetName: &lt;string&gt; #副本集名称，副本集中所有的mongod实例都必须有相同的名字，Sharding分布式下，不同的sharding应该使用不同的repSetName secondaryIndexPrefetch: &lt;string&gt; #副本集中的secondary，从oplog中应用变更操作之前，将会先把索引加载到内存 enalbeMajorityReadConcern: &lt;boolean&gt; #允许readConcern的级别为“majority” sharding分片相关参数： 123sharding: clusterRole: &lt;string&gt; #在sharding集群中，此mongod实例可选的角色。configsvr,默认监听27019端口 和 shardsvr,默认监听27018端口 archiveMovedChunks: &lt;boolean&gt; #当chunks因为“负载均衡”而迁移到其他节点时，mongod是否将这些chunks归档，并保存在dbPath/movechunk目录下，mongod不会删除moveChunk下的文件 setParameter自定义变量： 1234setParameter: &lt;parameter1&gt;: &lt;value1&gt; &lt;parameter2&gt;: &lt;value2&gt; enableLocalhostAuthBypass: false #栗子 auditLog审计相关参数： 12345auditLog: destination: &lt;string&gt; #指定审计记录的输出方式，有syslog, console, file format: &lt;string&gt; #输出格式，有JSON 和 BSON path: &lt;string&gt; #如果审计时间输入为文件，那么就需要指定文件完整路径及文件名 filter: &lt;string&gt; #过滤器，可限制审计系统记录的操作类型，该选项需要一个表单的查询文档的字符串表示形式 Mongo Shellmongo shell是一个交互式的JavaScript结构的MongoDB。使用mongo shell来查询和更新数据以及执行管理操作。 mongo shell基础知识启动monso shell启动mongo shell前确保MongoDB实例正在运行。 1234567891011121314mongo [option] [db address] [.js]#以默认配置启动mongo#以特定配置启动mongo --port 27018#连接远程mongo shellmongo --host $host --port $port -u $user -p $passwdmongo &lt;db&gt;mongo &lt;host&gt;/&lt;db&gt;mongo &lt;hsot:port&gt;/&lt;db&gt; .mongorc.js文件mongo shell开始运行时，mongo将在用户主目录下检查.mongorc.js的js文件。如果找到，mongo将在首次命令行之前解释执行.mongorc.js的内容。如果你使用mongo shell执行一个js或表达式，无论是通过mongo --eval，或指定一个.js文件，mongo都将在js处理完成之后读取.mongorc.js文件。可使用 --norc选项禁止加载.mongorc.js。 12ll /root/.mongorc.js# -rw------- 1 root root 0 Dec 27 2016 /root/.mongorc.js 使用mongo shell可能在启动mongo shell的时候会警告: WARNING: /sys/kernel/mm/transparent_hugepage/defrag is ‘always’. We suggest setting it to ‘never’. WARNING: /sys/kernel/mm/transparent_hugepage/defrag is ‘always’. We suggest setting it to ‘never’ WARNING: Access control is not enabled for the database. hugepage(大内存页面)，是Linux操作系统一种管理内存的方式。和通常方式相比，hugepage模式下内存分配管理会有所差异。MongoDB显然不希望这个特定被启用。新版MongoDB增加了安全性设计，推荐用户创建使用数据库时进行验证。所以我们需要创建用户认证。 关闭hugepage: 123456vim /etc/rc.d/rc.localecho never &gt; /sys/kernel/mm/transparent_hugepage/enabledecho never &gt; /sys/kernel/mm/transparent_hugepage/defragchmox a+x /etc/rc.d/rc.local 创建用户认证: 1234567891011121314&gt;use admin&gt;db.createUser(&#123; user: "zhang", pwd: "zhang", roles: [&#123; role: "root", db: "admin"&#125;]&#125;)mongo -u zhang -p zhang --authenticationDatabase admin#或mongouse admindb.auth("zhang", "1314520") 12345678910mongo#显示当前使用数据库&gt;db#切换数据库&gt;use &lt;database&gt;#查看所有数据库&gt;show dbs 你可以切换到一个并不存在的数据库。当你第一次向数据库存储数据，如创建一个集合，MongoDB将自动创建数据库。 123use nodbdb.nocollestion.insert(&#123;x:1&#125;); 格式化打印结果db.collection.find()方法返回一个cursor(游标)。如果返回的游标未使用var关键字指定变量，则游标将自动迭代最多20次，以打印出与查询匹配的前20个documents 1234567#在操作中添加`.pretty()`，以格式化打印结果#使用.pretty显示结果很舒服db.collection.find().pretty()print() #无格式打印printjson() #用JSON打印 mongo shell中的多行操作mongo shell中如果你以( , { , [开始，那么知道你输入了对应的) , } , ]才算结束命令。 Tab命令补全和键盘快捷键mongo shell支持键盘快捷键，例如： 使用 上/下箭头 进行历史命令切换； 使用 Tab键 自动补全命令。 mongo shell批量操作123456mongo -u xxx -p xxx --authenticationDatabase=xxx &lt;&lt; EOFshow dbsuse zhangdb.coll01.drop()db.coll02.update( &#123; _id: "xxx" &#125;, &#123; name: "zhang" &#125;)EOF 退出mongo shell12345quit()exitCtrl+c 配置mongo shell可在mongo shell中设置变量prompt的值来修改提示符内容。prompt变量可以存储字符串以及JavaScript代码。 也可以在.mongorc.js文件中增加提示符的逻辑操作来设置每次启动mongo shell的提示符。 自定义提示符自定义提示符展示操作符： 在mongo shell中定义一下变量。 12345678910cmdCount = 1;prompt = function() &#123; return (cmdCount++) + '&gt; ';&#125;#效果1&gt;2&gt;... 自定义提示符显示数据库和主机名： 形式为：@$ 12345678host = db.serverStatus().host;prompt = function() &#123; return db+'@'+host+'$'&#125;#效果test@localhost$ 自定义提示符展示服务器启动时间和文档数： 1234567prompt = function() &#123; return 'Uptime:' + db.serverStatus().uptime + 'Documents:' + db.stats().objects + '&gt; ';&#125;#效果Uptime:1234 Documents:5 &gt; 注意：在mongo shell里面定义的prompt变量知识临时生效的，退出shell后便没有。如果想要当前用户永久生效，可写入~/.mongorc.js文件。则此用户每次启动mongo shell前都会执行这个文件。 123456vim ~/.mongorc.jshost = db.serverStatus().host;prompt = function() &#123; return db+"@"+host+"&gt; "; &#125; 在mongo shell中使用外部编辑器可在启动mongo shell之前设置EDITOR环境变量来在mongo shell中使用自己的编辑器。 12345678910111213export EDITOR=vimmongo#edit &lt;variable&gt;|&lt;function&gt;function myfunc()&#123;&#125;edit myfunc#此时是edit使用vim编辑myfuncfunction myfunc()&#123; print("It was edited by vim!")&#125;myfunc() 修改mongo shell批处理大小db.collection.find()是一种JavaScript方法，返回一个cursor(游标)。如果返回的游标未使用var关键字指定变量，则游标将自动迭代最多20次，以打印出与查询匹配的前20个documents。可以设置DBQuery.shellBatchSize属性来修改默认20篇文档。 1DBQuery.shellBatchSize = 10; 获取mongo shell帮助合理运用Tab键补全命令！ 1234567891011121314151617181920212223242526###命令行帮助mongo --help###mongo shell里查看帮助列表help###数据库帮助#db.&lt;method&gt;show dbsdb.help()###集合帮助#db.&lt;collection&gt;.&lt;method&gt;show collectionsdb.collections.help()###游标帮助db.collection.find().help()###封装对象帮助help misc 给mongo shell写脚本可使用JavaScript为mongo shell编写脚本，用于处理MongoDB中的数据或执行管理操作。 打开新连接在mongo shell或JavaScript文件中，可使用Mongo()构造函数来实例化数据库连接： 12345678910111213141516171819new Mongo()new Mongo(&lt;host&gt;)new Mongo(&lt;host:port&gt;)#栗子conn = new Mongo();db = conn.getDB('mydb'); #将全局db变量设置为mydb#连接db = connect('localhost:27017/mydb');#认证db.auth(&lt;user&gt;, &lt;passwd&gt;)db.auth(&#123; user: &lt;user&gt;, pwd: &lt;passed&gt;&#125;) 交互式和脚本化mongo的区别mongo shell中的帮助与JavaScript中帮助不一样！ mongo shell帮助 JavaScript等量 show dbs db.adminCommand(‘listDatabases’) use db = db.getSiblingDB(‘‘) show collections db.getCollectionNames() show users db.getUsers() show log db.adminCommand({‘getLog’ : ‘‘}) 脚本使用mongo shell来计算JavaScript的值。 –eval mongo执行 --eval后的js命令 1mongo test --eval &quot;printjson(db.getCollectionNames())&quot; 执行JavaScript文件 12345mongo localhost:27017/test myjs.js#在shell中执行.js&gt;load("myjs.js")&gt;loca("/root/mongo/myjs.js") mongo shell中的数据类型MongoDB BSON提供了除JSON之外的其它数据类型的支持。Driver提供了对这些数据类型在主机语言的本地化支持，mongo shell也提供了一些帮助类来支持这些数据类型在mongo javascript shell中的使用。 日期mongo shell提供了多种方法返回日期: Date() 方法返回当前日期为一个字符串； new Date() 构造函数返回一个使用ISODate()包装返回的Date对象； ISODate() 构造函数返回一个使用ISODate()包装返回的Date对象。 返回一个日期为字符串： 123var myDateString = Date();#查看变量值myDateString 验证类型： 12typeof myDateString()#string 返回Date： 123456var myDate = new Date();myDate#ISODate(&quot;2017-12-12T08:43:31.405Z&quot;)#验证myDate instanceof Date ObjectIdmongo shell对objectid数据类型提供objectId()包装类。 new ObjectId NumberLongmongo shell默认将所有数字处理为浮点值。 用numberlong()包装来处理64位整数。 1NumberLong("2090845886852") NumberInt用NumberInt()构造函数来显式指定32位整数。 NumberDecimalmongo shell默认将所有的数字处理为64位浮点的double值。mongo shell提供了NumberDecimal()构造函数限制指定128位基于十进制的浮点值，能够以精确的精度仿效十进制近似值。这个功能在金融、税务以及科学计算等方面应用。 12&gt;NumberDecimal('1000.55')#强烈建议加上引号，没加引号可能会存在精度丢失的情况 ### 在mongo shell中检查类型 instanceof返回一个bool值来验证一个值是否为某些类型的实例。 12mydoc._id instanceof ObjectId#true typeof返回一个字段的类型。 12typeof mydoc._id#object mongo shell快速参考mongo shell 历史命令mongo shell历史命令保存在~/.dbshell文件中，cat ~/.dbshell。也可以使用上/下键切换历史命令。 命令行选项 option description --help 显示命令行选项 --nodb 启动mongo shell而不连接到数据库 --shell 执行文件后运行mongo shell mongo shell命令助手 help methods and commands description help 显示帮助 db.help 显示数据库方法的帮助 db.collection.help() 显示集合方法的帮助 show dbs 打印服务器上的所有数据库列表 show databases 打印所有可获取的数据库列表 use &lt;db&gt; 切换数据库 show collections 打印当前数据库上的所有集合列表 show users 打印当前数据库的用户列表 show roles 打印当前数据库的所有角色(user-define and built-in)列表 show profile 打印花费1ms或更多时间的五个最近的操作 load() 在shell中执行一个JavaScript文件，建议使用绝对路径 mongo shell的基本JavaScript操作mongo shell为数据库操作提供了一个JavaScript API。db引用当的是前数据库的变量。 JavaScript db-operation description db.auth() 在安全模式下认证用户 coll = db.&lt;collection&gt; 将当前db中的特定collection设置为coll，可在此变量上执行操作，如coll.find(); db.collection.find() 查找集合中的所有文档，并返回一个游标 db.collection.insert() 插入一个新文档到集合中 db.collection.update() 更新集合中一个存在的文档 db.collection.save() 插入或更新 集合中的文档 db.collection.remove() 从集合中删除文档 db.collection.drop() 删除整个集合 db.collection.createIndex() 在集合中创建索引 db.getSiblingDB() 跨数据库查询 键盘快捷键 keysrtoke function Up/Down arrow 前/后 历史命令 Left/Right arrow 左右移动 Home/End 行首/行尾 Tab 自动补全 ctrl+c 退出 ctrl+L 清屏 mongo shell查询方法在mongo shell中，使用find()和findOne()方法执行读操作。 read-operations description db.collection.find(&lt;query&gt;) 查找集合中与匹配的文档，如果未指定或为空，则读取操作会选择集合中的所有文档 db.collection.find(&lt;query&gt;, &lt;projection&gt;) 查找与匹配的文档，返回特定字段 db.collection.find().sort(&lt;sort order&gt;) 返回排序结果 db.collection.find(&lt;query&gt;).sort(&lt;sort order&gt;) 返回匹配和排序结果 db.collection.find(...).limit(&lt;n&gt;) 限制输出结果为行 db.collection.find().pretty().limit() 匹配，格式化，限制输出 db.collection.find().limit().pretty() 同上 db.collection.find(...).skip(&lt;n&gt;) 跳过前行 db.collection.count() 返回集合中文档总数 db.collection.find().count() 返回匹配文档总数 db.collection.findOne(&lt;query&gt;) 查找并返回单一的文档，null表示未找到 管理命令助手 js db-administrative-methods description db.cloneDatabase(&lt;host&gt;) 从指定主机克隆当前数据库，noauth mode db.copyDatabase(&lt;from&gt;, &lt;to&gt;, &lt;host&gt;) copy db to db db.fromColl.renameCollection(&lt;toColl&gt;) rename collection db.repairDatabase() 修复当前db db.dropDatabases() 删除当前数据库 打开附加连接可以在mongo shell中创建一个新连接。 12345&gt;db = connect("&lt;host&gt;:&lt;port&gt;/&lt;db&gt;")#db = connect("192.168.1.11/admin")&gt;conn = new Mongo()&gt;db = conn.getDB("dbname") MongoDB CRUD操作CRUD操作就是创建(create)，读取(read)，更新(update)，删除(delete)文档(document)! 创建(create)操作创建或插入， 即是向 collection 添加新的 document。如果插入时集合不存在，插入操作会创建该集合。 123db.collection.insert()db.collection.insertOne()db.collection.insertMany() 读取(read)操作读操作，获取 collection 中的 document。 1db.collection.find() 更新(update)操作更新操作，修改 collection 中已经存在的 document。 1234db.collection.update()db.collection.updateOne()db.collection.updateMany()db.collection.replaceOne() 删除(delete)操作删除操作，是从一个 collection 中删除 document 的操作。 123db.collection.remove()db.collection.deleteOne()db.collection.deleteMany() 插入文档(Insert) 插入方法MongoDB提供了如下插入方法向collection中插入document： db.collection.insert(), 向集合中插入一个或多个文档; db.collection.insertOne(), 向集合中插入一个文档; db.collection.insertMany(), 向集合中插入多个文档. db.collection.insert()db.collection.insert(),向collection中插入一个或多个document。要想插入一个document，传递一个文档给该方法；要想插入多个documents，传递文档数组给该方法。 12345678910111213141516171819#插入一个文档db.user.insert( &#123; _id: "ZhangTest", name: "zhang", age: 2017, sex: "man" &#125;)#插入多个文档db.user.insert( [ &#123; name: "AAA", age: 20, status: "A" &#125;, &#123; name: "BBB", age: 21, status: "B" &#125;, &#123; name: "CCC", age: 22, status: "C" &#125; ]) db.collection.insertOne()db.collection.insertOne(),向collection中插入单个document。 12345678910db.user.insertOne( &#123; name: "zhang", age: "2017", sex: "man", education: "bachelor" &#125;)#此处并未自定义_id字段，因此它会自动添加_id字段 db.collection.insertMany()db.collection.insertMany(),向collection插入多个documents。 123456789db.user.insertMany( [ &#123; name: "AAA", age: "20", status: "A" &#125;, &#123; name: "BBB", age: "21", status: "B" &#125;, &#123; name: "CCC", age: "22", status: "C" &#125; ])#自动生成3个document的_id字段 插入操作的行为表现创建集合插入的时候如果collection不存在，那么插入操作会创建collection。 _id字段在MongoDB中，存储于collection中的每一个document都需要一个唯一的_id字段作为primary_key。如果一个插入的document操作遗漏了_id字段，则MongoDB driver会自动生成一个ObjectId。 原子性MongoDB中所有的写操作在单一文档层级上是原子的。 查询文档(Read)MongoDB提供了db.collection.find()方法从collection中读取document。 1234db.collection.find( &lt;query filter&gt;, &lt;projection&gt; )#&lt;query filter&gt;指明返回哪些document#&lt;projection&gt;指明返回匹配document的那些filed 示例12345678910111213141516171819202122232425db.user.insertMany( [ &#123; _id: 1, name: "A", favorites: &#123; artist: "Picasso", food: "pizza" &#125;, finished: [ 11, "AA" ], points: [ &#123; points: 85, bonus: 30 &#125;, &#123; points: 85, bonus: 10 &#125; ] &#125;, &#123; _id: 2, name: "B", favorites: &#123; artist: "Miro", food: "merigue" &#125;, finished: [ 22, "BB" ], points: [ &#123; points: 85, bonus: 20 &#125;, &#123; points: 64, bonus: 12 &#125; ] &#125;, &#123; _id: 3, name: "C", favorites: &#123; artist: "Gaogeng", food: "cake" &#125;, finished: [ 33, "CC" ], points: [ &#123; points: 67, bonus: 8 &#125;, &#123; points: 55, bonus: 21 &#125; ] &#125; ]) 查询和规划操作符Comparison: 1234567$eq$gt$gte$lt$ne$in$nin Logical： 1234$or$and$not$nor Element: 12$exists$type Evaluation: 1234$mod$regex$text$where Geospatial: 1234$geoWithin$geoIntersects$near$nearSphere Array: 123$all$eleMatch$size Bitwise: 1234$bitsAllSet$bitsAnySet$bitsAllClear$bitsAnyClear Comments: 1$comment Projection Operators: 1234$$eleMatch$meta$slice 选择collectino中所有document一个空的query filter会选择集合汇总所有文档。 12db.users.find(&#123;&#125;)db.user.find() 指定查询过滤条件1. 指定等于条件 1234&#123; &lt;field1&gt;: &lt;value1&gt;, ...&#125;#栗子db.user.find( &#123; name: &quot;C&quot; &#125; ) 2. 使用查询操作符指定条件 1234&#123; &lt;field1&gt;: &#123; &lt;operator1&gt;: &lt;value1&gt; &#125;, ... &#125;#栗子db.user.find( &#123; name: &#123; $in: [ &quot;A&quot;, &quot;B&quot; ] &#125; &#125; ) 3. 指定逻辑查询条件条件逻辑查询(AND, OR, NOT)。符合查询可以在集合文档的多个字段上指定条件。 123456789101112131415#ANDdb.user.find( &#123; name: &quot;A&quot;, age: &#123; $lt: 30&#125; &#125; )#ORdb.user.find( &#123; $or: [ &#123; name: &quot;A&quot; &#125;, &#123; age: &#123; $lt: 30 &#125; &#125; ]&#125; )#AND和ORdb.user.find( &#123; name: &quot;A&quot;, $or: [ &#123;age: &#123; $lt: 30 &#125; &#125;, &#123; type: 1 &#125; ]&#125; ) 嵌入式文档的查询当字段中包含嵌入文档时，查询可以指定嵌入文档中的精确匹配或使用圆点(.)表示法对嵌入文档的单个字段指定匹配。 12345678#精确匹配db.user.find(&#123; favorites: &#123; artist: &quot;Picasso&quot;, food: &quot;pizza&quot; &#125;&#125;)#圆点.表示法，记得加引号db.user.find( &#123; &quot;favorites.artist&quot;: &quot;Picasso&quot; &#125; ) 数组上的查询当字段包含数组，可查询精确的匹配数组或数组中特定的值。如果数组包含嵌入文档，可使用圆点表示法查询内嵌文档中特定的字段。 123456789101112131415161718192021222324252627#精确匹配db.user.find(&#123; finished: [ 11, &quot;AA&quot; ] &#125;)#匹配一个数组元素，会显示整个文档db.user.find(&#123; finished: &quot;BB&quot; &#125;)#匹配数组中指定元素，会返回整个文档db.user.find(&#123; &quot;finished.1&quot;: &quot;CC&quot; &#125;)#指定数组中的多个查询条件db.user.find(&#123; finished: &#123; $elemMatch: &#123;$gte: 11, $lt: 33&#125; &#125; &#125;)db.user.find(&#123; finished: &#123; $gt: 11, $lt: 33 &#125; &#125;)#嵌入文档数组db.user.find(&#123; &apos;points.points&apos;: &#123;$lte: 80 &#125; &#125;)db.user.find(&#123; &quot;points.0.points&quot;: &#123;$lte: 80&#125; &#125;)#元素组合满足查询条件db.user.find(&#123; &quot;points.points&quot;: &#123;$lte: 80&#125;, &quot;points.bouns&quot;: 20&#125;) 返回查询的映射字段默认地，MongoDB中的查询返回匹配文档中的所有字段。为了限制MongoDB发送给应用的数据量，我们可以在查询操作中包括一个projection文档。 映射文档映射文档限制了返回所有匹配文档的字段。映射文档可以致命包括哪些字段或排除哪些字段。这个就很不错了，可以过滤掉我们不需要的信息。 12345db.users.find( &#123;name: &quot;AAA&quot;&#125; ,&#123;_id: 0, name: 1, age: ture&#125; )db.user.find( &#123; name: &quot;BBB&quot;&#125;, &#123;_id: false&#125; )1或true，表示在返回的文档中包含字段；0或false，排除该字段； 更新文档(Update)更新方法： db.collection.updateOne(), 更新一个文档 db.collection.updateMany(), 更新多个文档 db.replaceOne(), 替换一个文档 db.collection.update(), 更新或替换一个文档 更新的行为表现 原子性：MongoDB中所有的写操作在单一文档层级上是原子的。 _id字段：不能更新_id字段的值，也不能用不同_id字段值的替换文档来替换已存在的文档。 文档大小：当执行更新操作增加的文档大小超过了为该文档分配的空间时，更新操作会在磁盘上重定位该文档。 字段顺序：MongoDB按照文档写入的顺序整理文档字段。但_id字段始终是文档中第一个字段；renaming操作可能会导致文档中的字段重新排序。 Update OperatorFields name description $currentDate 将字段值设置为当前日期(date or timestamp) $inc 按指定的数字递增字段的值 $min 指定的值小于字段的值时才更新 $max 指定的值大于字段的值时才更新 $mul 将字段的值乘以指定的数字 $rename 重命名一个字段 $set 设置文档中字段的值 $setOnInsert 如果更新导致文档插入，则设置字段的值 $unset 从文档中删除指定的字段， Array name description $ 用作更新与查询条件匹配的第一个元素的占位符 $[] 用作更新与查询条件匹配的文档的数组的所有元素的占位符 $[] xxx $addToSet 在集合中不存在元素时添加元素到数组 $pop 移除数组中的第一项或最后一项 $pull 删除所有匹配指定查询的数组元素 $push 向数组中添加项 $pullAll 从数组中删除所有匹配的值 Modifiers name description $each 修饰$push and $addToSet， 向数组中添加多个项 $position 修饰$push，在数组中指定位置添加元素 $slice 修饰$push，限制更新数组的大小 $sort 修饰$push，重新排列存储在数组中的文档 BitWise 1$bit 执行按位AND,OR,XOR更新 更新文档字段中指定字段为了修改文档中的字段，MongoDB提供了update operators，如用来修改值的$set。 1234567891011121314151617181920212223&#123; &lt;update operator&gt;: &#123; &lt;field&gt;: &lt;value&gt;, ...&#125;&#125;#更改指定字段的值db.user.update( &#123; _id: 1 &#125;, &#123; $set: &#123;name: &quot;SET&quot;&#125; &#125;)#删除指定字段，文档中其他字段还在db.user.update( &#123; _id: 1 &#125;, &#123; $unset: &#123;name: &quot;SET&quot;&#125; &#125;)#db.user.updateMany( &#123; _id: 2&#125;, &#123; $set: &#123;name: &quot;AAA&quot;, age: 222&#125; &#125;) 文档替换(Replace)当替换文档时，替换的文档必须仅仅有 &lt;field&gt;: &lt;value&gt;组成。替换文档可以有不同于源文档的字段，但_id字段是不变的。 **建议使用_id作为过滤条件，因为它是唯一的。 123456789101112db.collection.replaceOne()db.user.replaceOne( &#123; name: &quot;AAA&quot; &#125;, &#123; name: &quot;A&quot;, age: 2, sex: &quot;man&quot;, favorites: &#123; artist: &quot;Dali&quot;, food: &quot;banana&quot; &#125; &#125;)db.user.update( &#123; _id: 1&#125;, &#123; name: &quot;A&quot;, age: 2, sex: &quot;man&quot;, favorites: &#123; artist: &quot;Dali&quot;, food: &quot;banana&quot; &#125; &#125;) 删除文档(Delete)方法： db.collection.remove(), 删除一个文档，或所有满足匹配的文档; db.collection.deleteOne(), 删除匹配最多条件的单个文档，即使可能有多个文档可能与指定过滤条件匹配; db.collection.deleteMany(), 删除所有匹配指定过滤条件的文档。 删除的行为表现 Indexes删除操作不会删除索引，即使从集合中删除了所有的文档。 原子性MongoDB中所有的写操作在单一文档层级上是原子的。 删除1234567891011121314#删除所有文档db.collectin.deleteMany(&#123;&#125;)db.collection.remove(&#123;&#125;)#删除所有满足条件的文档db.user.remove( &#123; name: &quot;A&quot; &#125; )db.user.deleteMany( &#123; name: &quot;A: &#125; )#仅删除一个满足条件最多的文档db.user.deleteOne( &#123; name: &quot;A&quot; &#125; )db.users.remove( &#123; name: &quot;A&quot;&#125;, 1) 聚合(Agrregation)聚合操作处理数据记录并返回计算的结果。聚合操作将多个文档中的值(value)分组，并对分组的数据进行各类操作以返回单个结果。 MongoDB提供了三种方式进行聚合： aggregation pipeline(聚合管道); map-reduce function(映射化简); single aggregation methods(聚合指南) Aggregation Pipeline(聚合管道) MongoDB的聚合框架(aggregation framework)是仿照数据处理管道的概念(concept)。Document输入多级管道，它将Document转换为聚合结果。 最基本的pipeline stage提供了：类似查询(query)操作的过滤器(filter)和类似修改(modify)输出文档格式的文档转换。 其他pipeline operation提供了按特定字段对文档进行分组和排序的工具，以及聚合数组内容(包括文档数组)的字段或工具。此外，pipeline stage可以使用运算符(operators)来处理任务。(如计算平均值和连接等…) pipeline通过在MongoDB中使用本地操作，从而提供了高效的数据聚合。所以也是MongoDB中数据聚合的首选方法。 aggregation pipeline能够在一个共享的集合上操作。 aggregation pipeline可以使用索引来提高某些阶段的性能(performance)。另外，管道聚合还有一个内部优化阶段(optimization phase)。 Map-Reduce(映射化简) 一般来说，map-reduce操作有两个阶段： map stage: 处理每个文档并未每个输入文档发出一个或多个对象(object)； reduce stage: 结合映射操作的输出。 可选地，map-reduce有一个对结果做最后修改的最后阶段。与aggregation-operation类似，map-reduce可以指定查询条件来选择一个输入文档，以及对结果进行排序和限制。 map-reduce使用自定义的JavaScript函数执行映射和化简操作，以及可选的最终操作。与聚合管线相比，自定义的JavaScript提供了很大的灵活性。一般来说，map-reduce比aggregation pipeline效率更低，更复杂。 map-reduce能够在一个共享的集合上操作，同样也可以输出到共享集合。 Single Purpose Aggregation Operations(聚合指南) MongoDB同样提供了db.collection.count()和db.collection.distinct()。 所有这些操作都从单个集合中聚合文档，虽然这些操作提供了对常见聚合过程的简单访问，但它们缺少aggregation pipeline和map-reduce的灵活性和功能。 Aggregation Pipeline(聚合管道)MongoDB的聚合框架是仿照数据处理管道的概念。文档输入多级管道，它将文档转换为聚合结果。 当map-reduce的复杂性可能是没有保证的，aggregation pipeline为map-reduce提供了一个可选也可能是聚合任务的首选解决方案。aggregation pipeline对key value和result size有一些限制。 映射化简 聚合指南 MongoDB文本索引MongoDB支持在字符串内容上执行文本检索(text search)的查询操作。视图不支持文本检索。为了执行文本检索，MongoDB使用text index和$text操作符。text索引可以包括任何值为字符串或字符串元素数组的字段。 栗子： 1234567db.sample.insert( [ &#123; _id: 1, name: "A", description: "AAA" &#125;, &#123; _id: 2, name: "B", description: "BBB" &#125;, &#123; _id: 3, name: "C", description: "CCC" &#125; ]) 为了执行文本检索查询，你必须在集合有一个text索引，一个集合只能有一个文本检索索引，但是这个索引可以覆盖多个字段。 启动在name和description字段上的文本检索： 123db.sample.createIndex( &#123; name: "text", description: "text" &#125;) 使用$text查询操作符在一个有text index的集合上执行文本检索 123456789101112131415db.sample.find(&#123; $text: &#123; $search: &quot;A B&quot; &#125;&#125;)#精确检索db.sample.find(&#123; $text: &#123; $search: &quot;A \&quot;B\&quot;&quot; &#125;&#125;)#词语排除db.sample.find(&#123; $text: &#123; $search: &quot;A B -AAA&quot; &#125;&#125;) MongoDB默认返回没排序的结果。然而文本检索将会对每个文档计算一个相关性分数，表明该文档与查询的匹配程度。为了使用相关性分数进行排序，你必须使用 $meta textScore字段进行映射然后基于该字段进行排序。 1234db.sample.find( &#123; $text: &#123; $search: &quot;A AAA B&quot; &#125; &#125;, &#123; score: &#123; $meta: &quot;textScore&quot; &#125; &#125;).sort( &#123; score: &#123; $meta: &quot;textScore&quot; &#125; &#125;) 文本检索可以在聚合管道中使用。 文本索引 文本检索操作符 在管道聚合中使用文本索引 使用基本技术Rosette语义平台的文本索引 文本检索语言 MongoDB数据模型MongoDB的数据具有灵活的模式，集合本身没有对文档结构的规则性校验。 数据模型设计介绍关系型数据库要求你再插入数据之前必须先定义好一个表的模式结构，而MongoDB的集合并不限制文档结构。这种灵活性让对象和数据库文档之间的映射变得很容易。即使数据记录之间有很大的变化，每个文档也可以很好的映射到各条不同的记录。当然，在实际使用中，同一个集合中的文档往往都有一个比较类似的结构。 数据模型设计中最具挑战性的是在应用程序需求，数据库引擎性能要求和数据读写模式之间的权衡考量。 文档结构引用(reference)引用方式通过存储链接或引用信息来实现两个不同文档之间的关联。应用程序可以通过解析这些数据库引用来访问相关数据。简单来讲，这就是规范化的数据模型。 内嵌(embedded data)内嵌方式指把相关联的数据保存在同一个文档之内。MongoDB的文档结构允许一个字段或一个数组内的值为一个嵌套的文档。这种冗余的数据模型可以让应用程序在一个数据库内完成对相关数据的读取或修改。 写操作的原子性在MongoDB中，写操作在文档级别是原子的(atomic)，没有一个单独的写操作可以原子地影响多个文档或多个集合。但，对原子性写操作利好的内嵌数据模型会限制应用程序对数据的使用场景。 嵌入(embdded)数据的非规格化(denormalized)数据模型将单个文档所表示的实体(entity)的所有相关数据组合在一起。这有利于原子写操作，因为单个写操作可以插入或更新实体的数据； 规格化(normalizing)数据通过多个集合拆分数据，并需要多个不是原子集合的写操作。 文档的增长如果文档的大小超出分配给文档的原空间大小，那么MongoDB就需要把文档从磁盘上的现有位置移动到一个新的位置以存放更多的数据。这种数据增长的情况也会影响到是否要使用规范化或非规范化。 数据的使用和性能设计文档模型时，一定要考虑应用程序会如何使用你的数据。 例如： 假如应用程序通常只会使用最近插入的文档，那么可以考虑使用限制集； 假如应用会做大量的读操作，那么可以加多一些索引的方法来提升常见查询的性能。 文档验证MongoDB提供了在更新和插入期间验证(validate)文档的功能(capability)。验证规则是在每个集合中指定使用验证符(validator)选项，利用一个文档指定验证堆栈或表达式。 通过collMod命令附带验证符选项向一个已经存在的集合添加文档验证； 利用db.createCollection()命令附带验证符选项来创建文档验证规则。 123456789db.createCollection( "contacts", &#123; validator: &#123; $or: [ &#123; phone: &#123; $type: "string" &#125; &#125;, &#123; email: &#123; $regex: /@mongodb\.com$/ &#125; &#125;, &#123; status: &#123; $in: [ "Unknown", "Incomplete" ] &#125; &#125; ] &#125;&#125; ) MongoDb同样提供了validationLevel选项，它确定了MongoDb在更新期间如何将验证规则应用到已有文档，以及验证操作选项。它确定MongoDB是否错误并拒绝违反验证规则的文档，或者警告日志中的违规，但允许无效的文档。 行为验证发生在更新和插入期间。当向一个文档添加验证，在修改之前，现有文档不会进行验证检查。 现有文档 可使用validationLevel选项来控制MongoDB怎样处理现有文档。 默认情况下，MongoDB是严格的，并且将验证规则应用于所有插入和更新操作。 12345678#moderate level#在中等级别下，对不符合验证标准的现有文档更新将不会检查有效性db.runCommand(&#123; collMod: "contacts", validator: &#123; $or: [ &#123; phone: &#123; $exists: true &#125; &#125;, &#123; email: &#123; $exists: true&#125;&#125; ] &#125;, validationLevel: "moderate"&#125;) 设置validationLevel为off以禁用验证功能。 接受或拒绝无效文档 validationAction选项决定了MongoDB如何处理违反(violate)验证规则的文档。 默认情况下，validationAction是错误的，并且拒绝任何违反验证条件的插入和更新操作。 123456789101112131415161718#当validationAction为warn时，MongoDB记录所有违反行为，但允许插入或更新操作。db.createCollection( "contacts", &#123; validator: &#123; $or: [ &#123; phone: &#123; $type: "string" &#125; &#125;, &#123; email: &#123; $regex: /@mongodb\.com$/ &#125; &#125;, &#123; status: &#123; $in: [ "Unknown", "Incomplete" ] &#125; &#125; ] &#125;, validationAction: "warn" &#125;)#如下违规操作将会报警，并由于是warn，所以写入成功db.contacts.insert( &#123; name: "Amanda", status: "Updated" &#125; ) 约束(restriction) 无法在admin,local,config数据库的集合 和 system.*集合 里面指定验证符(validator)。 绕过文档验证 通过bypassDocumentValidation选项来绕过文档验证。 数据建模理论数据模型设计一个高效的数据模型能够很好的满足应用程序的需求。设计一个文档数据结构最关键的考量就是决定是使用嵌套(embdded)还是引用(reference)。 内嵌式数据模型(非规范化)在MongoDB里面，可以把相关的数据包括在一个单个的结构或者文档下面。这样的数据模型也叫作非规范化模式。 内嵌数据可以让应用程序把相关的数据保存在同一条数据记录里面，这样，应用程序就可以发送较少的请求给MongoDB来完成常用的查询和更新请求。 一般来说，下述情况建议使用内嵌数据模型： 数据对象之间有包含(contain)关系； 数据对象间有一对多的关系。 通常情况下，内嵌数据会对读操作有比较好的性能提高，可以使应用程序在一个单个操作就可以完成对数据的读取。同时，内嵌数据也对更新相关数据提供了一个原子性写操作。 规范化数据模型一般来说，下述情况可以使用规范化模型： 内嵌数据会导致很多数据的重复，并且读性能的优势又不足与盖过数据重复的弊端时； 需要表达比较复杂的多对多关系时； 大型多层次结构数据集。 MongoDB特性和数据模型的关系MongoDB的数据建模不仅仅取决于应用程序的数据需求，也要考虑MongoDB本身的一些特性。 文档增长性(increase)如果更新操作导致文档大小增加，那么可能需要重新设计数据模型，在不同文档之间使用引用的方式而非内嵌、冗余的数据结构。MongoDB会自动调整空白填充的大小以尽可能的减小文档迁移。你也可以使用一个预分配策略来防止文档的增长。 原子性(atomic)在MongoDB中，所有在文档级别的操作都具有原子性。一个单个写操作最多只可以修改一个文档。即使是一个会改变同一个集合中多个文档的命令，在同一时间也只会操作一个文档。即便是涉及多个子文档的多个操作，只要是在同一文档之内，这些操作仍旧是有原子性的。 尽可能保证那些需要在一个原子操作内进行修改的字段定义在同一个文档里面。如果你的应用程序允许对两个数据的非原子性更新操作，那么可把这些数据定义在不同的文档内。 把相关数据定义到同一个文档里的内嵌方式有利于这种原子性操作。对于那些使用引用来关联相关数据的数据模型，应用程序必须再用额外的读和写操作去取回和修改相关的数据。 分片(sharding)MongoDB使用分片来实现水平扩展。使用分片的集群可以支持海量的数据和高并发读写。使用分片技术把一个数据库内的某一个集合的数据进行分区，从而达到把数据分到多个mongod实例(或分片上)的目的。 MongoDB依据分片键分发数据和应用程序的事务请求。选择一个合适的分片键对性能有很大的影响，也会促进或阻碍MongoDB的定向分片查询和增强的写性能。所以在选择分片键的时候要仔细考量分片键所用的字段。 索引(index)对常用操作可以使用索引来提高性能。对查询条件中常见的字段，以及需要排序的字段创建索引。MongoDB会对_id自动创建唯一索引。 创建索引时，需要考虑索引的下述特征： 每个索引要求至少8KB的数据空间； 每增加一个索引，就会对写操作性能有一些影响。对于一个写多读少的集合，索引会变得很费时。因为每个插入必须要更新所有索引； 每个索引都会占一定的硬盘空间和内存(对于活跃的索引)。索引可能会用到很多这样的资源，因此对这些资源要进行管理和规划，特别是在计算热点数据大小的时候。 集合的数量某些情况下，可能需要把相关的数据保存到多个集合里面。比如： 12&#123; log: &quot;dev&quot;, ts:..., info: ... &#125;&#123; log: &quot;debug&quot;, ts:..., info: ... &#125; 一般来说，很大的集合数量对性能没有什么影响，反而在某些场景下有不错的性能。使用不同的集合在高并发批处理场景下会有很好的帮助。 当使用有大量集合的数据模型时，请注意： 每个集合有几KB的额外开销； 每个索引(包含_id)，需要至少8KB的数据空间； 每个MongoDB的数据库有且仅有一个命名文件(namespace file)(.ns)。这个命名文件保存了数据库的所有元数据，每个索引和集合在这个文件里都有一条记录； MongoDB的命名文件有大小的限制(默认16MB)。利用db.system.namespaces.count()查看。 包含大量小文档的集合如果你有一个包含大量小文档的集合，则应该考虑为了性能而嵌入。如果你可以通过一些逻辑关系将这些小文档分组，并且你经常通过这个分组来检索文档，那么你应该考虑将小文档”卷起来”成为包含一系列嵌入式文档的大文档。 将这些小文档“卷起来”成为逻辑分组，意味着检索一组文档的查询设计顺序读取和较少的随机磁盘访问。此外，将文档“卷起”并将公共字段移动到较大的文档会使字段上的索引受益。公共字段的副本将会减少，并且相应索引中的关联键条目也会减少。 然而，如果你通常只需要检索分组中的一个文档的子集，那么“滚动”文档可能无法提供更好的性能。此外，如果晓得，独立的文档代表数据的自然模型，那你应该维护改模型。 小文档的存储优化(storage optimization)每个MongoDB文档都包含一定的开销(overhead)，这些开销通常是无关紧要的。但如果文档只有几个字节，那就相当重要了。 考虑以下有关优化这些集合的存储利用率的建议： 显示地使用_id字段； 使用较短的字段名称； 嵌套文档。 数据生命周期管理数据模型决策应考虑数据生命周期管理。 集合的*TTL功能在一段时间后标识文档到期。如果应用程序需要一些数据才能在数据库中持久化一段有限的时间，请考虑使用TTL特性。 此外，你的应用程序仅使用最近插入的文档，请考虑限制集。 数据模型例子与范式文档关系建模一对一关系建模：内嵌文档模型用内嵌文档方式实现一对一关系。 一对多关系建模：内嵌文档模型用内嵌文档方式实现一对多关系。 一对多关系建模：文档引用模式用文档引用实现一对多关系。 树结构建模父文档引用父文档引用模式用一个文档来表示树的一个节点。每一个文档除了存储节点的信息，同时也保存该节点父节点文档的id值。 1234567891011121314db.test.insert(&#123; _id: "MongoDB", parent: "Databases" &#125;)db.test.insert(&#123; _id: "Databases", parent: "Programming" &#125;)db.test.insert(&#123; _id: "Programming", parent: "Books" &#125;)db.test.insert(&#123; _id: "Books", parent: null &#125;)#查询父节点db.test.findOne(&#123; _id: "MongoDB" &#125;).parent#对parent字段创建索引，这样可以快速的按照父节点查找db.test.createIndex(&#123; parent: 1 &#125;)#查询一个父节点的所有子节点db.test.find(&#123; parent: "Databases" &#125;) 子文档引用子文档引用模式用一个文档来表示树的一个节点。每一个文档除了存储节点信息外，同时也用一个数组来保存该节点的所有子节点的id值。 1234567891011121314db.test.insert(&#123; _id: "MongoDB", children: [] &#125;)db.test.insert(&#123; _id: "Databases", children: [ "MongoDB", "dbm" ]&#125;)db.test.insert(&#123; _id: "Programming", children: [ "Languages", "Databases" ]&#125;)db.test.insert(&#123; _id: "Books", children: [ "Programming" ]&#125;)#查询子节点db.test.findOne(&#123; _id: "Databases"&#125;).children#对children字段创建索引，这样就可以快速按照子节点查找db.test.createIndex(&#123; children: 1 &#125;)#查找一个子节点的父节点和同级节点db.test.find(&#123; children: "MongoDB" &#125;) 祖先数组(ancestors array)祖先数组模式用一个文档来表示树的一个节点。每一个文档除了存储节点的信息，同时也存储了对父文档及祖先文档的id值。 1234567891011121314db.test.insert(&#123; _id: "MongoDB", ancestors: [ "Books", "Programming", "Databases" ], parent: "Databases" &#125;)db.test.insert(&#123; _id: "Databases", ancestors: [ "Books", Programming" ], parent: [ "MongoDB", "dbm" ]&#125;)db.test.insert(&#123; _id: "Programming", ancestors: [ "Books" ], parent: "Books" &#125;)db.test.insert(&#123; _id: "Books", ancestors: [ ], parent: null &#125;)#查询一个节点的祖先节点db.test.findOne(&#123; _id: "MongoDB" &#125;).ancestors#对ancestors创建索引db.test.createIndex(&#123; ancestors: 1 &#125;)#利用ancestors字段来查找某个节点的所有子代节点db.test.find(&#123; ancetors: "Programmming" &#125;) 物化路径(materialized path)物化路径模式将每个树节点存储在文档中。除了存储节点信息外，同时也存储了祖先文档或路径的id值。 123456789101112131415db.test.insert(&#123; _id: "Books", path: null &#125;)db.test.insert(&#123; _id: "Programming", path: ",Books," &#125;)db.test.insert(&#123; _id: "Databases", path: ",Books,Programming," &#125;)db.test.insert(&#123; _id: "MongoDB", path: ",Books,Programming,Databases," &#125;)#查询整个树的所有节点并按path排序db.test.find().sort(&#123; path: 1 &#125;)#可以在path字段上使用re来查询db.test.find(&#123; path: /,Programming,/ &#125;)db.test.find(&#123; path: /^,Books,/ &#125;)#在path字段上创建索引db.test.createIndex(&#123; path: 1 &#125;) 嵌套集合(nested set)嵌套集合模式对整个树结构进行一次深度优先的遍历。遍历时候对每个节点的压栈和出栈作为两个不同的步骤记录下来。每一个节点就是一个文档，除了节点信息外，文档还保存父节点的id以及遍历的两个步骤编号。压栈是的步骤保存到left字段里，而出栈时的步骤编号则保存到right字段里。 12345678db.test.insert(&#123; _id: "Books", parent: 0, left: 1, right: 12 &#125;)db.test.insert(&#123; _id: "Programming", parent: "Books", left: 2, right: 11 &#125;)db.test.insert(&#123; _id: "Databases", parent: "Programming", left: 5, right: 10 &#125;)db.test.insert(&#123; _id: "MongoDB", parent: "Databases", left: 6, right: 7 &#125;)#查询摸个节点的子代节点db.test.find(&#123; left: &#123; $gt: db.test.findOne(&#123; _id: "Databases" &#125;), right: &#123; $lt: db.test.findOne(&#123;"_id: "Databases"&#125;) &#125; &#125;) 具体应用模型举例原子性事务建模如何使用内嵌技术来保证同一文档内相关字段更新操作的原子性。 举例来说，假设你在设计一个图书馆的借书系统，你需要管理书的库存量以及出借记录。一本书的可借数量加上借出数量的和必须等于总的保有量，那么对这两个字段的更新必须是原子性的。 关键词搜索建模描述了一种把关键词保存在数组里并使用多键索引来实现关键词搜索功能的方法。 为实现关键词搜索，在文档内增加一个数组字段并把每一个关键词加到数组里。然后你可以对该字段建一个 多键索引。这样你就可以对数组里面的关键词进行查询了。 货币数据建模处理货币数据的应用程序通常需要捕获小数(franctional)货币单位，并在执行算术时需要精确地模拟十进制四舍五入。许多现代系统(float,double)使用的基于二级制的浮点运算不能精确地表示小数，而且需要某种程度的近似，因而不适合于货币运算。因此，在货币数据建模时，这一约束是一个重要的考虑因素。 数字模型如果需要查询数据库中精确、数学书有效匹配或需要执行Server端算术，则数字模型可能是适合的。 非数字模型如果需要在Server端做一些对货币数值的数学计算，那么严格精度可能会更合适一些。 时间数据模型MongoDB默认存储UTC时间，并将任何本地时间转换成这种形式。 MongoDB管理administration The administration 文档说明了MongoDB实例和部署正在进行的操作和维护。本文档包括这些问题的高级概述，以及涵盖操作MongoDB的特定过程的教程。 操作清单(operation checklist)如下清单，提供了帮助你避免在MongoDB部署中出现问题的建议。 文件系统(file system) 将磁盘分区与RAID配置对齐； 避免对dbpath使用NFS。使用NFS会导致性能下降和不稳定； 针对Linux/Unix的文件格式，建议使用XFS或EXT4。如果可能的话，对MongoDB使用XFS性能会更好； 对于WiredTiger存储引擎，强烈建议使用XFS来避免使用EXT4时发现的性能问题； 针对Windows，不要使用FAT(FAT16/32/exFAT)文件系统，请使用NTFS文件系统。 复制(replication) 验证所有非隐藏副本集成员的RAM, CPU, 磁盘, 网络设置, 配置等方面是否相同； 配置oplog的大小来适合你的用例； 确保副本集包好至少3个以journaling方式运行的数据承载节点； 在配置副本集成员时使用主机名(hostname)，而不是IP地址； 确保所有的mongod实例之间使用全双工网络； 确保每台主机都能解析它自己； 确保副本集包含奇数个投票的成员(voting members)，确保票数不会相等则一定会有主被选举出来； 确保mongod实例有0或1票； 为了高可用(high availability)，副本集集群最少部署3台数据中心。 分片(sharding) 将配置服务器放置于专用硬件，以便在大型集群中实现最佳性能。确保硬件有足够的RAM来讲数据文件完全存储到内存中，并且有专门的存储； 使用NTP同步分片集群上所有组件的时钟； 确保Mongod, mongos和配置服务器之间的全双工网络连接； 使用CNAME将配置服务器标识到集群中，以便可以在不停机的情况下重命名和重新编号配置服务器。 Journaling 确保所有实例都使用journaling； 将journal放置于低延迟(low-latency)磁盘上，用于编写密集的工作负载。注意，这将影响快照式备份(snapshot)，因为构成数据库状态的文件将驻留在单独的volume上。 硬件(hardware) 使用RAID10和SSD能够获得最佳性能； 确保每个mongod为它的dbpath提供了IOPS； 在虚拟环境中运行时，避免动态内存功能； 避免将所有副本集成员放置于相同的SAN(存储区网络)中。 部署到云上 AWS; Azure; Aliyun; Tencent. 操作系统配置Linux 关闭hugepages和defrag； 调整存储数据库文件设备上的readahead设置，以适应用例； 在虚拟环境中的RHEL7/CENTOS7上禁用优化工具； 为SSD驱动使用noop或deadline磁盘调度； 禁用NUMA或将vm.zone_reclaim_mode设置为0，并运行node interleaving的mongod实例； 调整硬件的ulimit值以适应实例； 对dbpath挂载点使用noatime； 对你的部署配置足够的文件句柄(fs.file-max value of 98000)，内核pid限制(kernel.pid_max value of 64000)，每个进程的最大线程数(kernel.threads-max value 0f 64000)； 确保你的系统配置有swap交换分区； 确保系统默认TCP keepalived设置正确。 Windows 考虑禁用NTFS的最后访问时间更新。这类似与在Unix-like系统上禁用atime。 备份(backup) 安排备份和恢复过程的定期测试，以便手头有时间估计，并恢复其功能。 监控(monitor) 监视Server的硬件统计信息(磁盘使用，CPU，可用磁盘空间…) 监视mongodb的状态。 负载均衡(load balance) 配置负载均衡启用”sticky session”或“client affinity”，对现有连接有足够的超时时间； 避免放置负载均衡器在MongoDb集群或副本集组件。 开发清单(development checklist)如下清单，提供了帮助你避免在MongoDB部署期间出现的问题的建议。 数据持久性(data durability) 确保副本集至少包含3个(带有w:majority)数据承载节点，这3个数据承载节点需要为副本集的高数据持久性； 确保所有实例都是用了journaling。 架构设计(schema design)MongoDB中的数据具有动态结构。collection并不要求document结构。这有助于迭代开发和多态性。然而，集合中的文档通常具有高度的同类结构。 确保你需要的集合集中的索引(indexes)支持你的查询(query)。除了_id索引，你必须显式的创建所有索引； 确保你的架构设计支持你的开发类型； 确保你的架构设计不依赖于长度不受绑定的索引数组； 再架构设计时考虑文档大小限制。 复制(replication) 使用奇数个副本集成员以确保选举顺利进行。如果有偶数个成员，请使用仲裁者(arbiter)以确保级数的选票； 确保使用监控工具和适当的写关注来保持从库数据最新； 不要使用从库读取来扩展整体读取吞吐量。 分片(sharding) 确保你的sharded key将负载均匀地分配到分片上； 对需要按分片数进行缩放的工作负载(workload)使用有针对性的操作； 对非目标(non-targeted)查询，总是从主节点读取可能对陈旧或孤立的数据很敏感； 当向新的非散列(hash)分片集合中插入大数据集时，Pre-split and manually balance chunks。 驱动(drivers) 使用连接池(connection pooling)； 确保你的应用程序在复制集选举期间还能够处理瞬时写入(transient write)和错误读取； 确保你的应用程序处理失败的请求并适时地重试它们； 使用指数退避逻辑重试数据库请求； 如果需要计算数据库操作的编译执行时间，对读操作使用cursor.maxTimeMS()，对写操作使用wtimeout。 性能(MongoDB Perfomance) 当遇到性能下降时，通常与数据库的访问策略、硬件可用性和开放的数据库连接数相关； 一些用户可能由于不适当的索引策略或结果不足而经历性能限制，或由于架构设计模式差； 性能问题可能表明数据库正以最大限度运行，是时候给数据库添加额外的容量(capacity)了。尤其是，应用程序的工作集应该有足够的物理内存。 锁紧性能(lock performance) MongoDB使用锁系统来确保数据集的一致性。如果某些操作需要长时间运行(long-running)，或队列窗体，随着请求和操作等待lock，性能将会下降； 锁相关的减速是可以间歇的，可查看lock部分是否影响了性能； locak.deadlockCount提供了遭遇死锁(deadlocks)的次数； 如果globalLock.currentQueue.total很高，则可能有大量的请求在等待lock。这表明并发问题(concurrency issue)可能影响性能； 如果globalLock.totalTime时间比uptime高，那么数据库在锁定状态中存在了大量时间； 长查询(long query)可能会导致索引无效使用、非最佳(non-optimal)建构设计、差的查询结构、系统体系结构问题、RAM不足导致页面错误(page fault)和磁盘读取。 连接数(number of connections)在某些情况下，应用程序和数据库之间的连接数量可能超出服务器处理请求的能力。serverStatus文档中的以下字段可以提供观察： globalLock.activeClients包含正在进行或排队的活动操作的客户端总数； connnections由以下两个字段组成： 1，connections.current连接到数据库实例的当前客户端总数； 2，connections.available可用的连接总数。 如果有大量的并发程序请求，则数据库可能无法满足需求。那么就需要增加部署的容量。 对于读操作巨大(read-heavy)的应用程序，增加你的副本集大小并将读操作分发给SECONDARY。对于写操作巨大(write-heavy)的应用程序，部署分片并将一个或多个分片添加到分片集群中，以便在mongod实例之间分配负载。 连接数到达峰值也可能是应用程序或驱动错误所导致的结果。 除非收到系统范围的限制，否则MongoDB对传入连接没有限制。在基于Unix系统上，可使用ulimit命令或修改/etc/sysctl系统文件来修改系统限制。 数据库性能分析(database profiling)MongoDB的profiler是一种数据库分析系统，可以帮助识别低效的查询和操作。 有如下分析级别(profiling-level)可用： Level Settiing 0 Off.No profiling 1 On.Only includes “slow” operations 2 On.Includes all operations 在mongo shell中运行如下命令来配置性能分析器： 123#dbsetProfilingLever()db.setProfilingLevel(1) slowOpThresholdMs的设置定义了什么是一个slow操作，要设置一个慢操作的阈值(threshold)，可以在运行时作为db.setProfilingLevel()操作的一个参数来配置slowOpThresholdMs。 默认情况下，mongod将会把所有的慢查询(slow query)记录到日志，这是由slowOpThresholdMs定义的。 通过在mongo shell中使用show profile，你可以在数据库中的system.profile集合中查看性能分析器的输出。或者执行如下操作： 12345#返回超过100ms的所有操作，这个值请高于阈值`slowOpThresholdMs`db.system.profile.find( &#123; millis: &#123; $gt: 100 &#125; &#125;) 你必须使用查询操作符去访问system.profile文档中的查询字段。 数据库性能分析器(databases profiler)数据库性能分析器(db profiler)收集有关MongoDB的写操作、游标和运行在mongod实例上的命令的细微数据，你可以在每个数据库或每个实例基础上启用性能分析(profiling)。默认情况系，分析器是关闭的。启用profiling的时候需要配置profiling leverl。 The database profiler将所有的数据收集到system.profile集合中，它是一个限制集(capped collection)。 分析等级(Profiling levels) 0， 关闭分析器，不收集任何数据。mongod总是将操作时间长于slowOpThresholdMs的值写入日志。这是默认分析器级别； 1， 只收集慢操作的分析数据。默认是以100ms； 2， 收集所有数据库操作的分析数据。 启用分析器(profiling)和设置分析级别(profiling level)当启用profiling，也要设置profiling level，分析器将数据记录到system.profile集合。当你在数据库中启用profiling后，MongoDB会在数据库中创建system.profile集合。 使用db.setProfilingLevel()来设置profiling level和启用profiling。 1db.setProfilingLevel(1) 指定慢操作的阈值(the Threshold for slow operations) 慢操作的阈值(threshold)应用于整个mongod实例。当你修改了阈值，那你就对所有的数据库实例进行了修改。修改了数据库慢操作的阈值同样也会影响整个mongod实例性能分析子系统的慢操作阈值。默认情况下，慢操作的阈值为100ms。性能分析level-1将会记录长于阈值的慢操作到日志。 要更改阈值，请将两个参数(parameter)在mongo shell传递给db.setProfilingLevel()。第一个参数是为当前的数据库设置profiling level，第二个参数是为整个mongod实例设置默认的慢操作阈值。 栗子： 123456mongo&gt;use zhang&gt;db.serProfilingLevel(1,100)#会在zhang数据库下生产system.profile集合 检查分析等级(check profiling level) 1234567db.getProfilingStatus()#default#&#123; &quot;was&quot; : 0, &quot;slowms&quot; : 100 &#125;db.getProfilingLevel()#0 为一个完整的mongod实例启用profiling 在测试环境中，处于开发目的，你可以为一个完整的mongod实例启用profiling功能。性能分析等级应用于mongod实例中的所有数据库。 12#设置level：1，slowOpThresholdMs: 50mongod --profile 1 --slowms 50 数据库分析和分片 无法对mongos实例启用profiling。要对分片集群启用profiling功能，你必须对分片集群中的每个mongod实例启用profiling功能才行。 查看性能分析器的数据(profiler data)数据库性能分析器关于数据库操作的日志信息放置于system.profile集合中。如需查看性能信息，请查询该集合。 栗子： 1234567891011121314151617db.system.profile.find()db.system.profile.find().limit(10).sort(&#123; ts: -1 &#125;).pretty()#指定时间db.system.profile.find( &#123; millis: &#123; $gt: 5 &#125; &#125; ).pretty()#除了某个命令外db.system.profile.find(&#123; op: &#123; $ne: &apos;cmd&apos; &#125; &#125;).pretty#某个特定集合db.system.profile.find( &#123; ns: &apos;db.collection&apos; &#125; ).pretty()#显示最近的事件show profile 分析器开销(profiler overhead)分析器对性能影响很小。system.profile集合是一个默认大小为1MB的限制集。这样大小的集合通常可以存储上千份分析文档，但一些应用程序可能在每次操作中只使用或多或少的分析数据。 在Primary上面修改system.profile集合的大小 停止profiling； 删除(drop)system.profile集合； 新建一个system.profile集合； 重启profiling。 12345use dbdb.serProfilingLevel(0)db.system.profile.drop()db.createCollection( &quot;system.profile&quot;, &#123; capped: true, size: 4000000 &#125; )db.setProfilingLevel(1) 在Secondary上修改system.profile集合的大小 在Secondary上修改system.profile集合的大小，你必须停止Secondary，然后以standalone模式运行它，之后执行修改步骤。当做完上述步骤之后，以一个副本集成员的方式使用standalone模式重启它。 禁用显见的大页面(Disable Transparent Huge Pages)Transpatent Huge Pages(THP)是一个Linux的内存管理系统，通过使用更大的内存页，减少了在具有大量内存的机器上进行Translation Lookaside Buffer(TLB)查找的开销。 然而，数据库工作负载(workload)在THP中的性能往往很差，因为它们往往具有稀疏的(sparse)而不是连续的(contiguous)内存访问模式。你应该在Linux机器上禁用THP来确保MongoDB获得最佳的性能。 1. 创建init.d脚本 12345678910111213141516171819202122232425262728293031323334353637383940#!/bin/bash### BEGIN INIT INFO# Provides: disable-transparent-hugepages# Required-Start: $local_fs# Required-Stop:# X-Start-Before: mongod mongodb-mms-automation-agent# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Disable Linux transparent huge pages# Description: Disable Linux transparent huge pages, to improve# database performance.### END INIT INFOcase $1 in start) if [ -d /sys/kernel/mm/transparent_hugepage ]; then thp_path=/sys/kernel/mm/transparent_hugepage elif [ -d /sys/kernel/mm/redhat_transparent_hugepage ]; then thp_path=/sys/kernel/mm/redhat_transparent_hugepage else return 0 fi echo 'never' &gt; $&#123;thp_path&#125;/enabled echo 'never' &gt; $&#123;thp_path&#125;/defrag re='^[0-1]+$' if [[ $(cat $&#123;thp_path&#125;/khugepaged/defrag) =~ $re ]] then # RHEL 7 echo 0 &gt; $&#123;thp_path&#125;/khugepaged/defrag else # RHEL 6 echo 'no' &gt; $&#123;thp_path&#125;/khugepaged/defrag fi unset re unset thp_path ;;esac 2. 使之可执行 1chmod 755 /etc/init.d/disable-transparent-hugepages 3. 配置操作系统以在开机的时候运行它 12345678910#Debian系列update-rc.d disable-transparent-hugepages defaults#RedHat系列chkconfig --add disable-transparent-hugepages#SUSEinsserv /etc/init.d/disable-transparent-hugepages 4. 如果适用，覆盖(override)tuned和ktune 12345678910111213#RedHat/CentOS7mkdir /etc/tuned/no-thpvim /etc/tuned/no-thp/tuned.conf[main]include=virtual-guest[vm]transparent_hugepages=nevertuned-adm profile no-thp 5. 测试你做的改变 1234cat /sys/kernel/mm/redhat_transparent_hugepage/enabledcat /sys/kernel/mm/redhat_transparent_hugepage/defrag#always madvise [never] 另一种简便的方式来禁用THP 123456vim /etc/rc.d/rc.localecho 'never' &gt; /sys/kernel/mm/transparent_hugepage/enabledecho 'never' &gt; /sys/kernel/mm/transparent_hugepage/defragchmod u+x /etc/rc.d/rc.local Unix系统下的ulimit的设置大多Unix-Like系统，都提供了限制每个进程和每个基本用户使用线程，文件和网络连接等系统资源的一些方法。ulimits防止单个用户使用太多的系统资源。有时，这些限制的默认值太小，这会导致MongoDB操作过程中出现一系列问题。 123#限制文件#/etc/security/limits.conf#/etc/security/limits.d/ 资源利用mongod和mongos每次使用线程和文件描述符来跟踪连接和管理内部操作。 通常情况下，所有的mongod和mongos实例： 利用每一个文件描述符和线程来跟踪每个即将到来的连接； 将每个内部线程或pthread作为一个系统进程来跟踪。 mongod mongod实例使用的每个数据文件都有一个文件描述符； 当storage.journal.enabled为true是，mongod进程实例使用的每个日志文件都有一个文件描述符； 在复制集中，每个mongod保持一个连接复制集中所有其他集合成员的连接。 mongos mongos实例与每个分片都保持一个连接池，所有mongos可以重用连接，这样因为不用建立新连接，从而能快速的满足请求； 通过限制连接数，可以防止mongos因在mongod实例上创建太多连接而产生级联效应。 资源限制的设置ulimit是指每个user使用各种资源的限制值。因此，无论你的mongod实例是以单个用户多进程执行还是以多mongod进程执行，都可以看到对这些资源的连接。 ulimits有hard和soft两个方式。 hard：是指用户在任何时候都可以活动的进程的最大数量，这是上限。没有任何non-root进程能够增加hard ulimit； soft：是对会话或进程实际执行的限制，但任何进程都可以将其增加到hard ulimit的最大值。 较低的soft limit可能无法创建新线程(thread)，如果连接数太高，则关闭错误连接。因此，将soft和hard的值都设置为推荐值是非常重要的。 修改ulimit设置之后，要重启程序修改值才会有效。可通过/proc文件系统查看运行进程当前的限制值。 使用ulimit对系统限制的改变在系统重启后都会恢复到默认值。需要修改其它文件来确保修改一直生效。 ulimit 123456789101112131415161718ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 7170max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 1024pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 7170virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited 修改ulimit 123456789#-f (文件大小)#-t (cpu 时间)#-v (虚拟内存)#-n (单个进程文件打开数)#-m (memory size)#-u (可打开的进程/线程)ulimit -t unlimitedulimit -u 64000 配置和维护(maintenance)Run-time databases configurationcommand line和configuration file interfaces为MongoDB管理员提供了控制数据库系统操作的大量选项和设置。 使用配置文件启动MongoDB实例： 12mongod --config /etc/mongod.confmongod -f /etc/mongod.conf 配置数据库mongodb的配置文件从MongoDB3.0以后使用YAML格式。 1234567891011121314151617vim /etc/mongod.confprocessManagement: fork: truenet: bindIp: 127.0.0.1 port: 27017storage: dbPath: /var/lib/mongodbsystemLog: destination: file path: "/var/log/mongodb/mongod.log" logAppend: truestorage: journal: enabled: true 对于大多数以standalone模式运行的servers，以上是一个足够的基本配置。Unix-Like操作系统需要以超级用户(root)权限才能运行端口小于1024的程序。 安全考虑(security consideration)下面的配置选项集合对于限制对于mongod实例的访问非常有用。 123456net: port: 27017 bindIp: 127.0.0.1,192.168.1.11security: authorization: enabled 复制集和分片配置(replication and sharding configuration)复制集的配置非常简单，只需要replSetName在集合中的所有成员具有一致的副本集名字。 12replication: replSetName: zhang 开启副本集认证： 12345678910#利用openssl生成keyFileopenssl rand -base64 256 &gt; /dir/path/mongodb/keyFilesecurity: replSetName: zhang keyFile: /dir/path/mongodb/keyfilechown -R mongod:mongod /dir/path/mongodb 设置keyFile启用身份认证，并为复制集成员在相互身份认证时使用的认证文件指定一个密钥文件。密钥文件的内容是任意的，但在复制集中的所有成员和连接到该集合的mongos实例之间必须相同。不然怎么能认证通过呢。秘钥文件的大小必须小于1KB，并且只能包含base64集中的字符，并且此密钥文件在Unix系统上必须not have group或not have world permissions。 分片配置(sharding configuration)分片要求配置服务器和分片服务器的Mongod实例具有不同的mongod配置文件。配置服务器存储集群的元数据(metadata)，而分片服务器存储数据(data)。 在配置文件中给mongod实例配置配置服务器(config-server)，给sharding.clusterRole指定配置服务器。 12345678910#配置config-servernet: bindIp: 192.168.1.11 port:27001replication: replSetName: zhangsharding: clusterRole: configserver#configserver必须要是一个部署的副本集 在同一个系统上运行多个数据库实例(multiple database instances)在许多情况下，在单个系统(single system)上运行多个数据库实例是不推荐的。 但可能由于一些部署或者测试的目的，你需要在单个系统上运行多个mongod实例。在这些情况下，请为每一个mongod实例使用一个基本的配置文件，但要额外配置如下值： dbpath(必须); pidFilePath(必须); systemLog(非必须，但建议开启); 栗子： 1234567891011121314151617181920212223242526#mongod_27017实例vim /etc/mongod_27017.confsystemLog: path: /var/log/mongod_27017.logstorage: dbPath: /var/lib/mongodb27017processManagement: pidFilePath: /var/lib/mongodb27017/mongod_27017.pid#mongod_27018实例vim /etc/mongod_27018.confsystemLog: path: /var/log/mongod_27018.logstorage: dbPath: /var/lib/mongodb27018processManagement: pidFilePath: /var/lib/mongodb27018/mongod_27018.pid##启动实例mongod -f /etc/mongod_27017.confmongod -f /etc/mongod_27018.conf 诊断配置(diagnostic configuration)以下配置选项可控制各种mongod行为，用以诊断的目的： operationProfiling.mode设置database profiler level。profiler在默认情况下不处于活动状态，因为它本身可能会影响性能。除非启用它，否则不会对查询进行分析； operationProfiling.slowOpThresholdMs配置慢操作的阈值以确定查询是否慢，用以作为分析器记录日志的目的。默认阈值是100ms； systemLog.verbosity控制mongod写入日志的日志输出量。只有在遇到未在正常日志记录级别中反映的问题是才启用此选项。 升级(upgrade)到最新的MongoDB修订(revisions)提供了security patches、bug fixes以及不包含任何反向破坏更改的新的或更改的功能。但是，最新版本也可能存在一些兼容性问题，请注意。 升级之前(before upgrading) 确保备份了最新的数据集； 有关特定MongoDb版本的特殊事项和兼容性问题，请注意查看； 如果你的安装包包括了复制集，在升级期间预定维护窗口(maintanence window)。 升级程序(upgrade procedure)在升级之前请一定要备份所有数据！ 按照如下步骤升级： 对于使用认证的部署，首先升级所有的MongoDB drivers； 升级分片集群； 升级任一standalone实例； 升级不属于分片集群的任一副本集。 升级一个MongoDB实例要升级mongod或mongos实例，使用如下方法之一： 使用操作系统的包管理工具和官方MongoDB包进行升级(推荐的方法)； 使用新二进制文件替换现有二进制文件来升级实例。 替换现有二级制文件(replace the existing binaries)在升级MongoDB前请一定备份你的所有数据！ 首选的升级方式是使用包管理工具和官方的MongoDB包。 通过替换现有二进制文件来升级mongod或mongos实例，执行如下操作： 下载最新MongoDB二进制文件到本地，并解压缩到MongoDB安装目录； 关闭实例； 替换二进制文件； 重启实例。 升级分片集群 禁用分片集群的平衡器(blancer)； 升级配置服务器(config-server)； 升级每个分片； 升级每个mongos实例； 重新启用平衡器。 升级复制集若要升级复制集，请单独升级每个副本集成员。从Secondary开始，最后以Primary结束。 升级SECONDARY 升级SECONDARY的mongod实例； 升级一个Secondary之后，在升级下一个实例之前，请等待Secondary恢复(recover)到SECONDARY state。使用rs.status()命令来检查复制集成员的状态。 升级PRIMARY 使用rs.stepDown命令来退出primary，以启动正常的故障转移过程； 查看是否有另外的SECONDARY节点成为了PRIMARY节点； 关闭并升级实例。 管理mongod进程开启mongod进程1234567891011121314151617mongod#指定数据目录mongod --dbpath /dir/mongodb/#指定TCP端口mondod --port 12345#将mongod以守护进程的方式启动mongod --fork --logpath /var/log/mongod.log#其他选项mongod --help 停止mongod进程1234567891011121314151617#使用shutdownServer()use admindb.shutdownServer()#使用--shutdownmongod --shutdown#使用ctrl+cctrl+c#使用kill#千万不要使用kill -9(SIGKILL)来终止mongodkill mongod_pidkill -2 mongod_pid 停止一个复制集步骤： 检查SECONDARY的oplog的时间戳； 如果从节点的时间戳落后于主节点10s内，mongod将会返回不会被关闭的消息。你可以传递一个timeoutSecs参数给shutdown命令来等待从节点追上主节点； 一旦从节点追上进度或60s后，主节点将会关闭。 强制关闭复制集：db.adminCommand( { shutdown: 1, force: true } ) 如果没有节点能立刻更新到最新的数据，发送shutdown加上timeoutSecs参数来在指定的时间内保持对从节点的检查。如果在分配的时间内有任意的一个从节点追上，主节点将会关闭。反之，主节点不会关闭。 1234db.adminCommand(&#123; shutdown: 1, timeoutSecs: 5 &#125;)#或db.shutdownServer(&#123; timeoutSecs: 5&#125;) 终止(Terminate)运行的操作MongoDB提供了两种方法来终止正在运行的操作。 maxTimeMS() db.killOp() maxTimeMS()maxTimeMS()方法给一个操作(operation)设置了时间限制(time limit)。这个时间单位默认是毫秒(ms)。当这个操作达到了指定的时间限制时，MongoDB将在下一个中断点(interrupt point)中断这个操作。 栗子： 123456789101112131415db.location.find( &#123; "town": &#123; "$regex": "(Pine Lumber)", "$options": 'i' &#125; &#125; ).maxTimeMS(30)db.runCommand( &#123; distinct: "collection", key: "city", maxTimeMS: 45 &#125;) killOpkillOp()方法将在下一个中断节点中断正在运行的操作。killOp()方法通过操作ID(operation ID)来标识目标操作。 栗子： 12345db.killOp(&lt;opID&gt;)#查看正在运行的操作db.currentOp() 注意：终止正在运行的操作时一定要谨慎！只使用db.killOp()方法来终止由客户端发起的操作，而不要终止内部数据库(internal database)的操作。 轮询(rotate)日志文件当使用--logpath选项或systemLog.path设置时，mongod或mongos实例会将所有活动和操作的实时账户报告给日志文件。默认情况下，只有当使用了logRotate命令，或者mongod或mongos进程从操作系统接收到一个SIGUSR1信号时，才会进行日志轮询响应。 MongoDB的标准日志轮询方法会存档当前日志文件并启动一个新的日志文件。为此，mongod或mongos实例将通过ISODate日期格式的UTC时间戳来重命名当前日志文件。然后它会打开一个新的日志文件，关闭旧的日志文件，并将所有新的日志发送到新的日志文件。 你也可以通过配置MongoDB的systemLog.logRatate或--logRotate选项，来支持Unix/Linux的日志轮询功能。最后，你可以使用--syslog选项来配置mongod发送日志数据到系统日志。在这种情况下，你可以选用其他的日志轮询工具。 默认日志轮询行为在mongo shell中轮询日志： 123456789101112131415#开启一个实例mongod -v --logpath /var/log/mongodb/test01.log#列出日志文件ls /var/log/mongodb/test01.log*#轮询日志文件mongo&gt;use admin&gt;db.runCommand(&#123; logRotate: 1 &#125;)#查看新的日志文件ls /var/log/mongodb/test01.log*#new: test01.log#old: test01.log-2018-01-11T08-22-50 使用--logRotate reopen选项轮询日志： 1234567mongod -v --logpath /var/log/mongodb/test01.log --logRotate reopen --logapendls /var/log/mongodb/test01.log*mongo&gt;use admin&gt;db.runCommand(&#123; logRotate: 1 &#125;) 系统日志轮询(Syslog log rotate)1mongod --syslog 使用SIGUSR1强制日志轮询对于基于Unix/Linux的系统，可以使用SIGUSR1信号来轮询单个进程的日志。 1kill -SIGUSR1 &lt;mongod-pid&gt; 数据中心意识(data center awareness)MongoDB部署中的分离(segregation)操作MongoDB拥有许多特性，包括允许数据库管理员和开发者在部署数据库的过程中通过一些功能或地理组群对数据库应用进行分割操作。 MongoDB支持跨越不同维度的操作的分段，这可能包括了在单个数据中心(single data center)的部署中的多数据中心(multi-date center)部署、机架、网络或电源电路的多个数据中心和地理区域。 MongoDB还支持基于功能或操作参数的数据库分离操作，以确保某些mongod实例仅用于报告工作负载，或只在特定的分片上分离集合的某些高频部分。 特别是在MongoDB中你可以： 确保写操作传播到复制集的特定成员； 确保复制集中的特定成员响应了查询操作； 确保分片键在具体范围上的平衡，并且驻留在特定的分片上。 区域(zone)管理分片区域(manage shard zones) 按位置分割数据(segementing data by location) 为SLA或SLO改变分层硬件 按应用程序或客户分割数据 Distributed Local Writes for Insert Only Workloads 管理分片区域 MongoDB备份方案(backup methods)在生存中部署MongoDB时，如果发生数据丢失的事件，你应该指定一个捕获和恢复备份的策略(strategy)。 back up with MongoDB cloud manager or Ops manager MongoDB Cloud Manager Ops Manager 复制底层数据文件进行备份(back up by copying underlying data files) 使用文件系统快照备份(back up with filesystem snapshots) 你可以通过复制MongoDB的底层数据文件来创建MongoDB部署的备份。如果MongoDB储存其数据文件的卷(volume)支持时间点快照(point-in-time snapshots)，则可以使用这些快照在某个时刻创建MongoDB系统的备份。文件系统的快照是一个操作系统的卷管理器的功能，并没有具体到MongoDB。通过文件系统快照，操作系统将卷的快照用作数据备份的基准。快照的机制取决于底层的存储系统。例如，在Linux上，逻辑卷管理器(LVM)可以创建快照。 要获得运行中的MongoDB进程的正确快照，必须启用日志记录(jorunaling)，并且日志必须与其它MongoDB数据文件存储在相同的逻辑卷上。如果没有启用日志记录，则无法保证快照将是一致有效地。 为了获得分片集群一致的快照，你必须禁用平衡器(balancer)和捕捉每一个分片的快照以及大约在同一时刻的配置服务器。 使用cp或scp备份 如果你的系统不支持快照功能，则可以使用cp，rsync或类似的工具直接复制文件。由于复制多个文件不是原子操作，因此你必须在复制文件之前停止对mongod的所有写入。否则，你将复制处于无效状态的文件。 复制底层数据而产生的备份不支持复制集的时间恢复节点，并且难以管理更大的共享集群。此外，这些备份很大。因为它们包括索引和复制底层存储填充和分片。相反，mongodump会创建较小的备份。 使用mongodump备份 如果在mongodump创建备份的同时，应用程序对数据进行修改，那么mongodump将会与这些应用竞争资源。 mongodump从一个MongoDB数据库中读取数据，并创建高保真度(high fidelity)的BSON文件。mongorestore工具可使用这个文件来进行MongoDB数据库恢复。mongodump和mongorestore是用于备份和恢复小型MongoDB部署的简单和高效的工具，但对于捕获较大的系统并不理想。 mongodump和mongorestore针对正在运行的mongod进程进行操作，可以直接操纵底层的数据文件。默认情况下，mongodump不会捕获local database数据库的内容。 mongodump只捕获数据库中的文档(documents)，用以给备份节省空间，但mongorestore或mongod必须在恢复数据之后重建索引。 当连接到MongoDB实例时，mongodump可能会对MongoDB的性能产生不利影响。如果你的数据大小大于系统内存，查询可能会将工作单元从内存中推开，从而导致页面错误。 当mongodump在捕获输出时，应用程序可以继续修改数据。对于复制集来说，mongodump提供了--oplog选项来用以在mongodump操作期间包含数据的oplog条目。这允许相应的mongorestore操作去还原所捕获的oplog。 然而，对于复制集来说，请考虑使用MongoDB Cloud Manager 或 Ops Manager来备份。 使用文件系统快照进行备份和恢复(back up and restore with filesystem snapshots)使用系统工具创建MongoDB系统的备份，诸如LVM，或block-level备份方法。使用系统工具来创建MongoDB数据文件的设备的副本。这些方法完成迅速、工作可靠，但是需要在MongoDB之外进行额外的系统配置。 快照综述(snapshots overview)快照的工作方式是在实时数据(live data)和一个特定快照卷之间创建指针(pointer)。这个指针在理论上等同于硬链接(hard link)。作为工作数据偏离的快照，快照过程使用写时复制(copy-on-write)策略。结果，快照又只存储修改的数据。 创建快照后，在文件系统上挂载(mount)快照镜像，并从中复制数据。生成的备份包含所有数据的完整副本。 Valid database at the time of snapshot 当快照生成时数据库必须有效。这就意味着数据库所接收的所有写入(write)都需要完整的写入磁盘————无论是journal还是数据文件。如果备份发生时磁盘上没有写入(write)，备份将不反映这些更改。 对于WiredTiger storage engine，数据文件反映了最后一个检查点(last checkpoint)的一致状态。每2GB的数据或每分钟就会出现检查点。 Entire disk image 快照创建一个整个磁盘镜像的镜像。除非你需要备份你的整个系统，否则考虑隔离(isolate)你的MongoDB数据文件、journal，并配置一个不包含任何其他数据的逻辑磁盘。或者，将所有的MongoDB数据文件保存在一个专用的设备上，这样你就可以在没有重复(duplicating)和无关(extraneous)数据的情况下进行备份。 Site failure precaution 确保将数据从快照复制到其他系统。这确保了在站点故障(site failure)的时候数据是安全的。 No incremental backups 本教程不包含增量备份(incremental backups)的过程。虽然不同的快照方法提供了不同的功能，但下面列出的LVM方法不提供捕获增量备份的任何容量。 Snapshots with journaling 如果你的mongod实例启用了journaling，则可以使用任何类型的文件系统和volume/block level快照工具来创建备份。 如果你在基于Linux的系统上管理你自己的基础架构，请使用LVM配置你的系统以提供磁盘包并提供快照功能。 在Linux上使用LVM进行备份和还原生产备份系统必须考虑一些特定环境的应用程序特定需求和因素。 Crete a snapshot 确保你创建的快照具有足够的空间来考虑数据的增长； 如果快照超出了空间，快照镜像将无法使用。请放弃这个逻辑卷并创建另外一个； 命令执行完毕时快照将存在。你可以随时直接从快照进行还原，也可以创建新的逻辑卷并从此快照还原到备用镜像； 虽然快照对于快速创建高质量的备份非常好，但它们并不是理想的作为存储备份数据的格式； 快照通常取决于并位于与原始磁盘镜像相同的存储基础架构上。因此，将这些快照存档并将其存储在别处至关重要。 12345#下面的这个vg-name指卷组名，这个卷组首先需要建立#系统卷组和设备的位置和路径可能因LVM的配置二略有不同#此大小不反映数据大小lvcreate --size 1G --snapshot --name mongodb-snap20180111 /dev/vg-name/mongodb Archive a snapshot 创建好snapshot之后，挂载mount快照并将数据复制到单独的存储中。 压缩快照： 12umount /dev/vg-name/mongodb-snap01dd if=/dev/vg-name/mongodb-snap01 | gzip &gt; mongodb-snap01.gz Restore a snapshot 同样适用LVM进行还原。 12345#lv-mongodb, vg0-vgnamelvcreate --size 1G --name mongodb vg0gzip -d -c mongodb-snap01.gz | dd of=/dev/vg0/mongodbmount /dev/bg0/mongodb /dir/path 还原的快照中有一个陈旧的mongo.lock文件，如果你没有从快照中删除此文件，那么MongoDB可能会认为锁文件指示的是不正常的关闭。如果你开启了storage.journal.enabled，但没有使用db.fsyncLock()的话，那不需要删除mongo.lock文件，反之，删除它。 Restore directly form a snapshot 不使用gz压缩文件下还原备份。 1234umount /dev/vg-name/mongodb-snap01lvcreate --size 1G --name mongodb vg0dd if=/dev/vg0/mongodb-snap01 of=/dev/vg0/mongodbmount /dev/vg0/mongodb /dir/path Remote backup storage 可以使用组合的进程和SSH实施离线备份。 12345umount /dev/vg-name/mongodb-snap01dd if=/dev/vg0/mongodb-snap01 | ssh user@host gzip &gt; /dir/path/mongodb-snap01.gzlvcreate --size 1G --name mongodb vg0ssh user@host gzip -d -c /dir/path/mongodb-snap-01.gz | dd of =/dev/vg0/mongodbmount /dev/vg0/mongodb /dir/path 使用单独卷上的Journal日志文件或没有Journal日志文件进行备份实例从MongoDB3.2开始，为了使用WiredTiger对MongoDB实例进行volume-level备份，数据文件和Journal日志文件不再要求驻留在一个卷上。 如果你的mongod实例没有使用Journal，或者启用了将Journal志文件放置于一个单独的卷上，则必须刷新(flush)对磁盘的所有写入，并在备份期间锁住数据库用以阻止写操作。如果有复制集(replica set)配置，那么你可以在SECONDARY上不接收读取用以备份数据。 1. 刷新写入磁盘并锁定数据库以防止进一步的写入： 12#锁住数据库db.fsyncLock(); 2. 使用快照备份数据库： 3. 解锁数据库： 12#解锁数据库db.fsyncUnlock(); 使用MongoDB工具进行备份和恢复(back up and restore with MongoDB tools)使用MongoDB提供的备份还原工具——mongodump和mongorestore来处理BSON data，对于创建小型部署的备份是很有用的。对于弹性(resilient)备份和非破坏性(non-disruptive)备份，使用文件系统或块级磁盘快照。 因为mongodump和mongorestore操作通过与正在运行中的mongod实例进行交互(interacting)，它们会影响正在运行的数据库的性能(performance)。这些工具不仅会为正在运行的数据库实例创建流量，还会强制数据库通过内存读取所有的数据。当MongoDB读取不经常(infrequently)使用的数据时，它会驱逐(evict)频繁(frequently)访问的数据，导致数据库正常工作负载的性能下降。 当使用MongoDB’s tools 来备份你的数据时，考虑如下建议： 标签文件(label file)，以便你可以识别备份的内容以及备份所反映的时间点 如果对你来说，mongodump和mongorestore对性能的影响是不可接受的，请使用替代备份策略——filesystem snapshot或MongoDB CloudManager 使用--oplog去捕获在mongodump期间的传入写(write)操作，以确保备份一致性的数据状态 通过将备份文件还原到测试环境中，以确认备份是可用的 MongoDB toolsMongoDB工具介绍及区别： mongoexportmongoexport is a utility that produces a JSON or CSV export of data stored in a MongoDB instance. mongoimportThe mongoimport tool imports content from an Extended JSON, CSV, or TSV export created by mongoexport, or potentially, another third-party export tool. mongodumpmongodump is a utility for creating a binary export of the contents of a database. mongodump can export data from either mongod or mongos instances.mongodump excludes the content of the local database in its output.The mongodump utility backs up data by connecting to a running mongod or mongos instance. mongorestoreThe mongorestore program writes data from a binary database dump created by mongodump to a MongoDB instance. 步骤(Procedures)使用mongodump备份 `mongodump·备份数据库，如果数据库启用了访问控制，则必须拥有每个备份的数据库查询的权限。内置的备份角色提供了执行任何和数据库备份有关所需的权限。 这就意味着你使用mongodump的user必须要对所备份的数据库有读取权限。 mongodump能够为整个服务器、数据库或集合创建备份，或者使用查询仅备份集合的一部分。 mongodump默认排除local数据库。 mongodump必须要能够连接到正在运行的mongod或mongos实例。默认连接为127.0.0.1:27017。 mongodump默认创建在当前目录下创建./dump备份文件。 如果mongodump备份目录中已经存在备份数据目录，那么mongodump将会覆盖它们。 指定认证库来认证你的用户名和密码。 使用oplog进行时间点操作 在mongodump中使用--oplog选项来收集oplog条目，用以在副本集中构建数据库的实时快照。 使用--oplog，mongodump会从源数据库复制所有的数据，包括备份开始到结束这段时间所有的oplog记录。 在mongorestore还原时使用--oplogReplay选项，允许你还原特定时间节点的备份。这就对应在mongodump期间oplog的记录。 123456789101112131415161718192021#127.0.0.1:27017 ./dumpmongodump#--host,-h --portmongodump -h mongodb.example.net --port 27107mongudump -h 127.0.0.1 --port 27018#-o, --outmongoodump -o /var/mongodb_backup/mongodump --host 127.0.0.1 --port 27017 --out /var/mongodb_backup/#--collection, --dbmongodump --db zhang --out /var/mongodb_backup/zhangmongodump --db zhang --collection test#--authenticationDatabasemongodump --port 27018 -u zhang -p "passwd" --authenticationDatabase admin -d zhang -o /var/mongodb_backup/zhang 使用mongorestore还原若要将数据还原到启用了访问控制的MongoDB部署，如果备份数据不包括system.profile集合数据，则restore角色提供了对数据库的访问权限。 如果备份数据包含了system.profile集合并且目标数据库不包含system.profile集合，那么mongorestore会去创建这个集合即使mongorestore并没有还原system.profile文档。因此，用户就需要额外的权限才能在system.profile集合中上执行createCollection和convertToCapped。 如果使用--oplogReplay，这个restore角色还不足以重放oplog。所以如果需要重放oplog，请使用一个能够重放oplog的角色。 1234567mongorestore /var/mnogodb_backupmongorestore /var/mnogodb_backup --oplogReplaymongorestore --port 27018 -u zhang -p "passwd" --authecticationDatabase admin -d zhang /var/mongodb_back/zhang 批量化操作mongo shell(EOF)1234567for coll in &#123;collection1,collection2,...&#125;do mongo host:port/db -u x -p xx &lt;&lt; EOF use db db.$coll.drop() EOFdone 从MongoDB备份中还原副本集你不能将单个数据集(data set)还原为三个新的mongod实例，然后为此创建一个副本集(replication set)。如果你将数据集复制到每个mongod实例，然后创建副本集，则MongoDB将强制SECONDARY执行initial sync。 向一个单一副本集节点中还原数据(Restore Database into a Single Node Replica Set) 获取备份数据库文件 使用备份数据库文件作为数据库路径启动一个mongod实例 1234567891011#方法1，直接启动mongod --dbpath /dir/path/mongodump --replSet &lt;replName&gt;#方法2，使用配置文件启动，推荐vim /etc/mongod.confstorage: dbPath: /dir/path/mongodumpreplication: replSetName: zhang 连接到mongo shell 初始化这个新的副本集 12#对于有且仅有一个成员的副本集使用rs.initiate()rs.initiate() 向副本集中添加成员(Add Members to the Replica Set)MongoDB对于还原副本集SECONDARY节点提供了两种选择： 手动复制数据库文件到数据目录 允许initial sync 建议： 如果备份的数据库文件很大，那么initial sync可能需要很长的时间才能完成。对于大型数据库，最好将数据库文件复制到每台主机上。 Copy Database File and Restart mongod Instance Shut down the mongod instance that you restored 使用 --shutdown 或 db.shutdownServer()来确保一个正常干净的关闭 复制Primary的数据目录到每个从节点 Start the mongod instance that you restorerd Add the secondaries to the replica set 1PRIMARY&gt;rs.add() Update Secondaries using Initial Sync 确保副本集成员的数据目录为空 将每个潜在成员添加到副本集 备份和还原分片集群(sharded cluster) 通过文件系统快照(fs snapshots)备份一个分片集群 通过Database Dumps备份一个分片集群 Schedule Backup Window for Sharded Clusters 还原一个分片集群 从意外关闭中恢复(Recover a standalone after an unexpected shutdow)当一个standalone模式的mongod实例关闭了journaling功能后，一个unclean的shutdown可能会导致数据处于不一致的状态。当unclean shutdown之后，如果在dbPath下存在一个非空的mongod.lock文件，则mongod实例会记录如下信息： Dectected unclean shutdown - mongod.lock is not empty 这样的话你必须要修复你的数据库，才能正常的启动mongod。 警告：不要用如下方法处理副本集 unclean shutdown。相反，你应该从备份或者从另一个副本集的成员恢复。 默认情况下，MongoDB在启用journaling的情况下运行，以防止发生unclean shutdown时数据不一致的问题。 使用运行mongod实例的那个用户来进行修复，避免由权限不一致而导致的新问题。 Create a backup of the data files Start mongod with –repair 监控(Monitoring)MongoDB监控是数据库管理的重要组成部分，充分了解MongoDB的运行状态，并在没有危机的情况下维护和部署。此外，了解MongoDB的正常操作参数将允许你在问题升级成为故障前诊断他们。 Monitoring for MongoDB Monitoring Strategies(策略)有三种方法可以从运行中的MongoDB实例中收集状态信息： MongoDB提供的一组实时上报程序，提供数据库活动的实时报告； 数据库命令以更大的保真度返回有关当前数据库状态的统计信息； MongoDB Atlas，MongoDB Cloud Manager； 每个策略在不同的情况下都是很有用的，所以它们能够很好地进行互补。 MongoDB Reporting ToolsUtilities MongoDB提供了许多可以返回活动统计信息的实用工具，这对于诊断问题和评估操作非常有用。 mongostat mongostat按类型捕获并返回数据库操作的计数(insert,query,update,delete…) mongotop mongotop通过类型捕获和返回数据库操作(insert,query,update,delete) CommandsMongoDB包含了许多上报数据库状态的命令。这些命令可以提供比上面的实用程序更精细的粒度级别。考虑在脚本和程序中使用它们的输出来开发自定义警报。db.currentOp方法是一个识别当前数据库实例正在进行的操作。 db.serverStatus() db.serverStatus()，返回数据库状态的一般概述，详细的磁盘使用，内存使用，连接，journaling日志和索引访问。它返回快速并不影响MongoDB性能。 db.stats() db.stats()，提供了database上的统计信息。返回使用的存储量，数据库包含的数据量及对象，collection和索引计数器。 db.collection.stats() db.collection.stats()，提供了collection上的统计信息。包含集合中的对象数量，结合大小，集合磁盘空间用量，索引信息。 rs.status() rs.status()，返回一个复制集状态的概述。 第三方工具许多第三方(third party)工具支持对MongoDB的监控。 Nagios Zabbix Ganglia Motop … Monitor MongoDB with SNMP on LinuxSNMP is only available in MongoDB Enterprise Monitor MongoDB Windows with SNMP MongoDB索引Indexes 索引支持在MongoDB中高效地(effecient)执行查询。没有索引，MongoDB就必须采取collection scan。扫描每个集合中的每个文档，用以匹配查询。如果查询存在适当的索引，则MongoDB可以使用该索引来限制它必须检查的文档数量。 索引是特殊的数据结构，将集合数据集中的一小部分以易于遍历(traverse)的形式存储。索引存储特定字段或字段集的值，按字段值排序。索引条目的排序支持高效的相等匹配和基于范围的查询操作。除此之外，MongoDB可以使用索引中的排序返回排序后的结果。 从根本上来说(fundamentally)，MongoDB中的索引类似于其他数据库的索引。MongoDB在collection级别定义索引，并支持集合的文档的任何字段或子字段上的索引。 默认_id索引 在创建一个collection期间，MongoDB在_id字段上创建一个唯一的索引。你也可以自定义_id的值。你不能在_id字段上删除此索引。 创建一个索引 db.collection.createIndex方法只有在同一规范不存在时才创建索引。 1db.collection.createIndex(&lt;key and index type&gt;, option) 索引类型MongoDB提供了许多不同的索引类型来支持特定类型的数据和查询。 Single Field 除了MongoDB定义的_id索引，MongoDB还支持在文档的单个字段上创建用户自定义的升序(ascending)/降序(descending)索引。 对于单字段索引和排序操作，MongoDB可以在任何方向遍历索引。 Compound(复合) Index MongoDB也支持多个字段的用户自定义索引。 Multikey Index MongoDB使用多键索引来索引存储在数组中的内容。 Geospatial(地理空间) Index 为了支持对地理空间坐标数据的有效查询，MongoDB提供了两个特殊的索引：2d index返回平面几何的2D索引；2dsphere index返回球形几何结果。 Text Index MongoDB提供了一个文本(text)类型索引，用以支持搜索集合中的字符串内容(string content)。 Hashed(散列) Index 为了支持基于散列的分片，MongoDB提供了散列索引类型，它索引字段值的散列值。但只支持相等的匹配，而不能支持基于范围的查询。 Index Properties(特性) Unique Index 索引的唯一性是MongoDB拒绝索引字段的重复值。 Partial Index 部分索引仅索引复合指定过滤器表达式的集合中的文档。 Sparse(稀疏) Index 索引的稀疏属性确保索引仅包含具有索引字段的文档的条目，跳过没有索引字段的文档。 TTL Index TTL索引是MongoDB可以用来在一定时间后自动从集合中删除文档的特殊索引。对于某些类型的消息，如机器生成的事件数据，日志和会话信息等，只需在数据库库中保存有限的时间，这是非常理想的。 Index Use索引能够提高读操作的效率。 Index and Collation要使用索引进行字符串比较，操作还必须指定相同的排序规则。 Coverd Query当查询条件和查询投影仅包含索引字段时，MongoDB将直接从索引返回结果，而不扫描任何文档或将文档带入内存。 Single Filed Index Compound Index Multikey Index Text Index 2dsphere Index 2d Index geoHaystack Index Hashed Index Index Property Index Build Operation on a Populated Collection Index Intersection Manage Index Measure Index Use Indexing Strategy Index Reference MongoDB存储Storage FAQ: MongoDB Storage: https://docs.mongodb.com/v3.4/faq/storage/ 存储引擎(storage engine)是MongoDB管理数据库主要的组件。 journal日志，用于数据库不正常关闭时修复数据库。有几种可选的配置项，用以平衡数据库的性能和可用性。 GridFS是一个适合处理大文件的多功能的存储系统，例如那些超过16MB文档大小限制的文件。 Storage Engine存储引擎是数据库的组件，负责管理数据库在内存(in-memory)和磁盘中(on-disk)两种存储方式。由于不同的存储引擎在特定的工作负载下有更好的性能，所以，为你的应用程序选择一个适当的存储引擎会提高性能。 WiredTiger是从MongoDB3.2开始的默认存储引擎。它非常适合大多数工作负载，并推荐使用它来进行部署。WiredTiger提供了文档级并发模型，检查点和要说等特性。 MMAPv1是一个原始的MongoDB存储引擎，它是MongoDB3.2以前的默认存储引擎。它在大量读取和写入以及更新方面的工作负载表现良好。 In-Memory要在MongoDB Enterprise中才能获取。它不是将文档保存在磁盘上，而是将它们保留在内存中，以获得可预测的数据延迟。 WiredTiger存储引擎MongoDB3.2以后使用WiredTiger存储引擎作为默认存储引擎。 12345678mongod --storageEngine wiredTiger#或vim /etc/mongod.confstorage: engine: wriedTiger 文档级别并发(currency)WiredTiger使用文档级并发来控制写操作。因此，多个客户端可以同时修改一个集合中的不同文档。 对于大多数读写操作，WiredTiger使用乐观的并发控制。WiredTiger仅在global、database和collection-levels使用intent lock。当存储引擎检测到两个操作之间的冲突时，其中一个操作将引发写冲突，从而导致MongoDB透明地重试该操作。 快照和检查点WiredTiger users multiVersion Concurrency Control(MVCC).在操作开始时，WiredTiger向事务提供数据的实时快照。快照显示内存中数据的一致性视图。 当写入磁盘时，WiredTiger将快照中的所有数据以一致性的方式跨越所有数据文件写入磁盘。持久(durable)的数据充当数据文件中的检查点。检查点确保数据文件与最后一个检查点保持一致性，并包括最后一个检查点。 MongoDB配置WiredTiger来创建检查点(即将快照数据写入磁盘)，间隔时间为60s，或2G日志数据。 在写入新检查点期间，前一个检查点仍然有效。 当WiredTiger的元数据表被原子地更新以引用新的检查点，新的检查点将变得可访问和永久。一旦新检查点可以访问，WiredTiger就会从旧的检查点这种释放页面(free page)。 JournalWiredTiger采用预写事务日志联合检查点，用以确保数据的持久性(durability)。你也可以关闭journal功能来减少维护日志的开销。 WiredTiger日志坚持在检查点之间修改所有数据。如果MongoDB在检查点之间退出，它将使用日志重放自上一个检查点以来修改的所有数据。 WiredTiger journal使用snappy compression Library来进行压缩。 WiredTiger最小日志记录的大小是128Byte，如果日志记录小于等于128Byte，则WiredTiger不会压缩日志文件。 对于以standalone模式运行的mongo实例，关闭journal日志功能意味着当MongoDB意外地在检查点之前退出时，你将丢失一些数据修改。对于复制集成员，复制过程和恒提供足够的持久性保证。 Compression使用WiredTiger，MongoDB支持压缩所有的collections和indexes。通过使用CPU进行压缩，减少了储存空间的使用。 默认地，WiredTiger使用snappy compression library对所有的collections进行block压缩，对所有索引进行前缀(prefix)压缩。 对于collection，也可以使用zlib进行block压缩。可通过storage.wiredTiger.collectionConfig.blockCompressor设置压缩方法。对于index，使用storage.wiredTiger.indexConfig.prefixCompression关闭prefix压缩。 对于大多数工作负载，默认压缩设置平衡了存储效率和处理要求。 Memory Use对于WiredTiger，MongodB使用WiredTiger内部缓存和文件缓存。 从MongoDB3.4开始，WiredTiger内部缓存将使用一下两种类型中更大的一种： 50% of RAM minus 1GB 256MB WiredTiger内部缓存中的数据与磁盘上格式的数据使用不同的表现形式： 文件系统缓存的数据与磁盘上的格式相同，包括了对数据文件进行压缩的好处。操作系统使用文件系统缓存来减少磁盘I/O 指标加载在WiredTiger内部缓存有一个不同的磁盘上的数据表示格式，但仍然可利用 prefix index compression来减少内存使用。索引前缀压缩重复数据删除常用前缀的索引字段。 WiredTiger内存缓存的collection数据是未压缩的，并使用与磁盘格式不同的表现形式。block compression能够节省大量磁盘空间，但必须解压缩数据后服务器才能操作。 通过文件系统缓存，MongoDB自动使用 (WiredTiger缓存或其他进程不使用)空闲内存。 调整WiredTiger内部缓存的大小，避免将WiredTiger的内初缓存值增加到默认值之上。 1234567#命令行--wiredTigerCacheSizeGB#配置文件storage.wiredTiger.engineConfig.cacheSizeGB Change Standalone to wiredTigerMongoDB version 3.0 or later in order to use wiredTiger storage engine! 过程： mongod is running export data using mongodump create a data directory for the new mongod running with wiredTiger start mongod with wiredTiger upload the dumpdata using mongorestore Change Replica Set to wiredTigerReplica sets can have members with different storage engines.因此，你可以把所有成员的存储引擎更换为WiredTiger。MongoDB version 3.0 or later in order to use wiredTiger storage engine! 过程： shutdown the secondary member.–db.shutdownServer prepare a data directory for the new mongod running with wiredTiger start mongod with wiredTiger repeat the procedure for other replica set secodaries you wish to upgrade Change Sharded Cluster to wiredTigerif the shard is a standalone, see Change Standalone to wiredTiger;if the shard is a replica set, see Change Replica Set to wiredTiger. Change config server to wriedTiger如果你打算更新config server使用WiredTiger，那么必须全部更新！ 过程： disable the balancer–sh.disableBalancer() shutdown the third config server to ensure read-only metadata.–db.shutdownServer() export the data of the second config server with mongodump For the second config server, create a new data directory for use with WiredTiger. Stop the second config server.–db.shutdownServer() Start the second config server mongod with the WiredTiger storage engine option. Upload the exported data using mongorestore to the second config server. Shut down the second config server to ensure read-only metadata.–db.shutdownServer() Restart the third config server to prepare for its upgrade. Export the data of the third config server with mongodump For the third config server, create a new data directory for use with WiredTiger. Stop the third config server. Start the third config server with the WiredTiger storage engine option. Upload the exported data using mongorestore to the third config server. Export data of the first config server with mongodump. For the first config server, create a new data directory for use with WiredTiger. Stop the first config server. Start the first config server with the WiredTiger storage engine option. Upload the exported data using mongorestore to the first config server. Restart the second config server to enable writes to the sharded cluster’s metadata Re-enable the balancer.–sh.startBalancer() MMAPv1存储引擎 In-Memory存储引擎 Journaling为了在发生故障时提供持久性，MongoDB使用了县写日志记录到磁盘的日志文件。To provide durability in the event of a failure, MongoDB uses write ahead logging to on-disk journal files. journaling and the wiredTiger storage engine本节所指的log指的是WiredTiger的 write-ahead log(journal)，而不是MongoDB日志文件。 WiredTiger使用checkpoints在磁盘上提供一致的数据视图，并允许MongoDB从上一个checkpoint修复。然而，如果MongoDB在检查点之间以外退出，则需要使用journaling来修复上次检查点之后发生的信息。 使用journaling的修复过程： 在数据文件中查找上一个检查点的标识符(identifier) 在journaling文件中搜索与上一个检查点标识符匹配的记录 应用自上一个检查节点依赖journal文件中的操作 journal process通过journaling，WiredTiger为每个客户端启动的写操作创建一个journal记录。journal record包括有初始写入引起的任何内部写入操作。 例如，集合中文档的更新可能导致对index的修改，WiredTiger创建一个包含update操作及其相关index修改的单独的journal record。 MongoDB将WiredTiger配置为in-memory的buffering来存储日志记录。线程坐标来分配和复制到他们的缓冲区的一部分。所有日志记录高达128KB是缓存的。WiredTiger根据如下条件将journal record同步到磁盘。 每50ms MongoDB在WiredTiger中设置60s为间隔的用户数据检查点或2GBjournal数据已被写入，以先发生为准。 如果写操作包含有j:true的写关注点，则WiredTiger强制对journal文件进行同步。 MongoDB限制了journal文件大小为100MB，因此WiredTiger每100MB就会创建一个新的journal文件。当创建了一个新的journal文件时，WiredTiger会同步上一个journal文件。 在写操作之间，虽然日志记录保留在WiredTiger缓冲区中，但在mongod实例hard shutdown之后可能会丢失更新。 Journal FileMongoDB在数据库目录下创建一个journal子目录存放journal文件。名字为WiredTigerLog.&lt;sequence&gt;，从0000000001开始。如上图所示。 Journal文件包含对每一个写操作的记录。每个记录都有唯一的标识符。 MongoDB将WiredTiger配置为对journal数据使用快速压缩。最小日志大小为128KB，如果小于此，WiredTiger不会压缩此记录。最大大小为100MB，超过此，WiredTiger会创建一个新的journal文件。 MongoDB自动删除旧日志文件，以维护从上一个检查点恢复所需的文件。 Journaling and the MMAPv1 Storage Engine Journaling and the In-Memory Storage Engine Manage JournalingMongoDB uses write ahead logging to an on-disk journal to guarantee write operation durability. 启用journal后，如果MongodB意外退出，则程序可以恢复写入了journal日志文件的所有内容。MongoDB将在重启时重新应用写操作，并保持一致性。 过程 Enable journaling123456789mongod --jouranl##或vim /etc/mongod.confstorage: journal: enabled: true Disable journaling12345mongod --noJournal###或修改配置文件 警告不要在生产系统上禁用日记功能。如果在一个副本集上使用--noJournal关闭了journal日志，则还应该修改副本集配置文件。 Monitor journal status serverStatus Recover data after unexpected shutdown在奔溃后重启时，MongoDB会在服务器可用之前replay journal日志记录中的所有日志文件。 GridFSGridFS是一种用于存储和检索超过BSON文档大小限制值16MB的文件规范。 GridFS没有将单个文件存储到单个的文档中，而是将文件分割成部分(parts)或块(chunks)，并将每个块存储到单独的文档中。默认情况下，GridFS的块大小为255KB。也就是说，GridFS将文件分成255KB的块，最后一块大小就不确定了。 GridFS使用两个集合来存储文件。一个存储文件块(chunks)，另一个存储文件元数据(metadata)。 当你查询(query)GridFS文件时，驱动程序会根据需要重新组装这些块。你可对通过GridFS存储的文件执行范围查询。还可以从任意文件部分访问信息。 GridFS不仅可用于存储超过16MB的文件，还可用于存储需要访问的任何文件，而不必将整个文件加载到内存中。 何时使用GridFS在MongoDB中，使用GridFS存储大于16MB的文件。 某些情况下，在MongoDB数据库中存储大文件可能比在系统级文件系统上更有效。 如果文件系统限制了一个目录中的文件数量，则可使用GridFS存储所需的文件 当你想要访问大文件的部分信息时而不想将整个文件加载到内存中时，可使用GridFS收回文件的各个部分，而不必将整个文件读入内存 当你希望文件和元数据自动同步并部署在多个系统和设施中时，可使用GridFS 如果需要原子地(atomically)更新整个文件的内容，请不要使用GridFS。作为一种选择，你可以为每个文件存储多个版本，并在元数据中指定该文件的当前版本。 此外，如果文件都是小于16MB的BSON文件大小限制，则考虑手动存储在一个单文档中，而不必使用GridFS。 使用GridFS使用GridFS存储和检索文件，请使用如下任何一项： A MongoDB Driver The mongofile cmd-line tool GridFS集合GridFS把文件存储在两个集合里： chunks collection stores the binary chunks files collection stores the file’s metadata GridFS将这些集合放在一个普通的存储区(bucket)中，每个存储区前面加上名称。默认地，GridFS使用两个名为fs的存储区集合： fs.files fs.chunks 币可以选择一个不同的存储区名字，也可以在一个数据库中创建多个存储区。 The chunks collection块集合中的每个文档都表示一个独立的文件块。格式如下： 123456&#123; &quot;_id&quot;: &lt;ObjectId&gt;, &quot;files_id&quot;: &lt;ObjectId&gt;, &quot;n&quot;: &lt;num&gt;, &quot;data&quot;: &lt;binary&gt;&#125; 块集合中的文档包含如下字段： chunks._id The unique ObjectId of the chunk chunks.files_id The _id of the “parent” document chunks.n The sequence number of the chunk，GridFS从0开始标号所有块 chunks.data BSON Binary type file集合GridFS的file集合，格式如下： 1234567891011&#123; &quot;_id&quot;: &lt;ObjectId&gt;, &quot;length&quot;: &lt;num&gt;, &quot;chunkSize&quot;: &lt;num&gt;, &quot;uploadData&quot;: &lt;timestamp&gt;, &quot;md5&quot;: &lt;hash&gt;, &quot;filename&quot;: &lt;string&gt;, &quot;contentType&quot;: &lt;string&gt;, &quot;aliases&quot;: &lt;string array&gt;, &quot;metadata&quot;: &lt;any&gt;&#125; files._id The unique identifier for this document files.length The size of the document in bytes files.chunSize The size of each chunk in bytes files.uploadDate The date the document was first stored by GridFS files.md5 An MD5 hash of the complete file file.filename Optional. A human-readable name for the GridFS file file.contentType Optional. A valid MIME type for the GridFS file files.aliases Optional. An array of alias strings files.metadata Optional. The metadata field may be of any data type and can hold any additional information you want to store GridFS索引为了提高效率，GridFS在每个chunks and files collections上使用索引。 chunks索引GridFS使用一个唯一的、混合的索引。在chunks集合上使用files_id和n字段。 12345db.fs.chunks.find( &#123; files_id: myFileID &#125; ).sort( &#123; n:1 &#125;)#创建索引db.fs.chunks.createIndex(&#123; files_id: 1, n:1 &#125;, &#123; unique: true &#125;); files索引GridFS使用索引，在files集合上使用filename和uploadDate字段。 12345db.fs.files.find(&#123; filename: myFileName &#125;).sort(&#123; uploadDate: 1 &#125;)#创建索引db.fs.files.createIndex(&#123; filename:1, uploadDate: 1 &#125;); 分片GridFS如果需要分片GridFS数据存储，使用chunks集合设置: { files_id: 1, n:1} or { files_id: 1 }作为分片key索引。 不能对chunks集合使用hash分片。 files_id是一个ObjectId。 MongoDB安全Security MongoDB提供了各种特性(features)，如身份认证(authentication)、访问控制(access control)、加密(encryption)，以保护MongoDB部署。 Security Checklist 启用访问控制和强制认证 Enable Access Control and Enforce Authentication 可使用默认的MongoDB认证机制或现有的外部框架 配置基于角色的访问控制 Configure Role-Based Access Control 首先创建administrator，接着在创建其他用户 创建角色，定义一组用户所需的确切访问权限 加密通信 Encrypt Communication 配置MongoDB使用TLS/SSL加密连接 加密和保护数据 Encrypt and Protect Data 限制网络曝光 Limit Network Exposure 确保MongoDB运行在一个受信任的网络环境上，并限制MongoDB的监听接口 审计系统活动 Audit System Activity 跟踪对数据库配置和数据的访问和更改 使用专用用户运行MongoDB Run MongoDB with a Dedicated User 使用专用的操作系统用户账户运行MongoDB进程 使用安全配置选项运行MongoDB Run MongoDB with Secure Configuration Options MongoDB为了支持某些服务端操作执行：mapReduce,group,$where 如果你不使用这些操作，请关闭服务器端脚本执行--noscripting 请求一个安全技术执行指南 Request a Security Technical Implementation Guide 考虑安全标准合格性 Consider Security Standards Compliance 认证Authentication 要作为用户进行身份认证，必须提供用户名(username)，密码(password)和与用户关联的身份验证数据库(authentication database)。 1234567mongo --host --username --password --authenticationDatabase#Ormongo&gt;use &lt;authenticationDatabase&gt;&gt;db.auth(&apos;username&apos;,&apos;password&apos;) 认证机制 Authentication Mechanisms MongoDB支持多种认证机制 SCRAM-SHA-1 MongoDB Challenge and Response (MONGODB-CR) x.509 Certificate Authentication LDAP proxy authentication(MongoDB Enterprise) Kerberos authentication(MongoDB Enterprise) 内部认证 Internal Authentication 除了验证客户端的身份外。MongoDB还可以要求副本集和分片集的成员对其各自的成员进行认证 用户Users 要在MongoDB中验证客户端，必须向MongoDB添加相应的用户。 用户管理接口 User Management Interface 使用db.createUser()方法创建用户 添加用户时，可为用户分配角色以授予权限 在数据库管理中创建的第一个用户应该是具有管理其他用户权限的administrator 也可以更新/删除一个已经存在的用户的权限 认证数据库 Authentication Database 在特定的数据库中创建用户，这个数据库是用户的认证库 用户名和认证库充当该用户的唯一标识符。如果两个用户具有相同的用户名，但是在不同的数据库中创建，则它们是两个单独的用户 用户可拥有不同数据库的权限，而不限于认证库 通过数据库角色给用户分配相应的权限 认证一个用户 Authentication Database 使用用户名、密码、认证库验证一个用户 集中的用户数据 Centralized User Data MongoDB将所有的用户名、密码和认证库信息，保存到admin库的syste.users集合中 使用用户管理命令而不要直接访问这个集合 分片集群用户 Sharded Cluster Users 添加用户Add Users MongoDB使用基于角色的访问控制(RBAC)来确定用户的访问权限。用户被授予一个或多个角色，这些角色确定用户对MongoDB资源的访问或权限，以及用户可以执行的操作。用户应该只具有确保系统最小权限所需要的最小权限。 前提(Prerequisites) 对于用户创建，你必须拥有以下权限 在数据库中创建一个新用户，必须在数据库资源上有createUser操作 对一个用户授权角色，必须在角色数据库中有grantRole操作 栗子 123456789101112131415161718use admindb.createUser( &#123; user: &apos;zhang&apos;, pwd: &apos;passwd123&apos;, roles: [ &#123; role: &apos;root&apos; &#125;, &#123; db: &apos;admin&apos; &#125; ] &#125;)#在配置文件中开启用户认证vim /etc/mongod.confsecurity: authorization: enabled 认证机制Authentication Mechanisms SCRAM-SHA-1 MONGODB-CR x.509MongoDB对于客户端身份认证和副本集、分片集成员的内部认证支持x.509证书认证。 x.509证书认证需要安全的TLS/SSL连接。 证书授权(Certificate Authority) 在生产使用中，MongoDB的部署应该使用由认证机构签名和生成的有效证书。 Client x.509 Certificates 要想服务器验证身份，客户端可以使用x.509证书而不是用户名和密码。 Client Certificate Requirements： 单个证书颁发机构(CA)必须同时为客户端和服务器颁发证书 客户端证书必须包含如下字段： 12keyUsage = digitalSignatureextendedKeyUsage = clientAuth 每个唯一的MongoDB用户必须有一个唯一的证书 一个客户端x.509证书的主题，包含了可辨识名称(DN)。必须不同于成员x.509证书 MongoDB user and $external database 若要使用客户端证书进行认证，必须先将客户端证书中的subject值添加为MongoDB用户。每个唯一的x.509客户端证书对因孤独一个MongoDB用户。 在$external database中添加用户，认证库便是外部数据库。 Authenticate 使用x.509客户端进行身份验证，请通过TLS/SSL连接到MongoDB。--ssl and --sslPEMKeyFile Member x.509 Certificates 对于内部认证，分片集和副本集的成员可以使用x.509证书来代替使用SCRAM-SHA-1认证机制的keyfile。 Member Certificate Requirements CA必须为所有分片集，副本集成员颁发x.509证书 成员证书的主题中找到Distinguished Name(DN)必须为以下至少一个属性指定非空值：Organization(O)，Organization Unit(OU)，Domain Component(DC) 组织属性，组织单元属性和域组件必须与其他集群成员的证书相匹配。12CN=host1,OU=Dept1,O=MongoDB,ST=NY,C=USC=US, ST=CA, O=MongoDB, OU=Dept1, CN=host2 MongoDB Configuration 配置文件：security.clusterAuthMode and net.ssl.clusterFile cmd-line options: –clusterAuthMode and –sslClusterFile Member Certificate and PEMKeyFile 配置文件： net.ssl.PEMKeyFile cmd-line option: –sslPEMKeyFile Enterprise Authentication Mechanisms MongoDB认证和角色要想了解MongoDB的权限必须先了解如下一些关键字： user 用户，用于提供客户端连接MongoDB的认证账户 role 角色，数据权限的集合，创建用户的时候必须要指定对应的角色，否则用户无法操作数据库 resource 资源，包括database或collection 也可以是database和collection的组合 actions 权限操作，定义了 user 能够对 resource document 执行的操作。如 增、删、改、查 privilege 权限，privilege 是一组 resource 和 action的组合，对资源拥有什么操作称为权限 authenticationDatabase 认证库，即创建角色或用户时所在的库 角色管理MondoDB支持基于角色的访问控制（RBAC）来管理对MongoDB系统的访问。一个用户可以被授权一个或多个角色以决定该用户对数据库资源和操作的访问权限。在权限以外，用户是无法访问系统的。 数据库角色在创建用户的role参数中设置。角色分为內建角色和自定义角色。 内建角色 数据库用户角色 read：允许用户读取指定数据库 readWrite：允许用户读写指定数据库 数据库管理员角色 dbAdmin：允许用户进行索引创建、删除，查看统计或访问system.profile，但没有角色和用户管理的权限 userAdmin：提供了在当前数据库中创建和修改角色和用户的能力 dbOwner：提供对数据库执行任何操作的能力。这个角色组合了readWrite、dbAdmin和userAdmin角色授权的特权 集群管理角色 hostManager：提供监视和管理服务器的能力 clusterManager：在集群上提供管理和监视操作。可以访问配置和本地数据库，这些数据库分别用于分片和复制 clusterMonitor：提供对监控工具的只读访问 clusterAdmin：提供最强大的集群管理访问(副本集、分片、主从等)。组合了clusterManager、clusterMonitor和hostManager角色的能力，还提供了dropDatabase操作 备份恢复角色 backup：提供备份数据所需的能力 restore： 提供使用mongorestore恢复数据的能力 所有数据库角色 readAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读权限 readWriteAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读写权限 userAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的userAdmin权限 dbAdminAnyDataBase：只在admin数据库中可用，赋予用户所有数据库的adAdmin权限 超级用户角色 root：超级权限，只能针对admin库 内部角色 __system：提供对数据库中任何对象的任何操作的特权 自定义角色 MongoDB内置角色一般来说都是够用的，但当内置角色不满足需求时就可以自定义角色了。使用 db.createRole() 方法来自定义角色。 只能在admin库中创建角色： 123456789101112use admindb.createRole( &#123; role:&lt;role_name&gt;, #定义角色名称 privilege:[ #权限集 &#123; resource:&#123;cluster:true, actions:[&lt;action_name&gt;] &#125;, &#123; resource: &#123;db:&lt;db_name&gt;, collection:&lt;coll_name&gt; &#125;, &#123; actions:[&lt;action_name&gt;] &#125; #定义对这个库或集合可进行的权限操作，这是一个数组 ], roles:[ &#123; role:&lt;role_name&gt;, db:&lt;db_name&gt; &#125; ] #是否继承其他的角色 &#125;) 角色创建完毕后MongoDB会在系统库admin下创建一个collection名叫 system.roles，里面存储的即是角色相关的信息。 1db.system.roles.find() 操作角色1234567891011#查看角色db.getRole()#角色继承#角色授权db.grantRolesToRole()#角色移权db.revokeRolesfromRole() 用户管理创建用户： 123456db.createUser(&#123; user:&quot;xxx&quot;, pwd:&quot;xxxx&quot;, customDate:&quot;xxx&quot;, roles:[&#123; #指定角色名称以及认证库 role:&quot;xxx&quot;, db:&quot;xxxx&quot; &#125;]&#125;) 开启认证： 1234567891011vim /etc/mongo.confsecurity: authorization：enableddb.auth(&quot;user&quot;,&quot;passwd&quot;) #在use db后或mongo -u user -p passwd --authenticationDatabase xxx#在哪个库创建的用户就需要使用哪个库进行认证 查看用户： 12db.getUser(&quot;user&quot;)db.system.users.find() 删除用户： 12db.dropUser(&quot;user&quot;)db.dropAllUsers() 添加用权限： 1db.grantRolesToUser() 修改用户密码： 1db.changeUserPassword(&quot;user&quot;,&quot;new_passwd&quot;) 在MongoDB中删除库和集合并不会级联删除对应的角色和用户。因此如果想彻底删除对应的业务应该先删除库与其对应的角色和用户。 如果既想实现精细化权限控制又想简化用户管理，原则上建议只给开发创建一个账户，并且使用admin做认证库，这样可以避免清理过期业务库而导致无法登陆的问题。 内部认证Internal Authentication 可以对副本集和分片集成员进行验证。对于成员的内部认证，MongoDB可以使用keyfile或x.509证书。 KeyFile keyfiles的内容作为成员的共享密码，其长度必须在6-1024个字符之间，只能包含base64 set中的字符。 1234567891011121314openssl rand -base64 512 &gt; /etc/mongodb.keyfilechmod 600 /etc/mongodb.keyfilechown mongod:mongod /etc/mongodb.keyfile#配置文件：security.keyFile#cmd-line option: --keyFilevim /etc/mongod.confsecurity: authorization: enabled keyFile: &quot;/etc/mongodb.keyfile&quot; clusterAuthMode: &quot;keyFile&quot; x.509 内部认证使用x.509进行验证。 CA必须为所有分片集，副本集成员颁发x.509证书 成员证书的主题中找到Distinguished Name(DN)必须为以下至少一个属性指定非空值：Organization(O)，Organization Unit(OU)，Domain Component(DC) 组织属性，组织单元属性和域组件必须与其他集群成员的证书相匹配。12CN=host1,OU=Dept1,O=MongoDB,ST=NY,C=USC=US, ST=CA, O=MongoDB, OU=Dept1, CN=host2 MongoDB Configuration 配置文件：security.clusterAuthMode and net.ssl.clusterFile cmd-line options: –clusterAuthMode and –sslClusterFile 在副本集中强制秘钥文件访问控制Enforce Keyfile Access Control in a Replica Set 对副本集执行访问控制需要配置： 使用内部身份验证副本集成员之间的安全性 使用用户访问控制连接客户端和副本集间的安全性 步骤： 创建一个密钥文件 Create a keyfile 通过密钥文件进行身份验证，副本集中的每个mongod实例都使用密钥文件的内容作为共享密码，用于验证部署中的其它成员。 12345#yum install -y opensslopenssl rand -base64 756 &gt; &lt;path-to-keyfile&gt;chmod 400 &lt;path-to-keyfile&gt;chown &lt;owner&gt;:&lt;owner&gt; 复制密钥文件到每个副本集成员 Copy the keyfile to each replica set member 将密钥文件复制到每一台主机的副本集成员中。确保运行mongod实例的用户就是keyfile的所有者，并可以访问密钥文件。 关闭所有的副本集成员 Shut down all members of the replica set 关闭每个副本集中的mongod，从Secondary开始。知道所有的成员都脱机为止，包括任何仲裁者(Arbiter)。Primary是最后一个关闭的成员。 12use admindb.shutdownServer() 启动访问控制并重启副本集成员 123456789101112vim /etc/mongod.confsecurity: keyFile: &lt;path-to-keyfile&gt; clusterAuthMode: keyfilereplication: replSetName: &lt;replcaSetName&gt;#cmd-linemongod --keyFile &lt;path-to-keyfile&gt; --clusterAuthMode keyfile --replSet &lt;replicaSetName&gt; 连接到mongo shell 在Primary上使用rs.status()来标识副本集成员。 创建一个administrator Create the user administrator 必须在Primary上创建用户。 12345678admin = db.getSiblingDB(&quot;admin&quot;)admin.createUser( &#123; user: &apos;zhang&apos;, pwd: &apos;password&apos;, roles: [&#123; role: &apos;userAdminAnyDatabase&apos;, db: &apos;admin&apos; &#125;] &#125;) 开启用户认证 12345678vim /etc/mongod.confsecurity: authorization: enabled keyFile: &lt;path-to-keyfile&gt; clusterAuthMode: keyfilereplication: replSetName: &lt;replcaSetName&gt; 以管理员身份进行认证 Authenticate as the User Administrator 123456mogno&gt;db.getSiblingDB(&quot;admin&quot;).auth(&apos;zhang&apos;,&apos;password&apos;)#ormongo -u &apos;zhang&apos; -p &apos;password&apos; --authenticationDatabase &apos;admin&apos; 创建集群管理员(可选) Create the cluster administrator (Optional) 1234567db.getSiblingDB(&quot;admin&quot;).createUser( &#123; &quot;user&quot; : &quot;ravi&quot;, &quot;pwd&quot; : &quot;changeme2&quot;, roles: [ &#123; &quot;role&quot; : &quot;clusterAdmin&quot;, &quot;db&quot; : &quot;admin&quot; &#125; ] &#125;) 在不停机的副本集中强制实施keyfile访问控制]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP请求方法和状态码]]></title>
    <url>%2F2017%2F12%2F01%2FHTTP-method-status%2F</url>
    <content type="text"><![CDATA[常见HTTP请求方法HTTP协议的请求方法有：GET, POST, HEAD PUT DELETE, OPTIONS, TRACE, CONNECT Method Description GET 向Server请求文件 POST 向Server发送数据并让Server进行处理 PUT 向Server发送数据并存储在Server端 HEAD 检查一个对象是否存在 DELETE 从Server上删除一个文件 CONNECT 对通道提供支持 TRACE 跟踪到Server的路径 OPTION 查询Server的性能 HTTP Status Code当我们从Client向Server发送请求时，Server会向我们返回StatusCode。StatusCode会告诉我们Server的响应的状态，通过它，我们就可以知道当前请求是成功还是出现了问题。 HTTP StatusCode放置在HTTP Response报文中。 StatusCode由三位数字组成，第一个数字定义了响应类型，有五种可能值： 状态码 响应类别 描述 1xx 指示信息 服务器正在处理请求 2xx 成功 请求以正常处理完毕 3xx 重定向 需要进行额外操作以完成请求 4xx 客户端错误 客户端原因导致服务器无法处理请求 5xx 服务器错误 服务器原因导致处理请求出错 常见HTTP状态码 状态码 描述 200-OK 服务器成功返回网页，这是成功的HTTP请求返回的标准状态码 301 - Moved Permanently 永久跳转，所有请求的网页将永久跳转到被设定的新位置 400 - Bad Request 客户端请求有语法错误，不能被服务器理解 403 - Forbidden 禁止访问，这个请求时合法的，但是服务器端因为匹配了预先设置的规则而拒绝响应客户端的请求，此类问题一般为服务器权限配置不当所致 404 - Not Found 服务器找不到客户端请求的指定页面，可能是客户端请求了服务器不存在的资源所导致 500 - Internal Server Error 内部服务器错误，服务器遇到了意料不到的情况，不能完成客户的请求。这是一个较为笼统的报错，一般为服务器的设置或内部程序问题所致 502 - Bad Gateway 坏的网关，一般是代理服务器请求后端服务器时，后端服务不可用或没有完成响应网关服务器。一般为代理服务器下面的节点出了问题 503 - Service Unavailable 服务当前不可用，可能为服务器超载或停机维护所致，或者是代理服务器后面没有可以提供服务的节点 504 - Gateway Timeout 网关超时，一般是网关代理服务器请求后端服务时，后端服务没有在特定的时间内完成处理请求，一般为服务器过载所致，没有在指定的时间内返回数据给代理服务器 1xx1xx（临时响应），表示临时响应并需要请求者继续执行操作。 状态码 描述 100 - Continue 请求者应当继续提出请求 101 - Switching Protocols 请求者要求服务器更换协议，服务器已确认并准备更换 2xx2xx（成功），表示成功处理了请求。 状态码 描述 200 - OK Server已成功处理了请求 201 - Created 请求成功并且Server创建了新的资源 202 - Accepted Server以接受请求，但尚未处理 203 - Non-Authoritative Information Server已成功处理了请求，但返回的信息可能来自另一个来源 204 - No Content Server成功处理了请求，但没有返回任何内容 205 - Reset Content 没有新的内容，但浏览器应该重置它所显示的内容 206 - Partial Content 服务器成功处理了部分GET请求 3xx3xx（重定向），表示要完成请求需要进一步操作。 状态码 描述 300 - Multiple Choices 针对请求，Server可执行多种操作 301 - Moved Permanently 请求的网页已移动到新位置 302 - Found Server目前从不同位置的网页响应请求 303 - See Other 请求者对不同位置使用单独的GET请求来检索时 304 - Not Modified 自从上次请求后，请求的网页内容未修改过 305 - Use Proxy 请求者只能使用代理访问请求的网页 307 - Temporary Redirect Server从不同位置的网页响应请求，但请求者继续使用原有位置进行请求 4xx4xx（请求错误），表示请求可能出错，妨碍了Server的处理。 状态码 描述 400 - Bad Request Server不理解请求的语法 401 - Unauthorized 请求要求身份认证 403 - Forbidden Server拒绝请求 404 - Not Found Server找不到请求的网页 405 - Method Not Allowed 请求方法不被允许 406 - Not Acceptable 无法使用请求的恩日工特性响应请求的网页 407 - Proxy Authentication Required 请求需要代理授权 408 - Request Timeout Server等候请求时超时 409 - Conflict Server在完成请求时发生冲突 410 - Gone 请求的资源以永久删除 411 - Length Required Server不接受不含有效内容长度Header的请求 412 - Precondition Failed Server为满足请求者在请求中设置的一个前提条件 413 – Request Entity Too Large 请求实体太大，Server无法处理 414 - Request URI Too Long 请求的URI过长，Server无法处理 415 – 不支持的媒体类型 请求的格式不受支持 416 – Requested Range Not Satisfiable 页面无法提供请求的范围 417 – 执行失败 Server未满足期望请求Header的要求 451 基于法律上的的原因，不能像请求者展示网页内容 5xx5xx（服务器错误），表示服务器在尝试处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是请求出错。 状态码 描述 500 - Internal Server Error Server遇到错误，无法完成请求 501 - Not Implemented Server不具备完成请求的功能 502 - Bad Gateway Server作为网关或代理时，从upstream收到无效响应 503 - Service Unavailable Server暂时无法使用 504 - Gateway Timeout Server作为网关或代理时，没有及时从upstream收到请求 505 - HTTP Version Not Supported Server不支持请求中所用的HTTP版本]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Filesystem Hierarchy Standard]]></title>
    <url>%2F2017%2F11%2F27%2FFHS%2F</url>
    <content type="text"><![CDATA[FHS介绍FHS(Filesystem Hierarchy Standard)，文件系统层次化标准：http://www.pathname.com/fhs FHS主要目的是希望让用户了解安装文件通常放置的目录。所以希望软件开发商、系统制定者以及维护系统的用户，都能够遵循FHS的标准。 FHS-compliant system： - 可分享的(shareable) 不可分享的(unshareable) 不变的(static) /usr /opt /etc /boot 可变的(variable) /var/mail /var/spool/news /var/run /var/lock shareable： 可分享给其他系统(主机)挂载使用； unshareable： 不适合分享给其他主机； static： 有些数据基本是不会变化的； variable： 进程变更的数据。 FHS针对目录树架构仅定义出三层目录下应该放置什么数据，这三个目录下所应该放置的目录也都有特定规定。 /： The root filesystem, 与开机系统有关； /usr: The /usr hierarchy, Unix software resource； /var: The /var hierarchy, 与系统运行过程有关。 The Root Filesystem根目录(/)是系统最重要的一个目录。不但所有目录都是由根目录衍生出来，同时根目录还与系统的启动、还原、修复等操作相关。若系统出现问题，根目录必须要包含能够修复文件系统的程序才行。破坏根文件系统上的数据的错误比破坏其他任何分区都要严重！ 为了平衡这些考虑，建议尽可能保持根分区小。应用程序不应在根目录中创建特殊文件或子目录！ The following dirs or symbolic-links, are required in / 目录 描述 /bin 必要的二进制命令 /boot boot-loader的静态文件 /dev 设备文件 /etc 主机特定的系统配置文件 /lib 基本的共享库(shared libraries)和内核模块(kernel modules) /media 可移除媒体的挂载点 /mnt 临时挂载文件系统的挂载点 /opt 第三方软件包放置目录 /sbin 必要的系统二进制命令 /srv 系统提供的服务数据 /tmp 临时文件 /usr /usr层次结构 /var /var层次结构 除了上面列出必须存在的目录，下面这些目录很也很重要。 目录 描述 /lost+found 在ext文件系统里，当文件系统发生错误时，将一些遗失的片段放置到此目录下 /home 用户家目录 /root root用户家目录 /proc 虚拟文件系统，放置的数据都在内存当中，不占磁盘空间 /sys 虚拟文件系统，记录内核相关信息，不占磁盘空间 另外需要注意的是，因为根目录与开机有关，开机过程中仅有根目录被挂载。其他分区则是在开机完成后才会持续进行挂载。因此，根目录下与开机过程有关的目录就不能放到不同的分区中去。 如： /etc /bin /sbin /dev /lib /bin/bin, 基本用户二进制命令文件，供所有用户（系统管理员和用户）使用。 /bin下不能有子目录(subdirectory)。 The following commands or symbolic-links to commands, are required in /bin 命令 描述 cat 将文件连接到stdout的实用程序(Utility) chgrp 更改文件所有权 chmod 更改文件访问权限 chown 更改文件所有者和和组 cp 复制文件和目录 date 打印或设置系统数据和时间 dd 转换和复制文件 df 磁盘使用情况 dmesg 打印或控制kernel消息缓冲区 echo 显示一行文本 false do nothing, 不成功 true do nothing, 成功 hostname 系统主机名 kill 发送信号到进程 ln 在文件之间创建链接 login 在系统上开始会话 ls 列出目录内容 mkdir 创建目录 mknod 创建block或character特殊文件 more 文本翻页 mount 挂载文件系统 umount 解挂文件系统 mv move/rename文件 ps 报告进程状态 pwd 打印当前工作目录 rm remove文件或目录 sed sed流编辑器 sh Bourne command shell stty 更改或打印终端设置 su change uid sync 刷新文件系统缓冲区 uname 打印系统信息 The following programs or symbolic-links to programs, must be in /bin if the corresponding-system is installed: 命令 描述 csh The C shell(可选) ed 编辑器(可选) tar tar归档(可选) cpio cpio归档(可选) gzip GNU压缩工具(可选) gunzip GNU解压缩工具(可选) netstat 网络统计(可选) ping ICMP网络测试(可选) /boot/boot :static file of the boot-loader 该目录包含引导过程所需所有内容，处理引导是不需要的配置文件和映射安装文件外。因此，/boot储存kernel开始执行用户模式之前使用的数据。 操作系统kernel必须位于 / or /boot /dev/dev :device files /dev 目录是特殊或设备文件的位置。 /etc/etc :host-specific system configuration 配置文件是用来控制程序操作的本地静态文件，不能是可执行的二进制文件。 The following files or symbolic-links to files, must be in /etc if the corresponding-subsystem is installed. 文件 描述 备注 csh.login C shell登录的系统范围初始化文件 Optional exports NFS文件系统访问控制列表 Optional fstab 文件系统静态信息 Optional ftpusers FTP守护进程用户访问控制列表 Optional gateways 路由网关文件 Optional gettydefs getty终端设置 Optional group 用户组文件 Optional passwd 密码文件 Optional host.conf 解析器配置文件 Optional hosts 主机域名的静态信息 Optional hosts.allow Tcp-wrapper的主机访问文件 Optional hosts.deny Tcp-wrapper的主机禁止文件 Optional hosts.equiv rlogin, rsh, rcp的可信主机列表 Optional hosts.lpd lpd的可信主机列表 Optional inetd.conf inetd配置文件 Optional inittab init配置文件 inittab is no longer used when using systemd id.so.conf 搜索共享库的额外目录 Optional issue 预登录消息和 CentOS Linux 7(core) kernel \r on an \m motd 登录后信息 Welcome to $host mtab 文件系统动态信息 Optional mtools.conf mtools配置文件 Optional networks 网络名称的静态信息 Optional printcap lpd打印机功能数据库 Optional profile sh shell login的系统范围初始化文件 Optional protocols IP协议列表 Optional resolv.conf 域名服务器解析文件 Optional rpc RPC协议列表 Optional securetty root登录的TTY访问控制 Optional shells 有效登录shell的路径名 Optional syslog.conf syslogd配置文件 Optional /etc/opt/etc/opt :/opt的配置文件 第三方应用程序软件的特定主机配置文件，必须安装在/etc/opt/ 中。 /etc/xml/etc/xml :XML的配置文件 这里安装和定义XML系统的高级参数同通用配置文件。 /home (Optional)/home :用户主目录 /home是一个相当标准的概念，但它显然是一个特定于站点的文件系统。设置会因主机而异。因此，任何程序都不应该依赖这个目录。 /lib/lib :基本的共享库和内核模块 /lib目录中包含引导系统和运行在根文件系统的命令，即/bin和/sbin中的命令。 至少需要包含以下文件(链接)： 文件 描述 libc.so.* 动态链接C库 ld* 执行时间 链接器/加载器 /lib (Optional)/lib&lt;qual&gt; : 不同格式的基本共享函数库如：64位的/lib64; 32位的/lib32。 用来存放与/lib不同格式的二进制函数库，如支持64位的/lib64函数库等。 /media/media :可移除媒体的挂载点 此目录包含的子目录，可作为各移动介质(USB,cdrom,floppy…)的挂载点。 尽管在 /mnt 中使用子目录作为挂载点已经很常见了，但与直接使用/mnt作为临时挂载点的传统相去甚远。 /mnt/mnt :临时挂载文件系统的挂载点 /opt/opt :为第三方软件包保留的目录 要安装在/opt中的软件包必须将其静态文件放置在单独的/opt/&lt;packge&gt;目录树中。 目录/opt/bin, /opt/doc, /opt/include, /opt/info, /opt/lib, /opt/man 是保留给本地系统管理员使用。如果第三方软件包含Unix手册，而手册必须放置于/opt//share/man/，必须使用与/usr/share/man相同的子结构。 /root (Optional)/root :root用户的主目录 /sbin/sbin :系统二进制文件 系统管理的实用程序(命令)，存储在/sbin, /usr/sbin, /usr/local/sbin中。/sbin包含启动，恢复，修复系统，以及/bin中二进制文件所必须的二进制文件。本地安装的系统管理程序应放置在/usr/local/sbin中。 The following commands or symbolic-links to commands are required in /sbin1shutdown #关闭系统 The following files or symbolic-links to files，must be in /sbin if the corresponding subsystem is installed 命令 描述 备注 fastboot 重启系统而不检查磁盘 Optional fasthalt 停止系统而不检查磁盘 Optional fdisk 分区表操作器 Optional fsck 文件系统检查和修理工具 Optional fsck.* 针对特定文件系统检查和修复 Optionaleg：fsck.ext3 getty getty程序 Optional half 停止系统 Optional ifconfig 配置网络接口 Optional init 初始化进程 Optional mkfs 创建文件系统 Optional mkfs.* 创建特定文件系统 OPtionaleg: mkfs.ext4 mkswap 设置swap分区 OPtional reboot 重启系统 OPtional route IP路由表实用程序 OPtional swapon 启用分页和交换 OPtional swapoff Disable paging and swapping Optional update 守护进程定期刷新文件系统缓冲区 Optional /srv/srv :系统提供的服务(service)的数据 /tmp/tmp :临时文件 /tmp目录为临时需要文件的程序提供。程序不能在程序的调用之间保留/tmp中的任何文件或目录。尽管/tmp中数据可能会以某种特定方式删除，但建议在系统启动时删除/tmp中所有文件。 The /usr Hierarchy/usr 里面放置的数据是可分享与不可变动的。这就意味着可在各种符合FHS的主机之间共享，但不能写入。大型软件包不应在/usr层次结构下使用直接子目录。 The following dirs of symbolic-links to dirs are required in /usr 目录 描述 /usr/bin 大多数用户命令 /usr/include C程序包含的头文件 /usr/lib 库文件 /usr/local 本地层次结构 /usr/sbin 非重要的系统二进制文件 /usr/share 独立于架构的数据 其他选项： 目录 描述 备注 /usr/lib&lt;qual&gt; 可选格式库 Optional /usr/src 源代码 OPtional /usr/games 游戏和教育二进制文件 OPtional /usr/bin/usr/bin :大多数用户命令这是系统上可执行命令的主要目录。 The following files or symbolic-links to files must be in /usr/bin, if the corresponding subsystem is installed 命令 描述 备注 perl 实用提取和报告语言 OPtional python python解释语言 Optional tclsh tcl解释器的简单shell OPtional wish 简单 tcl/tk windowing shell Optional expect 程序交互式对话 Optional 因为shell script解释器(在shell script脚本的第一行 #!)不能依赖路径，所以标准化它们的位置是有利的。Bourne shell 和 C-shell解释器已经被固定在/bin中，但 perl,python,tcl经常在许多不同的地方。 /usr/include/usr/include :标准C包含文件的目录 这是C语言所有系统的通用包含文件应该被放置的地方。 /usr/lib/usr/lib :编程和包的所需要的库 /usr/lib包括 不打算由用户或shell script直接执行的目标文件、库和内部二进制文件。 /usr/lib (Optional)/usr/lib&lt;qual&gt; :可选格式库 /usr/local/usr/local :本地层次结构 /usr/local是给系统管理员安装本地软件使用。当系统软件更新时，需保证安全。它可以用于在一组主机之间共享，但在 usr中找不到的程序和数据。 本地安装软件必须放在 /usr/local 而不是 /usr，除非安装它来升级或替换usr的软件 The following dirs or symbolic-links to dis must be in /usr/local 目录 描述 /usr/local/bin 本地二进制文件 /usr/local/etc 本地二进制文件的特定配置文件 /usr/local/games 本地游戏二进制文件 /usr/local/include 本地C头文件 /usr/local/lib 本地库 /usr/local/man 本地在线手册 /usr/local/sbin 本地系统二进制文件 /usr/local/share 本地独立架构层次结构 /usr/local/src 本地源码 /usr/local/share目录内容的要求应与/usr/share相同，唯一附加约束是/usr/local/share/man和/usr/local/man目录必须是同步的。（基本上就是符号链接了！） /usr/sbin/usr/sbin :非必要的标准系统二进制文件 该目录包含系统管理员专门使用的任何非必要的二进制文件。系统修复、恢复、挂载/usr等其他重要必要功能必须放在/sbin中。 /usr/share/usr/share :独立于架构的数据 /usr/share层次 是为了所有只读架构独立数据。该层次可以在给定OS的所有体系架构平台之间共享。如具有i386和PPC平台站点可能会维护一个集中安装的/usr/share目录。但/usr/share一般不打算由不同的操作系统共享，或由同一操作系统的不同版本共享。 The following dis or symbolic-links to dirs must be in /usr/share 目录 描述 man 在线手册 misc 其他独立于架构的数据 The following dis or symbolic-links to dirs must be in /usr/share, if the corresponding subsystem is installed 目录 描述 备注 dict 单词列表 Optional doc 各种文档 Optional games /usr/games的静态文件 Optional info GNU Info system’s primary dir Optional locale 支持的区域信息 Optional zoneinfo Timezone info and conf Optional NLS Native language support Optional sgml SGML数据 Optional terminfo terminfo数据库目录 Optional xml xml数据 Optional /usr/share/dict/usr/share/dict :单词列表这个目录是系统上单词列表的家目录，只包含英文单词，它们由look和各种拼写程序使用。它们是所有拼写检查器唯一通用的文件。 文件 描述 备注 words 单词列表 Optional linu.words linux可用单词列表 Optional /usr/share/man/usr/share/man :手册页它包含了/, /usr文件系统下的命令和数据的手册信息 手册页存储在 /usr/share/man/&lt;locale&gt;/man&lt;section&gt;/&lt;arch&gt;中。 每个部分的描述： man1: 可公开访问的命令的手册页，用户需要使用的大多数程序文档放置于此； man2: 系统调用部分，描述所有的系统调用(请求内核执行操作)； man3: 函数库和子例程部分，描述不直接调用内核服务的程序库例程； man4: 特定文件部分，描述系统中特定文件，相关驱动程序和网络支持。通常，这包含/dev中找到的设备以及网络协议支持的内核接口； man5: 文件格式部分，许多数据文件的格式记录在此； man6: 游戏，演示和一般小程序； man7: 各种难以分类的手册页； man8: 系统管理员用于操作和维护系统的程序记录在这。 The following dirs or symboli-link to dirs must be in /usr/share/man/&lt;locale&gt;, unless they are empty 目录 描述 备注 man1 用户程序 Optional man2 系统调用 Optional man3 函数库调用 Optional man4 特定文件 Optional man5 文件格式 Optional man6 游戏 Optional man7 混杂的手册页 Optional man8 系统管理 Optional 必须在/usr/share/man结构中作出规定，以支持用不同语言编写的手册页。这些规定必须考虑到手册页的存储和参考，相关因素包括语言和字符编码集。 栗子： Language Country CharacterSet Dir English - ASCII /usr/share/man/en English United Kingdom ISO 8859-15 /usr/share/man/en_GB English United States ASCII /usr/share/man/en_US /usr/share/misc/usr/share/misc :与架构无关的数据 /usr/share/sgml/usr/share/sgml :SGML数据 /usr/share/xml/usr/share/xml :XML数据 /usr/src/usr/src :源代码Source Code可能放置在此目录的子目录中，仅供参考。 /var Hierarchy/var 包含可变数据文件，包括假脱机目录和文件，系统管理和登录数据，以及临时文件。 如果/var不能成为一个单独的分区，最好将/var移出/分区并移入/usr分区。（为了减小根分区大小或当根分区空间不足时）也可将/var链接到/usr/var。 The following dirs or symbolic-link to dirs are required in /var. 目录 描述 /var/cache 应用程序缓存数据 /var/lib 可变状态信息 /var/local /usr/local的可变数据 /var/lock 锁文件 /var/log 日志文件 /var/opt /opt的可变数据 /var/run 与运行进程相关的数据 /var/spool 应用程序队列数据 /var/tmp 为系统重启保留的临时文件 The following dirs or symbolic-link to dir must be in /var,if the corresponding subsystem is installed. 目录 描述 备注 /var/account 进程账户日志 可选 /var/crash 系统奔溃转储 可选 /var/games 可变游戏数据 可选 /var/mail 用户邮箱文件 可选 /var/yp 网络信息服务数据库文件 /var/account/var/account :该目录保存当前活动的进程记账日志和复合进程数据。 /var/cache/var/cache :保存应用程序缓存的数据。应用程序必须能够重新生成或回复数据。与/var/spool不同，删除了缓存文件不会丢失数据。数据必须在应用程序调用和系统重启间保持有效。缓存目录的数据格式没有其他要求。 对于缓存数据单独存在的目录，系统管理员可从/var下其他目录设备不同的磁盘和备份策略。 目录 描述 备注 /var/cache/fonts 本地生成的字体 可选 /var/cache/man 本地格式化的手册页 可选 /var/cache/www www代理或缓存数据 可选 /var/cache/&lt;package&gt; 特定包缓存数据 可选 /var/lib/var/lib :可变状态信息。目录保存于应用程序或系统有关的状态信息。状态信息(state infofmation)，是程序在运行时修改的数据，属于一个特定的主机。 应用程序必须为其数据使用/var/lib/&lt;subdir&gt;，有一个必须的子目录/var/lib/misc用于不需要子目录的状态文件。 /var/lock/var/lock :锁文件，锁文件应该存储在此目录中。锁文件锁定多个应用程序共享的设备和其他资源。 这种锁文件内容的格式必须是HDB UUCP锁文件格式。HDB格式是将进程标识符(PID)存储为ASCII十进制数，并带有换行符。 /var/log/var/log :日志文件和目录，大多数日志必须写入此目录或适当子目录。 The following file or symbolic-link to file must be in /var/log. 文件 描述 lastlog 每个用户上次登录信息的记录 message syslogd的系统信息 wtmp 所有登录和注销的记录 /var/mail邮件缓存区必须通过/var/mail访问，邮件缓冲区文件必须采用的形式。 /var/run/var/run :运行时变化数据，此目录包含系统信息数据，描述系统启动以来的情况。此目录下的文件必须在引导过程开始时被清除。进程标识符(PID)文件放置于此目录或下的子目录里面。 /var/spool/var/spool :应用程序队列数据。此目录包含正在等待某种稍后处理的数据，/var/spool中的数据表示工作将在将来执行(通过程序，用户或管理员)，数据通常会在工作处理后被删除。 The following dirs or symbolic-link to dirs must be in /var/spool,if the corresponding subsystem is installed. 目录 描述 备注 lpd 打印机队列目录 可选 mqueue 发送邮件队列 可选 news 新闻假脱机目录 可选 rwho rwhod文件 可选 uucp uucp的假脱机目录 可选 /var/tmp/var/tmp :在系统重启之间保存的临时文件。存储在/var/tmp的数据比/tmp中的数据更持久。 OS Specific Annex本节是针对仅适用于特定OS的其他建议和要求。 LinuxLinux操作系统的附件 / :根目录在Linux系统上，如果内核位于/，建议使用Linux内核源代码包中使用的名称vmlinux或vmlinuz。 我的CentOS7中，内核文件默认是/boot/vmlinuz-$kernel-version.$arch /bin :基本用户命令二进制文件(供多有用户使用) /dev :设备和特殊文件 /dev/null : 写入该设备的所有数据都被丢弃。从这个设备读取将返回一个EOF条件。 /dev/zero : 该设备是归零数据的来源，写入该设备的所有数据被丢弃。从这个设备读取将返回包含zero的请求的字节数。 /dev/tty : 该设备类似于进程控制终端。一旦这个设备被打开，所有读写操作就好像实际的控制终端以及被打开一样。 /etc :主机的特定系统配置Linux系统要将附件文件放置到/etc中。 /lib64 和 /lib32 :64/32位库(依赖于体系结构)64位体系结构PPC64,AMD64,x86_64必须将64位库放置于/lib64中，将32位库放置于/lib中；64位体系结构IA64必须将64位库放置于/lib中。 /proc :内核和进程信息虚拟文件系统PROC文件系统是用于处理进程和系统信息的标准Linux方法，而不是/dev/kmem和其它类似方法。强烈建议使用PROC文件系统获取 存储，进程，内存，内核等信息。 /sbin :基本系统二进制文件Linux系统将这些附加文件放置于/sbin中： 第二扩展文件系统命令（可选）： 123456badblocksdumpe2fse2fsckmke2fsmklost+foundtune2fs boot-loader 映射安装程序（可选）：lilo 静态二进制文件： 123ldconfigsln(static ln)ssync(static sync) 出现问题时，sln（静态ln）和ssync（静态同步）非常有用；idconfig程序可以作为升级知道的手段；sln的主要用途，修复不良协调升级后/lib中不正确的符号链接动态库。 对于/sbin, idconfig二进制文件是可选的。因为站点可能会在启动时选择运行idconfig而不是仅在升级共享库时。以下是一些常见问题： 我刚刚删除了/lib/； 我无法找到库的名称，因为ls是动态链接。我使用的shell没有内置ls，我也不知道使用echo *作为替换； 我有一个静态ln，但我不知道怎么称呼这个链接。 杂项： 12345#ctrl+alt+delctrlaltdel#keyboard ratekbdrate 为了应对某些键盘出现如此高的重复速率一致无法使用,kbdrate可以安装在某些系统上的/sbin中； 由于ctrl+alt+del组合键在内核中的默认操作是硬重启，因此通常建议在将根文件系统挂在到读写模式之前禁用该行为。这就可能需要ctrlaltdel程序，它可以安装在系统的/sbin中。 /usr/include :C程序包含的头文件如果安装了C或C++编译器，则只有非 基于glibc的系统才需要这些链接符号。 12/usr/include/asm -&gt; /usr/src/linux/include/asm-&lt;arch&gt;/usr/include/linux -&gt; /usr/src/linux/include/linux /usr/src :源代码对于基于glibc的系统，此目录没有具体指导。 对于glibc之前基于linux libc修订版的系统： /usr/src/linux是唯一放置Linux内核源代码的位置。 /usr/spool/cron :cron和jobs此目录包含了cron和程序的可变数据。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>FHS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix]]></title>
    <url>%2F2017%2F11%2F14%2FZabbix%2F</url>
    <content type="text"><![CDATA[参考： Zabbix官方网站 Zabbix中文文档 Zabbix-repo仓库: http://repo.zabbix.com 阿里云镜像: https://mirrors.aliyun.com/zabbix/zabbix/ . 环境： CentOS7x86_64 Zabbix 3.4 Zabbix简介Zabbix （音同 zæbix），是由 Alexei Vladishev 开发的一种网络监视、管理系统，基于 Server-Client 架构。Zabbix 的授权是属于 GPLv2。Zabbix可用于监视各种网络服务、服务器和网络机器等状态。是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案。Zabbix也可经由SNMP、TCP、ICMP、SSH等对目标进行监视。 Zabbix的系统构成Zabbix系统由以下各独立模块组成： Zabbix Server，服务端(以C开发)。Server端通过收集SNMP和Agent发送的数据，写入数据库，再通过PHP+Apache在Web端展示； Zabbix Agent，客户端(基本支持所有操作系统)，并将监控主机数据发送给Server； Zabbix Frontend，Web管理端(以PHP和JavaScript构成)； Zabbix Proxy(可选组件)。用于分布式监控。 Zabbix的特点Zabbix是一个高度集成的网络监控解决方案，一个简单的安装包中提供多样性功能。 数据收集； 灵活的阀值(触发器)定义； 高度可配置化的告警； 实现图表绘制； Web监控功能； 丰富的可视化选项； 历史数据存储； 配置简单； 使用模板； 网络发现； Zabbix API； 权限管理系统； 功能强大并易于扩展的监控代理。 定义Zabbix的常用术语含义。 主机(host)： 一台你想监控的网络设备，用IP或域名表示。主机名不能使用中文创建，会报错。 主机组(host group):主机的逻辑组，它包含主机和模板。组名可以使用中文。 监控项(item):你想要接收的主机的特定数据，一个度量数据。 触发器(trigger):一个被用于定义问题阀值和评估监控项接收到的数据的逻辑表达式。 事件(event):单次发生的需要注意的事情。 异常(problem):一个处在异常状态的触发器。 动作(action):一个对事件作出反应的预定义的操作。 升级(escalation):一个在动作内执行操作的自定义场景。 媒介(media):发送报警通知的手段。 通知(notification):利用已选择的媒体途径把事情相关信息发送给用户。 远程命令(remote command):预先定义好的，满足一定条件后，可在被监控主机上自动执行的命令。 模板(template):一组可以被应用到一个或多个主机上的实体的集合。 应用(application):一组监控项组成的逻辑分组。 Web场景(Web scenario):利用一个或多个HTTP请求来检查网站的可用性。 前端(frontend):Zabbix提供的Web界面。 Zabbix API:Zabbix API允许你使用JSON RPC协议来创建、更新和获取Zabbix对象信息或执行任何其他的自定义的任务。 Zabbix server:Zabbix软件监控的核心程序，主要功能是与Zabbix proxies和agent进行交互、触发器计算、发送告警通知，并将数据集中保存等。 Zabbix agent:部署在监控对象上，能够主动监控本地资源和应用。 Zabbix proxy:帮助Zabbix server收集数据，分担Zabbix server的负载。 Zabbix进程Agentzabbix agent部署在监控的目标上，主动监测本地的资源和应用（硬件驱动，内存，处理器统计等）。zabbix agent手机本地的操作信息并将数据报告给zabbix server用于进一步处理。 zabbix agent有被动(passive)和主动(active)两种检查方式。 Serverzabbix server是zabbix软件的核心程序。它通过轮询和捕获数据，计算是否满足触发器条件，向用户发送通知。它是zabbix监控代理和Proxy代理报告系统可用性和完整性数据的核心组件。zabbix server自身可以通过简单远程检查网络服务(如Web服务器和邮件服务器)。 server是一个包含了被存储了所有配置，统计方面的和可操作数据的中央仓库，它是监控系统问题升级以致于激活警告管理器的zabbix中的实体。 基本的zabbix server分三个不同的组件：zabbix server，web前端，数据库存储。zabbix的所有配置信息都存储在服务器和web前端进行交互的数据库中。 zabbix server进程是以守护进程（Daemon）运行的。 Proxyzabbix proxy是一个可以从一个或多个受监控的设备设备收集监控数据，并将信息发送到zabbix server的进程，基本上是代表server工作。所有收集的数据都在本地进行缓存，然后传送到proxy所属的zabbix server。 zabbix proxy是完成远程区域、分支机构、没有本地管理员的网络的集中监控的理想解决方案。 zabbix proxy需要使用独立的数据库，以守护进程的方式运行。 Java gatewayzabbix守护进程原生支持监控JMX程序，它被称为zabbix java gateway。zabbix gateway是用Java语言写成。 要查得一台主机特定的JMX计数器值，zabbix server向zabbix java gateway发送请求，后者使用JMX管理API去请求远程的有关应用。应用不许额外安装软件，只需要启动时在命令行指定 -Dcom.sun.management.jmxremote即可（是在java程序）。 每个zabbix server或zabbix agent只能配置一个java gateway。 Senderzabbix sender是一种命令行应用，它可以将性能数据发送到zabbix server进行处理。该应用通常用在长时间运行的用户脚本，用于定期发送可用性和性能数据。 123456zabbix_sender -z zabbix -s &quot;xxx&quot; -k db.connections -0 43-z :server主机-s :受监控主机的技术名称-k :监控项的键-o :要发送的值 Getzabbix get也是一种命令行应用，用于与zabbix agent进行通信，并从agent那里获取所需的信息。该应用通常被用于zabbix agent故障排除 12345678zabbix_get -s $host -p xxx -k system.cpu.load[all,avg15]-s --host-p --port-I --source-address-k --key-h --help-V --version 安装ZabbixZabbix安装要求硬件： 内存，最小128MB； 磁盘，最小256MB； CPU，可能需要大量CPU资源； SMS(短信)通知服务，串行通讯口(serial communication port)和串口GSM调制解调器(serial GSM modem)。可选项。 支持平台： Linux; IBM AIX; FreeBSD; NetBSD; OpenBSD; Mac OS X; Solaris; Windows(Only Agent). 软件：Zabbix基于Apache Web服务器、领先的数据库引擎和PHP脚本语言进行构建。 数据库管理系统： MySQL 5.0.3 及以上； Oracle 10g 及以上； PostgreSQL 8.1 及以上； SQLite 3.5及以上； IBM DB2 9.7 及以上。 前端： Apache 1.3.12 及以上； PHP 5.4.0及以上； PHP-Extension: 软件 版本 备注 gd 2.0及以上 PHP GD扩展包必须支持PNG图片 bcmatch php-bcmatch ctype php-ctype libXML 2.6.15及以上 php-xml xmlreader php-xmlreader xmlwrite php-xmlwriter session php-session sockets php-net-socket mbstring php-mbstring gettext php-gettext ldap php-ldap mysqli 使用MySQL作为Zabbix后端数据库所需的组件 pgsql 使用PostgreSQL作为Zabbix后端数据库所需的组件 sqlite3 使用SQLite作为Zabbix后端数据库所需的组件 客户端浏览器：必须启用Cookie和JavaScript功能。 服务器： 要求 描述 OpenlPMI 支持IPMI功能所需组件 libssh2 支持SSH功能 fping 支持ICMP ping功能 libcurl 支持Web监控，VMware监控及SMTP认证 libiksemel 支持Jabber功能 libxml2 支持VMware监控 net-snmp 支持SNMP监控 Java网关：Java gateway编译和运行在Java 1.6 及以上版本。 数据库容量：Zabbix配置数据需要使用固定的磁盘空间，而这个空间不会过多增长。 Zabbix数据库容量主要依赖于以下参数： 每秒处理值的数量(Number of processed values per second); 历史(History)数据的回收清理设置(Housekeeper); 趋势(Trends)数据的回收清理设置(Housekeeper); 事件(Events)数据的回收清理设置(Housekeeper)。 时钟同步：对于Zabbix稳定运行而言，服务获取精确的系统时间是非常重要的。对于所有运行Zabbix组件的系统，强烈建议这些系统的时间保持同步。ntpd是一个临幸的用于同步主机和其他服务器之间的时间的后台程序。 安装、启动、配置ZabbixZabbix-repo仓库：repo.zabbix.com该仓库服务器同时提供yum和apt源码库。 配置源码库1. 从官方下载源码库 1234567#rpm -ivh http://repo.zabbix.com/zabbix/$version/rhel/7/$arch/$zabbix-release.rpmrpm -ivh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.centos.noarch.rpm#阿里云镜像#rpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.noarch.rpm#镜像失效的话自己去官网找 2. 手动配置zabbix.repo 1234567vim /etc/yum.repos.d/zabbix.repo[zabbix]name=Zabbix-Repobaseurl=http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/gpgcheck=0enable=1 安装Zabbix部署包使用MySQL数据库安装Zabbix Server、Web前端：1yum install -y zabbix-server-mysql zabbix-get 注意：此处Zabbix数据库使用MySQL，请自行安装MySQL。 安装Zabbix Agent：1yum install -y zabbix-agent 安装初始化数据库查看刚刚安装的 zabbix-server-mysql：解压得到的sql脚本create.sql只会在对应的数据库中初始化zabbix所需要的数据库表，但是不会创建zabbix数据库。所以后面我们还需要手动创建zabbix数据库。1234567rpm -ql zabbix-server-mysqlcd /usr/share/doc/zabbix-server-mysql-3.x.xx/#有一个create.sql.gz的压缩文件gunzip create.sql.gz#得到create.sql 在MySQL中创建zabbix数据库：12345678910111213141516171819msyql -uxxx -pmysql&gt;CREATE DATABASE 'zabbix' DEFAULT CHARACTER SET 'utf8';mysql&gt;SHOW DATABASES;mysql&gt;GRANT ALL ON zabbix.* TO 'zabbix'@'localhost' identified by 'zabbix';mysql&gt;FLUSH PRIVILEGES;#导入sql脚本mysql -uroot -p -Dzabbix &lt; ./create.sqlUSE zabbix;SHOW TABLES;#mysql限制IPvim /etc/my.cnf[mysqld]bind-address=127.0.0.1 配置zabbix server并启动编辑zabbix server配置文件：123456789101112131415161718192021vim /etc/zabbix/zabbix_server.conf#常会修改的参数#数据库配置DBHost=localhostDBName=zabbixDBUser=zabbixDBPassword=zabbixDBPort=3306DBSocket=/var/lib/mysql/mysql.sock#服务监听端口ListenPort=10051#服务端源IPSourceIP=#日志记录方式，file使用指定文件作为日志文件，system将日志发往syslog，console将日志发送控制台LogType=fileLogFile=/var/log/zabbix/zabbix_server.log 启动zabbix服务端：1234567891011121314systemctl start zabbix-server#此处可能由于没有关闭SELinux而报错tail /var/log/zabbix/zabbix_server.logcannot set resource limit: [13] Permission denied#关闭SELinuxsetenforce=0vim /etc/selinux/configSELINUX=disabled#查看zabbix-server默认监听的10051端口netstat -nltp 安装zabbix webzabbix web可以安装在单独的主机上，只要能连接到zabbix database所在数据库就行。但为了方便，都安装在了server上。 zabbix web需要LAMP环境：12345#可能需要自己配置PHP remi源，注意PHP及扩展版本问题yum install -y httpd php php-mysql php-mbstring php-gd php-bcmatch php-ldap php-xml#指定php版本#yum --enablerepo=remi-php56 install php-mysql php-mbstring php-gd php-bcmatch php-ldap php-xml 安装zabbix web所需的两个包：123456789yum install -y zabbix-web zabbix-web-mysql#此处默认使用php5.4#因为我的环境是php5.6,会报错#此时就需要指定php版本来安装yum --enablerepo=remi-php56 install zabbix-web zabbix-web-mysqlrpm -ql zabbix-web#zabbix-web位于/usr/share/zabbix/ 编辑zabbix的前端Apach-PHP配置文件zabbix前端的Apache配置文件位于 /etc/httpd/conf.d/zabbix.conf:1234567891011121314151617181920212223242526272829vim /etc/httpd/conf.d/zabbix.conf#需修改时区php_value max_execution_time 300php_value memory_limit 128Mphp_value post_max_size 16Mphp_value upload_max_filesize 2Mphp_value max_input_time 300php_value always_populate_raw_post_data -1php_value date.timezone Asia/Shanghai#建议顺便修改/etc/php.ini的时区vim /etc/php.inidate.timezone = Asia/Shanghai#添加httpd的虚拟主机访问zabbix web&lt;VirtualHost IP:80&gt;servername zabbix.medocumentroot /usr/share/zabbix默认数据&lt;/VirtualHost&gt;#开启httpd服务systemctl start httpd 添加hosts后就可以利用域名访问zabbix-web端了。 1echo -e "192.168.1.9 \t zabbix.me" &gt;&gt; /etc/hosts 在web端配置zabbix在浏览器访问 http://zabbix.me 初始化zabbix配置。配置好后就需要用账号密码进行登录zabbix-web端dashboard。 默认用户名是：admin，密码是配置文件里面设置的。 登录进Dashboard后，可修改语言为中文。 如果你的Zabbix无法看到中文选项，那么可能需要如下操作：1234vim /usr/share/zabbix/include/locales.inc.php#修改'zh_CN' =&gt; ['name' =&gt; _('Chinese (zh_CN)'), 'display' =&gt; true], 如果又遇到中文乱码的问题，则可以从windows中挑选一些好看的中文字体，将对应字体文件放置到zabbix web的字体目录中。windows中字体后缀.TTF，Linux中为.ttf。注意修改大小写。123456789101112131415cd /usr/share/zabbix/fonts#只有一个默认字体 graphfont.ttf#将新字体放置到此目录下#修改配置文件中对应字体名称vim /usr/share/zabbix/include/define.inc.php#将默认字体名字修改为字体目录下 你需要的字体名define('ZBX_FONT_NAME', 'graphfont');define('ZBX_GRAPH_FONT_NAME', 'graphfont'); // font file name#栗子，如perpetua字图PER.ttfdefine('ZBX_FONT_NAME', 'PER');define('ZBX_GRAPH_FONT_NAME', 'PER'); // font file name 图形显示乱码，同样是用以上方法。在windowss上找一个中文字体上传到zabbix字体目录，并修改配置文件就可以了。 Zabbix Web界面菜单： 管理菜单，用于管理zabbix自身及zabbix相关设置； 配置菜单，用于配置监控相关设置； 报表菜单，为管理员生成一段时间内的监控统计信息； 检测中菜单，用于查看被监控的相关数据； 资产记录菜单，查看被监控的主机有哪些，以及相关的资产信息。 安装zabbix agentAgent端安装也非常方便，直接在Client上安装两个包即可。 123456789101112#配置zabbix源rpm -ivh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.centos.noarch.rpm#aliyun镜像#rpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.noarch.rpm#安装yum install -y zabbix-agent zabbix-senderrpm -ql zabbix-agent#/etc/zabbix/zabbix_agentd.conf zabbix的“主动模式”与“被动模式”都在/etc/zabbix/zabbix_agentd.conf中定义。配置最常用的agent端：12345678910111213141516171819202122232425262728293031vim /etc/zabbix/zabbix_agentd.conf####GENERAL PARAMETERS 通用配置PidFile=LogFile=####Passive checks related 被动模式配置#指定允许哪台服务器拉取本机数据Server=#指定agent端工作于被动模式时监听的端口号ListenPort=10050(默认)#指定agent端工作与被动模式时所监听的IP地址ListenIP=0.0.0.0(默认)#指定预生成的agent进程数量StartAgents=####Active checks related#agent工作于主动模式时，将消息推送到哪台Server上ServerActive=IP1,IP2...#指定当前主机主机名，Server端通过对应的主机名识别主机Hostname=#指明agent端每隔多少秒将采集的数据发往Server端RefreshActiveChecks=#栗子Server=192.168.1.9ServerActive=192.168.1.9Hostname=zabbix.me 启动zabbix-agent1234systemctl zabbix-agent start#查看状态,默认端口10050netstat -nltp 快速开始zabbix-web菜单zabbix-web界面中包含有监测中、资产记录、报表、配置、管理五项菜单。 登录和配置用户在浏览器输入 zabbix.me (修改hosts)，登录zabbix-web后台。 默认用户名：Admin，密码：zabbix。它是超级管理员。 为了防止暴力破解和词典攻击，连续尝试五次登录失败，zabbix界面将暂停30秒。 可以通过管理(Management)菜单下的用户(User)，新建、查看、管理用户信息。 zabbix在安装后自定义了两个用户： Admin用户是zabbix的超级管理员，拥有所有权限； Guest用户是一个特殊的默认用户。如果你没有登录，你访问zabbix的时候其实就是“guest”权限。guest默认没有任何权限。 你可以创建一个用户(user)并将其加入特定的用户组(Group)以提升用户权限。 可以仅用用户信息里面-报警媒介里面，自定义严重性的报警。只有勾选部分的报警信息才会发送过来。这也很棒！ 如果存在严重性则使用： Not classified Information Warning Average High Disaster 新建主机zabbix中的主机(host)是一个你想要监控的网络实体(物理的、虚拟的)。对于主机的定义非常灵活。它可以是一台物理服务器，一个网络交换机，一个虚拟机或一些应用。 可以通过配置(Configuration)菜单下的主机(Host)，查看已配置主机相关信息。默认有一个“Zabbix Server”的定义好的主机。 点击创建主机(Create host)后，填写对应的主机名称、添加对应的主机群组，zabbix-agent的IP地址和端口，以及其它信息。 新建监控项监控项是zabbix中获得数据的基础。没有监控项，就没有数据。因为一个主机中只有监控项定义了”单一的指标“或者”需要获得的数据“。 可以通过配置(Configuration)菜单下的主机(Item)，找到需要配置监控项(Item)的主机，然后创建监控项。主机默认是没有定义任何监控项的。 填写对应的监控名称、类型、键值、主机接口、信息类型等等信息。 可在监控(Monitoring)菜单中最新数据(Latest data)查看之前定义的监控项和获得的值。还可选择以图形(Graph)或值来查看监控项的相关信息。 同样也还以在Zabbix-Server端获得数据信息：12#zabbix_get -s $ip -k $valuezabbix_get -s 192.168.1.9 -k system.cpu.load 新建触发器监控项只用于收集数据。如果要自动评估收到的数据，我们则需要定义触发器(trigger)。触发器包含了一个表达式，这个表达式定义了数据的可接受的阈值级别。 如果收到的数据超过了定义好的级别，触发器将被触发，或者进入异常状态(problem)。从而引起我们的注意，让我们知道有问题发生。如果数据再次恢复到合理范围，触发器将会转到正常状态(OK)。 可以通过配置(Configuration)菜单下的主机(Hosts)选项，找到某主机的触发器(Triggers)创建触发器。 填写对应的触发器名称、表达式、描述等信息。 获取问题通知当监控项收集了数据后，触发器会根据异常状态触发报警。根据一些报警机制，它也会通知我们一些重要的事情，而不是直接在zabbix-web端进行查看。这就是通知(Notification)的功能。E-mail是最常用的异常通知发送方式。当然还有SMS（短信），脚本等媒体类型。 可以通过管理(Administration)菜单中的报警媒体类型(Media types)，点击预定义媒体类型列表中的Email，来配置Email。 为了建立一个通知，我们需要在配置菜单下动作中，创建动作(Create action)。 一旦满足了触发器的条件，变回触发执行动作。如收到E-mail等… 新建模板如果我们配置上前台主机，一些自动化操作会带来更多便利性。没错，模板(templates)功能就可以实现。模板允许对有用的监控项、触发器和其他对象进行分组，只需要一步就可以对监控主机应用模板，已达到反复重用的目的。 当一个模板链接到一个主机后，主机会继承这个模板中的所有对象。简单而言，一组预先定义好的检查会被快速应用到主机上。 Zabbix为各种操作系统、设备以及应用准备好了一些预定义的模板。你可以快速部署使用他们。但是请注意，一些模板需要根据你的实际情况和使用环境进行适当俄调整。 比如，一些检查项是不需要的，一些轮询周期过于频繁等。 在配置菜单下的模板(Templates)下，点击创建模板(Create template)。填写对应的模板名称，群组等信息。 创建模板完毕后，可将模板链接到主机。之后，模板及其所有对象被添加到了主机。 配置(Configuration) 主机和主机组(Hosts and groups)一般来讲，zabbix主机是指你希望监控的那些设备。如服务器、工作站、交换机等。创建主机是使用zabbix过程的首要任务。 我们可以把主机组想象成项目组。根据不同的功能将主机划分到主机组是非常重要的，这样可以对以后创建的用户和用户组在定义权限的时候，不用给他们zabbix admin权限，而只需要根据主机组(项目组)给予用户和用户组对应项目(主机组)的权限即可。这样很大程度上方便了Zabbix监控多个项目，也利于管理。同样，报警的时候也只会收到权限内的相关报警信息。 配置一台主机配置–主机–创建主机–填写相关参数信息。 可以在已经存在的主机上使用 Clone或Full Clone创建一个新主机。 Clone将保留所有的主机参数和模板链接；Full Clone将额外保留指数实体(应用集、监控项、触发器、视图、规则、Web场景)。 新建主机下： 主机(Host)：包含了通用的主机属性； 模板(Template)：允许将模板链接诶到主机，所有实体将从模板继承； IPMI：包含IPMI管理属性； 宏(Macros)：允许定义主机级别的用户宏； 主机资产记录(Host inventory)：允许为主机收工输入库存信息； 允许你请求与主机的加密的连接。 资产管理(Inventory)你可以将联网设备的资产信息保存在zabbix里。资产信息实在配置主机时人工录入建立的资产信息数据，或者通过使用某些自动填充选项完成的录入。 构建资产库： 手动模式： 在配置一台主机的时候，手动输入资产信息； 自动模式： 在配置主机的时候，选择自动。 之后便可以在资产记录菜单中的概述，主机项中查看相关信息。 批量更新(Mass update)有时候可能需要一次更改多个主机的某些属性，使用批量更新(mass update)功能来代替打开每个主机进行编辑。 可批量处理主机、模板、IPMI、资产、加密相关信息。 监控项(Items)监控项是从主机收集的数据信息。配置主机后，需要添加一些监控项以开始获取数据。快速添加多个监控项的一种方法是将预定义的模板附加到主机。 在单个监控项中，可指定从主机收集哪些数据信息。为此，可使用监控项key。 如system.cpu.load将收集处理器负载的数据。要给 key 指定更过参数，请在后面添加方括号[]。 如system.cpu.load[avg5]， 返回最近5分钟的CPU负载平均值。 创建一个监控项可在主机中新建一个监控项。不支持的监控项：如果由于某种原因无法检索该值，则该监控项可能不被支持。这些监控项仍然以固定的间隔重新检查。 监控项的key: key名称允许使用字符： 0-9a-zA-Z_-. key参数，用 逗,号 分隔： xxx[par1,par2…] key参数也可以为空，此时使用默认值： key key参数带引号，则允许任何Unicode字符，如果包含双引号则需要 \反斜杠 转义 key参数是一个数组，它需要包含在方括号中 自定义间隔(Custom intervals) 创建关于监控项的自定义时间规则。灵活间隔被设计为重新定义默认监控项的的更新间隔，但调度间隔用于指定独立执行的检查计划。 灵活的间隔(Flexible intervals)：允许重定义特定时间段的默认间隔。 间隔(Interval)： 指定时间段的更新间隔； 期间(Period)： 灵活间隔有效的时间段； 举个栗子： 60(interval), 1-7,00-24(period)。监控项每隔60s检查一次。 调度间隔(Scheduling intervals)：用于在特定时间检查监控项。 调度间隔定义为， md&lt;filter&gt;wd&lt;filter&gt;h&lt;filter&gt;m&lt;filter&gt;s&lt;filter&gt;。 md: month days(1-31) wd: week days(1-7) h: hours(0-23) m: minutes(0-59) s: seconds(0-58) : 指定其前缀的值—-[from-to/step]。 其实类似于Linux中定时任务的写法，只不过这里把单位(md,wd,h,m,s)写在了数值的前面。 举个栗子： 123456789101112md1-15 #1-15号wd3 #星期三h0-12 #上半天m1,3,5,7,9 #每个1,3,5,7,9分钟s/10 #每个10s#组合体wd1-5h9-18m/10 #每个工作日的上班时间每个10分钟 监控项类型(Items type)监控项类型包含从系统获取数据的多种方式。每个监控项类型都有一组自己支持的监控项key和所需的参数。 zabbix提供的监控项类型： zabbix代理检查(agent checks) SNMP代理检查 SNMP traps IPMI检查 简单检查(simple checks) VMware监控(monitoring) 日志文件监控 计算监控项(Calculated items) zabbix内部检查(internal checks) SSH检查 Telnet检查 外部检查(External checks) 汇总检查(Aggregate checks) 捕捉器监控项(Trapper items) JMX监控 ODBC监控 zabbix代理(zabbix agent)：这些检查与zabbix代理进行通信实现数据的采集。 zabbix agent-passive： 被动模式，Server向Agent索要数据； zabbix agent-active： 主动模式，Agent主动上报数据给Server。 可支持的监控项，可在新建监控项是在键值里面查看。 SNMP代理(SNMP agent)： 在启用SNMP的设备(如打印机，交换机，路由器…)上使用SNMP监控，为了能够监控SNMP代理在这些设备上提供的数据，zabbix服务器初始化配置时必须具有SNMP支持。仅通过UDP协议执行SNMP检查。 配置SNMP监控： 使用SNMP接口为设备创建一个主机； 找出要监控项目的SNMP字符串； 创建一个监控项。 IPMI检查： 你可以在zabbix中监控 智能平台管理接口(IPMI) 设备的运行状况和可用性。要执行IPMI检查，zabbix服务器必须首先配置IPMI支持。 简单检查： 简单检查通常用于远程无代理监控服务。 日志文件监控： zabbix可用于集中监控和分析 具有/不具有 日志转动能力的日志文件。当日志文件包含某些字符串或字符串模式时，通知信息可用于警告用户。 计算监控项： 计算监控项是创建虚拟数据源的一种方式。这些值将根据算术表达式定期计算。所有计算都由Server完成。 内部检查：内部检查可以监控zabbix的内部检查。即Server或Agent Server的运行情况。 SSH检查： 运行SSH检查是作为无代理监控的，SSH检查不需要zabbix代理。执行SSH检查zabbix服务器必须初始化配置为SSH2支持。 SSH检查提供两种身份验证方法，一种是用户/密码，另一种是基于密钥文件。 zabbix SSH 密钥配置: 1234567891011vim /etc/zabbix/zabbix_server.conf#SSHKeyLocation=SSHKeyLocation=/home/zabbix/.sshusermod -m -d /home/zabbix zabbixchown zabbix:zabbix /home/zabbixchmod 700 /home/zabbixcd /home/zabbix &amp;&amp; su zabbixssh-keygen -t rsa 外部检查： 外部检查是由zabbix Server通过运行shell脚本或二进制的检查。外部检查不需要再被监控的主机上运行任何代理。 汇总检查： 在汇总检查中，zabbix通过直接从数据库中查询监控信息，然后进行信息聚合。聚合检查不需要再被监控的主机上运行任何代理。 捕捉器监控项： 捕捉器监控项接收传入的数据，而不是查询它。对于想要推送到zabbix的任何数据都是适用的。 要使用捕捉器监控项，需要在zabbix中建立一个捕捉器监控项，将数据送给zabbix。 JMX监控项： JMX监控可用于监视Java应用程序的JMX计数器。JMX监视器以zabbix守护进程方式运行，名为zabbix java gateway。 ODBC监控： ODBC监控对应于zabbix web管理端中的数据库监控器监控项类型。ODBC是用于访问 数据库管理系统(DBMS) 的C语言中间件API。 zabbix可以查询ODBC支持的任何数据库。为了实现监控，zabbix不直接连接到数据库，而是使用ODBC中设置的ODBC接口和驱动。该功能允许为多个目的更加有效地监控不同的数据库。 历史与趋势(history and trends)历史与趋势是zabbix中存储数据的两种方式。历史保持每个收集的值，而趋势是每小时的平均信息。 建议保持的历史数据尽可能少，但可以保留更多的趋势数据。 用户自定义参数(user parameter)有时你想运行一个代理检查，但它不是zabbix预定义的。这时就能用到用户参数。用户参数是由zabbix代理之星的命令，最多可以返回512KB的数据。key 是唯一的。 用户参数用法： 12345678910111213141516171819202122UserParameter=&lt;key&gt;,&lt;command&gt;#栗子UserParameter=ping,echo 1#使用ping键为一个监控项返回 1#复杂栗子UserParameter=mysql.ping,mysqladmin -uroot -ppwd ping | grep -c 'alive'#mysqld状态为alive返回1，否则0#灵活的用户参数UserParameter=key[*],command#[*]定义该key接受括号内的参数#栗子UserParameter=ping[*],echo $1UserParameter=mysql.ping[*],mysqladmin -u$1 -p$2 ping | grep -c 'alive'#mysql.ping[zabbix,passwd]UserParameter=wc[*],grep -c "$2" $1#wc[/etc/passwd,root] 用户自定义参数扩展zabbix代理：是将key添加到被监控的主机哦！123456789101112131415161718#编写命令--SQL查询总数mysqladmin -uxxx -pxxx status | cut -f4 -d":" | cut -f1 -d"S"#将命令添加到zabbix_agentd.confvim /etc/zabbix/zabbix_agentd.conf#找到如下字段### Option: UserParameterUserParameter=mysql.totalquery,mysqladmin -uroot -pxxx status | cut -f4 -d":" | cut -f1 -d"S"#mysql.totalquery这个key是唯一的标识符#测试此参数##测试参数可用与否很重要哈zabbix_agentd -t mysql.totalquery#重启zabbix-agent，将重新加载配置zabbix_get -s $host -k mysql.totalquery 可加载模块(loadable modules)可加载模块提供了一种关于zabbix性能扩展的选项。 可加载模块基本上只zabbix守护程序使用的共享库，并在启动时加载。可加载模块具有很多优点，卓越的性能和可实现任何逻辑的能力，更重要的是使用和共享了zabbix模块的开发能力。 windows性能计数器(windows perfomance counter)使用perf_counter[]key有效的监控windows性能计数器 批量更新(mass update)使用批量更新功能，可一次更改多个监控属性。 值映射(value mapping)对于接收值更人性化的表示，可以使用包含数值和字符串之间的映射的值映射。 如： 0 —&gt; error 1 —&gt; true F —&gt; Full D —&gt; Differential I —&gt; Incremental … 应用集(Application)应用集对逻辑组中的监控项进行分组。 如，对MongoDB的可用性，空间，负载，慢查询，执行命令…，可归于 MongoDB应用于中。 队列(queue)队列显示正在等待刷新的监控项。队列只是一个逻辑表达的数据。 队列显示的统计信息是zabbix服务器性能是否健康的指标。在 管理–队列 下对去队列。 值缓存(value cache)为了计算触发表达式，以及让计算/聚合监控项和一些宏更快，zabbix服务器支持值的缓存选项。 在内存中的缓存可用于访问历史数据，而不用之间调用数据库。如果缓存中不存在历史值，则从数据库请求缺少的值，并相应地跟新缓存。 要启用值缓存功能，修改zabbix_server.conf中可选的ValueCacheSize参数。 触发器(Trigger)触发器是评估有项目采集的数据并表示当前系统状况的逻辑表达式。触发器表达式允许定义一个什么状况的数据是“可接受”的阈值。如果超过了可接受状态，则触发器会被触发。 配置一个触发器(configuring a trigger)在主机里面配置触发器。 触发器表达式(trigger expression)一个简单有效的表达式看起来像： 1234&#123;&lt;server&gt;:&lt;key&gt;.&lt;function&gt;(&lt;parameter&gt;)&#125;&lt;operator&gt;&lt;constant&gt;#如&#123;192.168.1.7:agent.ping.time()&#125;=0 函数参数(function parameters)： 大多数数字型的函数接受秒数来作为参数。 1234567891011121314#600s内所有值的总和sum(600)#随后5个值总和sum(#5)avg()count()last()min()max()#5m 可被 300s 代替#1k 代表 1024bytes 运算符(operators)： 优先级 运算符 定义 1 - 负号(minus) 2 not 逻辑非(NOT) 3 *, / 乘，除 4 +, - 加，减 5 &lt;, &lt;=, &gt;, &gt;= - 6 =, &lt;&gt; 相等，不等于 7 and 逻辑与 8 or 逻辑或 触发器示例： 12345678910111213&#123;www.zabbix.com:system.cpu.load[all,avg1].last()&#125;&gt;5&#123;www.zabbix.com:system.cpu.load[all,avg1].last()&#125;&gt;5 or &#123;www.zabbix.com:system.cpu.load[all,avg1].min(10m)&#125;&gt;2&#123;www.zabbix.com:net.if.in[eth0,bytes].min(5m)&#125;&gt;100k&#123;$url1:net.tcp.service[smtp].last()&#125;=0 and &#123;$url2:net.tcp.service[smtp].last()&#125;=0&#123;$host:icmpping.count(30m,0)&#125;&gt;5&#123;$host:system.cpu.load[all,avg1].min(5m)&#125;&gt;2 and &#123;$hsot:system.cpu.load[all,avg1].time()&#125;&gt;000000 and &#123;$host:system.cpu.load[all,avg1].time)()&#125;&lt;060000... 滞后(Hysteresis): 有时候需要一个触发器状态OK和PROBLEM之间的间隔，而不是简单的阈值。 要做到这一点，我们首先定义一个PROBLEM事件的触发器表达式，然后为OK选择 ‘Recovery expression’，并未OK事件书如不同的表达式 如： 1234567#Problem expression&#123;server:temp.last()&#125;&gt;20#Recovery expression&#123;server:temp.last()&#125;&lt;=15#两者之间便有了几个滞后值 触发器依赖(trigger dependency)有时候，一台主机的可用性取决于另一台主机。如一台路由器后的上网设备。这就是主机之间某些依赖关系可能有用的地方，依赖关系设置的通知可能会被抑制，而只发送根本问题的通知。 zabbix中触发器的依赖，一个触发器可能有多个依赖于它的触发器。 路由器和路由器后的Server同时宕机，如果有依赖关系，则zabbix不会执行服务器的触发动作。值得注意的是，如果触发器所依赖的触发器被禁用，则次触发器的事件和动作将不会被抑制。 批量更新使用批量更新，可一次更改一些触发器的某些属性。 触发器严重性(trigger severity)触发器严重性定义了触发器的重要程度: 未分类(not classified), 灰色 信息(information), 淡蓝 警告(warning), 黄色 一般严重(average), 橙色 严重(High), 淡红 灾难(disaster), 红色 自定义触发器严重性(customising trigger)在 管理 – 一般 – 触发器严重性，里面自定义触发器严重性。 预测触发功能(predictive trigger function)有时候有即将到来的问题的迹象。可以发现这些迹象，以便提前采取行动，以减小影响。 zabbix具有基于历史数据预测受监视系统的未来行为的工具，这些工具通过预测触发功能实现。 事件标签(event tag)在zabbix中可以自定义事件标签，在触发器级别上定义事件标签。在事件标签定以后，相应的新事件被标记为时间标签数据。在拥有自定义时间标签的情况下，可以变得更加灵活。 例如： 识别日志文件中的问题并单独关闭他们； 用它来过滤通知； 查看前端的事件标签信息； 从项目值中提取的信息作为标签值； 在通知中更好地识别问题； 通过使用模板级别的标签来建华配置任务； 使用低级别发现的标签创建触发器。 事件(Events)zabbix可以生成一下几种类型的事件： trigger events-触发器事件； discovery events-发现事件； auto registration events-自动注册事件； internal events-内部事件； 事件以时间戳，并可以发送Email等基础动作。在 监控-问题 里面查看信息信息。 触发器事件生成(trigger events generation)触发器状态的变化是事件最常见和最重要的来源。每次触发器的状态改变时，都会生成一个事件。改时间包含了触发器状态变更的详细信息、发生时间以及信息的状态。 触发器会创建两种类型的事件：问题(problem)和正常(OK) 手动关闭问题事件(manual closing of problems)当触发器状态从“问题(problem)”变成“正常(OK)”时，很难判断是通过触发器表达式的方式解决。这时就需要手动解决。 只有在触发器中启用 “允许手动关闭” 选项，问题事件才可以被手动关闭。 其他事件来源(other event source)zabbix定期扫描网络发现规则中定义的IP范围，可以为每个规则单独配置检查频率。一旦发现主机或服务，就会生成一个发现事件。 zabbix可以生成以下事件： 1234Service Up/DownHost Up/DownService Discovered/LostHost Discovered/Lost 事件关联(event correlation)通常，在zabbix中正常事件会关闭所有的问题事件，但在某些情况下需要更细致的方法。可以根据事件标签关联问题事件。如，当监控日志文件时，在日志文件中想要发现某些问题，并将它们单独关闭，而不是一起关闭。 可视化(visualisation)图形(graphs)大量的监控数据被采集到zabbix中，如果能用可视化的表现形式来查看，那就直观和容易多了。 zabbix为用户提供了如下图形： 监控项数据的内置简单图形 “simple graphs”； 创建更复杂的自定义图形 “customised graphs”； 特定图形 “ad-hosc graphs”快速访问几个监控项的数据比较。 简单图形(simple graphs)：zabbix提供的简单图形，用来可视化显示监控项采集到的数据。并不需要配置就可以查看。 通过 监控-最新数据-图形 来展示图形。 自定义图形(customised graphs)：自定义图形，提供定制功能。这就有点厉害了。这个是手动配置的。可以为单个主机、多个主机、单个模板、多个模板创建自定义图形。 在 配置-主机-图形-创建图形 里编辑图形属性；图形编辑后可点击预览。 特设图形(ad-hoc graphs)：简单图形和自定义图形都不允许快速创建多个监控项目数据的比较图形，工作量小且没有维护。 在 检测-最新数据-旋转监控项前复选框-显示数据图(显示堆叠数据图) 下， 里面也包含了 正常和层积 的图形风格。 拓扑图(networking maps)运维人员如果想要了解网络环境的基础设施状况，可以在zabbix中创建网络拓扑图。 配置拓扑图(configurating network maps): 在 监控-拓扑图 下，可以创建拓扑图。点击拓扑图中的 构造函数 选项，来打开编辑区域。然后在编辑区域中添加元素和链接元素。 链接指示器(link indicators):可以为网络拓扑图中的元素之间的链接分配一些触发器，当这些触发器状况为“Problem”时，可以在链接上体现出来。如果多个触发器进入”Problem”状态，则严重程度最高的将决定链接的颜色和样式。 聚合图形(screen)在zabbix的聚合图形页面上，你可把各种来源的信息聚集到一起，一边在单个屏幕上快速查看。在 监测-图形聚合 下，对其进行创建、配置、管理和查看。 基本上，聚合图形是一个表格，你选择把每个表格有多少单元格以及其中要显示的元素。元素如下： 简单图形； 简单图形原型； 用户自定义图形； 自定义图形原型； 拓扑图； 其他聚合图形； 纯文本信息； 服务器信息； 触发器信息； 主机/主机组信息； 系统状态； 数据概述； 时钟； 事件历史； 动作历史； URL。 幻灯片演示(slide shows)在幻灯片演示中，可以配置多个聚合图形以设定的间隔逐个显示。在 监测-聚合图形-幻灯片演示 下。 模板(template)模板是可以方便地应用于多个主机的一组实体。 配置模板(configuring a template)：配置模板需要首先通过定义一些参数来创建模板，然后添加实例。在 配置-模板-创建模板 链接模板(linking)：链接是将模板应用于主机的过程，之后主机将拥有模板的所有实体。 嵌套(nesting)：嵌套是一种包含一个或多个其它模板的模板方式。可以在一个嵌套模板中奖一些模板链接在一起。 嵌套的好处在于，您只需要讲一个模板链接到主机，并且主机会自动继承链接的模板的所有实体。 事件通知(notifications upon events)当配置了一些项目和触发器，并且由于触发器改变状态，现在正在发生一些事件，之后就要考虑 action。发送通知是zabbix提供的主要操作之一。 为了能够发送和接收通知，必须： 定义一些media； 配置action，向指定的media发送消息。 action由condition和operation组成。当条件满足是，执行操作。操作主要是 发送消息和执行远程命令。 media类型媒体是zabbix中发送通知和警报的传送通道。 E-mail: 在 管理-媒体类型 下，配置Email。 SMS： zabbix支持使用连接到zabbix-server的串行端口的串行GSM调制解调器发送SMS消息。 确保： 串行设备的速度(在Linux下通常为/dev/ttyS0) 与 GSM调制解调器的速度相匹配。zabbix没有设置串行链路的速度，它使用默认设置。 zabbix用户对串行设备有读写访问权限。 GSM调制解调器输入PIN码，并在电源复位后保留PIN码。或者在SIM卡上禁用PIN。 管理-媒体类型下要为用户分配电话号码：管理-用户-报警媒介，添加报警媒介(如电话号码等) Jabber： zabbix支持发送jabber消息。 Ez Texting： 可以使用 zabbix技术合作伙伴 Ez Texting发送信息。 脚本： 警报脚本在zabbix服务器上执行，这些脚本位于服务器配置文件中定义的目录中(AlertScriptsPath)。123456789101112131415161718cat /etc/zabbix/zabbix_server.confAlertScriptsPath=/usr/lib/zabbix/alertscripts#创建报警脚本vim /usr/lib/zabbix/alertscripts/zabbix_test.sh#!/bin/bashto=$1subject=$2body=$3#可以同时给多个用户发送，用空格隔开cat &lt;&lt;EOF | mail -s &quot;$subject&quot; &quot;to&quot;$bodyEOF 然后我们在创建脚本媒体的时候，写入相关参数。 actions可以根据所有支持的类型的时间定义操作： 触发事件：当trigger的状态从OK转到Problem或回转时； 发现事件； 自动注册事件； 内部事件； 配置-动作-创建动作 条件(condition)只有在事件与定义的条件匹配的情况下才执行操作。 注意运算类型：似与非似 操作(operation)操作：发送信息，执行远程命令。 发送消息远程命令(不支持在zabbix-agent上执行远程命令，需要在zabbix-server到代理的命令才能直接连接。远程命令限制255字符，可以将过个命令放置于新行上来执行过个命令。及时目标主机处于维护状态，也会执行远程命令). 配置-动作-操作，在操作细节中修改操作类型为远程命令。 在Zabbix代理（自定义脚本）上执行的那些远程命令必须首先在相应的命令中启用 zabbix_agentd.conf.确保 EnableRemoteCommands 参数设置为 1 并取消注释。 如果更改此参数，请重新启动代理守护程序。 123456789101112vim /etc/zabbix/zabbix_agentd.confEnableRemoteCommands=1cd /usr/lib/zabbix/alertscripts#或修改zabbix-server.conf中的文件位置vi sendmail.shchown zabbix.zabbix ./sendmail.sh &amp;&amp; chmod a+x ./sendmail.sh 接下来在动作中选择为执行远程命令，并在相应位置输入命令。 支持自定义脚本、SSH、Telnet等方式。 在信息中使用宏(using macros in messages)：在消息主题和消息文本中，可使用宏来更有效的问题报告。 恢复操作(recovery operation):恢复操作允许在问题解决时通知我们。恢复操作支持消息和远程命令。 宏(macros)官方支持的宏的完整列表：https://www.zabbix.com/documentation/3.4/manual/appendix/macros/supported_by_location zabbix支持许多在多种情况下使用的宏。宏是一个变量，由如下特殊语法标识。 宏类似于全局变量，宏是特别有用的，特别是在报警动作中。对于不同的细节加上特定的宏，能够使报警信息更加详细。 {MACRO} 根据在上下文汇总，宏解析为一个特殊的值。有效地使用宏可以节省时间，并使zabbix更加高效。 宏可以在监控项键值参数中使用。宏只能用在监控项键值参数的一部分中。如item.key[server_{HOST.HOST}_local] 。 宏函数(macro function)宏函数能提供自定义宏值的功能。 宏函数语法：12345678&#123;&lt;macro&gt;.&lt;func&gt;(&lt;params&gt;)&#125;#&lt;macro&gt;, 要定义的宏#&lt;func&gt;, 要应用的函数#&lt;params&gt;, 以逗号分隔的函数参数列表#栗子&#123;&#123;ITEM.VALUE&#125;.regsub&#123;pattern, output&#125;&#125; 用户宏(user macro)除了支持开箱即用的宏之外，zabbix还支持更灵活的用户宏。 用户宏可在全局、模板和主机级别进行定义。有一个特殊语法：1&#123;$MACRO&#125; 用户宏可用于： 监控项名称； 监控项键值参数； 触发器名称和描述； 触发器表达式参数和常量； 许多其他位置。 自动发现宏(LLD)有一种自动发现(LLD)函数中使用的宏类型，可用于创建监控项、触发器和图形原型。然后，当发现真实的文件系统、网络接口等，这些宏将替换为真实的值，并且以这些值来创建真实的监控项、触发器和图形。1&#123;#MACRO&#125; 用户和用户组(user and group)zabbix中所有用户都通过web前端去访问zabbix应用程序。并为每一个用户分配唯一的登录名和密码，被加密储存于zabbix数据库中。 配置用户(configuring user)管理-用户，创建和管理用户。 权限(permission)可定义相应的用户类型，如用户，管理员和超级管理员。 用户组(groups)管理-用户组，创建和配置用户组。 服务监控(service monitoring)服务监控，旨在帮助那些想要高级业务监控的人。在很多情况下，我们关注的不是底层细节，而是提供的可用性服务。 服务是分层表示监控数据。 IT Workstations workstation1workstation2 Services 配置-服务，最高节点的服务是’root’。你可以通过添加低级服务节点和各个节点服务创建下层层次结构。 Web监控(web monitoring)配置-主机-web监测，创建或修改web监测信息。可使用zabbix检查几个网站可用性方面。(zabbix中包含libcurl库才行) 要使用web监控，需要定义web场景。包括一个或多个HTTP请求或步骤。Zabbix-Server根据预定义的命令周期性的执行这些步骤。 Web监测中的要求的字段(required string)支持正则表达式，所以这对于检索页面信息很有用。这个真的很有用！ 所有web场景会收集下列数据： 整个场景中所有步骤的平均下载速度； 失败的步骤数量； 最后一次错误信息 web场景的所有步骤，都会收集下列数据： 平均下载速度； 响应时间 HTTP状态吗 Web监控项(web monitoring items)在创建web场景时，会自动添加一些新监控项进行监控。 创建场景后，zabbix会自动添加以下监控项进行监控，将它们链接到所选的应用程序。 场景的下载速度； 场景的失败步骤； 场景的最后一个错误消息； 举个栗子：1234567891011121314151617181920212223242526272829303132333435363738394041##创建Web监测#配置-主机-Web监测-创建web监测URL：web.zabbix.me/monitor.php要求的状态码：200超时：20s##创建web监测触发器#配置-主机-触发器-创建触发器严重性：一般严重#触发条件：状态码!=200表达式：N&lt;&gt;200##创建触发报警对应的动作#配置-动作-创建动作#触发条件触发器示警度=一般严重 or 触发器=web.zabbix.me#操作：发送Email发送给zabbix administrator用户群组仅送到Email默认信息/自定义信息##在媒体类型中定义Email相关信息#管理-报警媒体类型-EmailSMTP服务器：smtp.xxx.comsmtp端口：465SMTP电邮：发件人Email安全链接：SSL/TLS认证：Usernameand passwd用户名：xxx密码： xxx##接下来就可以测试接收报警Email了 虚拟机监控(VM monitoring)zabbix支持对VMware的监控，使用low-levle-discovery(LLD)自动发现VMware hypervisors和虚拟机，并根据事先定义的主机原型，为这些虚拟机建立主机，添加监控。 zabbix中提供了几个模板，可以直接用来解控VMware vCenter 或 ESX hypervisor。 虚拟机监控分为两个步骤： 首先，zabbix是通过VMware collector进程来监控虚拟机。这些进程通过SOAP协议从VMware服务获取必要的信息，对其进行预处理并储存到zabbix-server共享内存中； 然后，zabbix-pollers通过zabbix简单检查VMware keys来检索这些数据。 要使虚拟机监控正常工作，需要libxml2库和libcurl库的支持。 配置-自动发现-创建自动发现配置-主机-自动发现 维护(maintenance)可在zabbix中为主机和主机组定义维护周期。有两种维护类型：“继续对目标进行监控数据的收集” 和 “停止对目标进行监控数据的收集” 要在维护期间正常接收问题通知，必须在动作配置中的选项中取消选择暂停操作。为了确保定期维护按照预期的时间进行，需要对zabbix的所有部分使用通用时区。 配置-维护-创建维护期 维护期的主机显示的是橙色背景！ 事件确认(event acknowledgment)zabbix中的问题事件可以由用户确认。 如果用户获得了有关问题时间的通知，可以访问zabbix前端，从时间导航到确认屏幕并确认问题。当他们确认时，可输入评论或其他一些相关描述。这样其他系统用户同样的问题，他们便会立即看到是否已被解决和目前的评论。 以这种方式，可以更协调的进行解决多个系统用户的问题的工作流程。 要确认事件，用户必须至少要有对相应触发器的读取权限。 在Dashboard下，在出现的问题里，点击确认，进入确认事件。也可在监控-问题下查看问题详细信息。 配置导出/导入(Configuration export/import)zabbix导入/导出功能，使得可以在一个zabbix系统与另一个zabbix系统之间交换各种配置实体。类似于数据库的导入导出。即也可以对zabbix做备份。 可导出/导入的对象有：主机组； 模板； 主机； 拓扑； 图片； 聚合图形； 值映射。 数据也可导出： XML - 在前端 XML or JSON - 在zabbix API 导出的详细信息： 所有支持的元素都导出到一个文件中； 不导出从连链接模板继承的主机和模板实体； 由低级别发现创建的实体依赖于他们的任何实体不会导出。 导入详细信息： 第一次遇到错误停止导入； 导入支持XML和JSON文件； 使用“删除缺失”选项导入主机/模板时，导入的XML文件中不存在主机/模板宏也将被删除。 将Zabbix展现在Nginx上毕竟现在Nginx用的多，那就把Apache换成Nginx吧！ Nginx仓库:http://nginx.org/packages/ 自己安装Nginx: 下载nginx-release-xx.rmp仓库源来安装； 手动创建/etc/yum.repo.d/nginx.repo； 直接下载ngix.rpm来安装； 直接下载源码来安装。 相较于Apache，Nginx也只是配置个server就行了。优化什么的自己弄。12345678910111213141516171819202122232425262728293031vim /etc/nginx/conf.d/zabbix.confserver &#123; listen 80; server_name zabbix.me; root /usr/share/zabbix; access_log /var/log/nginx/zabbix.access.log main; allow 127.0.0.1; allow Your-IP; deny all; location / &#123; if (!-f $request_filename) &#123; rewrite ^([^\?]+)$ /index.php?1=$1 last; &#125; &#125; location ~ \.php$ &#123; root /usr/share/zabbix; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; &#125;&#125;nginx -tsystemctl start nginx 下载就可以正常访问zabbix-web端了! Zabbix监控Zabbix自带的templates基本涵盖了大部分监控信息。 大部分操作系统： OS Linux; OS AIx; OS FreeBSD; OS Solaris; OS Windows; … 大部分服务： CPU; Filesystems; HTTP/HTTPS service; Memory; Network interfaces; Processes; Secutity; Zabbix server/agent/Proxy; SMTP,POP,SSH,NTP, service; ICMP Ping; SNMP; … 虚拟机： VM VMware; VM WMware Hypervisor; … 网络设备： Cisco; Huawei; TPLink; HP; … 除了Zabbix自带的templates，你还可以下载templates并导入zabbix-server。 例如PHP-FPM, MongoDB, Apache, Nginx, Redis等额外软件的监控就需要下载额外templates。 监控MySQL使用Zabbix自带模板监控MySQLZabbix默认带有MySQL的监控和模板，所以无需再去下载。不过需要配置用户，密码，主机，端口等信息。 123456789101112131415161718192021222324vim /etc/zabbix/zabbix-agentd.d/userparameter_mysql.conf#For all the following commands HOME should be set to the directory that has .my.cnf file with password information.#这句话叫我们新建一个带有mysql密码信息的.my.cnf文件#并把此配置文件里面的HOME改为.my.cnf所的在目录#.my.cnf文件里面的用户要对MySQL数据库有权限才行，没有权限请记得加[mysql]host=localhostuser=zabbixpassword=zabiixsocket=/var/lib/mysql/mysql.sock[mysqladmin]host=localhostuser=rootpassword=passwordsocket=/var/lib/mysql/mysql.sock#测试zabbix_get -s 127.0.0.1 -k mysql.ping#1 使用Percona插件监控MySQLZabbix默认带有MySQL的监控和模板，所以无需再去下载。不过需要配置用户，密码，主机，端口等信息。但是Zabbix自带的MySQL监控太简陋了。所以使用Percona提供的模板及监控。 Percona Monitoring Plugins-URL: https://www.percona.com/downloads/percona-monitoring-plugins/LATEST/Percona Monitoring Plugins for Zabbix- Instructions: https://www.percona.com/doc/percona-monitoring-plugins/LATEST/zabbix/index.html 此插件地址需要我们选择Percona-Version和Software平台。 选择平台后，我们只需安装zabbix的rpm包就好： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#安装rpm包yum install -y https://www.percona.com/downloads/percona-monitoring-plugins/percona-monitoring-plugins-1.1.7/binary/redhat/7/x86_64/percona-zabbix-templates-1.1.7-2.noarch.rpm#安装软件#注意php版本问题yum install -y percona-zabbix-templatesls /var/lib/zabbix/percona#scripts目录有.sh脚本文件#templates目录有配置文件和模板文件#复制配置文件cp /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf /etc/zabbix/zabbix_agentd.d/#我看了一下，这个配置文件和zabbix自带的MySQL配置文件一样#添加MySQL的相关信息vim /var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php$mysql_user = 'root';$mysql_pass = 'password';$mysql_port = 3306;$mysql_socket = '/var/lib/mysql/mysql.sock';$mysql_flags = 0;#测试脚本/var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh gg#10#创建.my.cnf文件vim /etc/zabbix/zabbix_agentd.d/.my.cnf[mysql]host=localhostuser=rootpassword=passwordsocket=/var/lib/mysql/mysql.sock[mysqladmin]host=localhostuser=rootpassword=passwordsocket=/var/lib/mysql/mysql.sock[client]host=localhostuser=rootpassword=passwordsocker=/var/lib/mysql/mysql.sock#重启服务systemctl restart zabbix-agent#测试sudo -u zabbix -H /var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh running-slave#0/1 导入模板，模板文件位于：/var/lib/zabbix/percona/templates/zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.7.xml 但我直接导入模板时报错——标签无效 “/zabbix_export/date”: “YYYY-MM-DDThh:mm:ssZ” 预计。此模板需要先导入Zabbix2.4后再导出，然后再导入到Zabbix3.4。太麻烦。 所以需要下载修改过的模板： http://jaminzhang.github.io/soft-conf/Zabbix/zbx_percona_mysql_template.xml 1wget http://jaminzhang.github.io/soft-conf/Zabbix/zbx_percona_mysql_template.xml 下载之后导入模板，然后链接主机。链接之后可以部分监控可能显示不支持的。 如：Received value [rm: 无法删除”/tmp/localhost-mysql_cacti_stats.txt”: 不允许的操作0] is not suitable for value type [Numeric (float)]没有权限。 解决办法： 1234cd /tmpchown -R zabbix:zabbix localhost-mysql_cacti_stats.txtsystemcet restart zabbix-agent 监控MongoDB感谢大神： MongoDB-templates: https://share.zabbix.com/databases/mongodb/mongodb-for-zabbix-3-2 ; GitHub: https://github.com/oscm/zabbix/tree/master/mongodb 此github-repo中还包含了Oracle, php-fpm, postfix, redis, Nginx。可参看README.md来配置zabbix对它们的监控。 安装步骤1. 在zabbix-agent安装jqjq - Command-line JSON processor; 1yum install -y jq 2. 在zabbix-agent的MongoDB中创建用于监控的账号创建用于读取MongoDB相关信息的账户及其权限。 12345678910111213mongo&gt;use admin&gt;db.createUser( &#123; user:'zabbix', pwd:'zabbix', roles:[&#123; role:'clusterMonitor', db:'admin'&#125;] &#125;) 3. 在agent下载github仓库的MongoDB模板等文件 12345678910111213wget https://codeload.github.com/oscm/zabbix/zip/master -O master.zip#这里面不仅仅有mongodb，还有redis,php等。#我们只需要进入mongodb目录就好unzip master.zipcd ./zabbix-master/mongodbls#mongodb.sh , 执行脚本#userparameter_mongodb.conf ，配置脚本#zbx_export_templates.xml，zabbix模板文件 4. 移动并配置mongodb.sh 123456789101112cp ./mongodb.sh /etc/zabbixchmod a+x /etc/zabbix/mongodb.shvi mongodb.sh#如果HOST,PORT不是默认，请修改DB_HOST=127.0.0.1DB_PORT=27017DB_USERNAME=zabbixDB_PASSWORD=zabbix 5. 移动并修改userparameter_mongodb.conf 1234567cp ./zabbix-master/userparameter_mongodb.conf /etc/zabbix/zabbix_agentd.dvi ./userparameter_mongodb.confUserParameter=mongodb.status[*],/etc/zabbix/mongodb.sh $1 $2 $3 $4 $5#修改为mongdb.sh真实位置#这个是用户自定义的参数，可以之间写入到zabbix_agent.conf里面 6. 重启zabbix-agent 1systemctl restart zabbix-agent 7. 在zabbix-web导入mongodb模板 配置-模板-导入模板； 选择./master/mongodb/zbx_export_templates.xml模板文件，并导入； 接下来便可以在 templates中看到”Template App MongoDB”这个模板； 可将此模板链接到某个主机上监控，并到最新数据里查看相关MongoDB信息； 如果相对此模板就行修改，可编辑zbx_export_templates.xml文件。 监控一台主机上的额外mongod实例由于可能一台主机上运行的mongod实例不止一个，所以我们需要修改一下前面下载的配置文件，用以监控其它端口的mongod实例。 此处假设默认的mongod实例运行在27017端口上 另外还有一个mongod实例运行在27018端口上 此处假设我们已经完成了前面对27017mongodb的监控了 操作： 12345678910111213141516171819202122232425262728cd /etc/zabbixcp mongodb.sh mongodb_27018.shvim ./mongodb_27018.sh#配置监控的mongodb账号和端口DB_HOST=127.0.0.1DB_PORT=27018DB_USERNAME=zabbixDB_PASSWORD=zabbix#现在就有了提取27017/27018两个mongodb实例的脚本#mongodb.sh#mongodb_27018.shcd ./zabbxi-agentd.dvim userparameter_mongodb.conf#在默认的27017下面添加一行提取mongodb_27018信息的脚本UserParameter=mongodb.status[*],/etc/zabbix/mongodb.sh $1 $2 $3 $4 $5UserParameter=mongodb_27018.status[*],/etc/zabbix/mongodb_27018.sh $1 $2 $3 $4 $5#现在zabbix-server端就可以同时获取27017/27018两个mongodb实例的信息#但是Web界面还不能直接显示出来，因为27018的键值和默认不相同#没错，就是上面我们修改的 mongodb_27018.status[*] 接下来要在Zabbix-Web端配置监控项用以提取信息 我们先找到一个默认的MongoDB自带的配置模板，如MongoDB Connections current，点进去查看它的键值对为mongodb.status[connections,current] 因此我们只需要修改为我们配置文件里面的mongodb_27018.status[*]就可以了。 其余个监控项以此类推，我觉得其他服务也应该可以如此。 你也可以对此建立一个单独的模板，如MongoDB_27108 templates。在此监控模板下创建上面的监控项。这样就可以对所有主机生效了。也可以批量化操作，更方便一些。 下面是我的参考Template App MongoDB模板建立的Template App MongoDB_27018 监控PHP-FPM同样使用上面大神的模板。 步骤和监控MongoDB类似： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687#进入下载的文件目录cd ./zabbix-master/php-fpmcp ./php-fpm.xml.sh /etc/zabbixchmod a+x /etc/zabbix/php-fpm.xml.shvim /etc/zabbix/php-fpm.xml.sh#如果这三个参数修改了，请修改#因为是使用culr，所以请允许此IP能够访问此页面#另外还要Nginx允许Server-IP访问哦，不然无法读取数据#我测试的时候用IP无法获取数据，所以用的域名#如果没做域名解析，请加本地hosts#php-fpm_status使用我修改的HOST="localhost"PORT="80"#status="status"status="php-fpm_status"cp ./userparameter_php-fpm.conf /etc/zabbix/zabbix_agent.d/#当然也可以把这个用户自定义参数写入zabbix_agent.conf#修改自定义参数里面的文件位置vim /etc/zabbix/zabbix_agent.d/userparameter_php-fpm.confUserParameter=php-fpm.status[*],/etc/zabbix/php-fpm.xml.sh $1#php-fpm，nginx的状态必须用Nginx展现，Zabbix-Server是使用curl提取状态页面的信息vim /etc/nginx/conf.d/zabbix.confserver &#123; listen 80; server_name zabbix.me localhost;#如果localhost与其他配置文件冲突，那就用IP#server_name zabbix.me 127.0.0.1 Private-IP Public-IP; root /usr/share/zabbix; access_log /var/log/nginx/zabbix.access.log main;#allow无法使用localhost，所有内外网要分开写 allow 127.0.0.1; allow Private-IP; allow Public-IP; allow Zabbix-Server-IP; allow Remote-View-IP; deny all; location / &#123; if (!-f $request_filename) &#123; rewrite ^([^\?]+)$ /index.php?1=$1 last; &#125; &#125;#Nignx_Status location /nginx_status &#123; stub_status on; #开启nginx自带的状态检查功能 access_log off; &#125;#php-fpm_Status#php-fpm的默认状态页面是/status,/ping。我修改了一下。 location ~ ^/php-fpm_(status|ping)$ &#123; access_log off; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; &#125; location ~ \.php$ &#123; root /usr/share/zabbix; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; &#125;&#125; php-fpm状态页面的配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163vim /etc/php-fpm.d/www.conf#说明和用法如下，我做简单修改#修改默认值;pm.status_path = /statuspm.status_path = /php-fpm_status;ping.path = /pingping.path = /php-fpm_ping;ping.response = pongping.response = 200#用法zabbix.me/php-fpm_statuszabbix.me/php-fpm_ping#配置文件提供了格式化输出zabbix.me/php-fpm_status?htmlzabbix.me/php-fpm_status?html&amp;full; output syntax. Example:; http://www.foo.bar/status; http://www.foo.bar/status?json; http://www.foo.bar/status?html; http://www.foo.bar/status?xml; http://www.foo.bar/status?full; http://www.foo.bar/status?json&amp;full; http://www.foo.bar/status?html&amp;full; http://www.foo.bar/status?xml&amp;full#修改完毕后重启服务systemctl restart php-fpm nginx#具体看下面描述##这下面是说明; The URI to view the FPM status page. If this value is not set, no URI will be; recognized as a status page. It shows the following informations:; pool - the name of the pool;; process manager - static, dynamic or ondemand;; start time - the date and time FPM has started;; start since - number of seconds since FPM has started;; accepted conn - the number of request accepted by the pool;; listen queue - the number of request in the queue of pending; connections (see backlog in listen(2));; max listen queue - the maximum number of requests in the queue; of pending connections since FPM has started;; listen queue len - the size of the socket queue of pending connections;; idle processes - the number of idle processes;; active processes - the number of active processes;; total processes - the number of idle + active processes;; max active processes - the maximum number of active processes since FPM; has started;; max children reached - number of times, the process limit has been reached,; when pm tries to start more children (works only for; pm 'dynamic' and 'ondemand');; Value are updated in real time.; Example output:; pool: www; process manager: static; start time: 01/Jul/2011:17:53:49 +0200; start since: 62636; accepted conn: 190460; listen queue: 0; max listen queue: 1; listen queue len: 42; idle processes: 4; active processes: 11; total processes: 15; max active processes: 12; max children reached: 0;; By default the status page output is formatted as text/plain. Passing either; 'html', 'xml' or 'json' in the query string will return the corresponding; output syntax. Example:; http://www.foo.bar/status; http://www.foo.bar/status?json; http://www.foo.bar/status?html; http://www.foo.bar/status?xml;; By default the status page only outputs short status. Passing 'full' in the; query string will also return status for each pool process.; Example:; http://www.foo.bar/status?full; http://www.foo.bar/status?json&amp;full; http://www.foo.bar/status?html&amp;full; http://www.foo.bar/status?xml&amp;full; The Full status returns for each process:; pid - the PID of the process;; state - the state of the process (Idle, Running, ...);; start time - the date and time the process has started;; start since - the number of seconds since the process has started;; requests - the number of requests the process has served;; request duration - the duration in µs of the requests;; request method - the request method (GET, POST, ...);; request URI - the request URI with the query string;; content length - the content length of the request (only with POST);; user - the user (PHP_AUTH_USER) (or '-' if not set);; script - the main script called (or '-' if not set);; last request cpu - the %cpu the last request consumed; it's always 0 if the process is not in Idle state; because CPU calculation is done when the request; processing has terminated;; last request memory - the max amount of memory the last request consumed; it's always 0 if the process is not in Idle state; because memory calculation is done when the request; processing has terminated;; If the process is in Idle state, then informations are related to the; last request the process has served. Otherwise informations are related to; the current request being served.; Example output:; ************************; pid: 31330; state: Running; start time: 01/Jul/2011:17:53:49 +0200; start since: 63087; requests: 12808; request duration: 1250261; request method: GET; request URI: /test_mem.php?N=10000; content length: 0; user: -; script: /home/fat/web/docs/php/test_mem.php; last request cpu: 0.00; last request memory: 0;; Note: There is a real-time FPM status monitoring sample web page available; It's available in: @EXPANDED_DATADIR@/fpm/status.html;; Note: The value must start with a leading slash (/). The value can be; anything, but it may not be a good idea to use the .php extension or it; may conflict with a real PHP file.; Default Value: not set;pm.status_path = /statuspm.status_path = /php-fpm_status; The ping URI to call the monitoring page of FPM. If this value is not set, no; URI will be recognized as a ping page. This could be used to test from outside; that FPM is alive and responding, or to; - create a graph of FPM availability (rrd or such);; - remove a server from a group if it is not responding (load balancing);; - trigger alerts for the operating team (24/7).; Note: The value must start with a leading slash (/). The value can be; anything, but it may not be a good idea to use the .php extension or it; may conflict with a real PHP file.; Default Value: not set;ping.path = /pingping.path = /php-fpm_ping; This directive may be used to customize the response of a ping request. The; response is formatted as text/plain with a 200 response code.; Default Value: pong;ping.response = pongping.response = 200 效果图： 展现的话是在Agent端的Nginx上，这个更直观一些。而Zabbix-Server就是通过curl -s zabbix.me来获取数据的，并通过对数据的提取来返回给Zabbix-Server。所以收集php-fpm，nginx的信息状态，都是基于这个页面的。 现在导入PHP-FPM模板，导入操作同MongoDB。 12#就是这个文件zbx_export_templates.xml 导入模板后，直接链接模板就可以啦。然后就可以使用了。 监控NginxZabbix是通过stub_status模块实现对Nginx的监控。Nginx的ngx_http_stub_status_module模块提供了基本的Nginx状态信息，源码安装的话需要加上–with-http_stub_status_module编译参数，如果是epel源yum安装的话，已经默认启用该模块。 在Nginx配置文件中加入如下配置： 1234567891011121314location /nginx_status &#123; allow IP; deny all; stub_status on; access_log off;&#125;#栗子Active connections: 14server accepts handled requests 22889 22889 72510Reading: 0 Writing: 2 Waiting: 12 一些状态信息 Active connections当前active client的连接数，包括Wating accepts接受的客户端连接总数 handled已处理的连接总数。通常，handled与accepts相同，除非已达到了资源限制(如worker_connections限制) requests客户端请求总数 Reading当前nginx正在读取request header的连接数 Writing当前Nginx将reponse写回客户端的连接数 Waiting当前等待请求的空闲客户端的连接数 上面的结果还可通过命令来查看 1netstat -n | awk &apos;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a,S[a]&#125;&apos; 以上数据是通过Web端查看。但，我们需要把数据收集到Zabbix-Server。还需要使用之前下载同MongoDB，php-fpm一起的那个包。 操作，基本还是类似MongoDB，php-fpm。只是个别参数需要修改一下。 1234567891011121314151617181920cd ./zabbix-master/nginx/cp ./nginx.sh /etc/zabbix/chmod a+x /etc/zabbix/nginx.shcp ./userparameter_nginx.conf /etc/zabbix/zabbix_agentd.dvim /etc/zabbix/nginx.sh#HOST=&quot;localhost&quot;PORT=&quot;80&quot;#stub_status=stub_statusstub_status=nginx_statusvim /etc/zabbix/zabbix_agentd.d/userparameter_nginx.conf#修改成脚本对应的位置UserParameter=nginx.status[*],/etc/zabbix/nginx.sh $1 现在想以前一样导入模板。然后在链接模板就可以了。 监控Redis监控Redis，也是把包里面对应的文件复制过去就行。 123456789101112131415cd ./zabbix-master/rediscp ./userparameter_redis.conf /etc/zabbix/zabbix_agentd.d/#如果redis设置有密码，请加上密码#如果是不同的端口，请修改UserParameter=redis.local[*],redis-cli -h 127.0.0.1 -p 6379 info|grep $1|grep -v _human|cut -d : -f2#UserParameter=redis.local[*],redis-cli -h 127.0.0.1 -p 6379 -a Password info|grep $1|grep -v _human|cut -d : -f2UserParameter=redis.status[*],redis-cli -h $1 -p $2 -a Password info|grep $3|grep -v _human|cut -d : -f2UserParameter=redis.proc,pidof redis-server | wc -l#重启服务systemctl restart redis 导入模板，链接主机，OK。 系统监控 CPUCPU的性能状态信息： 简写 描述 说明 us user cpu tim 用户使用CPU时间 sy system cpu time 系统使用CPU时间 id idle cpu time CPU的空闲时间 wa io wait cpu time CPU等待IO时间 ni user nice cpu time 用nice调整进程优先级的CPU时间 st steal time 虚拟机偷取的CPU时间比，被强制等待虚拟CPU的时间 si softirq time 系统处理软件中断所花费的CPU时间 hi hard time 系统硬中断所花费的CPU时间 interrupt 中断 被处理过的中断数 cs Context switches 上下文切换 ql processor queue length 队列长度 processor load processor load 处理器负载，几核乘以几 Tips 当我们要监控并报警CPU使用率时，我们可以反过来用CPU空闲时间来定义 cpu idle tiem% + cpu usage time% = 1 (CPU usage time% gt 80%) == (CPU idel time% lt 20%) (CPU usage time% gt 90%) == (CPU idel time% &lt; 10%) 所以监控CPU使用率就可以监控CPU空闲时间，并依据这个报警 内存Zabbix中自带的Linux OS模板提供了Total memory和Available memory选项，这两者直接用模板就可以了。但没有提供内存使用率的选项，因此需要我们自定义。 内存使用率 = 可用内存 / 总内存 ast(vm.memory.size[available])/last(vm.memory.size[total]) 自定义内存使用率我们只需要在Linux OS模板下配置内存使用率，就可以一劳永逸。 配置(Configuration) 模板(Templates) OS Linux模板的监控项(Items) 创建监控项 监控项名称: Available memory percent 类型： 可计算的 键值： vm.memory.size[percent] 公式： 100*last(vm.memory.size[available])/last(vm.memory.size[total]) 记得将其加入Memory应用集，这样便于查找和管理 可加入单位： % 添加触发器 配置 模板 OS Linux模板 触发器 创建触发器，当可用内存率在三分钟内的平均值小于20%时报警 名字：Available memory percent lt 20% on {HOST.NAME} 严重性：一般严重 表达式： {Template OS Linux:vm.memory.size[percent].avg(3)}&lt;20 磁盘由于Zabbix-Server自带的Linux OS模板中的filesystem的监控是一个自动发现规则，而在应用集中的filesystem是没有监控项的。所有对于磁盘的监控和触发要在自动发现规则中去定义。 进程和端口Zabbix-Server自带有检测进程和端口的键值对。 检测进程数proc.num[&lt;name&gt;,&lt;user&gt;,&lt;state&gt;,&lt;cmdline&gt;] name: 进程名； user: 运行该进程的用户； state: run sleep zomb cmdline: ps -ef的最后那项，如/usr/bin/mongod -f /etc/mongod.conf 现在Zabbix-Server端测试： 1234567891011#zabbix-get --host hostname --key proc.num[&lt;name&gt;,&lt;user&gt;,&lt;state&gt;,&lt;cmdline&gt;]#检测mongd进程数量zabbix-get --host 192.168.1.11 --key proc.num[mongod,,,]#2，因为我开了两个mongd实例zabbix-get --host 192.168.1.11 --key proc.num[mongod,root,,]#1，只有一个是以root运行的，有一个是以mongod运行的 由于我们上面使用的MongoDB监控模板没有判断mongod进程存活与否的判断，此处我们在MongoDB模板中增加一个检查mongod进程的监控项，并创建对应的触发器。 端口net.tcp.listen[port] 检查 TCP 端口 是否处于侦听状态。返回 0 - 未侦听；1 - 正在侦听 此处我也用Mongod举例。我的两个mongod实例分别监听在27017,27018/tcp。 在Zabbix-Server端先测试： 123456#net.tcp.listen[port]zabbix-get --host 192.168.1.11 --key net.tcp.listen[27017]#1zabbix-get --host 192.168.1.11 --key net.tcp.listen[27018]#1 在Web端创建监控项和触发器与上面类似。 用户自定义参数(user parameter)我也是参考了上述大神的脚本，进行参考而来。 由于公司需要监控大量的Web页面和API接口的状态，并通过页面判断相关key-value的正确性，用以判断状态。此处可能由模拟登录等操作，Zabbix自带的Web监控不太够用，所以此处自定义用户参数来实现。 此处，我叫公司开发人员帮忙将全部接口以及Web页面内容都生成到一个json文件里，如 http://zhang21.cn/test.json。然后用jq命令解析json文件，里面key一一对应value，这样取值就很方便了。 jqjq 是一款命令行下处理 JSON 数据的工具。真的很好用！ jq官网：https://stedolan.github.io/jq/GitHub: https://github.com/stedolan/jq 安装jq 1yum install -y jq 使用jq 123456789101112131415161718192021222324252627282930313233jq --help#查看所有键键值curl --silent http://zhang21.cn/test.json | jq .###栗子&#123; "collapsectimes": 130, "collapsectimes": 0, "bootfailtimes": 23, "failrate": 0.3623, "bootrate": 0.3324, "time": "2018-01-25 15:03:30", "db_error": false&#125;#查看某个键值curl --silent http://zhang21.cn/test.json | jq '.time'curl --silent http://zhang21.cn/test.json | jq '.bootrate'###2018-01-25 15:03:300.3324#查看某个不存在的值，会返回nullcurl --silent http://zhang21.cn/test.json | jq '.zhang'###null json嵌套解析 1234cat test.json | jq '.location.city'###"Chengdu" json解析数组 1234cat test.json | jq '.array[1].name'###"Zhang" 内建函数 jq还有一些内建函数，如key,hss。 key用来获取json中的key元素： 123456789101112curl --silent http://zhang21.cn/test.json | jq 'keys'###[ collapsectimes, collapsectimes, bootfailtimes, failrate, bootrate, time, db_error] has用来判断是否存在某个key: 1234curl --silent http://zhang21.cn/test.json | jq 'has("time")'###true jq的select语句使用select函数来完成jq的过滤操作。jq的select语句太好了! select 接受一个条件表达式作为参数。其输入可以是迭代器，或者和 map 函数配合使用来处理数组。当输入中的某个元素使 select 参数中的条件表达式结果为真时，则在结果中保留该元素，否则不保留该元素。 对json文件的值是数组的，根据数据里面的key在取值，厉害厉害。 123456789101112131415161718192021222324252627cat zhang.json"array": [&#123; "ip": "192.168.1.11", "loads": 1234&#125;,&#123; "ip": "192.168.1.22", "loads": 567&#125;]####栗子cat /etc/zabbix/zhang.json | jq ".array[] | select(.ip == \"192.168.1.11\")"&#123; "ip": "192.168.1.11", "loads": 1234&#125;cat /etc/zabbix/zhang.json | jq ".array[] | select(.ip == \"192.168.1.11\").loads"1234我们在自定义用户参数的时候便可以将ip作为参数传入cat /etc/zabbix/zhang.json | jq ".array[] | select(.ip == \"$1\").loads" 编写自定义参数和脚本将脚本放置于/etc/zabbix，可将自定义参数写入zabbix-agentd.conf文件，也可单独写入/etc/zabbix/zabbix_agentd.d/(推荐)，这样修改更方便。 编写脚本文件123456789101112131415161718192021222324252627282930cd /etc/zabbixvim xbreport.sh########### Zabbix3.4# Zhang21# Thu Jan 25 15:20:44 CST 2018###########url="http://zhang21.cn/test.json"JQ=`which jq`CURL=`which curl`function XBREPORT() &#123; $CURL --silent $url | $JQ ".$1"&#125;if [ $# == 0 ]; then echo $"Usage $0 &#123;browsercollapsectimes|servercollapsectimes|xiaobaibootfailtimes|terminaldesktopfailrate|competebootrate|db_error&#125;" exitelse XBREPORT "$1"fi 编写自定义参数文件123456789101112cd /etc/zabbix/zabbix_agentd.dvim userparameter_XBreport.conf########### Zabbix3.4# Zhang21# Thu Jan 25 15:45:19 CST 2018##########UserParameter=XBreport[*],/etc/zabbix/xbreport.sh $1 测试自定义参数1234zabbix_get --host host --key XBreport[time]###"2018-01-25 17:03:18" 自定义用户参数额外由于我的json文件key对应的value中内嵌有数组，所以我需要再提取数组内的值。 12345678910111213141516171819curl http://zhang21.cn/test.json | jq &apos;.array&apos;###[ &#123; &quot;ip&quot;: &quot;1.1.1.1&quot;, &quot;loads&quot;: 1051 &#125;, &#123; &quot;ip&quot;: &quot;2.2.2.2&quot;, &quot;loads&quot;: 356 &#125;]#array[],array[1],array[2],array[n]#array[].ip, array[1].ip#array[].loads, array[2].loads 上面的数据中包含有zabbix无法解析的特殊符号，所以需要改变策略。 由于zabbix对UserParameter中包含\’”`*?[]{}~$?&amp;;()&lt;&gt;|#@这些特殊字符无法进行处理，此处有两种方法来解决。 在zabbix_agentd.conf中开启参数UnsafeUserParameters，将其值设置为1 或者，使用多个变量$1 $2 $3...来解决我这个数组值的问题 我是使用多个变量来解决我这个情况的。看下脚本。 1234567891011121314151617181920212223242526272829303132cd /etc/zabbixvim ./zhang.shurl=&apos;http://www.zhang21.cn/test.json&apos;JQ=`which jq`CURL=`which curl`function ZHANG() &#123; $CURL --silent $url | $JQ &quot;.$1&quot;&#125;if [ $# == 0 ]; then echo $&quot;Usage $0 &#123;aaa|bbb|ccc|...&#125;&quot; exitelif [ $# ==1 ]; then ZHANG &quot;$1&quot;elif [ $# == 2 ]; then ZHANG &quot;$1[$2]&quot;else ZHANG &quot;$1[$2].$3&quot;ficd /etc/zabbix/zabbix_agentd.d/userparameter_Zhang.confUserParameter=Zhangxx[*],/etc/zabbix/zhang.sh $1 $2 $3 测试： 123456systemctl restart zabbix-agentdzabbix_get --host host --key Zhangxx[array]zabbix_get --host host --key Zhangxx[array,0]zabbix_get --host host --key Zhangxx[array,0,loads]zabbix_get --host host --key Zhangxx[array,1,ip] 测试正确能取到值的话，在Web端设置相对应的监控项。注意自己定义的key不要写错了。 数组的key栗子： Zhangxx[array] Zhangxx[array,0]或Zhangxx[array,1] Zhangxx[array,0,ip], Zhangxx[array,0,loads] 在Web端添加监控项由于这个参数是我们自定义的，所以在填写监控项key的时候需要我们手动填写自己定义的参数。注意监控项的参数和信息类型。 这里我遇到一个问题，我自定义key的执行脚本在Web端报超时问题，无法取值。这是由于zabbix默认的脚本执行超时时间为3s，所以我们需要修改超时时间30s(最大值)。 12vim /etc/zabbix/zabbix_server.confvim /etc/zabbix/zabbix_agentd.conf 设置触发器和报警这个就根据你个人项目实际情况设置对于的触发器和报警。 短信报警腾讯短信服务由于公司使用的是腾讯企业邮箱，可以将邮箱直接与微信绑定，从而在微信中实时显示邮件消息，所以不用微信报警！ 此处使用的腾讯短信SMS服务： https://cloud.tencent.com/product/sms 短信文档： https://cloud.tencent.com/document/product/382/13445 API文档： https://cloud.tencent.com/document/product/382/13297 SDK文档： https://cloud.tencent.com/document/product/382/5804 Python SDK: https://cloud.tencent.com/document/product/382/11672 由于腾讯提供了程序SDK，所以我选择了linux自带的Python SDK。这里面有详细的Python使用方法，做一些小修改就可以使用了。 配置获取Python SDK获取Python SDK 申请SDK AppID和App Key申请SDK AppID以及APP Key。 申请完毕后，效果如下： 申请短信签名下发短信必须携带短信签名。短信签名需要上传公司证件进行认证，大概十分钟左右！ 效果如下： 申请短信模板下发短信内容必须经过审核。在此短信模板中，我们必须要定义相关变量{n}，其他都是不会变化的常量。此处我定义了五个变量，分别为了带入Zabbix中的宏： 问题名，{TRIGGER.NAME} 主机名，{HOST.NAME} 事件事件，{EVENT.TIME} 事件日期，{EVENT.DATE} URL，{TRIGGER.URL} SDK配置1234yum install -y eple-realseyum install -y python-pippip install qcloudsms Python代码配置腾讯文档：https://cloud.tencent.com/document/product/382/11672 由于我是向多人发送短信，所以做了小修改： 12345678910111213141516171819202122232425262728293031323334#zabbix-servercd /usr/lib/zabbis/alartscriptsvim sendSms.py#!/bin/python#coding: utf-8from qcloudsms_py import SmsSingleSenderfrom qcloudsms_py.httpclient import HTTPErrorimport sysappid = App IDappkey = App Keyphone_numbers = ["12345", "1234567"]#params = ["Problem", "Hostname", "Time", "Date","Url"]params = [sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4], sys.argv[5]]msender = SmsSingleSender(appid, appkey)for i in phone_numbers: try: result = msender.send_with_param(86, i, 短信内容模板ID, params) except HTTPError as e: print(e) except Exception as e: print(e) print(result) 要给sendSms.py加上可执行权限哈！chmod a+x ./sendSms.py。 sys.argv变量是一个字符串的列表。特别地，sys.argv包含了命令行参数 的列表，即使用命令行传递给你的程序的参数。使用Python的sys.argv[n]可以像shell一样将放在文件后的变量传入文件执行。此处对于在Zabbix-Web端将宏放在脚本后，作为变量传入，非常重要。 sys.argv[0]代表sendSms.py文件 sys.argv[1]才代表第一个参数。 Zabbix Web端配置配置-动作-创建动作-操作 注意事项： 建议针对触发器示警度最高就行短信报警，其它交给Email 操作类型，选择远程命令 目标列表，选择当前主机 类型，自定义脚本 执行在，这个一定是放在Zabbix-Server上来执行哈 命令，文件名SendSms.py后面接的宏一定要加上双引号(“”) 最后根据不同的内容，设置不同的报警机制。后台的脚本也修改为对应的名称，修改里面对应的手机号码。 首先根据不同报警设置不同的触发条件 运维组，SendSms_dev.py，修改运维对应的号码 开发组，SendSms_develop.py，修改对于的号码 其实这个发送短信，就是在执行远程命令。 你命令里是发送短信就发送短信，你命令里是发送邮件就发送邮件。这个还是挺不错的。 针对不同业务向不同人员报警有时候我们只需要关心我们自己那部分就可以了，没必要所有报警都发送给所有人，这样很不方便。 所以，我们可以根据业务相关，组别权限等，分别向不同的人报警不同的信息。 如下我的一个栗子图：]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git]]></title>
    <url>%2F2017%2F11%2F07%2FGit%2F</url>
    <content type="text"><![CDATA[参考： 廖雪峰Git教程 Git介绍git(/ɡɪt/)是一个分布式版本控制软件,最初由林纳斯·托瓦兹（Linus Torvalds）创作，于2005年以GPL发布。Git是免费的。 林纳斯·托瓦兹自嘲地取了这个名字“git”，该词源自英国俚语，意思大约是“混账”。 集中式与分布式集中式版本控制系统，版本库是集中存放在中央服务器的，而干活的时候，用的都是自己的电脑，所以要先从中央服务器取得最新的版本，然后开始干活，干完活了，再把自己的活推送给中央服务器。集中式版本控制系统最大的毛病就是必须联网才能工作。常用集中式版本控制系统有：CVS、SVN。 分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。既然每个人电脑上都有一个完整的版本库，那多个人如何协作呢？比方说你在自己电脑上改了文件A，你的同事也在他的电脑上改了文件A，这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。常用分布式版本控制系统有：Git。 和集中式版本控制系统相比，分布式版本控制系统的安全性要高很多，因为每个人电脑里都有完整的版本库，某一个人的电脑坏掉了不要紧，随便从其他人那里复制一个就可以了。而集中式版本控制系统的中央服务器要是出了问题，所有人都没法干活了。 Git常用命令 创建版本库1234567891011121314151617181920212223242526272829303132333435#--global全局配置git config --global user.name &quot;Username&quot;git config --globla user.email &quot;Email&quot;#创建版本库#虽然在任意目录下都可创建git-repo，但还是建议在一个空目录下创建git-repomkdir gitest&amp;&amp;cd gitest#init, Create an empty Git repository or reinitialize an existing onegit init#生成了一个.git目录，这个目录是git用来追踪管理版本库的，不要随意修改此目录的内容echo &quot;First Git test&quot; &gt; README#所有的版本控制系统，只能跟踪文本文件的改动#把文件添加到仓库#git add file1 file2...git add README#把文件提交到仓库#-m, 为本次提交的说明信息git commit -m &quot;Update Readme&quot;#为什么Git添加文件需要add, commit一共两步呢？#因为commit可以一次提交很多文件，所以你可以多次add不同的文件。git add file1 file2 file3git commit -m &quot;add 3files&quot; 时光穿梭机12345678#查看repo当前状态git status#查看改变git diff 版本回退每当文件修改到一定程度的时候，就可以提交一次。这样即使误操作后，还可以从最近的commit中恢复，而不是把工作成果全部丢失。 123456789101112131415161718192021222324252627282930#查看提交记录#git的commit id是一个SHA1的16进制散列git log Update README.mdcommit e89d28373c19321466f99e15cd3cdcc5fffe868fAuthor: zhang21 &lt;elite_zhang21@163.com&gt;Date: Thu Apr 5 23:40:13 2018 +0800#版本回退，如果文件误删，可以从commit中恢复#查看提交记录，能看到Commit ID(sha1sum散列值)#在Git中，用HEAD表示当前版本，也就是最新的Commit ID#上一版本HEAD^, 上上版本HEAD^^, 倒数第十个版本HEAD~100#HEAD指的是当前版本#重置当前HEAD到指定状态git reset --hard HEAD^#也可以利用commit id回退git reset --hard $commit_id#查看历史命令git reflog 工作区和暂存区 git add实质是吧文件修改添加到暂存区 git commit实质是把暂存区的所有内容提交到当前分支 管理修改为什么git比其它版本控制系统设计的更优秀，因为它跟踪并管理的是修改，而非文件。如果修改后的文件没有使用git add放入暂存区的话，那么git commit也不会生效的。 撤销修改如果要纠正文件，可以手动修改文件并恢复到上一版本状态。但也可以使用git命令。 12345678910#丢弃工作区的修改#--很重要，没有--就变成了切换分支的命令git checkout -- filename#当你不但改乱了工作区某个文件的内容，还添加到了暂存区时。想丢弃修改，分两步。#第一步用命令git reset HEAD file，就回到了场景1，第二步git checkout --file。git reset HEAD file &amp;&amp; git checkout -- file 删除文件在git中，删除也是一个修改操作。 有两种情况： 误删除 真删除 12345678#rm，从工作区和索引中删除文件#如果一个文件已经被提交到版本库，那么你永远不用担心误删git rm README#误删某文件，需要恢复git checkout -- README 远程仓库用于验证推送，GitHub与本地仓库使用SSH加密传输，所以这需要创建一对密钥。 12345#生成SSH Keyssh-keygen -t rsa -C &quot;email-address&quot;#会生成.ssh目录，里面包含公私钥#将公钥id_ras.pub填入GitHub 添加远程仓库12345678910111213#origin是默认的远程仓库名，你可以修改git remote add origin git@xxx.com:username/xxx.git#推动本地仓库到远程#实际上是推动本地的master分支到远程#-u关联了本地master和远程mastergit push -u origin master#之后git push origin master 从远程库克隆1234567#将远程仓库克隆到本地#如果是多人协作开发，那么每个人各自从远程克隆一份就可以了#可以使用ssh协议或https协议(每次都要输入口令)git clone git@xxx.com:username/xxx.git#克隆指定分支git clone -b test URL 分支管理你可以创建一个自己的分支，别人看不到，还继续在原来的分支上正常工作。而你在自己的分支上干活，想提交就提交，而不会影响到其他人。 创建于合并分支HEAD严格来说不是指向提交，而是指向分支(如master)，分支才是指向提交。 当工作完成后，便可合并分支，然后删除额外的分支。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#查看分支#*代表当前工作分支git branch#创建分支git branch &lt;branch-name&gt;#切换分支git checkout &lt;branch-name&gt;#创建并切换分支，等于上面的创建和切换分支git checkout -b &lt;branch-name&gt;#在test分支下新建test.txtgit checkout testecho &apos;Just a test&apos; &gt; ./test.txtgit add test.txtgit commit -m &apos;Just a test branch&apos;#回到mastergit checkout master#此分支下并没有test.txt#也就是说并没有其它分支提交的内容#合并分支到当前分支git merge &lt;branch-name&gt;#合并test分支到当前的master分支git merge test#删除分支git branch -d &lt;branch-name&gt;#合并完成后删除test分支git brancd -d test 解决冲突合并分支玩玩也不是一帆风顺的！ 可能在你创建了新分支后，master分支又进行了提交，而你的新分支也做了提交，这是合并分支便会带了问题。当git分支无法合并时，就必须首先要解决冲突。解决冲突后，再提交和合并。 123#查看分支合并图git log --graph 分支管理策略 在实际开发中，master分支应该是非常稳定的。也就是只用来发布新版本，不能在上面干活 干活应在其它分支上(如dev)，干完后合并到master 工作人员都在dev上干活，每个人都有自己的分支，然后将自己的分支合并到dev就可以了 合并分支时，加上--no-ff参数就可以用普通模式合并，合并后的历史有分支，能看出来曾经做过合并，而fast forward合并就看不出来曾经做过合并。 Bug分支Git提供了一个stash功能，可以把工作现场储藏起来，等以后恢复现场后继续工作。 1234567891011121314151617181920git stash#创建debug分支git checkout -b &apos;issue-25&apos;git checkout mastergit merge --no-ff -m &quot;debug 25&quot; &apos;issue-25&apos;#切回工作区git stash listgit stash apply stash@xxx#手动删除stashgit stash drop#恢复同时也删除stashgit stash pop Feature分支添加一个新功能时，你肯定不希望因为一些实验性质的代码，把主分支搞乱了，所以，每添加一个新功能，最好新建一个feature分支，在上面开发，完成后，合并，最后，删除该feature分支。 丢弃一个没有被合并过得分支，可通过git branch -D &lt;branch-name&gt;强行删除。 多人协作123456789101112131415161718192021222324#查看远程仓库git remote#显示远程仓库详细信息git remote -v#推送指定分支git push origin test#抓取分支git clone#更新分支git pull#合并分支git merge#推送分支git push 版本库（Repository）隐藏目录.git是Git的版本库。Git版本库里面存放了很多东西，其中最重要的就是 stage(或index)的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。 用git add把文件添加进去，实际是把文件添加到暂存区； 用git commit提交更改，实际是把暂存区的所有内容提交到当前分支。默认git commit就是往master上提交更改。 SSHKey 创建SSHKey并在本地关联多个SSH 123#把你的github邮箱地址ssh-keygen -t rsa -C &quot;email@example.com&quot;#会生成 ~/.ssh，包含 私钥：id_rsa，公钥：id_rsa.pub 将公钥写入Github在Github–Account settings–SSH Keys–Add SSH Key里面，添加你的id_rsa.pub公钥文件。当然，你可以添加多个Key哦，毕竟可能你有多台登陆设备。这个就相当于SSH无密钥认证。 在主机上关联多个git 12345678910111213141516171819202122232425262728293031vim ~/.ssh/config#OneHost git.xxx.com IdentityFile ~/.ssh/id_rsa Hostname IP User git Port 10022#twoHost github IdentityFile ~/.ssh/id_rsa Hostname github.com User git Port 22#three#这样可用于ssh登录Host zhang21 Hostname ip User username Port 22 IdentityFile ~/.ssh/id_rsa#一定要记着修改权限chmoe 600 ~/.ssh/*#测试连接ssh -T git@github.com 标签管理发布一个新版本时，通常先在版本库中打一个标签(tag)，这样，就唯一确定了打标签时刻的版本。将来无论什么时候，取某个标签的版本，就是把那个打标签的时刻的历史版本取出来。所以，标签也是版本库的一个快照。 tag其实是指向 commit id的。git有commit，为什么还要引入tag? commit id 是一串散列值，并不简单明了。但是tag,我可以写为”v1.0”,”v1.2”…让tag，”v1.0”指向对应的commit id，很方便明了。 创建标签12345678910111213141516171819202122232425262728293031323334353637383940414243#切换到需要打tag的分支上git brach test#创建tag默认tag是打在最新提交的commit上#git tag &lt;tag-name&gt;git tag v1.0#查看所有taggit tag#指定tag对应的commit#git tag &lt;tag-name&gt; &lt;commit_id&gt;git tag v1.0 65432ba#标签不是按时间顺序列出的，而是按照字母排序git show $tag-namegit show v1.0#创建带有说明的标签#git tag -a &lt;tag-name&gt; -m &quot;v1.1 released&quot; &lt;commit-id&gt;git tag -a v1.1 -m &quot;V1.1&quot; 6543bb#查看标签说明git show &lt;tag-name&gt;#用私钥签名一个标签#依赖GPG#git tag -s &lt;tag-name&gt; -m &quot;pri-key&quot; &lt;commit-id&gt;git tag -s v1.2 -m &quot;pri-key v1.2&quot; 6543bc 操作标签1234567891011121314151617181920#删除标签#git tag -d &lt;tag-name&gt;git tag -d v1.2#推送某个标签到远程#git pust origin &lt;tag-name&gt;git push origin v1.0#推送全部标签git push origin --tags#删除远程标签git push origin :refs/tags/&lt;tag-name&gt; 搭建Git服务器常见的Git服务器有： GitLab: https://gitlab.com/ Gogs（go git service）: https://gogs.io/]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Love at First Sight]]></title>
    <url>%2F2017%2F11%2F06%2FLove-at-First-Sight%2F</url>
    <content type="text"><![CDATA[——波兰诗人维斯拉瓦·辛波丝卡(Wislawa Szymborska) They’re both convincedthat a sudden passion joined them. Such certainty is beautiful,but uncertainty is more beautiful still. Since they’d never met before,they’re sure that there’d been nothing between them. But what’s the word from the streets, staircases, hallways –perhaps they’ve passed each other a million times? I want to ask themif they don’t remembera moment face to facein some revolving door?perhaps a “sorry” muttered in a crowd?a curt “wrong number” caught in the receiver?but I know the answer. No, they don’t rememberThey’d be amazed to hearthat Chance has been toying with themnow for years. Not quite ready yetto become their Destiny,it pushed them close, drove them apart,it barred their path, stifling a laugh,and then leaped aside. There were signs and signals,even if they couldn’t read them yet. Perhaps three years agoor just last Tuesdaya certain leaf flutteredfrom one shoulder to another? Something was dropped and then picked up.Who knows, maybe the ball that vanished into childhood’s thicket? There were doorknobs and doorbellswhere one touch had covered another beforehand. Suitcases checked and standing side by side.One night, perhaps, the same dream,grown hazy by morning. Every beginning is only a sequel,after all,and the book of eventsis always open halfway through.]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>Poetry</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Wireshark]]></title>
    <url>%2F2017%2F10%2F25%2Fwireshark%2F</url>
    <content type="text"><![CDATA[过滤语法wireshark过滤分为两种: 抓包过滤 显示过滤 尽量避免使用抓包过滤。即便多看几个报文，也比漏掉一个报文要好。 抓包过滤类型 host net port 方向 src dst 协议 ether ip/arp tcp/udp http/dns/ftp/icmp … 逻辑运算符 &amp;&amp; || ! 栗子： 1234567891011121314151617181920212223242526272829303132333435#主机host www.xx.comsrc host 192.168.1.1 &amp;&amp; dst port 80host 193.168.1.1 || host 192.168.1.2#广播包!broadcast#MACether host 00:88:ab:56:12:0dsrc ether host 00:88:ab:56:12:0d#IPhost 192.168.1.1dst host 192.168.1.1#netnet 192.168.1.0/24src net 192.168.1.0/24#vlanvlan 11#Portport 80! port 443dst port 80udp dst port 5678portrange 1-80 显示过滤比较操作符 == != &gt; &lt; &gt;= &lt;= 逻辑操作符 and or xor not IP ip.addr ip.src ip.dst Port tcp.port tcp.srcport tcp.dstport tcp.flag.syn tcp.flag.ack Protocol arp ip icmp udp tcp dns … 栗子： 1234567891011121314#ipip.addr == 1.1.1.1ip.src == 1.1.1.1 and ip.dst == 2.2.2.2#porttcp.port == 80tcp.dstport == 80tcp.flag.syn == 1#proarpnot icmp]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Wireshark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell]]></title>
    <url>%2F2017%2F10%2F24%2FLinuxShell%2F</url>
    <content type="text"><![CDATA[参考： 《Linux Shell脚本攻略》 《鸟哥的Linux私房菜》 vi vim在Linux中使用文本编辑器来编辑你的Linux参数配置文件是一件很重要的事情，因此系统管理员至少应该熟悉一种文本编辑器。 在Linux中，绝大部分的配置文件都是以ASCII(键盘上可找到)的纯文本形式。因此利用简单的文本编辑器就能修改。 ASCII（发音：/ˈæski/ ass-kee[1]，American Standard Code for Information Interchange，美国信息交换标准代码）是基于拉丁字母的一套电脑编码系统。从[0000 0000 - 0111 1111]共128个字符。 vi文本编辑器 所有的Unix Like系统都会内置vi文本编辑器，其他的文本编辑器则不一定存在 很多软件的编辑接口都会主动调用vi(如 crontab等命令) vim是vi的高级版本 vim具有程序编辑的能力，可以主动以字体颜色辨别语法的正确性，方便程序设计 程序简单，编辑速度相当快速 vi中的tab键所得结果与空格符不一样 vi中，数字是很有意义的 数字通常代表重复做几次，或去到第几个的意思 vim保存、恢复与打开文件时的警告信息当我们使用vim时，vim会在当前目录下再创建一个名为filename.swp的暂存文件。 由于vim的工作被不正常中断，导致暂存盘无法通过正常流程来结束，所以暂存文件就不会消失。此时编辑文件就会出现某些异常情况。 可能有其他人或程序同时在编辑这个文件 在前一个vim的环境中，可能因为某些不明原因导致vim中断(crashed) vim的三种模式vim包括三种模式： 一般模式 编辑模式 命令行模式 一般模式 命令 说明 x 向后删除一个字符 X 向前删除一个字符 nx,nX 向前/后 删除n个字符 dd 删除当前行 D 删除当前行所有字符，使之成为空行 ndd 删除光标所在行的向下n行 d1G 删除光标所在行到第一行 dG 删除光标所在行到最后一行 yy 复制光标所在行 y1G 复制光标所在行到第一行 yG 复制光标所在行到最后一行 ynj 复制光标所在行和向下n行 dnj 删除光标所在行和向下n行 p 将复制的数据粘贴到光标下一行 P 将复制的数据粘贴到光标上一行 J 将光标所在行与下一行结合成一行 u undo,恢复前一个操作 ctrl+r 重做上一个操作 . 重复前一个操作 编辑模式 命令 说明 i 在当前光标所在处插入文字 I 在光标所在行第一个非空字符插入文字 a 在当前光标后插入文字 A 在当前光标所在行最后插入文字 o 在光标所在行的下一行行首插入字符 O 在光标所在行的上一行行首插入字符 r 替换光标所在那一个字符 R 一直替换光标所指的文字，直到退出 Esc 退出，回到一般模式 命令模式 命令 说明 h 方向左 j 方向下 k 方向上 l 方向右 + 光标移到下一行的第一个非空字符 - 光标移到当前行的第一个非空字符 0 光标移到当前行的第一个字符 $ 光标移到当前行的最后一个字符 n空格 光标在当前行向右移动n个字符 G 光标移到最后一行的第一个非空字符 gg 光标移到第一行的第一个非空字符，相当于1G nG 光标移到第n行的第一个非空字符 /word 在光标之后查找word字符串 ?word 在光标之前查找word字符串 n/N 重复前一个查找 :s/word1/word2 在光标当前行将word1替换成word2 :n1,n2s/word1/word2/g 在n1行-n2行间将word1替换成word2 %s/word1/word2/gc 全局将word1替换成word2，在替换前让用户确认(confirm) :w 保存到文件 :w file2 保存到file2文件 :r file3 从file3文件读取数据并写入 :wq/:x 保存并退出 :q 退出 :q! 强制退出 :!cmd 执行命令 :r!cmd 将执行命令写入 :set nu 显示行号 :set nonu 取消行号 :n1,n2w file4 将n1行-n2行的内容保存到file4文件 vim环境设置与记录因为vim会主动将你曾经的行为记录下来，好方便下次操作。这个文件是自动生成的。 ~/.vim.info ~/.vim.rc 整体vim设置 /etc/vimrc 此外，每个Distribution对vim的默认环境都不太相同。所以你可能需要设置成你自己的工作方式。 参数 说明 :set nu :set nonu 行号设定 :set hlsearch :set nohlsearch 高亮设定 :set autoindent :set noautoindent 自动缩排设定 :set backup 自动备份设定 :set ruler 状态栏设定 :set showmode 模式显示设定，如INSERT :set backspace=(012) 设定退格(backspace)值 :set all 显示所有环境参数 :set 显示与系统默认值不同的参数 :syntax on/off 程序语法显示 :set bg=dark/light 设定背景颜色 栗子： 123456789vim /root/.vimrc"这是注释"set nuset rulerset bg=darksyntax onset hlsearch vim注意事项 中文编码问题修改语系编码： LANG=zh_CN.utf-8 Linux与Dos的换行字符 Linux的换行(Enter)为LF符号($) Dos的换行(Enter)为CRLF符号(^M$) 不同系统之间复制纯文本文件可能会有问题，此时可以转换： unix2dos file newfile dos2unix file newfile 语系编码转换iconv - convert text from one character encoding to another 1234#iconv -f 源编码 -t 新编码 filename [-o newfile]#-o，转换到新文件iconf -f big4 -t utf8 old.big5 -o new.utf8 Unicode UTF-8 ASCII参考： ASCII: https://zh.wikipedia.org/wiki/ASCII Unicode: https://zh.wikipedia.org/wiki/Unicode Unicode计算机处理的是数字(二进制文件)。他们在存储字符时要给每个字符分配一个数值。 早期的编码系统称为 ASCII（美国信息交换标准码）， 一共有128（0-127）个值，每个值用7bit 保存。ASCII可以满足小写、大写、数字标点符号和一些控制字符的处理。 人们曾尝试将ASCII字符扩展到8bit，这种新的被称为“扩充ASCII”的编码一直没有成为国际性标准。 为了克服ASCII和扩充ASCII先天上的不足，Unicode Consortiun（多语言软件生产商群体）创建了一种能够提供广泛字符集的通用编码系统，称为Unicode。 Unicode最初设置为2Byte的字符集。但版本3的Unicode用的是4Byte编码，并且与ASCII与扩充的ASCII完全兼容。 现在被称为Basic Latin（基本拉丁文）的ASCII字符集就是前25位全部置零的Unicode码。现在被称为 Latin-1（拉丁文1）的扩充ASCII字符集就是前24位全部置零的Unicode码。 Unicode中的每个字符或符号由一个32bit数来定义，因此这种编码可以定义高达2的32次方(4 294 067 296)个字符或符号。它的记法使用了十六进制数字，格式如下： 1234U-XXXXXXXX#每个 X 都是一个十六进制的数字#因此，它的数值从U-00000000到U-FFFFFFFF ASCII美国信息交换码（American Standard Code of Information Internet，ASCII）是一种7bit码，设计来为128个大多数是美国英语里使用的符号提供编码。今天的ASCII码已成为Unicode的一部分，它占据了Unicode中的前128个码（00000000-0000007F）。 ASCII的一些特点： space(20-sp)字符，是一个可打印的字符，打印出一个空格 大写字母从(41-A)开始，小写字母从(61-a)开始。按ASCII比较时，大写字母的数值会小于小写字母 大写字母与小写字母在他们的7bit编码中只有1bit不同，A(1000001)，a(1100001)，两者相差(20)十六进制 小写字母并没有紧跟在大写字母后面，这两者之间还有几个标点符号(5B-60) 数字从(30-0)开始 从00到1F这最开始的32个字符加上最后一个字符(7F)全都是非打印字符。字符(00)被用作定界符，已定义字符串的结束。字符(7F)是删除字符，它被某些编程语言用来删除前一个字符。剩下的非打印字符称为控制字符，用于数据通信 ASCII控制字符： 二进制 十进制 十六进制 缩写 Unicode表示法 脱出字符表示法 名称/意义 0000 0000 0 00 NUL ␀ ^@ 空字符（Null） 0000 0001 1 01 SOH ␁ ^A 标题开始 0000 0010 2 02 STX ␂ ^B 本文开始 0000 0011 3 03 ETX ␃ ^C 本文结束 0000 0100 4 04 EOT ␄ ^D 传输结束 0000 0101 5 05 ENQ ␅ ^E 请求 0000 0110 6 06 ACK ␆ ^F 确认回应 0000 0111 7 07 BEL ␇ ^G 响铃 0000 1000 8 08 BS ␈ ^H 退格 0000 1001 9 09 HT ␉ ^I 水平定位符号 0000 1010 10 0A LF ␊ ^J 换行键 0000 1011 11 0B VT ␋ ^K 垂直定位符号 0000 1100 12 0C FF ␌ ^L 换页键 0000 1101 13 0D CR ␍ ^M Enter键 0000 1110 14 0E SO ␎ ^N 取消变换（Shift out） 0000 1111 15 0F SI ␏ ^O 启用变换（Shift in） 0001 0000 16 10 DLE ␐ ^P 跳出数据通讯 0001 0001 17 11 DC1 ␑ ^Q 设备控制一（XON 激活软件速度控制） 0001 0010 18 12 DC2 ␒ ^R 设备控制二 0001 0011 19 13 DC3 ␓ ^S 设备控制三（XOFF 停用软件速度控制） 0001 0100 20 14 DC4 ␔ ^T 设备控制四 0001 0101 21 15 NAK ␕ ^U 确认失败回应 0001 0110 22 16 SYN ␖ ^V 同步用暂停 0001 0111 23 17 ETB ␗ ^W 区块传输结束 0001 1000 24 18 CAN ␘ ^X 取消 0001 1001 25 19 EM ␙ ^Y 连接介质中断 0001 1010 26 1A SUB ␚ ^Z 替换 0001 1011 27 1B ESC ␛ ^[ 退出键 0001 1100 28 1C FS ␜ ^\ 文件分区符 0001 1101 29 1D GS ␝ ^] 组群分隔符 0001 1110 30 1E RS ␞ ^^ 记录分隔符 0001 1111 31 1F US ␟ ^_ 单元分隔符 0111 1111 127 7F DEL ␡ ^? 删除 ASCII可显示字符: 进制 十进制 十六进制 图形 0010 0000 32 20 (space) 0010 0001 33 21 ! 0010 0010 34 22 “ 0010 0011 35 23 # 0010 0100 36 24 $ 0010 0101 37 25 % 0010 0110 38 26 &amp; 0010 0111 39 27 ‘ 0010 1000 40 28 ( 0010 1001 41 29 ) 0010 1010 42 2A * 0010 1011 43 2B + 0010 1100 44 2C , 0010 1101 45 2D - 0010 1110 46 2E . 0010 1111 47 2F / 0011 0000 48 30 0 0011 0001 49 31 1 0011 0010 50 32 2 0011 0011 51 33 3 0011 0100 52 34 4 0011 0101 53 35 5 0011 0110 54 36 6 0011 0111 55 37 7 0011 1000 56 38 8 0011 1001 57 39 9 0011 1010 58 3A : 0011 1011 59 3B ; 0011 1100 60 3C &lt; 0011 1101 61 3D = 0011 1110 62 3E &gt; 0011 1111 63 3F ? 0100 0000 64 40 @ 0100 0001 65 41 A 0100 0010 66 42 B 0100 0011 67 43 C 0100 0100 68 44 D 0100 0101 69 45 E 0100 0110 70 46 F 0100 0111 71 47 G 0100 1000 72 48 H 0100 1001 73 49 I 0100 1010 74 4A J 0100 1011 75 4B K 0100 1100 76 4C L 0100 1101 77 4D M 0100 1110 78 4E N 0100 1111 79 4F O 0101 0000 80 50 P 0101 0001 81 51 Q 0101 0010 82 52 R 0101 0011 83 53 S 0101 0100 84 54 T 0101 0101 85 55 U 0101 0110 86 56 V 0101 0111 87 57 W 0101 1000 88 58 X 0101 1001 89 59 Y 0101 1010 90 5A Z 0101 1011 91 5B [ 0101 1100 92 5C \ 0101 1101 93 5D ] 0101 1110 94 5E ^ 0101 1111 95 5F _ 0110 0000 96 60 ` 0110 0001 97 61 a 0110 0010 98 62 b 0110 0011 99 63 c 0110 0100 100 64 d 0110 0101 101 65 e 0110 0110 102 66 f 0110 0111 103 67 g 0110 1000 104 68 h 0110 1001 105 69 i 0110 1010 106 6A j 0110 1011 107 6B k 0110 1100 108 6C l 0110 1101 109 6D m 0110 1110 110 6E n 0110 1111 111 6F o 0111 0000 112 70 p 0111 0001 113 71 q 0111 0010 114 72 r 0111 0011 115 73 s 0111 0100 116 74 t 0111 0101 117 75 u 0111 0110 118 76 v 0111 0111 119 77 w 0111 1000 120 78 x 0111 1001 121 79 y 0111 1010 122 7A z 0111 1011 123 7B { 0111 1100 124 7C l(管道线) 0111 1101 125 7D } 0111 1110 126 7E ~ ASCII缺点：ASCII的局限在于只能显示26个基本拉丁字母、阿拉伯数目字和英式标点符号。因此现在的软件系统大多采用Unicode。 UTF-8UTF-8（8-bit Unicode Transformation Format）是一种针对Unicode的可变长度字符编码，也是一种前缀码。它可以用来表示Unicode标准中的任何字符，且其编码中的第一个字节仍与ASCII兼容，这使得原来处理ASCII字符的软件无须或只须做少部分修改，即可继续使用。 UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。 UTF-8的编码规则很简单，只有二条: 对于单字节的符号，字节的第一位设为0，后面7位为这个符号的unicode码。因此对于英语字母，UTF-8编码和ASCII码是相同的 对于n字节的符号（n&gt;1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的unicode码 Bash bash与shell管理整个计算机硬件的其实是操作系统的内核(kernel)。这个内核是需要被保护的，所以一般用户就只能通过shell来跟内核通信，让内核达到我们想要达到的工作。 硬件、内核与shell我们必须通过shell，将我们输入的命令与内核通信，让内核可以控制硬件正确无误的工作。 操作系统其实是一组软件。由于这组软件在控制整个硬件与管理系统的活动监测，如果这组软件能被用户随意操作，若用户应用不当，将会使得整个系统奔溃。因为操纵系统管理的就是整个硬件功能，所以当然不能够被随便一些没有管理能力的终端用户随意使用。但我们总是需要让用户操作系统的，所以就有了在操作系统上面发展的应用程序。用户可以通过应用程序来指挥内核，让内核达到我们所需要的硬件任务。 也就是说，只要能够操作应用程序的接口都能够称为shell。狭义的shell指的是命令行方面的软件，包括bash等。广义的shell则包括图形界面的软件。 命令行shell 各Distribution的命令行界面都一样 远程管理非常快速 Linux的任督二脉 系统合法shell与/etc/shells由于shell依据发布者的不同就有许多版本，例如Bourne SHell（sh）、C SHell、K SHell、TCSH等。 Linux默认使用的这一版本就是Bourne Again SHell(bash)，这个shell是Bourne SHell的增强版，也是基于GNU框架下发展出来的。 检查系统可用shell: cat /etc/shells合法shell要写入/etc/shells，系统某些服务在运行过程中，会去检查用户能够使用的shell。 查看用户shell权限： cat /etc/passwd，最后一行便是默认shell。 bash shellbash是GNU计划中重要的工具软件之一，目前也是Linux distributions 的标准shell。bash主要兼容于sh，并且依据一些用户的需求而加强shell 版本。 bash的优点： 命令记忆能力history 命令与文件补全功能tab 命令别名设置功能alias 作业控制、前台、后台控制(job control, foreground, background) 使用前台、后台的控制可以让作业进行得更为顺利。至于作业控制(jobs)的用途更广，可以让我们随时将工作丢到后台中执行，而不怕不小心使用ctrl+c来中断该进程 程序脚本shell script 通配符(Wildcard) type命令type命令用于判断一个命令是內建命令还是外部命令(非bash提供)。 1234567type lstype -t ls#file，外部命令#alias，别名#builtin，內建命令 shell变量变量就是以一组文字或符号等，来替代一些设置或者是一串保留的数据。 变量显示与设置 echo: 显示变量 echo $PATH unset: 取消变量 unset $ZHANG 变量设置规则 变量与变量内容以一个等号=连接，如myname=zhang 等号两边不能有空格符，否则错误 变量名称只能是英文字母和数字，开头字符不能是数字 变量内容若有空格，可使用双引号或单引号 双引号内的特殊符号，保有原本的特性 单引号内的特殊字符则仅为一般字符 转义字符\\，将特殊符号变成一般字符 在一串命令中，还需要使用其他命令，使用反单引号 反引号``内的命令将被优先执行，而其执行结果将作为外部的输入信息 若该变量为了增加变量内容时，可用$变量名称 或${变量}累加内容 myname=${myname}xxx 若该变量需要在其他子进程执行，请以export来使变量变成环境变量 通常大写字符为系统默认变量，自行设置变量可以使用小写字符，方便判断 什么是子进程？在我目前这个shell下，去打开另一个新的shell。新的那个shell就是子进程。在一般状态下，父进程定义的变量是无法在子进程内使用的，要通过export将变量变成环境变量后才可以。 注意单引号、双引号和反引号。 环境变量环境变量可以帮我们达到很多功能，包括主文件夹的变换、提示符的显示、执行文件查找的路径等。 env: 显示环境变量 set: 查看所有变量 包括环境变量和自定义变量 1234567#HOME，用户主目录#SHELL，当前环境使用的shell#HISTSIZE，历史命令#PATH，执行文件查找路径#LANG，语系#$PS1，命令提示符#PS2，第二行提示符 设置$PS1，$PS2: 12345678910111213141516171819202122232425\d #可显示出『星期 月 日』的日期格式，如：&quot;Mon Feb 2&quot;\H #完整的主机名\h #仅取主机名在第一个小数点之前的名字\t #显示时间，24小时格式的『HH:MM:SS』\T #显示时间，为12小时格式的『HH:MM:SS』\A #显示时间，为24小时格式的『HH:MM』\@ #显示时间，为12小时格式的『am/pm』\u #目前使用者的账号名称，如『root』\v #BASH的版本信息\w #完整工作路径名，由根目录写起的目录名称。但家目录会以 ~ 取代\W #利用basename函数取得工作目录名称，所以仅会列出最后一个目录名。\# #下达的第几个命令\$ #提示字符，root时，提示字符为#；否则就是$ $钱字号本身也是变量，代表当前shell的PID –&gt; echo $$ ?问号也是一个特殊变量，代表上一个运行命令的回传值 –&gt; echo $? 0 命令运行成功 errorcode 命令运行错误 语系变量locale - get locale-specific information. 设置LANG的时候，其他的语系变量就会被这个变量所替代。 变量键盘读取、数组与声明 read： 读取来自键盘输入的变量 declare,typeset: 声明变量类型 变量的默认类型为字符串 若不指定变量类型，则1+2就是一个字符串而不是计算式 数组变量类型 var[1]=’varray1’ var[2]=’varray2’ echo “${${var[1]}, ${var[2]}}” bash shell操作环境自定义我们登录主机的时候屏幕上面会有一些说明文字，并且登录的时候还可以给用户提供一些信息或者欢迎文字，或环境变量和命令别名等。 路径与命令查找顺序命令的运行顺序： 以绝对/相对路径执行命令 由alias找到该命令来执行 由bash内置的（builtin）命令来执行 通过$PATH这个变量的顺序找到的第一个命令来执行 bash登录与欢迎消息 /etc/issue –&gt; 终端登录消息 CentOS Linux 7 (core)….. /etc/motd –&gt; 用户登录后取得一些消息 Welcome to aliyun ECS bash环境配置文件操作系统有一些环境配置文件的存在，让bash在启动时直接读取这些配置文件，以规划好bash的操作环境。这些配置文件又可以分为全体系统的配置文件以及用户个人偏好配置文件。 命令别名、自定义的变量在你注销bash后就会失效。所以你想要保留你的设置，就得要将这些设置写入配置文件才行。 login shell 取得bash需要完整的登录流程 non-login shell 取得bash接口的方法不需要登录 bash shell快捷键 Ctrl+C –&gt; 终止当前命令 Ctri+D –&gt; 输入结束(EOF) Ctri+M –&gt; Enter Ctrl+S –&gt; 暂停屏幕输出 Ctrl+Q –&gt; 恢复屏幕输出 Ctrl+U –&gt; 在提示字符下，将整列命令删除 Ctrl+Z –&gt; 暂停目前命令 通配符与特殊符号通配符： 符号 说明 * 代表0-∞个 任意字符 ? 代表一定有一个 任意字符 [-] 中括号内任一字符 [^] 非中括号内字符 bash常见特殊符号，理论上文件名不要用到上述字符。 符号 说明 # 注释 \ 转义字符 1 管道线 ; 连续命令分隔符 ~ 用户主目录 $ 取变量前导符 &amp; 将命令放入后台 ! 逻辑非 / 目录符号 &gt;, &gt;&gt; 输出定向 &lt;, &lt;&lt; 输入定向 ‘’ 单引号 “” 双引号 () 子shell {} 命令区块混合 重定向数据流重定向就是将某个命令执行后应该要出现在屏幕上的数据传输到其他的地方，如文件或设备。 标准输入(stdin)，代码为0，使用&lt;或者&lt;&lt; 标准输出(stdout)，代码为1，使用&gt;或者&gt;&gt; 标准错误(stderr)，代码为2，使用2&gt;或者2&gt;&gt; &gt;表示以覆盖方式写入，&gt;&gt;表示以追加方式写入 管道管道命令使用 “ | “ 这个界定符号。管道命令” | “ 仅能处理经由前面一个命令传来的正确信息。所以对stderror没有直接处理能力。 在每个管道后面接的第一个数据必定是命令，而且这个命令必须要能够接收standard input的数据才行，这样的命令才可以是管道命令。 Bash特殊符号在编写shellscripts的时候，特殊符号也有其重要的功能。 符号 描述 栗子 #! shellban，申明脚本所使用的shell #!/bin/bash \ 转义字符 \n l 管道 stdout l grep &gt;,&gt;&gt; 输出定向 &gt; 1.txt &lt;,&lt;&lt; 输入定向 &lt; 1.txt 2&gt; 错误定向 2&gt; error.txt ; 连续命令分隔符 cmd1;cmd2 &amp;&amp; 与，只有当前命令完成后才执行后一个命令 cmd1 &amp;&amp; cmd2 ll 或，或此或彼 cmd1 ll cmd2 ~ 用户家目录 cd ~ # 注释符 #comments $ 取用变量前导符 $PATH或${PATH} &amp; 工作控制，将命令放入后台(bg) command&amp; * ? [] [-] [^] 通配符 .sh ?.sh [a-z].txt [^zhang].txt ! 逻辑非 != = 两边无空格 赋值符号 name=zhang = 两边有空格 比较符号 if [ $name = zhang ] $0 执行文件脚本名 /root/zhang.sh $1, $2 第1,2个…变量 ./zhang.sh start $# 参数个数 if [ $# -ne 2 ]；then echo &#39;Usage: $0 arg1 arg2&#39; $@ 代表$1,$2,$3…之意 每个变量是独立的 $* 代表$1c$2c$3…之意 c为分割字符，默认为空格键 $? 命令状态码，成功为0 $? $$ 当前shell的PID echo $$ ‘单引号’ 单引号内特殊字符仅为一般字符 echo &#39;$host&#39;--$host “双引号” 双引号内特殊符号，可保有原本特性 echo &quot;$host&quot; --localhost `反引号` 运行命令 反引号内命令先执行 () 以子shell方式执行 $(date) {} 命令区块的组合 PS1 命令提示符 $PS1 PS2 第二行以后的提示字符 $PS2 shift 移动参数 shift后面可以接数字，代表拿掉最前面的几个参数 set 查看所有变量 set unset 取消变量 unset name，没有$符号 export 使某变量成为环境变量 export name，没有$符号 source source命令通常用于重新执行刚修改的初始化文件，使之立即生效，而不必注销并重新登录 source file shell scriptshell script 有点像早期的批处理程序，即将一些命令汇整起来一次执行.但shell script拥有更强大的功能，可以进行类似程序(program)的编写，并且不需要经过编译(compile)就能执行。 shell script介绍shell script是利用shell的功能写的一个程序(program)。这个程序是使用纯文本文件，将一些shell的语法与命令(含外部命令)写在里面，搭配正则表达式、命令管道与数据流重定向等功能，还提供了数组、循环、条件与逻辑判断等重要功能， 以达到我们所想要的处理目的。 shell script用在系统管理上面是很好的一项工具，但用在处理大量数值运算上就不够好。因为shell script的速度较慢，且使用的cpu资源较多，造成主机资源的分配不良。 使用shell script的优势： 自动化管理的重要依据 追踪与管理系统的重要工具 简单入侵检测功能 连续命令单一化 简单的数据处理 跨平台支持与学习历程较短 shell script注意事项： 命令的执行是从上到下从左到右，分析与执行 命令的执行中：命令、参数间的多个空白都会被忽略掉 空白行也将被忽略，tab按键所得的空白同样视为空格键 读取到一个Enter符号(CR)，就尝试开始执行该行命令 一行内容太多，则可以使用\[Enter]来扩展到下一行 任何加在#后面的内容都将被视为注释而被忽略 shell script文件的执行方式： 直接命令执行 .sh文件必须具有可读和可执行权限，使用绝对路径或相对路径来执行 以bash进程来执行 bash xx.sh sh xx.sh shell script执行方式的区别： 直接执行，script是在子进程的bash中执行的。当子进程完成后，子进程内的各项变量或操作将会结束而不会传回到父进程中。 source来执行，在父进程中执行 编写一个shell script一个良好的shell script应该纪录好如下信息： script的功能 script的版本信息 script的作者 script的版权声明方式 script的History（历史记录） script内较特殊的命令，使用绝对路径的方式来执行 script执行时需要的环境变量预先声明与设置 在较为特殊的程序代码部分，建议务必要加上批注说明 shell script判断式当我要检测系统上某些文件或相关属性时，使用test命令。 1test -e /root/test.txt &amp;&amp; echo 'Exist' || 'Not exist' 文件类型判断： 选项 说明 -e 是否存在 -f 是否存在文件 -d 是否存在目录 -b 是否存在block device -c 是否存在character device -S 是否存在Socket文件 -p 是否存在pipe文件 -L 是否存在链接文件 文件权限判断： 选项 说明 -r 是否可读 -w 是否可写 -x 是否可执行 -u 是否具有SUID -g 是够具有SGID -k 是否具有Sticky bit -s 是否为非空白文件 文件之间的比较： 选项 说明 -nt newer than -ot old than -ef 是否为同一个文件 整数之间的比较： 选项 说明 -eq equal -ne not equal -gt greater than -lt less than -ge greater or equal -le less or equal 字符串之间的比较： 选项 说明 -z 是否为空 -n 非空 str1 = str2 是否相等 != 不等于 多重条件判断： 选项 说明 -a and -o or ! 非 判断符号[]: 如果需要在bash中使用中括号来作为shell的判断式时，必须要注意中括号的两端需要有空格符来分隔。 中括号内的变量，每个最好都用双引号括起来 中括号内的常量，最好都以单或双引号括起来 shell script的默认变量: $0,$1…12/root/test.sh opt1 opt2 opt3 $0 $1 $2 $3 执行文件的脚本名就是$0 文件后接的第一个参数就是$1，以此类推 $#，表示参数个数 $@，表示”$1”, “$2”… shift，参数变量号码偏移 shift n，代表拿掉前面几个参数的意思 条件判断语句 if…then语句if…then 是最常见的条件判断式。 单层条件判断： 123if [ confition ]; then xxxfi 多层条件判断： 12345if [ condition ]; then xxx;else xxx;fi 1234567if [ confition1 ]; then xxx;elif [ condition2 ]; then xxx;else xxx;fi case…esac语句有多个既定变量内容，那么只需要针对这几个变量来设置状况就好。 12345678910111213141516171819202122232425262728293031case $变量名 in"$var1") xxx ;;"$var2") xxx ;;"...") xxx ;;esac####栗子#/etc/init.d/networkcase "$1" instart) xxx ;;stop) xxx ;;restart) xxx ;;status) xxx ;;esac function功能什么是函数？函数可以在shell script 当中做出一个类似自定义执行命令的东西。最大的动能是，可以简化很多的程序代码。 因为shell script的执行方式是由上而下、由左而右。因此在shell script当中，function的定义一定要在程序的最前面，这样才能够在执行时被找到可用的程序段。 1234567891011121314151617181920vim func.shfunction fname () &#123;&#125;####栗子function Zhang() &#123; echo $1 $2&#125;Zhang "$1" "$2"#执行sh func.sh aaa bbb 循环(loop)语句 while do done(不定循环)while是当condition条件成立时，就进行循环，condition条件不成立就停止。 1234while [ condition1 ]do xxxdone until do done(不定循环)until是当condition条件成立时，终止循环；否则就持续进行循环的循环。 1234until [ condition ]do xxxdone for do done(固定循环)1234567891011for i in con1 con2 con3 ...do xxxdone####栗子for i in 192.168.1.&#123;1,2,3&#125;do ping -c 1 $idone for do done的数值处理： 1234567891011for ((初始值;限制值；步长))do xxxdone####栗子for ((i=0;i&lt;10;i++))do echo $idone shell script的追踪与调试(debug)最好在shell script执行之前先行调试。 123456789sh [-nvx] xxx.sh#-v 运行脚本前，先将脚本内容输入到屏幕#-n 仅查询语法问题#-x 边显示边执行当然也可以把这几个调试参数写到shellbang中#!/bin/bash -x 小试牛刀简介123456789101112#bash(Bourne Again Shell)，shell环境使得用户能与操作系统的内核进行交互操作#!/bin/bash#date#descriptioncmd1; cmd2cmd3#sh /path/xx.sh#Bash还有一个历史记录文件 ~/.bash_history 终端打印(echo)12345678910111213141516171819202122#终端作为交互式工具，用户可以通过它与shell环境进行交互echo '$var'echo $varecho -e "1\t2\t3"echo -e '\e[1;31m Red color \e[0m' #彩色echo &#123;1..10&#125; #输出1到10echo &#123;A..H&#125; #for i in &#123;a..z&#125;cat &lt;&lt; EOF112233EOF# \转义字符printf "%-5s %-10s $-4.2f\n" 001 Zhang 56.789#格式替代符%s %d %c %f, -左对齐 玩转变量和环境变量123456789101112131415161718192021#Bash中，每一个变量默认值值都是字符串形式#环境变量和自定义变量echo $SHELLecho $UIDvar=value #这是赋值#var = value这是相等操作echo $varecho $&#123;var&#125;echo $&#123;#var&#125; #字符数#export用来设置环境变量，此后，任何shell中的程序都会继承环境变量ZHANG=Gentlemanexport ZHANGPATH="$PATH:/home/zhang/bin"export $PATH 通过shell进行数学运算1234567891011121314151617181920212223242526272829303132#let, expr, bc, [], (())#要注意默认是字符串类型哦n1=1;n2=2let sum=n1+n2let n1++;let n2-=1sum=$[ n1 + n2 ]sum2=$(( sum + 3 ))sum=`expr 3 + 4`#浮点计算 bcecho "8 * 1.1" | bc#设置小数点精度echo "scale=2; 3/8" | bc#进制转换num=100echo "obase=2; $num" | bcnum=1100100echo "obase=10; ibase=2; $num" | bc#平方和平方根echo "sqrt(100)" | bcecho "10^2" | bc 文件描述符重定向12345678910111213141516#最常用的文件描述符是 stdin(0), stdout(1), stderr(2); 通过内容过滤将输出重定向到文件echo "This is a sample text 1" &gt; temp.txt #覆盖echo "This is sample text 2" &gt;&gt; temp.txt #追加ls + &gt;stdout.txt 2&gt;stderr.txtcmd 2&gt;&amp;1 /dev/null == com &amp;&gt; /dev/null #null设备也被称为黑洞#当一个command发生错误并退回时，它会返回一个非0的状态码echo $?#tee命令，一方面可将数据重定向到文件，另一方面还可提供一份重定向数据的副本作为后续命令的stdin#tee默认覆盖文件，-a选项追加cat temp.txt | tee tee.txt | cat -n 数组和关联数组123456789101112131415161718192021#数组借助索引将多个独立的数据存储为一个集合#普通数组只能使用整数作为数组索引，而关联数组可以使用字符串作为数组索引#还可将数组定义成一组索引-值(index-value)arr=(1 two 3 four 5)echo $&#123;arr[0]&#125;arr[0]=Oneindex=3echo $&#123;arr[$index] #arr[3]echo $&#123;arr[*]&#125;echo $&#123;#arr[*]&#125; #arr-length#关联数组可用任意文本作为数组索引declare -A ass_arrass_arr=([index1]=val1 [index2]=val2 ...) #内嵌索引-值ass_arr[index3]=val3 #独立索引-值echo $&#123;!ass_arr[*]&#125; #列出数组索引 别名(alias)123456789101112#alias作用是暂时的，关闭终端后别名就失效；#为使别名一直保持，可将其写入 ~/.bashrc，因为每一个新的shell都会执行~/.bashrc中的命令#新设置的别名将取代已有别名alias vi=vim;unalias viecho "alias ll='ls -l --color=auto'" &gt;&gt; ~/.bashrc#\对别名命令进行转义，执行原本的命令。避免攻击者利用别名将某些特权命令替换成别有用心的命令\vi test.sh 获取、设置日期和延时(date)12345678910111213141516171819202122232425262728293031#很多应用程序需要以不同的格式打印日期，设置日期和时间，以及根据日期和时间执行操作;#延时通常用于在程序执行过程中提供一段等待时间;#在Unix-like系统中，日期被存储为一个整数，其大小为世界标准时间1970年1月1日0时0分0秒起所流逝的秒数；#这种计时方式被称之为 纪元时或Unix时间；#通过纪元时间，可知道两个日期之间相隔了多少秒#编写以循环方式运行的监视脚本时，设置时间间隔是必不可少的date +%s#!/bin/bashstart=$(date +%s)commandssleep 1end=$(date +%s)diff=$((end - start))echo "$diff seconds"#显示指定时间date +%F -d -1daysdate +%H -d -3hours#将标准时间转换为原子时间date -d '2018-02-07 14:05:53' +%s1517983553#将原子时间转换为标准时间date --date='@1517983553'Wed Feb 7 14:05:53 CST 2018 调试脚本(sh)12345#调试功能能在出现一些异常情况时生成运行信息#!/bin/bash -xvsh -xsh -n 函数和参数(function)123456789101112131415161718192021function fname()&#123;statements&#125;fname()&#123;echo $1, $2 #访问第参数1和参数2,$n第n个参数echo "$@" #以列表的形式一次性打印所有参数echo "$*" #类似于$@，但参数被作为单个实体return 0 #f返回值&#125;fname 1 22 333 #返回上面定义的变量#递归函数，能够调用自身，不断地生成新的进程，最终会造成xx#导出函数，使用export导出，这样函数作用域就可以扩展到子进程export -f fname#读取命令返回值echo $? 读取命令序列输出(` `, $() )12345678910#输入通常是stdin，输出stderr或stdout,这些命令称为 过滤器(filter)。我们使用 管道(pipe) 来连接每一个过滤器cmd1 | cmd2 | cmd3#子shell，子shell生成独立的进程，不会对当前shell有任何影响，所做改变仅限于子shell内zhang=$(ls | cat -n)#反引用zhang=`ls | cat -n` 读取字符(read)123456789101112131415161718#read是一个重要的从标准输入中读取文本的命令#可以使用read以交互的形式来读取用户的输入read -n 5 zhang #读取字符数echo $zhangread -s passwd #不回显echo $passwdread -t 5 zhang #超时时间echo $zhangread -p zhang #显示提示信息echo $zhangread -d ":" zhang #定界符结束输入123：echo $zhang 字段分隔符和迭代器12345678910111213141516171819#内部字段分隔符(Internal Field Separator, IFS)是shell中的一个重要概念#IFS的默认值为空白字符(换行符、制表符、空格)awk -F: '&#123;print $1,$3&#125;' /etc/passwd #IFS=":"#对一些列值进行迭代，循环非常有用for i in &#123;1..10&#125;docmddonewhile conditiondocmddoneuntil conditiondocmddone 比较与测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#程序中的流程控制是由比较和测试语句来处理的if condition1 || condition2then cmd1elif condition3 &amp;&amp; condition4then cmd2else cmd3fi#算术比较if [ $num -ge 10 -a $num -lt 20 ]-eq-gt-ge-lt-le-a-o#文件系统相关if [ -f $file1 -o -x $file2]-x-w-r-f-d-e-b #block-l#字符串比较[[ $str1 = $str2]]= #=号旁有空格--是比较关系；=号旁没空格，是赋值语句!=&gt;&lt;-z #空字符-n #非空字符#使用test命令来执行条件检测if [ $num -eq 0 ] -- if test $num -eq 0 命令之乐简介各种命令可谓Unix-Like系统中优美的部分，它能帮我们搞定各种繁杂的任务。一旦你尝试过Linux提供的这些利器，你一定会感到惊讶：以前没有这些命令的时候，自己是什么熬过来的。最钟爱的莫过于 grep, awk, sed, find 命令了！ 本章将会为你介绍一些最有趣同时也是最实用的命令。 用cat进行拼接12345678#cat命令通常用于读取、显示或拼接文件内容，不过它所具备的能力远不止此#cat(concatenate, 拼接)cat file1 file2 ···echo "Ahaha" | cat - file1 file2 #-指stdin文本文件名cat -s file3 -- cat file3 | tr -s '\n' #压缩空白行cat -T test.py #将制表符显示为 ^I, 避免制表符和连续空格误用, 产生错误缩进cat -n file4 #显示行号 录制与回放终端会话(script)当你需要准备一个命令行教程时，如果将我们输入命令后的一切按照先后次序记录下来，再进行回放，是不是很nice！通过 script, scriptreplay 命令, 把终端会话记录到文件，并回放。 123456789#-t,将时间数据输出到标准错误； -a,追加输出script -t 2&gt; timing.log -a output.session #两个文件随意取名, 如不将错误重定向会显示在屏幕上导致很乱输入命令cmd2···exit #退出录制scriptreplay -t timing.log output.session #播放 文件查找与文件列表(find)find 是Unix/Linux命令行工具箱中最棒的工具之一。find 命令沿着文件层次结构向下遍历，匹配符合条件的文件，并执行相应的操作。 find - search for files in a directory hierarchy 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#基于文件名及正则表达式搜索find /home/zhang #列出/home/zhang目录及其子目录线所有文件和文件夹find /home/zhang -name "*.txt"find . -name "*.sh" -o -iname "zhang*" #匹配多个find /home/zhang -path "201710*" #-path将文件路径作为一个整体进行匹配find . -regex ".*\(\.txt|\.[0-9]+\)$" #匹配以.txt或数字结尾的文件#使用-maxdepth, -mindepth参数，来限制find的遍历深度#-type, 根据文件类型搜索。 f(普通文件)，d(目录)，b(块设备)，l(符号链接)，s(套接字)等find /home -maxdepth 1 -type f(d) #参数顺序也会影响find的查找效率#根据文件类型搜索find /dev -type b #查看/dev及其子目录下设备文件find / -maxdepth 1 -type l #查找/下链接文件#根据文件时间进行搜索#Unix/Linux文件系统中的每一个文件都有三种时间戳(timestamp),-表示小于，+表示大于#Unix中并没有所谓的 "创建时间" 的概念#访问时间(-atime,以天为单位； -amin,以分钟为单位):用户最近一次访问文件时间；#修改时间(-mtime,以天为单位； -mmin,以分钟为单位):文件最后一次修改时间；#变化时间(-ctime,以天为单位； -cmin,以分钟为单位):文件元数据(如权限，所有权)最后一次变化时间；find /home/zhang -type f -mtime 7 #7天前被修改的普通文件find /home/zhang -type f -amin -10 #搜索10分钟内被修改的普通文件find . -type f -newer file1.txt #找出比file1.txt新的文件#基于文件大小的搜索#b(块，512字节), c(字节), w(字，2字节), k(千字节), M(兆字节), G(吉字节)find . -type -f -size +100k#删除匹配的文件find . -type f -name "*.swp" -delete#基于文件权限和所有权的匹配find . -type f -perm 644find /var/apache -type f -name "*.php" -perm 644 #搜索基于权限的文件find /var -maxdepth 2 -type f -user zhang #搜索基于用户的文件#执行命令或动作#find命令可以借助-exec与其他命令进行结合#&#123;&#125;是一个特殊字符串，将替换为相应文件名find . -type f -perm 764 -user zhang -exec chmod 644 &#123;&#125; \; #将所属用户zhang，权限764的文件权限修改为644find . -type f -mmin +30 -name "*.txt" -exec cp &#123;&#125; &#123;&#125;.old \; #复制最近30内修改的名字为.txt的文件#-exec结合多个命令#我们无法在-exec参数中直接使用多个命令，不过我们可以把多个命令写到一个shellscript中，然后执行-exec ./test.sh &#123;&#125; \;find . -type f -name "*.sh" -mmin -10 -exec sh &#123;&#125; \;#让find跳过特定目录-prune#利用find搭配tar打包#查找7天内的文件并打包#建议使用绝对路径，管道无效，所有要定向到文件find /dir/path/zhang -type -f -mmtime -7 &gt; /dir/path/zhang/zhang.list &amp;&amp; tar -T /dir/path/zhang/zhang.list -czvf /dir/path/zhang123.tar.gz#检查是否正确tar -tf /dir/path/zhang123.tar.gz#不能使用find -exec tar，这样打包以后只有最后一个文件 利用stat命令查看atime, mtime, ctimestat - display file or file system status 12345stat 1.txt#Access:#Modify:#Change: 利用touch命令修改atime, mtime, ctimetouch - change file timestamps 1234#-a change only the access time#-m change only the modification time#-d instead of current time#-t instead of current time 玩转xargsxargs - build and execute command lines from standard input 1234567891011121314151617181920212223242526272829303132#xargs能够处理stdin并将其转换为特定命令的命令行参数#也可以将单行或多行输入文本转换成其他格式(如多行变单行)cmd | xargs#将多行输入转换为单行输出echo -e "1\n2\n3" | xargs #将换行符替换为空格#将单行输入转换成多行输出echo "1 2 3" | xargs -n 1 #每行一个参数echo "hahaZhahaZhahaZhaha" | xargs -n 2 -d Z #-d指定分隔符#读取stdin，将格式化参数传递给命令cat test.txt | xargs -n 1 ./zhang.sh #zhang.sh arg1; zhang.sh arg2... 每次提供一个参数cat test.txt | xargs -n X ./zhang.sh #X为参数个数，一次提供全部参数#指定替换字符串cat test.txt | xargs -I &#123;&#125; ./zhang.sh &#123;&#125;#结合find使用xargsfind . -type f -name "*.txt" -print0 | xargs -0 ls #-print0无换行输出, -0将\0作为输入界定符#统计某文件行数find /path -type f -name "*.c" -print0 | xargs -0 wc -l#结合stdin，运用while和子shellcat file.txt | while read arg; do cat $arg; done == cat file.txt | xargs - &#123;&#125; cat &#123;&#125;cmd0 | (cmd1; cmd2; cmd3) | cmd4 #子shell 用tr进行转换tr - translate or delete characters 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#tr命令经常用来编写优美的单行命令#tr可对来自stdin的字符 进行替换、删除以及压缩echo "AH WONDERFUL" | tr 'A-Z' 'a-z' #转换大小写echo "AH WONDERFUL" | tr 'A-Z' 'a-b' --&gt; ab bbbbbbbbb#tr [option] set1 set2#如果两个字符集长度不相等，那么set2会不断重复其最后一个字符，直到长度与set1相同echo 12345 | tr '0-9' '9876543210' #数字加密echo 87654 | tr '9876543210' '0-9' #数字解密echo 'He is a cool boy, and she is a beautiful girl' | tr 'A-Za-z' 'NOPQRSRUVWXYZABCDEFGHIJKLMnopqrstuvwxyzabcdefghijklm' #加密echo 'Ur vf n pbby obl, naq fur' | tr 'NOPQRSRUVWXYZABCDEFGHIJKLMnopqrstuvwxyzabcdefghijklm' 'A-Za-z' #解密cat 1.txt | tr '\t' ' ' #将制表符转换为空格#删除字符echo "Hello 530 World" | tr -d '0-9' #-d删除，删除数字Hello Worldecho "Hello 520 World" | tr -d -c '0-9' #-c补集 520#压缩字符，将连续的重复字符压缩为单个字符echo "GNU's not Unix" | tr -s ' ' #-s压缩，压缩空格GNU's not Unixecho -e "1\n2\n3\n4\n5" &gt; sum.txtcat sum.txt | echo $[ $(tr '\n' '+') 0 ] -- echo $[1+2+3+4+5+0]#tr字符类\a 终端鸣响\b 退格\f 换页\n 换行\r 回车\t 水平制表符\v 垂直制表符string1-stringN #从字符1到字符N升序过程中的所有字符[字符*次数][:alnum:] #所有字母和数字[:alpha:] #所有字母[:digit:] #所有数字[:lower:] #所有小写字母[:upper:] #所有大写字母[:graph:] #所有可打印字符，不含空格[:print:] #所有可打印字符，包含空格[:blank:] #所有水平排列的空白字符[:cntrl:] #所有控制字符[:punct:] #所有标点字符[:space:] #所有空白字符[:xdigit:] #所有十六进制数[=字符] #指定字符 校验和 与 核实文件完整性(md5sum)12345678910111213141516171819202122#校验和(checksum)程序从文件中生成校验和密钥，然后利用校验和密钥核实文件的完整性#校验和对于编写备份脚本或系统维护脚本非常重要，因为它们都会涉及通过网络传输文件#通过使用校验和核实，我们就可以识别那些在网络传输过程中出现损坏的文件，并重传，从而确保数据完整性#校验和对于核实数据完整性非常有用#广泛使用的校验和技术有：md5sum, sha1sum#对单个文件进行校验md5sum sum.txt &gt; sum.md5#302c28003d487124d97c242de94da856 sum.txtmd5sum -c sum.md5 #-c检查#sum.txt: 确定#对目录进行校验#对目录计算校验和意味着我们需要对目录中的所有文件以递归的方式进行计算yum install -y md5deepmd5deep -r ./dir &gt; dir.md5 #recursive递归md5sum -c dir.md5#可以将测试dir下某个文件更改一下，校验的时候会报错 排序、单一、重复(sort,uniq)12345678910111213141516171819202122232425262728293031#sort - 对文本文件进行行排序#uniq - 删除排序文件中的重复行echo -e "333\n1" &gt; 1.txt; echo -e "22\n22" &gt; 2.txtsort 1.txt 2.txt -o ./sorted.txt#1#22#22#333cat sortec.txt | uniq#1#22#333sort -n #按数字进行排序sort -r #逆向排序sort -M #按月份排序sort -C #检查是否排序sort -b #忽略空白#依据键或列进行排序sort -k 2 data.txt #依据第二列来排序#uniq要么使用管道，要么使用排过序的文件作文输入uniq -u sorted.txt #只显示唯一的行(即没有重复出现的行)uniq -d sorted.txt #只显示重复的行uniq -s 2 -w 2 sorted.txt #-s忽略前2个字符，-w指定用于比较的最大字符数 临时文件命名、随机数123456#在编写shell脚本时，我们经常需要存储临时文件。最适合存储临时数据的位置是 /tmp#/tmp目录中的内容会在系统重启后被清空filename=$RANDOM #RANDOM返回一个随机数filename2=$$ #当前shell的PIDfilename3=$((date +%F)) #通过日期命令 分割文件和数据(split)123456789101112131415161718192021#某些情况下，需要把文件分割成多个更小的片段dd if=/dev/zero bs=100k count=1 of=./data.file #生成一个大小100k内容全是0的文件split -b 20k data.file #-d指定分割大小#data.file xaa xab xac xad xae,这五个文件都为20k#我测试了一下，几个文件加起来数据没变，几个文件总行数没变#单位有 k, m, G, c(byte), w(word)#-d以数字为后缀， -a指定后缀长度split data.file -b 20k -d -a 2 spt #增加前缀名'spt'#data.file spt00 spt01 spt02 spt03 spt04split -l 10 data.file #-l按行数来分割文件#split只能根据大小或行数分割文件#csplit可以根据文件本身特点进行分割-f #指定分割后文件前缀-n #指定分割后文件后缀数字个数-b #指定后缀格式 根据扩展名切分文件名12345678910111213141516171819202122232425262728#借助%操作符将名称从 “名称.扩展名” 格式中提取出来file="zhang.txt"name1=$&#123;file%.*&#125; #删除位于%右侧的通配符(.*)所匹配的字符串，通配符从右向左进行匹配#zhang#*号通配符，.号#%属于非贪婪匹配(non-greedy),它会匹配通配符最短结果#%%属于贪婪匹配(greedy)，它会匹配符号条件的最长字符串name2=$&#123;file#*.&#125; #删除位于#右侧的通配符(*.)所匹配的字符串，通配符从左向右进行匹配#txt# #属于非贪婪匹配# ##属于贪婪匹配#栗子URL=“www.google.com”echo $&#123;URL%.*&#125; #非贪婪匹配，移除最右边.及其后面内容www.googleecho $&#123;URL%%.*&#125; #贪婪匹配wwwecho $&#123;URL#*.&#125; #非贪婪匹配，移除最左边.及其前面内容google.comecho $&#123;URL##*.&#125; #贪婪匹配com 批量重命名和移动综合运用find、rename、mv命令。 拼写检查与词典操作123456#Linux大多数发行版都含有一份词典文件，另外还有一个被称为aspell的拼写检查命令#words --&gt; /usr/share/dict/linux.wordsgrep "^good" /usr/share/dict/linux.wordsaspell 交互输入自动化1234567891011121314151617181920212223242526272829303132#写一个读取交互式输入脚本vi jiaohu.sh#!/bin/bashread -p "Input a number:" numread -p "Input name:" nameecho "You have enterd number:$num, name:$name"echo -e "1\nzhang" | ./jiaohu.shYou have entered number:1, name:hello#orecho -e "1\nzhang" &gt; input.txt./jiaohu.sh &lt; input.txt#交互式输入自动化#用expect实现自动化yum install -y expectvim auto_expect.sh#!/bin/expectspawn ./jiaohu.sh #spawn指定需要自动化哪一个命令expect "Input a number:" #expect提供需要等待的消息send "1\n" #send是要发送的消息expect "Input name:"send "zhang"expect eof #expect eof指明命令交互结束./auto_expect.sh 以文件之名简介Unix将操作系统中的一切都视为文件。 生成任意大小的文件(dd)由于各种原因，可能需要生成一个包含随机数据的文件。 12345#dd命令会克隆给定的输入内容，然后将一模一样的副本写到输出#如果不指定if，dd会从stdin中读取输入；如果不指定of，dd会输出到stdout#/dev/zero是一个字符设备，它会不断返回0值字节(\0)dd if=/dev/zero of=junk.data bs=1M count=1 文本文件的交集与差集12345678910111213#comm命令用于两个文件之间的比较#交集(intersection),差集(set difference), 求差#comm必须使用排过序的文件作为输入echo -e "1\n2\n3" &gt; A.txt &amp;&amp; echo -e "3\n2\n3" &gt; B.txtsort -n A.txt -o A.txt &amp;&amp; sort -n B.txt -o B.txtcomm A.txt B.txt#输出第一列为A独有，第二列为B独有，第三列为交集comm A.txt B.txt -1 -2#-1从输出中删除第一列，-2删除第二列，-3删除第三列 查找并删除重复文件1234#重复文件指的是那些虽然名字不同但内容却一模一样的文件ls -lS #以文件大小排序，识别大小相等的文件md5sum #接下来计算这些文件的校验和 创建长路径目录1mkdir -p /home/zhang/1/22/333 2&gt;/dev/null 文件权限、所有权和粘滞位123456789101112131415161718192021222324252627282930313233343536373839404142#用户(user)，用户组(group)，其他用户(other)ll ./*#d目录，c字符设备，b块设备，l符号链接，s套接字，p管道，-普通文件#用户还有一个称为setuid(S)的特殊权限，它出现在用户的x位置#setuid权限允许用户以其拥有者的权限来执行可执行文件，即便这个文件是由其他用户运行的-rwSrw-r--#组也拥有一个setgid(S)权限，它出现在组的x位置#它允许以同该目录拥有者所在组相同的有效组权限来运行可执行文件-rwxrwSr--#目录有一个特殊权限，叫做粘滞位(sticky bit)(T或t)，出现在其他用户的x位置#当一个目录设置了粘滞位，只有创建该目录的用户才能删除目录中的文件,即便group和other有w权限-rwxr--rwTchmod u=rwx g=rw o=r file1chmod u+x g-w file2chmod 744 file3chmod a+x . -R #以递归方式设置权限chown user.group . -R #以递归方式设置所有权chmod a+t dir1 #设置粘滞位chmod +s fiel4chown root.root file4chmod +s file4./file4 #每次file4都是以root运行#setuid的使用不是无限制的，它只能应用在Linux ELF格式二进制，而不能用于脚本文件。 创建不可修改文件123456#不可修改(immutable),是保护文件不被修改的安全手段之一。#一旦文件被设置为不可修改，任何用户(包括root)都不能修改，除非将其不可修改属性移除chattr #修改文件在Linux第二扩展文件系统(E2fs)上的特有属性chattr +i file1 #这样就无法删除file1chattr -i file1 批量生成空白文件123456789#touch命令可用来生成空白文件，如果文件存在，则可以用它修改文件的时间戳for name in &#123;1..100&#125;.txt;dotouch $namedonetouch -a/-m #更改文件访问/修改时间touch -d "Thu Oct 31 14:20:13 CST 2017" file1 #指定特定时间戳 查找符号链接及其指向目标1234567#符号链接(软链接)只不过是指向其他文件的指针ln -s /usr/bin /binls -l / | grep "^l"find / -maxdepth 1 -type lreadlink /bin #找出链接目标 列举文件类型统计信息1234#在Unix/Linux系统中，文件类型并不是由文件扩展名决定的file /etc/passwdfile -b /etc/passwd 环回文件与挂载(mount)1234567891011#环回文件系统是指那些在文件中而非物理设备中创建的文件系统dd if=/dev/zero of=loopback.file bs=1G count=1mkfs.ext4 loopback.filemount -o loop loopback.file /mnt/loopback #-o loop来挂载环回文件df -humount /mnt/loopback#将ISO文件作为环回文件挂载mount -o loop linux.iso /mnt/iso 生成ISO文件以及混合ISO12345678#可引导光盘自身具备引导能力，也可以运行操作系统或其他软件。不可引导光盘则做不到这些。cat /dev/cdrom &gt; /dev/sdc #sdc指U盘dd if=/dev/cdrom of=/dev/sdc #将ISO写入usb存储设备mkisofs -V "Label" -o /dev/sdc /dev/cdromcdrecord -v dev=/dev/cdrom image.iso 查找文件差异并进行修补diff - compare files line by line 1234567891011121314#补丁文件(patch file)#diff命令可以生成差异文件diff -u file1 file2 #一体化形式输出diff -u file1 file2 &gt; diff.patchpatch -p1 file1 &lt; diff.patch #得到file2patch -p1 file2 &lt; diff.patch #得到file1patch -R file1 &lt; diff.patch; patch -R file2 &lt; diff.patch #还原#diff也能够以递归的形式作用于目录，它对目录中所有内容生成差异输出diff -Naur dir1 dir2#-N将所有确实文件视为空文件， -a将所有文件视为文本文件#-u生成一体化输出， -r遍历目录下所有文件 head与tail123456head file1; tail file1 #head与tail默认打印10行head -n 5 file1; tail -n 6 file1 #指定行数head -n -5 file1 #打印除了最后5行外所有行tail -n +(5+1) file1 #打印除了开始5行外所有行tail -f /var/log/nginx/access.log #--follow，动态关注文件 只列出目录的其他方法1234ls -d .ls -l . | grep &quot;^d&quot;ls -F . | grep &quot;/$&quot;find . -maxdepth 1 -type d pushd和popd1234567891011121314#在命令行中使用pushd和popd快速定位，pushd和popd以栈的方式运作#当没有鼠标时，复制粘贴就不怎么实用了#pushd和popd可以用于在多个目录之间进行切换而无需复制并粘贴目录路径pushd /home/user1; pushd /home/user2; pushd /home/user3 #将路径添加到栈pushd +2 #切换到/home/user3popd #移除最近添加入栈的目录cd /root; cd /home/usercd - #回到上次的目录cd .. #切换到上一级目录cd ~ #切换到用户主目录 统计文件的行数、单词数、字符数1234567#wc(word count)，是一个统计工具wc -l file1 #统计行数wc -w file1 #统计单词数wc -c file #统计字符数wc -L file #打印最长行长度wc file1 #行、单词、字符数 目录树123456789#tree命令是以图形化的树状结构打印文件和目录,在Linux发行版中默认未安装yum install -y treetree /home/zhangtree /home/zhang -P "*.sh" #只标记出.sh文件tree /home/zhang -I "*.sh" #标记出除.sh文件外所有文件tree /home/zhang -h #显示大小tree /home/zhang -H http://localhost -o tree.html #以html形式输出目录树 让文本飞简介shell脚本可以将sed, awk, grep, cut等这类优美的工具组合在一起，用于解决文本处理相关问题。 正则表达式(RE)正则表达式是一种用于文本匹配的形式小巧、具有高度针对性的编程语言。只依靠通配符技术，能够匹配的文本范围相当有限。 正则表达式基本组成 正则表达式 描述 ^ 行起始标记 $ 行尾标记 . 匹配任意一个字符 [] 匹配包含在[]中的任意一个字符 [^] 匹配出[^]之外任意一个字符 [-] 匹配[]中范围内的任意一个字符 ？ 重复0或1次 + 重复&gt;=1次 * 重复&gt;=0次 () 创建一个用于匹配的子串 {n} 重复n次 {n, } 重复&gt;=n次 {n,m} 重复n到m次 \ 转义字符 竖线l 匹配竖线l两边任意一项 POSIX字符类 POSIX字符类(POSIX character class),是一个形如[:…:]的特殊元序列，它用于匹配特定的字符范围。 正则表达式 描述 [:alnum:] 字母与数字字符 [:alpha:] 字母字符 [:blank:] 空格与制表符 [:digit:] 数字字符 [:lower:] 小写字母 [:upper:] 大写字母 [:punct:] 标点符号 [:space:] 所有空白字符 元字符 元字符(meta character)，是一种Perl风格的正则表达式，只有一部分文本处理工具支持它。 正则表达式 描述 \b 单词边界 \B 非单词边界 \d 单个数字字符 \D 单个非数字字符 \w 单个单词字符(数字，字母和_) \W 单个非单词字符 \s 单个空白字符 \S 单个非空白字符 \n 换行符 \r 回车 123456#匹配一个ipv4地址[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;#匹配一个邮箱地址[\w]+@[\w]\.com 用grep在文件中搜索文本grep命令是Unix中用于文本搜索的工具，它能够接受正则表达式和通配符。 12345678910111213141516171819202122grep "匹配文本/通配符" file1 file2... --color=auto #重点标记匹配grep -E "正则表达式" fileegrep "正则" filegrep -v #反向匹配grep -c #统计匹配行数grep -n #打印出匹配的行号grep -o #唯一匹配grep -l "匹配" file1 file2 #返回匹配的文件名grep -R #递归匹配grep -i #忽略大小写grep -e "匹配1" -e "匹配2" #匹配多个样式grep -f match.txt file1 #从match.txt文件读取匹配grep "匹配" --include=*.&#123;sh,txt&#125; --exclude=*.log --exclude-dir=/home/user -r /home #包括或排除文件-A/-B n #输出匹配 之后/之前 n行-c n #输出匹配 前后 n行#正则匹配多个egerep "(a|b)" 用cut按列切分文件cut是一个将文本按列进行切分的小工具，它也可以指定每列定界符。在cut的术语中，每列都是一个字段。 1234567#制表符'\t' 是cut默认的定界符cut -d' ' -f1 1.txt #-d指定分隔符，-f打印第几个字段cut -f1,2,3 #打印1,2，3列-c字符； -b字节；cut -c 1-5 1.txt #打印1-5字符cut -c -2 1.txt #打印前2个字符cut -c 3- #打印第3个字符到行尾 统计特定文件词频1234#单词解析可以用 关联数组,正则表达式配合sed,awk,grep等工具来完成#关联数组中，将单词作为数组索引，单词次数作为数组值egrep -o "\b[:alpha:]+\b" #匹配单词 sed入门sed是stream editor(流编辑器)的缩写，它是文本处理中非常重要的工具。能够完美地配合正则表达式使用。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#sed - stream editor for filtering and transforming text#字符/在sed中最为定界符使用#替换#sed 's/匹配样式/替代字符串/'sed 's/pattern/repalce/' file #替换sed -i 's/pattern/repalce/' file #将替换应用于fileecho "1.txt" &gt; 1.txt &amp;&amp; sed 's/txt/haha' 1.txt #在输出中用haha替换txtsed -i 's/txt/haha/' 1.txt #将1.txt文件中的txt用haha替换掉#-i选项替换原文件echo "hahaha" | sed 's/ha/HA/g' #全部替换echo "hahaha" | sed 's/ha/HA/2g' #指定位置替换，从第2处开替换全局#移除匹配样式的行sed '/pattern/dsed '/^$/d' ##移除空白行#在sed中用&amp;标记已匹配字符串echo "A wonderful goal" | sed 's/\w\+/[&amp;]/g' #\w\+匹配每一个单词#子串匹配标记\1,\2...echo "1st 2nd 3rd" | sed 's/\(\w\+\) \(\w\+\) \(\w\+\)/\2 \1 \3/'2nd 1st 3rd#将\2和\1交换次序，(),+等在sed中要转义，否则要报错#组合多个表达式sed 'expression1; expression2; ...echo "aabbcc" | sed 's/a/A/; s/b/B/; s/c/C/g'AaBbCC#双引号 " " 内的特殊符号（如$等），可以保有原本的特性#单引号 ' ' 内的特殊字符则仅为一般字符（纯文本）#引用text=helloecho 'hello world' | sed "s/$text/HELLO/"HELLO world awk入门awk被设计用于数据流，它可以对列和行进行操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#awk ‘begin&#123;print "start"&#125; pattern &#123;command&#125; end&#123;print "end"&#125;’ fileawk '&#123;sum += $1&#125;; &#123;print sum&#125;'#awk脚本由:begin块、end块和能使用模式(pattern)匹配的通用语句块 组成#3个部分都是可选的#awk也可以从stdin中读取内容cat /etc/passwd | awk -F: '&#123;print $1&#125;' #-F指定界定符#awk中的特殊变量#NR：记录数量(number of records)，对应于当前行号#NF：字段数量(number of fields)，对应于当前行的字段数#$0：执行过程中当前行的文本内容#$1,$2...$NF：第1个/2个.../最后一个 字段的内容echo -e "L1 1\nL2 22\nL3 333" | awk '&#123;print NR NF $0 $1 $2&#125;'# NR NF $0 $1 $2 $NF=最后一个=$2 1 2 L1 1 L1 1 1 2 2 L2 2 L2 2 2 3 2 L3 3 L3 3 3#将外部变量传递给awk#-v选项可将外部值传递给awk# -v var=val --assign=var=valvar='12345'echo | awk -v v1=$var '&#123;print v1&#125;'#多个变量var1=111; var2=222echo | awk '&#123;print v1,v2&#125;' v1=$var1 v2=$var2#变量来自文件而非标准输入awk '&#123;print v1,v2&#125;' v1=$var1 v2=$var2 file#用样式对awk进行过滤处理awk 'NR &lt; 3,NR==4' 1.txt #行号&lt;5的行awk '/linux/' 1.txt #匹配带有linux的行（可用re）awk '!/linux/' 1.txt #!匹配不带linux的行#设置定界符awk -F: '&#123;print $1&#125;' /etc/passwdawk '&#123;FS=":"&#125; &#123;print $1&#125;' /etc/passwdawk '&#123;FS=":"; print $1&#125;' /etc/passwd#从awk中读取命令输出，用getline读取行echo | awk '&#123;"grep root /etc/passwd" | getlin out; print out&#125;'root:x:0:0:root:/root:/bin/bash#在awk中使用循环awk '&#123;for(i=1;i&lt;4;i++) &#123;print $i&#125;&#125;' 2.txt #输出第1,2,3列#使用awk删除某列awk -F' ' '&#123;$1=null;$2=null;print&#125;' ./file 对文件中的行、单词、字符进行迭代123456789101112131415161718192021222324252627282930313233#迭代文件中的每一行echo -e "1\n22\n333" | while read line;do echo $line;donegrep "bash" /etc/passwd | while read line;do echo $line;done#1#22#333#迭代一行中的每一个单词echo "1 22 333" | while read line;do for word in $line;do echo $word;done;done#1#22#333#迭代一个单词中的每一个字符echo "abc" | while read line;do for word in $line; do for((i=0;i&lt;$&#123;#word&#125;;i++)); do echo $&#123;word:i:1&#125;; done; done;done#写成一行echo "abc" | while read line; do for word in $line; do for((i=0;i&lt;$&#123;#word&#125;;i++)); do echo $&#123;word:i:1&#125;; done; done; done#a#b#c#$&#123;#word&#125;返回变量word的长度 按列合并文件(paste)可以使用paste命令实现列拼接12345678#paste - merge(整合) lines of filesecho -e "1\n2\n3" &gt; 1.txt &amp;&amp; echo -e "Line1\nLine2\nLine3" &gt; 2.txtpaste 1.txt 2.txt1 Line12 Line23 Line3#默认定界符是制表符，用-d指定paste 1.txt 2.txt -d',' 打印文件或行中的第n个单词或n列12awk -F':' '&#123;print $1,$3&#125;' file1cut -d':' -f 1,3 file1 打印不同行或样式之间的文本123456awk 'NR==1,NR==10' /etc/passwdawk 'NR==1,NR==10' /etc/passwd | awk -F":" '&#123;print $1,$NF&#125;' #打印特定行内的特定列awk '/start_pattern/, /end_pattern/' file #打印start到end之间的内容,可使用reawk '/root/, /zhang/' /etc/passwd #打印root到zhang之间内容awk '/^ro.?t'/, /bash$/' /etc/pass 以逆序形式打印行可以使用awk, tac完成。tac就是反过来的cat。 123#tac - 反转显示文件中的行，行内的内容无法用tac反向排列tac 1.txtawk '&#123;lifo[NR]=$0; lno=NR&#125; END&#123; for(;lno&gt;-1;lno--) &#123;print lifo[lno]&#125;;&#125;' 1.txt 解析文本中的电子邮件和URL从给定的文件中解析出所需要的文本是我们从事文本处理时的一项任务。 grep, egrep, fgrep - print lines matching a pattern 123456789#egrep#匹配一个邮箱地址egrep -o '[a-zA-Z0-9.]+@[0-9a-zA-Z.]+\.[a-zA-Z]&#123;2,4&#125;' emails.txt#匹配一个URL地址egrep -o "http://[a-zA-Z0-9.]+\.[a-zA-Z]&#123;2,3&#125;" urls.txt 打印某个样式之前/之后n行(grep)123grep "zhang" /etc/passwd -A 5 #Atergrep "zhang" /etc/passwd -B 5 #Beforegrep "zhang" /etc/passwd -C 5 #前后五行都打印 在文件中移除包含某个单词的句子只要能写出正确的正则表达式(Regular Expression)，那就手到擒来 1sed 's/[^.]*handsome boy[^.]*\.//g' file.txt #句子以.结束 文本切片与参数操作12345678910111213141516#替换变量内容中的部分文字var="One two three"echo $&#123;var/t/T&#125; #只替换了一个#One Two three#指定字符串起始位置和长度#$&#123;变量:开始部分:长度&#125;$&#123;vari:start:length&#125;echo &#123;var:0:2&#125; #Onecho &#123;var:1:6&#125; #ne two#起始字符的索引是0,将最后一个字符索引记为-1echo $&#123;var:(-1)&#125; #eecho $&#123;var:(-3):3&#125; #ree 一团乱麻？没这回事入门本章会研究一些用于解析网站内容、下载数据、发送数据表单以及网站颇为任务自动化之类的实例。我们可以仅用几行脚本就将很多原本需要通过浏览器交互进行的活动管理自动化。通过命令行工具利用HTTP协议所提供的功能，我们可以用脚本解决大部分Web自动化的问题。 网站下载(wget,curl)使用一些命令行下载工具，从给定的URL中下载文件或网页。 wget是一个用于文件下载的命令行工具，选项多且用法灵活。 123456789101112131415161718192021222324252627282930313233343536373839#Wget - The non-interactive(非交互式) network downloaderwget URL1 URL2...wget http://xxx.com/nginx-1.12.0.tag.gzwget https://xxx/a.rpm http://xxxx/bb.rpm#指定文件名，指定信息输出(wget默认是stdout)wget http://mirrors.aliyun.com/repo/Centos-7.repo -O aliyun.repo -o ./wget.logwget URL -t 5 #-t，重试次数#下载限速wget --limit-rate=10m URL #下载限速wget -Q 100m URL #指定下载配额#端点续传#wget进行的下载在完成前被中断，从断点开始下载wget -c URL#用cURL下载#cURL是一个比wget更强大的高级命令工具#和wget不同，curl并不将下载数据写入文件，而是写入stdout，因此必须重定向到文件#复制或镜像整个网站#wget有一个选项可以使其像爬虫一样以递归方式手机网页上所有URL链接，并逐个下载#这样一来就可以下载一个网站的所有页面wget --mirror URL#-m(--mirror) -N -r -l inf --no-remove-listing 的缩写形式。或 wget -r -N -l DEPTH URL#-r递归下载，-l指定递归深度，-N(timestamp)只获取比本地时间新的文件#访问需要认证的HTTP或FTP页面wget --user "username" --password "pass" URL#如未在命令行内输入密码，则会由网页提示手动输入 以格式化纯文本下载网页(links)网页其实就是包含HTML标记和其他诸如Javascript，CSS等元素的HTML页面。HTML标记是网页的基础，也许需要解析网页来查找特定的内容。 links,是一个基于命令行的Web浏览器 123456789101112#links - lynx-like alternative character mode WWW browser#在命令行中浏览一个网页links www.baidu.com#以ASCII形式下载网页links --dump URL &gt; URL.txt#打开本地html文件links 1.html cURL入门cURL支持包括HTTP、HTTPS、FTP在内的众多协议。它还支持POST、cookie、认证、从指定偏移处下载部分文件、参照页(referer)、用户代理字符串、扩展头部(extra header)、限速、文件大小限制、进度条等特性。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#curl - transfer a URL#cURL通常将下载文件输出到stdout，将进度信息输出到stderr#要想避免显示进度信息，可使用--silent#curl可用来下载、发送各种HTTP请求、指定HTTP头部等操作curl URL --silent #输出到stdout#-O写入文件，文件名从URL中解析curl http://www.baidu.com/index.html -O --silent #创建index.html#-o将数据写入指定文件curl URL -o baidu.html --progress #--progress显示进度条links baidu.html#端点续传#和wget不同，cURL包含更高级的下载恢复特性，能够从特定的文件偏移处继续下载#curl可以通过指定一个偏移量来下载部分文件手动：curl URL/file -C offset #偏移量以Byte为单位的整数自动：curl -C -URL #自动续传#用cURL设置参照页字符串, --referer#参照页(referer)是位于HTTP头部中的一个字符串，用来标识用户从哪个页面到达当前页面的#如果用户点击网页A中某个链接，转到了网页B。那么网页B头部的referer会包含网页A的URLcurl --referer Referer_URL target_URLcurl --referer http://www.baidu.com http://jianshu.com#用cURL设置cookie, --cookie#可以用curl来存储HTTP操作过程中使用到的cookie#cookie用key=value形式，指定多个用 分号 分隔curl URL --cookie "user=AAA;name=bbb"curl URL --cookie-jar cookie.txt #将cookie另存为#用cURL设置用户代理字符串, --user-agent#如果不指定代理，一些需要用户代理的网页就无法显示curl URL --user-agent(-A) "Mozilla"#用-H "头部信息"传递多个头部信息curl -H "Host:www.haha.com" -H "Accept-language: en" URL#限定cURL可占用的带宽curl URL --limit-rate 10m#指定最大下载量curl URL --max-filesize 大小(Bytes)#用cURL进行认证，-u username:password指定用户名和密码curl -u user:pass URLcurl -u user URL #手动输入密码#只打印响应头部信息(无数据部分), -Icurl -I URL 从命令行访问163邮箱12curl -u user http://mail.163.com#手动输入密码 制作图片抓取器及下载工具可以用脚本解析图像文件并将图片自动下载下来。 1234567curl -s URL | grep -o "&lt;img src=[^&gt;]*&gt;" | sed 's/&lt;img src=//g; s/&gt;//g' &gt; img.list#匹配图片的URL，可能还需要细化修改#不同的URL可能有不同的规则，根据实际情况取出img的URL#下载图片wget $URL 或 curl -s -O $URL 查找网站中的无效链接(lynx)将查找无效链接的工作自动化，那就比纯手动厉害多了！ 123456789lynx -traversal URL #会将URL中所有链接生成到reject.dat文件中sort -u reject.dat | while read linkdo output=`curl -I $link -s | grep "HTTP/.*OK"` if [[ -z $output ]] then echo $link fidone &lt; links.txt 跟踪网站变更(curl+diff)可以编写一个定期运行的变更跟踪器(change tracker)，一旦发生变更，跟踪器便会发出声音或发送提示信息。在不同时间检索网站，然后利用 diff 命令进行比对。 123curl URL --silent -o `date +%F`.html #第一次curl URL --silent -o `date +%F`.html #第二次diff -u 第一次 第二次 以POST方式发送网页并读取响应POST 和 GET 是HTTP协议中用于发送或检索信息的两种请求类型。在GET请求方式中，利用网页的URL来发送参数(“键-值”)；而POST方式用于提交表单，如提交用户名、密码以及检索登录页面等。 1234curl URL -d “postarg=AABBCC” #-d,http post datacurl URL -d "post1=key1&amp;post2=key2&amp;post3..." #指定多个数据wget URL -post-data "post1=key1" Plan B 简介提取快照和备份数据都是重要的工作，我们可以通过shell脚本来实现备份自动化。归档和压缩对于SA来说同样很重要，有多种压缩格式。加密是一种保护数据的方法，为了减少加密数据的大小，文件在加密前通常需要先归档和压缩。 用tar归档tar命令可以用来归档文件(tar archives tar)。可以将多个文件和文件夹打包为单个文件，同时还能保留所有的文件属性。由tar命令创建的文件通常称为tarball。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#归档文件，-c(create file)tar -cf 1.tar [sources] #-f(specify filename)指定文件名#文件名必须紧跟在-f之后tar -cvf txt.tar *.txt #-v(verbose)详细信息#向已归档文件中添加文件，-rtar -rvf txt.tar *.html#列出归档文件中的内容，-ttar -tf txt.tar #列出归档内容tar -tvf txt.tar #列出内容详细信息#从归档文件中提取文件或文件夹，-x(exact)tar -xf txt.tar #默认提取到当前目录#-C指定提取目录tar -xvf txt.tar -C /dir/path#只提取归档中特定文件tar -xf txt.tar 1.txt 1.html -C /tmp #只会提取1.txt和1.html文件#在tar中使用stdin和stdouttar -cvf - *.text | tar -xvf - -C /tmp#拼接两个归档文件，-Atar -Af txt.tar html.tartar -tvf txt.tat #验证是否成功#添加选项，可以将指定的任意文件加入到归档文件中。如果同名文件已存在，不会覆盖源文件，那么结果就是归档中包含了多个同名文件#通过检查时间戳来更新对党文件中的内容，-u#只有比归档文件中同名文件 更新(newer) 才添加tar -uvf html.tar 1.html#比较归档文件与文件系统中的内容，-dtar -df txt.tar 1.txt 2.txt#从归档文件中删除文件，--deletetar -f txt.tar --delete 1.txt 2.txt#从归档文件中排除部分文件,--excludetar -cf all.tar ./* --exclude="*.html" #排除.html文件tar -cvf txt.tar *.txt --exclude="1.txt"#打印总字节数,--totalstar -cf all.txt ./* --totals#压缩tar归档文件，指定不同压缩格式#-z, .tar.gz#-j, .tar.bz2#--lzma, .tar.lzma,#.tar.lzotar -czvf txt.tar.gzip *.txttar -xzvf txt.tar -C /dir/path#tar后删除原文件tar -czvf txt.tar.gz ./txt --remove-files 用cpio归档cpio是类似于tar的另一种归档格式。它多用于RPM软件包、Linux内核和initramfs文件等。cpio通过stdin获取输入，并将归档写入stdout。 12345678touch file&#123;1..4&#125;echo file1 file2 file3 file4 | cpio -ov file.cpio#-o指定输出，-v打印归档文件列表#-i指定输入，-t列出归档中文件cpio -it &lt; file.cpio 用gunzip或gzip压缩gzip是GNU/Linux下常用压缩格式。gzip,gunzip都可处理gzip压缩文件类型。gzip只能够压缩单个文件，而无法对目录和多个文件进行归档。因此需要先交给tar，然后再用gzip压缩 12345678910111213141516171819202122232425gzip file #file.gz，会覆盖原文件gunzip file.gz #file，也会删除原文件#列出压缩文件的属性信息，-lgzip -l file.gz#指定gzip的压缩级别，--fast或--best--fast 最低压缩比，最快速度完成--best 最高压缩比，最慢速度完成#将gzip与归档文件结合，-ztar -czvf txt.tar.gzip ./*.txt#-a指定从文件扩展名自动判断压缩格式tar -cavf txt.tar.gzip ./*.txt#tar只能从命令行中接收有限个文件，要解决这个问题，可以写一个循环并添加-r选项#解压缩，-xtar -xzvf txt.tar.gziptar -xavf txt.tar.gzip -C /dir/path 用bunzip或bzip压缩bzip2通常能够生成比gzip更小(压缩比更高)的文件。 1234567891011121314151617181920212223bzip2 file #file.bz2,同理会覆盖原文件bzip2 file -k #保留原文件bunzip2 file.bz2 #解压缩bunzip file.bz2 -k#从stdin读入并写到stdoutcat file | bzip2 -c &gt; file.bz2#将bzip2与归档文件结合，-jtar -cvjf 1.tar.bz2 ./1.*tar -cavf 1.tar.bz2 ./1.* #-a根据文件扩展名自动判断压缩格式tar -xjvf 1.tar.bz2tar -xavf 1.tar.bz2 -C /tmp#压缩比#从1级(速度最快，压缩率最低)到9级bzip -9 -k file#对成千上万的文件进行归档，需要借助 循环和-r选项 lzma压缩lzma是一个较新的压缩工具，它提供了比gzip或bzip2更好的压缩率。xz, unxz, xzcat, lzma, unlzma, lzcat - Compress or decompress .xz and .lzma files 1234567891011121314151617lzma file #file.lzma,同样也会删除原文件lzma file -k #保留原文件unlzma file.lzma#从stdin读入并写入stdoutcat file | lzma -C &gt; file.lzma#与tar相结合,--lzmatar -cvf 1.tar.lzma ./1.* --lzmatar -cavf 1.tat.lzma ./1.* #自动判断tar -xvf 1.tar.lzma --lzmatar -xavf 1.tar.lzma -C /tmp#压缩率#从1级到9级(压缩级别最高，速度最慢)#对成千上万的文件，需要使用循环和-r选项 zip归档和压缩zip在Linux下不如gzip,bzip2那么广泛，但在Internet上的文件通常都采用这种格式。zip - package and compress (archive) files 12345678910111213141516171819zip file.zip fileunzip file.zip#与lzma,gzip,bzip2相比，zip完成后不会删除原文件#对目录和文件进行递归操作,-rzip -r dir.zip /root/test ./file#向归档文件中增加内容，-uzip dir.zip -u newfile#从压缩文件中删除内容，-dzip -d dir.zip file#列出归档文件中内容unzip -l dir.zip 超高压缩率的squashfs文件系统squashfs是一种只读型的超高压缩率文件系统。这种文件系统能够将 2GB-3GB的数据压缩成一个700MB的文件。你有没有想过Linux Live CD是怎样运行的？当Live CD启动后，它会加载一个完整的Linux环境。这就是利用了一种被称为squashfs的只读型压缩文件系统。它将根文件系统保存在一个压缩过的文件系统文件中。这个文件可以使用环回的形式来挂载并对其中的文件进行访问。一次当进程需要某些文件，可以将它们解压，然后载入内存中使用。如果需要构建一个定制的Live OS，或是需要超高压缩率的文件并且无需解压就可以访问文件，那么squashfs的相关知识就能派上用场。要解压个头较大的压缩文件，需要花费不少时间。但如果将文件以环回形式挂载，速度就飞快，因为只有出现访问请求的时候，对应的那部分压缩文件才会被解压缩。而普通的解压缩方式是首先解压缩所有的数据。 环回文件系统就是指那些在文件中而非物理设备中创建的文件系统。比如我们可以创建一个文件，然后把这个文件格式化为我们常见ntfs、exfat或者ext4等文件系统格式，然后把它挂载在一个目录上使用。 如果你有一张Ubuntu CD，可以在CDRom Root/casper/filesystem.squashfs中找到文件.squashfs。squashfs在内部采用了gzip和lzma这类压缩算法。 mksquashfs - tool to create and append to squashfs filesystems 1234567891011121314151617181920yum install squashfs-tools -y#创建squashfs文件mksquashfs source compressfile.squashfsmksquashfs /etc etc.squashfs#/etc(67M) --&gt; etc.suqashfs(18M)#要挂载squashfs文件，利用环回形式进行挂载mkdir /mnt/squashmount -o loop etc.squashfs /mnt/squash#此处挂载使用etc.squashfs文件系统#如果直接查看etc.squashfs，就是一个普通文件，但是挂载以后所有文件都出现了umount /mnt/squash#在创建squashfs文件时排除指定文件，-emksquashfs /etc etc.squashfs -e /etc/passwd /etc/shadow /etc/*.txt#在挂载之后就没有相关文件了 加密工具与散列加密技术主要用于防止数据遭受未经授权的访问。Linux下某些工具用于执行加密和解密，使用加密算法散列值来验证数据完整性。 crypt, gpg, base64, md5sum, sha1sum, openssl的用法 ccyptccrypt是为了取代UNIX crypt而设计的，这个实用工具可用于文件和数据流加密及解密。 ccrypt - encrypt and decrypt files and streams 12345678910ccrypt 1.txt #会要求输入口令(encryption key)#之后会生成1.txt.cpt覆盖原文件#更改key,-xccrypt -x 1.txt.cpt #输入old key和new key#解密，-d(--decrypt)ccrypt -d 1.txt.cpt #输入key解密 gpggpg(GNU privacy guard,GNU隐私保护)，是一种应用广泛的加密方案。它采用签名密钥技术保护文件内容，只有经过认证的用户才能访问数据。我们对gpg签名早已耳熟能详。 gpg - OpenPGP encryption and signing tool 12345#加密，-c(--symmetric)对称加密gpg -c file #会要求输入口令(Passphrase)，生成file.gpg#解密gpg file.gpg base64base64是一组类似的编码方案(encoding scheme)，它通过将ASCII字符转换成以64为基数的形式(radix-64 representation)来用ASCII字符串描述二进制数据。base64可用来对 编码和解码 base64字符串。 base64 - base64 encode/decode data and print to standard output 123456#将文件编码为base64格式base64 file &gt; outputfilecat file | base64 &gt; outputfile#解码,-dbase64 -d outputfile &gt; file md5sum与sha1summd5sum 和 sha1sum 都是单向散列算法(unidirecrional hash algorithm)，均无法逆推出原始数据。它们通常用于验证数据完整性或为特定数据生成唯一的密钥，因为通过分析文件内容，它们可以为每个文件生成一个唯一的密钥。 这种类型的散列算法是存储密码的理想方案。密码使用其对应的散列值来存储。如果某个用户需要认证，读取该用户提供的密码并转换成散列值，然后将其与之前存储的散列值进行比对。将密码以明文的形式存储是非常危险的事情，它面临密码泄露的危险。而因为 md5sum和sha1sum 是单向散列算法，所以密码使用散列值存储是很安全的。 123456789101112echo "1.txt" &gt; 1.txtmd5sum 1.txt #生成密钥到stdout#39061daa34ca3de20df03a88c52530ea 1.txtsha1sum file #生成密钥到stdout#659fcbc505db207c03b5c4c0b6981d63286abe21 1.txt#查看/etc/shadow中密码的散列值awk 'NR==1' /etc/shadow | awk -F: '&#123;print $2&#125;' #root密码散列#$6$BxpV48gPsjuq6.pF$wE7pUDwtOI.v64kd5folG68yUt2UAQDTUGgKa5Iz69GaupEoRAdCeerP8nRKXo48c4azutUCGhnDgzd1qe8YX0 shadowlike散列(salted散列)shadow密码通常都是salted密码，所谓SALT就是额外的一个字符串，用来起一个混淆的作用，使加密更加不同里被破解。salt由一些随机位组成，被用作密钥生成函数的输入之一，以生成密码的salted散列值。 12345678910111213#/etc/passwd里面的密码散列类型就是salted散列#查看root密码对应的散列值head -1 /etc/shadowroot:$6$ZlHRCZG2iRwQUXAu$RAEDH97nPdZB2RK20npua6Qf6jB7osatoC99ow3LtPQ6aORdLISYC7/4iTYU162emkQLt4ZafdgjyAeoSB7IU0::0:99999:7:::#openssl - OpenSSL command line tool#shadow密码是使用openssl生成#将SALT_STRING替换为随机字符串，同时将pass替换成你想测试的密码openssl -1 -salt SALT_STRING passwd 用rsync备份系统rsync借助差异计算以及压缩技术来最小化数据传输量。相较于cp命令，它的优势在于使用了高效的差异算法(difference algorithm)。它还支持网络数据传输。在进行复制的同时，rsync会比较源端和目的端的文件，只有当文件有更新是才进行复制。默认情况下，rsync并不会在目的端删除源端已不存在的文件。 rsync - a fast, versatile, remote (and local) file-copying toolinotifywait - wait for changes to files using inotify 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#-a进行归档，-v详细信息rsync -av source destinationrsync -av /etc /tmp#异地cprsync -av source username@host:PATHrsync -av username@host:PATH destination#rsync借助于ssh，可以使用ssh无秘钥认证rsync -av /etc zhang@192.168.1.11:~#-z, --compress compress file data during the transferrsync -avz zhang@192.168.1.11:/etc /tmp#注意，路径格式rsync /etc /tmp #整个/etc目录rsync /etc/ /tmp #/etc目录下所有内容#显示进度，--progressrsync -avz --progress /etc /tmp#排除部分文件，--excludersync -avz /etc /tmp --exclude=/etc/nginx --exclude "*.txt"#更新rsync时，删除不存在的文件，--delete#默认情况下，rsync并不会在目的端删除源端已不存在的文件rsync -avz /etc zhang@192.168.1.1:~ --delete#定期调度crontab -e0 */10 * * * rsync -avz /etc user@host:PATH#实时同步，inotifywait+rsyncyum install inotify-tools -y#-m(monitor),-r(recursive),-q(--quiet)静默模式，-e(event)vi inotify_rsync.shinotifywait -mrq -e creat,delete,modify,move --exclude "^.*\.filepart$" /etc | while read filedorsync -az --exclude=".*" --exclude="*.swp" --exclude=".filepart" --delete /etc /tmp &gt; /dev/null 2&gt;$1done 用Git备份版本控制维护和恢复变更最好的方法是使用版本控制系统。由于代码变更频繁，版本控制系统多用于软件开发和代码维护。Git(GNU it)是有名气也是最高效的版本控制系统。我们可在非编程环境下用Git备份普通文件。 git - the stupid content tracker 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354mkdir /home/zhang/gittestcd /home/zhang/gittest#在源主机中添加用户信息git config --global user.name "username" #设置用户名git config --global user.email "someone@example.com" #设置邮箱#创建一个空的Git版本库或初始化一个老版本git init#记录变更到版本库git commit#添加远程git目录并同步备份git remote add origin user@host:/home/zhang/gittest#为git跟踪(git tracking)添加或删除文件#add,添加内容至索引git add *#git add *.txt; git add *.ph #添加部分文件#删除不需要跟踪的文件和文件夹#rm,从工作去和索引删除文件git rm file#git rm *.txt#检查点或创建备份点(check point)git commit -m "Commit Message"#push,更新远程git push#用Git恢复数据#log,显示提交日志git log#返回之前某个版本或状态git checkout xxxxxxxx(Commit ID)#clone,克隆一个版本库到本地git clone URLgit clone user@host:PATH 用dd克隆磁盘dd命令能用于克隆任何类型的磁盘，如硬盘、闪存、CD、DVD及软盘。可能需要创建所有分区的副本而不仅仅是复制内容，包括硬盘分区、引导记录、分区表等信息。 使用dd的时候，要留意参数的顺序。错误的参数会损毁全部数据。dd基本上算是一个比特流复制器(bitstream duplicator),它可以将来自磁盘的比特流写入文件，也可以将来自文件的比特流写入硬盘。 dd - convert and copy a file 123456789101112dd if=source of=target bs=block_size count=count#bs块大小，count块数dd if=/tmp/centos7.iso of=/dev/sdc#/dev/zero是一个字符设备，它总是返回字符'\0'dd if=/dev/zero of=./file bs=10m count=100#用环回(loop back)方法可将任何由dd生产的文件镜像进行挂载mount -o loop file /mnt 无网不利简介网络是计算机系统中重要的部分。我们以Tcp/Ip为协议栈，所有操作都是基于它进行的。 一些使用网络的应用通过打开并连接到防火墙端口进行运作，而有的管理任务可以通过网络进行。 网络小知识网络接口(Interface)用来连接网络。在每个系统中，默认都有一个称之为环回接口的lo，这个接口指向当前主机本身。操作系统维护者一个被称为路由表(routing table)的表格，它包含了分组如何转发以及通过网络中的哪些节点转发的消息。metric是路由算法用以确定到达目的地的最佳路径的计量标准，如路径长度。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#显示网络接口、子网掩码等详细信息ifconfig #/sbin/ifconfig#显示某个特定接口ifconfig eth0#提取IP地址ifconfig eth0 | egrep -o "inet [^ ]*" | grep -o "[0-9.]*"#设置网络接口的IP地址和子网掩码ifconfig eht0 192.168.1.11ifconfig eth0 192.168.1.11 netmask 255.255.255.0#远程的时候，千万别乱改IP，不然连不上你就要去机房了#MAC地址欺骗ifoconfig eth0 hw ether 11:22:33:44:55:66#域名服务器与DNScat /etc/resolv.conf#添加域名服务器echo "name 114.114.114.114" &gt;&gt; /etc/resolv.conf#nameserver 114.114.114.114#一个域名可以分配多个地址，DNS只会返回其中一个#要想获得域名所有IP地址，需要使用DNS查找工具#DNS查找工具host www.baidu.comnslookup www.baidu.com#自定义解析cat /etc/hostsecho "192.168.1.11 www.zhang.me" &gt;&gt; /etc/hosts#设置默认网关，显示路由表信息#路由表routeroute -n #以数字形式显示地址#设置默认网关route add default gw $ip $interfaceroute add default gw 192.168.1.1 eht0#显示分组途经的所有网关地址traceroute www.baidu.com pingping使用 网际控制报文协议(Internet Control Message Protocol,ICMP)的echo分组。如果分组能够送达且该主机为活动主机，那它就会发送一条回应。一旦主机不可到达，ping返回错误信息”Destination Host Unreachable”。 123456ping 192.168.1.1#往返时间(Round Trip Time,RTT)#发送分组数量ping $URL -c 6 列出网络上所有活动主机当涉及大型局域网时，可能需要检查网络上的其他主机的活动状态。一台非活动主机可能是：没有开机；网络连接有问题；主机禁ping；防火墙问题。 当我们要检测ip时，在一个脚本中，每一次ping都是依次执行。即使所有的ip地址都是彼此独立，由于编写的是顺式程序(sequential program)，ping命令也只能按顺序执行。每次执行一个ping命令。都要经历一段延迟——“发送echo分组，并接收或等待回应超时”。 要是处理几百个ip地址的话，这个延时就真不短了。我们可以使用并行方式来加速所有ping命令的执行。可以将ping命令中的循环体放入( )&amp; 中，( ) 使其中的命令可作为子shell来执行，&amp; 使之在后台继续运行。 1234567891011121314151617181920#编写G一个并行方式的ping脚本fo ip in 192.168.1.&#123;1..255&#125;do ( ping $ip -c2 &amp;&gt; /dev/null; if[ $? -eq 0 ] then echo "$ip is alive" fi )&amp;waitdone#wait命令是脚本只有在所有子进程或后台进程全部终止或完成后才能结束#使用fping,-a显示活动主机，-g生成目标列表,-u显示无法到达主机fping -a 192.168.0.0/24 -g 2&gt; /dev/nullfping -a 192.168.0.1 192.168.3.255 -g 2&gt; ./unreach.txt#将unreach主机找出cat unreach.txt | egrep -o "to [0-9.]+$" | grep -o "[0-9.]*" 传输文件有很多不同的方法可以在网络节点上传输文件，常见的协议有FTP, SFTP, RSYNC, SCP。 通过FTP传输文件可使用lftp命令；通过SSH传输文件可使用sftp；RSYNC使用SSH与rsync命令；scp通过SSH进行传输。 文件传输协议(File Transfer Protocol, FTP)，使用21端口。FTP是明文传输，So…需要远程主机上启用了FTP服务器才能使用FTP。 1234567lftp user@ftp-host#输入密码后便可以操作如下命令cd -- lcd(本地)mkdirget filename #下载文件put filename #上传文件quit #退出 SFTP(Secure FTP,安全FTP)，运行在SSH连接之上。利用SSH连接模拟FTP接口。它不需要源端运行FTP服务器，不要运行OpenSSH。SFTP是一个交互式命令，提供了命令提示符。 rsync广泛用于网络文件与系统快照的备份。 SCP(Secure Copy,安全复制)，远程文件复制工具。通过SSH加密通过进行传输。123456789scp SOURCE DESTINATIONscp /path/file user@host:PATHscp usr@host:/dir/file /home/zhang#需要输入密码，可以用SSH无秘钥认证#-r递归复制,-p保持文件权限和模式scp -r /etc user@host:/tmpscp -rp user@host:/var/www /var SSH无秘钥认证特别是在定时任务传输备份文件时，无秘钥认证就很方便了。SSH服务默认在22端口，你可以在配置文件中修改。 具体步骤： 创建SSH密钥(公钥和私钥)； 将客户端公钥上传给需要连接的主机，并写入~/.ssh/authorized_keys文件； 修改相关目录(700)和文件权限(600)； 1234567ssh-keygen -t rsa#后续操作默认即可#生成~/.ssh/id_rsa.pub和id_rsa#写入远程主机ssh user@host "cat &gt;&gt; ~/.ssh/authorized_keys" &lt; ~/.ssh/id_rsa.pub 用SSH在远程主机上运行命令1234567891011121314151617#连接远程主机ssh user@host#非默认端口ssh user@host -p 2211#在远程主机中运行命令ssh user@host 'command'ssh user@host 'cmd1'; 'com2'...ssh user@host 'whoami'#-C压缩功能，当带宽有限时ssh -C user@host 'cmd' 在本地挂载远程驱动器(sshfs)在执行读写数据操作时，通过本地挂载远程主机文件系统。利用SSH和sshfs来实现这一功能。sshfs是FUSE文件系统的一个扩展，FUSE允许其支持的操作系统像使用本地文件系统一样挂载各类数据。sshfs允许将远程文件系统挂载到本地挂载点上。 相当于便捷的NFS，但并不需要搭建NFS服务。 SSHFS - filesystem client based on ssh 1234#挂载远程文件到本地ssh user@host:PATH /mnt/sshfsumout /mnt/sshfs 网络流量和端口分析应用程序在主机上打开端口，然后与远程主机中打开的端口实现通信。出于安全方面的考虑，必须留意系统中打开及关闭的端口。 恶意软件和rootkit可能会利用特定的端口及服务运行在系统之中，从而进行攻击。通过分析开放端口列表以及运行在端口上的服务，我们便可以分析并检查恶意软件，保证主机安全。 了解及使用各种端口分析工具。 lsof - list open fileslsof列出系统中开放端口以及运行在端口上的服务的详细信息，文件被哪个程序使用。 1234567891011121314151617-a：列出打开文件存在的进程-c&lt;进程名&gt;：列出指定进程所打开的文件-g：列出GID号进程详情-d&lt;文件号&gt;：列出占用该文件号的进程+d&lt;目录&gt;：列出目录下被打开的文件+D&lt;目录&gt;：递归列出目录下被打开的文件-n&lt;目录&gt;：列出使用NFS的文件-i&lt;条件&gt;：列出符合条件的进程（4、6、协议、:端口、 @ip ）-p&lt;进程号&gt;：列出指定进程号所打开的文件-u：列出UID号进程详情-h：显示帮助信息-v：显示版本信息lsof /var/log/messagesCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMErsyslogd 12231 root 5w REG 253,0 539973467 68539162 /var/log/messages netstat查看开放端口与服务netstat - 显示网络连接，路由表，接口状态，伪装连接，网络链路信息和组播成员组; iftop - display bandwidth usage on an interface by hostiftop - 展示带宽使用情况； ifstat - handy utility to read network interface statisticsifstat - 展示某时刻网络状态； nload - displays the current network usagenload - 可查看系统总带宽； nethogs - Net top tool grouping bandwidth per processnethogs- 可查看每个进程流量情况；ethtool - query or control network driver and hardware settingsethtool - 检查网卡支持的带宽 12345678910111213141516171819202122#lsof的每一项都对应着一个打开了特定端口的服务lsof -i:port#查看开放端口和服务netstat -nltp#查看网络实时状态iftop#查看当前网络状态ifstat#查看系统带宽nload#查看进程流量nethogs tcpdumptcpdump是一款嗅探工具，也就是命令行格式的wireshark。 1234tcpdump - dump traffic on a networktcpdump [options]` 12345678910111213141516171819202122232425-a：尝试将网络和广播地址转换成名称；-c&lt;数据包数目&gt;：收到指定的数据包数目后，就停止进行倾倒操作；-d：把编译过的数据包编码转换成可阅读的格式，并倾倒到标准输出；-dd：把编译过的数据包编码转换成C语言的格式，并倾倒到标准输出；-ddd：把编译过的数据包编码转换成十进制数字的格式，并倾倒到标准输出；-e：在每列倾倒资料上显示连接层级的文件头；-f：用数字显示网际网络地址；-F&lt;表达文件&gt;：指定内含表达方式的文件；-i&lt;网络界面&gt;：使用指定的网络截面送出数据包；-l：使用标准输出列的缓冲区；-n：不把主机的网络地址转换成名字；-N：不列出域名；-O：不将数据包编码最佳化；-p：不让网络界面进入混杂模式；-q ：快速输出，仅列出少数的传输协议信息；-r&lt;数据包文件&gt;：从指定的文件读取数据包数据；-s&lt;数据包大小&gt;：设置每个数据包的大小；-S：用绝对而非相对数值列出TCP关联数；-t：在每列倾倒资料上不显示时间戳记；-tt： 在每列倾倒资料上显示未经格式化的时间戳记；-T&lt;数据包类型&gt;：强制将表达方式所指定的数据包转译成设置的数据包类型；-v：详细显示指令执行过程；-vv：更详细显示指令执行过程；-x：用十六进制字码列出数据包资料；-w&lt;数据包文件&gt;：把数据包数据写入指定的文件。 栗子： 123456789101112131415161718192021#tcpdump默认将监视第一个网络接口上流过的数据包tcpdump#指定网络接口tcpdump -i eth1 -w /tmp/1.cap#指定主机tcpdump host $hostnametcpdump host $hostname1 and $hostname2#指定源和目标主机tcpdump -i eth0 src host $hostnametcpdump -i eth0 dst host $hostname#指定主机和端口tcpdump tcp port 22 host 192.168.1.11tcpdump udp port 53 当个好管家简介操作系统(Operation System,OS)，是由一系列用于不同目的、服务于不同任务的系统软件组成。日志记录(logging)和监视是很重要的，能帮助我们从大量数据中收集信息。 监视系统活动的各种命令，日志技术及其使用方法。 统计磁盘使用情况(df+du+fdisk)磁盘空间是一种有限资源，我们需要了解磁盘的可用空间。 df, du, fdisk是Linux中的磁盘管理三板斧df(disk free): 报告文件系统磁盘空间的使用情况;du(disk usage): 报告磁盘空间使用情况; 使用du时，要确保对其遍历的目录和文件拥有适合的读权限。fdisk: Linux分区表操作工具软件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748du file1 #默认以字节为单位#-a,显示目录下所有文件大小du -a /home/zhangdu /home/zhang #只显示目录大小#-h,以可读形式打印du -h /home/zhang#-c,显示使用总量du -c file1 /dir2du -c *.txt *.sh#-s，打印摘要du -s /dirdu -sh /home/zhang#-b,-k,-m,-B，用特定单位打印du -k file1du -m file2#--exclude,从磁盘统计中排除部分文件du --exclude="*.swap" -sh /home/zhang#--max-depth,指定最大遍历深度du -h --max-depth n /dirdu -h --max-depth=2 /home/zhang#-x,将/mnt中所有挂载点排除在磁盘统计之外du -xh /dir#找出目录中最大的文件du -ak /dir | sort -nrk 1 | head -n 5#此输出包含了目录大小，需要细化#利用find替du过滤文件find /dir -type f --exec du -ak &#123;&#125; \; | sort -nrk 1 | head#df,磁盘可用空间信息df -h 计算命令执行时间当测试一个应用程序或比较不同的算法时，程序的执行时间非常重要。所以需要计算命令执行时间。 所有的Unix-Like操作系统都包含time命令，可将time放在需要计算执行时间的命令前。 time命令有个可执行二进制文件位于/usr/bin/time，还有一个shell built-in命令也叫作time；当运行time时，默认调用的是shell built-in命令。內建time命令选项有限；因此，如果我们需要使用另外的功能，就应该使用/usr/bin/time命令。 123456789101112131415161718192021222324#计算命令执行时间time commandtime ls#real,挂钟时间(wall clock time),命令从开始执行到结束的时间；#user,指进程花费在用户模式(user-mode)中的CPU时间。这是唯一用于执行进程所花费的时间；#sys，指进程花费在内核模式(in the kernel)中的CPU时间。它代表在内核中执行系统调用所使用的时间。#-o,将命令执行时间写入文件/usr/bin/time -o exetime.txt ls /#-a,不影响原文件/usr/bin/time -a -o exetime.txt ls /home#-f,格式化时间输出#时间格式字符串#real %e#user %U#sys %S/usr/bin/time -f "FORMAT STRING" command/usr/bin/time -f "Rtme: %e" -a -o timing.log uname/usr/bin/time -f "Rtime: %e\nUtime: %U\nStime: %S" -ao timing.log uname 当前登录用户、启动日志、启动故障的相关信息(w+who+lastb+last)收集与操作系统、当前登录用户、主机运行时间、启动故障等相关信息很有用处。 1234567891011121314151617181920#获取当前登录用户who #显示已经登录的用户w #显示已经登录的用户以及他们在做什么#会显示用户使用的伪终端(pseudo TTY)，对应设备文件出现在/dev/pts/n#列出登录主机的用户列表users#查看系统运行时间uptime#显示用户登录列表last#获取某个用户登录信息last zhang#获取重启会话信息last reboot#获取失败的用户登录信息lastb 打印10条最常使用的命令(history)终端是用来访问shell的工具，在shell中我们可以输入并执行命令。我们可以找出在shell中运行最多的命令。 ~/.bash_history，默认保留1000个最近执行命令。或者history命令。 1cat .bash_history | sort -n | uniq -c | sorn -nr | head 列出占用CPU最多的进程CPU时间是一项重要资源，有时需要跟踪占用CPU周期最多的进程。对于需要处理大量请求的服务器来说，CPU是极其重要的资源。通过监视某个时期内CPU的使用情况，可以找出长期占用CPU的进程并对其进行优化，或是调试其他问题。 用ps命令收集系统中进程的详细信息。ps - report a snapshot of the current processes 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#-e,以标准语法显示每个进程ps -eps -ef#ax,以BSD语法显示每个进程ps axpa axu#获取安全信息#ps -eo euser,ruser,suser,fuser,f,comm,pcpu,label#comm显示命令，pcpu显示CPU使用率ps -eo comm,pcpu#监视并计算一小时内CPU使用情况的shell脚本secs=3600unit_time=60steps=$(($secs / $unit_time))echo "Whatching CPU usage..."for((i=0; i&lt;steps; i++))do ps -eo comm,pcpu | tail -n +2 &gt;&gt; /tmp/cpu_usage.$$ sleep $unit_timedoneecho "CPU eaters: "cat /tmp/cpu_usage.$$ | \awk '&#123;process[$1]+=$2&#125;END&#123; for (i in process) &#123; printf("%-20s %s",i,process[i]); &#125;&#125;' | sort -nrk 2 | head#tail -n +K，从第K行开始输出。上面输出第一行是 COMAND 和 %CPU#$1,command; $2,%CPU#process[$1]是一个关联函数，相当于arr[command]#arr[command]=arr[command]+ $2，计算同一命令的累积时间#i指命令，process[i]指命令运行时间 用watch监视命令输出可能需要在在某段时期内以固定的间隔时间不短监视某个命令的输出。可利用watch命令。 watch - execute a program periodically, showing output fullscreen 123456789101112131415#watch命令可以用来在终端以固定的间隔监视命令输出，默认2秒间隔watch commandwatch 'command'watch lswatch 'ls -l'#-n,指定时间间隔watch -n 5 'yum update -y'#-d，突出(highlighting)watch输出中的差异watch -d -n 1'dd if=/dev/zero of=/tmp/zero.test' 对文件及目录访问进行记录(inotifywait)记录重要文件及目录访问，对于追踪文件和目录的变化很有帮助。inotifywait命令可以用来收集有关文件访问的信息。inotifywait和rsync用户实时同步哦！ inotifywait - wait for changes to files using inotify 1234567891011yum install -y inotify-tools#-q,减少冗余信息inotifywait -m -r -q -e create,move,delete /dirinotifywait -m -r -q -e create,move,modify,delete /home/zhang &gt;&gt; inotifywait.log#利用inotifywait检测，rsync同步inotifywait -mrq -e create,move,modify,delete /dir --exclude="*.swap" | while read filedorsync -av --exclude="*.swqp" --delete /dir user@host:PATH &gt; /dev/null 2&gt;&amp;1done 用logrotate管理日志文件日志文件是Linux系统维护中必不可少的组成部分。日志文件可以帮助跟踪系统中多种服务所发生的事件，这有助于排除系统问题。但随着时间推移，日志文件会变得越来越大。因而必须对日志文件进行管理。 我们可以利用一种称为“轮询(rotation)”的技术来限制日志文件的体积。一旦日志文件超过了限定大小，就要对它的内容进行抽取(strip)，同时将日志文件的旧条目归档到文件中。 logratate是每一位Linux系统管理员都应该了解的命令。它能够将日志文件大大小限制在给定的SIZE内。logrotate配置文件位于/etc/logrotate.d logrotate ‐ rotates, compresses, and mails system logs 123456789101112vim /etc/logrotated.d/custom/var/log/custom.log &#123; missingok #日志文件丢失，则忽略 notifempty #仅当源日志文件非空时才进行轮替 size 30k #限制实施轮替的日志文件大小 compress #压缩旧日志 weekly #轮询时间，daily,weekly,yearly rotate 7 #保留旧日志数量 create 0600 root root #创建的日志文件模式，用户和用户组#还有一些其他选项&#125; 用sys记录日志在Linux系统中，在/var/log中创建并写入日志信息的是由被称为syslog的协议处理的。它由守护进程syslogd负责执行。每一个标准应用进程都可以用syslog记录日志信息。 syslog处理/var/log下的多个日志文件。但是当logger发送消息时，它用标记字符串来确定应该纪录到哪一个日志文件中。syslogd使用与日志相关联的TAG来决定应该将其记录到哪一个文件中。可以从/etc/rsyslog.d/目录的配置文件中看到与日志文件相关联的标记字符串。 Linux中一些重要日志文件： /var/log/boot.log， 系统启动信息；/var/log/message， 内核启动信息；/var/log/auth.log， 用户认证日志；/var/log/dmesg， 系统启动信息；/var/log/mail.log， 邮件服务器日志。 logger - a shell command interface to the syslog 123456#logger命令，默认记录日志信息到/var/log/messageslogger "test log message to messages"tail -n 1 /var/log/message#-t，指定特定TAGlogger -t TAG "test log message to messages" 管理重任简介GNU/Linux的生态系统是由运行的程序、服务、连接的设备、文件系统、用户等组成。按照我们需要的方式对整个系统有一个微观并对操作系统进行整体上的管理，这就是系统管理的主要目的。 收集进程信息(top+ps+pgrep)进程是程序运行实例(runing instance)。同一程序的多个实例可以同时运行，但他们的进程ID却互不相同。 进程管理相关的重要命令是： top, display Linux processes; ps, report a snapshot of the current processes; pgrep, look up or signal processes based on name and other attributes. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#ps命令#-f, 显示更多进程信息ps -f#-e,every; -a,allps -efps -ax#-o, 指定想要的列ps -e -o parameter1,parameter2...ps -eo comm,pcpu,pmem#pccpu CPU占用率#pid 进程ID#ppid 父进程ID#pmem 内存使用率#comm 命令名#cmd 简单命令#user 启动进程的用户#nice 优先级#time 累积的CPU时间#etime 进程启动后度过的时间#tty 所关联的TTY设备#euid 有效用户ID#stat 进程状态#--sort,根据参数对ps输出进行排序#+升序，-降序ps -eo comm,pcpu,pmem --sort -pcpups -eo comm,pcpu,pmem --sort -pcpu,+pmem#-C, 给定命令全名找出PIDps -C cmd -o comm,pid#-u, 指定有效用户列表#-U, 指定真实用户列表ps -u root -U zhang -o user,pcpu#-t, 用TTY过滤输出ps -t TTY1,TTY2...ps -t pts/0,pts/1 -ef#-L, 显示进程相关信息#LWP线程ID， NLWP线程数量ps -efL#pgrep命令, 获得一个特定命令的PID列表#它只需要命令的一部分即可pgrep cmdpgre inotifpgrep bas#-d, 指定定界符pgrep rsync -d ":"#-u, 指定进程的用户pgrep -u root,zhang rsync#-c, 返回匹配的进程数量pgrep -c rsync#top命令top 杀死进程以及发送响应信息(kill+killall+trap)在Unix-Like环境中与进程有关的一个重要概念就是信号。信号是一种进程间通信机制，它用来中断运行的进程以执行某些操作。终止程序也是通过使用信号技术来实现的。 像ctrl+C,ctrl+Z这种作业都属于信号。 kill 命令可用来向进程发送信号; trap 命令用来处理所接收的信号; killall 以名字方式来杀死进程. 123456789101112131415161718192021222324252627#列出所有可用信号kill -l#-s, 发送信号#信号名称和信号数都可以kill -信号数 PIDkill -s SIGNAL PID#常用信号#SIGHUP 1 终端断线(对控制进程或终端进行挂起检测(hangup detection))#SIGINT 2 中断(当按下Ctrl+C时发送该信号)#SIGQUIT 3 退出(同Ctrl+\)#SIGKILL 9 强制终止(强行杀死进程)#SIGTERM 15 终止进程#SIGCONT 18 继续(与STOP相反，fg/bg命令)#SIGTST0P 19 暂停(当按下crtl+z时发送该信号)#killall, 通过命令名终止进程killall -s SIGNAL PNamekillall -信号数 PName#trap, 捕捉并响应信号trap 'signal-handler-func' SIGNAL LIST kill信号详解参考: https://www.imooc.com/article/48534 1234567891011121314$ kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR111) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+338) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+843) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+1348) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-1253) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-758) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-263) SIGRTMAX-1 64) SIGRTMAX Linux信号列表： SIGHUP 1: A 终端挂起或者控制进程终止 SIGINT 2: A 键盘中断（如break键被按下） SIGQUIT 3: C 键盘的退出键被按下 SIGILL 4: C 非法指令 SIGABRT 6: C 由abort(3)发出的退出指令 SIGFPE 8: C 浮点异常 SIGKILL 9: AEF Kill信号 SIGSEGV 11: C 无效的内存引用 SIGPIPE 13: A 管道破裂: 写一个没有读端口的管道 SIGALRM 14: A 由alarm(2)发出的信号 SIGTERM 15: A 终止信号 SIGUSR1 30,10,16: A 用户自定义信号1 SIGUSR2 31,12,17: A 用户自定义信号2 SIGCHLD 20,17,18: B 子进程结束信号 SIGCONT 19,18,25: 进程继续（曾被停止的进程） SIGSTOP 17,19,23: DEF 终止进程 SIGTSTP 18,20,24: D 控制终端（tty）上按下停止键 SIGTTIN 21,21,26: D 后台进程企图从控制终端读 SIGTTOU 22,22,27: D 后台进程企图从控制终端写 处理动作中的字母含义： A: 缺省的动作是终止进程 B: 缺省的动作是忽略此信号，将该信号丢弃，不做处理 C: 缺省的动作是终止进程并进行内核映像转储（dump core），内核映像转储是指将进程数据在内存的映像和进程在内核结构中的部分内容以一定格式转储到文件系统，并且进程退出执行，这样做的好处是为程序员 提供了方便，使得他们可以得到进程当时执行时的数据值，允许他们确定转储的原因，并且可以调试他们的程序。 D: 缺省的动作是停止进程，进入停止状况以后还能重新进行下去，一般是在调试的过程中（例如ptrace系统调用） E: 信号不能被捕获 F: 信号不能被忽略 which, whereis, file, whatis与平均负载which hows the full path of (shell) commands。找出某个命令的位置;whereis locate the binary, source, and manual page files for a command。不仅返回命令路径，还能打印命令手册的位置以及命令源代码路径;file determine file type。用来确定文件类型;whatis display manual page descriptions。输出简短描述信息;平均负载(load average),是系统运行总负载量的一个重要参数。它指明了系统中可运行进程总量的平均值。平均负载由三个值来指定，第一个指明1分钟内的平均值，第二个指明5分钟内的平均值，第三个指明15分钟内的平均值。 单核CPU，类似于单车道，负载在 0.00-1.00 之间正常； 多核CPU，类似于多车道，负载在 核数*(0.00-1.00) 之间正常； 安全的系统负载，单核应该在 0.7 以下； 12345#查看平均负载uptimecat /proc/loadavg#0.00 0.01 0.05 1/355 44955#分母355表示系统进程总数, 分子表示正在运行的进程数, 最后一个数字表示最近运行进程ID 向用户终端发送消息系统管理员可能需要向网络中所有主机上的所有用户或特定用户的终端发送消息。`wallrsync -av –exclude=”*.s命令用来向所有当前登录用户的终端写入消息。 在Linux系统中，终端是作为设备存在的。因此那些打开的终端在dev/pts/中都会与对应的设备节点文件。向特定设备写入数据将会在对应的终端显示出消息。 12345echo "It's just a test" | wall#查看用户对应的/dev/pts/, 并向某一个用户终端发送信息ll /dev/pts | awk '&#123;print $3,$6&#125;'echo"Haha" &gt; /dev/pts/[1,2,3...] 收集系统信息包括主机名、内核版本、Linux发行版本、CPU信息、内存信息、磁盘分区信息等。 123456789101112131415161718192021222324252627#主机名hostnameuname -n#内核版本，架构uname -runame -muname -a#Linux发行版本cat /etc/redhat-release#CPU相关信息lscpucat /proc/cpuinfocat /proc/cpuinfo | grep 'model name'#内存详细信息free -hcat /proc/meminfo#分区信息cat /proc/partitionsfdisk -l#系统详细信息lshw 用/proc收集信息在GNU/Linux操作系统中，/proc是一个位于内存中的伪文件系统(in-memory pseudo filesystem)。它的引用是为了提供一个可以从用户空间(user space)读取系统参数的接口。 可以对/proc中的文件和子目录进行cat来获取信息，所有内容都是易读的格式化文本。 /proc/下的数字目录，包含了对应进程的相关信息；/proc/environ，包含于进程相关联的环境变量；/proc/cwd，是一个到进程工作目录的符号链接；/proc/fbcat，包含了由进程所使用的文件描述符。 用cron进行调度GNU/Linux系统包含了各种用于调度任务的工具。cron就是其中之一，它通过守护进程crond使得任务能够以固定的时间间隔在系统后台自动运行。cron利用的是一个被称为“cron表(cron table)”的文件，这个文件中存储了需要执行的脚本或命令的调度列表以及执行时间。 12345678910111213141516171819202122232425262728#分 时 日 月 周#* * * * * cmd#分钟(0-59)#小时(0-23)#天(1-31)#月(1-12)#工作日(0-7)，0和7都代表周天#命令#*号,所有值#,号,范围。1,3,5,7,9#-号,连续范文。1-10#/号,*/10;0-8/20#栗子crontab -e* 0-6 * * * /home/zhang/test.sh1,3,5,7,9 * * * * /home/zhang/test.sh*/5 * * * * /home/zhang/test.sh#-l,查看cron表crontab -l#-r,移除cron表crontab -r cron的高级写法栗子： 1234567891011121314151617181920@reboot #在启动的时候运行一次#其实@reboot类似于rc.local，开机启动@yearly == @annually == 0 0 1 1 * #一年一次@monthly == 0 0 1 * * #每月一次@weekly == 0 0 * * 0 #每周一次@daily == @midnight == 0 0 * * * #每天一次@hourly == 0 * * * * #每小时一次crontab -e@reboot /bin/mongod -f /etc/mongod_27018.confvim /etc/rc.d/rc.local/bin/mongod -f /etc/mongod_27018.confchmod a+x /etc/rc.d/rc.local 用户管理常用命令123456789101112131415161718192021222324252627282930313233343536#添加用户useradd#删除用户userdel--remove-all-file删除与用户相关的所有文件#修改shellchsh#修改用户属性usermod#修改密码过期时间chage#修改密码passwd#登录到一个新组newgrp#添加、删除组groupaddgroupdel#指纹finger iptables和firewalldfirewalld与iptables比较: iptables与firewalld都不是真正的防火墙，它们都只是用来定义防火墙策略的防火墙管理工具而已。或者说，它们只是一种服务 firewalld可以动态修改单条规则，动态管理规则集，允许更新规则而不破坏现有会话和连接；iptables在修改了规则后必须得全部刷新才可以生效 firewalld使用区域和服务而不是链式规则 firewalld默认是拒绝的，需要设置以后才能放行；iptables默认是允许，需要拒绝的才去限制 firewalld自身并不具备防火墙的功能，而是和iptables一样需要通过内核的netfilter来实现。真正使用规则干活的是内核的netfilter firewalld是iptables的一个封装，可以让你更容易地管理iptables规则。它并不是iptables的替代品 firewalld拥有CLI和GUI的两种管理方式 firewalld区域管理通过将网络划分成不同的区域，制定出不同区域之间的访问控制策略来控制不同程序区域间传送数据流。firewalld的默认区域是public区域。 九大区域： 阻塞区域（block）任何传入的网络数据包都将被阻止 工作区域（work）相信网络上的其他计算机，不会损害你的计算机 家庭区域（home）相信网络上的其他计算机，不会损害你的计算机 公共区域（public）不相信网络上的任何计算机，只有选择接受传入的网络连接 隔离区域（DMZ）隔离区域也称为非军事区域，内外网络之间增加的一层网络，起到缓冲作用。对于隔离区域，只有选择接受传入的网络连接 信任区域（trusted）所有的网络连接都可以接受 丢弃区域（drop）任何传入的网络连接都被拒绝 内部区域（internal）信任网络上的其他计算机，不会损害你的计算机。只有选择接受传入的网络连接 外部区域（external）不相信网络上的其他计算机，不会损害你的计算机。只有选择接受传入的网络连接 firewalld有三种配置方法： firewll-config(GUI) firewall-cmd(CLI) 编辑XML配置文件 firewalld默认提供了九个区域的配置文件，它们位于/usr/lib/firewalld/zones: 123ls /usr/lib/firewalld/zonesblock.xml dmz.xml drop.xml external.xml home.xml internal.xml public.xml trusted.xml work.xml 常用命令: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162yum install firewalld firewall-configsystemctl start firewalldfirewall-cmd --versionfirewall-cmd --help#永久生效需加上 --permannentfirewall-cmd xxx --permannentfirewall-cmd --state#查看网络接口使用的区域firewall-cmd --get-active-zones#查看指定区域的所有配置firewall-cmd --zone=public --list-all#查看所有区域配置firewall-cmd --list-all-zones#查看默认区域firewall-cmd --get-default-zone#设置默认区域firewall-cmd --set-default-zone=internal#查看指定接口所属区域firewall-cmd --get-zone-of-interface=eth0#将接口添加到区域，默认接口都在publicfirewall-cmd --zone=public --add-interface=eth0#拒绝|开启 所有包firewall-cmd --panic-on|off#查看是否拒绝firewall-cmd --query-panic#无需断开连接更新防火墙规则firewall-cmd --reload#类似于重启更新规则firewall-cmd --complete-reload#查看所有打开的端口firewall-cmd --zone=dmz --list-ports#加入一个端口的区域firewall-cmd --zone=dmz --add-port=8080/tcp 与服务一起使用firewalld可以根据特定网络服务的预定义规则来允许相关流量。你可以自定义系统规则，并将它们添加到任何区域。 默认支持的服务的配置文件位置: /usr/lib/firewalld/services 创建的服务文件位置: /etc/firewalld/services 123456789cat /usr/lib/firewalld/service/elasticsearch.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;service&gt; &lt;short&gt;Elasticsearch&lt;/short&gt; &lt;description&gt;Elasticsearch is a distributed, open source search and analytics engine, designed for horizontal scalability, reliability, and easy management.&lt;/description&gt; &lt;port protocol=&quot;tcp&quot; port=&quot;9300&quot;/&gt; &lt;port protocol=&quot;tcp&quot; port=&quot;9200&quot;/&gt;&lt;/service&gt; 常用命令: 1234567891011121314#查看默认可用服务firewall-cmd --get-services#永久启用或禁用HTTP服务firewall-cmd --zone=区域 --(add|remove)-service=http --permanent#添加123456端口的tcp流量firewall-cmd --zone=public --add-port=123456/tcp --permanent#将80端口的流量转发到123456端口firewall-cmd --zone=public --add-forward-port=port=80:proto=tcp:toport=123456 iptablesiptables/ip6tables — administration tool for IPv4/IPv6 packet filtering and NAT 切记谨慎使用iptables命令，特别是在远程连接的时候。规则是有顺序的，规则的顺序很重要。当规则顺序排列错误时，会产生很严重的错误。 12345678910111213141516171819202122232425262728293031iptables --help-t&lt;表&gt;： 指定要操纵的表，默认为filter-P： 设置默认策略-A &lt;链&gt;： 在规则链的末尾中添加条目-I &lt;链&gt;： 在规则链的头部中插入条目#请注意-A与-I，这两者的插入顺序是不一致的，-I顺序更高-D &lt;链&gt;： 从规则链中删除条目-R： 替换规则链中的条目-L： 显示规则链中已有的条目-F： 清楚规则链中已有的条目-Z： 清空规则链中的数据包计算器和字节计数器-X： 删除用户定义的链-N： 创建新的用户自定义规则链-p： 指定要匹配的数据包协议类型(tcp, udp, icmp...)-s： 指定要匹配的数据包源ip地址(ip/mask, !ip)-d： 匹配 目标地址--sport： 匹配源端口号--dport： 匹配目的端口号-i&lt;网络接口&gt;： 指定数据包进入本机的网络接口-o&lt;网络接口&gt;： 指定数据包要离开本机所使用的网络接口-j target： 指定要跳转的目标-m match： 扩展匹配-g chain： jump to chain with no return 表格/链/动作为什么称为iptables? 因为此软件里面有多个表格(table)，每个表格定义了自己的默认策略和规则，且每个表格的用途都不相同。 表(Table) raw: 高级功能 mangle: 数据包修改 nat: 网络地址转换 PREROUTING POSTROUTING OUTPUT filter: 包过滤，是默认表 INPUT OUTPUT FORWARD 链(Chain) INPUT：处理输入数据包 OUTPUT：处理输出数据包 FORWARD：处理转发数据包 PREROUTING：用于目标地址转换(DNAT) POSTOUTING：用于源地址转换(SNAT) 动作(Action) ACCEPT： 接收数据包 DROP： 丢弃数据包 REJECT: 拒绝 REDIRECT： 重定向、映射、透明代理 SNAT： 源地址转换 DNAT： 目标地址转换 MASQUERADE： IP伪装（NAT），用于ADSL LOG： 日志记录 常用命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#格式iptables -t 表名 &lt;-A/I/D/R&gt; 规则链名 [规则号] &lt;-i/o 网卡名&gt; -p 协议名 &lt;-s 源IP/源子网&gt; --sport 源端口 &lt;-d 目标IP/目标子网&gt; --dport 目标端口 -j 动作-A: 新增一条规则，在最后面-I: 插入一条规则，如果没有指定顺序，默认变成第一条规则--line-numbers： 显示规则行号-i: 包所进入的那个网络接口-o: 包所传出的那个网络接口-p: 指定网络协议-p tcp --syn(ack, rst)-p udp-p icmp-p all-s: 源IP或网段-d: 目标IP或网段-s 192.168.1.11-d 192.168.1.0/24(192.168.1.0/255.255.255.0)-s !192.168.2.0/24-j: 后接动作#记录，此日志默认追加到messages-j LOG --log-prefix=‘IPTABLES-’#端口号可以是连续的--sport 1026:65535--dport 80-m: 一些iptables外部模块-m state: 状态模块-m mac: 网卡地址--state: 数据包状态--state INVALID： 无效的数据包--state ESTABLISHED: 已建立连接--state NEW: 想要新建连接的数据包--state RELATED: 表示这个数据包是我们主机发送出去的--mac-source: 源主机的硬件地址 清除防火墙规则: 12345678910111213iptables [ -t tables ] [ -FXZ ]#清除所有已制定的规则iptables -F#清除用户 "自定义"iptables -X#将所有链表的计数与流量统计都归零iptables -Z#这三个命令会将本机防火墙的所有规则都清除，但却不会改变 默认策略 定义默认策略 12345--policy, -Piptables -P INPUT DROPiptables -P OUTPUT ACCESSiptables -P FORWARD ACCEPT 开放某个端口 1234567891011121314151617181920212223#允许本地回环接口(即运行本机访问本机)iptables -A INPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT#允许已建立的或相关连的通行iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT#针对网卡执行的放行和防御iptables -A INPUT -m mac --mac--source aa:bb:cc:11:22:33 -j DROP#允许所有本机向外的访问iptables -A OUTPUT -j ACCEPT#允许访问22端口iptables -A INPUT -p tcp --dport 22 -j ACCEPT#允许访问80端口iptables -A INPUT -p tcp --dport 80 -j ACCEPT# #禁止其他未允许的规则访问iptables -A INPUT -j reject#禁止其他未允许的规则访问iptables -A FORWARD -j REJECT 屏蔽IP 12345#屏蔽单个IP的命令iptables -I INPUT -s 123.45.6.7 -j DROP#封整个段即从123.0.0.1到123.255.255.254的命令iptables -I INPUT -s 123.0.0.0/8 -j DROP 查看规则 12345678910#推荐使用iptables-saveiptables-save#备份和恢复iptables-save &gt;/etc/sysconfig/iptablesiptables-restore &lt;/etc/sysconfig/iptablesiptables -L -niptables -L -n --line-numbers 删除已添加规则 1234iptables -L -n --line-numbersiptables -D INPUT 5iptables -D OUTPUT 3 解决重启失效1234iptables-save &gt;/etc/sysconfig/iptables#把此加入开机启动iptables-restore &lt;/etc/sysconfig/iptables 分屏显示tmux命令 — terminal multiplexer 上下分屏: ctrl+b -&gt; &quot; 左右分屏： ctrl_b -&gt; % 切换屏幕： ctrl+b -&gt; o 关闭终端： ctrl+b -&gt; x 上下屏与左右屏切换： ctrl+b -&gt; 空格 帮助： ctrl+b -&gt; ? 命令模式： ctrl+b -&gt; :]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作与人生]]></title>
    <url>%2F2017%2F09%2F04%2F%E5%B7%A5%E4%BD%9C%E4%B8%8E%E4%BA%BA%E7%94%9F%2F</url>
    <content type="text"><![CDATA[我现在已经活到了人生的中途，拿一日来比喻人的一生，现在正是中午。人在童年时从朦胧中醒来．需要一些时间来克服清晨的软弱，然后就要投入工作；在正午时分，他的精力最为充沛，但已隐隐感到疲惫；到了黄昏时节，就要总结一日的工作，准备沉入永恒的休息。按我这种说法，工作是人一生的主题。这个想法不是人人都能同意的。我知道在中国，农村的人把生儿育女看作是一生的主题。把儿女养大，自己就死掉，给他们空出地方来——这是很流行的想法。在城市里则另有一种想法，但不知是不是很流行：它把取得社会地位看作一生的主题。站在北京八宝山的骨灰墙前，可以体会到这种想法。我在那里看到一位已故的大叔墓上写着：副系主任、支部副书记、副教授、某某教研室副主任，等等。假如能把这些“副”字去掉个把，对这位大叔当然更好一些，但这些“副”字最能证明有这样一种想法。顺便说一句，我到美国的公墓里看过，发现他们的墓碑上只写两件事：一是生卒年月。二是某年至某年服兵役；这就是说，他们以为人的一生只有这两件事值得记述：这位上帝的子民曾经来到尘世，以及这位公民曾去为国尽忠，写别的都是多余的，我觉得这种想法比较质朴……恐怕在一份青年刊物上写这些墓前的景物是太过伤感，还是及早回到正题上来罢。 我想要把自己对人生的看法推荐给青年朋友们：人从工作中可以得到乐趣，这是一种巨大的好处。相比之下，从金钱、权力、生育子女方面可以得到的快乐，总要受到制约。举例来说，现在把生育作为生活的主题，首先是不合时宜；其次，人在生育力方面比兔子大为不如，更不要说和黄花鱼相比较；在这方面很难取得无穷无尽的成就。我对权力没有兴趣，对钱有一些兴趣，但也不愿为它去受罪——做我想做的事(这件事对我来说，就是写小说)，并且把它做好，这就是我的目标。我想，和我志趣相投的人总不会是一个都没有。 根据我的经验，人在年轻时，最头疼的一件事就是决定自己这一生要做什么。在这方面，我倒没有什么具体的建议：干什么都可以，但最好不要写小说，这是和我抢饭碗。当然，假如你执意要写，我也没理由反对。总而言之，干什么都是好的；但要干出个样子来，这才是人的价值和尊严所在。人在工作时，不单要用到手、腿和腰，还要用脑子和自己的心胸。我总觉得国人对这后一方面不够重视，这样就会把工作看成是受罪。失掉了快乐最主要的源泉，对生活的态度也会因之变得灰暗…… 人活在世上，不但有身体，还有头脑和心胸——对此请勿从解剖学上理解。人脑是怎样的一种东西，科学还不能说清楚。心胸是怎么回事就更难说清。对我自己来说，心胸是我在生活中想要达到的最低目标。某件事有悖于我的心胸，我就认为它不值得一做；某个人有悖于我的心胸，我就觉得他不值得一交；某种生活有悖于我的心胸，我就会以为它不值得一过。罗素先生曾言，对人来说，不加检点的生活，确实不值得一过。我同意他的意见：不加检点的生活，属于不能接受的生活之一种。人必须过他可以接受的生活，这恰恰是他改变一切的动力。人有了心胸，就可以用它来改变自己的生活。 中国人喜欢接受这样的想法：只要能活着就是好的，活成什么样子无所谓。从一些电影的名字就可以看出来：《活着》、《找乐》……我对这种想法是断然地不赞成。因为抱有这种想法的人就可能活成任何一种糟糕的样子，从而使生活本身失去意义。高尚、清洁、充满乐趣的生活是好的，人们很容易得到共识。卑下、肮脏、贫乏的生活是不好的，这也能得到共识。但只有这两条远远不够。我以写作为生，我知道某种文章好，也知道某种文章坏。仅知道这两条尚不足以开始写作。还有更加重要的一条，那就是：某种样子的文章对我来说不可取，绝不能让它从我笔下写出来，冠以我的名字登在报刊上。以小喻大，这也是我对生活的态度。]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>王小波</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[告别信]]></title>
    <url>%2F2017%2F09%2F04%2F%E5%91%8A%E5%88%AB%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[1999年，72岁的马尔克斯患上淋巴癌后，写了一封信向读者告别。如果有一刹那，上帝忘记我是一只布偶并赋予我片刻生命，我可能不会说出我心中的一切所想，但我必定会思考我所说的一切。 我会评价事物，按其意义大小而非价值多少。 我会少睡觉，多思考。因为我知道，每当我们闭上一分钟眼睛，我们也就同时失去了60秒。当他人停滞时我会前行，当他人入梦时我会清醒，当他人讲话时我会倾听，就像享受一支美味的巧克力冰激凌！ 如果上帝赏我一段生命，我会简单装束，伏在阳光下，袒露的不仅是身体，还有我的魂灵。 上帝呀，如果我有一颗心，我会将仇恨写在冰上，然后期待太阳的升起；我会用凡高的梦在星星上画一首贝内德第的诗，而塞莱特的歌会是将是我献给月亮的小夜曲。我会用泪水浇灌玫瑰，以此体味花刺的痛苦和花瓣的亲吻…… 上帝呀，如果我有一段生命……我不会放过哪怕是一天，而不对我所爱的人说我爱他们。我会使每个男人和女人都了解他们皆我所爱，我要怀着爱而生活。 对于大人，我会向他们证明，那种认为因衰老而失去爱的想法是多么错误，我们是因为失去爱而衰老而不是与之相反。对于孩子，我会给他们插上翅膀而让他们自己学会飞翔；对于老人，我会教给他们死亡的来临不是因为衰老而是因为遗忘。 人呀，我从你们身上学会了太多的东西… …我知道，人们都想伫立在颠峰上，殊不知，真正的幸福恰恰就在于攀登险阻的过程。我懂得，当婴儿用小拳头第一次抓住爸爸的手指时，他也就永远地抓住了它。 我明白，一个人只有在帮助他人站起时才有权利俯视他。我能够从你们身上学到的东西是如此之多，可事实上已经意义寥寥，因为当人们将我敛入棺木时，我正在死去。 永远说你感到的，做你想到的吧！如果我知道今天是我最后一次看你入睡，我会热烈地拥抱你，祈求上帝守护你的灵魂。如果我知道这是最后一次看你离开家门，我会给你一个拥抱一个吻，然后重新叫住你，再度拥抱亲吻。如果我知道这是最后一次听到你的声音，我会录下你的每个字句，以便可以一遍又一遍永无穷尽地倾听。如果我知道这是看到你的最后几分钟，我会说”我爱你”，而不是傻傻地以为你早已知道。 永远有一个明天，生活给我们另一个机会将事情做好，可是如果我搞错了，今天就是我们所剩的全部，我会对你说我多么爱你，我永远不会忘记你。 明天从不向任何人作保证，无论青年或老人，今天可能就是你最后一次看到你所爱的人。因此，别再等待了，今天就开始！因为如果明天永远不来，你也许会遗憾今天没来得及微笑，拥抱，亲吻，会遗憾自己忙碌得只能把它们归为一个最后的愿望。保护周围你爱的人吧，告诉他们你多么需要他们。爱他们，善待他们，用些时间对他们说：”对不起”，”原谅我”，”劳驾”，”谢谢”，以及你知道的所有爱的话语。 没有人会因为你秘而不宣的思想而记住你。向上帝祈求力量和智慧来表达它们吧，向你的朋友证明，他们对你来说是多么的重要。]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>马尔克斯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown]]></title>
    <url>%2F2017%2F09%2F01%2FMarkdown%2F</url>
    <content type="text"><![CDATA[参考: Markdown-wiki Markdown官网 Markdown中文文档 Markdown语法 果冻虾仁 关于Markdown 是一种轻量级标记语言。它允许人们使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML(或者HTML)文档。 语法 首行缩进12345678#一个空格&amp;ensp;#两个空格&amp;emsp;#不断行空白格&amp;nbsp; 栗子： &ensp;一个空格； &emsp;两个空格； &nbsp;不断行空白格； 段落与换行 段落的前后必须是空行 空行是指行内什么都没有，或者只有空白符（空格或制表符） 相邻两行文本，如果中间没有空行，会显示在一行中（换行符被转换为空格） 如果需要在段内加入换行 可以在前一行的末尾加入至少两个空格，然后换行写其它的文字 Markdown中的多数区块都需要在两个空行之间 粗体和斜体语法： 1234*斜体*, _斜体_**粗体*****粗斜体***~~删除线~~ 显示效果： 斜体, 斜体 粗体 粗斜体 删除线 分级标题Setext形式大标题： 123456一级大标题========二级大标题-------- atx形式普通标题： 12345# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题 超链接MarkDown支持两种形式的链接语法：行内式和参考式。 行内式语法说明：[ ] 里面写链接文字，( ) 里面写链接地址，()中的” “可以指定title属性。 代码： 欢迎来到 [简书](www.jianshu.com &quot;Jianshu&quot;) 效果： 欢迎来到 简书 参考式参考式超链接一般用在学术论文上面，或某一个链接在文章中多处使用，那么引用的方式创建链接将非常好，它可以让你对链接进行统一的管理。 语法说明： 123参考式链接分为两部分，文中的写法[链接文字][链接标记]，在文本任意位置添加[链接标记]:链接地址 “链接标题”，链接地址与链接标题前有一个空格如果链接文字本身可以作为链接标记，也可以写成[链接文字][][链接文字]：链接地址的形式 代码： 123456简书里面有 [简书早报][1]、[简书晚报][2]以及 [简黛玉][3][简黛玉 美人][3] 是一个[才女][][1]:http://www.jianshu.com &quot;Jianshu&quot;[2]:http://www.jianshu.com &quot;EveningPaper&quot;[3]:http://www.jianshu.com[才女]:http://www.jianshu.com 效果： 简书里面有 简书早报、简书晚报以及简黛玉简黛玉 美人 是一个才女 自动链接MarkDown支持以比较简短的自动链接形式来处理网址和电子邮件，只要用&lt;&gt;包起来，MarkDown就会自动把它转成链接。 代码： 12&lt;http://example.com&gt;&lt;address@example.com&gt; 锚点MarkDown Extra只支持在标题后插入锚点，其他地方无效。锚点中的标题如果有空格，则锚点无效。现在的锚点支持中文标题。 代码： 12345678910锚点连接页内标题[标题一](#Title1)[标题二](#Title2)[标题三](#标题3)# Title1## Title2### 标题3 列表无序列表使用 * ，+ ，- 表示无序列表 代码： 123- 无序列表1- 无序列表2- 无序列表3 效果： 无序列表1 无序列表2 无序列表3 有序列表有序列表使用数字接着英文点 代码： 1231. 有序列表12. 有序列表23. 有序列表3 效果： 有序列表1 有序列表2 有序列表3 定义型列表定义型列表由名词和解释组成。一行写上定义，紧跟一行写上解释。解释的写法：紧跟一个缩进（Tab） 列表缩进列表项目标记通常是放在最左边，但是其实也可以缩进，最多3个空格，项目标记后则一定要接着至少一个空格或制表符。 代码： 123* 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。* 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 效果： 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 引用引用需要在被引用的文本前加上&gt;符号 代码： 12&gt; 引用1&gt; 引用2 效果： 引用1引用2 引用的多层嵌套区块引用可以嵌套（如引用的引用），只要根据层次加上不同数量的 &gt;符号 代码： 123&gt;&gt;&gt; 请问MarkDown怎么用？&gt;&gt; 自己看教程！&gt; 教程在哪里？ 效果： 请问MarkDown怎么用？ 自己看教程！ 教程在哪里？ 插入图像图片的创建方式与超链接类似。 代码： ![](http://zhangxx5678.lofter.com/post/39b969_df4f526#) 内容目录在段落中填写 [TOC] 以显示全文内容结构目录 注脚在需要添加注脚的文字后加上注脚名字 [^注脚名字]，称为加注。然后在文中的任意位置（一般最后）添加脚注，脚注前必须有对应的脚注名字。注脚与注脚间必须空一行！注脚自动被搬运到最后面，请到文章末尾查看，并且脚注后的链接可以直接跳转会到加注的地方 代码： 123使用 MarkDown[^1]可以提高书写效率，直接转换成 HTML[^2][^1]:MarkDown是一种纯文本标记语言[^2]:HTML超文本标记语言 效果： 使用 MarkDown^1可以提高书写效率，直接转换成 HTML^2 分割线可以在一行中用 三个以上的 *,-,_ 建立一个分割线，行内不能有其他东西。 代码： 12345671. * * *2.3. ***4.5. - - -6.7. --- 效果： GitHub中的表情Github的Markdown语法支持添加emoji表情，输入不同的符号码（两个冒号包围的字符）可以显示出不同的表情。 比如:blush:,显示效果为 :blush: 每个表情对应的符号码：https://www.webpagefx.com/tools/emoji-cheat-sheet/ 或者，果冻虾仁的整理：https://github.com/guodongxiaren/README/blob/master/emoji.md Diff语法版本控制系统中都少不了diff功能——展示一个文件内容的增加与删除。 绿色(+)表示新增 红色(-)表示删除 语法效果与代码高亮类似，在三个反引号后面写上diff。在内容中+表示新增，-表示删除。 123456+ 111+ 11+ 1- 222- 22- 2 扩展语法Markdown标准 本身所包含的功能有限，所以产生了许多第三方扩展语法，如 GFW, GitHub Flavored Markdown Tasklist代码： 12345- [ ] Monday- [ ] Tuesday- [ ] Wednesday- [ ] Tuesday- [ ] Friday 效果： Monday Tuesday Wednesday Tuesday Friday 表格 不管是哪种方式，第一行为表头，第二行为分割表头和主体部分，第三行开始每一行为一个表格行 列与列之间用管道符号 | 隔开 还可设置对齐方式 左对齐 :| 右对齐 |: 中对齐 :|: 代码： 12345学号 | 姓名 | 分数- | - | -001 | 张三 | 78002 | 李四 | 67003 | 王五 | 99 学号 姓名 分数 001 张三 78 002 李四 67 003 王五 99 GitHub上的表格GitHub上的表格与上有一点不同。 12345| 学号 | 姓名 | 分数| - | - | -| 001 | 张三 | 78| 002 | 李四 | 67| 003 | 王五 | 99 学号 姓名 分数 001 张三 78 002 李四 67 003 王五 99 代码块和高亮代码块插入代码的方式有两种，一种是利用缩进(Tab)，另一种是利用反引号 `` 和 ``` ``` 代码： 1Python语言的输出函数 `Print()` 怎么使用？ 效果： Python语言的输出函数 Print() 怎么使用？ 123import osfrom flask import Flaskapp = Flask(app) 高亮在 ``` 之后添加代码的语言 代码： ```pythonimport osfrom flask import Flaskapp = Flask(app)``` 效果： 123import osfrom flask import Flaskapp = Flask(app) 流程图flow chart/flow diagram，需要安装额外的插件才能支持流程图。 流程图语法参考: https://mermaidjs.github.io/Hexo Plugins: https://hexo.io/plugins/ hexo默认好像不支持流程图，需要在hexo Plugins去查找此类插件，安装此类插件，然后修改hexo配置文件。具体的使用方法请参考插件说明。 数学公式参考: https://blog.csdn.net/lanxuezaipiao/article/details/44341645 https://juejin.im/post/5a6721bd518825733201c4a2 LaTex数学符号表 LaTEX: https://zh.wikipedia.org/wiki/LaTeX是一种跨平台的基于TEX的排版系统，对于生成复杂表格和数学公式，这一点表现得尤为突出。因此它非常适用于生成高印刷质量的科技和数学、化学类文档。 MathJax: https://en.wikipedia.org/wiki/MathJaxMathJax是一种跨浏览器JavaScript库，它使用MathML，LaTeX和ASCIIMathML 标记在Web浏览器中显示数学符号。MathJax作为Apache License下的开源软件。 MathJax语法: https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference 公式许多扩展的Markdown编辑器支持基于Mathjax编写的数学公式。 LaTeX有两种数学公式： 行内式与其它文字混杂。这是一个$行内式$栗子 块级公式单独成行。$$块级公式$$ 栗子： 12345678这是一个$E=mc^2$公式$$\sum_&#123;i=1&#125;^n a_i=0$$$$f(x_1,x_x,\ldots,x_n) = x_1^2 + x_2^2 + \cdots + x_n^2 $$$$\sum^&#123;j-1&#125;_&#123;k=0&#125;&#123;\widehat&#123;\gamma&#125;_&#123;kj&#125; z_k&#125;$$ 基本类型 上/下标 分式 根式 求和 积分 矩阵 数组 空格 省略号 矢量 括号 希腊字母 上下标 上标(superscript): ^ 下标(subscript): _ 如果上小标内容大于一个字符，要用{}虽然空格和顺序对公式没有影响，但建议使用统一的风格，不用混用： 先下标后上标 先上标后下标 12345678910111213141516171819#上标$$E=mc^2$$#下标$$x_2$$#上下标$$x_&#123;subscript&#125; ^&#123;superscript&#125;$$#左右上下标$$&#123;&#125;_&#123;a&#125; ^&#123;b&#125; x ^&#123;c&#125; _&#123;d&#125;$$$$&#123;&#125;_&#123;左下&#125; ^&#123;左上&#125; x ^&#123;右上&#125; _&#123;右下&#125;$$#空格和顺序其实没影响` 分式分式(fraction)为了区分frac是函数不是公式，使用\frac进行转义 1234567#用法$$\frac&#123;分子&#125;&#123;分母&#125;$$$$\frac&#123;x+y&#125; &#123;2&#125;$$$$\frac&#123;1&#125; &#123;1+\frac&#123;1&#125; &#123;2&#125;&#125; 根式开方(sqrt)使用\sqrt转义 123456789#默认为开平方$$\sqrt[开方次数]&#123;开方因子&#125;$$$$\sqrt &#123;x&#125;$$$$\sqrt[3] &#123;\frac&#123;x&#125; &#123;y&#125;&#125;$$$$\sqrt[x] &#123;1+\sqrt[y] &#123;1+a^2&#125;&#125;$$ 求和求和(summation)使用\sum转义 1234567#用法$$\sum_&#123;起点&#125;^&#123;终点&#125;表达式$$$$\sum_&#123;i=0&#125; ^&#123;n&#125; \frac&#123;1&#125; &#123;k&#125;$$$$\sum_&#123;i=0&#125;^&#123;n&#125; i^2=\frac&#123;(n^2+n)(2n+1)&#125; &#123;6&#125;$$ 积分积分(integral)使用\int转义 12345#用法$$\int_&#123;下限&#125;^&#123;上限&#125; 被积函数d被积量$$$$\int_&#123;a&#125;^&#123;b&#125; f(x)dx$$ 矩阵矩阵(matrix) 1234567891011121314151617181920212223242526#&amp;区分行间元素#\\\\代表换行#无括号矩阵$$\begin&#123;matrix&#125;1 &amp; 2 \\\\ 3 &amp; 4 \end&#123;matrix&#125;$$#花括号矩阵$$\begin&#123;pmatrix&#125; 1&amp;2 \\\ 3&amp;4 \end&#123;pmatrix&#125;$$#中括号矩阵$$\begin&#123;bmatrix&#125; 1&amp;2 \\\\ 3&amp;4 \end&#123;bmatrix&#125;$$#大括号矩阵$$\begin&#123;Bmatrix&#125; 1&amp;2 \\\\ 3&amp;4 \end&#123;Bmatrix&#125;$$#竖线矩阵$$\begin&#123;vmatrix&#125; 1&amp;2 \\\\ 3&amp;4 \end&#123;vmatrix&#125;$$#双竖线矩阵$$\begin&#123;Vmatrix&#125; 1&amp;2 \\\\ 3&amp;4 \end&#123;Vmatrix&#125;$$ 数组数组(array) 空格空格(space/blank) 12345678910111213141516171819202122232425#紧贴$$a\!b$$#正常$$ab$$#小空格$$a\,b$$#中空格$$a\;b$$#大空格$$a\ b$$#quad空格$$a\quad b$$#两个quad空格$$a\qquad b$$ 省略号省略号(ellipsis) \ldots与文本底线对齐的省略号 cdots与文本中线对齐的省略号 1234#\ldot, \cdot可表示单个点，对齐方式不变$$f(x_1,x_2,\ldots,x_n) = x_1^2 + x_2^2 + \cdots + x_n^2$$ 矢量矢量(vector) 1234567#用法$$\vec&#123;矢量值&#125;$$$$\vec&#123;a&#125;$$$$\vec&#123;a&#125; \cdot \vec&#123;b&#125;=0$$ 括号括号(bracket) (), [], |可以直接表示，而{}本来是用于分组，因此需要转义\{\}来表示，也可使用\lbrace, \rbrace来表示。 原始括号并不会随着公式大小缩放，需要使用\left和\right标记实现自适应调整，它两必须成对出现。 12345678910111213141516171819202122232425262728293031323334#小括号()$$(\frac&#123;1&#125;&#123;2&#125;)$$$$\left( \frac&#123;1&#125;&#123;2&#125; \right)$$#中括号[]$$[\frac&#123;1&#125;&#123;2&#125;]$$$$\left[ \frac&#123;1&#125;&#123;2&#125; \right]$$#绝对值|$$|\frac&#123;1&#125;&#123;2&#125;|$$$$\left| \frac&#123;1&#125;&#123;2&#125; \right|$$#大括号&#123;&#125;$$\&#123; \frac&#123;1&#125;&#123;2&#125; \&#125;$$$$\left\&#123; \frac&#123;1&#125;&#123;2&#125; \right\&#125;$$#尖括号&lt;&gt;#\langle \rangle$$\langle \frac&#123;1&#125;&#123;2&#125; \rangle$$$$\left\langle \frac&#123;1&#125;&#123;2&#125; \right\rangle$$#向正无穷大取整(ceil)$$\lceil \frac&#123;1&#125;&#123;2&#125; \rceil$$$$\left\lceil \frac&#123;1&#125;&#123;2&#125; \right\rceil$$#向下取整$$\lfloor \frac&#123;1&#125;&#123;2&#125; \rfloor$$$$\left\lfloor \frac&#123;1&#125;&#123;2&#125; \right\rfloor$$ 希腊字母 大写 LaTex代码 小写 LaTex代码 中文名称 A A α \alpha 阿尔法 B B β \beta 贝塔 Γ Γ γ \gamma 伽马 D D δ \delta 德尔塔 E E ϵ \epsilon 伊普西隆 Z Z ζ \zeta 泽塔 H H η \eta 伊塔 Θ Θ θ \theta 西塔 I I ι \iota 约塔 K K κ \kappa 卡帕 Λ Λ λ \lambda 兰姆达 M M μ \mu 缪 N N ν \nu 纽 X X ξ \xi 克西 O O ο \omicron 欧米克隆 P P π \pi 派 R R ρ \rho 柔 Σ Σ σ \sigma 西格玛 T T τ \tau 陶 Υ Υ υ \upsilon 宇普西隆 Φ Φ ϕ \phi 弗爱 X X χ \chi 卡 Ψ Ψ ψ \psi 普赛 Ω Ω ω \omega 欧米伽 1234567$$\alpha$$$$\beta$$$$\gamma$$$$\delta$$ 特殊符号 关系运算符 集合运算符 对数运算符 三角运算符 微积分运算符 逻辑运算符 带帽符号 连线符号 箭头符号 关系运算符12345678910111213141516171819±：\pm ×：\times ÷：\div ∣：\mid ∤：\nmid ⋅⋅：\cdot ∘：\circ ∗：\ast ⨀：\bigodot ⨂：\bigotimes ⨁：\bigoplus ≤：\leq ≥：\geq ≠：\neq ≈：\approx ≡：\equiv ∑：\sum ∏：\prod ∐：\coprod 集合运算符12345678910111213∅ ：\emptyset ∈：\in ∉：\notin ⊂：\subset ⊃：\supset ⊆：\subseteq ⊇：\supseteq ⊇：\bigcap ⋃：\bigcup ⋁：\bigvee ⋀：\bigwedge ⨄：\biguplus ⨆：\bigsqcup 对数运算符123log：\log lg：\lg ln：\ln 三角运算符123456789⊥ ：\bot ∠：\angle 30∘：30^\circ sin：\sin cos：\cos tan：\tan cot：\cot sec：\sec csc：\csc 微积分运算符123456789′：\prime ∫：\int ∬：\iint ∭：\iiint ∬∬：\iiiint ∮：\oint lim：\lim ∞：\infty ∇：\nabla 逻辑运算符1234567∵ ：\because ∴：\therefore ∀：\forall ∃：\exists ≠：\not= ≯：\not&gt; ⊄：\not\subset 戴帽符号123y^ ：\hat&#123;y&#125; yˇ：\check&#123;y&#125; y˘：\breve&#123;y&#125; 箭头符号123456789101112↑ ：\uparrow ↓：\downarrow ⇑：\Uparrow ⇓：\Downarrow →：\rightarrow ←：\leftarrow ⇒：\Rightarrow ⇐：\Leftarrow ⟶：\longrightarrow ⟵：\longleftarrow ⟹：\Longrightarrow ⟸：\Longleftarrow 生成GitHub上的徽章生成徽章: http://shields.io/生成进度： https://github.com/fehmicansaglam/progressed.io 进入徽章(Badge)网站，找到如下部分生成徽章。之后会得到一个徽章地址，在GitHub中插入此徽章地址就好。 进入进度(Progress)网站，找到某个格式的链接，在GitHub中插入此链接。 编辑器介绍一些常用的书写、编辑Markdown的工具。 MarkdownPad Windows (windows); Texts (Windows, osX); MarkPad (Windows); Haroopad (Windows, osX, Linux); ReText (Linux); 等等 格式转换Markdown文档可以方便地转换为 HTML, Word, PDF 等文件格式。可以利用 软件 或者 命令 转换文件。 转换为 HTML 转换为 PDF 转换为 Word]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx]]></title>
    <url>%2F2017%2F09%2F01%2FNginx%2F</url>
    <content type="text"><![CDATA[参考： Nginx官方文档 Nginx-Wikipedia Nginx-repo 环境： CentOS7x86_64; Nginx1.12.1 Nginx介绍Nginx（发音同engine x）是一个 Web服务器，也可以用作反向代理，负载平衡器和 HTTP缓存。它能反向代理 HTTP, HTTPS, SMTP, POP3, IMAP 的协议连接。基于BSD-like协议发行，支持多种操作系统。 作为HTTP服务软件的后起之秀，Nginx有很多优点： 在性能上，Nginx占用的系统资源更少，支持更多的并发连接（特别是小静态文件场景下），达到更高的访问效率； 在功能上，Nginx不仅是一个优秀的Web服务软件，还可以作为反向代理 负载均衡及缓存使用。它类似于LVS负载均衡及HAProxy等专业代理软件，又类似于Squid等专业缓存服务软件； 在安装配置上，Nginx方便、简单、灵活。 Nginx功能丰富，可作为HTTP服务器、反向代理服务器、邮件服务器。支持FastCGI, SSL, Virtual Host, URL Rewrite, Gzip等功能，并支持很多第三方模块扩展。 与PHP的集成自PHP-5.3.3起，PHP-FPM加入到了PHP核心，编译时加上–enable-fpm即可提供支持。PHP-FPM以守护进程在后台运行，Nginx响应请求后，自行处理静态请求，PHP请求则经过fastcgi_pass交由PHP-FPM处理，处理完毕后返回。Nginx和PHP-FPM的组合，是一种稳定、高效的PHP运行方式，效率要比传统的Apache和mod_php高出不少。 Nginx的重要特性： 可针对静态资源高速高并发访问及缓存；可使用反向代理加速，并且可进行数据缓存；具有简单负载均衡、节点健康检查和容错功能；支持远程FastCGI、Uwsgi、SCGI、Memcached Servers的加速和缓存；支持SSL、TLS、SNI；具有模块化的架构：过滤器包括gzip压缩、ranges支持、chunked响应、XSLT、SSI及图像缩放等功能。在SSI过滤器中，一个包含多个SSI的页面，如果FastCGI或反向代理处理，可被并行处理；它具备的其他WWW服务特性：支持基于名字、端口及IP的多虚拟主机站点；支持Keep-alived和pipelined连接；可进行修改Nginx配置，并且在代码上线时，可平滑重启，不中断业务访问；可自定义访问日志格式，临时缓冲些日志操作，快速日志轮询及通过rsyslog处理日志；可利用信号控制Nginx进程；支持 3xx-5xx HTTP状态码重定向；支持rewrite模块，支持URI重写及正则表达式匹配；支持基于客户端IP地址和HTTP基本认证的访问控制；支持PUT、DELETE、MKCOL、COPY及MOVE等较特殊的HTTP请求方法；支持FLV流和MP4流技术产品应用；支持HTTP响应速率限制；支持同一IP地址的并发连接或请求数连接；支持邮件服务器代理； Nginx常用功能http代理于反向代理Nginx在做反向代理时，提供性能稳定，并且能够提供配置灵活的转发功能。Nginx可以根据不同的正则匹配，采取不同的转发策略，比如图片文件结尾的走文件服务器，动态页面走web服务器，只要你正则写的没问题，又有相对应的服务器解决方案，你就可以随心所欲的玩。并且Nginx对返回结果进行错误页跳转，异常判断等。如果被分发的服务器存在异常，他可以将请求重新转发给另外一台服务器，然后自动去除异常服务器。 负载均衡Nginx提供的负载均衡策略有2种：内置策略和扩展策略。内置策略为轮询，加权轮询，Ip hash。扩展策略，就天马行空，只有你想不到的没有他做不到的啦，你可以参照所有的负载均衡算法，给他一一找出来做下实现。 web缓存Nginx可以对不同的文件做不同的缓存处理，配置灵活，并且支持FastCGI_Cache，主要用于对FastCGI的动态程序进行缓存。配合着第三方的ngx_cache_purge，对制定的URL缓存内容可以的进行增删管理。 web服务Nginx作为Web服务器的主要应用场景包括： 使用Nginx运行HTML、JS、CSS、小图片等静态数据； 结合FastCGI运行PHP等动态程序（如fastcgi_pass）； 结合Tomcat/Resin等支持Java动态程序（如proxy_pass）。 Nginx安装RPM源安装:12345678yum install -y gcc gcc-c++ make libtool zlib zlib-devel openssl openssl-devel pcre pcre-devel 安装依赖rpm -ivm http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm 安装RPM源#安装Nginxyum install -y nginx#查询安装rpm -q nginx 添加Nginx yum repository安装12345678910vim /etc/yum.repos.d/nginx.repo#必须唯一[nginx]name=nginx-repobaseurl=http://nginx.org/packages/$OS/$OSRELEASE/$basearch/gpgcheck=0enabled=1 源码安装12345678910#建议解压于此目录cd /usr/local/srcwget http://xxx.xx.com/nginx.tar.gztar -zxvf nginx.tar.gzcd ./nginx./configure --prefix=/usr/localmake&amp;&amp;make install Nginx配置*.confNginx配置文件主要分为四部分： main(全局设置)； server(主机设置)； upstream(上游服务器设置)，用于反向代理和负载均衡； location(URL匹配特定位置)。 栗子：运行nginx -t检查配置文件有误错误，这很重要! 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#main块user nginx;worker_processes 4;client_max_body_size 10Merror_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 102400;&#125;#http块http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - ...'; access_log /var/log/nginx/access.log main; sendfile on; gzip on; keepalive_timeout 60; include /etc/nginx/conf.d/*.conf; #upstream块 upstream up_name&#123; server ip1; server ip2:port; server domain; &#125; server &#123; server_name www.zhang21.cn; listen 80; listen 443; ssl on; ssl_certificate /dir/path/xxx.crt; ssl_certificate_key /dir/path/xxx.key; location / &#123; root /var/www/zhang; index index.php index.html index.htm; allow 192.168.1.0/22; deny all; &#125; location ~ \.php$ &#123; root /var/www/zhang; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; &#125; &#125;&#125; 全局块：配置影响Nginx全局的指令。一般由运行Nginx服务器的用户组，Nginx进程pid存放路径，日志存放路径，允许生成的worker_processes等。 events块：配置影响Nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网络连接，开启多个网络连接序列化等。 http块：可以嵌套多个server，配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，链接超时时间，单连接请求数等。 server块：配置虚拟主机的相关参数，一个http中可以有多个server。 location块：配置请求的路由，以及各种页面的处理情况。 Nginx http功能模块 模块说明 ngx_http_core_module 一些核心的http参数配置，对应Nginx的配置中的http块 ngx_http_access_module 访问控制模块，用来控制网站用户对Nginx的访问 ngx_http_gzip_module 压缩模块，对Nginx返回的数据压缩，属于性能优化模块 ngx_http_fastcgi_module FastCGI模块，和动态应用相关的模块，如PHP ngx_http_proxy_module proxy代理模块 ngx_http_upstream_module 负载均衡模块，可实现网站的负载均衡及节点的监控检查 ngx_http_rewrite_module URL重写模块 ngx_http_limit_conn_module 限制用户并发连接数及请求数模块 ngx_http_limit_req_module 根据定义的key限制Nginx请求过程的速率 ngx_http_log_module 访问日志模块，以指定的格式记录Nginx访问信息 ngx_http_auth_basic_module web认证模块，设置通过账号，密码访问Nginx ngx_http_ssl_module ssl模块 ngx_http_stub_status_module 记录Nginx基本访问状态信息扥的模块 Nginx的日志时自动切割，并且一行可以记录多个日志格式。 Nginx日志格式 说明 $remote_addr 客户端ip地址 $http_x_forward_for 当前端有代理服务器时，设置web节点记录web节点记录客户端地址的配置 $remote_user 客户端用户名称 $time_local 访问时间和时区 $request 请求的http协议和URL $status 请求状态，如200 $body_bytes_sent 发送给客户端文件主体内容大小 $http_referer 从哪个页面链接访问过来 $http_user_agent 客户端浏览器信息 serverhttp服务上支持若干虚拟主机。每个虚拟主机对应一个server配置项，配置项里面包含该虚拟主机的相关配置。每个server里面可同时有多个server_name。 在提供mail代理服务时，也可建立若干server，每个server通过监听地址或端口来区分。 12345#监听端口，默认80listen 80;listern 443;#listen 88server_name www.zhang21.cn locationlocation是http服务中，某些特定的URL对应的一系列配置项。 root 定义此location的根目录位置，一般放置在server里 index 定义路径下的默认访问的文件名 12345location / &#123; root /dir/path; index index.html index.htm;&#125; location的正则写法location的使用方法： 符号 含义 优先级 用法 = 精确匹配 最高 location = ~ 区分大小写的正则匹配 次次之 location ~ ~* 不区分大小写的正则匹配 次次之 location ~* ^~ 常规字符串匹配 次之 location ^~ / 通用匹配 最低 location / 优先级： = &gt; 完整路径 &gt; ^~ &gt; ~, ~* &gt; 部分路径 &gt; / location使用建议location的使用根据实际情况来定。 但个人觉得至少应该有三个匹配规则： 直接匹配网站跟，通过域名访问网站首页比较频繁 处理静态文件请求，这是Nginx作为http服务器的强项 通用规则，用来转发动态请求到后端的应用服务器(符php-fpm) 根据实际情况的自定义需求 1234567891011121314151617181920212223242526272829303132333435363738394041server &#123; listen 80; listen 443; server_name zhang21.cn www.zhang21.cn; root /dir/path/zhang; ssl on; ssl_certificate /etc/nginx/ssl/zhang.crt; ssl_certificate_key /etc/nginx/ssl/zhang.key; #rewtire ^(.*)$ https://zhang21.cn/$1 permanent; return 301 https://zhang21.cn/$requets_uri location = / &#123; rewrite .*? /index.html last; &#125; location ^~ /static/ &#123; root /dir/path/zhang/static; &#125; location ~* \.(gif|jpg|png|css|js)$ &#123; root /dir/path/zhang/static; &#125; location / &#123; if (!-f $request_filename) &#123; rewrite ^([^\?]+)$ /index.php?q=$1 last; &#125; location ~ \.php$ &#123; root /dir/path; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; &#125;&#125; RewriteNginx的主要功能是实现URL地址重写。Nginx的rewrite规则需要PCRE软件的支持，即通过Perl兼容正则表达式语法进行规则匹配。 Nginx rewrite语法： 123server, location, ifrewrite regex replacement [flag] rewrite的功能就是，使用Nginx提供的全局变量或自定义变量，结合正则表达式(re)和标志位实现URL重写以及重定向 rewrite只能放在server，location，if中，并且只能对域名后边的除去传递的参数外的字符串起作用 如果相对域名或参数字符串起作用，可以使用全局变量匹配，也可使用proxy_pass反向代理 表面看rewrite和location功能有点像，都能实现跳转。主要区别在于： rewrite实在同一域名内更改获取资源的路径 location是对一类路径做访问控制或反向代理，可proxy_pass到其它机器 循环超多10次，返回500 Internal Server Error! flag last 表示完成rewrite，继续向下匹配新的规则 break 停止执行当前虚拟主机的后续rewrite指令集 redirect 返回302临时重定向，地址栏会显示跳转后的地址 permanent 返回301永久重定向，地址栏会显示跳转后的地址 last和break用来实现URL重写，浏览器地址栏的URL地址不变，但在服务器端访问的程序及路径发生了变化 redirect和permanent用来实现URL跳转，浏览器地址栏会显示跳转后的URL地址 Nginx的rewrite功能应用非常广泛： 可调整用户浏览的URL，使其看起来更规范 将动态URL地址伪装成静态地址提供服务 让旧域名跳转到新域名上 根据特殊变量、目录、客户端的信息进行URL跳转 if指令if语法： 123if (condition) &#123; xxx;&#125; if的条件可以是如下内容： 当表达式只是一个变量时，如果值为空或任何以0开头的字符串都会被当作false 直接比较变量和内容时，使用=或!= ~正则表达式匹配，~*不区分大小写的正则匹配，!~不匹配 -f和!-f，用来判断是否存在文件 -d和!-d，用来判断是否存在目录 -e和!-e，用来判断时都存在文件或目录 -x和!-x，用来判断文件是否可执行 栗子： 123456789101112131415161718192021222324if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break;&#125;if ($http_cookie ~* "id=([^;])(?:;|$)") &#123; set $id $1;&#125;if ($http_method = POST) &#123; return 405;&#125;if (!-f $request_filename) &#123; break; proxy_pass http://zhang;&#125;if ($invalid_referer) &#123; return 403;&#125; Nginx全局变量常用作if判断的全局变量： 变量 描述 备注 $args 等于请求行中的参数 同$query_string $body_bytes_sent 响应是发送的body字节数 xxx $content_length Request Header中的Content-Length字段 内容长度 $content_type Request Header中的Content-Type字段 内容类型 $document_root 当前根路径 xxx $host 请求主机头字段，否则为服务器名称 xxx $hostname 主机名 xxx $http_user_agent 客户端agent信息 xxx $http_cookie 客户端cookie信息 xxx $is_args 如果有$args参数，这个变量等于”?”，否则等于空 xxx $limit_rate 限制连接数度 xxx $remote_addr 客户端IP地址 xxx $remote_port 客户端端口 xxx $remote_user 经过Auth Basic Module验证的用户名 要先开启Nginx认证 $request 用户请求信息 xxx $request_method 客户端请求方法 通常为POST或GET $request_body 记录POST过来的数据信息 xxx $request_filename 当前请求的文件路径 由root或alias指令与URI请求生成 $request_completion 如果请求结束，设置为OK。否则为空 xxx $scheme HTTP方法 如http, https $server_protocol 请求使用的协议 通常为HTTP/1.0或HTTP/1.1 $server_addr 服务器地址 在完成一次系统调用后可以确定这个值 $server_name 服务器名称 xxx $server_port 请求到达服务器的端口号 xxx $status 请求的响应状态码 如200 $request_uri 包含请求参数的原始URI，不包含主机名 如”/foo/bar.php?arg=abc” $uri 不带请求参数的当前URI，不包含主机名 如”/foo/bar.html” 栗子： 12345678http://localhost:88/test1/test2/test.php$hsot: localhost$server_port: 88$request_uri: http://localhost:88/test1/test2/test.php$document_uri: /test1/test2/test.php$document_root: /var/www/test$request_filename: /var/www/test/test1/test2/test.php rewrite实例12345678910111213141516171819202122232425http &#123; log_format main xxxx; rewrite_log on; server &#123; root /var/www/zhang; location / &#123; error_log logs/rewrite.log notice; rewrite '^/images/([a-z]&#123;2&#125;)/([a-z0-9]&#123;5&#125;)/(.*)\.(png|jpg|gif)'/data?file=$3.$4; set $image_file $3; set $image_type $4; &#125; location /data &#123; access_log logs/images.log main; root /data/images; type_file /$arg_file /images404.html; &#125; location = /image404.html &#123; return 404 "Image Not Found\n"; &#125; &#125;&#125; 访问控制 添加用户密码验证有时需要为我们的网站设置访问账号和密码权限。 具体为这两个参数： auth_basic 默认值： auth_basic off; 使用位置：http, server, location, limit_except auth_basic_user_file 使用位置： http, server, location, limit_except 栗子： 12345678910111213141516cd /etc/nginx/conf.dvim test.conflocation / &#123; auth_basic "Zhang"; auth_basic_user_file /etc/nginx/nginx.auth;&#125;vim /etc/nginx/nginx.auth#user:passwdzhang:zhangtest:test 限制IP访问 allow deny 1234567891011server &#123; ... allow IP1 allow IP2; deny all; location / &#123; allow IP 1; deny all; &#125;&#125; 注意： deny一定要加一个IP，否则会直接跳转403，不在往下执行。如果403默认页是在同一域名下，会造成死循环访问 对于allow的IP短，从允许访问的IP段位从小到大排列，如127.0.0.0/24， 10.10.0.0/16 以deny all结尾，表示除了上面允许的，其它都禁止 语法检查在启动或重启Nginx服务前检查语法非常重要，可以防止因配置错误导致网站重启或重载配置对用户的影响。 每次更改Nginx配置文件后都需要重新加载，将配置信息加载到内存中。这样设计的目的是大幅度提升Nginx的访问性。 123nginx -tnginx -s reload Nginx优化 常用优化 隐藏Nginx版本号一般来说，软件漏洞都和版本有关。因此要尽量隐藏对访问用户显示各类敏感信息。 123456789vim /etc/nginc/nginx.conf#nginx版本号默认是开启的#位置：http, server, locationhttp &#123; server_tokens off|on;&#125; 更改Nginx服务默认用户 修改配置文件 123vim /etc/nginx/nginx.confuser nginx; 如果是编译安装，直接在编译的时候指定用户和组 1./configure --user=nginx --group=nginx 优化Nginx进程对应的配置123456789101112vim /etc/nginx/nginx.confworker_process n;#建议n为CPU核数#高并发场合可考虑为核数*2#查看CPU核数cat /proc/cpuinfo | grep processor | wc -llscputop命令，按1显示所有CPU核数 优化绑定不同的Nginx进程到不同的CPU上默认情况下，Nginx的多个进程有可能跑在某一个CPU或CPU的某一核上，导致Nginx进程使用硬件资源不均。所以，要尽可能地分配不同的Nginx进程给不同的CPU处理，达到充分有效利用硬件的多CPU多核资源的目的。 4核CPU配置举例： 12345vim /etc/nginx/nginx.confworker_processes 4;#CPU亲和力参数worker_cpu_affinity 0001 0010 0100 1000; Nginx事件处理模型优化Nginx的连接处理机制在不同的操作系统会采用不同的I/O模型，在Linux下，Nginx使用epoll的I/O多路复用模型，在FreeBSD中使用kqueue的I/O多路复用模型，在solaris中使用/dev/poll方式的I/O多路复用模型，在Windows中使用的是icop。 配置： 12345678#对于linux内核，推荐使用epoll工作模式#Linux下默认epollvim /etc/nginx/nginx.confevents &#123; use epoll;&#125; Nginx单个进程允许的客户端最大连接数请根据服务器性能和程序的内存使用量来合理制定最大连接数。这个连接数包括了所有连接，如代理服务器连接、客户端的连接、实际的并发连接。 Nginx总并发连接数=worker*worker_connections 123456vim /etc/nginx/nginx.confevents &#123; worker_connections 10240;&#125; 仅仅修改了nginx最大连接数可能还不行，由于Linux系统有ulimit限制，所以可能还要做额外操作。 如：nginx: [warn] 10240 worker_connections exceed open file resource limit: 1024。 配置： 123ulimit -aulimit -n 10240 注意，使用ulimit命令修改的值并不是永久生效的。 Nginx worker进程最大打开文件数可能也要注意ulimit系统限制！ 12345vim /etc/nginx/nginx.confevents &#123; worker_rlimit_nofile 65535;&#125; 开启高效文件传输sendfilesendfile()是作用于两个文件描述符之间的数据拷贝，这个拷贝是在内核之中的，被称为零拷贝。sendfile（）比read和write函数要高效很多，因为write和read函数要把数据拷贝到应用层再进行操作。 12#位置：http, server, location, if in locationsendfile on; tcp_nopush激活或禁用Linux上的TCP_CORK socket选项，仅当开启sendfile生效。允许把 http response和文件的开始部分放在一个文件里发布，其积极作用是减少网络报文段的数量。 12位置： http, server, locationtcp_nopush on; Nginx连接参数，连接超时时间keep-alive可以使客户端到服务器端已经建立的连接一致工作不退出，当服务器有持续请求时，keep-alive会使用已经建立的连接提供服务，从而避免服务器重新建立新连接请求处理。 连接超时的作用： 将无用的连接设置为尽快超时，可保护系统资源（CPU、内存、磁盘）连接很多时，及时断掉那些已经建立好但又长时间不做事的连接，以减少其占用的服务器资源。因为服务器维护连接也是消耗资源的黑客和恶意用户攻击网站，也会不断地和服务器建立多个连接，消耗连接数但啥也不干，大量消耗服务器的资源，此时就应该及时断掉这些恶意占用资源的连接LNMP环境中，如果用户请求了动态服务，则Nginx就会建立连接，请求FastCGI服务以及后端的MySQL服务，此时这个Nginx连接就要设置一个超时时间，在用户容忍的时间内返回数据，或者再多等一会后端服务返回数据，具体策略根据具体业务进行具体分析后端的FastCGI服务及MySQL服务也有对连接的超时控制 12位置： http, server, locationkeepalive_timeout 60; 默认情况下当数据发送时，内核并不会马上发送，可能会等待更多的字节组成一个数据包，这样可以提高I/O性能。但是，在每次只发送很少字节的业务场景中，不使用tcp_nodelay功能，等待时间会比较长。 12位置： http, server, locationtcp_nodelay on; 读取客户端请求头数据的超时时间，如果超过这个时间，客户端还没有发送完整的header数据，服务器端将返回“Request time out（408）”错误。 12位置： http, serverclient_header_timeout 20; 读取客户端请求主体的超时时间，如果在这个超时时间内，客户端没有发送任何数据，Nginx将返回“Request time out（408）”错误。 12位置： http, server, locationclient_body_timeout 60; 指定响应客户端的超时时间，为握手后的一个超时。如果超过这个时间，客户端没有任何活动，Nginx将会关闭连接。 12位置： http, server, locationsend_timeout 60; 上传文件大小限制(动态应用)设置为0，表示禁止检查客户端请求主体的大小。 12位置： http, server, locationclient_max_body_size 20m; gzip压缩Nginx gzip压缩模块提供了压缩文件内容的功能，用户请求的内容在发送到用户客户端之前，Nginx服务器会根据一些具体的策略实施压缩，以节约网络出口带宽，同时加快数据传输效率，提升用户体验。 压缩对象： 纯文本内容压缩比很高，如 html, js, css, xml等 被压缩的纯文本文件必须要大于1KB，由于压缩算法的特殊原因，极小的文件压缩后可能反而变大 图片、媒体等文件尽量不要压缩，因为这些文件大都经过压缩，再压缩很可能不会减小很多，或有可能增大，同时还要消耗系统资源 配置： 1234567891011121314151617181920212223242526#压缩功能gzip on;#允许压缩的页面最小字节数gzip_min_length 1K;#申请4个单位为16K的内存作为压缩结果流缓存gzip_buffers 4 16K;#http协议版本gzip_http_version 1.1;#指定压缩比，1压缩比最小，处理速度最快；9压缩比最大，传输速度最快，处理最慢gzip_comp_level 5;#指定压缩类型，对应文件类型参考mime.typesgzip_types text/html text/css;#vary header支持gzip_vary on; 在response header中查看效果： Content-Encofing: gzip expires缓存Nginx expires的功能就是为用户访问的网站内容设定一个过期时间。 当用户第一次访问这些内容时，会把这些内容储存在用户浏览器本地，这样用户第二次及以后继续访问该网站时，浏览器会检查加载已经缓存在用户浏览器本地的内容，而不用去服务器下载，直到缓存的内容过期或被清除为止。 缓存也要根据业务！当网站数据更新时，用户端看到的可能还是旧的已经缓存的内容。 配置： 根据文件扩展名进行判断 12345678location ~ .*\.(gif|png|jpg|swf)$ &#123; expires 10d;&#125;location ~ .*\.(css|js)$ &#123; expires 20d;&#125; 根据目录进行判断 123location ~ ^/(images|static|media)/ &#123; expires 50d;&#125; 在response header中查看： Expires: 缓存过期时间Cache-Control： 缓存总时间 FastCGI相关参数FastCGI参数是配合Nginx向后请求PHP动态引擎服务的相关参数，这里指的是Nginx中的配置参数。 Module ngx_http_fastcgi_module： https://nginx.org/en/docs/http/ngx_http_fastcgi_module.html 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#给FastCGI服务器设置地址fastcgi_pass#设置一个将在 $fastcgi_scripts_name 变量结尾的URI之后添加的文件名fastcgi_index#设置一个应该传递给FastCGI服务器的参数，当且仅当fastcgi_param在当前级别上没有定义指令时，这些指令将从上一级继承fastcgi_param#指定在哪种情况下将请求传递给下一个服务器；fastcgi_next_upsteam#表示Nginx服务器和后端FastCGI服务器连接的超时时间，默认值为60秒，这个参数通常不要超过75秒fastcgi_connect_timeout#设置Nginx允许FastCGI服务器端返回数据的超时时间，即在规定时间之内后端服务器必须传完所有的数据。否则，Nginx将断开这个连接fastcgi_send_timeout#设置Nginx从FastCGI服务器端读取响应信息的超时时间，表示连接建立成功后，Nginx等待后端服务器的响应时间，是Nginx已经进入后端的排队之中等候处理的时间fastcgi_read_timeout#这是Nginx FastCGI的缓冲区大小参数，设定用来读取从FastCGI服务器端收到的第一部分响应信息的缓冲区大小，这里的第一部分通常会包含一个小的响应头部fastcgi_buffer_size#设定用来读取从FastCGI服务器端收到的响应信息的缓冲区大小和缓冲区数量fastcgi_buffers#用于设置系统很忙时可以使用的proxy_buffers大小，官方推荐大小为proxy_buffers * 2proxy_busy_buffers_size #用于设置系统很忙时可以使用的fastcgi_buffers大小，官方推荐为 fastcgi_buffers * 2fastcgi_busy_buffers_size#FastCGI临时文件大小fastcgi_temp_file_write_size#表示开启FastCGI缓存并为其指定一个名称fastcgi_cache cachename_nginx#fastcgi_cache缓存目录fastcgi_cache_path#用来指定应答代码的缓存时间fastcgi_cache_valid#设置请求几次之后响应将被缓存fastcgi_cache_min_uses#定义在哪些情况下使用过期缓存fastcgi_cache_use_stale#定义fastcgi_cache的keyfastcgi_cache_key 日志与安全现在Nginx 日志已经自动轮询了，所以感觉没有必要自己切割日志！ 不记录不需要的日志日志写入太频繁会消耗大量的磁盘I/O，降低服务性能。 123location ~ .*\.(js|png|css|gif|jpg) &#123; access_log off;&#125; 日志权限因为nginx master process的UID是root，所以可以修改日志权限。不需要在日志目录上给Nginx用户读或写许可，很多人没注意这个问题，把权限直接给了Nginx用户，这就存在安全隐患。 12chown -R root:root /path/log/nginxchmod -R 700 /path/log/nginx 站点目录及URL访问控制根据扩展名限制程序或文件访问利用Nginx配置禁止访问上传资源目录下的PHP、Shell、Perl、Python程序文件，这样用户即使上传了木马文件也没法执行，从而加强了网站的安全。 对这些的限制必须放在Nginx处理.php, .py, .sh等文件的前面！ 1234567891011121314151617#禁止解析指定目录下的程序location ~ ^/images/.*\.(php|py|sh|pl)$ &#123; deny all;&#125;location ~ ^/static/.*\.(py|php|pl|sh) &#123; deny all;&#125;#禁止访问某些文件location ~* \.(txt|doc)$ &#123; root /var/www/file; deny all;&#125; 禁止访问指定目录123456789101112131415location ~ ^/test/ &#123; deny all;&#125;#禁止访问多个目录location ~ ^/(test|zhang) &#123; deny all;&#125;#返回状态码location ~ ^/haha/ &#123; return 403 "Hahaha";&#125; 禁止非法域名解析访问网站防止用户恶意域名解析。 1234567891011121314151617181920cd /etc/nginx/conf.dvim default.conf#返回HTTP状态码server &#123; listen 80 default_server; server_name _; return 403;&#125;#重定向server &#123; listen 80 default_server; server_name _; rewrite ^(.*) https://www.baidu.com permanent;&#125; 利用default_server，将网站所有请求定向到维护页面。 1234567891011121314151617181920212223242526272829303132333435server &#123; listen 80 default_server; server_name _; root /var/www; location / &#123; rewrite ^(.*) /maintance.html break; &#125;&#125;cd /var/wwwvim maintance.html&lt;html&gt;&lt;head&gt;&lt;meta charset="UTF-8"&gt;&lt;style type="text/css"&gt; h1&#123;text-align: center; color: red;&#125;&lt;/style&gt;&lt;/head&gt;&lt;br&gt;&lt;br&gt;&lt;body&gt;&lt;h1&gt;网站维护中！&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 图片及目录防盗链 什么是资源盗链简单地说，就是某些不法网站未经许可，通过在其自身网站程序里非法调用其他网站的资源，然后在自己的网站上显示这些调用的资源，达到填充自身网站的效果。 这一举动不仅浪费了调用资源网站的网络流量，还造成其他网站的带宽及服务压力吃紧。 问题： 某公司CDN源站流量没有变化，但CDN加速那边流量超了很多。这么大异常流量，全都是钱呀！ 常见防盗链解决方案 根据HTTP referer 实现防盗链在HTTP 协议中，有一个表头字段叫 referer，使用URL格式来表示是哪里的链接用了当前网页的资源。 通过referer可以检测访问的来源网页，如果是资源文件，可以跟踪到显示它的网页地址，一旦检测出来不是本站，马上进行阻止。 HTTP referer 是header的一部分，当浏览器向web服务器发送请求时，一般会带上referer，告诉服务器我是从哪个页面过来的，服务器借此获得一些信息用于处理。 根据cookie防盗链通过加密技术变换访问路径实现防盗链 Nginx实现防盗链利用referer，针对指定扩展名进行rewrite或其他操作。 请根据实际情况进行域名防盗链！ 123456location ~* \.(jpg|png|gif|wav|mp3|zip|rar)$ &#123; valid_referers none blocked *.zhang.com; if ($invalid_regerer) &#123; rewrite https://www.baidu.com; &#125;&#125; 或者在产品设计上解决防盗链，如为资源加上水印等措施。 错误页面优雅展示我们可以将404、403等错误信息重定向到其他指定的页面，提升网站的用户访问体验！ 123456789101112location / &#123; xxxx; error_page 403 /403.html; error_page 404 /404.jpg; error_page 500 503 504 /50x.html; location = /50x.html &#123; root /var/www/50x.html; &#125;&#125; 目录及文件权限优化为了保证网站安全，所有站点的目录和用户组都为root，所有目录权限是755，所有文件权限是644。虽然这样的全线可以防止黑客上传修改站点的文件，但这样合法的用户便也没有了上传权限。 比较好的方法是将用户上传文件的服务器与读取服务器进行分离，这样就可以进行安全授权。不同的服务所在的目录的权限依据业务功能而不同。 严格控制Nginx目录的访问才能降低网站被入侵的风险！ 反爬虫优化 robots.txt机器人协议robots协议(维基百科)，也称为机器人协议，全称是网络爬虫排除标准（Robots Exclusion Protocol）。网站通过Robots协议告诉搜索引擎那些页面可以抓取，那些页面不能抓取。 robots.txt协议并不是一个规范，而只是约定俗成的，所以并不能保证网站的隐私。 123User-Agent: *Allow: /zhangDisallow: / Nginx反爬虫配置123456789if ($http_user_agent ~* LWP::Simple|BBBike|wget) &#123; return 403;&#125;if （$http_user_agent ~* (Firefox|MSIE) &#123;rewrite ^（.*） http://www.baidu.com:&#125; 限制HTTP请求方法123if ( $request_method !~ ^(GET|POST|HEAD)$ ) &#123; return 501;&#125; CDNCDN的全称是 Content Delivery Network，中文意思是内容分发网络。我们可以利用CDN做网站内容加速。 简单地讲，通过现有的Internet中增加一层新的网络架构，将网站的内容发布到最接近用户的Cache服务器内，通过智能DNS负载均衡技术，判断用户的来源，让用户就近使用与服务器相同线路的带宽访问Cache服务器，取得所需的内容。 例如，北京电信用户访问北京电信Cache服务器上的内容，四川网通用户访问成都网通Cache服务器上的内容。这样可以有效减少数据在网络上传输的时间，提高访问速度。CDN是一套全国或全球的风不是缓存集群，其实质是通过职能DNS判断用户的来源地域及上网线路，为用户选择一个最接近用户地域，以及和用户上网线路相同的服务器节点。因为低于近，线路相同，所以可以大幅度提升用户浏览网站的体验。 CDN的价值： 提升用户体验 阻挡大部分流量攻击 CDN的特点： 通过服务器内存缓存网站数据，提高了企业站点（尤其是含有大量图片、视频等的站点）的访问速度，并大大提高企业站点的稳定性； 用户根据智能DNS技术自动选择最适合的Cache服务器，降低不同运营商之间互联瓶颈造成的影响，实现了跨运营商的网络加速，保证不同网络中的用户都能得到良好的访问速度； 加快了访问速度，减少了原站点的带宽； 用户访问时从服务器的内存中读取数据，分担了网络流量，同时减轻了原站点负载压力； 使用CDN可以分担源站的网络流量，同时减轻源站的负载压力，并降低黑客入侵及各种DDOS攻击对网站的影响，保证网站有较好的服务质量； 使用CDN的要求首先要说的是，不是所有的网站都可以一上来就能用CDN的。要加速的业务数据应该存在独立的域名。如 pub.zhang21.com，业务内容图片、附件、JS、CSS等静态元素，这样的静态网站域名才能使用CDN。 将域名做CNAME(别名)将如上的pub.zhang21.com配置成CDN的域名。 程序架构优化解耦 是开发人员中流行的一个名词，简单地说就是把一堆程序代码按照业务用途分开，然后提供服务。 例如，注册登录、上传、下载、浏览、商品页信息等都应该是独立的程序服务，只不过在客户端看来是一个整体而已。 分离的最佳方式是分别使用独立的服务器，可以选择改动程序或者在负载均衡器上配置（如Nginx），过滤请求，然后抛给后面对应的服务器。 根据扩展名分发，请求图片就抛给图片服务器； 根据URL路径转发，请求下载就交给下载服务器； 请求动态PHP处理的就交给动态处理器； 不符合以上要求的就交给默认服务器； 使用no-root用户启动Nginx默认情况下，Nginx的Master进程使用的是root用户，worker进程使用的是Nginx指定的普通用户。 使用root用户跑Nginx的Master进程有两个最大问题： 管理权限必须是root，这就使得最小化分配权限原则遇到困难 使用root跑Nginx服务，一旦网站出现漏洞，用户就可以很容易地获取服务器的root权限 控制Nginx并发连接数ngx_http_limit_conn_module这个模块用于限制每个定义的Key值的连接数，特别是单IP的连接数。 不是所有的连接数都会被计数，一个符合要求的连接是整个请求头已经被读取的连接。 用法： 1234567#位置： httplimit_conn_zone key zone=name:size;#位置： http, server, locationlimit_conn zone number; 栗子： 123456789101112http &#123; limit_conn_zone $binary_remote_addr zone=addr:10m; xxx;&#125;server &#123; xxx; location /download/ &#123; limit_conn addr 3; #限制单IP并发连接为3 &#125;&#125; 控制客户端请求Nginx的速率ngx_http_limit_req_module被用来限制每个IP访问没法key的请求速率。 用法： 1234567#位置： httplimit_req_zone key zone=name:size rate=rate;#位置： http, server, locationlimit_req zone=name; 栗子： 123456789http &#123;limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; server &#123; location /search/ &#123; limit_req zone=one burst=5; &#125; &#125;&#125; upstream模块 反向代理与负载均衡严格地说，Nginx仅仅是作为Nginx Proxy反向代理使用的，因为这个反向代理功能表现的效果是负载均衡集群的效果，所以本文称之为Nginx负载均衡。 普通的负载均衡软件，如LVS，其实现的功能只是对请求数据包的转发、传递，从负载均衡下的节点服务器来看，接收到的请求还是来自访问负载均衡器的客户端的真实用户 反向代理服务器在接收访问用户请求后，会代理用户 重新发起请求代理下的节点服务器，最后把数据返回给客户端用户。在节点服务器看来，访问的节点服务器的客户端用户就是反向代理服务器，而非真实的网站访问用户 即，LVS等负载均衡是转发用户请求的数据包，而Nginx反向代理是接收用户请求后重新发起请求后端节点 这里我去看了一下Nginx的access.log，客户端的访问日志全在代理节点上（Nginx-upstream），而后端节点的access.log的来源是前端代理节点的IP Nginx负载均衡的组件实现Nginx负载均衡的组件主要有两个: proyx upstream Nginx_http模块 模块说明 ngx_http_proxy_module proxy代理模块，用于把请求后抛给服务器节点或upstream服务器池 ngx_http_upstream_module 负载均衡模块，可以实现网站的负载均衡功能即节点的健康检查 nginx upstream模块 upstream模块介绍Module ngx_http_upstream_module: https://nginx.org/en/docs/http/ngx_http_upstream_module.html upstream主要是用于七层上的负载均衡和转发。 123Syntax： upstream name &#123; ... &#125;Default: —Context: http Nginx的负载均衡功能依赖于ngx_http_upstream_module模。所支持的代理方式包括： proxy_pass fastcgi_pass memcached_pass uwsgi_pass scgi_pass upstream模块允许Nginx定义一组或多组节点服务器组，使用时可通过proxy_pass代理方式把网站的请求发送到事先定义好的对应upstream组的名字上。 upstream模块内容放置于http{}内: 12345678910111213141516171819202122232425262728293031323334upstream upstream_name &#123; server address [ parameters ]&#125;####栗子http &#123; upstream zhang &#123; server 192.168.1.22:8080 weight=5; server www.zhang.cn weigh=5 max_conns=102400; server 192.168.33 max_fails=2 fail_timeout=20s; server backup.zhang.cn backup; &#125;&#125;server &#123; location / &#123; proxy_pass http://zhang; &#125;&#125;####reslovehttp &#123; resolver 10.0.0.1; upstream u &#123; zone ...; ... server example.com resolve; &#125;&#125; address可以是主机名、域名、ip或Unix Socket，也可以指定端口号 域名时需要解析的哦 parameters代表可选参数, 有如下： backup，表示当前server是备用服务器，只有其它非backup后端服务器都挂掉了或很忙才会分配请求给它 max_conns，限制同时连接到代理服务器的最大数量。默认值为0，表示没有限制。 weight，表示当前server负载权重，权重越大几率愈高 max_fails和fail_timeout一般会关联使用，如果某台server在fail_timeout时间内出现了max_fails次连接失败，那么Nginx会认为其已经挂掉，从而在 fail_timeout 时间内不再去请求它，fail_timeout默认是 10s，max_fails默认是1，即默认情况只要是发生错误就认为服务器挂了，如果将max_fails设置为0，则表示取消这项检查 down，标志服务器永远不可用，可配合ip_hash使用 resolve，监视与服务器域名相对应的ip地址的变化，并自动地修改上游配置，而不用重启Nginx route，设置服务器路由名称 service slow_start，设置服务器将其weight从零恢复到正常值的时间 drain，使服务器进入drain模式，在此模式下，只有绑定到服务器的请求才会被代理 upstream模块参数 说明 weight 服务器权重 max_fails Nginx尝试连接后端主机失败的次数，这个值是配合proxy_next_upstream、fastcgi_next_upstream和memcached_next_upstream这三个参数来使用的。当Nginx接收后端服务器返回这三个参数定义的状态码时，会将这个请求转发给正常工作的的后端服务器。如404、503、503、max_files=1 fail_timeout max_fails和fail_timeout一般会关联使用，如果某台server在fail_timeout时间内出现了max_fails次连接失败，那么Nginx会认为其已经挂掉，从而在fail_timeout时间内不再去请求它，fail_timeout默认是10s，max_fails默认是1，即默认情况只要是发生错误就认为服务器挂了，如果将max_fails设置为0，则表示取消这项检查 backup 表示当前server是备用服务器，只有其它非backup后端服务器都挂掉了或很忙才会分配请求给它 down 标志服务器永远不可用，可配合ip_hash使用 如果是两台Web服务器做高可用，可能就需要Keepalived配合。那使用backup参数通过负载均衡功能就可以实现Web服务器集群了。 upstream模块调度算法调度算法一般分为： 静态调度算法: 即负载均衡器根据自身设置的规则进行分配，不需要考虑后端节点服务器的情况 轮询 权重 ip_hash 动态调度算法: 即负载均衡器会根据后端节点的当前状态来决定是否分发请求，如连接数少或响应时间短的优先获得请求 fair least_conn url_hash 一致性hash 轮询(rr)默认调度算法。按照客户端请求顺序把请求逐一分配到不同的后端节点服务器，相当于LVS中的rr算法。如果后端服务器宕机，宕机的服务器会被自动从节点服务器池中剔除，以使客户端的用户访问不受影响，新的请求分配给正常的服务器。 权重轮询(wrr)权重越大，被转发的请求也就越多。可以根据服务器的配置和性能指定权重大小，有效解决新旧服务器性能不均带来的请求分配问题。 1234upstream weight &#123; server 191.168.1.11 weight=1; server 192.168.1.22 weight=2;&#125; ip_hash每个请求按客户端IP的hash结果分配，当新的请求到达时，先将其客户端ip通过哈希算法得出一个值，在随后的客户端请求中，客户IP的哈希值只要相同，就会被分配到同一台服务器。 该调度算法可以解决动态网页的session共享问题，但有时会导致请求分配不均，因为国内大多数都是NAT上网模式，多个客户端对应一个外部IP，所以这些客户端都会被分配到同一个节点服务器，从而导致请求分配不均。 ip_hash中，后端服务器在负载均衡调度中的状态不能有 weight和backup，有也不会生效 12345upstream iphash &#123; ip_hash; server 192.168.1.11; server 192.168.1.22:8080;&#125; fair根据后端节点服务器的响应时间来分配请求，响应时间短的优先分配。这是更加智能的调度算法。 Nginx本身不支持这种算法，需要upstream_fair模块: https://github.com/gnosek/nginx-upstream-fair 12345upstream fair &#123; server 192.168.1.11; server 192.168.1.22; fair;&#125; least_conn根据后端节点的连接数来决定分配情况，哪个机器少就分发给它。 url_hash根据访问URL的hash结果来分配请求的，让每个URL定向到同一个后端服务器，后端服务器为缓存服务器时效果显著。 Nginx本身不支持url_hash，需要hash。 1234567upstream urlhash &#123; server hahaha1:5678; server hahaha2:5678; hash $request_uri; hash_method md5; #同样不能使用 weight、backup&#125; 一致性hash一致性hash算法一般用于代理后端业务为缓存服务器（如Memcached）的场景，通过将用户请求的URI或者指定字符串进行计算，然后调度到后端的服务器上，此后任何用户查找同一个URI货值指定字符串都会被调度到这一台服务器上，因此后端的每个节点缓存的内容都是不同的。 12345upstream &#123; consistent_hash $request_uri; server xxx; server xxx;&#125; nginx proxy模块 proxy_pass介绍123Syntax: proxy_pass URL;Default: —Context: location, if in location, limit_except proxy_pass指令属于ngx_http_proxy_module模块，此模块可以将请求转发到另一台服务器，在实际的反向代理工作中，会通过location功能匹配指定的URI，然后把接收到服务匹配URI的请求通过proyx_pass抛给定义好的upstream节点池。 12345678910location /download/ &#123; proxy_pass http://download/vedio/;&#125;#这是前端代理节点的设置#交给后端upstream为download的节点location /name/ &#123; rewrite /name/([^/]+) /users?name=$1 break; proyx_pass http://127.0.0.1;&#125; http_proyx模块参数ngx_http_proxy_module: https://nginx.org/en/docs/http/ngx_http_proxy_module.html Nginx的代理功能是通过http_proxy模块来实现的。 proxy模块 说明 proxy_next_upstream 什么情况下将请求传递到下一个upstream proxy_limite_rate 限制从后端服务器读取响应的速率 proyx_set_header 设置http请求header传给后端服务器节点，如：可实现让代理后端的服务器节点获取访问客户端的这是ip client_body_buffer_size 客户端请求主体缓冲区大小 proxy_connect_timeout 代理与后端节点服务器连接的超时时间 proxy_send_timeout 后端节点数据回传的超时时间 proxy_read_timeout 设置Nginx从代理的后端服务器获取信息的时间，表示连接成功建立后，Nginx等待后端服务器的响应时间 proxy_buffer_size 设置缓冲区大小 proxy_buffers 设置缓冲区的数量和大小 proyx_busy_buffers_size 用于设置系统很忙时可以使用的proxy_buffers大小，推荐为proxy_buffers*2 proxy_temp_file_write_size 指定proxy缓存临时文件的大小 Nginx负载均衡配置 配置后端节点12345678910vi /etc/nginx/nginx.confserver &#123; listen 80; root /path/xxx; location / &#123; xxxx; &#125;&#125; 配置反向代理节点12345upstream test &#123; server test1 weight=5; server test2 weight=5; server 192.168.1.33;&#125; 1234567891011121314151617181920vi /etc/nginx/nginx.confserver &#123; listen 8888; server_name www.test.com www.xx.com; location / &#123; proxy_read_timeout 10s; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_404; proyx_pass http://test;#把用户的请求反向代理定义的upstream服务器池 #proyx_set_header Host $host;在代理后端服务器发送的http请求头中加入host字段信息 #proxy_set_header X-Real-IP $remote_addr;后端节点服务器日志获取客户端真实ip，否则全都是代理节点的ip #proyx_connect_timeout 30s; #proxy_buffers 4m; #xxx&#125; xxxxx&#125; 与反向代理配置相关的参数除了具有多虚拟主机代理以及节点服务器记录真实用户ip的功能外，Nginx还提供了相当多的作为反向代理和后端节点服务器对话的相关控制参数。 由于参数众多，建议把这些参数都写到另外一个配置文件里，然后用 include 方式包含到虚拟主机配置文件里。其他Nginx参数也同样可以使用此方法。 12345678910111213vim /etc/nginx/proxy.confproxy_set_header Host $host;proxy_set_header $remote_addr;proxy_connect_timeout 60s;proxy_read_timeout 20s;proxy_send_timeout 20s;proxy_buffer_size 64k;proxy_buffers 4 64k;proxy_busy_buffers_size 128k;proxy_temp_file_write_size 2m;proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_404 12345678910vim /etc/nginx/conf.d/test.confserver &#123; listen 80; server_name www.test.com www.xxx.com; location / &#123; include /etc/nginx/proxy.conf; &#125;&#125; proxy_next_upstream参数补充当Nginx接收后端服务器发返回的proxy_next_upstream参数定义的状态码时，会将这个请求转发给正常工作的后端服务器，如500、502、503，此参数可以提升用户访问体验。 1proyx_next_upstream error timeout invalid_header http_500 http_503 http_502 http_504; 根据URL中的目录地址实现代理转发通过Nginx实现动静分离，即通过Nginx反向代理配置规则实现让动态资源和静态资源及其他业务分别由不同的服务器解析，已解决网站性能、安全、用户体验等重要问题。 动静态分离配置upstream.conf 123456789101112131415161718upstream static &#123; server 192.168.1.11; #或server static.com----hosts:static.com 192.168.1.11&#125;upstream upload &#123; server 192.168.1.22;&#125;upstream default &#123; server 192.168.1.33;&#125;#在http中加入,注意位置http &#123; include upstream.conf;&#125; 配置virtual.conf 12345678910111213141516171819202122232425262728293031323334353637#方案1：利用location实现location /static/ &#123; proyx_pass http://static; include proyx.conf;&#125;location /upload/ &#123; proxy_pass http://upload; include proxy.conf;&#125;location / &#123; proxy_pass http://default; include proxy.conf;&#125;========================================#方案2：利用if语句实现if ($request_uri ~* "^/static/(.*)$")&#123; proxy_pass http://static/$1;&#125;if ($request_uri ~* "^/upload/(.*)$")&#123; proxy_pass http://upload/$1;&#125;location / &#123; proxy_pass http://default; include proyx.conf;&#125; URL目录地址转发的应用场景根据HTTP的URL进行转发的应用情况，被称为 第7层（应用层）的负载均衡；而LVS的负载均衡一般用于TCP等的转发，因此被称为第四层（传输层）的负载均衡 。 有时因为需求，需要在代理服务器上通过配置规则，使得匹配不同规则的请求会交给不同的服务器池处理。 根据客户端的设备(user_agent)转发为了让不同客户端设备用户有更好的访问体验，需要在后端架设不同服务器来满足不同的客户端访问。如PC端和移动端，移动端又有安卓、苹果、Pad等。 常规4层负载均衡解决方案架构 在常规4层负载均衡架构下，可以使用不同的域名来实现这个需求。 如，分配移动端访问 wap.xxx.com，PC端访问www.xxx.com。 通过不同域名来引导用户到指定后端服务器，但是这样就分别得记住不同的域名。 第7层负载均衡解决方案 在7层负载均衡架构下，对外只需要用一个域名，如www.xxx.com，然后通过获取用户请求中的设备信息$http_user_agent，根据此信息转给后端合适的服务器处理。 根据$user_agent转发 123456789101112location / &#123; if ($http_user_agent ~* "android") &#123; proxy_pass http://android; &#125;if ($http_user_agent ~* "iphone") &#123; proxy_pass http://iphone; &#125;proxy_pass http://default;include proyx.conf; 根据文件扩展名实现代理转发 1234567891011121314location ~* .*\.(gif|jpg|png|css|js)$ &#123; proyx_pass http://static; include proxy.conf;&#125;#ifif ($request_uri ~* ".*\.php$") &#123; proxy_pass http://php; &#125;if ($request_uri ~* ".*\.(jpg|png|css|js)$") &#123; proxy_pass http://static; &#125; 在开发无法通过程序实现动静分离的时候，运维可以根据资源实体进行动静分离，根据不同实现策略制定后端服务器不同的组。在前端代理服务器上通过路径、扩展名等进行规则匹配，从而实现请求的动态分离。 Nginx负载均衡检测节点状态淘宝技术团队开发了一个Tengine（Nginx分支）模块nginx_upstream_check_module: https://github.com/yaoweibin/nginx_upstream_check_module，用于提供主动式后端服务器健康检查。通过它检测后端realserver的健康状态，如果后端节点不可用，则所有的请求就不会转发到该节点上。 Nginx需要通过打补丁的方式将该模块添加进去。 123456789101112131415161718192021222324252627282930wget https://codeload.github.com/yaoweibin/nginx_upstream_check_module/zip/masterunzip mastercd nginx_upstream_check_module-master #解压后的文件夹cd nginx源码安装包（我是 /usr/local/nginx-1.12.1）patch -p1 &lt; ../nginx_upstream_check_module-master/check_1.12.1+.patch #选择对应的Nginx版本号，我的是1.12.1 #打补丁#编译，注意以前的编译参数./configure --prefix=/usr/local/nginx \--user=nginx --group=nginx \--with-http_ssl_module \--with-http_realip_module \--with-http_addition_module \--with-http_gzip_static_module \--with-http_stub_status_module \--with-http_sub_module \--with-pcre \--add-module=../nginx_upstream_check_module-mastermake#给已经安装的Nginx系统打补丁不用执行make install#make是重新生成Nginx二进制启动命令#备份mv /usr/local/nginx/sbin/nginx&#123;,.bak&#125;#经打过补丁的Nginx二进制程序复制到/usr/local/nginx/sbin/ 下cp /usr/local/nginx-1.12.1/objs/nginx /usr/local/nginx/sbin/nginx -t 配置nginx_upstream_check 配置upstream.conf 12345678upstream zhang &#123; server 192.168.1.7:5678 weight=1; server 192.168.0.99:5678 weight=1; check interval=3000 rise=2 fall=5 timeout=1000 type=http; #每个3秒对负载均衡中所有节点检测一次，请求2次正常标记realserver状态为up； #如果检测5次都失败，则标记realserver状态为down，超时时间为1秒； #检查的协议为HTTP；&#125; 配置/status： 123456location /status &#123; check_status; access_log off; allow 192.168.1.0/24; deny all;&#125; stream模块Module ngx_stream_core_module: http://nginx.org/en/docs/stream/ngx_stream_core_module.html nginx从1.9.0开始，新增加了一个stream模块，用来实现四层协议(tcp/udp)的转发、代理和负载均衡。这个模块不是默认构建的，需要使用--with-stream参数。 1yum install -y nginx-mod-stream 这个实现四层反向代理和转发的功能真的是很强大，只需一台反向代理服务器，转发给所有后端机器。 栗子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495vim /etc/nginx/nginx.confstream&#123; include /etc/nginx/stream.d/*.conf&#125;##########################cd /etc/nginx/stream.d#转发Elasticsearchvim elastic.confupstream elastic-cluster &#123; server ip1:9200; server ip2:9200; xxx;&#125;server &#123; listen 9200; proxy_pass elastic-cluster;&#125;#dnsvim dns.confupsetrem dns-cluster &#123; server ip:5353; server dns.example.com:53; xxx&#125;#tcpserver &#123; listen port; proxy_pass dns-cluster;&#125;#udpserver &#123; listen 53 udp; proxy_pass dns-cluster;&#125;#ipv6server &#123; listen [::1]:53; proxy_pass unix:/xxx/xx.socket&#125;#MySQLvim mysql.confupstream mysql-cluster &#123; server ip:3306; server ip2:3306; xxx;&#125;server &#123; listen 3306; proxy_pass mysql-cluster;&#125;#SSH转发upstream ssh &#123; server ip:22;&#125;server &#123; listen port; proxy_pass ssh;&#125; 错误信息Nginx错误日志的详细说明。 错误信息 描述 (13: Permission denied) while reading upstream xxx (98: Address already in use) while connecting to upstream xxx (99: Cannot assign requested address) while connecting to upstream xxx (104: Connection reset by peer) while reading response header from upstream upstream-fastcgi超时时间request_terminate_timeout过小 (104: Connection reset by peer) 1: 服务器的并发连接数超过其承载量，服务器会将其中一些连接Down掉; 2: 客户关掉了浏览器，而服务器还在给客户端发送数据; 3: 浏览器端按了Stop (104: Connection reset by peer) while connecting to upstream upstream发送了RST，将连接重置 send() failed (111: Connection refused) xxx (111: Connection refued) while connecting to upstream 用户在连接时，若遇到后端upstream挂掉或不通，会收到该错误 (111: Connection refused) while reading response header from upstream 用户在连接成功后读取数据时，若遇到后端upstream挂掉或者不通，会收到此错误 (111: Connection refused) while sending request to upstream Nginx和upstream连接成功后发送数据时，若遇到后端upstream挂掉或不通，会收到该错误 (110: Connection timed out) while connecting to upstream Nginx连接upstream时超时 (110: Connection rimed out) while reading upstream Nginx读取来自upstream的响应时超时 (110: Connection timed out) while reading response header from upstream Nginx读取来自upstream的响应头时超时 (110: Connection timed out) while reading upstream Nginx读取来自upstream的响应时超时 upstream prematurely closed connection 请求URI的时候出现异常，是由于upstream还未返回应答给用户时，用户断掉连接造成。对系统没有影响。 upstream sent invalid header while reading response header from upstream upstream发送的响应头无效 upstream sent no valid HTTP/1.0 header while reading response header from upstream upstream发送的响应头无效 client intended to send too large body 用于设置允许接受的客户端请求内容的最大值，Client发送的body超过了设置 reopening logs 用户发送kill -USR1命令 gracefully shutting down 用户发送kill -WINCH命令 no servers are inside upstream upstream下未配置server no live upstreams while connecting to upstream upstream下的server全都挂了 SSL_do_handshake() failed SSL握手失败 SSL_write() failed(SSL) while sending to client xxx ngx_slab_alloc() failed: no memory in SSL session shared cache ssl_session_cache大小不够 could not add new SSL session to the session cache while SSL hanshaking ssl_session_cache大小不够]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[I Like For You To Be Still]]></title>
    <url>%2F2017%2F09%2F01%2FI-Like-For-You-To-Be-Still%2F</url>
    <content type="text"><![CDATA[《I Like For You To Be Still》 出自聂努达诗集：《二十首情诗和一首绝望的歌》。 I like for you to be stillIt is as though you are absentAnd you hear me from far awayAnd my voice does not touch youIt seems as though your eyes had flown awayAnd it seems that a kiss had sealed your mouthAs all things are filled with my soulYou emerge from the thingsFilled with my soulYou are like my soulA butterfly of dreamAnd you are like the word: Melancholy I like for you to be stillAnd you seem far awayIt sounds as though you are lamentingA butterfly cooing like a doveAnd you hear me from far awayAnd my voice does not reach youLet me come to be still in your silenceAnd let me talk to you with your silenceThat is bright as a lampSimple, as a ringYou are like the nightWith its stillness and constellationsYour silence is that of a starAs remote and candid I like for you to be stillIt is as though you are absentDistant and full of sorrowSo you would’ve diedOne word then, One smile is enoughAnd I’m happy;Happy that it’s not true]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>Pablo Neruda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Test-My-Site]]></title>
    <url>%2F2017%2F08%2F30%2FTest-My-Site%2F</url>
    <content type="text"><![CDATA[Monday Tuesday Wednesday Thursday Friday Saturday Sunday $$\sideset{^1_2}{^3_4}A$$ $E=mc^2$ $$\sum_{i=1}^n a_i=0$$ $$f(x_1,x_x,\ldots,x_n) = x_1^2 + x_2^2 + \cdots + x_n^2 $$ $$\sum^{j-1}{k=0}{\widehat{\gamma}{kj} z_k}$$]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>Test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F08%2F30%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
