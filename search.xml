<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Helm]]></title>
    <url>%2F2020%2F09%2F21%2FHelm%2F</url>
    <content type="text"><![CDATA[参考： docs: https://docs.helm.sh/ github: https://github.com/helm 环境： el7x86_64 helm v3.3 概述Helm是Kubernetes生态系统中的一个软件包管理工具，主要用来管理Charts，有点类似于Ubuntu中的apt或CentOS中的yum。由go编写，是Deis公司发起的一个开源工具，有助于简化部署和管理Kubernetes应用。 在Kubernetes中，应用管理是需求最多、挑战最大的领域。Helm项目提供了一个统一软件打包方式，支持版本控制，可以大大简化Kubernetes应用分发与部署中的复杂性。 Helm Chart是用来封装 Kubernetes原生应用程序的一系列YAML文件。可以在你部署应用的时候自定义应用程序的一些 Metadata，以便于应用程序的分发。 对于应用发布者而言，可以通过 Helm 打包应用、管理应用依赖关系、管理应用版本并发布应用到软件仓库。 对于使用者而言，使用 Helm 后不用需要编写复杂的应用部署文件，可以以简单的方式在 Kubernetes 上查找、安装、升级、回滚、卸载应用程序。 The package manager for Kubernetes. Helm is the best way to find, share, and use software built for Kubernetes. 术语Glossary: https://helm.sh/docs/glossary/ Chart Helm包涵盖了将k8s资源安装到k8s集群所需的足够多的信息。Charts包含了Chart.yaml文件核模板，默认值(values.yaml)，以及相关依赖。Charts开发设计了良好定义的目录结构，并打包为chart archive。 Chart Archive Chart包是被tar和gzip压缩（可选签名）的chart。 Chart Dependency(Subcharts) Chart可以依赖于其它chart。依赖有两种方式： 软依赖(soft): 如果另一个chart没有在集群中安装，chart可能会无法使用 硬依赖(hard): chart包含它所依赖的chart。（在charts/目录中） 当一个chart打包(helm package)时，所有的依赖都会和它绑定。 Chart Version 每个chart都需要版本号。 Chart.yaml chart的信息说明被存储在一个特定文件(Chart.yaml)。每个chart都必须有这个文件。 helm Helm是k8s包管理器。作为一个操作系统包管理器，使其很容易在操作系统中安装工具。Helm使得k8s集群中安装应用和资源变得异常简单。 Helm Configuration Files Helm将配置文件存储在XDG目录中。helm第一次运行，会自动生成。 Kube Config(KUBECONFIG) helm客户端通过Kube config配置文件来理解k8s集群。默认$HOME/.kube/config。 Lint Helm代码规范，规范一个chart是去验证其遵照Helm chart的标准规范和要求。Helm提供了helm lint命令。 Provenance Helm chart可以由来源文件(provenance file)提供chart的出处以及它所包含的内容。 来源文件(.prov)是Helm安全的一部分。一个来源包含chart包文件的加密哈希值，Chart.yaml数据，一个签名块。当再加上一个钥匙链(keychain)时，可为chart用户提供以下能力： 验证chart被可信第三方签名 验证chart文件没有被篡改 验证chart的元数据内容(Chart.yaml) 快速匹配chart的数据来源 Release 发行版本。chart安装之后，Helm库会创建一个release来跟踪这个安装。 单个chart可以在同一个集群中安装多次，并能创建多个不同的版本。 Release Number/Version 单个版本号可以被升级多次。通过连续技术来跟踪升级发布版本。 Rollback 每一次发布会更新chart或者配置。当生成发布历史后，一次发布也可以被 rolled back 之前的发布版本号。回滚使用helm rollback命令。 重要的是, 每一次回滚版本会生成一个新的发布版本号。 12345操作 版本号install release 1upgrade release 2upgrade release 3rollback 1 release 4 (但使用release 1的配置) Helm Library(SDK) Helm库（或SDK）涉及到go代码，可以直接与k8s API服务交互进行安装、升级、查询 以及移除k8s资源。 Repository Helm chart可以被存储到专用的HTTP服务器上，称之为chart仓库。 Helm客户端可以指向零个或多个chart仓库。默认没有配置仓库，可使用helm repo add添加。 Values Values 提供了一种使用您自己的信息覆盖模板默认值的方式。 Helm Chart是参数化的, 这意味着chart开发者可以在安装时显式配置。比如说，chart可以暴露username字段， 允许为服务设置一个用户名。这些可暴露的变量在Helm用语中称为values。 Values可在helm install, helm upgrage时设置。也可以在values.yaml文件中设置。 介绍Introduction: https://helm.sh/docs/intro/ 快速入门Quickstart: https://helm.sh/docs/intro/quickstart/ 如何快速安装核使用Helm。 先决条件Prerequisites 使用Helm的前置条件： k8s集群 建议最新k8s稳定版 kubectl 安装的安全配置(如果有的话) 安装和配置Helm 注意Helm版本对应支持的k8s版本。 安装Install: https://helm.sh/docs/intro/install/ 从源码、或二进制安装Helm CLI。 从Helm项目From The Helm Project 从二进制包: 下载特定版本包: https://github.com/helm/helm/releases 解压 添加到PATH 12345wget https://get.helm.sh/helm-v3.3.3-linux-amd64.tar.gztar -zxvf helm-v3.3.3-linux-amd64.tar.gzmv helm /usr/local/bin/helm 从脚本: 123curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3chmod 700 get_helm.sh./get_helm.sh 从源码123git clone https://github.com/helm/helm.gitcd helmmake 初始化Helm chartInitialize a Helm Chart Repository Helm安装好之后，你可以添加一个chart仓库。 1234567891011# 添加Helm官方仓库helm repo add stable https://kubernetes-charts.storage.googleapis.com/# 查看安装的charts列表helm search repo stableNAME CHART VERSION APP VERSION DESCRIPTIONstable/acs-engine-autoscaler 2.2.2 2.1.1 DEPRECATED Scales worker nodes within agent poolsstable/aerospike 0.2.8 v4.5.0.5 A Helm chart for Aerospike in Kubernetesstable/airflow 4.1.0 1.10.4 Airflow is a platform to programmatically autho...stable/ambassador 4.1.0 0.81.0 A Helm chart for Datawire Ambassador 安装ChartInstall an Example Chart 可以通过helm install命令安装chart。 12345678910111213141516171819202122232425262728293031323334353637383940414243helm repo update# helm install，都会创建一个新的release# 所以一个chart在同一个集群里面可以被安装多次，每一个都可以被独立的管理和升级helm install stable/mysql --generate-nameNAME: mysql-1600679719LAST DEPLOYED: Mon Sep 21 17:15:23 2020NAMESPACE: defaultSTATUS: deployedREVISION: 1NOTES:MySQL can be accessed via port 3306 on the following DNS name from within your cluster:mysql-1600679719.default.svc.cluster.localTo get your root password run: MYSQL_ROOT_PASSWORD=$(kubectl get secret --namespace default mysql-1600679719 -o jsonpath="&#123;.data.mysql-root-password&#125;" | base64 --decode; echo)To connect to your database:1. Run an Ubuntu pod that you can use as a client: kubectl run -i --tty ubuntu --image=ubuntu:16.04 --restart=Never -- bash -il2. Install the mysql client: $ apt-get update &amp;&amp; apt-get install mysql-client -y3. Connect using the mysql cli, then provide your password: $ mysql -h mysql-1600679719 -pTo connect to your database directly from outside the K8s cluster: MYSQL_HOST=127.0.0.1 MYSQL_PORT=3306 # Execute the following command to route the connection: kubectl port-forward svc/mysql-1600679719 3306 mysql -h $&#123;MYSQL_HOST&#125; -P$&#123;MYSQL_PORT&#125; -u root -p$&#123;MYSQL_ROOT_PASSWORD&#125;#查看此chart的基本信息helm show chart stable/mysqlhelm show all stable/mysql Releases12345678# 查看chart发行版helm lsNAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSIONmysql-1600679719 default 1 2020-09-21 17:15:23.169811348 +0800 CST deployed mysql-1.6.7 5.7.30# 列出所有部署的发行helm list 卸载Release使用helm uninstall命令卸载realease。 12helm uninstall mysql-1600679719release "mysql-1600679719" uninstalled 它会删除和该release相关的所有资源。使用--keep-history选项，Helm将保存release history。所以你可以审计集群历史甚至使用helm rollback回滚release。 主题Topic Guides: https://helm.sh/docs/topics/ ChartsCharts: https://helm.sh/docs/topics/charts/ Helm使用的包格式称为charts。chart就是一个描述k8s相关资源的文件集合。单个chart可以用来部署简单或复杂的服务。 Chart是作为特定目录布局的文件被创建，它们可以打包到要部署的版本存档中。 12# 下载一个chart，但不安装helm pull xxx 文件结构chart是一个组织在文件目录中的集合。目录名称就是chart名称(没有版本信息)。 示例: 12345678910wordpress/ Chart.yaml # 包含了chart信息的YAML文件 LICENSE # 可选: 包含chart许可证的纯文本文件 README.md # 可选: 可读的README文件 values.yaml # chart 默认的配置值 values.schema.json # 可选: 一个使用JSON结构的values.yaml文件 charts/ # 包含chart依赖的其他chart crds/ # 自定义资源的定义 templates/ # 模板目录， 当和values 结合时，可生成有效的Kubernetes manifest文件 templates/NOTES.txt # 可选: 包含简要使用说明的纯文本文件 Chart.yamlChart.yaml文件是chart必须的。包含以下字段。 12345678910111213141516171819202122232425262728293031apiVersion: chart API 版本 （必需）name: chart名称 （必需）version: 语义化2 版本（必需）kubeVersion: 兼容Kubernetes版本的语义化版本（可选）description: 一句话对这个项目的描述（可选）type: chart类型 （可选）keywords: - 关于项目的一组关键字（可选）home: 项目home页面的URL （可选）sources: - 项目源码的URL列表（可选）dependencies: # chart 必要条件列表 （可选） - name: chart名称 (nginx) version: chart版本 ("1.2.3") repository: 仓库URL ("https://example.com/charts") 或别名 ("@repo-name") condition: （可选） 解析为布尔值的yaml路径，用于启用、禁用chart (e.g. subchart1.enabled ) tags: # （可选） - 用于一次启用/禁用 一组chart的tag enabled: （可选） 决定是否加载chart的布尔值 import-values: # （可选） - ImportValue 保存源值到导入父键的映射。每项可以是字符串或者一对子/父列表项 alias: （可选） chart中使用的别名。当你要多次添加相同的chart时会很有用maintainers: # （可选） - name: 维护者名字 （每个维护者都需要） email: 维护者邮箱 （每个维护者可选） url: 维护者URL （每个维护者可选）icon: 用做icon的SVG或PNG图片URL （可选）appVersion: 包含的应用版本（可选）。不需要是语义化的deprecated: 不被推荐的chart （可选，布尔值）annotations: example: 按名称输入的批注列表 （可选）. Chart和版本控制 每个chart都必须有版本号。版本必须遵循SemVer2标准。 123# nginx chart的版本字段version: 1.2.3# 按照名称设置为nginx-1.2.3.tgz Chart.yaml文件中的version字段被很多Helm工具使用。当生成一个包时，helm package命令可以用Chart.yaml文件中找到的版本号作为包名的token。系统假设chart包名中的版本号可以与Chart.yaml文件中的版本号匹配。如果不满足这一假设会导致错误。 apiVersion字段 对于至少需要Helm3的chart，apiVersion字段应该是v2。 kubeVersion字段 可选的kubeVersion字段可以在支持的k8s版本上定义语义约束，Helm 在安装chart时会验证这个版本约束， 并在集群运行不支持的k8s版本时显示失败。 版本约束可以包含空格、比较操作符、逻辑操作符。 12345&gt;= 1.13.0 &lt; 1.15.0&gt;= 1.13.0 &lt; 1.14.0 || &gt;= 1.14.1 &lt; 1.15.01.1 - 2.3.4 deprecated字段 在Chart仓库管理chart时，有时需要废弃一个chart。deprecated字段可用来标记已弃用的chart。如果latest版本被标记为已弃用，则所有的chart都会被认为是已弃用的。以后可以通过发布未标记为已弃用的新版本来重新使用chart名称。 kubernetes/charts项目遵循的弃用charts的流程为： 升级chart的Chart.yaml文件，将这个文件标记为已弃用，并更改版本 在chart仓库中发布新版的chart 从源仓库中移除这个chart type字段 type字段定义了chart的类型。有两种类型： application：默认类型，是可以完全操作的标准chart。 library：不能安装，提供针对chart构建的实用程序和功能。通常不包含任何资源对象。 应用类型chart 可以作为库类型chart使用。可以通过将类型设置为library来实现。 然后这个库就被渲染成了一个库类型chart，所有的实用程序和功能都可以使用。所有的资源对象不会被渲染。 许可证和描述Chart LICENSE, README and NOTES Chart也可以包含描述安装、配置和使用的文件，以及chart许可证。 LICENSE是一个包含了chart license的纯文本文件。chart可以包含一个许可证，因为在模板里不只是配置，还可能有编码逻辑。如果需要，还可以为chart安装的应用程序提供单独的许可证。 README自述文件，一般包含： chart提供的应用或服务的描述 运行chart的先决条件或要求 values.yaml的可选项和默认值的描述 与chart的安装或配置相关的其它信息 chart也会包含一个简短的纯文本templates/NOTES.txt文件，这会在安装后及查看版本状态时打印出来。由于此文件是在运行helm install或helm status时打印到STDOUT的，因此建议保持内容简短，并指向自述文件以获取更多详细信息。 依赖Chart Dependencies Helm中，chart可能会依赖其它任意个chart。这些依赖可使用dependencies字段(Chart.yaml)动态链接，或写入charts/目录。 dependencies字段 当前chart依赖的其它chart会在dependencies字段定义为一个列表。 1234567dependencies: - name: apache version: 1.2.3 repository: https://example.com/charts - name: mysql version: 3.2.1 repository: https://another.example.com/charts 必须使用helm repo add在本地添加仓库。 一旦你定义好了依赖，运行helm dependency update就会使用你的依赖文件下载所有你指定的chart到你的charts/目录。 alias字段 为依赖chart添加一个别名，会使用别名作为新依赖chart的名称。 需要使用其他名称访问chart时可以使用alias。 123456789101112dependencies: - name: subchart repository: http://localhost:10191 version: 0.1.0 alias: new-subchart-1 - name: subchart repository: http://localhost:10191 version: 0.1.0 alias: new-subchart-2 - name: subchart repository: http://localhost:10191 version: 0.1.0 tags和condition字段 123456789101112131415dependencies: - name: subchart1 repository: http://localhost:10191 version: 0.1.0 condition: subchart1.enabled, global.subchart1.enabled tags: - front-end - subchart1 - name: subchart2 repository: http://localhost:10191 version: 0.1.0 condition: subchart2.enabled,global.subchart2.enabled tags: - back-end - subchart2 123456#values.yamlsubchart1: enabled: truetags: front-end: false back-end: true 12# 可以在CLI使用--set参数来设置标签和条件值helm install --set tags.front-end=true --set subchart2.enabled=false 通过依赖导入sub values 在某些情况下，允许子chart的值作为公共默认传递到父chart中是值得的。 12345678# parent's Chart.yaml filedependencies: - name: subchart repository: http://localhost:10191 version: 0.1.0 import-values: - data 12345# child's values.yaml fileexports: data: myint: 99 通过charts目录手动管理依赖 如果对依赖进行更多控制，通过将有依赖关系的chart复制到charts/目录中来显式表达这些依赖关系。 要将依赖放入charts/目录，使用helm pull命令。 Templates and ValuesHelm Chart模板是按照Go模板语言书写。让我想起了Django模板语言，Jinja2模板语言。 所有模板语言存放在chart的templates/目录下。当Helm渲染chart时，它会通过模板引擎遍历目录中的每个文件。 模板的Value通过两种方式提供： 通过values.yaml文件提供，此文件包含了默认值。 用户可以提供一个包含value的yaml文件，在helm install时使用它。 当用户提供自定义的value时，会覆盖values.yaml中的值。 模板文件示例 1234567891011121314151617181920212223242526apiVersion: v1kind: ReplicationControllermetadata: name: deis-database namespace: deis labels: app.kubernetes.io/managed-by: deisspec: replicas: 1 selector: app.kubernetes.io/name: deis-database template: metadata: labels: app.kubernetes.io/name: deis-database spec: serviceAccount: deis-database containers: - name: deis-database image: &#123;&#123; .Values.imageRegistry &#125;&#125;/postgres:&#123;&#123; .Values.dockerTag &#125;&#125; imagePullPolicy: &#123;&#123; .Values.pullPolicy &#125;&#125; ports: - containerPort: 5432 env: - name: DATABASE_STORAGE value: &#123;&#123; default &quot;minio&quot; .Values.storage &#125;&#125; 预定义的Values 以下值是预定义的，对每个模板都有效，并且可以被覆盖。和所有值一样，名称 区分大小写： Release.Name: 版本名称(非chart的) Release.Namespace: 发布的chart版本的命名空间 Release.Service: 组织版本的服务 Release.IsUpgrade: 如果当前操作是升级或回滚，设置为true Release.IsInstall: 如果当前操作是安装，设置为true Chart: Chart.yaml的内容。因此，chart的版本可以从Chart.Version获得， 并且维护者在Chart.Maintainers里 Files：chart中的包含了非特殊文件的类图对象 Capabilities: 包含了Kubernetes版本信息的类图对象 范围 Scope, Dependencies, and Values Values文件可以声明顶级chart的值，以及charts/目录中包含的其他任意chart。 全局Values Helm支持特殊的global值。 12global: app: MyWordPress 这个值以.Values.global.app在所有chart中有效。 架构文件 有时候，chart容器可能想基于它们的values值定义一个结构，这可以在values.schema.json文件中定义一个架构实现。 示例： 1234567891011121314151617181920212223242526272829303132333435&#123; "$schema": "https://json-schema.org/draft-07/schema#", "properties": &#123; "image": &#123; "description": "Container Image", "properties": &#123; "repo": &#123; "type": "string" &#125;, "tag": &#123; "type": "string" &#125; &#125;, "type": "object" &#125;, "name": &#123; "description": "Service name", "type": "string" &#125;, "port": &#123; "description": "Port", "minimum": 0, "type": "integer" &#125;, "protocol": &#123; "type": "string" &#125; &#125;, "required": [ "protocol", "port" ], "title": "Values", "type": "object"&#125; 这个架构会应用values值并验证它。当执行以下任意命令时会进行验证： helm install, helm upgrage, helm lint, helm template。 用户自定义资源Custom Resource Definitions k8s提供了一种声明k8s新类型对象的机制。使用CustomResourceDefinition（CRD），k8s开发者可以声明自定义资源类型。 Helm3中，CRD被视为一种特殊的对象。它们被安装在chart的其他部分之前，并受到一些限制。 CRD YAML文件应被放置在chart的crds/目录中。 多个CRD(用YAML的开始---和结束符...分隔)可以被放置在同一个文件中。Helm会尝试加载CRD目录中所有的文件到k8s。 当Helm安装新chart时，会上传CRD，暂停安装直到CRD可以被API服务使用，然后启动模板引擎， 渲染chart其他部分，并上传k8s。 CRD的限制 不像大部分k8s对象，CRD是全局安装的。因此Helm管理CRD时会采取非常谨慎的方式。 CRD受到以下限制： CRD从不重新安装。 如果Helm确定crds/目录中的CRD已经存在（忽略版本），Helm不会安装或升级。 CRD从不会在升级或回滚时安装。Helm只会在安装时创建CRD。 CRD从不会被删除。自动删除CRD会删除集群中所有命名空间中的所有CRD内容。因此Helm不会删除CRD。 希望升级或删除CRD的操作员应该谨慎地手动执行此操作。 管理chartUsing Helm to Manage Charts helm工具有一些命令用来处理chart。 12345678# 创建新charthelm create mychart# 打包helm package mychart# 格式信息helm lint mychart 仓库Chart Repositories 当helm用来管理本地chart目录时， 共享chart时，首选的机制就是使用chart仓库。 仓库的主要特征存在一个名为index.yaml的特殊文件，文件中包含仓库提供的包的完整列表， 以及允许检索和验证这些包的元数据。 在客户端，仓库使用helm repo命令管理。然而，Helm不提供上传chart到远程仓库的工具。 这是因为这样做会给执行服务器增加大量的必要条件，也就增加了设置仓库的障碍。 Starter Packshelm create命令可以附带一个可选的--starter选项指定一个starter chart。Starter就只是普通chart，但是被放置在$XDG_DATA_HOME/helm/starters。 HooksChart Hooks: https://helm.sh/docs/topics/charts_hooks/ Helm提供了一个hook机制，使chart开发者在发行版(release)生命周期的特定点进行干预。你可以使用hooks做以下事情： 安装过程中，在chart载入之前载入configmap或secret。 在安装一个新chart之前，执行一个作业(job)来备份数据库，然后执行第二个作业还原数据库。 在删除一个release之气，运行一个作业，在移除之前，来优雅地取出服务轮询。 hooks工作像常规模板，但它们有特殊的注释(写在annotations下)，因此helm可以不同地使用它们。本章节，我们将介绍hooks的基本使用模式。 12annotations: "helm.sh/hook": post-install 可用的hooks Annotation Value Description pre-install - 模板渲染之后执行，但在k8s创建任何资源之前 post-install - 所有资源载入k8s后执行 pre-delete - 在从k8s删除任意资源前，执行一个删除请求 post-delete - 在所有release的资源被删除后，执行一个删除请求 pre-upgrade - 在模板渲染后，执行一个升级请求，但在任意资源升级之前 post-upgrade - 在所有资源都升级后，执行一个升级 pre-rollback - 在模板渲染后，执行一个回滚请求，但在任意资源回滚前 post-rollback - 在所有资源都被修改后，执行一个回滚请求 test - 当heml test子命令调用时执行 测试Chart Tests: https://helm.sh/docs/topics/chart_tests/ chart包含许多k8s资源和协同工作的组件。作为包作者，你可能想编写一个测试，来验证包安装时是否如预期那样工作。 helm chart中的测试位于templates/目录下，是一个作业(job)定义，指定一个容器运行特定的命令。容器成功退出(exit 0)，被认为测试成功。作业定义必须包含helm.sh/hook: test的注释。 示例测试： 验证values.yaml文件被正确配置 验证服务、负载均衡正常 等等 可在helm中运行预定义测试，在release上使用helm test &lt;RELEASE_NAME&gt;命令。对于包的使用者，这是一个检测release of chart工作正常的方式。 示例Example Test 12345678910helm repo add bitnami https://charts.bitnami.com/bitnamihelm pull bitnami/wordpress --untarwordpress/ Chart.yaml README.md values.yaml charts/ templates/ templates/tests/test-mariadb-connection.yaml templates/tests/test-mariadb-connection.yaml的内容： 12345678910111213141516171819202122232425262728293031323334353637&#123;&#123;- if .Values.mariadb.enabled &#125;&#125;apiVersion: v1kind: Podmetadata: name: "&#123;&#123; .Release.Name &#125;&#125;-credentials-test" annotations: "helm.sh/hook": testspec: containers: - name: &#123;&#123; .Release.Name &#125;&#125;-credentials-test image: &#123;&#123; template "wordpress.image" . &#125;&#125; imagePullPolicy: &#123;&#123; .Values.image.pullPolicy | quote &#125;&#125; &#123;&#123;- if .Values.securityContext.enabled &#125;&#125; securityContext: runAsUser: &#123;&#123; .Values.securityContext.runAsUser &#125;&#125; &#123;&#123;- end &#125;&#125; env: - name: MARIADB_HOST value: &#123;&#123; template "mariadb.fullname" . &#125;&#125; - name: MARIADB_PORT value: "3306" - name: WORDPRESS_DATABASE_NAME value: &#123;&#123; default "" .Values.mariadb.db.name | quote &#125;&#125; - name: WORDPRESS_DATABASE_USER value: &#123;&#123; default "" .Values.mariadb.db.user | quote &#125;&#125; - name: WORDPRESS_DATABASE_PASSWORD valueFrom: secretKeyRef: name: &#123;&#123; template "mariadb.fullname" . &#125;&#125; key: mariadb-password command: - /bin/bash - -ec - | mysql --host=$MARIADB_HOST --port=$MARIADB_PORT --user=$WORDPRESS_DATABASE_USER --password=$WORDPRESS_DATABASE_PASSWORD restartPolicy: Never&#123;&#123;- end &#125;&#125; 运行测试: 123helm install quirky-walrus wordpress --namespace defaulthelm test quirky-walrus 注意： 你可以在templates/目录下定义许多测试 你可以嵌套你的测试&lt;chart-name&gt;/templates/tests/ 一个测试就是一个helm hook LibraryLibrary Charts: https://helm.sh/docs/topics/library_charts/ A library chart is a type of Helm chart，定义chart可通过helm模板在其它charts中共享。 完整性校验Helm Provenance and Integrity: https://helm.sh/docs/topics/provenance/ helm有来源工具，帮助chart user验证包的来源和完整性。使用基于行业标准的PIK, GnuPG等备受推崇的包管理器，Helm 可以生成和验证签名文件。 12345678# 生成helm package --sign ...helm package --sign --key &apos;John Smith&apos; --keyring path/to/keyring.secret mychart# 校验helm install --verifyhelm verify mychart-0.1.0.tgzhelm install --generate-name --verify mychart-0.1.0.tgz 仓库Chart Repository: https://helm.sh/docs/topics/chart_repository/ 官方的chart repo由Kubernetes Charts项目维护。欢迎各位参与。Helm也使得创建和运行自己的chart repo变得很容易。 创建仓库Create a chart repository: https://helm.sh/docs/topics/chart_repository/ 一个chart repo是一个HTTP服务器，它容纳了一个index.yaml文件和一些包。当你准备好分享你的charts，方法是将它们上传到一个chart repository。你可以使用GCS, S3, GitHub Pages等来创建你自己的web服务器。 注册中心Registries: https://helm.sh/docs/topics/registries/ Helm 3 支持OCI用于包分发。 Chart包可以通过基于OCI的注册中心存储和分发。 1234567891011121314151617181920212223242526272829303132333435363738394041# 激活对OCI的支持export HELM_EXPERIMENTAL_OCI=1# 运行一个注册中心docker run -dp 5000:5000 --restart=always --name registry registry# 认证htpasswd -cB -b auth.htpasswd myuser mypassdocker run -dp 5000:5000 --restart=always --name registry \ -v $(pwd)/auth.htpasswd:/etc/docker/registry/auth.htpasswd \ -e REGISTRY_AUTH=&quot;&#123;htpasswd: &#123;realm: localhost, path: /etc/docker/registry/auth.htpasswd&#125;&#125;&quot; \ registry# 登录helm registry login -u myuser localhost:5000# 注销helm registry logout localhost:5000# 保存helm chart save mychart/ localhost:5000/myrepo/mychart:2.7.0# 查看helm chart list# 导出helm chart export localhost:5000/myrepo/mychart:2.7.0# 推送到远程helm chart push localhost:5000/myrepo/mychart:2.7.0# 从缓存中移除helm chart remove localhost:5000/myrepo/mychart:2.7.0# 从远程拉取helm chart pull localhost:5000/myrepo/mychart:2.7.0 使用上述命令存储的chart会被缓存到文件系统中。OCI 镜像设计规范 严格遵守文件系统布局的。如： 123456789101112tree ~/Library/Caches/helm/└── registry ├── cache │ ├── blobs │ │ └── sha256 │ │ ├── 1b251d38cfe948dfc0a5745b7af5ca574ecb61e52aed10b19039db39af6e1617 │ │ ├── 31fb454efb3c69fafe53672598006790122269a1b3b458607dbe106aba7059ef │ │ └── 8ec7c0f2f6860037c19b54c3cfbab48d9b4b21b485a93d87b64690fdb68c2111 │ ├── index.json │ ├── ingest │ └── oci-layout └── config.json 架构Helm Architecture: https://helm.sh/docs/topics/architecture/ 介绍Helm在高级别的架构。 目的The Purpose of Helm Helm是管理称为chart的k8s包的工具。Helm可以做以下事情： 从头开始创建一个新的charts packages charts为归档(tgz) chart文件 与chart repo交互，并存储在那 安装和卸载charts到k8s集群 管理已安装的charts的发行版 对于Helm，有三个重要的概念： chart是创建一个k8s应用实例所需的信息束 config包含配置信息，可以合并到package chart来创建一个可发行的对象 release是一个运行的chart实例，包含特定的配置 组件Components Helm被实现为两个不同部分来执行： Helm CLI客户端，负责以下事情： 本地chart开发 管理repo 管理release 与Helm Library接口 发送chart安装 请求升级或卸载releases Helm Library提供了执行所有helm操作的逻辑。与k8s API接口交互，并提供以下功能： 组合chart和配置来构建一个release 安装chart到k8s，并提供release对象 通过与k8s交互，升级和卸载chart 实现Implementation Helm client和library由go编写。library使用k8s client与k8s集群通信。目前，library使用REST+JSON。它存储信息在k8s内的secrets里，不需要自己的数据库。配置文件以YAML编写。 高级技术Advanced Helm Techniques: https://helm.sh/docs/topics/advanced/ 后置渲染Post Rendering GO SDK 后端存储Storage backends RBACRole-based Access Control: https://helm.sh/docs/topics/rbac/ k8s rbac: https://kubernetes.io/docs/reference/access-authn-authz/rbac/ 介绍Helm如何与k8s RBAC进行交互。 在k8s中，授权角色给特定用户或应用的服务账号(service account)，以确保应用程序的操作在特定范围内。从k8s v1.6开始，RBAC默认启用。 使用RBAC，你可以： 授权特权操作给管理员 限制用户在特定命名空间/集群范围创建资源的能力 限制用户在特定命名空间/集群范围内查看资源的能力 管理用户账户Managing user accounts 所有的k8s集群有两种类型的用户： service accounts managed by Kubernetes normal users 普通用户假定由外部进行管理，独立的服务。管理员分发私钥，用户存储密码，甚至是用户名密码列表这样的文件。在这方面，k8s不具有代表普通用户账户的对象。普通用户无法通过API调用被添加到集群。 相比之下，服务账号是由k8s API管理的用户。它们被绑定到特定的命名空间，通过API server自动创建，或通过API调用手动创建。服务账号绑定在一组凭据里，存储为secret，它被挂载到pod，允许集群内进程与k8s API进行交谈。 API请求被绑定到任何一个用户（普通用户、服务账号），或者被视为匿名请求。这意味着集群内或集群外的每一个进程，从工作站上输入kubectl的人类用户，到节点上的kubelets，到控制面板的成员，在进行请求API server时必须进行认证，或被视为匿名用户。 角色、集群角色、角色绑定、集群角色绑定Roles, ClusterRoles, RoleBindings, and ClusterRoleBindings 在k8s中，用户账户和服务账户只能够根据授权访问来查看和修改资源。这种授权是通过使用角色(Roles)和角色绑定(RoleBindings)。角色和角色绑定被绑定到特定的命名空间，它通过角色提供授权，授予用户在此命名空间内查看或修改资源的能力。 在集群范围内，这些被称为集群角色(ClusterRoles)和集群角色绑定(ClusterRoleBindings)。授权用户集群角色，允许它们访问和修改整个集群的资源。这也需要查看和修改集群范围(命名空间，资源配额，节点)的资源。 集群角色可通过角色绑定的引用来绑定到特定的命名空间。admin, edit, view是最常使用的默认集群角色。 k8s有一些默认的集群角色可用，它们的本意是面向用户的角色。它们包含超级角色(cluster-admin)，和细粒度访问的角色(admin, edit, view)。 Default ClusterRole Default ClusterRoleBinding 描述 cluster-admin system:masters group 允许超级用户访问对任意资源执行任意动作。 admin None 允许管理员访问，在命名空间内使用角色绑定来授权。如读写命名空间内的大部分资源，包括在命名空间内创建角色和角色绑定的能力。但不允许对资源配额或命名空间进行写操作。 edit None 允许在命名空间内读取大多数对象的权限，不允许查看或修改角色和角色绑定 view None 允许在命名空间内查看大多数对象的权限。不允许查看角色和角色绑定。不允许查看secrets。 限制用户账户使用RBAC访问Restricting a user account access using RBAC 现在让我们了解基于角色的访问控制的基础知识，让我们讨论管理员如何限制用户的访问范围。 示例：授予用户命名空间范围的读写权限 Grant a user read/write access to a particular namespace 要限制用户对特定命名空间的读写权限，可以使用edit或admin角色。 此外，你还可以使用cluster-admin来创建一个角色绑定。授予在命名空间范围内的cluster-admin来提供在此命名空间内完整控制资源的权限，包含命名空间自身。 12345678# 创建nskubectl create namespace foo#创建RoleBindingkubectl create rolebinding sam-edit --clusterrole edit \ --user sam \ --namespace foo 示例：授予用户集群范围的读写权限 Example: Grant a user read/write access at the cluster scope 如果用户希望安装chart，在集群范围内安装集群资源（ns, roles, crd…），它们将需要集群范围的写权限。要这样做，授予用户admin或cluster-admin角色权限。 12345678kubectl create clusterrolebinding sam-view --clusterrole view \ --user samkubectl create clusterrolebinding sam-secret-reader --clusterrole secret-reader \ --user sam 示例：授予用户命名空间范围的只读权限 Example: Grant a user read-only access to a particular namespace 你可能注意到了，没有查看secret的集群角色。view集群角色没有授予用户访问secret的权限。然而，Helm默认将release metadata存储为secret。 为了使用户运行helm list，它需要读取这些secrets。为此，我们将创建一个特殊的secret-reader集群角色。 123456789# cluster-role-secret-reader.yamlapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: secret-readerrules:- apiGroups: [""] resources: ["secrets"] verbs: ["get", "watch", "list"] 1234567891011121314kubectl create -f clusterrole-secret-reader.yamlkubectl create namespace fookubectl create rolebinding sam-view --clusterrole view \ --user sam \ --namespace fookubectl create rolebinding sam-secret-reader --clusterrole secret-reader \ --user sam \ --namespace foo 示例：授予用户集群范围的只读权限 Example: Grant a user read-only access at the cluster scope 如果用户想运行helm l ist --all-namespaces命令，API需要用户拥有集群范围内的读权限。 1234567kubectl create clusterrolebinding sam-view --clusterrole view \ --user samkubectl create clusterrolebinding sam-secret-reader --clusterrole secret-reader \ --user sam 插件The Helm Plugins Guide: https://helm.sh/docs/topics/plugins/ Helm plugin是一个可通过helm CLI访问的工具，但不是内置的helm基础代码的一部分。 V2迁移到V3Migrating Helm v2 to v3: https://helm.sh/docs/topics/v2_v3_migration/ 弃用的k8s apiDeprecated Kubernetes APIs: https://helm.sh/docs/topics/kubernetes_apis/ 版本支持Helm Version Support Policy: https://helm.sh/docs/topics/version_skew/ SQL存储后端的权限管理Permissions management for SQL storage backend: https://helm.sh/docs/topics/permissions_sql_storage_backend/ 最佳实践The Chart Best Practices Guide: https://helm.sh/docs/chart_best_practices/ 涵盖了Helm团队对创建chart的最佳做法。它侧重于chart应该如何构造。主要关注那些可能会公开部署的charts的最佳实践。 一般约定General Conventions: https://helm.sh/docs/chart_best_practices/conventions/ chart名称Chart Names chart名称必须是小写字母和数字，可用-隔开。 chart目录必须与chart名称相同。 1234567# 示例drupalnginx-legoaws-cluster-autoscalernginx-legonginx-lego/ 版本号Version Numbers 只要有可能，Helm使用SemVer2来表示版本号。请注意，Docker image tag并不一定遵循SemVer，注意。 格式化YAMLFormatting YAML YAML应该使用两个空格（别使用tab）。 词Usage of the Words Helm and Chart Helm词的一些约定： Helm指作为一个整体的项目 helm客户端CLI chart不需要大写，它不是专有名词 Chart.yaml需要大写，因为该文件名是大小写敏感的 值Values: https://helm.sh/docs/chart_best_practices/values/ 提供给你如何组织和设计chart的values.yaml文件，并使用你的值。 命名约定Naming Conventions 变量名必须小写字母开头，使用驼峰分开： 12chicken: truechickenNoodleSoup: true 请注意，所有Helm内置变量以大写字母开头，用户可以轻松区分开: 12.Release.Name.Capabilities.KubeVersion 嵌套值YAML是一种灵活的格式，值可以被深度嵌套。 123server: name: nginx port: 80 123&#123;&#123; if .Values.server &#125;&#125; &#123;&#123; default &quot;none&quot; .Values.server.name &#125;&#125;&#123;&#123; end &#125;&#125; 使类型清晰Make Types Clear 12345678910# YAM的类型强制规则有时是反直觉的。例如一下两者是不同的foo: falsefoo: "false"# 避免类型转化错误的最简单的方法是要明确字符串和隐含的一切。使用引号引用字符串# 要避免整数转换错误，将整数存储为字符串，使用以下方法来获取整数值&#123;&#123; int $value &#125;&#125;# 在大多数情况下，显式类型标签被尊重。如以下1234被当作字符串foo: !!string 1234 考虑用户如何使用你的值Consider How Users Will Use Your Values 值有三个来源： values.yaml文件 helm install -f或helm upgrade -f时指定的文件里 --set或--set-string选项指定 当设计值的组织结构时，用户是希望可通过-f或--set选项来覆盖它们。YAML建议写成映射(mapping)，便于替换--set servers.foo.port=80。 12345servers: foo: port: 80 bar: port: 81 values.yaml每个在values.yaml中定义的属性应该被记录(documented)。文档字符串应该用它描述的属性的名称开始，然后给出至少一个单句描述。 1234# serverHost is the host name for the webserverserverHost: example# serverPort is the HTTP listener port for the webserverserverPort: 9191 模板Templates: https://helm.sh/docs/chart_best_practices/templates/ templates目录架构Structure of templates/ templates/目录应该是如下结构： 模板文件是.yaml扩展的YAML输出。.tpl扩展可用于未经格式化的模板文件 模板文件名应使用虚线(example-configmap.yaml)，而不是驼峰 每个资源定义应该有自己的模板文件 模板文件应放映资源类型（如foo-pod.yaml, bar-svc.yaml） 定义的模板的名称Names of Defined Templates 定义的模板(模板文件内的)是全局访问的。这意味着，chart和它的subchart可以访问所有创建的模板。这样我想起了Pythond的模板语言（Django模板语言，Jinja2等等）。 出于此原因，所有定义的模板名称都应该命名空间。 123&#123;&#123;- define &quot;nginx.fullname&quot; &#125;&#125;&#123;&#123;/* ... */&#125;&#125;&#123;&#123; end -&#125;&#125; It is highly recommended that new charts are created via helm create command as the template names are automatically defined as per this best practice. 格式化模板Formatting Templates 模板应该使用两个空格，而不是tab。花括号前后应该有空格。有适当的空格和缩进。 1234567&#123;&#123; .foo &#125;&#125;&#123;&#123; print &quot;foo&quot; &#125;&#125;&#123;&#123;- print &quot;bar&quot; -&#125;&#125;&#123;&#123; if $foo -&#125;&#125; &#123;&#123;- with .Bar &#125;&#125;Hello&#123;&#123; end -&#125;&#125;&#123;&#123;- end -&#125;&#125; 生成模板中的空格Whitespace in Generated Templates 优选的是，保持在生成的模板中的空格数量降到最低。特别是，许多空行不应出现彼此相邻。但偶尔空行还是可以的。 1234567891011121314151617181920# This is bestapiVersion: batch/v1kind: Jobmetadata: name: example labels: first: first second: second# This is okayapiVersion: batch/v1kind: Jobmetadata: name: example labels: first: first second: second 注释Comments (YAML Comments vs Template Comments) YAML文件注释和模板注释。当一个模板记录功能时，应该使用模板注释。当Helm用户通过查看注释调试时，在模板内应该使用YANML注释。 123456789101112131415161718# yaml 注释&#123;&#123;- /*模板注释*/ -&#125;&#125;&#123;&#123;- /*mychart.shortname provides a 6 char truncated version of the release name.*/ -&#125;&#125;&#123;&#123; define &quot;mychart.shortname&quot; -&#125;&#125;&#123;&#123; .Release.Name | trunc 6 &#125;&#125;&#123;&#123;- end -&#125;&#125;# This may cause problems if the value is more than 100Gimemory: &#123;&#123; .Values.maxMem | quote &#125;&#125; 在模板和模板输出中使用JSONUse of JSON in Templates and Template Output YAML是JSON的超集(superset)。在一些情况下，使用JSON语法可比其它YAML表示更具有可读性。 123456789# 列表# yamlarguments: - &quot;--dirname&quot; - &quot;/foo&quot;# jsonarguments: [&quot;--dirname&quot;, &quot;/foo&quot;] 依赖Dependencies: https://helm.sh/docs/chart_best_practices/dependencies/ 介绍Chart.yaml内声明的dependencies的最佳实践。 版本Versions 如果可能的化，使用版本范围，而不是某个确切的版本。建议使用补丁级别(patch-level)版本匹配: 12# &gt;= 1.2.3, &lt; 1.3.0version: ~1.2.3 repo ruls，如果可能，使用HTTPS。文件URL(file://...)被认为是一个特殊，对由一个固定部署的流水线charts。 条件和标记Conditions and Tags 条件或标记应被添加到任何依赖（可选的）。 1234567# 条件的推荐格式condition: somechart.enabled# 标记tags: - webaccelerator 标签和注释Labels and Annotations: https://helm.sh/docs/chart_best_practices/labels/ 讨论chart中使用标签和注释的最佳实践。 标签还是注释Is it a Label or an Annotation? 以下条件的元数据项应该为标签(label)： 它利用k8s来标识此资源 暴露给查询系统的目的是有用的 如果元数据的条目不用于查询，它应该设置为注释。Helm hooks总是注释。 标准的标签Standard Labels 下表定义了Helm chart常用的标签。Helm自身从未要求特定的标签存在。REC的标签是建议的，并应该放置到全局一致性的chart。OPT的标签是可选的。 12345678名称 状态 描述app.kubernetes.io/name REC 这应该是app名称。通常使用&#123;&#123; template &quot;name&quot; . &#125;&#125; 这由许多k8s manifests使用，不是Helm特定的helm.sh/chart REC chart名称和版本: &#123;&#123; .Chart.Name &#125;&#125;-&#123;&#123; .Chart.Version &#125;&#125;app.kubernetes.io/managed-by REC 这应该始终设置为&#123;&#123; .Release.Service &#125;&#125;app.kubernetes.io/instance REC 这应该为&#123;&#123; .Release.Name &#125;&#125;，有助于在同意应用不同实例之间进行区分app.kubernetes.io/version OPT 应用的版本设置为&#123;&#123; .Chart.AppVersion &#125;&#125;app.kubernetes.io/component OPT This is a common label for marking the different roles that pieces may play in an application|app.kubernetes.io/part-of OPT 当多个charts或软件片一起使用来做一个应用 可在k8s 文档中，带有app.kubernetes.io前缀的文档中查看更多信息。 Pods和PodTemplatesPods and PodTemplates: https://helm.sh/docs/chart_best_practices/pods/ 以下资源列表使用PodTemplate： Deployment ReplicationController ReplicaSet DaemonSet StatefulSet 镜像Images 容器镜像应该使用确定的标记或镜像的SHA。但不应该使用latest, head, canary这样的标记。 镜像可以在values.yaml文件中定义，使其很容易替换镜像。 1image: &#123;&#123; .Values.redisImage | quote &#125;&#125; 镜像和标记可在values.yaml中被定义为分开的两个字段： 1image: &quot;&#123;&#123; .Values.redisImage &#125;&#125;:&#123;&#123; .Values.redisTag &#125;&#125;&quot; 镜像拉取策略ImagePullPolicy helm create默认在deployment.yaml中设置imagePullPolicy为IfNotPresent。 1imagePullPolicy: &#123;&#123; .Values.image.pullPolicy &#125;&#125; 123# values.yamlimage: pullPolicy: IfNotPresent 同样，如果未设置impagePullPolicy，k8s默认会将其设置为IfNotPresent。如果想要修改此值，只需在values.yaml文件中更新此值。 PodTemplate应该声明选择器PodTemplates Should Declare Selectors 所有的PodTemplate部分应该指定一个选择器。示例： 1234567selector: matchLabels: app.kubernetes.io/name: MyNametemplate: metadata: labels: app.kubernetes.io/name: MyName 这是一个很好的做法，因为它使set和pod相关联。 但是，这对于像Deployment这样的集更为重要。没有这一点，整个标签集(set of labels)用于选择匹配pod，如果你使用的标签发生改变（如版本或日期），这将打破匹配。 自定义资源的定义Custom Resource Definitions 当使用自定义资源定义(CRDs)，区分两种不同的片是很重要的： 声明一个CRD(kind: CustomResourceDefinition) 然后资源使用CRD 使用资源前安装CRD声明Install a CRD Declaration Before Using the Resource Helm是尽可能优化地载入更多的资源到k8s中。按照设计，k8s可以采取一整套清单(manifests)，并带它们所有上线（这就是所谓的和解循环(reconciliation loop))）。 但是，CRDs有一些不同。对于CRD，在任意CRDs类型资源被使用之前，必须先注册声明。注册过程有时需要几秒。 方法1：让helm为你做此事 Method 1: Let helm Do It For You 随着Helm3的到来，出于更简单的方法，Helm移除了旧的crd-install hooks。这在是一个称为crds的新目录，在你创建的chart的此目录下保存你的CRDs。这些CRDs没有模板，但会在chart运行helm install时默认安装。如果CRD已存在，它会被跳过。你也可以通过传递--skip-crds选项来跳过CRD的安装。 一些注意事项: 目前不支持使用Helm更新或删除CRDs。这是一个经过反复讨论的明确的决定，由于存在非故意丢失数据的危险。此外，目前社区如何处理CRDs和它的生命周期没有共识，由于这种演变，Helm将添加对这些用例的支持。 helm install和helm upgrade的--dry-run选项暂不支持CRDs。Dry Run的目的是去验证chart的输出将实际地工作，如果发送到服务器。但CRDs可通过服务器行为的修改。Helm无法在dry run上安装CRD，因此发现客户端将不知道自定义资源(CR)，并验证将失败。你可以可选地移动CRDs到它们自己的chart，或使用helm template来代替。 围绕CRD支持的另一个重要的考虑点是如何处理模板的渲染(rendering of templates)。一个在Helm2中使用crd-install方法的明显的缺点是不能正确验证chart，由于改变API可用性（一个CRD被实际添加到另一个可用API到k8s集群）。如果一个chart安装了CRD，helm不再有一组API版本的有效集。这也是在移除从CRDs的模板支持的原因。随着安装CRD的新的crds方法，我们现在确保helm有关于当前集群状态的完整信息。 方法2：独立chart Separate Charts 另一种方法是，把CRD定义在一个chart中，然后把所有资源使用的该CRD放在另一个chart。 在此方法中，每个char都必须单独安装。然而，这个工作流程可能是集群操作器(cluster operators)（对集群拥有admin权限）使用。 RBACRole-Based Access Control: https://helm.sh/docs/chart_best_practices/rbac/ RBAC资源有： ServiceAccount (namespaced) Role (namespaced) ClusterRole RoleBinding (namespaced) ClusterRoleBinding YAML配置RBAC和ServiceAccount配置因该在单独的密钥里。它们是不同的东西。拆分这两个概念在YAML歧义消除它们，使之更清楚。 12345678910rbac: # Specifies whether RBAC resources should be created create: trueserviceAccount: # Specifies whether a ServiceAccount should be created create: true # The name of the ServiceAccount to use. # If not set and create is true, a name is generated using the fullname template name: 多个服务账号可以扩展为更复杂的charts。 12345678someComponent: serviceAccount: create: true name:anotherComponent: serviceAccount: create: true name: RBAC资源应该被默认创建RBAC Resources Should be Created by Default rbac.create应该是一个布尔值，由RBAC资源来控制创建。默认应该为true。希望管理RBAC访问控制的用户可以将此设置为false。 使用RBAC资源Using RBAC Resources serviceAccount.name应该被设置为由chart创建的访问控制资源使用的服务账号名称。如果serviceAccount.create为true，那么此名称的服务名称应该被创建。如果此名称未设置，则使用模板fullname来生成。如果为false，则它不应该被创建，但它应该与同样的资源相关联，以便创建后引用该手动创建RBAC资源正常工作。如果为false且没有指定名称，则使用默认的服务账号。 下面的助手模板应该用于服务账号： 12345678910&#123;&#123;/*Create the name of the service account to use*/&#125;&#125;&#123;&#123;- define "mychart.serviceAccountName" -&#125;&#125;&#123;&#123;- if .Values.serviceAccount.create -&#125;&#125; &#123;&#123; default (include "mychart.fullname" .) .Values.serviceAccount.name &#125;&#125;&#123;&#123;- else -&#125;&#125; &#123;&#123; default "default" .Values.serviceAccount.name &#125;&#125;&#123;&#123;- end -&#125;&#125;&#123;&#123;- end -&#125;&#125; 模板Chart Template: https://helm.sh/docs/chart_template_guide/ Helm‘s chart templates，重点介绍模板语言。让我想起的Django模板语言、Jinja2模板语言。 模板生成清单文件，这是k8s可理解的YAML格式的资源描述。本章重点介绍以下概念： Helm模板语言 Values使用 使用模板的技术 入门Getting Started: https://helm.sh/docs/chart_template_guide/getting_started/ 创建一个chart并添加一个模板。 Charts123456mychart/ Chart.yaml values.yaml charts/ templates/ ... templates/目录存放模板文件。当Helm评估一个chart，它会发送所有模板目录中的文件到模板渲染引擎。然后，它收集模板的结果，并将它们发送到k8s。 values.yaml文件对模板也很重要。此文件包含了一个chart的默认值。默认值可通过命令行选项进行覆盖。 Chart.yaml文件包含对chart包的描述信息。你可在模板中访问它。charts/目录可能包含其它chats(称为subcharts)。 示例A Starter Chart 123456789101112131415161718192021222324# 创建一个名为mychart的chart包helm create mychartCreating mychart# 目录结构tree ./mychart -L 2./mychart├── charts├── Chart.yaml├── templates│ ├── deployment.yaml│ ├── _helpers.tpl #模板助手，你可以重新使用整个chart│ ├── hpa.yaml #│ ├── ingress.yaml│ ├── NOTES.txt #chart包的帮助文本(help text)，会在运行helm install显示│ ├── serviceaccount.yaml│ ├── service.yaml│ └── tests└── values.yaml# 创建自己的模板rm -rf mychart/templates/* 当编写生产环境的chart包时，有这些charts包的基础版本可能很有用。 第一个模板A First Template 创建一个ConfigMap资源的模板。由于它是一个基本的资源，因此它为我们提供了一个很好的起点。 12345678# mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: mychart-configpmapdata: myvalue: "Hello World" 小技巧：模板名称不遵循严格的命名模式。然而，我们建议为YAML文件使用.yaml后缀，为模板助手使用.tpl后缀。 上述YAML文件是一个最基本的ConfigMap，最有最小的必要的字段。它会通过模板引擎进行发送。 一个普通的平YAML文件是蛮好的。当Helm读取此模板，它会简单地将文件原样发送给k8s。 在这个简单的例子中，我们现在有了一个可安装的chart包。安装一下： 1234567891011121314151617181920212223242526272829303132helm install full-coral mychartNAME: full-coralLAST DEPLOYED: Sun Sep 27 10:38:03 2020NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: Nonehelm lsNAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSIONfull-coral default 1 2020-09-27 10:38:03.546664865 +0800 CST deployed mychart-0.1.0 1.16.0helm get manifest full-coral---# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: mychart-configmapdata: myvalue: &quot;Hello World&quot;kubectl get configmapNAME DATA AGEmychart-configmap 1 9m47s# 卸载helm uninstall full-coral 添加一个简单的模板调用 Adding a Simple Template Call 硬编码的name，通常被认为是不好的做法。每个发行版的名称应该是唯一的。因此，我们可能将生成一个名称字段来写入发行版名称。 注意，由于DNS系统的限制，name字段被限制为63字符。出于这个原因，发行版名称被限制为53字符。 123456apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" 123456789101112131415161718192021222324# 模板指令放置于&#123;&#123; xxx &#125;&#125; 块内helm install clunky-serval mychart/NAME: clunky-servalLAST DEPLOYED: Sun Sep 27 11:16:20 2020NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: Nonehelm get manifest clunky-serval---# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: clunky-serval-configmapdata: myvalue: &quot;Hello World&quot;# 可使用--debug查看详情# 下面将渲染模板，返回渲染输出，不会真正安装helm install --debug --dry-run goodly-guppy ./mychart 使用--dry-run将更容易对代码进行测试，但它不会保证k8s会接受你生成的模板。 内置对象Built-in Objects: https://helm.sh/docs/chart_template_guide/builtin_objects/ 对象动模板引擎传递到模板。你的代码可以传递对象范围（如with和range）。有一些方法可在模板中创建新的对象，如tuple函数。 对象可以很简单，它只有一个值。它们也可以包含其它对象或函数。如，Realease对象可包含几个对象（如Release.Name），Files对象有一些函数。 12345678910111213141516171819202122232425- `Release`对象 - `Release.Name` - `Release.Namespace` - `Release.IsUpgrade` - `Release.IsInstall` - `Release.Revision` - `Release.Service`：在Helm中，总是Helm- `Values`: `values.yaml`中传递给模板的值- `Chart`: `Chart.yaml`文件内容- `Files`: 访问chart包中非模板的文件 - `Files.Get`: 通过名称生成文件的函数 - `Files.GetBytes` - `Files.Glob`: 返回文件为列表的函数 - `Files.Lines`: 一行行读取文件的函数 - `Files.AsSecrets`: 返回文件内容为base64编码字符串的函数 - `Files.AsConfig`: 返回文件内容为YAML map的函数- `Capabilities` - `Capabilities.APIVersions` - `Capabilities.APIVersions.Has $version` - `Capabilities.KubeVersion`, `Capabilities.KubeVersion.Version` - `Capabilities.KubeVersion.Major` - `Capabilities.KubeVersion.Minor`- `Template` - `Template.Name` - `Template.BasePath` 内置的值总以大写字母开头。这与go命名方式保持一致。 值文件Values Files: https://helm.sh/docs/chart_template_guide/values_files/ Values是一个内置的对象。它提供了访问值并传递到chart包。值文件是平YAML文件。其内容来源于多个源： chart包中的values.yaml文件 如果是一个subchart包，则为parent chart包的values.yaml文件 通过helm install/upgrade的-f myvals.yaml传递值 通过helm install/upgrade的--set foo=bar选项传递值 123456789101112# values.yamlfavoriteDrink: coffee# configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" drink: &#123;&#123; .Values.favoriteDrink &#125;&#125; 12345678910111213141516171819202122232425262728# 渲染helm install geared-marsupi ./mychart --dry-run --debugHOOKS:MANIFEST:---# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: geared-marsupi-configmapdata: myvalue: &quot;Hello World&quot; drink: coffee# 通过命令行选项覆盖值helm install solid-vulture ./mychart --dry-run --debug --set favoriteDrink=slurmHOOKS:MANIFEST:---# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: solid-vulture-configmapdata: myvalue: &quot;Hello World&quot; drink: slurm 值文件也可以包含更多结构化的内容。 123456789101112131415# values.yamlfavorite: drink: coffee food: pizza# configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" drink: &#123;&#123; .Values.favorite.drink &#125;&#125; food: &#123;&#123; .Values.favorite.food &#125;&#125; 虽然结构化数据这种方式是可行的，但建议你保持值的浅度(shallow)，有利于平整。当看到subcharts包的值时，我们将看到值是如何使用树状结构命名的。 删除一个默认键Deleting a default key 如果你需要从默认值删除一个键，你可以覆盖这个键的值为null，在这种情况下，Helm将从覆盖值得合并中移除这个键。 模板函数和管道Template Functions and Pipelines: https://helm.sh/docs/chart_template_guide/functions_and_pipelines/ 到目前为止，我们以将看到如何将信息转换为模板。但这些信息放入未修改的模板。有时候，我们希望以一种更可用的方式来转换提供的数据。 在模板指令中调用quote函数： 12345678apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" drink: &#123;&#123; quote .Values.favorite.drink &#125;&#125; food: &#123;&#123; quote .Values.favorite.food &#125;&#125; 模板函数使用funcationName arg1 arg2...语法。上面的quote .Values.favorite.drink调用quote函数并传递一个参数。 Helm有超过60个可用的函数。一些通过go模板语言定义。大多数是Sprig template library的一部分。 管道pipelines(|) 模板语言的一个强大功能就是它的管道(|)。管道是让几件事情依序进行的有效方式。让我们使用管道重写上面的示例： 12345678apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" drink: &#123;&#123; .Values.favorite.drink | quote &#125;&#125; food: &#123;&#123; .Values.favorite.food | quote &#125;&#125; 使用管道，我们可以将多个函数链接在一起： 12345drink: &#123;&#123; .Values.favorite.drink | repeat 5 | quote &#125;&#125;food: &#123;&#123; .Values.favorite.food | upper | quote &#125;&#125;#drink: "coffeecoffeecoffeecoffeecoffee"#food: "PIZZA" default函数default函数经常在模板中使用(default DEFAULT_VALUE GIVEN_VALUE)。此函数允许你指定一个默认值。有则替换它，无则使用默认值。 1drink: &#123;&#123; .Values.favorite.drink | default "tea" | quote &#125;&#125; 在实际的chart包中，所有静态默认值都应该位于values.yaml中，而不应该使用default重复。然而，default命令对于不能在values.yaml中声明的值，是完美的计算值的方法。例如： 1drink: &#123;&#123; .Values.favorite.drink | default (printf "%s-tea" (include "fullname" .)) &#125;&#125; lookup函数lookup函数可用于在正在运行的集群中查找资源。它查找apiVersion, kind, namespace, name到resource或resource list。 123456789101112# apiVersion, kind, namespace, name都是string# name, namespace两个是可选的，可以为空进行传递# 下列将会返回mynamespace对象的注释(lookup &quot;v1&quot; &quot;Namespace&quot; &quot;&quot; &quot;mynamespace&quot;).metadata.annotations# 当lookup返回一个列表(list)对象时，可以通过items字段访问列表对象&#123;&#123; range $index, $service := (lookup &quot;v1&quot; &quot;Service&quot; &quot;mynamespace&quot; &quot;&quot;).items &#125;&#125; &#123;&#123;/* do something with each service */&#125;&#125;&#123;&#123; end &#125;&#125; 当没有找到对象时，则返回一个空值。这可以用于检查对象是否存在。 lookup函数使用Helm现有的k8s连接配置来查询k8s。如果调用API server进行交互时返回错误，则Helm的模板处理将失败。 请记住，Helm是不应该在helm template或helm install|update|delete|rollback --dry-run期间连接到k8s API server，因此，lookup在此情况下将会获得一个空列表。 操作符Operators are functions 对于模板，操作符(eq, ne, lt, gt, and, or等)都被实现为函数。在管道中，操作符可使用括号()进行分组。 函数列表Template Function List: https://helm.sh/docs/chart_template_guide/function_list/ Helm包含很多模板函数，你可以在模板中使用它们。下面按照功能列出： Cryptographic and Security Date Dictionaries Encoding File Path Kubernetes and Chart Logic and Flow Control Lists Math Network Reflection Regular Expressions Semantic Versions String Type Conversion URL UUID 流程控制Flow Control: https://helm.sh/docs/chart_template_guide/control_structures/ 控制结构（在模板原语中称为行动）提供给模板作者，模板生成的控制流程的能力。Helm的模板语言提供了如下控制结构： if, else：创建条件块 with：指定一个范围 range： 提供一个类似的for循环 除此之外，它为声明和使用命名模板段提供了一些动作： define：在模板内声明一个新的命名模板 template：导入一个命名的模板 block：声明一个特殊的可填写的模板区域 这些都让我想起之前用Django模板语言写前端的时候，基本上一样的原理。 if和elseif, else块示例： 1234567&#123;&#123; if PIPELINE &#125;&#125; # Do something&#123;&#123; else if OTHER PIPELINE &#125;&#125; # Do something else&#123;&#123; else &#125;&#125; # Default case&#123;&#123; end &#125;&#125; 123456789apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" drink: &#123;&#123; .Values.favorite.drink | default "tea" | quote &#125;&#125; food: &#123;&#123; .Values.favorite.food | upper | quote &#125;&#125; &#123;&#123; if eq .Values.favorite.drink "coffee" &#125;&#125;mug: true&#123;&#123; end &#125;&#125; 控制空格Controlling Whitespace 虽然我们看到了条件语句，我们也应该了解模板中的空格的控制方式。这主要是确保对于生成的YAML文件的缩进的正确性。 1234567891011apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" drink: &#123;&#123; .Values.favorite.drink | default "tea" | quote &#125;&#125; food: &#123;&#123; .Values.favorite.food | upper | quote &#125;&#125; &#123;&#123; if eq .Values.favorite.drink "coffee" &#125;&#125; mug: true &#123;&#123; end &#125;&#125; 生成的不正确的YAML格式： 12345678910# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: eyewitness-elk-configmapdata: myvalue: "Hello World" drink: "coffee" food: "PIZZA" mug: true mug被不正确地缩进。让我们修改模板： 1234567891011apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" drink: &#123;&#123; .Values.favorite.drink | default "tea" | quote &#125;&#125; food: &#123;&#123; .Values.favorite.food | upper | quote &#125;&#125; &#123;&#123; if eq .Values.favorite.drink "coffee" &#125;&#125; mug: true &#123;&#123; end &#125;&#125; 这样生成的YAML是有效的，但显得很滑稽： 1234567891011# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: telling-chimp-configmapdata: myvalue: "Hello World" drink: "coffee" food: "PIZZA" mug: true 请注意，在YAML文件中生成了几个空行。为什么？当模板引擎运行时，它将删除花括号里的内容，但它留下的剩余空格完全一样。 YAML对空白很在意，所以管理空白变得非常重要。幸运的是，Helm有一些工具来帮助我们。 1234# 首先，模板声明的花括号 &#123;&#123; 可以使用特殊字符进行修改，来告诉模板引擎排列空白&#123;&#123;- 表示空白应靠左(chomped left)-&#125;&#125; 表示空白应在右边消耗(right should be consumed)# 注意，换行也是空白（Newlines are whitespace) 1234567891011apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" drink: &#123;&#123; .Values.favorite.drink | default "tea" | quote &#125;&#125; food: &#123;&#123; .Values.favorite.food | upper | quote &#125;&#125; &#123;&#123;- if eq .Values.favorite.drink "coffee" &#125;&#125; mug: true &#123;&#123;- end &#125;&#125; 12345678910# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: clunky-cat-configmapdata: myvalue: &quot;Hello World&quot; drink: &quot;coffee&quot; food: &quot;PIZZA&quot; mug: true 小心使用排列修改器(chomping modifier)。很容易不小心做了下面的事情： 1234food: &#123;&#123; .Values.favorite.food | upper | quote &#125;&#125;&#123;&#123;- if eq .Values.favorite.drink "coffee" -&#125;&#125;mug: true&#123;&#123;- end -&#125;&#125; 这会生成food: &quot;PIZZA&quot;mug:true这样，因为它消耗了两侧的换行。 123# 最后，有时很容易告诉模板系统如何缩进，而不是试图掌握模板指令的空格。# 出于此原因，你有时可能会发现使用 indent函数 处理缩进是很有用的&#123;&#123; indent 2 &quot;mug: true&quot; &#125;&#125; 使用with修改范围Modifying scope using with 另一个控制结构是with动作。这可以控制变量的范围，.是指的当前范围。因此，.Values告诉模板到当前范围下去寻找Values对象。 1234# with语法和if语句类似&#123;&#123; with PIPELINE &#125;&#125; # restricted scope&#123;&#123; end &#125;&#125; 范围可以被更改。with可以允许你将当前范围(.)设置为特定对象。例如，我们使用.Values.favorite工作。让我们在.Values.favorite范围来重写ConfigMap： 12345678910apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" &#123;&#123;- with .Values.favorite &#125;&#125; drink: &#123;&#123; .drink | default "tea" | quote &#125;&#125; food: &#123;&#123; .food | upper | quote &#125;&#125; &#123;&#123;- end &#125;&#125; 12# 注意，由于我们使用 with 将范围设置在了 .Values.favorite# 所以我们使用 .drink, .food。范围在 &#123;&#123; end &#125;&#125; 后被还原 但这里有一个值得注意的问题！在限制的范围内，你将无法从父对象范围(.)访问其它对象。以下示例会失败： 123456&#123;&#123;- with .Values.favorite &#125;&#125;drink: &#123;&#123; .drink | default "tea" | quote &#125;&#125;food: &#123;&#123; .food | upper | quote &#125;&#125;release: &#123;&#123; .Release.Name &#125;&#125;&#123;&#123;- end &#125;&#125;release-2: &#123;&#123; .Release.Name &#125;&#125; 由于Release.Name没有在限制的范围(.)内，会报错。但在限制的之外就没有问题。 或者，我们可以使用`符号从父范围访问`Release.Name`对象。`符号在开始执行时会映射到根范围内，在模板执行时也不会改变。示例如下： 12345&#123;&#123;- with .Values.favorite &#125;&#125;drink: &#123;&#123; .drink | default "tea" | quote &#125;&#125;food: &#123;&#123; .food | upper | quote &#125;&#125;release: &#123;&#123; $.Release.Name &#125;&#125;&#123;&#123;- end &#125;&#125; 在了解range后，我们会看到模板变量，它提供了一个解决上述作用域问题的方法。 range循环Looping with the range action 许多编程语言都是用for循环，在Helm模板语言中，它使用range操作符来实现迭代。 首先，让我们在values.yaml文件里添加一个列表。 12345678favorite: drink: coffee food: pizzapizzaToppings: - mushrooms - cheese - peppers - onions 在我们的ConfigMap中获取值里面的列表： 1234567891011121314apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" &#123;&#123;- with .Values.favorite &#125;&#125; drink: &#123;&#123; .drink | default "tea" | quote &#125;&#125; food: &#123;&#123; .food | upper | quote &#125;&#125; &#123;&#123;- end &#125;&#125; toppings: |- &#123;&#123;- ranage .Values.pizzaToppings &#125;&#125; - &#123;&#123; . | title | quote &#125;&#125; &#123;&#123;- end &#125;&#125; 我们可以使用`来访问父范围内的`Values.pizzaToppings`。`符号映射到根目录下，并在函数执行时不会改变。示例如下: 1234567891011121314apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" &#123;&#123;- with $.Values.favorite &#125;&#125; drink: &#123;&#123; .drink | default "tea" | quote &#125;&#125; food: &#123;&#123; .food | upper | quote &#125;&#125; toppings: |- &#123;&#123;- range $.Values.pizzaToppings &#125;&#125; - &#123;&#123; .| title | quote &#125;&#125; &#123;&#123;- end &#125;&#125; &#123;&#123;- end &#125;&#125; 渲染示例： 1234567891011121314# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: edgy-dragonfly-configmapdata: myvalue: "Hello World" drink: "coffee" food: "PIZZA" toppings: |- - "Mushrooms" - "Cheese" - "Peppers" - "Onions" 符号|-声明一个多行字符串。因此，实际上我们的toppings不是一个YAML list，而是一个big string。我们为什么要这样做？因为在ConfigMaps data里的数据是由键值对(k/v)组成，其中键和值都是简单的字符串。要理解为什么这样的化，请查看k8s configmap文档。 YAML里的|-符号表示一个多行字符串(multi-line string)。这可以在文件中嵌入一大块数据。 Helm模板具有一个tuple函数，来使得操作更简单。让我想起了Python中的tuple数据类型。示例如下: 1234sizes: |- &#123;&#123;- range ruple "small" "medium" "large"&#125;&#125; - &#123;&#123; . &#125;&#125; &#123;&#123;- end &#125;&#125; 结果如下： 1234sizes: |- - small - medium - large 除了list和tuple，range还可以迭代具有有键值对的map和dict。我们将在后面的章节中了解它们。 变量Variables: https://helm.sh/docs/chart_template_guide/variables/ 我们可以在模板中使用变量。在Helm模板中，变量是其它对象的命名引用。 123456789101112apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Releae.Name &#125;&#125;-configmapdata: myvalue: "Hello World" &#123;&#123;- $relname := .Release.Name -&#125;&#125; &#123;&#123;- with .Values.favorite &#125;&#125; drink: &#123;&#123; .drink | default "tea" | quote &#125;&#125; food: &#123;&#123; .food | upper | quote &#125;&#125; release: &#123;&#123; $relname &#125;&#125; &#123;&#123;- end &#125;&#125; 在with块之前，我们赋值了一个变量。在with块内，$relname变量仍然指向版本名称。 在range循环中使用变量： 1234toppings: |- &#123;&#123;- range $index, $topping := .Values.pizzaToppings &#125;&#125; &#123;&#123; $index &#125;&#125;: &#123;&#123; $topping &#125;&#125; &#123;&#123;- end &#125; 渲染效果： 12345toppings: |- 0: mushrooms 1: cheese 2: peppers 3: onions 有一个变量($)它永远是全局的，此变量将永远指向根上下文(root context)。放你使用range循环，并且需要知道chart的版本名称时，这非常有用。示例如下： 123456789101112131415161718192021&#123;&#123;- range .Values.tlsSecrets &#125;&#125;apiVersion: v1kind: Secretmetadata: name: &#123;&#123; .name &#125;&#125; labels: # Many helm templates would use `.` below, but that will not work, # however `$` will work here app.kubernetes.io/name: &#123;&#123; template "fullname" $ &#125;&#125; # I cannot reference .Chart.Name, but I can do $.Chart.Name helm.sh/chart: "&#123;&#123; $.Chart.Name &#125;&#125;-&#123;&#123; $.Chart.Version &#125;&#125;" app.kubernetes.io/instance: "&#123;&#123; $.Release.Name &#125;&#125;" # Value from appVersion in Chart.yaml app.kubernetes.io/version: "&#123;&#123; $.Chart.AppVersion &#125;&#125;" app.kubernetes.io/managed-by: "&#123;&#123; $.Release.Service &#125;&#125;"type: kubernetes.io/tlsdata: tls.crt: &#123;&#123; .certificate &#125;&#125; tls.key: &#123;&#123; .key &#125;&#125;---&#123;&#123;- end &#125;&#125; 到目前为止，我们已看到了只在一个文件中声明的模板。但是Helm模板语言的一个强大功能是声明多个模板和使用它们。我们将在后面的章节了解到。 命名模板Named Templates: https://helm.sh/docs/chart_template_guide/named_templates/ 是时候使用多个模板了。本章中，我们将在一个文件中命名模板，然后在其它地方使用它们。这让我想起了Python写Web是的模板。命名模板（有时称为子模板）是在文件中定义的一个简单的模板。有两种方法来创建它，有几种不同的方法来使用它。 在流程控制(flow control)章节，我们介绍了define, template, block这三个声明和管理模板的动作。在本章中，我们将讨论这三种动作，并引入一种特殊目的的include函数。 命名模板的一个重要细节：模板名称是全局的。如果声明了两个相同名称的模板，whichever one is loaded last will be the one used. 由于subcharts中的模板与顶级模板一起编译，你应该小心命名。 123# 一种流行的命名约定是使用chart名作为前缀：&#123;&#123; define &quot;mychart.labels&quot; &#125;&#125;# 通过使用特定的chart名称作为前缀，我们可以避免相同模板名称所带来的冲突 下划线文件Partials and _ files 目前为止，我们使用的一个文件中包含一个模板。但是Helm模板语言允许你创建命名嵌套模板，可通过名称在其它任何地方进行访问。 在我们开始编写这些模板之前，我们需要注意一下命名规范： templates/下的大多数文件被视为包含k8s manifests NOTES.txt是一个例外 以下划线(_)开头的文件被假定为不包含k8s manifests。这些文件不会被渲染为k8s对象定义，但可在任意chart templates中使用。 这些文件用来存储特定(partials)和助手(helpers)。实际上，当我们第一次创建mychart，我们会看到_helpers.tpl文件，此文件是默认的template partials。 声明和使用模板Declaring and using templates with define and template。 define动作允许我们在一个模板文件中创建命名模板(named template)。语法如下: 123&#123;&#123; define &quot;MY.NAME &quot;&#125;&#125; # body of template here&#123;&#123; end &#125;&#125; 栗子： 123456789101112131415&#123;&#123;- define "mychart.labels" &#125;&#125; labels: generator: helm data: &#123;&#123; now | htmlDate &#125;&#125;&#123;&#123;- end &#125;&#125;apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmap &#123;&#123;- template "mychart.labels" &#125;&#125; data: myvalue: "Hello World" &#123;&#123;- range $key, $va1 := .Values.favorite &#125;&#125; &#123;&#123; $key &#125;&#125;: &#123;&#123; $va1 | quote &#125;&#125; &#123;&#123;- end &#125;&#125; 渲染之后的效果： 123456789101112# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: running-panda-configmap labels: generator: helm date: 2016-11-02data: myvalue: "Hello World" drink: "coffee" food: "pizza" define仅定义，只有在模板中调用时才会产生输出。 按照惯例，Helm charts将这些模板放在partials文件中（通常是_helpers.tpl），如： 123456&#123;&#123;/* Generate basic labels */&#125;&#125;&#123;&#123;- define &quot;mychart.labels&quot; &#125;&#125; labels: generator: helm date: &#123;&#123; now | htmlDate &#125;&#125;&#123;&#123;- end &#125;&#125; 12# 按照管理，define函数 应该有一个简单的文档块 &#123;&#123;/*...*/&#125;&#125;# 如上。然后在其它模板文件中访问它。 设置模板范围Setting the scope of a template 在上面定义的模板中，我们没有使用任何对象。让我们做些修改： 12345678&#123;&#123;/* Generate basic labels */&#125;&#125;&#123;&#123;- define &quot;mychart.labels&quot; &#125;&#125; labels: generator: helm data: &#123;&#123; now | htmlData &#125;&#125; chart: &#123;&#123; .Chart.Name &#125;&#125; version: &#123;&#123; .Chart.Version &#125;&#125;&#123;&#123;- end &#125;&#125; 上面定义的名称和版本是动态的，会根据不同的模板生成不同的值。 之前的引用并没有床底范围，因此在模板内我们不能使用.来访问任何事物。现在我们对模板加上范围: 12345apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmap &#123;&#123;- template "mychart.labels" . &#125;&#125; 注意上面在模板调用处使用的点(.)。我们可以非常容易地传递.Values或.Values.favorite或任何我们需要的范围。但是，我们需要的是顶级范围。 现在运行渲染(helm install --dry-run --debug plinking-anaco ./mychart)来预览下： 12345678910# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: plinking-anaco-configmap labels: generator: helm date: 2016-11-02 chart: mychart version: 0.1.0 includeThe include function 假设我们定义了如下一个简单模板： 1234&#123;&#123;- define &quot;mychart.app&quot; -&#125;&#125;app_name: &#123;&#123; .Chart.Name &#125;&#125;app_version: &quot;&#123;&#123; .Chart.Version &#125;&#125;&quot;&#123;&#123;- end -&#125;&#125; 一个错误的栗子： 123456789101112apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmap labels: &#123;&#123; template "mychart.app" . &#125;&#125;data: myvalue: "Hello World" &#123;&#123;- range $key, $val := .Values.favorite &#125;&#125; &#123;&#123; $key &#125;&#125;: &#123;&#123; $val | quote &#125;&#125; &#123;&#123;- end &#125;&#125;&#123;&#123; template "mychart.app" . &#125;&#125; 渲染的结果并不正确： 1234567891011121314# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: measly-whippet-configmap labels: app_name: mychartapp_version: "0.1.0+1478129847"data: myvalue: "Hello World" drink: "coffee" food: "pizza" app_name: mychartapp_version: "0.1.0+1478129847" Because the template that is substituted in has the text aligned to the right. Because template is an action, and not a function, there is no way to pass the output of a template call to other functions; the data is simply inserted inline. To work around this case, Helm provides an alternative to template that will import the contents of a template into the present pipeline where it can be passed along to other functions in the pipeline. 因为模板是靠右对齐的文本，因为template是一个动作，不是一个函数，因此无法传递调用其它函数的template的输出，数据被简单的插入内联。 现在我们需要使用ident来告诉模板正确的缩进，栗子： 123456789101112apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmap labels:&#123;&#123; include "mychart.app" . | indent 4 &#125;&#125;data: myvalue: "Hello World" &#123;&#123;- range $key, $va1 := .Values.favorite &#125;&#125; &#123;&#123; $key &#125;&#125;: &#123;&#123; $val | quote &#125;&#125; &#123;&#123;- end &#125;&#125; &#123;&#123; include "mychart.app" . | indent 2 &#125;&#125; 正确的渲染结果： 1234567891011121314# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: edgy-mole-configmap labels: app_name: mychart app_version: "0.1.0+1478129987"data: myvalue: "Hello World" drink: "coffee" food: "pizza" app_name: mychart app_version: "0.1.0+1478129987" 在Helm template中使用include对template被认为更好，这使得输出格式可以为YAML文档更好地处理。 有时候，我们想要导入内容，但不作为模板。也就是逐字导入文件。我们可以通过.Files对象访问文件来实现这一目标。 在模板内访问文件Accessing Files Inside Templates: https://helm.sh/docs/chart_template_guide/accessing_files/ Helm提供了.Files对象来访问文件。在开始模板示例之前，有些事需要注意下： 可以添加额外的文件到Helm chart。这些文件将被捆绑。要注意，charts必须小于1MB，因为k8s对象的存储限制。 某些文件无法通过.Files对象访问，通常出于安全原因 templates/目录内的文件无法访问 .helmignore中包含的文件无法访问 Charts不保留UNIX mode信息，当设计到.Files对象时，文件级别的权限对一个文件的可用性没有影响。 示例Basic example 添加三个位于mychart/目录下的文件。 12345678# config1.tomlmessage = Hello from config 1# config1.tom2message = Hello from config 2# config1.tom3message = Goodbye from config 3 在模板中访问文件： 12345678910apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: &#123;&#123;- $files := .Files &#125;&#125; &#123;&#123;- range tuple "config1.tom1" "config2.toml" "config3.toml" &#125;&#125; &#123;&#123; .&#125;&#125;: |- &#123;&#123; $files.Get .&#125;&#125; &#123;&#123;- end &#125;&#125; 123# 首先，创建了一个 $files变量 来保存.Files对象的引用# 我们同样使用 tuple函数来创建循环的文件列表# 接着打印每个文件名 &#123;&#123; . &#125;&#125;: |- 后面接着文件内容 &#123;&#123; $files.Get . &#125;&#125; 渲染效果示例： 1234567891011121314# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: quieting-giraf-configmapdata: config1.toml: |- message = Hello from config 1 config2.toml: |- message = This is config 2 config3.toml: |- message = Goodbye from config 3 路径助手Path helpers 使用文件时，对文件路径执行一些标准的操作是有用的。为了帮助处理，Helm从go path包中引入了许多函数供你使用: Base Dir Ext IsAbs Clean Glob模式Glob patterns 随着你的chart包的增长，你会发现你有一个更大的需来组织你的文件，因此我们提供了Files.Glob(pattern string)方法，以帮助提取某些文件与glob patterns的所有灵活性。 .Glob返回一个Files类型，因此你可以在返回的对象上调用任意Files方法。 123456# 示例的目录结构foo/: foo.txt foo.yamlbar/: bar.go bar.conf baz.yaml 使用Globs的多种选项： 123456&#123;&#123; $currentScope := .&#125;&#125;&#123;&#123; range $path, $_ := .Files.Glob &quot;**.yaml&quot; &#125;&#125; &#123;&#123;- with $currentScope&#125;&#125; &#123;&#123; .Files.Get $path &#125;&#125; &#123;&#123;- end &#125;&#125;&#123;&#123; end &#125;&#125; 或者： 123&#123;&#123; range $path, $_ := .Files.Glob &quot;**.yaml&quot; &#125;&#125; &#123;&#123; $.Files.Get $path &#125;&#125;&#123;&#123; end &#125;&#125; ConfigMap和Secrets的实用功能ConfigMap and Secrets utility functions 将文件内容放置到K8s ConfigMap或Secrets中非常常见，然后在运行的时候挂载到容器。为了帮助实现此功能，我们在Files类型上提供了几种实用的方法： AsCoinfig AsSecrets 栗子： 1234567891011121314apiVersion: v1kind: ConfigMapmetadata: name: confdata:&#123;&#123; (.Files.Glob "foo/*").AsConfig | indent 2 &#125;&#125;---apiVersion: v1kind: Secretmetadata: name: very-secrettype: Opaquedata:&#123;&#123; (.Files.Glob "bar/*").AsSecrets | indent 2 &#125;&#125; 编码Encoding 你可以导入一个文件，并实用base64编码来确保成功传输： 12345678apiVersion: v1kind: Secretmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-secrettype: Opaquedata: token: |- &#123;&#123; .Files.Get "config1.toml" | b64enc &#125;&#125; 渲染后的效果： 123456789# Source: mychart/templates/secret.yamlapiVersion: v1kind: Secretmetadata: name: lucky-turkey-secrettype: Opaquedata: token: |- bWVzc2FnZSA9IEhlbGxvIGZyb20gY29uZmlnIDEK 行Lines 有时候需要在模板中访问一个文件中的每行内容。我们为此提供了Lines方法。 示例： 123data: some-file.txt: &#123;&#123; range .Files.Lines "foo/bar.txt" &#125;&#125; &#123;&#123; . &#125;&#125;&#123;&#123; end &#125;&#125; NOTES.txtCreating a NOTES.txt File: https://helm.sh/docs/chart_template_guide/notes_files/ 在helm install或helm upgrade结束，Helm可以为用户打印一块有用的信息。此信息使用模板且高度可定制。 要为你的chart包添加安装说明，简单地创建一个templates/NOTES.txt文件。此文件是纯文本文件，但它像作为模板一样处理，并可访问所有正常模板函数和对象。 NOTES.txt文件示例： 1234567Thank you for installing &#123;&#123; .Chart.Name &#125;&#125;Your release is named &#123;&#123; .Release.Name &#125;&#125;To learn more about the release, try: $ helm status &#123;&#123; .Release.Name &#125;&#125; $ helm get all &#123;&#123; .Release.Name &#125;&#125; 接下来运行： 123456789101112131415161718192021helm install rude-cardinal ./mychartRESOURCES:==&gt; v1/SecretNAME TYPE DATA AGErude-cardinal-secret Opaque 1 0s==&gt; v1/ConfigMapNAME DATA AGErude-cardinal-configmap 3 0sNOTES:Thank you for installing mychart.Your release is named rude-cardinal.To learn more about the release, try: $ helm status rude-cardinal $ helm get all rude-cardinal 强烈建议创建NOTES.txt文件，以帮助用户获得chart包的有用信息。 SubchartsSubcharts and Global Values: https://helm.sh/docs/chart_template_guide/subcharts_and_globals/ 之前我们只有一个chart，但charts可能会有依赖(dependencies)，称为subcharts。subcharts也有自己的值和模板。本章我们将会创建subchart，并看看我们可以从模板访问值的不同的方式。 subcharts的一些重要详情： 一个subchart被认为是独立的(stand-alone)，这意味着一个subchart不能明确依赖它的parent chart 出于此原因，subchart不能访问parent chart的值 parent chart可以覆盖subcharts的值 Helm有一个全局值(global values)的概念，这些全局值可被所有charts访问 创建一个subchartCreating a Subchart 12345cd mychart/chartshelm create mysubchartrm -rf mysubchart/templates/*.* 对subchart添加值和模板Adding Values and a Template to the Subchart 为subchart添加一个简单的值和模板： 12# values.yamldessert: cake 123456apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-cfgmap2data: dessert: &#123;&#123; .Values.dessert &#125;&#125; 因为每个subchart都是独立的chart，我们可以测试mysubchart： 123456789101112131415helm install --generate-name --dry-run --debug mychart/charts/mysubchartSERVER: "localhost:44134"CHART PATH: /Users/mattbutcher/Code/Go/src/helm.sh/helm/_scratch/mychart/charts/mysubchartNAME: newbie-elkTARGET NAMESPACE: defaultCHART: mysubchart 0.1.0MANIFEST:---# Source: mysubchart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: newbie-elk-cfgmap2data: dessert: cake 从parent chart覆盖值现在，mychart是mysubchart的parent chart。因为mychart是parent chart，我们可以在mychart中指定配置，并将配置推送到mysubchart中。 123456789101112# mychart/values.yamlfavorite: drink: coffee food: pizzapizzaToppings: - mushrooms - cheese - peppers - onionsmysubchart: dessert: ice cream 我们在parent chart(mychart)的值文件里添加了mysubchart的值，mysubchart这部分值会发送到mysubchart包，这回覆盖mysubchart的值。 123456789helm install --dry-run --debug mychart# Source: mychart/charts/mysubchart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: unhinged-bee-cfgmap2data: dessert: ice cream 全局值Global Chart Values 有时候你需要将值提供给所有模板，这可以使用全局值(global chart values)。全局值可被任意chart或subchart通过相同的名称来访问。全局需要明确地声明。 值数据类型保留在称为Values.global的区域，此区域可以设置全局值。 12345678910111213141516# mychart/values.yamlfavorite: drink: coffee food: pizzapizzaToppings: - mushrooms - cheese - peppers - onionsmysubchart: dessert: ice creamglobal: salad: caesar 12345678# 任意chart和subchart都可以使用 &#123;&#123; .Values.global.salad &#125;&#125; 来访问这个值# mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: salad: &#123;&#123; .Values.global.salad &#125;&#125; 12345678# mysubchart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-cfgmap2data: dessert: &#123;&#123; .Values.dessert &#125;&#125; salad: &#123;&#123; .Values.global.salad &#125;&#125; 渲染输出效果： 1234567891011121314151617# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: silly-snake-configmapdata: salad: caesar---# Source: mychart/charts/mysubchart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: silly-snake-cfgmap2data: dessert: ice cream salad: caesar 共享模板Sharing Templates with Subcharts parent charts和subcharts可以共享模板。任意在chart中定义的block(块)都可以被其它charts所使用。 定义一个简单的模板栗子： 1&#123;&#123;- define "labels" &#125;&#125;from: mychart &#123;&#123; end &#125;&#125; 尽管chart开发者可以在include和template之间选择，但使用include的优点是它可以动态引用模板： 1&#123;&#123; include $mytemplate &#125;&#125; 上面间接引用$mytemplate。template函数，相反它只接受一个字符串。 避免使用块Avoid Using Blocks go模板语言提供了一个block关键字，来允许开发者提供一个覆盖的默认实现。在Helm chart中，块(block)并不是覆盖的最佳工具，因为如果提供了相同块的多个实现，选择的那个是不可预测的。 建议使用include来代替。 .helmignoreThe .helmignore file: https://helm.sh/docs/chart_template_guide/helm_ignore_file/ .helmignore也就类似于.gitignore, .dockerignore，指定不需要包含在chart包中的文件。 如果此文件存在，helm package命令将忽略.helmignore里面匹配到的文件打包到应用的包里。 一个.helmignore文件的栗子： 12345678910111213141516171819202122232425# comment# Match any file or path named .git.git# Match any text file*.txt# Match only directories named mydirmydir/# Match only text files in the top-level directory/*.txt# Match only the file foo.txt in the top-level directory/foo.txt# Match any file named ab.txt, ac.txt, or ad.txta[b-d].txt# Match any file under subdir matching temp**/temp**/*/temp*temp? 模板调试Debugging Templates: https://helm.sh/docs/chart_template_guide/debugging/ 有几个命令可帮助调试模板： helm lint: 验证chart最佳实践的工具 helm install --dry-run --debug或helm template --debug：渲染模板并返回k8s manifest文件 helm get manifest：查看安装了哪些模板 YAML技巧YAML Techniques: https://helm.sh/docs/chart_template_guide/yaml_techniques/ Helm命令Helm Commands: https://helm.sh/docs/helm/ 社区指南Community Guides: https://helm.sh/docs/community/ FAQFrequently Asked Questions: https://helm.sh/docs/faq/]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Helm</tag>
        <tag>K8s</tag>
        <tag>CNCF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go]]></title>
    <url>%2F2020%2F07%2F22%2FGo%2F</url>
    <content type="text"><![CDATA[参考: github: https://github.com/golang/go Docs: https://golang.org/doc/ awesome-go: https://github.com/avelino/awesome-go 版本: go v1.14 介绍Go编程语言是一个开源项目，使开发人员更高效。 Go是传神，简洁，干净，高效的。它的并发机制(concurrency mechanisms)可充分利用多核和网络机器编写程序，它的新颖类型系统允许灵活和模块化结构。它是一个快速、静态类型、编译型语言，像一个动态类型、解释型语言。 安装下载对应平台的二进制包，解压，添加路径。 测试安装: 1234567package mainimport "fmt"func main() &#123; fmt.Printf("hello, world\n")&#125; 1234# 编译go build hello.go# 执行./hello 安装其它版本: 123go get golang.org/dl/go1.10.7go1.10.7 version 学习 旅程Tour: https://tour.go-zh.org/list 交互式地分三部分介绍Go： 基本语法和数据结构 方法和接口 并发原语(concurrency primitives) 可在线上或本地开启旅程： 线上: https://tour.golang.org/welcome/1 本地: go get golang.org/x/tour，会在go path的bin/tour。 sandbox.go测试程序显示时间： 1234567891011package mainimport ( "fmt" "time")func main() &#123; fmt.Println("Welcomt to the playground!") fmt.Println("The time is", time.Now())&#125; 基础语法学习go程序的基本结构。 包每个go程序都是由包构成。程序从main包开始运行。 按照约定，包名与导入路径的最后一个元素一致。例如，math/rand包中的源码均以package rand语句开始。 123456789101112// package.gopackage main// 导入两个包import ( "fmt" "math/rand")func main() &#123; fmt.Println("My favorite number is", rand.Intn(10))&#125; 导入使用圆括号进行分组导入，也可以编写多个导入语句。分组导入语句是更好的形式。 12345678910// 分组导入import ( "fmt" "math")// 单独导入import "fmt"import "math" 导出名在Go中，如果一个名字以大写字母，那么它就是已导出的。 在导入一个包时，你只能引用其中已导出的名字。任何未导出的名字在该包外均无法访问。 12345678910111213// exporter-nams.gopackage mainimport ( "fmt" "math")func main() &#123; fmt.Println(math.pi) //fmt.Println(math.Pi)&#125; 123456运行math.pi会报错./prog.go:9:14: cannot refer to unexported name math.pi./prog.go:9:14: undefined: math.pi运行math.Pi3.141592653589793 函数函数可以没有参数或接受多个参数。注意类型在变量名之后。 1234567891011121314// functions.gopackage mainimport "fmt"func add(x int, y int) int &#123; return x + y&#125;// 省略模式: x, y intfunc main() &#123; fmt.Println(add(42, 13))&#125; 多值返回函数可以返回任意数量的返回值。 123456789101112// multiple-results.goimport "fmt"func swap(x, y string) (string, string) &#123; return y, x&#125;func main() &#123; a, b := swap("hello", "world") fmt.Println(a, b)&#125; 命名返回值go的返回值可被命名，它们会被视作定义在函数顶部的变量。返回值的名称应当具有一定的意义。 没有参数的return语句返回已命名的返回值，也就是直接返回。直接返回语句应当仅在短函数中，在长函数中会影响代码的可读性。 123456789101112131415// name-result.gopackage mainimport "fmt"func split(sum int) (x, y int) &#123; x = sum * 4 / 9 y = sum -x return&#125;func main() &#123; fmt.Println(split(17))&#125; 变量var语句用于声明一个变量列表。 123456789101112// variables.gopackage mainimport "fmt"var c, python, java boolfunc main() &#123; var i int fmt.Println(i, c, python, java)&#125; 变量初始化变量声明可以包含初始值。如果初始化值已存在，则可以省略类型，变量会从初始值中获得类型。 123456789101112// var-ini.gopackage mainimpoort "fmt"var i, j, int = 1, 2func main() &#123; var c, python, java = true, false, "no!" fmt.Println(i, j, c, python, java)&#125; 短变量声明在函数中，简洁赋值语句:=可在类型明确的地方代替var声明。 函数外的每个语句都必须以关键字(var, func…)开始，因此:=结构不能在函数外使用。 12345678910111213// short-var-declarations.gopackage main()import "fmt"func main() &#123; var i, j int = 1, 2 k := 3 c, python, java := true, false, "no!" fmt.Println(i, j, k, c, python, java)&#125; 数据类型go的基本类型有： bool string int, int8, int16, int32, int64 uint, uint8, uint16, uint32, uint64, uintptr byte(uint8的别名) rune(int32的别名，表示一个unicode码点) float32, float64 complex64, complex128 int, uint 和 uintptr 在 32 位系统上通常为 32 位宽，在 64 位系统上则为 64 位宽。 当你需要一个整数值时应使用 int 类型，除非你有特殊的理由使用固定大小或无符号的整数类型。 1234567891011121314151617181920// basic-types.gopackage mainimport ( "fmt" "math/cmplx")var ( ToBe bool = false MaxInt uint64 = 1&lt;&lt;64 - 1 x complex128 = cmplx.Sqrt(-5 ++ 12i))func main() &#123; fmt.Printf("Type: %T Value: %v\n", ToBe, ToBe) fmt.Printf("Type: %T Value: %v\n", MaxInt, MaxInt) fmt.Printf("Type: %T Value: %v", z, z)&#125; 零值没有明确初始值的变量声明会被赋予它们的零值。 零值是: 数值类型为 0 布尔类型为 false 字符串为空字符串 12345678910111213// zero.gopackage mainimport "fmt"func main() &#123; var i int var f float64 var b bool var s string fmt.Printf("%v %v %v %q\n", i, f, b, s)&#125; 类型转换T(v)将v转换为T类型。 123456789101112131415// type-conversions.gopackage mainimport ( "fmt" "math")func main() &#123; var x, y int = 3, 4 var f float64 = math.Sqrt(float64(x*x + y*y)) var z unit = unit(f) fmt.Println(x, y, z)&#125; 类型推导在声明一个变量而不指定其类型时，变量的类型由右值推导而出。 12345678910// type-inference.gopackage mainimport "fmt"func main() &#123; v := 42 // int fmt.Printf("v is of type %T\n", v)&#125; 常量常量的声明与变量类似，只不过使用const关键字。 常量可以是字符、字符串、布尔值、数值。 常量不能用:=语法声明。 12345678910111213141516// constants.gopackage mainimport "fmt"const Pi = 3.14func main() &#123; const World = "世界" fmt.Println("Hello", World) fmt.Println("Happy", Pi, "Day") const Truth = true fmt.Println("Go rules?" Truth)&#125; 数值常量数值常量是高精度的值。一个未指定类型的常量由上下文来决定其类型。 123456789101112131415161718192021// nemeric-constants.gopackage mainimport "fmt"const ( // 将1左移100位来创建一个非常大的数字，即这个数的二进制是1后面跟着100个0 Big = 1 &lt;&lt; 100 // 再往右移99位，即Small = 1 &lt;&lt; 1，或Small = 2 Small = Big &gt;&gt; 99)func needInt(x int) int &#123; return x*10 + 1&#125;func needFloat(x float64) float64 &#123;return x * 0.1&#125;func main() &#123; fmt.Println(needInt(Small)) fmt.Println(needFloat(Small)) fmt.Println(needFloat(Big))&#125; 流程控制flowcontrol: https://tour.go-zh.org/flowcontrol 学习如何使用条件、循环、分支和推迟语句来控制代码的流程。 forgo只有一种循环结构: for循环。它由三部分组成： 初始化语句： 在第一次迭代前执行 条件表达式：在每次迭代前求值 后置语句： 在每次迭代的结尾执行 初始化语句和后置语句是可选的。 初始化语句通常为一句短变量声明，该变量声明仅在for语句的作用域中可见。一旦条件表达式的布尔值为false，循环迭代就会终止。 12345678910111213// for.gopackage mainimport "fmt"func main() &#123; sum := 0 for i := 0; i &lt; 10; i++ &#123; sum += i &#125; fmt.Println(sum)&#125; 12345678910111213// for-continued.gopackage mainimport "fmt"func main() &#123; sum := 1 for ; sum &lt; 1000; &#123; sum += sum &#125; fmt.Println(sum)&#125; for是whilego的for就是while。 12345678910111213// for-is-while.gopackage mainimport "fmt"func main() &#123; sum := 1 for sum &lt; 1000 &#123; sum += sum &#125; fmt.Println(sum)&#125; 无限循环如果省略循环条件，该循环就不会结束，因此无限循环可以写的很紧凑。 1234567// forever.gopackage mainfunc main() &#123; for &#123;&#125;&#125; if12345678910111213141516171819// if.gopackage mainimport ( "fmt" "math")func sqrt(x float64) string &#123; if x &lt; 0 &#123; return sqrt(-x) + "i" &#125; return fmt.Sprint(math.Sqrt(x))&#125;func main() &#123; fmt.Println(sqrt(2), sqrt(-4))&#125; 简短的ifif语句可在条件表达式前执行一个简单的语句。该语句声明的变量作用域仅在if之内。 12345678910111213141516171819202122// if-short.gopackage mainimport ( "fmt" "math")func pow(x, n, lim float64) float64 &#123; if v := math.Pow(x, n); v &lt; lim &#123; return v &#125; return lim&#125;func main() &#123; fmt.Println( pow(3, 2, 10), pow(3, 3, 20), )&#125; else123456789101112131415161718192021222324// else.gopackage mainimport ( "fmt" "math")func pow(x, n, lim float64) float64 &#123; if v := math.Pow(x, n); v &lt; lim &#123; return v &#125; else &#123; fmt.Printf("%g &gt;= %g\n", v, lim) &#125; return lim&#125;func main() &#123; fmt.Println( pow(3, 2, 10), pow(3, 3, 20), )&#125; switchswitch是一连串的if-else语句的简单写法。它运行第一个值等于条件表达式的case语句。 1234567891011121314151617181920// switch.gopackage mainimport ( "fmt" "runtime")func main() &#123; fmt.Print("Go runs on ") switch os := runtime.GOOS; os &#123; case "darwin": fmt.Println("OS X.") case "linux": fmt.Println("Linux.") default: fmt.Printf("%s. \n", os) &#125;&#125; switch的case语句从上到下依次执行，知道匹配成功时停止。 1234567891011121314151617181920212223// switch-order.gopackage mainimport ( "fmt" "time")func main() &#123; fmt.Println("When's Saturday?") today := time.NOw().Weekday() switch time.Saturday &#123; case today + 0: fmt.Println("Today.") case today + 1: fmt.Println("Tomorrow.") case today + 2: fmt.Println("In two days.") default: fmt.Println("Too far away.") &#125;&#125; 没有条件的switch同switch true一样。这种形式能将一长串if-then-else写得更加清晰。 1234567891011121314151617181920// switch-no-condition.gopackage mainimport ( "fmt" "time")func main() &#123; t := Now() switch &#123; case t.Hour() &lt; 12: fmt.Pringln("Good morning!") case t.Hour() &lt; 17: fmt.Println("Good afternoon.") default: fmt.Println("Good evening.") &#125;&#125; deferdefer语句会将函数推迟到外层函数返回之后执行。 推迟调用的函数其参数会立即求值，但直到外层函数返回前该函数都不会被调用。 1234567891011// defer.gopackage mainimport "fmt"func main() &#123; defer fmt.Println("world") fmt.Pringln("hello")&#125; 推迟的函数调用会被压入一个栈中。当外层函数返回时，被推迟的函数会按照后进先出的顺序调用。 12345678910111213// defer-multi.gopackage mainimport "fmt"func main() &#123; fmt.Pringln("counting") for i := 0; i &lt; 10; i++ &#123; defer fmt.Pringln(i) &#125; fmt.Println("done")&#125; 更多类型学习如何基于现有类型定义新的类型，包含结构体、数组、切片和映射。 指针go拥有指针。指针保存了值的内存地址。类型*T是指向T类型值的指针。其零值位nil。&amp;操作符会生成一个指向其操作数的指针。*操作符表示指针指向的底层值。这也就是常说的间接引用和重定向。 与C不同，go没有指针运算。 123456789101112131415161718// pointers.gopackage mainimport "fmt"func main() &#123; i, j := 42, 2701 p := &amp;i // 指向i fmt.Pringln(*p) // 通过指针读取i的值 *p = 21 // 通过指针设置i的值 fmt.Pringln(i) p = &amp;j *p = *p /37 fmt.Pringln(j)&#125; 结构体一个结构体(struct)就是一组字段(field)。 1234567891011121314// structs.gopackage mainimport "fmt"type Vertex struct &#123; X int Y int&#125;func main() &#123; fmt.Println(Vertex&#123;1, 2&#125;)&#125; 结构体字段使用点号来访问。 12345678910111213141516// struct-fields.gopackage mainimport "fmt"type Vertex struct &#123; X int Y int&#125;func main() &#123; v := Vertex&#123;1, 2&#125; v.X = 4 fmt.Println(v.X)&#125; 结构体字段可以通过结构体指针来访问。 如果有一个指向结构体的指针P，那么可通过(*p).X来访问其字段X。不过这样写太啰嗦，可隐式间接引用，直接写p.X。 1234567891011121314151617// struct-pointers.gopackage mainimport "fmt"type Vertex struct &#123; X int Y int&#125;func main() &#123; v := Vertex&#123;1, 2&#125; p := &amp;v // 指针 p.X = 1e9 fmt.Println(v)&#125; 结构体文法通过直接列出字段的值来新分配一个结构体。 1234567891011121314151617181920// struct-literals.gopackage mainimport "fmt"type Vertex struct &#123; X, Y int&#125;var ( v1 = Vertex&#123;1, 2&#125; // 创建一个Vertex类型的结构体 v2 = Vertex&#123;X: 1&#125; // Y:0被隐式地赋予 v3 = Vertex&#123;&#125; // X:0 Y:0 p = &amp;Vertex&#123;1, 2&#125; // 创建一个*Vertex类型的结构体(指针))func main() &#123; fmt.Println(v1, p, v2, v3)&#125; 数组类型[n]T表示拥有n个T类型的值的数组。 数组的长度是其类型的一部分，因此数组不能改变大小。 12345678910111213141516// array.gopackage mainimport "fmt"func main() &#123; var a [2]string a[0] = “Hello" a[1] = "World" fmt.Pringln(a[0], a[1]) fmt.Println(a) primes := [6]int&#123;2, 3, 5, 7, 11, 13&#125; fmt.Println(primes)&#125; 切片每个数组大小都是固定的，而切片则为数组元素提供动态大小的、灵活的视角。在实践中，切片比数组更常用。 类型[]T表示一个元素类型为T的切片。 123456789101112// slices.gopackage mainimport "fmt"func main() &#123; primes := [6]int&#123;2, 3, 5, 7, 11, 13&#125; var s []int = primes[1:4] fmt.Println(s)&#125; 切片并不存储任何数据，它只是描述了底层数组中的一段。更改切片的元素会修改其底层数组中对应的元素。与它共享底层数组的切片都会观测到这些修改。 123456789101112131415161718// slices-pointers.gopackage mainimport "fmt"func main() &#123; names := [4]string&#123;"John", "Paul", "George", "Ringo",&#125; fmt.Println(names) a := names[0:2] b := names[1:3] fmt.Pringln(a, b) b[0] = "XXX" fmt.Pringln(a, b) fmt.Pringln(names)&#125; 切片文法类似于没有长度的数组文法。 1234567891011121314151617181920212223242526// slice-literals.gopackage mainimport "fmt"func main() &#123; q := []int&#123;2, 3, 5, 7, 11, 13&#125; // 创建一个数组，并构建一个引用数组的切片 fmt.Pringln(q) r := []bool&#123;true, false, true, true, false, true&#125; fmt.Pringln(r) s := []struct &#123; i int b bool &#125; &#123; &#123;2, true&#125;, &#123;3, false&#125;, &#123;5, true&#125;, &#123;7, true&#125;, &#123;11, false&#125;, &#123;13, true&#125;, &#125; fmt.Pringln(s)&#125; 在进行切片时，你可以利用它的默认行为来忽略上下界。 切片拥有长度和容量。切片的长度就是它所包含的元素个数。切片的容量从第一个元素开始数，到元素末尾的个数。 可通过len()和cap()来获取。 1234567891011121314151617181920212223242526// slice-len-cap.gopackage mainimport "fmt"func main() &#123; s := []int&#123;2, 3, 5, 7, 11, 13&#125; printSlice(s) // 截取切片使其长度为0 s = s[:0] printSlice(s) // 扩展长度 s = s[:4] printSlice(s) // 舍弃前两个值 s = s[2:] printSlice(s)&#125;func printSlice(s []int) &#123; fmt.Printf("len=%d cap=%d %v\n", len(s), cap(s), s)&#125; 切片的零值nil。nil切片的长度和容量为0且没有底层数组。 12345678910111213// nil-slices.gopackage mainimport "fmt"func main() &#123; var s []int fmt.Println(s, len(s), cap(s)) if s == nil &#123; fmt.Pringln("nil!") &#125;&#125; 切片可以使用内建函数make来创建，这也是创建动态数组的方式。make函数会分配一个元素为零值的数组并返回一个引用了它的切片。 123456789101112131415161718192021222324// making-slices.gopackage mainimport "fmt"func main() &#123; a := make([]int, 5) PrintSlice("a", a) b := make([]int, 0, 5) printSlice("b", b) c := b[:2] printSlice("c", c) d := c[2:5] printSlice("d", d)&#125;func printSlice(s string, x []int) &#123; fmt.Printf("%s lend=%d cap=%d %v\n", s, len(x), cap(x), x)&#125; 切片可包含任何类型，甚至包括其他切片。 12345678910111213141516171819202122232425262728// slices-of-slices.gopackage mainimport ( "fmt" "STRINGS")func main() &#123; // 创建一个井字板 board := [][]string&#123; []string&#123;"_", "_", "_"&#125;, []string&#123;"_", "_", "_"&#125;, []string&#123;"_", "_", "_"&#125;, &#125; // 两个玩家轮流打上 x和o board[0][0] = "X" board[2][2] = "O" board[1][2] = "X" board[1][0] = "O" board[0][2] = "X" for i := 0; i &lt; len(board); i++ &#123; fmt.Printf("%s\n", strings.Join(board[i], " ")) &#125;&#125; 向切片追加新的元素是常用的操作，为此go提供了内建的append函数。 12345678910111213141516171819202122232425// append.gopackage mainimport "fmt"func main() &#123; var s []int printSlice(s) // 添加一个空切片 s = append(s, 0) printSlice(s) s = append(s, 1) printSlice(s) // 一次性添加多个元素 s = append(s, 2, 3, 4) printSlice(s)&#125;func printSlice(s []int) &#123; fmt.Printf("len=%d cap=%d %v\n", len(s), cap(s), s)&#125; rangefor循环的range形式可以遍历切片或映射。 1234567891011121314// range.gopackage mainimport "fmt"var pow = []int&#123;1, 2, 4, 8, 16, 32, 64, 128&#125;func main() &#123; // 下标，元素副本 for i, v := range pow &#123; fmt.Printf("2**%d = %d\n", i, v) &#125;&#125; 可将下标或值赋予下划线(_)来忽略它。 123456for i, _ := range powfor _, value := range pow# 若只要索引，忽略第二个变量即可for i := range pow 123456789101112131415// range-continued.gopackage mainimport "fmt"func main() &#123; pow := make([]int, 10) for i := range pow &#123; pow[i] = 1 &lt;&lt; uint(i) // == 2**i &#125; for _, value := range pow &#123; fmt.Printf("%s\n", value) &#125;&#125; 映射映射将键映射到值。映射的零值为nil。nil映射既没有键，也不能添加键。make函数会返回给定类型的映射，并将其初始化备用。 12345678910111213141516171819// maps.gopackage mainimport "fmt"type Vertex struct &#123; Lat, Long float64&#125;var m map[string]Vertexfunc main() &#123; m = make(map[string]Vertex) m["Bell Labs"] = Vertex&#123; 40.68433, -74.39967, &#125; fmt.Println(m["Bell Labs"])&#125; 映射的文法与结构体类似，不过必须有键名。 123456789101112131415161718// map-literals.gopackage mainimport "fmt"type Vertex struct &#123; Lat, Long float64&#125;var m = map[string]Vertex&#123; "Bell Labs": Vertex&#123;40.68433, -74.39967,&#125;, "Google": Vertex&#123;37.42202, -122.08408&#125;,&#125;func main() &#123; fmt.Println(m)&#125; 若顶级类型只有一个类型名，可以在文法的元素中省略它。 123456789101112131415161718// map-literals-continued.gopackage mainimport "fmt"type Vertex struct &#123; Lat, Long float64&#125;var m = map[string]Vertex&#123; "Bell Labs": &#123;40.68433, -74.39967&#125;, "Google": &#123;37.42202, -122.08408&#125;,&#125;func main() &#123; fmt.Println(m)&#125; 可对映射进行增删查改。 123456789101112# 插入或修改m[key] = elem# 获取elem = m[key]# 删除delete(m, key)# 通过双赋值检测某个键是否存在elem, ok = m[key]# 若 key 在 m 中，ok 为 true ；否则，ok 为 false。# 若 key 不在映射中，那么 elem 是该映射元素类型的零值。# 当从映射中读取某个不存在的键时，结果是映射的元素类型的零值。 123456789101112131415161718192021// mutating-maps.gopackage mainimport "fmt"func main() &#123; m := make(map[string]int) m["Answer"] = 42 fmt.Println("The value:", m["Answer"]) m["Answer"] = 48 fmt.Println("The value:", m["Answer"]) delete(m, "Answer") fmt.Println("The value:", m["Answer"]) v, ok := m["Answer"] fmt.Println("The value:", v, "Present?", ok)&#125; 函数值函数也是值。它们可以像其它值一样传递。 函数值可以用作函数的参数或返回值。 12345678910111213141516171819202122// function-values.gopackage mainimport ( "fmt" "math")func compute(fn func(float64, float64) float64) float64 &#123; return fn(3, 4)&#125;func main() &#123; hypot := func(x, y float64) float64 &#123; return math.Sqrt(x*x + y*y) &#125; fmt.Println(hypot(5, 12)) fmt.Println(compute(hypot)) fmt.Println(compute(math.Pow))&#125; 函数的闭包go函数可以是一个闭包。闭包是一个函数值，它引用了其函数体之外的变量。该函数可以访问并赋予其引用的变量的值，换句话说，该函数被这些变量绑定在一起。 例如，函数adder返回一个闭包。每个闭包都被绑定在其各自的sum变量上。 1234567891011121314151617181920212223// functtion-closures.gopackage mainimport "fmt"func adder() func(int) int &#123; sum := 0 return func(x int) int &#123; sum += x return sum &#125;&#125;func main() &#123; pos, neg := adder(), adder() for i := 0; i &lt; 10; i++ &#123; fmt.Println( pos(i), neg(-2*i), ) &#125;&#125; 斐波那契闭包 12345678910111213141516// fibonacci-closure.gopackage mainimport "fmt"// 返回一个int函数func fibonacci() func() int &#123;&#125;func main() &#123; f := fibonacci() for i := 0; i &lt; 10; i++ &#123; fmt.Println(f()) &#125;&#125; 方法和接口docs: https://tour.go-zh.org/methods/1 包含方法和接口，可以用这种构造来定义对象及其行为。 方法go没有类。 不过你可以为结构体类型定义方法。方法就是一类带特殊的接收者参数的函数。方法接收者在它自己的参数列表内，位于func关键字和方法名之间。 12345678910111213141516171819202122// methods.gopackage mainimport ( "fmt" "math")type Vertex struct &#123; X, Y float64&#125;// Abs方法拥有一个名为v，类型为Vertex的接收者func (v Vertex) Abs() float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;func main() &#123; v := Vertex&#123;3, 4&#125; fmt.Println(v.Abs())&#125; 方法只是个带接收者参数的函数。 123456789101112131415161718192021// metheods-funcs.gopackage mainimport ( "fmt" "math")type Vertex struct &#123; X, Y float&#125;func Abs(v Vertex) float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;func main() &#123; v := Vertex(3, 4) fmt.Println(Abs(v))&#125; 也可以为非结构体类型声明方法。接收者的类型定义和方法声明必须在同一包内，不能为内建类型声明方法。 12345678910111213141516171819202122// methods-continued.gopackage mainimport ( "fmt" "math")type MyFloat float64func (f MyFloat) Abs() float64 &#123; if f &lt; 0 &#123; return float64(-f) &#125; return float64(f)&#125;func main() &#123; f := MyFloat(-math.Sqrt2) fmt.Println(f.Abs())&#125; 指针接收者可以为指针接收者声明方法。 123456789101112131415161718192021222324252627// methods-pointers.gopackage mainimport ( "fmt" "math")type Vertex struct &#123; X, Y float64&#125;func (v, Vertex) Abs() float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;func (v *Vertex) Scale(f float64) &#123; v.X = v.X * f v.Y = v.Y * f&#125;func main() &#123; v := Vertex&#123;3, 4&#125; v.Scale(10) fmt.Println(v.Abs())&#125; 指针与函数123456789101112131415161718192021222324252627// methods-pointers-explained.gopackage mainimport ( "fmt" "math")type Vertex struct &#123; X, Y float64&#125;func Abs(v Vertex) float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;func Scale(v *Vertex, f float64) &#123; v.X = v.X * f x.Y = x.Y * f&#125;func main() &#123; v := Vertex&#123;3, 4&#125; Scale(&amp;v, 10) fmt.Println(Abs(v))&#125; 方法与指针重定向12345678910111213141516171819202122232425262728293031// indirection.gopackage mainimport "fmt"type Vertex struct &#123; X, Y float64&#125;func (v *Vertex) Scale(f float64) &#123; v.X = v.X * f x.Y = v.Y * f&#125;func ScaleFunc(v *Vertex, f float64) &#123; v.X = V.X * f v.Y = v.Y * f&#125;func main() &#123; v := Vertex&#123;3, 4&#125; v.Scale(2) ScaleFunc(&amp;v, 10) p := &amp;Vertex&#123;4, 3&#125; p.Scale(3) ScaleFunc(p, 8) fmt.Println(v, p)&#125; 123456789101112131415161718192021222324252627282930// indirection-values.gopackage mainimport ( "fmt" "math")type Vertex struct &#123; X, Y float64&#125;func (v Vertex) Abs() float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;func AbsFunc(v Vertex) float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;func main() &#123; v := Vertex&#123;3, 4&#125; fmt.Println(v.Abs()) fmt.Println(AbsFunc(v)) p := &amp;Vertex&#123;4, 3&#125; fmt.Println(p.Abs()) fmt.Println(AbsFunc(*p))&#125; 选择值或指针作为接收者使用指针接收者的原因有二： 方法能够修改其接收者指向的值 可以避免在每次调用方法时复制该值。若值的类型为大型结构体时，这样做会更加高效 12345678910111213141516171819202122232425262728// methods-pointer-receivers.gopackage mainimport ( "fmt" "math")type Vertex struct &#123; X, Y float64&#125;func (v *Vertex) Scale(f float64) &#123; v.X = v.X * f v.Y = v.Y * f&#125;func (v *Vertex) Abs() float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;func main() &#123; v := &amp;Vertex&#123;3, 4&#125; fmt.Printf("Before scaling: %+v, Abs: %v\n", v, v.Abs()) v.Scale(5) fmt.Printf("After scaling: %+v, Abs: %v\n", v, v.Abs())&#125; 接口接口类型是由一组方法签名定义的集合。接口类型的变量可以保存任何实现了这些方法的值。 类型通过实现一个接口的所有方法来实现该接口。既然无需专门显式声明，也就没有implements关键字。隐式接口从接口的实现中解耦了定义，这样接口的实现可以出现在任何包中，无需提前准备。因此，也就无需在每一个实现上增加新的接口名称，这样同时也鼓励了明确的接口定义。 1234567891011121314151617181920212223// interfaces-implicitly.gopackage mainimport "fmt"type I interface &#123; M()&#125;type T struct &#123; S string&#125;// 此方法表示类型T实现了接口I，但我们无需显式声明func (t T) M() &#123; fmt.Println(t.S)&#125;func main() &#123; var i I = T&#123;"Hello"&#125; i.M()&#125; 接口也是值。它们可以像其它值一样传递。接口值可以用作函数的参数或返回值。 在内部，接口值可以看做包含值和具体类型的元组：(value, type)。接口值保存了一个具体底层类型的具体值。接口值调用方法时会执行其底层类型的同名方法。 123456789101112131415161718192021222324252627282930313233343536373839404142// interface-values.gopackage mainimport ( "fmt" "math")type I interface &#123; M()&#125;type T struct &#123; S string&#125;func (t *T) M() &#123; fmt.Println(t.S)&#125;type F float64func (f F) M() &#123; fmt.Println(f)&#125;func main() &#123; var i I i = &amp;T["Hello"] describe(i) i.M() i = F(math.Pi) describe(i) i.M()&#125;func describe(i I) &#123; fmt.Printf("(%v, %T)\n", i, i)&#125; 底层值为nil的接口值。 即便接口内的具体值为nil， 方法仍然会被nil接收者调用。注意，保存了nil具体值的接口其自身并不为nil。 1234567891011121314151617181920212223242526272829303132333435363738// interface-values-nil.gopackage mainimport "fmt"type I interface &#123; M()&#125;type T struct &#123; S tring&#125;func (t *T) M() &#123; if t == nil &#123; fmt.Println("&lt;nil&gt;") return &#125; fmt.Println(t.S)&#125;func main() &#123; var i I var t *T i = t describe(i) i.M() i = &amp;T&#123;"hello"&#125; describe(i) i.M()&#125;func describe(i I) &#123; fmt.Printf("(%v, %T)\n", i, i)&#125; nil接口值nil接口值既不保存值也不保存具体类型。 12345678910111213141516171819// nil-interface-values.gopackage mainimport "fmt"type I interface &#123; M()&#125;func main() &#123; var i I describe(i) i.M()&#125;func describe(i I) &#123; fmt.Printf("(%v, %T)\n", i, i)&#125; 空接口指定了零个方法的接口值被称为空接口: interface{} 空接口可保存任何类型的值，因为每个类型都至少实现了零个方法。空接口被用来处理未知类型的值。 1234567891011121314151617181920// empty-interface.gopackage mainimport &quot;fmt&quot;func main() &#123; var i interface&#123;&#125; describe(i) i = 42 describe(i) i = &quot;hello&quot; describe(i)&#125;func describe(i interface&#123;&#125;) &#123; fmt.Printf(&quot;(%v, %T)\n&quot;, i, i)&#125; 类型断言类型断言提供了访问接口值底层具体值的方式。 1234567// 该语句断言接口值i保存了具体类型T，并将其底层类型为T的值赋予变量tt := i.(T)// 类型断言可返回两个值// 底层值以及一个报告断言是否成功的布尔值t, ok := i.(T) 123456789101112131415161718192021// type-assertions.gopackage mainimport "fmt"func main() &#123; var i interface&#123;&#125; = "hello" s := i.(string) fmt.Pringln(s) s, ok := i.(string) fmt.Println(s, ok) f, ok := i.(float64) fmt.Println(f, ok) f = i.(float64) // 报错(panic) fmt.Println(f)&#125; 类型选择类型选择是一种按顺序从几个类型断言中选择分支的结构。 12345678910111213141516171819202122// type-switches.gopackage mainimport "fmt"func do(i interface&#123;&#125;) &#123; switch v := i.(type) &#123; case int: fmt.Printf("Twice $v is %v\n", v, v*2) case string: fmt.Printf("%q is %v bytes long\n", v, len(v)) default: fmt.Printf("I don't how about type %T!\n", v) &#125;&#125;func main() &#123; do(21) do("hello") do(true)&#125; Stringerfmt包中定义的Stringer是最普遍的接口之一。 1234567891011121314151617181920// stringer.gopackage mainimport &quot;fmt&quot;type Person struct &#123; Name string Age int&#125;func (p Person) String() string &#123; return fmt.Sprintf(&quot;%v (%v years)&quot;, p.Name, p.Age)&#125;func main() &#123; a := Person&#123;&quot;Arthur Dent&quot;, 42&#125; z := Person&#123;&quot;Zaphod Beeb12brox&quot;, 9001&#125; fmt.Println(a, z)&#125; 错误go程序使用error值来表示错误状态，它是一个内建接口。 12345678910111213141516171819202122232425262728293031// errors.gopackage mainimport ( "fmt" "time")type MyError struct &#123; When time.Time What string&#125;func (e *MyError) Error() string &#123; return fmt.Sprintf("at %v, %s", e.When, e.What)&#125;func run() error &#123; return &amp;MyError&#123; time.Now(), "it didn't work", &#125;&#125;func main() &#123; if err := run(); err != nil &#123; fmt.Println(err) &#125;&#125; Readerio包指定了io.Reader接口，它表示从数据流的末尾进行读取。 1234567891011121314151617181920212223// reader.gopackage main()import ( "fmt" "io" "strings")func main() &#123; r := strings.NewReader("Hello, Reader!") b := make([]byte, 8) for &#123; n, err := r.Read(b) fmt.Printf("n = %v err = %v b = %v\n", n, err, b) fmt.Printf("b[:n] = %q\n", b[:n]) if err == io.EOF &#123; break &#125; &#125;&#125; 图像image包定义了Image接口。 1234567891011121314// images.gopackage mainimport ( "fmt" "image")func main() &#123; m := image.NewRGBA(image.Rect(0, 0, 100, 100)) fmt.Println(m.Bounds()) fmt.Println(m.At(0, 0).RGBA())&#125; 并发doc: https://tour.go-zh.org/concurrency/1 作为语言的核心部分，go提供了并发的特性。这一部分概览了goroutine和channel，以及如何使用它们来实现不同的并发模式。 goroutinego程(goroutine)是由go运行时管理的轻量级线程。 12345go f(x, y, z)# 会启动一个新的goroutine并执行f(x, y, z)# f, x, y, z的求值发生在goroutine中# 而f的执行发生在新的goroutine中 goroutine在相同的地址空间中运行，因此在访问共享的内存时必须进行同步。 1234567891011121314151617181920// goroutines.gopackage mainimport ( "fmt" "time")func say(s string) &#123; for i := 0; i &lt; 5; i++ &#123; time.Sleep(100 * time.Millisecond) fmt.Println(s) &#125;&#125;func main() &#123; go say("world") sqy("hello")&#125; 信道信道是带有类型的管道，通过它用信道操作符&lt;-来发送或接收值。 123456// 信道在使用前必须创建ch := make(chan int)// 箭头就是数据流的方向ch &lt;- v // 将v发送至信道chv := &lt;-ch // 从ch接收值并赋予v 123456789101112131415161718192021222324// channels.gopackage mainimport "fmt"func sum(s []int, c chan int) &#123; sum := 0 for _, v := range s &#123; sum += v &#125; c &lt;- sum // 将和送入c&#125;func main() &#123; s := []int&#123;7, 2, 8, -9, 4, 0&#125; c := make(chan int) go sum(s[:len(s)/2], c) go sum(s[len(s)/2:], c) x, y := &lt;-c, &lt;-c // 从c中接收 fmt.Println(x, y, x+y)&#125; 带缓冲的信道将缓冲长度作为第二个参数提供给make来初始化一个带缓冲的信道，仅当信道的缓冲区填满后，向其发送数据时才会阻塞。当缓冲区为空时，接受方会阻塞。 1234567891011121314// buffered-channels.gopackage mainimport "fmt"func main() &#123; ch := make(chan int, 2) ch &lt;- 1 ch &lt;- 2 // ch &lt;- 3 填满缓冲区 fmt.Println(&lt;-ch) fmt.Println(&lt;-ch)&#125; close发送者可通过close关闭一个信道来表示没有需要发送的值。接收者可以通过为接收表达式分配第二个参数来测试信道是否被关闭。 只有发送者才能关闭信道，而接收者不能。向一个已经关闭的信道发送数据会引发程序恐慌(panic)。信道与文件不同，通常情况下不需要关闭它们。只有在必须告诉接收者不再有需要发送的值时才有必要关闭，例如终止一个range循环。 1234// 若没有值可接收且信道已关闭，在执行完后,ok会被设置为falsev, ok := &lt;-ch// 循环for i := range c会不断从信道接收值，直到它关闭 123456789101112131415161718192021222324// range-and-close.gopackage mainimport ( "fmt")func fibonacci(n int, c chan int) &#123; x, y := 0, 1 for i := 0; i &lt; n; i++ &#123; c &lt;- x x, y = y, x+y &#125; close(c)&#125;func main() &#123; c := make(chan int, 10) go fibonacci(cap(c), c) for i := range c &#123; fmt.Println(i) &#125;&#125; selectselect语句使一个go routine可以等待多个通信操作。它会阻塞到某个分支可以继续执行为止，这时就会执行该分支。当多个分支都准备好时会随机选择一个执行。 123456789101112131415161718192021222324252627282930// select.gopackage mainimport "fmt"func fibonacci(c, quit chan int) &#123; x, y := 0, 1 for &#123; select &#123; case c &lt;- x: x, y = y, x+y case &lt;-quit: fmt.Println("quit") return &#125; &#125;&#125;func main() &#123; c := make(chan int) quit := make(chan int) go func() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Println(&lt;-c) &#125; quit &lt;- 0 &#125;() fibonacci(c, quit)&#125; 当select中的其它分支都没有转杯好时，default分支就会执行。 12345678910111213141516171819202122232425// default-selection.gopackage mainimport ( "fmt" "time")func main() &#123; tick := time.Tick(100 * time.Millisecond) boom := time.After(500 * time.Millisecond) for &#123; select &#123; case &lt;-tick: fmt.Println("tick.") case &lt;-boom: fmt.Println("BOOM!") return default: fmt.Println(" .") time.Sleep(50 * time.Millisecond) &#125; &#125;&#125; 互斥锁信道非常适合在各个Go routine间进行通信。但如果并不需要通信，只想保证每次只有一个go routine能够访问一个共享的变量，从而避免冲突。 这里面涉及的概念就做互斥(mutual exclusion)，通常使用互斥锁(Mutex)这一数据结构来提供这种机制。go标准库提供了sync.Mutex互斥锁及其两个方法: Lock, Unlock。 1234567891011121314151617181920212223242526272829303132333435363738394041// mutex-counter.gopackage mainimport ( "fmt" "sync" "time")// SafeCounter 的并发使用是安全的type SafeCounter struct &#123; v map[string]int mux sync.Mutex&#125;// Inc 增加给定 key 的计数器的值func (c *SafeCounter) Inc(key string) &#123; c.mux.Lock() // Lock 之后同一时刻只有一个 go routine 能访问c.v c.v[key]++ c.mux.Unlocak&#125;// Value 返回给定key的计数器的当前值func (c *SafeCounter) Value(key string) int &#123; c.mux.Lock() // Lock之后同一时刻只有一个 go routine 能访问c.v defer c.mux.Unlock() return c.v[key]&#125;func main() &#123; c := SafeCounter&#123;v: make(map[string]int)&#125; for i := 0; i &lt; 1000; i++ &#123; go c.Inc("somekey") &#125; time.Sleep(time.Second) fmt.Println(c.Value("somekey"))&#125; 如何编写go代码doc: https://golang.org/doc/code.html 介绍本文介绍如何开发一个模块内的一组简单的go包集合，并使用go工具，以标准的方式去fetch, build, install go modules, packages, commands。 注意:本文使用go v1.13+，并且没有设置GO111MODULE环境变量。 代码组织go程序被组织到包。包是编译在同一目录中的源文件的集合。定义在一个源文件中的函数、类型、变量、常量对同一个包中的其它源文件可见。 一个仓库(repo)包含一个或多个模块。模块是发布到一起关联go包的集合。一个go仓库通常只包含一个模块，位于该库的根目录。go.mod文件声明了模块路径，该模块内所有包的导入路径前缀。该模块包含了go.mod文件此目录及其子目录的包。 注意，在你可以构建之前，你并不需要将代码发布到远程仓库。一个模块可以定义在本地而不属于一个仓库。然而，如果你某天希望发布你的代码，那么组织你的代码是一个很好的习惯。 每个模块的路径不仅作为其包的导入路径前缀，也预示着go命令在哪里下载它。例如，要下载golang.org/x/tools模块，go命令会通过协商表示https://golang.org/x/tools。 导入路径是用来导入包的字符串。一个包的导入路径是它和模块内子目录的加入模块的路径。例如，模块github.com/google/go-cmp在cmp/目录下包含一个包，这个包的导入路径是github.com/google/go-cmp/cmp。标准库中的包没有模块路径前缀。 第一个程序要编译和运行一个简单的程序，首先要选择一个模块路径（如example.com/user/hello）并创建一个go.mod文件来声明它。 12345678910make hellocd hellogo mod init example.com/user/hellogo: creating new go.mod: module example.com/user/hellocat go.modmodule example.com/user/hellogo 1.14 go源文件的第一个语句必须是包名(package name)。可执行命令必须使用package main。 123456789// hello.gopackage mainimport "fmt"func main() &#123; fmt.Println("Hello, world.")&#125; 现在你可以使用go工具来构建和安装程序。 1go install example/user/hello 此命令构建hello命令，产生一个可执行二进制文件，安装此二进制到$HOME/go/bin/hello。 安装目录由GOPATH和GOBIN环境变量控制。如果GOBIN有设置，则安装到它这个目录。如果GOPATH有设置，二进制被安装到$GOPATH/bin/下。否则，二进制文件被安装到默认$GOPATH/bin目录下。 可以使用go env命令来设置和取消环境变量: 12345# 设置go env -w GOBIN=/somewhere/else/bin# 取消go env -u GOBIN 像go install这样的命令应用在包含当前工作目录的模块上下文内。如果当前工作目录不在example.com/user/hell模块内，则go install命令可能会失败。 为了方便，如果没有给定其它路径，go命令接收相对于当前工作目录的路径，默认为包的当前路径。因此，在当前工作目录下，下面的命令是等效的： 12345go install example.com/user/hellogo install .go install 接下来，让我们运行此程序以确保它工作。 123export PATH=$PATH:$(dirname $(go list -f &apos;&#123;&#123;.Target&#125;&#125;&apos; .))helloHello, world 如果你在使用版本控制，那现在是初始化仓库，添加文件并提交你的第一个变化的好时机。这一步是可选的，你不需要使用版本控制编写go代码。 1234go initgit add go.mod hello.gogit commit -m &quot;initial commit&quot; go命令通过请求HTTPS URL和从HTML响应中读取元数据来定位仓库包含的模块路径(go help importpath)。许多托管服务已经提供了包含go代码的元数据，使你的模块对其他人可用的最简单的方法通常是——使模块路径匹配仓库URL。 从你的模块导入包Importing packages from your module 让我们编写一个morestrings包，并从hello程序来使用它。首先，为包创建一个目录$HOME/hello/morestrings，并在目录下编写reverse.go源文件。 123456789101112// Package morestrings implements additional functions to manipulate UTF-8// encoded strings, beyond what is provided in the standard "strings" package.package morestrings// ReverseRunes returns its argument string reversed rune-wise left to right.func ReverseRunes(s string) string &#123; r := []rune(s) for i, j := 0, len(r)-1; i &lt; len(r)/2; i, j = i+1, j-1 &#123; r[i], r[j] = r[j], r[i] &#125; return string(r)&#125; 测试并使用go build来编译包： 123cd hello/morestringsgo build 这不会生成一个输出文件。相反，它在本地构建缓存(local build cache)中保存编译包(compiled package)。 在确认了morestrings包构建之后，让我们修改hello.go来使用morestrings包: 12345678910package mainimport ( "fmt" "example.com/usr/hello/morestrings")func main() &#123; fmt.Println(morestrings.ReverseRunes("!oG ,0lleH"))&#125; 12345// install hellogo install example.com/user/hellohelloHello, Go! 从远程模块导入包Importing packages from remote modules 导入路径可以描述如何使用版本控制获得源代码。go工具使用该属性从远程仓库自动获取包。比如，在程序中使用github.com/google/go-cmp/cmp： 123456789101112package mainimport ( "fmt" "example.com/user/hello/morestrings" "github.com/google/go-cmp/cmp")func main() &#123; fmt.Println(morestrings.ReverseRunes("!oG ,olleH")) fmt.Println(cmp.Diff("Hello World", "Hello Go"))&#125; 当你运行go install, go build, go run这些命令时，go命令会自动下载远程模块并在go.mod文件中记录版本。 1234567891011121314151617$ go install example.com/user/hellogo: finding module for package github.com/google/go-cmp/cmpgo: downloading github.com/google/go-cmp v0.4.0go: found github.com/google/go-cmp/cmp in github.com/google/go-cmp v0.4.0$ helloHello, Go! string(- &quot;Hello World&quot;,+ &quot;Hello Go&quot;, )$ cat go.modmodule example.com/user/hellogo 1.14require github.com/google/go-cmp v0.4.0$ 模块依赖关系自动下载到$GOPATH/pkg/mod目录。一个模块的特定版本的下载内容，要求该版本与所有其它模块之间共享，因此go命令标记目录和文件为只读。 12# 删除所有下载的模块go clean --modcache 测试go有一个轻量测试框架go test命令和testing包。 你可以通过创建一个以_test.go名称结尾的文件来编写一个测试，此测试文件包含以func (t *testing.T)签名的TestXXX函数。测试框架运行每个这样的函数，如果此函数调用一个失败的函数（如t.Error或t.Fail），则测试被认为失败。 通过创建包含以下代码的morestrings/reverse_test.go文件，对morestrings包添加一个测试。 12345678910111213141516171819package mainimport "test"func TestReverseRunes(t *testing.T) &#123; cases := []struct &#123; in, want string &#125;&#123; &#123;"Hello, world", "dlrow ,olleH"&#125;, &#123;"Hello, 世界", "界世 ,olleH"&#125;, &#123;"", ""&#125;, &#125; for _, c := range cases &#123; got := ReverseRunes(c.in) if got != c.want &#123; t.Errorf("ReverseRunes(%q) == %q, want %q, c.in, got, c.want") &#125; &#125;&#125; 接着使用go test运行测试: 1234567$ go testPASSok example.com/user/morestrings 0.165s$# 帮助go help test ide和插件doc: https://golang.org/doc/editors.html vim-go: https://github.com/fatih/vim-go Visual Studio Code: https://marketplace.visualstudio.com/items?itemName=golang.Go 我是用的k-vim已经添加了vim-go，只需要将let g:bundle_groups=中添加golang即可。 高效go编程Effective Go: https://golang.org/doc/effective_go.html 介绍Go是一门新语言。要把go写好，了解其性质和惯用语法是很重要的。同样重要的是要知道在go中程序所建立的约定。如命名、格式、项目建设等，让你写的程序会很容易为其他go程序员所理解。 此文档对编写清晰、惯用的go代码给出了一些技巧。 示例go package sources 不仅作为核心库，而且为如何使用语言做了示例。 格式化格式问题最具争议，但却始终没有形成统一的定论。若所有人都遵循相同的编码风格，在这类问题上浪费的时间将会更少。 在go中我们另辟蹊跷，让机器来处理大部分的格式问题。gofmt程序将go程序安装标准风格 进行缩进、对齐，保留注释并在需要时重新格式化。 举例来说，你无需花时间将结构体中的字段对其，gofmt将会为你代劳。 1234type T struct &#123; name string // 对象名 value int // 对象值&#125; gofmt会将它按列对齐： 1234type T struct &#123; name string // 对象名 value int // 对象值&#125; 标准包中的所有go代码都已经用gofmt格式化过了。一些关于格式化的细节： 缩进(Indentation)使用制表符tab，gofmt也默认使用它。在你认为有必要的时候使用空格符(space)。 行长度(Line length)go对行长度没有限制。如果一行实在太长，可以拆行并插入适当的tab缩进。 括号(Parentheses)比起C和Java，Go所需的括号更少。控制结构(if, for, switch)在语法上并不需要圆括号。此外，操作符优先级处理变得更加简洁： 1x&lt;&lt;8 + y&lt;&lt;16 注释go提供了C风格的块注释(/* */)和c++风格的行注释(//)。 godoc既是一个程序，又是一个Web服务器，它对go源码进行处理，并提取包中的文档内容。出现在顶级声明之前，且与该声明之间没有空行的注释，将与该声明一起被提取出来，作为该条目的说明文档。让我想起了Python的文档字符串(docstring)。 每个包都应包含一个包说明(package comment)——即放置在包子句前的一个块注释。对于包含多个文件的包，包注释只需出现在其中的任一文件中即可。包注释应在整体上对该包进行介绍，并提供包的相关信息。 1234567891011121314151617181920/*regexp 包为正则表达式实现了一个简单的库。它接受的正则表达式语法为： 正则： 串联 &#123; '|' 串联&#125; 串联： &#123; 闭包 &#125; 闭包： 条目 [ '*' | '+' | '?' ] 条目： '^' '$' '.' 字符 '[' [ '^' ] 字符遍历 ']' '(' 正则表达式 ')'*/package regexp 如果包比较简单，包说明可以简洁些： 12// Package path implements utility routines for// manipulating slash-separated filename paths. 注释无需额外的格式化。godoc会像gofmt一样处理好一切。注释是不会被解析的纯文本，因此特定的格式不会被渲染。godoc是否会重新格式化注释取决于上下文，因此必须确保它看起来清晰易辨：使用正确的拼写、标点、句子结构以及折叠长行等。 在包中，任何顶级声明前的注释都作为该声明的文档说明。每个可导出名称的程序(首字母大写)都有该用文档说明。这让我想起了Python的类。 文档注释最好是完整的句子，这样它才能适应各种自动化的展示。 第一句应当以被声明的东西开头，并且是单句的摘要。 123// Compile parses a regular expression and returns, if successful,// a Regexp that can be used to match against text.func Compile(str string) (*Regexp, error) &#123; 若注释总是以名称开头，godoc的输出就能通过grep变得更加有用。 1go doc -all regexp | grep -i parse go的声明语法允许成组声明。单个文档注释应介绍一组相关的常量或变量。 由于是整体声明，这种注释往往较为笼统。 1234567// Error codes returned by failures to parse an expression.var ( ErrInternal = errors.New("regexp: internal error") ErrUnmatchedLpar = errors.New("regexp: unmatched '('") ErrUnmatchedRpar = errors.New("regexp: unmatched ')'") ...) 即便是对于私有名称，也可通过成组声明来表明各项间的关系，例如某一组由互斥体保护的变量。 123456var ( countLock sync.Mutex inputCount uint32 outputCount uint32 errorCount uint32) 命名names 命名在编程语言中很重要！ 包名package names 当一个包被导入后，包名就会成为内容的访问器。 1import "bytes 包的名称应该简洁明了以便于理解。按照惯例，包应当以小写的单个单词来命名，且不应该使用下划线或驼峰记法(mixedCaps)。包名是就是导入时所需的默认名称，它并不需要在所有源码中保持唯一，即使在少数发生冲突的情况下，也可为导入的包选择一个别名来局部使用。无论如何，通过文件名来判定使用的包，基本不会产生混淆。 另一个约定就是包名应为其源码目录的基本名称。在src/encoding/base64中的包应作为encoding/base64导入，其包名为base64，而非encoding_base64或encodingBase64。 包的导入者可通过包名来引用其内容，因此包中的可导出名称可以此来避免冲突。请勿使用import .记法，它可以简化必须在被测试包外运行的测试， 除此之外应尽量避免使用。 另一个简短的例子是once.Do，once.Do(setup)表述足够清晰， 使用once.DoOrWaitUntilDone(setup)完全就是画蛇添足。 长命名并不会使其更具可读性。一份有用的说明文档通常比额外的长名更有价值。 获取器Getters Go并不对获取器（getter）和设置器（setter）提供自动支持。 你应当自己提供获取器和设置器，通常很值得这样做，但若要将 Get 放到获取器的名字中，既不符合习惯，也没有必要。 1234owner := obj.Owner()if owner != user &#123; obj.SetOwner(user)&#125; 接口名Interface names 按照约定，只包含一个方法的接口应当以该方法的名称加上-er后缀来命名，如Reader、Writer、 Formatter、CloseNotifier等。 驼峰记法MixedCaps 最后，go中约定使用MexedCaps或mixedCaps而不是下划线来编写多个词的名字。 分号Semicolons 和C一样，Go的正式语法使用分号(;)来结束语句。但和C不同的是，这些分号不会出现在源码中。取而代之，词法分析器会使用一条简单的规则来自动插入分号，因此大部分输入文本是自由的。 若在新行前的最后一个标记为一个标识符(包括int, float64)，数值或字符串常量的基本字面或以下标记之一: 1break continue fallthrough return ++ -- ) &#125; 词法分析器将始终在该标记后面插入一个分号。这可以概括为：如果新行前的标记为语句的末尾，则插入一个分号。 分号也可以在关闭括号之前直接省略，因此一个语句像如下这样，不需要分号。 1go func() &#123; for &#123; dst &lt;- &lt;-src &#125; &#125;() 通常go程序只在诸如for循环子句这样的地方使用分号。如果在一行中写多个语句，也需要使用分号分隔。 无论如何，你都不应该将控制结构(if, for, switch, select)的左括号放到下一行。你应该这样写： 123if i &lt; f() &#123; g()&#125; 而不是这样： 1234if i &lt; f() // wrong!&#123; // wrong! g()&#125; 控制结构Control structures go的控制结构与C有许多相似之处，但其不同才是独到之处。go不使用do或while循环，只有一个更通用的for；switch要更灵活些；if和switch像for一样接受一个可选的初始化语句；break和continue语句有一个可选的标签来确定那些break或continue；此外，还有一个包含类型选择和多路通信复用器的新控制结构——select。它们的语法也有些许不同，没有圆括号，主体必须始终使用大括号括住。 if123if x &gt; 0 &#123; return y&#125; 由于if和switch可接收初始化语句，因此用它们来设置局部变量很常见。 1234if err := file.Chmod(0644); err != nil &#123; log.Print(err) return err&#125; 重新声明和重新赋值Redeclaration and reassignment 123f, err := os.Open(name)d, err := f.Stat() 满足下列条件时，已被声明的变量可出现在:=声明中： 本次声明与已声明的变量出于同一作用域（若变量已在外层作用域中声明过，则此次声明会创建一个新的变量§） 在初始化中与其类型相应的值才能赋予变量，且在此次声明中至少另有一个变量是新声明的 forgo的for循环统一了for和while。它有三种形式，但只有一种需要分号。 12345678// Like a C forfor init; condition; post &#123; &#125;// Like a C whilefor condition &#123; &#125;// Like a C for(;;)for &#123; &#125; 简短的声明使得更容易在循环中声明下标变量： 1234sum := 0for i := 0; i &lt; 10; i++ &#123; sum += i&#125; 若你想遍历数组、切片、字符串、映射，或从信道中读取消息，range子句能够帮你轻松实现循环。 123for key, value := range oldMap &#123; newMap[key] = value&#125; 123456// 只需要遍历下标，去掉第二个for key := range m &#123; if key.expired() &#123; delete(m, key) &#125;&#125; 12345// 只需要值，使用空白标识符(_)来丢弃下标sum := 0for _, value := range array &#123; sum += value&#125; switchgo的switch比C更通用。其表达式无需为常量或整数，case语句会自上而下逐一进行求值直到匹配为止。如果switch后面没有表达式，它将匹配true。因此，我们可以将if-else-if-else链写成一个switch，这也更符合go的风格。 1234567891011func unhex(c byte) byte &#123; switch &#123; case '0' &lt;= c &amp;&amp; c &lt;= '9': return c - '0' case 'a' &lt;= c &amp;&amp; c &lt;= 'f': return c - 'a' + 10 case 'A' &lt;= c &amp;&amp; c &lt;= 'F': return c - 'A' + 10 &#125; return 0&#125; switch并不会自动下溯，但case可通过逗号分隔来列举相同的处理条件。 1234567func shouldEscape(c byte) bool &#123; switch c &#123; case ' ', '?', '&amp;', '=', '#', '+', '%': return true &#125; return false&#125; break语句可以使switch提前终止。不仅是switch，有时候也需要打破层层的循环。在go中，只需将标签(label)放置到循环外，然后break到标签。下例展示了两者的用法： 12345678910111213141516171819202122Loop: for n := 0; n &lt; len(src); n += size &#123; switch &#123; case src[n] &lt; sizeOne: if validateOnly &#123; break &#125; size = 1 update(src[n]) case src[n] &lt; sizeTwo: if n+1 &gt;= len(src) &#123; err = errShortInput break Loop &#125; if validateOnly &#123; break &#125; size = 2 update(src[n] + src[n+1]&lt;&lt;shift) &#125; &#125; 当然，continue语句也能接受一个可选的标签，不过它只能应用在循环中。 作为这一节的结束，下例使用两个switch语句对字节切片进行比较： 1234567891011121314151617181920// Compare returns an integer comparing the two byte slices,// lexicographically.// The result will be 0 if a == b, -1 if a &lt; b, and +1 if a &gt; bfunc Compare(a, b []byte) int &#123; for i := 0; i &lt; len(a) &amp;&amp; i &lt; len(b); i++ &#123; switch &#123; case a[i] &gt; b[i]: return 1 case a[i] &lt; b[i]: return -1 &#125; &#125; switch &#123; case len(a) &gt; len(b): return 1 case len(a) &lt; len(b): return -1 &#125; return 0&#125; 类型选择type switch switch也可用于判断接口变量的动态类型。如type switch通过括号中的关键字type使用类型断言。若switch在表达式中声明了一个变量，那么该变量的每个子句中都将有该变量对应的类型。 1234567891011121314var t interface&#123;&#125;t = functionOfSomeType()switch t := t.(type) &#123;default: fmt.Printf("unexpected type %T\n", t) // %T prints whatever type t hascase bool: fmt.Printf("boolean %t\n", t) // t has type boolcase int: fmt.Printf("integer %d\n", t) // t has type intcase *bool: fmt.Printf("pointer to boolean %t\n", *t) // t has type *boolcase *int: fmt.Printf("pointer to integer %d\n", *t) // t has type *int&#125; 函数function 多值返回multiple return values 以下简单的函数可从字节数组中的特定位置获取其值，并返回该数值和下一个位置。 123456789func nextInt(b []byte, i int) (int, int) &#123; for ; i &lt; len(b) &amp;&amp; !isDigit(b[i]); i++ &#123; &#125; x := 0 for ; i &lt; len(b) &amp;&amp; isDigit(b[i]); i++ &#123; x = x*10 + int(b[i]) - '0' &#125; return x, i&#125; 获取多值： 1234for i := 0; i &lt; len(b); &#123; x, i = nextInt(b, i) fmt.Println(x)&#125; 命名结果形参Named result parameters go函数的返回值(return)或结果(result)行参可被命名，并作为常规变量使用。就像传入的形参一样。命名后，一旦该函数开始执行，它们就会被初始化为与其类型相应的零值；若该函数执行了一条不带参数的return语句，则结果形参的当前值将作为返回值。 此名称不是强制性的，但它们能使代码更加简洁明了：它们就是文档。如果我们命名了nextInt的结果，那么它返回的int就值如其意了： 1func nextInt(b []byte, pos int) (value, nextPos int) &#123; 由于被命名的结果已经初始化，且已经关联至无参数的返回，它们就能让代码简单而清晰。 123456789func ReadFull(r Reader, buf []byte) (n int, err error) &#123; for len(buf) &gt; 0 &amp;&amp; err == nil &#123; var nr int nr, err = r.Read(buf) n += nr buf = buf[nr:] &#125; return&#125; Defergo的defer语句用于预设一个函数调用(即推迟执行函数(deferred function))，该函数会在执行defer的函数返回之前立即执行。它显得非比寻常， 但却是处理一些事情的有效方式，例如无论以何种路径返回，都必须释放资源的函数。 典型的例子就是解锁互斥和关闭文件。 12345678910111213141516171819202122// Contents returns the file's contents as a string.func Contents(filename string) (string, error) &#123; f, err := os.Open(filename) if err != nil &#123; return "", err &#125; defer f.Close() // f.Close will run when we're finished. var result []byte buf := make([]byte, 100) for &#123; n, err := f.Read(buf[0:]) result = append(result, buf[0:n]...) // append is discussed later. if err != nil &#123; if err == io.EOF &#123; break &#125; return "", err // f will be closed if we return here. &#125; &#125; return string(result), nil // f will be closed if we return here.&#125; 推迟如Close之类的函数调用有两个好处。第一， 它能确保你不会忘记关闭文件。如果你以后又为该函数添加了新的返回路径时，这种情况往往就会发生。第二，它意味着关闭离打开很近， 这总比将它放在函数结尾处要清晰明了。 推迟函数（如果函数是一个方法则还包括接收者）的实参在推迟执行时就会求值，而不是在调用执行时才求值。这样不仅无需担心变量值在函数执行时被改变， 同时还意味着单个已推迟的调用可推迟多个函数的执行。一个简单的例子： 123for i := 0; i &lt; 5; i++ &#123; defer fmt.Printf("%d ", i)&#125; 被推迟的函数会按照后见先出(LIFO)的顺序执行，因此上述返回为4 3 2 1 0。一个更具实际意义的例子，让程序跟踪函数的运行： 12345678910func trace(s string) &#123; fmt.Println("entering:", s) &#125;func untrace(s string) &#123; fmt.Println("leaving:", s) &#125;// Use them like this:func a() &#123; trace("a") defer untrace("a") // do something.... fmt.Println("---")&#125; 输出结果如下： 123entering: a---leaving: a 我们可以充分利用这个特点，即被推迟函数的实参在defer执行时才会求值。跟踪go程可针对反跟踪go程设置实参。 1234567891011121314151617181920212223func trace(s string) string &#123; fmt.Println("entering:", s) return s&#125;func un(s string) &#123; fmt.Println("leaving:", s)&#125;func a() &#123; defer un(trace("a")) fmt.Println("in a")&#125;func b() &#123; defer un(trace("b")) fmt.Println("in b") a()&#125;func main() &#123; b()&#125; 输出如下： 123456entering: bin bentering: ain aleaving: aleaving: b 数据Data newgo有两种分配原语，即内建函数new和make。new用来分配内存，但与其它同名函数不同，它不会初始化内存，只会将内存置零(zero)。new(T)会为类型T的新项分配已置零的内存控制，并返回它的地址，也即是类型*T的值。用go的术语，它返回一个指针，该指针指向新分配的类型为T的零值。 既然new返回的内存已置零，那么当你设计数据结构时，每种类型的零值就不必进一步初始化，这意味着该数据结构的使用者只需用new创建一个新的对象就能正常工作。 零值属性有各种好处，考虑以下声明： 1234type SyncedBuffer struct &#123; lock sync.Mutex buffer bytes.Buffer&#125; SyncedBuffer类型的值也是在声明时就分配好内存就绪了。后续代码中， p和v无需进一步处理即可正确工作。 12p := new(SyncedBuffer) // type *SyncedBuffervar v SyncedBuffer // type SyncedBuffer 构造函数与复合字面Constructors and composite literals 有时零值还不够好，这时就需要一个初始化构造函数。 1234567891011func NewFile(fd int, name string) *File &#123; if fd &lt; 0 &#123; return nil &#125; f := new(File) f.fd = fd f.name = name f.dirinfo = nil f.nepipe = 0 return f&#125; 这里显得代码过于冗长。我们可通过复合字面来简化它， 该表达式在每次求值时都会创建新的实例。 1234567func NewFile(fd int, name string) *File &#123; if fd &lt; 0 &#123; return nil &#125; f := File&#123;fd, name, nil, 0&#125; return &amp;f&#125; 请注意，返回一个局部变量的地址完全没有问题，这点与C不同。该局部变量对应的数据 在函数返回后依然有效。实际上，每当获取一个复合字面的地址时，都将为一个新的实例分配内存， 因此我们可以将上面的最后两行代码合并： 1return &amp;File&#123;fd, name, nil, 0&#125; 复合字面的字段必须按顺序全部列出。但如果以k:v对的形式明确地标出元素，初始化字段时就可以按任何顺序出现，未给出的字段值将赋予零值。 因此，我们可以用如下形式： 1return &amp;File&#123;fd: fd, name: name&#125; make再回到内存分配上来。不同于new，make只用于创建切片、映射和信道，并返回类型为T的一个已初始化的值。出现这种差异的原因在于，这三种类型本质上为引用数据类型，它们在使用前必须初始化。对于切片、映射和信道，make用于初始化其内部的数据结构并准备好将要使用的值。 123// ew([]int) 会返回一个指向新分配的，已置零的切片结构， 即一个指向 nil 切片值的指针// 会分配一个具有100个int的数组空间，接着创建一个长度为10， 容量为100并指向该数组中前10个元素的切片结构make([]int, 10, 100) new和make的区别： 123456789var p *[]int = new([]int) // allocates slice structure; *p == nil; rarely usefulvar v []int = make([]int, 100) // the slice v now refers to a new array of 100 ints// Unnecessarily complex:var p *[]int = new([]int)*p = make([]int, 100, 100)// Idiomatic:v := make([]int, 100) 请记住，make只适用于映射、切片和信道且不返回指针。若要获得明确的指针， 请使用new分配内存。 Arrays在详细规划内存布局时，数组非常有用，有时还能避免过多的内存分配，但它们主要用作切片的构件。 Go中数组： 数组是值。将一个数组赋予另一个数组会复制其所有元素。 若将某个数组传入某个函数，它将接收到该数组的一份副本而非指针。 数组的大小是其类型的一部分。类型[10]int和[20]int是不同的。 数组为值的属性很有用，但代价高昂。若你想要C那样的行为和效率，你可以传递一个指向该数组的指针。但这并不是Go的习惯用法，切片才是。 123456789func Sum(a *[3]float64) (sum float64) &#123; for _, v := range *a &#123; sum += v &#125; return&#125;array := [...]float64&#123;7.0, 8.5, 9.1&#125;x := Sum(&amp;array) // Note the explicit address-of operator Slices切片通过对数组进行封装，为数据序列提供了更通用、强大而方便的接口。 除了矩阵变换这类需要明确维度的情况外，Go中的大部分数组编程都是通过切片来完成的。 切片保存了对底层数组的引用，若你将某个切片赋予另一个切片，它们会引用同一个数组。只要切片不超出底层数组的限制，它的长度就是可变的。尽管append可修改切片的元素，但切片自身（其运行时数据结构包含指针、长度和容量）是通过值传递的。 二维切片Two-dimensional slices Go的数组和切片都是一维的。要创建等价的二维数组或切片，就必须定义一个数组的数组， 或切片的切片。像下面这样： 12type Transform [3][3]float64 // A 3x3 array, really an array of arrays.type LinesOfText [][]byte // A slice of byte slices. Maps映射是方便而强大的内建数据结构，它可以关联不同类型的值。其键可以是任何相等性操作符支持的类型， 如整数、浮点数、复数、字符串、指针、接口（只要其动态类型支持相等性判断）、结构以及数组。 切片不能用作映射键，因为它们的相等性还未定义。与切片一样，映射也是引用类型。 若将映射传入函数中，并更改了该映射的内容，则此修改对调用者同样可见。 1234567var timeZone = map[string]int&#123; "UTC": 0*60*60, "EST": -5*60*60, "CST": -6*60*60, "MST": -7*60*60, "PST": -8*60*60,&#125; 赋值和获取映射值的语法类似于数组，不同的是映射的索引不必为整数： 1offset := timeZone["EST"] 有时你需要区分某项是不存在还是其值为零值。可以使用多重赋值的形式来分辨这种情况。 123var seconds intvar ok boolseconds, ok = timeZone[tz] 若仅需判断映射中是否存在某项而不关心实际的值，可使用空白标识符(_)来代替该值的一般变量。 1_, present := timeZone[tz] 要删除映射中的某项，可使用内建函数 delete，它以映射及要被删除的键为实参。 即便对应的键不在该映射中，此操作也是安全的。 1delete(timeZone, "PDT") // Now on Standard Time PrintingGo采用的格式化打印风格和C的printf族类似，但却更加丰富而通用。这些函数位于fmt包中，且函数名首字母均为大写：如fmt.Printf、fmt.Fprintf，fmt.Sprintf等。 1234fmt.Printf("Hello %d\n", 23)fmt.Fprint(os.Stdout, "Hello ", 23, "\n")fmt.Println("Hello", 23)fmt.Println(fmt.Sprint("Hello ", 23)) append内建函数append像这个： 1func append(slice []T, elements ...T) []T 初始化Initialization 尽管从表面上看，Go的初始化过程与C或C++并不算太大，但它确实更为强大。 在初始化过程中，不仅可以构建复杂的结构，还能正确处理不同包对象间的初始化顺序。 常量Constants Go中的常量就是不变量。它们在编译时创建，即便它们可能是函数中定义的局部变量。 常量只能是数字、字符（符文）、字符串或布尔值。由于编译时的限制， 定义它们的表达式必须也是可被编译器求值的常量表达式。 变量变量的初始化与常量类似，但其初始值也可以是在运行时才被计算的一般表达式。 12345var ( home = os.Getenv("HOME") user = os.Getenv("USER") gopath = os.Getenv("GOPATH")) initThe init function 最后，每个源文件都可以通过定义自己的无参数init函数来设置一些必要的状态。而它的结束就意味着初始化结束： 只有该包中的所有变量声明都通过它们的初始化器求值后init才会被调用， 而那些init只有在所有已导入的包都被初始化后才会被求值。 除了那些不能被表示成声明的初始化外，init 函数还常被用在程序真正开始执行前，检验或校正程序的状态。 123456789101112131415Besides initializations that cannot be expressed as declarations, a common use of init functions is to verify or repair correctness of the program state before real execution begins.func init() &#123; if user == "" &#123; log.Fatal("$USER not set") &#125; if home == "" &#123; home = "/home/" + user &#125; if gopath == "" &#123; gopath = home + "/go" &#125; // gopath may be overridden by --gopath flag on command line. flag.StringVar(&amp;gopath, "gopath", gopath, "override default GOPATH")&#125; 方法Methods 指针与值Pointers vs. Values 以指针或值为接收者的区别在于：值方法可通过指针和值调用， 而指针方法只能通过指针来调用。 接口和其它类型 InterfacesGo中的接口为指定对象的行为提供了一种方法：如果某样东西可以完成这个， 那么它就可以用在这里。 每种类型都能实现多个接口。 类型转换Conversions 接口转换与类型断言Interface conversions and type assertions 类型选择是类型转换的一种形式：它接受一个接口，在选择中根据其判断选择对应的情况， 并在某种意义上将其转换为该种类型。 1234567891011type Stringer interface &#123; String() string&#125;var value interface&#123;&#125; // Value provided by caller.switch str := value.(type) &#123;case string: return strcase Stringer: return str.String()&#125; 类型断言接受一个接口值， 并从中提取指定的明确类型的值。 通用性Generality 若某种现有的类型仅实现了一个接口，且除此之外并无可导出的方法，则该类型本身就无需导出。 仅导出该接口能让我们更专注于其行为而非实现，其它属性不同的实现则能镜像该原始类型的行为。 这也能够避免为每个通用接口的实例重复编写文档。 在这种情况下，构造函数应当返回一个接口值而非实现的类型。 接口和方法Interfaces and methods 由于几乎任何类型都能添加方法，因此几乎任何类型都能满足一个接口。 1234// 一个很直观的例子就是 http 包中定义的 Handler 接口。任何实现了 Handler 的对象都能够处理HTTP请求type Handler interface &#123; ServeHTTP(ResponseWriter, *Request)&#125; 空白标识符The blank identifier 空白标识符(_)可被赋予或声明为任何类型的任何值，而其值会被无害地丢弃。它有点像Unix中的/dev/null文件：它表示只写的值，在需要变量但不需要实际值的地方用作占位符。 多重赋值中的空白标识符The blank identifier in multiple assignment for range循环中对空表标识符的用法是一种具体情况，更一般的情况即为多重赋值。 123if _, err := os.Stat(path); os.IsNotExist(err) &#123; fmt.Printf("%s does not exist\n", path)&#125; 未使用的导入和变量Unused imports and variables 若导入某个包或声明某个变量而不使用它就会产生错误。未使用的包会让程序膨胀并拖慢编译速度， 而已初始化但未使用的变量不仅会浪费计算能力，还有可能暗藏着更大的Bug。 要让编译器停止关于未使用导入的抱怨，需要空白标识符来引用已导入包中的符号。 1234567891011121314151617181920package mainimport ( "fmt" "io" "log" "os")var _ = fmt.Printf // For debugging; delete when done.var _ io.Reader // For debugging; delete when done.func main() &#123; fd, err := os.Open("test.go") if err != nil &#123; log.Fatal(err) &#125; // TODO: use fd. _ = fd&#125; 为副作用而导入Import for side effect 有时导入某个包只是为了其副作用， 而没有任何明确的使用。只为了其副作用来导入该包， 只需将包重命名为空白标识符： 1import _ "net/http/pprof" 这种导入格式能明确表示该包是为其副作用而导入的，因为没有其它使用该包的可能： 在此文件中，它没有名字。（若它有名字而我们没有使用，编译器就会拒绝该程序。） 接口检查Interface checks 一个类型无需显式地声明它实现了某个接口。取而代之，该类型只要实现了某个接口的方法， 其实就实现了该接口。在实践中，大部分接口转换都是静态的，因此会在编译时检测。 若只需要判断某个类型是否是实现了某个接口，而不需要实际使用接口本身 （可能是错误检查部分），就使用空白标识符来忽略类型断言的值： 123if _, ok := val.(json.Marshaler); ok &#123; fmt.Printf("value %v of type %T implements json.Marshaler\n", val, val)&#125; 在这种结构中出现空白标识符，即表示该声明的存在只是为了类型检查。 不过请不要为满足接口就将它用于任何类型。作为约定， 仅当代码中不存在静态类型转换时才能这种声明，毕竟这是种罕见的情况。 内嵌Embedding Go并不提供典型的，类型驱动的子类化概念，但通过将类型内嵌到结构体或接口中， 它就能借鉴部分实现。 并发Concurrency 通过通信共享内存Share by communicating 并发编程是个很大的话题。这里只讨论一些go特有的东西。 在并发编程中，为实现对共享变量的正确访问需要精确的控制，这在多数环境下都很困难。 Go语言另辟蹊径，它将共享的值通过信道传递，实际上，多个独立执行的线程从不会主动共享。 在任意给定的时间点，只有一个Go程能够访问该值。数据竞争从设计上就被杜绝了。 为了提倡这种思考方式，我们将它简化为一句口号： 不要通过共享内存来通信，而应通过通信来共享内存(Do not communicate by sharing memory; instead, share memory by communicating)。 这种方法意义深远。例如，引用计数通过为整数变量添加互斥锁来很好地实现。 但作为一种高级方法，通过信道来控制访问能够让你写出更简洁，正确的程序。 go程Goroutines 称它为GO程是因为现有的术语——线程(threads), 协程(coroutines), 进程(process)无法准确表达它的含义。Go程具有简单的模型：它是与其它Go程并发运行在同一地址空间的函数。它是轻量级的， 所有小号几乎就只有栈空间的分配。而且栈最开始是非常小的，所以它们很廉价， 仅在需要时才会随着堆空间的分配（和释放）而变化。 Go程在多线程操作系统上可实现多路复用，因此若一个线程阻塞，比如说等待I/O， 那么其它的线程就会运行。Go程的设计隐藏了线程创建和管理的诸多复杂性。 123// 在函数或方法前添加go关键字能够在新的Go程中调用它。当调用完成后， 该Go程也会安静地退出// 效果有点像Unix Shell中的 &amp; 符号，它能让命令在后台运行go list.Sort() // run list.Sort concurrently; don't wait for it. 函数字面在Go程调用中非常有用。 123456func Announce(message string, delay time.Duration) &#123; go func() &#123; time.Sleep(delay) fmt.Println(message) &#125;() // Note the parentheses - must call the function.&#125; 在Go中，函数字面都是闭包(closures)：其实现在保证了函数内引用变量的生命周期与函数的活动时间相同。这些函数没什么实用性，因为它们没有实现完成时的信号处理。因此，我们需要信道。 信道Channels 信道与映射一样，也需要通过make来分配内存，其结果充当了对底层数据结构的引用。若提供了一个可选的整数形参，它就会为该信道设置缓冲区大小。默认值是零，表示不带缓冲(unbuffered)的或同步(synchronous)的信道。 123ci := make(chan int) // unbuffered channel of integerscj := make(chan int, 0) // unbuffered channel of integerscs := make(chan *os.File, 100) // buffered channel of pointers to Files 无缓冲信道在通信时会同步交换数据，它能确保（goroutine）计算处于确定状态。 信道有很多惯用方法。 12345678c := make(chan int) // Allocate a channel.// Start the sort in a goroutine; when it completes, signal on the channel.go func() &#123; list.Sort() c &lt;- 1 // Send a signal; value does not matter.&#125;()doSomethingForAWhile()&lt;-c // Wait for sort to finish; discard sent value. 接收者在收到数据前会一直阻塞。若信道是不带缓冲的，那么在接收者收到值前， 发送者会一直阻塞；若信道是带缓冲的，则发送者仅在值被复制到缓冲区前阻塞； 若缓冲区已满，发送者会一直等待直到某个接收者取出一个值为止。 带缓冲的信道可被用作信号量，例如限制吞吐量。 回到编写服务器的一般问题上来。另一种管理资源的好方法就是启动固定数量的handleGo程，一起从请求信道中读取数据。Go程的数量限制了同时调用process的数量。Serve同样会接收一个通知退出的信道， 在启动所有Go程后，它将阻塞并暂停从信道中接收消息。 12345678910111213func handle(queue chan *Request) &#123; for r := range queue &#123; process(r) &#125;&#125;func Serve(clientRequests chan *Request, quit chan bool) &#123; // Start handlers for i := 0; i &lt; MaxOutstanding; i++ &#123; go handle(clientRequests) &#125; &lt;-quit // Wait to be told to exit.&#125; 信道中的信道Channels of channels Go最重要的特性就是信道是一等值，它可以被分配并像其它值到处传递。 这种特性通常被用来实现安全(safe)、并行(parallel)的多路分解(demultiplexing)。 并行化Parallelization 这些设计的另一个应用是在多CPU核心上实现并行计算。如果计算过程能够被分为几块 可独立执行的过程，它就可以在每块计算结束时向信道发送信号，从而实现并行处理。 12345678910111213const numCPU = 4 // number of CPU coresfunc (v Vector) DoAll(u Vector) &#123; c := make(chan int, numCPU) // Buffering optional but sensible. for i := 0; i &lt; numCPU; i++ &#123; go v.DoSome(i*len(v)/numCPU, (i+1)*len(v)/numCPU, u, c) &#125; // Drain the channel. for i := 0; i &lt; numCPU; i++ &#123; &lt;-c // wait for one task to complete &#125; // All done.&#125; 目前Go运行时的实现默认并不会并行执行代码，它只为用户层代码提供单一的处理核心。 任意数量的Go程都可能在系统调用中被阻塞，而在任意时刻默认只有一个会执行用户层代码。 它应当变得更智能，而且它将来肯定会变得更智能。但现在，若你希望CPU并行执行， 就必须告诉运行时你希望同时有多少Go程能执行代码。除了为CPU数量创建一个创建，还有两种方法： 12345// 1var numCPU = runtime.NumCPU()// 2var numCPU = runtime.GOMAXPROCS(0) 注意不要混淆并发(concurrency)和并行(parallelism)的概念。并发是用可独立执行的组件构造程序的方法， 而并行则是为了效率在多CPU上平行地进行计算。 尽管Go的并发特性能够让某些问题更易构造成并行计算， 但Go仍然是种并发而非并行的语言，且Go的模型并不适合所有的并行问题。 泄露的缓冲区A leaky buffer 并发编程的工具甚至能很容易地表达非并发的思想。 这里有个提取自RPC包的例子。 客户端Go程从某些来源，可能是网络中循环接收数据。为避免分配和释放缓冲区， 它保存了一个空闲链表，使用一个带缓冲信道表示。若信道为空，就会分配新的缓冲区。 一旦消息缓冲区就绪，它将通过serverChan被发送到服务器。 123456789101112131415161718var freeList = make(chan *Buffer, 100)var serverChan = make(chan *Buffer)func client() &#123; for &#123; var b *Buffer // Grab a buffer if available; allocate if not. select &#123; case b = &lt;-freeList: // Got one; nothing more to do. default: // None free, so allocate a new one. b = new(Buffer) &#125; load(b) // Read next message from the net. serverChan &lt;- b // Send to server. &#125;&#125; 服务器从客户端循环接收每个消息，处理它们，并将缓冲区返回给空闲列表。 12345678910111213func server() &#123; for &#123; b := &lt;-serverChan // Wait for work. process(b) // Reuse buffer if there's room. select &#123; case freeList &lt;- b: // Buffer on free list; nothing more to do. default: // Free list full, just carry on. &#125; &#125;&#125; 客户端试图从freeList中获取缓冲区；若没有缓冲区可用， 它就将分配一个新的。服务器将b放回空闲列表freeList中直到列表已满，此时缓冲区将被丢弃，并被垃圾回收器回收。依靠带缓冲的信道和垃圾回收器的记录， 我们仅用短短几行代码就构建了一个可能导致缓冲区槽位泄露的空闲列表。 错误error 库例程通常需要向调用者返回某种类型的错误提示。之前提到过，Go语言的多值返回特性， 使得它在返回常规的值时，还能轻松地返回详细的错误描述。 按照约定，错误的类型通常为error，这是一个内建的简单接口。 123type error interface &#123; Error() string&#125; 库的编写者通过更丰富的底层模型可以轻松实现这个接口，这样不仅能看见错误， 还能提供一些上下文。 123456789101112131415// PathError records an error and the operation and// file path that caused it.type PathError struct &#123; Op string // "open", "unlink", etc. Path string // The associated file. Err error // Returned by the system call.&#125;func (e *PathError) Error() string &#123; return e.Op + " " + e.Path + ": " + e.Err.Error()&#125;// 生成的错误信息例子// open /etc/passwx: no such file or directory 错误字符串应尽可能地指明它们的来源，例如产生该错误的包名前缀。若调用者关心错误的完整细节，可使用类型选择或者类型断言来查看特定错误，并抽取其细节。 Panic向调用者报告错误的一般方式就是将error作为额外的值返回。但如果错误时不可恢复的呢？有时程序就是不能继续运行。为此，我们提供了内建的panic函数，它会产生一个运行时错误并终止程序。该函数接受一个任意类型的实参（一般为字符串），并在程序终止时打印。 它还能表明发生了意料之外的事情，比如从无限循环中退出了。 12345678910111213// A toy implementation of cube root using Newton's method.func CubeRoot(x float64) float64 &#123; z := x/3 // Arbitrary initial value for i := 0; i &lt; 1e6; i++ &#123; prevz := z z -= (z*z*z-x) / (3*z*z) if veryClose(z, prevz) &#123; return z &#125; &#125; // A million iterations has not converged; something is wrong. panic(fmt.Sprintf("CubeRoot(%g) did not converge", x))&#125; 实际的库函数应避免panic。若问题可以被屏蔽或解决， 最好就是让程序继续运行而不是终止整个程序。 Recover当panic被调用后，程序将立刻终止当前函数的执行，并开始回溯Go程的栈，运行任何被推迟的函数。 若回溯到达Go程栈的顶端，程序就会终止。不过我们可以用内建的recover函数来重新或来取回Go程的控制权限并使其恢复正常执行。 调用recover将停止回溯过程，并返回传入panic的实参。 由于在回溯时只有被推迟函数中的代码在运行，因此recover只能在被推迟的函数中才有效。 recover的一个应用就是在服务器中终止失败的Go程而无需杀死其它正在执行的Go程。 1234567891011121314func server(workChan &lt;-chan *Work) &#123; for work := range workChan &#123; go safelyDo(work) &#125;&#125;func safelyDo(work *Work) &#123; defer func() &#123; if err := recover(); err != nil &#123; log.Println("work failed:", err) &#125; &#125;() do(work)&#125; 在此例中，若do(work)触发了Panic，其结果就会被记录， 而该Go程会被干净利落地结束，不会干扰到其它Go程。我们无需在推迟的闭包中做任何事情， recover会处理好这一切。 通过恰当地使用恢复模式，do函数（及其调用的任何代码）可通过调用 panic 来避免更坏的结果。我们可以利用这种思想来简化复杂软件中的错误处理。 让我们看看regexp包的理想化版本，它会以局部的错误类型调用 panic 来报告解析错误。以下是一个error类型的 Error方法和一个Compile函数的定义： 123456789101112131415161718192021222324// Error is the type of a parse error; it satisfies the error interface.type Error stringfunc (e Error) Error() string &#123; return string(e)&#125;// error is a method of *Regexp that reports parsing errors by// panicking with an Error.func (regexp *Regexp) error(err string) &#123; panic(Error(err))&#125;// Compile returns a parsed representation of the regular expression.func Compile(str string) (regexp *Regexp, err error) &#123; regexp = new(Regexp) // doParse will panic if there is a parse error. defer func() &#123; if e := recover(); e != nil &#123; regexp = nil // Clear return value. err = e.(Error) // Will re-panic if not a parse error. &#125; &#125;() return regexp.doParse(str), nil&#125; 顺便一提，这种重新触发Panic的惯用法会在产生实际错误时改变Panic的值。 然而，不管是原始的还是新的错误都会在崩溃报告中显示，因此问题的根源仍然是可见的。 这种简单的重新触发Panic的模型已经够用了，毕竟他只是一次崩溃。 但若你只想显示原始的值，也可以多写一点代码来过滤掉不需要的问题，然后用原始值再次触发Panic。 A web server让我们以一个完整的Go程序作为结束吧，一个Web服务器。该程序其实只是个Web服务器的重用。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport ( "flag" "html/template" "log" "net/http")var addr = flag.String("addr", ":1718", "http service address") // Q=17, R=18var templ = template.Must(template.New("qr").Parse(templateStr))func main() &#123; flag.Parse() http.Handle("/", http.HandlerFunc(QR)) err := http.ListenAndServe(*addr, nil) if err != nil &#123; log.Fatal("ListenAndServe:", err) &#125;&#125;func QR(w http.ResponseWriter, req *http.Request) &#123; templ.Execute(w, req.FormValue("s"))&#125;const templateStr = `&lt;html&gt;&lt;head&gt;&lt;title&gt;QR Link Generator&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&#123;&#123;if .&#125;&#125;&lt;img src="http://chart.apis.google.com/chart?chs=300x300&amp;cht=qr&amp;choe=UTF-8&amp;chl=&#123;&#123;.&#125;&#125;" /&gt;&lt;br&gt;&#123;&#123;.&#125;&#125;&lt;br&gt;&lt;br&gt;&#123;&#123;end&#125;&#125;&lt;form action="/" name=f method="GET"&gt; &lt;input maxLength=1024 size=70 name=s value="" title="Text to QR Encode"&gt; &lt;input type=submit value="Show QR" name=qr&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;` Go语言强大到能让很多事情以短小精悍的方式解决。 调试Diagnostics: https://golang.org/doc/diagnostics.html 总结工具和方法来诊断Go程序 介绍Go生态提供了一套API和工具来诊断go程序的逻辑和性能问题。本章总结了可用的工具，帮助用户去选择正确的工具来解决问题。 调试方案可分为一下几组： Profiling： 分析工具分析go程序的复杂性和成本，如内存使用和调用函数的频率，以确定go程序的昂贵的部分； Tracing： 追踪是分析整个延迟和调用或用户请求的生命周期的一种方法； Debugging： 调试可以让我们暂停go程序，检查并执行。程序的状态和流程可通过调试进行验证； Runtime statistics and events： 收集和分析运行时状态和事件，提供go程序运行状态的高度概括。 分析Profiling 对于识别昂贵的或频繁调用的代码部分，分析很有用。go runtime通过pprof可视化工具以格式化形式提供了分析数据。可通过go test或net/http/pprof包来收集分析数据。用户需要在代码顶级路径使用pprof工具来收集分析路径。 由runtime/pprof包预分析： cpu: cpu porfile，报告程序花费的CPU时间。 heap： heap profile，报告内存分配样本，监控当前和历史的内存使用，并检查内存泄漏。 threadcreate： thread profile，报告程序的操作系统的线程创建部分。 goroutine： goroutine profile，报告当前所有goroutine的栈追踪(stack trace)。 block： block profile，报告goroutine在哪里等待同步原语(synchronization primitives)阻塞。此功能默认关闭，使用runtime.SetBlockProfileRate开启。 mutex： mutex profile，报告锁的争用情况。当你认为由于互斥锁争用，CPU没有得到充分利用时，使用此功能。此功能默认关闭，使用runtime.SetMutexProfileFraction启用。 追踪Tracing 追踪是一种来分析整个调用链的生命周期的延迟的方法。go提供了golang.org/x/net/trace包作为每个go节点的最小化追踪后端，并使用一个简单的面板来提供一个小型的仪器库。go还提供了一个可执行的追踪程序在内部追踪运行时事件。 追踪使我们能够： 在go程序内工具和分析应用延迟。 衡量一个长链调用的特定调用的开销。 计算使用率和性能优化。 go的生态提供了多种追踪库。 调试Debugging 调试是识别一个程序行为不端的过程。调试器让我们了解程序的执行流程和当前状态。有几种调试风格，本章节将仅聚焦于一个调试器附加到一个程序和核心转储(core dump)调试。 go用户大多使用以下调试器： (Delve)[https://github.com/go-delve/delve]： Delve是一个go lang调试器。它支持go runtime和内建类型。它正努力成为一个go程序的全功能可靠的调试器。 (GDB)[https://golang.org/doc/gdb]： go通过标准的go编译器和Gccgo提供了GDB支持。尽管GDB可以用来调试go程序，但这不理想，可能导致混乱。 运行时统计数据和事件Runtime statistics and events 运行时(runtime)提供了统计信息和内部事件的报告，为用户在运行时级别诊断性能和利用率的问题。 用户可以监控这些数据，以便于更好地了解go程序的总体运行状况和性能。一些常用的监控统计数据和状态： runtime.ReadMemStats： 报告与堆分配(heap allocation)和垃圾回收(garbage collection)相关的指标。内存统计数据对监控进程消耗了多少内存资源是有用的，进程是否能很好地利用内存，并捕捉到内存泄漏。 debug.ReadGCStats： 阅读关于垃圾回收的统计数据。查看多少资源都花在了垃圾回收阶段也是很有用的。它还报告垃圾回收暂停和暂停事件百分数的时间线。 debug.Stack： 返回当前的栈追踪。栈追踪对于查看有多少goroutine正在运行，它们在做什么，它们是否阻塞很有用。 debug.WriteHeapDump： 中止所有goroutine的执行，并允许转存(dump)堆(heap)到文件。一个堆转存是go程序在特定时间内存的快照。它包含所有分配的对象，以及goroutine, finalizers… runtime.NumGoroutine： 返回当前的goroutine数量。该值可以被监测、以了解是否有足够的goroutine被利用，或检测goroutine泄漏。 执行追踪Execution tracer go使用runtime execution tracer来捕获广泛的运行时事件。调度、系统调用、垃圾回收、堆大小和其它收集的事件。执行追踪器是一个检测延迟和使用率问题的工具。你可以检查CPU如何利用，网络或系统调用时，抢占对goroutine的原因。 追踪器对这些有用： 理解你的goroutine如何执行 理解一些核心(core)的运行时事件，如垃圾回收 确定不佳的并行执行 然而，它不是很大用于识别热点（如分析内存溢出或CPU使用的原因）。使用分析工具而不是先定位它们。 详细信息查看go tool trace，来收集和分析运行时追踪。 GODEBUG如果GODEBUG环境变量相应地设置，运行时也会发出事件和信息。 GODEBUG=gctrace=1： 在每个收集中打印垃圾回收器事件，汇总内存收集量和停顿的长度。 GODEBUG=schedtrace=X： 每个x毫秒打印调度事件。 GODEBUG环境变量可用于在标准库和运行时中禁用指令集扩展。 GODEBUG=cpu.all=off： 禁止使用所有可选的扩展指令集。 GODEBUG=cpu.extension=off： 禁止从指定的指令集扩展中使用指令。 FAQdocs: https://golang.org/doc/faq 有关go的常见问答。 Go wikidocs: https://github.com/golang/go/wiki 由GO社区维护的wiki。 参考References 包Package Documentation: https://golang.org/pkg/ Go标准库文档。 命令Command Documentation: https://golang.org/doc/cmd Go工具文档。 语言规范Language Specification: https://golang.org/ref/spec 官方Go语言规范。 内存模型The Go Memory Model: https://golang.org/ref/mem]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript]]></title>
    <url>%2F2020%2F03%2F16%2FJavaScript%2F</url>
    <content type="text"><![CDATA[参考: wiki: https://zh.wikipedia.org/zh-cn/JavaScript W3school: https://www.w3school.com.cn/js/index.asp 廖雪峰：https://www.liaoxuefeng.com/wiki/1022910821149312 环境： ELRH7x86_64 简介Introduction JavaScript(JS)是一种解释型的高级编程语言。JavaScript是一门基于原型、函数先行的语言，是一门多范式的语言，它支持面向对象编程，命令式编程，以及函数式编程。它提供语法来操控文本、数组、日期以及正则表达式等，不支持I/O，比如网络、存储和图形等，但这些都可以由它的宿主环境提供支持。它已经由ECMA（欧洲电脑制造商协会）通过ECMAScript实现语言的标准化。它被世界上的绝大多数网站所使用，也被世界主流浏览器（Chrome、IE、Firefox、Safari、Opera）支持。 虽然JavaScript与Java这门语言不管是在名字上，或是在语法上都有很多相似性，但这两门编程语言从设计之初就有很大的不同。为什么起名叫JavaScript？原因是当时Java语言非常红火，所以网景公司希望借Java的名气来推广，但事实上JavaScript除了语法上有点像Java，其他部分基本上没啥关系。 JavaScript是世界上最流行的脚本语言，因为你在电脑、手机、平板上浏览的所有的网页，以及无数基于HTML5的手机App，交互逻辑都是由JavaScript驱动的。随着HTML5在PC和移动端越来越流行，JavaScript变得更加重要了。并且，新兴的Node.js把JavaScript引入到了服务器端，JavaScript已经变成了全能型选手。 ECMAScript为了让JavaScript成为全球标准，几个公司联合ECMA（European Computer Manufacturers Association）组织定制了JavaScript语言的标准，被称为ECMAScript标准。 所以简单说来就是，ECMAScript是一种语言标准，而JavaScript是网景公司对ECMAScript标准的一种实现。 JavaScript的标准是ECMAScript 。ECMAScript第一版标准发布于1997年。 那为什么不直接把JavaScript定为标准呢？因为JavaScript是网景的注册商标。 快速入门JavaScript代码可以直接嵌在网页的任何地方，不过通常我们都把JS代码放到&lt;head&gt;中。由&lt;script&gt;...&lt;/script&gt;包含的代码就是JS代码，它将直接被浏览器执行。 1234567&lt;html&gt;&lt;head&gt; &lt;script&gt; alert("hello, world"); &lt;/script&gt;&lt;/head&gt;&lt;/html&gt; 第二种方法是把JavaScript放到单独的.js文件，然后在HTML中通过&lt;script src=&quot;...&quot;&gt;&lt;/script&gt;来引入。 12345&lt;html&gt;&lt;head&gt; &lt;script src="/static/js/hello.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;/html&gt; 将JS代码放入单独的文件中更有利于维护代码，并且多个页面可以复用。 在同一个页面中引入多个JS文件（或编写多个JS代码），浏览器将按照顺序依次执行。 有时会看到&lt;script&gt;有一个type属性。但其实这是没有必要的，以你为默认的type就是javascript，所以不必显式指定。 123&lt;script type="text/javascript"&gt;...&lt;/script&gt; console.log()代替alert()的好处是可以避免弹出烦人的对话框。 123// 在chrome中console中查看var x = 100;console.log(x) 如何运行JS要让浏览器运行JavaScript，必须先有一个HTML页面，在HTML页面中引入JavaScript。然后，然浏览器加载该HTML页面，就可以执行JavaScript代码。 基本语法每个语句以分号;结束，语句块使用花括号{}。 123456789// 不建议一行写多个语句var x = 1;var y = 2;/* 缩进不是JS语法要求所必须，但有助于我们理解代码层次。 缩进通常是4个空格 */if (x &gt; y) &#123; x = y;&#125; 数据类型 数字(Number) 字符串(String) 布尔(Bool) 空(Null) 未定义(Undefined) Symbol: 独一无二的值 数组(Array) 对象(Object) 函数(Function) JS不区分整数和浮点数，统一用Number表示。NaN这个特殊的数字与所有其它值都不相等，包括它自己。 字符串以单引号或双引号括起来的任意文本。可通过转义字符()进行转义。 布尔值只有true和false两种值。 null表示一个空值，如Python的None。undefined表示未定义。大多数情况下，我们都应该使用null，undefined仅仅在判断函数参数是否传递的情况下有用。&#39;&#39;表示长度为0的字符串。 数组使用[]表示，元素间用逗号,分隔。类似于Python的List，包括所索引、切片等操作。 对象是一组由键值组成的无序集合。类似于Python的Dictionary。 1234567var person = &#123; name: 'A', age: 20, tags: ['js', 'html', 'css'], hasCar: true, zipCode: null&#125; Map和SetJavaScript的默认对象表示方式{}可以视为其他语言中的Map或Dictionary的数据结构，即一组键值对。但是JavaScript的对象有个小问题，就是键必须是字符串。但实际上Number或者其他数据类型作为键也是非常合理的。 为了解决这个问题，最新的ES6规范引入了新的数据类型Map。 123456// Mapvar m = new Map([['A': 90], ['b': 80]]);m.get('A');m.set('A', 99);m.has('B');m.delete('B'); Set和Map类似，也是一组Key的集合，但不存储Value。没有重复的键。 12345// Setvar s1 = new Set();var s2 = new Set([1, 2, 3, 1, 4, 'A'])s2.add(4)s2.delete('A') 动态类型JavaScript拥有动态类型，这意味着相同的变量可哦你工作不同的类型。 123var x; // x为unfefinedvar x = 5; // x为数字var x = "John"; // x为字符串 运算符 &amp;&amp; || ! &gt;, &lt; &gt;=, &lt;= ==: 会自动转换数据类型再比较 ===: 不会自动转换数据类型，如果数据类型不一致，返回false；如果一致，再比较 由于JS这个设计缺陷，不要使用==，始终坚持使用===。 变量变量在JavaScript中就是用一个变量名表示，变量名是大小写英文、数字、$和_的组合，且不能用数字开头。变量名也不能是JavaScript的关键字。变量名也可以用中文。 123456// 注意，只能用var申明一次var a = 123;a = 'ABC';/* 变量本身类型不固定的语言称为动态语言 与之相反的是静态语言，在定义变量时必须指定变量类型，如果类型不匹配，则会报错 动态语言更灵活 */ 可使用关键字new来声明变量类型: 12345var name = new String;var x = new Number;var y = new Boolean;var z = new Array;var o = new Object; 严格模式JavaScript在设计之初，为了便于学习，并不强制要求使用var声明变量。这个设计错误带来了严重的后果：如果一个变量没有通过var申明就被使用，那么该变量就自动被申明为全局变量。 12// i现在是全局变量i = 10; 在同一个页面的不同的JavaScript文件中，如果都不用var申明，恰好都使用了变量i，将造成变量i互相影响，产生难以调试的错误结果。使用var申明的变量则不是全局变量，它的范围被限制在该变量被申明的函数体内，同名变量在不同的函数体内互不冲突。 为了修补JavaScript这一严重设计缺陷，ECMA在后续规范中推出了严格(strict)模式，在strict模式下运行的JavaScript代码，强制通过var申明变量，未使用var申明变量就使用的，将导致运行错误。不用var申明的变量会被视为全局变量，为了避免这一缺陷，所有的JavaScript代码都应该使用strict模式。我们在后面编写的JavaScript代码将全部采用strict模式。 启用strict模式的方法是在JavaScript代码的第一行写上：&#39;use strict&#39;; 条件判断1234567891011121314if () &#123; xxx;&#125; else &#123; xxxx;&#125;if (condition) &#123; xx;&#125; else if (conditon) &#123; xxx;&#125; else &#123; xxxx;&#125; 栗子： 1234567891011'use strict';var age = 20;if (age&gt;=18) &#123; console.log('adult');&#125; else if (age &lt; 6) &#123; console.log('kid');&#125; else &#123; console.log('teenager');&#125; JavaScript把null, undefined, 0, NaN, &#39;&#39;视为fasle，其它一概视为true。 栗子： 123456789101112131415161718'use strict';// 类似于alert的弹窗输入var height = parseFloat(prompt('请输入身高(m):'));var weight = parseFloat(prompt('请输入体重(kg):'));var bmi = weight / height*height;console.log(bmi);if (bmi &lt; 18.5) &#123; console.log("过轻");&#125; else if (25 &gt; bmi &gt;= 18.5) &#123; console.log("正常");&#125; else if (32 &gt; bmi &gt;= 25) &#123; console.log("过重");&#125; else &#123; console.log("肥胖");&#125; 循环 for while do...while 1234567891011121314151617181920212223242526// forvar x = 0;var i;for (i=1; i&lt;=100; i++) &#123; x = x + i;&#125;console.log(x)// for 索引var arr = ['0', '1', '2'];var i, x;for (i=0; i&lt;arr.length; i++) &#123; x = arr[i]; console.log(x);&#125;// &gt;for infor (var i in arr) &#123; console.log(i); console.log(a[i]);&#125; 12345678910// whilevar x = 0;var n = 99;while (n &gt; 0) &#123; x = x + n; n = n -2;&#125;console.log(x) 12345678// do...whilevar n = 0;do &#123; n = n + 1;&#125; while (n &lt; 100); // &gt;哈哈console.log(n); iterable遍历Array可以采用下标循环，遍历Map和Set就无法使用下标。为了统一集合类型，ES6标志引入了新的iterable类型，Array, Map, Set都属于iterable类型。 具有iterable类型的集合可以通过新的for...of循环来遍历。 123456789101112var a = ['A', 'B', 'C'];var s = new Set(['A', 'B', 'C']);var m = new Map([[1, 'x'], [2, 'y'], [3, 'z']]);for (var x of a) &#123; // 遍历Array console.log(x);&#125;for (var x of s) &#123; // 遍历Set console.log(x);&#125;for (var x of m) &#123; // 遍历Map console.log(x[0] + '=' + x[1]);&#125; 函数Function 借助抽象，我们才能不关心底层的具体计算过程，而直接在更高的层次上思考问题。写计算机程序也是一样，函数就是最基本的一种代码抽象的方式。 函数定义JavaScript中，定义函数的方式如下： 12345678910111213141516171819202122232425262728function abs(x) &#123; if (x &gt;= 0) &#123; return x; &#125; else &#123; return -x; &#125;&#125;// 匿名函数// 注意赋值语句结束需要;var abs = function (x) &#123; if (x &gt;= 0) &#123; return x; &#125; else &#123; return -x; &#125;&#125;;// 调用函数abs(10);/* 由于JS允许传入任意个参数而不影响调用， 因此传入的参数比定义的参数多也没有问题。 虽然函数内部并不需要这些参数。 */abs(10, 'haha', null); JS还有一个免费赠送的关键字arguments，它只在函数内部起作用，并且永远指向当前函数的调用者传入的所有参数。实际上arguments最常用于判断传入参数的个数。 1234567function abs() &#123; if (arguments.length === 0) &#123; return 0; &#125; var x = arguments[0]; return x &gt;= 0 ? x : -x :&#125; ES6标准引入了rest参数。 1234567891011121314function foo(a, b, ...rest) &#123; console.log(a); console.log(b); console.log(rest);&#125;foo(1, 2, 3, 4);// 1// 2// Array [3, 4]foo(1);// 1// undefined// Array [] 变量作用域在JavaScript中，用var申明的变量实际上是有作用域的。如果一个变量在函数体内部申明，则该变量的作用域为整个函数体，在函数体外不可引用该变量。 变量提升虽然JavaScript的函数有一个变量提升的特点，它会先扫描整个函数体的语句，把所有申明的变量提升到函数顶部。但我们在函数内部定义变量时，请在函数内部首先申明所有变量。 全局作用域不在任何函数内定义的变量就具有全局作用域。实际上，JavaScript默认有一个全局对象window，全局作用域实际上被绑定到window的一个属性。 123var course = 'JavaScript';alert(course);alert(window.course); 这说明JavaScript实际上只有一个全局作用域。任何变量（函数也视为变量），如果没有在当前函数作用域中找到，就会继续往上查找，最后如果在全局作用域中也没有找到，则报ReferenceError错误。 命名空间全局变量会绑定到window上，不同的JavaScript文件如果使用了相同的全局变量，或者定义了相同名字的顶层函数，都会造成命名冲突，并且很难被发现。 减少冲突的一个方法是把自己的所有变量和函数全部绑定到一个全局变量中。例如： 123456789// 唯一的全局变量MYAPPvar MYAPP = &#123;&#125;;MYAPP.name = 'myapp';MYAPP.version = 1.0;MYAPP.foo = function () &#123; return 'foo';&#125;; 把自己的代码全部放入唯一的命名空间MYAPP中，会大大减少全局变量冲突的可能。许多著名的JS库都是这么做的：jQuery, YUI等等。 局部作用域由于JavaScript的变量作用域实际上是函数内部，我们在for循环等语句块中是无法定义具有局部作用域的变量的。 为了解决块级作用域，ES6引入了新的关键字let，用let替代var可以申明一个块级作用域的变量。 常量由于var和let申明的是变量，如果要申明一个常量，在ES6之前是不行的，我们通常用全部大写的变量来表示这是一个常量，不要修改它的值。 1var PI = 3.14; ES6标准引入了新的关键字const来定义常量，const和let都具有块级作用域。 12const PI = 3.14;PI = 3; // TypeError: Assignment to constant variable. 解构赋值从ES6开始，JavaScript引入了解构赋值，可以同时对一组变量进行赋值。 使用解构赋值可以减少代码量，但是，需要在支持ES6解构赋值特性的现代浏览器中才能正常运行。 方法在一个对象中绑定函数，称为这个对象的方法。 12345678var xiaoming = &#123; name: 'Ming', birth: 1990, age: function () &#123; var y = new Date().getFullYear(); return y - this.birth; &#125;&#125;; 注意，有一个this关键字。在一个方法内部，this是一个特殊变量，它始终指向当前对象，也就是xiaoming这个变量。 我们可以控制this的指向。要确定函数的this指向哪个对象，可以用函数本身的apply方法，它接收两个参数，第一个参数就是需要绑定的this变量，第二个参数是Array，表示函数本身的参数。 另一个与apply()类似的方法是call()，唯一区别是： apply()把参数打包成Array再传入； call()把参数按顺序传入。 栗子： 123// Math.max(3, 5, 4)Math.max.apply(null, [3, 5, 4]);Math.max.call(null, 3, 5, 4); 对普通函数调用，我们通常把this绑定为null。 装饰器利用apply()，我们还可以动态改变函数的行为。 JavaScript的所有对象都是动态的，即使内置的函数，我们也可以重新指向新的函数。 高阶函数一个函数就可以接收另一个函数作为参数，这种函数就称之为高阶函数(Higher order function)。 123456function add(x, y, f) &#123; return (f(x) + f(y));&#125;add(-5, 6, Math.abs) map/reducemap()方法定义在JS的Array中。 123456function pow(x) &#123; return (x * x);&#125;var arr = [1, 2, 3];var results = arr.map(pow); // [1, 4, 9] reduce()把结果继续和序列的下一个元素做累积计算。 1234var arr = [1, 4, 5, 7];arr.reduce(function (x, y) &#123; return (x + y);&#125;); // 17 filterfilter()它用于把Array的某些元素过滤掉，然后返回剩下的元素。 12345// 保留奇数var arr = [1, 2, 3, 4, 5];var r = arr.filter(function (x)&#123; return (x % 2 !== 0);&#125;); sortJavaScript的Array的sort()方法就是用于排序的，但它默认把所有元素先转换为String再排序，如果不知道这个，那么用它直接对数字排序会栽进坑里。 其它高阶函数Array对象还提供了许多非常实用的高阶函数： every(): 判断数组的所有元素是否满足测试条件 find(): 查找符合条件的第一个元素，如果找到了，返回这个元素；否则，返回undefined findIndex(): 它返回查找元素的索引 forEach: 把每个元素依次作用于传入的函数，但不会返回新的数组。常用于遍历数组 闭包闭包是一种保护私有变量的机制，在函数执行时形成私有的作用域，保护里面的私有变量不受外界干扰。直观的说就是形成一个不销毁的栈环境。 箭头函数ES6新增了一种新的函数：箭头函数(Arrow Function)。感觉有点类似于Python的lambda。 1234567// arrow functionx =&gt; x * x// 相当于function (x) &#123; return x * x;&#125; 其它用法: 1234567891011121314// 两个参数(x, y) =&gt; (x * x) + (y * y)// 无参数() =&gt; 3.14// 可变参数(x, y, ...rest) =&gt; &#123; xxx;&#125;// 返回对象x =&gt; (&#123;foo: x&#125;) 生成器生成器(generator)是ES6标准引入的新的数据类型。一个生成器看上去像一个函数，但可以返回多次。同样类似于Python的生成器，还记得next和yield吗？哈哈。 1234567891011121314// generator 斐波那契数列function* fib(max) &#123; var t, a = 0, b = 1, n = 0; while (n &lt; max) &#123; //&gt;haha yield a; [a, b] = [b, a+b]; n++; &#125; return;&#125; 直接调用生成器和调用函数不一样，仅仅是创建了一个生成器对象，还没有去执行它。 123456789101112// 第一种方法：不断调用生成器对象的next()方法，需要判断是否donevar f = fib(5);f.next();f.next();...f.next()// 第二种方法：for ... of循环迭代生成器对象for (var x of fib(10)) &#123; console.log(x);&#125; 标准对象在JavaScript的世界里，一切都是对象。但某些对象还是和其它对象不一样。 1234// typeof 获取对象类型typeof 123; // 'number'typeof null; // 'object'typeof []; // 'object' JS还提供了包装对象，熟悉Java的小伙伴肯定很清楚int和Integer这种暧昧关系。虽然包装对象看上去和原来的值一摸一样，但是它们的类型已经变为object了。所以，闲的蛋疼也不要使用包装对象。 123456// 包装对象用 new 创建var n = new Number(123);var b = new Boolean(true);typeof new Number(123); // 'object'new Number(123) === 123; // false Date在JavaScript中，Date对象用来表示日期和时间。注意，当前时间是浏览器从本机操作系统获取的时间，所以不一定准确，因为用户可以把当前时间设定为任何值。 JavaScript的Date对象月份值从0开始，牢记0=1月，1=2月，2=3月，……，11=12月。 12345678910111213141516171819202122232425var now = new Date();now; // Wed Jun 24 2015 19:49:22 GMT+0800 (CST)now.getFullYear(); // 2015, 年份now.getMonth(); // 5, 月份，注意月份范围是0~11，5表示六月now.getDate(); // 24, 表示24号now.getDay(); // 3, 表示星期三now.getHours(); // 19, 24小时制now.getMinutes(); // 49, 分钟now.getSeconds(); // 22, 秒now.getMilliseconds(); // 875, 毫秒数now.getTime(); // 1435146562875, 以number形式表示的时间戳// 创建一个日期对象var d = new Date(2015, 5, 19, 20, 15, 30, 123);d; // Fri Jun 19 2015 20:15:30 GMT+0800 (CST)// 或ISO 8601格式var d = Date.parse('2015-06-24T19:49:22.875+08:00');d; // 1435146562875// 或时间戳var d = new Date(1435146562875);d; // Wed Jun 24 2015 19:49:22 GMT+0800 (CST)d.getMonth(); // 5 时区 Date对象表示的时间总是按浏览器所在的时区显示，不过我们既可以显示本地时间，也可以显示调整后的UTC时间。 123var d = new Date(1435146562875);d.toLocaleString(); // '2015/6/24 下午7:49:22'，本地时间（北京时区+8:00），显示的字符串与操作系统设定的格式有关d.toUTCString(); // 'Wed, 24 Jun 2015 11:49:22 GMT'，UTC时间，与本地时间相差8小时 RegExp强大的正则表达式！ 了解了基本的RE知识，我们就可以在JavaScript中使用正则表达式了。JS有两种方式创建一个正则表达式： /正则表达式/ new RegExp(&#39;正则表达式&#39;)，创建一个RegExp对象 1234567var re1 = /ABC\-001/;var re2 = new RegExp('ABC\\-001'); // 使用了转义字符// 测试正则var re = /^$d&#123;3&#125;\-\d&#123;3, 8&#125;$/;re.test('010-12345'); // true 切分字符串 用正则表达式切分字符串比用固定的字符更灵活。 123'a b c'.split(' '); // ['a', 'b', '', '', 'c']'a b c'.split(/\s+/); // ['a', 'b', 'c'] 分组 除了简单地判断是否匹配之外，正则表达式还有提取子串的强大功能。用()表示的就是要提取的分组（Group）。 如果正则表达式中定义了组，就可以在RegExp对象上用exec()方法提取出子串来。 123var re = /^(\d&#123;3&#125;)-(\d&#123;3,8&#125;)$/;re.exec('010-12345'); // ['010-12345', '010', '12345']re.exec('010 12345'); // null 贪婪匹配 需要特别指出的是，正则匹配默认是贪婪匹配，也就是匹配尽可能多的字符。 1234567// 贪婪匹配var re = /^(\d+)(0*)$/;re.exec('102300'); // ['102300', '102300', '']// 非贪婪匹配var re = /^(\d+?)(0*)$/;re.exec('102300'); // ['102300', '1023', '00'] 全局搜索 JavaScript的正则表达式还有几个特殊的标志，最常用的是g，表示全局匹配。 123var r1 = /test/g;// 等价于:var r2 = new RegExp('test', 'g'); JSONJSON是JavaScript Object Notation的缩写，它是一种轻量级的数据交换格式。 在JSON出现之前，大家一直用XML来传递数据。因为XML是一种纯文本格式，所以它适合在网络上交换数据。XML本身不算复杂，但是，加上DTD、XSD、XPath、XSLT等一大堆复杂的规范以后，任何正常的软件开发人员碰到XML都会感觉头大了，最后大家发现，即使你努力钻研几个月，也未必搞得清楚XML的规范。 JSON实际上是JavaScript的一个子集。在JSON中，一共就这么几种数据类型： number boolean string null array object JSON还定死了字符集必须是UTF-8，表示多语言就没有问题了。为了统一解析，JSON的字符串规定必须用双引号&quot;&quot;，Object的键也必须用双引号&quot;&quot;。 由于JSON非常简单，很快就风靡Web世界，并且成为ECMA标准。几乎所有编程语言都有解析JSON的库，而在JavaScript中，我们可以直接使用JSON，因为JavaScript内置了JSON的解析。 把任何JavaScript对象变成JSON，就是把这个对象序列化成一个JSON格式的字符串，这样才能够通过网络传递给其他计算机。如果我们收到一个JSON格式的字符串，只需要把它反序列化成一个JavaScript对象，就可以在JavaScript中直接使用这个对象了。 序列化 123456789101112// JavaScript object to JSONvar xiaoming = &#123; name: 'xiaoming', age: 14, gender: true, height: 1.65, grade: null, skills: ['JS', 'Java', 'Python']&#125;;var s = JSON.stringift(xiaoming);console.log(s); 反序列化 12// JSON to JavaScript objectJSON.parse('&#123;"name":"小明","age":14&#125;'); // Object &#123;name: '小明', age: 14&#125; 面向对象编程JavaScript的面向对象编程和大多数其他语言如Java、C#的面向对象编程都不太一样。面向对象的两个基本概念： 类：类是对象的模板 实例：根据类创建的对象 所以，类和实例是大多数面向对象编程语言的基本概念。 不过，在JavaScript中，这个概念需要改一改。JavaScript不区分类和实例的概念，而是通过原型（prototype）来实现面向对象编程。JavaScript没有类的概念，所有对象都是实例。所谓继承关系不过是把一个对象的原型指向另一个对象而已。 创建对象JavaScript对每个创建的对象都会设置一个原型，指向它的原型对象。 当我们用obj.xxx访问一个对象的属性时，JavaScript引擎先在当前对象上查找该属性，如果没有找到，就到其原型对象上找，如果还没有找到，就一直上溯到Object.prototype对象，最后，如果还没有找到，就只能返回undefined。 12345// 创建Array对象var arr = [1, 2, 3];// 原型链arr ----&gt; Array.prototype ----&gt; Object.prototype ----&gt; null 构造函数 JavaScript还可以用一种构造函数的方法来创建对象。 1234567891011121314151617// 定义一个构造函数function Student(name) &#123; this.name = name; this.hello = function () &#123; alert('Hello, ' + this.name + '!'); &#125;&#125;// 这确实是一个普通函数，但在JavaScript中，可以用关键字new来调用这个函数，并返回一个对象// 写了new， 它就变成了一个构造函数var xiaoming = new Student('小明');xiaoming.name;xiaoming.hello();// xiaoming的原型链xiaoming ----&gt; Student.prototype ----&gt; Object.prototype ----&gt; null 要让创建的对象共享一个函数，根据对象的属性查找规则，我们只需要把此函数移动到这些对象的原型上就可以了，也就是xxx.prototype: 1234567function Student(name) &#123; this.name = name;&#125;Student.prototype.hello = function() &#123; alert('Hello, ' + this.name + '!');&#125; 为了区分普通函数和构造函数，按照约定，构造函数首字母应当大写，而普通函数首字母应当小写。 原型继承在传统的基于类的语言中，继承的本质是扩展一个已有的类(class)，并生成新的子类(subclass)。 但是，由于JavaScript采用原型继承，我们无法直接扩展一个类，因为根本不存在类。 JavaScript的原型继承方式是： 定义新的构造函数，并在内部用call()调用希望继承的构造函数，并绑定this 借助中间函数F实现原型继承，最好通过封装的inherits函数完成 继续在新的构造函数的原型上定义新方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849function Student(props) &#123; this.name = props.name || 'Unnamed';&#125;Student.prototype.hello = function () &#123; alert('Hello, ' + this.name + '!');&#125;// PrimaryStudent构造函数:function PrimaryStudent(props) &#123; Student.call(this, props); this.grade = props.grade || 1;&#125;// 空函数F:function F() &#123;&#125;// 把F的原型指向Student.prototype:F.prototype = Student.prototype;// 把PrimaryStudent的原型指向一个新的F对象，F对象的原型正好指向Student.prototype:PrimaryStudent.prototype = new F();// 把PrimaryStudent原型的构造函数修复为PrimaryStudent:PrimaryStudent.prototype.constructor = PrimaryStudent;// 继续在PrimaryStudent原型（就是new F()对象）上定义方法：PrimaryStudent.prototype.getGrade = function () &#123; return this.grade;&#125;;// 创建xiaoming:var xiaoming = new PrimaryStudent(&#123; name: '小明', grade: 2&#125;);xiaoming.name; // '小明'xiaoming.grade; // 2// 验证原型:xiaoming.__proto__ === PrimaryStudent.prototype; // truexiaoming.__proto__.__proto__ === Student.prototype; // true// 验证继承关系:xiaoming instanceof PrimaryStudent; // truexiaoming instanceof Student; // true class继承JavaScript的对象模型是基于原型实现的，特点是简单，缺点是理解起来比传统的类－实例模型要困难，最大的缺点是继承的实现需要编写大量代码，并且需要正确实现原型链。 但有更简单的写法。在ES6标准中，新的关键字class正式被引入到JavaScript中。它的目的就是让定义类更简单。 1234567891011121314// class的定义包含了构造函数constructorclass Student &#123; constructor(name) &#123; this.name = name; &#125; hello() &#123; alert('Hello, ' + this.name + '!'); &#125;&#125;// 创建对象var xiaoming = new Student('小明');xiaoming.hello(); 用class定义对象的另一个巨大好处是继承更方便了。不需要写大量的中间对象，直接通过extends来实现： 123456789class PrimaryStudent extends Student &#123; constructor(name, grade) &#123; super(name); // 记得用super调用父类的构造方法! this.grade = grade; &#125; myGrade() &#123; alert('I am at grade ' + this.grade); &#125;&#125; 要注意浏览器是不是支持ES6的class。 浏览器由于JavaScript的出现就是为了能在浏览器中运行，所以，浏览器自然是JavaScript开发者必须要关注的。 目前，主流浏览器分这几种： IE 6-11：从IE 10开始支持ES6； Chrome：Google出品的基于Webkit内核，内置非常强悍的JS引擎——V8。支持ES6； Safari：Mac自带的基于Webkit内核，支持ES6； Firefox：Mozilla研制的Gecko内核和JS引擎OdinMonkey。支持ES6； 移动设备(IOS/Android)：支持ES6 不同的浏览器对JavaScript支持的差异主要是，有些API的接口不一样，比如AJAX，File接口。对于ES6标准，不同的浏览器对各个特性支持也不一样。 在编写JavaScript的时候，就要充分考虑到浏览器的差异，尽量让同一份JavaScript代码能运行在不同的浏览器中。 浏览器对象JavaScript可以获取浏览器提供的很多对象，并进行操作。 windowwindow对象不但充当全局作用域，而且表示浏览器窗口。属性： innerWidth：浏览器窗口的内部宽度 innerHeight：内部高度 outerWidth: 浏览器窗口整个宽度 outerHeight: 整个高度 内部宽高是指除去菜单栏、工具栏、边框等占位元素后，用于显示网页的净宽高。 12// 可以调整浏览器窗口大小，进行测试cosole.log('window inner size: ' + window.innerWidth + 'x' + window.innerHeight); navigatornavigator表示浏览器的信息，最常用的属性包括： appName：浏览器名称； appVersion：浏览器版本； language：浏览器设置的语言； platform：操作系统类型； userAgent：浏览器设置的User-Agent字符； 请注意，navigator的信息可以轻易的被用户修改。 12345console.log('appName = ' + navigator.appName);console.log('appVersion = ' + navigator.appVersion);console.log('language = ' + navigator.language);console.log('platform = ' + navigator.platform);console.log('userAgent = ' + navigator.userAgent); screenscreen对象表示屏幕的信息，常用的属性有： width：屏幕宽度(px)； height：屏幕高度(px)； colorDepth：颜色位数； 1console.log('Screen size = ' + screen.width + ' x ' + screen.height); locationlocation对象表示当前页面的URL信息。 href：完整的URL protocol：协议 host: 主机名 port：端口 pathname： 路径 search： 参数 hash： assign()：加载一个新页面 reload()：重载当前页面 12345if (confirm('重新加载当前页' + location.href + '?')) &#123; location.reload();&#125; else &#123; location.assign('/'); // 设置一个新的URL地址&#125; documentdocument对象表示当前页面。由于HTML在浏览器中以DOM形式表示为树形结构，document对象就是整个DOM树的根节点。 title getElementById()：按id获得一个DOM节点； getElementsByTagName()：按tag获得一个DOM节点； getElementsByClassName() cookie：为了确保安全，服务器端在设置Cookie时，应该始终坚持使用httpOnly； 12// document.title属性从HTML文档中&lt;title&gt;xxx&lt;/title&gt;读取，但可以动态改变document.title = 'DOM title'; historyhistory保存了浏览器的历史记录，JavaScript可以调用history()对象的back()或forward()。这个对象属于历史遗留问题，任何情况，你都不应该使用history这个对象。 DOMDOM(文档对象模型, document object model)，是W3C(万维网联盟)的标准。它定义了访问HTML和XML文档的标准。 由于HTML文档被浏览器解析后就是一棵DOM树，要改变HTML的结构，就需要通过JavaScript来操作DOM。 DOM节点有几个操作： 更新 遍历 添加 删除 在操作一个DOM节点前，我们需要通过各种方式先拿到这个DOM节点。常用的方法： document.getElementById()：由于ID在HTML文档中是唯一的，所以可以直接定位唯一的一个DOM节点。 document.getElementsByTagName()：返回一组DOM节点 document.getElementsByClassName()：要精确地选择DOM，可以先定位父节点，再从父节点开始选择，以缩小范围 document.querySelector() document.queryAelectorAll() 更新DOM拿到DOM节点后，我们可以对它进行更新。可以直接修改节点文本，方法有两种： 一种是修改innerHTML属性，这个方式非常强大，不但可以修改一个DOM节点的文本内容，还可以直接通过HTML片段修改DOM节点内部的子树。用innerHTML时要注意，是否需要写入HTML。如果写入的字符串是通过网络拿到了，要注意对字符编码来避免XSS攻击。 1234567// 获取&lt;p id="p-id"&gt;...&lt;/p&gt;var p = document.getElementById('p-id');// 设置文本为abc:p.innerHTML = 'ABC'; // &lt;p id="p-id"&gt;ABC&lt;/p&gt;// 设置HTML:p.innerHTML = 'ABC &lt;span style="color:red"&gt;RED&lt;/span&gt; XYZ';// &lt;p&gt;...&lt;/p&gt;的内部结构已修改 第二种是修改innerText或textContent属性，这样可以自动对字符串进行HTML编码，保证无法设置任何HTML标签。 123456// 获取&lt;p id="p-id"&gt;...&lt;/p&gt;var p = document.getElementById('p-id');// 设置文本:p.innerText = '&lt;script&gt;alert("Hi")&lt;/script&gt;';// HTML被自动编码，无法设置一个&lt;script&gt;节点:// &lt;p id="p-id"&gt;&amp;lt;script&amp;gt;alert("Hi")&amp;lt;/script&amp;gt;&lt;/p&gt; 两者的区别在于读取属性时，innerText不返回隐藏元素的文本，而textContent返回所有文本。因为CSS允许font-size这样的名称，但它并非JavaScript有效的属性名，所以需要在JavaScript中改写为驼峰式命名fontSize。 修改CSS也是经常需要的操作。DOM节点的style属性对应所有的CSS，可以直接获取或设置。 123456// 获取&lt;p id="p-id"&gt;...&lt;/p&gt;var p = document.getElementById('p-id');// 设置CSS:p.style.color = '#ff0000';p.style.fontSize = '20px';p.style.paddingTop = '2em'; 插入DOM如果DOM节点是空的，那么，直接使用innerHTML = &lt;x&gt;aaa&lt;/x&gt;就可以修改DOM节点的内容，相当于插入了新的DOM节点。 如果DOM节点不是空，则不能这样做。有两个新办法。 一个是使用appendChild：把一个子节点添加到父节点的最后一个子节点。 1234var js = document.getElementById('js'), list = document.getElementById('list);list.append(js); 1234567// 更多的时候，我们会从零创建一个新的节点，然后插入到指定位置var list = document.getElementById('list'), haskell = document.createElement('p');haskell.id = 'haskell';haskell.innerText = 'Haskell';list.appendChild(haskell); 动态创建一个节点，然后田间道DOM树中，可以实现很多功能。 1234var d = document.createElement('style');d.setAttribute('type', 'text/css');d.innerHTML = 'p &#123;color: red&#125;';document.getElementsByTagName('head')[0].appendChild(d); 这个栗子更改了颜色。可在浏览器的console上执行来看效果。 insertBefore 使用parentElement.insertBefore(newElement, referenceElement);，子节点会插入到referenceElement之前。 1234567var list = document.getElementById('list'), ref = document.getElementById('python'), haskell = document.createElement('p');haskell.id = 'haskell';haskell.innerText = 'Haskell';list.insertBefore(haskell, ref); 可见，使用insertBefore重要的是拿到一个参考子节点的引用。很多时候，需要循环一个父节点的所有字节嗲，可以通过children属性实现： 123456var i, c, list = document.getElementById('list');for (i = 0; i &lt; list.children.length; i++) &#123; //&gt;haha c = list.children[i];&#125; 删除DOM要删除一个节点，首先要获得该节点本身以及它的父节点。然后，调用父节点的removeChild把自己删掉。 1234567// 拿到待删除节点:var self = document.getElementById('to-be-removed');// 拿到父节点:var parent = self.parentElement;// 删除:var removed = parent.removeChild(self);removed === self; // true 注意，删除后的节点虽不在文档树中，但其实它还在内存中，可以随时在此被添加到别的位置。 当你遍历一个父节点的子节点并进行删除操作时，要注意，children属性是一个只读属性，并且它在子节点变化时会实时更新。因此，删除多个节点时，要注意children属性时刻都在变化。 操作表单用JavaScript操作表单和操作DOM是类似的，因为表单本身也是DOM树。 不过，表单的输入框、下拉框等可以接收用户输入，所以用JavaScript来操作表单，可以获得用户输入的内容，或者对一个输入框设置新的内容。 HTML表单的输入控件主要有以下几种： 文本框：&lt;input type=&quot;text&quot;&gt;; 口令框：&lt;input type=&quot;password&quot;&gt;; 单选框：&lt;input type=&quot;radio&quot;&gt;; 复选框：&lt;input type=&quot;checkbox&quot;&gt;; 下拉框：&lt;select&gt;; 隐藏文本，用户不可见，但表单提交时会把隐藏文本发送到服务器: input type=&quot;hidden&quot;&gt;。 获取值如果我们获取了一个&lt;input&gt;节点的引用，就可以调用value获得对应的用户输入值。 123// &lt;input type="text" id="email"&gt;var input = document.getElementById('email');input.value; // '用户输入的值' 这种方式可以用于text, password, hidden, select。但是，对于单选框和复选框，value属性返回的永远是HTML预设的值，而我们需要获得的实际是用户是否勾上了选项，所以应该用checked判断。 12345678// &lt;label&gt;&lt;input type="radio" name="weekday" id="monday" value="1"&gt; Monday&lt;/label&gt;// &lt;label&gt;&lt;input type="radio" name="weekday" id="tuesday" value="2"&gt; Tuesday&lt;/label&gt;var mon = document.getElementById('monday');var tue = document.getElementById('tuesday');mon.value; // '1'tue.value; // '2'mon.checked; // true或者falsetue.checked; // true或者false 设置值对于text, password, hidden, select，直接设置value就可以。对于单/复选框，设置checked为true或false即可。 123// &lt;input type="text" id="email"&gt;var input = document.getElementById('email');input.value = 'test@example.com'; // 文本框的内容已更新 HTML5控件HTML5新增了大量标准空间，常用的包括date, datetime, datetime-local, color…，它们都使用&lt;input&gt;标签。 不支持HTML5的浏览器无法识别新的控件，会把它们当做type=&quot;text&quot;来显示。支持HTML5的浏览器将获得格式化的字符串。 提交表单最后，JavaScript可以以两种方式来处理表单的提交（AJAX方式在后面介绍）。 一是通过&lt;form&gt;元素的submit()方法提交一个表单。这种方式的缺点是扰乱了浏览器对form的正常提交。 1234567891011121314&lt;!-- html --&gt;&lt;form id="test-form"&gt; &lt;input type="text" name="test"&gt; &lt;button type="button" onclick="doSubmitForm()"&gt;Submit&lt;/button&gt;&lt;/form&gt;&lt;script&gt;function doSubmitForm() &#123; var form = document.getElementById('test-form'); // 可在此修改form的input // 提交form form.submit();&#125;&lt;/script&gt; 第二种方式是响应&lt;form&gt;本身的onsubmit事件，在提交form时作修改： 123456789101112&lt;!-- html --&gt;&lt;form id="test-form" onsubmit="return checkForm()"&gt; &lt;input type="text" name="test"&gt; &lt;button type="submit"&gt;Submit&lt;/button&gt;&lt;/form&gt;&lt;script&gt;function checkForm() &#123; var form = document.getElementById('test-id'); return true;&#125;&lt;/script&gt; 注意要return true来告诉浏览器继续提交，如果return false，浏览器将不会继续提交form，这种情况通常对应用户输入有误，提示用户错误信息后终止提交form。 在检查和修改&lt;input&gt;时，要充分利用&lt;input type=&quot;hidden&quot;&gt;来传递数据。例如，很多登录表单希望用户输入的口令（出于安全考虑）在提交表单时不传输明文口令，而是口令的MD5。 123456789101112131415&lt;!-- html --&gt;&lt;form id="login-form" method="post" onsubmit="return checkForm()"&gt; &lt;input type="text" id="username" name="username"&gt; &lt;input type="password" id="password" name="password"&gt; &lt;button type="submit"&gt;Submit&lt;/button&gt;&lt;/form&gt;&lt;script&gt;function checkForm() &#123; var pwd = document.getElementById('password'); // to MD5 pwd.value = toMD5(pwd.value); return true;&#125;&lt;/script&gt; 这样做看上去没问题，但用户输入了口令提交时，口令框突然会从几个*变为32个**（MD5有32个字符）。若不想改变用户的输入，可利用&lt;input type=&quot;hidden&quot;&gt;实现： 123456789101112131415161718&lt;!-- HTML --&gt;&lt;form id="login-form" method="post" onsubmit="return checkForm()"&gt; &lt;input type="text" id="username" name="username"&gt; &lt;input type="password" id="input-password"&gt; &lt;input type="hidden" id="md5-password" name="password"&gt; &lt;button type="submit"&gt;Submit&lt;/button&gt;&lt;/form&gt;&lt;script&gt;function checkForm() &#123; var input_pwd = document.getElementById('input-password'); var md5_pwd = document.getElementById('md5-password'); // 把用户输入的明文变为MD5: md5_pwd.value = toMD5(input_pwd.value); // 继续下一步: return true;&#125;&lt;/script&gt; 没有name属性的&lt;input&gt;的数据不会被提交。 操作文件在HTML表单中，可以上传文件的唯一控件就是&lt;input type=&quot;file&quot;&gt;。 注意：当一个表单包含&lt;input type=&quot;file&quot;&gt;时，表单的enctype必须指定为multipart/form-data，method必须指定为post，浏览器才能正确编码并以multipart/form-data格式发送表单的数据。 处于安全考虑，浏览器只允许用户点击&lt;input type=&quot;file&quot;&gt;来选择本地文件，用JavaScript对&lt;input type=&quot;file&quot;&gt;的value赋值是没有任何效果的。当用户选择了上传某个文件后，JavaScript也无法获得该文件的真实路径。 通常，上传的文件都由后台服务器处理，JavaScript可以在提交表单时对文件的扩展名做检查，以便防止用户上传无效格式的文件。 1234567var f = document.getElementById('file-upload');var filename = f.value;if(!filename || !(filename.endsWith('.jpg')) || filename.endsWith('.png') || filename.endsWith('.gif')) &#123; alert("Can only upload image file."); return false;&#125; File API 由于JavaScript对用户上传的文件操作非常有限，尤其是无法读取文件内容，使得很多需要操作文件的网页不得不用Flash这样的第三方插件来实现。 随着HTML5的普及，新增的File API允许JavaScript读取文件内容，获得更多的文件信息。HTML5的File API提供了File和FileReader两个主要对象，可以获得文件信息并读取文件。 回调 在JavaScript中，浏览器的JavaScript执行引擎在执行JavaScript代码时，总是以单线程模式执行，也就是说，任何时候，JavaScript代码都不可能同时有多于1个线程在执行。 你可能会问，单线程模式执行的JavaScript，如何处理多任务？在JavaScript中，执行多任务实际上都是异步调用。因为是异步操作，所以我们在JavaScript代码中就不知道什么时候操作结束，因此需要先设置一个回调函数： 123reader.onload = function(e) &#123; // 操作完成后，自动调用此函数&#125;; AJAXAJAX(Asynchronous JavaScript and XML)不是JavaScript的规范，意思是用JavaScript执行异步网络请求。 如果仔细观察一个Form的提交，你就会发现，一旦用户点击Submit按钮，表单开始提交，浏览器就会刷新页面，然后在新页面里告诉你操作是成功了还是失败了。如果不幸由于网络太慢或者其他原因，就会得到一个404页面。 这就是Web的运作原理：一次HTTP请求对应一个页面。 如果要让用户留在当前页面中，同时发出新的HTTP请求，就必须用JavaScript发送这个新请求，接收到数据后，再用JavaScript更新页面，这样一来，用户就感觉自己仍然停留在当前页面，但是数据却可以不断地更新。 最早大规模使用AJAX的就是Gmail，Gmail的页面在首次加载后，剩下的所有数据都依赖于AJAX来更新。 用JavaScript写一个完整的AJAX代码并不复杂，但是需要注意：AJAX请求是异步执行的，也就是说，要通过回调函数获得响应。 123456789101112131415161718192021222324252627282930313233// 在现代浏览器上写AJAX主要依靠XMLHttpRequest对象function success(text) &#123; var textarea = document.getElementById('response-text'); textarea.value = text;&#125;function fail(code) &#123; var textarea = document.getElementById('response-text'); textarea.value = 'Error code: ' + code;&#125;var request = new XMLHttpRequest(); // 新建XMLHttpRequest对象request.onreadystatechange = function () &#123; // 状态发生变化时，函数被回调 if (rquest.readyState === 4) &#123; // 判断相应结果 if (request.status === 200) &#123; return success(request.responseText); &#125; else &#123; return fail(request.status); &#125; &#125; else &#123; // HTTP请求还在继续 &#125;&#125;// 发送请求request.open('GET', '/api/categories');request.send();alert('请求已发送，请等待响应...'); 安全限制 上面代码的URL使用的是相对路径。如果你把它改为http://xxx.com/，再运行，肯定会报错。在console里，还可以看到错误信息。 这是因为浏览器的同源策略导致的。默认情况下，JavaScript在发送AJAX请求时，URL的域名必须和当前页面完全一致。 那是不是JavaScript无法请求外域（其它网站）的URL了呢？方法还是有的： 一是通过Flash插件发送HTTP请求，这种方式可以绕过浏览器的安全限制，但必须安装Flash，并且跟Flash交互。不过Flash用起来麻烦，而且现在用得也越来越少了。 二是通过在同源域名下架设一个代理服务器来转发，JavaScript负责把请求发送到代理服务器。代理服务器再把结果返回，这样就遵守了浏览器的同源策略。这种方式麻烦之处在于需要服务器端额外做开发。 三是JSONP。它有个限制，只能用GET请求，并且要求返回JavaScript。这种方式跨域实际上是利用了浏览器允许跨域引用JavaScript资源。 CORS 如果浏览器支持HTML5，那么就可以一劳永逸地使用新的跨域策略：CORS(Cross-Origin Resource Sharing)，它是HTML5规范定义的如何跨域访问资源。 了解CORS前，我们先搞明白概念。Origin表示本域，也就是浏览器当前页面的域。当JavaScript向外域发起请求后，浏览器收到响应后，首先检查Access-Control-Allow-Origin是否包含本域，如果是，则此次跨域请求成功，如果不是，则请求失败，JavaScript将无法获取到响应的任何数据。 可见，跨域能否成功，取决于对方服务器是否愿意给你设置一个正确的Access-Control-Allow-Origin，决定权始终在对方手中。 Promise在JavaScript的世界中，所有代码都是单线程执行的。由于这个缺陷，导致JavaScript的所有网络操作，浏览器事件，都必须是异步执行。 异步执行可以用回调函数实现： 123456function callback() &#123; console.log('Done');&#125;console.log("before setTimeout()");setTimeout(callback, 1000); // 1s后调用callbackconsole.log("after setTimeout()"); 可见，异步操作会在将来某个时间点触发一个函数调用。 Promise有各种开源实现，在ES6中被统一规范，由浏览器直接支持。 Promise最大的好处是在异步执行的流程中，把执行代码和处理结果的代码清洗地分离。 Promise还可以做更多的事情，比如，有若干个异步任务，需要先做任务1，如果成功后再做任务2，任何任务失败则不再继续并执行错误处理函数。要串行执行这样的异步任务，不用Promise需要些一层一层的嵌套代码。 12// job 1, 2, 3都是Promise对象job1.then(job2).then(job3).catch(handleError); 除了串行执行若干异步任务外，Promise还可以并行执行异步任务。 如果我们组合使用Promise，就可以把很多异步任务以并行和串行的方式组合起来执行。 CanvasCanvas是HTML5新增的组件，它就像一块幕布，可以用JavaScript在上面绘制各种图标、动画等。没有Canvas的年代，绘图只能借助Flash插件实现，页面不得不用JavaScript和Flash进行交互。有了Canvas，我们就再也不需要Flash了，直接使用JavaScript完成绘制。 一个Canvas定义了一个指定尺寸的矩形框，在这个范围内我们可以随意绘制： 1&lt;canvas id="test-canvas" width="300" height="200"&gt;&lt;/canvas&gt; 绘制形状 我们可以在Canvas上绘制各种形状。在绘制前，我们需要了解以下Canvas的坐标系统。Canvas的坐标以左上角为原点，水平向右为X轴，垂直向下为Y轴，以像素为单位，所以每个点都是非负整数。 绘制文本 绘制文本就是在指定的位置输出文本，可以设置文本的字体、样式、阴影等，与CSS完全一致。 Canvas除了能绘制基本的形状和文本，还可以实现动画、缩放、各种滤镜和像素转换等高级操作。如果要实现非常复杂的操作，考虑以下优化方案： 通过创建一个不可见的Canvas来绘图，然后将最终绘制结果复制到页面的可见Canvas中； 尽量使用整数坐标而不是浮点数； 可以创建多个重叠的Canvas绘制不同的层，而不是在一个Canvas中绘制非常复杂的图； 背景图片如果不变可以直接用&lt;img&gt;标签并放到最底层。 JQuery你可能听说过jQuery，它名字起得很土，但却是JavaScript世界中使用最广泛的一个库。江湖传言，全世界大约有80~90%的网站直接或间接地使用了jQuery。鉴于它如此流行，又如此好用，所以每一个入门JavaScript的前端工程师都应该了解和学习它。 JQuery的理念是Write Less, Do More，让你写更少的代码，完成更多的工作。 JQuery能帮助解决一些很重要的问题： 消除浏览器差异 简洁的操作DOM的方法：写$(&#39;#test&#39;)肯定比document.getElementById(&#39;test&#39;)来的简洁 轻松实现动画、修改CSS等各种操作。 JQuery版本 JQuery有1.x和2.x两个主要版本，区别在于2.x移除了对古老的IE6、7、8的支持，因此2.x的代码更精简。 JQuery只是一个jquery-xxx.js文件，但你会看到有compressed（已压缩）和uncompressed（未压缩）两种版本，使用时完全一样，但如果你想深入研究jQuery源码，那就用uncompressed版本。 使用JQuery 使用JQuery只需要在页面的&lt;head&gt;引入JQuery文件即可： 123456789&lt;html&gt;&lt;head&gt; &lt;script src="code.jquery.com/jquery-2.1.4.min.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;...&lt;/body&gt;&lt;/html&gt; $符号 `符号是著名的JQuery符号。实际上，Jquery把所有功能全部封装在一个全局变量`JQuery`中，而`也是一个合法的变量名，它是JQuery的别名。 1234window.jQuery; // jQuery(selector, context)window.$; // jQuery(selector, context)$ === jQuery; // truetypeof($); // 'function' `本质上是一个函数，但函数也是对象。于是`除了可以直接调用外，也可以有很多其它属性。 注意：你看到的`函数名可能不是`JQuery(selector, context)`，因为很多JavaScript压缩工具可以对函数名和参数改名，所以压缩过的JQuery源码`函数可能变成a(b, c)。 绝大多数时候，我们都直接用`。但是，如果`这个变量不幸地被占用了，而且还不能改，那我们只能让JQuery把$变量交出来，然后就只能使用JQuery这个变量。 1234$; // jQuery(selector, context)jQuery.noConflict();$; // undefinedjQuery; // jQuery(selector, context) 这种黑魔法的原理是JQuery在占用`之前，现在内部保存了原来的`，调用JQuery.noConflict()时会把原来保存的变量还原。 选择器选择器是JQuery的核心，一个选择器写出来大概是这样：$(&#39;#dom-id&#39;)。 为什么JQuery要发明选择器？来回顾一下DOM操作中经常使用的代码： 12345// 按ID查找var a = document.getElementById('dom-id');// 按tag查找var divs = document.getElementsByTagName('div'); 这些代码实在太过繁琐。并且在层级关系中，很多时候需要递归查找所有子节点。JQuery的选择器就是帮助我们快速定位到一个或多个DOM节点。 按id查找 123var div = $('#abc');// 如果不存在，则返回 [] 它返回JQuery对象。JQuery对象类似数组，它的每个元素都是一个引用了DOM节点的对象。 JQuery的选择器不会返回undefined或null，这样的好处是不必在下一行判断if (div === undefined)。 1234// JQuery对象和DOM对象直接可以互相转化var div = $('#abc'); //JQuery对象var divDom = div.get(0); // 假设存在div，获取第1个DOM元素var another = $(divDom); // 重新把DOM包装为JQuery对象 通常情况下你不需要获取DOM对象，直接使用jQuery对象更加方便。如果你拿到了一个DOM对象，那可以简单地调用$(aDomObject)把它变成jQuery对象，这样就可以方便地使用jQuery的API了。 按tag查找 12var ps = $('p'); // 返回所有&lt;p&gt;节点ps.length; // 数一数页面有多少个&lt;p&gt;节点 按class查找 1234var a = $('.red'); // 所有节点包含`class="red"`都将返回// 多个classvar a = $('.red.green'); // 注意没有空格！ 按属性查找 12345var email= $('[name=email]'); // 找出所有name属性为email的DOM// 还可使用前缀/后缀查找var icons = $('[name^=icon]'); // 找出所有name属性以icon开头的DOMvar names = $('[name$=with]'); // 找出所有name属性以with结尾的DOM 组合查找 组合查找就是把上述简单选择器组合起来使用。 1234var emailInput = $('input[name=email]');// tag and classvar tr = $('tr.red'); // 找出&lt;tr class='red ...'&gt;...&lt;/tr&gt; 多项选择器 多项选择器就是把多个选择器用逗号,组合起来： 12$('p,div'); // 把&lt;p&gt;和&lt;div&gt;都选出来$('p.red, p.green'); 层级选择器除了基本的选择器外，jQuery的层级选择器更加灵活，也更强大。因为DOM的结构就是层级结构，所以我们经常要根据层级关系进行选择。 层级选择器(Descendant Selector) 如果两个DOM元素具有层级关系，就可以用$(&#39;ancestor descendant&#39;)来选择，层级之间用空格隔开。 123$('ul.lang li.lang-javascript');$('div.testing li.lang-python'); 这种层级选择器相比单个的选择器好处在于，它缩小了选择范围，因为首先要定位父节点，才能选择相应的子节点，这样避免了页面其他不相关的元素。 子选择器(Child Selector) 子选择器$(&#39;parent&gt;child&#39;)是限定了父子关系的层级选择器。 1$('ul.lang&gt;li.lang-javascript'); 过滤器(Filter) 过滤器一般不单独使用，它通常附加在选择器上，帮助我们更精确地定位元素。 1234$('ul.lang li');$('ul.lang li:first-child');$('ul.lang li:nth-child(2)'); 表单相关 针对表单元素，jQuery还有一组特殊的选择器: :input，可选择input, textarea, select, button :file，可选择&lt;input type=&quot;file&quot;&gt;，和input[type=file]一样 :checkbox :radio :focus :checked :enabled :disabled 查找和过滤通常情况下选择器可以直接定位到我们想要的元素，但是，当我们拿到一个jQuery对象后，还可以以这个对象为基准，进行查找和过滤。 1234567891011121314151617181920// find()查找var ul = $('ul.lang'); // 获得&lt;ul&gt;var dy = ul.find('.dy'); // 获得JavaScript, Python, Schemevar swf = ul.find('#swift'); // 获得Swiftvar hsk = ul.find('[name=haskell]'); // 获得Haskell// 要从当前节点开始向上查找，使用parent()方法var swf = $('#swift'); // 获得Swiftvar parent = swf.parent(); // 获得Swift的上层节点&lt;ul&gt;var a = swf.parent('.red'); // 获得Swift的上层节点&lt;ul&gt;，同时传入过滤条件。如果ul不符合条件，返回空jQuery对象// 对于位于同一层级的节点，可以通过next()和prev()var swift = $('#swift');swift.next(); // Schemeswift.next('[name=haskell]'); // 空的jQuery对象，因为Swift的下一个元素Scheme不符合条件[name=haskell]swift.prev(); // Pythonswift.prev('.dy'); // Python，因为Python同时符合过滤器条件.dy 123// filter()方法可以过滤不符合选择器条件的节点var langs = $('ul.lang li'); // 拿到JavaScript, Python, Swift, Scheme和Haskellvar a = langs.filter('.dy'); // 拿到JavaScript, Python, Scheme 操作DOMjQuery的选择器很强大，用起来又简单又灵活，但是搞了这么久，我拿到了jQuery对象，到底要干什么？ 当然是操作对应的DOM节点啦！ 回顾一下修改DOM的CSS、文本、设置HTML有多么麻烦，而且有的浏览器只有innerHTML，有的浏览器支持innerText，有了jQuery对象，不需要考虑浏览器差异了，全部统一操作！ 修改Text和HTML jQuery对象的text()和html()方法分别获取节点的文本和原始HTML文本。 12345678910// 获取$('#ul li[name=book]').text();$('#ul li[name=book]').html();// 修改var j1 = $('#test-ul li.js');var j2 = $('#test-ul li[name=book]');j1.html('&lt;span style="color: red"&gt;JavaScript&lt;/span&gt;');j2.text('JavaScript &amp; ECMAScript'); 修改CSS 12345// css('name', 'value')var div = $('#test-div');div.css('color'); // '#000033', 获取CSS属性div.css('color', '#336699'); // 设置CSS属性div.css('color', ''); // 清除CSS属性 显示和隐藏DOM 考虑到显示和隐藏DOM元素使用非常普遍，jQuery直接提供show()和hide()方法。 注意，隐藏DOM节点并未改变DOM树的结构，它只影响DOM节点的显示。这和删除DOM节点是不同的。 123var a = $('a[target=_blank]');a.hide(); // 隐藏a.show(); // 显示 获取DOM信息 利用jQuery对象的若干方法，我们直接可以获取DOM的许多信息，而无需针对不同浏览器编写特定代码。 width() height() attr()：获取或修改属性 removeAttr() prop() … 12345678910$(window).width();$(window).height();var div = $('#test-div');div.width(400);div.height('200px');div.attr('name');div.attr('name', 'Hello');div.removeAttr('name'); 操作表单 对于表单元素，jQuery对象统一提供val()方法获取和设置对应的value属性。一个val()就统一了各种输入框的取值和赋值的问题。 123456var input = $('#input'), select = $('#select'), textarea = $('#textarea');input.val();input.val('xxx@example.com'); 修改DOM结构有了jQuery，我们就专注于操作jQuery对象本身，底层的DOM操作由jQuery完成就可以了，这样一来，修改DOM也大大简化了。 添加DOM 除了html()这种暴力方法外，还可以用append()方法。append()把DOM添加到最后，prepend()则把DOM添加到最前。 12var ul = $('#test-div&gt;ul');ul.append('&lt;li&gt;&lt;span&gt;xxx&lt;/span&gt;&lt;/li&gt;'); 除了接受字符串，append()还可以传入原始的DOM对象、jQuery对象和函数对象。 12345678910111213// 创建DOM对象:var ps = document.createElement('li');ps.innerHTML = '&lt;span&gt;Pascal&lt;/span&gt;';// 添加DOM对象:ul.append(ps);// 添加jQuery对象:ul.append($('#scheme'));// 添加函数对象:ul.append(function (index, html) &#123; return '&lt;li&gt;&lt;span&gt;Language - ' + index + '&lt;/span&gt;&lt;/li&gt;';&#125;); 同级节点可以用after()或者before()方法。 删除节点 要删除DOM节点，拿到jQuery对象后直接调用remove()方法就可以了。如果jQuery对象包含若干DOM节点，实际上可以一次删除多个DOM节点。 事件因为JavaScript在浏览器中以单线程模式运行，页面加载后，一旦页面上所有的JavaScript代码被执行完后，就只能依赖触发事件来执行JavaScript代码。 浏览器在接收到用户的鼠标或键盘输入后，会自动在对应的DOM节点上触发相应的事件。如果该节点已经绑定了对应的JavaScript处理函数，该函数就会自动调用。由于不同的浏览器绑定事件的代码都不太一样，所以用jQuery来写代码，就屏蔽了不同浏览器的差异，我们总是编写相同的代码。 123456789101112// 栗子：点击超链接弹出提示框，用jQuery绑定一个click事件var a = $('#test-link');a.on('click', function () &#123; alert('Hello!';)&#125;);// on方法用来绑定一个事件，需要传入事件名称和对应的处理函数// 一种更简化的写法a.click(function () &#123; alert('Hello!');&#125;); jQuery能够绑定的事件主要有： 鼠标事件 click：鼠标单击时触发； dblclick：鼠标双击时触发； mouseenter：鼠标进入时触发； mouseleave：鼠标移出时触发； mousemove：鼠标在DOM内部移动时触发； hover：鼠标进入和退出时触发两个函数（相当于mouseenter+mouseleave）。 键盘事件：仅作用在当前焦点的DOM上 keydown：键盘按下时触发； keyup：键盘松开时触发； keypress：按一次键后触发。 其它事件 focus：当DOM获得焦点时触发； blur：当DOM失去焦点时触发； change：当input, select, textarea的内容改变时触发； submit：当form提交时触发； ready：当页面被载入并且DOM树完成初始化后触发。 取消绑定 一个已被绑定的事件可以解除绑定，通过off(&#39;click&#39;, function)实现。 12345678910function hello() &#123; alert('hello!');&#125;a.click(hello); // 绑定事件// 10秒钟后解除绑定:setTimeout(function () &#123; a.off('click', hello);&#125;, 10000); 需要特别注意，以下这种写法无效： 12345678/ 绑定事件:a.click(function () &#123; alert('hello!');&#125;);// 解除绑定:a.off('click', function () &#123; alert('hello!');&#125;); 这是因为两个匿名函数虽然长得一模一样，但是它们是两个不同的函数对象，off(&#39;click&#39;, function () {...})无法移除已绑定的第一个匿名函数。 为了实现移除效果，可以使用off(&#39;click&#39;)一次性移除已绑定的click事件的所有处理函数。同理，无参数调用off()一次性移除已绑定的所有类型的事件处理函数。 事件触发条件 一个需要注意的问题是，事件的触发总是由用户操作引发的。 浏览器安全限制 在浏览器中，有些JavaScript代码只有在用户触发下才能执行。 123456// 如window.open()函数// 无法弹出新窗口，将被浏览器屏蔽:$(function () &#123; window.open('/');&#125;); 动画用JavaScript实现动画，原理非常简单：我们只需要以固定的时间间隔（例如，0.1秒），每次把DOM元素的CSS样式修改一点（例如，高宽各增加10%），看起来就像动画了。 但是要用JavaScript手动实现动画效果，需要编写非常复杂的代码。如果想要把动画效果用函数封装起来便于复用，那考虑的事情就更多了。 使用jQuery实现动画，代码就非常简单了。 jQuery内置的几种动画样式 show()：显示DOM元素，从左上角展开； hiden()：隐藏DOM元素，从左上角收缩； sideUp()：在垂直方向展开； sideDown()：在垂直反向收缩； fadeIn()：动画效果淡入； fadeOut()：动画效果淡出。 1234567891011var div = $('#test-show-hide');div.hide(3000); // 在3秒钟内逐渐消失var div = $('#test-show-hide');div.show('slow'); // 在0.6秒钟内逐渐显示var div = $('#test-slide');div.slideUp(3000); // 在3秒钟内逐渐向上消失var div = $('#test-fade');div.fadeOut('slow'); // 在0.6秒内淡出 自定义动画 使用animate()可实现任意动画效果，需要传入的参数就是DOM元素最终的CSS状态和时间，jQuery在时间段内不断调整CSS直到达到设定的值。 12345678910var div = $('#test-animate');div.animate(&#123; opacity: 0.25, width: '256px', height: '256px'&#125;, 3000, function () &#123; console.log('动画已结束'); // 恢复至初始状态: $(this).css('opacity', '1.0').css('width', '128px').css('height', '128px');&#125;); 串行动画 jQuery的动画效果还可以串行执行，通过delay()方法还可以实现暂停，这样我们可以实现更复杂的动画效果。 1234567891011121314var div = $('#test-animates');// 动画效果：slideDown - 暂停 - 放大 - 暂停 - 缩小div.slideDown(2000) .delay(1000) .animate(&#123; width: '256px', height: '256px' &#125;, 2000) .delay(1000) .animate(&#123; width: '128px', height: '128px' &#125;, 2000);&#125; AJAXjQuery在全局对象jQuery(也就是$)绑定了ajax()函数，可以处理AJAX请求。ajax(url, settings)常用的选项如下： async：是否异步执行AJAX请求，默认true，千万不要指定为false； method：缺省为GET； content type：发送POST请求的格式，默认为application/x-www-form-urlencoded; charset=UTF-8，也可指定为text/plain, application/json； data：发送的数据，可以是字符串、数组、对象； headers：发送的额外HTTP头，必须是一个对象； dataType：接收的数据格式，可指定为html, xml, json, text等。 get 对常用的AJAX操作，jQuery提供了一些辅助方法。由于GET请求最常见，所以jQuery提供了get()方法。 123456var jqxhr = $.get('/path/to/resource', &#123; name: 'xxx', check: 1&#125;);// 实际URL：/path/to/resource?name=Bob%20Lee&amp;check=1 post 与get类似，但传入的第二个参数默认被序列化为application/x-www-form-urlencoded。 123456var jqxhr = $.post('/path/to/resource', &#123; name: 'Bob Lee', check: 1&#125;);// 实际构造数据：name=Bob%20Lee&amp;check=1 getJSON 由于json越来越普遍，所以jQuery也提供了getJSON()方法来快速通过GET获取一个json对象。 123456var jqxhr = $.getJSON('/path/to/resource', &#123; name: 'Bob Lee', check: 1&#125;).done(function (data) &#123; // data已经被解析为JSON对象了&#125;); 安全限制 jQuery的AJAX完全封装的是JavaScript的AJAX操作，所以它的安全限制和前面讲的用JavaScript写AJAX完全一样。 扩展当我们使用jQuery对象的方法时，由于jQuery对象可以操作一组DOM，而且支持链式操作，所以用起来非常方便。但是jQuery内置的方法永远不可能满足所有的需求。 我们可以扩展jQuery来实现自定义方法。我们可以扩展jQuery来实现自定义方法。 编写jQuery插件给jQuery对象绑定一个新方法是通过扩展$.fn对象实现的。 1234567891011121314151617$.fn.highlight1 = function () &#123; // this已绑定为当前jQuery对象，所以函数内部代码可以正常调用所有jQuery对象的方法 this.css('backgroundColor', '#fffceb').css('color', '#d85030'); return this; // 因为jQuery对象支持链式操作，我们自己写的扩展方法也要能继续链式下去&#125;// 可以给方法加个参数，让用户自己把参数用对象传进去$.fn.highlight2 = function (options) &#123; // 要考虑到各种情况: // options为undefined // options只有部分key var bgcolor = options &amp;&amp; options.backgroundColor || '#fffceb'; var color = options &amp;&amp; options.color || '#d85030'; this.css('backgroundColor', bgcolor).css('color', color); return this;&#125; 另一种方法是使用jQuery提供的辅助方法$.extend(target, obj1, obj2, ...)，它把多个对象的属性合并到第一个target对象中，遇到同名属性，总是使用靠后的对象的值，也就是越往后优先级越高。 紧接着用户对highlight2()提出了意见：每次调用都需要传入自定义的设置，能不能让我自己设定一个缺省值，以后的调用统一使用无参数的highlight2()？也就是说，我们设定的默认值应该能允许用户修改。那默认值放哪比较合适？放全局变量肯定不合适，最佳地点是$.fn.highlight2这个函数对象本身。 123456789101112$.fn.highlight = function (options) &#123; // 合并默认值和用户设定值: var opts = $.extend(&#123;&#125;, $.fn.highlight.defaults, options); this.css('backgroundColor', opts.backgroundColor).css('color', opts.color); return this;&#125;// 设定默认值:$.fn.highlight.defaults = &#123; color: '#d85030', backgroundColor: '#fff8de'&#125; 最终，我们得出编写一个jQuery插件的原则： 给$.fn绑定函数，实现插件的代码逻辑； 插件函数最后要return this;以支持链式调用； 插件函数要有默认值，绑定在$.fn.&lt;pluginName&gt;.defaults上； 用户在调用时可传入设定值以便覆盖默认值。 针对特定元素的扩展我们还知道jQuery对象的有些方法只能作用在特定的DOM元素上，比如submit()方法只能针对form。如果我们编写的扩展只能针对某些类型的DOM元素，应该怎么写？ 还记得jQuery的选择器支持filter()方法来过滤吗？我们可以借助这个方法来实现针对特定元素的扩展。 错误处理错误分两种： 一种是程序逻辑写的不对，导致代码执行异常； 一种是执行过程中，程序可能遇到无法预测的异常情况而报错。 错误处理是程序设计时必须要考虑的问题。 12345678// 类似于Python的trytry &#123; ...&#125; catch (e) &#123; ...&#125; finally &#123; ...&#125; 错误类型 JavaScript有一个标准的Error对象表示错误，还有从Error派生的TypeError, FeferenceError等错误对象。 1234567891011try &#123; ...&#125; catch (e) &#123; if (e instanceof TypeError) &#123; alert('Type error!'); &#125; else if (e instanceof Error) &#123; alert(e.message); &#125; else &#123; alert('Error: ' + e); &#125;&#125; 抛出错误 程序也可以主动抛出一个错误，让执行流程直接跳转到catch块。抛出错误使用throw语句。 错误传播如果代码发生了错误，有没有被try...catch捕获，那么程序执行流程会跳转到哪呢？ 如果在一个函数内部发生了错误，它自身没有捕获，错误就会被抛到外层调用函数，如果外层函数也没有捕获，该错误会一直沿着函数调用链向上抛出，直到被JavaScript引擎捕获，代码终止执行。 异步错误处理编写JavaScript代码时，我们要时刻牢记，JavaScript引擎是一个事件驱动的执行引擎，代码总是以单线程执行，而回调函数的执行需要等到下一个满足条件的事件出现后，才会被执行。 所以，涉及到异步代码，无法在调用时捕获，原因就是在捕获的当时，回调函数并未执行。类似的，当我们处理一个事件时，在绑定事件的代码处，无法捕获事件处理函数的错误。 underscore正如jQuery统一了不同浏览器之间的DOM操作的差异，让我们可以简单地对DOM进行操作，underscore则提供了一套完善的函数式编程的接口，让我们更方便地在JavaScript中实现函数式编程。 jQuery在加载时，会把自身绑定到唯一的全局变量$上，underscore与其类似，会把自身绑定到唯一的全局变量_上，这也是为啥它的名字叫underscore的原因。 Node.js从本章开始，我们就正式开启JavaScript的后端开发之旅。 Node.js是目前非常火热的技术，但是它的诞生经历却很奇特。 Google认为要运行现代Web应用，浏览器必须有一个性能非常强劲的JavaScript引擎，于是Google自己开发了一个高性能JavaScript引擎，名字叫V8，以BSD许可证开源。 话说有个叫Ryan Dahl的歪果仁，他的工作是用C/C++写高性能Web服务。对于高性能，异步IO、事件驱动是基本原则，但是用C/C++写就太痛苦了。于是这位仁兄开始设想用高级语言开发Web服务。他评估了很多种高级语言，发现很多语言虽然同时提供了同步IO和异步IO，但是开发人员一旦用了同步IO，他们就再也懒得写异步IO了，所以，最终，Ryan瞄向了JavaScript。 因为JavaScript是单线程执行，根本不能进行同步IO操作，所以，JavaScript的这一缺陷导致了它只能使用异步IO。 选定了开发语言，还要有运行时引擎。这位仁兄曾考虑过自己写一个，不过明智地放弃了，因为V8就是开源的JavaScript引擎。让Google投资去优化V8，咱只负责改造一下拿来用，还不用付钱，这个买卖很划算。 于是在2009年，Ryan正式推出了基于JavaScript语言和V8引擎的开源Web服务器项目，命名为Node.js。虽然名字很土，但是，Node第一次把JavaScript带入到后端服务器开发，加上世界上已经有无数的JavaScript开发人员，所以Node一下子就火了起来。 在Node上运行的JavaScript相比其他后端开发语言有何优势？最大的优势是借助JavaScript天生的事件驱动机制加V8高性能引擎，使编写高性能Web服务轻而易举。 其次，JavaScript语言本身是完善的函数式语言，在前端开发时，开发人员往往写得比较随意，让人感觉JavaScript就是个“玩具语言”。但是，在Node环境下，通过模块化的JavaScript代码，加上函数式编程，并且无需考虑浏览器兼容性问题，直接使用最新的ECMAScript 6标准，可以完全满足工程上的需求。 Node.js是一个开源和跨平台的JavaScript runtime environment。 安装Node.js和npm由于Node.js平台是在后端运行JavaScript代码，所以需要在本机按照Node环境。 安装Node.js详情请看官网文档。 npmnpm is the standard package manager for Node.js. npm其实是Node.js的包管理工具。为啥我们需要一个包管理工具呢？因为我们在Node.js上开发时，会用到很多别人写的JavaScript代码。如果我们要使用别人写的某个包，每次都根据名称搜索一下官方网站，下载代码，解压，再使用，非常繁琐。于是一个集中管理的工具应运而生：大家都把自己开发的模块打包后放到npm官网上，如果要使用，直接通过npm安装就可以直接用，不用管代码存在哪，应该从哪下载。 更重要的是，如果我们要使用模块A，而模块A又依赖于模块B，模块B又依赖于模块X和模块Y，npm可以根据依赖关系，把所有依赖的包都下载下来并管理起来。否则，靠我们自己手动管理，肯定既麻烦又容易出错。 讲了这么多，npm究竟在哪？其实npm已经在Node.js安装的时候顺带装好了。 第一个Node程序在前面的章节中，编写的JavaScript代码都是在浏览器中运行的，因此，我们可以直接在浏览器中敲代码，然后直接运行。 从本章开始，我们编写的JavaScript代码将不能在浏览器环境中执行了，而是在Node环境中执行。 123'use strics';console.log('Hello, world.') 执行: 12node hello.js# Hello, world. 严格模式 在服务器环境下，如果有很多JavaScript文件，每个文件都写上&#39;use strict&#39;;很麻烦。我们可以给Nodejs传递一个参数，让Node直接为所有js文件开启严格模式： 1node --use_strict 模块为了编写可维护的代码，我们把很多函数分组，分别放到不同的文件里，这样，每个文件包含的代码就相对较少，很多编程语言都采用这种组织代码的方式。在Node环境中，一个.js文件就称之为一个模块（module）。 使用模块有什么好处？最大的好处是大大提高了代码的可维护性。其次，编写代码不必从零开始。当一个模块编写完毕，就可以被其他地方引用。我们在编写程序的时候，也经常引用其他模块，包括Node内置的模块和来自第三方的模块。 12345678910'use strict';var s = 'Hello';function greet(name) &#123; console.log(s + ', ' + name + '!');&#125;// 把函数greet作为模块的输出暴露出去，这样其他模块就可以使用greet函数了module.exports = greet; 1234567// 使用模块// 使用require引入模块，请注意路径var greet = require('./hello');var s = 'Michael';greet(s); CommonJS规范 这种模块加载机制被称为CommonJS规范。在这个规范下，每个.js文件都是一个模块，它们内部各自使用的变量名和函数名都互不冲突。 一个模块想要对外暴露变量（函数也是变量），可以用module.exports = variable;，一个模块要引用其他模块暴露的变量，用var ref = require(&#39;module_name&#39;);就拿到了引用模块的变量。 基本模块]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Web</tag>
        <tag>JavaScript</tag>
        <tag>JS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible]]></title>
    <url>%2F2019%2F12%2F26%2FAnsible%2F</url>
    <content type="text"><![CDATA[参考: Ansible docs: https://docs.ansible.com 环境: RHELx86_64 Ansible v2.9 介绍About Ansible: https://docs.ansible.com/ansible/latest/index.html Ansible是一个IT自动化工具。它可以配置系统，部署软件和编排更先进的IT任务。Ansible的主要目标是简单和易于使用。它也专注于安全性和可靠性。 Ansible以无代理(agent-less)方式管理机器。Ansible是分散的，它依赖于现有操作系统的平局来控制访问到远程主机。如果需要，Ansible可以很容易地使用Kerberos, LDAP等集中认证管理系统连接。 词汇表Glossary Action动作(action)是任务的一部分，用于指定要运行的模块和传递给该模块的参数。每个任务只能有一个动作，但也可能有其它参数。 Ad Hoc指使用/usr/bin/ansible运行Ansible执行一些快速命令，而不是编排语言，即/usr/bin/ansible-play-book。ad hoc命令的示例可能是重新启动基础结构中的50台计算机。你可以通过编写playbook来完成你可以做的任何事情，而playbook也可以将许多其它操作粘合在一起。 Async指配置为在后台运行而不是等待完成的任务。如果你的进程时间长度超过了SSH超时时间，那么以异步(async)模式启动该任务是有意义的。异步模式可以每隔很多秒轮询完成，或者可配置为’fire and forget’，在这种情况下，Ansible甚至不会再次检查任务，它将开始并继续进行未来的步骤。异步模式使用/usr/bin/ansible和/usr/bin/ansible-playbook。 Callback Plugin指一些用户编写的代码，可拦截Ansible的结构并对它们执行某些操作。GitHub中提供的一些示例执行自定义日志记录，发送电子邮件… Check Mode值运行带有--check选项的Ansible，它不会对远程系统进行任何更改，但仅输出在没有此标志的情况下运行时才有可能发生的更改。 Connection Plugin默认情况下，Ansible通过pluggable libraries与远程计算机通信。Ansible支持原生OpenSSH或称为paramiko的Python实现。如果您使用的是最新版本，则首选OpenSSH，并启用Kerberos和jump host等功能。还有其它连接类型，如accelerate模式，必须通过一种基于SSH的连接类型进行引导，但速度非常快，而本地模式则作用于本地系统。用户还可以编写自己的连接插件。 Conditionals条件是一个表达式，其计算结果为true或false，用于决定给定任务是否在给定计算机上执行。 Declarative实现使用最终状态描述的任务的方法，而不是实现该状态所需的步骤序列的描述。对于真实世界的栗子，任务的声明规范将是: “put me in California”。根据你当前的位置，前往加州的步骤顺序可能会有所不同，如果你已在加州，则根本不需要做任何事情。Ansible的资源是声明性的；它确定了实现最终状态所需的步骤。它还可让你知道是否需要采取任何步骤才能到达最终状态。 Diff Mode将--diff标志传递给Ansible，以显示支持它的模块。 ExecutorAnsible的核心软件组件，它是/usr/bin/ansible背后的力量——并且对应于剧本中每个任务的调用。 Facts事实是发现的有关远程节点的事情。通过在远程节点上执行内部设置模块来运行，Ansible会自动发现事实。 Filter Plugin这允许创建新的Jinja2过滤器，这只适用于知道Jinja2过滤器的人。 ForkAnsible并行地与远程节点通信，并且可通过传递--forks或编辑配置文件中的默认值来设置并行级别。 Gather Facts (Boolean)有时，当运行多重playbook时，如果不需要利用任何这些值，则希望有一些不打扰事实计算的playbook。 Globbing通配符是一种选择大量主机，或它们所在组的名称的方法 Group一组主机 Group Vars这是将提供给指定组的变量，尤其是复杂的数据结构，这样这些变量就不必嵌入到库存文件或playbook中。 Handlers处理程序就像Ansible playbook中的常规任务，但只有在任务包含notify指定并且还指示它已更改某些内容时才会运行。 Host主机是Ansible管理的远程机器。 Host SpecifierAnsible中的每个play都将一系列任务映射到一组系统。每个play中的hosts:指令通常称为主机说明符。它可以选择一个或多个系统，一个或多个组，甚至一个组中的一些主机，而不是另一个组中的主机。 Host Vars主机变量类似与组变量。 Idempotency如果执行一次的结果与在没有任何干预动作的情况下重复执行它的结果完全相同，则操作是幂等的。 Includesplaybook文件可以包括其它play list，任务列表可以外部化其它文件中的任务列表，类似于处理程序。 Inventory用于描述Ansible中的主机和组的文件。 Inventory Script一个程序，用于查找主机，主机的组关系以及外部资源的变量信息——无论是SQL数据库，CMDB方案，还是LDAP等。 Jinja2Jinja2是Ansible模板模块的首选语言。它是一种非常简单的Python模板语言，可读且易于编写。 JSONAnsible使用JSON从远程模块返回数据。这允许用任何语言编写。 Lazy Evaluation通常，Ansible会在最后一秒评估playbook内容中的任何变量。 LibraryAnsible的模块集合。 Limit Groups通过将--limit somegroup传递给Ansible或ansible-playbook可以限制主机的子集。 Local Action针对远程计算机的playbook中的本地活动指令意味着给定的步骤实际上将在本地计算机上发生，但是可以传入变量以引用该步骤中引用的远程主机名。 Local Connection通过在playbook中使用connection: local，或将-c local传递给/usr/bin/ansible，这表明我们正在管理本地主机而不是远程主机。 Lookup Plugin查找插件是一种从外部获取数据到Ansible的方法。 Loops通常，Ansible不是一种编程语言。它更喜欢声明性，尽管循环这样的各种结构允许对列表中的多个项重复特定任务。 Modules模块是Ansible发送到远程机器的工作单元。 Multi-TierIT系统不是一次管理一个系统的概念，而是通过明确定义的订单中多个系统和系统组之间的交互。 Notify任务注册更改事件并通知处理程序任务需要在play结束时运行另一个操作的行为。 Orchestration许多软件自动化系统使用这个词来表示不同的东西。Ansible使用它作为编排的指挥。 paramiko默认情况下，Ansible通过SSH管理机器。Ansible默认使用的库是一个名为paramiko的Python驱动库。 Playbooksplaybook是Ansible编排，配置，管理或部署系统的语言。它被称为剧本，部分原因在于它是一种运动类比，并且使用它们应该很有趣。 PlaysA playbook is a list of plays。剧本最小是由主机说明符选择的一组主机之间的映射，以及在这些主机上运行定义这些系统将执行的角色的任务。 Pull Mode默认情况下，Ansible以push模式运行，这使得它可以在与每个系统进行通信时进行非常精细的控制。当你希望在特定计划时间点检查节点时，可以使用pull模式。 Push Mode Register Variable在Ansible中运行任何任务的结果可以存储在变量中，以便在模板或条件语句中使用。 Resource ModelAnsible模块在资源方面起作用。 Roles角色是Ansible的组织单位。 Rolling Update一次解决组中的多个节点的行为，以避免一次更新所有节点并使系统脱机。 Sudo SSH (Native) TagsAnsible允许使用任意关键字标记剧本中的资源，然后仅运行与这些关键字对应的剧本部分。 Task任务将操作(模块及其参数)与名称和可选的其他关键字(如循环指令)组合在一起。 TemplatesAnsible可以轻松地将文件传输到远程系统，但通常需要在其它文件中替换变量。 TransportAnsible使用term:连接插件来定以可用传输的类型。 When一个可选的条件语句。 Vars (Variables)与事实相反，变量是值的名称(int, bool, string)或复杂的数据(dict, hash, lists)。它是声明的东西，而不是从远程系统获取的东西。 YAMLAnsible不想强迫人们编写程序代码来自动化基础设施，因此使用YAML来定义剧本配置语言和变量文件。 安装指南Installtion Guide: https://docs.ansible.com/ansible/latest/installation_guide/index.html 安装AnsibleInstalling Ansible: https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html Ansible是一个默认通过SSH协议管理机器的无代理(agentless)的自动化工具。一旦安装，Ansible不添加数据库，并且不需要启动守护进程。你只需要在一台机器上安装它，它可以从该中心点管理远程所有机器。 先决条件Prerequisite 在控制节点上安装Ansible，然后使用SSH(默认)与管理的节点通信。 控制节点的依赖Control node requirements 目前，Ansible可以从任何安装了Python2.7或Python3.5+的机器上运行。不支持Windows。 被管理节点的依赖 Managed node requirements 在被管理的节点上，你需要一种方法来通信（通常是SSH）。 选择版本Selecting an Ansible version to install 选择自己需要的Ansible版本进行安装，可选择一下几种方式： 使用操作系统包管理器进行安装 使用pip进行安装 使用源码进行安装 在RHEL上安装Installing Ansible on RHEL, CentOS, or Fedora 123yum search ansiblesudo yum install ansible 使用pip安装Installing Ansible with pip 使用Python的包管理工具pip来安装Ansible。 12345# env# python -m virtualenv ansible# source ansible/bin/activatepip install --user ansiblepip install --user paramiko Ansible command shell completionAnsible 2.9的命令行工具由称为argcomplete的依赖提供。 12345sudo yum install epel-releasesudo yum install python-argcomplete# pip# pip install argcomplete 配置argcomplete 有两种方式来配置Ansible的命令行工具argcomplete： 全局(Globally) 12# Global completion requires bash 4.2.sudo activate-global-python-argcomplete 每个命令(Per command) 1234567891011# If you do not have bash 4.2, you must register each script independently.# 可将这些写入.profile里eval $(register-python-argcomplete ansible)eval $(register-python-argcomplete ansible-config)eval $(register-python-argcomplete ansible-console)eval $(register-python-argcomplete ansible-doc)eval $(register-python-argcomplete ansible-galaxy)eval $(register-python-argcomplete ansible-inventory)eval $(register-python-argcomplete ansible-playbook)eval $(register-python-argcomplete ansible-pull)eval $(register-python-argcomplete ansible-vault) 配置AnsibleConfiguring Ansible: https://docs.ansible.com/ansible/latest/installation_guide/intro_configuration.html 配置文件Configuration file Ansible将按照一下顺序搜索配置文件： ANSIBLE_CONFIG环境变量 ansible.cfg当前目录 ~/.ansible.cfg /etc/ansible/ansible.cfg Ansible配置参考 Ansible移植指南Ansible Porting Guides: https://docs.ansible.com/ansible/latest/porting_guides/porting_guides.html 用户指南User Guide: https://docs.ansible.com/ansible/latest/user_guide/index.html 本指南介绍如何使用Ansible工作，包括CLI, invetory, playbooks。 QuickstartAnsible Quickstart Guide: https://docs.ansible.com/ansible/latest/user_guide/quickstart.html 概念Ansible concepts: https://docs.ansible.com/ansible/latest/user_guide/basic_concepts.html Controle node：按照Ansible的任意机器。Windows机器无法作为控制节点。可以有多个控制节点。 Managed nodes：使用Ansible管理的网络设备。通常称为主机，Ansible未安装在管理节点上。 Inventory：一组管理节点的列表。清单文件有时称为主机文件(hostfile)。 Modules：Ansible执行代码单元。Ansible模块列表 Tasks：Ansible中的动作单元。可使用ad-hoc命令执行单一任务一次。 Playbooks：任务的有序列表。可按照顺序反复执行这些任务。剧本可以包含变量和任务。它以YAML格式编写。 入门Getting Started: https://docs.ansible.com/ansible/latest/user_guide/intro_getting_started.html 一个基本的Ansible命令或playbooks： 从清单中选择机器来执行 连接到这些机器（通常是SSH） 复制一个或多个模块到远程机器，并执行 Ansible可以做很多事。一旦你理解了Ansible是如何工作的，你可以阅读有关的ad-hoc命令的详细信息，使用清单组织你的基础架构，并利用Ansible强大的playbooks。 从清单选择机器Ansible从你的清单中读取管理的机器的信息。虽然你可以通过IP地址和ad-hoc命令，你也需要清单来增加Ansible的灵活性和重复性。 123456# 创建一个基本的清单# 在此文件中添加远程系统vim /etc/ansible/hosts192.0.2.50aserver.example.orgbserver.example.org 也可以使用别名(aliases)，主机变量(host vars)，组变量(group vars)。 连接到远程节点Ansible与远程机器通过SSH协议进行通信。默认情况下，Ansible使用原生的OpenSSH连接到远程机器。 确认用户名可使用SSH进行连接。如有必要，将SSH公钥添加到系统的authorized_keys文件。 复制和执行模块一旦建立连接，Ansible传输你的命令或剧本需要的模块到远程机器。 123456# 运行第一个ansible命令ansible all -m ping# 运行一个节点上的命令ansible all -a &quot;/bin/echo hell&quot; 如何构建清单How to build your inventory: https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html Ansible对多个被管理的节点使用被称为清单的列表或组列表。一旦清单定义，你可以选择主机或组来运行。 清单的默认位置是/etc/ansible/hosts。可以通过-i选项来指定不同的清单文件。也可以同时使用多个清单文件。从动态或云拉取清单。 清单基本formats, hosts, groups。 清单文件有多种形式。最常用的是INI和YAML。 123456789101112# INI格式mail.example.com# 组名[webservers]a.example.comb.example.com[dbserver]db1.example.comdb2.example.comdb3.example.com 1234567891011121314# YAML格式all: hosts: mail.example.com: children: webserver: hosts: a.example.com: b.example.com: dbservers: hosts: db1.example.com: db2.example.com: db3.example.com: 默认组(default groups)，有两个默认组。 all：包含每个主机 ungrouped：all中没有组的主机 在多个组中的主机(Hosts in multiple groups)。 1234567891011121314151617181920212223242526all: hosts: mail.example: children: webservers: hosts: f.example.com: b.example.com: dbservers: hosts: one.example.com: two.example.com: east: hosts: f.example.com: one.example.com: west: hosts: b.example.com: two.example.com: prod: children: east: test: hosts: b.example.com: 添加主机范围(Adding ranges of hosts)。如果有很多主机有一个类似的模式，可将其添加为一个范围，而不是单独列出每个主机名。 1234567... webservers: hosts: www[01:20].example.com: dbservers: hosts: db-[a:f].example.com 添加变量到清单Adding variables to inventory 可以在清单中存储涉及到特定主机或组的变量值。 主机变量Assigning a variable to one machine: host variables 1234567atlanta: hosts1: http_port: 80 maxRequestPerChild: 808 hosts2: http_port: 303 maxRequestPerChild: 909 清单别名(Inventory aliases)。在清单中定义别名： 12345... hosts: jumper: ansible_port: 5555 ansible_host: 192.0.2.50 组变量Assigning a variable to many machines: group variables 在一组的主机中共享变量值。 1234567atlanta: hosts: hosts1: host2: vars: ntp_server: ntp.atlanta.example.com proxy: proxy.atlanta.example.com 继承变量值(Inheriting variable values: group variables for groups of groups)。可使用children:(yaml)来构建组的组，同样，可使用vars:来构建组变量的组变量。 12345678910111213141516171819202122all: children: usa: children: southeast: children: atlanta: hosts: hosts1: hosts2: raleigh: hosts: hosts2: hosts3: vars: some_server: foo.southeast.example.com halon_system_timeout: 30 self_destruct_countdown: 60 escape_pods: 2 northeast: norethwest: southwest: 子组有几个属性的注意事项： 子组成员的任何主机自动成为父组的成员 子组的变量的优先级高于(覆盖)父组的变量 组可以有多个父亲和孩子 主机可以在多个组，但只会有一台主机实例，合并来自多个组的数据 组织主机和组变量Organizing host and group variables 尽管你可以将变量存储在清单文件，但存储独立的主机和组变量可以帮助您更轻松地阻止你的变量值。主机和组变量文件必须使用YAML语法。 Ansible通过搜索清单文件或剧本文件的路径来载入主机和组变量文件。 变量如何合并How variables are merged 默认情况下，在play运行前变量被合并到特定的主机。这使Ansible集中在主机和任务，因此组并没有真正生存在清单和主机匹配之外。Ansible覆盖变量的顺序： all group parent group child group host 默认情况下Ansible在相同的父/子级按字母顺序合并组，并在最后一组加载覆盖前面的组。你可以通过设置组变量ansible_group_priority来改变同级组合并顺序的行为。数字越大，优先级就越高。默认值是1。 123456# testvar == aa_group: testvar: a ansible_group_priority: 10b_group: testvar: b 使用多个清单源Using multiple inventory sources 可通过在命令行中或配置ANSIBLE_INVENTORY通过给定多个清单参数在同一时间目标多个清单源（目录，动态清单脚本，清单插件…）。 12# target 2 sourcesansible-playbook get_logs.yml -i staging -i production 以一个目录组合多个清单源(Aggregating inventory sources with a directory) 还可以通过一个目录下结合多个清单源和原类型来创建清单。这对于动静结合主机和管理它们为一体化清单很有用。 123456inventory/ openstack.yml # configure inventory plugin to get hosts from Openstack cloud dynamic-inventory.py # add additional hosts with dynamic inventory script static-inventory # add static hosts and groups group_vars/ all.yml # assign variables to all hosts 12# target inventoryansible-playbook example.yml -i inventory 清单参数Connecting to hosts: behavioral inventory parameters 以下变量控制与远程主机如何与Ansible相互作用。 清单配置样例Inventory setup examples 每个环境一个清单(One inventory per environment) 通过功能分组(Group by function) 通过地址分组(Group by location) 12345# Example: One inventory per environment# inventory_test[dbservers]db01.test.example.comdb02.test.example.com 12345678# Example: Group by function- hosts: dbservers tasks: - name: allow access from 10.0.0.1 iptables: chain: INPUT jump: ACCEPT source: 10.0.0.1 1234# Example: Group by location[dc1]db01.test.example.comapp01.test.example.com 动态清单Working with dynamic inventory: https://docs.ansible.com/ansible/latest/user_guide/intro_dynamic_inventory.html cobbler AWS ec2 OpenStack 其它清单脚本Other inventory scripts 模式Patterns: targeting hosts and groups: https://docs.ansible.com/ansible/latest/user_guide/intro_patterns.html 当你通过ad-hoc或playbook执行Ansible时，你必须选择要对哪些节点或组执行。模式可以让你针对清单中的特定主机或组执行。一个Ansible Pattern可以指定单个主机、IP地址、清单组、一组组、所有主机…模式非常灵活，可以排除需要的主机子集、使用通配符、正则表达式…Ansible将在包含在模式上的所有清单主机上执行。 模式使用Using patterns 123# ad-hoc# ansible &#123;pattern&#125; -m &#123;module_name&#125; -a "&#123;module_options&#125;"ansible webservers -m service -a "name=httpd state=restarted" 123456# palybook- name: &#123;play_name&#125; hosts: &#123;pattern&#125;- name: restart webservers hosts: webservers 常见模式Common patterns 描述 模式 目标 All hosts all(*) - One host host1 - Multiple hosts host1:host2(host1,host2) - One group g1 - Multiple groups g1:g2 all hosts in g1 and g2 Excluding groups g1:!g2 all hosts in g1 except those in g2 Intersection of groups g1:&amp;g2 g1和g2的交集 模式的局限性Limitations of patterns 模式依赖于清单。如果主机或组不在清单中，则不能使用模式来目标它。如果模式中包含清单中不存在的IP地址或主机名，会报错。模式必须匹配清单语法。 高级的模式选项Advanced pattern options 常用的模式将满足你的大部分需求，但Ansible提供了几种方法来定义你需要定位(target)的主机和组。 在模式中使用环境变量Using variables in patterns 12# playbookwebservers:!&#123;&#123; excluded &#125;&#125;:&amp;&#123;&#123; required &#125;&#125; 在模式中使用组位置Using group position in patterns 12345678910[g1]aabbccg1[0]g1[-1]g1[0:2]g1[1:] 在模式中使用正则Using regexes in patterns 以~符号开始使用模式的正则: ~(web|db).*\.example\.com playbook标志Patterns and ansible-playbook flags 可以使用命令行选项改变playbook中定义的行为。 1ansible-playbook site.yml --limit datacenter2 ad-hocIntroduction to ad-hoc commands: https://docs.ansible.com/ansible/latest/user_guide/intro_adhoc.html 一个Ansible的ad-hoc命令使用ansible命令行工具在一个或多个管理节点上执行单一任务。ad-hoc命令是快速和容易的，但却无法重复使用。那么为什么首先学习ad-hoc命令呢？它表明Ansible的简单和功能。在这学的内容可直接到playbook里。在执行前，请先阅读构建清单。 ansible命令行实用程序的默认模块是command module。 如果像重复一个命令，可使用playbook中的template module。 为什么使用它Why use ad-hoc commands? ad-hoc命令针对的是很少会重复的任务。 12# 栗子ansible [pattern] -m [module] -a "[module options]" 用例Use cases for ad-hoc tasks ad-hoc任务可用来重启服务器、复制文件、管理包和用户…可在ad-hoc任务中使用任意Ansible模块。Ad-hoc tasks与playbooks类似，使用一个声明模型，计算并执行以达到规定的最终状态所需的操作。 重启服务器 ad-hoc任务调用命令模块。在执行前，确保清单和SSH。 12345678910111213141516171819# rebooting serversansible host1 -a "/sbin/reboot"# 默认是5并发进程ansible host1 -a "/sbin/reboot" -f 10# ansible将默认为你的用户账户ansible host1 -a "/sbin/reboot" -f 10 -u username# 重启服务器可能需要特权提升，如从user到rootansible host1 -a "/sbin/reboot" -f 10 -u username --become [--ask-become-pass]# 使用不同的模块ansible host1 -m shell -a 'echo $&#123;TERM&#125;' 文件管理 ad-hoc可利用Ansible和scp的力量，并行传输文件到多台机器。 1234567# 复制文件ansible atlanta -m copy -a "src=/etc/hosts dest=/tmp/hosts"# file模块属主和权限，创建目录，递归删除ansible webservers -m file -a "dest=/srv/foo/b.txt mode=600 owner=mdehaan group=mdehaan"ansible webservers -m file -a "dest=/path/to/c mode=755 owner=mdehaan group=mdehaan state=directory"ansible webservers -m file -a "dest=/path/to/c state=absent" 包管理 使用ad-hoc任务使用包管理模块（如yum），来安装、升级、移除包。 Ansible有许多平台的许多包管理工具的模块，详情请看文档。 123456789101112# 安装了包不更新ansible webservers -m yum -a "name=acme state=present"# 特定包版本ansible webservers -m yum -a "name=acme-1.5 state=present"# 确认包是最新版ansible webservers -m yum -a "name=acme state=latest"# 确保未安装ansible webservers -m yum -a "name=acme state=absent" 管理用户和组 使用ad-hoc任务在管理的节点上创建、管理、移除用户账户。 123ansible all -m user -a "name=foo password=&#123;crypted password here&#125;"ansible all -m user -a "name=foo state=absent" 服务管理 12345678910# 确保服务已启动ansible webservers -m service -a "name=httpd state=started"# 重启服务ansible webservers -m service -a "name=httpd state=restarted"# 确保服务已停止ansible webservers -m service -a "name=httpd state=stopped" 收集事实 事实代表发现关于系统的变量。 12# 查看所有factsansible all -m setup 连接方法和详情Connection methods and details: https://docs.ansible.com/ansible/latest/user_guide/connection_details.html ControlPersist和paramiko默认情况下，Ansible使用原生的OpenSSH，因为它支持ControlPersist（一个性能特点），Kerberos，和~/.ssh/config中的配置。如果你的控制机使用的旧版本OpenSSH不支持ControlPersist，Ansible将回退到称为paramiko的一个Python实现的OpenSSH。 ssh-key配置SSH key setup 默认情况下，Ansible假定您使用SSH keys连接到远程主机。推荐使用key，但可使用--ask-pass选项来使用密码。使用--ask-become-pass选项来使用特权提升。 123# 建立ssh agent来避免输入密码ssh-agent bashssh-add ~/.ssh/id_rsa 本地运行Running against localhost 1ansible localhost -m ping -e 'ansible_python_interpreter="/usr/bin/env python"' 主机密钥检查Host key checking Ansible默认启用主机密钥检查。如果主机重装并在known_hosts中有不同的密钥，这将导致一个错误消息，知道纠正。 可在/etc/ansible/ansible.cfg或~/.ansible.cfg中禁用它: 12[defaults]host_key_checking = False 或设置环境变量: export ANSIBLE_HOST_KEY_CHECKING=False 其它连接方法Other connection methods 除了SSH之外，Ansible还可以使用许多连接方法。 命令行工具Working with command line tools: https://docs.ansible.com/ansible/latest/user_guide/command_line_tools.html 大多数用户对ansible和ansilbe-playbook比较熟悉，但它们不是Ansible提供的唯一实用工具。下面是完整的Ansible使用工具列表。 ansible: 在一组主机上定义和运行一个单任务playbook ansible-config: 查看Ansible配置信息 ansible-console: REPL控制台执行Ansible任务 ansible-doc: 插件文档工具 ansible-galaxy: 执行各种角色并收集相关的操作 ansible-invotory: 显示或转配置清单 ansible-playbook: 运行Ansible playbook ansible-pull: 从仓库拉playbook并为本地主机执行 ansible-valut: Ansible数据文件的加解密工具 playbookWorking With Playbooks: https://docs.ansible.com/ansible/latest/user_guide/playbooks.html Playbooks是Ansible的配置(configuration)、部署(deployment)和编排(orchestration)语言。它可以描述你希望你的远程系统强制执行的策略，或在IT流程的步骤。 在最基本的级别上，playbook可以被用来管理部署的配置到远程机器。在更高级的，它们可以序列进行涉及多层(mulit-tier)的滚动更新和回滚，并可以委托操作其它主机，与监控服务器进行交互和负载均衡。它有很多功能和信息，详情看文档。 playbook被设计为人类可读的和基于文本语言开发。有多种方式来组织playbook和它包含的文件。 你应该看一看Example Playbooks，并与playbook文档一起阅读。这些说明的最佳实践，以及如何把众多的各种概念混合在一起。 介绍Intro to Playbooks: https://docs.ansible.com/ansible/latest/user_guide/playbooks_intro.html playbook是比在ad-hoc任务执行模式下的一个完全不同的使用ansible的方式，并且特别强大。 简单来说，Playbook是一个非常基础的用于配置管理和多机部署系统，不同于任何已存在的，并且非常适合部署复杂的应用程序。 playbook可以声明配置，但它也可以通过编排任意手动排序进程的步骤，尽管不同的步骤必须来回在特定命令的机器之间。它可以同步(synchronously)或异步(asynchronously)发射任务。 虽然你为ad-hoc任务运行主要的/usr/bin/ansible程序，playbook更可能被保持在原控制和用于推送配置或保证远程系统上的配置。palybook example中有许多栗子，建议去看一看。 playbook languageplaybook以YAML语法格式表示，故意不设计成一种编程语言或脚本，而是过程或配置的模型。 每个playbooks由列表中的play组成。play的目标是映射一组主机到一些良好定义的角色(roles)，由ansible调用任务来表示。通过多个paly组成playbook，有可能协调多机部署，在某个组的所有机器上运行某些步骤…你可以由相当多的影响你的系统做不同事情的paly。 123456789101112131415161718192021222324252627# 仅包含一个paly的`verigy-apache.yml`的playbook的栗子---- hosts: webserver vars: http_port: 80 max_clients: 200 remote_user: root tasks: - name: ensure apache is at the latest version yum: name: httpd state: latest - name: write the apache config file template: src: /srv/httpd.j2 dest: /etc/httpd.conf notify: - restart apache - name: ensure apache is running service: name: httpd state: started handlers: - name: restart apache service: name: httpd state: restarted 123456789101112131415161718192021222324252627# 包含多个play的栗子---- hosts: webservers remote_user: root tasks: - name: ensure apache is at the lastest version yum: name: httpd state: latest - name: write the apache config file template: src: /srv/httpd.j2 dest: /etc/httpd.conf- hosts: databases remote_user: root tasks: - name: ensure pgsql is at the latest version yum: name: postgresql state: latest - name: ensure that postgresql is started service: name: postgresql state: started 基本Basics 主机和用户Hosts and Users 对于playbook中的每个play，你可以选择哪些机器在你的基础设施到目标，什么远程用户完成这些步骤。 12345678# hosts行是一个或多个主机或组的模式，以冒号分隔---- hosts: webservers remote_user: root tasks: - name: test ping: remote_user: username # 远程用户可在每个用户中定义 12345# 特权提升---- hosts: webservers remote_user: username become: yes 12345678910# 也可在每个paly中使用become---- hosts: g1 remote_user: uername tasks: - service: name: nginx state: started become: yes become_method: sudo 123456# 权限提升为特定用户---- hosts: g1 remote_user: username become: yes become_user: postgres 12345678# 控制运行顺序，默认是清单里面的顺序---- hosts: all order: sorted gather_facts: False tasks: - debug: var: inventory_hostname 任务列表Tasks list 每个play包含任务列表。任务在移动到下一个任务之前执行，一次一个，由模式匹配的所有主机。理解在一个play中，所用主机都将得到同样的任务指令是很重要的。这是play映射选择主机到任务的目的。 当运行playbook时，它从上到下运行，失败任务的主机被从playbook轮转中取出。如果事情失败，只是纠正playbook文件，然后重新运行。 每个任务的目标是执行带有特定参数的模块，变量可以在参数中传给模块。 123456# 一个任务的基本栗子tasks: - name: make sure apache is running service: name: httpd state: started 12345678# command, shell模块tasks: - name: enable selinux command: /sbin/setenfore 1tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand || /bin/true 12345tasks: - name: create a virtual host file for &#123;&#123; vhost&#125;&#125; template: src: somefile.j2 dest: /etc/httpd/conf.d/&#123;&#123; vhost&#125;&#125; action shorthand1234# Ansible prefers listing modules like this:template: src: template/foo.j2 dest: /etc/foo.conf 早期版本使用以下格式，仍旧有效: action: template src=templates/foo.j2 dest=/etc/foo.conf HandlersHandlers: Running Operations On Change 如前所述，当远程系统上做了改变时模块应该是幂等的和可以中继(relay)。playbook认识到了这一点，并有一个基本的事件系统用于应对改变。 这些play中的notify行动在任务的每个末尾块触发，即使被多个不同任务通知也只能被触发一次。 例如，多个资源可能表明Apache需要重启，因为配置文件发生了更改，但Apache将跳跃一次，以避免不必要的重启。 12345678# 当一个文件的内容更改时（仅此文件），重启两个服务的栗子- name: template configuration file template: src: template.j2 dest: /etc/foo.conf notify: - restart memcached - restart apache 在任务的notify中列出的事情的部分被称为处理程序(handlers)。 处理程序是任务列表，与常规的任务没什么区别，由一个全局唯一的名称进行引用，并通过通知程序(notifier)进行通知。如果没有事情通知一个处理程序，它将不会运行。不管有多少任务通知处理程序，它只能运行一次，在一个特定paly中的所有任务完成之后。 12345678910# handlers sectionhandlers: - name: restart memcached service: name: memcached state: restarted - name: restart apached service: name: apache state: restarted 你可能想让Ansible handlers使用变量。如果handlers name使用的变量不可用，则整个paly将失败。取而代之的是，在handlers的任务参数中使用变量。 123456789tasks: - name: Set host variables based on distribution include_vars: "&#123;&#123; ansible_facts.distribution&#125;&#125;.yml"handlers: - name: restart web service service: name: "&#123;&#123; web_service_name | default('httpd') &#125;&#125;" state: restarted Ansible 2.2，handlers可以监听(listen)通用话题(generic topics)，任务可以通知这些话题。以下这种使用使它更容易触发多个处理程序。它还从名称解耦处理程序，使得在playbook和roles之间更容易共享处理程序。（特别是当使用像Galaxy的第三方角色时） 12345678910111213141516handlers: - name: restart memcached service: name: memcached state: restarted listen: "restart web service" - name: restart apache service: name: apached state: restarted listen: "restart web services"tasks: - name: restart everything command: echo "this task will restart the web services" notify: "resstart web service" 注意:Notify handlers are always run in the same order they are defined, not in the order listed in the notify-statement. This is also the case for handlers using listen.Handler names and listen topics live in a global namespace.Handler names are templatable and listen topics are not.Use unique handler names. If you trigger more than one handler with the same name, the first one(s) get overwritten. Only the last one defined will run.You cannot notify a handler that is defined inside of an include. As of Ansible 2.1, this does work, however the include must be static. 角色(Roles)后面会说明，但它值得指出的是： handlers notified within pre_tasks, tasks, and post_tasks sections are automatically flushed in the end of section where they were notified handlers notified within roles section are automatically flushed in the end of tasks section, but before any tasks handlers handlers are play scoped and as such can be used outside of the role they are defined in 执行playbookExecuting A Playbook 1ansible-playbook playbook.yml -f 10 Ansible-Pull节点检查到重要位置，而不是推送配置给它们。ansilbe-pull是一个检查从git指令配置仓库的一个脚本，然后针对改内容运行ansible-playbook。 Linting playbooks你可以在执行前使用ansible-lint来检查playbook的运行情况。 1234ansible-lint verify-apache.yml[403] Package installs should not use latestverify-apache.yml:8Task/Handler: ensure apache is at the latest version 其它playbook验证项Other playbook verification options 查看验证playbook工具的详情列表，你可以使用它们来验证playbook。这里有些情况你应该考虑： 要检查playbook语法问题，使用ansible-playbook的--syntax-check标志。 要查看完整的输出信息，使用--verbose标志。 要查看playbook会影响哪些主机，可运行: ansible-playbook playbook.yml --list-hosts 可重复使用的playbookCreating Reusable Playbooks: https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse.html 虽然可以在一个非常大的文件里编写playbook，最终你会想重新使用文件和整理东西。在Ansible中，有三种方式可以做到这一点： includes imports roles includes和imports允许用户将大型playbook分解为小型文件，可跨多个parent playbook或设置多次在相同的playbook里。roles允许不仅仅是任务可以打包在一起，可以包括变量(variables)，处理程序(handlers)，甚至模块(modules)和其它插件(plugins)。不同于includes和imports，roles也可上传并经由Ansible Galaxy共享。 including和importingIncluding and Importing: https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_includes.html include和import语句相似，但Ansible执行引擎处理它们却非常不同。 import*语句在playbook被解析的时候进行预处理(pre-processed)。include*语句在playbook的执行过程中遇到才处理。 include和import语句可以在任意深度使用。 在一个master playbook内包含playbook： 12- import_playbook: a.yml- import_playbook: b.yml 每个playbook中列出的plays和tasks将以列出的顺序 执行，就好像它们已经在这里直接定义。 大型任务划分成不同的文件是组织复杂任务或重用它们的一种好方式。一个任务文件只包含简单的任务列表： 1234- name: aaa command: /bin/aaa- name: bbb command: /bin/bbb 可以使用import_tasks或include_tasks来执行在主任务列表中的文件的任务： 1234tasks:- import_tasks: aaa_tasks.yml# or- include_tasks: aaa_tasks.yml 你也可以传递变量到imports和includes： 12345678910tasks:- import_tasks: aaa.yaml vars: user: aaa- import_tasks: aaa.yml vars: user: bbb- import_tasks: aaa.yml vars: user: ccc include和import同样可以用于handlers:部分。栗子： 12345# more_handlers.yml- name: restart apache service: name: apache state: restarted 1234handlers:- include_tasks: more_handlers.yml# or- import_tasks: more_handlers.yml Rolesroles: https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_roles.html 角色(role)是基于已知的文件架构自动加载某些变量文件、任务和处理程序的方式。按角色分组的内容还可以方便地与其他用户共享。 角色目录结构Role Directory Structure 栗子： 12345678910111213141516site.ymlwebservers.ymlfooservers.ymlroles/ common/ tasks/ handlers/ files/ templates/ vars/ defaults/ meta/ webservers/ tasks/ defaults/ meta/ 角色在特定目录名下期待文件。角色必须包括这些目录中的至少一个，但它是完全没排除任何未使用。在使用时，每个目录必须包含一个main.yml文件，其中包含的相关内容： tasks：包含由角色执行的主任务列表 handlers：包含可通过此角色甚至此角色外的任何地方使用的处理程序 defaults：角色的默认变量 vars：角色的其它变量 files：通过此角色可以部署的文件 templates：通过此角色可以部署的模板 meta：为角色定义的元数据 其它YAML文件可能包含在特定目录。栗子： 123456# roles/example/tasks/main.yml- name: added in 2.4, previously you used include import_tasks: redhat.yml when: ansible_facts['os_family']|lower == 'redhat' import_tasks: debian.yml when: ansible_facts['os_family']|lower == 'debian' 1234# roles/example/tasks/redhat.yml- yum: name: "httpd" state: present 1234# roles/example/tasks/debian.yml- pat: name: "apache2" state: present 角色还可以包含模块和其它插件类型。 角色使用使用角色的原始的方式是在play中通过roles:： 12345---- hosts: webservers roles: - common - webservers 这将为每个角色(x)指定以下行为： 如果roles/x/tasks/main.yml存在，其中列出的任务将被添加到play； 如果roles/x/handlers/main.yml存在，其中列出的处理程序将被添加到play； 如果roles/x/vars/main.yml存在，其中列出的变量将被添加到play； 如果roles/x/defaults/main.yml存在，其中列出的变量将被添加到play； 如果roles/x/meta/main.yml存在，其中列出的任何角色的依赖都将被添加到角色列表； 角色中的任意copy, script, template, include tasks，可在roles/x/{files,templates,tasks}/dir进行引用，而不必关心它们的相对或绝对路径。 当以这种方式使用时，playbook的执行顺序如下： play中定义的任意pre_tasks 任意处理程序触发到目前为止将会运行 在roles中列出的每个角色将依次执行。在角色meta/main.yml中定义的任意角色依赖将首先运行，受标签过滤和条件 play中定义的任意tasks 任意处理程序触发到目前为止将会运行 play中定义的任意post_tasks 任意处理程序触发到目前为止将会运行 可使用import_role或include_role在其它任务中使用角色： 1234567891011---- hosts: webservers tasks: - debug: msg: "before we run our role" - import_role: name: example - include_role: name: example - debug: msg: "after we ran our role" 当角色在原始方式中定义，它们被视为静态导入和在playbook解析时进行处理。 角色的名称可是很简单，也可以是一个完全合格的路径： 1234---- hosts: webservers roles: - role: '/path/to/roles/common' 角色可以接受其它关键字： 123456789101112---- hosts: webservers tasks: - include_role: name: foo_app_instance when: "ansible_facts['os_family'] == 'RedHat'" vars: dir: '/opt/a' app_port: 5000 tags: - aaa - bbb 角色副本和扩展Role Duplication and Execution Ansible只允许一个角色执行一次，即使多次定义： 12345---- hosts: webservers roles: - foo - foo 上面给出的foo角色仅将运行一次。为了使角色多次运行，有两种选择： 每个角色传递不同的参数 添加allow_duplicates: true到meta/main.yml文件 12345678910# playbook.yml---- hosts: webservers roles: - foo - foo# roles/foo/meta/main.yml---allow_duplicates: true 角色默认变量Role Default Variables 角色的默认变量允许你为角色设定默认变量。在角色目录中添加defaults/main.yml文件。这些变量具有最低优先级，可以轻易被覆盖。 角色依赖Role Dependencies 角色依赖让你在其它角色使用角色时自动拉取。角色依赖存储在角色目录的meta/main.yml文件。此文件应包含角色和参数列表在指定角色之前插入： 12345678910111213# orles/myapp/meta/main.yml---dependencies: - role: common vars: come_parameter: 3 - role: apache vars: apache_port: 80 - role: postgres vars: dbname: blarg other_parameter: 12 角色中的嵌入模块和插件Embedding Modules and Plugins In Roles 角色搜索路径Ansible将按以下方式为角色搜索： 相对于playbook文件的roles/目录 默认情况下，在/etc/ansible/roles GalaxyAnsible Galaxy是一个用于查找、下载、评级、审查各种社区ansible roles的免费网站。 ansible-galaxy客户端包含在Ansible中。可使用它从Ansible Galaxy下载角色。 动态与静态Dynamic vs. Static Ansible有两种操作模式用于可重用内容：动态与静态。 如果你使用include*，它将是动态的。如果你使用import*，它是静态的。 动态与静态的区别 两种操作模式都非常简单： 动态包含在遇到任务运行时处理 静态导入在解析playbook前处理 当遇到tag或when： 动态包含仅适用于动态的任务，不会复制到子任务 静态导入，将被复制到所有子任务 两者比较使用include*与import*有一定的优势，权衡两者。 使用include*语句的最大优势是循环。当在include中使用循环，所包含的将在每个循环中执行。 tags仅在动态包含内存在 tasks仅在动态包含内存在 在动态包含内不能使用notify来触发处理程序 在动态包含内不能使用--start-at-task来开始执行 静态导入内循环不能使用 静态导入内不能从库存源使用变量 静态导入内当通知它们的名字时，使用处理程序将不会触发 使用变量Using Variables: https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html Ansible中使用变量可以更好地帮助处理各系统之间的差异。 创建有效的变量名Creating valid variable names 有效的变量名是很重要的。变量名应该是字母 、数字和下划线，且总是以字母开头。 YAML也支持映射键值对的字典： 123foo: field1: one field2: two 你可以使用中括号或点来引用特定字段的值: 12foo[&apos;field1&apos;]foo.field2 请注意，如果使用点来引用，它们属性和Python字典的方法相冲突可能会导致一些问题。如果你使用的键开始和结束有两个下划线，或它们是已知的公共属性，则你应该使用中括号来代替点使用。 12# 公共属性add, append, count, decode... 在清单中定义变量Defining variables in inventory 通常，你需要为单独的主机或组设置变量。你可以在清单文件(如hosts)中定义所需的变量： 1234west: host1: port: 80 maxRequest: 808 123456east: hosts: host1: xx host2: xxx vars: port: 80 在playbook中定义变量Defining variables in a playbook 你可以直接在playbook中定义变量： 123- hosts: xxx vars: port: 80 在文件和角色中定义变量Defining variables in included files and roles 12345678- hosts: xxx roles: - role: test vars: dir: '/opt/a' - role: test2 vars: dir: '/opt/b' 在Jinja2中使用变量Using variables with Jinja2 一旦你定义了变量，便可以在Jinja2的模板系统中引用它： 1Ma amp goes to &#123;&#123; max_amp_value &#125;&#125; 使用Jinja2过滤器转换变量Transforming variables with Jinja2 filters Jinja2 filters 让你在模板表达式内转换变量的值。如capitalize大写过滤器，to_yaml和to_json过滤器来转换成对应格式。 Jinja2包含了许多内置过滤器： https://jinja.palletsprojects.com/en/2.11.x/templates/#builtin-filtersAnsible也支持许多过滤器： https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#playbooks-filters YAML疑难杂症Hey wait, a YAML gotcha YAML语法要求，如果你使用值引用整行，它要确保你不是想开始一个YAML字典。所以记得使用双引号。 12345678# wrong...vars: path: &#123;&#123; dir &#125;&#125;/22# rightvars: path: "&#123;&#123; dir &#125;&#125;/22" 系统facts中的变量Variables discovered from systems: Facts facts是从远程系统获得的信息。你可以从ansible_facts变量中找到。 12# 查看factsansible hostname -m setup 12- debug: var: ansible_facts 1&#123;&#123; ansible_facts[&apos;devices&apos;][&apos;xvda&apos;][&apos;model&apos;]&#125;&#125; 禁用facts 如果你不需要fact数据，你可以禁用它。 12- hosts: xxx gather_facts: no Local facts(facts.d) facts通常都是由Ansible setup模块自动发现。用户也可以编写自定义的facts模块，请参考API指南。但是，如果你想要一个简单的方法来使用用户提供的数据，而不需要写一个facts模块。 facts.d是一种可让用户控制它们的系统是如果管理的某些方面的机制。 如果远程管理系统有/etc/ansible/facts.d目录，该目录中的所有.fact文件（JSON, INI…）。可使用fact_path paly 关键字作为可选目录。 注册变量Registering variables 另一个主要使用的变量是正在运行一个命令和将此命令的返回的结果注册为一个变量，供其它地方使用。 1234567- hosts: xxx tasks: - shell: /usr/bin/foo register: foo_result ignore_errors: True - shell: /usr/bin/bar when: foo_result.rc == 5 访问复杂的变量数据Accessing complex variable data 有些提供的facts，如网络信息，包含了复杂的嵌套结构。取值会稍微麻烦一些： 1234567&#123;&#123; ansible_facts[&apos;eth0&apos;][&apos;ipv4&apos;][&apos;address&apos;]&#125;&#125;# or&#123;&#123; ansible_facts.eth0.ipv4.address &#125;&#125;# 访问数组的第一个元素&#123;&#123; foo[0] &#125;&#125; 使用magic变量访问其它主机的信息Accessing information about other hosts with magic variables 无论你是否定义变量，你也可以利用特殊的Ansible变量访问有关主机的信息，包括magic, facts, connection变量。magic变量名称被保留，所以不要使用这些名称来设置变量。enviroment变量也同样被保留。 最常使用的魔术变量有：hostvars, groups, group_names, inventory_hostname。 host_vars允许你访问其它主机的变量，包括该主机的facts。你可以在playbook中的任意一点访问主机变量。即使你在playbook中并没有连接到此主机，你仍可以得到变量。groups是清单中所有组的列表。这可以用于枚举组内的所有主机。group_names是所有组中当前主机的列表或数组。inventory_hostname是清单主机文件中配置的主机名。使用inventory_hostname_short获取更简短的信息。ansible_play_hosts是当前play中仍然活跃的主机列表。ansible_play_batch是当前批量paly上可用的主机名列表。ansible_playbook_python是python执行调用ansible命令行工具的路径。role_path返回当前角色的路径名。这仅在角色里工作。 123456789&#123;&#123; hostvars[&apos;test.example.com&apos;][&apos;ansible_facts&apos;][&apos;distribution&apos;] &#125;&#125;&#123;% for host in groups[&apos;app_servers&apos;] %&#125; &#123;&#123; hostvars[host][&apos;ansible_facts&apos;][&apos;eth0&apos;][&apos;ipv4&apos;][&apos;address&apos;] &#125;&#125;&#123;% endfor %&#125;&#123;% if &apos;webserver&apos; in group_names %&#125; # xxx&#123;% endif %&#125; 在文件中定义变量Defining variables in files 让playbook使用版本控制是很好的想法，但你可能希望让playbook 源公开化，但同时又保证一定的重要的私有变量。 你可以通过一个外部变量文件来这么做： 1234567---- hosts: all ... vars: color: blue vars_files: - /vars/external_vars.yml 123# external_vars.ymluser: xxpassword: xxxx 这消除了分享playbook但避免分享数据的风险。 在命令行上传递参数Passing variables on the command line 可在命令行上使用--extra-vars参数来设置变量： 12345678# k:v格式ansible-playbook release.yml --extra-vars "version=1.23.45 other_variable=foo"# json格式ansible-playbook arcade.yml --extra-vars '&#123;"pacman":"mrs","ghosts":["inky","pinky","clyde","sue"]&#125;'# 文件ansible-playbook release.yml --extra-vars "@some_file.json" 变量的优先级：我应该把变量放在哪Variable precedence: Where should I put a variable? 同一名称的变量如果在多个地方被定义，则它们会以特定的顺序发生覆盖，所需需要知道Ansible变量的优先级，以及它们的放置位置。下面是从小到大的优先级： command line values role defaults inventory file or script group vars inventory group_vars/all playbook group_vars/all inventory group_vars/* playbook group_vars/* inventory file or script host vars inventory host_vars/* playbook host_vars/* host facts / cached set_facts play vars play vars_prompt play vars_files role vars (defined in role/vars/main.yml) block vars (only for tasks in block) task vars (only for the task) include_vars set_facts/registered vars role (and include_role) params include params extra vars (always win precedence) Jinja2模板Templating (Jinja2): https://docs.ansible.com/ansible/latest/user_guide/playbooks_templating.html Ansible使用Jinja2模板化来实现动态表达式和访问变量。Ansilbe大大扩展的filters和tests数量，以及新增了一个插件类型：lookups。 请注意，所有模板发生在Ansible控制器上，在任务发送和执行在目标主机之前。 FiltersFilters: https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html TestsTests: https://docs.ansible.com/ansible/latest/user_guide/playbooks_tests.html Jinja中的测试是评估模板表达式并返回True或False。许多内置测试: https://jinja.palletsprojects.com/en/2.11.x/templates/#builtin-tests 测试器和过滤器的主要区别是测试用于比较，而过滤去用于数据操作。测试同样可以在列表处理器中使用，如map()和select()在列表中选择项。 与所有模板一样，测试始终在Ansible控制器上执行，而不是任务的目标主机。除了这些Jinja2的测试，Ansible支持用户轻松创建自己的测试。 LookupsLookups: https://docs.ansible.com/ansible/latest/user_guide/playbooks_lookups.html 查找插件允许访问外部数据源。与所有模板一样，这些插件在Ansible控制器上进行评估，并且可以包括读取文件系统、对外联络网络数据存储和服务。这些数据使用Ansible标准模板系统提供。 注意查找发生在本地主机，而不是远程主机；它们在包含role或play的目录内执行，而不是与执行脚本的目录执行本地任务；可以传递wantlist=True给lookups来使用Jinja2中的for循环；查找是一个高级的功能，你应该对Ansible有足够的了解。 Python版本和模板Python Version and Templating: https://docs.ansible.com/ansible/latest/user_guide/playbooks_python_version.html Jinja2模板利用Python数据类型和标准函数。这使得可对数据进行丰富的操作。然而，这也意味着潜在的Python的某些细节对模板编写者可见。由于Ansible playbook使用Jinja2用于模板与变量，这意味着playbook作者需要了解这些细节。 除了这些，请注意在Python2和Python3上运行Ansible的不同。 条件语句Conditionals: https://docs.ansible.com/ansible/latest/user_guide/playbooks_conditionals.html 经常的一个play的结果可能依赖于一个变量的值，或之前的任务的结果。在某些情况下，变量的值可能依赖于其它变量。本主题介绍如何在playbook中使用条件语句。 When语句The When Statement 有时你会想在某个特定主机上跳过特定的步骤。 在Ansible中使用when子句很容易达到，它不包含Jinja2中的双花括号表达式。它非常简单： 123456tasks: - name: "shut down CentOS 6 systems" command: /sbin/shutdown -t now when: - ansible_facts['distribution'] == "CentOS" - ansible_facts['distribution_major_version'] == "6" 许多Jinja2的测试器和过滤器都可在when子句中使用，其中某些是由Ansible单独提供的。 1234567891011121314tasks: - command: /bin/false register: result ignore_errors: True - command: /bin/something when: result is failed # In older versions of ansible use ``success``, now both are valid but succeeded uses the correct tense. - command: /bin/something_else when: result is succeeded - command: /bin/still/something_else when: result is skipped 123tasks: - shell: echo "This certainly is epic!" when: epic or monumental|bool 123456tasks: - shell: echo "I've got '&#123;&#123; foo &#125;&#125;' and am not afraid to use it!" when: foo is defined - fail: msg="Bailing out. this play requires 'bar'" when: bar is undefined 循环和条件Loops and Conditionals when和loops结合使用，请注意when语句是根据每个项分别处理。 1234tasks: - command: echo &#123;&#123; item &#125;&#125; loop: [ 0, 2, 4, 6, 8, 10 ] when: item &gt; 5 在自定义facts中载入Loading in Custom Facts 如果你想提供自己的facts也很简单。要运行它们，只需要在任务顶部调用你自己定义的模块，这里返回的变量将能访问未来的任务： 12345tasks: - name: gather site specific fact data action: site_facts - command: /usr/bin/thingy when: my_custom_fact_just_retrieved_from_the_remote_system == '1234' Applying when to roles,imports,and includes在roles, imports, includes中使用when语句： 1234- hosts: webservers roles: - role: debian_stock_config when: ansible_facts['os_family'] == 'Debian' 有条件的导入Conditional Imports 一个剧本适用于多个平台和操作系统是很好的栗子。 123456789---- hosts: all remote_user: root vars_files: - "vars/common.yml" - [ "vars/&#123;&#123; ansible_facts['os_family'] &#125;&#125;.yml", "vars/os_defaults.yml" ] tasks: - name: make sure apache is started service: name=&#123;&#123; apache &#125;&#125; state=started 基于变量来选择文件和模板Selecting Files And Templates Based On Variables 基于不同的系统来生成不同的配置文件： 12345678910- name: template a file template: src: "&#123;&#123; item &#125;&#125;" dest: /etc/myapp/foo.conf loop: "&#123;&#123; query('first_found', &#123; 'files': myfiles, 'paths': mypaths&#125;) &#125;&#125;" vars: myfiles: - "&#123;&#123;ansible_facts['distribution']&#125;&#125;.conf" - default.conf mypaths: ['search_location_one/somedir/', '/opt/other_location/somedir/'] 注册变量Register Variables 存储一个给定命令的结果，以便后面来访问它，在playbook中可能很有用。 注意：即使当一个任务由于条件语句跳过，注册也会发生。 register关键字决定将结果保存哪个变量。 12345678910111213- name: check registered variable for emptiness hosts: all tasks: - name: list contents of directory command: ls mydir register: contents - name: check contents for emptiness debug: msg: "Directory is empty" when: contents.stdout == "" 常用factsCommonly Used Facts 12345ansible_facts[‘distribution’]ansible_facts[‘distribution_major_version’]ansible_facts[‘os_family’] 循环Loops: https://docs.ansible.com/ansible/latest/user_guide/playbooks_loops.html 常见的Ansible循环包括改变多个文件/目录的权限、创建多个用户、重复轮询…Ansible提供了两个关键字来创建循环： loop with_&lt;lookup&gt; 注意：We added loop in Ansible 2.5. It is not yet a full replacement for with_&lt;lookup&gt;, but we recommend it for most use cases.We have not deprecated the use of with_&lt;lookup&gt;We are looking to improve loop syntax 两者比较Comparing loop and with_* with_&lt;lookup&gt;关键字依赖于Lookup插件，即便items也是查找； loop关键字等于with_list，它是简单循环的最佳选择； loop关键字不接受字符串作为输入； 一般来说，任何在Migrating from withX to loop中使用`with*可以更新为使用loop`； 当更改with_items为loop时请小心，with_items执行单级的。你需要在loop中使用flatten(1)。栗子如下： 1234567with_items: - 1 - [2,3] - 4# you would needloop: "&#123;&#123; [1, [2,3] ,4] | flatten(1) &#125;&#125;" 标准循环Standard loops 遍历一个简单列表Iterating over a simple list 12345678- name: add several users user: name: "&#123;&#123; item &#125;&#125;" state: present groups: "wheel" loop: - testuser1 - testuser2 遍历一个散列列表Iterating over a list of hashes 12345678- name: add several users user: name: "&#123;&#123; item.name &#125;&#125;" state: present groups: "&#123;&#123; item.groups &#125;&#125;" loop: - &#123; name: 'testuser1', groups: 'wheel' &#125; - &#123; name: 'testuser2', groups: 'root' &#125; 遍历一个字典Iterating over a dictionary 使用dict2items字典过滤器来遍历字典： 12345678910- name: create a tag dictionary of non-empty tags set_fact: tags_dict: "&#123;&#123; (tags_dict|default(&#123;&#125;))|combine(&#123;item.key: item.value&#125;) &#125;&#125;" loop: "&#123;&#123; tags|dict2items &#125;&#125;" vars: tags: Environment: dev Application: payment Another: "&#123;&#123; doesnotexist|default() &#125;&#125;" when: item.value != "" 循环与注册变量Registering variables with a loop 你可以将循环的输出注册为变量： 12345- shell: "echo &#123;&#123; item &#125;&#125;" loop: - "one" - "two" register: echo 复杂循环Complex loops 遍历嵌套的列表Iterating over nested lists 你可以使用Jinja2的表达式来遍历复杂的列表： 1234567- name: give users access to multiple databases mysql_user: name: "&#123;&#123; item[0] &#125;&#125;" priv: "&#123;&#123; item[1] &#125;&#125;.*:ALL" append_privs: yes password: "foo" loop: "&#123;&#123; ['alice', 'bob'] |product(['clientdb', 'employeedb', 'providerdb'])|list &#125;&#125;" 重试任务直到满足条件Retrying a task until a condition is met 可以使用until关键字来重试任务直到满足特定条件： 12345- shell: /usr/bin/foo register: result until: result.stdout.find("all systems go") != -1 retries: 5 delay: 10 循环清单Looping over inventory 遍历资产清单： 1234567891011121314151617181920# show all the hosts in the inventory- debug: msg: "&#123;&#123; item &#125;&#125;" loop: "&#123;&#123; groups['all'] &#125;&#125;"# show all the hosts in the current play- debug: msg: "&#123;&#123; item &#125;&#125;" loop: "&#123;&#123; ansible_play_batch &#125;&#125;"# show all the hosts in the inventory- debug: msg: "&#123;&#123; item &#125;&#125;" loop: "&#123;&#123; query('inventory_hostnames', 'all') &#125;&#125;"# show all the hosts matching the pattern, ie all but the group www- debug: msg: "&#123;&#123; item &#125;&#125;" loop: "&#123;&#123; query('inventory_hostnames', 'all:!www') &#125;&#125;" query与lookuploop关键字需要一个列表作为输入，但是lookup关键字默认返回逗号分隔的值的字符串。 1234# same thingloop: "&#123;&#123; query('inventory_hostnames', 'all') &#125;&#125;"loop: "&#123;&#123; lookup('inventory_hostnames', 'all', wantlist=True) &#125;&#125;" 循环控制Adding controls to loops loop_control关键字让你可以以有效的方式管理自己的循环。 限制循环输出Limiting loop output with label 当遍历复杂的数据结构，你的任务的控制台输出可能是巨大的。为了限制显示的输出，在loop_control中使用label。 123456789101112131415# 此任务输出仅显示每项的name字段- name: create servers digital_ocean: name: "&#123;&#123; item.name &#125;&#125;" state: present loop: - name: server1 disks: 3gb ram: 15Gb network: nic01: 100Gb nic02: 10Gb ... loop_control: label: "&#123;&#123; item.name &#125;&#125;" 暂停循环Pausing within a loop 要控制每个项的执行之间的时间(seconds)，在loop_control中使用pause。 12345678910# main.yml- name: create servers, pause 3s before creating next digital_ocean: name: "&#123;&#123; item &#125;&#125;" state: present loop: - server1 - server2 loop_control: pause: 3 追踪流程Tracking progress through a loop with index_var 要追踪你在循环的位置，在loop_control中使用index_var。 123456789- name: count our fruit debug: msg: "&#123;&#123; item &#125;&#125; with index &#123;&#123; my_idx &#125;&#125;" loop: - apple - banana - pear loop_control: index_var: my_idx inner and outer variable namesDefining inner and outer variable names with loop_var 可使用include_tasks嵌套两个循环任务。然而，默认情况下Ansible为每个循环item设置循环变量。This means the inner, nested loop will overwrite the value of item from the outer loop.你可以在loop_control中使用loop_var来为每个循环指定变量名。 123456789101112131415- include_tasks: inner.yml loop: - 1 - 2 - 3 loop_control: loop_var: outer_item# inner.yml- debug: msg: "outer item=&#123;&#123; outer_item &#125;&#125; inner item=&#123;&#123; item &#125;&#125;" loop: - a - b - c 扩展的循环变量Extended loop variables 在循环控制中使用extended选项来获取扩展的循环信息： 12loop_control: extended: yes 1234567891011Variable Descriptionansible_loop.allitems The list of all items in the loopansible_loop.index The current iteration of the loop. (1 indexed)ansible_loop.index0 The current iteration of the loop. (0 indexed)ansible_loop.revindex The number of iterations from the end of the loop (1 indexed)ansible_loop.revindex0 The number of iterations from the end of the loop (0 indexed)ansible_loop.first True if first iterationansible_loop.last True if last iterationansible_loop.length The number of items in the loopansible_loop.previtem The item from the previous iteration of the loop. Undefined during the first iteration.ansible_loop.nextitem The item from the following iteration of the loop. Undefined during the last iteration. 从with_x迁移到loopMigrating from with_X to loop 从Ansible 2.5开始，执行循环的推荐的方式是使用新的loop关键字来取代with_x格式的循环。 在许多情况下，loop语法是使用过滤器的更好的表达，而不是更复杂的query或lookup。 1234567891011121314# with_list被loop替代- name: with_list debug: msg: "&#123;&#123; item &#125;&#125;" with_list: - one - two- name: with_list -&gt; loop debug: msg: "&#123;&#123; item &#125;&#125;" loop: - one - two 12345678910# with_items被loop和flatten过滤器替代- name: with_items debug: msg: "&#123;&#123; item &#125;&#125;" with_items: "&#123;&#123; items &#125;&#125;"- name: with_items -&gt; loop debug: msg: "&#123;&#123; item &#125;&#125;" loop: "&#123;&#123; items|flatten(levels=1) &#125;&#125;" 123456789101112# with_indexed_items被loop, flatten, loop_control.index_var替代- name: with_indexed_items debug: msg: "&#123;&#123; item.0 &#125;&#125; - &#123;&#123; item.1 &#125;&#125;" with_indexed_items: "&#123;&#123; items &#125;&#125;"- name: with_indexed_items -&gt; loop debug: msg: "&#123;&#123; index &#125;&#125; - &#123;&#123; item &#125;&#125;" loop: "&#123;&#123; items|flatten(levels=1) &#125;&#125;" loop_control: index_var: index 12345678910# with_flattened被loop和flatten替代- name: with_flattened debug: msg: "&#123;&#123; item &#125;&#125;" with_flattened: "&#123;&#123; items &#125;&#125;"- name: with_flattened -&gt; loop debug: msg: "&#123;&#123; item &#125;&#125;" loop: "&#123;&#123; items|flatten &#125;&#125;" 123456789101112# with_together被loop和zip替代- name: with_together debug: msg: "&#123;&#123; item.0 &#125;&#125; - &#123;&#123; item.1 &#125;&#125;" with_together: - "&#123;&#123; list_one &#125;&#125;" - "&#123;&#123; list_two &#125;&#125;"- name: with_together -&gt; loop debug: msg: "&#123;&#123; item.0 &#125;&#125; - &#123;&#123; item.1 &#125;&#125;" loop: "&#123;&#123; list_one|zip(list_two)|list &#125;&#125;" 123456789101112131415# with_dict可通过loop和 dictsort或dict2items替代- name: with_dict debug: msg: "&#123;&#123; item.key &#125;&#125; - &#123;&#123; item.value &#125;&#125;" with_dict: "&#123;&#123; dictionary &#125;&#125;"- name: with_dict -&gt; loop (option 1) debug: msg: "&#123;&#123; item.key &#125;&#125; - &#123;&#123; item.value &#125;&#125;" loop: "&#123;&#123; dictionary|dict2items &#125;&#125;"- name: with_dict -&gt; loop (option 2) debug: msg: "&#123;&#123; item.0 &#125;&#125; - &#123;&#123; item.1 &#125;&#125;" loop: "&#123;&#123; dictionary|dictsort &#125;&#125;" 1234567891011# with_sequence被loop, range, format替代- name: with_sequence debug: msg: "&#123;&#123; item &#125;&#125;" with_sequence: start=0 end=4 stride=2 format=testuser%02x- name: with_sequence -&gt; loop debug: msg: "&#123;&#123; 'testuser%02x' | format(item) &#125;&#125;" # range is exclusive of the end point loop: "&#123;&#123; range(0, 4 + 1, 2)|list &#125;&#125;" 123456789101112# with_subelements被loop, subelements替代- name: with_subelements debug: msg: "&#123;&#123; item.0.name &#125;&#125; - &#123;&#123; item.1 &#125;&#125;" with_subelements: - "&#123;&#123; users &#125;&#125;" - mysql.hosts- name: with_subelements -&gt; loop debug: msg: "&#123;&#123; item.0.name &#125;&#125; - &#123;&#123; item.1 &#125;&#125;" loop: "&#123;&#123; users|subelements('mysql.hosts') &#125;&#125;" 123456789101112# with_nested/with_cartesian被loop, product替代- name: with_nested debug: msg: "&#123;&#123; item.0 &#125;&#125; - &#123;&#123; item.1 &#125;&#125;" with_nested: - "&#123;&#123; list_one &#125;&#125;" - "&#123;&#123; list_two &#125;&#125;"- name: with_nested -&gt; loop debug: msg: "&#123;&#123; item.0 &#125;&#125; - &#123;&#123; item.1 &#125;&#125;" loop: "&#123;&#123; list_one|product(list_two)|list &#125;&#125;" 12345678910# with_random_choice被random替代- name: with_random_choice debug: msg: "&#123;&#123; item &#125;&#125;" with_random_choice: "&#123;&#123; my_list &#125;&#125;"- name: with_random_choice -&gt; loop (No loop is needed here) debug: msg: "&#123;&#123; my_list|random &#125;&#125;" tags: random BlockBlocks: https://docs.ansible.com/ansible/latest/user_guide/playbooks_blocks.html 块允许任务的逻辑分组，并在play中错误处理。大多数可以适用于单任务的也可适用于块(block)，这使得它很容易设置数据或常见指令到任务。这并不意味着该指令影响块自身，而是有一个块包围的任务继承。 1234567891011121314151617181920212223tasks: - name: Install, configure, and start Apache block: - name: install httpd and memcached yum: name: - httpd - memcached state: present - name: apply the foo config template template: src: templates/src.j2 dest: /etc/foo.conf - name: start service bar and enable it service: name: bar state: started enabled: True when: ansible_facts['distribution'] == 'CentOS' become: true become_user: root ignore_errors: yes 在上面的栗子中，块中3个任务中的每一个附加在when条件后，在任务上下文评估之后都将执行。 块中的任务名在Ansible 2.3时可用。建议在所有任务中使用名称，无论是块还是其它地方。 块错误处理Blocks error handling 块同样介绍了类似于大多数编程语言的异常处理的错误处理的方法。块仅处理任务的失败(failed)状态。一个糟糕的任务定义或主机不可达不是rescuable错误。 12345678910111213# block error handling exampletasks: - name: Handle the error block: - debug: msg: 'I execute normally' - name: i force a failure command: /bin/false - debug: msg: 'I never execute, due to the above task failing, :-(' rescue: - debug: msg: 'I caught an error, can do stuff here to fix it, :-)' always部分，无论什么任务状态都将会运行。 1234567891011- name: Always do X block: - debug: msg: 'I execute normally' - name: i force a failure command: /bin/false - debug: msg: 'I never execute :-(' always: - debug: msg: "This always executes, :-)" 高级的playbook功能Advanced Playbooks Features: https://docs.ansible.com/ansible/latest/user_guide/playbooks_special_topics.html 下面有许多playbook功能不需要每个人都去学习，但可以为特定应用提供有用的功能。浏览这些话题，因为你可能找有一些有用的技巧。 特权晋升 异步操作和轮询Asynchronous Actions and Polling: https://docs.ansible.com/ansible/latest/user_guide/playbooks_async.html 默认情况下，playbook块中的任务，直到任务在每个节点上完成后连接才会断开。这可能不总是可取的，或者你需要运行超过ssh timeout的操作。 限时后台操作(Time-limited background operations) 你可以在后台运行长时间运行的操作，之后再检查它们的状态。例如，异步地在后台执行long_running_operation： 123456# -B 超时时间， -p 轮询数ansible all -B 3600 -P 0 -a "/usr/bin/long_running_operation --do-stuff"# async_status模块 检查状态ansible web1.example.com -m async_status -a "jid=488359678239.2844" 轮询模式是智能的，所以在轮询将在任意机器上开始之前所有的工作都将启动。如果想要所有工作快速开始，请确保使用足够高的--forks。在超时之后，远程节点上的进程将会被终止。 通常，你只需在后台长时间运行shell命令或软件更新。后台复制模块不会进行文件传输。 为了避免阻塞或超时问题，你可以使用异步模式来一次运行你的所有任务，并轮询直到它们完成。 异步模式的行为依赖于poll值。 Avoid connection timeouts: poll &gt; 0 当poll是正值，playbook仍然会阻塞任务直到它完成、失败或超时。 要异步启动任务，请指定其最大运行实践和要轮询状态的频率。如果未指定poll，则默认由DEFAULT_POLL_INTERVAL设置。 12345678---- hosts: all remote_user: root tasks: - name: simulate long running op (15 sec), wait for up to 45 sec, poll every 5 sec command: /bin/sleep 15 async: 45 poll: 5 Concurrent tasks: poll=0 当poll为0时，Ansible将启动任务，并立即移动到下一个而不必等待结果。 从序列试图这点是异步编程：任务现在可以同时运行。playbook将结束而不检查异步返回。异步任务将执行根据async的值，直到它们完成、失败或超时。 12345678---- hosts: all remote_user: root tasks: - name: simulate long running op, allow to run for 45 sec, fire and forget command: /bin/sleep 15 async: 45 poll: 0 检查模式Check Mode: https://docs.ansible.com/ansible/latest/user_guide/playbooks_checkmode.html DebuggerPlaybook Debugger Ansible包含了debugger作为策略插件的一部分。此调试器允许你调试任务。你可以在任务的上下文中访问所有的调试器的功能，以帮助解决失败的问题。 有多种方式来调用调试器。 使用debugger关键字(Using the debugger keyword) 可在提供name属性的块中使用debugger关键字，如paly, role, block, task。debugger关键字接受下列值： always: 总是调用调试器 never: 绝不调用调试器 on_failed: 任务失败才调用调试器 on_skipped: 任务跳过才调用调试器 全局配置： 1234# on a task- name: execute a command command: false debugger: on_failed 12345678# on a play- name: play hosts: all debugger: on_skipped tasks: - name: Execute a command command: true when: False 在特定层级上： 1234567- name: Play hosts: all debugger: never tasks: - name: Execute a command command: false debugger: on_failed 配置或环境变量(Configuration or environment variable) 123# ansible.cfg[defaults]enable_task_debugger = True 12# environment variableANSIBLE_ENABLE_TASK_DEBUGGER=True ansible-playbook -i hosts site.yml 策略(As a Strategy) 要使用debug策略，改变strategy属性： 1234- hosts: test strategy: debug tasks: ... 123# ansible.cfg[defaults]strategy = debug 12# environment variableANSIBLE_STRATEGY=debug 可用命令(Available Commands) 打印值： 12345678910111213141516171819[192.0.2.10] TASK: install package (debug)&gt; p taskTASK: install package[192.0.2.10] TASK: install package (debug)&gt; p task.args&#123;u&apos;name&apos;: u&apos;&#123;&#123; pkg_name &#125;&#125;&apos;&#125;[192.0.2.10] TASK: install package (debug)&gt; p task_vars&#123;u&apos;ansible_all_ipv4_addresses&apos;: [u&apos;192.0.2.10&apos;], u&apos;ansible_architecture&apos;: u&apos;x86_64&apos;, ...&#125;[192.0.2.10] TASK: install package (debug)&gt; p task_vars[&apos;pkg_name&apos;]u&apos;bash&apos;[192.0.2.10] TASK: install package (debug)&gt; p host192.0.2.10[192.0.2.10] TASK: install package (debug)&gt; p result._result&#123;&apos;_ansible_no_log&apos;: False, &apos;changed&apos;: False, u&apos;failed&apos;: True, ... u&apos;msg&apos;: u&quot;No package matching &apos;not_exist&apos; is available&quot;&#125; 滚动升级Delegation, Rolling Updates, and Local Actions: https://docs.ansible.com/ansible/latest/user_guide/playbooks_delegation.html 设置环境Setting the Environment: https://docs.ansible.com/ansible/latest/user_guide/playbooks_environment.html environment关键字可以允许你为远程目标主机设置环境变量。例如，需要为http请求设置一个代理。获取其它工具需要的环境变量。 123456789- hosts: all remote_user: root tasks: - name: Install cobbler package: name: cobbler state: present environment: http_proxy: http://proxy.example.com:8080 也可以存储在一个变量里： 123456789101112- hosts: all remote_user: root # here we make a variable named "proxy_env" that is a dictionary vars: proxy_env: http_proxy: http://proxy.example.com:8080 tasks: - name: Install cobbler package: name: cobbler state: present environment: "&#123;&#123; proxy_env &#125;&#125;" 特定语言版本管理器Working With Language-Specific Version Managers 一些特定语言版本管理器(如nvm)要求，而这些工具在使用中都要求环境变量。挡手动使用这些工具，通常需要在配置文件中添加一些环境变量，在Ansible中，你可使用enviroment代替： 123456789101112131415161718192021222324252627282930313233---### A playbook demonstrating a common npm workflow:# - Check for package.json in the application directory# - If package.json exists:# * Run npm prune# * Run npm install- hosts: application become: false vars: node_app_dir: /var/local/my_node_app environment: NVM_DIR: /var/local/nvm PATH: /var/local/nvm/versions/node/v4.2.1/bin:&#123;&#123; ansible_env.PATH &#125;&#125; tasks: - name: check for package.json stat: path: &apos;&#123;&#123; node_app_dir &#125;&#125;/package.json&apos; register: packagejson - name: npm prune command: npm prune args: chdir: &apos;&#123;&#123; node_app_dir &#125;&#125;&apos; when: packagejson.stat.exists - name: npm install npm: path: &apos;&#123;&#123; node_app_dir &#125;&#125;&apos; when: packagejson.stat.exists 错误处理Error Handling In Playbooks: https://docs.ansible.com/ansible/latest/user_guide/playbooks_error_handling.html Ansible通常有默认值来确保检查命令和模块的返回码和是否失败，进行错误处理，除非你做了决定。 忽略错误命令(Ignoring Failed Commands) 一般来说，如果主机上有任务失败，playbook将停止执行。有时，你想让它继续进行： 123- name: this will not be counted as a failure command: /bin/false ignore_errors: yes 重置不可达的主机(Resetting Unreachable Hosts) 连接失败将设置主机为不可达(UNREACHABLE)，它将从运行活跃主机列表中删除。可以使用meta: clear_host_errors来设置。 处理程序和失败(Handlers and Failure) 当主机上的一个任务失败时，先前通知(notify)的处理程序(handler)将不会在此主机上运行。例如，任务更新配置文件并通知处理程序去重启服务。如果任务以后的同一个play失败，则服务不会重启尽管配置已经更改。 可以使用--force-handlers命令行选项来改变此行为。或在play中包含force_handlers: True，或在ansible配置中包含force_handlers = True。当处理程序被强制执行，无论任务成功与否它们都会执行。 控制如何定义失败(Controlling What Defines Failure) Ansible允许你使用filed_when条件来定义失败。栗子： 1234- name: Fail task when the command error output prints FAILED command: /usr/bin/example-command -x -y -z register: command_result failed_when: "'FAILED' in command_result.stderr" 覆盖改变的结果(Overriding The Changed Result) 当一个模块运行，它通常会基于机器状态是否被影响而报告changed状态。 有时候你知道，基于返回码或返回结果，它并没有发生改变，并希望去覆盖changed结果，使它不出现在报告输出里： 123456- command: /bin/fake_command register: result ignore_errors: True changed_when: - '"ERROR" in result.stderr' - result.rc == 2 终止play(Aborting the play) 有时需要终止失败的play，而不是为某主机跳过剩余任务。 any_errors_fatal选项将终止Play，并防止任何后续的plays运行。当遇到一个错误，当前批次的所有主机都有机会完成致命的任务，然后play的执行停止。any_errors_fatal可在play或block层级设置： 12345678910- hosts: somehosts any_errors_fatal: true roles: - myrole- hosts: somehosts tasks: - block: - include_tasks: mytasks.yml any_errors_fatal: true 使用块(blocks) 大多数可应用到单个任务的也可应用到块，这使得它更容易设置数据或指定到任务。块只处理任务的失败(failed)状态。 123456789101112tasks:- name: Handle the error block: - debug: msg: 'I execute normally' - name: i force a failure command: /bin/false - debug: msg: 'I never execute, due to the above task failing, :-(' rescue: - debug: msg: 'I caught an error, can do stuff here to fix it, :-)' 高级语法Advanced Syntax: https://docs.ansible.com/ansible/latest/user_guide/playbooks_advanced_syntax.html 高级的YANL语法可以给你在Ansible的YAML文件中更多控制数据的地方。你可以在PyYAML文档中找到等多Python特定化的YAML信息。 不安全和原生字符串Unsafe or Raw Strings Ansible提供了一个内部的数据类型，用来声明变量不安全(unsafe)。这意味着变量中保存的数据应为不安全，防止字符串被替换和披露。 Jinja2包含了转义，或告诉Jinja2不渲染数据，如...。 12# 使用 !unsafe 标签my_unsafe_variable: !unsafe &apos;this variable has &#123;&#123; characters that should not be treated as a jinja2 template&apos; 123456---hosts: allvars: my_unsafe_variable: !unsafe 'unsafe value'tasks: ... 锚和别名YAML anchors and aliases: sharing variable values YAML的锚(anchor)和别名(aliase)可以帮助你在灵活的方式中定义、维护和使用共享变量。使用&amp;定义一个锚，使用别名(*)指向它。 1234567891011121314# 锚内设置了3个变量，别名使用其它2个，并覆盖第3个---...vars: app1: jvm: &amp;jvm_opts opts: '-Xms1G -Xmx2G' port: 1000 path: /usr/lib/app1 app2: jvm: &lt;&lt;: *jvm_opts path: /usr/lib/app2... path的值由合并操作符(&lt;&lt;)所合并。 使用插件Working With Plugins: https://docs.ansible.com/ansible/latest/plugins/plugins.html 插件时扩展Ansible的核心功能。Ansible使用插件架构来实现丰富的、灵活的、可扩展的功能集。 Ansible ships附带了许多插件，你也可以自己编写。 Action Plugins Become Plugins Cache Plugins Callback Plugins Cliconf Plugins Connection Plugins Httpapi Plugins Inventory Plugins Lookup Plugins Netconf Plugins Shell Plugins Strategy Plugins Vars Plugins Filters Tests Plugin Filter Configuration 提示和输入Prompts: https://docs.ansible.com/ansible/latest/user_guide/playbooks_prompts.html 当运行playbook时，你可能希望提示某些用户输入信息，可使用vars_prompt来完成。一个常见的用途可能是要求输入敏感的数据，但不希望记录。 1234567891011---- hosts: all vars_prompt: - name: username prompt: "What is your username?" private: no - name: password prompt: "What is your password?" tasks: - debug: msg: 'Logging in as &#123;&#123; username &#125;&#125;' 标签Tags: https://docs.ansible.com/ansible/latest/user_guide/playbooks_tags.html 如果你有一个大型的playbook，它可能成为一个有用的能够运行playbook的一个特定部分，而不是playbook中的所有。Ansible支持使用标签(tags)来完成。 标签可应用于Ansible的许多结构，但最简单的方法是单个任务。 栗子： 1234567891011121314tasks:- yum: name: - httpd - memcached state: present tags: - packages- template: src: templates/src.j2 dest: /etc/foo.conf tags: - configuration 当你执行playbook，你可以用两种方法基于标签过滤任务： 在命令行使用--tags或--skip-tags选项； 在Ansible配置中，使用TAGS_RUN或TAGS_SKIP选项。 12345678# 仅执行某个标签ansible-playbook example.yml --tags &quot;configuration,packages&quot;# 跳过某个标签ansible-playbook example.yml --skip-tags &quot;packages&quot;# 产看标签执行情况ansible-playbook example.yml --tags &quot;configuration,packages&quot; --list-tasks 标签重用Tag Reuse 控制playbook执行Controlling playbook execution: strategies and more: https://docs.ansible.com/ansible/latest/user_guide/playbooks_strategies.html 默认情况下，Ansible在使用5forks任意主机上开始下一个任务之前在所有被play影响的主机上运行每个任务。如果你想要改变此默认的行为，你可以使用不同的策略插件，改变fork数，或应用几个play级别的关键字（如serial）。 选择策略Selecting a strategy linear strategy: https://docs.ansible.com/ansible/latest/plugins/strategy/linear.html#linear-strategy debug strategy: https://docs.ansible.com/ansible/latest/plugins/strategy/debug.html#debug-strategy free strategy: https://docs.ansible.com/ansible/latest/plugins/strategy/free.html#free-strategy 1234- hosts: all strategy: free tasks: ... 设置fork数Setting the number of forks 1234567# ansible.cfg[defaults]forks = 30# or cliansible-playbook -f 30 my_playbook.ym 使用关键字控制执行Using keywords to control execution play level的关键字会影响paly的执行。 最常见的是serial，还有throttle, ignore_errors, ignore_unreachable, any_errors_fatal。 最佳实践Best Practices: https://docs.ansible.com/ansible/latest/user_guide/playbooks_best_practices.html 使用Ansible和playbooks的一些技巧。 你可以在ansible-examples仓库中找到最佳用法。 内容组织Content Organization 下面将介绍组织Playbook内容的多种方式。你的ansible的使用应该适合你的需求，因此你可以按需组合各种方法。 组织ansible playbook内容的一个关键方式是role。你应该理解它。 目录布局Directory Layout 栗子： 1234567891011121314151617181920212223242526272829303132333435363738394041staging # inventory file for staging environmentgroup_vars/ group1.yml # here we assign variables to particular groups group2.ymlhost_vars/ hostname1.yml # here we assign variables to particular systems hostname2.ymllibrary/ # if any custom modules, put them here (optional)module_utils/ # if any custom module_utils to support modules, put them here (optional)filter_plugins/ # if any custom filter plugins, put them here (optional)site.yml # master playbookwebservers.yml # playbook for webserver tierdbservers.yml # playbook for dbserver tierroles/ common/ # this hierarchy represents a "role" tasks/ # main.yml # &lt;-- tasks file can include smaller files if warranted handlers/ # main.yml # &lt;-- handlers file templates/ # &lt;-- files for use with the template resource ntp.conf.j2 # &lt;------- templates end in .j2 files/ # bar.txt # &lt;-- files for use with the copy resource foo.sh # &lt;-- script files for use with the script resource vars/ # main.yml # &lt;-- variables associated with this role defaults/ # main.yml # &lt;-- default lower priority variables for this role meta/ # main.yml # &lt;-- role dependencies library/ # roles can also include custom modules module_utils/ # roles can also include custom module_utils lookup_plugins/ # or other types of plugins, like lookup in this case webtier/ # same kind of structure as "common" was above, done for the webtier role monitoring/ # "" fooapp/ # "" 可选的目录布局Alternative Directory Layout 此布局为大型环境提供了更多灵活性，栗子： 1234567891011121314151617181920212223242526272829303132inventories/ production/ hosts # inventory file for production servers group_vars/ group1.yml # here we assign variables to particular groups group2.yml host_vars/ hostname1.yml # here we assign variables to particular systems hostname2.yml staging/ hosts # inventory file for staging environment group_vars/ group1.yml # here we assign variables to particular groups group2.yml host_vars/ stagehost1.yml # here we assign variables to particular systems stagehost2.ymllibrary/module_utils/filter_plugins/site.ymlwebservers.ymldbservers.ymlroles/ common/ webtier/ monitoring/ fooapp/ 使用云动态资产Use Dynamic Inventory With Clouds 如果你使用云服务提供商，你不应该在静态文件中管理你的资产。请参考Working with dynamic inventory 如何区分测试与生产How to Differentiate Staging vs Production 如果管理静态清单，经常会问到如何区分不同类型的环境。下面的例子提供了一个好方法。分组的类似方法可以适用动态清单。 123456789101112131415161718192021222324252627282930313233343536# file: production[atlanta_webservers]www-atl-1.example.comwww-atl-2.example.com[boston_webservers]www-bos-1.example.comwww-bos-2.example.com[atlanta_dbservers]db-atl-1.example.comdb-atl-2.example.com[boston_dbservers]db-bos-1.example.com# webservers in all geos[webservers:children]atlanta_webserversboston_webservers# dbservers in all geos[dbservers:children]atlanta_dbserversboston_dbservers# everything in the atlanta geo[atlanta:children]atlanta_webserversatlanta_dbservers# everything in the boston geo[boston:children]boston_webserversboston_dbservers 组和主机变量Group And Host Variables 1234---# file: group_vars/atlantantp: ntp-atlanta.example.combackup: backup-atlanta.example.com 1234---# file: group_vars/webserversapacheMaxRequestsPerChild: 3000apacheMaxClients: 900 1234---# file: group_vars/allntp: ntp-boston.example.combackup: backup-boston.example.com 顶级playbook通过角色分离Top Level Playbooks Are Separated By Role 1234---# file: site.yml- import_playbook: webservers.yml- import_playbook: dbservers.yml 123456---# file: webservers.yml- hosts: webservers roles: - common - webtier 这里，我们可以选择运行site.yml来配置我们的整个基础架构，或者通过运行webservers.yml来只运行一个子集。类似于下面： 12ansible-playbook site.yml --limit webserversansible-playbook webservers.yml 角色的任务和处理程序组织Task And Handler Organization For A Role 下面解释一个NTP任务是如何工作： 12345678910111213141516171819202122# file: roles/common/tasks/main.yml- name: be sure ntp is installed yum: name: ntp state: present tags: ntp- name: be sure ntp is configured template: src: ntp.conf.j2 dest: /etc/ntp.conf notify: - restart ntpd tags: ntp- name: be sure ntpd is running and enabled service: name: ntpd state: started enabled: yes tags: ntp 这是一个处理程序(handler)文件栗子： 123456---# file: roles/common/handlers/main.yml- name: restart ntpd service: name: ntpd state: restarted 什么组织启用What This Organization Enables 123456789101112131415161718# 重新配置基础服务ansible-playbook -i production site.yml# 重新配置NTPansible-playbook -i production site.yml --tags ntp# 重新配置webserversansible-playbook -i production webservers.yml# bostonansible-playbook -i production webservers.yml --limit boston# boston first 10ansible-playbook -i production webservers.yml --limit boston[0:9]# ad-hocansible boston -i production -m command -a &apos;/sbin/reboot&apos; 部署于配置组织Deployment vs Configuration Organization 上面的配置模型是一个典型的配置拓扑。当进行多级部署中，会有一些额外的playbook（hop between tiers to roll out an application）。 测试与生产Staging vs Production 如上所述，让staging(testing)和production环境分离是为不同的环境使用单独的清单文件。你的环境不一定是相同的大小，你可以使用变量来控制它们。 滚动更新Rolling Updates 理解serial关键字。 注意状态Always Mention The State state参数对许多模块是可选的。如state=present或state=absent。 通过角色分组Group By Roles 一个系统可以在多个组。这使得playbook基于角色来选择目标主机。以及使用该组变量系统来分配角色特定的变量。 操作系统和发行版本Operating System and Distribution Variance 当在两个不同的操作系统之间处理一个参数时，处理它的一个好方法是使用group_by模块。 1234567891011121314--- - name: talk to all hosts just so we can learn about them hosts: all tasks: - name: Classify hosts depending on their OS distribution group_by: key: os_&#123;&#123; ansible_facts['distribution'] &#125;&#125; # now just on the CentOS hosts... - hosts: os_CentOS gather_facts: False tasks: - # tasks that only happen on CentOS go here 123456- hosts: all tasks: - name: Set OS distribution dependent variables include_vars: "os_&#123;&#123; ansible_facts['distribution'] &#125;&#125;.yml" - debug: var: asdf 使用playbook捆绑ansible模块Bundling Ansible Modules With Playbooks 如果playbook有相对于其它YAML文件的./library目录，此目录可以用来添加ansible module，它会自动在ansible模块路径。这是一个保持模块与playbook在一起的好方法。 空白和注释Whitespace and Comments 空白和注释有利于文件可读性，值得使用。 任务命名Always Name Tasks 给任务建立一个正在做什么的名称。在运行时，playbook显示此名称。 使它简单Keep It Simple 当你能够简单地做事，那就简单地做。不要为了达到使用所有ansible功能而一起使用它们。使用你需要的。把复杂的事情简单化。 版本控制Version Control 使用版本控制来管理playbook。 变量和拱顶Variables and Vaults 当运行playbook，Ansible在未加密的文件中查找变量，并且所有敏感的变量来自加密文件。 一个最佳实践方法是在组下开始一个group_vars子目录。在此子目录内，创建两个名为vars和vault的文件。vars文件内定义所有需要的变量，包括敏感的。接下来，复制所有的敏感变量到vault文件或以vault_开头的文件。你应该在vars文件内使用Jinja2语法调整变量指向匹配的vault_文件，并确保vault文件是vault encrypted。 持续交付和滚动更新Playbook Example: Continuous Delivery and Rolling Upgrades: https://docs.ansible.com/ansible/latest/user_guide/guide_rolling_upgrade.html 什么是持续交付What is continuous delivery Continuous delivery(CD)是指经常更新你的软件应用程序。 特权晋升Understanding privilege escalation: become: https://docs.ansible.com/ansible/latest/user_guide/become.html Ansible使用现有的权限升级系统来执行具有root或其它权限的任务。此功能允许你成为(become)其它用户，与登录到远程机器不同，我们称之为become。become关键字利用现有的权限提升工具（如sudo, su, pfexec, doas, pbrun, dzdo, ksu, runas）。 使用你可以在任务、连接变量、命令行等控制become的使用。如果你以多种方式设置了特权提升，请注意优先级。 所有become plugins完整的列表: https://docs.ansible.com/ansible/latest/plugins/become.html#become-plugin-list become 你可在play或task层设置become指令。你可以设置连接变量，从不同主机之间覆盖它们。 12345678# 激活特权提升become: yes# 默认rootbecome_user: xxx# 参考become plugins，可在ansible.cfg中配置。默认sudobecome_method: sudo# 为role或task执行特定标志become_flags: xxx 栗子： 1234567891011121314151617- name: Ensure the httpd is running become: yes service: name: httpd state: started- name: Run a command as the apache user command: somecommand become: yes become_user: apache- name: Run a command as nobody command: somecommand become: yes become_method: su become_user: nobody become_flags: &apos;-s /bin/sh&apos; 连接变量 Become connection variables 你可以定义不同的选型来管理node或group。你可以在资产中定义这些变量，或将其作为正常的变量使用。 1234567ansible_becomeansible_become_methodansible_become_useransible_become_password# 栗子webserver ansible_user=manager ansible_become=yes 命令行选项 1234--ask-become-pass, -K--become, -b--become-method=BECOME_METHOD--become-user=BECOME_USER 风险和局限性Risks and limitations of become 虽然权限提升是很直观的，但它如何工作也有一些限制。用户应该知道这些，以避免意外。 成为一个非特权用户的风险Risks of becoming an unprivileged user Ansible模块由第一个参数带入模块文件，然后将其复制到远程主机，最后在远程机器上执行它。 如果模块文件不使用become，当become_ueer为root时，或当远程机器被设置为root时，一切都好。在这些情况下，Ansible创建具有只允许由所述用户和root读取，或只允许由所述非特权用户切换到读取权限模块文件。 然而，当连接用户和become_user都不是特权用户，模块文件被写入需要由Ansible设置为用户可读。在这种情况下，Ansible使得模块文件世界可读的Ansible模块执行的持续时间。一旦模块执行完毕，Ansible删除临时文件。 不是所有连接插件都支持Not supported by all connection plugins 特权升级方法也必须由连接使用的插件支持。 每个主机只能启用一个方法Only one method may be enabled per host 特权提升必须通用Privilege escalation must be general 你不能限制权限提升某些命令的权限。 VaultAnsible Vault: https://docs.ansible.com/ansible/latest/user_guide/vault.html Ansible Vault是Ansible的一个功能，可以让你在加密的文件中保存敏感数据（如密码、密钥），而不是像普通文本或playbooks或roles中。这些vault文件可以分布或放置在版本控制中。 要启用此功能，使用命令行选型-ansible-vault，和--vault-password-file。 ModulesAnsible Modules: https://docs.ansible.com/ansible/latest/user_guide/modules.html Ansible包含了大量的模块(module library)，可以直接在远程主机或通过playbook执行。 用户也可以编写自己的模块。这些模块可以控制系统资源（服务、包、文件…），或执行系统命令。 模块介绍Introduction to modules: https://docs.ansible.com/ansible/latest/user_guide/modules_intro.html 12# adhocansible webservers -m service -a "name=httpd state=started" 12345# playbook- name: restart webserver service: name: httpd state: restarted 返回值Return Values: https://docs.ansible.com/ansible/latest/reference_appendices/common_return_values.html Ansible模块通常正常返回一个可以注册为一个变量的数据结构，或直接看到由ansible程序输出。每个模块都可选的记录自己唯一的返回值。 本章节包含的返回值适用于所有模块。 Common backup_file changed failed invocation msg rc results skipped stderr stderr_lines stdout stdout_lines Internal use ansible_facts exception warning deprecations 模块索引Module Index: https://docs.ansible.com/ansible/latest/modules/modules_by_category.html 插件Working With Plugins: https://docs.ansible.com/ansible/latest/plugins/plugins.html 插件是一段代码，可以扩充Ansible的核心功能。Ansible使用插件架构，以实现丰富的、灵活的、可扩展的功能集。 Ansible附带了一些方便的插件，你也可以很容易地编写自己的插件。 collectionscollections: https://docs.ansible.com/ansible/latest/user_guide/collections_using.html Collections是Ansible的内容分发格式，可以包括playbooks, roles, modules, plugins。你可以通过Ansible Galaxy安装和使用collections。 开发指南Developer Guide: https://docs.ansible.com/ansible/latest/dev_guide/index.html Ansible GalaxyAnsible Galaxy: https://docs.ansible.com/ansible/latest/galaxy/user_guide.html Ansible Galaxy是一个查找、分享、下载社区开发的roles的网站。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Ansible</tag>
        <tag>Automation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tornado]]></title>
    <url>%2F2019%2F10%2F14%2FTornado%2F</url>
    <content type="text"><![CDATA[环境: Tornado: v5.1 Python: v3.6 参考: Docs: https://www.tornadoweb.org/en/branch5.1/ 用户指南 介绍Tornado是一个Python Web框架和异步(asynchronous)网络库。通过使用非阻塞(non-blocking)网络I/O，Tornado可以扩展到上万个连接，因此非常适合长轮询(long polling)、WebSocket需要长期连接到的每个用户的应用程序。 Tornado大致可以分为四个主要组件: Web框架：包含RequestHandler，它的子类用于创建web应用，并支持各种类。 HTTP的Client和Server的实现：HTTPServer和AsyncHTTPClient。 异步网络库(IOLoop和IOStream)，用于HTTP组件的构建块，并且还可实现其它协议。 协程库(tornado.gen)，允许异步代码写的更直接而不用链式回调(chaining callbacks)的方式。 Tornado web框架和HTTP server一起为WSGI提供了一个全栈(full-stack)式选择。为了充分利用Tornado的特性，你需要一起使用Tornado Web框架和HTTP Server。 异步和非阻塞I/O实时(real-time) Web功能需要为每个用户提供一个长时间空闲(mostly-idle)的长连接。在传统的同步(synchronous) web server，这意味着为每个用户提供一个线程(thread)，这是非常昂贵的。要尽可能减少并发连接(concurrent connections)的开销，Tornado使用一个单线程事件循环。这意味着所有应用程序代码都应该是异步非阻塞的，因为在同一时间只有一个操作是活跃的。异步和非阻塞这两个术语是非常相关的，并经常交换使用，但它们不是完全相同的事情。 阻塞一个函数在等待某些事情的返回的时候会被阻塞(block)。函数阻塞的原因有很多，如：网络IO、磁盘IO、互斥锁…事实上，每个函数在运行和使用CPU的时候或多或少会被阻塞。 一个函数可以在某些方面阻塞，在另外一些方面不阻塞。在Tornado下，我们通常讨论网络IO阻塞，尽管各种阻塞也被最小化。 异步异步(asynchronous)函数在完成之前返回，在应用中触发下一个动作之前通常会在后台执行一些工作（和正常的同步函数在返回之前就执行完所有的事情不同）。这里列举了几种风格的异步接口： 回调参数 返回一个占位符 传送给一个队列 回调注册表 栗子一个同步(synchronous)函数的栗子: 123456from tornado.httpclient import HTTPClientdef synchronous_fetch(url): http_client = HTTPClient() response = http_client.fetch(url) return response.body 一个异步(asynchronous)重写的函数: 123456from tornado.httpclient import AsyncHTTPClientasync def asynchronous_fetch(url): http_client = AsyncHTTPClient() response = await http_client.fetch(url) return response.body 协程(coroutines)有点不可思议，但它们在内如是这样的: 12345678910from tornado.concurrent import Futuredef async_fetch_manual(url): http_client = AsyncHTTPClient() my_future = Future() fetch_future = http_client.fetch(url) def on_fetch(f): my_future.set_result(f.result().body) fetch_future.add_done_callback(on_fetch) return my_future 任何可用协程做的都可传递到回调(callback)对象周围，但协程提供了一个重要的简化让你以相同的方式组织你的代码。这对于错误处理(error handling)尤其重要，在协程预期的tyr/except块工作，这是难以实现的回调。 在Tornado中，协程(Coroutines)是推荐的编写异步代码的方式。协程使用Python的await或yield关键字来暂停(suspend)和恢复(resume)来代替回调链。 协程几乎与同步(synchronous)代码一样简单，但不带线程(thread)的开销。它们使得并发(concurrency)更简单。 栗子: 1234async def fetch_coroutine(url): http_client = AsyncHTTPClient() response = await http_client.fetch(url) return response.body 原生与装饰的协程Native vs decorated coroutines Python 3.5介绍了async和await关键字。 只要可能，原生协程是推荐的形式。仅需要与旧版本的Python兼容时使用装饰的协程。Tornado文档中一般会使用原生形式。 这两种形式之间的转换一般是简单的: 12345678910111213141516171819202122# Decorated# Normal function declaration# with decorator@gen.coroutinedef a(): # 'yield' all async funcs b = yield c() # 'return' and 'yield' # cannot be mixed in # Python 2, so raise a # special execption raise gen.Return(b)# Native# 'async def' keywordsasync def a(): # 'await' all async funcs b = await c() # return normally return b 两种协程形式的不同: 原生协程通常更快 原生协程可以使用async for和async with语句，这使得一些模式更简单 除非await和yield它们，原生协程不会运行所有。装饰的协程一经调用就运行在后台(background)。请注意，这两种协程使用await或yield都很重要，以便任何异常都有地方可去 装饰的协程有与concurrent.futures包额外的集成，允许直接yielded executor.submit的结果。对于原生协程，使用IOLoop.run_in_executor代替 通过生成一个列表或字典，装饰的协程支持一些速记。在原生协程中使用tornado.gen.multi 装饰的协程可以支持与其它软件包的整合。要在原生协程中访问此功能，使用tornado.gen.convert_yielded 装饰的协程总是返回一个Future对象。原生协程返回一个awaitable对象 如何工作本节介绍装饰的协程的操作。原生协程在概念上相似，但多了几分复杂。因为与Python runtime额外集成。 包含yield的函数是一个生成器(generator)。所有的生成器都是异步的，调用它们时返回一个生成器对象，而不是运行到完成。@gen.coroutine装饰器(decorator)通过yield表达式与生成器进行通信，通过协程调用返回一个Future。 一个协程装饰器的内循环的简单栗子: 1234567891011# Simplified inner loop of tornado.gen.Runnerdef run(self): # send(x) makes the current yield return x # It returns when the next yield is reached future = self.gen.send(self.next) def callback(f): self.next = f.result() self.run() future.add_done_callback(callback) 装饰器从生成器接收一个Future，等待(不会阻塞)选择那些完成的Future，解包Future并将结果发送回生成器的yield表达式。大多数异步代码不直接接触Future类，除了由一个异步函数立即传递Future到yield表达式。 如何调用协程协程在正常方式下不抛出异常：它们抛出的任何异常都将在awaitable对象直到它被yielded。这意味着以正确的方式调用协程是重要的，或者可能有被你忽略的错误。 12345678async def divide(x, y): return x / ydef bad_call(): # This should raise a ZeroDivisionError, but it won't because # the coroutine is called incorrectly. divide(1, 0) 在几乎所有情况下，调用协程的任何函数都必须是一个协程本身，并在调用中使用await和yield关键字。当你重写superclass中定义的方法时，查看文档看协程是否被允许。 123async def good_call(): # await will unwrap the object returned by divide() and raise the exception. await divide(1, 0) 有时，你可能想fire and forget协程，而无需等待其结果。在这种情况下，推荐使用IOLoop.spawn_callback，这使得IOLoop负责调用。如果失败，IOLoop将记录stack trace。 1234# The IOLoop will catch the exception and print a stack trace in the logs.# Note that this doesn't look like a normal call, since we pass the function object to be called by the IOLoop.IOLoop.current().spawn_callback(divide, 1, 0) 函数使用@gen.coroutin在这种方式下建议使用IOLoop.spawn_callback，但它需要函数使用async def。 最后，在程序的顶层，如果IOLoop尚未运行，就可以启动IOLoop，运行协程，然后用IOLoop.run_sync方法停止IOLoop。这经常用来启动一个面向批处理程序的main()函数。 12# run_sync() doesn&apos;t take arguments, so we must wrap the call in lambda.IOLoop.current().run_sync(lambda: divide(1, 0)) 协程模式Coroutine patterns 调用阻塞函数Calling blocking functions 从协程调用阻塞函数最简单的方式是使用IOLoop.run_in_executor，它返回与协程兼容的Future: 12async def call_blocking(): await IOLoop.current().run_in_executor(None, blocking_func, args) Parallelismmulti函数接收列表和字典，其值是Futures，并等待所有并行(parallel)的Futures: 12345678910111213from tornado.gen import multiasync def paraller_fetch(url1, url2): resp1, resp2 = await multi([http_client.fetch(url1), http_client.fetch(url2)])async def paraller_fetch_many(urls): responses = await multi (http_client.fetch(url) for url in urls) # responses is a list of HTTPResponses in the same orderasync def parallel_fetch_dict(urls): responses = await multi(&#123;url: http_client.fetch(url) for url in urls&#125;) # responses is a dict &#123;url: HTTPResponse&#125; 在装饰的协程，可yield列表或字典: 123@gen.coroutinedef aprallel_fetch_decorated(url1, url2): resp1, resp2 = yield [http_client.fetch(url1), http_client.fetch(url2)] Interleaving有时保存Future是有用的而不立即yielding，因此你可以在等待之前启动其它操作。 123456789101112from tornado.gen import convert_yieldedasync def get(self): # convert_yielded() starts the native coroutine in the background. # This is equivalent to asyncio.ensure_future() (both work in Tornado). fetch_future = convert_yielded(self.fetch_next_chunk()) while True: chunk = yield fetch_future if chunk is None: break self.write(chunk) fetch_future = convert_yielded(self.fetch_next_chunk()) yield self.flush() 这是一个比较容易做装饰的协程，因为它们在调用时立即启动: 1234567@gen.coroutinedef get(self): fetch_future = self.fetch_next_chunk() if chunk is None: break self.write(chunk) fetch_future = self.fetch_next_chunk() yiield self.flush() Looping在原生协程，可使用async for。在不同版本的Python中，looping is tricky with coroutines，因为没有办法获得对for或while循环的每次迭代结果的yield。你需要从访问结果分隔循环条件。 123456789import motordb = motor.MotorClient().test@gen.coroutinedef loop_example(collection): cursor = db.collection.find() while (yield cursor.fetch_next): doc = cursor.netx_object() 在后台运行Running in the background PeriodicCallback通常不与协程使用。相反，协程可以包含While True:循环并使用tornado.gen.sleep: 1234567async def minute_loop(): while True: await do_something() await gen.sleep(60)# Coroutines that loop forever are generally started with spawn_callback().IOLoop.current().spawn_callback(minute_loop) 有时，一个更复杂的循环可能是可取的。例如，前一个循环每60+N秒运行，N是do_something的运行时间。要准确每60秒运行，使用上面的interleaving模式: 12345async def minute_loop2() while True: nxt = gen.sleep(60) # Start the clock. await do_something() # Run while the clock is ticking. await nxt # Wait for the timer to run out. QueueQueue example - a concurrent web spider Tornado的tornado.queues模块实现了协程异步 生产者(producer)/消费者(consumer)模式，类似于由Python标准库的queue模块为线程(thread)实现的模式。 yields Queue.get协程暂停直到队列中有项。如果队列设置了最大大小集(yield Queue.put)协程暂停，直到有另一个项。 Queue维护未完成的任务计数，从0开始。put递增计数，task_done递减它。 web-spider栗子，队列开始仅包含base_url。当worker获取它解析的链接和队列放出新的页面，然后调用task_done递减计数。最终，worker取出其url没有过的页面，也没有留在队列中工作。因此，worker调用task_done递减计数器归零。主协程，它等待join，取消暂停和完成。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798import timefrom datatime import timedeltafrom html.parser import HTMLParserfrom ulllib.parse import urljoin, urldefragfrom tornado import gen, httpclient, ioloop, queuesbase_url = 'http://www.tornadoweb.org/en/stable/'concurrency = 10async def get_links_from_url(url): """Download the page at `url` and parse it for links. Returned links have had the fragment after `#` removed, and have been made bsolute so, e.g. the URL 'gen.html#tornado.gen.coroutine' becomes 'http://www.tornadoweb.org/en/stable/gen.html'. """ response = await httpclient.AsyncHTTPClient().fetch(url) print('fetched %s' % url) html = response.body.decode('errors='ignore') return [urljoin(url, remove_fragment(new_url)) for new_url in get_links(html)]def remove_fragment(url): pure_url, frag = urldefrag(url) return pure_urldef get_links(html): class URLSeeker(HTMLParser): def __init__(self): HTMLParser.__init__(self) self.urls = [] sef handle_starttag(self, tag, attrs): href = dict(attrs).get('href') if href and tag == 'a': self.urls.append(href) url_seeker = URLSeeker() url_seeker.feed(html) return url_seeker.urlsasync def main(): q = queues.Queue() start = time.time() fetching, fetched = set(), set() async def fetch_url(currrent_url): if current_url in fetching: return print('fetching %s' % current_url) fetching.add(current_url) urls = await get_links_from_url(current_url) fetched.add(current_url) for new_url in urls: # Only follow links beneath the base URL if new_url.startswith(base_url): await q.put(new_url) async def worker(): async for url in q: if url in None: return try: await fetch_url(url) except Exception as e: print('Exception: %s %s' % (e, url)) finally: q.task_done() await q.put(base_url) # Start workers, then wait for the work queue to be empty. workers = gen.multi([worker() for _ in range(concurrency)]) await q.join(timeout=timedelta(seconds=300)) assert fetching == fetched print('Done in %d seconds, fetched %s URLs.' % ( time.time() - start, len(fetched))) # Signal all the workers to exit. for _ in range(concurrency): await q.put(None) await workersif __name__ == '__main__': io_loop = ioloop.IOLoop.current() io_loop.run_sync(main) Tornado web程序结构Structure of a Tornado web application 一个Tornado web程序通常由一个或多个RequestHandler子类组成，Application对象是哪些路由进入的请求的处理程序(handler)，main()函数来启动server。 一个最小化的hello world栗子: 12345678910111213141516import tornado.ioloopimport tornado.webclass MainHandler(tornado.web.RequestHandler): def get(self): self.write("Hello, world")def make_app(): return tornado.web.Application([ (r"/", MainHandler), ])if __name__ == "__main__": app = make_app() app.listen(8888) tornado.ioloop.IOLoop.current().start() Application对象Application对象是负责全局配置，包括映射请求到处理程序(handler)的路由表。 路由表是URLSpec对象的列表(或元组)，其中每一个包含(至少)一个正则表达式和一个处理类(handler class)。顺序匹配，第一匹配规则被使用。如果正则表达式中包含捕获组，这些组的路径参数将被传递给处理程序(handler)的HTTP方法。如果字典作为URLSpec的第三个参数传递，它提供将初始化参数传递给RequestHandler.initialize。最后，URLSpec可以有一个名称，这将允许它与RequestHandler.reverse_url使用。 栗子: 12345678910111213141516171819# / URL 映射到 MainHandler# /story/后跟数字 映射到 StoryHandler，数字(作为字符串)被传递给StoryHandler.getclass MainHandler(RequestHandler): def get(self): self.write('&lt;a href="%s"&gt; link to story 1&lt;/a&gt;' % self.reverse_url("story", "1"))class StoryHandler(RequestHandler): def initialize(self, db): self.db = db def get(self, story_id): self.write("this is story %s" % story_id)app = Application([ url(r"/", MainHandler), url(r"/story/([0-9]+)", StoryHandler, dict(db=db), name="story")]) Application构造器采用许多关键字参数，可用于定制应用程序的行为和启用可选功能。查看Application.settings获取完整列表。 RequestHandler子类Subclassing RequestHandler 大部分Tornado Web应用程序的工作是RequestHandler子类完成的。主入口点的处理程序子类(handler subclass)是正在处理的HTTP方法(get(), post())的方法命名。例如，每个handler可以定义这些方法中的一种或多种，以处理不同的HTTP动作。如上所述，这些方法将于对应于匹配的路由规则的捕获组参数来调用。 在处理程序内部，调用如RequestHandler.render或RequestHandler.write来产生响应(response)。render()通过名称加载一个模板，并与给定的参数来渲染它。write()被用于非基于模板(non-template-based)输出。它接受字符串，字节和字典(字典被编码为json)。 ReqestHandler中的许多方法都设计在子类中重写(overridden)，并在整个application中使用。这是常见的定义BaseHandler类，覆盖方法如write_error, get_current_user，并为你所有指定的handler继承BaseHandler而不是RequestHandler。 处理请求输入Handling request input request handler可以访问表示与self.quest获取当前请求的对象。查看HTTPServerRequest类来获取完整的列表。 通过HTML表单中使用的格式请求的数据将为你解析，并在如get_query_argument和get_body_argument方法中可用。 12345678910class MyFormHandler(tornado.web.RequestHandler): def get(self): self.write('&lt;html&gt;&lt;body&gt;&lt;form action="/myform" method="POST"&gt;' '&lt;input type="text" name="message"&gt;' '&lt;input type="submit" value="Submit"&gt;' '&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;') def post(self): self.set_header("Conten-Type", "text/plain") self.write("You wrote" + self.get_body_argument) 由于HTML表单的编码是模糊的，以元素中的一个参数是否为单一值(single value)或一个列表，RequestHandler有独特的方法，以允许application表明它是否期望一个列表。对于列表，使用get_query_arguments和get_body_arguments来代替它们的singular counterparts。 通过表单上传的文件在self.request.files可用，它映射名称(html input type=&quot;file&quot;元素)到一个文件列表。每个文件是{&quot;filename&quot;:..., &quot;content_type&quot;:..., &quot;body&quot;:...}格式的字典。files对象仅表示文件是否以一种form wrapper上传(如multipart/form-data 内容类型)。如果不使用这种格式，原始上传数据在self.request.body可用。默认情况下上传的文件在内存中完全缓冲(fully buffered)。如果你要处理的文件太大，但想在内存中舒适保存，可参考stream_request_body类装饰器。 由于HTML格式编码的怪癖，Tornado并不试图统一参数和其它输入类型的形式。特别是，我们不解析JSON请求主体。Applicaton希望使用JSON而不是form-encoding可以覆盖prepare来解析它们的请求: 12345def prepare(self): if self.request.headers.get("Content-Type", "").startswith('"application/json"'): self.json_args = json.loads(self.request.body) else: self.json_args = None 重写RequestHandler方法Overriding RequestHandler methods 除了get(), post()…，在RequestHandler某些其它方法被设计成在必要时由子类重写。在每次请求，调用以下顺序进行: 在每个请求上，一个新的RequestHandler对象被创建 initialize()被调用，从Application配置的初始化参数。初始化通常应该只保存传入成员变量的参数，不产生任何输出或调用(如send_error) prepare()被调用。这是最有用的，由所有handler subclass共享的基类，作为prepare被无论哪个HTTP方法所调用。prepare可产生输出，如果它调用finish或redirect，这里处理停止 当其中一个HTTP方法被调用时: get(), post(), put()。如果URL正则中包含捕获组(capturing group)，它们将被作为参数传递给该方法 当请求完成后，调用on_finish()。对于大多数handler这个在get()返回后立即调用。在调用finish()之后使用tornado.web.asynchronous装饰器来装饰handler 在RequestHandler文档中，所有的方法都设计来可重写。一些最常用的重写方法: writre_error: 输出HTML错误页面 on_connection_close: 当客户端断开连接时调用。应用可选择检测此情况并停止进一步的处理。注意，不能保证一个关闭的连接能够被及时发现 get_current_user get_user_locale: 返回当前用户的Locale对象 set_default_headers: 用于在响应中设置其它header 错误处理Error Handling 如果handler抛出一个异常，Tornado将调用RequestHandler.write_error来生成一个错误页。tornado.web.HTTPError可用来生成一个特定状态码。所有其它异常返回500状态。 debug模式下的默认错误页面包含一个stack trace和对错误的一行说明。要生成自定义错误页，重写RequestHandler.write_error。可通过如write和render方法来产生输出。如果错误是由异常导致的，一个exc_info将作为一个关键字参数传递。 也可通过调用set_status产生与常规处理方法write_error生成的错误页面，编写一个响应，并返回。特殊异常tornado.web.Finish可抛出终止处理而不调用write_error在简单返回不方便时。 对于404错误，使用default_handler_class应用设置(Application setting)。此处理程序应重写prepare，而不是像get()方法更具体的方法，所以它与任何HTTP方法工作。如上所述应该产生错误页面: 要么抛出HTTPError(404)和重写write_error，或调用self.set_status(404)和直接在prepare()中产生响应。 重定向Redirection Tornado中有两种主要的方式重定向请求: RequestHandler.redirect和RedirectHandler。 可在RequestHandler方法中使用self.redirect()来重定向到别处。这有一个permanent的可选参数，可用它来表示永久的重定向。permanent的默认值为False，其产生一个302 Found HTTP响应码，适合像POST请求成功之后使用。如果permanent为true， 则使用301 Moved Permanently HTTP响应码，其用于重定向到一个规范友好的URL。 RedirectHandler让你直接在Application路由表中配置重定向，栗子: 1234app = tornado.web.Application([ url(r"/app", tornado.web.RedirectHandler, dict(url="http://xxx.com")),]) RedirectHandler同样支持正则表达式取代。栗子: 12345app = tornado.web.Application([ url(r"/photos/(.*)", MyPhotoHandler), url(r"/pictures/(.*)", tornado.web.RedirectHandler, dict(url=r"/photo/&#123;0&#125;)),]) 不像RequestHandler.redirect，RedirectHandler默认使用永久重定向。这因为路由表在运行时不发生变化，被认定为时永久性的，而在处理中发现重定向可能改变其它逻辑的结果。要使用RedirectHandler发送一个临时的重定向，将permanent=False添加到RedirectHandler初始化参数。 异步处理程序Asynchronous handlers 某些处理方法(如prepare()和HTTP的get(), post()…)可能会被重写为协程，使处理程序异步。 Tornado同样支持使用tornado.web.asynchronous装饰器异步处理的回调风格，但这种风格已经过时，将在Tornado6中一处。新的应用应该使用协程来代替它。 使用协程的一个简单处理程序的栗子: 1234567class MainHandler(tornado.web.RequestHandler): async def get(self): http = tornado.httpclient.AsyncHTTPClient() response = await http.fetch("http://friendfeed-api.com/v2/feed/bret") json = tornado.escape.json_decode(response.body) self.write("Fetched " + str(len(json["entries"])) + " entries " "from the FriendFeed API") 更多高级的异步的栗子，查考文档。 模板和UITemplates and UI Tornado包含了一个简单、快速、灵活的模板语言。想想Django和Jinja2。 Tornado还可与任何其它Python模板语言使用，虽然没有规定集成这些系统到RequestHandler.render里。简单地渲染模板为字符串，并将其传递到RequestHandler.write。 配置模板Configuring templates 默认情况下，Tornado在引用它的.py文件中的同一目录下查找模板文件。要把模板文件放在不同的目录中，使用template_path应用设置。如果你有不同的模板路径用于不同的处理程序，请重写RequestHandler.get_template_path。 要从非文件系统位置载入模板，子类tornado.template.BaseLoader将在模板并传递一个实例作为template_loader应用设置。 默认缓存编译的模板。要关闭这个缓存和重新加载模板，使用compiled_template_cache=False或debug=True应用设置。 模板语法Template syntax Tornado模板仅仅是HTML(或其它基于文本的格式)与Python控制序列和嵌入在标记内的表达式，想想Django模板和Jinja2。 表达式可以是任意Python表达式，包括函数调用。模板代码在包括以下对象和函数的命名空间执行(请注意，以下列表适用于使用RequestHandler.render和render_string渲染模板。如果你直接使用在RequestHandler外的tornado.template模块，那么许多内容是不存在的。) escape: tornado.escape.xhtml_escape的别名 xhtml_escape: tornado.escape.xhtml_escape的别名 url_escape: tornado.escape.url_escape的别名 json_encode: tornado.escape.json_encode的别名 squeeze: tornado.escape.squeeze的别名 linkify: tornado.escape.linkify的别名 datetime: Python的datetime模块 handler: 目前的RequestHandler对象 request: handler.request的别名 current_user: handler.current_user的别名 locale: handler.locale的别名 _: handler.locale.translate的别名 static_url: handler.static_url的别名 xsrf_form_html: handler.xsrf_form_html的别名 reverse_url: Application.reverse_url的别名 所有条目从应用的ui_methods和ui_modules 任何关键字参数传递给render或render_string 当你在构建一个真正的应用时，你会想要使用Tornado模板的所用功能，尤其是模板继承。阅读tornado.template部分了解详细信息。 引擎盖下，Tornado模板直接转换为Python。模板中的表达式是逐字复制到Python函数中。我们不设法防止模板语言的任何东西。最后，如果你写的模板表达式内随机的东西，当你执行模板可能会获得随机的Python错误。 所有的模板输出默认被转义(escape)，使用tornado.escape.xhtml_escape函数。这个行为可通过全局地传递autoescape=None给应用或tornado.template.Loader构造器，对于模板文件指示autoescape None%&#125;```或通过```&#123;% raw ... %&#125;```代替```&#123;&#123; ... &#125;&#125;```。此外，在每一个可选择转义函数名的地方，可用`None`代替。1234567891011121314151617181920212223虽然Tornado的自动转义为避免XSS漏洞有帮助，但它并不是在所有情况下都有效。例如在JS或CSS表达式的某些地方，可能需要额外的转义。此外，必须小心地使用HTML双引号`&quot;`和`xhtml_escape`，可能包含不受信任的内容，或者必须为属性使用单独地转义函数。&lt;br&gt;&lt;br&gt;### UI模块UI modulesTornado支持UI模块，可以很容易地在你的应用中支持标准的、可重用的UI组件。UI模块都喜欢特殊的函数调用来渲染网页和组件，它们可以包装自己的CSS和JS。例如，如果要实现一个博客，你想拥有的博客条目同时出现在博客主页和每个博客页面上，你可以编写一个`Entry`模块在两个页面上渲染它们。首先，为你的UI模块创建一个Python模块:```py# uimodules.pyclass Entry(tonado.web.UIModule): def render(self, entry, show_commnets=False): return self.render_string(&quot;module-entry.html, entry=entry, show_comments=show_comments&quot;) 在应用中设置ui_modules告诉Tornado使用uimodules.py: 12345678910111213141516171819202122from . import uimodulesclass HomeHandler(tornado.web.RequestHandler): def get(self): entries = self.db.query("SELECT * FROM entries ORDER BY date DESC") self.render("home.html", entries=entries)class EntryHander(tornado.web.ReqestHandler): def get(self, entry_id): entry = self.db.get("SELECT * FROM entries WHERE id = %s, entry_id") if not entry: raise tornado.web.HTTPError(404) self.render("entry.html", entry=entry)settings = &#123; "ui_modules": uimodules,&#125;application = tornado.web.Application([ (r"/", HomeHandler), (r"/entry/([0-9])", EntryHandler),], **settings) 在模板内，你可以使用module %&#125;```调用模块，例如在`home.html`中调用`Entry`模块:12345```jinja2&#123;% for entry in entries%&#125;&#123;% module Entry(entry) %&#125;&#123;% end %&#125; entry.html中: 1&#123;% module Entry(entry, show_comments=True) %&#125; 模块可以通过重写embedded_css, embedded_javascript, javascript_files或css_files方法来包含自定义的CSS和JS函数: 123456class Entry(tornado.web.UIModule): def embedded_css(self): return ".entry &#123; margin-bottom: 1em; &#125;" def render(self, entry, show_comments=False): return self.render_string("module-entry", show_comments=show_comments) 模块CSS和JS将包含一次，不管一个页面中这个模块使用了多少次。CSS总是包含在页面的&lt;head&gt;，JS总是包含在&lt;/body&gt;标记之前在页面的页面结束标记。 当不需要附加的Python代码，模板文件本身可以用作一个模块。例如，前面的栗子可以改写在module-entry.html模块: 12&#123;&#123; set_resources(embedded_css=&quot;.entry &#123; margin-bottom: 1em; &#125;&quot;) &#125;&#125;&lt;!-- more template html... --&gt; 经修订的模板模块将与下栗被调用: 1&#123;% module Template(&quot;module-entry.html&quot;, show_comments=True) %&#125; 该set_resources功能尽在通过module Template(...) %&#125;```123456789101112131415161718192021222324252627282930313233343536373839调用模板。不同于```&#123;% include %&#125;```，模板模块具有从它们的包含模板的独特命名空间——它们只能看到全局模板命名空间和自己的关键字参数。&lt;br&gt;&lt;br&gt;&lt;br&gt;## 认证和安全Authentication and security&lt;br&gt;### Cookie和secure cookies可以使用`set_cookie`方法在用户浏览器中设置cookie:```pythonclass MainHandler(tornado.web.ReqestHandler): def get(self): if not self.get_cookie(&quot;mycookie&quot;): self.set_cookie(&quot;mycookie&quot;, &quot;myvalue&quot;) self.write(&quot;Your cookie was not set yet!&quot;) else: self.write(&quot;Your cookie was set!&quot;) cookie是不安全的，可以很容易地被客户修改。如果你需要设置cookie，请确定当前登录的用户，你需要签属(signed)你的cookie来防止伪造。Tornado支持使用set_secure_cookie和get_secure_cookie方法来签属(sign)cookie。要使用这些方法，你需要在创建应用时指定一个名为cookie_secret的密钥键。你可以在应用中设置关键字参数来传递给应用。 123application = tornado.web.Application([ (r"/", MainHandler),], cookie_secret="__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__") 签属的cookie含有时间戳和HMAC签名的cookie编码值。如果cookie是旧的，或者签名不匹配，get_secure_cookie将会返回None就像没有设置cookie那样。上面栗子的安全版本: 1234567class MainHandler(tornado.web.RequestHandler): def get(self): if not self.get_secure_cookie("mycookie"): self.set_secure_cookie("mycookie", "myvalue") self.write("Your cookie was not set yet!") else: self.write("Your cookie was set!") Tornado的secure cookie保证完整性，但不保密。也就是说，cookie不能被修改，但可以被用户看到。cookie_secret是一个对称密钥并且必须保密——得到这个值的人都可以制作自己的签名的cookie。 默认情况下，Tornado的cookie在30天后过期。可对set_secure_cookie使用expires_days参数和max_age_days来修改。 Tornado同样支持多个签名密钥来启用签名轮询。cookie_secret必须与整数密钥版本作为关键字和相应的secret作为字典的值。将当前使用的签名密钥必须在应用中设置为key_version，但在字典的所有其它键都允许cookie签名认证，如果设置在cookie中的是正确的密钥版本。要更新cookie，可通过查询get_secure_cookie_key_version获取当前的签名密钥版本。 用户认证User authentication 当前已认证的用户在每个request handler中可使用self.current_user，在每个模板中为current_user。默认情况下，current_user为None。 要在应用中执行用户身份认证，需要在request handler中重写get_current_user以基于cookie的值确定当前用户。下面是一个让用户登录到应用，简单地指定一个昵称，然后将其保存到cookie中: 123456789101112131415161718192021222324252627class BaseHandler(tornado.web.RequestHandler): def get_current_user(self): return self.get_secure_cookie("user")class MainHandler(BaseHandler): def get(self): if not self.current_user: self.redirect("/login") return name = tornado.escape.xhtml_escape(self.current_user) self.write("Hello, " + name)class LoginHandler(BaseHandler): def get(self): self.write('&lt;html&gt;&lt;body&gt;&lt;form action="/login" method="post"&gt;' 'Name: &lt;input type="text" name="name"&gt;' '&lt;input type="submit" value="Sign in"&gt;' '&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;') def post(self): self.set_secure_cookie("user", self.get_argument("name")) self.redirect("/")application = tornado.web.Application([ (r"/", MainHandler), (r"/login", LoginHandler),], cookie_secret="__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__") 你可以要求用户在使用tornado.web.authenticated Python装饰器处登录。如果请求的方法带有此装饰器，并且用户没有登录，则他们将被重定向到login_url或其它设置。重写上面的栗子: 123456789101112131415class MainHandler(BaseHandler): @tornado.web.authenticated def get(self): name = tornado.escaple.xhtml_escape(self.current_user) self.write("Hello, " + name)settings = &#123; "cookie_secret": "__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__", "login_url":"/login",&#125;application = tornado.web.Application([ (r"/", MainHandler), (r"/login", LoginHandler),], **settings) 如果你使用authenticate装饰器装饰一个post()方法，并且用户没有登录，则Server会返回403响应。@authenticated装饰器简单来说就是if not self.current_user: self.redirect()的快捷键，并且可能不适用于非基于浏览器的登录方案。 第三方认证Third party authentication tornado.auth模块实现了许多受欢迎的网站上提供的认证(authentication)和授权(authorization)协议，包括Google, FaceBook, Twitter… 下面是一个使用谷歌认证的示例，存储Google credential到cookie以便后续访问使用: 1234567891011121314class GoogleOAuth2LoginHandler(tornado.web.RequestHandler, tornado.auth.GoogleOAuth2Mixin): async def get(self): if self.get_argument('code', False): user = await self.get_authenticated_user( redirect_uri="http://your.site.com/auth/google", code=self.get_argument('code')) # Save the user with e.g. set_secure_cookie else: await self.authorize_redirect( redirect_uri='http://your.site.com/auth/google', client_id=self.setting['google_oauth']['key'], scope=['profile', 'email'], response_type='code', extra_params=&#123;'approval_prompt': 'auto'&#125;) 更多详细内容，请参考tornado.auth文档。 跨站请求伪造保护Cross-site request forgery protection 跨站请求伪造(Cross-site request forgery, XSRF)，是Web应用的一个常见的问题。 防止XSRF普遍接受的解决方案是每个用户的cookie使用不可预测的值，此值包含网站上每个表单提交的额外参数。如果表单提交的cookie和值不匹配，则请求可能是伪造的。 Tornado内置了XSRF保护。要在你的站点中包含它，启用应用scrf_cookies设置: 123456789settings = &#123; "cookie_secret": "__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__", "login_url": "/login", "xsrf_cookies": True&#125;application = tornado.web.Application([ (r"/", MainHandler), (r"/login", LoginHandler),], **settings) 如果设置了xsrf_cookies，Tornado Web Application将为所有用户设置_xsrf cookie，并拒绝没有包含正确的_xsrf值的所有POST, PUT, DELETE请求。如果你打开了此设置，你需要一切形式的POST提交中包含此字段。你可以使用特殊的UIModule vsrf_form_html()，在所有模板中可用: 12345&lt;form action=&quot;/new_message&quot; method=&quot;post&quot;&gt; &#123;% module xsrf_form_html() %&#125; &lt;input type=&quot;text&quot; name=&quot;message&quot;/&gt; &lt;input type=&quot;submit&quot; value=&quot;Post&quot;/&gt;&lt;/form&gt; 如果你提交AJAX POST请求，你还需要构造JS来包括每个请求的_xsfr值。所有包含_xsrf请求AJAX POST的JQuery函数: 123456789101112function getCookie(name) &#123; var r = document.cookie.match(&quot;\\b&quot; + name + &quot;=([^;]*)\\b&quot;); return r ? r[1] : undefined;&#125;jQuery.postJSON = function(url, args, callback) &#123; args._xsrf = getCookie(&quot;_xsrf&quot;); $.ajax(&#123;url: url, data: $.param(args), dataType: &quot;text&quot;, type: &quot;POST&quot;, success: function(response) &#123; callback(eval(&quot;(&quot; + response + &quot;)&quot;)); &#125;&#125;);&#125;; 对于PUT和DELETE请求，XSRF token可能会通过HTTP X-XSRFToken Header进行传递。使用xsrf_form_html时，XSRF cookie被正常设置，但是在不使用任何形式的纯JS应用中，可能需要手动访问self.xsrf_token。 如果你需要在每个handler中自定义XSRF行为，你可以重写RequestHandler.check_xsrf_cookie()。例如，如果你有一个不使用cookie的API，你可能希望通过使check_xsrf_cookie什么也不做来禁用XSRF保护。然而，如果你支持基于cookie和非基于cookie的认证，只要求当前请求使用cookie认证XSRF保护是重要的。 DNS重新绑定DNS Rebinding DNS重新绑定是一种攻击，可以绕过同源策略，并允许外部站点访问内部网络的资源。使用TLS的应用不容易受到这种攻击。没有使用TLS的应用依赖网络层的访问控制，应警惕通过验证的HTTP Header的Host被DNS重新绑定。This means passing a restrictive hostname pattern to either a HostMatches router or the first argument of Application.add_handlers: 12345678910111213# BAD: uses a default host pattern of r'.*'app = Application([('/foo', FooHandler)])# GOOD: only matches localhost or its ip address.app = Application()app.add_handlers(r'(localhost|127\.0\.0\.1)', [('/foo', FooHandler)])# GOOD: same as previous example using tornado.routing.app = Application([ (HostMatches(r'(localhost|127\.0\.0\.1)'), [('/foo', FooHandler)]), ]) 此外，应用的default_host参数，和DefaultHostMatches路由器不能在应用中使用，这可能受到DNS重新绑定，因为它有一个通配符主模式类似的效果。 运行和部署Running and deploying 自从Tornado提供了自己的HTTPServer，运行和部署它便和其它Python Web框架有点不同。不同于配置WSGI，你只需要写一个main()函数来启动Server: 1234567def main(): app = make_app() app.listen(8888) IOLoop.current().start()if __name__ == '__main__': main() 请注意，这可能需要增加每个进程可打开的文件数(open files)，可能修改ulimit限制。 进程和端口Processes and ports 由于Python的GIL(Global Interpreter Lock)，有必要运行多个Python进程，以充分利用多CPU机器。通常，最好为每个CPU运行一个进程。 Tornado包含了一个内置的多进程模式，一次可启动多个进程。这需要稍微修改以下启动方式: 123456def main(): app = make_app() server = tornado.httpserver.HTTPServer(app) server.bind(8888) server.start(0) # forks one process per cpu IOLoop.current().start() 这是启动多个进程，并让它们使用相同的端口最简单的方法，虽然它有一定的局限性。首先，每个子进程都会有自己的IOLoop，因此在fork前没有事物触及IOLoop示例是很重要的。第二，在这个模型中很难做到零停机更新(zero-downtime updates)。最后，由于所有的进程共享同一端口更难以单独监控。 对于更复杂的部署，建议单独启动进程，并监听不同的端口。supervisord是一个好办法。当每个进程使用了不同的端口，通常需要一个外部的负载均衡器(如HAProxy, Nginx)以单独的访问地址提供给访问者。 运行在负载均衡器后Running behind a load balancer 当运行在如Nginx这样的负载均衡器之后，建议传递xheaders=True给HTTPServer构造器。这将告诉Tornado使用X-Real-IP用户Header，来获取用户IP地址，而不是负载均衡器的IP地址。 一个栗子: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970user nginx;worker_processes 1;error_log /var/log/nginx/error.log;pid /var/run/nginx.pid;events &#123; worker_connections 1024; use epoll;&#125;http &#123; # Enumerate all the Tornado servers here upstream frontends &#123; server 127.0.0.1:8000; server 127.0.0.1:8001; server 127.0.0.1:8002; server 127.0.0.1:8003; &#125; include /etc/nginx/mime.types; default_type application/octet-stream; access_log /var/log/nginx/access.log; keepalive_timeout 65; proxy_read_timeout 200; sendfile on; tcp_nopush on; tcp_nodelay on; gzip on; gzip_min_length 1000; gzip_proxied any; gzip_types text/plain text/html text/css text/xml application/x-javascript application/xml application/atom+xml text/javascript; # Only retry if there was a communication error, not a timeout # on the Tornado server (to avoid propagating &quot;queries of death&quot; # to all frontends) proxy_next_upstream error; server &#123; listen 80; # Allow file uploads client_max_body_size 50M; location ^~ /static/ &#123; root /var/www; if ($query_string) &#123; expires max; &#125; &#125; location = /favicon.ico &#123; rewrite (.*) /static/favicon.ico; &#125; location = /robots.txt &#123; rewrite (.*) /static/robots.txt; &#125; location / &#123; proxy_pass_header Server; proxy_set_header Host $http_host; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_pass http://frontends; &#125; &#125;&#125; 静态文件和侵略性的文件缓存Static files and aggressive file caching 你可以通过在应用中指定static_path来设置Tornaodo提供静态文件: 12345678910111213settings = &#123; "static_path": os.path.join(os.path.dirname(__file__), "static"), "cookie_secret": "__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__", "login_url": "/login", "xsrf_cookies": True,&#125;application = tornado.web.Application([ (r"/", MainHandler), (r"/login", LoginHandler), (r"/(apple-touch-icon\.png)", tornado.web.StaticFileHandler, dict(path=settings['static_path'])),], **settings) 此设置会自动设置以/static/的所有请求到静态目录，如http://localhost:8888/static/foo.png将从指定的静态目录提供静态文件。同样还有/robots.txt和/favicon.ico，即便它们并未以/static/为前缀。 在上面的设置，我们已明确的配置Tornado从StaticFileHandler提供apple-touch-icon.png。 要提高性能，通常是浏览器缓存静态资源，因此浏览器将不会发送不必要的If-Modified-Since或Etag请求，这可能会阻止页面的渲染。Tornado支持这一开箱即用的静态内容版本。 要使用此功能，在你的模板中使用static_url方法，而不是在你的HTML中直接输入静态文件: 12345678&lt;html&gt; &lt;head&gt; &lt;title&gt;FriendFeed - &#123;&#123; _("Home") &#125;&#125;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div&gt;&lt;img src="&#123;&#123; static_url("images/logo.png") &#125;&#125;"/&gt;&lt;/div&gt; &lt;/body&gt; &lt;/html&gt; static_url()函数会将相对路径转换为如/static/images/logo.png?v=aae54这样的URI。v参数是logo.png的哈希内容，它的存在使得Tornado Server发送cache header到用户浏览器，这将使浏览器无限期缓存内容。 由于v参数使基于文件的内容，如果你更新文件并重启Server，它将发送一个新的v值，因此用户浏览器会自动获取新的文件。如果文件的内容没有改变，浏览器将继续使用本地缓存的副本而没有检查Server上的更新，显著提供渲染性能。 在生产环境，你可能希望从像Nginx这样更优化的静态文件服务器提供静态文件。你可以配置几乎所有的Web Server识别由static_url使用的标签，并设置相应的cache header。 栗子: 123456location /static/ &#123; root /var/friendfeed/static; if ($query_string) &#123; expires max; &#125; &#125; Debug模式和自动重载Debug mode and automatic reloading 如果将debug=True传递给Application构造器，应用将运行在debug/development模式下。在此模式下，一些便于开发调试的功能将被启用: autoreload=True：应用会监视更改的源文件并在发生变化时自动重载。这样减少了在开发过程中手动重启服务。然后，某些错误可能导致无法启动。 compiled_template_cache=False：模板不会被缓存。 static_hash_cache=False：静态文件哈希值(由static_url函数使用)将不会被缓存。 serve_traceback=True：当RequestHandler中的异常没有被捕获，将会生成一个包含stack trace的错误页面。 自动重载模式不兼容HTTPserver的多进程模式。如果你正在使用自动重载模式，你不要给HTTPServer.start一个或多于一个参数(或调用tornado.process.fork_processes)。 调式模式的自动重载功能是可用作为tornado.autoreload独立(standalone)模块。这两个可以组合使用，以提供对语法错误的额外稳健：在应用中设置autoreload=True来在运行时检测改变，并使用python -m tornado.autoreload myserver.py启动来在启动时捕获任意语法错误或其它错误。 重载将失去任何Python解释器命令行参数(如-u)，因为它使用sys.executable和sys.argv来重新执行Python。此外，修改这些变量将导致重载行为不正确。 WSGITornado通常是为了独立运行，而不用WSGI容器。然而，在一些环境中（如Google App Engine），只允许WSGI，应用程序无法运行自己的Server。在这种情况下，Tornado支持操作的限制模式，不支持异步操作，但允许在只有WSGI环境的Tornado功能的子集。未在WSIG模式允许的功能包括协程、@asynchronous装饰器，AsyncHTTPclient、auth模块和WebSockets。 你可以使用tornado.wsgi.WSGIAdapter将一个Tornado Application转换为WSGI application。 栗子: 123456789101112import tornado.webimport tornado.wsgiclass MainHandler(tornado.web.RequestHandler): def get(self): self.write('Hello, world')tornado_app = tornado.web.Application([ (r"/", MainHandler),])application = tornado.wsgi.WSGIAdapter(tornado_app)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Web</tag>
        <tag>Tornado</tag>
        <tag>DevOps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML CSS]]></title>
    <url>%2F2019%2F10%2F11%2FHTMLCSS%2F</url>
    <content type="text"><![CDATA[参考: 《Head First HTML and CSS》 w3cSchool: https://www.w3school.com.cn/ 认识HTMLHTML(Hyper Text Markup Language)超文本标记语言，创建结构。HTML会告诉浏览器文档的结构，标题放在哪、段落放在哪、哪些文本需要强调… CSS(Cascading Style Sheets)层叠样式表，创建样式。 与试图使用一种语言兼顾这两方面的工作相比，实际上学习两种语言让它们各司其职反而更容易。 首部(head): 包含了web页面的有关信息 页面元素(body): 包含web页面的所有内容和结构 元素(element): 开始标记+内容+结束标记（如element=&lt;&gt;+content+&lt;/&gt;），某些例外 属性(attribute): 如type=&quot;text/css&quot;，能提供元素的一些额外信息 &lt;Style&gt;元素放在HTML首部 123456789101112131415161718192021222324&lt;!--index.html--&gt;&lt;!DOCTYPE html&gt;&lt;html lang='en'&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Starbuzz Coffee&lt;/title&gt; &lt;style type="text/css"&gt; body &#123; background-color:skyblue; margin-left: 20%; margin-right: 20%; border: 2px dotted black; padding: 10px 10px 10px 10px; font-family: sans-serif; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Starbuzz Coffee Beverages&lt;/h1&gt; &lt;h2&gt;House Blend&lt;/h2&gt; &lt;p&gt;ABC&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 深入了解超文本想从一个页面链接到另一个页面，使用&lt;a&gt;元素。&lt;a&gt;元素的href属性制订了链接的目标文件。 文字和图像都可以用作链接的标签。单击一个链接时，浏览器会加载href属性中指定的Web页面。 可以链接到相同文件夹中的文件，也可以链接到其它文件夹的文件。 请注意相对路径和绝对路径。 为网站选择的文件名和文件夹不要有空格。 1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;AAA&lt;/title&gt; &lt;style type="text/css"&gt; body &#123; margin-left:20%; margin-right:20; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;h1 id="top"&gt;Welcome&lt;/h1&gt; &lt;img src="images/aaa.jpg"&gt; &lt;a href="aaa/aaa.html" title="aaa" target="_blank"&gt; &lt;h2&gt;aaa&lt;/h2&gt; &lt;/a&gt; &lt;p&gt; abcd &lt;em&gt;aaa&lt;/em&gt; &lt;/p&gt; &lt;a href='#top'&gt;&lt;h3&gt;返回TOP&lt;/h3&gt;&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 构建模块开始输入内容之前要规划好Web页面的结构。首先画出一个草图，然后创建一个略图，最后再写出HTML。规划页面时，首先设计大的块元素，然后用内联(inline)元素完善。 记住，要尽可能使用元素来告诉浏览器你的内容的含义。一定要使用与内容含义最接近的元素。例如，如果需要一个列表，就不要使用段落元素。 &lt;p&gt;, &lt;blockquote&gt;, &lt;ol&gt;, &lt;ul&gt;, &lt;li&gt;都是块元素。它们单独显示，与内容前后分别有一个换行(默认的)。 &lt;q&gt;, &lt;em&gt;是内联元素。这些元素中的内容与其包含元素的其余内容放在一起。 需要插入自己的换行时，可以使用&lt;br&gt;元素，它是一个void元素。void元素没有内容，只有一个标记组成。 空元素没有内容。不过它有开始和结束标记。 嵌套元素是指完全包含在另一个元素中的元素。如果元素能正确地嵌套，所有标记都能正确匹配。 要结合两个元素建立一个HTML列表，可以使用&lt;ol&gt;和&lt;li&gt;，也可以使用&lt;ul&gt;和&lt;li&gt;。 要对HTML内容中的特殊字符使用字符实体(character entity)，如&lt;符号使用&amp;lt。 元素大杂烩(elements) 1234567891011121314&lt;a&gt; # 建立链接&lt;p&gt; # 段落&lt;q&gt; # 短引用&lt;blockquote&gt; # 长引用&lt;code&gt; # 显示代码&lt;em&gt; # 斜体&lt;time&gt; # 告诉浏览器此内容是时间&lt;ul&gt; # 无序列表&lt;ol&gt; # 有序列表&lt;li&gt; # 列表&lt;strong&gt; # 强调文本&lt;pre&gt; # 浏览器按照你输入的格式显示文本&lt;br&gt; # 换行&lt;img&gt; # 图像 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;333&lt;/title&gt; &lt;style type="text/css"&gt; body &#123; margin-left: 20%; margin-right: 20%; &#125; q, blockquote, ol, ul &#123; font-size: x-large; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;333&lt;/h1&gt; &lt;p&gt;333&lt;/p&gt; &lt;h2&gt;333&lt;/h2&gt; &lt;img src="../images/333.png"&gt; &lt;p&gt; 333333333333: &lt;ol&gt; &lt;li&gt;3&lt;/li&gt; &lt;li&gt;33&lt;/li&gt; &lt;li&gt;333&lt;/li&gt; &lt;/ol&gt; &lt;p&gt; 3333 &lt;blockquote&gt; 3&lt;br&gt; 33&lt;br&gt; 333&lt;br&gt; &lt;/blockquote&gt; 333 &lt;/p&gt; &lt;h2&gt;333&lt;/h2&gt; &lt;p&gt; 333: &lt;ul&gt; &lt;li&gt;3&lt;/li&gt; &lt;li&gt;33&lt;/li&gt; &lt;li&gt;333&lt;/li&gt; &lt;ul&gt; 333 &lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 连接起来要把网站发布到Web上，通常最好的方法就是找一家公司来托管你的Web页面。域名(domain)是一个唯一的名字，如aaa.com，用来唯一标识网站。托管公司可能会为你的域创建一个或多个Web服务器，通常为www。 URL是统一资源定位符或Web地址，可用来标识Web上的任何资源。定性的URL是由一个协议、一个网站名和资源的一个绝对路径组成。 HTTP是一个请求和响应协议，用来在Web服务器和浏览器之间传送Web页面。浏览器使用file:///协议从你的计算机读取页面。 index.html和default.html都是默认页面，如果指定一个目录而没有指定文件名，则Web服务器会查找一个默认页面返回到浏览器。 &lt;a&gt;元素的href属性中可以使用相对路径或URL来链接其它web页面。对于你的网站中的其它页面，最好使用相对路径，对外部链接才使用URL。可以用id属性在页面中创建一个目标（如&lt;h1 id=&quot;top&quot;&gt;），使用#后面加一个目标id（如&lt;a href=&quot;#top&quot;&gt;），可以链接到页面中的那个位置。为了便于访问，可以在&lt;a&gt;元素中使用title属性提供链接的一个描述。使用target属性在另一个窗口中打开链接。对于不同设备和浏览器，target属性可能会有问题。 1234567891011121314151617181920212223&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;444&lt;/title&gt; &lt;style type="text/css"&gt; body &#123; margin-left: 20%; margin-right: 20%; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;h1 id="top"&gt;444&lt;/h1&gt; &lt;img src="images/444.jpg" width="800" height="400"&gt; &lt;a href="about/444.html" title="444" taget="_blank"&gt; &lt;h2&gt;4444&lt;/h2&gt; &lt;/a&gt; &lt;p&gt; 4 &lt;em&gt;44&lt;/em&gt; 444 &lt;/p&gt; &lt;a href="#top"&gt; &lt;h3&gt;Top&lt;/h3&gt;&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 为页面添加图像使用&lt;img&gt;元素在web页面中添加图像。&lt;img&gt;元素是一个内联元素，这说明浏览器不会在图像前后插入一个换行。浏览器对&lt;img&gt;元素的处理与其它HTML元素稍有不同。读取HTML页面之后，浏览器会从Web服务器获取各个图像并显示。如果web页面上有多个大图像，则可以通过创建图像的缩略图使web页面更可用，下载也更快。缩略图是一些小图像（大图像的缩小版本），用户单击这些缩略图时可以看到原来的大图像。 要利用src属性指定图像文件的位置。可以在src属性中使用相对路径包含自己网站中的图像，或者可使用URL包含其它网站的图像。 alt属性是对图像的一个有意义的描述，在一些浏览器中，如果无法找到图像，就会显示这个描述。 对于浏览器来说，太大的图像会使web页面很难用，而且下载和显示都很慢。图像可以用作指向其它web页面的链接。 1234567JPEG、PNG和GIF是web浏览器广泛支持的3中图像格式JPEG格式最适合保存照片和其他复杂图像GIF或PNG格式最适合保存Logo和其他包含单色、线条或文本的简单图形JPEG图像可以按不同的质量(quality）压缩，所以可以很好地权衡图像质量和文件大小，来满足你的需要GIF和PNG图像格式允许建立一个有透明背景的图像。如果把一个有透明背景的图像放在一个web页面中，图像后面的东西（如页面背景色）就是透过图像的透明部分显示出来GIF和PNG是无损格式，这说明相比JPEG文件，这些格式的文件往往更大PNG可以提供比GIF更好的透明度控制，而且不像GIF只支持256中颜色，PNG可以支持更多颜色) 12345678910111213141516171819202122232425262728293031323334353637&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;555&lt;/title&gt; &lt;style type="text/css"&gt; body &#123; background-color: rgb(228, 243, 191); margin-left: 10%; margin-right: 10%; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;p&gt;&lt;img src="logo/555.png"&gt;&lt;/p&gt; &lt;h1&gt;555&lt;/h1&gt; &lt;p&gt; &lt;pre&gt; 5 55 555 &lt;/pre&gt; &lt;/p&gt; &lt;h2&gt;55&lt;/h2&gt; &lt;p&gt; 5 55 &lt;/p&gt; &lt;p&gt; &lt;a href="html/5.html"&gt; &lt;img src="5/5.jpg" alt="555"&gt; &lt;/a&gt; &lt;/p&gt;&lt;/body&gt;&lt;/html&gt; CSS入门CSS包含一些简单语句，成为规则。每个规则为选择的一些HTML元素提供样式。 定性的规则包括一个选择器，以及一个或多个属性和值。选择器指定规则将应用到哪些元素。每个属性声明以一个分号结束。规则中的所有属性和值都放在{}大括号之间。 可以使用元素作为选择器，来选择任意元素。通过用逗号分隔元素名，可以一次选择多个元素。 要在HTML包含一个样式，最容易的办法就是使用&lt;style&gt;标记。对于HTML以及相当复杂的网站，可能要链接到一个外部样式表。&lt;link&gt;元素用于包含一个外部样式表。 很多属性都能继承。例如，如果为&lt;body&gt;元素设置了一个可继承的属性，那么&lt;body&gt;的所有子元素都会继承这个属性。通过为你想改变的元素创建一个更特定的规则，能覆盖该元素继承的属性。 可以使用class属性将元素增加到一个类。使用.classname可以选择属性这个类的多有元素。通过在class属性中放入多个类名，可以指定一个元素属于多个类，类名之间用空格分隔。 通过在元素名和类名之间加一个.，可以选择该类中的一个特定元素。 属性大杂烩 1234567891011121314color: 字体颜色font-weight: 文本粗细font-family: 字体样式font-style: 斜体font-size: 字体大小left: 指定一个元素左边所在位置top: 控制元素顶部的位置line-height: 行间距text-align: 文本对齐方式(左、右、居中)letter-spacing: 字母之间设置间距background-color: 背景色list-style: 改变列表项外观padding: 内边距border: 外边距 12345678910111213141516171819202122&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;7&lt;/title&gt; &lt;link rel="stylesheet" href="css/7.css"&gt;&lt;/head&gt;&lt;body&gt; &lt;h1 id="top"&gt;77&lt;/h1&gt; &lt;img src="images/77.jpg"&gt; &lt;a href="about/7.html" title="7" target="_blank"&gt;&lt;h2&gt;777&lt;/h2&gt;&lt;/a&gt; &lt;p&gt; 7 &lt;em&gt;77&lt;/em&gt; 777 &lt;/p&gt; &lt;a href="#top"&gt;&lt;h3&gt;Top&lt;/h3&gt;&lt;/a&gt; &lt;p&gt; Here &lt;em&gt;Tcons&lt;/em&gt;&lt;/a&gt; &lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 1234567891011121314body &#123; margin-left: 20%; margin-right: 20%;&#125;h1, h2 &#123; font-family: sans-serif; color: #6fa5fa;&#125;h1 &#123; text-decoration: underline;&#125;p.icon &#123; color: #4bd5ff;&#125; 字体和颜色样式访问者在你的web页面上看到的字体取决于他们自己计算机上安装了哪些字体，除非你使用web字体。 在font-family中指定候选字体是一个好主意，以防用户没有安装你的首选字体。最后一个字体要指定为通用字体。这样一来，如果找不到其它字体，浏览器可以替换适当的字体。 如果你要使用某种字体，而默认情况下用户可能没有安装这种字体，可以在CSS中使用@font-face规则。 字体大小通常为： 像素(px)、斜体(em)、百分比(%)、关键字(small, mediuml…)使用相对字体大小可以让你页面更可维护。 在body规则中使用字体大小关键字来设置基本字体大小，这样如果用户希望文本更大或更小，所有浏览器就能按比例缩放字体大小。 web颜色是混合数量不同的红、绿、蓝(RGB)得到的。可以使用红绿蓝百分数指定你想要的颜色，也可以用红绿蓝数值(0-255)，或者使用颜色的十六进制码来指定颜色。 可以使用text-decoration属性为文本创建 上划线(overline)、下划线(underline)、中划线(line-through)。有下划线的文档通常会被用户误以为是链接文件，所以要谨慎使用这个属性。 12345678910111213141516171819202122232425262728293031323334353637&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;8&lt;/title&gt; &lt;link ref="stylesheet" href="../css/8.css"&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;88&lt;/h1&gt; &lt;p&gt;88!&lt;/p&gt; &lt;h2&gt;888&lt;/h2&gt; &lt;img src="../images/8.jpg"&gt; &lt;p&gt; 8888: &lt;ol&gt; &lt;li&gt;1&lt;/li&gt; &lt;li&gt;2&lt;/li&gt; &lt;li&gt;3&lt;/li&gt; &lt;ol&gt; &lt;/p&gt; &lt;h2&gt;8888&lt;/h2&gt; &lt;p&gt; 8888: &lt;blockquote&gt; 88&lt;br&gt; 888&lt;br&gt; 8888&lt;br&gt; &lt;/blockquote&gt; 8888 &lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 12345678910111213141516171819202122232425262728293031@font-face &#123; font-family: "Emblema One"; src: url("http://wickedlysmart.com/hfhtmlcss/chapter8/journal/EmblemaOne-Regular.woff"), url("http://wickedlysmart.com/hfhtmlcss/chapter8/journal/EmblemaOne-Regular.ttf");&#125;body &#123; margin-left: 20%; margin-right: 20%; font-family: Verdana, Geneva, Arial, sans-serif; font-size: small;&#125;h1 &#123; font-size: 200%; font-family: "Emblema One";&#125;h2 &#123; font-size: 140%; font-weight: normal;&#125;h1, h2 &#123; color: #0cb8cc; text-decoration: line-through;&#125;blockquote, q &#123; font-style: italic;&#125; 盒模型CSS使用一个盒模型来控制元素如何显示。 盒子由： 内容区(content)内容区包含元素的内容。 可选的 内边距(padding)、边框(border)、外边距(margin)内边距用来在内容区周围创建可见的空间。边框包围内边距和内容，它提供了从视觉上分离内容的一种手段。外边距包围边框、内边距和内容，允许在元素和其它元素之间增加空间。 内边距和外边距都可以使用像素或百分数设置。边框宽度可以用像素设置，也可以使用关键字(thin, mediun, thick)来指定。对于外边距、内边距或边框，CSS提供了相应的属性，可以一次对所有四个边(上下左右)完成设置，也可以单独设置任意一边。 元素的背景会在内容和内边距下显示，但不会延伸到外边距下面。有八种不同的边框样式，包括实现、破折线、虚线和脊线。 对于希望成组指定样式的元素要使用class属性。使用id属性为元素指定一个唯一的名字，还可使用id属性为元素提供唯一的样式。可以使用id选择器按id选择元素。一个元素只能有一个id，不过它可以属于多个类class。 在HTML中可以使用多个样式表。如果两个样式表包含冲突的属性定义，HTML文件中最后链接的样式表最为优先。可以在&lt;link&gt;元素中使用媒体查询或使用CSS中的@media规则来指定设备。 元素 12345678910111213padding-top:padding-left:margin-right:margin-bottom:border-radius: 对有边框的元素创建圆角border-top-left-radius：border-right-bottom-radius：border-left-style：solid实线 / double双线 / groove槽线 / outset外凸 / inset内凹 / dotted虚线 / dashed破折线 / ridge脊线border-top-width：thin/ medium/ thick/ pxborder-right-color：background-image：url（images/*.jpg）或 url（http://*http://*）background-position：top left/ right bottom/ centerbackground-repeat：no-repeat/ repeat/ repeat-x/ repeat-y/ inherit（按父元素的设置来处理） 12345678910111213141516171819202122232425262728293031323334353637&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;9&lt;/title&gt; &lt;link rel="stylesheet" href="9.css"&gt;&lt;/head&gt;&lt;body&gt; &lt;strong&gt;&lt;img src="images/9.png" alt="9"&gt;&lt;/strong&gt; &lt;h1&gt;99&lt;/h1&gt; &lt;p&gt; 9 99 999 &lt;/p&gt; &lt;p id="wahaha"&gt; wa haha &lt;/p&gt; &lt;h2&gt;999&lt;/h2&gt; &lt;p&gt; 9 99 &lt;ul&gt; &lt;li&gt;999&lt;/li&gt; &lt;li&gt;999&lt;/li&gt; &lt;li&gt;999&lt;/li&gt; &lt;/ul&gt; &lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 12345678910111213141516171819202122232425262728293031323334353637383940body &#123; font-family: Verdana, Helvetica, Arial, sans-serif; font-size: small; line-height: 1.5em;&#125;h1, h2 &#123; color: rgba(118, 173, 226, 0.86)&#125;h1 &#123; font-size: 170%;&#125;h2 &#123; font-size: 1.6em;&#125;strong &#123; margin-left: 35%; margin-right: 20%;&#125;#wahaha &#123; font-family: Georgia, "Times New Roman", Times, Serif; line-height: 1.9em; font-style: italic; background-color: #ececec; background-image: url(images/9.gif); background-repeat: no-repeat; background-position: left top; border-color: white; border-radius: 20px; border-width: 2px; border-style: dashed; padding: 25px; padding-left: 60px; margin: 30px; margin-right: 250px;&#125; div和span&lt;div&gt;元素用于将相关的元素归组在一起，放在逻辑区中。创建逻辑区有助于标识主要内容区，以及页面的页眉和页脚。 可以使用&lt;div&gt;元素将需要共同样式的元素归组在一起。使用嵌套&lt;div&gt;元素为文件增加更多结构，这有利于保证结构清晰或方便增加样式。不过除非确实需要，否则不要过多地增加结构。一旦使用&lt;div&gt;将内容区归组在一起，类似于其它块元素，可以对这些&lt;div&gt;增加样式。例如，对于包含在&lt;div&gt;中的一组元素，可以使用嵌入这些元素的&lt;div&gt;的边框属性，对这组元素增加一个边框。 width属性设置设置一个元素内容区(content)的宽度。一个元素的总宽度是内容区宽度，加上所增加的页边距、边框和外边距的宽度。一旦设置一个元素的宽度，它不会延伸来占满浏览器窗口的整个宽度。 text-align是块元素的一个属性，用来将这个块元素中的所有内容对其，可以居中、左、右对齐。这个属性可以由所有嵌套的块元素继承。 可以使用子孙选择器来选择嵌套在其它元素中的元素。如子孙选择器div h2 {...}。会选择嵌套在&lt;div&gt;元素中的所有&lt;h2&gt;(包括子元素、孙子元素等)。 可对相关的属性使用快捷方式。如padding-top, padding-bottom, padding-left, padding-right都与内边距有关，可以用一个快捷规则来指定: padding。 &lt;span&gt;内联元素与&lt;div&gt;元素类似，它用于将相关的内联元素(inline)和文本归组在一起。类似于&lt;div&gt;，可以将&lt;span&gt;元素增加到类（或者为&lt;span&gt;元素指定唯一的id），对它们增加样式。 有些元素有不同的状态，&lt;a&gt;元素就是这样一个例子。&lt;a&gt;元素的主要状态包括 未访问、已访问、悬停。 可以用 伪类(pseudo class) 单独地为各个状态指定样式。伪类最常用于&lt;a&gt;元素。:link对应未访问的链接；:visited对应已访问链接；:hover对应悬停状态。伪类还可以用于其它元素，而不仅限于&lt;a&gt;元素。另外一些伪类包括：:acrivate, :focus, :first-child, :last-child等。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;!doctype html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;10&lt;/title&gt; &lt;link rel="stylesheet" href="10.css"&gt;&lt;/head&gt;&lt;body&gt; &lt;strong&gt;&lt;img src="images/10.png" alt="10"&gt;&lt;/strong&gt;&lt;br&gt; &lt;div id="elixirs"&gt; &lt;h2&gt;1010&lt;/h2&gt;&lt;br&gt; &lt;img src="images/1010.png" alt="1010"&gt; &lt;p&gt; 10 1010 &lt;/p&gt; &lt;/div&gt; &lt;p id="guarantee"&gt; 10 1010 101010 &lt;/p&gt; &lt;p class="pseudo"&gt; 10 1010 &lt;/p&gt; &lt;h2&gt;101010&lt;/h2&gt; &lt;p&gt; 10 1010 101010 &lt;ul&gt; &lt;li&gt; &lt;span class="cd"&gt;aaa&lt;/span&gt;, &lt;span class="artist"&gt;bbb&lt;/span&gt; &lt;/li&gt; &lt;li&gt; &lt;span class="cd"&gt;AAA&lt;/span&gt;, &lt;span class="artist"&gt;BBB&lt;/span&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/p&gt; &lt;div id="copyright"&gt; &lt;p&gt; @xxxx&lt;br&gt; xxxx &lt;/p&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182body &#123; font-family: Verdana, Helvetica, Arial, sans-serif; font-size: small; line-height: 1.5em;&#125;h1, h2 &#123; color: rgba(118, 173, 226, 0.86);&#125;h1 &#123; font-size: 170%;&#125;h2 &#123; font-size: 1.6em;&#125;strong &#123; margin-left: 35%; margin-right: 20%;&#125;#guarantee &#123; font: italic small/1.9em Feorgia, "Times New Roman", Times, Serif; background: #ececec url(images/bg.gif) no-repeat top left; border: white 2px dashed; border-radius: 20px; padding: 25px; padding-left: 60px; margin: 30px; margin-right: 250px;&#125;#elixirs &#123; border: thin solid #007e7e; width: 200px; /* 顺时针 top right bottom left */ padding: 0 20px 20px 20px; margin-left: 20px; text-align: center; background: url(images/bg2.gif) repeat-x top right; float: right;&#125;#elixirs h2 &#123; color: black;&#125;#elixirs p &#123; line-height: 1.5em;&#125;#copyright &#123; font-size: 50%; text-aligh: center; line-height: normal; margin-top: 30px;&#125;.cd &#123; font-style: italic;&#125;.artist &#123; font-weight: bold;&#125;#elixirs a:link &#123; color: #0cb8cc;&#125;#elixirs a:visited &#123; color: red;&#125;#elixirs a:hover &#123; background: #16a085; text-decoration: line-through;&#125;p.pseudo a:hover &#123; background: #333333;&#125; 布局与定位浏览器使用流(flow)在页面中放置元素。 块元素从上向下流，各元素之间有一个换行。默认的，每个块元素会占浏览器窗口的整个宽度。内联元素在块元素内部从左上方流向右下方。如果需要多行，浏览器会换行，在垂直方向上扩展外围块元素，来包含这些内联元素。 正常页面流中两个块元素上下相邻的外边距会折叠为最大外边距的大小，或者如果两个外边距大小相同，则会折叠为一个外边距。浮动元素会从正常流中取出，浮动到左边或者右边。浮动元素放在块元素之上，不会影响正常的页面流。不过，内联内容会考虑浮动元素的边界，围绕这个浮动元素。 clear属性用来指定一个块元素左边或右边（或左右两边）不能有浮动元素。设置了clear属性的块元素会下移，直到它旁边没有块元素。 浮动元素必须有特定的宽度，不能设置为auto。 流体布局是指，扩展浏览器窗口时，页面中的内容会扩展以适应页面。冻结布局是指，其中内容的宽度是固定的，不会随着浏览器窗口扩展或收缩。这有一个好处，可以对设计提供更多控制，不过也要付出代价，这样就不能有效地使用浏览器宽度了。凝胶布局是指，其中内容的宽度时固定的，但是外边距会随着浏览器窗口扩展或收缩。凝胶布局通常会把内容放在中央。这与冻结布局有同样的好处，不过通常更美观。 positon属性可以设置四个值：static(静态)、absolute(绝对)、fixed(固定)、relative(相对)。静态定位是默认方式，将元素放在页面的正常流中。绝对、固定和相对定位时，属性top, right, bottom, left可用来指定元素的位置。绝对定位元素可以使用z-index属性分层放置，是一个元素在另一个元素上面。z-index值越大，说明它的层次越高（在屏幕上离你越近）。固定定位元素总是相对于浏览器窗口定位，页面滚动时，固定定位的元素不会移动。页面中的其它内容会在这些固定定位元素下面正常滚动。相对定位元素首先正常流入页面，然后按指定的量偏移，从而留出它们原先所在的空间。使用相对定位时，left, right, top, bottom是指距正常流中该元素位置的偏移量。 CSS表格显示允许按一种表格布局来摆放元素。要创建CSS表格显示，需要使用对应表格的一个块元素，对应行的块元素。以及对应单元格的块元素。通常，这些块元素都是&lt;div&gt;元素。 如果需要建立多栏布局，而且内容栏是均匀的，表格显示就是一个很好的布局策略。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374&lt;!doctype html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;11&lt;/title&gt; &lt;link ref="stylesheet" href="11.css"&gt;&lt;/head&gt;&lt;/body&gt; &lt;div id="header"&gt; &lt;div id="header1"&gt; &lt;img src="images/11.png" alt="11"&gt; &lt;/div&gt; &lt;div id="header2"&gt; &lt;img src="images/bg2.gif"&gt; &lt;/div&gt; &lt;div id="header3"&gt; &lt;img src="images/bg3" width="200px" height="200px"&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id="tableContainer"&gt; &lt;div id="tableRow"&gt; &lt;div id="drinks"&gt; &lt;h1&gt;11&lt;/h1&gt; &lt;p&gt;1111&lt;/p&gt; &lt;/div&gt; &lt;div id="main"&gt; &lt;h1&gt;11&lt;/h1&gt; &lt;p&gt; 11 1111 &lt;/p&gt; &lt;p&gt; 1111 111111 &lt;/p&gt; &lt;p class="pseudo"&gt; 11 11 1111 1111 &lt;/p&gt; &lt;p&gt; 11 11 11 &lt;ul&gt; &lt;li&gt; &lt;span class="cd"&gt;aaa&lt;/span&gt;, &lt;span class="artist"&gt;bbb&lt;/span&gt; &lt;/li&gt; &lt;li&gt; &lt;span class="cd"&gt;AAA&lt;/span&gt;, &lt;span class="artist"&gt;BBB&lt;/span&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/p&gt; &lt;/div&gt; &lt;div id="sidebar"&gt; &lt;h2&gt;11 11 11&lt;/h2&gt; &lt;img src="iamges/img2.ico" alt="img2"&gt; &lt;p&gt; 11 11 11 11 11 11 &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id="copyright"&gt; &lt;p&gt; @2016,xxxx&lt;br&gt; xxxx &lt;/p&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109body &#123; font-family: Verdana, Helvetica, Arial, sans-serif; font-size: small; line-height: 1.5em;&#125;h1, h2 &#123; color: rgba(118, 173, 226, 0.86);&#125;h1 &#123; font-size: 170%;&#125;h2 &#123; font-size: 1.6em;&#125;#header1 &#123; margin-left: 35%; margin-right: 40%;&#125;#header2 &#123; position: fixed; top: 300px; left: 0px;&#125;#header3 &#123; position: absolute; top: 0px; left: 0px;&#125;#sidebar &#123; display: table-cell; font-size: 105%; padding: 15px; vertical-align: top;&#125;#sidebar h2 &#123; color: black;&#125;#sidebar h3 &#123; color: #d12c47;&#125;#sidebar p &#123; line-height: 1.5em;&#125;#sidebar a:link &#123; color: #0cb8cc;&#125;#sidebar a:visited &#123; color: red;&#125;#sidebar a:hover &#123; background: #16a085; text-decoration: line-through;&#125;#copyright &#123; font-size: 50%; color: #b9311b; font-weight: bold; text-align: center; line-height: normal; clear: both; margin: 0px 10px 10px 10px;&#125;.cd &#123; font-style: italic;&#125;.artist &#123; font-weight: bold;&#125;a &#123; text-decoration: none;&#125;#main &#123; display: table-cell; font-size: 105%; padding: 15px; vertical-align: top;&#125;#tableContainer &#123; display: table; border-spacing: 10px;&#125;#tableRow &#123; display: table-row;&#125;#drinks &#123; display: taable-cell; width: 15%; vertical-aligh: top; padding: 15px;&#125; HTML51234567891011121314&lt;aside&gt; # 用于表示放在内容旁边的内容，比如引用&lt;mark&gt; # 用于突出显示某些文件，就像记号笔一样棒&lt;audio&gt; # 用于在页面中包含声音内容&lt;time&gt; # 时间、日期或日期时间&lt;progress&gt; # 需要显示任务的完成进度，如90%&lt;footer&gt; # 定义一个区块或整个文档的页眉&lt;header&gt; # 有首部的区块和整个文档的页眉可以使用这个元素&lt;meter&gt; # 需要显示某个范围的度量。比如一个0到220度的温度计，现在显示90度&lt;article&gt; # 用来标记类似新闻报道或博客帖子等独立内容&lt;canvas&gt; # 在页面中显示js绘制的图像和动画&lt;section&gt; # 定义文档的主要区块&lt;nav&gt; # 把网站中用于导航的所有链接组织在一起&lt;figure&gt; # 定义类似照片、图像甚至代码清单等独立的内容&lt;video&gt; # 在页面中加入一个视频 视频编码是用来创建视频文件的编码。视频容器文件包含视频、音频和元数据。要提供多个视频源文件，确保你的用户可以在他们的浏览器中播放视频文件。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;!doctype html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset='utf-8'&gt; &lt;title&gt;12&lt;/title&gt; &lt;link rel="stylesheet" href="12.css"&gt;&lt;/head&gt;&lt;body&gt; &lt;header class="top"&gt; &lt;img src="images/12.png" alt="12"&gt; &lt;/header&gt; &lt;nav&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="1.html"&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="2.html"&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="3.html"&gt;&lt;/a&gt;&lt;/li&gt; &lt;ul&gt; &lt;/nav&gt; &lt;div id="tableContainer"&gt; &lt;div id="tableRow"&gt; &lt;section id="drinks"&gt; &lt;p&gt;x&lt;/p&gt; &lt;p&gt;xx&lt;/p&gt; &lt;/section&gt; &lt;section id="blog"&gt; &lt;article&gt; &lt;header&gt; &lt;h1&gt;blog&lt;/h1&gt; &lt;time datetime="2019-01-01"&gt;Jan 01 2019&lt;/time&gt; &lt;/header&gt; &lt;p&gt; 12 12 12 12 12 12 &lt;/p&gt; &lt;/article&gt; &lt;section&gt; &lt;aside&gt; &lt;h2&gt;12 12&lt;/h2&gt;&lt;br&gt; &lt;img src="images/1212.png" alt="1212"&gt; &lt;p&gt; 12 12 12 12 12 &lt;/p&gt; &lt;/aside&gt; &lt;/div&gt; &lt;/div&gt; &lt;footer&gt; &lt;p&gt; @2019,xxx xxxx &lt;/p&gt; &lt;/footer&gt;&lt;/body&gt;&lt;/html&gt; 表格与更多列表确实需要在页面中创建表格数据时，就使用HTML表格。如果只需要对其它类型的内容使用一种类似与表格的表现方式，就可以使用CSS表格来显示布局。 HTML表格用来建立表格数据结构。HTML表的元素： 表格(&lt;table&gt;)、表行(&lt;tr&gt;)、表头(&lt;th&gt;)、表格数据(td)，一齐用来创建一个表格。table元素定义并包围整个表格；表格使用&lt;tr&gt;元素按行定义；每行包含一个或多个数据单元格，用&lt;td&gt;元素定义；表格采用格状布局。每行对应HTML中的一个&lt;tr&gt;..&lt;/tr&gt;，每列对应行中的&lt;td&gt;...&lt;/td&gt;内容。如果一个数据单元格没有数据，&lt;td&gt;元素中不放置任何内容。不过，需要使用&lt;td&gt;&lt;/td&gt;维持表格对齐。如果你的数据单元格需跨多行或多列，可使用&lt;td&gt;元素的rowspan或colspan属性。 可以用&lt;caption&gt;元素提供关于表格的额外信息。 表格有边框间距，也就是单元格之间的间距。表格数据单元格还可以有内边距和边框，但没有外边距。就像能够控制元素的内边距、边框、外边距一样，可以用CSS控制表格单元格的内边距、边框和边框间距。 border-collapse(边框折叠)是针对表格的一个特殊CSS属性，允许将单元格边框合并为一个边框，让外观更简洁。 可以用text-align和vertic-align CSS属性改变表格单元格中数据的对齐方式。可以用background属性为表格增色。可以为整个表格、各行或单个的数据单元格增加背景色。 使用CSS的:nth-child伪类可为表格隔行增加背景色。 可以在表格中嵌套表格，将&lt;table&gt;元素及其内容放在一个数据单元格中。 表格应当应用于表示表格数据，而不是建立页面布局。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;!doctype html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;13&lt;/title&gt; &lt;link rel="syslesheet" href="../css/13.css"&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;13&lt;/html&gt; &lt;p&gt;13 13 13 13&lt;/p&gt; &lt;h2&gt;2019-01-10&lt;/h2&gt; &lt;img src="../images/13.png"&gt; &lt;p&gt; 13 13 13 &lt;table&gt; &lt;cpation&gt;&lt;b&gt;13 13&lt;/b&gt;&lt;/caption&gt; &lt;tr&gt; &lt;th&gt;L1&lt;/th&gt; &lt;th&gt;L2&lt;/th&gt; &lt;th&gt;L3&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;11&lt;/td&gt; &lt;td&gt;22&lt;/td&gt; &lt;td&gt;33&lt;/td&gt; &lt;/tr&gt; &lt;tr class="cellcolor"&gt; &lt;td&gt;1c&lt;/td&gt; &lt;td&gt;2c&lt;/td&gt; &lt;td&gt;3c&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td rowspan="2"&gt;111&lt;/td&gt; &lt;td colspan="2"&gt;222&lt;/td&gt; &lt;td rowspan="2"&gt;333&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1111&lt;/td&gt; &lt;td&gt;2222&lt;/td&gt; &lt;td&gt; &lt;table&gt; &lt;tr&gt; &lt;td&gt;1 1 &lt;/td&gt; &lt;td&gt;2 2 &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1 1 1&lt;/td&gt; &lt;td&gt;2 2 2&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 表单&lt;form&gt;元素定义了表单，所有表单输入元素都嵌套着这个元素中。 12345678910111213141516171819202122232425262728293031323334353637383940action 属性包含了服务器脚本的URLmethod 属性包含发送表单数据的方法，可以是GET或POSTPOST 打包数据表单，并把它作为请求的一部分发送到服务器GET 打包表单数据，并把数据追加到url如果表单数据应当是私有的，或者表单数据很多，如使用了一个&lt;textarea&gt;或者file &lt;input&gt;元素，就应当使用POST方法。对于可以加书签的请求，要使用GET方法。&lt;input&gt;元素在web页面上可以作为多种不同的输入控件，这取决于它的type属性值。type为 text 时会创建一个单行文本输入框type为 submit 时会创建一个提交按钮type为 radio 时会创建一个单选框。所有同名的单选框构成一组互斥的按钮type为 checkbox 时会创建一个复选框控件。通过为多个复选框指定相同的名字，可以创建一组选择type为 number 时会创建一个只允许数字字符的单行文本输入控件type为 range 时会创建一个滑动条控件提供数字输入color 类型会在支持这个类型的浏览器中创建一个颜色选择器（否则只会创建一个普通的文本输入控件）date 类型会在支持这个类型的浏览器中创建一个日期选择器（否则只会创建一个普通的文本输入控件）email, url, tel 类型会创建当行文本输入，在一些移动浏览器上出现定制键盘来方便数据输入&lt;textarea&gt; 元素会创建一个多行文本输入区。&lt;select&gt; 元素会创建一个菜单，包含一个或多个 &lt;option&gt; 元素。&lt;option&gt; 元素定义了菜单中的菜单项。如果将文本放在 &lt;textarea&gt; 元素的内容中，这会成为web页面上文本去控件中的默认文本text &lt;input&gt; 元素中的 value 属性可以用来为单行文本输入控件提供一个初始值。在提交按钮设置 value 属性可以改变按钮上显示的文本。提交一个web表单时，表单数据值与相应的数据名配对，所有名和值会发送到服务器。由于表单有一个表格结构，通常会用CSS表格显示来建立表单布局。CSS还可以用来指定表单的颜色、字体风格、边框样式。HTML允许用 &lt;fieldset&gt; 元素组织表单元素。可以用 &lt;lable&gt; 元素以一种有助于提高可访问性的方式关联标签与表单元素。使用 placeholder 属性可以为表单用户提供一个提示， 指出你希望在一个输入域中输入什么内容。required 属性指示一个输入域是必要的，要让表单成功提交，这个输入域中必须有值。有些浏览器在你提交表单之前会强制要求在这些域中输入数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Form&lt;/title&gt; &lt;link ref="stylesheet" href="form.css"&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Form 1&lt;/h1&gt; &lt;h2&gt;Form 2&lt;/h2&gt; &lt;form action="http://xxx.com/xx.php" method="post"&gt; &lt;div class="tableRow"&gt; &lt;p&gt; Choose: &lt;/p&gt; &lt;p&gt; &lt;select name="beans"&gt; &lt;option value="default"&gt;111&lt;/option&gt; &lt;option value="default"&gt;222&lt;/option&gt; &lt;option value="default"&gt;333&lt;/option&gt; &lt;option value="default"&gt;444&lt;/option&gt; &lt;/select&gt; &lt;/p&gt; &lt;/div&gt; &lt;div class="tableRow"&gt; &lt;p&gt;Type: &lt;/p&gt; &lt;p&gt; &lt;input type="radio" name="beantype" value="whole"&gt;55&lt;br&gt; &lt;input type="radio" name="beantype" value="ground"&gt;66 &lt;/p&gt; &lt;/div&gt; &lt;div class="tableRow"&gt; &lt;p&gt;Number:&lt;/p&gt; &lt;p&gt; &lt;input type="number" name="bags" min="1" max="20" required&gt; &lt;/p&gt; &lt;/div&gt; &lt;div class="tableRow"&gt; &lt;p&gt;Date:&lt;/p&gt; &lt;p&gt; &lt;input type="date" name="date"&gt; &lt;/p&gt; &lt;/div&gt; &lt;div class="tableRow"&gt; &lt;p&gt;Name: &lt;/p&gt; &lt;p&gt; &lt;input type="text" name="name" value=""&gt; &lt;/p&gt; &lt;/div&gt; &lt;div class="tableRow"&gt; &lt;p&gt;Address: &lt;/p&gt; &lt;p&gt; &lt;input type="text" name="address"value="" required&gt; &lt;/p&gt; &lt;div class="tableRow"&gt; &lt;p&gt;Phone: &lt;/p&gt; &lt;p&gt; &lt;input type="tel" name="phone" value="" required&gt; &lt;/p&gt; &lt;/div&gt; &lt;div class="tableRow"&gt; &lt;p&gt;Email: &lt;/p&gt; &lt;p&gt; &lt;input type="email" name="email" value="" placeholder="someone@example.com"&gt; &lt;/p&gt; &lt;/div&gt; &lt;div class="tableRow"&gt; &lt;p&gt;Choose file:&lt;/p&gt; &lt;p&gt; &lt;input type="file" name="file"&gt; &lt;/p&gt; &lt;/div&gt; &lt;div class="tableRow"&gt; &lt;p&gt;Comment: &lt;/p&gt; &lt;p&gt; &lt;textarea name="comment"&gt;&lt;/textarea&gt; &lt;/p&gt; &lt;/div&gt; &lt;div class="tableRow"&gt; &lt;p&gt; &lt;input type="submit" value="Order"&gt; &lt;/p&gt; &lt;/div&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 12345678910111213141516171819202122232425262728293031323334353637383940body &#123; background: #efe5d0; margin: 20px; font-family: Georgia, "Times New Roman", Times, Serif;&#125;form &#123; display: table; padding: 10px; border: thin dotted #7e7e7e; background: #e1ceb8; margin: 10px 200px;&#125;form textarea &#123; width: 500px; height: 150px;&#125;div.tableRow &#123; display: table-row;&#125;div.tableRow p &#123; display: table-cell; vertical-align: top; padding: 3px;&#125;div.tableRow p:first-child &#123; text-align: right;&#125;p.heading &#123; font-weight: bold;&#125;h1, h2 &#123; text-align: center;&#125;]]></content>
      <categories>
        <category>Frontend</category>
      </categories>
      <tags>
        <tag>Frontend</tag>
        <tag>HTML</tag>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django]]></title>
    <url>%2F2019%2F09%2F25%2FDjango%2F</url>
    <content type="text"><![CDATA[参考: docs: https://docs.djangoproject.com/zh-hans/2.1/topics/ 版本: Django Version: v2.1 使用Djangodocs: https://docs.djangoproject.com/zh-hans/2.1/topics/ 安装Django 模型和数据库docs: https://docs.djangoproject.com/zh-hans/2.1/topics/db/ 模型是你的数据唯一而且准确的信息来源。它包含你正在存储的数据的重要字段和行为。一般来说，每一个模型都映射一个数据库表。 模型docs: https://docs.djangoproject.com/zh-hans/2.1/topics/db/models/ 基础: 每个模型都是一个Python类(继承django.db.models.Model) 模型类的每个属性都相当于一个数据库的字段 快速上手这个样例模型定义了一个Person, 其拥有first_name和last_name: 12345from django import modelsclass Person(models.Model): first_name = models.CharField(max_length=30) last_name = models.CharField(max_length=30) first_name和last_name是模型的字段。每个字段都被指定为一个类属性，并且每个属性映射为一个数据库列。 上面的Person会创建一个如下的数据库表: 12345CREATE TABLE myapp_person ( "id" serial NOT NULL PRIMARY KEY, "first_name" varchar(30) NOT NULL, "last_name" varchar(30) NOT NULL); 说明: 表名myapp_person是自动从模型元数据中派生出来，但可以被改写 id字段会被自动添加，也可被改写 这是使用默认的PostgreSQL语法，数据库引擎可在settings中配置 使用模型一旦定义了模型，需要告诉Django使用这些模型。需要修改setting文件中的INSTALLED_APPS, 这个设置中添加包含你models.py文件的模块的名字。 12345678# 例如，模型位于项目中的myapp.models中# 包结构使用 manage.py startapp 创建INSTALLED_APPS = [ ... &apos;myapp&apos;, ...] 当你在配置中添加新应用的时候，请务必运行manage.py migrate &lt;migrate&gt;，此外你也可以先使用manage.py makemigrations先进行迁移。 进行查询docs: https://docs.djangoproject.com/zh-hans/2.1/topics/db/queries/ 一旦创建了数据模型，Django会自动地给你一个数据库抽象API——让你可创建、检索、更新和删除对象。 1234567891011121314151617181920212223242526272829from django.db import modelsclass Blog(models.Model): name = models.CharField(max_length=1000) tagline = models.TextField() def __str__(self): return self.nameclass Author(models.Model): name = models.CharField(max_length=1200) email = models.EmailField() def __str__(self): return self.nameclass Entry(models.Model): blog = models.ForeignKey(Blog, on_delete=models.CASCADE) headline = models.CharField(max_length=255) body_text = models.TextField() pub_date = models.DateField() authors = models.MangToManyField(Author) n_comments = models.IntegerField() n_pingbacks = models.IntegerField() def __str__(self): return self.headline 创建对象为了表示在Python对象数据库表中的数据，Django使用一个直观的系统: 一个模型类表示一个数据库表 类实例表示数据库中的表中的特定记录 要创建一个对象，使用关键字参数模型类的实例化，然后调用save()将它保存到数据库中。 12345# 例子from blog.models import Blogb = Blog(name='xxx', tagline='xxxx')b.save() 将更改保存到对象使用save()将更改保存到一个对象中已有的数据库。 1234b5.name = 'New b5'b5.save()# 这执行幕后的UPDATE SQL语句 检索对象要检索数据库对象，通过在模型类上Manager构建一个QuerySet。QuerySet代表从数据库的对象集合。它可以有0, 1, n个过滤器。在SQL方面，一个QuerySet相当于SELECT语句，而过滤器相当于WHERE, LIMIT。通过使用Manager模型获取QuerySet。每个模型至少有一个Manager，这就是所谓的默认objects。直接通过模型类访问: 12345Blog.objectsb = Blog(name='xxx', tagline='Bar')b.objects... 检索所有对象； 使用过滤器检索特定对象； 比较对象 删除对象 更新对象 关联对象 回落的原生SQL如果你发现自己使用Django 数据库映射器写一个SQL查询太复杂，你可以手边编写SQL fall back。 聚合docs: https://docs.djangoproject.com/zh-hans/2.1/topics/db/aggregation/ 有时候要获取的值需要根据一组对象聚合后才能得到。 搜索docs: https://docs.djangoproject.com/zh-hans/2.1/topics/db/search/ Web应用的一个常见任务就是寻找与用户输入数据库中的某些数据。 处理HTTP请求docs: https://docs.djangoproject.com/zh-hans/2.1/topics/http/ URL调度器docs: https://docs.djangoproject.com/zh-hans/2.1/topics/http/urls/ 对于高质量的Web应用来说，使用简洁、优雅的URL模式是一个非常值得重视的世界。Django允许你自由滴设计你的URL，不受框架束缚。 概况为了给一个应用设计URL，你需要创建一个Python模块，通常被称为URLconf。这个模块是纯粹的Python代码，包含URL模式(简单的正则)到Python函数(视图)的简单映射。映射可长可短，随便你。它可以引用其它映射。而且，因为它是纯粹的Python代码，它可以动态构造。 Django如何处理一个请求当一个用户请求Django站点的一个页面，下面是Django系统决定执行哪个Python代码使用的算法: Django确定 root URLconf 模块的使用。通常，这个setting中ROOT_URLCONF的值，但如果传入HttpRequest对象具有URL配置属性(由中间件设置)，它的值将代替ROOT_URLCONF。 Django载入 Python 模块并查找 urlpatterns变量。这应该是是一个 Python List。 Django依次匹配每个URL模式，在与请求的URL匹配的第一个模式停下来。 一旦URL模式匹配，Django导入并调用给定的视图——这是一个简单的Python函数(或基于类的视图)。该类会传递如下参数:4.1 一个HttpRequest实例4.2 如果匹配的URL模式没有返回命名组，则从正则匹配作为位置参数4.3 关键字参数是由通过路径表达式匹配的任何命名的部分，通过在任选关键字参数kwargs指定的任何参数重写django.urls.path()或django.urls.re_path() 如果每个URL模式匹配，或者一个异常在此过程中的任何点被抛出，则Django调用适当的错误处理视图。 栗子一个简单的URLconf: 123456789from django.urls import pathfrom . import viewsutlpatterns = [ path('articles/2003/', views.special_case_2003), path('articles/&lt;int:year&gt;/', views.year_archive), path('articles/&lt;int:year&gt;/&lt;int:month&gt;/', views.month_archive), path('articles/&lt;int:year&gt;/&lt;int:month&gt;/&lt;slug:slug&gt;/', view.article_detail)] 注意: 为了捕获从URL中的值，使用尖括号&lt;&gt; 捕获的值可任选地包括一个转换器类型。如，使用&lt;int: name&gt;来捕获整数参数。如果不包含一个转换器，则为任意string。排除/字符，被匹配。 没有必要添加开始的斜线/，因为每个URL都有。如articles而不是/articles。 一些请求栗子: 一个请求/articles/2005/03/将匹配李彪中的第三项。Django将调用函数view.mouth_archive(request, year=2005, month=3)。 /articles/2003/将匹配第一个模式，而不是第二个。Django将调用函数views.special_case_2003(request) /articles/2003将不会匹配这些模式，因为每个模式都要求URL以斜线/结束 /articles/2003/building-a-django-site/讲匹配最后一个模式。Django将调用函数view.article_detail(request, year=2003, month=3, slug=&quot;building-a-django-site&quot;) path转换器下面的路径转换器默认可用: str: 匹配任意非空字符串，不包括路径分隔符/。如果表达式中不包含转换器，这是默认值。 int: 匹配零个或多个正整数，返回一个int。 slug: 匹配任何由ASCII字母、数字、连字符、下划线组成的slug字符串。 uuid: 匹配一个格式化的UUID。为了防止映射到同一页面的多个网址，必须包含字符，必须小写。(如075194d3-6885-417e-a8a8-6c931e272f00)，返回一个UUID实例。 path: 匹配任意费控字符串，包含路径分隔符/。这允许你来匹配一个完整的URL路径. 注册自定义路径转换器对于更复杂的匹配要求，可以定义自己的路径转换器。 使用正则表达式如果路径和转换器的语法不够定义你的URL模式，你也可以使用正则表达式。要做到这一点，使用re_path()来代替path()。 在Python的正则表达式中，正则表达式组名语法是(?P&lt;name&gt;pattern)，name是组名和pattern相匹配。 将之前的URLconf使用正则表达式改写: 123456789from django.urls import path, re_pathfrom . import viewsurlpatterns = [ path('articles/2003/', views.special_case_2003), re_path(r'^articles/(?P&lt;year&gt;[0-9]&#123;4&#125;/$', views.year_archive)), re_path(r'^articles/(?P&lt;year&gt;[0-9]&#123;4&#125;)/(?P&lt;month&gt;[0-9]&#123;2&#125;)/$', views.month_archive), re_path(r'^articles/(?P&lt;year&gt;[0-9]&#123;4&#125;)/(?P&lt;month&gt;[0-9]&#123;2&#125;)/(?P&lt;slug&gt;[\w-]+)/$', views.article_detail),] 使用未命名的正则表达式组 嵌套的参数 1234567# 正则表达式允许嵌套参数from django.urls import re_pathurlpatterns = [ re_path(r'^blog/(page-(\d+)/)?$', blog_articles), # bad re_path(r'^comments/(?:page-(?P&lt;page_number&gt;\d+)/)?$', comments), # good] URLconf在什么上查找请求的URL被看成是一个普通的Python字符串，URLconf在其上查找并匹配。进行匹配时将不包括GET或POST请求方式的参数以及域名。例如，https://www.example.com/myapp/请求中，URLconf将查找myapp/。在https://www.example.com/myapp/?page=3请求中，URLconf仍将查找myapp/。URLconf不检查使用了哪种请求方法。换句话讲，所有的请求方法——无论是POST, GET, HEAD…，都将路由到相同的函数。 指定视图参数的默认值有一个方便的小技巧是指定视图参数的默认值。 123456789101112131415# URLconffrom django.urls import pathfrom . import viewsutlpatterns = [ path('blog/', views.page), path('blog/page&lt;int:num&gt;', views.page),]# Viewdef page(request, num=1): ... 错误处理当Django找不到请求的URL匹配，或将引发异常，Django调用错误处理视图。这些情况发生时使用的视图通过4个变量指定。它们的默认值应该能满足大部分项目，但也可给他们赋值以进一步自定义。 1234567handler400: django.conf.urls.handler400handler403: django.conf.urls.handler403handler404: django.conf.urls.handler404handler500: django.conf.urls.handler500 包含其它的URLconfs在任何时候，你的urlpatterns都可以include其它URLconf模块。这实际上将一部分URL放置于其它URL下面。 123456from django.urls import include, pathurlpatterns = [ ... path('community/', include('abc.urls')),] 当Django遇到include()，它砍掉任何匹配到该点和该URL的一部分发送所述剩余的字符串所包含的URL配置用于进一步的处理。 12345678910111213141516from django.urls import include, pathfrom app.main import view as main_viewsfrom credit import views as credit_viewsextra_patterns = [ path('reports/', credit_views.report), path('reports/&lt;int:id&gt;/', credit_views.report), path('charge/', credit_views.charge),]urlpatterns = [ path('', main_views.homepage), path('help/', include('apps.help.urls')), path('credit/', include(extra_patterns)),] 这个栗子中，/credit/reports/ URL将被credit_views.report()这个Django视图处理。 这种方法可以用来去除URLconf中的冗余，其中某个模式前缀被重复使用。如: 123456789101112131415161718192021from django.urls import pathfrom . import viewsurlpatterns = [ path('&lt;page_slug&gt;-&lt;page_id&gt;/history/', views.history), path('&lt;page_slug&gt;-&lt;page_id&gt;/edit/', views.edit), path('&lt;page_slug&gt;-&lt;page_id&gt;/discuss/', views.discuss), path('&lt;page_slug&gt;-&lt;page_id&gt;/permissions/', views.permissions),]# 改进它urlpatterns = [ path('&lt;page_slug&gt;-&lt;page_id&gt;/', include([ path('history/', views.history), path('edit/', views.edit), path('discuss/', views.disscuss), path('permissions/', views.permissions), ])),] 捕获的参数 被包含的URLconf会收到来自父URLconf捕获的任何参数: 12345678910111213141516# settings/urls/main.pyfrom django.urls import include, pathurlpatterns = [ path('&lt;username&gt;/blog/', include('foo.urls.blog')),]# foo/urls/blog.pyfrom django.urls import pathfrom . import viewsurlpatterns = [ path('', views.blog.index), path('archive/', views.blog.archive),] 在上面的栗子中，捕获的username变量将被如期传递给include()执行的URLconf。 传递额外选项到视图函数URLconfs有一个hooks，可以传递额外的参数给视图函数，作为Python字典。 The path() function can take an optional third argument which should be a dictionary of extra keyword arguments to pass to the view function. 12345678from django.urls import pathfrom . import viewsurlpatterns = [ path('blog/&lt;int:year&gt;/', views.year_archive, &#123;'foo': 'bar'&#125;),]# In this example, for a request to /blog/2005/, Django will call views.year_archive(request, year=2005, foo='bar'). 传递额外选项到include() 123456789101112131415# main.pyfrom django.urls import include, pathurlpatterns = [ path('blog/', include('inner'), &#123;'blog_id': 3&#125;),]# inner.pyfrom django.urls import pathfrom mysite import viewsurlpatterns = [ path('archive/', views.archive), path('about/', views.about),] URLs的反向解析Django项目工作时的一个常见需要是获得 URLs 它们的最终形式或用于在生成的内容中嵌入的 URL 的可能性为在服务器上的导航流处理测(重定向)。 强烈希望避免硬编码(hard-coding)这些URLs（费力，不可扩展且容易出错）。同样危险的是ad-hoc机制，以产生平行于所述 URLconf 描述的设计，这可能导致生成的 URLs 随着时间的推移而变得陈旧。 换句话说，需要一个 DRY 机制。在其它优点将允许 URL 设计的进化，而不必去复习所有项目的源代码来查找和替换过时的URLs。 Django提供了一个解决方案，以使 URL 映射器 是 URL 设计的唯一仓库。用你的 URL 喂养它，那么它可以在两个方向上使用: 与 user/browser 请求的 URL 开始，它调用正确的Django视图提供任意参数给需要从URL提取它的值。 与标识对应的Django视图将被传递给它的参数的值开始，获得相关的URL。 第一个前面讨论过，第二个是所谓的 URL 的反向解析、URL 反向匹配、 URL 反向查找或 URL 反转。 Django提供了用于执行 URL 反向，匹配不同层 URLs 的需要: Template: 使用url template tag Python code: 使用 reverse() 函数 在相关的Django模型实例的URL处理更高级别的代码: get_absolute_url()方法 就是给这个path取个名字，通过名字去找路径。即使修改了路径，只要名字没有修改，在其它部分里使用path名字的部分就不需要修改。 1234567from django.urls import pathfrom . import viewsurlpatterns = [ ... path('articles/&lt;int:year&gt;/', views.year_archive, name='news-year-archive'),] 你可通过使用这些模板代码获得: 1234567&lt;a href=&quot;&#123;% url &apos;news-year-archive&apos; 2012 %&#125;&quot;&gt;&#123;# Or with the year in a template context variable: #&#125;&lt;ul&gt;&#123;% for yearvar in year_list %&#125;&lt;li&gt;&lt;a href=&quot;&#123;% url &apos;new-year-archive&apos; yearvar %&#125;&quot;&gt;&#123;&#123; yearvar &#125;&#125; Archive&lt;/a&gt;&lt;/li&gt;&#123;% end for %&#125;&lt;/ul&gt; Or in Python Code: 12345678from django.http import HttpResponseRedirectfrom django.urls import reversedef redirect_to_year(request): # ... year = 2006 # ... return HttpResponseRedirect(reverse('news-year-archive', args=(year,))) 命名URL模式要执行URL反向，你需要使用命名的URL模式(named URL patterns)。这个名称可以包含任何你喜欢的字符，而不仅限于Python names。选择不太可能与其它应用程序名称相冲突的名字。如果你调用URL pattern comment 和其它应用程序做同样的事，URL reverse()查找取决于哪个模式是最后在项目的 urlpattens 的列表中。为你的URL名称放一个前缀，后去可以从应用程序的名称派生，这样降低了冲突的可能。 URL命名空间URL命名空间允许你唯一地反转 named URL patterns，即使不同的应用程序使用相同的URL名称。 一个URL命名空间有两个部分，两个都是字符串: application namespace instance namespace 命名空间URL使用特定的:操作符。命名空间同样可以嵌套。命名的URL sports:polls:index ，会在顶级命名空间sports中定义的polls的命名空间中，寻找名为index的一个模式。 反向命名空间URLs 当给定一个命名空间URL（如polls:index）来解析时，Django将分割名称为几个部分，然后尝试一下查找: 首先，Django查找 应用程序命名空间（如polls)，这将产生应用程序的实例列表。 如果有定义当前应用程序，Django查找并返回该实例的URL解析。 如果没有当前应用程序，Django查找默认应用程序实例。 如果没有默认的应用程序实例，Django会挑选最后部署的应用的实例。 如果提供的命名空间无法匹配步骤1中的应用程序命名空间，Django会尝试将此命名空间直接作为实例命名空间查找。 123456789101112131415161718# urls.pyfrom django.urls import include, pathurlpatterns = [ path('author-polls/', include('polls.urls', namespace='author-polls')), path('publisher-polls/', include('polls.urls', namespace='publisher-polls')),]# polls/urls.pyfrom django.urls import pathfrom . import viewsapp_name = 'polls'urlpatterns = [ path('', views.IndexView.as_view(), name='index'), path('&lt;int:pk&gt;/', views.DetailView.as_view(), name='detail')] 使用此设置，可能进行下面这些查找: 如果其中一个实例就是当前这个，如果我们在实例 author-polls 渲染详情页面，polls:index 将解析到 author-polls 实例页面。即两个都会导致 /author-polls/。 在 class-based view 的方法中: reverse(&#39;polls:index&#39;, current_app=self.request.resolver_match.namespace)在 模板中: url 'polls:index' %&#125;```12345678910111213141516171819202122232425262728293031- 如果没有当前实例，xxxx- `author-polls:index`将总是解析到`author-polls`实例的index页面。&lt;br&gt;**URL命名空间和included URLconfs**included URLconfs的应用程序命名空间可通过两种方式指定：- 首先，你可在 included URLconf 中设置一个 `app_name` 属性，它与 `urlpatterns` 属性同级。```py# polls/urls.pyfrom django.urls import pathform . import viewsapp_name = &apos;polls&apos;urlpatterns = [ path(&apos;&apos;, views.IndexView.as_view(), name=&apos;index&apos;), ...]# urls.pyfrom django.urls import include, pathurlpatterns = [ path(&apos;polls/&apos;, include(&apos;polls.urls&apos;))] 编写视图docs: https://docs.djangoproject.com/zh-hans/2.1/topics/http/views/ 视图函数，或 view short，是一个简单的Python函数——接收一个Web request，并返回一个Web response。这个response可以是HTML内容的Web页面，重定向，404错误，XML文档或图像…视图本身包含任意的逻辑是必要的返回响应。此代码可以选择你想要的任何地方，只要它是你的Python路径。对于将代码放在何处，默认的约定是把视图放在views.py文件中。 一个简单的视图一个简单的视图，返回当期的日期和时间: 1234567from django.http import HttpResponseimport datetimedef current_datetime(request): now = datetime.datetime.now() html = "&lt;html&gt;&lt;body&gt;It is now %s.&lt;/body&gt;&lt;/html&gt;" % now return HttpResponse(html) 让我们看看这个代码: 首先，我们从django.http模块导入了HttpResponse类，datetime库 接下来，我们定义了一个名为current_datetime的函数。这是视图函数，每个视图函数都接收一个HttpRequest对象作为第一个参数，通常称为请求request。注意，视图函数的名称并不重要，它并没有以某种方式按顺序命名的Django来识别它。我们在这里调用current_datetime，因为这个名字清楚地表明它做什么。 此视图返回一个包含生成的响应的HttpResponse对象。每个视图函数负责返回HttpResponse对象。 Django’s Time ZoneDjango includes a TIME_ZONE setting that defaults to America/Chicago. This probably isn’t where you live, so you might want to change it in your settings file. 映射URLs到视图因此，要回顾一下，这个视图函数返回一个HTML页面，其中包括当前的日期和时间。要显示此视图的特定URL，你需要创建一个URLconf。 返回错误在Django中返回HTTP error codes很容易。存在其它常见的HTTP状态码的HttpResponse子类(subclasses)。可在文档中找到所有可用的子类。 12345678from django.http import HttpResponse, HttpResponseNotFounddef my_view(request): # ... if foo: return HttpResponseNotFound('&lt;h1&gt;Page not found&lt;/h1&gt;') else: return HttpResponse('&lt;h1&gt;Page was found&lt;/h1&gt;') 没有对每个可能的HTTP响应码一个专门的子类，由于HttpResponse文档中，还可通过HTTP状态码到构造函数的HttpResponse创建你喜欢的任何状态码: 1234from django.http import HttpResponsedef my_view(request): return HttpResponse(status=201) 由于404错误是目前最常见的HTTP错误，处理它有简单的方法。 The Http404 exception class django.http.Http404 当你返回一个如HttpResponseNotFound的错误，你负责定义产生的错误页面的HTML: 12345678910from django.http import Http404from django.shortcuts import renderfrom polls.models import Polldef detail(request, poll_id): try: p = Poll.objects.get(pk=poll_id) except Poll.DoesNotExist: raise Http404("Poll does not exist") return render(request, 'polls/detail.html', &#123;'poll': p&#125;) 当Django返回一个404时，为了显示自定义的HTML，你可以创建一个名为 404.html的模板并放在模板树顶层。 自定义错误视图Django的默认错误应该能满足大多数情况，但你也可以自定义行为。 1234567891011# page_not_found()视图会被 handler404覆盖handler404 = 'mysite.views.my_custom_page_not_found_view'# server_error()视图会被handler500覆盖handler500 = 'mysite.views.my_custom_error_view'# permission_denied()视图会被handler403覆盖handler403 = 'mysite.views.my_custom_permission_denied_view'# bad_request()会被handler400覆盖handler400 = 'mysite.views.my_custom_bad_request_view' 参见Use the CSRF_FAILURE_VIEW setting to override the CSRF error view. 测试自定义错误视图 为了测试自定义错误处理程序的响应，提高在测试视图中的相应的异常: 12345678910111213141516171819202122232425262728from django.core.exceptions import PermissionDeniedfrom django.http import HttpResponsefrom django.test import SimpleTestCase, override_settingsfrom django.urls import pathdef response_error_handler(request, exception=None): return HttpResponse('Error handler content', status=403)def permission_denied_view(request): raise PermissionDeniedurlpatterns = [ path('403/', permission_denied_view),]handler403 = response_error_handler# ROOT_URLCONF must specify the module that contains handler403 = ...@override_settins(ROOT_URLCONF=__name__)class CustomErrorHandlerTests(SimpleTestCase): def test_handler_renders_template_response(self): response = self.client.get('/403/') # Make assertions on the response here. For example: self.assertContains(response, 'Error handler content', status_code=403) 视图装饰器docs: https://docs.djangoproject.com/zh-hans/2.1/topics/http/decorators/ Django提供了可应用于视图，以支持各种HTTP特征的几个装饰器(decorators)。 允许HTTP方法django.views.decorators.http中的装饰器可用于限制访问基于请求方法的视图。如果条件不具备装饰器会返回django.http.HttpResponseNotAllowed。 require_http_methods(request_method_list) 123456from django.views.decorators.http import require_http_methods@require_http_methods(["GET", "POST"])def my_view(request): # I can assume now that only GET or POST requests make it this far pass require_GET()：装饰器要求视图只接受GET方法 require_POST()：装饰器要求视图只接受POST方法 require_safe()：装饰器要求视图只接受GET和HEAD方法。这些方法通常被认为是安全的的。 条件视图处理装饰器django.views.decorators.http可用来控制特定视图的缓存行为。 condition(etag_func=None, last_modified_func=None) etag(etag_func) last_modified(last_modified_func) 这些装饰器可用来生成ETag和Last-Modified headers。 GZip压缩装饰器django.views.decorators.gzip在每个视图上控制内容压缩。 gzip_page()：如果浏览器允许使用gzip压缩，这个装饰器压缩内容。 Vary Headers装饰器django.views.decorators.vary可用于根据特定请求头来控制缓存。 vary_on_cookie(func) vary_on_headers(*headers) 缓存装饰器django.views.decorators.chache控制服务器和客户端的缓存。 cache_control(**kwargs)：此装饰器加入所有的关键字参数给它修补响应的Cache-Control头 never_cache(view_func)： 此装饰器添加Cache-Control: max-age=0, no-cache, no-store, must-revalidate头为响应指示页面不该被缓存。 文件上传docs: https://docs.djangoproject.com/zh-hans/2.1/topics/http/file-uploads/ Django处理文件上传时，文件最终会位于attr:request.FILES&lt;django.http.HttpRequest.FILES&gt; 快捷函数docs: https://docs.djangoproject.com/zh-hans/2.1/topics/http/shortcuts/ 包django.shortcuts收集助手函数或跨堆积MVC的类。换句话说，为了方便起见，这些函数/类引入受控耦合。 render() `render(request, template_name, context=None, content_type=None, status=None, using=None)：将给定的模板与给定的上下文字典组合在一起，并以渲染的文本返回一个HttpResponse对象。 12345678910# 必选参数request: 用于生成此响应的请求对象template_name: 要使用的模板名称# 可选参数context: 要添加到模板上下文的值的字典content_type 用于结果文档的MIME类型默认行为status: 响应的状态码，默认200using: 用于加载模板的模板引擎 栗子: 12345from django.shortcuts import renderdef my_view(request): # view code here return render(request, 'myapp/index.html', &#123;'foo': 'bar'&#125;, content_type='application/xhtml+xml') 此栗子相当于: 12345678from django.http import HttpResponsefrom django.template import loaderdef my_view(request): # view code here... t = loader.get_template('myapp/index.html') c = &#123;'foo': 'bar'&#125; return HttpResponse(t.render(c, request), content_type'application/xhtml+xml) redirect()12345678redirect(to, permanent=False, *args, **kwargs)# 将一个HttpResponseRedirect返回传递到参数的适当URL- A model: the model&apos;s get_absolute_url() function will be called.- A view name, possibly with arguments: reverse() will be used to reverse-resolve the name.- An absolute or relative URL, which will be used as-is for the redirect location.By default issues a temporary redirect; pass permanent=True to issue a permanent redirect. 栗子: 你可以在多种方式中使用redirect()函数。 123456789101112131415161718192021222324252627282930# By passing some object; that object's get_absolute_url() method will be called to figure out the redirect URLfrom django.shortcuts import redirectdef my_view(request): ... obj = MyModel.objects.get(...) return redirect(obj)# By passing the name of a view and optionally some positional or keyword arguments; the URL will be reverse resolved using the reverse() methoddef my_view(request): ... return ridirect('some-view-name', foo='bar')# By passing a hardcoded URL to redirect todef my_view(request): ... return redirect('/some/url/')# This also works with full URLsdef my_view(request): ... return redirect('https://example.com/')# 默认情况下，redirect()返回一个临时重定向。设置parmanent=True修改为永久def my_view(request): ... obj = MyModel.objects.get(...) return redirect(obj, permanent=True) get_object_or_404()1234567get_object_or_404(klass, *args, **kwargs)# Calls get() on a given model manager, but it raises Http404 instead of the model's DoesNotExist exception.# 必选参数klass # A Model class, a Manager, or a QuerySet instance from which to get the object.**kwargs # Lookup parameters, which should be in the format accepted by get() and filter(). 栗子: 1234567891011121314from django.shortcuts import get_object_or_404def my_view(reqeust): obj = get_object_or_404(MyModel, pk=1)# 此栗相当于from django.http import Http404def my_view(request): try: obj = MyModel.objects.get(pk=1) execpt MyModel.DoesNotExist： raise Http404("No MyModel matches the given query.") get_list_or_404()1234567get_list_or_404(lkass, *args, **kwargs)# Returns the result of filter() on a given model manager cast to a list, raising Http404 if the resulting list is empty.# 必选参数klass # A Model, Manager or QuerySet instance from which to get the list.**kwargs # Lookup parameters, which should be in the format accepted by get() and filter(). 栗子: 1234567891011121314# Get all published objects from MyModelfrom django.shortcuts import get_list_or_404def my_view(request): my_objects = get_list_or_404(MyModel, published=True)# 此栗子相当于from django.http import Http404def my_view(reqeust): my_objects = list(MyModel.objects.filter(published=True)) if not my_objects: raise Http404("No MyModel matches the given query.") 通用视图docs: https://docs.djangoproject.com/zh-hans/2.1/topics/http/generic-views/docs: https://docs.djangoproject.com/zh-hans/2.1/ref/class-based-views/ 基本视图与通用视图Base class-based views 可以被认为是父视图，其可以通过本身被使用，或者从继承。它们可能不提供所有项目所需要的功能，在这种情况下，有混入其中的扩至基视图可以做。 Django generic views are built off of those base views，被开发作为一个快捷功能，用于公共使用模式（如显示对象的详细信息）。They take certain common idioms and patterns found in view development and abstract them so that you can quickly write common views of data without having to repeat yourself.大多数的通用视图需要QuerySet键——它是一个QuerySet实例。 中间件docs: https://docs.djangoproject.com/zh-hans/2.1/topics/http/middleware/内检中间件: https://docs.djangoproject.com/zh-hans/2.1/ref/middleware/ 中间件是Django 请求/响应 处理的钩子框架。它是一个轻量级的、低级的插件系统，用于全局改变Django的输入或输出。 每个中间件组件负责做一些特定的功能。如Django的一个中间件组件AuthenticationMiddleware，它使用会话将用于与请求关联起来。文档中解释了中间件是如何工作的，如何激活中间件，如何编写自己的中间件。Django具有一些内置的中间件，你可以直接使用它们。 如何使用会话sessions: https://docs.djangoproject.com/zh-hans/2.1/topics/http/sessions/ Django是支持匿名会话的。会话框架允许你基于每个站点访问者存储和检索任意数据。它在服务端存储数据并提供cookie的发送和接收。Cookie包含会话ID，而不是数据本身。 打开会话会话通过配置一个中间件(django.contrib.sessions.middleware.SessionMiddleware)实现。 使用表单docs: https://docs.djangoproject.com/zh-hans/2.1/topics/forms/ 介绍Web表单的基本内容以及它们在Django中是如何处理的。 除非搭建的网站和应用只发布内容而不接收访问者的输入，否则你就需要理解和使用表单。Django提供了一系列的工具和库来帮助构建表单来接收网站访问者的输入，然后处理以及响应这些输入。 HTML表单在HTML中，表单是在&lt;form&gt;...&lt;/form&gt;中的一些元素，它允许访客做一些类似输入文档、选择选项、操作对象或空间等动作，然后发送这些信息到服务端。 一些表单界面元素(文本框或复选框)非常简单并内置在HTML中。其它会复杂些，如弹出日期选择、允许你移动滑块或操作控件，一般通过使用JavaScript，CSS以及HTML表单中的&lt;input&gt;元素来实现这些效果。 表单必须指定两样东西: 何地: 负责响应用户输入数据的URL地址 如何: 数据如何请求使用的HTTP方法 1234567例如，Django admin登录表单包含了一些&lt;input&gt;元素：用户名用type=&quot;text&quot;，密码用type=&quot;password&quot;，登录按钮用type=&quot;submit&quot;。它还包含一些用户看不到的隐藏文本字段，Django用它们来决定下一步行为。它还告诉浏览器表单数据应该发往&lt;form&gt;的action属性指定的URL——`/admin/`，并且应该使用method属性指定的HTTP方法——post。当&lt;input type=&quot;submit&quot; value=&quot;Log in&quot;&gt;元素被触发的时候，数据会发送到`/admin/`。 GET和POST 处理表单时只会用到GET和POST两种方法。Django的登录表单使用POST方法传输数据，在这个方法中浏览器会封装表单数据，为了传输会进行编码，然后发送到服务端并接收它的响应。 相比之下，GET方法将提交的数据捆绑到一个字符串中，并用它来组成一个URL。该URL包含了数据要发送的地址以及一些键值对应的数据。如https://docs.djangoproject.com/search/?q=forms&amp;release=1 任何可用于更改系统状态的请求都应该使用POST。GET方法也不适合密码表单，因为密码会出现在URL中，也是也会出现在浏览器的历史记录以及服务器的日志中，而且都是以纯文本都形式。它也不适合处理大量的数据或者二进制数据。在Web应用的管理表单中使用GET请求具有安全隐患：攻击者很容易通过模拟请求来访问系统的敏感数据。POST方法通过与其它像CSRF这样的保护措施配合使用，能对访问提供更多控制。 Django在表单中的角色处理表单是一件挺复杂的事情。许多不同的数据可能在一张表单中准备显示，渲染成HTML，使用方便的界面进行编辑，传到服务器，验证和清理数据，然后保存或跳过进行下一步处理。 Django会处理设计表单的三个不同部分: 准备并重组数据，以便下一步的渲染 为数据创建HTML表单 接收并处理客户端提交的表单和数据 你可以手动编写代码来实现，但Django可以帮你完成所有这些工作。 Django中的表单Web应用中所说的表单，可能指的是HTML &lt;form&gt;，或者是生成了它的Django Form，再或者是提交时返回的结构化数据，亦或是这些端到端作业的合集。 Django的Form类 Django表单系统的核心组件是Form类。它与Django模型描述对象的逻辑结构、行为以及它呈现给我们内容的形式的方式大致相同，Form类描述一张表单并决定它如何工作及呈现。类似于模型类的字段映射到数据库字段的方式，表单类的字段会映射到HTML表单的&lt;input&gt;元素。ModelForm通过Form映射模型类的字段到HTML表单的&lt;input&gt;元素。表单字段本身也是类，他们管理表单数据并在提交表单时执行验证。DateField和FileField处理的数据类型差别很大，所以必须用来处理不同的字段。在浏览器中，表单字段以HTML控件的形式展示给我们。每个字段类型都有与之相匹配的控件类，但必要时可以覆盖。 实例化、处理和渲染表单 在Django中渲染一个对象的时候，我们通常： 在视图中获取它 将它传递给模板上下文 使用模板变量将它扩展为HTML标记 在模板中渲染表单几乎与渲染任何其他类型的对象的一样，但是存在一些关键性的差异。如果模型实例不包含数据，在模板中对它做任何处理几乎没什么用。但完全有理由用来渲染一张空表单——当我们希望用户来填充的时候就会这么做。所以当我们在视图中处理模型实例时，我们一般从数据库中获取它。当我们处理表单时，我们一般在视图中实例化它。 当我们实例化表单时，我们可以选择让它为空或者对它预先填充： 来自已经保存的模型实例的数据 从其它来源获取的数据 从前面一个HTML表单提交过来的数据 构建一张表单需要完成的工作 假设你希望在你的网站上创建一张简易的表单，来获取用户的名字： 12345&lt;form action=&quot;/your-name/&quot; method=&quot;post&quot;&gt; &lt;label for=&quot;your_name&quot;&gt;Your name: &lt;/label&gt; &lt;input id=&quot;your_name&quot; type=&quot;text&quot; name=&quot;your_name&quot; value=&quot;&#123;&#123; current_name &#125;&#125;&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;OK&quot;&gt;&lt;/form&gt; 这告诉浏览器将表单数据返回给URL /your-name/，并使用POST方法。它将显示一个标签为”Your name:”的文本字段，以及一个”OK”按钮。如果模板上下文包含一个current_name变量，它会被预填充到your_name字段。你需要一个视图来渲染这个包含HTML表单的模板，并能适当提供current_name字段。提交表单时，发送给服务器的POST请求将包含表单数据。 现在，你还需要一个与该/your-name/ URL相对应的视图，该视图将在请求中找到相应的键值对，然后对其进行处理。 在Django中构建一张表单 Form类 12345678910# forms.pyfrom django import formsclass NameForm(forms.Form): your_name = forms.CharField(label='Your name', max_length=100)# Form表单实例有一个`is_valid()`方法，它运行所有的字段验证。当此方法被调用时，如果所有字段包含有效数据，它将会：# - 返回True# - 将表单数据放到它的cleaned_data属性中 这样整个表单在第一次渲染时，会显示如下: 12&lt;lable for=&quot;your_name&quot;&gt;Your name: &lt;/label&gt;&lt;input id=&quot;your_name&quot; type=&quot;text&quot; name=&quot;your_name&quot; maxlength=&quot;100&quot; required&gt; 注意它没有包含&lt;form&gt;标签和提交按钮。我们必须在模板中提供。 视图 发回Django网站的表单数据由视图来处理，一般和发布这个表单用的是同一个视图。这允许我们重用一些相同的逻辑。 为了处理表单，我们需要将它实例化到我们希望发布的URL的对应的视图中： 1234567891011121314151617181920212223# views.pyfrom django.http import HttpResponseRedirectfrom django.shortcuts import renderfrom .forms import NameFormdef get_name(request): # if this is a POST request we need to process the form data if request.method == 'POST': # create a form instance and populate it with data from the request form = NameForm(request.POST) # check whether it's valid if form.is_valid(): # process the data in form.cleaned_data as required # ... # redirect to a new URL return HttpResponseRedirect('/thanks/') else: form = NameForm() return render(request, 'name.html', &#123;'form': form&#125;) 如果我们访问这个视图用的是GET请求，它会创建一个空的表单实例并将其放置在模板上下文中进行渲染。如果表单提交用的是POST请求，那么该视图再次创建一个表单实例并使用请求中的数据填充它。form=NameForm(request.POST)，这叫绑定数据到表单。调用表单的is_valid()方法，如果不为True，就带着表单返回到模板。这次表单不在为空，所以HTML表单将用之前提交的数据进行填充，放到可以根据需要进行编辑和修正的位置。如果is_valid()为True，我们就能在cleaned_data属性中找到所有通过验证的表单数据。我们可以发送一个HTTP重定向告诉浏览器下一步去向之前用这些数据更新数据库或做其它处理。 模板 没有必要在模板name.html中做过多的操作。举个栗子: 12345&lt;form action=&quot;/your-name/&quot; method=&quot;post&quot;&gt; &#123;% csrf_token %&#125; &#123;&#123; form &#125;&#125; &lt;input type=&quot;submit&quot; value=&quot;Submit&quot;&gt;&lt;/form&gt; 所有的表单字段机器属性都将通过Django模板语言从 中被解包成HTML标记。 表格和跨站请求伪造保护Django自带一个简单易用的跨站请求伪造保护。当通过POST方法提交一张启用了CSRF防护的表单时，你必须使用上例中这样的模板标签 csrf_token。但是，由于CSRF防护在模板中没有与表单直接绑定，因此这个标签在本页文档之后的示例中都将被忽略。 现在我们有了一个可以工作的Web表单，它通过一张Django Form描述，由一个视图来处理并渲染成一个HTML &lt;form&gt;。 详解Django的Form类所有表单都作为django.forms.Form或者django.forms.ModelForm的子类来创建。 如果你的表单是要直接用来添加或编辑Django模型，用ModelForm，可以省时省力省代码，因为它会根据Model类构建一张对应字段及其属性的表单。 绑定和未绑定的表单实例 bound和unbound forms之间的区别非常重要： 未绑定的表单没有与其关联的数据。当渲染给用户时，它会是空的或者包含默认值。 绑定的表单拥有已提交的数据，因此可用来判断数据是否合法。 表单的is_bound属性将告诉你一张表单是否具有绑定的数据。 字段详解 栗子: 12345678# forms.pyfrom django import formsclass ContactForm(forms.Form): subject = forms.CharField(max_length=100) message = forms.CharField(widget=forms.Textarea) sender = forms.EmailField() cc_myself = forms.BooleanField(required=False) 控件 每个表单字段都有一个相对应的控件类，这个控件类又有对应的HTML表单控件，比如&lt;input type=&quot;text&quot;&gt;。 字段数据 无论用表单提交了什么数据，一旦通过调用is_valid()验证成功，已验证的表单数据将被放到form.cleaned_data字典中。这里的数据已经很好的为你转化为Python类型。如cc_myself会被转化成一个布尔值。同样的，字段 IntegerField 和 FloatField 的值分别会被转化为Python的 int 和 float 类型。 栗子: 123456789101112131415# views.pyfrom django.core.mail import send_mailif form.is_valid(): subjetct = form.cleaned_data['subject'] message = form.cleaned_data['message'] sender = form.cleaned_data['sender'] cc_myself = form.cleaned_data['cc_myself'] recipients = ['info@example.com'] if cc_myself: recipients.append(sender) send_mail(subject, message, sender, recipients) return HttpResponseRedirect('/thanks/') 使用表达模板你只需要将表单实例放到模板的上下文中即可。 表单渲染选项 额外表单模板标签不要忘记，一张表单的输出不包含外层&lt;form&gt;标签以及submit控件。这些必须由你自己提供。 对于&lt;label&gt;, &lt;input&gt;对，还有其它输出选项： form.as_table &#125;&#125;```将渲染它们作为表格包裹在``标记中12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455- ```&#123;&#123; form.as_p &#125;&#125;```将渲染它们包裹在`&lt;p&gt;`标记中- ```&#123;&#123; form.as_ul &#125;&#125;```将渲染它们包裹在`&lt;li&gt;`标记中注意，你必须自己提供外层的`&lt;table&gt;`或`&lt;ul&gt;`元素。&lt;br/&gt;&lt;br/&gt;---&lt;br/&gt;&lt;br/&gt;# 模板templates: &lt;https://docs.djangoproject.com/zh-hans/2.1/topics/templates/&gt;作为一个Web框架，Django需要一种动态生成HTML的便捷方法。最常用的方法依赖于模板。模板包含所需HTML输出的静态部分以及描述动态内容将被插入的一些特殊语法。Django项目可以配置一个或多个模板引擎（或者不使用模板引擎）。Django后端内置一个自己的模板系统，创造性地称为Django Template Language(DTL)。后端也可以使用第三方提供的其它可用的模板语言。Django template language是Django自己的模板系统。这是一个很好的模板库，即使它是相当僵硬和使用时带有它自己特质。如果你没有紧迫的理由需要去选择另一个后端，则应该使用DTL。Django定义了一个标准的API，用于加载和渲染模板，而不用考虑后端的模板系统。加载包括查找给定标识符的模板并对其进行预处理，通常将其编译的结果保存在内存中。渲染工具将上下文数据插入模板并返回结果字符串。&lt;br/&gt;## 模板引擎的支持```pyTEMPLATES = [ &#123; &apos;BACKEND&apos;: &apos;django.template.backends.django.DjangoTemplates&apos;, &apos;DIRS&apos;: [], &apos;APP_DIRS&apos;: True, &apos;OPTIONS&apos;: &#123; # ... some options here ... &#125;, &#125;,]# BACKEND: 实现Django模板后台API，内建后台有:# - django.template.backends.django.DjangoTemplates# - django.template.backends.jinja2.Jinja2# DIRS: 定义一个目录列表，其中模板引擎应该寻找的源文件# APP_DIRS: 告诉引擎是否应该在安装的应用内寻找模板 Django Template Language参考: https://docs.djangoproject.com/zh-hans/2.1/topics/templates/ https://docs.djangoproject.com/zh-hans/2.1/ref/templates/language/ Django模板引擎提供了一种强大的mini-language，用于定义应用程序的面向用户层，鼓励应用程序和表示逻辑的清晰分离。任何了解HTML的人都可以维护模板，不需要Python的知识。 Django模板语言其实和Jinja2类似，只不过Jinja2更自由些。 Django模板语言本文档解释了Django模板系统的语言语法。Django的模板语言只在功能和易用性之间取得平衡。它旨在让那些习惯使用HTML的人感到舒服。如果你对其它模板语言(Smart, Jinja2)有任何接触，那么您应该对Django的模板感到宾至如归。 哲学Django模板系统不仅仅是嵌入到HTML中的Python。模板系统用于表示，而不是程序逻辑。Django模板系统提供的tags功能与某些编程结构类似——if标签用于布尔测试，for标签用于循环…但这些并不是简单地作为相应的Python代码执行，并且模板系统不会执行任意Python表达式。 模板Templates 一个模板是一个简单的文本文件。它可以生成任何基于文本的格式(HTML, XML, CSV…)。 模板包含变量(variables)，这些变量在评估模板时将替换为值，而变量则包含控制模板逻辑的标签(tags)。 下面是一个最小的模板示例，每个元素将在后面解释。 12345678910111213141516&#123;% extends &quot;base_generic.html&quot; %&#125;&#123;% block title %&#125;&#123;&#123; section.title &#125;&#125;&#123;% endblock %&#125;&#123;% block content %&#125;&lt;h1&gt;&#123;&#123; section.title &#125;&#125;&lt;/h1&gt;&#123;% for story in story_list %&#125;&lt;h2&gt; &lt;a href=&quot;&#123;&#123; story.get_absolute_url &#125;&#125;&quot;&gt; &#123;&#123; story.headline|upper &#125;&#125; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&#123;&#123; story.tease|truncatewords:&quot;100&quot; &#125;&#125;&lt;/p&gt;&#123;% endfor %&#125;&#123;% endblock %&#125; 为什么使用基于文本而不是基于XML的模板？我们希望Django的模板语言不仅可用于XML/HTML模板。在互联网上，我们将其用于电子邮件、JS和CSV。你可将模板语言用于任何基于文本的格式。让人类编辑XML是虐待狂! 变量Variables 变量像这样: variable &#125;&#125;```。当模板引擎遇到变量时，它会计算该变量并将其替换为结果。变量名由字母、数字和下划线组成，但不能以下划线开头。点(`.`)也出现在变量部分，尽管它具有特殊含义。重要的是，变量名称中不能包含空格或标点符号。1234567891011121314151617181920212223242526272829303132333435363738394041从技术上来说，当模板系统遇到一个点时，它会按照一下顺序尝试查找:- 字典- 属性或方法- 数字索引在上面的例子中，```&#123;&#123; section.title &#125;&#125;```将替换为section对象的title属性。如果使用不存在的 变量，模板系统将插入`srting_if_invalid`选项的值，默认情况下设置为空`&apos;&apos;`。请注意，模板表达式```&#123;&#123; foo.bar &#125;&#125;```中的bar将被解释为文字字符串，而不使用变量bar的值(如果上下文中存在)。可能无法访问以下划线开头的变量属性，因为它们通常被视为私有。&lt;br/&gt;&lt;br/&gt;## 过滤器Filters你可使用过滤器(filters)修改要显示的变量。过滤器像这样: ```&#123;&#123; name|lower &#125;&#125;```。这会在通过小写过滤器后显示变量的值，后者将文本转换为小写。使用管道(`|`)应用过滤器。过滤器可以链接，一个过滤器的输出应用于下一个过滤器。```&#123;&#123; text|escape|linebreaks &#125;&#125;```。```&#123;&#123; text|escape|linebreaks &#125;&#125;```是转义文本内容，然后将换行符转换为`&lt;p&gt;`标签的常用习惯写法。一些过滤会使用参数，过滤器参数如下所示: ```&#123;&#123; bio|truncatewords:30 &#125;&#125;```，这将显示变量bio的前30个单词。过滤参数包含的空格必须使用引号引用，如: ```&#123;&#123; list|join:&quot;, &quot; &#125;&#125;```。Django提供了大约60个内置模板过滤器。可在[built-in filter reference](https://docs.djangoproject.com/zh-hans/2.1/ref/templates/builtins/#ref-templates-builtins-filters)查看全部。以下是一些常用的模板过滤器:- default如果变量为false或者为空，使用给定的默认值。```jinja2&#123;&#123; value|default:&quot;nothing&quot; &#125;&#125; length返回值得长度，使用与strings和lists。 1&#123;&#123; value|length &#125;&#125; filesizeformat将值格式化为人类可读的文件大小(12KB, 2MB…) 1&#123;&#123; value|filesizeformat &#125;&#125; 当然，你可以创建自己的自定义模板过滤器。 标记Tags 标记像这样: tag %&#125;```。标签比变量更复杂：有些在输出中创建文本，有些通过执行循环或逻辑来控制流，有些则将外部信息加载到模板中以供以后的变量使用。12345678910111213141516有些标签需要开始和结束标记: ```&#123;% tag %&#125;```...```&#123;% endtag %&#125;```。Django附带了大约24个内置模板标签。可查看[build-in tag reference](https://docs.djangoproject.com/zh-hans/2.1/ref/templates/builtins/#ref-templates-builtins-tags)。下面是一些常用的标记:- for循环遍历数组中的每个项。```jinja2&lt;ul&gt;&#123;% for athlete in athlete_list %&#125; &lt;li&gt;&#123;&#123; athlete.name &#125;&#125;&lt;/li&gt;&#123;% end for %&#125;&lt;/ul&gt; if, elif, else 1234567&#123;% if athlete_list %&#125; Number of athletes: &#123;&#123; athlete_list|length &#125;&#125;&#123;% elif athlete_in_locker_room_list %&#125; Athletes should be out of the locker room soon!&#123;% else %&#125; No athletes.&#123;% enfif %&#125; 可在if标记中使用过滤器和操作符: 12345&#123;% if athlete_list|length &gt; 1 %&#125; Team: &#123;% for athlete in athlete_list %&#125; ... &#123;% endfor %&#125;&#123;% else %&#125; Athlete: &#123;&#123; athlete_list.0.name &#125;&#125;&#123;% endif %&#125; block, extends设置模板继承template inheritance，这是一种在模板中减少样板(boilerplate)的强大方法。 你可以创建自己的自定义模板标记。 注释Comments 注释的语法为: #&#125;```。12345678910111213141516171819202122232425262728293031323334353637383940例如，此模板将呈现为hello: ```&#123;# greeting #&#125;hello```。&lt;br/&gt;&lt;br/&gt;## 模板继承Templates inheritanceDjango模板引擎最强大，也是最复杂的就是模板继承。模板继承允许你构建一个基础骨架模型，其中包含站点的所有常用元素(elements)，并定义子模块可以覆盖的块(block)。理解模板继承的栗子(`base.html`):```jinja2&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;style.css&quot;&gt; &lt;title&gt;&#123;% block title %&#125;My amazing site&#123;% endblock %&#125;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=&quot;sidebar&quot;&gt; &#123;% block sidebar %&#125; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/&quot;&gt;Home&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/blog/&quot;&gt;Blog&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &#123;% endblock %&#125; &lt;/div&gt; &lt;div id=&quot;content&quot;&gt; &#123;% block content %&#125;&#123;% endblock %&#125; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 定义了一个简单的HTML框架文档，你可将其用于简单的双列页面。子模板的工作是用内容填充空块(empty block)。在此示例中，块标记(block)定义了子模块可以填充的三个块。所有块标记的作用是告诉模板引擎子模块可以覆盖模板的这些部分。 子模板栗子: 12345678910&#123;% extends &quot;base.html&quot; %&#125;&#123;% block title %&#125;My amazing blog&#123;% endblock %&#125;&#123;% block content %&#125;&#123;% for entry in blog_entries %&#125; &lt;h2&gt;&#123;&#123; entry.title &#125;&#125;&lt;/h2&gt; &lt;p&gt;&#123;&#123; entry.body &#125;&#125;&lt;/p&gt;&#123;% endfor %&#125;&#123;% endblock %&#125; 扩展标记(extends)是这里的关键。它告诉模板引擎改模板扩展另一个模板。当模板系统评估此模板时，它首先找到父模板。 此时，模板引擎会注意到base.html中的三个块标记，并将这些块替换为子模板的内容。输出可能如下: 123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html lange=&quot;en&quot;&gt;&lt;head&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;style.css&quot;&gt; &lt;title&gt;My amazing blog&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=&quot;sidebar&quot;&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/&quot;&gt;Home&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/blog/&quot;&gt;Blog&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div id=&quot;content&quot;&gt; &lt;h2&gt;Entry one&lt;/h2&gt; &lt;p&gt;This is my first entry.&lt;/p&gt; &lt;h2&gt;Entry two&lt;/h2&gt; &lt;p&gt;This is my second entry.&lt;/p&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 请注意，由于子模块未定义sidebar块，因此将使用父模板中的值。 你可以根据需要使用尽可能多的继承级别。使用继承的一种常见方法是以下三级(three-level)方法: 创建base.html基础模板，其中包含网站的主要外观 为网站的每个部分(section)创建一个base_SECTIONNAME.html模板，这些模板都扩展基础模板，并包含特定于部分的样式设计 为每种类型的页面创建单独的模板，这些模板扩展了相应部分的模板 这种方法可以最大化代码重用，并且可以轻松地将项目添加到共享内容区域。 以下是使用继承的一些技巧与提示: 如果在模板中使用extends %&#125;```，则它必须是该模板中的第一个模板标记。否则，模板继承不起作用。12345678- 基础模板中的```&#123;% block %&#125;```标记越多越好。请记住，子模块不必定义所有父块，因此你可在多个块中填写合理的默认值，然后仅定义需要的块。- 如果在许多模板中复制了内容，则可能意味着你应该将内容移动到父模板中的```&#123;% block %&#125;```。- 如果需要从父模板获取块的内容，```&#123;&#123; block.super &#125;&#125;```变量将起作用。如果要添加到父模块的内容而不是完全覆盖它，这将非常有用。- 使用模板标记`as`语法在```&#123;% block %&#125;```块之外创建的变量不能在块内使用。```jinja2&#123;% trans &quot;Title&quot; as title %&#125;&#123;% block conten %&#125;&#123;&#123; title &#125;&#125;&#123;% endblock %&#125; 为了提高可读性，可选择为endblock %&#125;```标记指定名称。在较大的模板中，此技术可帮助查看正在关闭的块标记。12345```jinja2&#123;% block content %&#125;...&#123;% endblock conten %&#125; 最后，请注意，你无法在同一模板中定义多个名称相同的块标记。 自动HTML转义Automatic HTML escaping 当从模板生成HTML时，变量将始终存在影响生成的HTML的字符的风险。 考虑这个模板片段:1Hello &#123;&#123; name &#125;&#125; 首先，这似乎是一种显示用户名的无害方式。但考虑如果用户输入其名称会发生什么: &lt;script&gt;alert(&#39;hello&#39;)&lt;/script&gt;使用此名称值，模板将呈现为: Hello, &lt;script&gt;alert(&#39;hello&#39;)&lt;/script&gt;这意味着浏览器会弹出一个JS警告框！ 类似地，如果名称包含&lt;符号: &lt;b&gt;username这将导致像这样的渲染模板: Hello, &lt;b&gt;username反过来，这将导致网页的其余部分被加粗。 显然，用户提交的数据不应盲目信任并直接插入到你的网页中，因为恶意用户可能会利用这种漏洞来做坏事。此类安全漏洞称为跨站点脚本(XSS, cross site scripting)攻击。 要避免此问题，有两种选择: 一，可以确保通过转义过滤器运行每个不受信任的变量，该过滤器可将可能有害的HTML字符转换为无害的HTML字符。这是Django最初几年的默认解决方案，但问题在于它让你有责任确保你逃避一切。 二，可利用Django的自动HTML转义功能。 默认情况下，Django中的每个模板都会自动转义每个变量标记的输出。具体来说，这五个字符被转义: &lt;被转换为&amp;lt; &gt;被转换为&amp;gt; &#39;被转换为&amp;#39; &quot;被转换为&amp;quot; &amp;被转换为&amp;amp; 同样，我们强调默认情况下已启用此行为。如果你正在使用Django的模板系统，那么你将受到保护。 如何关闭如果不想自动转义数据，则可通过多种方式将其关闭。 单独的变量(individual bariables)使用safe过滤器。 12This will be escaped: &#123;&#123; data &#125;&#125;This will not be escaped: &#123;&#123; data|safe &#125;&#125; 模板块(template block)将模板包装在autoescape标记中。它将on或off作为其参数。 123&#123;% autoescape off %&#125; Hello &#123;&#123; name &#125;&#125;&#123;% endautoescape %&#125; 字符串文字和自动转义String literals and automatic escaping 如前面所说，过滤参数可以是字符串:1&#123;&#123; data|default:&quot;This is a string literal.&quot; &#125;&#125; 访问方法调用Accessing method calls Most method calls attached to objects are also available from within templates. 这意味着，模板必须比类属性和从视图中传递的变量获得更多的访问。 123&#123;% for comment in task.comment_set.all %&#125; &#123;&#123; comment &#125;&#125;&#123;% endfor %&#125; 你可以轻松访问你明确对自己的模型定义的方法: 1234# models.pyclass Task(models.Model): def foo(self): return "bar" 1&#123;&#123; task.foo &#125;&#125; 自定义tag和filter库某些应用程序提供了自定义的标签和过滤器库。要访问这些模板，确保应用在INSTALLED_APPS中，然后在模板中使用load标记. 12&#123;% load humanize %&#125;&#123;&#123; 45000|intcomma &#125;&#125; load标记载入humanize标记库，然后就可以使用intcomma过滤器。 load标记可载入多个:1&#123;% load humanize i18n %&#125; 基于类的视图class-based-views: https://docs.djangoproject.com/zh-hans/2.1/topics/class-based-views/ 视图是可调用的，能接受用户的请求并返回响应。视图远不止是个函数，Django提供了一些可用作视图的类的示例，允许你通过继承和复用构建自己的视图并且复用这些代码。 基于类的视图intro: https://docs.djangoproject.com/zh-hans/2.1/topics/class-based-views/intro/ 基于类的视图提供了实现视图作为Python对象来替代函数。相比基于函数的视图，它们不取代基于函数的视图，但有一定的差异和优势： Organization of code related to specific HTTP methods (GET, POST, etc.) can be addressed by separate methods instead of conditional branching. Object oriented techniques such as mixins (multiple inheritance) can be used to factor code into reusable components. 内置的基于类的通用视图Built-in class-based generic views: https://docs.djangoproject.com/zh-hans/2.1/topics/class-based-views/generic-display/ 编写Web应用程序可以是单调的，因为我们一次又一次地重复某些模式。Django视图带走一些在模型和模板层千篇一律的单调，但Web开发者也在视图层级遇到了这些无聊的单调。 Django的通用视图被开发来缓解此问题。他们采取的在视图中开发和抽象的发现，让你能快速地编写普通视图，而无需编写大量代码。我们我们可以发现一些常见的任务，比如显示对象的列表，并编写任何对象列表的代码。然后有问题的模型可以作为一个额外的参数传递到URLconf。 Django自带的通用视图能做到以下几点： 为单个对象显示列表和详细页面。如果我们创建一个应用程序来管理会议，那么TalkListView和RegisteredUserListView就应是列表视图的栗子。一个单一的talk page是我们成detail view的例子。 在基于日期(year/month/day)归档页的对象，associated detail, and “latest” pages 允许用户创建、更新和删除对象——是否授权 总之，这些视图提供了方便的接口来执行最常见的任务，以帮助开发者解决遇到的问题。 基类视图和表单处理Form handling with class-based views: https://docs.djangoproject.com/zh-hans/2.1/topics/class-based-views/generic-editing/ 表单处理通常有3条路径： Initial GET (blank or prepopulated form) POST with invalid data (typically redisplay form with errors) POST with valid data (process the data and typically redirect) 实现此常常导致自己有大量重复的样板代码。为了帮助避免此情况，Django提供的通用基于类视图的集合来处理表单处理。 基类视图混入Using mixins with class-based views: https://docs.djangoproject.com/zh-hans/2.1/topics/class-based-views/mixins/ 警告这是一个高级的话题。 Django内置的基类视图提供了许多功能，但其中某些你可能要分开使用。例如，你可能想编写一个视图，来渲染模板生成HTTP response，但是你不能使用TemplateView。或许你需要渲染仅POST模板，GET是另外一回事。虽然你可直接使用TemplateResponse，这将有可能导致重复的代码。 出于这个原因，Django还提供了许多离散功能的混入。模板渲染，例如，被封装在TemplateResponseMixin。 例子Django提供了适合广泛应用的基视图类。所有视图从View class继承，它处理链接到URLs的视图，HTTP方法调度等简单功能的视图继承。RedirectView是一个简单的HTTP重定向，并且TemplateView扩展基类使其也呈现渲染的模板。 简单使用使用通用视图组件但的方法是直接在URLconf中创建它们。如果你只改变一个基类视图的几个简单属性，你可以简单地将它们传递到as_view()方法来调用自身： 123456from django.urls import pathfrom django.views.generic import TemplateViewurlpatterns = [ path('about/', TemplateView.as_view(template_name="about.html")),] 传递给as_view()的任何参数将覆盖在类中设置的属性。在此例中，在TemplateView设置template_name。类似的覆盖模式可用于RedirectView的url属性。 子类通用视图第二种，更强大的方式去使用通用视图是从现有视图继承和在子类中提供新值或方法覆盖属性或方法。 12345# some_app/views.pyfrom django.views.generic import TemplateViewclass AboutView(TemplateView): template_name = "about.html" 1234567# urls.pyfrom django.urls import pathfrom some_app.views import AboutViewurlpatterns = [ path('aboug/', AboutView.as_view()),] 支持其它HTTP方法123456from django.urls import pathfrom books.views import BookListViewurlpatterns = [ path('books/', BookListView.as_view()),] 1234567891011121314from django.http import HttpResponsefrom django.views.generic import ListViewfrom books.models import Bookclass BookListView(ListView): model = Book def head(self, *args, **kwargs): last_book = self.get_queryset().latest('publication_date') response = HttpResponse('') # RFC 1123 date format response['Last-Modified'] = last_book.publication_date.strftime('%a, %d %b %Y %H:%M:%S GMT') return response 迁移Migrations: https://docs.djangoproject.com/zh-hans/2.1/topics/migrations/ 迁移是将你对模型的改变传播到你的数据库架构的Django方法。它被设计的目的主要是自动，但你需要知道什么时候才能迁移。当运行它们，你可能会遇到常见的问题。 命令与迁移和Django处理数据库交互的几个命令： migrate：负责applying和unapplying migrations makemigrations: 负责创建一个基于你对你的模型所做的更改的新的迁移 sqlmigrate: 显示一个迁移的SQL语句 showmigrations: 列出项目迁移及其状态 你应该考虑迁移为你的数据库模式的版本控制系统。makemigrations是负责包装你的模型改变为个体迁移文件——类似于提交(commit)。migrate是负责应用(applying)你的数据库。每个应用程序的迁移文件位于该应用程序内部的migrations目录，设计于commit和sidtributed，他是代码库的一部分。你应该在你的开发机上运行它们一次，然后在你同事的机器上运行相同的迁移，并最终在生产机上运行。 后端支持迁移支持Django的所有后端。 PostgreSQL MySQL SQLite 工作流迁移的工作很简单。修改模型，然后运行makemigrations: 1python manage.py makemigrations 你的模型将被扫描，并且与当前包含在迁移文件的版本进行比较，然后一组新的迁移会被写出来。请务必阅读makemigrations的输出，它并不完美，对于复杂的变化可能无法检测到你所期望的那样。 一旦有了新的迁移文件，你应该把它们应用到你的数据库，以确保它们达到预期效果: 123456python manage.py migrateOperations to perform: Apply all migrations: booksRunning migrations: Rendering model states... DONE Applying books.0003_auto... OK 一旦迁移已应用，提交迁移和模型改变到你的版本控制系统作为一个单个提交(singel commit)。这样，当其他开发者check out代码时，他们将同时获得模型的改变并在同一时间执行迁移。你可以为迁移取一个有意义的名称: 1python manage.py makemigrations --name changed_my_model your_app_label 版本控制由于迁移是存储在版本控制中，你会偶尔遇到你和另一个开发人员在同一个应用上都有提交一个迁移，导致两个开发人员的迁移有相同迁移编号。别担心，这些数字编号只是在开发者那里参考，Django只关注每个迁移有一个不同的名称。迁移指定它们依赖于哪些迁移——包括同一应用前面的迁移。 发生这些情况时，Django会提示你，给你一些选项。 依赖虽然迁移的每个程序，通过你的模型隐含的表和关系太复杂，无法在同一时间仅一个程序创建。当你依赖别的东西来运行迁移，所产生的迁移将包含在迁移的依赖上。 在限制单一应用的依赖行为为影响大部分迁移操作。限制到一个单一应用(makemigrations or migrate)是尽力的承诺，而不是保证。需要任何其它程序使用，以获得正确的依赖。 迁移文件迁移存储为磁盘上的格式，这里成为迁移文件(migration file)。这些文件实际上是商定布局和声明样式的普通的Python文件。 一个基本的迁移文件: 12345678910from django.db import migrations, modelsclass Migration(migrations.Migration): dependencies = [('migrations', '0001_initial')] operations = [ migrations.DeleteModel('Tribble'), migrations.AddField('Author', 'rating', models.IntegerField(default=0)), ] 向应用添加迁移向新应用添加迁移很简单，一旦你做了一些改动，只需运行makemigrations。 如果你的应用已经有模型和数据库表，并且没有迁移。你需要转化它使用迁移，一个例子: python manage.py makemigrations your_app_label这将为你的应用执行一个新的初始迁移。现在，执行python manage.py migrate --fake-initial，Django会检测你有一个初始迁移，它想创建的表已经存在，并将标识这些迁移为已经应用。 注意，这仅适用于给定的两件事： 你创建了表但没有改变你的模型。 你没有手动编辑你的数据库——Django将无法检测到与模型不匹配的数据库，你只得到迁移错误时尝试修改这些表。 历史模型当运行迁移时，Django是从存储在迁移文件中的模型的历史版本进行工作。 数据迁移与改变数据库模式一样，你也可以使用迁移数据库本身的数据。这通常称为数据迁移，最好把它写成单独地迁移，刚在模型架构迁移的旁边。Djaong不能为你自动生成数据迁移。 首先，生成一个空的迁移文件: 1python manage.py makemigrations --empty yourappname 接着，打开此文件: 1234567891011# Generated by Django A.B on YYYY-MM-DD HH:MMfrom django.db import migrationsclass Migration(migrations.Migration): dependencies = [ (&apos;yourappname&apos;, &apos;0001_initial&apos;), ] operations = [ ] 管理文件Managing files: https://docs.djangoproject.com/zh-hans/2.1/topics/files/ 此文档描述那些由用户上传的Django的文件的访问API。 测试Testing in Django: https://docs.djangoproject.com/zh-hans/2.1/topics/testing/ 用户认证Django Auth: https://docs.djangoproject.com/zh-hans/2.1/topics/auth/ Django自带了一个用户认证系统。它处理用户账户、组、权限和基于cookie的用户会话。这一部分文档介绍了如何实现开箱即用。 缓存框架Cache framework: https://docs.djangoproject.com/zh-hans/2.1/topics/cache/ 条件视图处理Conditional view processing: https://docs.djangoproject.com/zh-hans/2.1/topics/conditional-view-processing/ 加密签名Cryptographic signing: https://docs.djangoproject.com/zh-hans/2.1/topics/signing/ 发送邮件Sending email: https://docs.djangoproject.com/zh-hans/2.1/topics/email/ 国际化和本地化i18n: https://docs.djangoproject.com/zh-hans/2.1/topics/i18n/ 日志Logging: https://docs.djangoproject.com/zh-hans/2.1/topics/logging/ Django使用Python内置的logging模块处理系统日志。 分页Pagination: https://docs.djangoproject.com/zh-hans/2.1/topics/pagination/ Django提供了一些类来帮助你管理分页数据——跨页分割(Previous/Next)。它们位于django/core/paginator.py。 安全Security: https://docs.djangoproject.com/zh-hans/2.1/topics/security/ Django的安全功能的概述。 性能和优化本文档概述了一些技术和工具，这些技术和工具可以帮助您更有效地运行Django代码——更快，并且使用更少的系统资源。 序列化Django对象Serialization: https://docs.djangoproject.com/zh-hans/2.1/topics/serialization/ Django的序列化框架提供了translating Django Model成其它格式的机制。 设置Settings: https://docs.djangoproject.com/zh-hans/2.1/topics/settings/ Django的settings文件包含Django应用的所有配置项。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Beyond The Apex]]></title>
    <url>%2F2019%2F07%2F16%2FBeyondTheApex%2F</url>
    <content type="text"><![CDATA[参考: GT赛车 《Beyond The Apex》 序最近在PS4上购置了GTSport赛车游戏，刷知乎的时候看到GT赛车附赠了有关于汽车知识的书籍《Beyond The Apex》。出于好奇，在网上下载了这两本书的PDF版本，来帮助我学习相关汽车知识。谢谢网友对书籍的分享！ 汽车工程Engineering for Automotive 汽车的工学一般人与专业技师对汽车的印象，之所以会有这么大的差异，决定性的因素就在于是否拥有工学的基础知识。因此，接下来我们将解说专业汽车技师拥有的工学基础知识，希望能尽可能填补两者之间的落差。 第一节： 将介绍基本的机械力学，力、力矩、能量等概念，并导入振动的理论。力、力矩、能量是所有工学的基础。 第二节： 将介绍车辆运动力学与悬吊系统的调校。 第三节： 将介绍汽车引擎的基础知识——热力学与统计力学。 第四节： 将介绍空气力学。 第五届： 将介绍流体力学(CFD)。 本书中介绍的工学理论，对于专业的汽车技师来说，都是最基础的内容。不过，对于一般人来说可能比较陌生，要从头看到尾也有点困难。出现这种情况时，请先选择自己感兴趣的部分阅读即可。 力、力量与振动 力与力矩的概念行驶中的车辆，有各种力与力矩在作用。理解对车子产生作用的力与力矩，就是理解汽车原理的第一步。 力的定义 轮胎、悬吊系统、引擎……，汽车在行驶时，会有各种力发生于这些部分。这些作用力都是由不同的现象所引发，在直觉上或许会认为其种类也各不同。不过，从物理学角度而言，这些力全部都可以用F=ma（力量=质量x加速度），这个简单公式来代表，在本质上完全相同。 所谓力，就是改变物理的速度或运动方向的作用。反过来说，如果物理正在加速或加速，就一定有力在作用。例如，轮胎与地面之间产生的摩擦力可以改变汽车这个拥有质量的物体的运动方向或速度。避震器的阻尼力具有降低车体与轮胎振动速度的功效。 力矩的定义 若在行驶过程中转动方向盘，轮胎会产生与行驶方向垂直的力，车身的方向因而改变。车身会以为轮胎的作用力，而进行偏航运动。这种让有体积的物体出现旋转运动的作用，就称为力矩。所谓力矩，是因与旋转轴的举例，加重作用力力道的力量，以数学公式表示，就是M=LxF(力矩=旋转轴的距离x力)。 若将车子的重心位置设定于旋转轴，则前轮产生的力矩大小，就等于从重心至前轮的距离x前轮产生的横向作用力。当然，在转向时，后轮也可以发挥从重心至后轮的距离x后轮产生的横向作用力的力矩，让车子朝与前轮力矩相反的方向旋转。 让我们以实际的过弯来思考一下上述的情况。转动方向盘时，前轮的力矩会变大，因而开始转向。而到了弯道定点附近，前后轮的力矩达到平衡；过了顶点之后将方向盘回正，则后轮的力矩会变大，并完成转向。 能量的概念了解能量守恒定律。 能量守恒定律 关于汽车的物理现象，可细分为力学现象、热现象、电气现象、磁力现象、化学现象……。例如，在燃油引擎的气缸当中，燃油点火爆炸时，气缸内的温度上升、活塞会被推下。此时，气缸内部发生了化学现象、热现象与力学现象。这些物理现象的种类虽然不同，但在这些 现象之间，则有一种与力迥异的共通效应，那就是能量。能量可在不同的物理现象之间相互转换，而其总量在转换前与转换后会维持恒定、不会改变。这就是所谓的能量守恒定律。 刹车是将力学能量转换为热能量的行为。 引擎气缸内的能量守恒 若从能量的角度，观察发生于燃油引擎气缸内的物理现象，可说是气缸内的化学能量被转换成为热能与力学能量。换言之，燃油引擎可说是从化学能量当中，颉取出对人有帮助的力学能量的装置。此时，能量守恒会确保经过转换的化学能量的量与新生成的热能量与力学能量的总和相等。而引擎将化学能量转换为对人有帮助的力学能量的比率，称为引擎效率。 振动的机制振动现象的根源是物体的质量与弹性。 从力学角度看振动 为了让内容更容易理解，在此用独立的砝码与弹簧来说明（我们将可产生振动现象的对象统称为振动系统）。 从能量的角度看振动 振动也可以从前文提到的能量守恒定律来观察。若从能量的角度观察振动，则振动可说是由伸缩带动的砝码的运动能量，与弹簧的弹性能量之间的交互作用。 共振现象共振是指对来自外部的激励无抵抗的状态。 考量悬吊系统与引擎的振动时，必须特别注意的是共振的现象。共振必须尽可能避免。若无法避免时，也必须尽可能降低其影响。 自由振动与固有振动数 试着拉动前面的振动系统，然后放手让它自由震动，这种状态叫做自由振动。不久后砝码与弹簧会以某个特定的频率振动。无论一开始用什么方式拉扯，最终都会以一定的振动数振动。这个振动数，是仅有弹簧的弹性与砝码的质量决定的固有振动频率，因此称为固有振动数。固有振动数是振动系统进行自发性振动的频率，在以这个频率振动时，弹簧的弹力与砝码的惯性力会随时保持平衡，能量也自然会重复交互作用。 强制振动与共振 接下来试着用手强制让前文中使用弹簧与砝码伸缩，这种状态称为强制振动。用与固有振动数不同的振动数，让弹簧与砝码伸缩时，手应该会感受到阻力。让振动系统振动时，若将固有振动数视为自然的振动频率，则对于这个振动系统而言，其它的振动数都是不自然的频率。无论从外部施加何种振动，振动系统都会尝试以对自己最自然的频率来振动，因而会感受到阻力。 如果我们让这种砝码与弹簧用固有振动数来伸缩，结果又会如何？由于此时的振动对于该振动系统来说属于自然的振动数，因此不会感到阻力。不仅如此，振动的幅度反而会配合施加的外力而逐渐增大。因为振动系统对于来自外部的激励，不仅没有抵抗，而且会将其能量完全吸收。若持续以固有振动数对其施加振动则振幅会增加到无限大。 如上所述，若以振动系统本身自发振动时的振动频率，从外部强制让它振动，则振动的振幅将会持续增大，这种现象称为共振，而此时的频率称为共振频率。 以悬吊系统为例，共振将会导致接地性与乘坐的舒适度降低；而引擎出现共振，更会导致引擎本身的损坏。因此必须极力避免共振现象发生。防止共振导致损坏的方式之一，就是配置避震器。避震器可以吸收来自砝码与弹簧振动的能量，并将之转换成热能，是放到外部。因此即使产生共振，若阻尼力可却是发挥作用，就可以房子机械损坏。 阻尼力的作用振动的状态会因阻尼力而变化。 阻尼比不同的自由振动 振动衰减的情况，回音避震器阻尼力的大小而出现差异。而表示避震器阻尼力的大小，对于质量与弹簧弹力的效果有多大影响的量化指标，就是阻尼比。 当阻尼比大于1时，表示阻尼力强过质量与弹簧，因此振动系统的运动会朝向非振动收敛。这种状态称为过阻尼(over damping)。在过阻尼的状态下，振幅会随着之间而减少、逐渐趋近于零，属于无周期运动。而阻尼比小于1时，则阻尼力会弱于质量与弹簧的效应，振幅会随着时间减少、而振动周期则会逐渐拉长。这种状态称为阻尼不足(underdamping)。当阻尼比等于1时，则是振动或不振动的临界状态，这种状态称为临界阻尼(criticaldamping)。当阻尼比为0时，不会产生阻尼力，也就是避震器不会发生作用的状态，因此振幅也不会衰减。 相位差相位差就是振动的节奏的差异。 汽车通过路面的起伏时，起伏会被悬吊系统缩小，再传导至车体。在这种情况下，通常车体的振幅会比路面的起伏更为平稳。换言之，车体的振幅会先被悬吊系统缩小之后，再传导至车体。由此可知，车体振幅的响应能被缩减到何种程度，应是最重要的着眼点。要讨论振动时，对于入力能以多快的速度回应，这一点也非常重要。 振动的节奏之差异 要评估一个振动系统，对于人力会以多快的速度回应时，使用的基准就是相位差。 用固有振动数(共振频率)以外的振动数，轻质针对弹簧与砝码进行激励时，为何手会感受到阻力？手的振动节奏与振动系统的自然节奏不同所致。这种节奏上的差异，就是施加振动的方向与砝码惯性力的方向之差异。这种运动的节奏差异，就叫相位差。 频率响应应用于悬吊系统与车辆运动的解析。 频率响应与波德图 将振幅、相位差等振动系统对于激励频率(激励振动数)的回应，称为频率响应。 在分析汽车的振动现象时，通常会解析其频率响应。而解析频率响应时最常使用的，就是名为波德图的图标。 透过波德图了解阻尼系统的振动 还是使用前面的振动模型，从静止状态逐步提升激励的振动数(频率)。频率极低时的振幅比为1，换句话说，也就是激励的振幅与响应的振幅相同。不过，之后若逐步提升频率，振幅比也会随之变大，这表示响应的振幅比受入力影响而逐渐变大。而达到某一频率时，振幅比会达到最大，这就是所谓的共振。而此时的频率就是共振频率。如果再进一步提升频率，则振幅比会变小、并逐渐趋近于0.换言之，激励的振动数越高，响应的振幅也会随之逐渐趋近于0。 发生于悬吊系统的振动多自由读之振动。 悬吊系统的振动特性 汽车的悬吊系统有各种机构，但本质上是由质量与弹簧以及避震器组成的振动系统。车体与车辆之间的弹簧与避震器代表悬吊系统；车轮与路面之间的弹簧与避震器则代表轮胎弹性与阻尼。 车辆的运动性能 轮胎的力学理解轮胎产生的力。 转弯力 让物体滑动或扭转变形的力，称为剪应力；而物体对剪应力产生抵抗的特性，则称为剪弹性。若剪应力对轮胎朝横向作用，轮胎就会朝横向变形。不过，此时轮胎也会产生于剪应力对抗的力，尝试恢复原状。事实上，轮胎就是用抗拒让自身变形的作用力的方式，来产生车子的加速、减速、转向时所需的力。 从图中可以了解，轮胎的旋转面与车子的行进方向之间是有差异的。换言之，轮胎的力，是通过一边旋转、一边横向变形所产生。在此将旋转面如行进方向形成搞得角度，称为滑移角；而与行进方向垂直产生的力，则称为转弯力。车子之所以可以转向，就是因为轮胎可以产生如上述所述的转弯力。 一般来说，若剪弹性较大，即使滑移角相同，也会产生较大的转弯力。不过，当剪弹性过大时，些微的滑移角就可能导致摩擦饱和，使路感与车手的感觉不合；相反，如果剪弹性太弱，则会过度变形，而让车手感到不安。 转弯力与滑移角的关系 在滑移角较小的范围内，转弯力会呈直线增加；而当滑移角大到一定程度时，转弯力则会达到饱和。这种转弯力的变化比率，称为转向功率。只需些微的滑移角变化，便可产生较大转弯力的轮胎，其转向功率也比较大。 胎压与转向功率 一般来说，在胎压较低的范围内，胎压增加时，轮胎的剪弹性会提升，转向功率也会变大。不过胎压的上升，却会导致与路面的接地面积减少。换言之，接地面积与剪弹性，是针对胎压产生的相反效果。当垂直载重较小时，胎压增加造成接地面积较少的效果，会比剪弹性增加的影响更大，因此转向功率会降低。为了将转向功率提升到极限，最重要的是考量轮胎的特性与车重，在各项要素之间取得平衡。 伴随驱动与制动的轮胎横向力 从上方观察汽车时，与轮胎旋转面方向垂直产生的抓地力，称为横向力。理解横向力在驱动或制动时会产生何种变化，是非常重要的一点。踩下油门或刹车时，轮胎的抓地力被用于驱动力或制动力，所以即使在相同的滑移角下，横向力仍然会减少。赛车会随着车手的操控，而频繁进行制动与驱动，因此斜向的摩擦力，容易影响单圈时间。 车子的稳态定圆回转车子的转向由前后轮的力矩之平衡决定。 转向特性的定义 以一定的转向角与速度行驶的车辆，会维持特定的旋转半径画圆，这称为定圆回转(steady state cornering)。研究进行稳态定圆回转的车辆，将有助于理解车辆运动的基本特性。 假设有一台以特定速度进行稳态定圆回转的车子，我们从此状态慢慢提升其速度。若速度提升时，前轮产生的的力矩变小，则其旋转半径将会随着速度的提升而扩大，若要持续稳态定圆回转，就必须增加转向角。相较于此，若前轮的力矩变大，则旋转半径会随着速度的提升而变小，因此必须缩小转向角。 转向特性： 转向角不足的特性，称为转向不足(US)； 转向角过大的特性，称为转向过度(OS)； 旋转半径与速度的增减无关、维持一定数值，称为转向适中(NS). 必须注意的是，转向过度的车辆，在特定速度下旋转半径会变为0，也就代表车子会陷入打滑的状态。而达到打滑状态的速度，则称为稳定极限速度(stability limit speed)。 转向特性与滑移角的关系 前后轮的滑移角β前轮、β后轮与转向特性之间的关系十分有趣。 若β前轮&gt;β后轮，则为US； 若β前轮=β后轮，则为NS； 若β前轮&lt;β后轮，则为OS。 这种关系，与是否有转弯力以外的横向力作用于前后轮无关，也与转弯力是否和轮胎的横向力成比例无关，而是在进行稳态定远回转的车辆，以几何学来决定的关系。 车辆对转向角变化之回应车辆的运动只是一种振动现象。 转弯的机制 当转向角发生变化时，车辆会如何回应？偏航运动并不是在转动反向盘后立即发生，而会因车辆的惯性与轮胎的作用力发生的关系，而有短暂的时间差(相位差)存在。 转向平衡与车子的回应 车子对于车手操控的变化之回应，会受到转向特性与车速很大的影响。 US的车辆在达到一定速度后，会产生振动，但不久后就会收敛、并趋于稳态。 NS的车辆则不会产生振动，维持稳定的状态。 OS的车辆若行驶速度超过稳定极限速度，车子的回应将不会振动而出现发散，因而陷入打滑。 将振动理论适用于车辆运动 事实上，如果用阻尼比或振动频率(固有振动数)等特定的抽象概念，来观察物体的运动，可发现由质量、弹簧与避震器构成的振动系统与车辆的运动，两者完全没有差异，都可视为一个振动系统。换言之，车辆的运动只不过是一种振动现象。 US的车辆偏航阻尼的阻尼比低于1，因此会以振动方式回应。 OS的车辆偏航阻尼的阻尼比在1以上，所以其回应为非振动性。 NS的车辆则位于US与OS的分解处，也就是偏航阻尼的阻尼比为1的临界状态，其回应也属于非振动性。 车辆对周期性操控的回应以波德图了解车辆的特性。 对于转向特性与周期性操控的回应 车辆的运动只不过是一种振动现象。而接下来，则将利用振动理论检视在一定的车速下，反复转动与回正方向盘（进行周期性操控）时，若改变操控的速度（操控频率），车辆将会如何回应，今儿厘清在不同转向特性下的车辆特性。 当操控的频率极低时，不论在OS、NS、US任一特性下，振幅比都会与稳态定圆回转的偏航角速度大致相同。相反，当操控频率提升时，US的车辆会在特定频率达到高峰、振幅比也会变大；而NS与OS的车辆不会出现高峰，振幅比也会随着操控频率的增加而减少。 观察期相位图，可以发现随着操控频率的提升，不论在哪一种转向特性下，相位的延迟都会变大，但US的车辆相位延迟最小。换言之，越是转向不足的车辆，对于操控的回应就会越快。 看波德图时应留意的重点 以偏航角速度的频率为例： 1是极低频率的振幅比。这个数值与稳态定圆回转时的数值大致相同； 2是振幅比峰值的高度。US越强的车辆，偏航阻尼越小、共振则会越大，因此振幅比峰值会比较高；不过在NS与OS的车辆上，则不会出现高峰； 3是共振频率。共振频率越高，回应性愈佳，车手在操控时的路感也会愈明确； 4是相位的延迟。相位的延迟越大，针对转向角的偏航角速度发生的时间也会愈慢。因此，想要确保良好的转向特性，就必须开发出相位延迟较小的车辆。换言之，也就是US的车辆。 车体的滚转与运动将滚转运动活用于转向特性的调整。 转向中的车子，车体回想外侧滚转。实际上车辆的特性，会因为是否将滚转运动列入考量而出现差异。 相对于载重的转弯力变化 即使施加于车体的载重达到2倍，转弯力也不会增为2倍。这是因为随着载重的提升，转弯力的增幅会逐渐钝化（呈饱和曲线）。车辆转向时，会产生从内轮至外轮的移动载重。不过由于上述原因，左右转弯力的和，会比不考量移动载重的情况减少。换言之，转向造成的移动载重愈大，左右转弯力的和也会减少的多。 前后移动载重不同时的转向特性 轮胎转弯力的产生，会针对垂直载重以趋向饱和的方式变化，因此当前后的移动载重量因滚转运动而出现差异，转向特性也会随之变化。 如果是前轮的移动载重量&gt;后轮的移动载重，则转向特性回潮US方向变化； 相反，若是前轮的移动载重量&lt;后轮的移动载重，则转向特性会朝OS方向变化。 左右的移动载重量，会由于滚转运动相关的外力作用和与其相斥的车辆滚转刚性之作用的平衡关系来决定。此一关系主要是由前后的滚转中心的高低、前后的滚转刚性比，以及前轮的滚转中心的高低、前后的滚转刚性比，以及前后的轮距宽度来决定。 簧上质量与簧下质量的振动悬吊系统调校的振动特性。 车辆的上下振动，是会影响乘坐舒适度与轮胎接地性的重要问题。车体振动太大，会降低舒适度，更可能对接地面形成干扰、导致轮胎失去抓地力，因此必须仔细调校弹簧与避震器。 振动模式 簧上质量是指被悬吊系统支撑的质量；簧下质量是指位于悬吊系统与轮胎之间的质量。在此一次介绍簧上质量的弹跳振动(bounce vibration)、颠簸振动(pitching vibration)、簧下质量的上下振动。 为了便于理解，使用下图所示的模型来进行说明。 因悬吊系统调校而产生的振动模式变化 车体的共振，会导致轮胎的接地性与乘坐舒适度恶化，必须尽可能避免。此外，簧上质量的振动还会影响车体的空气力学性能（特别是对赛车而言，是一项十分重要的问题）。 簧上质量与簧下质量的上下振动，具有以下性质。若能充分理解，对于悬吊系统的调校应该有很大的帮助： 增加避震器的阻尼力，对于降低簧上质量在共振频率附近的振动十分有效，但在共振点意外的范围，反而会使振动增加； 提升避震器的阻尼力，簧上质量的共振频率也会略微提升； 变更簧上质量或弹簧的弹性，则簧上共振会大幅变化，但簧下共振则不太会变化； 变更簧下质量或轮胎的纵向刚性，则簧下共振会答复变化，但簧上的振动则不会有太大改变。 抑制颠簸运动 车辆直线前进时，从路面传导至后轮的人力，在时间上会出现轴距÷车速的延迟。若将后轮的簧上共振频率设定得比前轮略高，则后轮振动的收敛会追上前轮振动的收敛，可以抑制车辆的颠簸运动。 何为运动性能优良的车子车辆运动性的关键在于后轮。 偏航角速度的共振频率与转向特性 一般来说，车辆偏航角速度的共振频率越高，车辆的运动性能也就越利落敏捷。要提升偏航角速度的共振频率，可以通过提升后轮的转向功率、降低车子重量，或缩减偏航惯性半径等方式达成。 后轮抓地力的大小，对于车辆的运动性能十分重要。所以在调校悬吊系统时，除了要确保后轮的抓地力之外，也必须配合悬吊系统，将前后轮的抓地力最佳化。这是提升车辆运动性能时的基本概念。 车辆回应性的分类范例 引擎与效率 温度与压力温度与压力其实都是分子的运动。 热、温度与压力其实是由分子的运动造成的现象。问了正确理解引擎等机械的效率与能量损耗，以及将于后文中说明的空气力学（流体力学），在此最好先能掌握温度、压力相关的分子运动原理。 在密闭空间中不规则飞舞的分子样貌 请各位想象一下被密封在特定容器中的气体。以宏观角度来看，这个容器中的气体，在温度与压力都维持在均衡的状态，这种状态称为平衡状态。不过，如果站在可观测分子动态的微观角度，观察容器内部的状态，则可以看到无数的气体分子在其中不规则地随意飞舞。有的分子以非常缓慢的速度飞舞，有的则以非常快的速度飞舞。而且分子之间会互相撞击，有时还会撞到容器的内壁，因而改变了速度。 所谓温度，是每个分子的平均运动能量 在容器中，有无数个速度各不相同的分子存在，若从能量的角度观察，即可说是容器中存在有无数个运动能量各不相同的气体分子。事实上，所谓温度，就是指每个不规则飞舞的分子平均运动能量的对应量。 若以数学方式描述，则可写成：每个分子的平均运动能量=3/2kT。（T为绝对温度、k为波茨曼常数(Boltzmann constant，也就是气体的温度、密度、压力、量及种类无关的比例常数)）。在这个公式中，力学量——每个分子的平均运动能量；热能量——温度。波茨曼常数才是扮演连结力学量与热能量的重要角色。 压力为四处飞舞的分子撞击力的平均值 气体的分子会不断撞击到容器的内部，它们有些速度快、有些速度慢；有些是垂直撞击、有些则是斜向撞击，所以每个分子的撞击力道也不相同。不过，我们观察的所谓压力，其实是四处飞舞的无数分子，在不规则运动下的撞击力的平均值。在此要特别说明的是，在平衡状态下，上述分子撞击力的平均值，从任何一个方向测量都会得到相同的数值，不会因为量测的方向不同，压力就不同。换言之，容器中无无数的气体分子，虽然是以完全不规则的方式飞舞，但若以宏观的角度观察，撞击力其实是被平均分配至每一个方向。 何为理想的热机Heat Engine 完全不会产生无谓热能移动的卡诺循环(Carnot Cycle) 引擎，是可从热能量当中，以对人有助益的形式擷取出力学能量的机器。不过其效率到底是如何决定？在历史上，为了探索这个问题，而实际踏出一大步的，就是法国的卡洛。19世纪初期，卡洛以非常巧妙的论述，阐明了何为效率最高的热机，以及其效率的决定方式。他所提出的结论，成为之后开发热机时的重要指标。 卡诺留意到的两个事实 卡诺在考量何谓理想的热机时，留意到两个热能的性质。第一，是热机在作功时，必须要有温差存在。如果没有温差，就不会发生热能的移动，也就无法让热机运作。不过，若热机内有撷取功时不需要的温度差异在，热能就只会因温差而移动，称为完全不会作功的无效率热移动。因此卡诺认为，在作功时，不靠温差进行热移动的，才是理想的热机。第二，则是只要物体的体积或形状出现变化，即使没有温差、也可以进行热移动，这种现象称为等温变化(Isothermal change)。卡诺认为，如果能妥善运用等温变化，应该可以在不引发因温差而产生的热移动的情况下，便将功撷取出来。卡诺以上述假设为前提进行实验，并构思出不会因温差而产生无谓热移动的划时代热循环。 卡诺循环 为了明确凸显热的本质，卡诺设想出以高温与低温的热库(heat reservoir)，以及由空气充满的汽缸与活塞构成的空气引擎。下图是卡诺所设想出的热循环图： 让汽缸接触高温的热库，让热能从热库移动至汽缸内的空气，使空气膨胀。不过，由于不能在此步骤中产生温差，必须确保空气与热库的温度相同。此外，空气本身的温度也必须平均一致，不能有不均匀的情况。想要达到上述条件，必须让空气非常缓慢地逐渐膨胀。而这种以一定的温度让气体膨胀或压缩的现象，就是所谓的等温变化。 必须依照上述方式膨胀的汽缸，与低温的热库接触，但此时不可避免地会产生温差。卡诺因而利用了名为绝热变化(adiabatic change)的现象，也就是即使没有热能移动。若压缩气体、温度就会上升；相反，即使没有热能移动，若让气体膨胀，温度就会下降的现象。换言之，卡诺发现，只要让因高温热库而膨胀的气体，再因为绝热变化而膨胀，在没有热能移动的情况下，将气体的温度降低即可。要注意的是，在这个过程中，必须以非常缓慢的速度，让活塞动作才行。 当空气的温度下降到与低温的热库相同时，让汽缸与低温热库接触，就可让气体中的热能移动至低温的热库，同事压缩气体。如同先前说明过的，此时当然也不能有温差，所以必须以等温变化慢慢地让热能移动。 等温变化结束后，则开始利用绝热变化压缩空气，将温度提升上去。等到将空气压缩到与高温热库相同的温度时，在进行步骤1的等温膨胀，重复相同的过程。 如上所述，高温热库的等温膨胀-绝热膨胀让温度下降-低温热库的等温压缩-绝热压缩让温度上升，这4个过程进行一轮之后，汽缸的空气会恢复到与一开始完全相同的状态，在没有无谓的热移动的情况下，将热转换为工。由于以上热循环是卡诺构思开发，因此成为卡诺循环。 卡诺的结论以令人惊叹的方式将热能抽象化 卡诺循环的理论效率 经过以上说明，卡诺循环是可以达到热机最高效率的热循环。不过，卡诺的卓越之处，在于用巧妙的论述，以理论证明了由他所构思的热循环，也就是在汽缸内有温差的物体完全不会互相接触的热循环，就是最理想的热机，不会再有效率更好的热机。更令人惊叹的是，卡诺下了一个结论——那就是这个热循环的理论效率，仅取决于高温热库与低温热库的温度。他虽然没有将这套理论定型化，不过之后英国的William Thomson将它整理、归纳为一下数学公式: 卡诺循环的理论效率=1-\frac{低温热库的绝对温度}{高温热库的绝对温度} 将热机终极完美地抽象化 卡诺循环的理论效应，仅仅取决于热库的温度——这个由卡诺导出的结论，还证明了一项划时代的事实。那就是卡诺循环的理论效率，与热机的制作方式无关，仅仅取决于自然本身的性质。他的理论当中，完全没有不必要的成份，也完全没有遗漏不可或缺的部分，堪称是终极完美的抽象化。 汽车引擎的理论效率何谓奥图循环、狄赛尔循环的理论效率。 奥图循环的理论效率 在了解了何谓理想的热机之后，让我们来看看一般的汽车引擎。 目前的燃油引擎，事宜Nikolaus August Otto构思出的四衝程循环——奥图循环(otto cycle)为基础。奥图循环包括以下四个过程：1，绝热压缩；2，定容加热；3，绝热膨胀；4，定容冷却。定容加热、定容冷却，是指在不改变汽缸容积的情况下，将汽缸内的工作物质加热或冷却的作用。‘ 与卡诺循环相同，我们准备由高温与低温热库驱动的空气引擎，以非常缓慢的速度让活塞动作，就可以了解奥图循环是如何达到最高的效率。不过，在奥图循环中2和4的定容过程一定会产生温差，因为如果没有温差，从高温热库至空气的热移动，或是从空气至低热库的热移动就不会发生。因此，奥图循环的理论效率会低于卡诺循环，其差距就是上述温差导致热移动部分。 奥图循环的理论效率，可用以下的公式表示: 奥图循环的理论效率=1-\frac{1}{压缩比^{比热比-1}} 狄赛尔循环的理论效率 狄赛尔循环(Diesel cycle)是由Rudolf Christian Karl Diesel构思出的柴油引擎热循环。狄赛尔循环主要包括一下四个过程：1，绝热压缩；2，定压加热；3，绝热膨胀；4，定容冷却。这里所谓的定压加热，是指在不改变空气压力的情况下，将汽缸内的工作物质加热之作用。 迪赛尔循环的理论效率公式为：狄赛尔循环的理论效率=1-\frac{1}{压缩比^{比热比-1}}\frac{燃料喷射的截止比^{比热比-1}}{比热比(燃料喷射的截止比-1)} 卡诺循环、奥图循环、狄赛尔循环，不论采用哪一种循环，都无法制作出可实际达成理论效率的热机。因为非常缓慢的活塞运动，根本就不具有实质上的利用价值。此外，活塞与汽缸无法完全绝热，不仅会因为温差而产生无谓的热移动，活塞与汽缸之间的摩擦，也不可能完全消除。不过厘清理论效率，可以突显热机的本质，为工程师提供重要的指标。 可逆変化与不可逆变化自然的变化具有方向。 有一个重要的自然法则，会发生能量的损耗问题。请注意。 自然是从秩序朝向无秩序变化 准备高温与低温气体的两个容器。让温度不同的两个容器接触，热会从高温的容器朝向低温的容器移动。保持这一状态，不久后两个容器的温度将会相同，热将不再移动，进入平衡状态。若以微观的角度观察，最初高温的容器中，会有比较多激烈的分子；而低温的容器中，则较少激烈飞舞的分子。而在让容器互相接触时，高温容器内的分子的运动能量会朝向低温容器移动，低温容器内的分子的运动能量因而增加。等到两个容器内的分子平均运动能量（也就是温度）相等时，运动能量（热能量）的移动就会停止。 从无秩序朝向秩序的变化不会发生 接下来再从另一个角度观察。一开始，高运动能量的分子与低运动能量的分子，分处于不同的容器当中，可以明确区别出高温容器内的分子运动与低温容器内的分子运动。换句话说，容器内有可供判别两者差异的秩序存在，而可供区别其差异的资讯，就存在该项秩序当中。不过，达到平衡状态之后，可供判别两者间差异的资讯就会消失，进入所谓无秩序的状态。 事实上，上述从有秩序的状态朝向无秩序的状态之变化，对于自然界而言是十分自然的变化；相较于此，从无秩序朝向有秩序的变化，则不会自然发生。举例来说，让高温的容器与低温的容器接触时，高温的容器会冷却、低温的容器则会加温，这对于自然界而言是十分自然的变化。相较于此，让两个温度不同的容器接触时，高温容器的温度进一步提升，而低温容器的温度反而下降，这种现象绝不会发生。像这种不论用何种方式，都不可能将现有状态恢复到与原本完全相同的状态的变化，就称为不可逆变化；而可以复原的变化，则称为可逆变化。 尝试让热机逆向运转可逆循环与不可逆循环的差异。 到底实际上引擎为何无法达到理论效率？在可达到理论效率的热循环中，必须让活塞以非常缓慢的速度动作。 卡诺循环的逆向运转是可逆的 在此，将卡诺循环以1-2-3-4的顺序运作的情况称为顺向运转；而以4-3-2-1的顺序运行的情况称为逆向运转。 让卡诺循环进行顺向运转，让特定量的热从高温热库移动至低温热库，并将过程中产生的功存储起来。接下来再用存储的功，让卡诺循环逆向运转，使在顺向运转中移动的热，从低温热库移动至高温热库，恢复与原本完全相同的状态，不会剩下任何东西。换句话说，也就是将卡诺循环顺向运转产生的功存储起来，再用存储的功进行逆向运转，恢复到与原本完全相同的状态。之所以能做到，是因为在卡诺循环的过程中，完全没有物体相互接触，因而完全不会发生无谓的热移动。换言之，卡诺循环的所有过程都属于可逆变化，所以才能进行可逆的你想运转。 汽车引擎的逆向运转是不可逆的 如果换成奥图循环或狄赛尔循环，有会如何？在此同样让上述循环顺向运转，将过程中产生的功存储起来，再用存储的功进行逆向运转。结果发现即使将在顺向运转中存储的功完全耗尽，也只能让一部分的热复原，无法让所有的热从低温热库移动至高温热库。 原因是它们两者的定容过程中，必然会出现温差。无论如何都会产生无谓的热移动。因此我们可以说奥图循环和狄赛尔循环是不可逆的。而这代表了一个非常重要的观念，那就是热机无法进行可逆的逆向运动，其实也就证明了在该循环中，有发生无法产生工的无谓热移动。 能量的损耗能量的损耗其实就是不可逆变化。 在说明热机的理论效率时，我们多次强调了必须让活塞以非常缓慢的速度运动，其原因就是为了不要引起不可逆变化。因为不可逆变化，其实就是能量损耗的真面目。 引擎的能量损耗 如果在热机的运转过程中，包含了可归为不可逆变化的现象，则该现象就属于前文提到的无法作功的热移动，也就代表可使用的功会减少。实际上引擎是通过在汽缸内引发燃烧的化学变化来产生热能，并以该能量让活塞运动、从而产生功。此时产生的热会造成温差，引起无谓的热移动。而汽缸与活塞之间也会产生摩擦，导致声音与扰流。此外，燃油的化学变化也属于不可逆变化。这些现象一旦发生，就绝对无法向影片的你想播放一样，恢复到与发生前完全相同的状态，因此属于不可逆变化。换言之，也就是无法作功的无谓热移动。 机械的能量损耗 先前探讨的对象都仅限于热机，而事实上机器装置的能量损耗，全部都是因不可逆变化而产生。反过来说，效率高的机器，可以说是在运作时尽可能减少不可逆变化的机器。因此，想要制作出效率高的机器，重要的关键之一，就在于理解何种现象属于不可逆变化，并极可能减少该现象的发生。 阿特金森循环是与奥图循环相同的热循环，一般来说，其机制是通过将奥图循环的膨胀行程延长，来产生更多的功。 空气力学 白努利定律思考流体的压力与速度的关系。 汽车的空气力学特性，对于耗油量、加速性能与行驶稳定性等，都有很大的影响。特别是赛车，其空气力学特性，对于车辆整体运动性能的贡献占有很大的比例。因此，接下来就要解说作为汽车空气力学解析与设计基础的空气力学理论。 有流体流动时的分子运动 当有气流时，能量均分定理就无法成立。在气流当中，会有较多的分子运动能量被分配至流动的方向，而与气流不同方向的运动能量则会因而减少。如果在气流中量测压力，则在流动方向测到的压力会长高，在与流动垂直的方向量测到的压力则会最低。在此要注意的是，在流动变化的前与后，分子运动能量的总和是不会改变的。 有流动时的分子运动 由白努利(Daniel Bernoulli)提出的白努利定律，代表当分子的能量分配因流速的变化而改变时，流速与压力的关系。 白努利定律的数学公式如下（P代表压力，ρ为流体的密度、V则是流速）：P_0=P_1+\frac{1}{2}ρV_1^2=P_2+\frac{1}{2}ρV_2^2 升力发生的机制 接下来就用白努利定律，来说明翼型(airfoil)产生升力的机制。下图以流线代表翼型周围流场的示意图。所谓流线，是指以流体的速度向量为切线的曲线，也就是流动的路线。从流线的定义可以了解，气流不会横向穿过流线，换言之，被相同的流线上下包夹的区域，无论在哪个位置的流量都相同，这一点请留意。此外，流体存在的场域，称为流场(flow field)。 从下图的流场中可以了解，在翼型的前方，流线为等间隔，但在翼型的上表面，流线的间隔则会变窄。由于气流不会横向穿越流线，所以在翼型的上表面，实际上流路是被缩减的。尽管如此，由于被相同流线包夹的流路，其流量不会出现变化，所以在流路被缩减的翼型上表面，压力会与流速的平方成反比例降低。相反地，若翼型小表面的流线间隔变宽，则流速会下降、压力则会上升。而在此过程中产生的上表面压力与下表面压力的差，就是所谓的升力。 流体的运动法则流体的运动方程式代表的意义。 尤拉方程式 第一个导出流体运动方程式的，就是将白努利定律正确地以公式描述的尤拉。对于流体力学的进步而言，其重要性远超过白努利定律。因为若能解出气运动方程式，就可以计算出流场的状态。这个由尤拉导出的运动方程式，名为尤拉方程式(Euler equations)。 左边代表流体流动（加速）的效果；而右边则称为压力项，代表压力的梯度。总括来说，尤拉方程式描述的就是流体会沿着压力梯度流动。压力梯度与流经该流场的流体之间的关系，可说是和斜面与滚过斜面的球的关系相同。这里的斜面相当于压力梯度，而球则相当于流体。举例来说，在斜面坡度较陡的地方，球会加速；而在斜面坡度方向相反时，则会减速。同样，流体在压力梯度高的地方会加速，与压力梯度方向相反时，则会减速。 那维尔-史托克方程式 尤拉方程式，虽然已数学方式描述了流体的速度与压力的关系，但并不包括流体实际上具有的黏滞性之效果。而将黏滞性效果列入考量的运动方程式，是在19世纪由Navier与Stokes导出的那维尔-史托克方程式(navier-stoker equations)。 左边是流体流动（加速）的效果；右边第一项为压力项，表示压力的梯度；右边第二项，则称为黏滞性项或扩散项，代表黏滞的特性。 尤拉方程式与那维尔-史托克方程式，到目前为止都还没有通解，所以只能直接适用于非常特殊的流体。在此情况下，要从这些方程式了解一般的流场，目前只能利用电脑以数值方式求解。 涡线与不连续面回避流体运动方程式的策略。 尤拉方程式和那维尔-史托克方程式，都是可以正确描述流体运动的方程式，不过由于在数学上的难度过高，几乎无法适用于实际的流体，在发展上也出现瓶颈。在此情况下，因而出现了不仰赖上述方程式，来解析流体的动向。接下来就为各位介绍达朗伯特矛盾，与突破此一矛盾的尝试。 达朗伯特矛盾 达朗伯特(Jean Le Rondd’Alembert)，尝试以理论求出放置于恒定流中的圆柱的阻力（与流体的速度平行且逆向产生的力），结果他解出的阻力为0. 当然，在实际的流动中，阻力不会是0.尽管如此，在他的计算当中完全找不出错误，无论是由谁重新计算几次，得出的阻力都还是0，结果并没有改变。这成为了之后160年间流体力学上的重大问题，因此也被称为达朗伯特矛盾。 如果具备现代的知识，就可以了解他的计算本身完全没有错误，只是没有考量到流体的黏滞性，所以当然会导出阻力为0的结果。如果不考量黏滞性的恒定流，则圆柱前后的气流会对称，压力也会在圆柱前后形成对称，圆柱周围的压力会互相抵消，结果造成阻力成为0。 当时还没有那维尔-史托克方程式，对于黏滞性效果的处理方式，也不甚了解。一直到1904年德国物理学家Ludwig Prandtl提出边界层的概念之后，才完全解决了达朗特矛盾。 涡线与不连续面的概念 不直接针对流体的运动方程式求解，而是以数学的方式处理流体运动、开创出新境界的，就是德国的Hermann Von Helmholtz。他进一步扩展涡旋的概念，并提出新的流体概念。 Helmholtz导入涡线与涡层的概念后，让长达一世纪不得其解的朗伯特矛盾，突然豁然开朗。根据达朗伯特矛盾，平板的抗力应为0。不过，若假设没有不连续面从平板的前缘与后缘延伸，便可将平板的背面视为流速较低的范围，实际上达朗伯特矛盾便不再存在。虽然因为他们过度高估了平板背后的压力，结果并没有成功试算出阻力，不过计算阻力的努力确实是朝正确的方向迈进。 库塔-贾可斯基定律升力的循环理论。 Kirchhoff与Reyleigh，假设不连续面是由物体的锐角部分所形成。不过，这种不连续面，会发生与物体表面的任何位置，所以也可以说物体表面是由涡层所覆盖。事实上，这种想法与升力理论中的升力之循环理论密切相关。 库塔-贾可斯基定律 由于物体表面的流速，会因为黏滞性而产生很大的变化，所以从物体表面的任何位置都会产生涡线，并成为覆盖物体的涡层。此时，覆盖物体的涡层整体的强度，便称为循环。如此一来，我们就可以将物体周围的气流，分离成均匀流与循环流两种（循环的定义，是指沿着任意的平曲线，将流速线积分后得出的量）。 假设有均匀流与循环流存在，来思考一下将两者重叠的流体。由于在循环流的上方，其流动方向与均匀流一致，所以上方的流速会增加。而在循环流的下方，均匀流与循环流朝反方向流动，若将两者重叠，流速将会降低。结果依据白努利定律，循环流上方压力会下降，下方压力则会上升，所以会产生向上的升力。上述的流场正与翼型周围的流场类似，在翼型的上表面，流速变快、压力降低；而在翼型的下表面，则是流速变慢、压力上升。事实上，我们同样可以将翼型周围的流场，当作是均匀流与循环流的重叠流场来处理若能得出循环，就可用以下方式计算出升力：升力=流体的密度×均匀流的速度×涡漩的循环(L=\rho V \Gamma) 库塔条件 依据库塔-贾可斯基定律，若能解出物体周围的循环，就可以算出作用于该物体的升力。不过，要将该定律适用于翼型时，有一点必须特别注意，那就是基本上流体的方程式，是根据流动是平滑的这个前提导出。而对于尖锐或不连续的流动，通常必须另行考虑。 以翼型为例，翼型的后缘形状是尖的，因此在尖翼的后缘有一项限制，那就是无法满足翼型上表面的气流与下表面的气流会在翼型的后缘平顺汇进这个条件，库塔-贾可斯基定律就无法适用于机翼。而这个上表面与下表面的气流，会在翼的后缘平顺汇进的条件，就称为库塔条件。必须先满足库塔条件，才能决定循环，也才能用数学公式算出升力。要补充的是，如果针对气流在翼加上攻角，则攻角愈大、要满足的库塔条件时所需的循环也会变大。因此攻角愈大、循环也会自然随之变大，结果也就会产生较大的升力。这就是将攻角加大、升力也会随之提升的机制。 普朗特的边界层理论摩擦的影响局限于物体的表面附近。 Kirchhoff与Reyleigh计算阻力的尝试虽然失败，但已向成功迈进了一大步。接下来便介绍普朗特(Ludwig Prandtl)提出，最终解决了达朗伯特矛盾的边界层理论。 普朗特的边界层理论 想要估算阻力，除了压力之外，如何处理摩擦力也十分重要。而在处理摩擦力时，必须先了解物体表面的气流流动的情况。 率先提出边界层的概念，就是普朗特。他指出受到黏滞性的影响，物体表面的流速会变成0，而摩擦的影响，则仅局限于物体表面的邻近区域，而在其外部，气流基本上不会收到黏滞性的影响，可将该气流视为非黏滞性流体。而这个位于邻近物体表面、会受到黏滞性影响的范围，目前称为边界层。 普朗特于1904年发表名为《具有极低黏滞性的流体之运动》的论文，并在这篇仅有8页的论文中，首都提出边界层的概念。他指出那维尔-史托克方程式简化的边界层方程式。此外，利用他的边界层理论，在某种程度上也可以预测流体剥离的位置。就这样，边界层理论完全解决了达朗伯特矛盾的问题。普朗特于1904年发表的这篇论文，为流体力学开创了新的发展，因而被视为流体力学史上最重要的论文。 普朗特的升力线理论发生于有限翼的翼尖涡流问题。 Kutta和Joukowski催生了升力的循环理论，并得以正确计算出二维气流中的升力。不过一般来说，翼周围的气流都是三维的，无法直接使用二维流体的翼型理论。在此情况下，就必须构建出翼在三维流场中的升力理论。 有限翼展翼周围的气流情况 翼型也可以说是拥有无限长翼展的翼。这种无限翼展翼，在翼展任何一个位置的循环大小都相同，升力也维持一定，因此无限翼展翼可以直接使用库塔-贾可斯基定律。不过，实际上翼的翼展是有限的。所以在翼尖，气流会从压力较高的下表面流动至压力较低的上表面，其压力分布会与无限翼展不同。愈靠近翼尖，升力会变得愈小。此外，从翼尖的高压侧转入低压侧的气流会形成纵向涡旋，并朝向背风面流动。这种以翼尖为起点产生的涡旋，称为翼尖流。 普朗特的升力线理论 普朗特提出的有限翼展翼升力理论，成功的赋予了Lanchester建构的模型非常相似，不过普朗特成功赋予了该理论严密的数学描述，这是Lanchester没有做到的。普朗特构思出的模型，是沿着翼展方向在翼面配置由无数个无限弱的涡线组成的涡线束，而每条涡线均朝着背风面玩去流动。这个无限弱的涡线，就称为升力线。利用普朗特的升力线理论，可以算出有限翼可产生的升力与力矩。此外，普朗特也证明了由翼尖涡流诱发的下洗(downwash)气流造成的阻力，也就是诱导阻力的存在，并以理论阐明了翼展愈大的翼，其诱导阻力就会愈小。 计算流体力学 CFD的世界CFD是一个被离散化的世界。 随着电脑的普及，利用电脑求出流体方程式数值解答的手法持续发展。而这也是Computational Fluid Dynamics(计算流体力学、数值流体力学)，也就是统称为CFD的学问。目前CFD已成为研发汽车时不可或缺的工具，但一般人对于其机制都不甚了解。所以接下来就简单介绍一下与CFD有关的理论概念。 近似 真实的世界是类比，换言之，也就是平滑而连续的，无论在何时取出任何一个空间的一点，里面都包含了某些物理的资讯。相较于此，电脑是数位的，只能处理不连续的分散数值，也只能保存有限的资讯。因此CFD也只能将原本平滑连续的时间与空间分割，当成不连续的物体来处理。尽管如此，在CFD的世界当中，仍希望能尽量呈现出与真实世界接近的平滑类比世界，所以会通过模型化，来补足电脑没有的资讯。那么，应通过何种方式，来补足资讯欠缺的部分？答案其实很简单，只要用直线将电脑的资讯连结起来，将资讯欠缺的部分视为直线变化；或是用曲线进行模型化，将资讯欠缺的部分，以曲线变化的方式来补足即可。这种精确来说与原本的资讯有差异，却是在不减损原本资讯的性质下，进行单纯化的作业，称为近似。而通过此一过程所得出的与原本数值非常接近的数值，则称为近似值。在CFD当中，将上述的近似手法，称为数值法(scheme)。 Lax等价定理 只要近似值与真值之间的误差够小，在实用上就不会有问题。因此，对于解析气流的人来说，无意义的极小数值可以忽略，而通过模拟得出的结果误差，只要小于必要的精度，以专业的术语来说，只要模拟的计算结果向真值收敛即可。接下来介绍一个重要的定理，那就是由Peter David Lax证明的Lax等价定理。这个定理的内容是会趋于收敛的唯一数值法，就是稳定且相容的数值法。换言之，所谓的Lax等价定理，可以说就是指稳定性+相容性=收敛性的关系。 有限体积法运用最广泛的流体模拟方式。 有限体积法的概念 有限体积法主要是针对被分割的个别空间元素，留意其流入量与流出量的平衡（如1秒后容器中的水量=原本的水量+流入量-流出量）。在实际的流体模拟中，处理流体的量之外，对于压力与流速等物理量，也是用同样的方式计算。 数值通量 接下来让我们按照实际的CFD，更具体地观察有限体积法的基本概念。如下图，将空间细细分割，如此分割出来的空间，称为网格(grid)。让我们思考一下流经这些网格的流体。 首先，假设我们知道每个网格在特定时刻拥有的物理量，然后再根据这些资讯，以单位时间的流出量与流入量，来预测未来每个网格中的物理量——这就是以有限体积法模拟流体的方式。上述流入量与流出量，必须由操作CFD的人，根据当下的物理量之分布，用某种方式来推测出最合理的数值。换句话说，决定这些量的方式，有可供选择的空间，因此单位时间的流入流出量，无法定义为单值。向这种有人为选择空间的单位时间流入流出的物理量，称为数值通量，而数值通量的精度，会大幅左右计算结果的精度。 数值法的特征单调性与高精度无法兼顾。 数值通量的精度，会因为采用的数值法而出现差异，当然也会影响到模拟的精度。若采用了不适当的数值法，则误差将随着计算你的进行而持续扩大，计算甚至可能发散。 一街精度的数值法 一阶精度的数值法，优点在于可维持单调性，但缺点则是得出的解容易扩散。 高阶精度的数值法 采用高精度数值法得出的解，精度通常较高。不过，愈是高阶，就代表须从更多的网格中取得更多的物理量来进行计算，计算量势必会大增。此外，采用高阶精度数值法得出的解，在部分情况下会出现振荡，反而会导致精度下降，这也是其缺点之一。 戈多诺夫定理 数值法无法兼顾高精度与解的单调性（解不会出现振荡），这一点已经过数学上的验证，也就是所谓的戈多诺夫(Godunov)定理。根据戈多诺夫定理，可同时满足高精度与解不会出现振荡的数值法并不存在，无论如何费心，都无法制作出两全其美的高阶精度数值法。 一阶与高阶精度的并存设法让一阶精度与高阶精度并存。 TVD法 只要配合气流的性质，妥善运用不同数值法各自的优点，应该就能得出良好的计算结果。基于这种想法而实际开发出来的，就是名为TVD的数值法。TVD是一阶精度与高阶精度的混合数值法，特别注重于避免增加解整体的变动。它可以自行判断气流变化的激烈程度，大部分的气流以高阶精度进行计算，而气流急剧变化的部分，则切换为一阶精度，以维持其单调性。 TVD法不会像高阶精度的数值法般出现预测过度(overshoot)或预测不足(undershoot)的振荡。此外，TVD法也比一阶精度数值法更能控制解的扩散。而且不论与一阶或高阶的数值法相较，TVD法得出的解都更接近真值。不过，TVD法必须有判定流场变化的作业程序，因此多少会消耗额外的计算时间。 如何解析紊流设法降低庞大的计算量。 解析涡旋 汽车行驶时，其周围会发生紊流。紊流是由大大小小的空气涡旋构成。无论其结构有多单纯，要计算一个涡旋，至少需要9个网格。如果要直接计算车子周围所有的涡旋，所需的网格数量将会及其庞大，这应该很容易可以想象。 紊流模型 在进行研究分析时，通常会将以上述成果为基础的紊流模型导入CFD，放弃解析构成紊流的大大小小的所有涡旋，而仅计算具有特征的部分，以缩减庞大的计算量。接下来就简单介绍一下目前应用最为广泛的RANS与LES这两种紊流模型。 RANS(Reynolds Averaged Navier-Stokes) RANS，是将紊流的流速，分成平均流速与其中的变动成份之紊流模型。由RANS的计算量相对较少，所以是应用最为广泛的紊流模型。不过，它无法正确重现非恒定的气流，所以有较难正确估算剥离等的缺点。 LES(Large Eddy Simulation) 在紊流当中，拥有支配性影响力的是大型的涡旋：小型涡旋对于整体流场的影响则相对较弱。而放弃直接解析小型涡旋，只计算大型涡旋，并将小型涡旋模型化的方式，就是所谓的LES。与RANS相较，LES能够以非常高的精度重现流场，但计算量也远超RANS。 汽车结构Mechanism 车的基本要件车身骨架和基本结构的皮遏制称作车子的基本性能，从设计初期阶段便已决定，无法轻易更动。这是一辆车的潜能，会大幅影响它的三大性能： 行进、过弯、停止，同时也是用来判断一辆车的行进性能的重要基准。有关基本性能的部分，大多难以通过改装加一弥补，医药一点点规格上的差异，便足以影响上路时表现的优劣。 车身尺寸 轴距(wheel base) 从车身侧边看去，自前轮中心起到后轮中心为止的长度就叫做轴距。这项特性主要影响车子行进间的安全性。轴距越长越不容易受到路面的高低起伏和横风的影响，在直线行进时具有较高的安定性。一般而言，虽然轴距较短会降低车辆稳定性，但是当方向盘转向时，反应会变得较为敏锐，并可更灵活地过弯。就乘客的感受来说，长轴距可提供舒适的感受。 外悬(Overhang) 从前轮中心至前保险杠前端的距离称为前悬(front overhang)，从后轮中心到后保险杠末端的距离称为后悬(behind overhang)。如果有重物位于这个部位，将使得车的偏向惯性力矩（妨碍转向的力量）变大，降低车子的运动性能。因此从结构上来看，重量应尽量设置在轴距内侧较为理想。这一点对于引擎这类重型机具而言更是格外重要。另外，必须保留一定以上的外悬长度，才能处理空力的问题。 轮距(tread) 左右轮间的距离称为轮距。放宽轮距则可降低车身假想重心的高度。一般而言，轮距越宽，过弯时轮胎的抓地力效果越大。因此，若放大驱动轮的轮距，便有利于将汽车的马力传到到地面。在比赛用车种上，常会将前后轮改装成不同轮距，以改变操控感。另一方面，若轮距相较于轴距在比例上显得极度狭窄，则虽然可以得到快速的操纵反应，却也较容易使车子时区稳定性。 车高(height) 指从路面至车身最高处的高度。车高越低，则因为重心降低，可以抑制过弯时的晃动（车身横向的倾斜），提升回转反应速度。另一方面，降低车高将会影响车内的舒适性，切回造成难以确保悬吊行程的状况，是的行经赛道路石等处时，发生触底（避震行程完全用尽）的原因。 车重(weight) 这是左右汽车运动性能的重要因素。车重越轻，引擎负担也会降低，在动力性能面较占优势，且因降低了对刹车曹成的负担，得以提升制动力。另外，更因省去了惯性造成的浪费，让过弯变得更加轻快，好处不胜枚举。将车重除以最高输出功率的值称为重量马力比。这个值越小，包括出弯后起步在内的加速性将更敏锐，车子行驶起来也更加灵活，且在降低燃料消耗率方面也极具效果。因此从环保性能的角度来看，车重轻量化业已成为开发新车时的重要主题。 重量平衡与驱动方式驱动方式和车身尺寸同样属于基本的规格。驱动方式视引擎安装位置、驱动轮位置而定。一般分为：FF、FR、MR、RR等种类。决定将车身上最重的零件——引擎安装在哪里？又要让它驱动哪个轮胎，是决定车身重量平衡的重大因素。 一台重量平衡良好的车，可以让引擎动力有效地传导到驱动轮上，对于起步/加速性能都有帮助；刹车时不容易让车身受惯性影响而向前倾，并可以更有效地发挥刹车性能。 重量平衡影响最大的是过弯。由于过弯时离心力会使得车子变得不稳定，因此重量分配不当的车子，在车身过弯离心力增加的情况下，更容易发生打滑等风险。 基本上，车身重量分配的理想值为前后、左右各为50比50。将引擎安置在车身前部，驱动后轮的FR式配置较易实现上述50比50的比例。另一方面，将引擎和驱动机组集中在车身前方的FF（以及4WD）式配置，则较易呈现中心在前的倾向。引擎和驱动机组集中在车身后方的RR式配置，则较易呈中心在后的倾向。因此，部分FF配置的车种为了改善重量分配的问题，会可以将横向安置为主流的引擎，改为纵向方式安置。 驱动方式的种类： FR(Front engine Rear drive)引擎安置于车厢前方，并驱动后轮的配置。最易实现前后重量50:50的理想数据。除了具备优异的操作感受外，由于操舵轮和驱动轮的分离设计，因此不需要特别去习惯操舵感觉，则是它的另一优点。然而，随着路面状况不同，这种配置也会发生难以获得驱动力的情形。 FF(front engine front drive)集中在前方的引擎驱动配置。由于结构上将沉重的引擎和变速器都收纳在引擎盖当中，因此，虽然可提供更宽广的车厢空间，却无可避免地将使重量集中于车体前方。又因为前轮必须同时扮演了驱动和操舵轮两种角色，以致在过弯时，车胎的抓地力必须兼顾维持直进与转向两个部分。正因如此，这样的配置通常不太适合大马力的车种使用。 MR(Mid engine rear drive)引擎装在车身中央来驱动后轮，也称为中置引擎(middle-ship)配置。通过将引擎安装在车身中央附近、缩短引擎与车辆重心距离的方式，让车辆发挥锐利的过弯性能。且无论在加速或减速时，前后轮都能发挥最大的抓地力。这种配置对于车子行驶最为有利，是纯跑车、赛车常见的固定配置。 RR(rear engine rear drive)引擎安装在比后轮更后的后悬部位来驱动后轮。这样的做法会导致车辆重心偏后。然而，由于引擎和变速器的重量将后轮牢牢地压在路面上，因此反而容易取得驱动力，今儿获得更优秀的加速性能。但相反，由于前轮缺少负重，因此在过弯初期容易发生转向不足的问题。又因为后轮负重较重，因此在后胎超过负荷时，会产生激烈的打滑现象，想要从这样的状况中恢复正常，需要极高的驾驶技巧。 4WD(four wheel drive)通过前后左右四个轮胎进行驱动。这种配置架构除了增加车辆总重量的小缺点以外，可以说是姿势和起步与加速的驱动配置。然而，高度的稳定性却也意味着不容易过弯。 车的心脏在组成汽车的零件中，引擎扮演着最重要的角色。能够正确掌握引擎的原理，搭配上正确的操作，才能百分百发挥出车子的性能。 构造与原理几乎所有的燃油引擎车都搭载4衝程的往复式设计。往复式引擎当中配有汽缸，靠着汽缸中的活塞往返运动来产生动力。而所谓的4衝程设计，便是因具采用了进气-压缩-燃烧-排气等4到反复程序设计而命名。 首先，在活塞到达汽缸上死点前，进气门便会打开，而在活塞达到死点后开始下降，因此会自动开启的进气门吸入空气与汽油的混合气体。当活塞降至最下方，进气衝程即告结束，进入压缩衝程。此时，在所有气门都已关上的气缸当中，活塞开始加压前述混合气体。当压缩混合气体的活塞抵达稍微超过顶点的位置时，火星塞即会进行点火，于是便告进入燃烧衝程。此时汽油引擎的气缸内部甚至可以达到摄氏2000度以及200个大气压力。这样高温高压的能量会将活塞往下推，并推动曲轴以产生回转的动力。活塞抵达下端后，排气门便会打开，展开排气衝程。在此衝程中，与其说是活塞把气体推排出去，不如说是这些排出气体因本身夹带了高温、高压动力，自动地从排气门喷出。排气后， 顶点的进气门有会打开，于是再度回到进气衝程。 4衝程引擎即使在怠速状况下1分钟，也会执行数百次这4道步骤，在全力运转的状况下能够以1分钟数千次的速度转动曲轴，以持续产生动能。 气缸配置的种类 直列型(in-line engine)将复数汽缸配置成一列的设计。所有的汽缸均共享一根曲轴，可让气缸体机组成为整体化结构，因此有着结构简单、且较能降低重量的优点。然而，若汽缸数量越多，则本体长度也会随之增加，同事会影响空间上的运用。 V型(V engine)将汽缸左右交互配置呈V字型。这种配置可以缩短曲轴的长度，优点是在多汽缸的情况下，也能有效缩小引擎本身的体积。且无论汽缸数量有多少都不易震动，而较短的汽缸区块和曲轴长度，同时可让结构更为坚固。 水平对向型(flat engine)将汽缸左右交互进行水平配置的型式。各汽缸以曲轴为中心左右对置，且对向的活塞呈现左右对称的动作。就好像拳击场上两名选手交互打出的拳击一般，因此也被称为拳击手(boxer)引擎。另外，由于引擎高度较低，因此也有这适合低重心化的优点。 W型(W engine)原本是指1根曲轴对应3列气缸呈扇状安置的引擎设计，不过，现在也可用来称呼结合了2组狭角V型引擎的机组。这种配置的宽度大于V型引擎，但是在汽缸数超过12颗以上的多汽缸架构下，此种配置可以缩短曲轴长度（即引擎全长），并带来更大的好处。 气门驱动方式4衝程引擎当中，有着在进气衝程中开启以自外部引入混合气体的进气门，以及在排气衝程中开启以将燃烧气体送出外部的排气门。气门设置在汽缸盖的位置，负责在适当的时机阻隔/连接燃烧室与外界。 现代引擎一般选在将凸轮轴设在引擎的上半部，以更加正确地驱动气门。关于气门的数量，目前几乎都采用2个进气门、2个出气门，共计4气门的设计。不过，今后为了追求在低转速领域的燃烧效率，像进气门、排气门各1的2气门设计，仍很有可能重新面世。另外，近来潮流倾向于采用可变气门正时系统。原本在低转速和高转速领域间转换时，气门开闭正时也必须随之变更。然而，之后已进步到可随着引擎回转连续不间断地变换气门开闭正时和扬程深度。而自BMW推出可变气门扬程系统后，市面上一系列最新的可变气门结构，更能在不通过节流阀的情况下调整输出功率，这项进展得以进一步地提升效率。 气门驱动方式的种类： DOHC(double over head camshaft)DOHC(双凸轮轴)，使用两根凸轮轴分别驱动进气与排气门的设计。此设计减轻了凸轮轴的负担，不仅能更加确实地执行开关气门的动作，同时可以降低气门结构附近的往复运动质量（即惯性），以获得高转速表现。该配置也容易取得高输出功率，因此今日几乎所有的高性能引擎，都采用这种设计。 SOHC(single over head camshaft)在汽缸盖上设置1根凸轮轴的方式就称为SOHC(单凸轮轴)。依照燃烧室的形状不同，又可区分为凸轮轴直接驱动气门，或由凸轮轴通过一种像跷跷板的零件锁臂(locker arm)驱动气门。它拥有更可靠的气门运作表现，且可获得更高的转速。 OHV(over head value)OHV(顶置气门式)。顾名思义，气门机组设于汽缸盖上方。它与SOHC、DOHC引擎之间的差别，在于凸轮轴不是位于顶部，而是在汽缸旁，并从这个位置通过一种叫做推杆的长棒和锁臂来驱动气门。虽然此中结构较为简单、且便于维修，不过，在高速运转的状态下却缺乏可靠性，也因此通常不适合被赋予大功率输出。 转子引擎转子引擎(rotary engine)基本上也和往复式引擎一样，通过反复进气、压缩并燃烧、最后排除废气的过程来取得运转能力。然而在这样的过程中，转子引擎所用的原理却和往复式引擎完全不同。 在转子引擎当中有著名为转子室的茧形空间，完全取代了汽缸的功能。三角形的转子就安置在这个空间当中。在转子于其中进行偏心旋转时，转子和转子室之间的空间大小会有所变化，在此进行压缩-燃烧-排气过程。一般引擎之中通常拥有复数组的活塞反复运动，因此不仅难以控制作用力，同时也成为振动与噪音的起因。然而，由于转子引擎利用了旋转运动的原理，因此运转起来较为平稳顺畅。又因为不具备气门机组，所有有着零件总数大幅减少的优点。不过，随着往复式引擎近年逐步地趋向轻量化，相较之下，此优点并不显得格外突出，然而不可否认的，这种引擎整体而言是较为小巧的。转子引擎进气与排气的时机，取决于设置于转子室壁面与侧面的气埠（混合气体的通道）的形状而定。调节转子引擎的进气/排气时机，基本上便是通过改变气埠的位置和形状来进行。又由于回转引擎中不具备排气门，而是让排气动能直接自排气埠排出，因此非常适合搭配涡轮增压器。另一方面，转子引擎普遍被认为在节省燃料费用方面的表现不如往复式引擎。这是因为转子引擎的燃烧室容积与表面积比例相对较大，容易让热能散失，因此导致转换成回转动能的比例较低。 增压器若能让引擎吸入越多空气，便能提升越多马力。因此增加功率最简单的作法，便是从提升排气量着手。 然而有种东西可以不必提升排气量，便可获得相同的效果，那就是增压器(compressor)。这种装置可以大略分为机械增压器(supercharger)和涡轮增压器(turbocharger)。不过，大致上都是将空气压进引擎中（称为加压），以达到与提升排气量相同的效果。加压空气时的压力称为增压，提升此压力，便能得到更大的输出功率。 大气压为1气压时，记为1bar或1kg/cm^2。因此，若过增压为1bar连同大气压在内合计有2bar的压力，意味着会迫使2倍的空气进入引擎当中。 增压器的缺点在于随着增压提升，燃烧能量亦会提高，但同时却也会对引擎造成较大的损伤，例如偶发性的异常燃烧现象等。因此，装有增压器的引擎当中，大多会同时补强引擎内部零件的强度，或是降低压缩比例，以减少发生异常燃烧的次数。另外，空气经压缩之后将会夹带热能，使得密度降低，尤其在高负荷运作的条件或夏季时会特别显著，而此时点火亦无法得到巨大的爆发力（马力输出功率）据说进气温度每上升1度，便会损失1ps。因此，通过装设中冷器来降低压缩空气的温度，已被车坛视为常识。 由于增压器使用排气端的废气来推动增压器，因此在产生增压之前会出现一段延迟时间。另一方面，使用引擎曲轴作为动力来源的机械增压器虽然无此烦恼，但却会丧失些许引擎本身的功率输出。近来颉取两种增压器的长处：在低转速领域使用机械增压，但到了高转速领域该用涡轮增压的新引擎设计，开始受到业界注目。 机械增压器(supercharger)自引擎曲轴通过皮带来驱动增压器(compressor)，并将空气压缩后供给引擎的装置，便称为机械增压器。由于增压器的动力来自于曲轴运转，因此和涡轮增压器相比，具备在低回转领域有着极大的增压效果、加速反应灵敏等优点，并且相当适合搭配自动变速器。 图为鲁式(Rootsblower)机械增压器，其它还有李式(Lysholm)双螺管机械增压器、涡卷式(Scroll)等不同种类。 涡轮增压器(turbocharger)Turob意即涡轮机，通常是指利用通过排气管所排出的排气压力，来推动涡轮云总的增压器。由于使用排气动能作为动力，因此没有像机械增压器那样，会发生在高转速领域损失驱动力的缺点。但相对来说，由于排气的动能较低，在低转速领域不足以转动涡轮，就算想要开始加速，也必须等待涡轮转速升高。这就是所谓涡轮增压延迟现象的成因。为了克服此问题，技术人员想出了各种不同的系统架构，现在也仍不断地改进当中。目前欧洲地区仍持续推出可提升油耗表现的小型化涡轮引擎。 混合驱动系统混合驱动系统的目的在于并用引擎与马达以降低燃料消耗率。日本走在这个领域的前端，所开发出来的混合驱动车种清一色都是所谓的环保车，不过随着欧洲的车厂也开始研究，也许有朝一日这种系统会成为核心设计。 这种系统的弱点，在于引擎怠速和起步时的效率较差。不过，马达即使在零转速的情况下也能发挥最大扭力，且效率亦高，可以有效弥补引擎不擅长的低回转领域。而在速度上升之后，引擎运转的效率也随之提高，而相对低马达的输出效率则会下降。因此为了让两种机组都能在各自擅长的领域有所发挥，以充分提升能源的使用效率，混合驱动车便应运而生了。车上同时装载马达和电池的优点，在于可以回收能源再利用。这样的机制称为回生，在未踩油门/刹车时，会运用轮胎的转动能量带动发电机为电池充电，而这些存下来的电能，则可于再度驱动马达时使用。原本刹车产生的热能只能任其丧失，如今却能够回收成电能并再度利用。本系统的另一个优点，在于马达可以弥补引擎的性能，发挥近似于增压器的功能。欧洲车厂制作混合驱动车时，大多着眼于此。它们推出的这类车种，在设计上大多不使用增压器，改采用电动马达来呈现大排气量车种的驾驶感。 混合驱动系统种类 串联式(series hybrid) 并联式(parallel hybrid) 串并联混合式(series-parallel hybrid) 车子性能的关键字车辆的规格表上通常列出了许多数值与专有名词。必须充分掌握这些资料的意思以及解读方式，才能了解车子的引擎性能，并且推敲出车子锁蕴含的潜能。 马力(horsepower) 最能直截了当地表现出引擎性能的数值，便是以ps为单位的马力。1马力代表能将75KG重的物体在1s内举起1公尺的工作效率。也就是说，1台100马力的引擎可以将1T中的物体在1s内举起7.5公尺。马力是由扭力x引擎转速求得，所以即使引擎的排气量小，只要转速高，一样能够发挥出输出功率。顺便说一句，国际通用规格使用kW来换算马力（1ps:0.735kW）。 扭力(torque) 用来表示回转力的数值称为扭力。将长1公尺的扳手，对于位于1公尺源的螺帽施加1KG的力使其旋转时的回转力写做1kg-m。就引擎而言，扭力通常用来表示曲轴所拥有的回转力。扭力几乎等同于燃烧能，以自然进气引擎而言，大致上可以得到等同于排气量的扭力。一辆车的扭力越强，表示维持引擎回转的力道越强，如此一来我们便能说，这对驾驶人而言是一辆好驾驭的车子。 排气量/汽缸数(displacement/cylinder) 从排气量可以得知引擎能够吸入多少混合气体。这在往复式引擎来说，即活塞运动中往返的圆柱体积x汽缸数。 当引擎排气量越大，获得的输出功率也越大。然而若单个汽缸的容积过大，相对也会妨碍到运转。未解决此问题，一般采用的方法是增加汽缸的数目，来降低每个汽缸所需的容积。若汽缸数目增加，曲轴每回转1次在汽缸中的引爆次数也会随之增加，因此有着令引擎回转更加顺畅的效果。一般而言，一个汽缸的排气量以350-600cc较为理想，然而多汽缸引擎的成本非常高。因此，实际装载的汽缸数目大多依据车身尺寸和车款价位而定。 缸径衝程比(bore stroke ratio) 将汽缸内的衝程除以缸径所得到的值就叫做缸径衝程比。当此值小于1时，称为短衝程引擎；大于1时，称为长衝程引擎；等于1时，称为方型引擎。缸径衝程比会影响引擎的特性，一般来说，长衝程引擎在低中转速领域较容易产出扭力，但在高转速领域却不太能发挥功率；短衝程则相反。顺便说一句，当活塞运动到气缸内的最上部时称为上死点；降至最底部时称为下死点。 压缩比(compression ratio) 所谓压缩比是用来表示引擎将吸入的混合气体压缩至多少程度的数值。引擎的功率将大幅受此压缩比左右。将活塞被推至最下方时汽缸中呈现的最大容量(汽缸总容量)，除以活塞推至最高处时汽缸中呈现的最小容量(燃烧室容量)，即可求得此比例。所谓汽缸总容量，则是将活塞运动中上下往返的圆柱体积(排气量)再加上燃烧室容量。 以一个2000cc的4汽缸引擎为例，1个汽缸的排气量=汽缸容量(500cc)。假设燃烧室容量为50cc，则将总容量500cc+50cc=550cc处理燃烧室容量50cc，可得知压缩比为11。通常，自然进气式汽油引擎的压缩比大多设定在9-11之间，超过10的即可视为该引擎的排气量做了较高输出功率设定。若是装有增压器的引擎，一般则倾向于7-9之间。 将动力转化为速度的驱动装置为了有效地引出引擎功率并转化成速度，必须拥有适切的齿轮和驱动力配置。因此驱动系统的零件会大幅左右引擎效率。 变速器引擎每分钟可以达到数百甚至数千转，这样的速度如果直接用来转动轮胎则嫌太快，因此我们需要靠着变速器(transmission)，通过搭配齿轮(gear)以依照状况自引擎取出所需的速度与动力。 让我们回顾一下齿轮的原理。如果将某个此轮搭配上比它大的齿轮，那么虽然大齿轮的转速不如原本那么快，但却可以增大运作的力道；如果搭配的是比较小的齿轮，则虽然较小的齿轮转速较快，但相对取得的动力也比较有限。变速器靠的便是这样的原理。车子需要最大动力的时间点起步时，相反地，再告诉状况下维持固定速度行进时，则只需要少许动力即可。 因此在起步时让引擎搭配能产生较大扭力的大此轮（较大的减速比），才能确实地让车子往前推进。大齿轮虽然对于扭力有倍力的效果，但是转速较慢。这解释了为什么在打1档时，就算把引擎转速踩到极限，车辆的时速也只能达到数十公里左右。因此在变速器中北邮复数此轮，以逐渐缩小搭配齿轮（降低减速比）的方式，让使用者可以因应行进情况，自由地操纵车子的速度和动力。实际上在汽车当中，是靠着引擎正后方的变速器，以及驱动轮前方的最终传动齿轮两者间的搭配组合，调整出齿轮比例。变更此一齿轮比例，便能大幅影响车子的行进特性。特别是在赛道奔走时，为顺应赛道特性选择合适的齿轮搭配，往往是缩短时间记录的重要关键。 终传齿轮介于引擎和驱动轮间，在驱动机组中做最后一道减速步骤的此轮装置，就叫做终传齿轮。从整体驱动机组的角度来看，他和变速器有着相互补强的关系，也可以把它看做是将引擎的转速再减速过一次之后，才传给轮胎的装置。在纵向配置引擎的车种中，最终传动齿轮则还肩负著将动力传导的方向转换90度的责任。 由最终传动齿轮独立在变速器之外，因此比较便于拆装更换。换言之，当我们想要大幅变更车子的特性时，最终传动齿轮便是必须考量的重要因素之一。一般而言，若重视车子的运动性能，只需要调高最终传动齿轮齿轮比，就能提升车子的加速能力（到达极限会降低）。相反，若以降低燃料消耗为目标，则只需降低齿轮比，便可收到降低引擎转速的功效。 双踏板式变速器的种类 AT(Automatic transmission)自动变速器。利用扭力变换器（流体离合器）调整引擎断断续续输出的动力，能够顺应车速和引擎转速，自动切换成适当的变速比率，而在内部则配有行星齿轮，通过油压进行控制。虽然优点在于能够顺畅地进行变速，然而却也会因为使用油压带来打滑或浪费功率的问题，在油耗上比较不理想。 CVT(Continuously variable transmission)无段自动变速器或连续可变变速器。不像一般变速器通过切换齿轮达到变速效果，这种变速器通过变化金属带和链条等连接成的2组滑车和滚轮的直径，来连续地变换变速比。这种变速器在变速时不会产生震动，且在各种行进状况下，都能选择效率最佳的引擎回转域来行进。 DCT(Dual clutch transmission)双离合变速器是将手排变速器的操作以2具离合器加以自动化之后的产物。通过将奇数档分在不同轴上，以双离合器分别瞬时切换，在变速性能上可以超越手排变速器。在自动变速器当中，受限于行星齿轮的回转性能，引擎的最高转速也受到限制。然而，双离合变速器却能够搭配高转速的引擎。正因如此，跑车以至于环保车种都能有效地发挥此种变速器的性能。 差速齿轮对于左右两侧都有驱动轮的车种而言，差速齿轮是不可或缺的零件。虽然这在完全直线行进时派不上用场，但是会在过弯时发挥重要的功能。 过弯时，弯道外侧轮胎行走的距离比起内侧轮胎要来的长，这就是所谓的内轮差。如果不顺应这样的差异，对内/外胎设定不同的回转圈数，那么内侧轮胎将会卡住，车子根本无法转弯。能够吸收这种差异的，便是这里要介绍的差速齿轮。差速齿轮通常和终传齿轮整合为一，装置与左右驱动轮之间。 平时在车子直线前进时，主动此轮会配合终传四轮旋转与边此轮周围绕行，以将引擎动力传导至边齿轮。此时分配给左右驱动轮的扭力是相同的。而当开始过弯进入回转状态时，位于弯道内侧的轮胎将产生阻力，而这样的阻力会通过传动轴传至内轮的边齿轮。此时，原本只会绕着齿轮周围公转的主动齿轮会同时展开自转，以调整外侧轮胎和内侧轮胎之间的回转差。如此一来，分配引擎动力时，将只传给产生阻力的弯道内侧较少的动力，而给外轮胎更多的动力，以弥补两者之间的回转差。 限滑差速器前面介绍了差速齿轮在弯道的作用，不过这种机组在结构上存在著弱点：在装置了差速齿轮的驱动轮之中，只要有一个轮胎离开地面，就无法将驱动力传导给其它驱动轮。这是因为此时离开地面的轮胎将会空转，而差速齿轮则视图修正空转胎的回转差，将驱动力全部传给这个轮胎。路上常可以看到卡在泥泞或雪地上的车子，大多是因为差速齿轮的这种特性造成的。 因此，当左右驱动轮之间的回转差大于某个范围时，能够限制差速齿轮功能的，便是所谓的LSD(限滑差速器)。LSD的原理，是借由装上能够限制两侧边此轮转速差的装置，达到确实将驱动力分配各两轮的目的。具体的方式可以细分为多板离合器式、电子控制式、以及通过齿轮咬合和转轴方向产生的摩擦力，所作动的粘性耦合式等设计。LSD机制运用在跑车车种上时，与其说是为了从泥泞中爬出来，不如说是为了确保驱动力并提升操控性。 LSD的种类： 扭力感应式(torque sensing type)采用特殊齿轮组合的方式。当左右驱动轮间产生扭力差时，便会增加齿轮的齿面阻力，以限制差速效果。由于这样的差速限制力相当大，运用在像赛道上行进这类对车子负担较重的场面特别有效；切实际产生限制差速效果的反应时间也相当迅速。此类除多踏板离合器式之外，还有扭力感应式、螺旋齿轮式等。 回转感应式(revolution sensing type)不限制差速齿轮运作，而是利用高粘度矽油的方式。除了最具代表性，利用油类剪阻力（物质内部抗形变的阻力）的粘性耦合式之外，还有利用油类通过孔穴式。和扭力感应式相较之下，此类的差速限制力比较和缓，反应速度也比较迟，但是相对的也比较适合用在低摩擦系数的路面上。 动态控制式(active control type)就是电子控制式。由电脑通过收集自各种感应器的资讯，主动地进行差速限制。通常用在越野赛车等竞技车种当中。一般都用于世界越野锦标赛(WRC. 支持汽车行进的骨架车身结构对行进性能造成的影响大于引擎和变速器，操控性优良与否也取决于此，可说是一辆车的基础，也是最根本的部分。 车身应具备的性能能与车身、引擎、以及悬吊并列足以左右车子个性的要素，则是一辆车的骨干。一般来说，我们要求车身必需兼具刚性与强度，还得同事追求轻巧。这里所说的刚性简单来说便是不易变形的程度，而强度则是不易损坏的程度。 上述特征中，刚性对行驶性能造成的影响特别大。当一辆车通过凹凸路面，或处在过弯等对车身造成负担的状况下时，若车身仍不会轻易变形，则可以说这辆车刚性高。就算车身变形了，只要能够瞬间恢复原状，悬吊便可以正确地运作，也能提升轮胎接地性。车身刚性够高，动力便容易传达到路面，车子行进更加安定，也较容易驾驶。加诸于车身的冲击力并没有固定的模式；有些缓慢的到来，也有突然发生的。而在车辆的产品型号上有着弯曲刚性和扭曲刚性这类标示，这些大多是针对缓慢到来的冲击力而言的刚度。然而，真正具备高刚性的车身，即使受到剧烈摇晃这类瞬间的冲击力，也必须能够承受。另一方面，所谓的强度即硬度或坚固的程度。强度过低时，发生冲撞时对车身的伤害较大。然而，若因此便让车子具备有如坦克车般的强度，则虽然让车身毫发无损，但激烈的冲击力却会相对加诸在乘客身上。一辆车的车身，必须将刚性和强度的平衡追求到及完善的境界。如果只是要单纯地提升刚性和轻度，有许多简单的补强方法。然而，却无可避免地会让车身变重。 框架式车身(frame body) 也称为非承载式车身或车身与车架分离式结构。这种结构是将引擎和变速器、悬吊等装置在固定的车架上之后，再架设上理你性制作的车身。除了梯型式，还有背骨式、周长式、平台式等。而其中又以梯型式较能压低制造成本，同时又能确保强度，所以许多越野车种喜欢采用。 车体式车身(monocoque body) 车架和车身一体成形，是现代车身结构的主流。整个车体的强度来自于车身板件等多项结构零件，有如蛋壳般地支撑了车身的整体强度，不仅轻巧且也具备了高刚性。这种架构的另一个优点在于可以降低底盘高度，而在发生冲撞时也易于吸收能量。由于引擎和悬吊直接安装在车身上，使得过去这样的架构在乘坐舒适性和噪音抑制方面，一直比不上框架车身。然而，随着悬吊不断演进及组装技术提升，这些缺点已成为过去式。 用来降低车速的热交换器减速就是将车子行进的动能转化为热能。除了让车子停下的功率理所当然地必须大于引擎功率外，对于过热问题也必须做好万全的处置，因此这是车上最重要的零件。 结构与原理汽车的刹车，说穿了就是将动能转换为热能，以降低车速的装置。这种装置也有固定车身、防止静态状态下的车子产生移动的功能。 组成刹车的基本原件为接受驾驶员命令的操作装置、传导操作力的液压回路，以及最重要的制动装置。近来的刹车系统则还会在液压回路中额外加装能够放大操作力的倍力装置，以及能够防止轮胎锁死的ABS系统。刹车踏板和制动装置之间通过液压回路相连。由于液压回路仰仗帕斯卡原理运作，因此啥词踏板前端连接著一个大剖面积的刹车总泵。这个刹车总泵中产生的压力在放大过后，再传导给刹车来令和蹄片。刹车来令和蹄片是摩擦介质，将它们压在刹车碟盘或刹车鼓上之后，才能将动能转换成热能，以降低车速。流动在液压回路当中的并不是一般油类，而是专用的刹车液。针对刹车时的热能，刹车液必须具备不易沸腾的特性，也因此主要依沸点分为几种不同种类。随着高速道路的逐渐普及，小客车主流的前刹车设计，已由鼓刹转为碟刹。碟式刹车主要是通过在刹车卡钳当中的刹车来令片从两侧家住刹车碟盘，已发挥制动力。 碟式刹车(disc type) 通过从两侧来令片家住转动的金属制圆盘（刹车碟盘）产生摩擦力，以发挥刹车效果。最大的优点在于包括刹车碟盘在内，几乎所有的结构零件都露出在外，所以通风性、散热性十分优秀，不容易过热。另一个优点在于当水附著在刹车碟盘上的时候，可以靠著碟盘本身的旋转将其挥散，因此不至于使摩擦系数降至过低。不过，这种刹车虽然易于通过调整脚踩刹车踏板的力道来微调制动力，然而，自身却没有产生倍力效果，以至于如果停车时的制动维持力不如鼓式刹车。 鼓式刹车(drum type) 这种刹车系统，乃是将刹车蹄片由内侧压在和轮圈一起转动的圆筒型刹车鼓上来取得制动力。由于散热性不佳，比碟刹更容易发生过热的情形，且若刹车内部进水，需要一段时间才能恢复摩擦力。不过在制动时，刹车蹄片会自动朝向咬住刹车鼓的运动方向，因此可以发挥极大的制动力（这称为自我倍力作用）。在小客车上 ，通常装载刹车负荷较小的后轮为多，而在大型车中则会把它装载后轮碟刹的内侧，作为驻车用的刹车。 摩擦热引起的刹车问题 过温衰退现象(fade) 当过度使用刹车时，造成制动力急速下降的现象。具体而言，这样的现象时因为用作摩擦截止的来令片和刹车皮过热后产生气体，而这些气体在刹车碟和鼓之间发挥了近似于润滑剂的作用，导致摩擦系数降低。 气阻(vapor lock) 过热的来令片和刹车皮上的热能使得刹车液沸腾，使得刹车油管内产生气泡的现象。此时即使踩刹车踏板也无法将正规的压力送出刹车液，最糟的状况下甚至无法取得制动力。 刹车碟盘的种类 实心碟盘(solid disc) 仅使用一面碟盘，是最基本的结构种类设计。虽然散热效果不如通风式刹车，不过由于制造成本地，所以用于许多轻型汽车的前刹，或者在4轮碟刹系统中负责制动时符合较小的后刹。比起通风式刹车碟，此类设计对摩擦热承受度较强，并以散热效果高的钢铁材质为主流。 通气式碟盘(ventilated disk) 结合两面刹车碟盘，并在其中设置多个散热孔。原本是为了赛车所开发、运用，不过现在许多客车也采用此种刹车碟盘。由于和实心碟盘相较之下，碟面温度大概降低了30%，因此可以进一步提升耐热性（以及防止过温衰退），并延长来令片的寿命。缺点在于碟身较厚导致重量较重。 更加进化的通气式通气式刹车碟： 针孔式碟盘(pinhole type) 一般用来指在通风式刹车碟盘的摩擦面上打更多的洞，以提高散热性、冷却效率的刹车碟盘。而这种也叫做攒孔刹车碟(drilled disc)的碟盘设计，同时频繁使用在赛车和高性能跑车上。这些洞孔对于排除制动时产生的摩擦粉也很有效。而另一种在表面上挖满槽的画线式碟刹(slit disc)，在设计上也是出于同样目的。 螺翼式碟盘(spiral fin type) 在贴合的2面刹车碟盘内侧将散热排成螺旋状。翼片的形状是经过解析刹车碟盘内气流数据之后做出最佳化的设计，可以伴随着车辆转动有效地排除摩擦热。除了常用在高性能跑车以外，也会用在车重较重的大马力车种上。 刹车卡钳 浮动式刹车卡钳(floating type) 这是在刹车卡钳内部只有单边具有将刹车来令片推出的刹车活塞的型式，因此也叫单活塞式。承受来自于刹车踏板油压的活塞只存在于机组的一侧，对面的来令片则靠反作用力压制住刹车碟盘。在这种刹车卡钳当中，与刹车碟的解除位置是常时在调整的，且左右两侧来令片之间不存在著时间差的变化，每次都能得到同样的刹车感。由于这种刹车卡钳本身体积较小，重量也较轻，因此可以顺应高温扭曲变形的碟刹做出应变。虽然在赛道等连续行驶的状况下会导致效果降低，但是从性能上来看，在一般使用情况下丝毫没有问题。 对向活塞式刹车卡钳(opposite piston type) 左右皆装有刹车活塞，从两侧将来令片夹上刹车碟盘的型式。由于这种结构体积较大，必须选用吕质刹车卡钳，因此仅以维持刹车卡钳的刚度。用在赛道等跑车的行驶条件下十分有效，单向有发挥原本的性能，如果不一并把刹车碟盘改装成浮动式，碟盘会因为热变形而倾斜，导致来令片无法确实著力。随着刹车碟盘直径逐渐变大，市面上也有不少采用4活塞设置6活塞这类复数刹车活塞、以及来令片总面积较大的车种。从吕质轮圈的空隙间能窥见的大型对向活塞，可说是一台高性能车的有利表征。 控制车身动态的缓冲装置伸缩乍看之下是种简单的运作原理，然而车上要是没有悬吊，不仅无法正确操作，甚至无法正常行驶。 构造与原理从结构上来看，悬吊位于车身和轮胎间，一边支撑着车身，一面吸收来自轮胎的冲击力。这重要的机制大幅影响着车子行进间的操纵稳定性。 悬吊可以大略分为左/右轮动态会影响到另一轮的固定式悬吊，以及左右轮个别作动的独立式悬吊。而这两类悬吊又各自有几种具代表性的形式，如固定式车轴式、吊环式、扭力梁式等。而独立式则有支架式或双叉骨式等等。悬吊本身由弹簧、减震筒、连杆支臂等结构组成。弹簧能够缓和来自 路面的冲击力，减震筒则是可以抑制弹簧的弹跳，提升搭乘的舒适感与稳定性。连杆支臂则用在限制轮胎的动态，让轮胎能以最佳的方式与地面接触。悬吊还有另一个重大的用途，是通过弹簧的反作用力将轮胎压在地面，以稳定轮胎位置。 弹簧(spring) 除了具备先一步吸收加诸于行进间车身的冲击力、缓和震动的功能之外，还有维持固定车高的功能，是会影响操控性、方向盘性能、动作稳定性的重要因素。因此我们可以说，就算只调整弹簧设定，也足以让车子的个性不大相同。而一般除了金属制的线圈弹簧以外，还包括利用空气压力的气压式悬吊。 减震筒(shock absorbers) 线圈状的弹簧在承受负重时，虽然可以通过伸缩原理加以缓冲，然而光是如此却无法消弭上下的运动量。而抑制这样的动态便需要减震筒（也称阻尼装置）的责任。一般常见的减震筒种类是仰赖活塞在密封于筒内的油类和气体中上下运动时遭遇的抵抗力来运作，可通过慢慢伸缩、慢慢恢复的动态，来缓和弹簧激烈的上下运动。因此减震筒和弹簧同样左右着车子的操作性和稳定性。 悬吊臂(suspension arm) 这是控制轮圈动态的零件，也称为控制臂。这种零件借由安装在车身与轮轴之间，可以依照各种不同的形状分为A臂和I臂等不同种类。基本上使用压合钢板，不过有时也会使用强度更加的锻造制品。在双A臂式悬吊这种上下成对的悬吊组当中，上方称为上臂，下方称为下臂。 稳定杆(stabilizer)利用扭杆弹簧的扭曲来抑制车身晃动的安定装置，也称为防倾杆。两端安装于悬吊的下臂上，只会在左右车轮动态相異时作动。例如在过弯时，外侧车轮下沉，内侧车轮将会拉高，此时稳定杆就能控制左右车轮成为相同的动态，让行车姿势更安定。也有人会可以利用稳定杆的这种效果，调校成可以用来应变转向不足、转向过度的设定。 悬吊衬套(suspension bush) 用于构成悬吊的金属制连杆和悬吊臂等的结合部位，或是装著于车身部位的缓冲材质。如果衬套硬度不足，将会因过弯等情况下庞大的负重而变形，使得悬吊产生不必要的动作，影响车子的操作性和稳定性。因此，衬套的材料一般都选用冲击吸收性佳的橡胶材质，不过在竞技用车种当中，为了减少不必要的动作，较常改用鱼眼(pillow ball)这种金属球面轴承。衬套是能够引导出弹簧和避震装置性能的重要零件。 悬吊的种类虽然各种不同的悬吊同样具有保持车高、介绍行进间的负重和冲击的功能，不过彼此间的性能和特性却是各不相同的。这些性能与特性的差异，会影响到过弯、行驶性能、与安全息息相关的操控性能、以及乘客乘坐时的舒适性。悬吊正日新月异地进步，目前已发展出了许多不同种类。虽然结构复杂并非就等同于具备了高性能，但是为了实现理想的悬吊能够瞬间追踪路面的凹凸起伏，保持轮胎能够维持在正确的接地状态的目标，目前各方专家仍在持续努力研究改进的技术和手法。 固定式(rigid axle) 所谓固定式悬吊，即通过车轴连接左右轮和轮圈的结构。由于轮胎的动作将会传达给另一侧的轮胎，因此容易降低接地性。且因轴梁和轴殻本身重量也重，在比较簧下重量时便较为吃亏。不过一你诶这种结构成本低、且强度优异，尝尝用在低价位的后轮驱动车种中作为后悬吊。 独立悬架式(independent system) 能够让左右车轮独立上下运动，在应付凹凸起伏路面方面的表现亮眼。特别是在后轮驱动车种中，可以有效地将动力传导给左右车轮。除此之外，还能减轻运作部位的重量。能够兼顾操控稳定性和乘坐舒适性的特点也让人激赏。 常见于跑车款中的独立式悬吊： 支柱式悬吊(macpherson strut) 基本上是由弹簧和避震装置以及下臂组成的简单结构。strut的意思是承受作用力的支柱，在此指的是减震筒与弹簧装置。减震筒的上端通过缓冲橡胶支撑车身，下部则由下臂支撑。不了零件数量少，得以控制重量之外，也因为易于确保衝程距离，可吸收较大范围来自路面的震动。 双A臂悬吊(double wishbone) 由上下成对的悬吊臂悬架起车轮的结构。使用双悬吊臂，而因为V字型排列的悬吊臂就像鸡的锁骨的形状，因此便以之命名。随着悬吊臂形状和配置位置不同，可以比较自由地控制加速/减速时车子的姿势和车轮矫正的变化。另外也因为这种悬吊便于追求高刚性，所以常用在重视操作性和稳定性的跑车当中。然而，相对的也因为零件数量较多且结构复杂，需要较大的安装控件。 多连杆式悬吊(multi link) 虽然这属于双A臂式悬吊的进化形，不过相较于双A臂式悬吊仅由上下2根悬吊臂组成，这种悬吊则由3-5根的连杆来决定车轴的位置。由于各悬吊臂互相分离，配置的自由度极高，方便进行更细腻的调校。并且在由数根悬吊臂共同支撑的情况下，可以严密地监控悬吊系统几何的变化，轮胎接地性亦佳。在高性能的FF驱动车种一季大马力的后轮驱动车种当中，常以此为后悬吊，以维持在高速领域的动态稳定性和确保马力。 车辆矫正如果你身边的家具或椅子上装有移动的车辆，请稍微留意一下。从正上方俯瞰，便会发现车轮的中心轴与它被装在家具上的轴心位置并未对齐。在移动家具和椅子时，车轮之所以不会乱摆，而能朝着固定的方向前进，这是多亏了这样的位置差。 另一方面，假设我们把轮胎拆下来，任其在地面上滚动，那么躲过滚动时轮胎的接地面紧密地沿着地面，轮胎便会直线前进；然而若转动时只使用到一部分的接地面，就会发现轮胎会朝着特定的方向转弯。这说明了当轮胎固定在车身上时，只要给予各种不同的角度，便能让轮胎在适合车子的运动条件下运作。这就是所谓的车轮矫正(whell alignment)（悬吊系统几何）。行驶-过弯-停止的基本原则建立在4轮矫正处于正确地装置状况下，这道决定轮胎位置的手续将可引导出轮胎的性能，设置发挥决定车子特性的效果。 具体而言，车轮校正的代表性因素共有如下所列4项： 从车身上方俯瞰时轮胎的角度————束角； 从车身侧边看去时悬吊的倾斜角度————倾斜角； 从车身正面看过去时轮胎的扁平度————外倾角； 车身正面看过去时轮胎的扁平度————外倾角。 这些角度都必须以0.1mm或0.1度的精确度加以管控，只要有些许的误差，便会影响车子的直进性能，或让操作感觉起来有异。因此，务必谨记这些因素会对车造成的影响。 束角(toe angle) 自车身上方俯瞰时，左右轮朝外侧展开的角度。当轮胎朝向行进方向的外侧展开时，称为外束角(toe-out)，而朝内侧收敛时，称为内束角(toe-in)。此角度会大幅影响直进性，设定角度过大时将会使轮胎产生偏磨损。 后倾角(caster-angle) 从旁看向车轮时前悬吊的倾斜角度。这个角度除了有抑制轮圈横向震动的效果之外，还具有自校准扭力(self-aligning-torque)，打方向盘是会尝试着将轮圈转回直进状态的作用力的功用。如果左右轮的此角度不同，则车子会偏向角度较大的那一侧，导致在制动时无法操作方向盘的现象。 外倾角(camber-angle) 从车子正面看去，轮胎下册变宽的状况较做负外倾，而上侧变窄的状况则称为正外倾。在正常状态下，为了防止负重时轮胎呈外八字行，因此会实现设定为上方较开的角度。 内倾角(king-pin-angle) 从正面看向轮胎时，固定轮圈轴心的倾斜角。这个角度基本上用来输入自路面的作用力，以防止方向盘失去控制。主要影响车子的直进性、操作方向盘时的复元力（自校准扭力）、方向盘操舵力。 汽车与路面的交会点TIRES 引擎动力经由传动系统和悬吊，最后通过轮胎传到地面。无论是什么车种，行驶时都无法超越轮胎所能负荷的性能。 高性能轮胎的条件轮胎的功能主要分为4项： 支撑车身重量的负重支撑功能； 缓和来自路面冲击力的缓冲功能 开始行进与停止的制动/驱动功能； 安定地在直线与弯道上行进的路线维持功能。 改装轮胎时，必须在确保上述4项功能之间取得平衡后，才能按照各种轮胎不同的性能与特性进行调校。 就重视行驶功能的跑车轮胎而言，如果提升制动/驱动功能和路线维持功能，也就是有关开始、行进与停止的项目，显得格外重要。具体的做法是提升接触地面的橡胶的抓地力，并且提高刚度以抑制轮胎负重时的变形程度。如此一来，以过弯时为例，就可以让车子对方向盘操作的反应变得更敏锐，大幅提升回转速度。当然，高抓地力的轮胎也有其缺点。这种轮胎虽然在过弯时负荷极限较高，但是一旦超过了极限就会变得难以控制，因此需要箱单的驾驶技巧。另外，这种轮胎也会增加多悬吊与车身的负荷，打破抓地力的均衡，使得过弯中的翻滚量变大。这意味着要使用这种轮胎，车子也必须有足以支撑的负荷的能力。而且由于轮胎与路面的摩擦力较大，使得磨损迅速，会使得搭乘感受恶化，噪音也大。在泾滑路面上行进时，刻在轮胎接地面的满纹将会大幅左右其性能。这些满纹的目的在于排除存在于轮胎与路面间的水分，然而排水性能和接地面的刚度之间却有着相对的关系。在跑车轮胎中，两者间的平衡特别难以取舍。汽车无法超越轮胎所能负荷的性能行驶，因此必须具备相关知识，才能选出符合自己的驾驶风格的轮胎。 胎面胶料(tread compound) 用于接地面的橡胶。高性能轮胎使用抓地力强的软质橡胶，由于与路面摩擦力大，磨损迅速。而另一方面，一般车种使用的则比较表示耐磨损性，选择的硬质胶料就仅有一般水准的抓地性能。另外，虽然橡胶在未升温到某种程度时呈现坚硬的状态，不易发挥原本的抓地力，然而过热时也会使抓地力降低。 胎面花纹(tread pattern) 即雕刻在接地面上的纹路。主要目的在于（随着转动）将路面的水排出去。许多汽车为了提高排水效果，还会特别采用具备指定方向性纹路的轮胎。另一方面，由于胎纹是造成接地面刚性降低的主要原因，所以高性能轮胎通常会省去细微的纹路，全部采用较粗的胎纹。而有些轮胎甚至会使用左右非对称的纹路，减少在过弯时会被强力地压在地面外侧部分的胎纹以提高胎面刚度，并将较多的胎纹设置在内侧以改善排水性。 胎身刚性(casing rigid) 轮胎的横剖面有胎面、胎臂、各胎体层组成有如一容器状，而这种结构的刚度就称做胎身刚性。来自路面加诸于胎面的力将会传达到各部位，最后由胎圈底部承受。也就是说，在加速/减速、过弯这些对轮胎造成庞大负荷的场合，为了不使轮胎发生不必要的扭曲，重要的是提升轮胎整体的刚性（胎身刚性）。然而，刚度越高，虽然能提升车子的运动性能，却会损及搭乘时的舒适度感。这也是为什么调校轮胎时，必须考虑其扮演的角色和使用目的。 以吕制为主流的轮圈WHEELS 簧下重量每轻1KG，收到的效果是簧上重量轻量化的15倍。想要彻底在起步、加速、制动、过弯发挥出完整性能，绝对少不了选用轻巧的轮圈。 簧下重量吕制轮圈装饰性意义虽强，但一方面也仍对形式心梗造成不小的影响。 车子需要最多动力的时机在于起步时。想要让车子由静止状态稍稍开始移动，需要极大的动能。如果轮圈较重，则不易使其转动；所以轮圈越轻，便只需少量的动能(引擎马力)便可让它转动起来。因此这项条件就称为簧下重量，会大幅影响车的运动性能。轮圈和轮胎越轻，不仅起步、加速性能会提升，制动时也容易停止轮胎的转动(刹车较为有效)。另外，悬吊的运作也更加流畅，路面运动表现和搭乘舒适感也都会获得改善，更能节省燃料费用。目前成为主流的吕制轮圈，在优良的导热性、热容量以至于排除刹车热的效率方面的表现都十分出色，而且比起铁材料，耐腐蚀性更是优异。而在更换轮圈时，要特别注意尺寸变大导致重量增加。特别是尺寸大幅提升时，通常也会使得簧下重量大幅增加。因此必须审慎考虑扁平轮胎所带来的好处，以及随之增加的重量所带来的坏处。 结构： 单片式(one piece)轮框部位和轮盘部位一体成形，是最基本的结构。由于在制作上于锻造后进行切削加工，因此尺寸精确度极高。虽然在设计上自由度较小，不过因为零件数量少，重量较双片式和三片式来得轻，在重量平衡方面表现也相当优异。 双片式(two pieces)分别制作轮盘部位和轮框部位，使用螺丝和螺帽，或用焊接方式连接两者的结构。这种作法允许在轮盘和轮框分别采用不同的材质（镁、铝、钛…）和制造方法（锻造、铸造），因此在调整偏距值和设计轮盘的自由度上较高。 三片式(tree pieces)焊接起表面的轮框部位和内侧的轮框部位，再用穿孔螺栓组装轮盘部位的结构。具有双片式的特征与优点，但在重量上较为不利，因此许多重视时尚设计感的轮圈都采用此结构。 制法： 铸造(casting)将高温融化的铝液注入模具中使其成型的制法。用在双片式和三片式轮圈当中，可以提高轮盘部位的设计自由度。反过来说却也因此必须为了维持强度而增加厚度，使得原本该材质相较于钢铁材质在重量面的优势变得比较不明显。由于制作成本低，是为目前铝制轮圈的主流方法。 锻造(die casting)用数千吨的高压压缩金属块（令金属分子重新排列），使其变成高韧性、高硬度的材质。由于成品强度由于铸造，所以可以牺牲厚度换取亲量化。然而却也因为高硬度的特质，使得成品虽然抗拉力机枪，但是对扭曲变形力的承受力却较为脆弱，且制作成本较高，设计上限制也多。在材料方面不至于铝制，在赛车和部分跑车当中，设置还可以看到选择了比铝还轻的镁制轮圈。 对车身作用的空气力AERODYNAMICS 车身设计的影响力足以全盘改变汽车的高速性能。从极速、稳定性以至于经济性能都与此息息相关。现在讨论车子时，空气力学已是无法忽略的一大主题。 空气阻力与异力在高速行进间，空气阻力将发挥极大的影响力。这道肉眼看不见的空气墙，在车速越快时，会夺走越多车子的行进动力。 空气阻力所造成的影响大约从时速80公里以上便开始无法忽视，之后更随速度提升等比放大。也就是说当速度提升为2倍，阻力便成为4倍；速度提高3倍则阻力可达9倍。虽然实际上还必须将轮胎的转动阻力等因素考虑进去，不过，当引擎马力无法冲破这道空气墙时，那就是这辆车的极速。因此对重视极速与高速性能的带车与跑车而言，如何减低空气阻力的重要性自然不在话下。就连对以讲求节省燃料费用为诉求的车种来说也不容小觑。车高较低的阻力较小，而车身外型则以能够顺畅地将行进气流送往后方的流线型与楔形较为吃香。还有一种去除车身表面多余的凹凸起伏（齐平表面处理），同样是可以降低空气阻力的设计。仍需留意的是，空气阻力较小的车身，从侧面看去通常会呈现像是飞机主翼的形状。在这样的车身上，流动在上方的空气快于下方的空气，导致产生让车身往上方浮起的作用力（昇力的问题），然而要抑制昇力却又必须增加空气阻力。因此，如何在空气阻力和昇力之间取得平衡点，便是开发车子时的重要关键。另外，在高速行进间会打乱车子直线行进的横风，也是无法忽视的重要因素。在空气力学方面，必须考虑进包含空气阻力、昇力以及偏向力矩各种条件在内的整体平衡。 正面投影面积(frontal area)从车身正面望去时的车身剪影。此面积越广，必须承受越多的行进风阻，阻力也就越大。跑车之所以将车身压低，就是为了尽量缩小正面投影面积。因此箱型车或小货车在这方面必然较为不利。 Cd值-风阻系数(constant drag)这是用来表示当风吹在某个物体上时，气流流动的顺畅程度的系数。实际上在行进间会造成问题的空气阻力，就是一次空气阻力系数乘上正面投影面积所得。因此即使跑车的Cd系数高，只要正面投影面积小，承受的空气阻力便小，而向房车这类车种可说刚好相反。 CL值-昇力系数这是用来表示高速行进间的行进风产生的让车身上浮的作用力的系数。而相反地，将车身往下压的作用力则称为下压力或负昇力。想要获得下压力，必须增加空气阻力，因此为求稳定车子的动态，必须将车身前后的下压力调整到最佳平衡。 CYM值—偏向力矩系数(constant yawing moment)行进间所承受的风力不仅限于前方。当风力来自各种方向时，产生在车身中心轴周边，视图使其回转向的作用力=妨碍直线前进性能的力就称为偏向力矩。CYM值小的车种比较耐横风，而一般来说重心高度较高的高车身车种在此方面较为吃亏。 改装汽车Tuning and Settings 提升引擎的战斗力一味提升引擎马力，只会让车子更难驾驭，无助于让它奔驰得更加快速。因此必须先看准了追求的目标为何，如何炒理想迈进，才能做出符合车子用途或赛道条件的完美调校。 微调更换引擎电脑与改善排气系统的效率，可以说是为了提升引擎基本体力而做的处理。这些处理会成为之后针对引擎本体进行机械调校、加装增压器等正式调校工程的基础。虽然这些处理无法大幅提升马力，但效果却会展现在转速提升速度变得更敏锐、油门反应速度更快等，让驾驶员操作起来更舒适。另外，这些调校对于引擎造成的负担较小，且具有在高负荷运作下保护引擎的效果，可以带来提升引擎耐久度的好处。 电脑(computer) 通常是改写存有控制引擎的相关资讯的ROM中的资料，也称为记忆体调校。当提升增压器的增压质、更换进排气系统的零件以及对引擎本体做过变更之后，就有必要进行记忆体调校。 火星塞(spark plug) 想要对燃烧室内的混合气体点火使其正常引爆，需要产生强力的火花。即使是一般引擎，如果持续使用一般火星塞在高负荷下运转，便会导致过度燃烧。特别是在通过调校提升过马力的引擎当中，爆炸力增强将使燃烧室温度上升，导致变得容易发生异常燃烧现象(pre-ignition，也称预燃)。因此必须提高火星塞的耐热度，选择高价的火星塞。 空气滤清器(air cleaner) 空气滤清器能够去除引擎进气中含带的灰尘与异物。一般款式的阻力较大，会对马力输出造成不利影响，因此更换成阻力较小的竞赛用款式较为理想。这样带来的效果与其说是提升马力，不如说是会提升高转速领域的引擎反应速度和加速时加速性能方面的表现。同时，吸气音也可变得更大声。 排气系统(exhausut system) 降低排气阻力能够使引擎转速上升的速度、踩踏板时的油门反应速度变得更加敏锐。此调校对于利用排气动能驱动涡轮增压引擎来说效果尤其显著，甚至只靠着调校消音器便能提升1-2成马力。不过，在更换零件后引擎的扭力特性也会随之变化，因此动手调校引擎前应该要根据调校目的，预先设想调整后想得到的特性。 机油(engine oil) 高马力引擎内部各处都必须承受极大的压力，因此也必须使用高性能机油。机油除了润滑之外，还负有冷却、保持气密性等功用，因此若发生油膜破裂等情况，将引发缩缸导致马力降低。而在高速运转的金属零件之间，如果来不及润滑，很容易便会烧毁。另外，在选择机油时，影响摩擦损耗的黏度也是重要条件之一。 检修在以量产为目的的引擎当中，一般状况下的运作精确度可能未臻完美，导致无法发挥原本应有的马力。要改善这种状况，可以通过把引擎全面拆解为零件，重新加以精密组装，以压榨出引擎的所有性能。这是称为检修(overhaul)的作业步骤，若同时配合调整各零件之间的平衡与轻量化，可以收到更显著的效果。若调校条件对于排气量没有特别限制，借此机会同时提升引擎汽缸本身的容量，可望更有效率、更合理地提升马力和扭力。 提升排气量(scale up) 这是在对引擎本身进行调校时，可以最确定收到最高的效果的工程。让引擎燃烧更大量的混合气体，便可得到更大的马力。在做法上则可分为削薄汽缸内径，该用大口径活塞的扩大缸径式，或是更换曲轴与连杆等零件以增加活塞衝程的衝动式两种。虽然同样是增加排气量，但两者在特性上相当不同。前者适合增进提升转速以取得马力，后者适合用以提升中低转速领域的扭力。最近的引擎由于普遍经过轻量化处理，汽缸体的零件厚度变得较薄，因此想要大幅地提升内径更加困难了。 调整平衡(balancing) 在一般状态下，每个汽缸的活塞和连杆之间都存在着些微的重量误差。而曲轴的旋转平衡若不佳，则会产生阻力，成为损失马力的主要原因。因此，调整平衡所要做的就是分解引擎，并精密地测量、同一每个零件的重量，以及修正旋转平衡来确保引擎运转顺畅，并有效率地引导马力。如果只靠加工零件无法达到上述目的时，甚至必须更换全新的零件。对于参加无法大幅改造引擎的统一规格赛的赛车而言，调整平衡可说是必备的已向调校作业。 轻量化(lightweighting) 惯性会出现在以超高速运转的引擎零件上，造成摩擦损耗而折损马力。能够解决这个问题的便是轻量化处理。基本上，轻量化必须与调整平衡作业同时运行，不过，若过度轻量化削薄零件的厚度，将会发生耐久性发面的问题。 强化(build up) 在大幅调校引擎之后，随着燃烧力变大，会对各部位零件造成庞大的负担，甚至有造成损坏之处。为此，虽然提升零件强度势在必行，然而在另一个方面，也不能忽略要保持轻盈的原则。经常被用来解决这个难题的，是以钛合金为首的各种新材质，以及用锻造工法制造的强化零件。它们具备一般零件难以相比的轻巧度，且能兼顾强度与刚度。在赛车用火调校过的引擎当中，使用铝制锻造活塞、钛合金值连杆等零件，已成为标准。 高转速化由于马力=扭力x转速，所以想要提升马力，可说如何提升引擎转速。这个调校工程主要是和汽缸盖有关，关键在于提升高转速领域的进排气效率。主流做法是更换为凸轮运作角度更大的高角度轮轴，同时补强凸轮周围的结构。这样的处理可以收到与扩大进排气门相同效果，能够在高转速领域带来压倒性的马力。 气埠(port) 进气/排气埠分别是混合气体与燃烧后废气的通道。理想状况下，这个部分应该尽可能接近光滑；然而基于成本考量，在一般引擎中很少会讲究到这个部分，因此往往会对进排气造成阻力。造成问题的主要是铸造制品表面特有的粗燥起伏、与气流通道的尺寸大小或变形等。因此，有必要把气埠研磨成有如镜面般光滑，让进排气变得更顺畅。研磨气埠即可改善高速运转时的操驾感，然而若没针对汽缸整体同时进行更换凸轮、研磨汽缸表面等调校，则难以收到原本的功效。 气门(value) 在研磨气埠以及更换凸轮的同时，建议同时考虑扩大气门。扩大进气门的开口面积，可以增加进气量，提升填充效率。当然，气门尺寸越大便会越笨重(惯性作用力越强)，因此大多会选择以质轻的钛材料制造，来解决此问题。 气门弹簧 为了防止引擎在高转速运作时，气门弹簧发生异常震动，也就是所谓的激振（凸轮的运作跟不上弹簧伸缩速度的状态）想象，势必得要补强弹簧。在搭配高角度凸轮轴时更是如此，否则要是持续使用一般弹簧，将无法承受增加的气门扬程量，最糟糕的情况将会使得弹簧紧靠上凸轮导致锁死，或者让气门与活塞互相接触。但是若搭配国语强力的弹簧，又会造成引擎的阻力，或是加速气门周边磨损，因此必须特别注意。 凸轮轴(camshaft) 凸轮轴时负责开关进排气门的轴，而所谓的高角度凸轮轴=高扬程图轮轴，则是指高凸轮的抬举部分，以延长气门开启时间的凸轮轴款式。选用这种凸轮轴，可收到和扩大进排气们相同的功效。这虽然会降低在低中速领域的扭力，但是却能大幅提升高转速领域的马力。虽然无法否认这是种极端的特性，不过确实是在提升自然进气引擎的马力时最基本的调校手法。 高压缩化在引擎当中，当活塞上推以压缩混合气体的力道越强，燃烧力也就越强，进而能引出更强大的马力和扭力。针对这个部分所做的调校，主要以汽缸盖的燃烧室容量设计为重点。不过要是过度提升压缩比，除了会造成引擎运转时的阻力，也可能导致异常燃烧。因此在调校时，也必须调整燃料、延迟点火正时、换成冷式火星塞、补强活塞和连杆等部分，以对抗更强的爆炸力。 活塞(piston) 在提高压缩比时，最具代表的调校手法便是更换成高压缩比活塞。不过，在压缩比提高后，混合气体的温度、燃烧温度都会变高，容易发生引擎爆震现象，所以必须采取改善混合气体动线等相关措施加以因应。 燃烧室 在针对燃烧室所作的加工方面，比较简便的做法是把它修整成排气和点火效率优良的棱顶形状，但以因提高压缩比例预防异常燃烧所做压缩涡流加工为主流。这种加工方式是削薄燃烧室内压力变高的挤流区，稍微降低一些压缩比。但是在进行压缩涡流加工之后，各个燃烧室的容量将会出现差异，所以必须精密地重测各燃烧室容量。 汽缸盖(sylinder head) 以0.1mm的细小单位研磨汽缸盖的底面，这种手法称为盖面研磨。基本上这么做的目的在于减少燃烧室容量以提高压缩比例。盖面研磨的另一种用途，在于用来修正当引擎在过度严苛的热能条件下运作时，发生在汽缸体和汽缸盖之间的变形现象。 汽缸床垫片(head gasket) 结余汽缸盖与汽缸体之间，用以保持气密性，防止压缩气体外漏的金属板，就叫汽缸床垫片。将这块金属板磨得比一般状况下更薄，也能收到与盖面研磨相同的效果——即减少燃烧室容量以提高压缩比。最近常见通过选用热传导率高、强度优异的不锈钢作为汽缸床垫片的材质，以同时达到防止压缩气体外泄和调节压缩比的目的。 涡轮增压(turbo boosting pressure) 显示涡轮增压器能够吸入多少空气、并加以压缩的数值，即称为增压值。这个值以压力的单位kg/cm²加以表记，愈高表示能够引出愈大的马力。然而，在吸入大量空气的同时，也必须要提供足够的燃料与之搭配，因此需要借由电脑调节燃料供给，并更换能够喷出大量燃料的喷油嘴等零件。而引擎内部也必须具备足够的强度以承受增加后的爆炸力。 高流量涡轮(high flow turbine) 扩大用来压缩进气的压缩机轮部分，以争取更多风量的涡轮。基本上都采分解一般涡轮，只更换其中的压缩机轮部分的做法。由于涡轮经过削减处理惯性重量减轻，因此擅长于快速地发挥增压效果。这种做法几乎不需要牺牲引擎反应速度，便能提高马力。 增压器只需要提升增压和加大增压器自身的大小，便可发挥提升排气量相同的效果。如果搭配机械调校一起实施，则可望更加显著地提升马力。然而增压器加诸于引擎的负担甚至大过自然进气式，因此必须做出相对的因应措施。在自然进气引擎当中，提升马力的关键在于提高压缩比，不过，在使用增压器的引擎当中，反而得要降低压缩比，才能防止异常燃烧、或增加的爆炸力造成零件损坏。若使用的是涡轮增压器，泽荣旗产生动力迟滞现象，为了避免使引擎反应速度季度恶化，还得特别下工夫加以处理。 大容量涡轮(big turbine) 由于涡轮的大小决定了它的极限功率，所以这种调校手法就是直接将它更换成更大容量的涡轮。虽然可以飞跃性地提升马力，然而，却相对地因为要转动更大的涡轮，将使得引擎反应速度变得较为迟钝。除此之外，除非具备足以产生大量排气动能的排气量、或引擎本身具有足够的潜藏性能，否则这样的调校手法会使得地转速领域的扭力降低，并且只有在高转速领域才能得到增压下过。这样会让车子变得难以驾驭，是进行此种调校手法前应要事先考虑的部分。 中冷器(inter cooler) 能够冷却受涡轮增压器压缩而变得高温的空气，以提高引擎填充效率，进而提升马力的套件，便是所谓的中冷器。这种装置在市售车种当中亦属必备，尺寸越大、冷却效果也越强。不过如果因此装上过大的中冷器，会让压缩空气停驻于内部的时间变长，导致增压下降。这种现象叫做压力损失，依据条件不同，可能成为让增压值下降10%-20%的肇因。 机械增压器(super charger) 机械增压器和涡轮增压器同样采用将压缩空气压入引擎当中获得马力的设计原理。也就是说，在使用机械增压器时，只要提升增压值，同样可以提升更多的马力。机械增压器和涡轮增压器一样，都只要用螺丝便能装置在自然进气引擎上，可以轻易地大幅提升马力。由于结构上的设计，不易在踩踏油门时产生动力迟滞的状况，所以在技术赛道上非常占优势。 转子引擎调校转子引擎的重点在于提升进气效率，也就是如何扩大进气埠，将更多的混合气体送入燃烧室。这和在往复式引擎当中改用高角度凸轮轴得到的效果类似。不过值得注意的是，在转子引擎上扩大与移设气埠后得到的效果较大，同时车辆特性改变也较明显。在转子引擎上同时调校气埠和涡轮增压器，两相搭配之下可望引出跟多引擎的潜藏性能。 调校平衡(balancing) 转子引擎的结构比起往复式引擎相对简单，零件数目也比较少。因此，只要提升各零件的精确度，仔细地加以组装，便能够引导出引擎的潜藏性能，而改装重点则在于叫做sealset的作业。这是讲相当于往复式引擎活塞运动的三角气封加以重新组装，让它们具备相同的间隙。借此可以让转子室中的转子在保持着正确压缩比下，以极度顺畅地方式回转。反过来说，若气封发生问题，将造成马力降低，最糟糕的情况下将会导致烧毁。 侧边气埠(side port) 通过扩大设置在殻体侧边的进气埠口径，可以比平常更早开始吸入混合气体，进而提升马力。这种做法可以获得与在往复式引擎上该用高角度凸轮轴同样的效果。 桥状气埠(bridge port) 这是调校侧边气埠的手法之一。由于好像在磨削过的气埠间架起了桥梁一般，因而获得此名称。之所以在2道气埠开口之前设置桥状的通道，是因为要预留在气埠扩大到接近极限时，供三角气封通过动线范围。 外环气埠(peripheral port) 以特殊接著剂将通常位于普通引擎殻体侧边的进气埠塞住后，再将它移至转子室上部的做法。由于这可以让混合气体直接送入转子室内，因此优点是在高回转领域可以引出强大的马力。然而，另一方面却会失去在一般配置下，依据低回转/高回转区隔不同的混合气体进气方式以确保常用转速领域下扭力的功能，今儿使得引擎特性走向极端，变成在高回转领域能够发挥压倒性的马力，但低回转领域却几乎无法产生扭力。 组合式气埠(combination port) 结合了侧置气埠和外环气埠的调校手法。采用序列式控制，让低转速领域当中只有侧置气埠作动，而高转速当中只有外环气埠会运作，兼具了双发的优点。 调校驱动系统驱动系统负责将引擎效能转化为速度。除了必须具备良好的效率，将马力尽可能原封不动地传导至路面，害的要具备能够确实承受高功率的强度。 终传齿轮比想要将引擎动力按照重视速度、或重视加速的需求加以分配，可以通过改变终传齿轮的齿轮比来进行，亦即改变动力系统的终传比。特别是针对终传比进行低速档化，将可以更容易地引出拥有高转速、高马力效能的极端引擎特性，并可显著提升加速性能。 引导出引擎的性能。 高速档化(high geared) 这种手法可以提升在低引擎转速下的车速，因此在重视极速的情况下较为有利。另外，对于降低燃耗也很有效果。然而反过来说，想要提升引擎转速取得马力或扭力带时，将会产生时间延迟，所以不可否认地在加速上确实较为缓慢。在出了狭窄弯道后重新加速之类的情况下，将会因不易引出有效的马力与扭力，导致难以获得充分的加速力。 低速档化(low geared) 这种手法即使在3速和4速这类较高的档位下仍能轻易保持高转速，所以虽然会牺牲极速，但却能有效地引导出马力和扭力、提升加速性能。而在过弯时也能充分发挥引擎性能，使车子能在出弯时重新加速，因此十分适合用在以狭窄弯道为主的技术赛道。不过，随着引擎对油门操作的加速反应更加灵敏，必须留意转速提升过快的情况。 变速齿轮比一般而言，针对变速器所做的调校，主要指的是将齿轮进行密齿比化（让相邻齿轮的比率更为接近），方能够比较容易地维持有效的马力带。这样做虽然能大幅提升加速性能，但根据与终传齿轮之间的搭配方式的不同，可能容易发生转速过快、需要频繁地换挡的情况。 密齿轮比(close ratio) 调校手排变速器的各齿轮比，使其具有相近比率后，这样的变速器通常就称为横向变速器。当比率愈接近时，在切入高档次时引擎转速下降幅度愈少，可以更有效率地引出马力。用此方法再搭配高角度凸轮轴的助力下，可以说是特别适合用在马力带狭窄的自然进气引擎的此轮配置。通常要采用此方法时，会顺应赛道结构等情况，搭配终传比一起进行设定。 疏齿轮比(wige ratio) 和高速档化一样，一般市售车款重视降低燃耗，因此会为了抑制转速而刻意地将各档齿轮比设定得比较大。在如此设定下，即便是切入高档位，引擎马力却仍旧只能和缓地传导至地面，也等于是牺牲了车辆的加速性能。不过，通常不会将1到5档，甚至包括6档在内的所有档位都改为疏齿轮比设定。比较常见的做法是将用于起步、加速的1、2档设定为密齿轮比，在3档以上设定为远齿轮比，再顺应引擎特性和赛道配置，来选择搭配较密或较疏的此轮比率设定。 离合器减少驱动力损失，提高引擎反应速度。 想要将调校过后所增加的马力，尽可能地在未经损失的情况下传导给变速器，并确实执行换挡，则必须要补强离合器。离合器只要稍微打滑，便会导致车辆的加速性能下降。因此，合理的做法是配合马力/扭力提升的比率，提高离合器片的摩擦力与离合器压板的压著力。 离合器片与离合器压板(disc cover) 要想补强离合器，最传统的做法是将离合器片与离合器更换成强化过的款式。通过提高离合器片的摩擦力和离合器压板的压著力，可以更确实地将引擎马力传导给变速器。这些是引擎马力提升过后必备的零件，在家时跑车等严苛的离合器操作条件下，也不会产生反应变慢的情况。另外，离合器片目前以摩擦系数高，耐磨损性优异的金属制碟片为主流。 多片式离合器(multi plate) 相对于一般的离合器采单片式，补强过的离合器大多配有复数碟片，以扩大摩擦面积与加大压著力，来提升引擎马力的传导效率。多片式离合器从双片式到四片式都有，而增加的摩擦力大小与碟片数量成正比，摩擦力愈大便适用于马力愈高的引擎。此举虽然会提升动力系统的反应速度和耐久性，但在操作上却会产生缺点。如需更重的踏力，以及更细微的离合器接合动作等。 飞轮和传动轴想要提升引擎提高回转的速度、反应速度以及加速性能，将驱动系统加以轻量化可以带来相当大的效果。然而极度轻量化的飞轮，在爬坡时将难以产生足够的扭力，因此为了补强该特性，需要特别加以调校。 轻量化飞轮(lightweight flywheel) 装置在曲轴后端(离合器前方)的滑车称为飞轮，主要用途在于抑制引擎回转的落差。飞轮重量越重，回转起来越顺畅。然而飞轮的种类却会对追求速度方面带来负面影响，因此加以轻量化才是理想做法。虽然如此一来会让飞轮回转的顺畅度受到影响，也会使引擎扭力减少，但相对的却能使得转速提升速度和引擎反应更加敏锐。 领量化传动轴(lightweight propeller shaft) 介于变速器和差速齿轮之间，传导引擎马力的传动轴在经过轻量化之后，也能带来提升引擎反应速度和加速性能的好处。轻量化传动轴的材质主要为碳纤维和强化塑胶(FRP)，重量约只有一般款式的一般。减轻重量固然重要，不过是否保持正确的回转平衡则同样不容忽视。 限滑差速器将动力确实地传导至路面。 想要追求快速过弯的目的，绝对少不了能将引擎马力确实传达给路面的限滑差速器(LSD)。而在各类限滑差速器当中，能够发挥最大差速限制能力的，是利用多片式离合器产生压著力的机械式限滑差速器。这种限滑差速器最大的优点，在于能够自由设定开始生效、乃至生效为止的引擎反应速度。换言之，它能够配合驱动系统配置等车辆特性，驾驶风格与赛道配置，取得最适切的驱动力。然而，在发挥极大的差速限制力的同时，对于内部零件的负担也会增加，所以更要确实做好更换机油、全面检修等定期保养措施。 锁定比(lock ratio) 锁定比是用来显示LSD功效的数值。0%时为使用一般差速齿轮时的状况，而100%则表示差速器锁死。此数值越高，表示差速限制力越大。但一般来说并不是锁定比愈高愈好，理想值和驱动方式、车高和轮距等，都有很大的关联性，也会因为希望将车子调教成何种特性而有所不同。如果锁定比设定超出了理想值，则会在入弯初期呈现强烈的转向不足特性，并显著地影响过弯性能。一般来说，车辆在锁定比设定为约50%左右的情况下最容易操控，同时也能得到充分的差速限制效果，不过，仍有必要通过反复的测试，从错误中找出最合适的数值。 介入扭力(initial torque) 介入扭力指的是差速齿轮箱内部压制碟片的压力。提高或降低此压力，可以变更LSD达到锁死前的时间。提高介入扭力，可以让对油门操作的反应速度变快，转瞬间便能使LSD锁死；降低介入扭力，则能使LSD平缓地达到锁死，乘驾感较为舒适。在调校汽车性能的过程当中，提高扭力是基本需求。不过，若因此而使得转向性降低、或在FF式驱动车种中造成扭力转向增强等缺点，也同样不容忽视。附带一提，近来在低扭力领域当中，能够发挥极高差速限制效果的车种，有愈渐增加的趋势。 机械式LSD的种类 1WAY只有在踩踏油门时运作的LSD。由于不会在放开油门时运作，所以可以运用一般差速齿轮所具备的内轮差修正功能，更加顺畅地攻略弯道。这种LSD特别适合用在转向不足现象较强的FF式驱动车种上，不过会使得册子在踩踏/放开油门的情况下动态出现显著差异。 2WAY在踩踏/放开油门两种情况下都会生效的LSD。在初期会发生较强的转向不足现象，不过，由于在减速时能够确保车身动态稳定，让人可以放心地攻略弯道。引擎反应速度也极为优异，让驾驶员可以积极地踩踏油门过弯。 1.5WAY具有1WAY和2WAY双方特性的LSD。除了能够保持在加速方向的LSD效果，也能抑制LSD在减速方向的效果，同事也考虑到了在攻略弯道途中转向的容易性。可称得上是不会让驾驶人感受到车子的特殊习性，且能够应付各种状况的LSD。 为车瘦身轻巧、高刚性的车身，是高速奔驰的基本要件。无论提升了多少引擎马力，若搭配的是笨重脆弱的车身，还是难以发挥速度。 高刚性/轻量化为了将车子的运动性能提升至极限，无可避免地一定得对车身做轻量化以及高刚性化的调校。车身轻量化不仅对提升加速性能而言十分重要，也对改善刹车和过弯性能有很大的影响。另外，为了确保悬吊在高负荷状态下能够正确运作，同时兼顾轮胎的接地性，高刚性化同样是不可或缺的步骤。为了让驾驶员能够瞬间掌握车辆动态，采取正确的操作，也绝对需要一具不易变形的坚固车身。附带一提，在路面阻力系数极低，且有著来自纵横两方向的强力G力的纽堡林赛道，若尘神未具备坚实刚性，很可能连一圈都没办法顺利跑完。 拉杆(tower bar) 连接悬吊和车体相连部位（轮胎室上端）左右两侧的长棒叫做拉杆。车子装上拉杆之后，将能提升车身前部的刚性，并使悬吊能够正确运作。对于方向盘操作的反应也会更加锐利。基本上，拉杆应该在针对减震筒、弹簧、襯套等悬吊系统进行调校时一并装上。一般来说，拉杆通常只装在车身前方，不过若只考量到提升刚度的需求，最理想的做法是在车身前后都装上拉杆。 点焊(spot welding) 车身是用冲压过的金属板件接合起来所制成的。在所有接合手法中，最具代表性的就是每个固定的间隔设一个点建议焊接，称之为点焊。不过，由于市售车种为了讲求生产效率，必须尽可能减少焊接部位，所以容造成车体刚性不足的问题，因此，增加焊接部位的强化手法，就称为增加焊点。这能让车身板件间的接合部位更加坚固，可望大幅提升车体刚性，此外，由于不用增加新的零件即可执行，所以也不需要担心会导致车身变重。 获得正确的操纵性。 防滚笼(roll cage) 防滚笼原本的功用在于保护驾驶员不受变形的车身伤害，但在提高车身刚性时，它也能发挥很大的效果。不过先决条件时这款防滚笼和车顶与车柱之间必须毫无缝隙，稳固且确实地焊接在车身上的设计，而不是只通过螺丝固定的款式。另外，若能尽可能增加支撑点，并架设成有如立体攀爬架的状态，则可提升更多的刚性。 底架(member brace) 底架是看完去和变形的金属制长棒，在强化车舱地板下部刚性的同时，也能通过连接车身底座，限制悬索的多余动态，已完全发挥悬吊的性能。换句话说，就像拉杆从引擎盖内部支撑悬吊和车身一样，底架则是从车身下部支撑着。和栏杆并用不仅效果更佳，还能进一步地提升车身动态的稳定性。 轻量化(lightweighting) 想要提升车子的加速/减速/转向等所有行驶性能，最有效的调校手法莫过于减轻车体重量。在做法上，依照轻量化程度的不同，从最基本的省略空调等行车舒适设备和隔音材质，乃至于将车身板件换成轻质量的铝制或碳纤维制材质都有。或者更讲究一点，还得将车殻本身改为碳纤维材质，并把车架换成铝制。不过，为了在保持均衡的状况下提升行驶性能，轻量化与高刚性化因该要同时进行。另外，若能一并考虑重心高度(低重心)，并主要针对车体的上部进行轻量化，效果会较为显著，效率也跟高。 增强制动力调校刹车应该和提升马力同步进行考量。唯有具备足够的制动力，驾驶员才能放心踩油门。调校刹车时不仅得要强化制动力，对于热能也要有万全之策。 强化制动力/耐过温衰退性一辆调校过引擎、提升了绝对速度的车子，相对的也会需要更强大的制动力，以及更高的耐过温衰退性能。最基本的做法是更换来令片，而若要追求极致，则得将整套刹车系统换成大排气量赛车专用的套件。根据调校的需求层级不同，有许多的手法可供选择。不过，即使是赛车用的零件，也未必在各种用途上都能发挥完备的性能，还是应该要按照使用目的来选择零件。一味地加大刹车碟和卡钳的尺寸，可是会增加簧下重量，妨碍车辆运动性能。虽说刹车性能的铁则是必须高于引擎马力，但若因此就在轻量级的车种上装置大容量的系统，则明显大材小用了，极有可能会破坏车辆行驶时的整体平衡。 来令(pad) 刹车来令是在强化刹车时最基本的零件，会大幅影响制动力与耐过温衰退性。来令种类繁多，从街道用到竞赛用都有，然而在如此多样化的选择当中，适温(能够发挥最大制动力的温度)和耐热温度都各有不同，如果不能按照使用目前的选择最合适的种类，则很有可能效果不如预期，甚至对行驶造成不良影响。当然，跟一般的来令片比起来，特殊的来令片磨损较快，对刹车碟的伤害性也较高，为了确保制动力的平衡，通常会前后一起更换。 刹车油(fluid) 用在油压式刹车当中的作用油。为防止气阻现象，竞赛用的刹车油沸点必须在200度以上，但如此一来却也会使得吸湿性极高而容易裂化。刹车油的DOT级数越高，沸点也就越高，干同事也更容易因吸收湿气而裂化(沸点下降)。因此，竞赛专用的DOT5刹车油，在使用时必须以很短的周期频繁更换。需要特别留意的是，DOT值越大，并不表示制动力本身也跟着提升。 提升刹车的整体性能。 刹车油管(hoos) 刹车油管是刹车油的通道，一般为橡胶材质。因此在紧急刹车等油压升高的状况下，刹车油管将会膨胀，使得刹车踏感变得暧昧不扎实。能够排除这种现象的便是称为不锈钢網的刹车油管。这种刹车油管当中在铁氟龙油管外部披上网状的不锈钢，使其在保有和橡胶同等的柔软性之下，又能防止膨胀。这在竞赛用车种当中是必备的补强零件，并能经常维持直接而正确的刹车踏感。 刹车碟盘 在提高制动力的手法当中，最有效的的便是提升刹车面积，也就是加大碟盘直径以产生更大的摩擦热。然而，换用铸铁制的大直径刹车碟盘同事却会使得簧下重量增加，降低车子的行驶性能。因此，最近市面上开始出现以陶瓷或碳纤维为主要材质的轻量化刹车碟。刹车碟盘是随着使用逐渐磨损的耗材，想要得到应有的制动力，就得定期更换或者研磨。 刹车卡钳(caliper) 对刹车卡钳本身进行的调校手法之一，是干脆升级整个刹车系统。一般而言是将卡钳更换成能够将两侧来令片推夹刹车碟的对向活塞式设计，让刹车来令能够确实紧压刹车碟。而从许多市场车款也采用6活塞式刹车来看，课件活塞数目愈多，愈有助于同一队来令表面施加的压力，达到提升制动力的效果。另外，在对向活塞式刹车系统中，刹车卡钳本体可采一体成型，固定在车体上无需移动，这种配置当中刹车卡钳的刚性高，即使在严苛的使用条件下也能发挥稳定的刹车性能。 补强车底结构补强车底结构是重要的调校工程，可以在严苛的行驶条件下稳定车辆的动态，带来正确的操控性。这道步骤的效果足以使得车辆特性大幅转变。 变更驾驶特性在竞赛行驶目的下对悬吊所做的调校，通常意味着为追求速度而牺牲部分乘驾的舒适感。如果只会跑在像赛车跑道那种平坦的路面上，那么车高愈地，将使重心下降，车辆的动态便会愈安定。而悬吊越硬，就越能减少加速、减速、与转向时不必要的动态，让操控性更锐利。当然，实际上若悬吊完全不发挥功用，则重心便不会移动，让车辆的操控性变得极为糟糕，因此，在调硬悬吊阻尼时，应确保在能够运用重心移动的范围之内，并考量前后左右的均衡才是上策。随着车辆特性和路面状况不同，有时为了提升轮胎的抓地力，会刻意地调软悬吊。 弹簧(spring) 除了最基本的利用重心化来提高运行性能之外，同时是抑制过弯时的车身晃动、起步/加速时的后沉现象等，用以稳定车辆动态上所不可或缺的零件。 车高可调试悬吊(height adjust suspension) 拥有了可任意伸缩弹簧长度的车高调整功能，有些还同时具备可调整阻尼衰减的减震筒。各两件搭配的方式种类繁多，可以因应行驶情境做出细微的调整。调整车高的方式则可分为螺丝式、C环式、托架式等。 减震筒(damper) 通过赋予比一般减震筒更大的阻尼硬度，以确保在承受巨大负荷的高速行驶状况下，仍能维持车辆动态的稳定性，并提高操控性。更换与调校减震筒应该要与弹簧同时进行。 随心所以掌握操纵性能。 平衡杆(stabilizer) 通过调高比例，可以进一步提升平衡杆原本具备在过弯时抑制车身晃动的效果。若仅调高前方的比例，则可以使车子呈现出转向不足的特性，仅调高后方的比例，则会呈现出转向过度的特性。 悬吊襯套(bush) 通过强化装在避震装置和悬吊环等零件与车身相连处、以及各连杆的连接部位的缓冲材质（襯套），可以抑制悬吊的多余动态，给予驾驶员直线性的操盘反应与操控性。悬吊襯套的材质以橡胶或聚氨脂等树脂类为主，也有在可活动部位使用金属球（一般称为鱼眼）的种类。 轮胎的高性能化高性能轮胎的抓地力虽高，但是超出极限时却也极难控制，可说是有利有弊。因此在选择轮胎时，必须审慎考虑车子特性和动力间的平衡。 胎面加宽(width up) 加大胎面宽度能增加接地面积，则抓地性能自然会提升。不过轮胎的抓地力不仅来自于和地面的摩擦，同时也会因为轮胎的负重而大幅变化。例如，在车重较轻的车子上装上胎面极宽的轮胎时，因对轮胎施加的负重不足而导致无法获得高抓地力，也不是什么稀奇的事。而若是在马力不足的车种上装上尺寸过大的轮胎时，常会因轮胎的抓地力吃掉马力，反而使得车速变慢。因此，配合车重与引擎马力选择适当的轮胎相当重要。 提升抓地力/轮胎刚性高性能轮胎的要件是抓地力与刚性。将这两项条件追求到极致的境界的，是竞赛专用的光滑胎。这种轮胎的接地面胶料会因为摩擦热而融化，让车胎与路面紧密接触，而为了确保地面的刚性，这种轮胎上没有任何胎纹。这样的作法同样可以套用在公路胎上，凡是强调高性能的轮胎，无一例外会选用软质的胎面胶料，并且具备满较浅的粗胎纹。不过，为了确保在湿滑路面上的排水功能，胎面上势必还是得保留胎纹，且胎纹愈多、愈深，排水功能愈强。对轮胎而言，行驶性能和应付湿滑路面的性能时两种相斥的性能，如果将其中的平衡调整到极致境界也是一大学问。 紧紧地抓住地面。 升级轮圈尺寸(inch up) 所谓inch up，指藉由降低轮胎的扁平率（轮胎宽度相对于高度所占百分比），而在不需要变更轮胎外径的前提下，加大轮圈尺寸的手法，但这种手法未必等同于加宽轮胎宽度。主要的有点事当胎肩宽度（高度）变窄时，会减轻轮胎的过弯或刹车时的横向变形程度。这也可说是藉由提升刚性来改善操作方向盘的反应速度与操纵性。然而，极端的inch up将会因轮圈尺寸加大，导致簧下重量增加而显著折损运动性能。附带一提，竞赛用车种当中，inch up本来不低在于藉由扩大轮圈直径，以装载更大容量的刹车系统。 胎面胶料(compound) 用在轮胎接地部位的橡胶材质称为胎面胶料，对于轮胎抓地力有决定性的影响力。重视抓地力的高性能轮胎会使用容易紧贴于路面的软质胶料，特别是赛车胎的表面会因为与路面抹茶生热而融化，利用融化后的黏性牢牢地抓住地面。然而软质胶料虽然能够产生极高的抓地力，但相对地磨损也快。硬质胶料则具有完全相反的特性。选择轮胎时，应该对此基本特性有充分认识。另外，轮胎会随着时间经过而硬化，使得抓地力从全新品的状态开始逐渐劣化。越是软质的胎面胶料，这样的倾向越明显。 胎纹(groove) 刻在轮胎接地面上的满槽称为胎纹，具有在潮湿路面上排水，以保持接地面与路面间的抓地力的功能。另一方面，在干燥路面上进行过弯、刹车或加速等增加轮胎超负荷的动作时，胎纹只会带来使轮胎横向变形等坏处而已。最明显地说明了此一事实的，是赛道用的光滑胎上完全没有任何胎纹。而在试车会与假日车赛中使用的准赛车胎上，为了确保接地面的刚性，仅在胎面上刻上浅浅的、最低限度的胎纹。 提升空气性能为了提升高速领域的行驶性能，空气调校不可或缺。反过来说，如果这方面的调校稍有失误，则只会带来不好的影响。想要得到预期的效果，调校必须及其精密。 化解风阻并加以活用。 空力调校一般而言，安装空力套件大多是为了装饰目的。不过对正式地进行大幅调校的车而言，这道步骤发挥了非常重要的功能。空力调校的主要目的是降低在高速领域使车速变慢的风阻、抑制让车身浮起的升力，以提高行驶性能。其中，安装空力套件后产生将车体向下压的作用力（下压力），是提高车身动作稳定性、强化轮胎抓地力时不可或缺的力量，对于提升操纵性有很大的贡献。不过，进行空力调校时，必须注意与包含悬吊在内的车辆整体之间的平衡性，若空力调校不当，往往反而使得行驶性能恶化。 前扰流器(front spoiler) 加装前扰流器的目的在于抑制流入车身下方的空气，以降低升力。不过，在一些稀有的案例当中，帮车子装上外型未充分改装的空力套件，又将是离地高度降低以放低重心之后，加压过的气流不断流入空间变窄的车身下方，反而在车身前方产生升力，造成和原本预期的完全相反的效果。这在最糟糕的情况下，甚至会让车子失去控制。 后扰流器(rear spoiler) 这种空力套件的功用在于优化后保险杠的形状，以抑制车身后方产生的涡流，引导气流更顺畅地通过车身。有的后扰流器和后保险杠一体成型，也有一部分装设在保险杠下方。一般而言前者称为后保险杠扰流器(rear bumper spoiler)，后者则称为下扰流器(under spoiler)或后裙(rear skirt)。 尾翼(rear wing spoiler) 装置在车身后方上部，除了具有引导气流顺畅地通过车身的整流效果，还能抑制产生于车身后方的涡流。扰流尾翼的形状和能够产生升力的飞机主翼恰恰相反，因此尺寸越大，能够产生越大的下压力，并可借此提高后胎的抓地力。 侧扰流器(side spoiler) 也称做侧扰流裙(side skirt)、侧扰流梯(side step)，装置在车身两侧下方（侧油封附近），具有减低车体两侧风阻的效果。 扰流尾翼(rear diffuser) 这种整流板的作用是有效率地将车身下方的气流自后保险杠下导出，以产生负压进而获得下压力。扰流尾翼是赛车必备的零件，车身下方和路面间的间隔越窄，则效果越显著。 根据汽车特性改变设定改装一辆汽车必须根据车辆本身的特性来进行合适的设定与调校。每一辆车不同之处、驱动方式可能对于操控与车辆动态造成最大的影响，在改装前了解不同驱动方式的差异是相当重要的。 驱动方式车辆的驱动方式，指的是引擎位置——整车最重的地方，以及连接驱动轮的部分。不同的驱动方式拥有不同的优点与缺点，即使在高度改装的性能车上，操控特性与车身反应都无法不受到驱动方式的影响。改变车辆的驱动方式相当困难，但依旧可能藉由结构变动与调校，来改善驱动方式先天上的差异。最佳的改装与调校，就是要能在既有的驱动方式、悬吊、空力效应方面，提供比量产车更为优异的特性。 FR前置引擎后轮驱动 假设车辆的配重均衡的话，一辆FR(前置后驱)的汽车，可以提供顶尖的弯道表现与稳定性。如果想要提高车速，提升后轮循跡性，让车辆在加速过程中不发生后轮偏移的情况也是一种方法。另外针对非驱动轮的前轮，可以调整为转向不足的特性，有助于让整体转向特性趋于均衡，这尤其在车辆减速时可以让驾驶人更容易控制方向。 FF前置引擎前轮驱动 在一辆FF前置引擎前轮驱动的汽车上，尽管转向与驱动轮均在前轮，但也不能完全忘记后轮的反应。。在高速赛道的情况下，后轮需要更高的稳定性，降低在极端的情况下，后轮因为重量较低而产生偏移的几率，而车辆的调校必须让驾驶人松开油门后，让后轮回到可控制的反应范围内，并且协助前轮望准确的转向方向去，FF前置引擎前轮驱动车，可利用单向限制差速器，并且仅与车辆加速时作动提升车辆循跡性。 MR中置引擎后轮驱动 让引擎位于车辆的中心，可以提供车辆优异的加速与减速性能。但是在经过调校的情况下，若车头的负载较轻也可能让车辆出现转向不足的状况，车身后半部的偏移速度也会较快。所以当进行改装时，重点应该放在车辆入弯时容易操作的特性，之后才是车辆出弯时的循跡性，此外车辆的前方与后方的下压力也应该注意平衡。 RR后置引擎后轮驱动 将引擎放置在后轮上，并且采用后轮来驱动，这样的驱动方式，基本上会让车头更轻也可能出现明显的转向不足，但若在弯道操控时逼近极限，车尾可能出现钟摆效应，进而使整车出现瞬间转向过度的情况，通常改善的方式，是提升对于入弯时的控制能力，让车辆的转向趋于中性。 4WD四轮驱动 在各种不同的四轮驱动方式上，可能让车辆出现的过弯特性截然不同，但一般而言，让一辆车四轮驱动转弯更不容易，所以在设定方面往往都将焦点放在入弯控制的能力，通常会在前轴采用单向限滑差速器，并且在后轮导入双向限滑差速器，来解决先天上的问题。 逐项基本设定仅单纯地装置高性能组件，并无法让车变快，性能设定必须考虑到整车的均衡性表现，这样才能够发挥车辆各部分性能提升后的潜力。 悬吊 车辆高度/弹簧系数改变车身反应。 假设路况够好，车辆的重心降低，将让整车的稳定性明显提升，这会降低车辆加速或减速时的车身俯仰程度，藉由改变悬吊行程的长度，影响前后轮的高度，也会影响到提升整体性能。举例来说，若让前悬吊明显低于后悬吊，弯道上产生的进入制动会令前轮贴紧路面，使进弯的动作更顺畅。在FF前置引擎前轮驱动汽车上，可藉由提升加速来抑制车头俯仰程度，来改变车辆入弯的特性。 弹簧系数同样对于车辆的反应影响甚大，理论上悬吊设定更硬会提升过弯性能，但也不永远总是这样。较硬的悬吊可以让车辆在入弯时降低车头俯仰的幅度与车身的晃动，但是若降低悬吊高度太多，也可能会影响到车辆入弯时接触地面的面积与悬吊几何，结果影响到车辆的循跡状况，所以弹簧系数适当与否对于车辆入弯或出弯的表现影响甚大。弹簧系数也将对操控表现影响极大，提升弹簧系数可能导致转向不足，而且也可能提升后轮转向过度的几率，有时藉由调整阻尼系数，也可以补偿原有的特性。 阻尼系数控制弹簧的压缩比。 若增加负载的压力，避震器会控制悬吊弹簧扩张，而执行这项任务的应力，便被称为阻尼系数，通常这股力量减震筒内所封存的气体压力进行活塞运动来决定，阻尼系数愈高，表示弹簧的活动速度反应会变快，若被压缩地位置愈地，或是活动行程加长，避震器的反应会较为和缓。阻尼系数的设定独立施力，让车身反应与操控更精确，假设阻尼系数利用弹簧压缩，也会影响悬吊系统的反应时间、车身晃动与俯仰角度，也可以让车轮尽速脱离不均衡的状态，另外一方面，提升阻尼系数，也可以降低前悬吊在短时间内的反应幅度，维持车轮与地面的接触面积。 操控特性同样也可藉由改变阻尼系数的压缩或延伸还加以改变，也可以影响前后轮的反应状况，若藉由减少对前悬吊的压缩来改变阻尼系数，车辆大部分的重量将向前移，导致转向不足。降低后轴弹簧反应的阻尼系数改变，则可能让车身重心后移，提升转向过度的几率，这必须藉由事先的调校与设定才能改变车身的反应。 轮胎定位/外倾角最普遍的轮胎定位设置，就是轮胎外倾角的调整，负外倾角所指的是胎面与地面接触的面积，大于轮胎上半部；而正外倾角的状况正好相反，主要是轮胎轴心与铅直中央夹角向轮胎外侧扩大。 当车辆转弯时，离心力会导致车辆往弯道的外侧倾斜，假设在车辆转弯时出现负外倾角，表示转弯时轮胎胎面与地面接触面积较大，也代表可以提供较佳循跡表现，所以一般来说提升外倾角，指的就是造成负外倾角效应。然而，负外倾角在车辆直线行进时还是有缺点，由于直进时轮胎并未与地面保持垂直，所以可能会造成车轮在此时接地面积比转弯时小，也代表影响到循跡表现，进而对操控产生不利的影响，同时行进时轮胎的滚动阻抗会予以提升，直接影响到车辆的加速性表现，更甚者会让同样的速度情况下，车辆需要更长的距离与更强大的制动力才能刹车，进行极端的调整前要注意上列的利与弊。 当采用负外倾角定位时，最重要的就是考量到车身前后配重，对于弯道操控与车身反应造成的影响，若车头负载较重，前轮负外倾角应该要增加，而且后轮外倾角则应该减少，这样可以降低转向不足的风险。 正外倾角几乎很少用到，因为会降低轮胎的抓地力，而且会容易让车身反应过于灵敏。 轮胎定位/束角束角主要是当由上俯视轮胎时，与车辆前进方向之间所产生的夹角，束角的重要性，在于其在维持车辆稳定性方面，扮演十分吃重的角色，而且在轮胎左右对调时也将产生戏剧性的影响。 当内束角时，代表着由上方俯视车轮，车辆的方向呈现八字的状态，反之亦然，当前后轮均设定为内束角时，代表着会在转弯时造成较为明显的转向不足状态，若后轮为外束角时，代表着前轮呈现内八、后轮呈现外八字的状态，这时候则较为容易造成转向过度。束角的状态与轴距、轮距、外倾角以及动力输出等因素都有关联，其中一个因素变化，都可能导致束角产生的差距，将对于车辆在过弯状态下的转向特性产生改变，所以也影响驾驶人在弯道操控的掌握程度，通常在轮胎定位时会先调整或校正正前束角，之后才决定后束角的修正状况。 平衡杆/增加刚性平衡杆的本身就是拖拽臂结构中，连结下控制臂与左右两侧悬吊机构的部分。拖拽臂本身是运用扭曲力道所造成的阻力来运作的金属杆，主要作用为降低车身晃动状态，让轮胎的胎面可以保持与路面接触面积较大的相对稳定状态，并且提升车身抗扭曲性表现，而平衡杠同样也具备安定车身反应的功能。 当调整平衡杆系数时，别让弹簧系数高于悬吊的弹性系数相对来说十分重要。假如平衡杆强度愈高，悬吊弹簧会因此无法应付其所需要处理的状态，会让重量所产生的应力向轮胎外侧方向移动，导致内侧的悬吊组件举起平衡杆而丧失循跡性。这当然可能在调校前后平衡杆时繁盛，但这些调整方式主要是藉由调整悬吊的弹簧系数或是阻尼系数来大城其目标，提升平衡杆的刚性当然也可能达到同样的效果，但相对来说这一部分的调校，应该是完成其他部分的调整之后，才需要在最后检视时处理的程序。 驱动系统(限滑差速器)初期的扭力输出，决定了限滑差速器的介入的时机，若扭力输出较大，限滑差速器就愈容易做动，而且也让弯道加速过程更容易进行，反之，扭力输出较低，限滑差速器就较不容易作动与介入。 一般而言，提升初步扭力输出能强化车辆驱动配置的特征，然而过度转向在这样的处理方式下，却更容易在高速过弯时产生，而且前轮也可能因为驱动轮扭力输出过大，而产生较为明显的转向不足现象。所以初步扭力输出比例的调整，将可能影响到驾驶人希望车辆对于弯道反应的速度与幅度。 另一种调整，也可以藉由限滑差速器介入的时机与力道，来调整加速或减速时的扭力输出力道，加速设定将使得加速器与动作过程中反应更为强烈，而且驱动系统也会传送更多引擎输出的力道至驱动轮，这可以让入弯时驱动轮藉由取得更多的扭力，更容易入弯而达成提升过弯速度的能力。然而，这也可能影响到驾驶人的弯道操控乐趣，因为让车辆更容易克服弯道，而降低驾驶技术对于训练弯道过弯的能力。 减速过程中对于限滑差速器的设定，也将影响到弯道中减速之后车辆的反应。限滑差速器在减速过程中作动的反应提升，将可能增加弯道减速过程中刹车系统的作用力，这可能让驾驶人在入弯时用更快的速度进入弯道，因为驾驶人可以在任何情况下对于刹车力道有更高程度的掌握，然而此设定会使过弯难度提升，虽然是适用于驾驶技术较优异之职业或半专业驾驶者，但也是解决初期转向不足的必备技术。 驱动配置(齿轮比) 利用密齿比维持动力输出 为了应付各种赛道状况，由于蜿蜒的赛道具备更多的弯道，也充满各种加速直线道，为了让爱车引擎可以在这样复杂状况下适应反应，改变动力系统输出的比例便显得相当重要。这通常包括改变变速系统的终传比愈齿轮比。 当驾驶在较高比例的低速加速道与弯道上时，驾驶人的焦点将放在提升出弯速度，而非提升整体行车速度。变速系统在这种情况下，必须持续地在各档位、各种速度下维持相近的齿轮比，让驾驶人可以随时掌握动力系统较高的扭力输出状态，这样的设定就被称为密齿比。另一方面，若是驾驶在直线加速道比例较高的赛道上，就需要针对五档或六档来提升高速反应，即所谓较疏的齿轮比设定。 最高档位的齿轮比会决定变速系统的做动方式，假设最高档位齿轮比被提升，这将提升车辆的最终速度时所具备的加速力道，当开始调整齿比时，应该调整的是最高档位的终传比，这样才能让车辆在直线加速道时，于最高档位获得较高比例的动力输出以提升最终速度。 空力效应(下压力) 提升高速反应 当实行高速驾驶时，驾驶不可忽视气流对于车身产生的影响程度，空力效应主要对于车身造成二种影响：空气阻力将限制车辆的速度， 另外也可能在高速时抬升车身，进而影响到车辆行驶的速度。所以维持空力效应的均衡，将让车辆在高速行驶时更为顺利而且稳定。 此外，在高速行驶时所谓的下压力，也对于车辆行驶的稳定性造成相当重要的影响。下压力提升可以让车辆在高速行驶的情况下，提升车轮与地面接触的面积，也有利于提升车辆各轮的循跡性与稳定性。尽管下压力可能压制最终速度，但是在高速过弯时却有助提升车辆的动态稳定性，所以减少下压力，会降低车辆过弯的速度，但却可以容许车辆在直线高速道时维持较快的车速。下压力也可能受到赛道路线形状的影响，但若出现在起步时却不见得有利于车辆加速。最理想的状态，是提供车辆在不同的行驶状态下可以提供当时最适切的下压气流力道，在小排量动力的车辆上，通常藉由降低下压力来提升最终速度。 利用车身前后不同的下压力改变，可以用来提升车辆高速过弯时的操控表现，提升车身前端的下压力将增加车轮的抓地力，并且提升转向过度特性，相反地增加车身后半部的下压力，将较容易导致转向不足。各种不同的调整，将让车辆在高速赛道中拥有不同的反应特性。 依照目的状况进行设定针对特性的赛道或路况进行跳帧，其实是为了替身整体驾驶技巧，以及对于车辆各种状况下反应的掌握。反应速度较快的悬吊与驱动模式，将可以让车辆在赛道上产生令人难以想象的改变。 高速赛道 提升极速 在高速赛道上，理想的车辆设定，将让赛车可以在高速弯道中维持较高的行驶速度。悬吊系统避震器必须较为强固，而且保持车身高度较低。然而，若车身高度太低，则也会影响到悬吊弹簧的作动效率，悬吊系统会难以吸收车轮与地面接触所传处的震动，减低悬吊系统原本带给车辆的优点。 若使用较为硬的悬吊设定，降低防倾杆的刚性表现，将会让轮胎因为车身小幅度的滚动效应而提升抓地力，但另外一方面，若使用较软的悬吊设定，在崎岖不平的路面上，悬吊系统与避震器也会有较大的作来吸收来自路面的震动，这是因为平衡杆可以补偿悬吊系统弹簧能力的不足。当然，轮胎定位也十分重要，提升后轮的束角，也是提升车身稳定性的方法。当驾驶在高速赛道上，降低车辆在全力刹车时对于悬吊系统与避震器的负担，却也同样重要，因为这样可以维持车辆的反应与结构耐久程度。至于变速系统的齿轮比，其调校也是为了同样的目的：维持车辆动力系统，在较宽阔的高扭力输出范围，以提供随时都可以拥有强大的加速力道，藉由调整最终传比的设定，也可以让车辆及时在最高档位具备较强的扭力输出表现，当然提升下压力，也可以提升车辆在高速行驶时的稳定性，进而在高速赛道上追求更高的行驶速度，但必须避免在弯道与刹车时丧失稳定性。 建议悬吊设定依照车辆特性不同亦有可能有所差异。 技术赛道 让动力更有效率地传达至路面 所谓技术型赛道，通常代表着赛道上不满高难度的玩到，所以调校的目标将是让车身反应更为灵敏，而且让车辆在弯道时因为传输所丧失的动力比例降到最低，首先针对赛道状况设定适当的车身高度相当重要，当然也必须维持最佳的贴地性，但同时又必须考量悬吊系统与避震器，可以在任何状况下动作良好。 在这样的情况下，若是后轮驱动车辆，建议前轮弹簧应该调软，后轴弹簧应该调硬，以提升车辆过弯性能，另外在轮胎定位的部分，前路你应该增加束角角度，这样可以提升驾驶掌握车辆入弯时的反应，但也必须注意到车辆在过顶点后出弯的车身反应，负外倾角也可以适当地运用，但也同时必须考量到弯道行车与刹车时车辆的循跡性。变速系统应该提供较为紧密的齿轮比，让车辆随时可以维持较高的扭力输出，而且终传比例应该调低。若引擎调校的宜，那应该维持各种转速领域下可以输出的最大扭力，以便于车辆在各种状况下都可以获得最大的加速力道，空力效应中的下压力，作用于前后轴都应该维持在较强大的状况，已提供车辆在连续过弯之后拥有较佳的稳定性。 建议悬吊设定 转向不足之对策 了解为何车辆无法转弯 一开始为了定义何时开始出现转向不足，车辆何时开始转弯、靠近顶点，或是何时开始加速出弯都是关键。 假设转向不足在车辆入弯时发生，前轮抓地力必须尽可能增加。这可能藉由调软前轴悬吊弹簧以及增加避震器内部的延伸量，以及减少对弹簧的压缩量来增加对于轮胎的负载量，进而达成提升前轮抓地力的目标。各项与悬吊系统相关的变数，包含限滑差速器也同样可以让车辆，在这一个阶段出现转向不足，降低限滑差速器锁定的比例，或是限缩的扭力输出比例，也可予以纠正。如果是FR车辆使用双向限滑差速器（系统会视驾驶人踩踏油门踏板与否决定限缩输出比例），试着在车辆减速时，使用单向凡是控制限滑差速器。在车辆高速过弯时，提升前轴的下压力提升前轮抓地力，也可以达成同样的效果。若转向不足发生于车辆接近顶点，应该予以负增加外倾角，让前轮确认可在此时增加对于地面的抓地力，或是降低后轮束角也可以协助平衡前后轮的抓地力提升前轮距同样也可能达成效果。若转向不足发生于后轮驱动车准备加速出弯时，降低前轴车身高度则可以抵销其作用力，或是提升悬吊阻尼系数，促使避震器提升前轴行程，或压缩避震器行程也可以达成，若发生在FF前置引擎前轮驱动车上，提升限滑差速器的作用效果也同样可以解决此问题。 建议悬吊设定 转向过度之对策 后轮驱动车固有的麻烦 FF车与四驱车很少苦于转向过度。这个问题几乎否发生在后轮驱动车上。 如果以甩尾驾驶为主并注重操控性，前后轴的悬吊系统都必须强化到足以控制因为转向过度导致的偏滑或可能失控，然而在小场地的竞赛中，则需要计算维持循跡性的各项因素，才能顺利地让车辆前进。大部分发生转向过度的原因是因为后驱车，在加速过程中发生了后轮失去循跡性的状况，这将让传输的动力浪费在加速过程中发生的车辆打滑现象。弹簧与阻尼系数也可以藉由调校以降低转向过度，后悬吊应该调软，而避震器的阻尼系数应该降低压缩比例，并且提升延展性，这同样可以降低后平衡杆的刚性，增加转向内侧车轮往往行进方向移动。若可能的话，增加后轮距也是个方法。若前悬吊过软的话，后轴的负重比例可能向前移动，所以前悬吊应该强化来提升后轮的抓地力。若车辆皮质后扰流，可增加其角度，以提升车身后半部的下压力效应，但这也同时表示车辆可能必须牺牲最高车速。 建议悬吊设定 湿滑路况 重视轮胎表现 就像你可以想象的，在雨天时道路的摩擦力都已经降低了，当然轮胎的抓地力也会大受影响。在此就来看看有哪些设定在这样的路况下必须改变，让车辆可以充分地在湿滑路况发挥作用。包括弹簧系数、下压力与平衡杆的强度，都应该尽可能在干燥时事先降低，在部分的情况下，后平衡杆还必须完全拆除。过硬的悬吊可能让车辆更不容易掌握抓地力，当路况相当湿滑，车辆不容易维持抓地力时，悬吊设定愈软愈好。外倾角应该在还处于干燥的情况下略为增加，确定轮胎在路面湿滑的情况下，无论是加速或减速时都可以维持与路面最大的接触面积，当然车辆的空力套件也必须予以调整，前后下压力都应该增加，以尽可能地提升前后轮的抓地力。另外要降低气候对于汽车的负面影响，还有一个方法就是调整轮胎，若在大雨的情况下提升轮胎的负载，可以提升车轮的抓地力，相反的在雨小时，降低轮胎可以提升性能表现，随时注意并且调整前后胎压，在面对湿滑路面或大小雨气候时，都是调校过程中的优先考量。若可能提升动力调校的话，应该重视的是中低回转域的扭力输出表现，而非一味追求高速表现，而仰赖电子辅助系统的协助，在恶劣的湿滑路况下，更容易发现电子控制刹车系统的效果。 建议悬吊设定 砂砾路面 增加控制 当车辆必须在砂砾路面行驶时，针对车辆各部分的调校应该赋予最大的弹性，因为在这类路面上有太多难以预料的变化。可能在环境细微的变化，都必须针对车辆进行些许的调整，才能够让车辆顺利脱困并且降低应付路况所浪费的动力输出比例。 此外，在车辆加速的过程中，可能因此又随时改变了车轮与地面的抓地力，进而影响到循跡性，这也是砂砾路面随时可能变化的原因之一，所以对于车辆的调校与改变各项设定，在行驶砂砾路面时尤其重要。针对砂砾路面进行的调校中，必须注意的另外一个重点是当松开油门踏板之后，车辆所产生的反应，包括所产生的各种转向特性，这有被称为转向过度的调校，主要是为了要控制加速时的转向特性，这可能藉由使用双向限滑差速器或是调整前后刹车力道的均衡来达成。转向不足或过度同样可能发生在砂砾路面或柏油路面上，车身高度调整要视路面情况而定，尽管降低有其益处，但必须考量到在这类砂砾路面上，降低车身高度，会对底盘相关零件与结构造成的危机与损伤，当然在这样多变的情况下，车身空力效应依旧扮演重要角色，引擎的调校重点并不在于最高输出，而是可以在各种情况下保持最佳反应。 建议悬吊设定 — 赛道]]></content>
      <categories>
        <category>Automotive</category>
      </categories>
      <tags>
        <tag>PS4</tag>
        <tag>PlayStation</tag>
        <tag>Game</tag>
        <tag>Automotive</tag>
        <tag>GTSport</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统]]></title>
    <url>%2F2019%2F04%2F28%2FOperatingSystem%2F</url>
    <content type="text"><![CDATA[参考: OS Three Easy Pieces: https://book.douban.com/subject/19973015/ OSTEP: http://pages.cs.wisc.edu/~remzi/OSTEP/ 环境: ELRH7x86_64 操作系统介绍Introduction to Operating Systems 如果你正在攻读本科操作系统课程，你应该已经知道计算机程序运行时的想法。如果没有，这本书将很难。 那么，程序运行时会发生什么呢？好吧，正在运行的程序做了一件非常简单的事情: 它执行指令(it executes instructions)。每秒都有成千上万次，处理器从内存(mem)中取出(fetch)指令，对其进行解码(decode)——即确定这是哪条指令，并执行它。完成此指令后，进程将继续执行下一条指令，以此类推，直到程序最终完成。 刚刚描述了冯-诺依曼计算模型(Von Neumann model of computing)的基础知识。在本书中，我们将学习在程序运行的同时，还有许多其它的东西在运行，其主要目标是使系统易于使用。 事实上，有一大堆软件负责使应用程序运行变得容易，允许程序共享内存(share mem)，使程序与设备交互…该软件主体称为操作系统(Operating System)，它负责确保系统操作以易于使用的方式正确有效地运行。 操作系统执行此操作的主要方式是通过我们称为虚拟化(Virtualization)的通用技术。也就是说，操作系统采用物理资源(Physical Resource)(如处理器，内存，磁盘)并将其转换为更通用，功能强大且易于使用的虚拟形式。因此，我们有时将操作系统称为虚拟机(Virtual Machine)。 问题的关键: 如何虚拟化资源本书的一个核心问题：操作系统如何虚拟化资源？操作系统为什么要虚拟化资源——它使得系统更易于使用。因此，我们关注：操作系统使用什么机制和策略来实现虚拟化？操作系统如何有效地进行操作？需要什么硬件支持？ 当然，为了告诉用户操作系统做什么，从而利用虚拟机的功能(如运行程序、分配内存、访问文件…)，操作系统还提供了一些可调用的接口(API)。事实上，典型的操作系统会导出(Export)数百个可供应用程序访问的系统调用(System Call)。由于操作系统提供这些系统调用来运行程序、访问内存和设备、以及其它相关操作，有时也会说操作系统为应用程序提供了一个标准库(Standard Library)。 最后，因为虚拟化允许多个程序运行(共享CPU)，并且许多程序同时(Concurrently)访问它们自己的指令和数据(共享内存)，以及许多程序访问设备(共享磁盘等)，操作系统有时被称为资源管理器(Resource Manager)。每个CPU、MEM、DISK都是系统的资源。因此，操作系统的角色是管理这些资源，有效或公平地执行。 虚拟化CPUVirtualizing the CPU 12345678910111213141516171819202122// Code That Loops and Prints (cpu.c)#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/time.h&gt;#include &lt;assert.h&gt;#include "common.h"intmain(int argc, char *argv[])&#123; if (argc != 2) &#123; fprintf(stderr, "usage: cpu &lt;string&gt;\n"); exit(1); &#125; char *str = argv[1]; while (1) &#123; Spin(1); printf("%s\n", str); &#125; return 0;&#125; 上图的程序，它所做的只是调用Spin()——这是一个重复检查时间的函数。接下来我们具有单个处理器的系统上编译和运行它: 123456789101112131415# 编译# 此处遇到两个错误# 1. cpu.c:(.text+0xe0)：对‘pthread_create’未定义的引用# 2. cpu.c:(.text+0x127)：对‘pthread_join’未定义的引用# 网上方法: 在编译时需要添加 -lpthread 参数来使用 libpthread.a 库进行编译gcc -o cpu cpu.c -Wall -lpthread# 运行./cpu "ABC"ABCABC...# 需手动终止Ctrl+C 现在让程序复杂一点: 12345678910111213141516171819./cpu A &amp; ./cpu B &amp; ./cpu C &amp; ./cpu D &amp;[1] 7353[2] 7354[3] 7355[4] 7356ABDCABDCACBD... 现在事情变得更有趣了。即使只有一个处理器，但不知何故，所有四个程序都在同时运行！这种魔力是如何发生的呢？ 事实证明，操作系统在硬件的帮助下负责这种错觉(illusion)——即系统具有大量虚拟CPU的错觉。将单个CPU转换为看似无限数量的CPU，从而允许许多程序看起来像是一次运行，这就是我们所说的虚拟化CPU，这是本书第一部分的重点。 当然，要运行程序并停止它，以及告诉操作系统运行哪些程序，需要使用一些接口(API)来将你的需求传递给操作系统。实际上，它们是大多数用于与操作系统交互的主要方式。 你可能还注意到，一次运行多个程序会引发各种新问题。如，如果两个程序需要在特定时间运行，哪个应该运行。这些问题由操作系统的策略来回答，策略在操作系统中的许多不同位置用户回答这些类型的问题。 虚拟内存Virtualizing Memory 12345678910111213141516171819202122// A Program that Accesses Memory (mem.c)#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include "common.h"intmain(int argc, char *argv[])&#123; int *p = malloc(sizeof(int)); // a1 assert(p != NULL); printf("(%d) memory address of p: %08x\n", getpid(), (unsigned) p); // a2 *p = 0; // a3 while (1) &#123; Spin(1); *p = *p + 1; printf("(%d) p: %d\n", getpid(), *p); // a4 &#125; return 0;&#125; 现在让我们考虑一下内存(memory)。现代机器提供的物理内存的模型非常简单。内存只是一个字节数组(a array of bytes)。要读取内存，必须指定一个地址才能访问存储在那里的数据。要写入或更新(write/update)内存，还必须指定要写入数据的给定地址。 程序运行时始终访问内存。程序的所有数据结构保存在内存中，并通过各种指令访问它们，如loads, stores或其它在执行工作时访问内存的显式指令。不要忘记程序的每条指令也在内存中，每次取(fetch)指令时访问内存。 让我们来看下通过调用malloc()来分配一些内存的上面那个程序: 123456789101112131415161718192021./mem(6941) memory address of p: 01f13010(6941) p: 1(6941) p: 2^C# 该程序做了几件事。首先，它分配一些内存(a1)。然后，它打印出内存的地址(a2)，然后将数字零放入新分配的存储器的第一个插槽(a3)。最后，它循环，延迟1秒并递增存储在p中保存的地址的值。它还打出程序的PID。# Running The Memory Program Multiple Times./mem &amp; ./mem &amp;[1] 7544[2] 7545(7544) memory address of p: 012f3010(7545) memory address of p: 006cf010(7544) p: 1(7545) p: 1(7544) p: 2(7545) p: 2(7544) p: 3(7545) p: 3 实际上，这正是这里发生的事情，因为操作系统正在虚拟化内存。每个进程都访问自己的私有虚拟地址空间(private virtual address space)(有时也称为地址空间)，操作系统以某种方式将其映射到计算机的物理内存中。一个正在运行的程序中的内存引用不会影响其它进程的地址空间。就运行程序而言，它具有物理内存。然而，现实是物理内存是由操作系统管理的共享资源。 并发Concurrency 本书另一个主题是并发性(concurrency)。使用这个术语来指代同一程序中同时处理多个事件(即并发)。并发问题首先出现在操作系统自身，如前面的虚拟化程序，操作系统同时处理多个事情。 123456789101112131415161718192021222324252627282930313233343536373839// AMulti-threaded Program (threads.c) #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include "common.h" volatile int counter = 0; int loops; void *worker(void *arg) &#123; int i; for (i = 0; i &lt; loops; i++) &#123; counter++; &#125; return NULL;&#125; int main(int argc, char *argv[]) &#123; if (argc != 2) &#123; fprintf(stderr, "usage: threads &lt;value&gt;\n"); exit(1); &#125; loops = atoi(argv[1]); pthread_t p1, p2; printf("Initial value : %d\n", counter); Pthread_create(&amp;p1, NULL, worker, NULL); Pthread_create(&amp;p2, NULL, worker, NULL); Pthread_join(p1, NULL); Pthread_join(p2, NULL); printf("Final value : %d\n", counter); return 0;&#125;// &gt;本程序使用Pthread create()创建两个线程// 你可将线程视为与其它函数相同的内存空间中运行的函数，一次使用多个函数 如何构建正确的并发程序?当同一个内存空间中有许多并发执行的线程时，我们如何构建一个正常工作的程序？操作系统需要哪些原语？硬件提供哪些机制？如何使用它们来解决并发问题？ 运行: 1234567891011121314151617181920./threadsusage: threads &lt;value&gt;./threads 1000Initial value : 0Final value : 2000# 看看更高的值./threads 10000Initial value : 0Final value : 17726./threads 10000Initial value : 0Final value : 18741./threads 10000Initial value : 0Final value : 20000 上面出现了既正常又奇怪的结果。这些结果与指令的执行方式有关。不幸的是，上面程序的一个关键部分，共享计数器递增，需要三个指令： 一个用于将计数器的值从内存加载到寄存器； 一个用于递增； 一个用于将其存储回内存。 因为这三个指令不是原子地执行(一次全部执行)，所以会发生奇怪的事。 持久化Persistence 123456789101112131415161718// Program That Does I/O (io.c)#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;assert.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/types.h&gt;intmain(int argc, char *argv[])&#123; int fd = open("/tmp/file", O_WRONLY | O_CREAT | O_TRUNC, S_IRWXU); assert(fd &gt; -1); int rc = write(fd, "hello world\n", 13); assert(rc == 13); close(fd); return 0;&#125; 第三个主题是持久化(persistence)。在系统内存中，数据很容易丢失，因为如DRAM的设备是以易失的方式存储值。当断电或系统奔溃时，内存中的任何数据都会丢失。因此，我们需要硬件和软件能够持久存储数据。硬件以某种I/O设备的形式出现。 通常，操作系统中管理磁盘的软件被称为文件系统(file system)。它负责将用户创建的任何文件以可靠和有效的方式存储在磁盘上。 与操作系统为CPU何MEM提供的抽象不同，操作系统不会为每个应用程序创建专用的虚拟化磁盘。相反，它假设用户经常想要共享文件中的信息。 来看下上面的代码，它打开/tmp/file文件，并将hello world写入文件。1234./iocat /tmp/filehello world 如何持久存储数据？文件系统是负责管理持久化数据的操作系统的一部分。正确地处理需要哪些技术呢？面对硬件和软件故障，如何实现可靠性？ 要完成此任务，程序会对操作系统进行三次调用。这些系统调用被路由到称为文件系统的操作系统部分，然后处理请求并向用户返回某种错误代码。 第一，调用open()打开文件； 第二，调用write()将数据写入文件； 第三，调用close()关闭文件。 你可能想知道操作系统为了写入磁盘而执行的操作。文件系统必须完成相当多的工作，首先确定这些新数据将驻留在磁盘上的哪个位置，然后在文件系统维护的各种结构中跟踪它。这样做需要向底层存储设备发出I/O请求，以读取现有结构或更新它们。任何编写设备驱动程序的人都知道，让设备代表你做某事是一个复杂和详细的过程。它需要深入了解低级设备接口及其确切语义。幸运的是，操作系统提供了一个的标准和简单的方式——通过系统调用(system call)访问设备。因此，操作系统有时被视为标准库(standard library)。 为了处理写入期间系统崩溃的问题，大多数文件系统都包含某种复杂的写入协议。(如journaling或copy-on-write)。仔细写入磁盘以确保在写入序列期间发生故障时，系统之后可以恢复到合理的状态。为了使不同额公共操作高效，文件系统采用许多不同的数据结构和访问方法，从简单的列表到复杂的BTREE。 设计目标Design Goals 现在我们知道了操作系统实际上做了什么：它使用物理资源(CPU, MEM, DISK…)，并虚拟化它们。它处理与并发相关的棘手的问题。它可以持久存储文件，从而使它们长期安全。最基本的目标是建立一些抽象，以使系统方便和易于使用。抽象是我们计算机科学中所做的一切的基础。 设计和实现操作系统的一个目标是提供高性能(High Performance)；另一个目标是尽量减少操作系统的开销(overhead)。虚拟化和使操作系统易于使用是值得的，但不是不惜任何代价。因此，我们必须提供虚拟化和其它操作系统功能，而无需过多开销。这些开销以多种形式出现：额外时间、额外空间。 另一个目标是在应用程序之间，以及操作系统和应用程序之间提供保护(Protection)。由于我们系统多个程序同时运行，所有希望确保每一个程序的恶意或偶然的不良行为不会伤害到其它程序或操作系统。保护操作系统的主要核心原则始操作系统的隔离(Isolation)。将进程彼此隔离是保护的关键，因此是操作系统必须做的大部分工作的基础。 操作系统必须不间断地运行，当它失败时，系统上运行的所有应用程序也会失败。由于这种依赖性，操作系统通常努力提供高度可靠性(high degree of reliability)。随着操作系统越来越复杂，构建可靠的操作系统是一个相当大的挑战，这也是一个确切的研究性问题。 其它目标也是有意义的: 能源效率：在绿色世界中越发重要； 安全：对恶意应用程序的安全性至关重要； 可移植性：随着操作系统在越来越小的设备上运行，可移植性也变得很重要。 一些历史Some History 让我们简单介绍下操作系统的发展过程。与人类构建的任何系统一样，随着时间的推移，操作系统中积累了许多好的想法。 Early Operating Systems: Just Libraries一开始，操作系统并没有做太多。基本上，它只是一组常用函数库(function library)。 通常，在这些旧的主机系统上，一个程序由人工控制运行一次。许多你认为的现代操作系统将执行的大部分操作是由人工执行的。如果你和操作员很好，则他可以将你的工作移动到队列的前面。这种计算方式称为批处理(batch processing)，因为设置了很多作业，然后由人工以批处理的方式运行。到目前为止，计算机并没有以交互式(interactive)方式使用。因为成本：让用户坐在电脑面前使用它太昂贵了，因为大多数时候它只是闲置，而每小时需要花费数十万美元。 Beyond Libraries: Protection作为一个简单的常用服务库，操作系统在管理机器方面发挥了中心角色的作用。其中一个重要的方面是认识到运行操作系统自身的代码是特殊的。它控制了设备，因此应该与正常的应用程序代码区别对待。为什么这样？设想一下，如果你允许任何应用程序可以从磁盘的任何地方读取，隐私的概念就会消失，因为任何程序都可以读取任何文件。因此，实现文件系统作为一个库是没有任何意义的。 因此，系统调用(system call)的想法产生了。这里的想法是添加一对特殊的硬件指令和硬件状态，以便将操作系统转换为更正式、受控制的流程，而不是将操作系统例程(routine)作为库提供(你只需要进行过程调用以访问它们)。 系统调用(system call)和过程调用(procedure call)之间的关键区别在于，系统调用将控制转移到中，同时提高硬件权限级别(hardware privilege level)。用户应用程序在所谓的用户模式(user mode)下运行，这意味着硬件限制应用程序可以执行的操作。例如，以用户模式运行的应用程序通常不能发起对磁盘的I/O请求，但可以访问物理内存页面或在网络上发送数据包。当启动系统调用时，硬件将控制转移到预先指定的陷阱处理程序(trap handler)，并同时将特权级别提升到内核模式(kernel mode)。在内核模式下，操作系统可以完全访问系统的硬件，因此可以执行如启动I/O请求等操作。当操作系统完成对服务的请求时，它通过特殊返回陷阱指令(return-from-trap instrction)将控制权传递给用户，该指令恢复到用户模式，同事将控制权传递回应用程序停止的位置。 The Era of Multiprogramming操作系统真正起飞的时代是超大型计算时代，即minicomputer时代。成本的下降影响了使用者和开发者，从而使计算机系统更加有趣和美好。 特别是，由于希望更好地利用机器资源，多程序设计(multiprogramming)变得司空见惯。操作系统不是一次只运行一个作业，而是将大量作业加载到内存中并在它们之间快速切换，从而提高CPU利用率。这种切换特别重要，因为I/O设备很慢，而CPU很快。在I/O正在服务时让CPU等待程序是在浪费CPU时间。相反，为什么不切换到另一个工作运行呢？ 在存在I/O和中断的情况下支持多程序设计和重叠的愿望迫使操作系统的概念开发沿着多个方向进行创新。内存保存等问题变得很重要，我们不希望一个程序能够访问另一个程序的内存。了解如何处理多程序设计引入的并发问题也很关键，尽管存在中断，确保操作系统正常运行是一项巨大的挑战。 当时一个主要的进步是Unix操作系统的引入。Unix从不同的操作系统获得了很多好主意，但使它们更简单易用。很快，这个团队向世界各地的人们发送了包含Unix源代码的磁带，随后有许多人加入到了这个项目中来。 The Modern Era除了minicomputer之外，还出现了一种更便宜、速度更快的新机器，我们今天称之为PC(personal computer)。 不幸的是，对于操作系统而言，PC最初代表了一个巨大的飞跃，因为早期的系统忘记了在minicomputer时代学到的经验教训。例如，早期的操作系统，如DOS(the Disk Operating System, from Microsoft)，并不认为内存保护很重要。因此，恶意(或编程不佳)的应用程序可能会乱写内存。第一代Mac OS采用合作方式进行作业调度。因此，一个意外陷入无限循环的线程可以接管整个系统，迫使重启。这一代系统中缺少的操作系统功能的痛苦太多了… 幸运的是，经过几年的苦难，微机操作系统的旧功能开始找到它们的方式进入桌面系统。例如，Mac OS X/Mac OS的核心是Unix，包含了人们对这种成熟系统所期望的所有功能。Windows同样采用了计算历史中的许多好主意，特别是从Windows NT开始，这是Microsoft OS技术的一次重大飞跃。即便是今天的手机也运行这操作系统(如Linux)，这些操作系统更像是1970s年代的微型机，而不是1980s年代的PC。 旁白：Unix的重要性在操作系统的历史中，很难夸大Unix的重要性。受其它早期系统的影响，Unix汇集了许多伟大的想法，并使得系统既简单又强大。贝尔实验室的基础Unix是构建小型且强大程序的统一原则，这些程序可以连接在一起形成更大的工作流。shell提供了mete-level programing，当你输入命令，它将程序串联起来以完成更大的任务变得很容易。Unix环境对编程人员和开发人员都很友好，同时也为C编程语言提供了编译器。编程人员可以轻松编写自己的程序并共享它们，这使得Unix非常受欢迎。它还是免费的。同样重要的是代码的可读性和可访问性。拥有一个用C编写的漂亮的小内核(kernel)并邀请别人试玩、添加新的酷的功能。不幸的是，随着公司试图主张版权并从中获利，Unix的传播速度便有所放缓。许多公司都有自己的变体，如SunOS、HPUX…贝尔实验室和其它玩家之间的法律纠纷在Unix上投下了一片乌云，许多人想知道它是否能够活下来，特别是在Windows被引入并占据了PC市场的大部分时… 旁白：然后来了Linux(ASIDE: AND THEN CAME LINUX)对于Unix，幸运的是，一位名叫Linus Torvalds的年轻芬兰Hacker决定编写它自己的Unix版本，该版本大量借用原始系统背后的原则和思想，但不是来自代码库，因此避免了合法性问题。他获得了世界各地许多人的帮助，利用了已经存在的复杂的GNU工具，很快Linux就诞生了(以及现代开源软件运动)。随着互联网时代的带来，大多数公司(如Google、Amazon、Facebook..)选择运行Linux，因为它是免费的，可以随时修改以满足自己的实际需求。随着智能手机成为一个占主导地位的面向用户的平台，由于许多相同的原因，Linux也在那里找到了一个据点(Android)。 摘要Summary 因此，我们介绍了操作系统。今天的操作系统相对易于使用，而你今天使用的几乎所有操作系统都受到将在本书中讨论的发展的影响。不幸的是，书中不会介绍的很详细。例如，网络代码、图形设备、安全性。 但是，我们将介绍许多重要的主题，包括CPU和MEM的虚拟化知识，并发性以及通过设备和文件系统的持久性。别担心，虽然有很多方面可以覆盖，但大部分内容都非常酷，而且在路的尽头，你将对计算机系统的真正工作方式有了新的认识。现在开始吧！ 虚拟化Virtualization CPU虚拟化： A Dialogue on Virtualization The Abstraction: The Process Interlude: Process API Mechanism: Limited Direct Execution CPU Scheduling Scheduling: The Multi-Level Feedback Queue Scheduling: Proportional Share Multi-CPU Scheduling Summary Dialogue on CPU Virtualization MEM虚拟化： A Dialogue on Memory Virtualization The Abstraction: Address Spaces Interlude: Memory API Mechanism: Address Translation Segmentation Free-Space Management Paging Paging: Faster Translations Paging: Smaller Tables Beyond Physical Memory: Swapping Mechanisms Beyond Physical Memory: Swapping Policies Complete Virtual Memory Systems Summary Dialogue on Memory Virtualization 进程The Abstraction: The Process 本章，我们将讨论操作系统为用户提供的最基本的抽象之一：进程(process)。进程的定义非常简单：它是一个正在运行的程序(running program)。程序本身是一个没有生命的东西，它位于磁盘上，一对指令(可能是一些静态数据)，等待开始行动。操作系统采用这些字节并使它们运行，将程序转换为有用的东西。 事实证明，人们经常想要同时运行多个程序。如运行浏览器、音乐播放器、邮件程序…实际上，典型的操作系统似乎可能同时运行数百个进程。这样做使系统易于使用，因为不需要关心CPU是否可用。 TIP: USE TIME SHARING (AND SPACE SHARING)时间共享(time sharing)是操作系统用于共享资源的基本技术。通过允许资源被一个实体使用一段时间，然后另一个实体使用一段时间…资源可以被许多实体共享。时间共享对应于空间共享(space sharing)，其中资源在希望使用它的人之间被划分。例如，磁盘空间是一个空间共享资源，一旦将块分配给文件，在用户删除原始文件之前，通常不会将其分配给另一个文件。 我们的挑战是: 如何提供许多CPU的错觉？虽然只有少数物理CPU可用，但操作系统如何提供几乎无穷无尽的CPU供应的错觉？ 操作系统通过虚拟化(virtualizating)CPU来提供这种错觉。通过运行一个进程，然后停止它并运行另一个进程，等等。操作系统可以促使存在许多虚拟CPU存在的错觉，而实际上只有一个(几个)物理CPU。这种基本技术称为CPU的时间共享/分时(time sharing)，允许用户运行任意数量的并发进程(concurrent process)。潜在的成本是性能(Performance)，因为如果必须共享CPU，每个进程都会运行得更慢。 要实现CPU的虚拟化，操作系统需要一些低级机制(low-level machinery)和一些高级智能(high-level intelligence): 低级机制(low-level machinery mechanisms)，此机制是实现所需功能的低级方法或协议。例如，我们稍后将学习如何实现上下文切换(context switch)，这使操作系统能够停止运行一个程序并在给定的CPU上开始运行另一个程序。所有现代操作系统都采用这个分时机制(time-sharing mechanism)。 操作系统中还存在一些智能的策略(policy)，策略是在操作系统中做出某种决定的算法。例如，给定一些可能在CPU上运行的程序，操作系统运行哪个程序？操作系统中的调度策略将做出此决定，可能使用历史信息，工作负载信息，性能指标…来做出决定。 一个进程The Abstraction: A Process 为了理解进程的构成，我们必须了解其机器状态(machine state)：程序在运行时可以读取(read)或更新(update)的内容。在任何给定的时间，机器的哪些部分对于执行该程序很重要？包含进程的机器状态的一个明显组件是其内存(memory)。指令行在内存中，运行程序读写的数据也在内存中。因此，进程可以寻址的内存(称为其地址空间(address space))是进程的一部分。 寄存器(registers)也是进程机器状态的一部分。许多指令明确地读取或更新寄存器，因此它们对于执行过程很重要。 请注意，有一些特殊的寄存器构成了这种机器状态的一部分。如，program counter(instruction pointer)告诉我们当前正在运行哪个程序指令；Stack Pointer和相关的frame pointer用于管理函数参数、局部变量和返回地址的堆栈。 最后，程序通常也访问持久存储设备。此类I/O信息可能包括进程当前打开的文件列表。 TIP: SEPARATE POLICY AND MECHANISM在许多操作系统中，常见的设计范例是将高级策略与其低级机制分开。如，操作系统如何执行上下文切换？操作系统现在应该运行哪个进程？将两者分开可以很容易地改变策略，而不必重新考虑该机制，因此是一种模块化形式，一般的软件设计原则。 Process API先了解操作系统的任何接口中必须包含的内容，这些API以某种形式可用于任何现代操作系统。 Create：操作系统必须包含一些创建新进程的方法； Destroy：由于存在创建进程的接口，因此系统还提供了强制销毁进程的接口。当然，许多进程都会运行并在完成后自动退出。然而，当它们不这样做时，用户可能希望杀死它们； Wait：有时，等待进程停止运行时有用的； Miscellaneous Control：除了杀死或等待进程之外，有时还有其它可能的控制措施。如暂停进程，然后恢复它； Status：通常还有接口来获取有关进程的一些状态信息，如运行了多久… 进程创建Process Creation: A Little More Detail 我们应揭开的一个谜团是如何将程序(program)转换为进程(process)。具体来说，操作系统如何启动并运行程序？进程创建实际上如何运作？ 操作系统运行程序必须做的第一件事是将其代码和任何静态文件数据(如变量…)加载(load)到程序的地址空间中(address space of process)。程序最初以某种可执行格式驻留在磁盘(disk)上。因此，将程序和静态数据加载到内存中的过程需要操作系统从磁盘读取这些字节，并将它们放在内存中。在早期操作系统中，加载过程是热切地(eagerly)完成，即在运行程序之前一次完成；现代操作系统懒惰地(lazily)执行该过程，即仅在程序执行期间需要加载代码或数据。要真正了解代码和数据的延迟加载是如何工作的，你必须更多地了解分页(paging)和交换(swapping)的机制，这将在内存虚拟化里讨论。现在只需记住，在运行任何操作之前，操作系统显然必须要做一些工作才能将重要的程序从磁盘放入内存。 一旦将代码和静态数据加载到内存中，操作系统在运行该进程之前还需要执行一些其它操作。必须为程序的运行时栈(runtime stack)分配一些内存。如C程序将堆栈用于局部变量、函数参数和返回地址。操作系统分配此内存并将其提供给进程。操作系统也可能使用参数初始化堆栈，具体来说，它将填充main()函数的参数(argc, argv数组)。 操作系统还可以为程序的堆(heap)分配一些内存。在C程序中，堆用于显式请求的动态分配数据调用malloc()来请求这样的空间，并通过调用free()显式释放它。数据结构需要堆，如链表(linked list)、哈希表(hash table)、树(tree)和其它又去的数据结构。堆最初会很小，当程序运行并通过malloc()库API请求更多内存时，操作系统可能会参与并为进程分配更多内存以满足此类调用。 操作系统还将执行一些其它初始化任务，尤其是与I/O相关的任务。例如，在Unix系统中，默认情况下每个进程都有三个打开的文件描述符(file descriptors)，用于stdin, stdout, stderr。这些描述符使程序可以轻松地从终端读取输入并将输出打印到屏幕。将在持久化中详细介绍I/O和文件描述符。 通过将代码和静态数据加载到内存中，通过创建和初始化堆，通过执行与I/O设置相关的其它工作，操作系统最终为程序执行设置了阶段。它还有最后一个任务：启动在入口点运行的程序，即main()。通过跳转到main()例程，操作系统将CPU的控制权转移到新创建的进程，从而程序开始执行。 进程状态Process States 现在我们已经知道一个进程是什么以及如何创建它。现在来看看一个进程在给定事件可以处于的不同状态。进程可处以以下三种状态： Running：进程正在处理器上运行，这意味着它正在执行指令； Ready：进程已准备好，但由于某种原因，操作系统已选择不在此刻运行它； Blocked：进程执行某种操作，使其在其它事件发生之前不准备运行。例如，当进程向磁盘发起I/O请求时，它会被阻塞，因此其它一些进程可以使用该处理器。 如下图所示，可以根据系统的判断在准备和运行之间移动进程。从准备到运行意味着该进程已调度(scheduled)好；从运行转移到准备意味着该进程被取消调度(discheduled)。一旦进程被阻塞(blocked)，操作系统将保持这样知道某些事件完成，此时进程再次进入就绪状态。 来看一个栗子，两个进程如果通过其中一些状态转换的示例。 Time Process0 Process1 Notes 1 Running Ready 2 Running Ready 3 Running Ready 4 Running Ready Process0 now done 5 – Running 6 – Running 7 – Running 8 – Running Process1 now done 这个栗子中，process0在运行一段时间后发出I/O请求。此时，该进程被阻塞，使另一个进程有机会运行。更具体地说，process0启动I/O并被阻塞等待它完成。例如，从磁盘读取或等待来自网络的数据包时，进程会被阻止。操作系统识别process0未使用CPU并开始运行process1。当process1运行时，process0的I/O完成，将process0移回准备状态。最后，process1完成，process0运行然后完成。 Time Process0 Process1 Notes 1 Running Ready 2 Running Ready 3 Running Ready Process0 initiates I/O 4 Blocked Running Process0 is blocked 5 Blocked Running so Process1 runs 6 Blocked Running 7 Ready Running I/O done 8 Ready Running Process1 now done 9 Running – 10 Running – Process0 now done 请注意，即使在这个简单的示例中，操作系统也必须做出许多决定。首先，系统必须在process0发出I/O时运行process1；这样做可以通过保持CPU忙碌来提高资源利用率。其次，系统决定在其I/O完成时不切换会process0。目前尚不清楚这是否是一个好的决定。这些类型的决策是由操作系统调度程序做出的。 数据结构Data Structures 操作系统是一个程序，与任何程序一样，它有一些追踪各种相关信息的关键数据结构(data structure)。例如，为了追踪每个进程的状态，操作系统可能会为所有准备好的进程保留某种进程列表，并提供一些其它信息来追踪当前正在运行的进程。操作系统还必须以某种方式追踪被阻塞的进程；当I/O事件完成时，操作系统应确保唤醒正确的进程并准备好再次运行。 下面显示了操作系统需要跟踪内核中每个进程的信息类型。类似的过程结构存在于真实操作系统中，如Linux、Mac OSX、Windows…看看它们有多复杂。你可以看到操作系统追踪进程的几个重要信息。对于已停止的进程，寄存器上下文(register context)将保持其寄存器的内容。当进程停止时，其寄存器将保持到该内存位置(memory location)。通过恢复这些寄存器，操作系统可以恢复运行该进程。这在以后上下文切换中详细介绍。 1234567891011121314151617181920212223242526272829303132333435// the registers xv6 will save and restore// to stop and subsequently restart a processstruct context &#123;int eip;int esp;int ebx;int ecx;int edx;int esi;int edi;int ebp;&#125;;// the different states a process can be inenum proc_state &#123; UNUSED, EMBRYO, SLEEPING, RUNNABLE, RUNNING, ZOMBIE &#125;;// the information xv6 tracks about each process// including its register context and statestruct proc &#123; char *mem; // Start of process memory uint sz; // Size of process memory char *kstack; // Bottom of kernel stack // for this process enum proc_state state; // Process state int pid; // Process ID struct proc *parent; // Parent process void *chan; // If non-zero, sleeping on chan int killed; // If non-zero, have been killed struct file *ofile[NOFILE]; // Open files struct inode *cwd; // Current directory struct context context; // Switch here to run process struct trapframe *tf; // Trap frame for the // current interrupt&#125;; 还可从图中看出，除了running, ready, blocked之外，还有一些进程可以处于其它状态。有时，系统将具有该进程在创建是所处的初始状态(initial state)。此外，可将进程置于已退出但尚未清除的最终状态(final state)(在基于Unix的系统中，这称为僵尸状态(zombie state))。这个最终状态非常有用，因为它允许其它进程(通常是创建此进程的父进程)检查进程的返回代码并查看刚刚完成的进程是否成功运行(通常，程序在基于Unix系统中的返回码为0时，表示已成功完成任务，否则返回非0)。完成后，父进程将进行最后一次调用以等待孩子进程的完成，并且还向操作系统指示它可以清理任何涉及现在已经灭绝的进程的相关数据结构。 ASIDE: DATA STRUCTURE — THE PROCESS LIST操作系统充满了各种重要的数据结构。进程列表(process list)，也称为任务列表(task list)。它是比较简单的一个，都是现在能够同时运行多个程序的操作系统都会有类似于这种结构的东西，以便追踪系统中所有正在运行的程序。有时，人们会将存储过程信息的单个结构称为进程控制块(PCB, process control block)。 ASIDE: KEY PROCESS TERMS(关键进程术语)进程(process)是正在运行的程序的主要操作系统抽象。在任何时间点，该进程都可以通过其状态来描述：其地址空间中的内存内容、CPU寄存器的内容、有关I/O的信息。进程API由可使进程相关联的调用程序组成。通常，这包括创建、销毁、其它有用的调用。进程存在许多不同的进程状态(process state)，包括running、ready、blocking。不同的时间将进程从这些状态之一转换到另一个状态。进程列表(process list)包含有关系统中所有进程的信息。每个条目有时称为进程控制块(PCB)，它实际上只是一个包含特定进程信息的结构。 进程APIProcess API ASIDE: INTERLUDES插曲(interludes)将涵盖系统的多个实际方面，包括特别关注系统API以及如何使用它们。如果你不喜欢实际的事物(practical things)，你可跳过它。但你应该了解它，因为它们通常在现实生活中很有用。 CRUX: HOW TO CREATE AND CONTROL PROCESSES操作系统应该为进程创建和控制提供哪些接口？如何设计这些接口以实现强大的功能、易用性和高性能？ 在此插曲中，将讨论Unix系统中的进程创建。Unix提供了一种使用一对系统调用(system call)创建新进程的最有趣的方法: fork() exec() 第三个例程，可以由希望等待进程创建完成的进程使用： wait() fork系统调用The fork() System Call fork()系统调用用于创建新进程。但是，要预先警告：这是你将要调用的最奇怪的例行程序。更具体的说，你有一个正在运行的程序，代码如下所示。输入并运行它。 1234567891011121314151617181920// Calling fork() (p1.c)#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;int main(int argc, char *argv[]) &#123; printf("hello world (pid:%d)\n", (int) getpid()); int rc = fork(); if (rc &lt; 0) &#123; // &gt;&gt;&gt;fork failed; exit fprintf(stderr, "fork failed\n"); exit(1); &#125; else if (rc == 0) &#123; // child (new process) printf("hello, I am child (pid:%d)\n", (int) getpid()); &#125; else &#123; // parent goes down this path (main) printf("hello, I am parent of %d (pid:%d)\n", rc, (int) getpid()); &#125; return 0;&#125; 运行: 1234./p1hello world (pid:14506)hello, I am parent of 14507 (pid:14506)hello, I am child (pid:14507) 当它第一次运行时，该进程打印出hello world消息，包含在该消息中的进程标识符(PID, process identifier)。在Unix系统中，如果想要对进程执行某些操作(如停止它)，则使用PID来命名进程。 现在有趣的部分开始了：该进程调用fork()系统调用，操作系统提供该此方法来创建新进程。奇怪的部分：创建的进程是调用进程的精确副本。这意味着对于操作系统来说，现在看起来的两个进程都是p1程序运行的副本，并且两个进程都从fork()系统调用返回。新创建的进程(child)不会像main()那样开始在main()上运行(hello world只打印了一次)。相反，它刚出现时，好像它已经调用了fork()本身。 你可能注意到，子进程不是一个精确的副本。尽管它有自己的地址空间、寄存器、PC…，它返回给fork()调用者的值是不同的。具体来说，当父进程接收新创建的子进程PID时，子进程接收返回码0. 你可能还注意到：p1的输出不确定。系统中有两个活动的父进程和子进程。假设在单个CPU的系统上运行，可能会发生相反的情况。 1234./p1hello world (pid:29146)hello, I am child (pid:29147)hello, I am parent of 29147 (pid:29146) CPU调度器，确定哪个进程在给定时刻运行。因为调度程序很复杂，我们通常不能对它将选择做什么做出强有力的假设，如最先运行哪个进程。这些不确定性导致了一些有趣的问题，特别是在多线程程序中，这将在并发中讨论。 wait系统调用The wait() System Call 到目前为止，我们还没有做太多工作：只创建了一个打印消息并退出的子进程。有时，事实证明，父进程等待子进程完成它一直在做的事情时非常有用的。这个任务是通过wait()系统调用完成的。 在下面的栗子中，父进程调用wait()以延迟执行，直到子进程执行完毕。子进程完成后，wait()返回父进程。添加了wait()调用使得数据具有稳定性，你们明白为什么吗？ 12345678910111213141516171819202122// Calling fork() And wait() (p2.c)#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/wait.h&gt;int main(int argc, char *argv[]) &#123; printf("hello world (pid:%d)\n", (int) getpid()); int rc = fork(); if (rc &lt; 0) &#123; // &gt;&gt;&gt;fork failed; exit fprintf(stderr, "fork failed\n"); exit(1); &#125; else if (rc == 0) &#123; // child (new process) printf("hello, I am child (pid:%d)\n", (int) getpid()); &#125; else &#123; // parent goes down this path (main) int rc_wait = wait(NULL); printf("hello, I am parent of %d (rc_wait:%d) (pid:%d)\n", rc, rc_wait, (int) getpid()); &#125; return 0;&#125; 1234 ./p2hello world (pid:29266)hello, I am child (pid:29267)hello, I am parent of 29267 (rc_wait:29267) (pid:29266) 使用此代码，我们现在知道子进程将首先打印。但是，如果父进程碰巧先运行，它会立即调用wait()，这个系统调用在子进程运行并退出之前不会返回。因此，即使父进程先运行，它礼貌地等待子进程完成运行，然后wait()返回，然后父进程打印它的消息。 exec系统调用The exec() System Call 进程创建API的最后一个重要部分是exec()系统调用。当你想要运行与调用程序不同的程序时，此系统调用很有用。例如，在p2中调用fork()仅在你希望继续运行同一程序的副本时才有用。但是，通常你想运行一个不同的程序，exec()就是这么做的。 在下面的栗子中，子进程调用execvp()以运行程序wc(word count)。实际上，它从p3上运行wc，返回行数、词数和字节数。 12345678910111213141516171819202122232425262728// Calling fork(), wait(), And exec() (p3.c)#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;sys/wait.h&gt;int main(int argc, char *argv[]) &#123; printf("hello world (pid:%d)\n", (int) getpid()); int rc = fork(); if (rc &lt; 0) &#123; // &gt;&gt;&gt;fork failed; exit fprintf(stderr, "fork failed\n"); exit(1); &#125; else if (rc == 0) &#123; // child (new process) printf("hello, I am child (pid:%d)\n", (int) getpid()); char *myargs[3]; myargs[0] = strdup("wc"); // program: "wc" (word count) myargs[1] = strdup("p3.c"); // argument: file to count myargs[2] = NULL; // marks end of array execvp(myargs[0], myargs); // runs word count printf("this shouldn’t print out"); &#125; else &#123; // parent goes down this path (main) int rc_wait = wait(NULL); printf("hello, I am parent of %d (rc_wait:%d) (pid:%d)\n", rc, rc_wait, (int) getpid()); &#125; return 0;&#125; 12345./p3hello world (pid:29383)hello, I am child (pid:29384)29 107 1030 p3.chello, I am parent of 29384 (rc_wait:29384) (pid:29383) fork()系统调用很奇怪，它的伙伴exec()也不是那么正常。它的作用：给定可执行文件的名称和一些参数，从该可执行文件加载代码和静态数据并覆盖其当前代码段，重新初始化堆和栈以及程序内存空间的其它部分。然后操作系统运行该程序，传入任意参数为该进程的argv。因此，它不会创建新的进程。相反，它将当前运行的程序(p3)转换为不同的运行程序(wc)。在子进程的exec()之后，几乎就好像p3从未运行过，成功调用exec()永远不会有返回。 Motivating The APIWhy? Motivating The API 当然，可能会遇到一个大问题：为什么要建立一个奇怪的接口来创建一个新进程？事实证明，fork()和exec()的分离对于构建Unix shell至关重要，因为它允许shell在调用fork()之后，在调用exec()之前运行代码。此代码可以改变即将运行的程序的环境，从而可以轻松构建各种有趣的功能。 TIP: GETTING IT RIGHT简单和抽象都不能代替正确。有很多方法可以为进程创建设计API，但是，fork()和exec()的组合非常简单和强大。在这里，Unix设计师做对了。 shell只是一个用户程序。它会向你显示提示，然后等待你输入内容。你输入一个命令，在大多数情况下，shell确定文件系统中可执行文件所在的位置，调用fork()创建一个新的子进程来运行命令，调用exec()的某个变体来运行命令，然后通过调用wati()命令来等待命令的完成。当子进程完成时，shell从wait()返回并再次打印出一个提示，为下一个命令做好准备。 fork()和exec()的分离允许shell很容易地完成一堆有用的东西。例如: wc p3.c &gt; 1.txtshell完成此任务的方式非常简单，在创建子进程时，在调用exec()之前，shell关闭stdout并打开文件1.txt。通过这样做，即将运行的此程序的任何输出都被发送到文件而不是屏幕。 下面的程序便完成这样的操作: 12345678910111213141516171819202122232425262728// All Of The Above With Redirection (p4.c)#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/wait.h&gt;int main(int argc, char *argv[]) &#123; int rc = fork(); if (rc &lt; 0) &#123; // &gt;&gt;&gt;fork failed; exit fprintf(stderr, "fork failed\n"); exit(1); &#125; else if (rc == 0) &#123; // child: redirect standard output to a file close(STDOUT_FILENO); open("./p4.output", O_CREAT|O_WRONLY|O_TRUNC, S_IRWXU); // now exec "wc"... char *myargs[3]; myargs[0] = strdup("wc"); // program: "wc" (word count) myargs[1] = strdup("p4.c"); // argument: file to count myargs[2] = NULL; // marks end of array execvp(myargs[0], myargs); // runs word count &#125; else &#123; // parent goes down this path (main) int rc_wait = wait(NULL); &#125; return 0;&#125; 执行: 1234./p4cat p4.output 29 116 874 p4.c 首先，当运行p4时，看起来好像什么也没有发生过。shell只是打印命令提示符，并立即为下一个命令做准备。但事实并非如此，p4确实调用fork()来创建一个新子节点，然后通过调用execvp()来运行wc程序。你没有看到任何输出打印到屏幕是因为它已被重定向到文件中。 Unix 管道(pipe) 以类似的方式实现，但使用pipe()系统调用。这种情况下，一个进程的输出连接到一个内核管道(即队列)，另一个进程的输入连接到同一个管道。因此，一个进程的输出无缝地用作下一个进程的输入，并且长而有用的命令链可以串在一起。如这个栗子: grep -o foo file | wc -l。 现在，只需说fork()和exec()组合是一种创建和操作进程的强大方法就足够了。 ASIDE: READ THE MAN PAGES本书中，当提到特定的系统调用或库调用时，会让你阅读手册(man/manual pages)。花时间阅读手册石喜彤程序员成长的关键一步，这些手册页中隐藏了大量有用的花絮。最后，阅读手册可让你避免一些尴尬。当你向别人询问问题是，别人可能会叫你阅读文档。 进程控制和用户Process Control And Users 在Unix系统中，除了fork(), exec(), wait()之外，还有许多其它接口可与进程进行交互。例如，kill()系统调用用于向进程发送信号(signal)，包括暂停(pause)、死亡(die)和其它有用的指令。为了方便起见，在大多数Unix Shell中，某些键组合被配置为向当前运行的进程传递特定信号。栗子如下: 键组合 信号 描述 ctrl+c SIGINT(2) 中断 ctrl+z SIGTSTOP(19) 停止(暂停) 整个信号子系统提供了丰富的基础设施，可为进程提供外部事件，包括在各个进程中接收和处理这些信号的方法，以及向各个进程以及整个进程组(process groups)发送信号的方法。要使用这种通信形式，进程应使用signal()系统调用来捕获(catch)各种信号。这样做可确保当特定信号传递到进程时，它将暂停正常执行并运行特定代码以响应该信号。 这自然会提出一个问题：谁可以向进程发送信号，谁不能发送？通常，系统可以让多个用户同时使用。如果其中一个人可以随意发送信号(如SIGINT)，则系统的可用性和安全性将受到影响。因此，现代系统包含用户的强烈概念。用户在输入密码建立凭据后，登录以获取对系统资源的访问权限。然后，用户可以启动一个或多个进程，并对它们进行完全控制(pause, kill…)，用户通常只能控制自己的进程。操作系统的工作是将资源(cpu, mem, disk…)分配给每个用户(及其进程)以满足整体系统目标。 有用的工具Useful Tools 有许多命令行工具也很有用。如下: ps top sar kill killall 摘要Summary 我们介绍了一些处理Unix进程创建的API: fork(), exec(), wait()。但是，我们刚刚撇去了表面。 ASIDE: KEY PROCESS API TERMS 每个进程都有一个名字，在大多数系统中，该名称为PID； fork()系统调用在Unix系统中用于创建新进程。创建者被称为父进程（parent），被创建的新进程被称为子进程（child）； wait()系统调用允许父进程等待其子进程完成执行； exec()系统调用允许子进程摆脱与父进程的相似性并执行一个全新的程序； Unix Shell通常使用fork(), exec(), wait()来启动用户命令。fork()和exec()的分离支持I/O重定向、管道…； 进程控制以信号的方式提供，这可能导致作业停止、继续或终止； 可由特定用户控制哪些进程被封装在用户的概念中。操作系统允许多个用户同时登录，并确保用户只能控制自己的进程； 超级用户(superuser)可以控制所有进程。出于安全考虑，请不要使用此用户进行直接操作。 直接执行Mechanism: Limited Direct Execution 为了虚拟化CPU，操作系统需要以某种方式在同时运行的许多作业中共享物理CPU。基本思路很简单：运行一个进程一段时间，然后运行另一个进程，以此类推。通过分时共享(time sharing)CPU，实现了虚拟化。 然而，构建这样的虚拟化也存在一些挑战： 首先是性能（Performance）：如何在不增加系统过多开销的情况下实现虚拟化？ 第二是控制（Control）：如何保持在对CPU的控制的同时有效地运行进程？控制对操作系统尤其重要，，因为它控制资源。如果没有控制权，进程就可以永远运行并接管机器，或者访问不应该被它访问的信息。 因此，要在保持控制的同时获得高性能是构建操作系统的核心挑战之一。 关键：如何通过控制有效地虚拟化CPU操作系统必须以有效地方式虚拟化CPU，同时保持对系统的控制。为此，需要硬件和操作系统的支持。操作系统通常会使用明智的硬件支持来完成其工作。 基本技术：有限的直接执行Basic Technique: Limited Direct Execution 为了使程序以预期的速度运行，操作系统开发人员提出了一种技术——有限的直接执行（limited direct execution）。直接执行（direct execution）的想法很简单：只需在CPU上直接运行程序即可。因此，当操作系统启动一个程序运行时，它会在进程列表中为它创建一个进程条目，为它分配一些内存，将程序代码加载到内存中，找到它的入口点(main()例程或类似的东西)，跳转到它，并开始运行用户的代码。 Direct Execution Protocol (Without Limits) OS Program 创建进程列表条目为程序分配内存将程序加载到内存使用argc/argv设置堆栈清除寄存器执行调用main() 运行main()从main执行return 释放进程内存从进程列表中删除条目 听起来很简单，但这种方法在我们尝试虚拟化CPU的过程中会产生一些问题： 如果我们只运行一个程序，操作系统如何确保程序不执行我们不希望它执行的操作，同时仍然有效地运行它？ 当运行一个程序时，操作系统如何阻止它运行并切换到另一个进程，从而实现我们虚拟化CPU所需的分时共享？ 问题1：受限制的操作Problem1: Restricted Operations 直接执行具有快速的明显优势，程序直接在原生CPU硬件上运行，因此可按照预期的速度执行。但是在CPU上运行会引发一个问题：如果进程希望执行某种受限制的操作（如向磁盘发出I/O请求，访问更多系统资源(cpu, kernel)…），该怎么办？ 如何执行受限制的操作进程必须能够执行I/O或其它一些受限制的操作，但不能让进程完全控制系统。操作系统和硬件该如何协同工作？ 为什么系统调用看起来像程序调用你可能想知道为什么对系统调用（如open(), read()...）的调用看起来与C中的典型过程调用（procedure call）完全相同。也就是说，它看起来就像一个过程调用，系统如何知道它是一个系统调用，并做了所有正确的事情？原因很简单：它是一个过程调用，但隐藏在过程调用内部的是著名的陷阱指令（trap instruction）。举个栗子，当调用open()时，你正在执行对C library的过程调用。其中，无论是对于open()还是其它的系统调用，库都使用与内核达成一致的调用约定，将参数放在众所周知的位置（stack或register），也将系统调用号放入一个众所周知的位置(stack或register)，然后执行上述陷阱指令。陷阱解压后库中的代码将返回值，并将控制权返回给发出系统调用的程序。因此，进行系统调用的C库部分是在汇编中手工编码的，因为它们需要仔细准遵循约定，以便正确处理参数和返回值，以及执行特定于硬件的陷阱指令。这个汇编代码已经有人替你做了。 一种方法是让任何进程在I/O和其它相关操作方面做任何它们想做的事情。然而，这样做会妨碍构建所需的多种操作系统。例如，如果我们希望构建一个在授予文件访问权限之前检查权限的文件系统，我们不能简单地让任何用户进程向磁盘发出I/O。如果这样做了，一个进程可以简单地读写整个磁盘，因此所有的保护都将丢失。 因此，我们采用一种新的处理器模式——用户模式（user mode）。在用户模式下运行的代码受限于它们可以执行的操作。例如，在用户模式下运行时，进程无法发出I/O请求，这样做了会导致处理器引发异常，操作系统可能会杀死这个进程。 与用户模式相反，内核模式（kernel mode）是操作系统运行的模式。在此模式下，运行的代码可以执行其喜欢的操作，包括发出I/O请求、执行所有类型的受限制的指令。 但是，当用户进程（user process）希望执行某种特权操作（如I/O）时应该做什么？为了实现这一点，几乎所有的现代硬件都为用户程序提供了执行系统调用的能力。系统调用允许内核小心地将某些关键功能部件暴露给用户程序。如访问文件系统、创建和销毁进程、与其它进程通信以及分配更多内存…大多数操作系统提供了几百个调用（详情请参考POSIX标准）。 使用受保护的控制转移硬件通过提供不同的执行模式来协助操作系统。在用户模式下，应用程序无法完全访问硬件资源。在内核模式下，操作系统可以访问机器的全部资源。还提供了从陷阱（trap）到内核（kernel）并从陷阱返回（return-from-trap）到用户模式的特殊指令，以及允许操作系统告知硬件陷阱表（trap table）驻留在内存中的指令。 要执行系统调用，程序必须执行特殊的陷阱指令。该指令同时跳转到内核并将权限级别提升为内核模式。一旦进入内核，系统现在可以执行所需的任何特权操作（如果允许），从而为调用进程执行所需的工作。完成后，操作系统会调用一个特殊的从陷阱返回（return-from-trap）指令，该指令将返回到调用用户程序，同时将权限级别降低到用户模式。 执行陷阱(trap)时硬件需要小心，它必须确保保存足够的调用程序寄存器（caller’s register），以便在操作系统发出return-from-trap指令时能够正确返回。例如，在x86上，处理器会将程序计数器（counter）、标志（flag）和一些其它寄存器（register）推送（push）到每个进程的内核栈（kernel stack）。return-from-trap会将这些值从栈中弹出（pop）并继续执行用户模式的程序。其它硬件系统可能有所不同，但基本概念在不同平台上是相同的。 还有一个重要细节：陷阱如何知道在操作系统中运行哪些代码？显然，调用进程无法指定要跳转的地址。这样做会让程序跳转到内核，这显然是一个非常糟糕的想法。因此内核必须消息控制在陷阱（trap）上执行的代码。 内核通过在启动时设置陷阱表（trap table）来实现。当机器启动时，它在特权（内核）模式下，因此可以根据需要自由配置机器硬件。操作系统首先要做的事情之一就是告诉硬件在发生某些异常事件时要运行什么代码。例如，当发生硬盘中断、发生键盘中断或程序进行系统调用时，应该运行什么代码？操作系统通常通过某种特殊指令通知硬件这些陷阱处理程序（trap handler）的位置。一旦通知硬件，它会记住这些处理程序的位置，直到机器下次重启，因此当系统调用或其它异常事件发生时，硬件知道该做什么。 Limited Direct Execution Protocol os@boot hardware initialize trap table remember address of… syscall handler os@run hardware program(user mode) Create entry for process listAllocate memory for programLoad program into memorySetup user stack with argvFill kernel stack with reg/PCreturn-from-trap restore regs(from kernel stack)move to user modejump to main Run main()…Call system calltrap into OS save regs(to kernel stack)move to kernel modejump to trap handler Handle trapDo work of syscallreturn-from-trap restore regs(from kernel stack)move to user modejump to PC after trap …return from maintrap (via exit()) Free memory of processRemove from process list 此时间线总结了协议。假设每个进程都有一个内核寄存器，其中寄存器在进入和退出内核时保存到硬件，并从硬件恢复。 警惕安全系统中的用户输入即使我们在系统调用期间都非常努力地保护操作系统（通过添加硬件陷阱机制），但实现安全操作系统还有许多其它方面必须考虑。其中之一是在系统调用边界梳理参数，操作系统必须检查用户传入的内容并确保正确指定了参数，否则拒绝该调用。例如，通过write()调用，用户将缓冲区的地址指定为write调用的源。如果用户(意外或恶意)传入坏地址（如，内核地址空间的一部分），操作系统必须检测到这一点并拒绝该调用。否则，用户可以读取所有内核内存。鉴于kernel（virtual）内存通常还包括其它的所有物理内存，这个小的滑动将使程序能够读取系统中的任何其它进程的内存，这是非常危险的。通常，安全系统必须非常怀疑地（great suspicion）处理用户输入。不这样做容易导致软件被黑，世界是一个不安全和可怕的地方。 要指定确切地系统调用，通常会为每个系统调用分配系统调用号（system call number）。因此，用户代码负责将所有所需的系统调用号放在寄存器或栈上的特定位置。操作系统在陷阱处理程序内部处理系统调用时，检查此号码，确保它有效。如果有效，则执行相应的代码。这种间接性是一种保护形式，用户代码无法指定要跳转确切地址，而是必须通过号码请求特定服务。 能够执行指令告诉硬件陷阱表所在的位置是一个非常强大的功能。因此，如你所猜，它也是一种特权操作（ privileged operation）。如果你在用户模式下执行此指令，硬件不会鸟你。如果你可以安装自己的陷阱表，你可以对系统做些什么可怕的事情？你能接管机器吗？ 有限的直接执行（LDE）有两个阶段： 启动时，内核初始化陷阱表，CPU会记住它的位置以供后续使用； 内核通过特权指令执行此操作。内核在使用return-from-trap指令开始执行进程之前设置了一些东西（分配进程列表、内存…）。这会将CPU切换到用户模式并开始运行此进程。当进程希望发出系统调用时，操作系统处理进程并再次通过return-from-trap将控制权返回给进程。然后进程完成其工作，并从main()返回。它通常会返回存根代码，它将正确地退出程序。此时操作系统清理完毕，就完成了。 问题2：在进程间切换Problem2: Switching Between Processes 直接执行的下一个问题是实现进程之间的切换（switch between process）。进程之间的切换很简单吗？操作系统应该决定停止一个进程并启动另一个进程。这看起来简单，但实际上有点棘手。具体来说，如果一个进程在CPU上运行，这意味着操作系统没有运行。如果操作系统没有运行，它怎么能做任何事情？吐过操作系统没有在CPU上运行，它显然没有办法采取行动。 如何恢复控制CPU操作系统如何重新获得对CPU的控制，以便它可在进程间切换？ 合作方法：等待系统调用A Cooperative Approach: Wait For System Calls 一些系统过去采用一种合作方法（cooperative approach）。在这种风格中，操作系统信任系统的进程以合理地运行。假定运行时间过长的进程会定期放弃CPU，以便操作系统可以决定运行其它任务。 因此，你可能会问，友好的进程如何在这个乌托邦世界中放弃CPU？事实证明，大多数进程通过进行系统调用来非常频繁地将CPU的控制权转移到操作系统。像这样的系统通常包括一个显式的yield系统调用，除了将控制权转移到操作系统（以便操作系统可以运行其进程）之外什么都不做。 应用程序在执行非法操作时也会将控制权转移到操作系统。举个栗子，如果应用程序除以零，或者尝试访问它无法访问的内存，则会为操作系统生成陷阱（trap）。然后操作系统再次获得CPU控制权（并可能终止非法进程）。 因此，在协同调度（cooperative scheduling）系统中，操作系统通过等待系统调用或某种非法操作来重新获得CPU的控制权。你可能回想，这种被动方法也不理想呀！如果一个进程（恶意或错误）最终在无限循环中结束，并且从不进行系统调用，会发生什么？操作系统可以做什么？ 非合作方法：操作系统取得控制权A Non-Cooperative Approach: The OS Takes Control 如果没有硬件的额外帮助，当一个进程拒绝进行系统调用并因此将控制权返回给操作系统时，操作系统根本无法做很多事情。事实上，在合作方法中，当一个进程陷入无限循环时，你唯一的办法就是采用古老的办法解决计算机系统中的所有问题：重启（Reboot）。因此，我们再次提出了获得CPU控制权的一个子问题。 如何在没有合作的情况下获得控制权（HOW TO GAIN CONTROL WITHOUT COOPERATION）即使进程没有合作，操作系统如何才能获得对CPU的控制？操作系统可以做些什么确保流氓进程不会接管机器？ 答案很简单，许多人在许多年前构建操作系统时已经发现了：定时器终端（timer interrupt）。可以对定时器设备进行编程，以便每隔几毫秒(ms)产生一次中断。当中断被引发时，当前正在运行的进程停止（halted），并且操作系统中预配置的中断处理程序运行。此时，操作系统重新获得CPU的控制权。因此可以随心所欲：停止当前进程并启动另一个进程。 如前面讨论的那样，系统调用时，操作系统必须通知硬件当中断定时器发生时执行什么代码。因此，在启动时，操作系统就是这样做的。其次，在引导序列期间，操作系统必须启动定时器（这当然是特权操作）。一旦计时器开始，操作系统就可以感觉安全，因为控制权最终将返回给它，因此操作系统可以自由运行用户程序。 处理应用程序的坏事（DEALING WITH APPLICATION MISBEHAVIOR）操作系统通常必须处理行为不当的进程，这些进程（恶意或错误）尝试做它们不应该做的事情。在现代操作系统中，操作系统处理此类不当行为的方式是简单地终止（terminate）违法者。但当你试图非法访问内存或执行非法指令时，操作系统应该做什么呢？ 请注意，当发生中断时硬件有一定的责任，特别是为了保存中断发生时运行的程序的足够的状态，以便后续的return-from-trap指令能够正确地恢复正在运行的程序。这组操作非常类似与在显式系统调用陷阱到内核期间硬件的行为，因此各种寄存器被保存，因此可通过return-from-trap轻松恢复。 保存和恢复上下文Saving and Restoring Context 现在操作系统已经重新获得了控制权，无论是通过系统调用，还是通过定时器中断，都必须做出决定——是继续运行当前进程，还是切换到另一个进程。该决定由称为调度程序（scheduler）的操作系统的一部分做出，这将在后面学习。 如果决定做切换，则操作系统执行低级代码。我们称之为上下文切换（context switch）。上下文切换的概念很简单：所有操作系统必须做的是为当前正在执行的进程保存一些寄存器值（如，在其内核栈上），并为即将执行的进程恢复（如，来自其内核栈）。通过这样做，操作系统因此确保当最终执行return-from-trap指令时，系统继续执行另一个进程，而不是返回到正在运行的进程。 为了保存当前正在运行的进程的上下文，操作系统将执行一些低级汇编代码（low-level assembly code），以保存和运行当前正在运行的进程的通用寄存器、PC、内核栈指针，然后恢复所述寄存器、PC，并切换到内核堆栈，以便于即将执行的进程。通过切换栈，内核在一个进程（被中断的进程）的上下文中进行切换代码的调用，并在另一个进程（将被执行的进程）的上下文中返回。操作系统最终执行return-from-trap指令，即将执行的进程将成为当前正在运行的进程。因此上下文切换完成。 使用定时器中断来重新获得控制权定时器中断使操作系统能够在CPU上再次运行，即使进程以非协作方式运行。因此，此硬件功能对于帮助操作系统维护机器的控制至关重要。 重启是有用的早些时候，我们注意到在协作下抢占无限循环（infinite loops）的唯一解决办法是重启机器。虽然你可能会嘲笑，但研究人员已经证明重启可以成为构建健壮系统的一个非常有用的工具。具体来时，重启是有用的。因为它将软件移回到已知且更加可测试的状态。重启还会回收陈旧或泄露的资源（如，memory），否则这些资源可能难以处理。最后，重启很容易实现自动化。 整个进程的时间线如下所示。在此示例中，进程A正在运行，然后被定时器中断所中断。硬件保存其寄存器（在其内核栈上）并进入内核（切换到内核模式）。在定时器中断处理程序中，操作系统决定从正在运行的进程A切换到进程B。此时，它调用switch()例程，该例程小心地保存当前寄存器值（进入A的进程结构），恢复进程B的寄存器（来自其进程结构条目），然后切换上下文，特别是通过更改栈指针来使用B的内核栈（而不是A的）。最后，操作系统执行return-from-trap，它恢复B的寄存器并开始运行它。 : Limited Direct Execution Protocol (Timer Interrupt) os@bootkernel mode hardware initialize trap table remember addresses of…syscall handlertimer handler start interrupt timer start timerinterrupt CPU in X ms os@bootkernel mode hardware program user mode Process A… timer interruptsave regs(A) → k-stack(A)move to kernel modejump to trap handler Handle the trapCall switch() routinesave regs(A) → proc t(A)restore regs(B) ← proc t(B)switch to k-stack(B) return-from-trap (into B) restore regs(B) ← k-stack(B)move to user modejump to B’s PC Process B… 担心并发？Worried About Concurrency? 细心的读者可能会想到：在系统调用期间发生定时器中断，会发生什么？或，当你在处理一个中断时而另一个中断发生会发生什么？在内核中难处理吗？…… 操作系统确实需要关注在中断或陷阱处理期间发生其它中断会发生什么。事实上，这是本书后面关于并发（concurrency）的内容。为了满足读者的胃口，这里介绍操作系统如何处理这些棘手情况的一些基础知识。 操作系统可能做的一件简单的事情，在中断处理期间禁用中断(disable interrupts)。这样做可确保在处理一个中断时，不会将其它任何中断传递到CPU。当然，操作系统必须小心这样做，长时间禁用可能会导致中断丢失，这是不好的。 操作系统还开发了许多复杂的锁定（locking）方案，以保护对内部数据结构的并发访问。这使得许多活动可以同时在内核中进行，特别适用于多处理器（multiprocessors）。这种锁定可能很复杂，并导致各种有趣且难以发现的错误(bugs)。 摘要我们描述了一些实现CPU虚拟化的关键低级机制，这是一组我们统称为有限直接执行（limited direct execution）的技术。基本思路很简单：只需运行你想在CPU上运行的程序，但首先要确保设置硬件以便在没有操作系统辅助的情况下限制进程可以执行的操作。 我们具有虚拟化CPU的基本机制。但是一个主要问题没有回答：我们应该在给定时间运行哪个进程？调度器必须回答这个问题，这是后面讨论的问题。 上下文切换会花费多长时间你可能回想：上下文切换需要多长时间？或系统调用？有一些工作可以准确测量这些东西，以及一些其它可能的指标。这当然也和硬件配置有关系。应当注意，并非所有操作系统都追踪CPU性能。许多操作系统是内存密集型的，并且内存带宽并没有像处理器速度那样显著提高。所以，购买强大的硬件配置能加速你的操作系统。 CPU虚拟化术语 CPU至少支持两种执行模式：受限的用户模式和特权内核模式（非受限） 典型的用户应用程序以用户模式运行，并使用系统调用来陷阱(trap)到内核中以请求操作系统服务 陷阱指令小心保存寄存器状态，将硬件状态更改为内核模式，并跳转到操作系统到预先指定的目标：陷阱表（trap table） 当操作系统完成对系统调用的服务时，它会通过另一个特殊的return-from-trap指令返回到用户程序，这会降低权限并在跳转到操作系统的陷阱后将控制权返回给指令 操作系统必须在引导（boot）时设置陷阱表，并确保用户程序无法轻松修改它们。所有这些都是有限直接执行协议的一部分，改写以有效地运行程序但不会丢失操作系统控制 程序运行后，操作系统必须使用硬件机制（定时器中断）来确保用户程序不会永远运行。这种方法是CPU调度的非协作方法 有时，在定时器中断或系统调用期间，操作系统可能希望从运行当前进程切换到另一个进程，这是一种被称为上下文切换（context switch）的低级技术 调度CPU Scheduling 到现在为止，运行进程的低级机制（上下文切换）应该是清楚的。但是，我们尚未了解操作系统调度程序使用的高级策略。事实上，调度的起源早于计算机系统。早期的方法来自运营管理领域并应用于计算机。 如何制定调度策略（SCHEDULING POLICY）如何开发一个思考型调度策略的基本框架？关键假设是什么？哪些指标很重要？在最早的计算机系统中使用了哪些方法？ 工作负载假设Workload Assumptions 在介绍可能的策略范围之前，让我们首先对系统中运行的进程做一些简化的假设，有时统称为工作负载（workload）。确定工作负载是构建策略的关键部分，对工作负载了解的越多，你的策略就越精细。 我们将对系统中的进程（有时称为作业(jobs)）做出以下假设： 每个作业运行相同的时间 所有作业都在同一时间完成 一旦启动，每个作业都会运行完成 所有作业仅使用CPU 每个作业的运行时间都是已知的 这些假设很多是不现实的，正如乔治奥威尔《动物农场》中的一些动物比其它动物更平等，本章的一些假设比其它假设更不切实际。特别是，每个作业的运行时间都是已知的。这样做使调度程序无所不知。 调度指标Scheduling Metrics 除了进行工作负载假设之外，还需要一件事来使我们能够比较不同的调度策略：调度指标（Scheduling Metrics）。指标用来衡量某些事物，不同的指标在调度中也有不同的意义。但是，就目前而言。我们来看一个简单的指标：周转时间（turnaround time）。作业的周转时间定义为作业完成时间减去作业到达系统的时间： T_{turnaround} = T_{completion} − T_{arrival}应该注意，周转时间是一个性能指标。这将是本章的主要关注点。另一个有趣的指标是公平性（fairness）。在调度方面，性能和公平性往往不一致，这也告诉我们生活并不总是完美的。 先进先出First In, First Out (FIFO) 一个最基本的算法为先进先出（First In First Out (FIFO)）调度。它具有许多积极的属性，简单且易于实现。并且根据假设，它运作良好。 让我们做一个快速的栗子。想象一下，有三个作业A, B, C在大致相同的时间到达系统（T_{arrival}=0）。由于先进先出必须放置一些工作，让我们假设A-B-C的顺序，假设每个作业运行10s。这些作业的平均周转时间是多少？ 如图，A在10时完成，B在20时完成，C在30时完成。因此，三个作业的平均周转时间仅为\frac{10+20+30}{3}=30。 让我们举个栗子来说明不同长度的作业如何导致先进先出调度出现问题。特别是，假设A运行100s,B和C还是10s。 如图所示，在B或C有机会运行之前，作业A首先整整运行100s。因此，系统的平均周转时间很长：\frac{100+110+120}{3}=110，痛苦的110s。这个问题通常被称为车队效应（convoy effect），其中资源的一些小型消费者排在重量级消费者后面。那该怎么办？我们如何开发一种更好的算法来处理？ 最短作业优先Shortest Job First (SJF) 最短作业优先的原则最短作业优先表示可用于任何系统的一般调度原则，其中每个作业的感知周转时间很重要。如果有关机构关心客户满意度的话，很可能他们已经考虑使用最短作业优先。 最短作业优先（Shortest Job First(SJF)），它首先运行最短的作业，然后是下一个最短的作业，依此类推。 如图，该图表明了最短作业优先在平均周转时间方面的表现要好得多。它将之前的平均周转时间从110s减少到50s（\frac{10+20+120}{3}=50），这是极大的改善。事实上，鉴于我们对所有作业的假设都是同时到达，所以证明它是最优调度算法。但我们的假设相当不切实际。 这里再举个例子。假设A在t=0时到达并且需要运行100s，而B和C在t=10时到达并且每个需要运行10s。 如图，即使B和C在A之后不久到达，他们仍然被迫等到A完成，因此遭遇了同样的车队问题。平均周转时间为103.33s（\frac{100+(110-10)+(120-10)}{3}）。调度程序能做什么？ 预备调度器事实上，所有现代调度程序都是先发制人，并且非常愿意停止一个运行的进程以运行其它进程。这意味着调度程序采用我们之前学习的机制。特别是，调度程序可以进行上下文切换，暂时停止一个正在运行的进程并恢复另一个进程。 最短完成时间优先Shortest Time-to-Completion First (STCF) 我们还需要调度程序本身内的一些机制。鉴于前面关于计时器中断和上下文切换的讨论，调度程序当然可以在B和C到达时执行其它操作：它可以抢占作业A并决定运行另一个作业，可能会在执行继续作业A。最短作业优先是非抢先式（non-preemptive）调度程序，因此会遇到上述问题。幸运的是，有一个调度程序正是这样做：向最短作业优先添加抢占，称为最短完成时间优先（Shortest Time-to-Completion First (STCF)），或抢先最短作业优先（Preemptive Shortest Job First (PSJF)）调度程序。每当新作业进入系统时，最短完成时间优先调度程序就会确定剩余作业（包括新作业）中的哪一个剩余时间最少，并安排该作业。 如图，最短完成时间优先将抢占作业A并运行作业B和作业C以完成。只有当它们完成时才会安排作业A的剩余时间。这会大大改善平均周转时间：\frac{(120-0)+(20-10)+(30-10)}{3}=50。根据假设，可证明最短完成时间优先是最优。但假设相当不切实际。 响应时间指标A New Metric: Response Time 如果我们知道工作长度，并且工作只使用了CPU，并且我们唯一的指标是周转时间。那个STCF将是一个很好的策略。实际上，对于早期的批处理计算系统，这些类型的算法有一定意义。然而，分时（shared time）机器的引入改变了这一切。现在，用户将坐在终端上并要求系统提供交互式性能。因此，一个新的指标诞生了：响应时间（response time）。 响应时间：T_{response=T_{firstrun}-T_{arrival}} 例如，作业A在0时到达，作业B和作业C在10时到达。则每个作业的相应时间如下：A(0-0)，B(10-10)，C(20-10)，平均值(3.33)。 正如你可能认为那样，STCF和相关方法对响应时间并不是特别好。如果三个作业同时到达，则第三个作业必须等待前两个作业完全运行才能安排一次。虽然周转时间很好，但这种方法对于响应时间和交互性来说非常糟糕。事实上，想象一下坐在终端前，打字输入，并且不得不等待10s才能看到系统的响应，因为其它工作已安排在你前面：非常不爽。 因此，我们还有另外一个问题：如果构建一个对响应时间敏感的调度程序？ 轮询Round Robin 为了解决这个问题，将引入一种新的调度算法，通常称为轮询调度（RR, Round Robin）。基本思路很简单：轮询不是运行作业完成，而是运行时间切片（time slice）作业，然后切换到运行队列中的下一个作业。它重复这样做，知道工作完成。因此，轮询有时被称为时间切片（ time-slicing）。注意，时间片的长度必须是定时器中断周期的倍数。例如，如果定时器中断每10ms中断一次，则时间片可以是10ms, 20ms, 10Nms。 为了更详细的了解轮询，让我们来看一个栗子。假设有三个作业A, B, C在系统中同时到达，并且每个作业都希望运行5s。最短作业优先在运行另一个作业之前运行每个作业（图7.6），相比之下，时间切片为1s的轮询将快速循环作业（图7.7）。 平均响应时间： 轮询（RR）：\frac{0+1+2}{3}=1 最短作业优先（SJF）：\frac{0+5+10}{3}=5 如你所见，时间片的长度对轮询至关重要。它越短，响应时间的指标度量下轮询的性能越好。然而，使时间片太短是有问题的：上下文切换的成本将主导整体的性能。因此，决定时间片的长度给系统设计者带来了折中，使其足够长以分摊（amortize）切换成本不会使系统不再响应。 分摊可以降低成本（ AMORTIZATION CAN REDUCE COSTS）当某些操作存在固定成本时，一般的分摊技术通常用于系统中。通过较少地产生该成本，降低了系统的总成本。例如，如果时间片设置为10ms，并且上下文切换成本为1ms，则大约10%的时间用于上下文切换，浪费了。如果我们想分摊此成本，我们可以增加时间片（如100ms）。在这种情况下，上下文切换花费的时间少于1%，因此时间切片的成本已经分摊。 请注意，上下文切换的成本不仅仅来自于操作系统保存和恢复一些寄存器的操作。程序运行时，它们在CPU Cache、TLBs、Branch Predictors和其它分片上构建了大量状态(state)。切换到另一个作业会导致刷新(flush)此状态，并且将引入与当前正在运行的作业相关的新状态，这可能导致显著的性能成本。 因此，如果响应时间是我们的唯一指标，那么具有合理时间片的轮询将是一个出色的调度程序。但我们的老朋友周转时间呢？来看个栗子。A、B、C各自需要5s运行时间，它们同时到达，并且轮询的时间片为1s。从上面轮序的运行图可看出，A在13完成，B在14完成，C在15完成，平均时间为14。 如果周转时间使我们的指标，则轮序是最糟的策略之一。轮序正在做的是延长每个作业，只要它可以，只需在移动到下一个作业之前运行每个作业一小段。由于周转时间紧关注作业何时完成，因此在很多情况下，轮询几乎是悲观的，甚至比简单的先进先出更差。 任何公平的策略（如RR），即在小时间范围内在活跃进程之间均匀划分CPU，将在如周转时间的指标上表现不佳。实际上，这是一种固有的权衡：如果你愿意不公平，你可以完成更短的工作，按时以响应时间为代价；如果你更重视公平，那么响应时间会降低，但会以周转时间为代价。这种权衡(trade-off)在系统中很常见。you can’t have your cake and eat it too. 我们介绍了两种类型的调度程序，当然这些都是基于假设下： SJF, STCF优化了周转时间，但对响应时间不利； RR优化了响应时间，但对周转时间不利； 合并I/OIncorporating I/O 重叠使得更高的使用率(OVERLAP ENABLES HIGHER UTILIZATION)如果可能，重叠(overlap)操作以最大化系统的利用率。重叠在许多不同的域中都很有用，包括执行磁盘I/O或向远程计算机发送消息时。在任何一种情况下，启动操作然和切换到其它作业是一个好主意，并提高系统的整体利用率和效率。 放松假设4，假设所有程序都执行I/O。想象一个没有任何输入的程序，它每次会产生相同的输出。 当作业启动I/O请求时，调度程序明会做一个明确地决定。因为当前正在运行的作业在I/O期间不会使用CPU，它被阻止(blocked)以等待I/O完成。如果将I/O发送到磁盘驱动器，则该进程可能会被阻塞几毫秒或更长时间，具体取决于驱动器当前的I/O负载。因此，调度程序应该可能在那时在CPU上安排另一个作业。 调度程序还必须在I/O完成时做出决定。发生这种情况时，会引发中断，并且操作系统会运行并将发出I/O请求的进程从阻塞状态(blocked back)移回就绪状态(ready state)。当然，它甚至可以决定在那时开展工作。操作系统应如何处理每个工作？ 为了更好地理解这个问题，让我们假设有两个作业A和B，每个作业需要50ms的CPU时间。但有一个明显的区别：A运行10ms然后发出I/O请求（假设也许10ms），而B只使用CPU 50ms并且不执行I/O。调度程序首先运行A，然后运行B。 假设正在尝试构建STCF调度程序。显然，只运行一个工作然后运行另一个工作而不考虑I/O是没有意义的。 一种常见的方法是将A的每个10ms子作业视为独立工作。因此，当系统启动时，它的选择是是否安排10ms A或50ms B。使用STCF是明确的。当A的第一个子作业完成时，只剩下B，它开始运行。接着提交一个A的新子作业，它会抢占B并运行10ms。这样做允许重叠，一个进程在等待另一个进程的I/O完成时使用CPU，这样可以更好地利用该系统。 因此，我们看到调度程序如何合并I/O。通过将每个CPU突发视为作业，调度程序可确保交互(interactive)的进程进程运行。当这些交互式作业执行I/O时，其它CPU密集型作业会运行，从而更好地利用处理器。 摘要我们前面假设知道每个作业的长度，这可能是最糟糕的假设。实际上，在通用操作系统中，操作系统对每项工作的长度知之甚少。 我们介绍了调度背后的基本思想，并开发了两类方法。第一个运行剩余的最短作业，从而优化周转时间；第二个在所有作业之间交替运行，从而优化响应时间。两者都有好有坏，在系统中需要一个权衡。我们还看到了如何将I/O合并到调度中，但仍然没有解决操作系统基本无法看到未来的问题。不久我们将通过构建一个使用最近过去预测未来的调度程序，来了解如何克服这个问题。此调度程序称为多级反馈队列(multi-level feedback queue)，它是下一章的主题。 多级反馈队列Scheduling: The Multi-Level Feedback Queue 在本章中，我们将解决一种最著名的调度算法问题，称为多级反馈队列(MLFQ, Multi-level Feedback Queue)。多级反馈队列调度程序获得了图灵奖(Turing Award)。随后，调度程序经过多年的改进，完成了现代操作系统中的一些实现。 多级反馈队列试图解决的根本问题是双重的： 首先，它希望优化周转时间(turnaround time)。这是通过先运行较短的作业来完成。不幸的是，操作系统通常不知道作业运行的时间长短，这这是SJF, STCF等算法所需要的； 其次，它希望系统能够对交互式用户的敏感响应，从而最大限度地缩短响应时间。不幸的是，像RR这样的算法会缩短响应时间，但对于周转时间来说却很糟糕。 因此，问题是：鉴于我们通过对进行一无所知，如何构建调度程序来实现这些目标？在系统运行时，调度程序如何了解正在运行的作业的特征，从而做出更好的调度决策？ 如何在没有完美知识的情况下安排调度？如何设计一个调度程序，既可以最大限度地缩短交互式作业的响应时间，又可以在不事先了解作业长度的情况下做大限度地缩短周转时间？多级反馈队列是从学习过去预测未来的系统的一个很好的栗子。这些方法在操作系统中很常见。当工具具有行为阶段并且因此可预测时，这种方法起作用。当然，必须小心使用这些技术，因为它们很容易出错，并且驱使系统做出比没有任何知识的情况更糟糕的决策。 基本规则Basic Rule 为了构建这样的调度程序(scheduler)，在本章中我们将描述多级反馈队列背后的基本算法。虽然许多实施的MLFQ的细节不同，但大多数方法都是相似的。 在我们的处理中，MLFQ有许多不同的队列(queue)，每个队列分配不同的优先级(priority level)。在任何给定时间，准备运行的作业都在单个队列中。MLFQ使用优先级来决定在给定时间应该运行哪个作业：选择具有较高优先级的作业来运行。 当然，在给定队列上可能有多个作业，因此具有相同的优先级。在这种情况下，我们将在这些作业中使用轮询调度(round-robin scheduling)。因此，我们得出了MLFQ的前两个基本规则： Rule 1: If Priority(A) &gt; Priority(B), A runs (B doesn’t)； Rule 2: If Priority(A) = Priority(B), A and B run in RR。 因此，MLFQ调度的关键在于调度程序如何设置优先级。MLFQ不是为每个作业提供固定的优先级，而是根据其观察到的行为(observed behavior)改变(varies)作业的优先级。例如，如果作业在等待键盘输入是反复放弃CPU，MLFQ将保持其高优先级，因为这是交互式进程的行为方式。相反，如果作业长时间集中使用CPU，MLFQ将降低其优先级。通过这种方式，MLFQ将尝试在进程运行时了解进程，从而使用作业历史(history)来预测其未来(future)行为。 一个特定时刻可能的队列可能如下图这样。在此图中，作业(A和B)处于最高优先级，作业C处于中间，作业D处于最低优先级。当然，只显示某些队列的静态快照并不能真正让你了解MLFQ的工作原理。我们需要的是了解作业优先级如何随时间变化。 如何改变优先级How To Change Priority 我们现在必须决定MLFQ如何在作业的生命周期内更改作业的优先级。要做到这一点，我们必须牢记我们的工作负载：short-running（可能经常放弃CPU）的交互式作业的混合，以及一些需要大量CPU时间的longer-running的CPU-bound作业，但响应时间不重要。这将是我们首次尝试优先级调整算法： Rule 3： When a job enters the system, it is placed at the highest priority (the topmost queue). Rule 4a： If a job uses up an entire time slice while running, its priority is reduced (i.e., it moves down one queue). Rule 4b： If a job gives up the CPU before the time slice is up, it stays at the same priority level. 长作业栗子Example 1: A Single Long-Running Job 让我们看一个简单的栗子。首先我们来看一下当系统中存在长时间运行的作业时会发生什么。 如图所示，作业以最高优先级(Q2)进入。在10ms的单个时间片后，调度程序将作业的优先级降低1，因此作业位于Q1上。在Q1运行一段时间后，作业最终降低到系统中最低优先级(Q0)，并保留。 短作业栗子Example 2: Along Came A Short Job 让我们看一个复杂的栗子，看看MLFQ如何尝试接近近似SJF。在这个栗子中，有两个作业： A（长时间运行的CPU密集型作业）和B（短时间运行的交互式作业）。假设A已运行一段时间，然后B到达。会发生什么？MLFQ是否会接近B的SJF？ A（黑色）在最低优先级队列中运行；B（灰色）在T=100到达，因此被插入最高队列；因为它的运行时间很短(20ms)，所以B在到达底部队列之前完成，在两个时间片中；然后A恢复运行(低优先级)。 从这个栗子中，你可了解该算法的主要目标：因为它不知道工作是短期还是长期，所以它首先假设它可能是一项短期作业，从而使工作成为高优先级。如果它确实是一个短期作业，它将快速完成；如果它不是，它将慢慢向下排队，因此很快证明自己是一个长期运行的批处理进程。以这种方式，MLFQ近似于SJF。 I/O的栗子Example 3: What About I/O? 让我们看一些I/O的栗子。如果交互式作业正在执行大量I/O，它将在时间片完成前放弃CPU。在这种情况下，我们不希望惩罚工作，因此只是将其保持在同一水平。 图示显示了一个示例，其中交互式作业B在执行与长时间运行的批处理作业A的CPU的I/O竞争之前仅需要CPU 1ms。MLFQ方法将B保持在最高优先级，因此B不断释放CPU；如果B是一个交互式作业，MLFQ进一步实现快速运行交互式工作的目标。 优先级提升The Priority Boost 我们可以做些什么来保证CPU绑定的工作会取得一些进展。这里的简单想法是定期提高系统中所有作业的优先级。有很多方法可以实现这一点，但我们做一些简单的事情：将它们全部放在最顶层的队列中。因此，一条新规则： Rule 5： After some time period S, move all the jobs in the system to the topmost queue. 新规则同时解决了两个问题：保证进程不会挨饿(starve)，通过在最顶层队列中，作业将以循环方式与其它高优先级作业共享CPU，从而获得服务；其次，如果CPU绑定的作业已成为交互式，则调度程序在收到优先级提升后会对其进行正确处理。 来看个栗子，在这种情况下，我们只是在与两个短时间运行的交互式作业竞争CPU时显示长时间运行作业的行为。在左边没有优先级提升，因此一旦两个短作业到来，长作业就会挨饿。在右边，每50ms有一个优先级提升，因此我们至少保证长作业取得一些进展，得到提升到每50ms最高优先级，因此定期运行。 更好的计算Better Accounting 彩票调度Lottery Scheduling 在本章中，我们将研究一种称为proportional-share调度器，有时也称为fair share调度器。比例共享基于一个简单的概念：调度程序可能会尝试保证每个作业获得一定比例的CPU时间，而不是优化周转时间或响应时间。 彩票调度(lottery scheduler)是共享比例调度一个很好的早期栗子。基本想法非常简单：经常抽奖，以确定下一步应该运行哪一个进程。应该更频繁地运行的进程应该有更多机会赢得彩票，不是吗？ 如何按比例共享CPU？如何设计调度程序以按比例的方式共享CPU？这样的关键机制是什么？它们的效果如何？ 票代表你的份额Tickets Represent Your Share 抽奖调度是一个非常基本的概念：tickets，用于表示进程应该接收的资源的份额。进程所拥有的票百分比代表其所涉系统资源的份额。 来看个栗子。两个进程A（75票）和B（25票）。因此，我们想要的是A接收75%的CPU而B接收剩余的25%。 彩票调度每隔一段时间持有彩票来概率地实现这一点。持有彩票很简单：调度程序必须知道有多少总票数。调度程序从这里面选择一张中奖票。 使用票代表份额彩票调度设计中最强大的机制之一就是票。在这些示例中，票用于表示进程的CPU份额，但可更广泛地应用。例如，在最近关于虚拟机程序的虚拟内存管理的作业中，展示如何使用票来表示操作系统的内存份额。因此，如果你需要一种机制来代表一定比例的所有权，这个概念可能就是票。 票机制Ticket Mechanisms 彩票调度还提供了许多以不同且有时有用的方式操作票的机制。一种方式就是票货币(ticket currency)的概念。货币允许拥有一组票的用户在他们自己的工作中以他们想要的任何货币分配票，然后系统自动将所述货币转换为正确的全球价值。 例如，用户A和B每人都获得100张票。A正在运行两个作业A1和A2，并以A的货币向他们提供各500张票(共1000张)。用户B只运行一个作业并给它10张票(共10张)。 123User A -&gt; 500 (A’s currency) to A1 -&gt; 50 (global currency)-&gt; 500 (A’s currency) to A2 -&gt; 50 (global currency)User B -&gt; 10 (B’s currency) to B1 -&gt; 100 (global currency) 其它拥有的机制是票务转移(ticket transfer)。通过转移，一个进程可暂时将其票交给另一个进程。 多CPU调度Multi-CPU Scheduling 本章将会介绍多处理器调度(multiprocessor scheduling)的基础知识。由于此主题相对较高级，因此在你详细研究并发主题后，最好先介绍它。 多核处理器(multicore processor)（多个CPU核心被打包到单个芯片上）。 当然，随着多个CPU的到来，会出现很多困难。主要的一个典型是应用程序只使用一个CPU，添加更多CPU并不能使单个应用程序运行得更快。要解决此问题，你必须重新编写应用程序以并行(parallel)运行或使用线程(threads)。多线程应用程序可以在多个CPU之间传播工作，因此在获得更多CPU资源时运行速度更快。 除了应用程序之外，操作系统出现的新问题是多处理器调度(multiprocessor scheduling)的问题。到目前为止，我们已经讨论了单处理器背后的一些原则。如何将这些想法扩展到多CPU上？我们必须克服哪些问题？ 多处理器架构Multiprocessor Architecture 我们需要了解单CPU硬件和多CPU硬件之间的区别。这种差异主要围绕硬件缓存的使用，以及如何跨越多个处理器共享数据。这就涉及到了复杂的计算机架构问题。 在单CPU的系统中，存在硬件高速缓存(hardwarecaches )的层次结构，其通常帮助处理器更快地运行程序。高速缓存是小而快速的存储器，通常保存在系统主存储器中找到的数据的副本。相反，主存储器保存所有数据，但访问较大的存储器的速度较慢。通常将频繁访问的数据保存在高速缓存中，系统可以使大而慢的存储器看起来很快。 例如，考虑一个发出显式加载指令以从内存中获取值的程序，以及一个单CPU的简单系统。CPU有一个小缓存（64KB）和一个大的主内存。程序第一次发出负载时，数据驻留在主存储器中，因此需要很长时间才能获取。与其数据可以被重用的处理器将加载的数据的副本放入CPU的高速缓存中。如果程序稍后再次获取该相同的数据项，则CPU首先在高速缓存中检查它。如果在那里找到它，数据的获取速度要快的多，因此程序会运行得更快。 因此，高速缓存基于局部性的概念：时间局部性(temporal locality)和空间局部性(spatial locality)。时间局部性背后的想法是，当访问一条数据时，很可能在不就的将来再次访问它，想象变量设置指令本身在循环中反复访问。空间局部性的想法是，如果程序访问地址x处的数据项，则它也可以访问x附件的数据项。想想通过数组流式传输的程序，或者一个接一个地执行指令。由于这些类型的位置存在于许多程序中，因此硬件系统可以很好地擦侧哪些数据要放入缓存中，从而可以很好地工作。 事实证明，使用多个CPU进行缓存要复杂得多。想象一下，在CPU 1上运行的程序读取地址A的数据项（值D）；因为数据不在CPU 1的缓存中，系统从主存储器中取出数据，并获得值D。程序然后修改地址A的值，用新值D更新其缓存，将数据一直写入主存的速度很慢，因此系统稍后执行此操作。然后假设操作系统决定停止运行程序并将其移至CPU 2。然后程序重新读取地址A的值，CPU 2的缓存没有这样的数据，因此系统从主存中取值，并获得旧的值D而不是正确的值D。 这个一般性问题被称为缓存一致性(cache coherence)。 基本解决方案有硬件提供：通过监视内存访问，硬件可以确保基本上发生正确的事情并保留单个共享内存的视图。在基于总线的系统上执行此操作的每一种方法是使用称为总线侦听(bus snooping)，每个缓存通过观察它们连接到主存储器的总线来关注内存更新。当CPU然后看到它在缓存中保存的数据项的更新时，它将注意到该更改并使其副本无效，或更新它。如上所述，会写缓存会使这更加复杂，但你可以想象基本方案可能如何工作。 同步Don’t Forget Synchronization 鉴于缓存完成所有这些工作以提供一致性，程序在访问共享数据时是否必须担心什么？当跨CPU访问共享数据项或结构时，应该使用互斥来保证正确性。例如，假设我们在多个CPU上访问共享队列。没有锁，即使使用底层的一致性协议，同时在队列中添加或删除元素也不会按预期工作；一个需要锁定以原子方式将数据结构更新为新状态。 为了使其更具体，想象一下这个代码序列，它用于从共享链表中删除一个元素。如下图所示，如果两个CPU上的线程同时进入此例程。 Simple List Delete Code: 123456789101112typedef struct __Node_t &#123; int value; struct __Node_t *next;&#125; Node_t;int List_Pop() &#123; Node_t *tmp = head; // remember old head ... int value = head-&gt;value; // ... and its value head = head-&gt;next; // advance head to next pointer free(tmp); // free old head return value; // return value at head&#125; 缓存关联Cache Affinity 最后一个问题出现在构建多处理器缓存调度程序，称为缓存关联(cache affinity)。这个概念很简单：一个进程，当在特定的CPU上运行时，在CPU的高速缓存中建立一个相当大的状态。下一次进程运行时，在同一个CPU上运行它通常是有利的，因为如果它的某些状态已经存在于该CPU的高速缓存中，它将运行得更快。相反，如果每次在不同的CPU上运行进程，则进程的性能会更差，因为每次运行都必须重新加载状态。因此，多处理器调度程序在进行调度决策时应该考虑缓存关联，如果可能的话，可能更愿意将进程保留在同一CPU上。 单队列调度Single-Queue Scheduling 现在讨论为多处理器系统构建调度程序。最简单的方法是通过将需要调度的所有作业放入单个队列中，从而简单地将基本框架重用与单处理器调度。简称为单队列多处理器调度(singel queue multi processor scheduling)SQMS。这种方法的优点就是简单；采取现有策略选择下一个要运行的最优作业并使其适应与一个以上CPU的工作并不需要太多工作（例如，如果有两个CPU，它可以选择两个最优作业来运行。） 然而，SQMS有明显的缺点。 第一个问题是缺乏可伸缩性(scalability)。为了确保调度程序可以在多个CPU上正常工作，开发人员将在代码中插入某种形式的锁(locking)，如前所述。锁确保当SQMS代码访问单队列时（如，找到要运行的下一个作业），产生正确的结果。 不幸的是，锁会极大地降低性能，尤其是随着系统中CPU数量的增长。随着对单个锁的争夺增加，系统在锁开销(overhead)上花费的时间越来越多，而系统本应该执行的工作所花费的时间却越来越少。 第二个主要问题是缓存关联(cache affinity)。例如，假设我们有五个作业要运行(A, B, C, D, E)和四个处理器。调度队列如下所示： 因为每个CPU只是从全局共享队列中选择要运行的下一个作业，所以每个作业最终都会在各个CPU之间跳动，因此，与从缓存关联的角度来看完全相反。为了解决此问题，大多数SQMS调度程序都包含某种关联机制，以尽可能使进程仅能在在同一CPU上继续运行。具体来说，一个CPU可能为某些作业提供了亲和力，单四处移动以负载均衡。如，假设按照以下方式调度相同的五个作业： 在这种安排中，作业A到D不会在处理器之间移动，只有作业E从一个CPU迁移到另一个CPU，伊尼茨保留了大多数的亲和力。然后，你可以决定下一次迁移另一个作业，从而也实现某种亲和力公平性。但是，实施这种方案可能很复杂。 因此，我们可以看到SQMS方法有其有点和缺点。在给定现有的单CPU调度程序的情况下，实现起来很简单，根据定义，该调度程序只有一个队列。但是，它的伸缩性不好（由于同步开销），并且不容易保留缓存关联。 多队列调度Multi-Queue Scheduling 由于单队列调度程序中的问题，某些系统选择多队列。我们称这种方法为多队列多处理器调度(multi queue multiprocessor scheduling)MQMS。 在MQMS中，我们的基本调度框架由多个调度队列组成。尽管当然可以使用任何算法，但每个队列都可能遵循特定的调度规则，例如RR。当一个作业进入系统时，根据某种启发式方法（如，随机、选择一项作业比其他作业少的作业…），该作业将恰好放在一个调度队列中。它基本上是独立调度的，从而避免了在单队列方法中发现的信息共享和同步问题。 例如，假设我们有一个只有两个CPU（cpu0、cpu1）的系统，并有一些作业(A、B、C、D)进入系统。假设每个CPU现在都有一个调度队列，则操作系统必须决定将每个作业放入哪个队列。它可能会执行以下操作： 现在，根据队列调度策略，每个CPU在确定应该运行什么时都可以选择两个作业。例如，使用RR，系统可能会生产一个如下所示的时间表： 它具有更大的可伸缩性。随着CPU数量的增加，队列数量也随之增加，因此锁和缓存争用不应该成为中心问题。此外，MQMS本质上提供了缓存亲和力，作业保持在同一CPU上，从而获得了在其中重用缓存内容的优势。 但是，如果你注意到，可能会发现一个心问题，这是基于多队列方法的根本问题：负载不均衡(load imbalance)。假设作业C完成了，现在，我们有以下调度队列： 那么多队列多处理器调度程序一你改改怎么做？才能克服负载不均衡的隐患… CRUX: HOW TO DEAL WITH LOAD IMBALANCEHow should a multi-queue multiprocessor scheduler handle load imbalance, so as to better achieve its desired scheduling goals? 明显的答案是移动作业，我们再次将其称为迁移(migration)。通过将作业从一个CPU迁移到另一个CPU，可以实现真正的负载均衡。 当然，存在许多其它可能的迁移模式。但现在棘手的是：系统应该如何决定实施这种迁移？ 一种基本方法是使用一种成为work stealing的技术。使用工作窃取方法，工作量低的(source)队列有时会偷窥另一个(target)队列，以查看其填充(full)程度。如果目标队列比源队列更满，则源将从目标窃取一个或多个作业以帮助负载均衡。 当然，这种方法具有自然的张力。如果经常查看其它队列，那么将会遭受高昂的开销并难以扩展。另一方面，如果不经常查看其它队列，则有遭受负载不均衡的危险。在系统策略设计中很常见，找到正确的阈值是一件黑手艺。 Linux多处理器调度程序Linux Multiprocessor Schedulers 有趣的是，在Linux社区中，没有通用的解决方案来构建多处理器调度程序。随着时间的推移，出现了三种不同的调度程序： O(1) scheduler the Completely Fair scheduler(CFS) the BF scheduler O(1)和CFS都是用多队列，二BFS使用单队列，这表明两种方法都可以成功。例如，O(1)调度程序是基于优先级的（类似于前面讨论的MLFQ），随着时间的推移更改进程的优先级，然后调度优先级最高的进程，以满足各种给调度目标。交互性是另一个特别的重点。相比之下，CFS是确定性的比例共享(proportional-share)方法（更像前面讨论的Stride schedulig）。BFS是这三种方法中唯一的但队列方法，也是按比例共享，但它基于更复杂的方案，即Earliest Eligible Virtual Deadline First(EEVDF)。 总结Summary 我们已经看到了多处理器调度的各种方法。单队列方法(SQMS)构建起来很简单，并且可以很好地负载均衡，但是固有地很难扩展到多处理器并具有缓存关联。多队列方法(MQMS)可以更好地处理缓存亲和关系，但是在负载不均衡方面存在麻烦，并且更加复杂。无论采用哪种方法，都没有简单的答案：构建通用调度程序仍然是一项艰巨的任务，因为小的代码的更改可能会导致巨大的行为差异。仅当您确切地知道自己在做什么或者至少为此而获得了很多钱时，才进行这样的练习。 CPU虚拟化总结Summary Dialogue on CPU Virtualization: http://pages.cs.wisc.edu/~remzi/OSTEP/cpu-dialogue.pdf 内存虚拟化对话A dialogue on Memory Virtualization: http://pages.cs.wisc.edu/~remzi/OSTEP/dialogue-vm.pdf 内存地址Address Spaces: http://pages.cs.wisc.edu/~remzi/OSTEP/vm-intro.pdf 在早期，构建计算机系统很容易。因为那时用户期望不高。正是那些对易用性(ease of use)，高性能(high performance)，可靠性(reliability)…这些寄予厚望的用户确实导致了所有这些麻烦。 早期系统Early System 从内存的角度来看，早期的机器并没有为用户提供太多抽象(abstraction)。基本上，计算机的物理内存类似于下图: 操作系统是一组位语内存中的例程(routines)(实际上是一个库)（图中从物理地址0开始），并且将有一个正在运行的程序(process)当前位于内存中(从物理地址开始，图中为64k)，并使用了其余的内存。 多编程和时间共享Multiprogramming and Time Sharing 一段时间之后，由于机器价格昂贵，人们开始更有效地共享机器。因此，多重编程诞生了，在该时代，多进程准备在给定的时间运行，并且操作系统将在它们之间切换。例如，当一个人决定执行一个I/O时。这样做可以提高CPU的有效利用率(effective utilization)。在每台机器高达数十万百万的那些日子里，这种效率的提高尤其重要。 很快，人们开始需求更多的机器，时间共享(time share)诞生了。具体来说，许多人意识到批处理(batch computing)的局限性，特别是对程序员本身，因为他们厌倦了漫长的程序调试周期。交互性(interacttivity)的概念变得很重要，因为许多用户可能正在同时使用一台计算机，每个用户都在等待（或希望）他们当前正在执行的任务的及时响应。 实现时间共享的一种方法是短暂运行一个进程，使其完全访问所有的内存，然后停止它。将其所有状态保存到某种磁盘中（包括所有物理内存）。加载其它进程的状态，运行一段时间，从而实现对机器的某种粗略共享。 不幸的是，这种方法有一个大问题：它太慢了，特别是随着内存的增长。虽然保存和恢复寄存器级别状态(PC, general-purpose registers…)相对较快，但将整个内存内容保存到磁盘上却无法执行。因此，我们宁愿将进程留在内存中，同时在它们之间进行切换，从而使操作系统能够有效地实现时间共享。如下图所示: 该图有三个进程(A, B, C)，每个进程都为它们分配了512KB物理内存的一部分。假设一个单CPU，操作系统选择其中一个进程(如A)，而其它进程(B, C)在准备队列中等待运行。 随着时间共享变得越来越流行，您可能会猜到对操作系统提出了新的要求。尤其是，允许多个程序同时驻留(reside)在内存中使保护成为一个重要问题。您不希望某个进程能够读取(read)，更糟的是，写入其它进程的内存。 地址空间The Address Space 但是，我们必须牢记那些讨厌的用户，并且这样做需要操作系统创建易于使用(easy to use)的物理内存抽象(abstraction)。我们称这种抽象为地址空间(address space)，它是运行在系统中的程序的内存视图。了解内存的这种基本操作系统抽象是了解如何虚拟化内存的关键。 进程的地址空间包含正在运行的程序的所有内存状态。例如，程序代码(指令)必须驻留在内存中的某个位置，因此它们位于地址空间中。该程序在运行时会使用栈(stack)来追踪(track)它在函数调用链中的位置，并分配局部变量，并在例程之间传递参数以及返回值。最后，堆(heap)用于动态分配(dynamically allocated)、用户管理的内存。例如，您可能会从C中的malloc()调用或以面向对象语言(C++, Java)通过new调用中接收到。当然，其中也有其他内容（如，statically-initialized variables)，但是现在让我们假设这三个组件: code stack heap 在下图中，有一个小地址空间(16KB)。程序代码位于地址空间的顶部（此例中，从0开始，并打包到地址空间的前1K）。代码是静态的，因此很容易放置在内存中，因此我们可以将其放在地址空间的顶部，并知道在程序运行时不需要任何空间。 接下来，我们在程序运行时拥有地址空间的两个区域，它们可能增长(grow)或收缩(shrink)。这些是堆(heap)(在顶部)和栈(stack)(在底部)。之所以这样放置它们，是因为每个人都希望能够增长，并且通过将它们放在地址空间的相对两端(opposite ends)，我们可以允许这种增长：它们只需要朝相反的方向增长。这样，堆就在代码之后(1KB)开始向下增长（如，用户通过malloc()请求更多内存时），栈从底部(16KB)开始并向上增长（如，用户进行过程调用时）。但是，栈和堆的这种放置只是一个约定(convention)。您可以根据需要以不同的方式安排地址空间（将在后面看到，当多线程(multi threads)共存(co-exist)于一个地址空间时，再也没有一种很好的方法来划分地址空间了）。 当然，当我们描述地址空间时，我们所描述的操作系统为正在运行的程序提供的抽象(abstraction)。该程序实际上不在物理地址0到16KB的内存中，而是将其加载到某个任意物理地址。查看图13-2中的进程A, B, C，您可以看到每个进程如何以不同的地址加载到内存中。因此，问题来了。 THE CRUX: HOW TO VIRTUALIZE MEMORYHow can the OS build this abstraction of a private, potentially large address space for multiple running processes (all sharing memory) on top of a single, physical memory? 当操作系统执行此操作时，我们说操作系统正在虚拟化内存(virtualizing memory)，因为正在运行的程序认为它已加载到特定地址的内存中，并且具有很大的地址空间（如32-bits或64-bits）。现实是完全不同的。 例如，当13-2图中的进程A尝试在地址0（我们称其为虚拟地址）上执行加载时，以某种方式，操作系统与某些硬件支持相结合。将必须确保加载实际上并没有转到物理地址0，而是物理地址320KB（将A加载到内存中的地址）。这是内存虚拟化的关键，而内存虚拟化是世界上每个现代计算机系统的基础。 目标Goals 因此，我们在注释中完成了操作系统的工作：虚拟化内存。但是，操作系统不仅会虚拟化内存，还会以某种风格来做。为了确保操作系统能够做到这一点，我们需要一些目标来指导我们。我们之前已经看过这些目标，我们将再次看到它们，但肯定是值得重复的。 虚拟化内存(VM)系统的一个主要目标是透明度(transparency)。操作系统应以对运行的程序不可见的方式实现虚拟内存。因此，程序不应意识到内存已虚拟化。而是，程序行为就像具有自己的专用物理内存一样。在后台，操作系统（和硬件）完成了所有工作，以在许多不同的作业之间多路复用内存，从而实现了这种错觉。 虚拟化内存的另一个目标是效率(efficiency)。操作系统应努力在时间(不使程序运行速度更慢)和空间(不为支持虚拟化所需的结构使用过多内存)方面使虚拟化尽可能高效。在实现高效的虚拟化时，操作系统将不得不依赖硬件支持，包括诸如TLB的硬件功能。 最后，虚拟化内存的第三个目标是保护(protection)。操作系统应确保保护进程彼此之间以及操作系统本身不受进程影响。当一个进程执行加载、存储、指令获取时，它不应以任何方式访问或影响任何其它进程或操作系统本身（即，其地址空间之外的任何内容）的内存内容。因此，保护使我们能够在流程之间提供隔离(isolation)的特性。每个进程都以你敢再自己的隔离茧中运行，以免遭受其它故障甚至恶意进程的破坏。 在下一章中，我们将重点研究虚拟化内存所需的基本机制，包括硬件和操作系统支持。我们还将研究您在操作系统中会遇到的一些更相关的策略，包括如何管理可用空间(free space)以及当空间不足时要从内存中踢出(kick out of)哪些页面。这样，我们将加深您对现代虚拟内存系统实际工作方式的了解。 TIP: THE PRINCIPLE OF ISOLATIONIsolation is a key principle in building reliable systems. If two entities are properly isolated from one another, this implies that one can fail without affecting the other. Operating systems strive to isolate processes from each other and in this way prevent one from harming the other. By using memory isolation, the OS further ensures that running programs cannot affect the operation of the underlying OS. Some modern OS’s take isolation even further, by walling off pieces of the OS from other pieces of the OS. Such microkernels thus may provide greater reliability than typical monolithic kernel designs. 总结Summary 我们已经看到了一个主要的操作系统子系统的引入：虚拟化内存。虚拟化内存系统分则为程序提供庞大、稀疏的专用地址空间的错觉，这些程序将所有指令和数据保存在其中。操作系统将在一些严重的硬件帮助下获取这些虚拟化内存引用中的每一个，并将其转换为物理地址，可以将其提供给物理内存，以获取所需的信息。操作系统将一次对多个进程执行此操作，请确保相互保护程序并保护操作系统。整个方法需要大量的机制以及一些关键的策略才能起作用。我们将从头开始，首先描述关键机制。因此，继续。 123456789101112131415161718192021222324252627282930313233343536373839ASIDE: EVERY ADDRESS YOU SEE IS VIRTUALEver write a C program that prints out a pointer? The value you see(some large number, often printed in hexadecimal), is a virtual address.Ever wonder where the code of your program is found? You can printthat out too, and yes, if you can print it, it also is a virtual address. Infact, any address you can see as a programmer of a user-level programis a virtual address. It’s only the OS, through its tricky techniques ofvirtualizing memory, that knows where in the physical memory of themachine these instructions and data values lie. So never forget: if youprint out an address in a program, it’s a virtual one, an illusion of howthings are laid out in memory; only the OS (and the hardware) knows thereal truth.Here’s a little program (va.c) that prints out the locations of the main()routine (where code lives), the value of a heap-allocated value returnedfrom malloc(), and the location of an integer on the stack:#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(int argc, char *argv[]) &#123; printf(&quot;location of code : %p\n&quot;, main); printf(&quot;location of heap : %p\n&quot;, malloc(100e6)); int x = 3; printf(&quot;location of stack: %p\n&quot;, &amp;x); return x;&#125;When run on a 64-bit Mac, we get the following output:location of code : 0x1095afe50location of heap : 0x1096008c0location of stack: 0x7fff691aea64From this, you can see that code comes first in the address space, thenthe heap, and the stack is all the way at the other end of this large virtualspace. All of these addresses are virtual, and will be translated by the OSand hardware in order to fetch values from their true physical locations. 内存APIMemory API: http://pages.cs.wisc.edu/~remzi/OSTEP/vm-api.pdf 在这个插曲中，我们讨论Unix系统中内存分配接口。所提供的接口非常简单，因此本章简短而切合实际。主要问题如下: CRUX: HOW TO ALLOCATE AND MANAGE MEMORYIn UNIX/C programs, understanding how to allocate and manage memory is critical in building robust and reliable software. What interfaces are commonly used? What mistakes should be avoided? 内存类型Types of Memory 在运行C程序时，分配了两种类型的内存。第一种称为stack memory，由编译器为您隐式管理其分配(allocation)和释放(deallocation)。因此，有时称为automatic memory。 在C中的stack上声明内存很容易。例如，假设您在func()函数中需要一些空间来存放一个名为x的整数。要声明这样的一片内存，只需执行以下操作: 1234void func() &#123; int x; // declares an integer on the stack ...&#125; 其余部分由编译器完成，请确保在调用func()时在stack上留出空间。当您从函数返回时，编译器会为你释放内存。因此，如果你希望某些信息活到调用之后，你最好不要将该信息保留在stack中。 正是这种对long-lived memory的需求将我们带到了第二种类型的内存，称为heap memory，其中所有分配和释放都由您明确处理。毫无疑问，这是一个沉重的责任！无疑是许多bug的原因。但是，如果您小心翼翼并注意，您将可以正确使用此类接口，而不会遇到太多麻烦。如下是一个如何在堆(heap)上分配整数的示例: 1234void func() &#123; int *x = (int *) malloc(sizeof(int)); ...&#125; 关于此小代码段的一些注意事项。首先，您可能会注意到stack和heap分配都发生在这一行：首先，编译器在看到您的指针声明(int *x)时就知道为整数指针腾出空间。随后，当程序调用malloc()时，它将在heap上为整数请求空间。例程返回这样一个整数的地址（成功时返回，失败时返回NULL），然后将其存储在stack中以供程序使用。 由于其显式的性质以及更广泛的用途，heap memory对内存和系统都提出了更多挑战。因此，这是我们其余讨论的重点。 malloc调用The malloc() Call malloc()调用十分简单：向其传递一个大小，以要求在heap上留出一定的空间。它要么成功并返回给您指向新分配的空间的指针，要么失败并返回NULL。在命令行中输入man malloc以获取帮助。 123#include &lt;stdlib.h&gt;...void *malloc(size_t size); 从此信息中，您可以看到你需要做的就是包含头文件stdlib.h来使用malloc。实际上，您根本不需要这样做。因为默认情况下，所有C程序都链接到C library，之中包含了malloc()的代码。添加header只是让编译器检查你是否正确调用了malloc()（例如，向其传递了正确数量或类型的参数）。 malloc()的单个参数的大小为t，它简单地描述了您需要缩少字节。但是，大多数编程人员不会在此处直接输入数字。（实际上，这样做会被认为是糟糕的形式。）而是使用各种例程(routines)和宏(macros)。例如，要为双精度浮点值分配空间，只需执行以下操作: 1double *b = (double *) malloc(sizeof(double)); 这种对malloc()的调用使用sizeof()运算符来请求正确的空间量。在C语言中，通常将其视为编译时(compile-time)运算符，这意味着实际大小在编译时已知，因此将一个数字替换为malloc()的参数。因此，将sizeof()正确地视为运算符，而不是函数调用（函数调用将在运行时发生）。 您还可以将变量名（而不只是类型）传递给sizeof()，但是在某些情况下，您可能无法获得所需的结果，因此请小心。例如，让我们看下面的代码片段: 12int *x = malloc(10 * sizeof(int));printf("%d\n", sizeof(x)); 在第一行中，我们声明了一个由10个整数组成的数组的空间，即好又花哨。但是，当我们在下一行中使用sizeof()时，它将返回一个较小的值，如4(32-bit机器)或8(64-bit机器)。原因是在这种情况下，sizeof()认为我们只是在问整数的指针有多大，而不是动态分配了多少内存。然而，有时sizeof()确实可以按你于其的那样工作: 12int x[10];printf("%d\n", sizeof(x)); 在这种情况下，有足够的静态信息供编译器知道已经分配了40Bytes。 另一个要注意的地方是字符串(string)。在声明字符串的空间时，请使用以下管用法：malloc(strlen(s) + 1)，该字符串使用strlen()函数旱区字符串的长度，并向其加1为末尾字符串字符留出空间。在这里使用sizeof()可能会导致麻烦。 你可能还会注意到，malloc()返回了一个指向void类型的指针。这样做只是C语言中传回地址并让编程人员决定如何处理该地址的方法。编程人员通过使用强制转换来进一步提供帮助。 TIP: WHEN IN DOUBT, TRY IT OUTIf you aren’t sure how some routine or operator you are using behaves, there is no substitute for simply trying it out and making sure it behaves as you expect. While reading the manual pages or other documentation is useful, how it works in practice is what matters. Write some code and test it! That is no doubt the best way to make sure your code behaves as you desire. Indeed, that is what we did to double-check the things we were saying about sizeof() were actually true! free调用The free() Call 事实证明，分配内存时方程式最简单的部分。知道何时、如何释放内存是最困难的部分。要释放不再使用的heap memory，编程人员只需调用free()。 123int *x = malloc(10 * sizeof(int));...free(x); 该例程采用一个参数，即malloc()返回的指针。因此，您可能会注意到，分配的区域的大小不是由用户传递的，必须由内存分配本身进行跟踪。 常见错误Common Errors 使用malloc()和free()时会出现许多常见错误。这是我们在本科操作系统中反复看到的一些内容。所有这些示例都可以编译，并且无需编译器即可窥视。 正确的内存管理一直是一个问题，事实上，许多更新的语言都支持自动内存管理(automatic memory management)。在这样的语言中，当您调用类似于malloc()的东西来分配内存时，您不必调用任何东西来释放空间。相反，垃圾收集器(grabage collector)将运行并找出您不在引用的内存，并为您释放它。 TIP: IT COMPILED OR IT RAN 6= IT IS CORRECTJust because a program compiled(!) or even ran once or many times correctly does not mean the program is correct. Many events may have conspired to get you to a point where you believe it works, but then something changes and it stops. A common student reaction is to say (or yell) “But it worked before!” and then blame the compiler, operating system, hardware, or even (dare we say it) the professor. But the problem is usually right where you think it would be, in your code. Get to work and debug it before you blame those other components. 忘记分配内存Forgetting To Allocate Memory 许多例程(rutines)希望在调用它们之前先分配内存。例如，例程strcpy(dst, src)将字符串从源指针复制到目标指针。但是，如果您不小心，可能会这样做： 123char *src = "hello";char *dst; // oops! unallocatedstrcpy(dst, src); // segfault and die 当您运行此代码时，可能导致分段错误，这是您对内存有错误的幻想，因为您对程序感到迷惑，并且很生气。在这种情况下，正确的代码可能看起来像这样： 123char *src = "hello";char *dst = (char *) malloc(strlen(src) + 1);strcpy(dst, src); // work properly 或者您可以使用strdup()使您的生活更加轻松。 没有分配足够的内存Not Allocating Enough Memory 一个相关的错误是没有分配足够的内存(allocate enough memory)，有时称为缓存区溢出(buffer overflow)。在上面的示例中，常见的错误是为目标缓存区腾出几乎足够的空间： 123char *src = "hello";char *dst = (char *) malloc(strlen(src)); // too small!strcpy(dst, src); // work properly 奇怪的是，取决于malloc的实现方式和许多其它细节，该程序通常看似正确运行。在某些情况下，执行字符串复制时，它会在已分配空间的末尾写入一个字节，但这在某些情况下是无害的，可能会覆盖一个不再使用的变量。在某些情况下，这些溢出可能非常有害，并且实际上是许多安全漏洞(security vulnerabilities)的根源。在其它情况下，无论如何，malloc库都会分配一些额外的空间，因此，您的程序实际上不会在其它变量的值上乱写，并且可以正常工作。在其它情况下，该程序的确会出错并崩溃。因此，我们吸取了另一个宝贵的教训：即使正确运行了一次，也并不意味着它是正确的。 忘记初始化分配的内存Forgetting to Initialize Allocated Memory 遇到此错误，您可以正确地调用malloc()，但是忘记将某些值填写到新分配的数据类型中。不要这样做！如果您忘记了，您的程序最终将遇到未初始化的读取(uninitialized read)，即从heap中读取一些未知值的数据。谁知道里面会有什么？如果幸运的话，您可以通过一些值使程序仍然可以运行（如0）。如果不走运，那是随机和有害的事情。 忘记释放内存Forgetting To Free Memory 另一个常见的错误称为内存泄漏(memory leak)，当您忘记释放内存时就会发生。在长时间运行的应用程序或系统中，这是一个巨大的问题，因为缓慢泄露内存最终会导致内存用完(OOM)，此时需要重新启动。因此，通常，当您完成了一块内存后，应该确保释放它。请注意，使用垃圾回收的语言在这里无济于事。如果您仍然引用某些内存块，则没有垃圾回收器会释放它，因此即使在更现代的语言中，内存泄漏仍然时一个问题。 在某些情况下，似乎不用调用free()是合理的。例如，您的程序寿命很短，将很快推出。在这种情况下，当进程终止时，操作系统将清除其所有分配的页面，因此本身不会发生内存泄漏。尽管这肯定是有效的，但养成这种习惯可能是个坏习惯，因此请谨慎选择这种策略。从长远来看，作为程序员的目标之一是养成良好的习惯。这些习惯一是了解如何管理内存，以及释放已分配的内存块。即使您可以避免这样做，也应该养成释放显式分配的每个字节的习惯。 完成之前释放内存Freeing Memory Before You Are Done With It 有时，程序会在使用完成内存之前释放内存。这样的错误称为悬空指针(dangling pointer)，如您所猜测的那样，这也是一件坏事。后续使用可能会导致程序崩溃，或覆盖有效内存。 反复释放内存Freeing Memory Repeatedly 程序有时还不止一次释放内存，这就是所谓的double free。这样做的结果是不确定的。可以想象，内容分配库可能会感到困惑，并且会做各种奇怪的事情，崩溃是常见的结果。 ASIDE: WHY NO MEMORY IS LEAKED ONCE YOUR PROCESS EXITSWhen you write a short-lived program, you might allocate some space using malloc(). The program runs and is about to complete: is there need to call free() a bunch of times just before exiting? While it seems wrong not to, no memory will be “lost” in any real sense. The reason is simple: there are really two levels of memory management in the system.The first level of memory management is performed by the OS, which hands out memory to processes when they run, and takes it back when processes exit (or otherwise die). The second level of management is within each process, for example within the heap when you call malloc() and free(). Even if you fail to call free() (and thus leak memory in the heap), the operating system will reclaim all the memory of the process (including those pages for code, stack, and, as relevant here, heap) when the program is finished running. No matter what the state of your heap in your address space, the OS takes back all of those pages when the process dies, thus ensuring that no memory is lost despite the fact that you didn’t free it.Thus, for short-lived programs, leaking memory often does not cause any operational problems (though it may be considered poor form). When you write a long-running server (such as a web server or database management system, which never exit), leaked memory is a much bigger issue, and will eventually lead to a crash when the application runs out of memory. And of course, leaking memory is an even larger issue inside one particular program: the operating system itself. Showing us once again: those who write the kernel code have the toughest job of all… 错误地调用freeCalling free() Incorrectly 我们讨论的最后一个问题是对free()的错误调用。free()希望您仅将您从mallo()收到的指针之一传递给它。当您传递其它一些值时，可能会发生糟糕的事。因此，这种无效的释放是危险的，当然也应该避免。 总结Summary 如您所见，有很多滥用内存的方式。用于经常发生内存错误，因此开发了整个工具生态圈来帮助您在代码中查找此类问题。检出purify和valgrind，两者都很擅长帮助您找到与内存相关的问题的根源。一旦您习惯了使用这些强大的工具，您会想知道如果没有这些工具，您将如何生存。 底层操作系统支持Underlying OS Support 您可能已经注意到，在讨论malloc()和free()时，我们并未谈论系统调用。原因很简单，它们不是系统调用，而是库调用。因此，malloc库管理您的虚拟地址空间内的空间，但它本身是建立在某些系统调用之上，这些系统调用会向操作系统发出请求以请求更多内存或将一些内存释放回系统。 一个这样的系统调用称为brk，用于更改程序的中断(break)的位置：heap末尾的位置。它采用一个参数(新中断的地址)，因此根据新中断是大于还是小于当前中断来增加或减少heap的大小。一个附加的sbrk调用传递一个增量，起类似的作用。 请注意，永远不要直接调用brk或sbrk。它们由内存分配库使用。如果尝试使用它们，则可能会导致某些错误（非常严重）。坚持使用malloc()和free()。 最后，您还可以通过mmap调用从操作系统获取内存。通过传入正确的参数，mmap()可以在程序内创建一个匿名(anonymous)内存区域，该区域与任何特定文件都没有关联，而是与交换空间(swap space)关联，将在稍后详细讨论。 其它调用Other Calls 内存分配库还支持其它一些调用。例如，calloc()分配内存，并在返回之前将其清零。这样可以防止某些错误（假设您认为内存已清零）而忘记自己进行初始化。当您为某物分配了空间，然后需要向其中添加一些东西时，例程realloc()也会很有用。realloc()会创建一个更大的新内存区域，将旧区域复制到并返回指向新区域的指针。 地址转换Address Translation 在开发CPU的虚拟化过程中，我们集中于一种称为受限的直接执行(limited direct execution, LDE)。它背后的想法很简单：在大多数情况下，让程序直接在硬件上运行。但是，在某些关键的时间点（如，当进程发出系统调用或发生计时器中断时），请安排好操作系统，以确保正确的事情发生。因此，在几乎没有硬件支持的情况下，操作系统将尽最大努力拜托正在运行的程序，从而提供有效的虚拟化。但是，通过在这些关键时刻进行干预，操作系统可确保对硬件进行控制。效率(efficiency)和控制(control)是任何现代操作系统的两个主要目标。 在虚拟化内存中，我们将采取类似的策略，在提供所需的虚拟化的同时实现效率和控制力。效率要求我们利用硬件支持，起初会很基本（如，只有几个寄存器），但会变得相当复杂(如，TLB，page-table支持)。控制意味着操作系统确保除了自身的内存外，不允许使用其它任何应用程序访问任何内存。因此，为了保护应用程序彼此之间以及操作系统与应用程序之间的相互帮助，我们在这里也需要硬件的帮助。最后，就灵活性而言，我们将需要从VM系统中获取更多信息。具体来说，我们希望程序能够以任意方式使用其地址空间，从而使系统更易于编程。因此，我们找出了症结所在: HOW TO EFFICIENTLY AND FLEXIBLY VIRTUALIZE MEMORYHow can we build an efficient virtualization of memory? How do we provide the flexibility needed by applications? How do we maintain control over which memory locations an application can access, and thus ensure that application memory accesses are properly restricted? How do we do all of this efficiently? 我们将使用的通用技术可以被视为基于硬件的地址转换(hardware-based address translation)，简称为地址转换(address translation)，它是对有限直接执行(lde)的一般方法的补充。借助地址转换，硬件转换每个内存访问（如，fetch指令、load、store），将指令提供的虚拟地址更改为所需信息实际所在的物理地址。因此，在每个内存引用上，硬件都会执行地址转换，以将应用程序内存引用重定向到它们在内存中的实际位置。 当然，仅硬件本身不能虚拟化内存，因为它只是提供了低级机制来有效地进行虚拟化。操作系统必须在关键点接入以设置硬件，以便进行正确的转换。因此，它必须管理内存，跟踪那些位置空闲以及正在使用那些位置，并明智地进行干预以保持对内存使用方式的控制。 所有这些工作的目标是再次营造一种美好的幻想：该程序具有自己的私有内存，其自身代码和数据驻留在其中。虚拟现实的背后隐藏这丑陋的物理事实：当一个或多个CPU在运行一个程序与另一个程序之间切换时，许多程序实际上在同时共享内存。通过虚拟化，操作系统（在硬件的帮助下）将丑陋的机器现实转变为有用的，强大且易于使用的抽象。 假设Assumptions 我们首次关于虚拟化内存的尝试将非常简单，几乎时可笑的。当您视图了解TLB，multi-level page tables和其它技术的来龙去脉时，这就是操作系统的运行方式。 具体来说，我们现在假设用户的地址空间必须连续(contiguously)放置在物理内容中。为了简单起见，我们还将假定地址空间的大小不是太大（小于物理内存）。最后，我们还将假定每个地址空间的大小完全相同。如果这些假设听起来不切实际，请不要担心，我们将在使用过程中放松它，从而实现逼真的内存虚拟化。 一个栗子An Example 为了更好地了解实现地址转换所需做的事情以及为什么需要这种机制，我们来看一个简单的栗子。想象有一个进程的地址空间如图15-1所示。我们将在这里检查的是一个简短的代码序列，该序列从内存中加载值，将其递增3，然后将值存储回内存中。你可以想象此C语言的代码可能如下所示。编译器将这一行代码转换为汇编，可能看起来像着这样（在x86汇编中）。在Linux上使用objdmp进行反汇编。 1234void func() &#123; int x = 3000; // thanks, Perry. x = x + 3; // line of code we are interested in... 123128: movl 0x0(%ebx), %eax ;load 0+ebx into eax132: addl $0x03, %eax ;add 3 to eax register135: movl %eax, 0x0(%ebx) ;store eax back to mem 该段代码相对简单。假定x的地址已放置在寄存器ebx中，然后使用movl指令将该地址处的值加载到通用寄存器eax中。下一条指令将eax加3，最后一条指令将eax中的值存储在同一位置的内存中。 在图15-1中，观察代码和数据在进程的地址空间中的布局方式。三指令代码序列位于地址128（在顶部附近的代码部分）中，变量x的值位于地址15KB(在底部附近的stack中)。在图中，x的初始值为300，如其在栈中的位置所示。 当这些指令运行时，从进程的角度来看，将进行以下内存访问: Fetch instruction at address 128 Execute this instruction (load from address 15 KB) Fetch instruction at address 132 Execute this instruction (no memory reference) Fetch the instruction at address 135 Execute this instruction (store to address 15 KB) 从程序的角度来看，其地址空间从地址0开始，最大增加到16KB。它生成的所有内存引用都应该在这些范围内。但是，为了虚拟化内存，操作系统希望将进程放置在物理内存中的其它位置，而不必放在地址0。因此，我们遇到了一个问题：如何以一种对进程透明的方式将进程重新放置在内存中？当实际上地址空间位于其它物理地址时，我们如何提供从0开始的虚拟地址空间的错觉？ 在图15-2中找到了此进程的地址空间放置在内存中后，物理内存样子的栗子。在改图中，您可以看到操作系统本身使用了物理内存的第一个插槽，并且它已将上述示例中的过程重新定位到从32KB物理内存地址开始的插槽中。其它两个插槽时空闲的（16-32KB和48-64KB）。 动态(基于硬件)重定位Dynamic (Hardware-based) Relocation 为了对基于硬件的地址转换有一定的了解，我们将首先讨论第一代产品。在1950年代后期的第一台分时(time-sharing)机器中引入了一个简单的概念——基准(base)和边界(bounds)。该技术也称为动态重定位(dylamic relocation)。 具体来说，我们在每个CPU中需要两个硬件寄存器： base register bounds register（有时称为limitregister） 这个base-and-bounds对将使我们能够将地址空间放置在物理内粗中所需的任何位置，并在确保进程只能访问自己的地址空间的同时这样做。在这种设置下，每个程序都被编写和编译，就好像加载到地址0一样。但是，当程序开始运行时，操作系统会决定将其加载到物理内存中的哪个位置，并将base register设置为该值。在上面的栗子中，操作系统决定将进程加载到32KB的物理地址，因此将base register设置为此值。 进程运行时，有趣的事情开始发生。现在，当进程生成任何内存引用时，处理器将按以下方式对其进行转换: physical address = virtual address + base 进程生成的每个内存引用都是一个虚拟地址。硬件又将base register的内容添加到该地址，结果是可以发布到内存系统的物理地址。 为了更好地理解这一点，让我们追溯一条指令执行时发生的情况。具体来说，让我们看一下先前序列中的一条指令：128: movl 0x0(%ebx), %eax 程序计数器(program counter)设置为128，当硬件需要fetch(提取)该指令时，它首先将该值增加到32KB(32768)的base register值中，以得到32896的物理地址。然后，硬件从该物理地址获取指令。接下来，处理器开始执行指令。然后，在某个时候，该进程从虚拟地址15KB发出负载，处理器将其加载，然后再次添加到base register(32KB)，获得最终物理地址47KB，从而获得所需的内容。 将虚拟地址转换为物理地址正是我们称为地址转换的技术。也就是说，硬件获取进程认为正在引用的虚拟地址，并将其转换为数据实际驻留的物理地址。因为地址的这种重定位(relocation)发生在运行时，并且因为即使进程开始运行后我们也可以移动地址空间，所以该技术通常称为动态重定位(dynamic relocation)。 现在你那可能会问： bounds(limit) register发生了什么？您可能已经猜到了，bounds register在那里可以提供保护。具体来说，处理器将首先检查内存引用是否在范围之内，以确保它是否合法。在上面的简单示例中，bounds register始终设置为16KB。如果某个进程生成的虚拟地址大于边界(bound)，或为负数，则CPU将引发异常，并且该进程可能会终止。因此，边界点要确保进程生成的所有地址都是合法的，并且在进程的边界内。 我们应该注意，base和bounds寄存器是芯片上保留的硬件结构（每个CPU一对）。有时人们将处理器中有助于地址转换的部分称为内存管理单元(memory management unit, MMU)。随着我们开发更复杂的内存管理技术，我们将向MMU添加更多电路。 关于bound register的一些说明，可以在以下两种方式的其中一项定义：一种方式(如上所述)，它保持地址空间的大小，因此硬件在添加base之前首先针对它检查虚拟地址。第二种方式，它确保地址空间末端的物理地址，因此硬件首先添加base，然后确保该地址在范围之内。两种方法在逻辑上是等效的，为简单起见，我们通常采用前一种方法。 ASIDE: SOFTWARE-BASED RELOCATIONIn the early days, before hardware support arose, some systems performed a crude form of relocation purely via software methods. The basic technique is referred to as static relocation, in which a piece of software known as the loader takes an executable that is about to be run and rewrites its addresses to the desired offset in physical memory.For example, if an instruction was a load from address 1000 into a register (e.g., movl 1000, %eax), and the address space of the program was loaded starting at address 3000 (and not 0, as the program thinks), the loader would rewrite the instruction to offset each address by 3000 (e.g., movl 4000, %eax). In this way, a simple static relocation of the process’s address space is achieved.However, static relocation has numerous problems. First and most importantly, it does not provide protection, as processes can generate bad addresses and thus illegally access other process’s or even OS memory; in general, hardware support is likely needed for true protection [WL+93]. Another negative is that once placed, it is difficult to later relocate an address space to another location TIP: HARDWARE-BASED DYNAMIC RELOCATIONWith dynamic relocation, a little hardware goes a long way. Namely, a base register is used to transform virtual addresses (generated by the program) into physical addresses. A bounds (or limit) register ensures that such addresses are within the confines of the address space. Together they provide a simple and efficient virtualization of memory. 栗子Example Translations 要更详细地了解基于base-and-bound的地址转换，我们来看个栗子。想象一下，地址空间大小为4KB(假设)的进程已在16KB的物理地址处加载。以下是许多地址转换的结果： 12345Virtual Address Physical Address0 → 16 KB1 KB → 17 KB3000 → 193844400 → Fault (out of bounds) 从示例中可以看到，您很容易将base address简单地添加到虚拟地址（可以正确地视为地址空间的偏移量）来获得最终的物理地址。仅当虚拟地址太大或负数时，结果才是错误，从而引发异常。 硬件支持：摘要Hardware Support： A Summary 现在让我们总结一下我们需要硬件的支持(图15-3)。首先，正如有关CPU虚拟化的章节所讨论的，我们需要两种不同的CPU模式。操作系统以特权模式(privileged mode)(内核模式 kernel mode)，在该模式下，它可以访问整个机器。应用程序在用户模式(user mode)模式下运行，在此模式下它们只能有限制的做些什么。A single bit指示CPU当前正在运行的模式。在某些特殊场合（如系统调用或其它类型的异常或中断），CPU会切换模式。 硬件还必须自己提供base and bounds registers。因此，每个CPU都有一对额外的寄存器，它们是CPU的内存管理单元(MMU)的一部分。当用户程序运行时，硬件将通过将base value添加到用户程序生成的虚拟地址中来转换每个地址。硬件还必须能够检查地址是否有效，这可以通过使用bounds register的CPU中的某些电路来实现。 硬件应提供特殊的指令来修改base and bounds registers，从而允许操作系统在运行不同进程时对其进行改变。这些指令是特权的(privilegegd)，仅在内核模式下才能修改寄存器。想象一下，如果用户进程在运行时可以任意修改base register，则会给用户造成严重破坏，则会给用户造成严重破坏。想象一下，多可怕呀！ 最后，CPU必须能够在某些情况下生成异常(exceptions)，如一个用户程序试图非法访问内存（地址超出边界）。在这种情况下，CPU应该停止执行用户程序，并安排操作系统运行 out of bounds exception handler。操作系统处理程序(OS Handler)可以弄清楚如何做出反应，在这种情况下，可能会终止进程。同样，如果用户程序尝试更改(privileged) base and bounds registers，则CPU应引发异常并运行在用户模式下的处理程序来执行一个特权操作。CPU还必须提供一种方法来通知这些处理程序(handler)的位置。因此，需要更多特权指令。 操作系统问题Operating System Issues 正如硬件提供了支持动态重定位的新功能一样，该操作系统现在也必须解决新问题。硬件支持和操作系统管理的结合导致实现简单的虚拟内存。具体而言，在一些关键时刻，操作系统必须介入以实现我们的虚拟内存的base-and-bounds。 首先，操作系统必须在创建进程时采取措施，在内存中为其地址空间找到空间。幸运的是，假设每个地址空间小于物理内存的大小，并且每个空间大小相同，这对操作系统而言很容易。它可以简单地讲武里内u你视为一组插槽，并跟踪每个插槽是空闲的还是正在使用的。创建新进程时，操作系统必须搜索数据结构（通常称为空闲列表），以找到用于新地址空间的空间，然后将其标记为已使用。对于可变大小的地址空间，会更复杂，在后面的章节中讲解。 看个栗子。在图15-2中，您可以看到操作系统本身使用了物理内存的第一个插槽，并且它已将上述示例中的进程重新定位到从32KB物理内存地址开始的插槽中。其它两个插槽是空闲的（16-32KB, 48-94KB）。因此，空闲列表(free list)应该包含这两个条目。 其次，操作系统必须在进程终止时（即，它正常退出或由于行为不当而被强制杀死）做一些工作，回收其所有内存以供其它进程或操作系统使用。进程终止后，操作系统将其内存存放回空闲列表，并根据需要清楚所有相关联的数据结构。 第三，当发生上下文切换时，操作系统还必须执行一些其它步骤。毕竟，每个CPU上只有一对base and bounds register，并且它们的值对于每个正在运行的程序都是不同的，因为每个程序都加载到内存中不同的物理地址。因此，操作系统必须在进程之间进行切换时恢复 base-and-bounds register 对。具体来说，当操作系统决定停止运行某个进程时，它必须以某些按进程的结构将 base-and-bounds registers 的值保存到内存中。如process structure or process control block(PCB)。同样，当操作系统恢复正在运行的进程时，它必须将CPU的 base and bounds 的值设置为该进程的正确值。 我们应该注意，当进程停止时(即未运行)时，操作系统可能很容易地将地址空间从内存中一个位置移动到另一个位置。要移动进程的地址空间，操作系统首先要对进程进行调度。然后，操作系统将地址空间从当前位置复制到新位置。最后，操作系统会更新已保存的base register（在进程结构中）以指向新位置。恢复该过程后，将恢复其(新的) base registers，并再次开始运行，而不必担心其指令和数据现在位于内存中的全新位置。 第四，操作系统必须提供异常处理(exception handler)，或要调用的功能，如上所述，操作系统会在引导时(boot time)（via privileged instructions）安装这些处理程序(handler)。例如，如果某个进程视图访问边界之外的内存，则CPU将引发异常。当一个异常抛出时，操作系统必须准备好采取措施。操作系统的普遍反应将会有敌意：它可能会终止恶意程序。草最系统应高度保护正在运行的计算机，因此，它对于尝试访问内存或执行不应执行的指令的进程没有帮助。再见，行为异常。 图15-5和图15-6说明了许多硬件/操作系统时间轴上的互动。第一个显示了操作系统在引导时为准备使用机器所做的工作，第二个显示了进程(A)开始运行时发生的情况。请注意，在没有操作系统干预的情况下，硬件如何处理其内存转换。咋某个时间点(第二图的中间)，发生了计时器中断，并且操作系统切换到进程B，该进程执行错误的加载(到非法内存地址)。到那时，操作系统必须参与进来，终止进程并通过释放B的内存并将其条目从进程表中删除来进行清理。 从图中可看出，我们仍然遵循有限直接执行(limited direct execution)的基本方法。在大多数情况下，操作系统只是适当地设置硬件，然后让进程直接在CPU上运行。仅当进程异常时，才必须介入操作系统。 总结Summary 在本章中，我们用虚拟内存中使用的一种称为地址转换的特定机制扩展了LDE(limited direct execution)的概念。通过地址转换，操作系统可以控制进程中的每个内存访问，从而确保访问保持在地址空间的范围内。这项技术效率的关键是硬件支持，它可以为每次访问执行转换，将虚拟地址（进程的内存视图）转换为物理地址（实际视图）。 所有这些都以对已重定位的进程以透明的方式执行。该进程不知道其内存引用正在被转换，从而产生一种奇妙的幻想。 我们还看到了一种特殊的虚拟化形式，称为 base and bounds 或 dynamic relocation。 它非常有效，因为只需要一点硬件逻辑就可以将 base register 添加到虚拟地址并检查进程生成的地址是否在在边界内。base and bounds同样提供保护，操作系统和硬件相结合，以确保没有进程可以在其自身的地址空间之外生成内存引用。保护无疑是操作系统最重要的目标之一。没有它，操作系统将无法控制机器（如果进程可以自由覆盖内存，则它们可以轻松地执行令人讨厌的事情，例如覆盖陷阱表并接管系统）。 不幸的是，这种简单的动态重定位技术确实没有效率。如，图15-2中所看到的，重定位的过程正在使用32-48KB的物理内存。但是，由于进程stack和heap不是太大，因此两者之间的所有空间都被浪费掉了。这种类型的浪费通常被称为内部碎片(internal fragmentation)，因为分配的单元的内部的空间并未全部用完（即碎片化, fragmented），因此被浪费了。在我们目前的方法中，尽管可能有足够的物理内存用于更多进程，但是我们目前仅限于将地址孔家放置在固定大小的插槽中，因此可能产生内部碎片。因此，我们将需要更复杂的机制，以尝试更好地利用物理内存并避免内部碎片。第一个尝试是对 base and bounds 进行细微的概括，即分段(segmentaion)，接下来将进行讨论。 分段Segmentation 到目前为止，我们已经将每个进程的整个地址空间都放在了内存中。借助 base and bounds registers，操作系统可以轻松地将进程重定位到物理内存的不同部分。但是，您可能已经注意到关于我们的这些地址空间的一些有趣之处：在 stack 和 heap 之间的中间有一大块空闲(free)空间。 从图16-1可以想象，虽然进程没有使用 stack 和 heap 之间的空间，但是当我们将整个地址空间重新放置在物理内存中的某个位置时，它仍在占用物理内存。因此，使用 base and bounds registers pair 来虚拟化内存的简单方法很浪费。当整个地址空间都无法容纳到内存中时，这也使得运行程序变得非常困难。因此， base and bounds 并不像我们所希望的那样灵活。 THE CRUX: HOW TO SUPPORT A LARGE ADDRESS SPACEHow do we support a large address space with (potentially) a lot of free space between the stack and the heap? Note that in our examples, with tiny (pretend) address spaces, the waste doesn’t seem too bad. Imagine, however, a 32-bit address space (4 GB in size); a typical program will only use megabytes of memory, but still would demand that the entire address space be resident in memory. Generalized Base/Bounds为了解决这个问题，一个想法诞生了。它被称为分段(segmentation)。这是一个很老的想法，至少可以追溯到1960年代。这个想法很简单：为什么在我们的MMU中不仅有一对 base and bounds pair，而且为什么地址空间的每个逻辑段(logical segment)都没有 base and bounds pair？段只是特定长度的地址空间的连续部分，在我们的规范地址空间中，我们具有三个逻辑上的不同的段： code, stack, heap。分段允许操作系统执行的操作是将这些分段中的每个分段放置在物理内存的不同部分中，从而避免用未使用的虚拟地址空间填充物理内存。 让我们看一个栗子。假设我们想将图16-1中的地址空间放入物理内存中。通过每个段的 base and bounds pair，我们可以将每个段独立地放置在物理内存中。例如，请参见图16-2。在那，您看到一个64KB的物理内存，其中有这三个段（并且为操作系统保留了16KB）。 从图中可以看出，只有已使用的内存才在物理内存中分配了空间，因此可以容纳具有大量未使用地址空间的大地址空间（有时称为稀疏地址空间(sparse address space)）。MMU中支持分段所需的硬件结构正是您所期望的：在这种情况下，一组三个 base and bounds register pairs。下图6-3显示了上面示例的寄存器值，每个边界寄存器保存段的大小。 从图中可以看到，代码段位于物理地址32KB，大小为2KB，heap segment位于34KB，大小为3KB。这里的段大小(size segment)与之前介绍的边界寄存器完全相同。它准确地告诉硬件该段中有多少字节有效（因此，使硬件能够确定程序何时在那些界限之外进行了非法访问）。 让我们使用图16-1中的地址空间进行示例转换。假定引用了虚拟地址100（位于代码段中，如图16-1中那样）。发生引用时（如，fetch指令），硬件会将base value添加到段的偏移量(offset)中（这里为100），以达到所需的物理地址：100+32KB(32768)（或32868）。它将检查该地址是否在范围之内（100小于2KB），找到该地址，然后发出对物理内存地址32868的引用。 现在让我们看一下堆中的一个地址，虚拟地址4200（图16-1）。如果仅将虚拟地址4200添加到heap的base（34KB），则会得到一个物理地址39016，这不是正确的物理地址。我们首先要做的是将偏移量(offset)提取到堆(heap)中，即地址指向该段中的哪个字节。因为heap从虚拟地址4KB(4096)开始，所以4200的偏移量实际上是4200减去4096（或104）。然后，我们将此偏移量添加到base register 物理地址(34K)中以获得所需的结果：34920。 如果我们试图引用一个超出堆末尾的非法地址（即7KB或更大的虚拟地址）怎么办？您可以想象会发生什么：硬件检测到地址超出范围，trap os，可能会终止违规进程。现在您知道了所有C程序员都学过的著名术语的起源：分段违规(segmentation violation)或分段错误(segmentation fault)。 ASIDE: THE SEGMENTATION FAULTThe term segmentation fault or violation arises from a memory access on a segmented machine to an illegal address. Humorously, the term persists, even on machines with no support for segmentation at all. Or not so humorously, if you can’t figure out why your code keeps faulting. 我们指的是哪个段Which Segment Are We Referring To? 硬件在转换期间使用段寄存器(segment registers)。它如何知道一个段的偏移量，以及地址指向哪个段？ 一种常见的方法（有时称为显式方法）是根据虚拟地址的前几位将地址空间划分为多个段。该技术一再VAX/VMS系统中使用。在上面的栗子中，我们有三个段。因此我们需要2bits来完成我们的任务。如果我们使用14-bit虚拟地址的前两位来选择段，我们的虚拟地址看起来如下： 然后，在我们的示例中。如果高两位为00，则硬件知道虚拟地址在代码段(code segment)中，因此使用 code base and bounds pair 来重新定位到正确的物理位置。如果高两位为01，则硬件知道地址在heap中，因此使用heap base and bounds。让我们以上面栗子的堆虚拟地址(4200)进行转换，以确保其清晰明了。虚拟地址4200的二进制形式如下： 从图中可看到，高两位(01)告诉硬件我们指的是哪个段。低12位是该段的偏移量（0000 0110 1000，十六进制0x068，或十进制104）。因此，硬件仅使用前两位来确定要使用的段寄存器，然后将接下来的12位用作段中的偏移量。通过将base register添加到offset，硬件达到最终的物理地址。请注意，偏移量也使边界检查(bounds check)变得很容易：我们可以简单地检查偏移量是否小于边界。因此，只需要检查偏移量是否小于边界即可。如果不是，则该地址是非法的。因此，如果base and bounds是数组（每段只有一个条目），则硬件将执行以下操作以获得所需的物理地址： 123456789// get top 2 bits of 14-bit VASegment = (VirtualAddress &amp; SEG_MASK) &gt;&gt; SEG_SHIFT// now get offsetOffset = VirtualAddress &amp; OFFSET_MASKif (Offset &gt;= Bounds[Segment]) RaiseException(PROTECTION_FAULT)else PhysAddr = Base[Segment] + Offset Register = AccessMemory(PhysAddr) 在我们运行的栗子中，我们可以填写上述上述常量的值。具体来说，将SEG MASK设置为0x3000，将SEG SHIFT设置为12，将OFFSET MASK设置为0xFFF。 您可能还注意到，当我们使用前两位时，并且只有三个段(code, heap, stack)，地址空间的一个段将不使用。为了充分利用虚拟地址空间（并避免使用未使用的段），某些系统将代码(code)与堆(heap)放在同一段中，因此仅使用一位(1bit)来选择要使用的段。使用顶部这么多的最高位来选择段的另一个问题是，它限制了虚拟地址空间的使用。具体来说，每个段都被限制为最大大小，在我们的示例中为4KB（使用前两位选择意味着16KB的地址空间被分成4部分，在本例中为4KB）。如果正在运行的程序希望将段(stack, heap)增加到该最大值意外，则该程序不走运。 硬件还有其它方法可以确定特定地址位于哪个段中。在隐式方法中，硬件通过地址的形成方式来确定段。例如，如果该地址是从程序计数器生成的(fetch指令)，则该地址在代码段内；如果该地址是基于 stack或base pointer，则它必须在stack segment中；其它地址都必须的heap segment中。 栈What About The Stack? 到目前为止，我们省略了地址空间的一个重要组成部分：栈(stack)。上图中，栈以重定位到物理地址28KB，但有一个关键的区别：它向后增长（即向较低的地址）。在物理内存中，它从28KB开始，然后增长回26KB，对应于16KB至14KB的虚拟地址。转换必须以不同的方式进行。 我们需要的第一件事是额外的硬件支持。硬件不仅需要base and bounds values，还需要知道段增长的方式（例如，当段向正方向增长时，将其设置为1，反之为0）。我们对硬件轨迹的更新视图如图16-4所示： 有了硬件的了解，即段可能会向负方向增长，因此硬件现在必须稍微转换这些虚拟地址。让我们以栈虚拟地址为例，并对其进行转换以了解该过程。在此栗子中，假设我们希望访问虚拟地址15KB，该地址映射到物理地址27KB。因此，我们的虚拟地址的二进制形式：11 1110 0000 0000（十六进制0x3C00）。硬件使用最高的两位(11)来指定段，但随后我们留下了3KB的偏移量。为了获取正确的负偏移，我们必须从3KB中减去最大的段大小：在此示例中，一个段可以为4KB，因此正确的负偏移为3KB - 4KB = -1KB。我们秩序将负偏移量(-1KB)加到基数(base)(28KB)即可得到正确的物理地址(27KB)。可以通过确保负偏移的绝对值小于等于段的当前大小(2KB)来计算边界检查。 支持分享Support for Sharing 随着对分段的支持的增加，系统设计人员很快意识到，只要多一点硬件支持，它们就可以实现新型的效率。具体来说，为了节省内存，有时在地址空间之间共享某些内存段很有用。特别是，代码共享(code sharing)是常见的，并且仍在当今的系统中使用。 为了支持共享，我们需要硬件以保护位(protection bits)的形式提供一些额外的支持。基本的支持在每个段上增加了几位，只是程序是否可以读取或写入段，或者执行段内的代码。通过将代码段设置为只读(read-only)，可在多个进程之间共享同一段代码，而不必担心隔离问题。尽管每个进程仍认为自己正在访问自己的私有内存，但操作系统秘密地共享了无法被进程修改的内存，因此保留了这种幻觉。 硬件和操作系统追踪的附加信息如图16-5所示。如您所见，代码段被设置为read和exe，因此内存中的同一物理段可以映射到多个虚拟空间。 使用保护位，先前描述的硬件算法将不得不更改。除了检查虚拟地址是否在范围之内，硬件还必须检查是否允许特定访问。如果用户进程尝试写入只读段或执行不可执行的段，则硬件应引发异常，从而让操作系统处理有问题的进程。 细粒度与粗粒度分段Fine-grained vs. Coarse-grained Segmentation 到目前为止，我们的大多数示例都集中在只有几个段(code, stack, heap)的系统上。我们可以认为这种分段是粗粒度(coarse-grained)的，因为它将地址空间切分为相对较大的粗块(coarse chunks)。但是，某些早期的系统更加灵活，并且允许地址空间由大量较小的段组成，称为细粒度分段(fine-grained segmentation)。 支持许多段需要进一步的硬件支持，并将某种类型的分段表(segmentation table)存储在内存中。这样的分段表通常支持创建大量的段，因此使系统能够以比我们目前为止讨论的方式更灵活的方式使用段。例如，诸如Burroughs B5000之类的早期机器就支持数千个段，并期望编译器将代码和数据分成单独的段，然后操作系统和硬件将支持这些段。当时的想法是，通过拥有细粒度的段，操作系统可以更好地了解正在使用的段以及哪些未使用的段，从而更有效地利用主内存。 操作系统支持OS Support 您现在应该对分段的工作原理有了一个基本的了解。随着系统的运行，许多片(pieces of)地址空间会重新放置到物理内存中。因此相对与我们的更简单的方法（整个地址空间只有一个base/bound对），可以节省大量的物理内存。具体来说，不需要在物理内存中分配分配stack和heap之间未使用的空间，这使我们将更多地址空间放入物理内存中，并为每个进程支持较大且稀疏的虚拟地址空间。 但是，分段为操作系统带来了许多新问题： 第一个是一个老问题：操作系统应该在上下文切换上做什么？您现在应该有一个很好的猜测：段寄存器必须保存(saved)和恢复(restored)。显然，每个进程都有自己的虚拟地址空间，操作系统必须确保正确设置这些寄存器，然后才能再次运行该进程。 第二个是当段增长时的操作系统交互(interaction)。例如，程序可以调用malloc()分配对象。在某些情况下，现有的堆将能够处理请求，因此malloc()将为对象找到可用空间，并将指向该对象的指针返回给调用者(caller)。但是，在其它情况下，heap segment本身可能需要增长。在这种情况下，内存分配库将执行系统调用以增长堆（如，传统的UNIX sbrk() 系统调用）。然后，操作系统将提供更多孔家，将segment size register更新为新的(bigger)大小，并通知库成功。然后，库可以为新对象分配空间，并成功返回到调用程序。请注意，如果没有更多的物理内存可用，或操作系统确定调用进程已经有太多内存，则操作系统可能会拒绝该请求。 最后，也许是最重要的问题是管理物理内存中的可用空间(free space)。创建新的地址空间时，操作系统必须能够在物理内存中为其segment找到空间。先前，我们假设每个地址空间的大小相同，因此可以将物理内存视为一堆插槽(slots)，其中可以容纳多个进程。现在，每个进程有多个段，每个段可能不同大小。 出现的一般问题是物理内存很快就充满了可用空间的小洞(little holes of free space)，这使得分配新段或扩展现有的段变得困难。我们将此问题称为外部碎片(external fragmentation)，如图16-6左边。 在该示例中，出现了一个进程，并希望分配20KB的段。此例中，有24KB的可用空间，但不是在一个连续的段中（而是在三个非连续的块中）。因此，操作系统无法满足20KB的请求。当增长段的请求到达时，可能会发生类似的问题。如果物理空间的下一个如此之多的字节不可用，则操作系统将不得不拒绝该请求，即使物理内存中其它位置可能有可用的字节。 解决此问题的一种方法是通过重新布置现有的段来压缩(compact)物理内存。例如，操作系统可以停止任何正在运行的进程，将其数据复制到内存的一个连续区域，更改其段寄存器值以指向新的物理位置，从而可以使用很大的可用内存空间。通过这样做，操作系统使新的分配请求成功。但是，压缩是很昂贵的。因为复制段(copying segments)占用大量内存，并且通常会占用大量的处理器时间。请参见图16-6右边以获取压缩物理内存的示意图。压缩还会使增加现有的段的请求难以满足，因此可能会导致进一步调整以适应此类请求。 相反，一种更简单的方法可能是使用空闲列表(free list)管理法，该算法视图使大量内存可用于分配人们实际上采用了数百种方法，包括经典算法，例如最佳拟合（保留最佳空间列表，并返回大小最接近的空闲空间，满足对请求者的期望分配），最不适合(worst-fit, first-fit)以及更复杂的方案，如伙伴算法(buddy algorithm)。不幸的是，尽管算法多么聪明，但外部碎片仍然存在。因此，好的算法只是试图将其最小化。 总结Summary 分段解决了许多问题，并帮助我们构建了更有效的内存虚拟化。除了动态重定位之外，分段还可以避免地址空间逻辑段之间潜在的巨大内存浪费，从而更好地支持稀疏地址空间。它很快，因为进行算术分段所需的操作很容易且非常适合硬件。转换的开销很小。附带的好处：代码共享。如果将代码放在单独的段中，则可能在多个正在运行的程序之间共享该段。 但是，据我们了解，在内存中分配大小可变的段会导致一些我们需要克服的问题。如上所述，第一个是外部碎片(external fragmentation)。因为段是可变的，所以空闲内存会被切成奇数大小的片段，因此很难满足内存分配请求。可以尝试使用智能算法或定期压缩内存，但是问题是根本的，很难避免。 第二个也许是更重要的问题是，分段仍然不够灵活，无法支持我们完全通用的稀疏地址空间。例如，如果我们在一个逻辑段中有一个大型但稀疏使用的堆，则整个堆仍必须驻留在内存中才能被访问。换句话说，如果我们关于地址空间使用方式的模型与底层分段的支持方式完全不匹配，那么分段就不能很好地工作。因此，我们需要找到一些新的解决方案。 空闲空间管理Free-Space Management 在本章中，我们从虚拟内存的讨论中走了一段弯路，以讨论任何内存管理系统的基本方面。无论是malloc库（管理进程堆的页面）还是操作系统本身（管理进程地址空间的各个部分）。具体来说，我们将讨论有关空闲空间管理(free memory management)的问题。 让我们使问题更具体。正如我们在讨论分页(paging)的概念时将看到的那样，管理可用空间肯定很容易。将要管理的空间划分为固定大小的单元很容易。在这种情况下，您只需保留这些固定大小单元的列表即可。当客户端请求其中一个时，返回第一个条目。 当您管理的空闲空间由大小可变的单元组成时，空闲空间管理会变得更加困难（有趣）。当使用分段实现虚拟内存时，这会在用户级(user level)内存分配库(memory allocation library)（如malloc()和free()）以及管理物理内存的操作系统中出现。无论哪种情况，存在的问题都称为外部碎片：空闲空间被切成不同大小的小碎片，因此碎片化。后续请求可能会失败，以为即使可用空间总量超过了请求的大小，也没有单个连续的空间可以满足请求。 该图显示了此问题的示例。在这种情况下，可用的总可用空间为20Byte。不幸的是，它被分为两个大小为10的块。结果，即使有20个可用字节，对15Byte的请求也将失败。因此，我们得出了本章要解决的问题。 CRUX: HOW TO MANAGE FREE SPACEHow should free space be managed, when satisfying variable-sized requests? What strategies can be used to minimize fragmentation? Whatare the time and space overheads of alternate approaches? 假设Assumptions 大部分讨论将集中于用户级内存分配库中分配器的悠久历史。 我们假定一个基本接口，如malloc()和free()提供的接口。具体来说，void * malloc(size)采用单个参数，即应用程序请求的字节数。它会将一个指针交还给该大小(或更大)的区域。互补例程void free(void *ptr获取一个指针并释放相应的块。注意接口的含义：用户在释放空间时不会将其大小通知库。因此，该库必须能够弄清楚仅将指针分配给它时有多大的内存量。本章稍后将讨论如何执行此操作。 该库管理的空间在历史上称为堆(heap)，用于管理堆中空闲空间的通用数据结构是某种空闲列表(free list)。此结构包含对内存的托管区域中所有空闲空间块的引用。淡然，此数据结构本身不必是列表，而只需某种数据结构即可追踪空闲空间。 如上所述，我们进一步假设我们主要关注于外部碎片(external fragmentation)。分配器当然也有可能存在内部碎片(internal fragmentation)的问题。如果分配器分发(hand out)的内存块大于请求的内存块，则此类中未分配(因此未使用)的空间将被视为内部碎片（因为浪费发生在分配的单元内部），这是空间浪费的另一个示例。但是，为了简单起见，并且由于它是两种碎片类型中比较有趣的一种，我们将主要关注外部碎片。 我们还将假设，一旦将内存交付给客户端，便无法将其重定位到内存中的其它位置。例如，如果程序调用malloc()并被赋予指向堆中某些空间的指针，则该内存区域实质上该程序拥有的（并且不能被库移动），直到该程序通过相应的free()将其返回为止。因此，不可能压缩空闲空间，这将有助于对抗碎片。但是，在实现分段时，可在操作系统中使用压缩来处理分段。 最后，我们假设分配器管理一个连续的字节区域。在某些情况下，分配器可以要求该区域增长。例如，用户级内存分配库可能会在内核空间不足时调用内核来扩大堆（如调用sbrk之类）。但是，为了简单起见，我们仅假设该区域在整个生命周期中都是一个固定的大小。 低级机制Low-level Mechanisms 在深入研究一些政策细节之前，我们将首先介绍大多数分配器中使用的一些常见机制。首先，我们将讨论拆分(splitting)和合并(coalescing)的基础知识，以及大多数分配器中的常用技术。其次，我们将展示如何快速轻松地追踪分配区域的大小。最后，我们将讨论如何在可用空间内构建一个简单列表，以追踪什么是空闲的以及什么不是。 拆分和合并Splitting and Coalescing 空闲列表包含了一组元素，这些元素描述了堆中仍剩余的可用空间。因此，假定以下30字节堆： 该堆的空闲列表上将包含两个元素。一个条目描述了前十个字节空闲段(Bytes 0-9)，一个条目描述了另一个空闲段(Bytes 20-29)。 如上所述，任何大于10字节的请求都将失败（返回NULL）。只有一个连续的大内存块不可用。任意一个空闲块都可以轻松满足对大小恰好为10字节的请求。但是，如果请求的内容小于十个字节，会发生什么呢？ 假设我们只请求一个字节的内存，在这种情况下，分配器将执行称为拆分(splitting)的操作：它将找到一个可以满足请求的空闲内存块，并将其拆分为两个。它的第一个块将返回给调用者，第二个块将保留在列表中。因此，在上面的示例中，如果请求了1Byte，并且分配器决定使用列表中的第二个元素来满足请求，则对malloc()的调用将返回20(1Byte的分配区域)，列表最终看起来像这样： 在图中，您可以看到列表基本保持不变。唯一的变化是，空闲区域现在从21开始，而不是20，并且该空闲区域的长度现在只有9。因此，当请求小于任何特定空闲块的大小时，拆分通常在分配器中使用。 在许多分配器中发现的推论机制被称为空闲空间合并(coalescing)。再次以上面的示例为例。给定这个heap，当应用程序调用free(10)并返回堆中间的空间时会发生什么？如果我们不加考虑就简单地将此可用空间添加会列表中，则最终可能会得到一个如下所示的列表： 注意此问题：虽然整个堆现在都是空闲的，但似乎将其分成三个块，每个块10个字节因此，如果用户请求20字节，则简单的列表遍历将找不到这样的空闲块，并返回失败。 为了避免此问题，分配器要做的是在释放一块内存时合并可用空间。这个想法很简单：在返回内存中的空闲块时，请仔细查看块的地址以及附近的空闲空间块。如果新释放的空间紧邻一个现有的空闲块，请将它们合并为一个等大的空闲块。因此，通过合并，我们的最终列表应如下表示： 确实，这是在进行任何分配之前首先出现的堆列表。通过合并，分配器可以更好地确保可以为应用程序提供较大的空闲扩展区。 追踪分配区域的大小Tracking The Size Of Allocated Regions 您可能已经注意到free(void *ptr)的接口没有采用size参数。因此，假设给定一个指针，malloc库可以快速确定要释放的内存区域的大小，从而将空间合并放回空闲列表。 为了完成此任务，大多数分配器将一些额外的信息存储在header block中，该header block通常在分配的内存块之前保留在内存中。让我们再来看一个栗子（图17-1）。此例中，我们正在检查分配的大小为20Bytes的块，由ptr指向。假设用户调用了malloc()并将结果存储在ptr中，如ptr=malloc(20)。 header至少包含分配的区域的大小（此例下为20）。它可能还包含其它用于加速释放(deallocation)的指针，用于提供其它完整性检查的幻数以及其它信息。让我们假设一个简单的header，其中包含区域的大小和一个魔幻数字，如下： 1234typedef struct &#123; int size; int magic;&#125; header_t; 上面的栗子看起来像图17-2所示。当用户调用free(ptr)时，该库将使用简单的指针算法找出header的起始位置： 123void free(void *ptr) &#123; header_t *hptr = (header_t *) ptr - 1; ... 在获得指向header的指标之后，库可以轻松地确定魔术数字是否与期望值匹配，作为健全性检查(assert(hptr-&gt;magic == 1234567))，并可以通过以下方式计算新释放区域的总大小：简单的数学运算（即，将header的大小添加到区域的大小）。请注意一个细节：空闲区域的大小是header的大小加上分配给用户的空间的大小。因此，当用户请求N个字节的内容时，库不搜索大小为N的空闲块，而实搜索大小为N加上header大小的空闲块。 嵌入空闲列表Embedding A Free List 到目前为止，我们已经将简单的空闲列表视为概念实体。它只是描述堆中可用内存块的列表。但是，我们如何在空闲空间本身中建立这样的列表呢？ 在一个更典型的列表中，当分配新节点时，仅在需要节点空间时才调用malloc()。不幸的是，在内存分配库中，您无法执行此操作！相反，您需要在可用空间本身内部(inside)构建列表。 假设我们要管理一个4096字节的内存块（即，堆为4KB）。为了将其作为空闲列表进行管理，我们首先必须初始化所述列表。最初，列表应具有一个条目，大小为4096（减去header大小）。这是列表节点的描述： 1234typedef struct __node_t &#123; int size; struct __node_t *next;&#125; node_t; 现在，让我们看一些代码。该代码初始化堆并将空闲列表的第一个元素放入该空间。我们假设堆是在铜鼓调用系统调用mmap()获得的一些可用空间内构建的。这不是构建此类堆的唯一方法，但在此示例中对我们有好处，代码： 12345// mmap() returns a pointer to a chunk of free spacenode_t *head = mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_ANON|MAP_PRIVATE, -1, 0);head-&gt;size = 4096 - sizeof(node_t);head-&gt;next = NULL; 运行此代码后，列表的状态是它只有一个条目，大小为4088。这是一个很小的堆，当为我们提供了一个很好的栗子。header 指针包含该范围的起始地址。假设它是16KB。因此，堆看起来如图17-3所示。 现在，让我们想象一下，请求了一块内存，大小为100Bytes。为了满足该请求，库将首先找到一个足够大的块以容纳该请求。因为只有一个空闲块(4088)，所以选择此块。然后，该块将分为两部分：一个足以满足请求的块，以及剩余的空闲块。假设header为8字节，则堆中的空间现在看起来如图17-4所示。 因此，在请求100字节时，库从现有的一个空闲块中分配了108个字节，并向其返回一个指针(ptr)，在分配的空间之前立即存储了header 信息，以便以后使用free()，并将列表中的一个空闲节点缩小到3980字节(4088-108)。 现在让我们看一下分配了三个区域，每个区域100字节（包括header是108）。此堆的可视化效果如图17-5所示： 如您所见，现在分配了堆的前324个字节，因此我们看到该空间中的三个header以及调用程序正在使用的三个100字节区域。空闲列表仍然没有意思：只有一个节点(指向header)，但是在三个分割之后，现在只有3764个字节。但是，当调用程序通过free()返回一些内存时会发生什么呢？ 在此示例中，应用程序通过调用free(16500)返回分配的内存的中间块。该值在上图中由指针sptr显示。 该库立即计算空闲区域的大小，然后将空闲块添加回空闲列表中。假设我们在空闲列表的开头插入，现在该空间看起来像图17-6所示： 现在，我们有了一个列表，该列表以一个小的可用块(100字节，由列表的开头指向)和一个较大的空闲块(3764字节)开始。最后，我们的清单上有多个要素。是的，空闲空间是零散的，这是不幸的但却是很常见的情况。 最后一个栗子：现在假设释放了最后两个使用中的块。没有合并，最终会产生碎片，如图17-7。 从图中可以看出，我们现在一团糟。为什么？很简单，我们忘记了合并列表。尽管所有内存都是空闲的，但它被切成碎片，因此尽管不是一个内存，但仍显示为碎片内存。解决方案很简单：遍历列表并合并相邻的块。完成后，堆将再次完整。 堆越来越大Growing The Heap 我们应该讨论在许多分配库找到的最后一种机制。具体来说，如果堆空间不足，该怎么办？最简单的方法就是失败(fail)。在某些情况下，这是唯一的选择，因此返回NULL是一种明智的方法。 大多数传统的分配器从小堆(small-sized)开始，然后在耗尽时从操作系统请求更多内存。通常，这意味着它们进行某种系统调用（如，在大多数UNIX系统中为sbrk）来增长堆，然后从那里分配新的块。 为了满足sbrk请求，操作系统找到了空闲的物理页面，将它们映射到请求进程的地址空间中，然后返回新堆结尾的值。此时，可以使用更大的堆，并且可以成功处理请求。 基本策略Basic Strategies 让我们再来看一些管理空闲空间的基本策略。这些方法主要基于您可以考虑的非常简单的策略。在阅读之前尝试一下，看看是否有所有其它选择。 理想的分配器既快速有可以最大程度地减少碎片。不幸的是，由于分配和释放请求的流(stream)可以是任意的（毕竟，它们由程序员确定），因此，如果输入设置错误，任何特定的策略都可能表现不佳。因此，我们将不描述最佳方法，而实讨论一些基础知识并讨论其优缺点。 最佳拟合(best fit) 最佳拟合的策略非常简单：首先，搜索空闲列表，找到大于请求大小的空闲内存块。然后，返回该组候选人中最小的一个。这就是所谓的最适合的块（也称为最小拟合）。遍历空闲列表就足以找到要返回的正确的块。 最佳拟合的直觉很简单：通过返回与用户请求接近的块，，最适合将尝试减少浪费的空间。但是，这是有代价的。幼稚的实现在对正确的空闲块进行详尽搜索时会付出沉重的性能损失。 最差拟合(worst fit) 最差拟合方法与最佳拟合相反。找到最大的块并返回请求的数量，将其余块保留在空闲列表中。因此，最差的拟合尝试使大块空闲，而不是由最佳拟合方法产生很多小块空闲。但是，再次需要完全搜索空闲空间，因此这种方法可能会很昂贵。大多数研究表明它的性能很差，导致碎片过多，同时开销仍然很高。 首先拟合(first fit) 首先拟合方法只是找到足够大的第一个块，然后将请求的量返回给用户。和以前一样，剩余的空闲空间将保留供后续请求使用。首次拟合具有速度优势——无需详尽搜索所有空闲空间，但有时会用小对象污染空闲列表的开头。因此，分配器如何管理空闲列表的顺序(order)成为一个问题。一种方法是使用基于地址的排序。通过使列表按空闲空间的地址排序，合并变得更加容易，并且碎片减少了。 下一个拟合(next fit) 下一个拟合算法不会始终在列表的开头开始首次拟合搜索，而实保留了指向列表中最后看的为止的额外指针。这个想法是将对空闲空间的搜索更均匀地分布在整个列表中，从而避免分散列表的开头。这种方法的性能与首次拟合非常相似，因此再次避免了详尽的搜索。 栗子 下面是上述策略的一些栗子。设想一个空闲列表，上面有三个元素，大小分别为10、30、20（在此我们将忽略head和其它详细信息，而只关注策略的运行方式）： 假设一个分配请求的大小为15。最佳拟合将搜索整个列表，并发现20是最适合的，因为它是可容纳请求的最小空闲空间。产生的空闲列表： 正如本例中所发生的，并且通常是采用最佳拟合的方法发生的，现在剩下了一个小的空闲块。最差拟合找到了最大的块，此例中为30。产生的空闲列表： 在此栗子中，最佳拟合和最差拟合执行相同的操作，还找到了可以满足请求的第一个空闲块。区别在于搜索成本。最佳拟合和最差拟合都在整个列表中浏览。首次拟合仅检查空闲块，直到找到合适的块，从而降低了搜索成本。 这些栗子只是分配策略的表面。为了更深入地了解，需要对实际工作负载和更复杂的分配器行为进行更详细的分析。 其余方法Other Approaches 除了上述基本方法外，还有许多建议的技术和算法可以通过某种方式改善内存分配。我们在这里列出一些供您考虑。 隔离列表(Segregated Lists) 一段时间以来，一种有趣的方法是使用隔离列表。基本思想很简单：如果一个特定的应用程序发出一个（或几个）流行大小(popular-sized)的请求，则保留一个单独的列表以管理该大小的对象。所有其它请求都转发到更通用的内存分配器。 这种方法的好处是显而易见的。通过拥有一块专用于一个特定大小的请求的内存，碎片问题就不再那么重要了。此外，当分配和免费请求的大小合适时，它们可以很快得到服务，因为不需要复杂的列表搜索。 就像其它好主意一样，这种方法也将新的复杂性引入到系统中。例如，与通用池(general pool)相比，一个专用于给定大小的专用请求的内存池应占用多少内存？一个特殊的分配器——slab分配器，以一种相当不错的方式来处理此问题。 具体来说，当内核启动时，它将为可能经常被请求的内核对象（如，lock, file-system inode…）分配许多对象缓存。因此，每个对象高速缓存都是给定大小的空闲列表，它们分别为内存分配和空闲请求提供服务。当给定的高速缓存的空闲空间不足时，它会从更通用的内存分配器中请求一些内存块(slabs of memory)（请求的总量为页面大小和相关对象的倍数）。相反，当给定slab中对象的引用技术全部变为零时，通用分配器可以从专用分配器中回收它们，这通常在VM系统需要更多内存时执行。slab分配器还将通过将列表上的空闲对象保持在预先初始化的状态而超越了大多数隔离列表的方法。初始化和销毁数据结构的成本很高。通过将特定列表中的释放对象保持在其初始化状态，slab分配器避免了每个对象的频繁初始化和销毁周期，从而显着降低了开销。 ASIDE: GREAT ENGINEERS ARE REALLY GREATEngineers like Jeff Bonwick (who not only wrote the slab allocator mentioned herein but also was the lead of an amazing file system, ZFS) are the heart of Silicon Valley. Behind almost any great product or technology is a human (or small group of humans) who are way above average in their talents, abilities, and dedication. As Mark Zuckerberg (of Facebook) says: “Someone who is exceptional in their role is not just a little better than someone who is pretty good. They are 100 times better.” This is why, still today, one or two people can start a company that changes the face of the world forever (think Google, Apple, or Facebook). Work hard and you might become such a “100x” person as well. Failing that, work with such a person; you’ll learn more in a day than most learn in a month. Failing that, feel sad. Buddy Allocation 因为合并对于分配器至关重要所以围绕简化合并设计了一些方法。在binary buddy allocator中找到了一个很好的栗子。在这样的系统中，首先从概念上将空闲内存视为大小为2^N的一个大空间。发出请求后，对可用空间的搜索将可用空间递归地除以2，直到找到一个足够大的块来容纳该请求。此时，所请求的块将返回给用户。这是一个在搜索7KB时划分64KB可用空间的栗子，如图17-8： 在该示例中，分配了最左边的8KB块并返回给用户。请注意，此方案可能会遭受内部碎片的困扰，因为只允许您给出2的幂次方的块。buddy allocation的美妙之处在于释放该块时会发生什么。当将8KB块返回到空闲列表时，分配器检查buddy 8KB是否空闲。如果空闲，它将两个块合并为一个16KB的块。然后，分配器检查16KB的buddy是否仍然空闲。如果是，它将合并这两个块。该递归合并过程在树上继续进行，恢复了整个可用空间，或者发现buddy正在使用时停止。 buddy allocation之所以有效的原因是，确定特定块的buddy很简单。考虑上面的可用空间中块的地址。如果您仔细考虑，就会发现每个buddy pair的地址仅仅相差一位(a single bit)。因此，您对binary buddy allocation方案的工作原理有基本了解。 *其它想法(Other Ideas)* 上述许多方法的一个主要原因是它们缺乏伸缩性(scaling)。具体来说，搜索列表可能会非常慢。因此，高级分配器使用更复杂的数据结构来解决这些成本，从而简化性能。栗子包括平衡二叉树(balanced binary trees)、八叉树(splay trees)、部分有序树(partially-ordered trees)。 鉴于现代系统通常具有多个处理器并运行多线程工作负载，因此，在基于多处理器的系统上，花费了大量的精力使分配器正常工作也就不足为奇了 。 总结在本章中，我们讨论了最基本的内存分配形式。这样的分配器无处不在，它链接到您编写的每个C程序，也存在于底层操作系统中，该操作系统为自己的数据结构管理内存。与许多系统一样，在构建这样的系统时需要进行很多权衡，并且您对分配给分配器的确切工作量了解的越多，您就可以做的越多，就需要对其进行调整以使其更好地适应该工作量。在现代计算机系统中，制造一种快速、节省空间、可扩展的分配器，使其能够很好地适用于各种工作负载，仍然是一个持续的挑战。 分页Paging 有时候，在解决大多数空间管理问题时，操作系统会采用两种方法之一。第一种方法是将事物切成大小可变(variable-sized)的段，如我们在虚拟内存中的分段所见。不幸的是，该解决方案具有固定的困难。特别是，将空间分成不同大小的块时，空间本身可能会变得碎片化，因此随着时间的推移分配会变得更具有挑战性。 因此，可能值得考虑第二种方法：将空间切成固定大小(fixed-sized)的片。在虚拟内存中，我们称这种想法为分页(paging)，它可以追溯到早期的重要系统Atlas。我们没有将进程的地址空间划分为一些可变大小的逻辑段（如，代码、堆、栈），而是将其划分为固定大小的单元，每个单元成为一个页面(page)。相应地，我们将物理内存视为固定大小的插槽数组，称为页帧(page frame)。这些帧中的每一个都可以包含一个虚拟内存页面(virtual memory page)。我们的挑战: HOW TO VIRTUALIZE MEMORY WITH PAGESHow can we virtualize memory with pages, so as to avoid the problems of segmentation? What are the basic techniques? How do we make those techniques work well, with minimal space and time overheads? 栗子和概述A Simple Example And Overview 为了使这种方法更清晰，让我们以一个简单的栗子进行说明。图18-2提供了一个很小的地址空间的栗子，该地址空间的总大小仅为64字节，具有四个16字节的页面（虚拟页面0、1、2、3）。当然，实际的地址空间要大得多，通常是32位(4GB)，甚至64位的地址空间。 如图18-2所示，物理内存由多个大小固定的插槽组成，在这种情况下位八个页面帧(page frame)（用于128字节的物理内存）。如图所示，虚拟地址空间的页面已放置在整个物理内存中的不同位置。该图还显示了操作系统本身使用了一些物理内存。 分页与以前的方法相比具有许多优点。可能最重要的改进是灵活性：通过完全开发的分页方法，该系统将能够有效地支持地址空间的抽象性，而与进程如何使用地址空间无关。 另一个优点是分页提供的空闲空间管理的简单性。例如，当操作系统希望将我们的64字节地址空间放入我们的八个页面物理内存时，它只会找到四个空闲页。也许操作系统为此保留了所有空闲页面的空闲列表，而只是从该列表中获取了前四个空闲页面。在此例中，操作系统将地址空间(AS)的虚拟页面0(page 0)放置在物理页帧3(page frame 3)中…页面帧4和6当前时空闲的。 为了记录地址空间的每个虚拟页在物理内存中的放置位置，操作系统通常保留每个进程的数据结构——称为分页表(page table)。分页表的主要作用是为地址空间的每个虚拟页面存储地址转换。对于我们的栗子，分页表将具有一下四个条目: virtual page 0 -&gt; physical frame 3 vp 1 -&gt; pf 7 vp 2 -&gt; pf 5 vp 3 -&gt; pf 2 重要的是要记住，此分页表是按进程的数据结构。如果在上面的示例中要运行其它进程，则操作系统将不得不为其管理一个不同的分页表，因为其虚拟页面显然映射到了不同的物理页面。 让我们想象一下，地址空间很小(64Bytes)的进程正在执行内存访问：movl &lt;virtual address&gt;, %eax 具体来说，我们要注意将地址 virtual address 中的数据显式加载到寄存器eax中。 为了转换该进程生成的虚拟地址，我们必须首先将其分为两个部分： virtual page number(VPN) page offset 对于此栗子，由于进程的虚拟地址空间为64字节，因此我们总共需要6位虚拟地址(2^6=64)。因此，可将我们的虚拟地址概念化： 在图中，Va5是虚拟地址的最高位，而Va0是虚拟地址的最低位。因为我们知道页面大小(16Bytes)，所以我们可以进一步划分地址。如下： 在64字节的地址空间中，页面大小为16字节。因此，我们需要能够选择4个页面，并且地址的高两位就可以做到这一点。因此，我们有一个两位虚拟页码(vpn)。其余的位告诉我们页面的字节，在这种情况下为4位。我们称其为偏移量(offset)。 当进程生成虚拟地址时，操作系统和硬件必须结合起来才能将其转换为有意义的物理地址。例如，让我们假设上面的负载是虚拟地址21：movl 21, %eax 将21转换为二进制格式(010101)，因此我们可以检查该虚拟地址，并查看它如何分解为虚拟页码和偏移量： 因此，虚拟地址21在虚拟页面(01)的第五个字节上(0101)。使用虚拟页码，我们现在可以索引我们的分页表并找到虚拟页面1(vp 1)驻留在哪个物理帧页中。在上面的分页表中，物理帧码(physical frame number, PFN)，有时又称为物理页面号(physical page numer, PPN)是7(pf 7, 二进制111)。因此，我们可以通过PFN替换VPN来转换此虚拟地址，然后将负载发布到物理内存。如图18-3。 请注意，偏移量保持不变（即，不进行转换），因为偏移量仅告诉我们所需页面中的哪个字节。我们的最终物理地址为1110101（十进制117），正是我们希望从中获取数据的位置，如图18-2。 考虑到这一基本概述，我们现在可以问有关分页的一些基本问题。例如，这些分页表存储在哪里？分页表的典型内容是什么，有多大？分页会使系统变慢吗？ 分页表存储在哪里Where Are Page Tables Stored? 分页表(page table)会变得非常大，比我们之前讨论的小段(small segment)或base/bound pair要大得多。例如，设想一个典型的32位地址空间，4KB pages。该虚拟地址分为20位VPN和12位偏移量。 20位VPN表示操作系统必须为每个进程管理2^20个转换，假设每个分页表条目(page table entry)需要4字节来保存物理转换以及其它任何有用的东西，我们将为每个分页表获得4MB的巨大内存。那是很大的，现在想象有100个进程正在运行：这意味这操作系统仅需要所有这些地址转换就需要400MB内存！即使在机器拥有GB内存的现代时代，将很大一部分内存用于翻译也似乎有些疯狂，不是吗？而且，我们甚至都不会考虑这样的分页表对于64位地址空间会有多大。那太可怕了，也许会把你吓跑。 由于分页表非常大，因此我们不在MMU中保留任何特殊的片上硬件来存储当前正在运行的进程的分页表。相反，我们将每个进程的分页表存储在内存中的某个位置。现在假设分页表位于操作系统管理的物理内存中。稍后我们将看到许多操作系统内存本身可以被虚拟化，因此分页表可以存储在操作系统虚拟内存中（甚至交换到磁盘上），但是现在这太令人困惑了，因此我们将其忽略。图18-4中显示了操作系统内存中的分页表，在那看到很小的转换集。 ASIDE: DATA STRUCTURE — THE PAGE TABLEOne of the most important data structures in the memory management subsystem of a modern OS is the page table. In general, a page table stores virtual-to-physical address translations, thus letting the system know where each page of an address space actually resides in physical memory. Because each address space requires such translations, in general there is one page table per process in the system. The exact structure of the page table is either determined by the hardware (older systems) or can be more flexibly managed by the OS (modern systems). 分页表中实际上是什么？What’s Actually In The Page Table? 让我们谈谈分页表的组织方式。分页表只是一个数据结构，用于将虚拟地址(virtual page number)映射到物理地址(physical frame number)。因此，任何数据结构都可以工作。最简单的形式称为线性分页表(linear page table)，它只是一个数组。操作系统通过虚拟页码(vpn)位阵列建立索引(index)，并在该索引处查找分页表条目(pte)，以查找所需的物理帧号(pfn)。现在，我们将假定这种简单的线性结构。在后面的章节中，我们将使用更高级的数据结构来帮助解决分页中的某些问题。 至于每个pte的内容，我们在中有许多不同的地方值得一定程度的理解。有效位(valid bit)是通用的，用于指示特定转换是否有效。例如，当程序开始运行时，它将在其地址空间的一端具有代码和堆，而在另一端则具有栈。两者之间所有未使用的空间将被标记为无效(invalid)，并且如果该进程尝试访问此类内存，它将生成操作系统陷阱(trap)，这很可能会终止该进程。因此，有效位对于支持稀疏地址空间至关重要。通过简单地将地址空间中所有未使用的页面标记为无效，我们无需为这些页面分配物理帧，从而节省了大量内存。 我们还可能有保护位(protection bits)，指示是否可以读取、写入或执行页面。同样，以这些位不允许的方式访问页面将产生对操作系统的陷阱。 还有其它一些重要的方面，但我们暂时不会多谈。当前位(present bit)指示页面是在物理内存中还是在磁盘上(swapped out)。当我们研究如何将部分地址空间交换(swap)到磁盘以支持大于物理内存的地址空间时，我们将进一步理解这种机制。交换(swapping)使操作系统可以通过将很少使用的页面移动到磁盘来释放物理内存。脏位(dirty bit)也很常见，指示该页从进入内存以来是否已被修改。 引用位(reference bit, accessed bit)来跟踪页面是否已被访问，并且对于确定哪些页面受欢迎并因此应将其保留在内存中很有用。此类知识在页面替换期间至关重要，我们将在随后的章节中详细研究该主题。 图18-5显示了x86体系结构中的示例分页表条目(pte)。它包含： present bit(P)； read/write bit(R/W)，是否允许对该页面进行写操作； user/supervisor bit(U/S)，用于确定用户模式进程是否可以访问该页面； 一些位(PWT, PCD, PAT, G)确确定这些页面的硬件缓存工作方式； accessed bit(A)； dirty bit(D)； page frame number(PFN)； ASIDE: WHY NO VALID BIT?You may notice that in the Intel example, there are no separate valid and present bits, but rather just a present bit (P). If that bit is set (P=1), it means the page is both present and valid. If not (P=0), it means that the page may not be present in memory (but is valid), or may not be valid. An access to a page with P=0 will trigger a trap to the OS; the OS must then use additional structures it keeps to determine whether the page is valid (and thus perhaps should be swapped back in) or not (and thus the program is attempting to access memory illegally). This sort of judiciousness is common in hardware, which often just provide the minimal set of features upon which the OS can build a full service. 分页: 也很慢Paging: Also Too Slow 内存中的分页表，我们已经知道它们可能太大。事实证明，它们也可以放慢脚步。例如，采用简单的指令：movl 21, %eax 同样，让我们仅检查对地址21的显式引用，而不用担心指令提取(fetch)。此例中，我们假设硬件为我们执行转换。为了获取所需数据，系统必须首先将虚拟地址(21)转换为正确的物理地址(117)。因此，在从地址117提取数据之前，系统必须首先从进程的分页表中提取适当的页表项(page table entry)，执行转换，然后从物理内存中加载数据。 为此，硬件必须知道当前正在运行的进程的分页表所在的位置。现在让我们假设一个page table base register包含分页表起始位置的物理地址。为了找到所需PTE的位置，硬件将执行以下功能： 12VPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFTPTEAddr = PageTableBaseRegister + (VPN * sizeof(PTE)) 在我们的栗子中，VPN_MASK将设置为0x30，这将从完整的虚拟地址中提取VPN位。SHIFT设置为4（偏移量中的位数），以便我们将VPN位向下移动以形成正确的整数虚拟页码。例如，使用虚拟地址21(010101)，并通过mask将其值转换为010000；转换后可根据需要将其转换为01或virtual page 1。然后，我们将此值用作page table base register指向的分页表条目(pte)数组的索引。 一旦知道了该物理地址，硬件就可以从内存中获取PTE，提取PFN，并将其与虚拟地址的偏移量连接起来以形成所需要的物理地址。具体来说，您可以考虑将PFN通过SHIFT左移，然后将其与偏移量按位或操作(OR)，以形成最终地址。 12offset = VirtualAddress &amp; OFFSET_MASKPhysAddr = (PFN &lt;&lt; SHIFT) | offset 最后，硬件可以从内存中获取所需的数据，并将其放入寄存器eax中。该程序现在以成功从内存中加载值！ 总而言之，我们现在描述每个内存引用上发生的事情的初始协议。对于每个内存引用（无论是获取指令还是显式加载或存储），分页都要求我们执行一个额外的内存引用，以便首先从分页表中获取转换。那是很多工作！额外的内存引用成本很高，在这种情况下，可能会使处理速度减慢两倍或更多。 12345678910111213141516171819202122// Accessing Memory With Paging// Extract the VPN from the virtual addressVPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFT// Form the address of the page-table entry (PTE)PTEAddr = PTBR + (VPN * sizeof(PTE))// Fetch the PTEPTE = AccessMemory(PTEAddr)// Check if process can access the pageif (PTE.Valid == False) RaiseException(SEGMENTATION_FAULT)else if (CanAccess(PTE.ProtectBits) == False) RaiseException(PROTECTION_FAULT)else // Access is OK: form physical address and fetch it offset = VirtualAddress &amp; OFFSET_MASK PhysAddr = (PTE.PFN &lt;&lt; PFN_SHIFT) | offset Register = AccessMemory(PhysAddr) 现在您可以看到有两个必须解决的实际问题。没有对硬件和软件进行仔细设计，分页表将导致系统运行太慢，并占用太多内存。虽然这似乎是满足我们的内存虚拟化需求的绝佳解决方案，但必须首先克服这两个关键问题。 内存追踪A Memory Trace 在结束之前，我们现在追踪(trace)一个简单的内存访问示例，以演示使用分页时内存访问发生的所有的结果。示例代码片段(array.c文件)如下： 123456789int array[1000];...for (i = 0; i &lt; 1000; i++) array[i] = 0;//&gt; 编译// gcc -o array array.c -Wall -O// 执行// ./array 当然，要真正访问此代码段（只需初始化一个数组）的内存，我们就必须知道几件事。首先，我们必须对生成的二进制文件进行反汇编(disassemble)（在Linux上使用objdump，Mac上使用otool），以查看使用哪些汇编指令在循环中初始化数组。如下是生成的汇编代码： 12341024 movl $0x0,(%edi,%eax,4)1028 incl %eax1032 cmpl $0x03e8,%eax1036 jne 0x1024 如果了解一些x86的知识，则实际上很容易理解此代码。第一条指令将值0移至数组位置的虚拟内存地址。该地址通过将%edi的内容加上%eax乘4得出。因此，%edi保存数据的基地址，而%eax保存数组index(i)。将其乘4，因为该数组是一个整数数组，每个数组的大小为四字节。 第二条指令递增%eax中保存的数组索引。第三条指令将寄存器的内容与十六进制值0x03e8，或十进制1000进行比较。如果比较显示两个值还不相等(jne指令测试)，则第四条指令跳回循环的顶部。 为了了解该指令序列访问哪个内存（虚拟和物理级别上），我们必须假设一些有关代码片段和数组在虚拟内存中的位置以及分页表的内容和位置的信息。 对于此示例，我们假定虚拟地址空间的大小为64KB，我们还假定页面大小为1KB。现在我们只需要知道分页表的内容及其在物理内存中的位置。假设我们有一个基于数组的线性分页表，它位于物理地址1KB。至于它的内容，我们需要担心的几个虚拟页面，已经为此栗子映射了。首先，代码所在的虚拟页面。因为页面大小为1KB，所以虚拟地址1024位于虚拟地址空间的第二个页面上。假设此虚拟页面映射到物理帧4（vpn 1 -&gt; pfn 4)。 接下来，是数组本身。它的大小为4000字节(1000个整数)，我们假定它位于40000到44000的虚拟地址。此范围的虚拟页面为vpn=39…42。因此，我们需要这些页面的映射。如： vpn 39 -&gt; pfn 7 vpn 40 -&gt; pfn 8 vpn 41 -&gt; pfn 9 vpn 42 -&gt; pfn 10 现在，我们准备追踪程序的内存引用。在运行时，每条fetch指令将生成两个内存引用：一个指向分页表以查找指令所在的物理帧，另一个指向指令本身以将其提取给CPU以进行处理。另外，有一个以mov执行形式的显式内存引用。这将首先添加另一个分页表访问，然后添加阵列本身。 图18-7描述了前五个循环迭代的整个过程。 总结Summary 我们介绍了分页(paging)的概念，以解决我们虚拟化内存的挑战。与以前的方法（如，分段）相比，分页具有许多优点。首先，它不会导致外部碎片，因为分页将内存划分为固定大小的单元。其次，它非常灵活，可以稀疏地使用虚拟地址空间。 但是，不加注意地实现分页支持将导致机器速度变慢（具有许多额外的内存访问权限来访问分页表），以及内存浪费（内存被分页表填充，而不是有用的应用程序数据）。因此，我们将不得不更加努力地想出一种不仅可以工作而且很好运行的分页系统。幸运的是，接下来的两章将向我们展示如何做到这一点。 地址转换缓存Paging: Faster Translations (TLBs) Translation Lookaside Buffer 使用分页作为支持虚拟内存的核心机制可能会导致高性能开销。通过将地址空间切成固定大小的小单元(即，页面)，分页需要打两个的映射信息。因为映射信息通常存储在物理内存中，所以分页逻辑上需要对程序生成的每个虚拟地址进行额外的内存查找。在每条fetch指令或显示加载或存储之前进入内存获取转换信息的速度过慢。因此，我们的问题是： HOW TO SPEED UP ADDRESS TRANSLATIONHow can we speed up address translation, and generally avoid the extra memory reference that paging seems to require? What hardware support is required? What OS involvement is needed? 当我们想要加快速度时，操作系统通常需要一些帮助。而且帮助通常来自操作系统的老朋友：硬件。为了加快地址转换的速度，我们将添加所谓的转换后备缓冲器(translation lookaside buffer, TLB)。TLB是内存管理单元(MMU)的一部分，并且只是流行的虚拟到物理地址转换的一个硬件缓存。因此，更好的名称是地址转换缓存(address translation cache)。在引用每个虚拟内存时，硬件首先检查TLB。如果是，执行转换(快速地)而无需查阅分页表。由于它们对性能的巨大影响，真正意义上的TLB使虚拟内存成为可能。 TLB基本算法TLB Basic Algorithm 12345678910111213141516171819202122// TLB Control Flow AlgorithmVPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFT (Success, TlbEntry) = TLB_Lookup(VPN) if (Success == True) // TLB Hit if (CanAccess(TlbEntry.ProtectBits) == True) Offset = VirtualAddress &amp; OFFSET_MASK PhysAddr = (TlbEntry.PFN &lt;&lt; SHIFT) | Offset Register = AccessMemory(PhysAddr) else RaiseException(PROTECTION_FAULT) else // TLB Miss PTEAddr = PTBR + (VPN * sizeof(PTE)) PTE = AccessMemory(PTEAddr) if (PTE.Valid == False) RaiseException(SEGMENTATION_FAULT) else if (CanAccess(PTE.ProtectBits) == False) RaiseException(PROTECTION_FAULT) else TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits) RetryInstruction() 以上给出了硬件如何处理虚拟地址转换的示意图，假设有一个简单的线性分页表和由硬件管理的TLB（即，硬件承担了分页表访问的大部分责任）。硬件遵循的算法是这样的：首先，从虚拟地址中提取虚拟页码(vpn)，然后检查TLB是否有该vpn的转换。如果是，我们将获得一个TLB命中，这意味着TLB将保留转换。成功！现在，我们可以从相关的TLB条目中提取页帧号(pfn)，并将其连接到与原始虚拟地址的偏移量上，并形成所需的物理地址(pa)和访问内存，假设保护检查不会失败。 如果CPU在TLB中找不到转换(TLB miss)，我们还有更多工作要做。在此栗子中，硬件访问分页表以查找转换，并且假设该进程生成的虚拟内存引用是有效且可访问的，则使用此转换来更新TLB。这些操作的成本很高，主要是因为访问分页表需要额外的内存引用。最后，一旦更新了TLB，硬件将重新尝试该指令。这次，可在TLB中找到转换，并且可以快速地处理内存引用。 像所有高速缓存一样，TLB的构建前提是在通常情况下，在高速缓存中找到转换（即，命中(hit)）。如果是这样，则几乎不会增加任何开销，因为TLB位于处理核心附近，并且设计得非常快。发生未命中(miss)时，会产生很高的分页成本。必须访问分页表以查找转换，并获得额外的内存引用（更复杂的分页表则需要更多的内存引用）。如果这种情况经常发生，则程序运行速度可能会明显变慢。相对于大多数CPU指令，内存访问成本很高，而且TLB丢失会导致更多的内存访问。因此，我们希望尽可能避免TLB未命中。 访问数组的栗子Example: Accessing An Array 为了清楚说明TLB的操作，让我们检查一个简单的虚拟地址追踪，看看TLB如何改善其性能。在此例中，假设内存中有一个10个4字节整数的数组，从虚拟地址100开始。进一步假设我们有一个小的16位页面和8位虚拟地址空间。因此，虚拟地址分为4位vpn(16 virtual pages)和4位偏移量。 图19-2显示了排列在系统的16个16字节页面上的数组。如您所见，数组的第一个条目a[0]开始于(vpn=06, offset=04)。该页面上只能容纳三个4字节整数。数组继续到下一页(vpn=07)，在此找到下四个条目(a[3]..a[6])。下面也是如此。 现在，让我们考虑一个访问每个数组元素的简单循环，在C中看起来如下： 1234567int sum = 0;for (i = 0; i &lt; 10; i++) &#123; sum += a[i];&#125;//&gt; 为了简单起见，我们将假装循环生成的唯一内存访问是对数组的访问。当访问第一个数组元素(a[0])时，CPU将看到虚拟地址100的负载。硬件从中提取vpn，并使用该地址检查TLB的有效转换。假设这是程序第一次访问数组，结果将是TLB丢失(miss)。 下一步访问(a[1])，这里有一些好消息：TLB命中！由于数组的第二个元素紧挨着第一个元素，因此它位于同一个页上。因为我们在访问数组的第一个元素时已经刚问了此页面，所以转换已经加载到了TLB中。这是我们成功的原因。访问(a[2])会遇到类似的成功，因为它与(a[0])和(a[1])位于同一页面上。 不幸的是，当程序访问(a[3])时，我们遇到了另一个TLB丢失。但是，下一个条目(a[4]..a[6])将再次位于TLB中，因为它们都位于内存中的同一个页上。 最后，访问(a[7])会导致最后一个TLB丢失。硬件再次查询分页表以找出该虚拟分页在物理内存中的位置，并相应地更新TLB。最后两个访问(a[8], a[9])将获得此TLB更新的好处。当硬件在TLB中查找其转换时，又产生了两次命中。 让我们总结一下对数组的十次访问期间的TLB活动：miss, hit, hit, miss, hit, hit, hit, miss, hit, hit。因此，我们的TLB命中率为70%（实际上，我们希望命中率接近百分百）。即使这是程序第一次访问数组，TLB仍会由于空间位置而提高性能。数组的元素紧密地包装在页面中（即，它们在空间上彼此靠近），因此只有第一次访问页面上的元素才会产生TLB丢失。 还要注意在此栗子中页面大小的作用。如果页面大小是原来的两倍，则数组访问将遭受更小的丢失。由于典型的页面大小更像是4KB，因此这些类型的密集，基于数组的访问可实现出色的TLB性能，每页访问仅遇到一次丢失。 关于TLB性能的最后一点：如果程序在此循环完成后不久再次访问了数组，则假设我们有足够大的TLB来缓存所需的转换，那么我们可能会看到更好的结果: hit, hit, hit, hit, hit, hit, hit, hit, hit, hit。在这种情况下，由于时间上的局限性，即时间上的内存项快速重新引用，TLB命中率很高。像任何高速缓存(cache)一样，TLB依赖于空间和时间的局部性来获得成功，这是程序属性。如果感兴趣的程序表现出这种局限性，则TLB的命中率可能会很高。 TIP: USE CACHING WHEN POSSIBLECaching is one of the most fundamental performance techniques in computer systems, one that is used again and again to make the “commoncase fast” [HP06]. The idea behind hardware caches is to take advantage of locality in instruction and data references. There are usually two types of locality: temporal locality and spatial locality. With temporal locality, the idea is that an instruction or data item that has been recently accessed will likely be re-accessed soon in the future. Think of loop variables or instructions in a loop; they are accessed repeatedly over time. With spatial locality, the idea is that if a program accesses memory at address x, it will likely soon access memory near x. Imagine here streaming through an array of some kind, accessing one element and then the next. Of course, these properties depend on the exact nature of the program, and thus are not hard-and-fast laws but more like rules of thumb. Hardware caches, whether for instructions, data, or address translations (as in our TLB) take advantage of locality by keeping copies of memory in small, fast on-chip memory. Instead of having to go to a (slow) memory to satisfy a request, the processor can first check if a nearby copy exists in a cache; if it does, the processor can access it quickly (i.e., in a few CPU cycles) and avoid spending the costly time it takes to access memory (many nanoseconds).You might be wondering: if caches (like the TLB) are so great, why don’t we just make bigger caches and keep all of our data in them? Unfortunately, this is where we run into more fundamental laws like those of physics. If you want a fast cache, it has to be small, as issues like the speed-of-light and other physical constraints become relevant. Any large cache by definition is slow, and thus defeats the purpose. Thus, we are stuck with small, fast caches; the question that remains is how to best use them to improve performance. 谁处理TLB缺失Who Handles The TLB Miss? 我们必须回答一个问题：谁处理TLB缺失？可能有两个答案：硬件或软件。 在过去，硬件具有复杂的指令集(complex instruction sets)（对于复杂指令集计算机，称为CISC），而构建硬件的人并不十分信任那些狡猾的操作系统用户。因此，硬件将完全处理TLB丢失。为此，硬件必须准确地知道分页表在内存中的位置（使用 page table base register），以及它们的确切格式。如果丢失，则硬件将遍历(walk)分页表，找到正确的分页表条目并提取所需的转换并更新TLB，然后重试指令。硬件管理的TLB的旧架构的一个示例是Intel x86架构，该架构使用固定的多级页表。 更加现代的架构（如，精简指令集计算机(reduced instruction set computers, RISC)）都具有所谓的软件管理的TLB。在发生TLB丢失时，硬件仅引发异常（如下代码），该异常将暂停当前指令流(instruction stream)，将权限级别提升至内核模式，然后跳转至陷阱处理程序(trap handler)。您可能会猜测，此陷阱处理程序是操作系统中的代码，其明确目的是处理TLB丢失。当它运行时，代码将在分页表中查找转换，使用特殊的特权指令(privileged instruction)更新TLB，然后从陷阱返回。此时，硬件重试指令（TLB将命中）。 1234567891011121314// TLB Control Flow Algorithm (OS Handled)VPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFT (Success, TlbEntry) = TLB_Lookup(VPN) if (Success == True) // TLB Hit if (CanAccess(TlbEntry.ProtectBits) == True) Offset = VirtualAddress &amp; OFFSET_MASK PhysAddr = (TlbEntry.PFN &lt;&lt; SHIFT) | Offset Register = AccessMemory(PhysAddr) else RaiseException(PROTECTION_FAULT) else // TLB Miss RaiseException(TLB_MISS) //上面的引发异常 让我们讨论几个重要的细节。首先，从陷阱返回(return-from-trap)指令与我们在为系统调用提供服务之前所看到的从陷阱返回指令稍有不同。在后一种情况下，从陷阱返回应在陷阱进入操作系统之后的指令处恢复执行，就像从过程调用返回到调用该过程之后的指令一样。在前一种情况下，当从TLB丢失处理陷阱返回时，硬件必须在引起陷阱的指令处继续执行。否则，硬件将继续执行该指令。因此，此重试将使指令再次运行，这一次导致TLB命中。因此，根据导致陷阱或异常的方式，硬件必须在捕获到操作系统中时保存不同的PC，以便在需要时才能正确恢复。 其次，在运行TLB缺失处理代码时，操作系统需要格外小心，以免发生无限数量的TLB丢失链。存在许多解决方案。例如，您可以将TLB缺失处理程序保留在物理内存中（在这些内存中并未映射它们，并且不进行地址转换），或者在TLB中保留一些条目以进行永久有效的转换，并将在某些永久转换插槽用于处理程序代码本身。these wired translations always hit in the TLB. 软件管理方法的主要有点是灵活性：操作系统可以使用它实现想要实现分页表的任何数据结构，而无需更改硬件。从TLB控制流程中可以看出，另一个优点是简单。硬件在缺失方面没有做太多事情：仅引发异常，然后让操作系统TLB缺失处理程序完成其余工作。 ASIDE: RISC VS. CISCIn the 1980’s, a great battle took place in the computer architecture community. On one side was the CISC camp, which stood for Complex Instruction Set Computing; on the other side was RISC, for Reduced Instruction Set Computing [PS81]. The RISC side was spear-headed by David Patterson at Berkeley and John Hennessy at Stanford (who are also co-authors of some famous books [HP06]), although later John Cocke was recognized with a Turing award for his earliest work on RISC [CM00]. CISC instruction sets tend to have a lot of instructions in them, and each instruction is relatively powerful. For example, you might see a string copy, which takes two pointers and a length and copies bytes from source to destination. The idea behind CISC was that instructions should be high-level primitives, to make the assembly language itself easier to use, and to make code more compact.RISC instruction sets are exactly the opposite. A key observation behind RISC is that instruction sets are really compiler targets, and all compilers really want are a few simple primitives that they can use to generate high-performance code. Thus, RISC proponents argued, let’s rip out as much from the hardware as possible (especially the microcode), and make what’s left simple, uniform, and fast.In the early days, RISC chips made a huge impact, as they were noticeably faster [BC91]; many papers were written; a few companies were formed (e.g., MIPS and Sun). However, as time progressed, CISC manufacturers such as Intel incorporated many RISC techniques into the core of their processors, for example by adding early pipeline stages that transformed complex instructions into micro-instructions which could then be processed in a RISC-like manner. These innovations, plus a growing number of transistors on each chip, allowed CISC to remain competitive. The end result is that the debate died down, and today both types of processors can be made to run fast. ASIDE: TLB VALID BIT 6= PAGE TABLE VALID BITA common mistake is to confuse the valid bits found in a TLB with those found in a page table. In a page table, when a page-table entry (PTE) is marked invalid, it means that the page has not been allocated by the process, and should not be accessed by a correctly-working program. The usual response when an invalid page is accessed is to trap to the OS, which will respond by killing the process.A TLB valid bit, in contrast, simply refers to whether a TLB entry has a valid translation within it. When a system boots, for example, a common initial state for each TLB entry is to be set to invalid, because no address translations are yet cached there. Once virtual memory is enabled, and once programs start running and accessing their virtual address spaces, the TLB is slowly populated, and thus valid entries soon fill the TLB.The TLB valid bit is quite useful when performing a context switch too, as we’ll discuss further below. By setting all TLB entries to invalid, the system can ensure that the about-to-be-run process does not accidentally use a virtual-to-physical translation from a previous process.&gt; TLB内容是什么TLB Contents: What’s In There? 让我们更详细地了解硬件TLB的内容。一个典型的TLB可能有32、64或128个条目，这就是所谓的完全关联(a fully-associative)。基本上，这仅意味着任何给定的转换都可以在TLB中的任何位置，并且硬件将并行搜索整个TLB以找到所需的转换。一个TLB条目像这样：VPN | PFN | other bits。 请注意，VPN和PFN都存在于每个条目中，因为转换可能会发生在这些位置中的任何一个位置结束（就硬件而言，TLB被称为完全关联缓存）。硬件会并行搜索条目，以查看是否存在匹配项。 更有趣的是other bits。例如，TLB通常具有有效位，该位表明条目是否具有有效的转换。保护位也很常见，它们确定如何访问页面。例如，代码页可能被标记为read和execute，而堆页面可能被标记为read和write。可能还有一些其它字段，包括地址空间标识符、脏位… TLB问题：上下文切换TLB Issue: Context Switches 使用TLB，在进程（以及地址空间）之间切换时会出现一些问题。具体来说，TLB包含从虚拟到物理的转换，这些转换仅对当前正在运行的进程有效，对其它进程没有意义。因此，从一个进程切换到另一个进程时，硬件或操作系统必须小心，以确保即将运行的进程不会意外地使用某些先前运行的进程的转换。 为了更好地了解这种情况，我们来看一个栗子。当一个进程(p1)正在运行时，它假定TLB可能正在缓存对其有效的转换，即来自p1的分页表的转换。对于此栗子，假定p1的第十个虚拟页面被映射到物理帧100。在此例中，假定存在领域给进程(p2)，并且操作系统很快可能会决定执行上下文切换并运行它。这里假设p2的第十个虚拟页面被映射到物理帧170。如果这两个进程的条目都在TLB中，则TLB的内容为： 12345vpn | pfn | valid | prot10 | 100 | 1 | rwx- | - | 0 | -10 | 170 | 0 | rwx- | - | 0 | - 在上面的TLB中，我们显然有一个问题：vpn(10) 转换为 pfn(100)(p1) 或 pfn(170)(p2)？但是硬件无法区分哪个条目代表哪个进程。因此，我们需要做更多的工作，以便TLB正确有效地支持跨多个进程的虚拟化。因此，症结如下： HOW TO MANAGE TLB CONTENTS ON A CONTEXT SWITCHWhen context-switching between processes, the translations in the TLB for the last process are not meaningful to the about-to-be-run process. What should the hardware or OS do in order to solve this problem? 有许多解决此问题的方法。一种方法是简单地刷新(flush)上下文切换上的TLB，从而在运行下一个进程之前将其清空。在基于软件的系统上，这可以通过明确的硬件指令来完成。如果使用硬件管理的TLB，则可以在更改page table base register时执行刷新操作。无论哪种情况，刷新操作都将所有有效位简单地设置为0，这实质上清除了TLB的内容。 通过刷新每个上下文切换上的TLB，我们现在有了一个可行的解决方案。因为一个进程将永远不会偶然在TLB中遇到错误的转换。但是，这是有代价的：每次运行进程时，它在接触其数据和代码页时都会导致TLB缺失。如果操作系统频繁在进程之间切换，则此成本可能很高。 为了减少这种开销，某些系统添加了硬件支持，以实现在上下文切换之间共享TLB。特别地，某些硬件系统在TLB中提供了地址空间标识符(address space identifier, ASID)字段。您可以将ASID视为与PID类似，只不过它的位数更少。 如果我们从上面的示例TLB并添加ASID，很明显，进程可以轻松共享TLB：仅需要ASID字段即可区分其它相同的转换。这是带有添加的ASID字段的TLB的描述： 12345vpn | pfn | valid | prot | ASID10 | 100 | 1 | rwx | 1- | - | 0 | - | -10 | 170 | 1 | rwx | 2- | - | 0 | - | - 因此，借助地址空间标识符，TLB可以同时保存来自不同进程的转换，而不会造成任何混淆。当然，硬件还需要知道当前正在运行哪个进程才能执行转换，因此操作系统必须在上下文切换时将一些特权寄存器(privileged register)设置为当前进程的ASID。 顺便说一句，您可能还想到了另一种情况。其中TLB的两个条目非常相似。在此示例中，两个不同进程的两个条目具有两个指向相同物理页面的不同VPN： 12345vpn | pfn | valid | prot | ASID10 | 101 | 1 | r-x | 1- | - | 0 | - | -50 | 101 | 1 | r-x | 2- | - | 0 | - | - 例如，当两个进程共享一个页面时，可能会出现这种情况。在上面的栗子中，p1与p2共享物理页面101。p1将该页面映射到其地址空间的第10页，而p2将该页面映射到其地址空间的第50页。共享代码页（在二进制文件或共享库中）很有用，因为它减少了正在使用的物理页面的数量，从而减少了内存开销。 问题：替换策略Issue: Replacement Policy 与任何缓存一样，因此对于TLB，我们还必须考虑的另一个问题时缓存替换(cache replacement)。具体来说，当我们在TLB中安装新条目时，我们必须替换旧条目，从而产生了一个问题。我们要替换哪个条目？ HOW TO DESIGN TLB REPLACEMENT POLICYWhich TLB entry should be replaced when we add a new TLB entry? The goal, of course, being to minimize the miss rate (or increase hit rate) and thus improve performance. 在解决将页面交换到磁盘的问题时，我们将详细研究此类策略。在这里，我们只重点介绍一些典型的策略。一种常见的方法时逐出最近最少使用的LRU条目(least recently used)。LRU尝试利用内存引用流中的局部性，并假设最近未使用的条目很可能是驱逐的良好候选者。另一种典型的方法是使用随机策略，该策略会随机驱逐TLB映射。这样的策略由于其简单性和避免极端情况行为的能力而非常有用。 真实的TLB条目A Real TLB Entry 最后，让我们简要看一下真正的TLB。该示例来自MIPS R4000。它是使用软件管理的TLB的现代系统。在图19-4中可看到简化的MIPS TLB条目。 MIPS R4000支持具有4KB页面的32位地址空间。因此，我们期望在典型的虚拟地址中有20位的VPN和12位的偏移量。但是，正如您在TLB中所看大的，VPN只有19位。事实证明，用户地址将仅来自地址空间的一般（其余部分保留给内核），因此仅需19位VPN。VPN最多可转换为24位物理帧(pfn)，因此可以支持具有64GB(物理)主内存(2^24 4KB pages)。 MIPS TLB中还有一些其它有趣的地方。我们看到一个全局为(global bit, G)，用于进程之间全局共享的页面。因此，如果设置了全局位，则将忽略ASID。我们也看到了8位ASID，操作系统可以使用它来区分地址空间。您遇到一个问题：如果一次运行的进程超过256(2^8)个，操作系统应怎么做？最后，我们看到3个 Coherence(C) bits，这些位确定硬件如何缓存页面。当页面被写入时被标记的脏位；一个有效位，该值高速硬件条目中是否存在有效的转换。还有一个页面掩码字段，它支持多种页面大小。我们将在后面看到为什么较大的页面可能会有用。最后，这64位中的一些未使用。 MIPS TLB通常包含32或64个条目，其中大多数在运行时由用户进程使用。但是，为操作系统保留了一些。可以由操作系统设置wired register，以告知硬件为操作系统保留多少个TLB插槽。操作系统会使用这些保留的映射来存储要在关键时间访问的代码和数据，而这在TLB丢失中会造成问题。 由于MIPS TLB是软件管理的，因此需要一些说明来更新TLB。MIPS 提供了以下四个这样的指令。操作系统使用这些说明来管理TLB的内容。当然，这些指令必须具有特权。想象一下，如果用户进程可以修改TLB的内容（几乎任何事情，包括接管机器，运行自己的恶意操作系统），该怎么办？ TLBP，它探测TLB以查看其中是否存在特定转换； TLBR，它将TLB条目的内容读入寄存器； TLBWI，用于替换特定的TLB条目； TLBWR，它将替换随机的TLB条目。 总结Summary 我们已经了解了硬件如何帮助我们更快地进行地址转换。通过提供一个小型的专用片上TLB作为地址转换缓存，可以希望处理大多数内存引用，而不必访问主内存中的分页表。因此，在通常情况下，程序的性能几乎就像完全没有对内存进行虚拟化一样，这对于操作系统来说是一项出色的成就，并且对于现代操作系统中的分页使用必不可少。 但是，TLB并不会使每个存在的程序都变得乐观。特别是，如果程序在短时间内访问的页面数据超过了适合TLB的页面数，则该程序生成大量的TLB丢失，因此运行起来会慢得多。我们称这种现象超出了TLB的覆盖范围(coverage)，对于某些程序来说可能是个问题。正如我们将在下一章中讨论的那样，一种解决方案是包括对更大页面尺寸的支持。通过将关键数据结构映射到程序地址空间的较大页面所映射的区域中，可以提高TLB的有效覆盖率。 对大型页面的支持经常被诸如数据库管理系统(DBMS)之类的程序所利用，这些程序具有某些即大又随机访问的数据结构。 值得一提的另一个TLB问题：TLB访问很容易成为CPU pipeline的瓶颈，尤其是所谓的物理索引缓存。使用这种高速缓存，必须在访问高速缓存之前进行地址转换，这可能会大大降低速度。由于存在这个潜在的问题，人们已经研究了各种巧妙的方法来访问具有虚拟地址的缓存，从而避免在缓存命中的情况下进行昂贵的转换步骤。这种虚拟索引的缓存解决了一些性能问题，但也将新问题引入了硬件机制。 高级的分页表Advanced page table Paging: Smaller Tables 现在，我们解决介绍引入的第二个问题：分页表太大，因此消耗了太多内存。从线性分页表开始，您可能还记得，线性分页表变得很大。再次假定一个32位地址空间(2^32Bytes)，其中包含4KB(2^12Bytes)分页和4Bytes分页表条目。因此，一个地址空间中大约有一百万个虚拟页面(2^32/2^12)，乘以分页表条目大小，您会发现我们的分页表大小为4MB。还记得，我们通常为系统中的每个进程提供一个分页表！拥有一百个活跃的进程（在现代系统中并不罕见），我们仅为分页表分配数百兆的内容！结果，我们正在寻找减轻这种沉重负担的一些技术。这里有很多，让我们看看症结在哪： HOW TO MAKE PAGE TABLES SMALLER?Simple array-based page tables (usually called linear page tables) are too big, taking up far too much memory on typical systems. How can we make page tables smaller? What are the key ideas? What inefficiencies arise as a result of these new data structures? 简单的解决方案：更大的页面Simple Solution: Bigger Pages 我们可以通过一种简单的方法来减少分页表的大小：使用更大的页面。再次使用32位地址空间，但这次假设使用16KB页面。因此，我们将拥有一个18位的VPN和一个14位的偏移量。假设每个PTE的大小相同(4Bytes)，则我们现在有2^18个条目，因此每个分页表的总大小为1MB，这是分页表大小减少4倍的原因。 但是，这种方法的主要问题在于，大页面会导致每个页面内部的浪费，这就是内部化碎片的问题。因此，应用程序最终只能分配页面，但每个页面只使用很少的点滴，而内存很会被这些过大的页面填满。因此，在通常情况下，大多数系统使用相对较小的页面大小：4KB(x86)或8KB(SPARC V9)。 ASIDE: MULTIPLE PAGE SIZESAs an aside, do note that many architectures (e.g., MIPS, SPARC, x86-64) now support multiple page sizes. Usually, a small (4KB or 8KB) page size is used. However, if a “smart” application requests it, a single large page (e.g., of size 4MB) can be used for a specific portion of the address space, enabling such applications to place a frequently-used (and large) data structure in such a space while consuming only a single TLB entry. This type of large page usage is common in database management systems and other high-end commercial applications. The main reason for multiple page sizes is not to save page table space, however; it is to reduce pressure on the TLB, enabling a program to access more of its address space without suffering from too many TLB misses. However, as researchers have shown [N+02], using multiple page sizes makes the OS virtual memory manager notably more complex, and thus large pages are sometimes most easily used simply by exporting a new interface to applications to request large pages directly 混合方法：分页和段Hybrid Approach: Paging and Segments 每当您对生活中的某件事有两种合理但不同的方法时，都应始终检查这两种情况的组合，以了解是否可以同时兼顾两者。我们称这种组合为混合(hybrid)。 多年前，Multics的创造者在Multics虚拟内存系统的构建中碰巧出现了这种想法。具体来说，他将分页和分段结合在一起，以减少分页表的内存开销。我们可以通过更详细地检查典型的线性分页表来了解为什么这样做可行。假设我们有一个地址空间，其中堆和栈的已用部分很小。在此栗中，我们使用一个很小的16KB的地址空间和1KB页面（图20-1）。此地址空间和分页表在图20-2中。 此例中假定单个代码页(vpn 0)映射到pfn 10， 单个堆页面(vpn 4)映射到pfn 23，地址空间另一端的两个栈页面(vpn 14, 15)分别映射到(pfn 28, 4)。从图中可看出，大多数分页表都是未使用的，充满了无效的条目。真是浪费！这是一个很小的16KB地址空间。想象一下32位地址空间的分页表以及其中所有潜伏的浪费空间。太可怕了！ 因此，我们采用了混合方法：不在进程的整个地址空间中使用分页表，而在每个逻辑段(logical segment)中使用分页表。因此，在此栗子中，我们可能有三个分页表：一个用于代码，一个用于堆、一个用于栈。 现在，请记住分段。我们有一个base register，告诉我们每个段在物理内存中的位置，还有一个bound register，告诉我们该段的大小。在我们的混合方法中，我们在MMU中仍然具有这些结构。在这里，我们使用base不是指向该段本身，而是保存该段的分页表的物理地址。bound register用于指示分页表的末尾（即，它具有多少有效页面）。 一个栗子。假定一个具有4KB页面的32位虚拟地址空间，并将一个地址空间分为四段。在此栗中，我们仅使用三个段：code, heap, stack。为了确定地址所指向的段，我们将使用地址空间的前两位。假设00是未使用的段，其中01代表代码，10代表堆，11代表栈。因此，虚拟地址可能像这样： 因此，在硬件中，假设有三对 base/bound，每对用于代码、堆、栈。当进程正在运行时，这些段中的base register都包含该段线性分页表的物理地址。因此，系统中的每个进程现在都具有与其关联的三个分页表。在上下文切换时，必须更改这些寄存器以反映新运行的进程的分页表的位置。 在TLB丢失时（假设由硬件管理TLB），硬件使用segment bits(SN)来确定要使用的base/bound pair。然后，硬件在其中获取物理地址，并将其与VPN结合，如下所示以形成分页表项(PTE)的地址： 123SN = (VirtualAddress &amp; SEG_MASK) &gt;&gt; SN_SHIFTVPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; VPN_SHIFTAddressOfPTE = Base[SN] + (VPN * sizeof(PTE)) 这个顺序看起来应该很熟悉。它实际上与我们之前在线性分页表中看到的相同。当然，唯一的区别是使用了三个 segment base registers，而不是一个。 混合方案中的关键差异是每个段都有一个base register，基寄存器保存该段中最大有效页面的值。例如，如果代码正在使用其前三个页面(0, 1, 2)，则代码段分页表将仅分配三个条目，并且bound register将设置位3。段末尾以外的内存访问将产生异常，并可能导致进程终止。通过这种方式，混合方法与线性分页表相比节省了大量内存。栈和堆之间未分配的页面不在占用分页表中的空间（只是将其标记为无效）。 但是，您可能会注意到，这种方法并非没有问题。首先，它仍然需要我们使用分段。正如前面所讨论的，分段并不像我们所希望的那样灵活，因为它假定了地址空间的某种使用模式。例如，如果我们有一个很大但稀疏使用的堆，那么仍然会导致很多分页表浪费。其次，这种混合方法导致外部碎片再次出现。尽管大多数内存以页面大小为单位进行管理，但现在分页表可以具有任意大小(pte的倍数)。因此，在内存中为其找到空闲空间更加复杂。由于这些原因，人们继续寻找更好的方法来实现较小的分页表。 TIP: USE HYBRIDSWhen you have two good and seemingly opposing ideas, you should always see if you can combine them into a hybrid that manages to achieve the best of both worlds. Hybrid corn species, for example, are known to be more robust than any naturally-occurring species. Of course, not all hybrids are a good idea; see the Zeedonk (or Zonkey), which is a cross of a Zebra and a Donkey. If you don’t believe such a creature exists, look it up, and prepare to be amazed. 多级分页表Multi-level Page Tables 一种不同的方法不依赖于分段，而是攻击相同的问题：如果摆脱分页表中所有无效区域，而不是将它们全部保留在内存中？我们将这种方法称为多级分页表(multi level page table)，因为它将线性分页表变成了像树一样的东西。这种方法非常有效，以至于许多现代操作系统都采用这种方法（如，x86）。 多级分页表的基本思想很简单。首先，将页面切成页面大小(page-sized)的单位。然后，如果整个分页表条目(pte)无效，则根本不要分配该分页表的整个页面。若要追踪分页表的页面是否有效（如果有效，则在内存中的位置），请使用称为页目录(page directory)的新结构。因此，页目录可以用来告诉您分页表的页面在哪里，或者分页表的整个页面不包含有效页面。 图20-3显示了一个栗子。图的左侧是经典的线性分页表。即地址空间的大多数中间区域无效，我们仍然需要为这些区域分配分页表空间。右边是一个多级分页表。页面目录仅将分页表的两个页面标记为有效（第一个和最后一个）。因此，只有分页表的那两个页驻留在内存中。因此，您可以看到一种可视化多级表正在执行的方法：它只是使线性分页表的某些部分消失（将那些框架释放出来供其它用途），并跟踪分页表中的哪些页与页目录一起分配。 页目录在一个简单的两级表中，在分页表的每页中包含一个条目。它由许多页目录条目(page directory entry, PDE)组成。PDE（至少）具有一个有效位(valid bit)和一个页帧号(pfn)，类似于PTE。但是，如前所述，该有效位的含义略有不同：如果PDE有效，则意味着该条目指向的分页表中的至少一个页面(通过pfn)是有效的，即在此PDE指向的页面上的至少一个PTE中，该PTE中的有效位设置为1.如果PDE无效(0)，则未定义PDE的其余部分。 到目前为止，多级分页表具有一些明显的优势。首先，也许是最明显的是，多级表仅根据您正在使用的地址空间量分配分页表空间。因此，它通常是紧凑的，并且支持稀疏的地址空间。其次，如果精心构建，分页表的每个部分都可以整齐地放在一个页面中，从而更易于管理内存。当操作系统需要分配或增加分页表时，操作系统可以简单地获取下一个空闲页。将此与一个简单的（非分页）线性分页表进行对比，该表只是一个由VPN索引的PTE数组。采用这种结构，整个线性分页表必须连续地驻留在物理内存中。对于大的分页表(如，4MB)，找到这么大的未使用的连续可用物理内存可能是一个挑战。通过多级结构，我们通过使用页面目录添加了一个间接级别(level of indirection)，该目录指向分页表的各个部分。这种间接允许我们将分页表页面放置在物理内存中的任何位置。 应该注意的是，多级表是有代价的。在TLB丢失时，将需要两次从内存中加载来从分页表中获取正确的转换信息（一个用于页目录，一个用于PTE自身），而线性分页表仅需要一次加载。因此，多级表只是时空(time-space)权衡(trade-off)的一个小栗子。我们想要更小的表（并得到它），但不是免费的。尽管在常见情况下(TLB hit)，性能显然是相同的，但使用较小的表会导致TLB丢失而导致成本较高。 另一个明显的负面影响是复杂性(complexity)。无论是硬件还是操作系统处理分页表查找，与简单的线性分页表查找相比，这样做无疑涉及更多。通常，我们愿意增加复杂性以提高性能或减少开销。对于多级表，为了节省宝贵的内存，我们使分页表查找更加复杂。 TIP: UNDERSTAND TIME-SPACE TRADE-OFFSWhen building a data structure, one should always consider time-space trade-offs in its construction. Usually, if you wish to make access to a particular data structure faster, you will have to pay a space-usage penalty for the structure. 详细的多级示例A Detailed Multi-Level Example 为了更好地理解多级分页表背后的思想，让我们举个栗子。想象一下一个小的16KB地址空间，具有64Bytes的页面。因此，我们有一个14位的虚拟地址空间，其中8位用于VPN，6位用于offset。即使只使用一小部分地址空间，线性分页表也将具有(2^8=256)个条目。图20-4给出了这种地址空间的一个栗子。 在此栗子中，vp 0, 1用于代码，vp 4, 5用于堆，vp 254, 255用于栈。地址空间的其余页面未使用。为了为该地址空间构建要给两级分页表，我们从完整的线性分页表开始，然后将其分解为页面大小的单元。假设每个PTE的大小为4Bytes。因此，我们的分页表大小为1KB(256*4Bytes)。假设有64Bytes的页面，则1KB分页表可以分为16个64Bytes的页面。每个页面可以容纳16个PTE。现在，我们需要了解的是如何使用VPN并使用它索引到页面目录，然后再索引到分页表的页面。请记住，每个条目都是一个数组。因此，我们需要弄清楚的是如何从VPN的各个部分构建索引。 让我们首先索引页目录。在此示例中，我们的分页表很小：256个条目，分布在16个页面上。页目录在分页表的每页上需要一个条目。因此，我们需要VPN的四位索引到目录中。我们使用VPN的前四位，如下： 一旦从VPN中提取了页目录索引(page-directory index, PDIndex)，我们就可以使用它通过简单的计算来找到页目录条目(PDE)的地址：PDE Addr = PageDirBase + (PDIndex*sizeof(PDE))。此结果在我们的页目录中，现在我们将对其进行检查以在转换中取得进一步的进展。 如果页目录条目被标记为无效，则我们知道该访问无效。因此引发异常。但是，如果PDE有效，我们还有更多工作要做。具体来说，我们现在必须从此页目录条目指向的分页表的页面中获取分页表条目(PTE)。要找到此PTE，我们必须使用VPN的其余位来索引分页表的一部分： 然后可以使用此分页表索引(PTIndex)来索引分页表本身，从而为我们提供PTE的地址： 123PTEAddr = (PDE.PFN &lt;&lt; SHIFT) + (PTIndex * sizeof(PTE))// &gt;&gt; 请注意，从页目录获得的页面帧号(pfn)必须显左移到适当位置，然后再将其与分页表索引组合以形成PTE的地址。在图20-5中，您可以看到每个页目录条目(PDE)都描述了有关地址空间的分页表页面的内容。在这个例子中，我们在地址空间（开头和结尾）两个有效的区域，以及一些无效的映射在两者之间的。在物理页100（分页表第0页的物理帧号）中，我们在地址空间中具有前16个VPN的16页分页表条目的第一个页面。有关分页表此部分的内容，请参见图20-5。 分页表的此页面包含前16个映射VPN。在此例中，vpn 0, 1有效()code，vpn 4, 5有效(heap)。因此，该表具有每个页面的映射信息。其余条目被标记为无效。 分页表的另一个有效页位于pfn 101内。此页包含地址空间的最后16个VPN的映射。 在该栗子中，vpn 254, 255(stack)具有有效的映射。希望从本示例中可以看到，使用多级索引结构可以节省多少空间。在此示例中，我们没有为线性分页表分配完整的十六个页面，而是仅分配了三个：一个用于页目录，两个用于具有映射的分页表的块。大型地址空间(32bit/64bit)的节省显然会更大。 最后，让我们使用此信息来执行转换。这是引用VPN 254的第0个字节的地址：0x3F80或二进制的11 111 1000 0000。 回想一下，我们将使用VPN的高4位索引到页目录。因此，1111将选择上面页目录的最后一个条目。这将我们指向位于地址101的分页表的有效页。然后，我们使用VPN的下4位(1110)索引到分页表的该页并找到所需的PTE。1110是页面上的倒数第二个条目，它告诉我们虚拟地址空间的页面254映射到物理页面55。通过将PFN=55（或十六进制0x37)与offset=000000串联，我们这样就可以形成我们想要的物理地址，并向存储系统发出请求： 123PhysAddr = (PTE.PFN &lt;&lt; SHIFT) + offset = 00 1101 1100 0000 = 0x0DC0// &gt;&gt; 您现在应该对如何使用指向分页表页面的页目录构造一个二级分页表有所了解。然而不幸的是，我们的工作还没有完成。正如我们现在要讨论的那样，有时两个级别的分页表是不够的。 不止两级More Than Two Levels 到目前为止，在示例中。我们假设多级分页表只有两个级别：页目录，然后是分页表的各个部分。在某些情况下，更深的树是可能的（确实的、必需的）。 举个栗子，并用它来说明为什么更深层的多级表很有用。假设有一个30位的虚拟地址空间和一个小的页面(512Bytes)。因此，我们的虚拟地址具有21位的虚拟页码部分和9位偏移量。记住我们构建多级分页表的目标：使分页表的每个部分都适合单个页面。到目前为止，我们仅考虑了分页表本身。但是，如果页目录太大，该怎么办？ 为了确定多级表中需要多少级才能使分页表的所有部分都适合一个页面，我们首先确定一个页面中可以容纳多少分页表条目。给定的页面大小位512Bytes，并假设PTE大小为4Bytes，您应该看到可以在单个页面上容纳128个PTE。当我们索引到分页表的页面时，我们将需要vpn的最低有效位7位(2^7=128)作为索引： 您还可能从上图中注意到，页目录中还剩下多少位：14。如果我们的页目录有2^14个条目，那么它跨越的不是一页而是128个，因此我们使多级分页表的每个部分都适合一个页面的目标就消失了。 为了解决此问题，我们通过将页目录本身拆分为多个页面，然后在该页面之上添加另一个页目录，以指向该页目录的页面，来构建树的进一步层次。因此，我们可以如下拆分虚拟地址： 现在，在索引上级(upper-level)页目录时，我们使用虚拟地址的最高位（PDIndex 0）。该索引可用于从顶级页目录中获取页目录条目。如果有效，则通过组合来自顶层PDE和VPN的下一部分(PDIndex 1)的物理帧号来查询页目录的第二层。最后，如果有效，则可以通过使用页表索引与第二级PDE中的地址相结合来形成PTE地址。这是很多工作，所有这些只是为了在多级表中查找内容。 转换进程：记住TLBThe Translation Process: Remember the TLB 为了总结使用两级分页表的地址转换的整个过程，我们再次以算法形式给出如下控制流。它显示了在每个内存引用中硬件中发生的情况（假设由硬件管理的TLB）。 123456789101112131415161718192021222324252627282930313233// Multi-level Page Table Control FlowVPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFT(Success, TlbEntry) = TLB_Lookup(VPN)if (Success == True) // TLB Hit if (CanAccess(TlbEntry.ProtectBits) == True) Offset = VirtualAddress &amp; OFFSET_MASK PhysAddr = (TlbEntry.PFN &lt;&lt; SHIFT) | Offset Register = AccessMemory(PhysAddr) else RaiseException(PROTECTION_FAULT)else // TLB Miss // first, get page directory entry PDIndex = (VPN &amp; PD_MASK) &gt;&gt; PD_SHIFT PDEAddr = PDBR + (PDIndex * sizeof(PDE)) PDE = AccessMemory(PDEAddr) if (PDE.Valid == False) RaiseException(SEGMENTATION_FAULT) else // PDE is valid: now fetch PTE from page table PTIndex = (VPN &amp; PT_MASK) &gt;&gt; PT_SHIFT PTEAddr = (PDE.PFN &lt;&lt; SHIFT) + (PTIndex * sizeof(PTE)) PTE = AccessMemory(PTEAddr) if (PTE.Valid == False) RaiseException(SEGMENTATION_FAULT) else if (CanAccess(PTE.ProtectBits) == False) RaiseException(PROTECTION_FAULT) else TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits) RetryInstruction()// &gt;&gt;over 从图中可以看出，在进行任何复杂的多级页表访问之前，硬件首先检查TLB。命中后，就像以前一样直接形成物理地址，而根本不访问分页表。只有在TLB未命中时，硬件才需要执行完整的多级查找。在这条路径上，您可以看到传统的两级分页表的成本：两个额外的内存访问以查找有效的转换。 反向分页表Inverted Page Tables 使用反向分页表(inverted page tables)可以在分页表世界中节省更多空间。在这里，没有许多分页表（每个系统进程一个），而是保留了一个分页表，该表为系统的每个物理页面都有一个条目。该条目告诉我们哪个进程正在使用该页面，以及该进程的哪个虚拟页面映射到该物理页面。 现在，查找正确的条目只是搜索此数据结构的问题。线性扫描会很昂贵，因此通常在基本结构上构建哈希表以加快查找速度。PowerPC就是这种架构的一个示例。 更一般而言，反向分页表从一开始就说明了我们所说的话：分页表只是数据结构。您可以使用数据结构做很多疯狂的事情，使它们变小或变大、变快或变慢。多级和反向分页表只是一个人可以做的许多事情的两个栗子。 将分页表交换到磁盘Swapping the Page Tables to Disk 最后，我们讨论一个最终假设。到目前为止，我们已经假定分页表驻留在内核拥有的物理内存中。即使我们有很多减少分页表大小的技巧，但是仍然有可能它们太大而无法一次全部放入内存中。因此，某些系统将这样的分页表放置在内核虚拟内存(kerl virtual memory)中，从而允许系统在内存压力变紧时将这些分页表中的某些交换(swap)到磁盘上。一旦我们了解了如何更详细将页面移入和移出内存，我们将在以后的章节中进一步讨论这一点。 总结Summary 现在，我们已经看到了如何构建真实的分页表。不一定只是线性数组，而是更复杂的数据结构。这种表的权衡是在时间和空间上进行的，表越大，TLB丢失可以得到更快的服务。反之亦然。因此，结构的正确选择在很大程度上取决于给定环境的约束。 在受内存限制的系统中（旧的系统），小型结构是有意义的。在内存合理且工作负载主动使用大量页面的系统中，加快TLB丢失速度的较大表可能是正确的选择。借助软件管理的TLB，整个数据结构空间将为操作系统创新者带来惊喜。 交换机制Beyond Physical Memory(Swap) Mechanisms: http://pages.cs.wisc.edu/~remzi/OSTEP/vm-beyondphys.pdf 到目前为止，我们已经假定地址空间不切实际地小并且适合物理内存。实际上，我们一直假设每个运行进程的每个地址空间都适合内存。现在，我们将放宽这些大的假设，并假设我们希望支持许多同时运行的大地址空间。为此，我们需要在内存层次结构中增加一个级别。到目前为止，我们已经假设所有页面都驻留在物理内存中。但是，为了支持较大的地址空间，操作系统将需要一个地方来存放当前需求不大的部分地址空间。通常，这种位置的特征是它的容量应大于内存。结果，它通常会比较慢。在现代系统中，通常由硬盘驱动器(hard disk drive)担当此角色。因此，在我们的内存层次结构中，大而慢的硬盘驱动器位于底部，而内存位于上方。因此，我们得出了问题的症结： THE CRUX: HOW TO GO BEYOND PHYSICAL MEMORYHow can the OS make use of a larger, slower device to transparently provide the illusion of a large virtual address space? 您可能会有一个问题，为什么我们要为一个进程支持一个大地址空间？答案再次是方便和易用。地址空间很大，您不必担心程序中的数据结构是否有足够的内存空间。相反，您只是自然地编写程序，并根据需要分配内存。操作系统提供了一种强大的幻觉，使您的生活大大简化。在使用内存覆盖(memory overlays)的旧系统中发现了一种对比，这要求程序员在需要时手动将代码或数据片段移入或移出内存。试想一下这是什么样的：在调用函数或访问某些数据之前，您需要首相将代码或数据安排在内存中。 除了单个进程外，交换空间(swap space)的增加还使操作系统能够为多个同时运行的进程提供大型虚拟内存的支持。多程序的发明（一次运行多个程序，以更好地利用机器）几乎需要交换掉某些页面的能力，因为早期的机器显然不能同时容纳所有进程所需的所有页面。因此，多程序和易用性的结合使我们想要支持使用比物理可用内存更多的内存。所有现代虚拟内存系统都可以做到这一点。现在，我们将了解更多信息。 ASIDE: STORAGE TECHNOLOGIESWe’ll delve much more deeply into how I/O devices actually work later (see the chapter on I/O devices). So be patient! And of course the slower device need not be a hard disk, but could be something more modern such as a Flash-based SSD. We’ll talk about those things too. For now, just assume we have a big and relatively-slow device which we can use to help us build the illusion of a very large virtual memory, even bigger than physical memory itself. 交换空间Swap Space 我们需要做的第一件事是在磁盘上保留一些空间来回移动页面。在操作系统中，我们通常将此类空间称为交换空间(swap space)，因为我们将页面从内存中交换到该空间，并将页面从其中交换到内存。因此，我们仅假设操作系统可以以页面大小为单位读取和写入交换空间。为此，操作系统需要记住给定页面的磁盘地址(disk space)。 交换空间的大小很重要，因为它最终决定了系统在给定时间可以使用的最大内存页面数量。为了简单起见，让我们假设它现在很大。 在图21-1的栗子中，您可以看到一个4页面物理内存和8页面交换空间。在此例中，三个进程(P0, P1, P2)正在主动共享物理内存。但是，这三个中的每一个在内存中仅具有其部分有效页面，区域部分位于磁盘上的交换空间中。第四个进程(P3)将所有页面交换到磁盘，因此显然当前未运行。一块交换空间仍然是空闲的。即使从这个很小的栗子，也希望您能看到使用交换空间如何使系统假装内存大于实际内存。 我们应该注意到，交换空间不是交换流量(swapping traffic)的唯一磁盘位置。例如，假设您正在运行一个二进制程序（如，ls）。最初在磁盘上找到此二进制文件的代码页(code pages)，并且在程序运行时将它们加载到内存中（既可以在程序开始执行时一次全部加载，也可以在现代系统中需要时一次加载一页）。但是，如果系统需要在物理内存中腾出空间来满足其它需求，则可以安全地重用这些代码页的存储空间，因为它知道以后可以从文件系统中的磁盘二进制文件中再次交换它们。 当前位The Present Bit 现在，我们有一些空间在磁盘上。我们需要在系统中增加一些机制，以支持在磁盘之间交换页面。为了简单起见，让我们假设我们有一个带有硬件管理的TLB的系统。 首先回想一下内存引用中发生的情况。正在运行的进程会生成虚拟内存引用（用于指令提取，或数据访问），在这种情况下，硬件会在从内存中提取所需数据之前将其转换为物理地址。 请记住，硬件首先从虚拟地址中提取VPN，检查TLB是否匹配（TLB hit）。如果命中，将产生结果的物理地址并从内存中获取它。希望这是常见的情况，因为它速度很快（不需要额外的内存访问）。 如果在TLB中未找到VPN（TLB miss），则硬件会在内存中找到分页表（使用page table base register)，并使用VPN作为索引查找该页的分页表条目(PTE)。如果该页面有效并且存在于物理内存中，则硬件将从PTE中提取PFN，并将其写入TLB，然后重试指令，这一次将产生TLB命中，到目前为止，岁月静好。 但是，如果我们希望将页面交换到磁盘，则必须添加更多的设备。具体来说，当硬件在PTE中查找时，它可能会发现内存中不存在(not present)该页面。硬件确定这一点的方式是通过每个分页表条目中的一条信息——称为当前位(present bit)。如果当前位设置为1，则意味着该页存在于物理内存中，并且一切按上述步骤进行；如果其设置为0，则该页面不在内存中，而是在磁盘上的某个位置。访问不在物理内存中的页面的行为通常称为页面错误(page fault)。 出现页面错误时，将调用操作系统来服务该页面错误。正如我们现在所描述的，称为页面错误处理程序(page-fault handler)的特定代码运行，并必须服务于页面错误。 ASIDE: SWAPPING TERMINOLOGY AND OTHER THINGSTerminology in virtual memory systems can be a little confusing and variable across machines and operating systems. For example, a page fault more generally could refer to any reference to a page table that generates a fault of some kind: this could include the type of fault we are discussing here, i.e., a page-not-present fault, but sometimes can referto illegal memory accesses. Indeed, it is odd that we call what is definitely a legal access (to a page mapped into the virtual address space of a process, but simply not in physical memory at the time) a “fault” at all; really, it should be called a page miss. But often, when people say a program is “page faulting”, they mean that it is accessing parts of its virtual address space that the OS has swapped out to disk.We suspect the reason that this behavior became known as a “fault” relates to the machinery in the operating system to handle it. When something unusual happens, i.e., when something the hardware doesn’t know how to handle occurs, the hardware simply transfers control to the OS, hoping it can make things better. In this case, a page that a process wants to access is missing from memory; the hardware does the only thing it can, which is raise an exception, and the OS takes over from there. As this is identical to what happens when a process does something illegal, it is perhaps not surprising that we term the activity a “fault.” 页面错误The Page Fault 回想一下，对于TLB未命中，我们有两种类型的系统：硬件管理的TLB和软件管理的TLB。在这两种类型的系统中，如果页面不存在，则由操作系统负责处理页面错误。操作系统页面错误处理程序将运行以确定要执行的操作。实际上，所有系统都可以处理软件中的页面错误。即使使用硬件管理的TLB，硬件也信任操作系统来管理这一重要职责。 如果页面不存在并且已被交换到磁盘，则操作系统需要将页面交换到内存中已解决页面错误。因此，出现一个问题：操作系统如何知道在哪里可以找到所需的页面？在许多系统中，分页表时存储此类信息的天然场所。因此，操作系统可以将通常用于数据(pfn)的PTE中的位用于磁盘地址。当操作系统收到页面的页面错误时，它会在PTE中查找地址，然后向磁盘发出请求以将该页面读取到内存中。 磁盘I/O完成后，操作系统将更新分页表以将该页面标记为present，更新分页表条目(pte)的pfn字段以记录新获取的页面在内存中的位置，然后重试指令。下一个尝试可能会生成TLB未命中，然后服务并使用转换来更新TLB（为错误页面提供服务时，可以交替更新TLB以避免此步骤）。最后，最后一次重新启动将在TLB中找到转换，并因此从转换后的物理地址出的内存中获取所需的数据或指令。 请注意，在运行I/O时，该进程将处于阻塞状态(blocked state)。因此，在为页面错误提供服务时，操作系统将可以自由运行其它准备就绪的进程。因为I/O昂贵，所以一个进程的I/O和另一个进程的执行的这种重叠(overlap)是多程序系统可以最有效地利用其硬件的另一种方式。 如果内存满了怎么办What If Memory Is Full? 在上述描述中，您可能会注意到我们假设有足够的可用内存在交换空间中的页面中进行分页。然而，事实并非如此。内存可能已满。因此，操作系统可能希望首先剔出一个或多个页面，以便为操作系统将要引入的新页面腾出空间。挑选要踢出或替换的页面的过程称为页面替换策略(page-replacement policy)。 事实证明，创建一个好的页面替换策略引起了很多思考，因为踢错页面(kicki out of the wrong page)可能会导致程序性能损失巨大。错误的决定会导致程序以磁盘速度而不是内存速度运行。在目前的技术中，这意味着程序的运行可能会慢一万倍。因此，这种政策是我们应该详细研究的。实际上，这正是我们将在下一章中进行的操作。到目前为止，了解存在这样的策略已经足够了。 页面错误控制流Page Fault Control Flow 掌握了所有这些知识之后，我们现在可以大致概述内存访问的完整控制流程。换句话说，当有人问您程序从内存中获取一些数据时会发生什么？您应该对所有不同的可能性都有一个很好的了解。有关更多详细信息，请参考图21-2和21-3的控制流程。第一个图显示了硬件在转换过程中的作用，第二个图显示了页面错误时操作系统的作用。 从图21-2的硬件控制流程图中，请注意，当发生TLB丢失时，现在需要了解三个重要情况： 首先，该页面既存在又有效(line 18-21)。在这种情况下，TLB未命中处理程序可以简单地从PTE中获取PFN，重试指令（这一次导致TLB命中），从而按照前面所述继续操作。 在第二种情况下(line 22-23)，必须运行页面错误处理程序。尽管这是供进程访问的合放页面（毕竟它是有效的），但它不存在于物理内存中。 第三，访问可能是无效页面。例如由于程序中的错误(line 13-14)。在这种情况下，PTE中的其它位都不重要。硬件会批捕此无效访问，并且操作系统给陷阱处理程序将运行，可能会终止有问题的进程。 从图21-3的软件控制流程中，我们可以看到操作系统大致必须执行的操作才能解决页面错误。首先，操作系统必须为即将出现故障的页面找到驻留在其中的物理框架。如果没有这样的页面，我们将不得不等待替换算法进行并将其部分页面踢出内存，从而释放它们供此处使用。有了一个物理框架，处理程序便发出I/O请求以从交换空间中读取页面。最后，当该缓慢的操作完成时，操作系统将更新分页表并重试该指令。重试将导致TLB丢失，然后在再次重试时TLB命中，此时硬件将能够访问所需的项目。 真正发生替换时When Replacements Really Occur 到目前为止，我们描述替换的方式是假设操作系统一直等到内存完全用完，然后才替换（逐出）页面为其它页面腾出空间。可以想象，这有点不切实际，并且操作系统有很多原因可以更主动地释放一小部分内存。 为了使少量内存可用，大多数操作系统因此具有某种高水位(high watermark, HW)和低水位(low watermark, LW)来帮助确定何时开始从内存中逐出页面。它的工作方式如下：当操作系统注意到可用的页面少于LW时，负责释放内存的后台线程将运行。该线程逐出页面，直到有可用的HW为止。后台线程（有时称为swap daemon，或page daemon）随后进入睡眠状态，很高兴它释放了一些内存以供正在运行的进程和操作系统使用。 通过一次执行许多替换，新的性能优化成为可能。例如，许多系统将集群(cluster)和分组(group)并将它们立即写出到交换分区，从而提高磁盘的效率。正如我们稍后将更详细地讨论磁盘时所看到的那样，这种集群减少了磁盘的查找和旋转开销，从而显著提高了性能。要使用后台分页进程，应略微修改图21-3中的控制流程。该算法将直接检查是否有可用的空闲页面，而不是直接执行替换。如果没有，它将通知后台分页线程需要空闲页面。当线程释放一些页面时，它将重新唤醒原始线程，然后可以在所需的页面中分页并继续其工作。 TIP: DO WORK IN THE BACKGROUNDWhen you have some work to do, it is often a good idea to do it in the background to increase efficiency and to allow for grouping of operations. Operating systems often do work in the background; for example, many systems buffer file writes in memory before actually writing the data to disk. Doing so has many possible benefits: increased disk efficiency, as the disk may now receive many writes at once and thus better be able to schedule them; improved latency of writes, as the application thinks the writes completed quite quickly; the possibility of work reduction, as the writes may need never to go to disk (i.e., if the file is deleted); and better use of idle time, as the background work may possibly be done when the system is otherwise idle, thus better utilizing the hardware. 总结Summary 在简短的本章节中，我们介绍了访问比系统中实际存在的内存更多的内存的概念。这样做需要分页表结构中的更多复杂性，因为必须包括当前位(present bit)以告诉我们该页面是否存在于内存中。否则，操作系统页面错误处理程序将运行以处理页面错误，从而安排将所需的页面从磁盘传输到内存，也许首先替换内存中的某些页面以为即将被交换的那些页面腾出空间。 重要的是，记得这些动作对进程来说都是透明的。就进程而言，它只是在访问自己的私有连续虚拟内存。在幕后，页面被放置在物理内存中的任意(不连续)位置中，有时它们甚至不存在于内存中，需要从磁盘中获取。尽管我们希望在通常情况下可以快速访问内存，但在某些情况下仍需要多个磁盘操作来进行访问。在最坏的情况下，执行一条指令之类的简单操作可能需要花费几毫秒的时间才能完成。 交换策略Beyond Physical Memory(Swap) Policies: http://pages.cs.wisc.edu/~remzi/OSTEP/vm-beyondphys-policy.pdf 在虚拟内存呢管理器中，当您有大量可用内存时，生活很轻松。发生页面错误时，您在空闲页面列表中找到一个空闲页面，并将其分配给错误页面。不幸的是，只有很少的内存可用时，事情才会变得更加有趣。在这种情况下，内存压力(memory pressure)迫使操作系统开始调出页面，以便为活跃使用的页面腾出空间。使用包含在操作系统中的替换策略确定逐出哪个页面。从历史上看，这是早期虚拟内存系统做出的最重要的决定之一，因为旧的系统只有很少的物理内存。至少，这是一组有趣的策略，值得更多地了解。因此，我们的问题是： THE CRUX: HOW TO DECIDE WHICH PAGE TO EVICTHow can the OS decide which page (or pages) to evict from memory? This decision is made by the replacement policy of the system, which usually follows some general principles (discussed below) but also includes certain tweaks to avoid corner-case behaviors. 缓存管理Cache Management 在深入讨论策略之前，我们首先详细描述我们要解决的问题。假设主内存保存系统中所有页面的一些子集，那么可以正确地将其视为系统中虚拟内存页面的高速缓存(cache)。因此，我们为该高速缓存选择替换策略的目标是最小化高速缓存丢失(cache miss)的次数，即最小化我们必须从磁盘获取页面的次数。或，可以将我们的目标视为最大化高速缓存命中(cache hit)的次数，即在内存中找到被访问的页面的次数。 知道高速缓存命中和未命中的数量后，我们就可以计算程序的平均内存访问时间(average memory access time, AMAT)。具体来说，给定这些值，我们可以计算程序的AMAT： AMAT=T_{M}+(P_{miss}*T_{D}) T_{M}: 表示访问内存的成本 T_{D}: 表示访问磁盘的成本 P_{miss}: 表示在高速缓存中找不到数据的可能性(未命中)，在0.0-1.0之间变化，有时我们使用百分比来表示 请注意，您始终要支付访问内存中数据的费用。但是，当您错过时，您必须另外支付从磁盘中获取数据的费用。 例如，让我们想象一下一个具有微小地址空间的机器：4KB，具有256Bytes的页面。因此，虚拟地址的两个部分：4为VPN（最高有效位）和8位偏移（最低有效位）。因此，此示例中的进程可以访问2^4=16个虚拟页面。在此示例中，该进程生成如下内存引用（即，虚拟地址）：0x000, 0x100, 0x200, 0x300, 0x400, 0x500, 0x600, 0x700, 0x800, 0x900。这些虚拟地址指的是地址空间的前十个页面中每个页面的第一个字节。让我们进一步假设除虚拟页面3之外的每个页面都已经在内存中。因此，我们的内存引用序列将遇到以下行为：hit, hit, hit, miss, hit, hit, hit, hit, hit, hit。我们可以计算出命中率为90%，而未命中率为10%。 要计算AMAT，我们需要知道访问内存的成本和访问磁盘的成本。假设访问内存的成本约为100ns，访问磁盘的成文约为10ms。AMAT=100ns+(0.1*10ms)=1.0001ms，大约为1ms。如果我们的命中率很高(99.9%)，则结果将快100倍。 不幸的时，正如您所看到的那样，现代系统中磁盘访问的成本如此之高，以至于即使是很小的未命中也将很快主导正在运行的程序的整体AMAT。显然，我们需要以磁盘速度避免尽可能多的丢失。 最优替换策略The Optimal Replacement Policy 为了更好地了解特定替换策略的工作原理，最好将其与最佳替换策略进行比较。事实证明，这样的最优策略是Belady多年前开发的（最初称为MIN）。最佳的提花策略导致总体上的遗漏最少。一种简单的方法（不幸的是，实现起来很困难）替代了将来被最远访问(furthest in the future)的页面，这是最佳策略，从而导致了最少的高速缓存丢失。 最优策略背后的直觉是有意义的。如果您必须扔掉一些页面，为什么不扔掉从现在开始最远的那一页呢？这样，您实际上是在说高速缓存中的所有其它页面比最远的页面更重要。这个原因很简单：在引用最远的内容之前，您将显先引用其它页面。 让我们通过一个简单的示例进行追踪，以了解最优策略的决策。假设程序访问以下虚拟页面流：0, 1, 2, 0, 1, 3, 0, 3, 1, 2, 1。图22-1显示了优化的行为，假设缓存是很三个页面。 在该图中，您可以看到以下操作。毫不奇怪，由于高速缓存以空状态(empty state)开始，因此前三个访问是未命中。有时将这种丢失称为冷启动丢失(cold-start miss)（或强制丢失, compulsory miss）。然后，我们再次引用页面0和1，它们都在缓存中命中。最后，我们遇到另一个未命中的问题(page 3)，但这次缓存已满。必须进行替换！我们应该替换哪个页面？使用最佳策略，我们检查缓存中当前每个页面的未来(0, 1, 2)，发现几乎立即要访问0，稍后再访问1，将来访问最远的2。因此，最佳策略有一个简单的选择：逐出2，在缓存中生成0, 1, 3。接下来的三个引用会命中，但随后我们转到了之前逐出的2，但遭到了另一个丢失。在这，最佳策略再次检查缓存中每个页面(0, 1, 3)的未来，并发现只要不逐出页面1（将要访问的页面）就可以了。该示例显示page 3被驱逐，尽管page 0也是一个不错的选择。最后，我们命中page 1，追踪完成。 我们还可以计算缓存的命中率：6 hits and 5 misses， 6/(6+5)=54.5%。您还可以计算强制丢失的命中率（即，忽略给定页面的第一个丢失），得出的命中率为85.7%。 不幸的是，正如我们之前在指定调度策略中所看到的那样，未来并不为人所知。您无法为通用操作系统构建最佳策略。因此，在指定实际的、可部署的策略时，我们将集中于找到其它方法来确定要逐出哪个页面。因此，最优策略将仅用作比较，以了解我们与完美的距离。 TIP: COMPARING AGAINST OPTIMAL IS USEFULAlthough optimal is not very practical as a real policy, it is incredibly useful as a comparison point in simulation or other studies. Saying thatyour fancy new algorithm has a 80% hit rate isn’t meaningful in isolation; saying that optimal achieves an 82% hit rate (and thus your new approach is quite close to optimal) makes the result more meaningful and gives it context. Thus, in any study you perform, knowing what the optimal is lets you perform a better comparison, showing how much improvement is still possible, and also when you can stop making your policy better, because it is close enough to the ideal. ASIDE: TYPES OF CACHE MISSESIn the computer architecture world, architects sometimes find it useful to characterize misses by type, into one of three categories: compulsory, capacity, and conflict misses, sometimes called the Three C’s [H87]. A compulsory miss (or cold-start miss [EF78]) occurs because the cache isempty to begin with and this is the first eference to the item; in contrast, a capacity miss occurs because the cache ran out of space and had to evict an item to bring a new item into the cache. The third type of miss (a conflict miss) arises in hardware because of limits on where an item can be placed in a hardware cache, due to something known as setassociativity; it does not arise in the OS page cache because such caches are always fully-associative, i.e., there are no restrictions on where in memory a page can be placed. See HP for details [HP06]. 先进先出策略A Simple Policy: FIFO 许多早期的系统避免了尝试达到最佳状态的复杂性，并采用了非常简单的替换策略。例如，某些系统使用了先进先出(first-in, first-out FIFO)替换，将页面在进入系统时仅放入队列中。当发生替换时，队列尾部的页面（先进入的页面）将被逐出。FIFO具有强大的优势：实现起来非常简单。FIFO有一个强大的优势：实现起来非常简单。让我们研究一下FIFO在引用流中的作用，如图2-2。 我们再次从三个强制性丢失开始追踪，分别指向page 0, 1, 2，然后同时命中0和1。接下来，引用3，从而导致丢失。使用FIFO可以很容易地决定替换：选择作为先进入的第一个页面(page 0)。不幸的是，我们的下一个访问页面是page 0，从而导致另一个丢失和替换。然后，我们在3上命中，但在1和2上丢失，最后在3上命中。 将FIFO与最优进行比较，FIFO明显更糟：命中率为36.4%（不包括强制性丢失为57.1%）。先进先出根本无法确定块的重要性：即使page 0已被访问过多次，但FIFO仍将其踢出去，原因仅在于它是第一个进入内存的页面。 ASIDE: BELADY’S ANOMALYBelady (of the optimal policy) and colleagues found an interesting reference stream that behaved a little unexpectedly [BNS69]. The memoryreference stream: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5. The replacement policy they were studying was FIFO. The interesting part: how the cache hit rate changed when moving from a cache size of 3 to 4 pages.In general, you would expect the cache hit rate to increase (get better) when the cache gets larger. But in this case, with FIFO, it gets worse! Calculate the hits and misses yourself and see. This odd behavior is generally referred to as Belady’s Anomaly (to the chagrin of his co-authors).Some other policies, such as LRU, don’t suffer from this problem. Can you guess why? As it turns out, LRU has what is known as a stack property [M+70]. For algorithms with this property, a cache of size N + 1 naturally includes the contents of a cache of size N. Thus, when increasing the cache size, hit rate will either stay the same or improve. FIFO and Random (among others) clearly do not obey the stack property, and thus are susceptible to anomalous behavior. 其它简单策略：随机Another Simple Policy: Random 另一个类似的替换策略是随机(Random)，它只是在内存压力下仅选择一个随机页面进行替换。随机具有类似于FIFO的属性，实施起来很简单，但是在选择块驱逐时并没有太聪明。让我们看一下随机策略的效果，如图22-3。 当然，随机策略的表现完全取决于随机在其选择中的幸运度（或，不幸运度）。实际上，我们可以运行随机策略数千次，并确定其总体性能图22-4显示了随机进行一万多次实验的命中次数，每个实验都有不同的随机种子。如您所见，有时随机策略的效果最佳，有时效果会更差。随机策略的表现取决于抽奖的运气。 使用历史记录Using History: LRU(Least Rcently Used) 不幸的是，任何诸如FIFO或Random这样简单的策略都有可能会遇到一个普遍的问题：它可能会剔出一个重要的页面，该页面将再次被引用。FIFO踢出最先进入的页面，如果此页面上恰好有重要代码或数据结构，则无论如何都会被扔掉，即使它很快会被重新分页。因此，FIFO、Random和其它类似策略不太可能达到最佳状态。需要更聪明的东西。 与调度策略一样，为了提高对未来的猜测，我们再次依赖过去(past)，并以历史(history)为指导。例如，如果某个程序在近期访问过某个页面，则很可能在不久的将来再次访问该页面。 页面替换策略可以使用的一种历史信息是频率(frequency)。如果某个页面已被多次访问，则可能不应该替换该页面，因为它显然具有某些价值。页面最常用的属性是页面的访问频率。访问页面的时间越近，也许再次访问该页面的可能性就越大。 这一系列策略基于人们所说的本地性原则(principle of locality)，基本上只是对程序及其行为的观察。这个原理的意思很简单，就是程序倾向于非常频繁地访问某些代码序列和数据结构。因此，我们应尝试使用历史记录找出哪些页面很重要，并在驱逐时间(eviction time)将这些页面保留在内存中。 因此，诞生了一系列简单的基于历史的算法。最不常使用(Least Frenquently Used, LFU)策略将在必须进行逐出时替换最不常用的页面。同样，最近最少使用(Least Recently Used, LRU)策略替换了最近最少使用的页面。这些算法很容易记住，一旦知道名词，就确切知道它的作用。 为了更好地了解LRU，让我们检查一下LRU的表现。如图22-5。从图中可以看到，LRU如何使用历史记录来比无状态策略（如FIFO、Random）做得更好。 我们还应注意到，这些算法存在相反的情况：最常用(Most Frequently Used, MFU)和最近使用(Most Recently Used, MRU)。在大多数情况下，这些策略效果不佳，因为它们忽略了大多数程序所展示的位置，而不是拥抱(embracing)它。 ASIDE: TYPES OF LOCALITYThere are two types of locality that programs tend to exhibit. The first is known as spatial locality, which states that if a page P is accessed, it is likely the pages around it (say P − 1 or P + 1) will also likely be accessed. The second is temporal locality, which states that pages that have been accessed in the near past are likely to be accessed again in the near future. The assumption of the presence of these types of locality plays a large role in the caching hierarchies of hardware systems, which deploy many levels of instruction, data, and address-translation caching to help programs run fast when such locality exists.Of course, the principle of locality, as it is often called, is no hard-andfast rule that all programs must obey. Indeed, some programs access memory (or disk) in rather random fashion and don’t exhibit much or any locality in their access streams. Thus, while locality is a good thing to keep in mind while designing caches of any kind (hardware or software), it does not guarantee success. Rather, it is a heuristic that often proves useful in the design of computer systems. 工作负载Workload Examples 让我们再看几个栗子，以更好地理解其中一些策略的行为。在这里，我们将研究更复杂的工作负载，而不是细小的痕迹。但是，即使是这些工作量也大大简化。更好的研究应该包括应用程序追踪。 我们的第一个工作负载没有局部性，这意味着每个引用都是针对所访问页面集合的随机页面。在这个简单示例中，工作负载会随着时间访问100个唯一的页面，选择下一个页面进行随机引用。总共访问一万个页面。在实验中，我们将缓存大小从很小(1)更改为足以容纳所有唯一页面(100)，以查看每种策略在缓存大小范围内的行为。 图22-6显示了最优、LRU、Random、FIFO的实验结果。我们可从图中得出许多结论。首先，当工作负载没有局限性时，使用哪种实际策略都无关紧要。它们都执行相同的操作，命中率完全由缓存的大小确定。其次，当缓存足够大以适合整个工作负载时，使用哪种策略页无关紧要。当所有引用的块都放入高速缓存中时，所有策略都收敛到100%的命中率。最后，您可以看到最优执行比实际策略要好得多。 我们检查的下一个工作负载称为80-20工作负载，它有局部性：80%的引用指向20%的页面(the hot pages)，区域20%的引用指向其余80%的页面(the cold pages)。在我们的工作量中，共有100个唯一页面。因此，热页面是大多数时候都引用的页面，冷页面是其余页面。图22-7显示了策略在此工作负载下的执行情况。 从图中可以看出，尽管Random和FIFO都表现不错，但LRU表现更好，因为它更有可能保留在热页面上。由于这些页面在过去经常被引用，因此它们可能会在不久的将来在此被引用。优化策略再一次做的更好，表明LRU的历史的并不完美。 您现在可能想知道：LRU对Random和FIFO的改进真的有那么大的意义吗？答案通常是取决于情况。如果每个丢失的代价都很高（并不罕见），那么命中率的小幅度提高也会对性能产生巨大的影响。如果丢失不是那么昂贵，那么LRU可能带来的好处当然就不那么重要了。 让我们来看一个最终的工作负载，我们称其为循环顺序(looping sequential)工作负载 ，其中，我们依次引用了50个页面，从0、1…一直到49。然后我们循环、重复进行这些访问。总共一万次访问50个唯一页面。图22-8的最后一个图显示了此工作负载下的行为。 在许多应用程序中常见的这种工作量对于LRU和FIFO都是最坏的情况。在循环顺序的工作量下，这些算法会淘汰旧页面。不幸的是，由于工作负载的循环性质，这些旧页面的访问时间将比策略希望保留在缓存中的页面要早。确实，即使使用大小为49的缓存，循环顺序的50页工作负载也导致命中率为0%。有趣的是，Random明显更好，没有达到最佳状态，但至少达到了非零的命中率。事实证明，Random有一些不错的特性。这样的属性之一就是没有奇怪的极端情况行为。 实施历史算法Implementing Historical Algorithms 如您所见，诸如LRU之类的算法通常可以比诸如FIFO或Random之类的简单策略做的更好，后者可能会抛出重要页面。不幸的是，历史记录策略给我们带来了新的挑战：我们如何执行它们？ 以LRU为例。要完美实现它，我们需要做很多工作。具体而言，在每次页面访问(page access)时，我们都必须更新某些数据结构，以将该页面移至列表的开头。将此与FIFO进行对比，仅当逐出页面或将新页面添加到列表中时，才访问FIFO页面列表。为了追踪使用最少的页面、最近使用的页面，系统必须对每个内存引用(every memory reference)进行一些统计工作。显然，如果不加小心，这种统计可能会大大降低性能。 可以帮助加快速度的一种方法是添加一点硬件支持。例如，一台机器可以在每次访问页面时更新内存中的时间字段。因此，当访问页面时，硬件将当前时间设置为时间字段的值。然后，在替换页面时，操作系统可以简单地扫描系统中的所有时间字段以找到最近最少使用的页面。 不幸的是，随着系统中页面数量的增长，扫描大量的时间来查找最近最少使用的绝对页面的成本过高。想象一下，一台具有4GB内存的现代机器，它被切成4KB的页面，这台机器有100万页面。即使在现代CPU速度下，查找LRU也将花费很长时间。我们真的需要找到绝对最旧的页面来替换吗？我们可以近似地生存吗？ CRUX: HOW TO IMPLEMENT AN LRU REPLACEMENT POLICYGiven that it will be expensive to implement perfect LRU, can we approximate it in some way, and still obtain the desired behavior? 近似地LRUApproximating LRU 事实证明，答案是肯定的：从计算开销的角度来看，近似地LRU更可行，而实际上这是许多现代系统所做的。这个想法需要硬件支持，使用位(use bit)（有时称为参考位(reference bit)）的形式。系统每页有一个使用位，这些使用位生活在内存中的某个位置（它们可以在每个进程的分页表中，也可以仅在数组中的某个位置）。每当引用页面时，使用位都会由硬件设置位1.尽管硬件也不会清除该位。这是操作系统的责任。 操作系统如何用使用位(use bit)来近似LRU？可能有很多方法，但是对于时钟算法(clock algorithm)，建议一种简单的方法。想象一下以循环列表排列的系统的所有页面。clock hand指向某个特定的页面。当必须进行替换时，操作系统会检查当前指向的page P的使用位是1还是0.如果为1，则表明页面P最近被使用过，因此不是很好的替换对象。因此，P的使用位被设置为0，并且时针增加到下一页(P+1)。该算法继续进行，直到找到设置为0的使用位，这表明该页面最近未使用过。 注意，该方法不是采用使用位来近似LRU的唯一方法。实际上，任何定期清除使用位，然后区分哪些页面的使用位是1还是0来决定替换哪个页面的方法都可以。时钟算法只是一种早期的方法，取得了一些成功，并且具有不重复扫描所有内存以查找未使用页面的优点。 时钟算法变体的行为如图22-9所示。进行替换时，此变体会随机扫描页面。当遇到参考位设置为1的页面时，清除该位（将其设置为0）。当找到参考位设置位0的页面时，将其选择为牺牲品。如您所见，尽管它的LRU效果不如LRU完美，但比完全不考虑历史记录的方法要好。 脏页Considering Dirty Pages 通常对时钟算法的一个小修改是对内存中的页面是否已修改的其它考虑。这样做的原因是：如果页面已被修改(dirty)，则必须将其写回磁盘以驱逐它，这很昂贵。如果尚未修改(clean)，则驱逐是免费的。物理帧可以简单地重用于其它目的，而无需额外的I/0。因此，某些虚拟内存系统更喜欢将干净的页面移出脏页。 为支持此行为，硬件应包括一个修改后的位(modified bit, 又称dirty bit)。每次写入页面时都会设置此位，因此可以将其合并到页面替换算法中。例如，可以通过更改时钟算法，以扫描未使用的页面和干净的页面以优先逐出。找不到这些，然后找到脏的未使用的页面，依此类推。 其它虚拟内存策略Other VM Policies 页面替换不是虚拟内存子系统采用的唯一策略（尽管它可能是最重要的）。例如，操作系统还必须决定何时将页面放入内存。该策略有时称为页面选择(page selection)策略，它为操作系统提供了一些不同的选项。 对于大多数页面，操作系统仅使用按需分页(demand page)，这意味着操作系统在访问页面时将页面按需地带入内存。当然，操作系统可能会猜测将要使用一个页面，从而提前将其带入内存。这种行为称为预取(prefetching)，只有在有合理的成功机会时才应该这样做。例如，某些系统假定，如果将代码页P带入内存中，则该代码页(P+1)可能很快就会被访问，因此也应将其放入内存中。 另一个策略确定操作系统如何将页面写出到磁盘。当然，可以一次将它们写出来。但是，许多系统会在内存中收集大量待处理的写入，然后通过一次写入(更高效)将它们写入磁盘。此行为通常称为集群(clustering)或写操作的简单分组(grouping of writes)，并且由于磁盘驱动器的性质有效，因为磁盘驱动器必许多小型驱动器更有效地执行单个大型写入。 ThrashingThrashing 在结束之前，我们要解决一个最后的问题：如果仅是简单地过度地使用内存，并且正在运行的进程集合的内存需求仅超过可用的物理内存时，操作系统应该怎么做？在这种情况下，系统将不断进行分页，这种情况有时被称为颠簸(thrashing)。 一些较早的操作系统具有一套相当复杂的机制，可以在发生颠簸时检测并应对颠簸。例如，给定一组进程，系统可以决定不运行进程的子集，希望减少进程的工作集(working sets)的适合内存并因此可以取得进展。这种通常被称为准入控制(admission control)的方法指出，有时做好一些工作总比尝试一次做不好所有事情要好。，这是现实生活中以及现代操作系统中经常遇到的一种情况。 一些当前的系统对内存过载(memory overload)采取了更为严格的方法。例如，某些版本的Linux在内存超额(oversubscribed)时运行out of memory killer。此守护进程选择一个内存密集型(memory intensive)进程并将其终止，从而以一种不太微妙的方式减少了内存。在成功减少了内存压力的同时，此方法可能会遇到问题。例如，如果它终止了X Server，从而使任何需要显示(display)的应用程序无法使用。 总结Summary 我们已经看到了许多页面替换策略的引入，它们是所有现代操作系统的虚拟内存子系统的一部分。现代系统对简单的LRU近似值进行了一些调整。例如，扫描电阻(scan resistance)是许多现代算法（如，ARC）的重要组成部分。它类似于LRU，但也尝试避免LRU的最坏情况行为，这在循环顺序工作负载中可以看到。因此，页面替换算法的发展还将继续。 但是，在许多情况下，随着内存访问时间和磁盘访问时间之间的差异增加，所述算法的重要性降低了。因为分页到磁盘是如此昂贵，所以频繁地分页的成本令人望而却步。因此，过度分页的最佳解决方案通常是一种简单的方法：购买更多内存。 完整的虚拟内存系统Complete Virtual Memory Systems: http://pages.cs.wisc.edu/~remzi/OSTEP/vm-complete.pdf 在结束对内存虚拟化的研究之前，让我们仔细研究一下如何将整个虚拟内存系统组合在一起。我们已经看到了此类系统的关键要素，包括众多的分页表设计、与TLB的交互、确定哪些页面要保留在内存中以及哪些页面应该被踢出去的策略。但是，还有许多其它功能可以构成一个完整的虚拟内存系统，包括许多用于性能、功能和安全性的功能。 THE CRUX: HOW TO BUILD A COMPLETE VM SYSTEMWhat features are needed to realize a complete virtual memory system? How do they improve performance, increase security, or otherwise improve the system? 我们将介绍两个系统来完成此操作。第一个是1970年代早期开发的VAX/VMS操作系统中发现的现代虚拟内存管理器的最早示例之一。直到今天，这种系统中无数的技术和方法一直存在，因此值得研究。第二个是Linux，原因显而易见。Linux是一种广泛使用的系统，可以在像电话这样的小型且功能不足的系统上有效运行，而该系统却不像现代数据中心中可扩展性最高的多核系统那样。因此，虚拟内存操作系统必须足够灵活才能在所有这些情况下成功运行。我们将讨论每个系统，以说明前面几章提出的概念如何在完整的内存管理器中结合在一起。 VAX/VMS虚拟内存VAX/VMS Virtual Memory VAX-11微型计算机体系结构是由Digital Equipment Corporation(DEC)在1970年代末期引入的。在小型计算机时代，DEC在计算机行业扮演着重要的角色。该体系结构通过多种方式实现，包括VAX-11/780和较弱的VAX-11/750。 该系统称为VAX/VMS，其主要架构师之一有Dave Cutler，他后来领带开发了Microsoft Windows NT。VMS存在一个普遍的问题，那就是它可以在各种机器上运行，包括非常便宜的VAXen到同一体系结构家族中的高端机器和功能强大的机器。因此，操作系统必须具有能够在如此庞大的系统范围内运行的机制和策略。 作为一个附加问题，VMS用于隐藏体系结构某些固有缺陷的软件创新的一个很好的栗子。尽管操作系统通常依靠硬件来构建有效的抽象和错觉，但有时硬件设计人员并不能完全正确地完成所有工作。 内存管理硬件(Memory Management Hardware) VAX-11为每个进程提供了32位虚拟地址空间，分为512-byte pages。因此，虚拟地址由23位VPN和9位偏移量组成。此外，VPN的高两位用来区分页面驻留在哪个段中。因此，如前所述，该系统是分页(paging)和分段(segmentation)的混合体。 地址空间的下半部分被称为进程空间(process space)，并且对每个进程都是唯一的。在进程空间的前半部分中(称为P0)，找到了用户程序以及向下增长的堆(heap)。在进程空间的后半部分(P1)，我们找到了向上增长的栈(stack)。地址空间的上半部分称为系统空间(system space, S)，尽管仅使用了一半。受保护的操作系统代码和数据位于此处，并且操作系统以这种方式在进程之间共享。VMS设计人员的一个主要问题是VAX硬件中的页面大小极小(512Bytes)。由于历史原因而选择此大小，其基本问题是使简单的线性分页表过大。因此，VMS设计人员的首要目标之一就是确保VMS不会因分页表而淹没(overwhelm)内存。 系统通过两种方式减少了内存中压力分页表的位置(reduced the pressure page tables place)。首先，通过分段将用户地址空间分成两部分，VAX 11为每个进程的的区域(P0和P1)提供了一个分页表。因此，在栈和堆之间的地址空间的未使用部分不需要分页表空间。the base and bounds registers按预期使用。base registers保存该段的分页表地址，boungds register保存其大小（即，分页表条目的数量）。 其次，操作系统通过将用户分页表(P0和P1，因此每个进程有两个)放置在内核虚拟系统中，从而进一步降低了内存压力。因此，当分配和增加分页表时，内核会在Segment S中从自己的虚拟内存中分配空间。如果内存承受这巨大的压力，内核可以将这些分页表的分页换(out to)到磁盘上，从而使物理内存对其它用途可用。 将分页表放入内核虚拟内存(kernel virtual memory)意味着地址转换更加复杂。例如，要转换P0和P1中的虚拟地址，硬件必须首先尝试在其分页表（该进程的P0和P1）中查找该页面的分页表条目。但是，这样做，硬件可能首先必须查询系统分页表（位于物理内存中）。完成转换后，硬件可以了解分页表的页面地址，然后最终了解所需的内存访问地址。幸运的是，VAX的硬件管理的TLB使所有这些操作变得更快，这些TLB通常(希望)绕过这种费力的查找。 ASIDE: THE CURSE OF GENERALITYOperating systems often have a problem known as the curse of generality, where they are tasked with general support for a broad class of applications and systems. The fundamental result of the curse is that the OS is not likely to support any one installation very well. In the case of VMS, the curse was very real, as the VAX-11 architecture was realized in a number of different implementations. It is no less real today, where Linux is expected to run well on your phone, a TV set-top box, a laptop computer, desktop computer, and a high-end server running thousands of processes in a cloud-based datacenter. 真实的地址空间(A Real Address Space) 研究VMS的一个巧妙方面是，我们可以看到如何构造真正的地址空间（如图23-1）。到目前为止，我们已经假定了一个仅包含用户代码、用户数据、用户堆的简单地址空间，但是正如我们在上面看到的，实际的地址空间要复杂的多。 例如，代码段从不从page 0开始。该页面被标记为不可访问(inaccessible)，以便为检测空指针(null pointer)访问提供一些支持。因此，在设计地址空间时需要考虑的一个问题是调试的支持，此处无法访问的page 0以某种形式提供了调试。 也许更重要的是，内核虚拟地址空间（即其数据结构和代码）是每个用户地址空间的一部分。在上下文切换中，操作系统将P0和P1寄存器更改为指向即将运行(soon-to-be-run)的进程的相应分页表。但是，它不会更改S base and bounds registers。因此，相同内核结构并映射到每个用户地址空间。 出于多种原因，内核被映射到每个地址空间。这种构造使内核的工作轻松。例如，当操作系统收到来自用户程序的指针（如，write()系统调用）时，很容易将数据从该指针复制到自己的结构中。操作系统是自然编写和编译的，无需担心其访问的数据来自何处。相反，如果内核完全位于物理内存中，则很难进行诸如将分页表的页面交换到(swap)磁盘的操作。如果给内核提供了自己的地址空间，则在用户应用程序和内核之间移动数据将再次变得复杂而痛苦。通过这种构造(construction)（现已被广泛使用），内核几乎是应用程序的库(library)，尽管它是受保护的。 关于该地址空间的最后一点与保护有关。显然，操作系统不希望用户程序读取或写入操作系统数据和代码。因此，硬件必须支持页面的不同保护级别才能启用此功能。VAX通过在分页表中的保护位中指定CPU必须处于什么特权级别才能访问特定页面来做到这一点。因此，与用户数据和代码相比，将系统数据和代码设置为更高的保护级别。试图从用户代码访问此类信息将在操作系统中生成陷阱(trap)，并且可能会终止违规进程。 ASIDE: WHY NULL POINTER ACCESSES CAUSE SEG FAULTSYou should now have a good understanding of exactly what happens on a null-pointer dereference. A process generates a virtual address of 0, by doing something like this。The hardware tries to look up the VPN (also 0 here) in the TLB, and suffers a TLB miss. The page table is consulted, and the entry for VPN 0 is found to be marked invalid. Thus, we have an invalid access, which transfers control to the OS, which likely terminates the process (on UNIX systems, processes are sent a signal which allows them to react to such a fault; if uncaught, however, the process is killed). 12int *p = NULL; // set p = 0*p = 10; // try to store 10 to virtual addr 0 页面替换(Page Replacement) VAN中的分页表条目(PTE)包含以下位：有效位(a valid bit), 保护字段(protection bit 4 bits), 修改(脏)位(modify/dirty bit), 保留给操作系统使用的字段(5 bits), 将页面的位置存储在物理内存中的物理帧号(PFN)。机敏的读者可能会注意到：没有引用位(reference bit)！因此，VMS替换算法必须在没有硬件支持的情况下确定哪些页面处于活动状态。 开发人员还担心内存消耗(memory hogs)，程序占用大量内存，并使其它程序难以运行。迄今为止，我们研究的大多数策略都容易受到这种束缚。例如，LRU是一项全局策略，它不会在进程之间公平地共享内存。 ASIDE: EMULATING REFERENCE BITSAs it turns out, you don’t need a hardware reference bit in order to get some notion of which pages are in use in a system. In fact, in the early 1980’s, Babaoglu and Joy showed that protection bits on the VAX can be used to emulate reference bits [BJ81]. The basic idea: if you want to gain some understanding of which pages are actively being used in a system, mark all of the pages in the page table as inaccessible (but keep around the information as to which pages are really accessible by the process, perhaps in the “reserved OS field” portion of the page table entry). When a process accesses a page, it will generate a trap into the OS; the OS will then check if the page really should be accessible, and if so, revert the page to its normal protections (e.g., read-only, or read-write). At the time of a replacement, the OS can check which pages remain marked inaccessible, and thus get an idea of which pages have not been recently used.The key to this “emulation” of reference bits is reducing overhead while still obtaining a good idea of page usage. The OS must not be too aggressive in marking pages inaccessible, or overhead would be too high. The OS also must not be too passive in such marking, or all pages will end up referenced; the OS will again have no good idea which page to evict. 为了解决这两个问题，开发人员提出了分段FIFO替换策略(segmented FIFO)。这个想法很简单：每个进程最多可以保留在内存中的页面数称为驻留集大小(resident set size, RSS)。这些页面的每一个都保存在FIFO列表中。当进程超出其RSS时，将驱逐先进入(first-in)页面。FIFO显然不需要任何硬件的支持，因此易于实现。 当然，如我们先前所见，纯FIFO的性能不是特别好。为了提高FIFO的性能，VMS引入了两种第二机会列表(second chance lists)，在从内存中逐出页面之前先放置页面，特别是a global clean-page free list和dirty-page list。当进程P超过其RSS时，将从每个进程的FIFO中删除页面。如果是干净的(未修改)，则将其放在干净页面列表的末尾。如果是脏的(已修改)，则将其放在脏页列表的末尾。 如果另一个进程Q需要一个空闲页，它将第一个空闲页从全局干净列表中删除。但是，如果原始进程P在被回收之前在该页面上出错，则P从空闲（或脏）列表中回收该进程，从而避免了昂贵的磁盘访问。全局第二机会列表越大，分段FIFO算法对LRU的执行越接近。 VMS中使用的另一种优化还有助于克服VMS中较小的页面使用。特别是，使用如此小的页面(small pages)，交换过程中的磁盘I/O效率可能非常低，因为磁盘在进行大传输时表现更好。为了使swapping I/O更加有效，VMS添加了许多优化，但最重要的是集群(clustering)。通过集群，VMS将全局脏列表中的大批页面组合在一起，并一口气将它们写入磁盘（从而使它们干净）。在大多数现代系统中都使用集群，因为自由地将页面放置在交换空间的任何位置都可以使操作系统组页面(group pages)执行更少和更大的写入，从而提高性能。 其它整洁的技巧(Other Neat Tricks) VMS还有另外两个现在的标准技巧：demand zero, copy on write。现在我们来描述这些惰性优化。VMS中的一种惰性形式是页面需求归零(demand zeroing of pages)。为了更好地理解这一点，让我们考虑将页面添加到地址空间的示例，如，在堆中。在幼稚的实现中，操作系统通过在物理内存中查找页面并将其归零来响应将页面添加到堆中的请求，然后将其映射到您的地址空间。但是，幼稚的实现可能会付出高昂的代价，特别是如果该页面没有被进程使用的话。 当需求归零时，将页面添加到您的地址空间后，操作系统几乎不会执行任何工作。它将在分页表中放置一个条目，标记该页不可访问。如果该进程随后读取或写入页面，则会在操作系统中产生陷阱。处理陷阱时，操作系统会注意到这实际上是零需求页面。此时，操作系统完成了查找物理页面，将其归零并将其映射到进程的地址空间所需的工作。如果该进程从不访问该页面，则可以避免所有此类工作，从而可以将需求归零。 另一个很酷的优化是写时复制(copy on write, COW)。这个想法至少可以追溯到TENEX操作系统，它很简单：当操作系统需要将页面从一个地址空间复制到另一个地址空间，而不是复制它时，它可以将页面映射到目标地址空间并在两个地址空间中将其标记为只读。如果两个地址空间都只读取该页面，则不采取进一步的措施，因此操作系统实现了快速复制，而实际上没有移动任何数据。 但是，如果其中一个地址空间确实试图写入该页面，则它将触发操作系统的陷阱。然后，操作系统注意到该页面是COW页面，因此（懒惰地）分配一个新页面，用数据填充它，将此新页面映射到故障进程的地址空间中。然后，该进程继续进行，现在具有其页面的自己的私有副本。 出于多种原因，COW很有用。当然，任何类型的共享库都可以映射写时复制到许多进程的地址空间，从而节省了宝贵的内存空间。在Unix系统中，由于fork()和exec()的语义，COW更为重要。您可能还记得，fork()创建了调用程序地址空间的精确副本。如果地址空间较大，则运行此类复制的速度将很慢且数据密集。更糟的是，大多数地址空间被随后对exec()的调用所立即覆盖，该调用将调用进程的地址空间与即将执行的程序的地址空间覆盖在一起。通过代之以执行写时复制fork()，操作系统避免了很多不必要的复制，从而在提高性能的同时保留了正确的语义。 TIP: BE LAZYBeing lazy can be a virtue in both life as well as in operating systems. Laziness can put off work until later, which is beneficial within an OS for a number of reasons. First, putting off work might reduce the latency of the current operation, thus improving responsiveness; for example, operating systems often report that writes to a file succeeded immediately, and only write them to disk later in the background. Second, and more importantly, laziness sometimes obviates the need to do the work at all; for example, delaying a write until the file is deleted removes the need to do the write at all. Laziness is also good in life: for example, by putting off your OS project, you may find that the project specification bugs are worked out by your fellow classmates; however, the class project is unlikely to get canceled, so being too lazy may be problematic, leading to a late project, bad grade, and a sad professor. Don’t make professors sad! Linux虚拟内存系统The Linux Virtual Memory System 现在，我们将讨论Linux虚拟内存系统的一些更有趣的方面。Linux工程师解决了生产中遇到的实际问题，推动了Linux的发展。因此，大量功能已缓慢地集成到现在已完全可用的功能齐全的虚拟内存系统中。 虽然我们无法讨论Linux虚拟内存的各个方面，但我们将介绍最重要的方面，尤其是超出了经典的虚拟内存系统（如，VAX/VMS）的范围。我们还将强调Linux与旧系统之间的共性。 在本次讨论中，我们将重点介绍Linux for Intel x86。尽管Linux可以并且确实可以在许多不同的处理器结构上运行，但是x86上的Linux是其最主要和最重要的部署，因此也是我们关注的焦点。 The Linux Address Space 与其它现代操作系统一样，也与VAX/VMS类似，Linux虚拟地址空间由用户部分和内核部分组成。与其它系统一样，在上下文切换时，当前运行的用户部分的地址空间也会更改。跨进程的内核部分是相同的。与其它系统一样，在用户模式下运行的程序无法访问内核虚拟页面。只有陷入内核(trapping into the kernel)并转换为特权模式，才能访问此类内存。 用户部分(user portion)：user program code, stack, heap, other parts reside 内核部分(kernel prtion)：kernel code, stack, heap, other parts reside 在典型的32位Linux中(即具有32位虚拟地址空间的Linux)中，地址空间中的用户部分和内核部分之间的拆分发生在地址0xC0000000或地址空间的四分之三处。64位Linux的拆分方式相似，但略有不同。图23-2显示了典型(简化)的地址空间。 用户虚拟地址范围：0-0xBFFFFFFF 内核虚拟地址范围：0xC0000000-0xFFFFFFFF Linux的一个有趣的方面是它包含两种类型的内核虚拟地址。 第一种称为内核逻辑地址(kernel logic address)。这就是您需要考虑的内核的正常虚拟地址空间。为了获得更多这种类型的内存，内核代码仅需要调用kmalloc。大多数内核数据结构都存在于此，例如分页表，每个进程的内核栈等等。与系统中的其它大多数内存不同，内核逻辑内存无法交换到磁盘。 内核逻辑地址最有趣的方面使它们与物理内存的连接。具体而言，内核逻辑地址与物理内存的第一部分之间存在直接映射。因此，内核逻辑地址0xC0000000转换为物理地址0x00000000，0xC0000FFF转换为0x00000FFF，依此类推。这种直接映射有两个含义。首先，在内核逻辑地址和物理地址之间来回转换很简单。因此，这些地址通常被视为确实是物理地址。第二个问题是，如果一块内存在内核逻辑地址空间中是连续的，那么它在物理内存中也是连续的。这使得内核地址空间的此部分中分配的内存适合需要连续物理内存才能正常工作的操作，例如通过目录内存访问(directory memory access, DMA)与设备之间的I/O传输。 内核地址的另一种类型是内核虚拟地址(kernel virtual address)。为了获得这种类型的内存，内核代码调用了另一个分配器vmalloc，该分配器返回一个指向所需大小的虚拟连续区域的指针。与内核逻辑内存不同，内核虚拟内存通常是不连续的。每个内核虚拟页面都可以映射到不连续的物理页面（因此不适合DMA）。但是，这样的内存因此更易于分配，因此可用于大型缓冲区(large buffer)，这些缓冲区中查找连续的大块物理内存将非常困难。 在32位Linux中，存在内核虚拟地址的原因是，它们使内核能够寻址超过(大约)1GB的内存。几年前，计算机的内存远少于此，并且可以访问超过1GB的内存也不成问题。但是，技术进步了，很快就需要使内核能够使用更多的内存。内核虚拟地址以及严格的从一对一映射到物理内存的断开连接使之成为可能。但是，随着向64位Linux的迁移，这一需求已不再那么紧迫，因为内核不仅限于虚地址的的最后1GB。 分页表结构(Page Table Structure) 因为我们专注于x86的Linux，所以我们的讨论将集中在x86提供的分页表结构的类型上，因为它决定了Linux可以做什么和不能做什么。如前所述，x86提供了一种硬件管理的多层分页表结构，每个进程一个分页表。操作系统仅在其内存中设置映射，将特权寄存器指向页面目录的开始，然后由硬件处理其余部分。如预期那样，操作系统会参与进程创建、删除、上下文切换，请确保在每种情况下，硬件MMU都使用正确的分页表来执行转换。 如上所述，近年来最大的变化可能是从32位x86到64位x86的转变。正如在VAX/VMS系统中看到的那样，32位地址空间已经存在了很长时间，并且随着技术的变化，它们最终开始真正成为程序的限制。虚拟内存使对系统进行编程变得很容易，但是对于包含许多GB内存的现代系统而言，32位已不足以引用每个内存。因此，下一个飞跃变得很必要。 移至64位地址会以预期的方式影响x86中的分页表结构。由于x86使用多级分页表，因此当前的64位系统使用四级表(four level table)。虚拟地址空间的完整64位性质尚未使用，但是仅使用了最低的48位。因此，虚拟地址可以如下查看： 如图所示，虚拟地址的前16位未使用（因此在转换中不起作用），后12位（由于4KB页面大小）用作偏移量（直接使用，不进行转换），剩下的虚拟地址的中间36位将参与转换。地址的P1部分用于索引到最顶层的页面目录中，然后从那里开始一次转换级别，直到分页表的实际页面被P4索引为止，从而生成所需的分页表条目。 随着系统内存的增大，此庞大的地址空间的更多部分将被启用。从而导致五级分页表、六级分页表…想象一下，一个简单的分页表查找需要六级转换，只是要弄清楚某个数据在内存中的位置。 大页面支持(Large Page Support) Intel x86允许使用多种页面大小，而不仅仅是标准的4KB页面。具体而言，最近的设计在硬件上支持2MB甚至1GB的页面。因此，随着时间的流逝，Linux逐渐发展为允许应用程序利用这些巨大的页面(huge page)。 如前所述，使用大页面会带来很多好处。从VAX/VMS中可以看出，这样做可以减少分页表中所需的映射数。页面越大，映射越少。但是，较少的分页表条目并不是大页面背后的驱动力。相反，这是更好的TLB行为和相关的性能提升。当某个进程主动使用大量内存时，它将迅速用转换填充TLB。如果这些转换是针对4KB页面的，则只能访问少量的总内存，而不会导致TLB丢失。结果是，对于在具有大量GB内存的计算机上运行的现代大内存工作负载而言，这将带来明显的性能成本。最近的研究表明，某些应用程序将其周期的10%用于服务TLB丢失。 大页面允许进程通过使用更少的TLB插槽来访问大容量内存而不会TLB丢失，因此这是主要优势。但是，巨大的页面还有其它好处：较短的TLB丢失路径，这意味着当确实发生TLB丢失时，可以更快地提供服务。此外，分配可能非常快，这虽然很小但是有时很重要。 Linux对大页面的支持的一个有趣方面是它如何逐步完成的。刚开始，Linux开发人员直到这种支持仅对少数应用程序很重要，例如对性能有严格要求的大型数据库。因此，决定允许应用程序显式请求大页面的内存分配（通过mmap()或shmget()调用）。这样，大多数应用程序将不会受到影响。 最近，由于在许多应用程序中更常见的是需要更好的TLB行为，因此，Linux开发人员增加了透明的大页面支持。启用此功能后，操作系统会自动寻找分配大型页面（通常为2MB，但在某些系统上为1GB）的机会，而无需修改应用程序。 庞大的页面并非没有代价。潜在的最大成本是内部碎片(internal fragmentation)，即页面很大但是用稀疏的页面。这种浪费形式可以用很大但很少使用的页面填充内存。交换也不适用于大页面，有时会大大放大系统的I/O数量。分配的开销也可能不好。总的来说，有一件事很清楚：4KB的页面大小可以很好地服务于系统很多年，这并不是曾经的通用解决方案。不断增长的内存需求要求我们将大页面和其它解决方案视为VM系统必要发展的一部分。Linux对这种基于硬件的技术的缓慢采用证明了即将到来的变化。 页面缓存(The Page Cache) 为了降低访问持久化存储(persistent storage)的成本，大多数系统使用积极的缓存(caching)子系统将刘翔的数据项保留在内存中。在这方面，Linux与传统操作系统没有什么不同。 Linux页面缓存(page cache)是统一的，可以从三个主要来源将页面保留在内存中。这些实体保存在页面缓存哈希表中(page cache hash table)，以便在需要所述数据时进行快速查找。 内存映射文件(memory mapped files) 来自设备的文件数据(file data)和元数据(metadata)：通常通过将read()和write()调用定向到文件系统来访问 堆和栈(heap and stack)组成每个进程的页面：有时称为匿名内存(anonmous memory)，因为其下没有命名文件，而是交换空间 页面缓存追踪条目是干净的还是脏的。脏数据通过后台线程(称为pdflush)定期写入后备存储（即，写入文件的特定文件，或为匿名区域交换空间），从而确保最终将修改后的数据写回到持久性存储。此后台活动或者在特定时间段之后进行，或者如果认为太多页面是脏页面。 在某些情况下，系统的内存不足，Linux必须确定踢出内存的页面以释放空间。为此，Linux使用修改后的2Q替换，我们将在此进行描述。基本思想很简单：标准LRU替换是有效的，但是可以通过某些常见的访问模式来破坏。例如，如果某个进程重复访问一个大文件，则LRU会将所有其它文件踢出内存。更糟糕的是：将该文件的部分保留在内存中，因为在被踢出内存之前，它们从未被重新引用过。 Linux版本的2Q替换算法通过保留两个列表并在两个列表之间划分内存来解决此问题。首次访问时，页面被放在一个队列中（Linux中称为 inactive list）。重新引用该页面后，该页面将被提升到另一个队列（Linux中为active list）。当需要进行替换时，替换候选者将从不活跃列表中获取。Linux还定期将页面从活跃列表的底部移至不活跃列表，使活跃列表保持在页面高速缓存总大小的三分之二处。 Linux最好以完美的LRU顺序管理这些列表，但是，正如前面各章所讨论的那样，这样做非常昂贵。因此，与许多操作系统一样，使用LRU的近似值。 这种2Q方法的行为通常与LRU相当，但是特别地通过将周期性访问的页面限制在不活跃列表中来处理周期性大文件访问的情况。因为所述页面在被踢出内存之前从未被重新引用，所以它们不会清除活跃列表中找到的其它有用页面。 ASIDE: THE UBIQUITY OF MEMORY-MAPPINGMemory mapping predates Linux by some years, and is used in many places within Linux and other modern systems. The idea is simple: by calling mmap() on an already opened file descriptor, a process is returned a pointer to the beginning of a region of virtual memory where the contents of the file seem to be located. By then using that pointer, a process can access any part of the file with a simple pointer dereference.Accesses to parts of a memory-mapped file that have not yet been brought into memory trigger page faults, at which point the OS will page in the relevant data and make it accessible by updating the page table of the process accordingly (i.e., demand paging).Every regular Linux process uses memory-mapped files, even the code in main() does not call mmap() directly, because of how Linux loads code from the executable and shared library code into memory. Below is the (highly abbreviated) output of the pmap command line tool, which shows what different mapping comprise the virtual address space of a running program (the shell, in this example, tcsh). The output shows four columns: the virtual address of the mapping, its size, the protection bits of the region, and the source of the mapping:0000000000400000 372K r-x— tcsh00000000019d5000 1780K rw—- [anon ]00007f4e7cf06000 1792K r-x— libc-2.23.so00007f4e7d2d0000 36K r-x— libcrypt-2.23.so00007f4e7d508000 148K r-x— libtinfo.so.5.900007f4e7d731000 152K r-x— ld-2.23.so00007f4e7d932000 16K rw—- [stack ]As you can see from this output, the code from the tcsh binary, as well as code from libc, libcrypt, libtinfo, and code from the dynamic linker itself (ld.so) are all mapped into the address space. Also present are two anonymous regions, the heap (the second entry, labeled anon) and the stack (labeled stack). Memory-mapped files provide a straightforward and efficient way for the OS to construct a modern address space. 安全性和缓冲区溢出(Security And Buffer Overflows) 现代VM系统(Linux, Solaris, BSD)与旧VM系统(VAX/VMS)之间最大的区别可能是现代对安全性的重视。保护一直是操作系统的一个严重问题，但是随着计算机之间比以往任何时候都更加互联，开发人员实施了各种防御性对策以阻止哪些狡猾的黑客获得对系统的控制，这不足为奇。 缓冲区溢出(buffer overflow)攻击是一种主要威胁，可以用于普通用于程序，甚至内核本身。这些攻击的目的是在目标系统中发现一个漏洞，攻击者可以利用该漏洞将任意数据注入目标的地址空间。之所以会出现这种情况，是因为开发人员(错误地)认为输入不会太长，因此(可信地)将输入复制到缓冲区。因为输入实际上太长，所以它会使缓冲区溢出，从而覆盖目标的内存。如下所示的代码可能是问题的根源： 1234int some_function(char *input) &#123; char dest_buffer[100]; strcpy(dest_buffer, input); // oops, unbounded copy!&#125; 在许多情况下，这样的溢出并不是灾难性的。例如，无意中给用户程序甚至操作系统造成的错误输入都可能导致崩溃，但并不糟。但是，恶意程序员可以精心设计会使缓冲区溢出的输入，以便将自己的代码注入目标系统，从本质上允许他们接管并进行自己的竞标。如果在连接网络的用户程序上获得成功，则攻击者可以在受感染的系统上运行任意计算。如果在操作系统本身上获得成功，则攻击可以访问更多资源，并且是所谓的特权升级(privilege escalation)的一种形式（即，用户获得内核访问权限）。如果您无法猜测，这些都是坏事。 防止缓冲区溢出的第一个也是最简单的防御措施是防止执行在地址空间的某些区域中找到任何代码（如，栈内）。AMD在其x86版本中引入了NX bit，它是一种防御措施。它只是阻止从在相应分页表条目中设置了该位的任何页面执行。该方法可阻止攻击者注入到目标栈中的代码，从而减轻了问题。 但是，攻击者是聪明的。即使攻击者无法明确添加注入的代码，恶意代码也可以执行任意代码序列。这个想法以其一般的形式被称为面向返回的编程(return-oriented programming, ROP)，并且确实很棒。ROP背后的观察结果是，任何程序的地址空间中都有很多代码，尤其是与大量C库链接的C程序。因此，攻击者可以覆盖栈，以使当前执行功能中的返回地址指向所需的恶意指令，然后再返回指令。通过将大量小工具串在一起（即，确保每次返回都跳到下一个小工具），攻击者可以执行任意代码。 为了防御ROP，Linux添加了另一种防御，称为地址空间布局随机化(address space layout randomization, ASLR)。操作系统没有将代码、栈、堆放在虚拟地址空间内的固定位置上，而是将它们的放置位置随机化，从而使制作实现此类攻击所需的复杂代码变得颇具挑战性。因此，对易受攻击的用户程序的大多数攻击都将崩溃，但无法控制正在运行的程序。 有趣的是，您可以在实践中很容易地观察到这种随机性。这是一段在现代Linux系统上进行演示的代码： 12345int main(int argc, char *argv[]) &#123; int stack = 0; printf("%p\n", &amp;stack); return 0;&#125; 这段代码只是在栈上打印处变量的(虚拟)地址。在较旧的non-ASLR系统中，该值每次都相同。但是，如下所示，该值随每次运行而变化： 12345678prompt&gt; ./random0x7ffd3e55d2b4prompt&gt; ./random0x7ffe1033b8f4prompt&gt; ./random0x7ffe45522e94 ASLR是对用户级程序的一种有用防御措施，它还被并入内核，这是一种没有想象的功能，称为内核地址空间布局随机化(kernel address space layout randomization, KASLR)。但是，事实证明，内核可能还有更大的问题要处理。 Other Security Problems: Meltdown And Spectre 系统安全领域已经被两次新的相关攻击所颠覆。第一个称为崩溃(Meltdown)，第二个称为(Spectre)。它们是由四个不同的研究人员/工程师同时发现的，并引起了对上述计算机硬件和操作系统提供的基本保护的深切质疑。 这些攻击中每种漏洞利用的普遍缺点是，现代系统中发现的CPU会执行各种幕后花招，以提高性能。问题核心的一类技术称为推测执行(speculative execution)，其中CPU猜测将来会很快执行哪些指令，并提前开始执行它们。如果猜测正确，则程序运行速度更快；如果不是，则CPU再次尝试取消对架构状态（如，寄存器）的影响，这一次是正确的。 推测执行的问题在于，它倾向于在系统的各个部分（如，处理器缓存）中留下执行痕迹。因此，问题就来了：正如攻击者所表明的那样，这种状态会使内存的内容变得脆弱，甚至我们认为受MMU保护的内存也是如此。 因此，增加内核保护的一种方法是从每个用户进程中删除尽可能多的内核地址空间，而为大多数内核数据提供单独的内核分页表（kernel page table isolatio, KPTI)。因此，没有将内核的代码和数据结构映射到每个进程中，而是仅保留最小的最小值。当切换到内核时，现在需要切换到内核分页表。这样做可以提高安全性并避免某些攻击源，但是要付出代价：性能。切换分页表的成本很高。嗯，安全性成本：便利性和性能。 不幸的是，KPTI不能解决上面列出的所有安全问题，只是其中一些问题。而简单的解决方案（如，关闭推测）将毫无意义，因为系统运行速度会慢数千倍。因此，如果您需要系统安全，那么这是一个有趣的时代。 要真正了解这些攻击，您必须先学习很多知识。首先了解现代计算机体系结构，这是该主题的高级书籍中的内容，重点是推测以及实现该体系结构所需的所有机制。 总结现在，您已经看到了两个虚拟内存系统的从上到下(top-to-bottom)的回顾。希望大多数细节都易于理解，因为您应该已经对基本机制和政策有了很好的理解。您还了解了一些关于Linux的知识，尽管它是一个又大又复杂的系统，但它继承了过去的许多好主意，其中许多我们没有余地进行详细讨论。例如，Linux在fork()上执行页面的惰性写时复制(lazy copy-on-write)，从而通过避免不必要的复制来降低开销。Linux还要求将页面清零（使用/dev/zero设备的内存映射），并具有后台交换守护进程(swapd)，它将页面交换到磁盘以减少内存压力。 并发Concurrency 并发和线程Concurrency and Thread: http://pages.cs.wisc.edu/~remzi/OSTEP/threads-intro.pdf 到目前为止，我们已经看到了操作系统执行的基本抽象的发展。我们已经看到了如何采用单个物理CPU并将其转变为多个虚拟CPU，从而使人们幻想同时运行多个程序。我们还看到了如何为每个进程创建大型私有虚拟内存的错觉。当操作系统确实在物理内存之间秘密地复用地址空间时，地址空间的这种抽象使每个程序的行为就好像它具有自己的内存一样。 在本章中，我们为单个正在运行的进程引入了新的抽象——线程(thread)。多线程程序具有一个以上的执行点(point of execution)（如，多台PC，每台PC都从中获取并执行），而不是我们对程序中的单个执行点的经典观点（即，从中获取并执行指令的单个PC）。也许另一种思考方式是：每个线程都非常像一个单独进程，只是有一个区别——它们共享相同的地址空间，因此可以访问相同的数据。 单线程的状态与进程的状态非常相似。它具有一个程序计数器(program conter, PC)，用于追踪程序从哪里获取指令。每个线程都有自己的专用寄存器集(private set of registers)，用于计算。因此，如果在单个处理器上运行着两个线程，当从运行的T1切换到运行另一个T2时，必须进行上下文切换(context switch)。线程之间的下上文切换与进程之间的上下文切换非常相似，因为在运行T2之前必须保存T1的寄存器状态并恢复T2的寄存器状态。我们将进程的状态保存到进程控制块(process control block, PCB)，将线程的的状态保存到线程控制块(thread control block, TCB)。但是，线程的上下文切换与进程相比，有一个主要区别：线程的地址空间保持不变（即，无需切换我们正在使用的分页表）。 线程和进程之间的另一个主要区别在于栈(stack)。在经典的地址空间的简单模型（称其为单线程进程(single-threaded process)）中，有一个栈，通常位于地址空间的底部，如图16-2左侧。但是，在多线程进程(multi-threaded process)中，每个线程都独立运行，并且当然可以调用各种例程来执行其正在执行的任何工作。不同于地址空间中的单个栈，每个线程将有一个栈。假设我们有一个多线程进程，其中有两个线程，则它的地址空间看起来有所不同，如图26-1右侧。 在此图中，您可以看到两个栈分布在整个进程的地址空间中。因此，我们放在栈上的任何栈分配的变量(variables)、参数(parameters)、返回值(return values)和其它内容，都放置在有时称为线程局部存储(thread-local storage)的位置，即相关线程的栈中。 您可能还会注意到，这是如何破坏我们美丽的地址空间布局的。以前，栈和堆可以独立地增长，并且在地址空间不足时会出现麻烦。在这里，我们再也不会遇到这样的情况了。幸运的是，这通常时可以的。因为栈通常不必很大（例外是在大量使用递归的程序中）。 为什么要使用线程Why Use Threads? 在详细介绍线程以及编写多线程程序可能遇到的一些问题，让我们首先回答一个更简单的问题。为什么要完全使用线程？ 事实证明，使用线程至少有两个主要原因。第一个很简单：并行(parallelism)。想象一下，您正在编写一个非常大的数组执行操作的程序。如，将两个大数组加在一起，或者将数组中的每个元素的值增加一定量。如果仅在单处理器上运行，则任务很简单：只需执行每个操作即可。但是，如果要在具有多个处理器的系统上执行程序，则有可能通过使用处理器分别执行部分工作来大大加快此进程。将标准单线程程序转换为可在多个CPU上进行此类工作的程序的任务称为并行化(parallelization)，而使用每个CPU的线程来执行此工作是使程序在现代硬件上更快运行的自然而典型的方法。第二个原因更加微妙：避免由于I/O缓慢而阻塞程序进度。想象一下，您正在编写一个执行不同类型I/O的程序：等待发送或接受消息，完成显式磁盘I/O或隐式页面错误。您的程序可能希望执行其它操作，而不是等待，包括利用CPU执行计算，甚至发出其它I/O请求。使用线程是避免阻塞(block)的一个自然方法。当程序中的一些线程等待时（即被阻塞等待I/O时），CPU调度程序可以切换到其它线程，这些线程准备好运行并可以执行一些有用的操作。线程使I/O与单个程序中的其它活动重叠，就像多程序对跨程序的进程所做的一样。结果，许多现代的基于服务器的应用程序(Web, DB…)在其实现中都使用了线程。 当然，在上述情况下，您可以使用多进程取代多线程。但是，线程共享一个地址空间，因此很容易共享数据。因此在构造这些类型的程序时自然是一个选择。对于逻辑上独立的任务、对于几乎不需要共享内存中的数据结构的任务，进程是一个更合理的选择。 线程创建An Example: Thread Creation 让我们来探讨一些细节。假设我们要运行一个创建两个线程的程序，每个线程执行一些独立的工作，本例中打印A或B。代码如下所示： 1234567891011121314151617181920212223242526// Simple Thread Creation Code (t0.c)#include &lt;stdio.h&gt;#include &lt;assert.h&gt;#include &lt;pthread.h&gt;#include "common.h"#include "common_threads.h"void *mythread(void *arg) &#123; printf("%s\n", (char *) arg); return NULL;&#125;intmain(int argc, char *argv[]) &#123; pthread_t p1, p2; int rc; printf("main: begin\n"); Pthread_create(&amp;p1, NULL, mythread, "A"); Pthread_create(&amp;p2, NULL, mythread, "B"); // join waits for the threads to finish Pthread_join(p1, NULL); Pthread_join(p2, NULL); printf("main: end\n"); return 0;&#125; 创建两个线程（T1和T2）后，主线程(main thread)调用线程`join()，它等待特定线程完成。它执行两次，从而确保T1和T2在最终允许主线程再次运行之前可以运行并完成。总体而言，在此运行期间使用了三个线性:main,T1,T2`。 让我们检查一下这个程序的可能执行顺序。如执行图26-3中所示。 但是请注意，此排序不是唯一的排序。实际上，给定一系列指令，取决于调度程序决定在给定点运行哪个线程。例如，一旦创建线程，它可能立即运行，这将导致执行图26-4中所示的操作。 如果说调度程序决定先运行T2（即使T1是较早创建的），我们甚至还可以看到在A之前打印B。没有理由假定首先创建的线程将首先运行。图26-5显示了此最终执行顺序，其中T2在T1之前执行任务。 如您所见，思考线程创建的一种方法是它有点像运行函数调用。但是，系统不是先执行函数然后返回调用程序，而是为正在调用的例程创建一个新的执行线程，并且它独立于调用程序运行，可能在从创建返回之前，也有可能之后。接下来运行的内容由操作系统调度程序确定，尽管调度程序(scheduler)可能实现了一些明智的算法，但很难知道在任何给定的时间将运行什么。 从这个栗子中您还可以看出，线程使生活变得复杂。何时运行什么已经很难了！没有并发性(concurrency)，计算机就很难理解。不幸的是，并发只会使情况变得更糟。 为什么变得更糟：共享数据Why It Gets Worse: Shared Data 上面显示的简单线程示例对于显示线程的创建方式以及如何根据调度程序决定如何运行它们的顺序以不同的顺序运行很有用。但是，它并没有向您显示线程在访问共享数据时如何交互。 让我们想象一个简单的栗子，其中两个线程希望更新全局共享变量。代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445// Sharing Data#include &lt;stdio.h&gt;#include &lt;pthread.h&gt;#include "common.h"#include "common_threads.h"static volatile int counter = 0;// mythread()//// Simply adds 1 to counter repeatedly, in a loop// No, this is not how you would add 10,000,000 to// a counter, but it shows the problem nicely.//void *mythread(void *arg) &#123; printf("%s: begin\n", (char *) arg); int i; for (i = 0; i &lt; 1e7; i++) &#123; counter = counter + 1; &#125; printf("%s: done\n", (char *) arg); return NULL;&#125;// main()//// Just launches two threads (pthread_create)// and then waits for them (pthread_join)//int main(int argc, char *argv[]) &#123; pthread_t p1, p2; printf("main: begin (counter = %d)\n", counter); Pthread_create(&amp;p1, NULL, mythread, "A"); Pthread_create(&amp;p2, NULL, mythread, "B"); // join waits for the threads to finish Pthread_join(p1, NULL); Pthread_join(p2, NULL); printf("main: done with both (counter = %d)\n", counter); return 0;&#125;// &gt;over 效果： 123456789gcc -o main main.c -Wall -pthread./mainmain: begin (counter = 0)A: beginB: beginA: doneB: donemain: done with both (counter = 20000000) 不幸的是，即使在单个处理器上运行此代码，也不一定能够获得理想的结果。有时，我们得到： 12345678./mainmain: begin (counter = 0)A: beginB: beginA: doneB: donemain: done with both (counter = 19345221) 让我们再尝试一次。计算机不应该产生确定性的结果吗？ 12345678./mainmain: begin (counter = 0)A: beginB: beginA: doneB: donemain: done with both (counter = 19221041) 每次运行不仅错误，而且产生不同的结果。还有一个大问题：为什么会这样？ TIP: KNOW AND USE YOUR TOOLSYou should always learn new tools that help you write, debug, and understand computer systems. Here, we use a neat tool called a disassembler. When you run a disassembler on an executable, it shows you what assembly instructions make up the program. For example, if we wish to understand the low-level code to update a counter (as in our example), we run objdump (Linux) to see the assembly code: objdump -d main.Doing so produces a long listing of all the instructions in the program, neatly labeled (particularly if you compiled with the -g flag), which includes symbol information in the program. The objdump program is just one of many tools you should learn how to use; a debugger like gdb, memory profilers like valgrind or purify, and of course the compiler itself are others that you should spend time to learn more about; the better you are at using your tools, the better systems you’ll be able to build. 问题的核心：不受控制的调度The Heart Of The Problem: Uncontrolled Scheduling 要了解为什么会发生这种情况，我们必须了解编译器生成的代码序列，来更新counter。在这种情况下，我们希望简单地在计数器上添加一个number(1)。因此，这样做的代码序列可能看起来像这样(x86中)： 123mov 0x8049a1c, %eaxadd $0x1, %eaxmov %eax, 0x8049a1c 本示例假定变量counter位于地址0x8049a1c。在此三个指令序列中，首先使用x86 mov 指令获取该地址处的内存值，并将其放入寄存器eax中。然后，执行add，将1(0x1)加到寄存器的内容中。最后，eax的内容存储到同一地址的内存中。 让我们想象一下，我们的两个线程之一的T1进入此代码区域，因此即将使计数器(counter)增加1。它将计数器的值（假设是50）加载到其寄存器eax中。因此，T1的eax=50。将其加1，因此，eax=51。现在，不幸的事情发生了。定时器中断关闭了(timer interrupt goes off)。因此，操作系统将当前正在运行的线程（其PC，包括eax的寄存器等）的状态保存到该线程的TCB中。 现在，更糟的事情发生了。选择运行T2，并进入相同的代码片。它同样也执行第一条指令，获取计数器的值并将其放入eax中（请记住，每个线程在运行时都有自己的专用寄存器。这些寄存器由保存和恢复它们的上下文切换代码虚拟化）。此时计数器的值仍为50，因此T2的eax=50。然后，假设T2执行了以下两条指令，将eax加1(eax=51)，然后将eax的内容保存的计数器(地址0x8049a1c)。因此，全局变量counter现在的值为51。 最后，发生另一个上下文切换，T1恢复运行。回想一下，它刚刚执行了mov和add，现在将要执行最终的mov指令。还记得eax=51。因此，最终的mov指令将执行，并将该值保存到内存中。计数器再次设置为51。 简而言之，发生的事情是这样的：递增counter的代码已经运行了两次，但是从50开始的counter现在仅等于51。该程序的正确版本应该是counter=52。 让我们看一下详细的执行追踪。对此例，假定上面的代码在内存中的地址100处加载，如下序列所示（请注意那些曾经使用过类似RISC的指令集：x86具有可变长度指令。此mov指令占用5个字节的内存，而add只有3个字节）。 基于这些假设，发生的情况如图26-7所示。假定counter从值50开始，并通过此示例进行追踪以确保您了解发生了什么。我们在这里展示的内容称为竞争条件(race conditon)（或，数据竞争(data race)），结果取决于代码的时序执行。如果运气不好（即，在执行中不合时宜的时刻发生上下文切换），我们会得到错误的结果。实际上，我们每次都可能得到不同的结果。因此，我们将这个结果称为不确定的(indeterminate)，而不是一个好的确定性的计算(deterministic computation)。我们习惯于从计算机中使用该确定性计算。在这种情况下，未知的输出将是什么，并且在各次运行之间确实可能有所不同。 由于执行此代码的多个线程可能会导致竞争条件，因此我们将代码称为关键部分(critical section)。关键部分是用于访问共享变量（共享资源）的一段代码，并且不得由多个线程并发执行。 我们真正想要用于此代码的是所谓的互斥(mutual exclusion)。此属性保证如果一个线程在关键部分内执行，则其它线程将无法执行。 顺便说一下，几乎所有这些术语都是由Essger Dijkstra创造的，他是该领域的先去，并由于这项工作和其它工作而获得了图灵奖(Turing Award)。 TIP: USE ATOMIC OPERATIONSAtomic operations are one of the most powerful underlying techniques in building computer systems, from the computer architecture, to concurrent code (what we are studying here), to file systems (which we’ll study soon enough), database management systems, and even distributed systems [L+93].The idea behind making a series of actions atomic is simply expressed with the phrase “all or nothing”; it should either appear as if all of the actions you wish to group together occurred, or that none of them occurred, with no in-between state visible. Sometimes, the grouping of many actions into a single atomic action is called a transaction, an idea developed in great detail in the world of databases and transaction processing [GR92].In our theme of exploring concurrency, we’ll be using synchronization primitives to turn short sequences of instructions into atomic blocks of execution, but the idea of atomicity is much bigger than that, as we will see. For example, file systems use techniques such as journaling or copyon-write in order to atomically transition their on-disk state, critical for operating correctly in the face of system failures. If that doesn’t make sense, don’t worry — it will, in some future chapter 原子性The Wish For Atomicity 解决此问题的一种方法是拥有更强大的指令，只需一步即可完全完成我们需要的一切，从而消除了不及时中断的可能性。例如，如果我们有一个看起来像这样的超级指令怎么办：memory-add 0x8049a1c, $0x1。 假设该指令将一个值添加到内存位置，并且硬件保证其原子化执行。当指令需要执行时，它将根据需要执行更新。它不能再指令中间(mid-instrction)被中断，因为这恰恰是我们从硬件获得的保证：当发生中断时，指令要么根本没有运行，要么已经完成。没有中间状态。 原子化(atomically)，在此上下文中是指as a unit，有时我们将其视为all or none。我们想要以原子化执行这三个指令序列： 123mov 0x8049a1c, %eaxadd $0x1, %eaxmov %eax, 0x8049a1c 正如我们所说，如果只有一条指令来执行此操作，则必须发出(issue)该指令即可完成。但在一般情况下，我们不会有这样的指令。想象我们正在构建并发的B树(B-tree)，并希望对其进行更新。我们是否真的希望硬件支持B树的原子更新指令？至少在一个健全的指令集中，可能不是。 因此，我们要做的是向硬件询问一些有用的指令，在这些指令上我们可以构建通用的所谓同步原语(synchronization primitives)集。通过使用这种硬件支持，再结合操作系统的一些帮助，我们将能够构建多线程代码，以同步(synchronized)和受控制(controlled)的方式访问关键部分，从而尽管并发执行具有挑战性，但仍然可靠地产生正确的结果。非常棒，不是吗？ THE CRUX: HOW TO SUPPORT SYNCHRONIZATIONWhat support do we need from the hardware in order to build useful synchronization primitives? What support do we need from the OS? How can we build these primitives correctly and efficiently? How can programs use them to get the desired results? 等待另一个One More Problem: Waiting For Another 本章设置了并发问题，就好像线程之间仅发生一种交互类型一样，即访问共享变量的交互类型以及对关键部分支持原子性的需求。事实证明，出现了另一种常见的交互作用，其中一个线程必须等待另一个线程完成某些操作才能继续。例如，当进程执行磁盘I/O并使其进入睡眠状态时，就会发生这种交互。当I/O完成时，需要从休眠状态唤醒该进程，以便继续进行。 因此，在接下来的章节中，我们将不仅研究如何构建对同步原语(synchronization primitives)的支持以支持原子性，而且还将研究如何支持这种在多线程程序中常见的sleeping/waking交互机制。如果现在没有理解，没关系。当您阅读到条件变量(condition variables)章节时就会学习相关内容。 ASIDE: KEY CONCURRENCY TERMS CRITICAL SECTION, RACE CONDITION, INDETERMINATE, MUTUAL EXCLUSIONThese four terms are so central to concurrent code that we thought it worth while to call them out explicitly. See some of Dijkstra’s early work [D65,D68] for more details.A critical section is a piece of code that accesses a shared resource, usually a variable or data structure.A race condition (or data race [NM92]) arises if multiple threads of execution enter the critical section at roughly the same time; both attempt to update the shared data structure, leading to a surprising (and perhaps undesirable) outcome.An indeterminate program consists of one or more race conditions; the output of the program varies from run to run, depending on which threads ran when. The outcome is thus not deterministic, something we usually expect from computer systems.To avoid these problems, threads should use some kind of mutual exclusion primitives; doing so guarantees that only a single thread ever enters a critical section, thus avoiding races, and resulting in deterministic program outputs. 总结Summary: Why in OS Class? 在总结之前，您可能会遇到一个问题是：为什么要在OS Class中研究它？历史(history)是一句话的答案。操作系统是第一个并发程序，并且创建了许多技术供自己使用。后来，对于多线程进程，程序员还必须考虑这些事情。 例如，假设有两个进程正在运行。假设它们都调用write()写入文件，并且都希望将数据追加到文件中（即，将数据添加到文件的末尾）。为此，双方都必须分配一个新块(new block)，在该块所在的文件的inode中记录该文件，并更改文件的大小以反映新的更大的大小。由于随时可能发生中断，因此更新这些共享结构(shared structures)的代码的关键部分。因此，操作系统的设计者从引入中断的一开始就不得不担心操作系统如何更新内部结构。不及时的中断会导致上述所有问题。毫不奇怪，必须使用适当的同步原语仔细地访问分页表，进程列表、文件系统结构以及几乎每个内核数据结构，以使其正常工作。 Thread APIThread API: http://pages.cs.wisc.edu/~remzi/OSTEP/threads-api.pdf 本章简要介绍了Thread API的主要部分。当我们展示如何使用API时，将在后续章节中进一步解释每个部分。我们应该注意，后面的章节将以许多示例更慢地介绍锁(lock)和条件变量(condition variables)的概念。因此，本章可以更好地用作参考。 CRUX: HOW TO CREATE AND CONTROL THREADSWhat interfaces should the OS present for thread creation and control? How should these interfaces be designed to enable ease of use as well as utility? 线程创建Thread Creation 编写多线程程序必须要做的第一件事是创建新线程，因此必须存在某种线程创建接口(thread creation interface)。在POSIX中，这很容易： 123456#include &lt;pthread.h&gt;intpthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routie) (void*), void *arg); 该声明可能看起来有点复杂，特别是如果您没有在C语言中使用函数指针，但实际上它还不错。有四个参数： thread：指向pthread_t类型结构的指针。我们将使用此结构与线程进行交互，因此我们需要将其传递个pthread_create()进行初始化。 attr：指定此线程可能具有的任何属性。一些示例包括设置栈大小，或者可能设置有关线程的调度优先级的信息。通过对pthread_attr_init()的单独调用来初始化属性。但是，在大多数情况下，默认设置会很好。在这种情况下，我们将简单地传入NULL值。 start routine：第三个参数是最复杂的，但实际上只是在问：该线程应该在哪个函数开始运行？在C语言中，我们将其称为函数指针(function pointer)，它告诉我们以下内容：函数名称(start routine)，该函数名称传递了单个类型为void *(start routine)，并且它返回void *类型的值（即void pointer）。 arg：传递给线程开始执行的函数的参数。您可能会问：为什么我们需要这些空指针？好吧，答案很简单——将void pointer用作函数start routine的参数可以使我们传入任何类型的参数。将其作为返回值允许线程返回任何类型的结果。 如果此例程(routine)需要整数参数而不是void pointer，则声明将如下所示： 123int pthread_create(..., // first two args are the same void *(*start_routine) (int), int arg); 如果例程将void pointer作为参数，但返回整数，则它将如下所示： 123int pthread_create(..., // first two args are the same int (*start_routine) (void *), void *args); 让我们看一下下面代码的示例。在这里，我们只创建一个传递两个参数的线程，这些参数打包为我们自己定义的单个类型(myart_t)。线程一旦创建，就可以简单地将其参数转换为所需的类型，从而根据需要解压参数。 创建线程后，您实际上将拥有另一个活着的执行实体(live executing entity)，该实体具有其自己的调用栈(call stack)，并在与程序中所有当前现有线程相同的地址空间中运行。 12345678910111213141516171819202122#include &lt;stdio.h&gt;#include &lt;pthread.h&gt;// Creating a Threadtypedef struct &#123; int a; int b;&#125; myarg_t;void *mythread(vid *arg) &#123; myarg_t *args = (myarg_t *) args; printf("%d %d\n", args-&gt;a, args-&gt;b); return NULL;&#125;int mmain(int argc, char *argv[]) &#123; pthread_t p; myarg_t args = &#123; 10, 20&#125;; int rc = pthread_create(&amp;p, NULL, mythread, $args); ...&#125; 线程完成Thread Complete 上面的栗子显示了如何创建线程。但是，如果您要等待线程完成怎么办？您需要做一些特殊的事情才能等待线程完成。特别是，您需要调用pthread_join()例程。 1int pthread_join(pthread_t thread, void **value_ptr); 该例程有两个参数: pthread_t：用于指定要等待的线程。该变量由线程创建例程初始化（当您将指向它的指针作为参数传递给pthread_create()）。如果保留它，则可以使用它来等待该线程终止。 第二个参数是指向您希望返回的返回值的指针。由于该例程可以返回任何内容，因此将其定义为返回指向void的指针。因为pthread_join()例程会更改传入参数的值，所以您需要传递指向该值的指针，而不仅仅是传递值本身。 让我们看看下面的代码示例。在代码中，再次创建了一个线程，并通过myarg_t结构传递几个参数。要返回值，请使用myret_t类型。线程完成运行后，一直在pthread_join()例程中等待返回的主线程将返回，并且我们可以访问从线程返回的值，即myret_t的值。 123456789101112131415161718192021// Waiting for Thread Completiontypedef struct &#123; int a; int b; &#125; myarg_t;typedef struct &#123; int x; int y; &#125; myret_t;void *mythread(void *arg) &#123; myret_t *rvals = Malloc(sizeof(myret_t)); rvals-&gt;x = 1; rvals-&gt;y = 2; return (void *) rvals;&#125;int main(int argc, char *argv[]) &#123; pthread_t p; myret_t *rvals; myarg_t args = &#123; 10, 20 &#125;; Pthread_create(&amp;p, NULL, mythread, &amp;args); Pthread_join(p, (void **) &amp;rvals); printf("returned %d %d\n", rvals-&gt;x, rvals-&gt;y); free(rvals); return 0;&#125; 有关此示例的一些注意事项。首先，通常情况下，我们不必进行所有痛苦的参数的打包和拆包操作。例如，如果我们仅创建一个不带参数的线程，则可在创建线程时将NULL作为参数传递。通用，如果我们不关心返回值，则可以将NULL传递给pthread_join()。 其次，如果我们只是传递单个值（如，a long long int)，则不必将其打包为参数。下面的代码显示了一个示例。在这种情况下，生活会更简单一些，因为我们不必在结构内部打包参数和返回值。第三，我们应该注意，从线程返回值的防止必须格外小心。具体来说，永远不要返回指向该线程的调用栈(call stack)中分配的内容的指针。如果这样做，想下会发生什么？下面有一段危险的代码，它从上面示例的代码修改而来。 12345678910111213141516// Simpler Argument Passing to a Threadvoid *mythread(void *args) &#123; long long int value = (long long int) arg; printf("%lld\n", value); return (void *) (value + 1);&#125;int main(int argc, char *argv[]) &#123; pthread_t p; long long int rvalue; Pthread_create(&amp;p, NULL, mythread, (void *) 100); Pthread_join(p, (void **), &amp;rvalue); printf("returnd %lld\n", rvalue); return 0;&#125; 12345678910// a dangerous piece of codevoid *mythread(void *arg) &#123; myarg_t *args = (myarg_t *) arg; printf("%d %d\n", args-&gt;a, args-&gt;b); myret_t oops; // ALLOCATED ON STACK: BAD! oops.x = 1; oops.y =2; return (void *) &amp;oops;&#125; 在这种情况下，变量oops分配在mythread栈上。但是，当它返回时，该值会自动释放(deallocated)（这就是为什么栈是如此易于使用的原因！）因此，将指针传递回现在释放的变量将导致各种不良结果。当然，当您尝试打印出您认为返回的值时，您可能回感到惊讶。 最后，您可能会注意到，使用pthread_create()创建线程，然后立即调用pthread_join()，是创建线程的一种很奇怪的方法。实际上，有一种更简单的方法可以完成此确切任务。它称为过程调用(produre call)。显然，我们通常会创建多个线程并等待其完成，否则根本就没有太多用途。 我们应该注意到，并非所有多线程代码都使用join routine。例如，多线程Web Server可能会创建多个工作线程，然后使用主线程无限期地接受请求并将其传递给工作线程。这样的长期存在的程序因此可能不需要join。但是，创建线程以并行执行特定任务的并行程序很可能会使用join来确保所有此类工作在退出或进入下一阶段之前完成。 锁Locks: http://pages.cs.wisc.edu/~remzi/OSTEP/threads-locks.pdf 从介绍到并发，我们看到了并发编程中的一个基本问题：我们希望原子地执行一系列指令，但是由于单个处理器（多处理器上同时执行多个线程）存在中断，我们不能。因此，在本章中，我们通过引入称为锁(lock)的方法来直接解决此问题。程序员用锁来注释源代码，将它们放在关键部分周围，从而确保任何这样的关键部分都像单个原子指令一样执行。 锁的基本思想Locks: The Basic Idea 例如，假设我们的关键部分如下所示，即共享变量的规范更新： 1balance = balance + 1; 当然，其它关键部分也是可能的，例如将元素添加到链表或对共享结构进行其它更复杂的更新，但是我们现在仅继续简单的示例。要使用锁，我们在关键部分周围添加一些代码，如下所示： 12345lock_t mutex; // some globally-allocated lock &apos;mutex&apos;...lock(&amp;mutex);balance = balance + 1;unlock(&amp;mutex); 锁只是一个变量，因此要使用一个锁，您必须声明某种类型的锁变量(lock variable)（如上面的互斥锁）。这个锁变量在任何时候都保持锁的状态。它是可用的（available, unlocked or free），因此没有线程持有该锁，也没有线程获得(acquired, locked or held)，因此恰好有一个线程持有该锁，并且大概在关键部分。我们可以将其它信息存储在数据类型中，例如哪个线程持有锁，或者用于订购锁的队列，但是诸如此类的信息对于锁的用户是隐藏的。 lock()和unlock()例程的语义很简单。调用例程lock()尝试获取锁，如果没有其它线程持有该锁（即，它是空闲的），则该线程将将获取该锁并进入关键部分。有时将此线程称为锁的所有者(owner)。如果另一个线程然后对同一个锁(示例中的mutex)调用lock()，则当另一个线程持有该锁时它将不会返回。这样，可以防止其它线程进入关键部分，而持有锁的第一个线程在那里。 一旦锁的拥有者调用unlock()，锁现在就可以再次使用了(free)。如果没有其它线程在等待锁（即，没有其它线程调用lock()并停留在其中），则锁的状态将简单地更改为空闲(free)。如果有等待线程（卡在lock()中），其中一个将通知该锁状态的变化，获取该锁，然后进入关键部分。 锁为程序员提供了对调度的最小控制量。通常，我们将线程视为由程序员创建但由操作系统以操作系统选择的任何方式计划的实体。锁将某些控制权交还给程序员。通过在一段代码周围加一个锁，程序员可以保证在该代码中活动的线程最多为一个。因此，锁有助于将传统操作系统调度的混乱转变为更加受控的活动。 Pthread LocksPOSIX library用于锁的名称是一个互斥锁(mutex)，因为它用于提供线程之间的互斥(mutex exclusion)。即，如果一个线程在关键部分中，它会在该部分完成之前阻止其它进入。因此，当您看到以下POSIX线程代码时，您应该了解它正在执行与上述相同的操作： 12345pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;Pthread_mutex_lock(&amp;lock); // wrapper; exits on failurebalance = balance + 1;Pthread_mutex_unlock(&amp;lock); 您可能还会在这里注意到POSIX版本传递了一个变量来锁定和解锁，因为我们使用不同的锁来保护不同的变量。这样做可以提高并发性：代替访问任何关键部分时都使用的一个大锁（粗粒度(coarse-grained)锁策略），通常可以保护不同的数据和具有不同锁的数据结构，从而可以一次将更多线程放入锁代码中（一种更细粒度(fine-grained)的方法）。 建立锁Building A Lock 到目前为止，您应该从程序员的角度对锁的工作原理有所了解。但是，我们应该如何建立锁？需要什么样的硬件支持？什么样的操作系统支持？将在本章的其余部分中讨论这些问题。 要建立工作锁，我们将需要硬件和操作系统的帮助。多年以来，许多不同的硬件原语已被添加到各种计算机体系结构的指令集中。尽管我们不会研究这些指令的实现方式，但我们将如何研究如何使用它们来构建互斥锁原语。我们还将研究操作系统如何参与完成图片并使我们能够构建复杂的locking library。 评估锁Evaluating Locks 在构建任何锁之前，我们应该首先了解我们的目标是什么，因此我们要问如何评估特定锁实现的功效。为了评估锁是否有效，我们应该建立一些基本标准。首先是锁是否执行其基本任务，即提供互斥(mutual exclusion)。基本上，该锁是否起作用，从而防止多个线程进入关键部分。第二个是公平(fairness)。争夺锁的每个线程一旦获得空闲，都可以获得公平的机会吗？另一种看待这种情况的方法是检查更极端的情况：争夺锁的线程是否在这样做的时候挨饿了(starve)，因此从不获取锁？最终的标准是性能(performance)，特别是使用锁增加的时间开销。这里有一些不同的情况值得考虑。一种是不争夺的情况。当单个线程正在运行并获取和释放锁时，这样做的开销是多少？另一种情况是多个线程争用单个CPU上的锁。在这种情况下，是否存在性能问题？最后，当涉及多个CPU且每个线程争用该锁时，锁如何执行？通过比较这些不同的方案，我们可以更好地了解使用各种锁技术对于性能的影响，如下所述。 控制中断Controlling Interrupts 提供互斥的最早解决方案之一是禁用关键部分的中断。此解决方案是为单处理器系统发明的。代码如下所示： 123456void lock() &#123; DisableInterrupts();&#125;void unlock() &#123; EnableInterrupts();&#125; 假设我们在单处理器系统上运行。通过在进入关键部分之前关闭中断（使用某种特殊的硬件指令），我们确保关键部分内的代码不会被中断，因此将像执行原子操作一样执行。完成后，我们重新启用中断（同样是通过硬件指令），因此程序照常进行。这种方法的主要优点是它的简单性。您当然不必太费力气，以弄清楚为什么这行得通。在不中断的情况下，线程可以确保其执行的代码将执行，并且没有其它线程会干扰它。 不幸的是，负面因素很多。首先，这种方法要求我们允许任何调用线程执行执行特权操作(privileged operation)（打开和关闭中断），并因此相信不会滥用此功能。如您所知，每当我们信任任意程序时，我们都可能会遇到麻烦。在这里，问题以多种方式表现出来：贪婪的程序可能在执行开始时调用lock()，从而垄断(monopolize)了处理器。更糟糕的是，一个错误或恶意的程序可能会调用lock()并进入一个无限循环(endless loop)。在后一种情况下，操作系统永远不会重新获得对系统的控制，并且只有一种方法：重启系统。将中断禁用作为通用同步解决方案需要对应用程序的过多信任。其次，该方法不适用于多处理器。如果多个线程在不同的CPU上运行，并且每个线程都尝试进入相同的关键部分，则是否禁用中断都无关紧要。线程能够在其它处理器上运行，因此可以进入关键部分。由于多处理器现在很普遍，因此我们的通用解决方案必须做的更好。第三，长时间关闭中断可能导致中断丢失，从而导致严重的系统问题。例如，如果CPU错过了磁盘设备已完成读取请求的事实。操作系统将如何知道唤醒等待读的进程？最后，可能也是最不重要的，这种方法效率低下。与普通指令执行相比，屏蔽或取消屏蔽中断的代码往往会被现代CPU缓慢执行。 由于这些原因，关闭中断仅在有限的上下文中用作互斥原语。例如，在某些情况下，操作系统本身将使用中断屏蔽来确保访问其自己的数据结构时的原子性，或至少防止某些混乱的中断处理情况发生。这种用法很有意义，因为信任问题不再存在于操作系统内部，而操作系统始终信任自己以执行特权操作。 一个失败的尝试：仅使用Loads/StoresA Failed Attempt: Just Using Loads/Stores 为了建立基于中断的技术，我们将不得不依靠CPU硬件机器提供的指令来建立适当的锁。首先，我们尝试使用单个标志变量来构建简单的锁。在这次失败的尝试中，我们将看到构建锁所需的一些基本思想，并看到了为什么仅使用单个变量并通过常规加载和存储访问它是不够的。 在第一次尝试中（下面代码），想法很简单：使用简单变量(标志)指示某个线程是否拥有锁。进入关键区域的第一个线程将调用lock()，该线程测试该标志是否等于1（这种情况下，它不等于1），然后将标志设置为1以指示该线程现在持有该锁。完成关键部分后，线程将调用unlock()病清除该标志，从而指示该锁已不再持有。 123456789101112131415161718// A Simple Flagtypedef struct __lock_t &#123; int flag; &#125; lock_t;void init(lock_t, *mutex) &#123; // 0 -&gt; lock is available, 1 -&gt; held mutex -&gt; flag = 0;&#125;void lock(lock_t, *mutex) &#123; while (mutex-&gt;flag == 1) // TEST the flag ; // spin-wait (do nothing) mutex-&gt;flag = 1; // now SET it!&#125;void unlock(lock_t *mutex) &#123; mutex-&gt;flag = 0;&#125; 如果在第一个线程处于关键部分时另一个线程恰巧调用lock()，则它将仅在while循环中自旋等待(spin-wait)，以便该线程调用unlock()并清除标志。一旦第一个线程执行了此操作，等待线程将退出while循环，将其自身的标志设置为1，然后进入关键部分。不幸的是，代码有两个问题：一是正确性，另一个是性能。一旦习惯了并发编程，就很容易看到正确性问题。想象一下下面的代码，假定flag=0。 Trace: No Mutual Exclusion Thread 1 Thread 2 call lock() while(flag == 1) interrupt: switch to Thread 2 - call lock() while(flag == 1) flag =1; interrupt: switch to Thread 1 flag = 1; //set flag to 1 (too!) 从这种交错(interleaving)中可以看到，通过及时地(timely)（不及时地(untimely)）中断，我们可以很容易地产生一种情况——将两个线程的标志设置为1，因此两个线程都可以进如关键部分。这种行为被专业人员称为bad——我们显然未能提供最基本的要求：提供互斥。 性能问题是线程等待获取已持有的锁的方式：它无休止地检查标志的值，这是一种称为自旋等待(spin-wait)的技术。 自旋等待浪费时间等待另一个线程释放锁。在单处理器上浪费非常多，在单处理器上，等待者正在等待的线程甚至无法运行（至少在发生上下文切换之前）！因此，随着我们前进并开发更复杂的解决方案，我们还应该考虑避免这种浪费的方法。 通过test and set建立工作自旋锁Building Working Spin Locks with Test-And-Set 由于禁用中断在多处理器上不起作用，并且由于使用loads and stores的简单方法不起作用，因此系统设计人员开始发明对锁定的硬件支持。最早的多处理器系统都提供这种支持。如今，即使对于单CPU系统，所有系统都提供这种类型的支持。 最简单的硬件支持称为test and set（或atomic exchange）指令。我们通过以下C代码片段定义test and set指令的作用： 12345int TestAndSet(int *old_ptr, int new) &#123; int old = *old_ptr; //fetch old value at old_ptr *old_ptr = new; // store 'new' into old_ptr return old; // return the old value&#125; 在1960年代，Dijkstra向他的朋友们提出了并发问题，其中一位叫Dekker的数学家提出了一个解决方案。与我们在此讨论的解决方案使用特殊的硬件指令甚至是操作系统支持不同，Dekker的算法仅使用loads and stores。 Peterson后来完善了Dekker的方法。再一次，仅使用loads and stores，其思想是确保两个线程永远不会同时进入关键部分。下面是Peterson的算法（针对两个线程），看看您是否能够理解代码。 1234567891011121314151617181920int flag[2];int turn;void init() &#123; // indicate you intend to hold the lock 2/ 'flag' flag[0] = flag[1] = 0; // whose turn is it? (thread 0 or 1) turn = 0;&#125;void lock() &#123; // 'self' is the thread ID of caller flag[self] = 1; // make it other thread's turn turn = 1 - self; while ((flag[1-self] == 1) &amp;&amp; (turn == 1 - self)); //spin-wait while it's not your turn&#125;void unlock() &#123; // simply undo your intent flag[self] = 0;&#125; 由于某种原因，开发在没有特殊硬件支持的情况下工作的锁已成为一种流行，这给理论类型带来了很多需要解决的问题。当然，当人们意识到承担一点硬件支持要容易得多时，这一工作就变得毫无用处。此外，由于宽松的内存一致性模型，上述算法无法在现代硬件上运行。因此，它们的功能比以前更加有用。 test and set指令的作用如下。它返回old_ptr指向的旧值，并同时将该值更新为new。当然，关键是此操作是原子执行的。之所以称之为test and set，是因为它使您可以测试旧值，同时将内存位置设置为新值。事实证明，此功能稍强的指令足以构建一个简单的自旋锁(spin-lock)，如下面代码所示。 12345678910111213141516typedef struct __lock_t &#123; int flag;&#125; lock_t;void init(lock_t *lock) &#123; // 0: lock is available, 1: lock is held lock-&gt;flag = 0;&#125;void lock(lock_t *lock) &#123; while (TestAndSet(&amp;lock-&gt;flag, 1) == 1); // spin-wait (do nothing)&#125;void unlock(lock_t *lock) &#123; lock-&gt;flag = 0;&#125; 确保我们了解此锁的作用。首先想象一下一个线程调用lock()而当前没有其它线程持有该锁的情况。因此，标志应为0。当线程调用TestAndSet(flag, 1)时，例程将返回flag的旧值，即0。因此，正在测试flag值的调用线程不会在while循环中被不获，而将获得锁。该线程还将原子地将该值设置为1，从而指示该锁现在已被持有。当线程的关键部分结束时，它将调用unlock()将标志设置回零。 第二种情况是，一个线程已经持有了锁（即标志为1）。在这种情况下，该线程将调用lock()，然后也调用TestAndSet(flag, 1)。这次，TestAndSet()将在标志处返回旧值(1)（因为持有了锁），同时将其再次设置为1。只要锁由另一个线程持有，TestAndSet()将重复返回1，因此该线程自旋，知道最终释放该锁为止。当该标志最终被其它某个线程设置为0时，该线程将再次调用TestAndSet()，该调用现在将返回0，同时原子地将值设置为1，从而锁定并进入临界区。 通过将测试(旧锁值)和设置(新值)都将女性单个原子操作，我们确保只有一个线程获得该锁。这就是建立有效的互斥原语的方法。 您现在也可以理解为什么通常将这种类型的锁称为自旋锁(spin lock)。它是最简单的锁类型，可以使用CPU周期简单地自旋，直到锁可用。为了在单个处理器上正常工作，它需要一个抢先式调度程序(preemptive scheduler)（即，一个调度程序将通过计时器中断线程，以便不时运行另一个线程）。没有抢占，自旋锁在单个CPU上就没有多大意义，因为在CPU上旋转的线程永远不会放弃它。 TIP: THINK ABOUT CONCURRENCY AS A MALICIOUS SCHEDULERFrom this example, you might get a sense of the approach you need to take to understand concurrent execution. What you should try to do is to pretend you are a malicious scheduler, one that interrupts threads at the most inopportune of times in order to foil their feeble attempts at building synchronization primitives. What a mean scheduler you are! Although the exact sequence of interrupts may be improbable, it is possible, and that is all we need to demonstrate that a particular approach does not work. It can be useful to think maliciously! (at least, sometimes) 评估自旋锁Evaluating Spin Locks 有了基本的自旋锁，我们现在就可以评估先前描述的轴(zxes)的有效性。锁最重要的方面是正确性(correctness)：它是否提供互斥？答案是肯定的：自旋锁一次仅允许单个线程进入关键部分。因此，我们有一个正确的锁。 下一个轴是公平性(fairness)。自旋锁对正在等待的线程有多公平？您能否保证等待的线程会进入关键部分？不幸的是，答案是个坏消息：自旋锁不提供任何公平性保证。实际上，在争用的情况下，自旋锁可能会永远自旋。简单的自旋锁是不公平的，可能会导饥饿(starvation)。 最终的轴是性能(performance)。使用自旋锁的开销是多少？为了更仔细地分析这一点，我们建议考虑一些不同的情况。首先，想象一下线程争夺单个处理器上的锁；其次，考虑线程分布在多个CPU上。 对于自旋锁，在单CPU的情况下，性能开销可能会非常痛苦。设想在关键部分内抢占持有锁的线程的情况。然后，调度程序可能会运行其它所有线程（假设，还有N-1个线程），每个线程都试图获取锁。在这种情况下，这些线程中的每个线程都会在放弃CPU之前的一段时间内自旋，这浪费了CPU周期。 但是，在多个CPU上，自旋锁运行的很好（如果线程数大致等于CPU数）。思路如下：设想CPU1上的线程A与CPU2上的线程B都在争夺锁。如果线程A(CPU1)抓住了锁，然后线程B(CPU2)尝试这样做，则B将自旋。但是，假设关键部分很短，因此很快就可以使用该锁，并被线程B获取。在这种情况下，自旋等待另一个处理器上持有的锁不会浪费很多周期，因此很有效。 Compare-And-Swap一些系统提供的另一种硬件原语称为compare-and-swap(在SPARC上)或compare-and-exchange(在x86上)指令。下面是该指令的C伪代码。 12345678// compare and swapint CompareAndSwap(int *ptr, int expected, int new) &#123; int original = *ptr; if (original == expected) *ptr = new; return original;&#125; compare and swap的基本思想是测试ptr地址处的值是否等于expected。如果是，请使用新值更新ptr指向的内存地址。如果不是，什么也不做。无论哪一种情况，都应在该内存位置返回原始值，从而使调用compare-adn-swap的代码知道其是否成功。 使用compare-and-swap指令，我们可以以test-and-set非常相似的放肆构建锁。例如，我们可将上面的lock()例程替换为一下内容: 123void lock(lock_t *lock) &#123; while (CompareAndSwap(&amp;lock-&gt;flag, 0, 1) == 1); // spin&#125; 其余代码与test-and-set示例相同。它只是检查标志是否为0，如果是，则原子地交换为1，从而获得锁。试图在持有锁的同时获取锁的线程将卡住，知道锁最终被释放。最后，您可能已经感觉到了，compare-and-swap比test-and-set更强大。将来，当我们简要研究诸如lock-free synchronization之类的主题时，我们将利用这种功能。但是，如果仅使用它构建一个简单的自旋锁，则其行为与我们上面分析的自旋锁相同。 Load-Linked and Store-Conditional一些平台提供了一对协同工作的指令，以帮助构架关键部分。例如，在MIPS架构上，可使用load-linked和store-conditional指令来构建锁和其它并发结构。这些指令的C伪代码如下所示。Alpha、PowerPC、ARM提供类似的指令。 1234567891011121314// Load-linked And Store-conditionalint LoadLinked(int *ptr) &#123; return *ptr;&#125;int StoreConditional(int *ptr, int value) &#123; if (no update to *ptr since LoadLinked to this address) &#123; *ptr = value; return 1; // success! &#125; else &#123; return 0; // failed to update &#125;&#125; load-linked的操纵非常类似于典型的load指令，并仅从内存中获取一个值并将其放置在寄存器中。关键的区别在于store-conditional，只有在没有发生中间存储到地址的情况下，该条件才会成功（并更新存储在刚刚load-linked的地址上的值）。如果成功，则存储条件返回1并将ptr处的值更新为value，如果失败，则不会更新ptr的值，并返回0。 作为对自己的挑战，请尝试考虑如何使用load-linked和store-confitional的方式构建锁。完成后，查看下面的代码。改代码提供了一种简单的解决方案，如下所示。 1234567891011121314// Using LL/SC To Build A Lockvoid lock(lock_t *lock) &#123; while (1) &#123; while (LoadLinked(&amp;lock-&gt;flag) == 1); // spin until it's zero if (StoreConditional(&amp;lock-&gt;flag, 1) == 1) return; // if set-it-to-1 was success: all done // otherwise: try it all over again &#125;&#125;void unlock(lock_t, *lock) &#123; lock-&gt;flag = 0;&#125; lock()代码是唯一有趣的部分。首先，线程自旋以等待将标志设置为0（从而指示为持有该锁）。一旦这样，线程尝试通过存储条件获取锁。如果成功，则该线程自动将标志的值更改为1，因此可以进入关键部分。 请注意store-conditional的失败可能如何发生。一个线程调用lock()并执行load-linked，由于未持有该锁，因此返回0。在尝试store-conditional之前，它被中断，另一个线程进入锁代码，同时执行load-linked指令，并获得0并继续。在这一点上，两个线程已经执行了load-linked，并且每个线程都将尝试执行store-conditional。这些指令的关键特征是这些线程中只有一个可以成功将标志更新为1，从而获得锁。第二个尝试尝试store-conditional的线程将失败（因为另一个线程更新了其load-linked和store-conditional之间的标志的值），因此必须尝试再次获取该锁。 1234void lock(lock_t *lock) &#123; while (LoadLinked(&amp;lock-&gt;flag) || !StoreConditional(&amp;lock-&gt;flag, 1)); // spin&#125; Fetch-And-Add最后一个硬件原语是fetch-and-add指令，该指令原子地递增值，同时在特定地址返回旧值。它的C伪代码如下所示： 12345int FetchAndAdd(int *ptr) &#123; int old = *ptr; *ptr = old + 1; return old;&#125; 在此示例中，我们将使用fetch-and-add来构建一个更有趣的ticket lock。代码在下面。 123456789101112131415161718typedef struct __lock_t &#123; int ticket; int turn;&#125; lock_t;void lock_init(lock_t, *lock) &#123; lock-&gt;ticket = 0; lock-&gt;turn = 0;&#125;void lock(lock_t *lock) &#123; int myturn = FetchAndAdd(&amp;lock-&gt;ticket); while (lock-&gt;turn != myturn); // spin&#125;void unlock(lock_t *lock) &#123; lock-&gt;turn = lock-&gt;turn + 1;&#125; 该解决方案使用单个票(ticket)和转向变量(turn variable)来组合以构建锁，而不是使用单个值。基本操作非常简单：当线程希望获取锁时，它首先对票值进行原子fetch-and-add，现在将该值视为该线程的转向(turn)。然后使用全局共享的lock-&gt;turn来确定它是哪个线程。当给定线程myturn == turn时，轮到线程进入关键部分。只需通过增加转向即可完成解锁，以便下一个等待线程现在可以进入关键部分。 请注意，此解决方案与我们之前的尝试有一个重要区别：它确保所有线程的进度。一旦线程分配了票值(ticket value)，它将在将来的某个时间进行调度（一旦前面的通过了关键部分并释放了锁）。在我们以前的尝试中，不存在这样的保证。即使在其它线程获得并释放锁的情况下，它也可能永远自旋。 TIP: LESS CODE IS BETTER CODE (LAUER’S LAW)Programmers tend to brag about how much code they wrote to do something. Doing so is fundamentally broken. What one should brag about, rather, is how little code one wrote to accomplish a given task. Short, concise code is always preferred; it is likely easier to understand and has fewer bugs. As Hugh Lauer said, when discussing the construction of the Pilot operating system: “If the same people had twice as much time, they could produce as good of a system in half the code.” [L81] We’ll call this Lauer’s Law, and it is well worth remembering. So next time you’re bragging about how much code you wrote to finish the assignment, think again, or better yet, go back, rewrite, and make the code as clear and concise as possible. 自旋太多：现在怎么办Too Much Spinning: What Now? 我们简单的基于硬件的锁很简单（只有几行代码），并且可以正常工作（您甚至可以通过编写一些代码来证明这一点），这是任何系统或代码的两个出色特性。然而，在某些情况下，这些解决方案可能效率很低。假设您在单处理器上运行两个线程。现在，想象一个线程(T0)在关键部分中，因此持有锁，不幸的是被中断了。现在，第二个线程(T1)尝试获取该锁，但发现它已被持有。因此，它开始自旋、自旋…最后，定时器中断消失，T0再次运行，从而释放锁。最后，T1不必自旋太多，就能获得锁。因此，在此情况下，每当线程陷入自旋状态时，它都会浪费时间片只检查不会改变的值，而什么都不做。随着N个线程争用锁，问题变得更加严重。可以以类似的方式浪费N-1个时间片，只需自旋并等待单个线程释放锁即可。因此，我们的下一个问题是： THE CRUX: HOW TO AVOID SPINNINGHow can we develop a lock that doesn’t needlessly waste time spinning on the CPU? 单靠硬件支持无法解决问题。我们也需要操作系统执支持！现在，让我们弄清楚这可能如何工作。 Just YieldA Simple Approach: Just Yield, Baby 硬件支持使我们走得很远：工作锁，甚至在获取锁方面的公平性。但是，我们仍然有一个问题：当关键部分发生上下文切换时，并且线程开始无休止地旋转，等待被中断的线程再次运行，该怎么办？ 我们的第一个尝试是一种简单而友好的方法：当要自旋时，将CPU放弃给另一个线程。正如Davis可能说的那样，”Just yield, baby!” 下面显示了此方法。 1234567891011121314// Lock With Test-and-set And Yieldvoid init() &#123; flag = 0;&#125;void lock() &#123; while (TestAndSet (&amp;flag, 1) == 1) yield(); // give up the CPU&#125;void unlock() &#123; flag = 0;&#125; 在此方法中，我们假设一个操作系统原始的yield()，当一个线程想要放弃CPU并让另一个线程运行时，该线程可以调用它。线程可处于三种状态（running, ready, blocked）。yield只是一个系统调用，它将调用程序从运行状态转(running)移到就绪状态(ready)，从而将另一个线程提升为运行状态。因此，yielding线程本质上使自身调度(deschedules)。 考虑一个CPU上有两个线程的例子。在这种情况下，我们基于屈服的方法效果很好。如果一个线程恰巧调用lock()并找到一个持有锁，则它只会屈服CPU，因此另一个线程将运行并完成起关键部分。在这种简单情况下，屈服方法效果很好。 现在，让我们考虑有很多线程（假如100个）反复争用锁的情况。在这种情况下，如果一个线程获取了该锁并在释放前被抢占，则另外的99个线程将分别调用lock()，找到持有锁，并屈服于CPU。假设采用某种循环调度(RR)程序，则在持有该锁的线程再次运行之前，这99个轮询程序将执行run-and-yield模式。尽管比我们的自旋方法方法更好（浪费99个时间片进行自旋），但这种方法仍然昂贵。上下文切换的成本可能很高，因此有很多浪费。 更糟的是，我们根本没有解决饥饿问题(starvation)。一个线程可能陷入无限的屈服循环中，而其它线程则反复进入和退出关键部分。显然，我们将需要一种直接解决此问题的方法。 Using QueuesUsing Queues: Sleeping Instead Of Spinning 我们以前的方法的真正问题在于它们留下了太多机会。调度程序确定下一步运行哪个线程。如果调度程序做出了错误地选择，则线程必须自旋以等待锁来运行线程（第一种方法），或立即屈服于CPU（第二种方法）。无论哪种方法，都有浪费的可能，并且无法阻止饥饿。 因此，我们必须明确地控制当前持有者释放锁之后，下一个线程将获得锁。为此，我们将需要更多的操作系统的支持，以及一个队列来跟踪哪些线程正在等待获取锁。 为了简单起见，我们将通过使用由Solaris提供支持的两个调用程序：park()调用线程进入睡眠状态(sleep)，unpark(threadID)唤醒由threadID指定的特定线程。可以串联使用这两个例程来构建一个锁，如果调用放可以使其进入睡眠状态，并在锁释放时将其唤醒。来看下下面的代码，以了解此类原语。 123456789101112131415161718192021222324252627282930313233343536// Lock With Queues, Test-and-set, Yield, And Wakeuptypedef struct __lock_t &#123; int flag; int guard; queue_t *q;&#125; lock_t;void lock_init(lock_t *m) &#123; m-&gt;flag = 0; m-&gt;guard = 0; queue_init(m-&gt;q);&#125;void lock(lock_t *m) &#123; whild (TestAndSet(&amp;m-&gt;guard, 1) == 1); // acquire guard lock by spinning if (m-&gt;flag == 0) &#123; m-&gt;flag = 1; //lock is acquired m-&gt;guard = 0; &#125; else &#123; queue_add(m-&gt;q, gettid()); m-&gt;guard = 0; park(); &#125;&#125;void unlock(lock_t *m) &#123; while (TestAndSet (&amp;m-&gt;guard, 1) == 1); // acquire guard lock by spinning if (queue_empty(m-&gt;q)) m-&gt;flag = 0; // let go of lock; no now wats it else unpark(queue_remove(m-&gt;q)); // hold lock // for next thread! m-&gt;guard = 0;&#125; ASIDE: MORE REASON TO AVOID SPINNING: PRIORITY INVERSIONOne good reason to avoid spin locks is performance: as described in the main text, if a thread is interrupted while holding a lock, other threads that use spin locks will spend a large amount of CPU time just waiting for the lock to become available. However, it turns out there is another interesting reason to avoid spin locks on some systems: correctness. The problem to be wary of is known as priority inversion, which unfortunately is an intergalactic scourge, occurring on Earth [M15] and Mars [R97]!Let’s assume there are two threads in a system. Thread 2 (T2) has a high scheduling priority, and Thread 1 (T1) has lower priority. In this example, let’s assume that the CPU scheduler will always run T2 over T1, if indeed both are runnable; T1 only runs when T2 is not able to do so (e.g., when T2 is blocked on I/O).Now, the problem. Assume T2 is blocked for some reason. So T1 runs, grabs a spin lock, and enters a critical section. T2 now becomes unblocked (perhaps because an I/O completed), and the CPU scheduler immediately schedules it (thus descheduling T1). T2 now tries to acquire the lock, and because it can’t (T1 holds the lock), it just keeps spinning. Because the lock is a spin lock, T2 spins forever, and the system is hung.Just avoiding the use of spin locks, unfortunately, does not avoid the problem of inversion (alas). Imagine three threads, T1, T2, and T3, with T3 at the highest priority, and T1 the lowest. Imagine now that T1 grabs a lock. T3 then starts, and because it is higher priority than T1, runs immediately (preempting T1). T3 tries to acquire the lock that T1 holds, but gets stuck waiting, because T1 still holds it. If T2 starts to run, it will have higher priority than T1, and thus it will run. T3, which is higher priority than T2, is stuck waiting for T1, which may never run now that T2 is running. Isn’t it sad that the mighty T3 can’t run, while lowly T2 controls the CPU? Having high priority just ain’t what it used to be.You can address the priority inversion problem in a number of ways. In the specific case where spin locks cause the problem, you can avoid using spin locks (described more below). More generally, a higher-priority thread waiting for a lower-priority thread can temporarily boost the lower thread’s priority, thus enabling it to run and overcoming the inversion, a technique known as priority inheritance. A last solution is simplest: ensure all threads have the same priority 不同的操作系统，不同的支持Different OS, Different Support 到目前为止，我们已经看到了操作系统可以提供的一种支持，以便在线程库中建立更有效的锁。其它操作系统也提供类似的支持，细节各不相同。例如，Linux提供了一个于Solaris接口相似的futex，但提供了更多的内核功能。具体来说，每个futex都与一个特定的物理内存位置以及每个futex内核队列相关联。调用程序可以根据需要使用futex calls进行睡眠和唤醒工作。 具体来说，有两个调用可用。假定地址处的值等于预期值，调用futex_wait(address, expected)会使线程进入睡眠状态。如果不相等，则调用立即返回。调用例程futex_wake(address)将唤醒正在队列中等待的一个线程。Linux互斥锁中这些调用的用法如下所示。 1234567891011121314151617181920212223242526272829303132// Linux-based Futex Locksvoid mutex_lock (int *mutex) &#123; int v; /* Bit 31 was clear, we got the mutex (the fastpath) */ if (atomic_bit_test_set (mutex, 31) == 0) return; atomic_increment (mutex); while (1) &#123; if (atomic_bit_test_set (mutex, 31) == 0) &#123; atomic_decrement (mutex); return; &#125; /* We have to waitFirst make sure the futex value we are monitoring is truly negative (locked). */ v = *mutex; if (v &gt;= 0) continue; futex_wait (mutex, v); &#125;&#125;void mutex_unlock (int *mutex) &#123; /* Adding 0x80000000 to counter results in 0 if and only if there are not other interested threads */ if (atomic_add_zero (mutex, 0x80000000)) return; /* There are other threads waiting for this mutex, wake one of them up. */ futex_wake (mutex);&#125; nptl库(gnu libc库的一部分)中lowlevellock.h中的代码很有趣，原因有几个。首先，它使用单个整数来跟踪是否持有锁和锁上的等待数。因此，如果锁为负，则将其保留。其次，代码片段展示了如何针对常见情况进行优化，特别是在没有争用锁的情况下；仅使用一个线程来获取和释放锁，就完成了很少的工作。 Two-Phase Locks最后一点要注意：Linux方法具有一种古老的方法，这种方法已经使用了好几年，至少可以追溯的1960年代初期的Dahm Locks，现在称为two-phase lock。它意识到自旋很有用，特别是在锁即将被释放时。 因此，在第一阶段，锁自旋了一段时间，希望它可以获取锁。但是，如果在第一个自旋阶段未获取锁，则进入第二阶段，在此阶段，调用者进入睡眠状态，并且仅在以后释放锁时才唤醒。上面的Linux锁是这种锁的一种形式，但是它只会自旋一次。对此的一般化可能会在使用futex支持进入睡眠之前，在固定的时间内自旋一个循环。 两阶段锁是混合方法的又一实例，其中结合两个好主意确实可以产生更好的主意。当然，它是否确定取决于很多因素，包括硬件环境，线程数和其它工作负载详细信息。与往常一样，制作一个适用于所有可能用例的通用锁是很大的挑战。 总结上面的方法显示了如何构建真正的锁：某些硬件支持加上某些操作系统的支持。当然，细节有所不同，执行这种锁的确切代码通常经过高度调整。如果要查看更多详细信息，请查看Solaris或Linux代码库。 基于锁的并发数据结构Lock-based Concurrent Data Structures: http://pages.cs.wisc.edu/~remzi/OSTEP/threads-locks-usage.pdf 在离开锁之前，我们将首先介绍如何在一些常见的数据结构中使用锁。在数据结构中添加锁以使其可被线程使用，使该结构线程安全(thread safe)。当然，准确地添加此类锁的方式决定了数据结构的正确性和性能。因此，我们面临的挑战是： CRUX: HOW TO ADD LOCKS TO DATA STRUCTURESWhen given a particular data structure, how should we add locks to it, in order to make it work correctly? Further, how do we add locks such that the data structure yields high performance, enabling many threads to access the structure at once, i.e., concurrently? 并发计数器Concurrent Counters 计数器(counter)是最简单的数据结构之一。它是一种常用的结构，具有简单的接口。下面定义了一个简单的非并行计数器(non-concurrent counter)。 123456789101112131415161718192021// A Counter without Lockstypedef struct __counter_t &#123; int value;&#125; counter_t;void init(counter_t *c) &#123; c-&gt;value = 0;&#125;void increment(counter_t *c) &#123; c-&gt;value++;&#125;void decrement(counter_t *c) &#123; c-&gt;value--;&#125;int get(cunter_t *c) &#123; return c-&gt;value;&#125; 简单但不可扩展(Simple But Not Scalable) 如您所见，非同步计数器(non-synchronized)是一个微不足道的数据结构，需要少量的代码来实现。现在，我们面临下一个挑战：如何使此代码线程安全？下面展示了我们怎样做。 123456789101112131415161718192021222324252627282930// A Counter With Lockstypedef struct __counter_t &#123; int value; pthread_mutex_t lock;&#125; counter_t;void init(counter_t *c) &#123; c-&gt;value = 0; Pthread_mutex_init(&amp;c-&gt;lock, NULL);&#125;void increment(counter_t *c) &#123; Pthread_mutex_lock(&amp;c-&gt;lock); c-&gt;value++; Pthread_mutex_unlock(&amp;c-&gt;lock);&#125;void decrement(counter_t *c) &#123; Pthread_mutex_lock(&amp;c-&gt;lock); c-&gt;value--; Phread_mutex_unlock(&amp;c-&gt;lock);&#125;int get(counter_t *c) &#123; Pthread_mutex_lock(&amp;c-&gt;lock); int rc = c-&gt;value; Pthread_mutex_unlock(&amp;c-&gt;lock); return rc;&#125; 此并发计数器很简单，并且可以正常工作。实际上，它遵循最简单和最基本的并发数据结构共有的设计模式：它仅添加一个锁，该锁在调用操纵数据结构的例程时获取，并在从调用返回时释放。以这种方式，它类似于使用监视器构建的数据结构，其中在您从对象方法调用和返回时自动获取并释放锁。至此，您已经有了一个有效的并发数据结构。您可能回遇到性能问题。如果您的数据结构太慢，则您不仅需要添加一个锁，还需要做更多的事情。因此，如有必要，此类优化是本章其余部分的主题。 为了了解这种简单方法的性能成本，我们运行了一个基准测试(benchmark)，每个线程将一个共享计数器更新固定的次数。然后，我们更改线程数。图29-5显示了总的时间花费，其中一到四线程处于活动状态。每个线程将计数器更新一百万次。该实验是在具有四个CPU的Intel 2.7GHZ i5的iMac上运行的。随着更多CPU的活动，我们希望每单位时间(per unit time)完成更多的工作。 理想情况下，您希望看到线程在多个处理器上完成的速度与单个线程在单处理器上完成的速度一样快。实现这一目标称为完美伸缩(perfect scaling)。即使要完成更多工作，它也是并行完成的，因此完成任务所需的时间不会增加。 伸缩计数(Scalable Counting) 令人惊讶的是，研究人员多年来研究如何构建更多可扩展的计数器。正如操作系统性能分析的最新研究结果表明的那样，可扩展计数器至关重要。如果不进行可扩展计算，Linux上运行的某些工作负载将在多核计算机上遭受严重的可扩展性问题。 已经开发出的许多技术来解决这个问题。我们将介绍一种称为近似计数器(approximate counter)的方法。近似计数器的工作原理是通过多个本地物理计数器(local physical counter)（每个CPU core一个），和一个全局计数器(global counter)来表示单个逻辑计数器。具体来说，在一台具有四个CPU的计算机上，有四个本地计数器和一个全局计数器。除了这些计数器外，还有锁：每个本地计数器一个、全局计数器一个。 近似计数器的基本思想如下。当运行在给定core上的线程希望增加计数器时，它会增加其本地计数器。通过相应的本地锁同步对此本地计数器的访问。因为每个CPU都有自己的本地计数器，所以CPU上的线程可以在不争用的情况下更新本地计数器，因此该计数器的更新是可伸缩的。 但是，为了使全局计数器保持更新，通过获取全局锁并将其递增本地计数器的值，本地值会定期传输到全局计数器。然后将本地计数器归零。此本地到全局(local-to-global)传输的发生频率由阈值S决定。S越小，计数器的行为就越类似于上面的不可伸缩计数器；S越大，计数器的可伸缩性就越大，但是全局值与实际计数的距离可能越远。可以简单地获取所有本地锁和全局锁来获取确切的值，但这是不可伸缩的。 为了清楚起见，我们来看一个示例。下面的例子中，阈值S设置为5，并且四个CPU的每一个上都有线程更新其本地计数器L1…L4。追踪还显示了全局计数器值，随着时间的增加而下降。在每个时间步长，本地计数器都可以增加；如果本地值达到了阈值S，则将本地值传输到全局计数器并重置本地计数器。 图29-5显示了阈值S为1024的近似计数器的性能。性能出色。在四个处理器上更新计数器四百万次所花费的时间几乎不比在一个处理器上更新计数器一百万次所花费的时间高。 图29-6显示了阈值S的重要性，四个线程在四个CPU上分别使计数器递增100万次。如果S低，则性能不佳；如果S高，则性能出色，但全局计数器滞后。这种精度/性能的折衷是近似计数器实现的。 TIP: MORE CONCURRENCY ISN’T NECESSARILY FASTERIf the scheme you design adds a lot of overhead (for example, by acquiring and releasing locks frequently, instead of once), the fact that it is more concurrent may not be important. Simple schemes tend to work well, especially if they use costly routines rarely. Adding more locks and complexity can be your downfall. All of that said, there is one way to really know: build both alternatives (simple but less concurrent, and complex but more concurrent) and measure how they do. In the end, you can’t cheat on performance; your idea is either faster, or it isn’t. 并发链接列表Concurrent Linked Lists]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>OperatingSystem</tag>
        <tag>操作系统</tag>
        <tag>Optimization</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Istio]]></title>
    <url>%2F2019%2F04%2F26%2FIstio%2F</url>
    <content type="text"><![CDATA[参考: Istio docs: https://istio.io/docs Istio中文文档: https://istio.io/zh/docs/ Istio github: https://github.com/istio/istio 环境: RHEL7x86_64 Istio v1.1 概念Concepts Istio是什么What is Istio? Istio允许您连接(connect)，保护(secure)，控制(control)和观察(observe)服务。在较高的层级上，Istio有助于降低部署的复杂性，减轻开发团队的压力。它是一个完全开源的服务网格(service mesh)，可透明地分层到现有的分布式应用程序上。它也是一个平台，包括可以将其集成到任何日志记录平台或策略系统的API。Istio的多样化功能使你能够成功，高效地运行分布式微服务(microservice)架构，并提供安全，连接和监控微服务的统一方法。 服务网格Service Mesh Istio解决了开发人员和运营商在单片应用程序向分布式微服务架构过渡时所面临的挑战。有必要详细了解Istio服务网格。 术语服务网格用于描述构成此类应用程序的微服务网络以及它们之间的交互。随着服务网格的大小和复杂性的增加，理解和管理变得更加困难。其要求包括: 发现(discovery) 负载均衡(load balancing) 故障恢复(failure recovery) 指标(metrics) 监控(monitoring) 服务网格通常还具有更复杂的操作要求，如: A/B测试 金丝片部署(canary rollouts) 速率限制(rate limiting) 访问控制(access control) *端到端认证()end-to-end authentication* Istio作为一个整体提供对服务网格的行为洞察和操作控制。 为什么使用它Why use Istio? 通过负载均衡，服务到服务的身份认证，监控…使用服务代码中很少或不需要更改代码，Istio可以轻松创建已部署的服务网格。通过在整个环境中部署特殊的sidecar代理来拦截服务的Istio支持，该代理拦截微服务之间的所有网络通信，然后使用其控制平面配置和管理Istio。包括: HTTP, gRPC, WebSocket, TCP流量的自动负载均衡； 通过丰富的路由规则，重试(retries)，故障转移(failovers)，故障注入(fault injection)，对流量欣慰 进行细粒度控制； 可插入的策略层和API配置，支持访问控制，速率限制和配额； 集群中所有流浪的自动度量、日志和追踪，包括集群的ingress, egress； 通过强大的基于身份的认证和授权，在鸡群中实现安全的服务到服务的通信。 核心功能Core features 流量管理Traffic management 通过Istio简单的规则配置和流量路由，你可以控制服务之间的流量和API调用。它简化了服务级别的属性配置，如熔断器(circuit breakers)，超时(timeouts)，重试(retries)，并且可以轻松设置A/B测试，金丝片部署(canary rollouts)，基于百分比流量分割的分阶段部署等重要任务。 通过更好地了解流量和开箱即用的故障恢复功能，你可在问题出现之前发现问题，使调用更加可靠、网络更加强大。 安全Security Istio的安全功能使开发人员可以更加专注于应用程序级别的安全性。Istio提供了底层安全通信信道，并大规模管理服务通信的认证、授权和加密。使用Istio，服务通信在默认情况下是安全的，允许你跨多种协议和运行时一致地实施策略。所有这些基本都不用对应用程序进行更改。 虽然Istio与平台无关，但与k8s网络策略一起使用时，其优势更大，包括在网络层和应用层保护pod-to-pod或service-to-service通信的能力。 可观察性Observability Istio强大的追踪、监控和日志记录功能可以让你更深入了解服务网格部署。通过Istio的监控功能，真正了解服务性能如何影响上下游(upstream, downstream)的功能，而其自定义的仪表盘可提供对所有服务性能的可视性，并让你了解该性能如何影响你的其他进程。 Istio的混合器（Mixer)组件负责策略控制和遥测收集。它提供后端抽象和中间媒介，将Istio的其余部分与各个基础架构后端的实现细节隔离开来，并为运营商提供对网格网络和基础架构后端之间所有交互的细粒度控制。 这些功能使你可以更有效地设置，监控和实施服务上的SLOs。当然，最重要的是，你可以快速有效地检测和修复问题。 平台支持Platform support Istio是独立于平台的，旨在各种环境中运行。包括跨云，内在部署，k8s，Mesos…你可在k8s上部署Istio，或在带有Nomad的Consul上部署它。Istio目前支持: Service deployment on Kubernetes Services registered with Consul Services running on individual virtual machines 集成和自定义Integration and customization 可以扩展和自定义Istio的策略实施组件，来与现有的ACL，日志记录，监控，配额，审计等方案集成。 架构Architecture Istio服务网格逻辑上分为数据平面(data plane)和控制平面(data plane)。 数据平面由一组以 sidecar 方式部署的智能代理(Envoy)组成。这些代理可以调节和控制微服务及Mixer之间所有的网络通信。 控制平面负责管理和配置代理来路由流量。此外控制平面配置Mixer以实施策略和收集遥测数据。 EnvoyIstio使用Envoy代理的扩展版本，Envoy是以C++开发的高性能代理，用于调解服务网格中所有服务的所有入站和出站流量。Envoy 的许多内置功能被 Istio 发扬光大，如: 动态服务发现(Dynamic service discovery) 负载均衡(Load balancing) TLS termination HTTP/2 and gRPC proxies 熔断器(Circuit breakers) 健康检查(Health checks) 基于百分比流量拆分的灰度发布 故障注入(Fault injection) 丰富的度量指标(Rich metrics) Envoy 被部署为 sidecar，和对应服务在同一个 k8s pod 中。这允许 Istio 将大量关于流量行为的信号作为属性提取出来，而这些属性又可以在 Mixer 中用于执行策略决策，并发送给监控系统，以提供整个网格行为的信息。Sidecar 代理模型还可以将 Istio 的功能添加到现有部署中，而无需重新构建或重写代码。 MixerMixer 是一个独立于平台的组件，负责在服务网格上执行访问控制和使用策略，并从 Envoy 代理和其他服务收集遥测数据。代理提取请求级属性，发送到 Mixer 进行评估。 Mixer 中包括一个灵活的插件模型，使其能够接入到各种主机环境和基础设施后端，从这些细节中抽象出 Envoy 代理和 Istio 管理的服务。 PilotPilot 为 Envoy sidecar 提供服务发现功能，为智能路由（如 A/B测试、金丝雀部署）和弹性（超时、重试、熔断器）提供流量管理功能。 它将控制流量行为的高级路由规则转换为特定于 Envoy 的配置，并在运行时将它们传播到 sidecar。Pilot 将平台特定的服务发现机制抽象化并将其合成为符合 Envoy 数据平面 API 的任何 sidecar 都可以使用的标准格式。这种松散耦合使得 Istio 能够在多种环境下运行（如 k8s、Consul、Nomad），同时保持用于流量管理的相同操作界面。 CitadelCitadel 通过内置身份和凭证管理赋能强大的服务间和最终用户身份验证。可用于升级服务网格中未加密的流量，并为运维人员提供基于服务标识而不是网络控制的强制执行策略的能力。 GalleyGalley 代表其他的 Istio 控制平面组件，用来验证用户编写的 Istio API 配置。随着时间的推移，Galley 将接管 Istio 获取配置、 处理和分配组件的顶级责任。它将负责将其他的 Istio 组件与从底层平台(如k8s)获取用户配置的细节中隔离开来。 设计目标Design Goals Istio的架构设计中有几个关键目标，这些目标对于使系统能够应对大规模流量和高性能地服务处理至关重要。 最大化透明度(Maximize Transparency) 可扩展性(Extensibility) 可移植性(Portability) 策略一致性(Policy Uniformity) 流量管理Traffic Management]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>k8s</tag>
        <tag>Service Mesh</tag>
        <tag>Microservice</tag>
        <tag>微服务</tag>
        <tag>服务网格</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZooKeeper]]></title>
    <url>%2F2019%2F03%2F15%2FZooKeeper%2F</url>
    <content type="text"><![CDATA[参考: 维基百科 ZooKeeper: https://zookeeper.apache.org/ Docs: https://zookeeper.apache.org/doc/ 环境: RHEL7x86_64 ZooKeeper v3.5 介绍 ZooKeeper: Because Coordinating Distributed Systems is a Zoo. Apache ZooKeeper 是Apache软件基金会的一个软件项目，它为大型分布式计算提供开源的分布式配置服务、同步服务和命名注册，实现高度可靠的分布式协调。ZooKeeper曾经是Hadoop的一个子项目，但现在是一个独立的顶级项目。 ZooKeeper 是一种集中式服务，用于维护配置信息(conf info)，命名(naming)，分布式同步(distributed synchronization)，组服务(group service)。所有这些类型的服务都以分布式应用程序的某种形式应用。每次实施它们都需要做很多工作来修复不可避免的错误和竞争条件。由于难以实现这些类型的服务，应用程序最初通常会吝啬它们，这使得它们在变化的情况下变得脆弱并且难以管理。即使正确完成，这些服务的不同实现也会在部署应用程序时导致管理复杂性。 ZooKeeper的架构通过冗余服务实现高可用性。因此，如果第一次无应答，客户端就可以询问另一台ZooKeeper主机。ZooKeeper节点将它们的数据存储于一个分层的命名空间，非常类似于一个文件系统或一个前缀树结构。客户端可以在节点读写，从而以这种方式拥有一个共享的配置服务。更新是全序的。 概述ZooKeeper: A Distributed Coordination Service for Distributed Applications ZooKeeper 是一种用于分布式应用程序的分布式开源协调(coordination)服务。它被设计为易于编程，并使用在熟悉的文件系统目录树结构之后设计的数据模型。它在Java中运行，并具有Java和C的绑定。 众所周知，协调服务很难做到。他们特别容易出现竞赛条件(race conditions)和死锁(deadlock)。ZooKeeper背后的动机是减轻分布式应用程序从头开始实施协调服务的责任。 设计目标Design Goals ZooKeeper is simple ZooKeeper允许分布式进程通过 共享的层级命名空间(shared hierarchal namespace) 相互协调，该命名空间的组织方式与标准文件系统类似。命名空间由 数据寄存器(data registers) 组成——在ZooKeeper用语中被称为 znodes，这些与文件和目录类似。与专为存储而设计的典型文件系统不同，ZooKeeper数据保存在内存中，这意味着ZooKeeper可以实现高吞吐量(high throughput)和低延迟数(latency numbers)。 ZooKeeper的实现非常重视 高性能(high performance)， 高可用(highly available)， 严格有序的访问(strictly ordered access)。性能方面意味着它可以在大型分布式系统中使用。可靠性方面使其不会成为单点故障(a single point of failure)。严格的排序意味着可以在客户端实现复杂的同步原语。 ZooKeeper is replicated 与它协调的分布式进程一样，ZooKeeper本身也可以在称为 集合(ensemble) 的一组主机上进行 副本复制(replicated)。 组成ZooKeeper服务的Server必须了解彼此。它们维护一个内存中的状态镜像，以及持久性存储的事务日志和快照。只要大多数Servers可用，ZooKeeper服务就可用。 Client连接到单个Server。Client维护TCP连接，通过该连接发送请求，获取响应，获取监视事件(watch events)，以及发送心跳(heart beats)。如果与Server的TCP连接中断，则Client将连接到其它Server。 ZooKeeper is ordered ZooKeeper使用反映所有ZooKeeper事务顺序的数字标记每个更新。后续操作可以使用该顺序来实现更高级别的抽象，例如同步原语。 ZooKeeper is fast 它在读取 read-doninant 工作负载中特别快。ZooKeeper应用程序运行在成千上万的计算机上，并且在读取别写入更常见的情况下(比率10:1)表现最佳。 数据模型和分层命名空间Data model and the hierarchical namespace ZooKeeper提供的命名空间非常类似于标准文件系统。名称是由斜杠(/)分隔的路径元素序列。ZooKeeper命名空间中的每个节点都由路径标识。 节点和短暂节点Nodes and ephemeral nodes 与标准文件系统不同，ZooKeeper命名空间中的每个节点都可包含与之关联的数据以及孩子。这就像拥有一个允许文件也是目录的文件系统。ZooKeeper旨在存储协调数据：状态信息，配置，位置信息等，因此存储在每个节点的数据通常很小。我们使用术语 znode 来表明我们正在谈论的ZooKeeper数据节点。 Znodes 维护一个 状态结构(stat structure)，其中包括数据更改、ACL更改、时间戳更改，以允许缓存验证和协调更新。每次znode的数据更改时，版本号都会增加。例如，每当Client检索数据时，它也接收数据的版本。 存储在每个znode命名空间中的数据以原子(atomically)方式进行读写。读取与znode关联的所有数据字节，写入替换所有的数据。每个节点都有一个ACL限制谁可以做什么。 ZooKeeper也有 短暂节点(ephemeral nodes) 的概念。只要创建的znode处于活动状态，就会存在这些znode，回话结束时，znode将被删除。当你想要实现 [tbd] 时，短暂节点很有用。 协调更新和监视Conditional updates and watches ZooKeeper支持监视(watch)的概念。Client可以在znode上设置监视。当znode更改时，将触发并删除监视。触发监视时，Client会受到一个数据包，指出znode已更改。如果Client与其中一个ZooKeeper Server之间的连接中断，则Client将收到本地通知。这可以用于 [tbd] 。 保证Guarantees ZooKeeper非常快速和简单。但是，由于基于目标是构建更复杂的服务(如同步)的基础，因此它提供了一系列保证。这些是: 顺序一致性(Sequential Consistency): Client的更新将按发送顺序来应用 原子性(Atomicity): 更新成功或失败，没有其它结果 单系统镜像(Single System Image): 无论连接到哪个Server，Client都将看到相同的服务视图 可靠性(Reliability): 一旦更新被应用，它将从该时间开始持续，知道Client覆盖此更新 时宜性(Timeliness): 系统的Client视图保证在特定的时间范围内是最新的 APIZooKeeper的设计目标之一是提供非常简单的编程接口。因此，它仅支持以下操作: create: creates a node at a location in the tree delete: deletes a node exists: tests if a node exists at a location get data: reads the data from a node set data: writes data to a node get children: retrieves a list of children of a node sync: waits for data to be propagated 执行Implementation ZooKeeper组件显示了ZooKeeper服务的高级组件。除了请求处理器，构成ZooKeeper服务的每个Server都复制自己每个组件的副本。 副本数据库是一个包含整个数据树的内存数据库。更新将记录到磁盘以获得可恢复性，并且在写入内存数据库之前会序列化的磁盘 每个ZooKeeper Server都为Client服务。Client只连接到一台Server以提交请求。读取请求由每个Server数据库的本地副本提供。更改服务状态的请求，写请求由 协定协议(agreement protocol) 处理 作为协定协议的一部分，来自Client的所有写入请求都被转发到称为 leader 的单个Server。其余的ZooKeeper Server，称为follower，接收来自leader的消息提议并同意消息传递。消息传递层负责替换失败的leader，并将follower与leader同步 ZooKeeper使用自定义的原子消息(atomic messaging)协议。由于消息传递层是原子的，因此ZooKeeper可以保证本地副本永远不会发散。当leader收到写入请求时，它会计算应用写入时系统的状态，并将其转换为捕获此新状态的事务。 用户ZooKeeper的编程接口非常简单。但是，通过它，您可以实现更高阶的操作，例如同步原语，组成员身份，所有权等。 性能Performance ZooKeeper旨在提供高性能。在读取数量超过写入的应用程序中，它的性能尤其高，因为写入涉及同步所有Server的状态。 The events marked in the figure are the following: Failure and recovery of a follower Failure and recovery of a different follower Failure of the leader Failure and recovery of two followers Failure of another leader 入门ZooKeeper Getting Started Guide]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Apache</tag>
        <tag>ZooKeeper</tag>
        <tag>DataAnalysis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SonarQube]]></title>
    <url>%2F2019%2F02%2F22%2FSonarQube%2F</url>
    <content type="text"><![CDATA[参考: GitHub: https://github.com/SonarSource/sonarqube Website: https://www.sonarqube.org/ Docs: https://docs.sonarqube.org 环境: RHEL7x86_64 SonarQube v7.6 介绍SonarQube 是一个开源的代码质量管理系统。支持超过25中编程语言，不过有些是商业插件。 SonarQube 是一种自动代码审查(code review)工具，用于检测代码中的错误(bugs)，漏洞(vulnerabilities)和代码异味(code smell)。它可以与您现有的工作流程集成，以便在项目分支和拉取请求之间进行连续的代码检查。 架构与集成Architecture and Integration 概述SonarQube平台由4个组件组成: SonarQube Server启动三个主进程: Web Server，供开发人员，管理人员浏览质量快照并配置SonarQube实例 Search Server，基于ElasticSearch从UI返回搜索 Compute Engine Server，负责处理代码分析和上报并将其保存到SonarQube数据库中 SonarQube Database用于存储 SonarQube实例的配置(安全，插件…的设置) 项目，视图…的质量快照 Server上安装了多个插件，可能包括Language，SCM，Intergration，Authentication，Governance… 在CI/CD Server上运行一个或多个 SonarScanner 来分析项目 集成Integration 以下模式显示了SonarQube如何与其它ALM工具进行集成，以及在哪里使用SonarQube的各种组件。 开发者在他们的IDE中集成SonarLint运行本地分析 开发者推送他们的代码到代码库 CI Server触发自动构建，以及执行运行SonarQube分析所需的SonarScanner 分析报告将发送到SonarQube Server进行处理 SonarQube Server处理分析报告并将结果存储在SonarQuebe数据库中，并在UI中显示结果 开发者通过SonarQube UI审核，评论，挑战他们的Issues以管理和减少他们的技术债务 管理者从分析中接收报告，运维使用API自动配置并从SonarQube中提取数据，使用JMX监控SonarQube Server 关于机器和位置About Machines and Locations SonarQube平台不能够有多个SonarQube Server和SonarQube Database 为获得最佳性能，每个组件(Server, Database, Scanner)应该安装在单独的机器上，并且此机器应该是专用的 SonarScanner通过添加机器进行扩展 所有机器必须时钟同步 SonarQube Server和SonarQube Database必须位于同一网络下 SonarScanner不需要与SonarQube Server位于同一网络下 SonarScanner与SonarQube Database之间没有通信 要求Requirements 先决条件Prerequisites and Overview 运行SonarQube的唯一先决条件是安装Java(Oracle JRE 8/OpenJDK 8)。 硬件要求 2Cores+ 2GB RAM+ 建议使用高性能I/O的磁盘 支持的平台 Java Oracle JRE 8 OpenJDK 8 Database PostgreSQL v9.3-v9.6, v10. UTF-8 charset SQL Server v2014, v2016. Oracle v11, v12, vXE. UTF8-family charset, thin mode MySQL v5.6, v5.7. UTF8 charset, InnoDB storage, mysql-connector-java Web Browser IE 11 Edge Latest FireFox Latest Chrome Safari 平台说明 Linux如果在Linux上运行，请确保: vm.max_map_count 大于或等于 262144 fs.file-max 大于或等于 65535 运行SonarQube的用户可以打开至少65535个文件描述符 运行SonarQube的用户可以打开至少2048个线程 用以下命令查看和配置它们: 12345678910111213141516171819sysctl vm.max_map_countsysctl fs.file-maxulimit -nulimit -u# 配置，但只是临时生效# rootsysctl -w vm.max_map_count=262144sysctl -w fs.file-max=65536ulimit -n 65536ulimit -u 2048# 永久生效# /etc/sysctl.d/99-sonarqube.conf 或 /etc/sysctl.conf# user: sonarqubesonarqube - nofile 65536sonarqube - nproc 2048 如果使用systemd来启动SonarQube，你必须在[Service]的单元文件中指定这些限制: 1234[Service]...LimitNOFILE=65536LimitNPROC=2048 seccomp filter默认情况下，ElasticSearch使用seccomp filter。在大多数发行版中，此功能在内核中激活。但在RHL6等发行版上，此功能已停用。如果你的发行版中没有此功能，请无法升级到激活了seccomp filter功能的版本，则必须通过更新$SONARQUBEHOME/conf/sonar.properties_中的sonar.search.javaAdditionalOpts配置: 12345678910sonar.search.javaAdditionalOpts=-Dbootstrap.system_call_filter=false# 检查grep SECCOMP /boot/config-$(uname -r)# 如果内核有它，你将看到CONFIG_HAVE_ARCH_SECCOMP_FILTER=yCONFIG_SECCOMP_FILTER=yCONFIG_SECCOMP=y 配置和升级Setup and Upgrade 快速入门Get Started in Two Minutes Guide 从ZIP文件安装 使用Docker zip文件安装 现在 SonarQube CE 解压 运行 访问 12345# 具体位置取决于你的安装位置/opt/sonarqube/bin/[OS]/sonar.sh console# localhost:9000（admin/admin） Docker安装在Docker Hub上下载对应CE的镜像，上面有安装和配置的详细信息。 安装Server支持多个数据库引擎，请务必遵守各个数据库引擎的要求。 创建一个空的schema和一个sonarqube用户。授予此用户create, update, delete此schema对象的权限。 1234CREATE SCHEMA `sonar` DEFAULT CHARACTER SET utf8 ;CREATE USER 'sonarqube'@'localhost' IDENTIFIED BY 'sonarqube-PW123';GRANT ALL ON sonar.* TO 'sonarqube'@'localhost'; 安装数据库 SQL Server跳过，有需要的请看: https://docs.sonarqube.org/latest/setup/install-server/ Oracle跳过！ PostgreSQL如果你想使用custom schema而不是默认的public schema，则必须设置PostgreSQL的search_path属性: 1ALTER USER mySonarUser SET search_path to mySonarQubeSchema MySQL 注意:Data Center Edition(Enterprise)不支持MySQL!Data Center Edition: Designed for High Availability 可在MySQL中使用两种众所周知的数据库引擎: MyISAM和InnoDB。MyISAM是最老的，并且正在逐渐被InnoDB替代。随着质量控制项目数量的增加，InnoDB显然更快，并且使用SonarQube可以更好地扩展。如果你是SonarQube的早期使用者，你可能有一系列仍在使用MyISAM引擎的表。你应该将所有表的引擎更改为InnoDB。 一旦所有SonarQube表都使用InnoDB引擎，首先要做的是使用innodb_buffer_pool_size参数为MySQL实例分配最大的RAM，并为query_cache_size参数提供至少15Mb。 阅读这篇文档InnoDB Performance Optimization来优化InnoDB。 安装Web Server首先，检查安装要求；下载和解压压缩的发行版(不要解压到以数字开头的目录)；下面变量SONARQUBE-HOME指的是解压的路径。 设置数据库访问编辑$SONARQUBE-HOME/conf/sonar.properties来配置数据库设置。模板可用于每个受支持的数据库。 1234# Example for MySQLsonar.jdbc.username=sonarqubesonar.jdbc.password=sonarqube-PW123sonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance&amp;useSSL=false 添加JDBC驱动已提供受支持数据库(Oracle除外)的驱动程序。不要更换提供的驱动程序，它们是唯一受支持的。 对于Oracle，将JDBC驱动复制到$SONARQUBE-HOME/extensions/jdbc-driver/oracle。 配置ElasticSearch存储路径默认情况下，ES数据存储在$SONARQUBE-HOME/data中，但不建议用于生产环境。相反，你应该将数据存储在其它位置，最好是在具有高速I/O的专用卷。除了保持可接受的性能之外，还可简化SonarQube的升级。 编辑$SONARQUBE-HOME/conf/sonar.properties来配置以下设置: 123# 请记得添加读写权限sonar.path.data=/var/sonarqube/datasonar.path.temp=/var/sonarqube/temp 启动Web Server可在$SONARQUBE-HOME/conf/sonar.properties配置监听地址和端口等。 123sonar.web.host=192.0.0.1sonar.web.port=80sonar.web.context=/sonarqube 1234# 启动bin/sonar.sh start# 默认admin/admin 调整Web服务器默认情况下，SonarQube配置为在任何具有简单Java JRE的计算机上运行。 为了更好地性能，生产环境实例要做的第一件事是使用Java JDK并通过在sonar.web.javaOpts=-server中设置以下行来激活服务器模式。 1sonar.web.javaOpts=-server 要修改SonarQube使用的Java JVM只需编辑$SONARQUBE-HOME/conf/wrapper.conf并更新以下行: 1wrapper.java.command=/path/to/my/jdk/bin/java FAQdocs: https://docs.sonarqube.org/latest/setup/install-server/ 配置和操作ServerConfigure &amp; Operate the Server 以SystemD运行Running SonarQube as a Service on Linux with SystemD 假设如下信息: sonarqube用户 sonarqube组 java virtual machine安装在/opt/java/ sonarqube解压在/opt/sonarqube/ 创建sonarqube用户: 1useradd -M -s /sbin/nologin 创建service文件/etc/systemd/system/sonarqube.service，具体详情请安装自己的实际情况进行修改。 123456789101112131415161718[Unit]Description=SonarQube serviceAfter=syslog.target network.target[Service]Type=simpleUser=sonarqubeGroup=sonarqubePermissionsStartOnly=trueExecStart=/bin/nohup /opt/java/bin/java -Xms32m -Xmx32m -Djava.net.preferIPv4Stack=true -jar /opt/sonarqube/lib/sonar-application-7.6.jarStandardOutput=syslogLimitNOFILE=65536LimitNPROC=8192TimeoutStartSec=5Restart=always[Install]WantedBy=multi-user.target 123# 启动sudo systemctl enable sonarqube.servicesudo systemctl start sonarqube.service 在代理服务器后保护ServerSecuring the Server Behind a Proxy Server配置要通过HTTPS运行SonarQube Server，必须构建标准的反向代理服务器。必须配置反向代理，在每个HTTP Request Header中设置X_FORWARDED_PROTO: https值。如果没有此属性，SonarQube Server启动的重定向将回退到HTTP。 使用Apache代理跳过！ 使用Nginx代理123456789101112# the server directive is nginx&apos;s virtual host directiveserver &#123; # port to listen on. Can also be set to an IP:PORT listen 80; # sets the domain[s] that this vhost server requests for server_name www.somecompany.com; location / &#123; proxy_pass http://sonarhost:sonarport; &#125;&#125; 使用IIS跳过！ 安装插件在SonarQube中安装插件有两种选择: Marketplace，从SonarQube UI自动地安装插件 手动安装， 如果SonarQube实例无法访问Internet，请使用此方法 安装C/C++插件由于SonarQube的C, C++是商业版才有的功能，所以我使用的CE版就不支持对这两个语言的静态检查。 后来看到 SonarOpenCommunity: https://github.com/SonarOpenCommunity，它里面有这个插件，先感谢开发者，然后再使用。 sonar-cxx: https://github.com/SonarOpenCommunity/sonar-cxx，查看相关说明进行安装和配置。 安装 明白哪个插件版本与当前使用的SonarQube版本监控 下载jar插件，将其放置于$ SONARQUBE_HOME/extensions/plugins目录下 sonar-cxx-plugin-x.y.z.jar: c++ plug-in sonar-c-plugin-x.y.z.jar: c plug-in 重启SonarQube Server 在UI上的Marketplace查看更新 安装PS/SQL插件由于SonarQube的PL, SQL是商业版才有的功能，所以我使用的CE版就不支持对这两个语言的静态检查。 后来看到: sonar-plsql: https://github.com/felipebz/sonar-plsql 社区开源项目，先感谢开发者，再使用。 安装方法与上面的C/C++一样，下载当前版本支持的插件到对应目录，重启SonarQube Server。 将Server安装为集群docs: https://docs.sonarqube.org/latest/setup/install-cluster/ 先跳过！ 配置和操作集群Configure &amp; Operate a Cluster docs: https://docs.sonarqube.org/latest/setup/operate-cluster/ 先跳过！ 升级Upgrade the Server 自动处理non-LTS版本的升级。但是，如果在迁移路径中有LTS版本，则必须先迁移LTS，然后再迁移到目标版本。 例如，v5.1 -&gt; v7.0，迁移路径为 v5.1 -&gt; 5.6.7 LTS -&gt; v6.7.x LTS -&gt; v7.0。 如何升级在开始之前，请备份SnarQube Database。升级问题虽然很少见，但备份确实必须的。 分析源代码Analyzing Source Code 概述一旦安装了SonarQube平台，你就可以安装分析器(analyzer)并开始创建项目了。为此，你必须安装和配置适合你需求的扫描器(scanner)。Do you build with: Gradle - SonarScanner for Gradle MSBuild - SonarScanner for MSBuild Maven - use the SonarScanner for Maven Jenkins - SonarScanner for Jenkins Azure DevOps - SonarQube Extension for Azure DevOps Ant - SonarScanner for Ant anything else (CLI) - SonarScanner 注意，不建议在运行SonarQube Scanner Analysis的机器上运行反病毒扫描程序，这可能会导致不可预测的行为。 分析产生了什么What does analysis produce? SonarQube可以对20多种不同的语言进行分析。该分析的结果是 quality measures 和 issues。但是，分析的结果也会因语言而异: 在所有语言中，blame数据将自动从支持的SCM提供程序导入(自动支持Git和SVN)。其它提供需要额外的插件 在所有语言中，执行源代码的静态分析 可对某些语言执行编译代码的静态分析 可对某些语言执行代码的动态分析 是否会分析所有文件Will all files be analyzed? 默认情况下，在分析期间，只有语言分析器(language analyzer)可识别的文件才会加载到项目中。 分析期间会发生什么What happens during analysis? 在分析期间，从Server请求数据，分析提供给分析的文件，并以报告的形式将结果返回到Server，然后在Server-Side异步分析。 分析上报排队并按顺序处理，因此很可能在分析日志显示完成后的短暂时间内，更新的值在SonarQube项目中不可见。但是，你能够分辨出正在发生的事情，因为项目名称右侧的项目主页上会有一个图标。 分析参数Analysis Parameters 可以在多个位置设置用于配置项目分析的参数。这是参数的层次结构： 在UI里定义的全局分析参数(Global)，Administration &gt; Configuration &gt; General Settings 在UI里定义的项目分析参数(Project)，Project Level &gt; Administration &gt; General Settings 在项目分析配置文件或分析器配置文件中定义的项目分析参数 分析/命令行参数，再启动分析时定义，覆盖项目分析参数 注意，只有通过UI设置的参数才会存储在数据库中。 强制参数Mandatory Parameters Server Key Description Default sonar.host.url the server URL http://localhost:9000 Project Configuration Key Description Default sonar.projectKey The project’s unique key. Allowed characters are: letters, numbers, - , _ , . and : , with at least one non-digit. For Maven projects, this is automatically set to &lt;groupId&gt;:&lt;artifactId&gt; sonar.sources Comma-separated paths to directories containing source files. Read from build system for Maven, Gradle, MSBuild projects 可选参数Optional Parameters Project Identity Key Description Default sonar.projectName 显示在Web实例上的项目名称 Maven项目的&lt;name&gt;，否则为项目密钥。如果DB中已有名称，则不会覆盖该名称 sonar.projectVersion 项目版本 Maven项目的&lt;version&gt;，否则未提供 Authentication Key Description Default sonar.login 具有项目执行分析权限的SonarQube用户的登录或身份验证Token xxx sonar.password 与sonar.login用户名一起使用的密码。如果正在使用身份验Token，则应将此项留空 xxx Web Services Key Description Default sonar.ws.timeout 等待Web服务调用响应的最长时间（秒）。只有在等待服务器响应Web服务调用时在分析期间遇到超时时，才能从默认值修改此值。 60 Project Configuration Key Description Default sonar.projectDescription 项目描述。与Maven不兼容 &lt;description用于Maven项目 sonar.links.homepage 项目主页，与Maven不兼容 &lt;url&gt;用于Maven项目 sonar.links.ci CI，与Maven不兼容 &lt;ciManagement&gt;&lt;url&gt;用于Maven项目 sonar.links.issue Issue tracker，与Maven不兼容 &lt;issueManagement&gt;&lt;url&gt;用于Maven项目 sonar.links.scm 项目原仓库，与Maven不兼容 &lt;scm&gt;&lt;url&gt;用于Maven项目 sonar.links.scm_dev 开发者连接，与Maven不兼容 &lt;scm&gt;&lt;developerConnection&gt;用于Maven项目 sonar.tests 包含测试的目录的逗号分隔路径,与Maven不兼容 Maven项目的默认测试位置 sonar.sourceEncoding 源文件编码 系统编码 sonar.externalIssuesReportPaths 以逗号分隔的通用Issue上报路径列表 sonar.projectDate 为分析指定日期(yyyy-MM-dd) 当前日志 sonar.projectBaseDir 当您需要在除启动它之外的目录中进行分析时，请使用此属性 xxx sonar.working.directory 设置使用SonarScanner或SonarScanner for Ant（版本大于2.0）触发的分析的工作目录 .sonar sonar.scm.provider 此属性可用于明确告知SonarQube应使用哪个SCM插件来获取项目上的SCM数据 xxx sonar.scm.forceReloadAll 默认情况下，仅检索已更改文件的blame信息。将此属性设置为true可加载所有文件的blame信息 xxx sonar.coverage.jacoco.xmlReportPaths 导入以XML文件形式提供的JaCoCo代码覆盖率报告。此属性接受多个逗号分隔的条目。必须在分析之前生成JaCoCo XML报告 target/site/jacoco/jacoco.xml build/reports/jacoco/test/jacocoTestReport.xml Duplications Key Description Default sonar.cpd.exclusions 要从复制检测中排除的以逗号分隔的文件路径模式列表 xxx sonar.cpd.${language}.minimumtokens xxx 100 sonar.cpd.${language}.minimumLines 如上 10 Analysis Logging Key Description Default sonar.log.level 控制分析期间生成的日志级别 INFO sonar.verbose 向客户端和服务器端分析日志添加更多详细信息 false sonar.showProfiling 显示日志以查看分析仪花费时间的位置 false sonar.scanner.dumpToFile 将指向文件的完整属性列表输出到扫描程序API，作为调试分析的方法 xxx sonar.scanner.metadataFilePath 设置扫描程序写入report-task.txt文件的位置，该文件包含ceTaskId等 sonar.working.directory的值 后台任务Background Tasks 一个后台任务可以是: 导入一个分析报告 the computation of a Portfolio 导入或导出一个项目 扫描程序完成分析后会发生什么What happens after the scanner is done analyzing? 在相关后台任务完成之前，分析尚未完成。即使SonarScanner的日志显示执行完成，在完成后台任务之前，分析结果在SonarQube项目中将不可见。在SonarScanner外出分析代码后，分析结果(Sources, Issues, Metrics) - 分析报告 - 将发送到SonarQube Server，一共计算引擎进行最终处理。分析报告按顺序排队和处理。 在项目级别，当有待处理的分析报告等待消耗时，标题中的Pending（待处理）通知将在最近完成的分析的日期旁。 全局管理员可在Administration &gt; Projects &gt; Background Tasks查看当前队列；项目管理员可在Administration &gt; Background Tasks查看相关任务。 如何知道分析报告处理失败的时间How do I know when analysis report processing fails? 后台任务通常会成功，但有时候异常会导致处理失败。例如: 处理大项目是内存不足(OOM) 现有模块或项目的密钥与报告中的密钥冲突 … 当发生这种情况时，失败的状态会反映在项目主页上，但这需要有人注意到它。你还可以选择在后台任务失败时通过电子邮件接收通知(Notifications)——无论是逐个还是全局。 如何诊断失败的后台任务How do I diagnose a failing background task? 对于没法分析报告，都有一个下拉菜单，允许你访问扫描程序上下文(Scanner Context)，显示代码扫描是扫描程序的配置。如果任务处理失败，则可使用其它选项显示错误详细信息(Show Error Details)，以获取处理后台任务失败的详情。 如何取消待处理的分析报告How do I cancel a pending analysis report? 管理员可通过单击取消处理待处理任务(pending task)，一旦报告开始处理，取消它就为时已晚。 通用问题数据Generic Issue Data SonarQube支持通用导入格式，用于在代码中引发external issues。它旨在允许你从你喜欢的linter导入issues，即使它不存在插件。 外部问题受到两个重要限制: 它们无法在SonarQube内管理 在SonarQube中无法管理引发这些问题的规则的激活 Import分析参数sonar.externalIssueReportPaths接受以逗号分隔的报告路径列表。每个报告必须在顶层(top-level)包含一个名为issues对象的问题对象数组。 Issue字段: engineId - string ruleId - string primaryLocation - Location object type - string. One of BUG, VULNERABILITY, CODE_SMELL severity - string. One of BLOCKER, CRITICAL, MAJOR, MINOR, INFO effortMinutes - integer, optional. Defaults to 0 secondaryLocations - array of Location objects, optional Location字段: message - string filePath - string textRange - TextRange object, optional for secondary locations only TextRange字段: startLine - integer. 1-indexed endLine - integer, optional. 1-indexed startColumn - integer, optional. 0-indexed endColumn - integer, optional. 0-indexed 栗子以下是预期格式的栗子: 1234567891011121314151617181920212223242526272829303132333435363738394041&#123; &quot;issues&quot;: [ &#123; &quot;engineId&quot;: &quot;test&quot;, &quot;ruleId&quot;: &quot;rule1&quot;, &quot;severity&quot;:&quot;BLOCKER&quot;, &quot;type&quot;:&quot;CODE_SMELL&quot;, &quot;primaryLocation&quot;: &#123; &quot;message&quot;: &quot;fully-fleshed issue&quot;, &quot;filePath&quot;: &quot;sources/A.java&quot;, &quot;textRange&quot;: &#123; &quot;startLine&quot;: 30, &quot;endLine&quot;: 30, &quot;startColumn&quot;: 9, &quot;endColumn&quot;: 14 &#125; &#125;, &quot;effortMinutes&quot;: 90, &quot;secondaryLocations&quot;: [ &#123; &quot;message&quot;: &quot;cross-file 2ndary location&quot;, &quot;filePath&quot;: &quot;sources/B.java&quot;, &quot;textRange&quot;: &#123; &quot;startLine&quot;: 10, &quot;endLine&quot;: 10, &quot;startColumn&quot;: 6, &quot;endColumn&quot;: 38 &#125; &#125; ] &#125;, &#123; &quot;engineId&quot;: &quot;test&quot;, &quot;ruleId&quot;: &quot;rule2&quot;, &quot;severity&quot;: &quot;INFO&quot;, &quot;type&quot;: &quot;BUG&quot;, &quot;primaryLocation&quot;: &#123; &quot;message&quot;: &quot;minimal issue raised at file level&quot;, &quot;filePath&quot;: &quot;sources/Measure.java&quot; &#125; &#125;]&#125; 通用测试数据Generic Test Data 开箱即用，SonarQube支持用于测试覆盖和测试执行导入的通用格式。如果你的语言不插件不支持你的Coverage引擎的本机输出格式，只需将它们转换为这些格式即可。 Generic Coverage报告路径应该以逗号分隔的列表传递给: sonar.coverageReportPaths 支持的格式由sonar-generic-coverage.xsd进行描述: 123456789101112131415161718192021222324&lt;xs:schema&gt; &lt;xs:element name=&quot;coverage&quot;&gt; &lt;xs:complexType&gt; &lt;xs:sequence&gt; &lt;xs:element name=&quot;file&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;&gt; &lt;xs:complexType&gt; &lt;xs:sequence&gt; &lt;xs:element name=&quot;lineToCover&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;&gt; &lt;xs:complexType&gt; &lt;xs:attribute name=&quot;lineNumber&quot; type=&quot;xs:positiveInteger&quot; use=&quot;required&quot;/&gt; &lt;xs:attribute name=&quot;covered&quot; type=&quot;xs:boolean&quot; use=&quot;required&quot;/&gt; &lt;xs:attribute name=&quot;branchesToCover&quot; type=&quot;xs:nonNegativeInteger&quot;/&gt; &lt;xs:attribute name=&quot;coveredBranches&quot; type=&quot;xs:nonNegativeInteger&quot;/&gt; &lt;/xs:complexType&gt; &lt;/xs:element&gt; &lt;/xs:sequence&gt; &lt;xs:attribute name=&quot;path&quot; type=&quot;xs:string&quot; use=&quot;required&quot;/&gt; &lt;/xs:complexType&gt; &lt;/xs:element&gt; &lt;/xs:sequence&gt; &lt;xs:attribute name=&quot;version&quot; type=&quot;xs:positiveInteger&quot; use=&quot;required&quot;/&gt; &lt;/xs:complexType&gt; &lt;/xs:element&gt;&lt;/xs:schema&gt; 看起来像这样: 123456789&lt;coverage version=&quot;1&quot;&gt; &lt;file path=&quot;xources/hello/NoConditions.xoo&quot;&gt; &lt;lineToCover lineNumber=&quot;6&quot; covered=&quot;true&quot;/&gt; &lt;lineToCover lineNumber=&quot;7&quot; covered=&quot;false&quot;/&gt; &lt;/file&gt; &lt;file path=&quot;xources/hello/WithConditions.xoo&quot;&gt; &lt;lineToCover lineNumber=&quot;3&quot; covered=&quot;true&quot; branchesToCover=&quot;2&quot; coveredBranches=&quot;1&quot;/&gt; &lt;/file&gt;&lt;/coverage&gt; 根节点应该命名为coverage，其version属性应设置为1。 为每个文件插入一个可由测试覆盖的文件元素。其path属性可以是绝对的，也可是相对的。它具有以下属性: lineNumber(强制性) covered(强制性) - 布尔值，指示测试是否实际命中改行 branchesToCover(可选) - 可覆盖的分支数量 coveredBranches(可选) - 实际有测试覆盖的分支数量 Generic Execution报告路径应以逗号分隔的列表传递给: sonar.testExecutionReportPaths 支持的格式如下: 1234567891011121314&lt;testExecutions version=&quot;1&quot;&gt; &lt;file path=&quot;testx/ClassOneTest.xoo&quot;&gt; &lt;testCase name=&quot;test1&quot; duration=&quot;5&quot;/&gt; &lt;testCase name=&quot;test2&quot; duration=&quot;500&quot;&gt; &lt;skipped message=&quot;short message&quot;&gt;other&lt;/skipped&gt; &lt;/testCase&gt; &lt;testCase name=&quot;test3&quot; duration=&quot;100&quot;&gt; &lt;failure message=&quot;short&quot;&gt;stacktrace&lt;/failure&gt; &lt;/testCase&gt; &lt;testCase name=&quot;test4&quot; duration=&quot;500&quot;&gt; &lt;error message=&quot;short&quot;&gt;stacktrace&lt;/error&gt; &lt;/testCase&gt; &lt;/file&gt;&lt;/testExecutions&gt; 根节点应该被命名为testExecutions，它的version属性应该被设置成1。为每个测试文件插入一个文件元素，其path属性可以是绝对的，也可是相对于模块的根。 注意，与覆盖率报告不同，报告中的文件必须是测试文件名，而不是测试所涵盖的源代码文件。 在file元素内，通过单元测试为每个测试运行插入一个testCase。它具有以下属性/子项: testCase（强制性） name（强制性）: 测试事例的名称 duration(强制性): long value，ms为单位 failure|error|skipped(可选): 如果测试不正确，请使用消息和长描述报告原因 message(强制): 描述原因的短消息 stacktrace（可选）: 包含有关失败、错误、跳过状态的详细信息 PR分析Pull Request Analysis PR分析是作为Developer Edtion的一部分提供。它允许你: 在SonarQube UI中查看你的PR分析结果并查看状态以显示存在未解决的问题 在你的SCM提供商界面中使用SonarQube issue自动装饰你的PR 从项目的branch and pull request的下拉菜单中可以在SonarQube中看到PR。启用PR装饰后，SonarQube会在PR上发布分析状态。 SCM集成在代码分期期间收集SCM数据可以解锁许多SonarQube功能: 自动Issue分配 代码查看器中查看代码注释 SCM-driver的新代码检测，没有SCM数据，SonarQube使用分析日期确定新代码 SCM集成需要你的SCM提供商，默认情况下支持SVN和Git。其它提供商，请参阅Marketplace。如果需要，你可以通过管理设置将其在全局/项目级别将其关闭。 Git SVN Branches分支分析作为Developer Editon的一部分提供。分支分析允许你: 分析 long-lived branches 分析 short-lived branches 在短期分支的状态受到影响时通知外部系统 由于分支功能是开发版(也就是付费版)功能，因此社区版只能对每个分支创建一个项目。 例如: 1234567891011repo: zhang-repobranch: - master - test - zhangprojects: - zhang-repo-master - zhang-repo-test - zhang-repo-zhang 用户指南User Guide 修复漏水Fixing the Water Leak 什么是漏水What is the Water Leak 想象一下，有一天你回到家发现厨房地板上有一滩水，水慢慢变大。你想去拿拖把？还是找到漏水源头并修复它？选择很明显，你得修复它。 那么为什么与代码质量(code quality)有什么不同呢？当你使用SonarQube分析应用程序并意识到它有很多技术债务(technical debt)，这种下意识的反应通常是开始修复-这样那样，要么整理一个补救计划。这就像每天拖地一次而却忽略了漏水源头一样。 通常在这种传统方法中，在发布版本之前，定期进行代码质量(code quality)审计结果是开发人员在发布之前应该采取的行动。这种方法可能在短期内有效，特别是在强有力的管理支持下，但在中长期内始终失败，因为: 代码审查(code review)过程太迟，没有利益相关者热衷于解决问题，每个人都希望新版本发布 开发者通常会推迟不了解项目上下文的外部团队提出的建议。顺便提一下，正在审查的代码已经过时了 使用这种方法明显缺乏对代码质量的所有权。谁拥有质量审查权限？没有人 在整个应用程序投入生产之前，需要检查整个应用程序，显然不可能对所有应用程序使用相同的标准。每个项目都会进行谈判，这将耗尽整个过程的可信度 相反，为什么不将你在家中使用的相同的简单逻辑应用于管理代码质量的方式？修复泄露(leak)意味着将重点放在新代码上，即自上次发布以来添加或更改的代码。然后事情就变得很容易了: Quality Gate可以每天运行，并且可通过它。发版时没有任何意外 开发人员很难回避他们前一天介绍的问题。相反，他们通常很乐意在代码仍然新鲜时修复问题 代码质量有明确的所有权 做不做的标准在不同的应用程序中是一致的，并且在团队之间共享 成本微不足道，因为它是开发过程中的一部分 最为奖励，变化最大的代码具有最高的可维护性，并且未变更的代码具有最低的维护性，这很有意义。 怎么做SonarQube提供两种主要工具来帮助你找到泄漏点: 新代码指标(metrics)显示当前代码与你在其历史记录(previous_version)中选择的特定点之间的度量差异 新代码主要基于SCM blame 数据监测，从新代码期(泄漏期)的第一次分析开始，需要时使用回退机制 Quality Gates允许你设置测量代码的布尔阈值。将它们与差异指标一起使用，可确保你的代码质量随着时间的推移在正确的方向上行驶 项目页Project Page 项目主页(Project Homepage)是任何项目的切入点，它显示: the releasability status of the project the current state of its quality the quality of what has been produced since the beginning of its New Code Period 项目页面回答了两个问题: can I release my project today? if not, what should I improve to make the project pass the Quality Gate? 今天能发版吗Can I release today? 由于 Quality Gate 是你执行质量策略的最强大的工具，因此该页面以项目的当前质量门状态开始。如果项目通过，则会显示一个简单的绿色全清除。 如果没有，可立即获得详细信息和drill-downs，以便快速识别出错的地方，每个错误条件的一个部分显示当前项目值是什么以及它应该是什么。像往常一样，你可以点击当前值来进行深入分析。 应该优先解决什么What should I fix first? 因为提高项目质量的最佳方法是在问题变得根深蒂固之前捕获并修复新问题，项目的第一个视图以新代码周期为中心，在项目主页右侧以黄色突出显示。项目空间页面显示关键指标的高级摘要，包括当前值和新代码周期值。 在Quality Gate信息的下方，可以获得可靠性和安全域中的旧问题和新问题的数量。然后是可维护性域。单击页面上的任何图形将转到“详细信息”页面或“问题”页面中的详细视图。 开发人员必须做的最重要的事情是确保屏幕黄色部分的新问题得到确认，审核和修复，并确保测试涵盖新代码以防止将来出现回归。无论过去引入了多少问题，或者总体上测试覆盖范围有多少，关注新增问题将确保情况不会降低您之前在生产中发布的版本。 那么，您应该先找到哪些问题：错误，漏洞或代码异味？这取决于，因为答案取决于您的问题的性质。假设你有一个重复5次的代码块问题，在这个重复的代码块中，你有3个Bug和5个安全问题。最好的方法可能是首先修复重复，然后解决新集中位置的错误和漏洞，而不是修复它们5次。这就是为什么您需要在开始解决之前检查新问题。 ApplicationApplications are available as part of the Enterprise Edition. PortfoliosPortfolios are available as part of the Enterprise Edition. Issues在运行分析时，每当一段代码破坏编码规则时，SonarQube就会引发一个issue。编码规则(coding rules)是通过每种语言的相关质量配置文件定义的。 每个问题有五种严重程度: BLOCKER - 很有可能影响生产中应用程序行为的错误。必须立即修复 CRITICAL - 要么是在生产环境中影响应用程序行为可能性很小的bug，要么是代表安全漏洞的问题。必须立即检查代码 MAJOR - 可能严重影响开发人员生产力的质量缺陷 MINOR - 会轻微影响开发人员生产力产生的质量缺陷 INFO - 既不是错误，也不是质量缺陷，只是一个提示 理解issue上下文Understanding issue context 有时，一旦指出问题，问题就不言而喻了。例如，你的团队已约定了变量命名规则，在某个变量名出线问题时，你不需要理解大量上下文来理解该问题。但在其它情况下，上下文可能对理解为什么会出现这个问题至关重要。这就是为什么SonarQube不仅支持显示问题消息的主要问题位置，还支持次要问题位置。 但有时候，贡献位置地点并不足以理解问题。例如，当通过代码在某些路径上取消引用空指针时，您真正需要的是问题流。每个流程都是一组辅助位置，用于显示可能发生问题的代码的确切路径。 生命周期Lifecycle of Code Smell, Bug, and Vulnerability Issues 状态Status 创建之后，Issue会在生命周期中流动，可能为以下五种状态之一: 打开(Open) - 由SonarQube在新问题上设定 确认(Confirmed) - 手动确认以指示问题有效 解决(Resolved) - 手动设置以指示下一个分析应该关闭改问题 重开(Reopened) - 当一个已解决的问题实际上没有得到纠正时，SonarQube会自动设置 关闭(Closed) - 有SonarQube自动设置自动创建的问题 处理方式Resolutions 已关闭的问题将有一下两种方式之一: 已修复(Fixed) - 当后续分析显示问题已更正或文件不再可用时自动设置 已移除(Removed) - 当相关规则不再可用时自动设置。改规则可能无法使用，因为它已从质量配置文件中删除，或者因为已卸载基础插件 Resolved issues好友两个处理方式: 误判(False Positive) - 手动设置 不会修复(Won’t Fix) - 不会修复 问题工作流程Issue Workflow 在以下情况下，问题会自动关闭(Status: Closed): 问题以正确修复（Resolution: Fixed） 问题不再存在，因为相关编码规则已停用或不再可用(Resolution: Removed) 在以下情况下，问题会自动重新打开(Status: Reopened): 手动修改解决方式为已修复(但是不是误判)的问题，有后续分析显示仍然存在 安全热点问题的生命周期Lifecycle of Security Hotspot Issues 安全热点问题具有专用的生命周期。它们不被视为可操作，必须由具有相关权限的用户进行审核。 创建之后，安全热点问题将流经专用的生命周期，可能是以下四种状态之一: Open - 由SonarQube在新问题上自动设置 Resolved(Won’t Fix) - 当安全审核员接受开发人员针对手动漏洞所做的修复或安全审核员清楚打开的热点或手动漏洞时，SonarQube会自动设置 To Revied - 当开发人员请求安全审核员查看他对手动漏洞所做的修复时自动设置 Reopened - 当开发人员解除打开的手动漏洞或安全审计员手动重新打开问题以便对已解决的问题运行新审计时设置 如果删除了包含安全热点的代码，则只会关闭安全热点问题。如果从项目的质量配置文件中删除了标识热点的规则，则安全热点也可能会被删除。 理解哪些问题是新的Understanding which Issues are “New” 为了确定问题的创建日期，在每次分析期间执行算法已确定问题是新的还是之前存在的。此算法依赖于报告问题的行的内容的哈希值(不包括空格)。对于多行问题，使用第一行的哈希值。对于每个文件(在检测到文件重命名后)，算法将从先前的分析中获取问题的基本列表，并尝试将这些问题与新分析报告的原始问题列表进行匹配。该算法尝试使用最强的证据进行首次匹配，然后再回到较弱的启发式算法。 如果问题是在同一规则上，具有相同的行号和相同的行哈希 - 匹配 检测到块在文件内移动，然后如果问题出在同一行(移动的)和同一条规则上- 匹配 在相同的规则上，使用相同的消息并使用相同的行哈希 - 匹配 在相同的规则上，使用相同的消息并使用相同的行号 - 匹配 在相同的规则上，使用相同的行哈希 - 匹配 是否有匹配CLOSED的问题 - 匹配和重新打开 了解问题回溯Understanding Issue Backdating 一旦问题被确定为新，下一个问题便是提供它的日期。例如，如果它已经在代码中存在了很长时间，但只能在最近的分析中找到，因为新的规则被添加到配置文件中？该问题是否应该在其行的最后一次更改日期或首次提出的分析日期之间给出？那就是它应该回溯吗？ 如果最后一次更改改行的日期可用，那么在某些情况下，该问题将被回溯: 首先分析项目或分支 当配置文件中的规则为新时 当分析程序升级后 当规则是外部的 因此，回溯可能会使新提出的问题原理New Code Period。 自动问题分配Automatic Issue Assignment For Bug, Vulnerability and Code Smell For Security Hotspot User Correlation Known Limitation 问题编辑Issue edits SonarQube的问题工作流程可帮助你管理问题。你可对一个Issue做七件不同事情，这些行为可分为三类: Technical Review Confirm False Positive Won’t Fix Severity change Resolve Security Hotspots Detect Clear Request Review Reject Dispositioning General Comments Tag Bulk Change 清除已解决的问题Purging Closed Issues 默认情况下，已关闭的问题将保留30天。当然，你也可以修改它。 RulesSonarSource Rules: https://rules.sonarsource.com/ 概述在SonarQube中，分析程序提供在源代码上执行的规则来生成问题。有四种类型的规则: Code Smell (Maintainability domain) Bug (Reliability domain) Vulnerability (Security domain) Security Hotspot (Security domain) 规则默认情况下，点击带单栏Rules时，你将看到SonarQube实例上安装的分析程序带来的所有可用规则。你可根据以下条件缩小范围: Language Type Tag Repository Default Severity Status Available Since Template: 显示允许创建自定义规则的规则模板 Quality Profile 规则细节要查看规则的详细信息，请点击它。除了基本规则数据之外，您还可以查看其中活动的配置文件（如果有）以及已经引发了多少未解决的问题。只有拥有正确的权限时，才能使用以下两个操作: Add/Remove Tags Extend Description 规则模板和自定义规则Rule Templates and Custom Rules 规则模板(Rule templates)由创建提供，允许用户在SonarQube中定义自己的规则。它位于Rules -&gt; Template。 要从模板创建自定义规则，你必须填写一下信息: Name Key (auto-suggested) Description (Markdown format is supported) Default Severity Status The parameters specified by the template 扩展编码规则Extending Coding Rules 可以添加自定义编码规则。 规则类型和严重性Rule Types and Severities Type: Bug Vulnerability Code Smell Security Hotspot Severity: Blocker Critical Major Minor Info 安全相关的规则Security-related Rules SonarQube质量类型有三种不同的规则: Reliability (bug) Vulnerability (security) Maintainability (code smell) 但另外一种方式，只有两种类型: security rule 其它 两者之间的区别并不在它们捕获的内容，而在于她们来自何处以及强加于它们的标准。 从安全相关的规则的期望是什么What to expect from security-related rules 需要明确的是，SonarQube语言插件中实现的大多数规则的标准是非常严格: 没有误报。对于正常规则，你应该能够确信任何报告给你的问题确实是一个问题。 但对于与安全相关的规则，情况略有不同。例如，许多安全指南讨论了应如何处理敏感数据。但是，由于规则中不可能确定哪些数据是敏感，哪些是不敏感。因此选择变为： 保持无误判标准并且不实施与安全相关的规则，或者实施与安全的规则不同的标准。 这就是为什么与安全相关的规则很广泛。官方的想法是，该规则将标记任何可疑的内容，并将其留给安全审核人员来剔除误报并发送真正的问题进行补救。 安全热点是一种特殊类型的问题，用于识别安全审核人员应审核的敏感区域，以确定它们是否真的是漏洞。有关热点和审计过程的详细信息，请参阅安全审核和报告。 与安全相关的规则来自何方Where security-related rules come from 绝大多数与安全相关的规则源于既定标准: CWE(Common Weakness Enumeration)：是美国MITRE机构提出的一套语言标准，用于描述软件安全弱点的通用化描述语言。每个CWE条目都包含了CWE标识符/弱点类型名称、类型的描述、弱点的行为、弱点的利用方法、利用弱点的可能性、可能导致的后果、应对措施、代码示例、对应的CVE漏洞数量、参考信息等内容。 SANS Top 25 - CWE/SANS TOP 25 Most Dangerous Software Errors OWASP Top 10 - OWASP Top 10 Application Security Risks 要查找与任何这些标准相关的规则，你可以按标签或文本搜索规则。 CWECWE标准代表Common Weakness Enumeration: Common Weakness Enumeration (CWE™) 是一个常见软件弱点的正式列表或字典，可能出现在软件的体系结构、设计代码或实现中。可能导致可利用的安全漏洞。创建CWE是为了描述软件安全漏洞的通用语言，作为针对这些弱点的软件安全工具的衡量标准；并为弱点识别、缓解和预防工作提供共同的基线标准。CWE是弱化的描述的层次结构。层次结构中的最低级别是弱点基础(Weakness Base)，它描述了细腻度的弱点。 符合特定要求的工具可以认证为CWE兼容。这些要求是: 您必须能够使用CWE标识符搜索与CWE相关的规则。要在SonarQube平台中执行此操作，只需将CWE标识符（例如CWE-595）放在规则页面上的搜索文本输入中并运行搜索 规则必须与其相关的CWE项目准确链接。要查看SonarQube规则的CWE映射，请参阅规则说明底部的规则参见部分 您必须能够从问题中识别相关的CWE。要在SonarQube平台中执行此操作，请参阅相关规则 产品文档必须包含CWE和CWE兼容性的说明 除了通过CWE id搜索规则外，您还可以通过 cwe rule tag 进行搜索 SANS TOP 25SANS Top 25列表是由SANS组织编制的CWE中列出的25个最危险错误的集合。当前的SANS列表分为三类： Insecure Interaction Between Components Risky Resource Management Porous Defenses 要查找与SANS Top 25相关的规则，您可以对类别或相关CWE项目执行文本搜索，或执行规则标记搜索。 OWASP Top 10OWASP代表Open Web Application Security Project。它是: 501(c)(3)全球非营利慈善组织，致力于提高软件的安全性。我们的使命是使软件安全可见，以便全世界的个人和组织能够就真正的软件安全风险做出明智的决策。 OWASP Top 10列出了各种各样的弱点，每个弱点都可以映射到许多单独的规则。OWASP TOP 10在SonarQube中也对应相关的tag。 要查找与OWASP Top 10相关的规则，您可以对类别执行文本搜索，或执行规则标记搜索。 內建规则和标签Built-in Rule Tags 标签(tag) 是一种对问题(issue)和规则(rule)进行分类的方法。问题会继承引发它们的规则上的标记。有些标签适用于特定语言，但是更多的标签出现在各种语言中。用户可以为规则和问题添加标签。但大多数规则都有一些开箱即用的标签。以下是一些非全面的、包含一些內建标签: brain-overload - 一次有太多的东西要留在脑海里 bad-practice - 代码可能按设计工作，但它的设计方式被广泛认为是一个坏主意 cert - 设计CERT标准中的规则 clumsy - 用于完成可以更清晰和简洁地完成的事情的额外步骤 confusing - 将使维护者更长时间地理解，而不是代码实际所做的事情 convention - 编码约定，如格式化、命名、空格… cwe - CWE安全规则 design - 代码设计存在一些问题 lock-in - 使用特定于环境的功能 misra - MISRA标准相关的规则 owasp - 与OWASP TOP 10安全标准相关的规则 pitfall - 没有什么不对，但未来可能出现问题;已经为下一个人设置了一个陷阱，他可能会陷入其中并搞砸了代码 sans-top25 - 与SANS Top 25 Coding Errors安全相关 suspicious - 它不能保证这是一个bug，但它看起来很可疑。至少，代码应该重新检查并且可能为了清晰而重构 unpredictable - 代码可以在当前条件下正常工作，但如果条件发生变化可能会失败 unused - 未使用的代码 user-experience - 代码在技术上没有任何问题，但它可能会使您的部分或全部用户讨厌您 Quality Gates 概述质量阈(Quality Gates)是你在组织中实施质量策略的最佳方式。它可以回答一个问题: 我今天可以将项目发上线吗？为了回答这个问题，你可以根据测量项目的度量阈值定义一组布尔条件，例如: No new blocker issues Code coverage on new code greater than 80% … 理想状况下，所有项目都将通过同一质量阈进行验证。但这并不总是实用的。例如，你可能会发现: 技术实现因应用程序而异 您希望确保对某些应用程序有更强的要求 … 这就是为什么你可以根据需要自定义质量阈，它就在顶部的菜单栏上。 最佳质量阈配置Use the Best Quality Gate Configuration 质量阈默认激活并视为內建和只读的Sonar war方式，由SonarQube提供。它代表了我们对实施修复泄露。根据SonarQube的功能自动调整 有三个指标允许你强制执行给定的可靠性，安全性和可维护性的评级。不仅仅是整体而且还有新代码。建议使用这些指标，并将其作为默认质量阈的一部分，以便开发人员在项目页面上查看质量阈时更清楚的反馈。 不要忘记质量阈条件必须使用差值，检查绝对值是没有意义的(如: 代码行数大于1000)。 推荐的质量阈(Recommended Quality Gate) 內建的Sonar way质量阈都推荐用于大多数项目。如果专注于保持新代码清洁，而不是花费大量时间来修复旧代码。它开箱即用，已被设置为默认配置文件。 质量阈状态Quality Gate Status 当质量阈失败时获得通知Getting Notified When a Quality Gate Fails 使用通知机制，在质量阈失败时通知用户。为此，请订阅New quality gate status通知。 安全Security 任何用户(甚至是匿名用户)都可以访问质量阈。要就行更改(create, edit, delete)，必须授予用户管理质量阈的权限。项目管理员可选择与他们项目相关的质量阈。 定义质量阈Defining Quality Gates 要管理质量阈，请转到菜单栏的Quality Gates。 每个质量阈条件都是以下组合: 测量(measure) 比较符(comparison operator) 错误值(error value) 栗子，条件可能是: measure: Blocker issue comparison operator: &gt; error value: 0 指标Metric Definitions 项目有如下指标: 复杂度(Complexity) 重复(Duplications) 问题(Issues) 可维护性(Maintainability) 质量阈(Quality Gates) 可靠性(Reliability) 安全性(Security) 大小(Size) 测试(Tests) 复杂度应用的控制流是简单还是复杂。 圈复杂度Cyclomatic Complexity 可以计算出达到全面覆盖需要的最少测试用例。它是基于通过代码的路径数计算的，每当函数的控制流分裂时，复杂度计数器就会增加1。每个函数的最小复杂度为1.此计算因语言而异，因为关键字和功能有所不同。 特定语言的详细信息: Language Notes ABAP 这些关键字将使复杂度加一: AND , CATCH , CONTINUE , DO , ELSEIF , IF , LOOP , LOOPAT , OR , PROVIDE , SELECT…ENDSELECT , TRY , WHEN , WHILE C/C++/Objective-C 复杂度加一: `function definitions, while , do while , for , throw statements, switch , case , default , &amp;&amp; operator, operator, ? ternary operator, catch , break , continue , goto` COBOL 复杂度加一: ALSO , ALTER , AND , DEPENDING , END_OF_PAGE , ENTRY , EOP , EXCEPTION , EXIT , GOBACK , CONTINUE , IF , INVALID , OR , OVERFLOW , SIZE , STOP , TIMES , UNTIL , USE , VARYING , WHEN , EXEC CICS HANDLE , EXEC CICS LINK , EXEC CICS XCTL , EXEC CICS RETURN Java 复杂度加一: `if , for , while , case , catch , throw , &amp;&amp; , , ?` JS, PHP 复杂度加一: `function, if, &amp;&amp;, , loop, switch case, throw, catch, go to` PL/I 复杂度加一: `PROC , PROCEDURE , GOTO , GO TO , DO , IF , WHEN , , ! , = , != , &amp; , &amp;=` PL/SQL 复杂度加一: create procedure, create trigger, procedure definition, basic loop statement, when clause statement, continue statement,exit statement, for loop statement, forall statement, if statement, elsif clause, raise statement, return statement, while loop statement, and expression, or expression, when clause expression VB.NET 复杂度加一: method or constructor declaration, AndAlso , Case , Continue , End , Error , Exit , If , Loop , On Error , GoTo , OrElse , Resume , Stop , Throw , Try 认知复杂度Cognitive Complexity 对应这个应用是否很难被理解，理解代码的控制流程有多难。 重复有: 重复的块(Duplicated blocks) 重复的行(Duplicated lines) 重读文件(Duplicated files) 密度/重复行%(Duplicated lines %) 重复的块重复的行的块数。 特定语言的详细信息 非Java项目: There should be at least 100 successive and duplicated tokens. Those tokens should be spread at least on: 30 lines of code for COBOL 20 lines of code for ABAP 10 lines of code for other languages Java项目: There should be at least 10 successive and duplicated statements whatever the number of tokens and lines.检测重复时忽略缩进和字符串文字的差异。 问题有: 新问题(New issues) 新的严重问题(New xxx issues) 所有问题(Issues) 严重问题(xxx issues) 误判问题(False positive issues) 开启问题(Open issues) 确认问题(Confirmed issues) 重开问题(Reopened issues) 可维护性有: 异味(Code Smells) 新异味(New Code Smells) 维护率(Maintainability Rating) 技术债务(Technical Debt) 新代码的技术债务(Technical Debt on New Code) 技术债务率(Technical Debt Ratio) 新代码的技术债务率(Technical Debt Ratio on New Code) 维护率使用SQALE评级。与您的技术债务比率值相关的项目评级。默认的可维护性评级网格是: A=0-0.05 (&lt;5%) B=0.06-0.1 (6%-10%) C=0.11-0.20(11%-20%) D=0.21-0.5(21%-50%) E=0.51-1(50%-100%) 技术债务努力修复所有异味。以分钟(min)为度量单位存储在数据库中，单位值中的天假设为8小时(h)。 技术债务率开发成本与修复成本之间的比率。技术债务公式为: Remediation cost / Development cost 开发一行代码的成本价值为0.06 day == 0.06 * 8 * 60 min 质量阈有: 质量阈状态(Quality Gate Status) 质量阈详情(Quality Gate Details) 可靠性有: Bugs New Bugs 可靠率(Reliability Rating) 可靠性的修复工作(Reliability remediation effort) 新代码可靠性的修复工作(Reliability remediation effort on new code) 可靠率 A = 0 Bugs B = at least 1 Minor Bug C = at least 1 Major Bug D = at least 1 Critical Bug E = at least 1 Blocker Bug 修复工作努力解决所有Bugs。以分钟为单位度量值存储在数据库中。如果数值天，则假设一天为8小时。 安全性有: 漏洞(Vulnerabilities) 新漏洞(New Vulnerabilities) 安全级(Security Rating) 安全修复工作(Security remediation effort ) 新代码的安全修复工作(Security remedation effort on new code) 安全评级 A = 0 Vulnerabilities B = at least 1 Minor Vulnerability C = at least 1 Major Vulnerability D = at least 1 Critical Vulnerability E = at least 1 Blocker Vulnerability 大小有: 类(Classes) 注释行(Comment lines) 注释占比(Comments %) - Comment lines / (Lines of code + Comment lines) * 100 目录(Directories) 文件(Files) 行数(Lines) 代码行数(Lines of code) 每种语言的代码行数(Lines of code per language) 函数(Functions) 测试有: 条件覆盖(Condition coverage) 新代码条件覆盖(Condition coverage on new code) 条件覆盖命中(Condition coverage hits) 逐行条件(Conditions by line) 逐行条件覆盖(Covered conditions by line) 覆盖(Coverage) 新代码覆盖(Coverage on new code) 行覆盖(Line coverage) 新代码行覆盖(Line coverage on new code) 行覆盖命中(Line coverage hits) 要覆盖的行(Lines to cover) 新代码要覆盖的行(Lines to cover on new code) 跳过单元测试(Skipped unit tests) 未覆盖条件(Uncovered conditions) 新代码未覆盖条件(Uncovered conditions on new code) 未覆盖行(Uncovered lines) 新代码未覆盖行(Uncovered lines on new code) 单元测试(Unit tests) 单元测试持续时间(Unit tests duration) 单元测试错误(Unit test errors) 单元测试失败(Unit test failures) 单元测试成功密度(Unit test success density %) - Test success density = (Unit tests - (Unit test errors + Unit test failures)) / Unit tests * 100 条件覆盖在包含一些布尔表达式的每行代码中，条件覆盖只是回答了以下问题: 每个布尔表达式是否都被评估为 true 和 false?。这是在单元测试执行期间遵循的流控制结构中可能的条件密度。 Condition coverage = (CT + CF) / (2*B), where: CT = conditions that have been evaluated to ‘true’ at least once(已经被评估为true至少一次的条件) CF = conditions that have been evaluated to ‘false’ at least once(已经被评估为false至少一次的条件) B = 条件总数(total number of conditions) 覆盖它是行覆盖和条件覆盖的混合。它的目标是为以下问题提供更准确的答案: 单元测试覆盖了多少源代码? Coverage = (CT + CF + LC)/(2*B + EL), where: CT = 已经被评估为true至少一次的条件 CF = 已经被评估为false至少一次的条件 LC = 覆盖的行(covered lines) B = 条件总数 EL = 可执行行的总数( total number of executable lines) 行覆盖在给定的代码行上，行覆盖简单地回答了以下问题: 在执行单元测试期间是否执行了这行代码? 它是单元测试的覆盖率密度: Line coverage = LC / EL, where: LC = 覆盖的行(covered lines) EL = 可执行行的总数(total number of executable lines) 概念Concepts 架构Architecture 概念 定义 Analyzer 用于分析源代码以计算快照的客户端程序 Database 存储配置和快照 Server 用于浏览快照数据和进行配置修改的Web界面 质量Quality 概念 定义 Bug 表示代码中出错的问题 Code Smell 代码中与可维护性相关的问题 Cost 花费 Debt 解决问题所需的时间 Issue 代码不符合规则时，快照上会记录一个问题。有: Bugs , Code Smells and Vulnerabilities Measure 给定时间内给定文件或项目的度量值 Metric 一种测量方式。随着时间的推移，度量标准可能具有不同的值或度量 New Code Period 需要密切关注代码中引入新问题的时间段 Quality Profile 一组规则 Rule 应该遵循的编码标准或惯例 Remediation Cost 修复漏洞和可靠性问题所需的估计时间 Snapshot 在给定时间内针对给定项目的一组度量和问题 Security Hotspot 与安全相关的问题，突出显示使用安全敏感API的一段代码 Technical Debt 修复问题所需的估计时间 Vulnerability 与安全相关的问题，代表攻击者的后门 活动Activity and History 项目活动页面提供项目文件分析的完整列表，以及随着时间推移看到项目措施演变的能力。活动页面上的图标可帮助你了解几种相互选择的度量方法的演变。 事件Events 有四种类型的事件: Quality Gate Profile Version Other SonarLintSonarLint Smart Notifications SonarLint Smart Notifications是作为Developer Edtion的一部分来提供。 智能通知允许使用SonarLint中的连接模式的开发人员以一下情况下从SonarQube接收IDE内的通知: the Quality Gate status (failed / success) of a project /solution open in the IDE changes a SonarQube analysis raises new issues introduced by this developer in a project /solution open in the IDE SonarLint智能通知的激活和取消必须由每个开发人员直接在SonarLint(IDE端)进行单独完成。可以在SonarQube上逐个服务器地在SonarLint端配置接收通知。 Security Reports 安全报告显示了什么What do the Security Reports show? 安全报告旨在快速为您提供有关应用程序安全性的全景图，并详细说明OWASP, SANS, CWE标准的详细信息。安全报告由分析器提供，分析器依赖于质量配置文件中激活的规则来引发安全问题。 热点和漏洞有什么区别What’s the difference between a Hotspot and a Vulnerability? 漏洞是代码中可以攻击的点。安全热点是安全敏感的代码段，应由具有安全审计员帽的人仔细审查。安全热点的主要目标是帮助集中手动审查应用程序源代码的安全审核员的工作。第二个目标是教育开发人员并提高他们的安全意识。 为什么某些热点和漏洞非常相似Why are some Hotspot and Vulnerability rules very similar? 它们是故意重叠的。热点规则应该包括漏洞规则的所有匹配，以及污点分析引擎无法检测漏洞的情况。 为什么我看不到任何热点Why are some Hotspot and Vulnerability rules very similar? 有三个原因: 可能真的没有它们，因为代码是在没有使用任何安全敏感API的情况下编写的 热点规则可能可用，但尚未在你的质量配置文件中激活，因此自然不会引发任何问题 你正在使用的语言分析器可能还没有提供热点规则，所以它不会引发任何热点 为什么我看不到任何漏洞由于一些热点原因，你可能没有看到任何漏洞的，但你可能会看到项目主页中报告了一些漏洞，而安全报告中没有漏洞。这是因为语言分析器可能尚未提供安全报告中可见问题所需的安全标准的元数据。 开发者是否应该关心热点可能并不需要。热点并不是真正可行的，它们只是标记潜在的问题，所以在代码上没有立即做任何事情。这就是为什么在引发热点问题时没有收到通知。 如果热点确实标记为漏洞怎么办如果您查看引发热点的代码并意识到确实存在问题，请单击当前状态以注册您在代码中检测到漏洞。完成后，它将转换为漏洞，最后触摸该行的开发人员将收到新问题通知。 热点变为漏洞后会发生什么一旦您检测到热点位置确实存在问题，它将被分配给相应的开发人员，他们将进行修复，然后必须通过UI请求审核。 热点被标记为不会修复是什么意思What does it mean for a Hotspot to be marked “Won’t Fix”? 不会修复标记用于表示已经审查了热点，并且目前无法利用这段代码创建攻击。 用户账户User Account SonarQube用户可拥有自己的空间，可查看与自己相关的内容。 User Token每个用户都可生成令牌，这些令牌可用于运行分析或调用Web服务，而无需用户的实际凭据。 项目管理Project Administration 项目存在Project Existence 通常，项目在第一次分析时创建，不会删除(除非手动删除)。你可以管你你有权限管理的项目。 在第一次分析之前配置项目 配置还未分析的项目 修改项目权限(Private/Public) - 默认情况下，任何新创建的项目都被视为Public。这意味着每个经过认证的用户都能够Browse和See Source Code 删除项目 查找不再分析的项目 管理项目历史Managing Project History SonarQube最强大的功能之一是它不仅向你展示了你今天的项目健康状况，还展示了它随时间的变化情况。它通过有选择地保留以前分析的数据来做到这一点。它没有保留所有以前的分析——这会使数据库膨胀。同样，对于它确实存在的分析，SonarQube不会保留所有数据。一旦项目快照(snapshot)从最后分析(Last analysis)移动到项目历史的一部分，项目级别下面的数据就会被清除——再次放置数据库膨胀。 通常这些都不是你需要考虑的事情。SonarQube只为你专门处理它们。但有时你可能需要从项目的历史记录中删除错误的快照或修改内存处理算法。 可查看数据库表大小: 123456# sonarUSE information_schema;DESCRIBE TABLES;SELECT TABLE_SCHEMA, TABLE_NAME, TABLE_ROWS, DATA_LENGTH FROM TABLES WHERE TABLE_SCHEMA = 'sonar' ORDER BY DATA_LENGTH DESC; 有时你可能需要手动删除项目快照，无论是因为使用了错误的质量配置文件，还是因为分析存在问题…请注意，永远不能删除最新的快照。 对于每个快照，可以手动: Add, rename or remove a version Add, rename or remove an event Delete the snapshot 缩小关注点Narrowing the Focus 如果SonarQube的结果不相关，那么没有人会想要使用它。这就是为什么精确配置每个项目要分析的内容是非常重要的一步。SonarQube为你提供了几种选项，可以准确配置要分析的内容。你可以: 完全忽略一些文件或目录 从问题中排除文件或目录，但分析所有其它方面 从重复性中排除文件或目录，但分析所有其它方面 从覆盖率中排除文件或目录，但分析其它所有方面 你可以在全局或项目级别配置它们。 忽略文件Ignore Files 建议你从库中排除生成的代码，源代码等。有四种不同的方法可将分析范围缩小到与开发团队相关的源代码。 源目录(Source Directories) 文件后缀(File Suffixes) 选择文件(Choosing Files) 源文件排除(Source File Exclusions) 测试文件排除(Test File Exclusions) 源文件包含(Source File Inclusions) 测试文件包含(Test File Inclusions) 忽略问题Ignore Issues 可使用SonarQube忽略某些组件和某些编码规则的问题。Administration &gt; General Settings &gt; Analysis Scope &gt; Issues。 请注意，以下属性只能通过Web界面设置，因为它们是多值的。 Ignore Issues on Files Ignore Issues in Blocks Ignore Issues on Multiple Criteria Restrict Scope of Coding Rules 忽略重复Ignore Duplications 可在SonarQube中阻止检查某些文件的重复性。Administration &gt; General Settings &gt; Analysis Scope &gt; Duplications。 忽略代码覆盖率Ignore Code Coverage 可以通过单元测试防止某些文件考虑用于代码覆盖。Administration &gt; General Settings &gt; Analysis Scope &gt; Code Coverage &gt; Coverage Exclusions。 模式Patterns SonarQube中可以使用以下通配符: * - 零个或多个字符(zero or more characters) ** - 零个或多个目录(zero or more directories) ? - 单个字符(a single character) 项目设置Project Settings Tags项目标签(tags) 允许对项目进行分类和分组，以便在项目页面上更容易地选择。可以从项目主页管理项目标签。 管理项Administration Items: Adding a Project Analysis Report Processing Deleting a Project Setting the New Code Period Updating Project Key Default Issue Assignee Setting Quality Gate and Quality Profiles Setting Exclusions Customizing Links Webhooks网络调用(Webhooks) 在项目完成分析后通知外部服——An HTTP POST request including a JSON payload is sent to each URL。可在项目级别和全局指定URL。项目级别的配置不会取代全局的配置，两个级别的所有Webhooks都被调用。 HTTP(s) 调用: 无论后台任务的状态如何 使用POST方法将JSON文档作为负载 使用UTF-8编码的内容类型application/json Delivery and PayloadWebhook 管理控制台显示每个Webhook的最新交付的结果和时间戳，其中有效负载可通过列表图标获得。默认保留30天的记录。URL必须在10s响应，否则传递将标记为失败。 发送带有project key的 HTTP header X-SonarQube-Project，以便快速识别所涉及的项目。 Payload是一个JSON文档，包括: 什么时候运行分析(analysedAt) 分析的项目的标识(project) 每个质量阈标准和状态(qualityGate) 每个项目的质量阈状态(qualityGate.status) 后台任务的状态和标识(status, taskId) 用于定义的属性(properties) 栗子: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&#123; "analysedAt": "2016-11-18T10:46:28+0100", "project": &#123; "key": "org.sonarqube:example", "name": "Example" &#125;, "properties": &#123; &#125;, "qualityGate": &#123; "conditions": [ &#123; "errorThreshold": "1", "metric": "new_security_rating", "onLeakPeriod": true, "operator": "GREATER_THAN", "status": "OK", "value": "1" &#125;, &#123; "errorThreshold": "1", "metric": "new_reliability_rating", "onLeakPeriod": true, "operator": "GREATER_THAN", "status": "OK", "value": "1" &#125;, &#123; "errorThreshold": "1", "metric": "new_maintainability_rating", "onLeakPeriod": true, "operator": "GREATER_THAN", "status": "OK", "value": "1" &#125;, &#123; "errorThreshold": "80", "metric": "new_coverage", "onLeakPeriod": true, "operator": "LESS_THAN", "status": "NO_VALUE" &#125; ], "name": "SonarQube way", "status": "OK" &#125;, "serverUrl": "http://localhost:9000", "status": "SUCCESS", "taskId": "AVh21JS2JepAEhwQ-b3u"&#125; 附加参数Additional parameters 通过在Webhook的URL中提供user/passwd来支持基本的身份认证机制。(如: https://myLogin:myPassword@my_server/foo) 如果使用了sonar.analysis.*属性为SonarScanner提供其它属性，则这些属性将自动添加到有效负载的properties部分。 栗子: 1sonar-scanner -Dsonar.analysis.scmRevision=628f5175ada0d685fd7164baa7c6382c1f25cab4 -Dsonar.analysis.buildNumber=12345 实例管理Instance Administration 质量配置Quality Profiles 概述质量配置(Quality Profiles)服务是SonarQube的核心，因为它是您通过定义规则集来定义需求的地方。。 理想情况下，对于任何给定的语言，所有项目都将使用相同的配置文件进行测量，但这并不总是实用的。这就是为什么您可以根据需要定义尽可能多的质量配置文件，即使建议尽可能少的质量配置文件以确保公司项目的一致性。 每个语言都带有预定义的內建配置文件(通常称为 Sonar way)，因此你可以使用SonarQube分析进行快速开始。这就是为什么只要安装新的语言插件，就可以使用至少一个配置文件。 默认的Sonar way配置文件，它包含了通常适用于大多数项目的所有规则。但作为最佳实践，你应该创建一个新的配置文件(你可以通过复制Sonar way的内容来填充它)，并使用它。因为默认的Sonar way是不可编辑的，因此你无法根据需要对其进行自定义。此外，这使你可将Sonar way视为一个基线，可在对其进行更改时跟踪自己的配置文件。此外Sonar way通常会随插件的每个新版本更新，已添加规则，有时还会调整规则严重性。任何继承自內建Sonar way的配置文件都将在事实上同时自动更新。 我该怎么做 将质量配置管理的权限移交给其他人Delegate the management of Quality Profiles to someone else? 默认情况下，管理员才有此权限。但你可以授予用户/组权限来编辑配置文件。例如将Java配置文件权限分配给Java开发专家，将Python配置文件权限分配给Python专家… 将规则从一个配置复制到另一个配置Copy the rules from one profile to another? 许多时候，人们希望使用基于內建的配置文件的配置文件进行工作，而无实际需要使用內建配置文件。 了解配置中有什么改变Know what’s changed in a profile? 当SonarQube注意到使用与先前分析不同的配置文件执行分析时，会将质量配置文件事件添加到项目的事件日志中。 将配置文件从一个实例复制到另一个实例Copy a profile from one SonarQube instance to another? 使用实例上的备份(Back UP)功能将配置文件导出到XML文件。然后在另一个实例中选择恢复(Restore)。 将一组核心规则和附加规则应用于项目Apply a core set of rules plus additional rules to a project? 使用继承，从root继承核心规则集。然后创建一个子配置文件(Sprout)，修改从Root继承，然后添加缺少的规则。 确保我的非默认配置文件应用于项目Make sure my non-default profile is used on a project? 确保我的个人配置中包含所有相关的新规则Make sure I’ve got all the relevant new rules in my profile? 比较两个规则Compare two profiles? 确保我的配置中没有任何弃用的规则Make sure I don’t have any deprecated rules in my profile? 安全Security 任何用户都可以访问质量配置服务，你可以给他们配置质量配置管理权限，让他们可以创建，删除质量配置。 安全 概述SonarQube具有许多全局安全功能: 认证和授权机制 强制身份认证 委派认证 除此之外，还可在group/user级别配置: 查看一个已存在的项目 访问项目的源代码 管理一个项目 管理质量配置，质量阈，实例… 认证Authentication 第一个问题: 匿名用户是否可以浏览SonarQube实例？当然不行！那就需要强制用户认证。 认证机制(Authentication Mechanisms) 可通过多种方式来管理认证机制: 通过SonarQube內建的user/group数据库 通过外部程序(如LDAP) 通过HTTP headers 技术用户(Technical Users) 当你在SonarQube数据库中创建用户时，他将被视为本地用户，并且针对SonarQube自己的user/group数据库进行身份认证，而不是通过任何外部工具。默认情况下，admin是本地账户。 同样，所有非本地(non-local)账户将仅针对外部工具进行身份认证。 管理员可以管理所有用户的Tokens——创建和删除。一旦创建，Token就是运行分析所需的唯一凭证，作为sonar.login属性的值来传递。 默认管理员(Default Admin Credentials) 当安装SonarQube时，会自动创建具有管理系统权限的默认用户: 12user: adminpasswd: admin 重置管理员密码Reinstating Admin Access 如果你修改了管理员密码，但又忘记了: 123USE sonar;update users set crypted_password = '$2a$12$uCkkXmhW5ThVK8mpBvnXOOJRLd64LJeHTeCkSuB3lfaR2N0AYBaSi', salt=null, hash_method='BCRYPT' where login = 'admin' 如果您删除了管理员并随后锁定了具有全局管理权限的其他用户: 123USE sonar;INSERT INTO user_roles(user_id, role) VALUES ((select id from users where login='mylogin'), 'admin'); 授权Authorization 对不同组、不同用于仅限权限分配，以访问不同的资源。 user group Global Permissions Administer System Administer Quality Profiles Administer Quality Gates Execute Analysis Create Projects Create Applications Create Portfolios Project Permissions Public and Private Administer Issues Administer Security Hotspots Administer Execute Analysis Private Browse See Source Code 默认权限的权限模板Permission Templates for Default Permissions SonarQube附带默认权限模板，该模板在创建项目，项目组合或应用程序自动授予特定组的特定权限。管理员可以编辑此模板。 加密Encryption 加密主要用于从设置中删除明文密码。实现的解决方案是基于对称密钥算法，关键是密钥存储在磁盘上的安全文件中。此文件必须由运行SonarQube Server的系统账户拥有和读取。该算法是AES 128位。 Generate the secret key Store the secret key on the SonarQube server Generate the encrypted values of your settings Use the encrypted values in your SonarQube server configuration 必须在SonarQube基础架构的所有部分之间共享唯一的密钥。在Administration &gt; Configuration &gt; Encryption生成密钥。生成密钥之后，会显示如何使用此密钥。 之后便可以为你设置的值进行加密。同样在前面的加密下进行配置。之后在SonarQube Server中使用加密后的值: 12345# conf/sonar.propertiessonar.jdbc.password=&#123;aes&#125;CCGCFg4Xpm6r+PiJb1Swfg== # Encrypted DB password...sonar.secretKeyPath=C:/path/to/my/secure/location/my_secret_key.txt 委托认证Delegating Authentication docs: https://docs.sonarqube.org/latest/instance-administration/delegated-auth/ SonarQube认证: 自带用户数据库认证 外部 HTTP header LDAP … HTTP header认证 LDAP认证 通知Notifications 可以通过邮件配置，向用户发送分析的信息的通知。 使用实践 注意:由于使用的是SonarQube CE(社区版)，因此不支持在IDE中上传分析数据，也不支持多分支(branch)分析。所以需要对这些方面做一些规范。 SonarQube的使用主要分为两个方面: 开发者 IDE CI SonarScanner CICI端 需先安装 SonarQube Scanner 应用程序，并配置相应的路径和token。 由于社区版的缘故，我只对测试分支的CI进行SonarScanner分析，并将结果上传到SonarQube Server对应项目的路径。 由于测试分支(stage)的代码都是由开发者现在本地IDE中检测过代码质量(Code Quality)之后才MR过来，所以这样更方便和实用些。 CI SonarScanner分析上传之后，SonarQube会通知项目负责人此项目代码相关情况。由项目负责人去SonarQube Web UI上再去核查相关issues，核查无误之后，才能将测试分支的代码上线。如果项目负责人检查出相关代码的某些问题，请于相关分支开发者交流，叮嘱他们现在本地IDE自测，通过之后在MR代码。 IDE只需在IDE中下载SonarLint插件，并配置上运维人员提供的地址和token就可以使用了。 由于社区版的缘故，我这里让开发者自己的分支在IDE中调用远程SonarQube进行本地代码质量检查，并不需要将开发者的分支代码情况上传到SonarQube Server端。 开发者自己检查和核对自己分支的代码质量，确认之后才将自己的代码MR到dev分支。如果项目负责人检测到某位开发者的分支代码存在问题，则这个责任由分支开发者负责和处理。 权限问题权限有一些地方需要注意: 将项目设置为私有(默认: public) 项目对应项目组(group)，对应项目成员(user) 项目组中的CI, IDE用户具有不同的权限 … 具体配置可以在使用的时候灵活修改！ API可通过SonarQube API 进行许多操作。 12# 如导出python的代码规则curl -X GET -v -u user:passwd http://localhost:9000/api/rules/search?language=python &gt; python.json Scanner docs: https://docs.sonarqube.org/display/SCAN 建议将SonarQube Scanner用作使用SonarQube分析项目的默认扫描程序。 安装 OS平台: Linux Mac OS Windows 下载对应平台的Sonar Scanner应用程序，将它们解压之后加入系统路径($PATH)。 IDESonar Scanner 支持的 IDE 有: MSBuild Maven Gradle Ant Jenkins JetBrains 在IDE中下载SonarLint插件，之后配置SonarQube Server地址和管理员给的Token便可以正常使用。社区版的SonarQube 只能在IDE中检测，无法上传。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>SonarQube</tag>
        <tag>Static Analysis</tag>
        <tag>Code Quality</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DevOps]]></title>
    <url>%2F2019%2F02%2F13%2FDevOps%2F</url>
    <content type="text"><![CDATA[参考: 维基百科 GitLab GitHub 介绍DevOps（Development和Operations的组合词）是一种重视 软件开发人员（Dev） 和 IT运维技术人员（Ops） 之间沟通合作的文化、运动或惯例。透过自动化 软件交付 和 架构变更 的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。 Auto DevOpsGitLab Auto DevOps: Auto Build Auto Test Auto Code Quality Auto SAST (Static Application Security Testing) Auto Dependency Scanning Auto License Management Auto Container Scanning Auto Review Apps Auto DAST (Dynamic Application Security Testing) Auto Deploy Auto Browser Performance Testing Auto Monitoring DevOps工具下面介绍一些DevOps需要用到的工具，可能不够详细。 基础环境IaaS: VMware Xen KVM OpenStack 云平台 … 项目管理Task: RedaMine Jira 禅道 … 代码Code: git GitLab Gogs svn 云平台 … 持续集成/发布CI/CD: Jenkins Jenkins X GitLab CICD Bamboo Maven 云平台 … 容器Container: Docker K8s CoreOS Mesos Helm 云平台 … 测试Test: Selenium Katalon Studio Watir Jmeter Loadrunner LOCUST Selenium Website: https://www.seleniumhq.org/ Selenium是一个用于自动化测试Web apps的可移植框架。 Selenium提供了一种用于创作功能测试的回放工具，无需学习测试脚本语言。 Katalon Studio Wetsite: https://www.katalon.com/ Simplify API, Web, Mobile Automation Tests. Watir Website: http://watir.com/ An open source Ruby library for automating tests.Watir interacts with a browser the same way people do: clicking links, filling out forms and validating text. JMeterApache JMeter应用程序是开源软件，纯Java应用程序，旨在加载测试功能行为和测量性能。它最初是为测试Web应用程序而设计的，但后来扩展到其他测试功能。 Apache JMeter可用于测试静态和动态资源，Web动态应用程序的性能。它可用于模拟服务器，服务器组，网络或对象上的重负载，以测试其强度或分析不同负载类型下的整体性能。 Apache JMeter功能包括: Ability to load and performance test many different applications/server/protocol types Web - HTTP, HTTPS (Java, NodeJS, PHP, ASP.NET, …) SOAP / REST Webservices FTP Database via JDBC LDAP Message-oriented middleware (MOM) via JMS Mail - SMTP(S), POP3(S) and IMAP(S) Native commands or shell scripts TCP Java Objects Full featured Test IDE that allows fast Test Plan recording CLI mode to load test from any Java compatible OS Highly Extensible core … LoadRunner Website: https://www.microfocus.com LoadRunner is a Load Testing Software LOCUST Website: https://locust.io/ GitHub: https://github.com/locustio/locust/ An open source load testing tool. Define user behaviour with Python code, and swarm your system with millions of simultaneous users. 质量与安全Quality and Security: infer SonarQube Cuckoo Sandbox OWASP ZAProxy Mobile-Security-Framework-MobSF Clair Infer GitHub: https://github.com/facebook/infer Website: https://fbinfer.com/ Infer 是一个 Java，C ++，Objective-C 和 C 的代码静态分析工具。它会产生一个潜在的bug列表。任何人都可以使用Infer在发送给用户之前拦截关键错误，并帮助防止崩溃或性能不佳。 infer 主要用于 APP 端，也就是 Android/IOS App。 SonarQube GitHub: https://github.com/SonarSource/sonarqube Website: https://www.sonarqube.org/ SonarQube 是一个开源平台，通过代码的自动化静态分析不断的检查代码质量。 SonarQube 支持20多种语言的分析，并在各种类型的项目中输出和存储问题。通过不同的插件对这些结果进行再加工处理，通过量化的方式度量代码质量的变化，从而可以方便地对不同规模和种类的工程进行代码质量管理。 MobSF GitHub: https://github.com/MobSF/Mobile-Security-Framework-MobSF Mobile Security Framework is an automated, all-in-one mobile application (Android/iOS/Windows) pen-testing framework capable of performing static analysis, dynamic analysis, malware analysis and web API testing. Clair GitHub: https://github.com/coreos/clair Vulnerability Static Analysis for Containers.Clair is an open source project for the static analysis of vulnerabilities in application containers (currently including appc and docker). 配置管理Configuration Management: Ansible ZooKeeper CFEngine Chef MAAS Puppet SaltStack Vagrant Rundeck Rudder 云平台 … 数据分析Data Analysis: Hadoop Ambari Avro Flume HBase Hive Spark Sqoop ZooKeeper 日志Log: ElasticStack Elasticsearch Logstash Beat Hadoop, Hive - 与ELK类似的方案 Flume Fluentd Splunk Kafka Loggly Papertrail 云平台 … 流Stream: Kafka Apex Flink Heron Spark Heka Api网关Api Gateway: Gloo Ambassador Spring Cloud Kong Netflix Zuul 云平台 … 性能Performance: NetData Pinpoint Datadog AppDynamics Apache JMeter ab(ApacheBench) Gatling 监控Monitoring: Zabbix Nagios Prometheus Grafana Netdata Graphite Cacti Glances Collectd Ganglia Kibana Sensu 备份Backup: 全量 增量 灰度发布 ps:参考百度百科! 灰度发布（金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。在其上可以进行A/B testing，即让一部分用户继续用产品特性A，一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。 灰度期：灰度发布开始到结束期间的这一段时间，称为灰度期。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
        <tag>运维开发</tag>
        <tag>Auto DevOps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenLDAP]]></title>
    <url>%2F2019%2F01%2F18%2FOpenLDAP%2F</url>
    <content type="text"><![CDATA[参考: LDAP维基百科: https://zh.wikipedia.org/wiki/LDAP OpenLDAP维基百科: https://zh.wikipedia.org/wiki/OpenLDAP x.500维基百科: https://zh.wikipedia.org/wiki/X.500 OpenLDAP文档: http://www.openldap.org/doc/ 环境: RHEL7.x86_64 LDAP v2.4.44 概述 LDAPLDAP(轻型目录访问协议, Lightweight Directory Access Protocol）是一个开放的、中立的、工业标准的应用协议，通过IP协议提供访问控制和维护分布式信息的目录信息。LDAP基于X.500标准的子集。因为这个关系，LDAP有时被称为X.500-lite。LDAP在TCP/IP之上定义了一个相对简单的升级和搜索目录的协议。 LDAP目录与普通数据库的主要不同之处在于数据的组织方式，它是一种有层次的、树形结构。所有条目的属性的定义是对象类object class的组成部分，并组成在一起构成schema；那些在组织内代表个人的schema被命名为white pages schema。数据库内的每个条目都与若干对象类联系，而这些对象类决定了一个属性是否为可选和它保存哪些类型的信息。 LDAP目录的条目（entry）由属性（attribute）的一个聚集组成，并由一个唯一性的名字引用，即专有名称（distinguished name，DN）。 DN: Distinguished Name CN: Common Name OU: Domain Component LDAP组织数据方式: 12345 dc=org |dc=wikipedia / \ou=people ou=groups LDAP主要的应用场景是查询多而修改极少，那就充分发挥LDAP的优势了。因为没有事务处理，那数据库的速度可是比不上。 还有LDAP能存储海量的数据，还可以轻松地在各个系统之间复制，可用性超高。 目录是一个为查询、浏览和搜索而优化的专业分布式数据库，它呈树状结构组织数据，就好象Linux/Unix系统中的文件目录一样。目录数据库和关系数据库不同，它有优异的读性能，但写性能差，并且没有事务处理、回滚等复杂功能，不适于存储修改频繁的数据。所以目录天生是用来查询的，就好象它的名字一样。 OpenLDAPOpenLDAP是轻型目录访问协议（Lightweight Directory Access Protocol，LDAP）的自由和开源的实现，在其OpenLDAP许可证下发行，并已经被包含在众多流行的Linux发行版中。 OpenLDAP主要包括下述4个部分： slapd: 独立LDAP守护服务 slurpd: 独立的LDAP更新复制守护服务 实现LDAP协议的库 工具软件和示例客户端 Why OpenLDAP账号是登录系统的唯一入口。要登录系统，首先系统要存在登录所使用的账号（/etc/passwd）及密码信息（/etc/shadow），然后经过系统查找顺序（/etc/nsswith.conf）及认证模块（/etc/pam.d/*）验证，得到授权后方可登录系统。如果多个用户登录系统，就需要在每个系统上创建用户名和密码；否则，就无法登录系统。 对于账号管理人员而言，维护10 台、100 台机器的账号，或许勉强可以维护、管理。如果机器数量达到1000 以上时，对于账号的创建、回收、权限的分配、密码策略、账号安全审计等一系列操作，账号管理人员就心有余而力不足了。此时OpenLDAP 账号集中管理软件就应用而生，它可以实现账号集中维护、管理，只需要将被管理的机器加入到服务器端即可，此后所有与账号相关的策略均在服务端实现，从而解决了运维案例所产生的众多管理问题。 关于账号的添加、删除、修改、权限的赋予等一系列操作只需要在服务端操作即可，无须在客户端机器进行单独操作。客户端账号及密码均通过OpenLDAP 服务器进行验证，从而实现账号集中认证管理，此时账号管理员只须维护OpenLDAP 服务器条目即可。 OpenLDAP目录服务Introduction to OpenLDAP Directory Services 本节介绍如何构建，配置和操作OpenLDAP软件以提供目录服务。这包括有关如何配置和运行standalone LDAP daemon——slapd的详细信息。它适用于系统管理员。本节提供目录服务的基本介绍，特别是slapd提供的目录服务。本简介提供足够的信息，以便您可以开始学习LDAP，X.500和目录服务。 目录服务是什么目录是专门用于搜索(search)和浏览(browse)的专用数据库，另外还支持基本查找(lookup)和更新(update)功能。 目录往往包含描述性的，基于属性的信息，并支持复杂的过滤功能。目录通常不支持在为处理大量复杂更新而设计的数据库管理系统中发现的复杂事务或回滚方案。如果允许，目录更新通常是简单的全有或全无更改。目录通常用于快速响应高容量查找或搜索操作。他们可能具有广泛复制信息的能力，以提高可用性和可靠性，同时缩短响应时间。复制目录信息时，只要及时解决不一致问题，副本之间的临时不一致就可以了。 有许多不同的方法来提供目录服务。不同的方法允许将不同类型的信息存储在目录中，对如何引用，查询和更新信息。一些目录服务是本地的，向受限制的上下文提供服务；其它服务是全球性的，为更广泛的环境提供服务。全局服务通常是分布式的，这意味着它们包含的数据分布在许多机器上，所有机器都协作提供目录服务。通常，全局服务定义统一命名空间(namespace)，无论您在何处与数据本身相关，都可以提供相同的数据视图。 LDAP是什么LDAP(Lightweight Directory Access Protocol, 轻型目录访问协议)，顾名思义，它是一种用于访问目录服务的轻量级协议，特别是基于X.500的目录服务。LDAP通过TCP / IP或其他面向连接的传输服务运行。 哪些种类的信息可以存储在目录中？DAP信息模型基于条目(entry)。条目是具有全局唯一可分辨名称（DN）的属性(attributes)集合。DN用于明确指代Entry，每个条目的属性都有一个类型(type)和一个或多个值(value)。 12345678#这些类型通常是助记符字符串cnmail#值的语法取决于属性类型cn: ldap-testmail: example@test.com 信息是如何安排的？在LDAP中，目录条目以分层树状结构(tree-like structure)排列。传统上，这种结构反映了地理/组织边界。表示国家/地区的条目显示在树的顶部。下面是代表各州和国家组织的条目。再下面可能是表示组织单位，人员，打印机，文档或您可以想到的任何其他内容的条目。 传统命名: 还可以基于因特网域名来安排树。这种命名方法正变得越来越流行，因为它允许使用DNS定位目录服务。 基于域名命名: 此外，LDAP允许您通过使用名为对象类(objectClass)的特殊属性来控制条目中所需和允许的属性。它的值确定条目必须遵守的模式规则。 如何引用信息？条目由其可分辨名称(DN)引用，该名称通过获取条目本身的名称来构造(称为Relative Distinguished Name, RDN)，并连接其祖先条目的名称。 如何保护信息免受未经授权的访问？某些目录服务不提供保护，允许任何人查看信息。LDAP为客户端提供了一种机制，用于对目录服务器进行身份验证或证明其身份。LDAP还支持数据安全性（完整性和机密性）服务。 什么时候应该使用LDAP通常，当您需要通过基于标准的方法集中管理、存储、访问数据时，应使用目录服务器。总是有新的方法来使用目录并应用LDAP原则来解决某些问题，因此这个问题没有简单的答案。 一些常见的栗子： 机器认证: Machine Authentication 用户认证: User Authentication 用户/系统组: User/System Groups 地址簿: Address book 组织代表: Organization Representation 资产追踪: Asset Tracking 电话信息存储: Telephony Information Store 用户资源管理: User resource management 电子邮件查找: E-mail address lookups 应用配置存储: Application Configuration store PBX Configuration store … LDAP如何工作LDAP使用C-S模式。一个或多个LDAP服务器包含组成目录信息树（DIT，directory information tree）的数据。客户端连接到服务器并发出请求。服务端响应客户端的请求。无论客户端连接到哪个LDAP服务器，它都会看到相同的目录视图，这是全局目录服务的一个重要特性。 关于x.500X.500是计算机目录服务的标准系列。X.500协议包括: DAP (Directory Access Protocol) DSP (Directory System Protocol) DISP (Directory Information Shadowing Protocol) DOP (Directory Operational Bindings Management Protocol) LDAP (Lightweight Directory Access Protocol) 从技术上讲，LDAP是X.500目录服务的目录访问协议。DAP是一种重量级协议，可在完整的OSI协议栈上运行，并且需要大量的计算资源。LDAP旨在通过TCP/IP进行操作，并以更低的成本提供DAP的大部分功能。 虽然LDAP仍然用于通过网关访问X.500目录服务，但现在更常见的是在X.500服务器中直接实现LDAP。 可以将 standalone LDAP daemon(slapd) 视为轻量级X.500目录服务器。也就是说，它没有实现X.500的DAP，也不支持完整的X.500模型。 LDAP与RDBMS最常见的问题是——为什么OpenLDAP不使用 RDBMS(关系数据库管理系统) 而是使用像 LMDB 那样的嵌入式键/值存储？总的来说，期望商业级 RDBMS 实现的复杂算法可以使 OpenLDAP更 快或更好，并且同时允许与其他应用程序共享数据。 简而言之，使用嵌入式数据库和自定义索引系统，OpenLDAP可以在不损失可靠性的情况下提供更高的性能和可扩展性。所以OpenLDAP使用 LMDB 并发/事务 数据库软件。 下面是一个详细而冗长的答案: &lt;&gt; 很有可能认为在目录中使用RDBMS后端可以解决所有问题。但是，它是一头猪。这是因为数据模型非常不同。使用关系数据库表示目录数据将需要将数据拆分为多个表。现在最大的问题是从一个条目访问数据需要在不同的磁盘区域上进行搜索。在某些应用程序中，这可能没问题但在许多应用程序中性能会受到影响。 slapdslapd是OpenLDAP的守护进程， 在许多不同平台上运行的LDAP目录服务器。 slapd有一些有趣的功能和特性: LDAPv3: slapd实现轻量级目录访问协议的第3版，slapd支持IPv4和IPv6以及Unix IPC上的LDAP。 Simple Authentication and Security Layer: slapd通过使用SASL支持强身份验证和数据安全性（完整性和机密性）服务 Transport Layer Security: slapd通过使用 TLS/SSL 持基于证书的身份验证和数据安全性（完整性和机密性）服务 Topology control: slapd可以配置为根据网络拓扑信息限制 socket 层的访问，基于 TCP wrapper Access control: slapd提供了丰富而强大的访问控制功能，允许您控制对数据库中信息的访问 Internationalization: slapd支持Unicode 和 Language tag Choice of database backends: slapd附带了各种不同的数据库后端，您可以从中选择 Multiple database instances: slapd可以配置为同时为多个数据库提供服务。这意味着单个slapd服务器可以使用相同或不同的数据库后端响应LDAP树的许多逻辑上不同部分的请求 Generic modules API: 如果您需要更多自定义，slapd可让您轻松编写自己的模块 Threads: slapd具有高性能的线程 Replication: slapd可以配置为维护目录信息的集群副本 Proxy Cache: slapd可以配置为缓存LDAP代理服务 Configuration: slapd可通过单个配置文件进行高度配置，允许您更改您想要更改的所有内容 快速入门A Quick-Start Guide 注意：本快速入门指南不使用强身份验证，也不使用任何完整性或机密保护服务。这些服务在OpenLDAP的其它章节中进行了描述。 以下包括OpenLDAP v2.4软件的快速入门指南。 获取软件 打开发行包 审阅文档 运行configure 构建软件 测试构建 安装软件 编辑配置文件 导入配置数据库 启动SLAPD 添加初始化条目到目录 查看是否正常运行 配置选择The Big Picture - Configuration Choices 本节简要概述了各种LDAP目录配置。 本地目录服务Local Directory Service 在此配置中，您运行 slapd 实例，该实例仅为您的本地域提供目录服务。它不以任何方式与其他目录服务器进行交互。 带推荐的本地目录服务Local Directory Service with Referrals 在此配置中，运行 slapd 实例，该实例为本地域提供目录服务，并将其配置为将引用返回到能够处理请求的其它服务器。 如果要提供本地服务并参与全局目录，或者要将下级条目的责任委派给其他服务器，请使用此配置。 副本目录服务Replicated Directory Service slapd 包括对基于LDAP Sync 的复制的支持，称为syncrepl。可用于在多个目录服务器上维护目录信息的副本。在其最基本的配置中，master 是 syncrepl provider，slavee 是 syncrepl consumer。集群和提供了可靠性和可用性。 分布式目录服务Distributed Local Directory Service 在此配置中，本地服务被划分为较小的服务，每个服务都可以被复制，并与上级和下级引用粘合在一起。 安装Building and Installing OpenLDAP Software 本章详细介绍了如何构建和安装OpenLDAP软件包。 源码安装官方文档中是使用源码进行构建和安装。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#提取软件gunzip -c openldap-VERSION.tgz | tar xf -cd openldap-VERSION#依赖软件#请参考REAME，安装它所需的依赖软件#Transport Layer Security#Simple Authentication and Security Layer#Kerberos Authentication Service#Database Software#Threads#TCP Wrappers#configure./configure --help./configure --enable-wrappers \ CPPFLAGS="-I/usr/local/include" \ LDFLAGS="-L/usr/local/lib -Wl,-rpath,/usr/local/lib"#构建软件make dependmake#测试make test#安装#如果未指定安装位置，默认安装到 /usr/local#通常，安装需要超级用户权限sudo make install#配置文件/usr/local/etc/openldap 包安装因为在base源里面可直接搜索到openldap软件包，所以就是用软件包进行安装。 RPM包： 123456789101112131415161718192021222324252627#查看yum search openldapopenldap.x86_64 : LDAP support librariesopenldap-devel.x86_64 : LDAP development libraries and header filesopenldap-servers.x86_64 : LDAP serveropenldap-clients.x86_64 : LDAP client utilitiesopenldap-servers-sql.x86_64 : SQL support module for OpenLDAP servercompat-openldap.x86_64 : OpenLDAP compatibility shared librariescollectd-openldap.x86_64 : OpenLDAP plugin for collectdnss-pam-ldapd.x86_64 : An nsswitch module which uses directory servers#安装yum install -y openldap.x86_64 openldap-servers.x86_64 openldap-clients.x86_64#yum install -y collectd-openldap.x86_64 openldap-servers-sql.x86_64 compat-openldap.x86_64 openldap-devel.x86_64 nss-pam-ldapd.x86_64#验证rpm -qa | grep openldap#配置文件/etc/openldap 配置Configuring slapd 安装完毕后，你就可以配置并使用它。 本章介绍 slapd-config 配置系统的一般格式。OpenLDAP v2.3及更高版本已转换为使用动态运行配置引擎slapd-config: 完全启用LDAP 使用标准LDAP操作进行管理 将其配置数据存储在LDIF数据库中(openldap/slap.d/) 允许所有slapd的配置选项在运行中进行更改，通常无需重新启动服务器即可使更改生效 注意：虽然 slapd-config 统将其配置存储为（基于文本的）LDIF文件，但您不应直接编辑任何LDIF文件。配置更改应通过LDAP操作执行，如 ldapadd, ldapdelete, ldapmodify 配置的布局Configuration Layout slapd配置存储为具有预定义模式和DIT的特殊LDAP目录。有特定的objectClasses用于承载全局配置选项，模式定义，后端和数据库定义以及各种其它项。 栗子配置树: slapd-config 配置树具有非常特定的结构。树的根名为 cn=config 并包含全局配置设置。其他设置包含在单独的子条目中： Dynamically loaded modules Schema definitions Backend-specific configuration Database-specific configuration LDIF文件的常用规则适用于配置信息: #表示注释 如果一行以单个空格开头，则将其视为前一行的延续（即使前一行是注释），并删除单个前导空格。条目由空行分隔 配置LDIF的一般布局如下： 12345678910111213141516171819202122232425262728293031323334#globalconfigurationsettingsdn:cn=configobjectClass:olcGlobalcn:config&lt;globalconfigsettings&gt;#schemadefinitionsdn:cn=schema,cn=configobjectClass:olcSchemaConfigcn:schema&lt;systemschema&gt;dn:cn=&#123;X&#125;core,cn=schema,cn=configobjectClass:olcSchemaConfigcn:&#123;X&#125;core&lt;coreschema&gt;#additionaluser-specifiedschema...#backenddefinitionsdn:olcBackend=&lt;typeA&gt;,cn=configobjectClass:olcBackendConfigolcBackend:&lt;typeA&gt;&lt;backend-specificsettings&gt;#databasedefinitionsdn:olcDatabase=&#123;X&#125;&lt;typeA&gt;,cn=configobjectClass:olcDatabaseConfigolcDatabase:&#123;X&#125;&lt;typeA&gt;&lt;database-specificsettings&gt;#subsequentdefinitionsandsettings... 配置指令Configuration Directives 本节详细介绍了常用的配置指令 cn=config本条目中包含的指令通常适用于整个服务器。其中大多数是系统或面向连接，而不是数据库相关。条目必须具有 olcGlobal 对象类(objectClass) 123456789101112131415161718192021222324252627282930313233343536373839404142#指定强制关闭空闲客户端连接之前等待的秒数#默认值为0，表示禁用此功能olcIdleTimeout: &lt;integer&gt;#该指令指定syslog（当前记录到syslogd）的调试语句和操作统计信息的级别。您必须已配置OpenLDAP --enable-debug（默认值）才能使用olcLogLevel: &lt;level&gt;#Debugging LevelsLevel Keyword Description-1 any enable all debugging0 no debugging1 (0x1 trace) trace function calls2 (0x2 packets) debug packet handling4 (0x4 args) heavy trace debugging8 (0x8 conns) connection management16 (0x10 BER) print out packets sent and received32 (0x20 filter) search filter processing64 (0x40 config) configuration processing128 (0x80 ACL) access control list processing256 (0x100 stats) stats log connections/operations/results512 (0x200 stats2) stats log entries sent1024 (0x400 shell) print communication with shell backends2048 (0x800 parse) print entry parsing debugging16384 (0x4000 sync) syncrepl consumer processing32768 (0x8000 none) only messages that get logged whatever log level is set#指定当slapd无法找到本地数据库来处理请求时要传回的引用olcReferral &lt;URI&gt;#栗子条目dn: cn=configobjectClass: olcGlobalcn: configolcIdleTimeout: 30olcLogLevel: StatsolcReferral: ldap://root.openldap.org cn=module如果在配置slapd时启用了对动态加载模块的支持，则可以使用 cn=module 条目来指定要加载的模块集。 12345678910111213141516171819202122#指定要加载的可动态加载模块的名称olcModuleLoad: &lt;filename&gt;#指定要搜索可加载模块的目录列表olcModulePath: &lt;pathspec&gt;#栗子dn: cn=module&#123;0&#125;,cn=configobjectClass: olcModuleListcn: module&#123;0&#125;olcModuleLoad: /usr/local/lib/smbk5pwd.ladn: cn=module&#123;1&#125;,cn=configobjectClass: olcModuleListcn: module&#123;1&#125;olcModulePath: /usr/local/lib:/usr/local/lib/slapdolcModuleLoad: accesslog.laolcModuleLoad: pcache.la cn=schema此条目包含在 slapd 中硬编码的所有模式定义。因此，此条目中的值由slapd生成，因此配置文件中不需要提供 schema value。仍必须定义该条目，以作为用户定义的模式添加到下面的基础。schema entry 必须具有 olcSchemaConfig 的对象类 (objectClass)。 1234567891011121314151617181920212223242526#定义了一个属性类型olcAttributeTypes: &lt;RFC4512 Attribute Type Description&gt;#定义一个对象类olcObjectClasses: &lt;RFC4512 Object Class Description&gt;#栗子条目dn: cn=schema,cn=configobjectClass: olcSchemaConfigcn: schemadn: cn=test,cn=schema,cn=configobjectClass: olcSchemaConfigcn: testolcAttributeTypes: ( 1.1.1 NAME &apos;testAttr&apos; EQUALITY integerMatch SYNTAX 1.3.6.1.4.1.1466.115.121.1.27 )olcAttributeTypes: ( 1.1.2 NAME &apos;testTwo&apos; EQUALITY caseIgnoreMatch SUBSTR caseIgnoreSubstringsMatch SYNTAX 1.3.6.1.4.1.1466.115.121.1.44 )olcObjectClasses: ( 1.1.3 NAME &apos;testObject&apos; MAY ( testAttr $ testTwo ) AUXILIARY ) Backend-specific Directives后端指令适用于所有相同类型的数据库实例，并且可能会被数据库指令覆盖，具体取决于指令。后端条目必须具有 olcBackendConfig 的对象类 (objectClass)。 1234567891011121314151617181920212223242526#命名特定于后端的配置条目olcBackend: &lt;type&gt;#Database BackendsTypes Descriptionbdb Berkeley DB transactional backend (deprecated)config Slapd configuration backenddnssrv DNS SRV backendhdb Hierarchical variant of bdb backend (deprecated)ldap Lightweight Directory Access Protocol (Proxy) backendldif Lightweight Data Interchange Format backendmdb Memory-Mapped DB backendmeta Meta Directory backendmonitor Monitor backendpasswd Provides read-only access to passwd(5)perl Perl Programmable backendshell Shell (extern program) backendsql SQL Programmable backend#栗子dn: olcBackend=bdb,cn=configobjectClass: olcBackendConfigolcBackend: bdb Database-specific Directives每种类型的数据库都支持本节中的指令。数据库条目必须含有 olcDatabaseConfig 对象类 (objectClass)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#命名特定的数据库实例#可以提供数字&#123;&lt;index&gt;&#125;以区分相同类型的多个数据库olcDatabase: [&#123;&lt;index&gt;&#125;]&lt;type&gt;#权限指令#如果未指定，默认使用 to * by * readolcAccess: to &lt;what&gt; [ by &lt;who&gt; [&lt;accesslevel&gt;] [&lt;control&gt;] ]+#将数据库置于“只读”模式olcReadonly &#123; TRUE | FALSE &#125;#指定不受此访问控制的DN或对此数据库的操作的管理限制#DN不需要引用此数据库中的条目，甚至不需要引用目录中的条目。olcRootDN: &lt;DN&gt;#用于为root dn 指定DN的密码olcRootPW: &lt;password&gt;#指定从搜索操作返回的最大条目数olcSizeLimit: &lt;integer&gt;#定将传递给此后端数据库的查询的DN后缀olcSuffix: &lt;dn suffix&gt;#将当前 slapd 建立为运行 syncrepl 复制引擎的复制使用者站点，将当前数据库指定为主内容的副本olcSyncrepl#指定slapd将用于回答搜索请求的最大秒数olcTimeLimit: &lt;integer&gt;#该指令仅适用于slave slapdolcUpdateref: &lt;URL&gt;#栗子条目dn: olcDatabase=frontend,cn=configobjectClass: olcDatabaseConfigobjectClass: olcFrontendConfigolcDatabase: frontendolcReadOnly: FALSEdn: olcDatabase=config,cn=configobjectClass: olcDatabaseConfigolcDatabase: configolcRootDN: cn=Manager,dc=example,dc=com BDB and HDB Database Directives此类别中的指令适用于BDB和HDB数据库。除了上面定义的通用数据库指令之外，它们还用在 olcDatabase 条目中。除了olcDatabaseConfig 对象类之外，BDB和HDB数据库条目还必须分别具有 olcBdbConfig 和 olcHdbConfig 对象类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#指定包含数据库和相关索引的BDB文件所在的目录olcDbDirectory: &lt;directory&gt;#指定BDB后端数据库实例维护的内存高速缓存条目的大小olcDbCachesize: &lt;integer&gt;#指定检查BDB事务日志的频率，检查点操作将数据库缓冲区刷新到磁盘，并在日志中写入检查点记录olcDbCheckpoint: &lt;kbyte&gt; &lt;min&gt;#指定要放置在数据库目录的DB_CONFIG文件中的配置指令olcDbConfig: &lt;DB_CONFIG setting&gt;#此选项会导致磁盘上的数据库内容在更改时不会立即与内存更改同步olcDbNosync: &#123; TRUE | FALSE &#125;#在索引槽中指定内存中索引缓存的大小。默认值为零olcDbIDLcacheSize: &lt;integer&gt;#指定要为给定属性维护的索引olcDbIndex: &#123;&lt;attrlist&gt; | default&#125; [pres,eq,approx,sub,none]#如果此设置为TRUE，则slapindex将一次索引一个属性。默认设置为FALSE，在这种情况下，条目的所有索引属性将同时处理olcDbLinearIndex: &#123; TRUE | FALSE &#125;#指定新创建的数据库索引文件应具有的文件保护模式olcDbMode: &#123; &lt;octal&gt; | &lt;symbolic&gt; &#125;#指定用于搜索过滤器评估的堆栈深度olcDbSearchStack: &lt;integer&gt;#为共享内存BDB环境指定 key 。默认情况下，BDB环境使用内存映射文件。如果指定了非零值，则它将用作标识将容纳环境的共享内存区域的键olcDbShmKey: &lt;integer&gt;#栗子条目dn: olcDatabase=hdb,cn=configobjectClass: olcDatabaseConfigobjectClass: olcHdbConfigolcDatabase: hdbolcSuffix: &quot;dc=example,dc=com&quot;olcDbDirectory: /usr/local/var/openldap-dataolcDbCacheSize: 1000olcDbCheckpoint: 1024 10olcDbConfig: set_cachesize 0 10485760 0olcDbConfig: set_lg_bsize 2097152olcDbConfig: set_lg_dir /var/tmp/bdb-logolcDbConfig: set_flags DB_LOG_AUTOREMOVEolcDbIDLcacheSize: 3000olcDbIndex: objectClass eq slapd配置文件The slapd Configuration File 本章介绍如何通过 slapd.conf 配置文件来配置 slapd。 slapd.conf 已被弃用，建议使用前面介绍的 slapd-config进行配置。 由于已经被弃用，所以此处我跳过。 文档: http://www.openldap.org/doc/admin24/slapdconfig.html 运行slapdslapd 旨在作为独立服务运行。这允许服务器利用缓存，管理底层数据库的并发问题，并节省系统资源。 由于我使用RPM包进行安装，所以可利用 systemd 进行OpenLDAP的管理。 ldap默认监听地址: URL Protocol Transport ldap:/// LDAP TCP port 389 ldaps:/// LDAP over SSL TCP port 636 ldapi:/// LDAP IPC (Unix-domain socket) slapd方式1234567891011#查看帮助#man slapdslapd --help#启动slapd --option#停止kill -INT `cat /usr/local/var/slapd.pid` systemd方式12345678910systemctl status slapdsystemctl start slapd#ps -ef | grep slapd#/usr/sbin/slapd -u ldap -h ldapi:/// ldap:///systemctl stop slapd 访问控制]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>LDAP</tag>
        <tag>Permission</tag>
        <tag>权限管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenVPN]]></title>
    <url>%2F2019%2F01%2F16%2FOpenVPN%2F</url>
    <content type="text"><![CDATA[参考: OpenVPN: https://github.com/OpenVPN/openvpn easy-rsa: https://github.com/OpenVPN/easy-rsa 环境: RHEL7 OpenVPN v2.4.6 easy-rsa v3.0.3 概述通过在云端VPC， k8s集群内运行OpenVPN Server，让本地可以通过连接OpenVPN进行访问云资源，而不需要将云资源开放公网访问。 我是将OpenVPN运行在k8s 集群了，对它提供ELB进行公网连接。在S端配置文件中推送对应的路由信息——如集群内节点CIDR， 服务CIDR, VPC CIDR… 安装和配置 安装需要安装: EPEL openvpn easy-rsa: 用于制作CA证书，S端证书，C端证书 安装了EPEL源之后就可以直接安装openvpn和easy-rsa，当然也可以从GitHub上拉取。 123yum install -y epel-releaseyum install -y openvpn easy-rsa 制作证书 编辑vars文件此处需注意，通过yum安装可能会没有example.vars这个栗子文件。没关系，请在easy-rsa GitHub去下载一份过来。 123456789101112131415161718192021222324mkdir -p /etc/openvpn/easy-rsa/servermkdir -p /etc/openvpn/easy-rsa/client#拷贝easy-rsa文件，用于制作证书cp -r /usr/share/easy-rsa/3.0.3/ /etc/openvpn/easy-rsa/server/cp -r /usr/share/easy-rsa/3.0.3/ /etc/openvpn/easy-rsa/client/#先制作CA和S端证书cd /etc/openvpn/easy-rsa/server/cp vars.example vars#修改几个配置vim vars#根据自己的情况进行修改set_var EASYRSA_REQ_COUNTRY “CN” #国家set_var EASYRSA_REQ_PROVINCE “Sichuan” #省份set_var EASYRSA_REQ_CITY “ChengDu” #城市set_var EASYRSA_REQ_ORG “TianFu” #非盈利组织，此处可填公司之类set_var EASYRSA_REQ_EMAIL “abc@xyz.com” #邮箱地址set_var EASYRSA_REQ_OU “My OpenVPN” #组织单元 创建证书和秘钥 CA证书和S端证书 123456789101112131415161718192021222324252627282930313233343536373839cd /etc/openvpn/easy-rsa/server./easyrsa -h#初始化，会读取vars文件./easyrsa init-pki#创建根证书#这里会要求输入PEM pass，这个请记住，后面签名需要此密码./easyrsa build-ca#这里生成CA证书#pki/ca.crt#创建S端证书#nopass选项表示不加密./easyrsa gen-req server nopass#这里生成两个文件#pki/reqs/server.req#pki/private/server.key#签约S端证书#第一个server表示S端，后面是取的名字./easyrsa sign server server#这里需要输入CA证书的PEM pass#之后会生成S端证书#pki/issued/server.crt#创建Diffie-Hellman./easyrsa gen-dh#生成dh.pem文件#pki/dh.pem C端证书 12345678910111213141516171819202122232425262728293031cd /etc/openvpn/easy-rsa/client/#./easyrsa -h#初始化./easyrsa init-pki#创建C端证书./easyrsa gen-req client nopass#这里生成两个文件#pki/reqs/client.req#pki/private/client.key#在CA端导入C端证书cd /etc/openvpn/easy-rsa/server./easy-rsa import-req /etc/openvpn/easy-rsa/client/reqs/client.req client#签约C端证书#第一个client表示C端，第二个为定义的名字./easyrsa sign client client#这里需要输入CA证书的PEM pass#之后会生成C端证书#/etc/openvpn/easy-rsa/server/pki/issued/client.crt#注意生成的位置，不要搞错了 梳理上面生成的文件 1234567891011121314server/pki/ca.crtserver/pki/dh.pemserver/pki/reqs/server.reqserver/pki/reqs/client.reqserver/pki/private/ca.keyserver/pki/private/server.keyserver/pki/issued/server.crtserver/pki/issued/client.crt#client/pki/reqs/client.reqclient/pki/private/client.key 拷贝相应证书到openvpn目录下123456789101112131415#S端cd /etc/openvpn/servercp /etc/openvpn/easy-rsa/server/pki/ca.crt .cp /etc/openvpn/easy-rsa/server/pki/private/server.key .cp /etc/openvpn/easy-rsa/server/pki/issued/server.crt .cp /etc/openvpn/easy-rsa/server/pki/dh.pem .#C端cd /etc/openvpn/clientcp /etc/openvpn/easy-rsa/server/pki/ca.crt .cp /etc/openvpn/easy-rsa/client/pki/private/client.key .cp /etc/openvpn/easy-rsa/server/pki/issued/client.crt . 配置文件在openvpn GitHub去下载对应配置文件，做相应的修改。 S端配置文件一下只是我的栗子，详细信息请参考自己的项目。具体的每个选项描述，栗子文件里面有解释。 vim server.conf: 123456789101112131415161718192021222324252627282930313233343536373839404142port 1194proto udpdev tunca /etc/openvpn/server/ca.crtcert /etc/openvpn/server/server.crtkey /etc/openvpn/server/server.keydh /etc/openvpn/server/dh.pem#VPN CIDRserver 10.8.0.0 255.255.255.0ifconfig-pool-persist ipp.txt#推送的S端的CIDR给C端路由push &quot;route 10.0.0.0 255.255.224.0&quot;#推送S端DNSpush &quot;dhcp-option DNS 10.247.3.10&quot;push &quot;dhcp-option DNS 114.114.114.114&quot;client-to-clientkeepalive 20 120cipher AES-256-CBCpersist-keypersist-tunlog /dev/stdoutlog-append /dev/stdoutverb 3explicit-exit-notify 1#启用用户/密码进行登录需要添加的选项#栗子文件里面没有这些信息script-security 3auth-user-pass-verify /etc/openvpn/checkpsw.sh via-env#http://openvpn.se/files/other/checkpsw.sh#去下载这个脚本#client-cert-not-required#此选项只使用用户密码，不使用证书#注释它，使用证书和用户密码双重登录username-as-common-name C端配置文件vim client.ovpn: 12345678910111213141516171819202122232425262728293031323334353637383940414243clientdev tunproto udpremote addr portresolv-retry infinitenobindpersist-keypersist-tun#此处我将CA证书和C端证书信息写入配置文件#当然，也可下载证书在指定，但这麻烦了&lt;ca&gt;-----BEGIN CERTIFICATE-----xxxxxxxxxxx-----END CERTIFICATE-----&lt;/ca&gt;&lt;cert&gt;-----BEGIN CERTIFICATE-----xxxxxxxxxxxxxxxxx-----END CERTIFICATE-----&lt;/cert&gt;&lt;key&gt;-----BEGIN PRIVATE KEY-----xxxxxxxxxxxxxxxx-----END PRIVATE KEY-----&lt;/key&gt;remote-cert-tls servercipher AES-256-CBCverb 3#用户认证script-security 3auth-user-pass#可将用户信息写入文件，用户密码各一行 另外几个配置vi checksw.sh: 12345678910111213141516171819202122232425262728293031323334#!/bin/sh############################################################ checkpsw.sh (C) 2004 Mathias Sundman &lt;mathias@openvpn.se&gt;## This script will authenticate OpenVPN users against# a plain text file. The passfile should simply contain# one row per user with the username first followed by# one or more space(s) or tab(s) and then the password. PASSFILE="/etc/openvpn/psw-file"LOG_FILE="/etc/openvpn/openvpn-password.log"TIME_STAMP=`date "+%Y-%m-%d %T"` ########################################################### if [ ! -r "$&#123;PASSFILE&#125;" ]; then echo "$&#123;TIME_STAMP&#125;: Could not open password file \"$&#123;PASSFILE&#125;\" for reading." &gt;&gt; $&#123;LOG_FILE&#125; exit 1fi CORRECT_PASSWORD=`awk '!/^;/&amp;&amp;!/^#/&amp;&amp;$1=="'$&#123;username&#125;'"&#123;print $2;exit&#125;' $&#123;PASSFILE&#125;` if [ "$&#123;CORRECT_PASSWORD&#125;" = "" ]; then echo "$&#123;TIME_STAMP&#125;: User does not exist: username=\"$&#123;username&#125;\", password=\"$&#123;password&#125;\"." &gt;&gt; $&#123;LOG_FILE&#125; exit 1fi if [ "$&#123;password&#125;" = "$&#123;CORRECT_PASSWORD&#125;" ]; then echo "$&#123;TIME_STAMP&#125;: Successful authentication: username=\"$&#123;username&#125;\"." &gt;&gt; $&#123;LOG_FILE&#125; exit 0fi echo "$&#123;TIME_STAMP&#125;: Incorrect password: username=\"$&#123;username&#125;\", password=\"$&#123;password&#125;\"." &gt;&gt; $&#123;LOG_FILE&#125;exit 1 vi psw-file: 这为可登录的用户密码 直接往这个文件写入用户和密码即可，并不需要重启openvpn服务。 1234user1 pass-user1#commentuser2 pass-user2 vi start_openvpn.sh: 启动脚本 12345678910111213141516171819#!/bin/bashmkdir -p /dev/netif [ ! -c /dev/net/tun ]; then mknod /dev/net/tun c 10 200fiecho 'net.ipv4.ip_forward=1' &gt;&gt; /etc/sysctl.conf &amp;&amp; sysctl -p#此处一定要记得写iptables，否则后面连上了VPN也无法正常访问#我也是找了好久才找到这个问题#这个网段为openvpn里面定义的网段iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -j MASQUERADEcd /etc/openvpn#--daemon，放入后台/sbin/openvpn --config /etc/openvpn/server/server.conf 由于我是运行在k8s集群容器内，所有还有几个文件: Dockerfile .dockerignore k8s.yaml: 由于它需要创建和使用系统资源，所以请使用特权容器运行 启动 启动S端 客户端连接 Windows客户端 Linux客户端 Mac客户端 启动之后应该就能正常访问了，如果不能正常访问，请查看你推送的CIDR和DNS，还有ipv4转发和iptables等。 1234567891011121314#S端#由于需要使用和创建系统资源，所以请用特权容器进行运行，不然会提示没有权限/sbin/openvpn --config /etc/openvpn/server/server.conf#C端#Windows下载Openvpn GUI，制定客户端配置文件进行连接，之后输入用户名和面膜#Linux下#/sbin/openvpn --config /etc/openvpn/client/client.ovpn#Mac下，下载对应Openvpn软件，指定配置文件进行连接]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>OpenVPN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apollo]]></title>
    <url>%2F2019%2F01%2F09%2FApollo%2F</url>
    <content type="text"><![CDATA[参考: Apollo官方文档: https://github.com/ctripcorp/apollo/wiki 环境: Apollo v1.2 Docker v1.18 K8s v1.11 概述基本上按照官方文档都没什么问题，说几点我在配置过程中容易出错的地方。 总的来说就是一个portal，多个config+admin，而Eruea注册的Meta Server是和config在一起的，每个环境的admin注册到对应环境的Meta Server(config)。 我是将其放入k8s集群中运行，所以针对官方给出的Dockerfile和k8s.yaml文件做了对应的修改。 看一下我画的架构图和官方架构图: 我自己画的一个Apollo项目架构图： 多区域部署Apollo： 由于Apollo各组件之间并没有使用认证，所以如果通过公网跨区域则一定注意使用安全访问控制策略，添加白名单。 注意事项 为不同环境创建不同数据库 官方已经给出了创建数据库的sql语句，一个portadb, 多个configdb-project-env。我们需要修改数据库名，为不同的环境建立不同的数据库，所以需要在使用官方sql的时候把数据库名修改为自定义的即可，这样创建的各个环境数据库的表结构都是一样的。 配置了一个环境变量，它也就是部署服务的集群内访问地址(不在同一VPC可能需要外部访问地址) 官方是写入了Dockerfile里面作为环境变量，我是将其写入k8s yaml中的环境变量。当然，也可以写入启动脚本中。以下配置，随便用哪一个。 1234567891011121314#Dockerfile中ENV APOLLO_CONFIG_SERVICE_NAME="&#123;service-name&#125;.&#123;namespace&#125;.svc.cluster.local"#k8s yaml container中 env: - name: APOLLO_CONFIG_SERVICE_NAME value: &#123;service_name&#125;.&#123;namespace&#125;.svc.cluster.local#启动脚本#scripts/startup-kubernetes.sh#SERVER_URL="http://$&#123;APOLLO_ADMIN_SERVICE_NAME&#125;:$&#123;SERVER_PORT&#125;"SERVER_URL="http://&#123;service_name&#125;.&#123;namespace&#125;.svc.cluster.local:$&#123;SERVER_PORT&#125;" 将数据库和注册地址写入config/application-github.properties配置文件 官方是写入Dockerfile中作为环境变量，然后通过entrypoint.sh进行相应的替换。我直接将其写入此配置文件，并删除entrypoint.sh。 12345678spring.datasource.url = jdbc:mysql://&#123;mysql-ip&#125;:&#123;mysql-port&#125;/&#123;mysql-db&#125;?characterEncoding=utf8spring.datasource.username = userspring.datasource.password = passwdeureka.service.url = http://&#123;service-name&#125;.&#123;namespace&#125;.svc.cluster.local:8080/eureka/# 如果环境跨VPC，还需要指定公网地址的 HomePageUrl# eureka.instance.homePageUrl = http://ELB:PORT# 或 在启动命名指定: -Dapollo.configService=http://config-service的公网IP:端口来跳过meta service的服务发现# 如果不指定的话，则默认使用获取的内部地址，这无法正常访问 portal服务的默认环境是DEV，请注意 如果配置的第一个环境并不是DEV，请记得先修改数据库中的这个值，不然portal读取config, admin会失败。portaldb.serverconfig的apollo.portal.envs这个key，多个环境使用,分割，后面可以在UI上配置。其它环境请修改为其它环境名。 1UPDATE serverconfig SET Value='uat' WHERE Key='apollo.portal.envs'; 12345678910config/apollo-env.properties#dev.meta=http://DEV_META_SERVICE_NAME:8080#fat.meta=http://TEST_ALPHA_META_SERVICE_NAME:8080#uat.meta=http://TEST_BETA_META_SERVICE_NAME:8080#pro.meta=http://PROD_META_SERVICE_NAME:8080#某个环境的configuat.meta=http://&#123;service-name&#125;.&#123;namespace&#125;.svc.cluster.local:8080 将日志输出到标准输出/dev/stdout 由于我是运行在容器中，所以需要将日志输出到标准输出。这里很奇怪，直接在主机(centos7)上运行./apollo-xxx.jar start，日志正常输出到console；在openjdk容器里运行，./apollo-portal.jar start它放到后台运行，日志不输出到console，使用java ${JAVA_OPTS} -jar ./&quot;${SERVICE_NAME}.jar&quot;日志能够正常输出到console。所以这里修改startup-kubernetes.sh启动命令: 12345678910111213# 原# export JAVA_OPTS="$JAVA_OPTS -Dserver.port=$SERVER_PORT -Dlogging.file=$LOG_DIR/$SERVICE_NAME.log -Xloggc:$LOG_DIR/gc.log -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=5M -XX:HeapDumpPath=$LOG_DIR/HeapDumpOnOutOfMemoryError/"# 修改export JAVA_OPTS="$JAVA_OPTS -Dserver.port=$SERVER_PORT -Xloggc:$LOG_DIR/gc.log -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=5M -XX:HeapDumpPath=$LOG_DIR/HeapDumpOnOutOfMemoryError/"# 原# ./$SERVICE_NAME".jar" start# 修改# 因为 xxx.jar start也是调用 java $opt_java -jar xxx.jarjava $&#123;JAVA_OPT&#125; -jar ./"$&#123;SERVICE_NAME&#125;.jar" 登录Web UI后可修改配置 如组织里面的部门名，管理员等等参数，在系统参数里面更新Key对应的Value。具体这个Key可参考文档 —— 调整服务端配置 每个环境下有多个config/admin 请注意，每个环境只有一个数据库，也就是这几个服务都要连接同一个configdb，这点请注意。后面还需要修改ConfigDB.ServerConfig表，每个环境的都需要单独配置。这里的eureka.service.url - Eureka服务Url要来修改。 ps: 官方文档不管是apollo-configservice还是apollo-adminservice都需要向eureka服务注册，所以需要配置eureka服务地址。 按照目前的实现，apollo-configservice本身就是一个eureka服务，所以只需要填入apollo-configservice的地址即可，如有多个，用逗号分隔（注意不要忘了/eureka/后缀）。需要注意的是每个环境只填入自己环境的eureka服务地址，比如FAT的apollo-configservice是1.1.1.1:8080和2.2.2.2:8080，UAT的apollo-configservice是3.3.3.3:8080和4.4.4.4:8080，PRO的apollo-configservice是5.5.5.5:8080和6.6.6.6:8080，那么：在FAT环境的ApolloConfigDB.ServerConfig表中设置eureka.service.url为：http://1.1.1.1:8080/eureka/,http://2.2.2.2:8080/eureka/在UAT环境的ApolloConfigDB.ServerConfig表中设置eureka.service.url为：http://3.3.3.3:8080/eureka/,http://4.4.4.4:8080/eureka/在PRO环境的ApolloConfigDB.ServerConfig表中设置eureka.service.url为：http://5.5.5.5:8080/eureka/,http://6.6.6.6:8080/eureka/ 更过详情请查看官方文档！ 假如UAT环境下有: config-cd, config-bj, config-gz admin-cd, admin-bj, admin-gz 他们需要向这三个Eureka(cd, bj, gz)注册。 之后查看config:8080地址，便可以看到这几个地址的信息；在Portal集群信息里面，也可看到有三个CONFIG，三个ADMIN。 栗子具体信息可以查看官方文档，然后根据官方文档给出的栗子做一些修改。 apollo-config12345678910111213tree ..├── apollo-configservice.conf├── apollo-configservice.jar├── config│ ├── application-github.properties│ └── app.properties├── Dockerfile├── k8s-apollo-config-dev.yaml├── README.md└── scripts └── startup-kubernetes.sh Dockerfile 12345678910111213141516FROM openjdk:8-jre-alpine3.8RUN \ echo &quot;http://mirrors.aliyun.com/alpine/v3.8/main&quot; &gt; /etc/apk/repositories &amp;&amp; \ echo &quot;http://mirrors.aliyun.com/alpine/v3.8/community&quot; &gt;&gt; /etc/apk/repositories &amp;&amp; \ apk update upgrade &amp;&amp; \ apk add --no-cache procps curl bash tzdata &amp;&amp; \ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; \ echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone &amp;&amp; \ mkdir -p /apollo-config-serverCOPY . /apollo-config-server/EXPOSE 8080CMD [&quot;/apollo-config-server/scripts/startup-kubernetes.sh&quot;] config/ 12345678910# app.properties不用修改# application-github.properties# DataSourcespring.datasource.url = jdbc:mysql://host:port/configdbtest?characterEncoding=utf8spring.datasource.username = userspring.datasource.password = passwdeureka.service.url = http://xxx.svc.cluster.local:8080/eureka/# 扩公网的话请修改 HomePageUrl# config-web-test service homepage ELB# eureka.instance.homePageUrl = http://ELB:PORT scripts/ startup-kubernetes.sh 这个文件，文件名你也可以随便修改。有些值既可以写在这里面，也可以配置成环境变量(Dockerfile， 或k8s yaml)这里把 APOLLO_CONFIG_SERVICE_NAME 配置成 k8s yaml 里的环境变量 xxx.apollo-test.svc.cluster.local(即k8s service)。 1234567891011121314151617181920212223242526272829303132333435363738394041424344#!/bin/bashSERVICE_NAME=apollo-configservice## Adjust log dir if necessaryLOG_DIR=/opt/logs/apollo-config-server## Adjust server port if necessarySERVER_PORT=8080SERVER_URL="http://$&#123;APOLLO_CONFIG_SERVICE_NAME&#125;:$&#123;SERVER_PORT&#125;"## Adjust memory settings if necessary#export JAVA_OPTS="-Xms6144m -Xmx6144m -Xss256k -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=384m -XX:NewSize=4096m -XX:MaxNewSize=4096m -XX:SurvivorRatio=8"## Only uncomment the following when you are using server jvm#export JAVA_OPTS="$JAVA_OPTS -server -XX:-ReduceInitialCardMarks"########### The following is the same for configservice, adminservice, portal ###########export JAVA_OPTS="$JAVA_OPTS -XX:+UseParNewGC -XX:ParallelGCThreads=4 -XX:MaxTenuringThreshold=9 -XX:+UseConcMarkSweepGC -XX:+DisableExplicitGC -XX:+UseCMSInitiatingOccupancyOnly -XX:+ScavengeBeforeFullGC -XX:+UseCMSCompactAtFullCollection -XX:+CMSParallelRemarkEnabled -XX:CMSFullGCsBeforeCompaction=9 -XX:CMSInitiatingOccupancyFraction=60 -XX:+CMSClassUnloadingEnabled -XX:SoftRefLRUPolicyMSPerMB=0 -XX:+CMSPermGenSweepingEnabled -XX:CMSInitiatingPermOccupancyFraction=70 -XX:+ExplicitGCInvokesConcurrent -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationConcurrentTime -XX:+PrintHeapAtGC -XX:+UseGCLogFileRotation -XX:+HeapDumpOnOutOfMemoryError -XX:-OmitStackTraceInFastThrow -Duser.timezone=Asia/Shanghai -Dclient.encoding.override=UTF-8 -Dfile.encoding=UTF-8 -Djava.security.egd=file:/dev/./urandom"#官方默认是这个: export JAVA_OPTS="$JAVA_OPTS -Dserver.port=$SERVER_PORT -Dlogging.file=$LOG_DIR/$SERVICE_NAME.log -Xloggc:$LOG_DIR/gc.log -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=5M -XX:HeapDumpPath=$LOG_DIR/HeapDumpOnOutOfMemoryError/"# 这里我修改，不将GC信息输出到consoleexport JAVA_OPTS="$JAVA_OPTS -Dserver.port=$SERVER_PORT -Xloggc:$LOG_DIR/gc.log -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=5M -XX:HeapDumpPath=$LOG_DIR/HeapDumpOnOutOfMemoryError/"printf "$(date) ==== Starting ==== \n"cd `dirname $0`/..chmod 755 $SERVICE_NAME".jar"# 官方默认这样启动# ./$SERVICE_NAME".jar" start# 这样启动在主机上可以输出日志到console，但openjdk容器里不行，所以修改如下java $&#123;JAVA_OPTS&#125; -jar ./$SERVICE_NAME".jar"rc=$?;if [[ $rc != 0 ]];then echo "$(date) Failed to start $SERVICE_NAME.jar, return code: $rc" exit $rc;fitail -f /dev/null apollo-configservice.conf 这个也不需要做什么修改，看个人情况。 123MODE=servicePID_FOLDER=.LOG_FOLDER=/opt/logs/apollo-config-server apollo-admin这个其实和 apollo-config 差不多配置，只是修改一些配置项。 apollo-portal这个也和上面差不多，只是修改一些配置项。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Apollo</tag>
        <tag>分布式</tag>
        <tag>配置中心</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[税收与债务]]></title>
    <url>%2F2019%2F01%2F01%2F%E6%94%BF%E5%BA%9C%E6%94%B6%E5%85%A5%E4%B8%8E%E5%80%BA%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[参考: 财政部 国家统计局 最近观《雍正王朝》、《李卫当官》，对政府收入和政务债务想做一个了解，故此收集整理相关资料。 财政 财政收入 中央政府财政收入 地方政府财政收入 财政支出 中央政府财政支出 地方政府财政支出 外债 外债负载率 外债债务率 外债偿债率 财政收入指国家财政参与社会产品分配所取得的收入，是实现国家职能的财力保证。主要包括： 税收收入： 下设增值税等21款。包括国内增值税、国内消费税、进口货物增值税和消费税、出口货物退增值税和消费税、营业税、企业所得税、个人所得税、资源税、城市维护建设税、房产税、印花税、城镇土地使用税、土地增值税、车船税、船舶吨税、车辆购置税、关税、耕地占用税、契税、烟叶税等。 社会保险基金收入： 下设基本养老保险基金收入等6款。 非税收入：下设政府性基金收入等7款。包括专项收入、行政事业性收费、罚没收入和其他收入。 贷款转贷回收本金收入： 下设国内贷款回收本金收入等4款。 债务收入： 分设国内债务收入、国外债务收入2款。 转移性收入： 分设返还性收入等10款。 国资收入 财政收入按现行分税制财政体制划分为中央本级收入和地方本级收入。 中央财政收入属于中央财政的收入包括关税，进口货物增值税和消费税，出口货物退增值税和消费税，消费税，铁道部门、各银行总行、各保险公司总公司等集中交纳的营业税和城市维护建设税，增值税75%部分，纳入共享范围的企业所得税60%部分，未纳入共享范围的中央企业所得税、中央企业上交的利润，个人所得税60%部分，车辆购置税，船舶吨税，证券交易印花税97%部分，海洋石油资源税，中央非税收入等。 地方财政收入属于地方财政的收入包括营业税（不含铁道部门、各银行总行、各保险公司总公司集中交纳的营业税），地方企业上交利润，城市维护建设税（不含铁道部门、各银行总行、各保险公司总公司集中交纳的部分），房产税，城镇土地使用税，土地增值税，车船税，耕地占用税，契税，烟叶税，印花税，增值税25%部分，纳入共享范围的企业所得税40%部分，个人所得税40%部分，证券交易印花税3%部分，海洋石油资源税以外的其他资源税，地方非税收入等。 财政支出指国家财政将筹集起来的资金进行分配使用，以满足经济建设和各项事业的需要。 主要包括：一般公共服务、外交、国防、公共安全、教育、科学技术、文化体育与传媒、社会保障和就业、医疗卫生、环境保护、城乡社区事务、农林水事务、交通运输、资源勘探电力信息等事务、商业服务等事务、金融监管支出、国土气象等事务、住房保障支出、粮油物资储备管理等事务、国债付息支出等方面的支出。 财政支出根据政府在经济和社会活动中的不同职权，划分为中央财政支出和地方财政支出。 中央财政支出中央财政支出包括一般公共服务，外交支出，国防支出，公共安全支出，以及中央政府调整国民经济结构、协调地区发展、实施宏观调控的支出等。 地方财政支出地方财政支出包括一般公共服务，公共安全支出，地方统筹的各项社会事业支出等。 外债外债（或对外债务）（英语：external debt或foreign debt）是一个国家所拥有的、债权人为外国的债务。债务人可以是政府、企业或私人。债权人可以是私人商业银行、其他政府或国际金融机构。 外债负债率指外债余额与当年国内生产总值之比。 外债债务率指外债余额 外债偿债率指偿还外债本息与当年贸易和非贸易外汇收入（国际收支口径）之比。 债务政府债务（亦称公债）是指政府在国内外发行的债券或向外国政府和银行借款所形成的政府债务。具体是指政府凭借其信誉，政府作为债务人与债权人之间按照有偿原则发生信用关系来筹集财政资金的一种信用方式，也是政府调度社会资金，弥补财政赤字，并借以调控经济运行的一种特殊分配方式。政府债务是整个社会债务的重要组成部分。 政府债务（Government debt）分为中央政府债务和地方政府债务。中央政府债务即国债，是中央政府为筹集财政资金而举借的一种债务。除中央政府举债之外，不少国家有财政收入的地方政府及地方公共机构也举借债务，即地方政府债务。由于中国地方政府尚不能举债，因此中国的政府债务即为国债。 按偿还期限划分： 可分为短期、中期和长期公债。按发行地域划分： 可分为内债和外债。按发行的方式： 可分为强制公债和自愿公债。]]></content>
      <categories>
        <category>Economics</category>
      </categories>
      <tags>
        <tag>经济</tag>
        <tag>财政</tag>
        <tag>税收</tag>
        <tag>债务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[存储方案]]></title>
    <url>%2F2018%2F12%2F10%2FStorage%2F</url>
    <content type="text"><![CDATA[参考: 维基百科 Google 存储方案分类： DAS(Direct-Attached Storage)，直连式存储 NAS(Network Attached Storage)，网络附加存储 SAN(Storage Area Network)，存储区域网络 NAS和SAN既竞争又合作，很多高端NAS的后端存储就是SAN。NAS和SAN的整合也是存储设备的发展趋势。SAN提供的存储单位是LUN，属于block级别的。经过NAS创建成文件系统后，就变成文件级别的了。 NAS和SAN最本质的区别就是文件管理系统在哪里。 DAS直连式存储是指直接和计算机相连接的数据储存方式。像固态硬盘、机械硬盘、光盘驱动器与计算机直接相连的设备都是属于直连式存储设备。实际上，直连式存储的名称是后来为了区别于存储区域网络（SAN）和网络附加储存（NAS）而添加的。 缺点： 服务器本身容易成为系统瓶颈; 服务器发生故障，数据不可访问; 对于存在多个服务器的系统来说，设备分散，不便管理。同时多台服务器使用DAS时，存储空间不能在服务器之间动态分配，可能造成相当的资源浪费; 数据备份操作复杂。 NAS网络附加存储是一种专门的数据存储技术的名称，它可以直接连接在计算机网络上面，对异质网络用户提供了集中式数据访问服务。实际上就是网络文件服务器。NAS设备也提供了不止一种文件传输协议。NAS系统通常有一个以上的硬盘，而且和传统的文件服务器一样，通常会把它们组成RAID来提供服务。NAS设备直接连接到TCP/IP网络上，网络服务器通过TCP/IP网络存取管理数据。有了NAS以后，网络上的其他服务器就可以不必再兼任文件服务器的功能。 NAS是以文件为单位的通信协议，例如像是NFS（在UNIX系统上很常见）或是SMB（常用于Windows系统）。 缺点： 由于存储数据通过普通数据网络传输，因此易受网络上其它流量的影响。当网络上有其它大数据流量时会严重影响系统性能; 由于存储数据通过普通数据网络传输，因此容易产生数据泄漏等安全问题; 存储只能以文件方式访问，而不能像普通文件系统一样直接访问物理数据块，因此会在某些情况下严重影响系统效率，比如大型数据库就不能使用NAS. SAN存储区域网络是一种连接外接存储设备和服务器的架构。人们采用包括光纤通道技术(FC)、磁盘阵列(RAID)、磁带柜、光盘柜的各种技术进行实现。该架构的特点是，连接到服务器的存储设备，将被操作系统视为直接连接的存储设备。SAN实际是一种专门为存储建立的独立于TCP/IP网络之外的专用网络。SAN由于其基础是一个专用网络，因此扩展性很强，不管是在一个SAN系统中增加一定的存储空间还是增加几台使用存储空间的服务器都非常方便。 SAN是以区块为单位的通信协议，通常是透过SCSI再转为光纤通道或是iSCSI。还有其他各种不同的SAN通信协议。 缺点： 价格昂贵。不论是SAN阵列柜还是SAN必须的光纤通道交换机价格都是十分昂贵的，就连服务器上使用的光通道卡的价格也是不容易被小型商业企业所接受的; 需要单独建立光纤网络，异地扩展比较困难。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云计算]]></title>
    <url>%2F2018%2F12%2F07%2F%E4%BA%91%E8%AE%A1%E7%AE%97%2F</url>
    <content type="text"><![CDATA[参考： 维基百科 概述云计算（cloud computing），是一种基于互联网的计算方式，通过这种方式，共享的软硬件资源和信息可以按需求提供给计算机各种终端和其他设备。 用户不再需要了解“云”中基础设施的细节，不必具有相应的专业知识，也无需直接进行控制云计算描述了一种基于互联网的新的IT服务增加、使用和交付模式，通常涉及通过互联网来提供动态易扩展而且经常是虚拟化的资源。 三种模式美国国家标准和技术研究院的云计算定义中明确了三种服务模式： 基础环境即服务(IaaS, Infrastructure as a Service)消费者使用“基础计算资源”，如处理能力、存储空间、网络组件或中间件。消费者能掌控操作系统、存储空间、已部署的应用程序及网络组件（如防火墙、负载平衡器等），但并不掌控云基础架构。例如：Amazon AWS、Rackspace。 平台即服务(PaaS, Platform as a Service)消费者使用主机操作应用程序。消费者掌控运作应用程序的环境（也拥有主机部分掌控权），但并不掌控操作系统、硬件或运作的网络基础架构。平台通常是应用程序基础架构。例如：Google App Engine。 软件即服务(SaaS, Software as a Service)消费者使用应用程序，但并不掌控操作系统、硬件或运作的网络基础架构。是一种服务观念的基础，软件服务供应商，以租赁的概念提供客户服务，而非购买，比较常见的模式是提供一组账号密码。例如：Microsoft CRM与Salesforce.com。 部署模型美国国家标准和技术研究院的云计算定义中也涉及了关于云计算的部署模型: 公有云（Public Cloud）简而言之，公用云服务可透过网络及第三方服务供应者，开放给客户使用，“公用”一词并不一定代表“免费”，但也可能代表免费或相当廉价，公用云并不表示用户数据可供任何人查看，公用云供应者通常会对用户实施使用访问控制机制，公用云作为解决方案，既有弹性，又具备成本效益。 私有云（Private Cloud）私有云具备许多公用云环境的优点，例如弹性、适合提供服务，两者差别在于私有云服务中，数据与程序皆在组织内管理，且与公用云服务不同，不会受到网络带宽、安全疑虑、法规限制影响；此外，私有云服务让供应者及用户更能掌控云基础架构、改善安全与弹性，因为用户与网络都受到特殊限制。 社群云（Community Cloud）社群云由众多利益相仿的组织掌控及使用，例如特定安全要求、共同宗旨等。社群成员共同使用云数据及应用程序。 混合云（Hybrid Cloud）混合云结合公用云及私有云，这个模式中，用户通常将非企业关键信息外包，并在公用云上处理，但同时掌控企业关键服务及数据。 云技术 KVM XEN VMWare OpenStack(IaaS, 私有云) OpenShift(Paas) Docker Kubernetes Ansible Chef Puppet Salt]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>云服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitLab]]></title>
    <url>%2F2018%2F12%2F06%2FGitLab%2F</url>
    <content type="text"><![CDATA[参考: 维基百科 GitLab文档: https://docs.gitlab.com/ 版本: GitLib-CE: v11.6.0 GitLab-Runner: v11.6.0 GitLab是由GitLab Inc.开发，使用MIT许可证的基于网络的Git仓库管理工具。包括Git仓库管理、代码审查、问题跟踪、动态订阅、wiki等功能.以及GitLab内部集成的GitLab CI 更是一个持续集成和交付的好工具。 它有两个版本： CE EE UserUser docs AdminAdministrator documentation 安装和维护Installing and maintaining GitLab 安装Installation GitLab有多种方式进行安装。 依赖(requirements) 在安装之前，请先查看相关依赖文档。 依赖: https://docs.gitlab.com/ce/install/requirements.html 操作系统 Ruby版本 硬件 CPU Memory Storage 数据库 Unicorn WorkersUnicorn是多进程的Server容器。可以增加unicorn worker的数量，这通常有助于减少应用程序的响应时间并提高处理并行请求的能力。对于大多数情况，我们建议使用:CPU cores + 1 = unicorn workers 123456vi /etc/gitlab/gitlab.rb#CPU Cores=2unicorn['worker_processes'] = 3unicorn['worker_timeout'] = 60 Redis and SidekiqRedis存储所有用户会话和后台任务队列。Redis的存储要求很低，每个用户约25kB。Sidekiq是多线程的异步处理程序，使用多线程进程处理后台作业。 此过程从整个Rails Stack(200MB+)开始，如果存在内存泄漏，它可能会随着时间的推移而增长。 在非常活跃的服务器上（10,000+活动用户），Sidekiq进程可能使用1GB +内存。 GitLab Runner我们强烈不要在计划安装GitLab的同一台机器上安装GitLab Runner。根据您决定配置GitLab Runner的方式以及用于在CI环境中运行应用程序的工具，GitLab Runner可能会占用大量可用内存。如果您决定在同一台机器上运行GitLab Runner和GitLab Rails应用程序，则上面提供的内存消耗计算将无效。由于安全原因，将所有内容安装在一台计算机上也是不安全的——特别是当您计划将shell执行程序与GitLab Runner一起使用时。如果您打算使用CI功能，我们建议为每个GitLab Runner使用单独的计算机。 Prometheus and its exporters从Omnibus GitLab 9.0开始，Prometheus及其相关的exporter默认启用，一遍轻松、深入地监控GitLab。这些进程大概消耗200MB内存。 支持的浏览器 安装方式(Installation methods) Omnibus包: https://about.gitlab.com/install/ 源码 Docker 数据库(Database) PostgreSQL (highly recommended) MySQL/MariaDB (strongly discouraged, not all GitLab features are supported, no support for MySQL/MariaDB GTID) As of GitLab 10.0, PostgreSQL 9.6 or newer is required, and earlier versions are not supported. Users using PostgreSQL must ensure the pg_trgm extension is loaded into every GitLab database. This extension can be enabled (using a PostgreSQL super user) by running the following query for every database: 1CREATE EXTENSION pg_trgm; 在其它系统上，你可能需要安装附加包(e.g. postgresql-contrib)才能使得扩展可用。 如果你需要使用GitLab Geo，则需要postgres_fdw扩展： 1CREATE EXTENSION postgres_fdw; 包安装Centos7为栗子 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#安装依赖Ruby#因为需要v2.3版本，而yum查找出来的为v2.0，所以不使用yum安装#yum info ruby.x86_64#这里使用Ruby管理工具RVM（“Ruby Version Manager”）进行安装gpg --keyserver hkp://keys.gnupg.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB#开发版\curl -sSL https://get.rvm.io | bash#安装稳定版\curl -sSL https://get.rvm.io | bash -s stable --ruby#To start using RVM you need to run source ~/.rvm/scripts/rvmsource ~/.rvm/scripts/rvm#可把它写入profilevim /etc/profilesource ~/.rvm/scripts/rvmsource /etc/profile#查看rvm list known#安装ruby2.3rvm install 2.3ruby --versionruby 2.3.7p456 (2018-03-28 revision 63024) [x86_64-linux]#使用2.3rvm use 2.3#设为默认rvm use 2.3 --default#Install and configure the necessary dependenciessudo yum install -y curl policycoreutils-python openssh-serversudo systemctl enable sshdsudo systemctl start sshdsudo firewall-cmd --permanent --add-service=httpsudo systemctl reload firewalld#install Postfix to send notification emailssudo yum install postfixsudo systemctl enable postfixsudo systemctl start postfix#Add the GitLab package repository and install the packagecurl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bashsudo EXTERNAL_URL="http://gitlab.example.com" yum install -y gitlab-ce#镜像如无法下载，可使用国内清华，阿里镜像#重配置GitLabsudo gitlab-ctl reconfigure#这里GitLab会安装许多软件，如Nginx，Prometheus，Redis...#首次启动会有很多信息，请稍等#首次访问GitLab,系统会让你重新设置管理员的密码,设置成功后会返回登录界面.默认的管理员账号是root#在Web界面修改密码#Browse to the hostname and login#浏览器访问前面定义的URL##在Web界面修改密码，并登陆#Set up your communication preferences 配置域名或URL12345678910111213141516171819202122232425262728293031323334#Configuring the external URL for GitLabvi /etc/gitlab/gitlab.rbexternal_url "http://gitlab.example.com"#重载配置sudo gitlab-ctl reconfigure#Configuring a relative URL for Gitlab#从v8.17以后便不需要再重新编译#要求：4GB RAM, and 4 or 8 CPU cores#栗子: https://example.com/gitlab#Enable relative URL in GitLab#如果资源不够，可临时关闭 Unicorn and Sidekiq以节省资源sudo gitlab-ctl stop unicornsudo gitlab-ctl stop sidekiqvi /etc/gitlab/gitlab.rbexternal_url "https://example.com/gitlab"#重载配置sudo gitlab-ctl reconfigure#重新启动服务，以便Unicorn和Sidekiq获取更改sudo gitlab-ctl restart#Disable relative URL in GitLabexternal_url后面不包含相对路劲即可#之后重载配置sudo gitlab-ctl restart unicorn 从non-root用户载入配置Loading external configuration file from non-root user Omnibus-gitlab package 从 /etc/gitlab/gitlab.rb file载入所有配置。它属于root用户，有严格的权限配置。它通过root用户由ruby代码执行gitlab-ctl reconfigure。 指定其它配置: 123vim /etc/gitlab/gitlab.rbfrom_file "/home/admin/external_gitlab.rb" 将Git数据存储在备用目录中Storing Git data in an alternative directory 默认情况下，omnibus-gitlab将repository数据存放于/var/opt/gitlab/git-data目录下。repository存储在此目录下的repositories子目录中。可在/etc/gitlab/gitlab.rb中修改git-data来添加备用数据目录。请注意，目录和子目录的路径必须不是链接。 如果还运行了Gitaly，请为每个git数据目录包含gitaly_address。 123456789101112131415161718192021222324252627282930313233343536373839404142vim /etc/gitlab/gitlab.rb#git_data_dirs(&#123; "default" =&gt; &#123; "path" =&gt; "/mnt/nas/git-data" &#125; &#125;)#你可以添加不止一个数据目录git_data_dirs(&#123; "default" =&gt; &#123; "path" =&gt; "/var/opt/gitlab/git-data" &#125;, "alternative" =&gt; &#123; "path" =&gt; "/mnt/nas/git-data" &#125;&#125;)#重载配置，使得更改生效sudo gitlab-ctl reconfigure#查看sudo ls /var/opt/gitlab/git-datarepositories#如果你的/var/opt/gitlab/git-data已有Git repositories，则# Prevent users from writing to the repositories while you move them.sudo gitlab-ctl stop# Note there is _no_ slash behind 'repositories', but there _is_ a# slash behind 'git-data'.sudo rsync -av /var/opt/gitlab/git-data/repositories /mnt/nas/git-data/# Start the necessary processes and run reconfigure to fix permissions# if necessarysudo gitlab-ctl upgrade# Double-check directory layout in /mnt/nas/git-data. Expected output:# repositoriessudo ls /mnt/nas/git-data/# Done! Start GitLab and verify that you can browse through the repositories in# the web interface.sudo gitlab-ctl start 修改Git用户/组Changing the name of the Git user / group 默认情况下，omnibus-gitLab使用git用户登录gitlab-shell和远程Web接口。不推荐改变已安装的User/Group。 1234567891011121314151617181920212223vim /etc/gitlab/gitlab.rb#用户名/组名user['username'] = "git"user['group'] = "git"##! The shell for the git user# user['shell'] = "/bin/sh"##! The home directory for the git user# user['home'] = "/var/opt/gitlab"#uid/gid#omnibus-gitlab creates users for GitLab, PostgreSQL, Redis and NGINX.你可以指定他们的IDuser['uid'] = 1234user['gid'] = 1234postgresql['uid'] = 1235postgresql['gid'] = 1235redis['uid'] = 1236redis['gid'] = 1236web_server['uid'] = 1237web_server['gid'] = 1237 禁用用户和组的账号管理Disable user and group account management 默认情况下，omnibus-gitlab会创建系统用户/组账户，这些系统账户运行包的各种组件。大多数用户都不需要去改变这些行为。然而，如果你的系统账户由其它软件管理，你或许需要禁用此功能。 1234567891011121314151617181920212223242526272829303132333435vim /etc/gitlab/gitlab.rbmanage_accounts['enable'] = false#omnibus-gitlab依然保留之前创建的账户#默认创建以下用户# GitLab user (required)git# Web server user (required)gitlab-www# Redis user for GitLab (only when using packaged Redis)gitlab-redis# Postgresql user (only when using packaged Postgresql)gitlab-psql# Prometheus user for prometheus monitoring and various exportersgitlab-prometheus# GitLab Mattermost user (only when using GitLab Mattermost)mattermost# GitLab Registry user (only when using GitLab Registry)registry# GitLab Consul user (only when using GitLab Consul)gitlab-consul#查看用户sudo awk -F':' '&#123;print $1&#125;' /etc/passwd 你也可以在GitLab配置文件里面更改: 12345678910111213141516171819202122232425262728293031vi /etc/gitlab/gitlab.rb# Do not manage user/group accountsmanage_accounts['enable'] = false# GitLabuser['username'] = "custom-gitlab"user['group'] = "custom-gitlab"user['shell'] = "/bin/sh"user['home'] = "/var/opt/custom-gitlab"# Web serverweb_server['username'] = 'webserver-gitlab'web_server['group'] = 'webserver-gitlab'web_server['shell'] = '/bin/false'web_server['home'] = '/var/opt/gitlab/webserver'# Postgresql (not needed when using external Postgresql)postgresql['username'] = "postgres-gitlab"postgresql['group'] = "postgres-gitlab"postgresql['shell'] = "/bin/sh"postgresql['home'] = "/var/opt/postgres-gitlab"# Redis (not needed when using external Redis)redis['username'] = "redis-gitlab"redis['group'] = "redis-gitlab"redis['shell'] = "/bin/false"redis['home'] = "/var/opt/redis-gitlab"# And so on for users/groups for GitLab Mattermost1 禁用存储目录管理Disable storage directories management omnibus-gitlab负责使用正确的所有权与权限创建所必须的目录，并保持更新。一种一些目录在配置时可能会包含大量数据，也可能会挂载到NFS。 123456789vi /etc/gitlab/gitlab.rb#如果已挂在/etc/gitlab，则可关闭此目录的管理manage_storage_directories['manage_etc'] = false#如果要挂载GitLab的所有存储目录，并且每个目录都是单独地挂载，则应完全禁用存储目录的管理manage_storage_directories['enable'] = false GitLab所有数据目录： Default location Permissions Ownership Purpose /var/opt/gitlab/git-data 0700 git:root Holds repositories directory /var/opt/gitlab/git-data/repositories 2770 git:git Holds git repositories /var/opt/gitlab/gitlab-rails/shared 0751 git:gitlab-www Holds large object directories /var/opt/gitlab/gitlab-rails/shared/artifacts 0700 git:root Holds CI artifacts /var/opt/gitlab/gitlab-rails/shared/lfs-objects 0700 git:root Holds LFS objects /var/opt/gitlab/gitlab-rails/uploads 0700 git:root Holds user attachments /var/opt/gitlab/gitlab-rails/shared/pages 0750 git:gitlab-www Holds user pages /var/opt/gitlab/gitlab-ci/builds 0700 git:root Holds CI build logs /var/opt/gitlab/.ssh 0700 git:git Holds authorized keys 仅在挂载给定文件系统后启动Omnibus-GitLab服务Only start Omnibus-GitLab services after a given filesystem is mounted 如果你想防止Omnibus-GitLab服务(Nginx，Redis，Unicorn…)在挂载给定文件系统之前启动，则: 12345vi /etc/gitlab/gitlab.rb# wait for /var/opt/gitlab to be mountedhigh_availability['mountpoint'] = '/var/opt/gitlab' 配置运行时目录Configuring runtime directory 启用Prometheus监控后，GitLab-monitor将对每个Unicorn进程(Rails metrics)进行监控。每个Unicorn进行都需要将度量文件(metrics file)写入每个控制器临时的位置，然后，Prometheus收集这些文件并处理他们的值。 为了避免创建磁盘I/O，Omnibus-GitLab包将会使用一个运行时目录。 1234567891011#During reconfigure, package will check if `/run` is a `tmpfs` mount. If it is not, warning will be printed, and Rails metrics will be disabled.Runtime directory '/run' is not a tmpfs mount.#To enable Rails metrics again, create a tmpfs mount and specify itvi /etc/gitlab/gitlab.rb# runtime_dir '/run'runtime_dir '/path/to/tmpfs' 在安装期间禁用自动缓存清理Disabling automatic cache cleaning during installation 如果安装了大型的GitLab，则你可能不希望运行rake cache:clean，因为它将会耗费很长时间。 123456789101112131415161718192021222324252627282930313233343536373839vi /etc/gitlab/gitlab.rb# This is advanced feature used by large gitlab deployments where loading# whole RAILS env takes a lot of time.gitlab_rails['rake_cache_clear'] = false#Enabling/Disabling Rack Attack and setting up basic auth throttlinggitlab_rails['rack_attack_git_basic_auth'] = &#123; 'enabled' =&gt; true, # Enable/Disable Rack Attack 'ip_whitelist' =&gt; ["127.0.0.1"], # Whitelisted urls 'maxretry' =&gt; 10, # Limit the number of Git HTTP authentication attempts per IP 'findtime' =&gt; 60, # Reset the auth attempt counter per IP after 60 seconds 'bantime' =&gt; 3600 # Ban an IP for one hour (3600s) after too many auth attempts&#125;#Setting up paths to be protected by Rack Attack#如果你想改变默认保护路径#警告：此动作将会被Omnibus-GitLab提供的列表所覆盖gitlab_rails['rack_attack_protected_paths'] = [ '/users/password', '/users/sign_in', '/api/#&#123;API::API.version&#125;/session.json', '/api/#&#123;API::API.version&#125;/session', '/users', '/users/confirmation', '/unsubscribes/', '/import/github/personal_access_token']#Setting up throttling for ‘paths to be protected’gitlab_rails['rate_limit_requests_per_period'] = 10gitlab_rails['rate_limit_period'] = 60 其它 Nginx HTTPS Database Redis SMTP … 具体参考官方文档。 更新Update 更新方式取决你你使用的安装方法。 不停机升级(Upgrading without downtime) 从GitLab 9.1.0开始便可以非脱机更新，但要遵循一下依赖： You can only upgrade 1 minor release at a time. So from 9.1 to 9.2, not to 9.3. You have to use post-deployment migrations You are using PostgreSQL. If you are using MySQL please look at the release post to see if downtime is required. 更新版本(Upgrading between editions) CE-&gt;EE EE-&gt;CE 杂项(Miscellaneous) MySQL to PostgreSQL Restoring from backup after a failed upgrade Upgrading PostgreSQL Using Slony 高可用High Availability: Configure multiple servers for scaling or high availability. GitLab支持多种不同类型的集群和高可用。方案取决于你所依赖的伸缩和可用的级别。最简单的方式是可伸缩，但并不一定是高可用的。由于Git的分布式特性，即使GitLab不可用，开发人员仍然可以在本地提交代码。 但是，当GitLab关闭时，某些GitLab功能（如issue tracker and Continuous Integration…）不可用。 请记住，所有高可用性解决方案都需要在成本/复杂性和正常运行时间之间进行权衡。想要正常运行的时间越久，则解决方案就越复杂，则设置和维护它的工作就越多。高可用不是免费的，每个高可用方案都应该考虑成本和收益。 架构Architecture 有两种配置： active/active active/passive Active/Active 此体系结构可轻松扩展，因为所有应用程序Server可同时处理用户请求。Database、Redis、GitLab都部署在不同的Server上，如果他们配置也是如此，则高度可用。 配置active/active所遵循的步骤： 配置Database 配置Redis 配置NFS 配置GitLab 配置LoadBlancer Active/Passive 对于没有扩展的高可用/故障转移，你可使用Active/Passive。这利用DRBD（Distributed Replicated Block Device）来保持所有数据同步。DRBD要求低延迟链接保持同步。 不建议尝试在数据中心之间或不同的云可用区域中运行DRBD。 至少需要两台机器(one active/one passive)。 配置Configuring GitLab 配置时区Adjust your instance’s timezone: Customize the default time zone of GitLab. GitLab默认时区为UTC， 123456789101112vi /etc/gitlab/gitlab.rb# gitlab_rails['time_zone'] = 'UTC'gitlab_rails['time_zone'] = 'Asia/Shanghai'#重载重启gitlab-ctl reconfigure gitlab-ctl restart#查看时区gitlab-rake time:zones:all 系统钩子System hook，Notifications when users, projects and keys are changed. GitLab实例可对以下事件执行HTTP POST请求： project_create project_destroy project_rename project_transfer project_update user_add_to_team user_remove_from_team user_create user_destroy user_failed_login user_rename key_create key_destroy group_create group_destroy group_rename user_add_to_group user_remove_from_group 可以使用系统钩子，如用于记录或更改 LDAP Server 中的信息。 注意：我们遵循Webhook中对Push和Tag事件的相同结构，但不会显示commit的信息。Webhook的相同弃用在此有效。 Hook请求Request Header:1X-Gitlab-Event: System Hook 项目创建栗子，还有删除、重名、更新、用户、组等其它事件。 123456789101112&#123; "created_at": "2012-07-21T07:30:54Z", "updated_at": "2012-07-21T07:38:22Z", "event_name": "project_create", "name": "StoreCloud", "owner_email": "johnsmith@gmail.com", "owner_name": "John Smith", "path": "storecloud", "path_with_namespace": "jsmith/storecloud", "project_id": 74, "project_visibility": "private"&#125; Tag事件当向仓库(Repository)创建或删除标记(tag)时触发，它为每个修改过的标记生成一个事件。。 Request header: 1X-Gitlab-Event: System Hook Request body: 1234567891011121314151617181920212223242526272829303132333435363738&#123; "event_name": "tag_push", "before": "0000000000000000000000000000000000000000", "after": "82b3d5ae55f7080f1e6022629cdb57bfae7cccc7", "ref": "refs/tags/v1.0.0", "checkout_sha": "5937ac0a7beb003549fc5fd26fc247adbce4a52e", "user_id": 1, "user_name": "John Smith", "user_avatar": "https://s.gravatar.com/avatar/d4c74594d841139328695756648b6bd6?s=8://s.gravatar.com/avatar/d4c74594d841139328695756648b6bd6?s=80", "project_id": 1, "project":&#123; "name":"Example", "description":"", "web_url":"http://example.com/jsmith/example", "avatar_url":null, "git_ssh_url":"git@example.com:jsmith/example.git", "git_http_url":"http://example.com/jsmith/example.git", "namespace":"Jsmith", "visibility_level":0, "path_with_namespace":"jsmith/example", "default_branch":"master", "homepage":"http://example.com/jsmith/example", "url":"git@example.com:jsmith/example.git", "ssh_url":"git@example.com:jsmith/example.git", "http_url":"http://example.com/jsmith/example.git" &#125;, "repository":&#123; "name": "Example", "url": "ssh://git@example.com/jsmith/example.git", "description": "", "homepage": "http://example.com/jsmith/example", "git_http_url":"http://example.com/jsmith/example.git", "git_ssh_url":"git@example.com:jsmith/example.git", "visibility_level":0 &#125;, "commits": [], "total_commits_count": 0&#125; Merge请求事件在创建一个新的合并(merge)请求时触发，更新、合并、关闭现有合并请求，或在源分支中添加commit。 Request Header: 1X-Gitlab-Event: System Hook 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114&#123; "object_kind": "merge_request", "user": &#123; "name": "Administrator", "username": "root", "avatar_url": "http://www.gravatar.com/avatar/e64c7d89f26bd1972efa854d13d7dd61?s=80&amp;d=identicon" &#125;, "project": &#123; "name": "Example", "description": "", "web_url": "http://example.com/jsmith/example", "avatar_url": null, "git_ssh_url": "git@example.com:jsmith/example.git", "git_http_url": "http://example.com/jsmith/example.git", "namespace": "Jsmith", "visibility_level": 0, "path_with_namespace": "jsmith/example", "default_branch": "master", "ci_config_path": "", "homepage": "http://example.com/jsmith/example", "url": "git@example.com:jsmith/example.git", "ssh_url": "git@example.com:jsmith/example.git", "http_url": "http://example.com/jsmith/example.git" &#125;, "object_attributes": &#123; "id": 90, "target_branch": "master", "source_branch": "ms-viewport", "source_project_id": 14, "author_id": 51, "assignee_id": 6, "title": "MS-Viewport", "created_at": "2017-09-20T08:31:45.944Z", "updated_at": "2017-09-28T12:23:42.365Z", "milestone_id": null, "state": "opened", "merge_status": "unchecked", "target_project_id": 14, "iid": 1, "description": "", "updated_by_id": 1, "merge_error": null, "merge_params": &#123; "force_remove_source_branch": "0" &#125;, "merge_when_pipeline_succeeds": false, "merge_user_id": null, "merge_commit_sha": null, "deleted_at": null, "in_progress_merge_commit_sha": null, "lock_version": 5, "time_estimate": 0, "last_edited_at": "2017-09-27T12:43:37.558Z", "last_edited_by_id": 1, "head_pipeline_id": 61, "ref_fetched": true, "merge_jid": null, "source": &#123; "name": "Awesome Project", "description": "", "web_url": "http://example.com/awesome_space/awesome_project", "avatar_url": null, "git_ssh_url": "git@example.com:awesome_space/awesome_project.git", "git_http_url": "http://example.com/awesome_space/awesome_project.git", "namespace": "root", "visibility_level": 0, "path_with_namespace": "awesome_space/awesome_project", "default_branch": "master", "ci_config_path": "", "homepage": "http://example.com/awesome_space/awesome_project", "url": "http://example.com/awesome_space/awesome_project.git", "ssh_url": "git@example.com:awesome_space/awesome_project.git", "http_url": "http://example.com/awesome_space/awesome_project.git" &#125;, "target": &#123; "name": "Awesome Project", "description": "Aut reprehenderit ut est.", "web_url": "http://example.com/awesome_space/awesome_project", "avatar_url": null, "git_ssh_url": "git@example.com:awesome_space/awesome_project.git", "git_http_url": "http://example.com/awesome_space/awesome_project.git", "namespace": "Awesome Space", "visibility_level": 0, "path_with_namespace": "awesome_space/awesome_project", "default_branch": "master", "ci_config_path": "", "homepage": "http://example.com/awesome_space/awesome_project", "url": "http://example.com/awesome_space/awesome_project.git", "ssh_url": "git@example.com:awesome_space/awesome_project.git", "http_url": "http://example.com/awesome_space/awesome_project.git" &#125;, "last_commit": &#123; "id": "ba3e0d8ff79c80d5b0bbb4f3e2e343e0aaa662b7", "message": "fixed readme", "timestamp": "2017-09-26T16:12:57Z", "url": "http://example.com/awesome_space/awesome_project/commits/da1560886d4f094c3e6c9ef40349f7d38b5d27d7", "author": &#123; "name": "GitLab dev user", "email": "gitlabdev@dv6700.(none)" &#125; &#125;, "work_in_progress": false, "total_time_spent": 0, "human_total_time_spent": null, "human_time_estimate": null &#125;, "labels": null, "repository": &#123; "name": "git-gpg-test", "url": "git@example.com:awesome_space/awesome_project.git", "description": "", "homepage": "http://example.com/awesome_space/awesome_project" &#125;&#125; 库更新事件Repository Update events 当你push到Repository(包括tag)的时候仅触发一次。 Request Header： 1X-Gitlab-Event: System Hook Request body: 1234567891011121314151617181920212223242526272829303132&#123; "event_name": "repository_update", "user_id": 1, "user_name": "John Smith", "user_email": "admin@example.com", "user_avatar": "https://s.gravatar.com/avatar/d4c74594d841139328695756648b6bd6?s=8://s.gravatar.com/avatar/d4c74594d841139328695756648b6bd6?s=80", "project_id": 1, "project": &#123; "name":"Example", "description":"", "web_url":"http://example.com/jsmith/example", "avatar_url":null, "git_ssh_url":"git@example.com:jsmith/example.git", "git_http_url":"http://example.com/jsmith/example.git", "namespace":"Jsmith", "visibility_level":0, "path_with_namespace":"jsmith/example", "default_branch":"master", "homepage":"http://example.com/jsmith/example", "url":"git@example.com:jsmith/example.git", "ssh_url":"git@example.com:jsmith/example.git", "http_url":"http://example.com/jsmith/example.git", &#125;, "changes": [ &#123; "before":"8205ea8d81ce0c6b90fbe8280d118cc9fdad6130", "after":"4045ea7a3df38697b3730a20fb73c8bed8a3e69e", "ref":"refs/heads/master" &#125; ], "refs":["refs/heads/master"]&#125; 安全Security: Learn what you can do to further secure your GitLab instance. 密码长度Password length limits 如果要强制使用更长的用户密码，可使用Devise initializer来设置。 如果未使用devise_password_length.rb初始化程序，则在config/initializers/devise.rb中设置密码长度。 123cd /home/git/gitlabsudo -u git -H cp config/initializers/devise_password_length.rb.example config/initializers/devise_password_length.rbsudo -u git -H editor config/initializers/devise_password_length.rb # inspect and edit the new password length limits 限制SSH秘钥和长度Restrict SSH key technologies and minimum length ssh-keygen允许用户创建少至768位的RSA密钥，这远低于某些标准组的建议。 这个功能在Web界面的设置里去设置。 机架攻击Rack attack Rack Attack, 也称为Rack::Attack.旨在通过自定义限制和阻止用户IP来保护GitLab。从v 11.2开始，默认禁用此功能。您可以通过限制来自发出大量请求的IP地址的请求来防止暴力密码攻击，抓取程序或任何其他违规者。 如果您发现限制不足以保护您免受滥用客户端的攻击，Rack Attack提供IP白名单，黑名单，Fail2ban样式过滤和跟踪。如果你的实例并未对外有任何传入连接，则建议你禁用此功能。 设置123456789101112131415vi /etc/gitlab/gitlab.rb#启用gitlab_rails['rack_attack_git_basic_auth'] = &#123; 'enabled' =&gt; true, 'ip_whitelist' =&gt; ["127.0.0.1"], 'maxretry' =&gt; 10, # Limit the number of Git HTTP authentication attempts per IP 'findtime' =&gt; 60, # Reset the auth attempt counter per IP after 60 seconds 'bantime' =&gt; 3600 # Ban an IP for one hour (3600s) after too many auth attempts&#125;#重载sudo gitlab-ctl reconfigure 通过Redis冲机架攻击中移除阻止的IPRemove blocked IPs from Rack Attack via Redis 如果想移除阻止的IPs，参考下： 123456789101112131415161718#在日志中找出被阻止的IPsgrep &quot;Rack_Attack&quot; /var/log/gitlab/gitlab-rails/production.log#由于黑名单存在Redis中，所以需要连接Redis/opt/gitlab/embedded/bin/redis-cli -s /var/opt/gitlab/redis/redis.socket#删除此IPDEL cache:gitlab:rack::attack:allow2ban:ban:&lt;ip&gt;#查看KEYS *rack::attack*#或者，将其加入白名单 如果所有流量来自于负载均衡器，请记得把负载均衡器加入白名单。 Webhooks和不安全的内部Web服务Webhooks and insecure internal web services 如果您的GitLab Server或其本地网络中运行non-GitLab Web服务，则这些服务可能很容易被Webhooks利用。使用Webhook，你便可以设置项目在发生特定事件时触发的URL。通常，这些请求被发送到专门为此目的设置的外部Web服务，以适当的方式处理请求及其附加数据。 然而，当Webhook设置的URL不是指向外部服务而是指向内部服务时，可能会在触发webhook并发送POST请求时完全无意中执行操作。因为Webhook请求是由GitLab Server本身发出的，所以它们可以完全访问服务器上运行的所有内容或服务器的本地网络，即使这些服务受到其他方面的保护，无法与外界联系。 如果一个Web服务不需要身份认证，Webhooks可以通过让GitLab Server向端点(endpoint)发出POST请求来触发破坏性命令，例如http://localhost:123/some-resource/delete 为了防止这种类型的利用，从GitLab v10.6开始，默认禁止对当前GitLab Instance Server Address或private network的所有Webhook请求。 1234567#这意味着这些地址都被禁止127.0.0.1::10.0.0.010.0.0.0/8172.16.0.0/12173.192.168.0.0/16 可在Web界面的设置里面的Outbound requests里启用Allow requests to the local network from hooks and services. 信息独占性Information exclusivity Git是一个分布式版本控制系统，这意味着使用源代码的每一个人都拥有完整Repository的本地副本。GitLab有Guest、 Reporter、Developer、Maintainer这些项目用户权限。在获取此Repository后，用户可在任何位置上传此Repository。您无法构建访问控制来阻止有权访问源代码的用户有意共享源代码。这是DVCS的固有特性，所有git管理系统都有此限制。显然你可以采取措施防止无意的共享和信息破坏，这就是为什么只有一些人被允许邀请其他人，没有人可以强制推动受保护的分支。 重置root密码reset your root password 使用root权限登录Ruby Rail控制台: 1234567891011121314151617181920212223sudo su -#控制台gitlab-rails console production#等待终端的载入#查找用户user = User.where(id: 1).first#oruser = User.find_by(email: 'admin@local.host')#修改密码user.password = 'secret_pass'user.password_confirmation = 'secret_pass'#保存更改和退出user.save! 解锁锁定的用户How to unlock a locked user 使用root权限登录Server，启动Ruby Rail Console: 123456789101112sudo su -gitlab-rails console productionuser = User.where(id: 1).first#oruser = User.find_by(email: 'admin@local.host')#解锁user.unlock_access! 用户文件上传User File Uploads 如果有人知道直接URL，则附加图像到问题，合并请求或评论不需要查看身份验证。此直接URL包含一个随机的32个字符的ID，可防止未经授权的人员将URL猜到包含敏感信息的图像。我们不启用身份验证，因为这些图像需要在通知电子邮件正文中可见，通常从未通过GitLab验证的电子邮件客户端读取，例如Outlook、Gmail.. 请注意，非图像附件确实需要查看身份验证。 管理CRIME漏洞How we manage the CRIME vulnerability CRIME(“Compression Ratio Info-leak Made Easy”)是一种针对使用HTTPS和SPDY协议进行连接的秘密Web cookie的安全漏洞，这些协议也使用数据压缩。当用于恢复秘密身份验证cookie的内容时，它允许攻击者在经过身份验证的Web会话上执行会话劫持，从而允许发起进一步的攻击。 TLS协议CRIME漏洞影响HTTPS上的压缩，因此它警告不要使用SSL压缩（例如gzip）或SPDY，它也可以选择使用压缩。虽然在Omnibus安装中启用了SPDY，但CRIME依赖于压缩（’C’），并且NGINX的SPDY模块中的默认压缩级别为0（无压缩）。 GitLab支持gzip和SPDY，并在启用HTTPS时通过停用gzip来缓解CRIME漏洞。你可以看到问题的来源： Source installation NGINX file Omnibus installation NGINX file 强制双重认证Enforce Two-factor Authentication (2FA) 双因素身份验证（2FA）为GitLab帐户提供了额外的安全级别。启用后，除了提供用户名和密码登录外，还要求在输入应用程序生成的代码。 为所有账户启用两步认证： 有两种方式： Enforce on next login. Suggest on next login, but allow a grace period before enforcing. 在Web界面里Admin区域里的设置里面的“Sign-in Restrictions”选项。 为组中的所有用户启用： 如果你只想对某些特定组启用两步认证，则你需要则群组设置中启用它。 为所有用户禁用： 123456# Omnibus installationssudo gitlab-rake gitlab:two_factor:disable_for_all_users# Installations from sourcesudo -u git -H bundle exec rake gitlab:two_factor:disable_for_all_users RAILS_ENV=production 注册时用户邮件确认User email confirmation at sign-up 如果您想在所有用户电子邮件登录之前确认，GitLab管理员可以在注册时启用电子邮件确认。 在Web界面的Admin区域的设置的“ Sign-up Restrictions”里启用“Send confirmation email on sign-up”。 统计、检查和pingUsage statistics, version check, and usage ping: Enable or disable information about your instance to be sent to GitLab, Inc. GitLab定期从实例收集各种信息。你可在Admin area &gt; Settings去设置他们。 停止使用ping： 在设置面板里面取消，并修改配置。 1234567891011121314#omnibusvi /etc/gitlab/gitlab.rbgitlab_rails[&apos;usage_ping_enabled&apos;] = false#sourcevi ./gitlab.ymlproduction: &amp;base # ... gitlab: # ... usage_ping_enabled: false 轮询配置Polling: Configure how often the GitLab UI polls for updates. GitLab UI按照适合资源的计划轮询不同资源的更新(issue notes, issue titles, pipeline statuses, etc.)在Web UI的应用程序使用功能中设置它： 1(默认值，推荐用于大多数安装)（Issue notes poll every 2 seconds, and issue titles poll every 5 seconds.) 0(禁用UI轮询) 大于1(将减慢轮询速度) 0-1之间(轮询更频繁，不推荐) GitLab PageGitLab Pages configuration: Enable and configure GitLab Pages. GitLab Pages使用GitLab Pages Daemon，这是一个用Go编写的简单HTTP Server，可以侦听外部IP地址并提供对自定义域和自定义证书的支持。它通过SNI支持动态证书，默认情况下使用HTTP2公开页面。 对于自定义域（但不是通配符域），Pages Daemon需要侦听端口80/443。因此，您可以灵活设置它： 在与GitLab相同的Server中运行Pages Daemon，监听 Secondary IP 在与GitLab相同的Server上运行Pages Daemon，监听同一IP的不同Port 在单独的Server中运行Pages Daemon 依赖在配置Pages之前，你需要： 拥有用于提供GitLab Pages的独占根域。请注意，您不能使用GitLab实例域的子域。 配置wildcard DNS record. HTTPS(可选) 启用shared runner(可选，但推荐) 将域添加到公共后缀列表Add the domain to the Public Suffix List DNS配置 您需要添加指向GitLab运行的主机的通配符DNS A记录。 配置根据您的需要，您可以通过4种不同的方式设置GitLab页面。 Wildcard domains Wildcard domains with TLS support Custom domains Custom domains with TLS support Custom domain verification Access control 12345vi /etc/gitlab/gitlab.rbgitlab_pages... 其它一些配置： 1234567891011121314151617#日志记录gitlab_pages[&apos;log_verbose&apos;] = true#存储路径gitlab_rails[&apos;pages_path&apos;] = &quot;/mnt/storage/pages&quot;#监听和代理请求gitlab_pages[&apos;listen_proxy&apos;] = &quot;localhost:10080&quot;#禁用gitlab_pages[&apos;listen_proxy&apos;] = nil#安全#备份#page size... 环境变量Environment variables: Supported environment variables that can be used to override their defaults values in order to configure GitLab. GitLab公开了某些环境变量，这些变量可用于覆盖其默认值。 支持的环境变量： Variable Type Description GITLAB_CDN_HOST string Sets the base URL for a CDN to serve static assets (e.g. //mycdnsubdomain.fictional-cdn.com) GITLAB_ROOT_PASSWORD string Sets the password for the root user on installation GITLAB_HOST string The full URL of the GitLab server (including http:// or https://) RAILS_ENV string The Rails environment; can be one of production, development, staging or test DATABASE_URL string The database URL; is of the form: postgresql://localhost/blog_development GITLAB_EMAIL_FROM string The e-mail address used in the “From” field in e-mails sent by GitLab GITLAB_EMAIL_DISPLAY_NAME string The name used in the “From” field in e-mails sent by GitLab GITLAB_EMAIL_REPLY_TO string The e-mail address used in the “Reply-To” field in e-mails sent by GitLab GITLAB_EMAIL_SUBJECT_SUFFIX string The e-mail subject suffix used in e-mails sent by GitLab GITLAB_UNICORN_MEMORY_MIN integer The minimum memory threshold (in bytes) for the Unicorn worker killer GITLAB_UNICORN_MEMORY_MAX integer The maximum memory threshold (in bytes) for the Unicorn worker killer GITLAB_SHARED_RUNNERS_REGISTRATION_TOKEN string Sets the initial registration token used for GitLab Runners 完整的数据库变量： 指定数据库连接信息的推荐方法是设置DATABASE_URL环境变量。此变量仅保存连接信息(adapter, database, username, password, host, port)，没有行为信息(encoding, pool)。 如果你不想使用DATABASE_URL环境变量或想要使用数据库行为信息，则： 复制模板文件: cp config/database.yml.env config/database.yml 或，为GITLAB_DATABASE_XXX变量设置值 你可以设置的GITLAB_DATABASE_XXX变量列表： Variable Default value Overridden by DATABASE_URL? GITLAB_DATABASE_ADAPTER postgresql (for MySQL use mysql2) Yes GITLAB_DATABASE_DATABASE gitlab_#{ENV[‘RAILS_ENV’] Yes GITLAB_DATABASE_USERNAME root Yes GITLAB_DATABASE_PASSWORD None Yes GITLAB_DATABASE_HOST localhost Yes GITLAB_DATABASE_PORT 5432 Yes GITLAB_DATABASE_ENCODING unicode No GITLAB_DATABASE_POOL 10 No 添加更多变量： 我们欢迎合并请求，并通过变量进行更多配置。请在config/initializers/1_settings.rb文件中进行更改，并使用GITLAB_#{name in 1_settings.rb in upper case}这样的命名方案。 Omnibus设置自定义环境变量： 如有必要，您可以通过/etc/gitlab/gitlab.rb设置Unicorn，Sidekiq，Rails和Rake使用的自定义环境变量。这在您需要使用代理来访问Internet并且您希望将外部托管的存储库直接克隆到gitlab的情况下非常有用。 1234567891011121314151617181920212223242526272829gitlab_rails[&apos;env&apos;] = &#123; &quot;http_proxy&quot; =&gt; &quot;my_proxy&quot;, &quot;https_proxy&quot; =&gt; &quot;my_proxy&quot;&#125;#你还可以覆盖GitLab组件中的其它环境变量# Needed for proxying Git clonesgitaly[&apos;env&apos;] = &#123; &quot;http_proxy&quot; =&gt; &quot;my_proxy&quot;, &quot;https_proxy&quot; =&gt; &quot;my_proxy&quot;&#125;gitlab_workhorse[&apos;env&apos;] = &#123; &quot;http_proxy&quot; =&gt; &quot;my_proxy&quot;, &quot;https_proxy&quot; =&gt; &quot;my_proxy&quot;&#125;# If you use the docker registryregistry[&apos;env&apos;] = &#123; &quot;http_proxy&quot; =&gt; &quot;my_proxy&quot;, &quot;https_proxy&quot; =&gt; &quot;my_proxy&quot;&#125;#应用更改#对环境变量所做的任何更改都需要在重新配置后进行硬重启才能使其生效sudo gitlab-ctl reconfiguresudo gitlab-ctl restart 插件GitLab Plugin SystemPlugins: With custom plugins, GitLab administrators can introduce custom integrations without modifying GitLab’s source code. 使用自定义插件，GitLab管理员可以在不修改GitLab源代码的情况下引入自定义集成。你也可以之间修改GitLab源代码而不用编写插件。必须在GitLab Server上配置插件。 插件将在每个事件上运行，因此您可以在插件代码中过滤事件或项目。你可以拥有任意数量的插件。如果发生事件，每个插件都将由GitLab异步触发。 配置： 插件必须直接放在plugin目录中，按照以下步骤自定义hook: 在GitLab Server上，定位到plugin目录 source: /home/git/gitlab/plugins/ omnibus: /opt/gitlab/embedded/service/gitlab-rails/plugins 在plugins目录内，创建一个你需要的文件(文件名不要使用特殊字符) 使hook文件可执行，并有git用户所拥有 编写代码以使插件功能符合预期。这可以是任何语言 插件的数据将在STDIN上以JSON的形式提供 验证： 编写自己的插件可能会非常棘手，如果您可以在不改变系统的情况下进行检查，则会更容易。 123456# Omnibus installationssudo gitlab-rake plugins:validate# Installations from sourcecd /home/git/gitlabbundle exec rake plugins:validate RAILS_ENV=production 规范性Compliance: A collection of features from across the application that you may configure to help ensure that your 您可以配置以下GitLab功能，以帮助确保您的GitLab实例符合通用的规范性标准。 功能 GitLab tier Restrict SSH Keys 控制用于访问GitLab的SSH密钥的技术和密钥长度 Core+ Granular user roles and flexible permissions 使用五种不同的用户角色和外部用户设置管理访问权限和权限。根据人员的角色设置权限，而不是对存储库的读取或写入访问权限。不要与只需要访问问题跟踪器的人共享源代码。 Core+ Enforce TOS acceptance 通过阻止GitLab流量强制您的用户接受新的服务条款。 Core+ Email all users of a project, group, or entire server 管理员可以根据项目或组成员身份向用户组发送电子邮件，或使用GitLab实例向每个人发送电子邮件。 Starter+ Omnibus package supports log forwarding 将日志转发到中央系统。 Starter+ Lock project membership to group 组所有者可以阻止将新成员添加到组中的项目。 Starter+ LDAP group sync GitLab企业版使管理员能够自动同步组并管理SSH密钥，权限和身份验证，因此您可以专注于构建产品，而不是配置工具。 Starter+ LDAP group sync filters GitLab企业版Premium可以更灵活地基于过滤器与LDAP同步，这意味着您可以利用LDAP属性来映射GitLab权限。 Premium+ Audit logs 为了保持代码的完整性，GitLab Enterprise Edition Premium使管理员能够在高级审计日志系统中查看GitLab服务器内的任何修改，以便您可以控制，分析和跟踪每个更改。 Premium+ Auditor users 审核员用户是对GitLab实例上的所有项目，组和其他资源具有只读访问权限的用户。 Premium+ 自定义GitLab外观Customizing GitLab’s appearance 这些外观配置请在Web UI里面进行设置： Header logo Favicon Branded login page Welcome message “New Project” page 维护GitLabMaintaining GitLab 靶任务Raketasks: Perform various tasks for maintenance, backups, automatic webhooks setup, etc. 备份Backing up and restoring GitLab 应用程序数据备份会创建一个归档文件，其中包含数据库、所有Repository和所有附件。您只能将备份恢复到与其创建的GitLab完全相同的版本和类型（CE / EE）。将Repository从一个服务器迁移到另一个服务器的最佳方法是通过备份还原。 依赖(requirements)为了实现备份和还原，需要在系统上安装两个工具。 rsync tar v1.3+ 备份时间戳(Backup timestamp) Note: In GitLab 9.2 the timestamp format was changed from EPOCH_YYYY_MM_DD to EPOCH_YYYY_MM_DD_GitLab_version 备份存档将保存在backup_path中，它在config/gitlab.yml文件中指定。文件名为[TIMESTAMP] _gitlab_backup.tar，其中TIMESTAMP标识每个备份的创建时间以及GitLab版本。如果需要还原GitLab并且有多个备份可用，则需要时间戳。 创建备份(Creating a backup of the GitLab system) GitLab提供了一个简单的命令行接口来备份整个实例。包括： Database Attachments Git repositories data CI/CD job output logs CI/CD job artifacts LFS objects Container Registry images GitLab Pages content 注意：GitLab不会备份配置文件、SSL证书、系统文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#omnibussudo gitlab-rake gitlab:backup:create#sourcesudo -u git -H bundle exec rake gitlab:backup:create RAILS_ENV=production#dockerdocker exec -t &lt;container name&gt; gitlab-rake gitlab:backup:create#k8s clusterkubectl exec -it &lt;gitlab task-runner pod&gt; backup-utility#输出栗子sudo gitlab-rake gitlab:backup:createDumping database ...Dumping PostgreSQL database gitlabhq_production ... [DONE]doneDumping repositories ... * root/zhangbin-test ... [DONE][SKIPPED] Wiki * root/test02 ... [SKIPPED][SKIPPED] WikidoneDumping uploads ...doneDumping builds ...doneDumping artifacts ...doneDumping pages ...doneDumping lfs objects ...doneDumping container registry images ...[DISABLED]Creating backup archive: 1544578010_2018_12_12_11.5.1_gitlab_backup.tar ... doneUploading backup archive to remote storage ... skippedDeleting tmp directories ... donedonedonedonedonedonedonedoneDeleting old backups ... skipping#查看sudo ls /var/opt/gitlab/backups/1544578010_2018_12_12_11.5.1_gitlab_backup.tarsudo tar -tvf backups/1544578010_2018_12_12_11.5.1_gitlab_backup.tardrwx------ git/git 0 2018-12-12 09:26 repositories/drwxr-xr-x git/git 0 2018-12-12 09:26 repositories/root/-rw-r--r-- git/git 476 2018-12-12 09:26 repositories/root/zhangbin-test.bundledrwxr-xr-x git/git 0 2018-12-12 09:26 repositories/root/zhangbin-test/drwxr-xr-x git/git 0 2018-12-12 09:26 db/-rw------- git/git 84875 2018-12-12 09:26 db/database.sql.gz-rw------- git/git 152 2018-12-12 09:26 uploads.tar.gz-rw------- git/git 151 2018-12-12 09:26 builds.tar.gz-rw------- git/git 152 2018-12-12 09:26 artifacts.tar.gz-rw------- git/git 155 2018-12-12 09:26 pages.tar.gz-rw------- git/git 152 2018-12-12 09:26 lfs.tar.gz-rw-r--r-- git/git 190 2018-12-12 09:26 backup_information.yml 保存配置文件(Storing configuration files) Omnibus /etc/gitlab/gitlab-secrets.json /etc/gitlab/gitlab.rb Source /home/git/gitlab/config/secrets.yml /home/git/gitlab/config/gitlab.yml TLS keys and certificates SSH key … 备份选项(Backup options)备份策略提供了许多可用选项。 备份策略(Backup strategy option)默认备份策略是使用Linux命令tar和gzip将数据从相应的数据位置流式传输到备份。这在大多数情况下都可以正常工作，但在数据快速变化时会导致问题。当tar读取数据时数据发生变化，读取文件会发生错误，并导致备份过程失败。为了解决这个问题，v8.17引入了一种名为copy的新备份策略。该策略在调用tar和gzip之前将数据文件复制到临时位置，以避免错误。副作用(side-effect)是备份过程中占用额外的磁盘空间，该过程尽最大努力在每个阶段清理临时文件，因此问题不会复杂化，但对于大型安装而言，这可能是一个相当大的变化。 12#使用sudo gitlab-rake gitlab:backup:create STRATEGY=copy 从备份中排出特定目录(Excluding specific directories from the backup) db (database) uploads (attachments) repositories (Git repositories data) builds (CI job output logs) artifacts (CI job artifacts) lfs (LFS objects) registry (Container Registry images) pages (Pages content) 你可以使用SKIP环境变量来跳过不需要备份的内容，使用逗号来分隔多个 12#栗子sudo gitlab-rake gitlab:backup:create SKIP=db,uploads 上传到本地挂载来共享(Uploading to locally mounted shares)你也可以使用Fog Local存储提供程序将备份发送到已挂载的共享(NFS/CIFS/SMB…)。local_root key 指向的目录在挂载时必须由git用户拥有。除local_root key 外，还必须设置backup_upload_remote_directory，这是已挂载目录中将要复制备份的子目录，如果不存在则将创建。 1234567891011121314151617181920212223242526#Omnibus#vi /etc/gitlab/gitlab.rbgitlab_rails[&apos;backup_upload_connection&apos;] = &#123; :provider =&gt; &apos;Local&apos;, :local_root =&gt; &apos;/mnt/backups&apos;&#125;# The directory inside the mounted folder to copy backups to# Use &apos;.&apos; to store them in the root directorygitlab_rails[&apos;backup_upload_remote_directory&apos;] = &apos;gitlab_backups&apos;#source#vi home/git/gitlab/config/gitlab.ymlbackup: upload: # Fog storage connection settings, see http://fog.io/storage/ . connection: provider: Local local_root: &apos;/mnt/backups&apos; # The directory inside the mounted folder to copy backups to # Use &apos;.&apos; to store them in the root directory remote_directory: &apos;gitlab_backups&apos; 备份归档权限(Backup archive permissions)GitLab创建的备份归档文件的默认所属用户和组为(git:git)，这是为了避免其它系统用户读取GitLab数据。如果你需要备份文件具有其它权限，请在配置文件中修改它： 1234567891011#Omnibus#/etc/gitlab/gitlab.rbgitlab_rails['backup_archive_permissions'] = 0644 # Makes the backup archives world-readable#source#/home/git/gitlab/config/gitlab.yml:backup: archive_permissions: 0644 # Makes the backup archives world-readable 配置定时备份(Configuring cron to make daily backups) 请注意，backup_keep_time配置选项仅管理本地文件。 GitLab不会自动清理存储在第三方对象存储（例如，AWS S3）中的旧文件，因为用户可能没有列出和删除文件的权限。建议您为对象存储配置适当的保留策略。 1234567891011121314#Omnibus#/etc/gitlab/gitlab.rb#默认保留7天## Limit backup lifetime to 7 days - 604800 secondsgitlab_rails['backup_keep_time'] = 604800#cronsudo su -crontab -e#每天2AM0 2 * * * /opt/gitlab/bin/gitlab-rake gitlab:backup:create CRON=1 恢复Restore GitLab提供了一个简单的命令行界面来恢复整个安装，并且足够灵活，可以满足您的需求。您只能将备份恢复到与其创建的GitLab完全相同的版本和类型（CE / EE）。 先决条件(prerequisites)在执行还原之前，您需要安装有效的GitLab。这主要是因为通常不允许执行恢复操作（git）的系统用户创建或删除将数据导入（gitlabhq_production）所需的SQL数据库。所有现有数据将被删除或移动到单独的目录。要恢复备份，您还需要恢复/etc/gitlab/gitlab-secrets.json（Omnibus）或 /home/git/gitlab/.secret（Source），它包含了 database encryption key, CI/CD 变量 和 two-factor authentication的变量。如果您无法将此加密密钥文件与应用程序数据备份一起恢复，则启用了双因素身份验证的用户和GitLab Runners将无法访问您的GitLab服务器。你可能还需要还原TLS keys, certificates, or SSH host keys… 根据你的情况，你可能需要使用如下选项： BACKUP=timestamp_of_backup: 如果存在多个备份，则必需 force=yes: 不询问authorized_keys文件是否应该重新生成，并假设“yes”表示将删除数据库表，启用“写入authorized_keys文件”设置，并更新LDAP提供程序。 注意: 如果要还原到作为挂载点的目录，则需要在尝试还原之前确保这些目录为空。否则GitLab将在恢复新数据之前尝试移动这些目录，这将导致错误。 还原源码安装(Source) 1234# Stop processes that are connected to the databasesudo service gitlab stopbundle exec rake gitlab:backup:restore RAILS_ENV=production 还原包安装(Omnibus) 此过程假定： 你已使用包安装相同版本的GitLab 你至少已经运行了一次sudo gitlab-ctl reconfigure GitLab已经运行 首先确保你的备份文件已经放置到了备份目录中(默认为/var/opt/gitlab/backups)，并将其所属用户和组修改为git:git。 1234567891011121314151617181920#复制备份文件sudo cp 11493107454_2018_04_25_10.6.4-ce_gitlab_backup.tar /var/opt/gitlab/backups/sudo chown git.git /var/opt/gitlab/backups/11493107454_2018_04_25_10.6.4-ce_gitlab_backup.tar#暂停程序与数据库的连接sudo gitlab-ctl stop unicornsudo gitlab-ctl stop sidekiq# Verifysudo gitlab-ctl status#还原# This command will overwrite the contents of your GitLab database!sudo gitlab-rake gitlab:backup:restore BACKUP=1493107454_2018_04_25_10.6.4-ce#重启和检查sudo gitlab-ctl restartsudo gitlab-rake gitlab:check SANITIZE=true 还原Docker对于使用Docker或可k8s安装的GitLab，还原期望还原的目录为空。然而，使用Docker和k8s volume 挂载时，可能会在Volume根下创建一些系统级的目录(如: lost+found)。这些目录通常由root拥有，可能会导致访问权限错误。因为还原操作是以git用户运行。因此，要还原GitLab，请确保还原的目标目录为空。 12#Dockerdocker exec -it &lt;name of container&gt; gitlab-rake gitlab:backup:restore 其它备份策略Alternative backup strategies 如果您的GitLab服务器包含大量Git Repository数据，您可能会发现GitLab备份脚本太慢。在这种情况下，您可以考虑使用文件系统快照作为备份策略的一部分。 LVM snapshots + rsync建立一个临时的LVM快照，将它作为只读文件系统挂载到/mnt/gitlab_backup。现在我们可以有一个更长的rsync作业，它将在远程Server创建一致的副本。 完整性检查Integrity Check 仓库完整性(Repository Integrity) 即使Git非常有弹性并试图防止数据完整性问题，但有时候仍会出现问题。以下Rake task 旨在帮助GitLab管理员诊断问题 Repo，以便修复它们。 Git repository file system check Check for config.lock in the repository directory Check for any branch/references lock files in refs/heads 以下症状可能表示Repo完整性存在问题： Receiving an error when trying to push code - remote: error: cannot lock ref A 500 error when viewing the GitLab dashboard or when accessing a specific project 检查所有GitLab Repo完整性 此任务循环遍历GitLab服务器上的所有存储库，并运行前面描述的完整性检查。 123456#Omnibussudo gitlab-rake gitlab:git:fsck#sourcesudo -u git -H bundle exec rake gitlab:git:fsck RAILS_ENV=production 上传的文件完整性(Uploaded Files Integrity) 用户可以将各种类型的文件上传到GitLab上。此外，这些完整性检查可以检测丢失的文件。对于本地存储的文件，在上传时生成校验和(checksum)并将其存储在数据库中，并且这些检查将针对当前文件验证它们。目前，支持一下类型文件的完整性检查： CI artifacts LFS objects User uploads 12345678910#Omnibussudo gitlab-rake gitlab:artifacts:checksudo gitlab-rake gitlab:lfs:checksudo gitlab-rake gitlab:uploads:check#Sourcesudo -u git -H bundle exec rake gitlab:artifacts:check RAILS_ENV=productionsudo -u git -H bundle exec rake gitlab:lfs:check RAILS_ENV=productionsudo -u git -H bundle exec rake gitlab:uploads:check RAILS_ENV=production 这些任务还接受一些环境变量，您可以使用这些变量来覆盖某些值： Variable Type Description BATCH integer Specifies the size of the batch. Defaults to 200. ID_FROM integer Specifies the ID to start from, inclusive of the value. ID_TO integer Specifies the ID value to end at, inclusive of the value. VERBOSE boolean Causes failures to be listed individually, rather than being summarized. 1234#栗子sudo gitlab-rake gitlab:artifacts:check BATCH=100 ID_FROM=50 ID_TO=250sudo gitlab-rake gitlab:lfs:check BATCH=100 ID_FROM=50 ID_TO=250sudo gitlab-rake gitlab:uploads:check BATCH=100 ID_FROM=50 ID_TO=250 LDAP检查 清理Cleanup 从文件系统移除垃圾(Remove garbage from filesystem. Important! Data loss!) 如果GitLab数据库中不存在 namespace（dirs），则从所有Repo存储路径中删除它们。 123456# omnibus-gitlabsudo gitlab-rake gitlab:cleanup:dirs# installation from sourcebundle exec rake gitlab:cleanup:dirs RAILS_ENV=production 如果GitLab数据库中不存在Repo，则从所有Repo存储路径重命名存储库。Repo获得一个+orphaned+TIMESTAMP后缀，以便他们无法阻止新Repo的创建。 123456# omnibus-gitlabsudo gitlab-rake gitlab:cleanup:repos# installation from sourcebundle exec rake gitlab:cleanup:repos RAILS_ENV=production 如果GitLab数据库中不存在本地项目上传文件，请将其清除。该任务尝试修复文件，如果它可以找到它的项目，否则它将文件移动到丢失和找到的目录。 123456# omnibus-gitlabsudo gitlab-rake gitlab:cleanup:project_uploads# installation from sourcebundle exec rake gitlab:cleanup:project_uploads RAILS_ENV=production 如果GitLab数据库中不存在对象存储上载文件，请将其删除。 123456# omnibus-gitlabsudo gitlab-rake gitlab:cleanup:remote_upload_files# installation from sourcebundle exec rake gitlab:cleanup:remote_upload_files RAILS_ENV=production 命名空间Namespaces 为用户项目启用用户名和命名空间(Enable usernames and namespaces for user projects) 此命令启动命名空间，它将移动其命名空间文件夹中的每个项目。注意： 由于Repo Location发生改变，因此你需要更新git URL以指向新地址 用户名可在Profile中修改 12345678910#栗子#Old pathgit@example.org:myrepo.git#new pathgit@example.org:username/myrepo.git#orgit@example.org:groupname/myrepo.git LDAPLDAP Rake Tasks 检查(Check) LDAP检查Rake task 将测试bind_dn和password凭据（如果已配置），并将列出LDAP用户的示例。此任务作为gitlab:check任务的一部分执行，但可以使用以下命令单独运行。 123456#Omnibushsudo gitlab-rake gitlab:ldap:check#Sourcesudo -u git -H bundle exec rake gitlab:ldap:check RAILS_ENV=production 重命名提供商(Rename a provider) 如果更改了配置文件中的LDAP Server ID，则需要更新所有用户标识，否则将无法登录。输入旧的和新的提供商，此任务将更新数据库中的所有匹配标识。 12345678#栗子#main是LDAP Server IDmain: label: 'LDAP' host: '_your_ldap_server' port: 389 uid: 'sAMAccountName' ... 123456#Omnibussudo gitlab-rake gitlab:ldap:rename_provider[old_provider,new_provider]#Sourcebundle exec rake gitlab:ldap:rename_provider[old_provider,new_provider] RAILS_ENV=production 一般维护和自检收集有关GitLab及其运行的系统的信息 123456#Omnibussudo gitlab-rake gitlab:env:info#Sourcebundle exec rake gitlab:env:info RAILS_ENV=production 检查GitLab配置 运行以下rake tasks： gitlab:gitlab_shell:check gitlab:gitaly:check gitlab:sidekiq:check gitlab:app:check 它将检查每个组件是否已根据安装指南进行设置，并针对发现的问题提出修复建议。 123456#Omnibussudo gitlab-rake gitlab:check#Sourcebundle exec rake gitlab:check RAILS_ENV=production 重建authorized_keys文件 在某些情况下，有必要重建authorized_keys文件。 1234567#Omnibussudo gitlab-rake gitlab:shell:setup#Sourcecd /home/git/gitlabsudo -u git -H bundle exec rake gitlab:shell:setup RAILS_ENV=production 清理Redis缓存 如果由于某种原因，仪表板显示错误信息，您可能希望清除Redis的缓存。 1234567#Omnibussudo gitlab-rake cache:clear#Sourcecd /home/git/gitlabsudo -u git -H bundle exec rake cache:clear RAILS_ENV=production 跟踪部署(Tracking Deployments) GitLab提供了一个Rake task，可以让您跟踪GitLab性能监控中的部署。 1234567#Omnibussudo gitlab-rake gitlab:track_deployment#Sourcecd /home/git/gitlabsudo -u git -H bundle exec rake gitlab:track_deployment RAILS_ENV=production 创建或修复Repo hook符号链接(Create or repair repository hooks symlink) 如果GitLab shell hooks 目录位置更改或其他情况导致hooks符号链接丢失或无效，请运行此Rake task以创建或修复符号链接。 1234567#Omnibussudo gitlab-rake gitlab:shell:create_hooks#Sourcecd /home/git/gitlabsudo -u git -H bundle exec rake gitlab:shell:create_hooks RAILS_ENV=production 检查TCP连接(Check TCP connectivity to a remote site) 1234567#Omnibussudo gitlab-rake gitlab:tcp_check[example.com,80]#Sourcecd /home/git/gitlabsudo -u git -H bundle exec rake gitlab:tcp_check[example.com,80] RAILS_ENV=production 用户管理User management 将用户作为开发人员添加到所有项目中 12345# omnibus-gitlabsudo gitlab-rake gitlab:import:user_to_projects[username@domain.tld]# installation from sourcebundle exec rake gitlab:import:user_to_projects[username@domain.tld] RAILS_ENV=production 将所有用户添加到所有项目 12345# omnibus-gitlabsudo gitlab-rake gitlab:import:all_users_to_all_projects# installation from sourcebundle exec rake gitlab:import:all_users_to_all_projects RAILS_ENV=production 将用户作为开发人员添加到所有组 12345# omnibus-gitlabsudo gitlab-rake gitlab:import:user_to_groups[username@domain.tld]# installation from sourcebundle exec rake gitlab:import:user_to_groups[username@domain.tld] RAILS_ENV=production 将所有用户添加到所有组 12345# omnibus-gitlabsudo gitlab-rake gitlab:import:all_users_to_all_groups# installation from sourcebundle exec rake gitlab:import:all_users_to_all_groups RAILS_ENV=production 保持对GitLab上活跃用户数量的严格控制 12#启用此设置可以阻止新用户被管理员清除(默认：false)block_auto_created_users: false 禁用所有用户的双重验证（2FA） 123456# omnibus-gitlabsudo gitlab-rake gitlab:two_factor:disable_for_all_users# installation from sourcebundle exec rake gitlab:two_factor:disable_for_all_users RAILS_ENV=production 轮询双重认证的加密秘钥(Rotate Two-factor Authentication (2FA) encryption key) GitLab存储secret data，使双重认证(2FA)能够在加密的数据库列中工作。此数据的加密密钥称为otp_key_base，存储在config/secrets.yml中。如果该文件被泄露，但个别2FA secret 没有泄露，则可以使用新的加密密钥重新加密这些机密。这允许您更改泄漏的密钥，而不强制所有用户更改其2FA详细信息。 首先，查找old key。这是在config/secrets.yml文件中，但请确保您正在使用生产部分： 12production: otp_key_base: ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff 生成new secret 12345# omnibus-gitlabsudo gitlab-rake secret# installation from sourcebundle exec rake secret RAILS_ENV=production 现在您需要停止GitLab服务器，备份现有的secrets file并更新数据库： 12345678910# omnibus-gitlabsudo gitlab-ctl stopsudo cp config/secrets.yml config/secrets.yml.baksudo gitlab-rake gitlab:two_factor:rotate_key:apply filename=backup.csv old_key=&lt;old key&gt; new_key=&lt;new key&gt;# installation from sourcesudo /etc/init.d/gitlab stopcp config/secrets.yml config/secrets.yml.bakbundle exec rake gitlab:two_factor:rotate_key:apply filename=backup.csv old_key=&lt;old key&gt; new_key=&lt;new key&gt; RAILS_ENV=production 最后，将config/secrets.yml中的otp_key_base更改为&lt;new key&gt;并重新启动。再次，确保您在生产部分中运行： 12345678910#首先更改key#之后重启# omnibus-gitlabsudo gitlab-ctl start# installation from sourcesudo /etc/init.d/gitlab start 如果出现问题，你也可以进行回滚。 Webhooks为所有项目添加webhook 123456# omnibus-gitlabsudo gitlab-rake gitlab:web_hook:add URL="http://example.com/hook"# source installationsbundle exec rake gitlab:web_hook:add URL="http://example.com/hook" RAILS_ENV=production 为给定NAMESPACE中的项目添加webhook 123456# omnibus-gitlabsudo gitlab-rake gitlab:web_hook:add URL="http://example.com/hook" NAMESPACE=acme# source installationsbundle exec rake gitlab:web_hook:add URL="http://example.com/hook" NAMESPACE=acme RAILS_ENV=production 从所有项目中删除webhook 123456# omnibus-gitlabsudo gitlab-rake gitlab:web_hook:rm URL="http://example.com/hook"# source installationsbundle exec rake gitlab:web_hook:rm URL="http://example.com/hook" RAILS_ENV=production 从给定NAMESPACE中的项目中删除webhook： 123456# omnibus-gitlabsudo gitlab-rake gitlab:web_hook:rm URL="http://example.com/hook" NAMESPACE=acme# source installationsbundle exec rake gitlab:web_hook:rm URL="http://example.com/hook" NAMESPACE=acme RAILS_ENV=production 列出所有webhooks： 123456# omnibus-gitlabsudo gitlab-rake gitlab:web_hook:list# source installationsbundle exec rake gitlab:web_hook:list RAILS_ENV=production 列出给定NAMESPACE中项目的webhooks 1234# omnibus-gitlabsudo gitlab-rake gitlab:web_hook:list NAMESPACE=acme# source installationsbundle exec rake gitlab:web_hook:list NAMESPACE=acme RAILS_ENV=production 批量导入git库Import of git repositories in bulk 注意： The owner of the project will be the first admin The groups will be created as needed, including subgroups The owner of the group will be the first admin Existing projects will be skipped Projects in hashed storage may be skipped The existing Git repos will be moved from disk 如何使用： 创建一个新文件夹以从中导入您的Git Repo： 12#注意owner, group, permissionsudo -u git mkdir /var/opt/gitlab/git-data/repository-import-&lt;date&gt;/new_group 将Repo复制到新创建的文件夹中在任何子文件夹中找到的任何.git Repo 都将作为项目导入。将根据需要创建group 12345sudo cp -r /old/git/foo.git /var/opt/gitlab/git-data/repository-import-&lt;date&gt;/new_group/# Do this once when you are done copying git repositoriessudo chown -R git:git /var/opt/gitlab/git-data/repository-import-&lt;date&gt; 运行命令 1234567#Omnibussudo gitlab-rake gitlab:import:repos['/var/opt/gitlab/git-data/repository-import-&lt;date&gt;']#Sourcecd /home/git/gitlabsudo -u git -H bundle exec rake gitlab:import:repos['/var/opt/gitlab/git-data/repository-import-&lt;date&gt;'] RAILS_ENV=production 从hashed storage导入Repo 背景： 传统存储中的项目具有一个目录结构，该结构反映了GitLab中的完整项目路径，包括其命名空间结构。Repo导入程序利用此信息将项目导入其适当的位置。每个项目及其父命名空间都有名称。但是，散列存储中的项目的目录结构不包含此信息。这有利于各种原因，尤其是改进的性能和数据完整性。 GitLab v10.3 or earlier: 不支持导入hashed storage GitLab v10.4 and later: 为了支持从散列存储导入裸存储库，GitLab将每个存储库的完整项目路径存储在git Repo 配置文件的特殊部分中。 如果Repo发生以下事件，则可导入： Created Migrated to hashed storage Renamed Transferred to another namespace Ancestor renamed Ancestor transferred to another namespace 满足以下内容，Repo无法导入： It was created in GitLab 10.3 or earlier. It was not renamed, transferred, or migrated to hashed storage in GitLab 10.4 and later. Its ancestor namespaces were not renamed or transferred in GitLab 10.4 and later. 你也可以手动使用 Rails console 执行此操作： 1234567891011# start a Rails console for GitLabsudo gitlab-rails consoleproject = Project.find_by_full_path(&apos;gitlab-org/gitlab-ce&apos;)project.write_repository_config#在Rails控制台会话中，运行以下命令以迁移所有命名空间的项目namespace = Namespace.find_by_full_path(&apos;gitlab-org&apos;)namespace.send(:write_projects_repository_config) 上传Uploads 注意： 上传表示可以作为单个文件(single file)发送到GitLab的所有用户数据。例如，头像和附注的附件是上传的。上传是GitLab功能的组成部分，因此无法禁用。 使用本地存储(Local Storage)这是默认选项。 12345678910111213141516171819202122#Omnibus#上传默认存放位置： /var/opt/gitlab/gitlab-rails/uploads/-/system#修改vi /etc/gitlab/gitlab.rbgitlab_rails['uploads_storage_path'] = "/mnt/storage/"gitlab_rails['uploads_base_dir'] = "uploads"#Source#默认存放位置：/home/git/gitlab/public/uploads/-/system#修改vi /home/git/gitlab/config/gitlab.ymluploads: storage_path: /mnt/storage base_dir: uploads 使用对象存储(Object Storage) 如果不想使用本地存储，可使用对象存储(华为云、阿里云、腾讯云、aws…)。GitLab有几个选项，其它云服务商的配置请参考他们的文档。 uploads_object_store_ Description Default enabled Enable/disable object storage false remote_directory The bucket name where Uploads will be stored direct_upload Set to true to enable direct upload of Uploads without the need of local shared storage. Option may be removed once we decide to support only single storage for all files. false background_upload Set to false to disable automatic upload. Option may be removed once upload is direct to S3 true proxy_download Set to true to enable proxying all files served. Option allows to reduce egress traffic as this allows clients to download directly from remote storage instead of proxying all data false connection Various connection options described below 迁移上传文件Migrate Uploads 迁移到对象存储(Migrate to Object Storage) 为GitLab的上传配置对象存储之后，您可以使用此任务将现有的上传文件从本地存储迁移到远程存储。 All-in-one rake taskGitLab提供了一个 wrapper rake task，可以将所有上传的文件（头像，徽标，附件，图标等）一次性迁移到对象存储。在此之下，它会调用各个rake task来逐个迁移属于这个类别的文件。 123456#Omnibusgitlab-rake "gitlab:uploads:migrate:all"#Sourcesudo RAILS_ENV=production -u git -H bundle exec rake gitlab:uploads:migrate:all Individual rake tasks如果您已经运行了前面提到的rake task，则无需像自动完成那样运行这些单独的rake task。 rake task使用3个参数来查找要迁移的上传： Parameter Type Description uploader_class string Type of the uploader to migrate from model_class string Type of the model to migrate from mount_point string/symbol Name of the model’s column on which the uploader is mounted on. 注意：这些参数主要是GitLab结构的内部参数，您可能需要在下面引用任务列表。此任务还接受一些可用于覆盖某些值的环境变量： Variable Type Description BATCH integer Specifies the size of the batch. Defaults to 200. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#Omnibus# gitlab-rake gitlab:uploads:migrate[uploader_class, model_class, mount_point]# Avatarsgitlab-rake "gitlab:uploads:migrate[AvatarUploader, Project, :avatar]"gitlab-rake "gitlab:uploads:migrate[AvatarUploader, Group, :avatar]"gitlab-rake "gitlab:uploads:migrate[AvatarUploader, User, :avatar]"# Attachmentsgitlab-rake "gitlab:uploads:migrate[AttachmentUploader, Note, :attachment]"gitlab-rake "gitlab:uploads:migrate[AttachmentUploader, Appearance, :logo]"gitlab-rake "gitlab:uploads:migrate[AttachmentUploader, Appearance, :header_logo]"# Favicongitlab-rake "gitlab:uploads:migrate[FaviconUploader, Appearance, :favicon]"# Markdowngitlab-rake "gitlab:uploads:migrate[FileUploader, Project]"gitlab-rake "gitlab:uploads:migrate[PersonalFileUploader, Snippet]"gitlab-rake "gitlab:uploads:migrate[NamespaceFileUploader, Snippet]"gitlab-rake "gitlab:uploads:migrate[FileUploader, MergeRequest]"#Source#Use RAILS_ENV=production for every task.# sudo -u git -H bundle exec rake gitlab:uploads:migrate# Avatarssudo -u git -H bundle exec rake "gitlab:uploads:migrate[AvatarUploader, Project, :avatar]"sudo -u git -H bundle exec rake "gitlab:uploads:migrate[AvatarUploader, Group, :avatar]"sudo -u git -H bundle exec rake "gitlab:uploads:migrate[AvatarUploader, User, :avatar]"# Attachmentssudo -u git -H bundle exec rake "gitlab:uploads:migrate[AttachmentUploader, Note, :attachment]"sudo -u git -H bundle exec rake "gitlab:uploads:migrate[AttachmentUploader, Appearance, :logo]"sudo -u git -H bundle exec rake "gitlab:uploads:migrate[AttachmentUploader, Appearance, :header_logo]"# Faviconsudo -u git -H bundle exec rake "gitlab:uploads:migrate[FaviconUploader, Appearance, :favicon]"# Markdownsudo -u git -H bundle exec rake "gitlab:uploads:migrate[FileUploader, Project]"sudo -u git -H bundle exec rake "gitlab:uploads:migrate[PersonalFileUploader, Snippet]"sudo -u git -H bundle exec rake "gitlab:uploads:migrate[NamespaceFileUploader, Snippet]"sudo -u git -H bundle exec rake "gitlab:uploads:migrate[FileUploader, MergeRequest]" 操作Performing Operations in GitLabOperations: Keeping GitLab up and running (clean up Redis sessions, moving repositories, Sidekiq MemoryKiller, Unicorn) 清理陈旧的Redis回话Cleaning up stale Redis sessions 在GitLab v7.3之前，用户会话不会自动从Redis expire。 移动库Moving repositories 将GitLab管理的所有库移动到另一个文件系统或另一个服务器。 Sidekiq MemoryKiller配置Sidekiq MemoryKiller以重启Sidekiq。 GitLab Rails应用程序代码有内存泄漏。对于Web请求，使用unicorn-worker-killer可以管理这个问题，在需要时会在请求之间重新启动Unicorn工作进程。 Sidekiq MemoryKiller对GitLab用于处理后台作业的Sidekiq进程应用相同的方法。 与自从GitLab 6.4以来默认启用的所有GitLab安装的unicorn-worker-killer不同，Sidekiq MemoryKiller默认仅对Omnibus软件包启用。原因是MemoryKiller依赖于Runit在内存引发的关闭后重新启动Sidekiq，并且来自源的GitLab安装并不都使用Runit或等效的。 使用默认设置，MemoryKiller将导致Sidekiq重启频率不超过每15分钟一次，重启会导致传入后台作业延迟大约一分钟。 配置MemoryKillerMemoryKiller使用环境变量进行控制。 SIDEKIQ_MEMORY_KILLER_MAX_RSS如果设置了此变量，并且其值大于0，则在每个Sidekiq作业之后，MemoryKiller将检查执行该作业的Sidekiq进程的RSS。如果Sidekiq进程的RSS（KB）超过SIDEKIQ_MEMORY_KILLER_MAX_RSS，则会触发延迟关闭。默认值可在gitlab.rb当中查看。 SIDEKIQ_MEMORY_KILLER_GRACE_TIME默认为900s（15min）。当触发关闭时，Sidekiq进程将继续正常工作15分钟。 SIDEKIQ_MEMORY_KILLER_SHUTDOWN_WAIT默认为30秒。当宽限时间到期时，MemoryKiller告诉Sidekiq停止接受新的工作，现有工作有30s去完成。之后，MemoryKiller告诉Sidekiq去关闭，外部监督机制必须重启Sidekiq UnicornUnderstand Unicorn and unicorn-worker-killer UnicornGitLab使用Unicorn，一个pre-forking的Ruby Web服务器来处理Web请求。Unicorn是一个用Ruby和C编写的Daemon，可以加载和运行Ruby on Rails Application(如GitLab CE/EE)。 Unicorn具有多进程(multi-process)架构，可以更好地利用可用的CPU核心并具有更强的容错能力。在启动时，Unicorn的Master进程使用GitLab应用程序代码加载一个干净的Ruby环境，然后生成继承这个干净的初始环境的Worker。 Master永远不会处理任何请求，而是留给Worker。操作系统网络堆栈对传入的请求进行排队，并在Worker之间分配它们。 Unicorn的主要可调参数(Tunables)是工作进程(work process)的数量和请求超时(request timeout)。 unicorn-worker-killer GitLab存在内存泄漏。这些内存泄漏在长期运行的进程中表现出来，如Unicorn worker。为了使这些内存泄漏易于管理，GitLab附带了unicorn-worker-killer。这个gem修补了Unicorn工作人员在每16个请求后进行内存自检。如果Unicorn工作程序的内存超过预设限制，则工作进程退出。然后Unicorn Master自动替换Wroker。这是一种处理内存泄漏的强大方法：Unicorn旨在处理“崩溃”的Worker，因此不会丢弃任何用户请求。unicorn-worker-killer gem旨在仅在请求之间终止工作进程，因此不会影响用户请求。 加快SSH操作Speed up SSH operations by Authorizing SSH users via a fast, indexed lookup to the GitLab database, and/or by doing away with user SSH keys stored on GitLab entirely in favor of SSH certificates. 快速查找数据库中的授权SSH密钥(Fast lookup of authorized SSH keys in the database) https://docs.gitlab.com/ce/administration/operations/fast_ssh_key_lookup.html 通过Open SSH查找(User lookup via OpenSSH’s AuthorizedPrincipalsCommand) https://docs.gitlab.com/ce/administration/operations/ssh_certificates.html 文件系统性能基准测试Filesystem Performance Benchmarking 文件系统性能对整体GitLab性能有很大影响，特别是对于读取或写入Git Repo的操作。 写性能(Write Performance) 1234567891011121314#进入Repo root pathcd /var/opt/gitlab/git-data/repositories/test/#创建一个空目录，便于测试后删除mkdir test &amp;&amp; cd test#运行命令time for i in &#123;0..1000&#125;; do echo 'test' &gt; "test$&#123;i&#125;.txt"; done#删除测试目录cd .. &amp;&amp; rm -rf ./test 以下是消耗时间范围： Rating Benchmark result Best Less than 10 seconds OK 10-18 seconds Poor 18-25 seconds Very poor Greater than 25 seconds 重启Restart GitLab: Learn how to restart GitLab and its components 依据安装方式，有几种不同的方式： Omnibus GitLab restartGitLab Workhorse Sidekiq PostgreSQL (if you are using the bundled one) NGINX (if you are using the bundled one) Redis (if you are using the bundled one) Mailroom Logrotate Omnibus GitLab reconfigure Source installation restart 12345678910111213141516171819202122#Omnibus GitLab restart#GitLabsudo gitlab-ctl restart#Nginx组件sudo gitlab-ctl restart nginx#其它组件类似#GitLab Statussudo gitlab-ctl status#Nginx组件状态sudo gitlab-ctl status nginx#其它组件类似#有时，组件在重新启动期间会超时，有时会卡住#你可以发送kill信号gitlab-ctl kill &lt;service&gt; 12345#Omnibus GitLab reconfigure#在更改/etc/gitlab/gitlab.rb之后，需要重新配置GitLabsudo gitlab-ctl reconfigure 1234#Installations from sourcesudo service gitlab restart 更新Updating GitLab GitLab版本和维护策略GitLab versions and maintenance policy: Understand GitLab versions and releases (Major, Minor, Patch, Security), as well as update recommendations. GitLab releases: Major version: 主要版本，重要内容 Minor verson: 次要版本，小功能 Patch number: 补丁，fix bug Security: 安全，临时添加的安全补丁 123456#栗子GitLab v10.5.7#10 represents major version#5 represents minor version#7 represents patch number 升级建议: GitLab鼓励每个人运行最新的稳定版本(latest stable release)，以确保您可以轻松升级到最安全，功能最丰富的GitLab体验。如果您无法遵循GitLab的月度发布周期，则需要考虑几种情况： 在一个主要版本(Major)中升级补丁版本(Patch)和次要版本(Minor)被认为是安全的。 12345678#Upgrade the patch version:8.9.0 -&gt; 8.9.78.9.0 -&gt; 8.9.1#Upgrade the minor version:8.9.4 -&gt; 8.12.39.2.3 -&gt; 9.5.5 升级主要版本需要多加小心。GitLab无法保证主要版本之间的升级是无缝的。GitLab建议您首先升级到主要版本中的最新可用次要版本。通过执行此操作，您可以解决可能会在下一个主要版本中更改行为的任何弃用消息。 Latest stable version Your version Recommended upgrade path Note 9.4.5 8.13.4 8.13.4 -&gt; 8.17.7 -&gt; 9.4.5 8.17.7 is the last version in version 8 10.1.4 8.13.4 8.13.4 -&gt; 8.17.7 -&gt; 9.5.10 -&gt; 10.1.4 8.17.7 is the last version in version 8, 9.5.10 is the last version in version 9 11.3.4 8.13.4 8.13.4 -&gt; 8.17.7 -&gt; 9.5.10 -&gt; 10.8.7 -&gt; 11.3.4 8.17.7 is the last version in version 8, 9.5.10 is the last version in version 9, 10.8.7 is the last version in version 10 更新GitLabUpdate GitLab: Update guides to upgrade your installation to a new version. 根据安装方式与GitLab版本，有多种升级方法： Omnibus packages Source installation Docker installation 使用软件包的方式进行更新Updating GitLab installed with the Omnibus GitLab package 特定版本: GitLab 11 GitLab 10 GitLab 8 GitLab 7 GitLab 6 升级方法: 使用官方Repo 手动下载Package 零停机更新(Zero downtime updates) 注意：这仅适用于GitLab 9.1.0或更高版本。 地址: https://docs.gitlab.com/omnibus/update/README.html#zero-downtime-updates 降级(Downgrading): 注意：本指南假定您在要还原的版本下创建了备份存档。 步骤： Download the package of a target version Stop GitLab Install the old package Reconfigure GitLab Restoring the backup Starting GitLab 其它项的更新 MySQL to PostgreSQL PostgreSQL to MySQL 更新失败之后从备份文件进行还原 CE-EEUpgrading or downgrading GitLab Upgrade from GitLab CE to GitLab EE Downgrade from GitLab EE to GitLab CE 平台集成GitLab platform integrations 集成MattermostMattermost是一个开源，可托管的聊天服务。它被设计为组织和公司的内部聊天，并且主要将自己作为Slack的替代品。 https://docs.gitlab.com/omnibus/gitlab-mattermost/ 集成PlantUMLPlantUML是一个开源工具，允许用户使用纯文本语言创建UML图表。 https://docs.gitlab.com/ce/administration/integration/plantuml.html 集成Web终端从GitLab的CI/CD环境中提供对部署到Kubernetes的应用程序的终端访问。随着Kubernetes集成的引入，GitLab获得了为Kubernetes集群存储和使用凭证的能力。它使用这些凭据的一个原因是提供对环境的Web终端的访问。 Web终端的体系结构及其工作原理： GitLab依靠用户提供他们自己的Kubernetes凭据，并在部署时适当地标记他们创建的pod。 当用户到环境的终端页面时，它们将被提供一个JavaScript应用程序，该应用程序将WebSocket连接返回给GitLab。 WebSocket在Workhorse中处理，而不是Rails Application Server。 Workhorse查询Rails的连接细节和用户权限; Rails使用Sidekiq在后台查询Kubernetes Workhorse充当用户浏览器和Kubernetes API之间的代理服务器，在两者之间传递WebSocket frame Workhorse定期轮询Rails，如果用户不再具有访问终端的权限，或者连接详细信息已更改，则终止WebSocket连接。 ps: WebSocket是一种在单个TCP连接上进行全双工通信的协议。 启用/禁用终端支持(Enabling and disabling terminal support) 当Web终端使用WebSockets时，Workhorse前面的每个HTTP/HTTPS反向代理都需要配置为将Connection和Upgrade头传递给链中的下一个，在GitLab v8.15+，这是默认选项，不需要你配置。 但是，如果在GitLab前面运行负载均衡器，则可能需要对配置进行一些更改: Apache NGINX HAProxy Varnish Workhorse不会让WebSocket请求通过non-WebSocket端点，因此可以安全地在全局范围内启用对这些Header的支持。如果您宁愿使用较窄的规则集，则可以将其限制为以/terminal.ws结尾的URL。 如果您想在GitLab中禁用Web终端支持，只需停止在链中的第一个HTTP反向代理中传递Connection和Upgrade逐跳Header。对于大多数用户来说，这将是与Omnibus GitLab捆绑在一起的NGINX服务器： 123456#在gitLab.rb中找到 nginx[&apos;proxy_set_headers&apos;]#移除或注释 Connection和Upgrade# nginx[&apos;proxy_set_headers&apos;] = &#123;# &quot;Upgrade&quot; =&gt; &quot;$http_upgrade&quot;,# &quot;Connection&quot; =&gt; &quot;$connection_upgrade&quot; 限制Websocket连接时间(Limiting WebSocket connection time) ps: GitLab v8.17+ 终端会话使用长期连接。默认情况下，这些可能永远持续下去。如果从可伸缩性或安全性角度发现这是不受欢迎的，您可以在GitLab实例的Admin区域中配置最长会话时间。 用户设置和权限User settings and permissions LibravatarUse Libravatar instead of Gravatar for user avatars. https://docs.gitlab.com/ce/customization/libravatar.html 注册限制Sign-up restrictions: block email addresses of specific domains, or whitelist only specific domains. 您可以通过管理区域中的“应用程序设置”阻止特定域的电子邮件地址，或仅将某些特定域列入白名单。 Whitelist email domains Blacklist email domains 白名单和黑名单支持通配符。如可对白名单加自己信任的域(如：company.com)，再把所有加入黑名单(如： *) 访问限制Access restrictions: Define which Git access protocols can be used to talk to GitLab (SSH, HTTP, HTTPS). 启用Git访问协议 SSH 和 HTTP(s) 仅SSH 仅HTTP(s) 认证和授权Authentication/Authorization: Enforce 2FA, configure external authentication with LDAP, SAML, CAS and additional Omniauth providers. https://docs.gitlab.com/ce/topics/authentication/index.html 传入电子邮件Incoming email: Configure incoming emails to allow users to reply by email, create issues by email and merge requests by email, and to enable. GitLab有几个基于接收传入电子邮件的功能： Reply by Email: 允许GitLab用户通过回复notification电子邮件对issues发表comment并merge request New issue by email: 允许GitLab用户通过向用户特定的电子邮件地址发送电子邮件来创建新Issue New merge request by email: 允许GitLab用户通过向用户特定的电子邮件地址发送电子邮件来创建新的 merge request 依赖(Requirements)： Email sub-addressing Dedicated email address Catch-all mailbox 配置： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#Omnibus#在gitlab.rb中找到incoming_email，启用该功能并填写IMAP信息和账户信息### Reply by email###! Allow users to comment on issues and merge requests by replying to###! notification emails.###! Docs: https://docs.gitlab.com/ce/administration/reply_by_email.html# gitlab_rails['incoming_email_enabled'] = true#### Incoming Email Address####! The email address including the `%&#123;key&#125;` placeholder that will be replaced####! to reference the item being replied to.####! **The placeholder can be omitted but if present, it must appear in the####! "user" part of the address (before the `@`).**# gitlab_rails['incoming_email_address'] = "gitlab-incoming+%&#123;key&#125;@gmail.com"#### Email account username####! **With third party providers, this is usually the full email address.**####! **With self-hosted email servers, this is usually the user part of the####! email address.**# gitlab_rails['incoming_email_email'] = "gitlab-incoming@gmail.com"#### Email account password# gitlab_rails['incoming_email_password'] = "[REDACTED]"#### IMAP Settings# gitlab_rails['incoming_email_host'] = "imap.gmail.com"# gitlab_rails['incoming_email_port'] = 993# gitlab_rails['incoming_email_ssl'] = true# gitlab_rails['incoming_email_start_tls'] = false#### Incoming Mailbox Settings####! The mailbox where incoming mail will end up. Usually "inbox".# gitlab_rails['incoming_email_mailbox_name'] = "inbox"####! The IDLE command timeout.# gitlab_rails['incoming_email_idle_timeout'] = 60#重载配置和重启sudo gitlab-ctl reconfiguresudo gitlab-ctl restart#验证邮箱配置sudo gitlab-rake gitlab:incoming_email:check 项目设置Project settings Repo检查Repository checks: Periodic Git repository checks. 在GitLab 8.7中引入。它默认关闭，因为它仍会导致过多的误报。 Git有一个内置机制git fsck，用于验证提交到存储库的所有数据的完整性。GitLab管理员可以通过管理面板下的项目页面触发对项目的检查。检查以异步方式运行，因此可能需要几分钟才能在项目管理页面上显示检查结果。如果检查失败，您可以在repocheck.log下的管理日志页面上看到它们的输出。 定期检查(Periodic checks) 启用后，GitLab会定期对所有项目存储库和wiki存储库运行存储库检查，以检测数据损坏。一个项目每月检查不超过一次。如果任何项目未通过其存储库检查，则所有GitLab管理员都将收到有关该情况的电子邮件通知。\ 禁用 可在管理员面板上禁用定期检查。 检查失败 如果某个存储库检查失败，你应该在repocheck.log查找错误信息: 管理员面板 磁盘日志文件 /var/log/gitlab/gitlab-rails for Omnibus installations /home/git/gitlab/log for installations from source 如果由于某种原因定期检查导致大量错误警报，您可以在管理员设置里来选择清除所有存储库检查状态。 Repo存储路径Repository storage paths: Manage the paths used to store repositories. GitLab允许您定义多个存储库存储路径，以在多个挂载点之间分配存储负载。 注意: 您必须至少有一个名为default的存储路径 路径以键值对进行定义 目标目录及其任何子路径都不能是符号链接 目标目录不能是制定路径的子目录，因为不能嵌套 123456789101112#栗子default: path: /mnt/git-storage-1storage2: path: /mnt/git-storage-2#错误栗子default: path: /mnt/git-storage-1storage2: path: /mnt/git-storage-1/git-storage-2 # &lt;- NOT OK because of nesting 配置GitLab 注意:为了使备份正常工作，存储路径不能是挂载点，GitLab用户应具有路径父目录的正确权限。在Omnibus GitLab中，这是自动处理的，但对于Source Code安装，您应该格外小心。 12345678910gitlab.rbgit_data_dirs(&#123; &quot;default&quot; =&gt; &#123; &quot;path&quot; =&gt; &quot;/var/opt/gitlab/git-data&quot; &#125;, &quot;nfs&quot; =&gt; &#123; &quot;path&quot; =&gt; &quot;/mnt/nfs/git-data&quot; &#125;, &quot;cephfs&quot; =&gt; &#123; &quot;path&quot; =&gt; &quot;/mnt/cephfs/git-data&quot; &#125;&#125;)#Omnibus将存储库数据存储在git-data/repositories子目录下 选择新项目存储库的存储位置设置了多个存储路径后，可在Admin下Application Setting选择新项目的存储路径。从GitLab 8.13.4开始，可以选择多个路径。新项目将随机放置在其中一个选定路径上。 Repo存储靶任务Repository storage rake tasks: A collection of rake tasks to list and migrate existing projects and attachments associated with it from Legacy storage to Hashed storage 以下靶任务(rake task)，可用于帮助您列出现有项目以及与之关联的附件，从旧存储到新的Hashed存储类型。 将现有项目迁移到哈希存储Migrate existing projects to Hashed storage 在迁移现有项目之前，还应为新项目启用哈希/散列存储。 1234567#Omnibussudo gitlab-rake gitlab:storage:migrate_to_hashed# to migrate any non migrated project from ID 20 to 50.export ID_FROM=20 export ID_TO=50 你可在Admin &gt; Monitoring &gt; Background jobs里面进行查看。 在它达到零之后，您可以通过运行以下命令来确认已迁移每个项目。如果您认为有必要，可以再次运行此迁移脚本以安排缺少的项目。 列出旧版存储的项目List projects on Legacy storage 12345678#获取旧项目存储摘要#Ominibussudo gitlab-rake gitlab:storage:legacy_projects#列出项目使用的旧存储#Ominibussudo gitlab-rake gitlab:storage:list_legacy_projects 列出哈希散列上的项目List projects on Hashed storage 12345678#使用哈希存储的项目的简单摘要#Ominibussudo gitlab-rake gitlab:storage:hashed_projects#列出项目使用的散列存储#Ominibussudo gitlab-rake gitlab:storage:list_hashed_projects 列出旧版存储上的附件List attachments on Legacy storage 12345678#使用旧版存储的附件的简单摘要#Ominibussudo gitlab-rake gitlab:storage:legacy_attachments#列出使用旧版存储的项目附件#Ominibussudo gitlab-rake gitlab:storage:list_legacy_attachments 列出哈希存储上的附件List attachments on Hashed storage 12345678#使用哈希存储的附件的简单摘要#Ominibussudo gitlab-rake gitlab:storage:hashed_attachments#列出使用哈希存储的项目附件#Ominibussudo gitlab-rake gitlab:storage:list_hashed_attachments 限制Repo大小Limit repository size: Set a hard limit for your repositories’ size Introduced in GitLab Enterprise Edition 8.12. GitLab实例中的存储库可能会快速增长，尤其是在使用LFS时。它们的大小可以指数级增长，并且可以非常快速地耗尽您的存储设备。为了避免这种情况发生，您可以为存储库的大小设置硬限制。可以全局，按组或按项目设置此限制，每个项目限制具有最高优先级。 只有GitLab管理员才能设置这些限制。将限制设置为0表示没有限制。 到目前为止，无法检查新项目的第一次推送的大小，因此第一次推送将允许您上传超过限制规定，但每次后续推送都将被拒绝。但是，LFS对象可以在第一次推送时检查，如果它们的大小总和超过允许的最大存储库大小，则会被拒绝。 CIGitLab CI/CD Continuous Integration settings Auto DevOps GitLab Auto DevOps: Auto Build Auto Test Auto Code Quality (GitLab Ultimate) Auto SAST (Static Application Security Testing) (GitLab Ultimate) Auto Dependency Scanning (GitLab Ultimate) Auto License Management (GitLab Ultimate) Auto Container Scanning Auto Review Apps Auto DAST (Dynamic Application Security Testing) (GitLab Ultimate) Auto Deploy Auto Browser Performance Testing (GitLab Ultimate) Auto Monitoring MR规范 一些注意事项： 分支情况 生产环境: master 测试环境: test 代码分支: dev 其它分支 分支master, test, dev受到保护 可以根据需要添加受保护的分支 Protected Branch Allowed to MR Allowed to push master Maintainer None test Developer+Maintainer None dev Developer+Maintainer None 合并请求 合并请求有权限控制 开发者发起MR请求时，即触发对MR源分支的相关检测 MR受理者根据检测结果决定是否进行分支合并 运维通过调用检测结果，将分析结果发送给相应的开发人员 MR时请注意是否修改到了CICD相关文件 任何触发的Pipeline，都可以人工终止和重做 构建时，构建过程(STAT, 编译，打包，部署，UT…)可以手动选择关闭，各个过程强依赖 可以接受从任何源分支到任何目的分支的合并请求 CICD相关文件 GitLab根据.gitlab-ci.yml文件触发相应的动作 将CICD所需文件放于cicd目录下 开发者请勿修改CICD相关文件 12345678910111213141516# CICD需要的文件cicdFile: .gitlab-ci.ymlDockerFile: - Dockerfile-test - Dockerfile-prodk8sFile: - k8s-xxx-test.yaml - k8s-xxx-prod.yaml# 一些忽略文件ignoreFile: - .gitignore - .dockerignore 打包构建 Maven使用云端私有仓库，确保开发环境与Runner的统一 Maven公共基础包可配置为阿里云、华为云仓库等 Node版本会影响项目的运行，所以Node基础镜像的版本与开发者本地保持一致 Docker镜像使用git commit id作为tag k8s yaml配置文件中的镜像tag使用TTTAAAGGG这个唯一字符，在CD时替换成对应的镜像tag k8s yaml文件只应用工作负载(Deployment)，不应用服务(Service)。由于服务基本上不用更改，所以关联的服务一律在容器服务界面上配置 检测 开发者发起MR请求时，即触发对MR源分支的相关检测 运维通过调用检测结果，将分析结果发送给相应的开发人员 dev分支将定时触发Pipeline，并将检查结果发送给相应的开发人员，开发人员可登录Web UI进行查看 持续集成/发布(CI/CD)包含哪些内容 代码检测(STAT) 单元测试(UT) 项目打包(Maven, Node, Go…) Docker构建(build, push) K8s集群 自动化测试(Testing) 启用/禁用CICDEnable/disable GitLab CI/CD: Enable or disable GitLab CI/CD for your instance. 您可以在站点范围内禁用GitLab CI/CD，方法是修改配置文件。 有两点需要注意： 禁用GitLab CI/CD只会影响新创建的项目。在此修改之前启用它的项目将像以前一样工作 即使禁用了GitLab CI/CD，用户仍然可以在项目设置中启用它 123456789101112131415161718192021#Sourcevim gitlab.yml## Default project features settings, set build to falsedefault_projects_features: issues: true merge_requests: true wiki: true snippets: false builds: false#Omnibus/etc/gitlab/gitlab.rbgitlab_rails[&apos;gitlab_default_projects_features_builds&apos;] = false#重载sudo gitlab-ctl reconfigure CI/CD admin设置GitLab CI/CD admin settings: Enable or disable DevOps site-wide and define the artifacts’ max size and expiration time. 在以管理员登录GitLab Web UI，在Admin area里面，您将找到Auto DevOps，Runners和job artifacts的设置。 Auto DevOps 要为所有项目启用/禁用 Auto DevOps： 进入Admin area &gt; Settings &gt; Continuous Integration and Deployment 检查Default to Auto DevOps pipeline for all projects 可为Auto DevOps添加基本域 保存更改 从现在开始，每个现有项目和新创建的项目都没有.gitlab-ci.yml，将使用Auto DevOps pipeline。 Maximum artifacts size 可为GitLab实例设置[job artifacts][art-yml]的最大大小。它的单位为MB，默认为每个Job设置为100MB。GitLab.com上它被设置为1GB。 Default artifacts expiration 可为GitLab实例的job artifacts设置默认到期时间。GitLab.com它never expire。这里面的设置是按Job设置的，可在.gitlab-ci.yml中覆盖它。将其设置为0表示禁用过期，默认单位是秒。 Archive jobs 归档作业通过删除作业的一些功能（运行作业所需的元数据）来减少系统上的CI/CD占用空间，但是为了审计目的而保留跟踪(traces)和工件(artifacts)。一旦该时间过去，作业将被存档，不再能够重试。让它变空成为永不过期的工作(它必须不少于1天)。 Jobs artifactsJob artifacts: Enable, disable, and configure job artifacts (a set of files and directories which are outputted by a job when it completes successfully). Artifacts是在成功完成后附加到作业的文件和目录的列表。此功能在所有的安装中默认启用。 禁用 job artifacts 1234567#Omnibus#/etc/gitlab/gitlab.rbgitlab_rails['artifacts_enabled'] = false#重载 存储 job artifacts成功完成作业后，GitLab Runner将job artifacts的存档上传到GitLab。 使用本地存储 12#默认路径# gitlab_rails[&apos;artifacts_path&apos;] = &quot;/var/opt/gitlab/gitlab-rails/shared/artifacts&quot; 使用对象存储 Setting Description Default enabled Enable/disable object storage false remote_directory The bucket name where Artifacts will be stored direct_upload Set to true to enable direct upload of Artifacts without the need of local shared storage. Option may be removed once we decide to support only single storage for all files. false background_upload Set to false to disable automatic upload. Option may be removed once upload is direct to S3 true proxy_download Set to true to enable proxying all files served. Option allows to reduce egress traffic as this allows clients to download directly from remote storage instead of proxying all data false connection Various connection options described below - Expiring artifacts如果工件使用了失效日期，则在该日期过后立即标记为删除。文件由expire_build_artifacts_worker cron job清理，该作业由Sidekiq每小时的第50分钟（50 * * * *）运行。 更改工件过期的默认调度计划： 12345#Omnibus#/etc/gitlab/gitlab.rbgitlab_rails['expire_build_artifacts_worker_cron'] = "50 * * * *"#重配 依赖验证(dependencies validation)要禁用依赖验证，可在Rail Console设置。 1234567#Omnibus#rails consolesudo gitlab-rails console#禁用 Feature.enable(&apos;ci_disable_validates_dependencies&apos;) 实施细节当GitLab收到工件存档时，GitLab Workhorse也会生成存档元数据文件。此元数据文件描述了工件存档本身中的所有条目。元数据文件采用二进制格式，具有额外的GZIP压缩。 GitLab不解压工件存档以节省Disk，Mem和I/O。它改为检查包含所有相关信息的元数据文件。当存在大量工件或存档是非常大的文件时，这一点尤为重要。单击特定文件时，GitLab Workhorse会从存档中提取它并开始下载。此实现可节省空间，内存和磁盘I/O. Job tracesJob traces: Information about the job traces (logs). 作业跟踪由GitLab Runner在处理作业时发送。您可以在job, pipeline, email notification查看工作踪迹。 数据流Data flow 通常，作业踪迹中有两种状态： 实时跟踪(live trace) 存档跟踪(archived trace) Phase State Condition Data flow Stored path 1: patching Live trace When a job is running GitLab Runner =&gt; Unicorn =&gt; file storage #{ROOT_PATH}/builds/#{YYYY_mm}/#{project_id}/#{job_id}.log 2: overwriting Live trace When a job is finished GitLab Runner =&gt; Unicorn =&gt; file storage #{ROOT_PATH}/builds/#{YYYY_mm}/#{project_id}/#{job_id}.log 3: archiving Archived trace After a job is finished Sidekiq moves live trace to artifacts folder #{ROOT_PATH}/shared/artifacts/#{disk_hash}/#{YYYY_mm_dd}/#{job_id}/#{job_artifact_id}/job.log 4: uploading Archived trace After a trace is archived Sidekiq moves archived trace to object storage (if configured) #{bucket_name}/#{disk_hash}/#{YYYY_mm_dd}/#{job_id}/#{job_artifact_id}/job.log 修改工作踪迹本地位置Changing the job traces local location 更改存储Job Log的位置： 123456789101112#Omnibus#/etc/gitlab/gitlab.rbgitlab_ci[&apos;builds_directory&apos;] = &apos;/mnt/to/gitlab-ci/builds&apos;#Source#/home/git/gitlab/config/gitlab.ymlgitlab_ci: # The location where build traces are stored (default: builds/). # Relative paths are relative to Rails.root. builds_path: path/to/builds/ 将踪迹上传到对象存储Uploading traces to object storage 存档的踪迹被视为工作工件。因此，在设置对象存储集成时，作业踪迹会自动与其他作业工件一起迁移到它。 如何归档旧的作业踪迹文件How to archive legacy job trace files 旧的作业踪迹指的是在GitLab 10.5之前创建的，未定期归档的作业踪迹。那么你可能需要手动进行操作： 123456789#执行此任务后，GitLab实例将Sidekiq作业（异步进程）排队，以将作业跟踪文件从本地存储迁移到对象存储。完成所有迁移工作可能需要一些时间。gitlab-rake gitlab:traces:archivesudo gitlab-rails console#如果计数变为零，则归档过程完成[1] pry(main)&gt; Sidekiq::Stats.new.queues['pipeline_background:archive_trace'] =&gt; 100 如何将归档的作业踪迹迁移到对象存储How to migrate archived job traces to object storage 在GitLab 11.3中引入 如果作业踪迹已存档到本地存储中，并且您希望将这些踪迹迁移到对象存储： 确保已启用Job Artifacts的对象存储集成 执行此命令: gitlab-rake gitlab:traces:migrate 如何删除作业踪迹How to remove job traces 没有办法自动使旧的作业日志过期，但如果它们占用太多空间，则可以安全地删除它们。如果手动删除日志，则UI中的作业输出将为空。 新的实时踪迹架构New live trace architecture 在GitLab 10.4中引入。在GitLab 11.0中宣布的一般可用性。此功能默认禁用。 这是一个详细的数据流： GitLab Runner picks a job from GitLab GitLab Runner sends a piece of trace to GitLab GitLab appends the data to Redis Once the data in Redis reach 128KB, the data is flushed to a persistent store (object storage or the database). The above steps are repeated until the job is finished. Once the job is finished, GitLab schedules a Sidekiq worker to archive the trace. The Sidekiq worker archives the trace to object storage and cleans up the trace in Redis and a persistent store (object storage or the database) Enabling live trace 123456789101112131415161718#console# Omnibus GitLabgitlab-rails console# Installation from sourcecd /home/git/gitlabsudo -u git -H bin/rails console RAILS_ENV=production#检查实时踪迹Feature.enabled?(&apos;ci_enable_live_trace&apos;)#启用Feature.enable(&apos;ci_enable_live_trace&apos;)#禁用Feature.disable(&apos;ci_enable_live_trace&apos;) 潜在影响(Potential implications) 在某些情况下，将数据存储在Redis上可能会导致数据丢失： Case 1: When all data in Redis are accidentally flushed可以通过重新发送追踪来恢复实时踪迹。未归档的已完成作业的实时踪迹将丢失踪迹数据的最后一部分。 Case 2: When Sidekiq workers fail to archive目前，Redis中的所有踪迹数据将在一周后删除。如果Sidekiq Worker无法在过期之前完成，则踪迹数据的一部分将丢失。 可能出现的另一个问题是它可能占用Redis实例上的所有内存如果作业数为1000，则消耗128MB（128KB*1000）。 配置GitLab RunnerConfiguring GitLab RunnersRegister Shared and specific Runners: Learn how to register and configure Shared and specific Runners to your own instance. 在GitLab CI中，Runners运行.gitlab-ci.yml中定义的代码。它们是隔离(虚拟)机器，通过GitLab CI的协调器API获取作业。Runner可以特定于某个项目，也可以为GitLab CI中的任何项目提供服务。为所有项目提供服务的Runner称为shared Runner。理想情况下，GitLab Runner不应与GitLab安装在同一台机器上。你可以为GitLab实例配置多个Runner。 Runner的状态Shared, specific and group Runners 安装Runner后，您可以将其注册为共享的或特定的。如果您具有GitLab实例的管理员访问权限，则只能注册shared Runner。 每个Runner可处于一下状态； shared: Runner runs jobs from all unassigned projects group: Runner runs jobs from all unassigned projects in its group specific: Runner runs jobs from assigned projects locked: Runner cannot be assigned to other projects paused: Runner will not receive any new jobs 注册共享的RunnerRegistering a shared Runner 如果您是GitLab实例的管理员，则只能注册shared Runner。 在Web UI -&gt; Admin Area -&gt; Runner里面用它提供的URL和Token进行Runner注册。 默认情况下启用shared runner，但可在 Admin Area -&gt; CI/CD里面禁用。 注册特定的RunnerRegistering a specific Runner 注册特定的Runner有两种方式： 使用project registration token来注册Runner 将shared Runner 转换为 specific Runner(单向，仅限管理员) 使用项目Token注册特定的Runner：创建一个没有GitLab实例管理员权限的特定Runner。进入此项目， Setting -&gt; CI/CD -&gt; Runner进行配置。 注册一个组RunnerRegistering a group Runner 创建一个group Runner，然后访问词组，Setting -&gt; CI/CD -&gt; Runner。 将共享的Runner特定化(Making an existing shared Runner specific) 如果您是GitLab实例的管理员，则可以将任何shared Runner转换为specific Runner。请记住，这是一种单向转换，不能逆向转换。 Admin Ares -&gt; Overview -&gt; Runner -&gt; 需要的Runner 对项目启用Restrict projects for this Runner 这样，shared Runner便特定于某些项目。 之后此Runner的状态便发生了改变。 锁定特定RunnerLocking a specific Runner from being enabled for other projects 您可以配置Runner以将其专门分配给一个项目。当Runner以这种方式锁定时，不能再为其他项目启用它。 Visit your project’s Settings &gt; CI/CD Find the Runner you wish to lock/unlock and make sure it’s enabled Click the pencil button Check the Lock to current projects option Click Save changes for the changes to take effect 将Runner分配给另外的项目Assigning a Runner to another project 如果您是分配了特定Runner的项目的维护人员，并且Runner未仅锁定到该项目(not locked only to that project)，则还可以在具有Maintainer权限的任何其他项目上启用Runner。 请注意，如果您没有将特定的Runner锁定到特定项目，那么您项目中具有Maintainer角色的任何用户都可以将Runner分配给另一个任意项目，而无需您的授权，因此请谨慎使用。 启用： Visit your project’s Settings &gt; CI/CD Find the Runner you wish to enable/disable Click Enable for this project or Disable for this project 管理员可以为项目启用/禁用特定的Runner： Navigate to Admin &gt; Runners Find the Runner you wish to enable/disable Click edit on the Runner Click Enable or Disable on the project 受保护的RunnerProtected Runners 在GitLab 10.0中引入。 你可以保护Runner免于泄露敏感信息。每当Runner受到保护时，Runner仅选择在受保护的分支或受保护的标签上创建的作业，并忽略其他作业。 protect/unprotect: Visit your project’s Settings &gt; CI/CD Find a Runner you want to protect/unprotect and make sure it’s enabled Click the pencil button besides the Runner name Check the Protected option Click Save changes for the changes to take effect 手动清理Runner缓存Manually clearing the Runners cache Navigate to your project’s CI/CD &gt; Pipelines page. Click on the Clear Runner caches button to clean up the cache. On the next push, your CI/CD job will use a new cache. 共享Runner如何选择作业How shared Runners pick jobs 共享的Runner遵守我们称之为合理使用的进程队列(process queue)。公平的使用算法尝试从当前在shared Runners上运行的作业数量最少的项目中将作业分配给shared Runners。 有效地使用共享RunnerUsing shared Runners effectively 如果您打算使用共享的Runners，您应该记住几件事。 使用tags 您必须设置一个Runner才能运行所有不同类型的作业，它可能会在共享的项目中遇到。如果不使用tags，则对于大型项目可能会出现问题。通过为Runner打tag来标记它可以处理的作业类型，您可以确保shared Runners只运行它们配备的作业(only run the jobs they are equipped to run)。 例如，在GitLab中，如果Runners包含运行Rails测试套件的相应依赖项，那么我们将Runners标记为“rails” Preventing Runners with tags from picking jobs without tags您可以配置Runner以防止在Runner没有分配tag时使用tag选择作业。 Runner pick tagged/untagged jobs: Visit your project’s Settings ➔ CI/CD Find the Runner you wish and make sure it’s enabled Click the pencil button Check the Run untagged jobs option Click Save changes for the changes to take effect 为Runner设置做大作业超时 对于每个Runner，您可以指定最大作业超时时间。如果小于项目定义的超时，则此类超时将优先。 小心敏感信息 对于一些Runner Executors，如果您可以在Runner上运行作业，您就可以访问它运行的任何代码并获取Runner的Token。使用shared Runners，这意味着在Runner上运行作业的任何人都可以访问在Runner上运行的任何其他人的代码。 通过在大型公共GitLab实例上限制shared Runners的使用，控制对GitLab实例的访问以及使用更安全的Runner Executor，可以轻松避免上述情况。 Forks 每当项目forked时，它都会复制与其相关的作业的设置。这意味着如果您为项目设置了shared Runners并且有人fork该项目，则shated Runners也将为该项目的作业提供服务。 tagstags用于从允许运行此项目的所有Runner列表中选择特定的Runner。你可以制定Runner的tag. tags允许您使用分配了指定tag的Runners运行作业： 1234job: tags: - ruby - postgres 例子： 123456789101112131415windows job: stage: - build tags: - windows script: - echo Hello, %USERNAME%!osx job: stage: - build tags: - osx script: - echo "Hello, $USER!" 共享Runner的管道配额Shared Runners pipelines quota: Limit the usage of pipeline minutes for Shared Runners. 在Web UI的Admin Area下的Auto DevOps里面进行配置。 Auto DevOpsEnable/disable Auto DevOps: Enable or disable Auto DevOps for your instance 在GitLab 10.0中引入。一般在GitLab 11.0上可用。 Auto DevOps提供预定义的CI/CD配置，允许您自动检测(detect)，构建(build)，测试(test)，部署(deploy)和监控(monitor)应用程序。利用CI/CD最佳实践和工具，Auto DevOps旨在简化成熟和现代软件开发生命周期的设置和执行。 综述 从GitLab v11.3开始，默认情况下为所有项目启用Auto DevOps pipeline。如果尚未为项目显式启用，则会在第一个管道故障时自动禁用Auto DevOps。如果找到一个，您的项目将继续使用备用CI/CD配置文件。 借助Auto DevOps，软件开发过程变得更容易设置，因为每个项目都可以拥有从验证到监控的完整工作流程，并且配置最少。只需推送您的代码，GitLab就会处理其他所有事情。这样可以更轻松地启动新项目，并使整个公司的应用程序设置更加一致。 与应用程序平台和PaaS相比较Comparison to application platforms and PaaS Auto DevOps提供通常包含在应用程序平台或PaaS的功能。它有多个灵感： Auto DevOps适用于任何k8s集群;你不仅限于在GitLab的基础设施上运行。 没有额外成本，你可在任何公共云上使用自托管的k8s集群。 Auto DevOps包括了安全测试，性能测试和代码质量测试等众多功能。 Auto DevOps提供增量分级路径。如果您需要高级自定义，则可以开始修改模板，而无需在完全不同的平台上重新开始。 特性特性(Features): Auto Build Auto Test Auto Code Quality Auto SAST (Static Application Security Testing) Auto Dependency Scanning Auto License Management Auto Container Scanning Auto Review Apps Auto DAST (Dynamic Application Security Testing) Auto Deploy Auto Browser Performance Testing Auto Monitoring 由于Auto DevOps依赖于许多不同的组件，因此最好具备以下基本知识： Kubernetes Helm Docker GitLab Runner Prometheus Auto DevOps为所有阶段提供了很好的默认值;但是，您可以根据需要自定义几乎所有内容。 依赖Requirements 要充分利用Auto DevOps，您需要: GitLab Runner(所有阶段都需要)Runner需要配置为能够运行Docker(通常，这意味着使用Docker或Kubernetes executor，并启用特权模式)。Runner不需要安装在k8s集群中，但k8s executor易于使用并且可以自动进行自动伸缩。基于Docker的Runner也可以使用Docker Machine配置为自动伸缩。应将Runners注册为整个GitLab实例的shared Runners，或分配给特定项目的specific Runner。 Base domain(自动审阅和自动部署所需)您将需要一个配置了通配符DNS的域，该域将由您的所有Auto DevOps应用程序使用。 K8s(自动审阅、自动部署和自动监控所需)要启用部署，您需要k8s v1.5+。您需要项目的Kubernetes集群，或整个GitLab安装的Kubernetes默认服务模板。负载均衡器——您可以使用nginx-ingress Helm Chart将NGINX Ingress部署到Kubernetes集群，从而使用NGINX ingress。 Prometheus(自动监控所需)要启用自动监控，您需要在某处（集群内部或外部）安装Prometheus并配置为刮取您的Kubernetes集群。要获得除系统指标外的响应指标(Metrics)，您还需要配置Prometheus。 注意：如果您没有安装Kubernetes或Prometheus，则将自动跳过自动审阅，自动部署和自动监控。 自动化运维基本域Auto DevOps base domain 如果要使用自动审阅和自动部署，则需要启用Auto DevOps base domain。它可在三个地方定义： 在项目下的CI/CD 在Admin Area -&gt; Setting -&gt; CI/CD 在项目下配置变量: AUTO_DEVOPS_DOMAIN 在组级别配置变量: AUTO_DEVOPS_DOMAIN 需要一个与基本域匹配的通配符DNS A记录，如: 12345*.example.com 3600 A 1.2.3.4#在这种情况下，`example.com`是用于部署应用程序的域名，`1.2.3.4`是负载均衡器的IP地址(通常是NGINX)。如何设置DNS记录超出了本文档的范围;您应该咨询您的DNS提供商。#设置完成后，所有请求都会到达负载均衡器，然后负载均衡器会将它们路由到运行应用程序的Kubernetes pod 使用多个k8s集群Using multiple Kubernetes clusters 使用Auto DevOps时，您可能希望将不同的环境部署到不同的Kubernetes集群。在Auto DevOps template中，您需要知道3个已定义的环境名称： review/ (从review/开始每个环境) staging production 这些环境与使用自动部署的作业相关联，因此除了环境范围之外，它们还需要具有部署到的不同域。这就是您需要根据环境为上述所有内容定义单独的AUTO_DEVOPS_DOMAIN变量的原因。 下表是如何配置三个不同群集的示例: 集群名 集群环境范围 AUTO_DEVOPS_DOMAIN变量值 环境变量范围 备注 review review/* review.example.com review/* The review cluster which will run all Review Apps. * is a wildcard, which means it will be used by every environment name starting with review/. staging staging staging.example.com staging (Optional) The staging cluster which will run the deployments of the staging environments. You need to enable it first. production production example.com production The production cluster which will run the deployments of the production environment. You can use incremental rollouts. 要为每个环境添加不同的群集： 项目的Operations -&gt; Kubernetes并使用各自的环境范围创建Kubernetes集群，如上表所述 创建群集后，到每个群集并安装Helm Tiller和Ingress 确保已使用指定的自动化运维域配置DNS 到项目的Settings -&gt; CI/CD -&gt; Variables，添加AUTO_DEVOPS_DOMAIN变量及其各自的环境范围。 注意：具有多个群集的组不支持自动DevOps，因为无法在组级别上为每个环境设置AUTO_DEVOPS_DOMAIN。 启用/禁用Auto DevOps首次使用Auto Devops时，请查看要求以确保可以使用所有必要的组件来充分利用Auto DevOps。 在实例级别启用/禁用Auto DevOps（仅限管理员） Admin area -&gt; Settings -&gt; Continuous Integration and Deployment Default to Auto DevOps pipeline for all projects base domain 在项目级别启用/禁用 Auto DevOps project’s Settings -&gt; CI/CD -&gt; Auto DevOps Default to Auto DevOps pipeline Domain Deployment strategy 部署策略(Deployment strategy) Introduced in GitLab 11.0 你可以更改项目的部署策略。有三种策略: Continuous deployment to production: 允许master分支启用Auto Deploy来直接部署到生产环境 Continuous deployment to production using timed incremental rollout: 将INCREMENTAL_ROLLOUT_MODE变量设置为timed，并且将在rollout的每个增量之间延迟5分钟执行生产部署 Automatic deployment to staging, manual deployment to production: 设置STAGING_ENABLED为1，INCREMENTAL_ROLLOUT_MODE为manual。提供手动操作以部署到生产环境 自动化运维的阶段Stages of Auto DevOps 以下部分描述了Auto DevOps的各个阶段。仔细阅读它们以了解每个工作原理。 Auto Build自动化构建有两种方式创建应用程序的构建： 如果有Dockerfile, 则使用docker build来创建镜像 否则，它将使用Herokuish和Heroku buildpacks自动检测并将应用程序构建到Docker镜像中 无论哪种方式，生成的Docker镜像都会自动推送到Container Registry并使用commit SHA进行标记。 重要提示：如果您还使用Auto Review和Auto Deploy并选择提供自己的Dockerfile，请确保将应用程序expose到端口5000，因为这是默认Helm图表所假定的端口。 Auto TestAuto Test通过分析您的项目来检测语言和框架，使用Herokuish和Heroku buildpacket自动为您的应用程序运行相应的测试。自动检测多种语言和框架，但如果未检测到您的语言，您可以使用自定义构建包(Custom buildpacks)。可检查当前支持的语言。 注意：自动测试使用您在应用程序中已有的测试。如果没有测试，则由您来添加它们。 Auto Code Quality GitLab STARTER BRONZE Auto Code Quality使用Code Quality image对当前代码运行静态分析和其他代码检查。报告已创建，并作为工件上传，您可以在以后下载和检查。源分支和目标分支之间的任何差异也会显示在合并请求窗口小部件中。 Auto SAST GitLab ULTIMATE GOLD Static Application Security Testing(SAST)使用SAST Docker image对当前代码运行静态分析并检查潜在的安全问题。创建报告后，它将作为工件上载，您可以在以后下载和检查。 Auto Dependency Scanning GitLab ULTIMATE GOLD Dependency Scanning使用Dependency Scanning Docker image对项目依赖关系进行分析并检查潜在的安全问题。创建报告后，它将作为工件上载，您可以在以后下载和检查。 Auto License Management GitLab ULTIMATE GOLD License Management使用License Management Docker image搜索项目依赖项以获取其许可证。创建报告后，它将作为工件上载，您可以在以后下载和检查。 Auto Container Scanning GitLab ULTIMATE 容器的漏洞静态分析使用Clair在Docker image上运行静态分析并检查潜在的安全问题。创建报告后，它将作为工件上载，您可以在以后下载和检查。 Auto Review Apps 注意： 这是一个可选步骤，因为许多项目没有可用的Kubernetes集群。如果不满足要求，将默默跳过作业。警告：不应在Helm之外操作您的应用程序(直接使用Kubernetes)。这可能会导致Helm无法检测到更改，并且随后使用Auto DevOps进行部署可以撤消您的更改。此外，如果您更改某些内容并希望通过再次部署来撤消它，Helm可能无法检测到任何更改，因此没有意识到它需要重新应用旧配置。 Review App 是基于分支代码的临时应用程序环境，因此开发人员，设计人员，QA，产品经理和其他审阅者可以在审阅过程中实际查看代码更改并与之交互。Auto Review Apps为每个分支创建一个Review App。 Auto Review Apps 仅将您的应用部署到您的Kubernetes群集。如果没有可用的群集，则不会进行部署。Review App将具有基于项目名，分支名、唯一编号以及Auto DevOps基本域的唯一URL。如：user-project-branch-1234.example.com。审阅应用程序的链接显示在合并请求窗口小部件中，以便于发现。删除分支时，例如合并合并请求后，将自动删除Review App。 Auto DAST GitLab Ultimate Dynamic Application Security Testing (DAST)使用流行的开源工具OWASP ZAProxy对当前代码执行分析并检查潜在的安全问题。创建报告后，它将作为工件上载，您可以在以后下载和检查。 Auto Browser Performance Testing GitLab Premium 自动浏览器性能测试利用Sitespeed.io容器来衡量网页的性能。创建JSON报告并将其作为工件上载，其中包括每个页面的整体性能分数。默认情况下，将测试Review和Production环境的根页面。如果要添加其他URL以进行测试，只需将路径添加到根目录中名为.gitlab-urls.txt的文件中，每行一个。 栗子: 123//features/direction Auto Deploy 注意：这是一个可选步骤，因为许多项目没有可用的Kubernetes集群。如果不满足要求，将默默跳过作业。警告：不应在Helm之外操作您的应用程序（直接使用Kubernetes）。这可能会导致Helm无法检测到更改，并且随后使用Auto DevOps进行部署可以撤消您的更改。此外，如果您更改某些内容并希望通过再次部署来撤消它，Helm可能无法检测到任何更改，因此没有意识到它需要重新应用旧配置。 将branch或merge request合并到项目的默认分支（通常是master）后，Auto Deploy将应用程序部署到Kubernetes集群中的生产环境，其中包含基于项目名称和唯一项目ID的命名空间。您可以使用环境变量自动伸缩pod副本。 值得注意的是，当项目部署到Kubernetes集群时，它依赖于已推送到GitLab Container Registry的Docker image。k8s获取此镜像并运行应用。如果项目是公共的，Kubernetes可以在不进行任何身份验证的情况下访问该映像，从而使我们可以使部署更加可用。如果项目是私有/内部的，则注册表需要凭据才能提取镜像。目前，通过提供CI_JOB_TOKEN作为可以使用的密码来解决此问题，但是一旦部署作业完成，此标记将不再有效。这意味着Kubernetes可以运行应用程序，但是如果它应该重新启动或在其他地方执行，则无法再次访问。 Auto Monitoring 注意：检查自动监控的要求以使此阶段工作。 部署应用程序后，自动监控可以立即监控应用程序的服务器和响应指标。自动监控使用Prometheus直接从Kubernetes获取系统指标，如CPU和内存使用情况，以及来自NGINX服务器的响应指标，如HTTP错误率，延迟和吞吐量。 指标有： Response Metrics: latency, throughput, error rate System Metrics: CPU utilization, memory utilization 为了使用监控，你需要： 将Prometheus部署到k8s集群中 配置Prometheus以获取想要的指标 自定义Customizing 虽然Auto DevOps提供了很好的默认设置来帮助您入门，但您可以自定义几乎所有内容以满足您的需求;从自定义buildpacks到Dockerfiles，Helm chart，甚至将完整的CI/CD配置复制到项目中进行部署。 Custom buildpacks如果项目的自动buildpack检测失败，或者您想使用自定义buildpack，则可以使用项目变量或项目中的.buildpacks文件覆盖buildpack: Project variable: 使用要使用的buildpack的URL创建项目变量BUILDPACK_URL .buildpacks文件: 在项目中添加一个名为.buildpacks的文件，并添加要在文件中的一行使用的buildpack的URL(多个使用多行，一行一个) 警告：Auto DevOps尚不支持使用多个buildpack Custom Dockerfile如果您的项目的根目录中有一个Dockerfile，则Auto DevOps将基于Dockerfile而不是使用buildpacks构建Docker镜像。这可以更快，并导致更小的图像，尤其是如果您的Dockerfile基于Alpine。 Custom Helm ChartAuto DevOps使用Helm将您的应用程序部署到Kubernetes。您可以通过将chart捆绑到项目仓库中或通过指定项目变量来覆盖使用的Helm chart： Bundled chart: 如果您的项目有一个带有Chart.yaml文件的./chart目录，Auto DevOps将检测chart并使用它而不是默认chart。这可以很好地控制应用程序的部署方式 Project variable: 使用要使用的自定义chart的URL创建项目变量AUTO_DEVOPS_CHART Customizing .gitlab-ci.yml如果要修改Auto DevOps使用的CI/CD pipeline，可以将Auto DevOps template复制到项目的repo中并根据需要进行编辑。 假设您的项目是新的或者没有.gitlab-ci.yml文件： 在项目 CI/CD里面新建文件 选择.gitlab-ci.yml模板 选择Auto-DevOps 编辑此模板 提交 提示：Auto DevOps模板包含有用的注释，可帮助您自定义它。如果您希望部署转到临时(staging)环境而不是直接转到生产(production)环境，则可以通过将.staging重命名为staging来启用staging作业；然后确保取消注释生产作业的when，将其转换为手动操作，而不是自动部署。 PostgreSQL为了支持需要数据库的应用程序，默认情况下会配置PostgreSQL。访问数据库的凭据已预先配置，但可以通过设置关联的变量进行自定义。这些凭据可用于定义DATABASE_URL的格式：postgres://user:password@postgres-host:postgres-port/postgres-database Environment variables以下变量可用于设置Auto DevOps domain，提供自定义Helm chart或扩展应用程序。 PostgreSQL也可以自定义，您可以轻松使用自定义buildpack。 变量 描述 AUTO_DEVOPS_DOMAIN Auto DevOps domain AUTO_DEVOPS_CHART 用于部署应用的Helm Chart REPLICAS 要部署的副本数，默认为1 PRODUCTION_REPLICAS 要在生产环境中部署的副本数。这优先于REPLICAS;默认为1 CANARY_REPLICAS Canary Deployments部署的副本数，默认为1 CANARY_PRODUCTION_REPLICAS 生产环境的，优先于CANARY_REPLICAS，默认为1 POSTGRES_ENABLED 是否启用PostgreSQL,默认为true POSTGRES_USER PostgreSQL用户，默认为user POSTGRES_PASSWORD PostgreSQL密码，默认为testing-password POSTGRES_DB PostgreSQL数据库名称;默认值为$CI_ENVIRONMENT_SLUG BUILDPACK_URL buildpack的完整URL SAST_CONFIDENCE_LEVEL 您希望报告的安全问题的最低置信度; 1为低，2为中，3为高;默认为3 DEP_SCAN_DISABLE_REMOTE_CHECKS 是否禁用远程依赖扫描检查;默认为false DB_INITIALIZE 从GitLab 11.4开始，此变量可用于指定运行以初始化应用程序的PostgreSQL数据库的命令。它在应用程序pod内运行 DB_MIGRATE 从GitLab 11.4开始，此变量可用于指定运行以迁移应用程序的PostgreSQL数据库的命令。它在应用程序pod内运行 STAGING_ENABLED 可用于定义部署策略 CANARY_ENABLED 定义canary部署策略 INCREMENTAL_ROLLOUT_MODE 从GitLab 11.4开始，此变量（如果存在）可用于为生产环境启用应用程序的增量部署 TEST_DISABLED 从GitLab 11.0开始，此变量可用于禁用测试作业 CODE_QUALITY_DISABLED 从GitLab 11.0开始，此变量可用于禁用代码质量作业 SAST_DISABLED 从GitLab 11.0开始，此变量可用于禁用sast作业 DEPENDENCY_SCANNING_DISABLED 从GitLab 11.0开始，此变量可用于禁用dependency_scanning作业 CONTAINER_SCANNING_DISABLED 从GitLab 11.0开始，此变量可用于禁用sast：container作业 REVIEW_DISABLED 从GitLab 11.0开始，此变量可用于禁用审核和手动审核：停止作业 PERFORMANCE_DISABLED 从GitLab 11.0开始，此变量可用于禁用性能作业 提示：使用项目变量设置副本变量，并通过重新部署来扩展应用程序！小心: 你不应该直接使用k8s来扩展你的应用程序，这可能会导致Helm异常。 高级副本变量设置(Advanced replica variables setup) 除了上面提到的两个与副本相关的生产变量之外，您还可以将其它变量用于不同的环境。 目前支持的语言Currently supported languages 从GitLab 10.0开始，支持的构建包是： 12345678910111213- heroku-buildpack-multi v1.0.0- heroku-buildpack-ruby v168- heroku-buildpack-nodejs v99- heroku-buildpack-clojure v77- heroku-buildpack-python v99- heroku-buildpack-java v53- heroku-buildpack-gradle v23- heroku-buildpack-scala v78- heroku-buildpack-play v26- heroku-buildpack-php v122- heroku-buildpack-go v72- heroku-buildpack-erlang fa17af9- buildpack-nginx v8 Auto DevOps template各种模板: https://gitlab.com/gitlab-org/gitlab-ce/tree/master/lib/gitlab/ci/templates 在项目也可选择新建.gitlab-ci.yml模板文件，然后根据需要就行适当的修改。 CI/CD环境变量CI/CD Variables - Learn how to use variables defined in your .gitlab-ci.yml or the ones defined in your project’s settings 当从GitLab CI接收作业时，Runner准备构建环境。首先，设置预定义变量列表predefined variables（环境变量）和用户定义变量列表user-defined variables。 变量优先级Priority of variables 变量可以被覆盖，并且它们按此顺序优先于彼此： Trigger variables / scheduled pipeline variables Project-level variables / protected variables Group-level variables / protected variables YAML-defined job-level variables YAML-defined global variables Deployment variables Predefined variables 不支持的变量在某些情况下，某些变量无法在.gitlab-ci.yml定义的上下文中使用——如在script下定义的变量。 预定义变量Predefined variables (Environment variables) 注意：从GitLab 9.0开始，我们已经弃用了一些变量。阅读9.0重命名部分以找出它们的替代品。强烈建议您使用新变量，因为我们将在以后的GitLab版本中删除旧变量。 Variable GitLab Runner Description ARTIFACT_DOWNLOAD_ATTEMPTS 8.15 1.9 Number of attempts to download artifacts running a job CI all 0.4 Mark that job is executed in CI environment CI_COMMIT_BEFORE_SHA 11.2 all The previous latest commit present on a branch before a push request. CI_COMMIT_DESCRIPTION 10.8 all The description of the commit: the message without first line, if the title is shorter than 100 characters; full message in other case. CI_COMMIT_MESSAGE 10.8 all The full commit message. CI_COMMIT_REF_NAME 9.0 all The branch or tag name for which project is built CI_COMMIT_REF_SLUG 9.0 all $CI_COMMIT_REF_NAME lowercased, shortened to 63 bytes, and with everything except 0-9 and a-z replaced with -. No leading / trailing -. Use in URLs, host names and domain names. CI_COMMIT_SHA 9.0 all The commit revision for which project is built CI_COMMIT_SHORT_SHA 11.7 all The first eight characters of CI_COMMIT_SHA CI_COMMIT_TAG 9.0 0.5 The commit tag name. Present only when building tags. CI_COMMIT_TITLE 10.8 all The title of the commit - the full first line of the message CI_CONFIG_PATH 9.4 0.5 The path to CI config file. Defaults to .gitlab-ci.yml CI_DEBUG_TRACE all 1.7 Whether debug tracing is enabled CI_DEPLOY_PASSWORD 10.8 all Authentication password of the GitLab Deploy Token, only present if the Project has one related. CI_DEPLOY_USER 10.8 all Authentication username of the GitLab Deploy Token, only present if the Project has one related. CI_DISPOSABLE_ENVIRONMENT all 10.1 Marks that the job is executed in a disposable environment (something that is created only for this job and disposed of/destroyed after the execution - all executors except shell and ssh). If the environment is disposable, it is set to true, otherwise it is not defined at all. CI_ENVIRONMENT_NAME 8.15 all The name of the environment for this job CI_ENVIRONMENT_SLUG 8.15 all A simplified version of the environment name, suitable for inclusion in DNS, URLs, Kubernetes labels, etc. CI_ENVIRONMENT_URL 9.3 all The URL of the environment for this job CI_JOB_ID 9.0 all The unique id of the current job that GitLab CI uses internally CI_JOB_MANUAL 8.12 all The flag to indicate that job was manually started CI_JOB_NAME 9.0 0.5 The name of the job as defined in .gitlab-ci.yml CI_JOB_STAGE 9.0 0.5 The name of the stage as defined in .gitlab-ci.yml CI_JOB_TOKEN 9.0 1.2 Token used for authenticating with the GitLab Container Registry and downloading dependent repositories CI_JOB_URL 11.1 0.5 Job details URL CI_MERGE_REQUEST_ID 11.6 all The ID of the merge request if it’s pipelines for merge requests CI_MERGE_REQUEST_IID 11.6 all The IID of the merge request if it’s pipelines for merge requests CI_MERGE_REQUEST_PROJECT_ID 11.6 all The ID of the project of the merge request if it’s pipelines for merge requests CI_MERGE_REQUEST_PROJECT_PATH 11.6 all The path of the project of the merge request if it’s pipelines for merge requests (e.g. namespace/awesome-project) CI_MERGE_REQUEST_PROJECT_URL 11.6 all The URL of the project of the merge request if it’s pipelines for merge requests (e.g. http://192.168.10.15:3000/namespace/awesome-project) CI_MERGE_REQUEST_REF_PATH 11.6 all The ref path of the merge request if it’s pipelines for merge requests. (e.g. refs/merge-requests/1/head) CI_MERGE_REQUEST_SOURCE_BRANCH_NAME 11.6 all The source branch name of the merge request if it’s pipelines for merge requests CI_MERGE_REQUEST_SOURCE_PROJECT_ID 11.6 all The ID of the source project of the merge request if it’s pipelines for merge requests CI_MERGE_REQUEST_SOURCE_PROJECT_PATH 11.6 all The path of the source project of the merge request if it’s pipelines for merge requests CI_MERGE_REQUEST_SOURCE_PROJECT_URL 11.6 all The URL of the source project of the merge request if it’s pipelines for merge requests CI_MERGE_REQUEST_TARGET_BRANCH_NAME 11.6 all The target branch name of the merge request if it’s pipelines for merge requests CI_NODE_INDEX 11.5 all Index of the job in the job set. If the job is not parallelized, this variable is not set. CI_NODE_TOTAL 11.5 all Total number of instances of this job running in parallel. If the job is not parallelized, this variable is set to 1. CI_API_V4_URL 11.7 all The GitLab API v4 root URL CI_PIPELINE_ID 8.10 all The unique id of the current pipeline that GitLab CI uses internally CI_PIPELINE_IID 11.0 all The unique id of the current pipeline scoped to project CI_PIPELINE_SOURCE 10.0 all Indicates how the pipeline was triggered. Possible options are: push, web, trigger, schedule, api, and pipeline. For pipelines created before GitLab 9.5, this will show as unknown CI_PIPELINE_TRIGGERED all all The flag to indicate that job was triggered CI_PIPELINE_URL 11.1 0.5 Pipeline details URL CI_PROJECT_DIR all all The full path where the repository is cloned and where the job is run CI_PROJECT_ID all all The unique id of the current project that GitLab CI uses internally CI_PROJECT_NAME 8.10 0.5 The project name that is currently being built (actually it is project folder name) CI_PROJECT_NAMESPACE 8.10 0.5 The project namespace (username or groupname) that is currently being built CI_PROJECT_PATH 8.10 0.5 The namespace with project name CI_PROJECT_PATH_SLUG 9.3 all $CI_PROJECT_PATH lowercased and with everything except 0-9 and a-z replaced with -. Use in URLs and domain names. CI_PROJECT_URL 8.10 0.5 The HTTP address to access project CI_PROJECT_VISIBILITY 10.3 all The project visibility (internal, private, public) CI_REGISTRY 8.10 0.5 If the Container Registry is enabled it returns the address of GitLab’s Container Registry CI_REGISTRY_IMAGE 8.10 0.5 If the Container Registry is enabled for the project it returns the address of the registry tied to the specific project CI_REGISTRY_PASSWORD 9.0 all The password to use to push containers to the GitLab Container Registry CI_REGISTRY_USER 9.0 all The username to use to push containers to the GitLab Container Registry CI_REPOSITORY_URL 9.0 all The URL to clone the Git repository CI_RUNNER_DESCRIPTION 8.10 0.5 The description of the runner as saved in GitLab CI_RUNNER_EXECUTABLE_ARCH all 10.6 The OS/architecture of the GitLab Runner executable (note that this is not necessarily the same as the environment of the executor) CI_RUNNER_ID 8.10 0.5 The unique id of runner being used CI_RUNNER_REVISION all 10.6 GitLab Runner revision that is executing the current job CI_RUNNER_TAGS 8.10 0.5 The defined runner tags CI_RUNNER_VERSION all 10.6 GitLab Runner version that is executing the current job CI_SERVER all all Mark that job is executed in CI environment CI_SERVER_NAME all all The name of CI server that is used to coordinate jobs CI_SERVER_REVISION all all GitLab revision that is used to schedule jobs CI_SERVER_VERSION all all GitLab version that is used to schedule jobs CI_SERVER_VERSION_MAJOR 11.4 all GitLab version major component CI_SERVER_VERSION_MINOR 11.4 all GitLab version minor component CI_SERVER_VERSION_PATCH 11.4 all GitLab version patch component CI_SHARED_ENVIRONMENT all 10.1 Marks that the job is executed in a shared environment (something that is persisted across CI invocations like shell or ssh executor). If the environment is shared, it is set to true, otherwise it is not defined at all. GET_SOURCES_ATTEMPTS 8.15 1.9 Number of attempts to fetch sources running a job GITLAB_CI all all Mark that job is executed in GitLab CI environment GITLAB_USER_EMAIL 8.12 all The email of the user who started the job GITLAB_USER_ID 8.12 all The id of the user who started the job GITLAB_USER_LOGIN 10.0 all The login username of the user who started the job GITLAB_USER_NAME 10.0 all The real name of the user who started the job RESTORE_CACHE_ATTEMPTS 8.15 1.9 Number of attempts to restore the cache running a job GitLab 9.0 renaming 8.x name 9.0+ name CI_BUILD_ID CI_JOB_ID CI_BUILD_REF CI_COMMIT_SHA CI_BUILD_TAG CI_COMMIT_TAG CI_BUILD_BEFORE_SHA CI_COMMIT_BEFORE_SHA CI_BUILD_REF_NAME CI_COMMIT_REF_NAME CI_BUILD_REF_SLUG CI_COMMIT_REF_SLUG CI_BUILD_NAME CI_JOB_NAME CI_BUILD_STAGE CI_JOB_STAGE CI_BUILD_REPO CI_REPOSITORY_URL CI_BUILD_TRIGGERED CI_PIPELINE_TRIGGERED CI_BUILD_MANUAL CI_JOB_MANUAL CI_BUILD_TOKEN CI_JOB_TOKEN .gitlab-ci.yml定义的变量GitLab CI允许您添加在构建环境中设置的.gitlab-ci.yml变量。因此，变量保存在存储库中，它们用于存储非敏感项目配置。 组/库级别变量这个变量在Web UI上进行配置。 .gitlab-ci.yml配置使用.gitlab-ci.yml配置你的Jobs，该文件是GitLab Runner用来管理项目作业的文件。 JobsYAML文件定义了一组具有约束的作业，说明应该何时运行它们。您可以指定无限数量的作业，这些作业被定义为具有任意名称的顶级元素，并且始终必须至少包含script子句。可以是直接运行命令，也可以写成xxx.sh脚本，然后执行此脚本。 123456#两个单独的作业，执行各自的命令job1: script: "execute-script-for-job1"job2: script: "execute-script-for-job2" Runner选择Job并在Runner的环境中执行。重要的是，每项工作都是相互独立运作的，这里可对比Jenkins里面的workspace。 每个作业必须具有唯一的名称，但有一些保留的关键字(keywords)不能用作作业名称: image services stages types before_script after_script variables cache 作业由定义作业行为的参数列表定义: Keyword Required Description script yes Defines a shell script which is executed by Runner extends no Defines a configuration entry that this job is going to inherit from image no Use docker image, covered in Using Docker Images services no Use docker services, covered in Using Docker Images stage no Defines a job stage (default: test) type no Alias for stage variables no Define job variables on a job level only no Defines a list of git refs for which job is created except no Defines a list of git refs for which job is not created tags no Defines a list of tags which are used to select Runner allow_failure no Allow job to fail. Failed job doesn’t contribute to commit status when no Define when to run job. Can be on_success, on_failure, always or `manual dependencies no Define other jobs that a job depends on so that you can pass artifacts between them artifacts no Define list of job artifacts cache no Define list of files that should be cached between subsequent runs before_script no Override a set of commands that are executed before job after_script no Override a set of commands that are executed after job environment no Defines a name of environment to which deployment is done by this job coverage no Define code coverage settings for a given job retry no Define when and how many times a job can be auto-retried in case of a failure parallel no Defines how many instances of a job should be run in parallel extendsextends定义了一个使用extends的作业将继承的条目名称。 这是使用YAML锚点(anchor)的替代方案，并且更加灵活和可读： 12345678910111213.tests: script: rake test stage: test only: refs: - branchesrspec: extends: .tests script: rake rspec only: variables: - $RSPEC 在上面的示例中，rspec作业继承自.tests模板作业。GitLab将根据键执行反向深度合并。GitLab将: 将rspec内容以递归方式合并到.tests中 Not merge the values of the keys 这导致以下rspec作业: 123456789#注意，script: rake test将被script: rake rspec覆盖rspec: script: rake rspec stage: test only: refs: - branches variables: - $RSPEC 如果想要包含rake test, 请查看before_script-and-after_script.extends支持多级继承，但不建议使用三级以上。支持的最大嵌套级别为10。 一下栗子具有两级继承: 123456789101112131415161718192021.tests: only: - pushes.rspec: extends: .tests script: rake rspecrspec 1: variables: RSPEC_SUITE: '1' extends: .rspecrspec 2: variables: RSPEC_SUITE: '2' extends: .rspecspinach: extends: .tests script: rake spinach pagespages是一项特殊工作，用于将静态内容上传到GitLab，可用于为您的网站提供服务。它有一个特殊的语法，因此必须满足以下两个要求： 任何静态内容都必须放在public/目录下 须定义具有public/目录路径的artifacts 1234567891011pages: stage: deploy script: - mkdir .public - cp -r * .public - mv .public public artifacts: paths: - public only: - master 更多详细信息请参考GitLab Pages。 image and services这允许指定自定义Docker镜像和可用于作业时间的服务列表。 before_script and after_scriptbefore_script用于定义应在所有作业（包括部署作业）之前，在恢复工件(artifacts)之后，运行的命令；这可以是数组或多行字符串。after_script用于定义将在所有作业（包括失败的作业）之后运行的命令。这必须是数组或多行字符串。 before_script和main script连接在一个上下文/容器中运行。after_script是单独运行的，因此根据执行程序，在工作树之外完成的更改可能不可见。 如果在每个工作中定义了before_script和after_script，则可以覆盖全局定义： 12345678910before_script: - global before scriptjob: before_script: - execute this instead of global before script script: - my command after_script: - execute this after my script stagesstages用于在全局范围定义可由作业使用的阶段。stages规范允许具有灵活的多级阶段管道(multi stage pipeline)。stages元素的排序定义了作业执行的顺序: 同一阶段的作业是并行运行的 下一阶段的作业在上一阶段的作业成功完成之后运行 让我们考虑以下示例，它定义了3个阶段： 1234567891011stages: - build - test - deploy#首先，build阶段的所有作业都是并行执行的#如果build阶段的所有作业都成功，则test阶段的作业将并行执行#如果test阶段的所有作业都成功，则deploy阶段的作业将并行执行#如果deploy阶段的所有作业都成功，则commit将被标记为passwd#如果任何先前的作业失败，则commit被标记为failed，并且不执行其他阶段的作业 有两个边缘案例值得注意： 如果在.gitlab-ci.yml文件中没有定义stages，build、test和deploy用作默认情况允许的作业阶段； 如果作业未指定stage，则为作业分配test阶段 stagestage是按工作定义的，依赖于全局定义的stages。它允许将作业分组到不同的阶段，并且同一阶段的作业并行执行: 1234567891011121314151617181920stages: - build - test - deployjob 1: stage: build script: make build dependenciesjob 2: stage: build script: make build artifactsjob 3: stage: test script: make testjob 4: stage: deploy script: make deploy types不推荐使用types，可以在以后的某个版本中删除。请使用stages替代它。 scriptscript是作业所需的唯一必需关键字。这是一个由Runner执行的shell script。 123#栗子job: script: "bundle exec rspec" 此参数还可以包含使用数组的多个命令： 1234job: script: - uname -a - bundle exec rspec 有时，脚本命令需要用单引号或双引号括起来，例如命令中有特殊字符的时候。 only和except(简单)only和except两个参数，用于创建作业时设置作业策略来限制它: only定义作业将运行的branch和tag的名称 except定义作业不会运行的branch和tag的名称 有一些适用于作业策略的规则： only和except是包容性的，如果在作业规范中定义了only和except，则ref被only和except过滤 only和except允许使用正则表达式: Ruby regexp syntax only和except允许指定一个Repo path来为forks过滤作业 另外，only和except允许使用如下关键字: Value Description branches When a git reference of a pipeline is a branch tags When a git reference of a pipeline is a tag api When pipeline has been triggered by a second pipelines API (not triggers API) external When using CI services other than GitLab pipelines For multi-project triggers, created using the API with CI_JOB_TOKEN pushes Pipeline is triggered by a git push by the user schedules For scheduled pipelines triggers For pipelines created using a trigger token web For pipelines created using Run pipeline button in GitLab UI (under your project’s Pipelines) merge_requests When a merge request is created or updated 123456789101112131415161718192021222324252627#job将仅针对以issue-开头的refs运行，而所有分支都将被跳过job: # use regexp only: - /^issue-.*$/ # use special keyword except: - branches#job将仅对tagged refsjob: # use special keywords only: - tags - triggers - schedules#repo path可用于仅为parent repo而不是forks执行作业#将为除了master的gitlab-org/gitlab-ce上的所有分支运行jobjob: only: - branches@gitlab-org/gitlab-ce except: - master@gitlab-org/gitlab-ce 如果作业既没有only也没有except规则，则默认设置为only: [&#39;branches&#39;, &#39;tags&#39;]: 123456789#未配置job: script: echo 'test'#它被转换为下面这个样子job: script: echo 'test' only: ['branches', 'tags'] only和except(复杂) refs and kubernetes policies introduced in GitLab 10.0. variables policy introduced in GitLab 10.7. changes policy introduced in GitLab 11.4. 这是一个alpha功能，它可能随时更改，恕不另行通知！ GitLab支持简单和复杂的策略，因此可以使用数组和哈希配置方案。提供了4个key: refs variables changes kubernetes 可以使用AND组合多可键。 only: refs except: refs 12345deploy: only: refs: - master - schedules only: kubernetes except: kubernetes 1234#kubernetes策略只接受active关键字deploy: only: kubernetes: active only: variables except: variables 123456789#variables关键字用于定义变量表达式deploy: script: cap staging deploy only: refs: - branches variables: - $RELEASE == "staging" - $STAGING only: changes except: changes 1234567891011#是否应该根据git push事件修改的文件来创建作业docker build: script: docker build -t my-image:$CI_COMMIT_REF_SLUG . only: changes: - Dockerfile - docker/scripts/* - dockerfiles/**/* - more_scripts/*.&#123;rb,py,sh&#125;#这个例子中，只要有上面几个文件或文件夹内的内容发生了commit push tagstags从允许运行此项目的所有Runner中选择特定Runner。在注册Runner期间，您可以指定Runner的tag。tags允许你使用分配了特定标签的Runner运行作业。 12345678910111213141516171819202122job: tags: - ruby - postgres#栗子windows job: stage: - build tags: - windows script: - echo Hello, %USERNAME%!osx job: stage: - build tags: - osx script: - echo "Hello, $USER!" allow_failureallow_failure允许作业失败而不会影响CI套件的其余部分。除手动作业外，默认值为false。启用并且作业失败后，作业将在UI中显示橙色警告。但是，管道的逻辑流程将认为作业成功/通过，并且不会被阻止。假设所有其它作业都成功，作业的阶段及其管道将显示相同的橙色警告。但是，关联的提交将被标记为passed，而不会发出警告。 123456789101112131415job1: stage: test script: - execute_script_that_will_fail allow_failure: truejob2: stage: test script: - execute_script_that_will_succeedjob3: stage: deploy script: - deploy_to_staging whenwhen用于实现在发生故障或尽管失败时运行的作业，它有以下值: on_success： 只有当前几个阶段的所有工作都成功时才执行工作 on_failure： 仅当前一阶段中的至少一个作业失败时才执行作业 always： 无论先前阶段的工作状态如何，都可以执行工作 manual： 手动执行作业 delayed： 延迟执行作业(GitLab v11.4) 12345678910111213141516171819202122232425262728293031323334stages: - build - cleanup_build - test - deploy - cleanupbuild_job: stage: build script: - make buildcleanup_build_job: stage: cleanup_build script: - cleanup build when failed when: on_failuretest_job: stage: test script: - make testdeploy_job: stage: deploy script: - make deploy when: manualcleanup_job: stage: cleanup script: - cleanup after jobs when: always 手动操作是一种特殊类型的作业，不会自动执行，需要由用户明确启动。(例如，部署到生产环境)手动操作可以是可选的也可以是阻止的。阻止手动操作将在定义此操作的阶段阻止管道的执行。当有人通过单击播放按钮执行阻止手动操作时，可以继续执行管道。默认情况下，手动操作是非阻止的。如果要阻止手动操作，则需要添加allow_failure：false。手动操作被视为写入操作，因此当用户想要触发操作时，将使用受保护分支的权限。换句话说，为了触发分配给管道运行的分支的手动操作，用户需要具有合并到该分支的能力。 when: delayed，延迟作业用于在一段时间后执行脚本。如果要避免作业立即进入暂挂(pending)状态，这非常有用。你可以使用start_in键来设置时期，它的值是以秒(s)为单位的经过时间，或者你提供时间单位，它的值必须小于等于一小时。当阶段中的作业延迟时，管道将不会进展，直到延迟作业完成。这意味着此关键字也可用于在不同阶段之间插入延迟。延迟作业的计时器在前一阶段完成后立即开始。与其他类型的作业类似，除非前一阶段过去，否则延迟作业的计时器将无法启动。 12345678910#10 seconds#30 minutes#1 hour#栗子timed rollout 10%: stage: deploy script: echo &apos;Rolling out 10% ...&apos; when: delayed start_in: 30 minutes 您可以通过单击Unschedule按钮来停止延迟作业的活动计时器。除非您手动执行作业，否则将来不会执行此作业。您可以通过单击Play按钮立即开始延迟作业。 GitLab Runner很快就会选择你的工作并开始工作。 environmentenvironment用于定义作业部署到特定环境。如果指定了environment且该名称下没有环境，则将自动创建一个新环境。它有如下几个值: name url on_stop action 1234567891011121314151617181920212223242526272829303132333435363738#常见的名字有qa, staging, production#但你可以为你的工作流使用任何名称deploy to production: stage: deploy script: git push production HEAD:master environment: name: production#url是一个可选值#在设置时，它会在GitLab中的各个位置公开按钮，单击这些按钮会转到定义的URL#如果作业成功完成，它将在合并请求和environments/deployments页面中创建指向url的按钮deploy to production: stage: deploy script: git push production HEAD:master environment: name: production url: https://prod.example.com#on_stop来实现closing(stopping)环境。它声明了一个不同的工作，以便关闭环境#action与on_stop一起使用，在被调用以关闭环境的作业中定义review_app: stage: deploy script: make deploy-app environment: name: review on_stop: stop_review_appstop_review_app: stage: deploy script: make delete-app when: manual environment: name: review action: stop Dynamic environments123456deploy as review app: stage: deploy script: make deploy environment: name: review/$CI_COMMIT_REF_NAME url: https://$CI_ENVIRONMENT_SLUG.example.com/ cache Notes: Introduced in GitLab Runner v0.7.0 cache can be set globally and per-job From GitLab 9.0, caching is enabled and shared between pipelines and jobs by default-From GitLab 9.2, caches are restored before artifacts cache用于指定应在作业之间缓存的文件和目录列表，您只能使用项目工作区内的路径。如果在作业范围之外定义了cache，则表示它是全局设置的，并且所有作业都将使用该定义。 它的几个值: paths key untracked policy 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#paths指令选择要缓存的文件或目录。支持通配符rspec: script: test cache: paths: - binaries/*.apk - .config#由于cache是在作业之间共享的，如果对不同的作业使用不同的路径，则还应设置不同的cache:key，否则缓存内容可以被覆盖#key指令允许您定义作业之间的缓存关联，允许为所有作业提供single cache，cache per-job，cache per-branch或适合您工作流的任何其他方式cache: key: "$CI_COMMIT_REF_SLUG" paths: - binaries/#untracked：true缓存Git存储库中未跟踪的所有文件rspec: script: test cache: untracked: true paths: - binaries/#policy的默认行为是在执行开始时下载文件，并在结束时重新上载它们#这允许将作业所做的任何更改保留以供将来运行，并称为pull-push缓存策略#这有助于加快作业执行速度并减少缓存服务器上的负载，尤其是当您有大量并行执行缓存的作业时。stages: - setup - testprepare: stage: setup cache: key: gems paths: - vendor/bundle script: - bundle install --deploymentrspec: stage: test cache: key: gems paths: - vendor/bundle policy: pull script: - bundle exec rspec ... artifacts Notes: Introduced in GitLab Runner v0.7.0 for non-Windows platforms. Windows support was added in GitLab Runner v.1.0.0. From GitLab 9.2, caches are restored before artifacts. Not all executors are supported. Job artifacts are only collected for successful jobs by default. artifacts用于指定成功后应附加到作业的文件和目录列表。作业成功完成后，工件将被发送到GitLab，并可在GitLab UI中下载。 有以下值: paths name untracked when when: on_success when: on_failure when: always expire_in reports reports:junit reports:codequality reports:sast reports:dependency_scanning reports:container_scanning reports:dast reports:license_management reports:performance 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#artifacts:paths#要在不同作业之间传递工件，只能使用项目工作区内的路径default-job: script: - mvn test -U except: - tagsrelease-job: script: - mvn package -U artifacts: paths: - target/*.war only: - tags#artifacts:name#定义创建的工件归档的名称job: artifacts: name: "$CI_JOB_NAME" paths: - binaries/#artifacts:untracked#用于将所有Git未跟踪文件添加为工件artifacts: untracked: true paths: - binaries/#artifacts:when#用于在作业失败时上传工件job: artifacts: when: on_failure#artifacts:expire_in#允许您指定工件在到期之前应该存在多长时间并因此被删除，从它们上载和存储在GitLab上的时间开始计算#如果未定义到期时间，则默认为实例范围设置(默认30天)#到期后，每小时定时任务删除工件#默认单位是秒，支持提供时间单位#‘42’#‘3 mins 4 sec’#‘2 hrs 20 min’#‘2h20min’#‘6 mos 1 day’#‘47 yrs 6 mos and 4d’#‘3 weeks and 2 days’job: artifacts: expire_in: 1 week#artifacts:reports#用于从工作中收集测试报告并在GitLab UI中公开它们 dependencies此功能应与artifacts结合使用，并允许您定义要在不同作业之间传递的工件要使用此功能，请在作业上下文中定义dependencies，并传递应从中下载工件的所有先前作业的列表。 如果作为依赖项设置的作业的工件已过期或已擦除，则相关作业将失败。 1234567891011121314151617181920212223242526272829303132#当执行test:osx时，将在构建的上下文中下载并提取build:osx中的工件#test:linux也是如此，要从build: linux拉取工件build:osx: stage: build script: make build:osx artifacts: paths: - binaries/build:linux: stage: build script: make build:linux artifacts: paths: - binaries/test:osx: stage: test script: make test:osx dependencies: - build:osxtest:linux: stage: test script: make test:linux dependencies: - build:linuxdeploy: stage: deploy script: make deploy coverage允许您配置从作业输出中提取代码覆盖率的方式，正则表达式是此处唯一有效的值。 123job1: script: rspec coverage: '/Code coverage: \d+\.\d+/' retry允许您配置在发生故障时重试作业的次数。如果重试作业成功完成，则不会再进行剩余的重试。它的值为2&gt;=retry&gt;=0的正整数。 要更好的控制retry，可使用以下key: max: 最大重试次数 when: 败的情况下重试 always: 重试任何失败 (default) unknown_failure: 失败原因未知时重试 script_failure: 脚本失败时重试 api_failure: API失败重试 stuck_or_timeout_failure: 当作业卡住或超时时重试 runner_system_failure: 如果Runner故障，重试 missing_dependency_failure: 如果缺少依赖项，重试 runner_unsupported: 如果Runner不受支持，重试 123456789101112test: script: rspec retry: 2test: script: rspec retry: max: 2 when: - runner_system_failure - stuck_or_timeout_failure parallel允许您配置并行运行的作业实例数，它的值50&gt;=parallel&gt;=2。 1234#简单栗子test: script: rspec parallel: 5 include Introduced in GitLab Premium 10.5 使用include，可以允许包含外部YAML文件(本地Repo或远程URL)，但也需要为.yml和.yaml扩展格式。 1234567# Content of .gitlab-ci.ymlinclude: 'https://gitlab.com/awesome-project/raw/master/.before-script-template.yml'rspec: script: - bundle exec rspec variables 整数(浮点数)对于变量是有效的，浮点数无效。 GitLab CI/CD允许你在.gitlab-ci.yml中定义变量，然后在作业环境中传递。变量可以是全局的，也可以是基于每个作业的。当在作业级别定义了与全局或项目相同名称的变量时，则作业级别的变量会覆盖它们。 12variables: DATABASE_URL: "postgres://postgres@postgres/my_database" 特殊YAML功能可使用特殊的YAML功能，如锚点(anchors&amp;)、别名(aliases*)、map merging (&lt;&lt;)等，这大大降低了.gitlab-ci.yml的复杂性。 Hidden keys (jobs)如果要暂时禁用作业，而不是注释掉定义作业的所有行，你可是在作业名前加一个点(.)，这样GitLab CI将会忽略它。 123456789#hidden_job:# script:# - run test.hidden_job: script: - run test AnchorsYAML的锚点功能此处就不赘述了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#使用锚点和map merging.job_template: &amp;job_definition script: - test project.postgres_services: services: &amp;postgres_definition - postgres - ruby.mysql_services: services: &amp;mysql_definition - mysql - rubytest:postgres: &lt;&lt;: *job_definition services: *postgres_definitiontest:mysql: &lt;&lt;: *job_definition services: *mysql_definition---#扩展应该为这个样子.job_template: script: - test project.postgres_services: services: - postgres - ruby.mysql_services: services: - mysql - rubytest:postgres: script: - test project services: - postgres - rubytest:mysql: script: - test project services: - mysql - ruby Pipelines for MRPipelines for merge requests Note: 从GitLab v11.10开始，由于recent refspecs changes，Pipeline for merge requests需要GitLab Runner v11.9+。任何较低版本将导致Pipeline失败。Introduced in GitLab 11.6. 通常，在创建新的合并请求(MR)时，管道(pipeline)会使用新的更改运行，并检查它是否有资格合并到目标分支中。此管道仅包含用于验证新更改的必要作业。例如，在此周期中使用单元测试… 使用合并请求的管道，你可以在合并请求中运行管道时设计特定的管道结构。这可能是添加或删除管道中的步骤，以确保管道尽可能高效。 为MR配置管道Configuring pipelines for merge requests 要为合并请求配置管道，请将only: merge_requests参数添加到要仅为合并请求运行的作业。然后，当开发人员每次创建或更新合并请求时，每次将提交推送到GitLab时都会运行管道。 Note: If you use this feature with merge when pipeline succeeds, pipelines for merge requests take precedence over the other regular pipelines. 栗子.gitlab-ci.yml： 12345678910111213141516171819202122232425262728build: stage: build script: ./build only: - mastertest: stage: test script: ./test only: - merge_requests# multi conditions# only:# - test# - merge_requests# - tags# only默认是或操作，上面三个条件即是 test OR merge_requests OR tags# 下面介绍如何使用不并操作# only:# - test &amp;&amp; tags# - test AND $name == 'bingo'# - test AND NOT $name == 'zhang'deploy: stage: deploy script: ./deploy only: - master 使用新提交(commit)更新合并请求后： GitLab检测到已发生更改并为合并请求创建新管道 管道从源分支获取(fetch)最新代码并对其进行测试 Pipelines tagged with the detached badge indicate that they were triggered when a merge request was created or updated. Pipelines for Merged Results Introduced in GitLab Premium 11.10. This feature is disabled by default until we resolve issues with contention handling, but can be enabled manually. 商业版的功能，此处不介绍。 Merge when pipeline succeeds查看准备合并但仍有一个或多个CI作业运行的合并请求时，可以将其设置为在作业管道成功时自动合并(merged automatically)。这样，你不必等待作业完成，并记住去手动合并请求。 如何工作当您点击管道成功时合并(Merge When Pipeline Succeeds)按钮时，将更新合并请求的状态以表示即将发生的合并。如果你无法等待管道成功并希望立即合并，则可以在配置中启用此选项。 开发者和MR发起者都可以选择取消自动合并，如果他们找到了不应该自动合并的原因。 管道成功后，合并请求将自动合并。当管道发生故障时，MR作者有机会重试任何失败的作业，或推送新的提交来修复失败。在第二次尝试作业并成功时，合并请求将自动合并。使用新提交更新合并请求时，将自动取消自动合并以允许检查新更改。 Only allow MR to be merged if the pipeline succeeds如果合并请求的管道未成功或有待解决的问题，则可以阻止合并请求的合并。 在项目-&gt;设置-&gt;通用-&gt;合并请求-&gt;Merge checks中，选择Pipelines must succeed，单击保存以生效。 现在开始，每个管道发生故障时，你都无法合并Web UI中的合并请求，知道你通过所有相关的作业为止。 Scheduling Pipelines我们也可以使用定时任务的方式来触发Pipeline。在项目-&gt;CI/CD-&gt;计划(Sheduling)里面配置流水线计划，来定时运行Pipeline。 在GitLab CI中使用git submodulesUsing Git submodules with GitLab CI 注意：GitLab 8.12 introduced a new CI job permissions model and you are encouraged to upgrade your GitLab instance if you haven’t done already. If you are not using GitLab 8.12 or higher, you would need to work your way around submodules in order to access the sources of e.g., gitlab.com/group/project with the use of SSH keys.With GitLab 8.12 onward, your permissions are used to evaluate what a CI job can access. More information about how this system works can be found in the Jobs permissions model.（CI jobs 默认有权限拉取所有项目）The HTTP(S) Git protocol must be enabled in your GitLab instance. 好像之前需要先关联子模块，否则GitLab里面的.gitmodules它不生效。这个在你配置的时候先不做，如果不生效再来坐这一步。 12# project 关联 project-01git submodule add git@git.xxx.com/groupB/project-01.git 配置.gitmodules文件如果要处理Git submodules，你的项目需要一个名为.gitmodules的文件。 如果你使用GitLab v8.12+，并且你的子模块也位于同一GitLab Server上，则必须更新.gitmodules文件以使用relative URLs。由于Git允许使用.gitmodules配置相对URL，因此你可以轻松使用HTTP(S)克隆所有CI作业，并使用SSH进行所有本地checkout。 项目在同一个GitLab Server的.gitmodules示例： 123456789[submodule &quot;project-01&quot;] path = project-01 url = ../groupB/project-01.git branch = test[submodule &quot;project-02&quot;] path = project-02 url = ../project-02.git branch = master 上述配置将指示Git自动推断克隆源时应使用的URL。 对于不在同一GitLab Server上的其它子模块，请使用完整的HTTP(S)协议的URL： 1234[submodule &quot;project-x&quot;] path = project-x url = https://gitserver.com/group/project-x.git branch = master 一旦正确配置了.gitmodules，你就可以去配置.gitlab-ci.yml。 在CI中使用git submodules 首先，确保你已使用位于同一GitLab Server中的子模块的相对URL 如果你使用GitLab Runner v1.10+，你可将GIT_SUBMODULE_STRATEGY变量设置为normal或recursive，以告知Runner在作业之前获取子模块 1234567891011variables: GIT_SUBMODULE_STRATEGY: recursivebefore_script: - git submodule sync --recursive - git submodule update --init --recursive --remote #- git submodule update --init --recursive # 如果你使用旧版本的GitLab Runner，使用 git submodule sync/update # --recursive should be used in either both or none (sync/update) depending on whether you have recursive submodules # - git submodule sync/update 在before_script中设置同步和更新的基本原理是由于Git子模块的工作方式。在新的Runner Workspace中，Git将根据.gitmodules和当前远程URL设置.git/config中包含子模块的URL。 123456789101112131415cat .git/config[core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true[remote &quot;origin&quot;] url = git@git.xxx.com:groubA/test/project.git fetch = +refs/heads/*:refs/remotes/origin/*[branch &quot;master&quot;] remote = origin merge = refs/heads/master[submodule &quot;project-01&quot;] url = git@git.xxx.com:groupB/project-01.git 这里面显示的是子模块的完整URL。 最后，在GitLab Web UI中看一下显示效果。 GitLab CI/CD栗子各种语言、框架 、操作系统 CI/CD栗子: https://docs.gitlab.com/ce/ci/examples/README.html PHP Ruby Python Java Scala Clojure Elixir IOS and MacOS Android Debian Maven Git配置项Git configuration options 自定Git hooksCustom Git hooks: Custom Git hooks (on the filesystem) for when webhooks aren’t enough 注意：必须在GitLab服务器的文件系统上配置自定义Git hooks。只有GitLab服务器管理员才能完成这些任务。 Git本身支持在不同操作上执行的hooks。服务器端git hooks的示例包括预接收，后接收和更新。从gitlab-shell 2.2.0版（需要GitLab 7.5+）开始，GitLab管理员可以为任何GitLab项目添加自定义git hooks。 配置通常，Githooks放在存储库或项目的hooks目录中。 GitLab从每个项目的hooks目录创建一个符号链接到gitlab-shell hooks目录，以便于gitlab-shell升级之间的维护。因此，自定义挂钩的实现方式略有不同。但是，一旦创建了钩子，行为就完全相同了。 请按照以下步骤设置自定义hooks： 选择一个需要自定义Git hook的项目 在GitLab Server，导航到项目的存储库目录(如: /var/opt/gitlab/git-data/repositories/user/xx.git) 此位置创建名为custom_hooks的新目录 在custom_hooks目录中，创建一个名称与hook类型匹配的文件(如: pre-hook) 修改hook文件属主为git，添加可执行权限 编写代码以使Git hook函数按预期方式运行，可以是任何语言。确保顶部的shebang(#!/bin/python3)正确反映语言类型 假设正确实现了hook代码，hook将适当地触发。 链式hookChained hooks support 在GitLab Shell 4.1.0和GitLab 8.15中引入 hook也可以放在hook/&lt;hook_name&gt;.d（全局）或custom_hooks/&lt;hook_name&gt;.d（每个项目）目录中，支持钩子的链式执行。注意：&lt;hook_name&gt;.d需要pre-receive.d，post-receive.d或update.d才能正常工作。任何其他名称都将被忽略 要查看全局自定义hook（hook/&lt;hook_name.d&gt;）中的不同目录，请在gitlab-shell config中设置custom_hooks_dir。对于Omnibus安装，可在gitlab.rb中设置。 按以下顺序搜索并执行hook： gitlab-shell/hooks directory as known to Gitaly &lt;project&gt;.git/hooks/&lt;hook_name&gt; - executed by git itself, this is gitlab-shell/hooks/&lt;hook_name&gt; &lt;project&gt;.git/custom_hooks/&lt;hook_name&gt; - per project hook &lt;project&gt;.git/custom_hooks/&lt;hook_name&gt;.d/* - per project hooks &lt;project&gt;.git/hooks/&lt;hook_name&gt;.d/* OR &lt;custom_hooks_dir&gt;/&lt;hook_name.d&gt;/* - global hooks: all executable files 自定义错误信息Custom error messages 在GitLab 8.10中引入 如果commit被拒绝或在Git hook检查期间发生错误，则钩子的STDERR或STDOUT消息将出现在GitLab的UI中，STDERR优先于STDOUT。 Git LFS Git LFS: https://docs.gitlab.com/ce/workflow/lfs/manage_large_binaries_with_git_lfs.html Git LFS config: https://docs.gitlab.com/ce/workflow/lfs/lfs_administration.html 管理音频，视频和图形文件等大文件一直是Git的缺点之一。一般建议是不要让Git存储库大于1GB以保持性能。 HousekeepingHousekeeping(管家): Keep your Git repositories tidy and fast 在GitLab 8.4中引入 Automatic housekeeping在Git push后，GitLab会自动在存储库上运行git gc和git repack命令。如果需要，您可以更改这种情况发生的频率，或者将其关闭。在Admin ares -&gt; Setting Manual housekeepinghousekeeping功能将运行gc还是repack，取决于你的设置。 Git协议Configuring Git Protocol v2: Git protocol version 2 support 在GitLab 11.4中引入 Git第二版协议以多种方式改进了第一版协议，并且在GitLab中默认为HTTP请求启用。要为SSH启用，管理员需要进一步配置。 Requirements： 客户端，git v2.18.0+ 服务端，如果要配置SSH，需要设置sshd以接受GIT_PROTOCOL环境变量 12345678910111213141516171819202122232425262728293031323334#/etc/ssh/sshd_configAcceptEnv GIT_PROTOCOLsudo service ssh restart#配置新协议#局部git -c protocol.version=2#全局git config --global protocol.version 2#验证#HTTP#C端GIT_TRACE_CURL=1 git -c protocol.version=2 ls-remote https://your-gitlab-instance.com/group/repo.git 2&gt;&amp;1 | grep Git-Protocol#S端GIT_TRACE_PACKET=1 git -c protocol.version=2 ls-remote https://your-gitlab-instance.com/group/repo.git 2&gt;&amp;1 | head#SSH#C端GIT_SSH_COMMAND=&quot;ssh -v&quot; git -c protocol.version=2 ls-remote ssh://your-gitlab-instance.com:group/repo.git 2&gt;&amp;1 |grep GIT_PROTOCOL 监控Monitoring GitLab 故障排除Troubleshooting RunnerRunner是GitLab CI的客户端。 作为GitLab持续集成和持续部署(CI/CD)的一部分，主要用来配置和运行构建脚本以及其他的任务。GitLab Runner 是一个开源项目， 它用来运行你定制的任务（jobs）并把结果返回给 GitLab。 GitLab Runner配合GitLab CI（GitLab 内置的持续集成服务）协调完成任务。 要求(Requirements) GitLab Runner是用Go编写的，可以作为单个二进制文件运行，不需要语言特定的要求。它可在多个操作系统上运行，只要你在此平台上编译成二进制文件。支持Docker v1.5+。 特点(Feature) Allows to run: multiple jobs concurrently(同时) use multiple tokens with multiple server (even per-project) limit number of concurrent(并发) jobs per-token Jobs can be run: locally using Docker containers using Docker containers and executing job over SSH using Docker containers with autoscaling on different clouds and virtualization hypervisors connecting to remote SSH server Is written in Go and distributed as single binary without any other requirements Supports Bash, Windows Batch and Windows PowerShell Works on GNU/Linux, OS X and Windows (pretty much anywhere you can run Docker) Allows to customize the job running environment Automatic configuration reload without restart Easy to use setup with support for Docker, Docker-SSH, Parallels or SSH running environments Enables caching of Docker containers Easy installation as a service for GNU/Linux, OSX and Windows Embedded Prometheus metrics HTTP server 兼容性图表(Compatibility chart) GitLab Runner的版本应该与GitLab同步。如果存在版本差异，则功能可能无法使用或无法正常工作。 安装Install GitLab Runner Install using GitLab’s repository for Debian/Ubuntu/CentOS/RedHat (preferred) Install on GNU/Linux manually (advanced) Install on macOS Install on Windows Install as a Docker service Install in autoscaling mode using Docker machine Install on FreeBSD Install on Kubernetes Install the nightly binary manually (development) RepositoryInstall GitLab Runner using the official GitLab repositories 安装： 123456789101112131415161718192021222324252627282930313233343536#添加镜像库# For Debian/Ubuntu/Mintcurl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.deb.sh | sudo bash# For RHEL/CentOS/Fedoracurl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.rpm.sh | sudo bash#安装最新版# For Debian/Ubuntu/Mintsudo apt-get install gitlab-runner# For RHEL/CentOS/Fedorasudo yum install gitlab-runner#安装制定版本# for DEB based systemsapt-cache madison gitlab-runnersudo apt-get install gitlab-runner=10.0.0# for RPM based systemsyum list gitlab-runner --showduplicates | sort -rsudo yum install gitlab-runner-10.0.0-1#注册Runner#注册Runner参考后面 更新： 12345678# For Debian/Ubuntu/Mintsudo apt-get updatesudo apt-get install gitlab-runner# For RHEL/CentOS/Fedorasudo yum updatesudo yum install gitlab-runner 手动下载包安装 下载地址: https://packages.gitlab.com/runner/gitlab-runner 升级到GitLab Runner 10 1234567891011121314#移除旧库# For Debian/Ubuntu/Mintsudo rm /etc/apt/sources.list.d/runner_gitlab-ci-multi-runner.list# For RHEL/CentOS/Fedorasudo rm /etc/yum.repos.d/runner_gitlab-ci-multi-runner.repo#安装新库#再安装 手动安装12345678910111213141516171819202122232425262728293031#下载二进制包# Linux x86-64sudo wget -O /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64# Linux x86sudo wget -O /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-386# Linux armsudo wget -O /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-arm#添加可执行权限sudo chmod +x /usr/local/bin/gitlab-runner#如果想使用Dockercurl -sSL https://get.docker.com/ | sh#Create a GitLab CI user:sudo useradd --comment 'GitLab Runner' --create-home gitlab-runner --shell /bin/bash#Install and run as service:sudo gitlab-runner install --user=gitlab-runner --working-directory=/home/gitlab-runnersudo gitlab-runner start#Register the Runner#更新的话重新下载二进制包安装 Docker123456789101112131415#挂载运行 docker run -d --name gitlab-runner --restart always \ -v /srv/gitlab-runner/config:/etc/gitlab-runner \ -v /var/run/docker.sock:/var/run/docker.sock \ gitlab/gitlab-runner:latest#Register the Runner#更新的话，停止旧容器，拉取新镜像#GitLab Runner Logs#可以把Runner Logs目录挂载到宿主机，也可是使用docker 读取 k8s Autoscale 注册Register GitLab Runner 安装GitLab Runner后，需要将其注册到GitLab。注册Runner是将Runner与GitLab实例绑定的过程。 要求(Requirements)，在注册Runner之前，你需要： 将其安装在与安装GitLab位置不同的Server上 通过GitLab的界面获取共享或特定Runner的Token 注册环境： GNU/Linux macOS Windows FreeBSD Docker … GNU/Linux在GNU / Linux下注册Runner： 12345678910111213141516171819202122232425262728293031323334353637383940#URL和Token在GitLab实例的runner里面去看#运行命令sudo gitlab-runner register#输入GitLab 实例 URLPlease enter the gitlab-ci coordinator URL (e.g. https://gitlab.com )https://gitlab.com#输入获得的tokenPlease enter the gitlab-ci token for this runnerxxx#输入Runner的描述，之后可在Web UI下更改Please enter the gitlab-ci description for this runner[hostame] my-runner#输入与Runner相关联的tag，之后可在Web UI下更改Please enter the gitlab-ci tags for this runner (comma separated):my-tag,another-tag#输入Runner executorPlease enter the executor: ssh, docker+machine, docker-ssh+machine, kubernetes, docker, parallels, virtualbox, docker-ssh, shell:docker#如果您选择Docker作为执行程序，则会要求您未在.gitlab-ci.yml中定义的用于项目的默认imagePlease enter the Docker image (eg. ruby:2.1):alpine:latest#启动runnersudo systemctl start gitlab-runner 单行注册命令One-line registration command 如果要使用非交互模式注册Runner，可以使用register子命令或使用其等效的环境变量。 123456789101112131415#查看帮助gitlab-runner register -h#注册sudo gitlab-runner register \ --non-interactive \ --url "https://gitlab.com/" \ --registration-token "PROJECT_REGISTRATION_TOKEN" \ --executor "docker" \ --docker-image alpine:3 \ --description "docker-runner" \ --tag-list "docker,aws" \ --run-untagged \ --locked="false" \ 执行器Executors GitLab Runner实现了许多执行程序，可用于在不同的场景中运行构建。 执行器： Shell Docker Docker Machine and Docker Machine SSH (autoscaling) Parallels VirtualBox SSH Kubernetes 选择执行器Selecting the executor GitLab Runner实现了许多执行程序，可用于在不同的场景中运行构建。如果您不确定要选择什么，请阅读“我不确定”部分。访问兼容性图表，了解每个执行程序支持哪些功能，哪些功能不支持。 执行器支持不同平台和方法的项目构建： Executor SSH Shell VirtualBox Parallels Docker Kubernetes Clean build environment for every build ✗ ✗ ✓ ✓ ✓ ✓ Migrate runner machine ✗ ✗ partial partial ✓ ✓ Zero-configuration support for concurrent builds ✗ ✗ (1) ✓ ✓ ✓ ✓ Complicated build environments ✗ ✗ (2) ✓ (3) ✓ (3) ✓ ✓ Debugging build problems easy easy hard hard medium medium 不清楚该选择哪个执行器I am not sure ShellShell是最简单的配置执行器。需要在安装Runner的同一台机器上手动安装构建的所有必需依赖项。 Virtual Machine此类执行器允许您使用已创建的虚拟机，该虚拟机已克隆并用于运行构建。我们提供两种完整的系统虚拟化选项：VirtualBox和Parallels。如果您希望在不同的操作系统上运行构建，它们可以证明是有用的，因为它允许在Windows，Linux，OSX或FreeBSD上创建虚拟机，然后GitLab Runner连接到虚拟机并在其上运行构建。它的使用对于降低基础设施成本也很有用。 Docker一个很好的选择是使用Docker，因为它允许一个干净的构建环境，并且易于依赖管理（构建项目的所有依赖项都可以放在Docker镜像中）。 Docker执行程序允许您轻松创建具有依赖服务的构建环境，如MySQL KubernetesKubernetes执行程序允许您使用现有的Kubernetes集群进行构建。执行程序将调用Kubernetes集群API并为每个GitLab CI作业创建一个新的Pod（带有构建容器和服务容器）。 SSH添加SSH执行程序是为了完整性，但它是所有执行程序中支持最少的。它使GitLab Runner连接到外部服务器并在那里运行构建。(通常建议使用其它案例) 兼容性Compatibility 不同执行器支持的功能： Executor SSH Shell VirtualBox Parallels Docker Kubernetes Secure Variables ✓ ✓ ✓ ✓ ✓ ✓ GitLab Runner Exec command ✗ ✓ ✗ ✗ ✓ ✓ gitlab-ci.yml: image ✗ ✗ ✗ ✗ ✓ ✓ gitlab-ci.yml: services ✗ ✗ ✗ ✗ ✓ ✓ gitlab-ci.yml: cache ✓ ✓ ✓ ✓ ✓ ✓ gitlab-ci.yml: artifacts ✓ ✓ ✓ ✓ ✓ ✓ Absolute paths: caching, artifacts ✗ ✗ ✗ ✗ ✗ ✓ Passing artifacts between stages ✓ ✓ ✓ ✓ ✓ ✓ Use GitLab Container Registry private images n/a n/a n/a n/a ✓ ✓ Interactive Web terminal ✗ ✓ (bash) ✗ ✗ ✓ ✓ 不同shell支持的系统： Shells Bash Windows Batch PowerShell Windows ✓ ✓ (default) ✓ Linux ✓ (default) ✗ ✗ OSX ✓ (default) ✗ ✗ FreeBSD ✓ (default) ✗ ✗ 不同shell支持的交互式Web终端： Shells Bash Windows Batch PowerShell Windows ✗ ✗ ✗ Linux ✓ ✗ ✗ OSX ✓ ✗ ✗ FreeBSD ✓ ✗ ✗ ShellShell executor 是一个简单的执行程序，它允许您在运行Runner的机器上本地执行构建。它支持可以安装Runner的所有系统。这意味着它可使用Bash和PowerShell。 在Bash中，在gitlab-runner command命令之后加上--user，表示使用非特权用户运行。 源项目被切换到: &lt;working-directory&gt;/builds/&lt;short-token&gt;/&lt;concurrent-id&gt;/&lt;namespace&gt;/&lt;project-name&gt;项目的缓存放于: &lt;working-directory&gt;/cache/&lt;namespace&gt;/&lt;project-name&gt; 这些都在GitLab-runner的配置: /etc/gitlab-runner/atom.config.toml 以非特权用户运行(Running as unprivileged user) 在Linux上(rpm/dpk)，安装程序将尝试使用gitlab_ci_multi_runner用户(如果找到)；如果找不到，它将创建一个gitlab-runner用户并改为使用它。然后，所有shell build都将使用gitlab-runner或gitlab_ci_multi_runner用户执行。 在某些场景中，您的构建可能需要访问某些特权资源，例如Docker Engine或VirtualBox。在这种情况下，您需要将gitlab-runner用户添加到相应的组： 12usermod -aG docker gitlab-runnerusermod -aG vboxusers gitlab-runner DockerThe Docker executor 文档: https://docs.gitlab.com/runner/executors/docker.html K8sThe Kubernetes executor 文档: https://docs.gitlab.com/runner/executors/kubernetes.html 高级配置Advanced Configuration 配置文件Advanced configuration options Learn how to use the TOML configuration file that GitLab Runner uses. GitLab Runner配置使用TOML格式，配置文件可能在如下位置: /etc/gitlab-runner/config.toml ~/.gitlab-runner/config.toml ./config.toml global部分这定义了GitLab Runner的全局配置。 配置 描述 concurrent 限制全局可以同时运行多少个作业，0并不意味着无限制 log_level 日志级别(debug, info, warn, error, fatal, panic) log_format 日志格式(runner, text, json) check_interval 定义新作业检查之间的间隔长度(s)。默认值为3，如果设置为0或更低，将使用默认值 sentry_dsn 启用追踪所有系统级错误 listen_address host:port，Prometheus应该在其上进行监听 check_interval 如何工作: 如果config.toml配置文件中有多个[[runner]](称之为worker)，那么GitLab请求之间的间隔比人们预期的要频繁。GitLab Runner包含一个循环，该循环不断地为worker针对其配置的GitLab实例调度请求。 [session_server]部分[session_server]是系统运行程序级别的配置，因此应该在根级别指定，而不是每个执行器指定，即它应该在[[runners]]部分之外。session server允许用户与Runner负责的作业进行交互。如果想要禁用[session_server]部分，删掉它即可。 配置 描述 listen_address 用于session server的内部URL advertise_address 向GitLab公开的用于访问Runner的URL session_timeout 作业完成后，会话可以在多长时间内保持活动状态(默认1800s) [[runners]]部分如下定义了Runner entry: 配置 描述 name Runner的描述 url GitLab URL token Runner指定的token tls-ca-file HTTPS的CA证书 tls-cert-file HTTP的S端证书 tls-key-file HTTPS的S端Key limit 限制此token可同时处理的作业数，0为不限制 executor 执行器 shell 用于生成脚本的shell的名称 builds_dir 构建将存储在所选执行器的上下文中的目录(local, docker, ssh) cache_dir 构建缓存将存储在所选执行器的上下文中的目录(local, docker, ssh) environment 附加或覆盖环境变量 request_concurrency 限制GitLab新作业的并发请求数（默认值为1） output_limit 最大构建日志大小(默认4096KB) pre_clone_script 在克隆Git存储库之前要在Runner上执行的命令 pre_build_script 克隆Git存储库之后但在执行构建之前要在Runner上执行的命令 post_build_script 在执行构建之后但在执行after_script之前在Runner上执行的命令 clone_url 覆盖GitLab实例的URL clone_url怎样工作: 如果GitLab实例公开给Runner无法使用的URL，则可以配置clone_url。 EXECUTORS shell docker docker-ssh ssh parallels virtualbox docker+machine docker-ssh+machine kubernetes SHELLS bash sh cmd powershell [runners.docker]部分 参数 描述 host 指定Docker endpoint (默认 $DOCKER_HOST或unix:///var/run/docker.sock) hostname 为Docker容器指定主机名 runtime 为Docker容器指定一个运行环境 tls_cert_path 证书路径 image 使用此镜像进行构建 memory 容器内存限制 memory_swap 总内存限制 memory_reservation 容器内存soft limit oom_kill_disable 容器OOM后也不kill进程 cpuset_cpus 容器使用的CPU cpus CPU数量 dns 容器使用的DNS列表 dns_search DNS搜索域列表 privileged 特权容器 disable_entrypoint_overwrite 禁用镜像端点覆盖 userns_mode 启用usernamespace重映射选项时，为容器设置usernamespace模式 cap_add 向容器添加其他Linux功能 cap_drop 从容器中移除其他Linux功能 security_opt 设置安全选项(key: value) devices 与容器共享其他主机设备 cache_dir 指定缓存目录 disable_cache 禁用缓存 network_mode 将容器添加到一个自定义的网络 wait_for_services_timeout 等待docker的时间，0为禁用(默认30) volumes docker挂载卷 extra_hosts 指定应在容器环境中定义的主机 shm_size 指定镜像共享的内存大小(Byte)) volumes_from 指定从其它容器继承的卷(格式: `\[:\&lt;ro rw>]`) volume_driver 指定容器使用的卷的驱动 links 指定与其建立链接的容器 services 指定使用build运行的其它服务 allowed_images 指定可在.gitlab-ci.yml中指定的通配符图像列表 allowed_services 指定可在.gitlab-ci.yml中指定的通配符服务列表 pull_policy 指定镜像拉取策略 sysctls 指定sysctl options helper_image 覆盖用于克隆repos和上载工件的默认帮助程序镜像 [runners.parallels]部分 参数 描述 base_name 将克隆的Parallels VM的名称 template_name Parallels VM链接模板的自定义名称 disable_snapshots 如果禁用，则在构建之后将摧毁VM [runners.virtualbox]部分 参数 描述 base_name 要克隆的VirtualBox VM的名称 base_snapshot 要从中创建链接克隆的VM的特定快照的名称或UUID disable_snapshots 如果禁用，则在构建之后将摧毁VM [runners.ssh]部分 参数 描述 host 指定主机 port 指定端口 user 指定用户 password 指定密码 identity_file 指定私钥 [runners.machine]部分 Parameter Description IdleCount Number of machines, that need to be created and waiting in Idle state. IdleTime Time (in seconds) for machine to be in Idle state before it is removed. OffPeakPeriods Time periods when the scheduler is in the OffPeak mode. An array of cron-style patterns (described below). OffPeakTimezone Time zone for the times given in OffPeakPeriods. A timezone string like Europe/Berlin (defaults to the locale system setting of the host if omitted or empty). OffPeakIdleCount Like IdleCount, but for Off Peak time periods. OffPeakIdleTime Like IdleTime, but for Off Peak time mperiods. MaxBuilds Builds count after which machine will be removed. MachineName Name of the machine. It must contain %s, which will be replaced with a unique machine identifier. MachineDriver Docker Machine driver to use MachineOptions Docker Machine options [runners.cache]部分 Parameter Type Description Type string One of: s3, gcs Path string Name of the path to prepend to the cache URL Shared boolean Enables cache sharing between runners, false by default [runners.kubernetes]部分 参数 描述 host k8s master url cert_file k8s master认证证书 key_file k8s master 私钥 ca_file k8s master CA image 当未指定时，用于构建的默认docker镜像 namespace 命名空间 privileged 特权容器(true/false) node_selector 节点选择器 image_pull_secrets 镜像拉取秘钥 自签名证书Use self-signed certificates Configure certificates that are used to verify TLS peer when connecting to the GitLab server. 这允许在注册runner时解决由未知权限问题签名的证书(x509)。 支持自签名的证书: 默认情况下： GitLab Runner读取系统存储的证书并根据存储在系统中的CA验证GitLab服务器 GitLab Runner从预定义文件中读取PEM（不支持DER格式）证书: 如/etc/gitlab-runner/certs/ GitLab Runner在注册期间和[[runners]]部分下的config.toml配置中公开tls-ca-file选项，允许您指定带证书的自定义文件。每当Runner尝试访问GitLab服务器时，都会读取此文件。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>GitLab</tag>
        <tag>CI</tag>
        <tag>CD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[英语语法]]></title>
    <url>%2F2018%2F11%2F14%2F%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[参考: 《新概念英语语法手册》 名词概述名词是指人或事物的名称，也包括一些具有抽象概念的名词。 用法 充当动词的主语 12Our &apos;agent&apos; in Cairo sent a telex this morning.#今天早晨我们在开罗的代理人发来一封电传。 作动词的直接宾语 12Frank sent an urgent &apos;telex&apos; from Cairo this morning.#弗兰克今天早上从开罗发来一份加急电传。 作动词的间接宾语 12Frank sent his &apos;boss&apos; a telex.#弗兰克给他的老板发了一份电传。 作介词的宾语 12I read about it in &apos;the China Daily&apos;.#我在中国日报上看到了这个消息。 作be、seem等系动词的表语 12Jones is our &apos;guest&apos;.#琼斯是我们的客人 作同位语 12Laura, &apos;a BBC reporter&apos;, asked for an interview.#劳拉，BBC的记者，要求采访。 复合名词由两个或两个以上的名词部分组合而成的名词，称为复合名词。 复合名词通常有四种构成形式 123456789101112131. 名词+名词a keyboard(键盘)2. 形容词+名词a greenhouse(温室)3. 动名词+名词drinking water(饮用水)4. 名词+动名词sight-seeing(观光) 还有一些复合名词表示特定含义 1Oxford Road, Beijing Capital International Airport 分类 专有名词 专有名词指特定的人、地方、事物或概念，他们被认为是独一无二的。专有名词的开头字母要大写，前面一般不用冠词。 123456789101112131415#人名ParkerMr. Parker#称呼Mum#地名Asia#月份、星期、节日、季节AprilMondayChristmasspring(季节一般不大写) 普通名词 普通名词又可分为可数名词和不可数名词。在普通名词前通常要使用冠词a, an, the… 12345678910111213#可数名词a book, an envelophow many stamps do you have?#不可数名词water, milk, airhow much milk do you have?#既是可数又是不可数He ate much fish yesterday.There are a large variety of fishes in the pond. 复形名词 有些名词虽然形式上是复数形式，即以-s结尾，但实际上却表示单数意义。 1The news is at six. 名词的数 名词的单数形式和复数形式 拼写规则 单数 复数 一般情况下加-s cat cats 以 -o, -x, -ch, -sh 结尾的加 -es potato class box watch brush potatoes classes boxes watches brushes 以 辅音字母加 -y结尾，去-y加-ies 元音字母加 -y 结尾的加 -s country boys countries boys 以 -y 结尾的专有名词加 -s Fry Frys 以 -f, -fe 结尾的名词， 把-f, -fe变为 -ves wife wives 不规则变化 man sheep men sheep 以 -o 结尾一般要在后面加 -es 但元音字母加 -o 结尾的名词则只能加 -s。 不规则拼写法 123foot/feetmouse/micetooth/teeth 单/复数形式相同 1234sheepdeeraricraftChinese 名词的性 阳性 阴性 中性 123acrot(男演员)actress(女演员)guest(客人) 有些名词可以不加思索的用阳性代词he、阴性代词she、中性代词it来指代。表示动物性别相对的名词一般可用it指代。 名词的格 名词所有格的构成 说明 栗子 单数名词末尾加&#39;s child’s 以 -s结尾的单数名词末尾加&#39;s或加&#39; actress’s/actress’ 不规则的复数名词末尾加 &#39;s children’s 以-s结尾的复数名词末尾加 &#39; girls’ 一些以 -s 结尾的人名末尾加 &#39;s James’s 所有格一般表示人或事物的所属概念，通常可以回答Whose...?的问句。 通常来说&#39;s/s&#39;和of的作用是一样的，但&#39;s/s&#39;一般不和无生命的名词连用，而有生命的名词则两者通用。 冠词有若干个词可以用在名词或形容词+名词的前面，我们把这类词统称为限定词(determiners)，因为它们影响或限定着这个名词的意义。冠词就是其中一种。 限定词限定词分为两种： 有助于分类或确认的词 表数量的词 有助于分类或确认的词 不定冠词 123I bought &apos;a&apos; new shirt yesterday.&apos;A&apos; girl came in and put &apos;an&apos; envelope on his desk. 定冠词 1&apos;The&apos; shirt I am wearing is new. 指示代词 1I bought &apos;this/that&apos; shirt yesterday. 物主代词 1&apos;My&apos; shirt is blue. 表示数量的词 数词 1I bought &apos;two&apos; shirts yesterday. 量词 1I didn&apos;t buy &apos;many&apos; new shirts yesterday. 冠词的基本用法冠词分为： 不定冠词(a/an) 定冠词(the) 零冠词 代词代词是用来代替名词或名词短语的。 代词可分为： 人称代词: I, me, he… 物主代词: my, their, yours… 反身代词: myself, herself, themselves… 指示代词: this, that, those… 不定代词: some, many, each, any, all… 疑问代词: what, which… 关系代词: which, who(m), as, that… … 人称代词 主格人称代词在句子中一般用在谓语动词前面，充当句子的主语 1I think, therefore I am. it也可以用来表示人，它一般表示要确认什么人，或在表示弄不清楚小孩儿的性别的时候 1There&apos;s a knock at the door. Who is &apos;it&apos;? 宾格人称代词可代替处于宾语位置上的名词，充当动词或介词的宾语。有些动词接两个宾语：直接宾语和间接宾语。直接宾语指动作的承受者，间接宾语指动作所向的人或物。间接宾语必须与直接宾语连用 123I gave &apos;him&apos; a glass of water.#him 为间接宾语#a glass of water 为直接宾语 使用人称代词时无论主格还是宾格，都应考虑到其所处的具体位置，在系动词be后也可以使用宾格，但不强调 1Who is &apos;it&apos;? 当人称代词处于同位结构中时，应与其同位的部分保持一致。也就是说当其同位的部分为主语时，其同位代词也为主语(用主格)，而当其同位的部分为宾语时，所用代词也为宾语(用宾格) 1Both Jack an &apos;I&apos; can swim very well. 有时候，尤其在口语中，宾格人称代词me也可用作主语 1Me/Not me! 注意祈使句中可用宾格人称代词作主语，起强调作用 1She&apos;s been promoted. Lucky &apos;her&apos;! 关于动物、东西和国家，人们通常将其人格化，这样它们也就具有了阴/阳性 1The cuckoo lays &apos;her&apos; eggs in other birds&apos; nests. 当我们谈论汽车、船、摩托及其它机械时，常常把它们看做阴性 1My car&apos;s not fast, but &apos;she&apos; does 50 miles to the gallon. 国家通常也人格化，经常看成阴性 1In 1941, America assumed &apos;her&apos; role as a world power. 不定代词 不定代词指的是some, any, no, every…以及与之组成的复合词不定代词常常表示不确定的人、物或量。 123someone, anyone, none, everyonesomebody...something... 在表示一些时，some一般用于肯定陈述句中，而any则一般用于疑问句和否定句中 123There are &apos;some&apos; frogs in the pond.There aren&apos;t &apos;any&apos; frogs in the pod. 当表示建议或请求的时候，仍用some或something等 1Would you like &apos;something&apos; to drink? any或anything用于陈述句的肯定形式的时候，表示泛指概念，指任何 1You can choose &apos;anything&apos; you like here. 复合不定代词(如something, anything)等的定语一般应后置 123This is &apos;something&apos; special.Is there &apos;anything&apos; for me to sit on? 当需要排除概念时，经常将else与不定代词连用，构成如下组合词，表示另外的，别的之意 123everyone else, someone else, anyone else, anything else, nothing else...We need one more helper. Can you find &apos;anyone else&apos;? 指代a/an + 可数名词时，则必须用one作宾语 12Would you like a drink?I&apos;d love &apos;one&apos;. Thank you. 当不可数名词或复数名词用于非特指时，则必须使用some或any作宾语 1Have you got &apos;any&apos; sugar? Can you lend me &apos;some&apos;? 物主代词物主代词分为: 形容词性物主代词(或所有格形容词) 名词性物主代词(或所有格代词) 12形容词性: my, your, his, her, its, one's, our, your, their名词性: mine, yours, his, hers,ours, theirs 形容词性物主代词和名词性物主代词都表示所有，即某人或某物属于某个人，回答Whose…?的问题。形容词性物主代词是限定词，因此必须放在名词之前，不可单独使用。它们的形式取决于所有者，而不是被拥有的东西。 12345John&apos;s daugther = his daugtherJane&apos;s son = her sonthe cat&apos;s milk = its milk my, your, their可表示男性所有，也可表示女性所有。 123&quot;My house is there,&quot; Sally/John said.Your passports, please. their也可表示动物或物品所有。 123Dogs should have their own kennels outside the house.Cars with their engines at the back are very noisy. one’s 可用作非人称形容词性物主代词，但不能用作名词性物主代词。 1One&apos;s first duty is to one&apos;s family. 所有格代词mine, yours不能用在名词之前，且在说话时要加重语气。它们在指人或物时，单数或复数都一样。its从来不作所有格代词用。 123There are my children. These children are mine.I can&apos;t find my pen. Can you lend me yours? 名词性所有格可以放在句首。 1This is my cup. Yours is the one ttat&apos;s chipped. 在特别强调所有关系时，通常用one’s own。可以在任何形容词性物主代词而不是名词性物主代词后面加上own，这样形成的词组既可以起形容词性物主代词的作用，也可以起名词性物主代词的作用。 123I&apos;d love to have my own room / a room of my own.Our cat has its own corner / a corner of its own in this room. 如果需要再进一步强调则可以加上very。 1I&apos;d love to have my very own room /a room of my very own. 反身代词反身代词属于所有格形容词，其构成为”形容词性物主代词+self”组成的复合词，或”人称代词宾格+self”。 12单数: myself, yourself, himself, herself, itself, oneself复数: ourselves, yourselves, themselves 指示代词指示代词包括this, that, these, those。 其中， this, these为近指指示代词，与here对应； that, those为远指指示代词，与there对应。它们一般与名词连用。 1this girl, that boy, these teachers, those students 通常来说，单独用指示代词时，不指人而指物；但在Who…?问句中，也可指人。 123I found this watch. I found this.Who&apos;s this? Who&apos;s that? 数量词概述数量词或数量词组常用来修饰名词，表示我们所说的事物的数与量。 12345有些数量词修饰可数名词复数，如 many, (a) few, several...有些数量词修饰不可数名词，如 much, (a) little...有些两者皆可修饰，如 a lot of, lots of, some... 修饰可数名词时，用来回答How many…? 12How many eggs are there in the fridge?There are a few. 数量词修饰不可数名词时，用来回答How much…? 12How much milk is there in the fridge?There&apos;s a little. 两者皆可修饰，因此既能回答How many…? 也能回答How much…? 12345How many eggs are there in the fridge?There are plenty.How much milk is there in the fridge?There is plenty. 数量词+名词 的组合形式 搭配形式分类 同类数量词 数量词+复数可数名词 如: many books both, a couple of, hundreds of, (a) few, a number of, serval … 数量词+不可数名词 如: much sugar a amount of, a bit of, a drop of, a deal of, (a) little of … 数量词+复数可数名词,不可数名词 如: some books, some sugar some, any, all, hardly, a lot of, lots of, the other … 数量词+单数可数名词 如: each book another, each, either, the other, some, the whole … 不是不确定的数量1234567891011121314151617181920212223242526#数量可以是确定的，也就是可确切地说出到底有多少We need six eggs and half a kilo of butter.#更多的时候，数量是不确定的，它只说明了一个大致的情况Are there (any) apples in the bag?There is some milk in the fridge.#数量词后常和more连用I&apos;d like some more chipsI&apos;d like some more milk.#数量词后也常和less连用Much less soup, please.I want mush less, please.#数量词前用notNot enough is known about this subject.It has given not a little trouble. 数词的分类数词可分为: 基数词 序数词 分数 小数 百分数 … 123456789101112131415161718192021222324252627282930#基数词one, two, three...#序数词first, sixth, tenth...#分数#英语中分数的构成为: 一个基数词加一个序数词#分子为1时，分母直接使用序数词；分子大于1时，分母序数词+sone third, nine sixteenths#小数0.5, nought point five, point five2.5, two point five2.05, two nought five, two point o five#百分数8%, eight percent99%, ninety-nine percent#近似的数量about, almost, exactly, fewer than, at least, less than, nearly ...There wrer over seventy people at the party. not, no, none, little, bit not(any), no和none的区别 构成否定句的方式可以用not来否定动词，也可用no来否定后面的名词none可以直接作为一个代词来用，而no则不可 12345There aren&apos;t buses after midnight.There are no buses after midnight.Do you have any diaries? We&apos;ve got none at the moment. a great deal/amount of与a large/greate number of a great deal/amount of都有much之意，其后应接不可数名词； a great/large number of都有many之意，其后应接可数名词复数。 123A great deal/amount of money is spent on research.A large/great number of our students are American. (not) (a) little与(not) a bit及(a) few的区别 few和 a few; little和a little (a) few用于修饰可数名词复数 (a) little用来修饰不可数名词 不带不定冠词a时，两者都表示否定之意，强调少的概念 (a) little和(a) bit 在肯定句中，它们几乎是通用的 在否定句中，它们的含义正好相反 12345678910111213He has had very few opportunities to practise his English.He has very little hope of winning the race.A lot of guests wre execpted, but few came.There are only a few seats left.There&apos;s only a little soup left.I&apos;d like a little/bit of time to think about it, please.He was not a little surprised. # 他感到十分吃惊I don&apos;t like the book, Not a bit. # 一点也不喜欢 enough enough的基本意思是充足的。它既可修饰名词，也可修饰形容词和副词，还可做名词。修饰名词时放在名词前，修饰形容词放在形容词后。 123Is there enough hot water for me to take a bath?Is the water hot enough for me to take a bath? about, almost, hardly, less than, more than, nearly, not, not nearly, not quite scarcely等词常用来修饰enough。 1There are hardly enoush cakes. 在特定上下文中，little和few也可以修饰enough，强调不够。 12I can&apos;t lend you money. I have little enough as it is.I can&apos;t give you any stamps. I have few enough as it is. both, all, either, neither, each, every, other, another 这些不定代词中，either, neither, each, every只能修饰或代替单数名词 both, all一般修饰或代替复数可数名词。其中both表示两者都，通常适用于两者之间；而all表示全部，用于三者及以上 一般来说，either表示两者必有其一；而both则表示两者都 否定式用neither, nether…nor，注意当它们作主语时，谓语动词要和靠近谓语部分的名词或代词一致 当both, all, each, either, neither用在代词前面时，其后必须加of all和every都可表示泛指概念。all通常表示可视为一个整体的东西，或指一个总量；every则强调群体当中的每个单位，而且只用于修饰单数可数名词 当使用not对all或both进行否定时，其否定结果为部分否定；无论not直接用在all/both之前还是用于否定动词上，都表示一样的意义。完全否定时，应该用no, none, neither each和every的用法十分相似，经常可以通用。each更注重强调个体，every更侧重强调整体 another有两种意义: 外加的/同样的 不同的 another和other不是确指的，而the other(s)却是确指的 1234567891011121314151617181920212223All thirty passengers on the boat were saved.Both of you told a lie.Either of you is wrong.Neither he nor I speak English. #他和我都不讲英语Both of us left very early.Neither of the girls left early.I&apos;ve read all these books.I&apos;ve read every book in the library.Not all the girls left early.None of the girls left early.Neither of the girls left early. # 两个女孩都没有早走Each child in the school was questioned.Every child enjoys Christmas.Do you need annother cup of coffee?Give me another cup. This one&apos;s cracked. 形容词 形容词概述形容词经常用于说明人或事物的性质，最为常见的是作名词的定语。 根据所描述的对象和意图的不同，又可分为多种类型。请看下表： 形容词类型 栗子 表质量 a beautiful lady a fine/nine day 表大小 a big car、 a tall man 表新旧/老少 a young man a new bag 表温度 a cool evening a hot summer 表形状 a round table a square box 表颜色 blue esys、grey hair 其他 a Swiss watch 形容词作表语，通常可以描述整个词组的意思。 Professor Robert’s lecture on magnetism was fascinating.罗伯特教授的磁学讲得很精彩。 Yesterday, I bought a book. Books are not very expensive.昨天我买了一本书。书不很贵。 复合形容词 用过去分词构成 a candle-lit table(一张点着蜡烛的桌子)、a tree-lined avenue(林荫大道) 用现在分词构成 a long-playing record(密纹唱片)、a time-consuming job(费时的工作) 用看上去是分词，实际上是用名词+ed合成的词构成复合形容词 slow-footed(脚步慢的)、quick-witted(机敏的) 表示度量的复合形容词 特征 栗子 年龄 a three-year-old building an eighteen-year-old girl 面积/体积 a three-acre plot a two-litre car 持续时间 a four-hour meeting a two-day conference 长度/深度 a twelve-inch ruler a six-foot hole 价格 a 50 dollar dress 时间/距离 a ten-minute walk a three-hour journey 重量 a ten-stone man a five-kilo bag of flour 带序数词 a first-rate flim a second-hand car 用前缀或后缀构成的复合形容词 tax-free(免税的)、water-proof(防水的) 定语形容词和表语形容词一般来讲，几乎所有的形容词都能作表语，但有些形容词却不能或不常作表语。 countless、digital、indoor、western、commanding、thankless… 有些形容词，如old, late, heavy等，既能作表语也能作定语，但表示的意思是不同的。 Jordan is old now.乔丹现在已经老了。（old作表语，指年纪大） Jepson is an old friend.杰普森是一位老朋友。（old作定语，指相识的时间已经很久了） 有些形容词只能作表语而不能作定语，我们通常把这类形容词成为表语形容词。 表语形容词有以下三种： 描述与健康有关的一些形容词。如：faint, ill, poorly, unwell, well…He’s ill.他病了。(ill作表语) 很多以a开头的形容词，只能作表语而不能作定语。如：afloat, alight, awake, asleep, alone, afraid, ashamed…He ought to be ashamed. 一些描述感觉、反应的形容词，只能作表语，而不能作定语。如：content, glad, pelased, sorry, upset, far…I’m very glad to meet you. 用在名词后的形容词有些形容词常放到头衔名词的后面做修饰语。 Attorney General(检察总长)、Governor General(总督)、Heir Apparent(法定继承人) 还有一些固定搭配的词组，也是讲形容词置于所修饰的名词之后。 sum total(总计)、Asia Minor(小亚细亚)、hope eternal(永恒的希望) 有些形容词即可放在名词前也可放在名词后，但它们的意思通常有所改变。 如：concerned, elect, involved, present, proper, responsible… Jones is a responsible girl.琼斯是个有责任心的姑娘。 The girl responsible was expelled.负有责任的那个姑娘被开除了。 the+形容词的用法the+形容词表示作为整体的群体，谓语动词用复数。 the blind、 the poor/rich、the young/old… The rich should help the poor. 形容词的词序形容词的分级 大多数形容词是可以分级的，即有比较级和最高级形式。 但是，有一些形容词则不能分级，即没有比较级和最高级。它包括无分级形容词和极限形容词两种。 无分级形容词：daily, dead, medical, unique 极限形容词：excellent, perfect, favourite Fishing is my favorite sport. 形容词比较级的构成 形容词的比较级和最高级的一般构成方法是： 单音节形容词及少数双音节形容词直接在后面加-er和-est构成比较级和最高级。如：clod, cloder, clodest… 在以重读闭音节结尾的形容词中，当结尾是一个元音字母加一个辅音字母时，应双写其结尾的辅音字母后再加-er和-est。如：fat, fatter, fattest… 有些形容词是以字母-e结尾，它们的比较级和最高级可在其后直接加-r或-st。如：fine, finer, finest… 有些形容词是以字母-y结尾，而且在-y前面有一个辅音字母，这种形容词变为比较级和最高级时应首先把y变为i，然后再加-er和-est。如：tidy, tidier, tidiest… 三个和三个音节以上的形容词变为比较级和最高级形式时通常在词的前面加more和most。如：beautiful, more beautiful, most beautiful… 还有一些形容词的比较级和最高级的变化是不规则的。如：good/well, better, best… 形容词比较级和最高级的用法 当我们把一个人或事物与另一个人或事物进行比较时，用比较级。如： Jane is taller than Alice. 将某一个范围内的一个人或事物和其他一个以上的人或物作比较时，用最高级。短语或句子中的形容词最高级钱要用定冠词the，副词则不必。如：John is the tallest. 我们经常用more and more的句型来表示越来越…的意思。如：Alice is getting more and more beautiful. 在表示越…就越…时，用the more...,the more...句型。如：The more money you make, the more you spend. 可修饰形容词比较级的词形容词的比较级通常只有少数表示程度的词才能修饰。如：a bit, a little, a few, much, a lot, by far, even, still…Houses are much/far/a lot more expensive these days. 可修饰形容词最高级的词如：almost, altogether, by far, much, nearly, quite, the very…This is quite/by far the most expensive bicycle in the shop. 形容词原级的常用句型 当使用as+形容词原级+as的句型时， 表示前后两者具有同等程度；其否定形式一般为not as/so+形容词原级+as，一般可理解为前者不如后者。如： Jane is as tall/intelligent as Jones. 副词 副词概述一般情况下，副词可以修饰动词、形容词、其它副词、介词短语…，具有对这些词进行补充说明的作用。 修饰对象 栗子 形容词 very good awfully hungry 其它副词 very soon awfully quickly 介词短语 You’re entirely in the wrong. 完整的句子 Strangely, I won first prize. 副词的常见构成形式形容词+ly是最常见的副词构成形式。 如： beautiful, beautifully… 注意有些以-ly结尾的词，并不一定是副词，挡在名词后加-ly时，则一般构成形容词。如：friendly(有好的)、daily(每日的)… 副词的比较等级副词的比较等级与形容词的类似，由它构成的句型也大致一样，只是所修饰的对象不同。 She is the fastest girl.（fastest修饰女孩，为形容词最高级）She runs fastest.（fastest修饰跑，为副词最高级。注意多数副词的最高级钱不能使用the） 方式副词方式副词的位置通常有三种 在句尾或宾语/动词之后Jane watched the small monkey curiously.（在宾语后）It snowed heavily last January.（在动词后） 在主语和动词之间Bob angrily slammed the door behind him. 用在句子开头Normally, our papers are delivered every morning. 有些方式副词，如：bravely, cleverly, cruelly, foolishly, kindly, simply, badly…当位置改变时，其强调的方面也随之变化。 He foolishly locked himself out.（强调他是个傻瓜）He behaved foolishly at the party.（强调可笑的行为） 地点副词常用的地点副词有： abroad, ahead, anywhere, everwhere, right, left, here, there, south, north, forwards…其位置一般用于方式副词后、时间副词前。 Indoors it was nice and warm. Outdoors it was snowing heavily. 时间副词时间副词可分为表确定时间的副词和表不定时间的副词两种。 表确定时间的副词：tomorrow, yesterday, last month… 表不定时间的副词：already, another day, another time, at once, at last, early, eventually, formerly, immediately, just, recently, now, once… 表确定时间的的副词的位置一般在句首或句尾。This morning I had a telephone call from Jane.We checked in at the hotel this Monday. 表不定时间的副词的位置一般放在句首、句尾、实义动词之前和助动词或系动词be之后。Recently the clavichord was damaged by a visitor.By the way, have you seen Harry recently?I was recently in NewYork.（系动词后） already和yetalready一般不用在否定句和疑问句中，它的位置与非确定性频度副词相同。 This computer is out of date already. yet一般用于疑问句和否定句中，通常放在句尾。 Have the new petrol prices come into fore yet? 频度副词频度副词包括频度副词和频度副词短语 频度副词：hourly、once、twice、weekly、fortnightlt、annually、never、seldom、usually… 频度副词短语：three times a week、once a month… 确定性频度副词 如：once，twice，hourly，daily， on Fridays, three times a week…通常放在句尾。 I saw my girlfriend once a week. 非确定性频度副词，如果按频率的大小来排序的话，为 always&gt;almost always&gt;nearly always&gt;fenerally/normally/regularly/usually&gt;frequently&gt;often&gt;sometimes/occasionally&gt;almost never/hardly ever/rately/scarcely ever/seleom&gt;not…ever/never 表示否定意义的非确定性频度副词不能与not连用 We hardly ever see Mr. Lee these days.（不能说We don’t hardly ever…） 在肯定句和疑问句中的非确定性频度副词通常放在句子中间。大多数非确定性频度副词一般都位于助动词之后或实义动词之前。 I was never very good at maths. 非确定性频度副词也可放在句尾。 I get paid on Fridays usually. 程度副词常用的程度副词有：quite, almost, altogether, barely, a bit, enough, fairly, hardly, nearly, rather, somewhat, too…这些词大部分用在所修饰的词语前面。 修饰形容词： quite good 修饰副词：quite quickly 修饰动词：I quite like her 修饰名词：quite an experience fairly与rather fairly通常表示褒义的概念，描述主语所期望的和具有积极意义的情况，表示事物处于好的状态。The lecture was fairly good. rather比quite和fairly语气更强，往往含有过分的意思，通常用于描述主语所不愿意或消极的内容。He is clever but rather lazy.This jacket’s rather old. rather可与比较级连用，而fairly一般不能。Jack earns rather more than his father. rather可与too连用，强调过分的意思。This book is rather too easy for the college students. 当与褒义的形容词连用时，rather含有惊人地意思。I did rather well in the test——better than I had expected. rather在与名词连用时，其位置是灵活的，放在不定冠词前或不定冠词后君合；而fairly只能放在不定冠词后。 介词 概述介词经常用在名词或名词短语、代词或动名词之前，用来表示人、物、事件等与其他人、物、事件之间的关系。 I gave the book to Jane.（介词+名词）I gave the boo to her.（介词+代词）Jane devotes her time to reading.（介词+动名词） 介词经常表示的关系如下 We ran across the field.（空间）The plane landed at 6:55 p.m. precisely.（时间）You unlock the door by turning the key to the right. 介词的形式常见的介词的形式有两种 单个词：at, from, in, to, into… 介词短语：according to, apart from, because of… 介词后面的名词没有格的变化 The car stopped behind/in front of the girl.He was very angry with me. 可兼作介词和连词的词有些词既可作介词(其后接宾语)，也可作连词(其后跟从句)。如：as, after, till, since, before, untill… Please come to me after 3 o’clock.（介词）We went to the beach directly after we got up.（连词） 表示动态或静态的介词有些介词，如：into, onto, out of…一般都与表示动作的动词连用，表示动态概念。 A bird flew into my bedroom this morning.I drove out of the car park. 还有一些介词，如：near, above, behind, across, along, beside, between…与某些表示静态概念的动词连用时，表示静态；而与表示动态概念的动词连用时，则表示动态。 I waited in the hotel lobby.（静态）He hurried across the street.（动态） 表示时间的介词和介词短语介词at, in, on不仅表示地点，也表示时间。 Many tourists come here in summer. They usually come in July and in August. 用at的时间短语 at表示时间时一般表示具体的时间点，但也有例外。 适用情况 栗子 确切时间 at 10 o’clock 用餐时间 at lunch time 节日 at Christmas 年龄 at 18 其它时刻 at noon 用on的时间短语 on一般用于表示一整天的时间概念，如：on Monday…但也有例外，如果在一段时间前面有定语修饰的时候，一般也用on。如：on Monday morning…有些节目前也用on。如：on Christmas Day 用in的时间短语 in一般表示时间段，长短皆可。 适用情况 栗子 一天中的某段时间 in the evening 月份 in June 年份 in 1995 季节 in spring 世纪 in the 21st century 节日 in Easter Week 时期 in the holidays 动词+介词/副词小品词由动词+介词/副词小品词构成的短语动词是非常普遍的，而且短语动词的用法也特别合乎英语的行文习惯。 动词+介词/副词小品词的五种类型 类别 栗子 动词+介词（及物） get over (an illness) 动词+副词小品词（及物） bring up (the children) 动词+副词小品词（不及物） come out/break out 动词+副词小品词+介词（及物） run out of (matches) 动词+名词+介词（及物） take part in 在由动词+副词小品词构成的短语动词中，副词小品词的位置是比较灵活的。当其宾语是名词时，副词可以放在名词的前面或后面；当其宾语为代词时，则副词只可放在代词之后；但如果宾语比较长时，则应尽力避免把小品词与动词分开。 She turned off all the lights which had been left on.This cat is too noisy, Take it out, please. 大部分动词+副词小品词形式的动词短语中，小品词与动词本身的意义是有一定联系的，或者有一定的参照性。如： take off, pick up, take…away, come up, guess out… 但有些小品词与动词搭配时，动词本身已经没有什么实际意义，同一个动词在搭配了不同的小品词之后，其意思大相径庭。bring up the childrenbring off a deal 在英语中有些动词是不及物动词，当它们需要带宾语时必须通过后面跟介词的方式。 如：listen to, look at, ask for, wait for, look for…She is waiting for her boyfriend.You should ask for the bill. 一些不及物动词与小品词搭配之后，形成的仍然是不及物的短语动词。 Alice went out.We set off very early. 动词+介词/副词小品词+宾语 如：dream of, think of, succeed in, insist on…Your father insist on coming with us.He dreamed of being a pilot. 使用动词+介词形式的短语动词时，不能把介词放在宾语之后。 Look at this picture.（不能说Look this picture at.） 使用由动词+介词to形式的动词短语时，to后不能跟不定式，而必须分名词或动名词。 I look forward to seeing you soon. be used to后跟不定式和动名词时，所表达的意思是不一样的。 I’m used to getting up early in the morning. 动词 概述动词是构成句子的必备元素，充当句子的谓语部分。根据其不同的用途，动词又可分为： 及物动词、不及物动词； 实义动词、情态动词、系动词、助动词； 非谓语动词和谓语动词； 及物动词与不及物动词 有些动词，如：afford, allow, blame, bring, deny, need, get…，在使用的时候，其后必须跟宾语，称为及物动词；有些动词，如：lie, occur, happen, rain, sleep…，在使用的时候，后面不能跟宾语，称为不及物动词。 有些不表示动作而表示状态(如感受、状况等)的动词称为状态动词。 如： like(喜欢)、think(认为)、love(热爱)、understand(理解)… 状态动词在使用的时候，一般不用于进行时态。She loves/loved her baby more than anything else in the world.（不能说She is loving…） 有些动词则表示有意识或无意识的动作或者变化着的状态，称为行为动词。I’m making a dress. 动词在使用的时候应注意人称的一致性和时态的变化。 助动词 助动词一般包括：am/is/are/was/were, have/has/had, do/does/did, will/would, shall/should，它们的功能主要是帮助动词完成时态、语态的变化。 助动词be的用法 与现在分词构成现在进行时 与过去分词构成被动语态 … 助动词have的用法 与过去分词都成现在完成时 与现在分词构成现在完成进行时 与过去分词构成现在完成时的被动语态 类型 栗子 祈使句 Have a cup of coffee! 一般现在时 I always have milk in my tea. 现在进行时 We are having a nice time. 一般过去时 We had a lovely holiday last summer. 过去进行时 I was having a batch when the phone rang. 现在完成时 John has just had an accident. 现在完成进行时 The children have been having a lot of fun. 过去完成时 He went out to play basketball after he had finished his homework. 过去完成进行时 The file had been showing for 15 minutes when I got to the cinema. 一般将来时 I’ll have my hair cur tomorrow. 将来进行时 If anyone phones, I’ll be having a bath. 将来完成时 Tom will have had his exam by 18 Decembr. 将来完成进行时 She will have been having treatment for three months in the hospital by the end of this week. 情态动词 You could have a cup of coffee if you like. 助动词do的用法 助动词do最主要的用法有两个： 与动词原形搭配构成一般现在时或一般过去时的疑问句和否定句 用在实义动词前起强调作用 Do you do your shopping once a week? （构成疑问句，前一个do是助动词，后一个do是实义动词）He didn’t know when to set off.（构成否定句）The farmer did drive the cattle into the field.（表强调） 情态动词 概述 情态动词一般用于描述委婉、礼貌、客气、强令等特殊语气，达到表现说话人复杂心理及情感的目的。 情态动词包括： can/could, may/might, will/would, shall/should, must, ought to。另外，need和dare既可作实义动词也可作情态动词。 情态动词的主要功能 can/could主要指能力（不需要再努力）I can type. may主要指允诺You may leave early. will主要指预告、将要It will rain soon. should/ought to主要指不可推卸的义务或责任You should/ought to do as you’re told. must主要表示强令或不可推卸的责任You must be quite. needn’t指没有义务，既可作可不做You needn’t wati. 情态动词也叫情态助动词，它像助动词be, do, have一样可以直接在后面加not构成否定句或将其提到主语前面构成疑问句。 You mustn’t move this table.（否定句）Can I ask you some questions?（疑问句）Can’t you see the picture?（否定疑问句） 情态动词每次只能用一个 We may call a doctor.We must call a doctor. 如果需要同时表示两种意思，则要通过适当的解释。 It may be necessary (for us) to call a doctor.（may和necessary，同时表达了也许和必要两种意思） 情态动词的时态和语态 情态动词在形式上没有实义动词的各种变化，只有could, would, had to, wat/were to, might几个过去式。must和ought to过去式和现在式相同。 would, could, might, should在形式上都可以说是will, can, may, shall的过去式，但与它们的用法和意义却无多大关系。一般来说，情态动词的过去式往往可以表示更加委婉、客气等含义。当情态动词用于表示过去的状态或动作时，则是它们的过去时。She says you can/will/may leave early.（现在时）She said you could/would/miht leave early.（过去时） 情态动词should/ought to/could/must后接动词的完成时态时，往往可以表示一些特殊含义。The lights in her roo were out 15 minutes before I came here, so she must have been out then.（表示对过去了的情况的推测） can/could和be able to的区别 一般来说，can/could和be able to没有多大区别，经常可以互换。但can/could侧重于表示能力，而be able to则强调通过努力才能够… I can operate a computer.The girl is able to explain what had happeened to her. can/could, may/might用于表示请求别人允许或答复的情况 can, may, could, might通常都可以表示请求别人允许的意思。Can/Could/May/Might I borrow your umbrella? 但在使用的时候应该注意一下几点区别： can最常用，但也最不正式 could比can更为犹豫和客气，通常用在补鞥你确定请求能否得到同意的时候 may比can和could更正式，而且更客气和恭敬 might显得最犹豫，也最客气而恭敬 用情态动词表示推测 在对所发生的的事情进行描述的时候，一般有肯定、可能和推测三种情况。 如果说话人对所描述的事实确信无疑，就可以用be或任何实义动词直接描述。Jane is at home.He leaves at 9 p.m. 如果说话人指的是可能发生的事情，就可以用may/might/could+动词原形的结构表示。Jane may/might be at home. must+动词原形一般表示有根据而且是近乎肯定的推测；must一般用于肯定句，否定句和疑问句则通常用can/can’t+动词。在表示有根据但不太肯定的情况时则常常用may/might+动词。Jane’s light is on. She must be at home.（根据充分的肯定推测）She can’t be out.（有根据的否定推测）He may/might have left yesterday.（对过去情况的推测） 在表示推测时，其附加问句是通过情态动词后的动词形式来处理句尾的附加问句。并且，因为情态动词+动词的完成时表示对过去事实的推测，所以，有明确的的时间状语时，附加问句部分动词一般应用过去时的助动词；如果没有明确的时间状语，则可以采取have/has或did两种形式的任意一种。She might have left.（无时间状语）She might have left the day before yesterday.（有时间状语） must, have to和have got to 这三种情况就其表示的意义而言，一般可以互换，但也有区别。用于第一人称时，must通常强调主观因素，或内在的因素；而have to, have got to则常常强调客观因素或外在因素。 用于其他人称时must表示不可推卸的责任，其迫切性往往要比have to/have got to还强。 may在套语中可表示祝愿或非常希望，may通常用在句首。 May God be with you. 作情态动词的need和dare need和dare可以作为情态动词也可以作为实义动词。Need you leave so soon?（情态动词）You need to clean the bedroo.（实义动词） dare可表示气愤的强烈语气。How dare you! would和used to 情态动词would和used to可以表示习惯或过去常常。Jane used to make her own dresses. used to强调过去常常…而现在已经不…I used to smoke, but I don’t smoke any more. used to be/have 可以描述过去的状态。He used to be a postman a long time ageo.I used to have beard, but I’ve shaved it off. 非谓语动词 概述 非谓语动词包括不定式、现在分词、过去分词和动名词。非谓语动词在句子中，一般相当于形容词、副词或名词的作用，虽然仍有动作概念但不能直接充当谓语。 He wanted to find out the secret.（wanted为谓语动词，作该句的谓语；to find为不定式，为非谓语动词，作wanted的宾语） 不定式 不定式是非谓语动词中比较常用的一种。它通常由to+动词原形构成。有些情况下to可以省略。动词不定式的用法也相当多，它既可以像名词那样在句子中充当主语、宾语或表语，也可以像名词那样充当定语，还可以像副词那样作状语，主要作目的状语和结果状语。 It’s easy to say. （不定式作真正的主语）I’m waiting here to see the sunrise.（不定式作目的状语）However, they have decided to use the post office.（不定式作宾语）He seems to be fond of playing the guitar.（不定式作表语）I have a lot of things to deal with today.（不定式作定语） 在有些情况下不定式小品词to是可以省略的。当不定式作let, have, make的补语时，不定式小品词to可以省略。Let’s take a taxi. 但当这些词用于被动语态时，不定式的小品词to则不能省略。The peasants were made to work ten hours a day. help和know之后作补语的不定式小品词to可以省略亦可不省，而有时作其宾语的不定式小品词to可以省略亦可不省。Mother helped me (to) do my homework. 被动的help和help所带的被动的不定式的区别：和let, have, make一样，当help为被动式时，其后的不定式小品词to必须有，但当help之后的动词是被动形式时，则不受此影响。Jane wad helped to overcome her fear of flying. 并列不定式可以由and, or, but, except等连接。Which do you prefer, to win a million US dollars or (to) have a brain like Einstein’s? 在并列不定式中，第二个to常可以省略，而只使用其纯并列部分。I’d like to lie down and to to sleep. 叙述一些列动作时则多用不带to的不定式，或者叫省略不定式的符号to。The crowd watched the firemen climb the ladder, break a window on the first floor, and enter the building. 动词+宾语作宾语补足语feel(感觉)、hear(听见)、listen to(听)…动词后经常跟不带to的不定式或现在分词作补语。I watched a pavement-artist draw a portrait in crayons. 带to的不定式。 It+is/was+形容词+of+名词/代词+带to的不定式it作为形式主语的用法比作人称主语的用法更为常见。It’s very kind of her to help us. 动词的ing形式 动名词和现在分词皆由动词+ing构成，但是这两种词的用法却大不一样，动名词具有名词的性质，因此在句子中经常充当主语、宾语或表语；而现在分词具有形容词或副词的性质，因此在句子中充当定语、状语或补语。 动名词和现在分词虽然同形，但其作用是完全不一样的。动名词因为具有名词性质，因此常常可以做主语或宾语。而且，由于它是从动词变化而来，所以也可以在后面跟上自己的宾语。 过去分词 过去分词和现在分词一样，具有形容词或副词的功能，在句子中一般充当状语、定语、表语或补语。 现在分词和过去分词的区别。一般来说，现在分词表示与其被修饰词之间是主动的关系，同时强调其动作时正在发生的；而过去分词则截然相反，它一般表示与其被修饰词之间是被动的关系，切强调动作为已经完成了的。 独立主格结构 独立主格结构是由名词/代词（逻辑主语部分）+逻辑谓语部分组成的，其逻辑谓语部分可以是现在分词、过去分词、不定式或介词短语。独立主格结构一般用于逻辑主语与句子的真正主语不同的句子中。 时态 概述在英语中，动词时态的用法是尤其复杂和富于变化的。经常通过动词词尾、助动词等的变化来表明动作发生时间的先后顺序——即时态。总的来说，英语中动词的时态分为三个基本类型：过去、现在和将来。动词时态的变化常常伴随着相应的表示时间或频度的状语。 He often goes to the Great Wall.He went to the Great Wall yesterday.He will go to the Great Wall tomorrow. 判断谓语动词的时态，除了借助于时间或频度副词之外，通常还要考虑句子的上下文，利用各个动作的时间先后或因果关系来确定动词的时态。 He tells me he plays table tennis well.（他现在打得好）He told me he played table tennis well.（他过去打得好）He told me he plays table tennis well.（他现在仍然打得好） 一般现在时一般现在时可用于陈述现在时间内发生或存在的事件、动作或情况。这些事件、动作或情况也可能会无限期地延续下去。 一般来说，一般现在时可以用于以下几种情况： 一般现在时可以陈述永恒的真理。Summer follows spring. 一般现在时可用于现阶段内发生的情况。My father works in a school. 表示习惯性动作，通常表示不断重复的动作。I get up at 7:00 a.m. 当谈论的是关于时间表、节目单或日程表上所安排好的事情的时候，通常用现在时表示将来的意义。The exhibition opens on January 1st and closes on January 31st. 一般现在时中，当主语为第三人称单数时，其谓语动词后面要加-s，变化方法如下： 多数动词一般在词尾直接加-s，如：buy, buys 以字母-o, -s, -x, -ch, -sh结尾的动词词尾加-es，如：do, does 以辅音字母+-y结尾的动词变y为i，再加-es。如：fly, flies 当使用了频度副词，如always、never、usually、rarely…副词短语every day, every week…，这种现在时可使习惯性动作表现得更加明显。 I sometimes stay up till midnight.She visits her parents every day. 一般过去时一般过去时通常表示过去某一时间发生的而现在已经结束的动作、事情或状态，常和表示过去某一时间的状语yesterday、just now， at that time…连用 In the early days of the settlement of Australia, enterprising settlers unwisely introduced the European rabbit. 动词过去式的构成规则 在动词原形后直接加-ed。如：open, opened 动词以-e结尾，则只加-d。如：die, died 动词以辅音+-y结尾，则去-y再加-ied。如：try, tried 规则动词过去式词尾-ed的读音 在以浊辅音或元音结尾的动词后读[d]。如：saved 在以清辅音结尾的动词后读[t]。如：shopped, asked 在以-t或-d结尾的动词后读[id]。如：visited, wanted 不规则动词（约150个）与规则动词不同，它们的过去式基本上无规则可循，需记忆。如：sit, sat 一般过去时通常和表示过去的时间连用，有时没有具体的过去时间，需要通过上下文判断时间。 I travelled to Portsmounth by bus yesterday. I got on the bus and sat down. 若所给信息影响了时间限定，则必须给出时间状语。 I received the magazine I ordered last week. 时间状语从句可以起到描述过去时间背景的作用。 When the article arrived, the editor read the first sentence and then refused to publish it. 一般将来时一般将来时通常由shall, will或be going to加上动词原形构成。will可用于所有人称，shall只用于第一人称。在口语中，shall和will的区别常被忽略，因为他们的缩略形式都是&#39;ll I shall/will see you tomorrow.I’ll see you tomorrow. 在口语中，缩略形式&#39;ll常用于代词之后。如：He’ll wash these dishes soon. 否定式will not和shall not的缩略形式分别为won’t和shan’t。如：I/We won’t/shan’t go to the market. be going to表示将来的用法 在非正式文体中，表示意图、打算时，一般将来时多用be going to而不常用will。 表示将来而不借助于时间状语来表达时，这种情形常指马上或不久的将来。 也可与表示将来的时间状语连用。 可用来代替直接表达打算的动词 在条件句中一般将来时通常由一般现在时表达，即主句为一般将来时，从句为一般现在时。 If he is out, I‘ll call tomorrow.I shall wait here until he comes. 现在进行时现在进行时由be+动词的现在分词构成。它表示说话时正在进行的动作或事件，往往与now、at the moment、just…表示现在的时间状语连用。 Someone’s knocking at the door. Can you answer it? 现在进行时也可以描述暂时的情况或动作，强调这一动作或情况短时间内正在进行。 What’s your son doing these days? 现在进行时在与副词always、constantly、continually、forever、perpetually、repeatedly…连用时，表示不断重复的动作。 She’s always helping people. 现在进行时所描述的动作或事情发生得过多时，则有时含有抱怨的意思。 Our burglar alarm is forever going off for no reason. 过去进行时过去进行时表示过去某时正在进行的动作或状态，不一定需要时间状语。 His wife was sitting beside him holding a large cake. 过去进行时和以all开头的状语(all night)一起使用，强调动作的连续性。 It was raining all day. 过去进行时表示某事发生前已经开始的动作。在这种情况下，过去进行时常和一般过去时在同一个句子里使用。过去进行时表示当时正在进行的动作或情况，一般过去时则表示比较短暂的动作或事件。正在进行中的动作或情况常常和连词when、as、just as、while…等引导的时间状语从句连用。 When I was watering the garden, it began to rain. 过去进行时表示并行的动作，经常与while或at the time连用，强调同时进行的两种或几种动作。 While I was working in the garden, my wife was cooking dinner. meanwhile经常用于描述正在进行的动作。 Meanwhile, the editor was getting impatient, for the magazine would soon go to press. 过去进行时和used to 在使用时应注意的问题 过去进行时表示过去某个时间正在发生的动作；而used to +不定式表示一个动作或状态时过去的习惯，但并没有持续到现在。 I used to go to work by bus, but I go by car now. 现在完成时现在完成时主要有以下几种方法： 表示开始于过去并持续到现在的动作（也许还会持续下去）。它常和for+一段时间或since+某个时间点连用。He has been there for six months. 表示在过去不确定的时间里发生但对现在仍有影响的动作。I have read the book, but I don’t understand it. 表示刚刚完成的动作，可以与recently、just等连用。I have been reported in Russia Recently of people who can read and detect colours with their figers, and even see through solid doors and walls. 表示最近发生的动作，常和副词already(用于肯定句)和yet(用于否定句和疑问句)连用。Has she arrived yet? 描述重复动作Historians have long been puzzled by dots, lines, ans symbols which have been engraved on walls, bones, and the ivory tusks of mammoths. 表示结论性的陈述也常常使用现在完成时On the whole, business has been very good this year. 在现在完成时中，要注意have gone和have been的区别 He has gone to Alice Springs.（在那儿或在去那儿的路上）He has been to Alice Springs.（曾经去过那儿，但现在不在那） 一般过去时和现在完成时的区别 一般过去时的时间概念时明确的，我们关心的时过去的时间或过去的结果。而现在完成时的时间概念有时是不明确的，我们所关心的是现在的结果，或过去发生的事对现在的影响。 过去完成时过去完成时的主要用法时表示两个事件中过去一个动作开始之前另一个动作已经完成，前面发生的动作用过去完成时来表示。 The patient had been dead when the doctor arrived. 当句子中有after等能够暗示时间先后顺序的状语从句出现时，通常可以明确地说明主句与从句动作的先后关系。如果主句为过去时，那么从句中的动作就形成了过去的过去，因此表示从句动作的动词常常使用过去完成时。 After her husband had gont to work, Mrs. Richards sent her children to school and went upstaits to her bedroom. 但在谈及过去不同时间所发生的的两个动作时，并非总是要将先发生的动作用过去完成时表示。当按动作发生的顺序进行描述时，通常使用一般过去时即可。 Mary said some tather norrible things to me; I felt pretty upset, but tried not to think about thme too much. 当我们要强调过去时间以后的动作，而只想将发生再次动作之前的动作作为临时性过渡时，这一动作通常用过去完成时表达。这样使用时，并没有强调多去完成时表达的动作之意。 I felt pretty upset because of what Mary had said, but I tried not to think about it too much. 在过去完成时中，表示之前概念时不能使用ago，而必须使用before。因为前者用于表示时间的起点是现在，而后者描述的时间起点则为过去的时间概念。因此，前者一般适用于一般过去时，而后者可以用于过去完成时。 A week before, he had completed a successful overland flight furing which he covered 26 miles. 过去完成时的作用有时完全相当于现在完成时的过去形式，在间接引语中这种情况尤其多。 Juliet is excited because she has never been to a dance before.Juliet was excited because she had never benn to a dance before. 过去完成时被动语态为had+been+过去分词。 When she came, the room had already been cleaned. no sooner…than和scarcely/barely/hardly…when表示某件事仅随着另一件事发生。 现在/过去完成进行时现在/过去完成进行时由have、has/had been + 现在分词构成，所描述的动作主要强调以下几种情况： 表示动作在某一段时间内一直在进行She is very tired, she’s been typing letters all day. 表示持续性的动作I have been learning English. 表示经常重复的动作Jim has been phoning Jenny every night for the last week. 描述通过直接或间接的证据得出的结论。 Your eyes are red. You’ve been crying. 过去将来时过去将来时是由was/were going to, was/were about to, was/were to, was to have + 过去分词, was/were on the point of, was/were due to和would等来表示。 We were about to leave when a car drove up. 表示无法预见结果 Little did they know they were to be reunited ten years later. 过去将来时也可以表示过去因故中断的动作，通常用just ... when形式 We were just going to leave when Jean fell and hurt her ankle. was going to和was to have + 过去分词的异同 I was going to see Mr. Kay. 我要去看凯先生（可能见到，也可能没见到）I was to have seen Mr. Kay. 我本来要去见凯先生（没有见到他） 被动语态 概述在英语中，语态分为两种：主动语态和被动语态，它们都是指动词的形式而言。在主动句中，句子的主语时执行动作的人或物。 John cooked the food last night. 在主动语态中强调的是执行动作的人或物，即主语时动作的执行者；而在被动语态中强调的是接受动作的人或物，即主语时动作的承受者。 This bridge was built in 1942. 被动语态所强调的是动作的承受者而不是动作的执行者。因此，有时为了把话说得谨慎些，可以使用被动语态。 Muriel pays less income tax than she should. 为了使句子的结构更加平稳、严谨，经常使用下列三种被动结构： It is/was + 动词过去分词 + that 引导的从句It is said that there is plenty of oil off our coast. There + 动词 + to be + 补足语There is suppsed to be a train at 12:37. 除it意外的主语 + 动词 + 带to的动词不定式Tuner was considered to be a genius even in his lifetime. 被动语态所强调的对象是动作的承受者，即行为客体。如果需要说明动作的执行者即行为主体时，常常可以用by+行为主体的结构表示。 The windows was broken by the boy who lives opposite. It was composed by Mozart. 被动语态的构成在被动语态中，句子的主语是动作的承受者。被动语态的形式由相应的助动词加上动词的过去分词构成。 The food was cooked last night. 被动语态的构成形式分为： 一般现在时的被动语态: am/is/are + 过去分词 一般过去时的被动语态: was/were + 过去分词 现在进行时的被动语态: am/is/are + being + 过去分词 现在完成时的被动语态: have/has + been + 过去分词 过去进行时的被动语态: was/were + being + 过去分词 一般将来时的被动语态: be going to/ will/ shall + be + 过去分词 过去完成时的被动语态: had been + 过去分词 不定式的被动语态在主语+谓语+宾语+不定式结构中，当动词时被动语态时，其后的不定式可保持主动语态。 He told me/I was told to wait for him. 当含有被动含义时，不定式本身能变成被动语态。 He never expected te bicycle to be found. 情态动词的被动语态情态动词的被动语态是在will, can, must等情态动词后加 be + 过去分词构成。 Your watch will/can/must/should be repaired. 分词结构的被动语态现在分词的被动语态由being+过去分词构成，它的完成式由having been + 过去分词构成。 He hates to be criticized.I was worried about you all night. 直接引语和间接引语 直接引语一字不改地引述别人的话，叫直接引语。 “Why don’t we go sailing?” Diana said. 如果通过第三者进行转述，可以不用引号。 Diana suggested they should go sailing. 当把直接引语变为间接引语的时候，人称、时态、时间状语、地点等通常都应发生相应的变化。 间接引语说话人用自己的话转述别人的话，叫间接引语。间接引语需要由动词引述，因此这种动词称为引述动词。如say、tell、ask、declare… 动词tell、say…通常引述间接引语。tell后面必须跟人称间接宾语(tell sb…)，而say后面则可跟或不跟to引导的讲话对象。 He tells me/syas to me (that) he’s very busy. 直接引语变成间接引语时，其谓语动词时态变化规则如下： 当引述动词为现在或将来时态时，间接引语的时态不变。He says, “I’m tired.”He says he is tired. 当引述动词为过去时态时，间接引语的时态则一般应作为相应的变化，即时态的呼应。规则如下： 直接引语中的一般现在时，间接引语要变成一般过去时。He said, “I never work on Sundays.”He said he never worked on Sundays. 直接引语中的现在完成时，在间接引语中要变为过去完成时。Sylvia said, “I’ve moved to another flat.”Sylvia said (that) she had moved to another flat. 直接引语中的一般过去时，在间接引语中则通常变为过去完成时，当然不排除仍用一般过去时。“I moved to anther flat,” she said.She said she moved to another flat. 直接引语为现在进行时，间接引语变为过去进行时。She said, “he’s waiting.”She said (that) he was waiting. 直接引语为过去进行时和过去完成时，间接引语变为过去完成进行时或不变。“I was waiting for hours before you arrived,” he told Harriet.He told Harriet that he had been waiting for hours before she arrived. 直接引语为一般将来时，间接引语为过去将来时。“Where are you going?” he asked.He asked (us) where we were going. 直接引语为含情态动词的一般现在时，间接引语中情态动词变为一般过去时，如: shall/will变为would; can变为could…“I can/will/may see you later,” he said.He said he could/would/might see me later. 当must指过去时，可以不变；如果是指“不可推卸的义务”时，在间接引语中也可由had to代替。“I must warn you of the consequences,” He said.He told me (that) he must/had to warn me of the consequences. 如果直接引语内容为普遍真理，主句谓语时过去时，变成间接引语时，引语部分时态不变。“Light travels faster than sound,” the teacher said to his students.The teacher told hist students that light travels faster than sound. 直接引语变成间接引语时，人称、指示代词、时间状语、地点状语也应有相应的变化。 代词的变化I-&gt;she/he, me/you-&gt;him/her/I… 时间状语的变化now-&gt;then, ago-&gt;before… 地点状语的变化here-&gt;there, this place-&gt; that place… 直接引语为特殊疑问句，在变为间接引语时，其引导词应用疑问代词或特殊副词。ask可以转述疑问句，包括一般疑问句和特殊疑问句。 “When will Jack arrive?” Tom asked.Tom asked when Jack would arrive. 除了ask之外，转述疑问句(包括一般疑问句和特殊疑问句)的动词还可以是want to know, see, say, tell, wonder, inquire(较正式) 如果直接引语为选择疑问句，变为间接引语时，应有whether…or…They asked me whether I was ill or not.They asked whether I was ill or just lazy. 如果直接引语为一般疑问句，间接引语中用if或whether引导。“Have you been abroad?” Mary asked.Mary asked me whether we had been abroad. 当直接引语为祈使句时，间接引语中通常要用tell, order, command, ask等代替直接引语中的say，并且动词后要用“名词/代词+不定式”结构。 “Open the door for me, please.” She said (to me).She asked me to open the door for her. 动词insist和suggest不能用于“名词/代词+不定式”结构，其后通常要跟一个“that从句+(should)+动词原形”的结构。 “You really must stay and have lunch,” he said.He insisted that I (should) stay to have lunch. 倒装句 概述倒装句分为： 完全倒装句：指谓语动词完全在主语之前； 部分倒装句：通常是说相应的助动词在主语前面，而谓语动词仍在主语后面。 Here comes the taxi! （The taxi comes here.）Seldom did I go to the cinema.（助动词did提到主语前） 完全倒装句当地点副词如here、there以及back、down、off、up…在句首时，要求句子为完全倒装。 Down came the rain and up the umbrellas. 但是，当主语为代词时，主谓并不倒装。 There comes the bus.（主语为名词，主谓应倒装）There she goes.（主语为代词，主谓不倒装） 地点状语在句首时一般也要完全倒装。 At the top of the hill stood the tiny chapel. 定语从句中，也有少数情况适用这个规则。 We arrived at a farm house, in front of which sat a girl. 此规则也适用于被动语态。 In the distance could be seen the purple mountains. 部分倒装句当表示否定概念的副词，如：little, seldom, hardly, scarcely, never…，在句首时，要求使用部分倒装句。部分倒装句指的是谓语动词位置不变，而其相应的助动词要放在主语前面。 Little does he realize how important this meeting is. 但是，当否定副词不在句首时，则不倒装。 Never do cats fail to facinate human beings. 当only修饰状语或状语从句时，要求部分倒装；但当only不修饰状语而修饰其他成分时，则不倒装。 The pilot reassured the passengers. Only then did I realize how dangerous the situation had been.（修饰时间状语，因此需要倒装）Only girls are permitted to enter the theatre.（only修饰名词girls，所以不倒装） 关于so和such的倒装句 so和such在句首时也可引起部分倒装，通常可以分为两种情况： so+形容词+从句/such+从句So sudden was the attack (that) we had no time to escape. 在表示与前面句子有相同情形时，常用”so+倒装”结构He likes fishing. So do I. 当前面的句子为否定形式时，则应用”neither/nor+倒装句”，而不是使用”so+否定形式”。She doesn’t like dancing, nor/neither do I. 当前面句子中的动词出现并列，而且形式不统一时，后面的句子需要用so it is/was with结构。He was once a soldier and enjoyed hunting, so it was tieh me. 在as引导的让步状语从句中，需要倒装其表语、宾语或状语部分。 Much as we may pride ourselves on our good taste, we are no longer free to choose the things we want. 虚拟语气概述虚拟语气一般表示说话人的主观愿望、推测等，而非客观情况，常用在非真实条件句当中。 1234# 非客观事实How I wish I were a bird.If I were you I would buy this book. 虚拟语气的基本形式 虚拟语气根据其所表达意思的不同也有各种时态的变化。 如果所描述的情况与目前事实不符，用现在虚拟语气；所描述的情况与将来的情况可能不符时，用将来虚拟语气；而当所描述的情况与过去发生的情况不符时，则用过去虚拟语气。 主/从句中的动词形式 时态分类 主句中的动词形式 从句中的动词形式 与现在事实相反 should/would/could/might + 动词原形 动词的过去式(be一般用were) 与将来事实相反 should/would/could/might + 动词原形 动词的过去式、were to + 动词原形或should + 动词原形 与过去事实相反 should/would/could/might + 动词的现在完成式 动词的过去完成式 1234# 与现在事实不符If I were you, I should try it again.If you had gone to the exhibition, you would have enjoyed it. might/should/ought to + 动词的完成时态 结构表示过去可能发生而没有发生的事情。 1We should have caught the first train if we had got up earlier. wish与if only引起的虚拟语气 在英语中，可用wish或短语if only表示愿望，两者往往可以互换。if only侧重于强调所希望的情况并不存在；而wish则通常表示所希望的事情有可能发生。 12345I wish/If only Tessa were here now.I wish you wouldn&apos;t.I wish he would come tomorrow. 宾语从句中的虚拟语气 当wish, would rather/had better后接宾语从句，或在 It’s time that从句结构中，要使用虚拟语气，其虚拟语气的动词应为过去式/过去完成式，表示与现在/过去事实相反。 123I wish you saw the exhibition.I&apos;d rather she sat next to me. would rather/sooner + 从句时，从句通常使用虚拟语气。 1I would rather Jack take the former train. would rather/sooner + 从句结构也可以用于表示和过去的情况相反。 1I&apos;d rather he hadn&apos;t told me about it. suggest, propose, advise, insist, command, order, require, request和recommend等动词，在引导宾语从句时通常使用虚拟语气。 上述动词一般表示使令概念，因此它所要求的宾语从句当中的动作未必一定能实现，符合虚拟语气所表达的概念特点，其虚拟语气的谓语动词为should + 动词原形，但should常可以省略。 1To save time, I suggest we meet at the restaurant. 主语从句中的虚拟语气(It’s vital/essential + that 从句等引导的虚拟语气)表示重要、必要等意义的形容词，如important， vital，essential，necessary，desirable等，从句中的谓语用should + 动词原形。 123Was it essential that my uncle be informed?It is vital that we should control the spread of malaria. 由as if/though 引导的虚拟语气 当as if/though 进行非事实的比喻或夸张时，经常可以引导虚拟语气。 123The old machine runs as if it were a new one.He talked about Japan as if he had been there for many times. as if也可以用在句首，表示惊讶、不满、气愤的语气。 1As if we were all stupid and he alone clever! 如果as if表示的是一种真实的情况，应该用正常语气。 1It looks as if it is going to rain soon. 虚拟语气中的倒装结构在虚拟条件中，可以使用倒装结构的形式代替if。 123Should you change your mind, let us know.Had I realized what you intended I should not have wasted my time trying to explain matters to you. it的用法it作非人称代词 it指前面已经提到过的人或物时，作真实主语。 1What a beautiful baby, is it your nephew? it在句子当中作非人称代词时，常常用来表示时间、天气、温度、度量衡、距离等，因为在这种情况下它没有实际意义。 适用范围 栗子 时间、季节 It’s Spring Festival today. 天气、气候 It’s hot, though it’s raining. 温度 It’s 33 centigrade in the room. 距离、度量 It’s 10 KM to Paris. 环境 It’s noisy in here. 现状 Isn’t it a shame! 与since/says等连用 It’s 3 years since we last met. It says there was an earthquake in Japan yesterday. it作形式主语当不定式、动名词或名词从句作主语时，为了使句子的结构更加平稳、对称，我们经常使用it作形式主语，后面接不定式、动名词或名词从句作真正主语。 123It is pleasant to lie in the sun.It doesn&apos;t matter when we arrive. it用在强调句中强调句也叫分裂句，它通常可以用于强调某个词或短语。其结构为It is/was + 被强调的对象 + that 或 who(m)从句，其中that可用于引导强调任何内容的从句，who(m)只用于强调人的从句。 12It was Freda who/that phoned Jack last night.It was last night that Freda phoned. it作形式宾语it + 形容词 可用在像find一类的动词之后作形式宾语或先行宾语，再接作真正宾语的动词不定式或that引导的从句。 123Tom finds it diffcult to concenrate.Jones thinks it funny that I&apos;ve taken up yoga. it的一些搭配it还可用在enjoy, like, love, hate等动词后。 1I don&apos;t like it when you shout at me. It seems that/is possible that从句这种从句中it常常充当先行主语。 1It seems that he forgot to sign the letter. 句子概述 句子是一个完整的意义表述单位，通常由主语和谓语动词及其它附加成分组成。句子的主语可能藏而不漏。 123They arrived.Open the door, please. 由一个单词构成的或缩略的话同样也是一个完整的意义单位，特别是在口语或书面对话中尤为常见。 12345Good.All right!Want any help? 就其功能来说，句子是可以在基本句型的基础上进行扩充的。 12The man ran away.The man who stole the money ran away. 简单句 简单句是最小的句子单位。简单句一般只有一个谓语动词，并且由一个主谓结构组成。 1Last week I went to the theatre. 简单陈述句的语序很重要，否则表达的意思不同。 123The police arrested the thief.The thief arrested the policeman. 一个简单陈述句可以包含五个部分： 主语、谓语、宾语或表语、补语、状语。状语可以根据需要放在句尾、句中或句首。 123I(主) enjoyed(谓) the film(宾) yesterday(状).They(主) appointed(谓) him(宾) chairman(宾补). 有时，简单句中主语、谓语及宾语会通过连词(and, or, but, both and, either or, neither nor等)串接起来，从而形成主语、谓语、宾语并列的形式。 12345The boss and his secreteary(并列主语) are flying to Paris.I met Jane and her husband(并列宾语).We sang and danced(并列谓语) all night. 在英语中，状语是使用最频繁和最富变化的，它能使语言描述更加具体、形象、生动。 123In those days(时间状语) wandering minstrels(主语) were welcome(谓语) everwhere(地点状语)。Editors of newspapers and magazines(主语) often(频度状语) go to extremes(谓语) to provide their readers(目的状语) with unimportant facts and statistics(方式状语). 英语中常会出现同位语，它通常与所说的此有对等的关系。 1This was the Vasa, royal flagship of the great imperial fleet. 根据动词后面所使用的不同成分，简单句可分为五种基本句型。 12345678910111213141516171819202122# 主语+动词My head aches.# 主语+动词+主语补足语# 主语补足语通常出现在被动语态中。当还原为主动语态时，主语补足语则变成宾语补足语。Trump was made President of the U.S.A.Americans make Trump President of the U.S.A.# 主语+动词+直接宾语My sister enjoyed the play.# 主语+动词+间接宾语+直接宾语(双宾语)# 直接宾语一般表示物，而间接宾语则表示人# 通常间接宾语在前，直接宾语在后The firm gave Sam a watch.# 主语+动词+宾语+宾语补足语They made Sam chairman. 并列句 并列句一般是由并列连词(and, but, so, yet等)，分号或分号后跟一个并列连接副词(however, above, all, as far as等)，将两个或两个以上的简单句连接而成。 12345678910# 用并列连词连接You can wait here adn I&apos;ll get the car.# 用分号连接We fished all day; we didn&apos;t catch a thing.# 分号后再跟连接副词We fished all day; however, we didn&apos;t catch a thing. 并列句中不存在单独的主句和从属于它的从句。各并列句根据上下文的要求按逻辑顺序排列，但各个并列句均同等重要并且独立存在。 123The swimmer seemed to be in diffculty, but he managed to reach the shore in the end.I saw him yesterday but he did not greet me. 复合句 英语中复合句的使用最为广泛，在书面语中更是如此。复合句的构成方法通常是用从属连词，如if/unless引导条件状语从句、because/as/since表示原因、when/while/as soon as/until表示时间、where表示地点、although/though/as表示让步…把简单句连接起来。其中包括一个独立的简单句(主句)和一个或几个从属简单句(从句)。主句可以单独存在。 1The alarm was raised(主句) as soon as the fire was discovered(从句). 复合句从其作用上来说大致分为三个类型。 12345678910# 状语从句However hard I try, I can&apos;t remember people&apos;s names.# 名词性从句He told me (that) the match had been cancelled.# 定语从句All the things (that) I had packed so carefully were soon in a dreadful mess. 状语从句状语从句在句子中可以说明事情发生的时间、地点、原因、方式、结果、目的等，用相关的从属连词引导。 12345The children ran away after they had broken the window.As soon as the sun set we returned to our hotel.He missed the train because he did not hurry. 时间状语从句 时间状语从句一般回答when的问题，并且可以由下列从属连词引导(when, after, as soon as, before, by the time…)当状语从句位于句首时，后常用逗号隔开。 1234567You didn&apos;t look very well when you got up this moring.When he got married, Alf was too embarrassed to say anything to his wife adout his job.Whenever I meet his, he always talks about his personal problems.The moment he arrives, I shall let you know. 地点状语从句 这类从句回答where的问题，可由where， wherever, anywhere等连词引导。地点状语从句一般置于主语之后。 123You can&apos;t camp anywhere you like these days.Everywhere Jenny goes she&apos;s mistaken for Princess Diana. 方式状语从句 这类从句回答how问题，它可以由as和(in) the way引导。方式状语从句一般置于主句之后。be, act, appear, behave,sound…等后面通常用as if 和 as though。 12345I feel as if/as though I&apos;m floating on air.It feels as if it&apos;s going to rain.The fish isn&apos;t cooked as I like it. 原因状语从句 原因状语从句回答由why引导的问题，由以下从属连词(because, as, seeing, since…)引导。 123As/Because/Since there was very little support, the strike was not successful.I&apos;m afraid we don&apos;t stock refills for pens like yours because there&apos;s little demand for them. 条件状语从句 条件状语从句表示动作发生的条件，通常由连词(if, on condition that, unless, as/so long as…)引导。 12345678910If you see him, will you tell him about it?If I lose my job, I will go abroad.If the weather clears, we&apos;ll go for a walk.If you went to the exhibition you would enjoy it.If I had been in your position, I would have acted differently.If it rains tomorrow, we&apos;ll stay at home. 让步状语从句 让步状语从句含有使句子有对比的意义。引导让步状语从句的常用连词有: although, considering, though/as, even if, even though, while, whereas, no matter how, however… 123456While I disapprove of what you say, I would defend to the death your right to say it.I told him to report to me after the job was completed, no matter how late it was.# though多用于正式的口语或书面语， although用于各种文体Although/Though the factory is small, its products are of very good quality. 名词性从句名词性从句在句子中起名词的作用，可以作主语、宾语、表语及同位语。因此从功能上将其定义主语从句、宾语从句、表语从句和同位语从句。 主语从句 主语从句通常由which, who, that, what, when, where, whether等引导，在句子当中一般充当主语。 123Whether we find a joke funny or not largely depends on where we have been brought up.It has been said that everyone lives by selling something. 宾语从句 名词性从句作宾语时，前面的that经常被省略，特别是在非正式文体中更是如此。 1Everyone knows (that) money doesn&apos;t grow on trees. 同位语从句 跟在fact, idea, news, information, thought…后面的名词性从句通常是同位语从句。同位语从句中的that不能省略且不作任何成分，从含义上来说，它对其所修饰的词具有同等解释的作用。 1The fact that his proposal makes sense should be recognized. 定语从句 定语从句通常由关系代词(who, whom, which, that, whose)或关系副词(where, when, why)等引导。 从形式上来说，它通常分为两种情况:限制性定语从句（它一般提供被修饰名词的重要信息，对中心词起修饰作用，不能省略。这种定语从句与其修饰的词之间一般没有逗号隔开。）非限制性定语从句（它提供补充性信息，对其中心词起补充说明作用，可以省去。这种关系从句与其所修饰的词之间一般要有逗号隔开。） 12345# 限制性The government which promises to cut taxes。# 非限制性The government, which promises to cut taxes, will be popular. 定语从句中关系代词和关系副词的使用是有严格的界限和规定的。 定语从句中常用的关系代词有that(指人或物，在从句中充当主语或宾语)、who(指人，在从句中充当主语)、whom(指人，在从句中充当宾语)、which(指物或修饰整个句子)、whose(所指对象不限，在从句中充当定语)、as(指事件或现象，在从句中充当主语或宾语)。关系副词有(where, when, why…)。 在表示时间、地点、原因的限制性及非限制性定语从句中，可以使用关系副词when, where, why。这些关系副词在定语从句中作状语。 1231989 was the year when (in which) my son was born.She knows a wood where (in which) we can find wild strawberries. 在有些情况下，不管先行词是表示人还是物，只要指代它的是关系代词，即在剧中不作状语，就只用that而不用which或who/whom。 12345I&apos;ll do anything (that) I can.Bach is the greatest composer that&apos;s ever lived.Which is the flower that you just watered? 在所有的关系词中as的用法最为特殊。它主要有以下三种用法: 12345678# 当从句的先行词前有有such或the same时，必须使用as。I haven&apos;t seen such a good painting as you described just now.# as可像which一样引导一个定语从句修饰整个线性主句，而不是某一个单词。Taiwan belongs to China, as is known.# as是关系词中唯一可以置于句首的关系词。As is known., Taiwan belongs to China.]]></content>
      <categories>
        <category>English</category>
      </categories>
      <tags>
        <tag>English</tag>
        <tag>Grammar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[国际音标]]></title>
    <url>%2F2018%2F11%2F13%2FInternationalPhoneticAlphabet%2F</url>
    <content type="text"><![CDATA[参考： 国际音标维基 巴士英语网: https://en-yinbiao.xiao84.com/yinbiaofayin/ 知乎@姜枣茶茶母的回答: https://www.zhihu.com/question/19913374 介绍英语发音有多个国家的区别，我们重点了解两个： 公认发音，英国标准（Received pronunciation, RP） 通用美式英语（General American, GA） 国际音标(International Phonetic Alphabet，缩写：IPA)旁边的分隔号和括号并非音标的一部分，它们是语言专家用以分辨两个主要标音方法：音位标音和语音学标音。 48个国际音标通常是国内学生学习英语、学好英语发音必须掌握的发音基础，48个国际音标表也被称作48个音标表、48个英语音标表、48个英语国际英标表，48个国际英语音标表，这些称呼通常都是指48个英语国际英标表。48个国际音标中有20个元音、28个辅音。 元音，又称母音。 元音是在发音过程中由气流通过口腔而不受阻碍发出的音。按前后分类为高 、中、低元音。按音节分，可分为单元音和双元音。 气流在口腔或咽头受到阻碍而形成的音叫做辅音，辅音又叫子音。 共分为清辅音、浊辅音、鼻音、舌侧音 、半元音五种不同类型。其中鼻音、舌侧音 、半元音为浊辅音。 英语元音和辅音在英语发音中扮演着重要的角色，英语元音和辅音组合起来就成为英语音标，共48个音位，是英语发音的基础。 发音与技巧巴士英语网有每个音标的发音: https://en-yinbiao.xiao84.com/yinbiaofayin/ 国际音标： 1 2 3 4 元音 单元音 双元音 前元音 中元音 后元音 开合双元音 集中双元音 /iː/, /ɪ/, /e/, /æ/ /ɜː/, /ə/, /ʌ/ /uː/, /ʊ/, /ɔː/, /ɒ/, /ɑː/ /eɪ/, /aɪ/, /ɔɪ/, /aʊ/, /əʊ/ /ɪə/, /eə/, /ʊə/ 辅音 爆破音 摩擦音 破擦音 鼻音 舌则音 半元音 清辅音 浊辅音 清辅音 浊辅音 清辅音 浊辅音 浊辅音 浊辅音 浊辅音 /p/, /t/, /k/ /b/, /d/, /ɡ/ /f/, /s/, /ʃ/, /θ/, /h/ /v/, /z/, /ʒ/, /ð/, /r/ /tʃ/, /tr/, /ts/ /dʒ/, /dr/, /dz/ /m/, /n/, /ŋ/ /l/ /j/, /w/ 1 2 3 元音20个 长元音 短元音 双元音 /iː/, /ɑː/, /ɔː/, /uː/, /ɜː/ /ɪ/, /ʌ/, /ɒ/, /ʊ/, /ə/, /æ/, /e/ /eɪ/, /aɪ/, /ɔɪ/, /ɪə/, /eə/, /ʊə/, /aʊ/, /əʊ/ 辅音28个 轻辅音 浊辅音 轻辅音 浊辅音 鼻音 半元音 边音 /p/, /t/, /k/, /f/, /θ/, /s/ /b/, /d/, /ɡ/, /v/, /ð/, /z/ /ʃ/, /h/, /ts/, /tʃ/, /tr/ /ʒ/, /r/, /dz/, /dʒ/, /dr/ /m/, /n/, /ŋ/ /j/, /w/ /l/ 知识点讲解长短元音的区别在于——是否有: 有，则拖长音节 无，则短促音结尾 双元音就是把两个单元音拼到一起 发音也是两个拼到一起的，如： 12345/iə/= /i/ + /ə//uə/= /u/ + /ə//εə/= /e/ + /ə/ 清浊辅音的区别在于——喉结是否震动 震动，浊辅音 不震动，清辅音 鼻音—鼻腔发出 难读的音标易出问题的地方： 核心技巧： 用中文的音近字代替 用简单的英文字母或单词进行备注 中文字很挫，两种方法结合使用，哪个好记用哪个。 元音部分发音讲解： 12345678/ei/ ：A/ai/ ：I/ɔi/ ：“噢一”/iə/ : /i/ + /ə/ = ear/eə/ : /e/ + /ə/ = air/uə/ : /u/ + /ə/ = 污饿/əu/ ：O/au/ ：嗷（张大嘴） 辅音部分发音讲解： 第一组：/s/, /z/ 和 /θ/, /ð/这两组发音听起来差不多，唯一的区别在于：舌头是否看得见 看不见，/s/, /z/ 看得见，/θ/, /ð/ 第二组：/ʃ/, /ʒ/ “屎” “日” 第三组：/h/, /r/ “喝” “弱” 第四组：/ts/, /dz/ “此” “滋” 第五组：/tʃ/, /dʒ/ “尺” “之” 第六组：/tr/, /dr/ “戳” “捉” 第七组：/m/, /n/, /ŋ/ 都是发“嗯”的音，只是嘴型大小不一样。 /m/, 闭紧 /n/, 半张开 /ŋ/, 张大嘴 第八组：/l/这个音最难发，因为声音有点奇怪，像大舌头。发音技巧在于，把舌尖抵在上门牙底端，然后自然发出声音，就是这个音标啦。 知识点讲解 /m/, /n/, /l/ 分别有两个发音，一个是上面讲解的发音，另一个是他们的本来音，即英文字母m/n/l的发音（么，讷，勒）。 本身发音： 出现在每个音节的开头 奇怪音： 出现在每个音节的中间 练习自己找单词书进行测试和练习。]]></content>
      <categories>
        <category>English</category>
      </categories>
      <tags>
        <tag>English</tag>
        <tag>国际音标</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[劳动法]]></title>
    <url>%2F2018%2F10%2F26%2F%E5%8A%B3%E5%8A%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[参考： 中华人民共和国劳动法（2009年修正本） 《中华人民共和国劳动法》是为了保护劳动者的合法权益，调整劳动关系，建立和维护适应社会主义市场经济的劳动制度，促进经济发展和社会进步，根据宪法，制定本法。1994年7月5日第八届全国人民代表大会常务委员会第八次会议通过，自1995年1月1日起施行。 （1994年7年5日第八届全国人民代表大会常务委员会第八次会议通过 1994年7月5日中华人民共和国主席令第28号公布 根据2009年8月27日中华人民共和国主席令第18号《全国人民代表大会常务委员会关于修改部分法律的决定》修正 自公布之日起施行） 总则第一条： 为了保护劳动者的合法权益，调整劳动关系，建立和维护适应社会主义市场经济的劳动制度，促进经济发展和社会进步，根据宪法，制定本法。 第二条： 在中华人民共和国境内的企业、个体经济组织（以下统称用人单位）和与之形成劳动关系的劳动者，适用本法。 国家机关、事业组织、社会团体和与之建立劳动合同关系的劳动者，依照本法执行。 第三条: 劳动者享有平等就业和选择职业的权利、取得劳动报酬的权利、休息休假的权利、获得劳动安全卫生保护的权利、接受职业技能培训的权利、享受社会保险和福利的权利、提请劳动争议处理的权利以及法律规定的其他劳动权利。 劳动者应当完成劳动任务，提高职业技能，执行劳动安全卫生规程，遵守劳动纪律和职业道德。 第四条: 用人单位应当依法建立和完善规章制度，保障劳动者享有劳动权利和履行劳动义务。 第五条: 国家采取各种措施，促进劳动就业，发展职业教育，制定劳动标准，调节社会收人，完善社会保险，协调劳动关系，逐步提高劳动者的生活水平。 第六条: 国家提倡劳动者参加社会义务劳动，开展劳动竞赛和合理化建议活动，鼓励和保护劳动者进行科学研究、技术革新和发明创造，表彰和奖励劳动模范和先进工作者。 第七条: 劳动者有权依法参加和组织工会。 工会代表和维护劳动者的合法权益，依法独立自主地开展活动。 第八条: 劳动者依照法律规定，通过职工大会、职工代表大会或者其他形式，参与民主管理或者就保护劳动者合法权益与用人单位进行平等协商。 第九条: 国务院劳动行政部门主管全国劳动工作。 县级以上地方人民政府劳动行政部门主管本行政区域内的劳动工作。 促进就业第十条: 国家通过促进经济和社会发展，创造就业条件，扩大就业机会。 国家鼓励企业、事业组织、社会团体在法律、行政法规规定的范围内兴办产业或者拓展经营，增加就业。国家支持劳动者自愿组织起来就业和从事个体经营实现就业。 第十一条: 地方各级人民政府应当采取措施，发展多种类型的职业介绍机构，提供就业服务。 第十二条: 劳动者就业，不因民族、种族、性别、宗教信仰不同而受歧视。 第十三条: 妇女享有与男子平等的就业权利，在录用职工时，除国家规定的不适合妇女的工种或者岗位外，不得以性别为由拒绝录用妇女或者提高对妇女的录用标准。 第十四条: 残疾人、少数民族人员、退出现役的军人的就业，法律、法规有特别规定的，从其规定。 第十五条: 禁止用人单位招用未满十六周岁的未成年人。 文艺、体育和特种工艺单位招用未满十六周岁的未成年人，必须依照国家有关规定，履行审批手续，并保障其接受义务教育的权利。 劳动合同和集体合同第十六条: 劳动合同是劳动者与用人单位确立劳动关系、明确双方权利和义务的协议。 建立劳动关系应当订立劳动合同。 第十七条: 订立和变更劳动合同，应当遵循平等自愿、协商一致的原则，不得违反法律、行政法规的规定。 劳动合同依法订立即具有法律约束力，当事人必须履行劳动合同规定的义务。 第十八条: 下列劳动合同无效：（一）违反法律、行政法规的劳动合同；（二）采取欺诈、威胁等手段订立的劳动合同。 无效的劳动合同，从订立的时候起，就没有法律约束力。确认劳动合同部分无效的，如果不影响其余部分的效力，其余部分仍然有效。劳动合同的无效，由劳动争仪仲裁委员会或者人民法院确认。 第十九条: 劳动合同应当以书面形式订立，并具备以下条款：（一）劳动合同期限；（二）工作内容；（三）劳动保护和劳动条件；（四）劳动报酬；（五）劳动纪律；（六）劳动合同终止的条件；（七）违反劳动合同的责任。 劳动合同除前款规定的必备条款外，当事人可以协商约定其他内容。 第二十条: 劳动合同的期限分为有固定期限、无固定期限和以完成一定的工作为期限。 劳动者在同一用人单位连续工作满十年以上，当事人双方同意续延劳动合同的，如果劳动者提出订立无固定期限的劳动合同，应当订立无固定期限的劳动合同。 第二十一条: 劳动合同可以约定试用期。试用期最长不得超过六个月。 第二十二条: 劳动合同当事人可以在劳动合同中约定保守用人单位商业秘密的有关事项。 第二十三条: 劳动合同期满或者当事人约定的劳动合同终止条件出现，劳动合同即行终止。 第二十四条: 经劳动合同当事人协商一致，劳动合同可以解除。 第二十五条: 劳动者有下列情形之一的，用人单位可以解除劳动合同：（一）试用期间被证明不符合录用条件的；（二）严重违反劳动纪律或者用人单位规章制度的；（三）严重失职，营私舞弊，对用人单位利益造成重大损害的；（四）被依法追究刑事责任的。 第二十六条： 有下列情形之一的，用人单位可以解除劳动合同，但是应当提前三十日以书面形式通知劳动者本人：（一）劳动者患病或者非因工负伤，医疗期满后，不能从事原工作也不能从事由用人单位另行安排的工作的；（二）劳动者不能胜任工作，经过培训或者调整工作岗位，仍不能胜任工作的。（三）劳动合同订立时所依据的客观情况发生重大变化，致使原劳动合同无法履行，经当事人协商不能就变更劳动合同达成协议的。 第二十七条: 用人单位濒临破产进行法定整顿期间或者生产经营状况发生严重困难，确需裁减人员的，应当提前三十日向工会或者全体职工说明情况，听取工会或者职工的意见，经向劳动行政部门报告后，可以裁减人员。 用人单位依据本条规定裁减人员，在六个月内录用人员的，应当优先录用被裁减的人员。 第二十八条: 用人单位依据本法第二十四条、第二十六条、第二十七条的规定解除劳动合同的，应当依照国家有关规定给予经济补偿。 第二十九条: 劳动者有下列情形之一的，用人单位不得依据本法第二十六条、第二十七条的规定解除劳动合同：（一）患职业病或者因工负伤并被确认丧失或者部分丧失劳动能力的；（二）患病或者负伤，在规定的医疗期内的；（三）女职工在孕期、产期、哺乳期内的；（四）法律、行政法规规定的其他情形。 第三十条: 用人单位解除劳动合同，工会认为不适当的，有权提出意见。如果用人单位违反法律、法规或者劳动合同，工会有权要求重新处理；劳动者申请仲裁或者提起诉讼的，工会应当依法给予支持和帮助。 第三十一条: 劳动者解除劳动合同，应当提前三十日以书面形式通知用人单位。 第三十二条: 有下列情形之一的，劳动者可以随时通知用人单位解除劳动合同：（一）在试用期内的；（二）用人单位以暴力、威胁或者非法限制人身自由的手段强迫劳动的；（三）用人单位未按照劳动合同约定支付劳动报酬或者提供劳动条件的。 第三十三条: 企业职工一方与企业可以就劳动报酬、工作时间、休息休假、劳动安全卫生、保险福利等事项，签订集体合同。集体合同草案应当提交职工代表大会或者全体职工讨论通过。 集体合同由工会代表职工与企业签订；没有建立工会的企业，由职工推举的代表与企业签订。 第三十四条: 集体合同签订后应当报送劳动行政部门；劳动行政部门自收到集体合同文本之日起十五日内未提出异议的，集体合同即行生效。 第三十五条: 依法签订的集体合同对企业和企业全体职工具有约束力，职工个人与企业订立的劳动合同中劳动条件和劳动报酬等标准不得低于集体合同的规定。 工资第三十六条: 国家实行劳动者每日工作时间不超过八小时、平均每周工作时间不超过四十四小时的工时制度。 第三十七条: 对实行计件工作的劳动者，用人单位应当根据本法第三十六条规定的工时制度合理确定其劳动定额和计件报酬标准。 第三十八条: 用人单位应当保证劳动者每周至少休息一日。 第三十九条: 企业因生产特点不能实行本法第三十六条、第三十八条规定的，经劳动部门批准，可以实行其他工作和休息办法。 第四十条: 用人单位在下列节日期间应当依法安排劳动者休假：（一）元旦；（二）春节；（三）国际劳动节；（四）国庆节；（五）法律、法规规定的其他休假节日。 第四十一条: 用人单位由于生产经营需要，经与工会和劳动者协商后可以延长工作时间，一般每日不得超过一小时；因特殊原因需要延长工作时间的，在保障劳动者身体健康的条件下延长工作时间每日不得超过三小时，但是每月不得超过三十六小时。 第四十二条: 有下列情形之一的，延长工作时间不受本法第四十一条规定的限制：（一）发生自然灾害、事故或者因其他原因，威胁劳动者生命健康和财产安全，需要紧急处理的；（二）生产设备、交通运输线路、公共设施发生故障，影响生产和公众利益，必须及时抢修的；（三）法律、行政法规规定的其他情形。 第四十三条: 用人单位不得违反本法规定延长劳动者的工作时间。 第四十四条: 有下列情形之一的，用人单位应当按照下列标准支付高于劳动者正常工作时间工资的工资报酬；（一）安排劳动者延长工作时间的，支付不低于工资的百分之一百五十的工资报酬；（二）休息日安排劳动者工作又不能安排补休的，支付不低于工资的百分之二百的工资报酬；（三）法定休假日安排劳动者工作的，支付不低于工资的百分之三百的工资报酬。 第四十五条: 国家实行带薪年休假制度。 劳动者连续工作一年以上的，享受带薪年休假。具体办法由国务院规定。 第四十六条: 工资分配应当遵循按劳分配原则，实行同工同酬。 工资水平在经济发展的基础上逐步提高。国家对工资总量实行宏观调控。 第四十七条: 用人单位根据本单位的生产经营特点和经济效益，依法自主确定本单位的工资分配方式和工资水平。 第四十八条: 国家实行最低工资保障制度。最低工资的具体标准由各省、自治区直辖市人民政府规定，报国务院备案。 用人单位支付劳动者的工资不得低于当地最低工资标准。 第四十九条: 确定和调整最低工资标准应当综合参考下列因素：（一）劳动者本人及平均赡养人口的最低生活费用；（二）社会平均工资水平；（三）劳动生产率；（四）就业状况；（五）地区之间经济发展水平的差异。 第五十条: 工资应当以货币形式按月支付给劳动者本人。不得克扣或者无故拖欠劳动者的工资。 第五十一条: 劳动者在法定休假日和婚丧假期间以及依法参加社会活动期间，用人单位应当依法支付工资。 劳动安全卫生第五十二条: 用人单位必须建立、健全劳动安全卫生制度，严格执行国家劳动安全卫生规程和标准，对劳动者进行劳动安全卫生教育，防止劳动过程中的事故，减少职业危害。 第五十三条: 劳动安全卫生设施必须符合国家规定的标准。 新建、改建、扩建工程的劳动安全卫生设施必须与主体工程同时设计、同时施工、同时投入生产和使用。 第五十四条: 用人单位必须为劳动者提供符合国家规定的劳动安全卫生条件和必要的劳动防护用品，对从事有职业危害作业的劳动者应当定期进行健康检查。 第五十五条: 从事特种作业的劳动者必须经过专门培训并取得特种作业资格。 第五十六条: 劳动者在劳动过程中必须严格遵守安全操作规程。 劳动者对用人单位管理人员违章指挥、强令冒险作业，有权拒绝执行；对危害生命安全和身体健康的行为，有权提出批评、检举和控告。 第五十七条: 国家建立伤亡事故和职业病统计报告和处理制度。县级以上各级人民政府劳动行政部门、有关部门和用人单位应当依法对劳动者在劳动过程中发生的伤亡事故和劳动者 的职业病状况，进行统计、报告和处理。 女职工和未成年工特殊保护第五十八条: 国家对女职工和未成年工实行特殊劳动保护。 未成年工是指年满十六周岁未满十八周岁的劳动者。 第五十九条: 禁止安排女职工从事矿山井下、国家规定的第四级体力劳动强度的劳动和其他禁忌从事的劳动。 第六十条: 不得安排女职工在经期从事高处、低温、冷水作业和国家规定的第三级体力劳动强度的劳动。 第六十一条: 不得安排女职工在怀孕期间从事国家规定的第三级体力劳动强度的劳动和孕期禁忌从事的劳动，对怀孕七个月以上的女职工，不得安排其延长工作时间和夜班劳动。 第六十二条: 女职工生育享受不少于九十天的产假。 第六十三条: 不得安排女职工在哺乳未满一周岁的婴儿期间从事国家规定的第三级体力劳动强度的劳动和哺乳期禁忌从事的其他劳动，不得安排其延长工作时间和夜班劳动。 第六十四条: 不得安排未成年工从事矿山井下、有毒有害、国家规定的第四级体力劳动强度的劳动和其他禁忌从事的劳动。 第六十五条: 用人单位应当对未成年工定期进行健康检查。 职业培训第六十六条: 国家通过各种途径，采取各种措施，发展职业培训事业，开发劳动者的职业技能，提高劳动者素质，增强劳动者的就业能力和工作能力。 第六十七条: 各级人民政府应当把发展职业培训纳入社会经济发展的规划，鼓励和支持有条件的企业、事业组织、社会团体和个人进行各种形式的职业培训。 第六十八条: 用人单位应建立职业培训制度，按照国家规定提取和使用职业培训经费，根据本单位实际，有计划地对劳动者进行职业培训。 从事技术工种的劳动者，上岗前必须经过培训。 第六十九条: 国家确定职业分类，对规定的职业制定职业技能标准，实行职业资格证书制度，由经过政府批准的考核鉴定机构负责对劳动者实施职业技能考核鉴定。 社会保险和福利第七十条: 国家发展社会保险事业，建立社会保险制度，设立社会保险基金，使劳动者在年老、患病、工伤、失业、生育等情况下获得帮助和补偿。 第七十一条: 社会保险水平应当与社会经济发展水平和社会承受能力相适应。 第七十二条: 社会保险基金按照保险类型确定资金来源，逐步实行社会统筹。用人单位和劳动者必须依法参加社会保险，缴纳社会保险费。 第七十三条: 劳动者在下列情形下，依法享受社会保险待遇：（一）退休；（二）患病、负伤；（三）因工伤残或者患职业病；（四）失业；（五）生育。 劳动者死亡后，其遗属依法享受遗属津贴。劳动者享受社会保险待遇的条件和标准由法律、法规规定。劳动者享受的社会保险金必须按时足额支付。 第七十四条: 社会保险基金经办机构依照法律规定收支、管理和运营社会保险基金，并负有使社会保险基金保值增值的责任。 社会保险基金监督机构依照法律规定、对社会保险基金的收支、管理和运营实施监督。社会保险基金经办机构和社会保险基金监督机构的设立和职能由法律规定。任何组织和个人不得挪用社会保险基金。 第七十五条: 国家鼓励用人单位根据本单位实际情况为劳动者建立补充保险。 国家提倡劳动者个人进行储蓄性保险。 第七十六条: 国家发展社会福利事业，兴建公共福利设施、为劳动者休息、休养和疗养提供条件。 用人单位应当创造条件，改善集体福利，提高劳动者的福利待遇。 劳动争议第七十七条: 用人单位与劳动者发生劳动争议，当事人可以依法申请调解、仲裁、提起诉讼，也可以协商解决。 调解原则适用于仲裁和诉讼程序。 第七十八条: 解决劳动争议、应当根据合法、公正、及时处理的原则，依法维护劳动争议当事人的合法权益。 第七十九条: 劳动争议发生后，当事人可以向本单位劳动争议调解委员会申请调解；调解不成，当事人一方要求仲裁的，可以向劳动争议仲裁委员会申请仲裁。当事人一方也可以直接向劳动争议仲裁委员会申请仲裁。对仲裁裁决不服的，可以向人民法院提起诉讼。 第八十条: 在用人单位内，可以设立劳动争议调解委员会。劳动争议调解委员会由职工代表、用人单位代表和工会代表组成。劳动争议调解委员会主任由工会代表担任。 劳动争议经调解达成协议的，当事人应当履行。 第八十一条: 劳动争议仲裁委员会由劳动行政部门代表、同级工会代表、用人单位方面的代表组成，劳动争议仲裁委员会主任由劳动行政部门代表担任。 第八十二条: 提出仲裁要求的一方应当自劳动争议发生之日起六十日内向劳动争议仲裁委员会提出书面申请。仲裁裁决一般应在收到仲裁申请的六十日内作出。对仲裁裁决无异议的，当事人必须履行。 第八十三条: 劳动争议当事人对仲裁裁决不服的，可以自收到仲裁裁决书之日起十五日内向人民法院提起诉讼。一方当事人在法定期限内不起诉又不履行仲裁裁决的，另一方当事人可以申请人民法院强制执行。 第八十四条: 因签订集体合同发生争议，当事人协商解决不成的，当地人民政府劳动行政部门可以组织有关各方协调处理。 因履行集体合同发生争议，当事人协商解决不成的，可以向劳动争议仲裁委员会申请仲裁；对仲裁裁决不服的，可以自收到仲裁裁决书之日起十五日内向人民法院提起诉讼。 监督检查第八十五条: 县级以上各级人民政府劳动行政部门依法对用人单位遵守劳动法律、法规的情况进行监督检查，对违反劳动法律、法规的行为有权制止，并责令改正。 第八十六条: 县级以上各级人民政府劳动行政部门监督检查人员执行公务，有权进入用人单位了解执行劳动法律、法规的情况，查阅必要的资料，并对劳动场所进行检查。 县级以上各级人民政府劳动行政部门监督检查人员执行公务，必须出示证件，秉公执法并遵守有关规定。 第八十七条: 县级以上各级人民政府有关部门在各自职责范围内，对用人单位遵守劳动法律、法规的情况进行监督。 第八十八条: 各级工会依法维护劳动者的合法权益，对用人单位遵守劳动法律、法规的情况进行监督。 任何组织和个人对于违反劳动法律、法规的行为有权检举和控告。 法律责任第八十九条: 用人单位制定的劳动规章制度违反法律、法规规定的，由劳动行政部门给予警告，责令改正；对劳动者造成损害的，应当承担赔偿责任。 第九十条: 用人单位违反本法规定，延长劳动者工作时间的，由劳动行政部门给予警告，责令改正，并可以处以罚款。 第九十一条: 用人单位有下列侵害劳动者合法权益情形之一的，由劳动行政部门责令支付劳动者的工资报酬、经济补偿，并可以责令支付赔偿金：（一）克扣或者无故拖欠劳动者工资的；（二）拒不支付劳动者延长工作时间工资报酬的；（三）低于当地最低工资标准支付劳动者工资的；（四）解除劳动合同后，未依照本法规定给予劳动者经济补偿的。 第九十二条: 用人单位的劳动安全设施和劳动卫生条件不符合国家规定或者未向劳动者提供必要的劳动防护用品和劳动保护设施的，由劳动行政部门或者有关部门责令改正，可以处以罚款；情节严重的，提请县级以上人民政府决定责令停产整顿；对事故隐患不采取措施，致使发生重大事故，造成劳动者生命和财产损失的，对责任人员比照刑法第一百八十七条的规定追究刑事责任。 第九十三条: 用人单位强令劳动者违章冒险作业、发生重大伤亡事故，造成严重后果的，对责任人员依法追究刑事责任。 第九十四条: 用人单位非法招用未满十六周岁的未成年人的，由劳动行政部门责令改正，处以罚款；情节严重的，由工商行政管理部门吊销营业执照。 第九十五条: 用人单位违反本法对女职工和未成年工的保护规定，侵害其合法权益的，由劳动行政部门责令改正，处以罚款；对女职工或者未成年工造成损害的，应当承担赔偿责任。 第九十六条: 用人单位有下列行为之一，由公安机关对责任人员处以十五日以下拘留、罚款或者警告；构成犯罪的，对责任人员依法追究刑事责任： （一）以暴力、威胁或者非法限制人身自由的手段强迫劳动的。（二）侮辱、体罚、殴打、非法搜查和拘禁劳动者的。 第九十七条: 由于用人单位的原因订立的无效合同，对劳动者造成损害的，应当承担赔偿责任。 第九十八条: 用人单位违反本法规定的条件解除劳动合同或者故意拖延不订立劳动合同的，由劳动行政部门责令改正；对劳动者造成损害的，应当承担赔偿责任。 第九十九条: 用人单位招用尚未解除劳动合同的劳动者，对原用人单位造成经济损失的，该用人单位应当依法承担连带赔偿责任。 第一百条: 用人单位无故不缴纳社会保险费的，由劳动行政部门责令其限期缴纳，逾期不缴的，可以加收滞纳金。 第一百零一条: 用人单位无理阻挠劳动行政部门、有关部门及其工作人员行使监督检查权，打击报复举报人员的，由劳动行政部门或者有关部门处以罚款；构成犯罪的，对责任人员依法追究刑事责任。 第一百零二条: 劳动者违反本法规定的条件解除劳动合同或者违反劳动合同中约定的保密事项，对用人单位造成经济损失的，应当依法承担赔偿责任。 第一百零三条: 劳动行政部门或者有关部门的工作人员滥用职权、玩忽职守、徇私舞弊、构成犯罪的，依法追究刑事责任；不构成犯罪的，给予行政处分。 第一百零四条:国家工作人员和社会保险基金经办机构的工作人员挪用社会保险基金，构成犯罪的，依法追究刑事责任。 第一百零五条: 违反本法规定侵害劳动者合法权益，其他法律、行政法规已规定处罚的，依照该法律、行政法规的规定处罚。 附则第一百零六条: 省、自治区、直辖市人民政府根据本法和本地区的实际情况，规定劳动合同制度的实施步骤，报国务院备案。 第一百零七条: 本法自1995年1月1日起施行。]]></content>
      <categories>
        <category>法律</category>
      </categories>
      <tags>
        <tag>劳动法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[劳动合同法]]></title>
    <url>%2F2018%2F10%2F26%2F%E5%8A%B3%E5%8A%A8%E5%90%88%E5%90%8C%E6%B3%95%2F</url>
    <content type="text"><![CDATA[参考： 全国人民代表大会常务委员会关于修改《中华人民共和国劳动合同法》的决定（附2012年修正本） 网址： 中华人民共和国中央人民政府： http://www.gov.cn/ 中国政府法制信息网： http://www.chinalaw.gov.cn 百度百科 《中华人民共和国劳动合同法》是为了完善劳动合同制度，明确劳动合同双方当事人的权利和义务，保护劳动者的合法权益，构建和发展和谐稳定的劳动关系，制定本法。由第十届全国人民代表大会常务委员会第二十八次会议于2007年6月29日修订通过，自2008年1月1日起施行。（2012年12月28日第十一届全国人民代表大会常务委员会第三十次会议通过 2012年12月28日中华人民共和国主席令第73号公布 自2013年7月1日起施行） 总则第一条： 为了完善劳动合同制度，明确劳动合同双方当事人的权利和义务，保护劳动者的合法权益，构建和发展和谐稳定的劳动关系，制定本法。 第二条： 中华人民共和国境内的企业、个体经济组织、民办非企业单位等组织（以下称用人单位）与劳动者建立劳动关系，订立、履行、变更、解除或者终止劳动合同，适用本法。 国家机关、事业单位、社会团体和与其建立劳动关系的劳动者，订立、履行、变更、解除或者终止劳动合同，依照本法执行。 第三条： 订立劳动合同，应当遵循合法、公平、平等自愿、协商一致、诚实信用的原则。 依法订立的劳动合同具有约束力，用人单位与劳动者应当履行劳动合同约定的义务。 第四条 用人单位应当依法建立和完善劳动规章制度，保障劳动者享有劳动权利、履行劳动义务。 用人单位在制定、修改或者决定有关劳动报酬、工作时间、休息休假、劳动安全卫生、保险福利、职工培训、劳动纪律以及劳动定额管理等直接涉及劳动者切身利益的规章制度或者重大事项时，应当经职工代表大会或者全体职工讨论，提出方案和意见，与工会或者职工代表平等协商确定。在规章制度和重大事项决定实施过程中，工会或者职工认为不适当的，有权向用人单位提出，通过协商予以修改完善。用人单位应当将直接涉及劳动者切身利益的规章制度和重大事项决定公示，或者告知劳动者。 第五条： 县级以上人民政府劳动行政部门会同工会和企业方面代表，建立健全协调劳动关系三方机制，共同研究解决有关劳动关系的重大问题。 第六条： 工会应当帮助、指导劳动者与用人单位依法订立和履行劳动合同，并与用人单位建立集体协商机制，维护劳动者的合法权益。 劳动合同的订立第七条: 用人单位自用工之日起即与劳动者建立劳动关系。用人单位应当建立职工名册备查。 第八条: 用人单位招用劳动者时，应当如实告知劳动者工作内容、工作条件、工作地点、职业危害、安全生产状况、劳动报酬，以及劳动者要求了解的其他情况；用人单位有权了解劳动者与劳动合同直接相关的基本情况，劳动者应当如实说明。 第九条： 用人单位招用劳动者，不得扣押劳动者的居民身份证和其他证件，不得要求劳动者提供担保或者以其他名义向劳动者收取财物。 第十条： 建立劳动关系，应当订立书面劳动合同。 已建立劳动关系，未同时订立书面劳动合同的，应当自用工之日起一个月内订立书面劳动合同。用人单位与劳动者在用工前订立劳动合同的，劳动关系自用工之日起建立。 第十一条： 用人单位未在用工的同时订立书面劳动合同，与劳动者约定的劳动报酬不明确的，新招用的劳动者的劳动报酬按照集体合同规定的标准执行；没有集体合同或者集体合同未规定的，实行同工同酬。 第十二条 劳动合同分为固定期限劳动合同、无固定期限劳动合同和以完成一定工作任务为期限的劳动合同。 第十三条 固定期限劳动合同，是指用人单位与劳动者约定合同终止时间的劳动合同。 用人单位与劳动者协商一致，可以订立固定期限劳动合同。 第十四条 无固定期限劳动合同，是指用人单位与劳动者约定无确定终止时间的劳动合同。 用人单位与劳动者协商一致，可以订立无固定期限劳动合同。有下列情形之一，劳动者提出或者同意续订、订立劳动合同的，除劳动者提出订立固定期限劳动合同外，应当订立无固定期限劳动合同：（一）劳动者在该用人单位连续工作满十年的；（二）用人单位初次实行劳动合同制度或者国有企业改制重新订立劳动合同时，劳动者在该用人单位连续工作满十年且距法定退休年龄不足十年的；（三）连续订立二次固定期限劳动合同，且劳动者没有本法第三十九条和第四十条第一项、第二项规定的情形，续订劳动合同的。 用人单位自用工之日起满一年不与劳动者订立书面劳动合同的，视为用人单位与劳动者已订立无固定期限劳动合同。 第十五条： 以完成一定工作任务为期限的劳动合同，是指用人单位与劳动者约定以某项工作的完成为合同期限的劳动合同。 用人单位与劳动者协商一致，可以订立以完成一定工作任务为期限的劳动合同。 第十六条： 劳动合同由用人单位与劳动者协商一致，并经用人单位与劳动者在劳动合同文本上签字或者盖章生效。 劳动合同文本由用人单位和劳动者各执一份。 第十七条： 劳动合同应当具备以下条款：（一）用人单位的名称、住所和法定代表人或者主要负责人；（二）劳动者的姓名、住址和居民身份证或者其他有效身份证件号码；（三）劳动合同期限；（四）工作内容和工作地点；（五）工作时间和休息休假；（六）劳动报酬；（七）社会保险；（八）劳动保护、劳动条件和职业危害防护；（九）法律、法规规定应当纳入劳动合同的其他事项。 劳动合同除前款规定的必备条款外，用人单位与劳动者可以约定试用期、培训、保守秘密、补充保险和福利待遇等其他事项。 第十八条： 劳动合同对劳动报酬和劳动条件等标准约定不明确，引发争议的，用人单位与劳动者可以重新协商；协商不成的，适用集体合同规定；没有集体合同或者集体合同未规定劳动报酬的，实行同工同酬；没有集体合同或者集体合同未规定劳动条件等标准的，适用国家有关规定。 第十九条： 劳动合同期限三个月以上不满一年的，试用期不得超过一个月；劳动合同期限一年以上不满三年的，试用期不得超过二个月；三年以上固定期限和无固定期限的劳动合同，试用期不得超过六个月。 同一用人单位与同一劳动者只能约定一次试用期。以完成一定工作任务为期限的劳动合同或者劳动合同期限不满三个月的，不得约定试用期。试用期包含在劳动合同期限内。劳动合同仅约定试用期的，试用期不成立，该期限为劳动合同期限。 第二十条： 劳动者在试用期的工资不得低于本单位相同岗位最低档工资或者劳动合同约定工资的百分之八十，并不得低于用人单位所在地的最低工资标准。 第二十一条： 在试用期中，除劳动者有本法第三十九条和第四十条第一项、第二项规定的情形外，用人单位不得解除劳动合同。用人单位在试用期解除劳动合同的，应当向劳动者说明理由。 第二十二条： 用人单位为劳动者提供专项培训费用，对其进行专业技术培训的，可以与该劳动者订立协议，约定服务期。 劳动者违反服务期约定的，应当按照约定向用人单位支付违约金。违约金的数额不得超过用人单位提供的培训费用。用人单位要求劳动者支付的违约金不得超过服务期尚未履行部分所应分摊的培训费用。用人单位与劳动者约定服务期的，不影响按照正常的工资调整机制提高劳动者在服务期期间的劳动报酬。 第二十三条： 用人单位与劳动者可以在劳动合同中约定保守用人单位的商业秘密和与知识产权相关的保密事项。 对负有保密义务的劳动者，用人单位可以在劳动合同或者保密协议中与劳动者约定竞业限制条款，并约定在解除或者终止劳动合同后，在竞业限制期限内按月给予劳动者经济补偿。劳动者违反竞业限制约定的，应当按照约定向用人单位支付违约金。 第二十四条： 竞业限制的人员限于用人单位的高级管理人员、高级技术人员和其他负有保密义务的人员。竞业限制的范围、地域、期限由用人单位与劳动者约定，竞业限制的约定不得违反法律、法规的规定。 在解除或者终止劳动合同后，前款规定的人员到与本单位生产或者经营同类产品、从事同类业务的有竞争关系的其他用人单位，或者自己开业生产或者经营同类产品、从事同类业务的竞业限制期限，不得超过二年。 第二十五条： 除本法第二十二条和第二十三条规定的情形外，用人单位不得与劳动者约定由劳动者承担违约金。 第二十六条： 下列劳动合同无效或者部分无效： （一）以欺诈、胁迫的手段或者乘人之危，使对方在违背真实意思的情况下订立或者变更劳动合同的；（二）用人单位免除自己的法定责任、排除劳动者权利的；（三）违反法律、行政法规强制性规定的。 对劳动合同的无效或者部分无效有争议的，由劳动争议仲裁机构或者人民法院确认。 第二十七条： 劳动合同部分无效，不影响其他部分效力的，其他部分仍然有效。 第二十八条： 劳动合同被确认无效，劳动者已付出劳动的，用人单位应当向劳动者支付劳动报酬。劳动报酬的数额，参照本单位相同或者相近岗位劳动者的劳动报酬确定。 劳动合同的履行和变更第二十九条： 用人单位与劳动者应当按照劳动合同的约定，全面履行各自的义务。 第三十条： 用人单位应当按照劳动合同约定和国家规定，向劳动者及时足额支付劳动报酬。 用人单位拖欠或者未足额支付劳动报酬的，劳动者可以依法向当地人民法院申请支付令，人民法院应当依法发出支付令。 第三十一条： 用人单位应当严格执行劳动定额标准，不得强迫或者变相强迫劳动者加班。用人单位安排加班的，应当按照国家有关规定向劳动者支付加班费。 第三十二条： 劳动者拒绝用人单位管理人员违章指挥、强令冒险作业的，不视为违反劳动合同。 劳动者对危害生命安全和身体健康的劳动条件，有权对用人单位提出批评、检举和控告。 第三十三条： 用人单位变更名称、法定代表人、主要负责人或者投资人等事项，不影响劳动合同的履行。 第三十四条： 用人单位发生合并或者分立等情况，原劳动合同继续有效，劳动合同由承继其权利和义务的用人单位继续履行。 第三十五条： 用人单位与劳动者协商一致，可以变更劳动合同约定的内容。变更劳动合同，应当采用书面形式。 变更后的劳动合同文本由用人单位和劳动者各执一份。 劳动合同的解除和终止第三十六条： 用人单位与劳动者协商一致，可以解除劳动合同。 第三十七条： 劳动者提前三十日以书面形式通知用人单位，可以解除劳动合同。劳动者在试用期内提前三日通知用人单位，可以解除劳动合同。 第三十八条： 用人单位有下列情形之一的，劳动者可以解除劳动合同：（一）未按照劳动合同约定提供劳动保护或者劳动条件的；（二）未及时足额支付劳动报酬的；（三）未依法为劳动者缴纳社会保险费的；（四）用人单位的规章制度违反法律、法规的规定，损害劳动者权益的；（五）因本法第二十六条第一款规定的情形致使劳动合同无效的；（六）法律、行政法规规定劳动者可以解除劳动合同的其他情形。 用人单位以暴力、威胁或者非法限制人身自由的手段强迫劳动者劳动的，或者用人单位违章指挥、强令冒险作业危及劳动者人身安全的，劳动者可以立即解除劳动合同，不需事先告知用人单位。 第三十九条： 劳动者有下列情形之一的，用人单位可以解除劳动合同：（一）在试用期间被证明不符合录用条件的；（二）严重违反用人单位的规章制度的；（三）严重失职，营私舞弊，给用人单位造成重大损害的；（四）劳动者同时与其他用人单位建立劳动关系，对完成本单位的工作任务造成严重影响，或者经用人单位提出，拒不改正的；（五）因本法第二十六条第一款第一项规定的情形致使劳动合同无效的；（六）被依法追究刑事责任的。 第四十条： 有下列情形之一的，用人单位提前三十日以书面形式通知劳动者本人或者额外支付劳动者一个月工资后，可以解除劳动合同：（一）劳动者患病或者非因工负伤，在规定的医疗期满后不能从事原工作，也不能从事由用人单位另行安排的工作的；（二）劳动者不能胜任工作，经过培训或者调整工作岗位，仍不能胜任工作的；（三）劳动合同订立时所依据的客观情况发生重大变化，致使劳动合同无法履行，经用人单位与劳动者协商，未能就变更劳动合同内容达成协议的。 第四十一条： 有下列情形之一，需要裁减人员二十人以上或者裁减不足二十人但占企业职工总数百分之十以上的，用人单位提前三十日向工会或者全体职工说明情况，听取工会或者职工的意见后，裁减人员方案经向劳动行政部门报告，可以裁减人员：（一）依照企业破产法规定进行重整的；（二）生产经营发生严重困难的；（三）企业转产、重大技术革新或者经营方式调整，经变更劳动合同后，仍需裁减人员的；（四）其他因劳动合同订立时所依据的客观经济情况发生重大变化，致使劳动合同无法履行的。 裁减人员时，应当优先留用下列人员：（一）与本单位订立较长期限的固定期限劳动合同的；（二）与本单位订立无固定期限劳动合同的；（三）家庭无其他就业人员，有需要扶养的老人或者未成年人的。 用人单位依照本条第一款规定裁减人员，在六个月内重新招用人员的，应当通知被裁减的人员，并在同等条件下优先招用被裁减的人员。 第四十二条： 劳动者有下列情形之一的，用人单位不得依照本法第四十条、第四十一条的规定解除劳动合同：（一）从事接触职业病危害作业的劳动者未进行离岗前职业健康检查，或者疑似职业病病人在诊断或者医学观察期间的；（二）在本单位患职业病或者因工负伤并被确认丧失或者部分丧失劳动能力的；（三）患病或者非因工负伤，在规定的医疗期内的；（四）女职工在孕期、产期、哺乳期的；（五）在本单位连续工作满十五年，且距法定退休年龄不足五年的；（六）法律、行政法规规定的其他情形。 第四十三条： 用人单位单方解除劳动合同，应当事先将理由通知工会。用人单位违反法律、行政法规规定或者劳动合同约定的，工会有权要求用人单位纠正。用人单位应当研究工会的意见，并将处理结果书面通知工会。 第四十四条： 有下列情形之一的，劳动合同终止：（一）劳动合同期满的；（二）劳动者开始依法享受基本养老保险待遇的；（三）劳动者死亡，或者被人民法院宣告死亡或者宣告失踪的；（四）用人单位被依法宣告破产的；（五）用人单位被吊销营业执照、责令关闭、撤销或者用人单位决定提前解散的；（六）法律、行政法规规定的其他情形。 第四十五条： 劳动合同期满，有本法第四十二条规定情形之一的，劳动合同应当续延至相应的情形消失时终止。但是，本法第四十二条第二项规定丧失或者部分丧失劳动能力劳动者的劳动合同的终止，按照国家有关工伤保险的规定执行。 第四十六条： 有下列情形之一的，用人单位应当向劳动者支付经济补偿：（一）劳动者依照本法第三十八条规定解除劳动合同的；（二）用人单位依照本法第三十六条规定向劳动者提出解除劳动合同并与劳动者协商一致解除劳动合同的；（三）用人单位依照本法第四十条规定解除劳动合同的；（四）用人单位依照本法第四十一条第一款规定解除劳动合同的；（五）除用人单位维持或者提高劳动合同约定条件续订劳动合同，劳动者不同意续订的情形外，依照本法第四十四条第一项规定终止固定期限劳动合同的；（六）依照本法第四十四条第四项、第五项规定终止劳动合同的；（七）法律、行政法规规定的其他情形。 第四十七条： 经济补偿按劳动者在本单位工作的年限，每满一年支付一个月工资的标准向劳动者支付。六个月以上不满一年的，按一年计算；不满六个月的，向劳动者支付半个月工资的经济补偿。 劳动者月工资高于用人单位所在直辖市、设区的市级人民政府公布的本地区上年度职工月平均工资三倍的，向其支付经济补偿的标准按职工月平均工资三倍的数额支付，向其支付经济补偿的年限最高不超过十二年。本条所称月工资是指劳动者在劳动合同解除或者终止前十二个月的平均工资。 第四十八条： 用人单位违反本法规定解除或者终止劳动合同，劳动者要求继续履行劳动合同的，用人单位应当继续履行；劳动者不要求继续履行劳动合同或者劳动合同已经不能继续履行的，用人单位应当依照本法第八十七条规定支付赔偿金。 第四十九条： 国家采取措施，建立健全劳动者社会保险关系跨地区转移接续制度。 第五十条： 用人单位应当在解除或者终止劳动合同时出具解除或者终止劳动合同的证明，并在十五日内为劳动者办理档案和社会保险关系转移手续。 劳动者应当按照双方约定，办理工作交接。用人单位依照本法有关规定应当向劳动者支付经济补偿的，在办结工作交接时支付。用人单位对已经解除或者终止的劳动合同的文本，至少保存二年备查。 特别规定第一节 集体合同第五十一条： 企业职工一方与用人单位通过平等协商，可以就劳动报酬、工作时间、休息休假、劳动安全卫生、保险福利等事项订立集体合同。集体合同草案应当提交职工代表大会或者全体职工讨论通过。 集体合同由工会代表企业职工一方与用人单位订立；尚未建立工会的用人单位，由上级工会指导劳动者推举的代表与用人单位订立。 第五十二条： 企业职工一方与用人单位可以订立劳动安全卫生、女职工权益保护、工资调整机制等专项集体合同。 第五十三条： 在县级以下区域内，建筑业、采矿业、餐饮服务业等行业可以由工会与企业方面代表订立行业性集体合同，或者订立区域性集体合同。 第五十四条： 集体合同订立后，应当报送劳动行政部门；劳动行政部门自收到集体合同文本之日起十五日内未提出异议的，集体合同即行生效。 依法订立的集体合同对用人单位和劳动者具有约束力。行业性、区域性集体合同对当地本行业、本区域的用人单位和劳动者具有约束力。 第五十五条： 集体合同中劳动报酬和劳动条件等标准不得低于当地人民政府规定的最低标准；用人单位与劳动者订立的劳动合同中劳动报酬和劳动条件等标准不得低于集体合同规定的标准。 第五十六条： 用人单位违反集体合同，侵犯职工劳动权益的，工会可以依法要求用人单位承担责任；因履行集体合同发生争议，经协商解决不成的，工会可以依法申请仲裁、提起诉讼。 第二节 劳务派遣第五十七条： 经营劳务派遣业务应当具备下列条件：（一）注册资本不得少于人民币二百万元；（二）有与开展业务相适应的固定的经营场所和设施；（三）有符合法律、行政法规规定的劳务派遣管理制度；（四）法律、行政法规规定的其他条件。 经营劳务派遣业务，应当向劳动行政部门依法申请行政许可；经许可的，依法办理相应的公司登记。未经许可，任何单位和个人不得经营劳务派遣业务。 第五十八条： 劳务派遣单位是本法所称用人单位，应当履行用人单位对劳动者的义务。劳务派遣单位与被派遣劳动者订立的劳动合同，除应当载明本法第十七条规定的事项外，还应当载明被派遣劳动者的用工单位以及派遣期限、工作岗位等情况。 劳务派遣单位应当与被派遣劳动者订立二年以上的固定期限劳动合同，按月支付劳动报酬；被派遣劳动者在无工作期间，劳务派遣单位应当按照所在地人民政府规定的最低工资标准，向其按月支付报酬。 第五十九条： 劳务派遣单位派遣劳动者应当与接受以劳务派遣形式用工的单位（以下称用工单位）订立劳务派遣协议。劳务派遣协议应当约定派遣岗位和人员数量、派遣期限、劳动报酬和社会保险费的数额与支付方式以及违反协议的责任。 用工单位应当根据工作岗位的实际需要与劳务派遣单位确定派遣期限，不得将连续用工期限分割订立数个短期劳务派遣协议。 第六十条： 劳务派遣单位应当将劳务派遣协议的内容告知被派遣劳动者。 劳务派遣单位不得克扣用工单位按照劳务派遣协议支付给被派遣劳动者的劳动报酬。劳务派遣单位和用工单位不得向被派遣劳动者收取费用。 第六十一条： 劳务派遣单位跨地区派遣劳动者的，被派遣劳动者享有的劳动报酬和劳动条件，按照用工单位所在地的标准执行。 第六十二条 用工单位应当履行下列义务：（一）执行国家劳动标准，提供相应的劳动条件和劳动保护；（二）告知被派遣劳动者的工作要求和劳动报酬；（三）支付加班费、绩效奖金，提供与工作岗位相关的福利待遇；（四）对在岗被派遣劳动者进行工作岗位所必需的培训；（五）连续用工的，实行正常的工资调整机制。 用工单位不得将被派遣劳动者再派遣到其他用人单位。 第六十三条： 被派遣劳动者享有与用工单位的劳动者同工同酬的权利。用工单位应当按照同工同酬原则，对被派遣劳动者与本单位同类岗位的劳动者实行相同的劳动报酬分配办法。用工单位无同类岗位劳动者的，参照用工单位所在地相同或者相近岗位劳动者的劳动报酬确定。 劳务派遣单位与被派遣劳动者订立的劳动合同和与用工单位订立的劳务派遣协议，载明或者约定的向被派遣劳动者支付的劳动报酬应当符合前款规定。 第六十四条： 被派遣劳动者有权在劳务派遣单位或者用工单位依法参加或者组织工会，维护自身的合法权益。 第六十五条： 被派遣劳动者可以依照本法第三十六条、第三十八条的规定与劳务派遣单位解除劳动合同。 被派遣劳动者有本法第三十九条和第四十条第一项、第二项规定情形的，用工单位可以将劳动者退回劳务派遣单位，劳务派遣单位依照本法有关规定，可以与劳动者解除劳动合同。 第六十六条： 劳动合同用工是我国的企业基本用工形式。劳务派遣用工是补充形式，只能在临时性、辅助性或者替代性的工作岗位上实施。 前款规定的临时性工作岗位是指存续时间不超过六个月的岗位；辅助性工作岗位是指为主营业务岗位提供服务的非主营业务岗位；替代性工作岗位是指用工单位的劳动者因脱产学习、休假等原因无法工作的一定期间内，可以由其他劳动者替代工作的岗位。用工单位应当严格控制劳务派遣用工数量，不得超过其用工总量的一定比例，具体比例由国务院劳动行政部门规定。 第六十七条： 用人单位不得设立劳务派遣单位向本单位或者所属单位派遣劳动者。 第三节 非全日制用工第六十八条: 非全日制用工，是指以小时计酬为主，劳动者在同一用人单位一般平均每日工作时间不超过四小时，每周工作时间累计不超过二十四小时的用工形式。 第六十九条: 非全日制用工双方当事人可以订立口头协议。 从事非全日制用工的劳动者可以与一个或者一个以上用人单位订立劳动合同；但是，后订立的劳动合同不得影响先订立的劳动合同的履行。 第七十条: 非全日制用工双方当事人不得约定试用期。 第七十一条: 非全日制用工双方当事人任何一方都可以随时通知对方终止用工。终止用工，用人单位不向劳动者支付经济补偿。 第七十二条: 非全日制用工小时计酬标准不得低于用人单位所在地人民政府规定的最低小时工资标准。 非全日制用工劳动报酬结算支付周期最长不得超过十五日。 监督检查第七十三条： 国务院劳动行政部门负责全国劳动合同制度实施的监督管理。 县级以上地方人民政府劳动行政部门负责本行政区域内劳动合同制度实施的监督管理。县级以上各级人民政府劳动行政部门在劳动合同制度实施的监督管理工作中，应当听取工会、企业方面代表以及有关行业主管部门的意见。 第七十四条： 县级以上地方人民政府劳动行政部门依法对下列实施劳动合同制度的情况进行监督检查：（一）用人单位制定直接涉及劳动者切身利益的规章制度及其执行的情况；（二）用人单位与劳动者订立和解除劳动合同的情况；（三）劳务派遣单位和用工单位遵守劳务派遣有关规定的情况；（四）用人单位遵守国家关于劳动者工作时间和休息休假规定的情况；（五）用人单位支付劳动合同约定的劳动报酬和执行最低工资标准的情况；（六）用人单位参加各项社会保险和缴纳社会保险费的情况；（七）法律、法规规定的其他劳动监察事项。 第七十五条： 县级以上地方人民政府劳动行政部门实施监督检查时，有权查阅与劳动合同、集体合同有关的材料，有权对劳动场所进行实地检查，用人单位和劳动者都应当如实提供有关情况和材料。 劳动行政部门的工作人员进行监督检查，应当出示证件，依法行使职权，文明执法。 第七十六条： 县级以上人民政府建设、卫生、安全生产监督管理等有关主管部门在各自职责范围内，对用人单位执行劳动合同制度的情况进行监督管理。 第七十七条： 劳动者合法权益受到侵害的，有权要求有关部门依法处理，或者依法申请仲裁、提起诉讼。 第七十八条： 工会依法维护劳动者的合法权益，对用人单位履行劳动合同、集体合同的情况进行监督。用人单位违反劳动法律、法规和劳动合同、集体合同的，工会有权提出意见或者要求纠正；劳动者申请仲裁、提起诉讼的，工会依法给予支持和帮助。 第七十九条： 任何组织或者个人对违反本法的行为都有权举报，县级以上人民政府劳动行政部门应当及时核实、处理，并对举报有功人员给予奖励。 法律责任第八十条： 用人单位直接涉及劳动者切身利益的规章制度违反法律、法规规定的，由劳动行政部门责令改正，给予警告；给劳动者造成损害的，应当承担赔偿责任。 第八十一条： 用人单位提供的劳动合同文本未载明本法规定的劳动合同必备条款或者用人单位未将劳动合同文本交付劳动者的，由劳动行政部门责令改正；给劳动者造成损害的，应当承担赔偿责任。 第八十二条： 用人单位自用工之日起超过一个月不满一年未与劳动者订立书面劳动合同的，应当向劳动者每月支付二倍的工资。 用人单位违反本法规定不与劳动者订立无固定期限劳动合同的，自应当订立无固定期限劳动合同之日起向劳动者每月支付二倍的工资。 第八十三条： 用人单位违反本法规定与劳动者约定试用期的，由劳动行政部门责令改正；违法约定的试用期已经履行的，由用人单位以劳动者试用期满月工资为标准，按已经履行的超过法定试用期的期间向劳动者支付赔偿金。 第八十四条： 用人单位违反本法规定，扣押劳动者居民身份证等证件的，由劳动行政部门责令限期退还劳动者本人，并依照有关法律规定给予处罚。 用人单位违反本法规定，以担保或者其他名义向劳动者收取财物的，由劳动行政部门责令限期退还劳动者本人，并以每人五百元以上二千元以下的标准处以罚款；给劳动者造成损害的，应当承担赔偿责任。劳动者依法解除或者终止劳动合同，用人单位扣押劳动者档案或者其他物品的，依照前款规定处罚。 第八十五条： 用人单位有下列情形之一的，由劳动行政部门责令限期支付劳动报酬、加班费或者经济补偿；劳动报酬低于当地最低工资标准的，应当支付其差额部分；逾期不支付的，责令用人单位按应付金额百分之五十以上百分之一百以下的标准向劳动者加付赔偿金：（一）未按照劳动合同的约定或者国家规定及时足额支付劳动者劳动报酬的；（二）低于当地最低工资标准支付劳动者工资的；（三）安排加班不支付加班费的；（四）解除或者终止劳动合同，未依照本法规定向劳动者支付经济补偿的。 第八十六条： 劳动合同依照本法第二十六条规定被确认无效，给对方造成损害的，有过错的一方应当承担赔偿责任。 第八十七条： 用人单位违反本法规定解除或者终止劳动合同的，应当依照本法第四十七条规定的经济补偿标准的二倍向劳动者支付赔偿金。 第八十八条： 用人单位有下列情形之一的，依法给予行政处罚；构成犯罪的，依法追究刑事责任；给劳动者造成损害的，应当承担赔偿责任：（一）以暴力、威胁或者非法限制人身自由的手段强迫劳动的；（二）违章指挥或者强令冒险作业危及劳动者人身安全的；（三）侮辱、体罚、殴打、非法搜查或者拘禁劳动者的；（四）劳动条件恶劣、环境污染严重，给劳动者身心健康造成严重损害的。 第八十九条： 用人单位违反本法规定未向劳动者出具解除或者终止劳动合同的书面证明，由劳动行政部门责令改正；给劳动者造成损害的，应当承担赔偿责任。 第九十条： 劳动者违反本法规定解除劳动合同，或者违反劳动合同中约定的保密义务或者竞业限制，给用人单位造成损失的，应当承担赔偿责任。 第九十一条： 用人单位招用与其他用人单位尚未解除或者终止劳动合同的劳动者，给其他用人单位造成损失的，应当承担连带赔偿责任。 第九十二条： 违反本法规定，未经许可，擅自经营劳务派遣业务的，由劳动行政部门责令停止违法行为，没收违法所得，并处违法所得一倍以上五倍以下的罚款；没有违法所得的，可以处五万元以下的罚款。 劳务派遣单位、用工单位违反本法有关劳务派遣规定的，由劳动行政部门责令限期改正；逾期不改正的，以每人五千元以上一万元以下的标准处以罚款，对劳务派遣单位，吊销其劳务派遣业务经营许可证。用工单位给被派遣劳动者造成损害的，劳务派遣单位与用工单位承担连带赔偿责任。 第九十三条： 对不具备合法经营资格的用人单位的违法犯罪行为，依法追究法律责任；劳动者已经付出劳动的，该单位或者其出资人应当依照本法有关规定向劳动者支付劳动报酬、经济补偿、赔偿金；给劳动者造成损害的，应当承担赔偿责任。 第九十四条： 个人承包经营违反本法规定招用劳动者，给劳动者造成损害的，发包的组织与个人承包经营者承担连带赔偿责任。 第九十五条： 劳动行政部门和其他有关主管部门及其工作人员玩忽职守、不履行法定职责，或者违法行使职权，给劳动者或者用人单位造成损害的，应当承担赔偿责任；对直接负责的主管人员和其他直接责任人员，依法给予行政处分；构成犯罪的，依法追究刑事责任。 附则第九十六条： 事业单位与实行聘用制的工作人员订立、履行、变更、解除或者终止劳动合同，法律、行政法规或者国务院另有规定的，依照其规定；未作规定的，依照本法有关规定执行。 第九十七条： 本法施行前已依法订立且在本法施行之日存续的劳动合同，继续履行；本法第十四条第二款第三项规定连续订立固定期限劳动合同的次数，自本法施行后续订固定期限劳动合同时开始计算。 本法施行前已建立劳动关系，尚未订立书面劳动合同的，应当自本法施行之日起一个月内订立。本法施行之日存续的劳动合同在本法施行后解除或者终止，依照本法第四十六条规定应当支付经济补偿的，经济补偿年限自本法施行之日起计算；本法施行前按照当时有关规定，用人单位应当向劳动者支付经济补偿的，按照当时有关规定执行。 第九十八条： 本法自2008年1月1日起施行。]]></content>
      <categories>
        <category>法律</category>
      </categories>
      <tags>
        <tag>劳动合同法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bootstrap]]></title>
    <url>%2F2018%2F09%2F18%2FBootstrap%2F</url>
    <content type="text"><![CDATA[参考： Bootstrap中文文档: https://v3.bootcss.com/ 环境： CentOS7x86_64 Bootstrap v3 概述Bootstrap是最受欢迎的HTML、CSS和JS框架，用于开发响应式布局、移动设备优先的WEB项目。Bootstrap让前端开发更快速、简单。所有开发者都能快速上手、所有设备都可以适配、所有项目都适用。 起步安装 包含的内容Bootstrap 提供了两种形式的压缩包，在下载下来的压缩包内可以看到以下目录和文件，这些文件按照类别放到了不同的目录内，并且提供了压缩与未压缩两种版本。 Bootstrap 插件全部依赖 jQuery请注意，Bootstrap 的所有 JavaScript 插件都依赖 jQuery，因此 jQuery 必须在 Bootstrap 之前引入，就像在基本模版中所展示的一样。 预编译版，预编译文件可以直接使用到任何 web 项目中。 12345678910111213141516171819bootstrap/├── css/│ ├── bootstrap.css│ ├── bootstrap.css.map│ ├── bootstrap.min.css│ ├── bootstrap.min.css.map│ ├── bootstrap-theme.css│ ├── bootstrap-theme.css.map│ ├── bootstrap-theme.min.css│ └── bootstrap-theme.min.css.map├── js/│ ├── bootstrap.js│ └── bootstrap.min.js└── fonts/ ├── glyphicons-halflings-regular.eot ├── glyphicons-halflings-regular.svg ├── glyphicons-halflings-regular.ttf ├── glyphicons-halflings-regular.woff └── glyphicons-halflings-regular.woff2 Bootstrap源码，源码包含了预先编译的 CSS、JavaScript 和图标字体文件，并且还有 LESS、JavaScript 和文档的源码。 12345678910bootstrap/├── less/├── js/├── fonts/├── dist/│ ├── css/│ ├── js/│ └── fonts/└── docs/ └── examples/ 编译CSS和JS文件 基本模板这份超级简单的 HTML 模版，我们强烈建议你对这些实例按照自己的需求进行修改，而不要简单的复制、粘贴。 12345678910111213141516171819202122232425262728&lt;!DOCTYPE html&gt;&lt;html lang="zh-CN"&gt; &lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt; &lt;!-- 上述3个meta标签*必须*放在最前面，任何其他内容都*必须*跟随其后！ --&gt; &lt;title&gt;Bootstrap 101 Template&lt;/title&gt; &lt;!-- Bootstrap --&gt; &lt;link href="https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/css/bootstrap.min.css" rel="stylesheet"&gt; &lt;!-- HTML5 shim 和 Respond.js 是为了让 IE8 支持 HTML5 元素和媒体查询（media queries）功能 --&gt; &lt;!-- 警告：通过 file:// 协议（就是直接将 html 页面拖拽到浏览器中）访问页面时 Respond.js 不起作用 --&gt; &lt;!--[if lt IE 9]&gt; &lt;script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"&gt;&lt;/script&gt; &lt;script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"&gt;&lt;/script&gt; &lt;![endif]--&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;你好，世界！&lt;/h1&gt; &lt;!-- jQuery (Bootstrap 的所有 JavaScript 插件都依赖 jQuery，所以必须放在前边) --&gt; &lt;script src="https://cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"&gt;&lt;/script&gt; &lt;!-- 加载 Bootstrap 的所有 JavaScript 插件。你也可以根据需要只加载单个插件。 --&gt; &lt;script src="https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/js/bootstrap.min.js"&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 实例精选我们鼓励你根据自身项目的需要对 Bootstrap 进行定制和修改。 框架基本用法 入门级模板(starter template)只有基本的东西：引入了预编译版的 CSS 和 JavaScript 文件，页面只包含了一个 container 元素。 Bootstrap主题(theme)加载可选的 Bootstrap 主题，获得增强的视觉体验。 栅格(grids)多个关于栅格布局方面的实例，涉及到层级（tier）、嵌套（nesting）等等。 JumbotronBuild around the jumbotron with a navbar and some basic grid columns. Narrow jumbotronBuild a more custom page by narrowing the default container and jumbotron. 导航条实例(navbars) 导航条(navbar)包含导航条和一起附加内容的超级基础的模板。 静态导航条(static top navbar)包含一个静态导航条以及一些附加内容的超级基础的模板。 固定位置的导航条(fixed navbar)这是一个超简单的页面，拥有一个固定在顶部的导航条和一些演示内容。 自定义组件(customed Components) 封面图(cover)一个简单、漂亮的首页。 CarouselCustomize the navbar and carousel, then add some new components. 博客页面(blog)简单的两列式博客布局，还包含了自定义的导航、页头、分类等元素。 控制台(dashboard)包含基本结构的后台管理模板，还有固定的侧边栏和导航条。 登录页(sign-in)自定义的表单布局以及经过简单设计的登录表单。 Justified navCreate a custom navbar with justified links. Sticky footerAttach a footer to the bottom of the viewport when the content is shorter than it. Sticky footer with navbarAttach a footer to the bottom of the viewport with a fixed navbar at the top. 实现性案例(Experiments) 非响应式Bootstrap布局(Non-responsive)Easily disable the responsiveness of Bootstrap per our docs. OffcanvasBuild a toggleable off-canvas navigation menu for use with Bootstrap. 工具Tools CSSdocs: https://getbootstrap.com/docs/3.3/css/docs-cn: https://v3.bootcss.com/css/ 概览设置全局CSS样式；基本的HTML元素均可以通过class设置样式并得到增强效果；还有先进的栅格系统。 深入了解 Bootstrap 底层结构的关键部分，包括我们让 web 开发变得更好、更快、更强壮的最佳实践。 HTML5文档类型HTML5 DOCTYPE Bootstrap使用到某些HTML元素和CSS属性需要将页面设置为HTML5文档类型。在你项目的每个页面下都要参照下面的格式进行设置。 1234&lt;!DOCTYPE html&gt;&lt;html lang="zh-CN"&gt; ...&lt;/html&gt; 移动设备优先Bootstrap 是移动设备优先的。 排版与链接]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Frontend</tag>
        <tag>Bootstrap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Grafana]]></title>
    <url>%2F2018%2F09%2F13%2FGrafana%2F</url>
    <content type="text"><![CDATA[参考： Grafana 文档: http://docs.grafana.org/ GitHub: https://github.com/grafana/ 环境： CentOS7x86_64 Grafana v5.2]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Grafana</tag>
        <tag>Monitoring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Prometheus]]></title>
    <url>%2F2018%2F09%2F11%2FPrometheus%2F</url>
    <content type="text"><![CDATA[参考： Prometheus文档： https://prometheus.io/docs GitHub: https://github.com/prometheus/ PrometheusAlert: https://github.com/feiyu563/PrometheusAlert 环境： CentOS7x86_64 Prometheus v2.14 介绍Introduction 概述 Prometheus是什么What is Prometheus? Prometheus是一个最初在SoundCloud上构建的开源监控系统和报警工具包。现在是一个独立的开源项目，由社区进行维护。 功能(Features)Prometheus的主要特点： 具有由度量名称(metric name)和键值对(key-value)标识的时间序列(time series)数据的多维(multi-dimensional)数据模型 灵活的查询语言，以利用此维度 不依赖分布式存储(distributed storage)，单个服务器节点是自治的(autonomous) 时间序列集合通过HTPP的pull model发生 push时间序列通过中间网关(intermediary gateway)的支持 通过服务发现或静态配置来发现目标 图形和仪表盘支持多种模式 组件(Components)Prometheus系统由多个组件构成，其中某些组件是可选的： 主要的Prometheus Server，用于存储时间序列数据 client libraries，用于检测应用程序代码 push gateway，用于支持短暂的(short-lived)工作 exporters，用于服务的特殊目的 alertmanager，用于处理报警 各种支持工具 架构(Architecture)Prometheus的体系结构和系统组件图： 什么时候适合When does it fit? Prometheus适用于记录任何纯数字时间序列。它既适用于以机器为中心的监控，也适用于高度动态的面向服务架构的监控。在微服务的世界中，它对多维数据收集和查询的支持是一种特殊的优势。Prometheus专为提高可靠性而设计，是你在断电期间可以快速诊断问题的系统。每个Prometheus Server都是独立的，不依赖于网络存储或其它远程服务。当基础架构其它部分损坏时，你仍可以依赖它，并且你不需要设置大量的基础架构来使用它。 什么时候不适合When does it not fit? Prometheus重视可靠性。即使在系统故障情况下，你也可以随时查看有关系统的可用统计信息。如果你需要100%的准确度，Prometheus不是一个好的选择，你可能需要使用其它系统。 第一步步骤： 下载 配置 运行 使用表达式浏览器 使用图形接口 监控其它目标 术语GLOSSARY Alert是Prometheus正在开火的警报规则的结果。警报从Prometheus发送到AlterManger。 Alertmanager接收警报，将它们聚合成组，删除重复数据，应用静音、限制，然后发送电子邮件等通知。 Bridge是一个从Client Library中获取样本并将它们暴露给 non-Prometheus 监控系统的组件。例如，Python、Java、Go…客户端可将指标导出到Graphite。 Client library是某种语言的库(Go, Java, Python…)，可以直接检测代码，编写自定义收集器以从其它系统中收集指标并将指标公开给Prometheus。 Collector是表示一组度量标准的 exporter 的一部分。如果它是直接检测的一部分，则可以是单个度量，如果是从另一个系统提取度量，则可以是许多度量。 Direct instrumentation作为源代码程序的一部分内联添加的检测。 Endpoint Exporter是一个公开Prometheus指标的程序，通常将 non-prometheus 格式的指标转换为 Prometheus 支持的格式。 Instance唯一标识作业中目标的标签 Job具有相同目的的目标集合 Notification代表一组多个警报 Promdash原生Prometheus仪表盘构建器。它已被弃用，并被 Grafana 取代 Prometheus通常指的是Prometheus System的核心程序，也可指整个监控系统。 PromQLPrometheus Query Language Pushgateway持续从批量作业中最新推出的指标 Remote Read允许从其它系统透明读取时间序列作为查询的一部分 Remote Read Adapter并非所有系统都支持远程读取。远程读取适配器便是用于此。 Remote Read EndpointPrometheus进行远程读取时的对象 Remote Write允许动态地将采集的样本发送到其它系统 Remote Write Adapter Remote Write Endpoint Sample时间序列中某个时间点的单个值，Prometheus中，每个样本都包含一个float64和ms精度的时间戳。 Silence防止报警 Target抓取对象的定义 FAQfaq: https://prometheus.io/docs/introduction/faq/ 概念CONCEPTS 数据模型Data model Prometheus从根本上将所有数据存储为时间序列(time series): 属于同一指标和同一标记维度的带时间戳值的流。除了存储时间序列，Prometheus还可以临时生成时间序列作为查询的结果。 指标名称和标签Metric names and labels 每个时间序列都是有指标名称(metric name)和一组键值对(也称为标签(label))来唯一标识。 指标名称： 可能包含ASCII字母，下划线，冒号。它必须匹配正则: [a-zA-Z_:][a-zA-Z0-9_:]*。标签启用Prometheus的维度数据模型： 指标类型metric types: https://prometheus.io/docs/concepts/metric_types/ Prometheus Client Library提供了四个核心指标类型。这些目前仅在客户端和在有线协议(wire protocol)中区分。Prometheus Server尚未使用的类型信息和所有数据合并为无类型(untyped)时间序列。这在未来可能改变。 Prometheus clinet使用文档: Go Java Python CounterCounter，只增不减的计数器。 Counter是一个累计指标，代表一个单调递增计数器，即只增不减，除非重启或被重置为0。例如，你可以使用counter来代表服务的请求数、已完成的任务数、错误的数量… 不要用counter来暴露一个可以减少的值。例如，不要对当前运行的进程数使用counter类型，使用gauge类型。 一般在定义counter类型指标的名称时，推荐使用xxx_total作为后缀名。（如http_request_total） 12345# 获取HTTP请求量的增长率rate(http_requests_total[5m])# 统计前十topk(10, http_requests_total) GaugeGauge，可以任意变化的仪表盘。 Gauge类型代表一个样本数据可以任意变化，即可增可减。通常用于像温度、内存使用率这种指标数据，也可表示能随时升降的计数（如当前的并发数）。 12345# 获取一段时间内的变化情况dalta(cpu_temp_celsius&#123;host=&quot;zeus&quot;&#125;[2h])# 简单线性回归，预测未来数据predict_linear(node_filesystem_free&#123;job=&quot;node&quot;&#125;[2h], 4 * 3600) &lt; 0 HistogramHistogram和Summary主用用于统计和分析样本的分布情况。 Histogram(直方图)在一段时间范围内对数据进行采样（通常是请求持续时间(request durations)和响应大小(response sizes)等），并将其计入可配置的存储桶(bucket)中，后续可通过指定区间筛选样本，也可以统计样本总数，最后一般将数据展示为直方图。 Histogram类型的样本会提供三种指标： 样本值分布在桶中的数量，命名为xxx_bucket{le=&quot;&lt;上边界&gt;&quot;}。标识指标值小于等于上边界所有样本数量。 所有样本值的大小总和，命名为xxx_sum。 样本总数，命名为xxx_count，值和xxx_bucket{le=&quot;+Inf}相同。 可使用histogram_quantile()函数来计算Histogram类型样本的分位数。 SummarySummary(摘要)与Histogram类似，表示一段时间内的数据采集结果（通常是请求持续时间或响应大小）。它直接存储了分位数，而不是通过区间来计算。 Summary类型的样本也提供了三种指标： 样本值的分位数分布情况，命名为xxx{quantile=&quot;&lt;φ&gt;&quot;}。 所有样本值的大小总和，命名为xxx_sum。 样本总数，命名为xxx_count。 作业和实例Job and Instance Prometheus配置文件中配置。 Prometheus 入门GETTING STARTED 本节介绍如何安装，配置，使用Prometheus的简单例子。你将在本地安装和运行Prometheus，将其配置为自我填充和示例应用程序，然后使用查询，规则和图表来使用收集的序列数据。 下载 下载地址: https://prometheus.io/download/ 123tar xvfz prometheus-*.tar.gzcd prometheus-* 配置和监控Prometheus通过在目标上通过HTTP endPoints来抓取指标，来收集受监控目标的指标。由于Prometheus也以相同的方式公开自身数据，它也可以获取和监测自身的健康状况。虽然Prometheus Server只收集有关自身的数据在实践中不是很有用，但它是一个很好的示例。如prometheus.yml示例配置文件： 12345678910111213141516171819global: scrape_interval: 15s # By default, scrape targets every 15 seconds. # Attach these labels to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: monitor: 'codelab-monitor'# A scrape configuration containing exactly one endpoint to scrape:# Here it's Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: 'prometheus' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:9090'] 启动启动后，可访问9090端口查看状态。可访问localhost:9090/metrics查看有关自身的相关指标。 12cd prometheus-2.3.2.linux-amd64./prometheus --config.file=&quot;prometheus.yml&quot; 使用表达式浏览器让我们看一下Prometheus收集的一些数据。要使用Prometheus的内建表达式浏览器(expression browser)，请跳转到http://localhost:9090/graph并选择Graph -&gt; Console，在其中输入表达式。绘制表达式图形同样在此操作。 12345678910#表达式prometheus_target_interval_length_seconds#表达式prometheus_target_interval_length_seconds&#123;quantile=&quot;0.99&quot;&#125;#计算返回的时间序列数count(prometheus_target_interval_length_seconds) 启动简单的目标启动一些示例目标让Prometheus获取。确保已安装Go表一起并设置了正常的GO PATH。 123456789101112131415161718mkdir ./sample &amp;&amp; cd samplegit clone https://github.com/prometheus/client_golang.gitcd client_golang/examples/randomgo get -dgo build# Start 3 example targets in separate terminals:./random -listen-address=:9091./random -listen-address=:9092./random -listen-address=:9093#访问http://localhost:9091/metriceshttp://localhost:9092/metriceshttp://localhost:9093/metrices 监控示例目标现在需要配置Prometheus来抓取目标。 1234567891011121314scrape_configs: - job_name: 'example-random' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:8080', 'localhost:8081'] labels: group: 'production' - targets: ['localhost:8082'] labels: group: 'canary' 重启Prometheus，检测rpc_durations_seconds metric来验证。 配置规则Configure rules for aggregating scraped data into new time series 聚合超过数千个时间序列的查询在计算ad-hoc时会变慢。为了提高效率，Prometheus允许你通过配置的规则将预录表达式预先记录到全新的持久时间序列中。 创建规则文件prometheus.rules.yml：123456#job_service:rpc_durations_seconds_count:avg_rate5mgroups:- name: example rules: - record: job_service:rpc_durations_seconds_count:avg_rate5m expr: avg(rate(rpc_durations_seconds_count[5m])) by (job, service) 要是Prometheus选择此新规则，需要修改Prometheus配置： 123456789101112131415161718192021222324252627282930313233global: scrape_interval: 15s # By default, scrape targets every 15 seconds. evaluation_interval: 15s # Evaluate rules every 15 seconds. # Attach these extra labels to all timeseries collected by this Prometheus instance. external_labels: monitor: &apos;codelab-monitor&apos;rule_files: - &apos;prometheus.rules.yml&apos;scrape_configs: - job_name: &apos;prometheus&apos; # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: [&apos;localhost:9090&apos;] - job_name: &apos;example-random&apos; # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: [&apos;localhost:8091&apos;, &apos;localhost:8092&apos;] labels: group: &apos;production&apos; - targets: [&apos;localhost:9093&apos;] labels: group: &apos;canary&apos; 重启Prometheus，使用job_service:rpc_durations_seconds_count:avg_rate5m metric验证。 安装 使用预编译的二进制文件 使用源码 使用Docker所有的Prometheus服务都可以作为 Docker image 来使用。Prometheus image 使用 volume 来存储实际的指标。对于生产部署，强烈建议使用 Data Volume Container 来升级数据的管理。 栗子： 123456#bind-mountdocker run -p 9090:9090 -v /tmp/prometheus.yml:/etc/prometheus.yml prom/prometheus#volumedocker run -p 9090:9090 -v /promethe-data prom/prometheus --config.file=/prometheus-data/prometheus.yml 自定义镜像 Dockerfile: 123FROM prom/prometheusADD prometheus.yml /etc/prometheus/xxx 构建： 1docker build -t my-prometheus . 使用配置管理系统 Ansible Chef Puppet SaltStack 配置Configuration Prometheus通过命令行标志(flag)和配置文件进行配置。使用./prometheus -h查看所有命令行标志。Prometheus可在运行时重新加载配置。 配置文件configuration file: https://prometheus.io/docs/prometheus/latest/configuration/configuration/ 使用--config.file标志指定配置文件。配置文件使用YAML格式。 一个配置文件栗子: 1234567891011121314151617181920212223242526272829303132333435363738global: # How frequently to scrape targets by default. [ scrape_interval: &lt;duration&gt; | default = 1m ] # How long until a scrape request times out. [ scrape_timeout: &lt;duration&gt; | default = 10s ] # How frequently to evaluate rules. [ evaluation_interval: &lt;duration&gt; | default = 1m ] # The labels to add to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: [ &lt;labelname&gt;: &lt;labelvalue&gt; ... ]# Rule files specifies a list of globs. Rules and alerts are read from# all matching files.rule_files: [ - &lt;filepath_glob&gt; ... ]# A list of scrape configurations.scrape_configs: [ - &lt;scrape_config&gt; ... ]# Alerting specifies settings related to the Alertmanager.alerting: alert_relabel_configs: [ - &lt;relabel_config&gt; ... ] alertmanagers: [ - &lt;alertmanager_config&gt; ... ]# Settings related to the remote write feature.remote_write: [ - &lt;remote_write&gt; ... ]# Settings related to the remote read feature.remote_read: [ - &lt;remote_read&gt; ... ] 各个配置项，详细详细请看文档: https://prometheus.io/docs/prometheus/latest/configuration/configuration/ scrape_config tls_config azure_sd_config consul_sd_config dns_sd_config ec2_sd_config openstack_sd_config file_sd_config gce_sd_config kubernetes_sd_config marathon_sd_config nerve_sd_config serverset_sd_config triton_sd_config static_config relabel_config metric_relabel_configs alert_relabel_configs alertmanager_config remote_write remote_read 记录规则Recording rules 配置规则Configuring rules Prometheus支持两种类型的可被配置的以规定的间隔进行评估的规则: recording rules alterting rules 要在Prometheus中包含规则，创建包含必要规则的语句并在Prometheus配置文件中通过rule_files字段配置并加载文件。规则使用YAML格式。 规则文件可在Prometheus运行通过发送SIGHUP到Prometheus来进行重载。只有在所有规则文件都是正确格式下才会应用更改。 语法检查规则Syntax-checking rules 要快速检查规则文件的语法是否正确，而无需启动Prometheus Server，可安装和运行Prometheus的promtool命令行工具: 123go get github.com/prometheus/prometheus/cmd/promtoolpromtool check rules /path/to/example.rules.yml 如果规则文件语法正确，会返回0状态码。如果语法错误，会返回错误信息和1状态码。 记录规则Recording rules 记录规则允许你预先计算经常需要或计算昂贵的表达式并保存它们的结果到一个新的时序集(set of time series)。查询预先计算的结果会比每次执行原始表达式快得多。这对Dashboard来说尤其有用，它经常刷新时间反复查询同样的表达式。 记录和告警规则位于一个规则组(rule group)。一个组内的规则在一个规定的间隔内依序运行。 规则文件语法: 12groups: [ - &lt;rule_group&gt; ] 栗子: 12345groups: - name: example relues: - record: job:http_inprogress_requests:sum expr: sum(http_inprogress_requests) by (job) 12345678# The name of the group. Must be unique within a file.name: &lt;string&gt;# How often rules in the group are evaluated.[ interval: &lt;duration&gt; | default = global.evaluation_interval ]rules: [ - &lt;rule&gt; ... ] 记录规则的语法: 1234567891011# The name of the time series to output to. Must be a valid metric name.record: &lt;string&gt;# The PromQL expression to evaluate. Every evaluation cycle this is# evaluated at the current time, and the result recorded as a new set of# time series with the metric name as given by 'record'.expr: &lt;string&gt;# Labels to add or overwrite before storing the result.labels: [ &lt;labelname&gt;: &lt;labelvalue&gt;] 告警规则的语法: 12345678910111213141516171819# The name of the alert. Must be a valid metric name.alert: &lt;string&gt;# The PromQL expression to evaluate. Every evaluation cycle this is# evaluated at the current time, and all resultant time series become# pending/firing alerts.expr: &lt;string&gt;# Alerts are considered firing once they have been returned for this long.# Alerts which have not yet fired for long enough are considered pending.[ for: &lt;duration&gt; | default = 0s ]# Labels to add or overwrite for each alert.labels: [ &lt;labelname&gt;: &lt;tmp_string&gt;]# Annotations to add to each alert.annotations: [ &lt;labelname&gt;: &lt;tmpl_string&gt; ] 告警规则Alerting rules 告警规则允许你根据Prometheus表达式语言来定义告警条件，并发送提醒到外部服务。每当告警表达式在给定的时间内导致一个或多个矢量元素，告警计数主动作为这些元素的标签集。 定义告警规则在Prometheus中，告警规则的配置与记录规则的配置一样。 栗子: 12345678910groups:- name: example rules: - alerts: HighRequestLatency expr: job:request_latency_seconds:mean5m&#123;job="myjob"&#125; &gt; 0.5 for: 10m labels: severity: page annotations: summary: High request latency 可选的for子句导致Prometheus等待在第一次遇到一个新的表达式输出矢量元素和计数的告警作为点燃的此元素的一定持续时间。在这个栗子中，Prometheus将检查在点燃告警之前的每个10分钟的警告持续激活。元素是活跃的，但未点燃，出于待定(pending)状态。 labels子句允许指定一组附加标签到告警。任何目前有冲突的标签将被覆盖。标签的值可以作为模板。 annotations子句指定的一组信息可用来存储更长的附加信息。注释的值可以作为模板。 模板Templating 标签和注释的值可以使用console template作为模板。$labels变量保存一个告警实例的k/v键值对。已配置的外部标签可通过$externalLabels变量进行访问。$value变量保存告警实例的评估值。 12345# To insert a firing element's label values:&#123;&#123; $labels.&lt;labelname&gt; &#125;&#125;# To insert the numeric expression value of the firing element:&#123;&#123; $value &#125;&#125; 栗子: 123456789101112131415161718192021groups:- name: example rules: # Alert for any instance that is unreachable for &gt;5 minutes. - alert: InstanceDown expr: up == 0 for: 5m labels: severity: page annotations: summary: "Instance &#123;&#123; $labels.instance &#125;&#125; down" description: "&#123;&#123; $labels.instance &#125;&#125; of job &#123;&#123; $labels.job &#125;&#125; has been down for more than 5 minutes." # Alert for any instance that has a median request latency &gt;1s. - alert: APIHighRequestLatency expr: api_http_request_latencies_second&#123;quantile="0.5"&#125; &gt; 1 for: 10m annotations: summary: "High request latency on &#123;&#123; $labels.instance &#125;&#125;" description: "&#123;&#123; $labels.instance &#125;&#125; has a median request latency above 1s (current value: &#123;&#123; $value &#125;&#125;)s" 运行时检查告警Inspecting alerts during runtime 要手动检查告警是否活跃(active)(pending或firing)，请浏览原生Prometheus的Alerts栏目项。这里将确切地显示标签集，每个定义的告警当前的状态。 对于pengding和firing的告警，Prometheus还存储合成ALERTS{alertname=&quot;&lt;alert name&gt;&quot;, alertstate=&quot;pending|firing&quot;, &lt;additional alert labels&gt;}形式的时间序列。只要该警告是在所指示的active(pending或firing)状态，样本值被设置为1。当不再是这样时，该系列被标记为stale。 发送告警通知Sending alert notifications Prometheus的告警规则善于盘算现在什么坏了(broken)，但是它不是一个成熟的通知解决方案。需要另一层添加汇总，通知速率限制，沉默和告警依赖于简单告警定义。在Prometheus的生态系统中，Alertmanager承担了这一角色。因此，Prometheus可以配置成定期发送关于告警状态信息到Alertmanager实例，然后采取调度权发送通知。Prometheus通过集成服务发现，可配置为自动发现可用的Alertmanager实例。 模板Template example Prometheus在alerts的annotations和labels中支持模板化，以及在控制台页面。模板要针对本地数据库运行查询、迭代数据，使用条件、格式数据等能力。Prometheus模板语言是基于Go template system。 简单告警字段模板12345678alert: InstanceDownexpr: up == 0for: 5mlabels: severity: pageannotations: summary: "Instance &#123;&#123;$labels.instance&#125;&#125; down" description: "&#123;&#123;$labels.instance&#125;&#125; of job &#123;&#123;$labels.job&#125;&#125; has been down for more than 5 minutes." 告警字段模板为每个点燃的告警在每一个规则迭代过程中执行，所以保持任意查询和模板的轻量化。如果你需要为告警编写更复杂的模板，建议链接到控制台。 简单迭代simple iteration 这显示的实例列表，以及它们是否up: 123&#123;&#123; range query "up" &#125;&#125; &#123;&#123; .Labels.instance &#125;&#125; &#123;&#123; .Value &#125;&#125;&#123;&#123; end &#125;&#125; 特殊的.变量包含对于每次循环迭代当前样本的值。 展示一个值123&#123;&#123; with query "some_metric&#123;instance='someinstance'&#125;" &#125;&#125; &#123;&#123; . | first | value | humanize &#125;&#123;&#123; end &#125;&#125; Go和Go的模板语言两者都是强类型，因此必须检查阳平返回，以避免执行错误。这里所包含的prom_query_drilldown模板处理，允许结果的格式，并链接到表达式浏览器。 使用控制台url参数Using console URL parameters 123&#123;&#123; with printf "node_memory_MemTotal&#123;job='node', instance='%s'&#125;" .Params.instance | query&#125;&#125; &#123;&#123; . | first | value | humanize1024 &#125;&#125;B&#123;&#123; end &#125;&#125; 如果作为console.html?instance=hostname访问, .Params.instance将评估hostname。 高级的迭代Advanced iteration 123456789101112&lt;table&gt;&#123;&#123; range printf "node_network_receive_bytes&#123;job='node',instance='%s',device!='lo'&#125;" .Params.instance | query | sortByLabel "device"&#125;&#125;&lt;tr&gt;&lt;th colspan=2&gt;&#123;&#123; .Labels.device &#125;&#125;&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;Received&lt;/td&gt; &lt;td&gt;&#123;&#123; with printf "rate(node_network_receive_bytes&#123;job='node',instance='%s',device='%s'&#125;[5m])" .Labels.instance .Labels.device | query &#125;&#125;&#123;&#123; . | first | value | humanize &#125;&#125;B/s&#123;&#123;end&#125;&#125;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;Transmitted&lt;/td&gt; &lt;td&gt;&#123;&#123; with printf "rate(node_network_transmit_bytes&#123;job='node',instance='%s',device='%s'&#125;[5m])" .Labels.instance .Labels.device | query &#125;&#125;&#123;&#123; . | first | value | humanize &#125;&#125;B/s&#123;&#123;end&#125;&#125;&lt;/td&gt; &lt;/tr&gt;&#123;&#123; end &#125;&#125;&lt;/table&gt; 这里，我们迭代了所有网络设备，并显示每个设备的网络流量。随着range动作不指定变量，.Params.instance循环内不可用，.现在是作为循环变量。 定义可重复使用的模板Defining reusable templates Prometheus支持定义可重复使用的模板。当与控制台库相结合时，使得可共享模板，这很有用。 1234567&#123;&#123; /* Define the template */ &#125;&#125;&#123;&#123;define "myTemplate"&#125;&#125; do something&#123;&#123; end &#125;&#125;&#123;&#123;/* Use the template */&#125;&#125;&#123;&#123;template "myTemplate"&#125;&#125; 模板仅限于一个参数。args函数可包装多个参数。 12345&#123;&#123;define "myMultiArgTemplate"&#125;&#125; First argument: &#123;&#123;.arg0&#125;&#125; Second argument: &#123;&#123;.arg1&#125;&#125;&#123;&#123; end &#125;&#125;&#123;&#123; template "myMultiArgTemplate" (args 1 2)&#125;&#125; 模板引用TEMPLATE REFERENCE 数据结构Data Structures 用于处理时间序列数据的主要数据结构栗子: 1234type sample struct &#123; Labels map[string]string Value float64&#125; 栗子的指标名称(metric)编码在Labelsmap的特殊的__name__标签里。[]sample表示实例列表。Go中的interface{}与C中的void pointer类似。 函数除了Go模板提供的默认函数，Prometheus为模板查询结果提供了更易处理的函数。如果函数在管道中使用，管道值将作为最后一个参数传递。 Queries Numbers Strings Others 模板类型差异Template type differences 每种类型的模板提供了可用于参数模板的不同信息，并有一些其它差异。 规则单元测试Unit Testing for Rules 你可使用promtool来测试你的规则。 查询Querying 查询PrometheusPrometheus提供了一个名为PromQL(Prometheus Query Language)功能化查询语言，让用户选择并实时汇总时间序列数据。表达式的结果可被显示为图形，可在Prometheus浏览器上查看，或通过HTTP API来获取。 表达式语言数据类型Expression language data types 在Prometheus表达式语言中，一个表达式或子表达式可以评估为四种类型中的一种: 瞬时向量(Instant vector): 包含每个时间序列的单个样品的一组时间序列，全部共享相同的时间戳 区间向量(Range vector): 包含随时间序列的范围的数据点的一组时间序列 标量(Scalar): 一个简单的数字浮点值 字符串(String): 一个简单的字符串值，当前未使用 根据不同的使用情况(graphing, displaying the output of an expression)，例如：瞬时向量表达式返回的数据类型是唯一可以直接绘制成图表的数据类型。 LiteralsString literals 字符串可以被指定为在单引号、双引号或反引号内的文字。 PromQL遵循Go的转义规则。不像Go，Prometheus不丢弃反引号里面的换行符。 123&quot;this is a string&quot;&apos;these are unescaped: \n \\ \t&apos;`these are not unescaped: \n &apos; &quot; \t`&quot;&apos;` Float literals 标量浮点值可被逐字地写为[-](digits)[.(digits)]数字形式。 1-2.43 时序选择器Time series Selectors Prometheus中的所有正则表达式使用RE2 syntax。 Instant vector selectors Instant vector selectors允许一组时间序列并为每个在给定的时间戳单一样品值的选择: 在最简单的格式中，只制定了一个指标名称。这导致了包含有该指标名称的所有时间序列的元素instant vector。 这个栗子将选择具有http_requests_total指标名称的所有时间序列: 1http_requests_total 有可能通过附加一组标签在大括号来匹配进一步过滤这些时间序列。 这个栗子只选择job label为prometheus和group lable为canary的http_requests_total指标名称。 1http_requests_total&#123;job=&quot;prometheus&quot;, group=&quot;canary&quot;&#125; 也可将标签值负匹配，或匹配正则表达式。下面的标签匹配操作符存在: =: 等于; != 不等于; =~: 正则匹配; !~: 非正则匹配. 举个栗子，以下匹配staging, testing, development环境变量和GET以外的HTTP方法的http_requests_total指标名称的所有时序。 1http_requests_total&#123;environment=~&quot;staging|testing|development&quot;, method!=&quot;GET&quot;&#125; 栗子: 123456&#123;job=~&quot;.*&quot;&#125; # Bad!&#123;job=~&quot;.+&quot;&#125; # Good!&#123;job=~&quot;.*&quot;,method=&quot;get&quot;&#125; # Good!&#123;__name__=~&quot;job:.*&quot;&#125; Range Vector Selectors Range vector literals与 instant vector literals类似，不同之处在于它选择了一个范围。时间序列放在方括号[]内。 时间范围被指定为一个数字，使用以下单位: s: 秒; m: 分; h: 时; d: 天; w: 周; y: 年。 栗子: 1http_requests_total&#123;job=&quot;prometheus&quot;&#125;[5m] Offset modifier offset修饰符允许为查询中的individual instant和range vectors改变时间偏移。 栗子: 1234567http_requests_total offset 5msum(http_requests_total&#123;method=&quot;GET&quot;&#125; offset 5m) // GOOD.sum(http_requests_total&#123;method=&quot;GET&quot;&#125;) offset 5m // INVALID.rate(http_requests_total[5m] offset 1w) 子查询Subquery 子查询允许你为一个给定的range和resolution运行一个即时查询(instant)。子查询的结果为range vector。 语法: 12# resolution可选。Default is the global evaluation interval.Syntax: &lt;instant_query&gt; &apos;[&apos; &lt;range&gt; &apos;:&apos; [&lt;resolution&gt;] &apos;]&apos; [ offset &lt;duration&gt; ] 操作符Operators: https://prometheus.io/docs/prometheus/latest/querying/operators/ 二元运算符Binary Operators Prometheus查询语言支持基本的逻辑和算数运算符。 Arithmetic binary operators Prometheus中存在以下二元算术运算符: + (addition) - (subtraction) * (multiplication) / (division) % (modulo) ^ (power/exponentiation) 二元运算符在下列之间定义: scalar/scalar vector/scalar vector/vector Comparison binary operators Prometheus中有以下二元比较符: == (equal) != (not-equal) &gt; (greater-than) &lt; (less-than) &gt;= (greater-or-equal) &lt;= (less-or-equal) 比较运算符在下列之间定义，默认情况下进行筛选。它们的行为可由运算符之后提供的bool进行修改，这将返回0或1而不是过滤。 scalar/scalar vector/scalar vector/vector Logical/set binary operators logical/set 二元运算符尽在instan vectors之间定义: and (intersection) or (union) unless (complement) 矢量匹配Vector matching 矢量之间的操作试图找到为左手侧的每个条目匹配右手侧的元素。有两种基本类型匹配的行为: One-to-one 和 many-to-one/one-to-many。 One-to-one vector matches 一对一从操作的每一侧查找唯一的一对条目。在默认情况下，操作遵循如下格式vector1 &lt;operator&gt; vector2。如果它们有完全相同的一组标签和相应的值，则两个条目匹配。ignoring关键字允许匹配忽略某些标签，on关键字允许降低考虑的标签集来提供列表: 12&lt;vector expr&gt; &lt;bin-op&gt; ignoring(&lt;label list&gt;) &lt;vector expr&gt;&lt;vector expr&gt; &lt;bin-op&gt; on(&lt;label list&gt;) &lt;vector expr&gt; 输入案例: 123456789method_code:http_errors:rate5m&#123;method=&quot;get&quot;, code=&quot;500&quot;&#125; 24method_code:http_errors:rate5m&#123;method=&quot;get&quot;, code=&quot;404&quot;&#125; 30method_code:http_errors:rate5m&#123;method=&quot;put&quot;, code=&quot;501&quot;&#125; 3method_code:http_errors:rate5m&#123;method=&quot;post&quot;, code=&quot;500&quot;&#125; 6method_code:http_errors:rate5m&#123;method=&quot;post&quot;, code=&quot;404&quot;&#125; 21method:http_requests:rate5m&#123;method=&quot;get&quot;&#125; 600method:http_requests:rate5m&#123;method=&quot;del&quot;&#125; 34method:http_requests:rate5m&#123;method=&quot;post&quot;&#125; 120 查询栗子: 1method_code:http_errors:rate5m&#123;code=&quot;500&quot;&#125; / ignoring(code) method:http_requests:rate5m Many-to-one and one-to-many vector matches 多对一或一对多匹配指的是一侧能够匹配多侧的多个元素。这明确要求必须使用group_left或group_right修饰符，其中左/右确定该矢量有更高的基数。 1234&lt;vector expr&gt; &lt;bin-op&gt; ignoring(&lt;label list&gt;) group_left(&lt;label list&gt;) &lt;vector expr&gt;&lt;vector expr&gt; &lt;bin-op&gt; ignoring(&lt;label list&gt;) group_right(&lt;label list&gt;) &lt;vector expr&gt;&lt;vector expr&gt; &lt;bin-op&gt; on(&lt;label list&gt;) group_left(&lt;label list&gt;) &lt;vector expr&gt;&lt;vector expr&gt; &lt;bin-op&gt; on(&lt;label list&gt;) group_right(&lt;label list&gt;) &lt;vector expr&gt; 查询案例: 1method_code:http_errors:rate5m / ignoring(code) group_left method:http_request:rate5m 1234&#123;method=&quot;get&quot;, code=&quot;500&quot;&#125; 0.04 // 24 / 600&#123;method=&quot;get&quot;, code=&quot;404&quot;&#125; 0.05 // 30 / 600&#123;method=&quot;post&quot;, code=&quot;500&quot;&#125; 0.05 // 6 / 120&#123;method=&quot;post&quot;, code=&quot;404&quot;&#125; 0.175 // 21 / 120 聚合运算符Aggregation operators Prometheus支持以下内置聚合运算符，可以用于聚合单一瞬间向量的元素: sum (calculate sum over dimensions) min (select minimum over dimensions) max (select maximum over dimensions) avg (calculate the average over dimensions) stddev (calculate population standard deviation over dimensions) stdvar (calculate population standard variance over dimensions) count (count number of elements in the vector) count_values (count number of elements with the same value) bottomk (smallest k elements by sample value) topk (largest k elements by sample value) quantile (calculate φ-quantile (0 ≤ φ ≤ 1) over dimensions) 栗子: 1234567891011&lt;aggr-op&gt; [without|by (&lt;label list&gt;)] ([parameter,] &lt;vector expression&gt;)&lt;aggr-op&gt;([parameter,] &lt;vector expression&gt;) [without|by (&lt;label list&gt;)]sum without (instance) (http_requests_total)sum by (application, group) (http_requests_total)count_values(&quot;version&quot;, build_version)topk(5, http_requests_total) 二元运算符优先级Binary operator precedence 以下优先级由高到低: ^ *, /, % +, - ==, !=, &lt;=, &lt;, &gt;=, &gt; and, unless or 函数Founctions: https://prometheus.io/docs/prometheus/latest/querying/functions/ 一些函数有默认的参数，如year(v=vector(time()) instant-vector)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208abs()abs(v instant-vector) 返回输入向量的所有样本的绝对值absent()absent(v instant-vector)，判断是否存在absent(nonexistent&#123;job=&quot;myjob&quot;&#125;)# =&gt; &#123;job=&quot;myjob&quot;&#125;absent(nonexistent&#123;job=&quot;myjob&quot;,instance=~&quot;.*&quot;&#125;)# =&gt; &#123;job=&quot;myjob&quot;&#125;absent(sum(nonexistent&#123;job=&quot;myjob&quot;&#125;))# =&gt; &#123;&#125;ceil()ceil(v instant-vector) 将v中所有元素的样本值向上四舍五入到最接近的整数floor()floor(v instant-vector) 与ceil()相反，将v中所有元素的样本值向下四舍五入到最接近的整数changes()changes(v range-vector) 输入一个区间向量，返回这个区间向量内每个样本数据值变化的次数（瞬时向量）。如果样本数据值没有发生变化，则返回结果为1clamp_max()clamp_max(v instant-vector, max scalar) 输入一个瞬时向量和最大值，样本数据值若大于max，则改为max，否则不变clamp_min()clamp_min(v instant-vector, min scalar) 输入一个瞬时向量和最小值，样本数据值若小于min，则改为min，否则不变day_of_month()day_of_month(v=vector(time()) instant-vector) 值范围为1-31day_of_week()day_of_week(v=vector(time()) instant-vector) 值范围为0-6days_in_month()days_in_month(v=vector(time()) instant-vector) 月份的天数，值范围为28-31minute()minute(v=vector(time()) instant-vector) 函数返回给定UTC时间当前小时的第多少分钟，范围为0-59month()month(v=vector(time()) instant-vector) 函数返回给定UTC时间当前属于第几个月，范围为1-12year()year(v=vector(time()) instant-vector) 返回被给定 UTC 时间的当前年份hour()hour(v=vector(time()) instant-vector) 值范围为0-23delta()delta(v range-vector) 它计算一个区间向量v的第一个元素和最后一个元素之间的差值，返回一个瞬时向量delta(cpu_temp_celsius&#123;host=&quot;zeus&quot;&#125;[2h]) # 现在和两小时前的CPU温度差idelta()idelta(v range-vector) 计算最后两个样本之间的差deriv()deriv(v range-vector) 使用简单的线性回归计算区间向量v中各个时间序列的导数exp()exp(v instant-vector) 输入一个瞬时向量，返回各个样本值的e的指数值histogram_quantile()histogram_quantile(φ float, b instant-vector)histogram_quantile(0.9, rate(http_request_duration_seconds_bucket[10m])) # 计算过去10分钟内请求持续在90%histogram_quantile(0.9, sum(rate(http_request_duration_seconds_bucket[10m])) by (job, le)) # 聚合holt_winters()holt_winters(v range-vector, sf scalar, tf scalar) 基于区间向量v，生成时间序列数据平滑值increase()increase(v range-vector) 获取区间向量中的第一个和最后一个样本并返回其增长量increase(http_requests_total&#123;job=&quot;api-server&quot;&#125;[5m]) # 区间向量中每个时间序列过去5分钟内HTTP请求数的增长数label_join()label_replace()ln()ln(v instant-vector) 计算瞬时向量v中所有样本数据的自然对数log2()log2(v instant-vector) 函数计算瞬时向量v中所有样本数据的二进制对数log10()log10(v instant-vector) 计算瞬时向量v中所有样本数据的十进制对数predict_linear()predict_linear(v range-vector, t scalar) 函数可以预测时间序列v在t秒后的值predict_linear(node_filesystem_free&#123;job=&quot;node&quot;&#125;[2h], 4 * 3600) &lt; 0 # 基于2小时的样本数据，来预测主机可用磁盘空间的是否在4个小时候被占满rate()rate(v range-vector) 直接计算区间向量 v 在时间窗口内平均增长速率rate(http_requests_total[5m]) 区间向量中每个时间序列过去5分钟内HTTP请求数的每秒增长率irate()irate(v range-vector) 用于计算区间向量的增长率，但是其反应出的是瞬时增长率。通过区间向量中最后两个两本数据来计算区间向量的增长速率。irate(http_requests_total&#123;job=&quot;api-server&quot;&#125;[5m]) # 区间向量中每个时间序列过去 5 分钟内最后两个样本数据的 HTTP 请求数的增长率resets()resets(v range-vector) 的参数是一个区间向量。对于每个时间序列，它都返回一个计数器重置的次数。两个连续样本之间的值的减少被认为是一次计数器重置。round()round(v instant-vector, to_nearest=1 scalar) 与ceil和floor函数类似，返回向量中所有样本值的最接近的整数scalar()scalar(v instant-vector) 函数的参数是一个单元素的瞬时向量,它返回其唯一的时间序列的值作为一个标量sort()sort(v instant-vector) 函数对向量按元素的值进行升序排序sort_desc()降序排列sqrt()sqrt(v instant-vector) 计算向量v 所有元素的平方根vector()vector(s scalar)&lt;aggregation&gt;_over_time()avg_over_time(range-vector) : 区间向量内每个度量指标的平均值。min_over_time(range-vector) : 区间向量内每个度量指标的最小值。max_over_time(range-vector) : 区间向量内每个度量指标的最大值。sum_over_time(range-vector) : 区间向量内每个度量指标的求和。count_over_time(range-vector) : 区间向量内每个度量指标的样本数据个数。quantile_over_time(scalar, range-vector) : 区间向量内每个度量指标的样本数据值分位数，φ-quantile (0 ≤ φ ≤ 1)。stddev_over_time(range-vector) : 区间向量内每个度量指标的总体标准差。stdvar_over_time(range-vector) : 区间向量内每个度量指标的总体标准方差。 查询栗子Query examples: https://prometheus.io/docs/prometheus/latest/querying/examples/ 简单时序选择返回指标http_requests_total的所有时间序列数据: 1http_requests_total 返回指标名为http_requests_total，给定标签job和handler: 1http_requests_total&#123;job=&quot;apiserver&quot;, handler=&quot;/api/comments&quot;&#125; 加上时间，5分钟内: 1http_requests_total&#123;job=&quot;apiserver&quot;, handler=&quot;/api/comments&quot;&#125;[5m] 使用正则: 1http_requests_total&#123;job=~&quot;.*server&quot;&#125; http状态码不为4xx: 1http_requests_total&#123;status!~&quot;4..&quot;&#125; 子查询Return the 5-minute rate of the http_requests_total metric for the past 30 minutes, with a resolution of 1 minute. 1rate(http_requests_total[5m])[30m:1m] 嵌套子查询: 1max_over_time(deriv(rate(distance_covered_total[5s])[30s:5s])[10m:]) 使用函数，运算符过去5分钟的平均值 1rate(http_requests_total[5m]) 过去5分钟平均值综合 123sum by (job) ( rate(http_requests_total[5m])) 如果两个指标具有相同维度的标签，我们可以使用二元操作符计算样本数据: 1234567(instance_memory_limit_bytes - instance_memory_usage_bytes) / 1024 / 1024# 同样的表达式，只不过通过应用相加sum by (app, proc) ( instance_memory_limit_bytes - instance_memory_usage_bytes) / 1024 / 1024 获取CPU使用最高的三个样本: 1topk(3, sum by (app, proc) (rate(instance_cpu_time_ns[5m]))) 假设一个服务实例只有一个时间序列数据，那么我们可以通过下面表达式统计出每个应用的实例数量: 1count(instance_cpu_time_ns) by (app) HTTP APIHTTP API: https://prometheus.io/docs/prometheus/latest/querying/api/ 目前稳定的HTTP API在Prometheus Server的/api/v1下。 格式API响应格式为JSON。每个成功的请求都返回2xx状态码。 到达API处理程序无效的请求返回一个错误的JSON对象和以下状态码之一: 400 Bad Request: 当参数错误或者缺失 422 Unprocessable Entity: 当表达式无法执行 503 Service Unavailable: 当请求超时或者被中断时 JSON响应包格式如下: 12345678910111213&#123; "status": "success" | "error", "data": &lt;data&gt;, // Only set if status is "error". The data field may still hold // additional data. "errorType": "&lt;string&gt;", "error": "&lt;string&gt;", // Only if there were warnings while executing the request. // There will still be data in the data field. "warnings": ["&lt;string&gt;"]&#125; 请求中输入的时间为RFC3339或Unix原子时间，输出时间戳总是Unix原子时间。 查询参数的名称可用中括号[]重复次数。 &lt;duration&gt;占位符指的是[0-9]+[smhdwy]形式的Prometheus 持续时间字符串。例如，5m表示5分钟的持续时间。 表达式查询查询语言表达式可在单个时刻或一定范围内进行评估。以下部分用于描述每个类型的表达式查询的API endpoint。 瞬时查询(Instant query) 端点: 12GET /api/v1/queryPOST /api/v1/query URL查询参数: 12345678# 表达式query=&lt;string&gt;# 时间戳，可选。默认使用当前系统时间time=&lt;rfc3339 | unix_timestamp&gt;# 超时，可选。默认使用全局的-query.timeout参数timeout=&lt;duration&gt; 查询结果的data部分格式如下: 1234&#123; &quot;resultType&quot;: &quot;matrix&quot; | &quot;vector&quot; | &quot;scalar&quot; | &quot;string&quot;, &quot;result&quot;: &lt;value&gt;&#125; 栗子: 12345678910111213141516171819202122232425$ curl &apos;http://localhost:9090/api/v1/query?query=up&amp;time=2015-07-01T20:10:51.781Z&apos;&#123; &quot;status&quot; : &quot;success&quot;, &quot;data&quot; : &#123; &quot;resultType&quot; : &quot;vector&quot;, &quot;result&quot; : [ &#123; &quot;metric&quot; : &#123; &quot;__name__&quot; : &quot;up&quot;, &quot;job&quot; : &quot;prometheus&quot;, &quot;instance&quot; : &quot;localhost:9090&quot; &#125;, &quot;value&quot;: [ 1435781451.781, &quot;1&quot; ] &#125;, &#123; &quot;metric&quot; : &#123; &quot;__name__&quot; : &quot;up&quot;, &quot;job&quot; : &quot;node&quot;, &quot;instance&quot; : &quot;localhost:9100&quot; &#125;, &quot;value&quot; : [ 1435781451.781, &quot;0&quot; ] &#125; ] &#125;&#125; 区间查询(range query) 端点: 12GET /api/v1/query_rangePOST /api/v1/query_range URL查询参数: 123456789101112# 表达式query=&lt;string&gt;# 时间戳start=&lt;rfc3339 | unix_timestamp&gt;end=&lt;rfc3339 | unix_timestamp&gt;# 查询时间步长，时间区间内每step秒执行一次step=&lt;duration | float&gt;# 超时，可选timeout=&lt;duration&gt; 查询结果的data部分格式如下: 1234&#123; &quot;resultType&quot;: &quot;matrix&quot;, &quot;result&quot;: &lt;value&gt;&#125; 栗子: 123456789101112131415161718192021222324252627282930313233$ curl &apos;http://localhost:9090/api/v1/query_range?query=up&amp;start=2015-07-01T20:10:30.781Z&amp;end=2015-07-01T20:11:00.781Z&amp;step=15s&apos;&#123; &quot;status&quot; : &quot;success&quot;, &quot;data&quot; : &#123; &quot;resultType&quot; : &quot;matrix&quot;, &quot;result&quot; : [ &#123; &quot;metric&quot; : &#123; &quot;__name__&quot; : &quot;up&quot;, &quot;job&quot; : &quot;prometheus&quot;, &quot;instance&quot; : &quot;localhost:9090&quot; &#125;, &quot;values&quot; : [ [ 1435781430.781, &quot;1&quot; ], [ 1435781445.781, &quot;1&quot; ], [ 1435781460.781, &quot;1&quot; ] ] &#125;, &#123; &quot;metric&quot; : &#123; &quot;__name__&quot; : &quot;up&quot;, &quot;job&quot; : &quot;node&quot;, &quot;instance&quot; : &quot;localhost:9091&quot; &#125;, &quot;values&quot; : [ [ 1435781430.781, &quot;0&quot; ], [ 1435781445.781, &quot;0&quot; ], [ 1435781460.781, &quot;1&quot; ] ] &#125; ] &#125;&#125; 查询元数据通过标签匹配器查找序列(Finding series by label matchers) 端点: 12GET /api/v1/seriesPOST /api/v1/series URL请求参数: 123456# 标签选择器是 series_selector。必须至少提供一个match[]参数match[]=&lt;series_selector&gt;# 时间戳start=&lt;rfc3339 | unix_timestamp&gt;end=&lt;rfc3339 | unix_timestamp&gt; 返回结果的data部分，由k/v键值对的对象列表组成。栗子: 123456789101112131415161718192021$ curl -g &apos;http://localhost:9090/api/v1/series?&apos; --data-urlencode=&apos;match[]=up&apos; --data-urlencode=&apos;match[]=process_start_time_seconds&#123;job=&quot;prometheus&quot;&#125;&apos;&#123; &quot;status&quot; : &quot;success&quot;, &quot;data&quot; : [ &#123; &quot;__name__&quot; : &quot;up&quot;, &quot;job&quot; : &quot;prometheus&quot;, &quot;instance&quot; : &quot;localhost:9090&quot; &#125;, &#123; &quot;__name__&quot; : &quot;up&quot;, &quot;job&quot; : &quot;node&quot;, &quot;instance&quot; : &quot;localhost:9091&quot; &#125;, &#123; &quot;__name__&quot; : &quot;process_start_time_seconds&quot;, &quot;job&quot; : &quot;prometheus&quot;, &quot;instance&quot; : &quot;localhost:9090&quot; &#125; ]&#125; 获取标签名(label) 端点: 12GET /api/v1/labelsPOST /api/v1/labels 返回结果的data部分是一个标签名字符串列表。栗子: 123456789101112131415161718192021222324252627$ curl &apos;localhost:9090/api/v1/labels&apos;&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: [ &quot;__name__&quot;, &quot;call&quot;, &quot;code&quot;, &quot;config&quot;, &quot;dialer_name&quot;, &quot;endpoint&quot;, &quot;event&quot;, &quot;goversion&quot;, &quot;handler&quot;, &quot;instance&quot;, &quot;interval&quot;, &quot;job&quot;, &quot;le&quot;, &quot;listener_name&quot;, &quot;name&quot;, &quot;quantile&quot;, &quot;reason&quot;, &quot;role&quot;, &quot;scrape_job&quot;, &quot;slice&quot;, &quot;version&quot; ]&#125; 查询标签值 请求如下端点: 1GET /api/v1/label/&lt;label_name&gt;/values JSON响应的data部分是标签值字符串列表。栗子: 12345678$ curl http://localhost:9090/api/v1/label/job/values&#123; &quot;status&quot; : &quot;success&quot;, &quot;data&quot; : [ &quot;node&quot;, &quot;prometheus&quot; ]&#125; 表达式查询结果的格式Expression query result formats 表达式查询结果可能会在data部分的result字段中返回以下响应值。 区间向量(range vectors) 区间向量返回matrix resultType。result的响应格式如下: 1234567[ &#123; &quot;metric&quot;: &#123; &quot;&lt;label_name&gt;&quot;: &quot;&lt;label_value&gt;&quot;, ... &#125;, &quot;values&quot;: [ [ &lt;unix_time&gt;, &quot;&lt;sample_value&gt;&quot; ], ... ] &#125;, ...] 瞬时向量(instant vectors) 瞬时向量返回vector resultType。result的响应格式如下: 1234567[ &#123; &quot;metric&quot;: &#123; &quot;&lt;label_name&gt;&quot;: &quot;&lt;label_value&gt;&quot;, ... &#125;, &quot;value&quot;: [ &lt;unix_time&gt;, &quot;&lt;sample_value&gt;&quot; ] &#125;, ...] 标量(Scalars) 标量返回scalar resultType。result的响应格式如下: 1[ &lt;unix_time&gt;, &quot;&lt;scalar_value&gt;&quot; ] 字符串(string) 字符串返回string resultType。result的响应格式如下: 1[ &lt;unix_time&gt;, &quot;&lt;string_value&gt;&quot; ] 目标Targets 以下端点返回Prometheus目标发现的当前状态的概述: 1GET /api/v1/targets 栗子: 12345678910111213141516171819202122232425262728293031323334curl http://localhost:9090/api/v1/targets&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: &#123; &quot;activeTargets&quot;: [ &#123; &quot;discoveredLabels&quot;: &#123; &quot;__address__&quot;: &quot;127.0.0.1:9090&quot;, &quot;__metrics_path__&quot;: &quot;/metrics&quot;, &quot;__scheme__&quot;: &quot;http&quot;, &quot;job&quot;: &quot;prometheus&quot; &#125;, &quot;labels&quot;: &#123; &quot;instance&quot;: &quot;127.0.0.1:9090&quot;, &quot;job&quot;: &quot;prometheus&quot; &#125;, &quot;scrapeUrl&quot;: &quot;http://127.0.0.1:9090/metrics&quot;, &quot;lastError&quot;: &quot;&quot;, &quot;lastScrape&quot;: &quot;2017-01-17T15:07:44.723715405+01:00&quot;, &quot;health&quot;: &quot;up&quot; &#125; ], &quot;droppedTargets&quot;: [ &#123; &quot;discoveredLabels&quot;: &#123; &quot;__address__&quot;: &quot;127.0.0.1:9100&quot;, &quot;__metrics_path__&quot;: &quot;/metrics&quot;, &quot;__scheme__&quot;: &quot;http&quot;, &quot;job&quot;: &quot;node&quot; &#125;, &#125; ] &#125;&#125; 规则Rules 此api端点返回当前载入的告警和记录规则的列表。此外，它还会返回由每个告警规则的Prometheus实例点燃的当前激活的告警。 1GET /api/v1/rules 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849curl http://localhost:9090/api/v1/rules&#123; &quot;data&quot;: &#123; &quot;groups&quot;: [ &#123; &quot;rules&quot;: [ &#123; &quot;alerts&quot;: [ &#123; &quot;activeAt&quot;: &quot;2018-07-04T20:27:12.60602144+02:00&quot;, &quot;annotations&quot;: &#123; &quot;summary&quot;: &quot;High request latency&quot; &#125;, &quot;labels&quot;: &#123; &quot;alertname&quot;: &quot;HighRequestLatency&quot;, &quot;severity&quot;: &quot;page&quot; &#125;, &quot;state&quot;: &quot;firing&quot;, &quot;value&quot;: &quot;1e+00&quot; &#125; ], &quot;annotations&quot;: &#123; &quot;summary&quot;: &quot;High request latency&quot; &#125;, &quot;duration&quot;: 600, &quot;health&quot;: &quot;ok&quot;, &quot;labels&quot;: &#123; &quot;severity&quot;: &quot;page&quot; &#125;, &quot;name&quot;: &quot;HighRequestLatency&quot;, &quot;query&quot;: &quot;job:request_latency_seconds:mean5m&#123;job=\&quot;myjob\&quot;&#125; &gt; 0.5&quot;, &quot;type&quot;: &quot;alerting&quot; &#125;, &#123; &quot;health&quot;: &quot;ok&quot;, &quot;name&quot;: &quot;job:http_inprogress_requests:sum&quot;, &quot;query&quot;: &quot;sum(http_inprogress_requests) by (job)&quot;, &quot;type&quot;: &quot;recording&quot; &#125; ], &quot;file&quot;: &quot;/rules.yaml&quot;, &quot;interval&quot;: 60, &quot;name&quot;: &quot;example&quot; &#125; ] &#125;, &quot;status&quot;: &quot;success&quot;&#125; 告警Alerts 此端点返回所有激活的告警的列表。 1GET /api/v1/alerts 123456789101112131415161718curl http://localhost:9090/api/v1/alerts&#123; &quot;data&quot;: &#123; &quot;alerts&quot;: [ &#123; &quot;activeAt&quot;: &quot;2018-07-04T20:27:12.60602144+02:00&quot;, &quot;annotations&quot;: &#123;&#125;, &quot;labels&quot;: &#123; &quot;alertname&quot;: &quot;my-alert&quot; &#125;, &quot;state&quot;: &quot;firing&quot;, &quot;value&quot;: &quot;1e+00&quot; &#125; ] &#125;, &quot;status&quot;: &quot;success&quot;&#125; 查询目标元数据Query target metadata 此段点返回目前由目标爬取的关于指标的元数据。这是实验性的，未来可能发生改变。 1GET /api/v1/targets/metadata URL查询参数: match_target=&lt;label_selectors&gt;: 标签选择器通过标签集匹配的目标。如果为空，则所有目标都被选中。 metics=&lt;string&gt;: 检索元数据的指标名称。如果为空，则所有指标元数据都被检索。 limit=&lt;number&gt;: 匹配的目标的最大数量。 栗子: 123456789101112131415161718192021222324252627curl -G http://localhost:9091/api/v1/targets/metadata \ --data-urlencode &apos;metric=go_goroutines&apos; \ --data-urlencode &apos;match_target=&#123;job=&quot;prometheus&quot;&#125;&apos; \ --data-urlencode &apos;limit=2&apos;&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: [ &#123; &quot;target&quot;: &#123; &quot;instance&quot;: &quot;127.0.0.1:9090&quot;, &quot;job&quot;: &quot;prometheus&quot; &#125;, &quot;type&quot;: &quot;gauge&quot;, &quot;help&quot;: &quot;Number of goroutines that currently exist.&quot;, &quot;unit&quot;: &quot;&quot; &#125;, &#123; &quot;target&quot;: &#123; &quot;instance&quot;: &quot;127.0.0.1:9091&quot;, &quot;job&quot;: &quot;prometheus&quot; &#125;, &quot;type&quot;: &quot;gauge&quot;, &quot;help&quot;: &quot;Number of goroutines that currently exist.&quot;, &quot;unit&quot;: &quot;&quot; &#125; ]&#125; 栗子: 1234567891011121314151617181920212223242526272829curl -G http://localhost:9091/api/v1/targets/metadata \ --data-urlencode &apos;match_target=&#123;instance=&quot;127.0.0.1:9090&quot;&#125;&apos;&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: [ // ... &#123; &quot;target&quot;: &#123; &quot;instance&quot;: &quot;127.0.0.1:9090&quot;, &quot;job&quot;: &quot;prometheus&quot; &#125;, &quot;metric&quot;: &quot;prometheus_treecache_zookeeper_failures_total&quot;, &quot;type&quot;: &quot;counter&quot;, &quot;help&quot;: &quot;The total number of ZooKeeper failures.&quot;, &quot;unit&quot;: &quot;&quot; &#125;, &#123; &quot;target&quot;: &#123; &quot;instance&quot;: &quot;127.0.0.1:9090&quot;, &quot;job&quot;: &quot;prometheus&quot; &#125;, &quot;metric&quot;: &quot;prometheus_tsdb_reloads_total&quot;, &quot;type&quot;: &quot;counter&quot;, &quot;help&quot;: &quot;Number of times the database reloaded block data from disk.&quot;, &quot;unit&quot;: &quot;&quot; &#125;, // ... ]&#125; 告警器AlertManagers 此端点返回Prometheus alertmanager discovery的当前状态的概述: 1GET /api/v1/alertmanagers active和dropped Alertmanagers都是响应的一部分: 12345678910111213141516curl http://localhost:9090/api/v1/alertmanagers&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: &#123; &quot;activeAlertmanagers&quot;: [ &#123; &quot;url&quot;: &quot;http://127.0.0.1:9090/api/v1/alerts&quot; &#125; ], &quot;droppedAlertmanagers&quot;: [ &#123; &quot;url&quot;: &quot;http://127.0.0.1:9093/api/v1/alerts&quot; &#125; ] &#125;&#125; 状态Status 以下状态端点暴露当前Prometheus配置。 Config 此端点返回当前加载的配置文件: 1GET /api/v1/status/config 配置返回为转存的YAML文件。由于YAML库的限制，YAML中不包含注释: 1234567curl http://localhost:9090/api/v1/status/config&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: &#123; &quot;yaml&quot;: &quot;&lt;content of the loaded config file in YAML&gt;&quot;, &#125;&#125; Flags 此端点返回Prometheus配置的标志值: 1GET /api/v1/status/flags 所有值的结果类型都是字符串: 123456789101112curl http://localhost:9090/api/v1/status/flags&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: &#123; &quot;alertmanager.notification-queue-capacity&quot;: &quot;10000&quot;, &quot;alertmanager.timeout&quot;: &quot;10s&quot;, &quot;log.level&quot;: &quot;info&quot;, &quot;query.lookback-delta&quot;: &quot;5m&quot;, &quot;query.max-concurrency&quot;: &quot;20&quot;, ... &#125;&#125; RunTime Information 此端点返回Prometheus Server的各种运行信息属性: 1GET /api/v1/status/runtimeinfo 根据运行属性，返回的值有两种类型: 123456789101112131415161718curl http://localhost:9090/api/v1/status/runtimeinfo&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: &#123; &quot;startTime&quot;: &quot;2019-11-02T17:23:59.301361365+01:00&quot;, &quot;CWD&quot;: &quot;/&quot;, &quot;reloadConfigSuccess&quot;: true, &quot;lastConfigTime&quot;: &quot;2019-11-02T17:23:59+01:00&quot;, &quot;chunkCount&quot;: 873, &quot;timeSeriesCount&quot;: 873, &quot;corruptionCount&quot;: 0, &quot;goroutineCount&quot;: 48, &quot;GOMAXPROCS&quot;: 4, &quot;GOGC&quot;: &quot;&quot;, &quot;GODEBUG&quot;: &quot;&quot;, &quot;storageRetention&quot;: &quot;15d&quot; &#125;&#125; Build Information 此端点返回各种关于Prometheus Server的构建信息属性: 1GET /api/v1/status/buildinfo 所有结果的值的类型都是字符串: 123456789101112curl http://localhost:9090/api/v1/status/buildinfo&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: &#123; &quot;version&quot;: &quot;2.13.1&quot;, &quot;revision&quot;: &quot;cb7cbad5f9a2823a622aaa668833ca04f50a0ea7&quot;, &quot;branch&quot;: &quot;master&quot;, &quot;buildUser&quot;: &quot;julius@desktop&quot;, &quot;buildDate&quot;: &quot;20191102-16:19:59&quot;, &quot;goVersion&quot;: &quot;go1.13.1&quot; &#125;&#125; TSDB Admin APIs这些都是为高级用户公开的数据库功能的API。除非设置--web.enable-admin-api，否则不启用这些API。 我们也公开了一个gRPC API。这是实验性的，未来可能会改变。 Snapshot 创建所有当前数据的快照snapshots/datetime-rand早TSDB的数据目录并返回目录作为响应。它将可选地跳过快照数据尽在头部块，并且未被压缩到磁盘。 12POST /api/v1/admin/tsdb/snapshotPUT /api/v1/admin/tsdb/snapshot URL查询参数: skip_head=&lt;bool&gt;: 跳过存在于头部块(head block)的数据，可选。 1234567curl -XPOST http://localhost:9090/api/v1/admin/tsdb/snapshot&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: &#123; &quot;name&quot;: &quot;20171210T211224Z-2be650b6d019eb54&quot; &#125;&#125; 快照现在位于: &lt;data-dir&gt;/snapshots/20171210T211224Z-2be650b6d019eb54 Delete Series 删除在一个时间范围内选择的一些列数据。实际数据仍然存在于磁盘上，并在未来被清除或通过点击Clean Tombstones endpoint来明确清理。如果成功，返回204。 12POST /api/v1/admin/tsdb/delete_seriesPUT /api/v1/admin/tsdb/delete_series URL查询参数: match[]=&lt;series_selector&gt;: 至少必须提供一个 start=&lt;rfc3339 | unix_timestamp&gt; end=&lt;rfc3339 | unix_timestamp&gt; 未指定时间范围将删除匹配的所有数据。 1curl -X POST -g &apos;http://localhost:9090/api/v1/admin/tsdb/delete_series?match[]=up&amp;match[]=process_start_time_seconds&#123;job=&quot;prometheus&quot;&#125;&apos; Clean Tombstones 从磁盘中删除已删除的数据并清理现有的tombstones。这可在清理数据后腾出磁盘空间。 如果成功，返回204。 12POST /api/v1/admin/tsdb/clean_tombstonesPUT /api/v1/admin/tsdb/clean_tombstones 不需要任何参数或body: 1curl -XPOST http://localhost:9090/api/v1/admin/tsdb/clean_tombstones 存储Storage: https://prometheus.io/docs/prometheus/latest/storage/ Prometheus包含了一个本地磁盘上的时序数据库(time series database)，但是可选地与远程存储系统集成。 本地存储Local storage Prometheus本地时序数据库存储时序数据自定义格式存储到磁盘上。 On-disk layout Prometheus按两小时为一个时间窗口分组存储在一个块(block)中。每个块是一个单独地目录，里面包含该时间窗口内的所有样本数据(chunks)，元数据文件(meta.json)以及索引文件(index)。其中索引文件会将指标名称和标签索引到样板数据的时间序列中。此期间如果通过 API 删除时间序列，删除记录会保存在单独的逻辑文件tombstone当中。 当前样本数据所在的块会被直接保存在内存中，不会持久化到磁盘中。为了确保Prometheus发生崩溃或重启时能够恢复数据，Prometheus启动时会通过预写日志（write-ahead-log(WAL)）重新记录，从而恢复数据。预写日志文件保存在wal目录中，每个文件大小为128MB。wal 文件包括还没有被压缩的原始数据，所以比常规的块文件大得多。一般情况下，Prometheus 会保留三个 wal 文件，但如果有些高负载服务器需要保存两个小时以上的原始数据，wal文件的数量就会大于3个。 Prometheus块数据的目录结构如下所示: 1234567891011121314151617181920./data├── 01BKGV7JBM69T2G1BGBGM6KB12│ └── meta.json├── 01BKGTZQ1SYQJTR4PB43C8PD98│ ├── chunks│ │ └── 000001│ ├── tombstones│ ├── index│ └── meta.json├── 01BKGTZQ1HHWHV8FBJXW1Y3W0K│ └── meta.json├── 01BKGV7JC0RY8A6MACW02A2PJD│ ├── chunks│ │ └── 000001│ ├── tombstones│ ├── index│ └── meta.json└── wal ├── 00000002 └── checkpoint.000001 本地存储的局限性是它无法构建集群(clustered)或副本(replicated)。因此，如果本地磁盘或节点出现故障，存储将无法扩展和迁移。使用RAID用于磁盘的可用性，使用快照用于备份，容量规划…建议提高耐用性。如果你对数据持久化的要求不是很严格，可以使用本地磁盘存储多达数年的数据。 可替代地，外部存储可通过使用remote read/write APIs。仔细评估这些系统，因为它们在耐用性，性能和效率差异很大。 有关存储格式的详细信息，请参考 TSDB格式 Compaction最初两个小时的块最终会在后台被压缩成更长的块。 操作配置Prometheus提供了几个标志来允许配置本地存储。最重要的几个: 1234567891011121314# 数据存储路径，默认data/--storage.tsdb.path# 样本数据在存储中保存的时间。超过该时间限制的数据就会被删除。默认15d-storage.tsdb.retention.time# 每个块的最大字节数（不包括 wal 文件）。如果超过限制，最早的样本数据会被优先删除。支持的单位有 KB, MB, GB, PB。默认0，即为不限制--storage.tsdb.retention.size# 压缩wal--storage.tsdb.wal-compression 一般情况下，Prometheus中存储的每一个样本大概会占用1-2Byte。因此，如果需要对Prometheus Server的本地磁盘空间做容量规划，可通过以下公式计算: 1needed_disk_space = retention_time_seconds * ingested_samples_per_second * bytes_per_sample 从上面公式中可以看出在保留时间（retention_time_seconds）和样本大小（bytes_per_sample）不变的情况下，如果想减少本地磁盘的容量需求，只能通过减少每秒获取样本数（ingested_samples_per_second）的方式。因此有两种手段，一是减少时间序列的数量，二是增加采集样本的时间间隔。考虑到 Prometheus 会对时间序列进行压缩效率，减少时间序列的数量效果更明显。 可视化Visualization 表达式浏览器Expression browser 表达其浏览器在 Prometheus Server 的 /graph 处。对于图形，请使用 Grafana 或 Console template。 GrafanaGrafana: https://grafana.com/ Grafana，美丽的分析和监控的开放平台，时序分析的开源那软件。 Grafana 支持查询 Prometheus。如下是一个Grafana仪表盘，用于查询Prometheus的数据： 安装完整的安装说明，请查看Grafana Docs。 CentOSRPM 12#sudo yum install &lt;rpm package url&gt;sudo yum install https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-5.1.4-1.x86_64.rpm repo 1234567891011121314151617181920[grafana]name=grafanabaseurl=https://packagecloud.io/grafana/stable/el/7/$basearchrepo_gpgcheck=1enabled=1gpgcheck=1gpgkey=https://packagecloud.io/gpg.key https://grafanarel.s3.amazonaws.com/RPM-GPG-KEY-grafanasslverify=1sslcacert=/etc/pki/tls/certs/ca-bundle.crtsudo yum install -y grafana#启动systemctl start grafana-server#命令行工具grafana-cli 包详情 Installs binary to /usr/sbin/grafana-server Copies init.d script to /etc/init.d/grafana-server Installs default file (environment vars) to /etc/sysconfig/grafana-server Copies configuration file to /etc/grafana/grafana.ini Installs systemd service (if systemd is available) name grafana-server.service The default configuration uses a log file at /var/log/grafana/grafana.log The default configuration specifies an sqlite3 database at /var/lib/grafana/grafana.db 二进制tar文件 1234567# Download and unpack Grafana from binary tar (adjust version as appropriate).curl -L -O https://grafanarel.s3.amazonaws.com/builds/grafana-2.5.0.linux-x64.tar.gztar zxf grafana-2.5.0.linux-x64.tar.gz# Start Grafana.cd grafana-2.5.0/./bin/grafana-server web Docker123456789101112131415161718192021#基础栗子docker run -d -p 3000:3000 grafana/grafana#配置化docker run \ -d \ -p 3000:3000 \ --name=grafana \ -e &quot;GF_SERVER_ROOT_URL=http://grafana.server.name&quot; \ -e &quot;GF_SECURITY_ADMIN_PASSWORD=secret&quot; \ grafana/grafana:version#默认环境变量值GF_PATHS_CONFIG /etc/grafana/grafana.iniGF_PATHS_DATA /var/lib/grafanaGF_PATHS_HOME /usr/share/grafanaGF_PATHS_LOGS /var/log/grafanaGF_PATHS_PLUGINS /var/lib/grafana/pluginsGF_PATHS_PROVISIONING /etc/grafana/provisioning 使用默认情况下，访问http://localhost:3000来访问Grafana。默认登录的用户名和密码： admin/admin。 创建Prometheus数据源 创建Prometheus图表 Console template控制台模板允许使用Go templating language创建任意控制台。这些都是从Prometheus Server提供的。 示例配置由于prometheus自带的alertmanager对国内通知支持不够完善，因此使用PrometheusAlert做告警通知。 prometheus配置样例prometheus的配置示例: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# my global configglobal: scrape_interval: 1m # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 1m # Evaluate rules every 15 seconds. The default is every 1 minute. scrape_timeout: 1m # scrape_timeout is set to the global default (10s). # for thanos external_labels: region: ali # hw|tx replica: full# Alertmanager configurationalerting: alertmanagers: - static_configs: - targets: ["localhost:9093"]# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.rule_files: - "rules/*.yml" # 通用告警规则模板 - "rules/nodes/*.yml" # 各主机告警规则# A scrape configuration containing exactly one endpoint to scrape:# Here it's Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: node-process-exporter file_sd_configs: - files: - "discovery/exporter/*.yml" # metrics_path defaults to '/metrics' # scheme defaults to 'http'. - job_name: mongodb-exporter file_sd_configs: - files: - "discovery/mongodb/*.yml" - job_name: kafka-exporter file_sd_configs: - files: - "discovery/kafka/*.yml" - job_name: aliyun-exporter static_configs: - targets: ["localhost:9525", "localhost:9526", "localhost:9527", "localhost:9528", "localhost:9529"] - job_name: blackbox_exporter metrics_path: /probe file_sd_configs: - files: - "discovery/blackbox/*.yml" relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [module] target_label: __param_module - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: 127.0.0.1:9115 alertmanager配置样例alertmanager的配置示例: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# global configglobal: resolve_timeout: 5m # smtp config # slack config # wechat config # http config# templates configtemplates: []# route treeroute: receiver: 'web.hook.prometheusalert' group_by: - instanceId - hostname group_wait: 30s group_interval: 1m # notification again repeat_interval: 10m # continue config # match: [ &lt;labelname&gt;: &lt;labelvalue&gt;, ... ] # match_re: [ &lt;labelname&gt;: &lt;regex&gt;, ... ] routes: - match: severity: warning repeat_interval: 1h - match_re: severity: notice|info repeat_interval: 6h# receiver listsreceivers:- name: 'web.hook.prometheusalert' webhook_configs: - url: 'http://127.0.0.1:8080/prometheus/alert'# list of inhibit rulesinhibit_rules: # aliyun - source_match: severity: 'critical' target_match_re: severity: 'warning' # source_match_re # target_match_re # Labels that must have an equal value in the source and target equal: ['instance','job','instanceId','kind'] # nodes - source_match: severity: 'critical' target_match_re: severity: 'warning' equal: - instance - job - hostname - kind prometheus自动发现prometheus的文件自动发现示例: 123456- labels: hostname: localhost hostgroup: test targets: - "localhost:9100" # node-exporter - "localhost:9256" # process-exporter prometheus告警规则prometheus的告警规则示例: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258groups:- name: node-cpu rules: # cpu核数 - record: instance:node_cpus:count expr: count without (cpu, mode) (node_cpu_seconds_total&#123;mode="idle"&#125;) # 每个cpu使用率 - record: instance_cpu:node_cpu_seconds_not_idle:rate2m expr: sum without (mode) (1 - rate(node_cpu_seconds_total&#123;mode="idle"&#125;[2m])) # 总cpu使用率 - record: instance:node_cpu_utilization:ratio expr: avg without (cpu) (instance_cpu:node_cpu_seconds_not_idle:rate2m) - alert: cpu使用率大于85% ### expr: (1 - avg(irate(node_cpu_seconds_total&#123;mode="idle"&#125;[5m])) by(instance,hostname)) * 100 &gt; 85 expr: instance:node_cpu_utilization:ratio * 100 &gt; 85 for: 3m labels: severity: warning level: 2 kind: CpuUsage annotations: summary: "cpu使用率大于85%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125;的cpu使用率: &#123;&#123; $value | humanize &#125;&#125;%" - alert: cpu使用率大于90% ### expr: (1 - avg(irate(node_cpu_seconds_total&#123;mode="idle"&#125;[5m])) by(instance,hostname)) * 100 &gt; 90 expr: instance:node_cpu_utilization:ratio * 100 &gt; 90 for: 1m labels: severity: critical level: 3 kind: CpuUsage annotations: summary: "cpu使用率大于90%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125;的cpu使用率: &#123;&#123; $value | humanize &#125;&#125;%" wxurl: "xxx" - alert: cpu使用率一分钟内增长30%且大于70% expr: delta(instance:node_cpu_utilization:ratio[2m]) * 100 &gt; 30 and on(hostname) instance:node_cpu_utilization:ratio * 100 &gt; 70 labels: severity: warning level: 2 kind: CpuUsageDelta annotations: summary: "cpu使用率一分钟内增长30%且大于70%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125; 的cpu使用率一分钟内增长30%且大于70%，增长率: &#123;&#123; $value | humanize &#125;&#125;%" wxurl: "xxx" - alert: cpu使用率一分钟内增长40%且大于80% expr: delta(instance:node_cpu_utilization:ratio[2m]) * 100 &gt; 40 and on(hostname) instance:node_cpu_utilization:ratio * 100 &gt; 80 labels: severity: critical level: 3 kind: CpuUsageDelta annotations: summary: "cpu使用率一分钟内增长40%且大于80%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125; 的cpu使用率一分钟内增长40%且大于80%，增长率: &#123;&#123; $value | humanize &#125;&#125;%" - alert: cpu使用率一分钟内增长50% expr: delta(instance:node_cpu_utilization:ratio[2m]) * 100 &gt; 50 labels: severity: critical level: 3 annotations: summary: "cpu使用率一分钟内增长50%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125; 的cpu使用率一分钟内增长50%，增长率: &#123;&#123; $value | humanize &#125;&#125;%" - alert: cpu负载大于Cores ### expr: node_load1 &gt; count(node_cpu_seconds_total&#123;mode="idle"&#125;) without (cpu,mode) expr: node_load1 &gt; instance:node_cpus:count for: 3m labels: severity: warning level: 2 kind: CpuLoad annotations: summary: "cpu负载大于cpu核数: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125;的cpu负载: &#123;&#123; $value &#125;&#125;" - alert: cpu负载大于2Cores-2 ### expr: node_load1 &gt; 2 * (count(node_cpu_seconds_total&#123;mode="idle"&#125;) without (cpu,mode)) - 2 expr: node_load1 &gt; (instance:node_cpus:count * 2) - 2 for: 1m labels: severity: critical level: 3 kind: CpuLoad annotations: summary: "cpu负载大于2Cores-2: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125;的cpu负载: &#123;&#123; $value &#125;&#125;" - alert: 主机上下文切换忙 ### expr: (rate(node_context_switches_total[5m])) / (count without(cpu, mode) (node_cpu_seconds_total&#123;mode="idle"&#125;)) &gt; 2000 expr: (rate(node_context_switches_total[5m]) / instance:node_cpus:count) &gt; 2000 for: 5m labels: severity: warning level: 2 annotations: summary: "主机上下文切换忙: &#123;&#123; $labels.hostname &#125;&#125;" description: "主机&#123;&#123; $labels.hostname &#125;&#125;的上下文切换大于2000/s: &#123;&#123; $value | humanize &#125;&#125;/s"- name: node-memory rules: # 内存可用率 - record: instance:node_memory_available:ratio expr: &gt; ( node_memory_MemAvailable_bytes or ( node_memory_Buffers_bytes + node_memory_Cached_bytes + node_memory_MemFree_bytes + node_memory_Slab_bytes ) ) / node_memory_MemTotal_bytes # 内存使用率 - record: instance:node_memory_utilization:ratio expr: 1 - instance:node_memory_available:ratio - alert: 主机内存面临压力 expr: rate(node_vmstat_pgmajfault[1m]) &gt; 1000 for: 5m labels: severity: warning level: 2 annotations: summary: "主机内存面临压力: &#123;&#123; $labels.instance &#125;&#125;" description: "节点内存面临压力。High rate of major page faults: &#123;&#123; $value &#125;&#125;" - alert: 内存使用率大于85% ### expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 &gt; 85 expr: instance:node_memory_utilization:ratio * 100 &gt; 85 for: 3m labels: severity: warning level: 2 kind: MemoryUsage annotations: summary: "内存使用率超过85%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125;的内存使用率: &#123;&#123; $value | humanize &#125;&#125;%" - alert: 内存使用率大于90% ### expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 &gt; 90 expr: instance:node_memory_utilization:ratio * 100 &gt; 90 for: 1m labels: severity: critical level: 3 kind: MemoryUsage annotations: summary: "内存使用率超过90%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125;的内存使用率: &#123;&#123; $value | humanize &#125;&#125;%" - alert: 内存使用率一分钟内增长30%且大于70% expr: delta(instance:node_memory_utilization:ratio[2m]) * 100 &gt; 30 and on(hostname) instance:node_memory_utilization:ratio * 100 &gt; 70 labels: severity: warning level: 2 kind: MemoryUsageDelta annotations: summary: "内存使用率一分钟内增长30%且大于70%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125; 的内存使用率一分钟内增长30%且大于70%，增长率: &#123;&#123; $value | humanize &#125;&#125;%" - alert: 内存使用率一分钟内增长40%且大于80% expr: delta(instance:node_memory_utilization:ratio[2m]) * 100 &gt; 40 and on(hostname) instance:node_memory_utilization:ratio * 100 &gt; 80 labels: severity: critical level: 3 kind: MemoryUsageDelta annotations: summary: "内存使用率一分钟内增长40%且大于80%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125; 的内存使用率一分钟内增长40%且大于80%，增长率: &#123;&#123; $value | humanize &#125;&#125;%" - alert: 内存使用率一分钟内增长50% expr: delta(instance:node_memory_utilization:ratio[2m]) * 100 &gt; 50 labels: severity: critical level: 3 annotations: summary: "内存使用率一分钟内增长50%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125; 的内存使用率一分钟内增长50%，增长率: &#123;&#123; $value | humanize &#125;&#125;%" - alert: 主机检测到oom kill expr: &gt; increase(node_vmstat_oom_kill[1h]) &gt; 2 or increase(syslog_oom_kills_total[1h]) &gt; 2 labels: severity: warning level: 2 annotations: summary: "主机检测到oom kill: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125;检测到oom kill: &#123;&#123; $value &#125;&#125;"- name: node-filesystem rules: # 磁盘分区可用率 - record: instance:node_filesystem_avail:ratio expr: node_filesystem_avail_bytes&#123;device=~"(/dev/.+|tank/dataset)"&#125; / node_filesystem_size_bytes&#123;device=~"(/dev/.+|tank/dataset)"&#125; # 磁盘分区使用率 - record: instance:node_filesystem_utilization:ratio expr: 1 - instance:node_filesystem_avail:ratio # 分区inode可用率 - record: instance:node_filesystem_files_avail:ratio expr: node_filesystem_files_free / node_filesystem_files # 分区inode使用率 - record: instance:node_filesystem_files_utilization:ratio expr: 1 - instance:node_filesystem_files_avail:ratio - alert: 磁盘分区使用率大于85% ### expr: (1- (node_filesystem_avail_bytes&#123;fstype=~"ext4|xfs"&#125; / node_filesystem_size_bytes&#123;fstype=~"ext4|xfs"&#125;)) * 100 &gt; 85 expr: instance:node_filesystem_utilization:ratio&#123;fstype=~"(ext.|xfs|zfs)"&#125; * 100 &gt; 85 for: 10m labels: severity: warning level: 2 kind: "&#123;&#123; $labels.mountpoint &#125;&#125;" annotations: summary: "磁盘分区&#123;&#123; $labels.mountpoint&#125;&#125;使用率大于85%" description: "&#123;&#123; $labels.hostname &#125;&#125;的磁盘分区&#123;&#123; $labels.mountpoint &#125;&#125;使用率为: &#123;&#123; $value | humanize &#125;&#125;%" - alert: 磁盘分区使用率大于90% ### expr: (1- (node_filesystem_avail_bytes&#123;fstype=~"ext4|xfs"&#125; / node_filesystem_size_bytes&#123;fstype=~"ext4|xfs"&#125;)) * 100 &gt; 90 expr: instance:node_filesystem_utilization:ratio&#123;fstype=~"(ext.|xfs|zfs)"&#125; * 100 &gt; 90 for: 3m labels: severity: critical level: 3 kind: "&#123;&#123; $labels.mountpoint &#125;&#125;" annotations: summary: "磁盘分区&#123;&#123; $labels.mountpoint&#125;&#125;使用率大于90%" description: "&#123;&#123; $labels.hostname &#125;&#125;的磁盘分区&#123;&#123; $labels.mountpoint &#125;&#125;使用率为: &#123;&#123; $value | humanize &#125;&#125;%" - alert: 分区inode使用率大于70% ### expr: (1 - (node_filesystem_files_free&#123;fstype=~"ext4|xfs"&#125; / node_filesystem_files&#123;fstype=~"ext4|xfs"&#125;)) * 100 &gt; 70 expr: instance:node_filesystem_files_utilization:ratio&#123;fstype=~"(ext.|xfs)"&#125; * 100 &gt; 70 for: 3m labels: severity: info level: 1 annotations: summary: "磁盘分区&#123;&#123; $labels.mountpoint &#125;&#125;的inode使用率大于70%" description: "&#123;&#123; $labels.hostname &#125;&#125;的磁盘分区&#123;&#123; $labels.mountpoint &#125;&#125;的inode使用率: '&#123;&#123; $value | humanize &#125;&#125;%'" - alert: 分区inode使用率大于80% ### expr: (1 - (node_filesystem_files_free&#123;fstype=~"ext4|xfs"&#125; / node_filesystem_files&#123;fstype=~"ext4|xfs"&#125;)) * 100 &gt; 80 expr: instance:node_filesystem_files_utilization:ratio&#123;fstype=~"(ext.|xfs)"&#125; * 100 &gt; 80 for: 3m labels: severity: warning level: 2 annotations: summary: "磁盘分区&#123;&#123; $labels.mountpoint &#125;&#125;的inode使用率大于80%" description: "&#123;&#123; $labels.hostname &#125;&#125;的磁盘分区&#123;&#123; $labels.mountpoint &#125;&#125;的inode使用率: '&#123;&#123; $value | humanize &#125;&#125;%'" 进程探针配置process-exporter探针配置示例: 123456789101112131415# https://github.com/ncabatoff/process-exporter# /proc/&lt;pid&gt;/xxxprocess_names: # java - name: "&#123;&#123;.Matches&#125;&#125;" cmdline: - '.+/bin/java .+' - name: "&#123;&#123;.Matches&#125;&#125;" cmdline: - 'java .+' #匹配完整的运行命令 - name: "&#123;&#123;.Matches&#125;&#125;" #- name: "&#123;&#123;.Comm&#125;&#125;" cmdline: - '.+' 进程告警规则prometheus进程告警规则示例: 1234567891011121314151617181920212223242526groups:- name: 测试进程告警规则 rules: - alert: nginx进程不存在 expr: 'sum(namedprocess_namegroup_states&#123;groupname=~"map\\[:nginx: master process .+"&#125;) without(state) == 0' for: 1m labels: severity: critical level: 3 annotations: summary: "nginx进程不存在, 实例: &#123;&#123; $labels.instance &#125;&#125;" description: "主机: &#123;&#123; $labels.hostname &#125;&#125;, 进程不存在: &#123;&#123; $labels.groupname &#125;&#125;" wxurl: webhook1,webhook2 mobile: phone1,phone2 - alert: filebeat进程不存在 expr: sum without(state) (namedprocess_namegroup_states&#123;groupname=~"map\\[:/usr/share/filebeat/bin/filebeat -e -c .+", hostgroup="xxx"&#125;) == 0 for: 1m labels: severity: critical level: 3 annotations: summary: "filebeat进程不存在, 实例: &#123;&#123; $labels.instance &#125;&#125;" description: "主机: &#123;&#123; $labels.hostname &#125;&#125;, 进程不存在: &#123;&#123; $labels.groupname &#125;&#125;" wxurl: webhook1,webhook2 mobile: phone1,phone2 集成INSTRUMENTING 客户端库CLIENT LIBRARIES: https://prometheus.io/docs/instrumenting/clientlibs/ 在监控服务之前，您需要通过 Prometheus 客户端库在其代码中添加集成。 选择与你编程语言相匹配的prometheus client library。你可以通过你的应用程序实例的HTTP endpoint来定义和暴露内部指标数据。 当prometheus采集你实例的HTTP端点时，客户端库会将所有指标的当前状态发送给prometheus server。 编写客户端库WRITING CLIENT LIBRARIES: https://prometheus.io/docs/instrumenting/writing_clientlibs/ 本章涵盖了Prometheus client libraries应该提供的功能和API。支持10种编程语言，因此编写客户端有很好的感觉。 惯例Conventions 应该注意的事： 采取每门语言的优点 常见的使用情况应该很容易 做某事的正确方式应该是简单的方式 更复杂的用例应该是可能的 常见用例： Counters without labels spread liberally around libraries/applications Timing functions/blocks of code in Summaries/Histograms Gauges to track current states of things (and their limits) Monitoring of batch jobs 整体结构Overall structure 客户端必须在内部进行回调以进行写操作。客户端一般应该遵循如下描述的结构。 关键类是收集器(collector)。这有个方法(一般称为collect)，此方法返回0和更多指标和样本。Collectors get registered with a CollectorRegistry. 数据通过传递一个CollectorRegistry到一个bridge类/方法/函数来公开，返回的是Promehteus支持的格式指标。每次CollectorRegistry抓取它必须回调每个收集器的收集方法。 大多数用户交互的接口是Counter, Gauge, Summary, Histogram收集器。这些代表一个单一指标，并应涵盖绝大多数使用情况，其中用户集成自己的代码。 更高级的用户案例（如从其它监控系统进行代理）需要编写一个自定义收集器。有人可能还希望编写一个bridge，以一个格式不同的监控系统来产生CollectorRegistry和生成数据，允许用户只考虑一个集成系统。 CollectorRegistry应该提供register(), unregister()函数，并且一个收集器应该被允许注册到多个CollectorRegistrys。 客户端必须是线程安全的。 命名 Namming 客户端库应遵循此文档中提及的函数，方法，类名称，记住它们的命名规范。例如，set_to_current_time()是一个好的Python命名规范，SetToCurrentTime()是一个好的Go命名规范，setToCurrentTime()是一个好的Java命名规范。 指标Metrics Counter, Gauge, Summary, Histogram指标类型是用户的主要接口。 Counter和Gauge必须是客户端库的一部分。Summary和Histogram至少有一个必须提供。 这些应主要用于为静态文件变量(file-static variables)，也就是说，全局变量定义在同一个文件，因为他们集成代码。客户端库应该启用它。常用情况是集成一段整体代码，而不是一个对象的一个实例的上下文中的一段代码。用户不应该在代码中担心探测他们的指标，客户端库应该代劳。 必须有一个默认的CollectorRegistry，默认的标准指标必须隐式注册到它与该用户不需要的特殊工作。必须有一个方式来让指标不注册到默认CollectorRegistry，在批处理作业和单元测试。自定义收集器应该遵顼这一点。 究竟编程语言应该如何创建指标。对于一些(Java, Go)构建器方法是最好的，对于其它(Python)函数参数是足够丰富的。 Java样例客户端: 12345class YourClass &#123; static final Counter requests = Counter.build() .name("requests_total") .help("Requests.").register();&#125; Counter Counter是一个单调递增的计数器。它不允许值减少，但可能被重置为0（如服务器重启）。 计数器必须有以下方法： inc()：计数器递增1 inc(douvel v)：计数器由给定数增加（v&gt;=0） 计数器必须从0开始。 计数器建议有： 计算给定一段代码异常抛出/升起的方法，可选地仅特定异常类型 Gauge Gauge表示一个值可增可减。 测量必须有以下方法： inc()：测量递增1 inc(double v)：测量由给定数增加 dec()：测量递减1 dec(double v)：测量由戈丁数减少 set(double v)：测量被设置为给定值 测量必须从0开始，你也可以在启动时提供一个不同值。 测量应该有以下方法： set_to_current_time()：将测量设置为unixtime 测量建议有： 使用一个方法来追踪某条函数/代码正在进行的请求。在Python中是track_inprogress。 测试一段代码实践的一个方法和测试测量的持续时间。这对于批量作业很有用。 Summary Summary样例观察滑动时间窗，兵器提供分布、频率、和的瞬时观察。 摘要绝不允许用户设置quantile作为标签名，因为这是内部使用的指定摘要总数(summary quantiles)。摘要鼓励提供quantiles作为exports，但这些都布恩那个进行聚合，并趋于缓慢。摘要必须允许每个quantiles，如_count, _sum是非常有用的，这必须是默认的。 摘要_count, _sum必须从0开始。 摘要必须有的方法： observe(double v)：观察给定的量 摘要应该有的方法： 以秒为用户的时间码。在Python中是time()。不能提供除了秒之外的其它单位。 Histogram Histogram允许事件的可分布聚合，如请求的等待时间。 直方图绝不允许le作为用户设置的label，le用于内部指派桶。 直方图必须提供一个方式来手动选择桶。方式以linear(start, width, count)和exponential(start, factor, count)应该提供来设置桶。计数必须排除+Inf桶。 直方图应该有相同的默认桶作为其它客户端库。一旦创建了指标桶就不能改变。 直方图必须有的方法： observe(double v) 直方图应该有的方法： 以秒为用户的时间码。不能提供除了秒之外的其它单位。 标签 Labels 标签是Prometheus最强大的一个方面，但容易被滥用。因此客户端库必须在提供标签给用户时必须非常小心。 客户端库必须在任何情况下让用户为Gauge, Counter, Summary, Histogram或其它由库提供的任意收集器有不同的标签名。 自定义收集器指标应该总是具有一致的标签名。客户端不该对此进行验证。 虽然标签很强大，但多数指标没有标签。因此，API应该允许标签，而不是控制它。 一个客户端库必须允许在Gauge, Counter, Summary, Histogram创建时间指定任意标签名的列表。客户端库应该支持任意数量的标签名。客户端库必须验证标签名称符合文件要求。 提供访问指标的标记尺寸的一般方法是通过labels()方法，它可以以标签指列表或从标签名到标签执的映射，并返回一个child。通常是.inc(), .dec(), .observe()等等。方法可以在child上调用。 通过labels()返回的Child应该由用户缓存，以避免再次看到它。 有标签的指标应该支持有相同签名作为labels()的remove()方法，这将从指标中移除一个child并不再公开它，clear()方法将移除指标的所有孩子。 这应该有一个方法，来初始化一个带有默认值的孩子，通常只是调用labels()。不带标签的指标必须总是被初始化，以避免缺失指标问题。 指标名称 Metric names 指标名称必须遵循规范。正如指标名称，这必须满足Gauge, Counter, Summary, Histogram的用途，并与该库提供的任意收集器。 许多客户端库提供三个部分来设置名称：namespace_subsystem_name。 动态/生成 指标名称或指标名子部分必须阻止，当一个自定义收集器从其它监控系统代理时除外。动态的/生成的 指标名称是你要使用的标签而不是一个标志。 指标描述和帮助 Metric description and help Gauge/Counter/Summary/Histogram 必须要求提供指标描述和帮助。客户端库提供的任意自定义收集器必须在指标上有描述和帮助。 公开Exposition 客户端必须执行基于文本的公开格式，详细文档: https://prometheus.io/docs/instrumenting/exposition_formats/ 公开的指标的可再现的顺序是鼓励的（尤其是以人类可读的格式），如果它可在没有显著资源成本增加来实现。 标准和运行时收集器Standard and runtime collectors 客户端库应该在标准导出中提供些什么，下面将介绍。 这些应该被实现为自定义收集器，并在默认的CollectorRegistry默认注册。应该有方式来禁用这些。 进程指标 Process metrics 这有一些以process_为前缀的指标。如果获得必要的值是有问题的，或甚至根本无法使用语言，或运行时，客户端库应该留出相应的指标或特殊值(如NaN)。所有以字节的内存值，所有以unixtime/seconds的时间。 指标名 帮助字符串 单位 process_cpu_seconds_total Total user and system CPU time spent in seconds seconds process_open_fds Number of open file descriptors file descriptors process_max_fds Maximum number of open file descriptors file descriptors process_virtual_memory_bytes Virtual memory size in bytes bytes process_virtual_memory_max_bytes Maximum amount of virtual memory available in bytes bytes process_resident_memory_bytes Resident memory size in bytes bytes process_heap_bytes Process heap size in bytes bytes process_start_time_seconds Start time of the process since unix epoch in seconds seconds 运行时指标 Runtime metrics 此外，客户端库鼓励提供有意义的指标当语言运行时，如go_, hotspot_等等前缀开头的相关指标。 单元测试Unit tests 客户端库应该有覆盖核心集成库和公开的单元测试。 客户端库鼓励提供一个方式，使用户更容易进行单元测试。例如，在Python中有CollectorRegistry.get_sample_value。 打包和依赖Packaging and dependencies 理想情况下，客户端库可以被包括在任意应用程序中添加一些集成而不会破坏程序。因此，添加客户端库的依赖时请小心。 性能考虑Performance considerations 由于客户端库必须是线程安全的，需要某种形式的并发控制和考虑多核机器和应用程序的性能。 根据经验最少的高性能是互斥。处理器原子指令往往是在中间，并且一般是可接受的。 如上所述，labels()的结果应该是可缓存的。指标应该避免被阻塞当它们被递增或递减时。 推送指标PUSHING METRICS: https://prometheus.io/docs/instrumenting/pushing/ 偶尔，你需要监控不能被抓取的组件。Prometheus Pushgateway允许你推送指标。与Prometheus简单额基于文本格式相结合，这使得它很容易集成，甚至使用shell脚本而不需要客户端库。 探针和集成EXPORTERS AND INTEGRATIONS: https://prometheus.io/docs/instrumenting/exporters/ 有许多库和第三方系统可为Prometheus提供相应的指标。 第三方探针Third-party exporters 有一些探针是由Prometheus官方维护的，其它的是由第三方贡献和维护。 编写探针WRITING EXPORTERS: https://prometheus.io/docs/instrumenting/writing_exporters/ 如果你在集成自己的代码，那么Prometheus client library如何集成自己的代码的通用规则应该被遵守。当从另一个监控或集成系统采取指标时，事情往往并不是非黑即白。 当编写一个探针或自定义收集器时，此文档包含的事情你应该考虑。 可维护性和纯度Maintainability and purity 当你编写一个探针时，你需要做出的一个决定是有多少工作你愿意放在获得完美的指标上。 如果有问题的系统只有很少改变的指标的一小撮，然后让一切完美是一个容易的选择，一个好的样例是HAProxy exporter 在另一方面，当系统上有上百个指标是新版本经常变动的，如果你想试图把事情做完美，那么你已经给自己制造了许多正在进行的工作。MysQL exporter在这系列(spectrum)的末端。 node exporter是这些的混合。例如，mdadm收集器手动解析一个文件并公开为此收集器特定创建的指标。对于meminfo收集器，结果跨越不同内核版本，因此我们最终做足够的转换来创建有效的指标。 配置Configuration 当程序工作时，你的目标应该是探针不需要用户自定配置就可以运行。你可能还希望提供过滤某些指标的能力（用户定义只需要收集的指标，不需要收集所有指标），降低系统的开销。例如node exporter可让用户定义收集哪些指标，虽然我是全部收集。 当与其它监控系统一起工作时，框架和协议，你将提供额外的配置或自定义来生成适合Prometheus的指标。在最好的情况下，一个监控系统有类似的足够的Prometheus数据模型，你可以自动确定如何转换指标。如Cloudwatch, SNMP, collectd的情况。至多，我们需要让用户选择获取的那些指标。 也就是探针配置简单化，探针指标用户可选择。 在其它情况下，系统指标是不是十分标准的，这却决于系统和底层应用的使用情况。在这种情况下，用户必须告诉我们如何转换转换指标。JMX exporter是最明显的案例，与Graphite exporter和StatsD exporter也需要配置来提取标签。 确保探针出口开箱没有配置，以及提供需要转换的示例配置的选择，这是一个建议。 YAML是标准的Prometheus配置格式，所有配置默认都应该适应YAML。 指标和标签命名METRIC AND LABEL NAMING: https://prometheus.io/docs/practices/naming/ 指标和标签的约定不需要使用Prometheus，但可以作为一个风格指南和最佳实践的集合。 指标名称Metric names 一个指标名称： 必须符合有效字符的数据模型 应该有一个应用程序(single-word)相关的指标所属前缀。如： prometheus_notifications_total process_cpu_seconds_total http_request_duration_seconds 必须有一个单一的单位（如秒，毫秒等） 应该使用基本单位（如seconds, bytes, meters，而不是milliseconds, megabytes, kilometers） 应该有一个描述单位的后缀。如： http_request_duration_seconds node_memory_usage_bytes http_requests_total process_cpu_seconds_total foobar_build_info should represent the same logical thing-being-measured across all label dimensions request duration bytes of data transfer instantaneous resource usage as a percentage 作为一个经验，在给定指标的所有尺寸上，无论是sum()还是avg()都应该是有意义的。如果没有意义，则将数据分裂成多个指标。 标签Labels 使用标签来区分被测量的事物的特点： api_http_requests_total，不同的请求类型：operation=&quot;create|update|delete&quot; api_request_duration_seconds，不同的请求阶段：stage=&quot;extract|transform|load&quot; 不要将标签名对应到指标名，如果相应的标签聚合了，这会冗余并造成混乱。 注意：请记住，标签键值对每一个独特的组合代表了一个新的时间序列，这可能会极大的提高存储的数据量。不要使用标签来存储高基数，如用户ID，邮件地址等。 基本单位Base units Prometheus没有硬编码任何单位。为了更好的兼容性，应该使用基本单位。以下是一些栗子： Family Base unit Remark Time seconds - Temperature celsius 摄氏度优于开尔文 Length meters - Bytes bytes - Bits bytes 为了避免混淆，通常使用bytes Percent ratio 0-1而不是0-100 Voltage volts - Electric current amperes - Energy joules - Mass grams 克优于千克 指标Metrics 命名Naming 遵循指标命名的最佳实践。 指标名不应该由程序产生，除非在编写自定义收集器或探针时。 指标必须使用基础单位并让它们转换为更可读的图形工具。无论你使用了什么单位，指标名中的单位必须匹配在使用的单位。类似地，公开比率(ratios)，而不是百分比(percentages)。 指标名不应该包含导出的标签，如果标签被聚集将没有意义。Prometheus指标和标签名以snake_case编写。公开的指标不应包含冒号，这些被保留用于用户定义记录规则(recording rules)，当使用聚合时。 只有[a-zA-Z0-9:_]是有效的指标名。 _sum, _count, _bucket, _total后缀用于Summary, Histogram, Counter。_total是Counter的惯例，如果你使用COUNTER类型你应该使用它。 process_, scrape_前缀是保留的。 当你有一个successful request count和一个failed request count，最佳的方式是一个指标用于成功的请求，另一个指标用于失败的请求。这很容易计算出失败率。不要使用带success或failed标签的一个指标。同样，此规则也同样适用于其它指标。 一个带有原始名的HELP字符串可以提供大部分相同的好处。 标签Labels 避免将type作为标签名称，它过于笼统往往无意义。你应该尝试尽可能地避免发生冲突，如region, cluster等等。但是，如果这就是应用程序调用的一些资源，最好不要通过重命名来引起混乱。 因此要避免把东西放入一个指标，只是因为它们共享一个前缀。除非你确定一个指标是有意义的，多个指标是安全的。 le标签对于Histogram有特殊意义，quantile标签对于Summary有特殊意义。通常避免使用这些标签。write/read， send/receive最好划分为单独的指标，而不是一个指标。 经验法则是，当求和或求平均值时，一个指标应该是有意义的。 类型Type 你应该尝试匹配你的指标类型到Prometheus类型。这通常是counters和gauges。通常它不会很明显指标是什么类型，特别是如果你自动处理一组指标。一般UNTYPED是一个安全的默认值。 帮助字符串Help strings 当你转换指标时，它对用于能够追踪原来是什么样的有帮助，以及造成这种转换有什么规则。将收集器或探针名称、应用的任意规则的ID和名称和原始指标的详情写入帮助字符串将极大地帮助用户。 Prometheus不喜欢一个字段有不同的帮助字符串。 示例: 12345# HELP node_cooling_device_max_state Maximum throttle state of the cooling device# TYPE node_cooling_device_max_state gaugenode_cooling_device_max_state&#123;name=&quot;0&quot;,type=&quot;Processor&quot;&#125; 7node_cooling_device_max_state&#123;name=&quot;1&quot;,type=&quot;Processor&quot;&#125; 7node_cooling_device_max_state&#123;name=&quot;2&quot;,type=&quot;Processor&quot;&#125; 7 丢弃更少的有用信息Drop less useful statistics 有些集成系统公开了1m, 5m, 15m率、平均率，在应用程序启动的时候。 这些都应该被丢弃，因为它们不是很有用，并添加了混乱。Prometheus可以自己计算比率，并且通常作为公开的平均值呈指数衰减。 点字符串Dotted strings 许多监控系统没有标签，而是使用点: my.class.path.mymetric.labelvalue1.labelvalue2.labelvalue3 收集器Collectors 当为探针实现收集器时，你永远不应该使用通常的直接集成方法，并在每个抓取上更新指标。 每次创建新的指标。在Go的Collect()方法中使用MustNewConstMetric。Python请参考: https://github.com/prometheus/client_python#custom-collectors 原因有两方面。首先，两个抓取可能发生在同一时间，和直接集成使用的什么是文件级别的全局变量。其次，如果一个标签执消失，它仍然将公开。 关于抓取自身的指标Metrics about the scrape itself 有时你想导出关于抓取的指标，如处理了多少记录等。这应该被公开为gauges当它们关于事件时，通过探针名的指标名前缀，如jmx_scrape_duration_seconds。 机器和进程指标Machine and process metrics 许多系统，如ES，会公开机器指标（如cpu, memory, filesystem）等信息。Prometheus生态中的node exporter提供了这些信息，这些指标就应该被丢弃。 在Java世界里，许多集成框架公开了程序级别和JVM级别的统计信息，如CPU, GC等。Java客户端和JMX探针已包含这些，所以也应该丢弃。这同样也可用于其它类似的语言和框架。 部署Deployment 每个探针应该监控只有一个实例的应用程序，preferably sitting right beside it on the same machine。这意味着你运行没给一个HAProxy，你运行了一个haproxy_exporter进程。 调度Scheduling 当Prometheus抓取指标时，指标应该从应用处拉取，探针不应该基于自己的定时器执行抓取。也就是说，所有的抓取都应该是同步的(synchronous)。 因此，你不应该在公开的指标上设置时间戳，而让Prometheus来做。如果你认为需要时间戳，那么你可能需要使用pushgateway来代替。 如果检索指标特别昂贵，即超过了一分钟，可以接受的是缓存它(cache it)。这应该在注释在HELP字符串中。 Prometheus默认抓取的超时时间是10s。如果你的探针希望超过这一点，你应该在你的用户文档中明确的调用此。 推送Pushes 有些应用程序和监控系统只能推送指标(push metrics)，如StatsD, Graphite, collectd。有两方面的考虑： 首先，指标什么时候过期？其次，这些类型的系统倾向于允许你的用户发送变化量(deltas)或原始计数器(raw counter)。你应该尽可能依赖原生计数器，因为这一般是Prometheus model。 对于服务级别的指标，你应该有探针推送到Pushgateway，在事件而不是你自己处理状态之后退出。对于实例级别的指标，还没有明确模式。 抓取失败Failed scrapes 目前有两种模式的抓取失败，当应用程序不响应或其它问题时。 第一个就是返回5xx错误。 第二个是有一个myexporter_up，如haproxy_up，值是0还是1依赖于抓取工作。 后者更好，即使抓取失败，你还可以得到一些有用的指标。 抓取页面Landing page]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Prometheus</tag>
        <tag>Monitor</tag>
        <tag>Alert</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes]]></title>
    <url>%2F2018%2F06%2F26%2FKubernetes%2F</url>
    <content type="text"><![CDATA[参考： Kubernetes: https://zh.wikipedia.org/wiki/Kubernetes 官方文档: https://kubernetes.io/docs/ 中文文档: http://docs.kubernetes.org.cn/ GitHub: https://github.com/kubernetes/kubernetes etcd: https://coreos.com/etcd/docs/latest/ flannel: https://coreos.com/flannel/docs/latest/ 环境： CentOS7x86_64 Kubernetes v1.11 配置此章节提供了有关安装k8s和配置k8s集群的相关说明。 安装有几种方式创建k8s集群： minikube(自动部署) kubeadm(自动部署) 软件包(建议初学者使用此方式) 使用minikube创建集群Using Minikube to Create a Cluster 目标： 了解k8s集群是什么 了解Minikube是什么 启动一个k8s集群 k8s 集群k8s协调一个高度可用的计算机集群，它们连接起来作为一个单元工作 。k8s以更有效的方式自动化跨集群分发和调整应用程序容器。 k8s集群包含两种类型的资源： Master Nodes Master负责管理集群。它协调集群中的所有活动。Node是工作主机。每个节点有一个Kubelet的Agent，负责管理节点并与Master(API)通信。此外，节点上还应有处理容器操作的工具(如Docker)。生成环境的k8s集群至少有三个节点。用户可通过k8s API直接与集群进行交互。 使用Minikube部署集群: https://github.com/kubernetes/minikubeMinikube是一个工具，它运行一个单节点的k8s集群供开发用户使用。 Linux平台 12345678910111213141516curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 &amp;&amp; \chmod +x minikube &amp;&amp; \sudo mv minikube /usr/local/bin/##安装kubectlcurl -Lo kubectl https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubectl &amp;&amp; \chmod +x kubectl &amp;&amp; \sudo mv kubectl /usr/local/bin/minikube versionminikube startkubectl versionkubectl cluster-infokubectl get nodes kubeadm创建集群安装kubeadm本节介绍了如何安装kubeadm工具。 安装前 2GB RAM+ 2 cpus+ 集群主机网络互通 node上唯一的主机名，MAC，UUID 开放特定端口(防火墙) Swap disabled。必须关闭swap才能使kubelet正常工作。 验证MAC或UUID对每个node都是唯一的 ifconfig -a获取MAC cat /sys/class/dmi/id/product_uuid查看UUID 检查网络适配器 如果k8s组件不可达，请手动添加路由。 检查需要的端口 12345678910111213#masterProtocol Direction Port Range Purpose Used ByTCP Inbound 6443* Kubernetes API server AllTCP Inbound 2379-2380 etcd server client API kube-apiserver, etcdTCP Inbound 10250 Kubelet API Self, Control planeTCP Inbound 10251 kube-scheduler SelfTCP Inbound 10252 kube-controller-manager Self#workerProtocol Direction Port Range Purpose Used ByTCP Inbound 10250 Kubelet API Self, Control planeTCP Inbound 30000-32767 NodePort Services** All 安装docker使用阿里云镜像。kubeadm v1.11.1最高支持Docker 17.03，请注意。 123456789wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repomv docker-ce.repo /etc/yum.repos.dyum install -y docker-ce.x84_64#由于kubeadm不支持最新版的docker，所以需要安装指定版本yum list docker-ce --showduplicatesyum install -y docker-ce-17.03.2.ce 安装kubeadm, kubelet, kubectl kubeadm: 引导集群 kubelet: k8s agent kubectl: command line 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#创建repocat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpgEOF#国外镜像凉凉，所以换用阿里云cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF#禁用防火墙systemctl stop firewalldsystemctl disable firewalld#关闭selinuxsetenforce 0sed -i "s/^SELINUX=permissive/SELINUX=disabled/g" /etc/selinux/config#关闭swap，否则kubelet无法正常使用swapoff -a#将/etc/fstab中swap注释掉sed -i 's/.*swap.*/#&amp;/' /etc/fstab#安装yum install -y epel-release ebtables ethtoolyum install -y kubelet kubeadm kubectlsystemctl enable kubelet &amp;&amp; systemctl start kubelet#系统配置，开启网络桥接cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOF#生效sysctl -p /etc/sysctl.d/k8s.confsysctl --systemsystemctl daemon-reload#各主机时区，时间同步timedatectl set-timezone Asia/Shanghai#crontab -e#ntp*/30 * * * * /sbin/ntpdate 1.cn.pool.ntp.org &gt; /dev/null 2&gt;&amp;1#hosts&lt;master-ip&gt; master&lt;node-ip&gt; node 配置cgroup driver使用docker时，kubelet会将其驱动设置与Docker相同。kubeadm会自动检查kubelet的cgroup驱动，并在运行时将其设置到/var/lib/kubelet/kubeadm-flags.env文件。 12345678910111213docker info | grep -i 'cgroup driver'Cgroup Driver: systemd#此文件是kubeadm init生成的cat /var/lib/kubelet/kubeadm-flags.envKUBELET_KUBEADM_ARGS=--cgroup-driver=systemd --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni#如果此文件未配置此信息，我们手动添加cd /etc/systemd/system/kubelet.service.dvim 10-kubeadm.confKUBELET_KUBEADM_ARGS=--cgroup-driver=systemd --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni 挂载SS拉取k8s镜像由于无法直接拉去Google k8s镜像，所以可让Docker使用SS来拉取镜像。 123456789101112131415161718192021222324252627# 安装ss 客户端yum install libsodium libsodium-devel -ypip3 install https://github.com/shadowsocks/shadowsocks/archive/master.zip -U# 配置ss# /etc/shadowsocks.json# nohup sslocal -c /etc/shadowsocks.json &gt; ./ss.log 2&gt;&amp;1 &amp;yum -y install privoxy# 配置 /etc/privoxy/config# forward-socks5t / 127.0.0.1:1080 .# 参考: https://dylanyang.top/post/2019/05/15/centos7%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEshadowsocks%E5%AE%A2%E6%88%B7%E7%AB%AF/# systemctl start privoxy# vim /etc/profile# export http_proxy=http://127.0.0.1:8118# export https_proxy=http://127.0.0.1:8118# source /etc/profile# 这样其实Docker还是无法使用代理，但机器可以# 这是因为 systemd 引导启动的 service 默认不会读取这些变量，所以需要手动修改 service 启动文件，在其中加入环境变量解决。# 解决方法： 设置docker代理# vim /usr/lib/systemd/system/docker.service# 配置SS socks端口[Service]...Environment="ALL_PROXY=socks5://127.0.0.1:1080" 之后进行kubeadm初始化就没问题了，用完之后可以关闭。 1kubeadm init 拉取k8s.gcr.io镜像链接: https://console.cloud.google.com/gcr/images/google-containers/GLOBAL?location=GLOBAL&amp;project=google-containers 利用某台能上网的主机，拉取Google上kubeadm需要的k8s.gcr.io/image镜像。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193#查看kubeadm需要使用的imagekubeadm config images listk8s.gcr.io/kube-apiserver-amd64:v1.11.1k8s.gcr.io/kube-controller-manager-amd64:v1.11.1k8s.gcr.io/kube-scheduler-amd64:v1.11.1k8s.gcr.io/kube-proxy-amd64:v1.11.1k8s.gcr.io/pause-amd64:3.1k8s.gcr.io/etcd-amd64:3.2.18k8s.gcr.io/coredns:1.1.3#最好把所有镜像都拉下来，否则后面初始化的时候容易报错#在gcr.io上查找镜像#浏览器访问: &lt;https://console.cloud.google.com/gcr/images/google-containers/GLOBAL?location=GLOBAL&amp;project=google-containers&gt;#找一台能用的服务器，将这些image拉下来，推到自己的repo上再在kubeadm机器上拉取镜像，之后tag成kubeadm需要的格式#写一个脚本自动拉取镜像，更名镜像，推送镜像#我基本上把全部镜像都拉了vim k8sImages.shimages=(coredns:1.1.3etcd-amd64:3.1.15etcd-amd64:3.1.16etcd-amd64:3.1.17etcd-amd64:3.2.17etcd-amd64:3.2.18flannel-amd64:0.5.5heapster-amd64:v1.4.0heapster-amd64:v1.4.1heapster-amd64:v1.4.2heapster-amd64:v1.4.3heapster-amd64:v1.5.0heapster-amd64:v1.5.1heapster-amd64:v1.5.2heapster-amd64:v1.5.3heapster-amd64:v1.5.4heapster-grafana-amd64:v4.4.3heapster-grafana-amd64:v5.0.4heapster-influxdb-amd64:v1.3.3heapster-influxdb-amd64:v1.5.2k8s-dns-dnsmasq-nanny-amd64:1.14.10k8s-dns-dnsmasq-nanny-amd64:1.14.6k8s-dns-dnsmasq-nanny-amd64:1.14.7k8s-dns-dnsmasq-nanny-amd64:1.14.8k8s-dns-dnsmasq-nanny-amd64:1.14.9k8s-dns-kube-dns-amd64:1.14.10k8s-dns-kube-dns-amd64:1.14.5k8s-dns-kube-dns-amd64:1.14.6k8s-dns-kube-dns-amd64:1.14.7k8s-dns-kube-dns-amd64:1.14.8k8s-dns-kube-dns-amd64:1.14.9k8s-dns-sidecar-amd64:1.14.10k8s-dns-sidecar-amd64:1.14.5k8s-dns-sidecar-amd64:1.14.6k8s-dns-sidecar-amd64:1.14.7k8s-dns-sidecar-amd64:1.14.8k8s-dns-sidecar-amd64:1.14.9kube-apiserver-amd64:v1.10.5kube-apiserver-amd64:v1.10.6kube-apiserver-amd64:v1.11.0kube-apiserver-amd64:v1.11.1kube-apiserver-amd64:v1.9.10kube-controller-manager-amd64:v1.10.5kube-controller-manager-amd64:v1.10.6kube-controller-manager-amd64:v1.11.0kube-controller-manager-amd64:v1.11.1kube-controller-manager-amd64:v1.9.10kube-proxy-amd64:v1.10.6kube-proxy-amd64:v1.11.0kube-proxy-amd64:v1.11.1kube-proxy-amd64:v1.9.10kubernetes-dashboard-amd64:v1.6.2kubernetes-dashboard-amd64:v1.6.3kubernetes-dashboard-amd64:v1.7.0kubernetes-dashboard-amd64:v1.7.1kubernetes-dashboard-amd64:v1.8.0kubernetes-dashboard-amd64:v1.8.1kubernetes-dashboard-amd64:v1.8.2kubernetes-dashboard-amd64:v1.8.3kube-scheduler-amd64:v1.10.6kube-scheduler-amd64:v1.11.0kube-scheduler-amd64:v1.11.1kube-scheduler-amd64:v1.9.10pause-amd64:3.0pause-amd64:3.1pause:3.1)#可能pause与pause-amd64是一个，到时只需拉一个，然后tagfor image in $&#123;images[@]&#125;do docker pull k8s.gcr.io/$&#123;image&#125; docker tag k8s.gcr.io/$&#123;image&#125; zhang21/$&#123;image&#125; docker image rm k8s.gcr.io/$&#123;image&#125; docker push zhang21/$&#123;image&#125;done#查看docker image ls#到我的docker-hub中查看#https://hub.docker.com/u/zhang21/#现在在kubeadm集群机器上操作#还是写一个脚本来拉取镜像，更名镜像，删除镜像vim k8sImage.shimages=(coredns:1.1.3etcd-amd64:3.1.15etcd-amd64:3.1.16etcd-amd64:3.1.17etcd-amd64:3.2.17etcd-amd64:3.2.18flannel-amd64:0.5.5heapster-amd64:v1.4.0heapster-amd64:v1.4.1heapster-amd64:v1.4.2heapster-amd64:v1.4.3heapster-amd64:v1.5.0heapster-amd64:v1.5.1heapster-amd64:v1.5.2heapster-amd64:v1.5.3heapster-amd64:v1.5.4heapster-grafana-amd64:v4.4.3heapster-grafana-amd64:v5.0.4heapster-influxdb-amd64:v1.3.3heapster-influxdb-amd64:v1.5.2k8s-dns-dnsmasq-nanny-amd64:1.14.10k8s-dns-dnsmasq-nanny-amd64:1.14.6k8s-dns-dnsmasq-nanny-amd64:1.14.7k8s-dns-dnsmasq-nanny-amd64:1.14.8k8s-dns-dnsmasq-nanny-amd64:1.14.9k8s-dns-kube-dns-amd64:1.14.10k8s-dns-kube-dns-amd64:1.14.5k8s-dns-kube-dns-amd64:1.14.6k8s-dns-kube-dns-amd64:1.14.7k8s-dns-kube-dns-amd64:1.14.8k8s-dns-kube-dns-amd64:1.14.9k8s-dns-sidecar-amd64:1.14.10k8s-dns-sidecar-amd64:1.14.5k8s-dns-sidecar-amd64:1.14.6k8s-dns-sidecar-amd64:1.14.7k8s-dns-sidecar-amd64:1.14.8k8s-dns-sidecar-amd64:1.14.9kube-apiserver-amd64:v1.10.5kube-apiserver-amd64:v1.10.6kube-apiserver-amd64:v1.11.0kube-apiserver-amd64:v1.11.1kube-apiserver-amd64:v1.9.10kube-controller-manager-amd64:v1.10.5kube-controller-manager-amd64:v1.10.6kube-controller-manager-amd64:v1.11.0kube-controller-manager-amd64:v1.11.1kube-controller-manager-amd64:v1.9.10kube-proxy-amd64:v1.10.6kube-proxy-amd64:v1.11.0kube-proxy-amd64:v1.11.1kube-proxy-amd64:v1.9.10kubernetes-dashboard-amd64:v1.6.2kubernetes-dashboard-amd64:v1.6.3kubernetes-dashboard-amd64:v1.7.0kubernetes-dashboard-amd64:v1.7.1kubernetes-dashboard-amd64:v1.8.0kubernetes-dashboard-amd64:v1.8.1kubernetes-dashboard-amd64:v1.8.2kubernetes-dashboard-amd64:v1.8.3kube-scheduler-amd64:v1.10.6kube-scheduler-amd64:v1.11.0kube-scheduler-amd64:v1.11.1kube-scheduler-amd64:v1.9.10pause-amd64:3.0pause-amd64:3.1pause:3.1)for image in $&#123;images[@]&#125;do docker pull zhang21/$&#123;image&#125; docker tag zhang21/$&#123;image&#125; k8s.gcr.io/$&#123;image&#125; docker image rm zhang21/$&#123;image&#125;done#查看docker image ls 创建单master集群kubeadm可帮助你引导符合最佳实践的最小化可行的k8s集群。使用kubeadm，你的集群应通过k8s一致性测试。kubeadm还支持其它集群生命周期功能，如升级、降级和管理引导令牌(bootstrap token)。kubeadm旨在成为新用户开始尝试k8s的一种简单方法。可使用deb/rpm软件包在系统上轻松安装kubeadm。因为你可在各种类型的机器上安装kubeadm，所以它非常适合于Ansible/Salt等配置系统集成。 kubeadm的简单性意味着它可以服务于各种用例： 新用户可以从kubeadm开始，第一次尝试k8s 熟悉k8s的用户可以使用kubeadm启动集群，并测试他们的应用程序 较大的项目可以包括kubeadm作为更复杂系统中的构件，也可以包括其它安装程序工具 kubeadm Maturity(成熟度) Area Maturity Level Command line UX beta Implementation beta Config file API alpha Self-hosting alpha kubeadm alpha subcommands alpha CoreDNS GA DynamicKubeletConfig alpha kubeadm的整体功能状态为Beta，并将很快添加到GA(General Availability)。一些子功能，如自托管(self-hosting)和配置文件API仍在积极开发中。 k8s版本通常支持九个月，这也适用于kubeadm。 Kubernetes version Release month End-of-life-month v1.6.x March 2017 December 2017 v1.7.x June 2017 March 2018 v1.8.x September 2017 June 2018 v1.9.x December 2017 September 2018 v1.10.x March 2018 December 2018 v1.11.x June 2018 March 2019 开始前 一台或多台主机 2GB+ RAM(每台机器) 2CPUs+(master) 网络互通 目标 安装 单master/高可用性 的k8s集群 在集群上安装pod-network，以便pod间可互相通信 组件 123456789101112131415#Masteretcdkube-apiseverkube-controller-managerkube-schedulerkube-flannelkube-proxykube-dnskubectl#Nodekube-flannelkube-proxykubectl 说明 安装kubeadm如已安装，可升级到最新版。 初始化集群master主机是控制组件运行的地方，包括etcd, API server… 1234567891011121314151617#1#选择一个 pod network add-on，并验证是够需要将任何参数传递给kubeadm初始化。你可以使用--pod-network-cidr来指定特定值#这里使用flannel#2，可选#除非另有说明，否则kubeadm使用与默认网关关联的网络接口来通告master#使用kubeadm init --apiserver-advertise-address=&lt;ip-addr&gt;来使用不同网络接口#3，可选#在kubeadm init之前运行kubeadm config images pull以验证与gcr.io的连接#或kubeadm config images list查看需要的镜像#运行kubeadm init &lt;args&gt; 更多信息kubeadm init首先运行一系列检查，以确保机器 已准备好运行k8s。这些预检查会显示警告并退出错误。然后kubeadm init下载并安装集群控制组件。这可能需要一些时间。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171kubeadm --helpkubeadm init --help#k8s底层环境依赖于Docker#on mastersystemctl enable docker kubelet &amp;&amp; systemctl start dockerkubeadm initI0806 14:04:54.415853 2191 feature_gate.go:230] feature gates: &amp;&#123;map[]&#125;[init] using Kubernetes version: v1.11.1[preflight] running pre-flight checks [WARNING Service-Docker]: docker service is not enabled, please run &apos;systemctl enable docker.service&apos;I0806 14:04:54.433879 2191 kernel_validator.go:81] Validating kernel versionI0806 14:04:54.433934 2191 kernel_validator.go:96] Validating kernel config[preflight/images] Pulling images required for setting up a Kubernetes cluster[preflight/images] This might take a minute or two, depending on the speed of your internet connection[preflight/images] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;[preflight] Some fatal errors occurred: [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-apiserver-amd64:v1.11.1]: exit status 1 [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-controller-manager-amd64:v1.11.1]: exit status 1 [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-scheduler-amd64:v1.11.1]: exit status 1 [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-proxy-amd64:v1.11.1]: exit status 1 [ERROR ImagePull]: failed to pull image [k8s.gcr.io/pause-amd64:3.1]: exit status 1 [ERROR ImagePull]: failed to pull image [k8s.gcr.io/etcd-amd64:3.2.18]: exit status 1 [ERROR ImagePull]: failed to pull image [k8s.gcr.io/coredns:1.1.3]: exit status 1[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`#此处错误，由于镜像在Google，国内访问会超时。因此需要额外准备镜像。#需要做上面一步操作来拉取镜像#初始化#请确保资源满足条件，我就是由于VM内存为1GB而导致初始化失败，找了很久才找到这个错误kubeadm init --kubernetes-version=v1.11.1 --pod-network-cidr=10.244.0.0/16[init] using Kubernetes version: v1.11.1[preflight] running pre-flight checksI0807 14:47:10.658405 10612 kernel_validator.go:81] Validating kernel versionI0807 14:47:10.658484 10612 kernel_validator.go:96] Validating kernel config[preflight/images] Pulling images required for setting up a Kubernetes cluster[preflight/images] This might take a minute or two, depending on the speed of your internet connection[preflight/images] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;[kubelet] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;[kubelet] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;[preflight] Activating the kubelet service[certificates] Generated ca certificate and key.[certificates] Generated apiserver certificate and key.[certificates] apiserver serving cert is signed for DNS names [master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.31.49][certificates] Generated apiserver-kubelet-client certificate and key.[certificates] Generated sa key and public key.[certificates] Generated front-proxy-ca certificate and key.[certificates] Generated front-proxy-client certificate and key.[certificates] Generated etcd/ca certificate and key.[certificates] Generated etcd/server certificate and key.[certificates] etcd/server serving cert is signed for DNS names [master localhost] and IPs [127.0.0.1 ::1][certificates] Generated etcd/peer certificate and key.[certificates] etcd/peer serving cert is signed for DNS names [master localhost] and IPs [192.168.31.49 127.0.0.1 ::1][certificates] Generated etcd/healthcheck-client certificate and key.[certificates] Generated apiserver-etcd-client certificate and key.[certificates] valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/admin.conf&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/kubelet.conf&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/controller-manager.conf&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/scheduler.conf&quot;[controlplane] wrote Static Pod manifest for component kube-apiserver to &quot;/etc/kubernetes/manifests/kube-apiserver.yaml&quot;[controlplane] wrote Static Pod manifest for component kube-controller-manager to &quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&quot;[controlplane] wrote Static Pod manifest for component kube-scheduler to &quot;/etc/kubernetes/manifests/kube-scheduler.yaml&quot;[etcd] Wrote Static Pod manifest for a local etcd instance to &quot;/etc/kubernetes/manifests/etcd.yaml&quot;[init] waiting for the kubelet to boot up the control plane as Static Pods from directory &quot;/etc/kubernetes/manifests&quot; [init] this might take a minute or longer if the control plane images have to be pulled[apiclient] All control plane components are healthy after 42.001662 seconds[uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace[kubelet] Creating a ConfigMap &quot;kubelet-config-1.11&quot; in namespace kube-system with the configuration for the kubelets in the cluster[markmaster] Marking the node master as master by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;[markmaster] Marking the node master as master by adding the taints [node-role.kubernetes.io/master:NoSchedule][patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;master&quot; as an annotation[bootstraptoken] using token: uzdl9x.91uu2p155jczkgb3[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes master has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/You can now join any number of machines by running the following on each nodeas root: kubeadm join 192.168.31.49:6443 --token uzdl9x.91uu2p155jczkgb3 --discovery-token-ca-cert-hash sha256:bc5af0f4fbee0d0500c9d6782a279ee172ed45547a006136bfbad93d61ad39c7#root用户#一定要记得做此步骤，由于kubeadm设置的apiserver的监听端口为6443，而不是8080，所以执行会报错。export KUBECONFIG=/etc/kubernetes/admin.conf#之后，可将其写入/etc/profile#安装pod-network#你必须先安装pod network add-on，才能和pod相互通信。#必须在应用程序之前部署网络。#配置flannelkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.10.0/Documentation/kube-flannel.yml#如果无法访问，可将此文件下载到本地#kubectl apply -f /etc/kubernetes/kube-flannel.ymlclusterrole.rbac.authorization.k8s.io/flannel createdclusterrolebinding.rbac.authorization.k8s.io/flannel createdserviceaccount/flannel createdconfigmap/kube-flannel-cfg createddaemonset.extensions/kube-flannel-ds created#token用于master与node之间相互认证，它是加密的。#使用kubeadm token列出、创建和删除token#kubeadm token create#kubeadm token list#on node#kubeadm join#kubeadm join --token xxxxxxxxxxx host:portsystemctl enable kubelet docker &amp;&amp; systemctl start dockerkubeadm join 192.168.31.49:6443 --token uzdl9x.91uu2p155jczkgb3 --discovery-token-ca-cert-hash sha256:bc5af0f4fbee0d0500c9d6782a279ee172ed45547a006136bfbad93d61ad39c7#测试kubectl get nodeNAME STATUS ROLES AGE VERSIONmaster Ready master 48m v1.11.1node Ready &lt;none&gt; 15m v1.11.1#查看kubectl get pods --all-namespaces -o wideNAMESPACE NAME READY STATUS RESTARTS AGE IP NODEkube-system coredns-78fcdf6894-hn46d 1/1 Running 0 52m 10.244.0.3 masterkube-system coredns-78fcdf6894-wqxbx 1/1 Running 0 52m 10.244.0.2 masterkube-system etcd-master 1/1 Running 0 41m 192.168.31.49 masterkube-system kube-apiserver-master 1/1 Running 0 41m 192.168.31.49 masterkube-system kube-controller-manager-master 1/1 Running 0 41m 192.168.31.49 masterkube-system kube-flannel-ds-7gbvd 1/1 Running 0 41m 192.168.31.49 masterkube-system kube-flannel-ds-ktkxp 1/1 Running 0 19m 192.168.31.174 nodekube-system kube-proxy-pw7gz 1/1 Running 0 19m 192.168.31.174 nodekube-system kube-proxy-rhrks 1/1 Running 0 52m 192.168.31.49 masterkube-system kube-scheduler-master 1/1 Running 0 41m 192.168.31.49 master master isolation默认情况下，出于安全原因，你的集群不会在master上调度pod。如果你想在master上调度pod，对于单master的k8s集群，执行如下命令： 12#从拥有它的节点删除node-role.kubernetes.io/master污染kubectl taint nodes --all node-role.kubernetes.io/master- 加入节点要向集群添加新节点，请为每台计算机执行以下操作： 1234567#node#root/sudo#kubeadm init后执行下命令#kubeadm token listkubeadm join --token &lt;token&gt; &lt;master-ip&gt;:&lt;master-port&gt; --discovery-token-ca-cert-hash sha256:&lt;hash&gt; 从master之外控制集群(可选) 12scp root@&lt;master-ip&gt;:/etc/kubernetes/admin.conf .kubeclt --kubeconfig ./admin.conf get nodes 局限性此处创建的集群只有一个master，其上运行一个etcd数据库。这意味着如果master出现故障，你的集群可能会丢失数据。可考虑向k8s添加高可用支持。 使用kubeadm配置kubeletConfiguring each kubelet in your cluster using kubeadm kubeadm CLI工具的生命周期与Kubernetes Node Agent(kubelet)相分离，kubelet是运行在k8s集群master/node上的守护进程，它始终在后台运行。而kubeadm CLI工具由用户执行。由于kubelet是一个守护进程，它需要由init system或服务管理器来维护。Redhat7上使用systemd来进行管理。在集群设计的kubelet中，一些kubelet配置细节需相同；而其它方面则需要在每台机器的kubelet上单独配置。你可以手动管理kubelet配置，但kubeadm现在提供了一个MaterConfig API来集中管理kubelet配置。 注意，本节是利用kubeadm来配置kubelet，而不是手动配置kubelet。 kubelet配置模式 将集群级别配置传播到每个kubeletkubelet提供了一个版本化、结构化的API对象，可配置kubelet中大多数参数，并将此配置推送到集群中所有正在运行的kubelet。它被称为 the kubelet’s ComponentConfig(组件配置) 12345678910111213141516171819#为kubelet提供默认值。kubeadm initkubeadm join#修改服务默认子网kubeadm init --service-cidr 10.96.0.0/12#现在服务的VIP由此子网分配#还需要设置kubelet使用的DNS地址，每个kubelet必须相同--cluster-dns#componentConfigapiVersion: kubelet.config.k8s.io/v1beta1kind: KubeletConfigurationclusterDNS: - 10.96.0.10 提供特定实例的配置细节由于不同硬件、操作系统、网络…，一些主机需要特定的kubelet配置。由于我是使用systemd管理kubelet，所以可相应的修改对应的值。 1234567891011121314151617181920212223242526272829303132#DNS解析文件路径，如果路径错误，则在kubelet配置错误的节点上DNS将解析失败--resolve-conf#节点API对象，默认被设置为主机名.metadata.name#使用如下标志指定节点名来服务默认值--hostname-overide#目前，kubelet无法自动检查CRI runtime的cgroup driver#指定的驱动请与docker保持一致--cgroup-driver#根据集群使用的CRI runtime，可能需要为kubelet指定不同的标志#如，当使用Docker时，你需要指定如 --network-plugin=cni#但，当使用额外runtime，你需要指定 --container-runtime=remote, --container-runtime-path-endpoint=&lt;path&gt;#systemdcd /etc/systemd/system/kubelet.service.d/vim 10-kubeadm.conf#修改具体配置项#EnvFilevim /var/lib/kubelet/kubeadm-flags.envsystemctl daemon-reload &amp;&amp; systemctl restart kubelet 使用kubeadm配置kubeletkubeadm config API的MasterConfiguration类型，嵌入了kubelet&#39;s ComponentConfig到.kubeletConfiguration.baseConfig键下面。任何用户都可编写MasterConfiguration文件使用此配置键为集群中的所有kubelet设置基本配置。 使用kubeadm init的工作流程(workflow)当调用kubeadm init时，.kubeletConfiguration.baseConfig结构被整理到磁盘/var/lib/kubelet/config.yaml，并且上传到集群中的ConfigMap。ConfigMap名为kubelet-config-1.x，.x表示k8s的次要版本。kubelet配置文件同样被写入/etc/kubernetes/kubelet.conf。此配置文件指向允许kubelet与API server通信的客户端证书。 为了解决特定实例的配置细节的模式，kubeadm将环境文件写入/var/lib/kubelet/kubeadm-flags.env，它包含了在启动时传递给kubelet的许多标志。它还包含许多动态参数(如cgroup driver)。 12345678#标志栗子KUBELET_KUBEADM_ARGS=&quot;--flag1=value1, --flag2=value2 ...&quot;#在将这两个文件整理到磁盘后，kubeadm会尝试运行如下两个命令systemctl daemon-reload &amp;&amp; systemctl restart kubelet#在上面两个命令执行成功后，初始化会继续 使用kubeadm join的工作流程当运行kubeadm join命令时，kubeadm使用Bootstrap Token凭据执行TLS bootstrap，它下载kubelet-config-1.x ConfigMap并将其写入/var/lib/kubelet/config.yaml。动态环境文件/vat/lib/kubelet/kubeadm-flags.env的生成方式与kubeadm init完成相同。 12#同样，执行这两条命令systemctl daemon-reload &amp;&amp; systemctl restart kubelet 在kubelet载入新的配置文件后，kubeadm会写入/etc/kubernetes/bootstrap-kubelet.conf KubeConfig文件，该文件包含CA证书和Bootstrap Token。这些由kubelet用于执行TLS Bootstrap并获得唯一的凭证，该凭证存储在/etc/kubernetes/kubelet.conf中。写入文件后，kubelet完成执行TLS Bootstrap. systemd的kubelet管理文件此配置文件在RPM包安装的时候写入/etc/systemd/system/kubelet.service.d/10-kubeadm.conf，它由systemd使用。 123456789101112131415161718192021222324252627282930313233cat /etc/systemd/system/kubelet.service.d/10-kubeadm.conf# Note: This dropin only works with kubeadm and kubelet v1.11+[Service]Environment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf&quot;Environment=&quot;KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml&quot;# This is a file that &quot;kubeadm init&quot; and &quot;kubeadm join&quot; generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamicallyEnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env# This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use# the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file.EnvironmentFile=-/etc/sysconfig/kubeletExecStart=ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS#此文件指定kubeadm为kubelet管理的所有文件的默认位置#TLS Bootstrap/etc/kubernetes/bootstrap-kubelet.conf#unique kubelet identity/etc/kubernetes/kubelet.conf#kubelet&apos;s ComponentConfig/var/lib/kubelet/config.yaml#dynamic env file, KUBELET_KUBEADM_ARGS/var/lib/kubelt/kubeadm-flags.env#user-specified flag overrides, KUBELET_EXTRA_ARGS, 它具有最高优先级/etc/sysconfig/kubelet k8s 二进制文件和包内容 k8s release附带的DEB和RPM包： Package name Description kubeadm Installs the /usr/bin/kubeadm CLI tool and [The kubelet drop-in file(#the-kubelet-drop-in-file-for-systemd) for the kubelet. kubelet Installs the /usr/bin/kubelet binary. kubectl Installs the /usr/bin/kubectl binary. kubernetes-cni Installs the official CNI binaries into the /opt/cni/bin directory. cri-tools Installs the /usr/bin/crictl binary from https://github.com/kubernetes-incubator/cri-tools. 使用kubeadm自定义控制面板配置Customizing control plane configuration with kubeadm kubeadm配置公开以下字段，这些字段可覆盖传递给控制面板组件的默认标志： APIServerExtraArgs ControllerManagerExtraArgs SchedulerExtraArgs 1234567891011121314151617181920212223242526272829303132333435363738#apiserver#栗子apiVersion: kubeadm.k8s.io/v1alpha2kind: MasterConfigurationkubernetesVersion: v1.11.0metadata: name: 1.11-sampleapiServerExtraArgs: advertise-address: 192.168.0.103 anonymous-auth: false enable-admission-plugins: AlwaysPullImages,DefaultStorageClass audit-log-path: /home/johndoe/audit.log#controllermanager#栗子apiVersion: kubeadm.k8s.io/v1alpha2kind: MasterConfigurationkubernetesVersion: v1.11.0metadata: name: 1.11-samplecontrollerManagerExtraArgs: cluster-signing-key-file: /home/johndoe/keys/ca.key bind-address: 0.0.0.0 deployment-controller-sync-period: 50#scheduler#栗子apiVersion: kubeadm.k8s.io/v1alpha2kind: MasterConfigurationkubernetesVersion: v1.11.0metadata: name: 1.11-sampleschedulerExtraArgs: address: 0.0.0.0 config: /home/johndoe/schedconfig.yaml kubeconfig: /home/johndoe/kubeconfig.yaml 使用kubeadm创建高可用集群Creating Highly Available Clusters with kubeadm 使用kubeadm配置etcd高可用集群Set up a Highly Availabile etcd Cluster With kubeadm Troubleshooting kubeadm官方Troubleshooting: https://kubernetes.io/docs/setup/independent/troubleshooting-kubeadm/ 此外，在我启动kubelet之后，kubelet频繁出现一个错误信息： 12345678910111213141516#错误信息#journal -u kubeletkubelet[10720]: E0810 14:32:14.748713 10720 summary.go:102] Failed to get system container stats for &quot;/system.slice/kubelet.service&quot;: failed to get cgroup stats for &quot;/system.slice/kubelet.service&quot;: failed to get container info for &quot;/system.slice/kubelet.service&quot;: unknown container &quot;/system.slice/kubelet.service&quot;#解决方法vim /etc/sysconfig/kubelet#添加额外参数KUBELET_EXTRA_ARGS=&quot;--runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice&quot;#重启服务systemctl restart kubelet 使用软件包创建集群请定义相应的防火墙规则！ 我是CentOS7x86_64，所以只包含了RPM包。 自带的源安装的k8s可能版本比较老，如需较新版本，可以在网上搜索kubernetes rpm包进行手动安装。Rpmfind: https://rpmfind.net/ k8s集群组件 etcd flannel kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy kube-dns kubectl Master etcd flannel kube-apiserver kube-controller-manager kube-scheduler kubectl 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#默认镜像源安装yum install -y etcd flannel kubernetes-master kubernetes-client#配置kubernetes-master#cd /etc/kubernetes#apiserver config controller-manager scheduler#修改监听地址vim apiserverKUBE_API_ADDRESS="--insecure-bind-address=0.0.0.0"#生成环境一定要加上认证，我由于是测试，并未做认证#未添加认证，去掉 KUBE_ADMISSION_CONTROL中的SecurityContextDeny,ServiceAccount#Flag --admission-control has been deprecated, Use --enable-admission-plugins or --disable-admission-plugins instead.#KUBE_ADMISSION_CONTROL="--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota"KUBE_ADMISSION_CONTROL="--enable-admission-plugins=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota"#此处我修改了cidrKUBE_SERVICE_ADDRESSES="--service-cluster-ip-range=172.16.0.0/16"#配置etcd，可先使用默认值#后面可创建etcd-clustervim /etc/etcd/etcd.conf#修改监听地址ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:2379"#创建pod-network，cidr为kube-apiserver中的配置项#/atomic.io/network为flannel_etcd前缀,之后再启动flanneletcdctl mk /atomic.io/network/config '&#123;"Network":"172.16.0.0/16"&#125;'etcdctl lsetcdctl get '/atomic.io/network/config'#配置flannelvim /etc/sysconfig/flanneld#配置后启动systemctl start etcd flannel kube-apiserver kube-controller-manager kube-scheduler#查看[root@master kubernetes]# kubectl get allNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 172.16.0.1 &lt;none&gt; 443/TCP 4m#具体参数请根据实际情况来配置 Node flannel kubelet kube-porxy kubectl 123456789101112131415161718192021222324252627#epelyum install -y flannel kubernetes-node kubernetes-client#ls /etc/kubertes#config kubelet proxy#配置etcd的地址vim /etc/sysconfig/flanneldFLANNEL_ETCD_ENDPOINTS="http://master:2379vim /etc/kubernertes/configKUBE_MASTER="--master=http://master:8080"#修改kubelet地址KUBELET_ADDRESS="--address=node_addr"KUBELET_HOSTNAME="--hostname-override=node_addr"KUBELET_API_SERVER="--api-servers=http://master:8080"#配置后启动systemctl start flanneld kube-proxy kubelet#具体参数请根据实际情况来配置 验证集群 123#Master#kubectl安装如前kubectl get nodes 安装较新的k8s由于自带的源k8s版本比较低，可能我们需要较新的k8s版本。 12345678910111213141516171819202122#安装较新的Kubernetes浏览器访问 https://rpmfind.net/搜索：kubernetes-master(x86-64)kubernetes-node(x86-64)kubernetes-client(x86-64)选择合适的版本进行下载，三者版本请一致安装步骤和下面类似请注意，k8s组件安装好后，还需要安装额外组件。如docker, flannel, etcd...#masteryum install -y k8s-master k8s-client#nodeyum install -y k8s-node k8s-client k8s-release生成rpm包kubernetes-release: https://github.com/kubernetes/release 使用k8s-release手动生成rpm/dep包。由于yum源更不上k8s的更新速度，所以才需要我们手动制作。 需要安装并运行Docker，它要运行一个rpm-builder容器。 它生成一下rpm包： kubeadm kubelet kubectl 官方说明： 12345678910111213141516171819202122232425262728293031323334353637git clone https://github.com/kubernetes/release.gitcd ./release/rpm./docker-build.sh#此处如果连接google下载超时的话，可以在其它主机上下载，然后复制到此目录下#成功----------------------------------------RPMs written to:cri-tools-1.11.0-0.x86_64.rpm kubectl-1.11.0-0.x86_64.rpm kubernetes-cni-0.6.0-0.x86_64.rpmkubeadm-1.11.0-0.x86_64.rpm kubelet-1.11.0-0.x86_64.rpm repodataYum repodata written to:5e470d3c1c28cdd798237a48172b46f753655edee30988f4fde7000fde859d5a-primary.xml.gz9497c84e5650b15bf6edcffb68900b4f59f7271fa6318d3c0336386c99afd2d8-other.xml.gz94da9da6abd2dc8364ef51b4ca135b804deef0a37f1f13e4abeee455a8b0e897-primary.sqlite.bz2971e5af9d861f5ba85b12bad481749aa26546051090fa4e21c2393c21590dd5a-filelists.xml.gzb752df67070ff5552bd3137f00fb217578f1d810084a3e42579a53eee2a26085-other.sqlite.bz2f0ec7692c0654c1ec5ad9c8576ebe5b8f135c45b5d5242066df6e2d631a3ef6f-filelists.sqlite.bz2repomd.xml#会在./release/rpm/output/x86_64下生成特定版本的rpm包pwd#/root/release/rpm/output/x86_64ls -ltotal 47056-rw-r--r-- 1 root root 4383318 Aug 3 10:25 cri-tools-1.11.0-0.x86_64.rpm-rw-r--r-- 1 root root 7906382 Aug 3 10:25 kubeadm-1.11.0-0.x86_64.rpm-rw-r--r-- 1 root root 7859238 Aug 3 10:25 kubectl-1.11.0-0.x86_64.rpm-rw-r--r-- 1 root root 19012182 Aug 3 10:25 kubelet-1.11.0-0.x86_64.rpm-rw-r--r-- 1 root root 9008530 Aug 3 10:25 kubernetes-cni-0.6.0-0.x86_64.rpmdrwxr-xr-x 2 root root 4096 Aug 3 10:25 repodata 请注意，默认会自动编译所有平台。如果只需要x84_64，可以更改entry.sh文件，将其它平台去掉，以加快编译速度。 123456789vim ./release/rpm/entry.sh ARCHS=( amd64/x86_64 #arm/armhfp #arm64/aarch64 #ppc64le/ppc64le #s390x/s390x ) 后面还是需要使用kubeadm来进行引导！ 编译源码生成rpm包参考： How to build Kubernetes RPM: https://mritd.me/2017/07/12/how-to-build-kubernetes-rpm/ 由于墙的原因，使用kubeadm进行引导还是会timeout。使用自带的yum源或网上下载的k8s rpm可能也不是最新的版本。因此需要手动编译源码以生成rpm包。 生成如下rpm包： kubernetes-master kubernetes-client kubernetes-node k8s Dashboard说明: GitHub: https://github.com/kubernetes/dashboard image: kubernetes-dashboard-amd64:v1.8.3 FAQ: https://github.com/kubernetes/dashboard/wiki/FAQ Let’s Encrypt: https://letsencrypt.org/ Let’s Encrypt是一个免费，自动化和开放的证书颁发机构。 快速配置Quick setup 快速部署kubernetes-dashboard的方法请参考README。它适用于k8s新手并希望快速开始使用Dashboard的人。其它配置适用于有一定经验的用户，详情在以下章节。 k8s Dashboard是k8s集群的基于Web的通用UI。它允许用户管理运行在集群中的应用程序，并对应用程序进行故障排除，以及管理集群本身。 请注意，Dashboard使用了安全设置。这意味着，默认情况下它具有最小的权限集，并且只能通过https访问。建议在安装和执行Dashboard之前，先阅读Access Control指南。 1234567891011121314151617181920212223242526272829303132333435363738kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml#或#wget https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml#kubectl apply -f /path/kubernetes-dashboard.yamlsecret/kubernetes-dashboard-certs createdserviceaccount/kubernetes-dashboard createdrole.rbac.authorization.k8s.io/kubernetes-dashboard-minimal createdrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard-minimal createddeployment.apps/kubernetes-dashboard createdservice/kubernetes-dashboard created#查看kubectl get pods -n kube-system -o wide |grep dashboardkubernetes-dashboard-6948bdb78-rnnjp 1/1 Running 1 1d 10.244.1.2 node kubectl get service -n kube-system -o wide |grep dashboardkubernetes-dashboard ClusterIP 10.110.83.129 &lt;none&gt; 443/TCP 13m k8s-app=kubernetes-dashboard#要从本地访问Dashboard，必须为k8s集群创建安全通道kubectl applyStarting to serve on 127.0.0.1:8001#访问Dashboardhttp://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#http://localhost:8001/ui已弃用#&lt;h3&gt;Unauthorized&lt;/h3&gt;#会直接报403，还需要做前面所说的操作。#Heapster必须在集群中运行才能使metric, graphs可用#Heapster已被弃用，请考虑使用metrics-server和第三方metrics pipeline收集Prometheus格式的指标 安装Installation 官方版当从旧版Dashboard升级到 v1.7+，请确保删除kubernetes-dashboard服务账户的集群角色绑定，否则Dashboard将具有对集群的完全管理权限。 快速配置快速部署kubernetes-dashboard的方法请参考README。它适用于k8s新手并希望快速开始使用Dashboard的人。 推荐配置直接访问Dashboard(不是kubectl proxy)，应该使用有效的证书来建立安全的HTTPS连接。它们可由公共可信证书颁发机构(如Let’s Encrypt)生成，使用它们替代Dashboard自动生成的证书。 此配置要求证书存储在kube-system命名空间中名为kubernetes-dashboard-certs的证书中。假设你有存储在$HOME/certs目录下的dashboard.crt和dashboard.key文件。你应该使用这些文件创建secret。之后，便可以开始配置Dashboard。 123456789101112131415161718192021#查看kubectl get secret -n kube-system | grep dashboard#查看kubectl describe secret/kubernetes-dashboard-certs -n kube-systemName: kubernetes-dashboard-certsNamespace: kube-systemLabels: k8s-app=kubernetes-dashboardAnnotations:Type: OpaqueData====#创建kubectl create secret generic kubernetes-dashboard-certs --from-file=$HOME/certs -n kube-system#部署Dashboardkubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml 替代配置此配置并不安全。不使用证书，仅通过HTTP公开Dashboard。在此配置中，只能通过使用Authorization Header功能来确保访问控制。 12#配置kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/alternative/kubernetes-dashboard.yaml 开发版不建议在线上环境使用开发版，请使用稳定的正式版。 12#部署kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard-head.yaml 升级安装后，Deployment不会自动更新。为了更新它，你需要删除部署的pod并等待它重新创建。重新创建之后，它会使用最新的镜像image:latest. 12#删除podkubectl -n kube-system delete $(kubectl -n kube-system get pod -o name | grep dashboard) 证书管理Certificate management 本节简短介绍了如何获取可在Dashboard中启用HTTPS的证书。有两个步骤要做： 生成证书 证书认证机构(Certificate Authority) 自签名证书(Self-signed certificate) 将证书传递给Dashboard 按照前面的推荐配置方法 其它情况，你需要修改Dashboard的YAML部署文件，并将--tls-key-file, --tls-cert-file传递给Dashboard 公众信任的证书认证机构Public trusted Certificate Authority 有许多公共和免费的证书提供商可供选择。如前面提到的Let’s encrypt，具体操作查看此网站说明。 自签名证书Self-signed certificate 如果你打算自己生成证书，你需要像OpenSSL这样的库来帮助你。 生成私钥(private key)和证书签名请求(certificate signing request) 生成SSL证书 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#Generate private key and certificate signing request#创建SSL证书需要私钥和证书签名请求openssl genrsa -des3 -passout pass:x -out dashboard.pass.key 2048openssl rsa -passin pass:x -in dashboard.pass.key -out dashboard.keyrm dashboard.pass.key#需要填写一些信息#A challenge password []请直接按回车，不要填写内容openssl req -new -key dashboard.key -out dashboard.csrCountry Name (2 letter code) [XX]:CNState or Province Name (full name) []:SCLocality Name (eg, city) [Default City]:CDOrganization Name (eg, company) [Default Company Ltd]:StudentOrganizational Unit Name (eg, section) []:HTCommon Name (eg, your name or your server&apos;s hostname) []:Zhang21Email Address []:reds@zhang21.cnPlease enter the following &apos;extra&apos; attributesto be sent with your certificate requestA challenge password []:An optional company name []:#Generate SSL certificate#自签名SSL证书由 .key私钥 和 .csr生成openssl x509 -req -sha256 -days 1000 -in dashboard.csr -signkey dashboard.key -out dashboard.crtSignature oksubject=/C=CN/ST=SC/L=CD/O=Student/OU=HT/CN=Zhang21/emailAddress=reds@zhang21.cnGetting Private key#查看lsdashboard.crt dashboard.csr dashboard.key#将密钥和证书移动到需要的目录下mv ./dashboard.* /etc/kubernetes/pki/dashboard#接下来便可以创建secret了 访问DashboardAccessing Dashboard 在集群上安装Dashboard后，可通过几种不同的方式访问它。遇到什么问题，可查看FAQ。 1.6.x and below 1.7.x and above 1.7.x and aboveAccessing Dashboard 1.7.X and above 我的Dashboard v1.8.5. 前面的HTTP/HTTPs都不说了。但请注意，不要把Dashboard使用HTTP公开展示。 kubectl proxykubectl proxy在你的计算机和k8s APIserver之间创建代理服务器。默认情况下它只能在本地访问。 注意，不应该使用kubectl proxy命令公开Dashboard，因为它只允许HTTP连接。对于localhost和127.0.0.1以外的域，将无法登录。 首先让我们检查kubectl是否已正确配置并是否可访问集群: 123456789101112131415kubectl cluster-info#Kubernetes master is running at https://192.168.31.49:6443#KubeDNS is running at https://192.168.31.49:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy#启动代理服务器kubectl proxy#Starting to serve on 127.0.0.1:8001#之后你便可以从浏览器访问Dashboard#http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#但我访问还是403，应该还需要创建Service Token之类。 NodePort这种访问Dashboard的方式，建议用于单节点设置的开发环境中。请注意，此HTTPS方式需要安装前面生成的证书。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#编辑 kubernetes-dashboard服务kubectl -n kube-system edit service/kubernetes-dashboard# Please edit the object below. Lines beginning with a '#' will be ignored,# and an empty file will abort the edit. If an error occurs while saving this file will be# reopened with the relevant failures.#apiVersion: v1kind: Servicemetadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"v1","kind":"Service","metadata":&#123;"annotations":&#123;&#125;,"labels":&#123;"k8s-app":"kubernetes-dashboard"&#125;,"name":"kubernetes-dashboard","namespace":"kube-system"&#125;,"spec":&#123;"ports":[&#123;"port":443,"targetPort":8443&#125;],"selector":&#123;"k8s-app":"kubernetes-dashboard"&#125;&#125;&#125; creationTimestamp: 2018-08-09T01:14:01Z labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kube-system resourceVersion: "200618" selfLink: /api/v1/namespaces/kube-system/services/kubernetes-dashboard uid: 80091845-9b71-11e8-a08a-000c298ee39fspec: clusterIP: 10.110.83.129 ports: - port: 443 protocol: TCP targetPort: 8443 selector: k8s-app: kubernetes-dashboard sessionAffinity: None type: ClusterIPstatus: loadBalancer: &#123;&#125;#将 type: ClusterIP 修改为 type: NodePorttype: NodePort#直接保存退出(:wq)#service/kubernetes-dashboard edited#查看kubectl -n kube-system get service/kubernetes-dashboardNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes-dashboard NodePort 10.110.83.129 &lt;none&gt; 443:31965/TCP 6h#查看端口netstat -nltup | grep 31965tcp6 0 0 :::31965 :::* LISTEN 11280/kube-proxy#Dashboard展示在 31965(HTTPS) 端口上。#现在可在浏览器访问 &lt;master-ip&gt;:31965#可使用Nginx做前端代理#此处注意，需要将dashboard.crt证书安装到你的电脑上#不然浏览器会拒绝#如果你尝试在多节点集群上使用`NodePort`公开Dashboard，则必须找到运行Dashboard的节点的IP才能访问它。https://&lt;node-ip&gt;:&lt;nodeport&gt; 由图可看出，还需要配置权限才能够正常访问Dashboard！ API Server如果公开k8s API server并可以从外部访问，则你可直接访问url。Dashboard: https://master-ip:apiserver-port/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/ 注意，只有在浏览器中安装证书时，才能使用这用访问方式。 IngressDashboard可以使用 ingress 进行公开。详情: https://kubernetes.io/docs/concepts/services-networking/ingress/ Nginx反向代理直接使用NodePort方式访问比较麻烦，所以配置使用Nginx反向代理来访问。 Nginx配置文件: 1234567891011121314151617181920212223242526272829303132333435vim /etc/nginx/conf.d/k8sUI.confserver &#123; listen 443 ssl; server_name k8s.ui; ssl_certificate /etc/kubernetes/pki/dashboard/dashboard.crt; ssl_certificate_key /etc/kubernetes/pki/dashboard/dashboard.key; location / &#123; proxy_pass https://127.0.0.1:31965; proxy_read_timeout 60s; proxy_send_timeout 60s; proxy_connect_timeout 60s; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_404; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &apos;upgrade&apos;; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto https; proxy_buffer_size 64k; proxy_buffers 4 64k; proxy_busy_buffers_size 128k; proxy_temp_file_write_size 128k; &#125;&#125;nginx -tnginx -s reload 之后解析DNS，就可直接通过域名访问了。 访问控制Access Control 安装Dashboard后，我们便可以专注于为用户配置对集群资源的访问控制。从 v1.7 开始，Dashboard默认不再具有完全管理权限(admin privilige)，所有权限都被撤销，并且只授予了Dashboard工作所需的最小权限。所以下面的介绍都只针对于 v1.7+ 版本。如果Dashboard只能由受信任的人员访问，你可能希望授予他们完全管理权限，则所有人都具有完全管理的权限。请注意，其它应用程序不应直接访问Dashboard，因为它可能导致权限升级。确保集群内的流量仅限于命名空间，或者只是撤销集群内应用程序对Dashboard的访问权限。 可查看kubernetst-dashboard.yaml配置文件，里面有minimal的权限。 介绍k8s支持几种方法来认证(authenticating)和授权(authorizing)用户。授权由k8s API server处理。Dashboard仅充当代理并将所有认证信息传递给API server。在禁止访问的情况下，相应的警告信息会显示到Dashboard上。 默认Dashboard权限 v1.7 create and watch permissions for secrets in kube-system namespace required to create and watch for changes of kubernetes-dashboard-key-holder secret. get, update and delete permissions for secrets named kubernetes-dashboard-key-holder and kubernetes-dashboard-certs in kube-system namespace. proxy permission to heapster service in kube-system namespace required to allow getting metrics from heapster. v1.8 create permission for secrets in kube-system namespace required to create kubernetes-dashboard-key-holder secret. get, update and delete permissions for secrets named kubernetes-dashboard-key-holder and kubernetes-dashboard-certs in kube-system namespace. get and update permissions for config map named kubernetes-dashboard-settings in kube-system namespace. proxy permission to heapster service in kube-system namespace required to allow getting metrics from heapster. Authentication从v1.7版本开始，Dashboard支持的用户认证基于： Authorization: Bearer &lt;token&gt; Bearer Token Username/password Kubeconfig Login view要使其显示在Dashboard中，你需要启用HTTPS访问Dashboard。 使用跳过选项将使Dashboard使用Service Account权限。 Authorization header在通过HTTP访问Dashboard时，使用 authorization header 是使Dashboard充当用户的唯一方法。 要使Dashboard使用authorization header，你只需将每个请求中的Authorization: Bearer &lt;token&gt;传递给Dashboard。这可以通过在Dashboard前端配置反向代理来实现。代理将负责身份提供者的身份验证，并将请求头部中生成的token传递给Dashboard。注意，需要正确配置k8s API server才能接受这些token。 注意： 如果通过API server proxy访问Dashboard，则authorization header将不起作用。这是因为一旦请求到达API server，所有其它header都将被删除。 Bearer Token建议先熟悉k8s authentication doc，以了解如何获取可用于登录的token。例如，每个Service Account都有一个具有有效Bearer token，用于登录Dashboard。 推荐讲座，了解如何创建服务账户并对其进行授权： Service Account Tokens Role and ClusterRole Service Account Permissions 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#使用kubectl获取token#默认情况下，k8s创建了许多服务账号。所有都具有不同的访问权限kubectl -n kube-system get secretNAME TYPE DATA AGEattachdetach-controller-token-bszq5 kubernetes.io/service-account-token 3 2dbootstrap-signer-token-bqv44 kubernetes.io/service-account-token 3 2dbootstrap-token-uzdl9x bootstrap.kubernetes.io/token 7 2dcertificate-controller-token-rsftn kubernetes.io/service-account-token 3 2dclusterrole-aggregation-controller-token-x64f5 kubernetes.io/service-account-token 3 2dcoredns-token-dfmpb kubernetes.io/service-account-token 3 2dcronjob-controller-token-xwtkc kubernetes.io/service-account-token 3 2ddaemon-set-controller-token-vxzp4 kubernetes.io/service-account-token 3 2ddefault-token-5868t kubernetes.io/service-account-token 3 2ddeployment-controller-token-jc6bs kubernetes.io/service-account-token 3 2ddisruption-controller-token-znghk kubernetes.io/service-account-token 3 2dendpoint-controller-token-mnxfh kubernetes.io/service-account-token 3 2dexpand-controller-token-6srzj kubernetes.io/service-account-token 3 2dflannel-token-7548k kubernetes.io/service-account-token 3 2dgeneric-garbage-collector-token-22qd2 kubernetes.io/service-account-token 3 2dhorizontal-pod-autoscaler-token-zs8pj kubernetes.io/service-account-token 3 2djob-controller-token-zbfhd kubernetes.io/service-account-token 3 2dkube-proxy-token-xxp9h kubernetes.io/service-account-token 3 2dkubernetes-dashboard-certs Opaque 3 1hkubernetes-dashboard-key-holder Opaque 2 2dkubernetes-dashboard-token-sgq5t kubernetes.io/service-account-token 3 2dnamespace-controller-token-25n2k kubernetes.io/service-account-token 3 2dnode-controller-token-289v8 kubernetes.io/service-account-token 3 2dpersistent-volume-binder-token-x7t7x kubernetes.io/service-account-token 3 2dpod-garbage-collector-token-xxjqp kubernetes.io/service-account-token 3 2dpv-protection-controller-token-9s4x7 kubernetes.io/service-account-token 3 2dpvc-protection-controller-token-l7m7j kubernetes.io/service-account-token 3 2dreplicaset-controller-token-mszv9 kubernetes.io/service-account-token 3 2dreplication-controller-token-8gl9s kubernetes.io/service-account-token 3 2dresourcequota-controller-token-whljw kubernetes.io/service-account-token 3 2dservice-account-controller-token-h87wp kubernetes.io/service-account-token 3 2dservice-controller-token-qn5jz kubernetes.io/service-account-token 3 2dstatefulset-controller-token-zps2l kubernetes.io/service-account-token 3 2dtoken-cleaner-token-nccrw kubernetes.io/service-account-token 3 2dttl-controller-token-dmmb9 kubernetes.io/service-account-token 3 2dkubectl -n kube-system describe secret/replicaset-controller-token-mszv9Name: replicaset-controller-token-mszv9Namespace: kube-systemLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name=replicaset-controller kubernetes.io/service-account.uid=d18a5f8f-9a0d-11e8-a08a-000c298ee39fType: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 11 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJyZXBsaWNhc2V0LWNvbnRyb2xsZXItdG9rZW4tbXN6djkiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoicmVwbGljYXNldC1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZDE4YTVmOGYtOWEwZC0xMWU4LWEwOGEtMDAwYzI5OGVlMzlmIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOnJlcGxpY2FzZXQtY29udHJvbGxlciJ9.O6hXQwsXdSXREsaao_V7pmeQkfWGEd4QLDxczxNZVcrT2yN9F1KFJ9IklYVlGSTo1cKA4OxkYqjKWzWPBEn6wVLhVbf6_WqTrFi4qEtj_nmhXwqcwkpioJzyXu7x7wljpH-H32bEaLW1l-y5kQBUztF9fAHZZyv0f9vaRK4u4zVzuq4JzauLB9aVBrgt6rSaOENdr8OGm1yjM_--gQtc1qoF8mLo3RK6qLpFjT70EZKgyys_GXpFrrnhG5maUmlFqCPZ6P0cl8d6SuDfkQIlFxNHxtJmOPSCIE6wjgkOncRtgWHRRVsRPnhDGOp0kbmdLTfpOx2zZEiCD5btXL0OkA#我们可以使用显示的token登录Dashboard Basic默认情况下，禁用基本身份认证，也就是用户密码认证。原因是需要使用授权模式RBAC和--basic-auth-file标志配置k8s API server。没有的话，API server会自动回退到匿名用户(anonymous user)，并且无法检查提供的凭据是否有效。 修改--authentication-mode=basic标志在Dashboard中启用基本身份认证，默认值为--authentication-mode=token。 kubeconfig这种登录方法是为了方便起见而提供的。kubeconfig file仅支持--authentication-mode标志指定认证选项。如果它配置为其它方式，Dashboard中将显示错误消息。 Admin privileges注意： 在操作之前，请确保你知道自己在做什么。向Dashboard的服务账号赋予管理权限可能会存在安全风险。 你可以通过创建ClusterRoleBinding来授权Dashboard的服务账号完全的管理权限。 123456789101112131415161718192021222324252627282930313233343536#栗子dashboard-admin.yaml#官方文档版apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: kubernetes-dashboard labels: k8s-app: kubernetes-dashboardroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: kubernetes-dashboard namespace: kube-system#开发版apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: kubernetes-dashboard-head labels: k8s-app: kubernetes-dashboard-headroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: kubernetes-dashboard-head namespace: kube-system 创建示例用户Creating sample user 在本节中，我们将了解如何使用k8s Service Account机制创建新用户，授权用户管理权限并使用与此用户关联的Bearer Token进行登录。关于grant/deny权限，请查看文档authentication和authorization以了解详情。 创建xxx.yaml文件，并使用kubectl create -f xxx.yaml命令创建它们。 创建 Service Account在kube-system命名空间中创建名为admin-user的服务账户: 12345apiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kube-system 12345678#创建kubectl create -f /etc/kubernetes/auth/admin-user_SA.yaml#serviceaccount/admin-user created#查看kubectl -n kube-system get secret | grep admin-user#admin-user-token-qj8hj kubernetes.io/service-account-token 3 56s 创建 ClusterRoleBinding在大多数情况下，在使用kops, kubeadm等管理配置集群后，Role都已存在于集群中。我们可使用它为ServiceAccount仅创建RoleBinding。 注意: ClusterRoleBinding的apiVersion资源可能不同于k8s version。从v1.8开始，它被提升为rbac.authorization.k8s.io/v1。 123456789101112apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kube-system 123#创建kubectl create -f /etc/kubernetes/Auth/cluster-admin_CRB.yaml #clusterrolebinding.rbac.authorization.k8s.io/admin-user created Bearer Token现在我们需要去找到用于登录的Token。 123456789101112131415kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk &apos;&#123;print $1&#125;&apos;)Name: admin-user-token-qj8hjNamespace: kube-systemLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name=admin-user kubernetes.io/service-account.uid=58d39b31-9c40-11e8-a08a-000c298ee39fType: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 11 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLXFqOGhqIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI1OGQzOWIzMS05YzQwLTExZTgtYTA4YS0wMDBjMjk4ZWUzOWYiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.4hCqFj7R7CwAewnFxsy5QC91v6288T7aOCZXae7AbqXECiFb2yB5x7VQs0GjnUj8jbSZamBpI_D6D7p8PoRUmPZg2NOF46TEztsR9wcsEywUr6EHdXMGy6HUtvedy45K1j9h8oFp9nAqvxa6M7hrfV_yy-XlJdqTo7J06VlT_czpWNScCkjejIOlZXFvYL5f5ha0V4L5XCdlFkf7DYbsNV6odquIKavg270g4nAr1ZAJ14SjeFdfRVvimS4N-W7pb9vmOeZBnAmGuotKoqU1OlzZrMfpsPGIXy5GW3zD8PvsbGU9Xn6lyPHH08X0kXCUACQHx4UiaMFzlnhaC2XIMQ 现在复制Token来登录. HeapsterGitHub: https://github.com/kubernetes/heapster 注意: Heapster已被启用，考虑使用metric-server和第三方metric pipeline来收集Prometheus格式的指标。 Heapster 启用时间轴 Kubernetes Release Action Policy/Support Kubernetes 1.11 Initial Deprecation No new features or sinks are added. Bugfixes may be made. Kubernetes 1.12 Setup Removal The optional to install Heapster via the Kubernetes setup script is removed. Kubernetes 1.13 Removal No new bugfixes will be made. Move to kubernetes-retired organization. metric-serverGitHub: https://github.com/kubernetes-incubator/metrics-server 具体详情可参考README。 12345678910111213141516171819202122232425262728293031323334353637383940414243#下载到本地git clone https://github.com/kubernetes-incubator/metrics-server.git#移动到管理目录mv metrics-server/ /etc/kubernetes/#k8s v1.8+ls /etc/kubernetes/metrics-server/deploy/v1.8+/auth-delegator.yaml auth-reader.yaml metrics-apiservice.yaml metrics-server-deployment.yaml metrics-server-service.yaml resource-reader.yaml#注意metrics-server-deployment.yaml文件，需要一个镜像，请准备#gcr.io/google_containers/metrics-server-amd64:v0.2.1docker pull zhang21/metrics-server-amd64:v0.2.1docker tag zhang21/metrics-server-amd64:v0.2.1 gcr.io/google_containers/metrics-server-amd64:v0.2.1#创建#注意，在顶层进行创建cd /etc/kubernetes/metrics-serverkubectl create -f deploy/v1.8+/clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator createdrolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader createdapiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io createdserviceaccount/metrics-server createddeployment.extensions/metrics-server createdservice/metrics-server createdclusterrole.rbac.authorization.k8s.io/system:metrics-server createdclusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created#查看kubectl -n kube-system get deploymentNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEcoredns 2 2 2 2 2dkubernetes-dashboard 1 1 1 1 19hmetrics-server 1 1 1 0 39s pause容器参考: 《Kubernetes之“暂停”容器》: http://dockone.io/article/2785 《Pause容器》: https://jimmysong.io/kubernetes-handbook/concepts/pause-container.html GitHub: https://github.com/kubernetes/kubernetes/tree/master/build/pause Pause容器，又叫Infra容器。它不是pod，而是一个容器。 123456789101112131415161718192021docker ps | grep pause35c9aaa68a06 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_coredns-78fcdf6894-hn46d_kube-system_daab8e60-9a0d-11e8-a08a-000c298ee39f_0d22a1baac736 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_coredns-78fcdf6894-wqxbx_kube-system_daac5838-9a0d-11e8-a08a-000c298ee39f_04d0cdc392629 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_kube-flannel-ds-7gbvd_kube-system_59129dff-9a0f-11e8-a08a-000c298ee39f_04f28747a2044 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_kube-proxy-rhrks_kube-system_da990e28-9a0d-11e8-a08a-000c298ee39f_0f2bd7bd47eb4 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_kube-scheduler-master_kube-system_537879acc30dd5eff5497cb2720a6d64_0d732ffba5530 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_kube-controller-manager-master_kube-system_01c36146e2c80849d7b6993e68aa5e67_0cd7636bac6df k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_kube-apiserver-master_kube-system_1bd24cc043a06bf7e71b96167946c220_0d4adb3504543 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 18 hours ago Up 18 hours k8s_POD_etcd-master_kube-system_2cc1c8a24b68ab9b46bca47e153e74c6_0#或者是这样#registry.access.redhat.com/rhel7/pod-infrastructure:latest#rpm包安装kubelet的默认配置KUBELET_POD_INFRA_CONTAINER=&quot;--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest&quot;#kubeadm安装kubelet的默认配置KUBELET_POD_INFRA_CONTAINER=--pod-infra-container-image=k8s.gcr.io/pause:3.1 pause容器的作用k8s中的pause容器主要为每个业务提供以下功能： 在pod中担任Linux命名空间共享的基础 启用pid命名空间，开启init进程 使用pause容器和共享命名空间创建pod示例： 123456789101112131415161718192021222324252627#启动pause，以便可以将容器添加到pod中docker run -d --name pause k8s.gcr.io/pause-amd64:3.1#nginxcat &lt;&lt;EOF &gt;&gt; /tmp/nginx.conf&gt; error_log stderr;&gt; events &#123; worker_connections 1024; &#125;&gt; http &#123;&gt; access_log /dev/stdout combined;&gt; server &#123;&gt; listen 80 default_server;&gt; server_name example.com www.example.com;&gt; location / &#123;&gt; proxy_pass http://127.0.0.1:2368;&gt; &#125;&gt; &#125;&gt; &#125;&gt; EOF#指定网络和命名空间docker run -d --name nginx -v /tmp/nginx.conf:/etc/nginc/nginx.conf -p 8880:80 --net=container:pause --ipc=container:pause --pid=container:pause docker.io/nginx:lates#ghost博客docker run -d --name ghost --net=container:pause --ipc=container:pause --pid=container:pause docker.io/ghost:latest 在这两种情况下，我们将pasue容器指定为我们要加入的命名空间容器。这将有效地创建我们的pod。 访问可以看到ghost通过nginx代理运行。因为网络命名空间在pause, nginx, ghost容器之间共享。而这两个容器的init进程都是pause这个容器。 123456789101112131415161718192021222324252627docker logs -f nginx192.168.31.28 - - [08/Aug/2018:02:00:49 +0000] &quot;GET / HTTP/1.1&quot; 200 3195 &quot;-&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36&quot;192.168.31.28 - - [08/Aug/2018:02:00:49 +0000] &quot;GET /assets/built/screen.css?v=0bf822a279 HTTP/1.1&quot; 200 7360 &quot;http://node:8880/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36&quot;......docker logs -f ghost[2018-08-08 02:00:30] INFO Creating table: posts[2018-08-08 02:00:30] INFO Creating table: users[2018-08-08 02:00:30] INFO Creating table: posts_authors......#查看initdocker exec -it ghost /bin/bashroot@f12a374141a7:/var/lib/ghost# ps -efUID PID PPID C STIME TTY TIME CMDroot 1 0 0 01:55 ? 00:00:00 /pauseroot 5 0 0 01:58 ? 00:00:00 nginx: master process nginx -g daemon off;systemd+ 9 5 0 01:58 ? 00:00:00 nginx: worker processnode 10 0 0 02:00 ? 00:00:03 node current/index.jsroot 127 0 0 02:37 ? 00:00:00 /bin/bashroot 131 127 0 02:37 ? 00:00:00 ps -ef 构建大型集群Building Large Clusters 在k8s v1.11，k8s支持做多5 000个节点的集群。更具体地说，支持满足以下条件的配置： 不超过5 000个node 总量不超过150 000个pod 总量不超过300 000个container 每个节点不超过100个pod 使用salt配置k8sConfiguring Kubernetes with Salt k8s集群能够使用salt进行配置。 验证节点配置Validate Node Setup 节点一致性测试Node Conformance Test 节点一致性测试是一种容器化测试框架，为节点提供系统验证和功能测试。该测试验证节点是够满足k8s的最低要求，通过测试的节点有资格加入k8s集群。 局限Limitations 在k8s v1.5中，节点一致性测试具有如下限制： 节点一致性测试仅支持Docker作为容器runtime 节点先决条件Node Prerequisite 要运行节点一致性测试，节点必须满足与标准k8s节点相同的先决条件。该节点至少要安装一下守护进程: Container Runtime(Docker) Kubelet 运行节点一致性测试Running Node Conformance Test 执行如下步骤： 12345678910111213141516171. 将kubelet执行localhost，测试框架启动一个master来测试kubelet#可使用 --pod-cidr, --cloud-provide标志--api-servers=&quot;http://localhost:8080&quot;2. 运行节点一致性测试# $CONFIG_DIR is the pod manifest path of your Kubelet.# $LOG_DIR is the test output path.sudo docker run -it --rm --privileged --net=host \ -v /:/rootfs -v $CONFIG_DIR:$CONFIG_DIR -v $LOG_DIR:/var/result \ k8s.gcr.io/node-test:0.2#一致性测试的架构支持node-test-adm64node-test-armnode-test-arm64 运行选定测试Running Selected Test 123456789101112#运行指定测试，使用你想要运行的测试的正则表达式 覆盖环境变量FOCUSsudo docker run -it --rm --privileged --net=host \ -v /:/rootfs:ro -v $CONFIG_DIR:$CONFIG_DIR -v $LOG_DIR:/var/result \ -e FOCUS=MirrorPod \ # Only run MirrorPod test k8s.gcr.io/node-test:0.2#跳过指定测试，覆盖环境变量SKIPsudo docker run -it --rm --privileged --net=host \ -v /:/rootfs:ro -v $CONFIG_DIR:$CONFIG_DIR -v $LOG_DIR:/var/result \ -e SKIP=MirrorPod \ # Run all conformance tests but skip MirrorPod test k8s.gcr.io/node-test:0.2 强烈建议仅运行一致性测试，因为它需要更复杂的配置来运行不一致性测试。 概念concepts 概念部分可帮助你了解k8s系统的各个部分以及k8s用于表示集群的抽象，并帮助你更深入地了解k8s的工作原理。 标准词汇Standardized Glossary Annotation用于将任意非标识元数据(metadata)附加到随想的键值对。 Application Architect负责程序高级设计的人员。 Application Developer编写在Kubernetes集群中运行的应用程序的人。 Approver可以审批Kubernetes代码贡献的人。 CLA(Contributor License Agreement)贡献者向开源项目授予其贡献许可的条款。 Certificate一个加密安全文件，用于验证对Kubernetes集群的访问的加密。 Cloud Controller Manager Cloud Provider Cluster一组称为节点(node)的机器，运行着由Kubernetes管理的容器化的应用程序。 Cluster Architect设计一个或多个Kubernetes集群的基础架构的人。 Cluster Operator配置，控制和监控集群的人。 Code Contributor为Kubernetes开源代码库开发和共享代码的人。 ConfigMap一个API对象，用于在键值对中存储非机密的数据。可认为是环境变量，命令行参数… Container一个轻量化和可移植的包含应用程序及其依赖项的可执行的镜像。 Container Environment Variables容器环境变量是name/value对，为Pod中运行的容器提供有用的信息。 Contributor捐赠代码，文档或时间来帮助Kubernetes项目或社区的人。 Controller一个控制循环，通过APIServer监视集群的共享状态，并进行修改，尝试将当前状态移至理想(desired)状态。 CronJob管理一个定期运行的工作。 CustomResourceDefinition自定义码，用于定义要添加到Kubernetes APIServer的资源，而无需构建完整的自定义服务器。 DaemonSet确保Pod的副本在集群的一组节点上运行。 Deployment一个管理副本应用程序的API对象 Dynamic Volume Provision允许用户请求自动创建存储卷。 etcd一致且高度可用的键值存储，用作Kubernetes所有集群数据的备份存储。 Helm Chart可以使用Helm工具管理的预配置Kubernetes资源包。 Horizontal Pod Autoscaler一个API资源，可根据目标CPU利用率或自定义的指标自动调整Pod副本数。 Image一个容器的存储实例，其中包含运行一个应用程序需要的一组软件。 Ingress一个管理集群中服务的外部访问的API对象，通常是HTTP。 Init Container一个或多个初始化容器，必须在任意应用程序容器运行之前完成运行。 Istio一个开放平台，提供统一的方式来继承微服务，管理流量，实施策略和聚合遥测数据。 Job运行完成的 有限/一批 任务。 Kops一个命令行工具，可帮助你创建，销毁，升级和维护生产级、高可用性的Kubernetes集群。(仅支持AWS) Kubeadm一个快速安装Kubernetes和设置安全集群的工具。 Kubectl用于与Kubernetes APIServer通信的命令行工具。 Kubelet在集群的每个节点上运行的Agent。它确保容器运行在Pod中。 Kubernetes API通过RESTful接口提供Kubernetes功能的应用程序，用于存储集群的状态。 Label标记与用户有意义且相关的标识属性的对象。 Minikube一个在本地运行Kubernetes的工具。 Name客户端提供的字符串，用于引用资源URL中的对象。如/api/vi/pods/some-name. Namespace一个抽象概念，用于Kubernetes支持同一物理集群上的多个虚拟集群。 Network Policy允许Pod组如何与其它网络端点进行通信的规范。 Node节点是Kubernetes中的一个工作机器。 Persistent Volume一个表示集群中一块存储的API对象。 Persistent Volume Claim声明定义在一个PersistentVolume中的存储资源，以便可以作为一个volume挂载到容器中。 Pod最小和最简单的Kubernetes对象。Pod表示集群上一组正在运行的容器。 Pod Security Policy启用Pod创建和更新的细粒度授权。 PodPreset一个API对象，在创建时将信息(secrets, volume, env var…)注入到Pod中。 RBAC（role-basesd access control)管理授权决策，允许管理员通过Kubernetes API动态配置访问策略。 ReplicaSet副本集是下一代副本控制器。 Resource Quotas提供限制每个命名空间的聚合资源消耗的约束。 Reviemer在项目的某些部分检查代码质量和正确性的人。 Secret存储敏感信息，如密码，token… Security ContextsecurityContext字段定义Pod或容器的权限和访问控制设置，包括运行时UID和GID。 Selector允许用户根据label过滤资源列表。 Service一个API对象，描述如何访问应用程序，并可以描述端口和负载均衡器。 Service Account为运行在Pod中的进程提供一个标识。 Service Catalog一个扩展API，允许Kubernetes集群中运行的应用程序能够轻松使用外部托管软件，如数据库存储服务。 StatefulSet管理一组Pods的部署和伸缩，并提供有关这些Pod的排序和唯一性的保证。 UIDKubernetes系统生成的一个字符串，用于唯一标识对象。 Volume一个包含数据的目录，可供Pod中的容器访问。 Volume Plugin卷插件可在Pod中集成存储。 kube-apiserver一个Master组件，用于暴露Kubernetes API。它是Kubernetes控制面的前端。 kube-controller-manager一个Master组件，用于运行控制器。 kube-proxy运行在集群中的每一个节点上的网络代理。 kube-schedulerMaster上的组件，用于监测未创建节点新创建的Pod，并选择一个节点供其运行。 概述K8s是什么Kubernetes（常简称为K8s），Kubernetes的名字来自希腊语，意思是“舵手”或“领航员”。K8s是将8个字母“ubernete”替换为“8”的缩写。它用于自动部署、扩展和管理容器化（containerized）应用程序的开源系统。它旨在提供“跨主机集群的自动部署、扩展以及运行应用程序容器的平台”。它支持一系列容器工具, 包括Docker等。 通过Kubernetes你可以： 快速部署应用 快速扩展应用 无缝对接新的应用功能 优化硬件资源，降低成本 Kubernetes特点： 可移植(portable) 可扩展( extensible) 自动化(automatic) 容器优点： 快速创建/部署应用 持续开发、集成和部署(CI/CD) 开发和运维相分离 开发、测试、生产环境的一致性 可移植性 松耦合、分布式、弹性伸缩、微服务化 资源隔离 资源利用 Kubernetes能做什么Kubernetes还允许开发人员从物理和虚拟机脱离，从以主机为中心的基础架构转移到以容器为中心的基础架构。这样可以使用容器固有的全部优点。 Kubernetes满足的应用程序常见需求： Pod 挂载外部存储 分布式secrets 应用健康检查 副本应用实例 横向自动伸缩 服务发现 负载均衡 滚动更新 资源监控 日志采集和存储 自检和调试 认证和授权 这提供了平台即服务(PAAS)的简单性以及基础架构即服务(IAAS)的灵活性，并促进基础设施供应商的可移植性。 Kubernetes不是什么Kubernetes 不是一个传统意义上，包罗万象的PaaS(平台即服务)系统。 不限制支持的应用程序类型，不限制应用程序框架 不提供中间件(如消息中间件)、数据处理框架(如spark)，数据库或集群存储系统 不提供点击即部署的服务市场 不部署代码不构建应用 允许用户选择日志、监控和报警 不提供或授权一个全面的应用程序配置系统/语言 不提供任何机器配置、维护、管理或自我修复系统 你可以自定义你的PAAS，与你选择的CI系统集成，或与Kubernetes一起使用，将你的容器镜像部署到Kubernetes。由于Kubernetes在应用级别而不仅仅在硬件级别上运行，因此它提供了PAAS产品通用的一些功能。如部署、扩展、负载均衡、日志记录、监控等。 k8s组件Kubernetes Components Kubernetes 所需的各种二进制组件, 用于提供齐全的功能。 Master组件Master组件提供的集群控制面(control plane)。Master作出集群的全局决策，以及检测和相应集群事件。Master组件可在集群中任何节点上运行。然而，为了简单，通常在一台机器上启动所有Master组件，并且不会在此机器上运行用户容器。可使用多个机器的设置来构建高可用性能集群。 kube-apiserverkube-apiserver对外展示Kubernetes API。它是Kubernetes前端控制层，任何的资源请求/调用都是通过它提供的接口进行。它被设计为水平扩展，即通过部署更多实例来扩展。 etcd持久化和高可用的K/V存储，用于Kubernetes所有集群数据的后端存储。请始终为k8s集群的etcd数据做备份。 kube-controller-managerMaster上运行的控制器组件，它们是集群中处理常规任务的后台线程。逻辑上讲，每个控制器都是一个单独的进程，但为了降低复杂性，它们都被编译为单个二进制文件并在单个进程中运行。 这些控制器包含： 节点控制器(Node Controller): 负责在节点故障时通知和响应 副本控制器(Replication Controller): 负责维护系统中每个副本控制器对象正确的pod数 端点控制器(Endpoints Controller): 填入端点对象 服务账户(service accoute)和令牌控制器(token controller): 为新的命名空间(namespace)创建默认账户和API访问令牌 cloud-controller-manager云控制器管理器用于与底层云提供商进行交互。它仅运行云提供商特定的控制器循环。你必须在kube-controller-manager中禁用这些controller loops，将--cloud-provider标志设置为external来禁用。 以下控制器具有云提供商依赖关系： 节点控制器: 用于检查云服务商提供的程序 路由控制器: 用于在底层云基础架构中设置路由 服务控制器: 用于创建，更新，删除云服务商提供的负载均衡器 数据卷控制器: 用于创建，附件和挂载卷，以及与云服务商提供的卷进行交互 kube-scheduler监视还未分配节点的新创建的pod，选择一个节点供pod运行。调度决策所考虑的因素包括： 个体/集体的资源需求，硬件/软件/策略的约束，亲和力/反亲和性的规范，工作负载和期限。 Node组件节点(node)组件运行在每个节点，维护运行的pod并提供Kubernetes运行时环境。 kubelet在集群中每个节点上运行的Agent，它确保container运行在pod中。kubelet采用通过各种机制提供的一组PodSpecs，并确保这些PodSpecs中描述的容器运行且健康。kubelet不管理不是由k8s创建的容器。 提供如下功能： 挂载pod所需的数据卷 下载pod的secrets pod中运行docker容器 周期性的容器健康检查 如有需要，通过创建mirror pod将pod的状态报告回系统的其余部分 将节点的状态报告回系统的其余部分 kube-proxy通过维护主机上的网络规则并执行连接转发，来实现Kubernetes服务抽象。 container runtime负责运行容器的软件。k8s支持多种runtimes： docker, rkt, runc… docker, rkt, supervisord, fluentd… Addons扩展是实现集群功能的Pod和Service。pod可由Deployment， Replication等管理。命名空间扩展对象在kube-system命名空间中创建。 DNS虽然其它插件并非严格要求，但所有k8s集群都应具有集群DNS，因为许多示例都依赖于它。集群DNS是一个DNS服务器，除了你环境中的DNS服务器，它还为k8s服务提供DNS记录。由k8s启动的容器会在DNS搜索中自动包含此DNS服务器。 Web UI(dashboard)仪表盘。 container resource monitoring记录有关中央数据库中容器的通用时间序列度量标准，并提供用于浏览该数据的UI。 cluster-level logging集群级别的日志记录机制，复制将容器日志保存到具有search/browse界面的中央日志存储。 k8s APIk8s API还可作为系统声明性配置架构的基础。kubectl命令行工具可用于创建，更新，删除和获取API对象。k8s还根据API资源存储其序列化状态(etcd中)。k8s自身被分解为多个组件，这些组件通过其API进行交互。 OpenAPI和Swagger定义完整的API详细信息记录在Swagger v1.2和OpenAPI。k8s apiserver(master)公开了一个API，可用于检索位于/swaggerapi的Swagger v1.2 k8s API.从k8s 1.10开始，OpenAPI规范在单个/openapi/v2端点中提供。单独格式的端点(如swagger.json...)已被弃用，后面会被移除。 通过设置HTTP header指定请求格式: Header Possible Values Accept application/json, application/com.github.proto-openapi.spec.v2@v1.0+protobuf (the default content-type is application/json for / or not passing this header) Accept-Encoding gzip (not passing this header is acceptable) 栗子： Before 1.10 Starting with Kubernetes 1.10 GET /swagger.json GET /openapi/v2 Accept: application/json GET /swagger-2.0.0.pb-v1 GET /openapi/v2 Accept: application/com.github.proto-openapi.spec.v2@v1.0+protobuf GET /swagger-2.0.0.pb-v1.gz GET /openapi/v2 Accept: application/com.github.proto-openapi.spec.v2@v1.0+protobuf Accept-Encoding: gzip 123456789101112131415161718192021222324252627282930313233343536373839#查看curl localhost:8080&#123; &quot;paths&quot;: [ &quot;/api&quot;, &quot;/api/v1&quot;, &quot;/apis&quot;, &quot;/apis/apps&quot;, &quot;/apis/apps/v1beta1&quot;, &quot;/apis/authentication.k8s.io&quot;, &quot;/apis/authentication.k8s.io/v1beta1&quot;, &quot;/apis/authorization.k8s.io&quot;, &quot;/apis/authorization.k8s.io/v1beta1&quot;, &quot;/apis/autoscaling&quot;, &quot;/apis/autoscaling/v1&quot;, &quot;/apis/batch&quot;, &quot;/apis/batch/v1&quot;, &quot;/apis/batch/v2alpha1&quot;, &quot;/apis/certificates.k8s.io&quot;, &quot;/apis/certificates.k8s.io/v1alpha1&quot;, &quot;/apis/extensions&quot;, &quot;/apis/extensions/v1beta1&quot;, &quot;/apis/policy&quot;, &quot;/apis/policy/v1beta1&quot;, &quot;/apis/rbac.authorization.k8s.io&quot;, &quot;/apis/rbac.authorization.k8s.io/v1alpha1&quot;, &quot;/apis/storage.k8s.io&quot;, &quot;/apis/storage.k8s.io/v1beta1&quot;, &quot;/healthz&quot;, &quot;/healthz/ping&quot;, &quot;/healthz/poststarthook/bootstrap-controller&quot;, &quot;/healthz/poststarthook/extensions/third-party-resources&quot;, &quot;/healthz/poststarthook/rbac/bootstrap-roles&quot;, &quot;/logs&quot;, &quot;/metrics&quot;, &quot;/swaggerapi/&quot;, &quot;/ui/&quot;, &quot;/version&quot; ] API 版本为了更容易消除字段或重构资源表示，k8s支持多个API版本，每个版本位于不同的API路径。如/api/vi或/apis/extensions/v1beta1. 我们选择在API级别，而不是资源级别/字段级别进行版本控制，以确保API提供干净、一致的系统资源和行为视图，并允许控制对生命末端和实验性API的访问。json和protobuf序列化模式都遵循相同的模式更改指南。请注意，API版本和软件版本仅间接相关。 不同的API版本意味着不同级别的稳定性和支持： Alpha level 版本名包含alpha(如 v1aplha1) 启用该功能可能会暴露bug，默认禁用 可随时删除对功能的支持，恕不另行通知 可能会在以后软件版本中以不兼容的方式更改，恕不另行通知 由于错误风险和缺乏长期支持，建议仅在短期测试集群中使用 Beta level 版本名包含beta(如 v2beta3) 代码经过充分测试，启用该功能被认为是安全的。默认启用 虽然细节会有所变化，但不会删除对整体功能的支持 建议仅用于非关键业务，因为后续版本可能会发生不兼容的更改 请尝试我们测试版功能并提供反馈 Stable level 版本名是vx，x为整数 许多后续版本的软件将出现稳定版的功能 API groups为了更容易扩展k8s API，我们实施了API Groups，它在REST path和序列化对象的apiVersion字段中指定。 目前在使用的几个API groups: 核心组(core group)，又称遗留组，位于REST path的/api/v1，并使用apiVersion: v1 命名组(named group)，位于REST path的/apis/$GROUP_NAME/$VERSION，并使用apiVersion: $GROUP_NAME/$VERSION 两种受支持的自定义资源扩展API的路径： 自定义资源(CustomResourceDefiniton) 适用于具有非常基本CRUD需求的用户 需要完整k8s API语义的用户可以实现自己的apiserver，并使用聚合器使其无缝连接到客户端 启用 API groups默认情况下启用某些资源和API groups。通过在apiserver设置--runtime-config可启用/禁用它。此配置接收逗号分隔的KV，描述了apiserver运行时配置。 在API groups中启用资源默认情况下启动 DeamonSets, Deployments, HorizontalPodAutoscalers, Ingress, Jobs, ReplicaSets。其它扩展资源可通过在apiserver上设置--runtime-config启用或禁用。 k8s 对象本节解释了如何在k8s API中表示k8s对象，以及如何以.yaml格式表示它们。 理解k8s对象在k8s系统中，k8s对象是持久化的实体。k8s使用这些实体来表示整个集群的状态。特别地，它们描述了如下信息： 哪些容器化应用程序正在运行(以及运行在哪个节点上) 可以被这些应用程序使用的资源 应用程序行为方式的策略(重启、升级、容错) k8s 对象是一个意图记录(record of intent) —— 一旦创建了对象，k8s系统将持续工作以确保对象存在。通过创建一个对象，你可以有效地告诉k8s系统你希望集群的工作负载看起来像什么，这是你的集群的期望状态(desired state)。要使用k8s对象(创建, 修改, 删除)，需要使用k8s API。当你使用kubectl命令行接口时，CLI会为你进行必要的k8s API调用。 对象规约与状态Object Spec and Status 每个k8s 对象都包含了两个嵌套的对象字段，用于控制对象的配置：对象规约和对象状态。在任何时刻，k8s controller plane都会主动管理对象的实际状态，以匹配你提供的期望状态。 规约(spec)，必须提供。描述了对象的期望状态(diresed state)——你希望对象具有的特征。 状态(status)，描述对象的实际状态，由k8s系统提供和更新。 例如，k8s Deployment是一个可以表示你集群上运行的应用程序的对象。当你创建一个Deployment，你可以设置部署规约以指定你希望应用程序运行三个副本。k8s系统读取部署规约并启动应用程序所需的三个实例——更新状态以符合你的规范。如果这些事例中的任何一个失败(状态改变)，k8s系统通过进行校正来响应规约和状态之间的差异。在这种情况下，启动替换实例。 描述k8s 对象在k8s中创建对象时，必须提供描述其期望状态的对象规约，以及有关对象的一些基本信息(如 名称)。当你使用k8s API来创建对象时，API请求必须在请求正文中将信息作为JSON格式。通常，你在.yaml文件中向kubectl提供信息，kubectl在发出API请求时将信息转换为JSON格式。 栗子： 1234567891011121314151617181920# for versions before 1.9.0 use apps/v1beta2apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 使用类似上面的.yaml文件创建部署的方法，是在kubectl命令行工具中使用kubectl create命令，将.yaml文件作为参数传递。 12kubectl create -f https://k8s.io/examples/application/deployment.yaml --record#deployment &quot;nginx-deployment&quot; created 必填字段在要创建k8s 对象的.yaml文件中，必须配置一下字段： apiVersion： 创建对象的k8s API版本 kind： 创建的对象类型 metadata： 有助于识别对象唯一性的数据，包括name, uid, namespace… 你还需要提供spec字段。对于每个k8s对象，对象规约的精确格式是不同的，并且包含特定于该对象的嵌套字段。 NamesKubernetes REST API中所有对象都用Name和UID来明确标识。对于用户提供的非唯一的属性，k8s提供labels和annotations。 Names客户端提供的字符串，用于引用资源URL中的对象。如/api/v1/pods/some-name.一个给定kind的对象同时只能有一个name。但如果你删除了此对象，便可以为新对象赋予此名字。按照惯例，k8s资源的名称的最大长度应为253个字符，并由小写字母,数字, -, .字符组成。但某些资源可能具有更过限制。 UIDsk8s 系统生成的字符串，用于唯一标识对象。在k8s集群的整个生命周期中创建的每个对象都具有一个唯一的UID。它旨在区分类似实体的历史事件。 Namespacek8s支持在物理集群中创建多个虚拟集群，这些虚拟机群称为namespaces。命名空间是一种将集群资源划分为多个用途的方法。命名空间名称满足正则表达式，最大长度为63位。 什么时候使用多个命名空间命名空间旨在用于多个用户分布在多个团队/多个项目的环境中。对于具有几个到几十个用户的集群，你根本不需要创建和考虑命名空间。命名空间提供名称范围。资源名称在命名空间中必须唯一，但不能跨命名空间。命名空间是一种在多个用户之间划分集群资源的方法。在k8s的未来版本中，默认情况下，同一命名空间中的对象将具有相同的访问控制策略(ACP)。没有必要使用多个命名空间仅来分隔略有不同的资源。如同一软件的不同版本，使用labels来区分同一命名空间内的资源。 操作命名空间 12345678910111213141516171819202122232425262728293031323334353637383940#查看kubectl get nsNAME STATUS AGEdefault Active 13dkube-system Active 13d#通过命令创建kubectl create namespace my-namespace#或通过文件创建vim my-namespace.yamlapiVersion: v1kind: Namespacemetadata: name: my-namespacekubectl create -f ./my-namespace.yaml#查看kubectl get namespaceNAME STATUS AGEdefault Active 13dkube-system Active 13dmy-namespace Active 4s#删除kubectl delete namespace my-namespace#设置请求的命名空间#使用--namespace标志临时设置请求的命名空间kubectl kubectl get pods --namespace=default#设置命名空间首选项kubectl config set-context $(kubectl config current-context) --namespace=my-namespacekubectl config view Kubernetes有三个初始的命名空间： default: 没有其它命名空间时，对象的默认命名空间 kube-system: k8s系统创建的对象的命名空间 kube-public: 此命名空间是自动创建的，可供所有用户读取(包括未认证用户)。此命名空间主要用于集群使用，以防止某些资源在整个集群中可见且可公开读取。此命名空间的公共方面只是一个约定，而非要求。 注意： 删除一个命名空间会自动删除所有属于该命名空间的资源 k8s初始化的两个命名空间无法删除 持久化卷(persistent volume)不属于任何命名空间，但持久化卷声明(persistent volume claim)是属于某个特定命名空间的 事件(event)是否属于命名空间取决于产生事件的对象 命名空间和DNS当你创建一个服务(service)，它会创建相应的DNS条目(dns entry)。此条目的格式为&lt;service-name&gt;.&lt;namespace-name&gt;.svc.cluster.local，这表示如果一个容器只是用&lt;service-name&gt;，它将会解析为命名空间本地的服务。这对于在多个命名空间(如 开发/测试/生产)中使用相同的配置非常有用。如果想要扩命名空间访问，则需要使用完全限定的域名(fully qualified domain name)。 不是所有对象都在命名空间中大多数k8s资源(pods, services, replication controller…)都在某些命名空间中。然而，命名空间资源本身并不在命名空间中。并且，低级资源(node, persistentVolumes)并不在任何命名空间中。 查看k8s资源是否在命名空间中： 12kubectl api-resources --namespaced=truekubectl api-resources --namespaced=false Labels和Selectors标签是被关联到对象上的key/value对。标签旨在用于指定对用户有意义且相关的对象的标识属性，但不直接按时核心系统的语义。标签可用于组织和选择对象的子集。标签可在创建时附加到对象，随时可以添加和修改。每个对象可拥有多个标签，对于给定的对象，key必须唯一。 123456789101112131415"metadata": &#123; "labels": &#123; "key1" : "value1", "key2" : "value2", "keyN" : "valueN" &#125;&#125;#栗子"labels": &#123; "release" : "stable", "environment" : "dev", "track" : "daily"&#125; 我们最终将索引(index)和反向索引(reverse-index)标签，用于高效查询和监视，使用它们在UI和CLI中进行排序和分组。我们不希望对非标识(non-identifying)信息使用标签，特别是大型结构化数据。非标识信息应该记录到annorations。 标签使用户能够以松散耦合的方式将自己的组织结构映射到系统对象中，而无需客户端存储这些映射。 语法和字符集有效的label key有两个字段: 可选前缀和名称，用斜杆分隔。名字字段是必须的，小于等于63个字符，以字母数字开头和结尾，还可使用-, _, .三个字符。前缀可选。如果指定，前缀必须是DNS子域，不超过253个字符，后跟斜杆/。如果省略，则假定label key对用户是私有的。向最终用户对象添加标签的自动系统组件(kube-scheduler, kube-apserver…)必须制定前缀。kuberneter.io/前缀保留个k8s核心组件。 有效的label value必须小于等于63个字符，可为空，或以字母数字开头和结尾，还可使用-, _, .三个字符。 label selectors标签不提供唯一性。通常，我们希望许多对象携带相同的标签。通过label selector，客户端/用户 可以识别一组对象。标签选择器是k8s中的核心分组原语。 API目前支持两种类型的选择器: equality-based和set-based。标签选择器可由逗号,分隔的多个要求组成。一个空(empty)标签选择器(zero requirements)，选择集合中的每个对象。一个空(null)标签选择器(仅可用于选择器字段)不选择任何对象。 equality-based requirement基于平等/不平等的要求允许按标签键和值进行过滤。匹配对象必须满足所有指定的标签约束，尽管它们也可能具有其它标签。允许三种运算符:=, ==, !=。 12environment = productiontier != frontend set-based requirement基于集合的标签的要求允许根据一组值过滤键。支持三种操作符: in, notin, exists。 1234environment in (production, qa)tier notin (frontend, backend)partition!partition API LIST and WATCH filteringLIST和WATCH操作可以指定标签选择器来过滤使用查询参数返回的对象集。两个要求都是允许的。两种标签选择器的样式都可使用通过TEST客户端列出或查看资源。 equality-based requirements: ?labelSelector=environment%3Dproduction,tier%3Dfrontend set-based requirements: ?labelSelector=environment+in+%28production%2Cqa%29%2Ctier+in+%28frontend%29 12345678#equality-basedkubectl get pods -l environment=production,tier=frontend#set-basedkubectl get pods -l 'environment in (production),tier in (frontend)'kubectl get pods -l 'environment in (production, qa)'kubectl get pods -l 'environment,environment notin (frontend)' Service and ReplicationController服务所针对的一组pod使用标签选择器进行定义。类似地，副本控制器应该管理的pod数量也使用标签选择器定义。 123456789#json格式&quot;selector&quot;: &#123; &quot;component&quot;: &quot;redis&quot;&#125;#yaml格式selector: component: redis Annotation你可使用k8s annotation(注释)将任意非标识(non-identifying)元数据附加到对象。工具和库等客户端可以检索此元数据。它也是key/value对。Annotations不会被k8s直接使用，其主要目的是方便用户阅读查找。 将元数据追加到对象你可使用label或annotations将原数据追加到k8s对象。标签用于选择对象和查找满足特定条件的对象集合。相反，注释不用于识别和选择对象。 123456"metadata": &#123; "annotations": &#123; "key1" : "value1", "key2" : "value2" &#125;&#125; Field Selectors字段选择器允许你根据一个或多个资源字段的值选择k8s资源。 栗子： 123456789101112131415161718192021222324252627#三种操作符=, ==, !=metadata.name=my-servicemetadata.namespace!=defaultstatus.phase=Pending#kubectl get pods --field-selector status.phase=RunningNAME READY STATUS RESTARTS AGEhello-world-3198537413-138pg 1/1 Running 0 5dhello-world-3198537413-67g6d 1/1 Running 0 5dhello-world-3198537413-bf73l 1/1 Running 0 5dhello-world-3198537413-ddgb3 1/1 Running 0 5dhello-world-3198537413-ffj90 1/1 Running 0 5d#kubectl get ingress --field-selector foo.bar=baz#kubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always#kubectl get statefulsets,services --field-selector metadata.namespace!=default Recommended Labels你可以使用比kubectl和dashboard更多的工具来可视化和管理k8s对象。一组通用的标签允许工具以互操作的方式工作，以所有工具都能理解的通用方式描述对象。除了支持工具之外，推荐的标签还以可查询的方式描述应用程序。 shared labels and annotations共享一个通用的前缀: app.kubernetes.io。没有前缀的标签对用户是私有的。共享前缀可确保共享标签不会干扰自定义用户标签。 为了充分利用这些标签，应将它们应用于每个资源对象。 Key Description Example Type app.kubernetes.io/name The name of the application mysql string app.kubernetes.io/instance A unique name identifying the instance of an application wordpress-abcxzy string app.kubernetes.io/version The current version of the application (e.g., a semantic version, revision hash, etc.) 5.7.21 string app.kubernetes.io/component The component within the architecture database string app.kubernetes.io/part-of The name of a higher level application this one is part of wordpress string app.kubernetes.io/managed-by The tool being used to manage the operation of an application helm string 要说明这些标签的运行情况，请考虑一下StatefulSet对象: 12345678910apiVersion: apps/v1kind: StatefulSetmetadata: labels: app.kubernetes.io/name: mysql app.kubernetes.io/instance: wordpress-abcxzy app.kubernetes.io/version: "5.7.21" app.kubernetes.io/component: database app.kubernetes.io/part-of: wordpress app.kubernetes.io/managed-by: helm 使用kubectl进行对象管理kubectl命令行工具支持多种方式来创建和管理k8s对象。应该只使用一种技术来管理k8s对象。对同一个对象的混合和匹配技术会导致未定义的行为。 Management technique Operates on Recommended environment Supported writers Learning curve Imperative commands Live objects Development projects 1+ Lowest Imperative object configuration Individual files Production projects 1 Moderate Declarative object configuration Directories of files Production projects 1+ Highest 必要的命令Managing Kubernetes Objects Using Imperative Commands 使用k8s命令行工具内置的必要命令，可直接快速创建、更新、删除k8s对象。 权衡kubectl工具支持三种对象管理： Imperative commands(必要的命令) Imperative object configuration(必要的对象配置) Declarative object configuration(声明的对象配置) 创建对象kubectl工具支持动词驱动的命令，用以创建一些最常见的对象类型。这些命令被命名为即使不熟悉k8s对象类型的用户也能够识别。 12345678910#创建一个新的Deployment对象，以在一个或多个pod中运行containerrun#创建一个新的Service对象，以在pod间对流量进行负载均衡expose#创建一个新的Autoscaler对象，用以自动水平伸缩控制器autoscale kubectl工具还支持由对象类型驱动的创建命令。这些命令支持更多对象类型，并且更明确地表达了它们的意图，但要求用户知道他们打算创建的对象类型。 1234create &lt;objecttype&gt; [&lt;subtype&gt;] &lt;instancename&gt;#栗子kubectl create service nodeport &lt;service-name&gt; 更新对象kubectl命令支持动词驱动的命令，用于一些常见的更新操作。 12345678910#通过更新控制器的副本数，水平伸缩控制器，以添加或删除podscale#在对象中添加或删除注释annotate#在对象中添加或删除标签label kubectl工具还支持由对象的某个驱动的更新命令: 12#设置对象的一个方面set kubectl工具支持这些直接地更新实时对象的额外方法，但他们需要更好地裂解k8s对象模式。 123456#通过在编辑器中打开其配置，直接编辑实时对象的原始配置文件edit#使用补丁字符串，直接修改实时对象的特定字段patch 删除对象1234#从集群中删除对象delete &lt;type&gt;/&lt;name&gt;kubectl delete deployment/nginx 查看对象如下这些命令可用于打印除对象信息: 12345678910#打印有关匹配对象的基本信息get#打印有关匹配对象的详细信息describe#打印运行在pod中容器的stdout和stderrlogs 创建对象前修改对象有些对象字段没有可在create命令汇总使用的标志。在某些情况下，你可使用set和create的组合在对象创建之前为字段指定值。 12345678910#set命令kubectl create service clusterip my-svc --clusterip="None" -o yaml --dry-run \| kubectl set selector --local -f - 'environment=qa' -o yaml \| kubectl create -f -#--edit标志kubectl create service clusterip my-svc --clusterip="None" -o yaml --dry-run &gt; /tmp/srv.yamlkubectl create --edit -f /tmp/srv.yaml 配置文件Imperative Management of Kubernetes Objects Using Configuration Files 1234567891011121314#创建对象kubectl create -f &lt;file | url&gt;#更新kubectl replace -f &lt;file | url&gt;#删除kubectl delete -f &lt;file | url&gt;#查看kubectl get -f &lt;file | url&gt; -o yaml 使用配置文件声明管理的k8s对象Declarative Management of Kubernetes Objects Using Configuration Files 可通过在目录中存储多个对象配置文件来创建、更新、删除k8s对象，并使用kubectl apply根据递归创建和更新这些对象。kubectl apply不支持对象配置命令create和replace。 开始前声明性对象配置需要深入理解k8s对象定义和配置。 创建对象使用kubectl apply创建除指定目录中的配置文件定义的已存在的所有对象。 1kubectl apply -f &lt;directory&gt;/ 栗子： 12345678910111213141516171819202122232425apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx minReadySeconds: 5 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80#创建kubectl apply -f https://k8s.io/examples/application/simple_deployment.yaml#查看kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml 更新对象使用kubectl apply更新目录中定义的所有对象，即使这些对象已经存在。 1kubectl apply -f &lt;directory&gt;/ 栗子： 12345678910111213141516171819202122232425262728293031#伸缩kubectl scale deployment/nginx-deployment --replicas=2#更新nginx版本，从1.7.9升级到1.11.9#删除minReadySeconds字段apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.11.9 ports: - containerPort: 80#应用更新kubectl apply -f https://k8s.io/examples/application/update_deployment.yaml#查看kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml 删除对象有两种方法: 12345#推荐kubectl delete -f &lt;filename&gt;#选择kubectl apply -f &lt;directory/&gt; --prune -l &lt;labels&gt; 查看对象1kubectl get -f &lt;file | url&gt; -o yaml 计算,存储和网络Compute, Storage, and Networking Extensions 集群管理Cluster Administration 规划集群 管理集群 保护集群 集群服务 详情见配置章节。 证书Certificates 当使用客户端证书认证时，你可以通过easyras, openssl, cfssl手动生成证书。 openssl123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#Generate a ca.key with 2048bitopenssl genrsa -out ca.key 2048#According to the ca.key generate a ca.crtopenssl req -x509 -new -nodes -key ca.key -subj "/CN=$&#123;MASTER_IP&#125;" -days 10000 -out ca.crt#Generate a server.key with 2048bitopenssl genrsa -out server.key 2048#reate a config file for generating a Certificate Signing Request (CSR)[ req ]default_bits = 2048prompt = nodefault_md = sha256req_extensions = req_extdistinguished_name = dn[ dn ]C = &lt;country&gt;ST = &lt;state&gt;L = &lt;city&gt;O = &lt;organization&gt;OU = &lt;organization unit&gt;CN = &lt;MASTER_IP&gt;[ req_ext ]subjectAltName = @alt_names[ alt_names ]DNS.1 = kubernetesDNS.2 = kubernetes.defaultDNS.3 = kubernetes.default.svcDNS.4 = kubernetes.default.svc.clusterDNS.5 = kubernetes.default.svc.cluster.localIP.1 = &lt;MASTER_IP&gt;IP.2 = &lt;MASTER_CLUSTER_IP&gt;[ v3_ext ]authorityKeyIdentifier=keyid,issuer:alwaysbasicConstraints=CA:FALSEkeyUsage=keyEncipherment,dataEnciphermentextendedKeyUsage=serverAuth,clientAuthsubjectAltName=@alt_names#Generate the certificate signing request based on the config fileopenssl req -new -key server.key -out server.csr -config csr.conf#Generate the server certificate using the ca.key, ca.crt and server.csropenssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key \-CAcreateserial -out server.crt -days 10000 \-extensions v3_ext -extfile csr.conf#View the certificateopenssl x509 -noout -text -in ./server.crt easyrsa cfssl 分发自签名CA证书客户端节点可以拒绝将自签名(self-signed)CA 证书识别为有效。对于非生产环境火灾防火墙后面运行的部署，你可以将自签名CA证书分发给客户端，并刷新本地列表以获取有效证书。 1234567sudo cp ca.crt /usr/local/share/ca-certificates/kubernetes.crtsudo update-ca-certificatesUpdating certificates in /etc/ssl/certs...1 added, 0 removed; done.Running hooks in /etc/ca-certificates/update.d....done. 云提供商跳过！ 管理资源可能，你已经部署应用程序并通过服务公开它。接下来怎么办？k8s提供了许多工具来帮助你管理应用程序部署(包括伸缩和更新)。我们将更深入讨论配置文件和标签。 组织资源配置Organizing resource configurations 许多应用程序需要创建多个资源，如Deployment和Service。通过将多个资源组合在同一个文件中(在yaml中以---分隔)，可以简化多个资源的管理。 栗子：nginx-app.yaml 12345678910111213141516171819202122232425262728293031323334apiVersion: v1kind: Servicemetadata: name: my-nginx-svc labels: app: nginxspec: type: LoadBalancer ports: - port: 80 selector: app: nginx---apiVersion: apps/v1kind: Deploymentmetadata: name: my-nginx labels: app: nginxspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 使用与单个资源相同的方式创建多个资源。资源将按照它们在文件中出现的顺序创建。因此，最好首先指定Service，因为这将确保Scheduler可以扩展与服务关联的pod，因为它们是由Controller创建的。 1234567891011121314151617kubectl create -f https://k8s.io/examples/application/nginx-app.yaml#service "my-nginx-svc" created#deployment "my-nginx" created#同样也支持多个-fkubectl create -f https://k8s.io/examples/application/nginx/nginx-svc.yaml -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml#或者指定一个目录，读取yaml, yml, json文件kubectl create -f https://k8s.io/examples/application/nginx/#urlkubectl create -f https://raw.githubusercontent.com/kubernetes/website/master/content/en/examples/application/nginx/nginx-deployment.yaml 建议的做法是，将与同一微服务或应用程序相关的资源放入同一配置文件中，或将相关联的配置文件分组到同一目录下。 kubectl批量操作Bulk operations in kubectl 资源创建并不是kubectl可执行的唯一操作。 1234567891011121314151617181920kubectl delete -f https://k8s.io/examples/application/nginx-app.yaml#deployment "my-nginx" deleted#service "my-nginx-svc" deleted#分开的资源kubectl delete deployments/my-nginx services/my-nginx-svc#指定label(selector)删除kubectl delete deployment,services -l app=nginx#deployment "my-nginx" deleted#service "my-nginx-svc" deleted#递归删除--recursive -Rkubectl create -f project/k8s/development --recursivekubectl create -f project/k8s/namespaces -f project/k8s/development --recursive 高效使用labelUsing labels effectively 到目前为止，我们使用的示例最多只能将一个标签应用于任意资源。在许多情况下，应该使用多个标签来区分集合。 12345678910 labels: app: guestbook tier: backend role: master#查看kubectl get pods -Lapp -Ltier -Lrolekubectl get pods -l app=guestbook,role=master Canary deployments需要多个标签的另一种情况是区分不同版本的部署，或同一组件的配置。通常的做法是将新应用程序版本的canary与先前版本并排部署，以便新版本可以在完全推出前接收实时生产流量。 例如，你可以使用track标签来区分不同的版本: 12345678910111213141516171819202122232425262728#stable version name: frontend replicas: 3 ... labels: app: guestbook tier: frontend track: stable ... image: gb-frontend:v3#new version name: frontend-canary replicas: 1 ... labels: app: guestbook tier: frontend track: canary ... image: gb-frontend:v4#前端服务将通过选择其标签的公共子集(`track`)来跨越两组副本，以便将流量定向到两个应用程序。 selector: app: guestbook tier: frontend 更新标签Updating labels 有时，在创建新资源之前，需要重新标记现有的pod和其它资源。这可使用kubectl label来完成。 12345#更新kubectl label pods -l app=nginx tier=fe#查看kubectl get pods -l app=nginx -L tier 更新注释Updating annotations 有时，你会想要将注释附加到资源。这个使用kubectl annotatie来完成。 1234kubectl annotate pods my-nginx-v4-9gw19 description=&apos;my frontend running nginx&apos;#查看kubectl get pod my-nginx-v4-9gw19 -o yaml 伸缩应用程序Scaling your application 当应用程序上的负载增大或缩小时，可以使用kubectl轻松扩展。 1234567kubectl scale deployment/my-nginx --replicas=2kubectl get pods -l app=nginx#自动伸缩kubectl autoscale deployment/my-nginx --min=1 --max=3 就地更新资源In-place updates of resources 有时，需要对创建的资源进行简单，无中断(non-disruptive)的更新。 kubectl apply建议在源代码管理中维护一组配置文件，以便可以对它们配置的资源的代码进行维护和版本化。这样，你可以使用kubectl apply将更改的配置推送的集群。kubectl apply会将注释附加到资源，以便确定自上次调用以来对配置所做的更改。在调用它是，kubectl apply会在先前的配置，提供的输入和资源的当前配置之间进行差异比较，已确定如何修改资源。 kubectl edit或者，你可使用kubectl edit来更新资源。 12kubectl edit deployment/my-nginx#这样就和vim差不多，可修改此部署 kubectl patch你可使用kubectl patch来更新API对象。此命令支持JSON patch, JSON merge patch和 strategic merge patch。 破坏性更新Disruptive updates 在某些情况下，你可能需要更新初始化后无法更新的资源字段，或者你可能只想立即进行递归更改，例如修复部署创建的损坏的pod。要更改此类资源，请使用replace --force——它将删除并重新创建资源。 123kubectl replace -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml --forcedeployment &quot;my-nginx&quot; deleteddeployment &quot;my-nginx&quot; replaced 在服务没有中断的情况下更新应用程序Updating your application without a service outage 在某些时候，你最终需要更新已部署的应用程序，通常是指定新的image或image tag。kubectl支持多种更新操作，每种操作都适用于不同的场景。 123456kubectl run my-nginx --image=nginx:1.7.9 --replicas=3#deployment &quot;my-nginx&quot; created#更新nginx版本为: 1.9.1kubectl edit deployment/my-nginx#修改镜像那一行 部署将以声明的方式逐步更新已部署的nginx应用程序。它确保在更新时只有一定数量的旧副本可能会关闭，并且在所需数量的pod之上只能创建一定数量的新副本。 集群网络Cluster Networking 默认情况下，k8s与docker的网络方式有所不同。有4个网络问题需要解决： 高度耦合的容器到容器的通信: 这通过pod和localhost通信解决 pod到pod的通信： 这是侧重点 pod到service的通信： 这包含在Service中 external到service的通信： 这包含在service中 k8s假设pod与pod间是可以通信的，无论它们位于哪个主机。每个pod都有自己的IP地址，因此你无需在pod之间明确创建链接，也几乎不需要处理映射容器端口到主机端口。这创建了一个干净的向后兼容的模型，从端口分配、命名、服务发现、负载均衡、应用程序配置和迁移的角度来看，pod可以像VM或物理主机一样。 为实现此目的，你需要设置集群网络。 Docker模型在讨论k8s网络方法之前，有必要回顾Docker网络方式。默认情况下，Docker使用host-private网络。它创建一个虚拟网桥(称为docker0)，并从RFC1918中为该网桥定义的一个专用地址块中分配一个子网。对于Docker创建的每个容器，它分配一个连接到网桥的虚拟以太网设备(称为veth)。使用Linux命名空间将veth映射为容器中的eth0。容器内的eth0网口从桥接器的地址范围获取IP地址。为了使Docker容器跨节点进行通信，必须在计算机自己的IP地址上分配端口，然后将这些端口转发/代理到容器。这意味着容器必须小心地使用端口，或动态分配端口。 k8s模型跨多开发者协调端口非常难以大规模地进行，并使用户暴露在他们无法控制的集群级别问题之外。动态端口分配给系统带来了很多复杂性——每个应用程序都必须将端口作为标志，API server必须知道如何将动态端口号插入配置块，服务必须知道如何找到彼此。与此相关，k8s采取了不同的方法。 k8s对任何网络实施都强加了一下基本要求： 容器间可互相通信而无需NAT 所有节点都可与所有容器通信而无需NAT 容器看到的IP与其他人看到的IP相同 实际上，k8s在pod范围应用IP地址，pod中的容器共享其网络命名空间(包括IP地址)。这意味着pod中的容器都可以在localhost上彼此通信。这被称为ip-per-pod模型。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#在Docker中查看docker network inspect bridge#可看到副本集的容器，都是pod，而非container#这也证明container共享pod的网络空间#注意它的网关便是docker0[ &#123; &quot;Name&quot;: &quot;bridge&quot;, &quot;Id&quot;: &quot;68bc0cf07a4d7666e1d35f2c1cf179ae8605b431353ba93446abc898de086a9c&quot;, &quot;Created&quot;: &quot;2018-07-23T17:45:54.42038221+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;10.254.76.0/24&quot;, &quot;Gateway&quot;: &quot;10.254.76.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Containers&quot;: &#123; &quot;7d2e6561fa81730ae05743f78871666df75cf5e6f483b71da33137823c172333&quot;: &#123; &quot;Name&quot;: &quot;k8s_POD.24f70ba9_hello-world-3198537413-138pg_default_adb8f0fe-8fea-11e8-b10b-000c29aa7e75_785c4a84&quot;, &quot;EndpointID&quot;: &quot;bf50c5a71ad26531a370a73ce8da5903d32b9e2f8b8397d7405b914203071c45&quot;, &quot;MacAddress&quot;: &quot;02:42:0a:fe:4c:06&quot;, &quot;IPv4Address&quot;: &quot;10.254.76.6/24&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125;, &quot;ea9fbf660f27943b866759a084dc26457474d73c50082939f157ed1dfe0bc806&quot;: &#123; &quot;Name&quot;: &quot;k8s_POD.24f70ba9_hello-world-3198537413-ddgb3_default_adb90c8c-8fea-11e8-b10b-000c29aa7e75_0452e1f4&quot;, &quot;EndpointID&quot;: &quot;e83401827e0e6d2896eb46c7b252594c1694ca119d0cbd74c29383209b80a128&quot;, &quot;MacAddress&quot;: &quot;02:42:0a:fe:4c:02&quot;, &quot;IPv4Address&quot;: &quot;10.254.76.2/24&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;, &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;, &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 如何实现k8s网络模型How to implement the Kubernetes networking model 有多种方式实现此网络模型，以下做一个概述。 ACI AOS from Apstra Big Cloud Fabric from Big Switch Networks Cilium CNI-Genie from Huawei Contiv Contrail Flannel Google Compute Engine Kube-router L2 networks and linux bridging Multus NSX-T Nuage Networks VCS OpenVSwitch OVN Project Calico Romana Weave Net from Weaveworks 日志架构Logging Architecture 应用程序和系统日志可以帮助你了解集群内部发生的情况。大多数现代应用程序都有某种日志机制，因此，大多数容器化引擎同样设计来支持多种日志。容器化应用程序最简单、最受欢迎的日志方法是写入stdout和stderr。 但是，容器引擎或runtime提供的本地(native)功能通常不足以构建完整的日志解决方案。例如，如果container crashe、pod evicted、node dies，你通常仍然希望访问应用程序的日志。因此，日志应独立于container、pod、node，并具有单独存储(separate storage)和生命周期(lifecycle)。这个概念称为集群级日志(cluster-level-loggin)。集群级日志需要单独的后端来存储(store)、分析(analyze)、查询(query)日志。k8s不提供日志数据的本地存储解决方案，但你可以将许多现有的日志解决方案集成到k8s集群中。 集群级日志架构假设在集群内部或外部存在日志记录后端。 k8s基本日志Basic logging in Kubernetes 本节中，k8s将日志记录到到标准输出。 123456789101112131415161718192021222324252627282930313233343536vim /etc/k8s/test/counter-pod.yaml#此pod每秒输出一条信息apiVersion: v1kind: Podmetadata: name: counterspec: containers: - name: count image: busybox args: [/bin/sh, -c, &apos;i=0; while true; do echo &quot;$i: $(date)&quot;; i=$((i+1)); sleep 1; done&apos;]#创建#kubectl create -f /etc/k8s/test/counter-pod#不指定命名空间，则默认default#也可在配置文件里指定命名空间#kubectl create -f /etc/k8s/test/counter-pod --namespace=test#查看#如果pod有多个容器，则应该指定容器名称kubectl logs counter0: Fri Aug 10 07:43:09 UTC 20181: Fri Aug 10 07:43:10 UTC 20182: Fri Aug 10 07:43:11 UTC 20183: Fri Aug 10 07:43:12 UTC 20184: Fri Aug 10 07:43:13 UTC 20185: Fri Aug 10 07:43:14 UTC 20186: Fri Aug 10 07:43:15 UTC 20187: Fri Aug 10 07:43:16 UTC 20188: Fri Aug 10 07:43:17 UTC 20189: Fri Aug 10 07:43:18 UTC 2018...... 节点级日志记录Logging at the node level 容器化应用程序写入stdout, stderr的所有内容，都由容器引擎处理并重定向到某处。Docker容器引擎可修改日志驱动程序，将日志写入到其它地方(file, json, fluent…)。 注意Docker json日志驱动将每一行视为单独的消息，它没有直接支持多行消息，你需要使用更高级别来处理它。 默认情况下，如果容器重启，kubelet会使用其日志保留一个已终止(terminated)的容器。如果从节点上驱逐pod，则所有相应的容器也会被驱逐(包括日志)。 节点级日志记录中，一个重要考虑因素是实现日志轮询(log rotation)，以便日志不会占用节点所有可用存储。k8s目前不负责轮询日志，但部署工具应该配置方案来解决日志轮询问题。例如，在k8s集群中，部署一个脚本程序，用于日志轮询。或设置Docker container runtime的log-opt标志已自动轮询应用程序日志。 当在基本日志记录中运行kubectl logs命令时，节点上的kubelet会处理请求直接从日志文件读取，返回响应的内容。注意： 如果某个外部系统已执行轮询，则kubectl logs只能获取到最新的日志文件。 system component logs有两种类型的系统组件: run in container: 如kube-proxy not run in container: 如kubelet, Docker 在使用systemd的机器上，kubelet和container runtime将日志写到journald。如果没有systemd，则写到/var/log/下。容器内的系统组件始终将日志写入/var/log目录下，绕过默认的日志机制。与容器日志类似，在/var/log/目录下的系统组件日志也应该被轮询。 集群级日志架构Cluster-level logging architectures k8s官方没有提供原生的集群级日志记录，但你可以考虑集中常见方法： 在每个节点上使用node-level logging agent 用于记录应用程序pod的专用sidecar container 将日志直接从应用程序推送到后端 Using a node logging agent 你可以通过在每个节点上包含一个 节点级日志记录代理 来实现集群级日志记录。它是一个用于公开日志或将日志推送到后端的专用工具。通常，此日志代理是一个容器，它可以访问该节点上所有应用程序容器的日志文件的目录。 由于日志记录代理必须在每个节点上运行，因此，将其实现为节点上的DaemonSet replica, manifest pod, dedicated native process是很常见的。然后，后两种方法已被弃用，并且非常不建议。 对于k8s集群，使用节点级日志代理是最常见和鼓励的方法，因为它在每个节点上只创建一个Agent，并且不需要对节点上运行的应用程序进行任何更改。然而，节点级日志仅适用于应用程序的stdout和stderr。 k8s并未指定logging Agent，但有两个可选的日志代理与k8s一同打包。两者都使用fluentd的自定义配置作为节点上的代理。 Stackdriver Logging: 用于Google Cloud Platform Elasticsearch Using a sidecar container with the logging agent你可通过以下方式使用sidecar container: sidecar container将应用程序的日志传输到自己的stdout sidecar container容器运行一个Logging Agent，此代理从应用程序容器中获取日志 通过让sidecar container的stream流向他们自己的stdout/stderr，你可利用已经在每个节点上运行的kubelet和logging agent。sidecat container从file、socket、journald读取日志。每个单独的sidecar container将日志打印到自己的stdout/stderr。此方法允许你从应用程序的不同部分分离多个日志流，其中一些可能缺乏对写入stdout/stderr的支持。重定向日志背后的逻辑是最小的，因此它几乎不是一个重要的开销。此外，因为stdout/stderr由kubelet处理，所以你可以使用如kubectl logs这样的内置工具。 考虑如下栗子，pod运行单个容器，此容器使用两种不同的日志格式写入两个不同的日志。 two-files-counter-pod.yaml 1234567891011121314151617181920212223242526apiVersion: v1kind: Podmetadata: name: counterspec: containers: - name: count image: busybox args: - /bin/sh - -c - &gt; i=0; while true; do echo "$i: $(date)" &gt;&gt; /var/log/1.log; echo "$(date) INFO $i" &gt;&gt; /var/log/2.log; i=$((i+1)); sleep 1; done volumeMounts: - name: varlog mountPath: /var/log volumes: - name: varlog emptyDir: &#123;&#125; 即使你设法将两个组件重定向到容器的stdout，在同一个日志流中包含不同格式的日志条目也会很麻烦。相反，你可以引入两个sidecar container。每个sidecar container可以从共享卷(shared volume)中tail特定的日志文件，然后将日志重定向到自己的stdout。 这是pod运行两个sidecat container的配置文件。三个容器共享了/var/log。 two-file-counter-pod-streaming-sidecar.yaml 1234567891011121314151617181920212223242526272829303132333435363738apiVersion: v1kind: Podmetadata: name: counterspec: containers: - name: count image: busybox args: - /bin/sh - -c - &gt; i=0; while true; do echo "$i: $(date)" &gt;&gt; /var/log/1.log; echo "$(date) INFO $i" &gt;&gt; /var/log/2.log; i=$((i+1)); sleep 1; done volumeMounts: - name: varlog mountPath: /var/log - name: count-log-1 image: busybox args: [/bin/sh, -c, 'tail -n+1 -f /var/log/1.log'] volumeMounts: - name: varlog mountPath: /var/log - name: count-log-2 image: busybox args: [/bin/sh, -c, 'tail -n+1 -f /var/log/2.log'] volumeMounts: - name: varlog mountPath: /var/log volumes: - name: varlog emptyDir: &#123;&#125; 现在运行此pod，并单独访问每个日志流: 123456789101112131415161718192021222324252627282930313233#runkubectl create -f /etc/k8s/test/two-file-counter-pod-streaming-sidecar.yaml#getkubectl get pod/counter -o wideNAME READY STATUS RESTARTS AGE IP NODEcounter 3/3 Running 0 9m 10.244.2.9 salt01#kubectl logs counterError from server (BadRequest): a container name must be specified for pod counter, choose one of: [count count-log-1 count-log-2]#logskubectl logs counter count-log-10: Tue Aug 14 02:58:29 UTC 20181: Tue Aug 14 02:58:30 UTC 20182: Tue Aug 14 02:58:31 UTC 20183: Tue Aug 14 02:58:32 UTC 2018kubectl logs counter count-log-2Tue Aug 14 02:58:29 UTC 2018 INFO 0Tue Aug 14 02:58:30 UTC 2018 INFO 1Tue Aug 14 02:58:31 UTC 2018 INFO 2Tue Aug 14 02:58:32 UTC 2018 INFO 3 集群中安装的节点级代理会自动获取这些日志流，而无需进一步配置。如果愿意，可将代理配置为根据源容器解析日志行。 注意，进错CPU和内存使用率很低，将日志写入文件然后将它们流式传输到stdout会使磁盘使用量增加一倍。如果你有一个应用程序将日志写到单个文件，通常最好将/dev/stdout设置为目标，而不是实现流式sidecar container方法。 sidecar container还可用于应用程序本身日志轮询。然而，建议直接使用stdout/stderr并将日志的轮询和保留交给kubelet。 Sidecar container wiht a logging agent 如果节点级日志记录代理对你来说不够灵活，你可以创建一个带有单独日志记录代理程序的sidecar container，该代理可专门配置来与你的程序一起运行。 注意：在sidecar container使用日志记录代理将会消耗大量资源。此外，你将无法使用kubectl logs命令访问这些日志，因为它们不受kubelet控制。 栗子使用fluentd作为logging agent。有两个可用于实现此方法的配置文件： ConfigMap使用ConfigMap来配置fluentd。具体配置参考fluentd官方文档。 fluentd-sidecat-config.yaml 12345678910111213141516171819202122232425apiVersion: v1kind: ConfigMapmetadata: name: fluentd-configdata: fluentd.conf: | &lt;source&gt; type tail format none path /var/log/1.log pos_file /var/log/1.log.pos tag count.format1 &lt;/source&gt; &lt;source&gt; type tail format none path /var/log/2.log pos_file /var/log/2.log.pos tag count.format2 &lt;/source&gt; &lt;match **&gt; type google_cloud &lt;/match&gt; pod运行fluentd的sidecat container的pod。它挂载一个volume让fluentd获取配置数据。下面需要用到k8s.gcr.io/fluentd-gcp:1.30镜像，请提前准备。要挂载目录，请创建。 two-files-counter-pod-agent-sidecar.yaml 123456789101112131415161718192021222324252627282930313233343536373839apiVersion: v1kind: Podmetadata: name: counterspec: containers: - name: count image: busybox args: - /bin/sh - -c - &gt; i=0; while true; do echo &quot;$i: $(date)&quot; &gt;&gt; /var/log/1.log; echo &quot;$(date) INFO $i&quot; &gt;&gt; /var/log/2.log; i=$((i+1)); sleep 1; done volumeMounts: - name: varlog mountPath: /var/log - name: count-agent image: k8s.gcr.io/fluentd-gcp:1.30 env: - name: FLUENTD_ARGS value: -c /etc/fluentd-config/fluentd.conf volumeMounts: - name: varlog mountPath: /var/log - name: config-volume mountPath: /etc/fluentd-config volumes: - name: varlog emptyDir: &#123;&#125; - name: config-volume configMap: name: fluentd-config 这仅仅是一个栗子。你可以使用其它logging agent取代fluentd，如filebeat, logstash… Exposing logs directly from the application 你可以通过直接公开每个应用程序的日志或push日志来实现集群级日志记录。就相当于在写得程序中加入日志收集和处理。但是，这种日志记录机制超出了k8s的范围。 kubelet垃圾回收Configuring kubelet Garbage Collection 垃圾回收是一个有用的kubelet功能，它将清理未使用的镜像和容器。每分钟对容器执行垃圾回收，每五分钟对镜像进行垃圾回收。不推荐使用额外的垃圾回收工具，因为这可能会破坏kubelet的行为。 镜像回收Image Collection k8s在cadvisor的配合下，通过imageManager管理所有镜像的生命周期。镜像垃圾回收策略考虑了两个要素： HighThresholdPercent LowThresholdPercent 磁盘使用率高于高阈值将触发垃圾回收，垃圾回收将删除最近最少使用的镜像，直到满足低阈值。 镜像垃圾回收的kubelet flag: 123456789#触发镜像垃圾回收的磁盘使用率百分比#默认值 90%image-gc-high-threshold#镜像垃圾回收尝试释放磁盘使用的百分比#默认值 80%image-gc-low-threshold 容器回收Container Collection 容器垃圾回收策略考虑了三个用户定义的变量： MinAge MaxPerPodContainer MaxContainers MinAge是容器可以被垃圾回收的最小年龄。设置为0可禁用。MaxPerPodContainer是允许每个pod对允许拥有的最大死容器数。设置小于0可禁用。MaxContainers是总死亡容器的最大数量。设置小于0可禁用。 kubelet将对未识别、删除或标志设置的边界之外的容器起作用。通常首先移除最旧的容器。不受kubelet管理的容器不受容器垃圾回收的限制。 容器垃圾回收的kubelet flag: 1234567891011121314151617#完成的容器在垃圾回收之前的最低年龄#默认值 0min，意味着每个完成的容器都将被垃圾回收minimum-container-ttl-duration#每个容器要保留的最大旧实例数#默认值 1#强烈建议使用足够大的值，以允许每个预期容器保留至少1个死亡容器maximum-dead-containers-per-container#全局要保留的最大容器实例数#默认值 -1，意味着禁用#处于类似的原因，同样建议使用较大的值maximum-dead-containers 启用一些kubelet垃圾回收标志未来将被启用或取代。 Existing Flag New Flag Rationale —image-gc-high-threshold —eviction-hard or —eviction-soft existing eviction signals can trigger image garbage collection —image-gc-low-threshold —eviction-minimum-reclaim eviction reclaims achieve the same behavior —maximum-dead-containers xxx deprecated once old logs are stored outside of container’s context —maximum-dead-containers-per-container xxx deprecated once old logs are stored outside of container’s context —minimum-container-ttl-duration xxx deprecated once old logs are stored outside of container’s context —low-diskspace-threshold-mb —eviction-hard or eviction-soft eviction generalizes disk thresholds to other resources —outofdisk-transition-frequency —eviction-pressure-transition-period eviction generalizes disk pressure transition to other resources Federation先跳过，后面来学习。 ProxyProxies in Kubernetes 使用Kubernetes时可能会遇到几种不同的代理。代理已经取代了重定向功能，重定向已被弃用。 kubectl proxy runs on a user’s desktop or in a pod proxies from a localhost address to the Kubernetes apiserver client to proxy uses HTTP proxy to apiserver uses HTTPS locates apiserver adds authentication headers apiserver proxy is a bastion built into the apiserver connects a user outside of the cluster to cluster IPs which otherwise might not be reachable runs in the apiserver processes client to proxy uses HTTPS (or http if apiserver so configured) proxy to target may use HTTP or HTTPS as chosen by proxy using available information can be used to reach a Node, Pod, or Service does load balancing when used to reach a Service kube proxy runs on each node proxies UDP and TCP does not understand HTTP provides load balancing is just used to reach services A Proxy/Load-balancer in front of apiserver existence and implementation varies from cluster to cluster(e.g. nginx) sits between all clients and one or more apiservers acts as load balancer if there are several apiservers 云负载均衡器 由云服务商提供 当k8s服务有LoadBalancer类型时自动创建 仅使用udp/tcp 具体详情因云服务商而异 控制器管理器指标Controller manager metrics 控制器管理器指标，提供有关控制器管理器性能和运行状况的重要信息。 这些指标包括常见的Go语言运行时指标、控制器特定指标。可用于衡量集群的运行状况。 在集群中，当控制器管理器运行时，可从http://localhost:10252/metrics获取控制器管理器指标。 12345netstat -nltup | grep 10252tcp 0 0 127.0.0.1:10252 0.0.0.0:* LISTEN 11088/kube-controll curl http://localhost:10252/metrics 这些指标以prometheus format格式发出，并且是人类可读的。 附加组件Installing Addons 附加组件扩展了k8s的功能。 网络和网络策略Networking and Network Policy ACI： 通过 Cisco ACI提供集成的容器网络和网络完全 Calico： 是一个安全的L3网络和网络策略提供商 Canal: 将Flannel和Calico联合起来，提供网络和网络策略 Cilium： 是一个L3网络和网络策略插件 CNI-Genie： 使k8s能够无缝连接到各种CNI插件 Contiv： 提供可配置的网络，用于各种用例和丰富的策略框架 Flannel： 是一个可以与k8s一起使用的overlay网络提供商 Knitter： 是一个支持k8s多个网络的网络解决方案 Multus： 是一个用于k8s中多个网络支持，以支持所有CNI插件的多插件 NSX-T： 提供VMware NSX-T与容器协调器之间的集成 Nuage： 是一个SDN平台，可在k8s Pod和non-k8s环境之间提供基于策略的网络，并提供可见性和安全性监控 Romana： 用于Pod网络的L3网络解决方案 Weave Net： 提供网络和网络策略，将在网络分区的两侧进行工作，而不需要外部数据库 服务发现Service Discovery CoreDNS： 是一个灵活，可扩展的DNS服务器，可作为用于pod的集群DNS。 可视化，控制Visualization, Control Dashboard： k8s的Dashboard Web Interface Weave Scope： 是一个用于以图形可视化显示container, pod, service… k8s架构Kubernetes Architecture Nodenode是k8s中的工作机器，以前称为minion。也就是集群中的一台主机。节点可以是VM或物理机。每个节点都具有用于运行pod所需的服务，并由master组件管理。节点上的服务包括docker, kubelet, kube-proxy。 节点状态Node Status 节点的状态包含以下信息： 地址(Address) 条件(Condition) 容量(Capacity) 信息(Info) 地址这些字段的使用取决于机器配置。 HostName： 节点内核报告的主机名 ExternalIP： 通常是可从外部路由的节点IP地址 InternalIP： 通常是仅在集群内可路由的节点IP地址 123456789101112kubectl get node -o wideNAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIMEmaster Ready master 7d v1.11.1 192.168.31.49 &lt;none&gt; CentOS Linux 7 (Core) 3.10.0-862.9.1.el7.x86_64 docker://1.13.1node Ready &lt;none&gt; 7d v1.11.1 192.168.31.174 &lt;none&gt; CentOS Linux 7 (Core) 3.10.0-862.9.1.el7.x86_64 docker://1.13.1salt01 Ready &lt;none&gt; 1d v1.11.1 192.168.31.159 &lt;none&gt; CentOS Linux 7 (Core) 3.10.0-862.9.1.el7.x86_64 docker://1.13.1kubectl describe node/salt01Addresses: InternalIP: 192.168.31.159 Hostname: salt01 条件该字段描述了所有运行中节点的状态。节点条件使用JSON对象表示。 条件 描述 OutOfDisk True(节点上的可用空间不足以添加新pod), 否则为False Ready True(节点健康并准备好接受pod) False(节点不健康且不接受pod) Unknown(节点控制器在最后一个node-monitor-grace-period期限内没有从节点收到消息。默认40s) MemoryPressure True(节点内存有压力，即内存不足)，否则为False PIDPressure True(进程存在压力，即节点上有太多进程)，否则为False DiskPressure True(磁盘大小存在压力，即磁盘容量较低), 否则为False NetworkUnavailable True(节点网络配置错误)，否则为False ConfigOK True(kubelet配置正确)，否则为False 123456789kubectl describe node/salt01Conditions: Type Status LastHeartbeatTime LastTransitionTime Reason Message ---- ------ ----------------- ------------------ ------ ------- OutOfDisk False Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:51:40 +0800 KubeletHasSufficientDisk kubelet has sufficient disk space available MemoryPressure False Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:51:40 +0800 KubeletHasSufficientMemory kubelet has sufficient memory available DiskPressure False Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:51:40 +0800 KubeletHasNoDiskPressure kubelet has no disk pressure PIDPressure False Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:51:40 +0800 KubeletHasSufficientPID kubelet has sufficient PID available Ready True Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:53:00 +0800 KubeletReady kubelet is posting ready status 容量描述节点上的可用资源：CPU，内存，可调度到节点上的最大pods数。 1234567kubectl describe node/salt01Capacity: cpu: 2 ephemeral-storage: 49250820Ki hugepages-2Mi: 0 memory: 3881332Ki pods: 110 信息关于节点的一般信息，如Kernel版本，Kubernetes版本，Docker版本，OS… 123456789101112kubectl describe node/salt01System Info: Machine ID: e48d6bf22f9b4c8da5cb1a07b2fec730 System UUID: 564D1413-905B-64D6-E9A2-92E37F9B5BDA Boot ID: 1df89a81-77a4-44a0-9241-e6d766795e32 Kernel Version: 3.10.0-862.9.1.el7.x86_64 OS Image: CentOS Linux 7 (Core) Operating System: linux Architecture: amd64 Container Runtime Version: docker://1.13.1 Kubelet Version: v1.11.1 Kube-Proxy Version: v1.11.1 管理Management 与Pod与Service不同，k8s本身并不创建节点： 它由云服务商创建，或存在于物理机/虚拟机的pool中。当k8s创建节点时，它实际上只是创建了一个表示节点的对象。创建之后，k8s将检查节点是否有效。 栗子： 12345678910&#123; "kind": "Node", "apiVersion": "v1", "metadata": &#123; "name": "10.240.79.157", "labels": &#123; "name": "my-first-k8s-node" &#125; &#125;&#125; k8s将在内部创建节点对象，并通过基于metadata.name字段的运行状况检查来验证节点。如果节点有效(valid)，即所有必要的服务都已运行，它就符合了运行pod的条件。否则它将被所有的集群动作忽略，直到它变为有效。请注意，Kubernetes将保持无效(invalide)节点的对象，除非它被手动删除。Kubernetes将持续检查节点是否变得可用。 目前，有3个组件与k8s节点接口交互： Node Controller kubelet kubectl 节点控制器节点控制器是一个k8s Master组件，用于管理节点的各个方面。 节点控制器在节点的生命周期中具有多个角色(role)。第一个便是在节点注册时为其分配CIDR地址块。第二个是使节点控制器的内部节点列表与可用机器保持一致。只要节点不健康，节点控制器就会询问该节点是否仍然可用。如果不是，则节点控制器从其节点列表中删除该节点。第三个是监控节点的健康状况。当节点不可达时，节点控制器负责更新节点的条件(condition)状态，从Ready变为Unknown。如果节点继续无法访问，则稍后从节点中驱逐(evict)所有pod(graceful termination)。默认超时时间为40s开始上报Unknown，然后5min之后开始驱逐pods。节点控制器通过--node-nonitor-period秒检查每个节点的状态。 在大多数情况下，节点控制器将驱逐率(evication rate)限制为--node-eviction-rate(默认值 0.1)每秒。这意味着它将不会每10s从超过1个节点驱逐pod。 当给定可用区域中的节点变得不健康时，节点驱逐行为会发生变化。同时，节点控制器检查此区域中不健康节点的百分比。如果节点不健康比例至少为--unhealthy-zone-threshold(默认值 0.55)，那么驱逐率会降低；如果集群很小，小于或等于--large-cluster-size-threshold(默认值 50)，则停止驱逐；否则，驱逐率减小到每秒--secondary-node-eviction-rate(默认值 0.01)。每个可用区域实施这些策略的原因是，一个可用区域可能与其它可用区域保持连接。 在可用区域之间传播节点的一个关键原因是，当整个区域出现故障时，工作负载可以转移到健康区域。因此，如果区域中的全部节点都不健康，则节点控制器以正常速率--node-eviction-rate驱逐。The corner case是当所有区域都不健康时。在这种情况下，节点控制器假定Master连接存在一些问题，并在某些连接恢复之前停止所有驱逐。 节点自注册Self-Registration of Nodes 当kubelet标志--register-node为true(默认)时，它会尝试向API server注册自己。这是大多数发行版使用的首选模式。 对于自注册，kubelet使用如下选项： 12345678910111213141516171819202122#向API server验证自身的凭据路径--kubeconfig#r如何与云服务商交流--cloud-provider#向API server自动注册--register-node#节点IP地址--node-ip#集群中注册节点时要添加的标签--node-labels#指定kubelet将节点状态发送到master的频率--node-status-update-frequency 目前，任何kubelet都有权 create/modify 任何节点资源，但实际上它只 创建/修改 自己的节点资源。(将来，k8s打算只允许kubelet修改自己的节点资源) 手动管理节点 如果希望手动创建节点对象，请设置kubelet标志--register-node=false。修改包括在节点上设置标签(label)并将其标记为不可调度(unschedulable)。 节点容量Node Capacity 节点容量(cpu, memory)是节点对象的一部分。通常，当创建节点对象时，节点注册自己并上报其容量。如果是手动管理节点，则需要你在添加节点时设置节点容量。k8s调度器确保节点上的所有pod都有足够的资源。它检查节点上容器请求的总和不大于节点容量。它包括由kubelet启动的所有容器，但不包括由容器运行时直接启动的容器，也不包括容器外部的任何进程。所以，尽量不要在k8s集群节点上运行额外进程。 如果要为non-pod进程保留资源，你可以创建保留(placeholder)pod。将内存和CPU的值设置为要保留的资源量。 123456789101112apiVersion: v1kind: Podmetadata: name: resource-reserverspec: containers: - name: sleep-forever - image: k8s.gcr.io/pause:0.8.0 - resources: requests: cpu: 100m memory: 100Mi API对象Node is a top-level resource in the Kubernetes REST API. 节点通信Master-Node communication Master(APIserver)与k8s cluster之间的通信。目的是允许用户自定义其安装以强化网络配置，以便集群可在不受信任的网络上运行。 Cluster-&gt;Master从Cluster到Master的所有通信路径都终止于API server。在典型部署中，API server配置为在安全的HTTPS(443)端口上监听远程连接，并启用一种或多种形式的Client认证。应该为节点配置集群的公共根证书，以便他们可以使用有效证书安全地连接到API server。希望连接到API server的Pod可以利用Service Account安全地执行此操作，这样k8s在实例化时自动将公共根证书和有效bearer token注入到Pod中。the kubernetes service配置了一个虚拟IP地址，该地址被重定向到API server的HTTPS endpoint。Master组件还通过安全端口与Cluster API server通信。 123kubectl get serviceNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 8d 因此，默认情况下，从Cluster到Master的连接的默认操作模式是安全的，可在不受信任网络/公共网络上运行。 Master-&gt;Cluster从Master(API server)到Cluster有两条主要通信路径： API server -&gt; kubelet API server -&gt; node, pod, service API server -&gt; kubelet从API server到kubelet(它运行在集群中的每个节点上)。 从API server到kubelet的连接用于： 获取Pod的日志 附加到运行的Pod 提供kubelet的端口转发功能 这些连接终止于kubelet的HTTPS endpoint。默认情况下，API server不会验证kubelet的证书，这会使连接可能受到中间人工具，并且不安全地运行在不受信任/公共的网络上。要验证此连接，使用--kubelet-certificate-authority标志位API server提供根证书，用于验证kubelet的证书。 如果无法做到，请在API server和kubelet之间使用SSH隧道保障连接安全。 API server -&gt; node, pod, service从API server到node, pod, service的连接默认为纯HTTP，因此既不需要认证也未加密。他们可以通过在API URI的前缀使用https://来运行安全的HTTPS，但他们不会验证HTTPS endpoint提供的证书，也不会提供客户端凭据。因此连接将被加密，它不会提供任何完整性保证。 云控制器管理器Cloud Controller Manager 暂时跳过！ 扩展k8s 扩展k8s集群Extending your Kubernetes Cluster k8s具有高度可配置化和可扩展化。 定制方法可大致分为配置，只涉及更改标志，本地配置文件或API资源；扩展，设计运行其它程序或服务。 扩展模式Extensions Patterns k8s旨在通过编写客户端程序实现自动化。任意 read/write k8s API的程序都可以提供有用的自动化。自动化可在集群上启用或关闭。自动化通常适用于k8s集群，包括托管集群和管理安装。 有一种编写与k8s一起使用的称为控制器模式(Controller Pattern)客户端程序的特定模式。控制器通常读取对象的.spec，可能做些事情，然后更新对象的.status。控制器(Controller)是一个k8s client。当k8s为client并调用远程服务时，它被称为Webhook。远程服务被称为Webhook Backend。与控制器一样，Webhook确实增加了一个失败点。 在webhook模式中，k8s 向远程服务发出网络请求。在二进制插件模型中，k8s执行二进制程序。二进制插件由kubelet和kubectl使用。 扩展点Extension Points k8s 系统的扩展点: 用户使用kubectl与k8s API进行交互 API server处理所有请求 API server提供各种资源 k8s调度器决定将pod放在哪个节点上 k8s大部分行为都是由控制器实现的 kubelet帮助pod在集群网络上显示为具有自己IP的虚拟服务 kubelet还可挂载和解挂容器的卷 如果你不确定如何开始，查看如下流程图： API扩展API Extensions User-Defined Types如果想要定义新的控制器、应用程序配置对象、声明性API并管理他们，请考虑向k8s添加自定义资源。不要讲自定义资源用作应用程序、用户、监控数据的数据存储。 Combining New APIs with Automation通常，当添加新API时，还会添加一个 read/write 新API的控制循环。当自定义API和控制循环的组合用于管理特定的，通常是有状态的应用程序时，这被称为操作者模式(Operator Pattern)。 Changing Built-in Resources通过自定义资源添加扩展k8s API时，添加的资源始终属于新的API组。你无法替换或修改已经存在的API组。添加API不会直接影响现有API的行为，但API Access Extensions会影响现有API的行为。 API Access Extensions当请求到达k8s API server时，它首先进行身份验证，然后授权，然后进行各种准入控制。每个步骤都提供了扩展点。 Authentication身份验证将所有请求中的Header或证书映射到发出请求的客户端的用户名中。 Authorization授权确定特定用户是否可以对API资源进行读写和其它操作。它只是在整个资源的层面上工作，不基于任意对象字段进行区分。 Dynamic Admission Control当请求授权之后，如果它是一个写操作，它还需要通过Admission Control步骤。除了内建步骤之外，还有其它扩展： Image Policy webhook限制可在容器中运行的镜像 为了做出任意的admission control决策，可使用普通admission webhook 初始化程序可在创建对象之前修改对象的控制器 基础设施扩展Infrastructure Extensions Storage PluginsFlex Volumes允许用户通过kubelet调用二进制插件来安装卷，来安装没有内置支持的卷类型 Device Plugins设备插件允许节点通过设备发现插件发现新的节点资源 Network Plugins支持不同的网络结构 Scheduler Extensions调度器是一种特殊类型的控制器，用于监视Pod，并将Pod分配给节点。 扩展k8s APIExtending the Kubernetes API 在聚合层扩展k8s APIExtending the Kubernetes API with the aggregation layer 聚合层允许在集群中安装其它k8s-style的API。 自定义资源Custom Resources 自定义资源是k8s API的扩展，包括何时向k8s集群添加自定义资源以及何时使用独立服务。 资源是k8s API中的端点(endpoint)，用于存储某种API对象的集合。如，内建的pods资源包含了Pod对象的集合。自定义资源是k8s API的扩展，不一定在每个k8s集群上都可用。换句话说，它代表了特定k8s的定制安装。自定义资源可通过动态注册在正在运行的集群中出现和消失，集群管理员可独立于集群本身更新自定义资源。安装自定义资源后，用户可使用kubectl创建和访问其对象。 Custom controllers 自定义字段本身可让你存储和检索结构化数据。只有与控制器结合使用才能成为真正的声明性API。declare API允许你声明或指定资源的所需状态，并尝试将实际状态与此期望状态相匹配。这里，控制器将结构化的数据解释为用户期望状态的记录，并且不断采取行动以实现和维护该状态。自定义控制器是一种用户可在正在运行的集群上进行部署和更新，而与集群自身的生命周期无关的控制器。自定义控制器可使用任何类型的资源，但与自定义资源结合使用时，它们更有效。 Should I add a custom resource to my Kubernetes Cluster? 当创建新的API时，考虑是使用k8s cluster API还是让API独立运行。 Consider API aggregation if: Prefer a stand-alone API if: Your API is Declarative. Your API does not fit the Declarative model. You want your new types to be readable and writable using kubectl. kubectl support is not required You want to view your new types in a Kubernetes UI, such as dashboard, alongside built-in types. Kubernetes UI support is not required. You are developing a new API. You already have a program that serves your API and works well. You are willing to accept the format restriction that Kubernetes puts on REST resource paths, such as API Groups and Namespaces. (See the API Overview.) You need to have specific REST paths to be compatible with an already defined REST API. Your resources are naturally scoped to a cluster or to namespaces of a cluster. Cluster or namespace scoped resources are a poor fit; you need control over the specifics of resource paths. You want to reuse Kubernetes API support features. You don’t need those features 声明性APIDeclarative APIs 在一个声明性API中，通常： 你的API由相对较少的相对较小的对象组成 应用程序或基础结构的对象定义配置 对象很少更新 人们通常需要读写对象 对象的主要操作时CRUD 跨对象的事务不是必需的：API表示期望状态，而不是精确的状态 imperative API不是声明性的，你的API可能不是声明性的标志包括： 客户端说执行此操作，完成后获得同步响应 客户端说执行此操作，然后获取操作ID，并且必须检查单独的Operation对象以确定请求的完成 谈论Remote Procedure Calls(RPCs) 直接存储大量数据 需要高带宽访问 存储最终用户数据，或应用程序处理的其它大规模数据 对象非CRUD的自然操作 API不容易建模为对象 使用操作ID或操作对象表示挂起的操作 Should I use a configMap or a custom resource? 如果符合以下任意条件，请使用ConfigMap: 存在现有的，记录完备的配置文件格式 你希望将整个配置文件放入ConfigMap的一个key中 配置文件的主要用途是在集群上的Pod中运行的程序使用该文件来配置自身 文件的消费者更喜欢使用Pod中的文件或环境变量，而不是k8s API 你希望在文件更新时通过部署执行滚动升级 如果符合以下大部分情况，请使用自定义资源： 你希望使用k8s client library和CLI来创建和更新新资源 你希望来自kubectl的顶级支持 你希望构建新的自动化，监视新对象的更新，然后CRUD其它对象 你希望编写处理对象更新的自动化 你希望使用k8s API约定，如.spec, .status, .metadata 你希望对象是受控资源集合的抽象，或其它资源的汇总 添加自定义资源k8s提供了两种方式来向你的集群中添加自定义资源： CRD很简单，无需任何编程即可创建 API聚合需要编程，但允许更多控制API行为，如数据的存储方式和API版本间的转换 聚合API是位于主API server后面的从属API server，它充当代理。这种安排称为API聚合(AA, API Aggregation)。CRD允许用户添加新类型的资源，而无需添加其它API server，你无需了解API聚合即可使用CRD。无论如何安装，新资源都成为自定义资源，以区别于内置的k8s 资源。 自定义资源定义自定义资源定义 API资源允许你去定义自定义资源。定义CRD对象会创建一个新的自定义资源，其中包含指定的名称和架构。k8s API提供并处理自定义资源的存储。这使你无需编写自己的API server来处理自定义资源，但实现的一般特性意味着你的灵活性低于API server聚合。 API server aggregation通常，k8s API中的每个资源都需要处理REST 请求的代码并管理对象的持久化存储。k8s API server处理pod等内建资源，还可通过CRD处理自定义资源。聚合层允许你通过编写和部署自己的独立API server为自定义资源提供专门的实现。API server将请求委托给你处理的自定义资源，使其对所有客户端可用。 为添加自定义资源选择一个方法通常情况下，CRD很适合，如果： 你有少数几个领域 你正在使用公司内的资源，或作为小型开源项目的一部分 易用性比较： CRDs Aggregated API Do not require programming. Users can choose any language for a CRD controller. Requires programming in Go and building binary and image. Users can choose any language for a CRD controller. No additional service to run; CRs are handled by API Server. An additional service to create and that could fail. No ongoing support once the CRD is created. Any bug fixes are picked up as part of normal Kubernetes Master upgrades. May need to periodically pickup bug fixes from upstream and rebuild and update the Aggregated APIserver. No need to handle multiple versions of your API. For example: when you control the client for this resource, you can upgrade it in sync with the API. You need to handle multiple versions of your API, for example: when developing an extension to share with the world. 高级功能和灵活性： Feature Description CRDs Aggregated API Validation Help users prevent errors and allow you to evolve your API independently of your clients. These features are most useful when there are many clients who can’t all update at the same time. Yes. Most validation can be specified in the CRD using OpenAPI v3.0 validation. Any other validations supported by addition of a Validating Webhook. Yes, arbitrary validation checks Defaulting See above Yes, via a Mutating Webhook; Planned, via CRD OpenAPI schema. Yes Multi-versioning Allows serving the same object through two API versions. Can help ease API changes like renaming fields. Less important if you control your client versions. No, but planned Yes Custom Storage If you need storage with a different performance mode (for example, time-series database instead of key-value store) or isolation for security (for example, encryption secrets or different No Yes Custom Business Logic Perform arbitrary checks or actions when creating, reading, updating or deleting an object Yes, using Webhooks. Yes Scale Subresource Allows systems like HorizontalPodAutoscaler and PodDisruptionBudget interact with your new resource Yes Yes Status Subresource Finer-grained access control: user writes spec section, controller writes status section. Allows incrementing object Generation on custom resource data mutation (requires separate spec and status sections in the resource) Yes Yes Other Subresources Add operations other than CRUD, such as “logs” or “exec”. No Yes strategic-merge-patch The new endpoints support PATCH with Content-Type: application/strategic-merge-patch+json. Useful for updating objects that may be modified both locally, and by the server. For more information, see “Update API Objects in Place Using kubectl patch” No, but similar functionality planned Yes Protocol Buffers The new resource supports clients that want to use Protocol Buffers No Yes OpenAPI Schema Is there an OpenAPI (swagger) schema for the types that can be dynamically fetched from the server? Is the user protected from misspelling field names by ensuring only allowed fields are set? Are types enforced (in other words, don’t put an int in a string field?) No, but planned Yes 一般功能： Feature What it does CRUD The new endpoints support CRUD basic operations via HTTP and kubectl Watch The new endpoints support Kubernetes Watch operations via HTTP Discovery Clients like kubectl and dashboard automatically offer list, display, and field edit operations on your resources json-patch The new endpoints support PATCH with Content-Type: application/json-patch+json merge-patch The new endpoints support PATCH with Content-Type: application/merge-patch+json HTTPS The new endpoints uses HTTPS Built-in Authentication Access to the extension uses the core apiserver (aggregation layer) for authentication Built-in Authorization Access to the extension can reuse the authorization used by the core apiserver (e.g. RBAC) Finalizers Block deletion of extension resources until external cleanup happens. Admission Webhooks Set default values and validate extension resources during any create/update/delete operation. UI/CLI Display Kubectl, dashboard can display extension resources. Unset vs Empty Clients can distinguish unset fields from zero-valued fields. Client Libraries Generation Kubernetes provides generic client libraries, as well as tools to generate type-specific client libraries. Labels and annotations Common metadata across objects that tools know how to edit for core and custom resources 安装自定义资源在向集群添加自定义资源之前，需要注意几点 第三方代码和新的失败点 存储 认证，授权，审计 访问自定义资源k8s client library可用于访问自定义资源。并非所有client library都支持自定义资源，但go和python client library可以。 当你添加一个自定义资源时，你可以使用如下方式访问： kubectl k8s dynamic client REST client 由k8s client 生成工具生成的client 计算，存储和网络插件Compute, Storage, and Networking Extensions 网络插件Network Plugins Notice:FEATURE STATE: Kubernetes v1.11 alphaAlpha features change rapidly k8s中的网络插件有几种风格： CNI plugins: 遵守appc/CNI规范，旨在实现互操作性 Kubenet plugin: 使用bridge和host-local CNI plugins实现基本的cbr0 安装kubelet有一个默认的网络插件，以及整个集群的默认网络。它在启动时探测插件，记住它找到的内容，并在pod声明周期中的适当时间执行所选插件。使用插件时，请记住两个kubelet命令行参数： cni-bin-dir: kubelet在启动时检测此目录以获取插件 network-plugin： 从cni-bin-dir使用的网络插件 123ps -ef | grep kubelet/usr/bin/kubelet xxx --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni 网络插件需求除了提供网络插件接口来配置和清理pod网络外，该插件还可能需要对kube-proxy提供特定支持。iptables proxy依赖于iptables，插件可能需要确保容器流量可用于iptables。默认情况下，如果未指定kubelet网络插件，则使用noop插件，它设置net/bridge-nf-call-iptables=1来确保简单配置与iptables proxy正常工作。 CNI通过kubelet传递--network-plugin=cni选项来选择CNI插件。kubelet从cni-conf-dir(默认/etc/cni/net.d)中读取文件，并使用该文件中的CNI配置来设置每个pod的网络。引用的插件必须存在于--cni-bin-dir(默认/opt/cni/bin)中。如果目录中有多个CNI配置文件，则使用文件名的词典顺序的第一个。除了配置文件指定的CNI插件外，k8s还需要标准的CNI lo插件(loopback)，最低版本 v0.2.0 kubenetkubelet是一个仅使用与Linux的基本和简单的网络插件。它本身并不实现高级的功能，如跨节点网络或网络策略。kubenet创建一个名为cbr0的Linux bridge，并为每个pod创建一个veth对，每对的主机端连接到连接到cbr0。通过配置或控制器管理器为该对的pod端分配范围内的IP地址。为cbr0分配一个MTU，该MTU与主机上启用的普通接口的最小MTU相匹配。 此插件需要一些东西： 需要标准的CNI bridge, lo, host-local插件，最小版本 v0.2.0。首先从/opt/cni/bin查找。 kubelet必须使用--network-plugin=kubenet参数来启用此插件 kubelet应该指定--non-masquerade-cidr=&lt;clusterCidr&gt;参数确保超出范围的IP流量将使用IP masquerade。 必须通过kubelet的--pod-cidr选项或控制器管理器的--allocate-node-cidrs=true --cluster-cidr=&lt;cidr&gt;选项来为节点分配IP子网 自定义MTU(kubenet)应该始终正确配置MTU以获得最佳网络性能。网络插件通常会推断合理的MTU，但有时不会产生最佳的MTU。如果需要，你可使用kubenet的network-plugin-mtu选项来明确指定MTU，仅有kubenet插件支持此选项。 使用摘要 123--network-plugin=cni--network-plugin=kubenet--network-plugin-mtu=9001 设备插件Device Plugins 从v1.8开始，k8s为Vendors提供了设备插件框架，以便在不更改k8s核心代码的情况下将资源通知到kubelet，Vendor可实现手动部署或作为DaemonSet部署的设备插件，而不是编写自定义的k8s插件。目标设备包括GPU，高性能NIC， FPGA， InfiniBand和其它计算资源。 设备插件注册设备插件功能由DevicePlugins功能控制，默认在 v1.10之前禁用。当启用设备插件功能，kubelet将导出Registration gRPC服务: 123service Registration &#123; rpc Register(RegisterRequest) returns (Empty) &#123;&#125;&#125; 设备插件可通过gRPC服务向kubelet注册自己。在注册中，它需要发送： Unix socket名 设备插件API版本 想要告知的ResourceName 栗子： 1234567891011apiVersion: v1kind: Podmetadata: name: demo-podspec: containers: - name: demo-container-1 image: k8s.gcr.io/pause:2.0 resources: limits: vendor-domain/resource: 2 # requesting 2 vendor-domain/resource 设备插件实现设备插件的一般工作流包括如下步骤： 初始化 插件启动gRPC服务 插件使用kubelet的Unix socket注册自己 注册成功之后，设备插件以服务模式运行，在此期间，它会持续监控设备运行状况，并在任何设备状况发生变化时向kubelet报告 设备插件部署设备插件可手动或作为DaemonSet来部署。k8s 设备插件的支持人处于alpha状态。 服务目录Service Catalog 服务目录是一种扩展API，它使在k8s集群中运行的应用程序能够轻松使用外部托管软件。它提供了从Service Broker 列出，配置和绑定外部托管服务的方法，而无需详细了解如何创建或管理这些服务。使用服务目录，集群操作人员可以浏览服务代理提供的托管服务列表，配置托管服务的实例，并与其绑定以使其可供k8s集群中应用程序使用。 Containers Images你创建Docker image并将其push到registry，然后在k8s pod中引用它。容器的镜像属性支持与Docker命令相同的语法，包括私有注册表和标记。 更新镜像默认的拉取策略是ifNotPresent，这会导致kubelet跳过拉取镜像(如果镜像已存在)。所以在网络不好时，我们可以首先将镜像拉取下来。如果你总想强制拉取镜像，可以执行如下操作： 设置容器imagePullPolicy为Always 使用:latest作为镜像的标记 启用AlwaysPullImages准入控制器 如果没有对镜像指定标记，则假定为:latest标记。 使用私有注册表Using a Private Registry 私有注册表有： Docker Hub Aliyun Tencent yun Google Container Registry AWS Container Registry Azure Container Registry … 以下是配置节点已使用私有注册表的推荐步骤： 12345678910111213141516171819202122232425261. 运行 docker login2. 查看 ~/.docker/config.json&#123; &quot;auths&quot;: &#123; &quot;https://index.docker.io/v1/&quot;: &#123; &quot;auth&quot;: &quot;xxxxxxxxxxxxxxx&quot; &#125; &#125;, &quot;HttpHeaders&quot;: &#123; &quot;User-Agent&quot;: &quot;Docker-Client/18.03.1-ce (linux)&quot; &#125;3. 获取节点列表#namenodes=$(kubectl get nodes -o jsonpath=&apos;&#123;range.items[*].metadata&#125;&#123;.name&#125; &#123;end&#125;&apos;)#IPsnodes=$(kubectl get nodes -o jsonpath=&apos;&#123;range .items[*].status.addresses[?(@.type==&quot;ExternalIP&quot;)]&#125;&#123;.address&#125; &#123;end&#125;&apos;)4. 复制 .docker/config.json 到上面的搜索路径列表for n in $nodes; do scp ~/.docker/config.json root@$n:/var/lib/kubelet/config.json; done 通过创建pod来验证私有镜像： 12345678910111213kubectl create -f - &lt;&lt;EOFapiVersion: v1kind: Podmetadata: name: private-image-test-1spec: containers: - name: uses-private-image image: $PRIVATE_IMAGE_NAME imagePullPolicy: Always command: [ &quot;echo&quot;, &quot;SUCCESS&quot; ]EOFpod &quot;private-image-test-1&quot; created 预拉取镜像Pre-pulling Images 默认情况下，kubelet将尝试从指定的注册表中拉取镜像。但是，如果容器的imagePullPolicy属性为ifNotPresent或Never，则会使用本地镜像。如果你希望依赖于预先拉取的镜像作为注册表身份验证的替代，则必须确保集群中的所有节点都具有相同的预拉取镜像。这可以用于预加载某些镜像以提高速度，或者作为对私有注册表进行身份认证的替代方法。请确保所有的pods都对预拉取的镜像由访问权限。 Specifying ImagePullSecrets on a Podk8s支持在pod上指定registry keys。 123456789101112131415#使用Docker config创建secretkubectl create secret docker-registry -h#Create a new secret for use with Docker registries.kubectl create secret docker-registry zhang21-secret --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAILsecret &quot;myregistrykey&quot; created.kubectl get secretNAME TYPE DATA AGEzhang21-secret kubernetes.io/dockerconfigjson 1 22s#查看和修改kubectl edit secret/zhang21-secret 如果需要访问多个注册表，你可以为每个注册表创建一个secret。当为pod来取镜像时，kubelet会将imagePullSecret合并到 一个虚拟的.docker/config.json文件中。pod只能在自己的命名空间中引用image pull secret，因此每个命名空间都需要执行一次此过程。 pod上的imagePullSecret 12345678apiVersion:kind: Podxxxspec: container: xxx imagePullSecretes: name: zhang21-secret 容器环境变量Container Environment Variables k8s容器环境为容器提供了几个重要资源： 文件系统(是镜像和卷的组合) 容器自身信息 集群中对象的信息 容器生命周期钩子Container Lifecycle Hooks 本节描述了kubelet如何使用容器生命周期钩子框架来运行在管理生命周期中由事件触发的代码。与许多具有组件生命周期钩子的编程语言框架类似，k8s为容器提供了生命周期钩子。钩子使容器能够了解其生命周期中的事件，并在执行相应的生命周期钩子时运行在处理程序中实现的代码。 容器钩子有两个公开给容器的钩子： PostStart此钩子在容器创建后立即执行。但是，无法保证钩子将在容器ENTRYPOINT之前执行。没有参数传递给处理程序。 PreStop此钩子在容器终止前立即调用。它是阻塞的，意味着它是同步的。所以它必须在调用删除容器之前完成才能发送。没有参数传递给处理程序。 Hook handler implementations容器可以通过实施和注册该钩子的处理程序来访问钩子。可为容器实施两种类型的钩子处理程序： Exec： 在cgroup和namespace内执行特定的命令 HTTP： 在容器的特定端点上执行一个HTTP请求 Hook handler exection调用容器生命周期管理钩子时，k8s管理系统会在为钩子注册的容器中执行处理程序。 钩子处理程序调用包含在容器的Pod的上下文中是同步的。这意味着对PostStart钩子，容器ENTRYPOINT和钩子异步启动。但是，如果钩子 运行/挂起 太长时间，则容器无法达到running state。PreStop钩子的行为类似。如果钩子在执行期间挂起，则pod阶段将保持在Terminating state，并在pod结束的terminationGracePeriodSeconds之后被杀掉。如果PostStart或PreStop钩子失败，则会杀掉容器。 用户应该使他们的钩子处理程序尽可能的轻量化。 Hook delivery guarantees钩子交付至少是一次，这意味着对于任何给定的事件可以多次调用钩子。由钩子实现来正确处理这个问题。通常，只进行当次交付。在一些罕见的情况下，可能会发生双重交付。 Debugging Hook handlers钩子处理程序的日志并不会在Pod事件中公开。如果处理程序由于某种原因失败，它会广播这个事件。 工作负载Workloads PodsPod是k8s的基本构建块，是你创建和部署k8s对象模型中最小和最简单的单元。Pod代表了集群上正在运行的进程。Pod封装了(encapsulates) 一个/多个 应用程序容器，存储资源，唯一的IP地址(集群内)以及控制容器运行需要的选项。Pod代表了一个部署单元，k8s中的单个应用程序实例可能包含单个或少量紧密耦合且共享资源的容器。Docker是k8s Pod中最常使用的容器运行环境(runtime)，Pod同样也支持其它容器运行环境。 k8s 集群中的Pods可以用两种主要方法来使用： 运行单个容器的PodPods that run a single containerone-container-per-pod模型时最常见的k8s用例。在这种情况下，你可将Pod视为单个容器的包装，而k8s直接管理Pod而不是容器。 运行多个需要协同工作的容器的PodPods that run multiple containers that need to work togetherPod可能封装了由多个协同定位(co-located)容器组成的应用程序，这些容器紧密耦合并且需要共享资源。这些协同的容器可能形成一个统一的服务单元——一个容器从共享卷向公众提供文件，而一个单独的sidecar容器刷新或更新这些文件。Pod将这些容器和资源作为单个可管理的实体包装在一起。 每个Pod都用于运行给定应用程序的单个实例。如果你想要水平扩展应用程序，你可以使用多个Pods(每个实例一个)。在k8s中，这通常称为副本(replication)。 Replicated Pods通常通过称为控制器(Controller)的抽象来创建和管理。 Pod如何管理多个容器Pods旨在支持多个协作进程(as container)，形成一个具有凝聚力的服务单元。Pod中的容器将自动协同定位(co-located)，并在集群中的同一主机上协同调度(co-scheduled)。容器可以共享资源和依赖，彼此通信，并协调它们何时以及如何终止。 注意，将多个协同定位和协同管理的容器分组到一个Pod中是一个相对高级的栗子。你应该仅在容器紧密耦合的特定实例中使用此模式。例如，你可能有一个容器充当共享卷中文件的Web Server，以及一个单独的sidecat容器——用于从远程更新这个文件： Pod共享资源Pod为其组成容器提供了两种共享资源： Networking每个Pod都被分配了一个唯一的IP地址(within cluster)。Pod中的每个容器都共享网络命名空间，包括IP地址和网络端口。Pod内的容器可使用localhost相互通信。当Pod内的容器与Pod外的实体通信时，它们必须协调如何使用共享网络资源。 StoragePod可以指定一组共享存储卷。Pod中的所有容器都可以访问这个共享卷，允许这些容器共享数据。还是关于数据持久化的卷。 使用Pods你很少直接在k8s(甚至是单例Pod)中创建单独的Pod。这是因为Pod被设计为相对短暂的一次性实体，即用后即焚。当Pod被创建后，都会被调度到集群中的节点上运行。Pod保留在该节点上，知道进程终止，Pod对象被删除，Pod因资源不足而被驱逐，或节点失效。Pod不会自愈。注意： 重启Pod中的容器与重启Pod不是一回事。Pod本身不运行，它只提供容器的运行环境并保持容器的运行状态。但是容器运行的环境会持续存在，直到删除为止。 Pod本身不提供自我修复(self-heal)。如果将Pod调度到一个失败的节点，或调度操作本身失败，则会删除Pod。同样，由于缺乏资源或节点维护中，Pod将无法在驱逐中存活。k8s使用一个高更级别的抽象，称为控制器(Controller)。它管理相对可处理的Pod实例的工作。因此，尽管可以直接使用Pod，但在k8s中使用控制器管理Pod更为常见。控制器可为你创建和管理多个Pod，处理副本和上线，并在集群范围内提供自我修复功能。例如，如果节点故障，控制器可能会通过在不同节点上安排相同的替换来自动替换Pod。通常，控制器使用你提供的Pod模板来创建它负责的Pod。 Pod TemplatesPod模板是Pod规范，包含在其它对象中。控制器使用Pod模板制作实际的Pod。 栗子： 1234567891011apiVersion: v1kind: Podmetadata: name: myapp-pod labels: app: myappspec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo Hello Kubernetes! &amp;&amp; sleep 3600'] Pod模板不是指定所有副本的当前所需状态，而是像饼干切割器。饼干被切割后，饼干与切割器无关。 PodPod是可在k8s中创建和管理的最小可部署的计算单元。 Pod是什么Pod是一组 一个/多个容器，具有共享存储/网络，以及如何运行容器的规范。Pod中的容器总是co-located和co-scheduler，并在共享上下文中运行。一个pod模拟特定应用程序的逻辑主机，它包含一个/多个紧密耦合的应用程序容器。Pod的共享上下文十一组Linux namespace， cgroup，以及隔离方面。在Pod的上下文中，各个应用程序科恩能够回应用进一步的子隔离。Pod中的容器共享IP地址和端口空间，并且可通过localhsot找到彼此。它们还可使用IPC相互通信。不同Pod中的容器具有不同的IP地址，默认情况下无法通信，需要进行额外配置。Pod中的应用程序还可访问共享卷，共享卷被定义为Pod的一部分，可挂载到每个应用程序的文件系统中。就Docker构造而言，Pod被建模为一组具有共享命名空间和共享卷的Docker容器。与单个应用程序容器类似，Pod被认为是相对短暂(非持久)的实体。 Pod动机 管理(Management)Pod是多个协作过程进程模式的模型，形成了一个有凝聚力的服务单元。它们通过提供更高级别的抽象来简化应用程序部署和管理。Pod提供用于部署，水平扩展，副本的单元。对于Pod中的容器，它们将自动处理协同调度， 共享命运， 协同副本，资源共享和依赖管理… 资源共享和交流Pod可以实现成员之间的数据共享和通信。Pod中的应用程序都是用相同的网络命名空间，因此可通过localhost进行通信。因此，Pod中的应用程序必须协调对端口的使用。主机名设置为Pod中应用程序容器的Pod名。除了定义在Pod中运行的应用程序容器，Pod还制定了一组共享存储卷(持久化)。 123456789101112131415kubectl -n kube-system get pod -o wideNAME READY STATUS RESTARTS AGE IP NODEkubernetes-dashboard-6948bdb78-tdh5v 1/1 Running 0 8d 10.244.2.3 salt01metrics-server-85ff8f7b84-72rd4 1/1 Running 0 9d 10.244.2.2 salt01kubectl -n kube-system exec -it metrics-server-85ff8f7b84-72rd4 /bin/sh/ # hostnamemetrics-server-85ff8f7b84-72rd4/ # ifconfigeth0 10.244.2.2/ # ping 10.244.2.3PING 10.244.2.3 (10.244.2.3): 56 data bytes64 bytes from 10.244.2.3: seq=0 ttl=64 time=0.115 ms64 bytes from 10.244.2.3: seq=1 ttl=64 time=0.062 ms Pod使用Pod可用于托管垂直集成的应用程序栈，但主要动机是用于支持协同共处，协同管理的应用程序。如： 内容管理系统，文件和数据加载器，本地缓存管理器 日志和检查点的备份、压缩、轮询、快照 数据变更观察器，日志和监控适配器，事件发布器 代理，网桥和适配器 控制器，管理器，配置器和更新器 通常，单个Pod不用于运行同一程序的多个实例。 替代考虑为什么不在单个容器中运行多个程序？ 透明度 解耦软件依赖关系 使用方便 效率 Pod耐久性Pod不应被视为耐用实体。它们不会在 调度失败，节点故障，驱逐，节点维护等情况下存活。通常，用户不需要直接创建Pod。而应该(几乎总是)使用控制器。控制器提供了集群范围内的自修复(self-healing)，副本和上线管理。 Pod公开为一个原语以便于使用： 调度器和控制器可插拔 支持Pod级操作，而无需通过控制器API代理 将Pod寿命与控制器寿命分离 控制器和服务的分离 kubelet实际是Pod控制器 高可用应用程序 Pod终止由于Pod表示集群中节点上正在运行的进程，因此允许这些进程在不需要时优雅地终止(gracefully terminate)非常重要。用户应该能够请求并指导进程何时终止，但也要确保删除最终完成。当用户请求删除Pod时，系统会在允许Pod强制终止之前记录预期的宽限期(grace period)，并将TERM信号(-15)发送到每个容器的主进程中。宽限期到期后，KILL信号(-9)发送到这些进程，然后从API server中删除该Pod。如果在等待进程终止时Kubelet或容器管理器重启了，则将在完整的宽限期内重试终止。 流程： 用户发送删除Pod的命令，默认宽限期(30s) API server中的Pod随着时间的推移而更新，在此之后，除了宽限期外，Pod被认为死亡 列出客户端命令时，Pod显示为Terminating 当Kubelet发现Pod被标记为Terminating，它将开始Pod关闭过程 4.1 如果Pod定义了preStop hook，则会在Pod内调用 4.2 Pod中的进程发送TERM信号 Pod将从端点列表中删除，并且不再被视为副本控制器中运行的Pod的一部分。缓慢关闭的Pod无法继续为流量提供服务，因为负载均衡器会将其从轮询中删除 当宽限期到期后，仍在Pod中运行的任何进程都将被KILL信号杀死 Kubelet通过设置宽限期0（立即删除）完成删除API server上的Pod。Pod从API中消失，客户端不在可见 默认情况下，所有删除都有30s的宽限期。kubectl delete命令支持指定--grace-period=选项。设置为0表示强制删除Pod。--force --grace-period=0强制删除。 强制删除Pod强制删除Pod被定义为立即从集群状态和etcd中删除Pod。当执行强制删除时，API server不会等待来自Kubelet的确认——确认该Pod已在运行的节点上终止。它会立即删除API中的Pod，以便可使用相同的名称创建新的Pod。在节点上，设置为立即终止的Pod在被强制终止之前仍被授予一个小的宽限期。强制删除可能会对某些Pod有潜在危险，请谨慎执行。 Pod容器的特权模式(Privileged mode)在容器 spec的SecurityContext中使用privileged标志，来启用Pod中容器的特权模式。这对于想要使用Linux功能的容器非常有用。容器内的进程获得与可访问的容器外进程几乎相同的权限。使用特权模式，可以更容易的编写网络和卷插件，而不需要编译到kubelet。 API对象Pod是k8s REST API中的顶级资源, /pod/xxx。 Pod生命周期Pod Lifecycle 阶段(phase)Pod的status字段是一个PodStatus对象，它有一个phase字段。 阶段可能的值： Value Description Pending The Pod has been accepted by the Kubernetes system, but one or more of the Container images has not been created. This includes time before being scheduled as well as time spent downloading images over the network, which could take a while. Running The Pod has been bound to a node, and all of the Containers have been created. At least one Container is still running, or is in the process of starting or restarting. Succeeded All Containers in the Pod have terminated in success, and will not be restarted. Failed All Containers in the Pod have terminated, and at least one Container has terminated in failure. That is, the Container either exited with non-zero status or was terminated by the system. Unknown For some reason the state of the Pod could not be obtained, typically due to an error in communicating with the host of the Pod. 状况(conditions)Pod有一个PodStatus，它有一个PodConditions数组，表示Pod是否通过。每个PodCondition数字的每个元素都有六个可能的字段： lastProbeTime: 最后一次探测Pod状况的字段 lastTransitionTime: Pod最后从一个状态转换到另一个状态的时间戳的字段 message: 有关转换的人类可读的详细信息的字段 reason: 一个独特的，单字的最后转换的原因的字段 status: 字段值可能为True, False, Unknown type: 字段可能有如下值: PodScheduled: Pod已被调度到一个节点 Ready: Pod能提供请求，并应该添加到所有匹配服务的负载均衡池中 Initialized: 所有的初始化容器已成功启动 Unschedulable: 调度器现在无法调度Pod，如缺乏资源… ContainersReady: Pod中的所有容器都已准备好了 探测(probes)探测是由容器上的kubelet定期执行的诊断。为了执行诊断，kubelet调用容器执行处理器(Handler)。有三种类型的处理器: ExecAction: 在容器内执行指定命令。如果状态码为0，则认为诊断成功 TCPSocketAction: 在指定端口的容器IP地址执行TCP检查。如果端口打开，则认为诊断成功 HTTPGetAction: 在容器IP的特定端口的路径下执行HTTP GET请求。如果请求成功，则认为诊断成功 每个探测可能有三种结果: Success Failure Unknown kubelet可选择在运行容器上执行两种探测并对其作出反应: livenessProbe: 确定容器是否正在运行 readinessProbe: 确定容器是否准备好为请求提供服务 什么时候使用这两中探测？When should you use liveness or readiness probes? 如果容器中的进程在遇到问题或变得不健康时会自行崩溃(crash)，则你不一定需要livenessProbe。kubelet将根据Pod的restartPolicy自动执行正确的操作。如果希望在探测失败时杀死并重启容器，则请指定livenessPorbe和指定restartPolicy为Always 如果只想在探测成功时向Pod发送流量，请指定readinessProbe。如果容器需要在启动期间除了大型数据，配置文件或迁移，请指定readnessProbe。如果你希望容器能够自行维护，你可指定一个readnessProbe，它检查特定端点。 注意，如果你只想在删除Pod时排除请求，则不一定需要readnessProbe。无论是否存在readnessProbe，Pod都会自动将其置于未准备状态。Pod在等待Pod中容器停止时仍处于未准备状态。 Pod readiness gateFEATURE STATE: Kubernetes v1.11 alpha 为了通过向PodStatus调价额外的反馈或信号来增加Pod readness的可扩展性，k8s v1.11引入了一个名为Pod ready++的功能。你可在PodSpec中使用新字段ReadinessGate来指定要为Pod准备情况评估的其它条件。如果k8s在Pod的status.conditions字段找不到这样的状况，则状况的状态默认为False。 12345678910111213141516171819Kind: Pod...spec: readinessGates: - conditionType: &quot;www.example.com/feature-1&quot;status: conditions: - type: Ready # this is a builtin PodCondition status: &quot;True&quot; lastProbeTime: null lastTransitionTime: 2018-01-01T00:00:00Z - type: &quot;www.example.com/feature-1&quot; # an extra PodCondition status: &quot;False&quot; lastProbeTIme: null lastTransitionTime: 2018-01-01T00:00:00Z containerStatuses: - containerID: docker://abcd... ready: true... 重启策略PodSpec有一个restartPolicy字段，其值可能是Always(默认值), OnFailure, Never。此策略应用于Pod中的所有容器，它仅指由同一节点上的kubelet重启的容器。退出的容器将由kubelet以指定退避延迟(10s, 20s, 40s…)重新启动，上限5分钟，并在成功执行十分钟后重置。 寿命(lifetime)一般来说，Pod不会消失，直到有人摧毁它们。唯一的例外是，具有成功或失败超过一段时间的阶段的Pod将过期并自动销毁。 有三种类型的控制器可用： Use a Job for Pod Use a ReplicationController/ReplicaSet/Deployment for Pod Use a DaemonSet for Pod 所有三种类型的控制器都包含了PodTemplate。推荐创建适当的控制器并让它创建Pod，而不是自己直接创建Pod。这是因为Pod单独对机器故障没有弹性，但控制器不会。如果节点死亡或与集群的其余部分断开连接，k8s会应用策略将丢失节点上的所有Pod的阶段设置为Failed。 Init Containers本节提供了初始容器(init container)的概述，它是在应用程序容器运行之前的专用容器，可包含应用程序镜像中不存在的实用程序或脚本设置。 理解初始容器Pod可以有多个容器在其中运行应用程序，但它同样可以有一个或多个初始容器——它在应用程序容器启动前运行。初始容器与常规容器一样，除了： They always run to completion. 每一个必须在下一个启动之前成功完成 如果Pod的初始容器失败，则k8s会重复重启直到初始容器成功。但是，如果Pod的restartPolicy为Never，则不会重启。要将容器指定为初始容器，请将PodSpec上的initContainers字段添加为应用程序container数组旁边的容器类型对象的JSON数组。初始容器的状态在.status.initContainerStatuses字段中作为容器状态数据返回。 与常规容器的不同初始容器支持应用程序容器的所有字段和功能，包括资源限制，卷和安全设置。但资源请求和处理方式略有不同。此外，初始容器不支持readiness probes，因为它必须在Pod准备好之前运行完成。如果为Pod指定了多个初始容器，则按顺序依次运行一个容器。每个必须在下一个运行之前完成。当所有初始容器都运行完毕时，k8s会初始化Pod并像往常一样运行应用程序容器。 初始容器可用于什么由于初始容器具有来自应用程序容器的单独镜像，因此它们对于启动相关代码具有一些优势： 出于安全原因，它们可以包含并运行不希望包含在应用程序容器镜像中的使用程序 它可以包含应用程序镜像中不存在的实用程序或自定义代码。例如，在配置过程中，无需为了使用其他工具(sed, awk, dig…)而专门使用FROM创建一个镜像 应用程序镜像构建器和部署器角色可独立工作，而无需共同构建单个应用程序镜像 它们使用Linux命名空间，以便从应用程序容器中获得不同的文件系统视图。因此，它们可以访问应用程序容器无法访问的Secrets 它们在应用程序容器启动前运行完成，因此初始容器提供了一种简单的方法来阻止或延迟应用程序容器的启动，知道满足一组前置条件。 栗子这有些初始容器的使用案例: 等待使用shell命令创建服务: for in in {1..100}; do sleep 1; if dig myservice; then exit 0; fi; done; exit 1 使用API从远程服务器注册此Pod: curl -XPOST http://host:port/register -d &#39;instance=$()&amp;ip=$()&#39; 在启动应用程序之前等待一段时间: sleep 60 克隆一个git repo到某个卷 替换配置文件中的值并运行模板来动态生成应用程序容器的配置文件 使用初始容器两个初始容器。第一个等待myservice，第二个等待mydb。一旦两个容器完成，Pod将开始。 123456789101112131415161718apiVersion: v1kind: Podmetadata: name: myapp-pod labels: app: myappspec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo The app is running! &amp;&amp; sleep 3600'] initContainers: - name: init-myservice image: busybox command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;'] - name: init-mydb image: busybox command: ['sh', '-c', 'until nslookup mydb; do echo waiting for mydb; sleep 2; done;'] 创建: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970kubectl create -f /etc/k8s/test/init-container.yamlpod/myapp-pod createdkubectl get podNAME READY STATUS RESTARTS AGEinit-container 0/1 Init:0/2 0 6skubectl describe -f /etc/k8s/test/init-container.yamlInit Containers: init-myservice: Container ID: docker://f9ca73d4d2c8903a1fe84937e34ae27b909a691d2e524254b8f4aec9d5cc754c Image: busybox Image ID: docker-pullable://docker.io/busybox@sha256:cb63aa0641a885f54de20f61d152187419e8f6b159ed11a251a09d115fdff9bd Port: &lt;none&gt; Host Port: &lt;none&gt; Command: sh -c until nslookup myservice; do echo waiting for myservice; sleep 2; done; State: Terminated Reason: Completed Exit Code: 0 Started: Fri, 24 Aug 2018 16:31:13 +0800 Finished: Fri, 24 Aug 2018 16:31:18 +0800 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-69vgk (ro) init-mydb: Container ID: docker://a9946122976ff70ff1dd874299e3e63f4b07f2758f5e6518b84343c58daa3506 Image: busybox Image ID: docker-pullable://docker.io/busybox@sha256:cb63aa0641a885f54de20f61d152187419e8f6b159ed11a251a09d115fdff9bd Port: &lt;none&gt; Host Port: &lt;none&gt; Command: sh -c until nslookup mydb; do echo waiting for mydb; sleep 2; done; State: Terminated Reason: Completed Exit Code: 0 Started: Fri, 24 Aug 2018 16:31:24 +0800 Finished: Fri, 24 Aug 2018 16:31:29 +0800 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-69vgk (ro)Containers: myapp-container: Container ID: docker://b2c7a1f32d65dd41fa439d1f6879824b40c3014b32b15d61fed0cda171144a1b Image: busybox Image ID: docker-pullable://docker.io/busybox@sha256:cb63aa0641a885f54de20f61d152187419e8f6b159ed11a251a09d115fdff9bd Port: &lt;none&gt; Host Port: &lt;none&gt; Command: sh -c echo The app is running! &amp;&amp; sleep 3600 State: Running Started: Fri, 24 Aug 2018 16:31:34 +0800 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-69vgk (ro) 详细行为在Pod启动期间，初始化网络和卷后，初始容器将按顺序启动。每个容器必须在下一个容器启动前成功退出。如果容器由于运行环境未能启动或失败退出而启动失败，则它根据Pod的restartPolicy重试。如果Pod的restartPolicy为Always(默认)，则初始容器使用restartPolicy为OnFailure。在所有初始容器都成功之前，Pod无法变为Ready。初始容器上的端口无法聚合到服务下。正在初始化的Pod处于Pending状态，但应该具有Initializing设置为true的条件。如果Pod重启，则所有初始都要执行一遍。init container spec的更改仅限于容器镜像字段。更改初始容器镜像字段相当于重启Pod。由于初始容器可重启，重试或重新执行，因此初始容器代码应该是幂等的。In particular, code that writes to files on EmptyDirs should be prepared for the possibility that an output file already exists.在Pod上使用activeDeadlineSeconds，在容器上使用livenessProbe，以防止初始容器永远失败。Pod中每个应用程序和初始容器的名称必须是唯一的，否则会引发验证错误。 资源给定初始容器的排序和执行，适用一下资源使用规则： 在所有初始容器上定义的任何特定资源请求或限制的最高值是有效的初始 请求/限制 Pod对资源的有效请求/限制是以下值中的较高者: 所有的应用程序容器对资源请求/限制的总和 对资源的有效初始请求/限制 调度是基于有效请求/限制完成的，这意味着初始容器可以保留在Pod生命周期内未使用的初始化资源 Pod的有效QoS层与初始容器和应用程序容器一样 Pod级别的cgroup基于有效的Pod请求和限制，与调度程序相同。 Pod重启原因由于以下原因，Pod可重新启动，导致重新执行初始容器： 用户更新了PodSpec，导致初始容器镜像发生噶变。应用程序容器镜像的更改仅重启应用程序容器 Pod的基础架构容器重启 Pod的所有容器都终止，而restartPolicy设置为Always，强制重启，并且初始容器完成记录由于垃圾回收而丢失 Pod预设Pod Preset Pod Presets是对象，在创建时将特定信息注入Pod。Pod Preset是一种API资源，用于在创建时将其它运行时的需求写入到Pod。你可使用label selectors指定应用于Pod的给定Pod Preset。使用Pod Preset允许pod template作者不必显示提供每个pod的所有信息。这样，作者不需要知道有关该服务的所有详细信息。 它如何工作k8s提供了一个admission controller(Pod Preset)，启用后，会将Pod Preset应用于传入的pod创建请求。当Pod创建请求发生时，系统会执行一下操作： 检索所有可供使用的Pod Preset 检查任何Pod Preset的label selector是否与正在创建的Pod上的标签匹配 尝试将Pod Preset定义的各种资源合并到正在创建的Pod中 出错时，抛出一个记录Pod 合并错误的事件，然后创建不从Pod Preset写入任何资源的pod 注释生成的修改后的Pod spec，以表明它已被Pod Preset修改——podpreset.admission.kubernetes.io/podpreset-&lt;pod-preset name&gt;: &quot;&lt;resource version&gt;&quot; 每个Pod能够被零个或多个PodPreset匹配，每个PodPreset可以被应用到零个或多个Pod。当PodPreset应用于一个或多个Pod时，k8s会修改Pod spec。对于Env, EnvFrom, VolumeMounts，k8s修改Pod中所有容器的container spce；对于Volume的更改，k8s修改Pod spec。 为指定Pod禁用PodPreset在某些情况下，你希望Pod不被任何PodPreset修改。你可修改: podpreset.admission.kubernetes.io/exclude: &quot;true&quot; 启用PodPreset要在集群中使用PodPreset，你必须确保以下内容： 你已启用API类型: settings.k8s.io/v1alpha1/podpreset 你已经启动admission controller PodPreset 你已通过在将使用的命名空间中创建PodPreset对象来定义PodPreset 中断Disruptions 本节适用于想要构建高可用性应用程序的用户，因此需要了解Pod可能发生的中断类型。这同样适用于希望执行自动化集群操作的集群管理员，例如升级或自动伸缩集群。 自愿和非自愿中断Voluntary and Involuntary Disruptions Controller ReplicaSet副本集是下一个副本控制器。现在副本集和副本控制器之间的唯一区别是selector的支持。副本集支持labels user guide中描述的新的基于集合selector的要求，而副本控制器仅支持基于等同selector的要求。 如何使用副本集大多数支持副本控制器的kubectl命令也支持副本集。一个例外是rolling-update命令。如果你想要滚动更新功能，请考虑使用Deployments代替。虽然副本集可独立使用，但它主要被Deployment用作协调Pod创建，删除和更新的机制。使用部署时，你不必担心管理它们创建的副本集，部署拥有并管理其副本集。 何时使用副本集副本集确保在任何给定时间运行指定数量的Pod副本。但是，部署是一个更高级别的概念，它管理副本集并为Pod提供声明性更新以及许多其它有用的功能。因此，除非你需要自定义更新或无需更新，否则建议你使用部署而不是直接使用副本集。这实际上意味着，你不需要操作副本集对象：改为使用部署，并在spec部分定义你的应用程序。 栗子 1234567891011121314151617181920212223242526272829303132333435363738apiVersion: apps/v1kind: ReplicaSetmetadata: name: frontend labels: app: guestbook tier: frontendspec: # modify replicas according to your case replicas: 3 selector: matchLabels: tier: frontend matchExpressions: - &#123;key: tier, operator: In, values: [frontend]&#125; template: metadata: labels: app: guestbook tier: frontend spec: containers: - name: php-redis image: gcr.io/google_samples/gb-frontend:v3 resources: requests: cpu: 100m memory: 100Mi env: - name: GET_HOSTS_FROM value: dns # If your cluster config does not include a dns service, then to # instead access environment variables to find service host # info, comment out the 'value: dns' line above, and uncomment the # line below. # value: env ports: - containerPort: 80 1kubectl create -f /etc/k8s/test/frontend.yaml 编写副本集spec与所有其它k8s API对象一样，副本集需要apiVersion, kind, metadata字段，副本集还需要一个.spce部分。 123456789101112131415161718#Pod Template.spec.template是.spec唯一必需的字段除了pod的必须字段，副本集中的Pod模板还必须指定适当的`label`和`restart policy`#Pod Selector.spec.selector字段是一个label selector。副本集使用与selector匹配的label来管理所有pod。它不区分创建或删除的Pod以及人或进程创建或删除的pod。这允许替换副本集而不会影响正在运行的Pod。.spec.template.metadata.labels 必须匹配 .spec.selector，否则它将被API拒绝。此外，你通常不应创建任何label与selector匹配的pod。如果你这样做了，副本集会认为它创建了其它pod，k8s并没有阻止你这样做。#Labels on a ReplicaSet副本集本身可以有标签(.metadata.labels)。通常，你可将其设置为与 .spec.template.metadata.labels 一致。但，允许他们不同，并且 .metadata.labels 不会影响副本集的行为#Replicas你可通过设置 .spec.replicas 来指定应同时运行的pod数量。如果未指定，默认为1 使用副本集 1234567891011121314151617181920212223242526272829303132333435363738394041424344#删除副本集和它的podskubectl delete replicaset/xxx#或kubectl proxy --port=8080curl -XDELETE &apos;localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend \-d &apos;&#123;&quot;kind&quot;:&quot;DeleteOptions&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;propagationPolicy&quot;:&quot;Foreground&quot;&#125;&apos; \-H &quot;Content-Type: application/json&quot;#仅删除副本集kubectl delete rs/xxx --cascade=false#或kubectl proxy --port=8080curl -X DELETE &apos;localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend&apos; \-d &apos;&#123;&quot;kind&quot;:&quot;DeleteOptions&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;propagationPolicy&quot;:&quot;Foreground&quot;&#125;&apos; \-H &quot;Content-Type: application/json&quot;#从副本隔离pods可通过更改label从副本集的目标中删除Pod。此技术可用于从服务中删除pod以进行调试，数据恢复等。以这种方式删除的pod将自动替换#伸缩副本集只需更新副本集的 .spec.replicas 字段轻松伸缩副本集。副本集控制器确保具有匹配 label selector 所需数量的pod可用且可操作。#作为水平pod自动伸缩目标的副本集Horizontal Pod Autoscalers(HPA)，意味着副本集可通过HPA自动伸缩。#栗子apiVersion: autoscaling/v1kind: HorizontalPodAutoscalermetadata: name: frontend-scalerspec: scaleTargetRef: kind: ReplicaSet name: frontend minReplicas: 3 maxReplicas: 10 targetCPUUtilizationPercentage: 50kubectl create -f /path/xx/hpa.rs.yaml#此外，可使用kubectl命令来自动伸缩#kubectl autoscale rs frontend 替代副本集 Deployment(推荐) Bare Pods Job DaemonSet ReplicationController注意：现在，配置副本集的推荐方法是使用部署。 副本控制器确保一次运行指定数量的Pod副本。换言之，副本控制器确保一个Pod或一组同类Pod总是可用。 Deployments部署控制器为Pod和ReplicaSet提供了声明性更新。在部署对象中描述所需的状态，部署控制器以受控速率将实际状态更改为所需状态。你可定义部署来创建新的副本集，或删除现有的部署并使用新的部署收纳所有资源。你不应该直接管理部署所拥有的副本集，应该通过操作部署对象来涵盖所有用例。 栗子以下是部署的典型案例： 创建部署来上线副本集 声明Pod的新状态 回滚到早期的部署版本 伸缩部署 暂定部署 使用部署的状态 清理旧的副本集 创建一个部署下面的栗子，创建一个3个Nginx pods的副本集: 123456789101112131415161718192021apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment labels: app: nginxspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 12345kubectl create -f ./nginx-deployment.yamlkubectl get deploymentkubectl get rskubectl get pod --show-labels 更新部署当且仅当部署的pod template发生更改时，才会触发部署更新上线。假如我们要更新Nginx的版本为1.9.1: 12345678910111213141516171819202122232425kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1deployment.extensions/nginx-deployment image updated#或者kubectl edit deployment/nginx-deploymentdeployment.extensions/nginx-deployment edited#查看上线状态kubectl rollout status deployment/nginx-deploymentWaiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 old replicas are pending termination...Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 old replicas are pending termination...deployment &quot;nginx-deployment&quot; successfully rolled out#新旧副本集副本数kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deployment-67594d6bf6 0 0 0 16mnginx-deployment-d78fcfc84 3 3 3 3m 部署可以确保在更新时只有一定数量的Pod可能会关闭。默认情况下，它确保最大不可用率25%。部署确保在所需数量的Pod之上只能创建一定数量的Pod。默认情况下，它确保比最大数多25%。例如，如果仔细查看上面的部署，你将看到它首先创建了一个新的Pod，然后删除了一些旧的Pod并创建新的Pod。在有足够数量的新Pod出现之前，它不会杀死旧的Pod，并且在足够数量的旧Pod被杀死之前不会创建新的Pod。 通常不鼓励进行label selector的更改，建议你事先规划好selector。 回滚(rolling back)部署有时可能需要回滚部署，当部署不稳定时，如崩溃循环(crash looping)。默认情况下，所有的部署上线历史都保留在系统中，以便可以随时回滚。 假设我之间将nginx:1.7.1更新到nginx:1.9.1的时候错误的写成了nginx:1.91: 1234567891011121314kubectl set image deployment/nginx-deployment nginx=nginx:1.91#上线就会卡在此处kubectl rollout status deployments nginx-deploymentWaiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...error: deployment &quot;nginx-deployment&quot; exceeded its progress deadline#查看容器错误，它会报镜像拉取错误kubectl get podnginx-deployment-58c7645486-s5t6t 0/1 ImagePullBackOff 0 3m &lt;none&gt; node#UI里面的报错#Failed to pull image &quot;nginx:1.91&quot;: rpc error: code = Unknown desc = manifest for docker.io/nginx:1.91 not found 部署控制器将自动停止错误的rollout，并将停止扩展新的副本集。这取决于滚动升级的参数(maxUnavailable)。默认情况下，k8s将值设置为1，将.spec.replicas设置为1，因此你无需关心设置这些参数。你的部署可能具有100%的不可用性。 要修复它，你需要回滚到先前稳定的部署版本。 1234567891011121314151617181920212223242526272829#检查上线历史kubectl rollout history deployment/nginx-deploymentdeployments &quot;nginx-deployment&quot;REVISION CHANGE-CAUSE1 kubectl create -f ./nginx-deployment.yaml --record2 kubectl set image deployment/nginx-deployment nginx=nginx:1.9.13 kubectl set image deployment/nginx-deployment nginx=nginx:1.91#查看某个上线历史rollout history deployment/nginx-deployment --revision=2#回滚#回滚到前一个版本kubectl rollout undo deployment/nginx-deploymentdeployment.extensions/nginx-deployment#回滚到指定版本kubectl rollout undo deployment/nginx-deployment --to-revision=2#查看事件kubectl describe deployment/nginx-deploymentEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal DeploymentRollback 2m deployment-controller Rolled back deployment &quot;nginx-deployment&quot; to revision 3 Normal ScalingReplicaSet 2m deployment-controller Scaled down replica set nginx-deployment-58c7645486 to 0 伸缩副本 1234567891011#扩展部署kubectl scale deployment nginx-deployment --replicas=5#水平伸缩kubectl autoscale deployment nginx-deployment --min=3 --max=6 --cpu-percent=80#查看kubectl get horizontalpodautoscaler.autoscalingNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGEnginx-deployment Deployment/nginx-deployment &lt;unknown&gt;/80% 3 6 5 1m 比例伸缩(proportional scaling)滚动升级部署支持同时运行多个版本的应用程序。当你或自动伸缩器正在上线滚动更新的部署时，部署控制器将平衡现有活动的副本集中的其它副本，以降低风险。这称为比例缩放。 1234567891011121314151617kubectl get deployNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx-deployment 5 5 5 5 1h#更新一个错误镜像，它会卡住kubectl set image deploy/nginx-deployment nginx=nginx:sometagkubectl get rs -o wideNAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTORnginx-deployment-895bd59bc 3 3 0 1m nginx nginx:sometag app=nginx,pod-template-hash=451681567nginx-deployment-d78fcfc84 5 5 5 1h nginx nginx:1.7.1 app=nginx,pod-template-hash=834979740kubectl get deploy -o wideNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTORnginx-deployment 6 8 3 5 1h nginx nginx:sometag app=nginx 暂停和恢复部署你可以在触发一个或多个更新之前暂停(pause)部署，然后恢复(resume)它。这允许你在暂停和恢复之间应用多个修复，而不会触发不必要的上线。注意： 在恢复暂停部署之前，无法执行回滚操作。 123456789101112131415#暂停kubectl rollout pause deployment/nginx-deploymentdeployment.extensions/nginx-deployment pausedkubectl set image deploy/nginx-deployment nginx=nginx:1.9.1deployment.extensions/nginx-deployment image updatedkubectl set resources deployment nginx-deployment -c=nginx --limits=cpu=200m,memory=128Mideployment.extensions/nginx-deployment resource requirements updated#恢复kubectl rollout resume deployment/nginx-deploymentdeployment.extensions/nginx-deployment resumed 部署状态部署在其生命周期内会进入各种状态—kubectl rollout status Progessing Deployment 部署创建一个新的副本集 部署伸缩到新的/旧的副本集 新的Pod可用 Complete Deployment 所有与部署关联的副本都已完成 所有与部署关联的副本都可用 没有正在运行的旧的部署副本 Failed Deployment 配额不足 准备探针失败 镜像拉取失败 权限不足 限制范围 应用程序运行时配置错误 Operating on a failed deployment Clean up Policy可在部署中设置.spec.revisionHistoryLimit字段来指定需要保留的旧副本集数。其余的将在后台被垃圾回收，默认为10。 注意：将此字段设置为0会导致清理部署的所有历史记录，从而部署将无法回滚。 Deployment Spec与其它k8s配置一样，Deployment需要apiVersion, kind, metadata字段。但部署还需要.spec 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#pod template#必填字段.spec.template#Replicas.spec.replicas#Selector#它必须匹配.spec.template.metadata.labels，否则会被API拒绝.spec.selector#Strategy.spec.strategy#Recreate deployment.spec.strategy.type==Recreate#Rolling Update Deployment.spce.stratefy.type==RollingUpdate#Max Unavailable.spec.strategy.rollingUpdate.maxUnavailable#Max Surge.specstrategy.rollingUpdate.maxSurge#Progress Deadline Seconds.spec.progressDeadlineSeconds#Min Ready Seconds.spec.minReadySeconds#Rollback To.spec.rollbackTo#Revision History Limit.spec.revisionHistoryLimit#Paused.spec.paused 替代方案 kubectl rolling updatekubetl rolling update以类似的方式更新Pod和副本集控制器。但建议使用部署，因为它是声明性的。 StatefulSetsStatefulSet是用于管理有状态应用程序的工作负载的API对象。Note: StatefulSets are stable (GA) in 1.9. 管理一组Pod的部署和伸缩，并提供有关这些Pod的序列和唯一性的保证。与部署类似，有状态集管理基于相同容器规范(spec)的Pod；与部署不同，有状态集为其每个Pod维护一个粘性(sticky)标识。这些Pod根据相同的规范创建，但不可互换，每个Pod都有一个持久的标识符，它可在任何重新调度时保留。有状态集与任何其它控制器相同的模式运行。你在有状态集对象中定义所需的状态，有状态集控制器进行任何必要的更新以从当前状态到达期望状态。 使用有状态集有状态集对于需要以下一个或多个应用程序非常有用： 稳定，唯一的网络标识 稳定，持久存储 有序，优雅的部署和伸缩 有序，优雅的删除和终止 有序，自动的滚动更新 如果应用程序不需要任何稳定标识或有序部署、删除、伸缩，则应该使用提供一组无状态副本的控制器来部署你的应用程序。如部署或副本集这样的控制器可能更适合无状态需求。 局限(limitations) k8s v1.9+ 给定Pod的存储必须由PersistentVolume Provisioner根据请求的存储类进行配置，或由管理员预先配置 删除/伸缩有状态集将不会删除与有状态集相关联的卷。这是为了确保数据安 有状态集目前要求headless service负责Pod的网络身份，你有责任创建此服务 组件(components) headless service，用于控制网络域 StatefulSet volumeClaimTemplates，使用持久化卷提供稳定存储 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748apiVersion: v1kind: Servicemetadata: name: nginx labels: app: nginxspec: ports: - port: 80 name: web clusterIP: None selector: app: nginx---apiVersion: apps/v1kind: StatefulSetmetadata: name: webspec: selector: matchLabels: app: nginx # has to match .spec.template.metadata.labels serviceName: "nginx" replicas: 3 # by default is 1 template: metadata: labels: app: nginx # has to match .spec.selector.matchLabels spec: terminationGracePeriodSeconds: 10 containers: - name: nginx image: k8s.gcr.io/nginx-slim:0.8 ports: - containerPort: 80 name: web volumeMounts: - name: www mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: www spec: accessModes: [ "ReadWriteOnce" ] storageClassName: "my-storage-class" resources: requests: storage: 1Gi Pod Selector必须设置有状态集的.spec.selector字段以匹配.spec.template.metadata.labels的标签。 Pod Identity有状态集Pod有一个唯一的标识，由序数、稳定的网络表示和稳定的网络存储组成。 Ordinal Index对于有多个副本的有状态集，有状态集中的每个Pod将被分配一个唯一的整数序数(ordinal)，从0—(N-1)。 Stable Network ID有状态集中的每个Pod都从有状态集的名称和Pod的序号中派生其主机名。构造的主机名的模式时$(statefulset name)-$(ordinal)。 Stable Storagek8s为每个VolumeClaimTemplate创建一个PersistentVolume。 Pod Name Label当有状态集控制器创建Pod时，它会添加一个标签statefulset.kubernetes.io/pod-name，该标签设置为Pod的名称。该标签允许你将服务附加到有状态集中的特定Pod。 部署和伸缩保证(guarantees) 对于有多个副本的有状态集，当Pod被部署时，它们按顺序从{0…N-1}被创建 但Pod被删除，它们将以{N-1…0}的相反顺序终止 在伸缩操作应用于Pod之前，所有的前置任务(predecessors)必须是Running和Ready 在终止Pod之前，其所有后继者(successors)必须完全关闭 有状态集不应该指定pod.Spec.TerminationGracePeriodSeconds为0，这很不安全，强烈建议不要这么做。 k8s v1.7+，有状态集允许你放宽Pod管理策略的排序保证，同时通过其.spec.podManagementPolicy字段保留期唯一性和身份保证。OrderedReady pod管理是有状态集的默认设置。Parallel pod管理告诉有状态集控制器并行(parallel)启动或终止所有Pod，并且在启动或终止另一个Pod之前不等待Pod变为Running、Ready或完全终止。 更新策略有状态集的.spec.updateStrategy字段允许你为有状态集中的Pod配置和禁用容器、标签、资源请求/限制、注释的自动更新。 DaemonSet守护进程集确保所有(或某些)节点运行Pod的副本。随着节点添加到集群中，会将Pod添加到集群中。随着节点从集群中移除，Pod将被垃圾回收。删除一个守护进程集会清除它创建的Pod。 守护进程集的一些典型用法： 在每个节点上运行集群存储守护进程 在每个节点上运行日志收集守护进程 在每个节点上运行一个节点监控守护进程 Writing a DaemonSet Spec 123456789101112131415161718192021222324252627282930313233343536373839404142apiVersion: apps/v1kind: DaemonSetmetadata: name: fluentd-elasticsearch namespace: kube-system labels: k8s-app: fluentd-loggingspec: selector: matchLabels: name: fluentd-elasticsearch template: metadata: labels: name: fluentd-elasticsearch spec: tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule containers: - name: fluentd-elasticsearch image: k8s.gcr.io/fluentd-elasticsearch:1.20 resources: limits: memory: 200Mi requests: cpu: 100m memory: 200Mi volumeMounts: - name: varlog mountPath: /var/log - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true terminationGracePeriodSeconds: 30 volumes: - name: varlog hostPath: path: /var/log - name: varlibdockercontainers hostPath: path: /var/lib/docker/containers 12#创建守护进程集kubectl create -f ./daemonset.yaml Required Fields与其它k8s配置一样，守护进程集需要apiVersion, kind, metadata, .spec字段。 Pod Template.spec.template是.spec的必要字段。守护进程集中的人Pod模板必须要RestartPolicy: Always(默认)。 Pod Selector 仅在某些节点上运行Pod如果指定了.spec.template.spce.nodeSelector，则守护进程控制器将在node selector匹配的节点上创建Pod。同样，如果指定了.spec.template.spec.affinity，则守护进程控制器将在与该节点关联匹配的节点上创建Pod。如果未指定任何一个，则守护进程控制器将在所有节点上创建Pod。 Daemon Pods如何调度 由守护进程集控制器调度（默认）通常，Pod运行的机器由k8s调度程序选择。然而，由守护进程集控制器创建的Pod已经选择了机器(.spec.nodeName)。 由默认调度器调度功能阶段： k8s v1.11 alpha守护进程集确保所有符合条件的节点都运行Pod的副本。 Taints and Tolerations Daemon Pods间通信守护进程集中Pod通信的一些可能模式： Push NodeIP and Known Port DNS Service 更新DaemonSet如果更改了节点标签，守护进程集会立即将Pod添加到新匹配的节点，并从新匹配的节点中删除Pod。可以修改守护进程集创建的Pod。然而，Pod不允许更新所有字段。同样，守护进程集控制器在下次创建节点时使用原始模板。你也可以删除守护进程集，若指定了--cascade=false，则会在节点上保留Pod。 守护进程集的替代方案 Init Scripts Bare Pods Static Pods Deployments 垃圾回收Garbage Collection k8s垃圾回收的作用是删除曾经拥有所有者，但不再拥有所有者的某些对象。 Owners and dependents一些k8s对象是其它对象的所有者。如副本集是一组Pod的所有者。拥有的对象称为所有者的依赖项(dependents)。每个依赖对象都有一个metadata.ownerReferences字段来指向所有者。 控制垃圾回收器如何删除依赖项删除对象时，可以指定是否也自动删除对象的依赖项。删除对象而不自动删除依赖项，则称依赖项为孤立对象(orphaned)。自动删除依赖项被称为级联删除(cascading deletion)，这有两种级联删除模式： Foreground Background 设置级联删除策略删除对象时，设置deleteOptions参数的propagationPolicy字段来控制级联删除策略。 JobsJobs - Run to Completion 作业创建一个或多个Pod，并确保指定数量的Pod成功终止。随着Pod成功完成，作业跟踪也成功完成。删除作业将清除它创建的Pod。作业还可用于并行运行多个Pod。 栗子 12345678910111213apiVersion: batch/v1kind: Jobmetadata: name: pispec: template: spec: containers: - name: pi image: perl command: ["perl", "-Mbignum=bpi", "-wle", "print bpi(2000)"] restartPolicy: Never backoffLimit: 4 123456789kubectl create -f ./job.yamljob.batch/pi createdkubectl get jobkubectl describe job/pikubectl get podkubectl logs pi-xxx Job Spec与其它k8s配置一样，Job也需要apiVersion, kind, metadata, .spec字段。 Pod Template.spec.template是.spce字段的必要项。 Pod Selector.spec.selector字段可选。 Parallel Jobs: 有三种主要类型作业 Non-parallel Jobs 通常指启动一个Pod，除非Pod失败 Pod成功终止后，作业即告完成 Parallel Jobs with a fixed completion count 为.spec.completions指定非零正值 当1-.spec.completions范围内的每个值都有一个成功的Pod时，作业就完成了 尚未实施，每个Pod都传递了1-.spec.completions范围内不同的索引 Parallel Jobs with a work queue 每个Pod独立地确定是否所有对等都完成，因此整个Job完成 当任何Pod成功终止，不会创建新的Pod 一旦至少一个Pod成功终止并且所有Pod终止，则作业成功完成 一旦任意Pod已成功退出，其它任何Pod都不应该做任何工作或输出 控制并行Controlling Parallelism 请求的并行性(.spec.parallelism)可以设置为任何非负值。如果未指定，则默认为1.如果指定为0，则作业将暂停，直至其增加。由于各种原因，实际并行性(在任何时刻运行的Pod数量)可能多于或少于请求的并行度： 对于固定完成计数的作业，并行运行的实际Pod数不会超过剩余的Pod数 对于工作多列作业，任何Pod成功后都不会启动新的Pod，但允许剩余的Pod完成 如果控制器没有时间做出反应 如果控制器因任何原因无法创建Pod 由于同一作业中过多的先前Pod故障，控制器可能会限制新的Pod创建 当Pod正常关闭时，停止需要一些时间 处理Pod和Container失败Pod中的容器可能由于多种原因而失败，如果发生此情况，并且.spec.template.spec.restartPolicy = &quot;OnFailure&quot;，那么Pod会留在节点上，但容器会重新运行。因此，你的程序需要在本地处理此情况，或指定.spec.template.spec.restartPolicy = &quot;Never&quot;。 一个完整的Pod也可能由于多种原因而失败。当Pod失败时，作业控制器启动一个新的Pod。因此，你的程序需要在新Pod重启时处理此情况。 Pod Backoff failure policy在某些情况下，由于配置中的逻辑错误等原因，你需要在重试一段时间后使作业失败。为此，可设置.spec.backoffLimit将作为视为失败前的重试次数。默认值为6s。与作业关联的失败的Pod由作业控制器重新创建，指数退避延迟(10s, 20s, 40s…)，上限6分钟。如果在作业的下一次状态检查之前没有出现新的故障Pod，则重置退避计数。 作业终止和清理Job Termination and Cleanup 作业完成后，不会再创建Pod，也不会删除Pod。保持它们可让你仍然能查看已完成的Pod的日志以检查error, warning, 或其它诊断性输出。作业对象在完成后也会保留，以便可查看其状态。在注意到其状态后，用户可删除旧的作业。 12345#一并删除作业创建的Podkubectl delete jobs/xxx#不删除作业创建的Podkubectl delete jobs/xxx -- 默认情况下，除非Pod失败，否则作业将不间断运行，此时作业将延迟到上述的.spec.backoffLimit。终止作业的另一种方法是设置活动截止日期，通过设置.spec.activateDeadlineSeconds字段来执行此操作。请注意，作业的.spec.activateDeadlineSeconds优先于.spec.backoffLimit。因此，重试一个或多个失败的Pod的作业在达到activeDeadlineSeconds指定的时间限制后将不会重置其它Pod，即使尚未达到backoffLimit也是如此。 作业模式Job Patterns 作业对象可用于支持Pod的可靠并行执行，它不是为了支持紧密通信的并行进程而设计。在复杂系统中，可能存在多组不同的工作项。这里只考虑一组工作项——批处理作业 并行计算有几种不同的模式，每种模式都有有点和缺点： 一个工作项一个作业对象 vs 所有工作项一个作业对象 创建的Pod数等于工作项数 vs 每个Pod可以处理多个工作项 多个方法使用一个工作队列 高级用法Advanced Usage 指定自己的Pod selector通常，创建作业对象时，不会指定.spec.selector。系统默认在创建作业时添加此字段。然而，在某些情况下，你可能需要设置它。这样做的时候要非常小心，如果你指定的label selector不是该作业的Pod所独有，并且与不想关的Pod匹配，则可能会删除不相关作业的Pod。如果选择了non-unique selector，则其它控制器及其Pod也可能以不可预测的方式进行。在指定.spec.selector时，k8s不会阻止你犯错误。 替代方案Alternatives Bare Pods Replication Controller Single Job starts Controller Pod Cron Jobs在指定的时间/日期创建作业。 CronJobCron Job基于时间调度创建作业。一个定时任务对象类似于crontab中的一行。它以给定的时间周期性运行作业。 注意： 所有定时作业调度， 时间以UTC表示。 定时作业局限Cron Job Limitations 定时作业在其计划的每个执行时间创建一个作业对象。如果startingDeadlineSeconds被设置为较大值或未设置(默认值)，并且concurrencyPolicy设置为Allow，则作业将始终至少运行一次。如果设置了startDeadlineSeconds字段，则控制器会计算从startingDeadlineSeconds的值到现在发生的错过的作业数，而不是从上一个计划时间到现在。如果定时作业未能在其预定时间创建，则将其视为未命中。 定时作业仅负责创建与其计划相匹配的作业，而作业则负责管理它所代表的Pod。 配置Configuration 配置最佳实践Configuration Best Practices 一般配置技巧General Configuration Tips 定义配置时，请指定最新的稳定的API版本 在推送到集群之前，配置文件应存储在版本控制系统中。这允许你在必要时快速回滚配置，有助于集群重建和恢复 使用YMAL而不是JSON来编写配置文件，YAML格式更用户友好 只要有意义，就将相关对象分组到一个文件中。管理一个文件比管理一堆文件更便捷 可以在目录上调用许多kubectl命令。例如，你可在配置文件目录上调用kubectl create 不要不必要地指定默认值 将对象描述写在注释中，以便更好进行内省 Naked Pod vs 副本集，部署和作业“Naked” Pods vs ReplicaSets, Deployments, and Jobs 不要使用Naked Pods(即未绑定到副本集或部署的Pod)如果节点发生故障，裸Pod将不会被重新调度。 服务Service 在相应的后端工作负载(部署或副本集)访问它之前创建服务当k8s启动容器时，它提供指向启动容器时正在运行的所有服务的环境变量。 除非绝对必要，否则不要为Pod指定hostPort将Pod绑定到hostPort时，它会限制Pod可调度的位置数。因为每个hostIP, hostPort, protocol的组合必须是独特的。如果没有指定hostIp和protocol，k8s将使用0.0.0.0作为默认的hostIP，使用TCP作为默认协议。 如果你只需要访问端口以进行调试，可使用apiserver proxy或kubectl port-forward。如果你需要公开节点上Pod的端口，考虑使用NodePort服务。 避免使用hostNetwork， 原因与hostPort类似 当不需要kube-proxy负载均衡时，使用 headless Services可轻松服务发现 使用标签Using Labels 为你的应用程序或部署定义和使用标签你可使用这些标签为其它资源筛选合适的Pod 容器镜像Container Images 默认的镜像拉取策略。对于容器是ifNotPresent，kubelet只有在本地镜像不存在时才拉取镜像。如果希望每次k8s启动容器时都拉取镜像，请指定imagePullPolicy: Always。一个已弃用的替代方案。设置k8s总是拉取镜像的:latest标记，它会隐式地将imagePullPolicy设置为Always。 注意： 在生产环境中部署容器时，你应该避免使用:latest标记，因为这使得正在运行的镜像版本难以回滚。如果镜像使用:latest标记，回滚的话其实需要回滚代码，然后打包上线，然后触发动态更新，之后就还原成了之前的版本。这样确实要复杂很缓慢一些。 确保容器使用使用相同版本的镜像 使用kubectl 使用kubectl apply -f &lt;directory&gt; 或 kubectl create -f &lt;directory&gt;它在此目录中所有.yaml, .yml, .json文件汇总寻找k8s配置配置文件，并将其传递给kubectl。 使用label selectors进行get和delete操作，而不是特定的对象名称 使用kubectl run和kubectl expose快速创建单容器部署和服务 管理容器的计算资源Managing Compute Resources for Containers 指定Pod时，可以选择指定每个容器需要多少CPU和MEM。当容器指定了请求(requests)的资源时，调度器可以更好地决定将Pod放在哪个节点上。当容器指定了限制(limit)时，可以以指定的方式处理节点上资源的争用。 资源类型Resource types CPU和MEM都是资源类型。资源类型具有基本单元(unix)。CPU以核(cores)为指定单位，MEM以字节(Byte)为指定单位。CPU和MEM统称为计算资源，或资源。计算资源是可以请求，分配和使用的可测量数据。它们与API资源不同。API资源(如Pod和Service)，是可通过k8s APIserver读取和修改的对象。 资源的请求和限制Resource requests and limits of Pod and Container Pod中的容器都可指定一个或多个限制： spec.containers[].resources.limits.cpu spec.containers[].resources.limits.memory spec.containers[].resources.requests.cpu spec.containers[].resources.requests.memory 虽然只能在单独的容器上指定请求和限制，但是讨论Pod资源的请求和限制很方便。特定资源类型的Pod资源 请求/限制 是Pod中每个容器的该类型的资源 请求/限制 的总和。 CPUMeaning of CPU CPU资源的限制和请求以CPU单位进行测量。在k8s中，1 cpu等于： 1 AWS vCPU 1 GCP Core 1 Azure vCore 1 IBM vCPU 1 Hyperthread on a bare-metal Intel processor with Hyperthreading 允许分数请求。如spec.containers[].resources.requests.cpu: 0.5。表达式0.1相当于表达式100m。具有小数点的请求资源(如0.1)由API转换为100m，不允许精度小于1m。始终要求CPU作为绝对数量，而不是相对数量。因此，0.1单元对于单核，双核，八核机器上的CPU资源时相同的。 MemoryMeaning of memory 内存的限制和请求以字节为单位。你可使用以下后缀来表示整数内存: E, P, T, G, M, K；你还还可以使用2的幂等: Ei, Pi, Ti, Gi, Mi, Ki。 12345#相同值的不同表达128974848129e6129M123Mi 栗子： 123456789101112131415161718192021222324252627apiVersion: v1kind: Podmetadata: name: frontendspec: containers: - name: db image: mysql env: - name: MYSQL_ROOT_PASSWORD value: &quot;password&quot; resources: requests: memory: &quot;64Mi&quot; cpu: &quot;250m&quot; limits: memory: &quot;128Mi&quot; cpu: &quot;500m&quot; - name: wp image: wordpress resources: requests: memory: &quot;64Mi&quot; cpu: &quot;250m&quot; limits: memory: &quot;128Mi&quot; cpu: &quot;500m&quot; 如何调度具有资源请求的PodHow Pods with resource requests are scheduled 创建Pod时，k8s调度器会选择要运行Pod的节点。每个节点都具有每种资源类型的最大容量，它可为Pod提供CPU和MEM。调度程序确保对于每种资源类型，调度的容器的资源请求总和小于节点的容量。请注意，即使节点上的实际内存或CPU资源使用率非常低，但如果容量检查失败，调度器扔拒绝在节点上放置Pod。当资源使用随后增加时，这可以防止节点上的资源短缺。 如何运行具有资源限制的PodHow Pods with resource limits are run 当kubelet启动Pod中的容器时，它会将CPU和MEM限制传递给容器运行环境。 当使用Docker时： spec.container[].resources.requests.cpu被转换成core value，分数的话会乘以1024。此数字中的较大值用作docker run命令中--cpu-shares标志的值 spec.container[].resources.limits.cpu被转换为millicore value并乘以100。结果值代表容器每100ms可以使用的CPU时间总量。在此间隔期间，容器不能使用超过其CPU时间的份额。默认配额时间是100ms，CPU配额的最小解析为1ms。 spec.containers[].resources.limits.memory被转换为整数，并用作docker run命令中--memory标志的值 如果容器超出其内存限制(mem limit)，则容器可能会终止。如果它可以重启，则kubelet将重启它；如果容器超出其内存请求(mem request)，当节点内存不足时，它的Pod可能会被驱逐；容器可能会/可能不会被允许在较长时间内超过其CPU限制。但是，它不会因CPU使用率过高而被杀死。 监控计算资源使用Monitoring compute resource usage Pod的资源使用情况将作为Pod Status的一部分进行上报。 本地短暂存储Local ephemeral storage FEATURE STATE: Kubernetes v1.11 beta k8s v1.8介绍了一种新资源，用于管理本地短暂存储的短暂存储(ephemeral-storage)。在每个k8s 节点上，kubelet的根目录(默认/var/lib/kubelet)和日志目录(/var/log)存储在节点的根分区上。Pod还通过emptyDir volume，容器日志，镜像层，容器可写层共享和使用此分区。此分区是短暂的，应用程序不能指望来自此分区的任何SLA(如磁盘IO)。本地临时存储仅适用于根分区，镜像层和可写层的可选分区超出了范围。 本地短暂存储的请求和限制设置Requests and limits setting for local ephemeral storage Pod中的容器可指定一个或多个短暂存储： spec.containers[].resources.limits.ephemeral-storage spec.containers[].resources.requests.ephemeral-storage 短暂存储的限制和请求以字节(Byte)为单位。你可以使用一下后缀表示整数存储: E, P, T, G, M, K；你也可以使用2的幂等: Ei, Pi, Ti, Gi, Mi, Ki。 1234128974848129e6129M123Mi 栗子： Pod由两个容器，每个容器都有2GiB的本地短暂存储请求，4GiB的本地短暂存储限制。因此，总共是4GiB请求，8GiB限制。 1234567891011121314151617181920212223apiVersion: v1kind: Podmetadata: name: frontendspec: containers: - name: db image: mysql env: - name: MYSQL_ROOT_PASSWORD value: &quot;password&quot; resources: requests: ephemeral-storage: &quot;2Gi&quot; limits: ephemeral-storage: &quot;4Gi&quot; - name: wp image: wordpress resources: requests: ephemeral-storage: &quot;2Gi&quot; limits: ephemeral-storage: &quot;4Gi&quot; 如何调度具有本地短暂存储的PodHow Pods with ephemeral-storage requests are scheduled 对于容器级的隔离，如果容器的可写层和日志使用量超过其存储限制，则Pod将被驱逐。对于Pod级别的隔离，如果所有容器的本地短暂存储使用量与Pod的emptyDir volume的总和超过了限制，则Pod将被驱逐。 扩展的资源Extended resources 扩展资源是kubernetes.io域之外的完全限定资源名称。它们允许集群操作者通告和用户使用非k8s内置资源。使用扩展资源需要两个步骤，首先，集群操作者必须通告扩展资源；其次，用户必须在Pod中请求扩展资源。 节点级扩展资源节点级扩展资源与节点相关联。 集群级扩展资源集群级扩展资源不依赖与节点。它们通常由调度器扩展程序管理——它处理资源消耗和资源配额。 使用扩展资源用户可以在pod spec中项CPU和MEM一样使用扩展资源。调度程序负责资源核算，以便不会同时为Pod分配可用的数量。API server将扩展资源的数量限制为整数。 要在Pod中使用扩展资源，在container spec中的spec.container[].resources.limits映射中包含资源名称作为键。只有满足所有请求资源时，才会调度Pod。只要无法满足资源请求，Pod就会保持在PENDING status。 1234567891011121314apiVersion: v1kind: Podmetadata: name: my-podspec: containers: - name: my-container image: myimage resources: requests: cpu: 2 example.com/foo: 1 limits: example.com/foo: 1 分配Pod到节点Assigning Pods to Nodes 你可以将Pod约束为只能在特定节点上运行，或更喜欢在特定节点上运行。有几种方法做到这一点，它们都使用label selector来进行选择。通常这种约束是不必要的，因为调度程序将自动进行合理的放置。但在某些情况下，你可能希望对Pod放置的节点进行更多控制。如确保Pod放置在安装有SSD的计算机上… 节点选择器nodeSelector 节点选择器是最简单的约束形式。nodeSelector是PodSpecs的一个字段，它指定了一个键值对的映射。要使Pod有资格在节点上运行，该节点必须将每个指示的的键值对作为标签。最常见的用法是一个键值对。 Prerequisitesk8s 集群 Attach label to the node 12345678910111213#获取节点名kubectl get nodeNAME STATUS ROLES AGE VERSIONmaster Ready master 33d v1.11.1node Ready &lt;none&gt; 33d v1.11.1salt01 Ready &lt;none&gt; 27d v1.11.1#打标签kubectl label nodes &lt;node-name&gt; &lt;label-key&gt;=&lt;label-value&gt;#查看标签kubectl get node --show-labels Add a nodeSelector field to your pod configuration 12345678910111213apiVersion: v1kind: Podmetadata: name: nginx labels: env: testspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent nodeSelector: &lt;label-key&gt;: &lt;label-value&gt; 当创建这个资源时，Pod将调度到附加此标签的节点上。 内置节点标签built-in node labels 除了你附加的标签之外，节点还有一些预先填充的标准标签。 kubernetes.io/hostname failure-domain.beta.kubernetes.io/zone failure-domain.beta.kubernetes.io/region beta.kubernetes.io/instance-type beta.kubernetes.io/os beta.kubernetes.io/arch 亲和力和反亲和力Affinity and anti-affinity 节点选择器提供了一种非常简单的方法，使用特定标签约束Pod到特定节点。目前处于测试阶段的亲和力/反亲和力功能，极大地扩展了你可以表达的约束类型。关键的改进有： 语言更具表达性 你可以指示规则是soft/preference而不是硬性要求，因此如果调度程序不能满足，也仍然会调度Pod 你可以约束运行在节点上的其它Pod的标签，而不是对节点本身的标签进行约束 亲和力有两种类型： node-affinity inter-pod affinity/anti-affinity 节点亲和力节点亲和力在概念上类似于nodeSelector，它允许你根据节点标签约束pod调度的节点。目前有两种类型的节点亲和力： requiredDuringSchedulingIgnoredDuringExecution preferredDuringSchedulingIgnoredDuringExecution 你可将它们分别是为hard和soft，前者指定了将Pod调度到节点上必须满足的规则，后者指定调度程序将尝试执行但不保证的首选项。名称的IgnoredDuringExecution部分意味着，与节点选择器的工作方式类似，如果节点标签在运行时更改，而不再满足Pod的亲和力规则，则Pod将继续在节点上运行。未来，我们计划提供requiredDuringSchedulingRequiredDuringExecution，就像Ignored一样，它将从不再满足Pod的亲和力要求的节点中驱逐Pod。 节点亲和力在spec.affinity.nodeAffinity字段中指定： 1234567891011121314151617181920212223242526apiVersion: v1kind: Podmetadata: name: with-node-affinityspec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/e2e-az-name operator: In values: - e2e-az1 - e2e-az2 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: another-node-label-key operator: In values: - another-node-label-value containers: - name: with-node-affinity image: k8s.gcr.io/pause:2.0 此节点亲和力规则表示，Pod只能防止在kubernetes.io/e2e-az-name标签键，值为e2e-az1或e2e-az2的节点上。此外，在满足条件的节点中，应优先选择具有another-node-label-key键，值为another-node-label-value的节点。节点亲和力语法支持如下操作符: In, NotIn, Exists, DoesNotExist, Gt, Lt。 如果你同时指定了nodeSelector和nodeAffinity，则必须满足两者以将Pod调度到候选节点上；如果你指定了与nodeAffinity类型关联的多个nodeSelectorTerms。那么，如果满足其中一个nodeSelectorTerms，则可以将Pod调度到节点上；如果你指定了与nodeSelectorTerms关联的多个matchExpressions。那么，只有满足所有matchExpressions的情况下，才能将Pod安排到节点上；如果删除或更改调度Pod的节点标签，则Pod不会被删除。换句话说，亲和力仅在调度Pod时起作用。 Pod间亲和力和反亲和力Pod间亲和力和反亲和力，你可以根据已在节点上运行的Pod上的标签(而不是节点标签)，来约束Pod可以调度的节点。与节点不同，Pod有命名空间，Pod标签的标签选择器必须指定选择器应该应用于哪些命名空间。 注意： Pod间亲和力和反亲和力需要大量的处理，可会显著减慢大型集群中的调度。因此，不建议在大于几百个节点的集群中使用；注意： Pod反亲和力要求节点一致地标签节点，即集群中的每个节点都必须具有匹配的topologyKey标签，如果某些节点缺少，可能会导致意外情况。 目前有两种类型的Pod亲和力和反亲和力: requiredDuringSchedulingIgnoredDuringExecution preferredDuringSchedulingIgnoredDuringExecution 同样表示hard和soft要求。 1234567891011121314151617181920212223242526272829apiVersion: v1kind: Podmetadata: name: with-pod-affinityspec: affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: security operator: In values: - S1 topologyKey: failure-domain.beta.kubernetes.io/zone podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: security operator: In values: - S2 topologyKey: kubernetes.io/hostname containers: - name: with-pod-affinity image: k8s.gcr.io/pause:2.0 Pod亲和力和反亲和力的有效操作符有: In, NotIn, Exists, DoesNotExist原则上，topologyKey可以是任一合法的label-key。但是，出于性能和安全的原因，它也有一些限制： 对于亲和力和requiredDuringSchedulingIgnoredDuringExecution的Pod的反亲和力，不允许使用空的topologykey 对于requiredDuringSchedulingIgnoredDuringExecution的Pod的反亲和力，引入控制器LimitPodHardAntiAffinityTopology是为了将topologyKey限制为kubernetes.io/hostname。如果要使其可用于自定义，可修改控制器，或禁用它 对于preferredDuringSchedulingIgnoredDuringExecution的Pod的反亲和力，空的topologyKey被解释为all topologies 除了上面提到的，topologyKey可以是任一合法的label-key 除了labelSelector和topologyKey之外，你还可以选择指定labelSelector应匹配的命名空间。如果为空或省略，则默认为Pod的亲和力/反亲和力的命名空间。 污点和容忍Taints and Tolerations 节点亲和力是Pod的属性，它将它们吸引到节点；Taints则相反——它允许节点排斥Pod。Taints 和 Tolerations 一起工作以确保Pod不被安排的不适当的节点上。将一个或多个污点(taints)应用于节点，这标志着节点不应该接受任何不能容忍污点的Pod。容忍(tolerations)应用于Pod，并允许Pod安排到具有匹配污点的节点上。 概念使用kubectl taint命令对节点添加污染: 123456#除非具有匹配的容忍，否则不会将Pod调度到此节点上kubectl taint nodes &lt;node-name&gt; key=value:NoSchedule#删除kubectl taint nodes &lt;node-name&gt; key:NoSchedule- 你可以在PodSpec的指定Pod的容忍度： 12345tolerations:- key: &quot;key&quot; operator: &quot;Equal&quot; #default value: &quot;value&quot; effect: &quot;NoSchedule&quot; 1234tolerations:- key: &quot;key&quot; operator: &quot;Exists&quot; effect: &quot;NoSchedule&quot; effect的三个选项： NoSchedule PreferNoSchedule: soft of NoSchedule NoExecute 你可在同一个节点上放置多个污点，并在同一个Pod上放置多个容忍。k8s处理多个污点和容忍的方式就像一个过滤器：从节点的所有污点开始，忽略Pod匹配的容忍度的那些，剩下的未被忽略的污点对Pod有明显的影响。尤其是： 如果至少有一个未被忽略的effect为NoSchedule的污点，则k8s将不会调度Pod到该节点 如果没有effect为NoSchedule，但至少有一个未被忽略的effect为PreferNoSchedule的污点，则k8s将尝试不将Pod调度到该节点 如果至少有一个未被忽略的effect为NoExecute的污点，则Pod将从节点驱逐(如果它已经在节点上运行)，并且不会被调度到该节点上 栗子： 123kubectl taint nodes node1 key1=value1:NoSchedulekubectl taint nodes node1 key1=value1:NoExecutekubectl taint nodes node1 key2=value2:NoSchedule 有两个容忍度的Pod： 123456789tolerations:- key: "key1" operator: "Equal" value: "value1" effect: "NoSchedule"- key: "key1" operator: "Equal" value: "value1" effect: "NoExecute" 对于NoExecute的容忍度可以指定一个可选tolerationSeconds字段，它指示在添加污点后Pod将保持绑定到节点的时间： 123456tolerations:- key: "key1" operator: "Equal" value: "value1" effect: "NoExecute" tolerationSeconds: 3600 使用案例Example Use Cases 污点和容忍是一种灵活的方式来引导Pod远离节点或驱逐不应该运行的Pod。一些栗子： 专用节点(Dedicated Nodes) 特殊硬件的节点(Nodes with Special Hardware) 基于污点的驱逐(Taint based Evictions) Taint based Evictions内置的污点： node.kubernetes.io/not-ready node.kubernetes.io/unreachable node.kubernetes.io/out-of-disk node.kubernetes.io/memory-pressure node.kubernetes.io/disk-pressure node.kubernetes.io/network-unavailable node.kubernetes.io/unschedulable node.cloudprovider.kubernetes.io/uninitialized 使用NoExecute容忍的DaemonSet Pod为以下污点创建，没有tolerationSeconds： node.alpha.kubernetes.io/unreachable node.kubernetes.io/not-ready 这可确保DaemonSet Pod永远不会因为这个问题而被驱逐，这与禁用此功能时的行为相匹配。 按条件污染节点Taint Nodes by Condition 节点控制器创建对应于节点条件的污点。当启用此功能，调度程序不检查节点条件，调度程序检查污点。这可确保节点条件不会影响节点上的调度。用户可以通过添加适当的Pod容忍来选择忽略节点的一些问题。 DaemonSet controller自动将一下NoSchedule的容忍度添加到所有的守护进程，以防止守护进程破坏： node.kubernetes.io/memory-pressure node.kubernetes.io/disk-pressure node.kubernetes.io/out-of-disk (only for critical pods) node.kubernetes.io/unschedulable (1.10 or later) node.kubernetes.io/network-unavailable (host network only) 添加这些容忍度可确保向后兼容，你还可以向DaemonSet添加任意容忍度。 SecretsSecrets类型的对象旨在保存敏感信息，如密码、OAuth token、ssh keys。把这些敏感信息放在Secrets中比将其放在Pod中或image中更安全、更灵活。 概述用户和系统都可以创建一些秘密(Secrets)。要使用秘密，Pod需要引用该秘密。秘密可以通过两种方式与Pod一起使用： 作为挂载到容器中的卷中的文件 为Pod拉取镜像时由kubelet使用的文件 内建的秘密Built-in Secrets Service Accounts Automatically Create and Attach Secrets with API Credentialsk8s会自动创建包含用于访问API的证书的秘密，并自动修改Pod以使用此类秘密。你可禁用它，但不推荐。 创建自己的秘密Creating your own Secrets 使用kubectl创建秘密(Creating a Secret Using kubectl create secret)假设一些Pod需要访问数据库： 12345678910111213141516171819202122232425$ echo -n &apos;admin&apos; &gt; ./username.txt$ echo -n &apos;1f2d1e2e67df&apos; &gt; ./password.txt#创建秘密$ kubectl create secret generic db-user-pass --from-file=./username.txt --from-file=./password.txtsecret/db-user-pass created#查看#默认都不会显示文件内容，为了安全kubectl get secretskubectl describe secrets/db-user-passName: db-user-passNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Type: OpaqueData====password.txt: 12 bytesusername.txt: 5 bytes 手动创建秘密(Creating a Secret Manually)每项必须是base64编码： 123456789101112131415161718192021$ echo -n &apos;admin&apos; | base64YWRtaW4=$ echo -n &apos;1f2d1e2e67df&apos; | base64MWYyZDFlMmU2N2Rm#现在编写一个秘密对象文件#db-user-pass.yamlapiVersion: v1kind: Secretmetadata: name: mysecrettype: Opaquedata: username: YWRtaW4= password: MWYyZDFlMmU2N2Rm#创建它$ kubectl create -f ./secret.yamlsecret &quot;mysecret&quot; created 解码秘密(Decoding a Secret) 12345678910111213141516171819kubectl get secret mysecret -o yamlapiVersion: v1data: username: YWRtaW4= password: MWYyZDFlMmU2N2Rmkind: Secretmetadata: creationTimestamp: 2016-01-22T18:41:56Z name: mysecret namespace: default resourceVersion: &quot;164619&quot; selfLink: /api/v1/namespaces/default/secrets/mysecret uid: cfee02d6-c137-11e5-8d73-42010af00002type: Opaque#解码$ echo &apos;MWYyZDFlMmU2N2Rm&apos; | base64 --decode1f2d1e2e67df 使用秘密Using Secrets秘密可以作为数据卷来挂载，也可作为环境变量公开，以供Pod中的容器使用。它们也可以由系统的其它部分使用，而不是直接暴露在Pod中。 将秘密用作Pod中的文件(Using Secrets as Files from a Pod)在Pod中的卷中使用秘密： 创建或使用已有的秘密。多个Pod可以引用相同的秘密 修改Pod定义以添加卷和挂载卷 修改镜像或命令行，以便程序在该挂载目录中查找文件 栗子： 12345678910111213141516apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: mypod image: redis volumeMounts: - name: foo mountPath: "/etc/foo" readOnly: true volumes: - name: foo secret: secretName: mysecret 向指定路径投射密钥(Projection of secret keys to specific paths)栗子： 123456789101112131415161718192021apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: mypod image: redis volumeMounts: - name: foo mountPath: "/etc/foo" readOnly: true volumes: - name: foo secret: secretName: mysecret items: - key: username path: my-group/my-username#username秘密存储在/etc/foo/my-group/my-username而不是/etc/foo/username#password秘密没有投射 **秘密文件权限(Secret files permissions)你还可以指定秘密所具有的的权限: 12345678910111213141516apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: mypod image: redis volumeMounts: - name: foo mountPath: "/etc/foo" volumes: - name: foo secret: secretName: mysecret defaultMode: 256 #0400(八进制) 12345678910111213141516171819apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: mypod image: redis volumeMounts: - name: foo mountPath: "/etc/foo" volumes: - name: foo secret: secretName: mysecret items: - key: username path: my-group/my-username mode: 511 #0777 从卷中使用秘密值(Consuming Secret Values from Volumes)在挂载秘密卷的容器内，密钥显示为文件，秘密值基于base64进行解码并存储在这些文件中。 1234567$ ls /etc/foo/usernamepassword$ cat /etc/foo/usernameadmin$ cat /etc/foo/password1f2d1e2e67df 挂载的秘密会自动更新(Mounted Secrets are updated automatically) 当更新卷中已经使用的秘密时，最终也会更新投射的密钥。 使用秘密作为环境变量(Using Secrets as Environment Variables)要在Pod中的环境变量中使用秘密： 创建或使用已有的秘密。多个Pod可引用同一个秘密 修改Pod定义 修改Image或命令行，以便程序在指定的环境变量中查找值 栗子： 1234567891011121314151617181920apiVersion: v1kind: Podmetadata: name: secret-env-podspec: containers: - name: mycontainer image: redis env: - name: SECRET_USERNAME valueFrom: secretKeyRef: name: mysecret key: username - name: SECRET_PASSWORD valueFrom: secretKeyRef: name: mysecret key: password restartPolicy: Never 从环境变量中使用秘密值Consuming Secret Values from Environment Variables 容器内使用的环境变量的秘密值，它显示为base64的解码值。 1234$ echo $SECRET_USERNAMEadmin$ echo $SECRET_PASSWORD1f2d1e2e67df Using imagePullSecretsimagePullSecret是一种包含docker image registry password的秘密传递给kubelet的方法，因此它可以用于Pod拉取你的私有镜像。 细节 限制Restrictions 验证密钥卷源以确保指定的对象引用实际指向的秘密类型对象。因此，需要在任何Pod依赖它之前先创建秘密。Secret API对象驻留在命名空间中，它们只能由同一命名空间中的Pod引用。单个秘密的大小被限制为1MB。这是为了阻止创建非常大的秘密，这会耗尽apiserver和kubelet的内存。然而，创建许多小的秘密也可能耗尽内存。更多关于限制秘密对内存的使用是未来的计划功能。kubelet仅支持使用从apiserver获取的Pod秘密。这包含由kubectl创建的秘密，不包含通过--manifest-url标志或REST API创建的秘密。 Secret和Pod的终生交互Secret and Pod Lifetime interaction 通过API创建Pod时，不会检查引用的秘密是否存在。一旦调度了Pod，kubelet将尝试获取秘密值。如果由于该秘密不存在或暂时缺少与apiserver的连接而无法获取该秘密，则kubelet将定期重试。它将报告有关Pod的事件，说明它尚未启动的原因。一旦获取到秘密，kubelet将创建并挂载包含它的卷，在挂载所有Pod的卷之前，Pod的容器都不会启动。 使用案例 Pod with ssh keys 1234567891011121314151617181920212223#创建包含ssh keys的秘密kubectl create secret generic ssh-key-secret --from-file=ssh-privatekey=/path/to/.ssh/id_rsa --from-file=ssh-publickey=/path/to/.ssh/id_rsa.pub#创建引用此秘密的Podkind: PodapiVersion: v1metadata: name: secret-test-pod labels: name: secret-testspec: volumes: - name: secret-volume secret: secretName: ssh-key-secret containers: - name: ssh-test-container image: mySshImage volumeMounts: - name: secret-volume readOnly: true mountPath: &quot;/etc/secret-volume&quot; Pods with prod / test credentials 12345678910111213141516171819202122232425262728293031323334353637383940414243444546$ kubectl create secret generic prod-db-secret --from-literal=username=produser --from-literal=password=Y4nys7f11secret &quot;prod-db-secret&quot; created$ kubectl create secret generic test-db-secret --from-literal=username=testuser --from-literal=password=iluvtestssecret &quot;test-db-secret&quot; created#Pod中引用apiVersion: v1kind: Listitems:- kind: Pod apiVersion: v1 metadata: name: prod-db-client-pod labels: name: prod-db-client spec: volumes: - name: secret-volume secret: secretName: prod-db-secret containers: - name: db-client-container image: myClientImage volumeMounts: - name: secret-volume readOnly: true mountPath: &quot;/etc/secret-volume&quot;- kind: Pod apiVersion: v1 metadata: name: test-db-client-pod labels: name: test-db-client spec: volumes: - name: secret-volume secret: secretName: test-db-secret containers: - name: db-client-container image: myClientImage volumeMounts: - name: secret-volume readOnly: true mountPath: &quot;/etc/secret-volume&quot; Dotfiles in secret volume隐藏文件 123456789101112131415161718192021222324252627kind: SecretapiVersion: v1metadata: name: dotfile-secretdata: .secret-file: dmFsdWUtMg0KDQo=---kind: PodapiVersion: v1metadata: name: secret-dotfiles-podspec: volumes: - name: secret-volume secret: secretName: dotfile-secret containers: - name: dotfile-test-container image: k8s.gcr.io/busybox command: - ls - &quot;-l&quot; - &quot;/etc/secret-volume&quot; volumeMounts: - name: secret-volume readOnly: true mountPath: &quot;/etc/secret-volume&quot; Secret visible to one container in a pod考虑一个需要处理HTTP请求，执行一些复杂业务逻辑，然后使用HMAC签署一些消息的程序。由于它具有复杂的逻辑，因此可能存在未被注意的文件读取漏洞，这可能会将私钥暴露给攻击者。 这可以分为两个容器中的两个进程： 前端容器处理用户交互和业务逻辑，但无法看到私钥 后端容器可查看签名的私钥，并相应来自前端的签名请求 最佳做法Clients that use the secrets API 在部署与Secret API交互的应用程序时，应使用RBAC等授权策略限制访问。 安全属性保护由于可以独立于P使用秘密的Pod来创建秘密，因此在创建、查看、编辑Pod的工作流程中泄露秘密的风险较小。系统还可以对秘密对象采取额外的预防措施，如尽可能避免将其写入磁盘。如果节点上的Pod需要秘密，则仅将秘密发送到节点。它不会写入磁盘，而是存储在tmpfs中(RAM)。一旦删除依赖它的Pod，它就会被删除。节点上的秘密数据存储在tmpfs volume中，因此不会停留在节点上。在大多数k8s项目维护的发行版中，用于与apiserver之间的通信，以及apiserver到kubelet的通信受到SSL/TLS保护。同一节点上可能存在多个Pod的秘密，但是，只有Pod请求的密码可能在其容器中可见。因此，一个Pod无法访问另一个Pod的秘密。同一个Pod中可能有几个容器，但是，Pod中的每个容器都必须在其volumeMounts中请求秘密卷，以使其在容器中可见。 风险 apiserver中，秘密数据以明文形式存储在etcd中。因此： 管理员应该限制用户对etcd的访问权限 apiserver中的秘密数据在etcd使用的磁盘上处于静止状态；管理员可能想要在不再使用时擦除etcd使用的磁盘 如果通过json/yaml文件配置秘密，该文件的秘密数据的编码为base64，则该秘密可能被泄露。base64编码不是加密方法，被认为与纯文本相同 应用程序仍然需要在从卷读取秘密值后保护它 可创建使用秘密的Pod的用户也可看到秘密的值 如果运行了etcd的多个副本，则它们之间将共享秘密 目前，任何在节点上具有root权限的用户都可以模拟kubelet从apiserver中读取任何秘密 使用kubeconfig文件组织集群访问Organizing Cluster Access Using kubeconfig Files 使用kubeconfig文件来组织有关集群、用户、命名空间、身份验证机制的信息。kubectl使用kubeconfig文件来查找选择集群并与集群apiserver通信所需的信息。用于配置对集群的访问的文件称为kubeconfig。这是引用配置文件的普通方法，这并不意味着有一个名为kubeconfig的文件。 默认情况下，kubectl从$HOME/.kube目录下查找名为config的文件。你可以通过--kubeconfig标志设置KUBECONFIG环境变量来指定kubeconfig文件。 支持多集群、用户、认证机制Supporting multiple clusters, users, and authentication mechanisms 假设你有多个集群，并且用户和组件以各种方式进行认证： 正在运行的kubelet可能使用证书进行认证 用户可能使用令牌认证 管理员可能拥有他为用户提供的证书集 使用kubeconfig，你可以组织集群、用户和命名空间。你还可以定义上下文，以便在集群和命名空间之间快速进行切换。 上下文kubeconfig文件中的上下文元素用于在方便的名称下对访问参数进行分组。每个上下文都有三个参数：集群、命名空间、用户。默认情况下，kubectl使用从当前上下文的参数与集群通信。 12#Modify kubeconfig fileskubectl config -h KUBECONFIG环境变量$KUBECONFIG环境变量包含kubeconfig文件列表，它不是必须的。如果不存在，则kubectl使用默认的$HOME/.kube/config；如果存在，则kubectl使用有效配置。在Linux/Mac上使用冒号分隔，Windows使用分号分隔。 12echo $KUBECONFIG/etc/kubernetes/admin.conf 合并kubeconfig文件Merging kubeconfig files 12#查看配置kubectl config view 如果设置了--kubeconfig标志，则仅使用指定的文件。不合并，只允许此标志的一个实例。 否则，如果设置了$KUBECONFIG环境变量，将其应用于合并的文件列表。遵循以下规则： 忽略空文件名 对包含无法反序列化内容的文件生成错误 设置成特定值或映射见的第一个文件获胜 切勿修改值或映射键 否则，使用默认的$HOME/.kube/config文件，不做合并 Pod优先级和抢占Pod Priority and Preemption FEATURE STATE: Kubernetes 1.8 alphaFEATURE STATE: Kubernetes 1.11 beta Pod也有优先级，优先级表示Pod相对于其它Pod的重要性。如果无法调度Pod，则调度程序会尝试抢占(驱逐)较低优先级的Pod，以便可以处理待调度(Pending)的Pod。优先级还会影响Pod的调度顺序和节点上的资源驱逐顺序。 使用优先级和抢占How to use priority and preemption 要在k8s v1.11+使用优先级和抢占，遵循以下步骤： 添加一个或多个优先级类(PriorityClassed) 创建带有priorityClassName的Pod设置为添加的优先级类之一。当然，你不需要直接创建Pod，通常你只需要将priorityClassName添加到对象的Pod模板(如deployment) 禁用抢占How to disable preemption 禁用Pod优先级和抢占要禁用Pod优先级，请为apiserver、调度程序、kubelet将该功能设置false——--feature-gates=PodPriority=false 仅禁用抢占在k8s v1.11+，抢占由kube-scheduler的disablePreemption标志控制，默认设置为fasle。 12345678apiVersion: componentconfig/v1alpha1kind: KubeSchedulerConfigurationalgorithmSource: provider: DefaultProvider...disablePreemption: true PriorityClass优先级类(priorityClass)是一个非命名空间的对象，它定义从优先级类名到优先级的整数值的映射。该名称在PriorityClass对象的metadata的name字段中指定，必须的值在value字段中定义。值越高，优先级越高。优先级类对象可以具有小于等于10亿的任何32位整数值。较大的数字保留给通常不会被抢占或驱逐的系统Pod。集群管理员应为他们想要的每个这样的映射创建一个优先级类对象。优先级类有两个可选字段： globalDefault： 表示该优先级类的值应该用于没有priorityClassName的Pod，系统中只能有一个globalDefault为true的Pod。如果没有设置为globalDefault的优先级类，则Pod的优先级为零。 description： 旨在告诉用户何时应该使用此优先级类 有关PodPriority和现有集群的说明： 如果升级现有集群并启用此功能，则现有的Pod的优先级实际上为零 将globalDefault设置为true的优先级类添加将不会更改现有Pod的优先级。它的值仅用于添加优先级类之后创建的Pod 如果删除优先级类，则使用已删除的优先级类名称的现有Pod保持不变，但无法创建使用已删除的优先级类名称的Pod 栗子： 1234567apiVersion: scheduling.k8s.io/v1beta1kind: PriorityClassmetadata: name: high-priorityvalue: 1000000globalDefault: falsedescription: &quot;This priority class should be used for XYZ service pods only.&quot; Pod priority当有一个或多个优先级类之后，你就可以创建在spec中指定priority class name的Pod。优先级许可控制器使用priorityClassName字段并填充优先级的整数值。如果为找到优先级，则决绝Pod。 栗子： 123456789101112apiVersion: v1kind: Podmetadata: name: nginx labels: env: testspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent priorityClassName: high-priority Pod优先级对调度顺序的影响启用Pod优先级后，调度程序按其优先级对挂起的Pod进行排序，并将挂起的Pod置于调度队列中优先级较低的其它挂起Pod之前。因此，如果满足调度要求，则优先级较低的Pod可以更快地安排具有较低优先级的Pod。如果无法调度此类Pod，则调度程序将继续并尝试安排其它较低优先级的Pod。 Preemption创建Pod时，它们会进入队列并等待调度。调度程序从队列中选择一个Pod并尝试在节点上调度它。如果未找到满足Pod的所有指定要求的节点，则会为挂起的Pod触发抢占逻辑。抢占逻辑试图找到一个节点，其中删除优先级低于Pod P的一个或多个Pod，使得能够在该节点上调度Pod P。如果找到了此节点，则会删除那些Pod，在他们消失后，可在节点上调度Pod P。 用户公开的信息User exposed information 当Pod P在节点上抢占一个或多个Pod时，Pod P的状态的nominatedNodeName字段被设置为节点的名称。该字段帮助调度器追踪为Pod P保留的资源，并且还向用户提供关于其集群中的抢占信息。请注意，Pod P不一定安排到nominated node。在受害Pod被抢占后，它们将获得优雅的终止期。如果在调度程序等待受害Pod终止时另一个节点可用，则调度程序将使用另一个节点来调度Pod P。因此，Pod spec中的nominatedNodeName和nodeName并不总是相同。此外，如果调度程序在节点上抢占Pod，然后有比Pod P更高优先级的Pod到达，则调度程序可以将节点提供给新的更高优先级的Pod。 抢占的局限性Limitations of preemption Graceful termination of preemption victims PodDisruptionBudget is supported, but not guaranteed! Inter-Pod affinity on lower-priority Pods Cross node preemption 调试Pod优先级和抢占优先级和抢占可能会引起潜在的问题： Pods are preempted unnecessarily Pods are preempted, but the preemptor is not scheduled Higher priority Pods are preempted before lower priority pods Pod优先级和QoS的交互Interactions of Pod priority and QoS 调度程序的抢占逻辑在选择抢占目标是会考虑QoS。考虑QoS和Pod优先级的唯一组件kubelet out of resource驱逐。kubelet首先根据他们对饥饿资源的使用是否超过请求，然后按优先级，通过相对于Pod的调度请求消耗的计算资源来排除Pod的驱逐。kubelet资源溢出驱逐不会驱逐资源使用不超过其请求的Pod。如果 优先级较低的未超过其请求，则不会被驱逐。另一个优先级高高于其请求的Pod可能被驱逐。 服务，负载均衡和网络Services, Load Balancing, and Networking Servicesk8s Pod是会死的，从出生到死亡，它们没有复活(resurrected)。副本集特别地动态创建和销毁Pod。虽然每个Pod都有自己的IP，但即使是那些IP也不能依赖它们随时间变得稳定。这导致一个问题，如果某些Pod为k8s集群内的其它Pod提供功能，那么它们如何找出并追踪它们呢？这就需要用到服务了。 k8s 服务是一个抽象，它定义了一组逻辑Pod和一个访问它们的策略，有时称为微服务(micro-service)。服务目标的Pod由Label Selector来确定。 对于原生k8s应用程序，k8s提供了提供了一个简单的Endpoints API，只要服务中的Pod集发生变化，它就会更新。对于非原生k8s应用程序，k8s提供了一个基于虚拟IP的服务桥接器，可以重定向到后端的Pod。 定义服务Defining a service k8s中的服务是一个REST对象，类似于Pod。与所有REST对象一样，可以将服务定义POST到apiserver以创建实例。 例如： 1234567891011kind: ServiceapiVersion: v1metadata: name: my-servicespec: selector: app: MyApp ports: - protocol: TCP port: 80 targetPort: 9376 此规范会创建一个名为my-service的服务对象，该对象使用app=MyApp的标签定位任何Pod上的TCP协议9376端口。服务还将分配一个IP地址(称为cluster IP)，由服务代理(service proxy)使用。将连续评估服务的selector，并将结果POST到名为my-service的Endpoints对象。请注意，服务可以将传入端口映射到任何targetPort。默认情况下，targetPort将设置为与port字段相同的值。也许更有趣的是targetPort可以是一个字符串，指的是后端Pod中端口的名称。分配给该名称的实际端口号在每个后端Pod中可以不同。这为部署和发展你的服务提供了很大的灵活性。例如，你可以更改Pod的后端软件中公开的端口号，而不会破坏客户端。k8s 服务支持TCP和UDP协议，默认是TCP。 Services without selectors服务通常抽象访问k8s Pods，但它们也可以抽象访问其它类型的后端。例如： 你希望在生产环境中拥有外部数据库集群，但在测试环境中你使用自己的数据库 你希望将服务指向另外的命名空间或集群 你正在将工作负载迁移到k8s，并且你的一些后端运行在k8s之外 在任何方案中，你都可以定义不带选择器(selector)的服务： 123456789kind: ServiceapiVersion: v1metadata: name: my-servicespec: ports: - protocol: TCP port: 80 targetPort: 9376 由于此服务没有选择器(selector)，因此不会创建相应的Endpoints对象。你可以手动将服务映射到你自己的特定端点： 123456789kind: EndpointsapiVersion: v1metadata: name: my-servicesubsets: - addresses: - ip: 1.2.3.4 ports: - port: 9376 在没有选择器的情况下访问服务的工作方式与使用选择器的方式相同。流量都会被路由到定义的端点。 ExternalName service是一种特殊的服务案例，它没有选择器并且使用DNS名称代替。 虚拟IP和服务代理Virtual IPs and service proxies 在k8s v1.0中，服务是四层构造(tcp/udp)，代理纯粹实在用户空间中。在k8s v1.1中，添加了Ingress API来表示七层服务(HTTP)，也添加了iptables proxy。并成为k8s v1.2的默认操作模式。在k8s v1.8.0中，添加了ipvs proxy。 k8s 集群中的每个节点都运行一个kube-proxy——它负责为ExternalName以外类型的服务实现一种形式的虚拟IP。在任何这些代理模式中，绑定到服务的ip:port的任何流量都将代理到适当的后端，而客户端不知道有关k8s或服务或Pod的任何信息。 Proxy-mode: userspace 在userspace模式下，kube-proxy会监视k8s master以添加和删除Service和Endpoints对象。对于每个服务，它在本地节点上打开一个端口(随机选择)。与此proxy port的任何连接都将代理到服务后端的Pod之一，并根据服务的SessionAffinity决定使用哪个后端Pod。最后，它将安装iptables规则，捕获流量到服务的cluster IP(虚拟IP)，并将流量重定向到代理后端Pod的代理端口。默认情况下，后端的选择是轮询(round robin)。 Proxy-mode: iptables 在iptables模式下，kube-proxy会监视k8s master以添加和删除Service和Endpoint对象。对于每个服务，它将安装iptables规则，捕获流量到服务的cluster IP和端口，并将流量重定向到服务的后端集之一。对于每个Endpoint对象，它会按照选择后端Pod的iptables规则。默认情况下，后端的选择是随机的。显然，iptables不需要再用户空间(userspace)和内核空间(kernelspace)之间切换，它应该比用户空间代理更快更可靠。然而，与用户空间代理不同，如果最初选择的Pod没有响应，则iptables代理无法自动重试另一个Pod，因此它依赖于readiness probes的工作。 Proxy-mode： ipvs FEATURE STATE: Kubernetes v1.9 beta 在ipvs模式下，kube-proxy监视k8s的Service和Endpoints，调用netlink接口以相应地创建ipvs规则，并定期与k8s的Service和Endpoint同步ipvs规则，以确保ipvs转台与期望一致。访问服务时，流量将被重定向到其中一个后端Pod。与iptables类似，ipvs基于netfilter hook函数，但是用hash table作为底层数据结构，并在内核空间中工作。这意味着ipvs可以更快地重定向流量，并且再同步代理规则时具有更好的性能。此外，ipvs为负载均衡算法提供了更多选项： rr： round-robin lc： least connection dh： destination hashing sh： source hashing sed： shortest expected delay nq： never queue 注意：ipvs模式假设在运行kube-proxy之前便已在节点上安装了IPVS内核模块。当kube-proxy以ipvs代理模式启动时，kube-proxy将验证节点上是否安装了IPVS模块，如果未安装，则kube-proxy将回退到iptables代理模式。 多端口服务Multi-Port Services 许多服务可能需要公开多个端口。对于此情况，k8s支持服务对象上的多个端口定义。当使用多个端口时，必须提供所有端口名称，以便消除端点(Endpoint)的歧义。请注意，端口名称只能包含小写字母数字和横杠-，并须以字母数字结尾。 12345678910111213141516kind: ServiceapiVersion: v1metadata: name: my-servicespec: selector: app: MyApp ports: - name: http protocol: TCP port: 80 targetPort: 9376 - name: https protocol: TCP port: 443 targetPort: 9377 选择自己的IPChoosing your own IP address 你可以将自己的cluster ip指定为服务创建请求的一部分。为此，请设置.spec.clusterIP字段。用户选择的IP地址必须是有效的IP地址，并且在apiserver的标志指定的service-cluster-ip-range CIDR范围内。如果IP地址无效，则apiserver返回422 HTTP statuscode以指示该值无效。 为什么不适用DNS轮询？Why not use round-robin DNS? 为什么我们使用虚拟IP来完成所有这些工作，而不仅仅是标准的DNS轮询。原因如下： DNS libraries的历史悠久，不尊重DNS TTL并缓存名称的查找结果 许多应用程序执行一次DNS查找并缓存结果 即使应用程序和库进行了适当的重新解析，每个客户算反复重新解析DNS的负载也是难以管理的 我们试图阻止用户做出伤害自己的事情。也就是说，如果有足够的人要求这样做，我们可以将其作为替代方案来实施。 服务发现Discovering services k8s支持两种寻找服务的主要模式： enviroment variables和DNS。 Environment variables当Pod在节点上运行时，kubelet为每个活跃的服务添加一组环境变量。它支持Docker links compatible变量和更简单的{SVCNAME}_SERVICE_HOST和{SVCNAME}_SERVICE_PORT变量。 栗子，如redis-master服务公开TCP6379端口，并分配了10.0.0.11的cluster ip以生成如下环境变量： 1234567REDIS_MASTER_SERVICE_HOST=10.0.0.11REDIS_MASTER_SERVICE_PORT=6379REDIS_MASTER_PORT=tcp://10.0.0.11:6379REDIS_MASTER_PORT_6379_TCP=tcp://10.0.0.11:6379REDIS_MASTER_PORT_6379_TCP_PROTO=tcpREDIS_MASTER_PORT_6379_TCP_PORT=6379REDIS_MASTER_PORT_6379_TCP_ADDR=10.0.0.11 这有一个要求——必须在Pod本身之前创建它想要访问的任何服务，否则将不会填充环境变量。DNS没有此限制。 DNS可选的集群加载项是DNS server(强烈推荐)。DNS server监视k8s API以获取新服务，并为每个服务创建一组DNS 记录。如果已在集群中启用DNS，则所有Pod应该能够自动对服务进行名称解析。 例如，如果你在k8s命名空间my-ns中创建一个服务my-service，则会创建my-service.my-ns的DNS记录。存在于my-ns命名空间中的Pod应该能够通过简单地对my-service服务进行名称查找来找到它。存在于其它命名空间的Pod必须将名称限定为my-service.my-ns。这些名称查找的结果是cluster ip。k8s还支持命名端口的DNS SRV(service)记录。如果my-service.my-ns服务具有带有TCP协议的名为http的端口，则可以对_http._tcp.my-service.my-ns执行DNS SRV查询以发现http的端口号。k8s DNS server是访问ExternalName类型的服务的唯一方法。 Headless services有时你不需要或不想要负载均衡和单个服务IP。在这种情况下，你可以通过将clusterIP(.spec.clusterIP)指定为None来创建一个headless服务。此选项允许开发人员通过允许他们自由地以自己的方式进行发现来减少与k8s系统的耦合。应用程序仍然可以使用自注册(self-registration)模式，并且可以轻松地在API上构建适用于其它发现系统的适配器。 对于此类服务，并未分配clusterIP，kube-proxy也不处理这些服务，并且平台没有为它们执行负载均衡和代理。如何自动配置DNS取决于服务是否已定义选择器(selector)： With selectors对于定义了选择器的headless服务，端点控制器(endpoints controller)在API中创建端点记录(Endpoint records)，并修改DNS配置以返回直接指向支持服务的Pod的A记录(地址)。 Without selectors对于没有定义选择器的headless服务，端点控制器不会创建端点记录。但是，DNS系统会查找并配置下面任一项； ExternalName类型的服务的CNAME记录 所有其它类型的，与服务共享名称的任何端点记录 发布服务和服务类型Publishing services - service types 对于应用程序的某些部分(如前端)，你可能希望将服务公开到外部IP地址(集群外)。k8s ServiceTypes允许你指定所需的服务类型，默认为ClusterIP。 类型如下： ClusterIp在集群内部IP上公开服务，选择此值使服务只能从集群内访问。这是默认的服务类型。 NodePort在每个节点IP的静态端口上公开服务。将自动创建cluster ip服务(NodePort服务将路由到此服务)。你可以在集群外部通过请求&lt;NodeIP&gt;:&lt;NodePort&gt;来联系NodePort服务 LoadBalancer使用云提供商的负载均衡器在外部公开服务。将自动创建外部负载均衡器路由到NodePort服务和ClusterIP服务。 ExternalName通过返回CNAME记录的值，将服务映射到externalName字段的内容。没有设置任何类型的代理。这需要kube-dns v1.7+。 NodePortNodePort类型下，k8s master将从--service-node-port-range标志指定的范围(默认 30000-32767)分配端口，(当然，你也可以在此范围了自定义)，并且每个节点将代理进入服务的端口(每个节点上的端口号相同)。服务中的.spec.ports[].nodePort字段。 如果要制定代理端口的特定IP，可将kube-proxy中的--nodeport-addresses标志 设置为特定IP块(从k8s v1.10+支持)。使用逗号,分隔IP块列表(如10.0.0.0/8,1.2.3.4/31)用于过滤此节点的本地地址。例如，如果你使用--nodeport-address=127.0.0.0/8标志启动kube-proxy，则kube-proxy将仅为NodePort服务选择环回地址接口(loopback)。--nodeport-address默认为空，这意味着选择所有可用的接口并符合当前的NodePort行为。 如果你需要特定的端口号，可以在nodePort字段中指定一个值，系统将为你分配该端口。请注意，指定的端口值必须在默认范围内，且没有端口冲突。 请注意，服务将同时显示&lt;NodeIP&gt;:spec.ports[*].nodePort和.spec.clusterIP:spec.ports[*].port。 LoadBalancer在支持外部负载均衡器的云提供商上，将type字段设置为LoadBalancer将为服务配置负载均衡器。负载均衡器的实际创建是异步(asynchronously)发生的，有关已配置的均衡器的信息将发布在服务的.status.loadBalancer字段。 栗子： 123456789101112131415161718kind: ServiceapiVersion: v1metadata: name: my-servicespec: selector: app: MyApp ports: - protocol: TCP port: 80 targetPort: 9376 clusterIP: 10.0.171.239 loadBalancerIP: 78.11.24.19 type: LoadBalancerstatus: loadBalancer: ingress: - ip: 146.148.47.155 来自外部负载均衡器的流量将指向后端Pod，但具体如何工作取决于云提供商。某些云提供商允许指定loaBalancerIP。在这些情况下，将使用用户指定的loadBalancerIP创建负载均衡器。如果未指定loadBalancerIP字段，则将为负载均衡器分配临时IP。如果指定了loadBalancerIP字段，但云提供商不支持该功能，则该字段被忽略。 一些云提供商： AWS Azure GCP Aliyun TencentCloud ExternalName NOTE: ExternalName Services are available only with kube-dns version 1.7 and later. ExternalName类型的服务将服务映射到DNS名称(使用spec.externalName)，而不是映射到传统的选择器(如my-service)。 栗子： 12345678kind: ServiceapiVersion: v1metadata: name: my-service namespace: prodspec: type: ExternalName externalName: my.database.example.com 查找主机my-service.prod.svc.CLUSTER时，集群DNS服务将返回my.database.example.com的CNAME记录。访问my-service服务的工作方式与其它服务的工作方式相同，但重要的区别在于重定向发生在DNS级别，而不是通过代理或转发。 External IPs如果有外部IP路由到一个或多个集群节点，则可以在这些externalIPs上公开k8s 服务。在服务端口上使用外部IP，进入集群的流量将路由到其中一个服务端点。外部IP不由k8s管理，它是集群管理员的责任。 栗子； 1234567891011121314kind: ServiceapiVersion: v1metadata: name: my-servicespec: selector: app: MyApp ports: - name: http protocol: TCP port: 80 targetPort: 9376 externalIPs: - 80.11.12.10 不足Shortcomings 使用虚拟IP(VIP)的用户空间(userspace)将在中小规模(small to medium scale)上工作，但不会扩展到具有成千上万个服务的大集群中。 使用用户空间代理会模糊访问服务的数据包的源IP，这使得某些类型的防火墙变得不可能。iptabels代理不会掩盖集群内源IP，但它仍然会影响通过负载均衡器或节点端口的客户端。 Type字段设置为嵌套功能——每个级别都添加到前一个级别。并非所有云服务商都严格要求这样做，但目前的API需要它。 VIP细节The gory details of virtual IPs 避免冲突(Avoiding collisions)k8s的主要哲学之一是用户不应该暴露可能导致他们的行为失败的情况，而不是他们自己的过错。在这种情况下，我们查看网络端口——用户不应该选择可能与另一个用户发生冲突的网络端口。这叫隔离失败。为了允许用户为服务选择端口号，我们必须确保没有服务间的冲突。我们通过为每个服务分配IP地址来做到这一点。 为了确保每个服务都接收到一个唯一的IP，内部分配器会在创建每个服务之前以原子方式更新etcd中的全局分配映射。映射对象必须存在于映射表中以获取IP，否则创建将失败并显示一条消息，指示无法分配IP。后台控制器负责创建该映射以及由于管理员的干预而检查无效的分配，并清除已分配但当前没有服务使用的任何IP。 IPs和VIPs与实际路由到目的地的Pod IP不同，Service IP实际上并未由单个主机应答。相反，我们使用iptables来定义根据需要透明重定向的虚拟IP。当客户端连接到VIP时，其流量会自动传输到适当的端点。服务的环境变量和DNS实际上是根据服务的VIP和端口填充的。支持三种代理模式： userspace、iptables、ipvs，它们的操作略有不同。 API对象服务在k8s REST API中是顶级资源。 DNSDNS for Services and Pods 介绍k8s DNS在集群上调度DNS Pod和Service，并配置kubelet以告知各个容器使用DNS Service’s IP 来解析DNS名称。集群中定义的每个服务(包括DNS服务自身)，都会分配一个DNS名称。默认情况下，客户端Pod的DNS搜索列表将包含Pod自己的命名空间和集群的默认域。 栗子：假设在k8s的bar命名空间中有一个foo服务，运行在bar命名空间中的Pod可通过简单地为foo执行DNS查询来查找此服务。运行在quux命名空间中的Pod可通过foo.bar执行DNS查询来查找此服务。 ServicesA records正常的服务(非headless)都分配了一个名为my-svc.my-namespace.svc.cluster.local形式的DNS A记录，这将解析为服务的cluster ip。Headless服务同样分配了一个名为my-svc.my-namespace.svc.cluster.local形式的DNS A记录。与服务不同，这将解析为服务选择的Pod的IP。 SRV records为命名端口创建SRV记录，这些端口是普通服务或headless服务的一部分。对于每个命名端口，SRV记录的格式为_my-port-name._my-port-protocol.my-svc.my-namespace.svc.cluster.local；对于常规的服务，这将解析为端口号和域名：my-svc.my-namespace.svc.cluster.local；对于headless服务，这将解析为多个答案。一个用于支持服务的每个Pod，并且包含Pod形式的端口号和域名:auto-generated-name.my-svc.my-namespace.svc.cluster.local。 PodsA records启用后，将以pod-ip-address.my-namespace.pod.cluster.local的形式为Pod分配DNS A记录。如10-0-1-11.default.pod.cluster.local。 Pod’s hostname and subdomain fields目前，当创建Pod时，其主机名时Pod的metadata.name值。Pod spec有一个可选的hostname字段，可用于指定Pod的主机名。指定后，它优先于Pod的名称作为Pod的主机名。Pod spec同样有一个可选的subdomain字段，可用于指定其子域。 栗子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344apiVersion: v1kind: Servicemetadata: name: default-subdomainspec: selector: name: busybox clusterIP: None ports: - name: foo port: 1234 targetPort: 1234---apiVersion: v1kind: Podmetadata: nam: busybox1 labels: name: busyboxspec: hostname: busybox-1 subdomain: default-subdomain containers: - image: busybox command: - sleep - '3600' name: busybox---apiVersion: v1kind: Podmetadata: name: busybox2 labels: name: busyboxspec: hostname: busybox-2 subdomain: default-subdomain containers: - image: busybox command: - sleep - "3600" name: busybox Pod’s DNS Policy可以基于每个Pod设置DNS策略。目前，k8s支持以下特定于Pod的DNS策略。这些策略在Pod spec中的dnsPolicy字段中指定。 DefaultPod从Pod的节点继承名称解析配置。 ClusterFirst任何与配置的集群域后缀名称不匹配的DNS查询，都会转发到从该节点继承的上游名称服务器。集群管理员可能配置了额外的存根域和上游DNS server。注意Default不是默认的DNS策略，如果未指定DNS策略，则使用ClusterFirst。 ClusterFirstWithHostNet对于使用hostNetwork运行的Pod，你应该明确设置其DNS策略为ClusterFirstWithHostNet。 Nonek8s v1.9+中引入的新功能。它允许Pod忽略k8s环境中的DNS设置。应该使用DNS spec中的dnsConfig字段提供所有的DNS设置。 Pod’s DNS Config要启用此功能，集群管理员需要在apiserver和kubelet上启用--feature-gates=CustomPodDNS=true,...。之后，用户便可以将Pod的dnsPolicy字段设置为None，并可以将新字段dnsConfig添加到Pod spec中。 dnsConfig字段是可选的，它可与任何dnsPolicy设置一起使用。但是，当Pod的dnsPolicy字段设置为None时，必须指定dnsConfig字段。 用户可在dnsConfig字段中指定的属性： nameservers用作Pod的DNS服务器的IP地址列表，最多可以指定3个IP地址。当dnsPolicy设置为None时，必须至少包含一个IP地址，否则此属性是可选的。 searchesPod中主机名查找的DNS搜索域列表，此属性是可选的。k8s最多允许6个搜索域。 options一个可选的对象属性，其中每个对象有name(必须): value(可选)。 栗子： 1234567891011121314151617181920apiVersion: v1kind: Podmetadata: namespace: default name: dns-examplespec: containers: - name: test image: nginx dnsPolicy: "None" dnsConfig: nameservers: - 1.2.3.4 searches: - ns1.svc.cluster.local - my.dns.search.suffix options: - name: ndots value: "2" - name: edns0 查看: 1234kubectl exec -it -- cat /etc/resolv.confnameserver 1.2.3.4search ns1.svc.cluster.local my.dns.search.suffixoptions ndots:2 edns0 连接应用与服务Connecting Applications with Services 现在你拥有了一个连续运行的副本应用程序，你可以在网络上公开它。在讨论k8s网络方法之前，值得将它与Docker的方式进行对比。默认情况下，Docker使用host-private网络，因此只有当容器位于同一台主机上时，容器才能与其它容器进行通信。为了使Docker容器能够跨节点通信，必须在主机的IP地址上分配端口，然后将这些端口转发或代理到容器。这意味着容器要小心协调它们使用的端口。k8s假设Pod可与其它Pod通信，无论它们着落在哪个主机。我们为每个Pod提供了集群专用IP，因此无需在Pod之间明确创建链接，或将容器端口映射到主机端口。这意味着Pod中的容器都可以在localhost上到达彼此的端口，并且集群中的所有Pod都可以在没有NAT的情况下看到对方。 将Pod公开给集群Exposing pods to the cluster 12345678910111213141516171819apiVersion: apps/v1kind: Deploymentmetadata: name: my-nginxspec: selector: matchLabels: run: my-nginx replicas: 2 template: metadata: labels: run: my-nginx spec: containers: - name: my-nginx image: nginx ports: - containerPort: 80 创建服务Creating a Service 123456789101112apiVersion: v1kind: Servicemetadata: name: my-nginx labels: run: my-nginxspec: ports: - port: 80 protocol: TCP selector: run: my-nginx 访问服务Accessing the Service Environment Variables DNS 1234kubectl exec &lt;pod&gt; -- printenvkubectl get services kube-dns --namespace=kube-system 服务安全Securing the Service 在将服务公开到因特网之前，你需要确保通信渠道是安全的。你需要： https签名证书 使用证书的nginx server 使证书可供Pod访问的secret 公开服务Exposing the Service NodePort LoadBalancer Ingress管理集群中外部访问服务的API对象，通常是HTTP。Ingress(入口)可以提供负载均衡，SSL终止和基于名称的虚拟主机。 术语Terminology Node Cluster Edge router Cluster network Service Ingress是什么通常，服务和Pod具有的IP仅可在集群网络路由。最终在边缘路由器上的所有流量都被丢弃或转发到其它地方。从概念上讲，这可能看起来像： 1234 internet |------------[ Services ] Ingress是一组允许访问连接到达集群服务的一组规则： 12345 internet |[ Ingress ]--|-----|--[ Services ] 它可以配置为微服务提供外部可访问的URL，负载均衡流量、ssl terminate、基于名称的虚拟主机等。用户通过POST ingress资源到api-server来请求ingress。Ingress Controller负责完成ingress，通常使用负载均衡器(loadbalancer)，但也可配置为edge router或其它前端以帮助以HA方式处理流量。 先决条件Prerequisites 在开始使用ingress资源之前，你应该了解一些事项。Ingress是beta resource，在k8s v1.1 之前的版本中都没有。你需要一个ingress controller来满足Ingress，简单地创建资源将无法生效。GCE/Google Kubernetes Engine在master上部署ingress controller。你可以在Pod中部署任意数量的自定义入口控制器。你必须使用适当的class对每个入口进行注释。在GCE/google kubernetes engine以外的环境中，你需要将ingress controller部署为Pod。 Ingress资源一个最小化的Ingress看起来如下： 123456789101112131415apiVersion: extensions/v1beta1kind: Ingressmetadata: name: test-ingress annotations: nginx.ingress.kubernetes.io/rewrite-target: /#ingress spec需要配置负载均衡器或代理服务器所需的信息spec: rules: - http: paths: - path: /testpath backend: serviceName: test servicePort: 80 如果尚未配置ingress controller，则将此操作发送到api-verser将不起作用。 和其它k8s配置一样，Ingress也需要apiVersion, kind, metadata, spec字段。Ingress spec字段需要配置负载均衡器和代理服务器所需的所有信息。最重要的是，它包含与所有传入请求匹配的规则列表。目前，Ingress仅支持http规则。每个http rule都包含如下信息： a host，默认值为*；与后端挂念的一组path列表。在负载均衡器将流量定向到后端之前，host和path都必须与传入请求的内容匹配。后端(backend)是一个service:port的组合。入口流量通常直接发送到与后端匹配的端点(endpoint)。实例中没有包含Ingress的全局参数(global patameters)，详情请查看文档。 Ingress controllers为了使ingress资源正常工作，集群必须运行ingress controller——这与其它类型的控制器不同，后者通常为kube-controller-manager程序的一部分，并且通常作为集群创建的一部分而自启动。选择最适合你的集群的ingress controller。 k8s目前支持和维护GCE和Nginx控制器GCE: https://github.com/kubernetes/ingress-gce/blob/master/README.md F5 BIG-IP Controller for Kubernetes链接： http://clouddocs.f5.com/products/connectors/k8s-bigip-ctlr/latest Kong Ingress Controller for Kubernetes链接： https://konghq.com/blog/kubernetes-ingress-controller-for-kong/ TraefikTraefik: https://github.com/containous/traefikContainous: https://containo.us/services NGINX Ingress Controller for Kubernetes链接: https://www.nginx.com/products/nginx/kubernetes-ingress-controller/github: https://github.com/jcmoraisjr/haproxy-ingress HAProxy Ingress Controller for Kubernetes链接： https://www.haproxy.com/blog/haproxy_ingress_controller_for_kubernetes/ 基于istio的Control Ingress Trafficistio: https://istio.io/链接: https://istio.io/docs/tasks/traffic-management/ingress/ Ingress的类型 Single Service Ingress现有的k8s概念允许你公开单个服务，但你也可以通过Ingress指定不使用规则的默认后端。 12345678apiVersion: extensions/v1beta1kind: Ingressmetadata: name: test-ingressspec: backend: serviceName: testsvc servicePort: 80 12345678#创建kubectl create -f#查看kubectl get ingress test-ingressNAME HOSTS ADDRESS PORTS AGEtest-ingress * 107.178.254.228 80 59s#107.178.254.228是ingress controller为满足此Ingress而分配的IP Simple fanout如前所述，k8s中Pod只能在集群内网络上看到IP，因此我们需要在边缘处接收入口流量并将其代理到正确的端点。该组件通常是高可用的负载均衡器。Ingress允许你将负载均衡器的数量将至最低。例如： 12foo.bar.com -&gt; 178.91.123.132 -&gt; / foo s1:80 / bar s2:80 需要一个Ingress，例如： 12345678910111213141516171819apiVersion: extensions/v1beta1kind: Ingressmetadata: name: test annotations: nginx.ingress.kubernetes.io/rewrite-target: /spec: rules: - host: foo.bar.com http: paths: - path: /foo backend: serviceName: s1 servicePort: 80 - path: /bar backend: serviceName: s2 servicePort: 80 12345678910111213141516171819kubectl create -f xxxkubectl describe ingress testName: testNamespace: defaultAddress: 178.91.123.132Default backend: default-http-backend:80 (10.8.2.3:8080)Rules: Host Path Backends ---- ---- -------- foo.bar.com /foo s1:80 (10.8.0.90:80) /bar s2:80 (10.8.0.91:80)Annotations: nginx.ingress.kubernetes.io/rewrite-target: /Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ADD 22s loadbalancer-controller default/test Name based virtual hosting基于名称的虚拟主机对同一IP地址使用多个主机名。 123foo.bar.com --| |-&gt; foo.bar.com s1:80 | 178.91.123.132 |bar.foo.com --| |-&gt; bar.foo.com s2:80 如下的Ingress告诉后端负载均衡器根据Host Header来路由请求： 123456789101112131415161718apiVersion: extensions/v1beta1kind: Ingressmetadata: name: testspec: rules: - host: foo.bar.com http: paths: - backend: serviceName: s1 servicePort: 80 - host: bar.foo.com http: paths: - backend: serviceName: s2 servicePort: 80 default backend： 没有指定规则的Ingress将所有流量发送到单个默认后端。你可以使用相同的技术来指定一组规则和默认后端来告诉负载均衡器在哪里找到网站的404页面。如果Ingress中的所有主机都与请求Header中的主机不匹配，并且没有任何路径与请求的URL匹配，则流量将路由到你的默认后端。 TLS可以通过指定包含TSL私钥和证书的机密来保护Ingress。目前，Ingress仅支持单个TLS 443端口。TLS Secret必须包含名为tls.crt和tls.key的证书和密钥： 123456789apiVersion: v1data: tls.crt: base64 encoded cert tls.key: base64 encoded keykind: Secretmetadata: name: testsecret namespace: defaulttype: Opaque 在Ingress中引用secret将此告知ingress controller： 12345678910apiVersion: extensions/v1beta1kind: Ingressmetadata: name: no-rules-mapspec: tls: - secretName: testsecret backend: serviceName: s1 servicePort: 80 请注意，各种ingress controller支持的TLS功能存在差异性。 Loadbalancingingress controller通过一些适用于所有Ingress的负载均衡策略设置进行引导(bootstrapped)，一些高级 的负载均衡概念(持久会话、动态权重)尚未通过Ingress进行公开。但你仍然可以通过服务负载均衡器获得这些功能。 更新Ingress 直接更新资源 更新配置文件 123456#直接更新资源kubectl edit ingress test#更新修改的配置文件kubectl replace -f xxx 未来计划 各种模式的HTTPS/TLS支持 通过声明请求IP或Hostname 结合L4和L7 Ingress 更多ingress controller Alternatives有多种方式公开服务： LoadBalancer NodePort Port Proxy LoadBalancer/NodePort/Ingress比较参考: Kubernetes NodePort vs LoadBalancer vs Ingress? When should I use what? 这几种服务类型的优缺点，以及什么时候使用它们。 Cluster IPCluster IP是默认的k8s服务，它提供集群内部的访问，外部无法访问。但你可以使用kubernetes proxy来访问它。 什么时候使用： 调试服务 内部访问就可 12345#开启proxykubectl proxy --port=8080#访问资源http://localhost:8080/api/v1/proxy/namespaces/&lt;NAMESPACE&gt;/services/&lt;SERVICE-NAME&gt;:&lt;PORT-NAME&gt;/ NodePortNodePort是公开服务的最原始的方式。 什么时候使用？此方法有许多缺点： 每个端口只能有一个服务 默认端口范文30000-32767 如果节点IP地址发生更改，则需要处理该问题 由于这些原因，不建议在生产环境使用这种方法 LoadBalancerLoadBalancer是公开服务的标准方式。 什么时候用： 指定端口上的所有流量都被转发到该服务，没有过滤、路由等。这意味着你可以发送任何类型的流量，如HTTP, TCP, UDP, Websocket, gRPC… 最大的缺点，你必须为每一个公开的服务使用一个负载均衡器，这个负载均衡器公开的服务都将获得自己的IP，这可能会付出比较大的代价 Ingress与以上方式不同，Ingress不是一种服务。相反，它位于多个服务之前，充当集群中的入口。你可以使用Ingress做很多不同的事，并且有许多类型的 ingress controller，具有不同的功能。 什么时候用： Ingress可能是公开服务最强大的方式，但也可能是最复杂的 如果你希望在相同的IP下公开多个服务，则Ingress是最有用的 网络策略Network Policies 网络策略是允许容器组如何与彼此以及其它网络端点通信的规范。NetworkPolicy资源使用labels选择Pod并定义规则，这些规则指定允许选定的Pod的流量。 先决条件网络策略由网络插件来实现，因此你必须使用支持NetworkPolicy的网络解决方案——简单地创建资源而没有控制器来实现它将不起作用。 Isolated and Non-isolated Pods默认情况下，Pod是非隔离的(non-isolated)。它们接受任何来源的流量。可选择NetworkPolicy来隔离Pod，一旦命名空间中任何NetworkPolicy选择了特定的Pod，该Pod将拒绝网络策略不允许的任何连接。 NetworkPolicy资源The NetworkPolicy Resource 栗子： 12345678910111213141516171819202122232425262728293031323334apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: test-network-policy namespace: defaultspec: podSelector: matchLabels: role: db policyTypes: - Ingress - Egress ingress: - from: - ipBlock: cidr: 172.17.0.0/16 except: - 172.17.1.0/24 - namespaceSelector: matchLabels: project: myproject - podSelector: matchLabels: role: frontend ports: - protocol: TCP port: 6379 egress: - to: - ipBlock: cidr: 10.0.0.0/24 ports: - protocol: TCP port: 5978 必填字段： NetworkPolicy, apiVersion, kind, metadata spec: 网络策略所需的所有信息 podSelector： 选择策略适用的Pod分组。(如果为空，则表示此命名空间下的所有Pod) policyTypes： 可能包含Ingress, Egress。指示给定策略是否适用于入口流量和出口流量。(如果为空，默认为Ingress) ingress： 允许配置from和ports部分的流量。ipBlock, namespaceSelector, podSelector指定具体信息 egress： 允许配置to和ports部分的流量 默认策略Default policies 默认情况下，如果命名空间中不存在任何策略，则允许所有入口(ingress)和出口(egress)流量进出该命名空间中的Pod。 默认拒绝所有入口流量(Default deny all ingress traffic)你可以通过创建NetworkPolicy来为命名空间创建默认的隔离策略，该策略选择所有Pod但不允许任何入口流量到这些Pod。 12345678apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: default-denyspec: podSelector: &#123;&#125; policyTypes: - Ingress 默认允许所有入口流量(Default allow all ingress traffic)如果要允许所有流量到命名空间的所有Pod，你可以创建一个明确允许该命名空间中所有流量的策略。 12345678apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: allow-allspec: podSelector: &#123;&#125; ingress: - &#123;&#125; 默认拒绝所有出口流量(Default deny all egress traffic)可通过创建NetworkPolicy来为命名空间创建默认的出口隔离策略，该策略选择所有Pod但不允许来自这些Pod的出口流量。 12345678apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: default-denyspec: podSelector: &#123;&#125; policyTypes: - Egress 默认允许所有出口流量(Default allow all egress traffic) 12345678910apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: allow-allspec: podSelector: &#123;&#125; egress: - &#123;&#125; policyTypes: - Egress 默认拒绝所有入口/出口流量(Default deny all ingress and all egress traffic) 123456789apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: default-denyspec: podSelector: &#123;&#125; policyTypes: - Ingress - Egress 使用HostAliases向Pod的hosts添加条目Adding entries to Pod /etc/hosts with HostAliases 当DNS和其它选项不适用时，向Pod的/etc/hosts文件添加条目可提供主机名解析的Pod级别的覆盖。在 v1.7 中，用户可以使用pod spec中的HostAliases字段来添加这些自定义条目。不建议不使用HostAliases进行修改，因为该文件由Kubelet管理，并且可以在Pod 创建/重启 期间覆盖。 默认hosts文件Default Hosts File Content 查看Pod hosts文件： 123456789101112131415kubectl get pod -o=wideNAME READY STATUS RESTARTS AGE IP NODEnginx-deployment-597549df56-chjps 1/1 Running 0 26d 10.244.2.52 salt01#kubectl exec POD [-c CONTAINER] -- COMMAND [args...] [options]kubectl exec nginx-deployment-597549df56-chjps -- cat /etc/hosts# Kubernetes-managed hosts file.127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetfe00::0 ip6-mcastprefixfe00::1 ip6-allnodesfe00::2 ip6-allrouters10.244.2.52 nginx-deployment-597549df56-chjps 使用HostAliases添加额外条目Adding Additional Entries with HostAliases hostaliases-pod.yaml: 123456789101112131415161718192021apiVersion: v1kind: Podmetadata: name: hostaliases-podspec: restartPolicy: Never hostAliases: - ip: "127.0.0.1" hostnames: - "foo.local" - "bar.local" - ip: "192.168.31.119" hostnames: - zhang21 containers: - name: cat-hosts image: busybox command: - cat args: - "/etc/hosts" 123456789101112131415kubectl apply -f hostaliases-pod.yamlkubeclt logs hostaliases-pod# Kubernetes-managed hosts file.127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetfe00::0 ip6-mcastprefixfe00::1 ip6-allnodesfe00::2 ip6-allrouters10.244.1.69 hostaliases-pod# Entries added by HostAliases.127.0.0.1 foo.local127.0.0.1 bar.local192.168.31.119 zhang21 为什么kubelet管理hostsWhy Does Kubelet Manage the Hosts File? Kubelet管理Pod中每个容器的hosts文件，以防止Docker在容器已启动后修改文件。由于文件的托管性质，只要在容器重启或Pod重新调度的情况下由Kubelet重新挂载hosts文件，因此用户编写的内容都将被覆盖。因此，不建议直接修改文件的内容。 存储Storage Volumes容器中的磁盘文件是短暂的，这在容器中运行时会给重大的应用程序带来一些问题。首先，当一个容器奔溃时，kubelet将重启它，但文件会丢失，容器将以干净的状态启动。其次，在Pod中一起运行容器时，通常需要在这些容器间共享文件。k8s volume抽象解决这些问题。 BackgroundDocker也有关于卷的概念，虽然它有点宽松和管理较少。在Docker中，卷是磁盘上或其它容器中的目录，声明周期不受管理。Docker提供了卷驱动，但目前功能非常有限。 另一方面，k8s的卷具有明确的生命周期。因此，卷可以比Pod中运行的任何容器活得更久，并且可在容器重启之间保留数据。当然，当Pod不再存在时，卷也将不复存在。更重要的是，k8s支持多种类型的卷，Pod可以同时使用任意数量的卷。从本质上讲，卷只是一个目录，可能包含一些数据，Pod中的容器可以访问它。该目录如何形成，支持它的介质以及它的内容都由所用特定卷的类型决定。要使用卷，Pod Spec要指定提供的卷(.spec.volumes字段)，以及将这些卷挂载到容器中的位置(.spec.containers.volumeMounts字段)。 容器中的进程可以看到由Docker镜像和卷组成的文件系统视图。Docker镜像位于文件系统层次结构的根下，任何卷都挂载到镜像中的指定路径。卷不能挂载到其它卷或其它卷的硬链接上，Pod中的每个容器必须独立的指定每个卷的挂载位置。 卷类型k8s支持如下卷类型。注意，这些卷并非全部都是持久化的(如emptyDir)，它们会随着Pod的消亡而消亡。 awsElasticBlockStore azureDisk azureFile cephfs configMap csi downwardAPI emptyDir fc (fibre channel) flocker gcePersistentDisk gitRepo (deprecated) glusterfs hostPath iscsi local nfs persistentVolumeClaim projected portworxVolume quobyte rbd scaleIO secret storageos vsphereVolume 具体例子请参考: https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes configMapconfigMap资源提供了一种将配置数据注入Pod的方法。存储在configMap对象中的数据可以在configMap类型的卷中引用，然后由Pod中运行的应用程序使用。引用configMap对象时，只需在卷中提供其名称即可引用它。你还可以自定义configMap中的特定条路的路径。 例如，要将log-config的ConfigMap挂载到名为configmap-pod的Pod上，你可以这样操作：注意，在使用之前你先得创建ConfigMap使用ConfigMap作为subPath的卷挂载将不会收到ConfigMap的更新 12345678910111213141516171819apiVersion: v1kind: Podmetadata: name: configmap-podspec: containers: - name: test image: busybox volumeMounts: - name: config-vol mountPath: /etc/config volumes: - name: config-vol configMap: name: log-config items: - key: log_level path: log_level#log-config configMap作为卷挂载，存储在`log_level`的所有内容都挂载到路径`/etc/config/log_level`的Pod中 emptyDir将Pod分配给节点时，首先会创建一个emptyDir卷。只要节点还在该节点上运行，它就会存在。就如同它的名称一样，它最初是空的。Pod中的容器都可以在emptyDir卷中读取和写入相同的文件，尽管改卷可以安装在每个容器中相同或不同的路径上。当从节点上删除Pod时，将永久删除emptyDir中的数据。注意：容器奔溃不会从节点中删除Pod，因此emptyDir卷中的数据在容器奔溃时是安全的。 emptyDir的一些用途： 临时空间 检查从崩溃中恢复的长计算 保存内容管理器容器在Web服务器提供数据时提取的文件 默认情况下，emptyDir卷存储在节点的任何介质上(磁盘、SSD、网络存储…)，取决于你的环境。但是，你可以将emptyDir.medium字段设置为Memory，以告诉k8s为你安装tmpfs(RAM支持的文件系统)。tmpfs非常快，但请注意断电就没有了，并且你编写的任何文件都将计入容器的内存限制。 栗子： 1234567891011121314apiVersion: v1kind: Podmetadata: name: test-pdspec: containers: - image: k8s.gcr.io/test-webserver name: test-container volumeMounts: - mountPath: /cache name: cache-volume volumes: - name: cache-volume emptyDir: &#123;&#125; hostPathhostPath卷将文件或目录从主机节点的文件系统挂载到Pod中。这不是大多数Pod需要的东西，但它为某些应用程序提供了强大的逃生舱。 hostPath的一些用途： 运行需要访问Docker内部的容器，使用/var/lib/docker的hostPath 在容器中运行cAdvisor 允许Pod指定在Pod运行之前是否应该存在给定的hostPath，是否应该创建它以及它应该存在的内容 三个字段: hostPath path type 支持的type的值： Value Behavior 空 Empty string (default) is for backward compatibility, which means that no checks will be performed before mounting the hostPath volume. DirectoryOrCreate If nothing exists at the given path, an empty directory will be created there as needed with permission set to 0755, having the same group and ownership with Kubelet. Directory A directory must exist at the given path FileOrCreate If nothing exists at the given path, an empty file will be created there as needed with permission set to 0644, having the same group and ownership with Kubelet. File A file must exist at the given path Socket A UNIX socket must exist at the given path CharDevice A character device must exist at the given path BlockDevice A block device must exist at the given path 请注意何时使用此类型的卷，因为： 由于节点上的文件不同，具有相同配置的Pod在不同节点上的行为可能有所不同 当k8s按计划添加资源，它将无法考虑hostPath使用的资源 在底层主机上创建的文件或目录只能由root写入 栗子: 123456789101112131415161718apiVersion: v1kind: Podmetadata: name: test-pdspec: containers: - image: k8s.gcr.io/test-webserver name: test-container volumeMounts: - mountPath: /test-pd name: test-volume volumes: - name: test-volume hostPath: # directory location on host path: /data # this field is optional type: Directory locallocal卷表示已挂载的本地存储设备，如磁盘，分区或目录。它只能用作静态创建的持久化卷，尚不支持动态配置。与hostPath卷相比，可以以持久且可移植的方式使用lobal卷，而无需手动将Pod调度到节点。然而，local卷仍受基础节点可用性的限制，并不适用于所有应用程序。如果节点变得不健康，则local卷也将变得不可访问，并且使用它的Pod将无法运行。使用local volume的应用程序必须能够容忍这种降低的可用性以及潜在的数据丢失，具体取决于底层磁盘的持久性特征。 栗子： 1234567891011121314151617181920212223apiVersion: v1kind: PersistentVolumemetadata: name: example-pvspec: capacity: storage: 100Gi # volumeMode field requires BlockVolume Alpha feature gate to be enabled. volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Delete storageClassName: local-storage local: path: /mnt/disks/ssd1 nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - example-node NFS栗子： 123456volumes:- name: nfs nfs: # FIXME: use the right hostname server: 10.254.234.223 path: "/" persistentVolumeClaimpersistentVolumeClaim卷用于将持久化卷挂载到Pod中。 使用子路径Using subPath 有时，在单个Pod中共享一个卷用于多个用途是很有用的。volumeMounts.subPath属性可用于指定引用卷内的子路径，而不是根路径。 使用单个共享卷的Pod与LAMP Stack的示例，HTML内容被映射到html目录中，数据库存储在mysql目录中： 12345678910111213141516171819202122232425apiVersion: v1kind: Podmetadata: name: my-lamp-sitespec: containers: - name: mysql image: mysql env: - name: MYSQL_ROOT_PASSWORD value: &quot;rootpasswd&quot; volumeMounts: - mountPath: /var/lib/mysql name: site-data subPath: mysql - name: php image: php:7.0-apache volumeMounts: - mountPath: /var/www/html name: site-data subPath: html volumes: - name: site-data persistentVolumeClaim: claimName: my-lamp-site-data 使用带有扩展环境变量的子路径Using subPath with expanded environment variables FEATURE STATE: k8s v1.11 alpha subPath目录名也可从Downward API环境变量构造。在使用此功能之前，必须启用VolumeSubpathEnvExpansion。下例中，Pod使用subPath在主机路径卷/var/log/pods中创建pod1目录，使用Downward API中的Pod名。主机目录/var/log/pods/pod1被挂载到容器中的/logs目录。 123456789101112131415161718192021222324apiVersion: v1kind: Podmetadata: name: pod1spec: containers: - name: container1 env: - name: POD_NAME valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.name image: busybox command: [ &quot;sh&quot;, &quot;-c&quot;, &quot;while [ true ]; do echo &apos;Hello&apos;; sleep 10; done | tee -a /logs/hello.txt&quot; ] volumeMounts: - name: workdir1 mountPath: /logs subPath: $(POD_NAME) restartPolicy: Never volumes: - name: workdir1 hostPath: path: /var/log/pods 资源emptyDir卷的存储介质(磁盘，SSD…)由kubelet根目录的文件系统的介质确定。emptyDir或hostPath卷可以占用多少空间没有限制，容器之间或Pod之间没有隔离。 挂载传播Mount propagation FEATURE STATE: k8s v1.10 beta 挂载传播允许将容器挂载的卷共享到同一Pod的其它容器，或同一节点的其它Pod。如果MountPropagation功能被禁用，或Pod未指明特定的挂载环境，则不会传播Pod的容器中的挂载卷。卷的挂载传播由Container.volumeMounts中的mountPropagation字段控制。它的值为： None此卷的挂载不会接收主机挂载到此卷或任何子目录的任何后续挂载。此模式等同于于Linux kernel中描述的private挂载传播。 HostToContainer此卷的挂载将接收安装到此卷或其任何子目录的所有后续挂载。换句话说，如果主机在卷挂载中挂载任何内容，则容器将看到它挂载在那里。类似地，如果任何具有双向挂载传播的Pod挂载到同一个卷中，那么具有HostToContainer挂载传播的容器将看到它。此模式等同于Linux Kernel中描述的rslave挂载传播。 Bidirectional此卷的挂载行为与HostToContainer相同。此外，容器创建的所有卷 挂载都将传播会主机和所有使用相同卷的Pod中的容器。此模式等同于Linux kernel中描述的rshared挂载传播。 配置在挂载传播可以在某些部署上正常工作之前，必须在Docker中正确配置挂载共享，修改docker systemd服务文件，设置MountFlags： 1MountFlags=shared 重启Docker： 12systemctl daemon-reloadsystemctl restart docker 持久化卷Persistent Volumes 简介PersistentVolume 子系统为用户和管理员提供了一个API，它提供了如何根据消耗提供存储的详细信息。为此，我们引入了两个新的API资源： PersistentVolume(PV) PersistentVolumeClaim(PVC) PersistentVolume 是群集中由管理员配置的一块存储。它是集群中的资源，就像节点是集群资源一样。它是像 Volume 的 Volume Plugin，但其生命周期独立于使用它的任何单个 pod 。此API对象捕获存储实现的详细信息，包括NFS，iSCSI或特定于云提供程序的存储系统。 PersistentVolumeClaim 是用户存储的请求。与 Pod 类似，Pod 消耗 Node 资源，而 PVC 消耗 PV 的资源。Pod可以请求特定级别的资源(CPU, MEM)，Claim 可以请求特定的大小和访问模式。 虽然 PersistentVolumeClaims 允许用户使用抽象存储资源，但是对于不同的问题，用户需要具有不同属性的 PersistentVolumes。群集管理员需要能够提供各种PersistentVolume，这些PersistentVolume在多种方式上而不仅仅是大小和访问模式，而不会让用户了解这些卷的实现方式。对于这些需求，有 StorageClass 资源。 volume和claim的生命周期Lifecycle of a volume and claim PV是群集中的资源。 PVC是对这些资源的请求，并且还充当对资源的声明检查。PV和PVC之间的相互作用遵循如下生命周期。 Provisioning有两种方式配置PV: Static 集群管理员创建了许多PV。它们包含可供群集用户使用的实际存储的详细信息。它们存在于Kubernetes API中，可供使用。 Dynamic 当管理员创建的 Static PV 都不匹配用户的 PersistentVolumeClaim 时，群集可能会尝试为PVC 专门动态配置Volume。此 Provision 基于StorageClasses， PVC必须请求存储类，管理员必须已创建并配置该类，以便进行动态供应。 Binding用户在动态配置的情况下创建或已创建 PersistentVolumeClaim，其具有请求的特定存储量和某些访问模式。Master中的控制循环观察新PVC，找到匹配的PV（如果可能），并将它们绑定在一起。如果为新PVC动态配置PV，则循环将始终将该PV绑定到PVC。否则，用户将始终至少得到他们要求的内容，但是Volume可能超过所要求的数量。绑定后，PersistentVolumeClaim 绑定是独占的，无论它们如何绑定，PVC到PV绑定是一一对应。 如果不存在匹配的卷，则 Claim 将无限期地保持未绑定状态。Claim 将在匹配卷可用时受到绑定。例如，集群配置了许多50Gi PV，与请求100Gi的PVC不匹配。当100Gi PV添加到集群时，可以绑定PVC。 UsingPods 使用 Claim 作为 Volume。群集检查 Claim 以查找绑定卷并为该 Pod 挂载该卷。对于支持多种访问模式的卷，用户在将其声明用作 Pod 的卷时指定所需的模式。 一旦用户具有声明并且该声明被绑定，绑定的PV就属于用户，只要用户需要它。用户通过在Pod的 Volume Block 中包含 persistentVolumeClaim 来调度Pod并访问其声明的PV。 Storage Object in Use Protection使用中的存储对象保护 功能的目的是确保不会从系统中删除 绑定到 PVC，由 Pod 和 PV 主动使用的 PVC，因为这可能会导致数据丢失。 注意：当pod状态为Pending且pod已分配给Node，或pod状态为Running时，pod将主动使用PVC。 Reclaiming当用户完成卷时，他们可以从API中删除PVC对象，从而允许回收资源。PersistentVolume 的回收策略告诉群集在释放其声明后如何处理该卷。 目前，卷可以保留、回收、删除: Retain 保留回收政策允许手动回收资源。删除 PVC 时，PV 仍然存在，并且该卷被视为 已释放。但它还不能被 Claim 使用，因为之前的 Claim 的数据仍在卷上。管理员可以通过以下步骤手动回收该卷: 1231. 删除此PV2. 手动清理相关数据3. 手动删除关联的存储资产 Recycle 警告：Recycle Claim Policy 将会被移除，不推荐使用。相反，推荐的方法是使用动态配置。 Delete 对于支持删除回收策略的卷插件，将删除k8s中的 PV 对象以及外部基础结构中的关联存储资产。动态配置的卷继承其 StorageClass 的回收策略(默认为Delete)。管理员应根据用户的期望配置StorageClass，否则PV必须在创建后进行编辑或修补。 Expanding Persistent Volumes Claims FEATURE STATE: Kubernetes v1.8 alphaFEATURE STATE: Kubernetes v1.11 beta 只有将 StorageClass 的 allowVolumeExpansion 字段设置为 true，才能使用扩展的PVC。现在默认启用对扩展PVC的支持。您可以扩展以下类型的卷： gcePersistentDisk awsElasticBlockStore Cinder glusterfs rbd Azure File Azure Disk Portworx Resizing a volume containing a file system 如果文件系统是XFS，Ext3或Ext4，你可调整包含文件系统的卷的大小。当卷包含文件系统时，仅在使用 RW模式下的 PVC 启动新Pod时才调整文件系统的大小。 12#如果PVC的状态为FileSystemResizePending，则使用PVC重新创建pod是安全的kubectl describe pvc &lt;pvc_name&gt; Resizing an in-use PersistentVolumeClaim FEATURE STATE: Kubernetes v1.11 alpha 要使用它，请启用 ExpandInUsePersistentVolumes。在这种情况下，您无需删除并重新创建使用现有PVC的Pod或Deployment。任何正在使用的PVC在其文件系统扩展后自动可用于其Pod。 持久化卷的类型Types of Persistent Volumes PV类型实现为插件， k8s 目前支持以下插件: GCEPersistentDisk AWSElasticBlockStore AzureFile AzureDisk FC (Fibre Channel) FlexVolume Flocker NFS iSCSI RBD (Ceph Block Device) CephFS Cinder (OpenStack block storage) Glusterfs VsphereVolume Quobyte Volumes HostPath Portworx Volumes ScaleIO Volumes StorageOS Persistent Volumes每个PV都包含 spec 和 status: 123456789101112131415161718apiVersion: v1kind: PersistentVolumemetadata: name: pv0003spec: capacity: storage: 5Gi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle storageClassName: slow mountOptions: - hard - nfsvers=4.1 nfs: path: /tmp server: 172.17.0.2 PersistentVolumeClaims每个PVC都包含了 spec 和 status: 1234567891011121314151617kind: PersistentVolumeClaimapiVersion: v1metadata: name: myclaimspec: accessModes: - ReadWriteOnce volumeMode: Filesystem resources: requests: storage: 8Gi storageClassName: slow selector: matchLabels: release: "stable" matchExpressions: - &#123;key: environment, operator: In, values: [dev]&#125; Claims As VolumesPods使用 claim as a volume 来访问存储。声明必须与使用声明的pod存在于同一名称空间中。群集在pod的命名空间中查找声明，并使用它来获取支持声明的PV，然后将卷挂载到主机并进入容器。 123456789101112131415kind: PodapiVersion: v1metadata: name: mypodspec: containers: - name: myfrontend image: dockerfile/nginx volumeMounts: - mountPath: "/var/www/html" name: mypd volumes: - name: mypd persistentVolumeClaim: claimName: myclaim 编写可移植配置如果您正在编写在各种群集上运行并需要持久存储的配置模板或示例，我们建议您使用以下模式： 在配置中包含PVC对象 不要在配置中包含PV对象，因为实例化配置的用户可能没有创建PV的权限 在实例化模板时，为用户提供提供存储类名称的选项 如果用户提供存储类名称，请将该值放入 persistentVolumeClaim.storageClassName 字段中 如果用户未提供存储类名称，请将 persistentVolumeClaim.storageClassName 字段保留为 nil 这将导致使用群集中的默认StorageClass为用户自动配置PV 在您的工具中，请注意一段时间后未受约束的PVC并将其显示给用户，因为这可能表明群集没有动态存储支持或群集没有存储系统 Storage ClassesStorageClass 为管理员提供了一种描述他们提供的 存储类 的方法。不同的类可能映射到服务质量级别、备份策略，或者由集群管理员确定的任意策略。k8s 本身对于类代表什么是不受任何影响的，这个概念有时在其他存储系统中称为profile。 垃圾收集Kubernetes 垃圾收集器的角色是删除指定的对象，这些对象曾经有但以后不再拥有 Owner 了。 某些Kubernetes对象是其它一些对象的Owner。如，一个副本集是一组pod的Owner。具有Owner的对象被称为是Owner的Dependent。每个Dependent对象具有一个执行所属对象的metadata.ownerReference字段。 有时，Kubernetes会自动设置ownerReference的值。也可以手动设置ownerReference的值，来指定Owner和Dependent之间的关系。 控制垃圾收集器删除Dependent 级联删除 background foreground删除对象时自动删除Dependent。在bg级联删除模式下，k8s会立即删除Owner对象，然后垃圾收集器会在后台删除这些Dependent。在fg级联删除模式下，根对象首先进入删除中状态。一旦对象被设置为删除中状态，垃圾收集器会删除对象的所有Dependent。 孤儿删除对象时，不自动删除它的Dependent。这些Dependent就被称作孤儿。垃圾收集器在删除了所有 “Blocking” 状态的 Dependent（对象的 ownerReference.blockOwnerDeletion=true）之后，它会删除 Owner 对象。 教程Tutorials 教程展示了如何实现比单个任务更大的目标(task)。 一个栗子栗子里面包含一个Service和Deployment，请一定要注意yaml的语法格式，不使用-的话可能会报错。很多k8s配置我们只需要在云界面上小配置，看它生成的YAML文件如何，之后再进行相应修改即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130#注意yaml语法错误apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginx-deployment-test namespace: default labels: k8s-app: nginx env: test annotations: des: A k8s-deployment test author: Zhang21 date: 2018-09-13spec: replicas: 1 selector: matchLabels: k8s-app: nginx strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 50% maxSurge: 50% template: metadata: labels: k8s-app: nginx spec: dnsPolicy: ClusterFirst restartPolicy: Always volumes: - name: test01 emptyDir: &#123;&#125; - name: test02 hostPath: path: /tmp/k8s/volume/test02 containers: - name: nginx image: nginx:1.12.2 imagePullPolicy: Always #特权容器 securityContext: privileged: true workingDir: /usr/share/nginx/html ports: - protocol: TCP containerPort: 80 readinessProbe: httpGet: path: / port: 80 scheme: HTTP initialDelaySeconds: 10 periodSeconds: 5 livenessProbe: httpGet: path: / port: 80 scheme: HTTP #60s内，Server未启动则重启容器 initialDelaySeconds: 60 periodSeconds: 10 env: - name: AUTHOR value: Zhang21 - name: EMAIL value: me@zhang21.cn volumeMounts: - name: test01 mountPath: /usr/share/nginx/html/test01 - name: test02 mountPath: /usr/share/nginx/html/test02 resources: requests: cpu: 100m memory: 100Mi limits: cpu: 0.3 memory: 300Mi imagePullSecrets: - name: docker-secret---apiVersion: v1kind: Servicemetadata: name: nginx-service-test namespace: default labels: k8s-app: nginx annotations: des: A k8s Service test author: Zhang21 date: 2018-09-13spec: #记得指定应用，不然服务无法找到后端端点和容器组 selector: k8s-app: nginx type: NodePort ports: - name: http nodePort: 31234 #The range of valid ports is 30000-32767 protocol: TCP port: 80 targetPort: 80status: loadBalancer: &#123;&#125;##ClusterIP#spec:# ports:# - name: http# protocol: TCP# port: 80# targetPort: 80# selector:# k8s-app: nginx# type: ClusterIP###spec:# ports:# - name: http# protocol: TCP# port: 80# targetPort: 80# selector:# k8s-app: nginx# type: LoadBalancer# loadBalancerIP: 1.2.3.4 执行: 123456789kubectl apply -f ./nginx.yaml#apply可修改后更新kubectl apply -f ./nginx.yaml#之后在dashboard中查看成功与否#访问master 31234 portcurl master:31234 k8s基本 综述本教程提供了Kubernetes集群编排系统基础知识的介绍。 你将学到： 在集群上部署容器化服务 伸缩部署 使用新软件版本更新容器化应用程序 调试容器化应用程序 k8s能为你做什么？容器化有助于打包软件以实现这些目标，是应用程序能够以简单快速的方式发布和更新，而无需停机。k8s可帮助你确保这些容器化应用程序随时随地运行，并帮助它们找到运行所需的资源。 k8s 基础模块 创建(create)一个k8s集群 部署(deploy)应用程序 探索(explore)应用程序 公开(expose)展示应用程序 伸缩(scale)应用程序 升级(update)应用程序 创建集群Create a Cluseter 详情见安装部分。 部署应用程序Deploy an APP 使用kubectl创建部署Using kubectl to create a Deployment 目标： 了解应用程序部署 在k8s上使用kubectl部署你的第一个应用程序 k8s Deployments一旦运行了k8s集群，就可在其上部署容器化应用程序。为此，你需要创建Kubernetes Deployment configuration。它指示k8s 如何创建和更新应用程序实例。创建部署后，k8s master将应用程序实例调度到各个node上。创建应用程序实例后，Kubernetes Deployment Controller会持续监控这些实例。如果主机节点上的实例关闭或删除，Deployment Controller会替换它。这提供了一种自我修复(self-healing)机制来解决机器故障或维护。 部署应用程序可使用kubectl(使用k8s api与集群交互)来创建和管理Deployment。下面有一些关于使用kubectl在k8s集群上创建和管理Deployment的基础命令。 创建部署时，你需要指定应用程序的容器镜像(image)，以及要运行的副本数(replicas)。你可在以后改变这些信息来更新你的部署。 栗子：第一个部署，k8s使用一个Docker容器的Node.js应用程序包。 12345678910111213141516171819202122kubectl version#client#serverkubectl get nodes#创建名为k8s-bootcamp的deploymentkubectl run kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1 --port=8080#这是国内镜像: docker.io/jocatalin/kubernetes-bootcamp:v1kubectl get deploymentsNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEkubenetes-bootcamp 1 1 1 1 1h#表示 希望副本数，当前副本数，最新副本数，可用副本数#由于pod被封装在集群私网，没有对外开放#proxy将通信转发到集群内私网kubectl proxycurl http://localhost:8081/versioncurl http://localhost:8001/api/v1/namespaces/default/pods/$POD_NAME/proxy/#Hello Kubernetes bootcamp! 此处我遇到一个错误，replicats unavailable:原因是拉取的镜像在谷歌云上，无法访问，拉取失败所以导致部署失败。gcr(google container Registry) 12345678910111213141516171819#查看部署信息 kubectl get deployment kubernetes-bootcamp -o yaml message: &apos;unable to create pods: No API token found for service account &quot;default&quot;, retry after the token is automatically created and added to the service account&apos; reason: FailedCreate status: &quot;True&quot; type: ReplicaFailurekubectl get deploymentsNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEkubernetes-bootcamp 1 0 0 0 33mkubectl describe deployments kubernetes-bootcampReplicas: 1 desired | 0 updated | 0 total | 0 available | 1 unavailableStrategyType: RollingUpdateReplicaFailure True FailedCreate 针对unable to create pods: No API token found for service account “default”这个问题，需要修改kube-apiserver配置文件： 123456789101112131415161718192021222324252627282930313233343536#去掉 KUBE_ADMISSION_CONTROL中的SecurityContextDeny,ServiceAccountKUBE_ADMISSION_CONTROL=&quot;--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota&quot;#重启kube-apiserversystemctl restart kube-apiserver#之后查看副本数就正常了kubectl get deploymentsNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEkubernetes-bootcamp 1 1 1 0 8m#这里available还是0kubectl get podsNAME READY STATUS RESTARTS AGEkubernetes-bootcamp-390780338-6x48n 0/1 ContainerCreating 0 21h#pod处于创建状态#查看详情kubectl describe pods#错误信息 Warning FailedSync 4m (x258 over 21h) kubelet, 192.168.31.159 Error syncing pod, skipping: failed to &quot;StartContainer&quot; for &quot;POD&quot; with ErrImagePull: &quot;image pull failed for registry.access.redhat.com/rhel7/pod-infrastructure:latest, this may be because there are no credentials on this request. details: (open /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt: no such file or directory)&quot; Warning FailedSync 9s (x5728 over 21h) kubelet, 192.168.31.159 Error syncing pod, skipping: failed to &quot;StartContainer&quot; for &quot;POD&quot; with ImagePullBackOff: &quot;Back-off pulling image \&quot;registry.access.redhat.com/rhel7/pod-infrastructure:latest\&quot;&quot;#在node上查看此文件，发现它指向了一个空链接#并不存在/etc/rhsm目录ll /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crtlrwxrwxrwx. 1 root root 27 7月 16 16:58 /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt -&gt; /etc/rhsm/ca/redhat-uep.pem#在node安装此rhsmyum search rhsm#python-rhsm-certificates.x86_64#python-rhsm.x86_64yum install -y python-rhsm.x86_64 python-rhsm-certificates.x86_64#之后在node上手动拉取下image便可看到pod正常运行 探索应用程序Explore Your App 查看Pods和Nodes目标： 了解k8s Pods 了解k8s Nodes 部署应用的故障解决(troubleshoot) k8s Pods当你创建一个部署时，k8s创建了一个pod来托管你的应用程序实例。pod是k8s的一个抽象，表示一组(一个/多个)应用程序容器，以及这些容器的共享资源。pod有一个唯一的IP地址，甚至是同一节点上的pod。pod中的容器共享IP地址和端口，始终位于同一位置并共同调度，并在同一节点上共享上下文中运行。这些资源包括： 共享存储(volumes) 网络(唯一的集群内ip) 运行容器的相关信息 Nodespod总是运行在node上，一个node上可运行多个pod。每个node由master管理，master自动处理在node上调度pod。node至少运行如下组件： kubelet container runtime(如docker) Troubleshooting with kubectl最常用的kubectl命令： 12345678910111213141516171819#列出资源kubectl get#kubectl get nodes#某个资源的详细信息kubectl describe#kubectl describe deployments kubernetes-bootcamp#pod中容器日志kubectl logs#kubectl logs $pod --since=1h#在pod的容器执行命令kubectl exec#kubectl ecec $pod env#kubectl exec -it $pod /bin/bash 公开展示应用程序Expose Your App Publicly 使用服务来展示应用程序Using a Service to Expose Your App 目标： 了解k8s中的服务(service) 理解labels和LabelSelector对象如何关联服务 使用服务将应用程序展示在集群外部 k8s Service事实上，pods有一个生命周期。当工作node死亡，node上运行的pods也会丢失。ReplicationController可以通过创建新的Pod来动态地将集群驱动会所需状态，以使应用程序保持运行。k8s的服务是一个抽象概念，它定义了一组逻辑Pod和一个访问pods的策略。服务使用YAML或JSON来定义。由一组pods所构成的服务通常由LabelSelector来确定。尽管每个Pod都有一个唯一的IP地址，但如果没有服务，这些IP就不会在集群外公开。通过指定ServeceSpec中的type，可以不同方式公开服务: ClusterIP(默认方式)在集群内部IP公开服务，只可内部访问 NodePort使用NAT在集群的指定节点上公开服务 LoadBalancer创建一个外部负载均衡器，并给服务分配一个外部IP ExternalName通过返回带有名称的CNAME(k8s-dns)记录，使用任意名称公开服务 Services和Labels服务使用labels和selectors匹配一组pod这是一个允许对k8s的对象进行逻辑操作的分组原语。Label是附件到对象的键/值对，随时随地可修改。有多种方式可使用： 指定用于开发(development)、测试(test)、生产(procuct)的对象 嵌入版本tag 使用tag对对象进行分类 栗子： 1234567891011121314151617181920212223242526272829303132333435kubectl get pods#NAME READY STATUS RESTARTS AGE#kubernetes-bootcamp-390780338-6x48n 1/1 Running 0 22hkubectl get services#NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE#kubernetes ClusterIP 10.254.0.1 &lt;none&gt; 443/TCP 1d#公开展示应用程序kubectl expose deployment/kubernetes-bootcamp --type=&quot;NodePort&quot; --port 8080#service &quot;kubernetes-bootcamp&quot; exposedkubectl get services#NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE#kubernetes ClusterIP 10.254.0.1 &lt;none&gt; 443/TCP 1d#kubernetes-bootcamp NodePort 10.254.11.76 &lt;none&gt; 8080:31514/TCP 2mkubectl describe services/kubernetes-bootcampkubectl describe deployment#Labels: run=kubernetes-bootcamp#使用label查询kubectl get pods -l run=kubernetes-bootcampkubectl get services -l run=kubernetes-bootcamp#使用label删除kubectl delete service -l run=kubernetes-bootcampkubectl describe pods kubernetes-bootcamp-390780338-6x48nkubectl exec -it kubernetes-bootcamp-390780338-6x48n /bin/bash 扩展应用程序Scale Your App Running Multiple Instances of Your App 目标： 使用kubectl伸缩应用程序 伸缩应用程序前面通过部署创建的服务仅有一个pod，当遇到流量激增，我们便需要扩展应用程序。通过更改部署中的副本数来完成扩展。 扩展部署将确保使用可用资源(available resource)创建新的pod并将其调度到node。k8s支持Pod的自动伸缩，缩放到0(也就是没有pod)也是可能的，它将终止指定部署的所有Pod。对应用程序运行多个实例需要一种方法将流量分配给所有这些实例。服务有集成的负载均衡器(load-blancer)，可将网络流量分配到公开部署的所有Pod。服务将使用endpoint持续监控运行的Pod，以确保网络流量发送到可用的Pods。 一旦运行的应用程序有了多个实例，你就可以在不停机(downtime)的情况下执行滚动更新(rolling update)。 12345678910111213141516171819202122232425262728293031323334353637383940kubectl get deployments#1个#扩展实例kubectl scale deployments/kubernetes-bootcamp --replicas=4#deployment.extensions &quot;kubernetes-bootcamp&quot; scaledkubectl get deployments#4个kubectl get pods -o wide#4个kubectl describe deployment/kubernetes-bootcampkubectl describe services/kubernetes-bootcamp#缩放实例kubectl scale deployments/kubernetes-bootcamp --replicas=2#deployment.extensions &quot;kubernetes-bootcamp&quot; scaledkubectl get deployments#2个#有两个pods正在关闭中kubectl get pods -o wideNAME READY STATUS RESTARTS AGE IP NODEkubernetes-bootcamp-390780338-1zgvs 1/1 Terminating 0 7m 10.254.76.5 192.168.31.159kubernetes-bootcamp-390780338-6x48n 1/1 Running 0 2d 10.254.76.2 192.168.31.159kubernetes-bootcamp-390780338-bqztg 1/1 Running 0 7m 10.254.76.4 192.168.31.159kubernetes-bootcamp-390780338-hkwfd 1/1 Terminating 0 7m 10.254.76.3 192.168.31.159#关闭完成kubectl get pods -o wideNAME READY STATUS RESTARTS AGE IP NODEkubernetes-bootcamp-390780338-6x48n 1/1 Running 0 2d 10.254.76.2 192.168.31.159kubernetes-bootcamp-390780338-bqztg 1/1 Running 0 15m 10.254.76.4 192.168.31.159 升级应用程序Update your AppPerforming a Rolling Update 目标： 使用kubectl执行滚动升级 滚动更新用户希望应用程序始终可用，可发人员可能会多次部署新版本应用程序。在k8s中，这都可以通过滚动更新(rolling update)完成。滚动更新允许通过使用新的实例逐步更新Pod来实现部署的更新，而不需停机(downtime)。新的Pod将在具有可用资源的node上进行调度。在k8s中，更新是版本化的，任何部署更新都可以恢复到以前的版本。 与应用程序扩展类似，服务在更新期间仅会将流量负载均衡到可用的Pod(应用实例)。 滚动更新允许以下操作： 将应用程序从一个环境推到另一个环境 回滚(rollback)到之前的版本 无需停机的持续集成(CI)和持续交付(CD) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263kubectl get deploymentskubectl get pods#2个#更新镜像kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=docker.io/jocatalin/kubernetes-bootcamp:v2deployment.apps &quot;kubernetes-bootcamp&quot; image updated#kubectl get podsNAME READY STATUS RESTARTS AGEkubernetes-bootcamp-390780338-6x48n 1/1 Terminating 0 3dkubernetes-bootcamp-390780338-bqztg 1/1 Terminating 0 38mkubernetes-bootcamp-472176051-m6h1q 1/1 Running 0 29skubernetes-bootcamp-472176051-z4wqs 1/1 Running 0 29s#kubectl get podsNAME READY STATUS RESTARTS AGEkubernetes-bootcamp-472176051-m6h1q 1/1 Running 0 42skubernetes-bootcamp-472176051-z4wqs 1/1 Running 0 42s#检查回滚状态kubectl rollout status deployments/kubernetes-bootcampdeployment &quot;kubernetes-bootcamp&quot; successfully rolled out#更新kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=docker.io/jocatalin/kubernetes-bootcamp:v10deployment.apps &quot;kubernetes-bootcamp&quot; image updated#有错kubectl get deploymentsNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEkubernetes-bootcamp 2 3 2 1 3d#有错kubectl get podsNAME READY STATUS RESTARTS AGEkubernetes-bootcamp-384357858-7kjx1 0/1 ErrImagePull 0 2mkubernetes-bootcamp-384357858-t0wmt 0/1 ImagePullBackOff 0 2mkubernetes-bootcamp-472176051-m6h1q 1/1 Running 0 9m#kubectl describe pods#回滚kubectl rollout undo deployments/kubernetes-bootcampdeployment.apps &quot;kubernetes-bootcamp&quot;#查看kubectl get podskubectl decribe pods#Image: docker.io/jocatalin/kubernetes-bootcamp:v2#回到了V2版 配置Configuration 使用ConfigMap配置Redis目标(Objective) 创建ConfigMap 使用ConfigMap创建Pod规范 创建Pod 验证配置是否正确应用 开始之前需要有k8s集群，并且安装了kubectl命令行工具。 栗子：使用ConfigMap配置Redis 12345678910111213141516171819202122232425262728293031323334353637383940414243#Master#创建redis的ConfigMapkubectl create configmap redis-config --from-file=xxx/redis-configkubectl get configmap redis-config -o yaml#创建redis-pod.yaml文件apiVersion: v1kind: Podmetadata: name: redisspec: containers: - name: redis image: kubernetes/redis:v1 env: - name: MASTER value: &quot;true&quot; ports: - containerPort: 6379 resources: limits: cpu: &quot;0.1&quot; volumeMounts: - mountPath: /redis-master-data name: data - mountPath: /redis-master name: config volumes: - name: data emptyDir: &#123;&#125; - name: config configMap: name: redis-config items: - key: redis-config path: redis.conf#创建podkubectl create -f /etc/k8s/pods/config/redis-pod.yamlkubectl exec -it redis redis-cli 无状态应用程序Stateless Applications 公开外物IP以访问集群中的应用程序Exposing an External IP Address to Access an Application in a Cluster 目标 为一个Hello World应用程序运行五个实例 创建一个展示外部IP的服务对象 使用服务对象去访问运行的应用程序 为运行五个pods的应用程序创建一个服务 12345678910111213141516171819202122232425262728#运行hello worldkubectl run hello-world --replicas=5 --labels=&quot;run=load-balancer-example&quot; --image=gcr.io/google-samples/node-hello:1.0 --port=8080#--image=docker.io/jocatalin/hellonode:v1#查看信息kubectl get deployments hello-worldkubectl describe deployments hello-worldkubectl get replicasetskubectl describe replicasets#创建展示部署的服务对象kubectl expose deployment hello-world --type=LoadBalancer --name=my-service#如果外部地址显示为pending，请等待几分钟#查看信息kubectl get services my-servicekubectl describe services my-service#可看到LoanBlancer Ingresskubectl get pods --output=wide#访问外部地址(LoadBalancer Ingress)curl http://&lt;external-ip&gt;:&lt;port&gt; 清理 123456#删除服务kubectl delete services my-service#删除正在运行的程序的Deployment，ReplicaSet，Podskubectl delete deployment hello-world]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>k8s</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[性能分析]]></title>
    <url>%2F2018%2F05%2F14%2F%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[环境： CentOS7.x84_64 参考: strace命令: http://man.linuxde.net/strace pstack命令: http://man.linuxde.net/pstack lsof命令: http://man.linuxde.net/lsof 系统调用: https://zh.wikipedia.org/wiki/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8 Linux系统调用列表: https://www.ibm.com/developerworks/cn/linux/kernel/syscall/part1/appendix.html#8 高CPU分析: http://blog.51cto.com/yaocoder/1543352 系统调用系统调用(system call)，指运行在用户态的程序向操作系统内核请求需要更高权限运行的服务。系统调用提供用户程序与操作系统之间的接口。操作系统的进程空间可分为用户态和内核态，它们需要不同的执行权限。其中系统调用运行在内核态。 大多数系统交互式操作需求在内核态运行。如设备I/O或进程间通信。 内核态(kernel space)内核、核心扩充、驱动程序运行在内核空间上。 用户态(user space)其它的应用程序，则运行在用户空间上。所有运行在用户空间的应用程序，都被统称为用户级(userland)。 库函数系统调用和普通库函数调用非常相似，只是系统调用由操作系统内核提供，运行于内核核心态；而普通的库函数调用由函数库或用户自己提供，运行于用户态。 系统调用的意义 内核提供用户空间程序与内核空间进行交互的一套标准接口，这些接口让用户态程序能受限访问硬件设备，比如申请系统资源，操作设备读写，创建新进程等。用户空间发生请求，内核空间负责执行，这些接口便是用户空间和内核空间共同识别的桥梁，这里提到两个字“受限”，是由于为了保证内核稳定性，而不能让用户空间程序随意更改系统，必须是内核对外开放的且满足权限的程序才能调用相应接口。 在用户空间和内核空间之间，有一个叫做Syscall(系统调用, system call)的中间层，是连接用户态和内核态的桥梁。这样即提高了内核的安全型，也便于移植，只需实现同一套接口即可。Linux系统，用户空间通过向内核空间发出Syscall，产生软中断，从而让程序陷入内核态，执行相应的操作。对于每个系统调用都会有一个对应的系统调用号，比很多操作系统要少很多。 安全性与稳定性：内核驻留在受保护的地址空间，用户空间程序无法直接执行内核代码，也无法访问内核数据，通过系统调用 性能：Linux上下文切换时间很短，以及系统调用处理过程非常精简，内核优化得好，所以性能上往往比很多其他操作系统执行要好。 Linux系统调用方法 futexFutex 是fast userspace mutex的缩写，意思是快速用户空间互斥体。Linux内核把它们作为快速的用户空间的锁和信号量的预制构件提供给开发者。 selectselect系统调用允许程序同时在多个底层文件表述符上，等待输入的到达或输出的完成。 进程控制 函数 描述 fork 创建一个新进程 clone 按指定条件创建子进程 execve 运行可执行文件 exit 中止进程 _exit 立即中止当前进程 getdtablesize 进程所能打开的最大文件数 getpgid 获取指定进程组标识号 setpgid 设置指定进程组标志号 getpgrp 获取当前进程组标识号 setpgrp 设置当前进程组标志号 getpid 获取进程标识号 getppid 获取父进程标识号 getpriority 获取调度优先级 setpriority 设置调度优先级 modify_ldt 读写进程的本地描述表 nanosleep 使进程睡眠指定的时间 nice 改变分时进程的优先级 pause 挂起进程，等待信号 personality 设置进程运行域 prctl 对进程进行特定操作 ptrace 进程跟踪 sched_get_priority_max 取得静态优先级的上限 sched_get_priority_min 取得静态优先级的下限 sched_getparam 取得进程的调度参数 sched_getscheduler 取得指定进程的调度策略 sched_rr_get_interval 取得按RR算法调度的实时进程的时间片长度 sched_setparam 设置进程的调度参数 sched_setscheduler 设置指定进程的调度策略和参数 sched_yield 进程主动让出处理器,并将自己等候调度队列队尾 vfork 创建一个子进程，以供执行新程序，常与execve等同时使用 wait 等待子进程终止 wait3 参见wait waitpid 等待指定子进程终止 wait4 参见waitpid capget 获取进程权限 capset 设置进程权限 getsid 获取会晤标识号 setsid 设置会晤标识号 文件系统控制： 文件读写操作 fcntl 文件控制 open 打开文件 creat 创建新文件 close 关闭文件描述字 read 读文件 write 写文件 readv 从文件读入数据到缓冲数组中 writev 将缓冲数组里的数据写入文件 pread 对文件随机读 pwrite 对文件随机写 lseek 移动文件指针 _llseek 在64位地址空间里移动文件指针 dup 复制已打开的文件描述字 dup2 按指定条件复制文件描述字 flock 文件加/解锁 poll I/O多路转换 truncate 截断文件 ftruncate 参见truncate umask 设置文件权限掩码 fsync 把文件在内存中的部分写回磁盘 文件系统操作 access 确定文件的可存取性 chdir 改变当前工作目录 fchdir 参见chdir chmod 改变文件方式 fchmod 参见chmod chown 改变文件的属主或用户组 fchown 参见chown lchown 参见chown chroot 改变根目录 stat 取文件状态信息 lstat 参见stat fstat 参见stat statfs 取文件系统信息 fstatfs 参见statfs readdir 读取目录项 getdents 读取目录项 mkdir 创建目录 mknod 创建索引节点 rmdir 删除目录 rename 文件改名 link 创建链接 symlink 创建符号链接 unlink 删除链接 readlink 读符号链接的值 mount 安装文件系统 umount 卸下文件系统 ustat 取文件系统信息 utime 改变文件的访问修改时间 utimes 参见utime quotactl 控制磁盘配额 系统控制： ioctl I/O总控制函数 _sysctl 读/写系统参数 acct 启用或禁止进程记账 getrlimit 获取系统资源上限 setrlimit 设置系统资源上限 getrusage 获取系统资源使用情况 uselib 选择要使用的二进制函数库 ioperm 设置端口I/O权限 iopl 改变进程I/O权限级别 outb 低级端口操作 reboot 重新启动 swapon 打开交换文件和设备 swapoff 关闭交换文件和设备 bdflush 控制bdflush守护进程 sysfs 取核心支持的文件系统类型 sysinfo 取得系统信息 adjtimex 调整系统时钟 alarm 设置进程的闹钟 getitimer 获取计时器值 setitimer 设置计时器值 gettimeofday 取时间和时区 settimeofday 设置时间和时区 stime 设置系统日期和时间 time 取得系统时间 times 取进程运行时间 uname 获取当前UNIX系统的名称、版本和主机等信息 vhangup 挂起当前终端 nfsservctl 对NFS守护进程进行控制 vm86 进入模拟8086模式 create_module 创建可装载的模块项 delete_module 删除可装载的模块项 init_module 初始化模块 query_module 查询模块信息 *get_kernel_syms 取得核心符号,已被query_module代替 ioctl I/O总控制函数 _sysctl 读/写系统参数 acct 启用或禁止进程记账 getrlimit 获取系统资源上限 setrlimit 设置系统资源上限 getrusage 获取系统资源使用情况 uselib 选择要使用的二进制函数库 ioperm 设置端口I/O权限 iopl 改变进程I/O权限级别 outb 低级端口操作 reboot 重新启动 swapon 打开交换文件和设备 swapoff 关闭交换文件和设备 bdflush 控制bdflush守护进程 sysfs 取核心支持的文件系统类型 sysinfo 取得系统信息 adjtimex 调整系统时钟 alarm 设置进程的闹钟 getitimer 获取计时器值 setitimer 设置计时器值 gettimeofday 取时间和时区 settimeofday 设置时间和时区 stime 设置系统日期和时间 time 取得系统时间 times 取进程运行时间 uname 获取当前UNIX系统的名称、版本和主机等信息 vhangup 挂起当前终端 nfsservctl 对NFS守护进程进行控制 vm86 进入模拟8086模式 create_module 创建可装载的模块项 delete_module 删除可装载的模块项 init_module 初始化模块 query_module 查询模块信息 *get_kernel_syms 取得核心符号,已被query_module代替 内存管理： brk 改变数据段空间的分配 sbrk 参见brk mlock 内存页面加锁 munlock 内存页面解锁 mlockall 调用进程所有内存页面加锁 munlockall 调用进程所有内存页面解锁 mmap 映射虚拟内存页 munmap 去除内存页映射 mremap 重新映射虚拟内存地址 msync 将映射内存中的数据写回磁盘 mprotect 设置内存映像保护 getpagesize 获取页面大小 sync 将内存缓冲区数据写回硬盘 cacheflush 将指定缓冲区中的内容写回磁盘 网络管理： getdomainname 取域名 setdomainname 设置域名 gethostid 获取主机标识号 sethostid 设置主机标识号 gethostname 获取本主机名称 sethostname 设置主机名称 socket控制： socketcall socket系统调用 socket 建立socket bind 绑定socket到端口 connect 连接远程主机 accept 响应socket连接请求 send 通过socket发送信息 sendto 发送UDP信息 sendmsg 参见send recv 通过socket接收信息 recvfrom 接收UDP信息 recvmsg 参见recv listen 监听socket端口 select 对多路同步I/O进行轮询 shutdown 关闭socket上的连接 getsockname 取得本地socket名字 getpeername 获取通信对方的socket名字 getsockopt 取端口设置 setsockopt 设置端口参数 sendfile 在文件或端口间传输数据 socketpair 创建一对已联接的无名socket 用户管理： getuid 获取用户标识号 setuid 设置用户标志号 getgid 获取组标识号 setgid 设置组标志号 getegid 获取有效组标识号 setegid 设置有效组标识号 geteuid 获取有效用户标识号 seteuid 设置有效用户标识号 setregid 分别设置真实和有效的的组标识号 setreuid 分别设置真实和有效的用户标识号 getresgid 分别获取真实的,有效的和保存过的组标识号 setresgid 分别设置真实的,有效的和保存过的组标识号 getresuid 分别获取真实的,有效的和保存过的用户标识号 setresuid 分别设置真实的,有效的和保存过的用户标识号 setfsgid 设置文件系统检查时使用的组标识号 setfsuid 设置文件系统检查时使用的用户标识号 getgroups 获取后补组标志清单 setgroups 设置后补组标志清单 进程间通信： ipc, 进程间通信总控制调用 信号 sigaction 设置对指定信号的处理方法 sigprocmask 根据参数对信号集中的信号执行阻塞/解除阻塞等操作 sigpending 为指定的被阻塞信号设置队列 sigsuspend 挂起进程等待特定信号 signal 参见signal kill 向进程或进程组发信号 *sigblock 向被阻塞信号掩码中添加信号,已被sigprocmask代替 *siggetmask 取得现有阻塞信号掩码,已被sigprocmask代替 *sigsetmask 用给定信号掩码替换现有阻塞信号掩码,已被sigprocmask代替 *sigmask 将给定的信号转化为掩码,已被sigprocmask代替 *sigpause 作用同sigsuspend,已被sigsuspend代替 sigvec 为兼容BSD而设的信号处理函数,作用类似sigaction ssetmask ANSI-C的信号处理函数,作用类似sigaction 消息 msgctl 消息控制操作 msgget 获取消息队列 msgsnd 发消息 msgrcv 取消息 管道 pipe, 创建管道 信号量 shmctl 控制共享内存 shmget 获取共享内存 shmat 连接共享内存 shmdt 拆卸共享内存 共享内存 shmctl 控制共享内存 shmget 获取共享内存 shmat 连接共享内存 shmdt 拆卸共享内存 strace命令strace命令是一个集诊断、调试、统计与一体的工具，我们可以使用strace对应用的系统调用和信号传递的跟踪结果来对应用进行分析，以达到解决问题或者是了解应用工作过程的目的。当然strace与专业的调试工具比如说gdb之类的是没法相比的，因为它不是一个专业的调试器。 strace的最简单的用法就是执行一个指定的命令，在指定的命令结束之后它也就退出了。在命令执行的过程中，strace会记录和解析命令进程的所有系统调用以及这个进程所接收到的所有的信号值。 strace可跟踪一个命令或进程。 123strace - trace system calls and signalsstrace --help 问题案例当发现进程或服务异常时，我们可以通过strace来跟踪其系统调用，“看看它在干啥”，进而找到异常的原因。熟悉常用系统调用，能够更好地理解和使用strace。当然，万能的strace也不是真正的万能。当目标进程卡死在用户态时，strace就没有输出了。 定位进程异常退出 定位共享内存异常 性能分析 pstack命令pstack命令可显示每个进程(线程)的栈跟踪。 123yum install -y gdbpstack $PID lsof命令lsof命令用于查看你进程开打的文件，打开文件的进程，进程打开的端口(TCP、UDP)。 123456789101112-a：列出打开文件存在的进程-c&lt;进程名&gt;：列出指定进程所打开的文件-g：列出GID号进程详情-d&lt;文件号&gt;：列出占用该文件号的进程+d&lt;目录&gt;：列出目录下被打开的文件+D&lt;目录&gt;：递归列出目录下被打开的文件-n&lt;目录&gt;：列出使用NFS的文件-i&lt;条件&gt;：列出符合条件的进程（4、6、协议、:端口、 @ip ）-p&lt;进程号&gt;：列出指定进程号所打开的文件-u：列出UID号进程详情-h：显示帮助信息-v：显示版本信息 高CPU占用分析步骤： 查看进程 top 查看线程 top -H -p $pid 查看进程打开连接数 lsof -p ${pid} 追踪 strace -T -r -c -p $pid 栈 pstack $pid]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>系统调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python]]></title>
    <url>%2F2018%2F05%2F06%2FPython%2F</url>
    <content type="text"><![CDATA[环境: CentOS7x86_64 Python3.5 参考: Python教程: https://docs.python.org/3.5/tutorial/index.html Python术语: https://docs.python.org/3.5/glossary.html Python语言参考: https://docs.python.org/3.5/reference/index.html Python HOWTOs: https://docs.python.org/3.5/howto/index.html Python标准库: https://docs.python.org/3.5/library/ PyPI: https://pypi.org/ Awesome-Python https://github.com/vinta/awesome-python https://github.com/jobbole/awesome-python-cn 术语Glossary &gt;&gt;&gt;交互式shell的默认Python提示符 ...在为缩进代码块输入代码时，或在一对匹配的左右分隔符中，交互式shell的默认Python提示符 2to3将Python2.x代码转换为Python3.x代码的工具 抽象基类(abstract base class) 参数(argument)调用函数时传递给(或方法)的值: 关键字参数/可选参数 异步上下文管理器(asynchronous context manager)控制在异步语句中看到的环境对象 异步生成器(asynchronous generator)返回一个生成器迭代器的函数 异步生成器迭代器(asynchronous generator iterator)由异步生成器创建的对象 异步可迭代(asynchronous iterable)一个对象 异步迭代器(asynchronous iterator)一个对象 属性(attribute)按名称引用的对象关联的值 awaitable一个对象 二进制文件(binary file)能读写bytes-like对象的文件对象 bytes-like对象支持Buffer Protocol并可以导出C-contiguous buffer的对象 字节码(bytecode)Python源代码被编译成字节码 类(class)用于创建用户对象的模板 coercion在涉及两个相同类型参数的操作中，将一个类型的实例隐式转换为另一个类型的实例 复数(complex number) 上下文管理器(context manager) contiguous 协程(coroutine) coroutine function CPythonPython语言的规范实现 修饰器(decorator)返回另一个函数的函数 描述(descriptor) 字典(dictionary) 字典视图(dictionary view)从dict.keys(), dict.values(), dict.items()返回的对象称为字典视图 文档字符串(docstring)在类，函数，或模块中的第一个表达式出现的字符串文字 duck-typing一种编程风格 表达式(expression) 扩展模块(extension module)由C/C++编写，通过Python API与核心和用户代码交互 f-string 文件对象(file object) finder为正在导入的模块查找加载程序的对象 地板除(floor division) 函数(function) 函数注释(function annotation) __future__可使用伪模块来启用与当前解释器不兼容的新语言功能 垃圾回收(garbage collection)不再使用时释放内存的过程 生成器(generator) generator iterator 生成器表达式(generator expression)返回迭代器的表达式 通用函数(generic function)由多个函数组成的函数 global interpreter lock确保一次只有一个线程执行Python字节码的机制 hashable如果一个对象具有在其生命周期内从不改变的hash值，并且可与其它对象相比，那么这个对象就是可hash的 IDLEPython的集成开发环境 一成不变的(immutable)具有固定值的对象 易变的(mutable)可改变它们值得对象 import path importing一个模块中的Python代码在另一个Python代码中可获取 importer既能找到又能加载模块的对象 交互式(interactive) 解释型(interpreted)Python是一种解释型语言，与编译型语言相反 interpreter shutdown 迭代(iterable)一次能够返回其成员的对象 迭代器(iterator)表示数据流的对象 关键函数(key function)关键函数或整理函数是一个可调用函数，它返回用于排序的值 关键字参数(keyword argument) lambda一个匿名内联函数，由调用该函数时评估的单个表达式组成 LBYL三思而后行(Look before you leap) 列表(list)一个内建Python序列 list comprehension一种紧凑的方式来处理序列中的全部或部分元素，并返回列表和结果 loader加载模块的对象 映射(mapping)支持任意键查找并实现映射中指定方法的容器对象 meta path finder metaclassThe class of a class 方法(method)类里面定义的函数 method resolution order 模块(module)Python代码的组织单元的对象 module spec named tuple 命名空间(namespace)变量存储的地方 namespace package仅用作子包的包 嵌套范围(nested scope)能够在封闭变量中引用变量 new-style class 对象(object)具有状态和定义行为的任一数据 包(package)可包含子模块或递归子模块的Python模块 参数(parameter)函数或方法定义中的一个命名实体，用于指定该函数可接受的参数。有5中参数: positional-or-keyword: positional-only keyword-only var-positional var-keyword path entry path entry finder path entry hook path based finder path-like object portion单目录中的一组文件 positional argument provisional API provisional package Python 3000Python3.x发行版的昵称 Python化(Pythonic)与Python语言最常见的习惯用法密切相关的想法或代码片段，而不是使用其它语言通用的概念来实现该代码 合格的名字(qualified name) 引用计数(reference count)对某个对象的引用次数 regular package __slots__类中的声明，通过预先声明实例属性的空间并消除实例字典来节省内存 序列(sequence) 单一调度(single dispatch)通用函数调度的一种形式 切片(slice)通常包含一部分序列的对象 special method一种由Python隐式调用的方法 声明(statement) struct sequence具有命名元素的元组 text encoding text file 三重引号(triple-quoted string) type 通用换行符(universal newlines)Unix: \n; Windows: \r\n 变量注释(variable annotation)与模块全局变量或类属性关联的类型元数据值 虚拟环境(virtual environment) 虚拟机(virtual machine) Zen of PythonPythono的设计原理和哲学 教程官网: https://www.python.org/ Python教程非正式地向读者介绍了Python语言和系统的基本概念和功能。Python是一种易于学习，功能强大的编程语言。它具有高效的高级数据结构以及面向对象(object-oriented)编程的简单而有效的方法。优雅的语法和动态类型以及其解释的特性，使其成为大多数平台上许多领域脚本编写(scripting)和快速应用程序开发的理想语言。Python解释器很容易用C或C++实现新功能和数据类型进行扩展。Python也适合作为定制程序的扩展语言。 本教程非正式地向读者介绍了Python语言和系统的基本概念和功能，不会涵盖每个功能。相反，它引入了许多Python最值得注意的功能和语言风格。 激起你的胃口Whetting Your Appetite 将一些工作自动化，或编写一个小程序。 C/C++/Java，编写/编译/测试/重编译周期太慢，但你又不想为你的应用程序开发和设计一门全新的语言。 这样的话，Python就是适合你的语言！ 为一些任务编写Unix shell script或Windows batch file，但它们只适合文本数据，而不适合GUI应用程序…你可以编写C/C++/Java程序，但需要很长的开发时间。Python简单易用，可帮助你更快完成工作。 Python为大型程序提供更多的结构和支持，它提供了更多的错误检查。作为一种非常高级的语言，它有内建的高级数据类型(如灵活的数组和字典)。由于其更通用的数据类型，Python适用于比awk甚至Perl更大的问题域，但Python中的许多事情至少与这些语言一样容易。 Python允许你将你的程序拆分成模块，使其它Python程序能重用。它附带了大量的标准模块，你可将它们作为学习Python编程的基础。包括了: 文件I/O；系统调用；socket；GUI… Python是一种解释型语言，在程序开发中节省大量时间，因为不需要编译和链接。 Python可以使程序紧凑而易读，由Python编写的程序通常比等效的C/C++/Java程序代码少得多。原因如下: 高级数据类型允许你在单个语句中表达复杂的操作 语句分组通过缩进(4个空格)来完成，而不是开始和结束 无需声明变量和参数 Python是可扩展的，如果你会C编程的话，很容易为解释器添加一个新的内置函数或模块，或将Python程序链接到可用库的二进制形式。也可将Python解释器链接到C编写的应用程序中。 顺便说一句，该语言是根据BBC节目Monty Python’s Flying Circus命名，与爬行动物无关。 学习语言的最好方法就是使用它，以工代练！ 解释器Python Interpreter My Linux: /usr/bin/python3 /lib64/python3.5/ 交互模式Interactive Mode 1234python3&gt;&gt;&gt;for i in range(4):... 参数传递Argument Passing 使用sys模块的argv变量给脚本传递参数。 12345678910111213141516171819import sysnum = len(sys.argv)if num != 3: print('Usage: xxx.py argv1 argv2')else: print('argu[0] is ' + sys.argv[0]) print('argu[1] is ' + sys.argv[1]) print('argu[2] is ' + sys.argv[2])chmod u+x xxx.py./argvPass.py 1 22argu[0] is ./argvPass.pyargu[1] is 1argu[2] is 22 编码格式Source Code Encoding 12#!/usr/bin/python3# -*- coding: utf-8 -*- 介绍An Informal Introduction to Python 注意Python的两个默认提示符: &gt;&gt;&gt; ... 作为计算器Using Python as a Calculator Numbers12345678910111213+ -*///(取商)%(取余)**intfloatdecimalfraction(分数)comlex number(复数) Strings123456789101112131415'(single quote)"(double quote)\(转义)r(元字符)'''"""+*indexstring[-1]string[0:2]len() Lists1234567891011list = [xx, x, ...]indexlist[index]list[start:stop]methodappend()pop()del()... 编程第一步First Steps Towards Programming 斐波那契数列(Fibonacci series) 1234567a, b = 0, 1while b &lt; 10: print(b, end=',') a, b = b, a+b #多重赋值(multiple assignment) #关键字参数(keyword argument) 控制流Control Flow Tools whilewhile Statements 123456a = input(int('Please input an int: '))whiel a &lt; 50: a += 1print(a) ifif Statements 1234567891011x = int(input("please input an int: "))if x &lt; 0: x = 0 print('Negative changed to zero')elif x == 0: print('Zero')elif x == 1: print('Single')else: print('More') forfor Statements 12345678910111213141516words = ['a', 'bb', 'ccc']for w in words: print(w, len(w))'''如果需要修改迭代中的序列，建议先制作副本，遍历一个序列并不会隐式地创建一个副本'''words = ['a', 22, 'ccc']for w in words[:]: if type(w) is int: words.insert(0, w)words[22, 'a', 22, 'ccc'] rangeThe range() Function遍历一系列数字 1234567891011121314for i in range(5): print(i)for i in range(0, 101, 10): print(i)a = [1, 22, 'A', 'AA']for i in range(len(a)) print(i, a[i])list(range(5))[0, 1, 2, 3, 4] 注意在许多方面，由range()返回的对象的行为就好像它是一个列表，但事实并非如此。它是一个对象，在你迭代时才返回所需序列，但它并不真正生成列表，从而节省空间。我们说这样一个对象是可迭代的(iterable)。 12print(range(10))range(0, 10) break/continuebreak and continue Statements, and else Clauses on Loops break 结束循环 continue 结束本次循环 passpass Statementspass语句什么也不做！当语句需要语法而程序不需要任何操作时，可使用它。 12345while True: passclass emptyClass: pass 函数定义Defining Functions关键字def引入一个函数定义，必须跟随函数名称和形式参数。函数主体语句必须缩进 函数主体的第一个语句是可选的字符串文字(sting literal)，用于描述函数。在编写的代码中包含文档字符串是一种很好的做法，请养成此习惯。 函数中的所有变量赋值都将值存储在本地符号表中，而变量引用首先在本地符号表中查找，然后是封闭函数的本地符号表，然后是全局符号表，最后是内置名称表。因此，全局变量不能直接在函数内赋值(除非是global语句)，尽管它们可能被引用。 事实上即使是没有return语句的函数也会返回一个值，它被称为None(一个内建名) 1234567891011121314151617def fib(n): """function's documentation print a Fibonacci series up to n. """ a, b = 0, 1 while a &lt; n: print(a, end=' ') a, b = b, a+b print()fib(100)f = fibf(100)print(fib())None 也可以使用可变数量的参数来定会函数。 默认参数值Default Argument Values 最有用的形式是为一个或多个参数指定默认值。 1234567891011def ask_ok(prompt, retries=4, reminder='Please try again!'): while True: ok = input(prompt) if ok in ('y', 'ye', 'yes'): return True if ok in ('n', 'no', 'nop', 'nope'): return False retries = retries - 1 if retries &lt; 0: raise ValueError('invalid user response') print(reminder) 函数可通过如下方法调用: 只给出必须的参数: ask_os(&#39;Prompt xxx&#39;) 给出可选参数: ask_ok(&#39;Prompt xx&#39;, 3) 给出所有参数: ask_ok(agr1, arg2, arg3) 关键字参数Keyword Arguments 也可使用kwarg = value来调用函数。 1234567891011121314def parrot(voltage, state='a stiff', action='voom', type='Norwegian Blue'): print("-- This parrot wouldn't", action, end=' ') print("if you put", voltage, "volts through it.") print("-- Lovely plumage, the", type) print("-- It's", state, "!")parrot(1000) # 1 positional argumentparrot(voltage=1000) # 1 keyword argumentparrot(voltage=1000000, action='VOOOOOM') # 2 keyword argumentsparrot(action='VOOOOOM', voltage=1000000) # 2 keyword argumentsparrot('a million', 'bereft of life', 'jump') # 3 positional argumentsparrot('a thousand', state='pushing up the daisies') # 1 positional, 1 keyword *name/**name**name，它接收一个字典(keyword=value)。可能与*name结合使用。*name必须出现在**name之前。 123456789101112131415161718192021222324def shop(kind, *arguments, **keywords): print("-- Do you have any ", kind, "?") print("-- I'm sorry, we're all out of ", kind) for arg in arguments: print(arg) print('\n-----\n') for kw in keywords: print(kw, ':', keywords[kw])shop('Kind', 'arg1', 'arg2', kw1='KW1', kw2='KW2', kw3='KW3')"""-- Do you have any Kind ?-- I'm sorry, we're all out of Kindarg1arg2-----kw3 : KW3kw1 : KW1kw2 : KW2""" 任意参数列表Arbitrary Argument Lists 最不经常使用的选项是指定可以用任意数量的参数调用一个函数，这些参数将被封装在一个元组中。 12345def arb(*args): for arg in args: print(arg)art(1, 22, 'CCC') 解包参数Unpacking Argument Lists 当参数已经在一个列表或元组中时，会出现相反的情况。需要对单独的位置参数的函数调用进行解包。 123456list(range(5))[0, 1, 2, 3, 4]args = [5]list(range(*args))[0, 1, 2, 3, 4] Lambda表达式可以使用lambda关键字创建小的匿名函数。Lambda函数可用于需要函数对象的任何地方，它在语法上受限于单个表达式。 123456789def lambdaTest(n): return lambda x: x + nf = lambdaTest(10)f(1)11f(5)15 文档字符串Documentation Strings 以下是关于文档字符串内容和格式的一些约定: 第一行应该始终是对象目的的简短摘要 第二行应该是空白，如果有多行的话 以下几行应该是描述 12345678910111213def func(): """Document it. This func just print one argument. """ print(sys.argv[1])print(func.__doc__)Document it. This func just print one argument. 函数注释Function Annotations 函数注释完全是关于用户定义函数使用的类型的可选元数据信息。 Annotations以字典的形式存储在函数的__annotations__属性中，并且不影响函数的其它部分。参数注释由参数名称后面的冒号:定义，后跟表达式评估注释的值。注释由参数列表和def语句结束的冒号之间的-&gt;定义，后跟一个表达式。 123456def f(name: str, age: int = 18) -&gt; str: print("Annotations: ", f.__annotations__) print("Arguments: ", name, age) return name + 'and' + str(age)f('Zhang21') 编码风格不同的语言有不同的编码风格。但是，让别人很轻松便能阅读你的代码总是一个好主意！ 对于Python而言，PEP(Python Enhanced Proposals) 8 已成为大多数项目遵循的风格指南。它促进了非常可读和令人喜爱的编码风格，每个Python开发者都应该阅读它。以下是最重要的几点： 使用4空格缩进，而不是tab 自动换行，不要超过79个字符 使用空白行来分割函数和类，以及函数内的更大快代码 如有可能，请将注释放在它们的上一行 使用文档字符串 在运算符和逗号后面使用空格，但不要直接在包围结构中使用空格 -&gt; (a + b) 一致地命名函数和类 建议使用UTF-8编码方式 建议不要在标识符中使用non-ASCII字符，如果有其它语言的人会去维护代码 数据结构Data Structures 列表More on Lists 列表数据类型有多种方法： list.append(x)添加一个项到列表的末尾 list.extend(iterable)通过添加迭代中的所有项来扩展列表 list.insert(i, x)在列表中给定位置插入一个项 list.remove(x)删除列表中给定值的第一项 list.pop()返回并删除列表中给定位置的项如果未指定index，则默认为最后一项 list.clear()删除列表中的所有项 list.index(x)返回指定值的第一个索引如果没有此值，返回ValueError list.count(x)返回列表中指定值出现的次数 list.sort()对列表中的项进行排序 list.reverse()反转列表中的元素 list.copy()返回列表的shallow copy 列表用处： Stack Queue 列表解析List Comprehensions 12345678910111213 #列表解析提供了一个简洁的方式来创建列表l = []for i in range(10): l.append(i**2) #lambdal = list(map(lambda i: i**2, range(10))) #orl = [x**2 for i in range(10)][(x, y) for x in [1, 2, 3] for y in [3, 2, 1] if x != y] 嵌套列表解析Nested List Comprehensions 列表解析中的初始表达式可以是任意表达式，包括另一个列表解析。 1234567l = [ [1, 2, 3, 4], [5, 6, 7, 8], [9, 10 ,11, 12]][[row[i] for row in l] for i in range(4)] del语句del语句可从列表中删除切片或整个列表。 123456789a = [1, 2, 3, 4]del a[0]del a[1:3]del a[:]del a 元组和序列Tuples and Sequences 列表和字符串由许多共同属性，如索引和切片操作。列表是可变的，它们的元素通常是同类，并且通过遍历列表可访问。 元组是不可变的！无法对元组项赋值，但可创建包含可变对象的元组。 1234567891011121314151617181920212223t = (123, 321, 'hello')tt = t, ('a', 'bb')(123, 321, 'hello), ('a', 'bb') #对元组赋值会出错t[0] = 888TypeError: 'tuple' object does not support item assignment #序列拆包(unpacking) #要求变量数量等于元素数量x, y, z = tx123y321z'hello' 集合Sets Python中的集合是没有重复元素的无序集合，并支持数学操作: 并集 a | b 交集 a &amp; b 差集 a - b 异或 a ^ b 使用大(花)括号{}或set()创建集合，但创建一个空集合使用set()，而不是{}——后者创建一个空字典。 集合也支持集合解析。 123456789101112131415161718192021alpha = &#123;'a', 'b', 'c', 'a'&#125;alpha&#123;'c', 'b', 'a'&#125;'c' in alphaTrue #数学运算a = set('abracadabra')b = set('alacazam')a | ba &amp; ba - ba ^ b #集合解析&#123;x for x in 'abcdefgabc' if x not in 'abc'&#125; 字典Dictionaries 字典数据类型在其它语言中被称为“associative memories” or “associative arrays”。与由数字索引的序列不同，字典由key索引(可以是任何不可变类型)，字符串和数字都可作为key。如果元组只包含字符串，数字或元组，则可作为key。若包含任何可变对象，则不能作为key。你不能使用列表作为key。 可将字典视为无序的键:值对，并要求键是唯一！花括号{}创建一个空字典。 字典的主要操作是用某个key存储value，并提取给定key的value。使用del语句删除一个键值对；新键值对会替换旧键值对。 1234567891011121314151617181920info = &#123;'name': 'AA', 'id': 1, 'tel': 155&#125;info['addr'] = 'Chengdu'infoinfo['name']del info['id']list(info.keys())print(info.values())print(info.items()) #dict()构造函数dict([('name', 'A'), ('age', 11)])dict(&#123;'name': 'A', 'age': 11&#125;)dict(name='zhang', age=11) #字典解析&#123;x: x**2 for x in (2, 4, 6)&#125; 循环技巧Looping Techniques 字典循环 123456info = &#123;'name': 'AA', 'age': 11&#125;for k, v in info.items(): print(k, v, sep=':')name:AAage:11 序列循环可使用enumerate()函数同时检索位置索引和相应值 123456for i, v in enumerate(['a', 'b', 'c']): print(i, v)0 a1 b2 c 同时循环多个序列要同时循环多个序列，可将这些条目与zip()函数配对 123456789aa = [1, 2, 3]bb = ['a', 'b', 'c']for a, b in zip(aa, bb): print('&#123;0&#125;, &#123;1&#125;'.format(a, b))1, a2, b3, c 反向循环序列 1234for i in reversed(range(6)): print(i, end=',')5,4,3,2,1,0, 循环排序 123456789101112131415161718l = ['ac', 'fb', 'nx', 'by']for i in sorted(l): print(i)acbyfbnxll = ['ac', 'fb', 'nx', 'by', 'ac', 'by']for i in sorted(set(ll)): print(i)acbyfbnx 关于条件More on Conditions while和if语句中使用的条件可以包含任何运算符，而不仅仅是比较。 比较操作符in和not in检查值是否在序列中操作符is和is not比较两个对象是否相同，这适用于可变对象(如list) 比较操作可以使用布尔运算符and和or进行组合，结果可用not。它们的优先级低于比较操作所有的比较操作符(comparison operators)具有相同的优先级，都低于数值运算符 模块Modules 如果你从Python解释器中退出并重新进入，你所做的定义(函数和变量)将会丢失。因此，如果编写一个稍长的程序，最好使用文本编辑器，然后将代码文件作文输入来运行它。这就被称为创建一个脚本。随着程序变长，可能需要将其分割为便于维护的多个文件。你可能还想使用你在多个程序中编写的某个功能(函数)，而不是将其定义复制到每个程序中。 为了支持此，Python有一种方法可将定义(definition)放入一个文件中，并在脚本或交互式实例中使用它们。这样的文件被称为模块(module)。来自模块的定义可以被导入到其它模块或主模块中。 模块是一个包含Python定义和语句的文件。文件名是带有.py的模块名。在模块中，模块的名称(string)用作全局变量__name__的值。 编写一个模块：vim /path/fibo.py 12345678910111213141516 #Fibonacci numbers moduledef fib(n): a, b = 0, 1 while b &lt; n: print(b, end=' , ') a, b = b, a+b print()def fib2(n): result = [] a, b = 0, 1 while b &lt; n: result.appen(b) a, b = b, a+b return result 载入此模块：如果没有将此模块放入Python默认lib目录(如/usr/lib64/python3.5/)的话，则需要进入模块所在目录打开Python解释器。 12345678910111213cd /pathpython3&gt;&gt;&gt; import fibo&gt;&gt;&gt; fibo.fb(100)1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89,&gt;&gt;&gt; fibo.fib2(100)[1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89]&gt;&gt;&gt; fibo.__name__'fibo'&gt;&gt;&gt; fibo.__str__()module 'fibo' from '/path/fibo.py' 更多模块信息More on Modules 一个模块可以包含可执行语句以及函数定义。这些语句旨在初始化模块，它们仅在import语句中第一次遇到模块名称时执行。 每个模块都有自己的私人符号表(private symbol table)，它被模块中定义的所有函数(functions)用作全局符号表(global symbol talbe)。因此，模块的作者可以在模块中使用全局变量(global variable)，而不用担心与用户的全局变量发生意外冲突。 模块可以导入其它模块。习惯上(但不是硬性要求)，将import语句放在模块(脚本)的开头。导入模块的名称被放置在导入模块的全局符号表中。 将模块名称直接导入到导入模块的符号表中，这不会在本地符号表中引入导入模块的名称 12 #fibo模块名并没有被定义from fibo import fib, fib2 导入模块中定义的所有名称在大多数情况下，Python程序员不会使用这个工具。因为它会向解释器引入一组未知的名称，可能会隐藏你已经定义的一些东西。注意，通常从模块或包中import *的做法是不被接受的，因为它经常会导致代码可读性很差。但是，可以使用它来保存交互式会话中的输入。 12 #这会导入除了以下划线开头的所有名称from fibo import * 将导入模块名称绑定到指定名称 123456789import fibo as fibfib.fib(100)fib.fib2(100)from fibo import fib2 as fibonaccifibonacci(100) 把模块作为脚本来执行Executing modules as scripts 如果你将模块中的__name__设置为__main__，模块中的代码就会被执行，就像导入它一样。这意味着你需要在你的模块的末尾添加它们。如果模块被导入，代码也不会执行。 这通常用于为模块提供用户接口，或测试。 123456if __name__ == "__main__": import sys fib(int(sys.argv[1]))python3 fibo.py &#123;args&#125; 模块的搜索路径The Module Search Path 当import fibo模块时，解释器首先在内建模块中搜索此名称。如果找不到，它会在sys.path给出的目录列表中搜索fibo.py文件。 sys.path从以下位置初始化： 包含输入脚本的目录(未指定文件时的当前目录) PYTHONPATH 依赖于安装的默认值 包含符号链接的目录不会被添加到模块的搜索路径中 编译的Python文件Compiled Python files 为了加速载入模块，Python将每个模块的编译版本缓存在名为module.version.pyc的__pycache__目录下，对编译文件的格式进行编码，它通常包含Python版本号。Python根据编译后的版本检查源代码的修改日期，看它是否过期并需要重新编译。这是一个完全自动的过程。另外，编译后的模块时独立于平台的，因此可以在不同体系结构的系统之间共享相同的库。 有两种情况，Python不会检查缓存： 总是重新编译并且不存储从命令行直接加载的模块的结果 没有源模块 专家提示： 可以Python命令中使用-0或-00来减少已编译模块的大小 读取.pyc文件不会比.py文件快，唯一更快的事情是它们被加载的速度 模块compileall可以为目录中的所有模块创建.pyc文件 更多细节，参见PEP 3147 标准模块Standard Modules Python提供了一个标准模块库。 一些模块被内置到解释器中，提供了对操作的访问。这些操作不属于语言核心的一部分，但是为了提高效率或提供对操作系统的访问权限。 12345678910111213141516import syssys.ps1'&gt;&gt;&gt;'sys.ps2'...'sys.ps1 = '&lt;&lt;&lt;'sys.ps1'&lt;&lt;&lt;' #查看PYTHONPATHsys.path.__str__ #添加PYTHONPATHsys.path.append('/home/zhang/venv/python') dir()函数内建函数dir()用于找出模块定义的名称。它列出所有类型的名称： 变量，模块，函数… 123456789101112131415import fibo, sysdir(fibo)['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'fib', 'fib2']dir(sys)['__displayhook__', '__doc__', '__excepthook__', '__interactivehook__', '__loader__', '__name__', '__package__', '__spec__', '__stderr__', '__stdin__', '__stdout__', '_clear_type_cache', '_current_frames', '_debugmallocstats', '_getframe', '_home', '_mercurial', '_xoptions', 'abiflags', 'api_version', 'argv', 'base_exec_prefix', 'base_prefix', 'builtin_module_names', 'byteorder', 'call_tracing', 'callstats', 'copyright', 'displayhook', 'dont_write_bytecode', 'exc_info', 'excepthook', 'exec_prefix', 'executable', 'exit', 'flags', 'float_info', 'float_repr_style', 'getallocatedblocks', 'getcheckinterval', 'getdefaultencoding', 'getdlopenflags', 'getfilesystemencoding', 'getprofile', 'getrecursionlimit', 'getrefcount', 'getsizeof', 'getswitchinterval', 'gettrace', 'hash_info', 'hexversion', 'implementation', 'int_info', 'intern', 'last_traceback', 'last_type', 'last_value', 'maxsize', 'maxunicode', 'meta_path', 'modules', 'path', 'path_hooks', 'path_importer_cache', 'platform', 'prefix', 'ps1', 'ps2', 'setcheckinterval', 'setdlopenflags', 'setprofile', 'setrecursionlimit', 'setswitchinterval', 'settrace', 'stderr', 'stdin', 'stdout', 'thread_info', 'version', 'version_info', 'warnoptions'] #它不会列出内建函数和变量的名称，除非如下操作import builtinsdir(builtins)['ArithmeticError', 'AssertionError', 'AttributeError', 'BaseException', 'BlockingIOError', 'BrokenPipeError', 'BufferError', 'BytesWarning', 'ChildProcessError', 'ConnectionAbortedError', 'ConnectionError', 'ConnectionRefusedError', 'ConnectionResetError', 'DeprecationWarning', 'EOFError', 'Ellipsis', 'EnvironmentError', 'Exception', 'False', 'FileExistsError', 'FileNotFoundError', 'FloatingPointError', 'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError', 'ImportWarning', 'IndentationError', 'IndexError', 'InterruptedError', 'IsADirectoryError', 'KeyError', 'KeyboardInterrupt', 'LookupError', 'MemoryError', 'NameError', 'None', 'NotADirectoryError', 'NotImplemented', 'NotImplementedError', 'OSError', 'OverflowError', 'PendingDeprecationWarning', 'PermissionError', 'ProcessLookupError', 'ReferenceError', 'ResourceWarning', 'RuntimeError', 'RuntimeWarning', 'StopIteration', 'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit', 'TabError', 'TimeoutError', 'True', 'TypeError', 'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning', 'ValueError', 'Warning', 'ZeroDivisionError', '_', '__build_class__', '__debug__', '__doc__', '__import__', '__loader__', '__name__', '__package__', '__spec__', 'abs', 'all', 'any', 'ascii', 'bin', 'bool', 'bytearray', 'bytes', 'callable', 'chr', 'classmethod', 'compile', 'complex', 'copyright', 'credits', 'delattr', 'dict', 'dir', 'divmod', 'enumerate', 'eval', 'exec', 'exit', 'filter', 'float', 'format', 'frozenset', 'getattr', 'globals', 'hasattr', 'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', 'issubclass', 'iter', 'len', 'license', 'list', 'locals', 'map', 'max', 'memoryview', 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow', 'print', 'property', 'quit', 'range', 'repr', 'reversed', 'round', 'set', 'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type', 'vars', 'zip'] 包Packages 包是通过”dotted(.) module names“，来构造Python模块命名空间的一种方式。 假设你想设计一个模块集(包)来统一处理声音文件和声音数据。有许多不同的声音文件格式。因此你需要创建和维护不断增长的模块集合，以便在各种文件格式之间进行转换。你还可能需要对声音数据执行各种不同的操作，因此你还需要编写无止境的模块流以执行这些操作。 这可能是一个包结构: 1234567891011121314151617181920212223sound/ Top-level package __init__.py Initialize the sound package formats/ Subpackage for file format conversions __init__.py wavread.py wavwrite.py aiffread.py aiffwrite.py auread.py auwrite.py ... effects/ Subpackage for sound effects __init__.py echo.py surround.py reverse.py ... filters/ Subpackage for filters __init__.py equalizer.py vocoder.py karaoke.py ... 当导入包时，Python将搜索sys.path，并查找包的子目录。需要__init__.py文件才能使Python将目录视为包含包。这是为了防止具有通用名称的目录(如字符串)无意中隐藏稍后在模块搜索路径中发生的有效模块。在最简单的情况下，__init__.py可以是一个空文件，但它也可以执行包的初始化代码。 导入包: from package import itemitem可以是子模块，子包，函数，类，变量import语句首先测试项目是否在包中定义。 如果不在，它假定它是一个模块并尝试加载它。如果找不到它，则会引发ImportError异常 import item.subitem.subsubitem相反，当使用这种语法时，除最后一项外必须都是一个包，最后一项可以是模块或包，但不能是类或函数或变量 123import sound.effects.echofrom sound.effects import echo importing * from a package当输入from sound.effects import *会发生什么？理想情况下，人们会希望以某种方式进入文件系统，查找包中存在哪些子模块，然后将它们全部导入。这可能需要很长时间，并且导入子模块可能具有不希望的副作用，这些副作用在明确导入子模块时才会发生。 唯一的解决方案是软件包作者提供包的明确索引。import使用以下声明: 如果某个包的__init__.py定义了一个名为__all__的列表，则它将成为from package import *时应该导入的模块名称列表。当软件包新版本发布时，软件包作者需要保持该列表是最新版本。 栗子sound/effects/__init__.py: 12 #这意味着from sound.effects import *只会导入以下子模块__all__ = [&quot;echo&quot;, &quot;surround&quot;, &quot;reverse&quot;] 如果__all__没有被定义，则from sound.effcts import *语句不会将包sound.effects中所有子模块导入到当前命名空间。它只能确保包sound.effects被导入，然后导入包中定义的任何名称。这包括__init__.py定义的任何名称，还包括由以前的导入语句显示加载的软件包的任何子模块。 请记住，使用from packagee import submodule没有任何问题。事实上，这也是推荐的方法。除非导入模块需要使用不同包中具有相同名称的子模块。 内部包装Intra-package References 当包被构建为子包时，可以使用绝对导入来引用邻包中的模块。同样，也可以使用相对导入来导入邻包中的模块。 12345678 #Absolutefrom sound.effects import echo #Relativefrom . import echofrom .. import formatsfrom ..filter import equalizer 多个目录中的包Packages in Multiple Directories 包还支持一个特殊的属性__path__。在执行该文件中的代码之前，它被初始化为一个包含__init__.py的目录名称的列表。这个变量可以修改，这样做会影响将对包中包含的模块和子包的搜索。 虽然此功能通常不是必需的，但它可用于扩展包中找到的一组模块。 输入和输出Input and Output有多种方式来呈现程序的输出；数据也可以打印成人类可读的形式，或写入文件供将来使用。 幻想的输出格式Fancier Output Formatting 到目前为止，我们知晓两种写入值的方法: 表达式语句 print()函数 有两种方法可以格式化输出： 自己完成所有的字符串处理(使用切片和连接操作，你可创建任何你能想到的布局) 格式化字符串文字或str.format()方法 string模块提供了一个Template类，它提供了另一种将值替换为字符串的方法。Python有办法将任何值转换为字符串：将它传递给repr()或str()函数。 str()函数，用于返回相当可读(human-readable)的值的表示repr()函数，用于生成可由解释器读取的表示对于没有人定义的特定表示的对象，str()将返回与repr()相同的值 1234567891011121314for x in range(1, 6): print(repr(x).rjust(2), repr(x**2).rjust(3), end=' ') print(repr(x**3).rjust(4)) #Orfor x in range(1, 6): print('&#123;0:2d&#125; &#123;1:3d&#125; &#123;2:4d&#125;'.format(x, x**2, x**3)) 1 1 1 2 4 8 3 9 27 4 16 64 5 25 125 字符串对象的str.rjust()方法，它在给定宽度的字段中通过填充左边的空格来右对齐字符串。类似方法还有: str.ljust(), str.center()。这些方法不写入任何东西，它们只是返回一个新的字符串。 还有一种str.zfill()方法，它在数字字符串的左边填充数字0，它能识别加号和减号： 12345678&gt;&gt;&gt; '12'.zfill(5)'00012'&gt;&gt;&gt;&gt;&gt;&gt; '-3.14'.zfill(7)'-003.14'&gt;&gt;&gt;&gt;&gt;&gt; '3.1415678'.zfill(5)'3.1415678' str.format()方法: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152 #&#123;&#125;print('We are &#123;&#125; who say &#123;&#125; is "&#123;&#125;!".format('A', 'BB', 'WONDERFUL'))We are A who say BB is "WONDERFUL!" #括号中的数字用来指向传入的位置 #&#123;index&#125;,从0开始print('&#123;0&#125; and &#123;1&#125;'.format('A', 'BB'))A and BBprint('&#123;1&#125; and &#123;0&#125;'.format('A', 'BB'))BB and A #关键字参数print('My name is &#123;name&#125;, I\'m &#123;age&#125; years old!'.format(name='Zhang21', age=21))My name is Zhang21, I'm 21 years old! #位置参数和关键字参数的组合print('The story of &#123;0&#125;, &#123;1&#125;, and &#123;other&#125;'.format('A', 'BB', other='CCC'))The story of A, BB, and CCC'''!a, 应用ascii()!s, 应用str()!r, 应用repr():, 更好的控制格式:5:7d:.3f'''print('My full name is &#123;!s&#125;'.format('Zhang21'))My full name is Zhang21print('My full name is &#123;!r&#125;'.format('Zhang21'))My full name is 'Zhang21'print('The value of &#123;&#125; is approximately &#123;:.3f&#125;'.format('PI', 3.141567))The value of PI is approximately 3.142info = &#123;'A': 68, 'BB': 79, 'CCC': 89&#125;for k, v in info.items(): print('&#123;0:5&#125; ==&gt; &#123;1:6d&#125;'.format(k, v))A ==&gt; 68BB ==&gt; 79CCC ==&gt; 89print('A: &#123;A:d&#125;; B: &#123;BB:d&#125;, C: &#123;CCC:d&#125;'.format(**info))A: 68; B: 79, C: 89 %操作符同样可用于字符格式化: 12print('The value of %s is approximately %5.3f' % ('PI', 3.1415678))The value of PI is approximately 3.142 读写文件Reading and Writing Files open()返回一个文件对象，它最常用的两个参数：open(filename, mode) 12345678910f = open('/tmp/1.txt, 'r')f.readline()'1\n'f.closedFaslef.close()f.closedTrue mode: r: read only，未指定模式时的默认模式 w: only writing a: appending r+: reading and writing b: binary mode 通常情况下，文件以文本模式打开，这意味着你可读写文件中的字符串，并以特定编码方式进行编码(如UTF-8)。如果未指定编码，则默认值取决于平台。b以二进制模式打开文件，数据以字节对象的形式读写，该模式应该用于所有不包含文本的文件。在读写文件时要非常小心的使用二进制模式。 推荐使用with关键字处理文件对象，优点是，即使在某个时间点出现异常，文件在其套件结束后也能正常关闭。也比try-finally块短得多。如果没有使用with关键字，则你需要调用f.close()来关闭文件，并立即释放它使用的系统资源。如果你没有明确关闭一个文件，Python的垃圾回收器最终会摧毁这个对象并为你关闭吧这个打开的文件，但这个文件可能会保持打开一段时间。在关闭文件对象之后，尝试使用文件对象将会自动失败。 1234567891011with open('/tmp/1.txt') as f: read_Data = f.read()f.closedTruef.read()Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;ValueError: I/O operation on closed file. 文件对象方法Methods of File Objects f.read(size)读取文件内容，以字符串或字节对象的形式返回。size是一个可选的数值参数，当size被忽略或为负数时，文件的全部内容被读取并返回。如果超过内存限制，那就是你的问题了。f.readline()从文件读取一行，换行符Unix\n，Windows\r\nf.readlines(), list(f)读取文件的所有行f.write(string)向文件中写入字符内容，并返回写入的字符数f.tell()返回一个整数，表示二进制模式下文件开头的字节数f.seek(offset, from_what)改变文件对象的位置 1234567891011121314151617f = open('/tmp/1.txt', 'r+')f.write('Line4\n')6string = ('AAA', 11)s = str(string)f.write(s)11f = open('/tmp/1.txt', 'rb+')f.write(b'0123456789abcde')f.seek(1)1f.read(1)b'1' 使用json保存结构化数据Saving structured data with json 字符串可以很容易地读写文件和从文件读取。当你想要保存更复杂的数据类型——如嵌套列表和字典，手动解析和序列化将变得很复杂。 JSON格式通常被现代应用程序用于数据交换。Python允许你使用名为JSON的流行数据交换格式。称为json的标准模块可采用Python数据层次结构，并将其转换为字符串表示形式，这个过程被称为序列化(serializing)。重建字符串表示中的数据称为反序列化(deserializing)。 123456import jsonjson.dumps([1, 'simple', 'list'])'[1, "simple", "list"]'json.dump(x, f)x = json.load(f) 错误和异常Errors and Exceptions 至少有两种可区分的错误: syntax errors exceptions 语法错误Syntax Errors语法错误，也称为解析错误。这是最常见的语法问题错误。 异常Exceptions即使语法是正确的，但在执行时也可能导致错误。执行过程中检查到的错误称为异常。Built-in Exceptions列出了内置的异常及其含义。 1234567891011121314 &gt;&gt;&gt; 10 * (1/0)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;ZeroDivisionError: division by zero &gt;&gt;&gt; 4 + spam*3Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;NameError: name 'spam' is not defined &gt;&gt;&gt; '2' + 2Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: Can't convert 'int' object to str implicitly 处理异常Handling Exceptions编写处理选定异常的程序是可能的。 1234567891011while True: try: x = int(input("Please enter a number: ")) break except ValueError: print("Oops! That was no valid number. Try again...") #多个异常放入一个元组except (RuntimeError, TypeError, NameError): pass try语句工作原理： 首先，try子句(try...except之间的语句)被执行 如果没有异常发生，则执行try语句并跳过except子句后便结束 如果在执行try子句时发生异常，则跳过子句的其余部分。然后，如果异常类型匹配execpt后面的异常名称，则except子句被执行，然后在try语句后继续执行 如果产生的异常与except的异常名称不匹配，它将传递给外部try语句。如果没有找到处理程序，则它是一个未处理的异常，执行停止并显示错误消息 try语句可能有多个except子句，用于处理不同的异常。最多只有一个处理程序被执行 处理程序只处理发生在相应try子句中的异常，而不处理相同try语句的其它处理程序 except子句可将多个异常名放入一个元组 如果是相同的类或其基类，则except子句中的类与异常兼容 未使用异常名称的except子句作为通配符 请谨慎使用此功能，因为以这种方式很容易掩盖真正的编程错误 try...except语句还有一个可选的else子句。当存在时，它必须遵循所有except子句。如果try子句不引发异常，则必须执行该代码 12345678910111213import systry: f = open('/tmp/1.txt') s = f.readline() i = int(s.strip())except OSError as err: print('OS error: &#123;&#125;'.format(err))except ValueError: print("Could not convert data to an integer.")except: print("Unexpected erros", sys.exc_info()[0]) raise 123456try: sum = 'a' + 1except TypeError: print('TypeError')else: print('else: ', sum) 引发异常Raising Exceptions raise语句允许程序员强制执行指定的异常。 1234567891011121314151617&gt;&gt;&gt; raise NameError('HiThere')Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;NameError: HiThere&gt;&gt;&gt; try:... raise NameError('HiThere')... except NameError:... print('An exception flew by!')... raise...An exception flew by!Traceback (most recent call last): File "&lt;stdin&gt;", line 2, in &lt;module&gt;NameError: HiThere 用户定义的异常User-defined Exceptions 程序可以通过创建一个新的异常类(exception class)来为自己的异常命名。异常通常应该直接或间接地从 Exception class 派生。 可以定义异常类，它可以执行任何其它类可以执行的任何操作，但通常很简单，通常只提供一些属性，以便处理程序为异常提取有关错误的信息。创建可引发多个不同错误的模块时，通常的做法是为该模块定义的异常创建基类，并创建用于为不同错误条件创建特定异常类的子类: 123456789101112131415161718192021222324252627282930class Error(Exception): """Base class for exceptions in this module.""" passclass InputError(Error): """Exception raised for errors in the input. Attributes: expression -- input expression in which the error occurred message -- explanation of the error """ def __init__(self, expression, message): self.expression = expression self.message = messageclass TransitionError(Error): """Raised when an operation attempts a state transition that's not allowed. Attributes: previous -- state at beginning of transition next -- attempted new state message -- explanation of why the specific transition is not allowed """ def __init__(self, previous, next, message): self.previous = previous self.next = next self.message = message 大多数异常的名称都以Error结尾来定义，类似于标准异常的命名。许多标准模块定义了它们自己的异常，用于在其定义的功能中可能发生的错误。 定义清理行为Defining Clean-up Actions try语句还有一个可选的子句，用于定义在任何情况下都必须执行的清理操作(clean-up actions). finally子句总是在离开try语句之前执行，无论是否发生异常。 123456789&gt;&gt;&gt; try:... raise KeyboardInterrupt... finally:... print('Goodbye, world!')...Goodbye, world!KeyboardInterruptTraceback (most recent call last): File "&lt;stdin&gt;", line 2, in &lt;module&gt; 预定义的清理操作Predefined Clean-up Actions 某些对象定义了在不再需要对象是要执行的标准清楚操作，而不管使用对象的操作是成功还是失败。 123with open("myfile.txt") as f: for line in f: print(line, end="") 类Classes 类提供了将数据和功能捆绑在一起的手段。每个类实例都可附加属性以保持其状态。类实例也可以有方法来修改其状态。 与其它编程语言相比，Python的类机制为其添加了最少量的新语法和语义。Python类 提供了面向对象编程的所有标准功能: 类继承机制(inheritance mechanism)允许多个基类(base class)，派生类(derived class)可以重写其基类或类的任何方法，并且方法(method)可以调用具有相同名称的基类的方法。对象(object)可以包含任意数量和种类的数据。与模块一样，类也具有Python的动态特性: 它们是在运行时创建的，并且可以在创建后进一步修改。 关于名称和对象A Word About Names and Objects Objects have individuality, 并且可以将多个名称(在多作用域中)绑定到同一个对象。这在其它语言中被称为别名。别名在不可变类型中被安全地忽略。但对涉及可变对象(dict, list…)的Python代码的语义可能会有惊人的影响。这通常有利于程序，因为别名在某些方面表现得像指针。 作用域和命名空间Python Scopes and Namespaces 类定义在命名空间中扮演一些巧妙的技巧，并且你需要知道作用域和命名空间如何工作才能完全理解正在发生的事情。顺便一提，有关此主题的知识对于任何高级Python程序员都很有用。 让我们从一些定义开始: 命名空间是名称到对象的映射。大多数命名空间目前都是作为Python字典实现的，但通常不会以任何方式显示。命名空间的例子： 内建名称的集合；模块中的全局名称；函数调用中的本地名称。从某种意义上说，对象的一组属性也构成一个命名空间。了解命名空间的重要之处在于，不同命名空间中的名称之间没有绝对的关系。 顺便一提，使用单词属性来表示任意一个点.后面的名称——z.real，real是对象z的属性。严格地说，对模块中的名称引用是属性引用——modname.funcname，modname是一个模块对象，并且funcname是它的一个属性。在这种情况下，模块的属性和模块中定义的全局名称之间会有一个直接的映射关系: 它们共享相同的命名空间。 属性可以是只读或可写。 命名空间是在不同的时刻创建的，并且具有不同的生命周期。包含内建名称的命名空间是在Python解释器启动时创建的，并且永远不会被删除。读取模块定义时创建模块的全局命名空间，通常，模块命名空间也会持续到解释器退出。由解释器的顶层调用执行的语句，无论是从脚本文件读取还是交互式读取，都被视为名为__main__模块的一部分，因此它们具有其自己的全局命名空间。 函数的本地命名空间是在调用函数时创建，并在函数返回时删除或引发(raise)不在函数内处理的异常。当然，递归调用每个都有自己的本地命名空间。 作用域(scope)是Python程序的文本区域，可以直接访问命名空间(namespace)。这意味着对名称的非限定引用(unqualified reference)会尝试在命名空间中查找名称。 尽管作用域是静态确定的，但它们是动态使用的。在执行期间的任何时候，至少有三个作用域的命名空间都可以直接访问: 最先搜索的最内层作用域，包含本地名称 从最近封闭作用域开始搜索的任何封闭函数的作用域，包含非本地名称，也包含非全局名称 倒数第二个作用域包含当前模块的全局名称 最外层的作用域是包含内建名称的命名空间 如果某个名称被声明为全局(global)，则所有的引用(reference)和赋值(assignment)都将直接转到包含模块全局名称的中间作用域。要重新绑定(rebind)最内层作用域外发现的变量，可以使用nonlocal语句；如果没有声明nonlocal，那些变量是只读的。 通常，本地作用域引用当前函数的本地名称。在外部函数中，本地作用域引用与全局作用域相同的命名空间:模块的命名空间。类定义在本地作用域中放置另一个命名空间。 认识到作用域是以文本方式确定是很重要的: 模块中定义的函数的全局作用域是该模块的命名空间，无论从何处调用函数或调用函数的别名。另一方面，名称的实际搜索是在运行时动态完成的——但是，在编译时间，语言定义正在向静态名称解析发展，因此不要依赖动态名称解析。 Python的特殊之处在于——如果global语句没有生效，对名称的赋值总是进入最内层的范围。赋值不会分配数据——它们只是将名称绑定到对象。删除操作也是如此: 语句del x从本地作用域引用的命名空间中删除x的绑定。实际上，所有引用新名称的操作都是用本地作用域: 特别是，import语句和函数定义将模块或函数名称绑定到本地作用域。 global声明可以用来表明特定变量存在于全局作用域内，应该在此rebound(反弹)。nonlocal声明表明特定变量存在于封闭作用域内，应该在那里rebound. 作用域和命名空间的栗子 123456789101112131415161718192021222324252627282930313233def scope_test(): def do_local(): spam = "local spam" def do_nonlocal(): nonlocal spam spam = "nonlocal spam" def do_global(): global spam spam = "global spam" spam = "test spam" do_local() print("After local assignment: ", spam) do_nonlocal() print("After nonlocal assignment: ", spam) do_global() print("After global assignment: ", spam)scope_test()print("In global scope: ", spam)#输出After local assignment: test spamAfter nonlocal assignment: nonlocal spamAfter global assignment: nonlocal spamIn global scope: global spam 首先看类A first look at class 类引入了一些新的语法，三种新的对象类型和一些新的语义。 类定义语法Class Definition Syntax 类定义，像函数定义，必须在它们有效之前被执行。 123456class ClassName: &lt;statement-1&gt; . . . &lt;statement-N&gt; 实际上，类定义中的语句通常是函数定义，但其他语句是允许的，有时也是有用的。类中的函数定义通常有一个特殊形式的参数列表，由方法的调用约定决定。 当输入一个类定义时，会创建一个新的命名空间，并将其用作本地作用域——因此，所有对局部变量的赋值都会进入这个新的命名空间。特别是，函数定义在此绑定新函数的名称。 当类定义保持正常时，会创建一个类对象。这基本上是由类定义创建的命名空间的内容的一个包装。最初的本地作用域被恢复，并且类对象在这里被绑定到类定义头中给出的类名。 类对象Class Objects 类对象支持两种操作: 属性引用(attribute reference)和实例化(instantiation). 属性引用使用 用于Python中所有属性引用的标准语法: obj.name. 有效的属性名称在创建类对象时时位于类命名空间中的所有名称。 123456class MyClass: """A simple example class""" i = 12345 def f(self): return 'hello world' MyClass.i和MyClass.f是有效的属性引用，分别返回一个整数和函数对象。类属性也可以被分配，所以也可以通过赋值来改变MyClass.i的值。__doc__也是一个有效的属性，返回该类的文档字符串”A simple example class”. 类实例化使用函数表示法。假设类对象是一个返回类的新实例的无参数函数。 12#创建类的新实例，并将该对象分配给局部变量xx = MyClass() 实例化操作(“调用”一个类对象)创建一个空对象。许多类喜欢创建具有定制(customized)到特定初始状态(initial state)的实例对象。因此，类可以定义一个名为__init__()的特殊方法。 12def __init__(self): self.data = [] 当一个类定义了一个__init__()方法时，类实例化会自动为新创建的类实例调用__init__(). 当然，__init__()方法可能有更多灵活的参数。在这种情况下，给类实例化操作符的参数被传递给__init__(). 123456789class Complex: def __init__(self, realpart, imagpart): self.r = realpart self.i = imagpartx = Complex(3.0, -4.5)x.r, x.i3.0, -4.5 实例对象Instance Objects 实例对象理解的唯一操作是属性引用。有两种有效的属性名称，数据属性和方法。 数据属性不需要声明，像局部变量一样，当它们在第一次分配时就会弹出。另一种实力属性引用是一种方法。方法是属于对象的函数。 实例对象的有效方法名称取决于它的类。根据定义，作为函数对象的类的所有属性都定义其实例的相应方法。 方法对象Method Objects 关于方法的特殊之处在于 实例对象作为函数的第一个参数传递。一般来说，调用带有n个参数列表的方法相当于使用通过在第一个参数之前插入方法实例对象创建的参数列表来调用相应的函数。 当引用不是数据属性的实例属性时，将搜索类。如果名称表示一个有效的类属性，它是一个函数对象，则通过打包实例对象和在抽象对象中一起找到的函数对象来创建方法对象，这就是方法对象。当使用参数列表调用方法对象时，会从实例对象和参数列表构造一个新参数列表，并使用此新参数列表调用函数对象。 类变量和实例变量Class and Instance Variables 一般来说，实例变量是针对每个实例唯一的数据，而类变量是针对类的所有实例共享的属性和方法。 1234567891011121314151617class Dog: kind = 'canine' # class variable shared by all instances def __init__(self, name): self.name = name # instance variable unique to each instance&gt;&gt;&gt; d = Dog('Fido')&gt;&gt;&gt; e = Dog('Buddy')&gt;&gt;&gt; d.kind # shared by all dogs'canine'&gt;&gt;&gt; e.kind # shared by all dogs'canine'&gt;&gt;&gt; d.name # unique to d'Fido'&gt;&gt;&gt; e.name # unique to e'Buddy' 共享数据可能会带来令人惊讶的影响，涉及列表和字典等可变对象: 1234567891011121314151617class Dog: tricks = [] # mistaken use of a class variable def __init__(self, name): self.name = name def add_trick(self, trick): self.tricks.append(trick)&gt;&gt;&gt; d = Dog('Fido')&gt;&gt;&gt; e = Dog('Buddy')&gt;&gt;&gt; d.add_trick('roll over')&gt;&gt;&gt; e.add_trick('play dead')&gt;&gt;&gt; d.tricks # unexpectedly shared by all dogs['roll over', 'play dead'] 正确的类设计应该使用实例变量: 1234567891011121314151617class Dog: def __init__(self, name): self.name = name self.tricks = [] # creates a new empty list for each dog def add_trick(self, trick): self.tricks.append(trick)&gt;&gt;&gt; d = Dog('Fido')&gt;&gt;&gt; e = Dog('Buddy')&gt;&gt;&gt; d.add_trick('roll over')&gt;&gt;&gt; e.add_trick('play dead')&gt;&gt;&gt; d.tricks['roll over']&gt;&gt;&gt; e.tricks['play dead'] 随机备注Random Remarks 数据属性覆盖具有相同名称的方法属性；为了避免意外的名称冲突，这可能会在大型程序中导致难以发现的错误，使用某种最小化冲突几率的约定是明智的。可能的约定(convention)包括: 大写的方法名称，小唯一字符串(可能只是下划线)为数据属性名称加前缀，或者为方法和名词使用动词来表示数据属性。 数据属性可由方法及对象的普通用户引用。换句话说，累不可用于实现纯粹的抽象数据类型。事实上，Python中没有任何东西可以强制执行数据隐藏——它都基于约定。 客户端应该小心使用数据属性。请注意，客户端可以将自己的数据属性添加到实例对象，而不会影响方法的有效性，只要避免名称冲突——再次注意，命名约定可在此节省大量令人头痛的问题。 从方法中引用数据类型没有简写，这增加了方法的可读性: 在浏览方法时，不会混淆局部变量和实例变量。 通常，方法的第一个参数称为self。这只不过是一个约定: 名字self对Python来说绝对没有特殊含义。但是，请注意，不遵循约定的Python代码对于Python程序员来说可能不易读取。 任何作为类属性的函数对象都为该类的实例定义了一个方法 1234567891011121314# Function defined outside the classdef f1(self, x, y): return min(x, x+y)class C: f = f1 def g(self): return 'hello world' h = g#f, g, h都是类C的所有属性，它们都是指向函数对象的，因此它们都是C实例的所有方法。 方法可以通过使用self参数的方法属性来调用其它方法: 12345678910class Bag: def __init__(self): self.data = [] def add(self, x): self.data.append(x) def addtwice(self, x): self.add(x) self.add(x) 方法可以像普通函数一样引用全局名称。与方法关联的全局作用域是包含其定义的模块。(一个类永远不会被用作全局作用域) 虽然很少有人在方法中使用全局数据，但全局作用域有许多合法用途: 首先，导入全局作用域的函数和模块可以被方法使用，以及在其中定义的函数和类。通常，包含该方法的类本身是在全局作用域内定义的。 每个值都是一个对象，因此有一个类(类型)。它被存储为object.__class__ 继承Inheritance 当然，如果不支持继承，语言特性就不值得称为”类”。 1234567#派生(derived)class DerivedClassName(BaseClassName): &lt;statement-1&gt; . . . &lt;statement-N&gt; 基类(BaseClassName)必须在包含派生类(derived class)定义的作用域中定义。代替基类名称，其它表达式也是允许的。 12#当基类在另一个模块中被定义class DerivedClassName(modname.BaseClassName): 派生类(derived class)定义的执行过程与基类(base class)相同。当构造(constructed)类对象时，基类将被记住。这用于解析属性引用: 如果在类中未找到请求的属性，则搜索继续查找基类。如果基类本身是从其它类派生的，则此规则将递归应用。 派生类的实例化么有什么特别的: DerivedXlassName()创建一个新的类实例。方法解析如下: 如果需要，搜索相应的类属性，沿着基类链降序排列，如果产生函数对象，则方法引用是有效的。 派生类可以覆盖(override)基类的方法。由于方法在调用同一对象的其它方法时没有特殊的权限，因此调用另一个在同一基类中定义的方法的基类方法可能最终会调用派生类的方法来覆盖它。 派生类的覆盖(override)方法事实上可能需要扩展而不是简单地替换同名的基类方法。有一种简单的方法可以直接调用基类方法: 只需调用BaseClassName.methodname(self, arguments)即可。 Python有两个与继承有关的内建函数: isinstance()检查一个实例的类型。isinstance(obj, int)只有在obj.__class__是int或从int派生的某个类时才为true issubclass()检查类继承。 多重继承Multiple Inheritance Python支持多重继承的形式。 123456class DerivedClassName(Base1, Base2, Base3): &lt;statement-1&gt; . . . &lt;statement-N&gt; 在最简单的情况下，你可以将从父类继承的属性视为深度优先(depth first)，从左到右搜索，而不是在同一个类中进行两次搜索，其中层次结构中存在重叠。因此，如果在DerivedClassName中找不到属性，则在Base1中搜索该属性，然后(递归)在Base1的基类中搜索该属性。如果未找到，则在Base2中搜索该属性，依此类推。 动态排序是必要的，因为多重继承的情况都表现出一个或多个菱形关系。例如，所有类都从对象继承，所以任何多重继承的情况都会提供多条路径来达到对象。为了避免基类被多次访问，动态算法使搜索顺序线性化，以保留没各类众指定的从左到右的顺序，每个父类只调用一次，这是单调的。 私有变量Private Variables Python中不存在私有(private)实例变量，这些变量除了在对象内部以外不能访问。不过，大多数Python代码都有一个约定，以下划线_spam为前缀的名称应被视为API的非公共部分(无论是函数，方法或数据成员)。 由于私有类(class-private)成员有一个有效的用例(即为了避免名称与由子类定义的名称的冲突)，所以对这种称为name mangling的机制的支持有限。任何__spam形式的标识符在文本上用_classname__spam替换，其中classname是当前类名称，前导下划线被去除。只要它在类的定义类发生，就不会考虑标识符位置。 Name mangling 有助于让子类重写方法而不会破坏intraclass方法调用: 123456789101112131415161718class Mapping: def __init__(self, iterable): self.items_list = [] self.__update(iterable) def update(self, iterable): for item in iterable: self.items_list.append(item) __update = update # private copy of original update() methodclass MappingSubclass(Mapping): def update(self, keys, values): # provides new signature for update() # but does not break __init__() for item in zip(keys, values): self.items_list.append(item) 请注意，强化规则的设计主要是为了避免事故；它仍然可以访问或修改被认为是私有的变量。注意传递给exec()或eval()的代码并不认为调用类的类名是当前类；这与global语句的效果类似，其效果同样局限于一起进行字节编译的代码。getattr(), setattr()和delattr()以及直接使用__dict__时也有相同的限制。 Odds and Ends123456789class Employee: passjohn = Employee() # Create an empty employee record# Fill the fields of the recordjohn.name = 'John Doe'john.dept = 'computer lab'john.salary = 1000 一段期望特定抽象数据类型的Python代码通常通常可以传递一个模拟该数据类型方法的类。例如，如果你有一个函数可以格式化文件对象中的某些数据，则可以使用方法read()和readline()来定义一个类，以便从字符串缓冲区总获取数据，然后将其作为参数传递。 迭代器Iterators 你可能注意到大多数容器对象可以使用for语句循环遍历: 12345678910for element in [1, 2, 3]: print(element)for element in (1, 2, 3): print(element)for key in &#123;'one':1, 'two':2&#125;: print(key)for char in "123": print(char)for line in open("myfile.txt"): print(line, end='') 这种访问方式清晰，简洁，方便。迭代器的使用贯穿并统一了Python。for语句在容器对象上调用iter()。该函数返回一个迭代器对象，该对象定义一次访问容器中元素的方法__next__()。当没有更多元素是，__next__()引发一个StopIteration异常，它告诉for循环终止。你可使用next()内置函数调用__next__()方法: 123456789101112131415&gt;&gt;&gt; s = 'abc'&gt;&gt;&gt; it = iter(s)&gt;&gt;&gt; it&lt;iterator object at 0x00A1DB50&gt;&gt;&gt;&gt; next(it)'a'&gt;&gt;&gt; next(it)'b'&gt;&gt;&gt; next(it)'c'&gt;&gt;&gt; next(it)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; next(it)StopIteration 看到了迭代器协议背后的机制，很容易将迭代器行为添加到类中。定义一个__iter__()方法，该方法使用__next__()方法返回一个对象。 1234567891011121314class Reverse: """Iterator for looping over a sequence backwards.""" def __init__(self, data): self.data = data self.index = len(data) def __iter__(self): return self def __next__(self): if self.index == 0: raise StopIteration self.index = self.index - 1 return self.data[self.index] 12345678910&gt;&gt;&gt; rev = Reverse('spam')&gt;&gt;&gt; iter(rev)&lt;__main__.Reverse object at 0x00A1DB50&gt;&gt;&gt;&gt; for char in rev:... print(char)...maps 生成器Generators 生成器是创建迭代器的简单而强大的工具。它们像常规函数一样编写，但只要它们想返回数据就是用yield语句。每次next()被调用时，生成器都会从停止的地方恢复(它记住所有的数据值以上次执行的代码)。 123456789101112def reverse(data): for index in range(len(data)-1, -1, -1): yield data[index]&gt;&gt;&gt; for char in reverse('golf'):... print(char)...flog 任何可用生成器完成的事情也可用前面的基于类的迭代器完成。使生成器如此紧凑的原因是__iter__()和__next__()方法时自动创建的。 另一个关键特性是本地变量和执行状态在调用之间自动保存。这使得该函数更容易编写，并且比使用self.index和self.data等实例变量的方法更加清晰。除了自动方法创建和保存程序状态之外，当生成器终止时，它们会自动产生StopIteration。结合起来，这些功能可以轻松创建迭代器，而无需编写常规函数。 生成器表达式Generator Expressions 一些简单的生成器可以使用与列表解析类似的语法简洁地编码为表达式，带括号而不是方括号。这些表达式适用于通过封闭函数立即使用生成器的情况。生成器表达式比完整的生成器定义更紧凑但功能更少，并且倾向于比等效的列表解析更具有内存友好性。 123456789101112131415161718&gt;&gt;&gt; sum(i*i for i in range(10)) # sum of squares285&gt;&gt;&gt; xvec = [10, 20, 30]&gt;&gt;&gt; yvec = [7, 5, 3]&gt;&gt;&gt; sum(x*y for x,y in zip(xvec, yvec)) # dot product260&gt;&gt;&gt; from math import pi, sin&gt;&gt;&gt; sine_table = &#123;x: sin(x*pi/180) for x in range(0, 91)&#125;&gt;&gt;&gt; unique_words = set(word for line in page for word in line.split())&gt;&gt;&gt; valedictorian = max((student.gpa, student.name) for student in graduates)&gt;&gt;&gt; data = 'golf'&gt;&gt;&gt; list(data[i] for i in range(len(data)-1, -1, -1))['f', 'l', 'o', 'g'] 虚拟环境Virtual Environments and Packages 应用程序有时候需要特定的模块版本，或者某个模块只支持特定Python版本。这就意味着一个Python安装版本可能无法满足每个应用程序的要求。(如某个应用程序支持Python2.7，而某个应用程序支持Python3.x) 此问题的解决方案是创建一个虚拟环境(virtual environment)——一个包含特定Python安装包和软件包的目录树。这样，不同的应用程序就可以使用不同的虚拟环境。 创建虚拟环境Creating Virtual Environments 用于创建和管理虚拟环境额模块称为venv.它通常会为你安装最新版本的Python，你也可以选择Python版本。 激活虚拟环境后，会改变提示符并修改环境，以便提供特定的Python版本。 123456789101112131415#创建虚拟环境python3 -m venv /tmp/pythonVenv#激活source /tmp/pythonVenv/bin/activate(pythonVenv) [zhang@zhang21 ~]$(pythonVenv) [zhang@zhang21 ~]$ python&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.path[&apos;&apos;, &apos;/usr/lib64/python34.zip&apos;, &apos;/usr/lib64/python3.4&apos;, &apos;/usr/lib64/python3.4/plat-linux&apos;, &apos;/usr/lib64/python3.4/lib-dynload&apos;, &apos;/tmp/pythonVenv/lib64/python3.4/site-packages&apos;, &apos;/tmp/pythonVenv/lib/python3.4/site-packages&apos;]#退出deactivate pip包管理你可以使用pip程序进行搜索、安装、升级和移除软件包。pip程序默认从安装软件包。 pip freeze 以requirements的格式输出已安装软件包。这很重要。 12345678910111213141516171819202122pip search sh#默认安装最新版本pip install sh#安装指定版本pip install sh=1.10.2pip install --upgrade shpip uninstall sh#显示已安装的模块的详细信息pip show sh#列出已安装模块pip listpip freeze &gt; requirements.txt#安装依赖pip install -r ./requirements.txt 配置国内源Linux: 12345678910111213# globalvim ~/.pip/pip.conf# aliyun[global]trusted-host=mirrors.aliyun.comindex-url=https://mirrors.aliyun.com/pypi/simple/# temporarypip install xxx -i https://mirrors.aliyun.com/pypi/simple/ 下划线参考: https://shahriar.svbtle.com/underscores-in-python https://segmentfault.com/a/1190000002611411 https://zhuanlan.zhihu.com/p/36173202 本节讨论Python中下划线(_)的使用，它的大部分用法都是一种惯例约定。 模式 栗子 含义 单下划线前缀 _var 命名约定，仅供内部使用。通常不会有Python解释器强制执行，只作为对程序员的提示 单下划线后缀 var_ 按约定使用以避免与Python关键字的命名冲突 双下划线前缀 __var 当在类上下文中使用时，触发名称修饰 双下划线前后缀 __var__ 表示Python语言定义的特殊方法 单个下划线 _ 三个情况 单个下划线单下划线(_)主要有三种情况: 解释器中下划线(_)符号指交互式解释器中最后一次执行语句的返回结果。 12345678910&gt;&gt;&gt; _Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;NameError: name &apos;_&apos; is not defined&gt;&gt;&gt;&gt;&gt;&gt; 111111&gt;&gt;&gt;&gt;&gt;&gt; _111 作为名称使用下划线(_)用作被丢弃的名称。这样可以让阅读你代码的人知道，这是个不会被使用的特定名称。 国际化下划线(_)用作函数名。这种情况下，单下划线经常被用作国际化和本地化字符串翻译查询的函数名。在Django中，你可能会看到: 123456from django.utils.translation import ugettext as _from django.http import HttpResponsedef my_view(request): output = _("Welcome to my site.") return HttpResponse(output) 单下划线前缀的名称以单下划线做前缀的名称(如_shahriar)，指定了这个名称是私有的。在有些import *的场景中，下一个使用你代码的人会明白这个名称仅供内部使用。下划线前缀的含义是告知其他程序员：以单个下划线开头的变量或方法仅供内部使用。 该约定在PEP 8中有定义。 如果你写了from module import *，那么以单下划线开头的名称都不会被导入，除非模块或包中的__all__列表显式地包含了它们。 单下划线后缀的名称以单下划线后缀的名称(如var_)，有时，一个变量的最合适的名称已被一个关键字所占用。在这种情况下，你可以附加一个下划线来解决命名冲突。 12345&gt;&gt;&gt; def make_object(name, class):SyntaxError: &quot;invalid syntax&quot;&gt;&gt;&gt; def make_object(name, class_):... pass 双下划线前缀的名称以双下划线做前缀的名称(如__shahriar)，它对解释器有特定含义。Python中的这种用法是为了避免与子类定义的名称冲突。 前后都有双下划线的名称前后都有双下划线的名称(如__init__)，是Python的特殊方法名，这是一种惯例，一种确保Python系统中的名称不会跟用户自定义的名称发生冲突的方式。 代码和命名规范 代码规范 编码: 如无特殊情况，一律使用utf-8编码，文件头部加入#-*-coding: utf-8-*- 缩进: 统一使用4个空格进行缩进，不要使用tab 行宽: 每行代码尽量不要超过80个字符（特殊情况下最长不要超过120个字符） 引号: 自然语言使用双引号，机器语言使用单引号。因此，代码里多数应该使用单引号 空行: 模块级函数和类定义之间空两行； 类成员函数之间空一行。函数中可以使用空行分隔出逻辑相关的代码 1234567891011class Abc: def __init__(self): pass def bcd(self): passdef main(): pass import语句: 应该分行书写；应该放在模块说明和文档字符串之后，全局变量之前；应按照顺序排列，每组之间用一个空行分隔 123456import osimport sysfrom subprocess import Popen, PIPEfrom abc.bcd import Xyz 换行: python支持括号内换行；使用反斜杠换行 文档字符串: 所用公共模块、函数、类、方法，都应该写文档字符串 命名规范 模块名: 尽量使用小写、尽量短，尽量不要使用下划线（除非多个单词，且数量不多的情况） 123456# 正确的模块名import abcimport abc_def# 不推荐的模块名import Abc 包名: 和模块名一样 文件名: 小写，可使用下划线 类名: 使用驼峰命名风格，首字母大写，私有类可用一个下划线开头。 123456Class Abc(): passClass _PrivateAbc(Abc): pass 函数名: 一律小写，如有多个单词，用下划线隔开。私有函数在前面加一个下划线。 1234567def abc(): passdef abc_def(): passdef _abc(): pass 变量名: 尽量小写，如有多个单词，用下划线隔开；常量和全局变量采用全大写，如果多个单词，用下划线隔开。 123name = 'abc'MAX_CLIENT = 1000 语言参考The Python Language Reference Python参考手册描述了Python语言的语法(syntax)和核心语义(core semantics)。 介绍Introduction 此参考手册描述了Python编程语言，它并不是一个教程。如果你正在使用Python并且想知道关于改语言的特定区域的精确规则是什么，那么你绝对应该能够在这里找到它们。 词法分析Lexical analysis 解析器(parser)读取Python程序。解析器的输入是由词法分析器生成的令牌流(stream of tokens)。本章描述了词法解析器如何将文件分解为令牌。 Python将程序文本读作Unicode code point，源文件的编码可以通过编码声明给出，默认为UTF-8，具体请参阅PEP 320。如果源文件无法被编码，则抛出语法错误。 行结构Line structure Python程序分为许多逻辑行。 逻辑行Logical lines 逻辑行的结尾由token NEWLINE表示。语句不能跨过逻辑行边界，除非语法允许NEWLINE。通过遵循显式或隐式的行连接规则，从一个或多个物理行构造逻辑行。 物理行Physical lines 物理行是由行尾序列终止的字符序列。在源文件和字符串中，可使用任何标准平台的行终止序列。Unix格式使用ASCII的LF，Windows格式使用ASCII的CR LF，或使用旧的Macintosh格式ASCII CR字符。无论平台如何，所有这些格式都可以平等使用。输入的结尾也充当最终物理行的隐式终止符。嵌入Python时，应使用标准C约定的换行符将源代码字符传递给Python API。 注释Comments 注释以哈希字符(#)开头，以物理行的末尾结束。注释表示逻辑行的结束，除非调用隐式行连接规则。语法会直接忽略注释。 编码声明Encoding declarations 如果Python脚本中的第一行或第二行中的注释与正则表达式coding[=:]\s*([-\w.]+)相匹配，则此注释将作为编码声明处理。编码声明必须出现在它自己的一行上。若果是第二行，则第一行也必须是仅注释行。编码表达式的推荐格式: 1# -*- coding: &lt;encoding-name&gt; -*- 如果未发现编码声明，默认编码为UTF-8。如果声明了编码，则必须有Python识别编码名称。编码用于所有词法分析，包括字符串文字，注释和标识符。 显式行连接Explicit line joining 可使用反斜杠(\)将两个或多个物理行连接到逻辑行中。 1234if 1900 &lt; year &lt; 2100 and 1 &lt;= month &lt;= 12 \ and 1 &lt;= day &lt;= 31 and 0 &lt;= hour &lt; 24 \ and 0 &lt;= minute &lt; 60 and 0 &lt;= secod &lt; 60: #Look like a valid date return 1 以反斜杠结尾的行不能编写注释。反斜杠在字符串文字外的一行上的其他位置是非法的。 隐式行连接Implicit line joining 括号，方括号，花括号中的表达式可以在不使用反斜杠的情况下分割为多个物理行。 1234month_names = ['January', ‘February', 'March', #comments 'April', 'May', 'June', #comments 'July', 'Auguest', 'September', #comments 'October, 'November', 'December'] 隐式的连续行可以带有注释，连续行的缩进并不重要。允许空白的连续行。 空白行Blank lines 包含空格，制表符，换页符，注释的逻辑行会被忽略。在标准的交互式解释器中，完全空白的逻辑行终止多行语句。 缩进Indentation 逻辑行开头的前导空白(空格和制表符)用于计算行的缩进级别，而后者又用于语句的分组。 tabs被1-8个空格替换(从左到右)，使得包括被替换的字节数总是八的倍数。第一个非空白字符前面的空格总数确定行的缩进。缩进不能够使用反斜杠在多个物理行上分隔。如果源文件以一种方式混合制表符(tab)和空格，使得含义取决于空格中制表符的价值，则缩进被拒绝为不一致。会抛出TabError异常。 跨平台兼容性说明： 由于non_Unix平台上文本编辑器的性质，在源文件中使用制表符和空格的混合来缩进是不明智的。还应注意，不同平台可以明确地限制最大缩进级别。 标识符和关键字Identifiers and keywords 标识符也称为名称，标识符的长度不受限制。Python中标识符的语法基于Unicode标准附件UAX-31，详情请参考PEP 3131在ASCII范围内(U+0001...U+007F)，有效的字符与Python2相同。大小写字母A-z，除第一个字符外的下划线(_)，数字0-9。Python3引入了ASCII范围外的其它字符，对于这些字符，分类使用unicodedata模块中包含的Unicode Character Database的版本。 Unicode类别代码表示： Lu： uppercase letters Ll： lowercase letters Lt： titlecase letters Lm： modifier letters Lo： other letters Nl： letter numbers Mn： nonspacing marks Mc： spacing combining marks Nd： decimal numbers Pc： connector punctuations Other_ID_Start： explicit list of characters in PropList.txt to support backwards compatibility Other_ID_Continue： likewise 关键字Keywords 以下标识符用作保留字或关键字，不能用作普通标识符。 123456789help(keywords)False class finally is returnNone continue for lambda tryTrue def from nonlocal whileand del global not withas elif if or yieldassert else import passbreak except in raise 保留的类标识符Reserved classes of identifiers 某些类标识符(除了关键字)具有特殊含义。这些类由前导/后置下划线(_)字符标识： _*特殊标识符_，用于交互式解释器中存储上次评估的结果，它保存在内建模块中。当不处于交互式模式时，下划线_没有特殊含义，也没有定义。名称_通常与国际化一起使用，这是一种约定。 __*__系统定义的名称。这些名称由解释器及其实现(包括标准库)来定义。在任何情况下，任何使用__*__名称都不会明确记录，在没有任何警告的情况下会受到破坏。 __*私有类(class-private)名称。在类定义的上下文中使用中使用此目录中的名称，名称将被重写，以使用损坏的格式来帮助避免基类和派生类(base and derived class)的私有属性之间的名称冲突。 文字值Literals 文字值是一些内建类型的常量值的符号。 字符串和字节文字值String and Bytes literals 字符串文字值和字节文字值描述： 12345678910111213141516171819202122stringliteral ::= [stringprefix](shortstring | longstring)stringprefix ::= &quot;r&quot; | &quot;u&quot; | &quot;R&quot; | &quot;U&quot; | &quot;f&quot; | &quot;F&quot; | &quot;fr&quot; | &quot;Fr&quot; | &quot;fR&quot; | &quot;FR&quot; | &quot;rf&quot; | &quot;rF&quot; | &quot;Rf&quot; | &quot;RF&quot;shortstring ::= &quot;&apos;&quot; shortstringitem* &quot;&apos;&quot; | &apos;&quot;&apos; shortstringitem* &apos;&quot;&apos;longstring ::= &quot;&apos;&apos;&apos;&quot; longstringitem* &quot;&apos;&apos;&apos;&quot; | &apos;&quot;&quot;&quot;&apos; longstringitem* &apos;&quot;&quot;&quot;&apos;shortstringitem ::= shortstringchar | stringescapeseqlongstringitem ::= longstringchar | stringescapeseqshortstringchar ::= &lt;any source character except &quot;\&quot; or newline or the quote&gt;longstringchar ::= &lt;any source character except &quot;\&quot;&gt;stringescapeseq ::= &quot;\&quot; &lt;any source character&gt;bytesliteral ::= bytesprefix(shortbytes | longbytes)bytesprefix ::= &quot;b&quot; | &quot;B&quot; | &quot;br&quot; | &quot;Br&quot; | &quot;bR&quot; | &quot;BR&quot; | &quot;rb&quot; | &quot;rB&quot; | &quot;Rb&quot; | &quot;RB&quot;shortbytes ::= &quot;&apos;&quot; shortbytesitem* &quot;&apos;&quot; | &apos;&quot;&apos; shortbytesitem* &apos;&quot;&apos;longbytes ::= &quot;&apos;&apos;&apos;&quot; longbytesitem* &quot;&apos;&apos;&apos;&quot; | &apos;&quot;&quot;&quot;&apos; longbytesitem* &apos;&quot;&quot;&quot;&apos;shortbytesitem ::= shortbyteschar | bytesescapeseqlongbytesitem ::= longbyteschar | bytesescapeseqshortbyteschar ::= &lt;any ASCII character except &quot;\&quot; or newline or the quote&gt;longbyteschar ::= &lt;any ASCII character except &quot;\&quot;&gt;bytesescapeseq ::= &quot;\&quot; &lt;any ASCII character&gt; 两种类型的文字值都可用单引号(&#39;)或双引号(&quot;)括起来，也能包含在三个引号中。反斜杠(\)字符用于转义好友特殊含义的字符。字节文字值总是以b或B为前缀，它们生成byte类型的实例，而不是str类型。它们可能只包含ASCII字符(128)，更大的字节必须转义。字符串和字节文字值都可以选择以字母r或R为前缀，如原始字符串将反斜杠视为文字字符。因此，在字符串文字值中，原始字符串中的\u和\U不会被特殊处理。 公认的转义序列： Escape Sequence Meaning \newline Backslash and newline ignored \\ Backslash () \&#39; Single quote (‘) \&quot; Double quote (“) \a ASCII Bell (BEL) \b ASCII Backspace (BS) \f ASCII Formfeed (FF) \n ASCII Linefeed (LF) \r ASCII Carriage Return (CR) \t ASCII Horizontal Tab (TAB) \v ASCII Vertical Tab (VT) \ooo Character with octal value ooo \xhh Character with hex value hh 仅在字符串文字值中识别的转义序列： Escape Sequence Meaning \N{name} Character named name in the Unicode database \uxxxx Character with 16-bit hex value xxxx \Uxxxxxxxx Character with 32-bit hex value xxxxxxxx 字符串文字串联String literal concatenation 多个相邻的字符串或字节文字值(由空格分隔)，可能使用不同的引用约定，并且它们的含义与它们的串联相同。因此，&quot;hello&quot; &#39;world&#39;等同于&quot;helloworld&quot;。此功能可用于减少反斜杠的数量，方便地跨长行分隔长字符串，甚至可以为字符串的某些部分添加注释。 123re.compile(&quot;[A-Za-z]&quot; #letter or underscore &quot;[A-Za-z0-9_]*&quot; #letter, digit or underscore ) 注意，此功能在语法级别上定义，但在编译时实现。必须使用+操作符在运行时连接字符串表达式。 格式化的字符串文字值Formatted string literals 格式化的字符串文字值是以f或F为前缀的字符串文字，这些字符串可能包含替换字段——由{}分隔的表达式。 12345678f_string ::= (literal_char | &quot;&#123;&#123;&quot; | &quot;&#125;&#125;&quot; | replacement_field)*replacement_field ::= &quot;&#123;&quot; f_expression [&quot;!&quot; conversion] [&quot;:&quot; format_spec] &quot;&#125;&quot;f_expression ::= (conditional_expression | &quot;*&quot; or_expr) (&quot;,&quot; conditional_expression | &quot;,&quot; &quot;*&quot; or_expr)* [&quot;,&quot;] | yield_expressionconversion ::= &quot;s&quot; | &quot;r&quot; | &quot;a&quot;format_spec ::= (literal_char | NULL | replacement_field)*literal_char ::= &lt;any code point except &quot;&#123;&quot;, &quot;&#125;&quot; or NULL&gt; 栗子： 12345678910111213141516&gt;&gt;&gt; name = &quot;Fred&quot;&gt;&gt;&gt; f&quot;He said his name is &#123;name!r&#125;.&quot;&quot;He said his name is &apos;Fred&apos;.&quot;&gt;&gt;&gt; f&quot;He said his name is &#123;repr(name)&#125;.&quot; # repr() is equivalent to !r&quot;He said his name is &apos;Fred&apos;.&quot;&gt;&gt;&gt; width = 10&gt;&gt;&gt; precision = 4&gt;&gt;&gt; value = decimal.Decimal(&quot;12.34567&quot;)&gt;&gt;&gt; f&quot;result: &#123;value:&#123;width&#125;.&#123;precision&#125;&#125;&quot; # nested fields&apos;result: 12.35&apos;&gt;&gt;&gt; today = datetime(year=2017, month=1, day=27)&gt;&gt;&gt; f&quot;&#123;today:%B %d, %Y&#125;&quot; # using date format specifier&apos;January 27, 2017&apos;&gt;&gt;&gt; number = 1024&gt;&gt;&gt; f&quot;&#123;number:#0x&#125;&quot; # using integer format specifier&apos;0x400&apos; 数字文字值Numeric literals 有三种类型的数字文字值： integers floating point numbers imaginary numbers 没有复数文字值。请注意，数字文字值不包含符号。像-1实际是由一元运算符-和文字值1组成的表达式。 整数文字值除了可以存储在可用内存中之外，整数文字值的长度没有限制。 12345678910integer ::= decinteger | bininteger | octinteger | hexintegerdecinteger ::= nonzerodigit ([&quot;_&quot;] digit)* | &quot;0&quot;+ ([&quot;_&quot;] &quot;0&quot;)*bininteger ::= &quot;0&quot; (&quot;b&quot; | &quot;B&quot;) ([&quot;_&quot;] bindigit)+octinteger ::= &quot;0&quot; (&quot;o&quot; | &quot;O&quot;) ([&quot;_&quot;] octdigit)+hexinteger ::= &quot;0&quot; (&quot;x&quot; | &quot;X&quot;) ([&quot;_&quot;] hexdigit)+nonzerodigit ::= &quot;1&quot;...&quot;9&quot;digit ::= &quot;0&quot;...&quot;9&quot;bindigit ::= &quot;0&quot; | &quot;1&quot;octdigit ::= &quot;0&quot;...&quot;7&quot;hexdigit ::= digit | &quot;a&quot;...&quot;f&quot; | &quot;A&quot;...&quot;F&quot; 浮点数文字值 123456floatnumber ::= pointfloat | exponentfloatpointfloat ::= [digitpart] fraction | digitpart &quot;.&quot;exponentfloat ::= (digitpart | pointfloat) exponentdigitpart ::= digit ([&quot;_&quot;] digit)*fraction ::= &quot;.&quot; digitpartexponent ::= (&quot;e&quot; | &quot;E&quot;) [&quot;+&quot; | &quot;-&quot;] digitpart 虚数文字值 1imagnumber ::= (floatnumber | digitpart) (&quot;j&quot; | &quot;J&quot;) 运算符Operators 123+ - * ** / // % @&lt;&lt; &gt;&gt; &amp; | ^ ~&lt; &gt; &lt;= &gt;= == != 分隔符Delimiters 1234( ) [ ] &#123; &#125;, : . ; @ = -&gt;+= -= *= /= //= %= @=&amp;= |= ^= &gt;&gt;= &lt;&lt;= **= Python中以下ASCII字符有重要意义： 1&apos; &quot; # \ Python中不使用以下ASCII字符: 1$ ? 数据模型Data model 对象，值和类型Objects, values and types 对象(Objects)是Python的数据抽象。Python程序中的所有数据都由对象或对象之间的关系表示。每个对象都有一个标识(Identity)，一个类型(Type)和一个值(Value)。对象的标识一旦创建就永远不会改变。is操作符就是比较两个对象的标识；id()函数返回一个表示其标识的整数。 12345name = 'zhang'NAME = 'ZHANG'name is NAMEFalse CPython中，id(x)是存储x的内存地址。 对象的类型(Type)确定了对象支持的操作，并且还定义了该类型的对象的可能值。type()函数返回对象的类型。与对象标识一样，对象的类型也是不可更改的。 某些对象的值(Value)可以改变。值可以改变的对象被认为是可变的(mutable)，值不可改变的的对象被称为是不可变的(immutable)。对象的可变性由其类型决定。例如，数字(number)，字符串(string)，元组(tulple)是不可变的，字典(dictionary)和列表(list)是不可变的。 对象永远不会被明确销毁，然而，当它们变得无法到达(unreachable)时，它们可能会被垃圾回收(garbage-collected)。允许实现推迟垃圾回收或完全省略垃圾回收——只要没有回收到仍然是可以访问的对象，垃圾回收的实现方式就是如此。 请注意，使用实现的tracing或debugging工具可以使对象保持活动状态，这些对象通常是可回收的。另请注意，使用try...except语句捕获异常可能会使对象保持活动状态。 某些对象包含对外部(external)资源的引用，如打开的文件。当对象被垃圾回收时，这些资源被释放，但由于不能保证垃圾回收发生，这些对象还提供了一种释放外部资源的明确的方法——close()方法。强烈建议程序明确关闭此类对象。try...finally语句和with语句提供了方便的方法。 一些对象包含对其它对象的引用，这被称为容器(container)，容器的栗子是元组，列表和字典。引用是容器值的一部分。在大多数情况下，当我们谈论容器的值时，指的是值而并非容器对象的标识；但是，但我们谈论容器的可变性时，只隐含了直接包含的对象的标识。因此，如果一个不可变容器(如元组)包含对可变对象的引用，则如果更改了可变对象，则其值会改变。 类型几乎影响对象行为的所有方面。在某种意义上，即使对象标识的重要性也会受到影响：对于不可变类型，计算新值的操作实际上可以返回对具有相同类型和值的任何对象的引用，而对于可变对象，这是不允许的。 标准类型层次结构The standard type hierarchy 下面列出了Python內建的类型，扩展模块可定义其它类型。下面的一些类型描述包含一个列出的special attributes段落。这些属性提供对实现的访问，不适用于一般用途。它们的定义未来可能发生变化。 None此类型具有单个值(single value)。有一个具有此值的对象，可通过內建名称None访问此对象。在许多情况下它用于表示缺少值，例如，它是未明确返回任何内容的函数的返回。Its truth value is false. NotImplemented此类型具有单个值。有一个具有此值的对象，可通过內建名称NotImplemented访问此对象。如果数值方法和富比较方法尉氏县所提供的操作数的操作，则返回此值。Its truth value is true. Ellipsis此类型具有单个值。有一个具有此值的对象，可通过...或內建名称Ellipsis访问此对象。Its truth value is true. numbers.Number由数字创建，并由算术运算符和算术内置函数作为结果返回。数值对象是不可变的。Python数字与数学数字密切相关，但收到计算机中数值表示的限制。Python区分整数(integer)、浮点数(floating point number)和复数(complex number)： numbers.Integral表示整数的数学集合(正数和复数)的元素，有两种类型的整数: Integers (int)这代表无限范围内(unlimited range)的数字，仅受到可用(virtual)memory的限制。 Booleans (bool)这代表真值的True和False，这两个对象是唯一的布尔值对象。布尔类型是整数类型的子类型，布尔值在几乎所有上下文中的行为分别类似于值0和1，例外的是，当转换为字符串时，分别返回字符串False或True。 numbers.Real (float)这代表机器级双精度(double precision)浮点数。您可以接受底层机器架构，以获得可接受的范围和溢出处理。Python不支持单精度浮点数，没有理由使用两种浮点数复杂化语言。 numbers.Complex (complex)这将复数表示为一对机器级双精度浮点数。可通过只读属性z.real和z.imag来检索复数z的实部(real)和虚部(imaginary)。 Sequences这表示由非负数索引的有限有序集。內建函数len()返回序列的项数。当序列长度为n时，索引集数字为0, 1, ..., n-1。序列的i项由a[i]选择。序列还支持切片(slicing): a[i:j]选择一定范围内的项。当使用表达式时，切片是相同类型的序列。一些序列还支持带有步进(step)参数的扩展切片: a[i:j:k]。序列根据其可变性进行区分： Immutable sequences不可变序列类型的对象一旦创建就不能更改。如果对象包含对其它对象的引用，则这些其它对象可能是可变的并且可能会被更改；但是，由不可变对象直接引用的对象集合不能更改。不可变序列有以下类型： Strings字符串是表示Unicode code ponit的值序列。U+0000 - U+10FFFF范围内的代码点都可以用字符串表示。Python没有char类型；相反，字符串中的每个代码点都表示为长度为1的字符串对象。內建函数ord()将代码点从字符串形式转换为0-10FFFF范围内的整数；chr()将0-10FFFF范围内的整数转化为对应长度为1的字符串对象；str.encode()可用于将str转换为bytes，而bytes.decode()用于实现相反的操作。 12345678&gt;&gt;&gt; ord('a')97&gt;&gt;&gt; chr(97)a&gt;&gt;&gt; str.encode('a')b'a'&gt;&gt;&gt; bytes.decode(b'a')a Tuples元组的项是任意Python对象。两个或多个项的元组由逗号分隔的表达式列表组成。空元组可由一对空括号组成。 Bytes字节对象是一个不可变的数组。这些项是8-bit bytes，由0-255范围内的整数表示。 Mutable sequences可变序列创建之后可以更改。订阅和切片表示法可用作赋值和del语句的目标。目前有两种可变序列类型： **Lists列表的项是任意Python对象。通过将逗号分隔的表达式放在方括号中来形成列表。 Byte Arraysbytearray对象是一个可变数组。它们由內建的bytearray()构造器(constructor)创建。 扩展模块array提供了可变序列类型的另一个示例，collections模块也是如此。 Set types这代表无序，有限的唯一不可变的对象集。因此，它们不能被任何下标索引。但是，它们可以迭代，內建函数len()返回集合的项目数。集合的常见用途是进行快速成员资格测试，从序列中删除重复项，以及计算数学运算(交集、并集、差集…)。对于集合元素，相同的不可变性规则适用于字典的键。请注意，数字类型遵循数字比较的常规规则：如果两个数字相等(如 1, 1.0)，则它们中只能包含其中一个。目前有两种固有的集合类型: Sets这代表一个可变集合。它们通过內建的set()构造器进行创建，之后可通过多种方法进行修改(如 add())。 Frozen sets这代表一个不可变集合。它们通过內建的frozenset()构造器进行创建。它是可变且可清除的，因此它可以再次用作另一个集合的元素，或作为字典的键。 Mappings这表示由任意索引集合索引的有限对象集。如下标符号a[k]从映射a中选择由k索引的项；这可在表达式中使用，也可作为赋值或del语句的目标。內建函数len()返回映射中的项数。目前有一种内在映射类型： Dictionaries这表示有几乎任意值索引的有限对象集。唯一不能作为键接受的值是包含列表或字典或其它可变类型的值，这些值通过值而不是按对象标识进行比较，原因是字典的有效实现需要键的哈希值保持不变。用于键的数字类型遵循用于数字比较的正常规则：如果两个数字相等(如1, 1.0)，则它们互相地用于索引相同的字典项。字典是可变的，它们可通过{...}符号创建。扩展模块dbm.ndbm和dbm.gnu提供了映射类型的其它实例，collections模块也是如此。 Callable types这是可应用函数调用操作的类型： User-defined functions用户定义的函数对象由函数定义创建。它应使用包含于函数的形式参数列表相同数量的项的参数列表来调用它。特殊属性(special attributes): Attribute Meaning - __doc__ The function’s documentation string, or None if unavailable; not inherited by subclasses Writable __name__ The function’s name Writable __qualname__ The function’s qualified name. New in version 3.3. Writable __module__ The name of the module the function was defined in, or None if unavailable. Writable __defaults__ A tuple containing default argument values for those arguments that have defaults, or None if no arguments have a default value Writable __code__ The code object representing the compiled function body. Writable __globals__ A reference to the dictionary that holds the function’s global variables — the global namespace of the module in which the function was defined. Read-only __dict__ The namespace supporting arbitrary function attributes. Writable __closure__ None or a tuple of cells that contain bindings for the function’s free variables. Read-only __annotations__ A dict containing annotations of parameters. The keys of the dict are the parameter names, and return for the return annotation, if provided. Writable __kwdefaults__ A dict containing defaults for keyword-only parameters. Writable 标记为可写的大多数属性都会检查指定值的类型。函数对象同样支持获取和设置任意属性。如，可使用这些属性将元数据附加到函数。常规属性.点表示法用于获取和设置此类属性。请注意，当前实现仅支持用户定义函数的函数属性。将来可能会支持内置函数的函数属性。 Instance methods实例方法对象组合了类(class)，类实例(class instance)和任何可调用对象(通常是用户定义的函数)。 特殊的只读属性：__self__是类实例对象，__func__是函数对象；__doc__是方法的文档(同__func__.__doc__)；__name__是方法名(同__func__.__name__)；__module__是定义的方法的模块的名称，如果不可用，则为None。 方法也支持访问底层函数对象上的任意函数属性。 当获取类的属性时，如果该属性是用户定义的函数对象或类方法对象，则可创建用户定义的方法对象。当通过实例从类中检索用户定义的函数对象来创建实例方法对象时，其__self__属性是实例，并且方法对象被称为绑定(bound)。新方法__func__属性是原始函数对象。当通过从类或实例检索另一个方法对象来创建用户定义的方法对象时，行为与函数对象的行为相同，只是新实例的__func__属性不是原始方法对象，而是其__func__属性。当通过从类或实例检索类方法对象来创建实例方法对象时，其__self__属性是类本身，其__func__属性是类方法的基础函数对象。调用实例方法对象时，将调用基础函数__func__，将类实例__self__插入参数列表前面。 注意，每次从实例检索属性时，都会发生从函数到实例方法对象的转换。在某些情况下，有成效的优化将属性分配给局部变量并调用局部变量。还要注意，此转换仅适用于用户定义的函数；在不进行转换的情况下检索其它可调用对象(以及不可调用对象)。作为类实例属性的用户定义函数不会转换为绑定方法;这只有在函数是类的属性时才会发生。 Generator functions使用yield语句的函数或方法被称为生成器函数。这样的函数在被调用时总是返回一个迭代器对象，它可以用来执行函数体：调用迭代器的iterator.__next__()方法将导致函数执行，直到它使用yield语句提供一个值。当函数执行return语句或结束时，会引发StopIteration异常，并且迭代器将到达要返回的值集合的末尾。 Coroutine functions使用async def定义的函数或方法称为协程函数。这样的函数在被调用时返回一个协程对象。它可能包含await表达式，以及async with和async for语句。 Asynchronous generator functions使用async def定义并使用yield语句的函数或方法称为异步生成器函数。这样的函数在调用时返回一个异步迭代器对象，该对象可在async for语句中用于执行函数体。 调用异步迭代器的aiterator.__anext__()方法将返回一个awaitable来等待执行，直到它使用yield表达式。当函数执行一个空的return语句或从结尾处掉落时，会引发StopAsyncIteration异常，异步迭代器将到达要生成的值集的末尾。 Built-in functions內建函数对象是C函数的包装器。 Built-in methods这实际上是内建函数的不同伪装，包含作为隐式额外参数传递给C函数的对象。 Classes类是可调用的。这些对象通常作为新实例的工程，但是对于覆盖__new__()的类类型可能存在变化。调用的参数传递给__new__()，在典型情况下，传递给__init__()以初始化新实例。 Class Instances通过在类中定义__call__()方法，可使任意类的实例可调用。 Modules模块是Python代码的基本组织单元，由导入系统(import system)创建，由import语句调用。模块对象具有由字典对象实现的命名空间(由模块中定义的函数的__globals__属性引用)。属性引用被转换为该字典中的查找，如m.x相当于m.__dict__[&#39;x&#39;]。模块对象不包含用于初始化模块的代码对象。属性赋值更新模块命名空间字典，如m.x = 1等效于m.__dict__[&#39;x&#39;] = 1。 预定义(可写)属性： __name__是模块的名称； __doc__是模块的文档字符串，不可用为None。特殊的只读属性； __annotations__是包含在模块正文执行期间收集的变量注释的字典； __file__是从加载模块的文件的路径名，如果是从文件加载的。 Custom classes自定义类类型通常由类定义创建。类具有由字典对象实现的命名空间。类属性引用被转换为此字典中的查找，如C.x被翻译为C.__dict__[&#39;x&#39;]。类属性赋值更新类的字典，而不是基类(base class)的字典。可调用类对象以生成(yield)类实例。 特殊属性： __name__是类名； __module__是类定义的模块名； __dict__是包含类的命名空间的字典； __bases__是包含基类的元组，按它们在基类列表中出现的顺序排列； __doc__是类的文档字符串，不可用为None； __annotations__是包含在类主体执行期间收集的变量注释的字典。 Class instances通过调用类对象来创建类实例。类实例具有作为字典实现的名称空间，该字典是搜索属性引用的第一个位置。当在那找不到属性，并且实例的类具有该名称的属性时，搜索继续使用类属性。如果找到的类属性是用户定义函数对象，则将其转换为实例方法对象，其__self__属性为实例。静态方法和类方法对象也同样被转换。如果没有找类属性，并且对象的类具有__getattr__()方法，则调用该方法以满足查找。 属性分配和删除更新实例的字典，而不是类的字典。如果类具有__setattr__()或__delattr__()方法，则调用此方法而不是直接更新实例字典。如果类实例具有某些特殊名称的方法，则它们可以假装为数字，序列或映射。 特殊属性： __dict__是属性字典； __class__是实例的类。 I/O objects (also known as file objects)文件对象表示打开的文件。各种快捷方式可用于创建文件对象：open()內建函数，os.popen()，os.fdopen()，套接字对象的makefile()方法。 sys.stdin, sys.stdout和sys.stderr对象被初始化为与解释器的标准输入，标准输出和标准错误流相对应的文件对象。它们都以文本模式打开，因此遵循io.TextIOBase抽象类定义的接口。 Internal types解释器内部使用的一些类型向用户公开。它们的定义可能会随着解释器的未来版本而改变，但为了完整起见，这里提到它们。 Code objects代码对象表示字节编译的可执行Python代码或字节码。代码对象和函数对象之间的区别在于函数对象包含对函数的全局变量的显示引用，而代码对象不包含上下文；默认参数值 也存储在函数对象中，而不是存储在代码对象中。与函数对象不同，代码对象是不可变的，并且不包含可变对象的引用。特殊的只读属性： co_name给出函数名； co_argcount是位置参数的数量； co_nlocals是函数使用的局部变量数； co_varnames是包含局部变量名称的元组； co_cellvars是包含嵌套函数引用的局部变量的名称； co_freevars是包含自由变量名称的元组； co_consts包含字节码使用文字的元组； co_names包含字节码使用名称的元组； co_filename是编译代码的文件名； co_firstlineno是函数的第一个行号； co_lnotab是用于编码从字节码偏移到行号的映射； co_stacksize是必须的堆栈大小； co_flags是一个整数，用于编码解释器的许多标志； 如果代码对象表示韩式，则co_consts中的第一项是函数的文档字符串，如果未定义，则为None。 Frame objects帧对象表示执行帧。它们可能出现在回溯(traceback)对象中。特殊只读属性: f_back是前一个堆栈帧，如果这是底部堆栈帧(bottom stack frame)，则为None； f_code是在此帧中执行的代码对象； f_locals是用于查找局部变量的字典； f_global用于全局变量； f_builtins用于內建名称； f_lasti给出了精确的指令。特殊可写属性: f_trace，如果非None，则在每个源代码行的开头调用的函数； f_lineno是帧的当前行号——从跟踪函数内写入此跳转到给定行。帧对象支持一个方法: frame.clear()此方法清除帧所持有的局部变量的所有引用。如果帧属于生成器，则确定生成器。这有助于打破涉及帧对象的参考循环。如果帧当前正在运行，则引发RuntimeError。 Traceback objects回溯对象表示异常的堆栈追踪，发生异常时会创建回溯对象。当搜索异常处理程序展开执行堆栈时，在每个展开的级别上，会在当前回溯之前插入回溯对象。输入异常处理程序时，堆栈追踪可供程序使用。它可作为sys.exc_info()返回的元组的第三项进行访问。当程序不包含合适的处理程序时，堆栈追踪被写入到标准错误流；如果解释器是交互式的，那它可作为sys.last_traceback提供给用户。特殊只读属性: tb_next是堆栈追踪中的下一级，如果没有，则为None； tb_frame指向当前级别的执行帧； tb_lineno给出发生异常的行号； tb_lasti表示准确的指令。如果在没有匹配的except子句或finally子句的try语句中发生异常，则回溯中的行号和最有一条指令可能与其帧对象的行号不同。 Slice objects切片对象用于表示__getitem__()方法的切片。它们也是由内置的slice()函数创建的。特殊只读属性: start是下限； stop是上限； step是步长； 如果忽略，则每个都是None。切片对象支持一个方法: slice.indices(self, length)此方法采用单个整数参数长度，并计算切片对象在应用于一些列长度项时将描述的切片的信息。它返回一个由三个整数组成的元组——(start, stop, step)。以和常规切片一致的方法处理丢失或越界的索引。 Static method objects静态方法对象提供了一种破坏函数对象到上述方法对象的转换的方法。静态方法对象是任何其它对象的包装器，通常是用户定义的方法对象。当从类或类实例中检索静态方法对象时，实际返回的对象时包装的对象，该对象不受任何进一步转换的影响。静态方法对象本身不可调用，尽管它们通常包装的对象是。静态方法对象由內建的staticmethod()够赞函数创建。 Class method objects类方法对象，与静态方法对象类似，是另一个对象的包装器，它改变了从类和类实例中检索该对象的方式。类方法对象由內建的classmethod()构造函数创建。 特殊方法名称Special method names 类可以通过定义具有特殊名称的方法来实现有特殊语法调用的某些操作。这是Python的运算符重载方法，允许类根据语言运算符定义自己的行为。将特殊方法设置为None表示相应的操作不可用。例如，如果将类的__iter__()设置为None，则该类不可迭代，因此在其实例调用iter()将引发TypeError。 基本定制Basic customization object.__new__(cls[,...])被调用来创建类cls.__new__()的新实例是一个静态方法，它将请求实例的类作为其第一个参数。其余参数是传递给对象构造函数表达式的参数。 执行模块Execution model 程序结构Structure of a program Python程序由代码块构成。块是一段Python程序文档，作为一个单元执行。模块、函数体、类定义都是块。交互式输入的每个命令都是一个块。脚本文件是代码块，脚本命令是代码块。传递给内建函数eval()和exec()的字符串参数是一个代码块。 命名和绑定Naming and binding 名称绑定Binding of names 名称指的是对象。名称有名称绑定操作引入。 以下构造绑定名称: 函数的形式参数(formal parameters) import语句from...import *的import语句绑定导入模块中定义的所有名称，但以下划线(_)开头的名称除外。 类和函数的定义 作为标识符的目标 for循环头 在with...as或except子句之后 在del语句中出现的目标也被认为是此目的绑定的。每个赋值或导入语句都发生在由类或函数定义或模块级别定义的块中。如果名称绑定在块中，则它是该块的局部变量(local variable)，除非声明为nonlocal或global。如果名称绑定在模块级别，则它是全局变量(global variable)。模块代码块中的变量是本地和全局的。如果一个变量在代码块中使用但未在此定义，则它是一个自由变量(free variable)。程序文本中每次出现的名称都是指由以下名称解析规则建立的名称的绑定。 名称解析Resolution of names 范围(scopt)定义了块内名称的可见性。如果在块中定义了局部变量，则其范围包括该块。如果定义发生在函数块内，则作用于将扩展到定义块中包含的任何块，除非包含块为名称引入不同的绑定。 在代码块中使用名称时，将使用最近的封闭范围解析该名称。代码块可见的所有此类范围的集合称为块的环境。如果找不到名称，则会引发NameError异常。如果当前作用域是函数作用域，并且名称引用尚未绑定到使用该名称的值的本地变量，则会引发UnboundLocalError异常(它是NameError的子类)。 如果名称绑定操作发生在代码块中的任何位置，则块中名称的所有使用都将被视为对当前块的引用。在绑定之前在块中使用名称时，可能会导致错误。这条规则很微妙，Python缺少声明，并允许在代码块中的任何位置进行名称绑定操作。可以通过扫描块的整个文本以确定名称绑定操作来确定代码块的局部变量。 如果global语句发生在块中，则语句中指定的名称的所有使用都将引用在顶级命名空间中的绑定的名称。通过搜索全局(global)命名空间(包含代码块的命名空间)和內建(build-in)命名空间(內建模块的命名空间)，在顶级命名空间中解析名称。首先搜索全局命名空间。如果在那里找不到名称，则搜索內建命名空间。global语句必须在名称的所有使用之前。 global语句与同一块中名称绑定具有相同的范围。如果自由变量的最近封闭范围包含全局语句，则将自由变量视为全局变量。nonlocal语句使相应的名称引用最近的封闭函数范围中的先前绑定的变量。如果任何封闭的函数作用域中不存在给定的名称，则在编译时引发SyntaxError。 模块的命名空间在第一次导入模块式自动创建。脚本的主要模块始终被称为__main__。 exec()和eval()的类定义块和参数在名称解析的上下文中是特殊的。类定义是可以使用和定义名称的可执行语句。这些引用遵循名称解析的常规规则，但在全局命名空间中查找未绑定的局部变量。类定义的命名空间成为类的属性字典。类块中定义的名称范围仅限于类块;它没有扩展到方法的代码块——这包括了解和生成器表达式，因为它们是使用函数作用域实现的。 內建和严格执行Builtins and restricted execution CPython实现细节：用户不该触碰__builtins__，它严格来说是一个实现细节。想要覆盖內建命名空间中的值的用户应该导入內建模块并适当地修改其属性。与代码块执行相关联的內建命名空间实际上是通过在其全局命名空间中查找名称__builtins__来找到的；这应该是字典或模块。默认情况下，在__main__模块中，__builtin__是內建的builtins模块；在任何其它模块中，__builtins__是內建模块本身的字典的别名。 与动态功能的交互 Interaction with dynamic features 自由变量的名称解析在运行时发生，而不是在编译时发生。 eval()和exec()函数无权访问用于解析名称的完整环境。可在调用者的本地好全局命名空间中解析名称。自由变量不在最近的封闭空间中解析，而是在全局命名空间中解析。 异常Exceptions 异常(exception)是一种打破代码块正常控制流已处理错误或其它异常情况的方法。检测到错误时会出现异常，它可以由周围的代码块直接或间接调用发生错误的代码块的任何代码块处理。 Python解释器在检测到运行时错误引发异常。Python程序也可使用raise语句显式地引发异常。使用try...execpt语句处理异常，这种语句的finally子句可用于指定不处理异常的清理代码。Python使用错误处理的termination模型：异常处理程序可找出发生的情况并继续在外层执行，但它无法修复错误原因并重试失败操作。 当根本不处理异常时，解释器终止程序的执行，或返回其交互式主循环。在任何一种情况下，它都会打印stack backtrace除非异常是SystemExit。异常由类实例标识。根据实例的类选择except子句，它必须引用实例的类或其基类。该实例可以由处理程序接收，并且可以携带关于异常情况的附加信息。 import系统The import system 通过导入(import)，一个模块中的Python代码可以访问另一个模块中的Python代码。import语句是调用导入机制的最常用方法，但它不是唯一的方法。importlib.import_module()和內建__import__()等函数也可用于导入机制。 import语句结合了两个操作，它搜索命名模块，然后将搜索结果绑定到本地范围中的名称。import语句的搜索操作定义为使用适当的参数调用__import__()函数。__import__()的返回值用于执行import语句的名称绑定操作。 对__import__()的直接调用仅执行模块搜索，如果找到，则执行模块创建操作。虽然可能会发生某些副作用，如导入父包…但只有import语句执行名称绑定操作。 当调用__import__()作为import语句的一部分时，将调用标准的内置__import__()。调用导入系统的其它机制可选择颠覆__import__()并使用自己的解决方案来实现导入语义。 首次导入模块时，Python会搜索模块。如果找到，它会创建一个模块对象，并对其进行初始化。如果找不到名称模块，则引发ModuleNotFoundError异常(No module named ‘xxx’)。Python在调用导入机制时实现了搜索命名模块的各种策略，可以修改和扩展这些策略。 importlibimportlib模块提供了一个丰富的API，用于与导入系统进行交互。 PackagesPython只有一种类型的模块对象，所有模块都属于这种类型，无论模块是用Python、C还是其它方式实现。为了帮助组织模块并提供命名层次结构，Python有一个包(package)的概念。 你可将包视为文件系统上的目录，将模块视为目录中的文件。处于此文档的目的，我们将使用这种方便的类比。包是按层次结构组织的，包本身可能包含子包以及常规模块。需要记住的是，所有包都是模块，但并非所有模块都是包。换句话说，包是一种特殊的模块。具体来说，任何包含__path__属性的模块都被视为包。 Python定义了两种类型的包： Regular Packages Namespace packages Regular packages常规包是Python v3.2及更早版本中存在的传统的包。常规包通常实现为包含__init__.py文件的目录。导入常规包时，将隐式地执行此__init__.py文件，并且它定义的对象将绑定到包命名空间的名称。__init__.py文件可以包含与任何其它模块可以包含的相同的Python代码，并且Python将在导入模块时向模块添加一些其它属性。 12345678910# 栗子# 导入parent.one将隐式地执行parent/__init__.py和parent/one/__init__.pyparent/ __init__.py one/ __init__.py two/ __init__.py three/ __init__.py Namespace packages命名空间包是各个部分的组合，其中每个部分为父包提供子包。它可位于文件系统某个位置上，也可在zip文件、网络或Python导入期间其它位置。命名空间包可能/可能不(may or may not)直接对应于系统上得对象，它们可能是没有具体表示的虚拟模块。 命名空间包不使用普通列表作为其__path__属性。它们使用自定义可迭代类型，如果其父包的路径发生更改，它将在该包的下一次导入尝试时自动执行对包部分的新搜索。 使用命名空间包，没有parent/__init__.py文件。实际上，在导入搜索期间可能会找到多个父目录，其中每个目录由不同的部分提供。因此，parent/one可能不在物理上位于parent/two旁边。在这种情况下，Python就会为顶级父包创建一个命名空间包。 Searching要开始搜素(search)，Python需要导入模块的完全限定名称。此名称可能来自import语句或其它导入函数的各种参数。 模块缓存The module cache 导入期间检查的第一个位置是sys.modules。此映射用作先前已导入的所有模块的缓存，包括中间路径。因此，如果先前导入了a.b.c，则sys.modules将包含a, a.b, a.b.c的条目。每个键的值都是相应的模块对象。 在导入期间，将在sys.modules中查找模块名称。如果存在，则关联的值是满足导入的模块，并且该过程完成。但是，如果值为None，则引发ModuleNotFoundError异常。如果缺少模块名称，Python将继续搜索模块。 sys.modules是可写的。删除key可能不会破坏关联的模块，但它会使命名模块的缓存条目无效，导致Python在下次导入时重新搜索命名模块。key也可以分配None，强制下次导入模块导致ModuleNotFoundError异常。 请注意，就好像你保留对模块对象的引用，使其在sys.modules中的缓存条目无效，然后重新导入命名模块，两个模块对象将不同。相比之下，importlib.reload()将重用相同的模块对象，只需重新运行模块的代码即可重新初始化模块内容。 查找器和载入器Finders and loaders 如果在sys.modules中找不到指定的模块，则调用Python的导入协议来查找(find)和加载(load)模块。该协议有两个概念对象。实现这两个接口的对象称为导入器，当它发现可以加载所请求的模块时，它们会自行返回。 查找器(finder)：查找器的工作是确定它是否可以使用它所知道的任何策略找到命名模块。 加载器(loader) Python包含了许多默认查找器和导入器。第一个知道如何定位內建模块，第二个知道如何定位冻结模块。第三个默认查找器搜索模块的导入路径。导入机制是可扩展的，因此可以添加新的查找器以扩展模块搜索的范围。 查找器实际上并没有加载模块。如果它可以找到命名模块，则返回模块规范、模块的导入相关信息的封装，然后导入机器在加载模块时使用。 Import hooks导入机制设计为可扩展，它的主要机制是导入钩子(import hooks)。它有两种类型： Meta hooks：在进行任何其它导入之前，在导入处理开始时调用元钩子，而不是使用sys.modules缓存查找。这允许云钩子覆盖sys.path、冻结模块甚至内置模块。 Path hooks：导入路径钩子作为sys.path处理的一部分在遇到其关联路径时被调用。 载入Loading 如果找到模块规范，导入机制将在加载模块时使用它。 123456789101112131415161718192021222324252627282930module = Noneif spec.loader is not None and hasattr(spec.loader, 'create_module'): # It is assumed 'exec_module' will also be defined on the loader. module = spec.loader.create_module(spec)if module is None: module = ModuleType(spec.name)# The import-related module attributes get set here:_init_module_attrs(spec, module)if spec.loader is None: if spec.submodule_search_locations is not None: # namespace package sys.modules[spec.name] = module else: # unsupported raise ImportErrorelif not hasattr(spec.loader, 'exec_module'): module = spec.loader.load_module(spec.name) # Set __loader__ and __package__ if missing.else: sys.modules[spec.name] = module try: spec.loader.exec_module(module) except BaseException: try: del sys.modules[spec.name] except KeyError: pass raisereturn sys.modules[spec.name] HOWTOsPython HOWTOs是覆盖单个特定主机的文档，并尝试完全包含它。此文档比Python参考库更详细。 标准库 介绍Python标准库包含了各种不同类型的组件。 一些模块提供了特定于Python的接口；一些提供特定于特定操作系统的接口，一些提供特定于特定应用程序的接口。一些模块适用于所有Python版本和端口；一些只有在底层系统支持或需要它们是才可用；还有一些只有在编译和安装Python特定配置时才可用。 内建函数Python解释器内置了许多功能和类型，它们始终可用。 内建函数 abs() dict() help() min() setattr() all() dir() hex() next() slice() any() divmod() id() object() sorted() ascii() enumerate() input() oct() staticmethod() bin() eval() int() open() str() bool() exec() isinstance() ord() sum() bytearray() filter() issubclass() pow() super() bytes() float() iter() print() tuple() callable() format() len() property() type() chr() frozenset() list() range() vars() classmethod() getattr() locals() repr() zip() compile() globals() map() reversed() __import__() complex() hasattr() max() round() delattr() hash() memoryview() set() abs(x)返回一个数字的绝对值 all(iterable)如果迭代的所有元素均为真(或为空)，返回True any(iterable)如果迭代的任一元素为真，返回True；为空返回False ascii(object) bin(x)将整数转换为二进制字符串 bool([x])返回一个布尔值，True或False bytearray()返回一个新的字节数组 byte()返回一个新的字节对象，它是一个在0&lt;=x&lt;256范围内的不可变整数序列 callable(object)如果对象参数显示为可调用，返回True；否则返回False chr(i)返回代表Unicode编码为整数i的字符的字符串 classmethod(function)为函数返回一个类方法 compile()将源编译为代码或AST对象 complex()返回一个复数，或将字符串或数字转换为复数 delattr(object, name)这是setattr()的相对值 dict(kwarg)创建一个新的字典 dir(object)无参数，返回当前本地作用域中的名称列表有参数，尝试返回该对象的有效属性列表 divmod(a, b)以两个数字(非复数)为参数，使用整数除法时返回由它们的商和余数组成的一对数字 enumerate(iterable, start=0)返回一个枚举对象 eval(expression, globals, locals) exec()动态执行Python代码 filter(function, iterable)从函数返回true的可迭代元素构造一个迭代器 float()返回由数字或字符串构造的浮点数 format()将值转换为特定格式 frozenset()返回一个新的frozenset对象，可选用来自迭代的元素 getattr()返回对象命名属性的值 globals()返回表示当前全局符号表的字典 hasattr(obj, name)参数是一个对象和一份字符串，如果字符串是对象属性之一的名称，结果为True，否则False hash(obj)返回对象的hash值 help()调用内建的帮助系统 hex(x)将整数转换为十六进制数 id(obj)返回一个对象的标识 input()从标准输入中读取一行，转换为字符串，然后返回该行 int(x)返回一个整数对象，如果没有参数，则返回0 isinstance(obj, classinfo)如果对象参数是classinfo参数的实例或其子类的实例，返回true issubclass(class, classinfo)如果class是类信息的子类，返回true iter(obj)返回一个迭代器对象 len()返回对象的长度 list()列表实际上是一个可变的序列类型，而不是一个函数 locals()更新并返回表示当前本地符号表的字典 map()返回一个将函数应用于每个迭代项的迭代器，从而产生结果 max()返回最大项 memoryview(obj)从给定参数返回内存视图对象 min()返回最小项 next()从迭代器中检索下一项 object()返回一个新的无特征的对象 oct()将整数转换为八进制字符串 open()打开文件并返回相应的文件对象 ord()给定一个表示一个Unicode编码的字符，返回一个表示该字符的Unicode编码的整数 pow() print()将对象打印到流文件 property()返回一个property属性 range()范围一个不可变的序列类型，而不是函数 repr()返回一个包含对象可打印表示的字符串 reversed()返回一个反向迭代器 round()返回数字小数点后ndigits精度 set()返回一个新的集合对象，可选来自迭代的元素 setattr()getattr的对应部分 slice()返回由范围指定的一组索引的切片(slice)对象 sorted()从迭代项中返回一个新的排序列表 staticmethod()为函数返回一个静态方法 str()返回一个字符串对象 sum()对迭代项求和 super()返回将方法调用委托个父类或同类的代理对象 tuple()元组是一个不可变的序列类型，而不是函数 vars()返回对象的__dict__属性 zip()制作一个迭代器，用于聚合来自每个迭代器的元素 __import__这个函数被import语句调用 内建常量少量常量存在于命名空间中。 False True None NotImplemented Ellipsis __debug__ 内建类型主要的内建类型有： 数字(numeric) 序列(sequence) 映射(mapping) 类(class) 实例(instance) 异常(exception) 真值测试任何对象都可进行真值测试。 布尔操作 and or not 比较操作Python中有8个比较操作： &lt; &lt;= &gt; &gt;= == != is isnot 数字类型 int float complex 迭代器类型Python支持对容器进行迭代的概念。 序列类型 list 列表是可变序列，通常用于存储同类项目的集合 tuple 元组是不可变序列，通常用于存储异构数据的集合 range 范围表示一个不可变的数字序列，通常用于for循环 range(start, stop, step) 通用序列操作 in not in + * [i] [i:j] [i:j:k] len() min() max() count() index() 不可变序列类型 可变序列类型可变定义类型的操作： [i] [i:j] del [i:j:k] append() clear() copy() += *= insert() pop remove() reverse() 文本序列类型Python中的文本数据由str对象处理，字符串是Unicode编码点的不可变序列。 字符串以各种方式书写： 单引号 双引号 三引号 字符串方法 https://docs.python.org/3.5/library/stdtypes.html#string-methods 样式字符串格式字符串对象有一个唯一的内建操作: %操作符，也称为字符串格式化操作符。 转换类型： % s i x f c 二进制序列类型 bytes 字节对象是单字节的不可变序列 bytearray 是字节对象的可变对象 memoryview 运行Python代码访问支持缓冲区协议的对象的内部数据，而无需复制 字节和字节数组对象操作符都支持普通序列操作符，同样也支持字节格式。 集合类型 set frozenset 集合对象是不同可散列对象的无序集合。常见用途包含成员测试、删除重复项，数学计算(交集，并集，差集) 映射类型 dict 映射对象可将散列值映射到任意对象，它是可变对象。 字典视图对象 dict.keys() dict.values() dict.items() 上下文管理类型Python的with语句支持由上下文管理器定义的运行时上下文的概念。 其它内建类型模块类和类实例函数方法代码对象类型对象null对象ellipsis对象notImplimented对象布尔值内部对象 特殊属性一些特殊的只读属性： object.__dict__ instance.__class__ class.__bases__ definition.__name__ definition.__qualname__ class.__mro__ class.__subclasses__() 内建异常在Python中，所有异常(exception)都必须是派生自Baseexception的类的实例。 基类 BaseException Exception ArithmeticError bufferError LookupError 具体异常 AssertionError AttributeError EOFError FloatingPointError GeneratorExit ImportError IndexError KeyError KerboardInterrupt MemoryError NameError NotImplementedError OSError OverflowError RecursionError ReferenceError RuntimeError StopAsyncIteration SyntaxError IndentationError TabError SystemError SystemExit TypeError UnboundLocalError UnicodeError UnicodeEncodeError UnicodeDecodeError UnicodeTranslateError ValueError ZeroDivisionError EnvironmentError IOError 文本处理stringstring模块，字符串操作 rere模块，提供了正则表达式匹配操作。 字符串模式匹配 12345678&gt;&gt;&gt; import re&gt;&gt;&gt; re.findall(r'f[a-z]*', 'which foot or hand fell fastest')['foot', 'fell', 'fastest']#替换&gt;&gt;&gt; 'aaa and bbb'.replace('bbb', 'BBB')'aaa and BBB' difflibdifflib，助手计算三角洲。该模块提供用于比较序列的类和函数。 textwraptextwrap模块，文本环绕和填充。将段落文本格式化以适应给定的屏幕宽度。 12345678&gt;&gt;&gt; import textwrap&gt;&gt;&gt; doc = """ 1111 1111 1111 1111 1111 1111... 2222 2222 2222 2222 2222 2222... 3333 3333 3333 3333 3333 3333"""&gt;&gt;&gt; print(textwrap.fill(doc, width=50)) 1111 1111 1111 1111 1111 1111 2222 2222 2222 22222222 2222 3333 3333 3333 3333 3333 3333 unicodedataunicodedata，Unicode数据库。该模块提供对Unicode字符数据库(UCD)的访问，此数据库为所有Unicode字符定义字符属性。 stringprepstringprep，因特网字符串准备。 readlinereadline，GNU读行接口。该模块定义了许多方便Python解释器完成和读写历史文件的函数。 rlcompleterrlcompleter，GNU读行的完成函数。该模块通过完成有效的Python标识符合关键字来定义适用于readline模块的完成函数。 二进制数据structstruct模块，将字节解释为打包的二进制数据。提供了pack()和unpack()函数来处理可变长度的二进制记录格式。 codecscodes，编解码注册和基类。 数据和时间timetime模块，提供了许多操作时间值(time value)的函数，用于取得Unix纪元时间戳。 123456789import time#Unix时间time.time()#1531364576.3187952#delay for a number of seconds given as a floattime.sleep()time.time();time.sleep(10);time.time() datetimedatetime模块，基本日期和时间类型。支持日期和时间计算，并对输出做格式化处理。 1234567891011121314151617181920212223242526import datetimedatetime.datetime.now()#datetime.datetime(2018, 7, 12, 13, 45, 43, 127838)datetime.datetime.now().year, datetime.datetime.now().month, datetime.datetime.now().hour#Unix纪元转换datetime.datetime.fromtimestamp(1531374507.8268566)#datetime.datetime.fromtimestamp(time.time())#datetime.datetime(2018, 7, 12, 13, 48, 27, 826857)#日期比较yesterday = datetime.datetime(2018, 7, 11, 00, 00, 00, 00000)today = datetime.datetime.now()future = datetime.datetime(2018, 8, 12, 00, 00, 00, 00000)today &gt; yesterdaywhile future &gt; today: time.sleep(1)#timedelta表示一段时间#周，时，分，秒，毫秒，微秒period = datetime.timedelta(days=7, hours=6, minutes=20, seconds=55)str(period)#'7 days, 6:20:55' datetime.datetime.strftime()将datetime对象转换为字符串datetime.datetime.strptime()将字符串转换为datetime对象格式栗子: %Y: 2018 %y: 18 %m: 07 %B: July %b: Jul %d: 一月中的第几天 %j: 一年中的第几天 %w: 一周中的第几天(0-6) %A: Thursday %a: Thu %H: 14(00-23) %I: 2(0-12) %M: 分(00-59) %S: 秒(00-59) %p: AM/PM 12345datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')#'2018-07-12 14:11:20'datetime.datetime.strptime(2018-07-12 14:11:20', '%Y-%m-%d %H:%M:%S')#datetime.datetime(2018, 7, 12, 14, 11, 20) calendarcalendar，日历相关函数。 collectionscollections，容器数据类型。 collections.abccollections.abc，容器的抽象基类 heapqheapq，堆队列算法。 bisectbisect，数组二等分算法。 arrayarray模块，有效的数值数组。它提供了一个array()对象，就像一个只存储同质数据并将其存储更紧凑的列表。 weakrefweakref，弱引用。weakref模块提供了用于跟踪对象而不创建参考的工具。当不再需要该对象时，它将自动从弱参考表中移除，并为弱参考对象触发回调。 Python支持自动内存管理，内存在最后一次被删除后不久就被释放。 copycopy，浅层和深层操作。 pprintpprint模块，漂亮打印。 12345678&gt;&gt;&gt; import pprint&gt;&gt;&gt; t =[[[['black', 'cyan'], 'white', ['green', 'red']], [['magenta','yellow'], 'blue']]]&gt;&gt;&gt; pprint.pprint(t, width=30)[[[['black', 'cyan'], 'white', ['green', 'red']], [['magenta', 'yellow'], 'blue']]] reprlibreprlib模块，提供repr自定义显示 enumenum，支持枚举。 数字和数学numbersnumbers，数字抽象基类。 round按指定精度四舍五入一个浮点数。 12round(1.23456, 4)#1.236 mathmath模块，数学函数。 12345&gt;&gt;&gt; import math&gt;&gt;&gt; math.sin(math.pi / 2)1.0&gt;&gt;&gt; math.log(256, 2)8.0 cmathcmath，复数数学函数。 decimaldecimal，十进制定点和浮点运算。 fractionsfractions，有理数。 randomrandom，生成伪随机数。 123456789&gt;&gt;&gt; import random&gt;&gt;&gt; random.choice(['a', 'b', 'c'])'a'&gt;&gt;&gt; random.sample(range(10), 2)[2, 6]&gt;&gt;&gt; random.random()0.9714711378164909&gt;&gt;&gt; random.randrange(10)5 statisticsstatistics模块，数学统计函数。计算基本的统计属性： 平均数(mean) 中位数(median) 方差(variance) 12345678&gt;&gt;&gt; import statistics&gt;&gt;&gt; num = [1, 2, 3, 4, 5]&gt;&gt;&gt; statistics.mean(num)3&gt;&gt;&gt; statistics.median(num)3&gt;&gt;&gt; statistics.variance(num)2.5 函数式编程模块本章模块提供了支持函数式编程风格的函数和类，以及可调用函数的一般操作。 itertoolsitertools，为高校循环创建迭代器。 functoolsfunctools，可调用对象的高阶函数和操作 operatoroperator，作为函数的标准操作符 文件和目录本章介绍的模块处理磁盘文件和目录。 pathlibpathlib，面向对象的文件系统路径此模块提供了代表文件系统路径的类，其语义适用于不同的操作系统。 os.pathos.path，通用路径名操作该模块在路径名上实现了一些有用的功能。 fileinputfileinput，迭代来自多个输入流的行该模块实现了从一个帮助类和函数，可在标准输入或文件列表上快速编写循环。 statstat，解释stat()结果此模块定义用于解释os.stat(),os.fstat(),os.lstat()的结果的常量和函数。 filecmpfilecmp，文件和目录比较此模块定义了比较文件和目录的函数，以及各种可选的时间和权衡。 tempfiletempfile，生成临时文件和目录此模块创建临时文件和目录。 globglob，Unix样式路径名称模式扩展此模块根据Unix shell使用的规则查找与指定模式匹配的所有路径名，结果以任意顺序返回。 fnmatchfnmatch，Unix文件名模式匹配此模块提供了对Unix shell风格的通配符的支持，它与正则表达式不同。 通配符: * ? [seq] [!seq] linecachelinecache，随机访问文本行此模块允许从Python源文件中获取任意行，同时尝试使用缓存进行内部优化，这是一种从单个文件中读取多行的常见情况。 shutilshutil，高级文件操作此模块提供了许多关于文件和文件集合的高级操作。 目录和文件操作 copytree rmtree 归档操作 12345&gt;&gt;&gt; shutil.copyfile('/tmp/1.txt', '/tmp/111.txt')'/tmp/111.txt'&gt;&gt;&gt; shutil.move('/tmp/today', '/tmp/TODAY')'/tmp/TODAY globglob模块，从通配符中搜索创建文件列表 123&gt;&gt;&gt; import glob&gt;&gt;&gt; glob.glob('/tmp/*.txt')['/tmp/1.txt', '/tmp/2.txt', '/tmp/111.txt'] 数据持久化本章介绍的模块支持将Python数据持久化存储到磁盘上。 picklepickle，Python对象序列化此模块用于实现序列化(serializing)和反序列化Python对象结构的二进制协议。 copyregcopyreg，注册pickle支持函数该模块提供了一种定义胭脂(pickle)特定对象时使用的函数方法。 shelveshelve，Python对象持久化shelf是一个持久的，类似字典的对象。 marshalmarshal，内部Python对象序列化此模块包含了可以以二进制格式读写Python值得函数。 dbmdbm，到Unix数据库的接口dbm是DBM数据库变体的通用接口。 sqlite3sqlite3，SQLite数据库的DB-API 2.0接口SQLite是一个C库，它提供了一个轻量级的基于磁盘的数据库，它不需要单独的服务器进程，并允许使用SQL查询语言的非标准变体访问数据库。 数据压缩和归档本章介绍的模块，支持使用zlib, gzip, bzip2, lzma算法进行数据压缩，以及创建zip和tar格式的归档文件。 zlibzlib，兼容gzip的压缩对于需要数据压缩的应用程序，此模块中的功能允许使用zlib库进行压缩(compression)和解压缩(decompression)。 gzipgzip，支持gzip文件此模块提供了一个简单的接口来压缩和解压缩文件，就行GNU程序gzip和gunzip一样。 bz2bz2，支持bz2压缩该模块提供了一个全面的接口，用于使用bzip2压缩算法进行压缩和解压缩数据。 lzmalzma，使用lzma算法进行压缩该模块提供了类和函数，用于使用lzma进行压缩和解压缩数据。 zipfilezipfile，使用zip归档zip文件格式是一个常用的归档和压缩标准。此模块提供了工具，用于创建，读写，追加和列出zip文件的工具。 tarfiletarfile，读写tar归档文件该模块可读写tar归档文件，包括使用gzip，bz2和lzma压缩。 文件格式本章描述的模块，解析各种各样的文件格式，不包含标记语言和e-mail。 csvcsv，读写CSV文件 所谓的CSV(comma separated values)逗号分隔值，它是一种简化的电子表格，保存为纯文本文件。是电子表格和数据库最常用的导入和导出格式。该模块实现了以CSV格式读写表格数据。 CSV文件很简单，缺少了Excel表格的许多功能： 值没有类型，都是字符串 没有字体大小或颜色 没有多个工作表 不能指定单元格的宽度和高度 不能合并单元格 不能签入图像和图标 1234567891011import csvfile = open(&apos;/tmp/test.csv&apos;)reader = csv.reader(file)data = list(reder)#写file = open(&apos;/tmp/test.csv&apos;, &apos;w&apos;, newline=&apos;&apos;)writer = csv.writer(file)writer.writerow(&apos;[1, 11, 111]&apos;)file.close() configparserconfigparser，配置文件解析器此模块提供了ConfigParser类，它实现了一种基本配置，你可以使用它来编写可由最终用户轻松定制的Python程序。 netrcnetrc文件处理netrc类解析和封装Unix FTP程序和其它FTP客户端使用的netrc文件格式。 xdrlibxdrlib，编码(encode)和解码(decode)XDR数据该模块支持外部数据表示标准(External Data Representation Standard)。此模块定义了两个类，一个将变量打包(packing)到XDR，另一个从XDR中解包(unpack)。 加密服务本章描述的模块，实现了各种加密(cryptographic)算法 hashlibhashlib，安全散列和消息摘要(digest)该模块为许多不同安全散列和消息摘要算法实现了通用接口。 SHA1 SHA224 SHA256 SHA384 MD5 hmachmac，用于消息认证的键控散列 操作系统接口本章介绍的模块，提供了操作系统功能的接口。 osos，各种操作系统接口该模块为使用操作系统相关的功能提供了一种便携方式。 文件名，命令行参数，环境变量 进程参数 文件对象创建 文件描述符操作 文件和目录的Linux扩展属性 进程管理 调度程序的接口 各种各样的系统信息 各种各样的功能 12345678&gt;&gt;&gt; import os&gt;&gt;&gt; os.getcwd()'/home/zhang'&gt;&gt;&gt; os.chdir('/tmp')#在shell中运行命令&gt;&gt;&gt; os.system('mkdir /tmp/today')0 ioio，流处理的核心工具该模块提供了Python用于处理各种类型I/O的主要工具。 text i/o binary i/o raw i/o timetime，访问和转换时间此模块提供了各种与时间相关的函数 argparseargparse，解析命令行选项、参数和子命令该模块可以轻松编写用户友好的命令行接口。 getoptgetopt，用于命令行选项的C风格解析器该模块帮助脚本解析sys.argv中的命令行参数。 logginglogging，Python的日志工具。该模块定义了函数和类，为应用程序和库实现灵活事件记录系统。 log level: DEBUG最低级别。用于小细节，通常只有在诊断问题时，才需要关心这些信息。 INFO用于记录程序中的一般事件的信息。 WARNING用于表示可能的问题 ERROR用于记录错误 CRITICAL最高级别，用于表示致命的错误 日志级别是一种建议。归根到底，还是由你来决定日志消息属于哪一种类型。 12345678910111213141516import logginglogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(lineno)d - %(message)s')logging.debug('Debugging information')logging.info('Informational message')logging.warning('Warning:config file %s not found', 'server.conf')logging.error('Error occurred')logging.critical('Critical error -- shutting down')#输出2018-07-10 14:50:13,060 - INFO - 6 - Informational message2018-07-10 14:50:13,061 - WARNING - 7 - Warning:config file server.conf not found2018-07-10 14:50:13,061 - ERROR - 8 - Error occurred2018-07-10 14:50:13,061 - CRITICAL - 9 - Critical error -- shutting down 日志格式: 12345678910111213141516| %(name)s Name of the logger (logging channel)| %(levelno)s Numeric logging level for the message (DEBUG, INFO, WARNING, ERROR, CRITICAL)| %(levelname)s Text logging level for the message (&quot;DEBUG&quot;, &quot;INFO&quot;, &quot;WARNING&quot;, &quot;ERROR&quot;, &quot;CRITICAL&quot;)| %(pathname)s Full pathname of the source file where the logging call was issued (if available)| %(filename)s Filename portion of pathname| %(module)s Module (name portion of filename)| %(lineno)d Source line number where the logging call was issued (if available)| %(funcName)s Function name| %(created)f Time when the LogRecord was created (time.time() return value)| %(asctime)s Textual time when the LogRecord was created| %(msecs)d Millisecond portion of the creation time| %(relativeCreated)d Time in milliseconds when the LogRecord was created, relative to the time the logging module was loaded (typically at application startup time)| %(thread)d Thread ID (if available)| %(threadName)s Thread name (if available)| %(process)d Process ID (if available)| %(message)s The result of record.getMessage(), computed just as the record is emitted logging.configlogging.config，日志配置 logging.handlerslogging.handlers，日志处理程序 getpassgetpass，便携式密码输入 cursescurses，字符单元显示的终端处理 curses.textpadcurses.textpad，用于curses程序的文本输入小部件此模块提供了一个Textbox类，他在curses窗口中处理基本的文本编辑。 curses.asciicurses.ascii，用于ASCII字符的使用程序该模块为ASCII字符提供名称常量，并为各种ASCII字符类中的成员测试函数。 curses.panelcurses.panel，curses的面板堆栈扩展面板是具有深度附加功能的窗口，因此它可堆叠在彼此的顶部，并且只显示每个窗口的可见部分。 platformplatform，访问底层平台的识别数据 errnoerrno，标准的errno系统符号 ctypesctypes，一个Python的外部函数库该模块提供了C兼容的数据类型，并允许在DLL或共享中调用函数。 并发执行本章介绍的模块，为并发执行(consurrent execution)代码提供了支持。 这里需要理解一些基本知识: 并发：并发的关键是处理多个任务，不一定要同时，可理解为交替做不同事情； 并行：并行的关键是同时处理多个任务，可理解为同时做不同事情； 进程：进程是操作系统资源分配的最小单元，每个进程拥有独立的内存单元； 线程：线程是程序执行的最小单元，是系统独立调度和分配CPU（独立运行）的基本单位。进程内的线程共享资源。进程内的线程通信比进程之间的通信更快更有效，因为共享资源； 多进程：同时执行多个进程——同时运行wecat, qq 多线程：同时执行多个线程——浏览器边看视频、边听歌、边下载 threadingthreading，基于线程的并行此模块在较低级别的_thread模块之上构建较高级别的线程接口。 如果多线程同时读写变量，导致互相干扰，就会发生所谓的并发问题。 1234567891011121314import time, threadingprint('thread start.')def wakeup(times): time.sleep(5) n = times for i in range(n): print('Wake Up!')thread01 = threading.Thread(target=wakeup, args=[3])#thread01 = threading.Thread(target=wakeup, kwargs=&#123;'times': 3&#125;)thread01.start()print('End of program!') 使用queue队列通信-经典的生产者和消费者模型一个负责生成，一个负责消费，所生成的产品存放在queue里，实现了不同线程间沟通 1234567891011121314151617181920212223242526272829303132333435363738# Producerclass Producer(threading.Thread): def __init__(self, name, queue): threading.Thread.__init__(self, name=name) self.queue = queue def run(self): for i in range(1, 5): print('&#123;&#125; 生产 &#123;&#125; 到队列'.format(self.getName(), i)) self.queue.put(i) time.sleep(random.randrange(10) / 5) print('&#123;&#125; 完成!'.format(self.getName()))# Consumerclass Consumer(threading.Thread): def __init__(self, name, queue): threading.Thread.__init__(self, name=name) self.queue = queue def run(self): for i in range(1, 5): val = self.queue.get() print('&#123;&#125; 消费队列中的 &#123;&#125;'.format(self.getName(), val)) time.sleep(random.randrange(10)) print('&#123;&#125; 完成!'.format(self.getName()))def main(): queue = Queue() producer = Producer('Producer', queue) consumer = Consumer('Consumer', queue) producer.start() consumer.start() producer.join() consumer.join() print('所有线程已完成!')if __name__ == "__main__": main() multiprocessing参考: https://zhuanlan.zhihu.com/p/46368084 multiprocessing，基于进程的并行它是一个使用类似线程模块的API来支持产生进程的包。 新创建的进程与进程的切换都是要耗资源的，所以平时工作中进程数不能开太大 同时可以运行的进程数一般受制于CPU的核数 除了使用Process方法，我们还可以使用Pool类创建多进程 12345678910111213141516171819202122232425262728293031323334353637383940414243'''Learn multiprocess Learn multiprocess of python.'''import timeimport osfrom multiprocessing import Process"""# singe processdef long_time_task(): print('当前进程: &#123;&#125;'.format(os.getpid())) time.sleep(2) print('结果: &#123;&#125;'.format(8 ** 20))if __name__ == "__main__": print('当前母进程: &#123;&#125;'.format(os.getpid())) start = time.time() for i in range(2): long_time_task() end = time.time() print('用时: &#123;&#125;s'.format((end - start)))"""# multiprocessdef long_time_task(i): print("子进程: &#123;&#125; - 任务&#123;&#125;".format(os.getpid(), i)) time.sleep(2) print("结果: &#123;&#125;".format(8 ** 20))if __name__ == '__main__': print('当前母进程: &#123;&#125;'.format(os.getpid())) start = time.time() p1 = Process(target=long_time_task, args=(1,)) p2 = Process(target=long_time_task, args=(2,)) print('等待所有子进程完成!') p1.start() p2.start() p1.join() p2.join() end = time.time() 多进程间的数据共享与通信通常，进程之间是相互独立的，每个进程都有独立的内存。通过共享内存(nmap模块)，进程之间可以共享对象，使多个进程可以访问同一个变量(地址相同，变量名可能不同)。多进程共享资源必然会导致进程间相互竞争，所以应该尽最大可能防止使用共享状态。还有一种方式就是使用队列queue来实现不同进程间的通信或数据共享，这一点和多线程编程类似。 1234567891011121314151617181920212223242526272829from multiprocessing import Process, Queueimport os, time, random# share data with multiprocess# 2 process, one for write, one for read. Implemented sharing a queuedef write(q): print('进程写: &#123;&#125;'.format(os.getpid())) for value in ['A', 'B', 'C']: print('将 &#123;&#125; 放入队列...'.format(value)) q.put(value) time.sleep(random.random())def read(q): print('进程读: &#123;&#125;'.format(os.getpid())) while True: value = q.get(True) print('从队列获取 &#123;&#125;'.format(value))if __name__ == '__main__': q = Queue() pw = Process(target=write, args=(q,)) pr = Process(target=read, args=(q,)) pw.start() pr.start() # 等待pw结束 pw.join() # pr进程里是死循环，无法等待其结束，只能强行终止 pr.terminate() concurrentconcurrent包中只有一个模块concurrent.futures，启动并行任务该模块为异步(asynchronously)执行可调用提供了一个高级的接口。 subprocesssubprocess，子进程管理该模块允许你生成新的进程，连接到它们的input/output/error pipes，并获得它们返回的代码。每个进程可以有多个线程。 1234567891011import subprocess#在Python脚本中启动一个外部程序subprocess.Popen(‘/tmp/hello.py’)#hello world!#用Popen传递参数，这需要传递一个列表subprocess.Popen([‘/tmp/hello.py’, 'argv1'])#它还有许多参数help(subprocess.Popen) schedsched，事件调度程序(scheduler)该模块定义了一个实现通用时间调度器的类。 queuequeue，一个同步队列类该模块实现了多生产者、多消费者队列。当信息必须在多线程之间安全地交换时，它在线程编程中特别有用。 进程间的通信和网络本章介绍的模块，提供了不同进程进行通信的机制。 socketsocket，低级网络接口该模块提供了对BSD socket的访问。 Socket是网络编程的一个抽象概念。通常我们用一个Socket表示“打开了一个网络链接”，而打开一个Socket需要知道目标计算机的IP地址和端口号，再指定协议类型即可。tcp需要建立连接，udp不需要建立连接，因此udp每次需要指定发送地址。 socket类型： socket.AF_UNIX本机通信 socket.AF_INET服务器间的网络通信 socket.AF_INET6IPv6的服务器间的通信 socket.SOCK_STREAM基于TCP的流式socket通信 socket.SOCK_DGRAM基于UDP数据包的socket通信 socket.SOCK_RAM原始套接字 socket.SOCK_SEQPACKET可靠的连续数据包服务 123456789101112131415161718192021#服务端socket函数：bind() 在AF_INET下，以tuple(host, port)的方式传入，如s.bind((host, port))listen() 可设置挂起的最大连接数accept() 接收tcp连接并返回(conn, address), conn是新的套接字对象, address是客户端地址#客户端socket函数：connect()connect_ex()#公共socket函数#tcprecv() 接受TCP套接字的数据，数据以字符串形式返回，buffsize指定要接受的最大数据量send()sendall() 完整发送tcp数据#udprecvfrom()sendto()close() socket编程思想： 12345678910111213#Server-side1. 创建socket2. 监听3. 接收client请求4. 接收C端数据5. 关闭头街子#Client-side1. 创建socket2. 连接到S端3. 发送数据4. 关闭套接字 注意在Python3.x中，byte strings 和 unicodestrings是两种不同的类型，相互之间需要进行decode()和encode()send()和recv()都是bytes类型，需要与str类型进行转换。 1234567891011121314151617181920212223242526272829303132333435363738394041424344#tcp#S端import sockethost = 'localhost'port = 5678bf = 1024maxConn = 3tcpS = socket.socket(socket.AF_INET, socket.SOCK_STREAM)tcpS.bind((host, port))tcpS.listen(maxConn)print('Server start at &#123;host&#125;:&#123;port&#125;'.format(host=host, port=port))print('Waiting for connection...')while True: conn, addr = tcpS.accept() print('Connected by: &#123;addr&#125;'.format(addr=addr)) while True: data = conn.recv(bf) print(data.decode('utf-8')) conn.send('server received message.'.encode('utf-8')) tcpS.close()#C端import sockethost = 'localhost'port = 5678bf = 1024tcpC = socket.socket(socket.AF_INET, socket.SOCK_STREAM)tcpC.connect((host, port))while True: msg = input('Please input message: \n') tcpC.send(msg.encode('utf-8')) data = tcpC.recv(bf) print(data.decode('utf-8')) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#udp#S端from pymongo import MongoClientimport socket, datetimehost = 'localhost'port = 5679bf = 1024mongoPort = 27017mongoUser = 'zhang'mongoPw = 'password'mongoDb = 'zhang'mongoColl = 'udpS'udpS = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)udpS.bind((host, port))collection = MongoClient(host=host, port=mongoPort, \ username=mongoUser, password=mongoPw).zhang.udpSprint('udp socket on &#123;host&#125;:&#123;port&#125;...'.format(host=host, port=port))while True: data, addr = udpS.recvfrom(bf) print('Received from &#123;addr&#125;'.format(addr=addr)) print(data.decode('utf-8')) print('\n') msg = 'Server has recived!\n' udpS.sendto(msg.encode('utf-8'), addr) dateTime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') post = &#123; 'author': 'Server', 'date': dateTime, 'message': data.decode('utf-8') &#125; collection.insert_one(post)#C端from pymongo import MongoClientimport socket, datetimehost = 'localhost'port = 5679bf = 1024mongoPort = 27017mongoUser = 'zhang'mongoPw = 'password'mongoDb = 'zhang'mongoColl = 'udpC'udpC = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)collection = MongoClient(host=host, port=mongoPort, \ username=mongoUser, password=mongoPw).zhang.udpCwhile True: msg = str(input('Please input message: \n')) udpC.sendto(msg.encode('utf-8'), (host, port)) data = udpC.recv(bf) print(data.decode('utf-8')) dateTime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') post = &#123; 'author': 'Client', 'date': dateTime, 'message': data.decode('utf-8') collection.insert_one(post) udpC.close() sslssl，套接字对象的TLS/SSL封装此模块提供了对网络套接字的传输层安全(通常称为安全套接字层)的加密和对等身份验证功能。 selectselect，等待I/O完成该模块提供对大多数操作系统中可用的select()和poll()函数的访问。 selectorselector，高级I/O复用该模块基于select()模块构建，有序高级和高效的I/O复用。 asyncioasyncio，异步I/O，事件循环，协同程序和任务该模块提供了使用协同程序编写单线程并发代码的基础结构，在套接字和其它资源上多路复用I/O访问，运行网络客户端和服务器以及其它相关基元。 asyncoreasyncore，异步套接字处理器该模块为编写异步套接字服务(客户端和服务端)提供了基本的基础结构。 asynchatasynchat，异步套接字命令/响应处理器该模块构建在asyncore之上，简化了异步客户端和服务端，并更容易处理其元素被任何字符串终止和长度可变的协议。 signalsignal，为异步事件设置处理器该模块提供了在Python中使用信号处理程序的机制。 mmapmmap，内存映射文件支持内存映射文件对象的行为与bytearray和文件对象类似。 网络数据处理本章介绍的模块，支持处理常用网络数据格式。 emailemail，一个email和MIME处理包该包是用于管理电子邮件信息的库，包含MIME和其它基于RFC 2822的消息文档。 MIME(Multipurpose Internet Mail Extensions)多用途互联网邮件扩展，是一种标准化的方式来标识文档的性质和格式。浏览器通常使用MIME类型(而不是文件扩展名)来确定如何处理文档。 栗子： 12345678910111213type/subtypetext/plaintext/htmlimage/jpegimage/pngaudio/mpegaudio/oggaudio/*video/mp4application/octet-stream… email.message表示一个电子邮件信息 email.parser解析电子邮件信息 email.generator生成MIME文档 email.policy政策对象 email.headerregistry自定义头对象 email.contentmanager管理MIME内容 email.mime从抓挠中创建电子邮件和MIME对象。 email.headerInternationalized headers email.charset表示字符集 email.encoders编码器 email.errors异常和缺陷类 email.utils各种各样的功能 email.iterators迭代器 jsonjson，JSON编码器和解码器JSON(JavaScript Object Notation)，是一个受JavaScript对象语法启发的轻量级的数据交换格式。 json只能包含如下Python数据类型的值： 字符串 整型 浮点数 布尔型 列表 字典 NoneType 123456import jsonJSONDATA = &apos;&#123;&quot;name&quot;: &quot;zhang&quot;, &quot;age&quot;: 21, &quot;likeFootball&quot;: true&#125;loadData = json.loads(JSONDATA)dumpData = json.dumps(jsonData) mailcapmailcap，mailcap文件处理mailcap文件用于配置感知MIME的应用程序(如邮件阅读器和Web浏览器)，如何对具有不同MIME类型的文件做出反应。 mailboxmailbox，以各种格式操作邮箱该模块定义了两个类: Mailbox和Message，用于访问和操作磁盘邮箱及其包含的邮件。 mimetypesmimetypes，将文件名映射到MIME类型该模块在文件名或URL和MIME类型之间进行转换。 base64base64，base16、base32，base64，base85数据编码该模块提供了将二进制数据编码为可打印的ASCII字符，并将这些编码解码回二进制数据的函数。 binhexbinhex，编码和解码binhex4文件 binasciibinascii，在二进制和ASCII之间进行转换该模块包含了许多方法，用于转换在二进制和各种ASCII编码的二进制表示之进行转换的方法。 quopriquopri，编码和解码MIME引用打印数据 uuuu，编码和解码uuencode文件该模块以uuencode格式对文件进行编码和解码，允许任意二进制数据仅通过ASCII连接进行传输。 结构化标记处理工具Python支持用以处理各种形式的结构化数据标记的模块。 标准通用标记语言，SGML() 超文本标记语言，HTML 扩展标记语言，XML htmlhtml，支持超文本标记语言该模块定义了用以操作HTML的实用程序。 html.parserhtml.parser，简单HTML和XHTML解析器该模块提供了一个类，用来解析HTML和XHTML格式的文本文件的基础。 html.entitieshtml.entities，HTML一般实体的定义 XML处理模块用于处理XML的Python接口被分组到xml包 网络协议本章介绍的模块，实现了网络协议并支持相关技术。 webbrowserwebbrowser - Interfaces for launching and remotely controlling Web browsers.webbrowser，便利的web浏览器控制器该模块提供了一个高级interface，允许向用户显示基于web的文档。 123import webbrowserwebbrowser.open(&apos;https://www.baidu.com&apos;) cgicgi，通用网关接口支持CGI 脚本的支持模块；该模块定义了许多用Python编写的CGI脚本的实用功能。 cgitbcgitb，CGI脚本的追溯管理器此模块为Python脚本提供了一个特殊的异常处理程序。 wsgirefwsgiref，WSGI功能和参考实现Web服务器网关接口(WSGI)，是Web服务器软件和Web应用程序(Python编写)之间的标准接口。拥有标准接口可以轻松使用支持WSGI和多个不同Web服务器的应用程序。 urllburllib模块，处理URL urllib.requesturllib.request模块，用于打开URL的可扩展库该模块定义了函数和类，用于在复杂的世界中打开URL——基本和身份认证，重定向，cookie等 urllib.responseurllib.response，响应类该模块定义了向接口这样的最小文件的函数和类。 urllib.parseurllib.parse，将URL解析为组件此模块定义了一个标准接口，用于在组件中分解统一资源定位符(URL)字符串，将组件重新组合为URL，并将相对URL转换为基本URL的绝对URL。 urlllib.errorurllib.error，由urllib.request引起的异常类该模块定义了由urllib.request引发的异常类。 urllib.robotparserurllib.robotparser，解析robot.txt此模块提供了一个RobotFileParser类，它回答了有关特定用户代理是否可以在发布robots.txt文件的Web站点上获取URL的问题。 httphttp，HTTP模块 http.clienthttp.client，HTTP协议客户端该模块定义了实现HTTP和HTTPS协议客户端的类。 ftplibftplib，FTP协议客户端此模块定义了FTP类和一些相关项。FTP类实现了FTP协议的客户端。 poplibpoplib，POP3协议客户端此模块定义了POP3类，它封装了一个到POP3服务器的连接，并实现了该协议。 imaplibimaplib，IMAP4协议客户端此模块定义了三个类，封装一个到IMAP服务器的连接，并实现IAP4客户端协议的大部分子集。 nntplibnntplib，NNTP协议客户端此模块定义了NNTP类，它实现网络新闻传输协议(NNTP)客户端。 smtplibsmtplib模块，SMTP协议客户端此模块定义了一个SMTP客户端会话对象，可使用SMTP守护进程发送邮件给任一互联网计算机。 12345678910111213import smtplib#send = smtplib.STMP('smtp.example.com', port=xxx)send = smtplib.SMTP_SSL(‘smpt.exmail.qq.com’, 465)send.helo()#(250, b'smtp.qq.com')#登录需要提前设置邮箱授权码，使用授权码作为密码登录send.login(user, passed)send.sendmail(from, to, message)send.quti() smtpdsmtpd，SMTP服务器该模块提供了几个类来实现SMTP服务器。 telnetlibtelnetlib，Telnet客户端此模块提供了一个telnet类，用于执行Telnet协议。 uuiduuid，UUID对象此模块提供了不可修改的UUID对象和uuid[1-5]函数。 socketserversocketserver，一个网络服务器的框架此模块简化了编写网络服务器的任务。 http.serverhttp.server，HTTP服务器此模块定义了类，用于实现HTTP服务器。 http.cookiehttp.cookie，HTTP状态管理此模块定义了类，用于抽象cookie概念(HTTP状态管理机制)。 http.cookiejarhttp.cookiejar，HTTP客户端的cookie处理此模块定义了类，用于自动处理HTTPcookie。 xmlrpcxmlrpc，XMLRPC服务器和客户端模块XML-RPC是一种远程过程调用方法，它使用通过HTTP传递的XML传输。 xmlrpc.clientxmlrpc.client，XML-RPC客户端访问 xmlrpc.serverxmlrpc.server，基本的XML-RPC服务器 ipaddressipaddress，IPv4/IPv6操作库此模块提供了创建、修改和操作IPv4和IPv6和网络的功能。 多媒体服务本章介绍的模块，实现了用于多媒体应用的各种算法和接口。 audioopaudioop，操作原始音频数据此模块包含一些对声音片段有用的操作。 aifcaifc，读写AIFF和AIFC文件此模块提供了对读写AIFF和AIFC文件的支持。 AIFF is Audio Interchange File Format 一种用于将数字音频样本存储在文件中的格式 AIFC是一种更新的格式，包括压缩音频数据 sunausunau，读写Sun AU文件此模块为Sun AU声音格式提供了一个便利的接口。 wavewave，读写WAV文件此模块为WAV声音格式提供了一个便利的接口。 chunkchunk，读取IFF分块数据此模块为读取使用EA IFF块的文件提供了接口。 colorsyscolorsys，颜色系统之家的转换此模块定义了计算机显示器RGB和其它三个坐标系统：YIQ, HLS, HSV中使用的RGB颜色空间中表示的颜色之间的颜色值的双向转换。 imghdrimghdr，确定图像类型此模块确定文件或字节流中包含的图像类型。 sndhdrsndhdr，确定声音文件类型此模块提供了实用功能，视图确定文件中的声音数据类型。 ossaudiodevossaudiodev，访问与OSS兼容的音频设备此模块允许你访问OSS(open sound system)音频接口。OSS是Linux和FreeBSD的标准音频接口。 语言环境本章介绍的模块，可帮助你编写独立于语言和语言环境的软件。 gettextgettext，多语言国际化服务此模块为你的Python模块和应用程序提供了国际化和本地化服务。 localelocale语言环境模块，打开对POSIX语言环境数据库和功能的访问。 程序框架本章介绍的模块，是基本上决定程序结构的框架。 turtleturtle，乌龟图形乌龟图形是向孩子们介绍编程的一种流行方式。 cmdcmd，支持面向行的命令解释器此类为编写面向行的命令解释器提供了一个简单的框架。 shlexshlex，简单的词法分析此类可以容易地编写词法分析器，以获得类似Unix shell的简单语法。 带有Tk的图形用户界面Tk/Tcl是Python的一部分。它提供了一个强大且独立于平台的窗口工具包，可供Python程序员使用的tkinter包。 Tcl(Tool Command Language)，是一种脚本语言 Tk，是基于Tcl的图形界面开发工具箱 tkintertkinter，与Tcl/Tk的Python接口此包是到Tk GUI工具箱的标准Python接口。 tkinter.ttktkinter.ttk，Tk主题小部件此模块提供了对Tk主题小部件集的访问。 tkinter.tixtkinter，Tk扩展小工具此模块提供了一组额外的小工具。 tkinter.scrolledtext滚动(scrolled)文本工具此模块提供了一个相同名称的类，它实现了基本的文本小部件，具有一个垂直滚动条，用于执行正确的事情。 IDELIDEL是Python的集成开发和学习环境。 其它GUI包 PyGObject PyGTK PyQt PySide wxPython 开发工具本章介绍的模块可帮助你你编写软件。 开发高质量软件的一种方法是在开发过程中为每个函数编写测试，并在开发过程中频繁运行这些测试。 typingtyping，支持类型提示此模块支持PEP 484指定的类型提示。 pydocpydoc，文档生成器和在线帮助系统此模块从Python模块自动生成文档，文档可作为控制台上的文本页面呈现，提供个Web浏览器或保存到HTML文件。 doctestdoctest模块，测试交互式Python示例此模块搜索类似于交互式Python会话的文本片段，然后执行这些会话以验证它们是否完全安装所示工作。 unittestunittest，单元测试框架 2to32to3，自动翻译Python2-3代码获取Python2源代码并应用一系列修复程序将其转换为有效的Python3代码。 testtest，用于Python的回归测试包此包包含了Python的所有回归测试。 test.supporttest.support，Python测试套件功能 调试和分析 调试器(Debugger)使你能遍历代码，分析堆栈并设置断点 分析器(Profiler)运行代码并给出执行时间的详细分类，使你识别程序中的瓶颈 bdbbdb，调试器框架此模块处理基本的调试器功能。 faulthandlerfaulthandler，转储Python回溯(traceback) pdbpdb，Python调试器此模块为Python程序定义了一个交互式源代码调试器。 Python分析器cProfile和profile提供了Python程序的确定性分析。 timeittimeit模块，测量小代码片段的执行时间此模块提供了一个简单的方法类计算一小段Python代码的时间。 123&gt;&gt;&gt; from timeit import Timer&gt;&gt;&gt; Timer('a,b = b,a', 'a=1; b=2').timeit()0.020318730967119336 tracetrace，追踪Python语句的执行此模块允许你追踪程序执行，生成带注释的语句覆盖列表，打印调用关系和在程序运行期间执行的函数列表。 tracemalloctracemalloc，追踪内存分配此模块是一个追踪由Python分配的内存块的调试工具。 软件打包和分发这些库可帮助你发布和安装Python软件。这些模块被设计来与PyPi结合使用，但它们也可以与本地索引服务器一起使用，或根本不需要任何索引服务器。 distutilsdistutils，构建和安装Python模块此软件包为构建和安装其它模块到Python提供支持。 ensurepipensurepip，引导pip安装程序此软件包支持将pip安装程序引导到现有的Python或虚拟环境中。 venvvenv，创建虚拟环境此模块为创建轻量虚拟环境提供支持，可选地域系统目录隔离。 zipappzipapp，管理可执行的python zip归档Python提供了管理创建包含Python代码的zip文件的工具。 Python服务组件本章介绍的模块，提供了与Python解释器及其与环境交互相关的各种服务。 syssys模块，系统特定的参数和功能此模块提供了对解释器使用或维护的一些变量以及与解释器交互的函数非访问。 命令行参数 12import sysprint(sys.argv) 错误输出重定向和程序终止(termination)sys模块还具有stdin, stdout, stderr属性。 12&gt;&gt;&gt; sys.stderr.write('Warning, log file not found starting a new one\n')Warning, log file not found starting a new one sysconfigsysconfig，提供对Python配置信息的访问此模块提供对Python配置信息的访问，如安装路径列表和当前平台相关的配置变量。 builtinsbuiltins，内建对象此模块提供了对Python所有内置标识符的直接访问。例如，builtins.open是内建函数open()的全名。 __main____main__，顶级脚本环境__main__是顶级代码执行的范围的名称。从标准输入、脚本或交互式提示读取时，模块的__name__设置为等于__main__ warningswarnings，警告控制警告信息通常在有用的情况下发出，以提醒用户程序中的某些条件，该条件不能保证引发异常并终止程序。Python程序员通过调用此模块中的warn()函数来发出警告。 contextlibcontextlib，with语句上下文实用程序此模块为涉及with语句的常见任务提供使用程序。 abcabc，抽象基类(Abstract Base Classes)此模块提供了在Python中定义抽象基类的基础结构。 atexitatexit，退出处理程序此模块定义了注册和注销清理函数的函数。 tracebacktraceback，打印或取回堆栈回溯该模块提供了一个标准接口，用来提取、格式化和打印Python程序的堆栈追踪。 __future____future__，未来的声明定义 gcgc，垃圾收集器接口(Garbage Collector interface)此模块为可选的垃圾收集器提供了一个接口。 inspectinspect，检查活对象(Inspect live objects)此模块提供了几个有用的功能来帮助获取有关活动对象的信息，如模块、类、函数、回溯、框架对象和代码对象。 sitesite，Site-specific configuration hook fpectlfpectl，浮点异常控制(Floating point exception control) 自定义Python解释器本章介绍的模块，允许编写类似于Python的交互式解释器接口。 codecode，解释器基本类此模块提供了一些工具，来实现Python的read-eval-print循环。 codeopcodeop，编译Python代码此模块提供了实用程序，用于模拟Python read-eval-print循环，像code模块中做的那样 导入模块本章介绍的模块，提供了导入其它Python模块和以自定义导入进程的hook的新方法。 zipimportzipimport，从zip归档文件导入模块此模块增加了从Zip格式的归档中导入Python模块和软件包的功能。通常不需要明确使用zipimport模块，内置导入机制将自动使用zip归档文件的路径(sys.path)。 pkgutilpkgutil，包扩展程序此模块为导入system提供实用程序，尤其是软件包的支持。 modulefindermodulefinder，查找脚本使用的模块此模块可用于确定脚本导入的模块集。 runpyrunpy，定位和执行Python模块此模块用于定位和运行Python模块，而不必先导入它们。 importlibimportlib，执行import此软件包有两个目的： 在Python源代码中提供import语句的实现(__import__函数) 实现import组件暴露在此软件包中，使用户更容易创建它们自己的定制对象参与导入过程 Python语言服务Python提供了许多模块来协助处理Python语言。包括： 标记 解析 语法分析 字节码反汇编 … parserparser，访问Python解析树此模块为python内部解析器和字节码编译器提供了一个接口。 astast，抽象语法树(Abstract Syntax Trees)此模块帮助Python应用程序处理Python抽象语法的树。 symtablesymtable，访问编译器的符号符号表由AST编译器在字节码生成之前生成。 symbolsymbol，用于Python解析的常量该模块提供了，表示解析树内部节点数值的常量。 tokentoken，与Python解析树一起使用的常量此模块提供了，表示解析树(终端令牌)的叶子节点数值的常量。 keywordkeyword，测试Python关键字此模块允许Python程序确定字符串是否为关键字。 tokenizetokenize，用于Python源代码的令牌器此模块为Python源代码提供了一个用Python实现的语言扫描器。 tabnannytabnanny，检查不明确的缩进(Detection of ambiguous indentation) pyclbrpyclbr，Python类浏览器支持此模块可用于，确定有关模块中定义的类、方法和顶级函数的一些限制信息。 py_compilepy_compile，编译Python源文件此模块提供了功能，从源文件生成字节码文件，以及当模块源文件作为脚本被调用时使用。 compileallcompileall，字节编译Python库此模块提供了实用功能来支持安装Python库。 disdis，用于Python字节码的反汇编器此模块支持通过反汇编来支持CPython字节码的分析。 pickletoolspickletools，pickle开发者的工具此模块包含了各种常量，涉及到pickle模块的细节，一些关于实现的冗长的评论，一些用于分析pickle数据的有用函数。 杂项服务本章介绍的模块，提供了在所有Python版本中可用的杂项(miscellaneous)服务。 formatterformatter，通用输出格式此模块支持两种接口定义，每种都有多种实现方式： 格式化接口 格式化接口所需的写入接口 Windows特定服务本章介绍的模块仅可在MS windows平台上可获取。 msilibmsillib，读写微软安装程序文件此模块支持创建Microsoft Installer (.msi) 文件。 msvcrtmsvcrt，MS VC++运行时的有用例程此函数可访问Windows平台上的一些有用功能。 winregwinreg，Windows注册表访问此模块将Windows注册表的API暴露给Python。 winsoundwinsound，Windows的声音播放接口此模块提供了对Windows平台提供的基本声音播放机器的访问。 Unix特定服务本章介绍的模块，提供了Unix操作系统(Unix-Like)特有的功能的接口。 posixposix，最基本的POSIX系统调用此模块提供了对由C标准和POSIX标准 标准化的操作系统功能的访问。 pwdpwd， The password database此模块提供了对Unix用户账户和密码数据库的访问。 1234import pwdpwd.getpwdnam('zhang')pwd.struct_passwd(pw_name='zhang', pw_passwd='x', pw_uid=1000, pw_gid=1000, pw_gecos='zhang', pw_dir='/home/zhang', pw_shell='/bin/bash') spwdspwd，The shadow password database此模块提供了对Unix shadow password database的访问。 grpgrp，The group database此模块提供了对Unix group database的访问。 cryptcrypt，Function to check Unix passwords此模块实现crypt(3)例程的接口，该例程是基于修改的DES算法的单向散列函数。 termiostermios，POSIX风格的tty控件此模块提供了一个接口，用于I/O控制的POSIX调用。 ttytty，终端控制函数此模块定义了将tty置入cbreak和raw模式的函数。 ptypty，伪(Pseudo)终端程序此模块定义了处理伪终端概念的操作： 启动另一个进程并以编程方式写入和读取其控制终端。 fcntlfcntl，The fcntl and ioctl system calls此模块对文件描述符执行文件控制和I/O控制。 pipespipes，shell pipelines的接口此模块定义了一个类来抽象管道的概念——从一个文件到另一个文件的一系列转换器。 resourceresource，资源使用信息此模块提供了测量和控制程序使用系统资源的基本机制。 syslogsyslog，Unix syslog library routines此模块为Unix系统日志库例程提供了一个接口。 第三方库基本上可将第三方库理解为开源库！ Awesome-Python: https://github.com/jobbole/awesome-python-cnPyPI: https://pypi.org/ 系统管理 sh Watchdog 数据库 PyMySQL pymongo redis PyMySQLPyMySQL：https://pypi.org/project/PyMySQL/ 首先创建数据库 1234567CREATE TABLE `users` ( `id` int(11) NOT NULL AUTO_INCREMENT, `email` varchar(255) COLLATE utf8_bin NOT NULL, `password` varchar(255) COLLATE utf8_bin NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_binAUTO_INCREMENT=1 ; 连接 1234567891011121314151617181920212223242526import pymysqlconnection = pymysql.connect( host='localhost', user='username', password='password', port=3306, db='DBname', charset='utf8', cursorclass=pymysql.cursors.DictCursor)try: with connection.cursor() as cursor: sql = "INSERT INTO `users` (`email`, `password`) VALUES (%s, %s)" cursor.execute(sql, ('webmaster@python.org', 'very-secret')) #commit to save connection.commit() with connection.cursor() as cursor: sql = "SELECT `id`, `password` FROM `users` WHERE `email`=%s" cursor.execute(sql, ('webmaster@python.org',)) result = cursor.fetchone() print(result)finally: connection.close() pyMongopyMongo Docs: https://api.mongodb.com/python/current/ pyMongo是一个用于使用MongoDB的工具的Python发行版，并且是从Python工作于MongoDB的推荐方式。 依赖 mongodb pyMongo 连接 1234567891011from pymongo import MongoClient#host and portclient = MongoClient('localhost', 27017)#url formatclient = MongoClient('mongodb://localhost:27017')#认证client = MongoClient(host='localhost', port=27017, username='user', password='pass') 获取数据库 12345db = client.$&#123;database&#125;#ordb = client['$&#123;database&#125;'] 获取集合 1234collection = db.$&#123;collection&#125;#orcollection = db['$&#123;collection&#125;'] 文档 123456789import datetimepost = &#123; '_id': 'post01', 'author': 'Zhang21', 'text': 'My first post!', 'tags': [ 'mongodb', 'python', 'pymongo' ], 'date': datetime.datetime.now()&#125; 插入文档 123456#新建集合$&#123;collection&#125; = db.posts$&#123;collection&#125;.insert_one(post)#已有集合collection.insert_one(post) 批量插入 123456789101112131415161718new_post = [ &#123; '_id': 'post02', 'author': 'Zhang02', 'text': '2nd post', 'tags': ['bulk', 'insert'], 'date': datetime.datetime.now() &#125;, &#123; '_id': 'post03', 'author': 'Zhang03', 'text': '3rd post', 'tags': ['bulk', 'insert'], 'date': datetime.datetime.now() &#125;]collection.insert_many(new_post) 获取文档 12345678910collection.find_one()collection.find_one(&#123; '_id': 'post01'&#125;)#orcollection.find_one(&#123;'author': 'Zhang21'&#125;)import pprintpprint.pprint(collection.find_one(&#123; '_id': 'post01'&#125;)) 查询多个文档 12345678910111213141516171819202122232425262728293031323334for post in collection.find(): pprint.pprint(post)&#123;'_id': 'post01', 'author': 'Zhang21', 'date': datetime.datetime(2018, 6, 14, 11, 13, 11, 372000), 'tags': ['mongodb', 'python', 'pymongo'], 'text': 'My first post!'&#125;&#123;'_id': 'post02', 'author': 'Zhang02', 'date': datetime.datetime(2018, 6, 14, 11, 34, 47, 93000), 'tags': ['bulk', 'insert'], 'text': '2nd post'&#125;&#123;'_id': 'post03', 'author': 'Zhang03', 'date': datetime.datetime(2018, 6, 14, 11, 34, 47, 93000), 'tags': ['bulk', 'insert'], 'text': '3rd post'&#125;#orfor post in collection.find(&#123;'tags': ['bulk', 'insert']&#125;): pprint.pprint(post)&#123;'_id': 'post02', 'author': 'Zhang02', 'date': datetime.datetime(2018, 6, 14, 11, 34, 47, 93000), 'tags': ['bulk', 'insert'], 'text': '2nd post'&#125;&#123;'_id': 'post03', 'author': 'Zhang03', 'date': datetime.datetime(2018, 6, 14, 11, 34, 47, 93000), 'tags': ['bulk', 'insert'], 'text': '3rd post'&#125; 删除文档 12345collection.delete_one(&#123;"_id" : "post01"&#125;)#删除多个collection.delete_many(&#123;"_id" : "post02", "_id" : "post03"&#125;) 计数 12345collection.count()3collection.count(&#123;'tags': ['bulk', 'insert']&#125;)2 **索引 1234result = db.profiles.create_index([('user_id', pymongo.ASCENDING)], unique=True)sorted(list(db.profiles.index_information()))[u'_id_', u'user_id_1'] redisThe Python interface to the Redis key-value store.redis模块: https://pypi.org/project/redis/ redis模块提供两个类Redis和StrictRedis用于实现Redis的命令: redis.Strictredis(推荐)StrictRedis用于实现大部分官方的命令，并使用官方的语法和命令 123help(redis.StrictRedis)__init__(self, host=&apos;localhost&apos;, port=6379, db=0, password=None, socket_timeout=None, socket_connect_timeout=None, socket_keepalive=None, socket_keepalive_options=None, connection_pool=None, unix_socket_path=None, encoding=&apos;utf-8&apos;, encoding_errors=&apos;strict&apos;, charset=None, errors=None, decode_responses=False, retry_on_timeout=False, ssl=False, ssl_keyfile=None, ssl_certfile=None, ssl_cert_reqs=None, ssl_ca_certs=None, max_connections=None) redis.Redis(不推荐)Redis是StrictRedis的子类，用于向后兼容旧版本的redis模块 连接 12345678910111213141516171819202122232425import redisr = redis.StrictRedis()#orr = redis.StrictRedis(host='localhost', port=6379, db=0, password='password')#字符串操作r.set('name', 'Zhang21')r.get('name')r.type('name')r.delete('name')#列表操作r.rpush('LIST', 'list-01', 'list-02')r.type('LIST')r.llen('LIST')#help(r.lrane)#lrange(name, start, end)lrange('LIST', 0, -1)#其它redis数据类型操作方法类同 Connection Pools假设Redis服务器与客户端分处在异地，虽然基于内存的Redis数据库有着超高的性能，但是底层的网络通信却占用了一次数据请求的大量时间，因为每次数据交互都需要先建立连接，假设一次数据交互总共用时30ms，超高性能的Redis数据库处理数据所花的时间可能不到1ms，也即是说前期的连接占用了29ms，连接池则可以实现在客户端建立多个链接并且不释放，当需要使用连接的时候通过一定的算法获取已经建立的连接，使用完了以后则还给连接池，这就免去了数据库连接所占用的时间。 1234567#help(redis.ConnectionPool)pool = redis.ConnectionPool()#orpool = redis.ConnectionPool(host='localhost', port=6379, db=0, passeord='password')r = redis.StrictRedis(connection_pool=pool) Web抓取 request BeautifulSoup selenium requests从Internet上下载文件和网页。 12345678910import requests, pprint#help(requests)r = request.get(&apos;https://www.baidu.com&apos;)r.status_coder.headersr.urlr.textpprint.pprint(r.text) beautifulsoup解析HTML 123pip3 install beautifulsoup4import bs4 栗子：12345678import requests, bs4r = request.get(&apos;https://www.baidu.com&apos;)soup = bs4.BeautifulSoup(r.text)type(soup)#soup.select()#soup.find() selenium启动并控制一个Web浏览器。selenium能够填写表单，并模拟鼠标在此浏览器找那个点击 1234from selenium import webdriverbrowser = webdriver.Firefox()browser.get(&apos;https://www.baidu.com&apos;) 文档处理 openpyxl PyPDF2 pytho-docx openpyxlopenpyxl is a Python library to read/write Excel 2010 xlsx/xlsm/xltx/xltm files. 关于Excel电子表格：一个Excel电子表格文档称为一个工作簿。一个工作簿保存在扩展名为.xlsx的文件中。每个工作簿可以包含多个表(工作表)。用户当前查看的表被称为活动表。每个表有一些列(地址为从A开始的字母)，一些行(地址从1开始的数字)。在特定行和列的方格被称为单元格。单元格形成的网格和数据构成了表。 1234567891011121314151617181920212223242526272829pip3 install openpyxlimport openpyxlworkbook = openpyxl.load_workbook(&apos;/tmp/test.xlsx&apos;)type(workbook)#&lt;class &apos;openpyxl.workbook.workbook.Workbook&apos;&gt;workbook.get_sheet_names()#[&apos;Sheet1&apos;, &apos;Sheet2&apos;, &apos;Sheet3&apos;]sheet1 = workbook.get_sheet_by_name(&apos;Sheet1&apos;)type(sheet1)sheet1.title#&apos;Sheet1&apos;workbook.get_active_sheet()#&lt;Worksheet &quot;Sheet1&quot;&gt;sheet1[&apos;A1&apos;].value#&apos;1A&apos;sheet1[&apos;A1&apos;].row#1sheet1[&apos;A1&apos;].colume#Asheet1.cell(row=2, column=2).value#2B PyPDF2PDF和Word文档是二进制文件，它们比文本文件要复制得多。 1234567891011pip3 install PyPDF2import PyPDF2pdfFile = open(&apos;/tmp/test.pdf&apos;, &apos;rb&apos;)pdfReader = PyPDF2.pdfFileReader(pdfFile)pdfWriter = PyPDF2.pdfFileWriter()page = pdfReader.getPage()page.extractText() python-docx利用python-docx模块，Python可创建和修改Word文档，它带有.docx文件扩展名。 1234567891011121314151617181920212223242526pip3 insntall python-docximport docxdoc = docx.Document(&apos;/tmp/test.docx&apos;)len(doc.paragraphs)#paragraphs和run属性doc.paragraphs[0].textdoc.paragraphs[0].run[0].text#写入doc.add_paragraph(&apos;Add line01&apos;)doc.add_paragraph(&apos;Add line02&apos;).add_run(&apos;tail !&apos;)doc.save(&apos;/tmp/test.docx&apos;)#标题doc.add_heading(&apos;Header 0&apos;, 0)doc.add_heading(&apos;Header 4&apos;, 4)#分页doc.add_page_broke()#图像doc.add_picture(xxx) 图像处理 pillow(PIL) pillowPIL - the Python Imaging Library. 请了解RGB和CMYK颜色方式。 123pip3 install pillowimport PIL 日志处理 elasticsearch elasticsearchPython Elasticsearch Client pypi: https://pypi.org/project/elasticsearchgithub: https://github.com/elastic/elasticsearch-pydocs: https://elasticsearch-py.readthedocs.io 几个ES概念： index document type id 安装: 1pip3 install elasticsearch 栗子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475from datetime import datetimefrom elasticsearch import Elasticsearch#curl localhost:9200/?pretty#default http://localhost:9200es=Elasticsearch()es.info()#auth#es=Elasticsearch('https://url:port', http_auth=('elastic', 'passwd'))#es.info#sslfrom ssl import create_default_contextes = Elasticsearch('https://url:port', ssl_context=context, http_auth=('ealstic', 'passwd'))#es.index#es.create#es.update#es.delete#创建索引es.indices.create(index='my-index')#&#123;'acknowledged': True, 'shards_acknowledged': True, 'index': 'my-index'&#125;#curl localhost:9200/_cat/indices#添加或修改某个索引的文档格式es.index(index='my-index', doc_type='test-type', id=2018, body=&#123;'any': 'data', 'timestamp': datetime.now()&#125;)#es.create(index='my-index', doc_type='test-type', id=2018, body=&#123;'any': 'data', 'timestamp': datetime.now()&#125;)#&#123;'result': 'created', '_primary_term': 1, '_index': 'my-index', '_shards': &#123;'total': 2, 'failed': 0, 'successful': 1&#125;, '_type': 'test-type', '_id': '2018', '_version': 1, '_seq_no': 0&#125;#查看索引es.get(index='my-index', doc_type='test-type', id=2018)#&#123;'_index': 'my-index', '_source': &#123;'timestamp': '2018-07-18T11:34:49.573721', 'any': 'data'&#125;, '_type': 'test-type', 'found': True, '_id': '2018', '_version': 1&#125;#不指定id，es会自动生成，但查询时候需要iddata=&#123; 'timestamp': datetime.now(), 'name': 'zhang21', 'msg': 'Hello'&#125;es.index(index='my-index', doc_type='test-type', body=data)#&#123;'result': 'created', '_primary_term': 1, '_index': 'my-index', '_shards': &#123;'total': 2, 'failed': 0, 'successful': 1&#125;, '_type': 'test-type', '_id': 'C_vnq2QBmuTERb-Wz39W', '_version': 1, '_seq_no': 0&#125;es.get(index='my-index', doc_type='test-type', id='C_vnq2QBmuTERb-Wz39W')#&#123;'_index': 'my-index', '_source': &#123;'name': 'Zhang21', 'timestamp': '2018-07-18T13:40:04.005192', 'msg': 'Hello'&#125;, '_type': 'test-type', 'found': True, '_id': 'C_vnq2QBmuTERb-Wz39W', '_version': 1&#125;#查询es.search(index='my-index')#批量操作from elasticsearch import helperhelp(helper.bulk)#bulk()支持index, create, delete, upsate动作package=[]for i in range(5): rom=&#123; 'count': i, 'timestamp': datetime.now() &#125; package.append(row)actions=[ &#123; '_op_type': 'index', '_index': 'my-index', '_type': 'test-type', '_source': i &#125; for i in package]pprint(actions)helpers.bulk(es, actions)pprint(es.search(index='my-index')) 具体信息请查看文档！ 数据分析基于《Python Data Analysis》一书！强烈建议使用Anaconda安装Python和Jupyter。 ipython jupyter pandas numpy statsmodels matplotlib Anaconda site: doc: 参考: Anaconda 是一种Python语言的免费增值开源发行版，用于进行大规模数据处理, 预测分析, 和科学计算, 致力于简化包的管理和部署。Anaconda使用软件包管理系统Conda进行包管理。你可能已经安装了Python，那为什么还需要Anaconda？ Anaconda附带了一大批常用的数据科学包 Conda管理包 管理环境 安装到官网下载不同平台的包进行安装。 1234567891011wget https://repo.anaconda.com/archive/Anaconda3-5.2.0-Linux-x86_64.shbash ./Anaconda3-5.2.0-Linux-x86_64.sh#之后可设置安装路径和环境变量#查看conda --version#更新所有包conda upgrade --all 包管理conda is a tool for managing and deploying applications, environments and packages. 123456789101112131415161718192021#它会自动安装依赖#其实和pip差不多conda install &lt;package&gt;conda install requests=1.10.0conda install pandas numpy#卸载conda remove &lt;package&gt;#更新conda update &lt;package&gt;conda update &lt;package&gt; --all#列出conda list#搜索conda search 环境管理为不同项目创建不同的运行环境。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#conda create -h#创建环境#默认为 ~/.conda/envs/&lt;evn_name&gt;conda create -n &lt;env_name&gt; &lt;package_names&gt;conda create -n py3 pandas#指定Python版本conda create -n py3 python=3conda create -n py2 python=2conda create -n py36 python=3.6#使用环境source activate &lt;env_name&gt;#或conda activeate &lt;env_name&gt;#关闭环境source deactivate#或conda deactivate#自定义目录conda create -p /path/py2 python=2.7#删除环境conda env remove -n &lt;env_name&gt;#列出环境conda env list#查看环境库conda list -n &lt;env_name&gt;#环境变量#导出cond env export &gt; envName.yaml#或pip freeze &gt; evnName.txt#导入conda env update -f=/path/envName.yaml#或pip install -r /path/envName.txt#列出conda env list ipython site: github: pypi: Python Shell有很多弊端，所以使用功能更强大的ipython。ipython提供了丰富的工具包，可帮助你以交互的方式充分利用Python: 强大的交互式Shell Jupyter的内核 支持交互式数据可视化和GUI工具箱 灵活，可嵌入式的解释器，可加载到自己的项目中 使用方便，高性能的并行计算工具 安装: 1234567891011#bashsudo pip3 install ipython#使用Anacondaconda install ipython#启动ipythonPython 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 17:14:51)Type 'copyright', 'credits' or 'license' for more informationIPython 6.5.0 -- An enhanced Interactive Python. Type '?' for help jupyter site: github: pypi: Jupyter notebook是一种Web应用，能让用户将说明文本、数学方程、代码和可视化内容全部组合到一个易于共享的文档中。 安装 1234567891011121314#bashsudo pip3 install jupyter#Anacondaconda install jupyter#运行jupyter notebook --no-browser --ip=0.0.0.0#建议先设置密码jupyter notebook passwordjupyter notebook --no-browser --ip=192.168.31.119 --notebook-dir=/tmp/notebook 打开浏览器访问，输入密码： Anaconda虚拟环境目录： 栗子：]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elatic Stack]]></title>
    <url>%2F2018%2F04%2F15%2FElastic%2F</url>
    <content type="text"><![CDATA[参考： Elastic指南: https://www.elastic.co/guide/index.html Elasticsearch文档: https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html Logstash文档: https://www.elastic.co/guide/en/logstash/current/index.html Kibana文档: https://www.elastic.co/guide/en/kibana/current/index.html Filebeat文档: https://www.elastic.co/guide/en/beats/filebeat/index.html Metricbeat文档: https://www.elastic.co/guide/en/beats/metricbeat/current/index.html Lucence查询语法: https://wizardforcel.gitbooks.io/mastering-elasticsearch/content/chapter-1/114_README.html 环境： CentOS7.x86_64 Elastcisearch v6.2.3 Kibana v6.2.3 Logstash v6.2.3 Beats v6.2.3 综述开源的 Elastic Stack:能够安全可靠地获取任何来源、任何格式的数据，并且能够实时地对数据进行搜索、分析和可视化。 Elastic指的是elastic公司下的几款产品： Elasticsearch Logstash Kibana Beats X-Pack Elasticsearch 开放源码且自由使用 License: Apache License 2.0 GitHub: https://github.com/elastic/elasticsearch Doc: https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html 搜索、分析和存储您的数据。Elasticsearch 是基于 JSON 的分布式搜索和分析引擎，专为实现水平扩展、高可用和管理便捷性而设计。Elasticsearch 是一个分布式的 RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为 Elastic Stack 的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况。 基于Lucene。Lucene是一套用于全文检索和搜寻的开放源码程式库，由Apache软件基金会支持和提供。Lucene提供了一个简单却强大的应用程式介面，能够做全文索引和搜寻，在Java开发环境里Lucene是一个成熟的免费开放原始码工具；就其本身而论，Lucene是现在并且是这几年，最受欢迎的免费Java资讯检索程式库。 Logstash 开放源码且自由使用 GitHub: https://github.com/elastic/logstash Doc: https://www.elastic.co/guide/en/logstash/current/index.html 集中、转换和存储数据Logstash 是动态数据收集管道，拥有可扩展的插件生态系统，能够与 Elasticsearch 产生强大的协同作用。Logstash 是开源的服务器端数据处理管道，能够同时 从多个来源采集数据、转换数据，然后将数据发送到您最喜欢的 “存储库” 中。（我们的存储库当然是 Elasticsearch。） Kibana 开放源码且自由使用 GitHub: https://github.com/elastic/kibana Doc: https://www.elastic.co/guide/en/kibana/current/index.html 实现数据可视化Kibana 让您能够可视化 Elasticsearch 中的数据并操作 Elastic Stack，因此您可以在这里解开任何疑问：例如，为何会在凌晨 2:00 被传呼，雨水会对季度数据造成怎样的影响。 Beats 开放源码且自由使用 GitHub: https://github.com/elastic/beats Doc: https://www.elastic.co/guide/en/beats/libbeat/current/index.html Beats 是轻量型采集器的平台，从边缘机器向 Logstash 和 Elasticsearch 发送数据。Beats 平台集合了多种单一用途数据采集器。这些采集器安装后可用作轻量型代理，从成百上千或成千上万台机器向 Logstash 或 Elasticsearch 发送数据。 X-Pack Doc: https://www.elastic.co/guide/en/x-pack/current/index.html 一个程序包，带来丰富的可能性单就其自身而言，Elastic Stack 就是一款值得考虑的强大工具。X-Pack 将诸多强大功能集合到一个单独的程序包中，更将它带上了一个新的层次。X-Pack 是集成了多种便捷功能的单个插件 — security、alerting、monitoring、reporting、graph 探索和 machine learning — 您可以在 Elastic Stack 中放心地使用这些功能。 使用Dockerdocker hub里面有ELK的镜像，可以直接拉取使用。推荐使用官方ELK镜像。 我自己做了一个ELK的image，上传到了我的docker hub里。我自己做这个镜像不推荐，因为使用了centos7，导致了镜像很大，这应该避免。 在docker中运行centos7 直接拉取的centos没有systemd的权限，需要在运行添加docker run -id --privileged &lt;image-id&gt; /usr/sbin/init选项。 或者使用Docker Hub上CentOS提供的支持systemd的Dockerfile来构建centos: https://hub.docker.com/_/centos/其实Dockfile就是有这条命令CMD [&quot;/usr/sbin/init 123456789101112131415161718192021222324252627282930313233docker pull centosdocker image lsREPOSITORY TAG IMAGE ID CREATED SIZEcentos latest e934aafc2206 2 weeks ago 199MB#运行docker#此处如果没有/bin/bash的话，生成的container立马就停止了#端口映射什么的后面再弄docker run -d -i &lt;image-id&gt; /bin/bash#查看容器docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES27b10f5015be e934aafc2206 "/bin/bash" About an hour ago Up About an hour ecstatic_boyd#进入dockerdocke exec -it &lt;container-id&gt; /bin/bash#当然，你也可以运行SSHD，通过端口映射，连接到docker内#[root@27b10f5015be /]##在docker中安装各类需要的软件了#可能需要设置一下/etc/resolv.conf 将安装了各类软件的容器构建为一个新的镜像 12345678910111213141516171819202122232425262728293031323334#从运行的容器中重构镜像#docker commit -m "centos7+elk" &lt;container-id&gt; user/repo:tagdocker commit -m 'centos7+elk' 27b10f5015be zhang21/centos7:elk#查看新镜像docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEzhang21/centos7 elk 0b22d93f7353 16 minutes ago 1.04GBcentos latest e934aafc2206 2 weeks ago 199MB#运行新镜像docker run -id -p 80:80 9200:9200 &lt;image-id&gt; /bin/bash#此处遇到一个错，因为docker的网络是通过iptables来转发的，因此主机上不能关闭firewalld，不能无法启动容器#进入新容器docker exec -it &lt;container-id&gt; /bin/bash#此处无法使用systemctl，原因已写到前面#Failed to get D-Bus connection: Operation not permitted#获得systemd权限启动docker run -id --privileged -p 80:80 &lt;image-id&gt; /usr/sbin/init#进入docker exec -it &lt;container-id&gt; /bin/bash#启动Nginxsystemctl start nginx 将新镜像上传到Hub 我用的是Docker Hub免费版，当然线上的话可能是阿里云或腾讯云。 12345678docker login -u zhang21#上传镜像到我的Hubdocker push zhang21/centos7:elk#拉取镜像docker pull zhang21/centos7:elk 安装安装步骤： Elasticsearch Kibana Logstash Install X-Pack into Elasticsearch Install X-Pack into Kibana 安装ELKF需要依赖JDK（java），请先安装。我是直接使用的RPM包安装。 12345678910111213141516171819202122#安装Javayum install java-1.8.0-openjdk-headless-1.8.0.161-0.b14.el7_4.x86_64 -y#编写repovim /etc/yum.repo.d/elk.repo[elasticsearch-6.x]name=Elasticsearch repository for 6.x packagesbaseurl=https://artifacts.elastic.co/packages/6.x/yumgpgcheck=1gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearchenabled=1autorefresh=1type=rpm-md#安装yum install -y elasticsearch logstash kibana filebeat 由于elk默认将软件安装到/usr/share/下，因此我把它们的bin路径加入PATH。 123456789vim /etc/profileexport PATH=$PATH:/usr/share/elasticsearch/bin:/usr/share/kibana/bin:/usr/share/logstash/bin:/usr/share/elasticsearch/bin/x-pack:/usr/share/filebeat/bin#执行source /etc/profile ELKF使用RPM安装的布局说明： 主目录 /usr/share/elasticsearch /usr/share/kibana /usr/share/logstash /usr/share/filebeat 二进制文件 /usr/share/elasticsearch/bin /usr/share/kibana/bin /usr/share/logstash/bin /usr/share/filebeat/bin 配置文件 /etc/elastcisearch /etc/kibana /etc/logstash /etc/filebeat 环境变量 /etc/sysconfig/elasticsearch 插件 /usr/share/elastcisearch/plugins /usr/share/kibana/plugins 安装X-Pack 注意由于自动升级到Elastic v6.3自带了X-Pack，不需要额外安装。之前安装的一些插件会导致Elastic无法运行，请卸载这些插件。 123456elasticsearch-plugin listelasticsearch-plugin remove x-packkibana-plugin remove x-packlogstash-plugin remove x-pack 安装X-Pack前，请先安装ELK。请安装匹配版本的X-Pack。 Install X-Pack on Elasticsearch Install X-Pack on Kibana Install X-Pack on Logstash 启用或禁用X-Pack功能 有些功能默认开启，有些默认关闭。请在配置文件中查看详情。添加某些功能可能导致软件无法启动，请注意查看日志。 在以下文件中配置它们： elasticsearch.yml kibana.yml logstash.yml filebeat.yml X-Pack功能： 功能 描述 xpack.graph.enabled X-Pack图形功能 xpack.ml.enabled X-Pack机器学习功能 xpack.monitoring.enabled X-Pack监视功能 xpack.reporting.enabled X-Pack报告功能 xpack.security.enabled X-Pack安全功能 xpack.watcher.enabled X-Pack观察器 在ELK中启动X-Pack monitoring功能 123456789101112131415161718192021222324252627282930#xpack.graph.enabled#xpack.ml.enabled#xpack.monitoring.enabled#xpack.reporting.enabled#xpack.security.enabled#xpack.watcher.enabled#在Elasticsearch和kibana中禁用验证后，不用在logstash中输入，否则会报错。xpack.security.enabled: false#启用验证#具体可参考官方文档#在logstash.yml中配置xpack.monitoringxpack.monitoring.enabled: true#xpack.monitoring.elasticsearch.url: &quot;http://127.0.0.1:9200&quot;#xpack.monitoring.elasticsearch.username: logstash_system#xpack.monitoring.elasticsearch.password: logstash#在Filebeat中添加monitoringxpack.monitoring: enabled: true #elasticsearch: #url: &quot;http://localhost:9200&quot; #usernaem: &quot;elastic&quot; #password: &quot;elastic&quot; 安装：建议使用密码！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#Elastcisearch安装X-Packelasticsearch-plugin install x-pack#启动#9200, 9300端口#elasticsearch不能使用root启动，所以我把elastic用户修改为/bin/bashsu elasticsearchelasticsearch -d#elasticsearch#生成默认用户密码，此密码针对elastic和kibana用户#/usr/share/elasticsearch/bin/x-pack#将此加入PATHsetup-passwords auto#或手动输入密码setup-passwords interactiveelastic#elastickibana#kibanalogstash_system#logstash#Kibana安装X-Packkibana-plugin install x-pack#对kibana.yml添加用户和密码#此密码是前面默认生成的vim /etc/kibana/kibana.yml`elasticsearch.username: &quot;elastic&quot;elasticsearch.password: &quot;elastic&quot;#修改监听地址server.host: &quot;0.0.0.0&quot;logging.dest: /var/log/kibana/kibana.log#kibana日志默认是stdout#修改为/var/log/kibana/kibana.logmkdir /var/log/kibana#启动kibana#5601端口#kibana可用root启动kibana#或systemctl start kibana#Logstash安装X-Packlogstash-plugin install x-pack 启动ELK建议给他们加上密码！不知道为什么，我的ElasticStack都能用systemd来管理了！ 12#最便捷systemctl start elasticsearch logstash filebeat metricbeat heartbeat packetbeat auditbeat 123456789101112131415161718192021#Elasticsearchsu elasticsearch#elasticsearch，查看输出elasticsearch -d#kill -15 pid &amp;&amp; elasticsearch -d#Kibanakibana&amp;systemctl start kibana#kill -15 pid &amp;&amp; kibana&amp;#Logstash#logstash -f xxx.confsystemctl start logstash#Filebeat#filebeat -e -c filebeat.yml，查看输出信息systemctl start filebeat 启动时可能遇到的问题 can not run elasticsearch as root 专门建立一个管理ELK的用户，切换到此用户后运行，注意修改ELK相关目录权限 或者修改ELK各自用户的/etc/passwd，切换到对应用户后运行。注意权限 — su elasticsearch &amp;&amp; elasticsearch elasticsearch process is too low, increase to at least [65536] 12345678vim /etc/security/limits.conf* soft nofile 655350* hard nofile 655350ulimit -a 访问elasticsearch 123456$ip:9200#此处访问是需要用户名和密码的#使用前面X-Pack生成的默认用户名和密码elastic elastic#登录之后便可看到node，cluster相关信息 访问kibana 12#5601端口http://0.0.0.0:5601 启用xpack注意事项启用X-PACK后，请注意在kibana配置文件中认证Elasticsearch用户和密码，并且使用Elasticsearch的用户和密码登录Kibana的前端界面。 由于我使用kibana用户登录，导致很多地方访问Elasticsearch都没有权限。请注意。 这样使用Elasticsearch登录后，便可以之间在Dev Tools中通过REST API获取和更新相关信息，并且创建和管理相关用户和角色。 安装Filebeat由于前面我们添加了ELK-repo，所以这里我们可以直接安装。 12345678yum install -y filebeat#开启X-Pack monitor#默认关闭vim /etc/filebeat/filebeat.ymlxpack.monitoring.enabled: true 修改ELK jvm内存大小在此版本中，可直接在配置文件目录下的jvm.options里修改JVM 内存大小。 12345678910111213#最小-Xms#最大-Xmxvim /etc/elasticsearch/jvm.options-Xms4g-Xmx4g#其它如此 与Nginx结合使用将Kibana展现到Nginx上的话，便可以不对Kibana开放外网访问。 1234567891011121314151617181920212223242526272829303132333435363738#安装Nginxvim /etc/yum.repo.d/nginx.repo[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=0enabled=1yum install -y nginx nginx-mod-stream#配置vim /etc/nginx/conf.d/kibana.conf#可把IP换成kibana相应的域名#再将域名解析到此IPserver &#123; listen 80; server_name 172.16.129.150;#Kibana location / &#123; proxy_pass http://127.0.0.1:5601; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &apos;upgrade&apos;; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; &#125;&#125; 可能会遇到的问题 Nignx错误日志: Permission denied) while connecting to upstream 1234567891011sudo cat /var/log/audit/audit.log | grep nginx | grep denied#后来判断是SELinux的问题getenforcesetenforce 0#修改SELinuxvim /etc/selinux/configSELINUX=disabled Logstash文档 Logstash的pipeline有两个必须的元素： input 消耗来自source的数据 output 将修改后的数据写入destination 以及一个可选元素： filter 根据你的定义来修改数据 介绍Logstash是一个具有实时流水线(pipeling)功能的开源数据收集引擎。它可以动态统一来自不同source的数据，并将数据正常化的你的destination。 任何类型的事件都可以通过大量的输入、过滤和输出插件进行丰富和转换，通过本地编解码器进一步简化了摄取过程。 Logstash的能量具有强大的Elasticsearch和Kibana系统的水平可伸缩数据处理流水线。 Logstash喜欢的数据所有数据来者不拒！ Logs and Metrics 处理所有类型的日志数据 Apache Nginx Syslog 使用Filebeat享受互补的安全日志转发功能 从Ganglia, JMx, NetFlow和TCP,UDP收集metrics Web 将http request转换为events 分析Web服务 支持Webhook 通过轮询HTTP endpoint创建事件 通过Web API捕获健康状况、性能和其它类型的数据 数据存储和流从你已经拥有的数据中发现更多价值。 Sensors and IoT探索广泛的其它数据。 轻松丰富一切在摄取过程中清理并转换数据，以便在index或output时立即获得实时信息。Logstash具有许多聚合和突变以及模式匹配，地理映射和动态查找功能。 Grok是Logstash filter的金刚钻，用于从非结构化数据中派生出结构化数据 通过解析来自IP的地理坐标，标准化提起复杂性，简单K-V对和CSV数据，并通过本地查找或Elasticsearch查询进一步丰富你的数据，从而扩展你的视野 编解码器通常用于缓解JSON和多行事件等常见事件结构的处理 选择你的储藏室将数据放在最重要的位置。通过存储，分析和对数据采取行动，解锁各种downstream分析和操作用例。 Analysis Elasticsearch Data stores(MongoDB, Redis) Archiving HDFS S3 Monitoring Nagios Zabbix Ganglia Alerting Watcher(Elasticsearch) Email 入门安装，储藏，解析，汇聚多个Input/Output。 储藏第一个事件测试Logstash和运行一个基本的pipeline 12345logstash -e &apos;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123;&#125; &#125;&apos;#等待启动，输入hello world#Logstash将时间戳和主机名添加到message#2018-04-13T08:17:51.702Z zhang22 helloworld 启动logstsh时的一个问题： WARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash 虽然通过RPM安装Logstash存在/etc/logstash文件，但是还是会报错。 123cd /usr/share/logstash/binln -s /etc/logstash ./config 通过Logstash解析Logs前面我们创建了一个基本的Logstash pipeline来测试Logstash，但真正处理logs的Logstash pipeline不会这么简单，它可能会有多个input, filter, output。 本节利用一个Filebeat，将Nginx Web Logs作为Logstash pipeline的input，解析这些logs中创建的特定命名字段，并将解析的数据写入Elasticsearch集群。 配置Filebeat以发送Log Lines到Logstash 在创建Logstash pipeline之前，你将配置Filebeat以发送Log lines到Logstash。Filebeat从服务器上的文件收集日志，并将这些日志转发给Logstash实例进行处理。Filebeat专为可靠性和低延迟而设计。它占用的资源极少，beats input插件(默认安装)最大限度地减少了Logstash实例的资源需求。任何Beat框架编写的beat都可以讲事件数据发送到Logstash。 在你的data source主机上安装Filebeat。安装之后，配置filebeat.yml文件: 12345678910111213141516171819vim /etc/filebeat/filebeat.ymlfilebeat.prospectors:- type: log#需要处理的日志的路径，如Nginx paths: - /var/log/nginx/*.logoutput.logstash: hosts: [&quot;localhost:5044&quot;]#运行FilebeatFilebeat -e -c filebeat.yml -d &quot;publish&quot;#Filebeat将会尝试连接到5044端口，在Logstash以一个活动的beats plugin开始前，不会有任何应答。 为Filebeat Input配置Logstash 配置一个Logstash pipeline，使用beat input plugin接受来自beats的事件。格式如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455cd /etc/logstash/conf.dvim ./first-pipeline.confinput &#123;&#125;#filter部分可选filter &#123;&#125;output &#123;&#125;#实例input &#123; beats &#123; port =&gt; &quot;5044&quot; &#125;&#125;output &#123; stdout &#123; codec =&gt; dubydebug &#125;&#125;#验证配置logstash -f first-pipe.conf --config.tst_and_exit#消息2018-04-17T14:15:46.187+0800 ERROR pipeline/output.go:74 Failed to connect: dial tcp [::1]:5044: getsockopt: connection refused2018-04-17T14:15:46.607+0800 INFO log/harvester.go:241 File is inactive: /var/log/nginx/access.log. Closing because close_inactive of 5m0s reached.2018-04-17T14:15:46.607+0800 INFO log/harvester.go:241 File is inactive: /var/log/nginx/error.log. Closing because close_inactive of 5m0s reached.2018-04-17T14:15:46.923+0800 INFO log/harvester.go:241 File is inactive: /var/log/secure-20180409. Closing because close_inactive of 5m0s reached.2018-04-17T14:15:51.096+0800 INFO log/harvester.go:241 File is inactive: /var/log/secure-20180401. Closing because close_inactive of 5m0s reached.2018-04-17T14:15:52.687+0800 INFO log/harvester.go:241 File is inactive: /var/log/secure-20180415. Closing because close_inactive of 5m0s reached.#启动Logstash#修改配置后可动态载入logstash -f first-pipe.conf --config.reload.automatic#消息2018-04-17T14:18:41.542+0800 INFO [monitoring] log/log.go:124 Non-zero metrics in the last 30s &#123;&quot;monitoring&quot;: &#123;&quot;metrics&quot;: &#123;&quot;beat&quot;:&#123;&quot;cpu&quot;:&#123;&quot;system&quot;:&#123;&quot;ticks&quot;:150,&quot;time&quot;:159&#125;,&quot;total&quot;:&#123;&quot;ticks&quot;:450,&quot;time&quot;:468,&quot;value&quot;:450&#125;,&quot;user&quot;:&#123;&quot;ticks&quot;:300,&quot;time&quot;:309&#125;&#125;,&quot;info&quot;:&#123;&quot;ephemeral_id&quot;:&quot;84cbf5cd-dfff-4391-9631-2b8e77329696&quot;,&quot;uptime&quot;:&#123;&quot;ms&quot;:480009&#125;&#125;,&quot;memstats&quot;:&#123;&quot;gc_next&quot;:11030992,&quot;memory_alloc&quot;:6588088,&quot;memory_total&quot;:40882600&#125;&#125;,&quot;filebeat&quot;:&#123;&quot;harvester&quot;:&#123;&quot;open_files&quot;:5,&quot;running&quot;:8&#125;&#125;,&quot;libbeat&quot;:&#123;&quot;config&quot;:&#123;&quot;module&quot;:&#123;&quot;running&quot;:2&#125;&#125;,&quot;pipeline&quot;:&#123;&quot;clients&quot;:8,&quot;events&quot;:&#123;&quot;active&quot;:4118&#125;&#125;&#125;,&quot;registrar&quot;:&#123;&quot;states&quot;:&#123;&quot;current&quot;:10&#125;&#125;,&quot;system&quot;:&#123;&quot;load&quot;:&#123;&quot;1&quot;:4.86,&quot;15&quot;:4.41,&quot;5&quot;:4.53,&quot;norm&quot;:&#123;&quot;1&quot;:2.43,&quot;15&quot;:2.205,&quot;5&quot;:2.265&#125;&#125;&#125;&#125;&#125;&#125; 使用Grok filter plugin解析Web Logs 在某些时候，可能输出的日志信息的格式并不理想。你想要解析log以创建特定的命名字段。 grok过滤插件使你能够将非结构化的日志数据解析为结构化和可查询的内容。由于grok过滤器插件在传入的日志数据中查找模式，因此配置插件需要你作出关于如何识别你的用例。 你可以使用%{COMBINEDAPACHELOG} grok模式，它从如下模式的日志中构建行： 信息 Field Name IP Add clientip User ID ident User Auth auth timestamp timestamp HTTP Verb verb Request body request HTTP Status code respone Referer URL referer User agent agent 12345678910111213141516171819202122232425vim first-pipline.confinput &#123; beats &#123; port =&gt; &quot;5044&quot; &#125;&#125;filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot; &#125; &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125;&#125;#启动查看效果 通过Geoip过滤插件增强数据 除了解析日志数据以获得更好的搜索外，过滤插件还可从现有的数据中后去补充信息。geoip插件查找IP地址，从IP地址获取地理位置信息，并将该位置信息添加到日志中。 配置Logstash实例来使用geoip过滤插件: 12345678910111213141516171819202122vim first-pipeline.confinput &#123; beats &#123; port =&gt; &quot;5044&quot; &#125;&#125; filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot;&#125; &#125; geoip &#123; source =&gt; &quot;clientip&quot; &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125;&#125;#重启服务 索引数据到Elasticsearch 现在Web log已经被处理为指定的字段，现在Logstash pipeline便可以索引数据到一个Elasticsearch集群中。 1234567891011121314151617181920212223vim first-pipeline.confinput &#123; beats &#123; port =&gt; &quot;5044&quot; &#125;&#125; filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot;&#125; &#125; geoip &#123; source =&gt; &quot;clientip&quot; &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [ &quot;localhost:9200&quot; ] &#125;&#125;#重启服务 验证： 这里遇到一个错误： index_not_found_exception 这里要将logstash-$DATE反映索引的实际名称，也就是在通过下面的命令得到的logstash-2018.04.13。把我坑惨了！ 123456789101112131415curl -XGET &apos;localhost:9200/logstash-$DATE/_search?pretty&amp;q=response=200&apos;#索引名称使用的日期基于UTC，而不是Logstash正在运行的timezone#查看可用索引列表curl &apos;localhost:9200/_cat/indices?v&apos;health status index uuid pri rep docs.count docs.deleted store.size pri.store.sizeyellow open logstash-2018.04.13 dRW2veUgS2ObZmP3lepqsQ 5 1 154 0 266.6kb 266.6kbcurl -XGET &apos;localhost:9200/logstash-2018.04.13/_search?pretty&amp;q=response=200&apos; Kibana中的可视化效果： 拼接多个输入和输出插件你需要管理的信息通常来自多个不同的source，并且可能需要多个不同的destination来存储数据。Lostash pipeline可以使用多个输入和输出插件来处理这些需求。 官方文档中使用Twitter and Filebeat这两者作为Logstash input，并将信息输出到Elasticsearch和file。 配置Logstash实例使用Filebeat input plugin 配置Logstash实例写入Elasticsearch多节点(cluster) 配置Logstash pipeline将数据写入file 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#配置Filebeat发送Log Line到Logstashvim /etc/filebeat/filebeat.ymlfilebeat.prospectors:- type: log paths: - /var/log/*.log fields: type: syslogoutput.logstash: hosts: [&quot;localhost:5044&quot;]########################cd /etc/logstash/conf.dvim 2nd-pipeline.confinput &#123; twitter &#123; consumer_key =&gt; &quot;enter_your_consumer_key_here&quot; consumer_secret =&gt; &quot;enter_your_secret_here&quot; keywords =&gt; [&quot;cloud&quot;] oauth_token =&gt; &quot;enter_your_access_token_here&quot; oauth_token_secret =&gt; &quot;enter_your_access_token_secret_here&quot; &#125; beats &#123; prot =&gt; &quot;5044&quot; &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;hosts1:port1&quot;, &quot;host2:port2&quot;...] &#125; file &#123; path =&gt; &quot;/path/to/target/file&quot; &#125;&#125;#重启服务#测试，Replace $DATE with the current date, in YYYY.MM.DD format.curl -XGET &apos;localhost:9200/logstash-$DATE/_search?pretty&amp;q=fields.type:syslog&apos; Input输入插件可以使特定的事件源由Logstash读取。 可用的输入插件：我只列出了常见的，具体请参考: https://www.elastic.co/guide/en/logstash/current/input-plugins.html 插件 描述 beats 从Elastic框架接收事件 couchdb_changes 从CouchDB的_changesURI流式传输事件 dead_letter_queue 从Logstash的dead letter queue读取事件 elasticsearch 从Elasticsearch集群中读取查询结果 exec 抓取shell命令的输出作为事件 file 来自文件的流事件 github 从GitHub webhook读取事件 heartbeat 为测试生成心跳事件 http 通过HTTP/HTTPS接收事件 http_poller 解码HTTP API输出为事件 imap 从IMAP服务器读取邮件 jmx 通过JVM从java程序检索标准 kafka 从kafka中读取事件 log4j 通过TCP socket从Log4j对象读取事件 pipe 从长时间运行的命令管道中获取流事件 rabbitmq 从Redis实例读取事件 sqlite 基于SQLite数据库中的行创建事件 stdin 从标准输入中读取事件 syslog 读取系统日志作为事件 tcp 从TCP socket读取事件 udp 从UDP读取事件 unix 通过Unix socket读取事件 websocket 从一个websocket读取事件 input filter通用选项: Setting Input type Required add_field hash No codec codec No enable_metric boolean No id string No tags array No type string No add_field添加一个字段到一个事件，默认值为{} codec用于输入数据的编解码器。默认值是plain enable_metric为特定插件实例禁用或启用度量标准日志记录，默认值为true id为插件配置添加一个唯一的ID，如果未指定，Logstash会自动生成一个 tags为事件添加任意数量的任意标签 type为所有input处理的事件添加一个type beats此插件使Logstash能够从Elasticsearch框架中接收事件。 栗子： 123456789101112131415input &#123; beats &#123; port =&gt; 5044 &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; &quot;localhost:9200&quot; #hosts =&gt; [&quot;hosts1&quot;, &quot;hosts2&quot;, ...] manage_template =&gt; false index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;[@metadata][version]&#125;-%&#123;+YYYY.MM.dd&#125;&quot; document_type =&gt; &quot;%&#123;[@metadata][type]&#125;&quot; &#125;&#125; Beats Input配置项： Setting Input_type Required cipher_suites array No client_inactivity_timeout number No host string No include_codec_tag boolean No port number Yes ssl boolean No ssl_certificate a valid filesystem path No ssl_certificate_authorities array No ssl_handshake_timeout number No ssl_key a valid filesystem path No ssl_key_passphrase password No ssl_verify_mode string, one of [none, peer,force_peer] No tls_max_version number No tls_min_version number No elasticsearchElasticsearch Input配置项： Setting Input_type Required ca_file a valid filesystem path No docinfo boolean No docinfo_fields array No docinfo_target string No hosts array No index string No password password No query string No schedule string No scroll string No size number No ssl boolean No user string No 栗子： 1234567891011121314151617input &#123; elasticsearch &#123; hosts =&gt; &quot;es.production.mysite.org&quot; index =&gt; &quot;mydata-2018.09.*&quot; query =&gt; &apos;&#123; &quot;query&quot;: &#123; &quot;query_string&quot;: &#123; &quot;query&quot;: &quot;*&quot; &#125; &#125; &#125;&apos; size =&gt; 500 scroll =&gt; &quot;5m&quot; docinfo =&gt; true &#125;&#125;output &#123; elasticsearch &#123; index =&gt; &quot;copy-of-production.%&#123;[@metadata][_index]&#125;&quot; document_type =&gt; &quot;%&#123;[@metadata][_type]&#125;&quot; document_id =&gt; &quot;%&#123;[@metadata][_id]&#125;&quot; &#125;&#125; exec定期运行shell命令，并抓取整个输出为事件。 栗子： 123456input &#123; exec &#123; command =&gt; &quot;ls&quot; interval =&gt; 30 &#125;&#125; exec Input配置项： Setting Input_type Required command string Yes interval number No schedule string No 此调度表示方法如同Linux中定时任务* 5 * 1-3 *。 file从文件读取流事件。 file input配置项： Setting Input_type Required close_older number No delimiter string No discover_interval number No exclude array No ignore_older number No max_open_files number No path array Yes sincedb_path string No sincedb_write_interval number No start_position string, one of [“beginning”, “end”] No stat_interval number No githubgithub input配置项： Setting Input_type Required drop_invalid boolean No ip string No port number Yes secret_token string No kafkahttps://www.elastic.co/guide/en/logstash/current/plugins-inputs-kafka.html redis从redis实例读取事件，它支持redis的channel和list类型。 redis input配置项： Setting Input_type Required batch_count number No data_type string, one of [list,channel,pattern_channel] Yes db number No host string No path string No key string Yes password password No port number No ssl boolean No threads number No timeout number No sqlite栗子： 1234567891011input &#123; sqlite &#123; path =&gt; &quot;/tmp/example.db&quot; type =&gt; weblogs &#125;&#125;output &#123; stdout &#123; debug =&gt; true &#125;&#125; sqlite input配置项： Setting Input_type Required batch number No exclude_tables array No path string Yes stdin syslog栗子： 12345678input &#123; syslog &#123; port =&gt; 12345 codec =&gt; cef syslog_field =&gt; &quot;syslog&quot; grok_pattern =&gt; &quot;&lt;%&#123;POSINT:priority&#125;&gt;%&#123;SYSLOGTIMESTAMP:timestamp&#125; CUSTOM GROK HERE&quot; &#125;&#125; syslog input配置项： Setting Input_type Required facility_labels array No grok_pattern string No host string No locale string No port number No proxy_protocol boolean No severity_labels array No syslog_field string No timezone string No use_labels boolean No tcp栗子： 123456input &#123; tcp &#123; port =&gt; 12345 codec =&gt; json &#125;&#125; tcp input配置项： Setting Input_type Required host string No mode string, one of [server, client] No port number Yes proxy_protocol boolean No ssl_cert a valid file system path No ssl_enable boolean No ssl_extra_chain_certs array No ssl_key a valid file system path No ssl_key_passphrase password No ssl_verify boolean No udp unix websocket Output输出将事件数据发送到特定的目标。输出是事件管道的最后阶段。 输出列表： boundary circonus CSV datadog Elasticsearch email exec file gelf ganglia http/https influxdb irc kafka librato loggly lumberjack metriccatcher mongodb nagios opentsdb pipe rabbitmq redis redmine stdout syslog tcp udp websocket zabbix output通用配置项： Setting Input type Required codec codec No enable_metric boolean No id string No codec用于输出数据的编解码器，默认值是json_lines enable_metric为特定插件实例启用或禁用度量日志记录，默认值是true id为插件配置添加一个唯一的ID，如果未指定ID，Logstash会自动生成。 csvcsv output配置选项： Setting Input_type Required create_if_deleted boolean No csv_options hash No dir_mode number No fields array Yes file_mode number No filename_failure string No flush_interval number No gzip boolean No path string Yes spreadsheet_safe boolean No elasticsearchElasticsearch output配置项： Setting Input type Required action string No bulk_path string No cacert a valid filesystem path No doc_as upsert boolean No document_id string No document_type string No failure_type logging whitelist array No healthcheck_path string No hosts uri No http_compression boolean No index string No keystore a valid filesystem path No keystore_password password No manage_template boolean No parameters hash No parent string No password password No path string No pipeline string No pool_max number No pool_max per route number No proxy uri No resurrect_delay number No retry_initial interval number No retry_max_interval number No retry_on_conflict number No routing string No script string No script_lang string No script_type string, one of [inline, indexed, file] No script_var_name string No scripted_upsert boolean No sniffing boolean No sniffing_delay number No sniffing_path string No ssl boolean No ssl_certificate verification boolean No template a valid filesystem path No template_name string No template_overwrite boolean No timeout number No truststore a valid filesystem path No truststore_password password No upsert string No user string No validate_after inactivity number No version string No version_type string, one of [internal, external, external gt, external gte, force] No exec栗子： 1234567output &#123; if [type] == &quot;abuse&quot; &#123; exec &#123; command =&gt; &quot;iptables -A INPUT -s %&#123;clientip&#125; -j DROP&quot; &#125; &#125;&#125; exec output配置项： Setting Input type Required command string Yes quiet boolean No file栗子： 123456output &#123; file &#123; path =&gt; ... codec =&gt; line &#123; format =&gt; &quot;custom format: %&#123;message&#125;&quot;&#125; &#125;&#125; file output配置项： Setting Input type Required create_if_deleted boolean No dir_mode number No file_mode number No filename_failure string No flush_interval number No gzip boolean No path string Yes write_behavior string No kafka栗子： 123456output &#123; kafka &#123; codec =&gt; json topic_id =&gt; &quot;mytopic&quot; &#125;&#125; kafka output配置项： Setting Input type Required acks string, one of [0, 1, all] No batch_size number No bootstrap_servers string No buffer_memory number No client_id string No compression_type string, one of [none, gzip, snappy, lz4] No jaas_path a valid filesystem path No kerberos_config a valid filesystem path No key_serializer string No linger_ms number No max_request size number No message_key string No metadata_fetch_timeout_ms number No metadata_max_age_ms number No receive_buffer_bytes number No reconnect_backoff_ms number No request_timeout_ms string No retries number No retry_backoff_ms number No sasl_kerberos_service name string No sasl_mechanism string No security_protocol string, one of [PLAINTEXT, SSL, SASL PLAINTEXT, SASL SSL] No send_buffer_bytes number No ssl_key_password password No ssl_keystore_location a valid filesystem path No ssl_keystore_password password No ssl_keystore_type string No ssl_truststore_location a valid filesystem path No ssl_truststore_password password No ssl_truststore_type string No topic_id string Yes value_serializer string No mongodbmongodb output配置项： Setting Input type Required bulk boolean No bulk_interval number No bulk_size number No collection string Yes database string Yes generateId boolean No isodate boolean No retry_delay number No uri string Yes redis将Redis作为消息队列缓存能极大降低系统负载，减轻系统压力。 redis output配置项： Setting Input type Required batch boolean No batch_events number No batch_timeout number No congestion_interval number No congestion_threshold number No data_type string, one of [list, channel] No db number No host array No key string No password password No port number No reconnect_interval number No shuffle_hosts boolean No timeout number No redmine栗子： 1234567891011output &#123; redmine &#123; url =&gt; &quot;http://redmineserver.tld&quot; token =&gt; &apos;token&apos; project_id =&gt; 200 tracker_id =&gt; 1 status_id =&gt; 3 priority_id =&gt; 2 subject =&gt; &quot;Error ... detected&quot; &#125;&#125; redmine output配置项： Setting Input type Required assigned_to_id number No categorie_id number No description string No fixed_version_id number No parent_issue_id number No priority_id number Yes project_id number Yes ssl boolean No status_id number Yes subject string No token string Yes tracker_id number Yes url string Yes output栗子： 123output &#123; stdout &#123; codec =&gt; json &#125;&#125; syslogsyslog output配置： Setting Input type Required appname string No facility string No host string Yes message string No msgid string No port number Yes priority string No procid string No protocol string, one of [tcp, udp, ssl-tcp] No reconnect interval number No rfc string, one of [rfc3164, rfc5424] No severity string No sourcehost string No ssl_cacert a valid filesystem path No ssl_cert a valid filesystem path No ssl_key a valid filesystem path No ssl_key passphrase password No ssl_verify boolean No use_labels boolean No zabbixzabbix output配置项： Setting Input type Required multi_value array No timeout number No zabbix_host string Yes zabbix_key string No zabbix_server host string No zabbix_server port number No zabbix_value string No Filter https://www.elastic.co/guide/en/logstash/current/filter-plugins.html 过滤器插件对事件执行中介(intermediary)处理，过滤器通常根据事件的特征有条件的应用。 下面是Elastic支持的插件列表: 插件 描述 aggregate 汇总来自单个任务的多个事件的信息 alter 对mutate过滤器无法处理的字段进行常规更改 cidr 根据网络块列表检查IP地址 cipher 对事件应用或移除cipher(密码) clone 重复事件 csv 将csv(comma separated value)解析为单个字段 date 解析字段中的日期，以用作事件的Logstash timestamp de_dot Computationally expensive filter that removes dots from a field name dissect 使用分隔符将非结构化事件数据提取到字段中 dns 执行标准或反向DNS查询 drop 删除所有事件 elapsed 计算一对事件之间的经过时间 elasticsearch 将Elasticsearch中以前的日志事件的字段复制到当前事件中 environment 将环境变量存储为元数据子字段 extractnumbers 从字符串中提取数字 fingerprint 由一致的散列值的替换值的指纹字段 geoip 添加有关IP地址的地理信息 grok 将非结构化事件数据解析到字段中 i18n 从字段中删除特定字符 jdbc_static 使用从远程数据库预加载的数据来丰富事件 jdbc_streaming 用你的数据库数据丰富事件 json 解析JSON事件 json_encode 将字段序列化为JSON kv 解析键值对 metricize 处理包含多个度量标准的复杂事件并将它们分成多个事件，每个事件都包含一个度量标准 metrics 汇总指标(Aggregates metrics) mutate 对字段执行突变 prune 将基于字段列表的事件数据精简为黑名单或白名单 range 检查指定的字段是否在给定的大小或长度限制内 ruby 执行任意Ruby代码 sleep 休息一段指定的时间 split 将多行消息拆分成不同的事件 syslog_pri 解析syslog消息的优先字段 throttle 限制事件的数量 tld 用你在配置中指定的任何内容替换默认消息字段的内容 translate 根据散列或YAML文件，替换字段内容 truncate 截断长度超过给定长度的字段 urldecode 解码URL编码的字段 useragent 将用户代理字符串解析到字段中 uuid 为事件添加UUID xml 将XML解析到字段 所有过滤器都支持的配置选项： Setting Input_type Required add_field hash No add_tag array No enable_metric boolean No id string No periodic_flush boolean No remove_field array No remove_tag array No add_field如果此过滤器成功，添加任意字段到此事件。字段名称可以是动态的，并使用%{field}包含事件的部分内容 add_tag如果此过滤器成功，添加任意标签到此事件。标签可以是动态的，并使用%{field}语法包含事件的部分内容 enable_metric为特定插件实例启用/禁用度量标准日志记录 id为插件配置添加一个唯一的ID，如果没有指定ID，Logstash会生成一个。强烈建议在配置中设置此ID当你有多个相同类型的插件时，这特别有用 periodic_flush定期调用过滤器flush方法 remove_field如果此过滤器成功，从事件中移除任意字段 remove_tag如果此过滤器成功，从事件中移除任意标签 Aggregate此过滤器的目的是聚合属于同一任务的多个事件(通常是日志行)中可用的信息，并将最终聚合信息推送到最终任务事件中。 Aggregate Filter Configuration Options: Setting Input_type Required aggregate_maps_path string, a valid filesystem path No code string Yes end_of_task boolean No inactivity_timeout number No map_action string, one of [“create”, “update”, “create_or_update”] No push_map_as_event_on_timeout boolean No push_previous_map_as_event boolean No task_id string Yes timeout number No timeout_code string No timeout_tags array No timeout_task_id_field string No timeout_timestamp_field string No aggregate_maps_pathLogstash停止时存储聚合地图的文件路径，以及Logstash启动时加载的路径。如果未定义，聚合映射将不会存储在Logstash中，并且会丢失。 code使用当前事件执行更新map的代码；或使用当前的map执行更新事件的代码你将有一个可用的map variable 和 event variable end_of_task告诉过滤器该任务已结束，因此在代码执行后删除聚合map inactivity_timeout一个任务被认为已到期的秒数当某个任务超时时，其聚合map将被逐出必须小于timeout map_action create update create_or_update告诉过滤器如何处理聚合map push_map_as_event_on_timeout每次检测到任务超时时，它都会将任务集合映射推送为新的Logstash事件 push_previous_map_as_event每次聚合插件检测到新任务ID时，它会将先前的聚合映射推送为新的Logstash事件，然后为下一个任务创建新的空映射 task_id定义了关联日志的任务ID的表达式该值必须唯一标识任务 timeout time_code timeout_tags在生成超时事件添加的标记 timeout_task_id_field timeout_timestamp_field默认情况下，使用系统时间计算超时 栗子： 给定日志: 1234INFO - 12345 - TASK_START - startINFO - 12345 - SQL - sqlQuery1 - 12INFO - 12345 - SQL - sqlQuery2 - 34INFO - 12345 - TASK_END - end 过滤器: 12345678910111213141516171819202122232425262728293031filter &#123; grok &#123; match =&gt; [ &quot;message&quot;, &quot;%&#123;LOGLEVEL:loglevel&#125; - %&#123;NOTSPACE:taskid&#125; - %&#123;NOTSPACE:logger&#125; - %&#123;WORD:label&#125;( - %&#123;INT:duration:int&#125;)?&quot; ] &#125; if [logger] == &quot;TASK_START&quot; &#123; aggregate &#123; task_id =&gt; &quot;%&#123;taskid&#125;&quot; code =&gt; &quot;map[&apos;sql_duration&apos;] = 0&quot; map_action =&gt; &quot;create&quot; &#125; &#125; if [logger] == &quot;SQL&quot; &#123; aggregate &#123; task_id =&gt; &quot;%&#123;taskid&#125;&quot; code =&gt; &quot;map[&apos;sql_duration&apos;] += event.get(&apos;duration&apos;)&quot; map_action =&gt; &quot;update&quot; &#125; &#125; if [logger] == &quot;TASK_END&quot; &#123; aggregate &#123; task_id =&gt; &quot;%&#123;taskid&#125;&quot; code =&gt; &quot;event.set(&apos;sql_duration&apos;, map[&apos;sql_duration&apos;])&quot; map_action =&gt; &quot;update&quot; end_of_task =&gt; true timeout =&gt; 120 &#125; &#125;&#125; Alteralter filter允许对未包含在正常变异过滤器中的字段进行一般更改。 安装: 1logstash-plugin install logstash-filter-alter 配置项: Setting Input type Required coalesce array No condrewrite array No condrewriteother array No coalesce将file_name的值设置为其参数的第一个非空表达式 condrewrite如果实际内容等于预期内容，则将字段内容更改为指定值 condrewriteother如果另一个字段内容等于预期内容，则将字段内容更改为指定值 cidrCIDR filter用于检查时间中的IP地址与可能包含它的网络块列表。可以针对多个网络检查多个地址，任何匹配都可以成功。成功后，可将其它标记/字段添加到事件中。 配置项: Setting Input_type Required address array No network array No network_path a valid filesystem path No refresh_interval number No separator string No address要检查的IP地址 network要检查的IP网络 network_path包含过滤器应检查的网络的外部文件的完整路径 refresh_interval检查外部文件的更新频率 seperator从network_path指定的外部文件解析网络的分隔符 csvcsv filter处理包含csv数据的事件字段，解析它，并将其存储为单个字段此过滤器还可解析使用任何分隔符的数据，而不仅仅是逗号 配置项: Setting Input_type Required autodetect_column_names boolean No autogenerate_column_names boolean No columns array No convert hash No quote_char string No separator string No skip_empty_columns boolean No skip_empty_rows boolean No skip_header boolean No source string No target string No autodetect_column_names是否应该从标题列自动检测列名称，默认false autogenerate_column_names是否应该自动生成列名，默认true。如果设置为false，那么没有指定header的列将不会被解析 columns列名称的列表 convert应用于列的数据类型转换的集合，可能的转换: integer, float, date, date_time, boolean quote_char用于引用csv字段的字符，默认&quot; separator列分隔符值。默认值comma, skip_empty_columns是否应该跳过空列，默认false skip_empty_rows是否应该跳过空行，默认false skip_header是否应该跳过header，默认false source源字段值中的csv数据将被扩展为数据结构 target放置数据的目标字段 datedate filter从字段中解析日期，然后使用该日期或时间戳作为事件的Logstash时间戳。它对事件排序和回填旧数据尤其重要。在没有此过滤器的情况下，如果timestamp尚未在事件中设置，则Logstash将根据首次查看事件是(input time)选择一个时间戳。 date filter配置项： Setting Input_type Required locale string No match array No tag_on_failure array No target string No timezone string No locale使用POSIX语言标记指定用于日期解析的环境(locale)，如en,en_US如果未指定，则将使用平台默认值 match有字段名称和格式模式的数组，[ field, formats…] 如果时间字段有多种格式，你可这样做: 12345match =&gt; [ &quot;filed-name&quot;, &quot;MMM dd yyyy HH:mm:ss&quot;, &quot;MMM d yyyy HH:mm:ss&quot;, &quot;ISO8601&quot; ]嵌套字段表示[foo][bar] 有几个例外: ISO8601: 解析任何有效的ISO8601时间戳，如2011-04-19T03:44:01.103Z UNIX: 解析float/int Unix原子时间(s) UNIX_MS: 解析int Unix原子时间 TAI64N: 解析tai64n时间值 语法细节:用于解析日期和时间文本的语法使用字母来指示时间值的种类，以及重复的字母来指示该值的形式。 以下是可用于解析日期和时间的内容： y year yyyy完整年号，如2018 yy 两位数年份，如18 M month of the year M最小数字月份,1-12 MM两位数字月份，01-12 MMM缩写的月份文本，Jan, Feb... MMMM完整的月份文本，January, February... d day of the month d最小数字日，1, 2... dd两位数字日，01, 02... H hour of the day H最小数字小时，0, 1... HH两位数字小时，00, 01... m minutes of the hour m最小数字分钟，0, 1... mm两位数字分钟，00, 01... s seconds of the minute s最小数字秒数，0, 1... ss两位数字秒数，00, 01... S 秒的最大精度(毫秒)，附加零 S十分之一秒 SS百分之一秒 SSS千分之一秒 Z time zone offset or identity Z时区偏移量结构为HHmm(如上海)，+0800 ZZ时区偏移量结构为HH:mm，+08:00 ZZZ时区身份(如上海)，Asia/Shanghai z time zone names. Time zone names (z) cannot be parsed w week of the year w最小数字周数，1, 2... ww两位数字周数，01, 02... D day of the year e day of the week(number) E day of the week(text) E, EE, EEE星期几的缩写，Mon, Tue, Wed, Thu, Fri, Sat, Sun EEEE星期几的全文，Monday, Tuesday... 对于非格式化的语法，你需要在值的周围放置单引号字符。如”yyyy-MM-dd’T’HH:mm:ss” tag_on_failure没有成功匹配时，将值附加到tag字段，默认值[&quot;_dateparsefailure&quot;] target将匹配的timestamp存储到给定目标字段中。如果未提供，则默认更新事件的@timestamp字段 timezone指定用于日期分析的时区标准ID，如Asia/Shanghai dissectdissect filter是一种拆分操作。与对整个字符串应用一个分隔符的常规拆分操作不同，此操作将一组分隔符应用于字符串值。dissect不使用正则表达式，所以速度非常快。但是，如果文本结构因行而异，则Grok更适合。有一种混合的情况，dissect可用来结构可靠地重复部分，然后Grok用于余下的字段值，并具有更多的正则表达式可预测性和更少的整体工作。 一组字段和分隔符被称为dissection，它使用一组%来描述: 123field: %&#123;a&#125;delimiter: -%&#123;a&#125; - %&#123;b&#125; - %&#123;c&#125; dissect filter配置项 Setting Input type Required convert_datatype hash No mapping hash No tag_on_failure array No convert_datatype可以指定int, float数据类型转换。这些将在mapping发生后完成，如果没有mapping部分，请自由使用此设置。 12345678filter &#123; dissect &#123; convert_datatype =&gt; &#123; cpu =&gt; &quot;float&quot; code =&gt; &quot;int&quot; &#125; &#125;&#125; mappingA hash of dissections of field =&gt; value不要在值中使用具有转移的\n，它会被看做两个字符\+n+而不是实际的换行符。 12345678910filter &#123; dissect &#123; mapping =&gt; &#123; # using an actual line break &quot;message&quot; =&gt; &apos;&quot;%&#123;field1&#125;&quot; &quot;%&#123;field2&#125;&quot; &quot;%&#123;description&#125;&quot;&apos; &quot;description&quot; =&gt; &quot;%&#123;field3&#125; %&#123;field4&#125; %&#123;field5&#125;&quot; &#125; &#125;&#125; tag_on_failuredissection失败时，将值添加到tag字段。默认值为[&quot;_dissectfailure&quot;] geoipgeoip filter根据Maxmind GeoLite2数据库的数据，添加有关IP地址的地理位置信息。 此插件与GeoLite City Database数据库捆绑在一起。GeoLite2是免费的IP地址位置数据库，与MaxMind的GeoIP2数据库相比，不如其精确。如果需要使用捆绑的DeoLite之外的数据库，可从MaxMind下载它: https://dev.maxmind.com/geoip/geoip2/geolite2/ 如果GeoIP返回查找到的经度(latitude)和纬度(longitude)，则会创建[geoip][location]字段。 Geoip Filter配置项 Setting Inpu_type Required cache_size number No database a valid filesystem path No default_database_type City or ASN No fields array No source string Yes tag_on_failure array No target string No cache_size默认值为1000。GeoIP查询的成本非常高昂。缓存设置的越高，项目在缓存中的可能性就越大，并且此filter运行的越快。但是，如果设置得太高，则会耗费太多内存。如果缓存已满，则无法添加更多记录。尝试使用此选项的不同值来为数据集找到最佳性能。这个值必须大于0。 database地理数据库的文件路径，如果未指定，则默认为logstash自带的GeoLite2-City数据库。 default_database_type默认值是City。唯一可接受的值是City和ASN。 fields包含在事件中的geoip字段数组。可能的字段取决于数据库类型。 source包含要通过geoip映射的IP地址或主机名的字段。 tag_on_failure默认值为[&quot;_geoip_lookup_failure&quot;]. target默认值为geoip.指定Logstash应该存储的geoip数据的字段。 grokParse arbitrary text and structure it.Grok是将非结构化日志数据解析为结构化和可查询的好方法。 它非常适用于syslog, apache or webserver logs, mysql logs以及通常为人类而不是计算机编写的任何日志格式。 默认情况下，Logstash ship附带了大约120种模式。它们在这: https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns要grok某类日志文件的时候，可以先到上面的地址查看有无对应的模式。然后复制对应内容到patterns_dir下，再在filter中使用。当然，你也可以自定义模式来匹配你的日志。在这测试: http://grokdebug.herokuapp.com Grok filter配置项 Setting Input_type Required break_on_match boolean No keep_empty_captures boolean No match hash No named_captures_only boolean No overwrite array No pattern_definitions hash No patterns_dir array No patterns_files_glob string No tag_on_failure array No tag_on_timeout string No timeout_millis number No break_on_matchBreak on first match. grok的第一个成功的匹配将导致filter结束。如果你想grok尝试所有的模式，请将其设置为false。默认值为true。 keep_empty_captures默认值为false。如果为true，则将空捕获保留为事件字段。 matchfield ⇒ value的散列匹配，默认值为{} 123filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; [ &quot;Duration: %&#123;NUMBER:duration&#125;&quot;, &quot;Speed: %&#123;NUMBER:speed&#125;&quot; ] &#125; &#125;&#125; named_captures_only默认值为true。如果为true，只保存来自grok的命名捕获。 overwrite要覆盖的字段，这使你可覆盖已存在的字段中的值。 123456filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;SYSLOGBASE&#125; %&#123;DATA:message&#125;&quot; &#125; overwrite =&gt; [ &quot;message&quot; ] &#125;&#125; pattern_definitions默认值为{}模式名称和模式元组的散列，用于定义当前过滤器要使用的自定义模式。匹配现用名称的模式将覆盖预先存在的定义。 patterns_dir默认值为[]logstash默认提供了一堆模式，除非添加额外模式，否则不需要自定义模式。你可以使用此设置指向多个模式目录。grok将读取与patterns_files_glob匹配的目录汇总的所有文件，并假定它为模式文件。 1patterns_dir =&gt; [&quot;/opt/logstash/patterns&quot;, &quot;/opt/logstash/extra_patterns&quot;] patterns_files_glob默认值为&quot;*&quot;Glob模式，用于从patterns_dir目录中选择模式文件。 tag_on_failure默认值为[&quot;_grokparsefailure&quot;]匹配没有成功时，将值添加到tags字段。 tag_on_timeout默认值为&quot;_groktimeout&quot;如果grok正则表达式超时，则应用此tag. timeout_millis默认值为30000尝试在这段时间后终止正则表达式。设置为0以禁用超时。 基础知识Grok工作方式，将文本模式组合成与你的日志模式相匹配的内容。 Grok模式的语法为 %{SYNTAX:SEMANTIC} SYNTAX, 文本匹配的模式的名称 SEMANTIC, 正在匹配的文本的标识符 1%&#123;NUMBER:duration&#125; %&#123;IP:client&#125; 你也可以将数据类型转换添加到Grok模式。默认情况下，所有的语义(semantic)都保存为字符串(strings)。如果你想转换语义的数据类型，如将string转换为int。例如%{NUMBER:num:int}将num语义从string转换为integer。当前情况下，只支持转换为int和float. 12345678910111213141516日志格式55.3.244.1 GET /index.html 15824 0.043grok pattern grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;IP:client&#125; %&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; %&#123;NUMBER:bytes&#125; %&#123;NUMBER:duration&#125;&quot; &#125; &#125;grok filter之后的格式client: 55.3.244.1method: GETrequest: /index.htmlbytes: 15824duration: 0.043 正则表达式Grok位于正则表达式之上，所以任何正则表达式在grok中都是有效的。Regular Expression Library: https://github.com/kkos/oniguruma/blob/master/doc/RE 示例grok处理nginx/access.log日志:首先针对nginx.conf中日志格式来决定如何写logstash pattern 1234567891011121314mkdir /etc/logstash/patternsvim nginxNGINX_ACCESS %&#123;IPORHOST:clientip&#125; (?:-|(%&#123;WORD&#125;.%&#123;WORD&#125;)) %&#123;USER:ident&#125; \[%&#123;HTTPDATE:timestamp&#125;\] &quot;(?:%&#123;WORD:verb&#125; %&#123;NOTSPACE:request&#125;(?: HTTP/%&#123;NUMBER:httpversion&#125;)?|%&#123;DATA:rawrequest&#125;)&quot; %&#123;NUMBER:response&#125; (?:%&#123;NUMBER:bytes&#125;|-) %&#123;QS:referrer&#125; %&#123;QS:agent&#125; %&#123;QS:forwarder&#125;grok &#123; patterns_dir =&gt; &quot;/etc/logstash/patterns&quot; match =&gt; &#123; &quot;message&quot; =&gt; %&#123;NGINX_ACCESS&#125;&#125;&#125; grok debugger grok-patterns这是grok官方写得patterns，当然，你也可以自己写。就像Nginx日志那样！ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495USERNAME [a-zA-Z0-9._-]+USER %&#123;USERNAME&#125;EMAILLOCALPART [a-zA-Z][a-zA-Z0-9_.+-=:]+EMAILADDRESS %&#123;EMAILLOCALPART&#125;@%&#123;HOSTNAME&#125;INT (?:[+-]?(?:[0-9]+))BASE10NUM (?&lt;![0-9.+-])(?&gt;[+-]?(?:(?:[0-9]+(?:\.[0-9]+)?)|(?:\.[0-9]+)))NUMBER (?:%&#123;BASE10NUM&#125;)BASE16NUM (?&lt;![0-9A-Fa-f])(?:[+-]?(?:0x)?(?:[0-9A-Fa-f]+))BASE16FLOAT \b(?&lt;![0-9A-Fa-f.])(?:[+-]?(?:0x)?(?:(?:[0-9A-Fa-f]+(?:\.[0-9A-Fa-f]*)?)|(?:\.[0-9A-Fa-f]+)))\bPOSINT \b(?:[1-9][0-9]*)\bNONNEGINT \b(?:[0-9]+)\bWORD \b\w+\bNOTSPACE \S+SPACE \s*DATA .*?GREEDYDATA .*QUOTEDSTRING (?&gt;(?&lt;!\\)(?&gt;&quot;(?&gt;\\.|[^\\&quot;]+)+&quot;|&quot;&quot;|(?&gt;&apos;(?&gt;\\.|[^\\&apos;]+)+&apos;)|&apos;&apos;|(?&gt;`(?&gt;\\.|[^\\`]+)+`)|``))UUID [A-Fa-f0-9]&#123;8&#125;-(?:[A-Fa-f0-9]&#123;4&#125;-)&#123;3&#125;[A-Fa-f0-9]&#123;12&#125;# URN, allowing use of RFC 2141 section 2.3 reserved charactersURN urn:[0-9A-Za-z][0-9A-Za-z-]&#123;0,31&#125;:(?:%[0-9a-fA-F]&#123;2&#125;|[0-9A-Za-z()+,.:=@;$_!*&apos;/?#-])+# NetworkingMAC (?:%&#123;CISCOMAC&#125;|%&#123;WINDOWSMAC&#125;|%&#123;COMMONMAC&#125;)CISCOMAC (?:(?:[A-Fa-f0-9]&#123;4&#125;\.)&#123;2&#125;[A-Fa-f0-9]&#123;4&#125;)WINDOWSMAC (?:(?:[A-Fa-f0-9]&#123;2&#125;-)&#123;5&#125;[A-Fa-f0-9]&#123;2&#125;)COMMONMAC (?:(?:[A-Fa-f0-9]&#123;2&#125;:)&#123;5&#125;[A-Fa-f0-9]&#123;2&#125;)IPV6 ((([0-9A-Fa-f]&#123;1,4&#125;:)&#123;7&#125;([0-9A-Fa-f]&#123;1,4&#125;|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;6&#125;(:[0-9A-Fa-f]&#123;1,4&#125;|((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;)|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;5&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,2&#125;)|:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;)|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;4&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,3&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)?:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;3&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,4&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,2&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;2&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,5&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,3&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;1&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,6&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,4&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(:(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,7&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,5&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:)))(%.+)?IPV4 (?&lt;![0-9])(?:(?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5]))(?![0-9])IP (?:%&#123;IPV6&#125;|%&#123;IPV4&#125;)HOSTNAME \b(?:[0-9A-Za-z][0-9A-Za-z-]&#123;0,62&#125;)(?:\.(?:[0-9A-Za-z][0-9A-Za-z-]&#123;0,62&#125;))*(\.?|\b)IPORHOST (?:%&#123;IP&#125;|%&#123;HOSTNAME&#125;)HOSTPORT %&#123;IPORHOST&#125;:%&#123;POSINT&#125;# pathsPATH (?:%&#123;UNIXPATH&#125;|%&#123;WINPATH&#125;)UNIXPATH (/([\w_%!$@:.,+~-]+|\\.)*)+TTY (?:/dev/(pts|tty([pq])?)(\w+)?/?(?:[0-9]+))WINPATH (?&gt;[A-Za-z]+:|\\)(?:\\[^\\?*]*)+URIPROTO [A-Za-z]([A-Za-z0-9+\-.]+)+URIHOST %&#123;IPORHOST&#125;(?::%&#123;POSINT:port&#125;)?# uripath comes loosely from RFC1738, but mostly from what Firefox# doesn&apos;t turn into %XXURIPATH (?:/[A-Za-z0-9$.+!*&apos;()&#123;&#125;,~:;=@#%&amp;_\-]*)+#URIPARAM \?(?:[A-Za-z0-9]+(?:=(?:[^&amp;]*))?(?:&amp;(?:[A-Za-z0-9]+(?:=(?:[^&amp;]*))?)?)*)?URIPARAM \?[A-Za-z0-9$.+!*&apos;|()&#123;&#125;,~@#%&amp;/=:;_?\-\[\]&lt;&gt;]*URIPATHPARAM %&#123;URIPATH&#125;(?:%&#123;URIPARAM&#125;)?URI %&#123;URIPROTO&#125;://(?:%&#123;USER&#125;(?::[^@]*)?@)?(?:%&#123;URIHOST&#125;)?(?:%&#123;URIPATHPARAM&#125;)?# Months: January, Feb, 3, 03, 12, DecemberMONTH \b(?:[Jj]an(?:uary|uar)?|[Ff]eb(?:ruary|ruar)?|[Mm](?:a|ä)?r(?:ch|z)?|[Aa]pr(?:il)?|[Mm]a(?:y|i)?|[Jj]un(?:e|i)?|[Jj]ul(?:y)?|[Aa]ug(?:ust)?|[Ss]ep(?:tember)?|[Oo](?:c|k)?t(?:ober)?|[Nn]ov(?:ember)?|[Dd]e(?:c|z)(?:ember)?)\bMONTHNUM (?:0?[1-9]|1[0-2])MONTHNUM2 (?:0[1-9]|1[0-2])MONTHDAY (?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9])# Days: Monday, Tue, Thu, etc...DAY (?:Mon(?:day)?|Tue(?:sday)?|Wed(?:nesday)?|Thu(?:rsday)?|Fri(?:day)?|Sat(?:urday)?|Sun(?:day)?)# Years?YEAR (?&gt;\d\d)&#123;1,2&#125;HOUR (?:2[0123]|[01]?[0-9])MINUTE (?:[0-5][0-9])# &apos;60&apos; is a leap second in most time standards and thus is valid.SECOND (?:(?:[0-5]?[0-9]|60)(?:[:.,][0-9]+)?)TIME (?!&lt;[0-9])%&#123;HOUR&#125;:%&#123;MINUTE&#125;(?::%&#123;SECOND&#125;)(?![0-9])# datestamp is YYYY/MM/DD-HH:MM:SS.UUUU (or something like it)DATE_US %&#123;MONTHNUM&#125;[/-]%&#123;MONTHDAY&#125;[/-]%&#123;YEAR&#125;DATE_EU %&#123;MONTHDAY&#125;[./-]%&#123;MONTHNUM&#125;[./-]%&#123;YEAR&#125;ISO8601_TIMEZONE (?:Z|[+-]%&#123;HOUR&#125;(?::?%&#123;MINUTE&#125;))ISO8601_SECOND (?:%&#123;SECOND&#125;|60)TIMESTAMP_ISO8601 %&#123;YEAR&#125;-%&#123;MONTHNUM&#125;-%&#123;MONTHDAY&#125;[T ]%&#123;HOUR&#125;:?%&#123;MINUTE&#125;(?::?%&#123;SECOND&#125;)?%&#123;ISO8601_TIMEZONE&#125;?DATE %&#123;DATE_US&#125;|%&#123;DATE_EU&#125;DATESTAMP %&#123;DATE&#125;[- ]%&#123;TIME&#125;TZ (?:[APMCE][SD]T|UTC)DATESTAMP_RFC822 %&#123;DAY&#125; %&#123;MONTH&#125; %&#123;MONTHDAY&#125; %&#123;YEAR&#125; %&#123;TIME&#125; %&#123;TZ&#125;DATESTAMP_RFC2822 %&#123;DAY&#125;, %&#123;MONTHDAY&#125; %&#123;MONTH&#125; %&#123;YEAR&#125; %&#123;TIME&#125; %&#123;ISO8601_TIMEZONE&#125;DATESTAMP_OTHER %&#123;DAY&#125; %&#123;MONTH&#125; %&#123;MONTHDAY&#125; %&#123;TIME&#125; %&#123;TZ&#125; %&#123;YEAR&#125;DATESTAMP_EVENTLOG %&#123;YEAR&#125;%&#123;MONTHNUM2&#125;%&#123;MONTHDAY&#125;%&#123;HOUR&#125;%&#123;MINUTE&#125;%&#123;SECOND&#125;# Syslog Dates: Month Day HH:MM:SSSYSLOGTIMESTAMP %&#123;MONTH&#125; +%&#123;MONTHDAY&#125; %&#123;TIME&#125;PROG [\x21-\x5a\x5c\x5e-\x7e]+SYSLOGPROG %&#123;PROG:program&#125;(?:\[%&#123;POSINT:pid&#125;\])?SYSLOGHOST %&#123;IPORHOST&#125;SYSLOGFACILITY &lt;%&#123;NONNEGINT:facility&#125;.%&#123;NONNEGINT:priority&#125;&gt;HTTPDATE %&#123;MONTHDAY&#125;/%&#123;MONTH&#125;/%&#123;YEAR&#125;:%&#123;TIME&#125; %&#123;INT&#125;# ShortcutsQS %&#123;QUOTEDSTRING&#125;# Log formatsSYSLOGBASE %&#123;SYSLOGTIMESTAMP:timestamp&#125; (?:%&#123;SYSLOGFACILITY&#125; )?%&#123;SYSLOGHOST:logsource&#125; %&#123;SYSLOGPROG&#125;:# Log LevelsLOGLEVEL ([Aa]lert|ALERT|[Tt]race|TRACE|[Dd]ebug|DEBUG|[Nn]otice|NOTICE|[Ii]nfo|INFO|[Ww]arn?(?:ing)?|WARN?(?:ING)?|[Ee]rr?(?:or)?|ERR?(?:OR)?|[Cc]rit?(?:ical)?|CRIT?(?:ICAL)?|[Ff]atal|FATAL|[Ss]evere|SEVERE|EMERG(?:ENCY)?|[Ee]merg(?:ency)?) json这是一个json解析过滤器。 Json Filter配置项 Setting Input_type Required skip_on_invalid_json boolean No source string Yes tag_on_failure array No target string No skip_on_invalid_json默认值是false.允许跳过无效json上的过滤器。 sourcejson filter的配置如，从message字段中解析json 12345filter &#123; json &#123; source =&gt; &quot;message&quot; &#125;&#125; target定义放置解析数据的目标字段。如果目标字段已存在，则它会被覆盖。 12345filter &#123; json &#123; target =&gt; &quot;doc&quot; &#125;&#125; kv此过滤器有助于自动解析key=value类型的消息。这对于postfix, iptables和倾向于key=value语法类型的日志非常有用。 123456789101112#beforeip=1.2.3.4 error=REFUSEDfilter &#123; kv &#123;&#125;&#125;#afterip: 1.2.3.4error: REFUSED kv filter配置项 Setting Input_type Required allow_duplicate_values boolean No default_keys hash No exclude_keys array No field_split string No include_brackets boolean No include_keys array No prefix string No recursive boolean No remove_char_key string No remove_char_value string No source string No target string No transform_key string, one of [“lowercase”, “uppercase”, “capitalize”] No transform_value string, one of [“lowercase”, “uppercase”, “capitalize”] No trim_key string No trim_value string No value_split string No allow_duplicate_values默认值为true.用于删除重复 键/值对的布尔选项。 default_keys默认值为{}.一个散列，用于指定在解析源字段中不存在的键时应添加到事件中的默认值及其值。 exclude_keys默认值为[].一个数组，用于指定不应添加到事件中的解析键。默认情况下，没有键被排除。 field_split默认值为&quot; &quot;.用作解析出键值对后的单字符字段分隔符的字符串。 12345678#栗子name=zhang21&amp;age=25&amp;email=ab123@gamil.comfilter &#123; kv &#123; field_split =&gt; &quot;&amp;&quot; &#125;&#125; field_split_pattern一个正则表达式，用作字段分隔符来解析键值对。用于定义多字符字段分隔符。它优先于field_split选项。 12345678#栗子k1=v1:k2=v2:::k3=v3::k4=v4filter &#123; kv &#123; field_split_pattern =&gt; &quot;:+&quot; &#125;&#125; include_brackets默认值为true.一个布尔值，指定是否将 方括号[square bracket]，尖括号和括号(bracket) 视为的包装器(wrapper)，是否应该从值中删除。 12345678910111213#栗子one=(o n e) two=[t w o] three=&lt;t h r e e&gt;filter &#123; kv &#123; include_brackets =&gt; tree &#125;&#125;#afterone: o n etwo: t w othree: t h r e e include_keys默认值为[].一个数字，用于指定应该添加到解析的键。默认情况下，所有的键都会被添加。 prefix默认值为空。预先添加到所有提取的键的字符串。 recursive默认值为false.一个布尔值，执行是否向下提取值并递归获取更多的键值对。 remove_char_key要从键中移除的字符串。 remove_char_value要从值中移除的字符串。 source默认值为message.要在其上执行key=value搜索的字段。 target将所有键值对放入的容器的名称。 transform_key将键转换为大写，小写。 transform_value将值转换为大写，小写 trim_key从键中修建的字符串。如果键包含在括号中或以空格开头，这很有用。 trim_value从值中修建的字符串。如果你的值包含在括号中或以逗号结尾。这很有用。 value_split默认值为=.一个非空字符串，用作解析出键值对的单字符分隔符。 value_split_pattern用作值分隔符来解析出键值对的正则表达式。优先级高于value_split。 metricsmetrics filter用于聚合度量(aggregating metrics). 12345678#计算每种http响应吗filter &#123; metrics &#123; meter =&gt; [ &quot;http_%&#123;response&#125;&quot; ] add_tag =&gt; &quot;metric&quot; &#125;&#125; metrics filter配置项 Setting Input_type Required clear_interval number No flush_interval number No ignore_older_than number No meter array No percentiles array No rates array No timer hash No clear_interval默认值为-1.清理间隔，所有的计数器都被重置。 flush_interval默认值为5.刷新间隔，当metrics事件被创建时。此值必须是5的倍数。 ignore_older_than默认值为0.不要跟着@timestamp超过某个秒数的事件。 meter语法: meter =&gt; [ &quot;name of metric&quot;, &quot;name of metric&quot; ] percentiles默认值为percentiles.计时器值应该测量和发出的百分位数。 rates默认值为[1, 5, 15].应该按分钟测量的比率。 timer语法: timer =&gt; [ &quot;name of metric&quot;, &quot;%{time_value}&quot; ] meter valuesmeter =&gt; &quot;something&quot;, 会收到如下字段: “[thing][count]” - the total count of events “[thing][rate_1m]” - the per-second event rate in a 1-minute sliding window “[thing][rate_5m]” - the per-second event rate in a 5-minute sliding window “[thing][rate_15m]” - the per-second event rate in a 15-minute sliding window timer valuestimer =&gt; { &quot;thing&quot; =&gt; &quot;%{duration}&quot;}, 会收到如下字段: “[thing][count]” - the total count of events “[thing][rate_1m]” - the per-second average value in a 1-minute sliding window “[thing][rate_5m]” - the per-second average value in a 5-minute sliding window “[thing][rate_15m]” - the per-second average value in a 15-minute sliding window “[thing][min]” - the minimum value seen for this metric “[thing][max]” - the maximum value seen for this metric “[thing][stddev]” - the standard deviation for this metric “[thing][mean]” - the mean for this metric “[thing][pXX]” - the XXth percentile for this metric (see percentiles) mutatemutate filter允许你在字段上执行常规突变。你可以重命名，删除，替换和修改事件中的字段。 mutate filter配置项 Setting Input_type Required convert hash No copy hash No gsub array No join hash No lowercase array No merge hash No coerce hash No rename hash No replace hash No split hash No strip array No update hash No uppercase array No capitalize array No convert将字段的值转换为其它类型，如将string转换为int.如果只为数组，则所有成员都将转换；如果是散列，则不处理。 copy将现有字段复制到另一个字段(会覆盖)。 gsub将正则表达式与字段值进行匹配，并用替换字符替换所有匹配项。只支持string或string array. 1234567filter &#123; mutate &#123; gsub =&gt; [ &quot;field1&quot;, &quot;value&quot;, &quot;replacement string&quot;, ] &#125;&#125; join加入一个带分隔符的数组。对非数组字段没有任何作用。 lowercase将字符串转换为小写 merge合并数组或散列的两个字段。字符串字段将被自动转换为数组。 12345filter &#123; mutate &#123; merge =&gt; &#123; &quot;dest_field&quot; =&gt; &quot;added_field&quot;&#125; &#125;&#125; coerce为已存在但为空的字段设置默认值。 rename重命名一个或多个字段。 replace用新值替换一个字段。新值可以包含%{foo}字符串，以帮助你从事件的其它部分创建新值。 1234567filter &#123; mutate &#123; replace =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;source_host&#125;: My new message&quot; &#125; &#125;&#125; split使用分隔符将字段拆分为数组。只适用于字符串字段。 strip从字段剥离空白符。 update用新值更新现有字段。 xmlXML filter.获取包含XML的字段并将其展开为实际的数据结构。 XML Filter配置项 Setting Input_type Required force_array boolean No force_content boolean No namespaces hash No remove_namespaces boolean No source string Yes store_xml boolean No suppress_empty boolean No target string No xpath hash No force_array默认值为true.过滤器强制单个元素为数组。将其设置为false防止在数组中存储单个元素。 force_content默认值为false.过滤器将以不同于标签内的内容的方式展开属性。 namespace默认值为{}.这允许配置所有命名空间声明来解析XML文档。 12345678filter &#123; xml &#123; namespaces =&gt; &#123; &quot;xsl&quot; =&gt; &quot;http://www.w3.org/1999/XSL/Transform&quot; &quot;xhtml&quot; =&gt; &quot;http://www.w3.org/1999/xhtml&quot; &#125; &#125;&#125; remove_namespaces从文档中的所有节点中删除所有命名空间。 source store_xml默认为true.过滤器会将整个解析的XML存储在目标字段中。 suppress_empty默认值为true.默认情况下，如果元素为空，这不输出。如果设置为false,则空元素将产生一个空的散列对象。 target定义放置数据的目标。 条件判断使用条件判断决定filter和output处理特定的事件。 Logstash条件类似于编程语言，条件语句，可以嵌套： if else if else 比较操作： == != &lt; &gt; &lt;= &gt;= =~ 匹配正则 !~ 不匹配正则 in 包含 not in 不包含 布尔操作： and or nand xor 一元运算符： ! 取反 () 复合表达式 栗子： 1234567891011121314151617181920output &#123; if [path] == &quot;/var/nginx/access.log&quot; &#123; elasticsearch &#123; hosts =&gt; user =&gt; password =&gt; index =&gt; &quot;nginx-access-%&#123;+YYYY.MM.dd&#125;&quot; &#125; &#125; else if [path] == &quot;/var/nginx/error.log&quot; &#123; elasticsearch &#123; hosts =&gt; user =&gt; password =&gt; index =&gt; &quot;nginx-error-%&#123;+YYYY.MM.dd&#125;&quot; &#125; &#125; else &#123; &#125;&#125; Filebeat文档 概述filebeat是一个beat，它基于libbeat框架。 Filebeat是一个本地文件的日志数据搬运(shipper)。作为Agent安装，filebeat监视日志目录或指定的日志文件，并将它们转发给Elasticsearch或logstash进行索引。启动filebeat时，它会启动一个或多个prospectors(勘探者)，查看为日志指定的本地路径。对于prospectors所在的每个日志文件，filebeat启动harvester。每个harvester为新内容读取单一日志文件，并将新日志发送到filebeat配置的输出。 入门开始filebeat前，请确保安装和配置了如下产品： Elasticsearch(存储和索引数据) Kibana(UI) Logstash(可选) 配置filebeat module为常用日志格式提供了入门体验。 123456789101112131415161718vim /etc/filebeat/filebeat.ymlfilebeat.prospectors: -type: log enabled: true paths: - /var/log/*.logoutput.elasticsearch: hosts: [ &quot;ip:9200&quot; ] #username #passwordsetup.kibana: host: &quot;localhost:5601&quot; #username #password 配置filebeat使用logstash123456vim /etc/filebeat/filebeat.ymloutput.logstash: hosts: [ &quot;127.0.0.1:5044&quot; ]#logstash需要配置监听beats 在Elasticsearch中载入索引模板在Elasticsearch中，索引模板用于定义设置(setting)和映射(mapping)，以确定如何分析字段(fields)。 filebeat推荐的索引模板文件有filebeat软件包安装。在成功连接到Elasticsearch后，它会默认自动载入索引模板(fields.yml)。如果模板存在，它不会覆盖除，除非你配置要覆盖。通过修改配置文件，你也可以禁用自动载入模板，或者载入你自己的模板。 配置模板载入 1234567891011vim /etc/filebeat/filebeat.ymlsetup.template.name: &quot;template-name&quot;setup.template.fields: &quot;/path/xxx/xxx.yml&quot;#强制覆盖已存在模板setup.template.overwrite: true#关闭自动载入模板setup.template.enabled: false 修改索引名 filebeat的默认索引名为 filebeat-&lt;version&gt;-yyyy.MM.dd 在output.elasticsearch设置选项 你指定的索引名称应该包含索引的根名、索引版本和日期信息 1234output.elasticsearch.index: &quot;customname-%&#123;[version]&#125;-%&#123;+yyyy.MM.dd&#125;&quot;setup.template.name: &quot;customname&quot;setup.template.pattern: &quot;customname-*&quot;setup.dashboards.index: &quot;customname-*&quot; 手动载入模板 1filebeat setup --template 强制Kibana查看最新文件 1curl -XDELETE &apos;http://localhost:9200/filebeat-*&apos; 设置Kibana面板Filebeat附带了实例的Kibana dashboards, visualization和可视化搜索。在使用仪表板前，你需要创建索引filebeat-*，并将仪表板加载到Kibana中。你可使用setup命令或配置文件加载它。 启动Filebeat1234systemctl start filebeat#前台启动并查看相关信息filebeat -e -c filebeat.yml 查看示例Kibana仪表板访问你的kibana web端(localhost:5601)，可用Nginx做反向代理，再加上域名解析。 快速开始常见日志格式filebeat提供了一套预构建模块，可使用它快速实施和部署日志监视方案。 先决条件： 安装和配置Elastic Stack 安装filebeat 安装Ingest Node GeoIP和User Agent plugins 验证Elasticsearch和Kibana能从filebeat接收数据 12elasticsearch-plugin install ingest-geoipelasticsearch-plugin install ingest-user-agent 运行filebeat模块 12345678#启用模块filebeat modules enable nginx system#配置pathcd /etc/filebeat/modules.dvim nginx.ymlvim system.yml 最后就可以在Kibana中可视化查看日志。 查看dashboard时，遇到一个错误: Could not locate that index-pattern (id: filebeat-*) 解决办法： 12#重新载入索引模板filebeat setup output我们可根据系统的负载情况将Filebeat的output到合适的地方，output只能有一个！如果有时候系统负载过高的话，可以考虑output到Redis或Elasticsearch。 redis和logstash都还需要logstash的pipeline转交给Elasticsearch，但你可以filter。而直接使用Elasticsearch便不能过滤。 Logstash Elasticsearch Redis 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556vim /etc/filebeat/filebeat.yml#找到output#redisoutput.redis: hosts: &quot;localhost&quot; port: 6379 key: &quot;filebeat&quot; #自定义key-name #password: #db: #data_type: &apos;list&apos;#logstashoutput.logstash: hosts: [ &quot;localhost:5044&quot; ]#Elasticsearchelasticsearch.output: hosts: [ &quot;localhost:9200&quot; ] #username: #name:==================#redis对应的pipelinevim /etc/logstash/conf.d/redis-pipeline.confinput &#123; redis &#123; data_type =&gt; &quot;list&quot; key =&gt; &quot;filebeat&quot; host =&gt; &quot;localhost&quot; port =&gt; 6379 #password =&gt; #db =&gt; &#125;&#125;#filter&#123; &#125;output &#123; elasticsearch &#123; hosts =&gt; [ &quot;localhost:9200&quot; ] #user #password index =&gt; &quot;filebeat-%&#123;+YYYY.MM.dd&#125;&quot; &#125;&#125; 定义索引为filebeat定义index: 123456789101112131415161718192021222324vim /etc/filebeat/filebeat.yml# Optional index name. The default is &quot;filebeat&quot; plus date# and generates [filebeat-]YYYY.MM.DD keys.# In case you modify this pattern you must update setup.template.name and setup.template.pattern accordingly.#index: &quot;filebeat-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;&quot;#写到事件中的索引名，默认 &quot;filebeat-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;&quot;#如果更改此设置，还需要配置setup.template.name和setup.template.pattern选项#如果使用的是预先构建的kibana dashboard，还需要配置setup.dashboards.index选项#定义索引output.elasticsearch: hosts: [&quot;10.0.1.8:9002&quot;, &quot;10.0.1.7:9002&quot;, &quot;10.0.1.9:9002&quot;] loadbalance: true username: &quot;elastic&quot; password: xxx index: &quot;filebeat-publish-%&#123;+yyyy.MM.dd&#125;&quot;#添加这几项setup.template.name: &quot;filebeat&quot;setup.template.pattern: &quot;filebeat-*&quot;setup.template.fields: &quot;fields.yml&quot;setup.template.overwrite: false 配置RPM安装的配置文件默认是/etc/filebeat/filebeat.yml，还有一个完整的示例配置文件/etc/filebeat/filebeat.reference.yml，显示了所有未弃用的选项。配置文件使用YAML语法。 指定运行moduleSpecify which modules to run Filebeat module提供了一种快速处理常见日志格式的方法。它包含默认配置。 有几种不同方法来启用modules: 配置modules.d目录 filebeat命令启动 配置filebeat.yml文件 1234567891011121314#modules.dfilebeat modules listfilebeat modules enable nginx#filebeat modules disable nginx#filebeat命令./filebeat -e --modules nginx#filebeat.ymlfilebeat.modules:- module: nginx- module: system 指定变量设置Specify variable settings 每个模块和文件集合都有变量，你可以设置这些变量来更改木块的默认行为。 12345678- module: nginx access: var.path: [&quot;/var/log/nginx/access.log*&quot;]#orfilebeat -M &quot;nginx.access.var.paths=[/var/log/access.log*]&quot;filebeat --modules nginx -M &quot;nginx.access.var.paths=[/var/log/nginx/access.log*]&quot; -M &quot;nginx.error.var.paths=[/var/log/nginx/error.log*]&quot; 高级设置在幕后，每个木块都会启动filebeat input。高级用户可以添加或覆盖任何input设置。 12345678910- module: nginx access: input: close_eof: true#orfilebeat -M &quot;nginx.access.input.close_eof=true&quot;filebeat --modules nginx -M &quot;nginx.access.input.close_eof=true&quot; 读取动态文件名filbeat配置文件虽然可以将索引设置为: indexname-%{+yyyy.MM.dd} 的日志格式，但这个是发送给ES的，ES可以处理此配置，但filebeat是无法直接处理的，它会把它当做普通字符。假如我要读取一个按日期取名的日志文件，如service_20180808.log，filebeat配置文件中是无法直接配置和处理。后来想到，可以用sh写一个脚本来做此操作。 1234567891011yesterday=`/bin/date +%Y%m%d --date='-1days'`today=`/bin/date +%Y%m%d`/bin/sed -i "s/service_err_$&#123;yesterday&#125;/service_err_$&#123;today&#125;/" /etc/filebeat/filebeat.yml/bin/filebeat test configif [ $? -eq 0 ] ;then /bin/systemctl restart filebeatelse exit 0fi inputDEPRECATED: prospectors are deprecated, Use inputs instead. Will be removed in version: 7.0.0要手动配置filebeat(而不是使用modules)，需要在filebeat.yml的filebeat.inputs部分指定输入列表(一个YAML 数据)。你可指定多个输入，并可多次指定相同的输入类型。 input types log stdin redis udp docker tcp syslog input 通用选项： 12345678910111213141516171819202122232425262728#启用/禁用inputsenabled#增加tags字段tags#向输出添加其他信息fieldsfilebeat.inputs:- type: log fields: author: zhang21#自定义字段存储为输出文档中的顶级字段，而不是在字段子字典下分组。如果与filebeat冲突，则会覆盖源字段fields_under_root#应用于inputs的处理器列表#已被弃用processors#为input生成的事件设置ingest node pipeline idpipeline log使用log input从日志文件中读取行。 12345filebeat.inputs:- type: log paths: - /var/log/messages - /var/log/*.log 你可以将其它配置设置(fields, include_lines, exclude_lines, mutiline)应用于从日志文件获取的行。这里指定的选项将应用于input的所有文件。将不同的配置应用于不同的文件，需要定义多个input sections: 1234567891011filebeat.inputs:- type: log paths: - /var/log/1.log - /var/log/2.log- type: log paths: - "/var/log/appache/*" fields: apache: true fields_under_root: true log input 配置项 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123paths#将读取的基于全局路径的列表recursive_glob.enabled#true允许扩展为递归模式encoding#读取数据的文件编码exclude_lines#正则表达式列表，用于匹配你希望filebeat排除的行filebeat.inputs:- type: log ... exclude_lines: ['^debug']include_lines#正则表达式列表，用于匹配你希望filebeat包含的行。#如果`exclude_lines`和`include_lines`都定义了，filebeat首先执行`include_lines`，之后才执行`exclude_lines`。filebeat.inputs:- type: log ... include_lines: ['^ERR', '^WARN']harvester_buffer_size#每个收集器在获取文件时使用的buffer大小，默认 16 384Byte。max_bytes#单日志消息可以具有的最大字节数。默认 10MBjson#此选项使filebeat解码日志结构为json消息。filebeat逐行处理日志，因此每一行要有json对象才有效。json.keys_under_rootjson.overwrite_keysjson.add_error_keyjson.message_keyjson.ignore_decoding_errormutiline#控制filebeat如果处理跨越多行的日志消息。exclude_files#正则表达式列表，用于匹配你希望filebeat忽略的文件。默认无。filebeat.inputs:- type: log ... exclude_files: ['\.gz$']ignore_older#如果启用此选项，filebeat将忽略在指定的事件跨度之前修改的所有文件。close_*#用于在某个标准或时间后关闭收集器。close_inactive#如果文件尚未在指定的时间内收获，则filebeat将关闭文件句柄。close_renamed#filebeat会在重命名文件时关闭文件处理程序，请注意日志轮询。close_removed#删除文件后，filebeat会关闭收集器。close_eof#一旦到达文件末尾，filebeat就会关闭文件。clean_*#用于清理注册表文件中的状态条目。clean_inactive#filebeat在指定的不活动事件段过去后删除文件的状态。clean_removed#如果在最后一个已知名称下无法在磁盘上找到文件，则filebeat会清除注册表中的文件。scan_frequency#filebeat检查指定路径文件的频率。官方不建议将此值设置为小于1s。默认 10s。tail_files#filebeat开始在每个文件的末尾而不是开头读取新文件。默认 falsesymlinks#允许filebeat收集符号链接，它读取符号链接的原始文件。由于此选项可能会导致数据丢失，默认 disabledbackoff#指定filebeat如何积极地抓取打开的文件以进行更新。max_backoff#在到达eof后再次检查文件之间filebeat等待的最长时间。backoff_factor#指定等待时间增加的速度。harvester_limit#限制一个input并行启动的收集器数量。 stdin使用stdin input从标准输入读取事件。此输入不可与其它输入类型同时运行。 12filebeat.inputs:- type: stdin stdin input 配置项： 123456789101112encodingexclude_linesinclude_linesharvester_buffer_sizemax_bytesjsonmultiline udp使用 udp input通过udp读取事件。 1234filebeat.inputs:- type: udp max_message_size: 10KB host: "localhost:5678" udp input 配置项： 123456#通过udp接收的最大消息大小，默认 10KBmax_message_size#udp hosthost tcp使用 tcp input 通过tcp读取事件。 1234filebeat.inputs:- type: tcp max_message_size: 10MB host: "localhost:5679" tcp input 配置项： 1234567891011121314max_message_size#通过tcp接收的最大消息大小， 默认 10MB#host and tcp porthost#指定用于拆分事件的字符，默认 \nline_delimiter#关闭连接前不活动的秒数， 默认 300stimeout docker使用docker input从docker container读取日志。 12345678filebeat.inputs:- type: docke containers: path: "/var/lib/docker/containers" stream: "all" ids: - 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'#必须填写容器ID docker input 配置项： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960container.ids#默认 /var/lib/docker/containerscontainer.path#从指定stream读取: all/stdout/stderr，默认 allcontainer.streamencodingexclude_lineinclude_lineharvester_buffer_sizemax_bytesjsonmultilineexclude_filesignore_olderclose_*close_inactiveclose_renamedclose_removedclose_eofclose_timeoutclean_*clean_inactiveclean_removedsacn_frequencytail_filessymlinksbackoffmax_backoffbackoff_factorharvester_limit syslog使用 syslog input通过tcp/udp/读取事件。 修改syslog配置： 123456vim /etc/rsyslog.d/filebeat.conf*.* @127.0.0.1:5678#重启服务systemctl restart rsyslog 123456789101112131415filebeat.inputs:- type: syslog protocol.udp: host: "localhost:5678" max_message_size: 100KB#定义索引setup.template.name: "filebeat"setup.template.pattern: "filebeat-*"setup.template.fields: "fields.yml"setup.template.overwrite: falseout.elastisearch： hosts: ["localhost:9200"] index: "syslog-%&#123;+yyyy.MM.dd&#125;" 它的配置项就是tcp/udp的配置项。 之后查看主机端口情况： 123netstat -nltup | grep 5678udp 0 0 127.0.0.1:5678 0.0.0.0:* 12434/filebeat output你可以通过在filebet.yml配置文件的output部分设置选项来配置filebeat以特定方式输出。只能定义一个输出。 filebeat支持如下输出： Elasticsearch Logstash Kafka Redis File Console elasticsearchfilebeat使用es http api将事务发送到es。 12345678output.elasticsearch: hosts: [&quot;https://localhost:9200&quot;] username: &quot;filebeat_internal&quot; password: &quot;YOUR_PASSWORD&quot; index: &quot;filebeat-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;&quot; #ssl.certificate_authorities: [&quot;/etc/pki/root/ca.pem&quot;] #ssl.certificate: &quot;/etc/pki/client/cert.pem&quot; #ssl.key: &quot;/etc/pki/client/cert.key&quot; 配置项： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103#启用/禁用output，默认 trueenabledhosts#["hsot1:port1", "host2:port2", "host3:port3"]username#建议为filebeat创建一个专门的用户用于发送事件，而不是使用es的用户passwordcompression_level#gzip压缩等级, 0-9，默认 0worker#每个配置主机向es发布事件的worker数，默认 1parameters#http 参数字典protocol#网络协议, http/httpspath#http api调用前面的http路径前缀headers#定义headersproxy_url#代理的urlindex#写到事件中的索引名，默认 "filebeat-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;"#如果更改此设置，还需要配置setup.template.name和setup.template.pattern选项#如果使用的是预先构建的kibana dashboard，还需要配置setup.dashboards.index选项indices#支持条件的索引选择器规则数组，基于格式字符串的字段访问和名称映射。indices.index: 要使用的索引格式字符串indices.mapping： 映射indices.default： 如果映射找不到匹配项的默认字符串值indices.when： 成功的条件才执行当前规则output.elasticsearch: hosts: ["http://localhost:9200"] index: "logs-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;" indices: - index: "critical-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;" when.contains: message: "CRITICAL" - index: "error-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;" when.contains: message: "ERR"pipeline#与indices类似，管道选择器配置数组filebeat.inputs:- type: log paths: ["/var/log/app/normal/*.log"] fields: type: "normal"- type: log paths: ["/var/log/app/critical/*.log"] fields: type: "critical"output.elasticsearch: hosts: ["http://localhost:9200"] index: "filebeat-%&#123;[beat.version]&#125;-%&#123;+yyyy.MM.dd&#125;" pipelines: - pipeline: critical_pipeline when.equals: fields.type: "critical" - pipeline: normal_pipeline when.equals: fields.type: "normal"max_retriesbulk_max_size#单个es批量挨批索引请求中要批量处理的最大事件数，默认 50backoff.init#在网络错误之后尝试重连到es之前等待的秒数，默认 1sbackoff.max#在网络错误后尝试连接到es之前等待的最大秒数，默认 60stimeout#超时时间ssl logstash kafka redisredis output将事件插入redis list或redis channel。 12345678output.redis: hosts: "localhost" port: 6379 key: "filebeat" #自定义key-name #password: #db: #data_type: 'list' 配置项： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#启用/禁用outputenabledhostsport#可将端口写在hosts里，默认6379usernamepassworddbkeydatatype#默认 listcodeckeyskeys.keykeys.mappingkeys.defaultkeys.whenoutput.redis: hosts: ["localhost"] key: "default_list" keys: - key: "info_list" # send to info_list if `message` field contains INFO when.contains: message: "INFO" - key: "debug_list" # send to debug_list if `message` field contains DEBUG when.contains: message: "DEBUG" - key: "%&#123;[fields.list]&#125;" mapping: "http": "frontend_list" "nginx": "frontend_list" "mysql": "backend_list"loadbalance#如果配置了多个主机，则输出插件会将已发布的事件负载均衡到所有redis主机上timeoutmax_retriesbulk_max_sizesslproxy_urlproxy_use_local_resolver filefile output将事务转储到文件中，每个事务都是json格式。 123output.file: path: "/tmp/filebeat" filename: filebeat 配置项： 12345678910111213141516enabledpathfilenamerotate_every_kb#默认 10 240KBnumber_of_files#路径下要保存的最大文件数permissions#创建的文件权限， 默认 0600codec consoleconsole output将事件以json格式输出到标准输出。 12output.console: pretty: true 配置项： 12345678pretty#美化输出， 默认 falsecodecenabledbulk_max_size loadbalancefilebeat提供配置项，用于将事件发送到多个主机时微调负载均衡。loadbalance对redis, logstash, es output可用。 123output.logstash: hosts: ["localhost:5044", "localhost:5045"] loadbalance: true Kibana文档Kibana是一个开源分析和可视化平台，旨在与Elasticsearch合作。你可使用Kibana来检索(search)，查看(view)存储在Elasticsearch索引中的数据并与其进行交互(interact)。你可以很轻松地执行高级数据分析，并在各种图表、表格和地图中可视化你的数据。Kibana可以很容易地理解大量的数据。基于浏览器的接口能够快速创建和分享动态仪表盘，实时显示Elasticsearch查询的变化。 入门在开始前，请确保已安装Kibana并与Elasticsearch建立了连接。 载入示例数据本节依赖如下示例数据： shakespeare.json: https://download.elastic.co/demos/kibana/gettingstarted/shakespeare_6.0.json accounts.zip: https://download.elastic.co/demos/kibana/gettingstarted/accounts.zip uzip accounts.zip logs.jsonl.gz: https://download.elastic.co/demos/kibana/gettingstarted/logs.jsonl.gz gunzip logs.jsonl.gz shakespeare按以下模式组织： 12345678&#123; "line_id": INT, "play_name": "String", "speech_number": INT, "line_number": "String", "speaker": "String", "text_entry": "String"&#125; accounts按以下模式组织： 12345678910111213&#123; "account_number": INT, "balance": INT, "firstname": "String", "lastname": "String", "age": INT, "gender": "M or F", "address": "String", "employer": "String", "email": "String", "city": "String", "state": "String"&#125; 日志数据的模式有许多不同的字段，此例使用字段如下： 12345&#123; "memory": INT, "geo.coordinates": "geo_point", "@timestamp": "date"&#125; 载入数据前，需要为字段设置映射。映射将索引中的文档分成逻辑组，并指定字段特性。如可搜索性、标记化、分解为单独的单词。 在Kibana界面中的Dev Tools中输入如下命令，为shakespeare数据设置映射。 12345678910111213PUT /shakespeare&#123; "mappings": &#123; "doc": &#123; "properties": &#123; "speaker": &#123;"type": "keyword"&#125;, "play_name": &#123;"type": "keyword"&#125;, "line_id": &#123;"type": "integer"&#125;, "speech_number": &#123;"type": "integer"&#125; &#125; &#125; &#125;&#125; 日志数据集logs.jsonl需要映射才能将日志中的经纬度标记为地理位置。 12345678910111213141516PUT /logstash-2015.05.18&#123; &quot;mappings&quot;: &#123; &quot;log&quot;: &#123; &quot;properties&quot;: &#123; &quot;geo&quot;: &#123; &quot;properties&quot;: &#123; &quot;coordinates&quot;: &#123; &quot;type&quot;: &quot;geo_point&quot; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 12345678910111213141516PUT /logstash-2015.05.19&#123; &quot;mappings&quot;: &#123; &quot;log&quot;: &#123; &quot;properties&quot;: &#123; &quot;geo&quot;: &#123; &quot;properties&quot;: &#123; &quot;coordinates&quot;: &#123; &quot;type&quot;: &quot;geo_point&quot; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 12345678910111213141516PUT /logstash-2015.05.20&#123; &quot;mappings&quot;: &#123; &quot;log&quot;: &#123; &quot;properties&quot;: &#123; &quot;geo&quot;: &#123; &quot;properties&quot;: &#123; &quot;coordinates&quot;: &#123; &quot;type&quot;: &quot;geo_point&quot; &#125; &#125; &#125; &#125; &#125; &#125;&#125; accounts数据集不需要映射，这一点上使用Elasticsearch的bulk API去载入数据集： 12345678910#这些命令要花一些时间curl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/bank/account/_bulk?pretty' --data-binary @accounts.jsoncurl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/shakespeare/doc/_bulk?pretty' --data-binary @shakespeare_6.0.jsoncurl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/_bulk?pretty' --data-binary @logs.jsonl#验证#在Kibana中的DevTools中运行GET /_cat/indices?v 定义你的索引模式加载到Elasticsearch的每组数据集都有一个索引模式(index pattern)。索引模式是一个带有可匹配多个索引的可使用通配符的字符串。 在前面，Shakespeare数据集有一个名为: shakespeare 的索引；Account数据集有一个名为：bank 的索引。如，在常见的日志文件中，一个典型的索引包含YYYY.MM.DD日期格式，类似于logstash-2015.05.*。 进入Kibana界面，点击Management， Index Patterns， Create Index Pattern 来创建一个索引模式。 shakespeare和account数据集不包含 time-series data。确保为此数据集创建索引模式时，不包含基于时间的事件。logs数据集包含了时序数据，因此索引需要包含基于时间的事件。 shakes* ba* logstash-2015* 定义索引模式时，与Elasticsearch匹配的索引必须存在。 在Kibana的DevTools中输入: GET _cat/indices 来查看索引。 数据发现点击Kibana界面中的Discover以显示数据发现功能。 可视化Visualize Visualize允许你在Elasticsearch索引中创建数据的可视化。然后可以构建显示相关可视化的仪表盘。 Kibana的可视化基于Elasticsearch查询。通过使用一系列Elasticsearch聚合来提取和处理你的数据。你可以创建图标来显示你需要了解的趋势。 创建可视化 Elasticsearch文档入门Elasticsearch是一个高度可扩展的开源全文搜索和分析引擎。它允许你快速、近乎实时地存储、搜索和分析大量数据。 Elasticsearch的几个例子： 使用Elasticsearch来存储产品目录和库存，并为其提供搜索和建议 收集日志或交易数据，并分析和挖掘数据以便于查找趋势、统计数据、汇总或异常信息 价格提醒平台，允许顾客制定规则，收到相应规则信息 分析智能需求，快速调查、分析、可视化并对大量数据提出特别的问题 基本概念Near Realtime(NRT)Elasticsearch是一个近乎实时的搜索平台。这意味着从索引文档到可搜索之间存在轻微的延迟(通常为1s) Cluster集群是一个或多个节点(服务器)的集合，它们一起保存所有数据，并提供跨节点的联合索引和搜索功能。集群由默认名为elasticsearch的唯一名称标识，它很重要。确保不要在不同的环境中重复使用相同集群名称，否则可能会导致节点加入错误的集群。集群可以只有一个节点！你也可以拥有多个独立的集群，每个集群有自己唯一的集群名称。 Node节点是属于集群一部分的单个服务器，存储数据并参与集群的索引和索引。与集群一样，一个节点由一个名称来标识，启动时随机分配的UUID。你也可以自定义节点名。配置节点通过集群名称加入特定的集群，默认加入elasticsearch集群。在单集群中，你可以拥有任意数量的节点。 Index索引是一些具有相似特征的文档集合。例如，客户数据的索引，产品目录的索引，订单数据的索引……索引由名称标识(必须全小写)，文档执行索引、搜索、更新和删除操作时引用索引。在一个单集群中，你可以定义任何你想要的索引。 Document文档是可被索引的基本信息单位。例如，单个客户的文档，单个产品的文档，单个订单的文档…文档以JSON格式表示。一条记录就是一个文档。 Shards和Replicas索引可潜在地存储大量数据，这些数据可能会超多单个节点的硬件限制。例如，占用1TB磁盘空间的十亿文档的单个索引可能不适合单个节点的磁盘，或者可能太慢而无法单独向单个节点提供搜索请求。为了解决这个问题，Elasticsearch提供了将索引细分为称为分片的多个碎片上。当你创建索引时，你可以简单定义所需的分片数量。每个分片本身都是一个功能齐全且独立的索引，可以在集群中的任何节点上进行托管。 分片重要的两个原因： 允许你水平分割/缩放内容量 允许分布和并行操作跨分片，从而提高性能和吞吐量(throughput) 在任何时候都可能出现的网络环境中，强烈建议使用故障切换机制，以防止分片/节点因任何原因而消失。为此，Elasticsearch允许你将索引分片制作为一个或多个称为副本分片的副本集。副本集分片永远不会分配到与原始分片相同的节点上。 副本集重要的原因： 在分片/节点失效的情况下提供高可用性 因为搜索可以在所有副本上并行执行，它允许你扩展搜索量和吞吐量 总而言之，每个索引都可以分成多个分片，索引也可以被复制。一旦复制，每个索引将具有主分片和副本分片。在创建索引时，可为每个索引定义分片和副本数量。在索引创建之后，你可以动态更改副本的数量，但无法更改分片的数量。 默认情况下，Elasticsearch中的每个索引都分配了5个主分片和副本。 每个Elasticsearch分片都是一个Lucene索引。单个Lucene索引有最大文档数量限制。 探索你的集群The REST APIREST(Representational State Transfer)表现层状态转换，是一种万维网软件架构风格，目的是便于不同程序在网络中互相传递信息。REST通常使用HTTP, URI, XML和HTML这些协议和标准。 启动节点，下一步便是理解如何与它通信。幸运的是，Elasticsearch提供了一个非常全面(comprehensive)和强大的REST API，可以使用它与集群进行交互。 使用API可以完成如下几件事： 检查集群、节点和索引的健康、状态和统计信息 管理集群、节点、索引数据和元数据 执行CRUD(create, read, update, delete) 执行高级搜索操作(分页、排序、过滤、脚本、聚合…) 集群健康基本健康检查，看看集群正在做什么。使用_catAPI检查集群健康。可使用Kibana Console或curl等工具。 12345678910#KibanaGET /_cat/health?v#cmdcurl -X GET &quot;localhost:9200/_cat/health?v&quot; -u elasticepoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent1525330981 15:03:01 docker-elk yellow 1 1 32 32 0 0 6 0 - 84.2% 集群健康： green: 万事OK(集群功能齐全) yellow: 所有数据可用，但一些副本尚未分配(集群功能齐全) red: 一些数据因某种原因不可用(集群部分功能) 集群名称： 集群名称被修改为docker-elk 列出集群中的节点： 12345GET /_cat/nodes?vip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name127.0.0.1 47 74 93 3.18 3.13 2.90 mdi * LGrAIE5 随机节点名： LGrAIE5 列出所有索引123456789GET /_cat/indicies?vhealth status index uuid pri rep docs.count docs.deleted store.size pri.store.sizegreen open .monitoring-kibana-6-2018.04.27 bsKsurh7TKaCsnekwHs3yg 1 0 870 0 328.1kb 328.1kbgreen open .watcher-history-7-2018.04.28 zuq3rjI8S0OSS7vcZl7kSQ 1 0 954 0 1.4mb 1.4mbgreen open .kibana 8t_7lqq4TFSfelA7phgv5g 1 0 142 18 191.8kb 191.8kbgreen open .monitoring-es-6-2018.04.28 vtUSjqaITT28CMHArpfNoA 1 0 20436 0 9.6mb 9.6mbyellow open filebeat-6.2.4-2018.05.03 sK3lIvMXS8GoRbWYCjdgzg 3 1 568 0 348.6kb 348.6kb 创建索引创建一个名为customer的索引，然后列出索引 1234567891011121314#pretty漂亮JSON显示PUT /customer?pretty#或curl -X PUT &quot;localhost:9200/zhang&quot; -u elastic:elasticGET /_cat/indices?v#pri主分片，rep副本health status index uuid pri rep docs.count docs.deleted store.size pri.store.sizeyellow open customer WQ3qEnPQRW6FpVIHYVJ7yA 5 1 0 0 1.1kb 1.1kbyellow open zhang nkOUPOWERsS1PT_wEui67g 5 1 0 0 1.1kb 1.1kb 你可能注意到了，索引的健康状态是yellow，表明有一些副本尚未分配。这个索引发生这种情况的原因是Elasticsearch默认为这个索引创建了一个副本。由于此刻我们只有一个节点在运行，因此只有在其它几点加入集群后才能分配一个副本。一旦副本分配到另外的节点，健康状态会变成green。 索引和查询文档现在让我们把一些东西放入customer索引中。讲一个简单的customer文档放入customer索引中，ID为1： 12345678910111213141516171819202122232425262728293031323334353637383940414243PUT /customer/_doc/1?pretty&#123; &quot;name&quot;: &quot;John Doe&quot;&#125;#或curl -X PUT -u elastic:elastic &quot;localhost:9200/customer/_doc/1?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;name&quot;: &quot;John Doe&quot;&#125;&apos;&#123; &quot;_index&quot; : &quot;customer&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 0, &quot;_primary_term&quot; : 1&#125;GET /customer/_doc/1?pretty&#123; &quot;_index&quot;: &quot;customer&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;John Doe&quot; &#125;&#125;#name:John Doe _id:1 _type:_doc _index:customer _score:1 删除索引12345678DELETE /customer?prettycurl -X DELETE &quot;localhost:9200/customer?pretty&quot; -u elastic:elastic&#123; &quot;acknowledged&quot;: true&#125; 修改数据Elasticsearch几乎提示提供数据操作和搜索功能。从索引、更新、删除数据时可能会有1s延迟。数据在事物完成后立即可用。 索引/替换 文档 12345678910111213141516171819202122PUT /customer/_doc/1?pretty&#123; &quot;name&quot;: &quot;John Doe&quot;&#125;#如果我修改此处文档信息，则Elasticsearch会替换之前的文档PUT /customer/_doc/1?pretty&#123; &quot;name&quot;: &quot;Zhang&quot;&#125;#name:Zhang _id:1 _type:_doc _index:customer _score:1#或者新增一个文档PUT /customer/_doc/2?pretty&#123; &quot;name&quot;: &quot;Zhang&quot;&#125;#name:Zhang _id:2 _type:_doc _index:customer _score:1 未指定ID：ID是可选的。如果未指定ID，Elasticsearch会生成随机ID。注意，此时使用POST方法。 123456POST /customer/_doc?pretty&#123; &quot;name&quot;: &quot;Zhang&quot;&#125;#name:Zhang _id:76xJJWMBddhqcmsO07A_ _type:_doc _index:customer _score:1 更新文档除了能够索引和替换文档，我们还可以更新文档。Elasticsearch实际上并没有在原地就地更新，它是先删除旧文档，然后一次性更新索引新文档。 更新同样能够使用简单的脚本。Elasticsearch提供了通过查询条件(类似于SQL-UPDATE-WHERE)更细多个文档的能力。 1234567891011121314151617181920POST /customer/_doc/1/_update?pretty&#123; &quot;doc&quot;: &#123; &quot;name&quot;: &quot;Jane Doe&quot; &#125;&#125;#继续更新POST /customer/_doc/1/_update?pretty&#123; &quot;doc&quot;: &#123; &quot;name&quot;: &quot;Jane Doe&quot;, &quot;age&quot;: 20&#125;&#125;#简单脚本#ctx._source指即将更新的当前源文档POST /customer/_doc/1/_update?pretty&#123; &quot;script&quot;: &quot;ctx._source.age += 5&quot;&#125; 删除文档也可通过API匹配查询，删除所匹配的文档。 1DELETE /customer/_doc/2?pretty 批量处理Elasticsearch同样提供了使用_bulkAPI批量执行上述任何操作的功能。这是一种高效的机制，尽可能快地完成多项操作。 Bulk API不会因其中一个操作失败而停止，它将继续处理后面的动作。当它完成是，它会返回每个操作的状态，以便你可以检查是否失败。 123456789101112POST /customer/_doc/_bulk?pretty&#123; &quot;index&quot;: &#123; &quot;_id&quot;: &quot;1&quot; &#125; &#125;&#123; &quot;name&quot;: &quot;John Doe&quot; &#125;&#123; &quot;index&quot;: &#123; &quot;_id&quot;: &quot;2&quot; &#125; &#125;&#123; &quot;name&quot;: &quot;Jane Doe&quot; &#125;#更新POST /customer/_doc/_bulk?pretty&#123;&quot;update&quot;: &#123; &quot;_id&quot;: &quot;1&quot; &#125; &#125;&#123; &quot;doc&quot;: &#123; &quot;name&quot;: &quot;John Doe becomes Jane Doe&quot; &#125; &#125;&#123; &quot;delete&quot;: &#123; &quot;_id&quot;: &quot;2&quot; &#125; &#125; 探索你的数据简单数据集准备一个更加真实的数据集。如下生成的JSON文档，每个文档都有如下要点： 12345678910111213&#123; &quot;account_number&quot;: 0, &quot;balance&quot;: 16623, &quot;firstname&quot;: &quot;Bradshaw&quot;, &quot;lastname&quot;: &quot;Mckenzie&quot;, &quot;age&quot;: 29, &quot;gender&quot;: &quot;F&quot;, &quot;address&quot;: &quot;244 Columbus Place&quot;, &quot;employer&quot;: &quot;Euron&quot;, &quot;email&quot;: &quot;bradshawmckenzie@euron.com&quot;, &quot;city&quot;: &quot;Hobucken&quot;, &quot;state&quot;: &quot;CO&quot;&#125; 载入这个数据集下载Elasticsearch提供的accounts.json 123456curl -H &quot;Content-Type: application/json&quot; -u elastic:elastic -XPOST &quot;localhost:9200/bank/_doc/_bulk?pretty&amp;refresh&quot; --data-binary &quot;@accounts.json&quot;curl &quot;localhost:9200/_cat/indices?v&quot;health status index uuid pri rep docs.count docs.deleted store.size pri.store.sizeyellow open bank PGSvNwQwQIOhMDr1nmXIuw 5 1 1000 0 474.7kb 474.7kb 这样我们成功批量索引了1000个文档到bank索引。 Search API现在让我们做一些简单的搜索(search)。有两种基本搜索方式： REST request URI REST request body 以可读的JSON格式定义你的搜索，推荐方式 搜索的REST API可从_search端点访问: 12345678910111213141516171819202122232425262728293031323334353637#在bank索引下的_search端点搜索#匹配所有文档，并以账户字段顺序排列#最后以可读的JSON格式输出结果GET /bank/_search?q=*&amp;sort=account_number:asc&amp;pretty&#123; &quot;took&quot; : 63, &quot;timed_out&quot; : false, &quot;_shards&quot; : &#123; &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 &#125;, &quot;hits&quot; : &#123; &quot;total&quot; : 1000, &quot;max_score&quot; : null, &quot;hits&quot; : [ &#123; &quot;_index&quot; : &quot;bank&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;0&quot;, &quot;sort&quot;: [0], &quot;_score&quot; : null, &quot;_source&quot; : &#123;&quot;account_number&quot;:0,&quot;balance&quot;:16623,&quot;firstname&quot;:&quot;Bradshaw&quot;,&quot;lastname&quot;:&quot;Mckenzie&quot;,&quot;age&quot;:29,&quot;gender&quot;:&quot;F&quot;,&quot;address&quot;:&quot;244 Columbus Place&quot;,&quot;employer&quot;:&quot;Euron&quot;,&quot;email&quot;:&quot;bradshawmckenzie@euron.com&quot;,&quot;city&quot;:&quot;Hobucken&quot;,&quot;state&quot;:&quot;CO&quot;&#125; &#125;, &#123; &quot;_index&quot; : &quot;bank&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;sort&quot;: [1], &quot;_score&quot; : null, &quot;_source&quot; : &#123;&quot;account_number&quot;:1,&quot;balance&quot;:39225,&quot;firstname&quot;:&quot;Amber&quot;,&quot;lastname&quot;:&quot;Duke&quot;,&quot;age&quot;:32,&quot;gender&quot;:&quot;M&quot;,&quot;address&quot;:&quot;880 Holmes Lane&quot;,&quot;employer&quot;:&quot;Pyrami&quot;,&quot;email&quot;:&quot;amberduke@pyrami.com&quot;,&quot;city&quot;:&quot;Brogan&quot;,&quot;state&quot;:&quot;IL&quot;&#125; &#125;, ... ] &#125;&#125; took: Elasticsearch执行搜索花费的事件(ms) timed_out: 查询超时与否 _shards: 搜索了多少分片，包含成功和失败的次数 hits: 搜索结果 hits.total: 匹配搜索的文档数 hits.hits: 搜索结果数组(默认前十个文档) hits.sort: 结果的排序键 hits._score, max_score: 忽略的字段 REST request body方法 1234567GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;sort&quot;: [ &#123; &quot;account_number&quot;: &quot;asc&quot; &#125; ]&#125; 查询语法Elasticsearch提供了可用于执行查询的JSON格式语言，这被称为 Query DSL 12345#上一个查询栗子GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;&#125; 处理query参数，我们还可以传递其它参数来搜索结果: 123456789101112131415161718192021222324#size参数，返回从from开始多少个文档#from未指定，就默认为0GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;size&quot;: 1&#125;#from参数，指定从哪个文档索引开始GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;from&quot;: 10, &quot;size&quot;: 10&#125;#sort参数GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;sort&quot;: &#123; &quot;balance&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125; &#125;&#125; 执行搜索搜索某些字段： 12345GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;_source&quot;: [&quot;account_number&quot;, &quot;balance&quot;]&#125; 匹配查询： 12345678910111213141516GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;account_number&quot;: 20 &#125; &#125;&#125;GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;&#125;GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123; &quot;address&quot;: &quot;mill lane&quot; &#125; &#125;&#125; 布尔查询： must should must_not 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#mustGET /bank/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;lane&quot; &#125; &#125; ] &#125; &#125;&#125;#shouldGET /bank/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;should&quot;: [ &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;lane&quot; &#125; &#125; ] &#125; &#125;&#125;#must_notGET /bank/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must_not&quot;: [ &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;, &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;lane&quot; &#125; &#125; ] &#125; &#125;&#125;#组合使用must,must_not,shouldGET /bank/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;age&quot;: &quot;40&quot; &#125; &#125; ], &quot;must_not&quot;: [ &#123; &quot;match&quot;: &#123; &quot;state&quot;: &quot;ID&quot; &#125; &#125; ] &#125; &#125;&#125; 过滤前面我们跳过了称为文档分数的_score字段。它是文档与搜索查询匹配度相度量的一个数值。数值越大，与文档越相关。 但查询并不总是需要产生分数，特别是当它们仅用于过滤时。Elasticsearch检测这些情况并自动优化查询执行，以便不计算无用的分数。 range query: 通过一系列值来过滤文档 12345678910111213141516GET /bank/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;balance&quot;: &#123; &quot;gte&quot;: 20000, &quot;lte&quot;: 30000 &#125; &#125; &#125; &#125; &#125;&#125; 除了前面这些查询类型，还有很多其它类型。由于只是入门章节，所以并不会涉及太多太难。 聚合聚合(Aggregation)提供了从数据中分组和提取统计的功能。考虑聚合最简单方法是将其大致等同于SQL GROUP BY和SQL聚合函数。 在Elasticsearch中，你可以执行返回匹配的搜索，同时还可以在一个响应中返回与匹配不同的聚合结果。你可以运行查询和多个聚合，并一次性获得多个操作的结果。 1234567891011121314GET /bank/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_state&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;state.keyword&quot; &#125; &#125; &#125;&#125;#类似的SQLSELECT state, COUNT(*) FROM bank GROUP BY state ORDER BY COUNT(*) DESC 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#group, averageGET /bank/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_state&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;state.keyword&quot; &#125;, &quot;aggs&quot;: &#123; &quot;average_balance&quot;: &#123; &quot;avg&quot;: &#123; &quot;field&quot;: &quot;balance&quot; &#125; &#125; &#125; &#125; &#125;&#125;GET /bank/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;group_by_age&quot;: &#123; &quot;range&quot;: &#123; &quot;field&quot;: &quot;age&quot;, &quot;ranges&quot;: [ &#123; &quot;from&quot;: 20, &quot;to&quot;: 30 &#125;, &#123; &quot;from&quot;: 30, &quot;to&quot;: 40 &#125;, &#123; &quot;from&quot;: 40, &quot;to&quot;: 50 &#125; ] &#125;, &quot;aggs&quot;: &#123; &quot;group_by_gender&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;gender.keyword&quot; &#125;, &quot;aggs&quot;: &#123; &quot;average_balance&quot;: &#123; &quot;avg&quot;: &#123; &quot;field&quot;: &quot;balance&quot; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 还有很多其它聚合方法，请参考https://www.elastic.co/guide/en/elasticsearch/reference/6.2/search-aggregations.html。 elasticsearch-pyPython可使用elasticsearch-py模块来操作Elasticsearch，具体文档请查看Python这篇文章的elasticsearch第三方模块。 Lucene查询ElasticSearch提供的一些查询方式(query types)能够被Lucene的查询解析器(query parser)语法所支持。可直接在Kibana的发现面板上直接使用。 全文搜索 string “string1 string2” Kibana会匹配和展示对应的string。 键值对 key:value: 全文搜索 &quot;key:value&quot;： 精确搜索 _exists_:key: 返回结果中需要有key字段 _missing__:key: 不能含有key字段 如:http.code:502，log-levle:warn 通配符 ? * 这两者都不能用作第一个字符，如?.txt, *.txt 正则表达式它也支持性能较差的正则表达式。 模糊搜索 ~: 在一个单词后面加上~启用模糊搜索 ~n： 设置编辑距离(整数)，指定需要多少相似度，越大越接近原始值 在短语后面加~，可以搜索到被隔开或顺序不同的单词 first~也可以匹配到frist&quot;hello world&quot;~5表示两者之间可以隔着5个单词 范围搜索数值/时间/IP/字符串 类型的字段可以对某一范围进行查询 1234567891011length:[100 TO 200]sip:[&quot;172.24.20.110&quot; TO &quot;172.24.20.140&quot;]date:&#123;&quot;now-6h&quot; TO &quot;now&quot;&#125;tag:&#123;b TO e&#125; 搜索b到e中间的字符count:[10 TO *] * 表示一端不限制范围count:[1 TO 5&#125; [ ] 表示端点数值包含在范围内，&#123; &#125; 表示端点数值不包含在范围内，可以混合使用，此语句为1到5，包括1，不包括5可以简化成以下写法：age:&gt;10age:&lt;=10age:(&gt;=10 AND &lt;20) 优先级使用^使一个词语比另一个搜索优先级更高，默认为1。可以为0~1之间的浮点数，来降低优先级 逻辑操作 AND OR NOT +: 搜索结果中必须包含此项 -: 不能包含此项 123(a OR b) AND chost:(baidu OR qq OR google) AND host:(com OR cn) 转义字符 \：使用转义字符来转移特殊字符 MetricbeatMetricbeat是一个轻量级的托运器(lightweight shipper), 你可从安装该软件的操作系统和服务器上定期收集指标信息。它可将收集到的指标信息或统计信息发送到指定的输出(如elasticsearch/Logstash)。 具体使用方法也和Filebeat差不多！ Metricbeat通过从服务器上运行的系统和服务收集指标来帮助你监控服务器。如： Apache Docker Kafka Kubernets HAProxy MongoDB MySQL Nginx PHP-FPM PostgreSQL Redis RabbitMQ System Zookeeper … PacketbeatPacketbeat是一个实时网络数据包分析器，可与Elasticsearch一起提供应用程序监控和性能分析。 Packetbeat通过捕获应用服务器之间的网络流量，解码应用层协议(HTTP, MySQL, Redis…)，将请求与响应关联起来，并记录每个事务感兴趣的字段。Packetbeat可以帮助你轻松地注意到后端应用程序的问题，例如错误或性能问题，并且可以更快地排除故障并进行修复。Packetbeat捕获服务器之间的流量，即时分析应用层协议，并将这些消息关联到事务中。并将这些事务插入到Elasticsearch或使用Redis和Logstash的队列中。 Packetbeat支持的协议如下: ICMP DNS HTTP AMQP Cassandra MySQL PostgreSQL Redis MongoDB Thrift-RPC TLS HeartbeatHeartbeat是一个轻量级守护进程，用以定期检查服务的状态并确定它们是否可用。与Metricbeat不同，Metricbeat只会告诉你服务器是down/up，而Heartbeat会告诉你服务是否可以访问(reached)。 当你需要验证是否满足服务级别协议的服务正常运行时间时，Heartbeat非常有用。当需要验证外部没有人能访问企私有服务器上的服务时，这也很有用。你可以配置Heartbeat来ping指定主机名的所有DNS可解析的IP地址。这样，你可以检查所有负载均衡的服务，看他们是否可用。配置Heartbeat时，你可以指定用于表示要检查的主机名的监视器(monitor)。每台监视器都根据你指定的时间表运行。 Heartbeat目前支持通过通过如下方式监控主机： ICMP当你指向检查服务是否可用时，请使用icmp监视器。此功能需要root权限 TCP支持SSL/TLS/proxy你可以选择配置此监视器，通过发送 and/or 接收自定义有效内容来验证端点 HTTP支持SSL/TLS/proxy你可以选择配置此监视器，来验证该服务是否会返回预期的响应。如特定状态码，响应header或内容 AuditbeatAuditbeat是一个轻量化的托运器(shipper)，在系统上安装它，以审核(audit)系统上用户和进程的活动。 例如，你可以使用Auditbeat从Linux Audit Framework收集和集中审计事件。你还可以使用它来检查关键文件的改动，并识别潜在的安全策略违规。 Topbeat在v5.0, Topbeat被Metricbeat取代！ Topbeat的版本与其它Elastic Stack组件不同步，ES是v6.2.4， 而Topbeat是v1.3。所以需要额外安装repo. Topbeat是一个轻量化的托运器(shipper)，来定期读取系统和每个进程的CPU和内存统计信息，然后为Elasticsearch中的统计信息编制索引。 Topbeat通过收集如下指标来帮助你监控你的服务器: ystem-wide statistics system load 1, 5, 15 system wide CPU usage user, system, idle, IOWait system wide memory uusage total, used, free system wide swap usage total, used, free Per-process statistics process name process parent pid process state process pid process CPU usage process Memory usage File system statistics avaliable disks name, type, mounted total, used, free, available APMAPM(Application Performance Monitoring)应用程序性能监控，自动收集应用程序内部的深入性能指标和错误。 它由三个组件组成: Agents Node.js Django Flask Ruby on Rails Rack JS Server UI ElastAlert GitHub: https://github.com/Yelp/elastalert Docs: https://elastalert.readthedocs.io ElastAlert是一个简单灵活的用于Elasticsearch中数据异常的告警框架。它使用Python2.x编写，不支持Python3。ElastAlert功能与Watcher类似，只不过Watcher是Elastic Enterprise中才支持，而ElastAlert是一个开源软件。 Kibana非常适合可视化和查询数据，但它需要一个配套工具来对数据进行告警，出于这种需要，ElastAlert诞生了。如果你几乎实时地将数据写入Elasticsearch，并希望在数据与某些模式匹配时收到告警，则ElastAlert就是适合你的工具。 综述ElastAlert被设计为可靠、高度模块化、易于设置和配置。它使用两种类型的组件与Elasticsearch进行结合： rule type alerts 定期检查Elasticsearch并将数据传递给规则类型，它确定了何时找到匹配项。当匹配发生时，它触发一个或多个报警，而这些报警便采取具体行动。 每组规则定义了一个查询、一个规则类型和一组警报。 ElasAlert几种通用规则类型： frequencyMatch where there are X events in Y time spikeMatch when the rate of events increases or decreases flatlineMatch when there are less than X events in Y time blacklist/whitelistMatch when a certain field matches a blacklist/whitelist anyMatch on any event matching a given filter changeMatch when a field has two different values within some time ElasAlert几种内建报警类型： Command Email JIRA OpsGenie SNS HipChat Slack Telegram Debug Stomp 你也可以导入和编写规则类型和报警类型。 除了这些基础用法外，还有许多其它功能: Alerts link to Kibana dashboards Aggregate counts for arbitrary fields Combine alerts into periodic reports Separate alerts by using a unique key field Intercept and enhance match data 可靠性Reliability ElasAlert有多种功能，可在restart或Elasticsearch不可用时使其更可靠: ElastAlert将其状态保存到Elasticsearch，并在启动时先恢复先前停止的状态 如果Elasticsearch没有响应，ElastAlert将等待它恢复，然后再继续 抛出错误的警报可能会在一段时间内自动重试 模块性Modularity ElastAlert有3个主要组件，可作为模块导入或自定义。 rule types规则类型负责处理从Elasticsearch返回的数据。 alerts警报负责根据匹配采取行动。 enhancements增强功能是一种拦截警报并以某种方式修改或增强警报的方法。 配置配置项ElastAlert有一个全局配置文件config.yaml，它定义了几个操作方面: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#ElastAlert将持续查询熊当前到buffer_time前的窗口buffer_time#ESes_hostes_port#可选es_usernamees_password#URL prefix for the Elasticsearch endpointes_url_prefix#Method for querying Elasticsearch，默认GETes_send_get_body_as#默认20es_conn_timeout#可选配置use_sslverify_certsclient_certclient_keyca_certs#规则配置文件目录rules_folder#递归，默认truescan_subdirectories#查询频率，如 minutes: 5run_every#elastalert将存储数据的索引名称writeback_index#报警失败的重试窗口alert_time_limit#单个查询中从es下载的最大文档数，默认10 000max_query_sizescroll_keepalive#聚合在一起的最大警报数，默认10 000max_aggregation#ElastAlert从最近开始运行的查询开始的最长时间old_query_limit#当抛出未知异常时，禁用rule。 默认truedisable_rules_on_error#Email#接收通知的邮件nottify_email#默认值ElastAlertfrom_addrsmpt_hostemail_reply_to#Amazon Elasticsearch Serviceaws_regionboto_profileprofile#在将文档写入Elasticsearch前，ElastAlert使用下划线替换字段名中的任意一个点(.)。默认值Falsereplace_dots_in_field_names#es中用于字符串多字段的子字段的后缀string_multi_field_name 运行ElastAlert运行： 1python elastalert/elastalert.py 一些参数： 1234567891011121314151617--config--debug--verbose--start--end--rule--slience--es_debug--es_debug_trace--pin_rules 首次运行ElastAlertRunning ElastAlert for the First Time 依赖Requirements: es ISO8601 or Unxi timestamped data Python 2.7 python2-pip python-dev libffi-dev libssl-dev 安装12345678910111213141516#依赖yum install python2-pip python-dev#setuptools &gt;= 11.3pip2 install --upgrade setuptools#elasticsearch &gt;= 5.0pip2 install elasticsearchpip2 install elastalert#or#git clone https://github.com/Yelp/elastalert.git#cd elastalert#python2 setup.py install 之后修改配置文件，我将ElastAlert目录移动到了/etc/下。修改配置文件，并将ElastAlert的config.yaml.example配置保存为config.yaml。 设置esSetting Up Elasticsearch ElastAlert将有关其查询及报警的信息和元数据报错到Elasticsearch。这虽然不是必须的，但却强烈建议使用。 12345678910111213141516#创建一个用于ElastAlert写入的indexelastalert-create-index#会有es主机，端口，用户，密码和索引相关信息Enter Elasticsearch host: zhang21Enter Elasticsearch port: 9200Use SSL? t/f: fEnter optional basic-auth username (or leave blank):Enter optional basic-auth password (or leave blank):Enter optional Elasticsearch URL prefix (prepends a string to the URL of every request): New index name? (Default elastalert_status)Name of existing index to copy? (Default None)Elastic Version:6Mapping used for string:&#123;&apos;type&apos;: &apos;keyword&apos;&#125;New index elastalert_status createdDone! 创建一个规则Creating a Rule 每个规则定义要执行的查询，触发匹配的参数以及每个匹配要触发的报警列表。cat ./example_rules/example_frequency.yaml 1234567891011121314151617181920212223242526272829303132333435es_host: elasticsearch.example.comes_port: 14900#唯一的规则名name: Example rule#规则类型type: frequency#要查询的索引index: logstash-*#触发报警的阈值num_events: 50#阈值的时间区间timeframe: hours: 4#过滤列表filter:- term: some_field: &quot;some_value&quot;#报警列表alert:- &quot;email&quot;#报警地址列表email:- &quot;elastalert@example.com&quot; 栗子elastalert: 123456789101112131415161718192021222324vim /etc/elastalert/example_rules/example_frequency.yamles_host: &quot;192.168.1.11&quot;es_port: 9200name: &quot;test rule&quot;type: &quot;frequency&quot;#此处我用python新建一个索引，用于测试index: &quot;my-index&quot;num_events: 3timeframe: hours: 1filter:- query_string: query: &quot;log_level: ERROR&quot;#- term:# name: &quot;zhang21&quot;alert:- &quot;email&quot;email:- &quot;elastalert@example.com&quot; 测试规则运行elasticalert-test-rule工具将测试你的配置文件是否成功加载并在过去24h内以调试模式运行： 1elastalert-test-rule ./example_frequency.yaml 配置首选项将按如下方式加载： yaml文件中指定的配置 配置文件中指定的配置 默认配置 运行ElastAlert有两种方式来调用ElastAlert： Supervisor Python 为了便于调试，下面将直接调用。 123456789python2 -m elastalert.elastalert --verbose --rule /etc/elastalert/example_rules/example_frequency.yamlINFO:elastalert:Starting up#这里遇到一个错误ERROR:root:Error running query: TransportError(400, u'search_phase_execution_exception', u'No mapping found for [@timestamp] in order to sort on')#解决方法，在规则文件example_frequency.yaml中添加timestamp_field: timestamp 使用Python3创建索引： 1234567891011121314151617from datetime import datetimefrom elasticsearch import Elasticsearches=Elasticsearch('http://192.168.1.11:9200')es.info()#写入文档data = &#123; # 由于ES接收UTC时间，因此需要使用UTC事件，不然会给我+8(CST) # 'timestamp': datetime.now(), 'timestamp': datetime.utcnow(), 'name': 'zhang21'&#125;for i in range(1, 21): es.index(index='my-index', doc_type='test-type', id=i, body=data) 规则类型和配置项Rule Types and Configuration Options 规则配置项Rule Configuration Cheat Sheet 选项太多，自己去看: https://elastalert.readthedocs.io/en/latest/ruletypes.html 通用配置项每个在rules_folder下的.yaml文件默认都会被执行。 必须的配置 es_host es_port index name type alert 可选配置自己去看。 规则类型Rule Types 在elastalert/ruletypes.py中定义的各种RuleType class构成了ElastAlert的主要逻辑。每个规则都在内存中保存一个实例，传递通过给定过滤器查询es返回的所有数据，并根据该数据生成匹配。 any任意规则都将匹配所有内容。查询返回的每个匹配都会生成一个警报。 blacklist黑名单规则根据黑名单检查某个字段，如果它存在于黑名单中，则匹配。 黑名单规则需要两个额外项：compare_key——与黑名单进行比较的字段。如果为空，事件将被忽略。blacklist——黑名单列表值或黑名单文件列表(&quot;!file ./blacklist.txt&quot;) 栗子： 1234blacklist: - value1 - value2 - &quot;!file /tmp/blacklist1.txt&quot; whitelist白名单规则根据白名单检查某个字段，如果列表中不包含此字段，则匹配。 白名单规则需要三个额外项：compare_key——与白名单进行比较的字段ignore_null——如果为true，则没有compare_key字段的事件将不匹配whitelist——白名单列表值或白名单文件列表 栗子: 12345whitelist: - value1 - value2 - &quot;!file /tmp/whitelist1.txt&quot; - &quot;!file /tmp/whitelist2.txt&quot; change此规则将监视某个字段，如果此字段改变就匹配。 此规则需要三个额外项：compare_key——监控要改变的字段名。可以是一个列表，如果任意字段发生标号，都将触发警报。ignore_null——如果为true，则没有compare_key字段的事件将不计为已更改。query_key——此规则基于每个查询键应用。 一个可选字段：timeframe——改变之间的最大时间 frequency此规则匹配在给定时间范围内至少一定数量的事件。 此规则需要两个额外项：num_events——将会触发报警的事件数timeframe——上面事件的时间范围 spike(突增)当给定时间段内的事件量的spike_height次数大于或小于前一个时间段时，此规则匹配。它使用两个滑动窗口(引用和当前)来比较。 此规则需要三个额外项：spike_height——上次时间段时间数与前时间段事件数的比率，将处罚告警spike_type——up/down/bothtimeframe：时间段 flatline(脉波)当一段时间内事件总数匹配给定阈值时，此规则匹配。 此规则需要两个额外项：threshold——不触发警报的最小事件数timeframe——时间段 new term(术语)当一个以前从未见过的新值出现在字段中时，此规则匹配。 此规则需要一个额外项：fields——要监控的新术语的字段列表 cardinality(基数)在一个时间范围内，当某个字段的唯一值的总数高于或低于阈值时，此规则匹配。 此规则需要：timeframe——时间段cardinality_field——计算基数的字段 最大或最小基数取一个max_cardinality——数据的基数大于此报警min_cardinality——数据基数小于此报警 metric aggregation当计算窗口中的度量值高于或低于阈值时，此规则匹配。默认值为buffer_time。 此规则需要：metric_agg_key——计算度量标准的字段metric_agg_type——字段的类型doc_type——指定要搜索的文档类型 最大和最小至少需要一个max_threshold——计算的度量标准大与此，报警min_threshold——计算的度量标准小于此，报警 percentage match当计算窗口内匹配桶(bucket)中的文档百分比高于或低于阈值时，此规则匹配。默认情况下，计算窗口为buffer_time。 此规则需要：match_bucket_filter—— ES filter DSL。为匹配桶定义了一个过滤器，它应用匹配查询过滤器并返回文档的子集。doc_type——指定查询文档类型 最大和最小至少需要一个min_percentage——匹配文档的百分比小于此，报警max_percentage——匹配文档的百分比大于此，报警 Alerts每条规则都可以附加任意数量的报警。Alerts是Alerter的子类，并从ElastAlert传递包含相关信息的字典或字典列表。与规则配置类似，它们在规则配置文件中配置。 1234alert:- email- jira- xxx 多个邮件：12345alert:- emailfrom_addr: &quot;no-reply@example.com&quot;email: &quot;someone@example.com&quot; 1234567alert:- email: from_addr: &quot;no-reply@example.com&quot; email: &quot;someone@example.com&quot;- email: from_addr: &quot;xx&quot; email: &quot;xxx&quot; Alert Subject可通过添加包含自定义摘要的alert_subject来自定义电子邮件主题。 1alert_subject: &quot;Issue &#123;0&#125; ouccurreda at &#123;1&#125;&quot; 123alert_subject_args:- issue.name- &quot;@timestamp&quot; 如果规则匹配索引中的多个对象，则仅使用第一个匹配来填充格式化程序的参数。 Alert Content有几种方法可以格式化给种类型事件的正文： 1234567rule_name = namealert_text = alert_textruletype_text = Depends on typetop_counts_header = top_count_key, &quot;:&quot;top_counts_value = Value, &quot;: &quot;, Counttop_counts = top_counts_header, LF, top_counts_valuefield_values = Field, &quot;: &quot;, Value 默认：123456789body = rule_name [alert_text] ruletype_text &#123;top_counts&#125; &#123;field_values&#125; command命令报警允许你执行任意命令并从匹配中传递参数或stdin。该命令的参数可以使用Python格式的字符串语法来访问匹配的部分内容。报警器将打开一个子进程并可选地传递匹配，或在聚合报警的情况下，将其作为json阿虎组匹配到进程的stdin。 此报警需要一个选项：command——要执行的参数列表或要执行的字符串。如果是列表格式，则第一个参数是要执行的程序名。如果传递了一个字符串，则该命令通过shell执行。 字符串可使用%或.format()进行格式化。这是Python的替换。如果在命令中使用格式化数据，清泪建议使用args列表格式而不是shell字符串。 12345alert:- commandcommand: [&quot;/bin/send_alert&quot;, &quot;--username&quot;, &quot;%(username)s&quot;]#command: [&quot;/bin/send_alert&quot;, &quot;--username&quot;, &quot;&#123;match[username]&#125;&quot;] Email此报警将会发送电子邮件。它默认连接到smtp_host服务器。 它需要一个选项：email——接收报警的地址 Jira Debug调试报警器经使用Python logger的info level记录报警信息。它被记录到名为elastalert的Python logger对象中，可以使用getLogger命令轻松访问该对象。 HTTP POST此报警类型使用HTTP POST将结果发送到JSON ENDPOINT。默认情况下，json会包含所有匹配，除非你指定http_post_payload。 需要：http_post_url 123456alert: posthttp_post_url: &quot;http://example.com/api&quot;http_post_payload: ip: clientiphttp_post_static_payload: apikey: abc123 ElastAlert元数据索引ElastAlert Metadata Index ElastAlert使用Elasticsearch存储有关其状态的各种信息。这不仅允许对ElastAlert操作进行某种程度的审计和调试，而且还可以在ElastAlert关闭、重启或崩溃时避免数据丢失或重复报警。此集群和索引信息在全局配置文件中使用es_host, es_port, writeback_index定义。ElastAlert必须能够写入到此索引。elastalert-create-index将为你创建具有正确映射的索引，并可选择从现有的ElastAlert写回索引中复制文档。 ElastAlert将会在writeback index中创建三种不同类型的文档： elastalert_status elastalert elastalert_error elastalert_statuselastalert_status是为给定规则执行查询的日志，包含： @timestamp rule_name starttime endtime hits： 查询的结果数 matches： 匹配数 time_taken： 查询所用秒数 elastalertelastalert是有关触发的每个报警的日志信息，包含： @timestamp rule_name alert_info alert_sent alert_time match_body alert_exception aggregate_id elastalert_error当ElastAlert发生错误时，它将写入Elasticsearch和stderr。elastalert_error类型包含： @timestamp message traceback data silencesilence是指由于重新设置或使用-silence而抑制给定规则的警报的记录。 @timestamp rule_name until：警报在此开始发送的时间戳 exponent：除非设置了exponential_realert，否则它将为0 添加一个新规则类型Adding a New Rule Type 添加一个新报警器Adding a New Alerter 为规则编写过滤器Writing Filters For Rules 增强功能Enhancements 增强功能是一些模板，可让你在发送警报之前修改匹配项。 在容器内运行构建基础镜像: 123456# Docker-baseFROM ubuntu:latestRUN apt-get update &amp;&amp; apt-get upgrade -y &amp;&amp; \ apt-get -y install build-essential python-setuptools python2.7 python2.7-dev libssl-dev git tox python-pip vim &amp;&amp; \ pip install elastalert -i https://mirrors.aliyun.com/pypi/simple/ 以后只需将配置文件导入基础镜像就好: 1234567891011# DockerfileFROM zhang21/base-elastalert:latest# config.yaml# rules/# smtp_auth_file.yamlCOPY . /opt/elastalert/WORKDIR /opt/elastalertCMD [&quot;sh&quot;, &quot;-c&quot;, &quot;python -m elastalert.elastalert --verbose&quot;] kibana-pluginelastalert kibana-plugin是一个第三方插件。ElastAlert Kibana plugin repository: https://github.com/bitsensor/elastalert-kibana-plugin 注意，安装的时候要注意kibana的版本。具体信息见README。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>Logstash</tag>
        <tag>Kibana</tag>
        <tag>Filebeat</tag>
        <tag>Metricbeat</tag>
        <tag>Heartbeat</tag>
        <tag>Packetbeat</tag>
        <tag>Auditbeat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Supervisor]]></title>
    <url>%2F2018%2F04%2F08%2FSupervisor%2F</url>
    <content type="text"><![CDATA[参考： http://www.supervisord.org 环境： Supervisor 3.3.4 CentOS7.x86_64 介绍 综述Supervisor是一个C/S系统，允许用户在Unix-Like操作系统上控制许多进程。它受如下启发： Convenience Accuracy Delegation Process Group 特点 Simple Centralized(统一) Efficient Extensible Compatible Proven(久经考验) Supervisor组件 supervisord Supervisor的服务器部分被命名为supervisord。负责启动子进程，响应客户端的子进程，重启奔溃或退出的子进程，记录其stderr和stdout，以及生成对应的事件 默认使用的配置文件为/etc/supervisord.conf——Windows-INI格式的文件，由于它包含了未加密的username和password，请保证它安全 supervisorctl Supervisor的客户端部分被命名为supervisorctl。用户可连接到不同的supervisord，status/stop/start子进程，获取supervisord中正在运行的进程列表 通过Unix domain socket或TCP socket与server通信，客户端在执行命令前应该先提供认证。客户端和服务端使用同一个配置文件 Web server Web界面，可通过它查看或控制进程状态 XML-RPC接口 用于询问和控制管理程序及其运行的程序 平台要求 在Unix-Like系统上运行良好 不支持Windows系统 Supervisor运行在Python2.4或之后的版本，不支持Python3 安装安装方法取决于你的操作系统。 通过网络安装 推荐使用setuptools的easy_install 下载Supervisor包并调用一个命令 使用Setuptools的网络安装如果Python解释器安装了Setuptools: 1easy_install supervisor 不使用Setuptools的网络安装如果系统上未安装Setuptools，那么你需要手动去下载Supervisor发行套件和安装它。 PYPI： https://pypi.python.org/pypi/supervisor 123456wget https://pypi.python.org/pypi/supervisor/xxx.tar.gztar -xzf xxx.tar.gzpython setup.py install#它会自动通过网络下载依赖 安装一个分发包一些Linux发行版提供了可通过系统包管理工具安装Supervisor。这些包由第三方制作，包含了对特定发行版的一些修改。 1234yum info supervisoryum search supervisoryum install -y supervisor 通过pip安装1pip install supervisor 创建一个配置文件由于我是通过yum安装，所以supervisor配置文件自动在/etc下自动生成： 默认配置文件： /etc/supervisord.conf建议在此配置文件中加入[include]，默认已包含此配置 目录： /etc/supervisord.d建议将每个配置单独写在此目录下 运行Supervisor 添加一个程序在supervisord为你做任何有用的事情之前，你至少需要在配置文件中添加一个程序部分。program部分将定义在调用supervisord命令时如何运行和管理一个程序。 一个最简单的栗子： 12[program:foo]command=/bin/cat 上面的栗子只命名了一个命令，还有很多其它关于程序部分的设置。 运行supervisord使用supervisord命令启动supervisord，进程将自我守护，并从终端分离。并将操作日志默认放于$CWD/supervisor.log。你可传递-n/--nodaemon标志来将进程放置于前台，这样对于debug很有帮助。 要更改supervisord控制的程序集，请编辑配置文件并kill- HUP，或以其它方式重新启动supervisord进程。 supervisord命令接受许多命令行选项。这些命令行选项中的每一个都会覆盖配置文件中的任何等效值。 详细选项： http://www.supervisord.org/running.html#supervisord-command-line-options 运行supervisorctl使用supervisorclt命令启动supervisorctl客户端。如果需要验证supervisord调用，则系统会要求您提供验证凭据。 123supervisorctl status allsupervisorctl stop all supervisorctl Actions如果在命令行中指定了-i或未指定任何操作(action)，则将启动交互式输入的shell解释操作。 12345678supervisorctl help#查看可操作的actiondefault commands (type help &lt;topic&gt;):=====================================add clear fg open quit remove restart start stop updateavail exit maintail pid reload reread shutdown status tail version Signalssupervisord程序可能会发送某些actions，让它在运行时执行某些操作。你可将这些信号发送到一个单一的supervisord的PID。 信号处理程序 SIGTERM supervisord及其所有子进程都将关闭 SIGINT supervisord及其所有子进程都将关闭 SIGQUIT supervisord及其所有子进程都将关闭 SIGHUP supervisord将关闭所有进程，重新载入配置文件并启动所有进程 SIGUSR2 supervisord将关闭并重新打开主要活动日志和所有子日志文件 运行安全开发人员尽力确保以root身份运行的supervisord进程不会导致意外的权限升级。但supervisord允许在其配置文件中的任意路径规范写入数据，允许任意路径选择可能会造成符号链接工具的漏洞。确保supervisord配置文件的权限安全，除此之外，确保Python PATH和标准库都有足够的文件权限保护。 开机自启由于我是yum安装，所以能够直接使用系统服务管理来设置开机自启。 配置文件Supervisor的配置文件通常命名为supervisord.conf。如果没有指定-c配置文件，应用程序会从以下位置去寻找配置文件： $CWD/supervisord.conf $CWD/etc/supervisord.conf /etc/supervisord.conf /etc/supervisor/supervisord.conf (since Supervisor 3.3.0) ../etc/supervisord.conf (Relative to the executable) ../supervisord.conf (Relative to the executable) 文件格式supervisord.conf is a Windows-INI-style (Python ConfigParser) file.它包含section（[header]）和section中的key/value对。 环境变量使用Python字符串表达式语法%(ENV_X)%，可以在配置文件中使用环境中存在的环境变量 12[program:example]command=/usr/bin/example --loglevel=%(ENV_LOGLEVEL)s [unix_http_server]在此section中应该插入在Unix domain socket上监听的HTTP server的配置参数。如果没有配置此section，则Unix domain socket HTTP server将不会启动。 123456789101112131415161718192021[unix_http_server]#supervisor监听HTTP/XML-RPC请求的Unix domain socket的路径file#socket文件的权限模式chmod#socket的用户和组chown#访问HTTP server需要的认证username#密码可以是明文，或使用SHA加密的字符串password [inet_http_server]监听TCP(internet) socket 的HTTP server的配置参数。如果此section未配置，inet HTTP server将不会启动。 12345678910#tcp host:port，supervisor监听HTTP/XML-RPC请求的地址port#HTTP server认证username#密码可以是明文，或SHA加密passwd [supervisord]与supervisord进程有关的全局设置。 123456789101112131415161718192021222324252627282930313233logfilelogfile_maxbyteslogfile_backps#critical, error, warn, info, debug, tracelogevelpidfileumasknodaemonminfdsminprocs#防止supervisord在启动时清除任何现有子日志文件nocleanupchildlogdiruserdirectorystrip_ansienviromentidentifier [supervisorctl]supervisorctl交互式shell程序。 123456789serverurl#与前面设置的验证账户一致usernamepasswordprompthistory_file [program:x]supervisord知道的应该启动和控制的程序。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566 #该程序启动时将运行的命令command #进程名称process_name #多个实例numproc #用于计算numprocs开始的数量numprocs_start #程序在启动和关闭顺序中的相对优先级priority #当supervisord启动时，改程序将自动启动autostart #程序在启动后需要保持运行以考虑启动成功的总秒数，设置为0表示不需要再任何特定的事件内保持运行startsecs #允许失败的尝试次数，然后放弃并将进程置入fatal状态startretries #自动重启进程autorestart #异常退出码exitcodes #请求停止时用于杀死程序的信号stopsignal #发送停止信号后，等待系统将信号返回给supervisord的秒数stopwaitsecs #将停止信号发送给整个进程组stopagroup #killasgroup #以哪个用户运行该程序userredirect_stderrstdout_logfilestdout_logfile_maxbytesstdout_logfile_backupsstdout_capture_maxbytesstdout_events_enabledstderr_logfilestderr_logfile_maxbytesstderr_logfile_backupsstderr_capture_maxbytesstderr_events_enabledenvironmentdirectoryumaskserverurl [include]如果配置文件包含[include]部分，则它必须包含一个名为files的key。该key中的值包含了其它配置文件。 12#文件空间的空格分隔序列，路径可以是相对或绝对。files [group:x]将同质进程组组合成一个异质进程组通常很有用，所以它们可以作为supervisor各种控制器接口的一个单元进行控制。 12345#程序的逗号分隔列表programs#优先级priority [fcgi-program:x]12345678910#程序的fastCGI socket或TCP或Unix domain socketsocket#为socket指定特定user或groupsocket_owner#指定permission模式socket_mode [eventlistener:x]supervisor允许在配置文件中定义专门的同质进程组(event listener pools)。 12345buffer_sizeeventsresult_handler [rpcinterface:x][rpcinterface:x]适用于希望通过自定义行为扩展supervisor的人们。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Consul]]></title>
    <url>%2F2018%2F04%2F05%2FConsul%2F</url>
    <content type="text"><![CDATA[参考： https://www.consul.io/intro/index.html https://www.consul.io/docs/ Consul Template: https://www.hashicorp.com/blog/introducing-consul-template 环境： CentOS7x86_64 Consul v1.2.0 简介介绍consul是什么，它可以解决哪些问题，以及如何开始使用它。 Consul是什么Consule有多个组件，但总体而言，它是发现(discovery)和配置(config)基础架构(infrastructure)服务的工具。它提供几个关键特点： 服务发现(service discovery) Consul客户端可提供一个服务，如API或mysql，其它客户端能够使用Consul来发现给定服务的提供者。使用DNS或HTTP，应用程序可以轻松找到他们所依赖的服务 健康检查(health checking) Consul可以提供任何数量的健康检查，既可以与给定服务相关联(webserver return 200)，也可与本地节点(内存使用率小于90%)相关联。操作人员可用此信息来监视集群运行状况，服务发现组件使用此信息将流量(traffic)从不健康的主机中引导出去 KV store 应用程序可将Consul的分层Key/Value用于存储任何目的，包括动态配置(dynamic configuration)、功能标记(feature flagging)、协调(coordination)、领导选举(leader election)…简单的HTTP API使其易于使用 多数据中心(Multi Datacenter) Consul支持多数据中心，这意味着Consul的用户不必担心构建额外的抽象层以扩展到多个区域 Consul旨在与DevOps和应用程序开发者保持友好，使其成为现代化 ，弹性基础架构的完美选择。 Consul用例 服务发现(service )服务注册，集成健康检查，使用DNS或HTTP接口使得任何服务都能被其它服务发现。 服务分割(service segmentation)通过自动TLS加密和基于身份的授权实现安全的服务到服务通信。 服务配置(service configuration)功能丰富的 key/value 可轻易配置服务。 Consul基础架构Consul是一个分布式、高可用的系统。 每一个向Consul提供服务的节点都运行一个Consul agent。运行agent对于服务发现或get/set Key/Value不是必需的。agent负责健康检查节点上的服务和节点自身。 agent可与一个或多个Consul server交流。Consul server是数据存储和复制集所在之地。server之间选出一个leader。虽然Consul可以使用一台服务器，但推荐使用3-5台以避免数据丢失的故障情况。对每一个数据中心都推荐使用Consul server cluster。 需要发现其它服务或节点的基础架构组件 可以查询任何Consul server或Consul agent。agent自动将查询发送到server。 每个数据中心运行一组consul server cluster。当发生cross-datacenter服务发现或配置请求时，本地consul server将请求转发给远程数据中心并返回结果。 快速开始安装Consul 二进制包: https://www.consul.io/downloads.html 解压缩，得到一个consul二进制可执行文件，可将其放入系统路径 验证安装: consul 运行consul-agent安装consul后请务必运行agent，agent可运行在server或client模式。每个datacenter必须至少有一台server，推荐3-5台做一个集群。单一server部署非常不安全，在故障情况下数据丢失就不可避免了。 所有其它agents都以client模式运行。client是一个非常轻量化的进程——它注册服务、运行健康检查、转发查询给server。agent必须运行在集群的每个节点上。 启动agent测试consul development模式，不建议在生产环境使用此方法，此处做测试。 12345consul agent -devnetstat -nltp#可根据日志看出agent已成为server，并成为集群leader Consul成员members命令基于gossip protocol并最终保持一致。 12345678910111213consul members#节点名称、监听地址、健康状态、集群角色、版本信息Node Address Status Type Build Protocol DC Segmentzhang22 127.0.0.1:8301 alive server 1.0.6 2 dc1 &lt;all&gt;#使用HTTP API将请求转发给server以获取一致的view of worldculr localhost:8500/v1/catalog/nodes#DNS interface也可以查询节点，默认端口8600dig @127.0.0.1 -p 8600 zhang22.node.consul 停止agent可使用Ctrl + C优雅地终止agent，你可以看到它离开集群并关闭。 优雅关闭，Consul会通知集群其它节点此节点的离开。如果你强制kill agent，则集群的其它节点将检测该节点失败。当成员离开时，其服务和健康检查将从catalog中移除。当成员失败时，其健康状态被标记为critical，但不会从catalog中移除。Consul会自动尝试重连失败的节点，允许它从当前网络条件中修复，知道离开的节点不在联系。 此外，如果agent正作为server在运行，那么优雅地离开对避免造成严重的影响有帮助。 注册服务注册(register)服务并查询(query)服务。 定义一个服务服务可以通过以下两种方法注册： 服务定义(service definition) 调用HTTP API 服务定义是注册服务最常见的方式，我们将构建前面agent的配置。 1234567891011#创建一个consul配置目录mkdir /etc/consul.d#编写服务定义配置文件#假设有一个web服务运行在80端口，添加一个便于query的tagecho &apos;&#123;&quot;service&quot;: &#123;&quot;name: &quot;web&quot;, &quot;tag&quot;: [&quot;rails&quot;], &quot;port&quot;: 80 &#125;&#125;&apos; | tee /etc/consul.d/web.json#重启agent，指定配置目录consul agent -dev -config-dir=/etc/consul.d 如果你想注册多个服务，你可以在配置目录下创建多个服务定义文件。 查询服务一旦agent启动并且服务已同步，我们可通过HTTP API或DNS查询(query)服务。 DNS API使用DNS API(默认8600)查询服务 12345678#DNS name(默认) -- NAME.service.consul#只有IPdig @127.0.0.1 -p 8600 web.service.consul#返回IP/Portdig @127.0.0.1 -p 8600 web.service.consul SRV 我们还可以用DNS API按tag来过滤service。基于标签的查询格式为tag.name.service.consul。 1dig @127.0.0.1 -p 8600 rails.web.service.consul HTTP API除了DNS API，HTTP API(默认8500)同样可用于查询服务。 12#前面定义了web这个servicecurl http://localhost:8500/v1/catalog/service/web catalog API提供了给定服务的所有节点。 12#仅仅健康实例的查询 curl &apos;http://localhost:8500/v1/health/service/web?passing&apos; 更新服务服务定义可以通过更改配置文件并向agent发送SIGHUP来更新。这使得更新服务不会出现任何停机或查询服务不可达的情况。 另外，HTTP API能够用来动态地添加、移除、修改服务。 Consul集群具有多个成员的consul集群。 当consul节点启动时，它不知道任何其它节点，它是一个孤立的集群。为了了解到集群中的其它成员，agent必须要加入一个存在的集群。要加入一个现有的集群，只需知道一个现有成员。当加入集群后，agent将于其此成员闲聊，并迅速发现集群中的其它成员。一个agent可以加入任何其它agent，而不仅仅是server模式的agent。 启动agents123456789101112131415#node1consul agent -server -bootstrap-expect=1 \ -data-dir=/tmp/consul -node=agent-one -bind=ip1 \ -enable-script-checks=true -config-dir=/etc/consul.d#node2consul agent -data-dir=/tmp/consul -node=agent-two \ -bind=ip2 -enable-script-checks=true -config-dir=/etc/consul.d#两个独立的node#现在，我们有两个agent在运行中：一个server，一个client。但是他们两者并不知道对方，并仍然是一个单一节点的集群。#查看节点consul member 加入集群由于我们在启动agent的时候便已指定server，所以从哪个节点加入都一样。 12345678consul join ip#Successfully joined cluster by contacting 1 nodes.consul membersNode Address Status Type Build Protocol DC Segmentagent-one 172.16.129.141:8301 alive server 1.0.6 2 dc1 &lt;all&gt;agent-two 172.16.129.150:8301 alive client 1.0.6 2 dc1 &lt;default&gt; 在启动时自动加入集群理想情况下，每当一个新节点出现在数据中心时，它应该自动加入集群而不需要人工干预。 查询节点就像查询服务，consul有一个API用于查询节点。 123#NAME.node.consul或NAME.node.DATACENTER.conosuldig @localhost -p 8600 agent-one.node.consuldig @127.0.0.1 -p 8600 agent-two.node.consul 离开集群 优雅的退出: Ctrl+C 强制kill 健康检查对节点和服务添加健康检查(health check)。健康检查是服务发现的关键组件，可以防止使用不健康的服务。 定义检查与服务类似，一个检查能够通过定义检查或适当调用HTTP API来两种方式来注册。 定义检查是一个最基本和推荐的方法。 在consul配置目录中创建检查定义文件： 123456789#在基于脚本的健康检查上，它与consul进程使用同样的用户#如果命令以非0状态码退出，则该节点会被标记为unhealthyecho &apos;&#123;&quot;check&quot;: &#123;&quot;name&quot;: &quot;ping&quot;, &quot;args&quot;: [&quot;ping&quot;, &quot;-c1&quot;, &quot;baidu.com&quot;], &quot;interval&quot;: &quot;30s&quot;&#125;&#125;&apos; &gt;/etc/consul.d/ping.jsonecho &apos;&#123;&quot;service&quot;: &#123;&quot;name&quot;: &quot;web&quot;, &quot;tags&quot;: [&quot;rails&quot;], &quot;port&quot;: 80, &quot;check&quot;: &#123;&quot;args&quot;: [&quot;curl&quot;, &quot;localhost&quot;], &quot;interval&quot;: &quot;10s&quot;&#125;&#125;&#125;&apos; &gt;/etc/consul.d/web.jsonconsul reload 检查健康状态123curl http://localhost:8500/v1/health/state/criticaldig @127.0.0.1 -p 8600 web.service.consul KV数据Consul提供了一个易于使用的KV存储。这可以用来保存动态配置，协助服务协调，构建leader选举，并启用开发人员可以考虑构建的任何其它内容。 用法有两种方法与Consul K/V交互的方式： HTTP API Consul KV CLI 123456789101112131415161718192021222324252627282930#CLIconsul kv --helpconsul kv put name zhangconsul kv get name#zhangconsul kv get -detailed nameconsul kv puut -flags=42 who zhang21#所有key都支持设置一个64位的整数标志值#列出所有kvconsul kv get -recurse#删除consul kv delete name#使用 Check-And-Set 进行原子更新consul kv put -cas -modify-index=112 NAME zhang#导出与导入consul kv export &gt; xxx.jsonconsul kv import $xxx.json Web界面Consul支持美观的Web界面。用户界面可以查看所有的服务和节点，查看所有健康检查和当前状态，读取和设置kv数据，并自动支持多数据中心。 123consul agent -ui#localhost:8500/ui 内部详情Consul Internals 介绍Consul内部详情。 架构Architecture 词汇表Glossary Agent Client Server Datacenter Consensus Gossip LAN Geossip WAN Geossip RPC Consensus协议Consul使用consensus(共识) protocol来提供一致性(consistency)，它基于Raft(In search of an Understandable Consensus Algorithm) Raft协议Raft是基于Paxos的共识算法。 Raft的一些关键术语： LogThe primary unit of work in a Raft system is a log entry. FSM(Finite State Machine)An FSM(有限状态机) is a collection of finite states with transitions between them. Peer setThe peer set(对等集) is the set of all members participating in log replication. QuorumA quorum(仲裁) is a majority of members from a peer set: for a set of size n, quorum requires at least (n/2)+1 members. Committed EntryAn entry is considered committed when it is durably stored on a quorum of nodes. LeaderAt any given time, the peer set elects a single node to be the leader. Raft节点总是处于如下三种状态之一： follower(追随者) candidate(候选者) leader(领导者) 所有节点最初都是作为follower开始的。在这种状态下，节点可接受leader的日志条目并投票。如果一段时间内没有收到任何条目，则节点会自我提升到candidate。在candidate状态下，节点请求来自对等节点的投票。如果候选人获得仲裁(quorum)的票数，那么它将被提升为leader。leader必须接受新的日志条目并复制给其它所有follower。另外，如果陈旧读取不可接受，则所有查询也必须在leader上执行。 一旦集群具有leader，它就能够接受新的日志条目。Client可以请求leader添加新的日志条目。然后，leader将条目持久化，并尝试复制到仲裁的follower。一旦日志条目被认为提交(committed)，它就可以应用于有限状态机(FSM)。显然，允许复制日志以无限制的方式增长是不可取的。Raft提供了一种机制，可通过快照(snapshot)当前状态并压缩日志。达成共识是容错的，直到法定人数可用。建议为每个数据中心配置3-5台Consul Server。3个节点的Raft集群可以容忍单个节点故障，5个节点的Raft集群可以容忍2个节点故障。这可最大限制提高可用性。 Raft in Consul只有Consul Server节点参与Raft，并且是对等集的一部分。所有的Client节点都将请求转发给Server。 当启动的时候，单个Consul Server进入bootstrap模式，此模式允许它进行自我选举为leader。leader选出后，可以以一致性和安全性的方式将其它Server添加到对等集，之后，就可以禁用bootstrap模式。由于所有的Server作为对等集的一部分参与，因此他们都知道当前的leader。当一个RPC请求到达了non-leader Server时，请求被转发给leader。 如果RPC是查询(query)类型，意味着它是只读的，则leader根据FSM的当前状态生成结果 如果RPC是事务(transaction)类型，意味着它是可修改的，则leader生成新的日志条目并使用Raft应用它 提交日志条目并将其应用于FSM后，事务就完成了。 由于Raft副本的性质，性能对网络延迟很敏感。因此，每个数据中心选择一个独立的leader并维护一个不相交的对等集。数据由数据中心分区，每个leader仅负责其数据中心中的数据。 一致性模式Consistency Modes 虽然对副本日志的所有写入都通过Raft，但读取却更加灵活。Consul支持3种不同的读取一致性模式： default consistent stale 部署表 Servers Quorum Size Failere Tolerance 1 1 0 2 2 0 3 2 1 4 3 1 5 3 2 6 4 2 7 4 3 Gossip协议Consul 使用gossip协议来管理成员并向集群发送广播信息。所有这些都通过Serf Library提供。 Goossip in ConsulConsul使用两个不同的gossip pools: LAN pool WAN pool 网络坐标Network Coordinates Consul使用网络层层析系统来计算集群中节点的网络坐标。这些坐标允许使用非常简单的计算在任意两个节点之间估计网络往返时间。所有这些都通过使用Serf Library。 Consul中的网络坐标Network Coordinates in Consul 网络坐标在Consul中有多种表现方式： consul rtt Catalog/Health endpoints Prepared query Coordinate endpoint 使用坐标一旦你有了两个节点的坐标，则计算它们间的往返时间是很简单的： 123456&quot;Coord&quot;: &#123; &quot;Adjustment&quot;: 0.1, &quot;Error&quot;: 1.5, &quot;Height&quot;: 0.02, &quot;Vec&quot;: [0.34,0.68,0.003,0.01,0.05,0.1,0.34,0.06]&#125; 会话Sessions consul提供了一个用于构建分布式锁的会话机制。会话充当节点、健康检查和K/V数据之间的监听层。 会话设计 Agent启动和停止Consul Agent是Consul的核心进程。它维护成员关系信息，注册服务，运行检查，响应查询…Consul Agent必须运行在在Consul集群的每个节点上。 Agent有两种运行模式： server client Server节点承担了作为consensus quorum(共识法人)的额外责任，这些节点参与Raft，并在出现故障时提供强大的一致性和可用性。Client节点构成了集群的大部分，它们非常轻便。因为它们与Server进行大部分操作，保持自己的状态则很少。 运行Agent以下是一些重要信息： Node name Datacenter Server Client addr Cluster addr 123456789#直接指定配置项运行consul agent -options#将配置项写入文件，指定配置目录运行mkdir /etc/consul.dvim /etc/consul.d/consul.jsonconsul agent -config-dir=/etc/consul.d 停止Agent有两种停止方式： gracefully发送中断信号ctrl+c或运行kill -INT。优雅地退出，Agent首先通知集群它要离开集群。这样，集群便会通知其它成员该节点已离开。 forcefully通过kill signal来强制杀掉Consul。集群的其余部分最终会检测到该节点已死亡并通知集群节点已失效。 特别重要的是允许Server节点优雅地离开，以便对可用性产生最小的影响。对于Client Agent来说，节点失效和节点离开的区别对用例并不是那么重要。 生命周期Consul集群中的每个Agent都会经历一个生命周期(lifecycle)。当Agent首次启动时，他并不知道集群中的其它任何节点。要发现它的同伴，它必须加入集群。这使用join命令或在配置文件中配置。一旦一个节点加入，这个信息就会传递给整个集群，这意味着所有节点最终都会意识到对方。如果Agent是一个Server，则已经存在的Server就会开始复制(replicating)到新节点。 在网络故障的情况下，某些节点可能无法被其它节点访问。在这种情况下，无法访问的节点被标记为失败(failed)。无法区分网络故障和Agent崩溃，因此两种情况的处理方式都是相同的。该信息将在service catalog中被更新。 当一个节点离开时，它指定了它的意图，并且集群将该节点标记为已离开。与失败(failed)不同，节点提供的所有服务都立即注销(deregistered)。如果Agent是Server，则对其的复制(replication)将停止。 为了防止死亡(failed/left)节点的堆积，Consul会自动将死亡节点从目录中移除。这个过程被称为收割(reaping)。 DNS接口DNS接口允许应用程序利用服务发现，而无需与Consul进行高度整合。 有几个重要的配置项： client_addr ports.dns recursors domain dns_config 数据中心部分是可选的，如果没有提供，则默认为Agent自身的数据中心。 节点查找为了解析名称(name)，Consul依赖于特定的查询格式。基本上有两种类型的查询： node lookup service lookup 1234567#node lookup&lt;node&gt;.node[.datacenter].&lt;domain&gt;node1.node.dc1.consulnode1.node.consuldig @127.0.0.1 -p 8600 node1.node.consul 服务查找服务查找用于查询你服务提供者。 有两种查询方式： 标准查询DNS查询系统利用健康检查信息来防止路由到不健康的节点。为了实现简单的负载均衡，每次返回的节点集都是随机的。 123456[tag.]&lt;service&gt;.service[.datacenter].&lt;domain&gt;redis.service.consulpostgresql.service.dc2.consuldig @127.0.0.1 -p 8600 redis.service.consul SRV RFC 2782查询RFC 2782使用_下划线作为查询中服务和协议值的前缀，以防止DNS冲突。 123_&lt;service&gt;._&lt;protocol&gt;[.service][.datacenter][.domain]dig @127.0.0.1 -p 8600 _rabbitmq._amqp.service.consul SRV Prepared Query LookupsThe query or name is the ID or given name of an existing Prepared Query. 1&lt;query or name&gt;.query[.datacenter].&lt;domain&gt; 可连接的服务查找Connect-Capable Service Lookups. 1&lt;service&gt;.connect.&lt;domain&gt; Caching默认情况下，Consul服务的所有DNS结果都会设置一个为0的TTL。这会禁用DNS结果的缓存。但，很多情况下，缓存对性能和伸缩性都是可取的。 WAN地址转换默认情况下，Consul DNS查询将会返回一个节点的本地地址。如果你需要外部地址，则可使用advertise-wan和translate_wan_addrs选项来配置此行为。 配置Agent有许多通过命令行或配置文件配置的配置项。配置优先级如下： 命令行参数 环境变量 配置文件 配置文件可以是HCL或JSON格式。Consul可通过reload命令重新载入配置文件。 端口Consul默认使用的端口： 8300(tcp)Server RPC. Server用于处理来自其它Agent的传入请求。 8301(tcp/udp)Serf LAN. 用于处理LAN中的gossip，所有Agent都需要。 8302(tcp/udp)Serf WAN. Server用于处理WAN上gossip到其它Server。 8500(tcp)HTTP API. 8600(tcp/udp)DNS Interface. 可重新加载的配置Reloadable Configuration 重新加载配置文件不会加载所有配置项，如下这些配置项是可重新载入的： log level checks services watches http client address node metadata metric prefix filter discard check output rpc rate limiting 配置文件配置文件不仅用于设置代理，还用于提供检查和服务定义。 配置文件选项和命令行参数稍微有点不一样。使用consul agent -h查看具体配置项。 栗子： 12345678910111213141516#开始栗子vim /etc/consul.d/single.json&#123;&quot;bind_addr&quot;: &quot;192.168.1.11&quot;,&quot;bootstrap&quot;: true,&quot;client_addr&quot;: &quot;0.0.0.0&quot;,&quot;datacenter&quot;: &quot;zhang&quot;,&quot;data_dir&quot;: &quot;/var/lib/consul&quot;,&quot;log_level&quot;: &quot;WARN&quot;,&quot;node_name&quot;: &quot;zhang21&quot;,&quot;server&quot;: true,&quot;enable_syslog&quot;: true,&quot;ui&quot;: true&#125; 123456789101112131415161718192021222324#集群配置vim /etc/consul.d/cluster.json&#123; &quot;bind_addr&quot;: &quot;xxx&quot;, &quot;bootstrap_expect&quot;: 2, &quot;client_addr&quot;: &quot;0.0.0.0&quot;, &quot;datacenter&quot;: &quot;zhang&quot;, &quot;data_dir&quot;: &quot;/var/lib/consul&quot;, &quot;encrypt&quot;: &quot;a1b8vAA2==@xyz&quot;, &quot;log_level&quot;: &quot;WARN&quot;, &quot;node_name&quot;: &quot;zhang21&quot;, &quot;node_id&quot;: &quot;zhang21&quot;, &quot;server&quot;: true, &quot;enable_syslog&quot;: true, &quot;ui&quot;: true, &quot;retry_interval&quot;: 20s, &quot;retry_join&quot;: [ &quot;consul.domain.internal&quot;, &quot;10.0.1.2:8301&quot;, &quot;[::1]:8301&quot; ]&#125; 服务定义服务发现的主要目标之一是提供可用服务的目录(catalog)。为此，Agent提供了一种简单的服务定义格式来声明服务的可用性，并可能将其与健康检查相关联。如果健康检查与服务关联，则认为它是应用程序级别。 服务定义服务定义方式： 配置文件(推荐) HTTP API 一个服务定义包含的字段： name(必须) id(可选) tags(可选) address(可选) port(可选) check(可选) meta(可选) enable_tag_override(可选) token(可选) id必须唯一，如果未设置id，默认使用name。 服务可以关联健康检查，这是一个强大的功能。检查必须是脚本、HTTP、TCP或TTL类型。 脚本类型，必须提供参数和间隔 HTTP类型，必须提供http和interval TCP类型，必须提供tcp和interval TTL类型，只能提供ttl 检查名称自动生成为: service:&lt;service-id&gt;，如果有多个服务检查注册，生成的id为： service:&lt;service:-id&gt;:&lt;num&gt;，num是从1开始递增的数字。 栗子： 1234567891011121314151617181920212223242526vim /etc/consul.d/redis.json&#123; &quot;service&quot;: &#123; &quot;name&quot;: &quot;redis&quot;, &quot;id&quot;: &quot;redis01&quot;, &quot;tags&quot;: [ &quot;master&quot; ], &quot;address&quot;: &quot;127.0.0.1&quot;, &quot;port&quot;: 6379, &quot;meta&quot;: &#123; &quot;meta&quot;: &quot;service definition for redis&quot; &#125;, &quot;enable_tag_override&quot;: false, &quot;check&quot;: &#123; &quot;id&quot;: &quot;redisTCP&quot;, &quot;name&quot;: &quot;redis service check&quot;, &quot;tcp&quot;: &quot;localhost:6379&quot;, &quot;interval&quot;: &quot;10s&quot;, &quot;timeout&quot;: &quot;1s&quot; &#125; &#125;&#125; 多个服务定义1234567891011121314151617181920212223242526272829303132333435363738&#123; &quot;services&quot;: [ &#123; &quot;id&quot;: &quot;red0&quot;, &quot;name&quot;: &quot;redis&quot;, &quot;tags&quot;: [ &quot;primary&quot; ], &quot;address&quot;: &quot;&quot;, &quot;port&quot;: 6000, &quot;checks&quot;: [ &#123; &quot;args&quot;: [&quot;/bin/check_redis&quot;, &quot;-p&quot;, &quot;6000&quot;], &quot;interval&quot;: &quot;5s&quot;, &quot;ttl&quot;: &quot;20s&quot; &#125; ] &#125;, &#123; &quot;id&quot;: &quot;red1&quot;, &quot;name&quot;: &quot;redis&quot;, &quot;tags&quot;: [ &quot;delayed&quot;, &quot;secondary&quot; ], &quot;address&quot;: &quot;&quot;, &quot;port&quot;: 7000, &quot;checks&quot;: [ &#123; &quot;args&quot;: [&quot;/bin/check_redis&quot;, &quot;-p&quot;, &quot;7000&quot;], &quot;interval&quot;: &quot;30s&quot;, &quot;ttl&quot;: &quot;60s&quot; &#125; ] &#125;, ... ]&#125; 检查定义Agent的主要角色便是管理系统级和应用级的健康检查。一个检查的定义有两种方式： 配置文件 HTTP API 检查方式： Script + Interval HTTP + Interval TCP + Interval TTL Docker + Interval gRPC + Interval 定义检查A script check: 123456789&#123; &quot;check&quot;: &#123; &quot;id&quot;: &quot;mem-util&quot;, &quot;name&quot;: &quot;Memory utilization&quot;, &quot;args&quot;: [&quot;/usr/local/bin/check_mem.py&quot;, &quot;-limit&quot;, &quot;256MB&quot;], &quot;interval&quot;: &quot;10s&quot;, &quot;timeout&quot;: &quot;1s&quot; &#125;&#125; A HTTP check: 123456789101112&#123; &quot;check&quot;: &#123; &quot;id&quot;: &quot;api&quot;, &quot;name&quot;: &quot;HTTP API on port 5000&quot;, &quot;http&quot;: &quot;https://localhost:5000/health&quot;, &quot;tls_skip_verify&quot;: false, &quot;method&quot;: &quot;POST&quot;, &quot;header&quot;: &#123;&quot;x-foo&quot;:[&quot;bar&quot;, &quot;baz&quot;]&#125;, &quot;interval&quot;: &quot;10s&quot;, &quot;timeout&quot;: &quot;1s&quot; &#125;&#125; A TCP check: 123456789&#123; &quot;check&quot;: &#123; &quot;id&quot;: &quot;ssh&quot;, &quot;name&quot;: &quot;SSH TCP on port 22&quot;, &quot;tcp&quot;: &quot;localhost:22&quot;, &quot;interval&quot;: &quot;10s&quot;, &quot;timeout&quot;: &quot;1s&quot; &#125;&#125; A TTL check: 12345678&#123; &quot;check&quot;: &#123; &quot;id&quot;: &quot;web-app&quot;, &quot;name&quot;: &quot;Web App Status&quot;, &quot;notes&quot;: &quot;Web app does a curl internally every 10 seconds&quot;, &quot;ttl&quot;: &quot;30s&quot; &#125;&#125; A Docker check: 12345678910&#123;&quot;check&quot;: &#123; &quot;id&quot;: &quot;mem-util&quot;, &quot;name&quot;: &quot;Memory utilization&quot;, &quot;docker_container_id&quot;: &quot;f972c95ebf0e&quot;, &quot;shell&quot;: &quot;/bin/bash&quot;, &quot;args&quot;: [&quot;/usr/local/bin/check_mem.py&quot;], &quot;interval&quot;: &quot;10s&quot; &#125;&#125; A gRPC check: 123456789&#123;&quot;check&quot;: &#123; &quot;id&quot;: &quot;mem-util&quot;, &quot;name&quot;: &quot;Service health status&quot;, &quot;grpc&quot;: &quot;127.0.0.1:12345&quot;, &quot;grpc_use_tls&quot;: true, &quot;interval&quot;: &quot;10s&quot; &#125;&#125; 检查脚本使用enable_script_checks选项来启用脚本检查。 检查脚本的退出码(exit code)必须遵循如下约定： exit code o检查通过 exit code 1检查警告 any exit code检查失败 初始化健康检查状态在某些情况下，可能需要指定健康检查的初始状态。 12345678&#123; &quot;check&quot;: &#123; &quot;id&quot;: &quot;mem&quot;, &quot;args&quot;: [&quot;/bin/check_mem&quot;, &quot;-limit&quot;, &quot;256MB&quot;], &quot;interval&quot;: &quot;10s&quot;, &quot;status&quot;: &quot;passing&quot; &#125;&#125; 绑定服务检查健康检查可以选择性地绑定到特定服务。这可以确保健康检查的状态只会影响给定服务的健康状态，而不会影响整个节点。服务绑定检查需要添加一个service_id字段： 12345678&#123; &quot;check&quot;: &#123; &quot;id&quot;: &quot;web-app&quot;, &quot;name&quot;: &quot;Web App Status&quot;, &quot;service_id&quot;: &quot;web-app&quot;, &quot;ttl&quot;: &quot;30s&quot; &#125;&#125; 定义多个检查使用checks来定义多个服务检查。 1234567891011121314151617181920212223&#123; &quot;checks&quot;: [ &#123; &quot;id&quot;: &quot;chk1&quot;, &quot;name&quot;: &quot;mem&quot;, &quot;args&quot;: [&quot;/bin/check_mem&quot;, &quot;-limit&quot;, &quot;256MB&quot;], &quot;interval&quot;: &quot;5s&quot; &#125;, &#123; &quot;id&quot;: &quot;chk2&quot;, &quot;name&quot;: &quot;/health&quot;, &quot;http&quot;: &quot;http://localhost:5000/health&quot;, &quot;interval&quot;: &quot;15s&quot; &#125;, &#123; &quot;id&quot;: &quot;chk3&quot;, &quot;name&quot;: &quot;cpu&quot;, &quot;script&quot;: &quot;/bin/check_cpu&quot;, &quot;interval&quot;: &quot;10s&quot; &#125;, ... ]&#125; 加密Encryption Consul Agent支持加密所有流量。有两个独立的加密系统： gossip流量 RPC gossip加密启用geossip加密只需要你在启动Consul Agent时设置加密密钥(encryption key)。密钥是16Bytes的Base64编码。 123456789consul keygenFDGDpW55oCYJlh555Es1gA==vim /etc/consul.d/cluster.json&#123; &quot;encrypt&quot;: &quot;FDGDpW55oCYJlh555Es1gA==&quot;,&#125; consul集群的所有节点必须共享相同的加密密钥！ RPC加密Consul支持使用TLS来验证Server和Client之间的真实性。它们之间使用由证书机构颁发的密钥对，你可以自己生成CA。 TelemetryConsul Agent收集有关不同库和子系统的各种运行时指标。这些指标以10s为间隔进行汇总，并保留1min。查看这些数据，你需要向Consul进程发送信号： Unix: USR1 Windows: BREAK Consul收到信号后，它将当前的遥测(telemetry)信息转储到Agent’s STDERR。 12#USR1 10kill -10 $&#123;consul-pid&#125; 详情: https://www.consul.io/docs/agent/telemetry.html Watcheswatches是一种指定检测更新的数据视图的方式。检测到更新，将调用外部处理程序。watch使用HTTP API中的blocking query，Agent自动进行适当的API调用已检测更新，并在数据视图更新时通知处理程序。watch可以配置为Agent configuration的一部分，watch也可以在Agent之外启动。 处理程序监测配置指定要监测的数据视图，更新视图后，将调用指定的处理程序(Handler)。外部程序可为可执行程序(executable)或HTTP endpoint。 可执行程序可执行处理程序从stdin读取json信息，此外CONSUL_INDEX环境变量将被设置为Consul Index写入stdout。 12345678&#123; &quot;type&quot;: &quot;key&quot;, &quot;key&quot;: &quot;foo/bar/baz&quot;, &quot;handler_type&quot;: &quot;script&quot;, &quot;args&quot;: [&quot;/usr/bin/my-service-handler.sh&quot;, &quot;-redis&quot;]&#125;#在consul v1.0以后，args数组被添加，以便可在没有shell的情况下运行处理程序 HTTP endpoint当watch被调用时发送HTTP请求给HTTP处理程序。 123456789101112&#123; &quot;type&quot;: &quot;key&quot;, &quot;key&quot;: &quot;foo/bar/baz&quot;, &quot;handler_type&quot;: &quot;http&quot;, &quot;http_handler_config&quot;: &#123; &quot;path&quot;:&quot;https://localhost:8000/watch&quot;, &quot;method&quot;: &quot;POST&quot;, &quot;header&quot;: &#123;&quot;x-foo&quot;:[&quot;bar&quot;, &quot;baz&quot;]&#125;, &quot;timeout&quot;: &quot;10s&quot;, &quot;tls_skip_verify&quot;: false &#125;&#125; 全局参数Global Parameters datacenter token args handler Watch类型 key keyprefix services nodes service checks event 栗子： 123consul watch -type service -service redisconsul watch -type checks -service redis 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#key&#123; &quot;type&quot;: &quot;key&quot;, &quot;key&quot;: &quot;foo/bar/baz&quot;, &quot;args&quot;: [&quot;/usr/bin/my-service-handler.sh&quot;, &quot;-redis&quot;]&#125;#orconsul watch -type=key -key=foo/bar/baz /usr/bin/my-key-handler.sh#keyprefix&#123; &quot;type&quot;: &quot;keyprefix&quot;, &quot;prefix&quot;: &quot;foo/&quot;, &quot;args&quot;: [&quot;/usr/bin/my-service-handler.sh&quot;, &quot;-redis&quot;]&#125;#orconsul watch -type=keyprefix -prefix=foo/ /usr/bin/my-prefix-handler.sh#services&#123; &quot;redis&quot;: []&#125;#nodes[ &#123; &quot;Node&quot;: &quot;node1&quot;, &quot;Address&quot;: &quot;192.168.1.11&quot; &#125;, &#123; &quot;Node&quot;: &quot;node2&quot;, &quot;Address&quot;: &quot;xxx&quot; &#125;]#service&#123; &quot;type&quot;: &quot;service&quot;, &quot;service&quot;: &quot;redis&quot;, &quot;args&quot;: [&quot;/usr/bin/my-service-handler.sh&quot;, &quot;-redis&quot;]&#125;#check[ &#123; &quot;Node&quot;: &quot;foobar&quot;, &quot;CheckID&quot;: &quot;service:redis&quot;, &quot;Name&quot;: &quot;Service &apos;redis&apos; check&quot;, &quot;Status&quot;: &quot;passing&quot;, &quot;Notes&quot;: &quot;&quot;, &quot;Output&quot;: &quot;&quot;, &quot;ServiceID&quot;: &quot;redis&quot;, &quot;ServiceName&quot;: &quot;redis&quot; &#125;]#event&#123; &quot;type&quot;: &quot;event&quot;, &quot;name&quot;: &quot;web-deploy&quot;, &quot;args&quot;: [&quot;/usr/bin/my-service-handler.sh&quot;, &quot;-web-deploy&quot;]&#125;#orconsul watch -type=event -name=web-deploy /usr/bin/my-deploy-handler.sh -web-deploy 指南Consul Guide 本节提供了Consul各种常见的操作指南。 如下： ACLsConsul访问控制列表，该功能用于控制对资源的访问。 Adding/Removing Servers从集群中安全地添加和删除Consul Server，这应该小心操作。 Autopilot为Consul Server提供自动友好操作的管理。 Bootstrapping引导新的数据中心，包括安全地添加初始化Consul Server。 Consul with Container在容器内运行Consul Cluster。 DNS Caching为DNS查询缓存启用TTLS DNS Forwarding从BIND转发DNS查询到Consul External Services注册外部服务。允许在Consul框架内使用第三方服务。 Federation配置Consul以支持多个数据中心。 Geo Failover用准备好的查询来实现服务的地理故障转移。 Leader Election使用Consul构建Client端的领导选举。 Network Segments配置Consul使用网段-支持部分LAN连接。 Outage Recovery恢复因Server故障而无法使用的集群。 Semaphore使用KV存储实现一个信号量 Sentinel使用哨兵模式在Consul中执行策略。 Server PerformanceConsul Server的最低要求以及生产环境中运行Consul Server的指南。 ACLsConsul提供可选的访问控制列表系统，用于控制对数据和API的访问。它依赖于规则的token. 访问控制列表旨在提供易于使用，快速执行和灵活的新策略。 概述ACL Tokens访问控制列表系统基于token(令牌)，由Consul操作者通过 Consul ACL API进行管理。如果没有提供token，则会自动关联与特殊的可配置匿名令牌(anonymous token)的规则。 每个token具有： ID name type client management rule set(规则集) ACL Rules and Scopetoken绑定到一组规则，用于控制令牌可以访问的Consul资源。可在白名单(whitelist)/黑名单(blacklist)下定义策略，这取决于默认策略acl_default_policy的值。 构建规则的ACL策略： agent用于Agent API event用于Event API key用于KV Store API keyring用于Keyring API node用于Catalog API, Health API, Prepare Query API, Network Coordinate API， Agent API operator用于Operator API query用于Prepared Query API serviceCatalog API, Health API, Prepared Query API, Agent API session用于Session API 由于Consul snapshots实际上包含ACL token，因此Snapshot API需要一个管理token进行快照操作。 ACL策略不包括如下资源： Status API Catalog API ACL Datacenter必须使用acl_datacenter配置所有节点(client/server)来启用ACL强制实施，但同时也是权威数据中心。Consul依靠RPC转发来支持多数据中心(multi-datacenter)。但是，由于可以跨数据中心边界发出请求，因此ACL令牌必须在全局范围内有效。为避免一致性问题，单个数据中心被视为具有权威性，并存储规范的令牌集。 配置ACLs使用多个配置项配置ACL： 配置项 Server Client 目的 acl_datacenter required required 为ACL定义权威Consul数据中心来启用ACL的主控制 acl_default_policy 可选 n/a 定义白名单或黑名单模式 acl_down_policy 可选 可选 定义ACL数据中心脱机时执行的操作 acl_ttl 可选 可选 定义缓存ACL的生存时间 配置特殊令牌，允许引导ACL系统或在特殊情况下访问Consul： 特殊令牌 Server Client 目的 acl_agent_master_token 可选 可选 当ACL数据中心不可用或Server脱机时，可用于访问Agent API acl_agent_token 可选 可选 用于Agent内部操作 acl_master_token required n/a 用于引导ACL系统 acl_token 可选 可选 用于未提供token的客户端请求的默认令牌。这通常配置为对服务的只读访问权限，以便在Agent上启用DNS发现 ACL Agent Master Token由于acl_agent_master_token旨在Consul Server不可用时使用，因此其策略在Agent本地管理，并且不需要通过ACL API在Consul Server上定义token。 123456agent &quot;&lt;node name of agent&gt;&quot; &#123; policy = &quot;write&quot;&#125;node &quot;&quot; &#123; policy = &quot;read&quot;&#125; ACL Agent Tokenacl_agent_token是一个特殊令牌，用于Agent的内部操作。用于Agent的如下操作： 使用Catalog API更新Agent的节点条目 执行反熵同步 执行consul_exec命令时，读写KV存储库的特殊_rexec部分 123456789node &quot;node1&quot; &#123; policy = &quot;write&quot;&#125;service &quot;&quot; &#123; policy = &quot;read&quot;&#125;key &quot;_rexec&quot; &#123; policy = &quot;write&quot;&#125; 任何一个可在Agent上注册的服务，service策略需要读访问权限。 引导ACLsBootstrapping ACLs 在新集群上引导ACLs需要几个步骤： Enable ACLs on the Consul Servers引导ACLs的第一步便是在ACL数据中心的Consul Server上启用ACLs，配置如下： 1234567&#123; &quot;acl_datacenter&quot;: &quot;dc1&quot;, &quot;acl_master_token&quot;: &quot;123abc!@#, &quot;acl_default_policy&quot;: &quot;deny&quot;, &quot;acl_down_policy&quot;: &quot;deny&quot;, &quot;acl_down_policy&quot;: &quot;extend-cache&quot;&#125; Create an Agent Token使用ACL API和上一步中设置的ACL Master Token创建令牌： 1234567891011curl --request PUT --header &quot;X-Consul-Token: 123abc!@#&quot; --data \&apos;&#123; &quot;Name&quot;: &quot;Agent Token&quot;, &quot;Type&quot;: &quot;client&quot;, &quot;Rules&quot;: &quot;node \&quot;\&quot; &#123; policy = \&quot;write\&quot;&#125; service \&quot;\&quot; &#123; policy = \&quot;read\&quot; &#125;&quot;&#125;&apos; http://127.0.0.1:8500/v1/acl/create返回的值便是新创建的token&#123;&quot;ID&quot;: &quot;xxxxxxxxxxxxxx&quot;&#125; 返回的值便是新创建的token。将这个值添加到Consul Server配置中，并重启Server： 12345678&#123; &quot;acl_datacenter&quot;: &quot;dc1&quot;, &quot;acl_master_token&quot;: &quot;123abc!@#, &quot;acl_default_policy&quot;: &quot;deny&quot;, &quot;acl_down_policy&quot;: &quot;deny&quot;, &quot;acl_down_policy&quot;: &quot;extend-cache&quot;, &quot;acl_agent_token&quot;: &quot;xxxxxxxxxxxxxxxx&quot;&#125; 或使用API导入token： 1234curl --request PUT --header &quot;X-Consul-Token: 123abc!@#&quot; --data \&apos;&#123; &quot;Token&quot;: &quot;xxxxxxxxxxxxx&quot;&#125;&apos; http://127.0.0.1:8500/v1/agent/token/acl_agent_token Enable ACLs on the Consul Clients还需再Agent上配置ACL 12345678910111213141516&#123; &quot;acl_datacenter&quot;: &quot;dc1&quot;, &quot;acl_down_policy&quot;: &quot;extend-cache&quot;, &quot;acl_agent_token&quot;: &quot;前面的acl_agent_token&quot;&#125;#或使用APIcurl \ --request PUT \ --header &quot;X-Consul-Token: abc123!@#&quot; \ --data \&apos;&#123; &quot;Token&quot;: &quot;xxxxxxxxxxxx&quot;&#125;&apos; http://127.0.0.1:8500/v1/agent/token/acl_agent_token 使用由Server创建的相同ACL Agent token，因为它不是特定于任何节点或前缀集。建议每个Client获取一个ACL agent token，该令牌具有对自己的节点名称前缀的节点有写入权限，以及针对预期在该Client上注册的服务前缀的读权限。 Set an Anonymous Policy (Optional)此时，ACL已通过配置的ACL agent token进行引导，但还没有配置其它策略。甚至像consul members这样的基本操作也会受到ACL默认策略deny的限制。 如果我们提供上面的Token，则能够看到具体信息： 1CONSUL_HTTP_TOKEN=xxxxxxxx consul members 匿名令牌： 123456789curl \ --request PUT \ --header &quot;X-Consul-Token: 123abc!@#&quot; \ --data \&apos;&#123; &quot;ID&quot;: &quot;anonymous&quot;, &quot;Type&quot;: &quot;client&quot;, &quot;Rules&quot;: &quot;node \&quot;\&quot; &#123; policy = \&quot;read\&quot; &#125;&quot;&#125;&apos; http://127.0.0.1:8500/v1/acl/update 某个服务：123456789curl \ --request PUT \ --header &quot;X-Consul-Token: 123abc!@#&quot; \ --data \&apos;&#123; &quot;ID&quot;: &quot;anonymous&quot;, &quot;Type&quot;: &quot;client&quot;, &quot;Rules&quot;: &quot;node \&quot;\&quot; &#123; policy = \&quot;read\&quot; &#125; service \&quot;consul\&quot; &#123; policy = \&quot;read\&quot; &#125;&quot;&#125;&apos; http://127.0.0.1:8500/v1/acl/update Set Agent-Specific Default Tokens (Optional)匿名令牌的替代方法是acl_token配置项。 Create Tokens for UI Use (Optional)如果你使用具有限制性ACL策略的Consul UI，UI将无法使用匿名ACL令牌完整运行。建议使用特定于UI的ACL令牌，可以在Web浏览器绘画期间在UI中设置该令牌对进口进行认证。 123456789curl \ --request PUT \ --header &quot;X-Consul-Token: 123abc!@#&quot; \ --data \&apos;&#123; &quot;Name&quot;: &quot;UI Token&quot;, &quot;Type&quot;: &quot;client&quot;, &quot;Rules&quot;: &quot;key \&quot;\&quot; &#123; policy = \&quot;write\&quot; &#125; node \&quot;\&quot; &#123; policy = \&quot;read\&quot; &#125; service \&quot;\&quot; &#123; policy = \&quot;read\&quot; &#125;&quot;&#125;&apos; http://127.0.0.1:8500/v1/acl/create 规则Rule Specification ACL系统的和核心部分是规则语言，用于描述必须强制执行的策略。使用基于前缀的规则，最具体的前缀匹配决定了操作。使用HCL配置语言来指定规则，规则可定义多个策略。ACL API运行使用HCL或JSON来定义规则部分的内容。 策略有以下集中处理方式： read write(读写) deny 栗子： 12345678910111213# These control access to the key/value store.key &quot;&quot; &#123; policy = &quot;read&quot;&#125;key &quot;foo/&quot; &#123; policy = &quot;write&quot;&#125;key &quot;foo/private/&quot; &#123; policy = &quot;deny&quot;&#125;# This controls access to cluster-wide Consul operator information.operator = &quot;read&quot; Agent RulesAgent策略控制对Agent API中实用程序操作的访问。Agent规则通过节点名称，使用欧冠最长前缀匹配规则。 Agent rules栗子： 123456789agent &quot;&quot; &#123; policy = &quot;read&quot;&#125;agent &quot;foo&quot; &#123; policy = &quot;write&quot;&#125;agent &quot;bar&quot; &#123; policy = &quot;deny&quot;&#125; 如上，对具有空前缀的任何节点可读，对以foo开头的节点名进行读写，拒绝以bar开头的节点名。 Event Rules事件策略控制对事件API中事件操作的访问。事件规则由它们事件名称的前缀，使用最长匹配规则。 Event rules栗子： 123456event &quot;&quot; &#123; policy = &quot;read&quot;&#125;event &quot;deploy&quot; &#123; policy = &quot;write&quot;&#125; Key/Value Rules键值策略控制对KV API中的键值存储操作的访问。 Key规则栗子： 123456789key &quot;&quot; &#123; policy = &quot;read&quot;&#125;key &quot;foo&quot; &#123; policy = &quot;write&quot;&#125;key &quot;bar&quot; &#123; policy = &quot;deny&quot;&#125; List Policy for Keys一个新的键列表策略，只有在通过布尔配置参数acl_enable_key_list_policy选择时才会强制执行。 1234567891011key &quot;&quot; &#123; policy = &quot;deny&quot;&#125;key &quot;bar&quot; &#123; policy = &quot;list&quot;&#125;key &quot;baz&quot; &#123; policy = &quot;read&quot;&#125; Kerring Rules 1keyring = &quot;write&quot; Node Rules 123456789node &quot;&quot; &#123; policy = &quot;read&quot;&#125;node &quot;app&quot; &#123; policy = &quot;write&quot;&#125;node &quot;admin&quot; &#123; policy = &quot;deny&quot;&#125; Operator Rules 1operator = &quot;read&quot; Prepared Query Rules 123456query &quot;&quot; &#123; policy = &quot;read&quot;&#125;query &quot;foo&quot; &#123; policy = &quot;write&quot;&#125; 引导数据中心Bootstrapping a Datacenter 在Consul集群可以开始为请求提供服务之前，必须选在Server节点作为leader。Bootstrapping是将这些初始Server节点加入集群的过程。 建议的引导方式是使用-bootstrap-expect配置项。此配置项告知Consul预期的Server节点数，并在有许多Server可用时自动引导。为了防止不一致和脑裂情况(多个Server认为自己是leader)，所有Server应该指定相同的-bootstrap-expect，或根本不指定任何值。只有指定值的Server才会尝试引导集群。为了防止脑裂情况，Server不会选举自己作为leader。 推荐每个数据中心使用3或5台Server。不建议使用单个服务器部署数据中心。 加入一个集群: 12#On NodeBconsul join NodeA 创建集群要触发选举leader，必须将这些机器连接在一起并创建一个集群。 使用-join和start_join选项手动指定机器列表 使用-retry-join选项手动指定机器列表 leader选举使用Consul构建客户端的领导选举。 有多种方式建立领导选举，我们将专注于Consul sessions。会话允许我们构建一个可以优雅地处理故障的系统。 协调节点Contending Nodes 假设一组节点试图称为给定服务的领导者，参与的所有节点应该就给定的键进行协调。 1servece/&lt;service name&gt;/leader 首先创建会话： 123curl -X PUT &apos;&#123; &quot;Name&quot;: &quot;dbservice&quot; &#125;&apos; http://localhost:8500/v1/session/create这回返回一个JSON对象的session ID 下一步是使用?acquirre=&lt;session&gt;查询参数的KV条目上的PUT方法从此节点获取给定键的会话。PUT的&lt;body&gt;应该是表示本地节点的JSON对象。 1234curl -X PUT -d &lt;body&gt; http://localhost:8500/v1/kv/&lt;key&gt;?acquire=&lt;session&gt;如果返回true，则已获得锁定，并且本地节点时领导者如果返回false，则某个其它节点已获取锁定 通过对&lt;key&gt;的阻塞查询来监视更改，如果注意到&lt;key&gt;的session是空白的，那么就没有领导者，我们应该重新锁定获取。如果领导是自愿下台，这应该通过简单地释放锁来完成： 1curl -X PUT http://localhost:8500/v1/kv/&lt;key&gt;?release=&lt;session&gt; 发现一个领导者Discovering a Leader 关于领导者选举的另一种常见做法是节点希望识别给定服务的领导者。与领导者选举一样，所有参与的节点都应该同意用于协调的密钥(key)。 Client有一个非常简单的角色，它们只需阅读&lt;key&gt;来发现当前的领导者是谁: 1curl http://localhost:8500/v1/kv/&lt;key&gt; 如果密钥没有关联的话，就没有领导者。你可查询/v1/session/info获取session详细信息： 1curl http://localhost:8500/v1/session/info/xxxxxxxxxxx Client还应使用阻塞查询来查看密钥的更改，如果领导者退出或失败将清除与密钥相关联的会话。当选出新的领导者时，密钥值也将更新。 API文档链接: https://www.consul.io/api/index.html Consul的主要接口是RESTful HTTP API。API可对node，service，check，configuration…执行基本的CRUD操作。 版本前缀Version Prefix 所有API路由都以/v1/为前缀，这适用于v1 API。 consul-templateConsul Template 查询consul instance，并更新文件系统上任意数量的指定模板。作为额外的奖励，Consul Template可以在模板更新完成时执行任意命令。 Consul Tempalte可以查询Consul中的服务条目，keys, key values。强大的抽象和模板查询语言是Consul Template非常适合创建动态配置。 如： Apache Nginx HAproxy 安装 下载地址: https://releases.hashicorp.com/consul-template/ 步骤： 下载 解压 添加PATH 1234567891011121314wget https://releases.hashicorp.com/consul-template/0.19.5/consul-template_0.19.5_linux_amd64.tgztar -xzvf ./consul-template_0.19.5_linux_amd64.tgzmv ./consul-template /bin/#ormv consul-template /usr/local/binvim /etc/profileexport PATH=$PATH:/usr/local/binconsul-template --versionconsul-template v0.19.5 (57b6c71) 用法官方栗子： https://github.com/hashicorp/consul-template/tree/master/examples 1consul-template -h 命令行查询demo.consul.io这个consul实例。 渲染模板： 1234consul-template \ -template &quot;/tmp/nginx.ctmpl:/var/nginx/nginx.conf:nginx -s reload&quot; \ -template &quot;/tmp/redis.ctmpl:/var/redis/redis.conf:service redis restart&quot; \ -template &quot;/tmp/haproxy.ctmpl:/var/haproxy/haproxy.conf&quot; 监听Consul： 1consul-template -consul-addr=&quot;consul1:8500&quot; -consul-addr=&quot;consul2:8500&quot; 配置文件配置文件使用 HashiCorp Configuration Language编写的。这意味着，配置也是JSON兼容的。 命令行指定的选项优先于配置文件！ 12345mkdir /etc/consul-templatevim consul-template.hclconsul-template -config=&apos;/etc/consul-template/consul-template.hcl&apos; 配置文件详情： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353# This denotes the start of the configuration section for Consul. All values# contained in this section pertain to Consul.consul &#123; # This block specifies the basic authentication information to pass with the # request. For more information on authentication, please see the Consul # documentation. auth &#123; enabled = true username = &quot;test&quot; password = &quot;test&quot; &#125; # This is the address of the Consul agent. By default, this is # 127.0.0.1:8500, which is the default bind and port for a local Consul # agent. It is not recommended that you communicate directly with a Consul # server, and instead communicate with the local Consul agent. There are many # reasons for this, most importantly the Consul agent is able to multiplex # connections to the Consul server and reduce the number of open HTTP # connections. Additionally, it provides a &quot;well-known&quot; IP address for which # clients can connect. address = &quot;127.0.0.1:8500&quot; # This is the ACL token to use when connecting to Consul. If you did not # enable ACLs on your Consul cluster, you do not need to set this option. # # This option is also available via the environment variable CONSUL_TOKEN. token = &quot;abcd1234&quot; # This controls the retry behavior when an error is returned from Consul. # Consul Template is highly fault tolerant, meaning it does not exit in the # face of failure. Instead, it uses exponential back-off and retry functions # to wait for the cluster to become available, as is customary in distributed # systems. retry &#123; # This enabled retries. Retries are enabled by default, so this is # redundant. enabled = true # This specifies the number of attempts to make before giving up. Each # attempt adds the exponential backoff sleep time. Setting this to # zero will implement an unlimited number of retries. attempts = 12 # This is the base amount of time to sleep between retry attempts. Each # retry sleeps for an exponent of 2 longer than this base. For 5 retries, # the sleep times would be: 250ms, 500ms, 1s, 2s, then 4s. backoff = &quot;250ms&quot; # This is the maximum amount of time to sleep between retry attempts. # When max_backoff is set to zero, there is no upper limit to the # exponential sleep between retry attempts. # If max_backoff is set to 10s and backoff is set to 1s, sleep times # would be: 1s, 2s, 4s, 8s, 10s, 10s, ... max_backoff = &quot;1m&quot; &#125; # This block configures the SSL options for connecting to the Consul server. ssl &#123; # This enables SSL. Specifying any option for SSL will also enable it. enabled = true # This enables SSL peer verification. The default value is &quot;true&quot;, which # will check the global CA chain to make sure the given certificates are # valid. If you are using a self-signed certificate that you have not added # to the CA chain, you may want to disable SSL verification. However, please # understand this is a potential security vulnerability. verify = false # This is the path to the certificate to use to authenticate. If just a # certificate is provided, it is assumed to contain both the certificate and # the key to convert to an X509 certificate. If both the certificate and # key are specified, Consul Template will automatically combine them into an # X509 certificate for you. cert = &quot;/path/to/client/cert&quot; key = &quot;/path/to/client/key&quot; # This is the path to the certificate authority to use as a CA. This is # useful for self-signed certificates or for organizations using their own # internal certificate authority. ca_cert = &quot;/path/to/ca&quot; # This is the path to a directory of PEM-encoded CA cert files. If both # `ca_cert` and `ca_path` is specified, `ca_cert` is preferred. ca_path = &quot;path/to/certs/&quot; # This sets the SNI server name to use for validation. server_name = &quot;my-server.com&quot; &#125;&#125;# This is the signal to listen for to trigger a reload event. The default# value is shown below. Setting this value to the empty string will cause CT# to not listen for any reload signals.reload_signal = &quot;SIGHUP&quot;# This is the signal to listen for to trigger a graceful stop. The default# value is shown below. Setting this value to the empty string will cause CT# to not listen for any graceful stop signals.kill_signal = &quot;SIGINT&quot;# This is the maximum interval to allow &quot;stale&quot; data. By default, only the# Consul leader will respond to queries; any requests to a follower will# forward to the leader. In large clusters with many requests, this is not as# scalable, so this option allows any follower to respond to a query, so long# as the last-replicated data is within these bounds. Higher values result in# less cluster load, but are more likely to have outdated data.max_stale = &quot;10m&quot;# This is the log level. If you find a bug in Consul Template, please enable# debug logs so we can help identify the issue. This is also available as a# command line flag.log_level = &quot;warn&quot;# This is the path to store a PID file which will contain the process ID of the# Consul Template process. This is useful if you plan to send custom signals# to the process.pid_file = &quot;/path/to/pid&quot;# This is the quiescence timers; it defines the minimum and maximum amount of# time to wait for the cluster to reach a consistent state before rendering a# template. This is useful to enable in systems that have a lot of flapping,# because it will reduce the the number of times a template is rendered.wait &#123; min = &quot;5s&quot; max = &quot;10s&quot;&#125;# This denotes the start of the configuration section for Vault. All values# contained in this section pertain to Vault.vault &#123; # This is the address of the Vault leader. The protocol (http(s)) portion # of the address is required. address = &quot;https://vault.service.consul:8200&quot; # This is the grace period between lease renewal of periodic secrets and secret # re-acquisition. When renewing a secret, if the remaining lease is less than or # equal to the configured grace, Consul Template will request a new credential. # This prevents Vault from revoking the credential at expiration and Consul # Template having a stale credential. # # Note: If you set this to a value that is higher than your default TTL or # max TTL, Consul Template will always read a new secret! # # This should also be less than or around 1/3 of your TTL for a predictable # behaviour. See https://github.com/hashicorp/vault/issues/3414 grace = &quot;5m&quot; # This is the token to use when communicating with the Vault server. # Like other tools that integrate with Vault, Consul Template makes the # assumption that you provide it with a Vault token; it does not have the # incorporated logic to generate tokens via Vault&apos;s auth methods. # # This value can also be specified via the environment variable VAULT_TOKEN. token = &quot;abcd1234&quot; # This tells Consul Template that the provided token is actually a wrapped # token that should be unwrapped using Vault&apos;s cubbyhole response wrapping # before being used. Please see Vault&apos;s cubbyhole response wrapping # documentation for more information. unwrap_token = true # This option tells Consul Template to automatically renew the Vault token # given. If you are unfamiliar with Vault&apos;s architecture, Vault requires # tokens be renewed at some regular interval or they will be revoked. Consul # Template will automatically renew the token at half the lease duration of # the token. The default value is true, but this option can be disabled if # you want to renew the Vault token using an out-of-band process. # # Note that secrets specified in a template (using &#123;&#123;secret&#125;&#125; for example) # are always renewed, even if this option is set to false. This option only # applies to the top-level Vault token itself. renew_token = true # This section details the retry options for connecting to Vault. Please see # the retry options in the Consul section for more information (they are the # same). retry &#123; # ... &#125; # This section details the SSL options for connecting to the Vault server. # Please see the SSL options in the Consul section for more information (they # are the same). ssl &#123; # ... &#125;&#125;# This block defines the configuration for connecting to a syslog server for# logging.syslog &#123; # This enables syslog logging. Specifying any other option also enables # syslog logging. enabled = true # This is the name of the syslog facility to log to. facility = &quot;LOCAL5&quot;&#125;# This block defines the configuration for de-duplication mode. Please see the# de-duplication mode documentation later in the README for more information# on how de-duplication mode operates.deduplicate &#123; # This enables de-duplication mode. Specifying any other options also enables # de-duplication mode. enabled = true # This is the prefix to the path in Consul&apos;s KV store where de-duplication # templates will be pre-rendered and stored. prefix = &quot;consul-template/dedup/&quot;&#125;# This block defines the configuration for exec mode. Please see the exec mode# documentation at the bottom of this README for more information on how exec# mode operates and the caveats of this mode.exec &#123; # This is the command to exec as a child process. There can be only one # command per Consul Template process. command = &quot;/usr/bin/app&quot; # This is a random splay to wait before killing the command. The default # value is 0 (no wait), but large clusters should consider setting a splay # value to prevent all child processes from reloading at the same time when # data changes occur. When this value is set to non-zero, Consul Template # will wait a random period of time up to the splay value before reloading # or killing the child process. This can be used to prevent the thundering # herd problem on applications that do not gracefully reload. splay = &quot;5s&quot; env &#123; # This specifies if the child process should not inherit the parent # process&apos;s environment. By default, the child will have full access to the # environment variables of the parent. Setting this to true will send only # the values specified in `custom_env` to the child process. pristine = false # This specifies additional custom environment variables in the form shown # below to inject into the child&apos;s runtime environment. If a custom # environment variable shares its name with a system environment variable, # the custom environment variable takes precedence. Even if pristine, # whitelist, or blacklist is specified, all values in this option # are given to the child process. custom = [&quot;PATH=$PATH:/etc/myapp/bin&quot;] # This specifies a list of environment variables to exclusively include in # the list of environment variables exposed to the child process. If # specified, only those environment variables matching the given patterns # are exposed to the child process. These strings are matched using Go&apos;s # glob function, so wildcards are permitted. whitelist = [&quot;CONSUL_*&quot;] # This specifies a list of environment variables to exclusively prohibit in # the list of environment variables exposed to the child process. If # specified, any environment variables matching the given patterns will not # be exposed to the child process, even if they are whitelisted. The values # in this option take precedence over the values in the whitelist. # These strings are matched using Go&apos;s glob function, so wildcards are # permitted. blacklist = [&quot;VAULT_*&quot;] &#125; # This defines the signal that will be sent to the child process when a # change occurs in a watched template. The signal will only be sent after the # process is started, and the process will only be started after all # dependent templates have been rendered at least once. The default value is # nil, which tells Consul Template to stop the child process and spawn a new # one instead of sending it a signal. This is useful for legacy applications # or applications that cannot properly reload their configuration without a # full reload. reload_signal = &quot;&quot; # This defines the signal sent to the child process when Consul Template is # gracefully shutting down. The application should begin a graceful cleanup. # If the application does not terminate before the `kill_timeout`, it will # be terminated (effectively &quot;kill -9&quot;). The default value is &quot;SIGTERM&quot;. kill_signal = &quot;SIGINT&quot; # This defines the amount of time to wait for the child process to gracefully # terminate when Consul Template exits. After this specified time, the child # process will be force-killed (effectively &quot;kill -9&quot;). The default value is # &quot;30s&quot;. kill_timeout = &quot;2s&quot;&#125;# This block defines the configuration for a template. Unlike other blocks,# this block may be specified multiple times to configure multiple templates.# It is also possible to configure templates via the CLI directly.template &#123; # This is the source file on disk to use as the input template. This is often # called the &quot;Consul Template template&quot;. This option is required if not using # the `contents` option. source = &quot;/path/on/disk/to/template.ctmpl&quot; # This is the destination path on disk where the source template will render. # If the parent directories do not exist, Consul Template will attempt to # create them, unless create_dest_dirs is false. destination = &quot;/path/on/disk/where/template/will/render.txt&quot; # This options tells Consul Template to create the parent directories of the # destination path if they do not exist. The default value is true. create_dest_dirs = true # This option allows embedding the contents of a template in the configuration # file rather then supplying the `source` path to the template file. This is # useful for short templates. This option is mutually exclusive with the # `source` option. contents = &quot;&#123;&#123; keyOrDefault \&quot;service/redis/maxconns@east-aws\&quot; \&quot;5\&quot; &#125;&#125;&quot; # This is the optional command to run when the template is rendered. The # command will only run if the resulting template changes. The command must # return within 30s (configurable), and it must have a successful exit code. # Consul Template is not a replacement for a process monitor or init system. command = &quot;restart service foo&quot; # This is the maximum amount of time to wait for the optional command to # return. Default is 30s. command_timeout = &quot;60s&quot; # Exit with an error when accessing a struct or map field/key that does not # exist. The default behavior will print &quot;&lt;no value&gt;&quot; when accessing a field # that does not exist. It is highly recommended you set this to &quot;true&quot; when # retrieving secrets from Vault. error_on_missing_key = false # This is the permission to render the file. If this option is left # unspecified, Consul Template will attempt to match the permissions of the # file that already exists at the destination path. If no file exists at that # path, the permissions are 0644. perms = 0600 # This option backs up the previously rendered template at the destination # path before writing a new one. It keeps exactly one backup. This option is # useful for preventing accidental changes to the data without having a # rollback strategy. backup = true # These are the delimiters to use in the template. The default is &quot;&#123;&#123;&quot; and # &quot;&#125;&#125;&quot;, but for some templates, it may be easier to use a different delimiter # that does not conflict with the output file itself. left_delimiter = &quot;&#123;&#123;&quot; right_delimiter = &quot;&#125;&#125;&quot; # This is the `minimum(:maximum)` to wait before rendering a new template to # disk and triggering a command, separated by a colon (`:`). If the optional # maximum value is omitted, it is assumed to be 4x the required minimum value. # This is a numeric time with a unit suffix (&quot;5s&quot;). There is no default value. # The wait value for a template takes precedence over any globally-configured # wait. wait &#123; min = &quot;2s&quot; max = &quot;10s&quot; &#125;&#125; 栗子： 123456789101112131415161718192021222324252627282930313233343536373839404142vim /etc/consul-template/consul.hclmax_stale = &apos;10m&apos;wait = &#123; min = &apos;1s&apos; max = &apos;3s&apos;&#125;template &#123; source = &apos;/etc/consul-template/ctmpl/a.ctmpl&apos; destination = &apos;/etc/nginx/conf.d/upstream-a.conf&apos; command = &apos;systemctl reload nginx&apos; perms = 0644&#125;#vim /etc/consul-template/ctmpl/a.ctmplupstream upstream-a &#123; &#123;&#123;range service &apos;a&apos;&#125;&#125; server &#123;&#123;.Address&#125;&#125;:&#123;&#123;.Port&#125;&#125;; &#123;&#123;else&#125;&#125; server 127.0.0.1:12345; &#123;&#123;end&#125;&#125;&#125;#nginxvim /etc/nginx/conf.d/upstream-a.confupstream upstream-a &#123; server 192.168.1.11:12345;&#125; 模板语法Consul Template解析文件以 Go Template创作。Consul Template提供了如下函数： API函数API函数与远程API进行交互，与Consul等外部服务进行通信。 datacenters查询Consul目录中的所有数据中心。 12345678910&#123;&#123; datacenters &#125;&#125;#栗子&#123;&#123; range datacenters &#125;&#125;&#123;&#123; . &#125;&#125;&#123;&#123; end &#125;&#125;#效果dc1dc2]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Consul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker]]></title>
    <url>%2F2018%2F03%2F27%2FDocker%2F</url>
    <content type="text"><![CDATA[参考： Docker文档: https://docs.docker.com/ https://blog.csdn.net/sD7O95O/article/details/78623697 https://www.zhihu.com/question/22969309/answer/34030581 环境： CentOS7x86_64 Docker v18.03 概述Docker是一个开发、shipping、运行应用程序的开放平台。Docker使你能够将应用程序与基础架构(infrastructure)分离开，从而可以快速交付软件。借助Docker，你可以像管理应用程序一样管理基础架构。利用Docker的方法快速进行运输、测试和部署代码，可以显著缩短编写代码和在生存环境中运行代码之间的延迟。 Docker平台Docker提供了在称为容器的松散隔离(isolated)环境中 打包和运行应用程序的能力。隔离性和安全性允许你在给定的主机上同时运行多个容器。容器是轻量级(lightweight)的，因为它们不需要hypervisor的额外负载，而是直接使用主机的内核运行。这意味着，与使用虚拟机相比，你可以在给定的硬件组合上运行更多的容器。你甚至可以在虚拟主机中运行Docker容器。 Docker提供了工具和平台来管理容器的生命周期(lifecycle)： 使用容器开发应用程序及其支持组件 容器成为分发和测试你应用程序的单元 准备好后，将你的应用程序部署到生产环境中，作为容器协调服 Docker引擎Docker引擎是一个包含如下部件的client-server应用程序： Server是称为守护进程的dockerd REST API是指定程序可用于与守护进程进行通信并指示其执行操作的接口 Client是command line interface(CLI) Docker的开源许可协议是Apache2.0 能用Docker做什么快速、一致的交付应用程序 通过允许开发人员在 提供应用程序和服务的本地容器 的标准化环境 下工作，Docker简化了开发生命周期。容器非常适合持续集成(continuous intergration,CI)和持续交付(continuous deliver,CD)工作流程。 考虑如下示例场景： 开发者在本地编写代码，并使用Docker容器分享工作给他们的同事 使用Docker将应用程序push到测试环境，并自动执行和手动测试 当开发人员发现bug，他们能在开发环境中修复bug，并重新部署应用程序到测试环境进行测试和验证 测试完成后，向客户提供修补的应用程序 与将更新的image push到生产环境一样简单 响应式部署和伸缩 Docker的基于容器的平台支持高度可移植的工作负载。Docker container可以运行在笔记本、物理机、虚拟机、云平台… Docker的可移植性和轻量化特性也使得动态管理工作负载非常容易，可以近乎实时地按业务需求扩展或拆分应用程序和服务 在同一硬件上运行更多的工作负载 Docker轻量且快速。它为基于hypersior的虚拟机提供了一种可行、经济高效的替代方案，因此你可以使用更多计算容量来实现业务目标。Docker是高密度环境和中小型部署的理想选择，你需要用更小的资源做更多的事情。 Docker架构Docker使用了client-server的体系架构。客户端向守护进程发送消息，守护进程负责构建、运行和分发 Docker容器。客户端和守护进程可以在同一系统上运行，也可将客户端连接到远程的Docker守护进程。客户端和守护进程使用REST API，通过Unix socket或network interface进程通信。 Docker daemonDocker daemon(dockerd)，监听Docker API请求并管理Docker对象——image、container、network、volume。docker daemon还可与其它docker daemon通信来管理docker service。 Docker clientDocker client(docker)是许多Docker用户与Docker进行交互的主要方式。客户端将命令发送给守护进程，守护进程执行命令。Docker命令使用Docker API，Docker客户端可与多个守护进程进行通信。 Docker registryDocker registry存储Docker image。Docker Hub和Docker Cloud是任何人都可使用的public registry，你可以创建private registry。 docker pull或docker run需要的image便是从配置的registry中提取。docker push推送image到你配置的registry。 Docker对象当你使用Docker时，你会创建和使用 image、container、network、volume、plugin和其它对象。 image镜像是一个只读模板，带有创建Docker容器的说明。通常，镜像基于其它镜像，并具有一些额外的自定义功能。例如，你可构建基于Ubuntu镜像的镜像，但会按照ApacheWeb服务器和应用程序，以及应用程序所需的配置。 你可能创建自己的镜像，或使用由别人创建并推送到registry上的镜像。构建自己的镜像，需要使用简单的语法创建一个Dockerfile，以定义创建镜像并运行它所需的步骤。 container容器是镜像的可运行实例。可将容器连接到一个或多个网络，将存储器连接到它，还可根据当前状态创建新镜像。 默认情况下，容器与其它容器以及主机是相对隔离的。你可以控制容器的网络、存储、其它底层子系统与其它容器或主机的隔离程度。 容器由镜像定义，以及你在创建或启动时提供给它的任何配置选项。当一个容器被移除时，其未被存储在永久存储器中的状态会消失。 栗子： 123#运行一个Ubuntu镜像，交互地连接到本地命令会话docker run -i -t ubuntu /bin/bash 以上命令会发生如下步骤: 如果本地没有Ubuntu镜像，docker会从registry拉取，就好像你手动运行 docker pull ubuntu Docker创建一个新容器，就好像你手动执行docker container create Docker分配一个读写文件系统给容器，作为它的最后一层 如果你没有指定任何网络选项，Docker会创建一个网络接口将容器连接到默认网络。 Docker开启容器并执行/bin/bash 发送exit到/bin/bash，容器停止但并未被移除 service服务允许你伸缩多个Docker守护进程的容器，这些守护进程可以作为一个swarm与多个manager和worker一起工作。默认情况下，该服务在所有node之间进行负载均衡。 底层技术Docker使用GO编写，利用Linux内核的几个特性来提供其功能。 namespace Docker使用一个称为namespace的技术来提供称为容器的独立工作空间。当你运行一个容器时，Docker会为该容器创建一组命名空间。命名空间提供了一个隔离层。容器的每个方面都在单独namespace中运行，并且其访问权限仅限于该单独的namespace。 Docker引擎在Linux上使用如下namespace： pid namespace： 进程隔离 net namespace： 管理网络接口 ipc namespace： 管理对IPC(InterProcess Communication)资源的访问 mnt namespace： 管理文件系统挂载点 ust namespace： 隔离内核和版本标识符(Unix Timesharing System) control groups Linux上的Docker Engine也依赖与另一种称为控制组(cgroups)的技术。cgroup将应用程序限制为一组特定的资源。控制组允许Docker引擎将可用的硬件资源共享给容器，并可选地强制实施限制和约束。例如，你可限制特定容器的内存是CPU使用率等。 union file systems union file systems(UnionFS)，是通过创建layer进行操作的文件系统，使得它们非常轻量和快速。Docker引擎使用UnioFS为容器提供构建block。Docker引擎可以使用多种UnionFS变体，包括AUFS, brrfs, vfs, DeviceMapper… container format Docker引擎将namespace、cgroup、UnionFS组合成一个名为容器格式的包装器。默认的容器格式为libcontainer。 安装Docker有两个可获取的版本： Community Edition(CE) 适合开始使用Docker并尝试基于容器的应用程序的开发人员和小型团队 Enterprise Edition(EE) 专为企业开发和IT团队而设计，可以在生产规模上构建，发布和运行关键业务应用程序 CentOS7安装Docker CEOS要求 CentOS7.x centos-extras repository 推荐使用overlay2存储驱动 安装新版本Docker需卸载老版本Docker Docker CE包被称为docker-ce 安装Docker CE https://download.docker.com/ 多种安装方法： Docker’s repository RPM package scripts 使用repository安装： 12345678910111213141516171819202122232425262728 #安装依赖yum install -y yum-utils device-mapper-persistent-data lvm2 #设置repositoryyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo #安装Docker CEyum install -y docker-ce #Docker安装但未启动，docker group会被创建，但没有用户添加到组中 #在生产环境中，你可能需要安装特定版本的Docker CE，而不是最新版yum list docker-ce --showduplicates | sort -ryum search docker-ce --showduplicates #开启dockersystemctl start docker #测试dockerdocker run hello-world #此命令下载一个测试image并将其运行到container中 #Hello from Docker! 使用package安装： 1234567891011 #下载rpm包https://download.docker.com/linux/centos/7/x86_64/stable/Packages/ #安装yum install -y /path/docker-cexxx.rpmsystemctl start dockerdocker run hello-world 使用scripts安装： 123456curl -fsSL get.docker.com -o get-docker.shsh get-docker.sh #手动添加group合userusermod -aG docker your-user 卸载Docker CE123456yum remove docker-ce #默认文件rm -rf /var/lib/docker #你还需要手动删除其它配置文件 开始 关于DockerDocker文档会有如下讲解： 设置你的Docker环境 在一个容器(container)中构建并运行一个镜像 延伸你的APP以便在多个容器中运行 在整个集群中分配你的APP 通过添加后端数据库来堆栈服务 将应用部署到生产 Docker的概念Docker是开发人员，系统管理员使用容器来开发、部署和运行APP的平台。使用Linux容器来部署APP被称为集装箱化(containerzation) 集装箱受欢迎的几点原因： 灵活(flexible) 轻量(lightweight) 通用(Interchangeable) 可移植(portable) 延伸(scalable) 堆栈(stackable) 镜像和容器通过运行镜像(image)启动容器(container)。镜像是一个可执行包，包含运行APP所需的所有内容：代码，库，环境变量，配置文件… 容器是镜像的运行时(runtime)实例。在Linux上使用docker ps命令查看运行的容器列表。 容器和虚拟机容器在Linux本地上运行，并与其它容器共享主机Kernel。它是一个独立的进程，不占其它可执行文件内存，使其轻量化。 虚拟机(VM)运行一个完整的访客操作系统，通过虚拟机管理程序访问主机资源。一般来说，虚拟机比大多数应用程序需要的资源更多。 准备Docker环境Docker版本： CE: Docker Community Edition EE: Docker Enterprise Edition Install Docker 测试Docker12345678910111213141516171819202122docker --version#查看详细信息docker info#测试安装工作是否正常docker run hello-world#查看镜像docker image ls#列出容器docker container ls -all#docker命令dockerdocker container --help 小结集装箱化使得CI/CD无缝： 持续集成(Continuous integration, CI) 持续部署(continuous deployment, CD) APP无系统依赖 更新能够推送到分布式APP的任何部分 资源密度可以被优化 使用Docker，扩展APP的过程就是启动新的可执行文件，而不是运行繁重的VM主机。 容器Container 先决条件1docker run hello-world 介绍是时候使用Docker方式来构建一个APP了。 从应用程序的层次结构底部开始，这是一个容器(container) 在此级别之上，是一个服务(service)，它定义了容器在生产中的表现 最后，顶层是堆栈(stack)，定义所有服务的交互(interaction) Like this: Stack Service Container 新开发环境在过去，如果你要开始编写一个Python APP，你的第一要务是在你的机器运行时安装Python。但是，这会造成你的计算机上的环境，需要如预期般完美适合你的APP，并且还需要与你的生产环境相匹配。 使用Docker，你可以将一个可移植的Python运行时作为一个image，无需安装。接着，你的构建可以将基础Python image与APP代码一起包含在内，确保你的APP，依赖项…都构建一起。 使用Dockerfile定义一个容器Dockerfile定义了容器内环境中发生的事情。访问的网络接口(network interface)和磁盘驱动(disk driver)等资源是在此环境中虚拟化的(virtualized)，与系统其余部分隔离。因此你需要将端口映射(map port)到外部世界，并明确指定要将哪些文件复制到此环境中。但是，在完成这些后，你完全可以将它们看做一致 —— 在Dockerfile中定义的构建的APP的行为与它运行时的行为完全相同。 Dockerfile 创建一个空目录，并创建一个名叫Dockerfile的文件，复制以下内容： 1234567891011121314151617181920# Use an official Python runtime as a parent imageFROM python:2.7-slim# Set the working directory to /appWORKDIR /app# Copy the current directory contents into the container at /appADD . /app# Install any needed packages specified in requirements.txtRUN pip install --trusted-host pypi.python.org -r requirements.txt# Make port 80 available to the world outside this containerEXPOSE 80# Define environment variableENV NAME World# Run app.py when the container launchesCMD [&quot;python&quot;, &quot;app.py&quot;] 注意代理服务器会阻断你与APP的连接！ 这个Dockerfile引用了一些我们还没有创建的文件，分别是app.py和requirements.txt。接下来创建它们。 APP自身创建另外的文件，如上面的app.py和requirements.txt，并将它们与Dockerfile放置于同一目录下。这就完成了我们的APP，这看起来非常简单。当这个Dockerfile被构建成一个image时，由于Dockerfile的ADD命令，app.py和requirements.txt仍然存在，而且由于使用了EXPOSE命令，app.py的输出仍可以通过HTTP访问。 requirements.txt: 12FlaskRedis app.py: 123456789101112131415161718192021222324from flask import Flaskfrom redis import Redis, RedisErrorimport osimport socket# Connect to Redisredis = Redis(host=&quot;redis&quot;, db=0, socket_connect_timeout=2, socket_timeout=2)app = Flask(__name__)@app.route(&quot;/&quot;)def hello(): try: visits = redis.incr(&quot;counter&quot;) except RedisError: visits = &quot;&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;&quot; html = &quot;&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;&quot; \ &quot;&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;&quot; \ &quot;&lt;b&gt;Visits:&lt;/b&gt; &#123;visits&#125;&quot; return html.format(name=os.getenv(&quot;NAME&quot;, &quot;world&quot;), hostname=socket.gethostname(), visits=visits)if __name__ == &quot;__main__&quot;: app.run(host=&apos;0.0.0.0&apos;, port=80) 在容器内访问主机的名称将检索容器ID，这进程ID类似。 仅此而已，在你的系统中，你不需要任何Python或requirements.txt文件，也不需要在你的系统上安装 构建或运行的image。看起来你并没有真正用Python和Flask建立一个环境，但是你确实已经拥有了。 构建APP我们准备去构建(build)APP。确保你仍在目录的顶层。 123456789101112131415161718192021222324252627282930313233343536373839404142#查看是否还在顶层lsDockerfile app.py requirements.txt#在此目录运行build命令，这将创建一个Docker image，用 -t 命名docker build -t friendlyhello .#查看你build的imagedocker image lsREPOSITORY TAG IMAGE ID CREATED SIZEfriendlyhello latest b24e21d7645f 13 minutes ago 150MB#运行APPdocker run -p 4000:80 friendlyhello#测试curl http://localhost:4000links http://localhost:4000#在后台运行docker run -d -p 4000:80 friendlyhello#查看容器docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES146662dca737 friendlyhello &quot;python app.py&quot; 16 seconds ago Up 16 seconds 0.0.0.0:4000-&gt;80/tcp goofy_chaplygin#停止Ctrl + Cdocker container stop docker-IDdocker container stop 146662dca737 端口重映射4000:80是为了证明Dockerfile中的EXPOSE与使用docker run -p发布的内容之间的区别。在后续步骤中，我们只需将主机的80端口映射到容器的80端口就好。 分享你的image为了演示刚才创建的image的可移植性(portability)，让我们上传build的image并在其它地方run它。毕竟，当你需要将container部署到生产环境时，你需要知道如何push注册。 注册表(registry)是一个repository的集合，而repository是image的集合——有点类似于GitHub repository，但代码是已经构建了的。注册表上的账户可以创建许多repository。docker CLI 默认使用Docker’s public registry。你也可以选择其它注册表，或创建自己的注册表。 使用Docker ID登录： 如果没有Docker账户，请先注册 。 1234567891011121314151617docker logindocker login -u zhang21#时候docker login认证过后，会有~/.docker/config.json文件，里面包含了docker认证信息#k8s可使用此信息添加secretcat ~/.docker/config.json&#123; &quot;auths&quot;: &#123; &quot;https://index.docker.io/v1/&quot;: &#123; &quot;auth&quot;: &quot;base64encoding&quot; &#125; &#125;, &quot;HttpHeaders&quot;: &#123; &quot;User-Agent&quot;: &quot;Docker-Client/18.03.1-ce (linux)&quot; &#125; 标记image： 使用username/repository:tag将本地image与registry中的repository相关联。tag是可选的，但推荐使用tag。因为它是注册管理机构用于为Docker image提供版本的机制。为该内容提供一个有意义的repository和tag，例如get-started:part2。 12345678docker tag image username/repository:tag#例子docker tag friendlyhello zhang/test:tag-test#查看tagdocker images ls 发布image： 123456#上传你标记了的image到repositorydocker push username/repository:tagdocker push zhang21/test:tag-test#完成后，此image便可以公开获取 从远处repository拉取并运行image： 无论在哪里执行docker run，它都会将你的image以及Python和所有依赖关系一起拉取下来，并运行你的代码。 123docker run -p 4000:80 username/repository:tagdocker run -p 80:80 zhang21/test:tag-test 本节基础命令123456789101112131415161718192021222324252627282930313233343536373839404142434445#从Dockerfile创建imagedocker build -t image-name .#运行imagedocker run -p 4000:80 image-name#后台运行docker run -d -p 4000:80 image-name#列出运行的容器docker container ls#列出所有容器，包括未运行docker container ls -a#优雅停止容器docker container stop 容器ID#强制停止docker container kill 容器ID#删除容器docker container rm 容器ID#删除所有容器docker container rm $(docker container ls -a -q)#列出镜像docker image ls#列出所有镜像docker image ls -a#删除镜像docker image rm 镜像ID#删除所有镜像docker image rm $(docker image ls -a -q)#登录docker login#标记docker tag 镜像 username/repository:tag#上传到注册表docker push username/repository:tag#从注册表拉取docker run username/repository:tag 服务service 先决条件 安装Docker 获取Docker Compose 阅读Orientation 阅读Container 确保已发布friendlyhello image到你的registry 确保你的image工作为一个部署的container。docker run -p 80:80 username/repo:tag 介绍在此，我们扩展(scale)APP并启用负载均衡(load balancing)。要做到这样，我们必须在分布式(distributed)应用程序的层次结构中升一级: 服务 Stack Service Container 关于服务在分布式应用程序中，应用程序的不同部分称为服务(service)。 例如，一个视频共享站点。那么它可能包含： 用于将应用程序数据 存储到数据库中的服务 用户上传后的视频转码服务 前端服务 … 服务是真正的生产环境中的容器。一个service只运行一个image，但它可修改image的运行方式 —— 哪个端口、容器应该运行多少个副本以便于服务所需的容量等.伸缩服务会更改运行该软件的容器实例数量，从而为进程中的服务分配更多的计算资源。 在Docker平台上定义、运行和伸缩服务都是很简单的 —— 只需修改docker-compose.yml文件。 你的第一个docker-compose.yml文件docker-compose.yml是一个YAML文件，它定义了Docker container在生产中的行为方式。 docker-compose.yml： 将如下信息保存为docker-compose.yml，确保你已经pushed the image到registry，并通过修改.yml文件的image detail来替换username/repo:tag。 12345678910111213141516171819version: "3"services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 resources: limits: cpus: "0.1" memory: 50M restart_policy: condition: on-failure ports: - "80:80" networks: - webnetnetworks: webnet: docker-compose.yml文件告诉Docker之下如下操作： pull the image Run 5 instances of that image as a service called web 限制每个实例最多使用10%的CPU和50MB的RAM 如果一个失败，马上重启container 映射主机的80端口到web的80端口 指示web container通过称为webnet的负载均衡网络共享80端口 使用默认设置定义webnet网络 运行你的负载均衡APP12345678910111213141516171819202122232425262728293031323334docker swarm init#运行并设置APP名字docker stack -c docker-compose.yml app-namedocker stack -c docker-compose.yml LoadBalance#在一个主机上，单个服务栈通过部署的image运行5个container instance#获取service IDdocker service lsID NAME MODE REPLICAS IMAGE PORTS3d1a48yse0t4 LoabBalance_web replicated 5/5 zhang21/test:tag-test *:80-&gt;80/tcp#查看服务中的任务docker service ps app-name_webdocker container ls -q#5个容器IDc7ce0075890e52ba026bf28c6d4381be438fbd297a42e89d357b05cc38eb#访问的时候容器ID会在此5个负载中变化 在服务中运行的单个container称为任务(task)。任务是具有数字增量的唯一ID，最大数量是在docker-compose.yml中定义的副本数量。 伸缩APP通过修改docker-compose.yml中replicas的值，并重新运行docker stack deploy -c xxx app-name来伸缩APP。 Docker执行就地更新，不需要stack down或kill any containers. 卸下APP和swarm： 12345678#appdocker stack rm app-namedocker stack rm LoadBalance#swarmdocker swarm leave --force 使用Docker扩展APP非常简单。 本节命令1234567891011121314151617181920212223#列出栈或APPdocker stack ls#运行指定配置文件docker stack deploy -c &lt;composefile&gt; &lt;appname&gt;#列出与APP相关联的服务docker service ls#列出与APP相关联的任务docker service ps &lt;service&gt;#检查任务docker inspect &lt;task or container&gt;#列出容器IDdocker container ls -q#除掉APPdocker stack rm &lt;appname&gt;#从管理中除掉一个单一节点swarmdocker swarm leave --force swarm 先决条件 前面几个小节的内容 介绍前面你将一个服务运行在生产环境，并扩展为5个副本进程。 在此，你将APP部署到到集群上，并在多台机器上运行它。通过将多台主机连接到成为swarm的Dockerized集群，使得多容器、多主机应用成为可能。 理解swarm集群swarm是一组运行Docker并加入到集群中的机器。这样以后，你可以在集群的swarm manager上执行Docker命令。swarm中的机器可以是物理的或虚拟的，当他们加入swarm后，他们便被成为node。 swarm manager可以使用多种策略来运行容器，你可在compose file中指定相应的策略。 swarm manager是swarm中唯一可以执行命令、授权其他机器作为工作者加入swarm的机器。工作者(worker)只能在那提供能力(capacity)，并没有权力告诉任何机器能够做什么。 但目前为止，你已经在本机机器上以单主机(single host)模式使用Docker。但Docker也可以切换为swarm(集群)模式，这就是使用swarm的原因。立即启用swarm模式使得当前机器成为swarm manager。从此，Docker将运行在你管理的swarm上执行命令，而不仅仅是在当前机器上执行。 建立swarm一个swarm由多个节点组成，不管它是虚拟机还是物理机。 基本概念很简单，运行docker swarm init来开启swarm模式并使得当前机器成为swarm manager 在其它机器上运行docker swarm join使他们作为worker加入swarm 栗子：使用VM快速创建两台机器的集群，并将其变为swarm。 使用docker-machine创建一对VM: 123456789101112131415161718192021#CentOS7#安装VirtualBoxwget https://download.virtualbox.org/virtualbox/5.2.8/VirtualBox-5.2-5.2.8_121009_el7-1.x86_64.rpm &amp;&amp; yum install -y Virtual.xx.rpm#安装docker-machine curl -L https://github.com/docker/machine/releases/download/v0.14.0/docker-machine-`uname -s`-`uname -m` &gt;/tmp/docker-machine &amp;&amp; install /tmp/docker-machine /usr/local/bin/docker-machine#在BIOS中开启虚拟化支持#在VMware中开启虚拟化支持(如果是VM)docker-machine create --driver virtual myvm1docker-machine create --driver virtual myvm2#列出虚拟机docker-machine ls 初始化swarm并添加node 第一台机器作为swarm manager，执行命令和join认证，后面的机器作为worker。 你可以使用docker-machine ssh发送命令到VM。在swarm mananger上执行docker swarm init初始化： 12345678docker-machine ssh &lt;swarm manager&gt; &quot;docker swarm init --advertise-assr &lt;mananger-IP&gt;&quot;#add workerdocker swarm jion --toker &lt;token&gt; &lt;wroker-ip&gt;:&lt;port&gt;#添加managerdocker swarm join-token manaer 由于我的虚拟的无法使用VT，因此我用的两台机器两个Docker来做swarm。 123456789101112131415161718#初始化这台机器默认为managerdocker swarm init#作为worker加入，ip是manager的#以下信息会在manager初始化时生成#注意防火墙，可能会阻碍加入docker swarm join --toker &lt;toker&gt; &lt;ip:port&gt;docker swarm join --token SWMTKN-1-3vrbnuneu0hyu41evxlhbn5fp04ad5jvg9v5rzvdaedg2bghkt-e24mjnni3hu7782t3gkz0ny39 172.16.129.150:2377#查看swarmdocker node ls#离开swarmdocker swarm leave 在swarm集群上部署APP主需要记住，只有swarm manager才能执行docker命令，worker仅仅是容量(capacity)。 在swarm manager上使用docker-composr.yml和docker stack deploy命令来部署APP。使用docker service ps &lt;service name&gt;来验证部署。 123456789101112131415161718192021222324#在manager部署docker stack deploy -c ./docker-compose.yml LoadBalancedocker service lsdocker stack ls#注意node名docker stack ps LoadBalanceID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS6nrn4mwc6pvt LoadBalance_web.1 zhang21/test:tag-test zhang22 Running Preparing 2 minutes agobpssrnzesl7n LoadBalance_web.2 zhang21/test:tag-test zhang22 Running Preparing 2 minutes agokmhd8p5wkc12 LoadBalance_web.3 zhang21/test:tag-test zhang21 Running Running 2 minutes agoi0pkf4foms87 LoadBalance_web.4 zhang21/test:tag-test zhang22 Running Preparing 2 minutes agorvtpjk781frn LoadBalance_web.5 zhang21/test:tag-test zhang21 Running Running 2 minutes ago#分别访问个主机的IP#创建的网络在它们之间共享并负载均衡links ip1links ip2 两个IP地址工作的原因是集群中的节点参与入口(ingress)路由网络(routing mesh)。这可以确保部署在swarm中某个端口的服务始终将该端口保留给自己，而不管实际运行容器的节点是什么。 清理并重启1docker stack rm LoadBalance stack先决条件，已完成前面的步骤。 介绍你已到达分布式应用程序层次结构的顶端——stack。堆栈是一组相互关联的服务，它们可以共享依赖关系，并可以进行协调和缩放。单个堆栈能够定义和协调整个应用程序的功能(尽管非常复杂的应用程序可能需要使用多个堆栈)。 在前面使用的docker deploy——是运行在单主机上的单个服务堆栈，这通常不会发生在生产环境中。在这里，你会使用学到的东西使多个服务相互关联，并在多台机器上运行它们。 添加一个新服务并部署docker-compose2.yml 12345678910111213141516171819202122232425262728293031version: &quot;3&quot;services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 restart_policy: condition: on-failure resources: limits: cpus: &quot;0.1&quot; memory: 50M ports: - &quot;80:80&quot; networks: - webnet #可视化 visualizer: image: dockersamples/visualizer:stable ports: - &quot;8080:8080&quot; volumes: - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; deploy: placement: constraints: [node.role == manager] networks: - webnetnetworks: webnet: 新增的东西使web对等服务，称为visualizer。注意两个事： volumes: 给予visualizer访问主机Docker的socket文件 placement： 确保服务运行在manager而不是worker上 123456789docker stack deploy -c ./docker-compose2.yml stack-testCreating network stack-test_webnetCreating service stack-test_visualizerCreating service stack-test_web#查看visualizer，要等一会才能正常访问，别着急访问 IP:8080 持久化数据让我们再次通过相同的工作流程来添加用于存储应用程序数据的Redis数据库。 docker-compose3.yml，添加一个Redis服务器： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253version: &quot;3&quot;services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 restart_policy: condition: on-failure resources: limits: cpus: &quot;0.1&quot; memory: 50M ports: - &quot;80:80&quot; networks: - webnet visualizer: image: dockersamples/visualizer:stable ports: - &quot;8080:8080&quot; volumes: - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; deploy: placement: constraints: [node.role == manager] networks: - webnet redis: image: redis ports: - &quot;6379:6379&quot; volumes: - &quot;/home/docker/data:/data&quot; deploy: placement: constraints: [node.role == manager] command: redis-server --appendonly yes networks: - webnetnetworks: webnet:#部署docker stack deploy -c docker-compose3.yml redis-test#测试访问 IP:port Redis是一个Docker library中的官方image，并被授予redis镜像名称。 redis规范中有几件事使数据在这个堆栈的部署之间持续存在： redis运行在manager，所以它总是使用相同的文件系统 redis将数据存储在上面的目录 确保redis服务始终使用相同的主机 确保存储的数据的连续性 如果没有创建，redis会将数据存储在容器文件系统的/data中，如果该容器被重新部署，则数据将被清除。 部署APP先决条件为前面的操作步骤。 介绍compose file在生产环境中的效果与在您的计算机上的效果相同。 选择版本我安装的是社区版(ce)。如果你在生产环境中使用docker-ce，则可以使用Docker Cloud帮助管理你的应用程序，如AWS、Aliyun、腾讯云。docker cloud： , 可注册后建立、上传、管理自己的repo。 设置和部署： 连接Docker Cloud并授权它自动为你配置Dockerize VM 使用Docker Cloud创建你的计算资源和swarm 部署应用程序 连接DockerCloud你可以标准模式或swarm模式运行Docker Cloud。 AWS配置指南 Aliyun配置指南 腾讯云配置指南 创建swarm你可在Docker Cloud UI创建你的node，或docker swarm init|join命令。 在云提供商上部署应用程序 我觉得阿里云和腾讯云也有对应的平台。 运行部署命令: docker stack deploy -c xxx.yml &lt;cus_appname&gt;，现在你的APP就运行在云提供商上。 运行swarm命令来验证部署 12345docker node lsdocker service lsdocker service ps &lt;service&gt; 在云提供商开放端口 service type protocol port web http tcp 80 visualizer http tcp 8080 redis tcp tcp 6379 具体操作参见各云提供商。 迭代和清理 改变*.yml文件伸缩应用程序 使用docker stack deploy部署应用程序 push和pull image 使用docker stack rm &lt;name&gt;清除stack 修改Docker默认路径docker默认的目录为/var/lib/docker，但很多时候/var目录并没有单独挂载，可能导致空间不够。前提是你已经把源配置目录对应的文件拷贝到替换的目录。 方法1： 123456789101112131415systemctl stop dockercd /etc/dockervim daemon.json&#123; &quot;graph&quot;: &quot;/opt/docker&quot;&#125;systemctl start docker#systemctl reload docker#查看变更docker info 方法2: 123456789101112systemctl stop dockercd /etc/sysconfig/vim docker-storageDOCKER_STORAGE_OPTIONS=--graph=/opt/dockersystemctl start docker#查看变更docker info 容器服务自启动在运行docker容器时可以加如下参数来保证每次docker服务重启后容器也自动重启: 1234docker run --restart=always -d -p 80:80 &lt;container-id&gt;#对于已启动的容器服务，更新它docker update --restart=always &lt;container-id&gt; 交互式容器进入Docker容器以获得交互式体验。 123docker exec -it &lt;container&gt; /bin/bashdocker exec -it &lt;container&gt; /bin/sh 使用systemd默认情况下，容器是不直接支持使用systemd的。可在运行容器时添加选项来使用systemd。 12#centos:7docker run -dit --privileged --name=centos7-systemd centos:7 init 日志 docker服务日志： journalctl -u docker.service docker容器日志： &lt;docker-graph&gt;/containers/&lt;container-id&gt;/&lt;container-id&gt;-json.log 由于容器ID会变化，请注意提取容器ID 可使用ELK在此收集容器日志 更新镜像使用docker commit从改变的容器中生成一个新镜像。 更新镜像步骤： 备份镜像: docker tag 运行镜像 修改容器 生成新镜像: docker commit 推送镜像: docker push 动态映射端口如何给运行中的容器添加映射端口。有两种方法: 将运行的容器生成一个新镜像，之后有这个镜像重新映射端口 通过iptables 第一种方法就相当于重新启动一个镜像，在启动时重新映射端口。实在是麻烦。 由于docker 命令设置端口映射其实也就是下发 iptables 规则，所以我们可以直接创建 iptables 规则进行端口流量转发。 123456789#查看本机docker iptabels rulesiptables-save#我的一个hexo镜像#-A DOCKER -d 172.17.0.2/32 ! -i docker0 -o docker0 -p tcp -m tcp --dport 4000 -j ACCEPT#再它在添加一个端口iptables -t nat -A DOCKER ! -i dokcer0 -p tcp -m tcp --dport 56789 -j DNAT --to-destination 172.17.0.2:56789 备份与恢复 备份容器 docker commit: 生成新镜像 docker save： 生成本地tar包 1234567891011121314Usage: docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]docker commit -m &quot;Just a test&quot; -p $&#123;container-id&#125; Zhang21/test:01docker image lsdocker logindocker pushUsage: docker save [OPTIONS] IMAGE [IMAGE...] [flags]docker save -o /path/$&#123;image&#125;.tar $&#123;image&#125;ls /path 恢复容器 docker run ${image} docker load: 载入本地.tar镜像 1234Usage: docker load [OPTIONS]docker load -i /path/$&#123;image&#125;.tardocker image ls 应用场景与注意事项 应用场景 本地依赖 搭建环境 微服务 自动测试 部署过程 CI/CD 多租户环境 一台机器的多个APP 弹性伸缩 资源隔离 注意事项 一个进程，一个容器不推荐在Docker容器中运行多个进程！ 不要将数据存放到容器内所以请使用挂在卷的方式映射到本地磁盘目录 使用磁盘进行数据存储 容器通信每当一个Docker容器需要与另一个容器通信时，传递信息最好使用名称或环境变量。 以non-root用户运行Docker默认情况下，Docker容器以root用户身份运行，众所周知，以root用户运行的容器完全可以控制主机系统。 注意容器的体积选择一个容器的主要原因之一是它的体积小。但是，如果你把它做得更大，它的主要优势就没了。 制定控策略开发和部署Docker容器不是你的工作的结束。您需要持续监控已部署的容器以及整个系统的运行状况。选择合适的工具并制定一个策略来有效地监控您的Docker容器，以确保最短的停机时间，从而使客户满意。 安全问题安全补丁、防火墙… Dockerfile参考: https://docs.docker.com/engine/reference/builder/ https://yeasy.gitbooks.io/docker_practice/content/image/build.html 将镜像每一层的修改、安装、配置、操作的命令写入Dockerfile，并用它来构建、定制镜像，那么镜像构建透明性问题便会得到解决。 Dockerfile是一个文本文件，包含了一条条指令(instrction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 使用Dockerfile定制镜像 FROM所谓指定镜像，就是以一个镜像为基础，在其上进行定制。基础镜像必须指定，而FROM就是指定基础镜像，因此一个Dockerfile中FROM是必备的指令，并且必须是第一条指令。 只有有可能，请使用当前官方repo作为你的基础镜像。我们推荐使用Alpine镜像，因为它严格控制，体积小(只有5MB)，同时也是完整的Linux发行版。 Docker Hub中有很多常用的官方镜像——常用软件、常用语言和常用系统镜像。 12345FROM nginx#特殊镜像，scratch，空白镜像FROM scratch RUN在多行中使用反斜杠\或复杂的RUN语句，使Dockerfile更具可读性、易理解性和可维护性。 RUN指令是用来执行命令行命令的。有两种格式： shell格式 RUN &lt;CMD&gt;，就像直接在命令行中输入命令一样 exec格式 RUN [&quot;可执行文件&quot;, &quot;参数&quot;]，这更像函数调用中的格式 12345678910FROM debian:jessieRUN apt-get updateRUN apt-get install -y gcc libc6-dev makeRUN wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot;RUN mkdir -p /usr/src/redisRUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1RUN make -C /usr/src/redisRUN make -C /usr/src/redis install Dockerfile中的每一个指令都会建立一层，RUN也不例外。每一个RUN的行为，就和手工建立镜像的过程一样 —— 新建立一层，在其上执行这些命令，执行结束后，commit这一层的修改，构成新的镜像。 上面这种写法，创建了7层镜像，这是完全没有意义的，而且很多运行时不需要的东西都被装进了镜像里，比如编译环境和更新的软件包等。结果就会产生非常臃肿、非常多层的镜像，不仅增加了构建部署的时间，也容易出错。这是很多初学Docker的人常犯的一个错误。 UnionFS是Linux、FreeBSD的文件系统服务，UnionFS是有最大层数限制的。 修改后的Dockerfile： 1234567891011121314FROM debian:jessieRUN buildDeps=&apos;gcc libc6-dev make&apos; \ &amp;&amp; apt-get update \ &amp;&amp; apt-get install -y $buildDeps \ &amp;&amp; wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot; \ &amp;&amp; mkdir -p /usr/src/redis \ &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \ &amp;&amp; make -C /usr/src/redis \ &amp;&amp; make -C /usr/src/redis install \ &amp;&amp; rm -rf /var/lib/apt/lists/* \ &amp;&amp; rm redis.tar.gz \ &amp;&amp; rm -r /usr/src/redis \ &amp;&amp; apt-get purge -y --auto-remove $buildDeps 仅仅使用一个RUN指令，并使用&amp;&amp;将各指令串联起来。将之前的7层简化为1层。在编写Dockerfile时，要经常提醒自己，这并不是在写shell脚本，而是在定义每一层该如何构建。 Dockerfile支持shell类的换行\、注释#等格式，良好的格式，如换行、缩进、注释等，会让维护、排障更为容易，这也是一个好习惯。 此外，还可看到命令最后添加了清理工作的命令，删除了为编译构建所需要的软件，清理了所有下载文件。这很重要，镜像是多层存储，每一层的东西并不会在下一层被删除，会一直跟随镜像。因此，构建镜像时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。很多人初学docker制作出了很臃肿的镜像，原因之一就是顽疾了每一层构建的最后一定要清理无关文件。 构建镜像在Dockerfile目录下执行： 1234567#docker build [OPTIONS] PATH | URL | - [flags]#Build an image from a Dockerfile#-t指定镜像名称#.指的是上下文目录docker build -t nginx:test . 构建上下文(content) 上面的.是在指定上下文路径。 当我们在进行镜像构建的时候，并非所有的定制都会通过RUN指令完成，经常会需要一些本地文件复制进镜像，比如通过COPY, ADD指令。而docker build命令并非是在本地构建镜像，而是在服务端，也就是Docker引擎dockerd中构建的。那么在这种C/S架构中，如何才能让服务端获得本地文件呢？ 这就引进了上下文的概念。当构建的时候，用户会指定构建镜像的上下文的路径，docker build命令得知这个路径后，会将路径下的所有内容打包，然后上传给Docker引擎。这样Docker引擎收到这个上下文包后，展开就会获得构建镜像所需的一切文件。 12#复制上下文目录下的package.jsonCOPY ./package.json /app/ 因此COPY这类指令中的源文件的路径都是相对路径，因为绝对路径已经超出了上下文的范围，Docker引擎无法获取这些位置的文件。如果真需要这些文件，请将它们复制到上下文目录中去。 理解构建上下文对于镜像构建很重要，避免犯一些不应该的错误。 一般来说，应将Dockerfile置于一个空目录下，或者项目根目录下。如果该目录下没有所需文件，则应该把所需文件复制一份过来。如果目录下有些东西不希望构建时传给Docker引擎，可以写一个.dockerignore文件，用于剔除不需要作为上下文传递给Docker引擎的。 实际上，Dockerfile的文件名并不要求必须为Dockerfile，也并不要求必须位于上下文目录中。可使用-f指定某个文件为Dockerfile。 其它docker build的用法 直接使用Git repo进行构建 1234#docker build URLdocker build https://github.com/twang2218/gitlab-ce-zh.git#:8.14#docker会自己去clone、切换分支、并进入指定目录开始构建 使用给定tar压缩包构建 123docker build http://server/context.tar.gz#自动下载/解压缩 压缩包，以其作为上下文，开始构建 从标准输入中读取Dockerfile进行构建 1234567docker build - &lt; Dockerfilecat Dockerfile | docker build -docker build - &lt; context.tar.gz Dockerfile指令Dockerfile提供了十多个指令供我们操作。 LABLE你可以为你的镜像添加标签，以助于通过项目来组织镜像，记录相关信息。 123456# Set multiple labels at once, using line-continuation characters to break long linesLABEL vendor=ACME\ Incorporated \ com.example.is-beta= \ com.example.is-production="" \ com.example.version="0.0.1-beta" \ com.example.release-date="2015-02-12" COPY尽管ADD和COPY在功能上相似，但一般来说，COPY是首选，因为它比ADD更透明。COPY只支持将本地文件复制到容器中，而ADD具有一些功能(如提取tar文件和远程URL支持) COPY,复制文件。从构建上下文目录中&lt;源路径&gt;的文件/目录复制到新的一层的镜像内的&lt;目标路径&gt;位置。 源路径可以是多个，或通配符(需满足Go的规则)目标路径可是容器内的绝对路径，也可是相对于工作目录(WORKDIR)的相对路径。目标路径不需要事先创建。使用COPY指令，源文件的各种元数据都会保留 —— 如读、写、执行权限、文件变更时间… 12345678910111213141516COPY &lt;sourch&gt; &lt;destination&gt;#或COPY [&quot;&lt;source1&gt;&quot;, ... &quot;&lt;destination&gt;&quot;]#栗子COPY package.json /usr/src/app/COPY hom* /mydir/COPY hom?.txt /mydir/#目录COPY dir/ /dir/#复制目录的错误用法#COPY dir/* /dir/ ADDADD是更高级的复制文件。ADD和COPY的格式和性质基本一致，但增加了一些功能。ADD支持通过URL从远程服务器读取资源，但对远程的压缩包没有解压缩功能。尽可能的使用COPY，因为COPY的语义很明确，就是复制文件而已，而ADD则包含了更复杂的功能，其行为也不一定很清晰。最适合ADD的场合，就是所提及的需要自动解压缩的场合。 因此在COPY和ADD指令中选择的时候，可以遵循这样的原则，所有的文件复制均使用COPY指令，仅在需要自动解压缩或远程资源的场合使用ADD。 12345678FROM scratchADD ADD http://foo.com/bar.go /tmp/main.goADD abc.tar.gz / &amp;&amp; \ http://example.com/big.tar.xz /usr/src/things/ &amp;&amp; \RUN tar -xJf /usr/src/things/big.tar.xz -C /usr/src/thingsRUN make -C /usr/src/things all CMDCMD，容器启动命令。用于运行镜像中包含的软件以及任何参数。 也有两个格式： shell格式： CMD &lt;command&gt; shell格式，在实际中会被包装成sh -c的参数形式进行执行： 123456789CMD echo $HOME#转变为CMD[&quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot;]#-c string If the -c option is present, then commands are read from string.#这就是为什么我们可以使用环境变量的原因，因为这些环境变量会被 shell 进行解析处理 exec格式： CMD [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot; ...]CMD几乎总是以此格式使用。 Docker不是虚拟机，容器就是进程。既然是进程，那么在启动容器的时候，需要指定所运行的程序及参数。CMD指令就是用于指定默认的容器主进程的启动命令的。`` 对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。 ENTRYPOINTENTRYPOINT，入口点。指令格式同样分为shell格式和exec两种。 ENTRYPOINT和CMD一样，都是在指定容器启动程序及参数。当指定了ENTRYPOINT后，CMD的含义就发生了改变，不再是直接的运行其命令，而是将CMD的内容作为参数传给ENTRYPOINT指令。即变为如下模式： 1&lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; 有几大好处： 让镜像变成像命令一样使用 12345678910111213#可以从腾讯上拉取，快一些#ccr.ccs.tencentyun.com/qcloud/ubuntuFROM ubuntu:16.04RUN apt-get update \ &amp;&amp; apt-get install -y curl \ &amp;&amp; rm -rf /var/lib/apt/lists/*CMD [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://ip.cn&quot; ]docker build -t myipdocker run myip#当前 IP：182.150.x.xx 来自：四川省成都市 电信 不过命令总有参数，例如我想查看HTTP header，使用-i参数 1234567docker run myip -i#这样会报错，-i替换了CMD命令，而不是-s参数，然而-i并不是命令#重新完整输入命令docker run myip curl -s http://ip.cn -i#这样又太麻烦 这时便可以使用ENTRYPOINT解决这个问题。 1234567891011121314FROM ubuntu:16.04RUN apt-get update \ &amp;&amp; apt-get install -y curl \ &amp;&amp; rm -rf /var/lib/apt/lists/*ENTRYPOINT [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://ip.cn&quot; ]docker build it myipdocker run myip#当前 IP：182.150.x.xx 来自：四川省成都市 电信docker run myip -i#成功 当存在ENTRYPOINT后，CMD的内容将作为参数传递给ENTRYPOINT，而-i就是新的CMD，因此会作为参数传递给curl，从而达到预期效果。 应用运行前的准备工作 有时，在启动前需要做一些准备工作。 如MySQL，需要一些配置文件、初始化工作，这些工作需要在MySQL server运行前解决 避免使用root用户去启动服务，从而提高安全性 这些准备工作和CMD无关 ENVENV，设置环境变量。为了使新软件更容易运行，使用此命令为你的容器内安装的软件更新环境变量。 两种格式： ENV &lt;key&gt; &lt;value&gt; ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 123ENV PATH $PATH:/root/bin \ EMAIL abc@zhang21.cn \ NAME=&quot;Zhang21&quot; 下列指令可以支持环境变量展开： ADD, COPY, ENV, EXPOSE, LABEL, USER, WORKDIR, VOLUME, STOPGIGNAL, ONBUILD。 通过环境变量，我们可以让一份Dockerfile制作更多的镜像，只需使用不同的环境变量即可。 ARGARG，构建参数 格式： ARG &lt;参数名&gt;[=&lt;默认值&gt;] 构建参数和ENV的效果一样，都是设置环境变量。所不同的是，ARG所设置的构建环境的环境变量，在将来容器运行时是不会存在这些环境变量的。 VOLUMEVOLUME，定义匿名卷。用于显示有docker容器创建的任何数据库存储区域，配置存储或文件/文件夹。强烈建议将VOLUME用于镜像的任何可变部分和用户可用部分。 格式： VOLUME [&quot;&lt;路径1&gt;&quot;, &quot;&lt;路径2&gt;&quot;...] VOLUME &lt;路径&gt; 容器运行时应该尽量保持容器存储层不发生写操作，对于数据库类需要保存动态数据的应用，其数据库文件应该保存于卷(volume)中。为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在Dockerfile中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会像容器存储层写入大量数据。 123456#在运行时自动挂载为匿名卷VOLUME /data#覆盖挂载docker run -d -v mydata:/data xxx EXPOSEEXPOSE，声明容器监听连接的端口。 格式： EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...] EXPOSE指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在Dockerfile中写入这个声明有两个好处： 一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便映射 另一个用处则是在运行时使用随机端口映射(未定义时) 要将EXPOSE和在运行时使用-p &lt;宿主端口&gt;:&lt;容器端口&gt;区分开。EXPOSE仅仅声明容器打算使用哪些端口，并未包含端口映射。 WORKDIRWORKDIR，指定工作目录。为了清晰可靠，请使用绝对路径。 使用WORKDIR指令可以来指定工作目录，以后各层的当前目录就被改为指定的目录，如目录不存在，WORKDIR会帮你建立目录。如果需要改变Dockerfile各层的工作目录的位置，那么应该使用WORKDIR指令。 格式： WORKDIR &lt;工作目录&gt; USERUSER，指定当前用户。如果服务可以在非特权模式下运行，请使用USER将其改为non-root用户。首先在Dockerfile中创建相应的用户和组: 12RUN groupadd -r group &amp;&amp; \ useradd -r -g group group USER和WORKDIR相似，都是改变环境状态并影响以后的层。WORKDIR是改变工作目录，USER则是改变之后的层执行RUN, CMD, ENTRYPOINT这类命令的身份。这个用户必须存在。 格式： USER &lt;用户名&gt; 12USER redisRUN [&quot;redis-server&quot;] HEALTHCHECKHEALTHCHECK，健康检查HEALTHCHECK指令告诉docker应该如何进行判断容器的状态是否正常。 格式： HEALTHCHECK [选项] CMD &lt;命令&gt;， 设置检查容器健康状况的命令 HEALTHCHECK NONE， 如果基础镜像有健康检查，使用这行可以屏蔽其健康检查指令 当在一个镜像指定了HEALTHCHECK指令后，用其启动容器，初始状态会为starting，在HEALTHCHECK指令检查成功后变为healthy，如果连续一定次数失败，则会变为unhealthy。和CMD, ENTRYPOINT一样，HEALTHCHECK 只可以出现一次，如果写了多个，只有最后一个生效。 ONBUILDONBUILD，为他人做嫁衣。 ONBUILD是一个特殊的指令，它后面跟的是其它指令。而这些指令，在当前镜像构建时不会被执行。只有当以当前镜像为基础镜像(父镜像)，去构建下一级镜像(子镜像)的时候才会被执行。ONBUILD命令在子镜像的Dockerfile中任何命令之前执行。Dockerfile中的其它指令都是为了定制当前镜像而准备的，唯有ONBUILD是为了帮助别人定制自己而准备的。 格式： ONBUILD &lt;其它指令&gt; Dockerfile多阶段构建全部放入一个Dockerfile 将所有的构建过程包含在一个Dockerfile中，包括项目及其依赖库的编译、测试、打包等流程。这可能会带来一些问题： Dockerfile特别长，可维护性降低 镜像层次多，镜像体积较大，部署时间变长 源代码存在泄漏的风险 分散到多个Dockerfile 事先在一个Dockerfile将项目及其依赖库编译测试打包好后，再将其拷贝到运行环境中。这种方式需要编写两个Dockerfile和一些编译脚本才能将两个阶段自动整合起来。这种方式虽然可以很好避免全部写入一个Dockerfile的风险，但明显部署过程较复杂。 多阶段构建 使用多阶段构建我们就可以很容易解决前面提到的问题，并且只需要编写一个Dockerfile。 Dockerfile最佳实践 一般性建议 容器应该是短暂的 使用.dockerignore文件 使用多阶段构建减少镜像大小 避免安装不必要的包 一个镜像只运行一个进程 镜像层数尽可能少 将多行参数排序 构建缓存 Dockerfile指令 FROM LABEL RUN CMD EXPOSE ENV ADD COPY ENTRYPOINT VOLUME USER WORKDIR 多平台构建参考: buildx: https://docs.docker.com/buildx/working-with-buildx/ qemu-uer-static: https://github.com/multiarch/qemu-user-static 版本: 大于Docker 19.03 linux kernel: 5.x 使用Docker新功能buildx构建多平台的镜像。升级内核版本，不然使用qemu-user-static使会失败。 使用如下: 1234567891011121314151617# 开启此功能export DOCKER_CLI_EXPERIMENTAL=enabled# 需要使用qemu-user# 注意内核版本，升级到5.x的内核大版本docker run --rm --privileged multiarch/qemu-user-static --reset -p yesdocker buildx create --name builder --driver docker-container --usedocker buildx inspect --bootstrap# arm64，--load存放本地docker buildx build -t xxx:arm64-tag --load --platform linux/arm64 .# amd64，--push推送docker buildx build -t xxx:amd64-tag --push --platform linux/amd64 .# 多平台docker buildx build --platform linux/arm64,linux/amd64 -t user/test:latest --push . 多平台构建的镜像支持运行在各自的架构上，使用同一个tag。多平台构建只能使用--push, --load只能对应单个平台。 Compose file参考: https://docs.docker.com/compose/compose-file/ 使用Docker进行开发Develop with Docker 在Docker上开发应用程序Develop new apps on Docker Learn to build an image from a Dockerfile Use multistage builds to keep your images lean Manage application data using volumes and bind mounts Scale your app as a swarm service Define your app stack using a compose file General application development best practices 了解有关Docker上特定语言的开发： Java node.js Ruby on Rails .Net ASP.Net Docker开发最佳实践Docker development best practices 如下开发模式已被证明有助于人么使用Docker构建应用程序。 如何保持较小的镜像How to keep your images small 在启动容器或服务时，小图像可以更快速通过网络pull镜像并加载到内存中。有几条经验法则可保持较小的镜像： 从适当的基础镜像开始例如，如果需要JDK，请考虑官方镜像，而不是从一个通用的Ubuntu/Centos镜像并将Openjdk作为Dockerfile的一部分安装开始。 使用多阶段构建例如，你可以使用maven镜像构建java程序，然后重置到tomcat镜像，并将java构件复制到正确位置以部署应用程序，所有这些都位于相同的Dockerfile。这意味着你的最终镜像不包含构建时所引入的所有库和依赖项，仅包含运行它们所需的构件和环境。 如果你有多个共同的镜像，请考虑使用共享组件创建你的基本镜像，并在其上创建独特的镜像Docker只要家在一次通用层，然后便会缓存。 保持生产环境镜像精简但允许调试(degub)，请考虑使用生产环境镜像作为调试镜像的基本镜像 在构建镜像时，应该始终使用有用的标签对其进行标记，如(test, prod)。不要依赖自动创建的latest标签 何处以及如何持久化应用程序数据Where and how to persist application data 避免使用存储驱动(storge drivers)将应用程序的数据存储在容器的可写层(writeable layer)中与使用卷(volume)或绑定挂载(bound mounts)相比，这增加了容器的大小，并且从I/O角度来看效率较低 使用卷存储数据 适合使用绑定挂载的一种情况是在开发过程中，对于生产环境，请改用卷 对于生产环境，使用secerts来存储服务使用的敏感的应用程序数据，使用config来存储不敏感的数据(如配置文件) 尽可能使用swarm服务Use swarm services when possible 在可能的情况下，使用swarm服务进行伸缩的能力来设计你的应用程序 即使你只需运行单个实例，swarm服务也比standalone容器提供更多的优势 网络和卷可使用swarm服务连接和断开，并且docker可以以不中断的方式重新部署各个服务容器。standalone容器需要手动停止/移除/重新创建 一些功能仅适用于服务而不适用于standalone容器 让docker stack deploy处理任意镜像，而不是使用docker pull。通过这种方式，你的部署不会尝试从down的节点进行pull。此外，当新节点添加到集群时，镜像会自动pull 使用CI/CD进行测试和部署Use CI/CD for testing and deployment CI(Continuous integration) CD(continuous deployment) 当更新源码库或创建拉取请求时，请使用CI/CD pipeline 自动构建并标记Docker镜像，并对其进行测试。也可将测试过的应用程序直接部署到生产环境中 Develop images编写Dockerfile的最佳实践Best practices for writing Dockerfiles Docker通过读取Dockerfile(一个包含命令的文本文件)中的命令来自动构建镜像。Dockerfile reference: https://docs.docker.com/engine/reference/builder/ Dockerfile由read-only layer组成，每层代表一个Dockerfile指令。如: 1234FROM ubuntu:15.04COPY . /appRUN make /appCMD python /app/app.py 每个命令创建一个层: FROM从ubuntu:15.04 Docker image创建一个层 COPY从Docker client的当前目录添加文件 RUN使用make构建你的应用程序 CMD指定在容器内运行的命令 当你运行镜像并生成容器时，会在基础层的顶部添加一个可写层(writable layer)，也称容器层(container layer)。对正在运行的容器所做的所有更改(增删改文件)都会写入此可写容器层。 一般准则和建议General guidelines and recommendations 创建临时(ephemeral)容器 Create ephemeral containers由Dockerfile定义的镜像应该生成尽可能临时的容器。临时的意思为容器可以被停止(stop)和销毁(destroy)，然后重建(rebuild)并使用绝对最小化的设置和配置来替代。 理解构建上下文 Understand build context当你发出docker build命令时，当前的工作目录被称为构建上下文(build context)。默认情况下，假设Dockerfile位于此，但你也可以使用文件标志(-f)指定位置。无论Dockerfile位于何处，当前目录内的所有内容(除了.dockerignore中忽略的内容)都将作为构建上下文发送给Docker守护进程。 从stdin读取Dockerfile Pipe Dockerfile through stdin 12345678910111213#local build-contextdocker build -t . -f-&lt;&lt;EOFFROM busyboxRUN echo &quot;hello world&quot;COPY . /my-copied-filesEOF#remotedocker build -t foo https://github.com/thajeztah/pgadmin4-docker.git -f-&lt;&lt;EOFFROM busyboxCOPY LICENSE config_local.py /usr/local/lib/python2.7/site-packages/pgadmin4/EOF 使用.dockerignore排除文件 Exclude with .dockerignore要排除与构建无关的文件，请使用.dockerignore文件，这与.gitignore类似。 12345vim ./dockerignorefile1dir2... 使用多阶段构建 Use multi-stage builds多阶段构建允许你大幅缩减镜像大小，而不需要减少中间层和文件数。由于镜像是在构建过程的最后阶段构建的，因此可以通过利用构建缓存(build cache)来最小化镜像层 例如，如果你的版本博涵包含多个层，你可以从 不经常改动的版本到频繁改动的版本进行排序: 安装构建应用程序需要的工具 安装或更新依赖库 生成应用程序 A Dockerfile for Go application: 123456789101112131415161718192021222324FROM golang:1.9.2-alpine3.6 AS build# Install tools required for project# Run `docker build --no-cache .` to update dependenciesRUN apk add --no-cache gitRUN go get github.com/golang/dep/cmd/dep# List project dependencies with Gopkg.toml and Gopkg.lock# These layers are only re-built when Gopkg files are updatedCOPY Gopkg.lock Gopkg.toml /go/src/project/WORKDIR /go/src/project/# Install library dependenciesRUN dep ensure -vendor-only# Copy the entire project and build it# This layer is rebuilt when a file changes in the project directoryCOPY . /go/src/project/RUN go build -o /bin/project# This results in a single layer imageFROM scratchCOPY --from=build /bin/project /bin/projectENTRYPOINT [&quot;/bin/project&quot;]CMD [&quot;--help&quot;] 不要安装不必要的包 Don’t install unnecessary packages为了减少复杂性、依赖性，文件大小和构建时间，避免安装额外的或不不必要的软件包。 分离应用程序 Decouple applications每个容器应该只有一个问题。将应用程序分离到多个容器中可以更轻松地水平伸缩和重新使用容器。例如，Web应用程序堆栈可能有三个独立的容器组成，每个容器都有其独特的镜像，以分离的方式管理Web应用程序、数据库和内存缓存。 将每个容器限制为一个进程是一个很好的经验法则，但不是硬性规定。(想想高可用和负载均衡)。 尽你最大的努力使容器干净和模块化。如果容器相互依赖，则可以使用Docker container network来确保容器间可进行通信。 最小化层数 Minimize the number of layers在老版本的docker中，重要的是减少镜像的层数，以确保它们的性能。 对多行参数排序 Sort multi-line arguments只要有可能，通过按字母数字排序多行参数来简化修改。这有助于避免软件包重复，并使列表更容易更新。 123456RUN apt-get update &amp;&amp; apt-get install -y \ bzr \ cvs \ git \ mercurial \ subversion Leverage build cache 在构建镜像时，Docker安装Dockerfile中的指令逐步执行，并按指定的顺序执行每个镜像。在检查每条指令时，docker会在其缓存中查找可重用的现有镜像，而不是创建新的(重复)镜像。 如果你不想使用缓存，可在docker build命令中使用--no-cache=true选项。如果让Docker使用了缓存，那么了解何时可以 找到/找不到 匹配的图像就很重要了。 Docker遵循的基本规则如下: 从已经在缓存中的父镜像开始，将下一条指令与该基本镜像派生的所有子镜像进行比较，以查看是否使用完全相同的指令构建了其中的一条。否则，缓存失效。 大多数情况下，只需将Dockerfile中的指令与其中一个子镜像进行比较久够了。但是，某些说明需要更多的检查和解释。 对于ADD和COPY指令，将检查镜像文件中的内容，并为每个文件计算校验和。在缓存查找过程中，将检验和与现有镜像中的校验和进行比较，如果文件中由任何内容已更改，如内容和元数据，则缓存将失效。 除了ADD和COPY指令，缓存检查将不会查看容器中的文件已确定缓存。 一旦缓存失效，所有后续的Dockerfile命令将生产新的镜像，并且不会使用缓存。 Dockerfile instruction 请参考: Dockerfile 创建一个基镜像Create a base image 大多数Dockerfile从父镜像开始，如果需要完全控制镜像的内容，则可能需要创建基镜像(base image)。区别: 父镜像是镜像的所基于的镜像 基镜像的Dockerfile中没有FROM行 使用多阶段构建Use multi-stage builds 多阶段构建需要Docker v17.05及以上版本。多阶段构建对于优化Dockerfile来说非常有用，同时让它易读和维护。 构建之前构建镜像最具挑战的事情是保持镜像的大小。Dockerfile中的每条指令都会为镜像添加一层，在移动到下一层前清理不需要的任何构件。为了编写一个高效的Dockerfile，需要尽可能减小图层，并确保每个层都具有上一层需要的构件，而不是其它东西。 使用多阶段构建使用多阶段构建，你可以在Dockerfile中使用多个FROM语句。每条FROM命令可以使用不同的基镜像，并且每个指令都可是构建的新阶段。 1234567891011FROM golang:1.7.3WORKDIR /go/src/github.com/alexellis/href-counter/RUN go get -d -v golang.org/x/net/htmlCOPY app.go .RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .FROM alpine:latestRUN apk --no-cache add ca-certificatesWORKDIR /root/COPY --from=0 /go/src/github.com/alexellis/href-counter/app .CMD [&quot;./app&quot;] COPY --from=0将前面构建的工作复制到这个新阶段。Go SDK和任何中间工作件都被留下，并未保存在最终镜像中 命名你的构建阶段默认情况下，构建阶段没有命名。你可以通过它们的整数来引用它们，第一个指令FROM从0开始。但你可以命名它。 1234567891011FROM golang:1.7.3 as builderWORKDIR /go/src/github.com/alexellis/href-counter/RUN go get -d -v golang.org/x/net/htmlCOPY app.go .RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .FROM alpine:latestRUN apk --no-cache add ca-certificatesWORKDIR /root/COPY --from=builder /go/src/github.com/alexellis/href-counter/app .CMD [&quot;./app&quot;] 停止一个特定的构建阶段构建镜像时，不一定需要构建包含每个阶段的整个Dockerfile。如下的栗子停在名为builder的阶段: 1docker build --target builder -t alexellis2/href-counter:latest . 使用外部镜像用作一个阶段多阶段构架可使用COPY --from指令从单独的镜像中进行复制，可以使用本机镜像、远程Registry的镜像和标记的ID。 1COPY --from=nginx:latest /etc/nginx/nginx.conf /nginx.conf 使用Docker Engine SDKs和API进行开发Develop with Docker Engine SDKs and API 综述Docker提供了一个用于与Docker daemon(称为Docker Engine API)交互的API，以及用于Go和Python的SDK。 SDK允许你款速轻松地构建和扩展Docker APP。如果Go或Python不适合你，你可以直接使用Docker Engine API——它是由HTTP客户端(curl, wget)访问的RESTful API，或者是大多数现代编程语言的一部分HTTP库。 安装SDKsGo SDK Go SDK参考：https://godoc.org/github.com/docker/docker/client 1go get github.com/docker/docker/client Python SDK Python SDK参考: https://docker-py.readthedocs.io/en/stable/ 1pip install docker 快速开始SDK和APIPython: 运行一个容器 123import dockerclient = docker.from_env()print (client.containers.run(&quot;alpine&quot;, [&quot;echo&quot;, &quot;hello&quot;, &quot;world&quot;])) HTTP: 123456789101112$ curl --unix-socket /var/run/docker.sock -H &quot;Content-Type: application/json&quot; \ -d &apos;&#123;&quot;Image&quot;: &quot;alpine&quot;, &quot;Cmd&quot;: [&quot;echo&quot;, &quot;hello world&quot;]&#125;&apos; \ -X POST http:/v1.24/containers/create&#123;&quot;Id&quot;:&quot;1c6594faf5&quot;,&quot;Warnings&quot;:null&#125;$ curl --unix-socket /var/run/docker.sock -X POST http:/v1.24/containers/1c6594faf5/start$ curl --unix-socket /var/run/docker.sock -X POST http:/v1.24/containers/1c6594faf5/wait&#123;&quot;StatusCode&quot;:0&#125;$ curl --unix-socket /var/run/docker.sock &quot;http:/v1.24/containers/1c6594faf5/logs?stdout=1&quot;hello world SDK和API栗子链接: https://docs.docker.com/develop/sdk/examples/ 网络配置Configure networking 综述Docker容器和服务如此强大的原因之一是——你可以将它们连接在一起，或将它们连接到non-docker工作负载。Docker容器和服务甚至不需要知道它们是否部署在Docker上，或它们的对等端是否也是Docker工作负载。都可以使用Docker方式管理它们。 网络驱动Network drivers 使用驱动程序，Docker的网络子系统是可插拔的(pluggable)。 集中驱动程序: brige默认网络驱动。桥接网络通常用于你的应用程序运行在需要通信的独立容器中。 host对于独立容器，删除容器和Docker主机之间的网络隔离，并直接使用主机的网络。 overlayoverlay网络将多个docker daemon连接在一起，并使集群服务能够无相互通信。 macvlanmacvlan网络允许你为容器分配MAC地址，使其成为你网络上的物理设备。docker daemon通过其MAC地址将流量路由到容器。 none对于此容器，禁用所有网络。 network plugins你可在Docker上安装和使用第三方网络插件，从Docker Store获取: https://store.docker.com 网络驱动总结 User-defined bridge networks当你需要多个容器在同一个Docker主机上进行通信时 Host networks当网络堆栈不应与Docker主机隔离时，但希望容器的其它方面被隔离 Overlay networks当你需要运行在不同Docker主机上的容器进行通信时，或多个应用程序使用集群服务进行工作时 Macvlan networks当你从虚拟机迁移或需要你的容器看起来像物理主机时，每个都具有唯一的MAC地址 Third-party network plugins允许你将Docker与专用网络堆栈集成 bridge就网络而言，桥接网络是一种链路层设备，用于转发网段之间的流量。桥接可以是硬件设备，或在主机内核中运行的软件设备。就Docker而言，桥接网络允许连接到统一桥接网络的容器进行通信，同时提供与未连接到桥接网络的容器的隔离。Docker桥接驱动程序自动在主机上安装桥接规则，以便于不同桥接网络上的容器不能直接相互通信。 桥接网络适用于在同一个Docker daemon上运行的容器之间的通信。 当你启动Docker时，除非另有定义，否则将自动创建默认桥接网络，并且新启动的容器将连接到它。你也可以创建用户自定义的桥接网络。 bridge与user-defined bridgesDifferences between user-defined bridges and the default bridge 两者的差别： 用户自定义的桥接在集装箱化的应用程序之间提供了更好的隔离和互操作性 用户自定义的桥接提供了容器之间的自动DNS解析 容器可以在运行中与用户定义的网络进行连接(attach)和分离(detach) 每个用户定义的网络会创建一个可配置的桥接网络 在默认桥接网络上链接的容器共享环境变量 管理user-defined bridgeManage a user-defined bridge 1234567891011docker network create --help#创建一个用户自定义桥接网络#你还可以指定子网，范围，网关...docker network creat $&#123;name&#125;docker network creat my-net#删除docker network rm $&#123;name&#125; 连接到自定义桥接网络Connect a container to a user-defined bridge 当你创建一个新的容器时，你可以指定一个或多个--network标志。 12345678910111213#创建时docker create --name my-nginx \ --network my-net \ --publish 8080:80 \ nginx:latest#运行中的容器docker network connect my-net my-nginx#断开连接docker network disconnect my-net my-nginx 使用IPv6需要修改docker daemon的配置项以支持使用IPv6，在创建自定义网络是指定--ipv6标志。你不能有选择地禁用默认桥接网络上的IPv6支持。 启用容器转发Enable forwarding from Docker containers to the outside world 默认情况下，使用默认桥接网络的连接的容器的流量不会转发到外部世界。启用操作如下： 1234567#配置Linux内核sysctl net.ipv4.conf.all.forwarding=1#修改iptables FORWARD默认策略iptables -P FORWARD ACCEPT#重启后无效，请写入配置文件 默认桥接网络Use the default bridge network 默认桥接网络被视为Docker的遗留细节，不建议用于生产环境。 连接容器到默认桥接网络如果未指定网络，则默认使用默认桥接网络。 配置默认桥接网络指定并配置daemon.json文件 123456789&#123; &quot;bip&quot;: &quot;192.168.1.5/24&quot;, &quot;fixed-cidr&quot;: &quot;192.168.1.5/25&quot;, &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;, &quot;mtu&quot;: 1500, &quot;default-gateway&quot;: &quot;10.20.1.1&quot;, &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;, &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]&#125; 使用IPv6修改配置文件以支持IPv6，则默认桥接网络自动支持IPv6。 overlayoverlay网络驱动在多个docker daemon主机之间创建分布式网络。该网络位于特定主机网络之上，允许容器连接到此并安全地进行通信。 当初始化集群或将docker主机加入现有集群时，将在docker主机上创建两个新网络： 称为ingress的overlay网络处理与集群服务相关的控制和数据流量。当你创建集群服务并且不将其连接到用户自定义的网络时，它默认连接到ingress网络。 称为docker_gwbridge的桥接网络将单独的docker daemon连接到集群的其它docker daemon。 与创建自定义桥接网络类似，你也可以使用docker network create来创建自动以的overlay网络。服务或容器一次可连接到多个网络，但只能通过连接的网络进行通信。 尽管可以将集群服务和独立容器连接到overlay网络，但默认行为和配置是不同的。 所有overlay网络的操作Operations for all overlay networks 创建overlay网络Create an overlay network 先决条件 使用overlay网络的docker daemon的防火墙规则 2377(tcp): 集群通信管理 7946(tcp/udp)： 节点通信 4789(udp)： overlay网络流量 创建overlay网络前，需要初始化docker daemon集群 12345678docker network create -d overlay my-overlay#创建可供集群服务或独立容器与其它docker daemon上的独立容器进行通信docker network create -d overlay --attachable my-attachable-overlay#你可以指定IP地址范围，子网，网关... 加密overlay网络上的流量Encrypt traffic on an overlay network Overlay network encryption is not supported on Windows！ 所有集群服务管理流量默认都是加密的，在GCM模式下使用AES算法。要加密应用程序数据，在创建overlay网络时添加--opt encrypted。这种加密带来了不可忽视的性能问题，所以应该在生产环境使用前对其进行测试。当启用overlay加密时，docker会在节点间创建IPsec tunnel，在这些节点上调度连接到overlay网络的服务的任务。 12#SWARM MODE OVERLAY NETWORKS AND STANDALONE CONTAINERS docker network create --opt encrypted --driver overlay --attachable my-attachable-multi-host-network 自定义默认ingress网络如果自动选择的子网与已存在的网络冲突，或需要自定义其它低级网络设置(如MTU)，这次功能非常有用。 1234567891011121314#显示详细信息docker network inspect ingress#移除现有网络docker network rm ingress#创建新网络 --ingressdocker network create \ --driver overlay \ --ingress \ --subnet=10.11.0.0/16 \ --gateway=10.11.0.2 \ --opt com.docker.network.driver.mtu=1200 \ my-ingress 自定义docker_gwbridgedocker_gwbridge是一个虚拟桥接网络，它将overlay网路连接到单独的docker daemon的物理网络。当初始化集群或将主机加入集群时，docker会自动创建它，但它不是docker设备。啊存在于docker主机的内核之中。如果你需要自定义其设置，则必须在主机加入集群之前或将主机临时从集群中删除之后才执行此操作。 12345678910111213141516171. 停止docker2. 删除已存在的docker_gwbridgeip link set docker_gwbridge doenip link del dev docker_gwbridge3. 启动docker，但不加入或初始化集群4. 创建docker_gwbridgedocker network create \--subnet 10.11.0.0/16 \--opt com.docker.network.bridge.name=docker_gwbridge \--opt com.docker.network.bridge.enable_icc=false \--opt com.docker.network.bridge.enable_ip_masquerade=true \docker_gwbridge5. 集群初始化或加入集群 swarm服务的操作Operations for swarm services 在overlay网络上发布端口Publish ports on an overlay network 连接到同一overlay网络的集群服务可有效地将所有端口暴露给对方。要是端口可在服务外可访问，必须使用-p或--publish标志暴露此端口。 两种方法： 传统的冒号:分隔语法 较新的逗号,分隔语法 Flag value Description -p 8080:80 or -p published=8080,target=80 Map TCP port 80 on the service to port 8080 on the routing mesh -p 8080:80/udp or -p published=8080,target=80,protocol=udp Map UDP port 80 on the service to port 8080 on the routing mesh -p 8080:80/tcp -p 8080:80/udp or -p published=8080,target=80,protocol=tcp -p published=8080,target=80,protocol=udp Map TCP port 80 on the service to TCP port 8080 on the routing mesh, and map UDP port 80 on the service to UDP port 8080 on the routine mesh 绕过swarm的路由网格Bypass the routing mesh for a swarm service 默认情况下，发布端口的集群服务使用路由网格来发布。当你连接到任何swarm节点上已发布的端口时，都会透明地将你重定向到正在运行服务的工作。实际上，docker充当集群服务的负载均衡器(Load-Balancer)。使用路由网格的服务以虚拟IP(vip)模式运行。即使在每个节点上运行服务也使用路由网格。使用路由网格时，不能保证那个docker node处理客户端请求。 要绕过路由网格，可使用DNS Round Robin(DNSRR)模式启动——--endpoint-mode dnsrr。你必须在服务前运行负载均衡器。docker主机上DNS查询服务名称会返回运行该服务的节点的IP地址列表。配置你的负载均衡器使用此列表并平衡各节点间的流量。 分离控制流量和数据流量默认情况下，尽管集群控制流量是加密的，但集群管理和应用程序之间的控制流量运行在同一个网络上。你可以配置docker来使用单独的网络接口来处理来种不同类型的流量。 overlay网络上独立容器的操作Operations for standalone containers on overlay networks 将独立容器连接到overlay网络Attach a standalone container to an overlay network 独立容器连接到ingress网络需添加--attachable标志。这使得运行在不同docker daemon上的独立容器能够进行通信，而无需在各个docker daemon主机上设置路由。 发布端口Publish ports Flag value Desciption -p 8080:80 Map TCP port 80 in the container to port 8080 on the overlay network -p 8080:80/udp Map UDP port 80 in the container to port 8080 on the overlay network -p 8080:80/sctp Map SCTP port 80 in the container to port 8080 on the overlay network -p 8080:80/tcp -p 8080:80/udp Map TCP port 80 in the container to TCP port 8080 on the overlay network, and map UDP port 80 in the container to UDP port 8080 on the overlay network 容器发现Container discovery 对于大多数情况，应该连接到服务名称——它是负载均衡的，并支持服务的所有容器处理。要获取支持该服务的所有任务的列表，请执行DNS查找服务——tasks.&lt;service-name&gt;。 host如果你对容器使用host网络驱动，则该容器的网络堆栈将不与docker主机隔离。例如，如果运行一个绑定在80端口并使用host网络的容器，则该容器的应用程序将在主机IP地址的80端口上可用。 host网络驱动只能运行在Linux主机上。 Macvlan一些应用程序，尤其是需要监视网络流量的应用程序，希望连接到物理网络上。在这种情况下，你可以使用macvlan驱动为容器的虚拟网络接口分配MAC地址，使其看起来像是直接连接到物理网络的物理网络接口。在这种情况下，你需要指定Docker主机上的物理接口用于macvlan，以及macvlan的子网和网关。 创建一个macvaln网络macvlan网络可处于 bridge mode 或 802.1q trunk mode: 在桥接模式下，macvlan流量通过主机上的物理设备 在802.1q主干桥接模式下，流量通过Docker在运行中创建的802.1q子接口。这使你可以更细粒度地控制路由和过滤。 bridge mode 创建bridge macvlan: 123456789101112docker networkcreate --driver macvlan \ --subnet=172.16.86.0/24 \ --gateway=172.16.86.1 \ -o parent=eth0 pub_net#--aux-addresses排除IP地址docker networkcreate --driver macvlan \ --subnet=172.16.86.0/24 \ --gateway=172.16.86.1 \ --aux-address=&quot;my-router=192.168.32.129&quot; \ -o parent=eth0 pub_net 802.1q truk bridge mode 如果你指定了包含点.的接口名——如eth0.50，则Docker将其解释为eth0的子接口，并自动创建子接口。 1234docker network create --driver macvlan \ --subnet=192.168.50.0/24 \ --gateway=192.168.50.1 \ -o parent=eth0.50 macvlan50 使用ipvlan替换macvlan 123456docker network create -d ipvlan \ --subnet=192.168.210.0/24 \ --subnet=192.168.212.0/24 \ --gateway=192.168.210.254 \ --gateway=192.168.212.254 \ -o ipvlan_mode=l2 ipvlan210 IPv6 123456docker network create -d macvlan \ --subnet=192.168.216.0/24 --subnet=192.168.218.0/24 \ --gateway=192.168.216.1 --gateway=192.168.218.1 \ --subnet=2001:db8:abc8::/64 --gateway=2001:db8:abc8::10 \ -o parent=eth0.218 \ -o macvlan_mode=bridge macvlan216 禁用容器网络在启动容器时加上`—network none来禁用容器的网络堆栈，这样在容器内便仅仅创建loopback设备。 12345$ docker run --rm -dit \ --network none \ --name no-net-alpine \ alpine:latest \ ash 网络教程Networking tutorials bridge network default bridge network user-defined bridge network default bridge network 基本docker网络 12345docker network lsNETWORK ID NAME DRIVER SCOPE8d3b84bfe5a0 bridge bridge local3579d63da633 host host localf766b990db47 none null local 以上列出了默认的桥接网络，主机网络(启动直接连接到docker daemon的主机的网络堆栈的容器)，none(启动一个没有网络设备的容器)。 启动一个容器 1docker run -dit --name alpine1 alpine ash 由于启动时没有指定网络，所以默认为桥接网络。 Inspect the bridge network，以查看哪个容器连接到它 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748docker network inspect bridge[ &#123; &quot;Name&quot;: &quot;bridge&quot;, &quot;Id&quot;: &quot;8d3b84bfe5a034c65d043af80976a1e6127011fc1ab312446252f562e221d351&quot;, &quot;Created&quot;: &quot;2018-05-24T18:38:35.538308064+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.17.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;893903129d869f384bd78d63a382f1c9527d6979be0a6cf3c13ea4f45a1554d6&quot;: &#123; &quot;Name&quot;: &quot;hardcore_rosalind&quot;, &quot;EndpointID&quot;: &quot;515d1435470c9f72d3b07680515d9c503457b8eb5bcaaaa915bb53901eac9424&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.17.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;, &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;, &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 连接到容器 123456789101112131415161718docker attach alpine1/ # ip addr show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever506: eth0@if507: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever/ # ping -c 2 www.baidu.comPING www.baidu.com (119.75.216.20): 56 data bytes64 bytes from 119.75.216.20: seq=0 ttl=55 time=46.521 ms64 bytes from 119.75.216.20: seq=1 ttl=55 time=45.189 ms ping其它容器 1234/ # ping -c 2 172.17.0.2PING 172.17.0.2 (172.17.0.2): 56 data bytes64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.125 ms64 bytes from 172.17.0.2: seq=1 ttl=64 time=0.075 ms user-defined bridge networks 创建名为apline-net用户自定义网络当然，你可以手动指定子网，网关这些。 123456789docker network create --driver bridge alpine-netdocket network lsNETWORK ID NAME DRIVER SCOPE810fb1e02000 alpine-net bridge local8d3b84bfe5a0 bridge bridge local3579d63da633 host host localf766b990db47 none null local 查看alpine-net网络详情注意网关和子网发生了变化。 1234567891011121314151617181920212223242526272829303132docker network inspect alpine-net[ &#123; &quot;Name&quot;: &quot;alpine-net&quot;, &quot;Id&quot;: &quot;810fb1e020008c7c6598f3b830ca25896dde638b1190d383ee6a5214d284e77d&quot;, &quot;Created&quot;: &quot;2018-06-14T15:45:19.43941906+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123;&#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 创建两种网络的容器 12345#alpine-netdocker run -dit --name alpine1 --network alpine-net alpine ash#default bridgedocker run -dit --name alpine2 alpine ash 显示两种网络情况 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596docker network inspect bridge[ &#123; &quot;Name&quot;: &quot;bridge&quot;, &quot;Id&quot;: &quot;8d3b84bfe5a034c65d043af80976a1e6127011fc1ab312446252f562e221d351&quot;, &quot;Created&quot;: &quot;2018-05-24T18:38:35.538308064+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.17.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;893903129d869f384bd78d63a382f1c9527d6979be0a6cf3c13ea4f45a1554d6&quot;: &#123; &quot;Name&quot;: &quot;hardcore_rosalind&quot;, &quot;EndpointID&quot;: &quot;515d1435470c9f72d3b07680515d9c503457b8eb5bcaaaa915bb53901eac9424&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.17.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125;, &quot;e7472c3ddda5043bc03868f4bf7ed59562220f05772f02f57ff589d086630562&quot;: &#123; &quot;Name&quot;: &quot;alpine2&quot;, &quot;EndpointID&quot;: &quot;ba565a247e347feb59713c188eb38e184d781da0489ae80e26ecad6d24e165c2&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:03&quot;, &quot;IPv4Address&quot;: &quot;172.17.0.3/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;, &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;, &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;]docker network inspect alpine-net[ &#123; &quot;Name&quot;: &quot;alpine-net&quot;, &quot;Id&quot;: &quot;810fb1e020008c7c6598f3b830ca25896dde638b1190d383ee6a5214d284e77d&quot;, &quot;Created&quot;: &quot;2018-06-14T15:45:19.43941906+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;264ccde8b1d5198551d689f0dd49ffbfb612255e0bf76c9543325d7c2e588acb&quot;: &#123; &quot;Name&quot;: &quot;alpine1&quot;, &quot;EndpointID&quot;: &quot;563c48cc6b936bcd9d3f57e9bb5e162a8cb52a23c8980346f288d42cc9b0a8fc&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 连接到容器 12345678910111213141516171819docker container attach alpine1#网段内通/ # ping -c 2 172.18.0.3PING 172.18.0.1 (172.18.0.3): 56 data bytes64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.097 ms64 bytes from 172.18.0.3: seq=1 ttl=64 time=0.070 ms--- 172.18.0.1 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.070/0.083/0.097 ms#网段外不通/ # ping -c 2 172.17.0.2PING 172.17.0.2 (172.16.0.1): 56 data bytes--- 172.17.0.2 ping statistics ---2 packets transmitted, 0 packets received, 100% packet loss 使容器连接到default bridge这样，此容器便连接到了两个网络中。 1234567docker network connect bridge apline1/ # ping -c 2 172.17.0.2PING 172.17.0.2 (172.17.0.2): 56 data bytes64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.102 ms64 bytes from 172.17.0.2: seq=1 ttl=64 time=0.071 ms host networkhost网络不存在隔离问题。 12345678910111213141516171819202122232425262728293031323334353637383940414243#默认主机上的80端口docker run -rm -dit --network host --name my_nginx nginx#访问http://localhost:80Welcome to nginx!docker network inspect host[ &#123; &quot;Name&quot;: &quot;host&quot;, &quot;Id&quot;: &quot;3579d63da633adcc497417d39b8b1d270cf329a68b9222f6a75fae72086509d6&quot;, &quot;Created&quot;: &quot;2018-04-27T11:31:17.900886126+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;host&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;f02a3b11fce7228ad6ee196771bd9cf0b64966bfc2aa7c27719bc120dbdc7189&quot;: &#123; &quot;Name&quot;: &quot;my_nginx&quot;, &quot;EndpointID&quot;: &quot;4ee67fb4d0a0c1a357b5fdd141f856a70c205fad5c49b1cb6a4f5245df0318a8&quot;, &quot;MacAddress&quot;: &quot;&quot;, &quot;IPv4Address&quot;: &quot;&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123;&#125; &#125;] overlay network default overlay network user-defined overlay network overlay network for standalone containers Communicate between a container and a swarm service default overlay依赖： swarm集群 集群节点 worker-1 worker-2 mananger 123456789docker network lsNETWORK ID NAME DRIVER SCOPE495c570066be bridge bridge local961c6cae9945 docker_gwbridge bridge localff35ceda3643 host host localtrtnl4tqnc3n ingress overlay swarmc8357deec9cb none null local 创建nginx-net的overlay的网络: 123456789docker network create -d overlay nginx-net$ docker service create \ --name my-nginx \ --publish target=80,published=80 \ --replicas=5 \ --network nginx-net \ nginx user-defined overlay123456789docker network create -d overlay my-overlay$ docker service create \ --name my-nginx \ --network my-overlay \ --replicas 1 \ --publish published=8080,target=80 \ nginx:latest overlay network for standalone containers Communicate between a container and a swarm service macvalan network假设主机网络接口为eth0。 bridge此模式下，流量通过eth0流动，docker使用其MAC地址就流量路由到容器。 创建名为my-macvlan-net的macvlan网络 12345$ docker network create -d macvlan \ --subnet=172.16.86.0/24 \ --gateway=172.16.86.1 \ -o parent=eth0 \ my-macvlan-net 查看网络 1234567docker network lsNETWORK ID NAME DRIVER SCOPE810fb1e02000 alpine-net bridge local8d3b84bfe5a0 bridge bridge local3579d63da633 host host local6be80655739d my-macvlan-net macvlan localf766b990db47 none null local 以此网络运行容器 12345$ docker run --rm -itd \ --network my-macvlan-net \ --name my-macvlan-alpine \ alpine:latest \ ash 查看my-macvlan-net 1234567891011121314151617181920212223242526272829303132333435363738394041docker network inspect my-macvlan-net[ &#123; &quot;Name&quot;: &quot;my-macvlan-net&quot;, &quot;Id&quot;: &quot;6be80655739deffe204e087d098f97fc75072d95f9818e129cfd7d5667ed01f3&quot;, &quot;Created&quot;: &quot;2018-06-14T16:52:30.507647877+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;macvlan&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.16.86.0/24&quot;, &quot;Gateway&quot;: &quot;172.16.86.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;8301b669b4b63afb20911b46243f11b70e5a9d0880beaafa922b52bcb8ab0477&quot;: &#123; &quot;Name&quot;: &quot;my-macvlan-alpine&quot;, &quot;EndpointID&quot;: &quot;4f2971ba4bd92c34e2a299d301f739867d2b1b65d35566aef07d7a26b079662c&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:10:56:02&quot;, &quot;IPv4Address&quot;: &quot;172.16.86.2/24&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;parent&quot;: &quot;ens160&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 查看容器网卡和路由 123456789docker exec my-macvlan-alpine ip addr show eth0517: eth0@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UNKNOWN link/ether 02:42:ac:10:56:02 brd ff:ff:ff:ff:ff:ff inet 172.16.86.2/24 brd 172.16.86.255 scope global eth0 valid_lft forever preferred_lft foreverdocker exec my-macvlan-alpine ip routedefault via 172.16.86.1 dev eth0172.16.86.0/24 dev eth0 scope link src 172.16.86.2 802.1q trunked bridge network此模式下，流量流经eth0的子接口(eth0.10)，docker使用其MAC地址将流量路由到容器。 创建名为my-8021q-macvlan-net的macvlan网络 12345docker network create -d macvlan \ --subnet=172.16.87.0/24 \ --gateway=172.16.87.1 \ -o parent=eth0.10 \ my-8021q-macvlan-net 查看此网络 123456789101112docker network lsNETWORK ID NAME DRIVER SCOPE2aeafd44fd67 my-8021q-macvlan-net macvlan local6be80655739d my-macvlan-net macvlan localifconfigeth0.10: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet6 fe80::20c:29ff:feaa:7e75 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:aa:7e:75 txqueuelen 0 (Ethernet) 用此网络启动一个容器 12345docker run --rm -itd \ --network my-8021q-macvlan-net \ --name my-second-macvlan-alpine \ alpine:latest \ ash 查看my-8021q-macvlan-net 1234567891011121314151617181920212223242526272829303132333435363738394041docker network inspect my-8021q-macvlan-net[ &#123; &quot;Name&quot;: &quot;my-8021q-macvlan-net&quot;, &quot;Id&quot;: &quot;2aeafd44fd67e6ee937c82788745b1d45fb291efd61f545537528eafdff94e3d&quot;, &quot;Created&quot;: &quot;2018-06-14T17:06:33.426800076+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;macvlan&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.16.87.0/24&quot;, &quot;Gateway&quot;: &quot;172.16.87.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;90103673d94915c3c7fb572eec8bd97b2aee1c3dab877c598d0a62e6d797b06d&quot;: &#123; &quot;Name&quot;: &quot;my-second-macvlan-alpine&quot;, &quot;EndpointID&quot;: &quot;5c93f2ea1d29150ee57f099d42fc8e04a571efd0d1273a4f6bed755dc34f2e54&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:10:57:02&quot;, &quot;IPv4Address&quot;: &quot;172.16.87.2/24&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;parent&quot;: &quot;ens160.10&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 查看容器网络接口 12345678910docker exec my-second-macvlan-alpine ip addr show eth0519: eth0@if518: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UNKNOWN link/ether 02:42:ac:10:57:02 brd ff:ff:ff:ff:ff:ff inet 172.16.87.2/24 brd 172.16.87.255 scope global eth0 valid_lft forever preferred_lft foreverdocker exec my-second-macvlan-alpine ip routedefault via 172.16.87.1 dev eth0172.16.87.0/24 dev eth0 scope link src 172.16.87.2 配置守护进程和容器启用IPv6启用IPv6前，请确保支持IPv6. 给docker daemon启用IPv6: 12345/etc/docker/daemon.json&#123; &quot;ipv6&quot;: true&#125; iptables所有Docker的iptables规则都被添加到DOKCER chain。不要手动操作此表。如果你需要添加Docker规则，请将其添加到DOCKER-USER chain 栗子： 1iptables -I DOCKER-USER -m iprange -i ext_if ! --src-range 192.168.1.1-192.168.1.3 -j DROP 容器网络容器使用的网络类型(无论是bridge，overlay，macvlan还是自定义网络)，在容器内都是透明的。从容器的角度来看，它有一个带有IP地址，网关，路由表，DNS服务和其它网络细节的网络接口。 publish port默认情况下，创建容器时，它不会将任何端口发布的外部世界。要是端口可用于docker之外的服务，请使用--publish或-p标志。 1234-p 8080:80-p 192.168.1.100:8080:80-p 8080:80/udp-p 8080:80/tcp -p 8080:80/udp ip add and hostname默认情况下，容器会为其连接的每个docker网络分配一个IP地址。IP地址是从分配给网络的地址池中分配的，因此docker daemon有效地充当了每个容器的DHCP服务器。每个网络也有一个默认的子网掩码和网关。同样，一个容器的主机名也有docker daemon指定。 12345678910111213141516#指定运行网络docker run xxx --network#运行的容器连接到其它网络docker network connect#--ip，指定IP地址docker network connect my-bridge --ip 172.18.0.111#--hostname，指定主机名docker run xxx --network xxx --hostname container-01docker network connect my-bridge --hostname container-02 DNS默认情况下，容器会继承docker daemon的DNS设置，包括/etc/hosts和/etc/resolv.conf。你也可以基于每个容器覆盖这些默认设置。 12345678910#DNS server--dns#DNS搜索域--dns-search#表示DNS选项值的键值对--dns-opt--hostname Docker使用代理服务器在启动docker容器的用户主目录下创建此文件： ~/.docker/config.json 12345678910&#123; &quot;proxies&quot;: &#123; &quot;default&quot;: &#123; &quot;httpProxy&quot;: &quot;http://127.0.0.1:3001&quot;, &quot;noProxy&quot;: &quot;*.test.example.com,.example2.com&quot; &#125; &#125;&#125; 应用程序数据Manage application data 存储综述Manage data in Docker 默认情况下，容器内创建的所有文件都被存储容器的可写层上： 当容器不在运行时，数据不是持续存在的。容器外的进程很难从容器中获取数据 容器的可写层与主机紧密耦合，你很难将数据移动到其他地方 向容器的可写入层写入数据，需要存储驱动(storage driver)管理文件系统才存储驱动使用Linux kernel来提供一个union filesystem。与直接写入主机文件系统的数据卷相比，这种额外的抽象会降低性能。 Docker容器有两种选项将文件存储到主机上，这样即使容器停止之后这些文件也会被保留: volumes bind mounts tmpfs mount(Docker on Linux) 选择正确的挂载方式Choose the right type of mount 无论你选用哪种挂载方式，数据在容器内看起来都是相同的。它被公开为容器文件系统中的目录或单个文件。 一个简单的方法——考虑数据在docker主机上的位置，可以看出volumes, bind mounts, temfs之间的差异： Volumesvolumes存储在由docker管理的主机文件系统的一部分中(如Linux上: /var/lib/docker/volumes/)。non-docker进程不应该修改这部分文件系统。Volume是Docker中保存数据的最佳方式。 Bind mountsbind mounts可存储在主机系统上的任何地方。它们可能是最要的系统文件或目录。docker主机或docker容器上的non-docker进程可以随时修改它们。 tmpfs仅存储在主机系统的内存中，不会写入主机系统的文件系统。 volumes的好栗子Good use cases for volumes Volemes是在docker容器和服务中持久化数据的首选方式: 在多个运行容器之间共享数据。如果你没有明确创建它，会在第一次挂载到容器时创建volume。当容器停止或删除时，volume仍然存在。多个容器可以挂载相同的volume，无论是read-write还是read-only。只有在你手动删除volume时它才会被删除。 当docker主机不能保证具有给定的目录或文件结构时，volume帮助你将docker主机的配置与运行时的容器进行分离。 当你想要将容器的数据存储在远程主机而不是本地的时候。 当你需要备份、还原或将数据从一台docker主机迁移到另一台时，volume时更好的选择。 bind mounts的好栗子一般来说，你应该尽量使用volumes。bind mounts适合以下案例： 从主机共享配置文件到容器这就是默认情况下，通过将主机的/etc/resolv.conf挂载到每个容器中，Docker为每个容器提供DNS解析。 在docker主机/容器的开发环境上共享源码或构建工件 当docker主机的文件或目录结构保证与容器所需的bind mounts一致时 tmpfs mounts的好栗子当你不希望数据在主机上或容器内持久存储时，tmpfs mounts最合适。这可能处于安全原因，或在应用于程序需要编写大量非持久性状态数据时保护容器的性能。 使用bind或volumes的提示如果你要使用bind mounts 或 volumes，牢记以下事项： 如果你挂载一个空卷(empty volume)到存在文件或目录的容器中的目录上，则会将这些文件或目录赋值到卷中。同样，如果你启动容器并制定了一个尚不存在的卷，则会为你创建一个空卷。 如果你挂载一个bind mount或non-empty volume到存在文件或目录的容器中的目录上，则这些文件或目录会被挂载所遮蔽。就像在Linux上挂载卷一样。 Volumesvolumes是持久化Docker数据的首选机制，卷由docker完全管理。另外，由于卷不会增加使用它的容器的大小，并且该卷的内容存在于给定容器的周期之外，因此卷通产是比将容器的可写入层中的数据持久化更好的选择。 1234567891011-v/--volume#此选项更详细和简单#如果你需要指定volume driver，请使用此flag--mountdocker service create \ --mount &apos;type=volume,src=&lt;VOLUME-NAME&gt;,dst=&lt;CONTAINER-PATH&gt;,volume-driver=local,volume-opt=type=nfs,volume-opt=device=&lt;nfs-server&gt;:&lt;nfs-path&gt;,&quot;volume-opt=o=addr=&lt;nfs-address&gt;,vers=4,soft,timeo=180,bg,tcp,rw&quot;&apos; --name myservice \ &lt;IMAGE&gt; --volume 由三个由冒号:分割的字段组成。这些字段必须按照正确的顺序排列，每个字段的含义并不明显。第一个字段是卷的名称，并且在给定主机上是唯一的。对于匿名卷，第一个字段被省略。第二个字段是文件或目录在容器中的挂载路径。第三个字段是可选的，是由一个逗号`,分隔的选项列表。 --mount 由多个键值对组成，以逗号,分隔。--mount的语法比--volume更冗长，但键的顺序并不重要，并且标志的值更易于理解。挂载的类型(type)有bind, volume, tmpfs。挂载的来源(source, src)为卷的名称，对于匿名卷该字段可被省略。目的地(destination, dst, target)的值是安装在容器中的文件或目录的路径。只读(readonly)选项将导致bind mount以只读方式挂载到容器中。volume-opt选项可以多次指定，它是由选项名称和值组成的键值对组成。 创建和管理卷1234567891011121314151617181920212223docker volume create my-voldocker volume lsDRIVER VOLUME NAMElocal my-voldocker volume inspect my-vol[ &#123; &quot;CreatedAt&quot;: &quot;2018-06-15T17:19:02+08:00&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: &#123;&#125;, &quot;Mountpoint&quot;: &quot;/opt/docker/volumes/my-vol/_data&quot;, &quot;Name&quot;: &quot;my-vol&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Scope&quot;: &quot;local&quot; &#125;]docker volume rm my-vol 启动用卷的容器Start a container with a volume 包括两种卷： 已存在的卷 未存在的卷会自动创建 123456789101112#--mountdocker run -d \ --name devtest \ --mount source=myvol2,target=/app \ nginx:latest#--volumedocker run -d \ --name devtest \ --volume myvol2:/app \ nginx:latest 1234567891011121314151617181920docker volume lsDRIVER VOLUME NAMElocal my-vollocal myvol2docker inspect devtest#找到挂载 &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;myvol2&quot;, &quot;Source&quot;: &quot;/opt/docker/volumes/myvol2/_data&quot;, &quot;Destination&quot;: &quot;/app&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;z&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; &#125; ] 启动用卷的服务Start a service with volumes docker服务不支持使用--volume标志，请使用--mount标志。 12345docker service create -d \ --replicas=4 \ --name devtest-service \ --mount source=myvol2,target=/app \ nginx:latest 在机器间共享数据Share data among machines 在构建容错应用程序时，可能需要配置同一服务的多个副本能访问相同的文件，而这些副本可能分布于不同的节点上。 卷驱动程序(volume driver)允许你从应用程序逻辑中抽象出底层存储系统。 使用卷驱动Use a volume driver 在创建卷或启动带卷的容器时，你可以指定卷驱动。如vieux/sshfs卷驱动程序。 初始化 1docker plugin install --grant-all-permissions vieux/sshfs 使用卷驱动创建卷 12345#操作node2docker volume create --driver vieux/sshfs \ -o sshcmd=test@node2:/home/test \ -o password=testpassword \ sshvolume 启动一个带用卷驱动程序创建的卷的容器 12345docker run -d \ --name sshfs-container \ --volume-driver vieux/sshfs \ --mount src=sshvolume,target=/app,volume-opt=sshcmd=test@node2:/home/test,volume-opt=password=testpassword \ nginx:latest 备份，还原或迁移数据卷 使用--volumes-from标志创建一个挂载该卷的新容器。 1234567#备份docker run --rm --volumes-from dbstore -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata#从备份还原docker run -v /dbdata --name dbstore2 ubuntu /bin/bashdocker run --rm --volumes-from dbstore2 -v $(pwd):/backup ubuntu bash -c &quot;cd /dbdata &amp;&amp; tar xvf /backup/backup.tar --strip 1&quot; bind mounts与volumes相比，bind mounts功能有限。当你使用bind mounts时，主机上的文件或目录(绝对路径或相对路径)被挂载到容器内。相比之下，当你使用volumes时，会在主机上的Docker存储目录中创建一个新目录，并且Docker会管理该目录的内容。该文件或目录不需要已经存在于Docker主机上。如果它尚未存在，它会根据需求创建。bind mounts非常高效，但是它们依赖于具有特定目录结构的主机文件系统。如果你正在开发新的Docker Application，请考虑使用volumes。你不能使用Docker CLI直接管理bind mounts。 你可以使用--volume或--mount(语法更详细)flag。具体区别参考volumes的介绍。 启动用bind mount的容器Start a container with a bind mount 1234567891011121314#--mountdocker run -d \ -it \ --name devtest \ --mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app \ nginx:latest#--volumedocker run -d \ -it \ --name devtest \ -v &quot;$(pwd)&quot;/target:/app \ nginx:latest 挂载到容器内非空目录如果挂载在容器内非空目录上，则该目录的已有内容将被隐藏。 1234567891011121314#--mountdocker run -d \ -it \ --name broken-container \ --mount type=bind,source=/tmp,target=/usr \ nginx:latest#--volumedocker run -d \ -it \ --name broken-container \ -v /tmp:/usr \ nginx:latest 只读bind mountUse a read-only bind mount 某些时候，容器可能只需要只读权限。 1234567891011121314#--mountdocker run -d \ -it \ --name devtest \ --mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app,readonly \ nginx:latest#--volumedocker run -d \ -it \ --name devtest \ -v &quot;$(pwd)&quot;/target:/app:ro \ nginx:latest bind propagation对于bind mounts和volumes，bind propagation(传播)默认为rprivate。它只能对Linux主机上的bind mounts进行配置。它是一个高级话题，许多用户并不需要配置它。 bind propagation(传播)是指在给定的bind-mounts或named volume中创建的挂载是否可以传播(propagation)到该挂载(mount)的副本(replicas)。考虑一个挂载点/mnt，挂载在/tmp上。传播设置控制/tmp/a上的挂载点是否也可用于/mnt/a。每个传播设置都有一个递归对应点。在递归的情况下，考虑/tmp/a也被挂载到/foo。传播设置控制是否存在/mnt/a和/tmp/a。 传播设置 描述 shared 原始mount的sub-mount会暴露给replica mounts，并且replica mounts的sub-mount同样传播给原始mount。也就是双向 slave 类似于shared，但仅限于单方向。 private 私有挂载 rshared 与shared相同，但传播也扩展到嵌套在任何原始或副本挂载点内的挂载点 rslave 与slave相同，但传播也扩展到嵌套在任何原始或副本挂载点内的挂载点 rprivate 默认值。与private相同，这意味着原始或副本挂载点内的任何位置的挂载点都不会沿任一方向传播 在设置bind propagation之前，主机文件系统需要已经支持bind propagatin: https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt 12345678910111213141516#--mountdocker run -d \ -it \ --name devtest \ --mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app \ --mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app2,readonly,bind-propagation=rslave \ nginx:latest#--volumedocker run -d \ -it \ --name devtest \ -v &quot;$(pwd)&quot;/target:/app \ -v &quot;$(pwd)&quot;/target:/app2:ro,rslave \ nginx:latest selinux label如果你使用selinux，你可以添加z或Z选项来修改挂载到容器内的主机文件或目录的selinux标签。这户影响主机本身的文件或目录，并可能导致Docker范围之外的后果。 zbind mount的内容在多个容器之间共享。 Zbind mount的内容是私有和非共享的。 123456#不支持--mountdocker run -d \ -it \ --name devtest \ -v &quot;$(pwd)&quot;/target:/app:z \ nginx:latest tmpfs mountstmpfs: https://docs.docker.com/storage/tmpfs/#limitations-of-tmpfs-mountstmpfs mounts只支持运行在Linux上的Docker。 Troubleshoottroubleshoot: https://docs.docker.com/storage/troubleshooting_volume_errors/ 将数据存储到容器内Store data within containers 关于存储驱动为了有效地使用存储驱动(storage driver)，了解Docker如何构建和存储镜像，以及容器如何使用镜像是很重要的。你可以使用这些信息作出明智的选择，以便找到应用程序数据持久化的最佳方式，并避免出现性能问题。 存储驱动允许你在容器的可写入层创建数据。在容器停止后，这些文件将不会被保留，并且读写速度都很低。 镜像和层Images and layers Docker镜像由一系列层(layer)构建而成。每个层代表镜像的Dockerfile中的指令，除最后一层外的每个层都是只读的。 考虑如下Dockerfile: 1234FROM ubuntu:15.04COPY . /appRUN make /appCMD python /app/app.py 此Dockerfile包含4个命令，每个命令创建一个层。当你创建一个新容器时，你在底层之上添加了一个新的可写入层——它通常被称为容器层(container layer)。对运行中的容器所做的所有更改(增删改文件)都会写入此可写容器层。 存储驱动处理有关这些层相互交互的详细信息。有几个不同的驱动程序，在不同的情况下具有相应的优点和缺点。 容器和层Container and layers 容器和镜像之间的主要区别是最高的可写入层。当容器删除时，可写入层也被删除。但底层镜像保持不变。 由于每个容器都有自己的可写入容器层，并且所有的更改都存储在此容器中，因此多个容器可以共享相同的基础镜像的访问权限，并拥有自己的数据状态。 Docker使用存储驱动来管理镜像层和可写入容器层的内容。每个存储驱动程序都已不同方式实现，但所有驱动程序都是用可堆叠(stackable)的镜像层和写入时复制(copy-on-write)策略。 容器大小Container size on disk 使用docker ps -s(--size)命令查看正在运行的容器的大小。有两个大小: size每个容器的可写入层的数据量(在磁盘上的) virtual size容器使用的只读镜像的数据量加上容器可写入层大小 写入时复制The copy-on-write (CoW) strategy 写入时复制是一种共享和复制文件以实现最高效率的策略。如果文件或目录存在于镜像的较低层中，而另外的层(包括可写入层)需要对其进行读取访问，则它只是用已有文件。第一次需要修改文件时，该文件将被复制到该层并进行修改。这最大限度减少了每个后续层的I/O和大小。 共享促进了较小的容器Sharing promotes smaller images 当你创建和拉取镜像时，它们通常存储于本机的/var/lib/docker下。每层都存储在主机存储区内的特定目录下/var/lib/docker/&lt;storage-driver&gt;/layers。 123456ls /var/lib/docker/aufs/layers1d6674ff835b10f76e354806e16b950f91a191d3b471236609ab13a930275e245dbb0cbe0148cf447b9464a358c1587be586058d9a4c9ce079320265e2bb94e7bef7199f2ed8e86fa4ada1309cfad3089e0542fec8894690529e4c04a7ca2d73ebf814eccfe98f2704660ca1d844e4348db3b5ccc637eb905d4818fbfb00a06a 复制使容器高效Copying makes containers efficient 容器不会更改的任何文件都不会被复制到此可写入层中。这意味着可写入层尽可能小。 当容器中存在的文件被修改时，存储驱动之赐你个写入时复制操作(CoW)。涉及的具体步骤取决于具体的存储驱动。 aufs, overlay, overlay2存储驱动 遵循的基本顺序: 通过镜像层搜索要更新的文件 对找到的文件的第一个副本执行copy_up操作，将文件复制到容器的可写入层 任何修改应用于此复制的文件，并且该容器不能看到存在于较低层中的文件的只读副本 选择存储驱动Select a storage driver 理想情况下，将很少的数据写入容器的可写入层，并且使用Docker volume写入数据。但某些工作负载要求你能够写入容器的可写入层，这就是存储驱动进来的地方。 存储驱动控制镜像和容器在Docker主机上的存储和管理方式。 考虑三个高层次因素： 如果你的Kernel支持多个存储驱动，在没有指定存储驱动的情况下，Docker会列出要使用拿个存储驱动程序的优先级列表 如果可能，将使用配置最少的存储驱动。如brrfs, zfs 否则，请尝试在最常见的情况下使用具有最佳整体性能和稳定性的存储驱动程序 overlay2是首选(Docker CE的默认选择)，其次是overlay。这些都不需要额外的配置。 devicemapper居次，但需要direc-lvm用于生产环境，因为loopback-lvm的性能很差。 你的选择会受限于Docker版本、操作系统和发行版 某些存储驱动要求你为文件系统使用特定格式 你的选择还取决于工作负载和所需的稳定级别 Linux发行版支持的存储驱动Docker CE Linux distribution Recommended storage drivers Docker CE on Ubuntu aufs, devicemapper, overlay2 (Ubuntu 14.04.4 or later, 16.04 or later), overlay, zfs, vfs Docker CE on Debian aufs, devicemapper, overlay2 (Debian Stretch), overlay, vfs Docker CE on CentOS devicemapper, vfs Docker CE on Fedora devicemapper, overlay2 (Fedora 26 or later, experimental), overlay (experimental), vfs 存储驱动支持的文件系统 Storage driver Supported backing filesystems overlay, overlay2 ext4, xfs aufs ext4, xfs devicemapper direct-lvm btrfs btrfs zfs zfs 查看存储驱动12345docker infoServer Version: 18.03.1-ceStorage Driver: overlay2 AUFS存储驱动AUFS is a union filesystem. aufs存储驱动用于管理Ubuntu上Docker的镜像和层。 我的发行版是Centos，此驱动针对Ubuntu。注意 使用aufs存储驱动配置Docker 判断kernel是否支持aufs 1grep aufs /proc/filesystems 查看Docker存储驱动 1docker info 配置存储驱动 1234vim /etc/docker/daemon.json#或--storage-driver aufs存储驱动如何工作AUFS是一个联合文件系统，这意味着它在单个Linux主机上对多个目录进行分层并将它们呈现为单个目录。这些目录在AUFS术语中称为分支，在Docker术语中称为层。统一过程被称为联合安装。 容器如何使用aufs进行读写读取文件 Btrfs存储驱动Use the BTRFS storage driver Device Mapper存储驱动Use the Device Mapper storage driver Device Mapper是基于kernel的框架，支持Linux上的许多高级卷管理技术。Docker的devicemapper存储驱动利用此框架的精简配置和快照功能进行镜像和容器管理。 对于支持它的系统，devicemapper支持包含在Linux内核中。但是，需要特定配置才能将其用于Docker。devicemapper驱动使用专用于Docker的块设备，并在块级(block level)而不是文件级(file level)运行。这些设备可通过在Docker主机添加物理设备来扩展，并且它们比咋子操作系统级别使用文件系统更好。 依赖 Docker EE Docker CE 更改存储驱动会使已创建的容器在本地系统上都无法访问 配置devicemapper存储驱动 loop-lvm 1234567891011#loop-lvm模式/etc/docker/daemon.json&#123; &quot;storage-driver&quot;: &quot;devicemapper&quot;&#125;#查看docker info direct-lvm生产环境的devicemapper存储驱动必须使用direct-lvm模式。此模式使用块设备创建精简池。这比使用loopback设备更快，更高效地使用系统资源，并且块设备可以根据需求进行扩展。 Option Description Required Default Example dm.directlvm_device The path to the block device to configure for direct-lvm. Yes - dm.directlvm_device=”/dev/xvdf” dm.thinp_percent The percentage of space to use for storage from the passed in block device. No 95 dm.thinp_percent=95 dm.thinp_metapercent The percentage of space to for metadata storage from the passed-in block device. No 1 dm.thinp_metapercent=1 dm.thinp_autoextend_threshold The threshold for when lvm should automatically extend the thin pool as a percentage of the total storage space. No 80 dm.thinp_autoextend_threshold=80 dm.thinp_autoextend_percent The percentage to increase the thin pool by when an autoextend is triggered. No 20 dm.thinp_autoextend_percent=20 dm.directlvm_device_force Whether to format the block device even if a filesystem already exists on it. If set to false and a filesystem is present, an error is logged and the filesystem is left intact. No false dm.directlvm_device_force=true 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#安装依赖RHEL / CentOS: device-mapper-persistent-data, lvm2, and all dependenciesUbuntu / Debian: thin-provisioning-tools, lvm2, and all dependencies#创建物理卷(physical volume)pvcreate /dev/cvdf#创建卷组(volume group)vgcreat docker /dev/xvdf#创建逻辑卷(logical volume)lvcreate --wipesignatures y -n thinpool docker -l 95%VGlvcreate --wipesignatures y -n thinpoolmeta docker -l 1%VG#转换卷为精简池lvconvert -y \--zero n \-c 512K \--thinpool docker/thinpool \--poolmetadata docker/thinpoolmeta#配置lvm配置文件精简池自动扩展/etc/lvm/profile/docker-thinpool.profile#指定thin_pool_autoextend_threshold 和 thin_pool_autoextend_percent的值activation &#123; thin_pool_autoextend_threshold=80 thin_pool_autoextend_percent=20&#125;#应用LVM profilelvchange --metadataprofile docker-thinpool docker/thinpool#启用监控LVlvs -o+seg_monitor#配置devicemapper存储驱动/etc/docker/daemon.json&#123; &quot;storage-driver&quot;: &quot;devicemapper&quot;, &quot;storage-opts&quot;: [ &quot;dm.thinpooldev=/dev/mapper/docker-thinpool&quot;, &quot;dm.use_deferred_removal=true&quot;, &quot;dm.use_deferred_deletion=true&quot; ]&#125;#查看docker info 管理devicemapper1234567#查看LVM logsjournalctl -fu dm-event.servicepvdisplayvgdisplay/vgextendlvdisplay/lvextend/lvchange OverlayFS存储驱动Use the OverlayFS storage driver ZFS存储驱动Use the ZFS storage driver VFS存储驱动Use the VFS storage driver VFS存储驱动不是联合文件系统，相反，每层都是磁盘上的一个目录，它不支持CoW。要创建一个新层，先前的层会进行深层复制(deep copy)。与其它驱动相比，这导致磁盘性能下降和占用更多磁盘空间。但是，它强大，稳定，适用于各种环境。 配置VFS存储驱动 1234567891011121314151617vim /etc/docker/daemon.json&#123; &quot;storage-driver&quot;: &quot;vfs&quot;&#125;#控制大小&#123; &quot;storage-opts&quot;: [&quot;size=256M&quot;]&#125;#查看docker info 在生产环境运行应用程序Run your app in production 配置对象Configure all objects 自定义原数据Apply custom metadata to objects Docker object label标签(label)是一种将原数据(metadata)应用于docker object的机制，包含: image container local daemon volume network node service label key and value标签是一组键值对，以字符串形式存储。可以为对象指定多个标签，但每个键值对必须唯一。如果一个键有多个值，则最新写入的值会覆盖以前的值。 key格式建议label key是可能包含字母，数字，.，-组成的字符串。 第三方工具的作者给每个label key加上前缀域，如com.example.some-label 未经允许，不得使用他人域 com.docker.*, io.docker.*, org.dockerproject.*命名空间保留给Docker内部使用 以小写字母开头和结尾 用.分割命令空间字段 value 指南label value可以包含任何可表示为字符串的数据类型，包括JSON, XML, CSV, YAML…唯一的要求是，首先使用特定于结构类型的机制将该值序列化为字符串。 清理未使用的对象Prune unused Docker objects Docker采取保守的方法来清理未使用的对象(通常称为垃圾回收)，通常它不会删除这些对象，除非你明确要求Docker这样做。对于每个类型的对象，docker提供了prune命令。你也可以使用docker system prune命令一次清理多种类型的对象。 1234567891011121314151617#prune imagedocker image prune docker image prune -a --filter &quot;until=24h&quot;#prune containerdocker container prune#prune volumedocker volume prunedocker volume prune --filter &quot;label!=keep&quot;#prune everythingdocker system prunedocker system prune --volumes 格式化输出Format command and log output 1234567891011121314151617181920212223242526#joindocker inspect --format &apos;&#123;&#123;join .Args &quot; , &quot;&#125;&#125;&apos; container#jsondocker inspect --format &apos;&#123;&#123;json .Mounts&#125;&#125;&apos; container#lowerdocker inspect --format &quot;&#123;&#123;lower .Name&#125;&#125;&quot; container#splitdocker inspect --format &apos;&#123;&#123;split .Image &quot;:&quot;&#125;&#125;&apos;#titledocker inspect --format &quot;&#123;&#123;title .Name&#125;&#125;&quot; container#upperdocker inspect --format &quot;&#123;&#123;upper .Name&#125;&#125;&quot; container#printIndocker inspect --format=&apos;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;println .IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&apos; container 配置daemonConfigure the daemon 配置和运行Docker配置docker daemon 使用json配置文件 使用dockerd --flag 1234567891011121314151617/etc/docker/daemon.json&#123; &quot;debug&quot;: true, &quot;tls&quot;: true, &quot;tlscert&quot;: &quot;/var/docker/server.pem&quot;, &quot;tlskey&quot;: &quot;/var/docker/serverkey.pem&quot;, &quot;hosts&quot;: [&quot;tcp://192.168.59.3:2376&quot;]&#125;#或dockerd --debug \ --tls=true \ --tlscert=/var/docker/server.pem \ --tlskey=/var/docker/serverkey.pem \ --host tcp://192.168.59.3:2376 docker daemon目录docker daemon将所有数据保存在一个目录中。你可以手动修改它。 默认目录: Linux： /var/lib/docker Windows: C:\ProgramData\docker 使用systemd控制dockerControl Docker with systemd 123456cat /usr/lib/systemd/system/docker.service#orcat /etc/systemd/system/docker.servicesystemctl enable/start/stop/status docker 自定义docker daemon选项 123456vim /etc/docker/daemon.json&#123; &quot;data-root&quot;: &quot;/mnt/docker-data&quot;, &quot;storage-driver&quot;: &quot;overlay&quot;&#125; http/https proxyDocker daemon使用HTTP_PROXY，HTTPS_PROXY和NO_PROXY环境变量来配置代理行为。无法使用daemon.json文件来配置环境变量。 123456789101112131415mkdir -p /etc/systemd/system/docker.service.d#/etc/systemd/system/docker.service.d/http-proxy.conf[Service]Environment=&quot;HTTP_PROXY=http://proxy.example.com:80/&quot;#/etc/systemd/system/docker.service.d/https-proxy.conf[Service]Environment=&quot;HTTPS_PROXY=https://proxy.example.com:443/&quot;systemctl daemon-reloadsystemctl restart dockersystemctl show --property=Environment docker 收集Docker指标Collect Docker metrics with Prometheus Promethus: https://prometheus.io/Prometheus是一个开源的系统监控和报警工具包。你可以将Docker配置为Prometheus target。设置Prometheus作为Docker容器运行，并使用Prometheus监控Docker实例。 配置Docker配置docker daemon作为Prometheus target，你需要指定metrics-address。最佳方式是通过daemon.json。 1234&#123; &quot;metrics-addr&quot; : &quot;127.0.0.1:9323&quot;, &quot;experimental&quot; : true&#125; 配置和运行Prometheus 12345678910111213141516171819202122232425262728293031323334353637/tmp/prometheus.yml# my global configglobal: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Attach these labels to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: monitor: &apos;codelab-monitor&apos;# Load rules once and periodically evaluate them according to the global &apos;evaluation_interval&apos;.rule_files: # - &quot;first.rules&quot; # - &quot;second.rules&quot;# A scrape configuration containing exactly one endpoint to scrape:# Here it&apos;s Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: &apos;prometheus&apos; # metrics_path defaults to &apos;/metrics&apos; # scheme defaults to &apos;http&apos;. static_configs: - targets: [&apos;localhost:9090&apos;] - job_name: &apos;docker&apos; # metrics_path defaults to &apos;/metrics&apos; # scheme defaults to &apos;http&apos;. static_configs: - targets: [&apos;localhost:9323&apos;] 1234docker service create --replicas 1 --name my-prometheus \ --mount type=bind,source=/tmp/prometheus.yml,destination=/etc/prometheus/prometheus.yml \ --publish published=9090,target=9090,protocol=tcp \ prom/prometheus 访问: http://localhost:9090/targets/ 配置容器Configure containers 自动启动容器Start containers automatically Docker提供了重启策略，以控制容器在退出或重启时自动启动。重启策略可确保链接的容器以正确的书序启动。Docker建议你使用重启策略，并避免使用进程管理器(如supervisor)来启动容器。重启策略与docker xxx --live-restart标志不同，后者可以让你在Docker upgrage期间保持容器运行。 重启策略使用docker run xxx --restart标志来配置重启策略，--restart的值如下： 标志 描述 no 不要自动重启容器(默认值) on-failure 如果容器由于错误(非零退出码)退出，则重启容器 unless-stopped 除非明确停止或docker本身停止或重启，则重启容器 always 如果停止，则始终重启容器 12#栗子docker run -dit --restart unless-stopped redis 重启策略注意事项 重启策略尽在容器成功启动后才生效——这意味着容器已启动至少10s，并且Docker已开始监视它。这可以防止根本不启动的容器进入重启循环。 如果你手动停止容器(状态码为0)，则在重启Docker daemon或手动启动容器之前，其重启策略将会被忽略。这是另一个防止重启循环的尝试。 重启策略仅适用于容器。集群服务的重启策略与此不同。 在daemon停机期间保持容器活着Keep containers alive during daemon downtime 默认情况下，当Docker daemon终止时，它会关闭正在运行的容器。从Docker Engine 1.12开始，你可配置守护进程，以便在守护进程不可用时容器保持运行。这个功能被称为实时恢复(live restore)。它不支持Windows container。 实时恢复有两种方式来启用live restore，只启用其中一个就好。实时恢复仅适用于独立容器，不适用于集群服务。 修改配置文件 12345/etc/docker/daemon.json&#123; &quot;live-restore&quot;: true&#125; --live-restore标志不推荐 1dockerd xxx --live-restore 在一个容器中运行多个服务Run multiple services in a container 容器的主要运行进程是Dockerfile末尾的ENTRYPOINT或CMD指令。通常建议你通过每个容器运行一项服务来分割关注区域。这些服务可能会分成多个进程(如Nginx的worker processe)。你可以使用用户定义的network和shared volumes来连接多个容器。 容器的主进程负责管理它启动的所有进程。在某些情况下，主进程设计不好，在容器退出时无法正常处理停止子进程。如果你的进程属于这个类别，你可在容器运行时使用--init选型。--init标志将一个微小的inti-process作为主进程插入到容器中，并在容器退出时处理所有进程的停止。以这种方式处理这些进程优于使用完整的初始化进程。 如果你需要在一个容器中运行多个服务，则可通过几种不同方式来完成此操作。 将所有命令封装进一个脚本中，并附带测试和调试信息。以封装脚本作为你的CMD 1234567891011121314vim my_wrapper.sh#!/bin/bashxxxxxxxxvim DockerfileFROM ubuntu:latestCOPY my_first_process my_first_processCOPY my_second_process my_second_processCOPY my_wrapper_script.sh my_wrapper_script.shCMD ./my_wrapper_script.sh 使用如supervisord这样的进程管理器 1234567FROM ubuntu:latestRUN apt-get update &amp;&amp; apt-get install -y supervisorRUN mkdir -p /var/log/supervisorCOPY supervisord.conf /etc/supervisor/conf.d/supervisord.confCOPY my_first_process my_first_processCOPY my_second_process my_second_processCMD [&quot;/usr/bin/supervisord&quot;] 容器运行指标Container runtime metrics docker stats 12345docker stats redis1 redis2CONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/Oredis1 0.07% 796 KB / 64 MB 1.21% 788 B / 648 B 3.568 MB / 512 KBredis2 0.07% 2.746 MB / 64 MB 4.29% 1.266 KB / 648 B 12.4 MB / 0 B Control groups Linux Container依赖于control group，这些组不仅跟踪进程组，还公开有关CPU，mem，block I/O的使用情况和度量标准。你可以访问这些指标并判断容器运行状况。control group通过为文件系统(pseudo-fs)公开，你应该可在/proc/fs/cgroup中找到它。 查看cgroup子系统： 1234567891011121314151617181920212223grep cgroup /proc/mounts#ormount -l | grep cgroup#进程/proc/&lt;pid&gt;/cgroup#/表示进程尚未分配给groupcat /proc/1/cgroup11:devices:/10:cpuset:/9:hugetlb:/8:memory:/7:blkio:/6:net_prio,net_cls:/5:pids:/4:perf_event:/3:cpuacct,cpu:/2:freezer:/1:name=systemd:/ 查找给定容器的cgroup对于每个容器，每个层次结构中创建一个cgroup。 123456789101112131415161718192021222324252627282930313233343536373839/sys/fs/cgroup/memory/docker/&lt;docker-longid&gt;/cd /sys/fs/cgroup/memory/docker/893903129d869f384bd78d63a382f1c9527d6979be0a6cf3c13ea4f45a1554d6cat memory.statcache 36282368rss 196608rss_huge 0mapped_file 1077248swap 0pgpgin 212904pgpgout 205531pgfault 314692pgmajfault 204inactive_anon 131072active_anon 65536inactive_file 18223104active_file 18059264unevictable 0hierarchical_memory_limit 9223372036854771712hierarchical_memsw_limit 9223372036854771712total_cache 36282368total_rss 196608total_rss_huge 0total_mapped_file 1077248total_swap 0total_pgpgin 212904total_pgpgout 205531total_pgfault 314692total_pgmajfault 204total_inactive_anon 131072total_active_anon 65536total_inactive_file 18223104total_active_file 18059264total_unevictable 0#其它信息类似 限制容器的资源Limit a container’s resources 默认情况下，容器没有资源限制，可以使用主机内核调度程序允许给定的资源。Docker提供了一些方法来控制容器可以使用的CPU、memory、block I/O。 许多这些功能需要内核的支持。使用docker info命令检查是否支持。如果内核禁用了某功能，则可能会有如下警告: WARNING: No swap limit support memory你需要了解内存耗尽(out of memory)的风险不要让正在运行的容器消耗太多的主机内存，这很重要。在Linux主机上，如果内核检测到没有足够的内存来执行重要的系统功能，它会抛出一个OOME(out of memory exception)，并开始killing process以释放进程。任何进程都会是killing objects，包括Docker和其它重要应用程序。 docker尝试通过调整docker daemon的OOM优先级来降低这些风险，从而使其比系统上的其它进程更小(less)可能的被killing。容器的OOM优先级不进行调整，这使得单个容器被killing的可能性要大于docker或其它进程。你不应该给docker daemon的--oom-score-adj或container的--oom-kill-disable标志来绕过这些安全措施。 你可以通过以下方式减轻由OOM引起的系统不稳定的风险: 在上线之前，进行测试以了解应用程序的内存需求 确保应用程序仅在拥有足够资源的主机上运行 限制容器可使用的内存量 在主机上配置swap时请注意。swap比内存更慢，性能更低，但可以提供缓冲区以防系统内存耗尽 考虑将容器转换为服务，并使用服务级别约束和节点标签来确保应用程序仅在具有足够内存的主机上运行 限制容器对内存的Limit a container’s access to memory Docker可以强制hard limit，允许容器使用不超过给定数量的用户/系统内存，或soft limit。这允许容器使用尽可能多的内存。 如下这些选项具有这样一些效果，注意内存单位b, k, m, g： 选项 描述 -m/--memory= 容器可使用的最大内存量。如果你设置此选项，则允许的最小值为4m --memory-swap 容器允许使用的swap量。只有在--momery设置时才有意义 --memory-swappiness 默认情况下，容器可使用的主机内核可交换的匿名页面的百分比 --memory-reservation 允许你指定一个小于--memory的soft limit。当docker检测到内存不足时，此会被激活 --kernel-memory 容器可以使用的最大kernel memory。内核内存不能够被swap out，因此内核内存不足的容器可能会阻塞主机资源，这会对主机和其它容器产生副作用 --oom-kill-disable 默认情况下，如果发生内存溢出(OOM)，内核会杀死容器中的进程。使用此选项改变此行为 cpu默认情况下，每个容器对主机CPU周期的访问是无限制的。你可以设置各种约束来限制给定容器访问主机的CPU周期。 CFS schedulerCFS是用于普通Linux进程的Linux kernel CPU调度器，一些运行时标志用于配置容器的CPU资源访问量。 选项 描述 --cpu=&lt;value&gt; 指定容器可以使用的CPU资源，如--cpu=&quot;1.6&quot; --cpu-period=&lt;value&gt; 指定CFS调度器周期，它与--cpu-quota一起使用。默认100ms。Docker1.13以后，使用--cpus替代 --cpu-quota=&lt;value&gt; 在容器上条件CFS配额。在Docker1.13以后，使用--cpus替代 --cpuset-cpus 限制容器可以使用的特定CPU或CORE。如果有多个CPU，请使用逗号,分割。如0,2 --cpu-shares 将此标志设置为大于/小于1024(默认值)的值，以增加或减少容器的重量，并使其能够访问更大或更小比例的主机CPU周期。这仅在CPU周期受到限制时才会执行。 如果你只有1 CPU，如下命令可保证容器每秒最多有50%的CPU——docker run -it --cpus=&quot;.5&quot; xxx realtime scheduler 在Docker1.13及更高版本，对于无法使用CFS的任务，你可以使用realtime scheduler。在你配置docker daemon和container之前，请正确地配置主机内核。 注意： CPU调度和优先级是高级内核功能。大多数用户不需要修改它。错误地设置将导致主机系统不稳定或不可用。 配置主机内核通过运行zcat /proc/config.gz | grep CONFIG_RT_GROUP_SCHED或检查/sys/fs/cgroup/cpu.rt_runtime_us来验证内核是否启用了CONFIG_RT_GROUP_SCHED。有关配置内核实时调度器的指导，请参考相关文档。 配置docker daemon运行docker daemon时使用--cpu-rt-runtime标志设置每个运行时间段的实时任务保留的最大微秒数。可使用systemd的docker.service进行配置。 配置独立容器当使用docker run启动容器时，可以传递多个标志来控制容器CPU的优先级。 选项 描述 --cap-add=sys_nice 授予容器CAP_SYS_NICE功能，允许容器提升进程的nice值，设置实时调度策略，设置CPU关联和其它操作 --cpu-rt-runtime=&lt;value&gt; Docker实时调度器期间，容器可以以实时优先级运行的最大微秒数。需要--cap-add=sys_nice标志 --ulimit rtprio=&lt;value&gt; 容器允许的最大实时优先级，需要--cap-add=sys_nice标志 栗子： 1234docker run --it --cpu-rt-runtime=950000 \ --ulimit rtprio=99 \ --cap-add=sys_nice \ debian:jessie Logging查看容器日志记录的信息和日志格式取决于容器的端点命令。docker logs命令显示正在运行的容器记录的信息。docker service logs命令显示参与服务的所有容器记录的信息。在swarm模式下。 在某些情况下，docker logs可能不会显示有用的信息，除非你采取其它措施。 如果将日志发送到文件、主机、数据库或其它日志驱动程序，则docker logs可能不会显示有用的信息 如果你的镜像运行non-interactive进程(如数据库)，则该应用程序可能会将output发送到日志文件而不是stdout/stderr 配置日志驱动Configure logging drivers docker提供了多种日志记录机制(logging mechanisms)来帮助你从运行的容器和服务中获取信息。这些机制被称为日志驱动(logging driver)。每个docker daemon都有一个默认日志驱动，每个容器也默认使用该驱动。除非你给容器配置了其它日志驱动。除了使用docker附带日志驱动，在Docker v17.05之后，你还可以使用日志驱动插件(logging driver plugin)。 配置默认日志驱动默认的日志驱动是json-flie。可在daemon.json文件里通过log-driver选项匹配置日志驱动。 123456/etc/docker/daemon.json#设置为syslog&#123; &quot;log-driver&quot;: &quot;syslog&quot;&#125; 如果日志驱动存在可配置选项： 1234567891011121314/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;labels&quot;: &quot;production_status&quot;, &quot;env&quot;: &quot;os,customer&quot; &#125;&#125;#查看docker info | grep &apos;Loggin Driver&apos;Logging Driver: json-file 为容器配置日志驱动启动容器时，可使用--log-driver标志为其配置不同于docker daemon的日志驱动。 12345docker run -it --log-driver none alpine ash#查看容器日志驱动docker inspect -f &apos;&#123;&#123;.HostConfig.LogConfig.Type&#125;&#125;&apos; &lt;CONTAINER&gt; 配置从容器到日志驱动的log message的交付模式Docker为从容器到日志驱动的日志消息提供了两种交付(delivery）模式： 直接阻塞(blocking)从容器到驱动的交付(默认) 非阻塞交付(non-blocking)，将日志消息存储在中间每个容器的环形缓冲区中供驱动使用非阻塞消息交付模式可防止应用程序因日志反压而被阻塞。当STDERR或STDOUT流阻塞时，应用程序可能会以意想不到的方式失败。 注意：当缓冲区已满且新消息排入队列时，内存中最早的消息将被丢弃。丢弃消息通常首选阻止应用程序的日志写入过程。 1docker run -it --log-opt mode=non-blocking --log-opt max-buffer-size=4m alpine ping 127.0.0.1 日志驱动使用环境变量或label一些日志驱动将容器的--env/-e或--label标签的值添加到容器的日志中。 1docker run -dit --label production_status=testing -e os=ubuntu alpine sh 支持的日志驱动如下是受支持的日志驱动。 驱动 描述 none No logs are available for the container and docker logs does not return any output. json-file The logs are formatted as JSON. The default logging driver for Docker. syslog Writes logging messages to the syslog facility. The syslog daemon must be running on the host machine. journald Writes log messages to journald. The journald daemon must be running on the host machine. gelf Writes log messages to a Graylog Extended Log Format (GELF) endpoint such as Graylog or Logstash. fluentd Writes log messages to fluentd (forward input). The fluentd daemon must be running on the host machine. splunk Writes log messages to splunk using the HTTP Event Collector. logentries Writes log messages to Rapid7 Logentries. 云日志系统 各类云服务商提供的云日志系统 docker logs命令不适用于除json-file和journald之外的其它日志驱动。 日志驱动插件日志驱动插件允许你扩展和定制docker的日志记录功能，超越了内置的日志驱动的功能。 安装日志驱动插件 123docker plugin install &lt;org/image&gt;docker plugin ls 将插件配置为docker daemon默认日志驱动 12345/etc/docker/daemon.josn#or--loggin-driver 将插件配置为容器日志驱动 1docker run xxx --log-driver 定制日志驱动输出Customize log driver output 日志选项tag指定如何格式化表示容器日志消息。默认情况下，系统使用容器ID的前12个字符。你可以指定tag选项来覆盖此行为： 123docker run --log-driver=fluentd \ --log-opt fluentd-address=myhost.local:24224 \ --log-opt tag="mailer" 在指定tag时，Docker支持的一些特殊模板标记： 1234567891011121314151617181920212223242526&#123;&#123;.ID&#125;&#125;The first 12 characters of the container ID&#123;&#123;.FullID&#125;&#125;The full container ID&#123;&#123;.Name&#125;&#125;The container name&#123;&#123;.ImageID&#125;&#125;The first 12 characters of the container’s image ID&#123;&#123;.ImageFullID&#125;&#125;The container’s full image ID&#123;&#123;.ImageName&#125;&#125;The name of the image used by the container&#123;&#123;.DaemonName&#125;&#125;The name of the docker program (docker) 123--log-opt tag=&quot;&#123;&#123;.ImageName&#125;&#125;/&#123;&#123;.Name&#125;&#125;/&#123;&#123;.ID&#125;&#125;&quot;Aug 7 18:33:19 HOSTNAME hello-world/foobar/5790672ab6a0[9103]: Hello from Docker. 日志驱动介绍如下日志驱动！ LogentriesLogentries日志驱动将容器日志发送到Logentries server。 --log-opt: logentries-token: 指定Logentries log设置的token line-only: 仅发送原始有效载荷 docker daemon: 123dockerd --log-driver=logentries#可在docker.service中设置 docker container: 1docker run --log-driver=logentries ... 在使用此日志驱动之前，你需要在Logentries web界面中创建一个新的日志集，并将该日志集的令牌传递给docker： 1docker run --log-driver=logentries --log-opt logentries-token=abcd1234-12ab-34cd-5678-0123456789ab json file默认情况下，docker捕获所有容器的STDOUT和STDERR，并使用json格式将它们写入文件。每个文件包含仅包含一个容器的信息。 123456789101112131415161718/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;10m&quot; &#125;&#125;#ordocker run \ --log-driver json-file --log-opt max-size=10m \ alpine echo hello world#栗子docker run -it --log-opt max-size=10m --log-opt max-file=3 alpine ash json-file支持的日志选项： 选项 描述 栗子 max-size The maximum size of the log before it is rolled. A positive integer plus a modifier representing the unit of measure (k, m, or g). Defaults to -1 (unlimited). —log-opt max-size=10m max-file The maximum number of log files that can be present. If rolling the logs creates excess files, the oldest file is removed. Only effective when max-size is also set. A positive integer. Defaults to 1. —log-opt max-file=3 labels Applies when starting the Docker daemon. A comma-separated list of logging-related labels this daemon accepts. Used for advanced log tag options. —log-opt labels=production_status,geo env Applies when starting the Docker daemon. A comma-separated list of logging-related environment variables this daemon accepts. Used for advanced log tag options. —log-opt env=os,customer env-regex Similar to and compatible with env. A regular expression to match logging-related environment variables. Used for advanced log tag options. —log-opt env-regex=^(os或customer). Graylog Extended Format(gelf)gelf日志驱动是一种方便的格式，可被Graylog, Logstash, Fluentd等工具所理解。许多工具使用这种格式。 在GELF中，每条日志消息都是带有一下字段的字典： version host timestamp short and long version of the message 自定义的字段 12345678910111213141516171819/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;gelf&quot;, &quot;log-opts&quot;: &#123; &quot;gelf-address&quot;: &quot;udp://1.2.3.4:12201&quot; &#125;&#125;#ordockerd --log-driver gelf –-log-opt gelf-address=udp://1.2.3.4:12201#容器docker run \ --log-driver gelf –-log-opt gelf-address=udp://1.2.3.4:12201 \ alpine echo hello world GELF选项： Option Required Description Example gelf-address required GELF服务器地址(tcp/udp) --log-opt gelf-address=udp://192.168.0.42:12201 gelf-compression-type optional 仅限于UDP。类型有gzip(default),zlib,none --log-opt gelf-compression-type=gzip gelf-compression-level optional -1/0 - 9,-1/0(禁用压缩)，1(BestSpeed)，9(BestCompress) --log-opt gelf-compression-level=2 gelf-tcp-max-reconnect optional 仅TCP，连接断开尝试的最大重连次数，默认3 --log-opt gelf-tcp-max-reconnect=3 gelf-tcp-reconnect-delay optinal 仅TCP，重连等待的秒数，默认1s --log-opt gelf-tcp-reconnect-delay=1 tag optional 默认使用Docker容器ID的前12位 --log-opt tag=mailer labels optional 以逗号分隔的日志相关标签 --log-opt labels=production_status,geo env optional 以逗号分隔的日志相关的环境变量 --log-opt env=os,customer evn-regex optional 匹配日志相关环境变量的正则表达式 --log-opt env-regex=^(os l customer) Syslogsyslog日志驱动将日志路由到系统日志服务器。系统日志必须以特定方式格式化才能生效。从有效的消息中，接收者可以提取以下消息： priority日志级别，debug, info, warning, error… timestamp hostname facility记录消息的子系统 process name pid 12345678910111213141516/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;syslog&quot;, &quot;log-opts&quot;: &#123; &quot;syslog-address&quot;: &quot;udp://1.2.3.4:1111&quot; &#125;&#125;#or#syslog-address支持tcp和udpdocker run \ -–log-driver syslog –-log-opt syslog-address=udp://1.2.3.4:1111 \ alpine echo hello world syslog日志驱动选项： 选项 描述 栗子 syslog-address [tcp l udp l tcp+tls]:host:port, unixgram://path, unix://path --log-opt syslog-address=tcp+tls://192.168.1.3:514, --log-opt syslog-address=unix:///tmp/syslog.sock syslog-facility 子系统 --log-opt syslog-facility=daemon syslog-tls-ca-cert CA --log-opt syslog-tls-ca-cert=/etc/ca-certificates/custom/ca.pem syslog-tls-cert TLS certificate --log-opt syslog-tls-key=/etc/ca-certificates/custom/key.pem syslog-tls-skip-verify 跳过tls验证 --log-opt syslog-tls-skip-verify=true tag 如前 如前 syslog-format 日志格式 --log-opt syslog-format=rfc5424micro lables 如前 如前 env 如前 如前 env-regex 如前 如前 ETWETW日志驱动将容器日志转发为ETW事件。每个ETW时间都包含一条日志及其上下文信息的消息，然后客户端可以创建一个ETW监听器来监听这些事件。 Fluentdfluentd日志驱动将容器日志作为结构化日志数据发送到fluentd收集器。接着，用户便可以使用任意一种Fluentd output plugin将这些日志写入不同的目的地。 fluentd发送一下这些元数据： 字段 描述 container_id 完整的64位容器ID container_ame 启动时的容器名 source stdout or stderr log 容器日志 docker logs命令不可用于此日志驱动。 fluentd-address指定fluentd daemon地址 tag 1234567891011121314/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;fluentd&quot;, &quot;log-opts&quot;: &#123; &quot;fluentd-address&quot;: &quot;fluentdhost:24224&quot; &#125;&#125;#ordocker run --log-driver=fluentd --log-opt fluentd-address=fluentdhost:24224docker run --log-driver=fluentd --log-opt fluentd-address=tcp://fluentdhost:24224docker run --log-driver=fluentd --log-opt fluentd-address=unix:///path/to/fluentd.sock Journaldjournald 日志驱动将容器日志发送给 systemd journal。可以通过journalctl命令，journal API，docker logs来检索日志条目。 journald日志驱动还提供如下元数据： CONTAINER_ID CONTAINER_ID_FULL CONTAINER_NAME CONTAINER_TAG CONTAINER_PARTIAL_MESSAGE 123456789/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;journald&quot;&#125;#ordocker run --log-driver=journald ... 几个选项： tag label env env-regex 123456docker run --log-driver=journald \ --log-opt labels=location \ --log-opt env=TEST \ --env &quot;TEST=false&quot; \ --label location=west \ your/application 使用journalctl命令查看日志： 12journalctl CONTAINER_NAME=webserverjournalctl -o json CONTAINER_NAME=webserver 使用journal API： 123456789#pythonimport systemd.journalreader = systemd.journal.Reader()reader.add_match('CONTAINER_NAME=web')for msg in reader: print '&#123;CONTAINER_ID_FULL&#125;: &#123;MESSAGE&#125;'.format(**msg) Splunksplunk日志驱动将容器日志发送到Splunk Enterprise和Splunk Clound的HTTP Event Collector。 安全 CGroup参考: wiki DOCKER基础技术：LINUX CGROUP CGroup 介绍、应用实例及原理描述 linux cgroup 简介 Linux资源管理之cgroups简介 简介CGroup(Linux Control Groups)，是Linux内核的一个功能，用来限制、控制与分离一个进程组群的资源(CPU, Mem, Disk I/O…)。你可以监控你配置的CGroup，拒绝CGroup访问某些资源，甚至在运行的系统中动态配置CGroup。 CGroup的一个设计目标是为不同的应用情况提供统一的结构，从控制单一进程(nice)到操作系统层虚拟化(OpenVZ, Linux-VServer, LXC)。CGroup提供: 资源限制(Resource limitation)：限制资源使用； 优先级(Prioritization)：控制优先级； 结算(Accounting)：用来衡量系统确实把多少资源用到适合的目的上； 控制(Control)：冻结组或检查点和重启动。 使用CGroup，系统管理员可更具体地控制对系统资源的分配、优化顺序、拒绝、管理和监控。可更好地根据任务和用户分配硬件资源，提高总体效率。 核心概念CGroup需要考虑如何抽象进程和资源这两种概念，同时如何组织自己的结构。它有几个非常重要的核心概念: 任务(task)：系统中运行的实体，一般指进程； 子系统(subsystem)：具体的资源控制器，控制某个特定的资源使用； blkio(Block IO)：限制块设备的I/O速率； cpu：限制调度器分配的CPU使用率； cpuacct(CPU Accounting)：生成cgroup中任务使用CPU的报告； cpuset(CPU Set)：为cgroup中的进程分配单独的cpu节点或者内存节点，也就是哪些CPU和MEM上； devices：允许或者拒绝cgroup中任务对设备的访问； freezer：挂起或者恢复cgroup中的任务； hugetlb：主要针对于HugeTLB系统进行限制，这是一个大页文件系统； memory：限制cgroup中任务使用内存的量，并自动生成任务当前内存的使用情况报告； net_cls(Network Classifier)：为cgroup中的报文设置特定的classid标志，这样Linux流量控制(traffic control)程序可对其数据包进行控制； ns(namespace)：可使不同cgroups下面的进程使用不同的 namespace； net_prio(Network Priority)：对每个网络接口设置报文的优先级； perf_event：识别任务的 cgroup 成员，可以用来做性能分析； 控制组(CGroup)：一组任务和子系统的关联关系，表示对这些任务进行怎样的资源管理策略。 层级(hierarchy)：一系列CGroup组成的树形结构。每个节点都是一个CGroup，CGroup可以有多个子节点，子节点默认会继承父节点的属性。 相互关系: 每次在系统中创建新层级时，该系统中的所有任务都是那个层级的默认cgroup(称为根(root))的初始成员； 一个子系统最多只能附加到一个层级； 一个层级可以附加到多个子系统； 一个任务可以是多个CGroup的成员，但是这些CGroup必须在不同的层级； 系统中的进程(任务)创建子进程(任务)时，该子任务自动成为其父进程所在CGroup的程序，也就是继承。 文件系统Linux使用了多种数据结构在内核中实现了CGroup的配置，关联了进程和CGroups节点。CGroup提供了一个CGroup虚拟文件系统(VFS, Virtual File System)，作为进行分组管理和各子系统设置的用户接口。要使用CGroup，必须挂载CGroup文件系统。这时通过挂载选项指定使用哪个子系统。 VFS通用文件模型中包含的四中元数据结构: 超级块对象(superblock object)：用于存放已经注册的文件系统的信息。比如ext2，ext3等这些基础的磁盘文件系统，还有用于读写socket的socket文件系统，以及当前的用于读写cgroups配置信息的 cgroups 文件系统等； 索引节点对象(inode object)：用于存放具体文件的信息。对于一般的磁盘文件系统而言，inode 节点中一般会存放文件在硬盘中的存储块等信息；对于socket文件系统，inode会存放socket的相关属性，而对于cgroups这样的特殊文件系统，inode会存放与 cgroup 节点相关的属性信息。这里面比较重要的一个部分是一个叫做 inode_operations 的结构体，这个结构体定义了在具体文件系统中创建文件，删除文件等的具体实现； 文件对象(file object)：一个文件对象表示进程内打开的一个文件，文件对象是存放在进程的文件描述符表里面的。同样这个文件中比较重要的部分是一个叫 file_operations 的结构体，这个结构体描述了具体的文件系统的读写实现。当进程在某一个文件描述符上调用读写操作时，实际调用的是 file_operations 中定义的方法。 对于普通的磁盘文件系统，file_operations 中定义的就是普通的块设备读写操作；对于socket文件系统，file_operations 中定义的就是 socket 对应的 send/recv 等操作；而对于cgroups这样的特殊文件系统，file_operations中定义的就是操作 cgroup 结构体等具体的实现； 目录项对象(dentry object)：在每个文件系统中，内核在查找某一个路径中的文件时，会为内核路径上的每一个分量都生成一个目录项对象，通过目录项对象能够找到对应的 inode 对象，目录项对象一般会被缓存，从而提高内核查找速度。 CGroup支持的文件类型: 文件 R/W 用途 Release_agent RW 删除分组时执行的命令，这个文件只存在于根分组 Notify_on_release RW 设置是否执行release_agent，为1时执行 Tasks RW 属于分组的线程TID列表 Cgroup.procs R 属于分组的进程PID列表 Cgroup.event_control RW 监视状态变化和分组删除事件的配置文件 Namespace参考: docker 容器基础技术：linux namespace 简介 DOCKER基础技术：LINUX NAMESPACE 介绍Linux Namespace是Linux提供的一种内核级别环境(资源)隔离机制，用来让运行在同一个操作系统上的进程互相不会干扰。 Namespace的目的就是隔离。某个Namespace里面的进程就只能看到该Namespace的信息，无法看到该Namespace之外的信息，无法看到其它Namespace里面的信息。各个Namespace中的进程根本感觉不到对方的存在。 Linux内核提供的Namespace: Namespace clone()使用的flag 隔离的资源 CGroup CLONE_NEWCGROUP CGroup根目录 IPC CLONE_NEWIPC System V IPC，POSIX 消息队列 Network CLONE_NEWNET 网络设备、协议栈、端口等 Mount CLONE_NEWNS 挂载点 PID CLONE_NEWPID 进程 ID User CLONE_NEWUSER 用户和组 ID UTS CLONE_NEWUTS 主机名和域名 主要是三个子系统调用: clone()：实现线程的系统调用，用来创建一个新的进程，并可以通过设计上述参数达到隔离。 unshare()：使某进程脱离某个namespace setns()：把某进程加入到某个namespace 每个进程都有一个/proc/${pid}/ns目录，里面保存了该进程所在对应Namespace的链接。 12345678sudo ls -l /proc/8734/nstotal 0lrwxrwxrwx. 1 root root 0 4月 24 10:49 ipc -&gt; ipc:[4026531839]lrwxrwxrwx. 1 root root 0 4月 24 10:49 mnt -&gt; mnt:[4026531840]lrwxrwxrwx. 1 root root 0 4月 24 10:49 net -&gt; net:[4026531956]lrwxrwxrwx. 1 root root 0 4月 24 10:49 pid -&gt; pid:[4026531836]lrwxrwxrwx. 1 root root 0 4月 24 10:49 user -&gt; user:[4026531837]lrwxrwxrwx. 1 root root 0 4月 24 10:49 uts -&gt; uts:[4026531838] 每个文件对应于Namespace的文件描述符，方括号里的值是Namespace的inode。如果两个进程所在的Namespace一样，那么它们列出来的inode也是一样的。 inode是指在许多Unix-Like系统中的一种数据结构。每个inode保存了文件系统中的一个文件系统对象（包括文件、目录、设备文件、socket、管道, 等等）的元信息数据，但不包括数据内容或者文件名。inode这个命名的来源可能是文件系统的存储组织为一个扁平数组，分层目录信息使用一个数作为文件系统这个扁平数组的索引值（index）。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《网站运维》读书笔记]]></title>
    <url>%2F2018%2F03%2F05%2F%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4%2F</url>
    <content type="text"><![CDATA[参考： 《网站运维：保持数据实时的秘籍》(Web Operations: Keeping the Data on Time) 作为职业的运维互联网变化如此之快，以至于几乎没有时间认真思考一下我们在做什么，以及为什么做。我们奋力拼搏，才避免被淘汰出局，哪里还敢谈论什么引领潮流呢！这种高压、过度刺激的环境使得所有努力都只是为了一份工作，而没有职业的概念了。 职业是指占去你人生大部分时光的事业，并能够逐步晋升。工作只是拿钱干活儿，换句话说，工作就只是工作而已。 为什么运维如此艰难运维对如下领域都有深入的理解：网络、路由、交换、防火墙、负载均衡、高可用性、灾难恢复、TCP与UDP服务、网络运维中心管理、硬件规范、各种Unix、各种Web服务器技术、高速缓存技术、数据库技术、存储基础架构、密码学、算法、趋势分析、容量规划… 运维要求广博，可以说几乎是不可接受的。 运维领域成为一个合格的人选，需要具备三点素质：扎实的计算背景、娴熟的决断力、沉稳的性格。 扎实的计算背景运维要求理解架构中的各个组成部分，在理解计算系统的来龙去脉时，扎实的计算背景对你会有莫大的帮助。具有扎实的基础，对于理解为什么及如何架构解决方案，以及识别出问题所在，是非常重要的。毕竟，计算是架构我们的智能系统的基础。此外，工程师的思维方式和对物理定律的基本理解，也是一个很大的优势。 运维会经常遇到随意的、不切实际的期望。运维，就是理解理论和实践在哪里发生冲突，并发明适当的方法，以便在发生事故时减少损失。 娴熟的决断力虽然优柔寡断在任何领域都不算是一个优点，但在运维中却几乎不能容忍。 沉稳的性格一个沉稳与可控的思维过程是非常关键的，需要保持自己是清醒的一方。 在运维领域，目标很简单，使所有事情在所有时间正常运转。一个简单的定义，但却是一个不可能的期望。或许在这个领域成为一名工程师的更大挑战是组织内的同事对你的不切实际的期望。 从学徒到师傅掌握任何知识领域都需要四项基本要求：知识、工具、经验和纪律。 知识互联网行业的一个独特之处就是几乎所有的东西都是公开的，事实上，有专有权的东西也是极少的，而更为独特的是，几乎所有规范文档都是免费的。 在你走在从从学徒到师傅的路途中，尽可能多滴占有信息是你的职责，这样你的大脑才能将那些细微之处进行排序、过滤、关联，使其成为一幅简明、精确的图画，从而有助于你的决策——不管是长期的架构设计的关键决策，还是临时的排除故障的决策。 工具虽然工具各有优缺点，然而人们使用这些工具都取得了成功。制造和使用工具使我们人类的本性。所有的工具归根结底都只是人类肢体和感觉器官的延长。 师傅不适用工具炼成的。在互联网应用的环境中，你会看得更清楚，五花八门的语言、平台、技术都能够成功地结合在一起，将这些成功地构建为一个架构的，不是Java或PHP，而是设计与实现它的工程师——那些师傅们。 工具上的一个真理是，不管在用的工具是什么，要了解你的工具，这是在这个行业登堂入室的前提。灵巧地运用工具的能力，比工具本身的质量要重要的多。话虽如此，有经验的工程师还是应该手边备一件合适的高质量的工具。 经验从最本质的意义上来说，经验意味着良好的判断力，而良好的判断力却是从很多失败中取得的。 经验与知识是紧密相关的，知识可以认为是他人经验的总结。经验既是一个名词，也是一个动词。获得经验与应用经验，同样容易也同样困难。 一名资深工程师最大的特点是其一致与可靠的良好判断力。很显然，这要在需要做出判断的场合经受锻炼。 对进入运维这个领域而没有什么经验的工程师，我的忠告是：耐心。 纪律通过尽可能正确而高效地做事，从而为解决同样问题，而尽可能地少做工作。 如何应用云计算(Elastic Compute)云服务器(ECS, Elastic Compute Service) 什么地方适合云计算灵活性和一定程度上的自由是云服务器的特点，当然，本地服务器同样有这个特点。 混合计算混合计算=云计算+本地计算 什么地方不适合云计算当然，最先考虑的肯定是经济层面。 服务层与数据库是紧密耦合的，所以使它们之间的网络延迟最小化是很重要的。这意味着它们要么全在云里，要么全在云外。 结语尽管有大量广告吹嘘完整托管在云里，但从运维角度来说，混合应用架构模式或许是最有趣的。有些事情在云里做的不一定好。脚踏两只船，你才会游刃有余。 混合应用还强调一点，就是传统运维中的最佳时间仍然是成功的公司的云应用所必须的。 基础架构与应用程序测量任何规模的运维，采集测量数据就像将服务器连接到网络上一样重要，对于一个规模不断增长的基础架构来说，或许更加重要。 我们不光讨论你要采集并监视的测量数据的种类，还要讨论为了应对各种情况，你能利用这些数据做些什么。 测量数据的采集和带有报警(alerting)功能的监控有明显的区别。 时间刷新率和存留时间的考虑随着采集的数据不断增长，确保这些数据能够一直可查询和移动，这是很明智的。 如Zabbix中——获取数据的时间刷新率和数据保存时间。历史数据保留时长和趋势数据存储时间。比如有的数据要30s获取一次，而有的信息只需要1h获取一次。 测量数据真正出彩的地方： 对于某个特定的资源，每天的峰值是哪些？每周的峰值日是哪些？每年的峰值月是哪些？ 有季节性模式吗？ 如夏时日和节假日会高一些 最大(波峰)值与最小(波谷)值比较起来怎么样？ 在用户分布广泛的情况下，波峰与波谷是否发生变化？ 测量数据采集与存储的地点无论使用什么采集工具，易于采集和便于得出结果都是必须要考虑的。 测量数据的层次不同层次的数据存储在不同的数据库中。 高层业务或功能特定的测量数据有了这些高层数据之后，面向产品的那些人对这些数据也抱有极大的兴趣，你一点都不用感到惊讶。 对于应用层面的数据，最有用的是能够跟踪用户的交互情况。 系统及服务层面的测量数据这些是在运维工程师电脑上以图形方式显示的数据。 测量数据的层次： - 例子 测量项目 应用层 网页或API 故障：类型、延迟、发生率… 服务层 Nginx, MySQL, MongoDB… Nginx: 请求频率、响应时间、忙碌的工作进程… MySQL/MongoDB：导致故障的查询类型、慢查询、连接数… 物理层 CPU、内存、网络、硬盘 内存：繁忙程度 内存：空闲内存 硬盘：可用空间，I/O速率 网络：网络I/O带宽情况 有了这些数据，就能够回答如下问题： 平均的Web请求时间 CPU时间 调用最多的数据库查询 数据库慢查询 文件系统缓存 最大的页面响应 … 为异常检测和报警提供环境在本地采集的测量数据的主要理由，就像油表一样，有了这些数据，就可以明白基础架构正在发生什么，以及正在驶向何方。知道哪里的资源在增长或缩减，能够进行预测。使用预测对基础架构的容量需求进行预报，称为容量规划。观察网站运行是否有异常时，测量数据就派上用场了。 发生异常是，测量数据回味报警提供相关信息。报警的信息要尽量简明，告知检测到了什么，以及何时检测到。而测量数据会告诉你报警都发生了什么。 日志记录也是测量数据应用程序的日志文件也提供了测量数据和使用情况的信息。这些信息用于追踪过去发生的事件。 将变化管理和事件的时间线建立关联更新生产系统会带来风险。记录更新发生的时间，从而保留更新的踪迹，这在发生问题需要进行追踪时是非常有价值的。 给测量数据加入报警机制Zabbix、Nagios等就是一个测量数据采集系统配合使用的监控/报警工具。 使用测量数据建立加载-反馈机制采集时序数据的另一个好处，就是能够通过编程使你的应用生成测量数据，从而可以建立安全、精密的反馈循环。 结语测量数据的采集、存储、显示，可以认为是web基础架构的关键部分。不论是及时排查错误，预测容量、规划产品的发布，还是建立应用的反馈机制，如果没有正确的测量数据为你提供一个基础架构运行的全景图的话，你会损失惨重。 设计数据如何经过系统时，要考虑安全问题，而且数据要易于导出到其它应用。一旦运维部门采集了测量数据，你会发现，追踪数据是一件多么有趣的事情，同时也能使工作更加轻松。 连续部署软件应该以小批量的方式进行设计、编写和部署。 批量大小是产品在开发过程的各个阶段转移的单位。对于软件而言，最容易看到的批量是代码。每次工程师检入代码，都是在提交一定量的工作。有很多技术用来控制这些批量，从连续部署所需的最小批量到更为传统的分支开发，在分支开发中，多个开发者工作数周或数月产生的所有代码将被成批处理，并集中到一起。 结果证明，以远小于传统做法的建议的批量工作，有极大的好处。 小批量意味着更快的反馈工作转移到下一阶段越快，则也就能越快地发现下一个阶段是如何接纳你的工作的。 小批量意味着问题即刻被本地化问题发现得越快，则解决的也越快。 每次部署，都只有少量代码有变化，所以导致回归或料想不到的性能问题的任何变化，都能够快速识别出来，并进行改正。当然，由于需要改正或回滚的变化数量不仅是确定的，也是很小的，所以解决问题的平均时间也就很低了。 小批量能够减少风险 小批量可以降低总开销大多数机构都会降低自己的批量大小，以降低总的开销。大批量导致的瓶颈经常是隐含的，是这些隐含的瓶颈显现出来，是需要开销的，甚至要投入更多的工作才能修正这些瓶颈。 连续部署的目标，是在减小批量的同时，帮助开发团队清除开发过程中的垃圾，加快工作步伐。这样就能使各个团队处于持续的流动状态，这种状态使得团队的创新、试验变得非常容易，从而形成可持续发展的良性循环。 质量卫士的挽歌产生开发过程中的垃圾的一个很大原因是重复检查。 连续集成，有助于加快缺陷反馈流程；故事卡和看板，用于降低批量大小；日站，有助于加快步伐；连续部署也是这样的技术，有能力是开发团队更有活力。 为什么连续部署能行连续部署区分了发布的两种不同的定义： 一个是工程师使用的，指的是将代码完全集成到生产环境中的过程； 另一个是市场部门使用的，指的是客户看到的东西 使用连续部署，代码一旦写完，就在去往生产环境的路上了。连续部署也起着速度调节器的作用。 这种速度调节，对于习惯于通过个体效率来度量其进步的团队来说，是一种技巧性的调整。在这种团队中，每个工程师的头等大事就是保持忙碌。不幸的是，这种观点忽略了团队的整体生产能力。对于有些情形，大家坐下来讨论，找出协调方法，从而不需要做重复工作，这时候才是有效率的。 让我们开始吧步骤1：连续集成服务器这是连续部署的脊梁。我们需要一个中心服务器，运行所有的自动化测试，并监控每一次的提交。 步骤2：源代码控制提交检查下一个需要的基础框架是源代码控制服务器，并带有能进行提交检查的甲苯。如CVS、SVN、Git等。 作为一个团队，我们的目标是在能够可靠地生产高质量代码的前提下，尽可能快地工作，但不要过快。 步骤3：简单的部署脚本建立一个关键的部署脚本，用于逐台机器进行增量备份，与此同时，监控集群和业务的运行情况。这样一旦出现异常，就可以快速恢复。 步骤4：实时报警无论部署过程多么完美，缺陷仍然会通过部署而进入生产环境。需要一个监控平台，以便事情一旦偏离正常，能够进行提醒，并找到人来调试。 步骤5：根本原因分析无论问题多小，都要做些投资，而且各个级别都要做。小的改进，经过经年累月，非常像复利。 连续部署用于关键应用连续部署要求的第一个心态转移是：如果一个更新假设是无副作用的，马上发布。不要再等着与其它相关的更新捆绑在一起，否则，一旦发生副作用，就很难确定到底是哪个更新产生的。 第二个是心态转移是把市场发布的概念和工程发布的概念区分开。 更快更好的反馈 更多的自动化 对真实环境测量数据的监控 更好地处理间歇性错误 更小的批量 作为代码的基础架构只需要源代码库、应用程序数据备份、硬件裸机就能够把整个业务重建起来。 理想情况下，重组业务的最大制约是还原应用程序数据所需要的时间，应用程序数据是真正的业务价值所在。 面向服务体系结构将系统的每个组件都分解为可通过网络访问的服务，这些服务集成在一起就构成了一个功能性应用程序。 通过将每个基本组件都呈现为服务、应用开发者可自由组装的新的应用，结果就是重用更为容易、封装更为清洁、错误排查更为简单。 应该是模块化的 做一件事，并且做好在SOA中，每个服务都很小——只做一件事，并允许其它服务调用。每个服务都很简单，但应用程序员要做很多集成工作。每个服务都专注于自己的狭小领域，则管理、开发、测试都会很容易。基础架构服务也是一样的，缩小每个服务的操作范围，就可以降低复杂性，从而他人也就易于理解其行为。 应该是协作的 让我们团结起来在构建通过网络API呈现的基本服务时，要鼓励别人和你协作，而不是重复实现相同的功能。每个服务都要设计成与其它服务协作的，尽量少假设服务的使用方式。服务的协作本性决定了用的人越多，则服务本身就越有用。对于基础架构服务而言，这种本性是至关重要的——随着基础架构的每个部分都成为可集成的服务，服务之间相互协作的方式会呈指数增长。 应该是可组合的 应该一切准备就绪理想情况下，每个服务都应该通过易于访问的网络API呈现自己的配置和功能，实际情况是：大部分都没有。 配置管理配置管理是一种管理活动，从技术和管理两个方面作用于产品和生命周期、配置项，以及相关的产品配置信息。 配置管理是指对所有那些事情的跟踪，那些事情是把一个系统从裸机(baremetal)转变成做自己的事时必须要做的。系统管理员手工配置系统，并将笔记贴到wiki上时，他就是在实践着最基本的配置管理。软件开发者写了一个脚本来自动部署自己的应用程序，她就是在实践着自动化的配置管理。 配置管理是策略驱动的 把问题和解决方案的最终结果记入文档(设立策略)； 写出在策略中要执行的代码(执行策略)； 确认最终结果是正确的(审计策略)； 重复这个过程，确保以后呢能够可靠的执行(测试策略) 系统自动化就是用代码实现配置管理策略自动化几乎总是使用高级语言，自动化方式展现了三个原则： 应该是灵活的 无论需要什么，都应该有能力做 应该是可扩展的 遇到新情况时，要易于扩展 应该是可重复的 不管重复做了多少次，结果都一样 系统管理中的配置管理配置管理工具应该有如下思想： 描述的 说明做什么，而不是怎么做 抽象的 让工具为你操心细节 幂等的 旨在需要时才采取行动 聚合的 只关心自己，并信赖其他服务亦然 系统集成系统集成是指将各个组件整合为一个功能正常的、完全自动化的系统。系统集成侧重于广度，能否成功则依赖于对两个方面的理解： 系统中的每个组件是如何工作的 这些组件是如何相关的 应该遵循这两个步骤将基础架构构建为代码，这两个恰好也是系统集成阶段使用的步骤。系统集成就是将所有的东西整合在一起。 将基础架构分解为可重用的，可通过网络访问的服务 良好基础架构的十大核心原则： 应该是模块化的 启动过程将只处理这样的任务：使资源成为网络可访问 应该是协作的 启动服务应该能够将启动后的工作传给其他服务 应该是可组合的 能够从不同的服务中调用启动服务 应该是灵活的 足够灵活以应付不同类型的物理系统 应该是可扩展的 易于扩展，义启动新的资源类型 应该是可重复的 每次启动，都要生产相同的系统 应该是描述的 应该描述需要的系统类型，而不是如何安装和构建这些系统的细节 应该是抽象的 应该隐藏底层机制 应该是幂等的 应该是聚合的 应该尽快将每个系统都启动起来，并为随后的操作系统做好准备，而不用担心其他系统的状态 将服务集成在一起 现在，你已经创建了一个如何引导和配置系统的策略，你知道接收标准是什么、能够列出实现步骤、能够对策略进行测试。这种做系统集成的方式类似于做一个多层蛋糕：每一层都建立在前一层的美味基础上，使得整个蛋糕更为诱人。 监控我以前假定服务器资源是无限的，实际情况却是服务器正在为获得必要的内存而努力挣扎着。操作系统开始进行交换，CPU开始过载，从而响应时间开始变糟。 技术人员的观点和最终用户/业务的观点并不一致。 监控并不是设置一个系统，它是用来支持业务运转的，是用来保证系统中各个部分都在各司其职地工作着。能够正常工作也可以表述为保持网站的可用性。 可用性(A)可表述为：A = Uptime/(Uptime + Downtime) 网站可用性受如下4个参数的影响： MTTD(平均故障诊断时间) 诊断该问题所花费的平均时间 MTTR(平均修复时间) 用于修复问题所花费的平均时间 MTTF(平均无故障时间) 正常运行的平均时间 MTBF(平均故障间隔时间) 两次故障间隔的平均时间 A = MTTF/MTBF = MTTF/(MTTF+MTTD+MTTR) 并不是说你的业务需要接近90%或更高的可用性，业务要求的可能性只是一种期望值，如果宕机发生在周末，即使发生在工作日，只要还能工作，用户也不会说什么。你的目标是应该通过降低MTTD和MTTR，以及增加MTTF来增加可用性。 理解你在监控什么技术组件的依赖项： 组件 依赖关系 应用程序 应用程序服务器、Web服务器、邮件服务器、缓存服务器、队列服务器 Mail服务器 Mail服务进程、网络、主机、存储 DNS服务器 DNS服务进程、网络、主机、存储 应用程序服务 应用程序服务进程、网络、主机、存储 Web服务器 Web服务器进程、网络、主机、存储 数据库 数据库服务进程、网络、主机、存储 主机 设备、OS设备进程 网络 设备、网络设备进程 存储 设备、磁盘、RAID控制器、接口 通用设备 磁盘、内存、CPU、接口、房屋 房屋 UPS、电源、温度 依赖项常常不受你控制，相反，它是由公司内不同的组管理的。从你自己的筒子里走出来，到其他部门获取相关信息，并不是很容易。正是因为你依赖于他们，所以更好地理解他们的就很关键了。这样你就不用在讯早问题的原因上浪费时间，在用户访问服务所依赖的那些组件上也就不会存在盲点。 不同部门之间的边界： 企业部门 依赖项 支援部门 能影响浏览器、桌面设置、防病毒/间谍软件 开发组 专注于应用程序更新 中间件组 经常运行数据库、Web服务器、应用程序服务器、邮件服务器、缓存服务器队列服务器 系统组 操作系统、DNS、DHCP、虚拟化、集群 网络组 交换机、路由器、VPN、代理服务器 存储组 SAN、NAS、备份、恢复 数据中心组 电缆、电力、UPS 安全小组 防火墙、安全策略 这样划分责任，在不清楚问题的真正原因时，会显著增加修复问题的时间。大量精力会花在努力证明自己部门的清白上面，从而延长了解决问题的时间。这份额外时间称为平均清白时间(Mean Time to Innocence)。为了减少这种相互推诿的时间，良好的合作与协调很重要。持续的知识共享有助于增加这种共同应对问题的责任感。 组织边界到防火墙哪里就停止了，但Internet服务比内部控制的服务有更多的依赖项，这些外部依赖项有ISP、广告商、RSS信息、Internet邮件、DNS服务器、ISP连接等，内部依赖项和外部依赖项的主要区别在于，对于外部依赖项，你不知道这些服务是如何提供的。即使如此，也不能在监控这些服务上止步不前，毕竟它们仍然是你的服务的依赖项。 在无冗余的系统中，一个组件失效，整个服务就会失效。当一个组件的失效会影响整个服务时，这种失效就称为单点故障。这种影响既指服务完全中断，也指对服务质量的影响。为了避免单点故障，通常是在架构中的多个位置增加冗余，这些冗余是你的环境的安全卫士，而不是对问题的某种补偿方式。通常，增加冗余会增加复杂性，所以不要掉进过度设计的陷阱。 一些冗余机制： 服务/组件 冗余机制 应用程序 负载均衡器、状态复制 Mail服务器 一个域名多条MX记录 DNS服务器 一个域名多条NS记录 应用程序服务器 会话复制、多实例安装 Web服务器 Web服务器服务进程 数据库 集群服务、水平区分 主机 虚拟化、集群 网络 多网关、BGP、VRRP、多ISP 存储 RAID、镜像、多重路径技术 通用设备 多网卡、CPU、内存 数据中心 BGP任播、GSLB 不要忘了检查监控服务的依赖项，如果监控都挂了，那还监控什么呢。 各种检查： 检查种类 例子 可用性 能访问80端口吗？HTTP进程在运行吗？数据库能访问吗？ 功能/既时 应用程序在请求数据库，OS在进行DNS查询，控制器在进行磁盘写入，负载均衡器在请求Web服务器 功能/模拟 模拟HTTP请求、DNS请求、发送邮件 质量/利用 CPU、内存、磁盘等硬件信息使用情况，可以知道机器是否有足够的处理能力 质量/效率 Squid缓存命中率 质量/吞吐 订阅数、登录数、请求数、进/出请求数，用户数，数据库连接数，活动连接数，实例数 环境 配置监控，安全监控，备份监控 可信性 邮件域的垃圾邮件防范级别，SSL证书 不同层级的检查： 层级 例子 业务 内部网管理站点 交易 登录、增加文档、分享链接、注销 服务 Mail、DNS、Web服务器、数据库、路由、防火墙 机器 服务器、CPU、内存、交换机 理解正常行为即使你了解所有依赖项，但设计一个好的监控解决方案仍是要花时间的。需要根据业务实际需求和变化对监控实施改变。 一些监控中的主要问题：如果多次报警基于同一个原因，应该只发送一次报警；夜间，备份可能会在生产网络上产生很高的负载，这样由于响应时间的变慢而导致多个ping失败和其它可能的误报，从而产生起起伏伏的报警；如果我们想要随时待命的支持人员，必须尽可能降低报警和误报的次数。 加入的检查越多，消耗的生产系统的资源也就越多，这些资源可以是传送数据的带宽、计算结果的CPU…你需要找到正确的平衡：监控太多只会浪费资源，从而降低对整个状况的了解；监控不足将导致不能及时报警。越靠近业务层的检查越有机会检测出问题，而越底层的检查越能够对发生的问题进行定位。 监控被认为是运维环境的一部分，通常是由系统或网络管理员来管理的。开始时是一个很小的系统，在后台运行。随着监控环境的扩大，需要执行更多的配置和定制。虽然运维人员常常是第一个对要部署的新软件进行仔细检查的人，他们的标准却往往并不应用到自己的监控系统上。监控系统是你的关键应用之一，请一视同仁。 监控的最佳实践： 实践 说明 版本 对你的检查进行版本华，并把他们放入版本控制库中 不同环境 使用不同环境开发、测试新的检查 测试 将检查作为通常代码对待，在代码功能中加入测试 可使用性 创建一个所有组件及其关系的可视化总览图，指出失效和组件的关系对工程师很有帮助，只需要看一下仪表板就能明白问题出在哪里 信息架构 使用不同的数据表示法，将数据组织为层次结构以便于导航，同时还要避免信息过载 代码重用 如果能够重用所监控的应用程序中的业务逻辑，就不要自己写 无硬编码 避免将参数编码在脚本中，使用配置文件，这也易于脚本在不同环境中的迁移 部署 要易于部署和分发新的检查 备份/还原 备份监控数据，并了解在什么情况下需要还原 监控 监控你的监控系统 冗余 在监控上，使用高可用性的功能做维护工作 应用的安全规则 监控账号与其它事务账号分开 是用最小特权级 不要将密码保存为明文 限制对系统的访问，不要将其用于其它的测试 将监控系统用防火墙或代理系统保护起来，避免来自易受攻击的主机的访问 所有信息一旦采集和存储，接下来做的就是分析检查结果。服务或系统的状态有可用(Up)和不可用(Down)，某些监控系统还增加了两个状态，一个用于系统不可达(Unreachable)，一个用于系统/服务尚未检查(Pending)。 有的时候，在位新服务建立环境时，预先定义的阈值很困难——实际使用可能会超过预期，或者相反。所以，对阈值进行不断的调优就有意义了。先根据理论上的假设定义一组阈值，然后在测试环境中模拟预期的行为，并翻译为技术化的组件使用情况。因为系统及使用情况的复杂性，对系统、应用程序、用户行为建立精确的模型是很困难的。所以，对阈值只能持续不断地研究与改进。趋势分析确实有助于定义阈值，大部分监控软件都可以让你对监控的值做趋势分析，而不产生报警，根据历史数据得出阈值之后，再启动报警设置。 管理报警并不仅仅是状态变化时发出报警信息。所有报警如果一直打开着的话，工程师将无法安心做系统支持，因为报警信息太多了，可能要被报警轰炸。同样，如果有太多假设报警，也会导致同样的问题，这可以看成是你的监控系统存在技术缺陷。警报应该产生行动。如果一条警报可以忽略或不需要人工干预，这条报警就是一种浪费。然而，消除噪音却是真正的挑战。警报太多会导致狼来了效应，由于警报过载而忽略了正在重要的警报。 为了使网站可以忍受而限制报警是好的，但假如与业务需求不一致的话，就不行了。反之也是对的，如果业务不需要的话，为了显示网站运行正常而发送很多报警信息，也是毫无意义的。使监控保持正确的平衡，这很重要。 有备而学一个人不可能在每个方面都是专家，有一个清晰定义的升级路径，从而把问题提交给更为专业的人员去处理是明智的。对紧急报警进行跟踪和趋势分析，有助于提出架构和过程的改进建议。 故障时间本身并不仅仅有功能失效引起的，也可能是由于维护活动产生的。维护活动产生的故障时间被描述为维护窗口。在这种情况下，业务部门是认可默写故障时间的。为了避免不必要的报警，监控系统可能会在这段时间关闭报警。这会导致丢失一些与此次维护无关的系统/服务故障。所以，应该只关掉与维护相关的报警，而不是整个报警系统。然后，一旦服务运行稳定了，就要打开报警。 结语监控并不是要保持服务器运行正常，也要保持业务运行正常。理解了技术组件和业务行为，你就会有相当的把握减少和修复问题上的时间。错误总是会发生的，但要为此做好准备。万一系统失效，一定要将反馈信息发送给每一个希望听到的人，并对事情做出改进，避免再发生新的错误。愿监控的力量与你同在。 复杂系统是如何失败的所有复杂系统失败时，都有共同点。Web运维就是这样一个领域。 复杂系统是如何失效的 复杂系统本质上都是灾难系统 复杂系统都被重重地然而也是成功地防护着 灾难要求多点失效——单点失效是不够的 复杂系统包含潜藏在其中的缺陷的变化混合物 复杂系统以降级模式运行 灾难随时会发生 事后归结为”根本原因“是错误的 幕后认识对人类行为的时候评估存在偏见 人类操作员有双重角色：作为生产者，以及作为失效防护者 所有操作者的行为都是赌博 最为困难的行动解决了所有的模糊性 人类操作者是复杂系统的可调整因素 复杂系统中人类专门处理知识处于不断变化中 变化会引入新的失效 “原因”观点限制了对未来事件的有效防护 安全是系统的特性，而不是系统的组件 持续创造安全的是人 无事故的运维需要经历事故的历练 针对Web运维而言： 了解系统失效很困难 了解哪部分失效很困难 有意义的响应会被延迟 沟通会产生紧张，而脾气会冒火 维护会成为新的失效的主要源头 从备份中恢复本身就很困难，而且还有潜在的危险 创建测试过程，一线人员用来验证系统状态 对运维进行例行的每日管理 控制维护 定期对性能进行评估 要成为(独一无二)的用户 社区管理与Web运维运行一个大型且广为人知的网站，意味着会有大批人依赖于网站快速而稳定的服务。这些人会形成一个社区，以各种有趣新颖的方式进行交流，并彼此关照。 社区起着一个交流、沟通、反馈的渠道作用。 处理非预期的访问量激增有些时候，因为某种原因，Web的访问量会急剧增加(是正常用户访问而不是遭受攻击)，我们的服务器就会遭受严重的考验。 一切是如何开始的开能由于某个原因，导致Web流量激增，而我们服务器却无法应付这么高的并发和流量，所以导致Web瘫痪。 警报连连监控软件(如nagios, zabbix)警报连连。Web请求太多导致响应很慢或奔溃。 扑灭烈火查找是哪些环节导致Web响应很慢或奔溃，对之做相应的优化。 未雨绸缪当我们经历了非预期的流量激增，并处理优化之后，下一步就需要对整个基础架构进行加固，或转向新的架构。 救命稻草CDN解决带宽问题要靠内容分发网络(CDN)——在多个地点存储文件，为客户提供最近最快的响应。大部分静态资源适合移动到CDN上，以减轻原始服务器的负担。 但CDN也有一些不足。对于移动到CDN上的数据，你就失去了控制。对于短时间的静态内容，CDN的效果并不好。 代理服务器代理服务器处于我们系统的最前沿，尽可能让代理服务器转发请求，而不使用任何其它资源。 围剿踩踏如何避免缓存踩踏？ 一个是对数据库进行优化 一个是搭建数据库集群 将代码基流水化 怎么知道它能否工作确保系统能够处理负载的唯一途径是在流量汹涌而来时，对其进行现场测试。 真实测试必须要在真实的生产环境中查看其负载效果，才能确保其能正常工作。 教训总要为未来几年做一个规划——问问你自己：“当前的架构方案能够用于未来几年吗？” 要测试生产环境，经过适当的测试规划，很多问题是可以避免的。 当一个架构方案已经明显不能工作的时候，必须要有重新考虑整个方案的勇气。重新思考代码、硬件、网络、数据库模式，为可见的未来创建一个伸缩性更好的系统。 改进针对遭受的问题，之后对系统的改进。 开发者与运维者的协调与合作很多网站都将其开发和运维分为两个独立的团队，开发负责开发新功能和对现有功能进行改进，运维负责网站的正常运行。两个团队有不同的目标，工作方式的要求也是迥然有别。 这种设置很常见，但也是保证网站稳定性或及时推出新功能的最糟糕的设置。 这在种情形下，开发人员没有动力将网站做得更易于运维支持，开发团队交付的代码通常是一个黑盒子，一旦发生意外，运维团队没有办法及时去修复问题。这种结构也抑制了新的功能的开发、构建和部署网站的新版本，不仅耗时，成本高，还涉及很多不同团队之间的协调。对运维来说，部署是存在风险的，而且也是造成很多宕机事故的原因。 传统的运维和开发，两者之间存在着很多对彼此很有用的信息。对很多网站来说，性能瓶颈都出在应用程序代码上：开发团队最适合修正这些问题，但运维团队有测量数据，要想找出问题出在哪，是需要这些数据的。关于什么地方可能会出问题，以及如何修复，开发团队有很多很好的想法，但这些却很少会记录在文档里面。 所以，重新评估运维跟开发之间的关系！ 部署以合适的方式进行移交，则不同团队之间就能更好地共同工作，而改变过程这是困难的，需要协助以及每个人的认可。 一项服务之所以受人欢迎，频繁部署也是重要原因之一。小批量代码更新。 用户报告问题后，极短时间内就得到修复，这一做法会彻底征服用户。有了这种响应凡是，则将来有了问题，用户也会很乐意报告给你，这样产品就会越做越好，特别是你能够一直这样快速反应的话。对关键的数据损失或安全缺陷能够在短时间内而不是几周响应的话，用户的数据就会安全得多。 然而最重要的是，频繁部署并不比周部署或月部署风险更大。很多小的更新，每个都单独测试和检查过，比起一次大的更新来说，导致严重宕机的事故的可能性要小很多。 这是因为小更新的影响能够提前单独进行复审和测试，从而错误造成的影响也易于量化及应对。定位代码中的缺陷，复审10行的更新比起10000行来，会容易得多，而且只测试那些受更新影响的功能，比起测试整个系统，也要快得多。而且能够确保每次部署都只是更新一个区域，从而避免同时更新的两个组件之间发生预料不到的交互作用。小部署意味着更容易预言更新对基础架构的影响，而这也就意味着未雨绸缪更加有的放矢。 如果只是部署30行代码，缺陷通常是自明的。如果缺陷不自明，其影响也会非常小，即使回滚也非常容易。 只有在遵循以下三条规则的情形下，频繁的小更新才起作用： 构建与部署系统必须能够完全重复且自动地工作 具有几近完美的预演环境 部署必须尽可能快，理想情况是小于5min 大多数构建和部署系统在某种程度上都是自动化的，少数团队走得更远，把构建和部署做成了一键操作。 共享、开放的基础架构很多情形下，运维和工程都分为不同的小组，你会发现支持的基础架构也会一分为二。 共享基础架构是在团队之间进行协作的最容易的方式。 为了有效地工作，你需要了解系统的其它方面目前是如何运转的。为了建立信任，你需要使你的工作变得透明。 信任信任是开发和运维之间最常见的紧张关系之一。多数运维团队对开发团队多少都有点怀疑，开发人员通常也好不到哪去。团队之间的不信任是不健康的，也是不合适的。 信任最终是建立在一种尊敬的感觉之上的。如果你尊敬某人，就很容易信任此人能够做好他的事情。反之，如此人交往便会带有偏见、不满等情绪。 运维和开发之间的许多问题都是由于对两个团队不同角色的重要性认识不同而造成的。 充分尊重你的同事，而不是事后指责他们。 随叫随到的开发人员只有在开发人员对修正生产系统代码中的问题肩负起责任的情况下，才是有意义的，而这就意味着开发人员随叫随到。 现场调试工具很多代码对于运维团队来说都是黑盒子。 要想办法在运行时调用额外的调试信息，技术团队的每个人在用管理账号登录系统之后，都可以开启额外的调试信息。 功能标识禁掉某些依赖于问题架构的功能，而保持网站的其他部分正常运行，功能标识能够实现这一点。 单个标识，用来禁掉每个非核心的基础架构 只要这些服务出现问题，我们都可以暂时并优雅地禁止掉这些功能 如果生产系统出现新的错误场景，也可增加新的标识 避免职责在很多团队中，没有人愿意成为搞坏所有事情的傻瓜。发生问题时，人们都会将责任推卸给别人。 每个人都有貌似合理的理由将指责转嫁给别人，却没有挺身而出，实实在在地修复问题，组织良好的团队深切地了解，在将问题修复之前，争论到底是谁的责任是没有意义的，为保护自己而浪费的每一分钟，由于问题没有修复，都会成为给用户带来损失的一分钟。用户会尝试各种可能性，知道他们发现系统出问题了。 多数生产环境都有足够的冗余，也足够复杂，任何问题都不太可能存在单一的根本问题。很多问题都是由两个或多个系统发生意料之外的交互作用而引起的。 结语网站的稳定性是每一个人的责任，而不仅仅是某种应该交给运维团队去处理的东西。 让人人都拥有对网站的主人翁感觉，确实意味着能够减轻运维团队的工作负担。他们不用再花费大量时间呼吁采取防护性措施，一旦发生问题，也能够花更小的时间修复。这非常了不起，因为这意味着网站的宕机时间会减少很多。这也释放了运维团队，让他们能够把精力放在更为重要的任务上，即对基础架构的长期增长进行管理。 你的访问者感觉怎么样：面向用户的测量对于网站的成功而言，终端用户的测量也就变得和后台测量一样至关重要。 为何要采集面向用户的测量数据采集数据，从而就可以对业务的健康状况进行分析。 如： 每秒请求数/发布数 带宽 响应时间 HTTP错误率 记入日志的异常数 进程重启次数 队列大小 服务器的平均负载和进程数 数据库负载 内存 成功的创业公司所学到的以及必须适应的创业公司的一大优势就是敏捷，即快速反应的能力。要真正做到敏捷，创业公司需要了解终端用户真正体验到的是什么。 任何网站想要成功，就必须向用户学习，而且必须适应用户的需求。很多Internet巨头，它们现在的业务，都与其当初设定的相比有很大的不同。 性能问题响应越快的应用程序越好！ 响应级别： 加入事情的响应时间在10ms内，我们的大脑就会认为这是真实的 如点击桌面系统上的按钮 如果谈话有100ms左右的延迟，我们不会感觉到这种延迟 如国际长途电话 如果应用程序的响应时间在1s之内，我们的感觉就是仍然在与应用程序互动，仍然在工作 应用程序的响应时间要是明显长于1s的话，我们就会抓狂 研究量化了这种关系Web应用的速度越快，其Web业务员的优势就越明显！ 如果你的网站很慢，你将得到： 更少的用户搜索 更少的精度搜索 更少的每访客收入 更少的点击，更低的满意度 更少的每日搜索 等待访客点击的时间更长 更低的搜索引擎排名 更差的用户体验 是什么使网站变得很慢简单来说，由以下三点原因造成： 服务器花在处理用户请求上的时间 网络花在传输请求和响应上的时间 用户花在组装并显示结果内容上的时间 服务发现开始访问网站，用户都需要先找到服务器。 对于带有很多组件的网站——这是一个日渐普遍的模式——都会迫使用户去解析很多网站，并且页面加载的时间也延长了。 发送请求网络再快，用户与服务器之间的往返也是需要时间的。 请求包含的内容越多，则网络用来传输的时间就越长。加入是一个安全页面的话，还会有另外的延迟，用来在客户与服务器之间进行加密协商。 响应请求到达服务器之后，另一个导致延迟的罪魁祸首就登场了——主机。不论是从内存中检索静态对象，还是利用后台的第三方服务来完成一个复杂的请求，主机延迟都会对性能造成影响。 发送响应响应内容一旦准备就绪，服务器就可以通过HTTP协议发送这些请求对象——大多数页面包含多个对象(如html,css,js,gif,png,jpg…)，正是这些对象的发送造成了访客体验到的延迟。 异步通信与刷新某些应用包括一些客户与服务器之间的通信，这些通信是独立于页面进行的。包含某种异步更新或刷新的应用，有不同的延迟测量指标。 渲染时间随着客户端越来越复杂，浏览器做的也就越来越多。有可能是启动富互联网应用(RIA)，这些RIAs都是构建在Flash、Flex、HTML5、Java、JS…之上的，也可能是运行QuickTime或Windows媒体播放器等这样的插件，甚至决定如何对复杂页面进行布局也是需要花费时间的。所以，对于大量依赖客户端进行渲染的网站，就必须考虑这种延迟。 测量延迟有两种测量方法： 综合监控 实际用户监控(RUM) 综合监控综合监控是通过从多个地点对网站进行一系列正规的校本化测试，对网站的性能进行监控。 要记住，综合测试也是要消耗服务器资源的。 真实用户监控RUM的工作名副其实：它观察的是网站的真实访客，记录访客打开页面的速度，然后生成报表。 从这点来看，RUM会告诉你系统是否出问题了，因为你可以通过RUM发现问题以及速度变慢的情况，这些情况你没有进行测试，从而也就不知道是否存在。 编写SLAWeb运维收集终端用户的数据的一个主要理由就是用来编写SLA，哪怕与客户之间没有正式的SLA，但对于正常工作时间及页面延迟，也应该有内部的目标，因为网站速度对用户体验有直接的影响。 访客结果：分析对于成功的Web运维来说，监控就是了解存在哪些不利因素。而当进入Web业务时，这些测量就要让位于Web分析了。 市场营销如何定义成功对市场营销的最好描述——“更经常、更有效地卖出更多的东西给更多的人，从而得到更多的钱。”或许应该将成功的在线营销更精确地定义为“让人们有效地去做你要他们做的事情。” 网站的四种类型 交易性网站 协作型网站 作为服务(saas)网站 媒体网站 很多流行网站都是上述模式的混合。 网站分析就是对每种类型网站的成功因素进行追踪，从中识别出使这些因素得以增长的背后动因——不管是广告活动、性能的提升、社会网络上的关注、特殊的定价模式还是某个引人注目的内容。 分析一个简单的模型有一个简单方式来考虑网站分析，就是做一次访问。 网站分析的目标，就是通过优化网站，将访客的转变最大化，通常是对网站进行试验，并针对各种内部和外部区段，对这些试验结果进行分析。 市场营销关心的其他测量数据Web交互分析分析查看的是用户对多个页面的整体访问情况，Web交互分析集中在单个页面的可用性交互上。 用户之声用户之声工具用来询问客户在想什么。这些工具从网站的访问性中征求反馈，通过请求客户参与调查，或者在页面上提供一个反馈按钮。 用户体验如何影响Web运维随着新建公司对终端用户体验的关注，Web运维的角色正在发生变化。对线上事务的兴趣越来越浓，而且通过追踪分析，网站的所有事情都能够和业绩联系起来。 将监控作为生命周期的一部分网站现在已经有了很大的变化，随着敏捷和精简产品开发的流行，监控也需要跟上。所以来的综合监控脚本以及RUM配置也需如此。 Web监控的未来终端用户体验的监控正在兴起，变化很快。这是业务中最能进行分析、量化的部分，每周都能涌现出新的技术。 从系统转向用户 以服务为中心的架构 云与监控 APIs与RSS消息 将关系数据库用于Web的战略战术如何为产品或应用程序设计一个良好的关系数据库架构，如何构建良好的互联网数据库架构？ Web数据库需求其实，大多数网站，相对而言，都只是小型数据库。一些大型公司，可能才是一个大型数据库。 一直在线数据库通常要7x24小时运行。一直在线意味着维护和运维任务是很难做的，你不能简单地等到人们回家了然后将服务器卸下来，给硬件升级或备份。必须在不停机的情况下做这些事，而且很多情况下还不能给应用程序增加额外的负载。 话虽这么说，还是极少看到没有峰值时间的数据库。所以，还是有很好的机会，在数据库活动的间歇期来做备份或对数据库产生干扰工作。 事务最多的工作负载很多互联网应用都匹配以下模式： 应用程序读远大于写 一次读一行和一次读多行是混合出现的 一般，写每次只影响一行 这就是称之为的事务型负荷。 简单数据，简单查询网站的流量很大程度上决定了数据库的流量。 查询通常会满足下面的模式： 读写用户表，一次一行 以区域或集合方式读取用户自己的数据 以区域或集合方式读取其他用户的数据 从该用户到其他用户的关联表中读取区域行 对该用户和其他用户的数据进行汇总与计数 特别低，很多数据可以分区存储的事实说明了为什么分片(sharded)架构是可能的。 可用性胜过一致性从业务的角度看，最重要的事情是应用程序对用户的可用性。 快速开发传统应用极少以天或周为周期构建和部署，但对于大量Web应用来说却是常态，这些Web应用是永远的Beta版。 在线部署模式和数据的更新都做成代码形式，而且也有这样的框架，部署这些代码或将其回滚都很容易。 由开发人员构建大量的应用程序都是由开发人员做的，都没有一个高水平的DBA。 典型的Web数据库是如何增长的大多数Web数据库的增长，都经历了一些列的架构变动。这些架构变动，在应用程序的整个生命周期中，相对而言都是可预知的。 单台服务器一般应用程序都是从单台服务器开始起步的。使用单台服务器有很多好处： 数据只有一份拷贝，不存在你的数据是否正确或不同的问题 易于配置 便宜 当然，缺点就是只有一台服务器！假如发生问题，没有冗余机器做故障转移。性能也会受影响。 主服务器与单复制从服务器各数据库的复制技术都不一样，但一般而言，发生在主服务器上的数据修改，都要在从服务器上重复一遍，所以从服务器是主服务器数据的只读拷贝。依赖于数据库、系统负载以及执行的查询类型，从服务器不一定时刻与主服务器的数据完全一致(异步复制)。 增加一个复制从服务器有很多好处。数据库读请求可以在主、从指间分担，这称为读写分离。可以在从服务器上执行那些效率不高的查询、备份以及其它有可能对网站造成破坏的任务。 主服务器与多复制从服务器大多数复制技术对两台或多台从服务器都没问题。这样确实不错，而且随着从服务器越来越多，系统的数据库读取能力也越来越强。但这种增长不是无限制的，在很多层面上都会遇到收益递减的拐点。 第一个层面就是应用程序中读对写的比例 第二个方式表示主服务器的写操作有多忙，其中你会看到收益递减的情况 第三个限制是操作成本和复杂性 管理一群服务器，比管理单台服务器，要难得多也昂贵得多 最后一个不足是应用的复杂性 从单一数据源走向两个数据源，对于大多数应用程序而言，都是一个重大转移。应用程序不得不连接多个位置来进行查询。连接池、负载均衡器以及类似技术会在一定程度上保护你不受这种复杂性的困扰，但最终应用程序仍然要面对某种程度的复杂性 复杂性的一个最大来源是异步复制。异步意味着写操作先在主服务器上完成，随后送往从服务器执行。结果就是，从服务器总是拖后于主服务器某段时间，即时这段时间很短，但由此而造成的问题却很大。这可能会导致用户体验的不一致到数据完整性等一系列问题。 一般而言，不存在修复这个问题的神奇方法，应用程序必须自己处理这种延迟复制。一种不错的简单技术是基于会话的分裂。用户做了更新之后，一段时间之内，该用户的所有查询都导向到主服务器。认为能够安全地查询从服务器所需的时间戳通常都存储在会话里。 功能分区复制只对读有伸缩，对写没有。随着应用的规模越来越大，写操作的负载最终会大到系统无法处理。 功能分区(functional partitioning)，假如将某些部分与其余部分分开，则这些部分可以独立增长。如，对于博客服务，可将评论功能分离到它自己的服务器中。 从运维角度来看，不同部分处在不同位置，则应用程序的功能也就能够单独对待。比起网站宕机，将评论改为只读模式，用户的反感可能要小得多。 这种做法的不利之处是增加了复杂性。应用程序需要从多个位置获取数据，而运维团队必须保持这些服务器正常运行。 分片分片(sharding)，是将单一逻辑数据划分为多个片段并发布在多台服务器上的一种方式。所有的片段在逻辑上和功能上都是相同的，虽然这些片段分别包含数据的不同子集。 分片架构的主要设计目标和优势都是双重的。第一是允许写伸缩，因为负值无法实现写伸缩，假如应用程序的写操作草果了任何单台服务器能承受的程度，就必须要分片以减少写操作的负载，写操作的负载必须分担到完全隔离的服务器上，对一个分片的服务器的写操作不能复制到另一个分片服务器上。第二个目标和优势是，随着数据集的增长，能够增加更多容量的能力。 在分片架构中，许多查询也变得困难或不可能了。例如，需要访问所有客户数据的查询，通常都要在每个分片上分别执行，然后在应用程序代码中在聚合在一起。 分片架构还存在很多其他的不足和复杂性。 缓存层缓存层的目的是阻止查询到达数据库。标准的例子是：memcached，redis 缓存层的主要优势是极为容易，并且简单。 从运维的立场来看，需要考虑缓存服务器的冗余和可用性，就像为其他服务器所做的一样。 对集群的渴望在应用程序出现某种问题，或关于可用性或伸缩性的困难问题来的时候，人们的思想就会转向集群(cluster)，就像年轻人的思想转向春天和爱情一样。 CAP定理以及ACID和BASECAP原理： 一致性(Consistency)、可用性(Availability)、分区容错性(Partition Tolerance)。你可以具有两者，但不能三者皆具备。 ACID： 原子性(Atomicity)、一致性(Consisitency)、分离性(Isolation)、持续性(Durability)。 BASE: 根本可用性(basically available)、软状态(soft state)、最终一致性(eventual consistency)。 MySQL集群的状态MySQL Cluster是将MySQL服务器作为一个完全不相干的、称为NDB的软件的前端。NDB的意思是网络数据库，这是一个极快、分布式、无共享、高可用的数据库。 DRDB和HeartbeatDRDB在服务器之间对块设备进行复制，将修改的块通过网络复制给备机。如果主服务器失效了，则Heartbear激活备机。 从运维的角度来说，DRDB非常棒，装上就能工作，但却不能满足在线用户的需求。它不是为满足典型Web应用的高可用性而设计的。相反，它非常适合用户保证你不丢失数据的情况，也就是说，它关注的焦点是一致性而不是可用性。 另一个问题就是基于DRDB的集群不能改进性能。Web应用需要的是正常工作时间和性能，而基于DRDB的集群是以性能为代价来提供一致性，而一旦失效，宕机时间就会很长。 主服务器到主服务器的复制管理器(MMM)MMM是一系列的Perl脚本，管理复制和虚拟IP地址，从而为MySQL提供一个伪集群(pseudocluster)。 应用程序连接到虚拟IP而不是服务器的真实IP。服务器发生问题时，MMM将该服务器的虚拟IP移动到另外的可用服务器上。它也可以将复制从服务器从失效的主服务器移动到正常的主服务器上。MMM允许手工将服务器离线执行维护任务。 带复制的Heartbeat如果MMM无法完美地管理复制和虚拟IP地址，heartbeat考虑以下？ 不管怎么说，复制延迟仍然是一个复杂的问题。必须在应用程序层解决这一部分问题。 基于代理的解决方案有一种可供选择的方案，基于代理(proxy)，需要人工介入，MySQL Proxy位于前端。HAProxy是另一个流行的方案。 MySQL Proxy，事实上能够理解MySQL的协议，并且拦截、解释以及传递消息 HAProxy，只是传递TCP流，并不对内部进行窥探 基于代理的解决方案仍然没有入人们所愿的那样解决复制延迟问题，而且还引入了单点故障，并且影响性能。 小结前面讨论这么多，简而言之，就是没有一个完美的、万能的答案。 最好的数据库架构是为了应用而建的，期待集群所承担的指责分布在数据库、网络以及应用程序上，有运维的适度介入，以及起粘合作用的软件，就能把各部分整合在一起。 数据库战略如何选择一个对于大量的互联网架构来说都能够运转良好的架构。 架构需求最好定义你的需求，特别是，把那些超出你的范围从而成为别人的问题的内容写成文档。 有把握的架构以下数据库架构，是比较有把握的。 单主服务器，多从服务器这种主-从架构很难自动实现主服务器的故障转移，因为主服务器和从服务器的配置是不一样的，所以，一旦主服务器失效，则必须手动进行失效转移。 主服务器-主服务器复制，外加从服务器这种方式实际上与一台主服务器加多台从服务器的架构一样，但有时候主服务器本身也成为从服务器。这种架构的优点是，在协同的主服务器之间更容易实现失效转移和失效转回。缺点是，向两台主服务器进行写入存在风险，会导致数据库存在某种不一致性，也很难解决。 功能分区随着应用的增长，将应用中某些部分转移到特定的服务器或特定集群上。 失效转移和负载均衡使用负载均衡器，或者浮动的虚拟IP地址。 ACID仍然是有意义的高可用性要求快速而可靠的灾难恢复。 使用正确的工具不要使数据库处于关键路径上，不要讲应用程序的静态信息放入数据库中。数据库应该存储数据，而非应用程序本身。将数据库简单化，因为这是最难于伸缩，也是最昂贵的资源。但是，对于Web应用，还是应该分离应用程序和数据库，将数据库仅用来存储和检索数据。 有风险的架构建议不要使用这些架构 分片除非不得已，不要分片。对于一个中等规模的应用，将其构建在数百台低档机器的分片架构上，试图提供无线伸缩能力，是非常愚蠢的。其实，只需购买几台足够好的机器，在工程上多做一些考虑就足够了。分片架构比你预想要昂贵的多，甚至在短期内也是如此，长期则一定如此分片问题设计过度设计的风险 写入多台主服务器不要将多台服务器配置为可写，这会造成数据一致性问题。非常麻烦。 多级复制尽量不要使用多级复制。使用一主多从而不是从的从的从服务器，要简单的多。孙子辈的从服务器和重孙辈的从服务器很难管理。 环形复制避免使用环形复制，其失效情形，不管是数量还是复杂度，都打得超乎想象。 依赖于DNSDNS很脆弱，依赖DNS最终会自食苦果。 数据库战术数据库战术，即为保持数据库基础架构的可靠性而做的日常运维任务。 在从服务器上做备份一些小提示： 在备份上不要拖延，做备份其实并不难 做事不要追求完美，而要追求可恢复 至少对于可接受的数据损失、可接受的宕机时间、数据持续策略以及安全需求要形成文档 对恢复过程要进行练习并形成文档，恢复比备份要重要的多 对于备份成功与否，要进行外部验证，不要依赖于作业自身对你的提示 可以专门配置一台复制(备份)从服务器，将复制延迟一段时间——如30min，以避免主服务器上的某些误操作——如DROP table。 在线模式修改将表做的小一点是很有好处的。 一般的想法是设置主-主复制对，但只有一台服务器可写。在只读上执行更新，但不要复制到可写服务器上。更新一旦完成，则用正常方式使应用程序实现失效转移。这样，读和写便实现了角色转换。然后在另一台服务器上重复执行风险。这就实现了对应用程序隐含宕机时间的目的。 监控和图示构建用于测量和监控的系统是很值得做的事情，这些系统是基础架构非常重要的核心内容。 性能分析一般步骤是，在产生麻烦的时间内手机详细的诊断数据，消除掉可能的原因，集中在问题的现象上。问题往往是服务器产生大量负载，而这通常是由于糟糕的查询产生的。 MySQL所谓的慢查询日志(slow query log)可以回答这个问题，不仅是因为日志收集了慢查询的信息，而且对于每个查询还有时间信息。 加入性能问题不是查询引起的，则需要对MySQL本身进行性能测试。 归档和删除数据从一开始就要规划归档和删除不活动或不需要的数据，这样有助于减小“工作集”的大小。 将极不活跃的用户数据移动到慢速服务器，或仅仅将用户设置为过期。当用户登录或重新激活时，在倒回到正常表中 另外一类可归档或删除的数据是陈旧的历史数据，或将历史数据移到另外的服务器上 结语尽最大可能将数据库架构建立在逻辑的基础上，而不是做一些看起来很酷的事情。 努力使系统保持小巧，不要大——而当不得不变大时，也要保持在能够掌控的范围内。要确定应用程序的真正需求，尽可能满足这些需求。要尽早及经常做缓存，但不要尽早及经常做分片。 最重要的，请记住：做备份。 如何优雅地失败：事后处理的艺术与科学宕机意味着实际的金钱损失。客户才不会管这些故障，他们要的就是可靠性。互联网已经变得非常重要，宕机成本也越来越高。 但正如一个刚毕业的年轻人一样，只是知道你需要成长，但并没有告诉你如何去成长。我们需要将失败转化为学习经验。 保证网站稳定的首要事情，就是建立一个系统化的事后分析过程。通过阻止事故的重现以及改进处理事故的方法，使得系统稳定之后，事后分析能够让你全面地理解事故的本性。 例行的时候分析，是对运维的复杂问题进行科学分析的最贴近的方法。通过收集实际证据，可将有限的资源集中于解决产生问题的实际原因上。 什么是事后分析事后分析至少要包含这些内容： 事故描述 根本原因描述 事件是如何修复的 用于解决事故的行动的时间表 事故是如何影响用户的 纠正或改正动作 事后分析时，与事故明显有关的人员都要同时到场，对事故的真实情况作出共同的描述，从而正确地采取行动。 减少事故的修复时间，就跟消除事故本身一样重要。 对问题赋予严重级别，将帮助你按照轻重缓急来处理纠正项，而且对于活跃事件的评估也是有用的。 事故严重级别： 严重影响大批用户 网站降级运行、性能问题或很难应对的功能故障 对客户影响不大或易于应对 什么时候引入事后分析在事故处理完成之后，就应该进行事故分析。事后分析过程应该最终使用户获益，而不应该在恢复服务的过程中进行。 进行事后分析开始事后分析时，要明确基本规则，要明确告知参与事后分析的相关各方，事后分析不是指责谁(人们害怕这样的会议变成政治迫害)，主要目的是为了使类似事件不在重复发生。问题不可避免，重要的是我们能够从错误中学到教训。事情一旦清楚之后，就可以开始讨论为了使类似事情不在发生，需要做些什么。确保相关各方对各自领域都能得出补救的办法。但切记不可矫枉过正！ 一旦有了一套纠正措施，要将其记录在案，包括执行人员和完成日期。 事后分析的后续工作对纠正措施必须进行追踪，直到执行完成。 一些网站可操作性： 消除单点故障 容量规划 监控 发布管理 运维架构复审 配置管理 随时待命和提升过程 不稳定的组件 结语最后，对于避免事故的发生，事后分析是最有用的方法。在一个快速变化的环境中，发生问题时可以理解的，但问题重复发生却是不能原谅的。花些时间高清楚问题的实质，从而确定、记录以及实施高强度的纠正措施，就可以避免事故的重复发生。 存储数据是一项最重要、不可替代的商业资产。 数据资产的库存在开始一项新的存储工作时，首要的事情是要知道数据存在哪里。对于不了解的数据，你是无法进行保护的。 数据的保护数据保护对所有系统都是很重要的。良好的数据保护实践有助于处理范围广泛的情形，从还原被用户偶然删除的文件，到从灾难事件中恢复。 为了对数据中心问题提供完全的防护，重要的是将关键数据复制到不同的地点。 如今大多数的存储系统都有某种类型的复制技术。复制通常有两种形式：同步和异步。 容量规划在确保有效的的数据保护之后，作为一名存储专业人员，容量规划就是第二项最重要的职责。规划在前，确保应用和服务有足够的资源来运行和成长，不至于碰到天花板，这是必须的。 总是确保有足够的空间以应对突然的爆炸性增长，以及软件开发方面出现的延迟。 存储大小的变化存储是很昂贵的，这是现代基础框架中成本最高的组件。正是由于这个原因，对于存储上的开支进行明智地规划是很重要的。 存储需求要点： 应用是什么 应用位于哪里 存储的是什么类型的数据 需要共享存储吗 是否需要特殊的访问协议 典型的文件大小是多少 数据是压缩的吗 如果描述工作负载 需要批处理操作吗 工作负荷是大部分用于读、写、读写 工作负荷是大部分顺序、还是大部分随机、还是两者 快照是怎么安排的 快照的一致性问题 存储容量在6个月、12个月、18个月的计划是什么 工作负荷在6个月、12个月、18个月的计划是什么 复制策略是什么 业务连续性规划是什么 可用性需求是什么 备份的频度是什么 备份保持的计划是什么样的 归档策略是什么 综合性需求是什么 加密需求是什么 … 结语数据是最宝贵的业务资产，且是不可替换的。 非关系数据库应用的数据存储层的伸缩是很难的。不管用的是什么数据库技术，随着数据量和事务数量的增长，就需要做出改变以适应新的负荷。 SQL数据库的可伸缩性通常归结为四件事：缓存、查询优化、购买新硬件、数据库分片。 NoSQL数据库概览NoSQL共生系统，可将数据库划分为5大类： 纯粹的键值 数据结构 图 面向文档 高度分布 每种类别的数据库都面向不同的应用情况，每个类别也都做了不同的这种。 纯粹的键值如： Tokyo Cabinet、 Kyoto Cabinet、MemcacheDB 正是它们的简单性定义了这组数据库。向数据库存入一个键和一个值，然后用同一个键查询数据库，则会得到相同的值。没有结构或类型系统——通常所处理的只是字节或字符串。因为这种简单性，这些数据库的开销极小，所以非常块。事实上，这些数据库通常都是实现为磁盘上的B树或哈希表。 数据结构数据结构数据库对键值数据库做了些修改，数据结构数据库将其存储为特定的数据结构，如列表、集合、哈希表等。有了这些附加的结构，就可以对值执行一些原子操作。可以对数据库执行在应用程序中对数据结构进行的各种操作。 Redis默认是在内存中(in memory)存储其全部内容，只是周期性地将内容的快照存储到磁盘。这使得Redis出奇的快，但假如数据库奔溃了，就会对数据造成一些损失，同时也意味着必须有足够的RAM存储这个数据库。 图图数据库几乎就是数据结构数据库的一个特定实现，因为图本就是一种数据库。区别是图数据库不再是基于键值，数据是作为图的节点和边存储的。图数据库不是用键来查询值，而是给出根节点的句柄，然后就可以遍历整个图以找到需要的节点或边。 图数据库的优势：存储图或树形的数据。如一个社交图(social graph)。 常见图数据库包含：Neo4j、HyperGraphDB、InfoGrid、VertexDB。 面向文档面向文档的数据库又类似于键值数据库，但值不再是字节、字符串、列表、集合，而是文档。文档作为JSON(BSON)对象存储，本质上是一种哈希表或字典。这些值都想相同的结构，意味着可以用查询来探测这种结构，并只返回所需要的文档。这种查询能力是建立在通过键来查找文档的能力之上的。 常见面向文档数据库： MongoDB、CouchDB。 高度分布高度分布的数据库多少有些不同——有些本质上更接近于键值存储，其它则像大型的多维哈希图。 HBase、Cassandra是高度分布式数据库。 某些细节注意这些数据库之间的一些相似性，以及所做决策是如何影响系统可操作性的。 CassandraCassandra是一个高度分布数据库。 它有一些关键概念： 认为写比读更难于伸缩，所以它专门为写操作做了大量优化 认为不应该存在单一故障点任何数据可以写入到集群内的任何一个节点，而且读也一样。任何接收到请求的节点都可以，并且将会吧请求转发到合适的节点。 HBaseHBase选择一致性和可用性作为自己的核心价值。这样的结果，导致了在某些网段、集群无法实现优雅的恢复。作为这种牺牲的补偿，HBase有很强的一致性，保证写入一结束，写入的值就立即可以读取。 RiakRiak实现了向量时钟(vector clocks)，一些高度分布的数据库都没有实现——这些数据库选择了依赖于更为简单的基于时间戳的技术。 向量时钟是一种分布式系统中的机制，用于生成偏序事件。使用向量时钟，解决发生在两个独立的不同节点中的相同值的冲突就变得非常简单。从Riak客户端的角度来看，每个客户实例在Riak集群中执行一个动作时，都应该有一个唯一的标识(token)(连同其接收到的向量时钟一起)。然后，客户读取数据时，就可以看到向量时钟和数据值，使用包含的信息连接两个结果，从而将正确的版本写会数据库。 Riak也不存在单一故障点。 CouchDBCouchDB对世界的看法是一致的：所有东西都是文档，而且都通过RESTful HTTP来访问。CouchDB可以在数据库中直接存储静态媒体，它实际上是允许将整个应用程序都存储在数据库中的。CouchDB的数据模型很新颖，即数据以一种只附加的B树进行存储。 MongoDBMongoDB是一个面向文档的数据库，文档格式使用BSON——一种类似于JSON对象的二进制规范。MongoDB是用C++写的，因而有很高的性能。 所有能用SQL做的事情也能用MongoDB查询表达式来做。MongoDB与以SQL数据库相同的方式支持索引，同时这些索引也强制了唯一性。 MongoDB有一个mongostat命令来查看数据库状态。 有好几种MongoDB备份方式： 停掉数据库，复制数据文件 锁定数据库写入，复制数据文件，解除锁定 使用mongodump，将数据库转存到一个二进制文件中 可以设置一个从服务器，在从服务器上进行备份，而不是主服务器上 RedisRedis(remote dictionary server)，远程字典服务器。通过INFO可查看相关信息。 不管你将Redis运行在快照模式(rdb)还是只附加模式(aof)上，都可以简单地调用rsync实现备份。 如何高枕无忧企业持续规划(Business Continuity Planning)BCP。BCP简单最简单来说，就是什么都是两份。当然，两套设备间的失效转移必须完全自动化。 术语集中于BCP计划的高可用部分：保证站点正常工作。即使在高可用性领域，也有各种各样的技术，从热/热(Hot/Hot)、热/暖(Hot/Warm)、热/冷(Hot/Cold)到灾难恢复。 热/热是高可用性的最高级别。用户可以从任意的数据中心使用全部的应用程序。读和写可以发生在任何地方。折让自动的故障转移变得非常简单，但它不是万能的。你想必须思考如何处理数据一致性的问题。 热/暖是一种很好的方式，如果你不能容忍数据的不一致性的话。很多应用有大量的读操作，仅偶尔写一下(但很重要)。在这种情况下，区别处理这两种操作是有意义的。 热/冷让我害怕。这种架构将读写流量送到单一地点，而让另一个相同的部署在遥远的地平线上闲置。它容易建立，但价值很低。 灾难恢复是最差的技术，本质上是雾件(vaporware)。它的本意不是在平常的时候保护你，而是在大的灾难发生时给你提供重建的选项。 影响持续时间对事件持续时间当灾难来袭时，所有你需要考虑的是将用户流量以最快速度转移，离开问题区域。你需要立即降低影响。不要过于担心根源问题的修复，一旦将影响制止住，会有很多时间来解决这次事故。 怎样才能将流量从问题站点转出呢？通常方案是使用全局负载均衡(Global Server Load Balancing)GSLB。这实际是一个动态的授权DNS服务器，他能够根据相关因素对同一域名给出不同的IP地址。 数据中心数量我们知道数据中心会失效，所以你至少需要两个。这就够了吗？三个或更多是不是会好一些？这取决于三个因素，成本、复杂性和性能。 逐渐失效当数据中心出现局部问题(partial problem)时，不要等它解决从而希望你不需要撤离，立即导出复制数据！ 不信赖任何人正如最可靠的数据中心也会时不时宕机，你可以预期即使最好的第三方供应商，偶尔也会有问题。就是你不能完全信赖一个服务提供商。 故障测试转移通过早期和经常的测试，获取经验，以便当灾难袭来时，不会手忙脚乱，而是立即做出正确的事情。 监控和历史模式你要知道日、周、月的流量模式。如果清楚正常流量中的不寻常处，你就不会在切换、迁移或升级时感到惊讶。确保监控包括周对周的图形和趋势。 高枕无忧如果你能够事先有计划，能够解决大的问题，并且在日常工作中操练故障转移，则平台任何部分的失效将会变成容易处理的事件，而不是危机。 March 25, 2018 11:32 AM]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>Operations</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《经济学原理》读书笔记]]></title>
    <url>%2F2018%2F02%2F23%2F%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[参考： 《经济学原理-微观/宏观》 曼昆： https://book.douban.com/subject/26435630/ 学习指南图微观经济学:第1篇到第7篇，即第1章到第22章。 第1篇： 导言 第1章： 经济学十大原理 第2章： 像经济学家一样思考 第3章： 相互依存性和贸易的好处 第2篇： 市场如何运行 第4章： 供给与需求的市场力量 第5章： 弹性及其应用 第6章： 供给、需求和政府策略 第3篇： 市场和福利 第7章： 消费者、生产者与市场效率 第8章： 应用： 赋税的代价 第9章： 应用： 国际贸易 第4篇： 公共部门经济学 第10章： 外部性 第11章： 公共物品和公共资源 第12章： 税制的设计 第5篇： 企业行为与产业组织 第13章： 生产成本 第14章： 竞争市场上的企业 第15章： 垄断 第16章： 垄断竞争 第17章： 寡头 第6篇： 劳动市场经济学 第18章： 生产要素市场 第19章： 收入与歧视 第20章： 收入不平等与贫困 第7篇： 深入研究的论题 第21章： 消费者选择理论 第22章： 微观经济学前沿 宏观经济学：从第8篇到第13篇，即第23章到第36章。 第8篇： 宏观经济学的数据 第23章： 一国收入的衡量 第24章： 生活费用的衡量 第9篇： 长期中的真实经济 第25章： 生产与增长 第26章： 储蓄、投资和金融体系 第27章： 金融学的基本工具 第28章： 失业 第10篇： 长期中的货币与物价 第29章： 货币制度 第30章： 货币增长与通货膨胀 第11篇： 开放经济的宏观经济学 第31章： 开放经济的宏观经济学基本概念 第32章：开放经济的宏观经济理论 第12篇： 短期经济波动 第33章： 总需求与总供给 第34章： 货币政策和财政政策对总需求的影响 第35章： 通货膨胀与失业之间的短期权衡和取舍 第13篇： 最后的思考 第36章： 宏观经济政策的六个争论问题 阿尔弗雷德·马歇尔在《经济学原理》中写道经济学是一门研究人类一般生活事务的学问。 应当学习经济学的原因如下： 有助于你理解你所生活在其中的世界 使你更加精明的参与经济 使你更好地理解经济政策的潜力与局限性 经济学原理可以运用到生活中的方方面面 经济学领域的伟大洞见，如亚当·斯密的看不见的手的概念、大卫·李嘉图的比较优势原理，以及约翰·梅纳德·凯恩斯的总需求理论 导言经济学十大原理经济(economy)这个词来源于希腊语oikonomos，意思是“管理一个家庭的人”。 一个家庭面临着许多决策，同样，一个社会也面临着许多决策。 由于资源是稀缺的，社会资源的管理就尤为重要。 稀缺性(scarcity):社会资源的有限性 经济学(economics):研究社会如何管理自己的稀缺资源 人们如何做出决策由于一个经济的行为反映了组成这个经济的个人的行为，所以个人就需要做出决策。 人们面临权衡取舍 效率(efficiency):社会能从其稀缺资源中得到最大利益的特性 平等(equlity):经济成果在社会成员中平均分配的特性 作出决策就是要求我们在一个目标与另一个目标之间进行权衡取舍。 当人们组成社会时，他们会面临不同的权衡取舍。经典的权衡取舍是在大炮与黄油之间。 社会面临的另一种权衡取舍是在效率与平等之间。 然而，认识到人们面临权衡取舍本身并没有告诉我们人们将会或应该做出什么决策。 某种东西的成本是为了得到这种东西所放弃的东西 机会成本(opportunity cost):为了得到某种东西所必须放弃的东西 由于人们面临着权衡取舍，所以做决策就需要比较可供选择的行动方案的成本与收益。 理性人考虑边际量 理性人(rational people):系统而有目的地尽最大努力实现其目标的人 边际变动(marginal change):对行动计划的微小增量调整 边际成本(marginal cose):对行动计划调整所带来的成本 边际收益(marginal benefit):对行动计划调整所带来的的收益 边际决策(marginal decision):选择哪种决策 人们会对激励做出反应 激励(incentive):引起一个人做出某种行为的某种东西 在经济学研究中，激励起着中心作用。 市场上的高价格提供了买者少消费而卖者多生产的激励。价格对消费者和生产者行为的影响对于市场经济如何配置稀缺资源是至关重要的。 政府决策者决不能忘记激励，因为许多政策改变了人们面临的成本或收益，从而也改变了人们的行为。 在分析任何一种政策时，我们不仅应该考虑它的直接影响，而且还应该考虑它通过激励产生的不太明显的间接影响。如果政策改变了激励，那就会使人们改变自己的行为。 人们如何互相影响我们的许多决策不仅影响了我们自己，还会影响其他人。 贸易可以使每个人的状况都变得更好思考国家之间的竞争的想法很容易产生误导。美国与中国之间的贸易并不像体育比赛一样，一方赢而另一方输。实际上，事实正好相反：两国之间的贸易可以使两个国家的状况都变得更好。 贸易使每个人都可以专门从事自己最擅长的活动，无论它是耕种、做衣服还是盖房子。通过与其他人的贸易，人们可以以较低的成本获得各种各样的物品和服务。 国家和家庭一样，也能从相互贸易中获益。贸易可以使各国可以专门从事自己最擅长的活动，并享有种类更多的物品与服务。美国人和英国人、法国人一样，在世界经济中既是我们的竞争对手，又是我们的伙伴。 市场通常是组织经济活动的一种好方法 市场经济(market economy):当许多企业和家庭在物品与服务市场上相互交易时，通过他们的分散决策配置资源的经济 看不见的手(invisible hand): 利己心(self-interest): 中央计划经济国家运行的前提假设是，政府官员能够最佳地配置经济中稀缺资源。这些中央计划者决定，生产什么物品与服务、生产多少，以及谁生产和消费这些物品与服务。支撑中央计划经济的理论是，只有政府才能以促进整个社会经济福利的方式组织经济活动。 大部分曾经是中央计划经济的国家已经放弃了这个制度，代之以发展市场经济。在市场经济中，中央计划者的决策被数千百万企业和家庭的决策所取代。 在市场经济中，没有一个人追求整个社会的经济福利。自由市场包括大量物品与服务的许多买者与卖者，而所有的人都主要关心自己的福利。 经济学家亚当·斯密在《国富论》中提出了全部经济学中最著名的观察结果：“家庭和企业在市场上相互交易，他们仿佛被一只看不见的手所指引，并导致了合意的市场结果。” 价格就是看不见的手用来指引经济活动的工具。作为买者与卖者决策的结果，市场价格既反映了一种物品的社会价值，也反映了生产该物品的社会成本。斯密的重要洞察是，价格会自发调整，指引这些单个买者和卖者达到某种结果，该结果在大多数情况下会实现整个社会福利的最大化。 斯密的观点有一个重要的推论：当政府阻止价格根据供求状况自发调整时，它就限制了看不见的手对组成经济的千百万家庭和企业的决策进行协调的能力。这个推论解释了为什么税收对资源配置有不利的影响：由于税收扭曲了价格，从而也扭曲了家庭和企业的决策。这个推论还解释了像租金控制这类直接控制价格的政策所引起的巨大危害。而且，这个推论解释了中央计划经济的失败。在中央计划经济国家，价格并不是在市场上决定的，而是由中央计划者规定的。这些计划者缺乏关于消费者爱好和生产者成本的必要信息，而在市场经济中这些信息都反映在价格上。中央计划者之所以失败，是因为他们在管理经济时把市场这只看不见的手绑起来了。 亚当·斯密描述了市场经济中人们如何相互影响： 人类几乎随时随地都需要同胞的协助，要想仅仅依赖他人的恩惠，那是绝对不行的。他如果能够刺激他人的利己心，使其有利于他，并告诉其他人，给他做事是对他们自己有利的，那么他要达到目的就容易得多了。··· ···请给我们我所要的东西吧，同时，你也可以获得你所要的东西：这句话是交易的通义。我们所需要的相互帮助，大部分是依照这个方法取得的。我们每天所需的食物和饮料，不是出自屠户、酿酒师或面包师的恩惠，而是出自他们利己的打算。我们不说唤起他们利他心的话，而说唤起他们利己心得话。我们不说自己有需要，而说对他们有利。社会上，除乞丐外，没有一个人愿意全然靠别人的恩惠过活… …每一个人··· ···既不打算促进公共的利益，也不知道自己是在何种程度上促进那种利益··· ···他所盘算的也只是他自己的利益。在这种场合下，像在其他许多场合一样，他受着一只看不见的手的引导，去尽力达到一个并非他本意想要达到的目的。也并不因为不是出于本意，就对社会有害。他追求自己的利益，往往使他能比在真正处于本意的情况下更有效地促进社会的利益。 斯密是说，经济参与者受利己心所驱动，而市场上这只看不见的手指引这种利己心去促进总体的经济福利。 政府有时可以改善市场结果 产权(property rights):个人拥有并控制稀缺资源的能力 市场失灵(market failure):市场本身不能有效的配置资源的情况 外部性(externality):一个人的行为对旁观者福利的影响外部性的经典例子是污染 市场势力(market power):单个经济活动者(或某个经济活动小群体)对市场价格有显著影响的能力 我们需要政府的原因之一是：只有在政府实施规则并维持对市场经济至关重要的制度时，看不见的手才能施展其魔力。最重要的是，市场经济需要实施产权制度，以便个人可以拥有和控制稀缺资源。我们都依靠政府提供的警察和法律来实施我们对自己生产出来的东西的权利——而看不见的手依靠我们实施自己权利的能力。 然而，我们需要政府的另一个原因是：看不见的手是强有力的，但并不是无所不能的。政府干预经济并改变人们自己选择的资源配置的原因有两类：促进效率和促进公平。这就是说，大多数政策的目标要么是把经济蛋糕做大，要么是改变这个蛋糕的分割方式。 在存在外部性或市场势力的情况下，设计良好的公共政策可以提高经济效率。 即使看不见的手带来了有效率的产出，他也不能消除经济福利上巨大的不对称。根据某种政治哲学，这种不平等要求政府进行干预。实际上，许多公共政策，例如所得税和福利制度的目标就是要实现更平等的经济福利分配。 我们说政府有时可以改善市场结果并不意味着它总会这样。公共政策并不是天使制定的，而是由不完善的政治程序制定的。有时所设计的政策只是为了有利于政治上有权势的人；有时政策是由动机良好但信息不充分的领导人制定的。 整体经济如何运行决策和相互影响共同组成了经济。 一国的生活水平取决于它生产物品与服务的能力 生产率(productivity):每单位劳动投入所生产的物品与服务数量 世界各国生活水平的差别是惊人的。随着时间的推移，生活水平的变化也是巨大的。 几乎所有的生活水平的差别都可以归因于各国生产率的差别。 生产率和生活水平之间的基本关系是简单的，但它的意义却是深远的。如果生产率是生活水平的首要决定因素，那么，其他因素就应该是次要的。 当政府发行了过多货币时，物价上升 通货膨胀(inflation):经济中物价总水平的上升 在大多数严重或持续通货膨胀的情况下，罪魁祸首是货币量的增长。 当一国政府发行了大量本国货币时，货币的价值就下降了。由于高通货膨胀会让社会付出各种成本，所以世界各国的经济政策制定者都把保持低通货膨胀作为目标之一。 社会面临通货膨胀与失业之间的短期权衡取舍 经济周期(business cycle):就业和经济生产的波动 虽然在长期中，物价水平上升主要是货币增加的结果，但短期中，问题就变得更为复杂更具争议性。 大多数经济学家这样描述货币注入的短期效应： 经济中货币量增加刺激了社会的整体支出水平，从而增加了对物品与服务的需求 需求的增量随着时间的推移，会引起企业提高物价，但同时，它也鼓励企业雇佣更多的工人，并生产更多的产品与服务 服用更多的工人意味着更少的失业 你知道，支出链将以乘数扩大，并带来更高的收入和就业。人们看到了发生了的活动，但他们没有看到本来会发生的活动。 结论经济学十大原理： 人们如何做出决策 人们面临权衡取舍 某种东西的成本是为了得到它所放弃的东西 理性人考虑边际量 人们会对激励做出反应 人们如何相互影响 贸易可以使每个人的状况都变得更好 市场通常是组织经济活动的一种好方法 政府有时可以改善市场结果 整体经济如何运行 一国的生活水平取决于它生产物品与服务的能力 当政府发行了过多的货币时，物价上升 社会面临通货膨胀与失业之间的短期权衡取舍 像经济学家一样思考每个研究领域都有自己的语言和思考方式。经济学家也一样。供给、需求、弹性、比较优势、消费者剩余和无谓损失——这些术语也是经济学家语言的一部分。 作为科学家的经济学家先提出理论，再收集数据，然后分析数据，以努力证明或否定他们的理论。 科学方法：观察、理论和进一步观察在经济学研究中，进行实验往往是不可能的。通常不得不使用这个世界向他们提供的数据。为了寻找实验室实验的替代品，经济学家十分关注历史所提供的自然实验。 假设的作用当我们在研究政策变动在长短不同时间中的影响时，就会做出不同的假设。 经济模型经济学家也用模型来了解世界，但不是塑料模型，而通常是由图形和方程组成的模型。 第一个模型：循环流量图 循环流量图(circular-flow diagram):一个说明货币如何通过市场在家庭与企业之间流动的直观经济模型 生产要素(production factors):劳动、土地、资本等投入品被称为生产要素 企业用生产要素来生产产品和服务，家庭则拥有生产要素并消费企业生产的物品与服务。家庭与企业之间相互交易。 第二个模型：生产可能性边界 生产可能性边界(production possibilities frontier)：表示在可得到的生产要素与生产技术既定时，一个经济所能生产的产品数量的各种组合的图形。 由于资源是稀缺的因此并不是每一种想象的结果都是可行的。生产可能性边界表明了社会所面临的一种权衡取舍。 生产可能性边界表明在某一特定时期内生产不同物品之间的权衡取舍，但随着时间的推移，这种权衡取舍可以改变。生产可能性边界简化了复杂的经济，以便强调一些基本但极为重要的思想： 稀缺性、效率、权衡取舍、机会成本和经济增长。 微观经济学与宏观经济学尽管微观经济学和宏观经济学之间存在固有的联系，但这两个领域仍然是不同的。 微观经济学(micro economics)：研究家庭和企业如何做出决策，以及它们如何在市场上相互交易的学科。 宏观经济学(macro economics)：研究整体经济现象，包括通货膨胀、失业和经济增长的学科。 作为政策顾问的经济学家当经济学家试图去解释世界时，他们是科学家；当经济学家试图去帮助改变世界时，他们是政策顾问。 实证分析与规范分析一般来说，关于世界的表述有两种类型： 实证表述(positive statements)：试图描述世界是什么样子的观点。 规范表述(normative statements)：试图描述世界应该是什么样子的观点。 确定什么是好策略或什么是坏策略不仅仅是一个科学问题，它还涉及我们对伦理、宗教和政治哲学的看法。 经济学家意见分歧有两个基本原因： 经济学家可能对世界如何运行的不同实证理论的正确性看法不一致 经济学家可能有不同的价值观，因此对政策应该努力实现的目标有不同的规范观点 相互依存性与贸易的好处人们向你和其他消费者提供他们生产的物品与服务，是因为他们也得到了某种回报。 一个现代经济寓言每个人都可以通过专门从事自己最擅长的活动并从相互叫中获益。但是，当某个人在生产每一种物品上都较为擅长时，贸易的好处就不那么明显了。 生产可能性专业化和贸易 比较优势： 专业化的动力绝对优势 绝对优势(absolute advantage)：一个生产者用比另一个生产者更少的投入生产某种物品的能力。 机会成本与比较优势 机会成本(opportunity cost)：为了得到某种东西所必须放弃的东西。 比较优势(comparative advantage)：一个生产者以低于另一个生产者的机会成本生产某种物品的能力。 尽管一个人有可能在两种物品的生产上都具有绝对优势，但一个人却不可能在两种物品的生产上都具有比较优势。 比较优势与贸易专业化和贸易的好处不是基于绝对优势，而是基于比较优势。当每个人专门生产自己有比较优势的物品时，经济的总产量就增加了，经济蛋糕的变大可用于改善每个人的状况。 贸易可以使社会上的每个人都获益，因为它使人们可以专门从事他们具有比较优势的活动。 贸易的价格对从贸易中获益的双方而言，他们进行贸易的价格在两种机会成本之间。 比较优势的应用美国应该与其他国家进行贸易吗 进口品(imports)：在国外生产而在国内销售的物品。 出口品(exports)：在国内生产而在国外销售的物品。 每个国家都有许多具有不同利益的居民。即使国际贸易可以使国家作为一个整体的状况变好，但也会使一些人的状况变坏。但国际贸易并不像战争，在战争中有些国家是胜利者，而其他国家是失败者。贸易使所有国家都可以实现更大的繁荣。 市场如何运行 供给与需求的市场力量供给与需求是经济学家最经常——而且有充分的理由使用的两个词。供给与需求是使市场经济运行的力量。它们决定了每种物品的产量及其出售的价格。 市场与竞争 市场(market)：由某种物品或服务的买者与卖者组成的一个群体。 竞争市场(competitive market)：有许多买者与卖者，以至于每个人对市场价格的影响都微乎其微的市场。 我们假设市场是完全竞争的。为了达到此竞争的最高形式，一个市场必须具备两个特征： 可供销售的物品时完全相同的 买者与卖者人数众多，以至于没有任何一个买者或卖者可以影响市场价格 但是，并不是所有物品与服务都在完全竞争市场上出售。一些市场可能只有一个买者，而且这个卖者决定价格。这样的卖者被称为垄断者还有一些市场介于完全竞争和垄断这两种极端形式之间。 需求 价格与需求量之间的关系 需求量(quantity demanded)：买者愿意斌企鹅能够购买的一种物品的数量。 需求定理(law of demand)：认为在其他条件不变时，一种物品的价格上升，对该物品的需求量减少的观点。 需求表(demand schedule)：表示一种物品的价格与需求之间的关系的表格。 需求曲线(demand curve)：表示一种物品的价格与需求量之间关系的图形。 正常物品(normal good)：在其他条件相同时，收入增加引起需求量增加的物品。 低档物品(inferior good)：在其他条件相同时，收入增加引起需求量减少的物品。 替代品(substitutes)：一种物品价格的上升引起另一种物品需求量的增加的两种物品。 互补品(complements)：一种物品价格的上升引起另一种物品需求量的减少的两种物品。 影响买者的变量： 收入 价格 爱好 预期 其它 供给 价格与供给量之间的关系 供给量(quantity supplied)：卖者愿意并且能够出售的一种物品的数量。 供给定理(law of supply)：认为在其他条件不变时，一种物品的价格上升，该物品的供给量增加的观点。 供给表(supply schedule)：表示一种物品的价格与供给量之间的关系的表格。 供给曲线(supply curve)：表示一种物品的价格与供给量之间关系的图形。 使供给曲线移动的一些变量： 价格 技术 预期 卖者的数量 其它 供给与需求的结合 均衡(equilibrium)：市场价格达到使供给量与需求量相等的水平时的状态。 均衡价格(equilibrium price)：使供给与需求平衡的价格。 均衡数量(equilibrium quantity)：均衡价格下的供给量与需求量。 过剩(surplus)：供给量大于需求量的状态。 短缺(shortage)：需求量大于供给量的状态。 供求定力(law of supply and demand)：认为任何一种物品的价格都会自发调整，使该物品的供给与需求达到平衡的观点。 价格如何配置资源在市场经济中，价格是配置稀缺资源的机制。 弹性假设某件事情使得汽油价格上升，那么消费者将少买汽油。那么汽油的消费量会减少多少呢？——这个问题可以用弹性的概念来回答。 需求弹性 弹性(elasticity)：衡量需求量或供给量对某种决定因素的变动的反应程度的指标。 需求价格弹性(price elasticity of demand)：衡量一种物品需求量对其价格变动反应程度的指标，用需求量变动百分比除以价格变动百分比来计算。 总收益(total revenue)：一种物品的买者支付而卖者得到的量，用该物品的价格乘以销售量来计算。 需求收入弹性(income elasticity of demand)：衡量一种物品需求量对消费者收入变动反应程度的指标，用需求量变动百分比除以收入变动百分比来计算。 需求交叉价格弹性(cross-price elasticity of demand)：衡量一种物品需求量对另一种物品价格变动的反应程度的指标，用第一种物品需求量变动百分比除以第二种物品价格变动百分比来计算。 富有弹性 缺乏弹性 单位弹性 完全无弹性 完全有弹性 替代品 必需品 奢侈品 市场的定义 时间范围 供给弹性 供给价格弹性(price elasticity of supply)：衡量一种物品供给量对其价格变动反应程度的指标，用供给量变动百分比除以价格变动百分比来计算。 供给、需求和弹性的应用 农业的好消息可能对农民来说是坏消息吗 为什么石油输出国组织不能保持石油的高价格 禁毒增加了还是减少了毒品相关的犯罪 供给、需求与政府政策当决策者认为一种物品或服务的市场价格对买者或卖者不公平时，通常会实施价格控制。但这些控制政策本身也会引起不公平。决策者用税收为公共目标筹集资金并影响市场结果。 价格控制 价格上限(price ceiling)：出售一种物品的法定最高价格 价格下限(price floor)：出售一种物品的法定最低价格 由于任何一种物品的买者总希望价格更低，而卖者总希望价格更高。所以，这两个群体的利益就会产生冲突 当政府对竞争市场实行限制性价格上限时，就产生了物品的短缺，而且，卖者必须在大量潜在买者中配给稀缺物品。与此相比，一个自由竞争市场中的配给机制既有效率又是客观的。 价格有平衡供求从而协调经济活动的关键作用。当决策者通过法令确定价格时，他们就模糊了正常情况下指引社会资源配置的信号。 价格控制的目标往往是帮助穷人。但价格控制往往损害了那些它本想要帮助的人。可以用除了控制价格以外的其他方法来帮助那些需要帮助的人(如补贴或减税)。但是，税收也是有成本的。 税收 税收归附(塔下 incidence)：税收负担在市场参与者之间进行分配的方式。 当政府对一种物品征税时，谁实际承担了税收负担？无论税收是向买者征税还是想卖者征税，这一买者价格与卖者价格之间的楔子都是相同的。在这两种情况下，这个楔子都使供给曲线和需求曲线的相对位置移动。在新均衡时，都是买者与卖者分摊税收负担。无论向谁征税，一旦市场达到新均衡，都是买者与卖者分摊税收负担。 经济受两种规则体系支配： 供求规律和政府制定的法规。 市场和福利消费者、生产者与市场效率买者总想少付些钱，而卖者总想多买些钱。 福利经济学(welfare economics)研究资源配置如何影响经济福利的一门学问。 消费者剩余 支付意愿(willingness to pay)买者愿意为某种物品支付的最高量。 消费者剩余(consumer surplus)买者愿意为一种物品支付的量减去其为此实际支付的量。 生产者剩余 成本(cost)卖者为了生产一种物品而必须放弃的所有东西的价值。 生产者剩余(producer surplus)卖者出售一种物品得到的量减去其生产成本。 市场效率 总剩余消费者剩余和生产者剩余的总和，称为总剩余。 效率(efficiency)资源配置使社会所有成员得到的总剩余最大化的性质。 平等(equality)在社会成员中平均地分配经济成果的性质。 市场势力影响价格的能力，如市场上一小群能够控制市场价格的买卖者。 外部性市场的副作用，如污染。 在本质上，从市场贸易中获取的利益就像一块要在市场参与者间分配的蛋糕。效率问题涉及的是蛋糕是否尽可能地做大了。平等问题涉及的是如何把这块蛋糕切成小块，以及如何在社会成员中进行分配。 市场失灵是指一些不受管制的市场不能有效地配置资源。当出现市场失灵时，公共政策有可能纠正这些问题并提高经济效率。 赋税的代价买者和买者因税收遭受的损失大于政府筹集到的收入。 赋税的无谓损失 无谓损失(deadweight loss)市场扭曲(如税收)引起的总剩余减少。 税收引起的无谓损失是因为它使买者和卖者不能实现某些贸易的好处。 决定无谓损失的因素供给和需求的价格弹性越大，税收的无谓损失也就越大。 税收变动时无谓损失和税收收入税收很少长期保持不变。 当政府对一种商品的买者或卖者征税时，社会就损失了某些市场效率的好处。税收给市场参与者带来了损失，不仅是因为税收将资源从市场参与者手中转到政府手中，还因为税收改变了激励，并扭曲了市场结果。 国际贸易许多企业发现，由于面临可以以低成本生产高质量物品的外国竞争者，要通过生产某种产品获得利润已经越来越困难了。因此，他们迁移或关闭了工厂。 决定贸易的因素 世界价格(world price)一种物品在世界市场上通行的价格。 如果某种物品的世界价格高于国内价格，那么，一旦允许贸易，此国就会变成此物品出口国；反之，则变为此物进口国。各国之间的贸易最终要建立在比较优势的基础之上。 贸易的赢家与输家 关税(tariff)对在国外生产而在国内销售的物品征收的一种税。 当一国允许贸易并成为一种物品的出口国时，国内该物品的生产者的状况变好了，而国内该物品消费者的状况变坏了。 从赢家收益超过了输家损失的意义上说，贸易使一国的经济福利增加了。 当一国允许贸易并成为一种物品的进口国时，国内该物品消费者的状况变好了，而国内该物品生产者的状况变坏了。 从赢家收益超过了输家损失的意义上说，贸易使一国的经济福利增加了。 国际贸易的其它好处： 增加了物品的多样性 通过规模经济降低了成本 增加了竞争 加强了思想交流 关税减少了进口量，并使国内市场向没有贸易时的均衡移动 各种限制贸易的观点 工作岗位论贸易反对者会说，与其他国家进行贸易消灭了国内的一些工作岗位。但自由贸易在消灭了一些工作岗位的同时，也创造了一些工作岗位。 国家安全论一些行业收到来自其他国家的竞争威胁时，贸易反对者会说，该行业对国家安全是至关重要的。处于对国家安全的合理考虑，保护关键行业可能是合理的。但也应该由国家机构所提出。 幼稚产业论会说，应实行暂时性贸易限制，以有助于该产业的成长。这也难以实施。如何确定哪个产业是新兴的幼稚产业？ 不公平竞争论一种常见的观点是，如果不同国家的企业服从于不同的法律和管制，那么，让企业在国际市场上进行竞争就是不公平的。 作为讨价还价筹码的保护论当与自己的贸易伙伴讨价还价时，贸易限制可能还是有用的。 大多数经济学家支持自由的国际贸易，他们认为自由贸易是一种有效配置生产的方法，并提高了两国的生活水平。 公共部门经济学 外部性 外部性(externality)一个人的行为对旁观者福利的无补偿的影响 正外部性这种影响是有利的 负外部性这种影响是不利的 栗子： 汽车尾气 修复历史建筑 狂吠的狗 新技术的研究 外部性和市场无效率 外部性内在化(internalizing the externality)改变激励，以使人们考虑到自己行为的外部效应 政府可以通过对负外部性的物品征税和给予有正外部性的物品补贴来使外部性内在化 针对外部性的公共政策 管制政府可以通过规定或禁止某些行为来解决外部性。 矫正税旨在引导私人决策者考虑负外部性引起的社会成本的税收 补贴 可交易的污染许可证 外部性的私人解决方法 科斯定理(Coase theorem)认为如果私人各方面可以无成本地就资源配置进行协商，那么，他们就可以自己解决外部性问题的观点 交易成本(transaction cost)各方在达成协议与遵守协议过程中所发生的成本 公共物品和公共资源 不同类型的物品 排他性(excludability)一种物品具有的可以阻止一个人使用该物品的特性 消费品中的竞争性(rivalry in consumption)一个人使用一种物品将减少其他人对该物品的使用的特性 私人物品(private goods)既有排他性又有消费竞争性的物品 公共物品(public goods)即无排他性又无消费竞争性的物品 公共资源(common resources)有消费竞争性但无排他性的物品 俱乐部物品(club goods)有排他性但无消费竞争性的物品 公共物品产权的重要性 搭便车者(free rider)得到一种物品的利益但避免为此付费的人 一些重要的公共物品 国防 基础研究 反贫困 成本收益分析(cost-benefit analysis)比较提供一种公共物品的社会成本与社会收益的研究 公共资源 公共悲剧(Tragedy of the Commons)一个说明从整个社会的角度看，为什么公共资源的使用大于合意的水平的寓言 一些重要的公共资源 清洁的空气和水 拥堵的道路 野生动物 税制的设计在这个世界上除了死亡和税收以外，没有什么事情是确定无疑的。 政府的财政状况政府的税收占国民收入的多少？ 预算赤字(budget deficit)政府支出大于政府收入 预算盈余(budget surplus)政府收入大于政府支出 税收和效率税收会引起两个成本，良好的税收政策正是要使其最小化： 当税收扭曲了人们做出的决策时引起的无谓损失 纳税人在遵照税法纳税时承担的管理负担 收入税 消费税 平均税率(average tax rate)支付的总税收除以总收入 边际税率(marginal tax rate)增加1美元收入所支付的额外税收 定额税(lump-sum tax)对每个人等量征收的税收 税收和平等 受益原则(benefit principle)认为人们应该根据他们从政府服务中得到的利益来纳税的思想 支付能力原则(ability-to-pay principle)认为应该根据一个人可以承当的负担来对这个人征税的思想 纵向平等(vertical equity)主张支付能力更强的纳税人应该缴纳更多税收的思想 横向平等(horizontal equity)主张有相似支付能力的纳税人应该缴纳等量税收的思想 比例税(proportional tax)高收入纳税人和低收入纳税人缴纳收入中相同比例的税收 累进税(progressive tax)高收入纳税人缴纳的税收在收入中的比例高于低收入纳税人的这一比例 累退税(regressive tax)高收入纳税人缴纳的税收在收入中的比例低于低收入纳税人的这一比例 企业行为与产业组织 生产成本经济是由成千上万个生产你每天享用的物品与服务的企业(大型或小型)组成的。 产业组织研究企业有关价格和数量的决策如何取决于它们所面临的市场条件。 企业成本是其生产和定价决策的一个关键决定因素。 生么是成本总收益、总成本和利润 总收益(total revenue)企业出售其产品所得到的货币量 总成本(total cost)企业用于生产的投入品和市场价值 利润(profit)总收益减去总成本 作为机会成本的成本 显性成本(explicit costs)需要企业支出货币的投入成本 隐性成本(implicit costs)不需要企业支出货币的投入成本 作为一种机会成本的资本成本 经济利润与会计利润 经济利润(economic profit)总收益减去总成本，包括显性成本与隐性成本 会计利润(accounting profit)总收益减总显性成本 生产与成本 生产函数 生产函数(production function)用于生产一种物品的投入量与该物品产量之间的关系 边际产量(marginal product)增加一单位投入所引起的产量增加 边际产量递减(diminishing marginal product)一种投入的边际产量随着投入量增加而减少的特征 从生产函数到总成本曲线 成本的各种衡量指标 固定成本与可变成本 固定成本(fixed costs)不随着产量变动而变动的成本 可变成本(variable costs)随着产量变动而变动的成本 平均成本与边际成本 平均总成本(average total cost)总成本除以产量 平均固定成本(average fixed cost)固定成本除以产量 平均可变成本(average variable cost)可变成本除以产量 边际成本(marginal cost)额外一单位产量所引起的总成本的增加 成本曲线及其形状 有效规模(efficient scale)使平均总成本最小的产量 只要边际成本小于平均总成本，平均总成本就下降；反之，则上升。边际成本曲线与平均总成本曲线在平均总成本曲线的最低点处相交。 典型的成本曲线 三个特征： 随着产量增加边际成本最终会上升 平均总成本曲线是U形的 边际成本曲线与平均总成本曲线在平均总成本曲线的最低点处相交 短期成本与长期成本 短期与长期平均总成本之间的关系 规模经济与规模不经济 规模经济(economics of scale)长期平均总成本随产量增加而减少的特性 规模不经济(diseconomics of scale)长期平均总成本随产量增加而增加的特性 规模收益不变(constant returns to scale)长期平均总成本在产量变动时保持不变的特性 实际上，运用专业化实现规模经济是现代社会之所以这样繁荣的原因之一。 竞争市场上的企业如果每个买者和卖者与市场规模相比都微不足道，从而没有什么能力影响市场价格那么该市场就是竞争性的。于此相反，如果一个企业可以影响它出售的物品的市场价格，我们就说该企业有市场势力。 什么是竞争市场 竞争市场的含义 竞争市场(competitive market)有时又称为完全竞争市场。有几个特征： 市场上有许多买者和许多卖者 各个卖者提供的物品大体上是相同的 企业可以自由地进入或退出市场 竞争企业的收益 平均收益(average revenue)总收益除以销售量对所有企业而言，平均收益等于物品的价格 边际收益(marginal revenue)增加一单位销售量引起的总收益变动对竞争企业而言，边际收益等于物品的价格 利润最大化与竞争企业的供给曲线 利润最大化 边际成本曲线和企业的供给决策 利润最大化的一般规律： 如果边际收益大于边际成本，企业应该增加其产量 如果边际成本大于边际效益，企业应该减少其产量 在利润最大化的产量水平时，边际收益和边际成本正好相等 企业的短期停止营业决策 如果生产能得到的收益小于生产的可变成本，企业就停止营业。 覆水难收和其他沉没成本 沉没成本(sunk cost)已经发生而且无法收回的成本 在做个人决策时，沉没成本的无关性也是很重要的。 企业退出或进入一个市场的长期决策 如果从生产中得到的收益小于它的总成本，企业就应该退出市场。竞争企业的长期供给曲线是边际成本曲线位于平均总成本曲线之上的那一部分。 竞争市场的供给曲线两种情况： 考察有固定数量企业的市场； 考察企业数量会随着老企业退出和新企业进入而变动的市场 垄断可以说微软在Windows软件市场上拥有垄断地位。像微软这样的垄断者没有与之相近的竞争者，因此，它拥有影响其产品的市场价格的力量。竞争企业是价格接受者，而垄断企业是价格决定者。 竞争企业接受市场给定的其产品的价格，并选择供给量，以使价格等于边际成本。与此相比，垄断者收取高于其边际成本的价格。 垄断者对其产品收取高价格并不令人奇怪。垄断者的顾客似乎除了一个支付垄断者收取的价格之外别无选择。一个垄断企业可以控制它出售的物品的价格，但由于高价格会减少其顾客的购买量，因此垄断利润并不是无限的。 由于垄断企业不受竞争限制，有垄断的市场结果往往不符合社会的最佳利益。但政府有时可以改善市场结果。 为什么会产生垄断 垄断企业(monopoly)作为一种没有相近替代品的产品的唯一卖者的企业。 有三个主要形成原因： 垄断资源： 生产所需要的关键资源由单个企业所拥有 政府管制： 政府给予单个企业排他性地生产某种物品或服务的权利 生产流程： 某个企业能以低于大量企业的成本生产产品 专利法或版权法是两个重要的例子。 自然垄断(natural monopoly)由于一个企业能以低于两个或更多企业的成本向整个市场供给一种物品或服务而产生的垄断 垄断者如何做出生产与定价策略 垄断与竞争 垄断者的收益 利润最大化 垄断者的利润 垄断的福利代价 无谓损失 可以在需求曲线与边际成本曲线相交之处找出社会有效率的产量。垄断者生产的产量小于社会有效率的产量。 垄断利润：是一种社会代价吗 价格歧视 价格歧视(price discrimination)以不同的价格向不同顾客出售同一种物品的经营做法。 套利在一个市场上以低价购买一种商品，而在另一个市场上以高价出售，以便从价格差中获利的过程。 价格歧视的例子 电影票 飞机票 折扣券 财务援助 数量折扣 针对垄断的公共政策政府决策者应对垄断： 努力使垄断行业更有竞争性用反托拉斯法增强竞争。反托拉斯法是一部全面的经济自由宪章，其目的在于维护作为贸易的自由和不受干预的竞争。 管制管制垄断者的行为 公有制政府自己经营自然垄断的企业 不作为do nothing 垄断竞争 在垄断和完全竞争之间很多行业介于完全竞争和垄断的极端情况之间的某个位置，经济学家称这种情况为不完全竞争。 寡头(oligopoly)只有少数几个提供相似或者相同产品的卖者的市场结构。 垄断竞争(monopolistic competition)存在许多出售相似但不相同的产品的企业的市场结构。 垄断竞争和寡头一样，也是介于竞争和垄断这两种极端情况之间的一种市场结构。 垄断竞争具有以下特征的市场： 许多卖者： 有许多企业争夺相同的顾客群体 产品存在差别： 每个企业生产的一种产品至少与其他企业生产的这种产品略有不同 自由进入和退出：企业可以无限制地进入或退出一个市场 差别产品的竞争 短期中的垄断竞争企业 长期均衡 垄断竞争与完全竞争 垄断竞争与社会福利 广告在现代经济中，几乎每一天都伴随着铺天盖地的广告。这种行为是垄断竞争(以及某些寡头企业)的一个自然特征。 关于广告的争论 作为质量信号的广告 品牌 垄断竞争，顾名思义，是垄断和竞争的混合。由于垄断竞争企业生产有差别的产品，因此，每个企业都要靠做广告打出自己的品牌来吸引顾客。在某种程度上，广告操纵了消费者的偏好，促成了非理性的品牌忠诚，并抑制了竞争。在更大程度上，广告提供了信息，建立了具有可靠质量的品牌，并促进了竞争。 寡头]]></content>
      <categories>
        <category>Economics</category>
      </categories>
      <tags>
        <tag>Economics</tag>
        <tag>经济学</tag>
        <tag>Zhang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2F2018%2F02%2F08%2FRegularExpression%2F</url>
    <content type="text"><![CDATA[参考： 《鸟哥的Linux私房菜》 正则表达式维基百科 正则表达式介绍正则表达式，又称正规表示式、正规表示法、正规表达式、规则表达式、常规表示法(Regular Expression, 在代码中常简写为regex、regexp或RE）。是计算机科学的一个概念。正则表达式使用单个字符串来描述、匹配一系列匹配某个句法规则的字符串。在很多文本编辑器里，正则表达式通常被用来检索、替换那些匹配某个模式的文本。 正则表达式的POSIX规范，分为两大流派： 基本型正则表达式（Basic Regular Expression，BRE） grep、vi、sed都属于BRE，是历史最早的正则表达式，因此元字符必须转译之后才具有特殊含义 扩展型正则表达式（Extended Regular Express，ERE） egrep、awk则属于ERE，元字符不用转译 正则表达式基本语法一个正则表达式通常被称为一个模式（pattern），用来描述或者匹配一系列匹配某个句法规则的字符串。 大部分正则表达式有如下结构： 选择 |竖线符代表选择(或)，具有最低优先级 数量限定 字符后的数量限定符用来限定前面这个字符允许出现的个数 不加数量限定则代表仅出现一次 常见的数量限定符包括 +、?、* +加号代表前面的字符必须至少出现一次 ( $$$&gt;=1$$$ ) ?问号代表前面的字符最多只可出现一次 ( $$$1&gt;=?&gt;=0$$$ ) *星号代表前面的字符可不出现，也可出现一次或多次 ($$$&gt;=0$$$) 匹配 ()圆括号可以定义操作符的范围和优先度 PCRE表达式全集正则表达式有多种不同的风格。PCRE（Perl兼容正则表达式，Perl Compatible Regular Expression）。适用于Perl或者Python编程语言（grep或者egrep的正则表达式文法是PCRE的子集） 基础正则表达式 字符 描述 \ 转义字符 zhang 匹配文本字符串值zhang . 匹配除\r,\n之外的任何单个字符 竖线l 匹配竖线两边某一个 ^ 匹配输入字符串的开始位置 $ 匹配输入字符串的结束位置 * 匹配前面的子表达式零次或多次 + 匹配前面的子表达式一次或多次 ? 匹配前面的子表达式零次或一次 {n} n是一个非负整数。匹配n次 {n,} n是一个非负整数。至少匹配n次 {n,m} m和n均为非负整数，匹配n-m次 [xyz] 字符集合（character class）。匹配所包含的任意一个字符 xyz 排除型字符集合（negated character classes）。匹配未列出的任意字符 [a-z] 字符范围。匹配指定范围内的任意字符 a-z 排除型的字符范围。匹配任何不在指定范围内的任意字符 [:name:] 增加命名字符类（named character class） [=elt=] 增加当前locale下排序（collate）等价于字符“elt”的元素 [.elt.] 增加排序元素（collation element）elt到表达式中。这是因为某些排序元素由多个字符组成 元字符元字符(meta character)，是一种Perl风格的正则表达式，只有一部分文本处理工具支持它。 字符 描述 \b 匹配一个单词边界，也就是指单词和空格间的位置 \B 匹配非单词边界。“er\B”能匹配“verb”中的“er”，但不能匹配“never”中的“er” \cx 匹配由x指明的控制字符 \d 匹配一个数字字符。等价于[0-9]。注意Unicode正则表达式会匹配全角数字字符 \D 匹配一个非数字字符。等价于0-9 \f 匹配一个换页符。等价于\x0c和\cL \n 匹配一个换行符。等价于\x0a和\cJ \r 匹配一个回车符。等价于\x0d和\cM \s 匹配任何空白字符，包括空格、制表符、换页符等等 \S 匹配任何非空白字符。等价于 \f\n\r\t\v \t 匹配一个制表符。等价于\x09和\cI \v 匹配一个垂直制表符。等价于\x0b和\cK \w 匹配包括下划线的任何单词字符。等价于“[A-Za-z0-9_]”。注意Unicode正则表达式会匹配中文字符 \W 匹配任何非单词字符。等价于“A-Za-z0-9_” \ck 匹配控制转义字符。k代表一个字符。等价于“Ctrl-k”。用于ECMA语法 \xnn 十六进制转义字符序列。匹配两个十六进制数字nn表示的字符 \num 向后引用（back-reference）一个子字符串（substring），该子字符串与正则表达式的第num个用括号围起来的捕捉群（capture group）子表达式（subexpression）匹配。其中num是从1开始的十进制正整数，其上限可能是9[注 2]、31、[注 3]99甚至无限。[注 4]例如：“(.)\1”匹配两个连续的相同字符 \n 标识一个八进制转义值或一个向后引用。如果\n之前至少n个获取的子表达式，则n为向后引用。否则，如果n为八进制数字（0-7），则n为一个八进制转义值 \nm 3位八进制数字，标识一个八进制转义值或一个向后引用。如果\nm之前至少有nm个获得子表达式，则nm为向后引用。如果\nm之前至少有n个获取，则n为一个后跟文字m的向后引用。如果前面的条件都不满足，若n和m均为八进制数字（0-7），则\nm将匹配八进制转义值nm \nml 如果n为八进制数字（0-3），且m和l均为八进制数字（0-7），则匹配八进制转义值nml \un Unicode转义字符序列。其中n是一个用四个十六进制数字表示的Unicode字符 扩展正则表达式 字符 描述 ? 非贪心量化（Non-greedy quantifiers）：当该字符紧跟在任何一个其他重复修饰符（*,+,?，{n}，{n,}，{n,m}）后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串 (pattern) 匹配pattern并获取这一匹配的子字符串。该子字符串用于向后引用。所获取的匹配可以从产生的Matches集合得到，在VBScript中使用SubMatches集合，在JScript中则使用$0…$9属性。要匹配圆括号字符，请使用“(”或“)” (?:pattern) 匹配pattern但不获取匹配的子字符串（shy groups)，也就是说这是一个非获取匹配，不存储匹配的子字符串用于向后引用 (?=pattern) 正向肯定预查（look ahead positive assert），在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用 (?!pattern) 正向否定预查(negative assert)，在任何不匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用 (?&lt;=pattern) 反向(look behind)肯定预查，与正向肯定预查类似，只是方向相反 (?&lt;!pattern) 反向否定预查，与正向否定预查类似，只是方向相反 POSIX字符组POSIX字符类(POSIX character class),是一个形如[:…:]的特殊元序列，它用于匹配特定的字符范围。 POSIX字符组 说明 ASCII环境 Unicode环境 [:alnum:] 字母字符和数字字符 [a-zA-Z0-9] [\p{L&amp;}\p{Nd}] [:alpha:] 字母 [a-zA-Z] \p{L&amp;} [:ascii:] ASCII字符 [\x00-\x7F] \p{InBasicLatin} [:blank:] 空格字符和制表符 [ \t] [\p{Zs}\t] [:cntrl:] 控制字符 [\x00-\x1F\x7F] \p{Cc} [:digit:] 数字字符 [0-9] \p{Nd} [:graph:] 空白字符之外的字符 [\x21-\x7E] \p{Z}\p{C} [:lower:] 小写字母字符 [a-z] \p{Ll} [:print:] 类似[:graph:]，但包括空白字符 [\x20-\x7E] \P{C} [:punct:] 标点符号 }~-] [\p{P}\p{S}] [:space:] 空白字符 [ \t\r\n\v\f] [\p{Z}\t\r\n\v\f] [:upper:] 大写字母字符 [A-Z] \p{Lu} [:word:] 字母字符 [A-Za-z0-9_] [\p{L}\p{N}\p{Pc}] [:xdigit:] 十六进制字符 [A-Fa-f0-9] [A-Fa-f0-9] 优先级 优先权 符号 最高 \ 高 ( )、(?: )、(?= )、[ ] 中 *、+、?、{n}、{n,}、{m,n} 低 ^、$、中介字符 次最低 串接，即相邻字符连接在一起 最低 l]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>RegularExpression</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis]]></title>
    <url>%2F2018%2F02%2F05%2FRedis%2F</url>
    <content type="text"><![CDATA[参考: 《Redis官方文档》: http://www.redis.cn/documentation.html 《Redis命令大全》: http://www.redis.cn/commands.html 环境: CentOS7x86_64 Redis 3.2 简介 Redis是什么Redis是一个使用ANSI C编写的开源、支持网络、基于内存、可选持久性的、非关系型,键值对存储数据库。Redis是一个开源(BSD许可)的,内存中的数据结构存储系统,它可以用作数据库、缓存和消息中间件。 毫无疑问,Redis开创了一种新的数据存储思路,使用Redis,我们不用在面对功能单调的数据库时,把精力放在如何把大象放进冰箱这样的问题上,而是利用Redis灵活多变的数据结构和数据操作,为不同的大象构建不同的冰箱。希望你喜欢这个比喻。 Remote Dictionary Server(Redis)是由一个Salvatore Sanfilippo写的key-value储存系统。Redis提供了一些丰富的数据结构,包括lists,sets,ordered sets,hashes,当然还有和Memcached一样的string结构,所以常被称为是一款数据结构服务器(data structure server)。Redis当然还包括了对这些数据结构的丰富操作。 你可以在这些类型上面运行原子操作,例如,追加字符串,增加哈希中的值,加入一个元素到列表,计算集合的交集、并集和差集,或者是从有序集合中获取最高排名的元素。 Redis的优点为了满足性能,Redis采用内存(in-memory)数据集(dataset)。根据你的使用场景,你可以通过每隔一段时间转储数据集到磁盘,或者追加每条命令到日志来持久化。持久化也可以被禁用,如果你只是需要一个功能丰富,网络化的内存缓存。 性能极高,Redis能支持超过100K+每秒的读写频率 丰富的数据类型,Redis支持二进制案例的Strings,Lists,Hashes,Sets及Ordered Sets数据类型操作 原子,Redis的所有操作都是原子性的,同时Redis还支持对几个操作全并后的原子性执行 丰富的特性,Redis还支持publish/sucscribe,通知,key过期等特性 Redis还支持主从异步复制,非常快的非阻塞初次同步、网络断开时自动重连局部重同步 安装直接通过yum安装: 1yum install -y redis 启动redis-server的两种方式: redis-server: standalone模式 systemctl redis start: daemon模式 需要在配置文件中开启daemonize 启动redis-cli: 12redis-cliredis-cli -a passwd 配置redis配置文件(/etc/redis.conf)常用参数: 参数 说明 daemonize 以守护进程启动,放置于后台 bind 监听地址,建议只对本地127.0.0.1开放 protect-mode redis的保护模式 requirepass 设置密码 timeout 超时 tcp-keepalive 在Linux上,指定值(秒)用于发送ACKs的时间,关闭连接需要双倍的时间,默认为0 loglevle 指定日志记录的级别。有四个级别:debug(记录很多信息,用于开发测试)、notice(常用于生产环境)、warning(严重的信息)、verbose(有用的信息) logfile 日志文件,默认为stdout databases 可用数据库,范围在0-(database-1) save 保存数据到磁盘(.rdb) stop-writes-on-bgsave-error 后台储存错误停止写 rdbcompression 储存到本地数据库时(持久化到rdb文件)是否压缩 dbfilename 本地持久化数据库文件名,默认dump.rdb dir 数据库文件路径,是目录 salveof 设置从库 masterauth 设置主库认证的密码 slave-read-only 设置slave是否只读 slave-serve-stale-data 从库同主库失去连接或复制正在进行时,从库是否继续响应客户端请求 repl-disable-tcp-nodelay tcp-nodelay slave-priority slave优先级,master不能工作后,从众多slave中选出优先值最小的slave提升为master,优先值为0表示不能为master appendonly 是否开启AOF数据备份,redis会把所接收到的每一次写操作请求都追加到appendonly.aof文件,当此文件很大 appendsync AOF文件同步策略,后台会进行大量I/O no-appendfsync-on-rewrite - auto-aof-rewrite-percentage aof自动重写 auto-aof-rewrite-min-size 指定最小大小用于aof重写 slowlog-log-slower-than 慢日志,记录超过特定执行时间的命令,不包括I/o slowlog-max-len 慢日志记录的长度,超过大小,最先进入队列的记录会被踢出 hash-max-zipmap-entries hash将以一种特殊的编码方式(大大减少内存使用)来储存,这是其中一个临界值 hash-max-zipmap-value 另一个临界值 list-max-ziplist-entries 多个list以特定的方式编码来节省空间 activerehashing Redis将在每100ms时使用1ms的CPU时间来对redis的hash表进行重新hash,可降低内存的使用 hz 不是所有任务都以相同的频率执行,但redis按照指定的“hz”值执行检查任务 aof-rewrite-incremental-fsync 当一个子节点重写AOF文件时,则文件每生产32m数据进行同步 官方文档对VM的使用建议: 当KEY很小而VALUE很大时,使用VM的效果会比较好,因为这样节约内存比较大 当key不小时,可以考虑使用一些非常方法将很大的key变成value,比如将key,value组合成一个新的value 数据类型Redis不仅仅是简单的key-value存储器,同时也是一种data structure server。传统的key-value是指支持使用一个key字符串来索引value字符串的储存。而Redis中,value不仅仅支持字符串,还支持更多的复杂结构,包括列表、集合、哈希表等。Redis采用二进制安全,这就意味着你可以使用任何二进制序列作为重点。 字符串(strings)字符串 是一种最基本的Redis值类型。Redis字符串是二进制安全的,这意味着一个Redis字符串能包含任意类型的数据。 只关心二进制化的字符串,不关心具体格式。只会严格的按照二进制的数据存取。不会妄图已某种特殊格式解析数据。 列表(lists)Redis列表是简单的字符串列表,按照插入顺序序列,你可以添加一个或多个元素到列表的头部或者尾部。 散列(hash)Redis Hashes是字符串字段和字符串值之间的映射,因此他们是展现对象的完美数据类型。如一个有姓、名、年龄等属性的用户。一个带有一些字段的hash仅仅需要一块很小的空间储存,因此你可以储存数以百万计的对象在一个小的Redis实例中。 哈希主要用来表现对象,他们有能力储存很多对象,因此你可以将哈希用于许多其他的任务。 无序集合(unorder set)Redis集合(Set)是一个无序的字符串集合。可以用O(1)的时间复杂度(无论集合中有多少元素时间复杂度都是常量)完成添加、删除、测试元素是否存在。 Redis集合拥有令人满意的不允许包含相同成员的属性。多次添加相同的元素,最终在集合里只会有一个元素。实际上就是添加元素时无序检测元素是否存在。 一个Redis集合有趣的事情是它支持一些服务端的命令从现有的集合出发去进行集合运算,因此你可以在非常短的时间内进行合并(unions)、交集(intersections)、找出不同的元素(difference of sets)。 有序集合(order set)Redis有序集合与普通集合非常相似,也是一个没有重复项的字符串集合。不同之处是有序集合的每一个成员都关联了一个评分,这个评分被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的,但是评分可以是重复了。 使用有序集合可以以非常快的速度(O(log(N)))添加,删除和更新元素。可以很快根据评分(score)或者次序(position)来获取一个范围的元素。访问有序集合的中间元素也是很快的,因此能够使用有序集合作为一个没有重复成员的智能列表。在有序集合中,你可以很快捷的访问一切你需要的东西。 简而言之,使用有序的集合你可以做完许多对性能有极端要求的任务,而那些任务使用其他类型的数据库真的是很难完成。 命令 常用命令123456789101112131415161718192021exists key #判断一个key是否存在del key #删除某个或一系列keytype key #返回某个key元素的数据类型,key不存在返回空keys key-pattern #返回匹配的key列表randomkey #随机获取一个已经存在的keyrename oldname newname #改key的名字,如果存在将会覆盖dbsize #返回当前数据库的key的总和expire key time #设置某个key的过期时间(秒),到期后自动删除ttl #查询key剩余存活时间flushdb #清空当前数据库中的所有键flushall #清空所有数据库中的键 设置相关12345config get #用来读取Redis服务器的配置参数config set #用于更改运行Redis服务器的配置参数config resetstat #重置数据统计报告,通常返回OK 连接操作12345quit #关闭连接auth #密码认证help command #帮助 持久化1234567save #将数据同步保存到磁盘bgsave #将数据异步保存到磁盘lastsave #返回上次成功将数据保存到磁盘的Unix时戳 远程服务1234567891011121314151617181920212223242526272829info #服务器信息统计,基本所有信息monitor #实时转储收到的请求slaveof #改变复制策略shutdown #将数据同步保存到磁盘,然后关闭服务server #Redis server的常规信息clients #Client的连接选项memory #存储占用相关信息persistence #RDB and AOF 相关信息stats #常规统计replication #Master/slave请求信息cpu #CPU占用信息统计cluster #Redis 集群信息keyspace #数据库信息统计all #返回所有信息default #返回常规设置信息 值(value)操作12345678910111213141516171819202122232425exists key #判断一个key是否存在del key #删除一个keytype key #返回值的类型keys pattern #返回满足给定模式的所有keyrandomkey #随机返回key空间的一个rename oldname newname #改key的名字,如果存在将会覆盖dbsize #返回当前数据库中key的数目expire #设定一个key的活动时间(s)ttl #获得一个key的活动时间select index #按索引查询move key dbindex #移动当前数据库中的key到dbindex数据库flushdb #删除当前选择的数据库中的所有keyflushall #删除所有数据库中的所有key 字符串(string)操作123456789101112131415161718192021222324252627set key value #给数据库中名称为key的string赋值valueget key #返回数据库中名为key的string的valuegetset key value #给名称为key的string赋予上一次的valuemget key1 key2 ... key N #返回库中多个string的valuesetnx key value #添加string 名称为key 值为valuesetex key time value #向库中添加string 设定过期时间timemset key 1 value 1 ... key N value N #批量设置多个string的值msetnx key 1 value 1 ... key N value N #如果所有名称为 key N的string都不存在 则向库中添加string 名称为 key N赋值value Nincr key #名称为key的string加 1 操作incrby key integer #名称为key的string增减integerdecr key #名称为key的string减1操作decrby key integer #名称为key的string的值附加valueappend key value #名称为key的值附加valuesubstr key start end #返回名称为key的string的value的子串 列表(list)操作12345678910111213141516171819rpush key value #在名称为key的list尾部添加一个值为value的元素lpush key value #在名称为key的list首部添加一个值为value的元素llen key #返回名称为key的list的长度lrange key start end #返回名称为key的list中start至end之间的元素 下表从0开始ltrim key start end #截取名称为key的list 保留start至end之间的元素lindex key index #返回名称为key的list中index位置的元素lset key index value #给名称为key的list中index位置的元素赋值valuelrem key count value #删除count个名称为key的list中值为value的元素brpop key1 key2 ... keyN #rpop的block版本rpoplpush srckey dstkey #返回并删除名为srckey的list尾元素 并将该元素添加到名为dstkey的list的头部 集合(set)操作123456789101112131415161718192021222324252627sadd key member #向名为key的set中添加元素membersrem key member #删除名为key的set中元素的memberspop key #随机返回并删除名为key的set中的一个元素smove srckey dstkey member #将member元素从名为srckey的集合移动到名为dstkey的集合scard key #返回名为key的set的基数sismember key member #测试member是否是名称为key的set的集合sinter key1 key2 ... key N #求交集sinterstore dstkey key1 ... key N #求交集并将交集保存到dstkey的集合sunion key1 ... key N #求并集sunionstore dstkey key 1 ... key N #求并集并将并集保存到dstkey的集合sdiff key1 ... key N #求差集sdiffstore dstkey key 1 ... key N #求差集并将差集保存到dstkey的集合smembers key #返回名为key的set的所有元素srandmember key #随机返回名为key的set的一个元素 有序集合(sorted set)操作12345678910111213141516zadd key score member #向名为key的zset中添加元素member score用于排序 如果该元素已经存在 则根据score更新该元素的顺序zrem key member #删除名为key的zset中的元素memberzincrby key increment member #如果在名为key的zset中已经存在元素member 则该元素的score增加increment 否则向集合中添加该元素 其score的值为incrementzrank key member #返回名为key的zset 顺序zrevrank key member #返回名为key的zset 倒序zrange key start end #返回名为key的zset score顺序按index从start到end返回所有元素zrevrange key start end #返回名为key的zset score倒序按index从start到end返回所有元素zrangebyscore key min max #返回名为key的zset中score大于等于min 小于等于max的所有元 hash操作123456789101112131415161718192021hset key field value #向名为key的hash中添加元素filed----valuehget key field #返回名为key的hash中field对应的valuehmset key field1 value1 ... field N value N #向名为key的hash中添加元素field----valuehmget key field1 ... field N #返回名为key的hash中filed对应的valuehincrby key field integer #将名为key的hash中field的value增加integerhexists key field #名为key的hash中是否存在键为field的域hdel key field #删除名为key的hash中键为field的域hlen key #返回名为key的hash中元素个数hkeys key #返回名为key的hash中所有键hvals key #返回名为key的hash中所有键对应的valuehgetall key #返回名为key的hash中所有的键 field 及其对应的value 高级应用Redis高级应用包括安全性设置、主从复制、事务处理、持久化机制和虚拟内存的使用。 安全性由于redis速度相当快，一秒钟可以150K次密码尝试，所以需要设置一个密码强度很强大的密码。 设置密码的两种方法： config set requirepass &quot;passwd&quot;，通过命令设置密码 直接在配置文件中requirepass属性后加上密码 认证登录的两种方式： redis-cli -a passwd redi-cli —&gt; auth passwd 主从复制Redis的主从复制的配置和使用都比较简单。 master server slave server Redis主从复制特点： 一主多从 当master宕机后，优先级值小的那台slave server自动转变为master 主从复制不同阻塞master，在同步数据时master可以继续处理client的请求 提高了系统的可伸缩性 Redis主从复制过程： slave与master建立连接，发送sync同步命令 master会启动一个后台进程，将数据库快照保存到文件中，同时master主进程会开始收集新的写命令并缓存 后台完成保存后，就将此文件发送给slave slave将文件保存在磁盘上 主从复制栗子Redis主从配置，一主多从。注意：由于redis吃内存，可能会由于内存过小而无法正常启动redis，可查看/var/log/message。 配置master： 123456789101112131415161718vim /etc/redis_master.confdaemon yesbind 127.0.0.1 ip1port 6379requirepass fuza_mimaprotect-mode yesdatebases 100logfile /var/log/redis/redis_master.logdir /var/lib/redis_mastermkdir /var/lib/redis_masterchown redis:redis /var/lib/redis_mastersystemctl start redis 配置slave： 123456789101112131415161718192021222324252627282930vim /etc/redis_slave.confdaemon yesbind 127.0.0.1port 6379protect-mode yeslogfile /var/log/redis/redis_slave.logdir /var/lib/redis_slaveslaveof &lt;master-ip&gt; &lt;master-port&gt;masterauth &lt;master-passwd&gt;slave-read-only yesslave-priority 100#master挂掉后，从slave中选出优先级最小的作为master······#其他具体主从参数自己配置mkdir /var/lib/redis_slavechown redis:redis /var/lib/redis_slavesystemctl start redis 测试master： 1234redis-cli -a xxxset name zhangget zhang 测试slave： 123456redis-cliauth(&apos;passwd&apos;)key *get zhang 注意： 由于Redis只是主从，并不像MongoDB的集群功能。当Redis master挂掉以后，虽然优先级较小的slave成为了master，但从库是无法更新数据的。这点也可以从Redis从的配置文件中看出，连接到Redis主的IP：PORT，并通过主的密码来认证。 高可用Redis的主从模式，并不支持高可用。不过，Redis引进了哨兵模式(sentinel)，提供Redis实时监控和故障检测恢复的功能。Redis Sentinel 是 Redis 的官方高可用解决方案，是设计用来帮助管理 Redis 实例的系统。 运行 Sentinel 强制使用配置文件，这个文件被系统用来保存当前状态，在重启时能重新加载。如果没有指定配置文件，或者配置文件的路径不可写，Sentinel 将拒绝启动。Sentinel 运行时默认监听 TCP 端口 26379，所以为了让 Sentinel 正常运行，你的服务器必须开放 26379 端口，以接受从其他 Sentinel 实例 IP 地址的连接。否则，Sentinel 间就没法通信，没法协调，也不会执行故障转移。 Redis Sentinel 是一个分布式系统，这意味着，你通常想要在你的基础设施中运行多个 Sentinel 进程，这些进程使用 gossip 协议来判断一台主服务器是否下线(down)，使用 agreement 协议来获得授权以执行故障转移，并更新相关配置。 1234The redis-sentinel command is a symbolic link to the redis-server command which imply the --sentionel option.redis-server [ configuration_file ] [ options ] --sentinelredis-sentinel [ configuration_file ] [ options ] Redis Sentinel用于完成如下4个任务： 监控(Monitoring)Sentinel 不断检查你的主从实例是否运转正常。 通知(Notification)Sentinel 可以通过 API 来通知系统管理员，或者其他计算机程序，被监控的Redis实例出了问题。 自动故障转移(Automatic failover)如果一台主服务器运行不正常，Sentinel 会开始一个故障转移过程，将从服务器提升为主服务器，配置其他的从服务器使用新的主服务器，使用 Redis 服务器的应用程序在连接时会收到新的服务器地址通知。 配置提供者(Configuration provider)Sentinel 充当客户端服务发现的权威来源：客户端连接到 Sentinel 来询问某个服务的当前 Redis 主服务器的地址。当故障转移发生时，Sentinel 会报告新地址。 配置文件Redis Sentinel示例配置文件： 只需要指定需要监控的主服务器，并给主服务器去一个名字；没有必要指定从服务器，因为它们会被自动发现；每一次故障转移时，将一台从服务器提升为主服务器都会重写配置文件；无论你指定多少个同意来检测实例是否正常工作，Sentinel 需要系统中已知的大多数 Sentinel 的投票才能开始故障转移，并且在故障转移之后获取一个新的配置纪元(configuration Epoch) 赋予新的配置； 1234567891011121314151617181920212223#默认26379端口#sentinel &lt;option_name&gt; &lt;master_name&gt; &lt;option_value&gt;#仲裁数为2sentinel monitor mymaster 127.0.0.1 6379 2#哨兵认为实例不可达的毫秒数sentinel down-after-milliseconds mymaster 60000#sentinel failover-timeout mymaster 180000#在一次故障转移之后，被配置为同时使用新主服务器的从服务器数量sentinel parallel-syncs mymaster 1# master 有密码就要使用,#sentinel auth-pass mymaster ****sentinel monitor resque 192.168.1.3 6380 4sentinel down-after-milliseconds resque 10000sentinel failover-timeout resque 180000sentinel parallel-syncs resque 5 事务处理Redis的事务处理比较简单。只能保证client发起的事务中的命令可以连续的执行，而且不会插入其他的client命令。 当一个client在连接中发出multi命令时，这个连接就进入一个事务的上下文，该连接后续的命令不会执行，而是存放在一个队列中，当执行exec命令时，redis会顺序的执行队列中的所有命令。如果其中执行出现错误，执行正确的不会回滚，不同于关系型数据库的事务。 持久化机制持久化就是把数据从内存保存到硬盘。 Redis是一个支持持久化的内存数据库，Redis需要经常将内存中的数据同步到磁盘来保证持久化。 Redis支持两种持久化方式： snapshotting(快照) 将数据存放到文件里，默认方式。默认写入dump.rdb二进制文件中 可配置redis在n秒内超过m个key被修改就自动做快照 save 500 10 —&gt; 500s内超过10个key被修改，则保存快照 由于快照方式在一定间隔时间做一次保存， 如果Redis意外down掉的话，就会丢失最后一次快照后的所有修改。AOF比快照方式有更好的持久化性，是由于使用aof时，redis会将每一个收到的写命令都通过write函数写入到文件中当redis启动时会通过重新执行文件中保存的写命令在内存中重新建立整个数据库的内容。 appendonly file(AOF) aof方式redis会将每一次的函数都追加到文件中，当redis重启时会重新执行文件中保存的命令 配置文件参数： 1234567891011#启用aof持久化方式appendonly yes#每秒写入磁盘一次，在性能和持久化方面做了很好的折中appendonly everysc#将数据写入磁盘save 900 1save 300 10save 60 10000 虚拟内存Redis的虚拟内存是暂时把不经常访问的数据从内存交换到磁盘中，从而腾出内存空间用于其它的访问数据。对于redis这样的内存数据库，内存总是不够用的。 在配置文件(/etc/redis.conf)中配置VM: 123456789101112131415161718#开启vm功能vm-enableyes#交换出来的value保存的文件路径vm-swap-file /tmp/redis.swap#redis使用的最大内存上线vm-max-memory 10000000#每个页面的大小32字节vm-page-size 32#最多使用多少个页面vm-pages 123217729#用于执行value对象换入的工作线程数量vm-max-threads 4 批量删除123456789101112131415161718192021#删除库中所有KeySELECT 0FLUSHDB#删除所有库中KeyFLUSHALL#默认为db0#批量删除keysredis-cli KEYS &quot;test&quot; | xargs redis-cli DEL#通配符redis-cli KEYS &quot;test*&quot; | xargs redis-cli DEL#指定数据库redis-cli -n 1 KEYS &quot;test*&quot; | xargs redis-cli -n 1 DEL#指定主机，密码redis-cli -h xxx -a xx KEYS &quot;test*&quot; | xargs redis-cli -h xxx -a xx DEL bigkeys1234#对redis中的key进行采样，寻找较大的Keyredis-cli --bigkeys#之后对结果进行分析 注意 Redis监听地址bind： x.x.x.x，强烈建议只对本地127.0.0.1开放。不建议对外网开放，有安全隐患 防火墙，最简单就是关闭防火墙，另一个就是开放redis的监听端口 开启守护进程，让redis可以在后台运行而不必通过redis-server的方式来启动，将配置文件里的deamonize no改为yes 关闭redis的保护模式(protect-mode)，这里的保护模式是指是否允许其他IP的设备访问redis。如果开启的话就只能允许本机访问。如果是生产开发的实际运行环境，请一定开启保护模式 设置redis数据库密码！不仅仅是redis，任何数据库都应该设置密码，否则对外网开放的数据库就成了活靶子。 多数据库 Redis支持多个数据库 类似于其它数据库，不同的数据存储在不同的数据库中 Redis下，数据库是由一个整数索引标识，而不是数据库名称。默认情况下，客户端连接到数据库0 Redis不支持自定义数据库名称，所以需要开发者记录那些数据库存储了哪些数据 Redis不支持为每个数据库设置不同的访问密码，因为密码是在配置文件中设置的。所以一个用户可对所有数据库进行访问 Redis默认支持16个数据库，但可在配置文件中修改 使用SELECT命令切换数据库 FLUSHALL命令或清除所有数据库，请注意 123456cat /etc/redis.conf# Set the number of databases. The default database is DB 0, you can select# a different one on a per-connection basis using SELECT &lt;dbid&gt; where# dbid is a number between 0 and &apos;databases&apos;-1databases 16]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机集群]]></title>
    <url>%2F2018%2F02%2F03%2FComputerCluster%2F</url>
    <content type="text"><![CDATA[参考： 《老男孩Linux运维》 《服务器集群系统各概念》: https://segmentfault.com/a/1190000009923581 《WEB的负载均衡、集群、高可用解决方案》： https://zhuanlan.zhihu.com/p/23826048 计算机集群维基百科 计算机集群计算机集群简称集群(Clusters)，是一种计算机系统。它通过一组散列集成的软件或硬件 连接起来高度紧密地协作完成计算工作。在某种意义上，他们可以被看做是一台计算机。 集群就是指一组（若干）相互独立的计算机，利用高速通信网络组成的一个较大的计算机服务系统，每个集群结点都是运行各自服务的独立服务器。这些服务器之间可以彼此通信，协同向用户提供应用程序、系统资源和数据，并以单一系统的模式加以管理。 当客户机请求集群系统时，集群给用户的感觉就是一个单一独立的服务器，而实际上用户请求的是一组集群服务器。 集群系统中的单个计算机通常称为节点，通常通过内网连接，但也有其它的可能连接方式。集群计算机通常用来改进单个计算机的计算速度和可靠性。 服务器集群概念集群、冗余、负载均衡、主从复制、读写分离、分布式、分布式计算、分布式计算平台、并行计算…… 实际生产环境中常有的问题： 当数据库性能遇到问题时，是否能够横向扩展，通过添加服务器的方式达到更高的吞吐量，从而充分利用现有的硬件实现更好的投资回报率; 是否拥有实时同步的副本，当数据库面临灾难时，可以短时间内通过故障转移的方式保证数据库的可用性。此外，当数据丢失或损坏时，能否通过所谓的实时副本（热备）实现数据的零损失; 数据库的横向扩展是都对应用程序透明，如果数据库的横向扩展需要应用程序端进行大量修改，则所带来的后果不仅仅是高昂的开发成本，同时也会带来很多潜在和非潜在的风险. 集群和冗余集群和冗余并不对立，多台服务器做集群（不是主从），本身就有冗余和负载均衡的效果。狭义上来说，集群就是把多台服务器虚拟成一台服务器，而冗余的每台服务器都是独立的。 集群的侧重点在于协同，多台服务器系统分担工作，提升效率； 冗余的侧重点在于防止单点故障，一主多备的架构，也就是主从复制； 数据冗余==高可用性==主从 主从一定程度上起到了负载均衡的作用，但主要目的还是为了保证数据冗余和高可用性 主从只提供一种成本较低的数据备份方案加上不完美的灾难和负载均衡，由于复制存在时间差，不能同步读，所以只是不完善的负载均衡和有损灾备 主从显然达不到集群的严格度，不论是 HA 还是 AA（多活并行集群），主从都达不到数据一致性的集群要求 为什么要使用集群 高性能（Performance） 大型网站谷歌、淘宝、百度等，都不是几台大型机可以构建的，都是上万台服务器组成的高性能集群，分布于不同的地点。 只有当并发或总请求数量超过单台服务器的承受能力时，服务器集群的优势才会体现出来。 价格有效性（Cost-effectiveness） 在达到同样性能的需求下，采用计算机集群架构比采用同等运算能力的大型计算机具有更高的性价比。 可伸缩性（Scalability） 当服务负载、压力增长时，针对集群系统进行较简单的扩展即可满足需求，且不会降低服务质量。 高可用（Availability） 单一计算机发生故障时，就无法正常提供服务；而集群架构技术可以是得系统在若干硬件设备发生故障时仍可以继续工作。 集群系统在提高系统可靠性的同时，也大大减小了系统故障带来的业务损失，目前几乎100%的网站都要求7x24h提供服务。 透明性（Transparency） 多个独立计算机组成的耦合集群系统构成一个虚拟服务器。用户访问集群系统时，就像访问一台高性能、高可用的服务器一样，集群中一部分服务器的上线、下线不会中断整个系统服务，这对用户也是透明的。 可管理性（Manageability） 这个系统可能在物理上很大，但其实很容易管理，就像管理一个单一映像系统一样。 可编程性（Programmability） 在集群系统上，容易开发及修改各类应用程序。 集群分类集群分为同构和异构，他们区别在于 “组成集群系统的计算机之间的体系结构是否相同”。 集群计算机按功能和结构可以分为以下几类： 均衡集群（Load balancing clusters） 用性集群（High-availability clusters） 能计算集群（High-performance cluster） 计算集群（Grid computing） 负载均衡集群（LB）和高可用性集群（HA）是互联网行业常用的集群架构模式 负载均衡集群负载均衡集群用于抗并发。 负载均衡集群典型的开源软件包括：LVS、Nginx、Haproxy 等。 负载均衡集群可以把很多客户集中的访问请求负载压力尽可能平均分摊在计算机集群中处理。集群中每个节点都可以一定的访问请求负载压力，并且可以实现访问请求在各节点之间动态分配，以实现负载均衡。负载均衡集群运行时，一般是通过一个或多个前端负载均衡器（Director）将客户访问请求分发到后端的一组服务器上，从而达到整个系统的高性能和高可用性。一般高可用性集群和负载均衡集群会使用类似的技术，或同时具有高可用性与负载均衡的特点。 Linux虚拟服务器（LVS）项目 在Linux操作系统上提供最常用的负载均衡软件。 负载均衡的作用： 用户访问请求及数据流量（负载均衡） 业务连续性，即7x24h服务（高可用） 于Web业务及数据库从库等服务器的业务 高可用性集群高可用性集群用于避免单点故障。 高可用性集群常用开源软件包括：Keepalived、Heartbeat 等。 一般是指集群中任意一个节点失效的情况下，该节点上的所有任务会自动转移到其他正常的节点上。此过程不会影响整个集群的运行。 当集群中的一个节点系统发生故障时，运行着的集群服务器会迅速做出反应，将该系统的服务分配到集群中其他正在工作的系统上运行。考虑到计算机硬件和软件的容错性，高可用性集群的主要目的是使局群的整体服务尽可能可用。如果高可用集群中的主节点发生了故障，那么这段时间内将由备节点代替它。备节点通常是主节点的镜像。当它代替主节点时，它可以完全接管主节点（包括Ip和其他资源）提供服务，因此，使集群系统环境对系统环境来说是一致的，既不会影响用户的访问。 高可用性集群使服务器系统的运行速度和响应速度会尽可能的快。它们经常利用在多台机器上运行的冗余节点和服务来相互跟踪。如果某个节点失败，它的替补者将在几秒钟或更多时间内接管它的职责。因此，对于用户来说，集群里的任意一台机器宕机，业务都不会受影响。 高可用性集群的作用： 当一台机器宕机后，另外一台机器接管宕机的机器的Ip资源和服务资源，提供服务； 常用于不易实现负载均衡的应用，如负载均衡器、主数据库、主存储对之间； 高性能计算集群高性能计算集群也称并行计算。通常，高性能计算集群涉及为集群开发的并行应用程序，以解决复杂的科学问题。 高性能计算集群对外就好像一个超级计算机，这种超级计算机内部由数万个独立服务器组成，并且在公共消息传递层上进行通信以运行并行应用程序。 高可用与负载均衡有什么区别 HA偏重于备用资源，切机时会有业务的断开的，保证了数据的安全，但造成资源的浪费； LB侧重于资源的充分应用，没有主备的概念，只有资源的最大限度的加权平均应用，基本不会业务的中断； HA的目的是不中断服务，LB的目的是为了提高接入能力。虽然经常放一起用，但确实是两个不同的领域； HA在一条路不通的时候提供另一条路可走，而 LB 就类似于是春运时的多个窗口； 集群软硬件 企业运维中常见集群产品： 开源集群软件： + Nginx, LVS, Haproxy, Keepalived, Heartbear... 商业集群硬件： + F5， Netscaler,Radware, A10... 如何选择开源集群软件： 网站在并发访问和总访问量不是很大的情况下，建议首选Nginx负载均衡，Nginx配置简单使用方便安全稳定。 另一个实现负载均衡的产品为Haproxy 如果要考虑Nginx负载均衡的高可用功能，建议首选Keepalived软件，因为安装配置简单方便稳定。类似高可用软件还有Heartbeat，但比较复杂 如果是大型企业，负载均衡可以使用 LVS+Keepalived 在前端做四层转发，后端使用Nginx或Haproxy做七层转发，再后面是应用服务器。如果是数据库与存储的负载均衡和高可用，可选用LVS+Heartbeat 负载均衡所谓负载均衡，就是把大访问量分发给不同的服务器，也就是分流请求。 HTTP重定向协议实现负载均衡HTTP 重定向就是应用层的请求转发，用户的请求其实已经到了HTTP重定向负载均衡服务器，服务器根据算法要求用户重定向，用户收到重定向请求后，再次请求真正的集群. 优点：简单 缺点：性能较差 DNS域名解析负载均衡DNS域名解析负载均衡就是在用户请求DNS服务器，获取域名对应的IP地址时，DNS服务器直接给出负载均衡后的服务器IP。 优点：交给DNS，不用我们去维护负载均衡服务器 缺点：当一个应用服务器挂了，不能及时通知DNS，而且DNS负载均衡的控制权在域名服务商那里，网站无法做更多的改善和更强大的管理 反向代理负载均衡在用户的请求到达方向代理服务器时（已到达网站机房），由于反向代理服务器根据算法转发到具体的服务器，常用的Apache，Nginx都可以充当反向代理服务器。 优点：部署简单 缺点：代理服务器可能成为性能的瓶颈，特别是一次上传大文件 IP负载均衡(LVS-NAT)LVS集群中实现的三种IP负载均衡技术。 在请求到达负载均衡器后，负载均衡器通过修改请求的目的IP地址，从而实现请求的转发，做到负载均衡。 优点：性能更好 缺点：负载均衡器的带宽称为瓶颈 直接路由负载均衡(LVS-DR)数据链路层负载均衡，在请求到达负载均衡器后，负载均衡器通过修改请求的Mac地址，从而做到负载均衡，与IP负载均衡不一样的是，当请求访问完服务器之后，直接返回客户，而无需在经过负载均衡器。 IP隧道负载均衡(LVS-TUN) 主从复制主从是一种用于数据容错和灾备的高可用解决方案，而不是一种处理高并发压力的解决方案（负载均衡是用来抗并发的）。 如MySQL主从复制，MongoDB主从复制(副本集) 主机负责查询，从机负责增删改 可以在从机上执行备份，以避免备份期间影响主机的服务 主从复制后，也可以在从机上查询，以降低主机的访问压力。但是，只有更新不频繁的数据或者对实时性要求不高的数据可以通过从服务器查询，实时性要求高的数据仍需在主服务器查询（因为主从复制有同步延迟，所以不能保证强数据一致性） 主从复制和读写分离 主从复制是实现读写分离的技术之一，也是实现读写分离的前提条件 做读写分离时最重要的就是确保 读库 和 写库 的数据统一，而主从复制是实现数据统一最简单的方法（并不能够保证强数据的一致性） 读写分离，顾名思义，就是一个表只负责向前台页面展示数据，而后台管理人员对表的增删改在另一个表中，把两个表分开，就是读写分离 主从复制则是一个表数据 增删改 之后会及时更新到另一个表中，保证两个表的数据一致 主从类型 双机热备=主机+备机 主要应用运行在主机，备机即备用机器。备机不工作，主机出现故障时备机接管主机的所有工作 双机互备=主机（备机） + 备机（主机） 互为主备，部分应用运行于主机，部分应用运行于备机，主机备机同时工作 双机双工=主机+主机 两台主机同时运行应用，主机备机同时工作 分布式 广义上的分布式是指，将不同的服务分布在不同的服务器上 集群是指，将几台服务器集中在一起，实现同一业务 分布式中的每一个节点都可以做集群，而集群并不一定是分布式的]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>Cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL]]></title>
    <url>%2F2018%2F01%2F16%2FMySQL%2F</url>
    <content type="text"><![CDATA[参考： MySQL5.7参考文档： https://dev.mysql.com/doc/refman/5.7/en/ MySQL必知必会 环境： CentOS7.x86_64 MySQL5.7 序言MySQL官网： https://www.mysql.com/ 由于MySQL5.7和以前版本之间的许多功能和其他差异，因此此手册不太适用于之前的老版本。之前的版本请参考MySQL相关版本的手册。 综述General information MySQL™ software提供了一个快速、多线程、多任务和健壮的SQL(结构化查询语言)的数据库服务器。MySQL server是为关键服务(mission-critical)、重负荷(heavy-load)生产系统以及嵌入式(embedding)大规模部署的软件而设计。MySQL是Oracle Corporation的商标(trademark)。 MySQL software是双重许可的(dual license)： Open Source product of the GNU General Public License A Standard commercial License from Oracle 关于此手册 该手册作为一个参考，它不提供关于SQL或关系型数据库概念的一般指令； MySQL Database Software正在不断发展，所以参考手册也经常更新。可在此 &lt; http://dev.mysql.com/doc/&gt; 获取最新版的手册； 参考手册(Reference Manual)的源文件使用DocBook XML格式书写的，其他版本(如HTML)等是自动生成的； 如果在使用过程中有任何问题或建议，请发邮件给我们； 手册由MySQL Documentation Team维护。 MySQL数据库管理系统MySQL Database Management System MySQL介绍MySQL是最流行的开源的SQL数据库管理系统，由Oracle Corporation开发、分发和支持。 MySQL is a database management system数据库是一个结构化的数据集合。它可能是从简单的购物清单到图片库，或是公司网络中的大量信息。若要添加、访问和处理存储在计算机数据库中的数据，你需要一个像MySQL Server这样的数据库管理系统。由于计算机非常擅长处理大量的数据，数据库管理系统在计算机中扮演这一个重要的角色。 MySQL databases are relational关系型数据库将数据存储在单独的表(table)中，而不是将所有数据放入一个大的库房中。数据库结构被组织成针对速度优化的物理文件。具有数据库(database)，表(table)，视图(view)，行(row)，列(column)等物理对象的逻辑模型提供了灵活的编程环境。你设置了管理不同数据字段之间关系的规则，如一对一，一对多，唯一，必须和可选关系，以及不同表之间的指针(pointer)。数据库强制执行这些规则，这样在设计良好的数据库中，应用程序就不会看到不一致、重复、孤立、过时或丢失的数据。 MySQL也是代表SQL(Structure Query Language)的一部分。SQL是访问数据库最常用的标准化语言。你可以直接使用SQL语句，或者将SQL语法隐藏到语言特定的API中。 MySQL software is Open SourceMySQL software使用GPL(GNU General Public License)，开源意味着任何人都可以下载、转发、使用和修改软件，而不需要支付任何费用。 MySQL database server is very fast,reliable,scalabe and easy to use MySQL server works in Client/Server or embedded systemMySQL Database Server是一个由多线程(multi-threaded)SQL Server组成的客户/服务器系统。它支持不同的后端，多个不同的客户程序和库、管理工具和广泛的APIs。还提供MySQL Server作为一个嵌入式多线程库以便链接到你的产品，以获得一个更小，更快，更容易管理的独立产品。 A large amount of contributed MySQL software is available MySQL主要特点Internals and Portability 由C和C++写成 适用于许多不同的平台 为了可移植性，使用CMake 采用独立(independent)模块的多层(layer)服务器设计 设计为使用内核线程的完全多线程，如果有多核CPU，能够轻松使用它们 提供了事务性(transactional)和非事务性(notransactional)存储引擎 使用非常快速的带有索引压缩的B-tree磁盘表 添加其他存储引擎相对容易 使用非常快速的基于线程的内存分配系统 使用优化的嵌套循环(nested-loop)连接执行非常快的联结 实现内存中的hash table，这些表用作临时表 使用高度优化的类库实现SQL函数 数据类型 1,2,3,4和8byte的有无符号(signed/unsigned)的整数(integers) FLOAT DOUBLE CHAR, VARCHAR BINARY, VARBINARY TEXT BLOB DATE, TIME, DATETIME TIMESTAMP YEAR SET ENUM OpenGIS 状态和功能statement and function SELECT和WHERT中包含了所有支持的操作符和函数 SQL中的GROUP BY和ORDER BY也全部支持 GROUP functions(COUNT(), AVG(), STD(), SUM(), MAX(), MIN(), GROUP_CONCAT()) 支持LEFT OUTER JOIN和ROGHT OUTER JOIN 按照SQL标准支持table和columns的别名 支持DELETE,INSERT,REPLACE,UPDATE，以返回受影响的行数 支持MySQL特定的SHOW显示语句 一个EXPLAIN语句显示优化器如何解析查询 安全security 权限(privilege)和密码系统，非常灵活和安全，并且支持基于主机的验证 当连接到Server时，通过加密(encryption)所有密码通信量来确保密码安全 扩展性和限制Scalability and Limits 支持大型数据库。包含五千万条记录，二十万个表，五十亿行 每个表最多支持64个索引，每个索引可以由1到16个列组成 连通性Conectivity 客户端使用如下几种协议连接到MySQL Server TCP/IP sockets —enable-named-pipe on Windows Unix domain socket files on UNIX MySQL客户端可用多种语言编写 APIs对于多数语言是可用的 本地化Localization Server可以向多种语言的客户端提供错误信息 完全支持几个不同的字符集(character sets) 所有数据都被保存在选取的字符集(chracter set) 排序和比较是根据默认的字符集和排序规则完成 服务器时区(time zone)可动态更改，个客户端也可修改自己的时区 客户端和工具Clients and Tools MySQL包含几个客户机和使用程序 command-line： mysqldump, mysqladmin graphical: MySQL Workbench MySQL Server内置了对SQL语句的支持来检查、优化和修复表 MySQL程序可使用--help或-?来获取帮助 MySQL历史History of MySQL MySQL is named after co-founder Monty Widenius’s daughter, My. The name of the MySQL Dolphin (our logo) is “Sakila,” which was chosen from a huge list of names suggested by users in our “Name the Dolphin” contest. MySQL5.7新特色What Is New in MySQL 5.7 MySQL5.7新功能Features Added in MySQL 5.7 MySQL5.7中过期的功能Features Deprecated in MySQL 5.7 MySQL5.7中移除的功能Features Removed in MySQL 5.7 Server and Status Variables and Options Added, Deprecated, or Removed in MySQL 5.7 MySQL信息源MySQL Information Sources 本章节将列出有关MySQL的帮助信息。 MySQL站点MySQL Websites MySQL Documentation is https://dev.mysql.com/doc 术语MySQL Glossary 这些术语通常用于有关MySQL的信息中。 .ARM文件ARCHIVE表的metadata。由MySQL Enterprise Backup产品的mysqlbackup命令生成的备份中。 .ARZ文件ARCHIVE表的数据。由MySQL Enterprise Backup产品的mysqlbackup命令生成的备份中。 ACID代表原子性(atomic)，一致性(consistency)，隔离性(isolation)和持久性(durability)的首字母缩略词。事务是可以提交(commit)或回滚(rollback)的原子工作单位。当事务对数据库进行多次更改时，要么在提交事务时所有更改都成功，要么在事务回滚时撤消所有更改。数据库始终保持一致性状态 - 每次提交或回滚后，以及事务正在进行中。如果跨多个表更新相关数据，查询将查看所有旧值或所有新值，而不是旧值和新值的混合。交易在进行过程中受到保护（隔离），它们不能互相干扰或看到彼此未提交的数据。这种隔离是通过锁定机制(locking mechanism)实现的。经验丰富的用户可以调整隔离级别，在保证事务确实不会相互干扰的情况下，减少保护，转而提高性能和并发。事务的结果是持久的：一旦提交操作成功，该事务所做的更改就可以避免电源故障，系统崩溃，竞争条件或许多非数据库应用程序易受攻击的其他潜在危险。耐用性通常涉及写入磁盘存储，具有一定的冗余以防止写入操作期间的电源故障或软件崩溃。 adaptive flushingAn algorithm for InnoDB tables that smooths out the I/O overhead introduced by checkpoints.MySQL不会一次将所有修改过的页面从缓冲池(buffer pool)刷新(flush)到数据文件，而是定期刷新一小组修改过的页面。自适应刷新(adaptive flushing)算法通过基于刷新率和生成重做信息的速度来估计执行这些周期性刷新的最佳速率来扩展该过程。 adaptive hash indexInnoDB表的优化，通过在内存中构造hash index，可使用=和IN操作符加速查找。MySQL监控InnoDB表的索引搜索，如果查询可从哈希索引中受益，它会自动为经常访问的索引页创建一个。从某种意义上来说，自适应哈希索引在运行时配置MySQL以利用充足的主内存，更接近主内存数据库的体系结构。此功能由innodb_adaptive_hash_index配置项控制。 AIO异步(asynchronous)I/O的缩写。 Antelope原始InnoDB文件格式的代码名称。它支持REDUNDANT和COMPACT行格式，但不支持较新的DYNAMIC和COMPRESSED行格式。 API一组功能或程序。 apply当MySQL Enterprise Backup产品生成的备份不包括备份进行时发生的最新更改时，更新备份文件以包含这些更改的过程称为apply步骤。 asynchronous I/O一种I/O操作，允许在I/O完成前继续进行其它处理。也称为非阻塞(nonblocking)I/O，缩写为AIO。 atomic在SQL上下文中，事务是完全成功(commited)或根本没有效果(rollback)的工作单元。 atomic DDLatomic DDL语句将数据字典更新，存储引擎操作和DDL操作关联的二进制日志写入组合到单个原子事务中。即使服务器在操作期间暂停，事务也可以完全提交或回滚。MySQL 8.0中添加了Atomic DDL支持。 atomic instructionCPU提供的特殊指令。确保关键的低级操作不会被中断。 auto-increment(自增)表的列的属性(由AUTO_INCREMENT关键字指定)，在自动在列中添加值的升序。 auto-increment locking自动增量主键的便利性涉及一些与并发的权衡。 autocommit在每个SQL语句之后导致COMMIT的设置。建议不要将此模式用于具有跨多个语句的事务的InnoDB表。它可以帮助InnoDB表上的只读事务的性能，从而最大限度地减少锁定和生成撤消数据的开销。 availability能够对应于主机上的故障，并在必要时从中恢复故障。 B-tree一种在数据库索引中很常用的树数据结构。结构始终保持排序，从而能够快速查找完全匹配(=)和让位(&gt;, &lt;, BETWEEN)。这种索引类型适用于大多数索引类型。因为B树有很多子节点(children)，所以B树与二叉树(binary tree)不同，二叉树每个节点限制为2个子节点。与哈希索引(hash index)形成对比，HASH仅在MEMORY存储引擎中可使用，MEMORY存储引擎中也可使用B树索引。如果某些查询使用范围运算符，则应为MEMORY表选择B树索引。 backticks(反引号)如果MySQL SQL语句中的标识符包含特殊字符或保留字，则必须使用反引号(```)。 backup从MySQL实例复制部分或全部表数据和原数据的过程，以便妥善保管。 BarracudaInnoDB文件格式的编码名称，它支持启用InnoDB表压缩的COMPRESSED行格式，以及改进长度可变长度列的存储布局的DYNAMIC行格式。 base column存储生成的列或虚拟生成列多所基于的非生成表列。换句话说，基本列是非生成的表列，它是生成的列定义的一部分。 binary log包含尝试更改表数据的所有语句的记录的文件。可以重播(replayed)这些语句，以便在副本集方案中是Slave Server保持最新，或者在从备份中还原表数据使数据库保持最新。建议开启此功能。你可使用mysqlbinlog命令检查二进制日志的内容，以及重播这些内容。 binlog二进制日志文件的非正式名称。 blind query expansion由WITH QUERY EXPANSION子句启用的特殊全文搜索(full-text search)模式。它执行两次搜索，其中第二次搜索的搜索短语是与第一次搜索的少数最高度相关的文档连接的原始搜索短语。该技术主要适用于短搜索短语，可能只有一个单词。它可以发现文档中未出现精确搜索词的相关匹配。 bottleneck(瓶颈)系统的一部分，其大小或容量受到限制，具有限制总吞吐量的效果。 bounce关机(shutdown)操作后立即重启(restart)。 buddy allocator一种管理InnoDB缓冲池(buffer pool)不同大小页面(pages)的机制。 buffer用于临时存储的内存或磁盘区域。 buffer pool保存表和索引的缓存InnoDB数据的内存区域。为了提高大容量读取操作的效率，缓冲池被分成可以容纳多行的页面。在具有大内存的系统上，可以通过将缓冲池划分为多个缓冲池实例来提高并发性。几个InnoDB状态变量，INFORMATION_SCHEMA和performance_schema有助于监视缓冲池的内部工作。 buffer pool instance可以划分缓冲池的多个区域中的任何一个，由innodb_buffer_pool_instances配置项控制。innodb_buffer_pool_size指定的总内存大小在所有缓冲池实例之间划分。通常，具有多个缓冲池实例适用于为InnoDB缓冲池分配多个GigaBytes的系统，每个实例为1GigaByte或更大。 built-inMySQL内置的InnoDB存储引擎是存储引擎的原始分发形式。 .cfg文件与InnoDB可传输表空间功能一起使用的元数据(metadata)文件。它由命令FLUSH TABLES...FOR EXPORT生成，将一个或多个表置于可以复制到另一个Server的一致状态。 cache存储区域的通用术语，用于存储频繁或高速检索的数据副本。在InnoDB中，主要的缓存结构就是缓冲池(buffer pool)。 cardinality表列中的不同值的数量。当查询引用具有关联索引的列时，每列的基数会影响哪种访问方法最有效。 change buffer一种特殊的数据结构，用于记录二级(secondary)索引中页面的更改。 change buffering涉及change buffer功能的通用术语，包括insert buffering, delete buffering, pure buffering。 checkpoint当对缓冲池(buffer pool)中缓存(cached)的数据也进行更改时，这些更改将在稍后某个时间写入数据文件，这个过程称为刷新(flushing)。检查点是已成功写入数据文件的最新更改(LSN值)的记录。 checksum在InnoDB中的一种验证机制，用于在将表空间中的页面从磁盘读入InnoDB缓冲池时检测损坏。 child table在外键(foreign key)中，子表是其行引用另一个表中具有相同值的特定列的行的表。这是包含FOREIGN KEY...REFERENCES子句和可选ON UPDATE和ON DELETE子句的表。子表创建之前，父表中的相应行必须存在。 clean pageInnoDB缓冲池中的一个页面，启用所有在内存中进行的更改也写入(flushed)到数据文件中。dirty page的反面。 clean shutdown关闭完成且没有错误，并在完成之前对InnoDB表应用所有的更改，而不是奔溃或快速关闭。slow shutdown的同义词。 client客户端。 clustered indexInnoDB术语表示主键索引(primary key index)。InnoDB表存储基于主键列的值进行组织，以加速涉及主键列的查询和排序。为获得最佳性能，请根据性能最关键的查询仔细选择主键列。 cold backup数据库关闭时进行的备份。 column行中的数据项，其存储和语义由数据类型定义。每个表格索引主要由它包含的列集合来定义。每个列都有一个基数值。列可以是其表的主键，也可以是主键的一部分。列可以是受唯一约束(unique constraint)，NOT NULL constraint或两者都有。不同列中的值，甚至跨不同的表，可以通过外键关系(foreign key relationship)链接。 column index单列的索引。 column prefix当使用长度规范创建索引时(如: CREATE INDEX idx ON t1 (c1(N));)，只有列值的前N个字符存储在索引中。保持索引前缀较小使索引紧凑，内存和磁盘I/0节省有助于提高性能。 commit结束事务的SQL语句，使事务所做的任何更改永久化。它与回滚(rollback)相反，回滚撤销了在事务中所做的任何更改。 compact row format它是MySQL 5.0.3 to MySQL 5.7.8的默认行格式。从MySQL 5.7.9开始，默认行格式由innodb_default_row_format配置选项定义，该选项的默认设置为DYNAMIC。 composite index包含多个列的索引。 compressed backupMySQL Enterprise Backup产品的压缩功能生成每个表空间的压缩副本. compressed row format一种行格式，可为InnoDB表启用数据和索引压缩。 compressed table以压缩形式存储数据的表。对于InnoDB，它是使用ROW_FORMAT=COMPRESSED创建的表。 compression具有广泛优势的功能,包括使用更少的磁盘空间，执行更少的I/O以及使用更少的内存进行缓存。InnoDB支持表级别和页级别的压缩。 compression failure实际上并不是错误，而是在将压缩与DML操作结合使用时可能发生的昂贵操作。 concurrency(并发)多个操作同时运行的能力，而不会相互干扰。并发性还涉及性能，因为理想情况下，使用有效的锁定(locking)机制，对多个并发事务的保护以最小的性能开销工作。 configuration file包含MySQL在启动时使用的选项的文件。一般来说，Unix/Linux上此文件为my.cnf，Windows上为my.ini。你可在[mysqld]部分下设置与InnoDB相关的许多选项。 consistent read(一致读)一种读取操作，它使用快照信息基于某个时间点显示查询结果，而不管同时运行的其它事务所执行的更改。 constraint一种自动测试，可以阻止数据库更改以防止数据变得不一致。 counter由特定类型的InnoDB操作递增的值。用于测量Server的繁忙程度，对性能问题的来源进行故障排除，以及测试更改是否具有所需的低级别效果。 covering index包含查询检索的所有列的索引。查询不是使用索引值作为指针来查找完整的表行，而是从索引结构返回值，从而节省磁盘I/O。 CPU-bound一种工作负载(workload)，其主要瓶颈是内存中的CPU操作。通常涉及读取密集型操作，其中结果都可以缓存在缓冲池中。 crashMySQL使用术语崩溃(crash)来指代Server无法正常清理的任何意外关机操作。 crash recovery崩溃后再次启动MySQL时发生的清理活动。 CRUDcreate, read, update, delete的缩写，使数据库应用程序中常见的操作序列。 cursor一种内部数据结构，用于表示查询的结果集合或使用SQL WHERE子句执行搜索的其它操作。它的工作方式类似于其它高级语言中的迭代器，根据请求从结果集合中生成每个值。 data dictionary跟踪与InnoDB相关的对象(如table, indexs, columns)的元数据。此元数据实际位于InnoDB系统表空间。由于历史原因，它在某种程度上与存储在.frm文件中的信息重叠。 data directory每个MySQL实例保存InnoDB数据文件的目录和代表各个数据库的目录。由datadir配置项控制。 data files物理上包含table, index数据的文件。InnoDB系统表空间包含InnoDB数据字典，能保存多个InnoDB表的数据，由.ibd数据文件表示。由.ibd文件保存单个InnoDB表数据的每个表文件空间。 data warehouse主要运行大型查询(query)的数据库系统或应用程序。可以以非规范化(denormalized)形式组织只读或读取大部分数据以提高查询效率。 database在MySQL数据目录中，每个数据库有一个单独的目录表示。对于长期使用MySQL的用户来说，数据库是一个熟悉的概念。来自Oracle数据库背景的用户会发现数据的的MySQL含义更接近Oracle数据库调用schema。 DCL(data control language)数据控制语言，一组用于管理权限的SQL语句。在MySQL中，由GRANT, REVOKE语句组成。 DDL(data definition language)数据定义语言，一组用于操作数据库本身而不是单个表行的SQL语句。包括所有形式的CREATE, ALTER, DROP, TRUNCATE语句。DDL语句自动提交(commit)当前事务(transaction)，它们无法回滚(rolled back)。 DML数据操作语言，一组用于执行INSERT, UPDATE, DELETE操作的SQL语句。 deadlock不同事务无法继续的情况，因为每个事务都持有另一个需要的锁(lock)。因为两个事务都在等待资源可用，所以它们都不会释放它拥有的锁。当事务锁定多个表中的行(通过如UPDATE, SELECT... FOR UPDATE等语句)时，可能会发生死锁，但顺序相反。当语句锁定索引记录(index record)和间隙(gaps)的范围时，也可能会发生死锁，每个事务由于计时问题而获取某些锁而不是其它锁。 deadlock detection可自动检测何时发生死锁，并自动回滚其中一个事务(受害者(victim))的一种机制。可使用Innodb_deadlock_dectect配置项禁用死锁检测。 delete当InnoDB处理DELETE语句时，行(row)会立即标记为删除，查询不再返回。在称为清除(purge)操作的顶级垃圾收集期间，稍后将回收存储。为了删除大量数据，具有相关性能特征的相关操作是TRUNCATE和DROP。 delete buffering在更改缓冲区中存储由DELETE操作产生的二级索引页的更改而不是立即写入更改的技术，以便可以执行物理写入以最小化随机I/0。其它有insert buffering, purge buffering。 denormalized一种数据存储策略，跨不同的表复制数据，而不是将表与外键(FOREIGN KEYS)和连接查询(JOIN query)相关联。 descending index一种可用于某些数据库系统的索引的类型，其中索引存储已经过优化，可处理ORDER BY column DESC子句。目前，尽管MySQL在CREATE TABLE语句中允许使用DESC关键字，但它不会对结果索引使用任何特殊的存储布局。 dirty pageInnoDB缓冲池已在内存中更新的页面，其中的更改尚未写入(flush)到数据文件。与clean page相反。 dirty read检索不可靠数据的操作，由另一个事务更新但未提交的数据。只有隔离(isolation)级别称为read uncommitted才有可能。这种操作不符合ACID数据库设计原理。它被认为是非常危险的，因为数据可在提交之前回滚或更新；然后，执行dirty read的事务将使用从未确认为准确的数据。它的反面是一致读取(consistent read)，其中InnoDB确保事务不会读取由另一个事务更新的信息，即使使用其它事务也是如此。 disk-based一种主要在磁盘存储上组织数据的数据库。数据在磁盘和存储器之间来回传递以进行操作。反面是in-memory数据库。 disk-bound一种工作负载，其主要瓶颈(bottleneck)是磁盘I/O。 document id在InnoDB权威搜索功能中，表中包含FULLTEXT index的特殊列，用于唯一标识与每个ilist值相关联的文档。 doublewrite bufferInnoDB使用名为doublewrite的文件刷新(flush)技术。在将页面(page)写入数据文件之前，InnoDB首先将它们写入称之为doublewrite缓冲区的连续区域。只有在完成对doublewrite缓冲区的写入和刷新之后，InnoDB才会将页面写入数据文件中的正确位置。如果在页面写入过程中存在操作系统，存储子系统或mysqld进程崩溃，InnoDB稍后可以在崩溃恢复期间从doublewrite缓冲区中找到该页面的良好副本。 drop一种通过DROP TABLE, DROP INDEX等语句删除模式对象的DDL操作。它在内部映射到ALTER TABLE语句。 dynamic row formatInnoDB插件中引入的行格式，作为Barracuda file format的一部分提供。由于长的可变长度列值存储在保存行数据的页面之外，因此对于包含大对象的行非常有效。由于通常不访问大字段来评估查询条件，因此它们不会经常进入缓冲池，从而导致更少的I / O操作和更好的缓存内存利用率。默认行格式由innodb_default_row_fotmaat定义，其默认值为DYNAMIC。 early adopter类似于BETA的阶段，通常在非关键任务设置中评估软件产品的性能、功能和兼容性。 error log一种日志，显示有关MySQL启动和关键运行时错误以及奔溃信息的消息。 eviction从缓存或其它临时存储区域(如InnoDB buffer pool)中移除项(item)的过程。 exclusive lock一种阻止任何其它事务锁定同一行的锁。根据事务隔离级别，这种锁可能会阻止其它事务写入同一行，或者也可能阻止其它事务读取同一行。 extent表空间的一组页面。对于16KB的默认页面大小，范围包含64页。MySQL v5.7.6中增加了对32KB(2MB)和64KB(4MB) InnoDB页面大小的支持。 .frm文件包含MySQL表的元数据(如表定义)的文件。对于备份，必须始终保留完善的.frm文件集合备份数据，以便能够还原备份后更改或删除的表。虽然每个InnoDB表都有一个.frm文件，但InnoDB在系统表空间中维护自己的表元数据。InnoDB不需要.frm文件来操作InnoDB表。.frm文件由MySQL Enterprise Backup产品备份。 Fast Index CreationInnoDB插件中首次引入的功能，现在是MySQL 5.5及更高版本的MySQL的一部分。通过避免完全重写关联表的需要，加速了InnoDB 二级索引(secondary index)的创建。加速也适用于删除二级索引。由于索引维护可能会增加许多数据传输操作的性能开销，因此请考虑执行诸如AALTER TABLE ... ENGINE=INNODB或INSERT INTO ... SELECT * FROM ...之类的操作，而不使用任何二级索引，并在之后创建索引。在MySQL 5.6中，此功能变得更加通过。你可以在创建索引时读取和写入表，并且可以在不复制表的情况下执行等多种类的ALTER TABLE...操作，而不会阻止DML操作，或两者。因此在MySQL 5.6及更高版本中，这组功能称为online DDL，而不是快速索引创建。 fast shutdownInnoDB的某人关闭过程，基于配置innodb_fast_shutdown=1。为了节省时间，跳过某些FLUSH操作。这种类型的关闭在正常使用期间是安全的，因为刷新操作在下次启动期间执行，使用与崩溃恢复(crash recovery)中相同的机制。如果数据库正在关闭以进行升级或降级，请执行慢速关闭(slow shutdown)，以确保在关闭期间对数据文件应用所有相关更改。 file formatInnoDB表的文件格式，使用innodb_file_format配置项启用。支持的文件格式是： Antelope： 是最初的InnoDB文件格式，支持REDUNDANT和COMPACT行格式； Barracuda：是新的InnoDB文件格式，支持COMPRESSED和DYNAMIC行格式。 file-per-table由innodb_file_per_table选项控制的通用名称，这影响InnoDB文件存储、功能可用性和I/O特性方面的重要配置项。启用此配置项后，你可以在其.idb文件中创建表，而不是在系统表空间的共享idbdata文件中创建表。当表数据存储在单个.idb文件中时，你可更灵活地选择数据压缩等功能所需的行格式。 fill factor在InnoDB索引中，分隔页面之前索引数据占用的页面比例。 fixed row format此行格式由MyISAM存储引擎使用，而不是InnoDB。 flush将已在内存区域或临时磁盘存储区中缓冲中的更改写入数据库文件。定期刷新(flush)的InnoDB存储结构包括redo log, undo log, buffer log。 flush list一个内部InnoDB数据结构，用于跟踪缓冲池中的脏页面(dirty page)：即已更改并需要写入磁盘的页面。InnoDB内部小型事务经常更新此数据结构，因此受其自身的互斥锁(mutex)保护，以允许并发访问缓冲池。 foreign key一种指针关系类型，位于单独的InnoDB表中的行之间。外键关系在父表(par ent table)和子表(child table)中的一列上定义。除了能快速查找相关信息外，外键还可以防止这些指针在插入、更新和删除数据时变为无效，从而有助于强制引用完整性(referential integrity)。此强制机制是一种约束(constraint)。如果另一个表中不存在关联的外键值，则无法插入指向另一个表的行。如果删除了一行或更改了其外键值，并且另一个表中的行指向该外键值，则可以设置外键以防止删除，导致另一个表中的相应列值变为NULL，或者自动删除另一个表中的相应行。设计规范化(normalized)数据库是一个阶段是识别副本的数据，将数据分成新表，并设置外键关系，以便可使用连接(JOIN)操作像单个表一样查询多个表。 FOREIGN KEY constraint通过外键关系维护数据库一致性的约束类型。与其它类型的约束一样，如果数据不一致，它可以防止数据被插入和更新； FTS在大多数情况下，它是全文搜索(full-text search)的缩写。有时在性能泰伦中，它是全表扫描(full-table scan)的缩写。 full-text search一种MySQL功能，用于在表数据中查找单词(words)、短语(phrases)、单词的布尔组合…比如使用SQL的LIKE运算符或编写自己的应用程序级的搜索算法。 full table scan需要读取表的全部内容而不是仅使用索引选择的部分内容的操作。索引的目的是允许在大表中查找特定值或值范围，从而在实践时避免全表扫描。 full backup一种备份，包括每个msyql数据库中的所有表，以及MySQL实例中的所有库。 FULLTEXT index在MySQL全文搜索机制中保存搜索索引的特殊索引。 fuzzy checkpointing一种从缓冲池刷新小批量脏页面的技术，而不是一次刷新所有脏页面，这会破坏数据库处理。 GA一般可用(Generally available)，及产品出现测试阶段可供销售，官方支持和生产使用的阶段。 gapInnoDB索引数据结构中可以插入新值的位置。 gap lock锁定索引记录之间的间隙(gap)，或锁定第一个或最后一个索引记录之前的间隙。与记录锁(read lock)和下键锁(next-key lock)对比。间隙锁是性能和并发之间权衡的一部分，用于某些事务隔离级别而不是其它级别。 general log参考一般查询日志。 general query log一种用于诊断和排除MySQL Server处理SQL语句的日志。可存储在文件或数据库表中。你可使用gereral_log配置项启用此功能，可通过sql_log_off配置项为特定连接禁用它。记录比慢查询更广泛的查询。与用于副本的二进制日志不同，通用查询日志包含SELECT语句，并且不保持严格的排序。 general tablespace由CREATE TABLESPACE语法创建的共享InnoDB表空间。通用表空间可以在MySQL数据目录之外创建，能够保存多个表，并支持所有行格式的表。 MySQL 5.7.6中引入了一般表空间。与系统表空间(system tablespace)和每个表文件(file-per-table)空间对比。 generated column其值是根据列定义中包含的表达式计算的列。生成列可以是虚拟的(virtual)或存储的(stored)。 generated stored columnSee stored generated column. generated virtual columnSee virtual generated column. global transactionXA操作中涉及的一种事务。它由几个本身具有事务性的操作组成，但所有操作必须作为一个组成功完成，或者全部作为一个组回滚。 group commitInnoDB优化，对一组提交(commit)操作执行一次低级I/O操作(日志写入)，而不是为每次提交单独刷新和同步。 hash index一种索引类型，用于使用相等运算符的查询而不是范围运算符。它用于MEMORY表，它是MOMORY存储引擎的默认值，但它还支持B-TREE索引，B-TREE索引对一般查询来说是更好的选择。 heartbeat发送的周期性消息，指示系统正常运行。 high-water mark表示上限的值，也可是运行时不应超过的硬性限制。与low-water mark相反。 history list具有删除标记记录的事务列表，计划由InnoDB清除(purge)操作处理。记录在撤销(undo)日志中。历史列表的长度由SHOW ENGINE INNODB STATUS报告。如果历史列表长度超过innodb_max_purge_lag配置项，则么个DML操作都会稍微延迟，以允许清除操作完成刷新已删除的记录。 hole punching从页面释放空块(empty block)。InnoDB transparent page compression功能依赖于它的支持。 hot频繁地访问行、表或内部数据结构，需要某种形式的锁定或互斥的情况，这会导致性能或可伸缩性问题。 hot backup在数据库运行且应用程序正在读取和写入数据库时进行备份。备份不仅仅是复制数据文件：它必须包括备份过程中插入或更新的任何数据;它必须排除备份过程中删除的任何数据;它必须忽略任何未提交的更改。 .idb文件file-per-table表空间和通用表空间的数据文件。每个表的文件表空间(.idb文件)包含一个表和关联的索引数据。一般表空间(.idb文件)可能包含多个表的表数据和索引数据。.idb文件扩展不适用于系统表空间，该表空间由一个或多个ibdata文件组成。 .ibz文件当MySQL Enterprise Backup产品执行压缩备份时，它会将使用file-per-table设置创建的每个表空间文件从.ibd扩展名转换为.ibz扩展名。 .isl文件一个文件。它的功能类似于符号链接，没有实际符号链接机制的平台限制。 I/O-bound参考disk-bound。 ib-file set由InnoDB管理的文件集： 系统表空间， 每个表的表空间文件和重做日志文件(redo log)。根据MySQL版本和InnoDB配置，还可能包括通用表空间，临时表空间和撤消表空间文件。这个术语有时用于InnoDB文件结构和格式的详细讨论，以引用由InnoDB在MySQL数据库中管理的文件集。 ibbackup_logfile在热备份操作期间由MySQL Enterprise Backup产品创建的补充备份文件。 ibdata文件一组名称为ibdata1，ibdata2等的文件，构成InnoDB系统表空间。这些文件包含有关InnoDB表的元数据，以及一个或多个撤销日志(undo log)，更改缓冲区(change buffer)和双写入缓冲区域(doublewrite buffer)。它们还可以包含部分或全部数据。 ibtmp文件InnoDB临时表空间数据文件，用于非压缩的InnoDB临时表和相关对象。配置项innodb_temp_data_file_path允许用户定义临时表空间数据文件的相对路径，如果未指定，则默认在数据目录下创建。 ib_logfile一组文件，通常名为ib_logfile0和ib_logfile1，构成重做日志。有时也称为日志组。这些文件记录了尝试更改InnoDB表中数据的语句。在崩溃后启动时，会自动重播这些语句以更正由不完整事务写入的数据。此数据文件不能用于手动恢复；对于该类型的操作，请使用二进制日志(binlog)。 ilist在InnoDB全文索引中，数据结构由document id和token的位置信息组成。 implicit(隐式) row lockInnoDB获取的行锁，以确保一致性，而无需你特别请求它。 in-memory database一种数据库系统，用于维护内存中的数据，以避免磁盘I/O和磁盘块与内存区域之间的转换而产生的开销。 incremental backup(增量备份)由MySQL Enterprise Backup产品执行的一种热备份，仅保存自某个时间点以来更改的数据。 index一种数据结构，通常通过形式表示成特定列或列集的所有值的树结构(B-TREE)，为表的行提供快速查找功能。InnoDB表总是有一个表示主键(primary key)的聚集索引(clustered index)。它们还可以在一列或多列上定义一个或多个二级索引(secondary index)。根据其结构，二级索引可分为部分索引(partial index)、列索引(column index)和复合索引(composite index)。索引是查询性能的关键方面。数据库架构师设计表、查询和索引，以允许快速查找应用程序所需的数据。理想的数据库设计在可行的情况下使用覆盖索引(overing index)，查询结果完全从索引计算，而不读取实际的表数据。每个外键约束(foreign key constraint)还需要一个索引，以有效地检查父表和子表中是否存在值。虽然B-TREE索引最为常见，但不同类型的数据结构使用HASH索引(如memory存储引擎和InnoDB自适应哈希索引)。R-Tree索引用于多维信息的空间索引。 index cache保存InnoDB全文搜索的令牌数据(token)的内存区域。当数据在作为全文索引一部分的列中插入或更新时，它会缓冲数据以最小化磁盘I/O。当索引缓存已满时，令牌数据将写入磁盘。每个InnoDB全文所以都有自己独立的索引缓存，其大小由innodb_ft_cache_size配置项控制。 index condition pushdownIndex Condition Pushdown(ICP)是一种优化，如果可以使用索引中的字段评估条件的某些部分，则将部分WHERE条件下推到存储引擎。ICP可以减少存储引擎必须访问基表的次数以及MySQL服务器必须访问存储引擎的次数。 index hint用于覆盖优化程序建议的索引的扩展SQL。 index prefix在应用于多个列的索引(称为复杂索引)，索引的初始列或前导列。 index statistics infimum record索引中的伪记录(pseudo record)，表示该索引中最小值之下的差距。 INFORMATION_SCHEMA提供MySQL数据字典(data dictionary)查询接口的数据库。要检查有关数据库的信息(元数据)，可以查询诸如INFORMATION_SCHEMA.TABLES和INFORMATION_SCHEMA.COLUMNS之类的表。而不是使用生成非结构化输出的SHOW命令。INFORMATION_SCHEMA数据库还包含特定于InnoDB的表，这些表为InnoDB数据字典提供查询接口。使用这些表不是为了查看数据库的结构，而是获取有关InnoDB表的工作方式的实时信息，以帮助进行性能监视，调整和故障排除。 InnoDB一个MySQL组件，它结合了高性能和事务功能，可靠性，健壮性和并发访问。它体现了ACID的设计理念。代表作为存储引擎，它处理使用ENGINE=INNODB子句创建或更改的表。InnoDB表非常适合热备份。 innodb_autoinc_lock_modeinnodb_autoinc_lock_mode选项控制用于自动增量锁定的的算法。当你有一个自增主键，则只能使用innodb_autoinc_lock_mode=1来使用基于语句的复制。此设置称为连续锁定模式，因为事务中的多行插入会接收连续的自动增量值。如果您有innodb_autoinc_lock_mode=2，它允许插入操作具有更高的并发性，请使用基于行的复制而不是基于语句的复制。此设置称为交错锁定模式，因为同时运行的多个多行插入语句可以接收交错的自动增量值。除兼容性目的外，不应使用innodb_autoinc_lock_mode=0设置。 innodb_file_formatinnodb_file_format选项定义用于新InnoDB文件每表表空间的文件格式。目前，您可以指定Antelope和Barracuda文件格式。 innodb_file_per_table一个重要的配置项，它影响InnoDB文件存储的许多方面，功能的可用性和I/O特性。 innodb_lock_wait_timeoutinnodb_lock_wait_timeout选项设置在等待共享资源变为可用或放弃和处理错误，重试或在应用程序中执行备用处理之间的平衡。 innodb_strict_modeinnodb_strict_mode选项控制InnoDB是否在严格模式下运行，其中通常被视为警告的条件会导致错误。 insertSQL中的主要DML操作。 insert bufferchange buffer之前的名称。 insert buffering在更改缓冲区中存储由INSERT操作产生的二级索引页的更改而不是立即写入更改的技术，以便可以执行物理写入以最小化随机I/O。 insert intention lock一种间隙锁(gap lock)，由行插入前的INSERT操作设置。 instance一个mysqld守护程序，管理一个数据目录，表示一个或多个带有一组表的数据库。 instrumentation在源代码级别进行修改以收集用于调整和调试的性能数据。 intention exclusive lock intention lock一种适用于表的锁，用于指示事务要在表中的行上获取的锁类型。不同的事务可以在同一个表上获取不同类型的意图锁，但是获取表上的意图独占（IX）锁的第一个事务会阻止其他事务获取表上的任何S或X锁。 intention shared lock intrinsic temporary table优化程序使用的优化内部InnoDB临时表。 inverted index为文档检索系统优化的数据结构，用于InnoDB全文搜索的实现。 IOPS每秒I/O操作的缩写。 isolation level数据库处理的基础之一。从最高的一致性和保护到最小，InnoDB支持的隔离级别是: SERIALIZABLE, REPEATABLE READ, READ COMMITTED, READ UNCOMMITTED。InnoDB表中，许多用户可以保留默认所有操作的默认级别(REPEATABLE READ)。专家用户可以选在READ COMMITTED级别，因为它们通过OLTP处理推动可伸缩性的界限，或者在数据仓库操作期间，其中的轻微不一致性不会影响大量数据的聚合结果。边缘上的级别(SERIALIZABLE和READ UNCOMMITTED)将处理行为改变到很少使用它们的程度。 join通过引用包含相同值的表中的列来从多个表检索数据的查询(query)。理想情况下，这些列是InnoDB外键(foreign key)关系的一部分，它确保了引用完整性并且连接列已编制的索引。通常用于规范化数据设计中通过用数字ID替换重复的字符串来节省空间并提高查询性能。 KEY_BLOCK_SIZE用于指定InnoDB表中使用压缩行格式(compressed row format)的数据页(date page)大小的选项(默认8KB)。 latchInnoDB用于实现其内部存储器结构锁定的轻量级结构，通常以毫秒或微秒为单位保持一段时间。一般术语，包括互斥锁(mutexes)和读写锁(rw-locks)。它是InnoDB性能调整的重点，有关锁存器(latch)使用和争用的统计信息可通过 Performance Schema接口获取。 listInnoDB缓冲池表示为内存页列表。 lock控制对资源访问的对象的高级概念，作为锁定策略的一部分。 lock escalation在某些数据库系统中使用的操作，它将许多行锁转换为单个表锁，从而节省了内存空间，但减少了对表的并发访问。 lock mode共享锁(shared lock)允许事务读取表行。多个事务可以同时在同一行上获取共享锁。独占锁(exclusive lock)允许事务更新化删除行。没有其它事务可以同时在同一行上获取任何类型的锁。意图锁(intension lock)适用于表，用于指定事务要在表中的行上获取那种锁定。不同的事务可以在同一个表上获取不同类型的意图锁，但是获取表上的意图独占锁的第一个事务会阻止其它事务获取表上的任何共享锁或独占锁。 locking保护事务不被查看或更改其它事务正在查询或更改的数据的系统。 locking read锁定策略必须平衡数据库操作的可靠性和一致性与良好并发性所需的性能。一个SELECT语句，它还对InnoDB表执行锁定操作。它有可能产生死锁，具体取决于事务的隔离级别。 log包括redo log, undo log, error log, binary log, general query log, slow query log。 log buffer保存要写入日志文件的数据的内存区域。由innodb_log_buffer_size配置项控制。 log file数据从log buffer内存区域写入到这些文件。 log group logical一种设计高级抽象方面的操作。 logical backup一种备份，可以重现表结构和数据，而无需复制实际的数据文件。逻辑备份的输出包含如CREATE TABLE, INSERT...语句，与物理备份形成对比。它提供了灵活性，但恢复时间比物理备份长得多。 loose_在Server启动后添加到InnoDB配置项的前缀，因此当前级别的MySQL无法识别的任何新配置项都不会导致启动失败。MySQL处理以此前缀开头的配置选项，但如果前缀后面的部分不是可识别的选项，则会发出警告而不是失败。 low-water mark表示下限的值，通常是某些纠正措施开始或变得更具侵略性的阈值。 LRULRU(least recently used)是管理存储区域的常用方法。当需要空间来缓存较新的项目时，最近未使用的项目将被逐出。 LSNLSN(log sequence number)，这个任意的，不断增加的值表示与重做日志中记录的操作相对应的时间点。 .MRG文件包含MERGE存储引擎使用的其它表的引用的文件。 .MYD文件MySQL用于存储MyISAM表数据的文件。 .MYI文件MySQL用于存储MyISAM表索引的文件。 master server副本集中的数据库Master，用于处理数据的初始INSERT, UPDATE, DELETE。这些更改将传递管道其它Slave并在其上执行。 master threadInnoDB线程，在后台执行各种任务。这些任务中大多数都与I/O有关。为了提高并发性，有时将操作从主线程移动到单独的后台线程。 MDLMDL(metadata lock)。用于放置对另一个事务同时使用的表执行DDL操作。 memcachedMySQL和NoSQL软件堆栈的流行组件，允许对单个值进行快速读取和写入，并将结果完全缓存在内存中。 merge应用内存中缓存的数据的更改，更改缓冲区中记录的任何适用更改都将合并到缓冲池中的页面中。更新的数据最终由FLUSH机制写入表空间。 metrics counter midpoint insertion strategy最初将页面放入InnoDB缓冲池的技术不是在列表的最新端，而是在中间的某个位置。根据innodb_old_blocks_pct选项的设置，此点的确切位置可能会有所不同。 mini-transaction在DML操作期间在物理级别对内部数据结构进行更改时，InnoDB处理的内部阶段。 mixed-mode insert一个INSERT语句，为某些新行指定auto-increment值。 multiversion concurrency control(MVCC)这种技术是具有特定隔离级别的InnoDB事务执行一致的读操作。这是一种增强并发性的强大技术，允许查询继续进行而无需等待其它事务持有的锁。这种技术在数据库世界中并不普遍，其它数据库产品和其它MySQL引擎不支持它。 mutex互斥变量(mutex variable)的非正式缩写。InnoDB用于表示和强制执行内部内存数据结构的独占访问锁的低级对象。获取锁定后，将阻止任何其他进程，线程等获取相同的锁定。与读写锁对比，InnoDB使用它来表示和强制执行内部内存数据结构的共享访问锁。互斥锁(mutexes)和读写锁(rw locks)被统称为锁存器(latches)。 my.cnfUnix/Linux系统上，MySQL配置文件名称。 my.iniWindows系统上，MySQL配置文件名称。 mysqlmysql程序时MySQL数据库的CLI解释器。它通过将请求传递给mysqld daemon来处理SQL语句以及特定的MySQL命令。 mysqlbackupMySQL Enterprise备份产品的CLI工具。 mysqldump一个命令，用于对数据库、表、表结构、表数据等某些组合执行逻辑备份。 mysqldmysqld是MySQL数据库的数据库引擎。它作为守护进程运行，不断等待请求并在后台执行维护工作。 natural key索引列，通常是主键，其中值具有一些真实世界的重要性。通常建议不要因为: 如果值应该更改，这可能需要大量索引维护来重新排序聚集索引(clustered index)，并在更新在每个二级索引(secondary index)中重复的主键值的副本 即使看似稳定的值也会以不可预测的方式改变，这些方式难以在数据库中正确表示。因此，通常最好使用任意数值(arbitrary numeric)来形成组合键，如使用自增列(auto-increment column)。 neighbor page与特定页面具有相同程度(extent)的任何页面。当选择要刷新(flush)页面时，通常也刷新任何脏页面，作为传统硬盘的I/O优化。它通过innodb_flush_neihbors配置项进行控制。 next-key lock索引记录上的记录锁定(record lock)和索引记录之前的间隙上的间隙锁定(gap lock)的组合。 non-locking read不使用SELECT ... FOR UPDATE或SELECT ... LOCK IN SHARE MODE子句的查询。允许在只读事务(readonly transaction)中使用全局表的唯一查询类型。 non-repeatable read查询检索数据的情况，以及同一事务中的后续查询检索应该是相同数据的内容，但查询返回不同的结果。这种操作违背了ACID数据库设计原则。在事务中，数据应该是一致的，具有可预测和稳定的关系。在不同的隔离级别(isolation levels)中，可序列化读取(serializable read)和可重复读取级别阻止了不可重复读取，并且一致读取(consistent read)和读取未提交(read uncommitted)级别允许。 nonblocking I/O行业术语，与异步(asynchronous)I/O相同。 normalized数据库设计策略，将数据拆分为多个表，并将重复值压缩为由ID表示的单个行，以避免存储、查询和更新冗余或冗长(redundant or lengthy)的值。它通常用于OLTP应用程序。 NoSQL一组数据访问技术的广义术语，它不使用SQL语言作为读取和写入数据的主要机制。 NOT NULL约束(constraint)一种约束类型，指定列不能包含任何NULL值。 NULLSQL中的特殊值，表示缺少数据。任何涉及NULL值的算术运算或相等测试都会产生NULL结果。NULL值在索引操作中起作用，因为对于性能，数据库必须最小化跟踪丢失数据值的开销。由于主键必须能够唯一标识表中的每一行，因此单列主键不能包含任何NULL值，并且多列主键不能包含所有列中具有NULL值的任何行。 .OPT文件包含数据库配置信息的文件。由MySQL Enterprise Backup产品的mysqlbackup生成。 off-page列包含可变长度数据(如BLOB, VARCHAR)的列，由于列长度太长而无法放在B-Tree页面上。这个数据存储在溢出页面(overflow page)中。与旧的COMPACT行格式相比，DYNAMIC行格式对此类存储更有效。 OLTPOLTP(Online Transaction Processing)，数据库系统或数据库应用程序，它运行具有许多事务的工作负载，频繁写入和读取，通常一次影响少量数据。凭借其行级锁定(row-level locking)和事务功能，InnoDB是OLTP应用程序中使用的MySQL表的理想存储引擎。 online一种不涉及数据库停机(shutdown)、阻塞(blocking)或受限(restricted)操作的操作类型。通常适用于DDL。在备份中，热备(hot backup)是在线(online)操作，暖备(warm backup)是部分在线操作。 online DDL在DDL(主要是ALTER TABLE)期间改进InnoDB表的性能、并发性和可用性的功能。 optimistic一种指导关系型数据库系统的低级实现决策的方法。 optimizerMySQL组件，根据相关表的特征和数据分布，确定用于查询的最佳索引(index)和联结(join)顺序。 optionMySQL的配置参数，可存储在配置文件中，也可在命令行上传递。 option file包含MySQL实例的配置选项的文件。 overflow page包含可变长度的单独分配磁盘页面的列(如BLOB, VARCHAR)，这些列太长而无法放在B-Tree页面上。这个关联列也称为页外列(off-page)。 .par文件包含分区定义的文件。由 MySQL Enterprise Backup的mysqlbackup生成。 page一个单元，表示InnoDB在磁盘(data file)和内存(buffer pool)之间的任何事件传输的数据量。页面可以包含一行或多行，具体取决于每行中的数据量。 page cleanerInnoDB后台线程，用于刷新(flush)缓冲池(buffer pool)中的脏页面。 page size对于MySQL v5.5，每个页面的固定大小为16KB。从MySQL v5.6开始，InnoDB实例的页面大小可以是4KB, 8KB, 16KB，由innodb_page_size配置项控制。从MySQL v5.7.6开始，InnoDB还支持32KB和64KB的页面大小(但不支持ROW_FORMAT=COMPRESSED)。 parent table外键关系的表，其中包含从子表执行初始列值。 partial backup包含MySQL数据库中的某些库或某些表的备份。 partial index仅表示列值的一部分索引，通常是长度为VARCHAR值的前N个字符(前缀)。 Performance Schemaperformance_schema模式提供了一组表，可以查询这些表以获取有关MySQL Server的许多内部的性能详细信息。 persistent statistics一种功能，可将InnoDB表的索引统计信息存储在磁盘上，从而为查询提供更好的计划稳定性。 pessimistic一种牺牲性能或并发性以支持安全性的方法。InnoDB使用所谓pessimistic locking策略，以最大限度地减少死锁(deadlock)的可能性。在应用程序级别，你可通过一台是就获取事务所需的pessimistic lock策略来避免死锁。 phantom显示在查询结果集中但不在先前查询的结果集中的行。 physical设计硬件方面的操作。 physical backup复制实际数据文件的备份。 PITRPIRT(point-in-time recovery)时间点恢复的缩写。还原备份以在特定日志和时间重新创建数据库状态的过程。 plan stability查询执行计划的一个属性，优化程序每次为给定查询做出相同的选择，以便性能一致且可预测。 prefixindex prefix. primary key一组列，基于这组列的索引可以唯一标识表中的每一行。InnoDB要求每个表都有这样的索引，并根据主键的列值组织表存储。选择主键值时，请考虑使用任意值（synthetic key），而不是依赖于从某些其他源（natural key）派生的值。 pseudo-record索引中的人工记录，用于锁定当前不存在的键值或范围。 PthreadsPOSIX线程标准，它定义了用于Unix和Linux系统上的线程和锁定操作的API，InnoDB将此实现用于互斥锁(mutexes)。 purge由一个或多个单独的后台线程（由innodb_purge_threads控制）执行的一种垃圾收集，它以定期计划运行。 purge buffering在更改缓冲区中存储由DELETE操作产生的二级索引页的更改而不是立即写入更改的技术，以便可以执行物理写入以最小化随机I/O。 purge lagInnoDB历史列表的另一个名称。与innodb_max_purge_lag配置项有关。 purge threadInnoDB进程中的一个线程，专门用于执行定期清除操作。 query在SQL中，从一个或多个表中读取信息的操作。 query execution plan优化程序关于如何最有效地执行查询的决策集，包括要使用的索引或索引，以及联结表的顺序。 query log quiesce要减少数据库活动量，通常要为ALTER TABLE、备份或关闭等操作做准备。 R-tree一种树数据结构，用于诸如地理坐标(geographical coordinates)、矩形(rectangle)、多边形(polygons)之类的多维数据(multi-dimensional)进行空间索引。 RAID磁盘阵列(Redundant Array of Inexpensive Drives)的缩写。跨多个驱动器传播I/O操作可在硬件层面实现更高的并发性，并提高低级写入操作的效率，否则将按顺序执行。 random dive一种快速估量列中不同值的数量的技术。InnoDB从索引中随机采样页面，并使用该数据估计不同值的数量。 raw backup在应用binary log和incremental backup中的更改之前，MySQL Enterprise Backup产品生成的初识备份文件集。 READ COMMITTED为了提供性能，使用锁定策略的隔离级别可以放松事务之间的某些保护。事务无法查看来自其它事务未提交的数据，但它们可以查看当前事务启动后由另一个事务提交的数据。因此，事务永远不会看到任何不良数据，但它看到的数据可能在某种程度上取决于其它事务的时间。 read phenomena当事务读取另一个事务已修改的数据时可能发生 dirty reads, non-repeatable reads, phantom reads等现象。 READ UNCOMMITTED在事务之间提供最少保护的隔离级别。查询采用锁定策略，允许它们在通常等待另一个事务的情况下继续。但是，这种额外的性能是以不太可靠的结果为代价的，包括已被其他事务更改但尚未提交的数据(dirty data)。请谨慎使用此隔离级别，并注意结果可能不一致或可重现，具体取决于其它事务同时执行的操作。通常，具有此隔离级别的事务仅执行查询，而不执行插入，更新或删除操作。 read viewInnoDB的MVCC机制使用的内部快照。某些事务会查看事务启动时的数据值。使用读取视图(read view)的隔离级别是REPEATABLE READ, READ COMMITTED, READ UNCOMMITTED。 read-ahead一种I/O请求，它将一组页面异步预取到缓冲池中，预计很快就会需要这些页面。线性预读技术基于前一范围中的页面的访问模式预取一个范围的所有页面。 read-only transaction一种可以优化InnoDB表的事务，通过消除为每个事务创建读取视图所涉及的一些簿记(bookkeeping)。 record lock索引记录上的锁定。 redo当DML语句对InnoDB表进行更改时，以记录为单位的数据记录位于重做(redo)日志中。在崩溃恢复(crash cecovery)期间使用它来纠正未完成的事务写入的数据。 redo log在崩溃恢复期间使用的基于磁盘的数据结构，用于纠正由未完成的事务写入的数据。 redundant row format旧的InnoDB行格式。MySQL v5.0.3到MySQL v5.7.8的新格式为COMPACT。MySQL v5.7.9，默认行格式由innodb_default_fow_format配置项定义，默认为DYNAMIC，也可指定REDUNDANT行格式与旧的InnoDB表兼容。 referential integrity始终以一致的格式维护数据的技术，这是ACID理念的一部分。 relational数据库Server对一对一(one-to-one)，一对多(one-to-many)，多对一(many-to-one)和唯一性(uniqueness)等关系进行编码和实施。数据库Server可以使用这些关系来防止插入错误数据，并找到查找信息的有效方法。在数据库级别，这些关系通过SQL功能表示。在数学上下文中，数据库中的关系原子集合论。 relevance在全文搜索功能中，一个数字表示搜索字符串与全文索引中的数据之间的相似性。 REPEATABLE READInnoDB的默认隔离级别。它可以防止被查询的任何行被其他事务更改，从而阻止不可重复的读取但不阻止幻像读取。 repertoireRepertoire是一个应用于字符集的术语。 replication restore还原数据库。 rollback用于结束事务的SQL语句，撤销事务所做的任何更改。它与提交(commit)相反，提交使得在事务中进行任何更改都是永久性的。默认情况下，MySQL使用自动提交设置，该设置会在每个SQL语句后自动发出提交。你必须先更改此设置，然后才能使用回滚技术。 rollback segment包含撤销(undo)日志的存储区域。 row由一组列定义的逻辑数据结构。 row formatInnoDB表行的磁盘存储格式。 row lock一种锁，可防止另一个事务以不兼容的方式访问行。其它事务可以自由地写入同一表中的其它行。这是由InnoDB表上的DML操作完成的锁定类型。 row-based replication一种部分形式，事件从Master传播，指定如何更改Salve上的各行。可以安全地用于innodb_autoinc_loc_mode选项的所有设置。 row-level locking用于InnoDB表的锁定机制，依赖于行锁(row lock)而不是表锁(table lock)。多个事务可以同时修改同一个表。只有当两个事务尝试修改同一行时，其中一个事务才会等待另一个事务完成（并释放其行锁）。 rw-lockInnoDB用于根据某些规则表示并强制执行对内部内存数据结构(in-memory)的共享访问锁定的低级对象。与互斥(metexes)形成对比，InnoDB用它来表示和强制执行对内部内存数据结构的独占访问(exclusive access)。互斥锁和读写锁被统称为锁存器(latches)。 读写锁类型包括: s-locks(shared locks)，提供对公共资源的读访问权限； x-locks(exclusive locks)， 提供对公共资源的写访问权限，同事不允许其它线程进行不一致的读取； sx-locks(shared-exclusive locks)，提供对公共资源的写访问权限，同事允许其它线程进行不一致的读取。 - S SX X S Compatible Compatible Conflict SX Compatible Conflict Conflict X Conflict Conflict Conflict savepoint保存点(savepoint)有助于实现嵌套事务。它们可用于作为较大事务一部分的为表的操作提供范围。 scalability能够添加更多工作并向系统发出更多同时请求，而不会因超出系统容量而限制性能突然下降。 scale out横向扩展，一种通过添加新服务器和更多MySQL实例来提高可伸缩性的技术。 scale up纵向扩展，一种通过增加现有硬件或软件的容量来提供可扩展性的技术。 schema从概念上讲，模式(schema)是一组相互关联的数据库对象。如表、表列、列的数据类型、索引、外键…这些对象通过SQL语法连接，列构成表、外键引用表和列，依次类推。理想情况下，它们也是逻辑连接的，作为统一应用程序或灵活框架的一部分一起工作。在MySQL中，物理上，模式(schema)与数据库(database)是同义词。你可在MySQL SQL语法中使用关键字SCHEMA替换DATABASE。 1234567# 例如SHOW DATABASES;SHOW SCHEMAS;CREATE SHCEMA;CREATE DATABASE; search index在MySQL中，全文搜索(full-text search)查询使用特殊类型的FULLTEXT index。MySQL v5.6.4中，InnoDB和MyISAM都支持全文索引；以前，这些索引只支持MyISAM。 secondary index一种表示表列的子集的InnoDB索引。InnoDB表可以包含零个、一个或多个二级索引(辅助索引)。二级索引可用于满足仅查询来自索引列的值。对于更复杂的查询，他可用于标志表中的相关行，然后使用聚簇索引(clusterd index)通过查找检索这些行。传统上，创建和删除二级索引会因复制InnoDB表中的所有数据而产生大量开销。快速索引(fast index)创建功能使InnoDB二级索引的CREATE INDEX和DROP INDEX语句更快。 segmentInnoDB表空间的一个区。如果表空间类似于目录，则段与该目录中的文件类似。段可以增长，可以创建新段。 selectivity数据分布属性，列中不同值的数量除以表中的记录数。高选择性意味着列值相对独特，并且可以通过索引有效地检索。 semi-consistent read一种用于UPDATE语句测读操作，即READ COMMITTED和consistent read。当UPDATE语句检查已锁定的行时，InnoDB会将最新提交的版本返回给MySQL，以便MySQL可以确定该行是否与UPDATE的WHERE条件匹配。如果行匹配，MySQL再次读取该行，这次InnoDB锁定它或等待锁定它。这种类型的读取操作只能在事务具有READ COMMITTED隔离级别或启用innodb_locks_unsage_for_binlog配置项时发生。 SERIALIZABLE隔离级别(isolation level)，是用最保守的锁定策略，以防止任何其它事务插入或更改此事务读取的数据，直到完成为止。这样，可以在事务中反复运行相同的查询，并确保每次都检索相同的结果集。 shared lock一种锁，允许其它事务读取锁定的对象，并且还获取其上的其它共享锁，但不写入它。 shared tablespace引用系统表空间或通用表空间的另一种方法。MySQL 5.7中引入了通用表空间。多个表可以驻留在共享表空间中。只有一个表可以驻留在每个表的文件表空间中。 sharp checkpoint将重做条目包含在重做日志的某些部分中的所有脏缓冲池页面刷新到磁盘的过程。 shutdown停止MySQL Server的过程。 slave server通常缩短为slave。 slow query log一种用于MySQL Server处理的SQL语句的性能调整的日志。你必须先启用此功能才能使用它。 slow shutdown一种关闭，在完成之前执行额外的InnoDB flushing操作，也称为clean shutdown。由配置项innodb_fast_shutdown=0或命令SET GLOBAL innodb_fast_shudown=0;指定。 snapshot在特定时间的数据表示，即使其它事务提交更改，也保持相同。 sort buffer用于在创建InnoDB索引期间对数据进行排序的缓冲区。 space ID用于唯一标识MySQL实例中的InnoDB表空间的标识符。系统表空间的space ID始终未零。 sparse file一种文件类型，通过将标识空快的元数据写入磁盘而不是写入实际的空白空间来有效地使用文件系统空间。InnoDB透明页面压缩(transparent page compression)功能依赖于稀疏文件(sparse file)支持。 spin一种持续测试资源是否可用的等待操作类型。 SQL结构化查询语言(Structured Query Language)，是执行数据库的标准语言。 startup启动MySQL Server的过程。 statement-based replication一种复制形式，其中SQL语句从Master发送到Slave上重放(replay)。需要注意innodb_autoinc_lock_mode选项的设置，以避免自动增量锁定(auto-increment locking)的潜在时序问题。 statistics与每个InnoDB表和索引相关的估计值，用于构建有效的查询执行计划。 stemming能够根据共同的词根搜索单词的不同变体，如单数、复数，过去、现在、将来的动词时态。 stopword在全文索引中，一个被认为是普遍或微不足道的单词，它从搜索索引中被省略并在搜索查询中被忽略。 storage engineMySQL数据库的一个组件，用于执行存储、更新、查询数据的低级工作。 stored generated column其值是根据列定义中包含的表达式计算的一个列。 stored object一个存储的程序或试图。 stored program存储的例程(routine)(过程或函数)，触发器或事件调度程序事件。 stored routine一个存储的过程或函数。 strict mode由innodb_strict_mode选项控制的通用名称。启用此配置会导致某些通常被视为警告的情况被视为错误。 sublist在表示缓冲池的列表结构中，相对较旧且相对较新的页面由列表的不同部分表示。 supremum record索引中的伪记录(pseudo-record)，表示该索引中最大值之上的差距。 surrogate keysynthetic key的同义词名称。 synthetic key索引列，通常是主键，其中值是任意分配的。通常使用自增(auto-increment)列来完成。通过将值视为完全任意，你可以避免过度限制性规则和错误的应用程序假设。也称为surrogate key，与natural key相反。 system tablespace一个或多个数据文件(ibdate文件)，包含InnoDB相关对象(InnoDB数据字典)的元数据，以及更改缓冲区(change buffer)，双写缓冲区(doublewrite buffer)和可能的撤销日志(undo logs)。 .TRG文件包含触发器参数(trigger parameters)的文件。具有此扩展名的文件始终包含在由MySQL Enterprise Back产品的mysqlbackup令生成的备份中。 -.TRN文件包含触发器命名空间(trigger namespace)信息的文件。具有此扩展名的文件始终包含在由MySQL Enterprise Back产品的mysqlbackup令生成的备份中。 table每个MySQL表都与特定的存储引擎有关联。 InnoDB表具有影响性能(Performance)、可伸缩性(scalability)、备份(backup)、管理和开发的特定物理和逻辑特性。在文件存储方面，InnoDB表属于以下表空间类型之一: 共享的InnoDB系统表空间，由一个或多个idbdata文件组成； 每个表的文件表(file-per-table)空间，由单个.idb文件组成； 共享的通用表空间(general tablespace)，由单个.idb文件组成。 table lock一个阻止其它事务访问表的锁。InnoDB通过使用诸如DDL，row locks，用于处理DML语句和查询的一致读取(consistent reads)等技术，做出了相当大的努力来使这种锁不必要。你可使用LOCK TABLESSQL语句创建这样的锁，UNLOCK TABLES解除锁定。具体查看帮助HELP LOCK。 table scansee full table scan. table statisticssee statistics. table type存储引擎的过时同义词。 tablespace一个数据文件，可以保存一个或多个InnoDB表和相关索引的数据。系统表空间包含InnoDB数据字典。 temporary table其数据不需要真正持久化的表。例如，临时表可以用作复杂计算或转换中的中间结果的存储区域;崩溃后不需要恢复这些中间数据。有时，数据本身会在设定的时间自动删除，例如在事务结束或会话结束时。对于某些数据库产品，表本身也会自动删除。 temporary tablespaceMySQL 5.7中引入的非压缩InnoDB临时表和相关对象的表空间。innodb_temp_data_file_path配置选项定义临时表空间数据文件的相对路径，名称，大小和属性。如果未指定innodb_temp_data_file_path，则默认行为是在数据目录中创建名为ibtmp1的单个自动扩展12MB数据文件。在每个服务器启动时重新创建临时表空间，并接收动态生成的空间ID。临时表空间不能驻留在原始设备上。如果无法创建临时表空间，则拒绝启动。临时表空间在正常关闭或中止初始化时被删除。发生崩溃时，不会删除临时表空间。在这种情况下，数据库管理员可以手动删除临时表空间或使用相同的配置重新启动服务器，从而删除并重新创建临时表空间。 text collection全文索引(FULLTEXT INDEX)中包含的列集。 thread处理单元，通常比进程更亲量化，允许更大的并发性(concurrency)。 torn page由于I/O设备配置和硬件故障的组合可能发生的错误情况。如果数据以小于InnoDB页面大小的块（默认情况下为16KB）写出，则写入时硬件故障可能导致只有部分页面存储到磁盘。InnoDB doublewrite buffer可以防止这种可能性。 TPS每秒事务数(transaction per second)，是有时在基准测试中使用的度量单位。它的值取决于特定基准测试所代表的工作负载，以及一些配置情况。 transaction事务是可以提交(committed)或回滚(rolled back)的原子工作单元。当事务对数据库进行多次更改时，要么在提交事务时所有更改都成功，要么在事务回滚时撤消所有更改。 transaction ID与每行(row)相关的内部字段。通过INSERT, UPDATE, DELETE操作对此字段进行物理更改，以记录哪个事务已锁定该行。 transparent page compressionMySQL 5.7.8中添加的一项功能，允许对驻留在每个表文件表空间中的InnoDB表进行页面级压缩。通过使用CREATE TABLE或ALTER TABLE指定COMPRESSION属性来启用页面压缩。 transportable tablespace允许将表空间从一个实例移动到里一个实例的功能。 truncate一种DDL操作，用于删除表的全部内容，同时保持表和相关索引不变。 tuple指定有序元素集的技术术语。 two-phase commit作为XA规范下的分布式事务的一部分的操作。 undo在事务的整个生命周期中维护的数据，记录所有更改，以便在回滚操作时可以撤消这些更改。 undo buffersee undo log. undo log撤销日志，保存由活动事务修改的数据副本的存储区域。如果另一个事务需要查看原始数据（作为一致读取操作的一部分），则从该存储区域检索未修改的数据。 undo log segment撤销日志的集合。撤销日志段位于回滚段(rollback segments)中。撤销日志段可能包含来自多个事务的撤销日志。 undo tablespace撤销表空间包含撤销日志。 unique constraint唯一约束，列不能包含任何重复值。 unique key唯一键，包含唯一索引的列集(一个或多个)。如果可以定义仅与一行匹配的WHERE条件，并且查询可以使用关联的唯一索引，则可以非常有效地执行查找和错误处理。 variable-length type可变长度的数据类型。如VARCHAR, VARBINARY, BLOB, TEXT...InnoDB将长度大于或等于768Bytes的固定长度字段视为可变长度字段，可以在页外(off-page)存储。 victim检测到死锁时自动选择回滚的事务。可使用innodb_deadlock_detect配置项禁用死锁检测。 view一个存储的查询，在调用时会生成结果集。视图闯荡虚拟表(virutal table)。 virtual columnsee virtual generated column. virtual generated column一列，其列值是根据列定义中包含的表达式计算的。不存储列值，但在任何BEFORE触发器之后立即读取行时来计算列值。虚拟生成列不占用存储空间。InnoDB支持虚拟生成列的二级索引。 virtual index虚拟索引是一个或多个虚拟生成列上的二级索引，或是虚拟生成列与常规列或存储生成列的组合。 wait当无法立即完成诸如locak, mutex, latch等操作时，InnoDB会暂停并再次尝试。暂停的机制很精细，它也称为等待。 warm backup在数据库运行时进行备份，但在备份过程中限制某些数据库操作。例如，表可能变为只读。对于繁忙的程序，你可能更喜欢热备(hot backup)。 warm up在启动后的一段时间内在典型工作负载下运行系统，以便缓冲池和其他内存区域在正常条件下填充。当MySQL服务器重新启动或承受新工作负载时，此过程会自然发生。 workloadSQL和其他数据库操作的组合和数量，由数据库应用程序在典型或高峰使用期间执行。您可以在性能测试期间将数据库置于特定工作负载中，以识别瓶颈或在容量规划期间。 write combining一种优化技术，可在从InnoDB缓冲池中刷新(FLUSH)脏页面时减少写操作。 XA用于协调分布式事务的标准接口，允许多个数据库参与事务，同时保持ACID合规性。默认情况下启用XA分布式事务支持。如果您不使用此功能，则可以禁用innodb_support_xa配置选项，从而避免每个事务的额外fsync的性能开销。 youngInnoDB缓冲池中页面的一个特征意味着它最近已被访问，因此在缓冲池数据结构中移动，因此LRU算法不会很快刷新它。此术语用于与缓冲池相关的表的某些INFORMATION_SCHEMA列名称中。 安装和升级 mysql-repo: http://repo.mysql.com/ yum-repo: http://repo.mysql.com/yum/ 安装MySQL一般遵循以下步骤： 确定MySQL是否支持你的平台(platform) Unix、Linux、FreeBSD Windows OS X 选择要安装的发行版(distribution) 下载你想要安装的发行版 安装发行版 执行任何必要的安装后设置 通用安装指南General Installation Guidance 安装哪个发行版和MySQL版本Which MySQL Version and Distribution to Install 在准备安装MySQL时，请决定使用哪种版本(version)和发行(distribution)格式(binary or source) 首先，决定安装开发版还是稳定版。 Development release 具有新功能，但不推荐用于生产环境 General Availability(GA) release 也称为稳定版(stable release)，推荐为生产环境使用 MySQL命名方案(naming scheme)， 例如MySQL5.7.1： 5为主版本号(major) 7为次版本号(minor) 1为发行(release)系列版本号 系列号描述了稳定的功能集。对于每个新的修补程序，这都会增加。 在选择要安装的MySQL版本之后，决定要为操作系统安装哪个发行版格式。 二进制(binary) RPM, DMG 源码(source) tar, zip 在某些情况下，最好使用源码安装MySQL： 想在某个明确的位置安装MySQL 希望使用二进制发行版中未包含的特性配置mysqld 希望配置mysqld，而不需要二进制发行版中包含的一些功能 你希望读取或修改组成MySQL的C、C++源代码 源码发行版比二进制发行版包含更多的测试和示例 如何获取MySQLHow to Get MySQL MySQL当前版本下载页： https://dev.mysql.com/downloads/ 完整的MySQL镜像： https://dev.mysql.com/downloads/mirrors/ 基于RPM的Linux平台，MySQL Yum Repository： https://dev.mysql.com/downloads/repo/yum/ 基于Debian的Linux平台，MySQL APT Repository： https://dev.mysql.com/downloads/repo/apt/ SUSE Linux平台，MySQL SUSE Repository： https://dev.mysql.com/downloads/repo/suse/ 使用MD5校验和或GnuPG验证程序完整性Verifying Package Integrity Using MD5 Checksums or GnuPG 下载好MySQL包并在安装它之前，请确保它是完整的并未被篡改。有如下三种方法： MD5 checksums Cryptographic signatures using GnuPG, the GNU Privacy Guard For RPM packages, the built-in RPM integrity verification mechanism 验证MD5校验和Verifying the MD5 Checksum 应确保下载的MySQL包的MD5校验和与MySQL官方提供的校验和相匹配。 12md5sum mysql-standard-5.7.22-linux-i686.tar.gz#aaab65abbec64d5e907dcd41b8699945 mysql-standard-5.7.22-linux-i686.tar.gz 使用GnuPG进行签名检查Signature Checking Using GnuPG 要验证软件包的签名，首先需要我们的公共GPG密钥的副本。可从http://pgp.mit.edu/下载。你想要获得的密钥名为mysql-build@oss.oracle.com，如下: 12345678-----BEGIN PGP PUBLIC KEY BLOCK-----Version: GnuPG v1.4.5 (GNU/Linux)mQGiBD4+owwRBAC14GIfUfCyEDSIePvEW3SAFUdJBtoQHH/nJKZyQT7h9bPlUWC3RODjQReyCITRrdwyrKUGku2FmeVGwn2u2WmDMNABLnpprWPkBdCk96+OmSLN9brZfw2vOUgCmYv2hW0hyDHuvYlQA/BThQoADgj8AW6/0Lo7V1W9/8VuHP0gQwCgvzV3BqOx后面还有很多，省略-----END PGP PUBLIC KEY BLOCK----- 使用gpg --import将密钥导入到个人公共GPG密钥环中。如公共密钥为mysql_pubkey.asc： 12345gpg --import ./mysql_pubkey.asc#或使用public key id下载公共密钥gpg --recv-keys $pub-key-id 在rpm包中验证: 1rpm --import ./mysql_pubkey.asc 确保两个文件都放置于同一目录下，然后运行命令验证签名： 12345gpg --verify package_name.ascgpg --verify mysql-standard-5.7.22-linux-i686.tar.gz.ascgpg: Signature made Tue 01 Feb 2011 02:38:30 AM CST using DSA key ID 5072E1F5gpg: Good signature from &quot;MySQL Release Engineering &lt;mysql-build@oss.oracle.com&gt;&quot; 使用RPM进行签名检查Signature Checking Using RPM 1234rpm --checksig package_name.rpm[zhang@zabbix ~]$ rpm --checksig mysql-community-server-5.7.20-1.el7.x86_64.rpmmysql-community-server-5.7.20-1.el7.x86_64.rpm: (sha1) dsa sha1 md5 gpg OK rpm还支持从URL加载密钥: 1rpm --import http://dev.mysql.com/doc/refman/5.7/en/checking-gpg-signature.html 安装布局Installation Layouts 不同的安装类型(native packages, binary tarballs, and source tarballs)有不同的安装布局，这样可能会导致混淆。 在Unix/Linux上使用通用二进制文件安装MySQLInstalling MySQL on Unix/Linux Using Generic Binaries 包括以压缩的tar文件形式的通用二进制发行版，以及针对特定平台封装格式的二进制文件。 MySQL压缩tar文件二进制发行版具有 mysql-VERSION-OS.tar.gz的文件格式。 MySQL依赖于libaio Library： 1yum install -y libaio 默认地，tar文件二进制发行版，解压后安装于/usr/local/mysql目录。会在目录下生产 通用Unix/Linux二进制包的MySQL安装布局目录 目录 内容 bin mysqld server, client and utility programs docs MySQL manual in Info format man Unix manual pages include Include (header) files lib Libraries share Error messages, dictionary, and SQL for database installation support-files Miscellaneous support files 大致命令如下： 12345678910111213141516171819shell&gt; groupadd mysqlshell&gt; useradd -r -g mysql -s /bin/false mysqlshell&gt; cd /usr/localshell&gt; tar zxvf /path/to/mysql-VERSION-OS.tar.gzshell&gt; ln -s full-path-to-mysql-VERSION-OS mysqlshell&gt; cd mysqlshell&gt; mkdir mysql-filesshell&gt; chown mysql:mysql mysql-filesshell&gt; chmod 750 mysql-filesshell&gt; bin/mysqld --initialize --user=mysqlshell&gt; bin/mysql_ssl_rsa_setupshell&gt; bin/mysqld_safe --user=mysql &amp;# Next command is optionalshell&gt; cp support-files/mysql.server /etc/init.d/mysql.server#添加环境变量export PATH=$PATH:/usr/local/mysql/bin 在Linux上安装MySQLInstalling MySQL on Linux Linux支持多种方法来安装MySQL。建议使用Oracle提供的一个发行版： Apt Yum Zypper RPM DEB Generic Source Docker Oracle Unbreakable Linux Network 作为一个选择，你可以使用系统中的包管理工具自动下载和安装MySQL。 在Linux上使用Yum Repository安装MySQLInstalling MySQL on Linux Using the MySQL Yum Repository 安装一个全新的MySQL的步骤： 添加MySQL Yum Repository 首先，添加MySQL Yum repository到你的系统仓库列表 选择和下载对应平台的release 或者 手动添加repository文件 安装release package 12345#yum localinstall platform-and-version-specific-package-name.rpmyun install http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql57-community-release-el7-10.noarch.rpmyum repolist enabled | grep "mysql.*-community.*" 选择一个release series 默认是最新的GA series，当前最新是MySQL5.7。 查看所有的MySQL Yum repository: yum repolist all | grep mysql 安装最新MySQL不需要配置，而安装先前的版本则需要指定GA series。disable最新的GA series并且enable需要的GA series。 123yum-config-manager --disable mysql57-communityyum-config-manager --enable mysql56-community 或者手动创建repo，可直接定义版本 123456[mysql57-community]name=MySQL 5.7 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.7-community/el/7/$basearch/enabled=1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 安装MySQL 在安装MySQL过程中出现错误，请务必查看日志文件。 123yum install -y mysql-community-server mysql-community-client#也可不安装客户端 开启MySQL Server 1234service mysqld start#Starting mysqld:[ OK ]service mysqld status 在服务器初始启动时，如果服务器的数据目录为空，则会发生一下情况： 服务器已初始化 SSL certificate and key files 在数据目录中生成 validate_password已安装并启用 超级用户账户’root’@’localhost’被创建，超级用户密码被设置并被存储在error log files 这一点和以前版本有很大区别，我被坑惨了 注意： ValidPassword的默认密码策略要求包含大写字母、小写字母、数字和特殊字符，并且密码长度至少为8个字符 123456789101112131415161718192021222324252627#查看初始密码grep &apos;temporary password&apos; /var/log/mysqld.log#无法使用mysqladmin修改密码，需要登录mysql后修改mysql -uroot -p#重置密码ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;NewPass4!;#如果找不到初始密码vim /etc/my.cnf#在[mysqld]最后行加上skip-grant-tables实现无认证登录#重启MySQLUPDATE mysql.user SET authentication_string =PASSWORD(&apos;新密码&apos;) WHERE USER=&apos;xxx&apos;;#修改默认密码策略#更改密码强度set global validate_password_policy=0;#设置密码最小长度set global validate_password_length=4; 使用Yum安装额外的MySQL产品和组件 你可使用Yum安装和管理MySQL的个别组件。 123456yum --disablerepo=\* --enablerepo='mysql*-community*' list availableyum install package-name#栗子yum install mysql-community-libs 在Linux上使用Oracle提供的RPM包安装MySQLInstalling MySQL on Linux Using RPM Packages from Oracle MySQL Community Edition的rpm包如下： 包名 描述 mysql-community-server Database server and related tools mysql-community-client MySQL client applications and tools mysql-community-common Common files for server and client libraries mysql-community-server-minimal Minimal installation of the database server and related tools mysql-community-devel Development header files and libraries for MySQL database client applications mysql-community-libs Shared libraries for MySQL database client applications mysql-community-libs-compat Shared compatibility libraries for previous MySQL installations mysql-community-embedded MySQL embedded library mysql-community-embedded-devel Development header files and libraries for MySQL as an embeddable library mysql-community-test Test suite for the MySQL server 123456789#rpm -qpl mysql-community-server-version-distribution-arch.rpm#yum install mysql-community-&#123;server,client,common,libs&#125;-*wget http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql-community-server-5.7.20-1.el7.x86_64.rpmwget http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql-community-client-5.7.20-1.el7.x86_64.rpmyum install -y mysql-community-server-5.7.20-1.el7.x86_64.rpm mysql-community-client-5.7.20-1.el7.x86_64.rpm Linux RPM包MySQL开发区的安装布局： 文件或资源 位置 Client programs and scripts /usr/bin mysqld server /usr/sbin configuration file /etc/my.cnf data directory /var/lib/mysql error log file /var/log/mysqld.log Value of secure_file_priv /var/lib/mysql-files System V init script /etc/init.d/mysqld Systemd service mysqld pid file /var/run/mysql/mysqld.pid socket /var/lib/mysql/mysql.sock Keyring directory /var/lib/mysql-keyring Unix manual pages /usr/share/man include (header) files /usr/include/mysql Libraries /usr/lib/mysql Miscellaneous support files (for example, error messages, and character set files) /usr/share/mysql The installation also creates a user named mysql and a group named mysql on the system. 注意安装MySQL会在系统上生成一个名为mysql的用户和群组安装以前的MySQL版本可能会创建my.cnf配置文件。强烈建议先将my.cnf进行迁移，然后删除它。之后才安装MySQL 用systemd管理MySQL ServerManaging MySQL Server with systemd systemd综述Overview of systemd systemd提供了MySQL Server的自动开启和关闭，使用systemctl命令进行管理。 或者，使用system V系统兼容的service命令。 123systemctl &#123;start|stop|restart|status&#125; mysqldservice mysqld &#123;start|stop|restart|status&#125; 对systemd的支持包括这些文佳： mysqld.service systemd服务单元配置文件，以及有关MySQL服务的详细信息 mysqld@.service 用于管理多个MySQL实例 mysqld.tmpfiles.d 包含支持临时文件功能的信息 mysqld_pre_systemd 支持单元文件的脚本 为MySQL配置systemdConfiguring systemd for MySQL 为MySQL添加或修改systemd选项，参考如下方法： 使用一个本地化的systemd配置文件 安排systemd为MySQL Server进程设置环境变量 设置MYSQLD_OPTS systemd变量 创建/etc/systemd/system/mysqld.service本地化systemd配置文件，这里讨论的是将此文件名作为override.conf： 1234567891011121314[Service]LimitNOFILE=max_open_filesPIDFile=/path/to/pid/fileNice=nice_levelLimitCore=core_file_limitEnvironment="LD_PRELOAD=/path/to/malloc/library"Environment="TZ=time_zone_setting"#LimitNOFILE: 文件描述符数量#LimitCore: 最大核心文件大小#Nice: 优先级#LD_PRELOAD: 特定内存分配库#TZ: 指定时区 修改mysqld: 1systemctl edit mysqld 重新加载systemd配置，然后重启MySQL service： 123systemctl daemon-reloadsystemctl restart mysqld 可在override.conf中设置如下参数： 1234[Service]PIDFile=/var/run/mysqld/mysqld-custom.pidExecStart=ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld-custom.pid $MYSQLD_OPTS 在/etc/sysconfig/mysql下指定值： 12345LD_PRELOAD=/path/to/malloc/libraryTZ=time_zone_settingsystemctl restart mysqld 使用systemd配置多个MySQL实例Configuring Multiple MySQL Instances Using systemd 由于systemd具有在平台上管理多个MySQL实例的能力，而不必须需要mysqld_multi和mysqld_multi.server。 若要使用多实例(multiple-instance)功能，请修改/etc/my.cnf文件以包含每个实例的关键选项配置。例如，管理replication01和replication02两个实例： 123456789101112131415vim /etc/my.cnf[mysqld@replica01]datadir=/var/lib/mysql-replica01socket=/var/lib/mysql-replica01/mysql.sockport=3307log-error=/var/log/mysqld-replica01.log[mysqld@replica02]datadir=/var/lib/mysql-replica02socket=/var/lib/mysql-replica02/mysql.sockport=3308log-error=/var/log/mysqld-replica02.log 这里的名称使用@作为分隔符(delimiter)，因为这个是systemd支持的唯一分隔符。 管理两个实例: 12345678910111213systemctl start mysqld@replica01systemctl start mysqld@replica02systemctl enable mysqld@replica01systemctl enable mysqld@replica02#使用通配符systemctl status &apos;mysqld@replica*&apos;systemctl stop mysqld@replica0&#123;1,2&#125; 对于同一个机器上的不同MySQL实例，systemd自动使用不同的单元文件。在unit file中，%I和%i用于@标记后传入参数，用于管理特定实例。 12345678910111213141516171819#像这样mysqld --defaults-group-suffix=@%I ...systemctl status mysqld@replica01# mysqld@replica01.service - MySQL Server# Loaded: loaded (/usr/lib/systemd/system/mysqld@.service; disabled; vendor preset: disabled)# Active: active (running) since Tue 2018-02-27 12:18:34 CST; 1min 6s ago# Docs: man:mysqld(8)# http://dev.mysql.com/doc/refman/en/using-systemd.html# Process: 3927 ExecStart=/usr/sbin/mysqld --defaults-group-suffix=@%I --daemonize --pid-file=/var/run/mysqld/mysqld-%i.pid $MYSQLD_OPTS (code=exited, status=0/SUCCESS)# Process: 3845 ExecStartPre=/usr/bin/mysqld_pre_systemd %I (code=exited, status=0/SUCCESS)#Main PID: 3930 (mysqld)# CGroup: /system.slice/system-mysqld.slice/mysqld@replica01.service# `-3930 /usr/sbin/mysqld --defaults-group-suffix=@replica01 --daemonize --pid-file=/var/run/mysqld/mysqld-replica01.pid##eb 27 12:18:27 zabbix.me systemd[1]: Starting MySQL Server...#eb 27 12:18:34 zabbix.me systemd[1]: Started MySQL Server. 从mysqld_safe迁移到systemdMigrating from mysqld_safe to systemd 因为mysqld_safe没有安装在使用systemd管理MySQL的平台上，所以以前需要为该程序指定选项：[mysqld_safe] 一些[mysqld_safe]的选项也能被[mysqld]支持 一些[mysqld_safe]的选项类似于[mysqld]选项 从源码安装MySQLInstalling MySQL from Source 从源代码构建MySQL使我们能够自定义构建参数(parameter)、编译器优化(compiler optimization)和安装位置(installation location)。 在使用源码安装前，请检查Oracle是否为你的平台生成预编译的二进制发行版，以及是否适合你。Oracle付出了很多努力确保提供的二进制文件具有最佳的性能选择。 源码安装系统需求：使用源码安装MySQL需要多种开发工具。 使用源码安装MySQL，必须满足一下系统需求： CMake, which is used as the build framework on all platforms A good make program A working ANSI C++ compiler The Boost C++ libraries are required to build MySQL The ncurses library Sufficient free memory Perl is needed if you intend to run test scripts 使用standard source distribution安装MySQL，需要以下工具来unpack分发文件： For a .tar.gz compressed tar file: tar For a .zip Zip archive: zip For an .rpm RPM package: rpmbuild 用于源码安装的MySQL布局MySQL Layout for Source Installation 默认地，再从源码编译后安装MySQL时，安装步骤会将文件安装在/usr/local/mysql下。 使用标准源码发行版安装MySQLInstalling MySQL Using a Standard Source Distribution 从一个标准源码发行版安装MySQL： 确保系统满足工具需求 获取发行文件 配置、构建和安装 执行安装后程序 如果是source RPM: 1rpmbuild --rebuild --clean MySQL-VERSION.src.rpm 如果是compressed tar file 或 zip archive source: 12345678910111213141516171819202122232425262728# Preconfiguration setupshell&gt; groupadd mysqlshell&gt; useradd -r -g mysql -s /bin/false mysql# Beginning of source-build specific instructionsshell&gt; tar zxvf mysql-VERSION.tar.gzshell&gt; cd mysql-VERSIONshell&gt; mkdir bldshell&gt; cd bldshell&gt; cmake ..shell&gt; makeshell&gt; make install# End of source-build specific instructions# Postinstallation setupshell&gt; cd /usr/local/mysqlshell&gt; mkdir mysql-filesshell&gt; chown mysql:mysql mysql-filesshell&gt; chmod 750 mysql-filesshell&gt; bin/mysqld --initialize --user=mysqlshell&gt; bin/mysql_ssl_rsa_setupshell&gt; bin/mysqld_safe --user=mysql &amp;# Next command is optionalshell&gt; cp support-files/mysql.server /etc/init.d/mysql.server /sbin/nologin和/bin/false的区别 /bin/false是最严格的禁止login选项，一切服务都不能用 mongod:x:996:994:mongod:/var/lib/mongo:/bin/false /sbin/nologin只是不允许系统login，可以使用其他服务 ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin 执行预配置(preconfiguration)设置 在Unix上，设置MySQL用户和组，用于运行和执行MySQL服务器和数据库目录。 获得和解包distribution 选择要解压分发的目录，并将位置更改到其中。 1234tar zxvf mysql-VERSION.tar.gz#gunzip &lt; mysql-VERSION.tar.gz | tar xvf -#cmake -E tar zxvf mysql-VERSION.tar.gz 使用开发源码树安装MySQLInstalling MySQL Using a Development Source Tree install MySQL from the latest development source codew hich is hosted on GitHub: https://github.com/mysql/mysql-server 设置一个MySQL git repository 克隆MySQL git repository到本机 1git clone https://github.com/mysql/mysql-server.git 查看 1cd mysql-server 使用git branch -r查看远程MySQL分支 123cd mysql-servergit branch -r 查看分支 123cd mysql-servergit branch 切换分支 123cd mysql-servergit checkout 5.7 获取远程MySQL git repository更新 123cd mysql-servergit pull 检查提交历史 12345cd mysql-servergit log#也可在MySQL GitHub上查看commit history 在克隆MySQL git repository并切换到需要的分支后，便可以从源代码构建MySQL Server。 在生产机器上从分发源码树安装构件时要小心，安装命令可能会覆盖您的实时发行版安装。 MySQL源码配置选项MySQL Source-Configuration Options CMake程序提供了一个强大的如何配置MySQL源码发行版的控制。 具体链接参考: https://dev.mysql.com/doc/refman/5.7/en/source-configuration-options.html 处理MySQL编译问题Dealing with Problems Compiling MySQL 如果CMake先前已经运行过，那么现在运行的CMake可能使用先前的调用过程中收集到的信息。这些信息存储在 CMakeCache.txt。在CMake启动时，它会寻找和读取此文件。 每次运行CMake，必须再次运行make才能重新编译。 防止使用old object file或配置文件: 12make cleanrm CMakeCache.txt 安装之后的设置和测试Postinstallation Setup and Testing 在安装MySQL后你应该做的事： 如有必要，初始化数据目录并创建MySQL授权表 开启Server并确保它可以正常访问 将密码分配给授权表中的root用户 可选地，设置Server自启动 可选地，填写时区表，以便识别时区 初始化数据目录Initializing the Data Directory 安装MySQL之后，必须初始化数据目录，包括mysql系统数据库中的表。有些安装方法会自动初始化，有些则需要手动初始化。当然，如果修改了默认数据目录位置，那么也是需要手动初始化的。 初始化数据库目录，主要是包含了初始MySQL授权表(grant table)的MySQL服务器，这些表确定了如何允许用户连接到服务器。但是，初始化数据目录是不会覆盖(overwrite)任何现有权限表，因此在任何情况下运行都是安全的。 数据目录初始化会在MySQL数据库汇总创建time zone，但不会填充它，所以它是空的。 123456789101112131415cd /usr/local/mysqlmkdir mysql-fileschown mysql:mysql ./mysql-fileschmod 750 ./mysql-files#--user#使数据库目录文件属于mysql用户，以确保Server有读取权限/usr/local/mysql/bin/mysqld --initialize --user=mysql#开启安全连接/usr/local/mysql/bin/mysql_ssl_rsa_setup 使用mysqld手动初始化数据目录Initializing the Data Directory Manually Using mysqld 1234567891011121314151617181920212223242526cd /usr/local/mysql/bin#使数据库目录文件属于mysql用户，以确保Server有读取权限#默认是secure，会生成root初始密码./mysqld --initialize --user=mysql#不生成root初始密码./bin/mysqld --initialize-insecure --user=mysql#指定目录--basedir=/usr/local/mysql--datadir=/var/lib/mysql#或者将其写入配置文件vim /etc/my.cnf[mysqld]basedir=/usr/local/mysqldatadir=/var/lib/mysql#指定配置文件初始化./mysqld --defaults-file=/etc/mysql.cnf --initialize --user=mysql 使用mysql_install_db初始化数据目录Initializing the Data Directory Manually Using mysql_install_db 1234567891011121314151617cd /usr/local/mysql/bin#mysql_install_db命令会创建数据目录，并在数据目录下创建mysql数据库和授权表./mysql_install_db --user=mysql#指定目录是必须的--basedir=/usr/local/mysql--datadir=/var/lib/mysql./mysqld_safe --user=mysql &amp;#systemctl start mysqldmysql -u root -p xxxmysql&gt;SET PASSWORD FOR 'root'@'localhost' = PASSWORD('new_password'); Starting the Server Start the MySQL server like this if your installation includes mysqld_safe /usr/local/mysql/binmysqld_safe --user=mysql &amp; Start the server like this if your installation includes systemd support systemctl start mysqld 使用non-root用户运行MySQL服务很重要 如有错误请查看日志 Testing the Server执行一些简单测试以保证Server正常工作。 1234567891011121314151617181920#使用mysqladmin验证Server正在运行mysqladmin --helpmysqladmin -uuser -ppasswd versionmysqladmin -uuser -ppasswd variablesmysqladmin -user -ppasswd shutdown# 使用mysqlshow查看数据库mysqlshow -uuser -ppasswd#查看指定数据库信息mysqlshow -uuser -ppasswd mysql#读取信息#-e,Execute command and quitmysql -uuser -ppasswd -e "SELECT user, host from mysql.user" 保护初始化MySQL账户Securing the Initial MySQL Accounts 在安装MySQL后，root账户密码可能已经被分配。 mysql.user授权表定义了初始化MySQL用户账户和它们的访问权限。MySQL5.7只创建了一个&#39;root&#39;@&#39;localhost&#39;账户，但早期的版本可能有多个用户。 请务必为每一个MySQL账户创建密码。 查看用户： 1234567891011121314#存储在authentication_string列中的密码可能包含无法正常显示的二进制数据#所以将其转换为十六进制mysql&gt; SELECT user, host, hex(authentication_string) FROM mysql.user;mysql&gt; SELECT user, host, authentication_string FROM mysql.user;#或mysql -uuser -ppasswd -e "SELECT user, host, hex(authentication_string) FROM mysql.user;"#5.7以前的版本mysql&gt; mysql&gt; SELECT user, host, password FROM mysql.user;#或mysql -uuser -ppasswd -e "SELECT user, host, password FROM mysql.user;" 为root账户分配密码 12345678910#5.7.6mysql&gt; ALTER USER user IDENTIFIED BY &apos;new_passwd&apos;;mysql&gt; ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;new_passwd&apos;;#5.7.6前mysql&gt; SET PASSWORD FOR username = PASSWORD(&apos;new_passwd&apos;);mysql&gt; SET PASSWORD FOR &apos;root&apos;@&apos;localhost&apos; = PASSWORD(&apos;new_passwd&apos;); 给anonymous账户分配密码 1mysql&gt; SET PASSWORD FOR &apos;&apos;@&apos;localhost&apos; = PASSWORD(&apos;new_passwd&apos;); 移除匿名账户 1mysql&gt; DROP USER &apos;&apos;@&apos;localhost&apos;; 升级或降级MySQLUpgrading or Downgrading MySQL 升级是一个常见的过程。请在测试系统上确保运行正常后再实施到生产环境 降级不太常见。一般是由于新版本在生产环境上发生某些兼容性或性能问题，并且是在测试环境中没有发现的情况下，从而需要降级。请现在测试系统上运行正常后再实施到生产环境。 升级MySQL请使用有管理权限的MySQL账户执行升级相关命令。(如root账户) MySQL升级策略MySQL Upgrade Strategies 升级方法 直接升级(In-Place Upgrade) 包含关闭旧版MySQL，替换为新的MySQL版本，在现有数据目录上重启MySQL，运行mysql_upgrade 逻辑升级(Logical Upgrade) 包含使用mysqldump导出现有数据文件，安装新版MySQL，导入数据文件到新版MySQL，运行mysql_upgrade 升级路径 只支持GA release之间 这是一个发行系列的升级 如5.6.x到5.6.y 升级到下一个版本之前，建议先升级到最新版本 如先升级到5.6最新版，再升级到5.7 不支持跳版本升级 如5.5到5.7 升级之前 升级之前，请一定备份数据 查看新版本的Release Note 删除和增加了什么功能 新版本依赖什么 如果在InnoDB中使用XA事务，则在升级之前运行XA恢复以检查未提交的XA事务 如果MySQL数据量很大，就地升级以后可能需要很长的时间才能进行转换 你可能会发现创建一个”dummy”数据库实例是很有用的，以及评估可能需要哪些转换以及执行这些转换所涉及的工作 无论在你安装或升级到一个MySQL新版本，建议重建和重装MySQL language interface 如PHP MySQL扩展 直接升级 配置MySQL执行slow shutdown innoDB在关闭前执行一个完整的清除和更改缓冲区合并，这确保数据文件在不同的版本的文件格式做好充分准备。 1mysql -u root -p --execute="SET GLOBAL innodb_fast_shutdown=0" 关闭MySQL Server 1mysql -uroot -p shutdown 升级MySQL 开启新版MySQL 运行mysql_upgrade mysql_upgrade检查所有数据库中的所有表与当前版本MySQL的不兼容性。 1234mysql_upgrade -uroot -p#Upgrade process completed successfully.#Checking if update is needed. 关闭和重启MySQL Server来确保改变生效 123mysqladmin -uroot -p shutdownsystemctl start mysqld 逻辑升级 导出所有数据 1234567mysqldump -uroot -p --all-databases --force &gt; mysqldb_backup.sql#-f, --force Continue even if we get an SQL error#Use the --routines and --events options if your databases include stored programs#--add-drop-database Add a DROP DATABASE before each create.mysqldump -uroot -p --add-drop-table --routines --events --all-databases --force &gt; mysqldb_backup.sql 关闭MySQL Server 1mysqladmin -uroot -p shutdown 安装新版MySQL 初始化MySQL并启动 载入数据文件 1mysql -uroot -p --force &lt; ./mysqldb_backup.sql 运行mysql_upgrade 1234mysql_upgrade -uroot -p#Upgrade process completed successfully.#Checking if update is needed. 关闭并重启MySQL Server以确保更改生效 通过MySQL Yum Repository进行升级Upgrading MySQL with the MySQL Yum Repository 选择一个target series 默认情况下，MySQL Yum Repository会将MySQL升级到该release系列的最新版本。如5.7.1升级到5.7.10。 如果要升级到其他release(如5.6到5.7)，就必须要先禁用此subrepository，并选择和启用新的subrepository。 As a general rule, to upgrade from one release series to another, go to the next series rather than skipping a series. 升级MySQL 1yum update mysql-server mysql-client 重启MySQL MySQL Server总是在Yum更新之后重启，一旦重启，请运行mysql_upgrade来检查旧数据与升级软件之间的任何不兼容问题。 1234mysql_upgrade -uroot -p#Upgrade process completed successfully.#Checking if update is needed. 升级Shared Client Libraries 所以说，用yum repository安装软件是很方便的。不管是在管理还是升级等方面… 通过直接下载RPM包升级MySQL直接下载mysql相应组件的rpm进行升级。建议备份好配置文件。 12345wget http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql-community-server-5.7.20-1.el7.x86_64.rpmwget http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql-community-client-5.7.20-1.el7.x86_64.rpmyum install mysql-community-server-5.7.20-1.el7.x86_64.rpm mysql-community-client-5.7.20-1.el7.x86_64.rpm mysql降级MySQL降级类似于MySQL升级。也包含有直接降级和逻辑降级。 重建或修复表或索引Rebuilding or Repairing Tables or Indexes MySQL处理数据类型和字符集的方式的更改 表维修或升级(mysqlcheck, mysql_upgrade) 重建表的方法： Dump and Reload ALTER TABLE REPAIR TABLE Dump and Reload Method 由于MySQL升级/降级之后，不同版本的MySQL无法处理这些表，则需要转储和重载的方法来重建表。 12345678910mysqldump -uroot -p --all-databases --force &gt; mysql_backdb.sqlmysql -uroot -p --force &lt; mysql_backdb.sql#某个库或表mysqldump -uroot -p --databases test --force &gt; db_test.sqlmysql -uroot -p test &lt; db_test.sqlmysqldump -uroot -p --databases test --tables table222 &gt; table222.sqlmysql -uroot -p test &lt; table222.sql ALTER TABLE Method 更改表以使用它已经拥有的存储引擎。 1ALTER TABLE test ENGINE = InnoDB; REPAIR TABLE Method REPAIR TABLE仅适用于MyISAM， ARCHIVE和 csv 表。 mysqlcheck --repair提供了对REPAIR TABLE的命令行访问。 12345REPAIR TABLE t1;mysqlcheck --repair --databases db_name ...mysqlcheck --repair --all-databases 复制MySQL数据库到其他机器Copying MySQL Databases to Another Machine 在需要为不同体系架构之间传输MySQL数据库时，可使用mysqldump创建包含SQL语句的.sql文件，然后复制到另外的计算机上，将其作为输入提供给MySQL客户端。 不要忘记复制mysql数据库，因为这个存储授权表的地方。 123456mysqldump --host &apos;remote-host&apos; -uxxx -p --compress --all-databases | mysql -uxxx -pmysqldump --host &apos;remote-host&apos; -uxxx -p --compress db_name | mysql -uxxx -p db_namemysqladmin -uxxx -p flush-privileges Tutorial如何使用MySQL client程序来创建和使用数据库。 连接和断开服务器Connecting to and Disconnecting from the Server Like this: 不建议把密码直接写在命令行上 host表示了MySQL Server运行在的机器 某些MySQL允许匿名用户连接 -ppassword, not as -p password 123456789101112131415mysql --host host --user username -p#maybe not default portmysql --host host --user username -p --port port#匿名用户连接mysql#退出mysql&gt; QUIT#Unixmysql&gt; Ctrl+D 输入查询Entering Queries 1234567891011121314151617#简单查询mysql&gt; SELECT VERSION(), CURRENT_DATE;#简单计算SELECT SIN(PI()/2), (4+1)*5;#一行中输入多个语句SELECT VERSION(); SELECT NOW();#多行输入一个命令mysql&gt; SELECT -&gt; USER() -&gt; , -&gt; CURRENT_DATE; 这QUERY说明了有关MySQL的几件事： MySQL查询通常由一个SQL statement和;组成 MySQL将查询发送给服务器并返回结果，然后打印下一个mysql&gt;提示 MySQL以表格形式(rows and columns)显示查询输出 MySQL显示返回多少行，以及执行查询花费了多长时间 MySQL查询不区分大小写，但建议使用大写 MySQL支持在一行中输入多个语句 MySQL支持一个命令多行输入 MySQL提示符： Prompt Meaning mysql&gt; 准备新查询 -&gt; 等待多行查询的下一行 &#39;&gt; 等待下一行，等待单引号开头的字符串的完成 &quot;&gt; 等待下一行，等待双引号字开头的字符串的完成 \&gt;` 等待下一行，等待以反引号开始的标识符的完成 /*&gt; 等待下一行，等待以/*开头的注释的完成—&gt;/*comments*/ 创建和使用数据库Creating and Using a Database 大致操作： Create a database Create a table Load data into the table Retrieve data from the table in various ways Use multiple tables 123456789101112131415161718#显示数据库#不能显示你没有权限的数据库mysql&gt; SHOW DATABASES;#mysql数据库描述用户访问权限#test数据库通常作为用户尝试使用工作区#访问数据库mysql&gt; USE test;#USE和QUIT一样可以不使用分号，使用也无妨#USE只能是一个单行#授权#GRANT ALL ON da_name.table TO 'username'@'host';mysql&gt; GRANT ALL ON test.* TO 'test'@'127.0.0.1'; 创建和选择数据库Creating and Selecting a Database Unix是区分大小写的(case-sensitive)，这与SQL keyword不一致。请注意。 12345678910mysql&gt; CREATE DATABASE db01;mysql&gt; USE db01;#也可在mysql连接时直接指定数据库mysql -u username -p db01#查看当前选择的数据库mysql&gt; SELECT DATABASE(); 创建表Creating a Table 困难的部分是决定数据库的结构应该是什么： 你需要哪些表以及每个表中应该包含哪些列。 VARCHAR对于name，owner，species来说是一个不错的选择，因为column值的长度有所不同。DATE对于出生和死亡column来说很不错。如果以后你发现你需要更长的字段，MySQL提供了一个ALTER TABLE语句来修改。 12345678910111213141516171819202122#创建一个宠物表mysql&gt; CREATE TABLE pet (name VARCHAR(20), owner VARCHAR(20), -&gt; species VARCHAR(20), sex CHAR(1), birth DATE, death DATE);mysql&gt; SHOW TABLES;#验证表格#如果你忘记了表中列的名称或类型，使用DESCRIBEmysql&gt; DECRIBE pet;+---------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+---------+-------------+------+-----+---------+-------+| name | varchar(20) | YES | | NULL | || owner | varchar(20) | YES | | NULL | || species | varchar(20) | YES | | NULL | || sex | char(1) | YES | | NULL | || birth | date | YES | | NULL | || death | date | YES | | NULL | |+---------+-------------+------+-----+---------+-------+6 rows in set (0.00 sec) 将数据载入表格Loading Data into a Table 假设pet表信息如下： name owner species sex birth death PetA Aa cat f 1993-02-04 PetB Bb cat m 1994-03-17 PetC Cc dog f 1989-05-13 PetD Aa dog m 1979-08-25 1995-02-21 PetE Cc bird 1991-02-17 你可以创建一个pet.txt文本文件，每行包含一个记录，值由制表符分割，并按照CREATE TABLE语句中列出的顺序给出。 12345678vim pet.txtPetA Aa cat f 1993-02-04 \NPetB Bb cat m 1994-03-17 \NPetC Cc dog f 1989-05-13 \NPetD Aa dog m 1979-08-25 1995-02-21PetE Cc bird \N 1991-02-17 \N 将pet.txt载入pet表中： 123456789101112131415161718192021222324252627mysql&gt; LOAD DATA LOCAL INFILE '/path/file.txt' INTO TABLE table_name;mysql&gt; LOAD DATA LOCAL INFILE '/home/zhang/pet.txt' INTO TABLE pet;Query OK, 5 rows affected, 0 warnings (0.00 sec)Records: 5 Deleted: 0 Skipped: 0 Warnings: 0mysql&gt; SELECT * FROM pet;+-------+-------+---------+------+------------+------------+| name | owner | species | sex | birth | death |+-------+-------+---------+------+------------+------------+| PetA | Aa | cat | f | 1993-02-04 | NULL || PetB | Bb | cat | m | 1994-03-17 | NULL || PetC | Cc | dog | f | 1989-05-13 | NULL || PetD | Aa | dog | m | 1979-08-25 | 1995-02-21 || PetE | Cc | bird | NULL | 1991-02-17 | NULL |+-------+-------+---------+------+------------+------------+5 rows in set (0.00 sec)#通过命令行载入mysql&gt; INSERT INTO pet -&gt; VALUES ('PetF', 'Ff', 'hamster', 'f', '1999-03-21', NULL) -&gt; ;Query OK, 1 row affected (0.00 sec) 从表中检索信息Retrieving Information from a Table SELECT语句用于从表中提取信息： 123SELECT what_to_selectFROM which_tableWHERE condition; 查询所有数据Selecting All Data 1234567mysql&gt; SELECT * FROM pet;mysql&gt; DELETE FROM pet;mysql&gt; UPDATE pet SET birth = '1989-06-17' WHERE name = 'PetC'; 查询特定行Selecting Particular Rows 当一个表很大时，你通常不想看到整个表。 123456789101112131415161718192021#条件查询mysql&gt; SELECT * FROM pet WHERE name = 'PetA';mysql&gt; SELECT * FROM pet WHERE owner = 'Cc';mysql&gt; SELECT * FROM pet WHERE birth &gt;= '1990-01-01';#ANDmysql&gt; SELECT * FROM pet WHERE species = 'dog' AND sex = 'f';#ORmysql&gt; SELECT * FROM pet WHERE species = 'dog' OR species = 'bird';#AND和OR也可以混合使用mysql&gt; SELECT * FROM pet WHERE (species = 'cat' AND sex = 'm') OR (species = 'dog' AND sex='f'); 查询特定列Selecting Particular Columns 12345678910111213141516171819mysql&gt; SELECT name FROM pet;mysql&gt; SELECT name, species FROM pet;#获取唯一结果mysql&gt; SELECT DISTINCT species FROM pet;+---------+| species |+---------+| cat || dog || bird |+---------+3 rows in set (0.00 sec)mysql&gt; SELECT name, species, birth FROM pet WHERE species = 'dog' OR species = 'cat'; 行排序Sorting Rows 使用ORDER BY语句对结果进行排序。默认排序顺序是升序。 123456789101112131415mysql&gt; SELECT name, birth FROM pet ORDER BY birth;+------+------------+| name | birth |+------+------------+| PetD | 1979-08-25 || PetC | 1989-06-17 || PetE | 1991-02-17 || PetA | 1993-02-04 || PetB | 1994-03-17 |+------+------------+5 rows in set (0.00 sec)#倒序mysql&gt; SELECT name, birth FROM pet ORDER BY birth DESC; 可对多列进行排序，也可按不同的方向对不同的列进行排序。 12345678910111213141516mysql&gt; SELECT name, species, birth FROM pet -&gt; ORDER BY species, birth DESC;+------+---------+------------+| name | species | birth |+------+---------+------------+| PetE | bird | 1991-02-17 || PetB | cat | 1994-03-17 || PetA | cat | 1993-02-04 || PetC | dog | 1989-06-17 || PetD | dog | 1979-08-25 |+------+---------+------------+5 rows in set (0.00 sec)mysql&gt; SELECT name, species, birth FROM pet -&gt; ORDER BY species DESC, birth DESC 日期计算Date Calculations MySQL提供了几个函数用于日期计算。如计算年龄或提取日期一部分等。 TIMESTAMPDIFF() 使用TIMESTAMPDIFF()函数计算pet的年龄。它的两个参数为两个相隔的日期 12345678910111213141516171819202122232425262728mysql&gt; SELECT name, species, birth, CURDATE(), -&gt; TIMESTAMPDIFF(YEAR, birth, CURDATE()) AS age -&gt; FROM pet -&gt; ORDER BY age DESC;+------+---------+------------+------------+------+| name | species | birth | CURDATE() | age |+------+---------+------------+------------+------+| PetD | dog | 1979-08-25 | 2018-03-01 | 38 || PetC | dog | 1989-06-17 | 2018-03-01 | 28 || PetE | bird | 1991-02-17 | 2018-03-01 | 27 || PetA | cat | 1993-02-04 | 2018-03-01 | 25 || PetB | cat | 1994-03-17 | 2018-03-01 | 23 |+------+---------+------------+------------+------+5 rows in set (0.00 sec)#死去的pet的agemysql&gt; SELECT name, species, birth, death, -&gt; TIMESTAMPDIFF(YEAR, birth, death) AS age -&gt; FROM pet -&gt; WHERE death IS NOT NULL -&gt; ORDER BY age;+------+---------+------------+------------+------+| name | species | birth | death | age |+------+---------+------------+------------+------+| PetD | dog | 1979-08-25 | 1995-02-21 | 15 |+------+---------+------------+------------+------+1 row in set (0.00 sec) YEAR() 年 MONTH() 月 DAYOFMONTH() 日 1234567891011121314151617181920212223242526mysql&gt; SELECT name, birth, -&gt; YEAR(birth) AS bir_year, -&gt; MONTH(birth) AS bir_month, -&gt; DAYOFMONTH(birth) AS bir_day -&gt; FROM pet;+------+------------+----------+-----------+---------+| name | birth | bir_year | bir_month | bir_day |+------+------------+----------+-----------+---------+| PetA | 1993-02-04 | 1993 | 2 | 4 || PetB | 1994-03-17 | 1994 | 3 | 17 || PetC | 1989-06-17 | 1989 | 6 | 17 || PetD | 1979-08-25 | 1979 | 8 | 25 || PetE | 1991-02-17 | 1991 | 2 | 17 |+------+------------+----------+-----------+---------+5 rows in set (0.00 sec)#查找生日是2月的petmysql&gt; SELECT name, birth FROM pet WHERE MONTH(birth) =2;+------+------------+| name | birth |+------+------------+| PetA | 1993-02-04 || PetE | 1991-02-17 |+------+------------+ DATE_ADD() 将日期间隔添加到给定日期 12mysql&gt; SELECT name, birth FROM pet -&gt; WHERE MONTH(birth) = MONTH(DATE_ADD(CURDATE(), INTERVAL 1 MONTH)); 使用NULL值Working with NULL Values 从概念上讲，NULL value意味着一个缺失的未知值，它与其它值在某种程度上是不同的。 使用IS NULL和IS NOT NULL操作符 不能对NULL value使用算术运算符(arithmetic cpmparison operators) 如：=, &lt;, &gt;, &lt;&gt; 任何对NULL value的算术运算符的结果也是NULL value，所以无法得到有意义的结果 在MySQL中，0或NULL表示false，其他任何值都意味着true 两个NULL在GROUP BY中被认为是相等的 NULL在ORDER BY正向排序中首先显示。反之，最后显示 123456mysql&gt; SELECT 1 IS NULL, 1 IS NOT NULL;+-----------+---------------+| 1 IS NULL | 1 IS NOT NULL |+-----------+---------------+| 0 | 1 |+-----------+---------------+ 因此，完全可以将一个zero或empty string插入到一个NOT NULL的column中，因为这些值NOT NULL。 模式匹配Pattern Matching MySQL提供标准的SQL模式匹配以及基于扩展正则表达式的模式匹配形式。类似于Unix实用程序(vi, grep, sed…) SQL模式匹配允许: 使用_来匹配可以使用的任意单字符(single character) 使用%来匹配可以使用的任意数目的字符(arbitrary number of characters) SQL模式不区分大小写 使用LIKE或NOT LIKE而不是=或&lt;&gt; 12345678910111213141516mysql&gt; SELECT * FROM pet WHERE name LIKE '%b';+------+-------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+------+-------+---------+------+------------+-------+| PetB | Bb | cat | m | 1994-03-17 | NULL |+------+-------+---------+------+------------+-------+mysql&gt; SELECT * FROM pet WHERE name LIkE '___A' or name LIKE '___C';+------+-------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+------+-------+---------+------+------------+-------+| PetA | Aa | cat | f | 1993-02-04 | NULL || PetC | Cc | dog | f | 1989-06-17 | NULL |+------+-------+---------+------+------------+-------+ MySQL提供的其它类型的模式匹配使用扩展的正则表达式： REGEXP 或 RLIKE NOT REGEXP 或 NOT RLIKE 了解正则表达式知识 123456789101112131415161718192021222324252627282930313233343536373839mysql&gt; SELECT * FROM pet WHERE name RLIKE '^pet[AB]';+------+-------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+------+-------+---------+------+------------+-------+| PetA | Aa | cat | f | 1993-02-04 | NULL || PetB | Bb | cat | m | 1994-03-17 | NULL |+------+-------+---------+------+------------+-------+mysql&gt; SELECT * FROM pet WHERE owner RLIKE 'c$';+------+-------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+------+-------+---------+------+------------+-------+| PetC | Cc | dog | f | 1989-06-17 | NULL || PetE | Cc | bird | NULL | 1991-02-17 | NULL |+------+-------+---------+------+------------+-------+#包含某个字符mysql&gt; SELECT * FROM pet WHERE name RLIKE 'ete';+------+-------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+------+-------+---------+------+------------+-------+| PetE | Cc | bird | NULL | 1991-02-17 | NULL |+------+-------+---------+------+------------+-------+#匹配字符个数mysql&gt; SELECT * FROM pet WHERE name RLIKE '^....$';mysql&gt; SELECT * FROM pet WHERE name RLIKE '^.&#123;4&#125;$';#强制区分大小写mysql&gt; SELECT * FROM pet WHERE name RLIKE BINARY '^Pet[AB]'; 行数计算Counting Rows 使用COUNT()计算行数 12345678910111213141516171819202122232425262728293031323334#总行数mysql&gt; SELECT COUNT(*) AS count FROM pet;+-------+| count |+-------+| 5 |+-------+#针对某个统计行数mysql&gt; SELECT owner, COUNT(*) FROM pet GROUP BY owner;+-------+----------+| owner | COUNT(*) |+-------+----------+| Aa | 2 || Bb | 1 || Cc | 2 |+-------+----------+#多个条件mysql&gt; SELECT species, sex, COUNT(*) FROM pet GROUP BY species, sex;+---------+------+----------+| species | sex | COUNT(*) |+---------+------+----------+| bird | NULL | 1 || cat | f | 1 || cat | m | 1 || dog | f | 1 || dog | m | 1 |+---------+------+----------+ 使用多个表Using More Than one Table 创建一个额外的宠物信息表： name date type remark Fluffy 1995-05-15 litter 4 kittens, 3 female, 1 male Buffy 1993-06-23 litter 5 puppies, 2 female, 3 male Buffy 1994-06-19 litter 3 puppies, 3 female Chirpy 1999-03-21 vet needed beak straightened Slim 1997-08-03 vet broken rib Bowser 1991-10-12 kennel Fang 1991-10-12 kennel Fang 1998-08-28 birthday Gave him a new chew toy Claws 1998-03-17 birthday Gave him a new flea collar Whistler 1998-12-09 birthday First birthday 12345mysql&gt; CREATE TABLE event ( name VARCHAR(20), date DATE, -&gt; type VARCHAR(15), remark VARCHAR(255) );mysql&gt; LOAD DATA INFILE '/path/event.txt' INTO TABLE event; 获取数据库和表的信息Getting Information About Databases and Tables 查看当前数据库 mysql&gt; SELECT DATABASE(); 查看当前数据库下的表 mysql&gt; SHOW TABLES; 查看表的结构 mysql&gt; DESCRIBE pet; 创建数据库 mysql&gt; CREATE DATABASE db_01; 创建表 mysql&gt; CREATE TABLE table_01 {c1 VARCHAR(10), c2 INT, ...}; 查看索引(如果存在) SHOW INDEX FROM table_01; 在批处理下使用mysqlUsing mysql in Batch Mode 在前面，我们都是使用MySQL交互式(interactively)输入命令并查看结果。但还可在批处理模式下运行MySQL。我们可以创建一个脚本文件，然后以这种方式执行脚本文件。 1234567mysql &lt; batch-filemsyql -h host -u user -p &lt; /path/batch-file#出现错误也继续运行msyql -h host -u user -p --force &lt; /path/batch-file 为什么要使用脚本： 如果需要反复(repeat)执行查询，将其写入脚本以避免每次执行时重新输入查询 通过复制和修改脚本文件从现有查询中生成新的查询 批处理模型在开发查询时也很有用，特别是对于多行语句。写错了直接修改脚本就好，而不必重新输入 如果查询产生大量输出，可通过传呼机而不是翻滚到屏幕的最上方 mysql &lt; batch-file | more 可以把输出捕获到一个文件中 mysql &lt; batch-file &gt; mysql.out 可将脚本文件分发给其他人 批处理模式下的MySQL输出更简洁 可使用mysql -t获得交互式数据格式 使用mysql -v将执行语句回显 在mysql命令行中载入脚本 mysql&gt; source filename; 或’mysql&gt; . filename; 常见查询Examples of Common Queries 在命令行使用mysql并选择数据库 1mysql db_name -u user -p 创建和填充表 12345678CREATE TABLE shop ( article INT(4) UNSIGNED ZEROFILL DEFAULT '0000' NOT NULL, dealer CHAR(20) DEFAULT '' NOT NULL, price DOUBLE(16,2) DEFAULT '0.00' NOT NULL, PRIMARY KEY(article, dealer));INSERT INTO shop VALUES (1,'A',3.45),(1,'B',3.99),(2,'A',10.99),(3,'B',1.45), (3,'C',1.69),(3,'D',1.25),(4,'D',19.95); 查看表内容 1SELECT * FROM shop; 列的最大值(maximum) 1234567SELECT MAX(article) AS article FROM shop;SELECT article, MAX(price) AS priceFROM shopGROUP BY article; 使用用户定义的变量(user-defined variables) 123mysql&gt; SELECT @min_price:=MIN(price),@max_price:=MAX(price) FROM shop;mysql&gt; SELECT * FROM shop WHERE price=@min_price OR price=@max_price; 使用外键(Foreign Keys) 在MySQL中，InnoDB表支持检查外键约束。外键约束不仅仅需要连接两个表。 123456789101112131415161718192021222324252627282930313233343536373839CREATE TABLE person ( id SMALLINT UNSIGNED NOT NULL AUTO_INCREMENT, name CHAR(60) NOT NULL, PRIMARY KEY (id));CREATE TABLE shirt ( id SMALLINT UNSIGNED NOT NULL AUTO_INCREMENT, style ENUM('t-shirt', 'polo', 'dress') NOT NULL, color ENUM('red', 'blue', 'orange', 'white', 'black') NOT NULL, owner SMALLINT UNSIGNED NOT NULL REFERENCES person(id), PRIMARY KEY (id));INSERT INTO person VALUES (NULL, 'Antonio Paz');SELECT @last := LAST_INSERT_ID();INSERT INTO shirt VALUES(NULL, 'polo', 'blue', @last),(NULL, 'dress', 'white', @last),(NULL, 't-shirt', 'blue', @last);INSERT INTO person VALUES (NULL, 'Lilliana Angelovska');SELECT @last := LAST_INSERT_ID();INSERT INTO shirt VALUES(NULL, 'dress', 'orange', @last),(NULL, 'polo', 'red', @last),(NULL, 'dress', 'blue', @last),(NULL, 't-shirt', 'white', @last); 在两个键上查找(Searching on Two Keys) 12SELECT field1_index, field2_index FROM test_tableWHERE field1_index = '1' OR field2_index = '1' 使用自动增量 AUTO_INCREMENT属性能够为新行生成一个唯一的标识符。 123456789101112131415CREATE TABLE animals ( id MEDIUMINT NOT NULL AUTO_INCREMENT, name CHAR(30) NOT NULL, PRIMARY KEY (id));INSERT INTO animals (name) VALUES ('dog'),('cat'),('penguin'), ('lax'),('whale'),('ostrich');#设置指定增量开始值mysql&gt; ALTER TABLE tbl AUTO_INCREMENT = 100; MySQL程序 MySQL程序概述Overview of MySQL Programs MySQL安装中有多个不同的程序： mysqldSQL daemon, MySQL Server, mysqld是执行大部分工作的主要程序 mysqld_safe服务器启动脚本mysqld_safe尝试去启动mysqld mysql.server服务器启动脚本此脚本用于System V系统，包含启动特定运行级别的系统服务脚本它调用mysqld_safe来启动MySQL Server mysql_multi可启动和关闭安装在系统上的多个服务器的启动脚本 comp_err在MySQL build/installation过程中使用从错误源文件中编译错误消息文件 mysql_install_db初始化MySQL(数据目录，授权表，并设置InnoDB系统表空间)通常用于首次安装MySQL时 mysql_plugin配置MySQL Server插件 mysql_secure_installation能够提高MySQL安装的安全性 mysql_ssl_rsa_setup如果这些文件丢失，该程序会创建支持安全连接所需的SSL证书和密钥文件以及RSA密钥对文件 mysql_tzinfo_to_sql从mysql数据库中加载时区表 mysql_upgrade在MySQL升级操作后使用它检查表的不兼容性并在必要时修复它们，并用更新版的MySQL的任何更改来更新授权表 mysql交互式输入SQL语句的命令行工具或执行一个批处理模式的文件 mysqladmin执行管理操作的客户端如创建或删除数据库，重新加载授权表，刷新表的磁盘…也可用获取服务器版本、状态、进程信息 mysqlcheck表格客户端用于检查、修复、分析和优化表格 mysqldump将MySQL数据库转储为SQL、文本或XML文件的客户端 mysqlimport使用LOAD DATA INFILE将文本文件导入各自表格的客户端 mysqlpump将MySQL数据库转转储为SQL文件的客户端 mysqlsh用于MySQL Server的高级命令行客户端和代码编辑器除了SQL外，MySQL Shell还为JS和Python提供了脚本功能 mysqlshow显示有关数据库、表、列和索引的信息的客户端 mysqlslap用于模拟MySQL Server的客户端负载并报告每个阶段的时间 MySQL管理和实用程序： innochecksumInnoDB脱机文件校验和程序 myisam_ftdump在MyISAM表中显示有关全文索信息 myisamchk描述，检查，优化和修复MyISAM表 myisamlog处理MyISAM日志文件 myisampack压缩MyISAM表以生成更小的只读表 mysql_config_editor能够将认证凭证存储在名为安全的加密登录路径文件中 mysqlbinlog从二进制日志中读取语句 mysqldumpslow读取和总结慢查询日志内容 MySQL程序开发实用程序： mysql_config一个shell脚本，用于在编译MySQL程序是生产所需的选项值 my_print_defaults：显示选项文件的选项组中存在哪些选项 resolve_stack_dump将数值堆栈跟踪转储解析为符号 杂项(Miscellaneous)工具： lz4_decompress解压缩使用LZ4压缩格式的mysqldump输出 perror显示系统或MySQL错误代码含义 replace再输入文本中执行字符串替换 resolveip将主机名解析为IP地址，反之亦然 zlib_decompress解压缩使用ZLIB压缩格式的mysqldump输出 Oracle公司还提供了MySQL Workbench GUI工具，用于管理、创建、知悉和评估查询，以及从其它关系数据库管理系统迁移到MySQL系统。 MySQL Client和Server间的通信使用如下环境变量： Environment Variable Meaning MYSQL_UNIX_PORT The default Unix socket file; used for connections to localhost MYSQL_TCP_PORT The default port number; used for TCP/IP connections MYSQL_PWD The default password, insecure MYSQL_DEBUG Debug trace options when debugging TMPDIR The directory where temporary tables and files are created 使用MySQL程序调用MySQL程序从命令行调用一个MySQL程序，输入程序名称和选项及参数。 1234$ mysql --user=root test$ mysqladmin extended-status variables$ mysqlshow --help$ mysqldump -u root personnel 连接到MySQL Server介绍如何连接到MySQL Server。 MySQL程序环境变量的优先级最低，命令行选项最高。你可在配置文件中指定程序的默认值，同时你又可以使用命令行选项覆盖它。MySQL选项按顺序处理，所以如果多次指定选型，则最后一个选项优先。 123mysql --hostname xx --port xx --user xx --password $&#123;dbname&#125; --protocol=TCPmysql -h -P -u -p $&#123;dbname&#125; --protocol值： TCP(all) SOCKET(Unix) PIPE(windows) MEMORY(windows) 你可以在选项文件的[client]部分指定连接参数: 12345[client]host=xxxport=xxxuser=xxxpassword=xxx 1234567mysqladmin -u user -p --count=1k --sleep=10 pingmysql -u user -pxxx --execute=&quot;DESCRIBE db.table&quot;#执行多个语句mysql -u root -p -e &apos;SELECT VERSION(); SELECT NOW()&apos; 配置文件大多数MySQL程序都可从选项文件中读取启动选项。 MySQL不保证配置文件的读取顺序。 Unix和Unix-Like平台的MySQL配置文件： 文件 描述 /etc/my.cnf 全局选项 /etc/mysql/my.cnf 全局选项 $SYSCONFDIR/my.cnf 全局选项 $MYSQL_HOME/my.cnf MySQL Server Only ~/.my.cnf 特定用户选项 ~/.mylogin.cnf 特定用户登录选项，Client Only default-extra-file 使用--defaults-extra-file指定的文件 配置文件解释： 空行被忽略 #号表示注释 前后空格将自动从选项名称和值中删除 [group]为其设置配置项的程序名或组名。在此之后，任何选项设置都会应用到指定组，知道给出结尾。选项组名称不区分大小写。 你可在选项值中使用转义序列\b, \t, \n, \r, \\, \s !include来包含其它配置文件 123456789101112131415161718192021DATADIRmysqld --datadir[mysqld]port=3306socket=/tmp/mysql.sockkey_buffer_size=16Mmax_allowed_packet=8M[mysql]port=3306socket=/tmp/mysql.sockno-auto-rehash[mysqldump]quick!include /home/mysql/myopt.cnf 影响配置文件的命令行选项 --print-defaults --defaults-extra-file --defaults-file --defaults-group-suffix --login-path --no-defaults 使用选项指定环境变量 1234567891011[mysql]max_allowed_packet=16M[mysqld]key_buffer_size=512Mmysql --max_allowed_packet=16Mshell&gt; mysql --max_allowed_packet=16*1024*1024mysql&gt; SET GLOBAL max_allowed_packet=16*1024*1024; MySQL Server mysqldThe MySQL Server mysql_safeMySQL Server Startup Script mysql.serverMySQL Server Startup Script mysqld_multiManage Multiple MySQL Servers mysqldmysqld，也被称为MySQL服务器，是执行MySQL大部分工作的主要程序。MySQL服务器管理对包含数据库和表的MySQL数据目录的访问。 查看帮助： mysqld --verbose --help mysql_safe对于某些Linux平台，从RPM或DBP包安装的MySQL包括了用于管理MySQL服务启动和管理的systemd支持。在这些平台上，mysqld_safe不会被安装，因为它不是必须的。 mysql_safe是Unix上启动mysqld服务器的推荐方式。它添加了一些安全特性，如发生错误是重启服务器并将运行时的错误记录到日志。 mysqld_safe尝试启动一个名为mysqld的可执行程序。它会读取配置文件中[mysqld], [server], [mysqld_safe]部分的所有选项。 mysqld_safe选项： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647--basedir--core-file-size--datadir--defaults-extra-file--defaults-file--ledir--log-error--mallocl-lib--mysqld--mysqld-safe-login-timestamps--mysql-version--nice--no-defaults--open-files-limit--pid-file--plugin-dir--plugin-dir--port--skip-kill-mysqld--skip-syslog--socket--syslog-tag--timezone--user mysql.server对于某些Linux平台，从RPM和DPG包安装的MySQL包括了用于管理MySQL Server启动和关闭的systemd支持。在这些平台上，没有安装mysql.server和mysqld_safe，因为它们不是必须的。 Unix和Unix-Like平台上的MySQL发行版包含一个名为mysql.server的脚本，该脚本使用mysqld_safe启动MySQL Server。 mysqld_multi对于某些Linux平台，从RPM和DPG包安装的MySQL包括了用于管理MySQL Server启动和关闭的systemd支持。在这些平台上，没有安装mysqld_multi，因为它们不是必须的。 mysqld_multi设计用于管理多个监听不同Unix socket文件和TCP/IP port上连接的mysqld进程。 MySQL安装相关程序这些程序用于安装或升级MySQL！ com_errCompile MySQL Error Message File mysql_install_dbInitialize MySQL Data Directory mysql_pluginConfigure MySQL Server Plugins mysql_secure_installationImprove MySQL Installation Security mysql_ssl_rsa_setupCreate SSL/RSA Files mysql_tzinfo_to_sqlLoad the Time Zone Tables mysql_upgradeCheck and Upgrade MySQL Tables com_errcomp_err创建errmsg.sys文件，mysqld使用此文件来确定为不同错误代码(error code)显示错误消息。通常，在构建MySQL时，comp_err会自动运行。它从位于MySQL源发行版sq;/share/errmsg-utf8.txt文本文件汇编errmsg.sys文件。 comp_err同样会生成mysqld_error.h, mysqld_ername.h, sql_state.h头文件。 mysql_install_db在MySQL5.7中，由于mysql_install_db的功能已经被集成到mysqld中，因此不推荐使用它。在MySQL5.7.5之前，mysql_install_db是一个Perl脚本并依赖于Perl。在此之后，它是由C++写的可执行二进制文件。还有一些选项的更迭。 1234mysqld --initailize#ormysqld --initialize-insecure mysql_install_db处理在MySQL Server(mysqld)准备好使用之前，必须执行的初始化任务： 初始化MySQL数据目录，创建它包含的系统表 初始化管理InnoDB表所需的system tablespace和相关数据结构 加载服务器端help表 安装sys schema 创建一个管理员账户老版本的mysql_install_db可能会创建匿名账户。 如果mysql_install_db生成了一个随机管理员密码，它将把此密码写入文件并显示此文件名。密码包含一个时间戳以指示它的写入时间。默认情况下，该文件是用户主目录中的.mysql_secret文件。 mysql_plugin从MySQL5.7.11开始，不推荐使用mysql_plugin，并会在MySQL8.0中移除此功能。使用如下命令替代： 123456--plugin-load--plugin-load-add#或mysql&gt; INSTALL PLUGINmysql&gt; UNINSTALL PLUGIN mysql_plugin功能允许MySQL管理员管理由MySQL Server载入的插件。 mysql_secure_installationmysql_secure_installation通过以下方式来提高MySQL安装的安全性： 为root用户设置密码 删除可从本机外部访问的root账户 删除匿名账户 删除test数据库(默认情况下可由任何用户访问，包括匿名用户) 删除允许任何人访问以test_开头的数据库的权限 mysql_ssl_rsa_setupmysql_ssl_rsa_setup创建SSL证书和key文件和RSA key-pair文件，用于支持使用SSL进行安全连接。它生成的整数是自签名的，不太安全。请考虑从注册机构申请CA证书。mysql_ssl_rsa_setup使用opensll命令，所以请安装OpenSSL。 mysql_tzinfo_to_sqlmysql_tzinfo_to_sql加载MySQL数据库中的zone table。它使用系统上的zoneinfo信息。 msyql_upgrademysql_upgrade检查数据库中的所有表与当前版本的MySQL Server的不兼容，它还升级系统表，以便你可以利用新权限和功能。如果mysql_upgrade发现表有可能的不兼容性，它会执行检查表，如果发现问题，则会尝试修复表。 每次升级MySQL时都应该执行mysql_upgrade。在执行upgrade之前，你应该始终备份你的MySQL。 MySQL客户端程序 mysqlThe MySQL Command-Line Tool mysqladminClient for Administering a MySQL Server mysqlcheckA Table Maintenance Program mysqldumpA Database Backup Program mysqlimportA Data Import Program mysqlpumpA Database Backup Program mysqlshThe MySQL Shell mysqlshowDisplay Database, Table, and Column Information mysqlslapLoad Emulation Client mysqlmysql是一个具有输入编辑功能的SQL shell。 123456mysql --host= --port= --user= --password db_name#SQL文件#SQL语句以 ;或\g或\G结束mysql db_name &lt; script.sql &gt; output.tab mysql选项MySQL支持很多选项。这些选项可以写入配置文件的[mysql]和[client]组中。 1mysql --help mysql命令mysql将你发出的每个SQL语句发送到要执行的Server。如下为mysql自己解释的命令： 123456789101112131415161718192021222324252627282930mysql&gt; help;List of all MySQL commands:Note that all text commands must be first on line and end with &apos;;&apos;? (\?) Synonym for `help&apos;.charsetclear (\c) Clear the current input statement.connect (\r) Reconnect to the server. Optional arguments are db and host.delimiter (\d) Set statement delimiter.edit (\e) Edit command with $EDITOR.ego (\G) Send command to mysql server, display result vertically.exit (\q) Exit mysql. Same as quit.go (\g) Send command to mysql server.help (\h) Display this help.nopager (\n) Disable pager, print to stdout.notee (\t) Don&apos;t write into outfile.pager (\P) Set PAGER [to_pager]. Print the query results via PAGER.print (\p) Print current command.prompt (\R) Change your mysql prompt.quit (\q) Quit mysql.rehash (\#) Rebuild completion hash.source (\.) Execute an SQL script file. Takes a file name as an argument.status (\s) Get status information from the server.system (\!) Execute a system shell command.tee (\T) Set outfile [to_outfile]. Append everything into given outfile.use (\u) Use another database. Takes database name as argument.charset (\C) Switch to another charset. Might be needed for processing binlog with multi-byte charsets.warnings (\W) Show warnings after every statement.nowarning (\w) Don&apos;t show warnings after every statement.resetconnection(\x) Clean session context. 修改MySQL提示符 123456789101112131415#shellexport MYSQL_PS1=&quot;(\u@\h) [\d]&gt; &quot;#mysqlmysql --prompt=&quot;(\u@\h) [\d]&gt; &quot;#配置文件[mysql]prompt=(\\u@\\h) [\\d]&gt;\\_#mysql promptmysql&gt; prompt (\u@\h) [\d]&gt;\_ mysql服务端帮助mysql Server-Side Help 如果给help命令提供一个参数，mysql将其用作搜索字符串，以从MySQL参考手册的内容访问服务端帮助。 12345678910mysql&gt; help memysql&gt; help contentsmysql&gt; help logsmysql&gt; help rep% 从文本文件执行SQL语句mysql忽略文件开头的Unicode字节顺序标记(BOM)字符。BOM的存在不会导致MySQL更改其默认字符集(charset)。因此，请使用--default-char-set选项。 12345678910#shellmysql db_name &lt; test_filemysql&gt; source file_namemysql&gt; \. file_name#显示进度信息SELECT &apos;&lt;info_to_display&gt;&apos; AS &apos; &apos;; MySQL管理和实用程序 inochecksumOffline InnoDB File Checksum Utility myisam_ftdumpDisplay Full-Text Index information myisamchkMyISAM Table-Maintenance Utility myisamlogDisplay MyISAM Log File Contents myisampackGenerate Compressed, Read-Only MyISAM Tables mysql_config_editorMySQL Configuration Utility mysqlbinlogUtility for Processing Binary Log Files mysqldumpslowSummarize Slow Query Log Files mysql开发实用程序 mysql_configDisplay Options for Compiling Clients my_print_defaultsDisplay Options from Option Files resolve_stack_dumpResolve Numeric Stack Trace Dump to Symbols 杂项程序Miscellaneous Programs lz4_decompressDecompress mysqlpump LZ4-Compressed Output perrorExplain Error Codes replaceA String-Replacement Utility resolveipResolve Host name to IP Address or Vice Versa zlib_decompressDecompress mysqlpump ZLIB-Compressed Output MySQL环境变量这些环境变量直接或间接的被MySQL使用。 Variable Description AUTHENTICATION_LDAP_CLIENT_LOG Client-side LDAP authentication logging level. AUTHENTICATION_PAM_LOG PAM authentication plugin debug logging settings. CC The name of your C compiler (for running CMake). CXX The name of your C++ compiler (for running CMake). CC The name of your C compiler (for running CMake). DBI_USER The default user name for Perl DBI. DBI_TRACE Trace options for Perl DBI. HOME The default path for the mysql history file is $HOME/.mysql_history. LD_RUN_PATH Used to specify the location of libmysqlclient.so. LIBMYSQL_ENABLE_CLEARTEXT_PLUGIN Enable mysql_clear_password authentication plugin; see Section 6.5.1.6, “Client-Side Cleartext Pluggable Authentication”. LIBMYSQL_PLUGIN_DIR Directory in which to look for client plugins. LIBMYSQL_PLUGINS Client plugins to preload. MYSQL_DEBUG Debug trace options when debugging. MYSQL_GROUP_SUFFIX Option group suffix value (like specifying —defaults-group-suffix). MYSQL_HISTFILE The path to the mysql history file. If this variable is set, its value overrides the default for $HOME/.mysql_history. MYSQL_HISTIGNORE Patterns specifying statements that mysql should not log to $HOME/.mysql_history, or syslog if —syslog is given. MYSQL_HOME The path to the directory in which the server-specific my.cnf file resides. MYSQL_HOST The default host name used by the mysql command-line client. MYSQL_OPENSSL_UDF_DH_BITS_THRESHOLD Maximum key length for CREATE_DH_PARAMETERS(). See Section 12.18.2, “Enterprise Encryption Usage and Examples”. MYSQL_OPENSSL_UDF_DSA_BITS_THRESHOLD Maximum DSA key length for CREATE_ASYMMETRIC_PRIV_KEY(). See Section 12.18.2, “Enterprise Encryption Usage and Examples”. MYSQL_OPENSSL_UDF_RSA_BITS_THRESHOLD Maximum RSA key length for CREATE_ASYMMETRIC_PRIV_KEY(). See Section 12.18.2, “Enterprise Encryption Usage and Examples”. MYSQL_PS1 The command prompt to use in the mysql command-line client. MYSQL_PWD The default password when connecting to mysqld. Using this is insecure. See Section 6.1.2.1, “End-User Guidelines for Password Security”. MYSQL_TCP_PORT The default TCP/IP port number. MYSQL_TEST_LOGIN_FILE The name of the .mylogin.cnf login path file. MYSQL_TEST_TRACE_CRASH Whether the test protocol trace plugin crashes clients. See note following table. MYSQL_TEST_TRACE_DEBUG Whether the test protocol trace plugin produces output. See note following table. MYSQL_UNIX_PORT The default Unix socket file name; used for connections to localhost. MYSQLX_TCP_PORT The X Plugin default TCP/IP port number. MYSQLX_UNIX_PORT The X Plugin default Unix socket file name; used for connections to localhost. PATH Used by the shell to find MySQL programs. PKG_CONFIG_PATH Location of mysqlclient.pc pkg-config file. See note following table. TMPDIR The directory in which temporary files are created. TZ This should be set to your local time zone. See Section B.5.3.7, “Time Zone Problems”. UMASK The user-file creation mode when creating files. See note following table. UMASK_DIR The user-directory creation mode when creating directories. See note following table. USER The default user name on Windows when connecting to mysqld. MySQL Server管理MySQL Servermysqld is the MySQL Server.并非所有的MySQL Server二进制文件和配置都支持所有的存储引擎。 12345678910#查看帮助mysqld --verbose --help#运行Server的环境变量mysql&gt; SHOW VARIABLES;#运行Server的状态mysql&gt; SHOW STATUS; MySQL数据目录由MySQL管理的信息存储在称为数据目录的目录下。 数据目录子目录：每个子目录都是数据库目录对应于Server管理的数据库 mysql performance_schema sys 数据库 日志文件由Server写入 innoDB表空间和日志文件 自动生成的SSL/RSA证书和密钥文件 Server PID mysql数据库The mysql System Database The mysql database is the system database.它的表中存储了MySQL Server运行时需要的信息。 授权系统表如下这些系统表包含了用户账户和权限的授权信息。 userUser accounts, global privileges, and other non-privilege columns. dbDatabase-level privileges. tables_privTable-level privileges. columns_privColumn-level privileges. procs_privStored procedure and function privileges. proxies_privProxy-user privileges. 对象信息系统表如下这些系统表包含了存储程序，用户定义函数和服务器端插件的信息。 event关于Event Scheduler事件的信息 func用户定义函数的信息 plugin服务器端的插件的信息 proc有关存储过程和函数的信息 日志系统表Server使用如下系统表记录日志。日志表使用CSV存储引擎。 general_log一般查询日志表 slow_log慢查询日志表 服务器端帮助系统表如下系统表包含了服务器端帮助信息。 help_categoryInformation about help categories. help_keywordKeywords associated with help topics. help_relationMappings between help keywords and topics. help_topicHelp topic contents. 时区系统表如下系统表包含了时区信息。 time_zoneTime zone IDs and whether they use leap seconds. time_zone_leap_secondWhen leap seconds occur. time_zone_nameMappings between time zone IDs and names. time_zone_transition, time_zone_tansition_typeTime zone descriptions. 副本系统表Server使用如下这些系统表来提供副本服务。这些表使用InnoDB存储引擎。 gtid_executedTable for storing GTID values. ndb_binlog_indexBinary log information for NDB Cluster replication. slave_master_info, slave_relay_log_info, slave_worker_infoUsed to store replication information on slave servers. 优化器系统表如下系统表用于优化。 innodb_index_stats, innodb_table_statsUsed for InnoDB persistent optimizer statistics server_cost, engine_costThe optimizer cost model uses tables that contain cost estimate information about operations that occur during query execution. 杂项系统表 audit_log_filter, audit_log_user firewall_users, firewall_whitelist servers MySQL Server LogsMySQL Server提供如下几种日志： Error log启动、运行或停止mysqld遇到的问题 General query log建立Client连接和从Client收到的语句 Binary log更改数据的语句 Relay log从replication master server收到的数据更改 Slow query log执行时间超过long_query_time秒的查询 DDL(Metadata) log由DDL语句执行的元数据操作 默认情况下，不启用任何日志。 如果启用了这些日志，MySQL Server可以灵活地控制一般查询日志和慢查询日志的输出目的地——它可为日志文件或mysql数据库中的general_log和slow_log表。 123456789101112131415#--log-output#它的值可为TABLE/FILE/NONE#--general-log, --slow-query-log#TABLE和FILEmysqld --log-output=TABLE,FILE --general-log=msyql.general_log --slow-query-log=mysql.slow_log#or[mysqld]log_output=general_log=slow_query_log= 查看两个日志表的标准格式： 12SHOW CREATE TABLE mysql.general_log;SHOW CREATE TABLE mysql.slow_log; 错误日志The Error Log 错误日志包含mysqld启动和关闭时间的记录。它还包含诊断信息。 Unix/Unix-Like OS使用mysqld --log-error选项来将错误日志写入控制台(stderr)或文件。 如果未指定文件名，则默认为数据目录下的host_name.err文件。YUM或APT包安装，则配置的错误日志文件为--log-error=/var/log/mysqld.log。 将错误日志记录到系统日志Error Logging to the System Log 使用如下系统变量： log_syslog启用此变量将错误日志发送到系统日志 log_syslog_facilitysyslog消息的默认设置时daemon。设置此变量以指定其它工具。 log_syslog_include_pid是否在syslog输出中包含Server的PID。 log_syslog_tag在syslog消息中添加一个tag。 1msyqld --log_syslog= 错误日志过滤Error Log Filtering log_error_verbosity变量控制错误日志的详细程度。值如下： 1error only 2errors, warning 3(默认)errors, warnings, notes 错误日志消息格式Error Log Message Format 错误日志中包含的ID是mysqld中负责编写消息的线程的ID。这表示Server的哪部分生成了消息。log_timestamps变量控制写入错误日志的时区和时间格式。 1mysqld --log-timestamps= 错误日志文件刷新Error Log File Flushing and Renaming 如果你使用FLUSH_ERROR_LOGS, FLUSH_LOGS或mysqladmin flush-logs刷新日志，Server将关闭并重新打开它正在写的任何错误日志文件。 12mv host_name.err host_name.err-oldmysqladmin flush-logs 一般查询日志The General Query Log 一般查询日志是mysqld执行操作的记录。当Client连接或断开时，Server将此信息写入日志，并记录从Client收到的每个SQL语句。mysqld按照接收的顺序而不是执行顺序将语句写入日志。 默认情况下，一般查询日志是禁用的。指定初始化查询日志状态--general_log={0|1}。1启用，0禁用。指定日志文件名--general-log-file=file-name.如果未指定，默认为数据目录下host_name.log，除非指定了其它路径。指定日志文件位置--log-output=. 12345mysqld --log-output=&apos;/var/log/mysql&apos; --general-log=1 --general-log-file=&apos;general.log&apos;shell&gt; mv host_name.log host_name-old.logshell&gt; mysqladmin flush-logs 二进制日志The Binary Log 安全Security 当考虑MySQL安装中的安全性时，你应该考虑各种可能的主题以及他们如何影响MySQL Server和相关应用程序的安全性: 影响安全性的一般因素。包括选择好的密码，不向用户授予不必要的权限，防止SQL注入和数据损坏来确保应用程序的安全性… 安装本身的安全性。应保护数据文件，日志文件和安装的所有应用程序文件，以确保未经授权方无法读写这些文件… 数据库系统本身的访问控制和安全性。包括允许访问数据库中使用的数据库，视图和存储应用程序的用户和数据库… 安全相关插件提供的功能… MySQL和你的系统的网络安全性。安全性还与用户的授权有关，但你可能希望限制MySQL，使其仅在本地主机上可用，或者在一组有限的其它主机上可用… 确保你备份了足够和适当的数据库文件，配置和日志文件。还要确保你已准备好恢复解决方案，并测试是否能够从备份种恢复信息… 一般安全问题General Security Issues 本节介绍了要注意的一般安全问题，以及如何使MySQL安装更安全，防止攻击或滥用。 安全指南Security Guidelines 在连接了Internet的计算机上使用MySQL的任何人都应阅读本节，以避免最常见的安全错误。在讨论安全性时，有必要考虑完全保护整个服务器主机免受所有类型的攻击：窃听，更改，拒绝服务… MySQL使用基于访问控制列表(ACL)的安全性，来处理用户可以尝试执行的所有连接、查询和其它操作。MySQL Client和Server之间SSL加密连接。 当运行MySQL时，遵循以下准则： 不要让任何人(root除外)访问mysql.user数据表，这很关键。 了解MySQL访问权限系统的工作原理。使用GRANT和REVOKE语句来控制对MySQL的访问。不要授予超出必要的权限，永远不要授予所有主机权限。如果你能够在不被要求输入密码的情况下成功连接到MySQL Server，则任何人都可以以具有完全权限的root用户身份连接到MySQL Server。请重新查看MySQL安装说明，特别注意有关设置root密码的信息。检查哪些账户拥有访问权限，并移除不必要的权限。 1234567891011#测试mysql -u root#访问权限SHOW GRANTS;#移除权限#help REVOKEREVOKE 不要在数据库中存储明文密码。如果计算机被攻击，入侵者可以获得完整的密码列表并使用他们。相反，使用一些HASH函数并存储散列值。 不要从字典中选择密码，即不要使用简单和常规密码。存在某些破解密码的程序能计算你的密码。 启用防火墙。这可以保护你免受大部分漏洞攻击。将MySQL放在防火墙后面或DMZ。使用端口扫描软件(如nmap)扫描主机端口。MySQL默认使用3306端口。不应从不受信任的主机访问此端口。测试你的端口安全性： 123456789101112131415[zhang@zhang21 ~]$ telnet zhang21 3306Trying 192.168.31.119...Connected to zhang21.Escape character is &apos;^]&apos;.@Host &apos;zhang21&apos; is not allowed to connect to this MySQL serverConnection closed by foreign host.[zhang@zhang21 ~]$ telnet localhost 3306Trying ::1...Connected to localhost.Escape character is &apos;^]&apos;.J5.7.22[cqo3I @kX@n#I\mysql_native_password 访问MySQL的应用程序不应该信任用户输入的任何数据，应该使用适当的防御性编程技术编写。 不要通过Internet传输普通数据(未加密)。请使用SSL或SSH加密协议。MySQL支持内部SSL连接；或是使用SSH端口转发为通信创建加密隧道。 学习使用tcpdump和strings使用程序。可使用如下命令来检查MySQL数据流是否加密: 1tcpdump -l -i eth0 -w - src or dst port 3306 | strings 密码安全Keeping Passwords Secure 密码出现在MySQL的多个上下文中。此解提供了一些准则，使用户和管理员能够保护这些密码的安全性，并避免暴露这些密码。还讨论了MySQL如何在内部使用密码散列以及可用来强制执行更严格密码的插件。 密码安全用户指南End-User Guidelines for Password Security MySQL用户应使用以下准则来保证密码安全。当运行Client连接到MySQL server时，不建议以公开的方式来指定你的密码。 使用mysql_config_editor实用程序，它可将身份认证凭据存储在名为.mylogin.cnf的加密登录路径文件中。 使用-pPASSWD或--password=PASSWD选项 使用-p或--password选项不指定值 将密码存储到配置文件 将密码存储到MYSQL_PWD环境变量 12345678910111213141516171819202122232425#强烈不推荐#这虽然方便却不安全mysql -u user -pPASSWD db_name#推荐#但这适用于交互式mysql -u user -p db_nameEnter password: xxx#写入配置文件chmod 600 ~/.my.cnfvim ~/.my.cnf[client]password=xxxmysql --defaults-file=~/.my.cnf#指定MySQL密码环境变量的方法非常不安全，不应该使用 在Unix上，MySQL Client将执行语句的记录写入历史文件。默认情况下，此文件为~/.mysql_history。密码可以在SQL语句中以纯文本形式写入(如CREATE USER, ALTER USER)，如果使用了这些语句，它们将被记录到历史文件中。要保证此文件的安全，请使用限制访问模式。 如果命令解释器程序配置为维护历史记录，则保存命令的任何文件都将包含在命令行中输入的MySQL密码。如bash下的~/.bash_history。 密码安全管理员指南Administrator Guidelines for Password Security MySQL数据库管理员应使用以下准则来保证密码安全： MySQL在mysql.user表中存储用户账户密码。永远不要向任何非管理账户授予此表的访问权限 账户密码可以过期，以便用户必须重置密码 validate_password插件可用于对可接受的密码强制实施策略 应该保护可能写入密码的日志文件等文件 密码和日志Passwords and Logging 密码可在SQL语句中以纯文本形式写入，如CREATE USET, GRANT, SET PASSWORD和调用PASSWORD()函数的语句。如果MySQL Server记录了这些语句，那么访问日志的任何人都可以看到密码。 语句记录避免以明文形式为以下语句编写密码： 1234567CREATE USER ... IDENTIFIED BY ...ALTER USER ... IDENTIFIED BY ...GRANT ... IDENTIFIED BY ...SET PASSWORD ...SLAVE START ... PASSWORD = ...CREATE SERVER ... OPTIONS(... PASSWORD ...)ALTER SERVER ... OPTIONS(... PASSWORD ...) 对于常规查询日志，可通过使用--log-raw选项启动Server来抑制密码重写。出于安全原因，此选项不建议用于生产环境。处于诊断目的，查看Server收到的语句的确切文本可能很有用。审计日志插件生成的审计日志文件的内容未加密。出于安全原因，应将此文件写入只有MySQL Server和用户才能访问的目录，并且有正当理由查看目录。只有在需要纯文本密码时才会进行密码重写，对于具有期望密码散列语法的语句，不会发生重写。要保护日志文件免受不必要的暴露，请将他们放在限制访问Server和管理员的目录中。副本集slave将复制副本集master的密码存储在主信息存储库中，它可以是文件或表。确保只能由管理员访问此库。 使用受限的访问模式来保护包含日志表或密码的日志文件的数据库备份。 密码散列Password Hashing in MySQL MySQL在mysql.user数据表中列出用户账户。可以为每个MySQL账户分配一个密码，尽管用户表不存储明文密码，而是存储密码的散列值。 MySQL在Client/Server通信的两个阶段中使用密码： 当客户端尝试连接到Server时，有一个初始身份认证步骤，其中客户端必须提供密码，该密码的散列值与mysql.user用户表中存储的散列值相匹配 客户端连接之后，它可以(如果有足够权限)设置或更改mysql.user用户表中账户的密码的散列值。客户端可通过使用PASSWORD()函数来生成密码散列，或使用密码生成语句(CREATE USER, GRANT, SET PASSWORD)来完成此操作。 换句话说，Server在客户端首次尝试连接时在身份认证期间检查散列值。如果连接的客户端调用PASSWORD()函数，或使用密码生成语句来设置/更改密码，则Server会生成散列值。 12345678910111213141516171819202122232425help PASSWORD;#This function is deprecated as of MySQL 5.7.6 and will be removed in a future MySQL release#The Original (Pre-4.1) Hashing Method#原始散列方法产生一个16Byte的字符串mysql&gt; SELECT PASSWORD(&apos;mypass&apos;);+--------------------+| PASSWORD(&apos;mypass&apos;) |+--------------------+| 6f8c114b58f2ce9e |+--------------------+#The 4.1 Hashing Method#MySQL4.1引入了密码散列，提供了更好的安全性并降低了密码被截获的风险#生成更长的41Byte的散列值mysql&gt; SELECT PASSWORD(&apos;mypass&apos;);+-------------------------------------------+| PASSWORD(&apos;mypass&apos;) |+-------------------------------------------+| *6C8989366EAF75BB670AD8EA7A7FC1176A95CEF4 |+-------------------------------------------+ 散列方法的兼容性问题Compatibility Issues Related to Hashing Methods 使MySQL安全抵御攻击者Making MySQL Secure Against Attackers 连接到MySQL server时，应使用密码。密码在连接时不会以明文形式传输。所有其它信息都以文本形式传输，对任何能够看到连接的人都可读。如果连接通过不信任的网络，则可以使用压缩协议使流量更难以解密。你还可以使用MySQL的内部SSL支持来使连接更安全。或者，使用SSH在MySQL server和client之间获得加密的TCP/IP连接。 要使得MySQL系统安全，你应该强烈考虑以下建议： 要求所有MySQL账户都有密码 确保只有Unix用户账户对数据库目录具有读写权限，它是用于运行mysqld的账户 永远不要以root用户运行MySQL server，应该使用普通的非特权用户运行 MySQL用户账户和Unix系统账户没有关联 不要对非管理员用户授予FILE权限，具有此权限的用户都可使用mysqld daemon的权限在文件系统的任何位置编写文件，同样也可读取文件，并将文件载入数据库 不要对非管理员用户授予PROCESS或SUPER权限(可用于终止连接，修改系统变量…) 不允许对表使用符号链接 安全地存储程序和视图 如果不信任DNS，则应在授权表中使用IP地址而非主机名 如果想要限制单个账户的连接数，可在mysqld中配置max_user_connection变量 如果插件目录对server可写，这可修改它为只读 12345678910111213141516171819202122232425262728#服务cat /usr/lib/systemd/system/mysqld.service[Service]User=mysqlGroup=mysql#或配置文件/etc/my.cnf[mysqld]user=mysql#查看当前正在执行的语句msyql&gt; SHOW PROCESSLIST;+----+------+-----------+-------+---------+------+----------+------------------+| Id | User | Host | db | Command | Time | State | Info |+----+------+-----------+-------+---------+------+----------+------------------+| 18 | root | localhost | mysql | Query | 0 | starting | SHOW PROCESSLIST |+----+------+-----------+-------+---------+------+----------+------------------+# Disabling symbolic-links is recommended to prevent assorted security riskscat /etc/my.cnfsymbolic-links=0 安全相关的mysqld选项和变量Security-Related mysqld Options and Variables 下表显示了影响安全性的mysqld的选项和系统变量: Name Cmd-Line Option File System Var Status Var Var Scope Dynamic allow-suspicious-udfs Yes Yes automatic_sp_privileges Yes Global Yes chroot Yes Yes des-key-file Yes Yes local_infile Yes Global Yes old_passwords Yes Both Yes safe-user-create Yes Yes secure-auth Yes Yes Global Yes - Variable: secure_auth Yes Global Yes secure-file-priv Yes Yes Global No - Variable: secure_file_priv Yes Global No skip-grant-tables Yes Yes skip-name-resolve Yes Yes Global No - Variable: skip_name_resolve Yes Global No skip-networking Yes Yes Global No - Variable: skip_networking Yes Global No skip-show-database Yes Yes Global No - Variable: skip_show_database Yes Global No 以普通用户运行MySQLHow to Run MySQL as a Normal User 在Linux上，使用MySQL-repo、RPM包、Debian包来安装MySQL。MySQL server mysqld默认是由操作系统的mysql用户来启动。 对于使用.tar.gz包进行的安装，你需要修改为non-root用户。 1234567chown -R user_name /path/to/mysql/datadirvim /etc/my.cnf[mysqld]user=user_name LOAD DATA LOCAL的安全问题LOAD DATA语句可以载入主机上的文件。 这有两个潜在的安全问题： 从Client到Server的文件传输是由MySQL server启动。理论上，server可告诉client传输server选择的文件而不是LOAD DATA语句中client指定的文件。这样，server可以访问client端用户可访问的任何文件。 在client从web server连接的Web环境中，用户可使用LOAD DATA LOCAL来读取Web server进程具有访问权限的任何文件。 为了避免LOAD DATA问题，客户端应该避免使用LOCAL。为避免连接到不受信任的Server，Client可通过--ssl-mode=xxx选项和相应的CA证书建立安全的连接。 要是管理员和应用程序能够管理本地数据加载功能，LOCAL配置的工作方式如下： On the server sidelocal_infile系统变量控制服务器端的LOCAL功能。默认启用local_infile。 On the client sideENABLED_LOCAL_INFILE CMake选项控制MySQL Client Library的已编译的默认LOCAL功能。使用C API的客户端程序可通过调用mysql_options()来启用/禁用MYSQL_OPT_LOCAL_INFILE。对于mysql Client，默认禁止本地数据载入。使用--local-infile=1/0对于mysqlimport client，默认禁用本地数据载入。使用--local=1/0 客户端程序安全指南Client Programming Security Guidelines 访问MySQL的应用程序不应该信任用户输入的任何数据，用户可以尝试通过在Web表单，URL或构建的任何应用程序中输入特殊字符序列来欺骗你。如果用户输入DROP DATABASE mysql;类似语句，请确保你的应用程序保持安全，这是一个极端栗子。有时人们会认为，如果数据库只包含公开可用的数据，则无需受到保护。这是不正确的。即使允许在数据库中显示任何行，你仍应该防止拒绝服务攻击。 检查清单： 启用更严格的SQL模式以告知server对其接收的数据做更多限制 注意单/双引号 通过添加%22(&quot;), %23(&quot;), %27(&#39;)来修改动态URLs 动态修改URL中的数据类型 尝试输入字符、空格和特殊符号，而不是 数字 将数据传递给MySQL前检查数据大小 使用不同于管理员的用户将应用程序连接到数据库 访问权限系统The MySQL Access Privilege System MySQL权限系统的主要功能就是对从给定主机连接的用户进行身份认证，并将用户与数据库的权限(SELECT, INSERT, UPDATE, DELETE)相关联。其它功能包含匿名用户(anonymous user)和MySQL特定功能的授权。 有些事情你无法使用MySQL权限系统： 你无法明确指定拒绝给定用户访问 你无法指定用户创建/删除表的权限，但不能指定创建/删除数据库自身 适用于账户全局性的密码 MySQL权限系统的用户接口(user interface)由： CREATE USER, GRANT, REVOKE语句组成。 在内部，Server将权限信息存储在mysql数据库的授权表中。MySQL server在启动时将这些表内容读入内存，并根据授权表的内存中的副本建立访问控制决策。MySQL权限系统确保所有用户只能执行允许的操作。作为用户，当你连接到MySQL server时，你的身份由你连接的主机和你指定的用户名决定。在连接后，系统会根据你的身份和要执行的操作授予权限。MySQL会识别你的主机名和用户名，因为没有理由认为给定的用户名属于所有主机上的同一个人。 1234SHOW GRANTS;SHOW GRANTS FOR &apos;joe&apos;@&apos;office.example.com&apos;;SHOW GRANTS FOR &apos;joe&apos;@&apos;home.example.com&apos;; 当运行客户端程序连接到server时，MySQL访问控制包含两个阶段： server根据你的身份来接受/拒绝连接，以及你是否可通过提供正确的密码来验证你的身份 假设你可以连接，server会检查你发出的每个语句，以确定是否有足够的权限来执行它 MySQL提供的权限Privileges Provided by MySQL 授予MySQL账户的权限决定了账户可以指定的操作。MySQL权限在它们适用的上下文和不同操作级别上有所不同： 管理员权限(Administrative privileges)允许用户管理MySQL Server的操作。这些权限是全局的，因为它们不是特定于特定数据库 数据库权限(privileges for database)适用于数据库及其中的所有对象。可以为特定数据库或全局赋予这些权限，以便它们适用于所有数据库 数据库对象权限(privileges for database object)，如表，索引，视图… 可用权限Summary of Available Privileges 下表显示了GRANT和REVOKE语句中使用的权限名称，以及每个权限关联的列名和权限适用的上下文: Privilege Grant Table Column Context ALL [PRIVILEGES] Synonym for “all privileges” Server administration ALTER Alter_priv Tables ALTER ROUTINE Alter_routine_priv Stored routines CREATE Create_priv Databases, tables, or indexes CREATE ROUTINE Create_routine_priv Stored routines CREATE TABLESPACE Create_tablespace_priv Server administration CREATE TEMPORARY TABLES Create_tmp_table_priv Tables CREATE USER Create_user_priv Server administration CREATE VIEW Create_view_priv Views DELETE Delete_priv Tables DROP Drop_priv Databases, tables, or views EVENT Event_priv Databases EXECUTE Execute_priv Stored routines FILE File_priv File access on server host GRANT OPTION Grant_priv Databases, tables, or stored routines INDEX Index_priv Tables INSERT Insert_priv Tables or columns LOCK TABLES Lock_tables_priv Databases PROCESS Process_priv Server administration PROXY See proxies_priv table Server administration REFERENCES References_priv Databases or tables RELOAD Reload_priv Server administration REPLICATION CLIENT Repl_client_priv Server administration REPLICATION SLAVE Repl_slave_priv Server administration SELECT Select_priv Tables or columns SHOW DATABASES Show_db_priv Server administration SHOW VIEW Show_view_priv Views SHUTDOWN Shutdown_priv Server administration SUPER Super_priv Server administration TRIGGER Trigger_priv Tables UPDATE Update_priv Tables or columns USAGE Synonym for “no privileges” Server administration 授权指南Privilege-Granting Guidelines 最好只向账户授权它所需要的权限，在授予FILE和管理权限时应特别小心: FILE： 可在MySQL Server主机上读取的任何文件读入数据库表 GRANT OPTION： 使用户能够将其权限授权其他用户。具有不同权限且具有GRANT OPTION权限的两个用户可以组合权限 ALTER: 可通过重命名表来破坏权限系统 SHUTDOWN： 通过终止Server完全拒绝向其它用户提供服务 PROCESS： 用于查看当前正在执行的语句的纯文本，包括设置和更改密码的语句 SUPER： 用于终止其它会话或更改服务器的运行方式 为mysql系统数据本自身授予的权限可用于更改密码和其它访问权限信息： 密码以加密方式存储，因此恶意用户无法简单地读取明文密码。然而，具有对mysql.user表authentication_string列具有写权限的用户可以更改账户密码，然后进行登录 为mysql系统数据库授予INSERT或UPDATE权限允许用户添加或修改现有权限 mysql系统数据库的DROP权限使用户能够访问远程权限表，甚至是数据库本身 授权表Grant Tables mysql系统数据库包含多个授权表，其中包含有关用户账户及其拥有的权限信息。mysql数据库表包含的授权信息： user: 用户账户，全局权限，其它非权限列 db: 数据库级别权限 tables_priv：表级别权限 columns_priv： 列级别权限 procs_priv： 存储过程和功能权限 proxies_priv： 代理用户权限 每个授权表包含的列范围和列权限： 列范围确定表中每行的范围 列权限指示表中行授予的权限 Server以下列方式使用授权表： user表范围列确定是拒绝还是允许传入连接 db表范围列确定哪些用户可以从哪些主机上访问数据库 tables_priv和columns_priv表更精细，它们适用于表级别和列级别 procs_priv表用于存储的例程 proxies_priv表指示哪些用户可以充当其它用户的代理，以及用户是否可以将PROXY权限授予其它用户 指定账户名Specifying Account Names MySQL账户名由用户名和主机名组成。这样可以为具有相同名称且可以从不同主机连接的用户创建账户。 在SQL语句中，账户名称遵循以下规则： 账户名语法为: username@hostname 仅包含用户名的账户相当于username@% 注意反引号、单引号、双引号 引号的正确用法: &#39;username&#39;@&#39;hostname&#39; MySQL使用单独的用户名和主机名部分将账户名称存储到mysql系统数据库的授权表中： user表包含每个账户的一行，user.User，user.Host列存储用户名和主机名，此表还指示了账户具有哪些全局权限 其它授权表指示账户对数据库和库中对象的权限，这些表也有User, Host列来存储用户名和主机名 处于访问检查的目的，User value区分大小写，Host value不区分大小写 用户名和主机名还具有某些特殊值或通配符约定，如下:账户名的用户名部分是非空白值，或者是与任何用户名匹配的空值。具有空白用户名的账户是匿名用户(anonymous user)。在SQL语句中指定一个匿名用户，使用带引号的空用户名，如&#39;&#39;@&#39;localhost&#39;。 账户名的主机名部分可以采用多种形式，并允许使用通配符： host value可以是主机名或IP地址(ipv4, ipv6) 主机名或IP地址值中允许使用%和_通配符。例如，主机值%匹配任何主机名，如%.mysql.com匹配mysql.com域中的任何主机。 对于IPv4地址，可以给出网络掩码以指示用于网络号的地址位数 1CREATE USER &apos;test&apos;@&apos;198.51.100.0/255.255.255.0； Server使用系统DNS解析程序为客户端主机名或IP地址返回的值，意味着你应该使用DNS使用的相同格式指定的账户主机值。 访问控制Access Control 连接验证Access Control, Stage 1: Connection Verification 当你连接到MySQL Server，它会根据以下条件接受或拒绝连接： 身份和密码 账户是否被锁定 Server首先检查凭据，然后检查账户锁定状态。任一步骤失败都会导致Server完全拒绝你的访问权限。使用mysql.user表中的三个范围列：Host, User, authentication_string执行凭据检查。 1234567891011121314151617181920SELECT User, Host FROM mysql.user;+-----------+----------+-| Host | User | ...+-----------+----------+-| % | root | ...| % | jeffrey | ...| localhost | root | ...| localhost | | ...+-----------+----------+-#内存中排序的表+-----------+----------+-| Host | User | ...+-----------+----------+-| localhost | root | ...| localhost | | ...| % | jeffrey | ...| % | root | ...+-----------+----------+- %： 表示任意主机 空用户名： 表示任意 当可能存在多个匹配时，Server必须确定要使用安歇匹配项： 只要Server将用户表读入内存，它就会对行进行排序 当用户尝试连接时，Server按排序顺序查看行 Server使用与客户端host和username匹配的第一行 请求认证Access Control, Stage 2: Request Verification 通过连接发出的每个请求，Server确定你要执行的操作，然后检查你是否具有足够的权限来执行此操作。这就是授权表中权限列生效的地方。这些权限可以来自任何user, db, table, column, procs。 全局权限(global)适用于全局范围内 数据库权限 空用户名匹配匿名用户，用户名中没有通配符 通配符%和_可在Host和Db列中使用，与LIKE操作符执行的模式匹配类似。如果要使用原字符，请使用反斜杠对其转义 %或空白Host值表示任意主机 %或空白Db值表示任意数据库 表、列、proc权限 通配符%, _ 以布尔术语表示，总结用户权限： 12345global privilegesOR (database privileges AND host privileges)OR table privilegesOR column privilegesOR routine privileges 权限更改生效时When Privilege Changes Take Effect 启动msyqld时，它读取所有授权表到内存中，内存中的表在此时对访问控制有效。如果使用GRANT, REVOKE, SET PASSWORD, RENAME USER账户管理语句间接修改了授权表，则Server会注意到这些更改并立即在此将授权表加载到内存中。如果直接使用INSERT, UPDATE, DELETE语句修改授权表，则在重启Server或指示重新加载表之前，对权限的更改没有影响。也就是说，直接修改授权表但没有重新加载它的话，更改时无效的。 告诉Server重新加载授权表，有几种方式： 1234567mysql&gt; FLUSH PRIVILEGES#或$ mysqladmin flush-privileges#或$ mysqladmin reload 如果使用--skip-grant-tables选项启动Server，则它不会读取授权表或实现任何访问控制。任何人都可以连接并做任何事情，这是不安全的。 连接MySQL的一些问题Troubleshooting Problems Connecting to MySQL 链接: https://dev.mysql.com/doc/refman/5.7/en/problems-connecting.html 用户账户管理MySQL User Account Management 本节介绍如何为MySQL Server的客户端设置账户： MySQL中使用的账户名和密码的含义，与操作系统使用的名称和密码的比较 如何设置新账户和删除现有账户 如何修改密码 密码使用安全指南 用户名和密码User Names and Passwords 有两种方式创建MySQL账户： 使用创建账户(CREATE USER)和建立权限(GRANT)的账户管理语句。这些语句使Server对基础授权表进行适当的修改 直接操作MySQL授权表，如INSERT, DELETE, UPDATE命令 推荐使用账户管理语句，因为它们比直接操作授权表更简洁，更不容易出错。 栗子： 1mysql --user=root mysql 创建账户： 1234567891011121314151617CREATE USER 'finley'@'localhost' IDENTIFIED BY 'passwd';GRANT ALL PRIVILEGES ON *.* TO 'finley'@'localhost' WITH GRANT OPTION;CREATE USER 'finley'@'%' IDENTIFIED BY 'passwd';GRANT ALL PRIVILEGES ON *.* TO 'finley'@'%' WITH GRANT OPTION;CREATE USER 'admin'@'localhost' IDENTIFIED BY 'password';GRANT RELOAD,PROCESS ON *.* TO 'admin'@'localhost';#查看SHOW GRANTS FOR 'admin'@'localhost';#特定权限CREATE USER 'reader'@'localhost' INDENTIFIED BY 'passwd';GRANT SELECT ON readdb.* TO 'reader'@'localhost'; 删除账户Removing User Accounts 使用DROP USER语句删除用户账户。 1DROP USER 'reader'@'localhost'; 保留账户Reserved User Accounts MySQL安装过程中的数据目录初始化期间，MySQL会创建应被视为保留的用户账户： &#39;root&#39;@&#39;localhost&#39;： 用于管理，拥有一切权限，可执行任何操作 &#39;mysql.sys&#39;@&#39;localhost&#39;： 用作sys模式对象的DEFINER。可避免DBA重命名或删除root账户时出现的问题 &#39;mysql.session@&#39;localhost&#39;：由插件在内部使用以访问Server 账户资源限制Setting Account Resource Limits 限制Client使用MySQL Server资源的一种方式是将全局max_user_connections系统变量设置为非零值。这限制了任何账户(缺乏单个用户)可以进行同时连接的数量，但是对连接后Client可以执行的操作没有限制。 为了解决这些问题，MySQL允许限制单个账户的资源： 账户每小时可以发出的查询数 账户每小时可以发出的更新数 账户每小时可以连接到Server的次数 账户与Server同时连接的数量 要在创建账户时设置资源限制，使用CREATE USER语句；要修改现有账户的限制，使用ALTER USER语句。使用WITH字句，命名每个要限制的资源。每个限制的默认值为零，即无限制。限制类型不必全部在WITH字句中命名，每个小时的限制值应该是一个整数。 Server在该账户对应的user表的行中存储账户的资源限制。当任何账户对其使用任何资源具有非零限制时，将进行资源使用计数。如果超过其连接次数，则Server会拒绝该账户的其它连接，直到该小时结束为止。在所有这些情况下，Server都会发出相应的错误消息。 12345678CREATE USER 'francis'@'localhost' IDENTIFIED BY 'frank' WITH MAX_QUERIES_PER_HOUR 20 MAX_UPDATES_PER_HOUR 10 MAX_CONNECTIONS_PER_HOUR 5 MAX_USER_CONNECTIONS 2;ALTER USER 'francis'@'localhost' WITH MAX_QUERIES_PER_HOUR 100; 假设全局变量max_user_connections值为10： 123ALTER USER 'user1'@'localhost' WITH MAX_USER_CONNECTIONS 0;ALTER USER 'user2'@'localhost' WITH MAX_USER_CONNECTIONS 5;ALTER USER 'user3'@'localhost' WITH MAX_USER_CONNECTIONS 20; 可以为单个账户、所有账户全局重置当前的计数： 使用FLUSH USER RESOURCES语句，将所有账户当前的计数重置为零 将单个账户的限制值重新设置，可以将账户的计数重置为零 每小时计数重置不会影响MAX_USER_CONNECTIONS限制。所有计数从零开始，计数不会通过Server重启而延续。 分配账户密码Assigning Account Passwords MySQL会自动散列(hash)指定的密码。 12345678910#在创建用户是使用INDENTIFIED BY字句分配密码CREATE USER 'jeffrey'@'localhost' IDENTIFIED BY 'password';#修改密码ALTER USER 'jeffrey'@'localhost' IDENTIFIED BY 'password';#修改连接账户的密码ALTER USER USER() IDENTIFIED BY 'password'; 或者使用mysqladmin修改密码，出于安全问题，不推荐使用。 1mysqladmin -u user_name -h host_name password "password" 密码管理Password Management MySQL使数据库管理员可以手动使帐户密码过期，并建立自动密码过期的策略。可以在全局建立到期策略，并且可以将个人帐户设置为遵循全局策略或使用特定的每帐户行为覆盖全局策略。 使用ALTER USER语句设置密码过期： 1ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE; 密码过期策略是自动的，并且基于密码的年龄和最近密码的更改日期和时间进行评估。mysql.user表上有上次更改密码的时间。要全局地建立自动密码过期策略，请使用default_password_lifetime系统变量。默认值为零，表示禁用自动密码过期。如果将值设置为正整数N，则表示允许的密码生存期，因此密码必须每N天更改一次。 栗子： 12345vim /etc/my.cnf[mysqld]default_password_lifetime=365 或者在MySQL中设置全局变量： 1SET GLOBAL default_password_lifetime = 365; 或者在创建账户时设置： 123456789101112CREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE INTERVAL 90 DAY;ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE INTERVAL 365 DAY;#禁用CREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE NEVER;ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE NEVER;#默认CREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE DEFAULT;ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE DEFAULT; Client成功连接后，Server将确定账户密码是否已过期： Server检查密码是否手动过期 否则，Server根据自动密码过期策略检查密码年龄是否大于其允许的生存期 密码过期和沙箱Password Expiration and Sandbox Mode 对于使用具有过期密码的账户的连接，Server要么断开连接，要么将Client限制为沙箱模式。 沙箱模式允许这些操作： Client可使用ALTER USER或SET PASSWORD重置账户密码。重置密码后，Server恢复回话的正常访问 代理用户Proxy Users MySQL Server使用身份验证插件验证客户端连接。验证给定连接的插件可以请求将外部连接用户视为不同的用户以进行特权检查。这就使外部用户成为第二个用户的代理。也就是说，假设第二个用户的权限： 外部用户是代理用户 第二个用户是被代理的用户 代理用户支持的要求Requirements for Proxy User Support 对于给定身份认证的插件的代理，必须满足一下条件： 必须通过插件本身或代表插件的MySQL Server服务器来支持代理 必须将代理用户账户设置为由插件进行身份验证(CREATE USER和ALTER USER语句) 必须创建代理用户账户并授予相关权限(CREATE USER和GRANT语句) 代理用户账户必须具有代理账户的proxy权限(GRANT语句) 对于连接到代理账户的Client将被视为代理用户，身份验证插件必须返回与客户端用户名不同的用户名，以指示代理账户的用户名，该用户名定义代理所承担的权限用户。 代理机制允许将客户端用户名映射到代理用户名，没有规定映射主机名。当连接Client与代理账户匹配时，Server会尝试使用身份验证插件返回的用户名和代理账户的主机名来查找账户的匹配项。 考虑如下账户定义： 1234567891011121314-- create proxy accountCREATE USER 'employee_ext'@'localhost' IDENTIFIED WITH my_auth_plugin AS 'my_auth_string';-- create proxied account and grant its privilegesCREATE USER 'employee'@'localhost' IDENTIFIED BY 'employee_pass';GRANT ALL ON employees.* TO 'employee'@'localhost';-- grant PROXY privilege to proxy account for proxied accountGRANT PROXY ON 'employee'@'localhost' TO 'employee_ext'@'localhost'; 当Client从localhost使用employee_ext连接时，MySQL使用名为my_auth_plugin的插件来执行身份验证。假设my_auth_plugin根据my_auth_string的内容向Server返回employee的用户名，并可能通过咨询某些外部身份验证系统。employee与employee_ext不同，因此返回employee作为请求，Server将employee_ext视为employee本地用户，以便进行权限检查。 Server通过检查employee_ext是否具有employee的PROXY权限来验证employee_ext是否可以对employee进行代理身份验证。 在此例中，employee_ext是代理用户，employee是被代理用户。 发生代理时，USER()和CURRENT_USER()函数可用于查看连接用户(代理用户)与当前会话账户(被代理的用户)之间的区别： 123456SELECT USER(), CURRENT_USER();+------------------------+--------------------+| USER() | CURRENT_USER() |+------------------------+--------------------+| employee_ext@localhost | employee@localhost |+------------------------+--------------------+ 授予代理权限Granting the Proxy Privilege 需要PROXY权限才能使外部用户连接并拥有其他用户的权限。要授予此权限，请使用GRANT语句。 1234567GRANT PROXY ON 'proxied_user' TO 'proxy_user';GRANT PROXY ON 'a' TO 'b', 'c', 'd';GRANT PROXY ON 'a' TO 'd' WITH GRANT OPTION;GRANT PROXY ON 'a' TO ''@'';REVOKE PROXY ON 'a' FROM 'b', 'c', 'd'; 默认代理用户Default Proxy Users 要制定某些或所有用户应使用给定的身份验证进行连接，请创建一个空白MySQL账户(&#39;&#39;@&#39;&#39;)，将其与该插件关联，然后让插件返回真实身份验证的用户名。 栗子： 12345678910-- create default proxy accountCREATE USER ''@'' IDENTIFIED WITH ldap_auth AS 'O=Oracle, OU=MySQL';-- create proxied accountsCREATE USER 'developer'@'localhost' IDENTIFIED BY 'developer_pass';CREATE USER 'manager'@'localhost' IDENTIFIED BY 'manager_pass';-- grant PROXY privilege to default proxy account for proxied accountsGRANT PROXY ON 'manager'@'localhost' TO ''@'';GRANT PROXY ON 'developer'@'localhost' TO ''@''; 默认代理用户和匿名用户冲突Default Proxy User and Anonymous User Conflicts 如果打算创建默认代理用户，请检查其他现有的匹配任何用户账户，这些账户优先于默认代理用户，因为他们可以阻止该用户按预期工作。 在前面的讨论中，默认代理账户在主机部分具有&#39;&#39;，与任何主机匹配。如果你设置了默认代理用户，请注意检查非代理账户是否存在相同的用户部分和主机部分中的%，因为%也匹配任何主机，但优先于&#39;&#39;，Server用于在内部对账户进行排序。 要避免此问题，请使用以下策略之一： 删除匿名用户，使其不与默认代理用户冲突 使用在匿名用户之前匹配的更具体的默认代理用户，如&#39;&#39;@localhost 创建多个代理用户。用于本地连接和远程连接 Server支持代理用户映射Server Support for Proxy User Mapping 一些身份验证插件为自身实现代理用户映射(如PAM)。默认情况下，其他身份验证插件不支持代理用户。如果启用了check_proxy_users系统变量，则Server会对发出此类请求的任何身份认证插件执行代理用户映射： 默认情况下，check_proxy_users被禁用。因此即使对请求Server支持代理用户的身份验证插件，Server也不执行用户代理映射。 如果启用了check_proxy_users，则可能还需要启用特定于插件的系统变量以利用Server代理用户映射支持： 对于mysql_native_password插件，请启用mysql_native_proxy_users 对于sha256_password插件，请启用sha256_password_proxy_users Server执行的代理用户映射受以下限制： 即使授权了关联的PROXY权限，Server也不会代理匿名用户(FROM)或从匿名用户代理(TO) 如果单个账户授予了多个代理账户的代理权限，则Server代理用户是不确定的。因此，不鼓励为多个被代理账户授予单个账户代理权限 代理用户系统变量Proxy User System Variables 两个系统变量有助于追踪代理登录过程： proxy_user如果未使用代理，则此值为NULL。否则，它表示代理用户账户。 external_user有时，身份验证插件可能会使用外部用户对MySQL Server进行身份验证。 用户账户User Account Locking 从MySQL v5.7.6开始，MySQL支持使用ACCOUNT LOCK和ACCOUNT UNLOCK子句为CREATE USER和ALTER USER语句锁定和解锁用户账户： 与CREATE USER一起使用时，这些子句指定新账户的初始锁定状态。如果没有任何一个子句，则账户将以未锁定状态创建。 与ALTER USER一起使用时，这些子句指定现有账户的新锁定状态。如果没有任何一个子句，则账户锁定状态保持不变。 账户锁定状态记录在mysql.user系统表的account_locked列中。使用SHOW CREATE USER显示账户锁定状态。 如果Client尝试连接到已锁定的账户，则会失败。返回错误消息，并将错误写入日志。 锁定账户不会影响能够使用承担锁定账户身份的代理用户进行连接。她也不会影响执行存储程序和试图的能力，这些程序或视图具有命名锁定账户的DEFINER子句。也就是说，锁定账户，不会影响使用代理账户或存储的程序或视图的能力。 要从旧版本升级到MySQL 5.7.6以及更高版本，请运行mysql_upgrade以确保此列存在。对于没有account_locked列的非升级安装，Server会将所有账户视为已解锁。 基于SQL的MySQL账户活动审计SQL-Based MySQL Account Activity Auditing 应用程序可以使用以下准则来执行基于SQL的审计，该审计将数据库活动与MySQL账户联系起来。 MySQL账户对应于mysql.user系统表中的行。当Client连接成功后，Server会将Client验证到此表中的特定行。此行中的User和Host列的值唯一标识该账号，并对应于user@host格式，其中账户名称在SQL语句中写入。 用于验证Client的账户确定Client具有哪些权限。通常，可以调用CURRENT_USER()函数来确定这对于Client用户来说是哪个账户。其值有账户的用户表行的User和Host列构成。但是，在某些情况下，CURRENT_USER()值不对应于客户端用户，而是对英语不同的账户。当权限检查不基于客户端账户时，会发生这种情况： 使用 SQL SECURITY DEFINER特性定义的存储例程 使用 SQL SECURITY DEFINER特性定义的视图 触发器和事件 在这些上下文中，权限检查是针对DEFINER账户完成的，而CURRENT_USER()是指该账户，而不是指调用存储例程或视图的Client或导致触发器激活的账户。 如果应用程序必须调用USER()进行用户审计，但是还必须能够将USER()值与用户表中的账户相关联，则必须避免使用在User或Host列中包含通配符。具体来说，不允许User为空，并且不允许Host值中使用模式字符或网络掩码表示法。所有账户必须具有非空用户值和文字主机值。 更改账户用户主机： 1234RENAME USER ''@'localhost' TO 'user1'@'localhost';RENAME USER 'user2'@'%.example.com' TO 'user2'@'remote.example.com';-- 如果user2必须能够从example.com域中的多个主机进行连接，则每个主机应该有一个独立的账户 要从CURRENT_USER()或USER()函数中提取用户名或主机名，请使用SUBSTRING_INDEX()函数： 1234567891011121314SELECT SUBSTRING_INDEX(CURRENT_USER(),'@',1);+---------------------------------------+| SUBSTRING_INDEX(CURRENT_USER(),'@',1) |+---------------------------------------+| user1 |+---------------------------------------+SELECT SUBSTRING_INDEX(CURRENT_USER(),'@',-1);+----------------------------------------+| SUBSTRING_INDEX(CURRENT_USER(),'@',-1) |+----------------------------------------+| localhost |+----------------------------------------+ 使用加密连接Using Encrypted Connections MySQL Client和Server之间的未加密连接，有权访问网络的人可以监视你的所有流量和C/S之间发送和接受的数据。要使任何类型的在网络中数据不可读，请使用加密。加密算法必须包含安全元素，以抵御多种已知的攻击。 MySQL支持使用TLS协议在C/S之间建立加密连接。TLS有时被称为SSL，但MySQL实际上并不使用SSL协议进行加密，因为它的加密很弱。TLS使用加密算法来确保可以信任通过公共网络接收的数据。它具有检测数据更改、丢失、重放的机制。TLS还包含使用X.509标准提供的身份验证的算法。X.509可以识别互联网上的某个人。在基本术语中，有一些被称为证书颁发机构(CA)的实体，它将电子证书分配给需要它们的任何人。证书依赖于两个加密密钥(公钥和私钥)的非对称加密算法。证书所有者可以将证书提供给另一方作为身份证明。证书由其所有者的公钥组成，使用该公钥加密的任何数据只能使用有该证书的私钥来解密。 可以使用OpenSSL和yaSSL编译MySQL以获得加密连接支持。默认情况下，如果Server支持加密连接，MySQL将尝试使用加密连接。如果无法建立加密连接，则会回退到未加密的连接。MySQL基于每个连接执行加密，并且对给定用户使用加密可以是可选的或强制的。这使你可以根据各个应用程序的要求选择加密或未加密的连接。 加密连接同样可用于Master和Slave的副本集之间。也可以通过MySQL C API获得加密连接。也可以使用SSH连接内的加密连接到MySQL Server。 配置MySQL以使用加密连接Configuring MySQL to Use Encrypted Connections 有几个选项用于指示是否使用加密连接，以及制定适当的证书和密钥文件。它包括： Server端 Client端 S端加密连接配置Server-Side Configuration for Encrypted Connections 在S端，--ssl选项指定Server允许但不需要加密连接。默认情况下启用此选项。Server端的这些选项标识了Server在允许Client建立加密连接时使用的证书和密钥文件： --ssl-caCA颁发的证书文件的路径名 ssl-certServer公钥证书文件的路径名。可以发送到Client端，并根据它具有的CA证书进行身份验证 ssl-keyServer私钥文件的路径名 启用加密连接，修改my.cnf的栗子： 1234[mysqld]ssl-ca=ca.pemssl-cert=server-cert.pemssl-key=server-key.pem C端加密连接配置Client-Side Configuration for Encrypted Connections 默认情况下，如果Server支持加密连接，MySQL Client将尝试建立加密连接，并通过--SSL-mode选项进一步控制： 如果没有ssl-mode选项Client将尝试使用加密连接，如果无法建立加密连接，则会回退到未加密的连接。这等同于--ssl-mode=PREFFERED --ssl-mode=REQUIREDClient需要加密连接，如果无法建立，则会失败 --ssl-mode=DISABLEDClient使用未加密连接 --ssl-mode=VERIFY_CA或--ssl-mode=VERIFY_IDENTITY客户端需要加密连接，并且还要针对Server CA证书和对其他证书中的Server主机名进行验证 Client以下几个选项类似于Server端的几个选项，标识C/S加密连接时使用的证书和密钥文件： --ssl-ca --ssl-cert --ssl-key 加密连接的命名选项Command Options for Encrypted Connections 本节介绍使用加密连接的选项。 123456789101112--skip-ssl Do not use encrypted connection --ssl Enable encrypted connection --ssl-ca File that contains list of trusted SSL Certificate Authorities --ssl-capath Directory that contains trusted SSL Certificate Authority certificate files --ssl-cert File that contains X.509 certificate --ssl-cipher List of permitted ciphers for connection encryption --ssl-crl File that contains certificate revocation lists --ssl-crlpath Directory that contains certificate revocation list files --ssl-key File that contains X.509 key --ssl-mode Security state of connection to server 5.7.11--ssl-verify-server-cert Verify host name against server certificate Common Name identity --tls-version Protocols permitted for encrypted connections 5.7.10 创建SSL/RSA证书和密钥Creating SSL and RSA Certificates and Keys 可以使用MySQL自身提供的工具或直接调用openssl命令来创建所需文件。 使用MySQL创建Creating SSL and RSA Certificates and Keys using MySQL MySQL提供了这些方法来创建SSL证书和密钥文件以及使用SSL支持加密连接所需的RSA密钥对文件，以及使用RSA通过未加密连接进行安全密码交换。如果缺少这些文件： 对于使用OpenSSL编译的MySQL发行版，Server可在启动时自动生成这些文件 用户可以手动调用mysql_ssl_rsa_setup实用程序 对于某些发行版(如RPM包)，在数据目录初始化期间会调用mysql_ssl_rsa_setup。在这种情况下，只要openssl命令可用，就不需要使用OpenSSL编译MySQL发行版 自动SSL和RSA文件生成 Automatic SSL and RSA File Generation 对于使用OpenSSL编译的MySQL发行版，MySQL Server能够在启动时自动生成缺少的SSL和RSA文件。auto_generate_certs和sha256_password_auto_generate_rsa_keys系统变量控制这些文件的自动生成。默认情况下启用这两个变量，它们可以在启动时启用并检查，但不能在运行时设置。 启动时，如果启用了auto_generate_certs系统变量，则Server会自动在数据目录中生成S端和C端的SSL证书和密钥文件。 Server检查数据目录下的SSL文件： 123ca.pemserver-cert.pemserver-key.pem 如果存在，则不创建。反之，则创建 123456ca.pem Self-signed CA certificateca-key.pem CA private keyserver-cert.pem Server certificateserver-key.pem Server private keyclient-cert.pem Client certificateclient-key.pem Client private key 如果Server自动生成了RSA文件，它将使用其名称来设置相应的系统变量 启动时，如果满足以下条件(sha256_password_auto_generate_rsa_keys系统变量已启用；没有指定RSA选项；数据目录中缺少RSA文件)，则Server会自动在数据目录中生成RSA私钥/公钥对文件。 Server检查数据目录下的RSA文件 12private_key.pem Private member of private/public key pairpublic_key.pem Public member of private/public key pair 如果存在，则不创建。反之，则创建 如果Server自动生成了RSA文件，它将使用其名称来设置相应的系统变量 手动生成 Manual SSL and RSA File Generation Using mysql_ssl_rsa_setup MySQL发行版包含此实用程序，但它需要openssl命令可用。 SSL/RSA文件特性 SSL and RSA File Characteristics 它们具有以下特性： SSL/RSA密钥大小为2048bits SSL CA证书是自签名的 SSL Server/Client的CA证书和密钥对，使用sha256WithRSAEncryption签名算法 创建的SSL文件自生成之日起有效期为十年 RSA文件不会过期 SSL文件对于每个证书/密钥对具有不同的序列号(1 for CA, 2 for Server, 3 for Client) 创建的文件由运行程序执行创建的用户拥有 Unix/Unix-Like上，证书文件权限为644，密钥文件权限为600 查看SSL证书内容： 123openssl x509 -text -in ca.pemopenssl x509 -text -in server-cert.pemopenssl x509 -text -in client-cert.pem 使用SQL语句查看SSL证书过期时间： 1234567SHOW STATUS LIKE 'Ssl_server_not%';+-----------------------+--------------------------+| Variable_name | Value |+-----------------------+--------------------------+| Ssl_server_not_after | Apr 28 14:16:39 2027 GMT || Ssl_server_not_before | May 1 14:16:39 2017 GMT |+-----------------------+--------------------------+ 使用openssl创建SSL证书和密钥Creating SSL Certificates and Keys Using openssl 创建栗子： 123456789101112131415161718192021222324# Create clean environmentrm -rf newcertsmkdir newcerts &amp;&amp; cd newcerts# Create CA certificateopenssl genrsa 2048 &gt; ca-key.pemopenssl req -new -x509 -nodes -days 3600 \ -key ca-key.pem -out ca.pem# Create server certificate, remove passphrase, and sign it# server-cert.pem = public key, server-key.pem = private keyopenssl req -newkey rsa:2048 -days 3600 \ -nodes -keyout server-key.pem -out server-req.pemopenssl rsa -in server-key.pem -out server-key.pemopenssl x509 -req -in server-req.pem -days 3600 \ -CA ca.pem -CAkey ca-key.pem -set_serial 01 -out server-cert.pem# Create client certificate, remove passphrase, and sign it# client-cert.pem = public key, client-key.pem = private keyopenssl req -newkey rsa:2048 -days 3600 \ -nodes -keyout client-key.pem -out client-req.pemopenssl rsa -in client-key.pem -out client-key.pemopenssl x509 -req -in client-req.pem -days 3600 \ -CA ca.pem -CAkey ca-key.pem -set_serial 01 -out client-cert.pem 验证： 1openssl verify -CAfile ca.pem server-cert.pem client-cert.pem 使用openssl创建RSA密钥Creating RSA Keys Using openssl 创建： 12345openssl genrsa -out private_key.pem 2048openssl rsa -in private_key.pem -pubout -out public_key.pemchmod 400 private_key.pemchmod 444 public_key.pem 安全插件Security Plugins MySQL包括几个实现安全功能的插件： 用于MySQL C/S 连接尝试的插件 用于实施密码强度策略和评估潜在密码强度的密码验证插件 用于敏感信息安全存储的密钥环(keyring)插件 MySQL企业版插件 身份认证插件Authentication Plugins 原生可插拔认证Native Pluggable Authentication MySQL包含两个实现原生身份认证的插件。在引入可插拔身份验证之前，基于密码散列的方法的身份验证。 本级密码验证的插件和库名称： Plugin or File Plugin or File Name Server-side plugin mysql_native_password Client-side plugin mysql_native_password Library file None (plugins are built in) 安装本机可插拔认证Installing Native Pluggable Authentication mysql_native_password插件存在于Server和Client的表单中： S端插件内置于Server，无需显式加载，也无法通过卸载来禁用 C端插件内置于libmysqlclient库中，可用于链接到此库的任何程序 使用本机可插拔认证Using Native Pluggable Authentication MySQL Client程序默认使用mysql_native_password。 旧的本机可插拔认证Old Native Pluggable Authentication MySQL version 4.1机之前。 从旧的插件迁移到新的插件Migrating Away from Pre-4.1 Password Hashing and the mysql_old_password Plugin SHA-256可插拔认证SHA-256 Pluggable Authentication 备份和恢复Backup and Recovery 数据备份非常重要！ MySQL提供了各种备份策略，你可以从中选择最适合安装要求的方法。本章讨论几个你应该熟悉的备份和恢复的主题： 备份类型： 逻辑与物理，全量和增量… 创建备份的方法 恢复方法，包括时间点(point-in-time)恢复 备份调度，压缩和加密 表维护，以便恢复损坏的表 备份和恢复类型Backup and Recovery Types 物理与逻辑备份Physical (Raw) Versus Logical Backups 物理备份由目录的原始副本和存储数据库内容的文件组成。此类备份适用于需要在出现问题时快速恢复的大型重要数据库。 逻辑备份保存表示为逻辑数据库结构的信息(CREATE DATABASE, CREATE TABLE语句)和内容(INSERT语句和分割文本文件)。此类备份适用于较少量的数据，你可以在其中编辑数据值或表结构，或在不同计算机体系结构上重新创建数据。 物理备份方法具有以下特征： 此备份包含数据库目录和文件的精确副本。通常，这是MySQL数据目录的全部或部分副本 物理备份比逻辑备份更快，因为它们只涉及文件复制而不进行转换 输出比逻辑备份更紧凑(compact) 由于备份速度和紧凑性对于繁忙、重要的数据库很重要，因此MySQL Enterprise执行物理备份 备份和还原粒度范围从整个数据目录的级别到单个文件的级别。这可能会/也可能不会提供表级别的粒度，具体取决于存储引擎 除数据库外，此备份还可以包括任何相关文件(如日志和配置) 来自MEMORY表的数据很难以这种方式备份，因为它们的内容不存储在磁盘上 备份仅可移植到具有相同或类似硬件特征的其它计算机 可以在MySQL Server未运行时执行备份。如果Server正在运行，则必须执行适当锁定(lock)，以便Server在备份期间不会更改数据库内容。MySQL Enterprise备份会自动为它需要的表执行锁定 物理备份工具包括用于InnoDB或任何其它表的mysqlbackup，或用于MyISAM表的文件系统级别命令(cp, scp, tar, rsync) 对于恢复 MySQL Enterprise备份恢复InnoDB和备份的其它表 ndb_restore恢复NDB表 可使用文件系统级别的命令将文件复制回其原始位置 逻辑备份方法具有以下特性： 通过查询MySQL Server来获取数据库结构和内容信心来完成备份 此备份比物理备份慢，因为Server必须访问数据库信息并将其转换为逻辑格式 输出大于物理备份，特别是以文本格式保存时 备份和还原可在Server级别，数据库级别或表级别，而无论存储引擎如何 备份不包括日志和配置文件，或其它不属于数据库的相关文件 以逻辑格式的备份与机器无关，请具有高度可移植性 在MySQL Server运行时执行逻辑备份 逻辑备份工具包括mysqldump程序和SELECT ... INTO OUTFILE语句。这适用于任何存储引擎，甚至是MEMORY 要恢复逻辑备份，可使用mysql客户端处理SQL格式转储文件。要加载分割文本文件，使用LOAD DATA INFILE语句或mysqlimport客户端 在线与离线备份Online Versus Offline Backups 在MySQL Server运行时进行在线备份，以便可以从Server获取数据库信息。Server停止时进行离线备份。这种区别也可描述为热备(hot)与冷备(cold)，热备是Server保持允许但在外部访问数据库时锁定表以防止修改数据 在线备份具有以下特性： 此备份对其它客户端的干扰较小，其它客户端可在备份期间连接到MySQL Server，并且可以根据需要执行的操作来访问数据库 必须小心施加适当的锁定，以便不会发生损害备份完整性的数据修改。MySQL Enterprise会自动执行锁表 脱机备份方法有以下特性： 客户端可能会受到不利影响，因为备份期间Server不可用。因此，此类备份通常发生于Slave Server，可以脱机而不会损害可用性 备份过程简单，因为不会受到客户端活动的干扰 在线和离线之间的区别适用于恢复操作，并且适用于类似的特征。但是，由于恢复需要更强的锁定，因此客户端更有可能受到在线恢复的影响而不是在线备份。在备份期间，客户端可能能够在备份时读取数据；而恢复数据不仅仅是读取数据，因此必须防止客户端在恢复数据时访问数据。 本地与远程备份Local Versus Remote Backups 本地备份是在运行MySQL Server的统一主机上执行，而远程备份则从其它主机执行。 mysqldump能连接到本地或远程Server。对于SQL输出，既可在本地也可在远程；对于分割文件输出，将在Server上创建数据文件 SELECT ... INTO OUTFILE可从本地或远程启动，但输出文件是在Server上创建 物理备份通常在Server上启动，以便Server可以脱机 快照备份Snapshot Backups 某些文件系统可以实现快照，它们在给定时间点提供文件系统的逻辑副本，而不需要整个文件系统的物理副本。MySQL本身并未提供此功能，可通过Veritas, LVM或ZFS… 全量与增量备份Full Versus Incremental Backups 全量备份包括MySQL Server在给定时间点管理的所有数据；增量备份包括在给定时间点跨度内（从一个时间点到另一个时间点）对数据所做的更改。 全量与增量恢复Full Versus Point-in-Time (Incremental) Recovery 全量恢复可从完整备份恢复所有数据。这会将Server实例还原到备份时的状态。增量恢复是恢复在给定时间点跨度内所做的更改，这也称为时间点恢复。它基于二进制日志，通常在备份文件完全恢复之后，将备份文件还原到备份时的状态。然后，在二进制日志文件中写入的数据更改将作为增量恢复应用于重做数据修改，并使Server达到所需的时间点。 表维护Table Maintenance 如果表损坏，数据完整性可能会受到影响。 备份调度，压缩和加密Backup Scheduling, Compression, and Encryption 备份调度对于自动化备份过程很有价值；压缩备份输出可减少空间需求；输出加密可提供更好的安全性，防止未经授权访问备份数据。MySQL本身不提供这些功能，可使用第三方方案。 数据库备份方法Database Backup Methods 使用MySQL Enterprise进行热备 使用mysqldump进行备份Making Backups with mysqldump mysqldump程序可以进行备份，它可以备份各种表。 通过复制表文件进行备份Making Backups by Copying Table Files 对于使用自己的文件表示每个表的存储引擎，可通过复制这些文件来备份表。要获得一致性的备份，请停止服务器或锁定并刷新相关表： 1FLUSH TABLES tbl_list WITH READ LOCK; 你只需要一个读锁，这使得其它客户端可以在你复制数据库目录中的文件时继续查询表。需要刷新以确保在开始备份之前将所有活动索引页写入磁盘。只要Server没有更新，你也可以通过复制所有表文件来创建二进制备份。 通过分隔文本文件备份Making Delimited-Text File Backups 要创建包含表数据的分隔文本文件，可使用SELECT * INTO OUTFILE ‘filename’ FROM tablename语句进行创建。此方法适用于任何类型的数据文件，但仅保存表数据，而不保存表结构。 要载入分隔文本文件，请使用LOAD DATA INFILE或mysqlimport。 通过启用二进制日志进行增量备份Making Incremental Backups by Enabling the Binary Log MySQL支持增量备份，必须使用--log-bin选项启动Server以支持二进制日志记录。二进制日志文件为你提供了在执行备份之后副本数据库所需的信息。目前，你希望进行增量备份，你应该使用FLUSH LOGS轮换二进制日志。完成此操作后，你需要将所有二进制日志复制到备份位置，这些日志的范围从上次完全备份或增量备份到最后一个备份之一。 通过使用副本集Slaves进行备份Making Backups Using Replication Slaves 如果在进行备份时Master Server出现性能问题，可在Slave Server上进行复制和备份。 恢复损坏的表Recovering Corrupt Tables 如果必须还原已损坏的MyISAM表，请尝试首先使用REPAIR TABLE或myisamchk -r恢复它们。这应该在99.9％的情况下有效。 使用文件系统快照进行备份Making Backups Using a File System Snapshot VXFS文件系统操作步骤，其它文件系统类似： 客户端程序执行FLUSH TABLES WITH READ LOCK 从shell执行mount vxfs snapshot 解锁UNLOCK TABLES 从快照复制文件 umount快照 备份和恢复栗子Example Backup and Recovery Strategy 请注意磁盘问题，万一是磁盘不可用那就… 建立备份策略Establishing a Backup Policy 为了有用，必须定期进行备份。可使用多种工具在MySQL中完成全量备份。 12#备份之前锁表mysqldump --single-transaction --all-databases &gt; bacup.sql 全量备份是必要的，但创建它们并不总是方便。生成大型备份文件要话费大量时间和空间，它并非最佳。所以，进行初始化全量备份，然后进行增量备份更有效。增量备份更小，时间更短。 要进行增量备份，需要保存增量更改。在MySQL中，这些更改在二进制日志中表示，因此应始终使用--log-bin选项启动MySQL Server已启动二进制日志。启用它之后，Server会在更新数据时将每个数据更改写入文件。每次重启时，MySQL Server都会使用序列中的下一个数字创建创建一个新的二进制日志文件。在Server运行时，你还可以告诉它关闭当前的二进制日志文件并通过FLUSH LOGS语句或mysqladmin flush-logs命令手动开始新的二进制日志文件。mysqldump还有一个刷新日志的选项，数据目录中的.index文件包含目录中所有MySQL二进制日志的列表。 12345xxx-bin.000001xxx-bin.000002xxx-bin.000003xxx-bin.000004xxx-bin.index MySQL二进制日志对于恢复非常重要，因为它们构成了一组增量备份。如果确保在进行全量备份时刷新日志，则之后创建的二进制日志文件将包含自备份以来所做的所有数据的更改。 123mysqldump --single-transaction --flush-logs --master-data=2 \ --all-databases &gt; backup.sql#之后便会创建一个新的二进制日志文件 MySQL二进制日志占用磁盘空间，可不时删除它们。 1234mysqldump --single-transaction --flush-logs --master-data=2 \ --all-databases --delete-master-logs &gt; backup.sql#在副本集中，使用mysqldump --delete-master-logs删除MySQL二进制日志可能会很危险，因为可能Slave Server尚未处理完二进制日志的内容#可使用 PURGE BINARY LOGS语句删除 使用备份进行恢复Using Backups for Recovery 123456#全量恢复mysql &lt; backup.sql#增量恢复mysqlbinlog xxx-bin.000007 xxx-bin.000008 | mysql 备份策略摘要Backup Strategy Summary 不怕一万，就怕万一。InnoDB本身可以完成恢复数据的所有工作。但为了确保高枕无忧，请遵守以下准则： 始终使用--log-bin选项运行MySQL Server 使用mysqldump定期进行全量备份 使用FLUSH LOGS或mysqladmin flush-logs刷新日志来定期进行增量备份 mysqldump备份Using mysqldump for Backups 本节介绍如何使用mysqldump生产转储文件，以及如何重新加载转储文件。转储文件可通过多种方式使用： 作为备份，在数据丢失的情况下启用数据恢复 作为设置副本集的数据源 作为实验数据源 mysqldump处理两种类型的输出，具体取决于有无-tab选项： 没有--tab选项，mysqldump将SQL语句写入标准输出。输出包含用于创建转储对象(db, table, sotred routines)的CREATE语句，以及用于将数据加载到表中的INSERT语句。输出可保存到文件中。 带有--tab选项，mysqldump为每个转储的表生成两个输出文件。Server将一个文件写为制表符(tab)分隔的文本，每个表的行(row)为文本的一行，输出名为table_name.txt。Server还将创建表的CREATE TABLE语句发送到mysqldump，mysqldump将其写为输出目录中名为table_name.sql的文件。 使用mysqldump以SQL格式转储数据Dumping Data in SQL Format with mysqldump 12345678910111213mysqldump [args] &gt; file_name#all dbmysqldump --all-databases &gt; dbs.sql#specific dbmysql --databases test &gt; testDB.sqlmysqldump test &gt; testDB.sqlmysqldump --databases db1 db2 db3 &gt; db123.sqlmysqldump db1 db2 db3 &gt; db123.sql 关于有无--databases选项的区别： 转储输出不包含CREATE DATABASE或USE语句 重新加载转储文件时，必须指定默认数据库名称，以便Server知道要重新加载的数据库 对于重新加载，你可以指定与原始名称不同的数据库名，这使你可将数据重新加载到其它数据库中 如果要重载的数据库不存在，则必须先创建它 由于输出不包含CREATE DATABASE语句，因此--add-drop-database选项无效 只备份数据库表结构mysqldump使用-d(--no-data)选项，可以只备份数据库中表结构，而不备份数据。 栗子： 12345678910#-d(--no-data)#某个库中的所有表的结构mysqldump -h xxx --port 3306 -u xxx -p -d 数据库名 &gt; 数据库名.sql#之后再导入#某个表的结构mysqldump -h xxx -u xxx -p -d --databases=xxx --tables xxx &gt; 表.sql 重载SQL格式备份Reloading SQL-Format Backups 要重载由mysqldump备份的包含SQL语句的转储文件，使用mysql客户端输入。如果使用了--databases选项，则它包含了CREATE DATABASE和USE语句，就没有必要指定默认数据库。 12345678mysql &lt; dump.sql#或mysql&gt; source dump.sql#未使用--databases选项mysqladmin create db1mysql db1 &lt; dump.sql 使用mysqladmin以分隔文本格式转储数据Dumping Data in Delimited-Text Format with mysqldump 本节介绍如何使用mysqldump创建分隔文本转储文件。 123456789101112131415mysqldump --tab=/tmp db1#db1.txt#其它选项：--fields-terminated-by=str--fields-enclosed-by=char--fields-optionally-enclosed-by=char--fields-escaped-by=char--lines-terminated-by=str#栗子mysqldump --tab=/tmp --fields-terminated-by=, --fields-enclosed-by=&apos;&quot;&apos; --lines-terminated-by=0x0d0a db1 重载分隔文本格式的备份Reloading Delimited-Text Format Backups 123mysql db1 &lt; t1.sqlmysqlimport db1 t1.txt 12USE db1;LOAD DATA INFILE `t1.txt` INTO TABLE t1; mysqldump小技巧本节介绍使用mysqldump解决特定问题的技术： 如何复制数据库 如何将数据库从一个Server复制到另一个Server 如何转储存储的程序 如何单独转储定义和数据 复制数据库Making a Copy of a Database 123mysqldump db1 &gt; dump.sqlmysqladmin create db2mysql db2 &lt; dump.sql 将数据库从一个Server复制到另一个ServerCopy a Database from one Server to Another 123456789101112#Server1mysqldump --databases db1 &gt; dump.sql#Server2mysql &lt; dump.sql#无--databasesmysqldump db1 &gt; dump.sqlmysqladmin create db1mysql db1 &lt; dump.sql 转储存储的程序Dumping Stored Programs 几个选项控制mysqldump如何处理存储的程序： 12345678--events: Dump Event Scheduler events--routines: Dump stored procedures and functions--triggers: Dump triggers for tables--skip-events--skip-routines--skip-triggers. 转储表定义和Dumping Table Definitions and Content Separately 1234567#--no-data，不转储表数据，导致转储文件只包含用于创建表的语句#--no-create-info, 从输出中抑制CREATE语句，以便转储文件包含表数据mysqldump --no-data test &gt; dump-defs.sqlmysqldump --no-create-info test &gt; dump-data.sqlmysqldump --no-data --routines --events test &gt; dump-defs.sql 使用mysqldump测试升级不兼容性Using mysqldump to Test for Upgrade Incompatibilities 123456#oldmysqldump --all-databases --no-data --routines --events &gt; dump-defs.sql#newmysql &lt; dump-defs.sql 使用二进制日志进行增量恢复Point-in-Time (Incremental) Recovery Using the Binary Log 时间点恢复是指恢复自给定时间点以来所做的数据更改。通常，在还原全量备份之后执行此类恢复。 时间点恢复基于以下原则： 时间点恢复的信息源是由全量备份操作之后生成的二进制日志文件表示增量备份集，请开启--bin-log选项要从二进制日志还原数据，你必须知道二进制日志文件的名称和位置，默认情况下，它在数据目录中。 12345SHOW BINARY LOGS;--确定当前binary log file名称SHOW MASTER STATUS; mysqlbinlog实用程序将二进制日志文件中的事件从二进制格式转换为文本，以便可以执行或查看它们mysqlbinlog具有根据日志中事件时间或事件位置选择二进制日志部分的选项。 从二进制日志执行事件会导致重做它们所代表的数据修改，这样可以恢复给定时间段内的数据更改。 12#从二进制日志中执行事件mysqlbinlog binlog_files | mysql -u root -p 当需要确定事件时间或位置以在执行事件之前选择部分日志内容时，查看日志内容很有用 12345#查看binary logmysqlbinlog binlog_file | more#或mysqlbinlog binlog_file &gt; tmpfile 将输出保存在文件中非常有用，可以在删除某些事件时执行日志内容 1mysql -u root -p &lt; tmpfile 如果要在MySQL Server上执行多个二进制日志，安全的方法是使用与Server的单个连接来处理它们 1234567891011121314#unsafe#可能导致某些问题mysqlbinlog binlog.000001 | mysql -u root -p # DANGER!!mysqlbinlog binlog.000002 | mysql -u root -p # DANGER!!#safemysqlbinlog binlog.000001 binlog.000002 | mysql -u root -p#或mysqlbinlog --skip-gtids binlog.000001 &gt; /tmp/statements.sqlmysqlbinlog --skip-gtids binlog.000002 &gt;&gt; /tmp/statements.sqlmysql -u root -p -e "source /tmp/statements.sql" 使用事件时间进行时间点恢复Point-in-Time Recovery Using Event Times 要指示恢复的开始和结束时间，请以DATATIME格式指定mysqlbinlog的--start-datetime和--stop-datetime选项。请先查看binary log的时间区间。 1234567#恢复数据直到停止时间mysqlbinlog --stop-datetime="2005-04-20 9:59:59" \ /var/log/mysql/bin.123456 | mysql -u root -p#恢复数据从开始时间mysqlbinlog --start-datetime="2005-04-20 10:01:00" \ /var/log/mysql/bin.123456 | mysql -u root -p 使用事件位置进行时间点恢复Point-in-Time Recovery Using Event Positions mysqlbinlog的--start-position和--stop-position选项可用于指定日志位置，它的工作方式与指定时间类似。使用位置可以更准确地了解要恢复的日志部分，尤其是在许多事务与破坏性语句同时发生的情况下。要确定位置编号，请在执行不需要的事物的时间附近运行mysqlbinlog一段时间，但将结果重定向到文本文件以供检查: 123mysqlbinlog --start-datetime="2005-04-20 9:55:00" \ --stop-datetime="2005-04-20 10:05:00" \ /var/log/mysql/bin.123456 &gt; /tmp/mysql_restore.sql 位置编号以log_pos数字进行标记，查看并找到相应的位置标号，之后便可使用它们。 123456mysqlbinlog --stop-position=368312 /var/log/mysql/bin.123456 \ | mysql -u root -pmysqlbinlog --start-position=368315 /var/log/mysql/bin.123456 \ | mysql -u root -p MyISAM表维护和崩溃恢复MyISAM Table Maintenance and Crash Recovery 本节讨论了如何使用myisamchk检查或修复MyISAM表——具有用于存储数据和索引的.MYD和.MYI文件。你可以使用myisamchk来检查、修复、优化数据库表。 尽管使用myisamchk进行表修复十分安全，但在进行修复或任何可能对表进行大量更改的维护操作之前进行备份总是一个好主意。 影响索引的myisamchk操作可能导致使用与MySQL Server使用的值不兼容的全文参数重建MyISAM FULLTEXT索引。 MyISAM表也可以使用类似于myisamchk操作的SQL语句来完成： 检查MyISAM表，CHECK TABLE 修复MyISAM表，REPAIR TABLE 优化MyISAM表，OPTIMIZE TABLE 分析MyISAM表，ANALYZE TABLE 这些语句可以直接使用，也可通过mysqlcheck客户端程序使用。这些语句相对于myisamchk的一个优点是Server可以完成所有工作。使用myisamchk，你必须确保Server不会同时使用这些表，以便myisamchk和Server之间不会发生不需要的交互。 使用myisamchk进行崩溃恢复Using myisamchk for Crash Recovery 如果在禁用外部锁定(default)的情况下运行mysqld，则当mysqld使用同一个表时，你无法可靠地使用myisamchk来检查表。如果你可以确定在运行myisamchk时没有人会通过mysql访问表，你只需要在开始检查表之前执行mysqladmin flush-tables。如果你不能保证这一点，你必须在检查表时停止mysqld。如果你运行myisamchk来检查mysqld同时更新的表，你可能会收到一个警告，即使表没有也如此。 如果Server启用了外部锁定(external locking)，则可以随时使用myisamchk检查表。在这种情况下，如果Server尝试更新myisamchk正在使用的表，Server将等待myisamchk完成后再继续。 如果要使用myisamchk来修复或优化表，则必须始终确保mysqldServer未使用该表(或外部锁定)。如果没有停止mysqld，你应该在运行myisamchk之前至少做一个mysqladmin flush-tables。如果Server和myisamchk同时访问表，你的表可能会损坏。 执行崩溃恢复时，请务必了解数据库中每个MyISAM表table_name都对应于下面现实的数据库目录中的三个文件: 1234#数据文件和索引文件最常出问题tbl_name.frm Definition (format) filetbl_name.MYD Data filetbl_name.MYI Index file myisamchk的工作原理时逐行创建.MYD数据文件的副本。它通过删除旧的.MYD文件并将新文件重命名为原始文件名来结束修复阶段。如果使用--quick选项，myisamchk不会创建临时的.MYD文件，而是假定.MYD文件正确并且只生成新的索引文件而不触及.MYD文件。这是安全的，因为myisamchk会自动检查.MYD文件是否已损坏，如果存在则终止修复。 如何检查MyISAM表是否存在错误How to Check MyISAM Tables for Errors 使用以下命令检查MyISAM表： myisamchk tbl_name这能发现99.99%的错误，它找不到的是仅涉及数据文件的损坏。 myisamchk -m tbl_name这能发现99.999%的错误。它首先检查所有索引条目是否有错，然后读取所有行。它计算行中所有键值的校验和，并验证校验和是否与索引树种键的校验和匹配。 myisamchk -e tbl_name这可以对所有数据进行全面彻底的检查。 myisamchk -e -i tbl_name打印更多统计信息 如何修复MyISAM表How to Repair MyISAM Tables 你同样可使用CHECK TABLE和REPAIR TABLE语句来检查和修复MyISAM表。 损坏的表的症状： tbl_name.frm被锁定以防止修改 找不到文件tbl_name.MYI(Errorcode: nnn) 意外的文件结束 记录文件崩溃 从表处理获得error nnn 获取更多有关错误的信息： 1234567891011#perror nnnperror 126 127 132 134 135 136 141 144 145MySQL error code 126 = Index file is crashedMySQL error code 127 = Record-file is crashedMySQL error code 132 = Old database fileMySQL error code 134 = Record was already deleted (or record file crashed)MySQL error code 135 = No more room in record fileMySQL error code 136 = No more room in index fileMySQL error code 141 = Duplicate unique key or constraint on write or updateMySQL error code 144 = Table is crashed and last repair failedMySQL error code 145 = Table was marked as crashed and should be repaired 如果要从命令行修复表，则必须先停止mysqld Server。请注意，当你在远程Server执行mysqladmin shutdown时，mysqld Server在mysqladmin返回后仍然可用一段时间，直到所有语句处理并已停止并且所有索引更改都已刷新到磁盘。 步骤1： 检查表 123456myisamchk *.MYI#myisamchk -e *.MYI#如果mysqld已停止，使用--update-state告诉myisamchk将表标记为已检查myisamchk --update-state *.MYI 步骤2： 简易修复表 123456789#尝试修复索引，而不触及数据myisamchk -r -q table_name#数据1. 数据备份2. myisamchk -r table_name #这将删除不正确的行和以排除的行，并重构索引文件3. 如果上一步失败，请使用 myisamchk --safe-recover tbl_name4. 如果遇到意外错误，查看第3步 步骤3： 难以修复 1234567891011#只有当索引文件中的第一个16KB块被销毁或包含不正确的信息，或索引文件丢失时，才应该到达此阶段。#这种情况系，需要创建一个新的索引文件1. 将数据移动到安全的地方2. 创建空数据和新索引mysql db_namemysql&gt; SET autocommit=1;mysql&gt; TRUNCATE TABLE table_name;mysql&gt; QUIT3. 将旧的数据文件复制回新创建的数据文件4. 重新执行步骤2 步骤4： 很难修复 1234#仅当.frm描述文件也崩溃时才应该到达此阶段#这应该永远不会发生，因为创建表后描述文件不会发生更改1. 从备份还原描述文件并回到步骤32. 如果没有备份，但确切知道如何创建表，请在另一个数据库中创建该表的副本。删除新数据文件，然后将.frm和.MYI移动到崩溃的数据库。返回步骤2尝试重建索引文件 优化MyISAM表MyISAM Table Optimization 要合并碎片行并消除因删除或更新行而导致的浪费空间，请在恢复模式下运行myisamchk: myisamchk -r table_name 你也可以通过OPTIMIZE TABLE的SQL语句进行表优化。此语句执行表修复和Key 分析，并对索引数进行排序，以便Key查找更快。 myisamchk有许多其它选项可用于提高表的性能： --analyze or -a执行Key分析。这可通过使连接优化器更好地选择连接表的顺序自己应该使用的索引来提高连接性能。 --sort-index or -S排序索引块。这可优化搜索并使表扫描更快地使用索引。 --sort-records=index_num or -R index_num根据给定索引对数据行进行排序。这可使数据更加本地化，并可以加速使用此索引的基于范围的SELECT和ORDER BY操作 配置MyISAM表维护计划Setting Up a MyISAM Table Maintenance Schedule 最好定期执行检查表，而不是等着问题发生。启用自动检查MyISAM表也是一个好主意。还应该在正常系统操作期间定期检查你的表。 1234#栗子35 0 * * 0 /path/to/myisamchk --fast --silent /path/to/datadir/*/*.MYImyisamchk -r -s --sort-index --myisam_sort_buffer_size=16M */*.MYI 优化Optimization 本章介绍如何优化MySQL性能并提供示例。优化涉及多个级别配置，调整和测量性能。根据你的工作角色(Developer、DBA、both)，你可在单个SQL语句、整个应用程序、单个数据库Server、多个网络数据库Server的级别进行优化。有时你可以主动并提前计划性能，而有时可能会在出现问题后解决配置或代码问题。优化CPU和内存使用还可以提供伸缩性，允许数据库处理更多负载而不会降低速度。 优化概述Optimization Overview 数据库性能取决于数据库级别的几个因素，如表、查询、配置设置。这些软件结构导致硬件级别的CPU和I/O操作，你必须尽可能降低这些操作并使其尽可能高效。在处理数据库性能时，首先要了解软件方面的高级规则和指南，并使用挂钟时间(wall-clock time)来衡量性能。当你成为专家后，你将了解更多内部发生的信息，并开始测量CPU周期和I/O操作… 典型用户的目标是从现有的软件和硬件配置中获取最佳的数据库性能；高级用户寻找改进MySQL软件本身的机会，或者开发自己的存储引擎或硬件设备来扩展MySQL生态系统。 数据库级别的优化Optimizing at the Database Level 使数据库应用程序快速运行的最重要的因素是其基本设计： 表结构是否合适？特别是，列(columns)是否具有正确的数据类型，并且每个表是否具有适合工作类型的列？例如，更新频繁的应用程序通常具有少量列的许多表；而分析大量数据的应用程序通常具有大量列的少量表。 是否有适当的索引来提高查询效率？ 是否为每个表使用了适当的存储引擎，并利用使用的每个存储引擎的优势和功能？特别是，诸如InnoDB之类的事务性(transactional)存储引擎或诸如MyISAM之列的非事务性(nontransactional)存储引擎的选择，对于性能和伸缩性非常重要。InnoDB是新表的默认存储引擎。实际上，先进的InnoDB性能特征意味着InnoDB表通常优于更简单的MyISAM表，尤其是对于繁忙的数据库。 是否每个表都使用了适当的行格式？这取决于表所使用的数据库。特别是，压缩的表使用较少的磁盘空间，因此需要较少的磁盘I/O来读取和写入数据。压缩适用于InnoDB表的各种工作负载，以及只读(read-only)MyISAM表。 是否应用程序使用了适当的锁定策略？例如，通过允许共享访问，以便数据库操作可以并发运行，并在适当时请求独占访问，以便关键操作成为首要任务。同样，存储引擎的选择也很重要。InnoDB存储引擎可以处理大多数锁定问题而无需你的参与，从而在数据库中实现更好的并发性，并减少代码的实验和调优。 是否正确使用了用于缓存的所有内存区域？也就是说，足够大以容纳频繁访问的数据，但不能太大以至于它们会超载物理内存并导致分页。要配置的主缓存区域是：InnoDb缓冲池，MyISAM key缓存、MySQL查询缓存。 硬件级别的优化Optimizing at the Hardware Level 随着数据库变得越来越繁忙，任何数据库应用程序最终都会达到硬件限制。DBA必须评估是否可以调整应用程序或重新配置Server以避免这些瓶颈(bottlenecks)，或者是否需要更多硬件资源？ 系统瓶颈通常来自于这些来源： 磁盘需求磁盘需要一段时间才能找到一段数据。对于现代磁盘，平均时间通常低于10ms。优化搜索时间的方法是将数据分发到多个磁盘上。 磁盘读写当磁盘位于正确位置时，我们需要读写数据。可以从多个磁盘并行读取。 CPU周期当数据在主存储器中时，我们必须处理它们以获得我们想要的结果。 内存带宽当CPU需要的数据量超过了CPU缓存容量时，主存带宽就成了瓶颈。 平衡移植性和性能Balancing Portability and Performance 要在可移植的MySQL程序中使用面向性能的SQL扩展，你可在语句中包含MySQL特定关键字/* ... */评论分隔符(或--注释) 优化SQL语句Optimizing SQL Statements 数据库应用程序的核心逻辑是通过SQL语句执行的，无论是直接通过解释器还是通过API在幕后提交。 优化SELECT语句Optimizing SELECT Statements 查询以SELECT语句的形式执行数据库中的所有查找操作。调整这些语句的首要任务就是缩短响应时间。除了SELECT语句外，查询的调优技术也适用于DELETE语句中的CREATE TABLE ... AS SELECT, INSERT INTO ... SELECT和WHERE等构造子句。这些语句具有额外的性能考虑因素，因为它们将写操作与面向读操作的查询相结合。 优化查询的主要考虑因素有： 要使一个慢的SELECT ... WHERE查询更快，首先要检查是否可以添加索引。在WHERE字句中使用的列上设置索引，以加快评估、过滤和结果的最终检索。为避免浪费磁盘空间，请构建一小组索引，以加速应用程序中使用的许多相关查询。索引对于引用不同表的查询尤其重要，使用连接(joins)和外键(foreign keys)等功能。 隔离并调整查询的任何部分，例如函数调用，这会占用过多时间。根据查询的结构，可以为结果集中的每一行调用一次函数，甚至可以为表中的每一行调用一次函数，从而大大减轻任何低效率。 最大限度地减少查询中的全表扫描次数，尤其是对于大型表。 定期使用ANALYZE TABLE语句使表统计信息保持最新，因此优化程序具有构建有效执行计划所需的信息。 了解特定于每个表的存储引擎的调优技术，索引技术和配置参数。InnoDB和MyISAM都有一套指导方针，可以在查询中实现和维持高性能。 你可以优化InnoDB表的单查询事务。 避免以难以理解的方式转换查询。 如果其中一个基本准则无法轻松解决性能问题，请通过阅读EXPLAIN计划并调整索引、WHERE子句、JOIN子句等来调查特定查询的内部详细信息。 调整MySQL用于缓存区域的大小和属性。通过有效使用InnoDB buffer pool、MyISAM key cache、MySQL query cache，重复查询运行的更快，因为在第二次及以后的时间内都是从内存中检索结果 即使对于使用高速缓存存储区快速运行的查询，你仍可以进一步优化，以便它们需要更少的高速缓存，从而使你的应用程序更具可伸缩性。可伸缩性意味着你的应用程序可以处理更多的并发用户，更大的请求…，而不会出现性能大幅下降的情况 处理锁定问题，其中查询的速度可能会受到同时访问表的其它回话的影响 WHERE子句优化WHERE Clause Optimization 你可能想要重写查询以更快地进行过算数运算，同时牺牲可读性。因为MySQL会自动执行类似的优化，所以通常可以避免这种工作，并使查询保持更容易理解和可维护的形式。 移除不必要的括号 12((a AND b) AND c OR (((a AND b) AND (c AND d))))--&gt; (a AND b AND c) OR (a AND b AND c AND d) 恒量折叠 12(a&lt;b AND b=c) AND a=5--&gt; b&gt;5 AND b=c AND a=5 恒量条件去除 12(B&gt;=5 AND B=5) OR (B=6 AND 5=5) OR (B=7 AND 5=6)--&gt; B=5 OR B=6 索引使用的常量表达式仅计算一次 早期检测无效常量表达式 如果不使用GROUP BY或聚合函数(COUNT(), MIN()...)，HAVING将与WHERE合并 对于连接中的每个表，构造一个更简单的WHERE以获得对表的快速平均，并且还尽快跳过行 在查询中的任何其它表之前，首先读取所有常量表： 一个空表或只有一行的表 与主键或唯一索引上的WHERE子句一起使用的表，其中所有索引部分都与常量表达式进行比较并定义为NOT NULL 以下所有表都用作常量表： 123SELECT * FROM t WHERE primary_key=1;SELECT * FROM t1,t2 WHERE t1.primary_key=1 AND t2.primary_key=t1.id; 通过尝试所有可能性，可以找到加入表格的最佳连接组合。如果ORFER BY和GROUP BY子句中的所有列都来自同一个表，则在加入时首先选择该表 如果存在ORDER BY子句和不同的GROUP BY子句，或者ORDER BY或GROUP BY包含连接队列中第一个表以外的表中的列，则会创建临时表 如果使用SQL_SMALL_RESULT修饰符，MySQL将使用内存中的临时表 查询每个表索引，并使用最佳索引，除非优化程序认为使用表扫描更有效。 在某些情况下，MySQL甚至无需查阅数据文件即可从索引中读取行。 在输出每一行之前，将跳过与HAVING子句不匹配的行。 一些非常快的查询示例： 123456789101112SELECT COUNT(*) FROM tbl_name;SELECT MIN(key_part1),MAX(key_part1) FROM tbl_name;SELECT MAX(key_part2) FROM tbl_name WHERE key_part1=constant;SELECT ... FROM tbl_name ORDER BY key_part1,key_part2,... LIMIT 10;SELECT ... FROM tbl_name ORDER BY key_part1 DESC, key_part2 DESC, ... LIMIT 10; MySQL使用索引数解析一下查询，假设索引列是数字： 123456SELECT key_part1,key_part2 FROM tbl_name WHERE key_part1=val;SELECT COUNT(*) FROM tbl_name WHERE key_part1=val1 AND key_part2=val2;SELECT key_part2 FROM tbl_name GROUP BY key_part1; 以下查询使用索引来按排序顺序检索行，而不使用单独的排序传递： 12345SELECT ... FROM tbl_name ORDER BY key_part1,key_part2,... ;SELECT ... FROM tbl_name ORDER BY key_part1 DESC, key_part2 DESC, ... ; 范围优化Range Optimization range访问方法使用单个索引来检索包含在一个或多个索引值间隔内的表行的子集。他可用于单部分(single-part)或多部分(multiple-part)索引。 单部分索引的范围访问方法Range Access Method for Single-Part Indexes 对于单部分索引，索引值间隔可以方便地由WHERE子句中相应条件表示，表示为范围条件而不是间隔。 单部分索引的范围索引条件的定义如下： 对于BTREE和HASH索引，使用=, &lt;=&gt;, IN(), IS NULL, IS NOT NULL运算符时，关键部分与常量值的比较是范围条件 另外，对于BTREE索引，关键部分与常量值的比较是使用&gt;, &lt;, &gt;=, &lt;= between, !=, &lt;&gt;运算符时的范围条件，或者LIKE比较时的LIKE比较是一个不以通配符开头的常量字符串 对于所有索引类型，多个范围条件与OR或AND组合形成范围条件 常量值表示一下之一： 来自查询字符串中的常量 来自同一连接(join)的const或system表的列 不相关子查询的结果 由前面类型的子表达式组成的任何表达式 WHERE子句中带有范围条件的查询的栗子： 1234567891011SELECT * FROM t1 WHERE key_col &gt; 1 AND key_col &lt; 10;SELECT * FROM t1 WHERE key_col = 1 OR key_col IN (15,18,20);SELECT * FROM t1 WHERE key_col LIKE 'ab%' OR key_col BETWEEN 'bar' AND 'foo'; MySQL尝试从每个可能索引的WHERE子句中提取范围条件。在提取过程期间，丢弃不能用于构建范围条件的条件，组合产生重叠范围的条件，并且去除产生空范围的条件。 通常，用于范围扫描的条件比WHERE子句的限制性更小。MySQL执行额外的检查以过滤掉满足范围条件但不满足完整WHERE子句的行。MySQL不支持合并空间索引的范围方法的多个范围。要解决此限制，可以使用具有相同SELECT语句的UNION，但将每个空间谓词放在不同的SELECT中。 多部分索引的范围访问方法Range Access Method for Multiple-Part Indexes 多部分索引的范围条件是单部分索引范围条件的扩展。多部分索引上的范围条件将索引行限制在一个或多个关键元组上定义关键元组间隔。 例如，考虑定义为key1(key_part1, key_part2, key_part3)的多部分索引： 12345678key_part1 key_part2 key_part3 NULL 1 &apos;abc&apos; NULL 1 &apos;xyz&apos; NULL 2 &apos;foo&apos; 1 1 &apos;abc&apos; 1 1 &apos;xyz&apos; 1 2 &apos;abc&apos; 2 1 &apos;aaa&apos; 条件key_part1 = 1定义此间隔：(1,-inf,-inf) &lt;= (key_part1,key_part2,key_part3) &lt; (1,+inf,+inf)此间隔覆盖前面数据集中的第4、第5、第6个元组，并且可以由范围访问方法使用。相反，条件key_part3 = &#39;abc&#39;不定义单个间隔，并且不能由方位访问方法使用。 以下描述详细地说明了范围条件如何适用于多部分索引： 对于HASH索引，可使用包含相同值的每个间隔。 1234567891011--const1, const2, ...都是常量---cmp指的是=, &lt;=&gt;, IS NULL比较运算符--条件涵盖所有索引部分 key_part1 cmp const1AND key_part2 cmp const2AND ...AND key_partN cmp constN;--栗子key_part1 = 1 AND key_part2 IS NULL AND key_part3 = 'foo' 对于BTREE索引，间隔可用于AND组合的条件，其中每个条件使用=, &lt;=&gt;, IS NULL, &gt;, &lt;, &gt;=, &lt;=, !=, &lt;&gt;, BETWEEN, LIKE &#39;pattern&#39;来比较关键部分和常量值。只要可以确定包含于条件匹配的所有行的单个key元组，就可以使用间隔。 如果覆盖区间中包含的行集的条件与OR组合，则它们形成一个条件，该条件覆盖其间隔的并集中包含的一组行。如果条件与AND组合，则它们形成一个条件，该条件覆盖其间隔交集中包含的一组行。 多值比较的等价范围优化Equality Range Optimization of Many-Valued Comparisons 行构造函数表达式的范围优化Range Optimization of Row Constructor Expressions 对范围优化限制内存使用Limiting Memory Use for Range Optimization 要控制范围优化程序可用的内存，请使用range_optimizer_max_mem_size系统变量： 0意味着不限制 大于零时，优化程序会在考虑范围访问方法时跟踪消耗的内存。如果要超过指定的限制，则放弃范围访问方法，并考虑其它方法。 对于UPDATE和DELETE语句，如果优化程序回退到完整表扫描并启用了sql_safe_updates系统变量，则会发生错误而不会警告，因为实际上没有使用任何key来确定要修改的行。 对于超出不可用范围优化内存并且优化程序回退到不太理想的计划的单个查询，增加range_optimizer_max_mem_size值可以提高性能。 优化和索引Optimization and Indexes 提高SELECT操作性能的最佳方法是在查询中测试的一个或多个列上创建索引。索引条目的作用类似于表行的指针，允许查询快速确定哪些行与WHERE字句中的条件匹配，并检索这些行的其它列值。所有MySQL数据类型都可被索引。 尽管为查询中每个可能使用的列创建索引很有诱惑力，但不必要的索引会浪费空间并浪费时间让MySQL确定要使用的索引。索引还会增加insert, update, delete的成本，因为必须更新每个索引。你必须找到适当的平衡，以使用最佳索引集实现快速查询。 MySQL如何使用索引How MySQL Uses Indexes 索引用于快速查找具有特定列值(column value)的行(row)。如果没有索引，MySQL必须从第一行开始，然后读取整个表以查找相关行。表越大，成本越高。如果表中有相关列的索引，MySQL可以快速确定要在数据文件中间寻找的位置，而无需查看所有数据。这比按顺序读取每一行要快得多。 大多数MySQL索引(PRIMARY KEY, UNIQUE, INDEX, FULLTEXT)都存储在B树(B-trees)中。有几个例外： 空间数据类型的索引使用R树(R-trees) MEMORY表同样支持hash索引 InnoDB对FULLTEXT使用反转列表(inverted lists) MySQL使用索引进行这些操作： 快速查找与WHERE子句匹配的行 出于消除行的考虑。如果在多个索引之间有选择，MySQL通常使用找到最小行数的索引 如果表具有多列索引，则优化程序可以使用索引的任何左前缀来查找行 在执行join时从其它表中检索行。如果声明它们的类型和大小相同，MySQL可以更有效地使用列上的索引。如VARCHAR(10)和CHAR(10)的大小相同。 对于非二进制字符串之间的比较，两列应使用相同的字符集。 查找特定索引列key_col的MIN()和MAX()值，这是由预处理器优化的，它检查是否在索引中key_col之前出现的所有关键部分上使用WHERE key_part_N = 常量。在这种情况下，MySQL对每个MIN()或MAX()表达式执行单个键查找，并用常量替换它。如果所有表达式都替换为常量，则查询立即返回。 12SELECT MIN(key_part2),MAX(key_part2) FROM tbl_name WHERE key_part1=10; 如果对可用索引的最左前缀进行排序或分组，则对表进行排序或分组。 在某些情况下，可以优化查询以在不咨询数据行的情况下检索值。 对于小型表的查询，或大型表所有行的查询，索引不太重要。当查询要访问大多数行时，顺序读取比通过索引更快。顺序读取可以最大限度地减少磁盘搜索，即使查询不需要所有行也是如此。 主键优化Primary Key Optimization 表的主键(primary key)表示你在最重要的查询中使用的列或列的集合。它具有关联的索引，以实现快速查询优化。查询性能受益于NOT NULL，因为它不能包含任何NULL值。使用InnoDB存储引擎，表格数据在物理化上进行组织，以根据主键或列进行超快速查找和排序。 如果你的表又大又重要，但没有明显的列或列的集合作为主键，则可创建一个单独的列，其中包含自动增量值以用作主键。当你使用外键(foreign key)联接(join)表时，这些唯一ID可用于指向其它表中相应行的指针。 外键优化Foreign Key Optimization 如果一个表有很多列，并且你查询了许多不同的列组合，那么将频率较低的数据拆分为每个都有几列的单独表可能会很有效，并通过从主表中复制数字ID列将它们与主表相关联。这样，每个小表都可以有一个主键来快速查找器数据，并且你可以使用连接操作仅查询所需的列集。根据数据的分布方式，查询可能会执行较少的I/O并占用较少的高速缓存，因为相关列在磁盘上打包在一起。为了最大限度地提高性能，查询尝试从磁盘中读取尽可能少的数据块；只有几列的表可以在每个数据块中容纳更多行。 列索引Column Indexes 最常见的索引类型涉及单个列，在数据结构中存储该列的值的副本，允许快速查找具有相应列值的行。B树(B-tree)数据结构允许索引在WHERE子句中快速查找特定值，一组值或一系列值。 索引前缀(Index Prefixes)使用字符串列的索引规范中的col_name(N)语法，可以创建使用列的前N个字符的索引。以这种方式仅索引列值的前缀，可以使索引文件更小。当索引BLOB或TEXT列，必须为索引指定前缀长度。前缀最长可达1000 Byte，InnoDB表为767Byte(除非你设置了innodb_larger_prefix) 1CREATE TABLE test (blob_col BLOB, INDEX(blob_col(10))) 全文索引(FULLTEXT Indexes)全文索引用于全文搜索。只有InnoDB和MyISAM存储引擎支持FULLTEXT索引，并且仅支持CHAR, VARCHAR, TEXT列。索引始终发生在整个列上，并且不支持前缀索引。 空间索引(Spatial Indexes)你可以在空间数据类型上创建索引。MyISAM和InnoDB支持空间类型的R树(R-trees)索引。其它存储引擎使用B树来索引空间类型。 MEMORY存储引擎中的索引MEMORY存储引擎默认使用HASH索引，但也支持B树索引。 多列索引Multiple-Column Indexes MySQL可以创建复合索引(composite indexes)——即多列上的索引，索引最多包含16列。对于某些数据类型，你可以索引列的前缀。 MySQL可以对测试索引中的所有列的查询使用多列索引，或者只测试第一列，前几列等的查询。如果在索引定义中以正确的顺序指定列，则单个复合索引可以加速同一表上的多种查询。多列索引可被视为排序数组，其行包含通过连接索引列的值创建的值。 假设某表如下： 1234567891011121314151617181920212223242526272829303132333435CREATE TABLE test ( id INT NOT NULL, last_name CHAR(30) NOT NULL, first_name CHAR(30) NOT NULL, PRIMARY KEY (id), INDEX name (last_name,first_name));/*name索引是一个包含两列的索引，它可用于查询中的查询。可组合last_name和first_name的值进行查询，还可仅指定该索引的最左前缀last_name的值进行查询*/--因此，name索引可用于以下查询SELECT * FROM test WHERE last_name='Widenius';SELECT * FROM test WHERE last_name='Widenius' AND first_name='Michael';SELECT * FROM test WHERE last_name='Widenius' AND (first_name='Michael' OR first_name='Monty');SELECT * FROM test WHERE last_name='Widenius' AND first_name &gt;='M' AND first_name &lt; 'N';--然而，name索引无法用于以下查找SELECT * FROM test WHERE first_name='Michael';SELECT * FROM test WHERE last_name='Widenius' OR first_name='Michael'; 验证索引使用Verifying Index Usage 始终检查所有查询是否确实使用你在表中创建的索引，使用EXPLAIN语句。 InnoDB和MyISAM索引统计InnoDB and MyISAM Index Statistics Collection 存储引擎收集有关表的统计信息，供优化器使用。表统计信息基于值组(value group)，其中值组是具有相同键(key)前缀值的一组行。优化器的目的，一个重要统计信息是值组大小的平均值。 MySQL使用值组大小的平均值的方式如下： 估计每个ref访问必须读取多少行 估计一个部分联接将产生多少行，即此表单的操作将产生的行数： (...) JOIN tbl_name ON tbl_name.key = expr B树和Hash索引的比较Comparison of B-Tree and Hash Indexes 了解 B树(B-Tree)和哈希(Hash)数据结构有助于预测不同查询在索引中使用这些数据结构的不同存储引擎上的执行情况，特别是MEMORY存储引擎。 B树索引B-Tree Index Characteristics B树索引可用于 =, &lt;, &gt;, &lt;=, &gt;=, BETWEEN运算符的表达式中的列比较。如果LIKE的参数是不以通配符开头的常量字符串，则它也可用于LIKE比较。 1234567891011121314151617181920212223242526272829303132# SELECT使用索引的栗子SELECT * FROM tbl_name WHERE key_col LIKE 'Patrick%';SELECT * FROM tbl_name WHERE key_col LIKE 'Pat%_ck%';# SELECT没有使用索引SELECT * FROM tbl_name WHERE key_col LIKE '%Patrick%';SELECT * FROM tbl_name WHERE key_col LIKE other_col;# WHERE使用索引... WHERE index_part1=1 AND index_part2=2 AND other_column=3 /* index = 1 OR index = 2 */... WHERE index=1 OR A=10 AND index=2 /* optimized like "index_part1='hello'" */... WHERE index_part1='hello' AND index_part3=5 /* Can use index on index1 but not on index2 or index3 */... WHERE index1=1 AND index2=2 OR index1=3 AND index3=3;# WHERE没有使用索引 /* index_part1 is not used */... WHERE index_part2=1 AND index_part3=2 /* Index is not used in both parts of the WHERE clause */... WHERE index=1 OR A=10 /* No index spans all rows */... WHERE index_part1=1 OR index_part2=10 有时MySQL不使用索引，及时有索引也是如此。发生这种情况的一种情况是，优化器估计使用索引将需要MySQL访问表中非常大比例的行。但是，如果此类查询使用LIMIT仅检索某些行，则MySQL仍会使用索引，因为它可以更快地找到要在结果中返回的几行。 哈希索引Hash Index Characteristics 哈希索引与B树索引的特征有些不同: 仅使用=,&lt;=&gt;运算符来比较(速度飞快)，不使用比较符找到一系列值。依赖于这种类型的单值查找的系统被称为键值存储。要将MySQL应用于此类应用程序，请尽可能使用哈希索引 优化器无法使用哈希索引来加速ORDER BY MySQL无法确定两个值之间大约有多少行。如果将MyISAM或InnoDB表更改为哈希索引的MEMORY表，则可能会影响某些查询 只有整个键可用于搜索行 索引扩展Use of Index Extensions InnoDB通过将主键列附加到它来自动扩展每个二级索引。考虑如下表定义: 1234567CREATE TABLE t1 ( i1 INT NOT NULL DEFAULT 0, i2 INT NOT NULL DEFAULT 0, d DATE DEFAULT NULL, PRIMARY KEY (i1, i2), INDEX k_d (d)) ENGINE = InnoDB; 此表定义了i1, i2两个主键。它还在列(d)上定义了二级索引k_d, 但内部InnoDB扩展了该索引并将其视为列(d, i1, i2)。 在确定如何以及是否使用该索引时，优化程序会考虑扩展二级索引的主键列。这可以带来更高效的查询执行计划和更好的性能。 优化器使用生成的列索引Optimizer Use of Generated Column Indexes MySQL支持生成列的索引: 1CREATE TABLE t1 (f1 INT, gc INT AS (f1 + 1) STORED, INDEX (gc)); 生成的列gc定义为表达式f1 + 1.该列也被索引，优化器可以在执行计划构建期间考虑该索引。 优化数据库结构Optimizing Database Structure 作为数据库设计者的角色中，寻找组织 schemas, tables, columns最有效的方法。在调整应用程序代码时，您可以最小化I/O，将相关项目保持在一起，并提前计划，以便在数据量增加时性能保持较高。从高效的数据库设计开始，团队成员可以更轻松地编写高性能的应用程序代码，并使数据库可以随着应用程序的发展和重写而持久。 优化数据大小Optimizing Data Size 设计表以最小化磁盘空间。这可以通过 减少磁盘写入和读取的数据量 来实现巨大的改进。当在查询执行期间被主动处理时，较小的表通常需要较少的内存。表数据的任何空间缩减也会导致较小的索引可以更快地处理。 MySQL支持许多不同的存储引擎(表类型)和行格式。对于每个表，你可以决定使用哪种存储和索引方法。为你的应用程序选择合适的表格式可以为你带来巨大的性能提升。 通过使用此处列出的技术，你可以获得更好的表性能并最大限度地减少存储空间: Table Columns Row Format Indexes Joins Normalization 列 尽可能使用最有效(最小)的数据类型。MySQL有许多专门的类型可以节省磁盘空间和内存。例如，如有可能，请使用较小的整数类型(integer types)来获取较小的表。MEDIUMINT 通常是比 INT 更好的选择，因为 MEDIUMINT 列使用的空间减少了 25%。 如果可能，将列声明为NOT NULL。它通过更好地使用索引并消除测试每个值是否为 NULL 的开销，使SQL操作更快。你同样节省了一些存储空间，每列1bit。如果你确实需要表中的 NULL 值，请使用它们。只需避免在每列中允许 NULL 值得默认设置。 行格式 默认情况下，使用 DYNAMIC 行格式创建 InnoDB 表。要使用 DYNAMIC 以外的行格式，请配置 innodb_default_row_format， 或在 CREATE TABLE 或 ALTER TABLE 语句中显示指定 ROW_FORMAT 选项。 要通过以压缩格式存储表数据来进一步减少空间，请在创建 InnoDB 表时指定 ROW_FORMAT=COMPRESSED，或在现有 MyISAM 表上运行 myisampack 命令。 对于 MyISAM 表，如果没有任何可变长度列(VARCHAR, TEXT, BLOB列)，则使用固定大小的行格式。这更快，等可能浪费一些空间。 索引 表的主索引应该尽可能短。这使得每行的识别变得简单有效。对于 InnoDB 表，主键列在每个辅助索引条目中都是重复的，因此如果你有许多辅助索引，则短主键可以节省大量空间。 仅创建你需要提高查询性能的索引。索引适用于检索，但会降低插入和更新操作的速度。如果你主要通过搜索列的组合来访问表，请在它们上创建单个复合索引，而不是为每列创建单独的索引。索引的第一部分应该是最常用的列。如果从表中选择时总是使用多列，则索引中的第一列应该是具有最多重复的列，以获得更好地索引压缩。 如果长字符串列很可能在第一个字符数上有唯一的前缀，那么最好只索引此前缀，使用MySQL支持在列的最左边部分创建索引。较短的索引更快，不仅因为它们需要更少的磁盘空间，而且因为它们还会在索引缓存中为你提供更多命中，从而减少磁盘搜索次数。 联结 在某些情况下，分成两个经常扫描的表可能是有益的。如果它是动态格式的表，则尤其如此，并且可以使用较小的静态格式表，该表可用于在扫描表时查找相关行 在具有相同数据类型的不同表中声明具有相同信息的列，以基于相应列加速连接。 保持列名简单，以便你可以在不同的表中使用相同的名称并简化联结查询。例如，在名为 customer 的表中，使用名称 name 而不是 customer_name。要使你的名称可以知道其它SQL服务器，请考虑将它们保持为小于18个字符。 规范化 通常，尽量保持所有数据不冗余重复(这不是指的高可用的冗余，而是不要重复存储数据)。为了取代重复的名称、地址和长值，为它们分配唯一的ID，在多个较小的表中根据需要重复这些ID，并通过 join 子句中的 ID 来联接查询中的表。 如果速度比磁盘空间更重要，并且保留多个数据副本的维护成本，你可以放宽规范化规则，复制信息或创建汇总表以获得更快的速度。 优化数据类型Optimizing MySQL Data Types 优化数字数据Optimizing for Numeric Data 对于唯一ID或可以表示为字符串或数字的其它值，首选数字列(prefer numeric columns to string columns)。由于较大的数值可以存储在比相应于字符串更少的字节中，因此传输和比较的速度更快，占用的内存更小。 如果你使用数字数据，在许多情况下从数据库访问信息比访问文本文件更快。数据库中的信息可能以比文本文件更紧凑的格式存储，因此访问它涉及更少的磁盘访问。您还可以在应用程序中保存代码，因为您可以避免解析文本文件以查找行和列边界。 优化字符和字符串类型Optimizing for Character and String Types 对于 character and string columns，请遵循一下准则: 当您不需要特定于语言的整理(collation)规则功能时，请使用二进制排序顺序进行快速比较和排序操作。你可以使用 BINARY 运算符在特定查询中使用二进制整理规则。 比较不同列的值时，请尽可能声明具有相同字符集和整理规则的列，以避免在运行查询时进行字符串转换。 对于小于8KB的列值，请使用二进制 VARCHAR 而不是 BLOB。GROUP BY 和 ORDER BY 子句可以生成临时表，如果原始表不包含任何 BLOB 列，这些临时表可以使用 MEMORY 存储引擎。 如果表中包含的字符串列(如名字和地址)，但许多查询不检索这些列，请考虑将字符串拆分为单独的表，并在必要时使用带有外键的连接查询。当MySQL从一行中检索任何值时，它会都包含改行的所有列的数据块。仅使用最常用的列保持每行较小，允许更多行适合每个数据块。这种紧凑的表减少了常见查询的磁盘I/O和内存使用。 当你使用随机生成的值作为 InnoDB 表中的主键时，请在其前面加上一个升序(asce)值，如当前的日期和时间。当连续的主值物理存储在彼此附近是，InnoDB可以更快地插入和检索它们。 优化BLOB类型Optimizing for BLOB Types 存储包含文本数据的大型 BLOB 时，请考虑先压缩它。当压缩整个表时，请勿使用此技术。 对于具有多个列的表，要减少不使用的 BLOB 列的查询的内存要求，请考虑将 BLOB 列拆分为单独的表，并在需要时使用连接查询它。 由于检索和显示 BLOB 值得性能要求可能与其它数据类型有很大不同，因此你可以将 特定的BLOB表放在不同的存储设备上，甚至是单独的数据库实例上。 可以讲列值的哈希值存储在单独的列中，索引该列，并在查询中测试哈希值，而不是针对非常长的文本字符串测试相等性。 优化表Optimizing for Many Tables 用于快速保持个别查询的一些技术设计在多个表之间拆分数据。当表的数量达到上万，甚至是上百万时，处理所有这些表的开销成为新的性能考虑问题。 如何打开和关闭表How MySQL Opens and Closes Tables 当你执行mysqladmin status命令时，你应该看到如下内容: 123Uptime: 426 Running threads: 1 Questions: 11082Reloads: 1 Open tables: 12# 如果你的表少于12个，则这个值会有些令人费解 MySQL是多线程，因此可能有许多C端同时为给定的表发出查询。为了最大限度地减少同一个表上具有不同状态的多个C端回话的问题，该表由每个并发回话独立打开。对于MyISAM表，每个打开表的C端数据文件都需要一个额外的文件描述符。 table_open_cache和max_connections系统变量会影响Server保持打开的最大文件数。如果增加这些值中的一个或两个，则可能会遇到操作系统对每个进程的打开文件描述符数量施加的限制。许多操作系统允许你增加打开文件限制，该方法因系统而异。table_open_cache与max_connections有关。例如，对于200个并发运行的连接，请指定表缓存大小至少为200 * N，其中N是执行的任何查询中每个连接的最大表数。你还必须为临时表和文件保留一些额外的文件描述符。请确保操作系统可以处理table_open_cache设置隐含的打开文件描述符的数量。如果table_open_cache设置的太高，MySQL可能会用完文件描述符(file descriptors)并出现拒绝连接或无法执行查询等症状。 还有考虑到MyISAM存储引擎需要为每个唯一打开的表提供两个文件描述符。对于分区的MyISAM表，打开的表的每个分区都需要两个文件描述符。 （当MyISAM打开分区表时，它会打开此表的每个分区，无论是否实际使用给定分区。要增加MySQL可用的文件描述符，请设置open_files_limit系统变量。 打开表的缓存保持在table_open_cache条目的级别上，Server在启动时自动调整缓存大小。要显式设置大小，请在启动时设置table_open_cache系统变量。MySQL可能临时打开许多表来执行查询。 在以下情况，MySQL会关闭一个未使用的表并将其从表缓存中删除: 当缓存已满并且线程尝试打开不在缓存中的表时 当缓存包含多个table_open_cache条目并且任何线程都不再使用缓存中的表时 当table-flushing操作发生。这有可能在FLUSH TABLES语句、执行mysqladmin flush-tables或mysqladmin refresh命令 当表缓存填满时，Server使用以下过程来定位要使用的缓存条目: 从最近最少使用的表开始，发布当前未使用的表 如果必须打开新表，但缓存已满且无法释放表，则会根据需要临时扩展缓存。当缓存处于临时扩展状态并且表从已使用状态变为未使用状态时，表将关闭并从缓存中释放。 为每个并发访问打开MyISAM表。这意味着如果两个线程访问同一个表，或一个线程在同一个查询中两次访问该表，则需要打开两次表。每个并发打开都需要表缓存中的条目。在任何MyISAM表的第一次打开都需要两个文件描述符: 一个用于数据文件，一个用于索引文件。对表的每次额外使用仅为数据文件提供一个文件描述符。索引文件描述符在所有线程之间共享。 如果要使用HANDER tbl_name OPEN语句打开表，则会为该线程分配专用的表对象。此表对象不由其它线程共享，并且在线程调用HANDLER tbl_name CLOSE或线程终止之前不会关闭。发生这种情况时，表将被放回表缓存中（如果缓存未满）。 要确定表缓存是否太小，请检查Opened_tables状态变量，该变量指示自Server启动以来的表的打开操作数: 123456SHOW GLOBAL STATUS LIKE 'Opened_tables';+---------------+-------+| Variable_name | Value |+---------------+-------+| Opened_tables | 2741 |+---------------+-------+ 如果值非常大或快速增加，及时你没有发出许多FLUSH TABLES语句，也请在Server启动时增加table_open_cache的值。 在同一数据库中创建多个表的缺点Disadvantages of Creating Many Tables in the Same Database 如果在同一个数据库目录中有许多MyISAM表，则打开(open)、关闭(close)和创建(create)操作很慢。如果在许多不同的表上执行SELECT语句，则表缓存已满时会有一些开销，因为对于每个必须打开的表，必须关闭另一个表。您可以通过增加表缓存中允许的条目数来减少此开销。 内部临时表Internal Temporary Table Use in MySQL 在某些情况下，Server在处理语句时创建内部临时表。用户无法直接控制何时发生这种情况。 Server在以下条件下创建临时表: 评估UNION语句，稍后描述一些异常 评估某些视图(view) 评估派生的表 为实现子查询或半连接创建的表 评估包含ORDER BY和GROUP BY子句的语句，或它们包含连接队列中第一个表以外的表中的列的语句 评估DISTINCT结合ORDER BY可能需要临时表 对于使用SQL_SMALL_RESULT修饰符的查询，MySQL使用内存临时表，除非查询还包含需要磁盘存储的元素 为了评估从同一个表中选择和插入的INSERT ... SELECT语句，MySQL创建一个临时表来保存SELECT中的行，然后将这些行插入到目标表中 评估多表UPDATE语句 评估GROUP_CONCAT()或COUNT (DISTNCT)表达式 要确定语句是否需要临时表，请使用EXPLAIN并检查Extra列以查看是否显示Using temporary。当Server创建内部临时表(无论是内存还是磁盘上)时，它会增加Created_tmp_tables状态变量。 某些查询条件会阻止使用内存中的临时表，在这种情况下，Server会使用磁盘上的表: 表中存在BLOB或TEXT列，这包括具有字符串值的用户定义的变量，因此它们被视为BLOB或TEXT列，具体取决于它们的值分别是二进制字符串还是非二进制 如果使用UNION或UNION ALL，则SELECT列表中存在最大长度大于512的字符串列 SHOW COLUMNS和DESCRIBE语句使用BLOB作为某些列的类型，因此用于结果的临时表是磁盘上的表 Server不对具有某些限定条件的UNION语句使用临时表。相反，它仅从临时表创建中执行结果列类型转换所必须的数据结构。该表未完全实例化，并且没有写入和读取行，行直接发送到C端。结果是减少了内存和磁盘要求，并且在第一行发送到客户端之前的延迟较小，因为Server不需要等到最后一个查询块执行。EXPLAIN和优化程序输出反映了此执行策略：UNION RESULT查询不存在，因此该块对应于从临时表中读取的部分。 这些条件使UNION无需临时表即可进行评估: The union is UNION ALL, not UNION or UNION DISTINCT 没有全局ORDER BY子句 The union is not the top-level query block of an {INSERT | REPLACE} … SELECT … statement 内部临时表存储引擎Internal Temporary Table Storage Engine 内部临时表可以保存在内存中(由MEMORY存储引擎处理)，或由InnoDB或MyISAM存储引擎存储在磁盘上。 如果将内部临时表创建在内存中，但变得很大，MySQL会自动将其转换为磁盘表。内存临时表的最大大小由tmp_table_size或max_heap_table_size的值定义，以较小者为准。这与使用CREATE TABLE显式创建的MEMORY表不同。对于此类表，只有max_heap_table_size变量确定表可以增长的大小，并且没有转换为磁盘格式。internal_tmp_disk_storage_engine变量定义Server用于管理磁盘内部临时表的存储引擎。允许的值是：INNODB(默认)和MyISAM。 内部临时表存储格式Internal Temporary Table Storage Format 内存临时表由MEMORY存储引擎管理，该引擎使用固定长度的行格式。VARCHAR和VARBINARY列值填充到最大列长度，实际上将它们存储为CHAR和BINARY列。 磁盘临时表由InnoDB或MyISAM存储引擎管理。两个存储引擎都使用动态宽度行格式存储临时表。与使用固定长度行的磁盘相比，列只占用所需的存储空间，从而减少磁盘I/O，空间要求和处理时间。 对于最初在内存中创建内部临时表的语句，然后将其转换为磁盘表，可以通过跳过转换步骤并在磁盘上创建表开始来实现更好的性能。big_tables变量可用于强制内部临时表的磁盘存储。 优化InnoDB表Optimizing for InnoDB Tables InnoDB是MySQL客户通常在生产环境中使用的存储引擎，其中可靠性和并发性非常重要。它是默认的MySQL存储引擎。本节介绍如何优化InnoDB表的数据库操作。 优化InnoDB表的存储布局Optimizing Storage Layout for InnoDB Tables 一旦数据达到稳定大小，或者增长的表增加到上百兆字节(MB)，请考虑使用OPTIMIZE TABLE语句重新组织并压缩任何浪费的空间。重组的表需要较少的磁盘I/O来执行全表扫描(full table scan)。这是一个简单的技术，可在其它技术不切实际时提高性能。OPTIMIZE TABLE复制表的数据部分并重建检索。其好处改进了索引中数据的打包，减少了表空间和磁盘上的碎片。好处取决于每个表中的数据。如果表很大或者正在重建的索引不适合缓冲池，则此操作可能很慢。向表中添加大量数据后的第一次运行通常比以后的运行慢得多。 在InnoDB中，具有long PRIMARY KEY(具有冗长值的单个列或形成长度复合值的多个列)浪费了大量磁盘空间。在指向同一行的所有辅助索引(secondary index)记录中，行的主键值重复。如果主键很长，则创建AUTO_INCREMENT列作为主键，或者索引long VARCHAR列的前缀而不是整个列。 使用VARCHAR数据类型而不是CHAR来存储可变长度(variable-length)字符串或具有许多NULL值的列。即使字符串较短或其值为NULL，CHAR(N)的列也始终使用N个字符(character)来存储数据。较小的表更适合缓冲池并减少磁盘I/O。当使用COMPACT行格式(默认的InnoDB格式)和可变长度字符串(如utf8)时，CHAR(N)列占用可变的空间量，但仍至少占用N个字节。 对于大型表或包含大量重复文本(repetitive text)或数字(nemeric)数据的表，情考虑使用COMPRESSED行格式。将数据放入缓冲池(buffer pool)或执行全表扫描需要较少的磁盘I/O。在作出永久性决策之前，请使用COMPRESSED与COMPACT行格式测量可以实现的压缩量。 优化InnoDB事务管理Optimizing InnoDB Transaction Management 要优化InnoDB事务处理，请在事务功能的性能开销(performance overhead)和Server的工作负载(workload)之间找到理想的平衡点。例如，如果应用程序每秒提交数千次，则可能会遇到性能问题， 默认的MySQL设置AUTOCOMMIT=1可以对繁忙的数据库Server施加性能限制。在可行的情况下，通过发出SET AUTOCOMMIT=0或START TRANSACTION语句，然后在进行所有更改后发出COMMIT语句，将多个相关数据更改操作包装到单个事务中。如果该事务对数据库进行了修改，InnoDB必须在每次事务提交时将日志刷新到磁盘。当每次更改后都提交时，存储设备的I/O吞吐量会限制每秒潜操作的数量。 对于仅包含单个SELECT语句的事务，启用AUTOCOMMIT可帮助InnoDB识别只读事务并对其进行优化。 INSERT, DELETE, UPDATE大量行后，避免执行行回滚。如果大型事务正在降低Server性能，则将其回滚可能会使问题变得更糟，可能需要花费几倍的时间来执行原始数据更改操作。杀死数据库进程没有帮助，因为Server启动时会再次启动回滚。为了尽量减少此问题发生的可能性： 增加缓冲池的大小，以便可以缓存所有数据更改，而不是立即写入磁盘 设置innodb_change_buffering=all，以便缓冲除INSERT之外的UPDATE, DELETE操作 考虑在大数据更改操作期间定期发出COMMIT语句，可能会破坏单个删除或更新为较少行数进行操作的多个语句要在发生失控回滚后摆脱它，请增加缓冲池使回滚变为CPU限制并快速运行，或杀死Server并使用innodb_force_recovery=3选项来启动它。预计此问题很少发生，默认设置innodb_change_buffering=all，他允许将UPDATE和DELETE操作缓存在内存中，从而使它们可在第一时间更快地执行，并且如果需要还可以更快地回滚。确保在处理具有许多INSERT, UPDATE, DELETE操作的长时间运行事务的Server上使用此参数设置。 如果发生奔溃时，如果你可以承受丢失一些最新提交的事务，则可以设置 innodb_flush_log_at_trx_commit=0。InnoDB无论如何都会尝试每秒刷新(FLUSH)一次日志，尽管无法保证。此外，设置innodb_support_xa=0将减少磁盘数据和BINLOG同步而导致到磁盘刷新次数。 修改或删除行时，不会立即删除行和关系链的undo log，甚至在事务提交后。旧数据将保留，直到先前或同时启动的事务完成，以便这些事务可以访问已修改或已删除的行的先前状态。因此，长时间运行的事务可以阻止InnoDB清除由不同事务更改的数据。 在长时间运行的事务中修改或删除行时，使用READ COMMITTED和REPEATABLE READ隔离级别的其它事务必须执行更多工作，以便在读取相同行时重建旧数据。 当长时间运行的事务修改表时，从其它事务对该表的查询不会使用covering index technique。通常可从二级索引检索所有结果列的查询，而不是从表数据中查找适当的值。如果发现二级索引页面的PAGE_MAX_TRX_ID太新，或二级索引中的记录被删除标记，则InnoDB可能需要使用clustered index来查找记录。 优化InnoDB只读事务Optimizing InnoDB Read-Only Transactions InnoDB可以避免与已知为只读的事务设置事务ID(TRX_ID字段)相关的开销。只有可能执行写操作或锁定读取的事务(如SELECT…FOR UPDATE)才需要事务ID。消除不必要的事务ID会减少每次查询或数据更改语句构造读取视图时所咨询的内部数据结构的大小。 语言结构Language Structure 本章讨论在使用MySQL时编写SQL语句的以下元素的规则： 文字值，如字符串和数字 标识符，如数据库、表和列名 关键词与保留词 用户定义变量和系统变量 评论 文字值Literal Values 本节描述如何在MySQL中写入文字值。这包含了字符串、数字、十六进制、位值、布尔值、NULL。还将介绍在MySQL中处理这些基本类型时可能遇到的各种细微差别。 字符串String Literals 字符串时字节(Byte)或字符(character)序列，包含在单引号(&#39;)或双引号(&quot;)中。 栗子： 123&apos;a string&apos;&apos;a&apos; &apos; &apos; &apos;string&apos;&quot;another string&quot; 注意如果启用了ANSI_QUOTES SQL模式，字符串只能在单引号中引用，因为双引号的字符串被解释为标识符。 二进制字符串(binary string)是一串字节(Bytes)。每个二进制字符串都有一个名为binary的字符集(character set)和排序规则。非二进制字符串是一串字符(characters)，它具有二进制以外的字符集和与字符集兼容的排序规则。 对于两种类型的字符串，比较是基于字符串单元的数值。对于二进制字符串，单位是字节(byte)，使用数字字节值比较；对于非二进制字符串，单位是字符(character)和支持多字节字符的字符集，使用数字字符码值比较。字符码排序是字符串排序的函数。 字符串文字可以有一个可选的字符集导入器和排序字句，将其指定为使用特定字符集和排序的字符串：[_charset_name]&#39;string&#39; [COLLATE collation_name]栗子: 12345678SELECT _latin1'string';SELECT _binary'string';SELECT _utf8'string' COLLATE utf8_danish_ci;SELECT N'some text';SELECT n'some text';SELECT _utf8'some text'; 在字符串中，某些序列具有特俗含义，除非启用了No_BACKSLASH_ESCAPES SQL模式。如转义字符每个序列都以反斜线(backslash)(\)开始。 特殊字符转义序列： Escape Sequence Character Represented by Sequence \0 An ASCII NUL (X’00’) character \&#39; A single quote (‘) character \&quot; A double quote (“) character \b A backspace character \n A newline (linefeed) character \r A carriage return character \t A tab character \Z ASCII 26 (Control+Z); see note following the table \\ A backslash () character \% A % character; see note following the table \_ A _ character; see note following the table 在字符串中包含引号字符有几种方法： 两个引号 引号包含引号 转义引号 栗子： 12345678910111213141516171819202122SELECT 'hello', '"hello"', '""hello""', 'hel''lo', '\'hello';+-------+---------+-----------+--------+--------+| hello | "hello" | ""hello"" | hel'lo | 'hello |+-------+---------+-----------+--------+--------+SELECT "hello", "'hello'", "''hello''", "hel""lo", "\"hello";+-------+---------+-----------+--------+--------+| hello | 'hello' | ''hello'' | hel"lo | "hello |+-------+---------+-----------+--------+--------+SELECT 'This\nIs\nFour\nLines';+--------------------+| ThisIsFourLines |+--------------------+SELECT 'disappearing\ backslash';+------------------------+| disappearing backslash |+------------------------+ 要将二进制数据插入字符串列中，应该使用转义序列表示某些字符。在某些特定的Client环境下，可能还需要转换NUL或Ctrl + Z。在编写应用程序时，必须将包含特殊字符正确的转义发送给MySQL。 数字Numeric Literals 数字包括精确值(整数和小数)和近似值(浮点数)。 整数用数字序列表示。数字可能包括., -, +，科学表示法E等。 12345#精确值，定点数2.34#近似值，浮点数2.34E0 日期和时间Date and Time Literals 日期和时间可以用几种格式表示。如&#39;2015-07-21&#39;, &#39;20150721&#39;, 20150721都可解释为日期。 标准SQL和ODBC日期和时间：标准SQL允许使用type关键字和字符串指定时态文字。 1234--空格可选DATE 'str'TIME 'str'TIMESTAMP 'str' ODBC语法： 123&#123; d &apos;str&apos; &#125;&#123; t &apos;str&apos; &#125;&#123; ts &apos;str&apos; &#125; MySQL使用type关键字，这些结构分别包含DATE, TIME, DATETIME值，如果指定的话，好包括后面的小数秒部分。TIMESTAMP语法在MySQL中生成一个DATETIME值，因为DATETIME的范围与标准SQL TIMESTAMP类型更接近，后者年限为0001-9999。而MySQL的TIMESTAMP范围是1970-2038年。 日期和时间上下文中的字符串和数字： MySQL可以识别以下格式的DATE值： &#39;YYYY-MM-DD&#39;或&#39;YY-MM-DD&#39;字符串格式。允许宽松的语法——即任何标点字符都可作为日期之间的分隔符。如&#39;2012-12-31&#39;, &#39;2012/12/31/&#39;, &#39;2012@12@31&#39;... &#39;YYYYMMDD&#39;或&#39;YYMMDD&#39;没有分隔符的字符串格式，前提是该字符作为日期有意义。如&#39;20121231&#39;, &#39;121231&#39;... YYYYMMDD或YYMMDD数字格式，前置是该数字作为日期有意义。如20121231, 121231... MySQL可以识别以下格式的DATETIME和TIMESTAMP： &#39;YYYY-MM-DD HH:MM:SS&#39;或&#39;YY-MM-DD HH:MM:SS&#39;字符串格式。允许宽松的语法。如2012/12/31 00*01*02...日期和时间部分可以用T分隔，而不是空格。如2012-12-31 00:01:02, 2012-12-31T01:02:03 &#39;YYYYMMDDHHMMSS&#39;或&#39;YYMMDDHHMMSS&#39;没有分隔符的字符串格式，前提是该字符作为日期有意义 YYYYMMDDHHMMSS或YYMMDDHHMMSS数字格式，前提是该数字作为日期有意义 DATETIME和TIMESTAMP值可以包含一个精度不超多微秒(6位)的小数部分。小数部分应该始终使用小数点.与其他部分跟开，无法识别分数秒分隔符。 MySQL使用以下规则解释两位数的年值： 70-99转换为1970-1999 00-69转换为2000-2069 MySQL可以识别以下格式的TIME值： &#39;D HH:MM:SS&#39;字符串格式，D表示天数(0-34)。可以使用放松的语法。 &#39;HHMMSS&#39;没有分隔符字符串格式，前提是作为时间有意义。 HHMMSS数字格式，前提是作为时间有意义。 小数秒部分在&#39;D HH:MM:SS.fraction&#39;时间格式中识别，其中小数是精度最高可达微秒(6位)的小数部分，小数部分使用小数点.与其它部分分隔开，无法识别其它小数秒分隔符。 十六进制Hexadecimal Literals 字符集和编码Character Sets, Collations, Unicode 数据类型Data Type MySQL支持多种类型的SQL数据类型： numeric date/time string character byte JSON 数据类型描述使用如下约定： M表示整数类型的最大显示宽度 D适用于浮点和定点类型，并指示小数点后面的位数 fsp适用于TIME, DATATIME, TIMESTAMP类型，表示小数点的秒精度 方括号[]表示类型定义的可选部分 数字Numberic type 如果为数字列指定ZEROFILL，MySQL会自动将UNSIGNED属性添加到列中。 数字数据类型允许UNSIGNED(无符号)属性，也允许SIGNED(符号)。默认情况下，这些数据类型是SIGNED，因此SINGED属性不起作用。 BITA bit-value type.(1-64) TINYINTA very small integer.有符号范围: -128 to 127, 无符号范围: 0-255 BOOL SMALLINTA small integer.有符号范围: -32768 to 32767, 无符号范围: 0-65535 MEDIUMINTA medium-sized integer.有符号范围: -8388608 to 8388607, 无符号范围: 0-16777215 INTA normal-size integer.有符号范围: -2147483648 to 2147483647, 无符号范围: 0- 4294967295 INTERGER此类型是INT的同义词。 BIGINTA large integer.符号范围: -9223372036854775808 to 9223372036854775807, 无符号范围: 0 to 18446744073709551615SERIAL是BIGINT UNSIGNED NOT NULL AUTO_INCREMENT UNIQUE的别名。 DECIMAL/DEC FLOATA small(单精度) floating-point number.允许的值为: -3.402823466E+38 to -1.175494351E-38, 0, and 1.175494351E-38 to 3.402823466E+38 DOUBLEA normal-size(双精度) floating-point number.允许值为: -1.7976931348623157E+308 to -2.2250738585072014E-308, 0, and 2.2250738585072014E-308 to 1.7976931348623157E+308 FLOATA floating-point number. 日期和时间Date and Time Type MySQL允许的TIME, DATETIME, TIMESTAMP值的小数，精度高达微秒(小数点后6位)。 DATEA date.支持范围: 1000-01-01到9999-12-31。MySQL以YYYY-MM-DD格式显示DATE值，但允许使用字符串或数字将值分配给DATE列。 DATETIMEA date and time combination.支持范围: 1001-01-01 00:00:00.000000到9999-12-31 23:59:59.999999。MySQL以YYYY-MM-DD HH:MM:SS.[fraction]的格式显示DATETIME值，同样允许字符串或数字将值分配给DATETIME列。 TIMESTAMPA timestamp.支持范围: 1970-01-01 00:00:01.000000UTC到2038-01-19 03:14:07.999999UTCTIMESTAMP值存储为自纪元1970-01-01 00:00:01.000000 UTC以来的秒数，这也叫原子时间。 TIMEA time.支持范围: -838:59:59.000000 to 838:59:59.000000MySQL以HH:MM:SS[.fraction]的格式显示TIME值，但允许使用字符串或数字将值分配给TIME列。 YEARA year in four-digit format.MySQL以YYYY格式显示YEAR值，但允许使用字符串或数字将值分配给YEAR列。 字符串String Type 在某些情况下，MySQL可能会使用CREATE TABLE或ALTER TABLE语句更改字符串的类型。 CHARACTER SET/CHARSET指定字符集 12345CREATE TABLE t( c1 VARCHAR(20) CHARACTER SET utf8, c2 TEXT CHARACTER SET latin1 COLLATE latin1_general_cs); CHAR一个固定长度的字符串，在存储时使用用空格填充指定长度。VARCHAR的有效最大长度取决于最大行大小(65535字节)和使用的字符集。 VARCHAR一个可变长度的字符串。 BINARYBINARY类似于CHAR，但存储二进制字节字符串而不是非二进制字符串。 VARBINARY TINYBLOBA BLOB column with a maximum length of 255 (2^8 − 1) bytes. TINYTEXTA TEXT column with a maximum length of 255 (2^8 − 1) characters. BLOBA BLOB column with a maximum length of 65,535 (2^16 − 1) bytes. TEXTA TEXT column with a maximum length of 65,535 (2^16 − 1) characters. MEDIUMBLOBA BLOB column with a maximum length of 16,777,215 (2^24 − 1) bytes. MEDIUMTEXTA TEXT column with a maximum length of 16,777,215 (2^24 − 1) characters. LONGBLOBA BLOB column with a maximum length of 4,294,967,295 or 4GB (2^32 − 1) bytes. LONGTEXTA TEXT column with a maximum length of 4,294,967,295 or 4GB (2^32 − 1) characters. ENUMAn enumeration. SETA set. 必知必会MySQL Crash Course 了解SQL 数据库基础在学习MySQL以及SQL之前，应该对数据库及数据库技术的概念有所了解。 什么是数据库数据库是一种以某种有组织的方式存储的数据集合。 人们通常用数据库这个术语来代表他们使用的数据库软件。这是不正确的，它是引起混淆的根源。确切地说，数据库软件应该成为DBMS(数据库管理系统). 表在文件柜中创建文件，然后将相关的资料放入特定的文件中。在数据库领域，这种文件成为表(table)，表是一种结构化的文件，可用来存储某种特定类型的数据。绝不应该将顾客的清单与订单的订单存储在同一个数据库表中。这样讲使以后的检索和访问很困难。应该创建两个表，每个清单一个表。 模式(schema)，关于数据库和表的布局及特征的信息。有时，模式用作数据库的同义词。 列和数据类型表由列组成。列中存储着表中某部分的信息。列(column)，表中的一个字段。数据库中的每个列都有相应的数据类型。 正确地将数据分解为多个列极为重要。如城市、省、邮编应该是独立的列。通过将它们分隔开，才有可能对其进行组合操作。 数据类型(datatype)，所容许的数据的类型。每个表列都有相应的数据类型。 行表中的数据是按行存储的，所保存的每个记录存储在自己的行内。行(row)，表中的一个记录。 主键表中每一行都应该有可以表示自己的一列(一组列)。主键(primary key)，一列(一组列)，其值能够唯一区分表中的每个行。 唯一标识表中的每行的这个列(这组列)称为主键，主键用来表示一个特定的行。应该总是定义主键。虽然并不总是都需要主键，但数据库设计人员都应该保证他们创建的每个表都具有一个主键，以便于以后的数据操作和管理。 表中的任何列都可作为主键，只要它满足一下条件: 任意两行都不具有相同的主键值； 每行都必须具有一个主键值(主键值不允许NULL值)。 主键通常定义在表的一列上，但这并不是必须的，也可以一起使用多个列作为主键。所有列值的组合必须是唯一的(但单个列的值可以不唯一)。 主键的好习惯: 不更新主键列中的值； 不重用主键列的值； 不在主键列中使用可能会更改的值。 什么是SQLSQL（发音为字母S-Q-L或sequel）是结构化查询语言（Structured Query Language）的缩写。 SQL有以下优点: SQL不是为某个特定数据库供应商专有的语言。几乎所有的DMS都支持SQL。 SQL简单易学。它的语句全都是由描述性很强的英语单词组成。 SQL尽管看上去很简单，但它实际上是一种强有力的语言，可进行非常复杂和高级的数据库操作； SQL不区分大小写，但建议对SQL关键字使用大写，表列等使用小写，这样方便阅读和调试； 在处理SQL语句时，所有空格都将被忽略。 SQL注释 单行注释 # -- 多行注释 /* */ 12345678910#sql single line comment-- single line comment-- 注意，有空格/*line1 commentline2 comment...*/ MySQL简介 什么是MySQLMySQL是一种DBMS，即它是一种数据库管理软件。 众多开发者和公司使用MySQL的原因: 成本，MySQL是开源的； 性能，MySQL执行很快； 可信赖，大公司也使用它； 简单，MySQL易于安装和使用。 C-SDBMS可分为两类: 基于共享文件系统，如Microsoft Access，通常用于桌面用途； 基于C-S，如MySQL、Oracle、SQL Server。 MySQL工具工欲善其事必先利其器。有3个工具需要提及: msyql命令行使用程序 MySQL Administrator MySQL Query Browser 条件判断语句 IF语句 CASE语句 IF IF FUNCTION IF STATEMENT 123456789101112131415161718192021222324252627282930313233343536HELP IF STATEMENT;IF search_condition THEN statement_list [ELSEIF search_condition THEN statement_list] ... [ELSE statement_list]END IF-- 栗子CREATE PROCEDURE test1BEGIN IF score &gt;= 90 THEN SELECT score, 'A'; ELSEIF score&lt;90 AND socre&gt;=80 THEN SELECT score, 'B' ELSEIF socre&lt;80 AND score&gt;=70 THEN SELECT score, 'C' ELSEIF score&lt;70 AND score&gt;=60 THEN SELECT socre, 'D' ELSE SELECT score, 'E' END IF;END;HELP IF FUNCTION;IF(expr1,expr2,expr3)-- 栗子SELECT IF(1&gt;2,2,3);+-------------+| IF(1&gt;2,2,3) |+-------------+| 3 |+-------------+ CASE CASE OPERATOR CASE STATEMENT 123456789101112131415161718192021222324252627282930313233343536373839404142434445HELP CASE OPERATOR;CASE value WHEN [compare_value] THEN result [WHEN [compare_value] THENresult ...] [ELSE result] ENDCASE WHEN [condition] THEN result [WHEN [condition] THEN result ...][ELSE result] END-- 栗子SELECT CASE 1 WHEN 1 THEN 'one' WHEN 2 THEN 'two' ELSE 'more' END;-- oneHELP CASE STATEMENT;CASE case_value WHEN when_value THEN statement_list [WHEN when_value THEN statement_list] ... [ELSE statement_list]END CASE-- 或CASE WHEN search_condition THEN statement_list [WHEN search_condition THEN statement_list] ... [ELSE statement_list]END CASE-- 栗子CREATE PROCEDURE p()BEGIN DECLARE v INT DEFAULT 1; CASE v WHEN 2 THEN SELECT v; WHEN 3 THEN SELECT 0; ELSE BEGIN END; END CASE;END; 循环语句 WHILE语句 REPEAT语句 LOOP语句 WHILE123456789101112131415HELP WHILE;[begin_label:] WHILE search_condition DO statement_listEND WHILE [end_label]-- 栗子CREATE PROCEDURE dowhile()BEGIN DECLARE v1 INT DEFAULT 5; WHILE v1 &gt; 0 DO SET v1 = v1 - 1; END WHILE;END; REPEAT123456789101112131415HELP REPEAT;[begin_label:] REPEAT statement_listUNTIL search_conditionEND REPEAT [end_label]-- 栗子CREATE PROCEDURE dorepeat(p1 INT)BEGIN SET @x = 0; REPEAT SET @x = @x + 1; UNTIL @x &gt; p1 END REPEAT;END; LOOP123456789101112131415161718HELP LOOP;[begin_label:] LOOP statement_listEND LOOP [end_label]-- 栗子CREATE PROCEDURE doiterate(p1 INT)BEGIN label1: LOOP SET p1 = p1 + 1; IF p1 &lt; 10 THEN ITERATE label1; END IF; LEAVE label1; END LOOP label1; SET @x = p1;END; 使用MySQL 连接在执行命令之前需要登录到DBMS。为了连接到MySQL，需要以下信息: hostname port username passwd(可选) 选择数据库选择数据库有两种方式: 在连接是指定数据库名 登录后选择数据库 12345# 1mysql -h xxx -P xxx -u xxx -p dbName# 2mysql&gt; USE dbName; 了解数据库和表数据库、表、列、用户、权限等的信息被存储在数据库和表中。不过，内部表一般不直接访问，可用SHOW命令来显示这些信息。 123456789101112131415161718192021HELP SHOW;SHOW DATABASES;SHOW TABLES;SHOW COLUMNS FROM tableName;# 显示服务器信息SHOW STATUS;# 显式创建SHOW CREATE DATABASE xxx;SHOW CREATE TABLE xxx;# 查看权限SHOW GRANTS;# 显示Server错误或警告信息SHOW ERRORS;SHOW WARNINGS; 检索数据 SELECT语句SQL语句有简单的英语单词构成，这些单词称为关键字，每个SQL语句由一个或多个关键字构成。大概，最常用的SQL语句就是SELECT语句了，它从一个或多个表中检索信息。 检索单个列1SELECT columnName from tableName; 检索多个列选择列名时，一定要在列名之间加上逗号，但最后一个列名不加。 1SELECT columnName1, columnName2 FROM tableName; 检索所有列一般，除非你确定表中的每个列，否则最好不要使用*通配符。 1SELECT * FROM tableName; 检索不同的行你不想要每个值每次出现，使用DISTINCT关键字以指示MySQL只返不同(唯一)的值。DISTINCT关键字必须放在列名的前面。DISTINCT关键字应用于所有列，而不仅是前置它的列。 1SELECT DISTINCT columnName FROM tableName; 限制结果SELECT返回所有匹配的行，为了返回一个或多个行，可使用LIMIT子句。 1234567SELECT columnName FROM tableName LIMIT 10;# LIMIT a, b指示MySQL返回从行a开始的b行# 第一个数为开始位置，第二个数为要检索的行数# 行数是从0开始计算的SELECT columnName FROM tableName LIMIT 10, 5;# 行数不够时，MySQL只返回它能返回的行 使用完全限定的表名迄今为止使用的SQL栗子只通过列名引用列。也可能会使用完全限定的名字来引用列(同时使用表名和列名)。 1234SELECT tableName.columnName FROM tableName;# 表名也可以是完全限定的SELECT tableName.columnName FROM dbName.tableName; 排序检索数据本章讲解如何使用SELECT语句的ORDER BY子句，根据需要排序检索出的数据。 排序数据关系数据库设计理论认为，如果不明确规定排序顺序，则不应该假定检索出的数据的顺序有意义。 子句(clause)，SQL语句有子句构成，有些子句是必须的，而有的是可选的。 为了明确排序SELECT语句检索出的数据，可使用ORDER BY子句。 1234# 默认为升序SELECT columnName FROM tableName ORDER BY columnName;SLECT columnName1, columnName2 FROM tableName ORDER BY columnName2; 按多个列排序经常需要按不止一个列进行排序。多列排序，只要指定列名，列名之间用逗号分隔开即可。 12# 先按列1排序，再按列2排序SELECT columnName1, columnName2, columnName3 FROM tableName ORDER BY columnName1, columnName2; 排序指定方向 升序(默认): 从A-Z，关键字AESC。因为是默认，所以无需指定。 降序: 从Z-A，使用DESC关键字。 123456789101112SELECT columnName, columnName1 FROM tableName ORDER BY columnName1 DESC;# 多序列，需要对每个列指定关键字SELECT columnName, columnName1, columnName2 FROM tableName ORDER BY columnName1 DESC, columnName2i DESC;# ORDER BY和LIMIT的组合SELECT columnNameFROM tableNameORDER BYcolumnName DESCLIMIT 10; 过滤数据本章讲解如何使用SELECT语句的WHERE子句指定搜索条件。 WHERE子句数据库一般包含大量的数据，很少需要检索表中所有行。通常只会根据特定操作或报告的需要提取表数据的子集。只检索所需数据需要指定搜索条件(也称为过滤条件)。 在SELECT语句中，数据根据WHERE子句中指定的搜索条件进行过滤。在同时使用ORDER BY和WHERE子句时，应该让ORDER BY位于WHERE之后，否则将产生错误。 123SELECT columnNameFROM tableNameWHERE id = 1001; WHERE子句操作符MySQL支持如下条件操作符: 操作符 说明 = 等于 &lt;&gt; 不等于 != 不等于 &lt; 小于 &lt;= 小于等于 &gt; 大于 &gt;= 大于等于 BETWEEN 在指定的两个值之间 检查单个值1234567SELECT column1, column2FROM table1WHERE name = 'zhang';SELECT column1, column2FROM table1WHERE price &lt;= 10; 不匹配检查1234567SELECT column1, column2FROM table1WHERE id &lt;&gt; 1002;SELECT column1, column2FROM table1WHERE id != 1003; 范围值检查为了检查某个范围的值，可使用BETWEEN操作符。它需要两个值，即范围的开始值和结束值。 123SELECT column1, column2FROM table1WHERE price BETWEEN 2 AND 10; 空值检查在创建表时，可指定列是否可以不包含值。在一个列不包含值时，称其为空值NULL。NULL， 无值(no value)，它与字段包含0、空字符串或仅仅包含空格㓊。 有一个特殊的WHERE子句ISNULL，用来检测具有NULL值的列。 123SELECT column1FROM table1WHERE price IS NULL; 组合WHERE子句使用组合的WHERE子句，以AND和OR子句(逻辑操作符)的方式，进行更强的数据控制。 AND操作符123SELECT column1, column2FROM table1WHERE name = 'zhang' AND price &lt;= 10;&gt; OR操作符123SELECT column1, column2FROM table1WHERE name = 'zhang' OR name = 'abc'; 计算次序WHERE可包含任意数目的AND和OR操作符，允许两者结合已进行复杂和高级的过滤。由于逻辑操作符存在优先级，所以请记得使用括号。 123SELECT column1, column2FROM table1WHERE (id = 1001 OR id = 1003) AND price &gt;= 10; IN操作符IN操作符用来指定条件范围，范围中的每个条件都可以进行匹配。 123456SELECT column1, column2FROM table1WHERE id IN (1001, 1002)ORDER BY column2;# WHERE id = 1001 OR id = 1002 其实这里的IN和OR操作符完成相同的功能。为什么要使用IN操作符: 在使用长的合法选项清单时，IN操作符的语法更清楚且更直观 在使用IN时，计算的次序更容易管理 IN操作符一般比OR操作符清单执行更快 IN的最大优点是可以包含其他SELECT语句，使得能够更动态地建立WHERE子句 NOT操作符WHERE子句中的NOT操作符有且只有一个功能，那就是否定它之后所跟的任何条件。 1234SELECT column1, column2FROM table1WHERE id NOT IN (1001, 1002)ORDER BY column2; 通配符过滤本章介绍什么是通配符、如何使用通配符以及怎样使用LIKE操作符进行通配搜索，以便对数据进行负载过滤。 通配符(wildcard)，用来匹配一部分的特殊字符。搜索模式(search pattern)，由字面值、通配符或两者组合构成的搜索条件。 LIKE操作符通配符本身本身实际是SQL的WHERE子句中有特殊含义的字符，SQL支持几种通配符: 百分号(%)通配符 下划线(_)通配符 为了在搜索子句中使用通配符，必须使用LIKE操作符。LIKE只是MySQL，后跟搜索模式利用通配符，而不是直接相等匹配进行比较。 百分号通配符 注意，除了一个或多个字符，%还能匹配0个字符(也就是&gt;=0); %通索配符不能匹配NULL; 在搜索中，%通配符表示任何字符出现任何次数(类似Linux中的星号*); %通配符可在搜索模式的任意位置使用，并且可以使用多个通配符(这点Linux的星号不支持); 通配符也可以出现在搜索模式的中间，虽然这样并不太有用; 根据MySQL的配置方式，搜索可以是区分大小写的。 1234567SELECT id, nameFROM table1WHERE name LIKE '%zhang%';SELECT nameFROM table1WHERE name LIKE 'a%z'; 下划线通配符下划线(_)通配符只匹配单个字符 123SELECT id, nameFROM table1WHERE name LIKE 'zhan_'; 使用通配符的技巧如上所见，MySQL通配符很有用。但这种功能是有代价的: 通配符搜索的处理一般要比前面讨论的其它搜索所花时间更长。这里给出一些使用通配符要记住的技巧： 不要过度使用通配符。如果其它操作符能达到相同的目的，应该使用其它操作符； 在确实需要使用通配符时，除非绝对有必要，否则不要把它们用在搜索模式的开始处(这样太慢了)； 请注意通配符的放置位置，不要乱放。 正则表达式搜索本章介绍如何在MySQL WHERE子句内使用正则表达式(RE)来更好地控制数据过滤。 正则表达式介绍正则表达式用来匹配文本的特殊的串(字符集)。所有种类的程序设计语言、文本编辑器、操作系统…都支持正则表达式。正则表达式用正则表达式语言来建立，它是一种特殊语言。 MySQL正则表达式MySQL用WHERE子句中的REGEXP关键字对正则表达式提供了初步的支持。MySQL中的正则表达式默认不缺分大小写；如果要区分，可使用BINARY关键字。 基本字符匹配123456789101112SELECT nameFROM table1WHERE score REGEXP '100';# 这里使用的正则效果还没有LIKE好，因为它并不复杂，这里仅做栗子参考-- 下面看一个复杂点的-- 特殊字符.表示匹配任意一个字符SELECT scoreFROM table1WHERE socre REGEXP '.0' OR匹配使用|进行或匹配。 123SELECT nameFROM table1WHERE name REGEXP '111|222|333'; 匹配多个字符之一利用一组括号[]来完成。 123SELECT nameFROM table1WHERE name REGEXP '[zhang|li|song]'; 匹配范围集合可用来定义要匹配的一个或多个字符。 12345678910/*[0123456789][0-9][a-z][a-zA-Z]*/SELECT nameFROM table1WHERE name REGEXP '[a-zA-z]hang'; 转义字符MySQL中的正则表达式使用两个反斜线(\\)做转义。 123SELECT scoreFROM table1WHERE score REGEXP '[8|9]0\\.0'; 匹配字符类为了更方便的工作，可以使用预定义的字符集，称为字符类(character class)。 类 说明 [:alnum:] 任意字母和数字（同[a-zA-Z0-9]） [:alpha:] 任意字符（同[a-zA-Z]） [:blank:] 空格和制表（同[\t]） [:cntrl:] ASCII控制字符（ASCII 0到31和127） [:digit:] 任意数字（同[0-9]） [:graph:] 与[:print:]相同，但不包括空格 [:lower:] 任意小写字母（同[a-z]） [:print:] 任意可打印字符 [:punct:] 既不在[:alnum:]又不在[:cntrl:]中的任意字符 [:space:] 包括空格在内的任意空白字符（同[\f\n\r\t\v]） [:upper:] 任意大写字母（同[A-Z]） [:xdigit:] 任意十六进制数字（同[a-fA-F0-9]） 匹配多个实例重复元字符: 元字符 说明 * 0个或多个匹配 + 1个或多个匹配（等于{1,}） ? 0个或1个匹配（等于{0,1}） {n} 指定数目的匹配 {n,} 不少于指定数目的匹配 {n,m} 匹配数目的范围（m不超过255 123SELECT nameFROM table1WHERE name REGEXP '\\([0-9] zhang?\\)'; 定位符匹配特定位置的文本。 元字符 说明 ^ 文本的开始 $ 文本的结尾 [[:&lt;:]] 词的开始 [[:&gt;:]] 词的结尾 123SELECT nameFROM table1WHERE name REGEXP '^[0-9\\.]'; 创建计算字段本章介绍什么是计算字段，如何创建计算字段以及怎样从应用程序中使用别名引用它们。 计算字段存储在数据库表中的数据一般不是应用程序所需要的格式，我们需要直接从数据库中检索转换过的数据，然后再在C端重新格式化。 拼接字段拼接(concatenate)，将值联结到一起构成单个值。在MySQL的SELECT语句中，可使用Concat()函数来拼接两个列。多数DBMS使用+或||来实现拼接，MySQL使用Concat()函数来实现。当把SQL语句转换为MySQL语句时请一定注意。 12SELECT Concat(name, ', id')FROM table1; 使用别名拼接字段做的很好，但新列并没有名字，而是使用Concat(name, &#39;, id&#39;)作为列名。这样虽不能说不好，但利于使用。为了解决这个问题，MySQL支持别名(alias)。可使用AS关键字赋予。 12SELECT CONCAT(name, ', id') AS nameIdFROM table1; 执行算术计算计算字段的另一常见用途是对检索出的数据进行算术计算。 MySQL算术操作符: 操作符 说明 + 加 - 减 * 乘 / 除 12SELECT id, quantity, price, quantity*price AS totalPriceFROM table1; 数据处理函数本章介绍什么是函数，MySQL支持何种函数，以及如何使用这些函数。 函数与其它大多数计算机语言一样，SQL支持利用函数来处理数据。函数一般在数据上执行，它给数据的转换和处理提供了方便。 函数没有SQL的可移植性强。几乎每种DBMS的实现都支持其它不支持的函数，而且可能差异还很大。为了代码的可移植性，许多SQL程序员不赞成使用特殊实现的功能。虽然这样有很多好处，但不总是利于应用程序的性能。如果你决定使用函数，应该做好代码注释，以便大家知晓。 使用函数大多数SQL支持以下类型的函数: 用于处理文本串的文本函数 用于在数值数据上进行算术操作的数值函数 用于处理日期和时间值并从这些值中提取特定成分的日期和时间函数 返回DBMS正使用的特殊信息的系统函数 文本处理函数常见文本处理函数: 函数 说明 Left() 返回串左边的字符 Length() 返回串的长度 Locate() 找出串的子串 Lower() 将串转换为小写 LTrim() 去掉串左边的空格 Right() 返回串右边的字符 RTrim() 去掉串右边的空格 Soundex() 返回串的SOUNDEX值 SubString() 返回子串的字符 Upper() 将串转换为大写 SOUNDEX是将任何文本串转换为描述其语音表示的字母数字模式的算法。 123SELECT name, UPPER(name) AS name_upcase, LENGTH(name) AS name_lengthFROM table1ORDER BY name; 日期和时间处理函数日期和时间采用相应的数据类型和特殊的格式存储，以便能快速和有效地排序或过滤，并且节省物理存储空间。一般，应用程序不使用用来存储日期和时间的格式，因此日期和时间函数总是被用来读取、统计和处理这些值。由于这个原因，日期和时间函数在MySQL语言中具有重要的作用。 常用的日期和时间处理函数: 函数 说明 AddDate() 增加一个日期 AddTime() 增加一个时间 CurDate() 返回当前时间 Month() 返回日期的月份部分 Now() 返回当前日志和时间 Second() 返回时间的秒部分 Time() 返回日期时间的时间部分 Year() 返回日期的年份部分 123456SELECT CURDATE(), CURTIME(), Now();SELECT id, nameFROM table1WHERE Date(datetime)BETWEEN '2018-12-01' AND '2019-01-31'; 这是用WHERE使用日期和时间对数据进行过滤的一个好时机。请注意日期格式(yyyy-mm-dd)，应该总是使用yyyy而不是YY表示年份，这样更可靠。 数值处理函数数值处理函数仅处理数值数据。这些函数一般用于代数、三角或几何运算。 常用数值处理函数: 函数 说明 Abc() 求绝对值 Cos() 求余弦 Exp() 求指数值 Mod() 求余数 Pi() 求圆周率 Rand() 返回一个随机数 Sin() 求正弦 Sqrt() 求平方根 Tan() 求正切 汇总数据本章介绍什么是SQL的聚集函数，以及如何利用它们汇总表的数据。 聚集函数我们经常需要汇总熟不而不用把它们实际检索出来，为此MySQL提供了专门的函数。以便分析和报表的生成。 这种类型的检索栗子有以下几种: 确定表中行数 获得表中行组的和 找出表列的最大值、最小值、平均值 返回实际表数据是对时间和处理资源的一种浪费。而实际想要的是汇总信息。 聚集函数(aggregate function)，运行在行组上，计算和返回单个值的函数。 SQL聚集函数: 函数 说明 AVG() 返回某列的平均值 COUNT() 返回某列的行数 MAX() 返回某列的最大值 MIN() 返回 某列的最小值 SUM() 返回某列值之和 AVG函数AVG()通过对表中的行数计数并计算特定列值之和，求得该列的平均值。可用来返回所有列的平均值，也可用来返回特定列或行的平均值。AVG()忽略列值为NULL的行。 123456SELECT AVG(price) AS avg_priceFROM table1;# 多列SELECT AVG(price), AVG(age)FROM table1; COUNT函数可利用COUNT()确定表中行的数据或符合特定条件的行的数目。 COUNT()函数有两种使用方式: 使用COUNT(*)对表中的行的数目进行技术，不管是否为空 石宏COUNT(column)对特定列的值进行行计数 12345678910SELECT COUNT(*)FROM table1;SELECT COUNT(column1)FROM table1;SELECT COUNT(column1)FROM table1WHERE name = 'xxx'; MAX函数MAX()函数用于返回列中的最大值。它忽略列值为空的行。 对非数值数据使用MAX()，虽然它一般用来找出最大的数值或日期，但MySQL允许将它用来返回任意列中的最大值，包括返回文本列中的最大值。在用于文本数据时，如果数据按相应的列排序，则它返回最后一行。 12SELECT MAX(column1), MAX(column2)FROM table1; MIN函数MIN()函数返回指定列的最小值。它也会忽略列值为空的行。 对于非数值的使用，它与MAX类似。MySQL允许将它用来返回任意列中的最小值，包括返回文本列中的最小值。在用于文本数据时，如果数据按相应的列排序，则它返回最前面的行。 12SELECT MIN(column1)FROM table1; SUM函数SUM()用来返回特定列值的和。它也可以用来合计计算值。SUM()函数忽略列值为NULL的行。 1234567SELECT SUM(price) AS totalFROM table1;SELECT SUM(price*quantity) AS totalFROM table1WHERE xxx; 聚集不同值对于以上5个聚集函数，都可以使用如下: 对所有的行执行计算，指定ALL参数或不给参数； 只包含不同的值，使用DISTINCT参数； ALL为默认。 12SELECT AVG(DISTINCT price) AS avg_priceFROM table1; 组合聚集函数SELECT语句可以根据需要包含多个聚集函数。 12345SELECT COUNT(*), MIN(price), MAX(price), AVG(price) AS avg_priceFROM table1; 分组数据本章介绍如何分组数据，以便能汇总表内容的自己。这涉及到GROUP BY子句和HAVING子句。 数据分组分组允许把数据分为多个逻辑组，以便能对每个组进行聚集计算。 创建分组在SELECT语句中使用GROUP BY子句建立分组。使用GROUP BY的一些重要规定: GROUP BY可以包含任意数目的列。这使得能对分组进行嵌套，分数据分组提供更细致的控制； 如果在GROUP BY子句中嵌套了分组，数据将在最后规定的分组上进行汇总； GROUP BY子句中列出的每个列都必须是检索列或有效的表达式； 除聚集计算语句外，SELECT语句中的每个列都必须在GROUP BY子句中给出； 如果分组列中具有NULL值，则NULL将作为一个分组返回。如果列中有多行NULL值，它们将分为一组； GROUP BY子句必须出现在WHERE子句之后，ORDER BY子句之前； 使用WITH ROLLUP关键字，可以得到每个分组以及每个分组汇总界别的值。 123SELECT id, SUM(score)FROM table1GROUP BY id; 过滤分组除了能用GROUP BY分组数据外，MySQL还允许过滤分组。规定包括哪些分组、排除哪些分组。因为WHERE过滤指定的是行而不是分组，所以MySQL为此提供了另外的子句——HAVING。它非常类似于WHERE，事实上，目前为止所学过的所有类型的WHERE子句都可以用HAVING来替代。唯一差别是WHERE过滤行，而HAVING过滤分组。 HAVING支持所有WHERE操作符；WHERE在数据分组前进行过滤，它排除的行不包括在分组中；HAVING在数据分组后进行过滤。 1234567891011SELECT id, SUM(score)FROM table1GROUP BY idHAVING SUM(score) &gt;= 200;SELECT id, SUM(score)FROM table1WHERE id &gt; 10GROUP BY idHAVING SUM(score) &gt; 200; 分组和排序虽然GROUP BY和ORDER BY经常完成相同的工作，但它们非常不同。一般在使用GROUP BY子句时，应该也给出ORDER BY子句。这是保证数据正确包旭的唯一方法。 123456SELECT id, SUM(score)FROM table1WHERE id &gt; 10GROUP BY idHAVING SUM(socre) &gt; 200ORDER BY SUM(score) DESC; SELECT子句顺序 子句 说明 是否必须使用 SELECT 要返回的列或表达式 是 FROM 从中检索数据的表 仅在从表选择数据时使用 WHERE 行级过滤 否 GROUP BY 分组说明 仅在按组计算聚集时使用 HAVING 组级过滤 否 ORDER BY 输出排序顺序 否 LIMIT 要检索的行数 否 子查询本章介绍什么是子查询以及如何使用它们。 子查询SELECT语句是SQL的查询。从单个数据库表中检索数据的单条SELECT语句是简单查询。 SQL还允许创建子查询(subquery)——即嵌套在其它查询中的查询。 利用子查询进行过滤把一条SELECT语句的返回结果用于另一条SELECT语句的WHERE子句。 12345678910111213# 将复杂的子查询分解为多行并进行适当缩进，能极大简化子查询的使用SELECT id, scoreFROM table1WHERE id IN (SELECT Sid FROM table2);SELECT id, nameFROM table1WHERE id IN (SELECT Sid FROM table2 WHERE Score IN (SELECT Score FROM table3)); 在WHERE子句中使用子查询能够编写出功能很强并且灵活的SQL语句。对于嵌套的子查询数目没有限制，不过在实际使用时由于性能的限制，不建议嵌套太多。请注意权衡子查询和性能。 作为计算字段使用子查询使用子查询的另一方法是创建计算字段。相关子查询(correlated subquery)，涉及外部查询的子查询。逐渐增加子查询来建立查询，用子查询测试和调试查询很有技巧性，特别是在这些语句的复杂性不断增加的情况下更是如此。 1234567SELECT name, score (SELECT COUNT(*) FROM table2 WHERE table2.id = table1.id)FROM table1ORDER BY name; 联结表本章介绍什么是联结，为什么要使用联结，如果编写使用联结的SELECT语句。 联结SQL最强大的功能之一就是能在数据检索查询的执行中联结(join)表。 在能够有效地使用联结之前，必须了解关系表以及关系数据库设计的一些基础知识。 关系表外键(foreign key)，为某个表中的一列，它包含另一个表的主键值，定义了两个表之间的关系。 可伸缩(scale)，能够不断适应增加的工作量而不失败。设计良好的数据库或应用程序称之为可伸缩性好(scale well)。 关系数据可以有效地存储和方便处理。因此，关系数据库的可伸缩性比菲关系数据库要好。 为什么要使用联结分解数据为多个表能更有效地存储，更方便地处理，并且具有更大的可伸缩性。但这些好处是有代价的。 如果数据存储在多个表中，怎样使用单条SELECT语句检索出数据？答案是使用联结。简单地说，联结是一种机制，用来在同一条SELECT语句中关联表，因此称之为联结。使用特殊的语法，可以联结多个表返回一组输出，联结在运行时关联表中正确的行。联结是由MySQL根据需要建立，它存在于查询的执行当中。 创建联结1234SELECT t1_name, t2_name, t2_priceFROM table1, table2WHERE t1.id = t2.idORDER BY t1_name, t2_name; 应该保证所有联结都有WHERE子句，否则MySQL经返回比想要的数据多得多的数据。 叉联结(cross join)，有时我们会听到返回称为叉联结的笛卡尔积的联结类型。 内部联结目前为止所用的联结称为等值联结(equijoin)，它基于两个表之间的相等测试。这种联结也称为内部联结。其实，对于这种联结可以使用稍微不同的语法来明确指定联结的类型。ANSI SQL规范首选INNER JOIN语法。 123SELECT t1_name, t2_name, t2_priceFROM table1 INNER JOIN t2ON t1.id = t2.id; 联结多个表SQL对一条SELECT语句中可以联结的表的数目没有限制，创建联结的基本规则也相同。 MySQL在运行时关联指定的每个表已处理联结，这种处理可能是非常耗费资源的，因此应该仔细，不要联结不必要的表。联结的表越多，性能下降的越厉害。 12345SELECT t2_name, t1_name, t2_price, quantityFROM table1, table2, table3WHERE table2.id = table1.id AND table3.id = table2.id AND num = xxx; 高级联结本章介绍如何对被联结的表使用表别名和聚集函数。 表别名SQL还允许给表名起别名: 缩短SQL语句； 允许在单条SELECT语句中多次使用相同的表； 表别名只在查询中使用，与列别名不同，它不返回到客户机。 12345SELECT name, contactFROM table1 AS t1, table2 AS t2, table3 AS t3WHERE t1.id = t2.id AND t3.num = t2.num AND id = 'xxx'; 不同类型的联结前面使用的称为内部联结或等值联结，除此之外，还有3中其它联结: 自联结 自然联结 外部联结 自联结使用自联结而不用子查询。自联结通常作为外部语句用来替代从相同表中检索数据时使用的子查询语句。虽然最终结果是相同的，但有时候处理联结比处理子查询快的多。应该试一下两种方法，以确定哪一种的性能更好。 12345678910111213141516# 子查询SELECT prod_id, prod_nameFROM productsWHERE vend_id = (SELECT vend_id FROM products WHERE prod_id = 'xxx')# 使用联结# 此查询中的两个表实际上是相同的表# 虽然这是合法的，但对products的引用具有二义性，因为MySQL不知道你引用的是products表中的哪个实例# 为了解决此问题，使用了表别名SELECT p1.prod_id, p2.prod_nameFROM products AS p1, products AS p2WHERE p1.vend_id = p2.vend_id AND p2.prod_id = 'xxx'; 自然联结无论何时对表进行联结，应该至少有一列出现在不止一个表中。标准的联结返回所有数据，甚至相同的列多次出现。自然联结排除多次出现，使每个列只返回一次。 12345678# 通配符只对第一个表使用。# 所有其它列明确列出，所以没有重复的列被检索出来。SELECT c.* o.order_num, o.order_date, oi.prod_id, oi.quantity, OI.item_priceFROM customers AS c, orders AS o, orderitems AS oiWHERE c.cust_id = o.cust_id AND oi.order_num = o.order_num AND prod_id = 'xxx'; 事实上，迄今为止我们建立的每个内部联结都是自然联结，很可能我们永远都不会用到不是自然联结的内部联结。 外部联结许多联结将一个表中的行与另一个表中的行相关联。但有时候会需要包含没有关联行的那些行。联结包含了那些在相关表中没有关联行的行，这种类型的联结称为外部联结。 在使用OUTER JOIN语法时，必须使用RIGHT或LEFT关键字指定包括其所有行的表。(（RIGHT指出的是OUTER JOIN右边的表，而LEFT指出的是OUTER JOIN左边的表)外部联结的类型，它们的唯一差别是所关联的表的顺序不同。 左外部联结 右外部联结 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 内部联结栗子SELECT Student.Id, Score.scoreFROM Student INNER JOIN ScoreON Student.Id = Score.Sid;+----+-------+| Id | score |+----+-------+| 1 | 80.0 || 1 | 90.0 || 1 | 99.0 || 2 | 70.0 || 2 | 60.0 || 2 | 80.0 |+----+-------+6 rows in set (0.00 sec)# 外部联结# LEFTSELECT Student.Id, Score.scoreFROM Student LEFT OUTER JOIN ScoreON Student.Id = Score.Sid;+----+-------+| Id | score |+----+-------+| 1 | 80.0 || 1 | 90.0 || 1 | 99.0 || 2 | 70.0 || 2 | 60.0 || 2 | 80.0 |+----+-------+6 rows in set (0.00 sec)# RIGHTSELECT Student.Id, Score.scoreFROM Student RIGHT OUTER JOIN ScoreON Student.Id = Score.Sid;+------+-------+| Id | score |+------+-------+| 1 | 80.0 || 1 | 90.0 || 1 | 99.0 || 2 | 70.0 || 2 | 60.0 || 2 | 80.0 || NULL | 80.0 || NULL | 80.0 || NULL | 80.0 |+------+-------+9 rows in set (0.01 sec) MySQL不支持简化字符*=和=*的使用，这两种操作在其它DBMS中很流行。 带聚合函数的联结聚合函数用来汇总数据。 123456789101112SELECT customers.cust_name, customers.cust_id, COUNT(orders.order_num) AS num_ordFROM customers INNER JOIN orders ON customers.cust_id = orders.cust_idGROUP BY customers.cust_id;SELECT customers.cust_name, customers.cust_id, COUNT(orders.order_num) AS num_ordFROM customers LEFT OUTER JOIN orders ON customers.cust_id = orders.cust_idGROUP BY customers.cust_id; 联结和联结条件联结及其使用要点: 注意所使用的联结类型； 保证使用正确的联结条件，否则将返回不正确的数据； 应该总是提供联结条件，否则会得出笛卡尔积； 在一个联结中可以包含多个表，甚至每个联结可以采用不同的联结类型。虽然这样做合法也很有用，但应该在一起测试它们之前，分别测试每个联结。 组合查询本章讲述如何利用UNION操作符将多余SELECT语句组合成一个结果集。 组合查询多数SQL查询都只包含从一个或多个表中返回数据的单条SELECT语句。MySQL也允许执行多个查询(多条SELECT语句)，并将结果作为单个查询结果集返回。这些组合查询通常称为并(union)或符合查询(compound query)。 有两种基本情况，需要使用组合查询: 在单个查询中从不同的表返回类似结构的数据； 对单个表执行多个查询，按单个查询返回数据。 组合查询和多个WHERE条件。多数情况下，组合相同表的两个查询完成的工作与具有多个WHERE子句条件的单挑插叙完成的工作相同。换句话说，任何具有多个WHERE的SELECT语句都可以作为一个组合查询给出。 为了使表述简单，本章栗子的组合查询使用相同的表。但是UNION组合查询可以使用不同的表。 创建组合查询可用UNION操作来组合数条SQL查询。 使用UNION在各条SELECT语句之间放上关键字UNION。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849SELECT Sid, scoreFROM ScoreWHERE score &gt;= 80;+-----+-------+| Sid | score |+-----+-------+| 01 | 80.0 || 01 | 90.0 || 01 | 99.0 || 02 | 80.0 || 03 | 80.0 || 03 | 80.0 || 03 | 80.0 |+-----+-------+SELECT Sid, scoreFROM Score WHEREscore IN (60, 70);+-----+-------+| Sid | score |+-----+-------+| 02 | 70.0 || 02 | 60.0 |+-----+-------+# 使用UNION组合这两条语句SELECT Sid, scoreFROM ScoreWHERE score &gt;= 80UNIONSELECT Sid, scoreFROM Score WHEREscore IN (60, 70);+-----+-------+| Sid | score |+-----+-------+| 01 | 80.0 || 01 | 90.0 || 01 | 99.0 || 02 | 80.0 || 03 | 80.0 || 02 | 70.0 || 02 | 60.0 |+-----+-------+ UNION规则在进行UNION操作是有几条规则需要注意: UNION必须由两条或两条以上的SELECT语句组成，语句之间用关键自UNINO分隔； UNION中的每个查询必须包含先沟通的列、表达式或聚集函数； 列数据类型必须兼容，类型不必完全相同，但必须是DBMS可以隐含地转换的类型 包含或取消重复的行UNION从查询结果中自动去除了重复的行，这是UNION的默认行为。如果有需要想返回所有匹配行，可使用UNION ALL。 123456789101112131415161718192021SELECT Sid, scoreFROM ScoreWHERE score &gt;= 80UNION ALLSELECT Sid, scoreFROM ScoreWHERE score IN (60, 70);+-----+-------+| Sid | score |+-----+-------+| 01 | 80.0 || 01 | 90.0 || 01 | 99.0 || 02 | 80.0 || 03 | 80.0 || 03 | 80.0 || 03 | 80.0 || 02 | 70.0 || 02 | 60.0 |+-----+-------+ 对组合查询结果排序在使用UNION组合查询时，只能使用一条ORDER BY子句，并且它必须出现在最后一条SELECT语句之后。对于结果集，不存在用一种方式排序一部分，而又用另一种方式排序另一部分，因此不允许使用多条ORDER BY子句。 1234567891011121314151617181920SELECT Sid, scoreFROM ScoreWHERE score &gt;= 80UNIONSELECT Sid, scoreFROM ScoreWHERE score IN (60, 70)ORDER BY Sid, score;+-----+-------+| Sid | score |+-----+-------+| 01 | 80.0 || 01 | 90.0 || 01 | 99.0 || 02 | 60.0 || 02 | 70.0 || 02 | 80.0 || 03 | 80.0 |+-----+-------+ 全文本搜索本章将介绍如何使用MySQL的全文本搜索功能进行高级的数据查询和选择。 理解全文本搜索并非所有引擎都支持全文本搜索(FULLTEXT SEARCH)。MySQL最常用的两个引擎为MyISAM何InnoDB，前者支持全文本搜索，而后者不支持。 虽然LIKE通配符匹配和REGX正常匹配非常有用，但存在几个重要的限制: 性能，通配符和正则表达式通常要求MySQL尝试匹配表中所有行(而这些搜索极少使用表索引)。因此，由于被搜索的行数不断增加，这些搜索可能非常耗时； 明确控制，使用通配符和正则表达式匹配，很难明确地控制什么和不匹配什么； 智能化的结果，虽然基于通配符和正则表达式的搜索提供了非常灵活的搜索，但它们都不能提供一种智能化的选择结果的办法。 所有这些限制以及更多的限制都可用全文本搜索来解决。在使用全文本搜索时，MySQL不需要分别查看每个行，不需要分别分析和处理每个词。MySQL创建指定列中各词的一个索引，搜索可以针对这些词进行。这样，MySQL可以快速有效地决定哪些词匹配，哪些词不匹配，匹配的频率… 使用全文搜索为了进行全文搜索，必须索引被搜索的列，而且要随着数据的改变不断地重新索引。在对表列进行适当设计后，MySQL会自动进行所有的索引和重新索引。索引之后，SELECT可与Match()和Against()一起使用以实际执行搜索。 启用全文本搜索123456789# 创建MyISAM引擎表CREATE TABLE fulltextSearch( note_id int NOT NULL AUTO_INCREMENT, prod_id char(10) NOT NULL, note_date datetime NOT NULL, note_text text NULL, PRIMARY KEY(note_id), FULLTEXT(note_text) ) ENGINE=MyISAM CHARSET=utf8; 不要再导入数据时使用FULLTEXT。更新索引要花时间，虽然不是很多，但毕竟要花时间。如果正在导入数据到一个新表，此时不应该启用FULLTEXT索引。应该先导入所有数据，再修改表，定义FULLTEXT。 进行全文本搜索在索引之后，使用两个函数Match()(指定搜索的列)，Against()(指定要使用的搜索表达式)执行全恩搜索。 1234SELECT note_text, Match(note_text) Against('salah') AS rankFROM fulltextSearch; 使用查询扩展查询扩展用来设法放宽所返回的全文本搜索结果的范围。 在使用查询扩展时，MySQL对数据和索引进行两边扫描来完成搜索: 首先，进行一个基本的全文本搜索，找出与搜索条件匹配的所有行； 其次，MySQL检查这些匹配行并选择所有有用的词； 再其次，MySQL再次进行全文本搜索，这次不仅使用原来的条件，而且还是用所有有用的词。 利用查询扩展，能找出可能相关的结果，即使它们并不精确包含所查找的词。 12345678910# 简单栗子，没有扩展查询SELECT note_textFROM table1WHERE Match(note_text) Against('xxx');# 使用扩展查询SELECT note_textFROM table1WHERE Match(note_text) Against('xxx' WITH QUERY EXPANSION); 表中的行越多，使用查询扩展返货的结果越好。 布尔文本搜搜MySQL支持全文本搜索的布尔方式(bollean mode)。布尔方式即使某有FULLTEXT索引也可以使用。但这是一个非常缓慢的操作。 以布尔方式，可提供关于如下内容的细节: 要匹配的词； 要排斥的此；· 排列提示； 表达式分组； 另外一些内容。 123SELECT note_textFROM table1WHERE Match(note_text) Against('xxx' IN BOOLEAN NODE); 全文本布尔操作符: 布尔操作符 说明 + 包含，词必须存在 - 排除，词必须不出现 &gt; 包含，而且增加等级值 &lt; 包含，且减少等级值 () 把此排成子表达式 ~ 取消一个此的排序值 * 词尾的通配符 &quot;&quot; 定义一个短语 123456789101112131415-- 栗子-- 搜索包含rabbit和bait的行SELECT note_textFROM table1WHERE Match(note_text) Against('+rabbit +bait' IN BOOLEAN MODE);-- 没有指定操作符，匹配包含rabbit和bait中的至少一个词的行SELECT note_textFROM table1WHERE Match(note_text) Against('rabbit bait' IN BOOLEAN MODE);-- 匹配rabbit bait短语而不是两个词SELECT note_textFROM table1WHERE Match(note_text) Against('"rabbit bait"' IN BOOLEAN MODE); 全文本搜索的使用说明全文本搜索的某些重要说明: 在索引全文本数据时，短词(3个或3个以下字符的词)被忽略且从索引中排除； MySQL带有一个內建的费用次(stopword)列表，这些词在索引全文本数据时总是被忽略。如果需要，可覆盖这个列表； 许多次出现的频率很高，搜索它们没有用处。因此MySQL规定了一条50%规则，如果一个词出现在50%以上的行中，则将它作为一个非用词忽略。此规则不用于布尔方式； 如果表中的函数少于3行，则全文本搜索不反悔结果(因为每个词或者不出现，或者至少出现在50%的行中)； 忽略词中的单引号； 不具有词分隔符的语言不能恰当地返回全文本搜索结果； 仅在MyISAM引擎中支持全文本搜索 插入数据本章介绍如何利用SQL的INSERT语句将数据插入表中。 数据插入INSERT是用来插入(添加)行到数据库表的。插入有几种方式: 插入完整的行； 插入行的一部分； 插入多行； 插入某些查询的结果。 插入完整的行各个列必须以它们在表定义中出现的次序填充。 虽然这种语法很简单，但并不安全，应该尽量避免使用。下面的SQL语句高度依赖于表中列的定义次序，并且还依赖于其次序容易获得的信息。即使可得到这种次序信息，也不能保证下一次表结构变动后各个列完全保持相同的次序，因此，编写依赖于特定列次序的SQL语句是很不安全的。 1234567891011INSERT INTO table1VALUES(NULL, 'aaaa A, AA', 'abCD', 'ChengDu', '12345', 'xxx', NULL);# INSERT语句一般不会产生输出# 由于第一列id是自增，所以可以不给出值 更安全INSERT语句: 12345678910111213141516INSERT INTO table1( name, address, city, state, contact, email)VALUES( 'zhang', 'HighTech', 'Chengdu', 'SC', '15566668888', 'xxx@example.com'); 因为提供了列名，VALUES必须以其指定的次序匹配指定的列名，不一定按各个列出现在表中的次序。其优点是，即使表的结构发生改变，此INSERT语句仍然能够正确工作。你会发现id列的NULL值是不必要的，id列并没有出现在列表中，所以不需要任何值。当然，你也可以给出列名，并给出其NULL值。 123456789101112INSERT INTO table1( name, contact, email, address)VALUES( 'ZHANG', NULL, NULL, 'HighTect'); 总使用列的列表。一般不要使用没有明确给出列的列表的INSERT语句。使用列表能使SQL代码继续发挥作用，即使表结构发生了变化。 仔细地给出值。不管使用哪种INSERT语法，都必须给出VALUES的正确数目。如果不提供列名，则必须给每个表列提供一个值。如果提供列名，则必须对每个列出的列给出一个值。否则，将产生行插入不成功的错误消息。 省略列。如果表的定义允许，则可以在INSERT操作中省略某些列。省略的列必须满足以下某个条件: 该列定义为允许NULL值； 在表定义中给出默认值。如果不给出值，将使用默认值； 提高整体性能。INSERT操作可能很耗时(特别是有很多索引需要更新时)，而且它可能降低等待处理的SELECT语句的性能。如果数据检索是最重要的，你可通过在INSERT和INTO之间添加关键字LOW_PRIORITY，指示MySQL降低INSERT语句的优先级。这同样也适用于UPDATE和DELETE语句。 插入多行INSERT可以插入一行或多行到一个表中。有两种方式: 使用多条INSERT语句； 一条INSERT的多个值 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 多条INSERT INTO table1( name, address, city, state)VALUES( 'name1', 'hightec', 'cd', 'sc');INSERT INTO table1( name, city, state)VALUES( 'name2', 'cd', 'sc')# 单条INSERT INTO table1( name, address, city, state, country)VALUES( 'NAME1', 'HIGHTEC', 'CD', 'SC', 'CN'), ( 'NAME2', 'HIGHTEC', 'CD', 'SC', 'CN'); 提高INSERT的性能。此技术可提高数据库处理的能力，因为MySQL用单条INSERT语句处理多个插入比使用多条INSERT语句快。 插入检索的数据INSERT可将一条SELECT语句的结果插入表中，这称为INSERT SELECT，顾名思义，它由一条INSERT语句和一条SELECT语句组成。 1234567891011121314151617181920INSERT INTO table1( id, contact, email, name, address, city, state, country)SELECT id, contact, email, name, address, city, state, countryFROM table2WHERE name = 'zhang21'; INSERT SELECT中的列名，为了简单起见，此例子中使用了相同的列名。但其实不一定要求列名匹配。 更新和删除数据本章介绍如何利用UPDATE语句和DELETE语句进一步操控表数据。 更新数据有两种方式使用UPDATE: 更新表中特定行； 更新表中所有行。 基本的UPDATE语句由3部分组成: 要更新的表； 列名和它们的新值； 确定要更新行的过滤条件。 不要省略WHERE子句。在使用UPDATE时一定要注意细心。因为稍有不注意，就会更新表中的所有行。 UPDATE与安全。可以限制和控制UPDATE语句的使用。 12345678910111213141516-- 更新单列UPDATE table1SET email = 'beef@meat.com'WHERE id = 123 AND name = 'beef';# 更新多列UPDATE table1SET email = 'milk@drink.com', address = 'hightec'WHERE id = 123;# 为了删除某个列的值，可将其设置为NULLUPDATE table1SET email = NULLWHERE id = 123; 在UPDATE语句中使用子查询。UPDATE语句可以使用子查询，使得能用SELECT语句检索出的数据更新列数据。 1234567UPDATE table1SET zip = (SELECT zip FROM table2 WHERE id = 111)WHERE id = 111;UPDATE table1SET zip = '646100'WHERE id = (SELECT id FROM table2 WHERE zip = '646100'); IGNORE关键字。如果用UPDATE语句更新多行，并且在更新这些行中的一行或多行时出现一个错误，则整个UPDATE操作被取消。而使用IGNORE关键字，这可以忽略错误，继续执行。 1UPDATE IGNORE table1 ... 删除数据有两种方式使用DELETE: 从表中删除特定的行； 从表中删除所有行。 不要省略WHERE子句。在使用DELETE时一定要注意细心。因为稍不注意，就会错误地删除表中所有行。 DELETE与安全。可以限制和控制DELETE语句的使用。 删除表的内容而不是表。DELETE语句从表中删除行，甚至是表中所有行。但是，DELETE不删除表本身。 更快地删除。如果想从表中删除所有行，不要使用DELETE。可使用TRUNCATE TABLE语句，它完成相同的工作，但速度更快。(它实际是删除原来的表并重新创建一个表，而不是逐行删除表中的数据)。 12DELETE FROM tableWHERE id = 123 AND name = 'beef'; DELETE不需要列名或通配符，以为它删除整行而不是删除列。为了删除指定的列，请使用UPDATE语句。 更新和删除的指导原则UPDATE语句和DELETE语句都使用了WHERE子句，这样做的理由很充分。如果省略了WHERE子句，则UPDATE或DELETE操作将应用到表中所有行。 下面是SQL使用者在使用UPDATE和DELETE语句时应该遵循的习惯: 请一定使用带WHERE子句的UPDATE或DELETE语句； 保证每个表都有主键，尽可能像WHERE子句那样使用它； 在对UPDATE或DELETE语句使用WHERE子句前，应先使用SELECT进行测试，以保证它过滤的是正确的记录； 使用强制实施完整性的数据库，这样MySQL将不允许删除具有与其它表相关联的数据的行； 一定要小心操作，MySQL没有撤销按钮。 创建和操作表本章介绍表的创建、更改和删除的基本知识。 创建表一般有两种创建表的方法: 使用交互式创建和管理表的工具； 直接使用MySQL语句操纵。 利用CREATE TABLE语句创建表，必须给出下列信息: 新表的名字； 表列的名字和定义。 1234567891011121314-- HELP CREATE TABLE;# CREATE TABLE tablename IF NOT EXISTSCREATE TABLE tablename( id int NOT NULL AUTO_INCREMENT, name char(50) NOT NULL , address char(50) NULL , country char(20) NULL DEFAULT CN, email char(255) NULL , texts text NULL , PRIMARY KEY (id), FULLTEXT(texts)) ENGINE=InnoDB CHARSET=utf8mb4; 关于上面创建表语句的一些解释: MySQL忽略空格，所以建议进行适当的缩进(格式化)以方便阅读； 在创建新表时，指定的表名必须不存在，否则将出错； 如果你仅想创建一个不存在的表， 应该在表后面给出IF NOT EXISTS; NULL值就是没有值或缺值 允许NULL值的列也允许在插入行时不给出该列的值； 不允许NULL值的列不接受没有值的行，也就是必须要有值。 注意理解NULL值和空串(&#39;&#39;，两个单引号，中间没有字符)。空串是一个有效的值，而不是无值； 主键必须唯一 如果主键使用单个列，则它的值必须唯一； 如果主键使用多个列，则这些列的组合值必须唯一； 主键中只能使用不允许NULL值的列。允许NULL值的列不能作为唯一标识。 自增(AUTO_INCREMENT)告诉MySQL，本列每当增加一行 时自动增量。每个表只允许一个自增列，而且它必须被索引。当然，你也可以在插入语句中指定它的值，只要这个值是唯一的即可。后续的增量将开始使用该手工插入的值。让MySQL生成主键的一个缺点就是你不知道这些值是谁； 指定默认值。如果在插入行时没有给出值，MySQL允许指定此时使用的默认值。使用DEFAULT关键字指定。默认值只支持常量； 数据库引擎。如果忽略，则默认为InnoDB InnoDB是一个可靠地事务处理引擎； MEMORY在功能等同于MyISAM，速度很快(特别适合临时表)； MyISAM是一个性能极高的引擎，它支持全文搜索。 更新表为更新表定义，可使用ALTER TABLE语句。但是，理想状态下，当表中存储数据以后，该表就不应该再被更新。在表的设计过程中需要花费大量时间来考虑，以便后期不贵该表进行大的改动。 小心使用ALTER TABLE。应该在进行表结构改动之前做一个完整的备份。数据表的更改不能撤销。如果增加了不需要的列，可能不能删除它们。类似地，如果删除了不应该删除的列，可能会丢失该列中的所有数据。 使用ALTER TABLE必须给出以下信息: 必须存在的表名； 所做更改的列表。 123456789-- HELP ALTER TABLE;# 给表添加一个列ALTER TABLE tablenameADD add_line1 CHAR(20) NULL ,# 删除表列ALTER TABLE tablenameDROP COLUMN add_line1; ALTER TABLE的一种常见用途是定义外键。 1234567ALTER TABLE orderitemsADD CONSTRAINT fk_orderitems_ordersFOREIGN KEY(order_num) REFERENCE orders(order_num);ALTER TABLE ordersADD CONSTRAINT fk_orders_customersFOREIGN KEY(cust_id) REFERENCE customers(cust_id); 复杂的表结构一般需要手动删除过程，它涉及: 用新的列布局创建一个新表； 使用INSERT SELECT语句从旧表复制数据到新表； 检验包含所需数据的新表； 重命名旧表； 用旧表原来的名字重命名新表； 根据需要，重新创建触发器、存储过程、索引和外键。 删除表删除表(删除整个表而不是其内容)，使用DROP TABLE语句。删除表没有确认，也不能撤销，执行这条语句将会永久删除该表。 123-- HELP DROP TABLE;DROP TABLE tablename; 重命名表使用RENAME TABLE语句可以重命名一个表。 1234567-- HELP RENAME TABLE;RENAME TABLE oldname TO newname;# 重命名多个表RENAME TABLE oldname1 TO newname1, oldname2 TO newname2; 视图本章将介绍视图是什么，它们怎样工作，何时使用它们。 视图不建议对视图进行更新，因为视图主要用于数据检索，而非更改。 视图(view)是虚拟的表。与包含数据的表不一样，视图只包含使用时动态检索数据的查询。 来看个栗子:12345678910111213/* 任何需要这个数据的人都必须理解相关表的结构， 并且知道如何查询和对表进行联结。 */SELECT cust_name, cust_contactFROM customers, orders, orderitemsWHERE customers.cust_id = orders.cust_id AND orderitems.order_num = orders.order_num AND prod_id = 'TNT2';/* 假如把整个查询包装成一个名为productcustomers的虚拟表，则可轻松检索出相同的数据。 作为视图，它不包含表中应该有的任何列或数据，它包含的是一个SQL查询。 */SELECT cust_name, cust_contactFROM productcustomersWHERE prod_id = 'TNT2'; 为什么使用视图视图的常见应用: 重用SQL语句； 简化复杂的SQL操作。在编写查询后，可以方便地重用它而不必知道它的基本查询细节； 使用表的组成部分而不是整个表； 保护数据。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限； 更改数据格式和表示。视图可返回与底层表的标识和格式不同的数据。 在视图创建之后，可以用与表基本相同的方式利用它们。可以对视图执行SELECT操作，过滤和排序，将视图联结到其它视图或表，甚至还能添加和更新数据。 重要的是知道视图仅仅是用来查看存储在别处的数据的一种设施。视图本身不包含数据，因此它们返回的数据是从其它表中检索出来的。在添加或更改这些表中的数据时，视图将返回改变过的数据。 性能问题因为视图不包含数据，所以每次使用视图时，都必须处理查询执行时所需的任一个检索。如果你用多个联结和过滤创建了复杂的视图或嵌套了视图，可能会发现性能下降得很厉害。因此，在部署使用了大量视图的应用前，应该进行测试。 视图的规则和限制视图创建和使用的一些最常见的规则和限制: 视图必须唯一命名(不能与其它视图或表同名)； 对于可以创建的视图数目没有限制； 为了创建视图，必须具有足够的访问权限； 视图可以嵌套，即可从其它视图中检索数据的查询来构造一个视图； ORDER BY可用在视图中，但如果该视图检索数据SELECT中也含有ORDER BY，那么该视图中的ORDER BY将被覆盖； 视图不能索引，也不能有关联的触发器或默认值； 视图可以和表一起使用。 使用视图 使用CREATE VIEW viewName创建视图； 使用SHOW CREATE VIEW viewName查看创建视图的语句； 使用DROP VIEW viewName删除视图； 更新视图时，可以先用DROP再用CREATE，也可以直接使用CREATE OR REPLACE VIEW。 利用视图简化复杂的联结视图最常见的应用之一是隐藏复杂的SQL，这通常会涉及联结。 12345678910111213141516171819-- 这是不使用AS会报错CREATE VIEW productcustomers ASSELECT cust_name, cust_contact, prod_idFROM customers, orders, orderitemsWHERE customers.cust_id = order.cust_id AND orderitems.order_num = orders.order_num;# 查看视图SHOW VIEW productcustomers;# 此视图包含上面检索出来的三列内容DESCRIBE productcustomers;SHOW COLUMNS FROM productcustomers;# 检索的结果也是这三列SELECT * FROM productcustomers;# 这里注意，如果创建视图中使用的源表数据发生更新或变动，则视图也会相应的发生改变 用视图重新格式化检索出的数据视图的另一常见用途是重新格式化检索出的数据。 1234567891011121314-- 例如要经常使用拼接列SELECT Concat(RTrim(name), '(', RTrim(contry), ')') AS titleFROM table1ORDER BY name;-- 不必在每次需要时执行联结，创建一个视图每次需要时使用它即可CREATE VIEW viewLocation ASSELECT Concat(RTrim(name), '(', RTrim(country), ')') AS titleFROM table1ORDER BY name;-- 检索SELECT *FROM viewLocation; 使用视图过滤不想要的数据视图对于应用普通的WHERE子句也很有用。 如果从视图检索数据时使用了WHERE子句，则两组WHERE子句(传递给视图的和视图自身的)将自动组合。 12345678910-- 栗子CREATE VIEW customerEmailList ASSELECT id, name, emailFROM table1WHERE email IS NOT NULL;SELECT *FROM customerEmailListWHERE id = 111; 使用视图与计算字段视图对于简化计算字段的使用特别有用。 123456789101112-- 栗子CREATE VIEW viewTotal ASSELECT id, num, quantity, item_price, quantity*item_price AS total_priceFROM table1;SELECT *FROM viewTotalWHERE id = 123; 更新视图通常，视图是可更新的(即对它使用INSERT, UPDATE, DELETE)。更新一个视图将更新其基表。如果你对视图增加或删除行，实际上是对其基表增加或删除行。 但是，并非所有视图都是可更新的。如果MySQL不能正确地确定被更新的基数据，则不允许更新、插入和删除。如果视图定义中有以下操作: 分组(GROUP BY, HAVING)； 联结； 子查询； 并； 聚集函数(MIN(), COUNT()...)； DICTINCT; 导出(计算)列。 不建议对视图进行更新，因为视图主要用于数据检索，而非更改。 存储过程本章介绍什么是存储过程，为什么要使用存储过程以及如何使用存储过程… 存储过程迄今为止，使用的大多数SQL语句都是以针对一个/多个表的单条语句。并非所有操作都这么简单，经常会有一个完整的操作需要多条语句才能完成。 可以创建存储过程。存储过程简答来说，就是为以后的使用而保存的一条或多条MySQL语句的集合。可将其视为批文件，虽然它们的作用不仅限于批处理。 为什么要使用存储过程使用它的一些主要理由: 通过把处理封装在容易使用的单元中，简化复杂的操作； 由于不要求反复建立一系列处理步骤，这保证了数据的完整性； 简化对变动的管理； 提高性能； 存在一些职能用在单个请求中的MySQL元素和特性，存储过程可以使用它们来编写功能更强更灵活的代码； 一般来说，存储过程的编写比基本SQL语句更复杂，编写存储过程需要更高的技能，更丰富的经验； 你可能没有创建存储过程的安全访问权限。 MySQL将编写存储过程与执行存储过程的安全和访问分开来。即使你没有权限编写存储过程，也可在适当的时候执行别的存储过程。 使用存储过程使用存储过程需要知道如何执行和创建它们。 创建存储过程1234567-- HELP CREATE PROCEDURE;CREATE PROCEDURE procedureTest()BEGIN SELECT Avg(price) AS priceAvg FROM table1;END;# BEGIN, END语句用来限定存储过程体 注意MySQL命令行的分隔符，如果使用MySQL命令行实用程序，请仔细阅读此说明。 默认的MySQL语句分隔符为;，MySQL命令行实用程序也是用;作为语句分隔符。如果命令行实用程序要解释存储过程自身内的;字符，则它们最终不会成为存储过程的成分，这会使存储过程的SQL出现语法错误。解决办法是临时修改命令行实用程序的语句分隔符。 123456789101112-- 除了\(转义字符)，其它都可作为语句分隔符-- 临时修改MySQL分隔符DELIMITER //CREATE PROCEDURE procedureTest()BEGIN SELECT Avg(price) AS priceAvg FROM table1;END //-- 恢复MySQL默认分隔符DELIMITER ; 执行存储过程CALL语句接受存储过程以及需要传递给它的参数。 存储过程实际上是一种函数，所以后面需要有括号()。 12-- 栗子CALL procedureTest(); 删除存储过程12-- 如果过程不存在，则删除会产生一个错误DROP PROCEDURE procedureTest; 使用参数一般，存储过程并不显示结果，而是把结果返回给你指定的变量。变量是内存中一个特定的位置，用来临时存储数据。MySQL的变量都必须以@开始。 MySQL支持三种类型的参数: IN，传递给存储过程 OUT，从存储过程传出 INOUT，对存储过程传入和传出 123456789101112131415161718192021222324252627282930313233343536-- 此存储过程接受三个参数CREATE PROCEDURE procedureTest2( OUT pl DECIMAL(8, 2), OUT ph DECIMAL(8, 2), OUT pa DECIMAL(8, 2))BEGIN SELECT Min(price) INTO pl FROM table1; SELECT Max(price) INTO ph FROM table1; SELECT Avg(price) INTO pa FROM table1;END;-- 执行CALL procedureTest2(@pricelow, @pricehigh, @priceaverage);SELECT @pricelow, @pricehigh, @priceaverage;-- 另一个栗子CREATE PROCEDURE orderTotal( IN onumer INT, OUT ototal DECIMA(8, 2))BEGIN SELECT Sum(item_price*quantity) FROM orderitems WHERE order_num = onumber INTO ototal;END;-- 执行CALL orderTotal(12345, @total);SELECT @total; 建立智能存储过程在存储过程内包含业务规则和智能处理时，它们的威力才真正显现出来。 12345678910111213141516171819202122232425262728293031323334353637# 栗子/* Name: ordertotal Parameter: onumber = order number taxable = 0 if not taxable, 1 if taxable ototal = order total variable */CREATE PROCEDURE ordertotal( IN onumber INT, IN taxable BOOLEAN, #布尔值1(true), 0(false) OUT ototal DECIMAL(8 , 2)) COMMENT 'Obtain order total, optinally adding tax.'BEGIN -- Declare variable for total DECLARE total DECIMAL(8, 2); -- Declare tax percentage DECLARE taxrate INT DEFAULT 6; -- Get the order total SELECT Sum(item_price*quantity) FROM orderitems WHERE order_num = onumber INTO total; -- Is this taxable? IF taxable THEN -- Yes, so add taxrate to the total SELECT total+(total/100*taxrate) INTO total; END IF; -- And finally, save to out varible SELECT total INTO ototal;END;-- 执行CALL ordertotal(12345, 0, @total);SELECT @total; 检查存储过程1234567-- 显示创建存储过程SHOW CREATE PROCEDUTE xxx;-- 获得存储过程详细信息SHOW PROCEDURE STATUS;SHOW PROCEDURE STATUS LIKE 'procedureTest1'; 游标本章将介绍任何是游标，如何使用游标。 游标MySQL检索操作返回一组称为结果集的行。但没有办法得到某些行，也不存在每次一行地处理所有行的简单方法。有时，需要在检索出来的行中前进或后退一行或多行。这就是使用游标(cursor)的原因。 游标(cursor)，是一个存储在MySQL服务器上的数据库查询，它不是一条SELECT语句，而是被该语句检索出来的结果集。在存储了游标之后，应用程序可以根据需要滚动或浏览其中的数据。游标主要用于交互式应用，其中用户需要滚动屏幕上的数据，并对其数据进行浏览或做出更改。不像其它DBMS，MySQL的游标只能用于存储过程(和函数)。 使用游标使用游标的几个明确步骤: 在使用游标前，必须声明它(DECLARE)。此过程并没有检索数据，它只是定义要使用的SELECT语句； 一旦声明后，必须打开(OPEN)游标以供使用。此过程用前面定义的SELECT把数据检索出来； 对于填有数据的游标，根据需要取出各行； 在结束游标使用时，必须关闭(CLOSE)游标。 创建游标DECLARE语句创建游标，并定义相应的SELECT语句，根据需要带WHERE和其它子句。 12345678-- 游标栗子CREATE PROCEDURE procedureTest()BEGIN DECLARE numberCursor CURSOR FOR SELECT number FROM table1;END; 打开和关闭游标123456789-- 打开游标-- 在处理OPEN语句时执行查询，存储检索出的数据以供浏览和滚动OPEN numberCursor;-- 关闭游标-- CLOSE释放游标使用的所有内部内存和资源，因此在每个游标不再需要时都应该关闭CLOSE numberCursor;-- 一个游标关闭后，如果没有重新打开，则不能使用它 如果你不明确关闭游标，MySQL将会在到达END语句是自动关闭它。 1234567891011121314-- 此存储过程声明、打开和关闭一个游标，但对检索出的数据什么也没做。CREATE PROCEDURE procedureTest()BEGIN DECLARE numberCursor CURSOR FOR SELECT number FROM table1; -- OPEN OPEN numberCursor; -- CLOSE CLOSE numberCursor;END; 使用游标数据游标打开后，可使用FETCH语句分别访问它的每一行。它指定检索什么数据，检索出的数据存储在什么地方。它还向前移动游标的内部行指针，是下一条FETCH语句检索下一行。 12345678910111213CREATE PROCEDURE procedureTest()BEGIN DECLARE o INT; DECLARE numberCursor CURSOR FOR SELECT number FROM table1; OPEN numberCursor; FETCH numberCursor INTO o; CLOSE numberCursor;END; 触发器本章介绍什么是触发器，为什么要使用触发器，如何使用触发器。 介绍MySQL语句在需要时被执行，存储过程也是如此。但是，如果你想要某条语句(某些语句)在事件发生时自动执行，怎么办？例如: 检查每次新增的电话号码格式是否正确 检查大小写 每卖出一个产品时，都从库存中减去订购的数量 无论何时删除一行，都在某个存档表中保留一个副本 这些例子的共同之处是它们都需要在某个表发生更改时自动处理。这确切地说就是触发器(trigger)。触发器是MySQL响应一下任意语句而自动执行的一条MySQL语句(或位于BEGIN和END语句之间的一组语句): DELETE INSERT UPDATE 其它MySQL语句不支持触发器。 只有表才支持触发器。 创建触发器创建触发器时，需要给出4条信息: 唯一的触发器名； 触发器关联的表； 触发器应该响应的活动(DELETE, INSERT, UPDATE)； 触发器何时执行(BEFORE或AFTER)。 123456789-- HELP CREATE TRIGGER;CREATE TRIGGER triggerTest -- 创建新触发器 AFTER INSERT ON table1 -- 触发器将在INSERT 表table1成功执行后执行 FOR EACH ROW -- 对每个插入行执行 SELECT 'table1 added' INTO @triggerInfo; -- 对每个插入显示一次，MySQL v5+ 需要使用变量来实现# 查看SHOW TRIGGERS; 删除触发器触发器不能更新或覆盖。为了修改一个触发器，必须先删除然后重新创建。 1DROP TRIGGER triggerTest; 使用触发器三种触发器: INSERT UPDATE DELETE INSERT触发器INSERT触发器在INSERT语句执行之前(BEFORE)或之后(AFTER)执行。 在INSERT触发器代码内，可引用一个名为NEW的虚拟表，访问被插入的行； 在BEFORE INSERT触发器中，NEW中的值也可被更新(允许更改被插入的值)； 对于AUTO_INCREMENT列，NEW在INSERT执行之前包含0，在INSERT执行之后包含新的自动生成值。 UPDATE触发器UPDATE触发器在UPDATE语句执行之前或之后执行。 在UPDATE触发器代码中，你可引用一个名为OLD的虚拟表访问以前(UPDATE语句前)的值，引用一个名为NEW的虚拟表访问新更新的值； 在BEFORE UPDATE触发器中，NEW中的值也可被更新(允许更改将要用于UPDATE语句的值)； OLD中的值全都是只读的，不能更新。 1234567891011121314151617181920-- 以下保证name总为大写CREATE TRIGGER updateTable1 BEFORE UPDATE ON table1 FOR EACH ROW SET NEW.name = UPPER(NEW.name)-- 测试UPDATE table1SET name = 'NAme1'WHER id = 1;SELECT nameFROM table1WHERE id = 1;+-------+| name |+-------+| NAME1 |+-------+ DELETE触发器DELETE触发器在DELETE语句执行之前或之后执行。 在DELETE触发器代码内，你可引用一个名为OLD的虚拟表，访问被删除的行； OLD中的值全都是只读的，不能更新。 12345678910111213-- 使用OLD保存将要被删除的行到一个备份表-- 你需要创建一个与table1相同列的table1BAK表DELIMITER //CREATE TRIGGER deletetable1 BEFORE DELETE ON table1 FOR EACH ROWBEGIN INSERT INTO table1BAK(id, name, date) VALUES(OLD.id, OLD.name, OLD.date);END //DELIMITER ; 小技巧 创建触发器可能需要特殊的安全访问权限，但是，触发器的执行是自动的。如果INSERT, UPDATE, DELETE能够执行，则触发器也能执行； 应该使用触发器来保证数据的一致性(大小写、格式…)； 触发器的一种非常有意义的使用是创建审计跟踪； MySQL触发器中不支持CALL语句，这表示触发器不能调用存储过程。 事务处理本章介绍什么是事务处理，如何利用COMMIT和ROLLBACK语句来管理事务处理。 介绍并非所有存储引擎都支持事务处理。MyISAM不支持明确的事务处理管理 ，而InnoDB支持。 事务处理(transaction processing)，可以用来维护数据库的完整性，它保证成批的MySQL操作要么完全执行，要么完全不执行。 事务处理的几个术语: 事务(transaction)，指一组SQL语句； 回退(rollback)，指撤销指定SQL语句； 提交(commit)，指将未存储的SQL语句结果写入数据库表； 保留点(savepoint)，指事务处理中设置的临时占位符(placeholder)，你可以对它发布回退(与回退整个事务处理不同)。 控制事务处理管理事务处理的关键在于将SQL语句组分解为逻辑块，并明确规定数据很是应该回退，何时不应该回退。 12-- 标识事务的开始START TRANSACTION; 使用ROLLBACKMySQL的ROLLBACK命令用来回退(撤销)MySQL语句。它只能在一个事务处理内使用。事务处理可用来管理INSERT, UPDATE和DELETE语句。你不能回退CREATE或DROP操作。 123456SELECT * FROM talbe1; -- 显示该表不为空START TRANSACTION; -- 开始事务处理DELETE FROM table1; -- 删除整个表内容SELECT * FROM table1; -- 检索空表ROLLBACK; -- 回退开始事务之后的所有语句SELECT * FROM table1; -- 检索表，所有信息又回来了 隐含地事务关闭。当COMMIT或ROLLBACK语句执行后，事务会自动关闭。 使用COMMIT一般的MySQL语句都是直接针对数据库表执行和编写的。这就是所谓的隐含提交(implicit commit)，即提交操作是自动进行的。 但在事务处理块中，提交不会隐含地进行。为进行明确的提交，使用COMMIT语句。 1234START TRANSACTION;DELETE FROM table1 WHERE id = 2010;DELETE FROM table2 WHERE id = 2010;COMMIT; -- 仅在不出错时写入更改，如果其中一条语句出错，则DELETE不会提交，即它自动撤销。 使用SAVEPOINT简单的ROLLBACK和COMMIT语句就可以写入或撤销整个事务处理。更复杂的事务处理可能需要部分提交或回退。 为了支持回退部分事务处理，必须能在事务处理块中何时的位置放置占位符。这样，如果需要回退，则可回退到某个占位符。这些占位符称为保留点。 123-- 创建占位符-- 使用唯一名字，以便知道回退到何处SAVEPOINT detele1; 保留点越多越好，这样便能进行灵活地回退。保留点在事务处理完成(COMMIT或ROLLBACK)后自动释放。也可使用RELEASE SAVEPOINT明确地释放保留点。 更改默认提交行为默认的MySQL行为是自动提交所有更改。 123-- 你可以设置MySQL不自动提交-- autocommit标志决定是否自动提交更改，不管有没有COMMIT语句SET autocommit=0; 字符集和校对本章介绍MySQL处理不同字符集和语言的基础知识。 字符集和校对顺序数据库被用来存储和检索数据。不同的语言和字符集需要以不同的方式存储和检索。因此，MySQL需要适应不同的字符集，适应不同的排序和检索数据的方法。 重要术语: 字符集，为字母和符号的集合； 编码，为某个字符集成员的内部表示； 校对，为规定字符如何比较的指令。 使用字符集和校对顺序MySQL支持众多的字符集。不同的表、不同的列口可以指定不同的字符集。 12345678910111213141516171819202122232425262728293031323334353637-- 查看完整的字符集SHOW CHARACTER SET;SHOW CHARACTER SET LIK 'utf8%';+---------+---------------+--------------------+--------+| Charset | Description | Default collation | Maxlen |+---------+---------------+--------------------+--------+| utf8 | UTF-8 Unicode | utf8_general_ci | 3 || utf8mb4 | UTF-8 Unicode | utf8mb4_general_ci | 4 |+---------+---------------+--------------------+--------+-- 默认字符集SHOW VARIABLES LIKE 'character%';+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | latin1 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | latin1 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+-- 默认校对SHOW VARIABLES LIKE 'collation%';+----------------------+-------------------+| Variable_name | Value |+----------------------+-------------------+| collation_connection | utf8_general_ci || collation_database | latin1_swedish_ci || collation_server | latin1_swedish_ci |+----------------------+-------------------+ 为表和列指定字符集: 123456-- 栗子CREATE TABLE tableTest( c1 INT, c2 VARCHAR(10), C3 VARCHAR(20) CHARACTER SET latin1 COLLATE latin1_general_ci) DEFAULT CHARACTER SET utf8mb4 COLLATE hebrew_general_ci; 安全管理本章将介绍mysql的访问控制和用户管理。 访问控制尽量权限最小化。除非必要，尽量不要使用root进行登录。不该在日常的MySQL操作中使用root用户。 管理用户注意理解MySQL中用户和账户的概念，账户为用户加权限。 12-- mysql.user表包含所用账户信息SELECT user FROM mysql.user; 创建用户12345-- 新建用户CREATE USER user1 IDENTIFIED BY 'user1-passwd';-- 重命名用户RENAME USER user1 TO User1; 删除用户12-- 删除用户账号及权限DROP USER User1; 设置权限新创建的用户没有分配权限，它们能登录MySQL，但不能看到数据。 GRANT至少需要以下信息: 要授予的权限； 被授予访问权限的库或表； 用户名。 GRANT和REVOKE可在几个层次上控制访问权限: 整个Server，使用GRANT ALL和REVOKE ALL; 整个Database，使用ON db.*; 特定的表，使用ON db.tableName; 特定的列; 特定的存储过程。 详细权限: 权限 描述 ALL 除GRANT OPTION外的所有权限 ALTER 修改表 ALTER ROUNTINE 修改和删除存储过程 CREATE 创建表 CREATE ROUTINE 创建存储过程 CREATE TEMPORARY TABLE 创建临时表 CREATE USER 创建、删除、重名用户和解除所有权限 CREATE VIEW 创建视图 DELETE 删除 DROP 删除表 EXECUTE 使用CALL和存储过程 FILE 使用SELECT INTO OUTFILE和LOAD DATA INFILE GRANT OPTION 使用GRANT和REVOKE INDEX 创建和删除索引 INSERT 插入 LOCK TABLES 锁表 PROCESS 使用SHOW FULL PROCESSLIST RELOAD 使用FLUSH REPLICATION CLIENT 服务器位置的访问 REPLICATION SLAVE 由复制从属使用 SELECT 检索权限 SHOW DATABASES 查看数据库 SHOW VIEW 查看视图 SHUTDOWN 关闭MySQL SUPER 使用CHANGE MASTER, KILL, LOGS, PURGE, MASTER, SET GLOBAL的超级权限 UPDATE 更新 USAGE 无访问权限 1234567891011121314151617181920-- 查看用户权限SHOW GRANTS FOR User1;+-----------------------------------+| Grants for User1@% |+-----------------------------------+| GRANT USAGE ON *.* TO 'User1'@'%' |+-----------------------------------+-- 添加权限-- HELP GRANT;-- 如果未指定主机，默认为%GRANT SELECT ON testDB.* TO 'User1'@'localhost';-- 多个权限GRANT SELECT, INSERT ON testDB.user1T TO 'User1'@'localhost';-- 解除权限-- HELP REVOKEREVOKE SELECT ON testDB.* FROM 'User1'@'localhost'; 修改密码12345-- 修改指定用户密码SET PASSWORD FOR User1 = Password('User-passwd');-- 不指定用户名，则修改自己密码SET PASSWORD = Password('My-passwd'); 数据库维护本章介绍常见的数据库维护。 备份数据可能的解决方案: mysqldump实用程序来备份； 可使用MySQL的BACKUP TABLE或SELECT INTO OUTFILE转储所有数据到某个外部文件，此外部文件必须不存在。使用RESTORE TABLE来还原。 为保证所有数据都被写到磁盘，可能需要在备份前刷新(FLUSH TABLES)。 进行数据库维护应该知道的一些语句: ANALYZE TABLE，用来检查表键是否正确； CHECK TABLE，用来针对许多问题对表进行检查: 如果MyISAM表访问产生不正确和不一致的结果，可能需要用REPAIR TABLE来修复相应的表。这条语句不应该经常使用； 如果bong一个表中删除大量数据，应该使用OPTIMIZE TABLE来回收所用的空间，从而优化表的性能。 123456789101112131415ANALYZE TABLE mysql.user;+------------+---------+----------+----------+| Table | Op | Msg_type | Msg_text |+------------+---------+----------+----------+| mysql.user | analyze | status | OK |+------------+---------+----------+----------+CHECK TABLE mysql.user;+------------+-------+----------+----------------------------------------------------------+| Table | Op | Msg_type | Msg_text |+------------+-------+----------+----------------------------------------------------------+| mysql.user | check | warning | 2 clients are using or haven't closed the table properly || mysql.user | check | status | OK |+------------+-------+----------+----------------------------------------------------------+ 诊断启动问题在排除系统启动问题时，首先应该用手动启动Server。使用以下几个重要的mysqld命令行选项: --help --safe-mode，装载减去某些最佳配置的Server； --verbose，显示全文本消息； --version，显示版本信息 查看日志主要日志有: 错误日志，可用--log-error命令行选项更改； 查询日志，可用--log命令行选项更改； 二进制日志， 可用--log-bin命令行选项更改； 慢查询日志，可用--log-slow-queries命令行选项更改。 在使用日志时，可使用FLUSH LOGS语句来刷新和重新开始所有日志文件。 改善性能本章将学习与MySQL性能有关的某些要点。 与性能相关的一些要点: 硬件； MySQL配置 SHOW VARIABLES; SHOW STATUS; 查看所有MySQL活动进程, SHOW PROCESSLIST; 可终止某个特定的进程，KILL $mysql-pid; 使用联结、并、子查询等查询方式，找出最佳的查询方法； 使用EXPLAIN语句让MySQL解释他将如何执行一条SELECT语句； 一般来说，存储过程比一条条地执行MySQL语句快； 应该总使用正确的数据类型； 绝不要检索比需求还有多的数据； 有的操作支持一个可选的DELAYED关键字； 在导入数据时，应该关闭自动提交。你可能还想删除索引，然后在导入完成后再重建索引； 必须索引数据库表以改善数据检索的性能； 索引改善数据检索的性能，但损害数据插入、删除和更新的性能； LIKE很慢，一般来说，最好使用FULLTEXT而不是LIKE； 数据库是不断变化的实体。之前优化好了，之后可能也会面目全非了； 记得查看MySQL官方文档。 数据类型本章介绍MySQL中不同的数据类型。 串最常用的数据类型是串，有两种基本串类型: 定长串：接受长度固定的字符串，其长度是在创建表时指定的。CHAR属于定长串类型； 变长串：存储可变长度的文本。有些具有最大定长，有些则是完全变长的。不管哪种，只有指定的数据得到保存(额外的数据不保存)，TEXT数据变长串类型。 既然变长数据类型这样灵活，为什么还要使用定长数据类型？因为性能。MySQL处理定长列远比处理变长列快的多。此外，MySQL不允许对变长列(或列的可变部分)进行索引。这会极大影响性能。 不管使用何种形式的串数据类型，请使用引号。 数据类型 描述 CHAR 1-255个字符的定长串。它的长度必须在创建时指定，否则MySQL假定为CHAR(1) ENUM 接受最多6K个串组成的一个预定义集合的某个串 LONGTEXT 与TEXT相同，但最大长度为4GB MEDIUMTEXT 与TEXT相同，但最大长度为16K SET 接受最多64个串组成的一个预定义集合的零个或多个串 TEXT 最大长度为64K的变长文本 TINYTEXT 与TEXT相同，但最大长度为255字节 VARCHAR 长度可变，最大不超过255字节。如果指定VARCHAR(n)，则可存储0-n个字符的变长串 你可能会认为电话号码和邮政编码等应该存储在数值字段中，但是，这样做确是不可取的。如果邮政编码为01234，则保存的数值为1234，实际上丢失了一位数字。需遵守的基本规则是，如果是数值计算，则应该存储在数值类型中；如果作为字符串使用，则应该保存在串数据类型中。 数值数据类型数据数据类型存储数值。注意有符号和无符号(UNSIGNED)也会影响存储范围。 数据类型 描述 BIT 位字段，1-64位 BIGINT 整数值，64位。有符号和无符号范围不同 BOOLEAN 布尔值，0或1 DECIMAL 精度可变的浮点数 DOUBLE 双精度浮点数 FLOAT 单精度浮点数 INT(INTEGER) 整数值，32位。有符号和无符号范围不同 MEDIUMINT 整数值，24位。有符合和无符号范围不同 REAL 4字节的浮点值 SMALLINT 整数值，16位。有符号和无符号范围不同 TINYINT 整数值，8位。有符号和无符号范围不同 数值不使用引号。MySQL中没有专门存储货币的数据类型，一般情况下使用DECIMA(8, 2)。 日期和时间类型MySQL使用专门的数据类型来存存储日期和时间。 数据类型 描述 DATE 日期格式为YYYY-MM-DD DATETIME DATE和TIME的组合 TIMESTAMP 功能呢DATETIME相同，但范围较小 TIME 时间格式为HH:MM:SS YEAR 2位数字，表示70(1970)-69(2069)，不推荐 4位数字，表示1901-2155年，推荐 二进制数据类型二进制数据类型可以存储任何数据，如图像、多媒体、字处理文档… 数据类型 描述 BLOB 最大长度位64KB MEDIUMBLOB 最大长度为16MB LONGBLOB 最大长度位4GB TINYBLOB 最大长度位255字节]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>MySQL</tag>
        <tag>RDS</tag>
        <tag>DBMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sysctl,ulimit以及/proc]]></title>
    <url>%2F2018%2F01%2F09%2Fsysctl%E3%80%81ulimit%E5%92%8Cproc%2F</url>
    <content type="text"><![CDATA[参考： sysctl命令 ulimit命令 ulimit、limits.conf、sysctl和proc文件系统 sysctl.conf学习和调优 sysctlsysctl 命令被用于在内核运行时动态地修改内核的运行参数，可用的内核参数在目录 /proc/sys 中。它包含一些Tcp/Ip堆栈和虚拟内存系统的高级选项，可以通过修改某些值来提高系统性能。 sysctl可以读取和设置超过五百个系统变量。sysctl变量的设置通常是字符串、数字或布尔型（布尔型用1表示yes，0表示no）。 sysctl - configure kernel parameters at runtime. 语法： 123#sysctl [options] [variable[=value]] [...]sysctl -w net.ipv4.tcp_syncookies=1 可以通过sysctl命令修改系统变量，也可以通过编辑sysctl.conf配置文件来修改系统变量。 sysctl.conf - sysctl preload/configuration file. 举个栗子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124vim /etc/sysct.conf# Controls source route verification# Default should work for all interfaces net.ipv4.conf.default.rp_filter = 1# net.ipv4.conf.all.rp_filter = 1# net.ipv4.conf.lo.rp_filter = 1# net.ipv4.conf.eth0.rp_filter = 1# Disables IP source routing# Default should work for all interfaces net.ipv4.conf.default.accept_source_route = 0# net.ipv4.conf.all.accept_source_route = 0# net.ipv4.conf.lo.accept_source_route = 0# net.ipv4.conf.eth0.accept_source_route = 0# Controls the System Request debugging functionality of the kernelkernel.sysrq = 0# Controls whether core dumps will append the PID to the core filename# Useful for debugging multi-threaded applicationskernel.core_uses_pid = 1# Increase maximum amount of memory allocated to shm# Only uncomment if needed# kernel.shmmax = 67108864# Disable ICMP Redirect Acceptance# Default should work for all interfacesnet.ipv4.conf.default.accept_redirects = 0# net.ipv4.conf.all.accept_redirects = 0# net.ipv4.conf.lo.accept_redirects = 0# net.ipv4.conf.eth0.accept_redirects = 0# enable Log Spoofed Packets, Source Routed Packets, Redirect Packets# Default should work for all interfacesnet.ipv4.conf.default.log_martians = 1#net.ipv4.conf.all.log_martians = 1# net.ipv4.conf.lo.log_martians = 1# net.ipv4.conf.eth0.log_martians = 1# Decrease the time default value for tcp_fin_timeout connectionnet.ipv4.tcp_fin_timeout = 25# Decrease the time default value for tcp_keepalive_time connectionnet.ipv4.tcp_keepalive_time = 1200# Turn on the tcp_window_scalingnet.ipv4.tcp_window_scaling = 1# Turn on the tcp_sacknet.ipv4.tcp_sack = 1# tcp_fack should be on because of sacknet.ipv4.tcp_fack = 1# Turn on the tcp_timestampsnet.ipv4.tcp_timestamps = 1# Enable TCP SYN Cookie Protectionnet.ipv4.tcp_syncookies = 1# Enable ignoring broadcasts requestnet.ipv4.icmp_echo_ignore_broadcasts = 1# Disable ping requestsnet.ipv4.icmp_echo_ignore_all = 1# Enable bad error message Protectionnet.ipv4.icmp_ignore_bogus_error_responses = 1# make more local ports available# net.ipv4.ip_local_port_range = 1024 65000# set TCP Re-Ordering value in kernel to 5net.ipv4.tcp_reordering = 5# Lower syn retry ratesnet.ipv4.tcp_synack_retries = 2net.ipv4.tcp_syn_retries = 3# Set Max SYN Backlog to 2048net.ipv4.tcp_max_syn_backlog = 2048# Various Settingsnet.core.netdev_max_backlog = 1024# Increase the maximum number of skb-heads to be cachednet.core.hot_list_length = 256# Increase the tcp-time-wait buckets pool sizenet.ipv4.tcp_max_tw_buckets = 360000# This will increase the amount of memory available for socket input/output queuesnet.core.rmem_default = 65535net.core.rmem_max = 8388608net.ipv4.tcp_rmem = 4096 87380 8388608 net.core.wmem_default = 65535net.core.wmem_max = 8388608net.ipv4.tcp_wmem = 4096 65535 8388608net.ipv4.tcp_mem = 8388608 8388608 8388608net.core.optmem_max = 40960 重新加载内核参数： 12345#-p, read values from filesysctl -p#-a, display all variablessysctl -a ulimit大多Unix-Like系统，都提供了限制每个进程和每个基本用户使用线程，文件和网络连接等系统资源的一些方法。 假设有这样一种情况，当一台Linux主机上同时登陆了10人，在资源无限制的情况下，这10个用户同时打开了500个文件。假设每个文件的大小有10M，这是系统的内存资源就会收到巨大挑战。但是任何一台主机的资源都不可能是无限的。所以，资源的合理配置和分配，不仅仅是保证系统可用性的必要条件，也与系统上软件运行的性能有着密不可分的联系。 ulimit是指每个user使用各种资源的限制值。ulimit 命令用来限制系统用户对shell资源的访问，它是一种简单并且有效的实现资源限制的方式。 ulimit的设置值是 per-process的，也就是说，每个进程都有自己的limits值； 使用ulimit进行修改，是立即生效的； ulimit只影响shell进程及其子进程，用户登出后失效； 修改ulimit设置之后，要重启程序修改值才会有效。可通过/proc文件系统查看运行进程当前的限制值; 使用ulimit对系统限制的改变在系统重启后都会恢复到默认值; 可以在profile中加入ulimit的设置，便能做到永久生效。 ulimit 用于限制 shell 启动进程所占用的资源，支持以下各种类型的限制： 所创建的内核文件的大小； 进程数据块的大小； Shell进程创建文件的大小； 内存锁住的大小； 常驻内存集的大小； 打开文件描述符的数量； 分配堆栈的最大大小； CPU时间； 单个用户的最大线程数； Shell进程所能使用的最大虚拟内存； 它支持硬资源(hard)和软资源(soft)的限制。 sort和hard hard：是指用户在任何时候都可以活动的进程的最大数量，这是上限。没有任何non-root进程能够增加hard ulimit； soft：是对会话或进程实际执行的限制，但任何进程都可以将其增加到hard ulimit的最大值。 设置ulimit可以在以下位置进行ulimit的设置： /etc/profile，所有用户有效，永久生效； ~/.bash_profile,当前用户有效，永久生效； 直接在控制台修改，当前用户有效，临时生效； 永久生效： 123vim /etc/profilevim ~/.bash_profile 临时生效： 12345678910111213141516171819202122232425ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 7170max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 1024pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 7170virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited#修改限定值ulimit -n 201400ulimit -t ulimited limits.conflimits.conf - configuration file for the pam_limits module limits.conf是pam_limits.so的配置文件，Linux PAM(Pluggable Authentication Modules，插入式认证模块)。突破系统默认限制，对系统资源有一定保护作用。 pam_limits模块对用户的会话进行资源限制，然后/etc/pam.d/下的应用程序调用pam_***.so模块。 limits.conf是针对用户，而sysctl.conf是针对整个系统参数配置。 一个shell的初始limits就是由pam_limits设定的，用户登录后，pam_limits会给用户的shell设定在limits.conf定义的值； pam_limits的设定值也是per-process； pam_limits的设置是 永久生效的。 配置limits.conf： 1vim /etc/security/limits.conf 举个栗子： 123456789#&lt;domain&gt; &lt;type&gt; &lt;item&gt; &lt;value&gt;#* soft core 0#* hard rss 10000#@student hard nproc 20#@faculty soft nproc 20#@faculty hard nproc 50#ftp hard nproc 0#@student - maxlogins 4 domain： username @groupname type： soft hard - item： core，限制内核文件的大小 date，最大数据大小 fsize，最大文件大小 memlock，最大锁定内存地址空间 nofile，打开文件的最大数目 rss，最大持久设置大小 stack，最大栈大小 cpu，以分钟为单位的最多CPU时间 nproc，进程的最大数目 as，地址空间限制 maxlogins，此用户允许登录的最大数目 value： item值的大小 /proc什么是/proc文件系统Linux内核提供了一种通过/proc文件系统，在运行时访问内核内部数据结构，改变内核设置的机制。 proc文件系统是一个伪文件系统，它只存在内存当中，不占用外部空间。它以文件系统的方式为访问系统内核数据的操作提供接口。 对/proc中内核文件的修改，针对的是整个系统的内核参数，修改后立即生效，但修改是 临时的，重启后失效。 /proc与sysctl.conf的对应关系修改/proc文件系统中的参数是临时的，但修改sysctl.conf的参数确是永久有效的。 配置文件sysctl.conf变量在/proc/sys下，其对应关系如下： 123456789#将文件名的 . 变为 /#/proc/sys/net/ipv4/icmp_echo_ignore_all#net.ipv4.icmp_echo_ignore_allecho 0 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_allvim /etc/sysctl.confnet.ipv4.icmp_echo_ignore_all = 0 /proc文件系统几个常用的内核文件 /proc/meminfo #内存信息 /proc/cpuinfo #CPU信息 /proc/sys/fs/file-max #文件打开数 /proc/sys/fs/file-nr #整个系统目前使用的文件句柄数量 /proc文件系统中文件的权限proc中的每个文件都有一组分配给它的非常特殊的文件许可权，并且每个文件属于特定的用户标识。 只读：任何用户都不能更改该文件，它用于表示系统信息 root写 root读 对/proc进行读写123456cat /proc/sys/net/ipv4/icmp_echo_ignore_all#0echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all#当然,也可是用sysctl来配置 /proc内核文件详解 /proc/buddyinfo 每个内存区中的每个order有多少块可用，和内存碎片问题有关 /proc/cmdline 启动时传递给kernel的参数信息 /proc/cpuinfo cpu的信息 /proc/crypto 内核使用的所有已安装的加密密码及细节 /proc/devices 已经加载的设备并分类 /proc/dma 已注册使用的ISA DMA频道列表 /proc/execdomains Linux内核当前支持的execution domains /proc/fb 帧缓冲设备列表，包括数量和控制它的驱动 /proc/filesystems 内核当前支持的文件系统类型 /proc/interrupts x86架构中的每个IRQ中断数 /proc/iomem 每个物理设备当前在系统内存中的映射 /proc/ioports 一个设备的输入输出所使用的注册端口范围 /proc/kcore 代表系统的物理内存，存储为核心文件格式，里边显示的是字节数，等于RAM大小加上4kb /proc/kmsg 记录内核生成的信息，可以通过/sbin/klogd或/bin/dmesg来处理 /proc/loadavg 根据过去一段时间内CPU和IO的状态得出的负载状态，与uptime命令有关 /proc/locks 内核锁住的文件列表 /proc/mdstat 多硬盘，RAID配置信息(md=multiple disks) /proc/meminfo RAM使用的相关信息 /proc/misc 其他的主要设备(设备号为10)上注册的驱动 /proc/modules 所有加载到内核的模块列表 /proc/mounts 系统中使用的所有挂载 /proc/mtrr 系统使用的Memory Type Range Registers (MTRRs) /proc/partitions 分区中的块分配信息 /proc/pci 系统中的PCI设备列表 /proc/slabinfo 系统中所有活动的 slab 缓存信息 /proc/stat 所有的CPU活动信息 /proc/sysrq-trigger 使用echo命令来写这个文件的时候，远程root用户可以执行大多数的系统请求关键命令，就好- 像在本地终端执行一样。要写入这个文件，需要把/proc/sys/kernel/sysrq不能设置为0。这个文件对root也是不可- 读的 /proc/uptime 系统已经运行了多久 /proc/swaps 交换空间的使用情况 /proc/version Linux内核版本和gcc版本 /proc/bus 系统总线(Bus)信息，例如pci/usb等 /proc/driver 驱动信息 /proc/fs 文件系统信息 /proc/ide ide设备信息 /proc/irq 中断请求设备信息 /proc/net 网卡设备信息 /proc/scsi scsi设备信息 /proc/tty tty设备信息 /proc/net/dev 显示网络适配器及统计信息 /proc/vmstat 虚拟内存统计信息 /proc/vmcore 内核panic时的内存映像 /proc/diskstats 取得磁盘信息 /proc/schedstat kernel调度器的统计信息 /proc/zoneinfo 显示内存空间的统计信息，对分析虚拟内存行为很有用 以下是/proc目录中进程N的信息： /proc/N pid为N的进程信息 /proc/N/cmdline 进程启动命令 /proc/N/cwd 链接到进程当前工作目录 /proc/N/environ 进程环境变量列表 /proc/N/exe 链接到进程的执行命令文件 /proc/N/fd 包含进程相关的所有的文件描述符 /proc/N/maps 与进程相关的内存映射信息 /proc/N/mem 指代进程持有的内存，不可读 /proc/N/root 链接到进程的根目录 /proc/N/stat 进程的状态 /proc/N/statm 进程使用的内存的状态 /proc/N/status 进程状态信息，比stat/statm更具可读性 /proc/self 链接到当前正在运行的进程]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>系统优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开源许可协议]]></title>
    <url>%2F2018%2F01%2F09%2F%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[当你为你的产品签发许可，你就是在出让自己的权利。不过，你仍拥有版权和专利（如果申请了专利）。许可的目的，是向使用你产品的人提供一定的权利。 不管产品是免费分发，还是出售，指定一份许可协议都非常有用。否则，对于免费，你相当于放弃了自己的所有权利，任何人都没有义务表明你的原始作者身份。对于出售，你将不得不花费比开发更多的精力用来处理授权问题。 而开源许可协议是这些事情变得简单，开发者很容易向一个项目贡献自己的代码，它还可以保护你原始作者的身份，使你至少获得认可。开源许可协议还可以阻止其它人将某个产品据为己有。 几大开源许可协议 GNU Project GNU是“GNU’s Not Unix”的递归缩写，发音为 /‘gnu:’/； GNU Project，是一个由自由软件集体协作项目，它的目标是创建一套完全自由的操作系统，称为GNU； GNU是一个自由操作系统，其内容软件完全以 GPL 方式发布，它的设计类似于Unix，但它不包含具有著作权的Unix代码。 GPLGNU(General Public Licence)，GNU通用许可协议(简称GPL)是广泛使用的免费软件许可证，也称为 copyleft，与copyright相对应。GPL保证了所有开发者的权利，同时为使用者提供了足够的复制、分发、修改的权利。 需要注意的是，分发的时候，需要明确提供源代码和二进制文件。 可自由复制： 你可以将软件复制到你的电脑或任何地方，复制份数没有限制； 可自由分发： 可下载后拷贝分发； 可以用来盈利： 你可以在分发软件的时候收费，但必须在收费前向你的客户提供该软件的 GNU GPL许可协议，以便让他们知道，他们可以从别的渠道免费得到这份软件以及你收费的理由； 可自由修改： 你过你想添加或删除某个功能，没问题。如果你想在别的项目中使用部分代码，也没问题，唯一要求是使用了这段代码的项目也必须使用 GPL协议。 LGPLGNU还有另外一种协议，叫做LGPL（Lesser General Public License），它对产品所保留的权利比GPL少。总的来说，LGPL适合那些用于非GPL或非开源产品的开源类库或框架。因为GPL要求，使用了GPL代码的产品也必须使用GPL协议，开发者不允许将GPL代码用于商业产品。LGPL绕过了这一限制。 GPL和LGPL都属于GNU计划里面的许可证。 BSD伯克利软件套件（Berkeley Software Distribution，缩写BSD），也被称为伯克利Unix，是一个操作系统的名称，衍生自Unix，也被用来代表一整套软件发行版。 BSD许可证（Berkeley Software Distribution License），是自由软件中使用广泛的许可证。BSD软件就是遵照这个许可证来发布，该许可证也因此而得名。 BSD在软件分发方面的限制比别的开源协议要少，且和GPL兼容，并为开源组织所认可。 MITMIT（Massachusetts Institute of Technology），麻省理工学院。MIT许可协议（The MIT License）是许多软件授权条款中，被广泛使用的其中一种。与其他常见的软件许可协议相比，MIT是相对宽松的软件许可协议，除了必须包含许可声明外，再无任何限制。 MIT许可协议核心条款： 该软件及其相关文档对所有人免费，可以任意处置，包括使用、复制、修改、合并、发表、分发、再授权或销售； 唯一的限制，软件中必须包含上述版权和许可证。 ApacheApache许可证（Apache License），是一个由Apache软件基金会发布的自由软件许可证。Apache许可证要求被授权者保留版权和放弃权利的声明，但它不是一个反版权的许可证。兼容与GPL。 除了为用户提供版权许可之外，还有专利许可，对于那些涉及专利内容的开发者而言，该协议最适合。 永久权利：一旦被授权，永久拥有； 全球范围的权利：在一个国家获得授权，适用于所有国家； 授权免费，且无版税：前后期均无任何费用； 授权不可撤销：一旦获得授权，没有任何人可以取消。 分发代码方面，要在声明中对参与开发的人给予认可并包含一份许可协议原文。 MPLMPL是The Mozilla[mɔzilə] Public License的简写，是1998年初Netscape的 Mozilla小组为其开源软件项目设计的软件许可证。MPL许可证出现的最重要原因就是，Netscape公司认为GPL许可证没有很好地平衡开发者对源代码的需求和他们利用源代码获得的利益。 同著名的GPL许可证和BSD许可证相比，MPL在许多权利与义务的约定方面与它们相同（因为都是符合OSIA 认定的开源软件许可证）。 MPL几个特点： MPL虽然要求对于经MPL许可证发布的源代码的修改也要以MPL许可证的方式再许可出来，以保证其他人可以在MPL的条款下共享源代码。但是，在MPL 许可证中对“发布”的定义是“以源代码方式发布的文件”，这就意味着MPL允许一个企业在自己已有的源代码库上加一个接口，除了接口程序的源代码以MPL 许可证的形式对外许可外，源代码库中的源代码就可以不用MPL许可证的方式强制对外许可。这些，就为借鉴别人的源代码用做自己商业软件开发的行为留了一个豁口； MPL许可证第三条第7款中允许被许可人将经过MPL许可证获得的源代码同自己其他类型的代码混合得到自己的软件程序； 对软件专利的态度，MPL许可证不像GPL许可证那样明确表示反对软件专利，但是却明确要求源代码的提供者不能提供已经受专利保护的源代码（除非他本人是专利权人，并书面向公众免费许可这些源代码），也不能在将这些源代码以开放源代码许可证形式许可后再去申请与这些源代码有关的专利； 对源代码的定义，MPL许可证第3条有专门的一款是关于对源代码修改进行描述的规定，就是要求所有再发布者都得有一个专门的文件就对源代码程序修改的时间和修改的方式有描述。 CC知识共享许可协议(Creative Commons License，简称CC)，并非严格意义上的开源许可，是一种公共版权许可协议。它主要用于设计，其允许分发受版权保护的作品。 CC协议主要包含4种基本形式： 署名权：必须为原始作业署名，然后才可以修改、分发、复制； 保持一致：作品同样可以在CC协议的基础上修改、分发、复制； 非商业：不能用于商业用途； 不能衍生新作品：你可以复制、分发、但不能修改，也不能以此为基础创作自己的作品。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>开源许可协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yum源]]></title>
    <url>%2F2018%2F01%2F09%2FYum%2F</url>
    <content type="text"><![CDATA[参考： CentOS 7下配置本地yum源及yum客户端 Centos7 配置本地源+阿里yum源/epel-yum+修改优先级 调整CentOS 7中yum仓库的优先级 国内开源站点 国内开源镜像站点 网易开源镜像站：http://mirrors.163.com/ 阿里云开源镜像站：http://mirrors.aliyun.com 清华大学开源镜像站：https://mirrors.tuna.tsinghua.edu.cn/ 浙江大学开源镜像站： http://mirrors.zju.edu.cn/ 中国科技大学开源镜像站：http://mirrors.ustc.edu.cn/ CentOS自带源rpm包管理方式，对于安装、升级、卸载却难以处理包之间的依赖关系。而yum作为一个rpm包前端管理工具，可以自动处理依赖性，并支持在线现在、安装、升级、卸载rpm软件包。 CentOS默认自带CentOS-Base.repo源，但官方源在国外，连接速度令人心痛。并且有很多软件在默认源里面是找不到的。 配置网络yun源配置aliyun.repo： 12345678910#先备份默认源mv CentOS-Base.repo&#123;,.bak&#125;#下载阿里云源替换默认源wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repoyum clean allyum makecache #重构yum缓存yum repolist #查看yum仓库 配置本地yum源配置本地yum源，考虑到优先使用本地安装包，所以会涉及到一个优先级的概念。 安装完毕后，就可以在yum源中添加一个优先级priority。 安装yum优先级插件： 1234567yum install -y yum-plugin-priorities#检查安装完成后配置vim /etc/yum/pluginconf.d/priorities.confenable=1#enable=0 创建本地yum源： 123456789101112131415161718192021222324mv /etc/yum.repos.d/CentOS-Base.repo&#123;,.bak&#125;vim /etc/yum.repos.d/CentOS-Local.repo[base-Local]name=Centos- Localbaseurl=file:///mnt/xxxgpgcheck=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7priority=1 #优先级为1[updates-Local]name=CentOS- Localgpgcheck=0baseurl=file:///dir/path/gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7priority=1······#具体可参考CentOS-Base.repo#可将aliyun源优先级写成2yum clean allyum makecache 配置ftp方式源1234567891011vim /etc/yum.repos.d/ftp.repo[ftp-media]name=name=CentOS-$releasever - mediabaseurl=ftp://ipgpgcheck=0enable=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7yum clean allyum makecache 其他常见YUM源官方的默认yum源提供的软件包往往是很滞后的，(可能为了服务器版本的稳定性和安全性)。并且官方默认源提供的RPM包也不够丰富。 EPEL源EPEL的全称叫 Extra Packages for Enterprise Linux 。EPEL是由 Fedora 社区打造，为 RHEL 及衍生发行版如 CentOS、Scientific Linux 等提供高质量软件包的项目。装上了 EPEL之后，就相当于添加了一个第三方源。 EPEL源为服务器提供了大量的rpm包(这些包可能有很多在默认源中没有)，并且绝大多数rpm包比官方默认源版本要新。 添加epel源：epel下载地址：http://download.fedora.redhat.com/pub/epel/123rpm -vih http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-9.noarch.rpm#yum install -y epel-release remi源Remi源大家或许很少听说，不过Remi源GoFace强烈推荐，尤其对于不想编译最新版的linux使用者，因为Remi源中的软件几乎都是最新稳定版。或许您会怀疑稳定不？放心，这些都是Linux骨灰级的玩家编译好放进源里的，他们对于系统环境和软件编译参数的熟悉程度毋庸置疑。 添加remi源：Remi下载地址：http://rpms.famillecollet.com123rpm -ivh http://rpms.famillecollet.com/enterprise/remi-release-7.rpm#yum install -y http://rpms.famillecollet.com/enterprise/remi-release-7.rpm RPMForge源RPMForge是CentOS系统下的软件仓库，拥有4000多种的软件包, 被CentOS社区认为是最安全也是最稳定的一个软件仓库。 添加RPMForge源：RPMForge下载地址：http://repository.it4i.cz/mirrors/repoforge/redhat/el7/en/x86_64/rpmforge/RPMS/GitHub:https://github.com/repoforge 123rpm -ivh http://repository.it4i.cz/mirrors/repoforge/redhat/el7/en/x86_64/rpmforge/RPMS/rpmforge-release-0.5.3-1.el7.rf.x86_64.rpm#yum localinstall --nogpgcheckhttp://repository.it4i.cz/mirrors/repoforge/redhat/el7/en/x86_64/rpmforge/RPMS/rpmforge-release-0.5.3-1.el7.rf.x86_64.rpm]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构]]></title>
    <url>%2F2017%2F12%2F11%2FDataStructrue%2F</url>
    <content type="text"><![CDATA[数据结构在计算机科学中，数据结构(data structure)是计算机中存储、组织数据的方式。大多数数据结构都有数列、记录、可辨识联合、引用等基本类型构成。 数据结构意味着结构和封装，一个数据结构可被视为两个函数之间的接口，或是由数据类型联合组成的存储内容的访问方法和封装。数据结构可通过程序语言所提供的数据类型、引用及其它操作加以实现。不同种类的数据结构适合不同种类的应用，部分数据结构甚至是为了解决特定问题而设计。一个涉及良好的数据结构，应该尽可能使用较少的时间与空间资源的前提下，支持各种程序运行。 正确选择数据结构可以提高算法的效率，在计算机程序设计里，选择适当的数据结构是一项重要工作。 常见数据结构 数组(Array); 栈(Stack): 后进先出，线性表； 队列(Queue): 先进先出，线性表； 链表(Linked List): 每个节点包括两部分，一个存储数据元素的数据域，另一个存储下一个节点地址的指针域； 树(Tree)； 图(Graph)； 堆(Heap): 一种动态树形结构； 散列表(Hash)； 数组(Array)数组数据结构，是由相同类型的元素的集合所组成，分配一块连续的内存来存储。利用数组元素的索引(index)可计算出元素对应存储地址。 数组有 一维数组、二维数组、多维数组、可变长数组…。 栈(Stack)堆栈又称为栈，是计算机科学中一种特殊的串列形式的抽象资料类别。其特殊之处在于只能允许在链接串列或阵列的一端(栈顶指标:top)，进行加入数据(push)和取出数据(pop)。 由于栈数据结构只允许在一端进行操作，因为按照后进先出(LIFO, last-in-first-out)的原理运行。 队列(Queue)队列，是先进先出(FIFO, first-in-first-out)的线性表。在具体应用中通常用链表或数组来实现。队列只允许在后端(Rear)进行插入操作，在前端(Front)进行删除操作。 链表(Linked List)链表是一种线性表，但并不按线性的顺序存储数据，而是在每一个节点里存到下一个节点的指针(Pointer)。由于不必须按顺序存储，链表再插入的时候可以达到 O(1)的时间复杂度，比另一种线性表顺序表快得多。但查找一个节点或访问特定节点则需要 O(n)的时间，而顺序表相应的时间复杂度分别是 O(logn)和O(1)。 是用链表结构可以克服数组链表需要预先知道数据大小的缺点，链表可以充分利用计算机内存空间，实现灵活的内存动态管理。但是链表失去了数组随机读取的优点，同时链表由于增加了节点的指针域，空间开销比较大。 链表有单向链表、双向链表、循环链表…。链表用来构建许多其它数据结构，如栈，队列和他们的派生。 树(Tree)树是一种抽象数据类型，用来模拟具有树状结构性质的数据集合。 树有有序树、无序树（二叉树，B树，霍夫曼树）。 图(Graph)在数学上，一个图是表示物体与物体之间的关系的方法，是图论的基本研究对象。 图有：有向图、无向图、简单图、多重图。 堆(Heap)堆是计算机科学中一类特殊的数据结构的统称。堆通常是一个可以被看做一棵树的数组对象。在队列中，调度程序反复提取队列中的第一个作业并运行，因为实际情况中某些时间较短的任务将等待很长时间才能结束，或者某些不短小，但具有重要性的作业，同样应当具有优先权。堆即为解决此类问题设计的一种数据结构。 堆常用于排序，这种算法称作堆排序。 散列表(Hash)散列表也叫哈希表，是根据键(key)而直接访问在内存存储位置的数据结构。它通过计算一个关于键值的函数，将所需查询的数据映射到表中的一个位置来访问记录，这加快了查找速度。这种映射函数称为散列函数，存放记录的数组称为散列表。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB]]></title>
    <url>%2F2017%2F12%2F11%2FMongoDB%2F</url>
    <content type="text"><![CDATA[参考： MongoDB官方文档 MongoDB中文文档 https://zh.wikipedia.org/wiki/MongoDB http://www.ywnds.com/?p=5635 https://www.centos.bz/2017/08/mongodb-secure-intro-user-auth/ http://www.03sec.com/3176.shtml http://www.ywnds.com/?p=6502 http://wiki.jikexueyuan.com/project/the-little-mongodb-book/ 环境： CentOS7_x64； MongoDB3.4； NoSQLNoSQL(Not Only SQL)是对不同于传统的关系型数据库的数据库管理系统(DBMS)的统称。NoSQL不使用SQL作为查询语言，其数据结构可以不需要固定的表格模式，有横向可扩展性的特征。NoSQL用于超大规模数据的存储，这些类型的数据存储不需要固定的模式，无序多余操作就可以横向扩展。 关系型数据库的典型实现主要被调整用于执行规模小而读写频繁，或大批量极少写访问的事务。当代典型的关系型数据库在一些数据敏感的应用中表现了糟糕的性能。例如： 为巨量文档创建索引 高流量网站的网页服务 发送流媒体 NoSQL数据库分类： 类型 栗子 特点 文档存储 MongoDB 用类似json的格式存储，存储的内容是文档型的。这样就有机会对某些字段建立索引，实现关系数据库的某些功能 图形关系存储 Neo4j 图形关系的最佳存储 键-值(key-value)存储 最终一致性的键-值存储 架构性键-值存储 xxx 主机式服务 key-value硬盘存储 key-value RAM存储 MemcacheDB Redis 多数据库 OpenQM xxx 时序型数据库 Graphite xxx 对象数据库 ObjecStore 通过类似面向对象语言的语法操作数据库，通过对象的方式存取数据 列存储 HBase 顾名思义，按列存储数据。方便存储结构化和半结构化数据，方便做数据压缩，针对某一列或某几列的查询有很大的IO优势。 MongoDB简介 MongoDB(https://www.mongodb.com/)，是一种文档导向的数据库管理系统，由C++撰写而成，以此来解决应用程序开发社区中的大量现实问题。它是一种NoSQL。MongoDB支持的数据结构非常松散，是类似于json的bson格式，因此可以存储比较复杂的数据类型。MongoDB是一个开源文档数据库，提供高性能，高可用性和自动扩展。 预备知识： MongoDB中的database有和数据库一样的概念。一个MongoDB实例中，可以有零个或多个数据库，每个都作为一个高等容器，用于存储数据； MongoDB数据库中有零个或多个collections(集合)。集合类似于传统意义上的table(表)； MongoDB的集合是由零个或多个documents(文档)组成。文档类似于row(行)； MongoDB的文档由零个或多个fields(字段)组成。字段类似于columns(列)； MongoDB中Indexes(索引)扮演的角色与RDMS中一样； MongoDB中的Cursors(游标)很重要，当你向MongoDB取数据的时候，它会给你返回一个结果集的指针而不是真正的数据，这个指针我们叫它游标。我们可以用游标做任何事情，比如计数或跨行之类。 MongoDB特点不如这样认为，MongoDB是关系型数据库的一个代替案。比如用Lucene作为关系型数据库的全文检索索引的加强，或者是Redis作为持久性key-value存储。 无模式(Flexible Schema)：它不需要一个固定的模式，这使得他们比传统的数据库表要灵活更多。 写操作(Writes)：MongoDB可以胜任的一个特殊角色是在日志领域。有两点使得MongoDB的写操作非常快： 可以选择发送了写操作之后立刻返回，而无需等到操作完成； 可以控制数据持久性的写行为。 高性能(High Performance)：MongoDB提供了高性能的数据持久性。尤其是： 对嵌入式数据模型的支持减少了数据库系统上的I/O活动； 索引支持更快的查询，并且可以包含来自嵌入式文档和数组的键。 高可用(High Availability)：MongoDB的复制工具，称为副本集。提供：自动故障转移和数据冗余。 持久性(Durability)：在MongoDB中，日志(Journaling)是默认启动的，该功能允许快速恢复服务器，比如遭遇到了服务器奔溃或停电的问题。 丰富的查询语言(Rich Query Language)：MongoDB支持丰富的查询语言来支持读写操作(CRUD)，数据聚合(Data Aggregation)，全文搜索(Text Search)。 水平可伸缩性(Horizontal Scalability)：MongoDB提供了横向可伸缩性。 支持多个存储引擎(Support for Multiple Storage Engines)：在MongoDB3.2以后默认引擎为: WiredTiger Storage Engine，允许第三方为MongoDB开发存储引擎。 database和collectionMongoDB stores BSON documents. databasesIn MongoDB,databases hold collections of documents.如果一个数据库不存在，当你第一次存储数据时，MongoDB会自动创建数据库。这意味着可以切换到不存在的数据库。 默认情况下，集合不要求其文档具有相同的模式；文档不要求具有相同的字段集；字段的数据类型在集合的文档间可以有所不同。 123456789#select a dbuse &lt;db&gt;#create a dbuse newdbdb.newcoll.insert(&#123;name:'zhang'&#125;)db.newcoll.insert(&#123;filed01:'filed01', filed02:'filed02', filed03:'filed03', filed04:'filed04'&#125;)db.newcoll.insert(&#123;groups: ['A', 'B', 'C']&#125;)db.newcoll.find().pretty() collectionMongoDB stores documents in collections.collection类似于关系型数据库中的table。 12db.coll02.insert(&#123;x:1&#125;)db.coll03.createIndex(&#123;y:1&#125;) 显式创建(explicit creation)MongoDB提供了db.createCollection()方法来显式创建一个附带各种选项的集合。如设置document最大大小，文件验证规则等选项。如果不需要指定这些选项，就不需要使用显式创建集合，而直接向集合中插入数据即可。修改collection选项，使用collMod方法。 视图(View)视图的定义是公开的，视图的解释操作将包括定义视图的管道。因此，避免直接引用视图定义中的敏感字段和值。 创建/删除视图： 12345678910db.runCommand(&#123; crete: &lt;view&gt;, viewOn: &lt;source&gt;, pipeline: &lt;pipeline&gt;&#125;)db.createView(&lt;view&gt;, &lt;source&gt;, &lt;pipeline&gt;, &lt;collation&gt;)db.collection.drop() 视图行为： 视图存在以下行为： 视图只读，视图上的写操作将会出错； 视图使用底层集合的索引； 如果视图的基础集合被分割，视图也被认为可分割； 不能重命名视图； 视图上的字符串使用视图的默认排序规则。 限制集限制集是固定大小的集合支持基于文档插入顺序的高吞吐率的插入、检索、删除操作。限制集工作在某种程度上类似于循环缓冲区：一旦一个文档填满分配给它的空间，它将通过在限制集中重写老文档来给新文档让出空间。 行为插入顺序限制集合能够保留插入顺序。因此，查询并不需要索引来保证以插入顺序来返回文档。减少了索引的消耗，限制集可以支持更高的插入吞吐量。 最旧文档的自动删除为了给新文档腾出空间，再不需要脚本或显示删除操作的前提下，限制集自动删除集合中最旧的文档。 例如replication set中的oplog.rs集合。考虑潜在用于集合封顶的用例： 存储高容量系统生成的日志信息。没有索引的情况下向限制集中插入文档的速度接近于直接在文件系统中写日志的速度； 在限制集中缓存少量的数据。 _id索引限制集合有一个_id字段并且默认在_id字段上创建索引。 限制和建议更新更新限制集中的文档，创建一个索引保证这些更新操作不需要进行集合扫描。 文档大小一个更新或替换操作改变了文档大小，操作将会失败。 文档删除不能从一个限制集中删除文档！为了从一个集合中删除所有文档，使用drop()方法来删除集合然后重新创建限制集。 分片不能对限制集分片。 查询效率用自然顺序监视限制集中大部分最近插入的文档。 程序创建一个限制集必须使用db.createCollection()方法创建限制集。且必须指定以字节为单位的最大集合大小。MongoDB将会预先分配集合。另外，可为限制集指定最大文档数据，用max字段。 大小参数是必须的。MongoDB会在达到最大限制前删除旧的文件。 1234567use &lt;db&gt;#限制集大小db.createCollection("log", &#123;capped: true, size: 1000000&#125;)#限制集和文档大小db.createCollection("log", &#123;capped: true, size: 5242880, max: 5000&#125;) 查询一个限制集如果没有对限制集指定排序，则MongoDB的结果顺序和插入顺序相同。 检查一个集合是否是限制集isCapped()方法 123db.collection.isCapped()#db.coll01.isCapped()#false 将集合转换为限制集convertToCapped()方法 123db.runCommand(&#123;"covertToCapped": "coll01", size: 1000000&#125;);#db.coll01.isCapped()#true 在规定的时间周期之后将自动移除数据通过设置MongoDB的TTL时集合中的数据过期。TTL collection与限制集不兼容。 Tailable游标类似于Unix中的taif -f documentMongoDB存储数据记录为BSON文档。BSON是JSON文档的二进制表示，因此它包含比JSON更多的数据类型。 document structureMongoDB字段由key-value对组成。字段值可以是任一BSON数据类型，包括其他文档，数组，阵列。 1234567891011121314151617181920212223&#123; filed1: value1; filed2: value2; ... filedN: valueN&#125;#data typevar mydoc =&#123; _id: ObjectId("5099803df3f4948bd2f98391"), name: &#123; first: "Alan", last: "Turing" &#125;, birth: new Date('Jun 23, 1912'), death: new Date('Jun 07, 1954'), contribs: [ "Turing machine", "Turing test", "Turingery" ], views : NumberLong(1250000)&#125;_id是ObjectID；name是嵌入式文档；birth是日期类型；contribs是字符串数组；view是NumberLong类型。 字段名(field name)字段名是字符串。document对field name有以下限制: 字段名称_id保留用作主键(primary key)，它的值在collection中必须唯一，不可变。它的类型可以是数组外的任何类型； 字段名称不能以$字符开头； 字段名称不能包含.字符； 字段名称不能包含null字符。 BSON documents 可能有多个字段名称相同的字段。然而，大多数的MongoDB Interface，MongoDB结构（如hash表），并不支持重复字段名称。如果需要操作具有多个相同名称字段的文档，请参考 mongo driver。 一些由内部MongoDB进程创建的documents可能会有重复的字段，但是没有MongoDB进程会向一个已经存在的user document中添加重复字段。 字段值限制(field value limit)For indexed collections，indexed fields的值有一个最大索引值长度限制(maximum index key length)。 圆点表示法(dot notation)MongoDB使用圆点表示法来访问数组中的元素，访问嵌套文档中的字段。 数组(array)通过基于0的索引位置来指定或访问数组中的元素。 123456789&lt;array&gt;.&lt;index&gt;&#123; contribs: [ 'Turing machine', 'Turing test', 'Turingery' ]&#125;#contribs.0 == 'Turing machine'#contribs.1 == 'Turing test'#contribs.2 == 'Turingery' 嵌套文档(embedded documents)通过圆点表示法来指定或访问嵌套文档中的字段。 123456789&lt;embedded document&gt;.&lt;field&gt;&#123; name: &#123; first: 'AAA', last: 'ZZZ'&#125;, contact: &#123; phone: &#123; type: 'cell', number: '1-22-333' &#125;&#125;&#125;#name.first == 'AAA'#contact.phone.number == '1-22-333' 文档限制(document limitation)文档大小限制(size limit)BSON document最大size为：16MB。 最大document size确保一个单一document不能使用过量的RAM，或是传输期间的过量带宽。MongoDB提供了GridFS API，用来保存超过最大size的文档。 文档字段序列(field order)MongoDB用write operation来作为document的序列，除了一下情况： _id字段总是document中的第一个field； 包含重命名的update操作，会导致document中的field重新排序。 _id字段在MongoDB中，每个保存在collection中的document都要求一个唯一的_id，用以担任主键(primary key)。如果向document中insert数据是忽略的_id字段，则MongoDB driver会为_id字段自动生成一个ObjectID。 1234567#默认生成_iddb.coll01.insert(&#123;name: 'zhang', sex: 'man', hobby: 'woman'&#125;)# "_id" : ObjectId("5a32166ebf2c986e8106f891")#自定义_iddb.coll01.insert(&#123;_id:'ZhangCustomDefine', name:'zhang', sex: 'man', arr: [0, 1, 2, 3], emmdoc: &#123;emm01:'Emm01', emm02: 'Emm02', emm03: 'Emmo3'&#125;&#125;)#"_id" : "ZhangCustomDefine" _id字段有以下行为和约束： 默认情况下，MongoDB在collection创建document时，会创建一个唯一的_id作为索引； _id字段总是document中的第一个字段。如果server接受的document中_id不在第一个字段，那么Server会移动_id到第一个字段； _id字段的数据类型除了数组外的任意BSON 数据类型； 不要存储BSON正则表达式的类型在_id字段中。 _id字段值的常用选项： 使用ObjectId； 使用了自然唯一的标识符，节省了空间并避免了额外的索引； 生成一个自动递增的数字； 在应用程序代码中生成UUID； 文档结构的其他用途查询过滤文档(query filter)使用:表达式来指定条件。 12345&#123; &lt;field1&gt;: &lt;value1&gt; &lt;field2&gt;: &lt;value2&gt; ...&#125; 更新特定文档(update)使用db.collection.update()操作更新数据。 BSON类型BSON是一个用来存储document和MongoDB进行远程调用的二进制序列化格式。BSON支持以下数据类型作为文档中的值。每个数据类型都有一个相应的数字和字符串别名，可与$type操作符一起使用，以便按照bson类型查询文档。 Type Number Alias double 1 “double” 字符串 2 “string” 对象 3 “object” 数组 4 “array” 二进制数据 5 “binData” 未定义 6 “undefined” ObjectId 7 “objectId” Boolean 8 “bool” 日期 9 “date” 空 10 “null” 正则表达式 11 “regex” DBPointer 12 “dbPointer” JavaScript 13 “javascript” 符号 14 “symbol” JavaScript(带范围) 15 “javascriptWithScope” 32位整数 16 “int” 时间戳 17 “timestamp” 64位整数 18 “long” Decimal128 19 “decimal” Min key -1 “minKey” Max key 127 —- 如果你想要将BSON转换为JSON，参考Extended JSON。 ObjectIdObjcetIds are small, likely unique, fast to generate, and ordered.ObjectIds由12个字节组成，其中前4个字节是反映ObjectId创建的时间戳(timestamp)。 一个4字节的值，代表从Unix纪元开始的秒数； 一个3字节的机器标识符； 日期对象排在时间戳对象之前； MongoDB在比较过程中，会把一些类型看成相等。 栗子：{ &quot;_id&quot; : ObjectId(&quot;5a33354068b6c5e5fb6f213f&quot;), &quot;name&quot; : &quot;ZHANG&quot; }。 在mongo shell中，可以访问ObjectId的创建时间，使用ObjectId.getTimestamp()方法。在_id字段中存储的ObjectId值的排序，大致相当于按其创建时间排序。ObjectId的值顺序与生成时间之间并不严格。 字符串BSON字符串都是UTF-8编码。一般来说，每种编程语言的驱动程序在序列化和反序列化BSON的时候，都会从语言的字符串形式转化为UTF-8。这就使得使用BSON字符串简单存储大多数国际字符变为可能。 时间戳BSON有一个特殊的时间戳类型用于MongoDB内部使用，与普通的日期类型无关。而在应用开发中可使用BSON日期类型。时间戳值是一个64位的值： 前32位是与Unix纪元相差的秒数，后32位是在某秒总操作的一个递增的序列数。 在MongoDB复制集中，oplog有一个ts字段。这个字段的值使用BSON时间戳表示了操作时间。 1234db.coll02.insert( &#123; ts: new Timestamp() &#125; )db.coll02.find()#&#123; "_id" : ObjectId("5a333e3f68b6c5e5fb6f2141"), "ts" : Timestamp(1513307711, 1) &#125; 日期BSON日期是一个64位整数，表示利当前Unix新纪元(1970.01.01)的毫秒数，可到未来的2.9亿年。BSON日期类型是有符号的，负数表示1970年之前的时间。 123456var date1 = new Date()var date2 = ISODate()#date1#date2#ISODate(&quot;2017-12-15T03:28:08.227Z&quot;) MongoDB Extended JSONJSON只能表示BSON类型的一个子集。为了保留类型信息，MongoDB对JSON格式添加了如下扩展性： Strict mode： Any JSON parser can parse these strict mode representations as key/value pairs; mongo shell mode： The MongoDB internal JSON parser and the mongo shell can parse this mode. 多种数据类型的表示取决于JSON解析的上下文！ 解析器(parser)和支持的格式(format)Input in Strict mode如下可在严格模式下被解析并识别类型信息。 REST Interface; mongo import; —query; MongoDB Compass. Input in mongo shell mode如下可在严格模式下被解析并识别类型信息。 REST Interface; mongo import; --query; MongoDB Compass Output in Strict modemongoexport, REST, HTTP Interfaces. Output in mongo shell modebsondump BSON数据类型和关联表示Binary Strict mode mongo shell mode { “$binary”: ““, “$type”: ““ } BinData ( , ) 12&lt;bindata&gt;是二进制base64表示；&lt;t&gt;是由单字节的数据类型表示。 Date Strict mode mongo shell mode { “$date”: ““ } new Date ( ) 12In Strict mode, &lt;date&gt;是 ISO-8601的日期格式的时区字段，类型如**YYYY-MM-DDTHH:mm:ss.mm&lt;+/-offset&gt;;MongoDb JSON解析器目前暂不支持载入ISO-8601日期类型。 Timestamp Strict mode mongo shell mode { “$timestamp” ; { “t”: , “i” } } Timestamp( , ) 12&lt;t&gt;是32位无符号整数的JSON表现形式；&lt;i&gt;是增量的32位无符号整数。 Regular Expression Strict mode mongo shell mode { “$regex”: , “$options”: ““ } // 1234&lt;sRegex&gt;是有效地JSON字符串；&lt;jRegex&gt;是一个可能包含有效的JSON字符和未转义的双引号(&quot;)，但可能不包括未转义的斜杠(/)字符；&lt;sOptions&gt;是一个正则表达式选项；&lt;jOptions&gt;是一个只能包含字符&quot;g&quot;, &quot;i&quot;, &quot;m&quot;, &quot;s&quot;的字符串。 OID Strict mode mongo shell mode { “$oid”: ““ } ObjectId( ““ ) &lt;id&gt;是一个24字符的十六进制(hexadecimal)字符串 DB Reference strict mode mongo shell mode { “$ref”: ““, “$id”: ““ } DBRef(““, ““) 12&lt;name&gt;是一个有效的JSON字符；&lt;id&gt;是任一extended JSON type。 Undefined Type strict mode mongo shell mode { “$undefined”: true } undefined MinKey/MaxKey strict mode mongo shell mode { “$minkey”: 1 } MinKey { “$maxkey”: 1 } MaxKey NumberLong strict mode mongo shell mode { “$numberLong”: ““ } NumberLong( ““ ) 12Number是一个64位有符号整数。必须使用&quot;，否则它将被解释为浮点数，从而导致损失精度；db.json.insert&#123;&#123; longquoted: NumberLong(&quot;12345678901234345&quot;) &#125;) MongoDB安装参考: https://docs.mongodb.com/manual/administration/install-on-linux/; https://docs.mongodb.com/manual/tutorial/install-mongodb-on-red-hat/; MongoDB有社区版(Community)和企业版(Enterprise)。社区版免费，企业版在商业方面收费。 MongoDB在仓库中提供官方支持的包，包含以下软件包： Package Description monogdb-org 将自动安装下面四个组件包 mongodb-org-server 包含mongod守护进程和相关配置和init脚本 mongodb-org-mongos 包含mongos守护进程 mongodb-org-shell 包含mongo-shell mongodb-org-tools 包含相关MongoDB工具，如mongoimport,mongoexport,mongodump,mongorestore… mongodb-org-server包提供了一个/etc/mongod.conf配置文件来开始和初始化mongod。默认配置文件默认bind_ip为 127.0.0.1，当你有需要和副本集时请修改它。 自建mongodb.repo仓库安装仓库地址：https://repo.mongodb.org 12345678910111213vim /etc/yum.repos.d/mongodb34.repo#编辑仓库[mongodb34]name=MongoDB34 Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.4/x86_64/gpgcheck=0enabled=1#安装mongodbyum install -y mongodb-org 下载rpm包安装1234567cd /root/mongodbwget https://repo.mongodb.org/yum/redhat/7/mongodb-org/3.4/x86_64/RPMS/mongodb-org-3.4.10-1.el7.x86_64.rpmwget https://repo.mongodb.org/yum/redhat/7/mongodb-org/3.4/x86_64/RPMS/mongodb-xxx-3.4.10-1.el7.x86_64.rpm#共五个包yum ./mongo-org* 源码安装1234567wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-3.6.0.tgztar -axvf mongodb-linux-x86_64-rhel70-3.6.0.tgz -C ./#默认路径/usr/localmake &amp;&amp; make install 开启mongodb123456789101112131415161718192021#默认启动方式systemctl start mongod#指定配置文件启动#注意修改配置文件里面的某些路径和名称，不然会和默认配置文件冲突mongod -f /etc/mongo_27018.confmongod -f /etc/mongo_27019.conf``&lt;br&gt;## 卸载mongodb```shsystemctl stop mongodyum remove $(rpm -qa | grep mongodb-org)rm -rf /var/log/mongodbrm -rf /var/dbpath/mongo mongodb异常关闭后12345#首先查看日志文件tail /var/log/mongodb/mongod.log#删除rm /var/run/mongodb/mongod.pid /var/db/mongodb/mongod.lock MongoDB配置文件MongoDB的配置文件格式使用了YAML格式。YAML维基百科，Yet Another Markup Language。强调以数据为中心，而不是标记语言为重点，用方向缩略语重命名。 默认配置文件/etc/mongod.conf 的几个大块： 123456789101112131415161718192021systemLog: #日志storage: #存储processManagement: #进程管理net: #网络security: #安全operationProfiling: #性能分析器replication: #主从复制sharding: #架构setParameter: #自定义变量auditLog: #检测日志snmp: #简单网络管理协议 systemLog日志相关参数： 123456789101112131415systemLog: verbosity: &lt;int&gt; #日志级别，默认0,1-5均会包含debug信息 quiet: &lt;boolean&gt; #安静，true时mongod将会减少日志的输出量 traceAllExceptions: &lt;boolean&gt; #打印异常详细信息 syslogFacility: &lt;string&gt; #指定用于登录时信息到syslog Facility水平，前提是启用syslog path: &lt;string&gt; #日志路径，默认情况下，MongoDB将覆盖现有的日志文件 logAppend: &lt;boolean&gt; #mongod重启后，在现有日志后继续添加日志，否则备份当前日志，然后创建新日志 logRotate: rename|reopen #日志轮询，防止一个日志文件特别大。rename重命名日志文件，默认值；reopen使用Linuxrotate特性，关闭并重新打开日志文件，前提为logAppend: true destination: &lt;string&gt; #日志输出目的地，可为file或syslog，若不指定，则会输出到 std out timeStampFormat: &lt;string&gt; #指定日志格式的时间戳，有 ctime, Iso869-utc, iso8691-local component: #为不同的组件指定各自的日志信息级别 accessControl: verbosity: &lt;int&gt; command: verbosity: &lt;int&gt; storage存储引擎相关参数: 123456789101112131415161718192021222324252627282930313233storage: dbPath: &lt;string&gt; #mongodb进程存储数据目录，此配置进队此mongod进程有效，你使用配置文件开启的mongod就可以指定额外的数据目录 indexBuildRetry: &lt;boolean&gt; #当构件索引时mongod意外关闭，那么在此启动是否重建索引，默认true repairPath: &lt;string&gt; #在repair期间使用此目录存储临时数据，repair结束后此目录下数据将被删除 journal: enabled: &lt;boolean&gt; #journal日志持久存储，journal日志用来数据恢复，通常用于故障恢复，建议开启 commitIntervalMs: &lt;num&gt; #mongod日志刷新值，范围1-500毫秒，默认100，不建议修改 directoryPerDB: &lt;boolean&gt; #是否将不同的数据存储在不同的目录中，dbPath子目录 syncPeriodSecs: &lt;int&gt; #fsync操作将数据flush到磁盘的时间间隔，默认为60秒，不建议修改 engine: &lt;string&gt; #存储引擎 mmapv1: #mmapv1存储引擎，3.2前默认 preallocDataFiles: &lt;boolean&gt; nsSize: &lt;int&gt; quota: enforced: &lt;boolean&gt; maxFilesPerDB: &lt;int&gt; smallFiles: &lt;boolean&gt; journal: debugFlags: &lt;int&gt; commitIntervalMs: &lt;num&gt; wiredTiger: #WiredTiger存储引擎，3.2后默认 engineConfig: cacheSizeGB: &lt;number&gt; #最大缓存大小 journalCompressor: &lt;string&gt; #日志压缩算法，可选值有 none，snappy(默认)，zlib directoryForIndexes: &lt;boolean&gt; #是否将索引和collections数据分别存储在dbPath单独的目录中 collectionConfig: blockCompressor: &lt;string&gt; #collection数据压缩算法，可选none, snappy，zlib indexConfig: prefixCompression: &lt;boolean&gt; #是否对索引数据使用前缀压缩。对那些经过排序的值存储有很大帮助，可有效减少索引数据的内存使用量。 inMemory: #inMemory内存存储引擎，bate版 engineConfig: inMemorySizeGB: &lt;number&gt; processManagement进程相关参数: 123processManagement: fork: &lt;boolean&gt; #是否以fork模式运行mongod进程，默认情况下，mongod不作为守护进程运行 pidFilePath: &lt;string&gt; #将mongod进程ID写入指定文件，如未指定，将不会创建PID文件 net网络相关参数: 123456789101112131415161718192021222324252627282930net: prot: &lt;int&gt; #监听端口，默认27017 bindIp: &lt;string&gt; #绑定IP，如果此值是“0.0.0.0”则绑定所有接口 maxIncomingConnections: &lt;int&gt; #mongod进程允许的最大连接数，如果此值超过系统配置的连接数阈值，将不会生效(ulimit) wireObjectCheck: &lt;boolean&gt; #当客户端写入数据时，检查数据的有效性（BSON）。如果数据格式不良，update,insert等操作将会被拒绝 ipv6: &lt;boolean&gt; #是否支持多实例之间使用ipv6 unixDomainSocker: #适用于Unix系统 enabled: &lt;boolean&gt; pathPrefix: &lt;string&gt; filePermissions: &lt;int&gt; http: # enabled: &lt;boolean&gt; JSONEnabled: &lt;boolean&gt; RESTInterfaceEnabled: &lt;boolean&gt; ssl: sslOnNormalPorts: &lt;boolean&gt; mode: &lt;string&gt; PEMKeyFile: &lt;string&gt; PEMKeyPassword: &lt;string&gt; clusterFile: &lt;string&gt; clusterPassword: &lt;string&gt; CAFile: &lt;string&gt; CRLFile: &lt;string&gt; allowConnectionsWithoutCertificates: &lt;boolean&gt; allowInvalidCertificates: &lt;boolean&gt; allowInvalidHostnames: &lt;boolean&gt; disabledProtocols: &lt;string&gt; FIPSMode: &lt;boolean&gt; compression: compressors: &lt;string&gt; security安全相关参数: 1234567891011121314151617181920212223242526272829303132333435security: authorization: enabled #MondoDB认证功能 keyFile: /path/mongo.key #MongoDB副本集节点身份验证密钥文件 clusterAuthMode: &lt;string&gt; #集群members间的认证模式 transitionToAuth: &lt;boolean&gt; javascriptEnabled: &lt;boolean&gt; #是否允许执行JavaScript脚本 redactClientLogData: &lt;boolean&gt; sasl: hostName: &lt;string&gt; serviceName: &lt;string&gt; saslauthdSocketPath: &lt;string&gt; enableEncryption: &lt;boolean&gt; encryptionCipherMode: &lt;string&gt; encryptionKeyFile: &lt;string&gt; kmip: keyIdentifier: &lt;string&gt; rotateMasterKey: &lt;boolean&gt; serverName: &lt;string&gt; port: &lt;string&gt; clientCertificateFile: &lt;string&gt; clientCertificatePassword: &lt;string&gt; serverCAFile: &lt;string&gt; ldap: servers: &lt;string&gt; bind: method: &lt;string&gt; saslMechanism: &lt;string&gt; queryUser: &lt;string&gt; queryPassword: &lt;string&gt; useOSDefaults: &lt;boolean&gt; transportSecurity: &lt;string&gt; timeoutMS: &lt;int&gt; userToDNMapping: &lt;string&gt; authz: queryTemplate: &lt;string&gt; operationProfiling慢查询相关参数： 1234operationProfiling: slowOpThresholdMs: &lt;int&gt; #数据库profiler判定一个操作是“慢查询”的时间阈值，单位毫秒。mongod会把慢查询记录到日志中，默认100ms mode: &lt;string&gt; #数据库profiler级别，操作的性能信息将会被写入日志文件中，可选值“off”--关闭profiling，“slowOp”--只包包含慢操作，“all”--记录所有操作 #数据库profiling会影响性能，建议只在性能调试阶段开启 replication副本集： 12345replication: oplogSizeMB: &lt;int&gt; #replication操作日志的最大尺寸，如果太小，secondary将不能通过oplog来同步数据，只能全量同步 replSetName: &lt;string&gt; #副本集名称，副本集中所有的mongod实例都必须有相同的名字，Sharding分布式下，不同的sharding应该使用不同的repSetName secondaryIndexPrefetch: &lt;string&gt; #副本集中的secondary，从oplog中应用变更操作之前，将会先把索引加载到内存 enalbeMajorityReadConcern: &lt;boolean&gt; #允许readConcern的级别为“majority” sharding分片相关参数： 123sharding: clusterRole: &lt;string&gt; #在sharding集群中，此mongod实例可选的角色。configsvr,默认监听27019端口 和 shardsvr,默认监听27018端口 archiveMovedChunks: &lt;boolean&gt; #当chunks因为“负载均衡”而迁移到其他节点时，mongod是否将这些chunks归档，并保存在dbPath/movechunk目录下，mongod不会删除moveChunk下的文件 setParameter自定义变量： 1234setParameter: &lt;parameter1&gt;: &lt;value1&gt; &lt;parameter2&gt;: &lt;value2&gt; enableLocalhostAuthBypass: false #栗子 auditLog审计相关参数： 12345auditLog: destination: &lt;string&gt; #指定审计记录的输出方式，有syslog, console, file format: &lt;string&gt; #输出格式，有JSON 和 BSON path: &lt;string&gt; #如果审计时间输入为文件，那么就需要指定文件完整路径及文件名 filter: &lt;string&gt; #过滤器，可限制审计系统记录的操作类型，该选项需要一个表单的查询文档的字符串表示形式 Mongo Shellmongo shell是一个交互式的JavaScript结构的MongoDB。使用mongo shell来查询和更新数据以及执行管理操作。 mongo shell基础知识启动monso shell启动mongo shell前确保MongoDB实例正在运行。 1234567891011121314mongo [option] [db address] [.js]#以默认配置启动mongo#以特定配置启动mongo --port 27018#连接远程mongo shellmongo --host $host --port $port -u $user -p $passwdmongo &lt;db&gt;mongo &lt;host&gt;/&lt;db&gt;mongo &lt;hsot:port&gt;/&lt;db&gt; .mongorc.js文件mongo shell开始运行时，mongo将在用户主目录下检查.mongorc.js的js文件。如果找到，mongo将在首次命令行之前解释执行.mongorc.js的内容。如果你使用mongo shell执行一个js或表达式，无论是通过mongo --eval，或指定一个.js文件，mongo都将在js处理完成之后读取.mongorc.js文件。可使用 --norc选项禁止加载.mongorc.js。 12ll /root/.mongorc.js# -rw------- 1 root root 0 Dec 27 2016 /root/.mongorc.js 使用mongo shell可能在启动mongo shell的时候会警告: WARNING: /sys/kernel/mm/transparent_hugepage/defrag is ‘always’. We suggest setting it to ‘never’. WARNING: /sys/kernel/mm/transparent_hugepage/defrag is ‘always’. We suggest setting it to ‘never’ WARNING: Access control is not enabled for the database. hugepage(大内存页面)，是Linux操作系统一种管理内存的方式。和通常方式相比，hugepage模式下内存分配管理会有所差异。MongoDB显然不希望这个特定被启用。新版MongoDB增加了安全性设计，推荐用户创建使用数据库时进行验证。所以我们需要创建用户认证。 关闭hugepage: 123456vim /etc/rc.d/rc.localecho never &gt; /sys/kernel/mm/transparent_hugepage/enabledecho never &gt; /sys/kernel/mm/transparent_hugepage/defragchmox a+x /etc/rc.d/rc.local 创建用户认证: 1234567891011121314&gt;use admin&gt;db.createUser(&#123; user: "zhang", pwd: "zhang", roles: [&#123; role: "root", db: "admin"&#125;]&#125;)mongo -u zhang -p zhang --authenticationDatabase admin#或mongouse admindb.auth("zhang", "1314520") 12345678910mongo#显示当前使用数据库&gt;db#切换数据库&gt;use &lt;database&gt;#查看所有数据库&gt;show dbs 你可以切换到一个并不存在的数据库。当你第一次向数据库存储数据，如创建一个集合，MongoDB将自动创建数据库。 123use nodbdb.nocollestion.insert(&#123;x:1&#125;); 格式化打印结果db.collection.find()方法返回一个cursor(游标)。如果返回的游标未使用var关键字指定变量，则游标将自动迭代最多20次，以打印出与查询匹配的前20个documents 1234567#在操作中添加`.pretty()`，以格式化打印结果#使用.pretty显示结果很舒服db.collection.find().pretty()print() #无格式打印printjson() #用JSON打印 mongo shell中的多行操作mongo shell中如果你以( , { , [开始，那么知道你输入了对应的) , } , ]才算结束命令。 Tab命令补全和键盘快捷键mongo shell支持键盘快捷键，例如： 使用 上/下箭头 进行历史命令切换； 使用 Tab键 自动补全命令。 mongo shell批量操作123456mongo -u xxx -p xxx --authenticationDatabase=xxx &lt;&lt; EOFshow dbsuse zhangdb.coll01.drop()db.coll02.update( &#123; _id: "xxx" &#125;, &#123; name: "zhang" &#125;)EOF 退出mongo shell12345quit()exitCtrl+c 配置mongo shell可在mongo shell中设置变量prompt的值来修改提示符内容。prompt变量可以存储字符串以及JavaScript代码。 也可以在.mongorc.js文件中增加提示符的逻辑操作来设置每次启动mongo shell的提示符。 自定义提示符自定义提示符展示操作符： 在mongo shell中定义一下变量。 12345678910cmdCount = 1;prompt = function() &#123; return (cmdCount++) + '&gt; ';&#125;#效果1&gt;2&gt;... 自定义提示符显示数据库和主机名： 形式为：&lt;database&gt;@$ 12345678host = db.serverStatus().host;prompt = function() &#123; return db+'@'+host+'$'&#125;#效果test@localhost$ 自定义提示符展示服务器启动时间和文档数： 1234567prompt = function() &#123; return 'Uptime:' + db.serverStatus().uptime + 'Documents:' + db.stats().objects + '&gt; ';&#125;#效果Uptime:1234 Documents:5 &gt; 注意：在mongo shell里面定义的prompt变量知识临时生效的，退出shell后便没有。如果想要当前用户永久生效，可写入~/.mongorc.js文件。则此用户每次启动mongo shell前都会执行这个文件。 123456vim ~/.mongorc.jshost = db.serverStatus().host;prompt = function() &#123; return db+"@"+host+"&gt; "; &#125; 在mongo shell中使用外部编辑器可在启动mongo shell之前设置EDITOR环境变量来在mongo shell中使用自己的编辑器。 12345678910111213export EDITOR=vimmongo#edit &lt;variable&gt;|&lt;function&gt;function myfunc()&#123;&#125;edit myfunc#此时是edit使用vim编辑myfuncfunction myfunc()&#123; print("It was edited by vim!")&#125;myfunc() 修改mongo shell批处理大小db.collection.find()是一种JavaScript方法，返回一个cursor(游标)。如果返回的游标未使用var关键字指定变量，则游标将自动迭代最多20次，以打印出与查询匹配的前20个documents。可以设置DBQuery.shellBatchSize属性来修改默认20篇文档。 1DBQuery.shellBatchSize = 10; 获取mongo shell帮助合理运用Tab键补全命令！ 1234567891011121314151617181920212223242526###命令行帮助mongo --help###mongo shell里查看帮助列表help###数据库帮助#db.&lt;method&gt;show dbsdb.help()###集合帮助#db.&lt;collection&gt;.&lt;method&gt;show collectionsdb.collections.help()###游标帮助db.collection.find().help()###封装对象帮助help misc 给mongo shell写脚本可使用JavaScript为mongo shell编写脚本，用于处理MongoDB中的数据或执行管理操作。 打开新连接在mongo shell或JavaScript文件中，可使用Mongo()构造函数来实例化数据库连接： 12345678910111213141516171819new Mongo()new Mongo(&lt;host&gt;)new Mongo(&lt;host:port&gt;)#栗子conn = new Mongo();db = conn.getDB('mydb'); #将全局db变量设置为mydb#连接db = connect('localhost:27017/mydb');#认证db.auth(&lt;user&gt;, &lt;passwd&gt;)db.auth(&#123; user: &lt;user&gt;, pwd: &lt;passed&gt;&#125;) 交互式和脚本化mongo的区别mongo shell中的帮助与JavaScript中帮助不一样！ mongo shell帮助 JavaScript等量 show dbs db.adminCommand(‘listDatabases’) use db = db.getSiblingDB(‘‘) show collections db.getCollectionNames() show users db.getUsers() show log db.adminCommand({‘getLog’ : ‘‘}) 脚本使用mongo shell来计算JavaScript的值。 —eval mongo执行 --eval后的js命令 1mongo test --eval &quot;printjson(db.getCollectionNames())&quot; 执行JavaScript文件 12345mongo localhost:27017/test myjs.js#在shell中执行.js&gt;load("myjs.js")&gt;loca("/root/mongo/myjs.js") mongo shell中的数据类型MongoDB BSON提供了除JSON之外的其它数据类型的支持。Driver提供了对这些数据类型在主机语言的本地化支持，mongo shell也提供了一些帮助类来支持这些数据类型在mongo javascript shell中的使用。 日期mongo shell提供了多种方法返回日期: Date() 方法返回当前日期为一个字符串； new Date() 构造函数返回一个使用ISODate()包装返回的Date对象； ISODate() 构造函数返回一个使用ISODate()包装返回的Date对象。 返回一个日期为字符串： 123var myDateString = Date();#查看变量值myDateString 验证类型： 12typeof myDateString()#string 返回Date： 123456var myDate = new Date();myDate#ISODate(&quot;2017-12-12T08:43:31.405Z&quot;)#验证myDate instanceof Date ObjectIdmongo shell对objectid数据类型提供objectId()包装类。 new ObjectId NumberLongmongo shell默认将所有数字处理为浮点值。 用numberlong()包装来处理64位整数。 1NumberLong("2090845886852") NumberInt用NumberInt()构造函数来显式指定32位整数。 NumberDecimalmongo shell默认将所有的数字处理为64位浮点的double值。mongo shell提供了NumberDecimal()构造函数限制指定128位基于十进制的浮点值，能够以精确的精度仿效十进制近似值。这个功能在金融、税务以及科学计算等方面应用。 12&gt;NumberDecimal('1000.55')#强烈建议加上引号，没加引号可能会存在精度丢失的情况 在mongo shell中检查类型instanceof返回一个bool值来验证一个值是否为某些类型的实例。 12mydoc._id instanceof ObjectId#true typeof返回一个字段的类型。 12typeof mydoc._id#object mongo shell快速参考mongo shell 历史命令mongo shell历史命令保存在~/.dbshell文件中，cat ~/.dbshell。也可以使用上/下键切换历史命令。 命令行选项 option description --help 显示命令行选项 --nodb 启动mongo shell而不连接到数据库 --shell 执行文件后运行mongo shell mongo shell命令助手 help methods and commands description help 显示帮助 db.help 显示数据库方法的帮助 db.collection.help() 显示集合方法的帮助 show dbs 打印服务器上的所有数据库列表 show databases 打印所有可获取的数据库列表 use &lt;db&gt; 切换数据库 show collections 打印当前数据库上的所有集合列表 show users 打印当前数据库的用户列表 show roles 打印当前数据库的所有角色(user-define and built-in)列表 show profile 打印花费1ms或更多时间的五个最近的操作 load() 在shell中执行一个JavaScript文件，建议使用绝对路径 mongo shell的基本JavaScript操作mongo shell为数据库操作提供了一个JavaScript API。db引用当的是前数据库的变量。 JavaScript db-operation description db.auth() 在安全模式下认证用户 coll = db.&lt;collection&gt; 将当前db中的特定collection设置为coll，可在此变量上执行操作，如coll.find(); db.collection.find() 查找集合中的所有文档，并返回一个游标 db.collection.insert() 插入一个新文档到集合中 db.collection.update() 更新集合中一个存在的文档 db.collection.save() 插入或更新 集合中的文档 db.collection.remove() 从集合中删除文档 db.collection.drop() 删除整个集合 db.collection.createIndex() 在集合中创建索引 db.getSiblingDB() 跨数据库查询 键盘快捷键 keysrtoke function Up/Down arrow 前/后 历史命令 Left/Right arrow 左右移动 Home/End 行首/行尾 Tab 自动补全 ctrl+c 退出 ctrl+L 清屏 mongo shell查询方法在mongo shell中，使用find()和findOne()方法执行读操作。 read-operations description db.collection.find(&lt;query&gt;) 查找集合中与匹配的文档，如果未指定或为空，则读取操作会选择集合中的所有文档 db.collection.find(&lt;query&gt;, &lt;projection&gt;) 查找与匹配的文档，返回特定字段 db.collection.find().sort(&lt;sort order&gt;) 返回排序结果 db.collection.find(&lt;query&gt;).sort(&lt;sort order&gt;) 返回匹配和排序结果 db.collection.find(...).limit(&lt;n&gt;) 限制输出结果为行 db.collection.find().pretty().limit() 匹配，格式化，限制输出 db.collection.find().limit().pretty() 同上 db.collection.find(...).skip(&lt;n&gt;) 跳过前行 db.collection.count() 返回集合中文档总数 db.collection.find().count() 返回匹配文档总数 db.collection.findOne(&lt;query&gt;) 查找并返回单一的文档，null表示未找到 管理命令助手 js db-administrative-methods description db.cloneDatabase(&lt;host&gt;) 从指定主机克隆当前数据库，noauth mode db.copyDatabase(&lt;from&gt;, &lt;to&gt;, &lt;host&gt;) copy db to db db.fromColl.renameCollection(&lt;toColl&gt;) rename collection db.repairDatabase() 修复当前db db.dropDatabases() 删除当前数据库 打开附加连接可以在mongo shell中创建一个新连接。 12345&gt;db = connect("&lt;host&gt;:&lt;port&gt;/&lt;db&gt;")#db = connect("192.168.1.11/admin")&gt;conn = new Mongo()&gt;db = conn.getDB("dbname") MongoDB CRUD操作CRUD操作就是创建(create)，读取(read)，更新(update)，删除(delete)文档(document)! 创建(create)操作创建或插入， 即是向 collection 添加新的 document。如果插入时集合不存在，插入操作会创建该集合。 123db.collection.insert()db.collection.insertOne()db.collection.insertMany() 读取(read)操作读操作，获取 collection 中的 document。 1db.collection.find() 更新(update)操作更新操作，修改 collection 中已经存在的 document。 1234db.collection.update()db.collection.updateOne()db.collection.updateMany()db.collection.replaceOne() 删除(delete)操作删除操作，是从一个 collection 中删除 document 的操作。 123db.collection.remove()db.collection.deleteOne()db.collection.deleteMany() 插入文档(Insert) 插入方法MongoDB提供了如下插入方法向collection中插入document： db.collection.insert(), 向集合中插入一个或多个文档; db.collection.insertOne(), 向集合中插入一个文档; db.collection.insertMany(), 向集合中插入多个文档. db.collection.insert()db.collection.insert(),向collection中插入一个或多个document。要想插入一个document，传递一个文档给该方法；要想插入多个documents，传递文档数组给该方法。 12345678910111213141516171819#插入一个文档db.user.insert( &#123; _id: "ZhangTest", name: "zhang", age: 2017, sex: "man" &#125;)#插入多个文档db.user.insert( [ &#123; name: "AAA", age: 20, status: "A" &#125;, &#123; name: "BBB", age: 21, status: "B" &#125;, &#123; name: "CCC", age: 22, status: "C" &#125; ]) db.collection.insertOne()db.collection.insertOne(),向collection中插入单个document。 12345678910db.user.insertOne( &#123; name: "zhang", age: "2017", sex: "man", education: "bachelor" &#125;)#此处并未自定义_id字段，因此它会自动添加_id字段 db.collection.insertMany()db.collection.insertMany(),向collection插入多个documents。 123456789db.user.insertMany( [ &#123; name: "AAA", age: "20", status: "A" &#125;, &#123; name: "BBB", age: "21", status: "B" &#125;, &#123; name: "CCC", age: "22", status: "C" &#125; ])#自动生成3个document的_id字段 插入操作的行为表现创建集合插入的时候如果collection不存在，那么插入操作会创建collection。 _id字段在MongoDB中，存储于collection中的每一个document都需要一个唯一的_id字段作为primary_key。如果一个插入的document操作遗漏了_id字段，则MongoDB driver会自动生成一个ObjectId。 原子性MongoDB中所有的写操作在单一文档层级上是原子的。 查询文档(Read)MongoDB提供了db.collection.find()方法从collection中读取document。 1234db.collection.find( &lt;query filter&gt;, &lt;projection&gt; )#&lt;query filter&gt;指明返回哪些document#&lt;projection&gt;指明返回匹配document的那些filed 示例12345678910111213141516171819202122232425db.user.insertMany( [ &#123; _id: 1, name: "A", favorites: &#123; artist: "Picasso", food: "pizza" &#125;, finished: [ 11, "AA" ], points: [ &#123; points: 85, bonus: 30 &#125;, &#123; points: 85, bonus: 10 &#125; ] &#125;, &#123; _id: 2, name: "B", favorites: &#123; artist: "Miro", food: "merigue" &#125;, finished: [ 22, "BB" ], points: [ &#123; points: 85, bonus: 20 &#125;, &#123; points: 64, bonus: 12 &#125; ] &#125;, &#123; _id: 3, name: "C", favorites: &#123; artist: "Gaogeng", food: "cake" &#125;, finished: [ 33, "CC" ], points: [ &#123; points: 67, bonus: 8 &#125;, &#123; points: 55, bonus: 21 &#125; ] &#125; ]) 查询和规划操作符Comparison: 1234567$eq$gt$gte$lt$ne$in$nin Logical： 1234$or$and$not$nor Element: 12$exists$type Evaluation: 1234$mod$regex$text$where Geospatial: 1234$geoWithin$geoIntersects$near$nearSphere Array: 123$all$eleMatch$size Bitwise: 1234$bitsAllSet$bitsAnySet$bitsAllClear$bitsAnyClear Comments: 1$comment Projection Operators: 1234$$eleMatch$meta$slice 选择collectino中所有document一个空的query filter会选择集合汇总所有文档。 12db.users.find(&#123;&#125;)db.user.find() 指定查询过滤条件1. 指定等于条件 1234&#123; &lt;field1&gt;: &lt;value1&gt;, ...&#125;#栗子db.user.find( &#123; name: &quot;C&quot; &#125; ) 2. 使用查询操作符指定条件 1234&#123; &lt;field1&gt;: &#123; &lt;operator1&gt;: &lt;value1&gt; &#125;, ... &#125;#栗子db.user.find( &#123; name: &#123; $in: [ &quot;A&quot;, &quot;B&quot; ] &#125; &#125; ) 3. 指定逻辑查询条件条件逻辑查询(AND, OR, NOT)。符合查询可以在集合文档的多个字段上指定条件。 123456789101112131415#ANDdb.user.find( &#123; name: &quot;A&quot;, age: &#123; $lt: 30&#125; &#125; )#ORdb.user.find( &#123; $or: [ &#123; name: &quot;A&quot; &#125;, &#123; age: &#123; $lt: 30 &#125; &#125; ]&#125; )#AND和ORdb.user.find( &#123; name: &quot;A&quot;, $or: [ &#123;age: &#123; $lt: 30 &#125; &#125;, &#123; type: 1 &#125; ]&#125; ) 嵌入式文档的查询当字段中包含嵌入文档时，查询可以指定嵌入文档中的精确匹配或使用圆点(.)表示法对嵌入文档的单个字段指定匹配。 12345678#精确匹配db.user.find(&#123; favorites: &#123; artist: &quot;Picasso&quot;, food: &quot;pizza&quot; &#125;&#125;)#圆点.表示法，记得加引号db.user.find( &#123; &quot;favorites.artist&quot;: &quot;Picasso&quot; &#125; ) 数组上的查询当字段包含数组，可查询精确的匹配数组或数组中特定的值。如果数组包含嵌入文档，可使用圆点表示法查询内嵌文档中特定的字段。 123456789101112131415161718192021222324252627#精确匹配db.user.find(&#123; finished: [ 11, &quot;AA&quot; ] &#125;)#匹配一个数组元素，会显示整个文档db.user.find(&#123; finished: &quot;BB&quot; &#125;)#匹配数组中指定元素，会返回整个文档db.user.find(&#123; &quot;finished.1&quot;: &quot;CC&quot; &#125;)#指定数组中的多个查询条件db.user.find(&#123; finished: &#123; $elemMatch: &#123;$gte: 11, $lt: 33&#125; &#125; &#125;)db.user.find(&#123; finished: &#123; $gt: 11, $lt: 33 &#125; &#125;)#嵌入文档数组db.user.find(&#123; &apos;points.points&apos;: &#123;$lte: 80 &#125; &#125;)db.user.find(&#123; &quot;points.0.points&quot;: &#123;$lte: 80&#125; &#125;)#元素组合满足查询条件db.user.find(&#123; &quot;points.points&quot;: &#123;$lte: 80&#125;, &quot;points.bouns&quot;: 20&#125;) 返回查询的映射字段默认地，MongoDB中的查询返回匹配文档中的所有字段。为了限制MongoDB发送给应用的数据量，我们可以在查询操作中包括一个projection文档。 映射文档映射文档限制了返回所有匹配文档的字段。映射文档可以致命包括哪些字段或排除哪些字段。这个就很不错了，可以过滤掉我们不需要的信息。 12345db.users.find( &#123;name: &quot;AAA&quot;&#125; ,&#123;_id: 0, name: 1, age: ture&#125; )db.user.find( &#123; name: &quot;BBB&quot;&#125;, &#123;_id: false&#125; )1或true，表示在返回的文档中包含字段；0或false，排除该字段； 更新文档(Update)更新方法： db.collection.updateOne(), 更新一个文档 db.collection.updateMany(), 更新多个文档 db.replaceOne(), 替换一个文档 db.collection.update(), 更新或替换一个文档 更新的行为表现 原子性：MongoDB中所有的写操作在单一文档层级上是原子的。 _id字段：不能更新_id字段的值，也不能用不同_id字段值的替换文档来替换已存在的文档。 文档大小：当执行更新操作增加的文档大小超过了为该文档分配的空间时，更新操作会在磁盘上重定位该文档。 字段顺序：MongoDB按照文档写入的顺序整理文档字段。但_id字段始终是文档中第一个字段；renaming操作可能会导致文档中的字段重新排序。 Update OperatorFields name description $currentDate 将字段值设置为当前日期(date or timestamp) $inc 按指定的数字递增字段的值 $min 指定的值小于字段的值时才更新 $max 指定的值大于字段的值时才更新 $mul 将字段的值乘以指定的数字 $rename 重命名一个字段 $set 设置文档中字段的值 $setOnInsert 如果更新导致文档插入，则设置字段的值 $unset 从文档中删除指定的字段， Array name description $ 用作更新与查询条件匹配的第一个元素的占位符 $[] 用作更新与查询条件匹配的文档的数组的所有元素的占位符 $[] xxx $addToSet 在集合中不存在元素时添加元素到数组 $pop 移除数组中的第一项或最后一项 $pull 删除所有匹配指定查询的数组元素 $push 向数组中添加项 $pullAll 从数组中删除所有匹配的值 Modifiers name description $each 修饰$push and $addToSet， 向数组中添加多个项 $position 修饰$push，在数组中指定位置添加元素 $slice 修饰$push，限制更新数组的大小 $sort 修饰$push，重新排列存储在数组中的文档 BitWise 1$bit 执行按位AND,OR,XOR更新 更新文档字段中指定字段为了修改文档中的字段，MongoDB提供了update operators，如用来修改值的$set。 1234567891011121314151617181920212223&#123; &lt;update operator&gt;: &#123; &lt;field&gt;: &lt;value&gt;, ...&#125;&#125;#更改指定字段的值db.user.update( &#123; _id: 1 &#125;, &#123; $set: &#123;name: &quot;SET&quot;&#125; &#125;)#删除指定字段，文档中其他字段还在db.user.update( &#123; _id: 1 &#125;, &#123; $unset: &#123;name: &quot;SET&quot;&#125; &#125;)#db.user.updateMany( &#123; _id: 2&#125;, &#123; $set: &#123;name: &quot;AAA&quot;, age: 222&#125; &#125;) 文档替换(Replace)当替换文档时，替换的文档必须仅仅有 &lt;field&gt;: &lt;value&gt;组成。替换文档可以有不同于源文档的字段，但_id字段是不变的。 **建议使用_id作为过滤条件，因为它是唯一的。 123456789101112db.collection.replaceOne()db.user.replaceOne( &#123; name: &quot;AAA&quot; &#125;, &#123; name: &quot;A&quot;, age: 2, sex: &quot;man&quot;, favorites: &#123; artist: &quot;Dali&quot;, food: &quot;banana&quot; &#125; &#125;)db.user.update( &#123; _id: 1&#125;, &#123; name: &quot;A&quot;, age: 2, sex: &quot;man&quot;, favorites: &#123; artist: &quot;Dali&quot;, food: &quot;banana&quot; &#125; &#125;) 删除文档(Delete)方法： db.collection.remove(), 删除一个文档，或所有满足匹配的文档; db.collection.deleteOne(), 删除匹配最多条件的单个文档，即使可能有多个文档可能与指定过滤条件匹配; db.collection.deleteMany(), 删除所有匹配指定过滤条件的文档。 删除的行为表现 Indexes删除操作不会删除索引，即使从集合中删除了所有的文档。 原子性MongoDB中所有的写操作在单一文档层级上是原子的。 删除1234567891011121314#删除所有文档db.collectin.deleteMany(&#123;&#125;)db.collection.remove(&#123;&#125;)#删除所有满足条件的文档db.user.remove( &#123; name: &quot;A&quot; &#125; )db.user.deleteMany( &#123; name: &quot;A: &#125; )#仅删除一个满足条件最多的文档db.user.deleteOne( &#123; name: &quot;A&quot; &#125; )db.users.remove( &#123; name: &quot;A&quot;&#125;, 1) 聚合(Agrregation)聚合操作处理数据记录并返回计算的结果。聚合操作将多个文档中的值(value)分组，并对分组的数据进行各类操作以返回单个结果。 MongoDB提供了三种方式进行聚合： aggregation pipeline(聚合管道); map-reduce function(映射化简); single aggregation methods(聚合指南) Aggregation Pipeline(聚合管道) MongoDB的聚合框架(aggregation framework)是仿照数据处理管道的概念(concept)。Document输入多级管道，它将Document转换为聚合结果。 最基本的pipeline stage提供了：类似查询(query)操作的过滤器(filter)和类似修改(modify)输出文档格式的文档转换。 其他pipeline operation提供了按特定字段对文档进行分组和排序的工具，以及聚合数组内容(包括文档数组)的字段或工具。此外，pipeline stage可以使用运算符(operators)来处理任务。(如计算平均值和连接等…) pipeline通过在MongoDB中使用本地操作，从而提供了高效的数据聚合。所以也是MongoDB中数据聚合的首选方法。 aggregation pipeline能够在一个共享的集合上操作。 aggregation pipeline可以使用索引来提高某些阶段的性能(performance)。另外，管道聚合还有一个内部优化阶段(optimization phase)。 Map-Reduce(映射化简) 一般来说，map-reduce操作有两个阶段： map stage: 处理每个文档并未每个输入文档发出一个或多个对象(object)； reduce stage: 结合映射操作的输出。 可选地，map-reduce有一个对结果做最后修改的最后阶段。与aggregation-operation类似，map-reduce可以指定查询条件来选择一个输入文档，以及对结果进行排序和限制。 map-reduce使用自定义的JavaScript函数执行映射和化简操作，以及可选的最终操作。与聚合管线相比，自定义的JavaScript提供了很大的灵活性。一般来说，map-reduce比aggregation pipeline效率更低，更复杂。 map-reduce能够在一个共享的集合上操作，同样也可以输出到共享集合。 Single Purpose Aggregation Operations(聚合指南) MongoDB同样提供了db.collection.count()和db.collection.distinct()。 所有这些操作都从单个集合中聚合文档，虽然这些操作提供了对常见聚合过程的简单访问，但它们缺少aggregation pipeline和map-reduce的灵活性和功能。 Aggregation Pipeline(聚合管道)MongoDB的聚合框架是仿照数据处理管道的概念。文档输入多级管道，它将文档转换为聚合结果。 当map-reduce的复杂性可能是没有保证的，aggregation pipeline为map-reduce提供了一个可选也可能是聚合任务的首选解决方案。aggregation pipeline对key value和result size有一些限制。 映射化简 聚合指南 MongoDB文本索引MongoDB支持在字符串内容上执行文本检索(text search)的查询操作。视图不支持文本检索。为了执行文本检索，MongoDB使用text index和$text操作符。text索引可以包括任何值为字符串或字符串元素数组的字段。 栗子： 1234567db.sample.insert( [ &#123; _id: 1, name: "A", description: "AAA" &#125;, &#123; _id: 2, name: "B", description: "BBB" &#125;, &#123; _id: 3, name: "C", description: "CCC" &#125; ]) 为了执行文本检索查询，你必须在集合有一个text索引，一个集合只能有一个文本检索索引，但是这个索引可以覆盖多个字段。 启动在name和description字段上的文本检索： 123db.sample.createIndex( &#123; name: "text", description: "text" &#125;) 使用$text查询操作符在一个有text index的集合上执行文本检索 123456789101112131415db.sample.find(&#123; $text: &#123; $search: &quot;A B&quot; &#125;&#125;)#精确检索db.sample.find(&#123; $text: &#123; $search: &quot;A \&quot;B\&quot;&quot; &#125;&#125;)#词语排除db.sample.find(&#123; $text: &#123; $search: &quot;A B -AAA&quot; &#125;&#125;) MongoDB默认返回没排序的结果。然而文本检索将会对每个文档计算一个相关性分数，表明该文档与查询的匹配程度。为了使用相关性分数进行排序，你必须使用 $meta textScore字段进行映射然后基于该字段进行排序。 1234db.sample.find( &#123; $text: &#123; $search: &quot;A AAA B&quot; &#125; &#125;, &#123; score: &#123; $meta: &quot;textScore&quot; &#125; &#125;).sort( &#123; score: &#123; $meta: &quot;textScore&quot; &#125; &#125;) 文本检索可以在聚合管道中使用。 文本索引 文本检索操作符 在管道聚合中使用文本索引 使用基本技术Rosette语义平台的文本索引 文本检索语言 MongoDB数据模型MongoDB的数据具有灵活的模式，集合本身没有对文档结构的规则性校验。 数据模型设计介绍关系型数据库要求你再插入数据之前必须先定义好一个表的模式结构，而MongoDB的集合并不限制文档结构。这种灵活性让对象和数据库文档之间的映射变得很容易。即使数据记录之间有很大的变化，每个文档也可以很好的映射到各条不同的记录。当然，在实际使用中，同一个集合中的文档往往都有一个比较类似的结构。 数据模型设计中最具挑战性的是在应用程序需求，数据库引擎性能要求和数据读写模式之间的权衡考量。 文档结构引用(reference)引用方式通过存储链接或引用信息来实现两个不同文档之间的关联。应用程序可以通过解析这些数据库引用来访问相关数据。简单来讲，这就是规范化的数据模型。 内嵌(embedded data)内嵌方式指把相关联的数据保存在同一个文档之内。MongoDB的文档结构允许一个字段或一个数组内的值为一个嵌套的文档。这种冗余的数据模型可以让应用程序在一个数据库内完成对相关数据的读取或修改。 写操作的原子性在MongoDB中，写操作在文档级别是原子的(atomic)，没有一个单独的写操作可以原子地影响多个文档或多个集合。但，对原子性写操作利好的内嵌数据模型会限制应用程序对数据的使用场景。 嵌入(embdded)数据的非规格化(denormalized)数据模型将单个文档所表示的实体(entity)的所有相关数据组合在一起。这有利于原子写操作，因为单个写操作可以插入或更新实体的数据； 规格化(normalizing)数据通过多个集合拆分数据，并需要多个不是原子集合的写操作。 文档的增长如果文档的大小超出分配给文档的原空间大小，那么MongoDB就需要把文档从磁盘上的现有位置移动到一个新的位置以存放更多的数据。这种数据增长的情况也会影响到是否要使用规范化或非规范化。 数据的使用和性能设计文档模型时，一定要考虑应用程序会如何使用你的数据。 例如： 假如应用程序通常只会使用最近插入的文档，那么可以考虑使用限制集； 假如应用会做大量的读操作，那么可以加多一些索引的方法来提升常见查询的性能。 文档验证MongoDB提供了在更新和插入期间验证(validate)文档的功能(capability)。验证规则是在每个集合中指定使用验证符(validator)选项，利用一个文档指定验证堆栈或表达式。 通过collMod命令附带验证符选项向一个已经存在的集合添加文档验证； 利用db.createCollection()命令附带验证符选项来创建文档验证规则。 123456789db.createCollection( "contacts", &#123; validator: &#123; $or: [ &#123; phone: &#123; $type: "string" &#125; &#125;, &#123; email: &#123; $regex: /@mongodb\.com$/ &#125; &#125;, &#123; status: &#123; $in: [ "Unknown", "Incomplete" ] &#125; &#125; ] &#125;&#125; ) MongoDb同样提供了validationLevel选项，它确定了MongoDb在更新期间如何将验证规则应用到已有文档，以及验证操作选项。它确定MongoDB是否错误并拒绝违反验证规则的文档，或者警告日志中的违规，但允许无效的文档。 行为验证发生在更新和插入期间。当向一个文档添加验证，在修改之前，现有文档不会进行验证检查。 现有文档 可使用validationLevel选项来控制MongoDB怎样处理现有文档。 默认情况下，MongoDB是严格的，并且将验证规则应用于所有插入和更新操作。 12345678#moderate level#在中等级别下，对不符合验证标准的现有文档更新将不会检查有效性db.runCommand(&#123; collMod: "contacts", validator: &#123; $or: [ &#123; phone: &#123; $exists: true &#125; &#125;, &#123; email: &#123; $exists: true&#125;&#125; ] &#125;, validationLevel: "moderate"&#125;) 设置validationLevel为off以禁用验证功能。 接受或拒绝无效文档 validationAction选项决定了MongoDB如何处理违反(violate)验证规则的文档。 默认情况下，validationAction是错误的，并且拒绝任何违反验证条件的插入和更新操作。 123456789101112131415161718#当validationAction为warn时，MongoDB记录所有违反行为，但允许插入或更新操作。db.createCollection( "contacts", &#123; validator: &#123; $or: [ &#123; phone: &#123; $type: "string" &#125; &#125;, &#123; email: &#123; $regex: /@mongodb\.com$/ &#125; &#125;, &#123; status: &#123; $in: [ "Unknown", "Incomplete" ] &#125; &#125; ] &#125;, validationAction: "warn" &#125;)#如下违规操作将会报警，并由于是warn，所以写入成功db.contacts.insert( &#123; name: "Amanda", status: "Updated" &#125; ) 约束(restriction) 无法在admin,local,config数据库的集合 和 system.*集合 里面指定验证符(validator)。 绕过文档验证 通过bypassDocumentValidation选项来绕过文档验证。 数据建模理论数据模型设计一个高效的数据模型能够很好的满足应用程序的需求。设计一个文档数据结构最关键的考量就是决定是使用嵌套(embdded)还是引用(reference)。 内嵌式数据模型(非规范化)在MongoDB里面，可以把相关的数据包括在一个单个的结构或者文档下面。这样的数据模型也叫作非规范化模式。 内嵌数据可以让应用程序把相关的数据保存在同一条数据记录里面，这样，应用程序就可以发送较少的请求给MongoDB来完成常用的查询和更新请求。 一般来说，下述情况建议使用内嵌数据模型： 数据对象之间有包含(contain)关系； 数据对象间有一对多的关系。 通常情况下，内嵌数据会对读操作有比较好的性能提高，可以使应用程序在一个单个操作就可以完成对数据的读取。同时，内嵌数据也对更新相关数据提供了一个原子性写操作。 规范化数据模型一般来说，下述情况可以使用规范化模型： 内嵌数据会导致很多数据的重复，并且读性能的优势又不足与盖过数据重复的弊端时； 需要表达比较复杂的多对多关系时； 大型多层次结构数据集。 MongoDB特性和数据模型的关系MongoDB的数据建模不仅仅取决于应用程序的数据需求，也要考虑MongoDB本身的一些特性。 文档增长性(increase)如果更新操作导致文档大小增加，那么可能需要重新设计数据模型，在不同文档之间使用引用的方式而非内嵌、冗余的数据结构。MongoDB会自动调整空白填充的大小以尽可能的减小文档迁移。你也可以使用一个预分配策略来防止文档的增长。 原子性(atomic)在MongoDB中，所有在文档级别的操作都具有原子性。一个单个写操作最多只可以修改一个文档。即使是一个会改变同一个集合中多个文档的命令，在同一时间也只会操作一个文档。即便是涉及多个子文档的多个操作，只要是在同一文档之内，这些操作仍旧是有原子性的。 尽可能保证那些需要在一个原子操作内进行修改的字段定义在同一个文档里面。如果你的应用程序允许对两个数据的非原子性更新操作，那么可把这些数据定义在不同的文档内。 把相关数据定义到同一个文档里的内嵌方式有利于这种原子性操作。对于那些使用引用来关联相关数据的数据模型，应用程序必须再用额外的读和写操作去取回和修改相关的数据。 分片(sharding)MongoDB使用分片来实现水平扩展。使用分片的集群可以支持海量的数据和高并发读写。使用分片技术把一个数据库内的某一个集合的数据进行分区，从而达到把数据分到多个mongod实例(或分片上)的目的。 MongoDB依据分片键分发数据和应用程序的事务请求。选择一个合适的分片键对性能有很大的影响，也会促进或阻碍MongoDB的定向分片查询和增强的写性能。所以在选择分片键的时候要仔细考量分片键所用的字段。 索引(index)对常用操作可以使用索引来提高性能。对查询条件中常见的字段，以及需要排序的字段创建索引。MongoDB会对_id自动创建唯一索引。 创建索引时，需要考虑索引的下述特征： 每个索引要求至少8KB的数据空间； 每增加一个索引，就会对写操作性能有一些影响。对于一个写多读少的集合，索引会变得很费时。因为每个插入必须要更新所有索引； 每个索引都会占一定的硬盘空间和内存(对于活跃的索引)。索引可能会用到很多这样的资源，因此对这些资源要进行管理和规划，特别是在计算热点数据大小的时候。 集合的数量某些情况下，可能需要把相关的数据保存到多个集合里面。比如： 12&#123; log: &quot;dev&quot;, ts:..., info: ... &#125;&#123; log: &quot;debug&quot;, ts:..., info: ... &#125; 一般来说，很大的集合数量对性能没有什么影响，反而在某些场景下有不错的性能。使用不同的集合在高并发批处理场景下会有很好的帮助。 当使用有大量集合的数据模型时，请注意： 每个集合有几KB的额外开销； 每个索引(包含_id)，需要至少8KB的数据空间； 每个MongoDB的数据库有且仅有一个命名文件(namespace file)(.ns)。这个命名文件保存了数据库的所有元数据，每个索引和集合在这个文件里都有一条记录； MongoDB的命名文件有大小的限制(默认16MB)。利用db.system.namespaces.count()查看。 包含大量小文档的集合如果你有一个包含大量小文档的集合，则应该考虑为了性能而嵌入。如果你可以通过一些逻辑关系将这些小文档分组，并且你经常通过这个分组来检索文档，那么你应该考虑将小文档”卷起来”成为包含一系列嵌入式文档的大文档。 将这些小文档“卷起来”成为逻辑分组，意味着检索一组文档的查询设计顺序读取和较少的随机磁盘访问。此外，将文档“卷起”并将公共字段移动到较大的文档会使字段上的索引受益。公共字段的副本将会减少，并且相应索引中的关联键条目也会减少。 然而，如果你通常只需要检索分组中的一个文档的子集，那么“滚动”文档可能无法提供更好的性能。此外，如果晓得，独立的文档代表数据的自然模型，那你应该维护改模型。 小文档的存储优化(storage optimization)每个MongoDB文档都包含一定的开销(overhead)，这些开销通常是无关紧要的。但如果文档只有几个字节，那就相当重要了。 考虑以下有关优化这些集合的存储利用率的建议： 显示地使用_id字段； 使用较短的字段名称； 嵌套文档。 数据生命周期管理数据模型决策应考虑数据生命周期管理。 集合的*TTL功能在一段时间后标识文档到期。如果应用程序需要一些数据才能在数据库中持久化一段有限的时间，请考虑使用TTL特性。 此外，你的应用程序仅使用最近插入的文档，请考虑限制集。 数据模型例子与范式文档关系建模一对一关系建模：内嵌文档模型用内嵌文档方式实现一对一关系。 一对多关系建模：内嵌文档模型用内嵌文档方式实现一对多关系。 一对多关系建模：文档引用模式用文档引用实现一对多关系。 树结构建模父文档引用父文档引用模式用一个文档来表示树的一个节点。每一个文档除了存储节点的信息，同时也保存该节点父节点文档的id值。 1234567891011121314db.test.insert(&#123; _id: "MongoDB", parent: "Databases" &#125;)db.test.insert(&#123; _id: "Databases", parent: "Programming" &#125;)db.test.insert(&#123; _id: "Programming", parent: "Books" &#125;)db.test.insert(&#123; _id: "Books", parent: null &#125;)#查询父节点db.test.findOne(&#123; _id: "MongoDB" &#125;).parent#对parent字段创建索引，这样可以快速的按照父节点查找db.test.createIndex(&#123; parent: 1 &#125;)#查询一个父节点的所有子节点db.test.find(&#123; parent: "Databases" &#125;) 子文档引用子文档引用模式用一个文档来表示树的一个节点。每一个文档除了存储节点信息外，同时也用一个数组来保存该节点的所有子节点的id值。 1234567891011121314db.test.insert(&#123; _id: "MongoDB", children: [] &#125;)db.test.insert(&#123; _id: "Databases", children: [ "MongoDB", "dbm" ]&#125;)db.test.insert(&#123; _id: "Programming", children: [ "Languages", "Databases" ]&#125;)db.test.insert(&#123; _id: "Books", children: [ "Programming" ]&#125;)#查询子节点db.test.findOne(&#123; _id: "Databases"&#125;).children#对children字段创建索引，这样就可以快速按照子节点查找db.test.createIndex(&#123; children: 1 &#125;)#查找一个子节点的父节点和同级节点db.test.find(&#123; children: "MongoDB" &#125;) 祖先数组(ancestors array)祖先数组模式用一个文档来表示树的一个节点。每一个文档除了存储节点的信息，同时也存储了对父文档及祖先文档的id值。 1234567891011121314db.test.insert(&#123; _id: "MongoDB", ancestors: [ "Books", "Programming", "Databases" ], parent: "Databases" &#125;)db.test.insert(&#123; _id: "Databases", ancestors: [ "Books", Programming" ], parent: [ "MongoDB", "dbm" ]&#125;)db.test.insert(&#123; _id: "Programming", ancestors: [ "Books" ], parent: "Books" &#125;)db.test.insert(&#123; _id: "Books", ancestors: [ ], parent: null &#125;)#查询一个节点的祖先节点db.test.findOne(&#123; _id: "MongoDB" &#125;).ancestors#对ancestors创建索引db.test.createIndex(&#123; ancestors: 1 &#125;)#利用ancestors字段来查找某个节点的所有子代节点db.test.find(&#123; ancetors: "Programmming" &#125;) 物化路径(materialized path)物化路径模式将每个树节点存储在文档中。除了存储节点信息外，同时也存储了祖先文档或路径的id值。 123456789101112131415db.test.insert(&#123; _id: "Books", path: null &#125;)db.test.insert(&#123; _id: "Programming", path: ",Books," &#125;)db.test.insert(&#123; _id: "Databases", path: ",Books,Programming," &#125;)db.test.insert(&#123; _id: "MongoDB", path: ",Books,Programming,Databases," &#125;)#查询整个树的所有节点并按path排序db.test.find().sort(&#123; path: 1 &#125;)#可以在path字段上使用re来查询db.test.find(&#123; path: /,Programming,/ &#125;)db.test.find(&#123; path: /^,Books,/ &#125;)#在path字段上创建索引db.test.createIndex(&#123; path: 1 &#125;) 嵌套集合(nested set)嵌套集合模式对整个树结构进行一次深度优先的遍历。遍历时候对每个节点的压栈和出栈作为两个不同的步骤记录下来。每一个节点就是一个文档，除了节点信息外，文档还保存父节点的id以及遍历的两个步骤编号。压栈是的步骤保存到left字段里，而出栈时的步骤编号则保存到right字段里。 12345678db.test.insert(&#123; _id: "Books", parent: 0, left: 1, right: 12 &#125;)db.test.insert(&#123; _id: "Programming", parent: "Books", left: 2, right: 11 &#125;)db.test.insert(&#123; _id: "Databases", parent: "Programming", left: 5, right: 10 &#125;)db.test.insert(&#123; _id: "MongoDB", parent: "Databases", left: 6, right: 7 &#125;)#查询摸个节点的子代节点db.test.find(&#123; left: &#123; $gt: db.test.findOne(&#123; _id: "Databases" &#125;), right: &#123; $lt: db.test.findOne(&#123;"_id: "Databases"&#125;) &#125; &#125;) 具体应用模型举例原子性事务建模如何使用内嵌技术来保证同一文档内相关字段更新操作的原子性。 举例来说，假设你在设计一个图书馆的借书系统，你需要管理书的库存量以及出借记录。一本书的可借数量加上借出数量的和必须等于总的保有量，那么对这两个字段的更新必须是原子性的。 关键词搜索建模描述了一种把关键词保存在数组里并使用多键索引来实现关键词搜索功能的方法。 为实现关键词搜索，在文档内增加一个数组字段并把每一个关键词加到数组里。然后你可以对该字段建一个 多键索引。这样你就可以对数组里面的关键词进行查询了。 货币数据建模处理货币数据的应用程序通常需要捕获小数(franctional)货币单位，并在执行算术时需要精确地模拟十进制四舍五入。许多现代系统(float,double)使用的基于二级制的浮点运算不能精确地表示小数，而且需要某种程度的近似，因而不适合于货币运算。因此，在货币数据建模时，这一约束是一个重要的考虑因素。 数字模型如果需要查询数据库中精确、数学书有效匹配或需要执行Server端算术，则数字模型可能是适合的。 非数字模型如果需要在Server端做一些对货币数值的数学计算，那么严格精度可能会更合适一些。 时间数据模型MongoDB默认存储UTC时间，并将任何本地时间转换成这种形式。 MongoDB管理administration The administration 文档说明了MongoDB实例和部署正在进行的操作和维护。本文档包括这些问题的高级概述，以及涵盖操作MongoDB的特定过程的教程。 操作清单(operation checklist)如下清单，提供了帮助你避免在MongoDB部署中出现问题的建议。 文件系统(file system) 将磁盘分区与RAID配置对齐； 避免对dbpath使用NFS。使用NFS会导致性能下降和不稳定； 针对Linux/Unix的文件格式，建议使用XFS或EXT4。如果可能的话，对MongoDB使用XFS性能会更好； 对于WiredTiger存储引擎，强烈建议使用XFS来避免使用EXT4时发现的性能问题； 针对Windows，不要使用FAT(FAT16/32/exFAT)文件系统，请使用NTFS文件系统。 复制(replication) 验证所有非隐藏副本集成员的RAM, CPU, 磁盘, 网络设置, 配置等方面是否相同； 配置oplog的大小来适合你的用例； 确保副本集包好至少3个以journaling方式运行的数据承载节点； 在配置副本集成员时使用主机名(hostname)，而不是IP地址； 确保所有的mongod实例之间使用全双工网络； 确保每台主机都能解析它自己； 确保副本集包含奇数个投票的成员(voting members)，确保票数不会相等则一定会有主被选举出来； 确保mongod实例有0或1票； 为了高可用(high availability)，副本集集群最少部署3台数据中心。 分片(sharding) 将配置服务器放置于专用硬件，以便在大型集群中实现最佳性能。确保硬件有足够的RAM来讲数据文件完全存储到内存中，并且有专门的存储； 使用NTP同步分片集群上所有组件的时钟； 确保Mongod, mongos和配置服务器之间的全双工网络连接； 使用CNAME将配置服务器标识到集群中，以便可以在不停机的情况下重命名和重新编号配置服务器。 Journaling 确保所有实例都使用journaling； 将journal放置于低延迟(low-latency)磁盘上，用于编写密集的工作负载。注意，这将影响快照式备份(snapshot)，因为构成数据库状态的文件将驻留在单独的volume上。 硬件(hardware) 使用RAID10和SSD能够获得最佳性能； 确保每个mongod为它的dbpath提供了IOPS； 在虚拟环境中运行时，避免动态内存功能； 避免将所有副本集成员放置于相同的SAN(存储区网络)中。 部署到云上 AWS; Azure; Aliyun; Tencent. 操作系统配置Linux 关闭hugepages和defrag； 调整存储数据库文件设备上的readahead设置，以适应用例； 在虚拟环境中的RHEL7/CENTOS7上禁用优化工具； 为SSD驱动使用noop或deadline磁盘调度； 禁用NUMA或将vm.zone_reclaim_mode设置为0，并运行node interleaving的mongod实例； 调整硬件的ulimit值以适应实例； 对dbpath挂载点使用noatime； 对你的部署配置足够的文件句柄(fs.file-max value of 98000)，内核pid限制(kernel.pid_max value of 64000)，每个进程的最大线程数(kernel.threads-max value 0f 64000)； 确保你的系统配置有swap交换分区； 确保系统默认TCP keepalived设置正确。 Windows 考虑禁用NTFS的最后访问时间更新。这类似与在Unix-like系统上禁用atime。 备份(backup) 安排备份和恢复过程的定期测试，以便手头有时间估计，并恢复其功能。 监控(monitor) 监视Server的硬件统计信息(磁盘使用，CPU，可用磁盘空间…) 监视mongodb的状态。 负载均衡(load balance) 配置负载均衡启用”sticky session”或“client affinity”，对现有连接有足够的超时时间； 避免放置负载均衡器在MongoDb集群或副本集组件。 开发清单(development checklist)如下清单，提供了帮助你避免在MongoDB部署期间出现的问题的建议。 数据持久性(data durability) 确保副本集至少包含3个(带有w:majority)数据承载节点，这3个数据承载节点需要为副本集的高数据持久性； 确保所有实例都是用了journaling。 架构设计(schema design)MongoDB中的数据具有动态结构。collection并不要求document结构。这有助于迭代开发和多态性。然而，集合中的文档通常具有高度的同类结构。 确保你需要的集合集中的索引(indexes)支持你的查询(query)。除了_id索引，你必须显式的创建所有索引； 确保你的架构设计支持你的开发类型； 确保你的架构设计不依赖于长度不受绑定的索引数组； 再架构设计时考虑文档大小限制。 复制(replication) 使用奇数个副本集成员以确保选举顺利进行。如果有偶数个成员，请使用仲裁者(arbiter)以确保级数的选票； 确保使用监控工具和适当的写关注来保持从库数据最新； 不要使用从库读取来扩展整体读取吞吐量。 分片(sharding) 确保你的sharded key将负载均匀地分配到分片上； 对需要按分片数进行缩放的工作负载(workload)使用有针对性的操作； 对非目标(non-targeted)查询，总是从主节点读取可能对陈旧或孤立的数据很敏感； 当向新的非散列(hash)分片集合中插入大数据集时，Pre-split and manually balance chunks。 驱动(drivers) 使用连接池(connection pooling)； 确保你的应用程序在复制集选举期间还能够处理瞬时写入(transient write)和错误读取； 确保你的应用程序处理失败的请求并适时地重试它们； 使用指数退避逻辑重试数据库请求； 如果需要计算数据库操作的编译执行时间，对读操作使用cursor.maxTimeMS()，对写操作使用wtimeout。 性能(MongoDB Perfomance) 当遇到性能下降时，通常与数据库的访问策略、硬件可用性和开放的数据库连接数相关； 一些用户可能由于不适当的索引策略或结果不足而经历性能限制，或由于架构设计模式差； 性能问题可能表明数据库正以最大限度运行，是时候给数据库添加额外的容量(capacity)了。尤其是，应用程序的工作集应该有足够的物理内存。 锁紧性能(lock performance) MongoDB使用锁系统来确保数据集的一致性。如果某些操作需要长时间运行(long-running)，或队列窗体，随着请求和操作等待lock，性能将会下降； 锁相关的减速是可以间歇的，可查看lock部分是否影响了性能； locak.deadlockCount提供了遭遇死锁(deadlocks)的次数； 如果globalLock.currentQueue.total很高，则可能有大量的请求在等待lock。这表明并发问题(concurrency issue)可能影响性能； 如果globalLock.totalTime时间比uptime高，那么数据库在锁定状态中存在了大量时间； 长查询(long query)可能会导致索引无效使用、非最佳(non-optimal)建构设计、差的查询结构、系统体系结构问题、RAM不足导致页面错误(page fault)和磁盘读取。 连接数(number of connections)在某些情况下，应用程序和数据库之间的连接数量可能超出服务器处理请求的能力。serverStatus文档中的以下字段可以提供观察： globalLock.activeClients包含正在进行或排队的活动操作的客户端总数； connnections由以下两个字段组成： 1，connections.current连接到数据库实例的当前客户端总数； 2，connections.available可用的连接总数。 如果有大量的并发程序请求，则数据库可能无法满足需求。那么就需要增加部署的容量。 对于读操作巨大(read-heavy)的应用程序，增加你的副本集大小并将读操作分发给SECONDARY。对于写操作巨大(write-heavy)的应用程序，部署分片并将一个或多个分片添加到分片集群中，以便在mongod实例之间分配负载。 连接数到达峰值也可能是应用程序或驱动错误所导致的结果。 除非收到系统范围的限制，否则MongoDB对传入连接没有限制。在基于Unix系统上，可使用ulimit命令或修改/etc/sysctl系统文件来修改系统限制。 数据库性能分析(database profiling)MongoDB的profiler是一种数据库分析系统，可以帮助识别低效的查询和操作。 有如下分析级别(profiling-level)可用： Level Settiing 0 Off.No profiling 1 On.Only includes “slow” operations 2 On.Includes all operations 在mongo shell中运行如下命令来配置性能分析器： 123#dbsetProfilingLever()db.setProfilingLevel(1) slowOpThresholdMs的设置定义了什么是一个slow操作，要设置一个慢操作的阈值(threshold)，可以在运行时作为db.setProfilingLevel()操作的一个参数来配置slowOpThresholdMs。 默认情况下，mongod将会把所有的慢查询(slow query)记录到日志，这是由slowOpThresholdMs定义的。 通过在mongo shell中使用show profile，你可以在数据库中的system.profile集合中查看性能分析器的输出。或者执行如下操作： 12345#返回超过100ms的所有操作，这个值请高于阈值`slowOpThresholdMs`db.system.profile.find( &#123; millis: &#123; $gt: 100 &#125; &#125;) 你必须使用查询操作符去访问system.profile文档中的查询字段。 数据库性能分析器(databases profiler)数据库性能分析器(db profiler)收集有关MongoDB的写操作、游标和运行在mongod实例上的命令的细微数据，你可以在每个数据库或每个实例基础上启用性能分析(profiling)。默认情况系，分析器是关闭的。启用profiling的时候需要配置profiling leverl。 The database profiler将所有的数据收集到system.profile集合中，它是一个限制集(capped collection)。 分析等级(Profiling levels) 0， 关闭分析器，不收集任何数据。mongod总是将操作时间长于slowOpThresholdMs的值写入日志。这是默认分析器级别； 1， 只收集慢操作的分析数据。默认是以100ms； 2， 收集所有数据库操作的分析数据。 启用分析器(profiling)和设置分析级别(profiling level)当启用profiling，也要设置profiling level，分析器将数据记录到system.profile集合。当你在数据库中启用profiling后，MongoDB会在数据库中创建system.profile集合。 使用db.setProfilingLevel()来设置profiling level和启用profiling。 1db.setProfilingLevel(1) 指定慢操作的阈值(the Threshold for slow operations) 慢操作的阈值(threshold)应用于整个mongod实例。当你修改了阈值，那你就对所有的数据库实例进行了修改。修改了数据库慢操作的阈值同样也会影响整个mongod实例性能分析子系统的慢操作阈值。默认情况下，慢操作的阈值为100ms。性能分析level-1将会记录长于阈值的慢操作到日志。 要更改阈值，请将两个参数(parameter)在mongo shell传递给db.setProfilingLevel()。第一个参数是为当前的数据库设置profiling level，第二个参数是为整个mongod实例设置默认的慢操作阈值。 栗子： 123456mongo&gt;use zhang&gt;db.serProfilingLevel(1,100)#会在zhang数据库下生产system.profile集合 检查分析等级(check profiling level) 1234567db.getProfilingStatus()#default#&#123; &quot;was&quot; : 0, &quot;slowms&quot; : 100 &#125;db.getProfilingLevel()#0 为一个完整的mongod实例启用profiling 在测试环境中，处于开发目的，你可以为一个完整的mongod实例启用profiling功能。性能分析等级应用于mongod实例中的所有数据库。 12#设置level：1，slowOpThresholdMs: 50mongod --profile 1 --slowms 50 数据库分析和分片 无法对mongos实例启用profiling。要对分片集群启用profiling功能，你必须对分片集群中的每个mongod实例启用profiling功能才行。 查看性能分析器的数据(profiler data)数据库性能分析器关于数据库操作的日志信息放置于system.profile集合中。如需查看性能信息，请查询该集合。 栗子： 1234567891011121314151617db.system.profile.find()db.system.profile.find().limit(10).sort(&#123; ts: -1 &#125;).pretty()#指定时间db.system.profile.find( &#123; millis: &#123; $gt: 5 &#125; &#125; ).pretty()#除了某个命令外db.system.profile.find(&#123; op: &#123; $ne: &apos;cmd&apos; &#125; &#125;).pretty#某个特定集合db.system.profile.find( &#123; ns: &apos;db.collection&apos; &#125; ).pretty()#显示最近的事件show profile 分析器开销(profiler overhead)分析器对性能影响很小。system.profile集合是一个默认大小为1MB的限制集。这样大小的集合通常可以存储上千份分析文档，但一些应用程序可能在每次操作中只使用或多或少的分析数据。 在Primary上面修改system.profile集合的大小 停止profiling； 删除(drop)system.profile集合； 新建一个system.profile集合； 重启profiling。 12345use dbdb.serProfilingLevel(0)db.system.profile.drop()db.createCollection( &quot;system.profile&quot;, &#123; capped: true, size: 4000000 &#125; )db.setProfilingLevel(1) 在Secondary上修改system.profile集合的大小 在Secondary上修改system.profile集合的大小，你必须停止Secondary，然后以standalone模式运行它，之后执行修改步骤。当做完上述步骤之后，以一个副本集成员的方式使用standalone模式重启它。 禁用显见的大页面(Disable Transparent Huge Pages)Transpatent Huge Pages(THP)是一个Linux的内存管理系统，通过使用更大的内存页，减少了在具有大量内存的机器上进行Translation Lookaside Buffer(TLB)查找的开销。 然而，数据库工作负载(workload)在THP中的性能往往很差，因为它们往往具有稀疏的(sparse)而不是连续的(contiguous)内存访问模式。你应该在Linux机器上禁用THP来确保MongoDB获得最佳的性能。 1. 创建init.d脚本 12345678910111213141516171819202122232425262728293031323334353637383940#!/bin/bash### BEGIN INIT INFO# Provides: disable-transparent-hugepages# Required-Start: $local_fs# Required-Stop:# X-Start-Before: mongod mongodb-mms-automation-agent# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Disable Linux transparent huge pages# Description: Disable Linux transparent huge pages, to improve# database performance.### END INIT INFOcase $1 in start) if [ -d /sys/kernel/mm/transparent_hugepage ]; then thp_path=/sys/kernel/mm/transparent_hugepage elif [ -d /sys/kernel/mm/redhat_transparent_hugepage ]; then thp_path=/sys/kernel/mm/redhat_transparent_hugepage else return 0 fi echo 'never' &gt; $&#123;thp_path&#125;/enabled echo 'never' &gt; $&#123;thp_path&#125;/defrag re='^[0-1]+$' if [[ $(cat $&#123;thp_path&#125;/khugepaged/defrag) =~ $re ]] then # RHEL 7 echo 0 &gt; $&#123;thp_path&#125;/khugepaged/defrag else # RHEL 6 echo 'no' &gt; $&#123;thp_path&#125;/khugepaged/defrag fi unset re unset thp_path ;;esac 2. 使之可执行 1chmod 755 /etc/init.d/disable-transparent-hugepages 3. 配置操作系统以在开机的时候运行它 12345678910#Debian系列update-rc.d disable-transparent-hugepages defaults#RedHat系列chkconfig --add disable-transparent-hugepages#SUSEinsserv /etc/init.d/disable-transparent-hugepages 4. 如果适用，覆盖(override)tuned和ktune 12345678910111213#RedHat/CentOS7mkdir /etc/tuned/no-thpvim /etc/tuned/no-thp/tuned.conf[main]include=virtual-guest[vm]transparent_hugepages=nevertuned-adm profile no-thp 5. 测试你做的改变 1234cat /sys/kernel/mm/redhat_transparent_hugepage/enabledcat /sys/kernel/mm/redhat_transparent_hugepage/defrag#always madvise [never] 另一种简便的方式来禁用THP 123456vim /etc/rc.d/rc.localecho 'never' &gt; /sys/kernel/mm/transparent_hugepage/enabledecho 'never' &gt; /sys/kernel/mm/transparent_hugepage/defragchmod u+x /etc/rc.d/rc.local Unix系统下的ulimit的设置大多Unix-Like系统，都提供了限制每个进程和每个基本用户使用线程，文件和网络连接等系统资源的一些方法。ulimits防止单个用户使用太多的系统资源。有时，这些限制的默认值太小，这会导致MongoDB操作过程中出现一系列问题。 123#限制文件#/etc/security/limits.conf#/etc/security/limits.d/ 资源利用mongod和mongos每次使用线程和文件描述符来跟踪连接和管理内部操作。 通常情况下，所有的mongod和mongos实例： 利用每一个文件描述符和线程来跟踪每个即将到来的连接； 将每个内部线程或pthread作为一个系统进程来跟踪。 mongod mongod实例使用的每个数据文件都有一个文件描述符； 当storage.journal.enabled为true是，mongod进程实例使用的每个日志文件都有一个文件描述符； 在复制集中，每个mongod保持一个连接复制集中所有其他集合成员的连接。 mongos mongos实例与每个分片都保持一个连接池，所有mongos可以重用连接，这样因为不用建立新连接，从而能快速的满足请求； 通过限制连接数，可以防止mongos因在mongod实例上创建太多连接而产生级联效应。 资源限制的设置ulimit是指每个user使用各种资源的限制值。因此，无论你的mongod实例是以单个用户多进程执行还是以多mongod进程执行，都可以看到对这些资源的连接。 ulimits有hard和soft两个方式。 hard：是指用户在任何时候都可以活动的进程的最大数量，这是上限。没有任何non-root进程能够增加hard ulimit； soft：是对会话或进程实际执行的限制，但任何进程都可以将其增加到hard ulimit的最大值。 较低的soft limit可能无法创建新线程(thread)，如果连接数太高，则关闭错误连接。因此，将soft和hard的值都设置为推荐值是非常重要的。 修改ulimit设置之后，要重启程序修改值才会有效。可通过/proc文件系统查看运行进程当前的限制值。 使用ulimit对系统限制的改变在系统重启后都会恢复到默认值。需要修改其它文件来确保修改一直生效。 ulimit 123456789101112131415161718ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 7170max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 1024pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 7170virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited 修改ulimit 123456789#-f (文件大小)#-t (cpu 时间)#-v (虚拟内存)#-n (单个进程文件打开数)#-m (memory size)#-u (可打开的进程/线程)ulimit -t unlimitedulimit -u 64000 配置和维护(maintenance)Run-time databases configurationcommand line和configuration file interfaces为MongoDB管理员提供了控制数据库系统操作的大量选项和设置。 使用配置文件启动MongoDB实例： 12mongod --config /etc/mongod.confmongod -f /etc/mongod.conf 配置数据库mongodb的配置文件从MongoDB3.0以后使用YAML格式。 1234567891011121314151617vim /etc/mongod.confprocessManagement: fork: truenet: bindIp: 127.0.0.1 port: 27017storage: dbPath: /var/lib/mongodbsystemLog: destination: file path: "/var/log/mongodb/mongod.log" logAppend: truestorage: journal: enabled: true 对于大多数以standalone模式运行的servers，以上是一个足够的基本配置。Unix-Like操作系统需要以超级用户(root)权限才能运行端口小于1024的程序。 安全考虑(security consideration)下面的配置选项集合对于限制对于mongod实例的访问非常有用。 123456net: port: 27017 bindIp: 127.0.0.1,192.168.1.11security: authorization: enabled 复制集和分片配置(replication and sharding configuration)复制集的配置非常简单，只需要replSetName在集合中的所有成员具有一致的副本集名字。 12replication: replSetName: zhang 开启副本集认证： 12345678910#利用openssl生成keyFileopenssl rand -base64 256 &gt; /dir/path/mongodb/keyFilesecurity: replSetName: zhang keyFile: /dir/path/mongodb/keyfilechown -R mongod:mongod /dir/path/mongodb 设置keyFile启用身份认证，并为复制集成员在相互身份认证时使用的认证文件指定一个密钥文件。密钥文件的内容是任意的，但在复制集中的所有成员和连接到该集合的mongos实例之间必须相同。不然怎么能认证通过呢。秘钥文件的大小必须小于1KB，并且只能包含base64集中的字符，并且此密钥文件在Unix系统上必须not have group或not have world permissions。 分片配置(sharding configuration)分片要求配置服务器和分片服务器的Mongod实例具有不同的mongod配置文件。配置服务器存储集群的元数据(metadata)，而分片服务器存储数据(data)。 在配置文件中给mongod实例配置配置服务器(config-server)，给sharding.clusterRole指定配置服务器。 12345678910#配置config-servernet: bindIp: 192.168.1.11 port:27001replication: replSetName: zhangsharding: clusterRole: configserver#configserver必须要是一个部署的副本集 在同一个系统上运行多个数据库实例(multiple database instances)在许多情况下，在单个系统(single system)上运行多个数据库实例是不推荐的。 但可能由于一些部署或者测试的目的，你需要在单个系统上运行多个mongod实例。在这些情况下，请为每一个mongod实例使用一个基本的配置文件，但要额外配置如下值： dbpath(必须); pidFilePath(必须); systemLog(非必须，但建议开启); 栗子： 1234567891011121314151617181920212223242526#mongod_27017实例vim /etc/mongod_27017.confsystemLog: path: /var/log/mongod_27017.logstorage: dbPath: /var/lib/mongodb27017processManagement: pidFilePath: /var/lib/mongodb27017/mongod_27017.pid#mongod_27018实例vim /etc/mongod_27018.confsystemLog: path: /var/log/mongod_27018.logstorage: dbPath: /var/lib/mongodb27018processManagement: pidFilePath: /var/lib/mongodb27018/mongod_27018.pid##启动实例mongod -f /etc/mongod_27017.confmongod -f /etc/mongod_27018.conf 诊断配置(diagnostic configuration)以下配置选项可控制各种mongod行为，用以诊断的目的： operationProfiling.mode设置database profiler level。profiler在默认情况下不处于活动状态，因为它本身可能会影响性能。除非启用它，否则不会对查询进行分析； operationProfiling.slowOpThresholdMs配置慢操作的阈值以确定查询是否慢，用以作为分析器记录日志的目的。默认阈值是100ms； systemLog.verbosity控制mongod写入日志的日志输出量。只有在遇到未在正常日志记录级别中反映的问题是才启用此选项。 升级(upgrade)到最新的MongoDB修订(revisions)提供了security patches、bug fixes以及不包含任何反向破坏更改的新的或更改的功能。但是，最新版本也可能存在一些兼容性问题，请注意。 升级之前(before upgrading) 确保备份了最新的数据集； 有关特定MongoDb版本的特殊事项和兼容性问题，请注意查看； 如果你的安装包包括了复制集，在升级期间预定维护窗口(maintanence window)。 升级程序(upgrade procedure)在升级之前请一定要备份所有数据！ 按照如下步骤升级： 对于使用认证的部署，首先升级所有的MongoDB drivers； 升级分片集群； 升级任一standalone实例； 升级不属于分片集群的任一副本集。 升级一个MongoDB实例要升级mongod或mongos实例，使用如下方法之一： 使用操作系统的包管理工具和官方MongoDB包进行升级(推荐的方法)； 使用新二进制文件替换现有二进制文件来升级实例。 替换现有二级制文件(replace the existing binaries)在升级MongoDB前请一定备份你的所有数据！ 首选的升级方式是使用包管理工具和官方的MongoDB包。 通过替换现有二进制文件来升级mongod或mongos实例，执行如下操作： 下载最新MongoDB二进制文件到本地，并解压缩到MongoDB安装目录； 关闭实例； 替换二进制文件； 重启实例。 升级分片集群 禁用分片集群的平衡器(blancer)； 升级配置服务器(config-server)； 升级每个分片； 升级每个mongos实例； 重新启用平衡器。 升级复制集若要升级复制集，请单独升级每个副本集成员。从Secondary开始，最后以Primary结束。 升级SECONDARY 升级SECONDARY的mongod实例； 升级一个Secondary之后，在升级下一个实例之前，请等待Secondary恢复(recover)到SECONDARY state。使用rs.status()命令来检查复制集成员的状态。 升级PRIMARY 使用rs.stepDown命令来退出primary，以启动正常的故障转移过程； 查看是否有另外的SECONDARY节点成为了PRIMARY节点； 关闭并升级实例。 管理mongod进程开启mongod进程1234567891011121314151617mongod#指定数据目录mongod --dbpath /dir/mongodb/#指定TCP端口mondod --port 12345#将mongod以守护进程的方式启动mongod --fork --logpath /var/log/mongod.log#其他选项mongod --help 停止mongod进程1234567891011121314151617#使用shutdownServer()use admindb.shutdownServer()#使用--shutdownmongod --shutdown#使用ctrl+cctrl+c#使用kill#千万不要使用kill -9(SIGKILL)来终止mongodkill mongod_pidkill -2 mongod_pid 停止一个复制集步骤： 检查SECONDARY的oplog的时间戳； 如果从节点的时间戳落后于主节点10s内，mongod将会返回不会被关闭的消息。你可以传递一个timeoutSecs参数给shutdown命令来等待从节点追上主节点； 一旦从节点追上进度或60s后，主节点将会关闭。 强制关闭复制集：db.adminCommand( { shutdown: 1, force: true } ) 如果没有节点能立刻更新到最新的数据，发送shutdown加上timeoutSecs参数来在指定的时间内保持对从节点的检查。如果在分配的时间内有任意的一个从节点追上，主节点将会关闭。反之，主节点不会关闭。 1234db.adminCommand(&#123; shutdown: 1, timeoutSecs: 5 &#125;)#或db.shutdownServer(&#123; timeoutSecs: 5&#125;) 终止(Terminate)运行的操作MongoDB提供了两种方法来终止正在运行的操作。 maxTimeMS() db.killOp() maxTimeMS()maxTimeMS()方法给一个操作(operation)设置了时间限制(time limit)。这个时间单位默认是毫秒(ms)。当这个操作达到了指定的时间限制时，MongoDB将在下一个中断点(interrupt point)中断这个操作。 栗子： 123456789101112131415db.location.find( &#123; "town": &#123; "$regex": "(Pine Lumber)", "$options": 'i' &#125; &#125; ).maxTimeMS(30)db.runCommand( &#123; distinct: "collection", key: "city", maxTimeMS: 45 &#125;) killOpkillOp()方法将在下一个中断节点中断正在运行的操作。killOp()方法通过操作ID(operation ID)来标识目标操作。 栗子： 12345db.killOp(&lt;opID&gt;)#查看正在运行的操作db.currentOp() 注意：终止正在运行的操作时一定要谨慎！只使用db.killOp()方法来终止由客户端发起的操作，而不要终止内部数据库(internal database)的操作。 轮询(rotate)日志文件当使用--logpath选项或systemLog.path设置时，mongod或mongos实例会将所有活动和操作的实时账户报告给日志文件。默认情况下，只有当使用了logRotate命令，或者mongod或mongos进程从操作系统接收到一个SIGUSR1信号时，才会进行日志轮询响应。 MongoDB的标准日志轮询方法会存档当前日志文件并启动一个新的日志文件。为此，mongod或mongos实例将通过ISODate日期格式的UTC时间戳来重命名当前日志文件。然后它会打开一个新的日志文件，关闭旧的日志文件，并将所有新的日志发送到新的日志文件。 你也可以通过配置MongoDB的systemLog.logRatate或--logRotate选项，来支持Unix/Linux的日志轮询功能。最后，你可以使用--syslog选项来配置mongod发送日志数据到系统日志。在这种情况下，你可以选用其他的日志轮询工具。 默认日志轮询行为在mongo shell中轮询日志： 123456789101112131415#开启一个实例mongod -v --logpath /var/log/mongodb/test01.log#列出日志文件ls /var/log/mongodb/test01.log*#轮询日志文件mongo&gt;use admin&gt;db.runCommand(&#123; logRotate: 1 &#125;)#查看新的日志文件ls /var/log/mongodb/test01.log*#new: test01.log#old: test01.log-2018-01-11T08-22-50 使用--logRotate reopen选项轮询日志： 1234567mongod -v --logpath /var/log/mongodb/test01.log --logRotate reopen --logapendls /var/log/mongodb/test01.log*mongo&gt;use admin&gt;db.runCommand(&#123; logRotate: 1 &#125;) 系统日志轮询(Syslog log rotate)1mongod --syslog 使用SIGUSR1强制日志轮询对于基于Unix/Linux的系统，可以使用SIGUSR1信号来轮询单个进程的日志。 1kill -SIGUSR1 &lt;mongod-pid&gt; 数据中心意识(data center awareness)MongoDB部署中的分离(segregation)操作MongoDB拥有许多特性，包括允许数据库管理员和开发者在部署数据库的过程中通过一些功能或地理组群对数据库应用进行分割操作。 MongoDB支持跨越不同维度的操作的分段，这可能包括了在单个数据中心(single data center)的部署中的多数据中心(multi-date center)部署、机架、网络或电源电路的多个数据中心和地理区域。 MongoDB还支持基于功能或操作参数的数据库分离操作，以确保某些mongod实例仅用于报告工作负载，或只在特定的分片上分离集合的某些高频部分。 特别是在MongoDB中你可以： 确保写操作传播到复制集的特定成员； 确保复制集中的特定成员响应了查询操作； 确保分片键在具体范围上的平衡，并且驻留在特定的分片上。 区域(zone)管理分片区域(manage shard zones) 按位置分割数据(segementing data by location) 为SLA或SLO改变分层硬件 按应用程序或客户分割数据 Distributed Local Writes for Insert Only Workloads 管理分片区域 MongoDB备份方案(backup methods)在生存中部署MongoDB时，如果发生数据丢失的事件，你应该指定一个捕获和恢复备份的策略(strategy)。 back up with MongoDB cloud manager or Ops manager MongoDB Cloud Manager Ops Manager 复制底层数据文件进行备份(back up by copying underlying data files) 使用文件系统快照备份(back up with filesystem snapshots) 你可以通过复制MongoDB的底层数据文件来创建MongoDB部署的备份。如果MongoDB储存其数据文件的卷(volume)支持时间点快照(point-in-time snapshots)，则可以使用这些快照在某个时刻创建MongoDB系统的备份。文件系统的快照是一个操作系统的卷管理器的功能，并没有具体到MongoDB。通过文件系统快照，操作系统将卷的快照用作数据备份的基准。快照的机制取决于底层的存储系统。例如，在Linux上，逻辑卷管理器(LVM)可以创建快照。 要获得运行中的MongoDB进程的正确快照，必须启用日志记录(jorunaling)，并且日志必须与其它MongoDB数据文件存储在相同的逻辑卷上。如果没有启用日志记录，则无法保证快照将是一致有效地。 为了获得分片集群一致的快照，你必须禁用平衡器(balancer)和捕捉每一个分片的快照以及大约在同一时刻的配置服务器。 使用cp或scp备份 如果你的系统不支持快照功能，则可以使用cp，rsync或类似的工具直接复制文件。由于复制多个文件不是原子操作，因此你必须在复制文件之前停止对mongod的所有写入。否则，你将复制处于无效状态的文件。 复制底层数据而产生的备份不支持复制集的时间恢复节点，并且难以管理更大的共享集群。此外，这些备份很大。因为它们包括索引和复制底层存储填充和分片。相反，mongodump会创建较小的备份。 使用mongodump备份 如果在mongodump创建备份的同时，应用程序对数据进行修改，那么mongodump将会与这些应用竞争资源。 mongodump从一个MongoDB数据库中读取数据，并创建高保真度(high fidelity)的BSON文件。mongorestore工具可使用这个文件来进行MongoDB数据库恢复。mongodump和mongorestore是用于备份和恢复小型MongoDB部署的简单和高效的工具，但对于捕获较大的系统并不理想。 mongodump和mongorestore针对正在运行的mongod进程进行操作，可以直接操纵底层的数据文件。默认情况下，mongodump不会捕获local database数据库的内容。 mongodump只捕获数据库中的文档(documents)，用以给备份节省空间，但mongorestore或mongod必须在恢复数据之后重建索引。 当连接到MongoDB实例时，mongodump可能会对MongoDB的性能产生不利影响。如果你的数据大小大于系统内存，查询可能会将工作单元从内存中推开，从而导致页面错误。 当mongodump在捕获输出时，应用程序可以继续修改数据。对于复制集来说，mongodump提供了--oplog选项来用以在mongodump操作期间包含数据的oplog条目。这允许相应的mongorestore操作去还原所捕获的oplog。 然而，对于复制集来说，请考虑使用MongoDB Cloud Manager 或 Ops Manager来备份。 使用文件系统快照进行备份和恢复(back up and restore with filesystem snapshots)使用系统工具创建MongoDB系统的备份，诸如LVM，或block-level备份方法。使用系统工具来创建MongoDB数据文件的设备的副本。这些方法完成迅速、工作可靠，但是需要在MongoDB之外进行额外的系统配置。 快照综述(snapshots overview)快照的工作方式是在实时数据(live data)和一个特定快照卷之间创建指针(pointer)。这个指针在理论上等同于硬链接(hard link)。作为工作数据偏离的快照，快照过程使用写时复制(copy-on-write)策略。结果，快照又只存储修改的数据。 创建快照后，在文件系统上挂载(mount)快照镜像，并从中复制数据。生成的备份包含所有数据的完整副本。 Valid database at the time of snapshot 当快照生成时数据库必须有效。这就意味着数据库所接收的所有写入(write)都需要完整的写入磁盘————无论是journal还是数据文件。如果备份发生时磁盘上没有写入(write)，备份将不反映这些更改。 对于WiredTiger storage engine，数据文件反映了最后一个检查点(last checkpoint)的一致状态。每2GB的数据或每分钟就会出现检查点。 Entire disk image 快照创建一个整个磁盘镜像的镜像。除非你需要备份你的整个系统，否则考虑隔离(isolate)你的MongoDB数据文件、journal，并配置一个不包含任何其他数据的逻辑磁盘。或者，将所有的MongoDB数据文件保存在一个专用的设备上，这样你就可以在没有重复(duplicating)和无关(extraneous)数据的情况下进行备份。 Site failure precaution 确保将数据从快照复制到其他系统。这确保了在站点故障(site failure)的时候数据是安全的。 No incremental backups 本教程不包含增量备份(incremental backups)的过程。虽然不同的快照方法提供了不同的功能，但下面列出的LVM方法不提供捕获增量备份的任何容量。 Snapshots with journaling 如果你的mongod实例启用了journaling，则可以使用任何类型的文件系统和volume/block level快照工具来创建备份。 如果你在基于Linux的系统上管理你自己的基础架构，请使用LVM配置你的系统以提供磁盘包并提供快照功能。 在Linux上使用LVM进行备份和还原生产备份系统必须考虑一些特定环境的应用程序特定需求和因素。 Crete a snapshot 确保你创建的快照具有足够的空间来考虑数据的增长； 如果快照超出了空间，快照镜像将无法使用。请放弃这个逻辑卷并创建另外一个； 命令执行完毕时快照将存在。你可以随时直接从快照进行还原，也可以创建新的逻辑卷并从此快照还原到备用镜像； 虽然快照对于快速创建高质量的备份非常好，但它们并不是理想的作为存储备份数据的格式； 快照通常取决于并位于与原始磁盘镜像相同的存储基础架构上。因此，将这些快照存档并将其存储在别处至关重要。 12345#下面的这个vg-name指卷组名，这个卷组首先需要建立#系统卷组和设备的位置和路径可能因LVM的配置二略有不同#此大小不反映数据大小lvcreate --size 1G --snapshot --name mongodb-snap20180111 /dev/vg-name/mongodb Archive a snapshot 创建好snapshot之后，挂载mount快照并将数据复制到单独的存储中。 压缩快照： 12umount /dev/vg-name/mongodb-snap01dd if=/dev/vg-name/mongodb-snap01 | gzip &gt; mongodb-snap01.gz Restore a snapshot 同样适用LVM进行还原。 12345#lv-mongodb, vg0-vgnamelvcreate --size 1G --name mongodb vg0gzip -d -c mongodb-snap01.gz | dd of=/dev/vg0/mongodbmount /dev/bg0/mongodb /dir/path 还原的快照中有一个陈旧的mongo.lock文件，如果你没有从快照中删除此文件，那么MongoDB可能会认为锁文件指示的是不正常的关闭。如果你开启了storage.journal.enabled，但没有使用db.fsyncLock()的话，那不需要删除mongo.lock文件，反之，删除它。 Restore directly form a snapshot 不使用gz压缩文件下还原备份。 1234umount /dev/vg-name/mongodb-snap01lvcreate --size 1G --name mongodb vg0dd if=/dev/vg0/mongodb-snap01 of=/dev/vg0/mongodbmount /dev/vg0/mongodb /dir/path Remote backup storage 可以使用组合的进程和SSH实施离线备份。 12345umount /dev/vg-name/mongodb-snap01dd if=/dev/vg0/mongodb-snap01 | ssh user@host gzip &gt; /dir/path/mongodb-snap01.gzlvcreate --size 1G --name mongodb vg0ssh user@host gzip -d -c /dir/path/mongodb-snap-01.gz | dd of =/dev/vg0/mongodbmount /dev/vg0/mongodb /dir/path 使用单独卷上的Journal日志文件或没有Journal日志文件进行备份实例从MongoDB3.2开始，为了使用WiredTiger对MongoDB实例进行volume-level备份，数据文件和Journal日志文件不再要求驻留在一个卷上。 如果你的mongod实例没有使用Journal，或者启用了将Journal志文件放置于一个单独的卷上，则必须刷新(flush)对磁盘的所有写入，并在备份期间锁住数据库用以阻止写操作。如果有复制集(replica set)配置，那么你可以在SECONDARY上不接收读取用以备份数据。 1. 刷新写入磁盘并锁定数据库以防止进一步的写入： 12#锁住数据库db.fsyncLock(); 2. 使用快照备份数据库： 3. 解锁数据库： 12#解锁数据库db.fsyncUnlock(); 使用MongoDB工具进行备份和恢复(back up and restore with MongoDB tools)使用MongoDB提供的备份还原工具——mongodump和mongorestore来处理BSON data，对于创建小型部署的备份是很有用的。对于弹性(resilient)备份和非破坏性(non-disruptive)备份，使用文件系统或块级磁盘快照。 因为mongodump和mongorestore操作通过与正在运行中的mongod实例进行交互(interacting)，它们会影响正在运行的数据库的性能(performance)。这些工具不仅会为正在运行的数据库实例创建流量，还会强制数据库通过内存读取所有的数据。当MongoDB读取不经常(infrequently)使用的数据时，它会驱逐(evict)频繁(frequently)访问的数据，导致数据库正常工作负载的性能下降。 当使用MongoDB’s tools 来备份你的数据时，考虑如下建议： 标签文件(label file)，以便你可以识别备份的内容以及备份所反映的时间点 如果对你来说，mongodump和mongorestore对性能的影响是不可接受的，请使用替代备份策略——filesystem snapshot或MongoDB CloudManager 使用--oplog去捕获在mongodump期间的传入写(write)操作，以确保备份一致性的数据状态 通过将备份文件还原到测试环境中，以确认备份是可用的 MongoDB toolsMongoDB工具介绍及区别： mongoexportmongoexport is a utility that produces a JSON or CSV export of data stored in a MongoDB instance. mongoimportThe mongoimport tool imports content from an Extended JSON, CSV, or TSV export created by mongoexport, or potentially, another third-party export tool. mongodumpmongodump is a utility for creating a binary export of the contents of a database. mongodump can export data from either mongod or mongos instances.mongodump excludes the content of the local database in its output.The mongodump utility backs up data by connecting to a running mongod or mongos instance. mongorestoreThe mongorestore program writes data from a binary database dump created by mongodump to a MongoDB instance. 步骤(Procedures)使用mongodump备份 `mongodump·备份数据库，如果数据库启用了访问控制，则必须拥有每个备份的数据库查询的权限。内置的备份角色提供了执行任何和数据库备份有关所需的权限。 这就意味着你使用mongodump的user必须要对所备份的数据库有读取权限。 mongodump能够为整个服务器、数据库或集合创建备份，或者使用查询仅备份集合的一部分。 mongodump默认排除local数据库。 mongodump必须要能够连接到正在运行的mongod或mongos实例。默认连接为127.0.0.1:27017。 mongodump默认创建在当前目录下创建./dump备份文件。 如果mongodump备份目录中已经存在备份数据目录，那么mongodump将会覆盖它们。 指定认证库来认证你的用户名和密码。 使用oplog进行时间点操作 在mongodump中使用--oplog选项来收集oplog条目，用以在副本集中构建数据库的实时快照。 使用--oplog，mongodump会从源数据库复制所有的数据，包括备份开始到结束这段时间所有的oplog记录。 在mongorestore还原时使用--oplogReplay选项，允许你还原特定时间节点的备份。这就对应在mongodump期间oplog的记录。 123456789101112131415161718192021#127.0.0.1:27017 ./dumpmongodump#--host,-h --portmongodump -h mongodb.example.net --port 27107mongudump -h 127.0.0.1 --port 27018#-o, --outmongoodump -o /var/mongodb_backup/mongodump --host 127.0.0.1 --port 27017 --out /var/mongodb_backup/#--collection, --dbmongodump --db zhang --out /var/mongodb_backup/zhangmongodump --db zhang --collection test#--authenticationDatabasemongodump --port 27018 -u zhang -p "passwd" --authenticationDatabase admin -d zhang -o /var/mongodb_backup/zhang 使用mongorestore还原若要将数据还原到启用了访问控制的MongoDB部署，如果备份数据不包括system.profile集合数据，则restore角色提供了对数据库的访问权限。 如果备份数据包含了system.profile集合并且目标数据库不包含system.profile集合，那么mongorestore会去创建这个集合即使mongorestore并没有还原system.profile文档。因此，用户就需要额外的权限才能在system.profile集合中上执行createCollection和convertToCapped。 如果使用--oplogReplay，这个restore角色还不足以重放oplog。所以如果需要重放oplog，请使用一个能够重放oplog的角色。 1234567mongorestore /var/mnogodb_backupmongorestore /var/mnogodb_backup --oplogReplaymongorestore --port 27018 -u zhang -p "passwd" --authecticationDatabase admin -d zhang /var/mongodb_back/zhang 批量化操作mongo shell(EOF)1234567for coll in &#123;collection1,collection2,...&#125;do mongo host:port/db -u x -p xx &lt;&lt; EOF use db db.$coll.drop() EOFdone 从MongoDB备份中还原副本集你不能将单个数据集(data set)还原为三个新的mongod实例，然后为此创建一个副本集(replication set)。如果你将数据集复制到每个mongod实例，然后创建副本集，则MongoDB将强制SECONDARY执行initial sync。 向一个单一副本集节点中还原数据(Restore Database into a Single Node Replica Set) 获取备份数据库文件 使用备份数据库文件作为数据库路径启动一个mongod实例 1234567891011#方法1，直接启动mongod --dbpath /dir/path/mongodump --replSet &lt;replName&gt;#方法2，使用配置文件启动，推荐vim /etc/mongod.confstorage: dbPath: /dir/path/mongodumpreplication: replSetName: zhang 连接到mongo shell 初始化这个新的副本集 12#对于有且仅有一个成员的副本集使用rs.initiate()rs.initiate() 向副本集中添加成员(Add Members to the Replica Set)MongoDB对于还原副本集SECONDARY节点提供了两种选择： 手动复制数据库文件到数据目录 允许initial sync 建议： 如果备份的数据库文件很大，那么initial sync可能需要很长的时间才能完成。对于大型数据库，最好将数据库文件复制到每台主机上。 Copy Database File and Restart mongod Instance Shut down the mongod instance that you restored 使用 --shutdown 或 db.shutdownServer()来确保一个正常干净的关闭 复制Primary的数据目录到每个从节点 Start the mongod instance that you restorerd Add the secondaries to the replica set 1PRIMARY&gt;rs.add() Update Secondaries using Initial Sync 确保副本集成员的数据目录为空 将每个潜在成员添加到副本集 备份和还原分片集群(sharded cluster) 通过文件系统快照(fs snapshots)备份一个分片集群 通过Database Dumps备份一个分片集群 Schedule Backup Window for Sharded Clusters 还原一个分片集群 从意外关闭中恢复(Recover a standalone after an unexpected shutdow)当一个standalone模式的mongod实例关闭了journaling功能后，一个unclean的shutdown可能会导致数据处于不一致的状态。当unclean shutdown之后，如果在dbPath下存在一个非空的mongod.lock文件，则mongod实例会记录如下信息： Dectected unclean shutdown - mongod.lock is not empty 这样的话你必须要修复你的数据库，才能正常的启动mongod。 警告：不要用如下方法处理副本集 unclean shutdown。相反，你应该从备份或者从另一个副本集的成员恢复。 默认情况下，MongoDB在启用journaling的情况下运行，以防止发生unclean shutdown时数据不一致的问题。 使用运行mongod实例的那个用户来进行修复，避免由权限不一致而导致的新问题。 Create a backup of the data files Start mongod with —repair 监控(Monitoring)MongoDB监控是数据库管理的重要组成部分，充分了解MongoDB的运行状态，并在没有危机的情况下维护和部署。此外，了解MongoDB的正常操作参数将允许你在问题升级成为故障前诊断他们。 Monitoring for MongoDB Monitoring Strategies(策略)有三种方法可以从运行中的MongoDB实例中收集状态信息： MongoDB提供的一组实时上报程序，提供数据库活动的实时报告； 数据库命令以更大的保真度返回有关当前数据库状态的统计信息； MongoDB Atlas，MongoDB Cloud Manager； 每个策略在不同的情况下都是很有用的，所以它们能够很好地进行互补。 MongoDB Reporting ToolsUtilities MongoDB提供了许多可以返回活动统计信息的实用工具，这对于诊断问题和评估操作非常有用。 mongostat mongostat按类型捕获并返回数据库操作的计数(insert,query,update,delete…) mongotop mongotop通过类型捕获和返回数据库操作(insert,query,update,delete) CommandsMongoDB包含了许多上报数据库状态的命令。这些命令可以提供比上面的实用程序更精细的粒度级别。考虑在脚本和程序中使用它们的输出来开发自定义警报。db.currentOp方法是一个识别当前数据库实例正在进行的操作。 db.serverStatus() db.serverStatus()，返回数据库状态的一般概述，详细的磁盘使用，内存使用，连接，journaling日志和索引访问。它返回快速并不影响MongoDB性能。 db.stats() db.stats()，提供了database上的统计信息。返回使用的存储量，数据库包含的数据量及对象，collection和索引计数器。 db.collection.stats() db.collection.stats()，提供了collection上的统计信息。包含集合中的对象数量，结合大小，集合磁盘空间用量，索引信息。 rs.status() rs.status()，返回一个复制集状态的概述。 第三方工具许多第三方(third party)工具支持对MongoDB的监控。 Nagios Zabbix Ganglia Motop … Monitor MongoDB with SNMP on LinuxSNMP is only available in MongoDB Enterprise Monitor MongoDB Windows with SNMP MongoDB索引Indexes 索引支持在MongoDB中高效地(effecient)执行查询。没有索引，MongoDB就必须采取collection scan。扫描每个集合中的每个文档，用以匹配查询。如果查询存在适当的索引，则MongoDB可以使用该索引来限制它必须检查的文档数量。 索引是特殊的数据结构，将集合数据集中的一小部分以易于遍历(traverse)的形式存储。索引存储特定字段或字段集的值，按字段值排序。索引条目的排序支持高效的相等匹配和基于范围的查询操作。除此之外，MongoDB可以使用索引中的排序返回排序后的结果。 从根本上来说(fundamentally)，MongoDB中的索引类似于其他数据库的索引。MongoDB在collection级别定义索引，并支持集合的文档的任何字段或子字段上的索引。 默认_id索引 在创建一个collection期间，MongoDB在_id字段上创建一个唯一的索引。你也可以自定义_id的值。你不能在_id字段上删除此索引。 创建一个索引 db.collection.createIndex方法只有在同一规范不存在时才创建索引。 1db.collection.createIndex(&lt;key and index type&gt;, option) 索引类型MongoDB提供了许多不同的索引类型来支持特定类型的数据和查询。 Single Field 除了MongoDB定义的_id索引，MongoDB还支持在文档的单个字段上创建用户自定义的升序(ascending)/降序(descending)索引。 对于单字段索引和排序操作，MongoDB可以在任何方向遍历索引。 Compound(复合) Index MongoDB也支持多个字段的用户自定义索引。 Multikey Index MongoDB使用多键索引来索引存储在数组中的内容。 Geospatial(地理空间) Index 为了支持对地理空间坐标数据的有效查询，MongoDB提供了两个特殊的索引：2d index返回平面几何的2D索引；2dsphere index返回球形几何结果。 Text Index MongoDB提供了一个文本(text)类型索引，用以支持搜索集合中的字符串内容(string content)。 Hashed(散列) Index 为了支持基于散列的分片，MongoDB提供了散列索引类型，它索引字段值的散列值。但只支持相等的匹配，而不能支持基于范围的查询。 Index Properties(特性) Unique Index 索引的唯一性是MongoDB拒绝索引字段的重复值。 Partial Index 部分索引仅索引复合指定过滤器表达式的集合中的文档。 Sparse(稀疏) Index 索引的稀疏属性确保索引仅包含具有索引字段的文档的条目，跳过没有索引字段的文档。 TTL Index TTL索引是MongoDB可以用来在一定时间后自动从集合中删除文档的特殊索引。对于某些类型的消息，如机器生成的事件数据，日志和会话信息等，只需在数据库库中保存有限的时间，这是非常理想的。 Index Use索引能够提高读操作的效率。 Index and Collation要使用索引进行字符串比较，操作还必须指定相同的排序规则。 Coverd Query当查询条件和查询投影仅包含索引字段时，MongoDB将直接从索引返回结果，而不扫描任何文档或将文档带入内存。 Single Filed Index Compound Index Multikey Index Text Index 2dsphere Index 2d Index geoHaystack Index Hashed Index Index Property Index Build Operation on a Populated Collection Index Intersection Manage Index Measure Index Use Indexing Strategy Index Reference MongoDB存储Storage FAQ: MongoDB Storage: https://docs.mongodb.com/v3.4/faq/storage/ 存储引擎(storage engine)是MongoDB管理数据库主要的组件。 journal日志，用于数据库不正常关闭时修复数据库。有几种可选的配置项，用以平衡数据库的性能和可用性。 GridFS是一个适合处理大文件的多功能的存储系统，例如那些超过16MB文档大小限制的文件。 Storage Engine存储引擎是数据库的组件，负责管理数据库在内存(in-memory)和磁盘中(on-disk)两种存储方式。由于不同的存储引擎在特定的工作负载下有更好的性能，所以，为你的应用程序选择一个适当的存储引擎会提高性能。 WiredTiger是从MongoDB3.2开始的默认存储引擎。它非常适合大多数工作负载，并推荐使用它来进行部署。WiredTiger提供了文档级并发模型，检查点和要说等特性。 MMAPv1是一个原始的MongoDB存储引擎，它是MongoDB3.2以前的默认存储引擎。它在大量读取和写入以及更新方面的工作负载表现良好。 In-Memory要在MongoDB Enterprise中才能获取。它不是将文档保存在磁盘上，而是将它们保留在内存中，以获得可预测的数据延迟。 WiredTiger存储引擎MongoDB3.2以后使用WiredTiger存储引擎作为默认存储引擎。 12345678mongod --storageEngine wiredTiger#或vim /etc/mongod.confstorage: engine: wriedTiger 文档级别并发(currency)WiredTiger使用文档级并发来控制写操作。因此，多个客户端可以同时修改一个集合中的不同文档。 对于大多数读写操作，WiredTiger使用乐观的并发控制。WiredTiger仅在global、database和collection-levels使用intent lock。当存储引擎检测到两个操作之间的冲突时，其中一个操作将引发写冲突，从而导致MongoDB透明地重试该操作。 快照和检查点WiredTiger users multiVersion Concurrency Control(MVCC).在操作开始时，WiredTiger向事务提供数据的实时快照。快照显示内存中数据的一致性视图。 当写入磁盘时，WiredTiger将快照中的所有数据以一致性的方式跨越所有数据文件写入磁盘。持久(durable)的数据充当数据文件中的检查点。检查点确保数据文件与最后一个检查点保持一致性，并包括最后一个检查点。 MongoDB配置WiredTiger来创建检查点(即将快照数据写入磁盘)，间隔时间为60s，或2G日志数据。 在写入新检查点期间，前一个检查点仍然有效。 当WiredTiger的元数据表被原子地更新以引用新的检查点，新的检查点将变得可访问和永久。一旦新检查点可以访问，WiredTiger就会从旧的检查点这种释放页面(free page)。 JournalWiredTiger采用预写事务日志联合检查点，用以确保数据的持久性(durability)。你也可以关闭journal功能来减少维护日志的开销。 WiredTiger日志坚持在检查点之间修改所有数据。如果MongoDB在检查点之间退出，它将使用日志重放自上一个检查点以来修改的所有数据。 WiredTiger journal使用snappy compression Library来进行压缩。 WiredTiger最小日志记录的大小是128Byte，如果日志记录小于等于128Byte，则WiredTiger不会压缩日志文件。 对于以standalone模式运行的mongo实例，关闭journal日志功能意味着当MongoDB意外地在检查点之前退出时，你将丢失一些数据修改。对于复制集成员，复制过程和恒提供足够的持久性保证。 Compression使用WiredTiger，MongoDB支持压缩所有的collections和indexes。通过使用CPU进行压缩，减少了储存空间的使用。 默认地，WiredTiger使用snappy compression library对所有的collections进行block压缩，对所有索引进行前缀(prefix)压缩。 对于collection，也可以使用zlib进行block压缩。可通过storage.wiredTiger.collectionConfig.blockCompressor设置压缩方法。对于index，使用storage.wiredTiger.indexConfig.prefixCompression关闭prefix压缩。 对于大多数工作负载，默认压缩设置平衡了存储效率和处理要求。 Memory Use对于WiredTiger，MongodB使用WiredTiger内部缓存和文件缓存。 从MongoDB3.4开始，WiredTiger内部缓存将使用一下两种类型中更大的一种： 50% of RAM minus 1GB 256MB WiredTiger内部缓存中的数据与磁盘上格式的数据使用不同的表现形式： 文件系统缓存的数据与磁盘上的格式相同，包括了对数据文件进行压缩的好处。操作系统使用文件系统缓存来减少磁盘I/O 指标加载在WiredTiger内部缓存有一个不同的磁盘上的数据表示格式，但仍然可利用 prefix index compression来减少内存使用。索引前缀压缩重复数据删除常用前缀的索引字段。 WiredTiger内存缓存的collection数据是未压缩的，并使用与磁盘格式不同的表现形式。block compression能够节省大量磁盘空间，但必须解压缩数据后服务器才能操作。 通过文件系统缓存，MongoDB自动使用 (WiredTiger缓存或其他进程不使用)空闲内存。 调整WiredTiger内部缓存的大小，避免将WiredTiger的内初缓存值增加到默认值之上。 1234567#命令行--wiredTigerCacheSizeGB#配置文件storage.wiredTiger.engineConfig.cacheSizeGB Change Standalone to wiredTigerMongoDB version 3.0 or later in order to use wiredTiger storage engine! 过程： mongod is running export data using mongodump create a data directory for the new mongod running with wiredTiger start mongod with wiredTiger upload the dumpdata using mongorestore Change Replica Set to wiredTigerReplica sets can have members with different storage engines.因此，你可以把所有成员的存储引擎更换为WiredTiger。MongoDB version 3.0 or later in order to use wiredTiger storage engine! 过程： shutdown the secondary member.—db.shutdownServer prepare a data directory for the new mongod running with wiredTiger start mongod with wiredTiger repeat the procedure for other replica set secodaries you wish to upgrade Change Sharded Cluster to wiredTigerif the shard is a standalone, see Change Standalone to wiredTiger;if the shard is a replica set, see Change Replica Set to wiredTiger. Change config server to wriedTiger如果你打算更新config server使用WiredTiger，那么必须全部更新！ 过程： disable the balancer—sh.disableBalancer() shutdown the third config server to ensure read-only metadata.—db.shutdownServer() export the data of the second config server with mongodump For the second config server, create a new data directory for use with WiredTiger. Stop the second config server.—db.shutdownServer() Start the second config server mongod with the WiredTiger storage engine option. Upload the exported data using mongorestore to the second config server. Shut down the second config server to ensure read-only metadata.—db.shutdownServer() Restart the third config server to prepare for its upgrade. Export the data of the third config server with mongodump For the third config server, create a new data directory for use with WiredTiger. Stop the third config server. Start the third config server with the WiredTiger storage engine option. Upload the exported data using mongorestore to the third config server. Export data of the first config server with mongodump. For the first config server, create a new data directory for use with WiredTiger. Stop the first config server. Start the first config server with the WiredTiger storage engine option. Upload the exported data using mongorestore to the first config server. Restart the second config server to enable writes to the sharded cluster’s metadata Re-enable the balancer.—sh.startBalancer() MMAPv1存储引擎 In-Memory存储引擎 Journaling为了在发生故障时提供持久性，MongoDB使用了县写日志记录到磁盘的日志文件。To provide durability in the event of a failure, MongoDB uses write ahead logging to on-disk journal files. journaling and the wiredTiger storage engine本节所指的log指的是WiredTiger的 write-ahead log(journal)，而不是MongoDB日志文件。 WiredTiger使用checkpoints在磁盘上提供一致的数据视图，并允许MongoDB从上一个checkpoint修复。然而，如果MongoDB在检查点之间以外退出，则需要使用journaling来修复上次检查点之后发生的信息。 使用journaling的修复过程： 在数据文件中查找上一个检查点的标识符(identifier) 在journaling文件中搜索与上一个检查点标识符匹配的记录 应用自上一个检查节点依赖journal文件中的操作 journal process通过journaling，WiredTiger为每个客户端启动的写操作创建一个journal记录。journal record包括有初始写入引起的任何内部写入操作。 例如，集合中文档的更新可能导致对index的修改，WiredTiger创建一个包含update操作及其相关index修改的单独的journal record。 MongoDB将WiredTiger配置为in-memory的buffering来存储日志记录。线程坐标来分配和复制到他们的缓冲区的一部分。所有日志记录高达128KB是缓存的。WiredTiger根据如下条件将journal record同步到磁盘。 每50ms MongoDB在WiredTiger中设置60s为间隔的用户数据检查点或2GBjournal数据已被写入，以先发生为准。 如果写操作包含有j:true的写关注点，则WiredTiger强制对journal文件进行同步。 MongoDB限制了journal文件大小为100MB，因此WiredTiger每100MB就会创建一个新的journal文件。当创建了一个新的journal文件时，WiredTiger会同步上一个journal文件。 在写操作之间，虽然日志记录保留在WiredTiger缓冲区中，但在mongod实例hard shutdown之后可能会丢失更新。 Journal FileMongoDB在数据库目录下创建一个journal子目录存放journal文件。名字为WiredTigerLog.&lt;sequence&gt;，从0000000001开始。如上图所示。 Journal文件包含对每一个写操作的记录。每个记录都有唯一的标识符。 MongoDB将WiredTiger配置为对journal数据使用快速压缩。最小日志大小为128KB，如果小于此，WiredTiger不会压缩此记录。最大大小为100MB，超过此，WiredTiger会创建一个新的journal文件。 MongoDB自动删除旧日志文件，以维护从上一个检查点恢复所需的文件。 Journaling and the MMAPv1 Storage Engine Journaling and the In-Memory Storage Engine Manage JournalingMongoDB uses write ahead logging to an on-disk journal to guarantee write operation durability. 启用journal后，如果MongodB意外退出，则程序可以恢复写入了journal日志文件的所有内容。MongoDB将在重启时重新应用写操作，并保持一致性。 过程 Enable journaling123456789mongod --jouranl##或vim /etc/mongod.confstorage: journal: enabled: true Disable journaling12345mongod --noJournal###或修改配置文件 警告不要在生产系统上禁用日记功能。如果在一个副本集上使用--noJournal关闭了journal日志，则还应该修改副本集配置文件。 Monitor journal status serverStatus Recover data after unexpected shutdown在奔溃后重启时，MongoDB会在服务器可用之前replay journal日志记录中的所有日志文件。 GridFSGridFS是一种用于存储和检索超过BSON文档大小限制值16MB的文件规范。 GridFS没有将单个文件存储到单个的文档中，而是将文件分割成部分(parts)或块(chunks)，并将每个块存储到单独的文档中。默认情况下，GridFS的块大小为255KB。也就是说，GridFS将文件分成255KB的块，最后一块大小就不确定了。 GridFS使用两个集合来存储文件。一个存储文件块(chunks)，另一个存储文件元数据(metadata)。 当你查询(query)GridFS文件时，驱动程序会根据需要重新组装这些块。你可对通过GridFS存储的文件执行范围查询。还可以从任意文件部分访问信息。 GridFS不仅可用于存储超过16MB的文件，还可用于存储需要访问的任何文件，而不必将整个文件加载到内存中。 何时使用GridFS在MongoDB中，使用GridFS存储大于16MB的文件。 某些情况下，在MongoDB数据库中存储大文件可能比在系统级文件系统上更有效。 如果文件系统限制了一个目录中的文件数量，则可使用GridFS存储所需的文件 当你想要访问大文件的部分信息时而不想将整个文件加载到内存中时，可使用GridFS收回文件的各个部分，而不必将整个文件读入内存 当你希望文件和元数据自动同步并部署在多个系统和设施中时，可使用GridFS 如果需要原子地(atomically)更新整个文件的内容，请不要使用GridFS。作为一种选择，你可以为每个文件存储多个版本，并在元数据中指定该文件的当前版本。 此外，如果文件都是小于16MB的BSON文件大小限制，则考虑手动存储在一个单文档中，而不必使用GridFS。 使用GridFS使用GridFS存储和检索文件，请使用如下任何一项： A MongoDB Driver The mongofile cmd-line tool GridFS集合GridFS把文件存储在两个集合里： chunks collection stores the binary chunks files collection stores the file’s metadata GridFS将这些集合放在一个普通的存储区(bucket)中，每个存储区前面加上名称。默认地，GridFS使用两个名为fs的存储区集合： fs.files fs.chunks 币可以选择一个不同的存储区名字，也可以在一个数据库中创建多个存储区。 The chunks collection块集合中的每个文档都表示一个独立的文件块。格式如下： 123456&#123; &quot;_id&quot;: &lt;ObjectId&gt;, &quot;files_id&quot;: &lt;ObjectId&gt;, &quot;n&quot;: &lt;num&gt;, &quot;data&quot;: &lt;binary&gt;&#125; 块集合中的文档包含如下字段： chunks._id The unique ObjectId of the chunk chunks.files_id The _id of the “parent” document chunks.n The sequence number of the chunk，GridFS从0开始标号所有块 chunks.data BSON Binary type file集合GridFS的file集合，格式如下： 1234567891011&#123; &quot;_id&quot;: &lt;ObjectId&gt;, &quot;length&quot;: &lt;num&gt;, &quot;chunkSize&quot;: &lt;num&gt;, &quot;uploadData&quot;: &lt;timestamp&gt;, &quot;md5&quot;: &lt;hash&gt;, &quot;filename&quot;: &lt;string&gt;, &quot;contentType&quot;: &lt;string&gt;, &quot;aliases&quot;: &lt;string array&gt;, &quot;metadata&quot;: &lt;any&gt;&#125; files._id The unique identifier for this document files.length The size of the document in bytes files.chunSize The size of each chunk in bytes files.uploadDate The date the document was first stored by GridFS files.md5 An MD5 hash of the complete file file.filename Optional. A human-readable name for the GridFS file file.contentType Optional. A valid MIME type for the GridFS file files.aliases Optional. An array of alias strings files.metadata Optional. The metadata field may be of any data type and can hold any additional information you want to store GridFS索引为了提高效率，GridFS在每个chunks and files collections上使用索引。 chunks索引GridFS使用一个唯一的、混合的索引。在chunks集合上使用files_id和n字段。 12345db.fs.chunks.find( &#123; files_id: myFileID &#125; ).sort( &#123; n:1 &#125;)#创建索引db.fs.chunks.createIndex(&#123; files_id: 1, n:1 &#125;, &#123; unique: true &#125;); files索引GridFS使用索引，在files集合上使用filename和uploadDate字段。 12345db.fs.files.find(&#123; filename: myFileName &#125;).sort(&#123; uploadDate: 1 &#125;)#创建索引db.fs.files.createIndex(&#123; filename:1, uploadDate: 1 &#125;); 分片GridFS如果需要分片GridFS数据存储，使用chunks集合设置: { files_id: 1, n:1} or { files_id: 1 }作为分片key索引。 不能对chunks集合使用hash分片。 files_id是一个ObjectId。 MongoDB安全Security MongoDB提供了各种特性(features)，如身份认证(authentication)、访问控制(access control)、加密(encryption)，以保护MongoDB部署。 Security Checklist 启用访问控制和强制认证 Enable Access Control and Enforce Authentication 可使用默认的MongoDB认证机制或现有的外部框架 配置基于角色的访问控制 Configure Role-Based Access Control 首先创建administrator，接着在创建其他用户 创建角色，定义一组用户所需的确切访问权限 加密通信 Encrypt Communication 配置MongoDB使用TLS/SSL加密连接 加密和保护数据 Encrypt and Protect Data 限制网络曝光 Limit Network Exposure 确保MongoDB运行在一个受信任的网络环境上，并限制MongoDB的监听接口 审计系统活动 Audit System Activity 跟踪对数据库配置和数据的访问和更改 使用专用用户运行MongoDB Run MongoDB with a Dedicated User 使用专用的操作系统用户账户运行MongoDB进程 使用安全配置选项运行MongoDB Run MongoDB with Secure Configuration Options MongoDB为了支持某些服务端操作执行：mapReduce,group,$where 如果你不使用这些操作，请关闭服务器端脚本执行--noscripting 请求一个安全技术执行指南 Request a Security Technical Implementation Guide 考虑安全标准合格性 Consider Security Standards Compliance 认证Authentication 要作为用户进行身份认证，必须提供用户名(username)，密码(password)和与用户关联的身份验证数据库(authentication database)。 1234567mongo --host --username --password --authenticationDatabase#Ormongo&gt;use &lt;authenticationDatabase&gt;&gt;db.auth(&apos;username&apos;,&apos;password&apos;) 认证机制 Authentication Mechanisms MongoDB支持多种认证机制 SCRAM-SHA-1 MongoDB Challenge and Response (MONGODB-CR) x.509 Certificate Authentication LDAP proxy authentication(MongoDB Enterprise) Kerberos authentication(MongoDB Enterprise) 内部认证 Internal Authentication 除了验证客户端的身份外。MongoDB还可以要求副本集和分片集的成员对其各自的成员进行认证 用户Users 要在MongoDB中验证客户端，必须向MongoDB添加相应的用户。 用户管理接口 User Management Interface 使用db.createUser()方法创建用户 添加用户时，可为用户分配角色以授予权限 在数据库管理中创建的第一个用户应该是具有管理其他用户权限的administrator 也可以更新/删除一个已经存在的用户的权限 认证数据库 Authentication Database 在特定的数据库中创建用户，这个数据库是用户的认证库 用户名和认证库充当该用户的唯一标识符。如果两个用户具有相同的用户名，但是在不同的数据库中创建，则它们是两个单独的用户 用户可拥有不同数据库的权限，而不限于认证库 通过数据库角色给用户分配相应的权限 认证一个用户 Authentication Database 使用用户名、密码、认证库验证一个用户 集中的用户数据 Centralized User Data MongoDB将所有的用户名、密码和认证库信息，保存到admin库的syste.users集合中 使用用户管理命令而不要直接访问这个集合 分片集群用户 Sharded Cluster Users 添加用户Add Users MongoDB使用基于角色的访问控制(RBAC)来确定用户的访问权限。用户被授予一个或多个角色，这些角色确定用户对MongoDB资源的访问或权限，以及用户可以执行的操作。用户应该只具有确保系统最小权限所需要的最小权限。 前提(Prerequisites) 对于用户创建，你必须拥有以下权限 在数据库中创建一个新用户，必须在数据库资源上有createUser操作 对一个用户授权角色，必须在角色数据库中有grantRole操作 栗子 123456789101112131415161718use admindb.createUser( &#123; user: &apos;zhang&apos;, pwd: &apos;passwd123&apos;, roles: [ &#123; role: &apos;root&apos; &#125;, &#123; db: &apos;admin&apos; &#125; ] &#125;)#在配置文件中开启用户认证vim /etc/mongod.confsecurity: authorization: enabled 认证机制Authentication Mechanisms SCRAM-SHA-1 MONGODB-CR x.509MongoDB对于客户端身份认证和副本集、分片集成员的内部认证支持x.509证书认证。 x.509证书认证需要安全的TLS/SSL连接。 证书授权(Certificate Authority) 在生产使用中，MongoDB的部署应该使用由认证机构签名和生成的有效证书。 Client x.509 Certificates 要想服务器验证身份，客户端可以使用x.509证书而不是用户名和密码。 Client Certificate Requirements： 单个证书颁发机构(CA)必须同时为客户端和服务器颁发证书 客户端证书必须包含如下字段： 12keyUsage = digitalSignatureextendedKeyUsage = clientAuth 每个唯一的MongoDB用户必须有一个唯一的证书 一个客户端x.509证书的主题，包含了可辨识名称(DN)。必须不同于成员x.509证书 MongoDB user and $external database 若要使用客户端证书进行认证，必须先将客户端证书中的subject值添加为MongoDB用户。每个唯一的x.509客户端证书对因孤独一个MongoDB用户。 在$external database中添加用户，认证库便是外部数据库。 Authenticate 使用x.509客户端进行身份验证，请通过TLS/SSL连接到MongoDB。--ssl and --sslPEMKeyFile Member x.509 Certificates 对于内部认证，分片集和副本集的成员可以使用x.509证书来代替使用SCRAM-SHA-1认证机制的keyfile。 Member Certificate Requirements CA必须为所有分片集，副本集成员颁发x.509证书 成员证书的主题中找到Distinguished Name(DN)必须为以下至少一个属性指定非空值：Organization(O)，Organization Unit(OU)，Domain Component(DC) 组织属性，组织单元属性和域组件必须与其他集群成员的证书相匹配。12CN=host1,OU=Dept1,O=MongoDB,ST=NY,C=USC=US, ST=CA, O=MongoDB, OU=Dept1, CN=host2 MongoDB Configuration 配置文件：security.clusterAuthMode and net.ssl.clusterFile cmd-line options: —clusterAuthMode and —sslClusterFile Member Certificate and PEMKeyFile 配置文件： net.ssl.PEMKeyFile cmd-line option: —sslPEMKeyFile Enterprise Authentication Mechanisms MongoDB认证和角色要想了解MongoDB的权限必须先了解如下一些关键字： user 用户，用于提供客户端连接MongoDB的认证账户 role 角色，数据权限的集合，创建用户的时候必须要指定对应的角色，否则用户无法操作数据库 resource 资源，包括database或collection 也可以是database和collection的组合 actions 权限操作，定义了 user 能够对 resource document 执行的操作。如 增、删、改、查 privilege 权限，privilege 是一组 resource 和 action的组合，对资源拥有什么操作称为权限 authenticationDatabase 认证库，即创建角色或用户时所在的库 角色管理MondoDB支持基于角色的访问控制（RBAC）来管理对MongoDB系统的访问。一个用户可以被授权一个或多个角色以决定该用户对数据库资源和操作的访问权限。在权限以外，用户是无法访问系统的。 数据库角色在创建用户的role参数中设置。角色分为內建角色和自定义角色。 内建角色 数据库用户角色 read：允许用户读取指定数据库 readWrite：允许用户读写指定数据库 数据库管理员角色 dbAdmin：允许用户进行索引创建、删除，查看统计或访问system.profile，但没有角色和用户管理的权限 userAdmin：提供了在当前数据库中创建和修改角色和用户的能力 dbOwner：提供对数据库执行任何操作的能力。这个角色组合了readWrite、dbAdmin和userAdmin角色授权的特权 集群管理角色 hostManager：提供监视和管理服务器的能力 clusterManager：在集群上提供管理和监视操作。可以访问配置和本地数据库，这些数据库分别用于分片和复制 clusterMonitor：提供对监控工具的只读访问 clusterAdmin：提供最强大的集群管理访问(副本集、分片、主从等)。组合了clusterManager、clusterMonitor和hostManager角色的能力，还提供了dropDatabase操作 备份恢复角色 backup：提供备份数据所需的能力 restore： 提供使用mongorestore恢复数据的能力 所有数据库角色 readAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读权限 readWriteAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读写权限 userAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的userAdmin权限 dbAdminAnyDataBase：只在admin数据库中可用，赋予用户所有数据库的adAdmin权限 超级用户角色 root：超级权限，只能针对admin库 内部角色 __system：提供对数据库中任何对象的任何操作的特权 自定义角色 MongoDB内置角色一般来说都是够用的，但当内置角色不满足需求时就可以自定义角色了。使用 db.createRole() 方法来自定义角色。 只能在admin库中创建角色： 123456789101112use admindb.createRole( &#123; role:&lt;role_name&gt;, #定义角色名称 privilege:[ #权限集 &#123; resource:&#123;cluster:true, actions:[&lt;action_name&gt;] &#125;, &#123; resource: &#123;db:&lt;db_name&gt;, collection:&lt;coll_name&gt; &#125;, &#123; actions:[&lt;action_name&gt;] &#125; #定义对这个库或集合可进行的权限操作，这是一个数组 ], roles:[ &#123; role:&lt;role_name&gt;, db:&lt;db_name&gt; &#125; ] #是否继承其他的角色 &#125;) 角色创建完毕后MongoDB会在系统库admin下创建一个collection名叫 system.roles，里面存储的即是角色相关的信息。 1db.system.roles.find() 操作角色1234567891011#查看角色db.getRole()#角色继承#角色授权db.grantRolesToRole()#角色移权db.revokeRolesfromRole() 用户管理创建用户： 123456db.createUser(&#123; user:&quot;xxx&quot;, pwd:&quot;xxxx&quot;, customDate:&quot;xxx&quot;, roles:[&#123; #指定角色名称以及认证库 role:&quot;xxx&quot;, db:&quot;xxxx&quot; &#125;]&#125;) 开启认证： 1234567891011vim /etc/mongo.confsecurity: authorization：enableddb.auth(&quot;user&quot;,&quot;passwd&quot;) #在use db后或mongo -u user -p passwd --authenticationDatabase xxx#在哪个库创建的用户就需要使用哪个库进行认证 查看用户： 12db.getUser(&quot;user&quot;)db.system.users.find() 删除用户： 12db.dropUser(&quot;user&quot;)db.dropAllUsers() 添加用权限： 1db.grantRolesToUser() 修改用户密码： 1db.changeUserPassword(&quot;user&quot;,&quot;new_passwd&quot;) 在MongoDB中删除库和集合并不会级联删除对应的角色和用户。因此如果想彻底删除对应的业务应该先删除库与其对应的角色和用户。 如果既想实现精细化权限控制又想简化用户管理，原则上建议只给开发创建一个账户，并且使用admin做认证库，这样可以避免清理过期业务库而导致无法登陆的问题。 内部认证Internal Authentication 可以对副本集和分片集成员进行验证。对于成员的内部认证，MongoDB可以使用keyfile或x.509证书。 KeyFile keyfiles的内容作为成员的共享密码，其长度必须在6-1024个字符之间，只能包含base64 set中的字符。 1234567891011121314openssl rand -base64 512 &gt; /etc/mongodb.keyfilechmod 600 /etc/mongodb.keyfilechown mongod:mongod /etc/mongodb.keyfile#配置文件：security.keyFile#cmd-line option: --keyFilevim /etc/mongod.confsecurity: authorization: enabled keyFile: &quot;/etc/mongodb.keyfile&quot; clusterAuthMode: &quot;keyFile&quot; x.509 内部认证使用x.509进行验证。 CA必须为所有分片集，副本集成员颁发x.509证书 成员证书的主题中找到Distinguished Name(DN)必须为以下至少一个属性指定非空值：Organization(O)，Organization Unit(OU)，Domain Component(DC) 组织属性，组织单元属性和域组件必须与其他集群成员的证书相匹配。12CN=host1,OU=Dept1,O=MongoDB,ST=NY,C=USC=US, ST=CA, O=MongoDB, OU=Dept1, CN=host2 MongoDB Configuration 配置文件：security.clusterAuthMode and net.ssl.clusterFile cmd-line options: —clusterAuthMode and —sslClusterFile 在副本集中强制秘钥文件访问控制Enforce Keyfile Access Control in a Replica Set 对副本集执行访问控制需要配置： 使用内部身份验证副本集成员之间的安全性 使用用户访问控制连接客户端和副本集间的安全性 步骤： 创建一个密钥文件 Create a keyfile 通过密钥文件进行身份验证，副本集中的每个mongod实例都使用密钥文件的内容作为共享密码，用于验证部署中的其它成员。 12345#yum install -y opensslopenssl rand -base64 756 &gt; &lt;path-to-keyfile&gt;chmod 400 &lt;path-to-keyfile&gt;chown &lt;owner&gt;:&lt;owner&gt; 复制密钥文件到每个副本集成员 Copy the keyfile to each replica set member 将密钥文件复制到每一台主机的副本集成员中。确保运行mongod实例的用户就是keyfile的所有者，并可以访问密钥文件。 关闭所有的副本集成员 Shut down all members of the replica set 关闭每个副本集中的mongod，从Secondary开始。知道所有的成员都脱机为止，包括任何仲裁者(Arbiter)。Primary是最后一个关闭的成员。 12use admindb.shutdownServer() 启动访问控制并重启副本集成员 123456789101112vim /etc/mongod.confsecurity: keyFile: &lt;path-to-keyfile&gt; clusterAuthMode: keyfilereplication: replSetName: &lt;replcaSetName&gt;#cmd-linemongod --keyFile &lt;path-to-keyfile&gt; --clusterAuthMode keyfile --replSet &lt;replicaSetName&gt; 连接到mongo shell 在Primary上使用rs.status()来标识副本集成员。 创建一个administrator Create the user administrator 必须在Primary上创建用户。 12345678admin = db.getSiblingDB(&quot;admin&quot;)admin.createUser( &#123; user: &apos;zhang&apos;, pwd: &apos;password&apos;, roles: [&#123; role: &apos;userAdminAnyDatabase&apos;, db: &apos;admin&apos; &#125;] &#125;) 开启用户认证 12345678vim /etc/mongod.confsecurity: authorization: enabled keyFile: &lt;path-to-keyfile&gt; clusterAuthMode: keyfilereplication: replSetName: &lt;replcaSetName&gt; 以管理员身份进行认证 Authenticate as the User Administrator 123456mogno&gt;db.getSiblingDB(&quot;admin&quot;).auth(&apos;zhang&apos;,&apos;password&apos;)#ormongo -u &apos;zhang&apos; -p &apos;password&apos; --authenticationDatabase &apos;admin&apos; 创建集群管理员(可选) Create the cluster administrator (Optional) 1234567db.getSiblingDB(&quot;admin&quot;).createUser( &#123; &quot;user&quot; : &quot;ravi&quot;, &quot;pwd&quot; : &quot;changeme2&quot;, roles: [ &#123; &quot;role&quot; : &quot;clusterAdmin&quot;, &quot;db&quot; : &quot;admin&quot; &#125; ] &#125;) 在不停机的副本集中强制实施keyfile访问控制]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP请求方法和状态码]]></title>
    <url>%2F2017%2F12%2F01%2FHTTP-method-status%2F</url>
    <content type="text"><![CDATA[常见HTTP请求方法HTTP协议的请求方法有：GET, POST, HEAD PUT DELETE, OPTIONS, TRACE, CONNECT Method Description GET 向Server请求文件 POST 向Server发送数据并让Server进行处理 PUT 向Server发送数据并存储在Server端 HEAD 检查一个对象是否存在 DELETE 从Server上删除一个文件 CONNECT 对通道提供支持 TRACE 跟踪到Server的路径 OPTION 查询Server的性能 HTTP Status Code当我们从Client向Server发送请求时，Server会向我们返回StatusCode。StatusCode会告诉我们Server的响应的状态，通过它，我们就可以知道当前请求是成功还是出现了问题。 HTTP StatusCode放置在HTTP Response报文中。 StatusCode由三位数字组成，第一个数字定义了响应类型，有五种可能值： 状态码 响应类别 描述 1xx 指示信息 服务器正在处理请求 2xx 成功 请求以正常处理完毕 3xx 重定向 需要进行额外操作以完成请求 4xx 客户端错误 客户端原因导致服务器无法处理请求 5xx 服务器错误 服务器原因导致处理请求出错 常见HTTP状态码 状态码 描述 200-OK 服务器成功返回网页，这是成功的HTTP请求返回的标准状态码 301 - Moved Permanently 永久跳转，所有请求的网页将永久跳转到被设定的新位置 400 - Bad Request 客户端请求有语法错误，不能被服务器理解 403 - Forbidden 禁止访问，这个请求时合法的，但是服务器端因为匹配了预先设置的规则而拒绝响应客户端的请求，此类问题一般为服务器权限配置不当所致 404 - Not Found 服务器找不到客户端请求的指定页面，可能是客户端请求了服务器不存在的资源所导致 500 - Internal Server Error 内部服务器错误，服务器遇到了意料不到的情况，不能完成客户的请求。这是一个较为笼统的报错，一般为服务器的设置或内部程序问题所致 502 - Bad Gateway 坏的网关，一般是代理服务器请求后端服务器时，后端服务不可用或没有完成响应网关服务器。一般为代理服务器下面的节点出了问题 503 - Service Unavailable 服务当前不可用，可能为服务器超载或停机维护所致，或者是代理服务器后面没有可以提供服务的节点 504 - Gateway Timeout 网关超时，一般是网关代理服务器请求后端服务时，后端服务没有在特定的时间内完成处理请求，一般为服务器过载所致，没有在指定的时间内返回数据给代理服务器 1xx1xx（临时响应），表示临时响应并需要请求者继续执行操作。 状态码 描述 100 - Continue 请求者应当继续提出请求 101 - Switching Protocols 请求者要求服务器更换协议，服务器已确认并准备更换 2xx2xx（成功），表示成功处理了请求。 状态码 描述 200 - OK Server已成功处理了请求 201 - Created 请求成功并且Server创建了新的资源 202 - Accepted Server以接受请求，但尚未处理 203 - Non-Authoritative Information Server已成功处理了请求，但返回的信息可能来自另一个来源 204 - No Content Server成功处理了请求，但没有返回任何内容 205 - Reset Content 没有新的内容，但浏览器应该重置它所显示的内容 206 - Partial Content 服务器成功处理了部分GET请求 3xx3xx（重定向），表示要完成请求需要进一步操作。 状态码 描述 300 - Multiple Choices 针对请求，Server可执行多种操作 301 - Moved Permanently 请求的网页已移动到新位置 302 - Found Server目前从不同位置的网页响应请求 303 - See Other 请求者对不同位置使用单独的GET请求来检索时 304 - Not Modified 自从上次请求后，请求的网页内容未修改过 305 - Use Proxy 请求者只能使用代理访问请求的网页 307 - Temporary Redirect Server从不同位置的网页响应请求，但请求者继续使用原有位置进行请求 4xx4xx（请求错误），表示请求可能出错，妨碍了Server的处理。 状态码 描述 400 - Bad Request Server不理解请求的语法 401 - Unauthorized 请求要求身份认证 403 - Forbidden Server拒绝请求 404 - Not Found Server找不到请求的网页 405 - Method Not Allowed 请求方法不被允许 406 - Not Acceptable 无法使用请求的恩日工特性响应请求的网页 407 - Proxy Authentication Required 请求需要代理授权 408 - Request Timeout Server等候请求时超时 409 - Conflict Server在完成请求时发生冲突 410 - Gone 请求的资源以永久删除 411 - Length Required Server不接受不含有效内容长度Header的请求 412 - Precondition Failed Server为满足请求者在请求中设置的一个前提条件 413 – Request Entity Too Large 请求实体太大，Server无法处理 414 - Request URI Too Long 请求的URI过长，Server无法处理 415 – 不支持的媒体类型 请求的格式不受支持 416 – Requested Range Not Satisfiable 页面无法提供请求的范围 417 – 执行失败 Server未满足期望请求Header的要求 451 基于法律上的的原因，不能像请求者展示网页内容 5xx5xx（服务器错误），表示服务器在尝试处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是请求出错。 状态码 描述 500 - Internal Server Error Server遇到错误，无法完成请求 501 - Not Implemented Server不具备完成请求的功能 502 - Bad Gateway Server作为网关或代理时，从upstream收到无效响应 503 - Service Unavailable Server暂时无法使用 504 - Gateway Timeout Server作为网关或代理时，没有及时从upstream收到请求 505 - HTTP Version Not Supported Server不支持请求中所用的HTTP版本]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Filesystem Hierarchy Standard]]></title>
    <url>%2F2017%2F11%2F27%2FFHS%2F</url>
    <content type="text"><![CDATA[FHS介绍FHS(Filesystem Hierarchy Standard)，文件系统层次化标准：http://www.pathname.com/fhs FHS主要目的是希望让用户了解安装文件通常放置的目录。所以希望软件开发商、系统制定者以及维护系统的用户，都能够遵循FHS的标准。 FHS-compliant system： - 可分享的(shareable) 不可分享的(unshareable) 不变的(static) /usr /opt /etc /boot 可变的(variable) /var/mail /var/spool/news /var/run /var/lock shareable： 可分享给其他系统(主机)挂载使用； unshareable： 不适合分享给其他主机； static： 有些数据基本是不会变化的； variable： 进程变更的数据。 FHS针对目录树架构仅定义出三层目录下应该放置什么数据，这三个目录下所应该放置的目录也都有特定规定。 /： The root filesystem, 与开机系统有关； /usr: The /usr hierarchy, Unix software resource； /var: The /var hierarchy, 与系统运行过程有关。 The Root Filesystem根目录(/)是系统最重要的一个目录。不但所有目录都是由根目录衍生出来，同时根目录还与系统的启动、还原、修复等操作相关。若系统出现问题，根目录必须要包含能够修复文件系统的程序才行。破坏根文件系统上的数据的错误比破坏其他任何分区都要严重！ 为了平衡这些考虑，建议尽可能保持根分区小。应用程序不应在根目录中创建特殊文件或子目录！ The following dirs or symbolic-links, are required in / 目录 描述 /bin 必要的二进制命令 /boot boot-loader的静态文件 /dev 设备文件 /etc 主机特定的系统配置文件 /lib 基本的共享库(shared libraries)和内核模块(kernel modules) /media 可移除媒体的挂载点 /mnt 临时挂载文件系统的挂载点 /opt 第三方软件包放置目录 /sbin 必要的系统二进制命令 /srv 系统提供的服务数据 /tmp 临时文件 /usr /usr层次结构 /var /var层次结构 除了上面列出必须存在的目录，下面这些目录很也很重要。 目录 描述 /lost+found 在ext文件系统里，当文件系统发生错误时，将一些遗失的片段放置到此目录下 /home 用户家目录 /root root用户家目录 /proc 虚拟文件系统，放置的数据都在内存当中，不占磁盘空间 /sys 虚拟文件系统，记录内核相关信息，不占磁盘空间 另外需要注意的是，因为根目录与开机有关，开机过程中仅有根目录被挂载。其他分区则是在开机完成后才会持续进行挂载。因此，根目录下与开机过程有关的目录就不能放到不同的分区中去。 如： /etc /bin /sbin /dev /lib /bin/bin, 基本用户二进制命令文件，供所有用户（系统管理员和用户）使用。 /bin下不能有子目录(subdirectory)。 The following commands or symbolic-links to commands, are required in /bin 命令 描述 cat 将文件连接到stdout的实用程序(Utility) chgrp 更改文件所有权 chmod 更改文件访问权限 chown 更改文件所有者和和组 cp 复制文件和目录 date 打印或设置系统数据和时间 dd 转换和复制文件 df 磁盘使用情况 dmesg 打印或控制kernel消息缓冲区 echo 显示一行文本 false do nothing, 不成功 true do nothing, 成功 hostname 系统主机名 kill 发送信号到进程 ln 在文件之间创建链接 login 在系统上开始会话 ls 列出目录内容 mkdir 创建目录 mknod 创建block或character特殊文件 more 文本翻页 mount 挂载文件系统 umount 解挂文件系统 mv move/rename文件 ps 报告进程状态 pwd 打印当前工作目录 rm remove文件或目录 sed sed流编辑器 sh Bourne command shell stty 更改或打印终端设置 su change uid sync 刷新文件系统缓冲区 uname 打印系统信息 The following programs or symbolic-links to programs, must be in /bin if the corresponding-system is installed: 命令 描述 csh The C shell(可选) ed 编辑器(可选) tar tar归档(可选) cpio cpio归档(可选) gzip GNU压缩工具(可选) gunzip GNU解压缩工具(可选) netstat 网络统计(可选) ping ICMP网络测试(可选) /boot/boot :static file of the boot-loader 该目录包含引导过程所需所有内容，处理引导是不需要的配置文件和映射安装文件外。因此，/boot储存kernel开始执行用户模式之前使用的数据。 操作系统kernel必须位于 / or /boot /dev/dev :device files /dev 目录是特殊或设备文件的位置。 /etc/etc :host-specific system configuration 配置文件是用来控制程序操作的本地静态文件，不能是可执行的二进制文件。 The following files or symbolic-links to files, must be in /etc if the corresponding-subsystem is installed. 文件 描述 备注 csh.login C shell登录的系统范围初始化文件 Optional exports NFS文件系统访问控制列表 Optional fstab 文件系统静态信息 Optional ftpusers FTP守护进程用户访问控制列表 Optional gateways 路由网关文件 Optional gettydefs getty终端设置 Optional group 用户组文件 Optional passwd 密码文件 Optional host.conf 解析器配置文件 Optional hosts 主机域名的静态信息 Optional hosts.allow Tcp-wrapper的主机访问文件 Optional hosts.deny Tcp-wrapper的主机禁止文件 Optional hosts.equiv rlogin, rsh, rcp的可信主机列表 Optional hosts.lpd lpd的可信主机列表 Optional inetd.conf inetd配置文件 Optional inittab init配置文件 inittab is no longer used when using systemd id.so.conf 搜索共享库的额外目录 Optional issue 预登录消息和 CentOS Linux 7(core) kernel \r on an \m motd 登录后信息 Welcome to $host mtab 文件系统动态信息 Optional mtools.conf mtools配置文件 Optional networks 网络名称的静态信息 Optional printcap lpd打印机功能数据库 Optional profile sh shell login的系统范围初始化文件 Optional protocols IP协议列表 Optional resolv.conf 域名服务器解析文件 Optional rpc RPC协议列表 Optional securetty root登录的TTY访问控制 Optional shells 有效登录shell的路径名 Optional syslog.conf syslogd配置文件 Optional /etc/opt/etc/opt :/opt的配置文件 第三方应用程序软件的特定主机配置文件，必须安装在/etc/opt/ 中。 /etc/xml/etc/xml :XML的配置文件 这里安装和定义XML系统的高级参数同通用配置文件。 /home (Optional)/home :用户主目录 /home是一个相当标准的概念，但它显然是一个特定于站点的文件系统。设置会因主机而异。因此，任何程序都不应该依赖这个目录。 /lib/lib :基本的共享库和内核模块 /lib目录中包含引导系统和运行在根文件系统的命令，即/bin和/sbin中的命令。 至少需要包含以下文件(链接)： 文件 描述 libc.so.* 动态链接C库 ld* 执行时间 链接器/加载器 /lib (Optional)/lib&lt;qual&gt; : 不同格式的基本共享函数库如：64位的/lib64; 32位的/lib32。 用来存放与/lib不同格式的二进制函数库，如支持64位的/lib64函数库等。 /media/media :可移除媒体的挂载点 此目录包含的子目录，可作为各移动介质(USB,cdrom,floppy…)的挂载点。 尽管在 /mnt 中使用子目录作为挂载点已经很常见了，但与直接使用/mnt作为临时挂载点的传统相去甚远。 /mnt/mnt :临时挂载文件系统的挂载点 /opt/opt :为第三方软件包保留的目录 要安装在/opt中的软件包必须将其静态文件放置在单独的/opt/&lt;packge&gt;目录树中。 目录/opt/bin, /opt/doc, /opt/include, /opt/info, /opt/lib, /opt/man 是保留给本地系统管理员使用。如果第三方软件包含Unix手册，而手册必须放置于/opt//share/man/，必须使用与/usr/share/man相同的子结构。 /root (Optional)/root :root用户的主目录 /sbin/sbin :系统二进制文件 系统管理的实用程序(命令)，存储在/sbin, /usr/sbin, /usr/local/sbin中。/sbin包含启动，恢复，修复系统，以及/bin中二进制文件所必须的二进制文件。本地安装的系统管理程序应放置在/usr/local/sbin中。 The following commands or symbolic-links to commands are required in /sbin1shutdown #关闭系统 The following files or symbolic-links to files，must be in /sbin if the corresponding subsystem is installed 命令 描述 备注 fastboot 重启系统而不检查磁盘 Optional fasthalt 停止系统而不检查磁盘 Optional fdisk 分区表操作器 Optional fsck 文件系统检查和修理工具 Optional fsck.* 针对特定文件系统检查和修复 Optionaleg：fsck.ext3 getty getty程序 Optional half 停止系统 Optional ifconfig 配置网络接口 Optional init 初始化进程 Optional mkfs 创建文件系统 Optional mkfs.* 创建特定文件系统 OPtionaleg: mkfs.ext4 mkswap 设置swap分区 OPtional reboot 重启系统 OPtional route IP路由表实用程序 OPtional swapon 启用分页和交换 OPtional swapoff Disable paging and swapping Optional update 守护进程定期刷新文件系统缓冲区 Optional /srv/srv :系统提供的服务(service)的数据 /tmp/tmp :临时文件 /tmp目录为临时需要文件的程序提供。程序不能在程序的调用之间保留/tmp中的任何文件或目录。尽管/tmp中数据可能会以某种特定方式删除，但建议在系统启动时删除/tmp中所有文件。 The /usr Hierarchy/usr 里面放置的数据是可分享与不可变动的。这就意味着可在各种符合FHS的主机之间共享，但不能写入。大型软件包不应在/usr层次结构下使用直接子目录。 The following dirs of symbolic-links to dirs are required in /usr 目录 描述 /usr/bin 大多数用户命令 /usr/include C程序包含的头文件 /usr/lib 库文件 /usr/local 本地层次结构 /usr/sbin 非重要的系统二进制文件 /usr/share 独立于架构的数据 其他选项： 目录 描述 备注 /usr/lib&lt;qual&gt; 可选格式库 Optional /usr/src 源代码 OPtional /usr/games 游戏和教育二进制文件 OPtional /usr/bin/usr/bin :大多数用户命令这是系统上可执行命令的主要目录。 The following files or symbolic-links to files must be in /usr/bin, if the corresponding subsystem is installed 命令 描述 备注 perl 实用提取和报告语言 OPtional python python解释语言 Optional tclsh tcl解释器的简单shell OPtional wish 简单 tcl/tk windowing shell Optional expect 程序交互式对话 Optional 因为shell script解释器(在shell script脚本的第一行 #!)不能依赖路径，所以标准化它们的位置是有利的。Bourne shell 和 C-shell解释器已经被固定在/bin中，但 perl,python,tcl经常在许多不同的地方。 /usr/include/usr/include :标准C包含文件的目录 这是C语言所有系统的通用包含文件应该被放置的地方。 /usr/lib/usr/lib :编程和包的所需要的库 /usr/lib包括 不打算由用户或shell script直接执行的目标文件、库和内部二进制文件。 /usr/lib (Optional)/usr/lib&lt;qual&gt; :可选格式库 /usr/local/usr/local :本地层次结构 /usr/local是给系统管理员安装本地软件使用。当系统软件更新时，需保证安全。它可以用于在一组主机之间共享，但在 usr中找不到的程序和数据。 本地安装软件必须放在 /usr/local 而不是 /usr，除非安装它来升级或替换usr的软件 The following dirs or symbolic-links to dis must be in /usr/local 目录 描述 /usr/local/bin 本地二进制文件 /usr/local/etc 本地二进制文件的特定配置文件 /usr/local/games 本地游戏二进制文件 /usr/local/include 本地C头文件 /usr/local/lib 本地库 /usr/local/man 本地在线手册 /usr/local/sbin 本地系统二进制文件 /usr/local/share 本地独立架构层次结构 /usr/local/src 本地源码 /usr/local/share目录内容的要求应与/usr/share相同，唯一附加约束是/usr/local/share/man和/usr/local/man目录必须是同步的。（基本上就是符号链接了！） /usr/sbin/usr/sbin :非必要的标准系统二进制文件 该目录包含系统管理员专门使用的任何非必要的二进制文件。系统修复、恢复、挂载/usr等其他重要必要功能必须放在/sbin中。 /usr/share/usr/share :独立于架构的数据 /usr/share层次 是为了所有只读架构独立数据。该层次可以在给定OS的所有体系架构平台之间共享。如具有i386和PPC平台站点可能会维护一个集中安装的/usr/share目录。但/usr/share一般不打算由不同的操作系统共享，或由同一操作系统的不同版本共享。 The following dis or symbolic-links to dirs must be in /usr/share 目录 描述 man 在线手册 misc 其他独立于架构的数据 The following dis or symbolic-links to dirs must be in /usr/share, if the corresponding subsystem is installed 目录 描述 备注 dict 单词列表 Optional doc 各种文档 Optional games /usr/games的静态文件 Optional info GNU Info system’s primary dir Optional locale 支持的区域信息 Optional zoneinfo Timezone info and conf Optional NLS Native language support Optional sgml SGML数据 Optional terminfo terminfo数据库目录 Optional xml xml数据 Optional /usr/share/dict/usr/share/dict :单词列表这个目录是系统上单词列表的家目录，只包含英文单词，它们由look和各种拼写程序使用。它们是所有拼写检查器唯一通用的文件。 文件 描述 备注 words 单词列表 Optional linu.words linux可用单词列表 Optional /usr/share/man/usr/share/man :手册页它包含了/, /usr文件系统下的命令和数据的手册信息 手册页存储在 /usr/share/man/&lt;locale&gt;/man&lt;section&gt;/&lt;arch&gt;中。 每个部分的描述： man1: 可公开访问的命令的手册页，用户需要使用的大多数程序文档放置于此； man2: 系统调用部分，描述所有的系统调用(请求内核执行操作)； man3: 函数库和子例程部分，描述不直接调用内核服务的程序库例程； man4: 特定文件部分，描述系统中特定文件，相关驱动程序和网络支持。通常，这包含/dev中找到的设备以及网络协议支持的内核接口； man5: 文件格式部分，许多数据文件的格式记录在此； man6: 游戏，演示和一般小程序； man7: 各种难以分类的手册页； man8: 系统管理员用于操作和维护系统的程序记录在这。 The following dirs or symboli-link to dirs must be in /usr/share/man/&lt;locale&gt;, unless they are empty 目录 描述 备注 man1 用户程序 Optional man2 系统调用 Optional man3 函数库调用 Optional man4 特定文件 Optional man5 文件格式 Optional man6 游戏 Optional man7 混杂的手册页 Optional man8 系统管理 Optional 必须在/usr/share/man结构中作出规定，以支持用不同语言编写的手册页。这些规定必须考虑到手册页的存储和参考，相关因素包括语言和字符编码集。 栗子： Language Country CharacterSet Dir English - ASCII /usr/share/man/en English United Kingdom ISO 8859-15 /usr/share/man/en_GB English United States ASCII /usr/share/man/en_US /usr/share/misc/usr/share/misc :与架构无关的数据 /usr/share/sgml/usr/share/sgml :SGML数据 /usr/share/xml/usr/share/xml :XML数据 /usr/src/usr/src :源代码Source Code可能放置在此目录的子目录中，仅供参考。 /var Hierarchy/var 包含可变数据文件，包括假脱机目录和文件，系统管理和登录数据，以及临时文件。 如果/var不能成为一个单独的分区，最好将/var移出/分区并移入/usr分区。（为了减小根分区大小或当根分区空间不足时）也可将/var链接到/usr/var。 The following dirs or symbolic-link to dirs are required in /var. 目录 描述 /var/cache 应用程序缓存数据 /var/lib 可变状态信息 /var/local /usr/local的可变数据 /var/lock 锁文件 /var/log 日志文件 /var/opt /opt的可变数据 /var/run 与运行进程相关的数据 /var/spool 应用程序队列数据 /var/tmp 为系统重启保留的临时文件 The following dirs or symbolic-link to dir must be in /var,if the corresponding subsystem is installed. 目录 描述 备注 /var/account 进程账户日志 可选 /var/crash 系统奔溃转储 可选 /var/games 可变游戏数据 可选 /var/mail 用户邮箱文件 可选 /var/yp 网络信息服务数据库文件 /var/account/var/account :该目录保存当前活动的进程记账日志和复合进程数据。 /var/cache/var/cache :保存应用程序缓存的数据。应用程序必须能够重新生成或回复数据。与/var/spool不同，删除了缓存文件不会丢失数据。数据必须在应用程序调用和系统重启间保持有效。缓存目录的数据格式没有其他要求。 对于缓存数据单独存在的目录，系统管理员可从/var下其他目录设备不同的磁盘和备份策略。 目录 描述 备注 /var/cache/fonts 本地生成的字体 可选 /var/cache/man 本地格式化的手册页 可选 /var/cache/www www代理或缓存数据 可选 /var/cache/&lt;package&gt; 特定包缓存数据 可选 /var/lib/var/lib :可变状态信息。目录保存于应用程序或系统有关的状态信息。状态信息(state infofmation)，是程序在运行时修改的数据，属于一个特定的主机。 应用程序必须为其数据使用/var/lib/&lt;subdir&gt;，有一个必须的子目录/var/lib/misc用于不需要子目录的状态文件。 /var/lock/var/lock :锁文件，锁文件应该存储在此目录中。锁文件锁定多个应用程序共享的设备和其他资源。 这种锁文件内容的格式必须是HDB UUCP锁文件格式。HDB格式是将进程标识符(PID)存储为ASCII十进制数，并带有换行符。 /var/log/var/log :日志文件和目录，大多数日志必须写入此目录或适当子目录。 The following file or symbolic-link to file must be in /var/log. 文件 描述 lastlog 每个用户上次登录信息的记录 message syslogd的系统信息 wtmp 所有登录和注销的记录 /var/mail邮件缓存区必须通过/var/mail访问，邮件缓冲区文件必须采用的形式。 /var/run/var/run :运行时变化数据，此目录包含系统信息数据，描述系统启动以来的情况。此目录下的文件必须在引导过程开始时被清除。进程标识符(PID)文件放置于此目录或下的子目录里面。 /var/spool/var/spool :应用程序队列数据。此目录包含正在等待某种稍后处理的数据，/var/spool中的数据表示工作将在将来执行(通过程序，用户或管理员)，数据通常会在工作处理后被删除。 The following dirs or symbolic-link to dirs must be in /var/spool,if the corresponding subsystem is installed. 目录 描述 备注 lpd 打印机队列目录 可选 mqueue 发送邮件队列 可选 news 新闻假脱机目录 可选 rwho rwhod文件 可选 uucp uucp的假脱机目录 可选 /var/tmp/var/tmp :在系统重启之间保存的临时文件。存储在/var/tmp的数据比/tmp中的数据更持久。 OS Specific Annex本节是针对仅适用于特定OS的其他建议和要求。 LinuxLinux操作系统的附件 / :根目录在Linux系统上，如果内核位于/，建议使用Linux内核源代码包中使用的名称vmlinux或vmlinuz。 我的CentOS7中，内核文件默认是/boot/vmlinuz-$kernel-version.$arch /bin :基本用户命令二进制文件(供多有用户使用) /dev :设备和特殊文件 /dev/null : 写入该设备的所有数据都被丢弃。从这个设备读取将返回一个EOF条件。 /dev/zero : 该设备是归零数据的来源，写入该设备的所有数据被丢弃。从这个设备读取将返回包含zero的请求的字节数。 /dev/tty : 该设备类似于进程控制终端。一旦这个设备被打开，所有读写操作就好像实际的控制终端以及被打开一样。 /etc :主机的特定系统配置Linux系统要将附件文件放置到/etc中。 /lib64 和 /lib32 :64/32位库(依赖于体系结构)64位体系结构PPC64,AMD64,x86_64必须将64位库放置于/lib64中，将32位库放置于/lib中；64位体系结构IA64必须将64位库放置于/lib中。 /proc :内核和进程信息虚拟文件系统PROC文件系统是用于处理进程和系统信息的标准Linux方法，而不是/dev/kmem和其它类似方法。强烈建议使用PROC文件系统获取 存储，进程，内存，内核等信息。 /sbin :基本系统二进制文件Linux系统将这些附加文件放置于/sbin中： 第二扩展文件系统命令（可选）： 123456badblocksdumpe2fse2fsckmke2fsmklost+foundtune2fs boot-loader 映射安装程序（可选）：lilo 静态二进制文件： 123ldconfigsln(static ln)ssync(static sync) 出现问题时，sln（静态ln）和ssync（静态同步）非常有用；idconfig程序可以作为升级知道的手段；sln的主要用途，修复不良协调升级后/lib中不正确的符号链接动态库。 对于/sbin, idconfig二进制文件是可选的。因为站点可能会在启动时选择运行idconfig而不是仅在升级共享库时。以下是一些常见问题： 我刚刚删除了/lib/； 我无法找到库的名称，因为ls是动态链接。我使用的shell没有内置ls，我也不知道使用echo *作为替换； 我有一个静态ln，但我不知道怎么称呼这个链接。 杂项： 12345#ctrl+alt+delctrlaltdel#keyboard ratekbdrate 为了应对某些键盘出现如此高的重复速率一致无法使用,kbdrate可以安装在某些系统上的/sbin中； 由于ctrl+alt+del组合键在内核中的默认操作是硬重启，因此通常建议在将根文件系统挂在到读写模式之前禁用该行为。这就可能需要ctrlaltdel程序，它可以安装在系统的/sbin中。 /usr/include :C程序包含的头文件如果安装了C或C++编译器，则只有非 基于glibc的系统才需要这些链接符号。 12/usr/include/asm -&gt; /usr/src/linux/include/asm-&lt;arch&gt;/usr/include/linux -&gt; /usr/src/linux/include/linux /usr/src :源代码对于基于glibc的系统，此目录没有具体指导。 对于glibc之前基于linux libc修订版的系统： /usr/src/linux是唯一放置Linux内核源代码的位置。 /usr/spool/cron :cron和jobs此目录包含了cron和程序的可变数据。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>FHS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix]]></title>
    <url>%2F2017%2F11%2F14%2FZabbix%2F</url>
    <content type="text"><![CDATA[参考： Zabbix官方网站 Zabbix中文文档 Zabbix-repo仓库: http://repo.zabbix.com 阿里云镜像: https://mirrors.aliyun.com/zabbix/zabbix/ . 环境： CentOS7x86_64 Zabbix 3.4 Zabbix简介Zabbix （音同 zæbix），是由 Alexei Vladishev 开发的一种网络监视、管理系统，基于 Server-Client 架构。Zabbix 的授权是属于 GPLv2。Zabbix可用于监视各种网络服务、服务器和网络机器等状态。是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案。Zabbix也可经由SNMP、TCP、ICMP、SSH等对目标进行监视。 Zabbix的系统构成Zabbix系统由以下各独立模块组成： Zabbix Server，服务端(以C开发)。Server端通过收集SNMP和Agent发送的数据，写入数据库，再通过PHP+Apache在Web端展示； Zabbix Agent，客户端(基本支持所有操作系统)，并将监控主机数据发送给Server； Zabbix Frontend，Web管理端(以PHP和JavaScript构成)； Zabbix Proxy(可选组件)。用于分布式监控。 Zabbix的特点Zabbix是一个高度集成的网络监控解决方案，一个简单的安装包中提供多样性功能。 数据收集； 灵活的阀值(触发器)定义； 高度可配置化的告警； 实现图表绘制； Web监控功能； 丰富的可视化选项； 历史数据存储； 配置简单； 使用模板； 网络发现； Zabbix API； 权限管理系统； 功能强大并易于扩展的监控代理。 定义Zabbix的常用术语含义。 主机(host)： 一台你想监控的网络设备，用IP或域名表示。主机名不能使用中文创建，会报错。 主机组(host group):主机的逻辑组，它包含主机和模板。组名可以使用中文。 监控项(item):你想要接收的主机的特定数据，一个度量数据。 触发器(trigger):一个被用于定义问题阀值和评估监控项接收到的数据的逻辑表达式。 事件(event):单次发生的需要注意的事情。 异常(problem):一个处在异常状态的触发器。 动作(action):一个对事件作出反应的预定义的操作。 升级(escalation):一个在动作内执行操作的自定义场景。 媒介(media):发送报警通知的手段。 通知(notification):利用已选择的媒体途径把事情相关信息发送给用户。 远程命令(remote command):预先定义好的，满足一定条件后，可在被监控主机上自动执行的命令。 模板(template):一组可以被应用到一个或多个主机上的实体的集合。 应用(application):一组监控项组成的逻辑分组。 Web场景(Web scenario):利用一个或多个HTTP请求来检查网站的可用性。 前端(frontend):Zabbix提供的Web界面。 Zabbix API:Zabbix API允许你使用JSON RPC协议来创建、更新和获取Zabbix对象信息或执行任何其他的自定义的任务。 Zabbix server:Zabbix软件监控的核心程序，主要功能是与Zabbix proxies和agent进行交互、触发器计算、发送告警通知，并将数据集中保存等。 Zabbix agent:部署在监控对象上，能够主动监控本地资源和应用。 Zabbix proxy:帮助Zabbix server收集数据，分担Zabbix server的负载。 Zabbix进程Agentzabbix agent部署在监控的目标上，主动监测本地的资源和应用（硬件驱动，内存，处理器统计等）。zabbix agent手机本地的操作信息并将数据报告给zabbix server用于进一步处理。 zabbix agent有被动(passive)和主动(active)两种检查方式。 Serverzabbix server是zabbix软件的核心程序。它通过轮询和捕获数据，计算是否满足触发器条件，向用户发送通知。它是zabbix监控代理和Proxy代理报告系统可用性和完整性数据的核心组件。zabbix server自身可以通过简单远程检查网络服务(如Web服务器和邮件服务器)。 server是一个包含了被存储了所有配置，统计方面的和可操作数据的中央仓库，它是监控系统问题升级以致于激活警告管理器的zabbix中的实体。 基本的zabbix server分三个不同的组件：zabbix server，web前端，数据库存储。zabbix的所有配置信息都存储在服务器和web前端进行交互的数据库中。 zabbix server进程是以守护进程（Daemon）运行的。 Proxyzabbix proxy是一个可以从一个或多个受监控的设备设备收集监控数据，并将信息发送到zabbix server的进程，基本上是代表server工作。所有收集的数据都在本地进行缓存，然后传送到proxy所属的zabbix server。 zabbix proxy是完成远程区域、分支机构、没有本地管理员的网络的集中监控的理想解决方案。 zabbix proxy需要使用独立的数据库，以守护进程的方式运行。 Java gatewayzabbix守护进程原生支持监控JMX程序，它被称为zabbix java gateway。zabbix gateway是用Java语言写成。 要查得一台主机特定的JMX计数器值，zabbix server向zabbix java gateway发送请求，后者使用JMX管理API去请求远程的有关应用。应用不许额外安装软件，只需要启动时在命令行指定 -Dcom.sun.management.jmxremote即可（是在java程序）。 每个zabbix server或zabbix agent只能配置一个java gateway。 Senderzabbix sender是一种命令行应用，它可以将性能数据发送到zabbix server进行处理。该应用通常用在长时间运行的用户脚本，用于定期发送可用性和性能数据。 123456zabbix_sender -z zabbix -s &quot;xxx&quot; -k db.connections -0 43-z :server主机-s :受监控主机的技术名称-k :监控项的键-o :要发送的值 Getzabbix get也是一种命令行应用，用于与zabbix agent进行通信，并从agent那里获取所需的信息。该应用通常被用于zabbix agent故障排除 12345678zabbix_get -s $host -p xxx -k system.cpu.load[all,avg15]-s --host-p --port-I --source-address-k --key-h --help-V --version 安装ZabbixZabbix安装要求硬件： 内存，最小128MB； 磁盘，最小256MB； CPU，可能需要大量CPU资源； SMS(短信)通知服务，串行通讯口(serial communication port)和串口GSM调制解调器(serial GSM modem)。可选项。 支持平台： Linux; IBM AIX; FreeBSD; NetBSD; OpenBSD; Mac OS X; Solaris; Windows(Only Agent). 软件：Zabbix基于Apache Web服务器、领先的数据库引擎和PHP脚本语言进行构建。 数据库管理系统： MySQL 5.0.3 及以上； Oracle 10g 及以上； PostgreSQL 8.1 及以上； SQLite 3.5及以上； IBM DB2 9.7 及以上。 前端： Apache 1.3.12 及以上； PHP 5.4.0及以上； PHP-Extension: 软件 版本 备注 gd 2.0及以上 PHP GD扩展包必须支持PNG图片 bcmatch php-bcmatch ctype php-ctype libXML 2.6.15及以上 php-xml xmlreader php-xmlreader xmlwrite php-xmlwriter session php-session sockets php-net-socket mbstring php-mbstring gettext php-gettext ldap php-ldap mysqli 使用MySQL作为Zabbix后端数据库所需的组件 pgsql 使用PostgreSQL作为Zabbix后端数据库所需的组件 sqlite3 使用SQLite作为Zabbix后端数据库所需的组件 客户端浏览器：必须启用Cookie和JavaScript功能。 服务器： 要求 描述 OpenlPMI 支持IPMI功能所需组件 libssh2 支持SSH功能 fping 支持ICMP ping功能 libcurl 支持Web监控，VMware监控及SMTP认证 libiksemel 支持Jabber功能 libxml2 支持VMware监控 net-snmp 支持SNMP监控 Java网关：Java gateway编译和运行在Java 1.6 及以上版本。 数据库容量：Zabbix配置数据需要使用固定的磁盘空间，而这个空间不会过多增长。 Zabbix数据库容量主要依赖于以下参数： 每秒处理值的数量(Number of processed values per second); 历史(History)数据的回收清理设置(Housekeeper); 趋势(Trends)数据的回收清理设置(Housekeeper); 事件(Events)数据的回收清理设置(Housekeeper)。 时钟同步：对于Zabbix稳定运行而言，服务获取精确的系统时间是非常重要的。对于所有运行Zabbix组件的系统，强烈建议这些系统的时间保持同步。ntpd是一个临幸的用于同步主机和其他服务器之间的时间的后台程序。 安装、启动、配置ZabbixZabbix-repo仓库：repo.zabbix.com该仓库服务器同时提供yum和apt源码库。 配置源码库1. 从官方下载源码库 1234567#rpm -ivh http://repo.zabbix.com/zabbix/$version/rhel/7/$arch/$zabbix-release.rpmrpm -ivh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.centos.noarch.rpm#阿里云镜像#rpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.noarch.rpm#镜像失效的话自己去官网找 2. 手动配置zabbix.repo 1234567vim /etc/yum.repos.d/zabbix.repo[zabbix]name=Zabbix-Repobaseurl=http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/gpgcheck=0enable=1 安装Zabbix部署包使用MySQL数据库安装Zabbix Server、Web前端：1yum install -y zabbix-server-mysql zabbix-get 注意：此处Zabbix数据库使用MySQL，请自行安装MySQL。 安装Zabbix Agent：1yum install -y zabbix-agent 安装初始化数据库查看刚刚安装的 zabbix-server-mysql：解压得到的sql脚本create.sql只会在对应的数据库中初始化zabbix所需要的数据库表，但是不会创建zabbix数据库。所以后面我们还需要手动创建zabbix数据库。1234567rpm -ql zabbix-server-mysqlcd /usr/share/doc/zabbix-server-mysql-3.x.xx/#有一个create.sql.gz的压缩文件gunzip create.sql.gz#得到create.sql 在MySQL中创建zabbix数据库：12345678910111213141516171819msyql -uxxx -pmysql&gt;CREATE DATABASE 'zabbix' DEFAULT CHARACTER SET 'utf8';mysql&gt;SHOW DATABASES;mysql&gt;GRANT ALL ON zabbix.* TO 'zabbix'@'localhost' identified by 'zabbix';mysql&gt;FLUSH PRIVILEGES;#导入sql脚本mysql -uroot -p -Dzabbix &lt; ./create.sqlUSE zabbix;SHOW TABLES;#mysql限制IPvim /etc/my.cnf[mysqld]bind-address=127.0.0.1 配置zabbix server并启动编辑zabbix server配置文件：123456789101112131415161718192021vim /etc/zabbix/zabbix_server.conf#常会修改的参数#数据库配置DBHost=localhostDBName=zabbixDBUser=zabbixDBPassword=zabbixDBPort=3306DBSocket=/var/lib/mysql/mysql.sock#服务监听端口ListenPort=10051#服务端源IPSourceIP=#日志记录方式，file使用指定文件作为日志文件，system将日志发往syslog，console将日志发送控制台LogType=fileLogFile=/var/log/zabbix/zabbix_server.log 启动zabbix服务端：1234567891011121314systemctl start zabbix-server#此处可能由于没有关闭SELinux而报错tail /var/log/zabbix/zabbix_server.logcannot set resource limit: [13] Permission denied#关闭SELinuxsetenforce=0vim /etc/selinux/configSELINUX=disabled#查看zabbix-server默认监听的10051端口netstat -nltp 安装zabbix webzabbix web可以安装在单独的主机上，只要能连接到zabbix database所在数据库就行。但为了方便，都安装在了server上。 zabbix web需要LAMP环境：12345#可能需要自己配置PHP remi源，注意PHP及扩展版本问题yum install -y httpd php php-mysql php-mbstring php-gd php-bcmatch php-ldap php-xml#指定php版本#yum --enablerepo=remi-php56 install php-mysql php-mbstring php-gd php-bcmatch php-ldap php-xml 安装zabbix web所需的两个包：123456789yum install -y zabbix-web zabbix-web-mysql#此处默认使用php5.4#因为我的环境是php5.6,会报错#此时就需要指定php版本来安装yum --enablerepo=remi-php56 install zabbix-web zabbix-web-mysqlrpm -ql zabbix-web#zabbix-web位于/usr/share/zabbix/ 编辑zabbix的前端Apach-PHP配置文件zabbix前端的Apache配置文件位于 /etc/httpd/conf.d/zabbix.conf:1234567891011121314151617181920212223242526272829vim /etc/httpd/conf.d/zabbix.conf#需修改时区php_value max_execution_time 300php_value memory_limit 128Mphp_value post_max_size 16Mphp_value upload_max_filesize 2Mphp_value max_input_time 300php_value always_populate_raw_post_data -1php_value date.timezone Asia/Shanghai#建议顺便修改/etc/php.ini的时区vim /etc/php.inidate.timezone = Asia/Shanghai#添加httpd的虚拟主机访问zabbix web&lt;VirtualHost IP:80&gt;servername zabbix.medocumentroot /usr/share/zabbix默认数据&lt;/VirtualHost&gt;#开启httpd服务systemctl start httpd 添加hosts后就可以利用域名访问zabbix-web端了。 1echo -e "192.168.1.9 \t zabbix.me" &gt;&gt; /etc/hosts 在web端配置zabbix在浏览器访问 http://zabbix.me 初始化zabbix配置。配置好后就需要用账号密码进行登录zabbix-web端dashboard。 默认用户名是：admin，密码是配置文件里面设置的。 登录进Dashboard后，可修改语言为中文。 如果你的Zabbix无法看到中文选项，那么可能需要如下操作：1234vim /usr/share/zabbix/include/locales.inc.php#修改'zh_CN' =&gt; ['name' =&gt; _('Chinese (zh_CN)'), 'display' =&gt; true], 如果又遇到中文乱码的问题，则可以从windows中挑选一些好看的中文字体，将对应字体文件放置到zabbix web的字体目录中。windows中字体后缀.TTF，Linux中为.ttf。注意修改大小写。123456789101112131415cd /usr/share/zabbix/fonts#只有一个默认字体 graphfont.ttf#将新字体放置到此目录下#修改配置文件中对应字体名称vim /usr/share/zabbix/include/define.inc.php#将默认字体名字修改为字体目录下 你需要的字体名define('ZBX_FONT_NAME', 'graphfont');define('ZBX_GRAPH_FONT_NAME', 'graphfont'); // font file name#栗子，如perpetua字图PER.ttfdefine('ZBX_FONT_NAME', 'PER');define('ZBX_GRAPH_FONT_NAME', 'PER'); // font file name 图形显示乱码，同样是用以上方法。在windowss上找一个中文字体上传到zabbix字体目录，并修改配置文件就可以了。 Zabbix Web界面菜单： 管理菜单，用于管理zabbix自身及zabbix相关设置； 配置菜单，用于配置监控相关设置； 报表菜单，为管理员生成一段时间内的监控统计信息； 检测中菜单，用于查看被监控的相关数据； 资产记录菜单，查看被监控的主机有哪些，以及相关的资产信息。 安装zabbix agentAgent端安装也非常方便，直接在Client上安装两个包即可。 123456789101112#配置zabbix源rpm -ivh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.centos.noarch.rpm#aliyun镜像#rpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.noarch.rpm#安装yum install -y zabbix-agent zabbix-senderrpm -ql zabbix-agent#/etc/zabbix/zabbix_agentd.conf zabbix的“主动模式”与“被动模式”都在/etc/zabbix/zabbix_agentd.conf中定义。配置最常用的agent端：12345678910111213141516171819202122232425262728293031vim /etc/zabbix/zabbix_agentd.conf####GENERAL PARAMETERS 通用配置PidFile=LogFile=####Passive checks related 被动模式配置#指定允许哪台服务器拉取本机数据Server=#指定agent端工作于被动模式时监听的端口号ListenPort=10050(默认)#指定agent端工作与被动模式时所监听的IP地址ListenIP=0.0.0.0(默认)#指定预生成的agent进程数量StartAgents=####Active checks related#agent工作于主动模式时，将消息推送到哪台Server上ServerActive=IP1,IP2...#指定当前主机主机名，Server端通过对应的主机名识别主机Hostname=#指明agent端每隔多少秒将采集的数据发往Server端RefreshActiveChecks=#栗子Server=192.168.1.9ServerActive=192.168.1.9Hostname=zabbix.me 启动zabbix-agent1234systemctl zabbix-agent start#查看状态,默认端口10050netstat -nltp 快速开始zabbix-web菜单zabbix-web界面中包含有监测中、资产记录、报表、配置、管理五项菜单。 登录和配置用户在浏览器输入 zabbix.me (修改hosts)，登录zabbix-web后台。 默认用户名：Admin，密码：zabbix。它是超级管理员。 为了防止暴力破解和词典攻击，连续尝试五次登录失败，zabbix界面将暂停30秒。 可以通过管理(Management)菜单下的用户(User)，新建、查看、管理用户信息。 zabbix在安装后自定义了两个用户： Admin用户是zabbix的超级管理员，拥有所有权限； Guest用户是一个特殊的默认用户。如果你没有登录，你访问zabbix的时候其实就是“guest”权限。guest默认没有任何权限。 你可以创建一个用户(user)并将其加入特定的用户组(Group)以提升用户权限。 可以仅用用户信息里面-报警媒介里面，自定义严重性的报警。只有勾选部分的报警信息才会发送过来。这也很棒！ 如果存在严重性则使用： [ ] Not classified [ ] Information [ ] Warning [ ] Average [ ] High [ ] Disaster 新建主机zabbix中的主机(host)是一个你想要监控的网络实体(物理的、虚拟的)。对于主机的定义非常灵活。它可以是一台物理服务器，一个网络交换机，一个虚拟机或一些应用。 可以通过配置(Configuration)菜单下的主机(Host)，查看已配置主机相关信息。默认有一个“Zabbix Server”的定义好的主机。 点击创建主机(Create host)后，填写对应的主机名称、添加对应的主机群组，zabbix-agent的IP地址和端口，以及其它信息。 新建监控项监控项是zabbix中获得数据的基础。没有监控项，就没有数据。因为一个主机中只有监控项定义了”单一的指标“或者”需要获得的数据“。 可以通过配置(Configuration)菜单下的主机(Item)，找到需要配置监控项(Item)的主机，然后创建监控项。主机默认是没有定义任何监控项的。 填写对应的监控名称、类型、键值、主机接口、信息类型等等信息。 可在监控(Monitoring)菜单中最新数据(Latest data)查看之前定义的监控项和获得的值。还可选择以图形(Graph)或值来查看监控项的相关信息。 同样也还以在Zabbix-Server端获得数据信息：12#zabbix_get -s $ip -k $valuezabbix_get -s 192.168.1.9 -k system.cpu.load 新建触发器监控项只用于收集数据。如果要自动评估收到的数据，我们则需要定义触发器(trigger)。触发器包含了一个表达式，这个表达式定义了数据的可接受的阈值级别。 如果收到的数据超过了定义好的级别，触发器将被触发，或者进入异常状态(problem)。从而引起我们的注意，让我们知道有问题发生。如果数据再次恢复到合理范围，触发器将会转到正常状态(OK)。 可以通过配置(Configuration)菜单下的主机(Hosts)选项，找到某主机的触发器(Triggers)创建触发器。 填写对应的触发器名称、表达式、描述等信息。 获取问题通知当监控项收集了数据后，触发器会根据异常状态触发报警。根据一些报警机制，它也会通知我们一些重要的事情，而不是直接在zabbix-web端进行查看。这就是通知(Notification)的功能。E-mail是最常用的异常通知发送方式。当然还有SMS（短信），脚本等媒体类型。 可以通过管理(Administration)菜单中的报警媒体类型(Media types)，点击预定义媒体类型列表中的Email，来配置Email。 为了建立一个通知，我们需要在配置菜单下动作中，创建动作(Create action)。 一旦满足了触发器的条件，变回触发执行动作。如收到E-mail等… 新建模板如果我们配置上前台主机，一些自动化操作会带来更多便利性。没错，模板(templates)功能就可以实现。模板允许对有用的监控项、触发器和其他对象进行分组，只需要一步就可以对监控主机应用模板，已达到反复重用的目的。 当一个模板链接到一个主机后，主机会继承这个模板中的所有对象。简单而言，一组预先定义好的检查会被快速应用到主机上。 Zabbix为各种操作系统、设备以及应用准备好了一些预定义的模板。你可以快速部署使用他们。但是请注意，一些模板需要根据你的实际情况和使用环境进行适当俄调整。 比如，一些检查项是不需要的，一些轮询周期过于频繁等。 在配置菜单下的模板(Templates)下，点击创建模板(Create template)。填写对应的模板名称，群组等信息。 创建模板完毕后，可将模板链接到主机。之后，模板及其所有对象被添加到了主机。 配置(Configuration) 主机和主机组(Hosts and groups)一般来讲，zabbix主机是指你希望监控的那些设备。如服务器、工作站、交换机等。创建主机是使用zabbix过程的首要任务。 我们可以把主机组想象成项目组。根据不同的功能将主机划分到主机组是非常重要的，这样可以对以后创建的用户和用户组在定义权限的时候，不用给他们zabbix admin权限，而只需要根据主机组(项目组)给予用户和用户组对应项目(主机组)的权限即可。这样很大程度上方便了Zabbix监控多个项目，也利于管理。同样，报警的时候也只会收到权限内的相关报警信息。 配置一台主机配置—主机—创建主机—填写相关参数信息。 可以在已经存在的主机上使用 Clone或Full Clone创建一个新主机。 Clone将保留所有的主机参数和模板链接；Full Clone将额外保留指数实体(应用集、监控项、触发器、视图、规则、Web场景)。 新建主机下： 主机(Host)：包含了通用的主机属性； 模板(Template)：允许将模板链接诶到主机，所有实体将从模板继承； IPMI：包含IPMI管理属性； 宏(Macros)：允许定义主机级别的用户宏； 主机资产记录(Host inventory)：允许为主机收工输入库存信息； 允许你请求与主机的加密的连接。 资产管理(Inventory)你可以将联网设备的资产信息保存在zabbix里。资产信息实在配置主机时人工录入建立的资产信息数据，或者通过使用某些自动填充选项完成的录入。 构建资产库： 手动模式： 在配置一台主机的时候，手动输入资产信息； 自动模式： 在配置主机的时候，选择自动。 之后便可以在资产记录菜单中的概述，主机项中查看相关信息。 批量更新(Mass update)有时候可能需要一次更改多个主机的某些属性，使用批量更新(mass update)功能来代替打开每个主机进行编辑。 可批量处理主机、模板、IPMI、资产、加密相关信息。 监控项(Items)监控项是从主机收集的数据信息。配置主机后，需要添加一些监控项以开始获取数据。快速添加多个监控项的一种方法是将预定义的模板附加到主机。 在单个监控项中，可指定从主机收集哪些数据信息。为此，可使用监控项key。 如system.cpu.load将收集处理器负载的数据。要给 key 指定更过参数，请在后面添加方括号[]。 如system.cpu.load[avg5]， 返回最近5分钟的CPU负载平均值。 创建一个监控项可在主机中新建一个监控项。不支持的监控项：如果由于某种原因无法检索该值，则该监控项可能不被支持。这些监控项仍然以固定的间隔重新检查。 监控项的key: key名称允许使用字符： 0-9a-zA-Z_-. key参数，用 逗,号 分隔： xxx[par1,par2…] key参数也可以为空，此时使用默认值： key key参数带引号，则允许任何Unicode字符，如果包含双引号则需要 \反斜杠 转义 key参数是一个数组，它需要包含在方括号中 自定义间隔(Custom intervals) 创建关于监控项的自定义时间规则。灵活间隔被设计为重新定义默认监控项的的更新间隔，但调度间隔用于指定独立执行的检查计划。 灵活的间隔(Flexible intervals)：允许重定义特定时间段的默认间隔。 间隔(Interval)： 指定时间段的更新间隔； 期间(Period)： 灵活间隔有效的时间段； 举个栗子： 60(interval), 1-7,00-24(period)。监控项每隔60s检查一次。 调度间隔(Scheduling intervals)：用于在特定时间检查监控项。 调度间隔定义为， md&lt;filter&gt;wd&lt;filter&gt;h&lt;filter&gt;m&lt;filter&gt;s&lt;filter&gt;。 md: month days(1-31) wd: week days(1-7) h: hours(0-23) m: minutes(0-59) s: seconds(0-58) : 指定其前缀的值——[from-to/step]。 其实类似于Linux中定时任务的写法，只不过这里把单位(md,wd,h,m,s)写在了数值的前面。 举个栗子： 123456789101112md1-15 #1-15号wd3 #星期三h0-12 #上半天m1,3,5,7,9 #每个1,3,5,7,9分钟s/10 #每个10s#组合体wd1-5h9-18m/10 #每个工作日的上班时间每个10分钟 监控项类型(Items type)监控项类型包含从系统获取数据的多种方式。每个监控项类型都有一组自己支持的监控项key和所需的参数。 zabbix提供的监控项类型： zabbix代理检查(agent checks) SNMP代理检查 SNMP traps IPMI检查 简单检查(simple checks) VMware监控(monitoring) 日志文件监控 计算监控项(Calculated items) zabbix内部检查(internal checks) SSH检查 Telnet检查 外部检查(External checks) 汇总检查(Aggregate checks) 捕捉器监控项(Trapper items) JMX监控 ODBC监控 zabbix代理(zabbix agent)：这些检查与zabbix代理进行通信实现数据的采集。 zabbix agent-passive： 被动模式，Server向Agent索要数据； zabbix agent-active： 主动模式，Agent主动上报数据给Server。 可支持的监控项，可在新建监控项是在键值里面查看。 SNMP代理(SNMP agent)： 在启用SNMP的设备(如打印机，交换机，路由器…)上使用SNMP监控，为了能够监控SNMP代理在这些设备上提供的数据，zabbix服务器初始化配置时必须具有SNMP支持。仅通过UDP协议执行SNMP检查。 配置SNMP监控： 使用SNMP接口为设备创建一个主机； 找出要监控项目的SNMP字符串； 创建一个监控项。 IPMI检查： 你可以在zabbix中监控 智能平台管理接口(IPMI) 设备的运行状况和可用性。要执行IPMI检查，zabbix服务器必须首先配置IPMI支持。 简单检查： 简单检查通常用于远程无代理监控服务。 日志文件监控： zabbix可用于集中监控和分析 具有/不具有 日志转动能力的日志文件。当日志文件包含某些字符串或字符串模式时，通知信息可用于警告用户。 计算监控项： 计算监控项是创建虚拟数据源的一种方式。这些值将根据算术表达式定期计算。所有计算都由Server完成。 内部检查：内部检查可以监控zabbix的内部检查。即Server或Agent Server的运行情况。 SSH检查： 运行SSH检查是作为无代理监控的，SSH检查不需要zabbix代理。执行SSH检查zabbix服务器必须初始化配置为SSH2支持。 SSH检查提供两种身份验证方法，一种是用户/密码，另一种是基于密钥文件。 zabbix SSH 密钥配置: 1234567891011vim /etc/zabbix/zabbix_server.conf#SSHKeyLocation=SSHKeyLocation=/home/zabbix/.sshusermod -m -d /home/zabbix zabbixchown zabbix:zabbix /home/zabbixchmod 700 /home/zabbixcd /home/zabbix &amp;&amp; su zabbixssh-keygen -t rsa 外部检查： 外部检查是由zabbix Server通过运行shell脚本或二进制的检查。外部检查不需要再被监控的主机上运行任何代理。 汇总检查： 在汇总检查中，zabbix通过直接从数据库中查询监控信息，然后进行信息聚合。聚合检查不需要再被监控的主机上运行任何代理。 捕捉器监控项： 捕捉器监控项接收传入的数据，而不是查询它。对于想要推送到zabbix的任何数据都是适用的。 要使用捕捉器监控项，需要在zabbix中建立一个捕捉器监控项，将数据送给zabbix。 JMX监控项： JMX监控可用于监视Java应用程序的JMX计数器。JMX监视器以zabbix守护进程方式运行，名为zabbix java gateway。 ODBC监控： ODBC监控对应于zabbix web管理端中的数据库监控器监控项类型。ODBC是用于访问 数据库管理系统(DBMS) 的C语言中间件API。 zabbix可以查询ODBC支持的任何数据库。为了实现监控，zabbix不直接连接到数据库，而是使用ODBC中设置的ODBC接口和驱动。该功能允许为多个目的更加有效地监控不同的数据库。 历史与趋势(history and trends)历史与趋势是zabbix中存储数据的两种方式。历史保持每个收集的值，而趋势是每小时的平均信息。 建议保持的历史数据尽可能少，但可以保留更多的趋势数据。 用户自定义参数(user parameter)有时你想运行一个代理检查，但它不是zabbix预定义的。这时就能用到用户参数。用户参数是由zabbix代理之星的命令，最多可以返回512KB的数据。key 是唯一的。 用户参数用法： 12345678910111213141516171819202122UserParameter=&lt;key&gt;,&lt;command&gt;#栗子UserParameter=ping,echo 1#使用ping键为一个监控项返回 1#复杂栗子UserParameter=mysql.ping,mysqladmin -uroot -ppwd ping | grep -c 'alive'#mysqld状态为alive返回1，否则0#灵活的用户参数UserParameter=key[*],command#[*]定义该key接受括号内的参数#栗子UserParameter=ping[*],echo $1UserParameter=mysql.ping[*],mysqladmin -u$1 -p$2 ping | grep -c 'alive'#mysql.ping[zabbix,passwd]UserParameter=wc[*],grep -c "$2" $1#wc[/etc/passwd,root] 用户自定义参数扩展zabbix代理：是将key添加到被监控的主机哦！123456789101112131415161718#编写命令--SQL查询总数mysqladmin -uxxx -pxxx status | cut -f4 -d":" | cut -f1 -d"S"#将命令添加到zabbix_agentd.confvim /etc/zabbix/zabbix_agentd.conf#找到如下字段### Option: UserParameterUserParameter=mysql.totalquery,mysqladmin -uroot -pxxx status | cut -f4 -d":" | cut -f1 -d"S"#mysql.totalquery这个key是唯一的标识符#测试此参数##测试参数可用与否很重要哈zabbix_agentd -t mysql.totalquery#重启zabbix-agent，将重新加载配置zabbix_get -s $host -k mysql.totalquery 可加载模块(loadable modules)可加载模块提供了一种关于zabbix性能扩展的选项。 可加载模块基本上只zabbix守护程序使用的共享库，并在启动时加载。可加载模块具有很多优点，卓越的性能和可实现任何逻辑的能力，更重要的是使用和共享了zabbix模块的开发能力。 windows性能计数器(windows perfomance counter)使用perf_counter[]key有效的监控windows性能计数器 批量更新(mass update)使用批量更新功能，可一次更改多个监控属性。 值映射(value mapping)对于接收值更人性化的表示，可以使用包含数值和字符串之间的映射的值映射。 如： 0 —-&gt; error 1 —-&gt; true F —-&gt; Full D —-&gt; Differential I —-&gt; Incremental … 应用集(Application)应用集对逻辑组中的监控项进行分组。 如，对MongoDB的可用性，空间，负载，慢查询，执行命令…，可归于 MongoDB应用于中。 队列(queue)队列显示正在等待刷新的监控项。队列只是一个逻辑表达的数据。 队列显示的统计信息是zabbix服务器性能是否健康的指标。在 管理—队列 下对去队列。 值缓存(value cache)为了计算触发表达式，以及让计算/聚合监控项和一些宏更快，zabbix服务器支持值的缓存选项。 在内存中的缓存可用于访问历史数据，而不用之间调用数据库。如果缓存中不存在历史值，则从数据库请求缺少的值，并相应地跟新缓存。 要启用值缓存功能，修改zabbix_server.conf中可选的ValueCacheSize参数。 触发器(Trigger)触发器是评估有项目采集的数据并表示当前系统状况的逻辑表达式。触发器表达式允许定义一个什么状况的数据是“可接受”的阈值。如果超过了可接受状态，则触发器会被触发。 配置一个触发器(configuring a trigger)在主机里面配置触发器。 触发器表达式(trigger expression)一个简单有效的表达式看起来像： 1234&#123;&lt;server&gt;:&lt;key&gt;.&lt;function&gt;(&lt;parameter&gt;)&#125;&lt;operator&gt;&lt;constant&gt;#如&#123;192.168.1.7:agent.ping.time()&#125;=0 函数参数(function parameters)： 大多数数字型的函数接受秒数来作为参数。 1234567891011121314#600s内所有值的总和sum(600)#随后5个值总和sum(#5)avg()count()last()min()max()#5m 可被 300s 代替#1k 代表 1024bytes 运算符(operators)： 优先级 运算符 定义 1 - 负号(minus) 2 not 逻辑非(NOT) 3 *, / 乘，除 4 +, - 加，减 5 &lt;, &lt;=, &gt;, &gt;= - 6 =, &lt;&gt; 相等，不等于 7 and 逻辑与 8 or 逻辑或 触发器示例： 12345678910111213&#123;www.zabbix.com:system.cpu.load[all,avg1].last()&#125;&gt;5&#123;www.zabbix.com:system.cpu.load[all,avg1].last()&#125;&gt;5 or &#123;www.zabbix.com:system.cpu.load[all,avg1].min(10m)&#125;&gt;2&#123;www.zabbix.com:net.if.in[eth0,bytes].min(5m)&#125;&gt;100k&#123;$url1:net.tcp.service[smtp].last()&#125;=0 and &#123;$url2:net.tcp.service[smtp].last()&#125;=0&#123;$host:icmpping.count(30m,0)&#125;&gt;5&#123;$host:system.cpu.load[all,avg1].min(5m)&#125;&gt;2 and &#123;$hsot:system.cpu.load[all,avg1].time()&#125;&gt;000000 and &#123;$host:system.cpu.load[all,avg1].time)()&#125;&lt;060000... 滞后(Hysteresis): 有时候需要一个触发器状态OK和PROBLEM之间的间隔，而不是简单的阈值。 要做到这一点，我们首先定义一个PROBLEM事件的触发器表达式，然后为OK选择 ‘Recovery expression’，并未OK事件书如不同的表达式 如： 1234567#Problem expression&#123;server:temp.last()&#125;&gt;20#Recovery expression&#123;server:temp.last()&#125;&lt;=15#两者之间便有了几个滞后值 触发器依赖(trigger dependency)有时候，一台主机的可用性取决于另一台主机。如一台路由器后的上网设备。这就是主机之间某些依赖关系可能有用的地方，依赖关系设置的通知可能会被抑制，而只发送根本问题的通知。 zabbix中触发器的依赖，一个触发器可能有多个依赖于它的触发器。 路由器和路由器后的Server同时宕机，如果有依赖关系，则zabbix不会执行服务器的触发动作。值得注意的是，如果触发器所依赖的触发器被禁用，则次触发器的事件和动作将不会被抑制。 批量更新使用批量更新，可一次更改一些触发器的某些属性。 触发器严重性(trigger severity)触发器严重性定义了触发器的重要程度: 未分类(not classified), 灰色 信息(information), 淡蓝 警告(warning), 黄色 一般严重(average), 橙色 严重(High), 淡红 灾难(disaster), 红色 自定义触发器严重性(customising trigger)在 管理 — 一般 — 触发器严重性，里面自定义触发器严重性。 预测触发功能(predictive trigger function)有时候有即将到来的问题的迹象。可以发现这些迹象，以便提前采取行动，以减小影响。 zabbix具有基于历史数据预测受监视系统的未来行为的工具，这些工具通过预测触发功能实现。 事件标签(event tag)在zabbix中可以自定义事件标签，在触发器级别上定义事件标签。在事件标签定以后，相应的新事件被标记为时间标签数据。在拥有自定义时间标签的情况下，可以变得更加灵活。 例如： 识别日志文件中的问题并单独关闭他们； 用它来过滤通知； 查看前端的事件标签信息； 从项目值中提取的信息作为标签值； 在通知中更好地识别问题； 通过使用模板级别的标签来建华配置任务； 使用低级别发现的标签创建触发器。 事件(Events)zabbix可以生成一下几种类型的事件： trigger events-触发器事件； discovery events-发现事件； auto registration events-自动注册事件； internal events-内部事件； 事件以时间戳，并可以发送Email等基础动作。在 监控-问题 里面查看信息信息。 触发器事件生成(trigger events generation)触发器状态的变化是事件最常见和最重要的来源。每次触发器的状态改变时，都会生成一个事件。改时间包含了触发器状态变更的详细信息、发生时间以及信息的状态。 触发器会创建两种类型的事件：问题(problem)和正常(OK) 手动关闭问题事件(manual closing of problems)当触发器状态从“问题(problem)”变成“正常(OK)”时，很难判断是通过触发器表达式的方式解决。这时就需要手动解决。 只有在触发器中启用 “允许手动关闭” 选项，问题事件才可以被手动关闭。 其他事件来源(other event source)zabbix定期扫描网络发现规则中定义的IP范围，可以为每个规则单独配置检查频率。一旦发现主机或服务，就会生成一个发现事件。 zabbix可以生成以下事件： 1234Service Up/DownHost Up/DownService Discovered/LostHost Discovered/Lost 事件关联(event correlation)通常，在zabbix中正常事件会关闭所有的问题事件，但在某些情况下需要更细致的方法。可以根据事件标签关联问题事件。如，当监控日志文件时，在日志文件中想要发现某些问题，并将它们单独关闭，而不是一起关闭。 可视化(visualisation)图形(graphs)大量的监控数据被采集到zabbix中，如果能用可视化的表现形式来查看，那就直观和容易多了。 zabbix为用户提供了如下图形： 监控项数据的内置简单图形 “simple graphs”； 创建更复杂的自定义图形 “customised graphs”； 特定图形 “ad-hosc graphs”快速访问几个监控项的数据比较。 简单图形(simple graphs)：zabbix提供的简单图形，用来可视化显示监控项采集到的数据。并不需要配置就可以查看。 通过 监控-最新数据-图形 来展示图形。 自定义图形(customised graphs)：自定义图形，提供定制功能。这就有点厉害了。这个是手动配置的。可以为单个主机、多个主机、单个模板、多个模板创建自定义图形。 在 配置-主机-图形-创建图形 里编辑图形属性；图形编辑后可点击预览。 特设图形(ad-hoc graphs)：简单图形和自定义图形都不允许快速创建多个监控项目数据的比较图形，工作量小且没有维护。 在 检测-最新数据-旋转监控项前复选框-显示数据图(显示堆叠数据图) 下， 里面也包含了 正常和层积 的图形风格。 拓扑图(networking maps)运维人员如果想要了解网络环境的基础设施状况，可以在zabbix中创建网络拓扑图。 配置拓扑图(configurating network maps): 在 监控-拓扑图 下，可以创建拓扑图。点击拓扑图中的 构造函数 选项，来打开编辑区域。然后在编辑区域中添加元素和链接元素。 链接指示器(link indicators):可以为网络拓扑图中的元素之间的链接分配一些触发器，当这些触发器状况为“Problem”时，可以在链接上体现出来。如果多个触发器进入”Problem”状态，则严重程度最高的将决定链接的颜色和样式。 聚合图形(screen)在zabbix的聚合图形页面上，你可把各种来源的信息聚集到一起，一边在单个屏幕上快速查看。在 监测-图形聚合 下，对其进行创建、配置、管理和查看。 基本上，聚合图形是一个表格，你选择把每个表格有多少单元格以及其中要显示的元素。元素如下： 简单图形； 简单图形原型； 用户自定义图形； 自定义图形原型； 拓扑图； 其他聚合图形； 纯文本信息； 服务器信息； 触发器信息； 主机/主机组信息； 系统状态； 数据概述； 时钟； 事件历史； 动作历史； URL。 幻灯片演示(slide shows)在幻灯片演示中，可以配置多个聚合图形以设定的间隔逐个显示。在 监测-聚合图形-幻灯片演示 下。 模板(template)模板是可以方便地应用于多个主机的一组实体。 配置模板(configuring a template)：配置模板需要首先通过定义一些参数来创建模板，然后添加实例。在 配置-模板-创建模板 链接模板(linking)：链接是将模板应用于主机的过程，之后主机将拥有模板的所有实体。 嵌套(nesting)：嵌套是一种包含一个或多个其它模板的模板方式。可以在一个嵌套模板中奖一些模板链接在一起。 嵌套的好处在于，您只需要讲一个模板链接到主机，并且主机会自动继承链接的模板的所有实体。 事件通知(notifications upon events)当配置了一些项目和触发器，并且由于触发器改变状态，现在正在发生一些事件，之后就要考虑 action。发送通知是zabbix提供的主要操作之一。 为了能够发送和接收通知，必须： 定义一些media； 配置action，向指定的media发送消息。 action由condition和operation组成。当条件满足是，执行操作。操作主要是 发送消息和执行远程命令。 media类型媒体是zabbix中发送通知和警报的传送通道。 E-mail: 在 管理-媒体类型 下，配置Email。 SMS： zabbix支持使用连接到zabbix-server的串行端口的串行GSM调制解调器发送SMS消息。 确保： 串行设备的速度(在Linux下通常为/dev/ttyS0) 与 GSM调制解调器的速度相匹配。zabbix没有设置串行链路的速度，它使用默认设置。 zabbix用户对串行设备有读写访问权限。 GSM调制解调器输入PIN码，并在电源复位后保留PIN码。或者在SIM卡上禁用PIN。 管理-媒体类型下要为用户分配电话号码：管理-用户-报警媒介，添加报警媒介(如电话号码等) Jabber： zabbix支持发送jabber消息。 Ez Texting： 可以使用 zabbix技术合作伙伴 Ez Texting发送信息。 脚本： 警报脚本在zabbix服务器上执行，这些脚本位于服务器配置文件中定义的目录中(AlertScriptsPath)。123456789101112131415161718cat /etc/zabbix/zabbix_server.confAlertScriptsPath=/usr/lib/zabbix/alertscripts#创建报警脚本vim /usr/lib/zabbix/alertscripts/zabbix_test.sh#!/bin/bashto=$1subject=$2body=$3#可以同时给多个用户发送，用空格隔开cat &lt;&lt;EOF | mail -s &quot;$subject&quot; &quot;to&quot;$bodyEOF 然后我们在创建脚本媒体的时候，写入相关参数。 actions可以根据所有支持的类型的时间定义操作： 触发事件：当trigger的状态从OK转到Problem或回转时； 发现事件； 自动注册事件； 内部事件； 配置-动作-创建动作 条件(condition)只有在事件与定义的条件匹配的情况下才执行操作。 注意运算类型：似与非似 操作(operation)操作：发送信息，执行远程命令。 发送消息远程命令(不支持在zabbix-agent上执行远程命令，需要在zabbix-server到代理的命令才能直接连接。远程命令限制255字符，可以将过个命令放置于新行上来执行过个命令。及时目标主机处于维护状态，也会执行远程命令). 配置-动作-操作，在操作细节中修改操作类型为远程命令。 在Zabbix代理（自定义脚本）上执行的那些远程命令必须首先在相应的命令中启用 zabbix_agentd.conf.确保 EnableRemoteCommands 参数设置为 1 并取消注释。 如果更改此参数，请重新启动代理守护程序。 123456789101112vim /etc/zabbix/zabbix_agentd.confEnableRemoteCommands=1cd /usr/lib/zabbix/alertscripts#或修改zabbix-server.conf中的文件位置vi sendmail.shchown zabbix.zabbix ./sendmail.sh &amp;&amp; chmod a+x ./sendmail.sh 接下来在动作中选择为执行远程命令，并在相应位置输入命令。 支持自定义脚本、SSH、Telnet等方式。 在信息中使用宏(using macros in messages)：在消息主题和消息文本中，可使用宏来更有效的问题报告。 恢复操作(recovery operation):恢复操作允许在问题解决时通知我们。恢复操作支持消息和远程命令。 宏(macros)官方支持的宏的完整列表：https://www.zabbix.com/documentation/3.4/manual/appendix/macros/supported_by_location zabbix支持许多在多种情况下使用的宏。宏是一个变量，由如下特殊语法标识。 宏类似于全局变量，宏是特别有用的，特别是在报警动作中。对于不同的细节加上特定的宏，能够使报警信息更加详细。 {MACRO} 根据在上下文汇总，宏解析为一个特殊的值。有效地使用宏可以节省时间，并使zabbix更加高效。 宏可以在监控项键值参数中使用。宏只能用在监控项键值参数的一部分中。如item.key[server_{HOST.HOST}_local] 。 宏函数(macro function)宏函数能提供自定义宏值的功能。 宏函数语法：12345678&#123;&lt;macro&gt;.&lt;func&gt;(&lt;params&gt;)&#125;#&lt;macro&gt;, 要定义的宏#&lt;func&gt;, 要应用的函数#&lt;params&gt;, 以逗号分隔的函数参数列表#栗子&#123;&#123;ITEM.VALUE&#125;.regsub&#123;pattern, output&#125;&#125; 用户宏(user macro)除了支持开箱即用的宏之外，zabbix还支持更灵活的用户宏。 用户宏可在全局、模板和主机级别进行定义。有一个特殊语法：1&#123;$MACRO&#125; 用户宏可用于： 监控项名称； 监控项键值参数； 触发器名称和描述； 触发器表达式参数和常量； 许多其他位置。 自动发现宏(LLD)有一种自动发现(LLD)函数中使用的宏类型，可用于创建监控项、触发器和图形原型。然后，当发现真实的文件系统、网络接口等，这些宏将替换为真实的值，并且以这些值来创建真实的监控项、触发器和图形。1&#123;#MACRO&#125; 用户和用户组(user and group)zabbix中所有用户都通过web前端去访问zabbix应用程序。并为每一个用户分配唯一的登录名和密码，被加密储存于zabbix数据库中。 配置用户(configuring user)管理-用户，创建和管理用户。 权限(permission)可定义相应的用户类型，如用户，管理员和超级管理员。 用户组(groups)管理-用户组，创建和配置用户组。 服务监控(service monitoring)服务监控，旨在帮助那些想要高级业务监控的人。在很多情况下，我们关注的不是底层细节，而是提供的可用性服务。 服务是分层表示监控数据。 IT Workstations workstation1workstation2 Services 配置-服务，最高节点的服务是’root’。你可以通过添加低级服务节点和各个节点服务创建下层层次结构。 Web监控(web monitoring)配置-主机-web监测，创建或修改web监测信息。可使用zabbix检查几个网站可用性方面。(zabbix中包含libcurl库才行) 要使用web监控，需要定义web场景。包括一个或多个HTTP请求或步骤。Zabbix-Server根据预定义的命令周期性的执行这些步骤。 Web监测中的要求的字段(required string)支持正则表达式，所以这对于检索页面信息很有用。这个真的很有用！ 所有web场景会收集下列数据： 整个场景中所有步骤的平均下载速度； 失败的步骤数量； 最后一次错误信息 web场景的所有步骤，都会收集下列数据： 平均下载速度； 响应时间 HTTP状态吗 Web监控项(web monitoring items)在创建web场景时，会自动添加一些新监控项进行监控。 创建场景后，zabbix会自动添加以下监控项进行监控，将它们链接到所选的应用程序。 场景的下载速度； 场景的失败步骤； 场景的最后一个错误消息； 举个栗子：1234567891011121314151617181920212223242526272829303132333435363738394041##创建Web监测#配置-主机-Web监测-创建web监测URL：web.zabbix.me/monitor.php要求的状态码：200超时：20s##创建web监测触发器#配置-主机-触发器-创建触发器严重性：一般严重#触发条件：状态码!=200表达式：N&lt;&gt;200##创建触发报警对应的动作#配置-动作-创建动作#触发条件触发器示警度=一般严重 or 触发器=web.zabbix.me#操作：发送Email发送给zabbix administrator用户群组仅送到Email默认信息/自定义信息##在媒体类型中定义Email相关信息#管理-报警媒体类型-EmailSMTP服务器：smtp.xxx.comsmtp端口：465SMTP电邮：发件人Email安全链接：SSL/TLS认证：Usernameand passwd用户名：xxx密码： xxx##接下来就可以测试接收报警Email了 虚拟机监控(VM monitoring)zabbix支持对VMware的监控，使用low-levle-discovery(LLD)自动发现VMware hypervisors和虚拟机，并根据事先定义的主机原型，为这些虚拟机建立主机，添加监控。 zabbix中提供了几个模板，可以直接用来解控VMware vCenter 或 ESX hypervisor。 虚拟机监控分为两个步骤： 首先，zabbix是通过VMware collector进程来监控虚拟机。这些进程通过SOAP协议从VMware服务获取必要的信息，对其进行预处理并储存到zabbix-server共享内存中； 然后，zabbix-pollers通过zabbix简单检查VMware keys来检索这些数据。 要使虚拟机监控正常工作，需要libxml2库和libcurl库的支持。 配置-自动发现-创建自动发现配置-主机-自动发现 维护(maintenance)可在zabbix中为主机和主机组定义维护周期。有两种维护类型：“继续对目标进行监控数据的收集” 和 “停止对目标进行监控数据的收集” 要在维护期间正常接收问题通知，必须在动作配置中的选项中取消选择暂停操作。为了确保定期维护按照预期的时间进行，需要对zabbix的所有部分使用通用时区。 配置-维护-创建维护期 维护期的主机显示的是橙色背景！ 事件确认(event acknowledgment)zabbix中的问题事件可以由用户确认。 如果用户获得了有关问题时间的通知，可以访问zabbix前端，从时间导航到确认屏幕并确认问题。当他们确认时，可输入评论或其他一些相关描述。这样其他系统用户同样的问题，他们便会立即看到是否已被解决和目前的评论。 以这种方式，可以更协调的进行解决多个系统用户的问题的工作流程。 要确认事件，用户必须至少要有对相应触发器的读取权限。 在Dashboard下，在出现的问题里，点击确认，进入确认事件。也可在监控-问题下查看问题详细信息。 配置导出/导入(Configuration export/import)zabbix导入/导出功能，使得可以在一个zabbix系统与另一个zabbix系统之间交换各种配置实体。类似于数据库的导入导出。即也可以对zabbix做备份。 可导出/导入的对象有：主机组； 模板； 主机； 拓扑； 图片； 聚合图形； 值映射。 数据也可导出： XML - 在前端 XML or JSON - 在zabbix API 导出的详细信息： 所有支持的元素都导出到一个文件中； 不导出从连链接模板继承的主机和模板实体； 由低级别发现创建的实体依赖于他们的任何实体不会导出。 导入详细信息： 第一次遇到错误停止导入； 导入支持XML和JSON文件； 使用“删除缺失”选项导入主机/模板时，导入的XML文件中不存在主机/模板宏也将被删除。 将Zabbix展现在Nginx上毕竟现在Nginx用的多，那就把Apache换成Nginx吧！ Nginx仓库:http://nginx.org/packages/ 自己安装Nginx: 下载nginx-release-xx.rmp仓库源来安装； 手动创建/etc/yum.repo.d/nginx.repo； 直接下载ngix.rpm来安装； 直接下载源码来安装。 相较于Apache，Nginx也只是配置个server就行了。优化什么的自己弄。12345678910111213141516171819202122232425262728293031vim /etc/nginx/conf.d/zabbix.confserver &#123; listen 80; server_name zabbix.me; root /usr/share/zabbix; access_log /var/log/nginx/zabbix.access.log main; allow 127.0.0.1; allow Your-IP; deny all; location / &#123; if (!-f $request_filename) &#123; rewrite ^([^\?]+)$ /index.php?1=$1 last; &#125; &#125; location ~ \.php$ &#123; root /usr/share/zabbix; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; &#125;&#125;nginx -tsystemctl start nginx 下载就可以正常访问zabbix-web端了! Zabbix监控Zabbix自带的templates基本涵盖了大部分监控信息。 大部分操作系统： OS Linux; OS AIx; OS FreeBSD; OS Solaris; OS Windows; … 大部分服务： CPU; Filesystems; HTTP/HTTPS service; Memory; Network interfaces; Processes; Secutity; Zabbix server/agent/Proxy; SMTP,POP,SSH,NTP, service; ICMP Ping; SNMP; … 虚拟机： VM VMware; VM WMware Hypervisor; … 网络设备： Cisco; Huawei; TPLink; HP; … 除了Zabbix自带的templates，你还可以下载templates并导入zabbix-server。 例如PHP-FPM, MongoDB, Apache, Nginx, Redis等额外软件的监控就需要下载额外templates。 监控MySQL使用Zabbix自带模板监控MySQLZabbix默认带有MySQL的监控和模板，所以无需再去下载。不过需要配置用户，密码，主机，端口等信息。 123456789101112131415161718192021222324vim /etc/zabbix/zabbix-agentd.d/userparameter_mysql.conf#For all the following commands HOME should be set to the directory that has .my.cnf file with password information.#这句话叫我们新建一个带有mysql密码信息的.my.cnf文件#并把此配置文件里面的HOME改为.my.cnf所的在目录#.my.cnf文件里面的用户要对MySQL数据库有权限才行，没有权限请记得加[mysql]host=localhostuser=zabbixpassword=zabiixsocket=/var/lib/mysql/mysql.sock[mysqladmin]host=localhostuser=rootpassword=passwordsocket=/var/lib/mysql/mysql.sock#测试zabbix_get -s 127.0.0.1 -k mysql.ping#1 使用Percona插件监控MySQLZabbix默认带有MySQL的监控和模板，所以无需再去下载。不过需要配置用户，密码，主机，端口等信息。但是Zabbix自带的MySQL监控太简陋了。所以使用Percona提供的模板及监控。 Percona Monitoring Plugins-URL: https://www.percona.com/downloads/percona-monitoring-plugins/LATEST/Percona Monitoring Plugins for Zabbix- Instructions: https://www.percona.com/doc/percona-monitoring-plugins/LATEST/zabbix/index.html 此插件地址需要我们选择Percona-Version和Software平台。 选择平台后，我们只需安装zabbix的rpm包就好： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#安装rpm包yum install -y https://www.percona.com/downloads/percona-monitoring-plugins/percona-monitoring-plugins-1.1.7/binary/redhat/7/x86_64/percona-zabbix-templates-1.1.7-2.noarch.rpm#安装软件#注意php版本问题yum install -y percona-zabbix-templatesls /var/lib/zabbix/percona#scripts目录有.sh脚本文件#templates目录有配置文件和模板文件#复制配置文件cp /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf /etc/zabbix/zabbix_agentd.d/#我看了一下，这个配置文件和zabbix自带的MySQL配置文件一样#添加MySQL的相关信息vim /var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php$mysql_user = 'root';$mysql_pass = 'password';$mysql_port = 3306;$mysql_socket = '/var/lib/mysql/mysql.sock';$mysql_flags = 0;#测试脚本/var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh gg#10#创建.my.cnf文件vim /etc/zabbix/zabbix_agentd.d/.my.cnf[mysql]host=localhostuser=rootpassword=passwordsocket=/var/lib/mysql/mysql.sock[mysqladmin]host=localhostuser=rootpassword=passwordsocket=/var/lib/mysql/mysql.sock[client]host=localhostuser=rootpassword=passwordsocker=/var/lib/mysql/mysql.sock#重启服务systemctl restart zabbix-agent#测试sudo -u zabbix -H /var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh running-slave#0/1 导入模板，模板文件位于：/var/lib/zabbix/percona/templates/zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.7.xml 但我直接导入模板时报错——标签无效 “/zabbix_export/date”: “YYYY-MM-DDThh:mm:ssZ” 预计。此模板需要先导入Zabbix2.4后再导出，然后再导入到Zabbix3.4。太麻烦。 所以需要下载修改过的模板： http://jaminzhang.github.io/soft-conf/Zabbix/zbx_percona_mysql_template.xml 1wget http://jaminzhang.github.io/soft-conf/Zabbix/zbx_percona_mysql_template.xml 下载之后导入模板，然后链接主机。链接之后可以部分监控可能显示不支持的。 如：Received value [rm: 无法删除”/tmp/localhost-mysql_cacti_stats.txt”: 不允许的操作0] is not suitable for value type [Numeric (float)]没有权限。 解决办法： 1234cd /tmpchown -R zabbix:zabbix localhost-mysql_cacti_stats.txtsystemcet restart zabbix-agent 监控MongoDB感谢大神： MongoDB-templates: https://share.zabbix.com/databases/mongodb/mongodb-for-zabbix-3-2 ; GitHub: https://github.com/oscm/zabbix/tree/master/mongodb 此github-repo中还包含了Oracle, php-fpm, postfix, redis, Nginx。可参看README.md来配置zabbix对它们的监控。 安装步骤1. 在zabbix-agent安装jqjq - Command-line JSON processor; 1yum install -y jq 2. 在zabbix-agent的MongoDB中创建用于监控的账号创建用于读取MongoDB相关信息的账户及其权限。 12345678910111213mongo&gt;use admin&gt;db.createUser( &#123; user:'zabbix', pwd:'zabbix', roles:[&#123; role:'clusterMonitor', db:'admin'&#125;] &#125;) 3. 在agent下载github仓库的MongoDB模板等文件 12345678910111213wget https://codeload.github.com/oscm/zabbix/zip/master -O master.zip#这里面不仅仅有mongodb，还有redis,php等。#我们只需要进入mongodb目录就好unzip master.zipcd ./zabbix-master/mongodbls#mongodb.sh , 执行脚本#userparameter_mongodb.conf ，配置脚本#zbx_export_templates.xml，zabbix模板文件 4. 移动并配置mongodb.sh 123456789101112cp ./mongodb.sh /etc/zabbixchmod a+x /etc/zabbix/mongodb.shvi mongodb.sh#如果HOST,PORT不是默认，请修改DB_HOST=127.0.0.1DB_PORT=27017DB_USERNAME=zabbixDB_PASSWORD=zabbix 5. 移动并修改userparameter_mongodb.conf 1234567cp ./zabbix-master/userparameter_mongodb.conf /etc/zabbix/zabbix_agentd.dvi ./userparameter_mongodb.confUserParameter=mongodb.status[*],/etc/zabbix/mongodb.sh $1 $2 $3 $4 $5#修改为mongdb.sh真实位置#这个是用户自定义的参数，可以之间写入到zabbix_agent.conf里面 6. 重启zabbix-agent 1systemctl restart zabbix-agent 7. 在zabbix-web导入mongodb模板 配置-模板-导入模板； 选择./master/mongodb/zbx_export_templates.xml模板文件，并导入； 接下来便可以在 templates中看到”Template App MongoDB”这个模板； 可将此模板链接到某个主机上监控，并到最新数据里查看相关MongoDB信息； 如果相对此模板就行修改，可编辑zbx_export_templates.xml文件。 监控一台主机上的额外mongod实例由于可能一台主机上运行的mongod实例不止一个，所以我们需要修改一下前面下载的配置文件，用以监控其它端口的mongod实例。 此处假设默认的mongod实例运行在27017端口上 另外还有一个mongod实例运行在27018端口上 此处假设我们已经完成了前面对27017mongodb的监控了 操作： 12345678910111213141516171819202122232425262728cd /etc/zabbixcp mongodb.sh mongodb_27018.shvim ./mongodb_27018.sh#配置监控的mongodb账号和端口DB_HOST=127.0.0.1DB_PORT=27018DB_USERNAME=zabbixDB_PASSWORD=zabbix#现在就有了提取27017/27018两个mongodb实例的脚本#mongodb.sh#mongodb_27018.shcd ./zabbxi-agentd.dvim userparameter_mongodb.conf#在默认的27017下面添加一行提取mongodb_27018信息的脚本UserParameter=mongodb.status[*],/etc/zabbix/mongodb.sh $1 $2 $3 $4 $5UserParameter=mongodb_27018.status[*],/etc/zabbix/mongodb_27018.sh $1 $2 $3 $4 $5#现在zabbix-server端就可以同时获取27017/27018两个mongodb实例的信息#但是Web界面还不能直接显示出来，因为27018的键值和默认不相同#没错，就是上面我们修改的 mongodb_27018.status[*] 接下来要在Zabbix-Web端配置监控项用以提取信息 我们先找到一个默认的MongoDB自带的配置模板，如MongoDB Connections current，点进去查看它的键值对为mongodb.status[connections,current] 因此我们只需要修改为我们配置文件里面的mongodb_27018.status[*]就可以了。 其余个监控项以此类推，我觉得其他服务也应该可以如此。 你也可以对此建立一个单独的模板，如MongoDB_27108 templates。在此监控模板下创建上面的监控项。这样就可以对所有主机生效了。也可以批量化操作，更方便一些。 下面是我的参考Template App MongoDB模板建立的Template App MongoDB_27018 监控PHP-FPM同样使用上面大神的模板。 步骤和监控MongoDB类似： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687#进入下载的文件目录cd ./zabbix-master/php-fpmcp ./php-fpm.xml.sh /etc/zabbixchmod a+x /etc/zabbix/php-fpm.xml.shvim /etc/zabbix/php-fpm.xml.sh#如果这三个参数修改了，请修改#因为是使用culr，所以请允许此IP能够访问此页面#另外还要Nginx允许Server-IP访问哦，不然无法读取数据#我测试的时候用IP无法获取数据，所以用的域名#如果没做域名解析，请加本地hosts#php-fpm_status使用我修改的HOST="localhost"PORT="80"#status="status"status="php-fpm_status"cp ./userparameter_php-fpm.conf /etc/zabbix/zabbix_agent.d/#当然也可以把这个用户自定义参数写入zabbix_agent.conf#修改自定义参数里面的文件位置vim /etc/zabbix/zabbix_agent.d/userparameter_php-fpm.confUserParameter=php-fpm.status[*],/etc/zabbix/php-fpm.xml.sh $1#php-fpm，nginx的状态必须用Nginx展现，Zabbix-Server是使用curl提取状态页面的信息vim /etc/nginx/conf.d/zabbix.confserver &#123; listen 80; server_name zabbix.me localhost;#如果localhost与其他配置文件冲突，那就用IP#server_name zabbix.me 127.0.0.1 Private-IP Public-IP; root /usr/share/zabbix; access_log /var/log/nginx/zabbix.access.log main;#allow无法使用localhost，所有内外网要分开写 allow 127.0.0.1; allow Private-IP; allow Public-IP; allow Zabbix-Server-IP; allow Remote-View-IP; deny all; location / &#123; if (!-f $request_filename) &#123; rewrite ^([^\?]+)$ /index.php?1=$1 last; &#125; &#125;#Nignx_Status location /nginx_status &#123; stub_status on; #开启nginx自带的状态检查功能 access_log off; &#125;#php-fpm_Status#php-fpm的默认状态页面是/status,/ping。我修改了一下。 location ~ ^/php-fpm_(status|ping)$ &#123; access_log off; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; &#125; location ~ \.php$ &#123; root /usr/share/zabbix; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; &#125;&#125; php-fpm状态页面的配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163vim /etc/php-fpm.d/www.conf#说明和用法如下，我做简单修改#修改默认值;pm.status_path = /statuspm.status_path = /php-fpm_status;ping.path = /pingping.path = /php-fpm_ping;ping.response = pongping.response = 200#用法zabbix.me/php-fpm_statuszabbix.me/php-fpm_ping#配置文件提供了格式化输出zabbix.me/php-fpm_status?htmlzabbix.me/php-fpm_status?html&amp;full; output syntax. Example:; http://www.foo.bar/status; http://www.foo.bar/status?json; http://www.foo.bar/status?html; http://www.foo.bar/status?xml; http://www.foo.bar/status?full; http://www.foo.bar/status?json&amp;full; http://www.foo.bar/status?html&amp;full; http://www.foo.bar/status?xml&amp;full#修改完毕后重启服务systemctl restart php-fpm nginx#具体看下面描述##这下面是说明; The URI to view the FPM status page. If this value is not set, no URI will be; recognized as a status page. It shows the following informations:; pool - the name of the pool;; process manager - static, dynamic or ondemand;; start time - the date and time FPM has started;; start since - number of seconds since FPM has started;; accepted conn - the number of request accepted by the pool;; listen queue - the number of request in the queue of pending; connections (see backlog in listen(2));; max listen queue - the maximum number of requests in the queue; of pending connections since FPM has started;; listen queue len - the size of the socket queue of pending connections;; idle processes - the number of idle processes;; active processes - the number of active processes;; total processes - the number of idle + active processes;; max active processes - the maximum number of active processes since FPM; has started;; max children reached - number of times, the process limit has been reached,; when pm tries to start more children (works only for; pm 'dynamic' and 'ondemand');; Value are updated in real time.; Example output:; pool: www; process manager: static; start time: 01/Jul/2011:17:53:49 +0200; start since: 62636; accepted conn: 190460; listen queue: 0; max listen queue: 1; listen queue len: 42; idle processes: 4; active processes: 11; total processes: 15; max active processes: 12; max children reached: 0;; By default the status page output is formatted as text/plain. Passing either; 'html', 'xml' or 'json' in the query string will return the corresponding; output syntax. Example:; http://www.foo.bar/status; http://www.foo.bar/status?json; http://www.foo.bar/status?html; http://www.foo.bar/status?xml;; By default the status page only outputs short status. Passing 'full' in the; query string will also return status for each pool process.; Example:; http://www.foo.bar/status?full; http://www.foo.bar/status?json&amp;full; http://www.foo.bar/status?html&amp;full; http://www.foo.bar/status?xml&amp;full; The Full status returns for each process:; pid - the PID of the process;; state - the state of the process (Idle, Running, ...);; start time - the date and time the process has started;; start since - the number of seconds since the process has started;; requests - the number of requests the process has served;; request duration - the duration in µs of the requests;; request method - the request method (GET, POST, ...);; request URI - the request URI with the query string;; content length - the content length of the request (only with POST);; user - the user (PHP_AUTH_USER) (or '-' if not set);; script - the main script called (or '-' if not set);; last request cpu - the %cpu the last request consumed; it's always 0 if the process is not in Idle state; because CPU calculation is done when the request; processing has terminated;; last request memory - the max amount of memory the last request consumed; it's always 0 if the process is not in Idle state; because memory calculation is done when the request; processing has terminated;; If the process is in Idle state, then informations are related to the; last request the process has served. Otherwise informations are related to; the current request being served.; Example output:; ************************; pid: 31330; state: Running; start time: 01/Jul/2011:17:53:49 +0200; start since: 63087; requests: 12808; request duration: 1250261; request method: GET; request URI: /test_mem.php?N=10000; content length: 0; user: -; script: /home/fat/web/docs/php/test_mem.php; last request cpu: 0.00; last request memory: 0;; Note: There is a real-time FPM status monitoring sample web page available; It's available in: @EXPANDED_DATADIR@/fpm/status.html;; Note: The value must start with a leading slash (/). The value can be; anything, but it may not be a good idea to use the .php extension or it; may conflict with a real PHP file.; Default Value: not set;pm.status_path = /statuspm.status_path = /php-fpm_status; The ping URI to call the monitoring page of FPM. If this value is not set, no; URI will be recognized as a ping page. This could be used to test from outside; that FPM is alive and responding, or to; - create a graph of FPM availability (rrd or such);; - remove a server from a group if it is not responding (load balancing);; - trigger alerts for the operating team (24/7).; Note: The value must start with a leading slash (/). The value can be; anything, but it may not be a good idea to use the .php extension or it; may conflict with a real PHP file.; Default Value: not set;ping.path = /pingping.path = /php-fpm_ping; This directive may be used to customize the response of a ping request. The; response is formatted as text/plain with a 200 response code.; Default Value: pong;ping.response = pongping.response = 200 效果图： 展现的话是在Agent端的Nginx上，这个更直观一些。而Zabbix-Server就是通过curl -s zabbix.me来获取数据的，并通过对数据的提取来返回给Zabbix-Server。所以收集php-fpm，nginx的信息状态，都是基于这个页面的。 现在导入PHP-FPM模板，导入操作同MongoDB。 12#就是这个文件zbx_export_templates.xml 导入模板后，直接链接模板就可以啦。然后就可以使用了。 监控NginxZabbix是通过stub_status模块实现对Nginx的监控。Nginx的ngx_http_stub_status_module模块提供了基本的Nginx状态信息，源码安装的话需要加上–with-http_stub_status_module编译参数，如果是epel源yum安装的话，已经默认启用该模块。 在Nginx配置文件中加入如下配置： 1234567891011121314location /nginx_status &#123; allow IP; deny all; stub_status on; access_log off;&#125;#栗子Active connections: 14server accepts handled requests 22889 22889 72510Reading: 0 Writing: 2 Waiting: 12 一些状态信息 Active connections当前active client的连接数，包括Wating accepts接受的客户端连接总数 handled已处理的连接总数。通常，handled与accepts相同，除非已达到了资源限制(如worker_connections限制) requests客户端请求总数 Reading当前nginx正在读取request header的连接数 Writing当前Nginx将reponse写回客户端的连接数 Waiting当前等待请求的空闲客户端的连接数 上面的结果还可通过命令来查看 1netstat -n | awk &apos;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a,S[a]&#125;&apos; 以上数据是通过Web端查看。但，我们需要把数据收集到Zabbix-Server。还需要使用之前下载同MongoDB，php-fpm一起的那个包。 操作，基本还是类似MongoDB，php-fpm。只是个别参数需要修改一下。 1234567891011121314151617181920cd ./zabbix-master/nginx/cp ./nginx.sh /etc/zabbix/chmod a+x /etc/zabbix/nginx.shcp ./userparameter_nginx.conf /etc/zabbix/zabbix_agentd.dvim /etc/zabbix/nginx.sh#HOST=&quot;localhost&quot;PORT=&quot;80&quot;#stub_status=stub_statusstub_status=nginx_statusvim /etc/zabbix/zabbix_agentd.d/userparameter_nginx.conf#修改成脚本对应的位置UserParameter=nginx.status[*],/etc/zabbix/nginx.sh $1 现在想以前一样导入模板。然后在链接模板就可以了。 监控Redis监控Redis，也是把包里面对应的文件复制过去就行。 123456789101112131415cd ./zabbix-master/rediscp ./userparameter_redis.conf /etc/zabbix/zabbix_agentd.d/#如果redis设置有密码，请加上密码#如果是不同的端口，请修改UserParameter=redis.local[*],redis-cli -h 127.0.0.1 -p 6379 info|grep $1|grep -v _human|cut -d : -f2#UserParameter=redis.local[*],redis-cli -h 127.0.0.1 -p 6379 -a Password info|grep $1|grep -v _human|cut -d : -f2UserParameter=redis.status[*],redis-cli -h $1 -p $2 -a Password info|grep $3|grep -v _human|cut -d : -f2UserParameter=redis.proc,pidof redis-server | wc -l#重启服务systemctl restart redis 导入模板，链接主机，OK。 系统监控 CPUCPU的性能状态信息： 简写 描述 说明 us user cpu tim 用户使用CPU时间 sy system cpu time 系统使用CPU时间 id idle cpu time CPU的空闲时间 wa io wait cpu time CPU等待IO时间 ni user nice cpu time 用nice调整进程优先级的CPU时间 st steal time 虚拟机偷取的CPU时间比，被强制等待虚拟CPU的时间 si softirq time 系统处理软件中断所花费的CPU时间 hi hard time 系统硬中断所花费的CPU时间 interrupt 中断 被处理过的中断数 cs Context switches 上下文切换 ql processor queue length 队列长度 processor load processor load 处理器负载，几核乘以几 Tips 当我们要监控并报警CPU使用率时，我们可以反过来用CPU空闲时间来定义 cpu idle tiem% + cpu usage time% = 1 (CPU usage time% gt 80%) == (CPU idel time% lt 20%) (CPU usage time% gt 90%) == (CPU idel time% &lt; 10%) 所以监控CPU使用率就可以监控CPU空闲时间，并依据这个报警 内存Zabbix中自带的Linux OS模板提供了Total memory和Available memory选项，这两者直接用模板就可以了。但没有提供内存使用率的选项，因此需要我们自定义。 内存使用率 = 可用内存 / 总内存 ast(vm.memory.size[available])/last(vm.memory.size[total]) 自定义内存使用率我们只需要在Linux OS模板下配置内存使用率，就可以一劳永逸。 配置(Configuration) 模板(Templates) OS Linux模板的监控项(Items) 创建监控项 监控项名称: Available memory percent 类型： 可计算的 键值： vm.memory.size[percent] 公式： 100*last(vm.memory.size[available])/last(vm.memory.size[total]) 记得将其加入Memory应用集，这样便于查找和管理 可加入单位： % 添加触发器 配置 模板 OS Linux模板 触发器 创建触发器，当可用内存率在三分钟内的平均值小于20%时报警 名字：Available memory percent lt 20% on {HOST.NAME} 严重性：一般严重 表达式： {Template OS Linux:vm.memory.size[percent].avg(3)}&lt;20 磁盘由于Zabbix-Server自带的Linux OS模板中的filesystem的监控是一个自动发现规则，而在应用集中的filesystem是没有监控项的。所有对于磁盘的监控和触发要在自动发现规则中去定义。 进程和端口Zabbix-Server自带有检测进程和端口的键值对。 检测进程数proc.num[&lt;name&gt;,&lt;user&gt;,&lt;state&gt;,&lt;cmdline&gt;] name: 进程名； user: 运行该进程的用户； state: run sleep zomb cmdline: ps -ef的最后那项，如/usr/bin/mongod -f /etc/mongod.conf 现在Zabbix-Server端测试： 1234567891011#zabbix-get --host hostname --key proc.num[&lt;name&gt;,&lt;user&gt;,&lt;state&gt;,&lt;cmdline&gt;]#检测mongd进程数量zabbix-get --host 192.168.1.11 --key proc.num[mongod,,,]#2，因为我开了两个mongd实例zabbix-get --host 192.168.1.11 --key proc.num[mongod,root,,]#1，只有一个是以root运行的，有一个是以mongod运行的 由于我们上面使用的MongoDB监控模板没有判断mongod进程存活与否的判断，此处我们在MongoDB模板中增加一个检查mongod进程的监控项，并创建对应的触发器。 端口net.tcp.listen[port] 检查 TCP 端口 是否处于侦听状态。返回 0 - 未侦听；1 - 正在侦听 此处我也用Mongod举例。我的两个mongod实例分别监听在27017,27018/tcp。 在Zabbix-Server端先测试： 123456#net.tcp.listen[port]zabbix-get --host 192.168.1.11 --key net.tcp.listen[27017]#1zabbix-get --host 192.168.1.11 --key net.tcp.listen[27018]#1 在Web端创建监控项和触发器与上面类似。 用户自定义参数(user parameter)我也是参考了上述大神的脚本，进行参考而来。 由于公司需要监控大量的Web页面和API接口的状态，并通过页面判断相关key-value的正确性，用以判断状态。此处可能由模拟登录等操作，Zabbix自带的Web监控不太够用，所以此处自定义用户参数来实现。 此处，我叫公司开发人员帮忙将全部接口以及Web页面内容都生成到一个json文件里，如 http://zhang21.cn/test.json。然后用jq命令解析json文件，里面key一一对应value，这样取值就很方便了。 jqjq 是一款命令行下处理 JSON 数据的工具。真的很好用！ jq官网：https://stedolan.github.io/jq/GitHub: https://github.com/stedolan/jq 安装jq 1yum install -y jq 使用jq 123456789101112131415161718192021222324252627282930313233jq --help#查看所有键键值curl --silent http://zhang21.cn/test.json | jq .###栗子&#123; "collapsectimes": 130, "collapsectimes": 0, "bootfailtimes": 23, "failrate": 0.3623, "bootrate": 0.3324, "time": "2018-01-25 15:03:30", "db_error": false&#125;#查看某个键值curl --silent http://zhang21.cn/test.json | jq '.time'curl --silent http://zhang21.cn/test.json | jq '.bootrate'###2018-01-25 15:03:300.3324#查看某个不存在的值，会返回nullcurl --silent http://zhang21.cn/test.json | jq '.zhang'###null json嵌套解析 1234cat test.json | jq '.location.city'###"Chengdu" json解析数组 1234cat test.json | jq '.array[1].name'###"Zhang" 内建函数 jq还有一些内建函数，如key,hss。 key用来获取json中的key元素： 123456789101112curl --silent http://zhang21.cn/test.json | jq 'keys'###[ collapsectimes, collapsectimes, bootfailtimes, failrate, bootrate, time, db_error] has用来判断是否存在某个key: 1234curl --silent http://zhang21.cn/test.json | jq 'has("time")'###true jq的select语句使用select函数来完成jq的过滤操作。jq的select语句太好了! select 接受一个条件表达式作为参数。其输入可以是迭代器，或者和 map 函数配合使用来处理数组。当输入中的某个元素使 select 参数中的条件表达式结果为真时，则在结果中保留该元素，否则不保留该元素。 对json文件的值是数组的，根据数据里面的key在取值，厉害厉害。 123456789101112131415161718192021222324252627cat zhang.json"array": [&#123; "ip": "192.168.1.11", "loads": 1234&#125;,&#123; "ip": "192.168.1.22", "loads": 567&#125;]####栗子cat /etc/zabbix/zhang.json | jq ".array[] | select(.ip == \"192.168.1.11\")"&#123; "ip": "192.168.1.11", "loads": 1234&#125;cat /etc/zabbix/zhang.json | jq ".array[] | select(.ip == \"192.168.1.11\").loads"1234我们在自定义用户参数的时候便可以将ip作为参数传入cat /etc/zabbix/zhang.json | jq ".array[] | select(.ip == \"$1\").loads" 编写自定义参数和脚本将脚本放置于/etc/zabbix，可将自定义参数写入zabbix-agentd.conf文件，也可单独写入/etc/zabbix/zabbix_agentd.d/(推荐)，这样修改更方便。 编写脚本文件123456789101112131415161718192021222324252627282930cd /etc/zabbixvim xbreport.sh########### Zabbix3.4# Zhang21# Thu Jan 25 15:20:44 CST 2018###########url="http://zhang21.cn/test.json"JQ=`which jq`CURL=`which curl`function XBREPORT() &#123; $CURL --silent $url | $JQ ".$1"&#125;if [ $# == 0 ]; then echo $"Usage $0 &#123;browsercollapsectimes|servercollapsectimes|xiaobaibootfailtimes|terminaldesktopfailrate|competebootrate|db_error&#125;" exitelse XBREPORT "$1"fi 编写自定义参数文件123456789101112cd /etc/zabbix/zabbix_agentd.dvim userparameter_XBreport.conf########### Zabbix3.4# Zhang21# Thu Jan 25 15:45:19 CST 2018##########UserParameter=XBreport[*],/etc/zabbix/xbreport.sh $1 测试自定义参数1234zabbix_get --host host --key XBreport[time]###"2018-01-25 17:03:18" 自定义用户参数额外由于我的json文件key对应的value中内嵌有数组，所以我需要再提取数组内的值。 12345678910111213141516171819curl http://zhang21.cn/test.json | jq &apos;.array&apos;###[ &#123; &quot;ip&quot;: &quot;1.1.1.1&quot;, &quot;loads&quot;: 1051 &#125;, &#123; &quot;ip&quot;: &quot;2.2.2.2&quot;, &quot;loads&quot;: 356 &#125;]#array[],array[1],array[2],array[n]#array[].ip, array[1].ip#array[].loads, array[2].loads 上面的数据中包含有zabbix无法解析的特殊符号，所以需要改变策略。 由于zabbix对UserParameter中包含\’”`*?[]{}~$?&amp;;()&lt;&gt;|#@这些特殊字符无法进行处理，此处有两种方法来解决。 在zabbix_agentd.conf中开启参数UnsafeUserParameters，将其值设置为1 或者，使用多个变量$1 $2 $3...来解决我这个数组值的问题 我是使用多个变量来解决我这个情况的。看下脚本。 1234567891011121314151617181920212223242526272829303132cd /etc/zabbixvim ./zhang.shurl=&apos;http://www.zhang21.cn/test.json&apos;JQ=`which jq`CURL=`which curl`function ZHANG() &#123; $CURL --silent $url | $JQ &quot;.$1&quot;&#125;if [ $# == 0 ]; then echo $&quot;Usage $0 &#123;aaa|bbb|ccc|...&#125;&quot; exitelif [ $# ==1 ]; then ZHANG &quot;$1&quot;elif [ $# == 2 ]; then ZHANG &quot;$1[$2]&quot;else ZHANG &quot;$1[$2].$3&quot;ficd /etc/zabbix/zabbix_agentd.d/userparameter_Zhang.confUserParameter=Zhangxx[*],/etc/zabbix/zhang.sh $1 $2 $3 测试： 123456systemctl restart zabbix-agentdzabbix_get --host host --key Zhangxx[array]zabbix_get --host host --key Zhangxx[array,0]zabbix_get --host host --key Zhangxx[array,0,loads]zabbix_get --host host --key Zhangxx[array,1,ip] 测试正确能取到值的话，在Web端设置相对应的监控项。注意自己定义的key不要写错了。 数组的key栗子： Zhangxx[array] Zhangxx[array,0]或Zhangxx[array,1] Zhangxx[array,0,ip], Zhangxx[array,0,loads] 在Web端添加监控项由于这个参数是我们自定义的，所以在填写监控项key的时候需要我们手动填写自己定义的参数。注意监控项的参数和信息类型。 这里我遇到一个问题，我自定义key的执行脚本在Web端报超时问题，无法取值。这是由于zabbix默认的脚本执行超时时间为3s，所以我们需要修改超时时间30s(最大值)。 12vim /etc/zabbix/zabbix_server.confvim /etc/zabbix/zabbix_agentd.conf 设置触发器和报警这个就根据你个人项目实际情况设置对于的触发器和报警。 短信报警腾讯短信服务由于公司使用的是腾讯企业邮箱，可以将邮箱直接与微信绑定，从而在微信中实时显示邮件消息，所以不用微信报警！ 此处使用的腾讯短信SMS服务： https://cloud.tencent.com/product/sms 短信文档： https://cloud.tencent.com/document/product/382/13445 API文档： https://cloud.tencent.com/document/product/382/13297 SDK文档： https://cloud.tencent.com/document/product/382/5804 Python SDK: https://cloud.tencent.com/document/product/382/11672 由于腾讯提供了程序SDK，所以我选择了linux自带的Python SDK。这里面有详细的Python使用方法，做一些小修改就可以使用了。 配置获取Python SDK获取Python SDK 申请SDK AppID和App Key申请SDK AppID以及APP Key。 申请完毕后，效果如下： 申请短信签名下发短信必须携带短信签名。短信签名需要上传公司证件进行认证，大概十分钟左右！ 效果如下： 申请短信模板下发短信内容必须经过审核。在此短信模板中，我们必须要定义相关变量{n}，其他都是不会变化的常量。此处我定义了五个变量，分别为了带入Zabbix中的宏： 问题名，{TRIGGER.NAME} 主机名，{HOST.NAME} 事件事件，{EVENT.TIME} 事件日期，{EVENT.DATE} URL，{TRIGGER.URL} SDK配置1234yum install -y eple-realseyum install -y python-pippip install qcloudsms Python代码配置腾讯文档：https://cloud.tencent.com/document/product/382/11672 由于我是向多人发送短信，所以做了小修改： 12345678910111213141516171819202122232425262728293031323334#zabbix-servercd /usr/lib/zabbis/alartscriptsvim sendSms.py#!/bin/python#coding: utf-8from qcloudsms_py import SmsSingleSenderfrom qcloudsms_py.httpclient import HTTPErrorimport sysappid = App IDappkey = App Keyphone_numbers = ["12345", "1234567"]#params = ["Problem", "Hostname", "Time", "Date","Url"]params = [sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4], sys.argv[5]]msender = SmsSingleSender(appid, appkey)for i in phone_numbers: try: result = msender.send_with_param(86, i, 短信内容模板ID, params) except HTTPError as e: print(e) except Exception as e: print(e) print(result) 要给sendSms.py加上可执行权限哈！chmod a+x ./sendSms.py。 sys.argv变量是一个字符串的列表。特别地，sys.argv包含了命令行参数 的列表，即使用命令行传递给你的程序的参数。使用Python的sys.argv[n]可以像shell一样将放在文件后的变量传入文件执行。此处对于在Zabbix-Web端将宏放在脚本后，作为变量传入，非常重要。 sys.argv[0]代表sendSms.py文件 sys.argv[1]才代表第一个参数。 Zabbix Web端配置配置-动作-创建动作-操作 注意事项： 建议针对触发器示警度最高就行短信报警，其它交给Email 操作类型，选择远程命令 目标列表，选择当前主机 类型，自定义脚本 执行在，这个一定是放在Zabbix-Server上来执行哈 命令，文件名SendSms.py后面接的宏一定要加上双引号(“”) 最后根据不同的内容，设置不同的报警机制。后台的脚本也修改为对应的名称，修改里面对应的手机号码。 首先根据不同报警设置不同的触发条件 运维组，SendSms_dev.py，修改运维对应的号码 开发组，SendSms_develop.py，修改对于的号码 其实这个发送短信，就是在执行远程命令。 你命令里是发送短信就发送短信，你命令里是发送邮件就发送邮件。这个还是挺不错的。 针对不同业务向不同人员报警有时候我们只需要关心我们自己那部分就可以了，没必要所有报警都发送给所有人，这样很不方便。 所以，我们可以根据业务相关，组别权限等，分别向不同的人报警不同的信息。 如下我的一个栗子图：]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git]]></title>
    <url>%2F2017%2F11%2F07%2FGit%2F</url>
    <content type="text"><![CDATA[参考： 廖雪峰Git教程 Git内部原理 Git内部原理-伯乐在线 介绍git(/ɡɪt/)是一个分布式版本控制软件,最初由林纳斯·托瓦兹（Linus Torvalds）创作，于2005年以GPL发布。Git是免费的。 林纳斯·托瓦兹自嘲地取了这个名字“git”，该词源自英国俚语，意思大约是“混账”。 集中式与分布式集中式版本控制系统，版本库是集中存放在中央服务器的，而干活的时候，用的都是自己的电脑，所以要先从中央服务器取得最新的版本，然后开始干活，干完活了，再把自己的活推送给中央服务器。集中式版本控制系统最大的毛病就是必须联网才能工作。常用集中式版本控制系统有：CVS、SVN。 分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。既然每个人电脑上都有一个完整的版本库，那多个人如何协作呢？比方说你在自己电脑上改了文件A，你的同事也在他的电脑上改了文件A，这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。常用分布式版本控制系统有：Git。 和集中式版本控制系统相比，分布式版本控制系统的安全性要高很多，因为每个人电脑里都有完整的版本库，某一个人的电脑坏掉了不要紧，随便从其他人那里复制一个就可以了。而集中式版本控制系统的中央服务器要是出了问题，所有人都没法干活了。 常用命令 几个专用名词: Workspace：工作区 Index/Stage：暂存区 Repository：仓库区（或本地仓库） Remote：远程仓库 常用命令： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186#配置#Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下#--global全局配置git config --global user.name "Username"git config --globla user.email "Email"#创建版本库#虽然在任意目录下都可创建git-repo，但还是建议在一个空目录下创建git-repomkdir gitest&amp;&amp;cd gitest#init, Create an empty Git repository or reinitialize an existing onegit init#生成了一个.git目录，这个目录是git用来追踪管理版本库的，不要随意修改此目录的内容echo "First Git test" &gt; README#增加/删除文件#所有的版本控制系统，只能跟踪文本文件的改动#把文件添加到暂存区#git add file#git add dir#当前目录#git add .git add README#删除#git rm file#改名#git move file#提交#把暂存区提交到仓库区#-m, 为本次提交的说明信息git commit -m "Update Readme"#为什么Git添加文件需要add, commit一共两步呢？#因为commit可以一次提交很多文件，所以你可以多次add不同的文件。git add file1 file2 file3git commit -m "add 3files"#分支#查看分支git branchgit branch -a# 新建一个分支，但依然停留在当前分支git branch [branch-name]# 新建一个分支，并切换到该分支git checkout -b [branch]# 新建一个分支，与指定的远程分支建立追踪关系git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区git checkout [branch-name]# 建立追踪关系，在现有分支与指定的远程分支之间git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支git merge [branch]# 删除分支git branch -d [branch-name]# 删除远程分支git push origin --delete [branch-name]git branch -dr [remote/branch]#标签git tag#远程同步# 下载远程仓库的所有变动git fetch [remote]# 显示所有远程仓库git remote -v# 显示某个远程仓库的信息git remote show [remote]# 增加一个新的远程仓库，并命名git remote add [shortname] [url]# 取回远程仓库的变化，并与本地分支合并git pull [remote] [branch]# 上传本地指定分支到远程仓库git push [remote] [branch]# 强行推送当前分支到远程仓库，即使有冲突git push [remote] --force# 推送所有分支到远程仓库git push [remote] --all#撤销# 恢复暂存区的指定文件到工作区git checkout [file]# 恢复某个commit的指定文件到暂存区和工作区git checkout [commit] [file]# 恢复暂存区的所有文件到工作区git checkout .# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变git reset [file]# 重置暂存区与工作区，与上一次commit保持一致git reset --hard# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变git reset [commit]# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致git reset --hard [commit]# 重置当前HEAD为指定commit，但保持暂存区和工作区不变git reset --keep [commit]# 新建一个commit，用来撤销指定commit# 后者的所有变化都将被前者抵消，并且应用到当前分支git revert [commit]# 暂时将未提交的变化移除，稍后再移入git stashgit stash pop#其它# 生成一个可供发布的压缩包$ git archive 内部原理Git 的内部工作原理和实现方式，学习这些内容对于理解 Git 的用处和强大功能是非常重要的。首先要弄明白一点，从根本上来讲 Git 是一套内容寻址(content-addressable) 文件系统——它是一个相当酷的东西，在此之上提供了一个 版本控制系统(VCS)用户界面。 底层命令和高层命令由于 Git 最初是一套面向版本控制系统的工具集，而不是一个完整的、用户友好的版本控制系统，所以它还包含了一部分用于完成底层工作的命令。 这些命令被设计成能以 UNIX 命令行的风格连接在一起，抑或藉由脚本调用，来完成工作。 这部分命令一般被称作底层命令（plumbing），而那些更友好的命令则被称作高层命令（porcelain）。 Git Repo下有一个.git目录，几乎所有 Git 存储和操作的内容都位于该目录下。如果你要备份或复制一个库，基本上将这一目录拷贝至其他地方就可以了。 .git内容: branches/ config: 包含项目特有的配置选项 description: 仅供 GitWeb 程序使用 HEAD： Git核心部分，指向当前分支 hooks/： 客户端或服务端钩子脚本 index： Git核心部分，保存了暂存区域信息 info/: 保存了一份不希望在.gitignore文件中管理的忽略模式的全局性排除文件 objects/： Git核心部分，存储所有数据内容 refs/： Git核心部分，存储指向数据 (分支) 的提交对象的指针 可能还有其它文件 COMMIT_EDITMSG FETCH_HEAD logs/ ORIG_HEAD Git对象Git 是一套内容寻址文件系统。从内部来看，Git 是简单的 key-value 数据存储。它允许插入任意类型的内容，并会返回一个键值，通过该键值可以在任何时候再取出该内容。可以通过底层命令 hash-object 来示范这点，传一些数据给该命令，它会将数据保存在 .git 目录并返回表示这些数据的键值。Git 初始化了 objects 目录，同时在该目录下创建了 pack 和 info 子目录。 新建文件后，此目录中会出现新目录(目录内容为哈希值)。 1234567891011121314echo &amp;#039;test content&amp;#039; | git hash-object -w --stdind670460b4b4aece5915caf5c68d12f560a9fe3e4#也可以直接添加文件#git hash-object -w test.txtfind .git/objects -type f.git/objects/d6/70460b4b4aece5915caf5c68d12f560a9fe3e4#使用git cat-file取回对象内容git cat-file -p d670460b4b4aece5915caf5c68d12f560a9fe3e4test content 树对象tree object tree 对象可以存储文件名，同时也允许存储一组文件。Git 以一种类似 UNIX 文件系统但更简单的方式来存储内容。所有内容以 tree 或 blob 对象存储，其中 tree 对象对应于 UNIX 中的目录，blob 对象则大致对应于 inodes 或文件内容。 123456789101112131415git cat-file -p master^&#123;tree&#125;100644 blob a38f463bb1bdb05ce38cf7d9cfd4ed11286a708c README.md040000 tree f7cda840304ce5729444dd60904a0bbdf95fa0b5 test#master^&#123;tree&#125; 表示 branch 分支上最新提交指向的 tree 对象#请注意 test 子目录并非一个 blob 对象，而是一个指向别一个 tree 对象的指针git cat-file -p f7cda840304ce5729444dd60904a0bbdf95fa0b5040000 tree 02e9e8af4ae37db0fcd1943fdc832b27ad03ea03 2018#这才是两个blob对象git cat-file -p 02e9e8af4ae37db0fcd1943fdc832b27ad03ea03100644 blob 7066d2a8d6f8e3c6c44bdbf3a775c96cc9d0a3b9 2018-12-14.md100644 blob c0a915bf91f77db873a425058391e500c1504bae 2018-12-21.md 你可以自己创建 tree 。通常 Git 根据你的暂存区域或 index 来创建并写入一个 tree 。因此要创建一个 tree 对象的话首先要通过将一些文件暂存从而创建一个 index 。 123#指定了文件模式为 100644，表明这是一个普通文件git update-index --add --cacheinfo 100644 \83baae61804e65cc73a7201a7252750c76066a30 test.txt 提交对象commit object 1234567#创建commit 对象echo &amp;#039;first commit&amp;#039; | git commit-tree d8329ffdf4fc3344e67ab068f836878b6c4951e3b15f3d#查看git cat-file -p fdf4fc3 Git References引用(references, refs)，可在.git/refs下查看相关内容。 123#有三个目录ls .git/refsheads remotes tags HEAD当你执行 git branch &lt;branch-name&gt; 这条命令的时候，Git 怎么知道最后一次提交的散列值呢？答案就是 HEAD 文件。HEAD 文件是一个指向你当前所在分支的引用标识符。 12345678910111213141516171819#这就是上面.git/refs目录下cat .git/HEADref: refs/heads/testgit checkout mastercat .git/HEADref: refs/heads/master#你也可以设置它的值#但不能设置为refs以外的值，会报错git symbolic-ref HEAD refs/heads/testcat .git/HEADref: refs/heads/test TagsTag 对象指向一个 commit 而不是一个 tree。它就像是一个分支引用，但是不会变化——永远指向同一个 commit，仅仅是提供一个更加友好的名字。Tag 有两种类型：annotated 和 lightweight 。 Remotes如果你添加了一个 remote 然后推送代码过去，Git 会把你最后一次推送到这个 remote 的每个分支的值都记录在refs/remotes 目录下。 12345678910111213141516git logcommit 1deea62fa622d00db113abe136e9b22e1f3eac4cxxxxxxxxxcat .git/refs/heads/origin/master1deea62fa622d00db113abe136e9b22e1f3eac4c#切换分支git checkout testgit logcommit 3e1fcc1f8c035320d985b0202e18a6a00fe068c0cat .gt/refs/heads/origin/test3e1fcc1f8c035320d985b0202e18a6a00fe068c0 PackfilesGit 往磁盘保存对象时默认使用的格式叫松散对象 (loose object) 格式。Git 时不时地将这些对象打包至一个叫 packfile 的二进制文件以节省空间并提高效率。当仓库中有太多的松散对象，或是手工调用git gc 命令，或推送至远程服务器时，Git 都会这样做。Git 打包对象时，会查找命名及尺寸相近的文件，并只保存文件不同版本之间的差异内容。Git 自动定期对仓库进行重新打包以节省空间。当然也可以手工运行 git gc 命令来这么做。 1234567891011121314#举个栗子find .git/objects -type f.git/objects/01/55eb4229851634a0f03eb265b69f5a2d56f341 # tree 2.git/objects/1a/410efbd13591db07496601ebc7a059dd55cfe9 # commit 3.git/objects/1f/7a7a472abf3dd9643fd615f6da379c4acb3e3a # test.txt v2.git/objects/3c/4e9cd789d88d8d89c1073707c3585e41b0e614 # tree 3.git/objects/83/baae61804e65cc73a7201a7252750c76066a30 # test.txt v1.git/objects/95/85191f37f7b0fb9444f35a9bf50de191beadc2 # tag.git/objects/ca/c0cab538b970a37ea1e769cbbde608743bc96d # commit 2.git/objects/d6/70460b4b4aece5915caf5c68d12f560a9fe3e4 # &amp;#039;test content&amp;#039;.git/objects/d8/329fc1cc938780ffdd9f94e0d364e0ea74f579 # tree 1.git/objects/fa/49b077972391ad58037050f2a75f74e3671e92 # new.txt.git/objects/fd/f4fc3344e67ab068f836878b6c4951e3b15f3d # commit 1 Refspec1234#假设添加了一个远程Repogit remote add origin git@ github.com:schacon/simplegit-progit.git#之后可在.git/config中查看 缺省情况下 refspec 会被 git remote add 命令所自动生成， Git 会获取远端上 refs/heads/ 下面的所有引用，并将它写入到本地的 refs/remotes/origin/: 12345git log origin/mastergit log remotes/origin/mastergit log refs/remotes/origin/master#它们全是等价的，因为 Git 把它们都扩展成 refs/remotes/origin/master 如果你想让 Git 每次只拉取远程的 master 分支，而不是远程的所有分支，你可以把 fetch 这一行修改成这样： 123#默认#fetch = +refs/heads/*:refs/remotes/origin/*fetch = +refs/heads/master:refs/remotes/origin/master 你可以使用命名空间来达到这个目的。如你有一个QA组，他们推送一系列分支，你想每次获取 master 分支和QA组的所有分支，你可以使用这样的配置段落： 1234[remote &amp;quot;origin&amp;quot;] url = git@ github.com:schacon/simplegit-progit.git fetch = +refs/heads/master:refs/remotes/origin/master fetch = +refs/heads/qa/*:refs/remotes/origin/qa/* push Refspec 如果QA组成员想把他们的 master 分支推送到远程的 qa/master 分支上，可以这样运行： 1git push origin master:refs/heads/qa/master 删除 Refspec 以使用 refspec 来删除远程的引用，是通过运行这样的命令： 123#因为 refspec 的格式是 : #通过把 部分留空的方式，这个意思是是把远程的topic 分支变成空，也就是删除它git push origin :topic 传输协议Git 可以通过两种主要的方式在版本库之间传输数据：dumb Protocol 和 smart protocol Dumb protocolGit 基于HTTP之上传输通常被称为 dump protocol，这是因为它在服务端不需要有针对 Git 特有的代码。这个获取过程仅仅是一系列 GET 请求，客户端可以假定服务端的Git仓库中的布局。 12#栗子git clone http://github.com/schacon/simplegit-progit.git Smart protocoldump procotol 虽然很简单但效率略低，且它不能从客户端向服务端发送数据。智能协议是更常用的传送数据的方法，但它需要在服务端运行一个进程，而这也是 Git 的智能之处——它可以读取本地数据，理解客户端有什么和需要什么，并为它生成合适的包文件。 总共有两组进程用于传输数据，它们分别负责上传和下载数据。为了上传数据至远端， Git 使用 send-pack 和 receive-pack 进程。这个 send-pack 进程运行在客户端上，它连接至远端运行的 receive-pack 进程。当你在下载数据时， fetch-pack 和 upload-pack 进程就起作用了。客户端启动 fetch-pack 进程，连接至远端的 upload-pack 进程，以协商后续数据传输过程。 举例来说，在项目中使用命令 git push origin master 时, origin 是由基于 SSH 协议的 URL 所定义的。 Git 会运行 send-pack 进程，它会通过 SSH 连接你的服务器。 它会尝试通过 SSH 在服务端执行命令 维护和恢复有的时候，你需要对仓库进行清理 - 使它的结构变得更紧凑，或是对导入的仓库进行清理，或是恢复丢失的内容。 维护Git 会不定时地自动运行一个叫做 auto gc 的命令。 大多数时候，这个命令并不会产生效果。 然而，如果有太多松散对象（不在包文件中的对象）或者太多包文件，Git 会运行一个完整的 git gc 命令。这个命令通常并不会产生效果。 大约需要 7000 个以上的松散对象或超过 50 个的包文件才能让 Git 启动一次真正的 gc 命令。 你可以通过修改 gc.auto 与 gc.autopacklimit 的设置来改动这些数值。 12#栗子git gc --auto 数据恢复在你使用 Git 的时候，你可能会意外丢失一次提交。 通常这是因为你强制删除了正在工作的分支，但是最后却发现你还需要这个分支；亦或者硬重置了一个分支，放弃了你想要的提交。 如果这些事情已经发生，该如何找回你的提交呢？ 首先需要判断当前处于什么位置，然后恢复到之前某个位置。 12345678910111213141516171819202122232425262728293031#查看commitgit log --pretty=oneline3e1fcc1f8c035320d985b0202e18a6a00fe068c0 update 1.txta3f3bdd9cf22ce499d1b3cdff5bb26c94032a15d add 2.txtf4c90e173ef18e738f0287af71ae0878beec9316 add 1.txt748d8d3152b3a9a81068e29ae00fa797c2223520 add README#重置git reset --hard $&#123;commit-id&#125;#也可以使用git reflog1a410ef HEAD@&#123;0&#125;: reset: moving to 1a410efab1afef HEAD@&#123;1&#125;: commit: modified repo.rb a bit484a592 HEAD@&#123;2&#125;: commit: added repo.rb#查看loggit log -gcommit 1a410efbd13591db07496601ebc7a059dd55cfe9Reflog: HEAD@&#123;0&#125; (Scott Chacon &lt;schacon@gmail.com&gt;)Reflog message: updating HEADAuthor: Scott Chacon &lt;schacon@gmail.com&gt;Date: Fri May 22 18:22:37 2009 -0700 third commit 你可以通过创建一个新的分支指向这个提交来恢复它： 12345678910111213#748d8d3152b3a9a81068e29ae00fa797c2223520 add READMEgit branch test 748d8d3152b3a9a81068e29ae00fa797c2223520git checkout testlsREADME.md#删除分支git checkout mastergit branch -D test 移除对象Git 有许多过人之处，不过有一个功能有时却会带来问题：git clone 会将包含每一个文件的所有历史版本的整个项目下载下来。如果项目包含的仅仅是源代码的话这并没有什么坏处，毕竟 Git 可以非常高效地压缩此类数据。不过如果有人在某个时刻往项目中添加了一个非常大的文件，那们即便他在后来的提交中将此文件删掉了，所有的签出都会下载这个 大文件。因为历史记录中引用了这个文件，它会一直存在着。 警告：这个操作对提交历史的修改是破坏性的。 它会从你必须修改或移除一个大文件引用最早的树对象开始重写每一次提交。 如果你在导入仓库后，在任何人开始基于这些提交工作前执行这个操作，那么将不会有任何问题 - 否则，你必须通知所有的贡献者他们需要将他们的成果变基到你的新提交上。 1234567git rm bigfiles.tar.gzgit commit -m "remove big files"#查看清理了多少空间git gc#git count-objects -v 环境变量Git 总是在一个 bash shell 中运行，并借助一些 shell 环境变量来决定它的运行方式。 全局行为 GIT_EXEC_PATH: 决定 Git 到哪找它的子程序 PREFIX: 也类似，除了用于系统级别的配置 GIT_PAGER: 控制在命令行上显示多页输出的程序 GIT_EDITOR: 当用户需要编辑一些文本（比如提交信息）时， Git 会启动这个编辑器 版本库位置 GIT_DIR: 是 .git 目录的位置 GIT_CEILING_DIRECTORIES: 控制查找 .git 目录的行为 GIT_WORK_TREE: 是非空版本库的工作目录的根路径 如果没指定，就使用 $GIT_DIR 的父目录 GIT_INDEX_FILE: 是索引文件的路径 GIT_OBJECT_DIRECTORY: 用来指定 .git/objects 目录的位置 GIT_ALTERNATE_OBJECT_DIRECTORIES: 一个冒号分割的列表 (格式类似/dir/one:/dir/two:…) 用来告诉 Git 到哪里去找不在 GIT_OBJECT_DIRECTORY 目录中的对象. 如果你有很多项目有相同内容的大文件，这个可以用来避免存储过多备份。 路径规则 GIT_GLOB_PATHSPECS, GIT_NOGLOB_PATHSPECS: 控制通配符在路径规则中的默认行为 GIT_LITERAL_PATHSPECS: 禁用上面的两种行为；通配符将不能用，前缀覆盖也不能用 GIT_ICASE_PATHSPECS: 让所有的路径规格忽略大小写 提交 `GIT_AUTHOR_NAME: 是 “author” 字段的可读的名字 GIT_AUTHOR_EMAIL: 是 “author” 字段的邮件 GIT_AUTHOR_DATE: 是 “author” 字段的时间戳 GIT_COMMITTER_NAME: 是 “committer” 字段的可读的名字 GIT_COMMITTER_EMAIL: 是 “committer” 字段的邮件 GIT_COMMITTER_DATE: 是 “committer” 字段的时间戳 网络 GIT_SSL_NO_VERIFY: 告诉 Git 不用验证 SSL 证书。 这在有些时候是需要的， 例如你用一个自己签名的证书通过 HTTPS 来提供 Git 服务， 或者你正在搭建 Git 服务器，还没有安装完全的证书 GIT_HTTP_USER_AGENT: 设置 Git 在通过 HTTP 通讯时用到的 user-agent 比较与合并 GIT_DIFF_OPTS: 这个有点起错名字了 有效值仅支持 -u 或 —unified=，用来控制在 git diff 命令中显示的内容行数 GIT_EXTERNAL_DIFF: 用来覆盖 diff.external 配置的值。 如果设置了这个值， 当执行Gitgit diff 时，Git 会调用该程序 GIT_DIFF_PATH_COUNTER 和 GIT_DIFF_PATH_TOTAL: 对于 GIT_EXTERNAL_DIFF 或diff.external 指定的程序有用。 前者表示在一系列文件中哪个是被比较的（从 1 开始），后者表示每批文件的总数。 GIT_MERGE_VERBOSITY: 控制递归合并策略的输出。 允许的值有下面这些： 0: 什么都不输出，除了可能会有一个错误信息 1: 只显示冲突 2: 还显示文件改变(默认值) 3: 显示因为没有改变被跳过的文件 4: 显示处理的所有路径 5: 显示详细的调试信息 调试 GIT_TRACE: 控制常规跟踪，它并不适用于特殊情况。 它跟踪的范围包括别名的展开和其他子程序的委托 GIT_TRACE_PACK_ACCESS: 控制访问打包文件的跟踪信息 GIT_TRACE_PACKET: 打开网络操作包级别的跟踪信息 GIT_TRACE_PERFORMANCE: 控制性能数据的日志打印 GIT_TRACE_SETUP: 显示 Git 发现的关于版本库和交互环境的信息 其它 GIT_SSH GIT_ASKPASS GIT_NAMESPACE GIT_FLUSH GIT_REFLOG_ACTION fetch与pullGit中从远程的分支获取最新的版本到本地有两个命令: fetch: 当于是从远程获取最新版本到本地，不会自动merge pull: 相当于是从远程获取最新版本并merge到本地 几个概念： FETCH_HEAD: 是一个版本链接，记录在本地的一个文件中，指向着目前已经从远程仓库取下来的分支的末端版本 commit-id git fetch: 这将更新git remote中所有的远程仓库所包含分支的最新commit-id, 将其记录到.git/FETCH_HEAD文件中 git pull: 基于本地的FETCH_HEAD记录，比对本地的FETCH_HEAD记录与远程仓库的版本号，然后git fetch获得当前指向的远程分支的后续版本的数据，然后再利用git merge将其与本地的当前分支合并。 首先，你的每一个操作都是要指明来源和目标，对于pull来说，目标就是当前分支。其次，你得清楚git是有tracking的概念的，所谓tracking就是把来源和目标绑定在一起，节省一些操作是需要输入的参数。默认是在当前分支，平时养成好习惯，没谱的时候把来源和目标都带上。 12345678910111213141516171819202122232425262728293031323334#直接使用git fetch#创建并更新本 地远程分支git fetch#只是手动指定了要fetch的remote。在不指定分支时通常默认为master#git fetch origin [branch]git fetch origin#指定远程remote和FETCH_HEAD，并且只拉取该分支的提交git fetch origin dev#git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;#取回远程主机某个分支的更新，再与本地的指定分支合并。#当你在 master 下git pull#等于 fetch origin，然后 merge origin/master#当你在 develop 下git pull#等于 fetch origin，然后 merge origin/develop#多个分支#切换到devgit checkout dev#这会在当前分支合并testgit pull origin test 123456789101112#查看 .git/config[remote &quot;origin&quot;] url = git@xxx:xxx/xxx.git fetch = +refs/heads/*:refs/remotes/origin/*#它指明了 fetch 动作的来源#也就是说， git fetch 的操作就是取下上述目标的更新#但是——取下的东西到底在哪儿？#查看 .git/FETCH_HEAD 可以简单的这样理解： 123456789101112#fetch 从另外一个版本库下载对象和引用#pull 获取并合并另外的版本库或一个本地分支git pull = git fetch + merge to local#git fetch origin master#git merge FETCH_HEAD#如果搞不清楚，指明源和目标是最稳当的git pull [remote] [branch] 时光穿梭机12345678#查看repo当前状态git status#查看改变git diff 版本回退每当文件修改到一定程度的时候，就可以提交一次。这样即使误操作后，还可以从最近的commit中恢复，而不是把工作成果全部丢失。 123456789101112131415161718192021222324252627282930313233343536#查看提交记录#git的commit id是一个SHA1的16进制散列git log Update README.mdcommit e89d28373c19321466f99e15cd3cdcc5fffe868fAuthor: zhang21 &lt;elite_zhang21@163.com&gt;Date: Thu Apr 5 23:40:13 2018 +0800#版本回退，如果文件误删，可以从commit中恢复#查看提交记录，能看到Commit ID(sha1sum散列值)#在Git中，用HEAD表示当前版本，也就是最新的Commit ID#上一版本HEAD^, 上上版本HEAD^^, 倒数第十个版本HEAD~100#HEAD指的是当前版本#重置当前HEAD到指定状态git reset --hard HEAD^#也可以利用commit id回退git reset --hard $commit_id#查看历史命令git reflog#在本地回退之后，是无法push到远程的#必须强制pushgit push origin master --force 工作区和暂存区 git add实质是吧文件修改添加到暂存区 git commit实质是把暂存区的所有内容提交到当前分支 管理修改为什么git比其它版本控制系统设计的更优秀，因为它跟踪并管理的是修改，而非文件。如果修改后的文件没有使用git add放入暂存区的话，那么git commit也不会生效的。 撤销修改如果要纠正文件，可以手动修改文件并恢复到上一版本状态。但也可以使用git命令。 12345678910#丢弃工作区的修改#--很重要，没有--就变成了切换分支的命令git checkout -- filename#当你不但改乱了工作区某个文件的内容，还添加到了暂存区时。想丢弃修改，分两步。#第一步用命令git reset HEAD file，就回到了场景1，第二步git checkout --file。git reset HEAD file &amp;&amp; git checkout -- file 删除文件在git中，删除也是一个修改操作。 有两种情况： 误删除 真删除 12345678#rm，从工作区和索引中删除文件#如果一个文件已经被提交到版本库，那么你永远不用担心误删git rm README#误删某文件，需要恢复git checkout -- README 远程仓库用于验证推送，GitHub与本地仓库使用SSH加密传输，所以这需要创建一对密钥。 12345#生成SSH Keyssh-keygen -t rsa -C &quot;email-address&quot;#会生成.ssh目录，里面包含公私钥#将公钥id_ras.pub填入GitHub 添加远程仓库12345678910111213#origin是默认的远程仓库名，你可以修改git remote add origin git@xxx.com:username/xxx.git#推动本地仓库到远程#实际上是推动本地的master分支到远程#-u关联了本地master和远程mastergit push -u origin master#之后git push origin master 从远程库克隆1234567#将远程仓库克隆到本地#如果是多人协作开发，那么每个人各自从远程克隆一份就可以了#可以使用ssh协议或https协议(每次都要输入口令)git clone git@xxx.com:username/xxx.git#克隆指定分支git clone -b test URL 分支管理你可以创建一个自己的分支，别人看不到，还继续在原来的分支上正常工作。而你在自己的分支上干活，想提交就提交，而不会影响到其他人。 创建于合并分支HEAD严格来说不是指向提交，而是指向分支(如master)，分支才是指向提交。 当工作完成后，便可合并分支，然后删除额外的分支。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#查看分支#*代表当前工作分支git branch#创建分支git branch &lt;branch-name&gt;#切换分支git checkout &lt;branch-name&gt;#创建并切换分支，等于上面的创建和切换分支git checkout -b &lt;branch-name&gt;#在test分支下新建test.txtgit checkout testecho &apos;Just a test&apos; &gt; ./test.txtgit add test.txtgit commit -m &apos;Just a test branch&apos;#回到mastergit checkout master#此分支下并没有test.txt#也就是说并没有其它分支提交的内容#合并分支到当前分支git merge &lt;branch-name&gt;#合并test分支到当前的master分支git merge test#删除分支git branch -d &lt;branch-name&gt;#合并完成后删除test分支git brancd -d test 解决冲突合并分支玩玩也不是一帆风顺的！ 可能在你创建了新分支后，master分支又进行了提交，而你的新分支也做了提交，这是合并分支便会带了问题。当git分支无法合并时，就必须首先要解决冲突。解决冲突后，再提交和合并。 123#查看分支合并图git log --graph 分支管理策略 在实际开发中，master分支应该是非常稳定的。也就是只用来发布新版本，不能在上面干活 干活应在其它分支上(如dev)，干完后合并到master 工作人员都在dev上干活，每个人都有自己的分支，然后将自己的分支合并到dev就可以了 合并分支时，加上--no-ff参数就可以用普通模式合并，合并后的历史有分支，能看出来曾经做过合并，而fast forward合并就看不出来曾经做过合并。 Bug分支Git提供了一个stash功能，可以把工作现场储藏起来，等以后恢复现场后继续工作。 1234567891011121314151617181920git stash#创建debug分支git checkout -b &apos;issue-25&apos;git checkout mastergit merge --no-ff -m &quot;debug 25&quot; &apos;issue-25&apos;#切回工作区git stash listgit stash apply stash@xxx#手动删除stashgit stash drop#恢复同时也删除stashgit stash pop Feature分支添加一个新功能时，你肯定不希望因为一些实验性质的代码，把主分支搞乱了，所以，每添加一个新功能，最好新建一个feature分支，在上面开发，完成后，合并，最后，删除该feature分支。 丢弃一个没有被合并过得分支，可通过git branch -D &lt;branch-name&gt;强行删除。 多人协作123456789101112131415161718192021222324#查看远程仓库git remote#显示远程仓库详细信息git remote -v#推送指定分支git push origin test#抓取分支git clone#更新分支git pull#合并分支git merge#推送分支git push 版本库（Repository）隐藏目录.git是Git的版本库。Git版本库里面存放了很多东西，其中最重要的就是 stage(或index)的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。 用git add把文件添加进去，实际是把文件添加到暂存区； 用git commit提交更改，实际是把暂存区的所有内容提交到当前分支。默认git commit就是往master上提交更改。 SSHKey 创建SSHKey并在本地关联多个SSH 123#把你的github邮箱地址ssh-keygen -t rsa -C &quot;email@example.com&quot;#会生成 ~/.ssh，包含 私钥：id_rsa，公钥：id_rsa.pub 将公钥写入Github在Github—Account settings—SSH Keys—Add SSH Key里面，添加你的id_rsa.pub公钥文件。当然，你可以添加多个Key哦，毕竟可能你有多台登陆设备。这个就相当于SSH无密钥认证。 在主机上关联多个git 12345678910111213141516171819202122232425262728293031vim ~/.ssh/config#OneHost git.xxx.com IdentityFile ~/.ssh/id_rsa Hostname IP User git Port 10022#twoHost github IdentityFile ~/.ssh/id_rsa Hostname github.com User git Port 22#three#这样可用于ssh登录Host zhang21 Hostname ip User username Port 22 IdentityFile ~/.ssh/id_rsa#一定要记着修改权限chmoe 600 ~/.ssh/*#测试连接ssh -T git@github.com 标签管理发布一个新版本时，通常先在版本库中打一个标签(tag)，这样，就唯一确定了打标签时刻的版本。将来无论什么时候，取某个标签的版本，就是把那个打标签的时刻的历史版本取出来。所以，标签也是版本库的一个快照。 tag其实是指向 commit id的。git有commit，为什么还要引入tag? commit id 是一串散列值，并不简单明了。但是tag,我可以写为”v1.0”,”v1.2”…让tag，”v1.0”指向对应的commit id，很方便明了。 创建标签12345678910111213141516171819202122232425262728293031323334353637383940414243#切换到需要打tag的分支上git brach test#创建tag默认tag是打在最新提交的commit上#git tag &lt;tag-name&gt;git tag v1.0#查看所有taggit tag#指定tag对应的commit#git tag &lt;tag-name&gt; &lt;commit_id&gt;git tag v1.0 65432ba#标签不是按时间顺序列出的，而是按照字母排序git show $tag-namegit show v1.0#创建带有说明的标签#git tag -a &lt;tag-name&gt; -m &quot;v1.1 released&quot; &lt;commit-id&gt;git tag -a v1.1 -m &quot;V1.1&quot; 6543bb#查看标签说明git show &lt;tag-name&gt;#用私钥签名一个标签#依赖GPG#git tag -s &lt;tag-name&gt; -m &quot;pri-key&quot; &lt;commit-id&gt;git tag -s v1.2 -m &quot;pri-key v1.2&quot; 6543bc 操作标签1234567891011121314151617181920#删除标签#git tag -d &lt;tag-name&gt;git tag -d v1.2#推送某个标签到远程#git pust origin &lt;tag-name&gt;git push origin v1.0#推送全部标签git push origin --tags#删除远程标签git push origin :refs/tags/&lt;tag-name&gt; 忽略特殊文件创建一个.gitignore特殊文件，然后把要忽略的文件名填进去，Git就会自动忽略这些文件。 各种模板： https://github.com/github/gitignore 检查.gitignore文件: git check-ignore .gitignore 搭建Git服务器常见的Git服务器有： GitLab: https://gitlab.com/ Gogs（go git service）: https://gogs.io/]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Love at First Sight]]></title>
    <url>%2F2017%2F11%2F06%2FLove-at-First-Sight%2F</url>
    <content type="text"><![CDATA[——波兰诗人维斯拉瓦·辛波丝卡(Wislawa Szymborska) They’re both convincedthat a sudden passion joined them. Such certainty is beautiful,but uncertainty is more beautiful still. Since they’d never met before,they’re sure that there’d been nothing between them. But what’s the word from the streets, staircases, hallways —perhaps they’ve passed each other a million times? I want to ask themif they don’t remembera moment face to facein some revolving door?perhaps a “sorry” muttered in a crowd?a curt “wrong number” caught in the receiver?but I know the answer. No, they don’t rememberThey’d be amazed to hearthat Chance has been toying with themnow for years. Not quite ready yetto become their Destiny,it pushed them close, drove them apart,it barred their path, stifling a laugh,and then leaped aside. There were signs and signals,even if they couldn’t read them yet. Perhaps three years agoor just last Tuesdaya certain leaf flutteredfrom one shoulder to another? Something was dropped and then picked up.Who knows, maybe the ball that vanished into childhood’s thicket? There were doorknobs and doorbellswhere one touch had covered another beforehand. Suitcases checked and standing side by side.One night, perhaps, the same dream,grown hazy by morning. Every beginning is only a sequel,after all,and the book of eventsis always open halfway through.]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>Poetry</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Wireshark]]></title>
    <url>%2F2017%2F10%2F25%2FWireshark%2F</url>
    <content type="text"><![CDATA[过滤语法wireshark过滤分为两种: 抓包过滤 显示过滤 尽量避免使用抓包过滤。即便多看几个报文，也比漏掉一个报文要好。 抓包过滤类型 host net port 方向 src dst 协议 ether ip/arp tcp/udp http/dns/ftp/icmp … 逻辑运算符 &amp;&amp; || ! 栗子： 1234567891011121314151617181920212223242526272829303132333435#主机host www.xx.comsrc host 192.168.1.1 &amp;&amp; dst port 80host 193.168.1.1 || host 192.168.1.2#广播包!broadcast#MACether host 00:88:ab:56:12:0dsrc ether host 00:88:ab:56:12:0d#IPhost 192.168.1.1dst host 192.168.1.1#netnet 192.168.1.0/24src net 192.168.1.0/24#vlanvlan 11#Portport 80! port 443dst port 80udp dst port 5678portrange 1-80 显示过滤比较操作符 == != &gt; &lt; &gt;= &lt;= 逻辑操作符 and or xor not IP ip.addr ip.src ip.dst Port tcp.port tcp.srcport tcp.dstport tcp.flag.syn tcp.flag.ack Protocol arp ip icmp udp tcp dns … 栗子： 1234567891011121314#ipip.addr == 1.1.1.1ip.src == 1.1.1.1 and ip.dst == 2.2.2.2#porttcp.port == 80tcp.dstport == 80tcp.flag.syn == 1#proarpnot icmp HTTPSWireshark也可以分析HTTPS加密的包，但你需要用证书将包先解密。在Edit-&gt;Preferences-&gt;Protocol-&gt;SSL选项填写相关信息进行解密。]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Wireshark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell]]></title>
    <url>%2F2017%2F10%2F24%2FLinuxShell%2F</url>
    <content type="text"><![CDATA[参考： Linux Shell脚本攻略 鸟哥的Linux私房菜 k-vim: https://github.com/wklken/k-vim inode参考: wiki: https://zh.wikipedia.org/wiki/Inode 关于 inode 理解inode 简介inode是UNIX操作系统中的一种数据结构，它包含了与文件系统中各个文件系统对象(文件、目录、设备文件、socket、管道…)的元数据信息。在UNIX中创建文件系统时，同时将会创建大量的inode。通常，文件系统磁盘空间中大约百分之一空间分配给了inode表。 Unix先驱丹尼斯·里奇说，inode这个命名的来源可能是文件系统的存储组织为一个扁平数组，分层目录信息使用一个数作为文件系统这个扁平数组的索引值（index）。 理解inode，要从文件储存说起。 文件储存在硬盘上，硬盘的最小存储单位叫做扇区（Sector）。每个扇区储存512字节（相当于0.5KB）。操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个块（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个sector组成一个block。文件数据都储存在块中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为索引节点。 细节文件系统创建（格式化）时，就把存储区域分为两大连续的存储区域。一个用来保存文件系统对象的元信息数据，这是由inode组成的表，每个inode默认是256字节或者128字节。另一个用来保存文件系统对象的内容数据，划分为512字节的扇区，以及由8个扇区组成的4K字节的块。块是读写时的基本单位。一个文件系统的inode的总数是固定的。这限制了该文件系统所能存储的文件系统对象的总数目。典型的实现下，所有inode占用了文件系统1%左右的存储容量。 文件系统中每个文件系统对象对应一个inode数据，并用一个整数值来辨识。这个整数常被称为inode号码（i-number或inode number）。由于文件系统的inode表的存储位置、总条目数量都是固定的，因此可以用inode号码去索引查找inode表。 Inode存储了文件系统对象的一些元信息，如所有者、访问权限（读、写、执行）、类型（是文件还是目录）、内容修改时间、inode修改时间、上次访问时间、对应的文件系统存储块的地址，等等。知道了1个文件的inode号码，就可以在inode元数据中查出文件内容数据的存储地址。 文件名与目录名是文件系统对象便于使用的别名。一个文件系统对象可以有多个别名，但只能有一个inode，并用这个inode来索引文件系统对象的存储位置。 inode不包含文件名或目录名的字符串，只包含文件或目录的元信息 Unix的文件系统的目录也是一种文件。打开目录，实际上就是读取目录文件。目录文件的结构是一系列目录项（dirent）的列表。每个目录项，由两部分组成：所包含文件或目录的名字，以及该文件或目录名对应的inode号码 文件系统中的一个文件是指存放在其所属目录的目录文件中的一个目录项，其所对应的inode的类别为文件；文件系统中的一个目录是指存放在其父目录文件中的一个目录项，其所对应的inode的类别为目录。可见，多个文件可以对应同一个inode;多个目录可以对应同一个inode 文件系统中如果两个文件或者两个目录具有相同的inode号码，那么就称它们是硬链接关系。实际上都是这个inode的别名。换句话说，一个inode对应的所有文件（或目录）中的每一个，都对应着文件系统某个目录文件中唯一的一个目录项 创建一个目录时，实际做了3件事：在其父目录文件中增加一个条目；分配一个inode；再分配一个存储块，用来保存当前被创建目录包含的文件与子目录。被创建的目录文件中自动生成两个子目录的条目，名称分别是：.和..。前者与该目录具有相同的inode号码，因此是该目录的一个硬链接。后者的inode号码就是该目录的父目录的inode号码。所以，任何一个目录的硬链接总数，总是等于它的子目录总数（含隐藏目录）加2。即每个子目录文件中的..条目，加上它自身的目录文件中的.条目。再加上父目录文件中的对应该目录的条目。 通过文件名打开文件，实际上是分成三步实现：首先，操作系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。 讨论 一个文件系统对象可以有多个名字，这些具有硬链接关系的文件系统对象名字具有相同的inode号码，彼此是平等的。即首个被创建的文件并没有特殊的地位。这与符号链接不同。一个符号链接文件有自己的inode，符号链接文件的内容是它所指向的文件的名字。因此删除符号链接所指向的文件，将导致这个符号链接文件在访问时报错 删除一个文件或目录，实际上是把它的inode的链接数减1。这并不影响指向此inode的别的硬链接 一个inode如果没有硬链接，此时inode的链接数为0，文件系统将回收该inode所指向的存储块，并回收该inode自身 从一个inode，通常是无法确定是用哪个文件名查到此inode号码的。打开一个文件后，操作系统实际上就抛掉了文件名，只保留了inode号码来访问文件的内容。库函数getcwd()用来查询当前工作目录的绝对路径名。其实现是从当前工作目录的inode逐级查找其上级目录的inode，最后拼出整个绝对路径的名字 历史上，对目录的硬链接是可能的。这可以使目录结构成为一个有向图，而不是通常的目录树的有向无环图。一个目录甚至可以是自身的父目录。现代文件系统一般禁止这些混淆状态，只有根目录保持了特例：根目录是自身的父目录。ls /..就是根目录的内容 一个文件或目录在文件系统内部移动时，其inode号码不变。文件系统碎片整理可能会改变一个文件的物理存储位置，但其inode号码不变。非UNIX的FAT及其派生的文件系统是无法实现inode不变这一特点。 inode文件系统中安装新库十分容易。当一些进程正在使用一个库时，其它进程可以替换该库文件名字的inode号码指向新创建的inode，随后对该库的访问都被自动引导到新inode所指向的新的库文件的内容。这减少了替换库时重启系统的需要。而旧的inode的链接数已经为0，在使用旧库的进程结束后，旧的inode与旧库文件会被系统自动回收。 结构POSIX标准强制规范了文件系统的行为。每个文件系统对象必须具有： 设备ID，标识容纳该文件的设备 以字节为单位的文件大小 磁盘块 用户(uid) 组(gid) r/w/x权限 时间戳 ctime: inode自身被修改的时间； mtime：内容修改的时间； atime：最后一次被访问的时间 链接数，有多少硬链接指向此inode 使用stat系统调用可以查询一个文件的inode号码及一些元信息。 12345678910# 使用stat查看某个文件inodestat _config.yml File: '_config.yml' Size: 2522 Blocks: 8 IO Block: 4096 regular fileDevice: fd02h/64770d Inode: 52354 Links: 1Access: (0664/-rw-rw-r--) Uid: ( 1000/ zhang) Gid: ( 1000/ zhang)Access: 2019-04-22 09:39:28.735991059 +0800Modify: 2018-07-07 15:37:50.000000000 +0800Change: 2018-12-11 07:38:26.287109004 +0800 Birth: - 大小inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode表（inode table），存放inode所包含的信息。 由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是磁盘还未存满的情况。这时，就无法在磁盘上创建新文件。 123456789101112# 查看inodedf -iFilesystem Inodes IUsed IFree IUse% Mounted onoverlay 26214400 597690 25616710 3% /tmpfs 485005 17 484988 1% /devtmpfs 485005 16 484989 1% /sys/fs/cgroup/dev/mapper/centos-home 215418880 297955 215120925 1% /home/test/dev/mapper/centos-root 26214400 597690 25616710 3% /etc/hostsshm 485005 1 485004 1% /dev/shmtmpfs 485005 1 485004 1% /proc/acpitmpfs 485005 1 485004 1% /proc/scsitmpfs 485005 1 485004 1% /sys/firmware 硬软链接 硬链接一般情况下，文件名和inode号码是”一一对应”关系，每个inode号码对应一个文件名。但是，Unix/Linux系统允许，多个文件名指向同一个inode号码。 这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为”硬链接”（hard link）。 运行上面这条命令以后，源文件与目标文件的inode号码相同，都指向同一个inode。inode信息中有一项叫做”链接数”，记录指向该inode的文件名总数，这时就会增加1。反过来，删除一个文件名，就会使得inode节点中的”链接数”减1。当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。 这里顺便说一下目录文件的”链接数”。创建目录时，默认会生成两个目录项：”.”和”..”。前者的inode号码就是当前目录的inode号码，等同于当前目录的”硬链接”；后者的inode号码就是当前目录的父目录的inode号码，等同于父目录的”硬链接”。所以，任何一个目录的”硬链接”总数，总是等于2加上它的子目录总数（含隐藏目录）。 软链接文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的”软链接”（soft link）或者”符号链接（symbolic link）。 这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错：”No such file or directory”。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode”链接数”不会因此发生变化。 vim在Linux中使用文本编辑器来编辑你的Linux参数配置文件是一件很重要的事情，因此系统管理员至少应该熟悉一种文本编辑器。 在Linux中，绝大部分的配置文件都是以ASCII(键盘上可找到)的纯文本形式。因此利用简单的文本编辑器就能修改。 ASCII（发音：/ˈæski/ ass-kee[1]，American Standard Code for Information Interchange，美国信息交换标准代码）是基于拉丁字母的一套电脑编码系统。从[0000 0000 - 0111 1111]共128个字符。 vi文本编辑器 所有的Unix Like系统都会内置vi文本编辑器，其他的文本编辑器则不一定存在 很多软件的编辑接口都会主动调用vi(如 crontab等命令) vim是vi的高级版本 vim具有程序编辑的能力，可以主动以字体颜色辨别语法的正确性，方便程序设计 程序简单，编辑速度相当快速 vi中的tab键所得结果与空格符不一样 vi中，数字是很有意义的 数字通常代表重复做几次，或去到第几个的意思 警告信息当我们使用vim时，vim会在当前目录下再创建一个名为filename.swp的暂存文件。 由于vim的工作被不正常中断，导致暂存盘无法通过正常流程来结束，所以暂存文件就不会消失。此时编辑文件就会出现某些异常情况。 可能有其他人或程序同时在编辑这个文件 在前一个vim的环境中，可能因为某些不明原因导致vim中断(crashed) 三种模式vim包括三种模式： 一般模式 编辑模式 命令行模式 一般模式 命令 说明 x 向后删除一个字符 X 向前删除一个字符 nx,nX 向前/后 删除n个字符 dd 删除当前行 D 删除当前行所有字符，使之成为空行 ndd 删除光标所在行的向下n行 d1G 删除光标所在行到第一行 dG 删除光标所在行到最后一行 yy 复制光标所在行 y1G 复制光标所在行到第一行 yG 复制光标所在行到最后一行 ynj 复制光标所在行和向下n行 dnj 删除光标所在行和向下n行 p 将复制的数据粘贴到光标下一行 P 将复制的数据粘贴到光标上一行 J 将光标所在行与下一行结合成一行 u undo,恢复前一个操作 ctrl+r 重做上一个操作 . 重复前一个操作 编辑模式 命令 说明 i 在当前光标所在处插入文字 I 在光标所在行第一个非空字符插入文字 a 在当前光标后插入文字 A 在当前光标所在行最后插入文字 o 在光标所在行的下一行行首插入字符 O 在光标所在行的上一行行首插入字符 r 替换光标所在那一个字符 R 一直替换光标所指的文字，直到退出 Esc 退出，回到一般模式 命令模式 命令 说明 h 方向左 j 方向下 k 方向上 l 方向右 + 光标移到下一行的第一个非空字符 - 光标移到当前行的第一个非空字符 0 光标移到当前行的第一个字符 $ 光标移到当前行的最后一个字符 n空格 光标在当前行向右移动n个字符 G 光标移到最后一行的第一个非空字符 gg 光标移到第一行的第一个非空字符，相当于1G nG 光标移到第n行的第一个非空字符 /word 在光标之后查找word字符串 ?word 在光标之前查找word字符串 n/N 重复前一个查找 :s/word1/word2 在光标当前行将word1替换成word2 :n1,n2s/word1/word2/g 在n1行-n2行间将word1替换成word2 %s/word1/word2/gc 全局将word1替换成word2，在替换前让用户确认(confirm) :w 保存到文件 :w file2 保存到file2文件 :r file3 从file3文件读取数据并写入 :wq/:x 保存并退出 :q 退出 :q! 强制退出 :!cmd 执行命令 :r!cmd 将执行命令写入 :set nu 显示行号 :set nonu 取消行号 :n1,n2w file4 将n1行-n2行的内容保存到file4文件 Visual模式参考: https://vimjc.com/vim-visual-mode.html Visual Mode下可以选择一块编辑区域，然后对选中的文件内容执行复制、粘贴、插入、删除、替换、改变大小写等操作，是vim使用过程中常用的一种模式。 在vim命令模式下，使用v或V或ctrl+v都可进入可视化模式。这三种模式的主要区别在于: v字符选择模式: 选中光标经过的所有字符 V行选择模式: 选中光标经过的所有行 ctrl+v块选择模式: 选中一整个矩形框表示的所有文本 具体细致的操作就不写了，但却是非常使用。 环境设置与记录因为vim会主动将你曾经的行为记录下来，好方便下次操作。这个文件是自动生成的。 ~/.vim.info ~/.vim.rc 整体vim设置 /etc/vimrc 此外，每个Distribution对vim的默认环境都不太相同。所以你可能需要设置成你自己的工作方式。 参数 说明 :set nu :set nonu 行号设定 :set hlsearch :set nohlsearch 高亮设定 :set autoindent :set noautoindent 自动缩排设定 :set backup 自动备份设定 :set ruler 状态栏设定 :set showmode 模式显示设定，如INSERT :set backspace=(012) 设定退格(backspace)值 :set all 显示所有环境参数 :set 显示与系统默认值不同的参数 :syntax on/off 程序语法显示 :set bg=dark/light 设定背景颜色 栗子： 123456789vim /root/.vimrc"这是注释"set nuset rulerset bg=darksyntax onset hlsearch 注意事项 中文编码问题修改语系编码： LANG=zh_CN.utf-8 Linux与Dos的换行字符 Linux的换行(Enter)为LF符号($) Dos的换行(Enter)为CRLF符号(^M$) 不同系统之间复制纯文本文件可能会有问题，此时可以转换： unix2dos file newfile dos2unix file newfile 语系编码转换iconv - convert text from one character encoding to another 1234#iconv -f 源编码 -t 新编码 filename [-o newfile]#-o，转换到新文件iconf -f big4 -t utf8 old.big5 -o new.utf8 使用正则VIM里的正则用着太爽了，不用不知道，用了非常好！请注意转义哈！ 在vim里的查找(/, ?)和替换(:s, :1,ns, :%s)功能中，使用正则可极大提高效率。 vim毕竟是个编辑器，如果直接饮用正则表达式的元字符会造成一些麻烦。所以需要对正则元字符进行转义。 vim有一个magic，可以设置哪些正则元字符需要转义，哪些不需要。 1234567891011vim:set magic:set nomagicmagic (\m)：除了 $ . * ^ 之外的元字符都需要转义，也就是反斜杠(\)/\m.* #查找任意字符串nomagic (\M)：除了`$ ^`之外的元字符都需要转义/\M.* #查找特定字符串.* 我不建议使用，这样使得vim使用很错乱。还是老老实实使用转义好些。 正则表达式的元字符参考本文档的正则表达式章节。 栗子: 123456789101112131415161718192021vim 1.txt# \s，空格# 删除每行开通的空格:%s/^\s*//g# 去掉开头的行号11, 20s/^[0-9]\&#123;2\&#125;//g# 查找/[0-9]\&#123;3,5\&#125;# 查找多个/aaa\|bbb\|ccc#替换多个:%s/aaa\|bbb/HAHAHAHA/g 插件插件是一种扩展VIM功能的方法。VIM将插件分为： 全局插件(global)：无条件加载和操作 文件类型插件(filetype)：仅为特定文件类型加载和操作，参阅vim --&gt; :help filetype VIM默认会在特定位置查找插件： Linux/OS X： ~/.vim/plugin Windows： $HOME/vimfiles/plugin 文件类型插件为ftplugin 插件只是VIM脚本，因此你可以使用它们来定义函数、映射和命令，就像在.vimrc中一样。插件通常不仅仅是位于相应目录中的单个.vim文件。它们通常还包括自动加载脚本(:help autoload)，语法脚本(:help syntax)和缩进处理脚本。将这些脚本中的所有代码打包在一起，提供强大的钩子来增强VIM。 VIM內建的帮助(:help plugin)包含各种详细信息。有一些优秀资源: Learn Vimscript the Hard Way Writing Vim Plugins 可使用放在适当的目录的插件并启动VIM。当然，有些插件可能有比较复杂的安装过程(比如YouCompleteMe插件)。目前，像Pathogen和Vundle这样的插件管理器是手动安装插件文件的流行替代品，特别是因为插件通常带有多个文件。 vim插件管理器当没有插件管理器时，Vim 用户必须手动下载 tarball 包形式的插件，并将它们解压到 ~/.vim 目录中。在少量插件的时候可以。但当他们安装更多的插件时，就会变得一团糟。所有插件文件分散在单个目录中，用户无法找到哪个文件属于哪个插件。此外，他们无法找到他们应该删除哪个文件来卸载插件。这时 Vim 插件管理器就可以派上用场。插件管理器将安装插件的文件保存在单独的目录中，因此管理所有插件变得非常容易。 介绍几个常见的VIM插件管理器: Pathogen: https://github.com/tpope/vim-pathogen Vundle: https://github.com/VundleVim/Vundle.vim Plug: https://github.com/junegunn/vim-plug Vundle安装Vundle前请先安装vim和git。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384sudo yum install -y vim git# 下载Vundlegit clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim# 配置vundlevim ~/.vimrc#加入以下内容set nocompatible " requiredfiletype off " requiredset rtp+=~/.vim/bundle/Vundle.vimcall vundle#begin()Plugin 'gmarik/Vundle.vim'call vundle#end() " requiredfiletype plugin indent on " required" 设置包括vundle和初始化相关的runtime pathset rtp+=~/.vim/bundle/Vundle.vimcall vundle#begin()" 另一种选择, 指定一个vundle安装插件的路径"call vundle#begin('~/some/path/here')" 让vundle管理插件版本,必须Plugin 'VundleVim/Vundle.vim'" 以下范例用来支持不同格式的插件安装." 请将安装插件的命令放在vundle#begin和vundle#end之间." Github上的插件" 格式为 Plugin '用户名/插件仓库名'Plugin 'tpope/vim-fugitive'" 来自 http://vim-scripts.org/vim/scripts.html 的插件" Plugin '插件名称' 实际上是 Plugin 'vim-scripts/插件仓库名' 只是此处的用户名可以省略Plugin 'L9'" 由Git支持但不再github上的插件仓库 Plugin 'git clone 后面的地址'Plugin 'git://git.wincent.com/command-t.git'" 本地的Git仓库(例如自己的插件) Plugin 'file:///+本地插件仓库绝对路径'Plugin 'file:///home/gmarik/path/to/plugin'" 插件在仓库的子目录中." 正确指定路径用以设置runtimepath. 以下范例插件在sparkup/vim目录下Plugin 'rstacruz/sparkup', &#123;'rtp': 'vim/'&#125;" 安装L9，如果已经安装过这个插件，可利用以下格式避免命名冲突Plugin 'ascenator/L9', &#123;'name': 'newL9'&#125;" 你的所有插件需要在下面这行之前call vundle#end() " 必须filetype plugin indent on " 必须 加载vim自带和插件相应的语法和文件类型相关脚本" 忽视插件改变缩进,可以使用以下替代:"filetype plugin on"" 简要帮助文档" :PluginList - 列出所有已配置的插件" :PluginInstall - 安装插件,追加 `!` 用以更新或使用 :PluginUpdate" :PluginSearch foo - 搜索 foo ; 追加 `!` 清除本地缓存" :PluginClean - 清除未使用插件,需要确认; 追加 `!` 自动批准移除未使用插件"" 查阅 :h vundle 获取更多细节和wiki以及FAQ" 将你自己对非插件片段放在这行之后# 安装插件# vim中:PluginInstall# bashvim _PluginInstall +qall# 查找插件# vim:PluginSearch# 要从vimscripts网站刷新本地的列表:PluginSearch!# 查看已安装插件# vim:PluginList# 更新插件# vim:PluginUpdate Plug它是一个速度非常快的、极简的 vim 插件管理器。它可以并行地安装或更新插件。你还可以回滚更新。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# 下载安装curl -fLo ~/.vim/autoload/plug.vim --create-dirs \ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim# 配置vim ~/.vimrc# 以 call plug#begin(PLUGIN_DIRECTORY) 开始，并以 call plug#end() 结束# 栗子" Specify a directory for plugins" - For Neovim: ~/.local/share/nvim/plugged" - Avoid using standard Vim directory names like 'plugin'call plug#begin('~/.vim/plugged')" Make sure you use single quotes" Shorthand notation; fetches https://github.com/junegunn/vim-easy-alignPlug 'junegunn/vim-easy-align'" Any valid git URL is allowedPlug 'https://github.com/junegunn/vim-github-dashboard.git'" Multiple Plug commands can be written in a single line using | separatorsPlug 'SirVer/ultisnips' | Plug 'honza/vim-snippets'" On-demand loadingPlug 'scrooloose/nerdtree', &#123; 'on': 'NERDTreeToggle' &#125;Plug 'tpope/vim-fireplace', &#123; 'for': 'clojure' &#125;" Using a non-master branchPlug 'rdnetto/YCM-Generator', &#123; 'branch': 'stable' &#125;" Using a tagged release; wildcard allowed (requires git 1.9.2 or above)Plug 'fatih/vim-go', &#123; 'tag': '*' &#125;" Plugin optionsPlug 'nsf/gocode', &#123; 'tag': 'v.20150303', 'rtp': 'vim' &#125;" Plugin outside ~/.vim/plugged with post-update hookPlug 'junegunn/fzf', &#123; 'dir': '~/.fzf', 'do': './install --all' &#125;" Unmanaged plugin (manually installed and updated)Plug '~/my-prototype-plugin'" Initialize plugin systemcall plug#end()# 重载.vimrc以使用vimsource ~/.vimrc# vim:PlugInstall:PlugUpdate:PlugClean# 升级plug# vim:PlugUpgrade vim常见插件 NERDTree： 文档树 YouCompleteMe： 代码补全 Rainbow： 彩虹括号 UndoTree： 关闭vim后也可代码撤回 vim-gitgutter：显示git信息 ctrlp： tagbar：浏览当前文件的标签并获得其结构的概述 k-vimk-vim: https://github.com/wklken/k-vim k-vim是一份很好的vim配置，我个人使用的是这个配置。 代码折叠vim支持多种代码折叠: manual: 手工定义折叠 indent: 用缩进表示折叠 expr: 用表达式来定义折叠 syntax: 用语法高亮来定义折叠 diff: 对没有更改的文本进行折叠 marker: 用标志折叠 k-vim里配置的折叠方法是indent。此缩进方法的操作如下： za: 折叠缩进处的代码 ,zz: k-vim配置的za zM: 关闭所有的折叠 zR: 打开所有的折叠 调试器介绍vim下常用的代码调试器(debugger)。 GDB 官网: https://www.gnu.org/software/gdb/ 教程: https://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/gdb.html GDB(GNU debugger)，是GNU软件系统中的标准调试器。支持C、C++等。 pdb和ipdbPythone调试器: pdb: Python内建的调试器，用法与gdb一样。 ipdb: 一个开源的Python调试器，它和pdb有相同的接口，但是，它相对于pdb，具有语法高亮、tab补全、更友好的堆栈信息等高级功能。 pdb是python的标准库，无需安装就可以使用。而ipdb是一个第三方库，需要使用pip安装。 这两个调试器有两种使用方法： 一是集成在源代码中加入断点，但需要修改源码，麻烦。 1234import ipdbxxxipdb.set_strace() 二是交互式命令调试 12345678910111213141516171819python3 -m ipdb xxx.pyipdb&gt;ipdb&gt; helpDocumented commands (type help &lt;topic&gt;):========================================EOF cl disable interact next psource rv unta clear display j p q s untilalias commands down jump pdef quit source upargs condition enable l pdoc r step wb cont exit list pfile restart tbreak whatisbreak continue h ll pinfo return u wherebt d help longlist pinfo2 retval unaliasc debug ignore n pp run undisplayMiscellaneous help topics:==========================exec pdb ipdb常用命令 命令 描述 b/break 设置断点 tbreak 设置临时断点 cl/clear 清除断点 c/continue 继续执行程序 l/list 查看指定的代码行 ll/longlist 查看整个代码 s/step 执行会进入函数 n/next 执行不会进入函数 a 可列出当前函数的参数 r/return 执行代码直到从当前函数返回 j 忽略某段代码 pp 打印表达式的值 run/restart 重启，重启后断点、设置等会保留 q/quie/exit 中止并退出 h/help 帮助 栗子： 123456789python3 -m ipdb xxx.py# 在第3行设置断点ipdb&gt; b 3# 执行到断点处ipdb&gt; c# 查看2-7行代码ipdb&gt; l 2,7 编码参考： ASCII: https://zh.wikipedia.org/wiki/ASCII Unicode: https://zh.wikipedia.org/wiki/Unicode Unicode计算机处理的是数字(二进制文件)。他们在存储字符时要给每个字符分配一个数值。 早期的编码系统称为 ASCII（美国信息交换标准码）， 一共有128（0-127）个值，每个值用7bit 保存。ASCII可以满足小写、大写、数字标点符号和一些控制字符的处理。 人们曾尝试将ASCII字符扩展到8bit，这种新的被称为“扩充ASCII”的编码一直没有成为国际性标准。 为了克服ASCII和扩充ASCII先天上的不足，Unicode Consortiun（多语言软件生产商群体）创建了一种能够提供广泛字符集的通用编码系统，称为Unicode。 Unicode最初设置为2Byte的字符集。但版本3的Unicode用的是4Byte编码，并且与ASCII与扩充的ASCII完全兼容。 现在被称为Basic Latin（基本拉丁文）的ASCII字符集就是前25位全部置零的Unicode码。现在被称为 Latin-1（拉丁文1）的扩充ASCII字符集就是前24位全部置零的Unicode码。 Unicode中的每个字符或符号由一个32bit数来定义，因此这种编码可以定义高达2的32次方(4 294 067 296)个字符或符号。它的记法使用了十六进制数字，格式如下： 1234U-XXXXXXXX#每个 X 都是一个十六进制的数字#因此，它的数值从U-00000000到U-FFFFFFFF ASCII美国信息交换码（American Standard Code of Information Internet，ASCII）是一种7bit码，设计来为128个大多数是美国英语里使用的符号提供编码。今天的ASCII码已成为Unicode的一部分，它占据了Unicode中的前128个码（00000000-0000007F）。 ASCII的一些特点： space(20-sp)字符，是一个可打印的字符，打印出一个空格 大写字母从(41-A)开始，小写字母从(61-a)开始。按ASCII比较时，大写字母的数值会小于小写字母 大写字母与小写字母在他们的7bit编码中只有1bit不同，A(1000001)，a(1100001)，两者相差(20)十六进制 小写字母并没有紧跟在大写字母后面，这两者之间还有几个标点符号(5B-60) 数字从(30-0)开始 从00到1F这最开始的32个字符加上最后一个字符(7F)全都是非打印字符。字符(00)被用作定界符，已定义字符串的结束。字符(7F)是删除字符，它被某些编程语言用来删除前一个字符。剩下的非打印字符称为控制字符，用于数据通信 ASCII控制字符： 二进制 十进制 十六进制 缩写 Unicode表示法 脱出字符表示法 名称/意义 0000 0000 0 00 NUL ␀ ^@ 空字符（Null） 0000 0001 1 01 SOH ␁ ^A 标题开始 0000 0010 2 02 STX ␂ ^B 本文开始 0000 0011 3 03 ETX ␃ ^C 本文结束 0000 0100 4 04 EOT ␄ ^D 传输结束 0000 0101 5 05 ENQ ␅ ^E 请求 0000 0110 6 06 ACK ␆ ^F 确认回应 0000 0111 7 07 BEL ␇ ^G 响铃 0000 1000 8 08 BS ␈ ^H 退格 0000 1001 9 09 HT ␉ ^I 水平定位符号 0000 1010 10 0A LF ␊ ^J 换行键 0000 1011 11 0B VT ␋ ^K 垂直定位符号 0000 1100 12 0C FF ␌ ^L 换页键 0000 1101 13 0D CR ␍ ^M Enter键 0000 1110 14 0E SO ␎ ^N 取消变换（Shift out） 0000 1111 15 0F SI ␏ ^O 启用变换（Shift in） 0001 0000 16 10 DLE ␐ ^P 跳出数据通讯 0001 0001 17 11 DC1 ␑ ^Q 设备控制一（XON 激活软件速度控制） 0001 0010 18 12 DC2 ␒ ^R 设备控制二 0001 0011 19 13 DC3 ␓ ^S 设备控制三（XOFF 停用软件速度控制） 0001 0100 20 14 DC4 ␔ ^T 设备控制四 0001 0101 21 15 NAK ␕ ^U 确认失败回应 0001 0110 22 16 SYN ␖ ^V 同步用暂停 0001 0111 23 17 ETB ␗ ^W 区块传输结束 0001 1000 24 18 CAN ␘ ^X 取消 0001 1001 25 19 EM ␙ ^Y 连接介质中断 0001 1010 26 1A SUB ␚ ^Z 替换 0001 1011 27 1B ESC ␛ ^[ 退出键 0001 1100 28 1C FS ␜ ^\ 文件分区符 0001 1101 29 1D GS ␝ ^] 组群分隔符 0001 1110 30 1E RS ␞ ^^ 记录分隔符 0001 1111 31 1F US ␟ ^_ 单元分隔符 0111 1111 127 7F DEL ␡ ^? 删除 ASCII可显示字符: 进制 十进制 十六进制 图形 0010 0000 32 20 (space) 0010 0001 33 21 ! 0010 0010 34 22 “ 0010 0011 35 23 # 0010 0100 36 24 $ 0010 0101 37 25 % 0010 0110 38 26 &amp; 0010 0111 39 27 ‘ 0010 1000 40 28 ( 0010 1001 41 29 ) 0010 1010 42 2A * 0010 1011 43 2B + 0010 1100 44 2C , 0010 1101 45 2D - 0010 1110 46 2E . 0010 1111 47 2F / 0011 0000 48 30 0 0011 0001 49 31 1 0011 0010 50 32 2 0011 0011 51 33 3 0011 0100 52 34 4 0011 0101 53 35 5 0011 0110 54 36 6 0011 0111 55 37 7 0011 1000 56 38 8 0011 1001 57 39 9 0011 1010 58 3A : 0011 1011 59 3B ; 0011 1100 60 3C &lt; 0011 1101 61 3D = 0011 1110 62 3E &gt; 0011 1111 63 3F ? 0100 0000 64 40 @ 0100 0001 65 41 A 0100 0010 66 42 B 0100 0011 67 43 C 0100 0100 68 44 D 0100 0101 69 45 E 0100 0110 70 46 F 0100 0111 71 47 G 0100 1000 72 48 H 0100 1001 73 49 I 0100 1010 74 4A J 0100 1011 75 4B K 0100 1100 76 4C L 0100 1101 77 4D M 0100 1110 78 4E N 0100 1111 79 4F O 0101 0000 80 50 P 0101 0001 81 51 Q 0101 0010 82 52 R 0101 0011 83 53 S 0101 0100 84 54 T 0101 0101 85 55 U 0101 0110 86 56 V 0101 0111 87 57 W 0101 1000 88 58 X 0101 1001 89 59 Y 0101 1010 90 5A Z 0101 1011 91 5B [ 0101 1100 92 5C \ 0101 1101 93 5D ] 0101 1110 94 5E ^ 0101 1111 95 5F _ 0110 0000 96 60 ` 0110 0001 97 61 a 0110 0010 98 62 b 0110 0011 99 63 c 0110 0100 100 64 d 0110 0101 101 65 e 0110 0110 102 66 f 0110 0111 103 67 g 0110 1000 104 68 h 0110 1001 105 69 i 0110 1010 106 6A j 0110 1011 107 6B k 0110 1100 108 6C l 0110 1101 109 6D m 0110 1110 110 6E n 0110 1111 111 6F o 0111 0000 112 70 p 0111 0001 113 71 q 0111 0010 114 72 r 0111 0011 115 73 s 0111 0100 116 74 t 0111 0101 117 75 u 0111 0110 118 76 v 0111 0111 119 77 w 0111 1000 120 78 x 0111 1001 121 79 y 0111 1010 122 7A z 0111 1011 123 7B { 0111 1100 124 7C l(管道线) 0111 1101 125 7D } 0111 1110 126 7E ~ ASCII缺点：ASCII的局限在于只能显示26个基本拉丁字母、阿拉伯数目字和英式标点符号。因此现在的软件系统大多采用Unicode。 UTF-8UTF-8（8-bit Unicode Transformation Format）是一种针对Unicode的可变长度字符编码，也是一种前缀码。它可以用来表示Unicode标准中的任何字符，且其编码中的第一个字节仍与ASCII兼容，这使得原来处理ASCII字符的软件无须或只须做少部分修改，即可继续使用。 UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。 UTF-8的编码规则很简单，只有二条: 对于单字节的符号，字节的第一位设为0，后面7位为这个符号的unicode码。因此对于英语字母，UTF-8编码和ASCII码是相同的 对于n字节的符号（n&gt;1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的unicode码 Bash bash与shell管理整个计算机硬件的其实是操作系统的内核(kernel)。这个内核是需要被保护的，所以一般用户就只能通过shell来跟内核通信，让内核达到我们想要达到的工作。 硬件、内核与shell我们必须通过shell，将我们输入的命令与内核通信，让内核可以控制硬件正确无误的工作。 操作系统其实是一组软件。由于这组软件在控制整个硬件与管理系统的活动监测，如果这组软件能被用户随意操作，若用户应用不当，将会使得整个系统奔溃。因为操纵系统管理的就是整个硬件功能，所以当然不能够被随便一些没有管理能力的终端用户随意使用。但我们总是需要让用户操作系统的，所以就有了在操作系统上面发展的应用程序。用户可以通过应用程序来指挥内核，让内核达到我们所需要的硬件任务。 也就是说，只要能够操作应用程序的接口都能够称为shell。狭义的shell指的是命令行方面的软件，包括bash等。广义的shell则包括图形界面的软件。 命令行shell 各Distribution的命令行界面都一样 远程管理非常快速 Linux的任督二脉 系统合法shell与/etc/shells由于shell依据发布者的不同就有许多版本，例如Bourne SHell（sh）、C SHell、K SHell、TCSH等。 Linux默认使用的这一版本就是Bourne Again SHell(bash)，这个shell是Bourne SHell的增强版，也是基于GNU框架下发展出来的。 检查系统可用shell: cat /etc/shells合法shell要写入/etc/shells，系统某些服务在运行过程中，会去检查用户能够使用的shell。 查看用户shell权限： cat /etc/passwd，最后一行便是默认shell。 bash shellbash是GNU计划中重要的工具软件之一，目前也是Linux distributions 的标准shell。bash主要兼容于sh，并且依据一些用户的需求而加强shell 版本。 bash的优点： 命令记忆能力history 命令与文件补全功能tab 命令别名设置功能alias 作业控制、前台、后台控制(job control, foreground, background) 使用前台、后台的控制可以让作业进行得更为顺利。至于作业控制(jobs)的用途更广，可以让我们随时将工作丢到后台中执行，而不怕不小心使用ctrl+c来中断该进程 程序脚本shell script 通配符(Wildcard) type命令type命令用于判断一个命令是內建命令还是外部命令(非bash提供)。 1234567type lstype -t ls#file，外部命令#alias，别名#builtin，內建命令 shell变量变量就是以一组文字或符号等，来替代一些设置或者是一串保留的数据。 变量显示与设置 echo: 显示变量 echo $PATH unset: 取消变量 unset $ZHANG 变量设置规则 变量与变量内容以一个等号=连接，如myname=zhang 等号两边不能有空格符，否则错误 变量名称只能是英文字母和数字，开头字符不能是数字 变量内容若有空格，可使用双引号或单引号 双引号内的特殊符号，保有原本的特性 单引号内的特殊字符则仅为一般字符 转义字符\\，将特殊符号变成一般字符 在一串命令中，还需要使用其他命令，使用反单引号 反引号``内的命令将被优先执行，而其执行结果将作为外部的输入信息 若该变量为了增加变量内容时，可用$变量名称 或${变量}累加内容 myname=${myname}xxx 若该变量需要在其他子进程执行，请以export来使变量变成环境变量 通常大写字符为系统默认变量，自行设置变量可以使用小写字符，方便判断 什么是子进程？在我目前这个shell下，去打开另一个新的shell。新的那个shell就是子进程。在一般状态下，父进程定义的变量是无法在子进程内使用的，要通过export将变量变成环境变量后才可以。 注意单引号、双引号和反引号。 环境变量环境变量可以帮我们达到很多功能，包括主文件夹的变换、提示符的显示、执行文件查找的路径等。 env: 显示环境变量 set: 查看所有变量 包括环境变量和自定义变量 1234567#HOME，用户主目录#SHELL，当前环境使用的shell#HISTSIZE，历史命令#PATH，执行文件查找路径#LANG，语系#$PS1，命令提示符#PS2，第二行提示符 设置$PS1，$PS2: 12345678910111213141516171819202122232425\d #可显示出『星期 月 日』的日期格式，如：&quot;Mon Feb 2&quot;\H #完整的主机名\h #仅取主机名在第一个小数点之前的名字\t #显示时间，24小时格式的『HH:MM:SS』\T #显示时间，为12小时格式的『HH:MM:SS』\A #显示时间，为24小时格式的『HH:MM』\@ #显示时间，为12小时格式的『am/pm』\u #目前使用者的账号名称，如『root』\v #BASH的版本信息\w #完整工作路径名，由根目录写起的目录名称。但家目录会以 ~ 取代\W #利用basename函数取得工作目录名称，所以仅会列出最后一个目录名。\# #下达的第几个命令\$ #提示字符，root时，提示字符为#；否则就是$ `钱字号本身也是变量，代表当前shell的PID --> `echo $?问号也是一个特殊变量，代表上一个运行命令的回传值 —&gt; echo $? 0 命令运行成功 errorcode 命令运行错误 语系变量locale - get locale-specific information. 设置LANG的时候，其他的语系变量就会被这个变量所替代。 变量键盘读取、数组与声明 read： 读取来自键盘输入的变量 declare,typeset: 声明变量类型 变量的默认类型为字符串 若不指定变量类型，则1+2就是一个字符串而不是计算式 数组变量类型 var[1]=’varray1’ var[2]=’varray2’ echo “${${var[1]}, ${var[2]}}” bash shell操作环境自定义我们登录主机的时候屏幕上面会有一些说明文字，并且登录的时候还可以给用户提供一些信息或者欢迎文字，或环境变量和命令别名等。 路径与命令查找顺序命令的运行顺序： 以绝对/相对路径执行命令 由alias找到该命令来执行 由bash内置的（builtin）命令来执行 通过$PATH这个变量的顺序找到的第一个命令来执行 bash登录与欢迎消息 /etc/issue —&gt; 终端登录消息 CentOS Linux 7 (core)….. /etc/motd —&gt; 用户登录后取得一些消息 Welcome to aliyun ECS bash环境配置文件操作系统有一些环境配置文件的存在，让bash在启动时直接读取这些配置文件，以规划好bash的操作环境。这些配置文件又可以分为全体系统的配置文件以及用户个人偏好配置文件。 命令别名、自定义的变量在你注销bash后就会失效。所以你想要保留你的设置，就得要将这些设置写入配置文件才行。 login shell 取得bash需要完整的登录流程 non-login shell 取得bash接口的方法不需要登录 bash shell快捷键 Ctrl+C —&gt; 终止当前命令 Ctri+D —&gt; 输入结束(EOF) Ctri+M —&gt; Enter Ctrl+S —&gt; 暂停屏幕输出 Ctrl+Q —&gt; 恢复屏幕输出 Ctrl+U —&gt; 在提示字符下，将整列命令删除 Ctrl+Z —&gt; 暂停目前命令 通配符与特殊符号通配符： 符号 说明 * 代表0-∞个 任意字符 ? 代表一定有一个 任意字符 [-] 中括号内任一字符 非中括号内字符 bash常见特殊符号，理论上文件名不要用到上述字符。 符号 说明 # 注释 \ 转义字符 1 管道线 ; 连续命令分隔符 ~ 用户主目录 $ 取变量前导符 &amp; 将命令放入后台 ! 逻辑非 / 目录符号 &gt;, &gt;&gt; 输出定向 &lt;, &lt;&lt; 输入定向 ‘’ 单引号 “” 双引号 () 子shell {} 命令区块混合 重定向数据流重定向就是将某个命令执行后应该要出现在屏幕上的数据传输到其他的地方，如文件或设备。 标准输入(stdin)，代码为0，使用&lt;或者&lt;&lt; 标准输出(stdout)，代码为1，使用&gt;或者&gt;&gt; 标准错误(stderr)，代码为2，使用2&gt;或者2&gt;&gt; &gt;表示以覆盖方式写入，&gt;&gt;表示以追加方式写入 管道管道命令使用 “ | “ 这个界定符号。管道命令” | “ 仅能处理经由前面一个命令传来的正确信息。所以对stderror没有直接处理能力。 在每个管道后面接的第一个数据必定是命令，而且这个命令必须要能够接收standard input的数据才行，这样的命令才可以是管道命令。 Bash特殊符号在编写shellscripts的时候，特殊符号也有其重要的功能。 符号 描述 栗子 #! shellban，申明脚本所使用的shell #!/bin/bash \ 转义字符 \n l 管道 stdout l grep &gt;,&gt;&gt; 输出定向 &gt; 1.txt &lt;,&lt;&lt; 输入定向 &lt; 1.txt 2&gt; 错误定向 2&gt; error.txt ; 连续命令分隔符 cmd1;cmd2 &amp;&amp; 与，只有当前命令完成后才执行后一个命令 cmd1 &amp;&amp; cmd2 ll 或，或此或彼 cmd1 ll cmd2 ~ 用户家目录 cd ~ # 注释符 #comments $ 取用变量前导符 $PATH或${PATH} &amp; 工作控制，将命令放入后台(bg) command&amp; * ? [] [-] 通配符 .sh ?.sh [a-z].txt zhang.txt ! 逻辑非 != = 两边无空格 赋值符号 name=zhang = 两边有空格 比较符号 if [ $name = zhang ] $0 执行文件脚本名 /root/zhang.sh $1, $2 第1,2个…变量 ./zhang.sh start $# 参数个数 if [ $# -ne 2 ]；then echo &#39;Usage: $0 arg1 arg2&#39; $@ 代表$1,$2,$3…之意 每个变量是独立的 $* 代表$1c$2c$3…之意 c为分割字符，默认为空格键 $? 命令状态码，成功为0 $? $$$$ 当前shell的PID echo $$ ‘单引号’ 单引号内特殊字符仅为一般字符 echo &#39;$host&#39;--$host “双引号” 双引号内特殊符号，可保有原本特性 echo &quot;$host&quot; --localhost `反引号` 运行命令 反引号内命令先执行 () 以子shell方式执行 $(date) {} 命令区块的组合 PS1 命令提示符 $PS1 PS2 第二行以后的提示字符 $PS2 shift 移动参数 shift后面可以接数字，代表拿掉最前面的几个参数 set 查看所有变量 set unset 取消变量 unset name，没有$符号 export 使某变量成为环境变量 export name，没有$符号 source source命令通常用于重新执行刚修改的初始化文件，使之立即生效，而不必注销并重新登录 source file shell scriptshell script 有点像早期的批处理程序，即将一些命令汇整起来一次执行.但shell script拥有更强大的功能，可以进行类似程序(program)的编写，并且不需要经过编译(compile)就能执行。 shell script介绍shell script是利用shell的功能写的一个程序(program)。这个程序是使用纯文本文件，将一些shell的语法与命令(含外部命令)写在里面，搭配正则表达式、命令管道与数据流重定向等功能，还提供了数组、循环、条件与逻辑判断等重要功能， 以达到我们所想要的处理目的。 shell script用在系统管理上面是很好的一项工具，但用在处理大量数值运算上就不够好。因为shell script的速度较慢，且使用的cpu资源较多，造成主机资源的分配不良。 使用shell script的优势： 自动化管理的重要依据 追踪与管理系统的重要工具 简单入侵检测功能 连续命令单一化 简单的数据处理 跨平台支持与学习历程较短 shell script注意事项： 命令的执行是从上到下从左到右，分析与执行 命令的执行中：命令、参数间的多个空白都会被忽略掉 空白行也将被忽略，tab按键所得的空白同样视为空格键 读取到一个Enter符号(CR)，就尝试开始执行该行命令 一行内容太多，则可以使用\[Enter]来扩展到下一行 任何加在#后面的内容都将被视为注释而被忽略 shell script文件的执行方式： 直接命令执行 .sh文件必须具有可读和可执行权限，使用绝对路径或相对路径来执行 以bash进程来执行 bash xx.sh sh xx.sh shell script执行方式的区别： 直接执行，script是在子进程的bash中执行的。当子进程完成后，子进程内的各项变量或操作将会结束而不会传回到父进程中。 source来执行，在父进程中执行 编写一个shell script一个良好的shell script应该纪录好如下信息： script的功能 script的版本信息 script的作者 script的版权声明方式 script的History（历史记录） script内较特殊的命令，使用绝对路径的方式来执行 script执行时需要的环境变量预先声明与设置 在较为特殊的程序代码部分，建议务必要加上批注说明 shell script判断式当我要检测系统上某些文件或相关属性时，使用test命令。 1test -e /root/test.txt &amp;&amp; echo 'Exist' || 'Not exist' 文件类型判断： 选项 说明 -e 是否存在 -f 是否存在文件 -d 是否存在目录 -b 是否存在block device -c 是否存在character device -S 是否存在Socket文件 -p 是否存在pipe文件 -L 是否存在链接文件 文件权限判断： 选项 说明 -r 是否可读 -w 是否可写 -x 是否可执行 -u 是否具有SUID -g 是够具有SGID -k 是否具有Sticky bit -s 是否为非空白文件 文件之间的比较： 选项 说明 -nt newer than -ot old than -ef 是否为同一个文件 整数之间的比较： 选项 说明 -eq equal -ne not equal -gt greater than -lt less than -ge greater or equal -le less or equal 字符串之间的比较： 选项 说明 -z 是否为空 -n 非空 str1 = str2 是否相等 != 不等于 多重条件判断： 选项 说明 -a and -o or ! 非 判断符号[]: 如果需要在bash中使用中括号来作为shell的判断式时，必须要注意中括号的两端需要有空格符来分隔。 中括号内的变量，每个最好都用双引号括起来 中括号内的常量，最好都以单或双引号括起来 shell script的默认变量: $0,$1…12/root/test.sh opt1 opt2 opt3 $0 $1 $2 $3 执行文件的脚本名就是$0 文件后接的第一个参数就是$1，以此类推 $#，表示参数个数 $@，表示”$1”, “$2”… shift，参数变量号码偏移 shift n，代表拿掉前面几个参数的意思 条件判断语句 if…then语句if…then 是最常见的条件判断式。 单层条件判断： 123if [ confition ]; then xxxfi 多层条件判断： 12345if [ condition ]; then xxx;else xxx;fi 1234567if [ confition1 ]; then xxx;elif [ condition2 ]; then xxx;else xxx;fi case…esac语句有多个既定变量内容，那么只需要针对这几个变量来设置状况就好。 12345678910111213141516171819202122232425262728293031case $变量名 in"$var1") xxx ;;"$var2") xxx ;;*) xxx ;;esac####栗子#/etc/init.d/networkcase "$1" instart) xxx ;;stop) xxx ;;restart) xxx ;;status) xxx ;;esac function功能什么是函数？函数可以在shell script 当中做出一个类似自定义执行命令的东西。最大的动能是，可以简化很多的程序代码。 因为shell script的执行方式是由上而下、由左而右。因此在shell script当中，function的定义一定要在程序的最前面，这样才能够在执行时被找到可用的程序段。 1234567891011121314151617181920vim func.shfunction fname () &#123;&#125;####栗子function Zhang() &#123; echo $1 $2&#125;Zhang "$1" "$2"#执行sh func.sh aaa bbb 循环(loop)语句 while do done(不定循环)while是当condition条件成立时，就进行循环，condition条件不成立就停止。 1234while [ condition1 ]do xxxdone until do done(不定循环)until是当condition条件成立时，终止循环；否则就持续进行循环的循环。 1234until [ condition ]do xxxdone for do done(固定循环)1234567891011for i in con1 con2 con3 ...do xxxdone####栗子for i in 192.168.1.&#123;1,2,3&#125;do ping -c 1 $idone for do done的数值处理： 1234567891011for ((初始值;限制值；步长))do xxxdone####栗子for ((i=0;i&lt;10;i++))do echo $idone shell script的追踪与调试(debug)最好在shell script执行之前先行调试。 123456789sh [-nvx] xxx.sh#-v 运行脚本前，先将脚本内容输入到屏幕#-n 仅查询语法问题#-x 边显示边执行当然也可以把这几个调试参数写到shellbang中#!/bin/bash -x 小试牛刀简介123456789101112#bash(Bourne Again Shell)，shell环境使得用户能与操作系统的内核进行交互操作#!/bin/bash#date#descriptioncmd1; cmd2cmd3#sh /path/xx.sh#Bash还有一个历史记录文件 ~/.bash_history 终端打印(echo)12345678910111213141516171819202122#终端作为交互式工具，用户可以通过它与shell环境进行交互echo '$var'echo $varecho -e "1\t2\t3"echo -e '\e[1;31m Red color \e[0m' #彩色echo &#123;1..10&#125; #输出1到10echo &#123;A..H&#125; #for i in &#123;a..z&#125;cat &lt;&lt; EOF112233EOF# \转义字符printf "%-5s %-10s $-4.2f\n" 001 Zhang 56.789#格式替代符%s %d %c %f, -左对齐 玩转变量和环境变量123456789101112131415161718192021#Bash中，每一个变量默认值值都是字符串形式#环境变量和自定义变量echo $SHELLecho $UIDvar=value #这是赋值#var = value这是相等操作echo $varecho $&#123;var&#125;echo $&#123;#var&#125; #字符数#export用来设置环境变量，此后，任何shell中的程序都会继承环境变量ZHANG=Gentlemanexport ZHANGPATH="$PATH:/home/zhang/bin"export $PATH 通过shell进行数学运算1234567891011121314151617181920212223242526272829303132#let, expr, bc, [], (())#要注意默认是字符串类型哦n1=1;n2=2let sum=n1+n2let n1++;let n2-=1sum=$[ n1 + n2 ]sum2=$(( sum + 3 ))sum=`expr 3 + 4`#浮点计算 bcecho "8 * 1.1" | bc#设置小数点精度echo "scale=2; 3/8" | bc#进制转换num=100echo "obase=2; $num" | bcnum=1100100echo "obase=10; ibase=2; $num" | bc#平方和平方根echo "sqrt(100)" | bcecho "10^2" | bc 文件描述符重定向12345678910111213141516#最常用的文件描述符是 stdin(0), stdout(1), stderr(2); 通过内容过滤将输出重定向到文件echo "This is a sample text 1" &gt; temp.txt #覆盖echo "This is sample text 2" &gt;&gt; temp.txt #追加ls + &gt;stdout.txt 2&gt;stderr.txtcmd 2&gt;&amp;1 /dev/null == com &amp;&gt; /dev/null #null设备也被称为黑洞#当一个command发生错误并退回时，它会返回一个非0的状态码echo $?#tee命令，一方面可将数据重定向到文件，另一方面还可提供一份重定向数据的副本作为后续命令的stdin#tee默认覆盖文件，-a选项追加cat temp.txt | tee tee.txt | cat -n 数组和关联数组123456789101112131415161718192021#数组借助索引将多个独立的数据存储为一个集合#普通数组只能使用整数作为数组索引，而关联数组可以使用字符串作为数组索引#还可将数组定义成一组索引-值(index-value)arr=(1 two 3 four 5)echo $&#123;arr[0]&#125;arr[0]=Oneindex=3echo $&#123;arr[$index] #arr[3]echo $&#123;arr[*]&#125;echo $&#123;#arr[*]&#125; #arr-length#关联数组可用任意文本作为数组索引declare -A ass_arrass_arr=([index1]=val1 [index2]=val2 ...) #内嵌索引-值ass_arr[index3]=val3 #独立索引-值echo $&#123;!ass_arr[*]&#125; #列出数组索引 别名(alias)123456789101112#alias作用是暂时的，关闭终端后别名就失效；#为使别名一直保持，可将其写入 ~/.bashrc，因为每一个新的shell都会执行~/.bashrc中的命令#新设置的别名将取代已有别名alias vi=vim;unalias viecho "alias ll='ls -l --color=auto'" &gt;&gt; ~/.bashrc#\对别名命令进行转义，执行原本的命令。避免攻击者利用别名将某些特权命令替换成别有用心的命令\vi test.sh 获取、设置日期和延时(date)12345678910111213141516171819202122232425262728293031#很多应用程序需要以不同的格式打印日期，设置日期和时间，以及根据日期和时间执行操作;#延时通常用于在程序执行过程中提供一段等待时间;#在Unix-like系统中，日期被存储为一个整数，其大小为世界标准时间1970年1月1日0时0分0秒起所流逝的秒数；#这种计时方式被称之为 纪元时或Unix时间；#通过纪元时间，可知道两个日期之间相隔了多少秒#编写以循环方式运行的监视脚本时，设置时间间隔是必不可少的date +%s#!/bin/bashstart=$(date +%s)commandssleep 1end=$(date +%s)diff=$((end - start))echo "$diff seconds"#显示指定时间date +%F -d -1daysdate +%H -d -3hours#将标准时间转换为原子时间date -d '2018-02-07 14:05:53' +%s1517983553#将原子时间转换为标准时间date --date='@1517983553'Wed Feb 7 14:05:53 CST 2018 调试脚本(sh)12345#调试功能能在出现一些异常情况时生成运行信息#!/bin/bash -xvsh -xsh -n 函数和参数(function)123456789101112131415161718192021function fname()&#123;statements&#125;fname()&#123;echo $1, $2 #访问第参数1和参数2,$n第n个参数echo "$@" #以列表的形式一次性打印所有参数echo "$*" #类似于$@，但参数被作为单个实体return 0 #f返回值&#125;fname 1 22 333 #返回上面定义的变量#递归函数，能够调用自身，不断地生成新的进程，最终会造成xx#导出函数，使用export导出，这样函数作用域就可以扩展到子进程export -f fname#读取命令返回值echo $? 读取命令序列输出(` `, $() )12345678910#输入通常是stdin，输出stderr或stdout,这些命令称为 过滤器(filter)。我们使用 管道(pipe) 来连接每一个过滤器cmd1 | cmd2 | cmd3#子shell，子shell生成独立的进程，不会对当前shell有任何影响，所做改变仅限于子shell内zhang=$(ls | cat -n)#反引用zhang=`ls | cat -n` 读取字符(read)123456789101112131415161718#read是一个重要的从标准输入中读取文本的命令#可以使用read以交互的形式来读取用户的输入read -n 5 zhang #读取字符数echo $zhangread -s passwd #不回显echo $passwdread -t 5 zhang #超时时间echo $zhangread -p zhang #显示提示信息echo $zhangread -d ":" zhang #定界符结束输入123：echo $zhang 字段分隔符和迭代器12345678910111213141516171819#内部字段分隔符(Internal Field Separator, IFS)是shell中的一个重要概念#IFS的默认值为空白字符(换行符、制表符、空格)awk -F: '&#123;print $1,$3&#125;' /etc/passwd #IFS=":"#对一些列值进行迭代，循环非常有用for i in &#123;1..10&#125;docmddonewhile conditiondocmddoneuntil conditiondocmddone 比较与测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#程序中的流程控制是由比较和测试语句来处理的if condition1 || condition2then cmd1elif condition3 &amp;&amp; condition4then cmd2else cmd3fi#算术比较if [ $num -ge 10 -a $num -lt 20 ]-eq-gt-ge-lt-le-a-o#文件系统相关if [ -f $file1 -o -x $file2]-x-w-r-f-d-e-b #block-l#字符串比较[[ $str1 = $str2]]= #=号旁有空格--是比较关系；=号旁没空格，是赋值语句!=&gt;&lt;-z #空字符-n #非空字符#使用test命令来执行条件检测if [ $num -eq 0 ] -- if test $num -eq 0 命令之乐简介各种命令可谓Unix-Like系统中优美的部分，它能帮我们搞定各种繁杂的任务。一旦你尝试过Linux提供的这些利器，你一定会感到惊讶：以前没有这些命令的时候，自己是什么熬过来的。最钟爱的莫过于 grep, awk, sed, find 命令了！ 本章将会为你介绍一些最有趣同时也是最实用的命令。 用cat进行拼接12345678#cat命令通常用于读取、显示或拼接文件内容，不过它所具备的能力远不止此#cat(concatenate, 拼接)cat file1 file2 ···echo "Ahaha" | cat - file1 file2 #-指stdin文本文件名cat -s file3 -- cat file3 | tr -s '\n' #压缩空白行cat -T test.py #将制表符显示为 ^I, 避免制表符和连续空格误用, 产生错误缩进cat -n file4 #显示行号 录制与回放终端会话(script)当你需要准备一个命令行教程时，如果将我们输入命令后的一切按照先后次序记录下来，再进行回放，是不是很nice！通过 script, scriptreplay 命令, 把终端会话记录到文件，并回放。 123456789#-t,将时间数据输出到标准错误； -a,追加输出script -t 2&gt; timing.log -a output.session #两个文件随意取名, 如不将错误重定向会显示在屏幕上导致很乱输入命令cmd2···exit #退出录制scriptreplay -t timing.log output.session #播放 文件查找与文件列表(find)find 是Unix/Linux命令行工具箱中最棒的工具之一。find 命令沿着文件层次结构向下遍历，匹配符合条件的文件，并执行相应的操作。 find - search for files in a directory hierarchy 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#基于文件名及正则表达式搜索find /home/zhang #列出/home/zhang目录及其子目录线所有文件和文件夹find /home/zhang -name "*.txt"find . -name "*.sh" -o -iname "zhang*" #匹配多个find /home/zhang -path "201710*" #-path将文件路径作为一个整体进行匹配find . -regex ".*\(\.txt|\.[0-9]+\)$" #匹配以.txt或数字结尾的文件#使用-maxdepth, -mindepth参数，来限制find的遍历深度#-type, 根据文件类型搜索。 f(普通文件)，d(目录)，b(块设备)，l(符号链接)，s(套接字)等find /home -maxdepth 1 -type f(d) #参数顺序也会影响find的查找效率#根据文件类型搜索find /dev -type b #查看/dev及其子目录下设备文件find / -maxdepth 1 -type l #查找/下链接文件#根据文件时间进行搜索#Unix/Linux文件系统中的每一个文件都有三种时间戳(timestamp),-表示小于，+表示大于#Unix中并没有所谓的 "创建时间" 的概念#访问时间(-atime,以天为单位； -amin,以分钟为单位):用户最近一次访问文件时间；#修改时间(-mtime,以天为单位； -mmin,以分钟为单位):文件最后一次修改时间；#变化时间(-ctime,以天为单位； -cmin,以分钟为单位):文件元数据(如权限，所有权)最后一次变化时间；find /home/zhang -type f -mtime 7 #7天前被修改的普通文件find /home/zhang -type f -amin -10 #搜索10分钟内被修改的普通文件find . -type f -newer file1.txt #找出比file1.txt新的文件#基于文件大小的搜索#b(块，512字节), c(字节), w(字，2字节), k(千字节), M(兆字节), G(吉字节)find . -type -f -size +100k#删除匹配的文件find . -type f -name "*.swp" -delete#基于文件权限和所有权的匹配find . -type f -perm 644find /var/apache -type f -name "*.php" -perm 644 #搜索基于权限的文件find /var -maxdepth 2 -type f -user zhang #搜索基于用户的文件#执行命令或动作#find命令可以借助-exec与其他命令进行结合#&#123;&#125;是一个特殊字符串，将替换为相应文件名find . -type f -perm 764 -user zhang -exec chmod 644 &#123;&#125; \; #将所属用户zhang，权限764的文件权限修改为644find . -type f -mmin +30 -name "*.txt" -exec cp &#123;&#125; &#123;&#125;.old \; #复制最近30内修改的名字为.txt的文件#-exec结合多个命令#我们无法在-exec参数中直接使用多个命令，不过我们可以把多个命令写到一个shellscript中，然后执行-exec ./test.sh &#123;&#125; \;find . -type f -name "*.sh" -mmin -10 -exec sh &#123;&#125; \;#让find跳过特定目录-prune#利用find搭配tar打包#查找7天内的文件并打包#建议使用绝对路径，管道无效，所有要定向到文件find /dir/path/zhang -type -f -mmtime -7 &gt; /dir/path/zhang/zhang.list &amp;&amp; tar -T /dir/path/zhang/zhang.list -czvf /dir/path/zhang123.tar.gz#检查是否正确tar -tf /dir/path/zhang123.tar.gz#不能使用find -exec tar，这样打包以后只有最后一个文件 利用stat命令查看atime, mtime, ctimestat - display file or file system status 12345stat 1.txt#Access:#Modify:#Change: 利用touch命令修改atime, mtime, ctimetouch - change file timestamps 1234#-a change only the access time#-m change only the modification time#-d instead of current time#-t instead of current time 玩转xargsxargs - build and execute command lines from standard input 1234567891011121314151617181920212223242526272829303132#xargs能够处理stdin并将其转换为特定命令的命令行参数#也可以将单行或多行输入文本转换成其他格式(如多行变单行)cmd | xargs#将多行输入转换为单行输出echo -e "1\n2\n3" | xargs #将换行符替换为空格#将单行输入转换成多行输出echo "1 2 3" | xargs -n 1 #每行一个参数echo "hahaZhahaZhahaZhaha" | xargs -n 2 -d Z #-d指定分隔符#读取stdin，将格式化参数传递给命令cat test.txt | xargs -n 1 ./zhang.sh #zhang.sh arg1; zhang.sh arg2... 每次提供一个参数cat test.txt | xargs -n X ./zhang.sh #X为参数个数，一次提供全部参数#指定替换字符串cat test.txt | xargs -I &#123;&#125; ./zhang.sh &#123;&#125;#结合find使用xargsfind . -type f -name "*.txt" -print0 | xargs -0 ls #-print0无换行输出, -0将\0作为输入界定符#统计某文件行数find /path -type f -name "*.c" -print0 | xargs -0 wc -l#结合stdin，运用while和子shellcat file.txt | while read arg; do cat $arg; done == cat file.txt | xargs - &#123;&#125; cat &#123;&#125;cmd0 | (cmd1; cmd2; cmd3) | cmd4 #子shell 用tr进行转换tr - translate or delete characters 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#tr命令经常用来编写优美的单行命令#tr可对来自stdin的字符 进行替换、删除以及压缩echo "AH WONDERFUL" | tr 'A-Z' 'a-z' #转换大小写echo "AH WONDERFUL" | tr 'A-Z' 'a-b' --&gt; ab bbbbbbbbb#tr [option] set1 set2#如果两个字符集长度不相等，那么set2会不断重复其最后一个字符，直到长度与set1相同echo 12345 | tr '0-9' '9876543210' #数字加密echo 87654 | tr '9876543210' '0-9' #数字解密echo 'He is a cool boy, and she is a beautiful girl' | tr 'A-Za-z' 'NOPQRSRUVWXYZABCDEFGHIJKLMnopqrstuvwxyzabcdefghijklm' #加密echo 'Ur vf n pbby obl, naq fur' | tr 'NOPQRSRUVWXYZABCDEFGHIJKLMnopqrstuvwxyzabcdefghijklm' 'A-Za-z' #解密cat 1.txt | tr '\t' ' ' #将制表符转换为空格#删除字符echo "Hello 530 World" | tr -d '0-9' #-d删除，删除数字Hello Worldecho "Hello 520 World" | tr -d -c '0-9' #-c补集 520#压缩字符，将连续的重复字符压缩为单个字符echo "GNU's not Unix" | tr -s ' ' #-s压缩，压缩空格GNU's not Unixecho -e "1\n2\n3\n4\n5" &gt; sum.txtcat sum.txt | echo $[ $(tr '\n' '+') 0 ] -- echo $[1+2+3+4+5+0]#tr字符类\a 终端鸣响\b 退格\f 换页\n 换行\r 回车\t 水平制表符\v 垂直制表符string1-stringN #从字符1到字符N升序过程中的所有字符[字符*次数][:alnum:] #所有字母和数字[:alpha:] #所有字母[:digit:] #所有数字[:lower:] #所有小写字母[:upper:] #所有大写字母[:graph:] #所有可打印字符，不含空格[:print:] #所有可打印字符，包含空格[:blank:] #所有水平排列的空白字符[:cntrl:] #所有控制字符[:punct:] #所有标点字符[:space:] #所有空白字符[:xdigit:] #所有十六进制数[=字符] #指定字符 校验和 与 核实文件完整性(md5sum)12345678910111213141516171819202122#校验和(checksum)程序从文件中生成校验和密钥，然后利用校验和密钥核实文件的完整性#校验和对于编写备份脚本或系统维护脚本非常重要，因为它们都会涉及通过网络传输文件#通过使用校验和核实，我们就可以识别那些在网络传输过程中出现损坏的文件，并重传，从而确保数据完整性#校验和对于核实数据完整性非常有用#广泛使用的校验和技术有：md5sum, sha1sum#对单个文件进行校验md5sum sum.txt &gt; sum.md5#302c28003d487124d97c242de94da856 sum.txtmd5sum -c sum.md5 #-c检查#sum.txt: 确定#对目录进行校验#对目录计算校验和意味着我们需要对目录中的所有文件以递归的方式进行计算yum install -y md5deepmd5deep -r ./dir &gt; dir.md5 #recursive递归md5sum -c dir.md5#可以将测试dir下某个文件更改一下，校验的时候会报错 排序、单一、重复(sort,uniq)12345678910111213141516171819202122232425262728293031#sort - 对文本文件进行行排序#uniq - 删除排序文件中的重复行echo -e "333\n1" &gt; 1.txt; echo -e "22\n22" &gt; 2.txtsort 1.txt 2.txt -o ./sorted.txt#1#22#22#333cat sortec.txt | uniq#1#22#333sort -n #按数字进行排序sort -r #逆向排序sort -M #按月份排序sort -C #检查是否排序sort -b #忽略空白#依据键或列进行排序sort -k 2 data.txt #依据第二列来排序#uniq要么使用管道，要么使用排过序的文件作文输入uniq -u sorted.txt #只显示唯一的行(即没有重复出现的行)uniq -d sorted.txt #只显示重复的行uniq -s 2 -w 2 sorted.txt #-s忽略前2个字符，-w指定用于比较的最大字符数 临时文件命名、随机数123456#在编写shell脚本时，我们经常需要存储临时文件。最适合存储临时数据的位置是 /tmp#/tmp目录中的内容会在系统重启后被清空filename=$RANDOM #RANDOM返回一个随机数filename2=$$ #当前shell的PIDfilename3=$((date +%F)) #通过日期命令 分割文件和数据(split)123456789101112131415161718192021#某些情况下，需要把文件分割成多个更小的片段dd if=/dev/zero bs=100k count=1 of=./data.file #生成一个大小100k内容全是0的文件split -b 20k data.file #-d指定分割大小#data.file xaa xab xac xad xae,这五个文件都为20k#我测试了一下，几个文件加起来数据没变，几个文件总行数没变#单位有 k, m, G, c(byte), w(word)#-d以数字为后缀， -a指定后缀长度split data.file -b 20k -d -a 2 spt #增加前缀名'spt'#data.file spt00 spt01 spt02 spt03 spt04split -l 10 data.file #-l按行数来分割文件#split只能根据大小或行数分割文件#csplit可以根据文件本身特点进行分割-f #指定分割后文件前缀-n #指定分割后文件后缀数字个数-b #指定后缀格式 根据扩展名切分文件名12345678910111213141516171819202122232425262728#借助%操作符将名称从 “名称.扩展名” 格式中提取出来file="zhang.txt"name1=$&#123;file%.*&#125; #删除位于%右侧的通配符(.*)所匹配的字符串，通配符从右向左进行匹配#zhang#*号通配符，.号#%属于非贪婪匹配(non-greedy),它会匹配通配符最短结果#%%属于贪婪匹配(greedy)，它会匹配符号条件的最长字符串name2=$&#123;file#*.&#125; #删除位于#右侧的通配符(*.)所匹配的字符串，通配符从左向右进行匹配#txt# #属于非贪婪匹配# ##属于贪婪匹配#栗子URL=“www.google.com”echo $&#123;URL%.*&#125; #非贪婪匹配，移除最右边.及其后面内容www.googleecho $&#123;URL%%.*&#125; #贪婪匹配wwwecho $&#123;URL#*.&#125; #非贪婪匹配，移除最左边.及其前面内容google.comecho $&#123;URL##*.&#125; #贪婪匹配com 批量重命名和移动综合运用find、rename、mv命令。 拼写检查与词典操作123456#Linux大多数发行版都含有一份词典文件，另外还有一个被称为aspell的拼写检查命令#words --&gt; /usr/share/dict/linux.wordsgrep "^good" /usr/share/dict/linux.wordsaspell 交互输入自动化1234567891011121314151617181920212223242526272829303132#写一个读取交互式输入脚本vi jiaohu.sh#!/bin/bashread -p "Input a number:" numread -p "Input name:" nameecho "You have enterd number:$num, name:$name"echo -e "1\nzhang" | ./jiaohu.shYou have entered number:1, name:hello#orecho -e "1\nzhang" &gt; input.txt./jiaohu.sh &lt; input.txt#交互式输入自动化#用expect实现自动化yum install -y expectvim auto_expect.sh#!/bin/expectspawn ./jiaohu.sh #spawn指定需要自动化哪一个命令expect "Input a number:" #expect提供需要等待的消息send "1\n" #send是要发送的消息expect "Input name:"send "zhang"expect eof #expect eof指明命令交互结束./auto_expect.sh 以文件之名简介Unix将操作系统中的一切都视为文件。 生成任意大小的文件(dd)由于各种原因，可能需要生成一个包含随机数据的文件。 12345#dd命令会克隆给定的输入内容，然后将一模一样的副本写到输出#如果不指定if，dd会从stdin中读取输入；如果不指定of，dd会输出到stdout#/dev/zero是一个字符设备，它会不断返回0值字节(\0)dd if=/dev/zero of=junk.data bs=1M count=1 文本文件的交集与差集12345678910111213#comm命令用于两个文件之间的比较#交集(intersection),差集(set difference), 求差#comm必须使用排过序的文件作为输入echo -e "1\n2\n3" &gt; A.txt &amp;&amp; echo -e "3\n2\n3" &gt; B.txtsort -n A.txt -o A.txt &amp;&amp; sort -n B.txt -o B.txtcomm A.txt B.txt#输出第一列为A独有，第二列为B独有，第三列为交集comm A.txt B.txt -1 -2#-1从输出中删除第一列，-2删除第二列，-3删除第三列 查找并删除重复文件1234#重复文件指的是那些虽然名字不同但内容却一模一样的文件ls -lS #以文件大小排序，识别大小相等的文件md5sum #接下来计算这些文件的校验和 创建长路径目录1mkdir -p /home/zhang/1/22/333 2&gt;/dev/null 文件权限、所有权和粘滞位123456789101112131415161718192021222324252627282930313233343536373839404142#用户(user)，用户组(group)，其他用户(other)ll ./*#d目录，c字符设备，b块设备，l符号链接，s套接字，p管道，-普通文件#用户还有一个称为setuid(S)的特殊权限，它出现在用户的x位置#setuid权限允许用户以其拥有者的权限来执行可执行文件，即便这个文件是由其他用户运行的-rwSrw-r--#组也拥有一个setgid(S)权限，它出现在组的x位置#它允许以同该目录拥有者所在组相同的有效组权限来运行可执行文件-rwxrwSr--#目录有一个特殊权限，叫做粘滞位(sticky bit)(T或t)，出现在其他用户的x位置#当一个目录设置了粘滞位，只有创建该目录的用户才能删除目录中的文件,即便group和other有w权限-rwxr--rwTchmod u=rwx g=rw o=r file1chmod u+x g-w file2chmod 744 file3chmod a+x . -R #以递归方式设置权限chown user.group . -R #以递归方式设置所有权chmod a+t dir1 #设置粘滞位chmod +s fiel4chown root.root file4chmod +s file4./file4 #每次file4都是以root运行#setuid的使用不是无限制的，它只能应用在Linux ELF格式二进制，而不能用于脚本文件。 创建不可修改文件123456#不可修改(immutable),是保护文件不被修改的安全手段之一。#一旦文件被设置为不可修改，任何用户(包括root)都不能修改，除非将其不可修改属性移除chattr #修改文件在Linux第二扩展文件系统(E2fs)上的特有属性chattr +i file1 #这样就无法删除file1chattr -i file1 批量生成空白文件123456789#touch命令可用来生成空白文件，如果文件存在，则可以用它修改文件的时间戳for name in &#123;1..100&#125;.txt;dotouch $namedonetouch -a/-m #更改文件访问/修改时间touch -d "Thu Oct 31 14:20:13 CST 2017" file1 #指定特定时间戳 查找符号链接及其指向目标1234567#符号链接(软链接)只不过是指向其他文件的指针ln -s /usr/bin /binls -l / | grep "^l"find / -maxdepth 1 -type lreadlink /bin #找出链接目标 列举文件类型统计信息1234#在Unix/Linux系统中，文件类型并不是由文件扩展名决定的file /etc/passwdfile -b /etc/passwd 环回文件与挂载(mount)1234567891011#环回文件系统是指那些在文件中而非物理设备中创建的文件系统dd if=/dev/zero of=loopback.file bs=1G count=1mkfs.ext4 loopback.filemount -o loop loopback.file /mnt/loopback #-o loop来挂载环回文件df -humount /mnt/loopback#将ISO文件作为环回文件挂载mount -o loop linux.iso /mnt/iso 生成ISO文件以及混合ISO12345678#可引导光盘自身具备引导能力，也可以运行操作系统或其他软件。不可引导光盘则做不到这些。cat /dev/cdrom &gt; /dev/sdc #sdc指U盘dd if=/dev/cdrom of=/dev/sdc #将ISO写入usb存储设备mkisofs -V "Label" -o /dev/sdc /dev/cdromcdrecord -v dev=/dev/cdrom image.iso 查找文件差异并进行修补diff - compare files line by line 1234567891011121314#补丁文件(patch file)#diff命令可以生成差异文件diff -u file1 file2 #一体化形式输出diff -u file1 file2 &gt; diff.patchpatch -p1 file1 &lt; diff.patch #得到file2patch -p1 file2 &lt; diff.patch #得到file1patch -R file1 &lt; diff.patch; patch -R file2 &lt; diff.patch #还原#diff也能够以递归的形式作用于目录，它对目录中所有内容生成差异输出diff -Naur dir1 dir2#-N将所有确实文件视为空文件， -a将所有文件视为文本文件#-u生成一体化输出， -r遍历目录下所有文件 栗子： 1234567891011121314151617181920212223242526272829303132333435363738echo -e '1\n1\n1\n1' &gt; /tmp/1.txtecho -e '1\n1\n0\n1' &gt; /tmp/2.txt#比较diff -u 1.txt 2.txt--- 1.txt 2018-12-14 16:08:36.457495835 +0800+++ 2.txt 2018-12-14 16:08:37.574495820 +0800@@ -1,4 +1,4 @@ 1 1-1+0 1#解释--- 1.txt 2018-12-14 16:08:36.457495835 +0800+++ 2.txt 2018-12-14 16:08:37.574495820 +0800#第一部分，是文件的基本信息#---表示变动前的文件#+++表示变动后的文件@@ -1,4 +1,4 @@#第二部分，变动的位置用两个@作为起首和结束。#-号表示第一个文件(1.txt), 1表示第一行，4表示连续四行。也就是第一个文件从第一行开始连续四行#+号表示第二个文件(2.txt), 1表示第一行，4表示连续四行。 1 1-1+0 1#第三部分表示变动的具体内容#除了有变动的那些行以外，也是上下文各显示3行。它将两个文件的上下文合并显示在一起，所以称为合并显示#每一行最前面的标志位，空表示无变动，减号表示第一个文件删除的行，加号表示第二个文件新增的行 head与tail123456head file1; tail file1 #head与tail默认打印10行head -n 5 file1; tail -n 6 file1 #指定行数head -n -5 file1 #打印除了最后5行外所有行tail -n +(5+1) file1 #打印除了开始5行外所有行tail -f /var/log/nginx/access.log #--follow，动态关注文件 只列出目录的其他方法1234ls -d .ls -l . | grep &quot;^d&quot;ls -F . | grep &quot;/$&quot;find . -maxdepth 1 -type d pushd和popd1234567891011121314#在命令行中使用pushd和popd快速定位，pushd和popd以栈的方式运作#当没有鼠标时，复制粘贴就不怎么实用了#pushd和popd可以用于在多个目录之间进行切换而无需复制并粘贴目录路径pushd /home/user1; pushd /home/user2; pushd /home/user3 #将路径添加到栈pushd +2 #切换到/home/user3popd #移除最近添加入栈的目录cd /root; cd /home/usercd - #回到上次的目录cd .. #切换到上一级目录cd ~ #切换到用户主目录 统计文件的行数、单词数、字符数1234567#wc(word count)，是一个统计工具wc -l file1 #统计行数wc -w file1 #统计单词数wc -c file #统计字符数wc -L file #打印最长行长度wc file1 #行、单词、字符数 目录树123456789#tree命令是以图形化的树状结构打印文件和目录,在Linux发行版中默认未安装yum install -y treetree /home/zhangtree /home/zhang -P "*.sh" #只标记出.sh文件tree /home/zhang -I "*.sh" #标记出除.sh文件外所有文件tree /home/zhang -h #显示大小tree /home/zhang -H http://localhost -o tree.html #以html形式输出目录树 让文本飞简介shell脚本可以将sed, awk, grep, cut等这类优美的工具组合在一起，用于解决文本处理相关问题。 正则表达式Regular Expression 正则表达式是一种用于文本匹配的形式小巧、具有高度针对性的编程语言。只依靠通配符技术，能够匹配的文本范围相当有限。 正则表达式基本组成 正则表达式 描述 ^ 行起始标记 $ 行尾标记 . 匹配任意一个字符 [] 匹配包含在[]中的任意一个字符 匹配出之外任意一个字符 [-] 匹配[]中范围内的任意一个字符 ？ 重复0或1次 + 重复&gt;=1次 * 重复&gt;=0次 () 创建一个用于匹配的子串 {n} 重复n次 {n, } 重复&gt;=n次 {n,m} 重复n到m次 \ 转义字符 竖线l 匹配竖线l两边任意一项 POSIX字符类 POSIX字符类(POSIX character class),是一个形如[:…:]的特殊元序列，它用于匹配特定的字符范围。 正则表达式 描述 [:alnum:] 字母与数字字符 [:alpha:] 字母字符 [:blank:] 空格与制表符 [:digit:] 数字字符 [:lower:] 小写字母 [:upper:] 大写字母 [:punct:] 标点符号 [:space:] 所有空白字符 元字符 元字符(meta character)，是一种Perl风格的正则表达式，只有一部分文本处理工具支持它。 正则表达式 描述 \A 字符串的开头 \b 单词边界 \B 非单词边界 \d 单个数字字符 \D 单个非数字字符 \f 换页字符 \n 换行符 \r 回车 \s 单个空白字符 \S 单个非空白字符 \t 跳进字符 \v 垂直跳进字符 \w 单个单词字符(数字，字母和_) \W 单个非单词字符 \z 字符串的结尾 \Z 匹配字符串的结尾，或结尾的换行符之前 123456#匹配一个ipv4地址[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;#匹配一个邮箱地址[\w]+@[\w]\.com 用grep在文件中搜索文本grep命令是Unix中用于文本搜索的工具，它能够接受正则表达式和通配符。 12345678910111213141516171819202122grep "匹配文本/通配符" file1 file2... --color=auto #重点标记匹配grep -E "正则表达式" fileegrep "正则" filegrep -v #反向匹配grep -c #统计匹配行数grep -n #打印出匹配的行号grep -o #唯一匹配grep -l "匹配" file1 file2 #返回匹配的文件名grep -R #递归匹配grep -i #忽略大小写grep -e "匹配1" -e "匹配2" #匹配多个样式grep -f match.txt file1 #从match.txt文件读取匹配grep "匹配" --include=*.&#123;sh,txt&#125; --exclude=*.log --exclude-dir=/home/user -r /home #包括或排除文件-A/-B n #输出匹配 之后/之前 n行-c n #输出匹配 前后 n行#正则匹配多个egerep "(a|b)" 用cut按列切分文件cut是一个将文本按列进行切分的小工具，它也可以指定每列定界符。在cut的术语中，每列都是一个字段。 1234567#制表符'\t' 是cut默认的定界符cut -d' ' -f1 1.txt #-d指定分隔符，-f打印第几个字段cut -f1,2,3 #打印1,2，3列-c字符； -b字节；cut -c 1-5 1.txt #打印1-5字符cut -c -2 1.txt #打印前2个字符cut -c 3- #打印第3个字符到行尾 统计特定文件词频1234#单词解析可以用 关联数组,正则表达式配合sed,awk,grep等工具来完成#关联数组中，将单词作为数组索引，单词次数作为数组值egrep -o "\b[:alpha:]+\b" #匹配单词 sed入门sed是stream editor(流编辑器)的缩写，它是文本处理中非常重要的工具。能够完美地配合正则表达式使用。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#sed - stream editor for filtering and transforming text#字符/在sed中最为定界符使用#替换#sed 's/匹配样式/替代字符串/'sed 's/pattern/repalce/' file #替换sed -i 's/pattern/repalce/' file #将替换应用于fileecho "1.txt" &gt; 1.txt &amp;&amp; sed 's/txt/haha' 1.txt #在输出中用haha替换txtsed -i 's/txt/haha/' 1.txt #将1.txt文件中的txt用haha替换掉#-i选项替换原文件echo "hahaha" | sed 's/ha/HA/g' #全部替换echo "hahaha" | sed 's/ha/HA/2g' #指定位置替换，从第2处开替换全局#移除匹配样式的行sed '/pattern/dsed '/^$/d' ##移除空白行#在sed中用&amp;标记已匹配字符串echo "A wonderful goal" | sed 's/\w\+/[&amp;]/g' #\w\+匹配每一个单词#子串匹配标记\1,\2...echo "1st 2nd 3rd" | sed 's/\(\w\+\) \(\w\+\) \(\w\+\)/\2 \1 \3/'2nd 1st 3rd#将\2和\1交换次序，(),+等在sed中要转义，否则要报错#组合多个表达式sed 'expression1; expression2; ...echo "aabbcc" | sed 's/a/A/; s/b/B/; s/c/C/g'AaBbCC#双引号 " " 内的特殊符号（如$等），可以保有原本的特性#单引号 ' ' 内的特殊字符则仅为一般字符（纯文本）#引用text=helloecho 'hello world' | sed "s/$text/HELLO/"HELLO world awk入门awk被设计用于数据流，它可以对列和行进行操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#awk ‘begin&#123;print "start"&#125; pattern &#123;command&#125; end&#123;print "end"&#125;’ fileawk '&#123;sum += $1&#125;; &#123;print sum&#125;'#awk脚本由:begin块、end块和能使用模式(pattern)匹配的通用语句块 组成#3个部分都是可选的#awk也可以从stdin中读取内容cat /etc/passwd | awk -F: '&#123;print $1&#125;' #-F指定界定符#awk中的特殊变量#NR：记录数量(number of records)，对应于当前行号#NF：字段数量(number of fields)，对应于当前行的字段数#$0：执行过程中当前行的文本内容#$1,$2...$NF：第1个/2个.../最后一个 字段的内容echo -e "L1 1\nL2 22\nL3 333" | awk '&#123;print NR NF $0 $1 $2&#125;'# NR NF $0 $1 $2 $NF=最后一个=$2 1 2 L1 1 L1 1 1 2 2 L2 2 L2 2 2 3 2 L3 3 L3 3 3#将外部变量传递给awk#-v选项可将外部值传递给awk# -v var=val --assign=var=valvar='12345'echo | awk -v v1=$var '&#123;print v1&#125;'#多个变量var1=111; var2=222echo | awk '&#123;print v1,v2&#125;' v1=$var1 v2=$var2#变量来自文件而非标准输入awk '&#123;print v1,v2&#125;' v1=$var1 v2=$var2 file#用样式对awk进行过滤处理awk 'NR &lt; 3,NR==4' 1.txt #行号&lt;5的行awk '/linux/' 1.txt #匹配带有linux的行（可用re）awk '!/linux/' 1.txt #!匹配不带linux的行#设置定界符awk -F: '&#123;print $1&#125;' /etc/passwdawk '&#123;FS=":"&#125; &#123;print $1&#125;' /etc/passwdawk '&#123;FS=":"; print $1&#125;' /etc/passwd#从awk中读取命令输出，用getline读取行echo | awk '&#123;"grep root /etc/passwd" | getlin out; print out&#125;'root:x:0:0:root:/root:/bin/bash#在awk中使用循环awk '&#123;for(i=1;i&lt;4;i++) &#123;print $i&#125;&#125;' 2.txt #输出第1,2,3列#使用awk删除某列awk -F' ' '&#123;$1=null;$2=null;print&#125;' ./file 对文件中的行、单词、字符进行迭代123456789101112131415161718192021222324252627282930313233#迭代文件中的每一行echo -e "1\n22\n333" | while read line;do echo $line;donegrep "bash" /etc/passwd | while read line;do echo $line;done#1#22#333#迭代一行中的每一个单词echo "1 22 333" | while read line;do for word in $line;do echo $word;done;done#1#22#333#迭代一个单词中的每一个字符echo "abc" | while read line;do for word in $line; do for((i=0;i&lt;$&#123;#word&#125;;i++)); do echo $&#123;word:i:1&#125;; done; done;done#写成一行echo "abc" | while read line; do for word in $line; do for((i=0;i&lt;$&#123;#word&#125;;i++)); do echo $&#123;word:i:1&#125;; done; done; done#a#b#c#$&#123;#word&#125;返回变量word的长度 按列合并文件(paste)可以使用paste命令实现列拼接12345678#paste - merge(整合) lines of filesecho -e "1\n2\n3" &gt; 1.txt &amp;&amp; echo -e "Line1\nLine2\nLine3" &gt; 2.txtpaste 1.txt 2.txt1 Line12 Line23 Line3#默认定界符是制表符，用-d指定paste 1.txt 2.txt -d',' 打印文件或行中的第n个单词或n列12awk -F':' '&#123;print $1,$3&#125;' file1cut -d':' -f 1,3 file1 打印不同行或样式之间的文本123456awk 'NR==1,NR==10' /etc/passwdawk 'NR==1,NR==10' /etc/passwd | awk -F":" '&#123;print $1,$NF&#125;' #打印特定行内的特定列awk '/start_pattern/, /end_pattern/' file #打印start到end之间的内容,可使用reawk '/root/, /zhang/' /etc/passwd #打印root到zhang之间内容awk '/^ro.?t'/, /bash$/' /etc/pass 以逆序形式打印行可以使用awk, tac完成。tac就是反过来的cat。 123#tac - 反转显示文件中的行，行内的内容无法用tac反向排列tac 1.txtawk '&#123;lifo[NR]=$0; lno=NR&#125; END&#123; for(;lno&gt;-1;lno--) &#123;print lifo[lno]&#125;;&#125;' 1.txt 解析文本中的电子邮件和URL从给定的文件中解析出所需要的文本是我们从事文本处理时的一项任务。 grep, egrep, fgrep - print lines matching a pattern 123456789#egrep#匹配一个邮箱地址egrep -o '[a-zA-Z0-9.]+@[0-9a-zA-Z.]+\.[a-zA-Z]&#123;2,4&#125;' emails.txt#匹配一个URL地址egrep -o "http://[a-zA-Z0-9.]+\.[a-zA-Z]&#123;2,3&#125;" urls.txt 打印某个样式之前/之后n行(grep)123grep "zhang" /etc/passwd -A 5 #Atergrep "zhang" /etc/passwd -B 5 #Beforegrep "zhang" /etc/passwd -C 5 #前后五行都打印 在文件中移除包含某个单词的句子只要能写出正确的正则表达式(Regular Expression)，那就手到擒来 1sed 's/[^.]*handsome boy[^.]*\.//g' file.txt #句子以.结束 文本切片与参数操作12345678910111213141516#替换变量内容中的部分文字var="One two three"echo $&#123;var/t/T&#125; #只替换了一个#One Two three#指定字符串起始位置和长度#$&#123;变量:开始部分:长度&#125;$&#123;vari:start:length&#125;echo &#123;var:0:2&#125; #Onecho &#123;var:1:6&#125; #ne two#起始字符的索引是0,将最后一个字符索引记为-1echo $&#123;var:(-1)&#125; #eecho $&#123;var:(-3):3&#125; #ree 一团乱麻？没这回事入门本章会研究一些用于解析网站内容、下载数据、发送数据表单以及网站颇为任务自动化之类的实例。我们可以仅用几行脚本就将很多原本需要通过浏览器交互进行的活动管理自动化。通过命令行工具利用HTTP协议所提供的功能，我们可以用脚本解决大部分Web自动化的问题。 网站下载(wget,curl)使用一些命令行下载工具，从给定的URL中下载文件或网页。 wget是一个用于文件下载的命令行工具，选项多且用法灵活。 123456789101112131415161718192021222324252627282930313233343536373839#Wget - The non-interactive(非交互式) network downloaderwget URL1 URL2...wget http://xxx.com/nginx-1.12.0.tag.gzwget https://xxx/a.rpm http://xxxx/bb.rpm#指定文件名，指定信息输出(wget默认是stdout)wget http://mirrors.aliyun.com/repo/Centos-7.repo -O aliyun.repo -o ./wget.logwget URL -t 5 #-t，重试次数#下载限速wget --limit-rate=10m URL #下载限速wget -Q 100m URL #指定下载配额#端点续传#wget进行的下载在完成前被中断，从断点开始下载wget -c URL#用cURL下载#cURL是一个比wget更强大的高级命令工具#和wget不同，curl并不将下载数据写入文件，而是写入stdout，因此必须重定向到文件#复制或镜像整个网站#wget有一个选项可以使其像爬虫一样以递归方式手机网页上所有URL链接，并逐个下载#这样一来就可以下载一个网站的所有页面wget --mirror URL#-m(--mirror) -N -r -l inf --no-remove-listing 的缩写形式。或 wget -r -N -l DEPTH URL#-r递归下载，-l指定递归深度，-N(timestamp)只获取比本地时间新的文件#访问需要认证的HTTP或FTP页面wget --user "username" --password "pass" URL#如未在命令行内输入密码，则会由网页提示手动输入 以格式化纯文本下载网页(links)网页其实就是包含HTML标记和其他诸如Javascript，CSS等元素的HTML页面。HTML标记是网页的基础，也许需要解析网页来查找特定的内容。 links,是一个基于命令行的Web浏览器 123456789101112#links - lynx-like alternative character mode WWW browser#在命令行中浏览一个网页links www.baidu.com#以ASCII形式下载网页links --dump URL &gt; URL.txt#打开本地html文件links 1.html cURL入门cURL支持包括HTTP、HTTPS、FTP在内的众多协议。它还支持POST、cookie、认证、从指定偏移处下载部分文件、参照页(referer)、用户代理字符串、扩展头部(extra header)、限速、文件大小限制、进度条等特性。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#curl - transfer a URL#cURL通常将下载文件输出到stdout，将进度信息输出到stderr#要想避免显示进度信息，可使用--silent#curl可用来下载、发送各种HTTP请求、指定HTTP头部等操作curl URL --silent #输出到stdout#-O写入文件，文件名从URL中解析curl http://www.baidu.com/index.html -O --silent #创建index.html#-o将数据写入指定文件curl URL -o baidu.html --progress #--progress显示进度条links baidu.html#端点续传#和wget不同，cURL包含更高级的下载恢复特性，能够从特定的文件偏移处继续下载#curl可以通过指定一个偏移量来下载部分文件手动：curl URL/file -C offset #偏移量以Byte为单位的整数自动：curl -C -URL #自动续传#用cURL设置参照页字符串, --referer#参照页(referer)是位于HTTP头部中的一个字符串，用来标识用户从哪个页面到达当前页面的#如果用户点击网页A中某个链接，转到了网页B。那么网页B头部的referer会包含网页A的URLcurl --referer Referer_URL target_URLcurl --referer http://www.baidu.com http://jianshu.com#用cURL设置cookie, --cookie#可以用curl来存储HTTP操作过程中使用到的cookie#cookie用key=value形式，指定多个用 分号 分隔curl URL --cookie "user=AAA;name=bbb"curl URL --cookie-jar cookie.txt #将cookie另存为#用cURL设置用户代理字符串, --user-agent#如果不指定代理，一些需要用户代理的网页就无法显示curl URL --user-agent(-A) "Mozilla"#用-H "头部信息"传递多个头部信息curl -H "Host:www.haha.com" -H "Accept-language: en" URL#限定cURL可占用的带宽curl URL --limit-rate 10m#指定最大下载量curl URL --max-filesize 大小(Bytes)#用cURL进行认证，-u username:password指定用户名和密码curl -u user:pass URLcurl -u user URL #手动输入密码#只打印响应头部信息(无数据部分), -Icurl -I URL 从命令行访问163邮箱12curl -u user http://mail.163.com#手动输入密码 制作图片抓取器及下载工具可以用脚本解析图像文件并将图片自动下载下来。 1234567curl -s URL | grep -o "&lt;img src=[^&gt;]*&gt;" | sed 's/&lt;img src=//g; s/&gt;//g' &gt; img.list#匹配图片的URL，可能还需要细化修改#不同的URL可能有不同的规则，根据实际情况取出img的URL#下载图片wget $URL 或 curl -s -O $URL 查找网站中的无效链接(lynx)将查找无效链接的工作自动化，那就比纯手动厉害多了！ 123456789lynx -traversal URL #会将URL中所有链接生成到reject.dat文件中sort -u reject.dat | while read linkdo output=`curl -I $link -s | grep "HTTP/.*OK"` if [[ -z $output ]] then echo $link fidone &lt; links.txt 跟踪网站变更(curl+diff)可以编写一个定期运行的变更跟踪器(change tracker)，一旦发生变更，跟踪器便会发出声音或发送提示信息。在不同时间检索网站，然后利用 diff 命令进行比对。 123curl URL --silent -o `date +%F`.html #第一次curl URL --silent -o `date +%F`.html #第二次diff -u 第一次 第二次 以POST方式发送网页并读取响应POST 和 GET 是HTTP协议中用于发送或检索信息的两种请求类型。在GET请求方式中，利用网页的URL来发送参数(“键-值”)；而POST方式用于提交表单，如提交用户名、密码以及检索登录页面等。 1234curl URL -d “postarg=AABBCC” #-d,http post datacurl URL -d "post1=key1&amp;post2=key2&amp;post3..." #指定多个数据wget URL -post-data "post1=key1" Plan B 简介提取快照和备份数据都是重要的工作，我们可以通过shell脚本来实现备份自动化。归档和压缩对于SA来说同样很重要，有多种压缩格式。加密是一种保护数据的方法，为了减少加密数据的大小，文件在加密前通常需要先归档和压缩。 用tar归档tar命令可以用来归档文件(tar archives tar)。可以将多个文件和文件夹打包为单个文件，同时还能保留所有的文件属性。由tar命令创建的文件通常称为tarball。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#归档文件，-c(create file)tar -cf 1.tar [sources] #-f(specify filename)指定文件名#文件名必须紧跟在-f之后tar -cvf txt.tar *.txt #-v(verbose)详细信息#向已归档文件中添加文件，-rtar -rvf txt.tar *.html#列出归档文件中的内容，-ttar -tf txt.tar #列出归档内容tar -tvf txt.tar #列出内容详细信息#从归档文件中提取文件或文件夹，-x(exact)tar -xf txt.tar #默认提取到当前目录#-C指定提取目录tar -xvf txt.tar -C /dir/path#只提取归档中特定文件tar -xf txt.tar 1.txt 1.html -C /tmp #只会提取1.txt和1.html文件#在tar中使用stdin和stdouttar -cvf - *.text | tar -xvf - -C /tmp#拼接两个归档文件，-Atar -Af txt.tar html.tartar -tvf txt.tat #验证是否成功#添加选项，可以将指定的任意文件加入到归档文件中。如果同名文件已存在，不会覆盖源文件，那么结果就是归档中包含了多个同名文件#通过检查时间戳来更新对党文件中的内容，-u#只有比归档文件中同名文件 更新(newer) 才添加tar -uvf html.tar 1.html#比较归档文件与文件系统中的内容，-dtar -df txt.tar 1.txt 2.txt#从归档文件中删除文件，--deletetar -f txt.tar --delete 1.txt 2.txt#从归档文件中排除部分文件,--excludetar -cf all.tar ./* --exclude="*.html" #排除.html文件tar -cvf txt.tar *.txt --exclude="1.txt"#打印总字节数,--totalstar -cf all.txt ./* --totals#压缩tar归档文件，指定不同压缩格式#-z, .tar.gz#-j, .tar.bz2#--lzma, .tar.lzma,#.tar.lzotar -czvf txt.tar.gzip *.txttar -xzvf txt.tar -C /dir/path#tar后删除原文件tar -czvf txt.tar.gz ./txt --remove-files 用cpio归档cpio是类似于tar的另一种归档格式。它多用于RPM软件包、Linux内核和initramfs文件等。cpio通过stdin获取输入，并将归档写入stdout。 12345678touch file&#123;1..4&#125;echo file1 file2 file3 file4 | cpio -ov file.cpio#-o指定输出，-v打印归档文件列表#-i指定输入，-t列出归档中文件cpio -it &lt; file.cpio 用gunzip或gzip压缩gzip是GNU/Linux下常用压缩格式。gzip,gunzip都可处理gzip压缩文件类型。gzip只能够压缩单个文件，而无法对目录和多个文件进行归档。因此需要先交给tar，然后再用gzip压缩 12345678910111213141516171819202122232425gzip file #file.gz，会覆盖原文件gunzip file.gz #file，也会删除原文件#列出压缩文件的属性信息，-lgzip -l file.gz#指定gzip的压缩级别，--fast或--best--fast 最低压缩比，最快速度完成--best 最高压缩比，最慢速度完成#将gzip与归档文件结合，-ztar -czvf txt.tar.gzip ./*.txt#-a指定从文件扩展名自动判断压缩格式tar -cavf txt.tar.gzip ./*.txt#tar只能从命令行中接收有限个文件，要解决这个问题，可以写一个循环并添加-r选项#解压缩，-xtar -xzvf txt.tar.gziptar -xavf txt.tar.gzip -C /dir/path 用bunzip或bzip压缩bzip2通常能够生成比gzip更小(压缩比更高)的文件。 1234567891011121314151617181920212223bzip2 file #file.bz2,同理会覆盖原文件bzip2 file -k #保留原文件bunzip2 file.bz2 #解压缩bunzip file.bz2 -k#从stdin读入并写到stdoutcat file | bzip2 -c &gt; file.bz2#将bzip2与归档文件结合，-jtar -cvjf 1.tar.bz2 ./1.*tar -cavf 1.tar.bz2 ./1.* #-a根据文件扩展名自动判断压缩格式tar -xjvf 1.tar.bz2tar -xavf 1.tar.bz2 -C /tmp#压缩比#从1级(速度最快，压缩率最低)到9级bzip -9 -k file#对成千上万的文件进行归档，需要借助 循环和-r选项 lzma压缩lzma是一个较新的压缩工具，它提供了比gzip或bzip2更好的压缩率。xz, unxz, xzcat, lzma, unlzma, lzcat - Compress or decompress .xz and .lzma files 1234567891011121314151617lzma file #file.lzma,同样也会删除原文件lzma file -k #保留原文件unlzma file.lzma#从stdin读入并写入stdoutcat file | lzma -C &gt; file.lzma#与tar相结合,--lzmatar -cvf 1.tar.lzma ./1.* --lzmatar -cavf 1.tat.lzma ./1.* #自动判断tar -xvf 1.tar.lzma --lzmatar -xavf 1.tar.lzma -C /tmp#压缩率#从1级到9级(压缩级别最高，速度最慢)#对成千上万的文件，需要使用循环和-r选项 zip归档和压缩zip在Linux下不如gzip,bzip2那么广泛，但在Internet上的文件通常都采用这种格式。zip - package and compress (archive) files 12345678910111213141516171819zip file.zip fileunzip file.zip#与lzma,gzip,bzip2相比，zip完成后不会删除原文件#对目录和文件进行递归操作,-rzip -r dir.zip /root/test ./file#向归档文件中增加内容，-uzip dir.zip -u newfile#从压缩文件中删除内容，-dzip -d dir.zip file#列出归档文件中内容unzip -l dir.zip 超高压缩率的squashfs文件系统squashfs是一种只读型的超高压缩率文件系统。这种文件系统能够将 2GB-3GB的数据压缩成一个700MB的文件。你有没有想过Linux Live CD是怎样运行的？当Live CD启动后，它会加载一个完整的Linux环境。这就是利用了一种被称为squashfs的只读型压缩文件系统。它将根文件系统保存在一个压缩过的文件系统文件中。这个文件可以使用环回的形式来挂载并对其中的文件进行访问。一次当进程需要某些文件，可以将它们解压，然后载入内存中使用。如果需要构建一个定制的Live OS，或是需要超高压缩率的文件并且无需解压就可以访问文件，那么squashfs的相关知识就能派上用场。要解压个头较大的压缩文件，需要花费不少时间。但如果将文件以环回形式挂载，速度就飞快，因为只有出现访问请求的时候，对应的那部分压缩文件才会被解压缩。而普通的解压缩方式是首先解压缩所有的数据。 环回文件系统就是指那些在文件中而非物理设备中创建的文件系统。比如我们可以创建一个文件，然后把这个文件格式化为我们常见ntfs、exfat或者ext4等文件系统格式，然后把它挂载在一个目录上使用。 如果你有一张Ubuntu CD，可以在CDRom Root/casper/filesystem.squashfs中找到文件.squashfs。squashfs在内部采用了gzip和lzma这类压缩算法。 mksquashfs - tool to create and append to squashfs filesystems 1234567891011121314151617181920yum install squashfs-tools -y#创建squashfs文件mksquashfs source compressfile.squashfsmksquashfs /etc etc.squashfs#/etc(67M) --&gt; etc.suqashfs(18M)#要挂载squashfs文件，利用环回形式进行挂载mkdir /mnt/squashmount -o loop etc.squashfs /mnt/squash#此处挂载使用etc.squashfs文件系统#如果直接查看etc.squashfs，就是一个普通文件，但是挂载以后所有文件都出现了umount /mnt/squash#在创建squashfs文件时排除指定文件，-emksquashfs /etc etc.squashfs -e /etc/passwd /etc/shadow /etc/*.txt#在挂载之后就没有相关文件了 加密工具与散列加密技术主要用于防止数据遭受未经授权的访问。Linux下某些工具用于执行加密和解密，使用加密算法散列值来验证数据完整性。 crypt, gpg, base64, md5sum, sha1sum, openssl的用法 ccyptccrypt是为了取代UNIX crypt而设计的，这个实用工具可用于文件和数据流加密及解密。 ccrypt - encrypt and decrypt files and streams 12345678910ccrypt 1.txt #会要求输入口令(encryption key)#之后会生成1.txt.cpt覆盖原文件#更改key,-xccrypt -x 1.txt.cpt #输入old key和new key#解密，-d(--decrypt)ccrypt -d 1.txt.cpt #输入key解密 gpggpg(GNU privacy guard,GNU隐私保护)，是一种应用广泛的加密方案。它采用签名密钥技术保护文件内容，只有经过认证的用户才能访问数据。我们对gpg签名早已耳熟能详。 gpg - OpenPGP encryption and signing tool 12345#加密，-c(--symmetric)对称加密gpg -c file #会要求输入口令(Passphrase)，生成file.gpg#解密gpg file.gpg base64base64是一组类似的编码方案(encoding scheme)，它通过将ASCII字符转换成以64为基数的形式(radix-64 representation)来用ASCII字符串描述二进制数据。base64可用来对 编码和解码 base64字符串。 base64 - base64 encode/decode data and print to standard output 123456#将文件编码为base64格式base64 file &gt; outputfilecat file | base64 &gt; outputfile#解码,-dbase64 -d outputfile &gt; file md5sum与sha1summd5sum 和 sha1sum 都是单向散列算法(unidirecrional hash algorithm)，均无法逆推出原始数据。它们通常用于验证数据完整性或为特定数据生成唯一的密钥，因为通过分析文件内容，它们可以为每个文件生成一个唯一的密钥。 这种类型的散列算法是存储密码的理想方案。密码使用其对应的散列值来存储。如果某个用户需要认证，读取该用户提供的密码并转换成散列值，然后将其与之前存储的散列值进行比对。将密码以明文的形式存储是非常危险的事情，它面临密码泄露的危险。而因为 md5sum和sha1sum 是单向散列算法，所以密码使用散列值存储是很安全的。 123456789101112echo "1.txt" &gt; 1.txtmd5sum 1.txt #生成密钥到stdout#39061daa34ca3de20df03a88c52530ea 1.txtsha1sum file #生成密钥到stdout#659fcbc505db207c03b5c4c0b6981d63286abe21 1.txt#查看/etc/shadow中密码的散列值awk 'NR==1' /etc/shadow | awk -F: '&#123;print $2&#125;' #root密码散列#$6$BxpV48gPsjuq6.pF$wE7pUDwtOI.v64kd5folG68yUt2UAQDTUGgKa5Iz69GaupEoRAdCeerP8nRKXo48c4azutUCGhnDgzd1qe8YX0 shadowlike散列(salted散列)shadow密码通常都是salted密码，所谓SALT就是额外的一个字符串，用来起一个混淆的作用，使加密更加不同里被破解。salt由一些随机位组成，被用作密钥生成函数的输入之一，以生成密码的salted散列值。 12345678910111213#/etc/passwd里面的密码散列类型就是salted散列#查看root密码对应的散列值head -1 /etc/shadowroot:$6$ZlHRCZG2iRwQUXAu$RAEDH97nPdZB2RK20npua6Qf6jB7osatoC99ow3LtPQ6aORdLISYC7/4iTYU162emkQLt4ZafdgjyAeoSB7IU0::0:99999:7:::#openssl - OpenSSL command line tool#shadow密码是使用openssl生成#将SALT_STRING替换为随机字符串，同时将pass替换成你想测试的密码openssl -1 -salt SALT_STRING passwd 用rsync备份系统rsync借助差异计算以及压缩技术来最小化数据传输量。相较于cp命令，它的优势在于使用了高效的差异算法(difference algorithm)。它还支持网络数据传输。在进行复制的同时，rsync会比较源端和目的端的文件，只有当文件有更新是才进行复制。默认情况下，rsync并不会在目的端删除源端已不存在的文件。 rsync - a fast, versatile, remote (and local) file-copying toolinotifywait - wait for changes to files using inotify 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#-a进行归档，-v详细信息rsync -av source destinationrsync -av /etc /tmp#异地cprsync -av source username@host:PATHrsync -av username@host:PATH destination#rsync借助于ssh，可以使用ssh无秘钥认证rsync -av /etc zhang@192.168.1.11:~#-z, --compress compress file data during the transferrsync -avz zhang@192.168.1.11:/etc /tmp#注意，路径格式rsync /etc /tmp #整个/etc目录rsync /etc/ /tmp #/etc目录下所有内容#显示进度，--progressrsync -avz --progress /etc /tmp#排除部分文件，--excludersync -avz /etc /tmp --exclude=/etc/nginx --exclude "*.txt"#更新rsync时，删除不存在的文件，--delete#默认情况下，rsync并不会在目的端删除源端已不存在的文件rsync -avz /etc zhang@192.168.1.1:~ --delete#定期调度crontab -e0 */10 * * * rsync -avz /etc user@host:PATH#实时同步，inotifywait+rsyncyum install inotify-tools -y#-m(monitor),-r(recursive),-q(--quiet)静默模式，-e(event)vi inotify_rsync.shinotifywait -mrq -e creat,delete,modify,move --exclude "^.*\.filepart$" /etc | while read filedorsync -az --exclude=".*" --exclude="*.swp" --exclude=".filepart" --delete /etc /tmp &gt; /dev/null 2&gt;$1done 用Git备份版本控制维护和恢复变更最好的方法是使用版本控制系统。由于代码变更频繁，版本控制系统多用于软件开发和代码维护。Git(GNU it)是有名气也是最高效的版本控制系统。我们可在非编程环境下用Git备份普通文件。 git - the stupid content tracker 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354mkdir /home/zhang/gittestcd /home/zhang/gittest#在源主机中添加用户信息git config --global user.name "username" #设置用户名git config --global user.email "someone@example.com" #设置邮箱#创建一个空的Git版本库或初始化一个老版本git init#记录变更到版本库git commit#添加远程git目录并同步备份git remote add origin user@host:/home/zhang/gittest#为git跟踪(git tracking)添加或删除文件#add,添加内容至索引git add *#git add *.txt; git add *.ph #添加部分文件#删除不需要跟踪的文件和文件夹#rm,从工作去和索引删除文件git rm file#git rm *.txt#检查点或创建备份点(check point)git commit -m "Commit Message"#push,更新远程git push#用Git恢复数据#log,显示提交日志git log#返回之前某个版本或状态git checkout xxxxxxxx(Commit ID)#clone,克隆一个版本库到本地git clone URLgit clone user@host:PATH 用dd克隆磁盘dd命令能用于克隆任何类型的磁盘，如硬盘、闪存、CD、DVD及软盘。可能需要创建所有分区的副本而不仅仅是复制内容，包括硬盘分区、引导记录、分区表等信息。 使用dd的时候，要留意参数的顺序。错误的参数会损毁全部数据。dd基本上算是一个比特流复制器(bitstream duplicator),它可以将来自磁盘的比特流写入文件，也可以将来自文件的比特流写入硬盘。 dd - convert and copy a file 123456789101112dd if=source of=target bs=block_size count=count#bs块大小，count块数dd if=/tmp/centos7.iso of=/dev/sdc#/dev/zero是一个字符设备，它总是返回字符'\0'dd if=/dev/zero of=./file bs=10m count=100#用环回(loop back)方法可将任何由dd生产的文件镜像进行挂载mount -o loop file /mnt 无网不利简介网络是计算机系统中重要的部分。我们以Tcp/Ip为协议栈，所有操作都是基于它进行的。 一些使用网络的应用通过打开并连接到防火墙端口进行运作，而有的管理任务可以通过网络进行。 网络小知识网络接口(Interface)用来连接网络。在每个系统中，默认都有一个称之为环回接口的lo，这个接口指向当前主机本身。操作系统维护者一个被称为路由表(routing table)的表格，它包含了分组如何转发以及通过网络中的哪些节点转发的消息。metric是路由算法用以确定到达目的地的最佳路径的计量标准，如路径长度。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#显示网络接口、子网掩码等详细信息ifconfig #/sbin/ifconfig#显示某个特定接口ifconfig eth0#提取IP地址ifconfig eth0 | egrep -o "inet [^ ]*" | grep -o "[0-9.]*"#设置网络接口的IP地址和子网掩码ifconfig eht0 192.168.1.11ifconfig eth0 192.168.1.11 netmask 255.255.255.0#远程的时候，千万别乱改IP，不然连不上你就要去机房了#MAC地址欺骗ifoconfig eth0 hw ether 11:22:33:44:55:66#域名服务器与DNScat /etc/resolv.conf#添加域名服务器echo "name 114.114.114.114" &gt;&gt; /etc/resolv.conf#nameserver 114.114.114.114#一个域名可以分配多个地址，DNS只会返回其中一个#要想获得域名所有IP地址，需要使用DNS查找工具#DNS查找工具host www.baidu.comnslookup www.baidu.com#自定义解析cat /etc/hostsecho "192.168.1.11 www.zhang.me" &gt;&gt; /etc/hosts#设置默认网关，显示路由表信息#路由表routeroute -n #以数字形式显示地址#设置默认网关route add default gw $ip $interfaceroute add default gw 192.168.1.1 eht0#显示分组途经的所有网关地址traceroute www.baidu.com pingping使用 网际控制报文协议(Internet Control Message Protocol,ICMP)的echo分组。如果分组能够送达且该主机为活动主机，那它就会发送一条回应。一旦主机不可到达，ping返回错误信息”Destination Host Unreachable”。 123456ping 192.168.1.1#往返时间(Round Trip Time,RTT)#发送分组数量ping $URL -c 6 列出网络上所有活动主机当涉及大型局域网时，可能需要检查网络上的其他主机的活动状态。一台非活动主机可能是：没有开机；网络连接有问题；主机禁ping；防火墙问题。 当我们要检测ip时，在一个脚本中，每一次ping都是依次执行。即使所有的ip地址都是彼此独立，由于编写的是顺式程序(sequential program)，ping命令也只能按顺序执行。每次执行一个ping命令。都要经历一段延迟——“发送echo分组，并接收或等待回应超时”。 要是处理几百个ip地址的话，这个延时就真不短了。我们可以使用并行方式来加速所有ping命令的执行。可以将ping命令中的循环体放入( )&amp; 中，( ) 使其中的命令可作为子shell来执行，&amp; 使之在后台继续运行。 1234567891011121314151617181920#编写G一个并行方式的ping脚本fo ip in 192.168.1.&#123;1..255&#125;do ( ping $ip -c2 &amp;&gt; /dev/null; if[ $? -eq 0 ] then echo "$ip is alive" fi )&amp;waitdone#wait命令是脚本只有在所有子进程或后台进程全部终止或完成后才能结束#使用fping,-a显示活动主机，-g生成目标列表,-u显示无法到达主机fping -a 192.168.0.0/24 -g 2&gt; /dev/nullfping -a 192.168.0.1 192.168.3.255 -g 2&gt; ./unreach.txt#将unreach主机找出cat unreach.txt | egrep -o "to [0-9.]+$" | grep -o "[0-9.]*" 传输文件有很多不同的方法可以在网络节点上传输文件，常见的协议有FTP, SFTP, RSYNC, SCP。 通过FTP传输文件可使用lftp命令；通过SSH传输文件可使用sftp；RSYNC使用SSH与rsync命令；scp通过SSH进行传输。 文件传输协议(File Transfer Protocol, FTP)，使用21端口。FTP是明文传输，So…需要远程主机上启用了FTP服务器才能使用FTP。 1234567lftp user@ftp-host#输入密码后便可以操作如下命令cd -- lcd(本地)mkdirget filename #下载文件put filename #上传文件quit #退出 SFTP(Secure FTP,安全FTP)，运行在SSH连接之上。利用SSH连接模拟FTP接口。它不需要源端运行FTP服务器，不要运行OpenSSH。SFTP是一个交互式命令，提供了命令提示符。 rsync广泛用于网络文件与系统快照的备份。 SCP(Secure Copy,安全复制)，远程文件复制工具。通过SSH加密通过进行传输。123456789scp SOURCE DESTINATIONscp /path/file user@host:PATHscp usr@host:/dir/file /home/zhang#需要输入密码，可以用SSH无秘钥认证#-r递归复制,-p保持文件权限和模式scp -r /etc user@host:/tmpscp -rp user@host:/var/www /var SSH无秘钥认证特别是在定时任务传输备份文件时，无秘钥认证就很方便了。SSH服务默认在22端口，你可以在配置文件中修改。 具体步骤： 创建SSH密钥(公钥和私钥)； 将客户端公钥上传给需要连接的主机，并写入~/.ssh/authorized_keys文件； 修改相关目录(700)和文件权限(600)； 1234567ssh-keygen -t rsa#后续操作默认即可#生成~/.ssh/id_rsa.pub和id_rsa#写入远程主机ssh user@host "cat &gt;&gt; ~/.ssh/authorized_keys" &lt; ~/.ssh/id_rsa.pub 用SSH在远程主机上运行命令1234567891011121314151617#连接远程主机ssh user@host#非默认端口ssh user@host -p 2211#在远程主机中运行命令ssh user@host 'command'ssh user@host 'cmd1'; 'com2'...ssh user@host 'whoami'#-C压缩功能，当带宽有限时ssh -C user@host 'cmd' 在本地挂载远程驱动器(sshfs)在执行读写数据操作时，通过本地挂载远程主机文件系统。利用SSH和sshfs来实现这一功能。sshfs是FUSE文件系统的一个扩展，FUSE允许其支持的操作系统像使用本地文件系统一样挂载各类数据。sshfs允许将远程文件系统挂载到本地挂载点上。 相当于便捷的NFS，但并不需要搭建NFS服务。 SSHFS - filesystem client based on ssh 1234#挂载远程文件到本地ssh user@host:PATH /mnt/sshfsumout /mnt/sshfs 网络流量和端口分析应用程序在主机上打开端口，然后与远程主机中打开的端口实现通信。出于安全方面的考虑，必须留意系统中打开及关闭的端口。 恶意软件和rootkit可能会利用特定的端口及服务运行在系统之中，从而进行攻击。通过分析开放端口列表以及运行在端口上的服务，我们便可以分析并检查恶意软件，保证主机安全。 了解及使用各种端口分析工具。 lsof - list open fileslsof列出系统中开放端口以及运行在端口上的服务的详细信息，文件被哪个程序使用。 1234567891011121314151617-a：列出打开文件存在的进程-c&lt;进程名&gt;：列出指定进程所打开的文件-g：列出GID号进程详情-d&lt;文件号&gt;：列出占用该文件号的进程+d&lt;目录&gt;：列出目录下被打开的文件+D&lt;目录&gt;：递归列出目录下被打开的文件-n&lt;目录&gt;：列出使用NFS的文件-i&lt;条件&gt;：列出符合条件的进程（4、6、协议、:端口、 @ip ）-p&lt;进程号&gt;：列出指定进程号所打开的文件-u：列出UID号进程详情-h：显示帮助信息-v：显示版本信息lsof /var/log/messagesCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMErsyslogd 12231 root 5w REG 253,0 539973467 68539162 /var/log/messages netstat查看开放端口与服务netstat - 显示网络连接，路由表，接口状态，伪装连接，网络链路信息和组播成员组; iftop - display bandwidth usage on an interface by hostiftop - 展示带宽使用情况； ifstat - handy utility to read network interface statisticsifstat - 展示某时刻网络状态； nload - displays the current network usagenload - 可查看系统总带宽； nethogs - Net top tool grouping bandwidth per processnethogs- 可查看每个进程流量情况；ethtool - query or control network driver and hardware settingsethtool - 检查网卡支持的带宽 12345678910111213141516171819202122#lsof的每一项都对应着一个打开了特定端口的服务lsof -i:port#查看开放端口和服务netstat -nltp#查看网络实时状态iftop#查看当前网络状态ifstat#查看系统带宽nload#查看进程流量nethogs tcpdumptcpdump是一款嗅探工具，也就是命令行格式的wireshark。 1234tcpdump - dump traffic on a networktcpdump [options]` 12345678910111213141516171819202122232425-a：尝试将网络和广播地址转换成名称；-c&lt;数据包数目&gt;：收到指定的数据包数目后，就停止进行倾倒操作；-d：把编译过的数据包编码转换成可阅读的格式，并倾倒到标准输出；-dd：把编译过的数据包编码转换成C语言的格式，并倾倒到标准输出；-ddd：把编译过的数据包编码转换成十进制数字的格式，并倾倒到标准输出；-e：在每列倾倒资料上显示连接层级的文件头；-f：用数字显示网际网络地址；-F&lt;表达文件&gt;：指定内含表达方式的文件；-i&lt;网络界面&gt;：使用指定的网络截面送出数据包；-l：使用标准输出列的缓冲区；-n：不把主机的网络地址转换成名字；-N：不列出域名；-O：不将数据包编码最佳化；-p：不让网络界面进入混杂模式；-q ：快速输出，仅列出少数的传输协议信息；-r&lt;数据包文件&gt;：从指定的文件读取数据包数据；-s&lt;数据包大小&gt;：设置每个数据包的大小；-S：用绝对而非相对数值列出TCP关联数；-t：在每列倾倒资料上不显示时间戳记；-tt： 在每列倾倒资料上显示未经格式化的时间戳记；-T&lt;数据包类型&gt;：强制将表达方式所指定的数据包转译成设置的数据包类型；-v：详细显示指令执行过程；-vv：更详细显示指令执行过程；-x：用十六进制字码列出数据包资料；-w&lt;数据包文件&gt;：把数据包数据写入指定的文件。 栗子： 123456789101112131415161718192021#tcpdump默认将监视第一个网络接口上流过的数据包tcpdump#指定网络接口tcpdump -i eth1 -w /tmp/1.cap#指定主机tcpdump host $hostnametcpdump host $hostname1 and $hostname2#指定源和目标主机tcpdump -i eth0 src host $hostnametcpdump -i eth0 dst host $hostname#指定主机和端口tcpdump tcp port 22 host 192.168.1.11tcpdump udp port 53 当个好管家简介操作系统(Operation System,OS)，是由一系列用于不同目的、服务于不同任务的系统软件组成。日志记录(logging)和监视是很重要的，能帮助我们从大量数据中收集信息。 监视系统活动的各种命令，日志技术及其使用方法。 统计磁盘使用情况(df+du+fdisk)磁盘空间是一种有限资源，我们需要了解磁盘的可用空间。 df, du, fdisk是Linux中的磁盘管理三板斧df(disk free): 报告文件系统磁盘空间的使用情况;du(disk usage): 报告磁盘空间使用情况; 使用du时，要确保对其遍历的目录和文件拥有适合的读权限。fdisk: Linux分区表操作工具软件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748du file1 #默认以字节为单位#-a,显示目录下所有文件大小du -a /home/zhangdu /home/zhang #只显示目录大小#-h,以可读形式打印du -h /home/zhang#-c,显示使用总量du -c file1 /dir2du -c *.txt *.sh#-s，打印摘要du -s /dirdu -sh /home/zhang#-b,-k,-m,-B，用特定单位打印du -k file1du -m file2#--exclude,从磁盘统计中排除部分文件du --exclude="*.swap" -sh /home/zhang#--max-depth,指定最大遍历深度du -h --max-depth n /dirdu -h --max-depth=2 /home/zhang#-x,将/mnt中所有挂载点排除在磁盘统计之外du -xh /dir#找出目录中最大的文件du -ak /dir | sort -nrk 1 | head -n 5#此输出包含了目录大小，需要细化#利用find替du过滤文件find /dir -type f --exec du -ak &#123;&#125; \; | sort -nrk 1 | head#df,磁盘可用空间信息df -h 计算命令执行时间当测试一个应用程序或比较不同的算法时，程序的执行时间非常重要。所以需要计算命令执行时间。 所有的Unix-Like操作系统都包含time命令，可将time放在需要计算执行时间的命令前。 time命令有个可执行二进制文件位于/usr/bin/time，还有一个shell built-in命令也叫作time；当运行time时，默认调用的是shell built-in命令。內建time命令选项有限；因此，如果我们需要使用另外的功能，就应该使用/usr/bin/time命令。 123456789101112131415161718192021222324#计算命令执行时间time commandtime ls#real,挂钟时间(wall clock time),命令从开始执行到结束的时间；#user,指进程花费在用户模式(user-mode)中的CPU时间。这是唯一用于执行进程所花费的时间；#sys，指进程花费在内核模式(in the kernel)中的CPU时间。它代表在内核中执行系统调用所使用的时间。#-o,将命令执行时间写入文件/usr/bin/time -o exetime.txt ls /#-a,不影响原文件/usr/bin/time -a -o exetime.txt ls /home#-f,格式化时间输出#时间格式字符串#real %e#user %U#sys %S/usr/bin/time -f "FORMAT STRING" command/usr/bin/time -f "Rtme: %e" -a -o timing.log uname/usr/bin/time -f "Rtime: %e\nUtime: %U\nStime: %S" -ao timing.log uname 当前登录用户、启动日志、启动故障的相关信息(w+who+lastb+last)收集与操作系统、当前登录用户、主机运行时间、启动故障等相关信息很有用处。 1234567891011121314151617181920#获取当前登录用户who #显示已经登录的用户w #显示已经登录的用户以及他们在做什么#会显示用户使用的伪终端(pseudo TTY)，对应设备文件出现在/dev/pts/n#列出登录主机的用户列表users#查看系统运行时间uptime#显示用户登录列表last#获取某个用户登录信息last zhang#获取重启会话信息last reboot#获取失败的用户登录信息lastb 打印10条最常使用的命令(history)终端是用来访问shell的工具，在shell中我们可以输入并执行命令。我们可以找出在shell中运行最多的命令。 ~/.bash_history，默认保留1000个最近执行命令。或者history命令。 1cat .bash_history | sort -n | uniq -c | sorn -nr | head 列出占用CPU最多的进程CPU时间是一项重要资源，有时需要跟踪占用CPU周期最多的进程。对于需要处理大量请求的服务器来说，CPU是极其重要的资源。通过监视某个时期内CPU的使用情况，可以找出长期占用CPU的进程并对其进行优化，或是调试其他问题。 用ps命令收集系统中进程的详细信息。ps - report a snapshot of the current processes 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#-e,以标准语法显示每个进程ps -eps -ef#ax,以BSD语法显示每个进程ps axpa axu#获取安全信息#ps -eo euser,ruser,suser,fuser,f,comm,pcpu,label#comm显示命令，pcpu显示CPU使用率ps -eo comm,pcpu#监视并计算一小时内CPU使用情况的shell脚本secs=3600unit_time=60steps=$(($secs / $unit_time))echo "Whatching CPU usage..."for((i=0; i&lt;steps; i++))do ps -eo comm,pcpu | tail -n +2 &gt;&gt; /tmp/cpu_usage.$$ sleep $unit_timedoneecho "CPU eaters: "cat /tmp/cpu_usage.$$ | \awk '&#123;process[$1]+=$2&#125;END&#123; for (i in process) &#123; printf("%-20s %s",i,process[i]); &#125;&#125;' | sort -nrk 2 | head#tail -n +K，从第K行开始输出。上面输出第一行是 COMAND 和 %CPU#$1,command; $2,%CPU#process[$1]是一个关联函数，相当于arr[command]#arr[command]=arr[command]+ $2，计算同一命令的累积时间#i指命令，process[i]指命令运行时间 用watch监视命令输出可能需要在在某段时期内以固定的间隔时间不短监视某个命令的输出。可利用watch命令。 watch - execute a program periodically, showing output fullscreen 123456789101112131415#watch命令可以用来在终端以固定的间隔监视命令输出，默认2秒间隔watch commandwatch 'command'watch lswatch 'ls -l'#-n,指定时间间隔watch -n 5 'yum update -y'#-d，突出(highlighting)watch输出中的差异watch -d -n 1'dd if=/dev/zero of=/tmp/zero.test' 对文件及目录访问进行记录(inotifywait)记录重要文件及目录访问，对于追踪文件和目录的变化很有帮助。inotifywait命令可以用来收集有关文件访问的信息。inotifywait和rsync用户实时同步哦！ inotifywait - wait for changes to files using inotify 1234567891011yum install -y inotify-tools#-q,减少冗余信息inotifywait -m -r -q -e create,move,delete /dirinotifywait -m -r -q -e create,move,modify,delete /home/zhang &gt;&gt; inotifywait.log#利用inotifywait检测，rsync同步inotifywait -mrq -e create,move,modify,delete /dir --exclude="*.swap" | while read filedorsync -av --exclude="*.swqp" --delete /dir user@host:PATH &gt; /dev/null 2&gt;&amp;1done 用logrotate管理日志文件日志文件是Linux系统维护中必不可少的组成部分。日志文件可以帮助跟踪系统中多种服务所发生的事件，这有助于排除系统问题。但随着时间推移，日志文件会变得越来越大。因而必须对日志文件进行管理。 我们可以利用一种称为“轮询(rotation)”的技术来限制日志文件的体积。一旦日志文件超过了限定大小，就要对它的内容进行抽取(strip)，同时将日志文件的旧条目归档到文件中。 logratate是每一位Linux系统管理员都应该了解的命令。它能够将日志文件大大小限制在给定的SIZE内。logrotate配置文件位于/etc/logrotate.d logrotate ‐ rotates, compresses, and mails system logs 123456789101112vim /etc/logrotated.d/custom/var/log/custom.log &#123; missingok #日志文件丢失，则忽略 notifempty #仅当源日志文件非空时才进行轮替 size 30k #限制实施轮替的日志文件大小 compress #压缩旧日志 weekly #轮询时间，daily,weekly,yearly rotate 7 #保留旧日志数量 create 0600 root root #创建的日志文件模式，用户和用户组#还有一些其他选项&#125; 用sys记录日志在Linux系统中，在/var/log中创建并写入日志信息的是由被称为syslog的协议处理的。它由守护进程syslogd负责执行。每一个标准应用进程都可以用syslog记录日志信息。 syslog处理/var/log下的多个日志文件。但是当logger发送消息时，它用标记字符串来确定应该纪录到哪一个日志文件中。syslogd使用与日志相关联的TAG来决定应该将其记录到哪一个文件中。可以从/etc/rsyslog.d/目录的配置文件中看到与日志文件相关联的标记字符串。 Linux中一些重要日志文件： /var/log/boot.log， 系统启动信息；/var/log/message， 内核启动信息；/var/log/auth.log， 用户认证日志；/var/log/dmesg， 系统启动信息；/var/log/mail.log， 邮件服务器日志。 logger - a shell command interface to the syslog 123456#logger命令，默认记录日志信息到/var/log/messageslogger "test log message to messages"tail -n 1 /var/log/message#-t，指定特定TAGlogger -t TAG "test log message to messages" 管理重任简介GNU/Linux的生态系统是由运行的程序、服务、连接的设备、文件系统、用户等组成。按照我们需要的方式对整个系统有一个微观并对操作系统进行整体上的管理，这就是系统管理的主要目的。 收集进程信息(top+ps+pgrep)进程是程序运行实例(runing instance)。同一程序的多个实例可以同时运行，但他们的进程ID却互不相同。 进程管理相关的重要命令是： top, display Linux processes; ps, report a snapshot of the current processes; pgrep, look up or signal processes based on name and other attributes. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#ps命令#-f, 显示更多进程信息ps -f#-e,every; -a,allps -efps -ax#-o, 指定想要的列ps -e -o parameter1,parameter2...ps -eo comm,pcpu,pmem#pccpu CPU占用率#pid 进程ID#ppid 父进程ID#pmem 内存使用率#comm 命令名#cmd 简单命令#user 启动进程的用户#nice 优先级#time 累积的CPU时间#etime 进程启动后度过的时间#tty 所关联的TTY设备#euid 有效用户ID#stat 进程状态#--sort,根据参数对ps输出进行排序#+升序，-降序ps -eo comm,pcpu,pmem --sort -pcpups -eo comm,pcpu,pmem --sort -pcpu,+pmem#-C, 给定命令全名找出PIDps -C cmd -o comm,pid#-u, 指定有效用户列表#-U, 指定真实用户列表ps -u root -U zhang -o user,pcpu#-t, 用TTY过滤输出ps -t TTY1,TTY2...ps -t pts/0,pts/1 -ef#-L, 显示进程相关信息#LWP线程ID， NLWP线程数量ps -efL#pgrep命令, 获得一个特定命令的PID列表#它只需要命令的一部分即可pgrep cmdpgre inotifpgrep bas#-d, 指定定界符pgrep rsync -d ":"#-u, 指定进程的用户pgrep -u root,zhang rsync#-c, 返回匹配的进程数量pgrep -c rsync#top命令top 杀死进程以及发送响应信息(kill+killall+trap)在Unix-Like环境中与进程有关的一个重要概念就是信号。信号是一种进程间通信机制，它用来中断运行的进程以执行某些操作。终止程序也是通过使用信号技术来实现的。 像ctrl+C,ctrl+Z这种作业都属于信号。 kill 命令可用来向进程发送信号; trap 命令用来处理所接收的信号; killall 以名字方式来杀死进程. 123456789101112131415161718192021222324252627#列出所有可用信号kill -l#-s, 发送信号#信号名称和信号数都可以kill -信号数 PIDkill -s SIGNAL PID#常用信号#SIGHUP 1 终端断线(对控制进程或终端进行挂起检测(hangup detection))#SIGINT 2 中断(当按下Ctrl+C时发送该信号)#SIGQUIT 3 退出(同Ctrl+\)#SIGKILL 9 强制终止(强行杀死进程)#SIGTERM 15 终止进程#SIGCONT 18 继续(与STOP相反，fg/bg命令)#SIGTST0P 19 暂停(当按下crtl+z时发送该信号)#killall, 通过命令名终止进程killall -s SIGNAL PNamekillall -信号数 PName#trap, 捕捉并响应信号trap 'signal-handler-func' SIGNAL LIST kill信号详解参考: https://www.imooc.com/article/48534 1234567891011121314$ kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR111) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+338) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+843) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+1348) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-1253) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-758) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-263) SIGRTMAX-1 64) SIGRTMAX Linux信号列表： SIGHUP 1: A 终端挂起或者控制进程终止 SIGINT 2: A 键盘中断（如break键被按下） SIGQUIT 3: C 键盘的退出键被按下 SIGILL 4: C 非法指令 SIGABRT 6: C 由abort(3)发出的退出指令 SIGFPE 8: C 浮点异常 SIGKILL 9: AEF Kill信号 SIGSEGV 11: C 无效的内存引用 SIGPIPE 13: A 管道破裂: 写一个没有读端口的管道 SIGALRM 14: A 由alarm(2)发出的信号 SIGTERM 15: A 终止信号 SIGUSR1 30,10,16: A 用户自定义信号1 SIGUSR2 31,12,17: A 用户自定义信号2 SIGCHLD 20,17,18: B 子进程结束信号 SIGCONT 19,18,25: 进程继续（曾被停止的进程） SIGSTOP 17,19,23: DEF 终止进程 SIGTSTP 18,20,24: D 控制终端（tty）上按下停止键 SIGTTIN 21,21,26: D 后台进程企图从控制终端读 SIGTTOU 22,22,27: D 后台进程企图从控制终端写 处理动作中的字母含义： A: 缺省的动作是终止进程 B: 缺省的动作是忽略此信号，将该信号丢弃，不做处理 C: 缺省的动作是终止进程并进行内核映像转储（dump core），内核映像转储是指将进程数据在内存的映像和进程在内核结构中的部分内容以一定格式转储到文件系统，并且进程退出执行，这样做的好处是为程序员 提供了方便，使得他们可以得到进程当时执行时的数据值，允许他们确定转储的原因，并且可以调试他们的程序。 D: 缺省的动作是停止进程，进入停止状况以后还能重新进行下去，一般是在调试的过程中（例如ptrace系统调用） E: 信号不能被捕获 F: 信号不能被忽略 which, whereis, file, whatis与平均负载which hows the full path of (shell) commands。找出某个命令的位置;whereis locate the binary, source, and manual page files for a command。不仅返回命令路径，还能打印命令手册的位置以及命令源代码路径;file determine file type。用来确定文件类型;whatis display manual page descriptions。输出简短描述信息;平均负载(load average),是系统运行总负载量的一个重要参数。它指明了系统中可运行进程总量的平均值。平均负载由三个值来指定，第一个指明1分钟内的平均值，第二个指明5分钟内的平均值，第三个指明15分钟内的平均值。 单核CPU，类似于单车道，负载在 0.00-1.00 之间正常； 多核CPU，类似于多车道，负载在 核数*(0.00-1.00) 之间正常； 安全的系统负载，单核应该在 0.7 以下； 12345#查看平均负载uptimecat /proc/loadavg#0.00 0.01 0.05 1/355 44955#分母355表示系统进程总数, 分子表示正在运行的进程数, 最后一个数字表示最近运行进程ID 向用户终端发送消息系统管理员可能需要向网络中所有主机上的所有用户或特定用户的终端发送消息。`wallrsync -av —exclude=”*.s命令用来向所有当前登录用户的终端写入消息。 在Linux系统中，终端是作为设备存在的。因此那些打开的终端在dev/pts/中都会与对应的设备节点文件。向特定设备写入数据将会在对应的终端显示出消息。 12345echo "It's just a test" | wall#查看用户对应的/dev/pts/, 并向某一个用户终端发送信息ll /dev/pts | awk '&#123;print $3,$6&#125;'echo"Haha" &gt; /dev/pts/[1,2,3...] 收集系统信息包括主机名、内核版本、Linux发行版本、CPU信息、内存信息、磁盘分区信息等。 123456789101112131415161718192021222324252627#主机名hostnameuname -n#内核版本，架构uname -runame -muname -a#Linux发行版本cat /etc/redhat-release#CPU相关信息lscpucat /proc/cpuinfocat /proc/cpuinfo | grep 'model name'#内存详细信息free -hcat /proc/meminfo#分区信息cat /proc/partitionsfdisk -l#系统详细信息lshw 用/proc收集信息在GNU/Linux操作系统中，/proc是一个位于内存中的伪文件系统(in-memory pseudo filesystem)。它的引用是为了提供一个可以从用户空间(user space)读取系统参数的接口。 可以对/proc中的文件和子目录进行cat来获取信息，所有内容都是易读的格式化文本。 /proc/下的数字目录，包含了对应进程的相关信息；/proc/environ，包含于进程相关联的环境变量；/proc/cwd，是一个到进程工作目录的符号链接；/proc/fbcat，包含了由进程所使用的文件描述符。 用cron进行调度GNU/Linux系统包含了各种用于调度任务的工具。cron就是其中之一，它通过守护进程crond使得任务能够以固定的时间间隔在系统后台自动运行。cron利用的是一个被称为“cron表(cron table)”的文件，这个文件中存储了需要执行的脚本或命令的调度列表以及执行时间。 12345678910111213141516171819202122232425262728#分 时 日 月 周#* * * * * cmd#分钟(0-59)#小时(0-23)#天(1-31)#月(1-12)#工作日(0-7)，0和7都代表周天#命令#*号,所有值#,号,范围。1,3,5,7,9#-号,连续范文。1-10#/号,*/10;0-8/20#栗子crontab -e* 0-6 * * * /home/zhang/test.sh1,3,5,7,9 * * * * /home/zhang/test.sh*/5 * * * * /home/zhang/test.sh#-l,查看cron表crontab -l#-r,移除cron表crontab -r cron的高级写法栗子： 1234567891011121314151617181920@reboot #在启动的时候运行一次#其实@reboot类似于rc.local，开机启动@yearly == @annually == 0 0 1 1 * #一年一次@monthly == 0 0 1 * * #每月一次@weekly == 0 0 * * 0 #每周一次@daily == @midnight == 0 0 * * * #每天一次@hourly == 0 * * * * #每小时一次crontab -e@reboot /bin/mongod -f /etc/mongod_27018.confvim /etc/rc.d/rc.local/bin/mongod -f /etc/mongod_27018.confchmod a+x /etc/rc.d/rc.local 用户管理常用命令123456789101112131415161718192021222324252627282930313233343536#添加用户useradd#删除用户userdel--remove-all-file删除与用户相关的所有文件#修改shellchsh#修改用户属性usermod#修改密码过期时间chage#修改密码passwd#登录到一个新组newgrp#添加、删除组groupaddgroupdel#指纹finger iptables和firewalldfirewalld与iptables比较: iptables与firewalld都不是真正的防火墙，它们都只是用来定义防火墙策略的防火墙管理工具而已。或者说，它们只是一种服务 firewalld可以动态修改单条规则，动态管理规则集，允许更新规则而不破坏现有会话和连接；iptables在修改了规则后必须得全部刷新才可以生效 firewalld使用区域和服务而不是链式规则 firewalld默认是拒绝的，需要设置以后才能放行；iptables默认是允许，需要拒绝的才去限制 firewalld自身并不具备防火墙的功能，而是和iptables一样需要通过内核的netfilter来实现。真正使用规则干活的是内核的netfilter firewalld是iptables的一个封装，可以让你更容易地管理iptables规则。它并不是iptables的替代品 firewalld拥有CLI和GUI的两种管理方式 firewalld区域管理通过将网络划分成不同的区域，制定出不同区域之间的访问控制策略来控制不同程序区域间传送数据流。firewalld的默认区域是public区域。 九大区域： 阻塞区域（block）任何传入的网络数据包都将被阻止 工作区域（work）相信网络上的其他计算机，不会损害你的计算机 家庭区域（home）相信网络上的其他计算机，不会损害你的计算机 公共区域（public）不相信网络上的任何计算机，只有选择接受传入的网络连接 隔离区域（DMZ）隔离区域也称为非军事区域，内外网络之间增加的一层网络，起到缓冲作用。对于隔离区域，只有选择接受传入的网络连接 信任区域（trusted）所有的网络连接都可以接受 丢弃区域（drop）任何传入的网络连接都被拒绝 内部区域（internal）信任网络上的其他计算机，不会损害你的计算机。只有选择接受传入的网络连接 外部区域（external）不相信网络上的其他计算机，不会损害你的计算机。只有选择接受传入的网络连接 firewalld有三种配置方法： firewll-config(GUI) firewall-cmd(CLI) 编辑XML配置文件 firewalld默认提供了九个区域的配置文件，它们位于/usr/lib/firewalld/zones: 123ls /usr/lib/firewalld/zonesblock.xml dmz.xml drop.xml external.xml home.xml internal.xml public.xml trusted.xml work.xml 常用命令: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162yum install firewalld firewall-configsystemctl start firewalldfirewall-cmd --versionfirewall-cmd --help#永久生效需加上 --permannentfirewall-cmd xxx --permannentfirewall-cmd --state#查看网络接口使用的区域firewall-cmd --get-active-zones#查看指定区域的所有配置firewall-cmd --zone=public --list-all#查看所有区域配置firewall-cmd --list-all-zones#查看默认区域firewall-cmd --get-default-zone#设置默认区域firewall-cmd --set-default-zone=internal#查看指定接口所属区域firewall-cmd --get-zone-of-interface=eth0#将接口添加到区域，默认接口都在publicfirewall-cmd --zone=public --add-interface=eth0#拒绝|开启 所有包firewall-cmd --panic-on|off#查看是否拒绝firewall-cmd --query-panic#无需断开连接更新防火墙规则firewall-cmd --reload#类似于重启更新规则firewall-cmd --complete-reload#查看所有打开的端口firewall-cmd --zone=dmz --list-ports#加入一个端口的区域firewall-cmd --zone=dmz --add-port=8080/tcp 与服务一起使用firewalld可以根据特定网络服务的预定义规则来允许相关流量。你可以自定义系统规则，并将它们添加到任何区域。 默认支持的服务的配置文件位置: /usr/lib/firewalld/services 创建的服务文件位置: /etc/firewalld/services 123456789cat /usr/lib/firewalld/service/elasticsearch.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;service&gt; &lt;short&gt;Elasticsearch&lt;/short&gt; &lt;description&gt;Elasticsearch is a distributed, open source search and analytics engine, designed for horizontal scalability, reliability, and easy management.&lt;/description&gt; &lt;port protocol=&quot;tcp&quot; port=&quot;9300&quot;/&gt; &lt;port protocol=&quot;tcp&quot; port=&quot;9200&quot;/&gt;&lt;/service&gt; 常用命令: 1234567891011121314#查看默认可用服务firewall-cmd --get-services#永久启用或禁用HTTP服务firewall-cmd --zone=区域 --(add|remove)-service=http --permanent#添加123456端口的tcp流量firewall-cmd --zone=public --add-port=123456/tcp --permanent#将80端口的流量转发到123456端口firewall-cmd --zone=public --add-forward-port=port=80:proto=tcp:toport=123456 iptablesiptables/ip6tables — administration tool for IPv4/IPv6 packet filtering and NAT 切记谨慎使用iptables命令，特别是在远程连接的时候。规则是有顺序的，规则的顺序很重要。当规则顺序排列错误时，会产生很严重的错误。 12345678910111213141516171819202122232425262728293031iptables --help-t&lt;表&gt;： 指定要操纵的表，默认为filter-P： 设置默认策略-A &lt;链&gt;： 在规则链的末尾中添加条目-I &lt;链&gt;： 在规则链的头部中插入条目#请注意-A与-I，这两者的插入顺序是不一致的，-I顺序更高-D &lt;链&gt;： 从规则链中删除条目-R： 替换规则链中的条目-L： 显示规则链中已有的条目-F： 清楚规则链中已有的条目-Z： 清空规则链中的数据包计算器和字节计数器-X： 删除用户定义的链-N： 创建新的用户自定义规则链-p： 指定要匹配的数据包协议类型(tcp, udp, icmp...)-s： 指定要匹配的数据包源ip地址(ip/mask, !ip)-d： 匹配 目标地址--sport： 匹配源端口号--dport： 匹配目的端口号-i&lt;网络接口&gt;： 指定数据包进入本机的网络接口-o&lt;网络接口&gt;： 指定数据包要离开本机所使用的网络接口-j target： 指定要跳转的目标-m match： 扩展匹配-g chain： jump to chain with no return 表格/链/动作为什么称为iptables? 因为此软件里面有多个表格(table)，每个表格定义了自己的默认策略和规则，且每个表格的用途都不相同。 表(Table) raw: 高级功能 mangle: 数据包修改 nat: 网络地址转换 PREROUTING POSTROUTING OUTPUT filter: 包过滤，是默认表 INPUT OUTPUT FORWARD 链(Chain) INPUT：处理输入数据包 OUTPUT：处理输出数据包 FORWARD：处理转发数据包 PREROUTING：用于目标地址转换(DNAT) POSTOUTING：用于源地址转换(SNAT) 动作(Action) ACCEPT： 接收数据包 DROP： 丢弃数据包 REJECT: 拒绝 REDIRECT： 重定向、映射、透明代理 SNAT： 源地址转换 DNAT： 目标地址转换 MASQUERADE： IP伪装（NAT），用于ADSL LOG： 日志记录 常用命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#格式iptables -t 表名 &lt;-A/I/D/R&gt; 规则链名 [规则号] &lt;-i/o 网卡名&gt; -p 协议名 &lt;-s 源IP/源子网&gt; --sport 源端口 &lt;-d 目标IP/目标子网&gt; --dport 目标端口 -j 动作-A: 新增一条规则，在最后面-I: 插入一条规则，如果没有指定顺序，默认变成第一条规则--line-numbers： 显示规则行号-i: 包所进入的那个网络接口-o: 包所传出的那个网络接口-p: 指定网络协议-p tcp --syn(ack, rst)-p udp-p icmp-p all-s: 源IP或网段-d: 目标IP或网段-s 192.168.1.11-d 192.168.1.0/24(192.168.1.0/255.255.255.0)-s !192.168.2.0/24-j: 后接动作#记录，此日志默认追加到messages-j LOG --log-prefix=‘IPTABLES-’#端口号可以是连续的--sport 1026:65535--dport 80-m: 一些iptables外部模块-m state: 状态模块-m mac: 网卡地址--state: 数据包状态--state INVALID： 无效的数据包--state ESTABLISHED: 已建立连接--state NEW: 想要新建连接的数据包--state RELATED: 表示这个数据包是我们主机发送出去的--mac-source: 源主机的硬件地址 清除防火墙规则: 12345678910111213iptables [ -t tables ] [ -FXZ ]#清除所有已制定的规则iptables -F#清除用户 "自定义"iptables -X#将所有链表的计数与流量统计都归零iptables -Z#这三个命令会将本机防火墙的所有规则都清除，但却不会改变 默认策略 定义默认策略 12345--policy, -Piptables -P INPUT DROPiptables -P OUTPUT ACCESSiptables -P FORWARD ACCEPT 开放某个端口 1234567891011121314151617181920212223#允许本地回环接口(即运行本机访问本机)iptables -A INPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT#允许已建立的或相关连的通行iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT#针对网卡执行的放行和防御iptables -A INPUT -m mac --mac--source aa:bb:cc:11:22:33 -j DROP#允许所有本机向外的访问iptables -A OUTPUT -j ACCEPT#允许访问22端口iptables -A INPUT -p tcp --dport 22 -j ACCEPT#允许访问80端口iptables -A INPUT -p tcp --dport 80 -j ACCEPT# #禁止其他未允许的规则访问iptables -A INPUT -j reject#禁止其他未允许的规则访问iptables -A FORWARD -j REJECT 屏蔽IP 12345#屏蔽单个IP的命令iptables -I INPUT -s 123.45.6.7 -j DROP#封整个段即从123.0.0.1到123.255.255.254的命令iptables -I INPUT -s 123.0.0.0/8 -j DROP 查看规则 12345678910#推荐使用iptables-saveiptables-save#备份和恢复iptables-save &gt;/etc/sysconfig/iptablesiptables-restore &lt;/etc/sysconfig/iptablesiptables -L -niptables -L -n --line-numbers 删除已添加规则 1234iptables -L -n --line-numbersiptables -D INPUT 5iptables -D OUTPUT 3 解决重启失效1234iptables-save &gt;/etc/sysconfig/iptables#把此加入开机启动iptables-restore &lt;/etc/sysconfig/iptables 分屏显示tmux命令 — terminal multiplexer 上下分屏: ctrl+b -&gt; &quot; 左右分屏： ctrl_b -&gt; % 切换屏幕： ctrl+b -&gt; o 关闭终端： ctrl+b -&gt; x 上下屏与左右屏切换： ctrl+b -&gt; 空格 帮助： ctrl+b -&gt; ? 命令模式： ctrl+b -&gt; : 运维常见命令以下命令来自：知乎-运维工程师技能-知道创宇的回答 I/O, Device: blktrace: 收集磁盘IO信息中当IO进行到块设备层时的详细信息 perf: 全称Performance Event，是用来进行软件性能分析的工具。它不但可以分析指定应用程序的性能问题，也可以用来分析内核的性能问题，当然也可以同时分析应用代码和内核，从而全面理解应用程序中的性能瓶颈。 iotop: 用来监视磁盘I/O使用状况的top类工具 iostat: 用于监视系统输入输出设备和CPU的使用情况。它的特点是汇报磁盘活动统计情况，同时也会汇报出CPU使用情况。同vmstat一样，iostat也有一个弱点，就是它不能对某个进程进行深入分析，仅对系统的整体情况进行分析。 Network: ping: 测试主机之间网络的连通性。执行ping指令会使用ICMP传输协议，发出要求回应的信息，若远端主机的网络功能没有问题，就会回应该信息，因而得知该主机运作正常。 ip: 来显示或操纵Linux主机的路由、网络设备、策略路由和隧道，是Linux下较新的功能强大的网络配置工具。 ifconfig: 配置和显示Linux内核中网络接口的网络参数。用ifconfig命令配置的网卡信息，在网卡重启后机器重启后，配置就不存在。要想将上述的配置信息永远的存的电脑里，那就要修改网卡的配置文件了。 dig: 域名查询工具，可以用来测试域名系统工作是否正常。 iftop: 实时流量监控工具,监控TCP/IP连接等,缺点就是无报表功能。 ifstat: 网络接口监测工具,比较简单看网络流量。 nload: 查看系统带宽 neghogs: 查看进程流量 ethtool: 检查网卡支持的带宽 tcpdump: 是一款sniffer工具，它可以打印所有经过网络接口的数据包的头信息 netstat: 打印Linux中网络系统的状态信息，可让你得知整个Linux系统的网络情况。 nicstat: 是一款分析网卡流量信息的工具 sar: 是Linux下系统运行状态统计工具，它将指定的操作系统状态计数器显示到标准输出设备。sar工具将对系统当前的状态进行取样，然后通过计算数据和比例来表达系统的当前运行状态。它的特点是可以连续对系统取样，获得大量的取样数据。取样数据和分析的结果都可以存入文件，使用它时消耗的系统资源很小。 /proc: 一个虚拟文件系统 FS: fdisk: 用于观察硬盘实体使用情况，也可对硬盘分区 du: 对文件和目录磁盘使用的空间的查看 df: 显示磁盘分区上的可使用的磁盘空间 Scheduler, VM: strace: strace命令是一个集诊断、调试、统计与一体的工具，我们可以使用strace对应用的系统调用和信号传递的跟踪结果来对应用进行分析，以达到解决问题或者是了解应用工作过程的目的。 vmstat: 显示虚拟内存状态，但是它可以报告关于进程、内存、I/O等系统整体运行状态。 slabtop: 以实时的方式显示内核slab缓冲区的细节信息 dstat: 是一个全能系统信息统计工具 free: 显示当前系统未使用的和已使用的内存数目，还可以显示被内核使用的内存缓冲区 perf: top: 实时动态地查看系统的整体运行情况，是一个综合了多方信息监测系统性能和运行信息的实用工具 pidstat: 用于监控全部或指定进程的cpu、内存、线程、设备IO等系统资源的占用情况 mpstat: 主要用于多CPU环境下，它显示各个可用CPU的状态]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
        <tag>Bash</tag>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yaml]]></title>
    <url>%2F2017%2F09%2F02%2FYaml%2F</url>
    <content type="text"><![CDATA[参考: 维基百科: https://zh.wikipedia.org/wiki/YAML YAML: https://yaml.org/ YAML语法检测: http://www.yamllint.com 概述YAML: YAML Ain’t Markup Language.YAML is a human friendly data serialization standard for all programming languages. YAML（/ˈjæməl/，尾音类似camel骆驼）是一个可读性高，用来表达数据序列的格式。YAML是”YAML Ain’t a Markup Language”(YAML不是一种标记语言)的递归缩写。在开发的这种语言时，YAML的意思其实是：”Yet Another Markup Language”（仍是一种标记语言，但为了强调这种语言以数据做为中心，而不是以标记语言为重点，而用反向缩略语重命名。 YAML是专门用来写配置文件的语言，非常简洁和强大，远比JSON格式方便。 YAML的特点: YAML数据可在编程语言之间移植 包括数据一致的数据模型 人类易于阅读 支持单向处理 易于实现和使用 语法规则基本语法规则如下： 大小写敏感 使用缩进表示层级关系 缩进时不允许使用Tab键，只允许使用空格 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可(一般2个或4个) #表示单行注释，不支持多行注释。多行注释请使用多个# 具有单个流的多个文档用3个连字符(---)分隔 阻止列表项包括与周围块级相同的缩进，因为-符号被视为缩进的一部分 格式YAML支持三种格式： 对象：键值对的集合，又称为映射(mapping)/哈希(hashes)/字典(dictionary) 数组：一组按次序排列的值，又称为序列(sequence)/列表(list) 纯量值（scalars）：单个的、不可再分的值 1234567#栗子- key1: value1- key2: value2#一个列表，两个对象，四个纯量 对象对象是一组键值对，使用冒号结构表示。 12345key: vaule#Yaml也允许另一种写法，将所有键值对写成一个行内对象。hash: &#123; name: Steve, foo: bar &#125; 数组又称为列表或序列。 1234567- list- sequence- array#数组也可以采用行内表示法。animal: [list, sequence, array] 数据结构的子成员是一个数组，则可以在该项下面缩进一个空格。 1234- - Cat - Dog - Goldfish 纯量值纯量是最基本的、不可再分的值。 － 字符串－ 布尔值－ 整数－ 浮点数－ Null－ 时间－ 日期 复合结构对象和数组可以结合使用，形成复合结构。 123456789languages: - Ruby - Perl - Pythonwebsites: YAML: yaml.org Ruby: ruby-lang.org Python: python.org Perl: use.perl.org 特殊符号 ---: 表示文档开始；分割不同内容 ...和---的配合使用: 在一个配置文件中代表一个文件的结束 !!: 类型强行转换 &gt;: 在字符串中折叠换行 |: 保留换行符 引用 &amp;: 完成锚点定义 *: 完成锚点引用 合并内容: 主要和锚点配合使用，可以将一个锚点内容直接合并到一个对象中 123456789101112#栗子---Time: 2018-07-17T15:02:31+08:00User: edWarning: This is an error message for the log file---Time: 2018-07-17T15:05:21+08:00User: edWarning: A slightly different error message. 1234567891011#栗子---time: 20:03:20player: Sammy Sosaaction: strike (miss)...---time: 20:03:47player: Sammy Sosaaction: grand slam... 123string: - !!str 54321 - !!str true]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Yaml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown]]></title>
    <url>%2F2017%2F09%2F01%2FMarkdown%2F</url>
    <content type="text"><![CDATA[参考: Markdown-wiki Markdown官网 Markdown中文文档 Markdown语法 果冻虾仁 关于Markdown 是一种轻量级标记语言。它允许人们使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML(或者HTML)文档。 语法 首行缩进12345678#一个空格&amp;ensp;#两个空格&amp;emsp;#不断行空白格&amp;nbsp; 栗子： &ensp;一个空格； &emsp;两个空格； &nbsp;不断行空白格； 段落与换行 段落的前后必须是空行 空行是指行内什么都没有，或者只有空白符（空格或制表符） 相邻两行文本，如果中间没有空行，会显示在一行中（换行符被转换为空格） 如果需要在段内加入换行 可以在前一行的末尾加入至少两个空格，然后换行写其它的文字 Markdown中的多数区块都需要在两个空行之间 粗体和斜体语法： 1234*斜体*, _斜体_**粗体*****粗斜体***~~删除线~~ 显示效果： 斜体, 斜体 粗体 粗斜体 删除线 分级标题Setext形式大标题： 123456一级大标题========二级大标题-------- atx形式普通标题： 12345# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题 超链接MarkDown支持两种形式的链接语法：行内式和参考式。 行内式语法说明：[ ] 里面写链接文字，( ) 里面写链接地址，()中的” “可以指定title属性。 代码： 欢迎来到 [简书](www.jianshu.com &quot;Jianshu&quot;) 效果： 欢迎来到 简书 参考式参考式超链接一般用在学术论文上面，或某一个链接在文章中多处使用，那么引用的方式创建链接将非常好，它可以让你对链接进行统一的管理。 语法说明： 123参考式链接分为两部分，文中的写法[链接文字][链接标记]，在文本任意位置添加[链接标记]:链接地址 “链接标题”，链接地址与链接标题前有一个空格如果链接文字本身可以作为链接标记，也可以写成[链接文字][][链接文字]：链接地址的形式 代码： 123456简书里面有 [简书早报][1]、[简书晚报][2]以及 [简黛玉][3][简黛玉 美人][3] 是一个[才女][][1]:http://www.jianshu.com &quot;Jianshu&quot;[2]:http://www.jianshu.com &quot;EveningPaper&quot;[3]:http://www.jianshu.com[才女]:http://www.jianshu.com 效果： 简书里面有 简书早报、简书晚报以及简黛玉简黛玉 美人 是一个才女 自动链接MarkDown支持以比较简短的自动链接形式来处理网址和电子邮件，只要用&lt;&gt;包起来，MarkDown就会自动把它转成链接。 代码： 12&lt;http://example.com&gt;&lt;address@example.com&gt; 锚点MarkDown Extra只支持在标题后插入锚点，其他地方无效。锚点中的标题如果有空格，则锚点无效。现在的锚点支持中文标题。 代码： 12345678910锚点连接页内标题[标题一](#Title1)[标题二](#Title2)[标题三](#标题3)# Title1## Title2### 标题3 列表无序列表使用 * ，+ ，- 表示无序列表 代码： 123- 无序列表1- 无序列表2- 无序列表3 效果： 无序列表1 无序列表2 无序列表3 有序列表有序列表使用数字接着英文点 代码： 1231. 有序列表12. 有序列表23. 有序列表3 效果： 有序列表1 有序列表2 有序列表3 定义型列表定义型列表由名词和解释组成。一行写上定义，紧跟一行写上解释。解释的写法：紧跟一个缩进（Tab） 列表缩进列表项目标记通常是放在最左边，但是其实也可以缩进，最多3个空格，项目标记后则一定要接着至少一个空格或制表符。 代码： 123* 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。* 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 效果： 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 引用引用需要在被引用的文本前加上&gt;符号 代码： 12&gt; 引用1&gt; 引用2 效果： 引用1引用2 引用的多层嵌套区块引用可以嵌套（如引用的引用），只要根据层次加上不同数量的 &gt;符号 代码： 123&gt;&gt;&gt; 请问MarkDown怎么用？&gt;&gt; 自己看教程！&gt; 教程在哪里？ 效果： 请问MarkDown怎么用？ 自己看教程！ 教程在哪里？ 插入图像图片的创建方式与超链接类似。 代码： ![](http://zhangxx5678.lofter.com/post/39b969_df4f526#) 内容目录在段落中填写 [TOC] 以显示全文内容结构目录 注脚在需要添加注脚的文字后加上注脚名字 注脚名字，称为加注。然后在文中的任意位置（一般最后）添加脚注，脚注前必须有对应的脚注名字。注脚与注脚间必须空一行！注脚自动被搬运到最后面，请到文章末尾查看，并且脚注后的链接可以直接跳转会到加注的地方 代码： 123使用 MarkDown[^1]可以提高书写效率，直接转换成 HTML[^2][^1]:MarkDown是一种纯文本标记语言[^2]:HTML超文本标记语言 效果： 使用 MarkDown1可以提高书写效率，直接转换成 HTML2 分割线可以在一行中用 三个以上的 *,-,_ 建立一个分割线，行内不能有其他东西。 代码： 12345671. * * *2.3. ***4.5. - - -6.7. --- 效果： GitHub中的表情Github的Markdown语法支持添加emoji表情，输入不同的符号码（两个冒号包围的字符）可以显示出不同的表情。 比如:blush:,显示效果为 :blush: 每个表情对应的符号码：https://www.webpagefx.com/tools/emoji-cheat-sheet/ 或者，果冻虾仁的整理：https://github.com/guodongxiaren/README/blob/master/emoji.md Diff语法版本控制系统中都少不了diff功能——展示一个文件内容的增加与删除。 绿色(+)表示新增 红色(-)表示删除 语法效果与代码高亮类似，在三个反引号后面写上diff。在内容中+表示新增，-表示删除。 123456+ 111+ 11+ 1- 222- 22- 2 扩展语法Markdown标准 本身所包含的功能有限，所以产生了许多第三方扩展语法，如 GFW, GitHub Flavored Markdown Tasklist代码： 12345- [ ] Monday- [ ] Tuesday- [ ] Wednesday- [ ] Tuesday- [ ] Friday 效果： [ ] Monday [ ] Tuesday [ ] Wednesday [ ] Tuesday [ ] Friday 表格 不管是哪种方式，第一行为表头，第二行为分割表头和主体部分，第三行开始每一行为一个表格行 列与列之间用管道符号 | 隔开 还可设置对齐方式 左对齐 :| 右对齐 |: 中对齐 :|: 代码： 12345学号 | 姓名 | 分数- | - | -001 | 张三 | 78002 | 李四 | 67003 | 王五 | 99 学号 姓名 分数 001 张三 78 002 李四 67 003 王五 99 GitHub上的表格GitHub上的表格与上有一点不同。 12345| 学号 | 姓名 | 分数| - | - | -| 001 | 张三 | 78| 002 | 李四 | 67| 003 | 王五 | 99 学号 姓名 分数 001 张三 78 002 李四 67 003 王五 99 代码块和高亮代码块插入代码的方式有两种，一种是利用缩进(Tab)，另一种是利用反引号 `` 和 ``` ``` 代码： 1Python语言的输出函数 `Print()` 怎么使用？ 效果： Python语言的输出函数 Print() 怎么使用？ 123import osfrom flask import Flaskapp = Flask(app) 高亮在 ``` 之后添加代码的语言 代码： ```pythonimport osfrom flask import Flaskapp = Flask(app)``` 效果： 123import osfrom flask import Flaskapp = Flask(app) 流程图flow chart/flow diagram，需要安装额外的插件才能支持流程图。 流程图语法参考: https://mermaidjs.github.io/Hexo Plugins: https://hexo.io/plugins/ hexo默认好像不支持流程图，需要在hexo Plugins去查找此类插件，安装此类插件，然后修改hexo配置文件。具体的使用方法请参考插件说明。 数学公式参考: https://blog.csdn.net/lanxuezaipiao/article/details/44341645 https://juejin.im/post/5a6721bd518825733201c4a2 LaTex数学符号表 LaTEX: https://zh.wikipedia.org/wiki/LaTeX是一种跨平台的基于TEX的排版系统，对于生成复杂表格和数学公式，这一点表现得尤为突出。因此它非常适用于生成高印刷质量的科技和数学、化学类文档。 MathJax: https://en.wikipedia.org/wiki/MathJaxMathJax是一种跨浏览器JavaScript库，它使用MathML，LaTeX和ASCIIMathML 标记在Web浏览器中显示数学符号。MathJax作为Apache License下的开源软件。 MathJax语法: https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference 由于许多支持markdown的都不会显示LaTeX公式，所以有一个加载链接来显示的效果。 参考知乎: https://www.zhihu.com/question/26887527 1234#如![](http://latex.codecogs.com/gif.latex?\\frac&#123;1&#125;&#123;1+sin(x)&#125;)#后接具体的公司，注意转移 公式许多扩展的Markdown编辑器支持基于Mathjax编写的数学公式。 LaTeX有两种数学公式： 行内式与其它文字混杂。这是一个行内式栗子 块级公式单独成行。 块级公式 栗子： 12345678这是一个$E=mc^2$公式$$\sum_&#123;i=1&#125;^n a_i=0$$$$f(x_1,x_x,\ldots,x_n) = x_1^2 + x_2^2 + \cdots + x_n^2 $$$$\sum^&#123;j-1&#125;_&#123;k=0&#125;&#123;\widehat&#123;\gamma&#125;_&#123;kj&#125; z_k&#125;$$ 基本类型 上/下标 分式 根式 求和 积分 矩阵 数组 空格 省略号 矢量 括号 希腊字母 上下标 上标(superscript): ^ 下标(subscript): _ 如果上小标内容大于一个字符，要用{}虽然空格和顺序对公式没有影响，但建议使用统一的风格，不用混用： 先下标后上标 先上标后下标 12345678910111213141516171819#上标$$E=mc^2$$#下标$$x_2$$#上下标$$x_&#123;subscript&#125; ^&#123;superscript&#125;$$#左右上下标$$&#123;&#125;_&#123;a&#125; ^&#123;b&#125; x ^&#123;c&#125; _&#123;d&#125;$$$$&#123;&#125;_&#123;左下&#125; ^&#123;左上&#125; x ^&#123;右上&#125; _&#123;右下&#125;$$#空格和顺序其实没影响` 分式分式(fraction)为了区分frac是函数不是公式，使用\frac进行转义 1234567#用法$$\frac&#123;分子&#125;&#123;分母&#125;$$$$\frac&#123;x+y&#125; &#123;2&#125;$$$$\frac&#123;1&#125; &#123;1+\frac&#123;1&#125; &#123;2&#125;&#125; 根式开方(sqrt)使用\sqrt转义 123456789#默认为开平方$$\sqrt[开方次数]&#123;开方因子&#125;$$$$\sqrt &#123;x&#125;$$$$\sqrt[3] &#123;\frac&#123;x&#125; &#123;y&#125;&#125;$$$$\sqrt[x] &#123;1+\sqrt[y] &#123;1+a^2&#125;&#125;$$ 求和求和(summation)使用\sum转义 1234567#用法$$\sum_&#123;起点&#125;^&#123;终点&#125;表达式$$$$\sum_&#123;i=0&#125; ^&#123;n&#125; \frac&#123;1&#125; &#123;k&#125;$$$$\sum_&#123;i=0&#125;^&#123;n&#125; i^2=\frac&#123;(n^2+n)(2n+1)&#125; &#123;6&#125;$$ 积分积分(integral)使用\int转义 12345#用法$$\int_&#123;下限&#125;^&#123;上限&#125; 被积函数d被积量$$$$\int_&#123;a&#125;^&#123;b&#125; f(x)dx$$ 矩阵矩阵(matrix) 1234567891011121314151617181920212223242526#&amp;区分行间元素#\\\\代表换行#无括号矩阵$$\begin&#123;matrix&#125;1 &amp; 2 \\\\ 3 &amp; 4 \end&#123;matrix&#125;$$#花括号矩阵$$\begin&#123;pmatrix&#125; 1&amp;2 \\\ 3&amp;4 \end&#123;pmatrix&#125;$$#中括号矩阵$$\begin&#123;bmatrix&#125; 1&amp;2 \\\\ 3&amp;4 \end&#123;bmatrix&#125;$$#大括号矩阵$$\begin&#123;Bmatrix&#125; 1&amp;2 \\\\ 3&amp;4 \end&#123;Bmatrix&#125;$$#竖线矩阵$$\begin&#123;vmatrix&#125; 1&amp;2 \\\\ 3&amp;4 \end&#123;vmatrix&#125;$$#双竖线矩阵$$\begin&#123;Vmatrix&#125; 1&amp;2 \\\\ 3&amp;4 \end&#123;Vmatrix&#125;$$ 数组数组(array) 空格空格(space/blank) 12345678910111213141516171819202122232425#紧贴$$a\!b$$#正常$$ab$$#小空格$$a\,b$$#中空格$$a\;b$$#大空格$$a\ b$$#quad空格$$a\quad b$$#两个quad空格$$a\qquad b$$ 省略号省略号(ellipsis) \ldots与文本底线对齐的省略号 cdots与文本中线对齐的省略号 1234#\ldot, \cdot可表示单个点，对齐方式不变$$f(x_1,x_2,\ldots,x_n) = x_1^2 + x_2^2 + \cdots + x_n^2$$ 矢量矢量(vector) 1234567#用法$$\vec&#123;矢量值&#125;$$$$\vec&#123;a&#125;$$$$\vec&#123;a&#125; \cdot \vec&#123;b&#125;=0$$ 括号括号(bracket) (), [], |可以直接表示，而{}本来是用于分组，因此需要转义\{\}来表示，也可使用\lbrace, \rbrace来表示。 原始括号并不会随着公式大小缩放，需要使用\left和\right标记实现自适应调整，它两必须成对出现。 12345678910111213141516171819202122232425262728293031323334#小括号()$$(\frac&#123;1&#125;&#123;2&#125;)$$$$\left( \frac&#123;1&#125;&#123;2&#125; \right)$$#中括号[]$$[\frac&#123;1&#125;&#123;2&#125;]$$$$\left[ \frac&#123;1&#125;&#123;2&#125; \right]$$#绝对值|$$|\frac&#123;1&#125;&#123;2&#125;|$$$$\left| \frac&#123;1&#125;&#123;2&#125; \right|$$#大括号&#123;&#125;$$\&#123; \frac&#123;1&#125;&#123;2&#125; \&#125;$$$$\left\&#123; \frac&#123;1&#125;&#123;2&#125; \right\&#125;$$#尖括号&lt;&gt;#\langle \rangle$$\langle \frac&#123;1&#125;&#123;2&#125; \rangle$$$$\left\langle \frac&#123;1&#125;&#123;2&#125; \right\rangle$$#向正无穷大取整(ceil)$$\lceil \frac&#123;1&#125;&#123;2&#125; \rceil$$$$\left\lceil \frac&#123;1&#125;&#123;2&#125; \right\rceil$$#向下取整$$\lfloor \frac&#123;1&#125;&#123;2&#125; \rfloor$$$$\left\lfloor \frac&#123;1&#125;&#123;2&#125; \right\rfloor$$ 希腊字母 大写 LaTex代码 小写 LaTex代码 中文名称 A A α \alpha 阿尔法 B B β \beta 贝塔 Γ Γ γ \gamma 伽马 D D δ \delta 德尔塔 E E ϵ \epsilon 伊普西隆 Z Z ζ \zeta 泽塔 H H η \eta 伊塔 Θ Θ θ \theta 西塔 I I ι \iota 约塔 K K κ \kappa 卡帕 Λ Λ λ \lambda 兰姆达 M M μ \mu 缪 N N ν \nu 纽 X X ξ \xi 克西 O O ο \omicron 欧米克隆 P P π \pi 派 R R ρ \rho 柔 Σ Σ σ \sigma 西格玛 T T τ \tau 陶 Υ Υ υ \upsilon 宇普西隆 Φ Φ ϕ \phi 弗爱 X X χ \chi 卡 Ψ Ψ ψ \psi 普赛 Ω Ω ω \omega 欧米伽 1234567$$\alpha$$$$\beta$$$$\gamma$$$$\delta$$ 特殊符号 关系运算符 集合运算符 对数运算符 三角运算符 微积分运算符 逻辑运算符 带帽符号 连线符号 箭头符号 关系运算符12345678910111213141516171819±：\pm ×：\times ÷：\div ∣：\mid ∤：\nmid ⋅⋅：\cdot ∘：\circ ∗：\ast ⨀：\bigodot ⨂：\bigotimes ⨁：\bigoplus ≤：\leq ≥：\geq ≠：\neq ≈：\approx ≡：\equiv ∑：\sum ∏：\prod ∐：\coprod 集合运算符12345678910111213∅ ：\emptyset ∈：\in ∉：\notin ⊂：\subset ⊃：\supset ⊆：\subseteq ⊇：\supseteq ⊇：\bigcap ⋃：\bigcup ⋁：\bigvee ⋀：\bigwedge ⨄：\biguplus ⨆：\bigsqcup 对数运算符123log：\log lg：\lg ln：\ln 三角运算符123456789⊥ ：\bot ∠：\angle 30∘：30^\circ sin：\sin cos：\cos tan：\tan cot：\cot sec：\sec csc：\csc 微积分运算符123456789′：\prime ∫：\int ∬：\iint ∭：\iiint ∬∬：\iiiint ∮：\oint lim：\lim ∞：\infty ∇：\nabla 逻辑运算符1234567∵ ：\because ∴：\therefore ∀：\forall ∃：\exists ≠：\not= ≯：\not&gt; ⊄：\not\subset 戴帽符号123y^ ：\hat&#123;y&#125; yˇ：\check&#123;y&#125; y˘：\breve&#123;y&#125; 箭头符号123456789101112↑ ：\uparrow ↓：\downarrow ⇑：\Uparrow ⇓：\Downarrow →：\rightarrow ←：\leftarrow ⇒：\Rightarrow ⇐：\Leftarrow ⟶：\longrightarrow ⟵：\longleftarrow ⟹：\Longrightarrow ⟸：\Longleftarrow 生成GitHub上的徽章 生成徽章: https://shields.io/ 生成进度： https://github.com/fehmicansaglam/progressed.io 进入徽章(Badge)网站，找到如下部分生成徽章。之后会得到一个徽章地址，在GitHub中插入此徽章地址就好。 进入进度(Progress)网站，找到某个格式的链接，在GitHub中插入此链接。 编辑器介绍一些常用的书写、编辑Markdown的工具。 MarkdownPad Windows (windows); Texts (Windows, osX); MarkPad (Windows); Haroopad (Windows, osX, Linux); ReText (Linux); 等等 格式转换Markdown文档可以方便地转换为 HTML, Word, PDF 等文件格式。可以利用 软件 或者 命令 转换文件。 转换为 HTML 转换为 PDF 转换为 Word]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx]]></title>
    <url>%2F2017%2F09%2F01%2FNginx%2F</url>
    <content type="text"><![CDATA[参考： Nginx官方文档 Nginx-Wikipedia Nginx-repo 环境： CentOS7x86_64; Nginx1.12.1 Nginx介绍Nginx（发音同engine x）是一个 Web服务器，也可以用作反向代理，负载平衡器和 HTTP缓存。它能反向代理 HTTP, HTTPS, SMTP, POP3, IMAP 的协议连接。基于BSD-like协议发行，支持多种操作系统。 作为HTTP服务软件的后起之秀，Nginx有很多优点： 在性能上，Nginx占用的系统资源更少，支持更多的并发连接（特别是小静态文件场景下），达到更高的访问效率； 在功能上，Nginx不仅是一个优秀的Web服务软件，还可以作为反向代理 负载均衡及缓存使用。它类似于LVS负载均衡及HAProxy等专业代理软件，又类似于Squid等专业缓存服务软件； 在安装配置上，Nginx方便、简单、灵活。 Nginx功能丰富，可作为HTTP服务器、反向代理服务器、邮件服务器。支持FastCGI, SSL, Virtual Host, URL Rewrite, Gzip等功能，并支持很多第三方模块扩展。 与PHP的集成自PHP-5.3.3起，PHP-FPM加入到了PHP核心，编译时加上—enable-fpm即可提供支持。PHP-FPM以守护进程在后台运行，Nginx响应请求后，自行处理静态请求，PHP请求则经过fastcgi_pass交由PHP-FPM处理，处理完毕后返回。Nginx和PHP-FPM的组合，是一种稳定、高效的PHP运行方式，效率要比传统的Apache和mod_php高出不少。 Nginx的重要特性： 可针对静态资源高速高并发访问及缓存；可使用反向代理加速，并且可进行数据缓存；具有简单负载均衡、节点健康检查和容错功能；支持远程FastCGI、Uwsgi、SCGI、Memcached Servers的加速和缓存；支持SSL、TLS、SNI；具有模块化的架构：过滤器包括gzip压缩、ranges支持、chunked响应、XSLT、SSI及图像缩放等功能。在SSI过滤器中，一个包含多个SSI的页面，如果FastCGI或反向代理处理，可被并行处理；它具备的其他WWW服务特性：支持基于名字、端口及IP的多虚拟主机站点；支持Keep-alived和pipelined连接；可进行修改Nginx配置，并且在代码上线时，可平滑重启，不中断业务访问；可自定义访问日志格式，临时缓冲些日志操作，快速日志轮询及通过rsyslog处理日志；可利用信号控制Nginx进程；支持 3xx-5xx HTTP状态码重定向；支持rewrite模块，支持URI重写及正则表达式匹配；支持基于客户端IP地址和HTTP基本认证的访问控制；支持PUT、DELETE、MKCOL、COPY及MOVE等较特殊的HTTP请求方法；支持FLV流和MP4流技术产品应用；支持HTTP响应速率限制；支持同一IP地址的并发连接或请求数连接；支持邮件服务器代理； Nginx常用功能http代理于反向代理Nginx在做反向代理时，提供性能稳定，并且能够提供配置灵活的转发功能。Nginx可以根据不同的正则匹配，采取不同的转发策略，比如图片文件结尾的走文件服务器，动态页面走web服务器，只要你正则写的没问题，又有相对应的服务器解决方案，你就可以随心所欲的玩。并且Nginx对返回结果进行错误页跳转，异常判断等。如果被分发的服务器存在异常，他可以将请求重新转发给另外一台服务器，然后自动去除异常服务器。 负载均衡Nginx提供的负载均衡策略有2种：内置策略和扩展策略。内置策略为轮询，加权轮询，Ip hash。扩展策略，就天马行空，只有你想不到的没有他做不到的啦，你可以参照所有的负载均衡算法，给他一一找出来做下实现。 web缓存Nginx可以对不同的文件做不同的缓存处理，配置灵活，并且支持FastCGI_Cache，主要用于对FastCGI的动态程序进行缓存。配合着第三方的ngx_cache_purge，对制定的URL缓存内容可以的进行增删管理。 web服务Nginx作为Web服务器的主要应用场景包括： 使用Nginx运行HTML、JS、CSS、小图片等静态数据； 结合FastCGI运行PHP等动态程序（如fastcgi_pass）； 结合Tomcat/Resin等支持Java动态程序（如proxy_pass）。 Nginx安装RPM源安装:12345678yum install -y gcc gcc-c++ make libtool zlib zlib-devel openssl openssl-devel pcre pcre-devel 安装依赖rpm -ivm http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm 安装RPM源#安装Nginxyum install -y nginx#查询安装rpm -q nginx 添加Nginx yum repository安装12345678910vim /etc/yum.repos.d/nginx.repo#必须唯一[nginx]name=nginx-repobaseurl=http://nginx.org/packages/$OS/$OSRELEASE/$basearch/gpgcheck=0enabled=1 源码安装12345678910#建议解压于此目录cd /usr/local/srcwget http://xxx.xx.com/nginx.tar.gztar -zxvf nginx.tar.gzcd ./nginx./configure --prefix=/usr/localmake&amp;&amp;make install Nginx配置*.confNginx配置文件主要分为四部分： main(全局设置)； server(主机设置)； upstream(上游服务器设置)，用于反向代理和负载均衡； location(URL匹配特定位置)。 栗子：运行nginx -t检查配置文件有误错误，这很重要! 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#main块user nginx;worker_processes 4;client_max_body_size 10Merror_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 102400;&#125;#http块http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - ...'; access_log /var/log/nginx/access.log main; sendfile on; gzip on; keepalive_timeout 60; include /etc/nginx/conf.d/*.conf; #upstream块 upstream up_name&#123; server ip1; server ip2:port; server domain; &#125; server &#123; server_name www.zhang21.cn; listen 80; listen 443; ssl on; ssl_certificate /dir/path/xxx.crt; ssl_certificate_key /dir/path/xxx.key; location / &#123; root /var/www/zhang; index index.php index.html index.htm; allow 192.168.1.0/22; deny all; &#125; location ~ \.php$ &#123; root /var/www/zhang; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; &#125; &#125;&#125; 全局块：配置影响Nginx全局的指令。一般由运行Nginx服务器的用户组，Nginx进程pid存放路径，日志存放路径，允许生成的worker_processes等。 events块：配置影响Nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网络连接，开启多个网络连接序列化等。 http块：可以嵌套多个server，配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，链接超时时间，单连接请求数等。 server块：配置虚拟主机的相关参数，一个http中可以有多个server。 location块：配置请求的路由，以及各种页面的处理情况。 Nginx http功能模块 模块说明 ngx_http_core_module 一些核心的http参数配置，对应Nginx的配置中的http块 ngx_http_access_module 访问控制模块，用来控制网站用户对Nginx的访问 ngx_http_gzip_module 压缩模块，对Nginx返回的数据压缩，属于性能优化模块 ngx_http_fastcgi_module FastCGI模块，和动态应用相关的模块，如PHP ngx_http_proxy_module proxy代理模块 ngx_http_upstream_module 负载均衡模块，可实现网站的负载均衡及节点的监控检查 ngx_http_rewrite_module URL重写模块 ngx_http_limit_conn_module 限制用户并发连接数及请求数模块 ngx_http_limit_req_module 根据定义的key限制Nginx请求过程的速率 ngx_http_log_module 访问日志模块，以指定的格式记录Nginx访问信息 ngx_http_auth_basic_module web认证模块，设置通过账号，密码访问Nginx ngx_http_ssl_module ssl模块 ngx_http_stub_status_module 记录Nginx基本访问状态信息扥的模块 Nginx的日志时自动切割，并且一行可以记录多个日志格式。 Nginx日志格式 说明 $remote_addr 客户端ip地址 $http_x_forward_for 当前端有代理服务器时，设置web节点记录web节点记录客户端地址的配置 $remote_user 客户端用户名称 $time_local 访问时间和时区 $request 请求的http协议和URL $status 请求状态，如200 $body_bytes_sent 发送给客户端文件主体内容大小 $http_referer 从哪个页面链接访问过来 $http_user_agent 客户端浏览器信息 serverhttp服务上支持若干虚拟主机。每个虚拟主机对应一个server配置项，配置项里面包含该虚拟主机的相关配置。每个server里面可同时有多个server_name。 在提供mail代理服务时，也可建立若干server，每个server通过监听地址或端口来区分。 12345#监听端口，默认80listen 80;listern 443;#listen 88server_name www.zhang21.cn locationlocation是http服务中，某些特定的URL对应的一系列配置项。 root 定义此location的根目录位置，一般放置在server里 index 定义路径下的默认访问的文件名 12345location / &#123; root /dir/path; index index.html index.htm;&#125; location的正则写法location的使用方法： 符号 含义 优先级 用法 = 精确匹配 最高 location = ~ 区分大小写的正则匹配 次次之 location ~ ~* 不区分大小写的正则匹配 次次之 location ~* ^~ 常规字符串匹配 次之 location ^~ / 通用匹配 最低 location / 优先级： = &gt; 完整路径 &gt; ^~ &gt; ~, ~* &gt; 部分路径 &gt; / location使用建议location的使用根据实际情况来定。 但个人觉得至少应该有三个匹配规则： 直接匹配网站跟，通过域名访问网站首页比较频繁 处理静态文件请求，这是Nginx作为http服务器的强项 通用规则，用来转发动态请求到后端的应用服务器(符php-fpm) 根据实际情况的自定义需求 1234567891011121314151617181920212223242526272829303132333435363738394041server &#123; listen 80; listen 443; server_name zhang21.cn www.zhang21.cn; root /dir/path/zhang; ssl on; ssl_certificate /etc/nginx/ssl/zhang.crt; ssl_certificate_key /etc/nginx/ssl/zhang.key; #rewtire ^(.*)$ https://zhang21.cn/$1 permanent; return 301 https://zhang21.cn/$requets_uri location = / &#123; rewrite .*? /index.html last; &#125; location ^~ /static/ &#123; root /dir/path/zhang/static; &#125; location ~* \.(gif|jpg|png|css|js)$ &#123; root /dir/path/zhang/static; &#125; location / &#123; if (!-f $request_filename) &#123; rewrite ^([^\?]+)$ /index.php?q=$1 last; &#125; location ~ \.php$ &#123; root /dir/path; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; &#125;&#125; RewriteNginx的主要功能是实现URL地址重写。Nginx的rewrite规则需要PCRE软件的支持，即通过Perl兼容正则表达式语法进行规则匹配。 Nginx rewrite语法： 123server, location, ifrewrite regex replacement [flag] rewrite的功能就是，使用Nginx提供的全局变量或自定义变量，结合正则表达式(re)和标志位实现URL重写以及重定向 rewrite只能放在server，location，if中，并且只能对域名后边的除去传递的参数外的字符串起作用 如果相对域名或参数字符串起作用，可以使用全局变量匹配，也可使用proxy_pass反向代理 表面看rewrite和location功能有点像，都能实现跳转。主要区别在于： rewrite实在同一域名内更改获取资源的路径 location是对一类路径做访问控制或反向代理，可proxy_pass到其它机器 循环超多10次，返回500 Internal Server Error! flag last 表示完成rewrite，继续向下匹配新的规则 break 停止执行当前虚拟主机的后续rewrite指令集 redirect 返回302临时重定向，地址栏会显示跳转后的地址 permanent 返回301永久重定向，地址栏会显示跳转后的地址 last和break用来实现URL重写，浏览器地址栏的URL地址不变，但在服务器端访问的程序及路径发生了变化 redirect和permanent用来实现URL跳转，浏览器地址栏会显示跳转后的URL地址 Nginx的rewrite功能应用非常广泛： 可调整用户浏览的URL，使其看起来更规范 将动态URL地址伪装成静态地址提供服务 让旧域名跳转到新域名上 根据特殊变量、目录、客户端的信息进行URL跳转 if指令if语法： 123if (condition) &#123; xxx;&#125; if的条件可以是如下内容： 当表达式只是一个变量时，如果值为空或任何以0开头的字符串都会被当作false 直接比较变量和内容时，使用=或!= ~正则表达式匹配，~*不区分大小写的正则匹配，!~不匹配 -f和!-f，用来判断是否存在文件 -d和!-d，用来判断是否存在目录 -e和!-e，用来判断时都存在文件或目录 -x和!-x，用来判断文件是否可执行 栗子： 123456789101112131415161718192021222324if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break;&#125;if ($http_cookie ~* "id=([^;])(?:;|$)") &#123; set $id $1;&#125;if ($http_method = POST) &#123; return 405;&#125;if (!-f $request_filename) &#123; break; proxy_pass http://zhang;&#125;if ($invalid_referer) &#123; return 403;&#125; Nginx全局变量常用作if判断的全局变量： 变量 描述 备注 $args 等于请求行中的参数 同$query_string $body_bytes_sent 响应是发送的body字节数 xxx $content_length Request Header中的Content-Length字段 内容长度 $content_type Request Header中的Content-Type字段 内容类型 $document_root 当前根路径 xxx $host 请求主机头字段，否则为服务器名称 xxx $hostname 主机名 xxx $http_user_agent 客户端agent信息 xxx $http_cookie 客户端cookie信息 xxx $is_args 如果有$args参数，这个变量等于”?”，否则等于空 xxx $limit_rate 限制连接数度 xxx $remote_addr 客户端IP地址 xxx $remote_port 客户端端口 xxx $remote_user 经过Auth Basic Module验证的用户名 要先开启Nginx认证 $request 用户请求信息 xxx $request_method 客户端请求方法 通常为POST或GET $request_body 记录POST过来的数据信息 xxx $request_filename 当前请求的文件路径 由root或alias指令与URI请求生成 $request_completion 如果请求结束，设置为OK。否则为空 xxx $scheme HTTP方法 如http, https $server_protocol 请求使用的协议 通常为HTTP/1.0或HTTP/1.1 $server_addr 服务器地址 在完成一次系统调用后可以确定这个值 $server_name 服务器名称 xxx $server_port 请求到达服务器的端口号 xxx $status 请求的响应状态码 如200 $request_uri 包含请求参数的原始URI，不包含主机名 如”/foo/bar.php?arg=abc” $uri 不带请求参数的当前URI，不包含主机名 如”/foo/bar.html” 栗子： 12345678http://localhost:88/test1/test2/test.php$hsot: localhost$server_port: 88$request_uri: http://localhost:88/test1/test2/test.php$document_uri: /test1/test2/test.php$document_root: /var/www/test$request_filename: /var/www/test/test1/test2/test.php rewrite实例12345678910111213141516171819202122232425http &#123; log_format main xxxx; rewrite_log on; server &#123; root /var/www/zhang; location / &#123; error_log logs/rewrite.log notice; rewrite '^/images/([a-z]&#123;2&#125;)/([a-z0-9]&#123;5&#125;)/(.*)\.(png|jpg|gif)'/data?file=$3.$4; set $image_file $3; set $image_type $4; &#125; location /data &#123; access_log logs/images.log main; root /data/images; type_file /$arg_file /images404.html; &#125; location = /image404.html &#123; return 404 "Image Not Found\n"; &#125; &#125;&#125; 访问控制 添加用户密码验证 参考: https://docs.nginx.com/nginx/admin-guide/security-controls/configuring-http-basic-authentication/ 有时需要为我们的网站设置访问账号和密码权限。注意，此密码需要使用加密软件生成，直接写入密码的明文无效。 具体为这两个参数： auth_basic 默认值： auth_basic off; 使用位置：http, server, location, limit_except auth_basic_user_file 使用位置： http, server, location, limit_except 栗子： 12345678cd /etc/nginx/conf.dvim test.conflocation / &#123; auth_basic "nginx auth test"; auth_basic_user_file /etc/nginx/.auth;&#125; 配置用户密码 123456789101112#Verify that apache2-utils (Debian, Ubuntu) or httpd-tools (RHEL/CentOS/Oracle Linux) is installed.yum install -y httpd-tools#htpasswd file usernamehtpasswd .auth user1New password:Re-type new password:Adding password for user user1#查看加密密码cat .authuser1:$apr1$NIOeayen$hTAvJ5ZTwUHE6Hm1MiF920 限制IP访问 allow deny 1234567891011server &#123; ... allow IP1 allow IP2; deny all; location / &#123; allow IP 1; deny all; &#125;&#125; 注意： deny一定要加一个IP，否则会直接跳转403，不在往下执行。如果403默认页是在同一域名下，会造成死循环访问 对于allow的IP短，从允许访问的IP段位从小到大排列，如127.0.0.0/24， 10.10.0.0/16 以deny all结尾，表示除了上面允许的，其它都禁止 语法检查在启动或重启Nginx服务前检查语法非常重要，可以防止因配置错误导致网站重启或重载配置对用户的影响。 每次更改Nginx配置文件后都需要重新加载，将配置信息加载到内存中。这样设计的目的是大幅度提升Nginx的访问性。 123nginx -tnginx -s reload Nginx优化 常用优化 隐藏Nginx版本号一般来说，软件漏洞都和版本有关。因此要尽量隐藏对访问用户显示各类敏感信息。 123456789vim /etc/nginc/nginx.conf#nginx版本号默认是开启的#位置：http, server, locationhttp &#123; server_tokens off|on;&#125; 更改Nginx服务默认用户 修改配置文件 123vim /etc/nginx/nginx.confuser nginx; 如果是编译安装，直接在编译的时候指定用户和组 1./configure --user=nginx --group=nginx 优化Nginx进程对应的配置123456789101112vim /etc/nginx/nginx.confworker_process n;#建议n为CPU核数#高并发场合可考虑为核数*2#查看CPU核数cat /proc/cpuinfo | grep processor | wc -llscputop命令，按1显示所有CPU核数 优化绑定不同的Nginx进程到不同的CPU上默认情况下，Nginx的多个进程有可能跑在某一个CPU或CPU的某一核上，导致Nginx进程使用硬件资源不均。所以，要尽可能地分配不同的Nginx进程给不同的CPU处理，达到充分有效利用硬件的多CPU多核资源的目的。 4核CPU配置举例： 12345vim /etc/nginx/nginx.confworker_processes 4;#CPU亲和力参数worker_cpu_affinity 0001 0010 0100 1000; Nginx事件处理模型优化Nginx的连接处理机制在不同的操作系统会采用不同的I/O模型，在Linux下，Nginx使用epoll的I/O多路复用模型，在FreeBSD中使用kqueue的I/O多路复用模型，在solaris中使用/dev/poll方式的I/O多路复用模型，在Windows中使用的是icop。 配置： 12345678#对于linux内核，推荐使用epoll工作模式#Linux下默认epollvim /etc/nginx/nginx.confevents &#123; use epoll;&#125; Nginx单个进程允许的客户端最大连接数请根据服务器性能和程序的内存使用量来合理制定最大连接数。这个连接数包括了所有连接，如代理服务器连接、客户端的连接、实际的并发连接。 Nginx总并发连接数=worker*worker_connections 123456vim /etc/nginx/nginx.confevents &#123; worker_connections 10240;&#125; 仅仅修改了nginx最大连接数可能还不行，由于Linux系统有ulimit限制，所以可能还要做额外操作。 如：nginx: [warn] 10240 worker_connections exceed open file resource limit: 1024。 配置： 123ulimit -aulimit -n 10240 注意，使用ulimit命令修改的值并不是永久生效的。 Nginx worker进程最大打开文件数可能也要注意ulimit系统限制！ 12345vim /etc/nginx/nginx.confevents &#123; worker_rlimit_nofile 65535;&#125; 开启高效文件传输sendfilesendfile()是作用于两个文件描述符之间的数据拷贝，这个拷贝是在内核之中的，被称为零拷贝。sendfile（）比read和write函数要高效很多，因为write和read函数要把数据拷贝到应用层再进行操作。 12#位置：http, server, location, if in locationsendfile on; tcp_nopush激活或禁用Linux上的TCP_CORK socket选项，仅当开启sendfile生效。允许把 http response和文件的开始部分放在一个文件里发布，其积极作用是减少网络报文段的数量。 12位置： http, server, locationtcp_nopush on; Nginx连接参数，连接超时时间keep-alive可以使客户端到服务器端已经建立的连接一致工作不退出，当服务器有持续请求时，keep-alive会使用已经建立的连接提供服务，从而避免服务器重新建立新连接请求处理。 连接超时的作用： 将无用的连接设置为尽快超时，可保护系统资源（CPU、内存、磁盘）连接很多时，及时断掉那些已经建立好但又长时间不做事的连接，以减少其占用的服务器资源。因为服务器维护连接也是消耗资源的黑客和恶意用户攻击网站，也会不断地和服务器建立多个连接，消耗连接数但啥也不干，大量消耗服务器的资源，此时就应该及时断掉这些恶意占用资源的连接LNMP环境中，如果用户请求了动态服务，则Nginx就会建立连接，请求FastCGI服务以及后端的MySQL服务，此时这个Nginx连接就要设置一个超时时间，在用户容忍的时间内返回数据，或者再多等一会后端服务返回数据，具体策略根据具体业务进行具体分析后端的FastCGI服务及MySQL服务也有对连接的超时控制 12位置： http, server, locationkeepalive_timeout 60; 默认情况下当数据发送时，内核并不会马上发送，可能会等待更多的字节组成一个数据包，这样可以提高I/O性能。但是，在每次只发送很少字节的业务场景中，不使用tcp_nodelay功能，等待时间会比较长。 12位置： http, server, locationtcp_nodelay on; 读取客户端请求头数据的超时时间，如果超过这个时间，客户端还没有发送完整的header数据，服务器端将返回“Request time out（408）”错误。 12位置： http, serverclient_header_timeout 20; 读取客户端请求主体的超时时间，如果在这个超时时间内，客户端没有发送任何数据，Nginx将返回“Request time out（408）”错误。 12位置： http, server, locationclient_body_timeout 60; 指定响应客户端的超时时间，为握手后的一个超时。如果超过这个时间，客户端没有任何活动，Nginx将会关闭连接。 12位置： http, server, locationsend_timeout 60; 上传文件大小限制(动态应用)设置为0，表示禁止检查客户端请求主体的大小。 12位置： http, server, locationclient_max_body_size 20m; gzip压缩Nginx gzip压缩模块提供了压缩文件内容的功能，用户请求的内容在发送到用户客户端之前，Nginx服务器会根据一些具体的策略实施压缩，以节约网络出口带宽，同时加快数据传输效率，提升用户体验。 压缩对象： 纯文本内容压缩比很高，如 html, js, css, xml等 被压缩的纯文本文件必须要大于1KB，由于压缩算法的特殊原因，极小的文件压缩后可能反而变大 图片、媒体等文件尽量不要压缩，因为这些文件大都经过压缩，再压缩很可能不会减小很多，或有可能增大，同时还要消耗系统资源 配置： 1234567891011121314151617181920212223242526#压缩功能gzip on;#允许压缩的页面最小字节数gzip_min_length 1K;#申请4个单位为16K的内存作为压缩结果流缓存gzip_buffers 4 16K;#http协议版本gzip_http_version 1.1;#指定压缩比，1压缩比最小，处理速度最快；9压缩比最大，传输速度最快，处理最慢gzip_comp_level 5;#指定压缩类型，对应文件类型参考mime.typesgzip_types text/html text/css;#vary header支持gzip_vary on; 在response header中查看效果： Content-Encofing: gzip expires缓存Nginx expires的功能就是为用户访问的网站内容设定一个过期时间。 当用户第一次访问这些内容时，会把这些内容储存在用户浏览器本地，这样用户第二次及以后继续访问该网站时，浏览器会检查加载已经缓存在用户浏览器本地的内容，而不用去服务器下载，直到缓存的内容过期或被清除为止。 缓存也要根据业务！当网站数据更新时，用户端看到的可能还是旧的已经缓存的内容。 配置： 根据文件扩展名进行判断 12345678location ~ .*\.(gif|png|jpg|swf)$ &#123; expires 10d;&#125;location ~ .*\.(css|js)$ &#123; expires 20d;&#125; 根据目录进行判断 123location ~ ^/(images|static|media)/ &#123; expires 50d;&#125; 在response header中查看： Expires: 缓存过期时间Cache-Control： 缓存总时间 FastCGI相关参数FastCGI参数是配合Nginx向后请求PHP动态引擎服务的相关参数，这里指的是Nginx中的配置参数。 Module ngx_http_fastcgi_module： https://nginx.org/en/docs/http/ngx_http_fastcgi_module.html 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#给FastCGI服务器设置地址fastcgi_pass#设置一个将在 $fastcgi_scripts_name 变量结尾的URI之后添加的文件名fastcgi_index#设置一个应该传递给FastCGI服务器的参数，当且仅当fastcgi_param在当前级别上没有定义指令时，这些指令将从上一级继承fastcgi_param#指定在哪种情况下将请求传递给下一个服务器；fastcgi_next_upsteam#表示Nginx服务器和后端FastCGI服务器连接的超时时间，默认值为60秒，这个参数通常不要超过75秒fastcgi_connect_timeout#设置Nginx允许FastCGI服务器端返回数据的超时时间，即在规定时间之内后端服务器必须传完所有的数据。否则，Nginx将断开这个连接fastcgi_send_timeout#设置Nginx从FastCGI服务器端读取响应信息的超时时间，表示连接建立成功后，Nginx等待后端服务器的响应时间，是Nginx已经进入后端的排队之中等候处理的时间fastcgi_read_timeout#这是Nginx FastCGI的缓冲区大小参数，设定用来读取从FastCGI服务器端收到的第一部分响应信息的缓冲区大小，这里的第一部分通常会包含一个小的响应头部fastcgi_buffer_size#设定用来读取从FastCGI服务器端收到的响应信息的缓冲区大小和缓冲区数量fastcgi_buffers#用于设置系统很忙时可以使用的proxy_buffers大小，官方推荐大小为proxy_buffers * 2proxy_busy_buffers_size #用于设置系统很忙时可以使用的fastcgi_buffers大小，官方推荐为 fastcgi_buffers * 2fastcgi_busy_buffers_size#FastCGI临时文件大小fastcgi_temp_file_write_size#表示开启FastCGI缓存并为其指定一个名称fastcgi_cache cachename_nginx#fastcgi_cache缓存目录fastcgi_cache_path#用来指定应答代码的缓存时间fastcgi_cache_valid#设置请求几次之后响应将被缓存fastcgi_cache_min_uses#定义在哪些情况下使用过期缓存fastcgi_cache_use_stale#定义fastcgi_cache的keyfastcgi_cache_key 日志与安全现在Nginx 日志已经自动轮询了，所以感觉没有必要自己切割日志！ 不记录不需要的日志日志写入太频繁会消耗大量的磁盘I/O，降低服务性能。 123location ~ .*\.(js|png|css|gif|jpg) &#123; access_log off;&#125; 日志权限因为nginx master process的UID是root，所以可以修改日志权限。不需要在日志目录上给Nginx用户读或写许可，很多人没注意这个问题，把权限直接给了Nginx用户，这就存在安全隐患。 12chown -R root:root /path/log/nginxchmod -R 700 /path/log/nginx 站点目录及URL访问控制根据扩展名限制程序或文件访问利用Nginx配置禁止访问上传资源目录下的PHP、Shell、Perl、Python程序文件，这样用户即使上传了木马文件也没法执行，从而加强了网站的安全。 对这些的限制必须放在Nginx处理.php, .py, .sh等文件的前面！ 1234567891011121314151617#禁止解析指定目录下的程序location ~ ^/images/.*\.(php|py|sh|pl)$ &#123; deny all;&#125;location ~ ^/static/.*\.(py|php|pl|sh) &#123; deny all;&#125;#禁止访问某些文件location ~* \.(txt|doc)$ &#123; root /var/www/file; deny all;&#125; 禁止访问指定目录123456789101112131415location ~ ^/test/ &#123; deny all;&#125;#禁止访问多个目录location ~ ^/(test|zhang) &#123; deny all;&#125;#返回状态码location ~ ^/haha/ &#123; return 403 "Hahaha";&#125; 禁止非法域名解析访问网站防止用户恶意域名解析。 1234567891011121314151617181920cd /etc/nginx/conf.dvim default.conf#返回HTTP状态码server &#123; listen 80 default_server; server_name _; return 403;&#125;#重定向server &#123; listen 80 default_server; server_name _; rewrite ^(.*) https://www.baidu.com permanent;&#125; 利用default_server，将网站所有请求定向到维护页面。 1234567891011121314151617181920212223242526272829303132333435server &#123; listen 80 default_server; server_name _; root /var/www; location / &#123; rewrite ^(.*) /maintance.html break; &#125;&#125;cd /var/wwwvim maintance.html&lt;html&gt;&lt;head&gt;&lt;meta charset="UTF-8"&gt;&lt;style type="text/css"&gt; h1&#123;text-align: center; color: red;&#125;&lt;/style&gt;&lt;/head&gt;&lt;br&gt;&lt;br&gt;&lt;body&gt;&lt;h1&gt;网站维护中！&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 图片及目录防盗链 什么是资源盗链简单地说，就是某些不法网站未经许可，通过在其自身网站程序里非法调用其他网站的资源，然后在自己的网站上显示这些调用的资源，达到填充自身网站的效果。 这一举动不仅浪费了调用资源网站的网络流量，还造成其他网站的带宽及服务压力吃紧。 问题： 某公司CDN源站流量没有变化，但CDN加速那边流量超了很多。这么大异常流量，全都是钱呀！ 常见防盗链解决方案 根据HTTP referer 实现防盗链在HTTP 协议中，有一个表头字段叫 referer，使用URL格式来表示是哪里的链接用了当前网页的资源。 通过referer可以检测访问的来源网页，如果是资源文件，可以跟踪到显示它的网页地址，一旦检测出来不是本站，马上进行阻止。 HTTP referer 是header的一部分，当浏览器向web服务器发送请求时，一般会带上referer，告诉服务器我是从哪个页面过来的，服务器借此获得一些信息用于处理。 根据cookie防盗链通过加密技术变换访问路径实现防盗链 Nginx实现防盗链利用referer，针对指定扩展名进行rewrite或其他操作。 请根据实际情况进行域名防盗链！ 123456location ~* \.(jpg|png|gif|wav|mp3|zip|rar)$ &#123; valid_referers none blocked *.zhang.com; if ($invalid_regerer) &#123; rewrite https://www.baidu.com; &#125;&#125; 或者在产品设计上解决防盗链，如为资源加上水印等措施。 错误页面优雅展示我们可以将404、403等错误信息重定向到其他指定的页面，提升网站的用户访问体验！ 123456789101112location / &#123; xxxx; error_page 403 /403.html; error_page 404 /404.jpg; error_page 500 503 504 /50x.html; location = /50x.html &#123; root /var/www/50x.html; &#125;&#125; 目录及文件权限优化为了保证网站安全，所有站点的目录和用户组都为root，所有目录权限是755，所有文件权限是644。虽然这样的全线可以防止黑客上传修改站点的文件，但这样合法的用户便也没有了上传权限。 比较好的方法是将用户上传文件的服务器与读取服务器进行分离，这样就可以进行安全授权。不同的服务所在的目录的权限依据业务功能而不同。 严格控制Nginx目录的访问才能降低网站被入侵的风险！ 反爬虫优化 robots.txt机器人协议robots协议(维基百科)，也称为机器人协议，全称是网络爬虫排除标准（Robots Exclusion Protocol）。网站通过Robots协议告诉搜索引擎那些页面可以抓取，那些页面不能抓取。 robots.txt协议并不是一个规范，而只是约定俗成的，所以并不能保证网站的隐私。 123User-Agent: *Allow: /zhangDisallow: / Nginx反爬虫配置123456789if ($http_user_agent ~* LWP::Simple|BBBike|wget) &#123; return 403;&#125;if （$http_user_agent ~* (Firefox|MSIE) &#123;rewrite ^（.*） http://www.baidu.com:&#125; 限制HTTP请求方法123if ( $request_method !~ ^(GET|POST|HEAD)$ ) &#123; return 501;&#125; CDNCDN的全称是 Content Delivery Network，中文意思是内容分发网络。我们可以利用CDN做网站内容加速。 简单地讲，通过现有的Internet中增加一层新的网络架构，将网站的内容发布到最接近用户的Cache服务器内，通过智能DNS负载均衡技术，判断用户的来源，让用户就近使用与服务器相同线路的带宽访问Cache服务器，取得所需的内容。 例如，北京电信用户访问北京电信Cache服务器上的内容，四川网通用户访问成都网通Cache服务器上的内容。这样可以有效减少数据在网络上传输的时间，提高访问速度。CDN是一套全国或全球的风不是缓存集群，其实质是通过职能DNS判断用户的来源地域及上网线路，为用户选择一个最接近用户地域，以及和用户上网线路相同的服务器节点。因为低于近，线路相同，所以可以大幅度提升用户浏览网站的体验。 CDN的价值： 提升用户体验 阻挡大部分流量攻击 CDN的特点： 通过服务器内存缓存网站数据，提高了企业站点（尤其是含有大量图片、视频等的站点）的访问速度，并大大提高企业站点的稳定性； 用户根据智能DNS技术自动选择最适合的Cache服务器，降低不同运营商之间互联瓶颈造成的影响，实现了跨运营商的网络加速，保证不同网络中的用户都能得到良好的访问速度； 加快了访问速度，减少了原站点的带宽； 用户访问时从服务器的内存中读取数据，分担了网络流量，同时减轻了原站点负载压力； 使用CDN可以分担源站的网络流量，同时减轻源站的负载压力，并降低黑客入侵及各种DDOS攻击对网站的影响，保证网站有较好的服务质量； 使用CDN的要求首先要说的是，不是所有的网站都可以一上来就能用CDN的。要加速的业务数据应该存在独立的域名。如 pub.zhang21.com，业务内容图片、附件、JS、CSS等静态元素，这样的静态网站域名才能使用CDN。 将域名做CNAME(别名)将如上的pub.zhang21.com配置成CDN的域名。 程序架构优化解耦 是开发人员中流行的一个名词，简单地说就是把一堆程序代码按照业务用途分开，然后提供服务。 例如，注册登录、上传、下载、浏览、商品页信息等都应该是独立的程序服务，只不过在客户端看来是一个整体而已。 分离的最佳方式是分别使用独立的服务器，可以选择改动程序或者在负载均衡器上配置（如Nginx），过滤请求，然后抛给后面对应的服务器。 根据扩展名分发，请求图片就抛给图片服务器； 根据URL路径转发，请求下载就交给下载服务器； 请求动态PHP处理的就交给动态处理器； 不符合以上要求的就交给默认服务器； 使用no-root用户启动Nginx默认情况下，Nginx的Master进程使用的是root用户，worker进程使用的是Nginx指定的普通用户。 使用root用户跑Nginx的Master进程有两个最大问题： 管理权限必须是root，这就使得最小化分配权限原则遇到困难 使用root跑Nginx服务，一旦网站出现漏洞，用户就可以很容易地获取服务器的root权限 控制Nginx并发连接数ngx_http_limit_conn_module这个模块用于限制每个定义的Key值的连接数，特别是单IP的连接数。 不是所有的连接数都会被计数，一个符合要求的连接是整个请求头已经被读取的连接。 用法： 1234567#位置： httplimit_conn_zone key zone=name:size;#位置： http, server, locationlimit_conn zone number; 栗子： 123456789101112http &#123; limit_conn_zone $binary_remote_addr zone=addr:10m; xxx;&#125;server &#123; xxx; location /download/ &#123; limit_conn addr 3; #限制单IP并发连接为3 &#125;&#125; 控制客户端请求Nginx的速率ngx_http_limit_req_module被用来限制每个IP访问没法key的请求速率。 用法： 1234567#位置： httplimit_req_zone key zone=name:size rate=rate;#位置： http, server, locationlimit_req zone=name; 栗子： 123456789http &#123;limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; server &#123; location /search/ &#123; limit_req zone=one burst=5; &#125; &#125;&#125; upstream模块 反向代理与负载均衡严格地说，Nginx仅仅是作为Nginx Proxy反向代理使用的，因为这个反向代理功能表现的效果是负载均衡集群的效果，所以本文称之为Nginx负载均衡。 普通的负载均衡软件，如LVS，其实现的功能只是对请求数据包的转发、传递，从负载均衡下的节点服务器来看，接收到的请求还是来自访问负载均衡器的客户端的真实用户 反向代理服务器在接收访问用户请求后，会代理用户 重新发起请求代理下的节点服务器，最后把数据返回给客户端用户。在节点服务器看来，访问的节点服务器的客户端用户就是反向代理服务器，而非真实的网站访问用户 即，LVS等负载均衡是转发用户请求的数据包，而Nginx反向代理是接收用户请求后重新发起请求后端节点 这里我去看了一下Nginx的access.log，客户端的访问日志全在代理节点上（Nginx-upstream），而后端节点的access.log的来源是前端代理节点的IP Nginx负载均衡的组件实现Nginx负载均衡的组件主要有两个: proyx upstream Nginx_http模块 模块说明 ngx_http_proxy_module proxy代理模块，用于把请求后抛给服务器节点或upstream服务器池 ngx_http_upstream_module 负载均衡模块，可以实现网站的负载均衡功能即节点的健康检查 nginx upstream模块 upstream模块介绍Module ngx_http_upstream_module: https://nginx.org/en/docs/http/ngx_http_upstream_module.html upstream主要是用于七层上的负载均衡和转发。 123Syntax： upstream name &#123; ... &#125;Default: —Context: http Nginx的负载均衡功能依赖于ngx_http_upstream_module模。所支持的代理方式包括： proxy_pass fastcgi_pass memcached_pass uwsgi_pass scgi_pass upstream模块允许Nginx定义一组或多组节点服务器组，使用时可通过proxy_pass代理方式把网站的请求发送到事先定义好的对应upstream组的名字上。 upstream模块内容放置于http{}内: 12345678910111213141516171819202122232425262728293031323334upstream upstream_name &#123; server address [ parameters ]&#125;####栗子http &#123; upstream zhang &#123; server 192.168.1.22:8080 weight=5; server www.zhang.cn weigh=5 max_conns=102400; server 192.168.33 max_fails=2 fail_timeout=20s; server backup.zhang.cn backup; &#125;&#125;server &#123; location / &#123; proxy_pass http://zhang; &#125;&#125;####reslovehttp &#123; resolver 10.0.0.1; upstream u &#123; zone ...; ... server example.com resolve; &#125;&#125; address可以是主机名、域名、ip或Unix Socket，也可以指定端口号 域名时需要解析的哦 parameters代表可选参数, 有如下： backup，表示当前server是备用服务器，只有其它非backup后端服务器都挂掉了或很忙才会分配请求给它 max_conns，限制同时连接到代理服务器的最大数量。默认值为0，表示没有限制。 weight，表示当前server负载权重，权重越大几率愈高 max_fails和fail_timeout一般会关联使用，如果某台server在fail_timeout时间内出现了max_fails次连接失败，那么Nginx会认为其已经挂掉，从而在 fail_timeout 时间内不再去请求它，fail_timeout默认是 10s，max_fails默认是1，即默认情况只要是发生错误就认为服务器挂了，如果将max_fails设置为0，则表示取消这项检查 down，标志服务器永远不可用，可配合ip_hash使用 resolve，监视与服务器域名相对应的ip地址的变化，并自动地修改上游配置，而不用重启Nginx route，设置服务器路由名称 service slow_start，设置服务器将其weight从零恢复到正常值的时间 drain，使服务器进入drain模式，在此模式下，只有绑定到服务器的请求才会被代理 upstream模块参数 说明 weight 服务器权重 max_fails Nginx尝试连接后端主机失败的次数，这个值是配合proxy_next_upstream、fastcgi_next_upstream和memcached_next_upstream这三个参数来使用的。当Nginx接收后端服务器返回这三个参数定义的状态码时，会将这个请求转发给正常工作的的后端服务器。如404、503、503、max_files=1 fail_timeout max_fails和fail_timeout一般会关联使用，如果某台server在fail_timeout时间内出现了max_fails次连接失败，那么Nginx会认为其已经挂掉，从而在fail_timeout时间内不再去请求它，fail_timeout默认是10s，max_fails默认是1，即默认情况只要是发生错误就认为服务器挂了，如果将max_fails设置为0，则表示取消这项检查 backup 表示当前server是备用服务器，只有其它非backup后端服务器都挂掉了或很忙才会分配请求给它 down 标志服务器永远不可用，可配合ip_hash使用 如果是两台Web服务器做高可用，可能就需要Keepalived配合。那使用backup参数通过负载均衡功能就可以实现Web服务器集群了。 upstream模块调度算法调度算法一般分为： 静态调度算法: 即负载均衡器根据自身设置的规则进行分配，不需要考虑后端节点服务器的情况 轮询 权重 ip_hash 动态调度算法: 即负载均衡器会根据后端节点的当前状态来决定是否分发请求，如连接数少或响应时间短的优先获得请求 fair least_conn url_hash 一致性hash 轮询(rr)默认调度算法。按照客户端请求顺序把请求逐一分配到不同的后端节点服务器，相当于LVS中的rr算法。如果后端服务器宕机，宕机的服务器会被自动从节点服务器池中剔除，以使客户端的用户访问不受影响，新的请求分配给正常的服务器。 权重轮询(wrr)权重越大，被转发的请求也就越多。可以根据服务器的配置和性能指定权重大小，有效解决新旧服务器性能不均带来的请求分配问题。 1234upstream weight &#123; server 191.168.1.11 weight=1; server 192.168.1.22 weight=2;&#125; ip_hash每个请求按客户端IP的hash结果分配，当新的请求到达时，先将其客户端ip通过哈希算法得出一个值，在随后的客户端请求中，客户IP的哈希值只要相同，就会被分配到同一台服务器。 该调度算法可以解决动态网页的session共享问题，但有时会导致请求分配不均，因为国内大多数都是NAT上网模式，多个客户端对应一个外部IP，所以这些客户端都会被分配到同一个节点服务器，从而导致请求分配不均。 ip_hash中，后端服务器在负载均衡调度中的状态不能有 weight和backup，有也不会生效 12345upstream iphash &#123; ip_hash; server 192.168.1.11; server 192.168.1.22:8080;&#125; fair根据后端节点服务器的响应时间来分配请求，响应时间短的优先分配。这是更加智能的调度算法。 Nginx本身不支持这种算法，需要upstream_fair模块: https://github.com/gnosek/nginx-upstream-fair 12345upstream fair &#123; server 192.168.1.11; server 192.168.1.22; fair;&#125; least_conn根据后端节点的连接数来决定分配情况，哪个机器少就分发给它。 url_hash根据访问URL的hash结果来分配请求的，让每个URL定向到同一个后端服务器，后端服务器为缓存服务器时效果显著。 Nginx本身不支持url_hash，需要hash。 1234567upstream urlhash &#123; server hahaha1:5678; server hahaha2:5678; hash $request_uri; hash_method md5; #同样不能使用 weight、backup&#125; 一致性hash一致性hash算法一般用于代理后端业务为缓存服务器（如Memcached）的场景，通过将用户请求的URI或者指定字符串进行计算，然后调度到后端的服务器上，此后任何用户查找同一个URI货值指定字符串都会被调度到这一台服务器上，因此后端的每个节点缓存的内容都是不同的。 12345upstream &#123; consistent_hash $request_uri; server xxx; server xxx;&#125; nginx proxy模块 proxy_pass介绍123Syntax: proxy_pass URL;Default: —Context: location, if in location, limit_except proxy_pass指令属于ngx_http_proxy_module模块，此模块可以将请求转发到另一台服务器，在实际的反向代理工作中，会通过location功能匹配指定的URI，然后把接收到服务匹配URI的请求通过proyx_pass抛给定义好的upstream节点池。 12345678910location /download/ &#123; proxy_pass http://download/vedio/;&#125;#这是前端代理节点的设置#交给后端upstream为download的节点location /name/ &#123; rewrite /name/([^/]+) /users?name=$1 break; proyx_pass http://127.0.0.1;&#125; http_proyx模块参数ngx_http_proxy_module: https://nginx.org/en/docs/http/ngx_http_proxy_module.html Nginx的代理功能是通过http_proxy模块来实现的。 proxy模块 说明 proxy_next_upstream 什么情况下将请求传递到下一个upstream proxy_limite_rate 限制从后端服务器读取响应的速率 proyx_set_header 设置http请求header传给后端服务器节点，如：可实现让代理后端的服务器节点获取访问客户端的这是ip client_body_buffer_size 客户端请求主体缓冲区大小 proxy_connect_timeout 代理与后端节点服务器连接的超时时间 proxy_send_timeout 后端节点数据回传的超时时间 proxy_read_timeout 设置Nginx从代理的后端服务器获取信息的时间，表示连接成功建立后，Nginx等待后端服务器的响应时间 proxy_buffer_size 设置缓冲区大小 proxy_buffers 设置缓冲区的数量和大小 proyx_busy_buffers_size 用于设置系统很忙时可以使用的proxy_buffers大小，推荐为proxy_buffers*2 proxy_temp_file_write_size 指定proxy缓存临时文件的大小 Nginx负载均衡配置 配置后端节点12345678910vi /etc/nginx/nginx.confserver &#123; listen 80; root /path/xxx; location / &#123; xxxx; &#125;&#125; 配置反向代理节点12345upstream test &#123; server test1 weight=5; server test2 weight=5; server 192.168.1.33;&#125; 1234567891011121314151617181920vi /etc/nginx/nginx.confserver &#123; listen 8888; server_name www.test.com www.xx.com; location / &#123; proxy_read_timeout 10s; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_404; proyx_pass http://test;#把用户的请求反向代理定义的upstream服务器池 #proyx_set_header Host $host;在代理后端服务器发送的http请求头中加入host字段信息 #proxy_set_header X-Real-IP $remote_addr;后端节点服务器日志获取客户端真实ip，否则全都是代理节点的ip #proyx_connect_timeout 30s; #proxy_buffers 4m; #xxx&#125; xxxxx&#125; 与反向代理配置相关的参数除了具有多虚拟主机代理以及节点服务器记录真实用户ip的功能外，Nginx还提供了相当多的作为反向代理和后端节点服务器对话的相关控制参数。 由于参数众多，建议把这些参数都写到另外一个配置文件里，然后用 include 方式包含到虚拟主机配置文件里。其他Nginx参数也同样可以使用此方法。 12345678910111213vim /etc/nginx/proxy.confproxy_set_header Host $host;proxy_set_header $remote_addr;proxy_connect_timeout 60s;proxy_read_timeout 20s;proxy_send_timeout 20s;proxy_buffer_size 64k;proxy_buffers 4 64k;proxy_busy_buffers_size 128k;proxy_temp_file_write_size 2m;proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_404 12345678910vim /etc/nginx/conf.d/test.confserver &#123; listen 80; server_name www.test.com www.xxx.com; location / &#123; include /etc/nginx/proxy.conf; &#125;&#125; proxy_next_upstream参数补充当Nginx接收后端服务器发返回的proxy_next_upstream参数定义的状态码时，会将这个请求转发给正常工作的后端服务器，如500、502、503，此参数可以提升用户访问体验。 1proyx_next_upstream error timeout invalid_header http_500 http_503 http_502 http_504; 根据URL中的目录地址实现代理转发通过Nginx实现动静分离，即通过Nginx反向代理配置规则实现让动态资源和静态资源及其他业务分别由不同的服务器解析，已解决网站性能、安全、用户体验等重要问题。 动静态分离配置upstream.conf 123456789101112131415161718upstream static &#123; server 192.168.1.11; #或server static.com----hosts:static.com 192.168.1.11&#125;upstream upload &#123; server 192.168.1.22;&#125;upstream default &#123; server 192.168.1.33;&#125;#在http中加入,注意位置http &#123; include upstream.conf;&#125; 配置virtual.conf 12345678910111213141516171819202122232425262728293031323334353637#方案1：利用location实现location /static/ &#123; proyx_pass http://static; include proyx.conf;&#125;location /upload/ &#123; proxy_pass http://upload; include proxy.conf;&#125;location / &#123; proxy_pass http://default; include proxy.conf;&#125;========================================#方案2：利用if语句实现if ($request_uri ~* "^/static/(.*)$")&#123; proxy_pass http://static/$1;&#125;if ($request_uri ~* "^/upload/(.*)$")&#123; proxy_pass http://upload/$1;&#125;location / &#123; proxy_pass http://default; include proyx.conf;&#125; URL目录地址转发的应用场景根据HTTP的URL进行转发的应用情况，被称为 第7层（应用层）的负载均衡；而LVS的负载均衡一般用于TCP等的转发，因此被称为第四层（传输层）的负载均衡 。 有时因为需求，需要在代理服务器上通过配置规则，使得匹配不同规则的请求会交给不同的服务器池处理。 根据客户端的设备(user_agent)转发为了让不同客户端设备用户有更好的访问体验，需要在后端架设不同服务器来满足不同的客户端访问。如PC端和移动端，移动端又有安卓、苹果、Pad等。 常规4层负载均衡解决方案架构 在常规4层负载均衡架构下，可以使用不同的域名来实现这个需求。 如，分配移动端访问 wap.xxx.com，PC端访问www.xxx.com。 通过不同域名来引导用户到指定后端服务器，但是这样就分别得记住不同的域名。 第7层负载均衡解决方案 在7层负载均衡架构下，对外只需要用一个域名，如www.xxx.com，然后通过获取用户请求中的设备信息$http_user_agent，根据此信息转给后端合适的服务器处理。 根据$user_agent转发 123456789101112location / &#123; if ($http_user_agent ~* "android") &#123; proxy_pass http://android; &#125;if ($http_user_agent ~* "iphone") &#123; proxy_pass http://iphone; &#125;proxy_pass http://default;include proyx.conf; 根据文件扩展名实现代理转发 1234567891011121314location ~* .*\.(gif|jpg|png|css|js)$ &#123; proyx_pass http://static; include proxy.conf;&#125;#ifif ($request_uri ~* ".*\.php$") &#123; proxy_pass http://php; &#125;if ($request_uri ~* ".*\.(jpg|png|css|js)$") &#123; proxy_pass http://static; &#125; 在开发无法通过程序实现动静分离的时候，运维可以根据资源实体进行动静分离，根据不同实现策略制定后端服务器不同的组。在前端代理服务器上通过路径、扩展名等进行规则匹配，从而实现请求的动态分离。 Nginx负载均衡检测节点状态淘宝技术团队开发了一个Tengine（Nginx分支）模块nginx_upstream_check_module: https://github.com/yaoweibin/nginx_upstream_check_module，用于提供主动式后端服务器健康检查。通过它检测后端realserver的健康状态，如果后端节点不可用，则所有的请求就不会转发到该节点上。 Nginx需要通过打补丁的方式将该模块添加进去。 123456789101112131415161718192021222324252627282930wget https://codeload.github.com/yaoweibin/nginx_upstream_check_module/zip/masterunzip mastercd nginx_upstream_check_module-master #解压后的文件夹cd nginx源码安装包（我是 /usr/local/nginx-1.12.1）patch -p1 &lt; ../nginx_upstream_check_module-master/check_1.12.1+.patch #选择对应的Nginx版本号，我的是1.12.1 #打补丁#编译，注意以前的编译参数./configure --prefix=/usr/local/nginx \--user=nginx --group=nginx \--with-http_ssl_module \--with-http_realip_module \--with-http_addition_module \--with-http_gzip_static_module \--with-http_stub_status_module \--with-http_sub_module \--with-pcre \--add-module=../nginx_upstream_check_module-mastermake#给已经安装的Nginx系统打补丁不用执行make install#make是重新生成Nginx二进制启动命令#备份mv /usr/local/nginx/sbin/nginx&#123;,.bak&#125;#经打过补丁的Nginx二进制程序复制到/usr/local/nginx/sbin/ 下cp /usr/local/nginx-1.12.1/objs/nginx /usr/local/nginx/sbin/nginx -t 配置nginx_upstream_check 配置upstream.conf 12345678upstream zhang &#123; server 192.168.1.7:5678 weight=1; server 192.168.0.99:5678 weight=1; check interval=3000 rise=2 fall=5 timeout=1000 type=http; #每个3秒对负载均衡中所有节点检测一次，请求2次正常标记realserver状态为up； #如果检测5次都失败，则标记realserver状态为down，超时时间为1秒； #检查的协议为HTTP；&#125; 配置/status： 123456location /status &#123; check_status; access_log off; allow 192.168.1.0/24; deny all;&#125; stream模块Module ngx_stream_core_module: http://nginx.org/en/docs/stream/ngx_stream_core_module.html nginx从1.9.0开始，新增加了一个stream模块，用来实现四层协议(tcp/udp)的转发、代理和负载均衡。这个模块不是默认构建的，需要使用--with-stream参数。 1yum install -y nginx-mod-stream 这个实现四层反向代理和转发的功能真的是很强大，只需一台反向代理服务器，转发给所有后端机器。 栗子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495vim /etc/nginx/nginx.confstream&#123; include /etc/nginx/stream.d/*.conf&#125;##########################cd /etc/nginx/stream.d#转发Elasticsearchvim elastic.confupstream elastic-cluster &#123; server ip1:9200; server ip2:9200; xxx;&#125;server &#123; listen 9200; proxy_pass elastic-cluster;&#125;#dnsvim dns.confupsetrem dns-cluster &#123; server ip:5353; server dns.example.com:53; xxx&#125;#tcpserver &#123; listen port; proxy_pass dns-cluster;&#125;#udpserver &#123; listen 53 udp; proxy_pass dns-cluster;&#125;#ipv6server &#123; listen [::1]:53; proxy_pass unix:/xxx/xx.socket&#125;#MySQLvim mysql.confupstream mysql-cluster &#123; server ip:3306; server ip2:3306; xxx;&#125;server &#123; listen 3306; proxy_pass mysql-cluster;&#125;#SSH转发upstream ssh &#123; server ip:22;&#125;server &#123; listen port; proxy_pass ssh;&#125; 错误信息Nginx错误日志的详细说明。 错误信息 描述 (13: Permission denied) while reading upstream xxx (98: Address already in use) while connecting to upstream xxx (99: Cannot assign requested address) while connecting to upstream xxx (104: Connection reset by peer) while reading response header from upstream upstream-fastcgi超时时间request_terminate_timeout过小 (104: Connection reset by peer) 1: 服务器的并发连接数超过其承载量，服务器会将其中一些连接Down掉; 2: 客户关掉了浏览器，而服务器还在给客户端发送数据; 3: 浏览器端按了Stop (104: Connection reset by peer) while connecting to upstream upstream发送了RST，将连接重置 send() failed (111: Connection refused) xxx (111: Connection refued) while connecting to upstream 用户在连接时，若遇到后端upstream挂掉或不通，会收到该错误 (111: Connection refused) while reading response header from upstream 用户在连接成功后读取数据时，若遇到后端upstream挂掉或者不通，会收到此错误 (111: Connection refused) while sending request to upstream Nginx和upstream连接成功后发送数据时，若遇到后端upstream挂掉或不通，会收到该错误 (110: Connection timed out) while connecting to upstream Nginx连接upstream时超时 (110: Connection rimed out) while reading upstream Nginx读取来自upstream的响应时超时 (110: Connection timed out) while reading response header from upstream Nginx读取来自upstream的响应头时超时 (110: Connection timed out) while reading upstream Nginx读取来自upstream的响应时超时 upstream prematurely closed connection 请求URI的时候出现异常，是由于upstream还未返回应答给用户时，用户断掉连接造成。对系统没有影响。 upstream sent invalid header while reading response header from upstream upstream发送的响应头无效 upstream sent no valid HTTP/1.0 header while reading response header from upstream upstream发送的响应头无效 client intended to send too large body 用于设置允许接受的客户端请求内容的最大值，Client发送的body超过了设置 reopening logs 用户发送kill -USR1命令 gracefully shutting down 用户发送kill -WINCH命令 no servers are inside upstream upstream下未配置server no live upstreams while connecting to upstream upstream下的server全都挂了 SSL_do_handshake() failed SSL握手失败 SSL_write() failed(SSL) while sending to client xxx ngx_slab_alloc() failed: no memory in SSL session shared cache ssl_session_cache大小不够 could not add new SSL session to the session cache while SSL hanshaking ssl_session_cache大小不够]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[I Like For You To Be Still]]></title>
    <url>%2F2017%2F09%2F01%2FI-Like-For-You-To-Be-Still%2F</url>
    <content type="text"><![CDATA[《I Like For You To Be Still》 出自聂努达诗集：《二十首情诗和一首绝望的歌》。 I like for you to be stillIt is as though you are absentAnd you hear me from far awayAnd my voice does not touch youIt seems as though your eyes had flown awayAnd it seems that a kiss had sealed your mouthAs all things are filled with my soulYou emerge from the thingsFilled with my soulYou are like my soulA butterfly of dreamAnd you are like the word: Melancholy I like for you to be stillAnd you seem far awayIt sounds as though you are lamentingA butterfly cooing like a doveAnd you hear me from far awayAnd my voice does not reach youLet me come to be still in your silenceAnd let me talk to you with your silenceThat is bright as a lampSimple, as a ringYou are like the nightWith its stillness and constellationsYour silence is that of a starAs remote and candid I like for you to be stillIt is as though you are absentDistant and full of sorrowSo you would’ve diedOne word then, One smile is enoughAnd I’m happy;Happy that it’s not true]]></content>
      <categories>
        <category>Literature</category>
      </categories>
      <tags>
        <tag>Pablo Neruda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Test-My-Site]]></title>
    <url>%2F2017%2F08%2F30%2FTest-My-Site%2F</url>
    <content type="text"><![CDATA[[ ] Monday [ ] Tuesday [ ] Wednesday [ ] Thursday [ ] Friday [ ] Saturday [ ] Sunday \sideset{^1_2}{^3_4}A $E=mc^2$ \sum_{i=1}^n a_i=0 f(x_1,x_x,\ldots,x_n) = x_1^2 + x_2^2 + \cdots + x_n^2 \sum^{j-1}_{k=0}{\widehat{\gamma}_{kj} z_k}]]></content>
      <categories>
        <category>Test</category>
      </categories>
      <tags>
        <tag>Test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F08%2F30%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
