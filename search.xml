<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Helm]]></title>
    <url>%2F2020%2F09%2F21%2FHelm%2F</url>
    <content type="text"><![CDATA[参考： docs: https://docs.helm.sh/ github: https://github.com/helm 环境： el7x86_64 helm v3.3 概述Helm是Kubernetes生态系统中的一个软件包管理工具，主要用来管理Charts，有点类似于Ubuntu中的apt或CentOS中的yum。由go编写，是Deis公司发起的一个开源工具，有助于简化部署和管理Kubernetes应用。 在Kubernetes中，应用管理是需求最多、挑战最大的领域。Helm项目提供了一个统一软件打包方式，支持版本控制，可以大大简化Kubernetes应用分发与部署中的复杂性。 Helm Chart是用来封装 Kubernetes原生应用程序的一系列YAML文件。可以在你部署应用的时候自定义应用程序的一些 Metadata，以便于应用程序的分发。 对于应用发布者而言，可以通过 Helm 打包应用、管理应用依赖关系、管理应用版本并发布应用到软件仓库。 对于使用者而言，使用 Helm 后不用需要编写复杂的应用部署文件，可以以简单的方式在 Kubernetes 上查找、安装、升级、回滚、卸载应用程序。 The package manager for Kubernetes. Helm is the best way to find, share, and use software built for Kubernetes. 术语Glossary: https://helm.sh/docs/glossary/ Chart Helm包涵盖了将k8s资源安装到k8s集群所需的足够多的信息。Charts包含了Chart.yaml文件核模板，默认值(values.yaml)，以及相关依赖。Charts开发设计了良好定义的目录结构，并打包为chart archive。 Chart Archive Chart包是被tar和gzip压缩（可选签名）的chart。 Chart Dependency(Subcharts) Chart可以依赖于其它chart。依赖有两种方式： 软依赖(soft): 如果另一个chart没有在集群中安装，chart可能会无法使用 硬依赖(hard): chart包含它所依赖的chart。（在charts/目录中） 当一个chart打包(helm package)时，所有的依赖都会和它绑定。 Chart Version 每个chart都需要版本号。 Chart.yaml chart的信息说明被存储在一个特定文件(Chart.yaml)。每个chart都必须有这个文件。 helm Helm是k8s包管理器。作为一个操作系统包管理器，使其很容易在操作系统中安装工具。Helm使得k8s集群中安装应用和资源变得异常简单。 Helm Configuration Files Helm将配置文件存储在XDG目录中。helm第一次运行，会自动生成。 Kube Config(KUBECONFIG) helm客户端通过Kube config配置文件来理解k8s集群。默认$HOME/.kube/config。 Lint Helm代码规范，规范一个chart是去验证其遵照Helm chart的标准规范和要求。Helm提供了helm lint命令。 Provenance Helm chart可以由来源文件(provenance file)提供chart的出处以及它所包含的内容。 来源文件(.prov)是Helm安全的一部分。一个来源包含chart包文件的加密哈希值，Chart.yaml数据，一个签名块。当再加上一个钥匙链(keychain)时，可为chart用户提供以下能力： 验证chart被可信第三方签名 验证chart文件没有被篡改 验证chart的元数据内容(Chart.yaml) 快速匹配chart的数据来源 Release 发行版本。chart安装之后，Helm库会创建一个release来跟踪这个安装。 单个chart可以在同一个集群中安装多次，并能创建多个不同的版本。 Release Number/Version 单个版本号可以被升级多次。通过连续技术来跟踪升级发布版本。 Rollback 每一次发布会更新chart或者配置。当生成发布历史后，一次发布也可以被 rolled back 之前的发布版本号。回滚使用helm rollback命令。 重要的是, 每一次回滚版本会生成一个新的发布版本号。 12345操作 版本号install release 1upgrade release 2upgrade release 3rollback 1 release 4 (但使用release 1的配置) Helm Library(SDK) Helm库（或SDK）涉及到go代码，可以直接与k8s API服务交互进行安装、升级、查询 以及移除k8s资源。 Repository Helm chart可以被存储到专用的HTTP服务器上，称之为chart仓库。 Helm客户端可以指向零个或多个chart仓库。默认没有配置仓库，可使用helm repo add添加。 Values Values 提供了一种使用您自己的信息覆盖模板默认值的方式。 Helm Chart是参数化的, 这意味着chart开发者可以在安装时显式配置。比如说，chart可以暴露username字段， 允许为服务设置一个用户名。这些可暴露的变量在Helm用语中称为values。 Values可在helm install, helm upgrage时设置。也可以在values.yaml文件中设置。 介绍Introduction: https://helm.sh/docs/intro/ 快速入门Quickstart: https://helm.sh/docs/intro/quickstart/ 如何快速安装核使用Helm。 先决条件Prerequisites 使用Helm的前置条件： k8s集群 建议最新k8s稳定版 kubectl 安装的安全配置(如果有的话) 安装和配置Helm 注意Helm版本对应支持的k8s版本。 安装Install: https://helm.sh/docs/intro/install/ 从源码、或二进制安装Helm CLI。 从Helm项目From The Helm Project 从二进制包: 下载特定版本包: https://github.com/helm/helm/releases 解压 添加到PATH 12345wget https://get.helm.sh/helm-v3.3.3-linux-amd64.tar.gztar -zxvf helm-v3.3.3-linux-amd64.tar.gzmv helm /usr/local/bin/helm 从脚本: 123curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3chmod 700 get_helm.sh./get_helm.sh 从源码123git clone https://github.com/helm/helm.gitcd helmmake 初始化Helm chartInitialize a Helm Chart Repository Helm安装好之后，你可以添加一个chart仓库。 1234567891011# 添加Helm官方仓库helm repo add stable https://kubernetes-charts.storage.googleapis.com/# 查看安装的charts列表helm search repo stableNAME CHART VERSION APP VERSION DESCRIPTIONstable/acs-engine-autoscaler 2.2.2 2.1.1 DEPRECATED Scales worker nodes within agent poolsstable/aerospike 0.2.8 v4.5.0.5 A Helm chart for Aerospike in Kubernetesstable/airflow 4.1.0 1.10.4 Airflow is a platform to programmatically autho...stable/ambassador 4.1.0 0.81.0 A Helm chart for Datawire Ambassador 安装ChartInstall an Example Chart 可以通过helm install命令安装chart。 12345678910111213141516171819202122232425262728293031323334353637383940414243helm repo update# helm install，都会创建一个新的release# 所以一个chart在同一个集群里面可以被安装多次，每一个都可以被独立的管理和升级helm install stable/mysql --generate-nameNAME: mysql-1600679719LAST DEPLOYED: Mon Sep 21 17:15:23 2020NAMESPACE: defaultSTATUS: deployedREVISION: 1NOTES:MySQL can be accessed via port 3306 on the following DNS name from within your cluster:mysql-1600679719.default.svc.cluster.localTo get your root password run: MYSQL_ROOT_PASSWORD=$(kubectl get secret --namespace default mysql-1600679719 -o jsonpath="&#123;.data.mysql-root-password&#125;" | base64 --decode; echo)To connect to your database:1. Run an Ubuntu pod that you can use as a client: kubectl run -i --tty ubuntu --image=ubuntu:16.04 --restart=Never -- bash -il2. Install the mysql client: $ apt-get update &amp;&amp; apt-get install mysql-client -y3. Connect using the mysql cli, then provide your password: $ mysql -h mysql-1600679719 -pTo connect to your database directly from outside the K8s cluster: MYSQL_HOST=127.0.0.1 MYSQL_PORT=3306 # Execute the following command to route the connection: kubectl port-forward svc/mysql-1600679719 3306 mysql -h $&#123;MYSQL_HOST&#125; -P$&#123;MYSQL_PORT&#125; -u root -p$&#123;MYSQL_ROOT_PASSWORD&#125;#查看此chart的基本信息helm show chart stable/mysqlhelm show all stable/mysql Releases12345678# 查看chart发行版helm lsNAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSIONmysql-1600679719 default 1 2020-09-21 17:15:23.169811348 +0800 CST deployed mysql-1.6.7 5.7.30# 列出所有部署的发行helm list 卸载Release使用helm uninstall命令卸载realease。 12helm uninstall mysql-1600679719release "mysql-1600679719" uninstalled 它会删除和该release相关的所有资源。使用--keep-history选项，Helm将保存release history。所以你可以审计集群历史甚至使用helm rollback回滚release。 主题Topic Guides: https://helm.sh/docs/topics/ ChartsCharts: https://helm.sh/docs/topics/charts/ Helm使用的包格式称为charts。chart就是一个描述k8s相关资源的文件集合。单个chart可以用来部署简单或复杂的服务。 Chart是作为特定目录布局的文件被创建，它们可以打包到要部署的版本存档中。 12# 下载一个chart，但不安装helm pull xxx 文件结构chart是一个组织在文件目录中的集合。目录名称就是chart名称(没有版本信息)。 示例: 12345678910wordpress/ Chart.yaml # 包含了chart信息的YAML文件 LICENSE # 可选: 包含chart许可证的纯文本文件 README.md # 可选: 可读的README文件 values.yaml # chart 默认的配置值 values.schema.json # 可选: 一个使用JSON结构的values.yaml文件 charts/ # 包含chart依赖的其他chart crds/ # 自定义资源的定义 templates/ # 模板目录， 当和values 结合时，可生成有效的Kubernetes manifest文件 templates/NOTES.txt # 可选: 包含简要使用说明的纯文本文件 Chart.yamlChart.yaml文件是chart必须的。包含以下字段。 12345678910111213141516171819202122232425262728293031apiVersion: chart API 版本 （必需）name: chart名称 （必需）version: 语义化2 版本（必需）kubeVersion: 兼容Kubernetes版本的语义化版本（可选）description: 一句话对这个项目的描述（可选）type: chart类型 （可选）keywords: - 关于项目的一组关键字（可选）home: 项目home页面的URL （可选）sources: - 项目源码的URL列表（可选）dependencies: # chart 必要条件列表 （可选） - name: chart名称 (nginx) version: chart版本 ("1.2.3") repository: 仓库URL ("https://example.com/charts") 或别名 ("@repo-name") condition: （可选） 解析为布尔值的yaml路径，用于启用、禁用chart (e.g. subchart1.enabled ) tags: # （可选） - 用于一次启用/禁用 一组chart的tag enabled: （可选） 决定是否加载chart的布尔值 import-values: # （可选） - ImportValue 保存源值到导入父键的映射。每项可以是字符串或者一对子/父列表项 alias: （可选） chart中使用的别名。当你要多次添加相同的chart时会很有用maintainers: # （可选） - name: 维护者名字 （每个维护者都需要） email: 维护者邮箱 （每个维护者可选） url: 维护者URL （每个维护者可选）icon: 用做icon的SVG或PNG图片URL （可选）appVersion: 包含的应用版本（可选）。不需要是语义化的deprecated: 不被推荐的chart （可选，布尔值）annotations: example: 按名称输入的批注列表 （可选）. Chart和版本控制 每个chart都必须有版本号。版本必须遵循SemVer2标准。 123# nginx chart的版本字段version: 1.2.3# 按照名称设置为nginx-1.2.3.tgz Chart.yaml文件中的version字段被很多Helm工具使用。当生成一个包时，helm package命令可以用Chart.yaml文件中找到的版本号作为包名的token。系统假设chart包名中的版本号可以与Chart.yaml文件中的版本号匹配。如果不满足这一假设会导致错误。 apiVersion字段 对于至少需要Helm3的chart，apiVersion字段应该是v2。 kubeVersion字段 可选的kubeVersion字段可以在支持的k8s版本上定义语义约束，Helm 在安装chart时会验证这个版本约束， 并在集群运行不支持的k8s版本时显示失败。 版本约束可以包含空格、比较操作符、逻辑操作符。 12345&gt;= 1.13.0 &lt; 1.15.0&gt;= 1.13.0 &lt; 1.14.0 || &gt;= 1.14.1 &lt; 1.15.01.1 - 2.3.4 deprecated字段 在Chart仓库管理chart时，有时需要废弃一个chart。deprecated字段可用来标记已弃用的chart。如果latest版本被标记为已弃用，则所有的chart都会被认为是已弃用的。以后可以通过发布未标记为已弃用的新版本来重新使用chart名称。 kubernetes/charts项目遵循的弃用charts的流程为： 升级chart的Chart.yaml文件，将这个文件标记为已弃用，并更改版本 在chart仓库中发布新版的chart 从源仓库中移除这个chart type字段 type字段定义了chart的类型。有两种类型： application：默认类型，是可以完全操作的标准chart。 library：不能安装，提供针对chart构建的实用程序和功能。通常不包含任何资源对象。 应用类型chart 可以作为库类型chart使用。可以通过将类型设置为library来实现。 然后这个库就被渲染成了一个库类型chart，所有的实用程序和功能都可以使用。所有的资源对象不会被渲染。 许可证和描述Chart LICENSE, README and NOTES Chart也可以包含描述安装、配置和使用的文件，以及chart许可证。 LICENSE是一个包含了chart license的纯文本文件。chart可以包含一个许可证，因为在模板里不只是配置，还可能有编码逻辑。如果需要，还可以为chart安装的应用程序提供单独的许可证。 README自述文件，一般包含： chart提供的应用或服务的描述 运行chart的先决条件或要求 values.yaml的可选项和默认值的描述 与chart的安装或配置相关的其它信息 chart也会包含一个简短的纯文本templates/NOTES.txt文件，这会在安装后及查看版本状态时打印出来。由于此文件是在运行helm install或helm status时打印到STDOUT的，因此建议保持内容简短，并指向自述文件以获取更多详细信息。 依赖Chart Dependencies Helm中，chart可能会依赖其它任意个chart。这些依赖可使用dependencies字段(Chart.yaml)动态链接，或写入charts/目录。 dependencies字段 当前chart依赖的其它chart会在dependencies字段定义为一个列表。 1234567dependencies: - name: apache version: 1.2.3 repository: https://example.com/charts - name: mysql version: 3.2.1 repository: https://another.example.com/charts 必须使用helm repo add在本地添加仓库。 一旦你定义好了依赖，运行helm dependency update就会使用你的依赖文件下载所有你指定的chart到你的charts/目录。 alias字段 为依赖chart添加一个别名，会使用别名作为新依赖chart的名称。 需要使用其他名称访问chart时可以使用alias。 123456789101112dependencies: - name: subchart repository: http://localhost:10191 version: 0.1.0 alias: new-subchart-1 - name: subchart repository: http://localhost:10191 version: 0.1.0 alias: new-subchart-2 - name: subchart repository: http://localhost:10191 version: 0.1.0 tags和condition字段 123456789101112131415dependencies: - name: subchart1 repository: http://localhost:10191 version: 0.1.0 condition: subchart1.enabled, global.subchart1.enabled tags: - front-end - subchart1 - name: subchart2 repository: http://localhost:10191 version: 0.1.0 condition: subchart2.enabled,global.subchart2.enabled tags: - back-end - subchart2 123456#values.yamlsubchart1: enabled: truetags: front-end: false back-end: true 12# 可以在CLI使用--set参数来设置标签和条件值helm install --set tags.front-end=true --set subchart2.enabled=false 通过依赖导入sub values 在某些情况下，允许子chart的值作为公共默认传递到父chart中是值得的。 12345678# parent's Chart.yaml filedependencies: - name: subchart repository: http://localhost:10191 version: 0.1.0 import-values: - data 12345# child's values.yaml fileexports: data: myint: 99 通过charts目录手动管理依赖 如果对依赖进行更多控制，通过将有依赖关系的chart复制到charts/目录中来显式表达这些依赖关系。 要将依赖放入charts/目录，使用helm pull命令。 Templates and ValuesHelm Chart模板是按照Go模板语言书写。让我想起了Django模板语言，Jinja2模板语言。 所有模板语言存放在chart的templates/目录下。当Helm渲染chart时，它会通过模板引擎遍历目录中的每个文件。 模板的Value通过两种方式提供： 通过values.yaml文件提供，此文件包含了默认值。 用户可以提供一个包含value的yaml文件，在helm install时使用它。 当用户提供自定义的value时，会覆盖values.yaml中的值。 模板文件示例 1234567891011121314151617181920212223242526apiVersion: v1kind: ReplicationControllermetadata: name: deis-database namespace: deis labels: app.kubernetes.io/managed-by: deisspec: replicas: 1 selector: app.kubernetes.io/name: deis-database template: metadata: labels: app.kubernetes.io/name: deis-database spec: serviceAccount: deis-database containers: - name: deis-database image: &#123;&#123; .Values.imageRegistry &#125;&#125;/postgres:&#123;&#123; .Values.dockerTag &#125;&#125; imagePullPolicy: &#123;&#123; .Values.pullPolicy &#125;&#125; ports: - containerPort: 5432 env: - name: DATABASE_STORAGE value: &#123;&#123; default &quot;minio&quot; .Values.storage &#125;&#125; 预定义的Values 以下值是预定义的，对每个模板都有效，并且可以被覆盖。和所有值一样，名称 区分大小写： Release.Name: 版本名称(非chart的) Release.Namespace: 发布的chart版本的命名空间 Release.Service: 组织版本的服务 Release.IsUpgrade: 如果当前操作是升级或回滚，设置为true Release.IsInstall: 如果当前操作是安装，设置为true Chart: Chart.yaml的内容。因此，chart的版本可以从Chart.Version获得， 并且维护者在Chart.Maintainers里 Files：chart中的包含了非特殊文件的类图对象 Capabilities: 包含了Kubernetes版本信息的类图对象 范围 Scope, Dependencies, and Values Values文件可以声明顶级chart的值，以及charts/目录中包含的其他任意chart。 全局Values Helm支持特殊的global值。 12global: app: MyWordPress 这个值以.Values.global.app在所有chart中有效。 架构文件 有时候，chart容器可能想基于它们的values值定义一个结构，这可以在values.schema.json文件中定义一个架构实现。 示例： 1234567891011121314151617181920212223242526272829303132333435&#123; "$schema": "https://json-schema.org/draft-07/schema#", "properties": &#123; "image": &#123; "description": "Container Image", "properties": &#123; "repo": &#123; "type": "string" &#125;, "tag": &#123; "type": "string" &#125; &#125;, "type": "object" &#125;, "name": &#123; "description": "Service name", "type": "string" &#125;, "port": &#123; "description": "Port", "minimum": 0, "type": "integer" &#125;, "protocol": &#123; "type": "string" &#125; &#125;, "required": [ "protocol", "port" ], "title": "Values", "type": "object"&#125; 这个架构会应用values值并验证它。当执行以下任意命令时会进行验证： helm install, helm upgrage, helm lint, helm template。 用户自定义资源Custom Resource Definitions k8s提供了一种声明k8s新类型对象的机制。使用CustomResourceDefinition（CRD），k8s开发者可以声明自定义资源类型。 Helm3中，CRD被视为一种特殊的对象。它们被安装在chart的其他部分之前，并受到一些限制。 CRD YAML文件应被放置在chart的crds/目录中。 多个CRD(用YAML的开始---和结束符...分隔)可以被放置在同一个文件中。Helm会尝试加载CRD目录中所有的文件到k8s。 当Helm安装新chart时，会上传CRD，暂停安装直到CRD可以被API服务使用，然后启动模板引擎， 渲染chart其他部分，并上传k8s。 CRD的限制 不像大部分k8s对象，CRD是全局安装的。因此Helm管理CRD时会采取非常谨慎的方式。 CRD受到以下限制： CRD从不重新安装。 如果Helm确定crds/目录中的CRD已经存在（忽略版本），Helm不会安装或升级。 CRD从不会在升级或回滚时安装。Helm只会在安装时创建CRD。 CRD从不会被删除。自动删除CRD会删除集群中所有命名空间中的所有CRD内容。因此Helm不会删除CRD。 希望升级或删除CRD的操作员应该谨慎地手动执行此操作。 管理chartUsing Helm to Manage Charts helm工具有一些命令用来处理chart。 12345678# 创建新charthelm create mychart# 打包helm package mychart# 格式信息helm lint mychart 仓库Chart Repositories 当helm用来管理本地chart目录时， 共享chart时，首选的机制就是使用chart仓库。 仓库的主要特征存在一个名为index.yaml的特殊文件，文件中包含仓库提供的包的完整列表， 以及允许检索和验证这些包的元数据。 在客户端，仓库使用helm repo命令管理。然而，Helm不提供上传chart到远程仓库的工具。 这是因为这样做会给执行服务器增加大量的必要条件，也就增加了设置仓库的障碍。 Starter Packshelm create命令可以附带一个可选的--starter选项指定一个starter chart。Starter就只是普通chart，但是被放置在$XDG_DATA_HOME/helm/starters。 HooksChart Hooks: https://helm.sh/docs/topics/charts_hooks/ Helm提供了一个hook机制，使chart开发者在发行版(release)生命周期的特定点进行干预。你可以使用hooks做以下事情： 安装过程中，在chart载入之前载入configmap或secret。 在安装一个新chart之前，执行一个作业(job)来备份数据库，然后执行第二个作业还原数据库。 在删除一个release之气，运行一个作业，在移除之前，来优雅地取出服务轮询。 hooks工作像常规模板，但它们有特殊的注释(写在annotations下)，因此helm可以不同地使用它们。本章节，我们将介绍hooks的基本使用模式。 12annotations: "helm.sh/hook": post-install 可用的hooks Annotation Value Description pre-install - 模板渲染之后执行，但在k8s创建任何资源之前 post-install - 所有资源载入k8s后执行 pre-delete - 在从k8s删除任意资源前，执行一个删除请求 post-delete - 在所有release的资源被删除后，执行一个删除请求 pre-upgrade - 在模板渲染后，执行一个升级请求，但在任意资源升级之前 post-upgrade - 在所有资源都升级后，执行一个升级 pre-rollback - 在模板渲染后，执行一个回滚请求，但在任意资源回滚前 post-rollback - 在所有资源都被修改后，执行一个回滚请求 test - 当heml test子命令调用时执行 测试Chart Tests: https://helm.sh/docs/topics/chart_tests/ chart包含许多k8s资源和协同工作的组件。作为包作者，你可能想编写一个测试，来验证包安装时是否如预期那样工作。 helm chart中的测试位于templates/目录下，是一个作业(job)定义，指定一个容器运行特定的命令。容器成功退出(exit 0)，被认为测试成功。作业定义必须包含helm.sh/hook: test的注释。 示例测试： 验证values.yaml文件被正确配置 验证服务、负载均衡正常 等等 可在helm中运行预定义测试，在release上使用helm test &lt;RELEASE_NAME&gt;命令。对于包的使用者，这是一个检测release of chart工作正常的方式。 示例Example Test 12345678910helm repo add bitnami https://charts.bitnami.com/bitnamihelm pull bitnami/wordpress --untarwordpress/ Chart.yaml README.md values.yaml charts/ templates/ templates/tests/test-mariadb-connection.yaml templates/tests/test-mariadb-connection.yaml的内容： 12345678910111213141516171819202122232425262728293031323334353637&#123;&#123;- if .Values.mariadb.enabled &#125;&#125;apiVersion: v1kind: Podmetadata: name: "&#123;&#123; .Release.Name &#125;&#125;-credentials-test" annotations: "helm.sh/hook": testspec: containers: - name: &#123;&#123; .Release.Name &#125;&#125;-credentials-test image: &#123;&#123; template "wordpress.image" . &#125;&#125; imagePullPolicy: &#123;&#123; .Values.image.pullPolicy | quote &#125;&#125; &#123;&#123;- if .Values.securityContext.enabled &#125;&#125; securityContext: runAsUser: &#123;&#123; .Values.securityContext.runAsUser &#125;&#125; &#123;&#123;- end &#125;&#125; env: - name: MARIADB_HOST value: &#123;&#123; template "mariadb.fullname" . &#125;&#125; - name: MARIADB_PORT value: "3306" - name: WORDPRESS_DATABASE_NAME value: &#123;&#123; default "" .Values.mariadb.db.name | quote &#125;&#125; - name: WORDPRESS_DATABASE_USER value: &#123;&#123; default "" .Values.mariadb.db.user | quote &#125;&#125; - name: WORDPRESS_DATABASE_PASSWORD valueFrom: secretKeyRef: name: &#123;&#123; template "mariadb.fullname" . &#125;&#125; key: mariadb-password command: - /bin/bash - -ec - | mysql --host=$MARIADB_HOST --port=$MARIADB_PORT --user=$WORDPRESS_DATABASE_USER --password=$WORDPRESS_DATABASE_PASSWORD restartPolicy: Never&#123;&#123;- end &#125;&#125; 运行测试: 123helm install quirky-walrus wordpress --namespace defaulthelm test quirky-walrus 注意： 你可以在templates/目录下定义许多测试 你可以嵌套你的测试&lt;chart-name&gt;/templates/tests/ 一个测试就是一个helm hook LibraryLibrary Charts: https://helm.sh/docs/topics/library_charts/ A library chart is a type of Helm chart，定义chart可通过helm模板在其它charts中共享。 完整性校验Helm Provenance and Integrity: https://helm.sh/docs/topics/provenance/ helm有来源工具，帮助chart user验证包的来源和完整性。使用基于行业标准的PIK, GnuPG等备受推崇的包管理器，Helm 可以生成和验证签名文件。 12345678# 生成helm package --sign ...helm package --sign --key &apos;John Smith&apos; --keyring path/to/keyring.secret mychart# 校验helm install --verifyhelm verify mychart-0.1.0.tgzhelm install --generate-name --verify mychart-0.1.0.tgz 仓库Chart Repository: https://helm.sh/docs/topics/chart_repository/ 官方的chart repo由Kubernetes Charts项目维护。欢迎各位参与。Helm也使得创建和运行自己的chart repo变得很容易。 创建仓库Create a chart repository: https://helm.sh/docs/topics/chart_repository/ 一个chart repo是一个HTTP服务器，它容纳了一个index.yaml文件和一些包。当你准备好分享你的charts，方法是将它们上传到一个chart repository。你可以使用GCS, S3, GitHub Pages等来创建你自己的web服务器。 注册中心Registries: https://helm.sh/docs/topics/registries/ Helm 3 支持OCI用于包分发。 Chart包可以通过基于OCI的注册中心存储和分发。 1234567891011121314151617181920212223242526272829303132333435363738394041# 激活对OCI的支持export HELM_EXPERIMENTAL_OCI=1# 运行一个注册中心docker run -dp 5000:5000 --restart=always --name registry registry# 认证htpasswd -cB -b auth.htpasswd myuser mypassdocker run -dp 5000:5000 --restart=always --name registry \ -v $(pwd)/auth.htpasswd:/etc/docker/registry/auth.htpasswd \ -e REGISTRY_AUTH=&quot;&#123;htpasswd: &#123;realm: localhost, path: /etc/docker/registry/auth.htpasswd&#125;&#125;&quot; \ registry# 登录helm registry login -u myuser localhost:5000# 注销helm registry logout localhost:5000# 保存helm chart save mychart/ localhost:5000/myrepo/mychart:2.7.0# 查看helm chart list# 导出helm chart export localhost:5000/myrepo/mychart:2.7.0# 推送到远程helm chart push localhost:5000/myrepo/mychart:2.7.0# 从缓存中移除helm chart remove localhost:5000/myrepo/mychart:2.7.0# 从远程拉取helm chart pull localhost:5000/myrepo/mychart:2.7.0 使用上述命令存储的chart会被缓存到文件系统中。OCI 镜像设计规范 严格遵守文件系统布局的。如： 123456789101112tree ~/Library/Caches/helm/└── registry ├── cache │ ├── blobs │ │ └── sha256 │ │ ├── 1b251d38cfe948dfc0a5745b7af5ca574ecb61e52aed10b19039db39af6e1617 │ │ ├── 31fb454efb3c69fafe53672598006790122269a1b3b458607dbe106aba7059ef │ │ └── 8ec7c0f2f6860037c19b54c3cfbab48d9b4b21b485a93d87b64690fdb68c2111 │ ├── index.json │ ├── ingest │ └── oci-layout └── config.json 架构Helm Architecture: https://helm.sh/docs/topics/architecture/ 介绍Helm在高级别的架构。 目的The Purpose of Helm Helm是管理称为chart的k8s包的工具。Helm可以做以下事情： 从头开始创建一个新的charts packages charts为归档(tgz) chart文件 与chart repo交互，并存储在那 安装和卸载charts到k8s集群 管理已安装的charts的发行版 对于Helm，有三个重要的概念： chart是创建一个k8s应用实例所需的信息束 config包含配置信息，可以合并到package chart来创建一个可发行的对象 release是一个运行的chart实例，包含特定的配置 组件Components Helm被实现为两个不同部分来执行： Helm CLI客户端，负责以下事情： 本地chart开发 管理repo 管理release 与Helm Library接口 发送chart安装 请求升级或卸载releases Helm Library提供了执行所有helm操作的逻辑。与k8s API接口交互，并提供以下功能： 组合chart和配置来构建一个release 安装chart到k8s，并提供release对象 通过与k8s交互，升级和卸载chart 实现Implementation Helm client和library由go编写。library使用k8s client与k8s集群通信。目前，library使用REST+JSON。它存储信息在k8s内的secrets里，不需要自己的数据库。配置文件以YAML编写。 高级技术Advanced Helm Techniques: https://helm.sh/docs/topics/advanced/ 后置渲染Post Rendering GO SDK 后端存储Storage backends RBACRole-based Access Control: https://helm.sh/docs/topics/rbac/ k8s rbac: https://kubernetes.io/docs/reference/access-authn-authz/rbac/ 介绍Helm如何与k8s RBAC进行交互。 在k8s中，授权角色给特定用户或应用的服务账号(service account)，以确保应用程序的操作在特定范围内。从k8s v1.6开始，RBAC默认启用。 使用RBAC，你可以： 授权特权操作给管理员 限制用户在特定命名空间/集群范围创建资源的能力 限制用户在特定命名空间/集群范围内查看资源的能力 管理用户账户Managing user accounts 所有的k8s集群有两种类型的用户： service accounts managed by Kubernetes normal users 普通用户假定由外部进行管理，独立的服务。管理员分发私钥，用户存储密码，甚至是用户名密码列表这样的文件。在这方面，k8s不具有代表普通用户账户的对象。普通用户无法通过API调用被添加到集群。 相比之下，服务账号是由k8s API管理的用户。它们被绑定到特定的命名空间，通过API server自动创建，或通过API调用手动创建。服务账号绑定在一组凭据里，存储为secret，它被挂载到pod，允许集群内进程与k8s API进行交谈。 API请求被绑定到任何一个用户（普通用户、服务账号），或者被视为匿名请求。这意味着集群内或集群外的每一个进程，从工作站上输入kubectl的人类用户，到节点上的kubelets，到控制面板的成员，在进行请求API server时必须进行认证，或被视为匿名用户。 角色、集群角色、角色绑定、集群角色绑定Roles, ClusterRoles, RoleBindings, and ClusterRoleBindings 在k8s中，用户账户和服务账户只能够根据授权访问来查看和修改资源。这种授权是通过使用角色(Roles)和角色绑定(RoleBindings)。角色和角色绑定被绑定到特定的命名空间，它通过角色提供授权，授予用户在此命名空间内查看或修改资源的能力。 在集群范围内，这些被称为集群角色(ClusterRoles)和集群角色绑定(ClusterRoleBindings)。授权用户集群角色，允许它们访问和修改整个集群的资源。这也需要查看和修改集群范围(命名空间，资源配额，节点)的资源。 集群角色可通过角色绑定的引用来绑定到特定的命名空间。admin, edit, view是最常使用的默认集群角色。 k8s有一些默认的集群角色可用，它们的本意是面向用户的角色。它们包含超级角色(cluster-admin)，和细粒度访问的角色(admin, edit, view)。 Default ClusterRole Default ClusterRoleBinding 描述 cluster-admin system:masters group 允许超级用户访问对任意资源执行任意动作。 admin None 允许管理员访问，在命名空间内使用角色绑定来授权。如读写命名空间内的大部分资源，包括在命名空间内创建角色和角色绑定的能力。但不允许对资源配额或命名空间进行写操作。 edit None 允许在命名空间内读取大多数对象的权限，不允许查看或修改角色和角色绑定 view None 允许在命名空间内查看大多数对象的权限。不允许查看角色和角色绑定。不允许查看secrets。 限制用户账户使用RBAC访问Restricting a user account access using RBAC 现在让我们了解基于角色的访问控制的基础知识，让我们讨论管理员如何限制用户的访问范围。 示例：授予用户命名空间范围的读写权限 Grant a user read/write access to a particular namespace 要限制用户对特定命名空间的读写权限，可以使用edit或admin角色。 此外，你还可以使用cluster-admin来创建一个角色绑定。授予在命名空间范围内的cluster-admin来提供在此命名空间内完整控制资源的权限，包含命名空间自身。 12345678# 创建nskubectl create namespace foo#创建RoleBindingkubectl create rolebinding sam-edit --clusterrole edit \ --user sam \ --namespace foo 示例：授予用户集群范围的读写权限 Example: Grant a user read/write access at the cluster scope 如果用户希望安装chart，在集群范围内安装集群资源（ns, roles, crd…），它们将需要集群范围的写权限。要这样做，授予用户admin或cluster-admin角色权限。 12345678kubectl create clusterrolebinding sam-view --clusterrole view \ --user samkubectl create clusterrolebinding sam-secret-reader --clusterrole secret-reader \ --user sam 示例：授予用户命名空间范围的只读权限 Example: Grant a user read-only access to a particular namespace 你可能注意到了，没有查看secret的集群角色。view集群角色没有授予用户访问secret的权限。然而，Helm默认将release metadata存储为secret。 为了使用户运行helm list，它需要读取这些secrets。为此，我们将创建一个特殊的secret-reader集群角色。 123456789# cluster-role-secret-reader.yamlapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: secret-readerrules:- apiGroups: [""] resources: ["secrets"] verbs: ["get", "watch", "list"] 1234567891011121314kubectl create -f clusterrole-secret-reader.yamlkubectl create namespace fookubectl create rolebinding sam-view --clusterrole view \ --user sam \ --namespace fookubectl create rolebinding sam-secret-reader --clusterrole secret-reader \ --user sam \ --namespace foo 示例：授予用户集群范围的只读权限 Example: Grant a user read-only access at the cluster scope 如果用户想运行helm l ist --all-namespaces命令，API需要用户拥有集群范围内的读权限。 1234567kubectl create clusterrolebinding sam-view --clusterrole view \ --user samkubectl create clusterrolebinding sam-secret-reader --clusterrole secret-reader \ --user sam 插件The Helm Plugins Guide: https://helm.sh/docs/topics/plugins/ Helm plugin是一个可通过helm CLI访问的工具，但不是内置的helm基础代码的一部分。 V2迁移到V3Migrating Helm v2 to v3: https://helm.sh/docs/topics/v2_v3_migration/ 弃用的k8s apiDeprecated Kubernetes APIs: https://helm.sh/docs/topics/kubernetes_apis/ 版本支持Helm Version Support Policy: https://helm.sh/docs/topics/version_skew/ SQL存储后端的权限管理Permissions management for SQL storage backend: https://helm.sh/docs/topics/permissions_sql_storage_backend/ 最佳实践The Chart Best Practices Guide: https://helm.sh/docs/chart_best_practices/ 涵盖了Helm团队对创建chart的最佳做法。它侧重于chart应该如何构造。主要关注那些可能会公开部署的charts的最佳实践。 一般约定General Conventions: https://helm.sh/docs/chart_best_practices/conventions/ chart名称Chart Names chart名称必须是小写字母和数字，可用-隔开。 chart目录必须与chart名称相同。 1234567# 示例drupalnginx-legoaws-cluster-autoscalernginx-legonginx-lego/ 版本号Version Numbers 只要有可能，Helm使用SemVer2来表示版本号。请注意，Docker image tag并不一定遵循SemVer，注意。 格式化YAMLFormatting YAML YAML应该使用两个空格（别使用tab）。 词Usage of the Words Helm and Chart Helm词的一些约定： Helm指作为一个整体的项目 helm客户端CLI chart不需要大写，它不是专有名词 Chart.yaml需要大写，因为该文件名是大小写敏感的 值Values: https://helm.sh/docs/chart_best_practices/values/ 提供给你如何组织和设计chart的values.yaml文件，并使用你的值。 命名约定Naming Conventions 变量名必须小写字母开头，使用驼峰分开： 12chicken: truechickenNoodleSoup: true 请注意，所有Helm内置变量以大写字母开头，用户可以轻松区分开: 12.Release.Name.Capabilities.KubeVersion 嵌套值YAML是一种灵活的格式，值可以被深度嵌套。 123server: name: nginx port: 80 123&#123;&#123; if .Values.server &#125;&#125; &#123;&#123; default &quot;none&quot; .Values.server.name &#125;&#125;&#123;&#123; end &#125;&#125; 使类型清晰Make Types Clear 12345678910# YAM的类型强制规则有时是反直觉的。例如一下两者是不同的foo: falsefoo: "false"# 避免类型转化错误的最简单的方法是要明确字符串和隐含的一切。使用引号引用字符串# 要避免整数转换错误，将整数存储为字符串，使用以下方法来获取整数值&#123;&#123; int $value &#125;&#125;# 在大多数情况下，显式类型标签被尊重。如以下1234被当作字符串foo: !!string 1234 考虑用户如何使用你的值Consider How Users Will Use Your Values 值有三个来源： values.yaml文件 helm install -f或helm upgrade -f时指定的文件里 --set或--set-string选项指定 当设计值的组织结构时，用户是希望可通过-f或--set选项来覆盖它们。YAML建议写成映射(mapping)，便于替换--set servers.foo.port=80。 12345servers: foo: port: 80 bar: port: 81 values.yaml每个在values.yaml中定义的属性应该被记录(documented)。文档字符串应该用它描述的属性的名称开始，然后给出至少一个单句描述。 1234# serverHost is the host name for the webserverserverHost: example# serverPort is the HTTP listener port for the webserverserverPort: 9191 模板Templates: https://helm.sh/docs/chart_best_practices/templates/ templates目录架构Structure of templates/ templates/目录应该是如下结构： 模板文件是.yaml扩展的YAML输出。.tpl扩展可用于未经格式化的模板文件 模板文件名应使用虚线(example-configmap.yaml)，而不是驼峰 每个资源定义应该有自己的模板文件 模板文件应放映资源类型（如foo-pod.yaml, bar-svc.yaml） 定义的模板的名称Names of Defined Templates 定义的模板(模板文件内的)是全局访问的。这意味着，chart和它的subchart可以访问所有创建的模板。这样我想起了Pythond的模板语言（Django模板语言，Jinja2等等）。 出于此原因，所有定义的模板名称都应该命名空间。 123&#123;&#123;- define &quot;nginx.fullname&quot; &#125;&#125;&#123;&#123;/* ... */&#125;&#125;&#123;&#123; end -&#125;&#125; It is highly recommended that new charts are created via helm create command as the template names are automatically defined as per this best practice. 格式化模板Formatting Templates 模板应该使用两个空格，而不是tab。花括号前后应该有空格。有适当的空格和缩进。 1234567&#123;&#123; .foo &#125;&#125;&#123;&#123; print &quot;foo&quot; &#125;&#125;&#123;&#123;- print &quot;bar&quot; -&#125;&#125;&#123;&#123; if $foo -&#125;&#125; &#123;&#123;- with .Bar &#125;&#125;Hello&#123;&#123; end -&#125;&#125;&#123;&#123;- end -&#125;&#125; 生成模板中的空格Whitespace in Generated Templates 优选的是，保持在生成的模板中的空格数量降到最低。特别是，许多空行不应出现彼此相邻。但偶尔空行还是可以的。 1234567891011121314151617181920# This is bestapiVersion: batch/v1kind: Jobmetadata: name: example labels: first: first second: second# This is okayapiVersion: batch/v1kind: Jobmetadata: name: example labels: first: first second: second 注释Comments (YAML Comments vs Template Comments) YAML文件注释和模板注释。当一个模板记录功能时，应该使用模板注释。当Helm用户通过查看注释调试时，在模板内应该使用YANML注释。 123456789101112131415161718# yaml 注释&#123;&#123;- /*模板注释*/ -&#125;&#125;&#123;&#123;- /*mychart.shortname provides a 6 char truncated version of the release name.*/ -&#125;&#125;&#123;&#123; define &quot;mychart.shortname&quot; -&#125;&#125;&#123;&#123; .Release.Name | trunc 6 &#125;&#125;&#123;&#123;- end -&#125;&#125;# This may cause problems if the value is more than 100Gimemory: &#123;&#123; .Values.maxMem | quote &#125;&#125; 在模板和模板输出中使用JSONUse of JSON in Templates and Template Output YAML是JSON的超集(superset)。在一些情况下，使用JSON语法可比其它YAML表示更具有可读性。 123456789# 列表# yamlarguments: - &quot;--dirname&quot; - &quot;/foo&quot;# jsonarguments: [&quot;--dirname&quot;, &quot;/foo&quot;] 依赖Dependencies: https://helm.sh/docs/chart_best_practices/dependencies/ 介绍Chart.yaml内声明的dependencies的最佳实践。 版本Versions 如果可能的化，使用版本范围，而不是某个确切的版本。建议使用补丁级别(patch-level)版本匹配: 12# &gt;= 1.2.3, &lt; 1.3.0version: ~1.2.3 repo ruls，如果可能，使用HTTPS。文件URL(file://...)被认为是一个特殊，对由一个固定部署的流水线charts。 条件和标记Conditions and Tags 条件或标记应被添加到任何依赖（可选的）。 1234567# 条件的推荐格式condition: somechart.enabled# 标记tags: - webaccelerator 标签和注释Labels and Annotations: https://helm.sh/docs/chart_best_practices/labels/ 讨论chart中使用标签和注释的最佳实践。 标签还是注释Is it a Label or an Annotation? 以下条件的元数据项应该为标签(label)： 它利用k8s来标识此资源 暴露给查询系统的目的是有用的 如果元数据的条目不用于查询，它应该设置为注释。Helm hooks总是注释。 标准的标签Standard Labels 下表定义了Helm chart常用的标签。Helm自身从未要求特定的标签存在。REC的标签是建议的，并应该放置到全局一致性的chart。OPT的标签是可选的。 12345678名称 状态 描述app.kubernetes.io/name REC 这应该是app名称。通常使用&#123;&#123; template &quot;name&quot; . &#125;&#125; 这由许多k8s manifests使用，不是Helm特定的helm.sh/chart REC chart名称和版本: &#123;&#123; .Chart.Name &#125;&#125;-&#123;&#123; .Chart.Version &#125;&#125;app.kubernetes.io/managed-by REC 这应该始终设置为&#123;&#123; .Release.Service &#125;&#125;app.kubernetes.io/instance REC 这应该为&#123;&#123; .Release.Name &#125;&#125;，有助于在同意应用不同实例之间进行区分app.kubernetes.io/version OPT 应用的版本设置为&#123;&#123; .Chart.AppVersion &#125;&#125;app.kubernetes.io/component OPT This is a common label for marking the different roles that pieces may play in an application|app.kubernetes.io/part-of OPT 当多个charts或软件片一起使用来做一个应用 可在k8s 文档中，带有app.kubernetes.io前缀的文档中查看更多信息。 Pods和PodTemplatesPods and PodTemplates: https://helm.sh/docs/chart_best_practices/pods/ 以下资源列表使用PodTemplate： Deployment ReplicationController ReplicaSet DaemonSet StatefulSet 镜像Images 容器镜像应该使用确定的标记或镜像的SHA。但不应该使用latest, head, canary这样的标记。 镜像可以在values.yaml文件中定义，使其很容易替换镜像。 1image: &#123;&#123; .Values.redisImage | quote &#125;&#125; 镜像和标记可在values.yaml中被定义为分开的两个字段： 1image: &quot;&#123;&#123; .Values.redisImage &#125;&#125;:&#123;&#123; .Values.redisTag &#125;&#125;&quot; 镜像拉取策略ImagePullPolicy helm create默认在deployment.yaml中设置imagePullPolicy为IfNotPresent。 1imagePullPolicy: &#123;&#123; .Values.image.pullPolicy &#125;&#125; 123# values.yamlimage: pullPolicy: IfNotPresent 同样，如果未设置impagePullPolicy，k8s默认会将其设置为IfNotPresent。如果想要修改此值，只需在values.yaml文件中更新此值。 PodTemplate应该声明选择器PodTemplates Should Declare Selectors 所有的PodTemplate部分应该指定一个选择器。示例： 1234567selector: matchLabels: app.kubernetes.io/name: MyNametemplate: metadata: labels: app.kubernetes.io/name: MyName 这是一个很好的做法，因为它使set和pod相关联。 但是，这对于像Deployment这样的集更为重要。没有这一点，整个标签集(set of labels)用于选择匹配pod，如果你使用的标签发生改变（如版本或日期），这将打破匹配。 自定义资源的定义Custom Resource Definitions 当使用自定义资源定义(CRDs)，区分两种不同的片是很重要的： 声明一个CRD(kind: CustomResourceDefinition) 然后资源使用CRD 使用资源前安装CRD声明Install a CRD Declaration Before Using the Resource Helm是尽可能优化地载入更多的资源到k8s中。按照设计，k8s可以采取一整套清单(manifests)，并带它们所有上线（这就是所谓的和解循环(reconciliation loop))）。 但是，CRDs有一些不同。对于CRD，在任意CRDs类型资源被使用之前，必须先注册声明。注册过程有时需要几秒。 方法1：让helm为你做此事 Method 1: Let helm Do It For You 随着Helm3的到来，出于更简单的方法，Helm移除了旧的crd-install hooks。这在是一个称为crds的新目录，在你创建的chart的此目录下保存你的CRDs。这些CRDs没有模板，但会在chart运行helm install时默认安装。如果CRD已存在，它会被跳过。你也可以通过传递--skip-crds选项来跳过CRD的安装。 一些注意事项: 目前不支持使用Helm更新或删除CRDs。这是一个经过反复讨论的明确的决定，由于存在非故意丢失数据的危险。此外，目前社区如何处理CRDs和它的生命周期没有共识，由于这种演变，Helm将添加对这些用例的支持。 helm install和helm upgrade的--dry-run选项暂不支持CRDs。Dry Run的目的是去验证chart的输出将实际地工作，如果发送到服务器。但CRDs可通过服务器行为的修改。Helm无法在dry run上安装CRD，因此发现客户端将不知道自定义资源(CR)，并验证将失败。你可以可选地移动CRDs到它们自己的chart，或使用helm template来代替。 围绕CRD支持的另一个重要的考虑点是如何处理模板的渲染(rendering of templates)。一个在Helm2中使用crd-install方法的明显的缺点是不能正确验证chart，由于改变API可用性（一个CRD被实际添加到另一个可用API到k8s集群）。如果一个chart安装了CRD，helm不再有一组API版本的有效集。这也是在移除从CRDs的模板支持的原因。随着安装CRD的新的crds方法，我们现在确保helm有关于当前集群状态的完整信息。 方法2：独立chart Separate Charts 另一种方法是，把CRD定义在一个chart中，然后把所有资源使用的该CRD放在另一个chart。 在此方法中，每个char都必须单独安装。然而，这个工作流程可能是集群操作器(cluster operators)（对集群拥有admin权限）使用。 RBACRole-Based Access Control: https://helm.sh/docs/chart_best_practices/rbac/ RBAC资源有： ServiceAccount (namespaced) Role (namespaced) ClusterRole RoleBinding (namespaced) ClusterRoleBinding YAML配置RBAC和ServiceAccount配置因该在单独的密钥里。它们是不同的东西。拆分这两个概念在YAML歧义消除它们，使之更清楚。 12345678910rbac: # Specifies whether RBAC resources should be created create: trueserviceAccount: # Specifies whether a ServiceAccount should be created create: true # The name of the ServiceAccount to use. # If not set and create is true, a name is generated using the fullname template name: 多个服务账号可以扩展为更复杂的charts。 12345678someComponent: serviceAccount: create: true name:anotherComponent: serviceAccount: create: true name: RBAC资源应该被默认创建RBAC Resources Should be Created by Default rbac.create应该是一个布尔值，由RBAC资源来控制创建。默认应该为true。希望管理RBAC访问控制的用户可以将此设置为false。 使用RBAC资源Using RBAC Resources serviceAccount.name应该被设置为由chart创建的访问控制资源使用的服务账号名称。如果serviceAccount.create为true，那么此名称的服务名称应该被创建。如果此名称未设置，则使用模板fullname来生成。如果为false，则它不应该被创建，但它应该与同样的资源相关联，以便创建后引用该手动创建RBAC资源正常工作。如果为false且没有指定名称，则使用默认的服务账号。 下面的助手模板应该用于服务账号： 12345678910&#123;&#123;/*Create the name of the service account to use*/&#125;&#125;&#123;&#123;- define "mychart.serviceAccountName" -&#125;&#125;&#123;&#123;- if .Values.serviceAccount.create -&#125;&#125; &#123;&#123; default (include "mychart.fullname" .) .Values.serviceAccount.name &#125;&#125;&#123;&#123;- else -&#125;&#125; &#123;&#123; default "default" .Values.serviceAccount.name &#125;&#125;&#123;&#123;- end -&#125;&#125;&#123;&#123;- end -&#125;&#125; 模板Chart Template: https://helm.sh/docs/chart_template_guide/ Helm‘s chart templates，重点介绍模板语言。让我想起的Django模板语言、Jinja2模板语言。 模板生成清单文件，这是k8s可理解的YAML格式的资源描述。本章重点介绍以下概念： Helm模板语言 Values使用 使用模板的技术 入门Getting Started: https://helm.sh/docs/chart_template_guide/getting_started/ 创建一个chart并添加一个模板。 Charts123456mychart/ Chart.yaml values.yaml charts/ templates/ ... templates/目录存放模板文件。当Helm评估一个chart，它会发送所有模板目录中的文件到模板渲染引擎。然后，它收集模板的结果，并将它们发送到k8s。 values.yaml文件对模板也很重要。此文件包含了一个chart的默认值。默认值可通过命令行选项进行覆盖。 Chart.yaml文件包含对chart包的描述信息。你可在模板中访问它。charts/目录可能包含其它chats(称为subcharts)。 示例A Starter Chart 123456789101112131415161718192021222324# 创建一个名为mychart的chart包helm create mychartCreating mychart# 目录结构tree ./mychart -L 2./mychart├── charts├── Chart.yaml├── templates│ ├── deployment.yaml│ ├── _helpers.tpl #模板助手，你可以重新使用整个chart│ ├── hpa.yaml #│ ├── ingress.yaml│ ├── NOTES.txt #chart包的帮助文本(help text)，会在运行helm install显示│ ├── serviceaccount.yaml│ ├── service.yaml│ └── tests└── values.yaml# 创建自己的模板rm -rf mychart/templates/* 当编写生产环境的chart包时，有这些charts包的基础版本可能很有用。 第一个模板A First Template 创建一个ConfigMap资源的模板。由于它是一个基本的资源，因此它为我们提供了一个很好的起点。 12345678# mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: mychart-configpmapdata: myvalue: "Hello World" 小技巧：模板名称不遵循严格的命名模式。然而，我们建议为YAML文件使用.yaml后缀，为模板助手使用.tpl后缀。 上述YAML文件是一个最基本的ConfigMap，最有最小的必要的字段。它会通过模板引擎进行发送。 一个普通的平YAML文件是蛮好的。当Helm读取此模板，它会简单地将文件原样发送给k8s。 在这个简单的例子中，我们现在有了一个可安装的chart包。安装一下： 1234567891011121314151617181920212223242526272829303132helm install full-coral mychartNAME: full-coralLAST DEPLOYED: Sun Sep 27 10:38:03 2020NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: Nonehelm lsNAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSIONfull-coral default 1 2020-09-27 10:38:03.546664865 +0800 CST deployed mychart-0.1.0 1.16.0helm get manifest full-coral---# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: mychart-configmapdata: myvalue: &quot;Hello World&quot;kubectl get configmapNAME DATA AGEmychart-configmap 1 9m47s# 卸载helm uninstall full-coral 添加一个简单的模板调用 Adding a Simple Template Call 硬编码的name，通常被认为是不好的做法。每个发行版的名称应该是唯一的。因此，我们可能将生成一个名称字段来写入发行版名称。 注意，由于DNS系统的限制，name字段被限制为63字符。出于这个原因，发行版名称被限制为53字符。 123456apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" 123456789101112131415161718192021222324# 模板指令放置于&#123;&#123; xxx &#125;&#125; 块内helm install clunky-serval mychart/NAME: clunky-servalLAST DEPLOYED: Sun Sep 27 11:16:20 2020NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: Nonehelm get manifest clunky-serval---# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: clunky-serval-configmapdata: myvalue: &quot;Hello World&quot;# 可使用--debug查看详情# 下面将渲染模板，返回渲染输出，不会真正安装helm install --debug --dry-run goodly-guppy ./mychart 使用--dry-run将更容易对代码进行测试，但它不会保证k8s会接受你生成的模板。 内置对象Built-in Objects: https://helm.sh/docs/chart_template_guide/builtin_objects/ 对象动模板引擎传递到模板。你的代码可以传递对象范围（如with和range）。有一些方法可在模板中创建新的对象，如tuple函数。 对象可以很简单，它只有一个值。它们也可以包含其它对象或函数。如，Realease对象可包含几个对象（如Release.Name），Files对象有一些函数。 12345678910111213141516171819202122232425- `Release`对象 - `Release.Name` - `Release.Namespace` - `Release.IsUpgrade` - `Release.IsInstall` - `Release.Revision` - `Release.Service`：在Helm中，总是Helm- `Values`: `values.yaml`中传递给模板的值- `Chart`: `Chart.yaml`文件内容- `Files`: 访问chart包中非模板的文件 - `Files.Get`: 通过名称生成文件的函数 - `Files.GetBytes` - `Files.Glob`: 返回文件为列表的函数 - `Files.Lines`: 一行行读取文件的函数 - `Files.AsSecrets`: 返回文件内容为base64编码字符串的函数 - `Files.AsConfig`: 返回文件内容为YAML map的函数- `Capabilities` - `Capabilities.APIVersions` - `Capabilities.APIVersions.Has $version` - `Capabilities.KubeVersion`, `Capabilities.KubeVersion.Version` - `Capabilities.KubeVersion.Major` - `Capabilities.KubeVersion.Minor`- `Template` - `Template.Name` - `Template.BasePath` 内置的值总以大写字母开头。这与go命名方式保持一致。 值文件Values Files: https://helm.sh/docs/chart_template_guide/values_files/ Values是一个内置的对象。它提供了访问值并传递到chart包。值文件是平YAML文件。其内容来源于多个源： chart包中的values.yaml文件 如果是一个subchart包，则为parent chart包的values.yaml文件 通过helm install/upgrade的-f myvals.yaml传递值 通过helm install/upgrade的--set foo=bar选项传递值 123456789101112# values.yamlfavoriteDrink: coffee# configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" drink: &#123;&#123; .Values.favoriteDrink &#125;&#125; 12345678910111213141516171819202122232425262728# 渲染helm install geared-marsupi ./mychart --dry-run --debugHOOKS:MANIFEST:---# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: geared-marsupi-configmapdata: myvalue: &quot;Hello World&quot; drink: coffee# 通过命令行选项覆盖值helm install solid-vulture ./mychart --dry-run --debug --set favoriteDrink=slurmHOOKS:MANIFEST:---# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: solid-vulture-configmapdata: myvalue: &quot;Hello World&quot; drink: slurm 值文件也可以包含更多结构化的内容。 123456789101112131415# values.yamlfavorite: drink: coffee food: pizza# configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" drink: &#123;&#123; .Values.favorite.drink &#125;&#125; food: &#123;&#123; .Values.favorite.food &#125;&#125; 虽然结构化数据这种方式是可行的，但建议你保持值的浅度(shallow)，有利于平整。当看到subcharts包的值时，我们将看到值是如何使用树状结构命名的。 删除一个默认键Deleting a default key 如果你需要从默认值删除一个键，你可以覆盖这个键的值为null，在这种情况下，Helm将从覆盖值得合并中移除这个键。 模板函数和管道Template Functions and Pipelines: https://helm.sh/docs/chart_template_guide/functions_and_pipelines/ 到目前为止，我们以将看到如何将信息转换为模板。但这些信息放入未修改的模板。有时候，我们希望以一种更可用的方式来转换提供的数据。 在模板指令中调用quote函数： 12345678apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" drink: &#123;&#123; quote .Values.favorite.drink &#125;&#125; food: &#123;&#123; quote .Values.favorite.food &#125;&#125; 模板函数使用funcationName arg1 arg2...语法。上面的quote .Values.favorite.drink调用quote函数并传递一个参数。 Helm有超过60个可用的函数。一些通过go模板语言定义。大多数是Sprig template library的一部分。 管道pipelines(|) 模板语言的一个强大功能就是它的管道(|)。管道是让几件事情依序进行的有效方式。让我们使用管道重写上面的示例： 12345678apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" drink: &#123;&#123; .Values.favorite.drink | quote &#125;&#125; food: &#123;&#123; .Values.favorite.food | quote &#125;&#125; 使用管道，我们可以将多个函数链接在一起： 12345drink: &#123;&#123; .Values.favorite.drink | repeat 5 | quote &#125;&#125;food: &#123;&#123; .Values.favorite.food | upper | quote &#125;&#125;#drink: "coffeecoffeecoffeecoffeecoffee"#food: "PIZZA" default函数default函数经常在模板中使用(default DEFAULT_VALUE GIVEN_VALUE)。此函数允许你指定一个默认值。有则替换它，无则使用默认值。 1drink: &#123;&#123; .Values.favorite.drink | default "tea" | quote &#125;&#125; 在实际的chart包中，所有静态默认值都应该位于values.yaml中，而不应该使用default重复。然而，default命令对于不能在values.yaml中声明的值，是完美的计算值的方法。例如： 1drink: &#123;&#123; .Values.favorite.drink | default (printf "%s-tea" (include "fullname" .)) &#125;&#125; lookup函数lookup函数可用于在正在运行的集群中查找资源。它查找apiVersion, kind, namespace, name到resource或resource list。 123456789101112# apiVersion, kind, namespace, name都是string# name, namespace两个是可选的，可以为空进行传递# 下列将会返回mynamespace对象的注释(lookup &quot;v1&quot; &quot;Namespace&quot; &quot;&quot; &quot;mynamespace&quot;).metadata.annotations# 当lookup返回一个列表(list)对象时，可以通过items字段访问列表对象&#123;&#123; range $index, $service := (lookup &quot;v1&quot; &quot;Service&quot; &quot;mynamespace&quot; &quot;&quot;).items &#125;&#125; &#123;&#123;/* do something with each service */&#125;&#125;&#123;&#123; end &#125;&#125; 当没有找到对象时，则返回一个空值。这可以用于检查对象是否存在。 lookup函数使用Helm现有的k8s连接配置来查询k8s。如果调用API server进行交互时返回错误，则Helm的模板处理将失败。 请记住，Helm是不应该在helm template或helm install|update|delete|rollback --dry-run期间连接到k8s API server，因此，lookup在此情况下将会获得一个空列表。 操作符Operators are functions 对于模板，操作符(eq, ne, lt, gt, and, or等)都被实现为函数。在管道中，操作符可使用括号()进行分组。 函数列表Template Function List: https://helm.sh/docs/chart_template_guide/function_list/ Helm包含很多模板函数，你可以在模板中使用它们。下面按照功能列出： Cryptographic and Security Date Dictionaries Encoding File Path Kubernetes and Chart Logic and Flow Control Lists Math Network Reflection Regular Expressions Semantic Versions String Type Conversion URL UUID 流程控制Flow Control: https://helm.sh/docs/chart_template_guide/control_structures/ 控制结构（在模板原语中称为行动）提供给模板作者，模板生成的控制流程的能力。Helm的模板语言提供了如下控制结构： if, else：创建条件块 with：指定一个范围 range： 提供一个类似的for循环 除此之外，它为声明和使用命名模板段提供了一些动作： define：在模板内声明一个新的命名模板 template：导入一个命名的模板 block：声明一个特殊的可填写的模板区域 这些都让我想起之前用Django模板语言写前端的时候，基本上一样的原理。 if和elseif, else块示例： 1234567&#123;&#123; if PIPELINE &#125;&#125; # Do something&#123;&#123; else if OTHER PIPELINE &#125;&#125; # Do something else&#123;&#123; else &#125;&#125; # Default case&#123;&#123; end &#125;&#125; 123456789apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" drink: &#123;&#123; .Values.favorite.drink | default "tea" | quote &#125;&#125; food: &#123;&#123; .Values.favorite.food | upper | quote &#125;&#125; &#123;&#123; if eq .Values.favorite.drink "coffee" &#125;&#125;mug: true&#123;&#123; end &#125;&#125; 控制空格Controlling Whitespace 虽然我们看到了条件语句，我们也应该了解模板中的空格的控制方式。这主要是确保对于生成的YAML文件的缩进的正确性。 1234567891011apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" drink: &#123;&#123; .Values.favorite.drink | default "tea" | quote &#125;&#125; food: &#123;&#123; .Values.favorite.food | upper | quote &#125;&#125; &#123;&#123; if eq .Values.favorite.drink "coffee" &#125;&#125; mug: true &#123;&#123; end &#125;&#125; 生成的不正确的YAML格式： 12345678910# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: eyewitness-elk-configmapdata: myvalue: "Hello World" drink: "coffee" food: "PIZZA" mug: true mug被不正确地缩进。让我们修改模板： 1234567891011apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" drink: &#123;&#123; .Values.favorite.drink | default "tea" | quote &#125;&#125; food: &#123;&#123; .Values.favorite.food | upper | quote &#125;&#125; &#123;&#123; if eq .Values.favorite.drink "coffee" &#125;&#125; mug: true &#123;&#123; end &#125;&#125; 这样生成的YAML是有效的，但显得很滑稽： 1234567891011# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: telling-chimp-configmapdata: myvalue: "Hello World" drink: "coffee" food: "PIZZA" mug: true 请注意，在YAML文件中生成了几个空行。为什么？当模板引擎运行时，它将删除花括号里的内容，但它留下的剩余空格完全一样。 YAML对空白很在意，所以管理空白变得非常重要。幸运的是，Helm有一些工具来帮助我们。 1234# 首先，模板声明的花括号 &#123;&#123; 可以使用特殊字符进行修改，来告诉模板引擎排列空白&#123;&#123;- 表示空白应靠左(chomped left)-&#125;&#125; 表示空白应在右边消耗(right should be consumed)# 注意，换行也是空白（Newlines are whitespace) 1234567891011apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" drink: &#123;&#123; .Values.favorite.drink | default "tea" | quote &#125;&#125; food: &#123;&#123; .Values.favorite.food | upper | quote &#125;&#125; &#123;&#123;- if eq .Values.favorite.drink "coffee" &#125;&#125; mug: true &#123;&#123;- end &#125;&#125; 12345678910# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: clunky-cat-configmapdata: myvalue: &quot;Hello World&quot; drink: &quot;coffee&quot; food: &quot;PIZZA&quot; mug: true 小心使用排列修改器(chomping modifier)。很容易不小心做了下面的事情： 1234food: &#123;&#123; .Values.favorite.food | upper | quote &#125;&#125;&#123;&#123;- if eq .Values.favorite.drink "coffee" -&#125;&#125;mug: true&#123;&#123;- end -&#125;&#125; 这会生成food: &quot;PIZZA&quot;mug:true这样，因为它消耗了两侧的换行。 123# 最后，有时很容易告诉模板系统如何缩进，而不是试图掌握模板指令的空格。# 出于此原因，你有时可能会发现使用 indent函数 处理缩进是很有用的&#123;&#123; indent 2 &quot;mug: true&quot; &#125;&#125; 使用with修改范围Modifying scope using with 另一个控制结构是with动作。这可以控制变量的范围，.是指的当前范围。因此，.Values告诉模板到当前范围下去寻找Values对象。 1234# with语法和if语句类似&#123;&#123; with PIPELINE &#125;&#125; # restricted scope&#123;&#123; end &#125;&#125; 范围可以被更改。with可以允许你将当前范围(.)设置为特定对象。例如，我们使用.Values.favorite工作。让我们在.Values.favorite范围来重写ConfigMap： 12345678910apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" &#123;&#123;- with .Values.favorite &#125;&#125; drink: &#123;&#123; .drink | default "tea" | quote &#125;&#125; food: &#123;&#123; .food | upper | quote &#125;&#125; &#123;&#123;- end &#125;&#125; 12# 注意，由于我们使用 with 将范围设置在了 .Values.favorite# 所以我们使用 .drink, .food。范围在 &#123;&#123; end &#125;&#125; 后被还原 但这里有一个值得注意的问题！在限制的范围内，你将无法从父对象范围(.)访问其它对象。以下示例会失败： 123456&#123;&#123;- with .Values.favorite &#125;&#125;drink: &#123;&#123; .drink | default "tea" | quote &#125;&#125;food: &#123;&#123; .food | upper | quote &#125;&#125;release: &#123;&#123; .Release.Name &#125;&#125;&#123;&#123;- end &#125;&#125;release-2: &#123;&#123; .Release.Name &#125;&#125; 由于Release.Name没有在限制的范围(.)内，会报错。但在限制的之外就没有问题。 或者，我们可以使用$符号从父范围访问Release.Name对象。$符号在开始执行时会映射到根范围内，在模板执行时也不会改变。示例如下： 12345&#123;&#123;- with .Values.favorite &#125;&#125;drink: &#123;&#123; .drink | default "tea" | quote &#125;&#125;food: &#123;&#123; .food | upper | quote &#125;&#125;release: &#123;&#123; $.Release.Name &#125;&#125;&#123;&#123;- end &#125;&#125; 在了解range后，我们会看到模板变量，它提供了一个解决上述作用域问题的方法。 range循环Looping with the range action 许多编程语言都是用for循环，在Helm模板语言中，它使用range操作符来实现迭代。 首先，让我们在values.yaml文件里添加一个列表。 12345678favorite: drink: coffee food: pizzapizzaToppings: - mushrooms - cheese - peppers - onions 在我们的ConfigMap中获取值里面的列表： 1234567891011121314apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" &#123;&#123;- with .Values.favorite &#125;&#125; drink: &#123;&#123; .drink | default "tea" | quote &#125;&#125; food: &#123;&#123; .food | upper | quote &#125;&#125; &#123;&#123;- end &#125;&#125; toppings: |- &#123;&#123;- ranage .Values.pizzaToppings &#125;&#125; - &#123;&#123; . | title | quote &#125;&#125; &#123;&#123;- end &#125;&#125; 我们可以使用$来访问父范围内的Values.pizzaToppings。$符号映射到根目录下，并在函数执行时不会改变。示例如下: 1234567891011121314apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: myvalue: "Hello World" &#123;&#123;- with $.Values.favorite &#125;&#125; drink: &#123;&#123; .drink | default "tea" | quote &#125;&#125; food: &#123;&#123; .food | upper | quote &#125;&#125; toppings: |- &#123;&#123;- range $.Values.pizzaToppings &#125;&#125; - &#123;&#123; .| title | quote &#125;&#125; &#123;&#123;- end &#125;&#125; &#123;&#123;- end &#125;&#125; 渲染示例： 1234567891011121314# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: edgy-dragonfly-configmapdata: myvalue: "Hello World" drink: "coffee" food: "PIZZA" toppings: |- - "Mushrooms" - "Cheese" - "Peppers" - "Onions" 符号|-声明一个多行字符串。因此，实际上我们的toppings不是一个YAML list，而是一个big string。我们为什么要这样做？因为在ConfigMaps data里的数据是由键值对(k/v)组成，其中键和值都是简单的字符串。要理解为什么这样的化，请查看k8s configmap文档。 YAML里的|-符号表示一个多行字符串(multi-line string)。这可以在文件中嵌入一大块数据。 Helm模板具有一个tuple函数，来使得操作更简单。让我想起了Python中的tuple数据类型。示例如下: 1234sizes: |- &#123;&#123;- range ruple "small" "medium" "large"&#125;&#125; - &#123;&#123; . &#125;&#125; &#123;&#123;- end &#125;&#125; 结果如下： 1234sizes: |- - small - medium - large 除了list和tuple，range还可以迭代具有有键值对的map和dict。我们将在后面的章节中了解它们。 变量Variables: https://helm.sh/docs/chart_template_guide/variables/ 我们可以在模板中使用变量。在Helm模板中，变量是其它对象的命名引用。 123456789101112apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Releae.Name &#125;&#125;-configmapdata: myvalue: "Hello World" &#123;&#123;- $relname := .Release.Name -&#125;&#125; &#123;&#123;- with .Values.favorite &#125;&#125; drink: &#123;&#123; .drink | default "tea" | quote &#125;&#125; food: &#123;&#123; .food | upper | quote &#125;&#125; release: &#123;&#123; $relname &#125;&#125; &#123;&#123;- end &#125;&#125; 在with块之前，我们赋值了一个变量。在with块内，$relname变量仍然指向版本名称。 在range循环中使用变量： 1234toppings: |- &#123;&#123;- range $index, $topping := .Values.pizzaToppings &#125;&#125; &#123;&#123; $index &#125;&#125;: &#123;&#123; $topping &#125;&#125; &#123;&#123;- end &#125; 渲染效果： 12345toppings: |- 0: mushrooms 1: cheese 2: peppers 3: onions 有一个变量($)它永远是全局的，此变量将永远指向根上下文(root context)。放你使用range循环，并且需要知道chart的版本名称时，这非常有用。示例如下： 123456789101112131415161718192021&#123;&#123;- range .Values.tlsSecrets &#125;&#125;apiVersion: v1kind: Secretmetadata: name: &#123;&#123; .name &#125;&#125; labels: # Many helm templates would use `.` below, but that will not work, # however `$` will work here app.kubernetes.io/name: &#123;&#123; template "fullname" $ &#125;&#125; # I cannot reference .Chart.Name, but I can do $.Chart.Name helm.sh/chart: "&#123;&#123; $.Chart.Name &#125;&#125;-&#123;&#123; $.Chart.Version &#125;&#125;" app.kubernetes.io/instance: "&#123;&#123; $.Release.Name &#125;&#125;" # Value from appVersion in Chart.yaml app.kubernetes.io/version: "&#123;&#123; $.Chart.AppVersion &#125;&#125;" app.kubernetes.io/managed-by: "&#123;&#123; $.Release.Service &#125;&#125;"type: kubernetes.io/tlsdata: tls.crt: &#123;&#123; .certificate &#125;&#125; tls.key: &#123;&#123; .key &#125;&#125;---&#123;&#123;- end &#125;&#125; 到目前为止，我们已看到了只在一个文件中声明的模板。但是Helm模板语言的一个强大功能是声明多个模板和使用它们。我们将在后面的章节了解到。 命名模板Named Templates: https://helm.sh/docs/chart_template_guide/named_templates/ 是时候使用多个模板了。本章中，我们将在一个文件中命名模板，然后在其它地方使用它们。这让我想起了Python写Web是的模板。命名模板（有时称为子模板）是在文件中定义的一个简单的模板。有两种方法来创建它，有几种不同的方法来使用它。 在流程控制(flow control)章节，我们介绍了define, template, block这三个声明和管理模板的动作。在本章中，我们将讨论这三种动作，并引入一种特殊目的的include函数。 命名模板的一个重要细节：模板名称是全局的。如果声明了两个相同名称的模板，whichever one is loaded last will be the one used. 由于subcharts中的模板与顶级模板一起编译，你应该小心命名。 123# 一种流行的命名约定是使用chart名作为前缀：&#123;&#123; define &quot;mychart.labels&quot; &#125;&#125;# 通过使用特定的chart名称作为前缀，我们可以避免相同模板名称所带来的冲突 下划线文件Partials and _ files 目前为止，我们使用的一个文件中包含一个模板。但是Helm模板语言允许你创建命名嵌套模板，可通过名称在其它任何地方进行访问。 在我们开始编写这些模板之前，我们需要注意一下命名规范： templates/下的大多数文件被视为包含k8s manifests NOTES.txt是一个例外 以下划线(_)开头的文件被假定为不包含k8s manifests。这些文件不会被渲染为k8s对象定义，但可在任意chart templates中使用。 这些文件用来存储特定(partials)和助手(helpers)。实际上，当我们第一次创建mychart，我们会看到_helpers.tpl文件，此文件是默认的template partials。 声明和使用模板Declaring and using templates with define and template。 define动作允许我们在一个模板文件中创建命名模板(named template)。语法如下: 123&#123;&#123; define &quot;MY.NAME &quot;&#125;&#125; # body of template here&#123;&#123; end &#125;&#125; 栗子： 123456789101112131415&#123;&#123;- define "mychart.labels" &#125;&#125; labels: generator: helm data: &#123;&#123; now | htmlDate &#125;&#125;&#123;&#123;- end &#125;&#125;apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmap &#123;&#123;- template "mychart.labels" &#125;&#125; data: myvalue: "Hello World" &#123;&#123;- range $key, $va1 := .Values.favorite &#125;&#125; &#123;&#123; $key &#125;&#125;: &#123;&#123; $va1 | quote &#125;&#125; &#123;&#123;- end &#125;&#125; 渲染之后的效果： 123456789101112# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: running-panda-configmap labels: generator: helm date: 2016-11-02data: myvalue: "Hello World" drink: "coffee" food: "pizza" define仅定义，只有在模板中调用时才会产生输出。 按照惯例，Helm charts将这些模板放在partials文件中（通常是_helpers.tpl），如： 123456&#123;&#123;/* Generate basic labels */&#125;&#125;&#123;&#123;- define &quot;mychart.labels&quot; &#125;&#125; labels: generator: helm date: &#123;&#123; now | htmlDate &#125;&#125;&#123;&#123;- end &#125;&#125; 12# 按照管理，define函数 应该有一个简单的文档块 &#123;&#123;/*...*/&#125;&#125;# 如上。然后在其它模板文件中访问它。 设置模板范围Setting the scope of a template 在上面定义的模板中，我们没有使用任何对象。让我们做些修改： 12345678&#123;&#123;/* Generate basic labels */&#125;&#125;&#123;&#123;- define &quot;mychart.labels&quot; &#125;&#125; labels: generator: helm data: &#123;&#123; now | htmlData &#125;&#125; chart: &#123;&#123; .Chart.Name &#125;&#125; version: &#123;&#123; .Chart.Version &#125;&#125;&#123;&#123;- end &#125;&#125; 上面定义的名称和版本是动态的，会根据不同的模板生成不同的值。 之前的引用并没有床底范围，因此在模板内我们不能使用.来访问任何事物。现在我们对模板加上范围: 12345apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmap &#123;&#123;- template "mychart.labels" . &#125;&#125; 注意上面在模板调用处使用的点(.)。我们可以非常容易地传递.Values或.Values.favorite或任何我们需要的范围。但是，我们需要的是顶级范围。 现在运行渲染(helm install --dry-run --debug plinking-anaco ./mychart)来预览下： 12345678910# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: plinking-anaco-configmap labels: generator: helm date: 2016-11-02 chart: mychart version: 0.1.0 includeThe include function 假设我们定义了如下一个简单模板： 1234&#123;&#123;- define &quot;mychart.app&quot; -&#125;&#125;app_name: &#123;&#123; .Chart.Name &#125;&#125;app_version: &quot;&#123;&#123; .Chart.Version &#125;&#125;&quot;&#123;&#123;- end -&#125;&#125; 一个错误的栗子： 123456789101112apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmap labels: &#123;&#123; template "mychart.app" . &#125;&#125;data: myvalue: "Hello World" &#123;&#123;- range $key, $val := .Values.favorite &#125;&#125; &#123;&#123; $key &#125;&#125;: &#123;&#123; $val | quote &#125;&#125; &#123;&#123;- end &#125;&#125;&#123;&#123; template "mychart.app" . &#125;&#125; 渲染的结果并不正确： 1234567891011121314# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: measly-whippet-configmap labels: app_name: mychartapp_version: "0.1.0+1478129847"data: myvalue: "Hello World" drink: "coffee" food: "pizza" app_name: mychartapp_version: "0.1.0+1478129847" Because the template that is substituted in has the text aligned to the right. Because template is an action, and not a function, there is no way to pass the output of a template call to other functions; the data is simply inserted inline. To work around this case, Helm provides an alternative to template that will import the contents of a template into the present pipeline where it can be passed along to other functions in the pipeline. 因为模板是靠右对齐的文本，因为template是一个动作，不是一个函数，因此无法传递调用其它函数的template的输出，数据被简单的插入内联。 现在我们需要使用ident来告诉模板正确的缩进，栗子： 123456789101112apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmap labels:&#123;&#123; include "mychart.app" . | indent 4 &#125;&#125;data: myvalue: "Hello World" &#123;&#123;- range $key, $va1 := .Values.favorite &#125;&#125; &#123;&#123; $key &#125;&#125;: &#123;&#123; $val | quote &#125;&#125; &#123;&#123;- end &#125;&#125; &#123;&#123; include "mychart.app" . | indent 2 &#125;&#125; 正确的渲染结果： 1234567891011121314# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: edgy-mole-configmap labels: app_name: mychart app_version: "0.1.0+1478129987"data: myvalue: "Hello World" drink: "coffee" food: "pizza" app_name: mychart app_version: "0.1.0+1478129987" 在Helm template中使用include对template被认为更好，这使得输出格式可以为YAML文档更好地处理。 有时候，我们想要导入内容，但不作为模板。也就是逐字导入文件。我们可以通过.Files对象访问文件来实现这一目标。 在模板内访问文件Accessing Files Inside Templates: https://helm.sh/docs/chart_template_guide/accessing_files/ Helm提供了.Files对象来访问文件。在开始模板示例之前，有些事需要注意下： 可以添加额外的文件到Helm chart。这些文件将被捆绑。要注意，charts必须小于1MB，因为k8s对象的存储限制。 某些文件无法通过.Files对象访问，通常出于安全原因 templates/目录内的文件无法访问 .helmignore中包含的文件无法访问 Charts不保留UNIX mode信息，当设计到.Files对象时，文件级别的权限对一个文件的可用性没有影响。 示例Basic example 添加三个位于mychart/目录下的文件。 12345678# config1.tomlmessage = Hello from config 1# config1.tom2message = Hello from config 2# config1.tom3message = Goodbye from config 3 在模板中访问文件： 12345678910apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: &#123;&#123;- $files := .Files &#125;&#125; &#123;&#123;- range tuple "config1.tom1" "config2.toml" "config3.toml" &#125;&#125; &#123;&#123; .&#125;&#125;: |- &#123;&#123; $files.Get .&#125;&#125; &#123;&#123;- end &#125;&#125; 123# 首先，创建了一个 $files变量 来保存.Files对象的引用# 我们同样使用 tuple函数来创建循环的文件列表# 接着打印每个文件名 &#123;&#123; . &#125;&#125;: |- 后面接着文件内容 &#123;&#123; $files.Get . &#125;&#125; 渲染效果示例： 1234567891011121314# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: quieting-giraf-configmapdata: config1.toml: |- message = Hello from config 1 config2.toml: |- message = This is config 2 config3.toml: |- message = Goodbye from config 3 路径助手Path helpers 使用文件时，对文件路径执行一些标准的操作是有用的。为了帮助处理，Helm从go path包中引入了许多函数供你使用: Base Dir Ext IsAbs Clean Glob模式Glob patterns 随着你的chart包的增长，你会发现你有一个更大的需来组织你的文件，因此我们提供了Files.Glob(pattern string)方法，以帮助提取某些文件与glob patterns的所有灵活性。 .Glob返回一个Files类型，因此你可以在返回的对象上调用任意Files方法。 123456# 示例的目录结构foo/: foo.txt foo.yamlbar/: bar.go bar.conf baz.yaml 使用Globs的多种选项： 123456&#123;&#123; $currentScope := .&#125;&#125;&#123;&#123; range $path, $_ := .Files.Glob &quot;**.yaml&quot; &#125;&#125; &#123;&#123;- with $currentScope&#125;&#125; &#123;&#123; .Files.Get $path &#125;&#125; &#123;&#123;- end &#125;&#125;&#123;&#123; end &#125;&#125; 或者： 123&#123;&#123; range $path, $_ := .Files.Glob &quot;**.yaml&quot; &#125;&#125; &#123;&#123; $.Files.Get $path &#125;&#125;&#123;&#123; end &#125;&#125; ConfigMap和Secrets的实用功能ConfigMap and Secrets utility functions 将文件内容放置到K8s ConfigMap或Secrets中非常常见，然后在运行的时候挂载到容器。为了帮助实现此功能，我们在Files类型上提供了几种实用的方法： AsCoinfig AsSecrets 栗子： 1234567891011121314apiVersion: v1kind: ConfigMapmetadata: name: confdata:&#123;&#123; (.Files.Glob "foo/*").AsConfig | indent 2 &#125;&#125;---apiVersion: v1kind: Secretmetadata: name: very-secrettype: Opaquedata:&#123;&#123; (.Files.Glob "bar/*").AsSecrets | indent 2 &#125;&#125; 编码Encoding 你可以导入一个文件，并实用base64编码来确保成功传输： 12345678apiVersion: v1kind: Secretmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-secrettype: Opaquedata: token: |- &#123;&#123; .Files.Get "config1.toml" | b64enc &#125;&#125; 渲染后的效果： 123456789# Source: mychart/templates/secret.yamlapiVersion: v1kind: Secretmetadata: name: lucky-turkey-secrettype: Opaquedata: token: |- bWVzc2FnZSA9IEhlbGxvIGZyb20gY29uZmlnIDEK 行Lines 有时候需要在模板中访问一个文件中的每行内容。我们为此提供了Lines方法。 示例： 123data: some-file.txt: &#123;&#123; range .Files.Lines "foo/bar.txt" &#125;&#125; &#123;&#123; . &#125;&#125;&#123;&#123; end &#125;&#125; NOTES.txtCreating a NOTES.txt File: https://helm.sh/docs/chart_template_guide/notes_files/ 在helm install或helm upgrade结束，Helm可以为用户打印一块有用的信息。此信息使用模板且高度可定制。 要为你的chart包添加安装说明，简单地创建一个templates/NOTES.txt文件。此文件是纯文本文件，但它像作为模板一样处理，并可访问所有正常模板函数和对象。 NOTES.txt文件示例： 1234567Thank you for installing &#123;&#123; .Chart.Name &#125;&#125;Your release is named &#123;&#123; .Release.Name &#125;&#125;To learn more about the release, try: $ helm status &#123;&#123; .Release.Name &#125;&#125; $ helm get all &#123;&#123; .Release.Name &#125;&#125; 接下来运行： 123456789101112131415161718192021helm install rude-cardinal ./mychartRESOURCES:==&gt; v1/SecretNAME TYPE DATA AGErude-cardinal-secret Opaque 1 0s==&gt; v1/ConfigMapNAME DATA AGErude-cardinal-configmap 3 0sNOTES:Thank you for installing mychart.Your release is named rude-cardinal.To learn more about the release, try: $ helm status rude-cardinal $ helm get all rude-cardinal 强烈建议创建NOTES.txt文件，以帮助用户获得chart包的有用信息。 SubchartsSubcharts and Global Values: https://helm.sh/docs/chart_template_guide/subcharts_and_globals/ 之前我们只有一个chart，但charts可能会有依赖(dependencies)，称为subcharts。subcharts也有自己的值和模板。本章我们将会创建subchart，并看看我们可以从模板访问值的不同的方式。 subcharts的一些重要详情： 一个subchart被认为是独立的(stand-alone)，这意味着一个subchart不能明确依赖它的parent chart 出于此原因，subchart不能访问parent chart的值 parent chart可以覆盖subcharts的值 Helm有一个全局值(global values)的概念，这些全局值可被所有charts访问 创建一个subchartCreating a Subchart 12345cd mychart/chartshelm create mysubchartrm -rf mysubchart/templates/*.* 对subchart添加值和模板Adding Values and a Template to the Subchart 为subchart添加一个简单的值和模板： 12# values.yamldessert: cake 123456apiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-cfgmap2data: dessert: &#123;&#123; .Values.dessert &#125;&#125; 因为每个subchart都是独立的chart，我们可以测试mysubchart： 123456789101112131415helm install --generate-name --dry-run --debug mychart/charts/mysubchartSERVER: "localhost:44134"CHART PATH: /Users/mattbutcher/Code/Go/src/helm.sh/helm/_scratch/mychart/charts/mysubchartNAME: newbie-elkTARGET NAMESPACE: defaultCHART: mysubchart 0.1.0MANIFEST:---# Source: mysubchart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: newbie-elk-cfgmap2data: dessert: cake 从parent chart覆盖值现在，mychart是mysubchart的parent chart。因为mychart是parent chart，我们可以在mychart中指定配置，并将配置推送到mysubchart中。 123456789101112# mychart/values.yamlfavorite: drink: coffee food: pizzapizzaToppings: - mushrooms - cheese - peppers - onionsmysubchart: dessert: ice cream 我们在parent chart(mychart)的值文件里添加了mysubchart的值，mysubchart这部分值会发送到mysubchart包，这回覆盖mysubchart的值。 123456789helm install --dry-run --debug mychart# Source: mychart/charts/mysubchart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: unhinged-bee-cfgmap2data: dessert: ice cream 全局值Global Chart Values 有时候你需要将值提供给所有模板，这可以使用全局值(global chart values)。全局值可被任意chart或subchart通过相同的名称来访问。全局需要明确地声明。 值数据类型保留在称为Values.global的区域，此区域可以设置全局值。 12345678910111213141516# mychart/values.yamlfavorite: drink: coffee food: pizzapizzaToppings: - mushrooms - cheese - peppers - onionsmysubchart: dessert: ice creamglobal: salad: caesar 12345678# 任意chart和subchart都可以使用 &#123;&#123; .Values.global.salad &#125;&#125; 来访问这个值# mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-configmapdata: salad: &#123;&#123; .Values.global.salad &#125;&#125; 12345678# mysubchart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: &#123;&#123; .Release.Name &#125;&#125;-cfgmap2data: dessert: &#123;&#123; .Values.dessert &#125;&#125; salad: &#123;&#123; .Values.global.salad &#125;&#125; 渲染输出效果： 1234567891011121314151617# Source: mychart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: silly-snake-configmapdata: salad: caesar---# Source: mychart/charts/mysubchart/templates/configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: silly-snake-cfgmap2data: dessert: ice cream salad: caesar 共享模板Sharing Templates with Subcharts parent charts和subcharts可以共享模板。任意在chart中定义的block(块)都可以被其它charts所使用。 定义一个简单的模板栗子： 1&#123;&#123;- define "labels" &#125;&#125;from: mychart &#123;&#123; end &#125;&#125; 尽管chart开发者可以在include和template之间选择，但使用include的优点是它可以动态引用模板： 1&#123;&#123; include $mytemplate &#125;&#125; 上面间接引用$mytemplate。template函数，相反它只接受一个字符串。 避免使用块Avoid Using Blocks go模板语言提供了一个block关键字，来允许开发者提供一个覆盖的默认实现。在Helm chart中，块(block)并不是覆盖的最佳工具，因为如果提供了相同块的多个实现，选择的那个是不可预测的。 建议使用include来代替。 .helmignoreThe .helmignore file: https://helm.sh/docs/chart_template_guide/helm_ignore_file/ .helmignore也就类似于.gitignore, .dockerignore，指定不需要包含在chart包中的文件。 如果此文件存在，helm package命令将忽略.helmignore里面匹配到的文件打包到应用的包里。 一个.helmignore文件的栗子： 12345678910111213141516171819202122232425# comment# Match any file or path named .git.git# Match any text file*.txt# Match only directories named mydirmydir/# Match only text files in the top-level directory/*.txt# Match only the file foo.txt in the top-level directory/foo.txt# Match any file named ab.txt, ac.txt, or ad.txta[b-d].txt# Match any file under subdir matching temp**/temp**/*/temp*temp? 模板调试Debugging Templates: https://helm.sh/docs/chart_template_guide/debugging/ 有几个命令可帮助调试模板： helm lint: 验证chart最佳实践的工具 helm install --dry-run --debug或helm template --debug：渲染模板并返回k8s manifest文件 helm get manifest：查看安装了哪些模板 YAML技巧YAML Techniques: https://helm.sh/docs/chart_template_guide/yaml_techniques/ Helm命令Helm Commands: https://helm.sh/docs/helm/ 社区指南Community Guides: https://helm.sh/docs/community/ FAQFrequently Asked Questions: https://helm.sh/docs/faq/]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Helm</tag>
        <tag>K8s</tag>
        <tag>DevOps</tag>
        <tag>CNCF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go]]></title>
    <url>%2F2020%2F07%2F22%2FGo%2F</url>
    <content type="text"><![CDATA[参考: github: https://github.com/golang/go Docs: https://golang.org/doc/ awesome-go: https://github.com/avelino/awesome-go 版本: go v1.14 介绍Go编程语言是一个开源项目，使开发人员更高效。 Go是传神，简洁，干净，高效的。它的并发机制(concurrency mechanisms)可充分利用多核和网络机器编写程序，它的新颖类型系统允许灵活和模块化结构。它是一个快速、静态类型、编译型语言，像一个动态类型、解释型语言。 安装下载对应平台的二进制包，解压，添加路径。 测试安装: 1234567package mainimport "fmt"func main() &#123; fmt.Printf("hello, world\n")&#125; 1234# 编译go build hello.go# 执行./hello 安装其它版本: 123go get golang.org/dl/go1.10.7go1.10.7 version 学习 旅程Tour: https://tour.go-zh.org/list 交互式地分三部分介绍Go： 基本语法和数据结构 方法和接口 并发原语(concurrency primitives) 可在线上或本地开启旅程： 线上: https://tour.golang.org/welcome/1 本地: go get golang.org/x/tour，会在go path的bin/tour。 sandbox.go测试程序显示时间： 1234567891011package mainimport ( "fmt" "time")func main() &#123; fmt.Println("Welcomt to the playground!") fmt.Println("The time is", time.Now())&#125; 基础语法学习go程序的基本结构。 包每个go程序都是由包构成。程序从main包开始运行。 按照约定，包名与导入路径的最后一个元素一致。例如，math/rand包中的源码均以package rand语句开始。 123456789101112// package.gopackage main// 导入两个包import ( "fmt" "math/rand")func main() &#123; fmt.Println("My favorite number is", rand.Intn(10))&#125; 导入使用圆括号进行分组导入，也可以编写多个导入语句。分组导入语句是更好的形式。 12345678910// 分组导入import ( "fmt" "math")// 单独导入import "fmt"import "math" 导出名在Go中，如果一个名字以大写字母，那么它就是已导出的。 在导入一个包时，你只能引用其中已导出的名字。任何未导出的名字在该包外均无法访问。 12345678910111213// exporter-nams.gopackage mainimport ( "fmt" "math")func main() &#123; fmt.Println(math.pi) //fmt.Println(math.Pi)&#125; 123456运行math.pi会报错./prog.go:9:14: cannot refer to unexported name math.pi./prog.go:9:14: undefined: math.pi运行math.Pi3.141592653589793 函数函数可以没有参数或接受多个参数。注意类型在变量名之后。 1234567891011121314// functions.gopackage mainimport "fmt"func add(x int, y int) int &#123; return x + y&#125;// 省略模式: x, y intfunc main() &#123; fmt.Println(add(42, 13))&#125; 多值返回函数可以返回任意数量的返回值。 123456789101112// multiple-results.goimport "fmt"func swap(x, y string) (string, string) &#123; return y, x&#125;func main() &#123; a, b := swap("hello", "world") fmt.Println(a, b)&#125; 命名返回值go的返回值可被命名，它们会被视作定义在函数顶部的变量。返回值的名称应当具有一定的意义。 没有参数的return语句返回已命名的返回值，也就是直接返回。直接返回语句应当仅在短函数中，在长函数中会影响代码的可读性。 123456789101112131415// name-result.gopackage mainimport "fmt"func split(sum int) (x, y int) &#123; x = sum * 4 / 9 y = sum -x return&#125;func main() &#123; fmt.Println(split(17))&#125; 变量var语句用于声明一个变量列表。 123456789101112// variables.gopackage mainimport "fmt"var c, python, java boolfunc main() &#123; var i int fmt.Println(i, c, python, java)&#125; 变量初始化变量声明可以包含初始值。如果初始化值已存在，则可以省略类型，变量会从初始值中获得类型。 123456789101112// var-ini.gopackage mainimpoort "fmt"var i, j, int = 1, 2func main() &#123; var c, python, java = true, false, "no!" fmt.Println(i, j, c, python, java)&#125; 短变量声明在函数中，简洁赋值语句:=可在类型明确的地方代替var声明。 函数外的每个语句都必须以关键字(var, func…)开始，因此:=结构不能在函数外使用。 12345678910111213// short-var-declarations.gopackage main()import "fmt"func main() &#123; var i, j int = 1, 2 k := 3 c, python, java := true, false, "no!" fmt.Println(i, j, k, c, python, java)&#125; 数据类型go的基本类型有： bool string int, int8, int16, int32, int64 uint, uint8, uint16, uint32, uint64, uintptr byte(uint8的别名) rune(int32的别名，表示一个unicode码点) float32, float64 complex64, complex128 int, uint 和 uintptr 在 32 位系统上通常为 32 位宽，在 64 位系统上则为 64 位宽。 当你需要一个整数值时应使用 int 类型，除非你有特殊的理由使用固定大小或无符号的整数类型。 1234567891011121314151617181920// basic-types.gopackage mainimport ( "fmt" "math/cmplx")var ( ToBe bool = false MaxInt uint64 = 1&lt;&lt;64 - 1 x complex128 = cmplx.Sqrt(-5 ++ 12i))func main() &#123; fmt.Printf("Type: %T Value: %v\n", ToBe, ToBe) fmt.Printf("Type: %T Value: %v\n", MaxInt, MaxInt) fmt.Printf("Type: %T Value: %v", z, z)&#125; 零值没有明确初始值的变量声明会被赋予它们的零值。 零值是: 数值类型为 0 布尔类型为 false 字符串为空字符串 12345678910111213// zero.gopackage mainimport "fmt"func main() &#123; var i int var f float64 var b bool var s string fmt.Printf("%v %v %v %q\n", i, f, b, s)&#125; 类型转换T(v)将v转换为T类型。 123456789101112131415// type-conversions.gopackage mainimport ( "fmt" "math")func main() &#123; var x, y int = 3, 4 var f float64 = math.Sqrt(float64(x*x + y*y)) var z unit = unit(f) fmt.Println(x, y, z)&#125; 类型推导在声明一个变量而不指定其类型时，变量的类型由右值推导而出。 12345678910// type-inference.gopackage mainimport "fmt"func main() &#123; v := 42 // int fmt.Printf("v is of type %T\n", v)&#125; 常量常量的声明与变量类似，只不过使用const关键字。 常量可以是字符、字符串、布尔值、数值。 常量不能用:=语法声明。 12345678910111213141516// constants.gopackage mainimport "fmt"const Pi = 3.14func main() &#123; const World = "世界" fmt.Println("Hello", World) fmt.Println("Happy", Pi, "Day") const Truth = true fmt.Println("Go rules?" Truth)&#125; 数值常量数值常量是高精度的值。一个未指定类型的常量由上下文来决定其类型。 123456789101112131415161718192021// nemeric-constants.gopackage mainimport "fmt"const ( // 将1左移100位来创建一个非常大的数字，即这个数的二进制是1后面跟着100个0 Big = 1 &lt;&lt; 100 // 再往右移99位，即Small = 1 &lt;&lt; 1，或Small = 2 Small = Big &gt;&gt; 99)func needInt(x int) int &#123; return x*10 + 1&#125;func needFloat(x float64) float64 &#123;return x * 0.1&#125;func main() &#123; fmt.Println(needInt(Small)) fmt.Println(needFloat(Small)) fmt.Println(needFloat(Big))&#125; 流程控制flowcontrol: https://tour.go-zh.org/flowcontrol 学习如何使用条件、循环、分支和推迟语句来控制代码的流程。 forgo只有一种循环结构: for循环。它由三部分组成： 初始化语句： 在第一次迭代前执行 条件表达式：在每次迭代前求值 后置语句： 在每次迭代的结尾执行 初始化语句和后置语句是可选的。 初始化语句通常为一句短变量声明，该变量声明仅在for语句的作用域中可见。一旦条件表达式的布尔值为false，循环迭代就会终止。 12345678910111213// for.gopackage mainimport "fmt"func main() &#123; sum := 0 for i := 0; i &lt; 10; i++ &#123; sum += i &#125; fmt.Println(sum)&#125; 12345678910111213// for-continued.gopackage mainimport "fmt"func main() &#123; sum := 1 for ; sum &lt; 1000; &#123; sum += sum &#125; fmt.Println(sum)&#125; for是whilego的for就是while。 12345678910111213// for-is-while.gopackage mainimport "fmt"func main() &#123; sum := 1 for sum &lt; 1000 &#123; sum += sum &#125; fmt.Println(sum)&#125; 无限循环如果省略循环条件，该循环就不会结束，因此无限循环可以写的很紧凑。 1234567// forever.gopackage mainfunc main() &#123; for &#123;&#125;&#125; if12345678910111213141516171819// if.gopackage mainimport ( "fmt" "math")func sqrt(x float64) string &#123; if x &lt; 0 &#123; return sqrt(-x) + "i" &#125; return fmt.Sprint(math.Sqrt(x))&#125;func main() &#123; fmt.Println(sqrt(2), sqrt(-4))&#125; 简短的ifif语句可在条件表达式前执行一个简单的语句。该语句声明的变量作用域仅在if之内。 12345678910111213141516171819202122// if-short.gopackage mainimport ( "fmt" "math")func pow(x, n, lim float64) float64 &#123; if v := math.Pow(x, n); v &lt; lim &#123; return v &#125; return lim&#125;func main() &#123; fmt.Println( pow(3, 2, 10), pow(3, 3, 20), )&#125; else123456789101112131415161718192021222324// else.gopackage mainimport ( "fmt" "math")func pow(x, n, lim float64) float64 &#123; if v := math.Pow(x, n); v &lt; lim &#123; return v &#125; else &#123; fmt.Printf("%g &gt;= %g\n", v, lim) &#125; return lim&#125;func main() &#123; fmt.Println( pow(3, 2, 10), pow(3, 3, 20), )&#125; switchswitch是一连串的if-else语句的简单写法。它运行第一个值等于条件表达式的case语句。 1234567891011121314151617181920// switch.gopackage mainimport ( "fmt" "runtime")func main() &#123; fmt.Print("Go runs on ") switch os := runtime.GOOS; os &#123; case "darwin": fmt.Println("OS X.") case "linux": fmt.Println("Linux.") default: fmt.Printf("%s. \n", os) &#125;&#125; switch的case语句从上到下依次执行，知道匹配成功时停止。 1234567891011121314151617181920212223// switch-order.gopackage mainimport ( "fmt" "time")func main() &#123; fmt.Println("When's Saturday?") today := time.NOw().Weekday() switch time.Saturday &#123; case today + 0: fmt.Println("Today.") case today + 1: fmt.Println("Tomorrow.") case today + 2: fmt.Println("In two days.") default: fmt.Println("Too far away.") &#125;&#125; 没有条件的switch同switch true一样。这种形式能将一长串if-then-else写得更加清晰。 1234567891011121314151617181920// switch-no-condition.gopackage mainimport ( "fmt" "time")func main() &#123; t := Now() switch &#123; case t.Hour() &lt; 12: fmt.Pringln("Good morning!") case t.Hour() &lt; 17: fmt.Println("Good afternoon.") default: fmt.Println("Good evening.") &#125;&#125; deferdefer语句会将函数推迟到外层函数返回之后执行。 推迟调用的函数其参数会立即求值，但直到外层函数返回前该函数都不会被调用。 1234567891011// defer.gopackage mainimport "fmt"func main() &#123; defer fmt.Println("world") fmt.Pringln("hello")&#125; 推迟的函数调用会被压入一个栈中。当外层函数返回时，被推迟的函数会按照后进先出的顺序调用。 12345678910111213// defer-multi.gopackage mainimport "fmt"func main() &#123; fmt.Pringln("counting") for i := 0; i &lt; 10; i++ &#123; defer fmt.Pringln(i) &#125; fmt.Println("done")&#125; 更多类型学习如何基于现有类型定义新的类型，包含结构体、数组、切片和映射。 指针go拥有指针。指针保存了值的内存地址。类型*T是指向T类型值的指针。其零值位nil。&amp;操作符会生成一个指向其操作数的指针。*操作符表示指针指向的底层值。这也就是常说的间接引用和重定向。 与C不同，go没有指针运算。 123456789101112131415161718// pointers.gopackage mainimport "fmt"func main() &#123; i, j := 42, 2701 p := &amp;i // 指向i fmt.Pringln(*p) // 通过指针读取i的值 *p = 21 // 通过指针设置i的值 fmt.Pringln(i) p = &amp;j *p = *p /37 fmt.Pringln(j)&#125; 结构体一个结构体(struct)就是一组字段(field)。 1234567891011121314// structs.gopackage mainimport "fmt"type Vertex struct &#123; X int Y int&#125;func main() &#123; fmt.Println(Vertex&#123;1, 2&#125;)&#125; 结构体字段使用点号来访问。 12345678910111213141516// struct-fields.gopackage mainimport "fmt"type Vertex struct &#123; X int Y int&#125;func main() &#123; v := Vertex&#123;1, 2&#125; v.X = 4 fmt.Println(v.X)&#125; 结构体字段可以通过结构体指针来访问。 如果有一个指向结构体的指针P，那么可通过(*p).X来访问其字段X。不过这样写太啰嗦，可隐式间接引用，直接写p.X。 1234567891011121314151617// struct-pointers.gopackage mainimport "fmt"type Vertex struct &#123; X int Y int&#125;func main() &#123; v := Vertex&#123;1, 2&#125; p := &amp;v // 指针 p.X = 1e9 fmt.Println(v)&#125; 结构体文法通过直接列出字段的值来新分配一个结构体。 1234567891011121314151617181920// struct-literals.gopackage mainimport "fmt"type Vertex struct &#123; X, Y int&#125;var ( v1 = Vertex&#123;1, 2&#125; // 创建一个Vertex类型的结构体 v2 = Vertex&#123;X: 1&#125; // Y:0被隐式地赋予 v3 = Vertex&#123;&#125; // X:0 Y:0 p = &amp;Vertex&#123;1, 2&#125; // 创建一个*Vertex类型的结构体(指针))func main() &#123; fmt.Println(v1, p, v2, v3)&#125; 数组类型[n]T表示拥有n个T类型的值的数组。 数组的长度是其类型的一部分，因此数组不能改变大小。 12345678910111213141516// array.gopackage mainimport "fmt"func main() &#123; var a [2]string a[0] = “Hello" a[1] = "World" fmt.Pringln(a[0], a[1]) fmt.Println(a) primes := [6]int&#123;2, 3, 5, 7, 11, 13&#125; fmt.Println(primes)&#125; 切片每个数组大小都是固定的，而切片则为数组元素提供动态大小的、灵活的视角。在实践中，切片比数组更常用。 类型[]T表示一个元素类型为T的切片。 123456789101112// slices.gopackage mainimport "fmt"func main() &#123; primes := [6]int&#123;2, 3, 5, 7, 11, 13&#125; var s []int = primes[1:4] fmt.Println(s)&#125; 切片并不存储任何数据，它只是描述了底层数组中的一段。更改切片的元素会修改其底层数组中对应的元素。与它共享底层数组的切片都会观测到这些修改。 123456789101112131415161718// slices-pointers.gopackage mainimport "fmt"func main() &#123; names := [4]string&#123;"John", "Paul", "George", "Ringo",&#125; fmt.Println(names) a := names[0:2] b := names[1:3] fmt.Pringln(a, b) b[0] = "XXX" fmt.Pringln(a, b) fmt.Pringln(names)&#125; 切片文法类似于没有长度的数组文法。 1234567891011121314151617181920212223242526// slice-literals.gopackage mainimport "fmt"func main() &#123; q := []int&#123;2, 3, 5, 7, 11, 13&#125; // 创建一个数组，并构建一个引用数组的切片 fmt.Pringln(q) r := []bool&#123;true, false, true, true, false, true&#125; fmt.Pringln(r) s := []struct &#123; i int b bool &#125; &#123; &#123;2, true&#125;, &#123;3, false&#125;, &#123;5, true&#125;, &#123;7, true&#125;, &#123;11, false&#125;, &#123;13, true&#125;, &#125; fmt.Pringln(s)&#125; 在进行切片时，你可以利用它的默认行为来忽略上下界。 切片拥有长度和容量。切片的长度就是它所包含的元素个数。切片的容量从第一个元素开始数，到元素末尾的个数。 可通过len()和cap()来获取。 1234567891011121314151617181920212223242526// slice-len-cap.gopackage mainimport "fmt"func main() &#123; s := []int&#123;2, 3, 5, 7, 11, 13&#125; printSlice(s) // 截取切片使其长度为0 s = s[:0] printSlice(s) // 扩展长度 s = s[:4] printSlice(s) // 舍弃前两个值 s = s[2:] printSlice(s)&#125;func printSlice(s []int) &#123; fmt.Printf("len=%d cap=%d %v\n", len(s), cap(s), s)&#125; 切片的零值nil。nil切片的长度和容量为0且没有底层数组。 12345678910111213// nil-slices.gopackage mainimport "fmt"func main() &#123; var s []int fmt.Println(s, len(s), cap(s)) if s == nil &#123; fmt.Pringln("nil!") &#125;&#125; 切片可以使用内建函数make来创建，这也是创建动态数组的方式。make函数会分配一个元素为零值的数组并返回一个引用了它的切片。 123456789101112131415161718192021222324// making-slices.gopackage mainimport "fmt"func main() &#123; a := make([]int, 5) PrintSlice("a", a) b := make([]int, 0, 5) printSlice("b", b) c := b[:2] printSlice("c", c) d := c[2:5] printSlice("d", d)&#125;func printSlice(s string, x []int) &#123; fmt.Printf("%s lend=%d cap=%d %v\n", s, len(x), cap(x), x)&#125; 切片可包含任何类型，甚至包括其他切片。 12345678910111213141516171819202122232425262728// slices-of-slices.gopackage mainimport ( "fmt" "STRINGS")func main() &#123; // 创建一个井字板 board := [][]string&#123; []string&#123;"_", "_", "_"&#125;, []string&#123;"_", "_", "_"&#125;, []string&#123;"_", "_", "_"&#125;, &#125; // 两个玩家轮流打上 x和o board[0][0] = "X" board[2][2] = "O" board[1][2] = "X" board[1][0] = "O" board[0][2] = "X" for i := 0; i &lt; len(board); i++ &#123; fmt.Printf("%s\n", strings.Join(board[i], " ")) &#125;&#125; 向切片追加新的元素是常用的操作，为此go提供了内建的append函数。 12345678910111213141516171819202122232425// append.gopackage mainimport "fmt"func main() &#123; var s []int printSlice(s) // 添加一个空切片 s = append(s, 0) printSlice(s) s = append(s, 1) printSlice(s) // 一次性添加多个元素 s = append(s, 2, 3, 4) printSlice(s)&#125;func printSlice(s []int) &#123; fmt.Printf("len=%d cap=%d %v\n", len(s), cap(s), s)&#125; rangefor循环的range形式可以遍历切片或映射。 1234567891011121314// range.gopackage mainimport "fmt"var pow = []int&#123;1, 2, 4, 8, 16, 32, 64, 128&#125;func main() &#123; // 下标，元素副本 for i, v := range pow &#123; fmt.Printf("2**%d = %d\n", i, v) &#125;&#125; 可将下标或值赋予下划线(_)来忽略它。 123456for i, _ := range powfor _, value := range pow# 若只要索引，忽略第二个变量即可for i := range pow 123456789101112131415// range-continued.gopackage mainimport "fmt"func main() &#123; pow := make([]int, 10) for i := range pow &#123; pow[i] = 1 &lt;&lt; uint(i) // == 2**i &#125; for _, value := range pow &#123; fmt.Printf("%s\n", value) &#125;&#125; 映射映射将键映射到值。映射的零值为nil。nil映射既没有键，也不能添加键。make函数会返回给定类型的映射，并将其初始化备用。 12345678910111213141516171819// maps.gopackage mainimport "fmt"type Vertex struct &#123; Lat, Long float64&#125;var m map[string]Vertexfunc main() &#123; m = make(map[string]Vertex) m["Bell Labs"] = Vertex&#123; 40.68433, -74.39967, &#125; fmt.Println(m["Bell Labs"])&#125; 映射的文法与结构体类似，不过必须有键名。 123456789101112131415161718// map-literals.gopackage mainimport "fmt"type Vertex struct &#123; Lat, Long float64&#125;var m = map[string]Vertex&#123; "Bell Labs": Vertex&#123;40.68433, -74.39967,&#125;, "Google": Vertex&#123;37.42202, -122.08408&#125;,&#125;func main() &#123; fmt.Println(m)&#125; 若顶级类型只有一个类型名，可以在文法的元素中省略它。 123456789101112131415161718// map-literals-continued.gopackage mainimport "fmt"type Vertex struct &#123; Lat, Long float64&#125;var m = map[string]Vertex&#123; "Bell Labs": &#123;40.68433, -74.39967&#125;, "Google": &#123;37.42202, -122.08408&#125;,&#125;func main() &#123; fmt.Println(m)&#125; 可对映射进行增删查改。 123456789101112# 插入或修改m[key] = elem# 获取elem = m[key]# 删除delete(m, key)# 通过双赋值检测某个键是否存在elem, ok = m[key]# 若 key 在 m 中，ok 为 true ；否则，ok 为 false。# 若 key 不在映射中，那么 elem 是该映射元素类型的零值。# 当从映射中读取某个不存在的键时，结果是映射的元素类型的零值。 123456789101112131415161718192021// mutating-maps.gopackage mainimport "fmt"func main() &#123; m := make(map[string]int) m["Answer"] = 42 fmt.Println("The value:", m["Answer"]) m["Answer"] = 48 fmt.Println("The value:", m["Answer"]) delete(m, "Answer") fmt.Println("The value:", m["Answer"]) v, ok := m["Answer"] fmt.Println("The value:", v, "Present?", ok)&#125; 函数值函数也是值。它们可以像其它值一样传递。 函数值可以用作函数的参数或返回值。 12345678910111213141516171819202122// function-values.gopackage mainimport ( "fmt" "math")func compute(fn func(float64, float64) float64) float64 &#123; return fn(3, 4)&#125;func main() &#123; hypot := func(x, y float64) float64 &#123; return math.Sqrt(x*x + y*y) &#125; fmt.Println(hypot(5, 12)) fmt.Println(compute(hypot)) fmt.Println(compute(math.Pow))&#125; 函数的闭包go函数可以是一个闭包。闭包是一个函数值，它引用了其函数体之外的变量。该函数可以访问并赋予其引用的变量的值，换句话说，该函数被这些变量绑定在一起。 例如，函数adder返回一个闭包。每个闭包都被绑定在其各自的sum变量上。 1234567891011121314151617181920212223// functtion-closures.gopackage mainimport "fmt"func adder() func(int) int &#123; sum := 0 return func(x int) int &#123; sum += x return sum &#125;&#125;func main() &#123; pos, neg := adder(), adder() for i := 0; i &lt; 10; i++ &#123; fmt.Println( pos(i), neg(-2*i), ) &#125;&#125; 斐波那契闭包 12345678910111213141516// fibonacci-closure.gopackage mainimport "fmt"// 返回一个int函数func fibonacci() func() int &#123;&#125;func main() &#123; f := fibonacci() for i := 0; i &lt; 10; i++ &#123; fmt.Println(f()) &#125;&#125; 方法和接口docs: https://tour.go-zh.org/methods/1 包含方法和接口，可以用这种构造来定义对象及其行为。 方法go没有类。 不过你可以为结构体类型定义方法。方法就是一类带特殊的接收者参数的函数。方法接收者在它自己的参数列表内，位于func关键字和方法名之间。 12345678910111213141516171819202122// methods.gopackage mainimport ( "fmt" "math")type Vertex struct &#123; X, Y float64&#125;// Abs方法拥有一个名为v，类型为Vertex的接收者func (v Vertex) Abs() float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;func main() &#123; v := Vertex&#123;3, 4&#125; fmt.Println(v.Abs())&#125; 方法只是个带接收者参数的函数。 123456789101112131415161718192021// metheods-funcs.gopackage mainimport ( "fmt" "math")type Vertex struct &#123; X, Y float&#125;func Abs(v Vertex) float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;func main() &#123; v := Vertex(3, 4) fmt.Println(Abs(v))&#125; 也可以为非结构体类型声明方法。接收者的类型定义和方法声明必须在同一包内，不能为内建类型声明方法。 12345678910111213141516171819202122// methods-continued.gopackage mainimport ( "fmt" "math")type MyFloat float64func (f MyFloat) Abs() float64 &#123; if f &lt; 0 &#123; return float64(-f) &#125; return float64(f)&#125;func main() &#123; f := MyFloat(-math.Sqrt2) fmt.Println(f.Abs())&#125; 指针接收者可以为指针接收者声明方法。 123456789101112131415161718192021222324252627// methods-pointers.gopackage mainimport ( "fmt" "math")type Vertex struct &#123; X, Y float64&#125;func (v, Vertex) Abs() float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;func (v *Vertex) Scale(f float64) &#123; v.X = v.X * f v.Y = v.Y * f&#125;func main() &#123; v := Vertex&#123;3, 4&#125; v.Scale(10) fmt.Println(v.Abs())&#125; 指针与函数123456789101112131415161718192021222324252627// methods-pointers-explained.gopackage mainimport ( "fmt" "math")type Vertex struct &#123; X, Y float64&#125;func Abs(v Vertex) float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;func Scale(v *Vertex, f float64) &#123; v.X = v.X * f x.Y = x.Y * f&#125;func main() &#123; v := Vertex&#123;3, 4&#125; Scale(&amp;v, 10) fmt.Println(Abs(v))&#125; 方法与指针重定向12345678910111213141516171819202122232425262728293031// indirection.gopackage mainimport "fmt"type Vertex struct &#123; X, Y float64&#125;func (v *Vertex) Scale(f float64) &#123; v.X = v.X * f x.Y = v.Y * f&#125;func ScaleFunc(v *Vertex, f float64) &#123; v.X = V.X * f v.Y = v.Y * f&#125;func main() &#123; v := Vertex&#123;3, 4&#125; v.Scale(2) ScaleFunc(&amp;v, 10) p := &amp;Vertex&#123;4, 3&#125; p.Scale(3) ScaleFunc(p, 8) fmt.Println(v, p)&#125; 123456789101112131415161718192021222324252627282930// indirection-values.gopackage mainimport ( "fmt" "math")type Vertex struct &#123; X, Y float64&#125;func (v Vertex) Abs() float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;func AbsFunc(v Vertex) float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;func main() &#123; v := Vertex&#123;3, 4&#125; fmt.Println(v.Abs()) fmt.Println(AbsFunc(v)) p := &amp;Vertex&#123;4, 3&#125; fmt.Println(p.Abs()) fmt.Println(AbsFunc(*p))&#125; 选择值或指针作为接收者使用指针接收者的原因有二： 方法能够修改其接收者指向的值 可以避免在每次调用方法时复制该值。若值的类型为大型结构体时，这样做会更加高效 12345678910111213141516171819202122232425262728// methods-pointer-receivers.gopackage mainimport ( "fmt" "math")type Vertex struct &#123; X, Y float64&#125;func (v *Vertex) Scale(f float64) &#123; v.X = v.X * f v.Y = v.Y * f&#125;func (v *Vertex) Abs() float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;func main() &#123; v := &amp;Vertex&#123;3, 4&#125; fmt.Printf("Before scaling: %+v, Abs: %v\n", v, v.Abs()) v.Scale(5) fmt.Printf("After scaling: %+v, Abs: %v\n", v, v.Abs())&#125; 接口接口类型是由一组方法签名定义的集合。接口类型的变量可以保存任何实现了这些方法的值。 类型通过实现一个接口的所有方法来实现该接口。既然无需专门显式声明，也就没有implements关键字。隐式接口从接口的实现中解耦了定义，这样接口的实现可以出现在任何包中，无需提前准备。因此，也就无需在每一个实现上增加新的接口名称，这样同时也鼓励了明确的接口定义。 1234567891011121314151617181920212223// interfaces-implicitly.gopackage mainimport "fmt"type I interface &#123; M()&#125;type T struct &#123; S string&#125;// 此方法表示类型T实现了接口I，但我们无需显式声明func (t T) M() &#123; fmt.Println(t.S)&#125;func main() &#123; var i I = T&#123;"Hello"&#125; i.M()&#125; 接口也是值。它们可以像其它值一样传递。接口值可以用作函数的参数或返回值。 在内部，接口值可以看做包含值和具体类型的元组：(value, type)。接口值保存了一个具体底层类型的具体值。接口值调用方法时会执行其底层类型的同名方法。 123456789101112131415161718192021222324252627282930313233343536373839404142// interface-values.gopackage mainimport ( "fmt" "math")type I interface &#123; M()&#125;type T struct &#123; S string&#125;func (t *T) M() &#123; fmt.Println(t.S)&#125;type F float64func (f F) M() &#123; fmt.Println(f)&#125;func main() &#123; var i I i = &amp;T["Hello"] describe(i) i.M() i = F(math.Pi) describe(i) i.M()&#125;func describe(i I) &#123; fmt.Printf("(%v, %T)\n", i, i)&#125; 底层值为nil的接口值。 即便接口内的具体值为nil， 方法仍然会被nil接收者调用。注意，保存了nil具体值的接口其自身并不为nil。 1234567891011121314151617181920212223242526272829303132333435363738// interface-values-nil.gopackage mainimport "fmt"type I interface &#123; M()&#125;type T struct &#123; S tring&#125;func (t *T) M() &#123; if t == nil &#123; fmt.Println("&lt;nil&gt;") return &#125; fmt.Println(t.S)&#125;func main() &#123; var i I var t *T i = t describe(i) i.M() i = &amp;T&#123;"hello"&#125; describe(i) i.M()&#125;func describe(i I) &#123; fmt.Printf("(%v, %T)\n", i, i)&#125; nil接口值nil接口值既不保存值也不保存具体类型。 12345678910111213141516171819// nil-interface-values.gopackage mainimport "fmt"type I interface &#123; M()&#125;func main() &#123; var i I describe(i) i.M()&#125;func describe(i I) &#123; fmt.Printf("(%v, %T)\n", i, i)&#125; 空接口指定了零个方法的接口值被称为空接口: interface{} 空接口可保存任何类型的值，因为每个类型都至少实现了零个方法。空接口被用来处理未知类型的值。 1234567891011121314151617181920// empty-interface.gopackage mainimport &quot;fmt&quot;func main() &#123; var i interface&#123;&#125; describe(i) i = 42 describe(i) i = &quot;hello&quot; describe(i)&#125;func describe(i interface&#123;&#125;) &#123; fmt.Printf(&quot;(%v, %T)\n&quot;, i, i)&#125; 类型断言类型断言提供了访问接口值底层具体值的方式。 1234567// 该语句断言接口值i保存了具体类型T，并将其底层类型为T的值赋予变量tt := i.(T)// 类型断言可返回两个值// 底层值以及一个报告断言是否成功的布尔值t, ok := i.(T) 123456789101112131415161718192021// type-assertions.gopackage mainimport "fmt"func main() &#123; var i interface&#123;&#125; = "hello" s := i.(string) fmt.Pringln(s) s, ok := i.(string) fmt.Println(s, ok) f, ok := i.(float64) fmt.Println(f, ok) f = i.(float64) // 报错(panic) fmt.Println(f)&#125; 类型选择类型选择是一种按顺序从几个类型断言中选择分支的结构。 12345678910111213141516171819202122// type-switches.gopackage mainimport "fmt"func do(i interface&#123;&#125;) &#123; switch v := i.(type) &#123; case int: fmt.Printf("Twice $v is %v\n", v, v*2) case string: fmt.Printf("%q is %v bytes long\n", v, len(v)) default: fmt.Printf("I don't how about type %T!\n", v) &#125;&#125;func main() &#123; do(21) do("hello") do(true)&#125; Stringerfmt包中定义的Stringer是最普遍的接口之一。 1234567891011121314151617181920// stringer.gopackage mainimport &quot;fmt&quot;type Person struct &#123; Name string Age int&#125;func (p Person) String() string &#123; return fmt.Sprintf(&quot;%v (%v years)&quot;, p.Name, p.Age)&#125;func main() &#123; a := Person&#123;&quot;Arthur Dent&quot;, 42&#125; z := Person&#123;&quot;Zaphod Beeb12brox&quot;, 9001&#125; fmt.Println(a, z)&#125; 错误go程序使用error值来表示错误状态，它是一个内建接口。 12345678910111213141516171819202122232425262728293031// errors.gopackage mainimport ( "fmt" "time")type MyError struct &#123; When time.Time What string&#125;func (e *MyError) Error() string &#123; return fmt.Sprintf("at %v, %s", e.When, e.What)&#125;func run() error &#123; return &amp;MyError&#123; time.Now(), "it didn't work", &#125;&#125;func main() &#123; if err := run(); err != nil &#123; fmt.Println(err) &#125;&#125; Readerio包指定了io.Reader接口，它表示从数据流的末尾进行读取。 1234567891011121314151617181920212223// reader.gopackage main()import ( "fmt" "io" "strings")func main() &#123; r := strings.NewReader("Hello, Reader!") b := make([]byte, 8) for &#123; n, err := r.Read(b) fmt.Printf("n = %v err = %v b = %v\n", n, err, b) fmt.Printf("b[:n] = %q\n", b[:n]) if err == io.EOF &#123; break &#125; &#125;&#125; 图像image包定义了Image接口。 1234567891011121314// images.gopackage mainimport ( "fmt" "image")func main() &#123; m := image.NewRGBA(image.Rect(0, 0, 100, 100)) fmt.Println(m.Bounds()) fmt.Println(m.At(0, 0).RGBA())&#125; 并发doc: https://tour.go-zh.org/concurrency/1 作为语言的核心部分，go提供了并发的特性。这一部分概览了goroutine和channel，以及如何使用它们来实现不同的并发模式。 goroutinego程(goroutine)是由go运行时管理的轻量级线程。 12345go f(x, y, z)# 会启动一个新的goroutine并执行f(x, y, z)# f, x, y, z的求值发生在goroutine中# 而f的执行发生在新的goroutine中 goroutine在相同的地址空间中运行，因此在访问共享的内存时必须进行同步。 1234567891011121314151617181920// goroutines.gopackage mainimport ( "fmt" "time")func say(s string) &#123; for i := 0; i &lt; 5; i++ &#123; time.Sleep(100 * time.Millisecond) fmt.Println(s) &#125;&#125;func main() &#123; go say("world") sqy("hello")&#125; 信道信道是带有类型的管道，通过它用信道操作符&lt;-来发送或接收值。 123456// 信道在使用前必须创建ch := make(chan int)// 箭头就是数据流的方向ch &lt;- v // 将v发送至信道chv := &lt;-ch // 从ch接收值并赋予v 123456789101112131415161718192021222324// channels.gopackage mainimport "fmt"func sum(s []int, c chan int) &#123; sum := 0 for _, v := range s &#123; sum += v &#125; c &lt;- sum // 将和送入c&#125;func main() &#123; s := []int&#123;7, 2, 8, -9, 4, 0&#125; c := make(chan int) go sum(s[:len(s)/2], c) go sum(s[len(s)/2:], c) x, y := &lt;-c, &lt;-c // 从c中接收 fmt.Println(x, y, x+y)&#125; 带缓冲的信道将缓冲长度作为第二个参数提供给make来初始化一个带缓冲的信道，仅当信道的缓冲区填满后，向其发送数据时才会阻塞。当缓冲区为空时，接受方会阻塞。 1234567891011121314// buffered-channels.gopackage mainimport "fmt"func main() &#123; ch := make(chan int, 2) ch &lt;- 1 ch &lt;- 2 // ch &lt;- 3 填满缓冲区 fmt.Println(&lt;-ch) fmt.Println(&lt;-ch)&#125; close发送者可通过close关闭一个信道来表示没有需要发送的值。接收者可以通过为接收表达式分配第二个参数来测试信道是否被关闭。 只有发送者才能关闭信道，而接收者不能。向一个已经关闭的信道发送数据会引发程序恐慌(panic)。信道与文件不同，通常情况下不需要关闭它们。只有在必须告诉接收者不再有需要发送的值时才有必要关闭，例如终止一个range循环。 1234// 若没有值可接收且信道已关闭，在执行完后,ok会被设置为falsev, ok := &lt;-ch// 循环for i := range c会不断从信道接收值，直到它关闭 123456789101112131415161718192021222324// range-and-close.gopackage mainimport ( "fmt")func fibonacci(n int, c chan int) &#123; x, y := 0, 1 for i := 0; i &lt; n; i++ &#123; c &lt;- x x, y = y, x+y &#125; close(c)&#125;func main() &#123; c := make(chan int, 10) go fibonacci(cap(c), c) for i := range c &#123; fmt.Println(i) &#125;&#125; selectselect语句使一个go routine可以等待多个通信操作。它会阻塞到某个分支可以继续执行为止，这时就会执行该分支。当多个分支都准备好时会随机选择一个执行。 123456789101112131415161718192021222324252627282930// select.gopackage mainimport "fmt"func fibonacci(c, quit chan int) &#123; x, y := 0, 1 for &#123; select &#123; case c &lt;- x: x, y = y, x+y case &lt;-quit: fmt.Println("quit") return &#125; &#125;&#125;func main() &#123; c := make(chan int) quit := make(chan int) go func() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Println(&lt;-c) &#125; quit &lt;- 0 &#125;() fibonacci(c, quit)&#125; 当select中的其它分支都没有转杯好时，default分支就会执行。 12345678910111213141516171819202122232425// default-selection.gopackage mainimport ( "fmt" "time")func main() &#123; tick := time.Tick(100 * time.Millisecond) boom := time.After(500 * time.Millisecond) for &#123; select &#123; case &lt;-tick: fmt.Println("tick.") case &lt;-boom: fmt.Println("BOOM!") return default: fmt.Println(" .") time.Sleep(50 * time.Millisecond) &#125; &#125;&#125; 互斥锁信道非常适合在各个Go routine间进行通信。但如果并不需要通信，只想保证每次只有一个go routine能够访问一个共享的变量，从而避免冲突。 这里面涉及的概念就做互斥(mutual exclusion)，通常使用互斥锁(Mutex)这一数据结构来提供这种机制。go标准库提供了sync.Mutex互斥锁及其两个方法: Lock, Unlock。 1234567891011121314151617181920212223242526272829303132333435363738394041// mutex-counter.gopackage mainimport ( "fmt" "sync" "time")// SafeCounter 的并发使用是安全的type SafeCounter struct &#123; v map[string]int mux sync.Mutex&#125;// Inc 增加给定 key 的计数器的值func (c *SafeCounter) Inc(key string) &#123; c.mux.Lock() // Lock 之后同一时刻只有一个 go routine 能访问c.v c.v[key]++ c.mux.Unlocak&#125;// Value 返回给定key的计数器的当前值func (c *SafeCounter) Value(key string) int &#123; c.mux.Lock() // Lock之后同一时刻只有一个 go routine 能访问c.v defer c.mux.Unlock() return c.v[key]&#125;func main() &#123; c := SafeCounter&#123;v: make(map[string]int)&#125; for i := 0; i &lt; 1000; i++ &#123; go c.Inc("somekey") &#125; time.Sleep(time.Second) fmt.Println(c.Value("somekey"))&#125; 如何编写go代码doc: https://golang.org/doc/code.html 介绍本文介绍如何开发一个模块内的一组简单的go包集合，并使用go工具，以标准的方式去fetch, build, install go modules, packages, commands。 注意:本文使用go v1.13+，并且没有设置GO111MODULE环境变量。 代码组织go程序被组织到包。包是编译在同一目录中的源文件的集合。定义在一个源文件中的函数、类型、变量、常量对同一个包中的其它源文件可见。 一个仓库(repo)包含一个或多个模块。模块是发布到一起关联go包的集合。一个go仓库通常只包含一个模块，位于该库的根目录。go.mod文件声明了模块路径，该模块内所有包的导入路径前缀。该模块包含了go.mod文件此目录及其子目录的包。 注意，在你可以构建之前，你并不需要将代码发布到远程仓库。一个模块可以定义在本地而不属于一个仓库。然而，如果你某天希望发布你的代码，那么组织你的代码是一个很好的习惯。 每个模块的路径不仅作为其包的导入路径前缀，也预示着go命令在哪里下载它。例如，要下载golang.org/x/tools模块，go命令会通过协商表示https://golang.org/x/tools。 导入路径是用来导入包的字符串。一个包的导入路径是它和模块内子目录的加入模块的路径。例如，模块github.com/google/go-cmp在cmp/目录下包含一个包，这个包的导入路径是github.com/google/go-cmp/cmp。标准库中的包没有模块路径前缀。 第一个程序要编译和运行一个简单的程序，首先要选择一个模块路径（如example.com/user/hello）并创建一个go.mod文件来声明它。 12345678910make hellocd hellogo mod init example.com/user/hellogo: creating new go.mod: module example.com/user/hellocat go.modmodule example.com/user/hellogo 1.14 go源文件的第一个语句必须是包名(package name)。可执行命令必须使用package main。 123456789// hello.gopackage mainimport "fmt"func main() &#123; fmt.Println("Hello, world.")&#125; 现在你可以使用go工具来构建和安装程序。 1go install example/user/hello 此命令构建hello命令，产生一个可执行二进制文件，安装此二进制到$HOME/go/bin/hello。 安装目录由GOPATH和GOBIN环境变量控制。如果GOBIN有设置，则安装到它这个目录。如果GOPATH有设置，二进制被安装到$GOPATH/bin/下。否则，二进制文件被安装到默认$GOPATH/bin目录下。 可以使用go env命令来设置和取消环境变量: 12345# 设置go env -w GOBIN=/somewhere/else/bin# 取消go env -u GOBIN 像go install这样的命令应用在包含当前工作目录的模块上下文内。如果当前工作目录不在example.com/user/hell模块内，则go install命令可能会失败。 为了方便，如果没有给定其它路径，go命令接收相对于当前工作目录的路径，默认为包的当前路径。因此，在当前工作目录下，下面的命令是等效的： 12345go install example.com/user/hellogo install .go install 接下来，让我们运行此程序以确保它工作。 123export PATH=$PATH:$(dirname $(go list -f &apos;&#123;&#123;.Target&#125;&#125;&apos; .))helloHello, world 如果你在使用版本控制，那现在是初始化仓库，添加文件并提交你的第一个变化的好时机。这一步是可选的，你不需要使用版本控制编写go代码。 1234go initgit add go.mod hello.gogit commit -m &quot;initial commit&quot; go命令通过请求HTTPS URL和从HTML响应中读取元数据来定位仓库包含的模块路径(go help importpath)。许多托管服务已经提供了包含go代码的元数据，使你的模块对其他人可用的最简单的方法通常是——使模块路径匹配仓库URL。 从你的模块导入包Importing packages from your module 让我们编写一个morestrings包，并从hello程序来使用它。首先，为包创建一个目录$HOME/hello/morestrings，并在目录下编写reverse.go源文件。 123456789101112// Package morestrings implements additional functions to manipulate UTF-8// encoded strings, beyond what is provided in the standard "strings" package.package morestrings// ReverseRunes returns its argument string reversed rune-wise left to right.func ReverseRunes(s string) string &#123; r := []rune(s) for i, j := 0, len(r)-1; i &lt; len(r)/2; i, j = i+1, j-1 &#123; r[i], r[j] = r[j], r[i] &#125; return string(r)&#125; 测试并使用go build来编译包： 123cd hello/morestringsgo build 这不会生成一个输出文件。相反，它在本地构建缓存(local build cache)中保存编译包(compiled package)。 在确认了morestrings包构建之后，让我们修改hello.go来使用morestrings包: 12345678910package mainimport ( "fmt" "example.com/usr/hello/morestrings")func main() &#123; fmt.Println(morestrings.ReverseRunes("!oG ,0lleH"))&#125; 12345// install hellogo install example.com/user/hellohelloHello, Go! 从远程模块导入包Importing packages from remote modules 导入路径可以描述如何使用版本控制获得源代码。go工具使用该属性从远程仓库自动获取包。比如，在程序中使用github.com/google/go-cmp/cmp： 123456789101112package mainimport ( "fmt" "example.com/user/hello/morestrings" "github.com/google/go-cmp/cmp")func main() &#123; fmt.Println(morestrings.ReverseRunes("!oG ,olleH")) fmt.Println(cmp.Diff("Hello World", "Hello Go"))&#125; 当你运行go install, go build, go run这些命令时，go命令会自动下载远程模块并在go.mod文件中记录版本。 1234567891011121314151617$ go install example.com/user/hellogo: finding module for package github.com/google/go-cmp/cmpgo: downloading github.com/google/go-cmp v0.4.0go: found github.com/google/go-cmp/cmp in github.com/google/go-cmp v0.4.0$ helloHello, Go! string(- &quot;Hello World&quot;,+ &quot;Hello Go&quot;, )$ cat go.modmodule example.com/user/hellogo 1.14require github.com/google/go-cmp v0.4.0$ 模块依赖关系自动下载到$GOPATH/pkg/mod目录。一个模块的特定版本的下载内容，要求该版本与所有其它模块之间共享，因此go命令标记目录和文件为只读。 12# 删除所有下载的模块go clean --modcache 测试go有一个轻量测试框架go test命令和testing包。 你可以通过创建一个以_test.go名称结尾的文件来编写一个测试，此测试文件包含以func (t *testing.T)签名的TestXXX函数。测试框架运行每个这样的函数，如果此函数调用一个失败的函数（如t.Error或t.Fail），则测试被认为失败。 通过创建包含以下代码的morestrings/reverse_test.go文件，对morestrings包添加一个测试。 12345678910111213141516171819package mainimport "test"func TestReverseRunes(t *testing.T) &#123; cases := []struct &#123; in, want string &#125;&#123; &#123;"Hello, world", "dlrow ,olleH"&#125;, &#123;"Hello, 世界", "界世 ,olleH"&#125;, &#123;"", ""&#125;, &#125; for _, c := range cases &#123; got := ReverseRunes(c.in) if got != c.want &#123; t.Errorf("ReverseRunes(%q) == %q, want %q, c.in, got, c.want") &#125; &#125;&#125; 接着使用go test运行测试: 1234567$ go testPASSok example.com/user/morestrings 0.165s$# 帮助go help test ide和插件doc: https://golang.org/doc/editors.html vim-go: https://github.com/fatih/vim-go Visual Studio Code: https://marketplace.visualstudio.com/items?itemName=golang.Go 我是用的k-vim已经添加了vim-go，只需要将let g:bundle_groups=中添加golang即可。 高效go编程Effective Go: https://golang.org/doc/effective_go.html 介绍Go是一门新语言。要把go写好，了解其性质和惯用语法是很重要的。同样重要的是要知道在go中程序所建立的约定。如命名、格式、项目建设等，让你写的程序会很容易为其他go程序员所理解。 此文档对编写清晰、惯用的go代码给出了一些技巧。 示例go package sources 不仅作为核心库，而且为如何使用语言做了示例。 格式化格式问题最具争议，但却始终没有形成统一的定论。若所有人都遵循相同的编码风格，在这类问题上浪费的时间将会更少。 在go中我们另辟蹊跷，让机器来处理大部分的格式问题。gofmt程序将go程序安装标准风格 进行缩进、对齐，保留注释并在需要时重新格式化。 举例来说，你无需花时间将结构体中的字段对其，gofmt将会为你代劳。 1234type T struct &#123; name string // 对象名 value int // 对象值&#125; gofmt会将它按列对齐： 1234type T struct &#123; name string // 对象名 value int // 对象值&#125; 标准包中的所有go代码都已经用gofmt格式化过了。一些关于格式化的细节： 缩进(Indentation)使用制表符tab，gofmt也默认使用它。在你认为有必要的时候使用空格符(space)。 行长度(Line length)go对行长度没有限制。如果一行实在太长，可以拆行并插入适当的tab缩进。 括号(Parentheses)比起C和Java，Go所需的括号更少。控制结构(if, for, switch)在语法上并不需要圆括号。此外，操作符优先级处理变得更加简洁： 1x&lt;&lt;8 + y&lt;&lt;16 注释go提供了C风格的块注释(/* */)和c++风格的行注释(//)。 godoc既是一个程序，又是一个Web服务器，它对go源码进行处理，并提取包中的文档内容。出现在顶级声明之前，且与该声明之间没有空行的注释，将与该声明一起被提取出来，作为该条目的说明文档。让我想起了Python的文档字符串(docstring)。 每个包都应包含一个包说明(package comment)——即放置在包子句前的一个块注释。对于包含多个文件的包，包注释只需出现在其中的任一文件中即可。包注释应在整体上对该包进行介绍，并提供包的相关信息。 1234567891011121314151617181920/*regexp 包为正则表达式实现了一个简单的库。它接受的正则表达式语法为： 正则： 串联 &#123; '|' 串联&#125; 串联： &#123; 闭包 &#125; 闭包： 条目 [ '*' | '+' | '?' ] 条目： '^' '$' '.' 字符 '[' [ '^' ] 字符遍历 ']' '(' 正则表达式 ')'*/package regexp 如果包比较简单，包说明可以简洁些： 12// Package path implements utility routines for// manipulating slash-separated filename paths. 注释无需额外的格式化。godoc会像gofmt一样处理好一切。注释是不会被解析的纯文本，因此特定的格式不会被渲染。godoc是否会重新格式化注释取决于上下文，因此必须确保它看起来清晰易辨：使用正确的拼写、标点、句子结构以及折叠长行等。 在包中，任何顶级声明前的注释都作为该声明的文档说明。每个可导出名称的程序(首字母大写)都有该用文档说明。这让我想起了Python的类。 文档注释最好是完整的句子，这样它才能适应各种自动化的展示。 第一句应当以被声明的东西开头，并且是单句的摘要。 123// Compile parses a regular expression and returns, if successful,// a Regexp that can be used to match against text.func Compile(str string) (*Regexp, error) &#123; 若注释总是以名称开头，godoc的输出就能通过grep变得更加有用。 1go doc -all regexp | grep -i parse go的声明语法允许成组声明。单个文档注释应介绍一组相关的常量或变量。 由于是整体声明，这种注释往往较为笼统。 1234567// Error codes returned by failures to parse an expression.var ( ErrInternal = errors.New("regexp: internal error") ErrUnmatchedLpar = errors.New("regexp: unmatched '('") ErrUnmatchedRpar = errors.New("regexp: unmatched ')'") ...) 即便是对于私有名称，也可通过成组声明来表明各项间的关系，例如某一组由互斥体保护的变量。 123456var ( countLock sync.Mutex inputCount uint32 outputCount uint32 errorCount uint32) 命名names 命名在编程语言中很重要！ 包名package names 当一个包被导入后，包名就会成为内容的访问器。 1import "bytes 包的名称应该简洁明了以便于理解。按照惯例，包应当以小写的单个单词来命名，且不应该使用下划线或驼峰记法(mixedCaps)。包名是就是导入时所需的默认名称，它并不需要在所有源码中保持唯一，即使在少数发生冲突的情况下，也可为导入的包选择一个别名来局部使用。无论如何，通过文件名来判定使用的包，基本不会产生混淆。 另一个约定就是包名应为其源码目录的基本名称。在src/encoding/base64中的包应作为encoding/base64导入，其包名为base64，而非encoding_base64或encodingBase64。 包的导入者可通过包名来引用其内容，因此包中的可导出名称可以此来避免冲突。请勿使用import .记法，它可以简化必须在被测试包外运行的测试， 除此之外应尽量避免使用。 另一个简短的例子是once.Do，once.Do(setup)表述足够清晰， 使用once.DoOrWaitUntilDone(setup)完全就是画蛇添足。 长命名并不会使其更具可读性。一份有用的说明文档通常比额外的长名更有价值。 获取器Getters Go并不对获取器（getter）和设置器（setter）提供自动支持。 你应当自己提供获取器和设置器，通常很值得这样做，但若要将 Get 放到获取器的名字中，既不符合习惯，也没有必要。 1234owner := obj.Owner()if owner != user &#123; obj.SetOwner(user)&#125; 接口名Interface names 按照约定，只包含一个方法的接口应当以该方法的名称加上-er后缀来命名，如Reader、Writer、 Formatter、CloseNotifier等。 驼峰记法MixedCaps 最后，go中约定使用MexedCaps或mixedCaps而不是下划线来编写多个词的名字。 分号Semicolons 和C一样，Go的正式语法使用分号(;)来结束语句。但和C不同的是，这些分号不会出现在源码中。取而代之，词法分析器会使用一条简单的规则来自动插入分号，因此大部分输入文本是自由的。 若在新行前的最后一个标记为一个标识符(包括int, float64)，数值或字符串常量的基本字面或以下标记之一: 1break continue fallthrough return ++ -- ) &#125; 词法分析器将始终在该标记后面插入一个分号。这可以概括为：如果新行前的标记为语句的末尾，则插入一个分号。 分号也可以在关闭括号之前直接省略，因此一个语句像如下这样，不需要分号。 1go func() &#123; for &#123; dst &lt;- &lt;-src &#125; &#125;() 通常go程序只在诸如for循环子句这样的地方使用分号。如果在一行中写多个语句，也需要使用分号分隔。 无论如何，你都不应该将控制结构(if, for, switch, select)的左括号放到下一行。你应该这样写： 123if i &lt; f() &#123; g()&#125; 而不是这样： 1234if i &lt; f() // wrong!&#123; // wrong! g()&#125; 控制结构Control structures go的控制结构与C有许多相似之处，但其不同才是独到之处。go不使用do或while循环，只有一个更通用的for；switch要更灵活些；if和switch像for一样接受一个可选的初始化语句；break和continue语句有一个可选的标签来确定那些break或continue；此外，还有一个包含类型选择和多路通信复用器的新控制结构——select。它们的语法也有些许不同，没有圆括号，主体必须始终使用大括号括住。 if123if x &gt; 0 &#123; return y&#125; 由于if和switch可接收初始化语句，因此用它们来设置局部变量很常见。 1234if err := file.Chmod(0644); err != nil &#123; log.Print(err) return err&#125; 重新声明和重新赋值Redeclaration and reassignment 123f, err := os.Open(name)d, err := f.Stat() 满足下列条件时，已被声明的变量可出现在:=声明中： 本次声明与已声明的变量出于同一作用域（若变量已在外层作用域中声明过，则此次声明会创建一个新的变量§） 在初始化中与其类型相应的值才能赋予变量，且在此次声明中至少另有一个变量是新声明的 forgo的for循环统一了for和while。它有三种形式，但只有一种需要分号。 12345678// Like a C forfor init; condition; post &#123; &#125;// Like a C whilefor condition &#123; &#125;// Like a C for(;;)for &#123; &#125; 简短的声明使得更容易在循环中声明下标变量： 1234sum := 0for i := 0; i &lt; 10; i++ &#123; sum += i&#125; 若你想遍历数组、切片、字符串、映射，或从信道中读取消息，range子句能够帮你轻松实现循环。 123for key, value := range oldMap &#123; newMap[key] = value&#125; 123456// 只需要遍历下标，去掉第二个for key := range m &#123; if key.expired() &#123; delete(m, key) &#125;&#125; 12345// 只需要值，使用空白标识符(_)来丢弃下标sum := 0for _, value := range array &#123; sum += value&#125; switchgo的switch比C更通用。其表达式无需为常量或整数，case语句会自上而下逐一进行求值直到匹配为止。如果switch后面没有表达式，它将匹配true。因此，我们可以将if-else-if-else链写成一个switch，这也更符合go的风格。 1234567891011func unhex(c byte) byte &#123; switch &#123; case '0' &lt;= c &amp;&amp; c &lt;= '9': return c - '0' case 'a' &lt;= c &amp;&amp; c &lt;= 'f': return c - 'a' + 10 case 'A' &lt;= c &amp;&amp; c &lt;= 'F': return c - 'A' + 10 &#125; return 0&#125; switch并不会自动下溯，但case可通过逗号分隔来列举相同的处理条件。 1234567func shouldEscape(c byte) bool &#123; switch c &#123; case ' ', '?', '&amp;', '=', '#', '+', '%': return true &#125; return false&#125; break语句可以使switch提前终止。不仅是switch，有时候也需要打破层层的循环。在go中，只需将标签(label)放置到循环外，然后break到标签。下例展示了两者的用法： 12345678910111213141516171819202122Loop: for n := 0; n &lt; len(src); n += size &#123; switch &#123; case src[n] &lt; sizeOne: if validateOnly &#123; break &#125; size = 1 update(src[n]) case src[n] &lt; sizeTwo: if n+1 &gt;= len(src) &#123; err = errShortInput break Loop &#125; if validateOnly &#123; break &#125; size = 2 update(src[n] + src[n+1]&lt;&lt;shift) &#125; &#125; 当然，continue语句也能接受一个可选的标签，不过它只能应用在循环中。 作为这一节的结束，下例使用两个switch语句对字节切片进行比较： 1234567891011121314151617181920// Compare returns an integer comparing the two byte slices,// lexicographically.// The result will be 0 if a == b, -1 if a &lt; b, and +1 if a &gt; bfunc Compare(a, b []byte) int &#123; for i := 0; i &lt; len(a) &amp;&amp; i &lt; len(b); i++ &#123; switch &#123; case a[i] &gt; b[i]: return 1 case a[i] &lt; b[i]: return -1 &#125; &#125; switch &#123; case len(a) &gt; len(b): return 1 case len(a) &lt; len(b): return -1 &#125; return 0&#125; 类型选择type switch switch也可用于判断接口变量的动态类型。如type switch通过括号中的关键字type使用类型断言。若switch在表达式中声明了一个变量，那么该变量的每个子句中都将有该变量对应的类型。 1234567891011121314var t interface&#123;&#125;t = functionOfSomeType()switch t := t.(type) &#123;default: fmt.Printf("unexpected type %T\n", t) // %T prints whatever type t hascase bool: fmt.Printf("boolean %t\n", t) // t has type boolcase int: fmt.Printf("integer %d\n", t) // t has type intcase *bool: fmt.Printf("pointer to boolean %t\n", *t) // t has type *boolcase *int: fmt.Printf("pointer to integer %d\n", *t) // t has type *int&#125; 函数function 多值返回multiple return values 以下简单的函数可从字节数组中的特定位置获取其值，并返回该数值和下一个位置。 123456789func nextInt(b []byte, i int) (int, int) &#123; for ; i &lt; len(b) &amp;&amp; !isDigit(b[i]); i++ &#123; &#125; x := 0 for ; i &lt; len(b) &amp;&amp; isDigit(b[i]); i++ &#123; x = x*10 + int(b[i]) - '0' &#125; return x, i&#125; 获取多值： 1234for i := 0; i &lt; len(b); &#123; x, i = nextInt(b, i) fmt.Println(x)&#125; 命名结果形参Named result parameters go函数的返回值(return)或结果(result)行参可被命名，并作为常规变量使用。就像传入的形参一样。命名后，一旦该函数开始执行，它们就会被初始化为与其类型相应的零值；若该函数执行了一条不带参数的return语句，则结果形参的当前值将作为返回值。 此名称不是强制性的，但它们能使代码更加简洁明了：它们就是文档。如果我们命名了nextInt的结果，那么它返回的int就值如其意了： 1func nextInt(b []byte, pos int) (value, nextPos int) &#123; 由于被命名的结果已经初始化，且已经关联至无参数的返回，它们就能让代码简单而清晰。 123456789func ReadFull(r Reader, buf []byte) (n int, err error) &#123; for len(buf) &gt; 0 &amp;&amp; err == nil &#123; var nr int nr, err = r.Read(buf) n += nr buf = buf[nr:] &#125; return&#125; Defergo的defer语句用于预设一个函数调用(即推迟执行函数(deferred function))，该函数会在执行defer的函数返回之前立即执行。它显得非比寻常， 但却是处理一些事情的有效方式，例如无论以何种路径返回，都必须释放资源的函数。 典型的例子就是解锁互斥和关闭文件。 12345678910111213141516171819202122// Contents returns the file's contents as a string.func Contents(filename string) (string, error) &#123; f, err := os.Open(filename) if err != nil &#123; return "", err &#125; defer f.Close() // f.Close will run when we're finished. var result []byte buf := make([]byte, 100) for &#123; n, err := f.Read(buf[0:]) result = append(result, buf[0:n]...) // append is discussed later. if err != nil &#123; if err == io.EOF &#123; break &#125; return "", err // f will be closed if we return here. &#125; &#125; return string(result), nil // f will be closed if we return here.&#125; 推迟如Close之类的函数调用有两个好处。第一， 它能确保你不会忘记关闭文件。如果你以后又为该函数添加了新的返回路径时，这种情况往往就会发生。第二，它意味着关闭离打开很近， 这总比将它放在函数结尾处要清晰明了。 推迟函数（如果函数是一个方法则还包括接收者）的实参在推迟执行时就会求值，而不是在调用执行时才求值。这样不仅无需担心变量值在函数执行时被改变， 同时还意味着单个已推迟的调用可推迟多个函数的执行。一个简单的例子： 123for i := 0; i &lt; 5; i++ &#123; defer fmt.Printf("%d ", i)&#125; 被推迟的函数会按照后见先出(LIFO)的顺序执行，因此上述返回为4 3 2 1 0。一个更具实际意义的例子，让程序跟踪函数的运行： 12345678910func trace(s string) &#123; fmt.Println("entering:", s) &#125;func untrace(s string) &#123; fmt.Println("leaving:", s) &#125;// Use them like this:func a() &#123; trace("a") defer untrace("a") // do something.... fmt.Println("---")&#125; 输出结果如下： 123entering: a---leaving: a 我们可以充分利用这个特点，即被推迟函数的实参在defer执行时才会求值。跟踪go程可针对反跟踪go程设置实参。 1234567891011121314151617181920212223func trace(s string) string &#123; fmt.Println("entering:", s) return s&#125;func un(s string) &#123; fmt.Println("leaving:", s)&#125;func a() &#123; defer un(trace("a")) fmt.Println("in a")&#125;func b() &#123; defer un(trace("b")) fmt.Println("in b") a()&#125;func main() &#123; b()&#125; 输出如下： 123456entering: bin bentering: ain aleaving: aleaving: b 数据Data newgo有两种分配原语，即内建函数new和make。new用来分配内存，但与其它同名函数不同，它不会初始化内存，只会将内存置零(zero)。new(T)会为类型T的新项分配已置零的内存控制，并返回它的地址，也即是类型*T的值。用go的术语，它返回一个指针，该指针指向新分配的类型为T的零值。 既然new返回的内存已置零，那么当你设计数据结构时，每种类型的零值就不必进一步初始化，这意味着该数据结构的使用者只需用new创建一个新的对象就能正常工作。 零值属性有各种好处，考虑以下声明： 1234type SyncedBuffer struct &#123; lock sync.Mutex buffer bytes.Buffer&#125; SyncedBuffer类型的值也是在声明时就分配好内存就绪了。后续代码中， p和v无需进一步处理即可正确工作。 12p := new(SyncedBuffer) // type *SyncedBuffervar v SyncedBuffer // type SyncedBuffer 构造函数与复合字面Constructors and composite literals 有时零值还不够好，这时就需要一个初始化构造函数。 1234567891011func NewFile(fd int, name string) *File &#123; if fd &lt; 0 &#123; return nil &#125; f := new(File) f.fd = fd f.name = name f.dirinfo = nil f.nepipe = 0 return f&#125; 这里显得代码过于冗长。我们可通过复合字面来简化它， 该表达式在每次求值时都会创建新的实例。 1234567func NewFile(fd int, name string) *File &#123; if fd &lt; 0 &#123; return nil &#125; f := File&#123;fd, name, nil, 0&#125; return &amp;f&#125; 请注意，返回一个局部变量的地址完全没有问题，这点与C不同。该局部变量对应的数据 在函数返回后依然有效。实际上，每当获取一个复合字面的地址时，都将为一个新的实例分配内存， 因此我们可以将上面的最后两行代码合并： 1return &amp;File&#123;fd, name, nil, 0&#125; 复合字面的字段必须按顺序全部列出。但如果以k:v对的形式明确地标出元素，初始化字段时就可以按任何顺序出现，未给出的字段值将赋予零值。 因此，我们可以用如下形式： 1return &amp;File&#123;fd: fd, name: name&#125; make再回到内存分配上来。不同于new，make只用于创建切片、映射和信道，并返回类型为T的一个已初始化的值。出现这种差异的原因在于，这三种类型本质上为引用数据类型，它们在使用前必须初始化。对于切片、映射和信道，make用于初始化其内部的数据结构并准备好将要使用的值。 123// ew([]int) 会返回一个指向新分配的，已置零的切片结构， 即一个指向 nil 切片值的指针// 会分配一个具有100个int的数组空间，接着创建一个长度为10， 容量为100并指向该数组中前10个元素的切片结构make([]int, 10, 100) new和make的区别： 123456789var p *[]int = new([]int) // allocates slice structure; *p == nil; rarely usefulvar v []int = make([]int, 100) // the slice v now refers to a new array of 100 ints// Unnecessarily complex:var p *[]int = new([]int)*p = make([]int, 100, 100)// Idiomatic:v := make([]int, 100) 请记住，make只适用于映射、切片和信道且不返回指针。若要获得明确的指针， 请使用new分配内存。 Arrays在详细规划内存布局时，数组非常有用，有时还能避免过多的内存分配，但它们主要用作切片的构件。 Go中数组： 数组是值。将一个数组赋予另一个数组会复制其所有元素。 若将某个数组传入某个函数，它将接收到该数组的一份副本而非指针。 数组的大小是其类型的一部分。类型[10]int和[20]int是不同的。 数组为值的属性很有用，但代价高昂。若你想要C那样的行为和效率，你可以传递一个指向该数组的指针。但这并不是Go的习惯用法，切片才是。 123456789func Sum(a *[3]float64) (sum float64) &#123; for _, v := range *a &#123; sum += v &#125; return&#125;array := [...]float64&#123;7.0, 8.5, 9.1&#125;x := Sum(&amp;array) // Note the explicit address-of operator Slices切片通过对数组进行封装，为数据序列提供了更通用、强大而方便的接口。 除了矩阵变换这类需要明确维度的情况外，Go中的大部分数组编程都是通过切片来完成的。 切片保存了对底层数组的引用，若你将某个切片赋予另一个切片，它们会引用同一个数组。只要切片不超出底层数组的限制，它的长度就是可变的。尽管append可修改切片的元素，但切片自身（其运行时数据结构包含指针、长度和容量）是通过值传递的。 二维切片Two-dimensional slices Go的数组和切片都是一维的。要创建等价的二维数组或切片，就必须定义一个数组的数组， 或切片的切片。像下面这样： 12type Transform [3][3]float64 // A 3x3 array, really an array of arrays.type LinesOfText [][]byte // A slice of byte slices. Maps映射是方便而强大的内建数据结构，它可以关联不同类型的值。其键可以是任何相等性操作符支持的类型， 如整数、浮点数、复数、字符串、指针、接口（只要其动态类型支持相等性判断）、结构以及数组。 切片不能用作映射键，因为它们的相等性还未定义。与切片一样，映射也是引用类型。 若将映射传入函数中，并更改了该映射的内容，则此修改对调用者同样可见。 1234567var timeZone = map[string]int&#123; "UTC": 0*60*60, "EST": -5*60*60, "CST": -6*60*60, "MST": -7*60*60, "PST": -8*60*60,&#125; 赋值和获取映射值的语法类似于数组，不同的是映射的索引不必为整数： 1offset := timeZone["EST"] 有时你需要区分某项是不存在还是其值为零值。可以使用多重赋值的形式来分辨这种情况。 123var seconds intvar ok boolseconds, ok = timeZone[tz] 若仅需判断映射中是否存在某项而不关心实际的值，可使用空白标识符(_)来代替该值的一般变量。 1_, present := timeZone[tz] 要删除映射中的某项，可使用内建函数 delete，它以映射及要被删除的键为实参。 即便对应的键不在该映射中，此操作也是安全的。 1delete(timeZone, "PDT") // Now on Standard Time PrintingGo采用的格式化打印风格和C的printf族类似，但却更加丰富而通用。这些函数位于fmt包中，且函数名首字母均为大写：如fmt.Printf、fmt.Fprintf，fmt.Sprintf等。 1234fmt.Printf("Hello %d\n", 23)fmt.Fprint(os.Stdout, "Hello ", 23, "\n")fmt.Println("Hello", 23)fmt.Println(fmt.Sprint("Hello ", 23)) append内建函数append像这个： 1func append(slice []T, elements ...T) []T 初始化Initialization 尽管从表面上看，Go的初始化过程与C或C++并不算太大，但它确实更为强大。 在初始化过程中，不仅可以构建复杂的结构，还能正确处理不同包对象间的初始化顺序。 常量Constants Go中的常量就是不变量。它们在编译时创建，即便它们可能是函数中定义的局部变量。 常量只能是数字、字符（符文）、字符串或布尔值。由于编译时的限制， 定义它们的表达式必须也是可被编译器求值的常量表达式。 变量变量的初始化与常量类似，但其初始值也可以是在运行时才被计算的一般表达式。 12345var ( home = os.Getenv("HOME") user = os.Getenv("USER") gopath = os.Getenv("GOPATH")) initThe init function 最后，每个源文件都可以通过定义自己的无参数init函数来设置一些必要的状态。而它的结束就意味着初始化结束： 只有该包中的所有变量声明都通过它们的初始化器求值后init才会被调用， 而那些init只有在所有已导入的包都被初始化后才会被求值。 除了那些不能被表示成声明的初始化外，init 函数还常被用在程序真正开始执行前，检验或校正程序的状态。 123456789101112131415Besides initializations that cannot be expressed as declarations, a common use of init functions is to verify or repair correctness of the program state before real execution begins.func init() &#123; if user == "" &#123; log.Fatal("$USER not set") &#125; if home == "" &#123; home = "/home/" + user &#125; if gopath == "" &#123; gopath = home + "/go" &#125; // gopath may be overridden by --gopath flag on command line. flag.StringVar(&amp;gopath, "gopath", gopath, "override default GOPATH")&#125; 方法Methods 指针与值Pointers vs. Values 以指针或值为接收者的区别在于：值方法可通过指针和值调用， 而指针方法只能通过指针来调用。 接口和其它类型 InterfacesGo中的接口为指定对象的行为提供了一种方法：如果某样东西可以完成这个， 那么它就可以用在这里。 每种类型都能实现多个接口。 类型转换Conversions 接口转换与类型断言Interface conversions and type assertions 类型选择是类型转换的一种形式：它接受一个接口，在选择中根据其判断选择对应的情况， 并在某种意义上将其转换为该种类型。 1234567891011type Stringer interface &#123; String() string&#125;var value interface&#123;&#125; // Value provided by caller.switch str := value.(type) &#123;case string: return strcase Stringer: return str.String()&#125; 类型断言接受一个接口值， 并从中提取指定的明确类型的值。 通用性Generality 若某种现有的类型仅实现了一个接口，且除此之外并无可导出的方法，则该类型本身就无需导出。 仅导出该接口能让我们更专注于其行为而非实现，其它属性不同的实现则能镜像该原始类型的行为。 这也能够避免为每个通用接口的实例重复编写文档。 在这种情况下，构造函数应当返回一个接口值而非实现的类型。 接口和方法Interfaces and methods 由于几乎任何类型都能添加方法，因此几乎任何类型都能满足一个接口。 1234// 一个很直观的例子就是 http 包中定义的 Handler 接口。任何实现了 Handler 的对象都能够处理HTTP请求type Handler interface &#123; ServeHTTP(ResponseWriter, *Request)&#125; 空白标识符The blank identifier 空白标识符(_)可被赋予或声明为任何类型的任何值，而其值会被无害地丢弃。它有点像Unix中的/dev/null文件：它表示只写的值，在需要变量但不需要实际值的地方用作占位符。 多重赋值中的空白标识符The blank identifier in multiple assignment for range循环中对空表标识符的用法是一种具体情况，更一般的情况即为多重赋值。 123if _, err := os.Stat(path); os.IsNotExist(err) &#123; fmt.Printf("%s does not exist\n", path)&#125; 未使用的导入和变量Unused imports and variables 若导入某个包或声明某个变量而不使用它就会产生错误。未使用的包会让程序膨胀并拖慢编译速度， 而已初始化但未使用的变量不仅会浪费计算能力，还有可能暗藏着更大的Bug。 要让编译器停止关于未使用导入的抱怨，需要空白标识符来引用已导入包中的符号。 1234567891011121314151617181920package mainimport ( "fmt" "io" "log" "os")var _ = fmt.Printf // For debugging; delete when done.var _ io.Reader // For debugging; delete when done.func main() &#123; fd, err := os.Open("test.go") if err != nil &#123; log.Fatal(err) &#125; // TODO: use fd. _ = fd&#125; 为副作用而导入Import for side effect 有时导入某个包只是为了其副作用， 而没有任何明确的使用。只为了其副作用来导入该包， 只需将包重命名为空白标识符： 1import _ "net/http/pprof" 这种导入格式能明确表示该包是为其副作用而导入的，因为没有其它使用该包的可能： 在此文件中，它没有名字。（若它有名字而我们没有使用，编译器就会拒绝该程序。） 接口检查Interface checks 一个类型无需显式地声明它实现了某个接口。取而代之，该类型只要实现了某个接口的方法， 其实就实现了该接口。在实践中，大部分接口转换都是静态的，因此会在编译时检测。 若只需要判断某个类型是否是实现了某个接口，而不需要实际使用接口本身 （可能是错误检查部分），就使用空白标识符来忽略类型断言的值： 123if _, ok := val.(json.Marshaler); ok &#123; fmt.Printf("value %v of type %T implements json.Marshaler\n", val, val)&#125; 在这种结构中出现空白标识符，即表示该声明的存在只是为了类型检查。 不过请不要为满足接口就将它用于任何类型。作为约定， 仅当代码中不存在静态类型转换时才能这种声明，毕竟这是种罕见的情况。 内嵌Embedding Go并不提供典型的，类型驱动的子类化概念，但通过将类型内嵌到结构体或接口中， 它就能借鉴部分实现。 并发Concurrency 通过通信共享内存Share by communicating 并发编程是个很大的话题。这里只讨论一些go特有的东西。 在并发编程中，为实现对共享变量的正确访问需要精确的控制，这在多数环境下都很困难。 Go语言另辟蹊径，它将共享的值通过信道传递，实际上，多个独立执行的线程从不会主动共享。 在任意给定的时间点，只有一个Go程能够访问该值。数据竞争从设计上就被杜绝了。 为了提倡这种思考方式，我们将它简化为一句口号： 不要通过共享内存来通信，而应通过通信来共享内存(Do not communicate by sharing memory; instead, share memory by communicating)。 这种方法意义深远。例如，引用计数通过为整数变量添加互斥锁来很好地实现。 但作为一种高级方法，通过信道来控制访问能够让你写出更简洁，正确的程序。 go程Goroutines 称它为GO程是因为现有的术语——线程(threads), 协程(coroutines), 进程(process)无法准确表达它的含义。Go程具有简单的模型：它是与其它Go程并发运行在同一地址空间的函数。它是轻量级的， 所有小号几乎就只有栈空间的分配。而且栈最开始是非常小的，所以它们很廉价， 仅在需要时才会随着堆空间的分配（和释放）而变化。 Go程在多线程操作系统上可实现多路复用，因此若一个线程阻塞，比如说等待I/O， 那么其它的线程就会运行。Go程的设计隐藏了线程创建和管理的诸多复杂性。 123// 在函数或方法前添加go关键字能够在新的Go程中调用它。当调用完成后， 该Go程也会安静地退出// 效果有点像Unix Shell中的 &amp; 符号，它能让命令在后台运行go list.Sort() // run list.Sort concurrently; don't wait for it. 函数字面在Go程调用中非常有用。 123456func Announce(message string, delay time.Duration) &#123; go func() &#123; time.Sleep(delay) fmt.Println(message) &#125;() // Note the parentheses - must call the function.&#125; 在Go中，函数字面都是闭包(closures)：其实现在保证了函数内引用变量的生命周期与函数的活动时间相同。这些函数没什么实用性，因为它们没有实现完成时的信号处理。因此，我们需要信道。 信道Channels 信道与映射一样，也需要通过make来分配内存，其结果充当了对底层数据结构的引用。若提供了一个可选的整数形参，它就会为该信道设置缓冲区大小。默认值是零，表示不带缓冲(unbuffered)的或同步(synchronous)的信道。 123ci := make(chan int) // unbuffered channel of integerscj := make(chan int, 0) // unbuffered channel of integerscs := make(chan *os.File, 100) // buffered channel of pointers to Files 无缓冲信道在通信时会同步交换数据，它能确保（goroutine）计算处于确定状态。 信道有很多惯用方法。 12345678c := make(chan int) // Allocate a channel.// Start the sort in a goroutine; when it completes, signal on the channel.go func() &#123; list.Sort() c &lt;- 1 // Send a signal; value does not matter.&#125;()doSomethingForAWhile()&lt;-c // Wait for sort to finish; discard sent value. 接收者在收到数据前会一直阻塞。若信道是不带缓冲的，那么在接收者收到值前， 发送者会一直阻塞；若信道是带缓冲的，则发送者仅在值被复制到缓冲区前阻塞； 若缓冲区已满，发送者会一直等待直到某个接收者取出一个值为止。 带缓冲的信道可被用作信号量，例如限制吞吐量。 回到编写服务器的一般问题上来。另一种管理资源的好方法就是启动固定数量的handleGo程，一起从请求信道中读取数据。Go程的数量限制了同时调用process的数量。Serve同样会接收一个通知退出的信道， 在启动所有Go程后，它将阻塞并暂停从信道中接收消息。 12345678910111213func handle(queue chan *Request) &#123; for r := range queue &#123; process(r) &#125;&#125;func Serve(clientRequests chan *Request, quit chan bool) &#123; // Start handlers for i := 0; i &lt; MaxOutstanding; i++ &#123; go handle(clientRequests) &#125; &lt;-quit // Wait to be told to exit.&#125; 信道中的信道Channels of channels Go最重要的特性就是信道是一等值，它可以被分配并像其它值到处传递。 这种特性通常被用来实现安全(safe)、并行(parallel)的多路分解(demultiplexing)。 并行化Parallelization 这些设计的另一个应用是在多CPU核心上实现并行计算。如果计算过程能够被分为几块 可独立执行的过程，它就可以在每块计算结束时向信道发送信号，从而实现并行处理。 12345678910111213const numCPU = 4 // number of CPU coresfunc (v Vector) DoAll(u Vector) &#123; c := make(chan int, numCPU) // Buffering optional but sensible. for i := 0; i &lt; numCPU; i++ &#123; go v.DoSome(i*len(v)/numCPU, (i+1)*len(v)/numCPU, u, c) &#125; // Drain the channel. for i := 0; i &lt; numCPU; i++ &#123; &lt;-c // wait for one task to complete &#125; // All done.&#125; 目前Go运行时的实现默认并不会并行执行代码，它只为用户层代码提供单一的处理核心。 任意数量的Go程都可能在系统调用中被阻塞，而在任意时刻默认只有一个会执行用户层代码。 它应当变得更智能，而且它将来肯定会变得更智能。但现在，若你希望CPU并行执行， 就必须告诉运行时你希望同时有多少Go程能执行代码。除了为CPU数量创建一个创建，还有两种方法： 12345// 1var numCPU = runtime.NumCPU()// 2var numCPU = runtime.GOMAXPROCS(0) 注意不要混淆并发(concurrency)和并行(parallelism)的概念。并发是用可独立执行的组件构造程序的方法， 而并行则是为了效率在多CPU上平行地进行计算。 尽管Go的并发特性能够让某些问题更易构造成并行计算， 但Go仍然是种并发而非并行的语言，且Go的模型并不适合所有的并行问题。 泄露的缓冲区A leaky buffer 并发编程的工具甚至能很容易地表达非并发的思想。 这里有个提取自RPC包的例子。 客户端Go程从某些来源，可能是网络中循环接收数据。为避免分配和释放缓冲区， 它保存了一个空闲链表，使用一个带缓冲信道表示。若信道为空，就会分配新的缓冲区。 一旦消息缓冲区就绪，它将通过serverChan被发送到服务器。 123456789101112131415161718var freeList = make(chan *Buffer, 100)var serverChan = make(chan *Buffer)func client() &#123; for &#123; var b *Buffer // Grab a buffer if available; allocate if not. select &#123; case b = &lt;-freeList: // Got one; nothing more to do. default: // None free, so allocate a new one. b = new(Buffer) &#125; load(b) // Read next message from the net. serverChan &lt;- b // Send to server. &#125;&#125; 服务器从客户端循环接收每个消息，处理它们，并将缓冲区返回给空闲列表。 12345678910111213func server() &#123; for &#123; b := &lt;-serverChan // Wait for work. process(b) // Reuse buffer if there's room. select &#123; case freeList &lt;- b: // Buffer on free list; nothing more to do. default: // Free list full, just carry on. &#125; &#125;&#125; 客户端试图从freeList中获取缓冲区；若没有缓冲区可用， 它就将分配一个新的。服务器将b放回空闲列表freeList中直到列表已满，此时缓冲区将被丢弃，并被垃圾回收器回收。依靠带缓冲的信道和垃圾回收器的记录， 我们仅用短短几行代码就构建了一个可能导致缓冲区槽位泄露的空闲列表。 错误error 库例程通常需要向调用者返回某种类型的错误提示。之前提到过，Go语言的多值返回特性， 使得它在返回常规的值时，还能轻松地返回详细的错误描述。 按照约定，错误的类型通常为error，这是一个内建的简单接口。 123type error interface &#123; Error() string&#125; 库的编写者通过更丰富的底层模型可以轻松实现这个接口，这样不仅能看见错误， 还能提供一些上下文。 123456789101112131415// PathError records an error and the operation and// file path that caused it.type PathError struct &#123; Op string // "open", "unlink", etc. Path string // The associated file. Err error // Returned by the system call.&#125;func (e *PathError) Error() string &#123; return e.Op + " " + e.Path + ": " + e.Err.Error()&#125;// 生成的错误信息例子// open /etc/passwx: no such file or directory 错误字符串应尽可能地指明它们的来源，例如产生该错误的包名前缀。若调用者关心错误的完整细节，可使用类型选择或者类型断言来查看特定错误，并抽取其细节。 Panic向调用者报告错误的一般方式就是将error作为额外的值返回。但如果错误时不可恢复的呢？有时程序就是不能继续运行。为此，我们提供了内建的panic函数，它会产生一个运行时错误并终止程序。该函数接受一个任意类型的实参（一般为字符串），并在程序终止时打印。 它还能表明发生了意料之外的事情，比如从无限循环中退出了。 12345678910111213// A toy implementation of cube root using Newton's method.func CubeRoot(x float64) float64 &#123; z := x/3 // Arbitrary initial value for i := 0; i &lt; 1e6; i++ &#123; prevz := z z -= (z*z*z-x) / (3*z*z) if veryClose(z, prevz) &#123; return z &#125; &#125; // A million iterations has not converged; something is wrong. panic(fmt.Sprintf("CubeRoot(%g) did not converge", x))&#125; 实际的库函数应避免panic。若问题可以被屏蔽或解决， 最好就是让程序继续运行而不是终止整个程序。 Recover当panic被调用后，程序将立刻终止当前函数的执行，并开始回溯Go程的栈，运行任何被推迟的函数。 若回溯到达Go程栈的顶端，程序就会终止。不过我们可以用内建的recover函数来重新或来取回Go程的控制权限并使其恢复正常执行。 调用recover将停止回溯过程，并返回传入panic的实参。 由于在回溯时只有被推迟函数中的代码在运行，因此recover只能在被推迟的函数中才有效。 recover的一个应用就是在服务器中终止失败的Go程而无需杀死其它正在执行的Go程。 1234567891011121314func server(workChan &lt;-chan *Work) &#123; for work := range workChan &#123; go safelyDo(work) &#125;&#125;func safelyDo(work *Work) &#123; defer func() &#123; if err := recover(); err != nil &#123; log.Println("work failed:", err) &#125; &#125;() do(work)&#125; 在此例中，若do(work)触发了Panic，其结果就会被记录， 而该Go程会被干净利落地结束，不会干扰到其它Go程。我们无需在推迟的闭包中做任何事情， recover会处理好这一切。 通过恰当地使用恢复模式，do函数（及其调用的任何代码）可通过调用 panic 来避免更坏的结果。我们可以利用这种思想来简化复杂软件中的错误处理。 让我们看看regexp包的理想化版本，它会以局部的错误类型调用 panic 来报告解析错误。以下是一个error类型的 Error方法和一个Compile函数的定义： 123456789101112131415161718192021222324// Error is the type of a parse error; it satisfies the error interface.type Error stringfunc (e Error) Error() string &#123; return string(e)&#125;// error is a method of *Regexp that reports parsing errors by// panicking with an Error.func (regexp *Regexp) error(err string) &#123; panic(Error(err))&#125;// Compile returns a parsed representation of the regular expression.func Compile(str string) (regexp *Regexp, err error) &#123; regexp = new(Regexp) // doParse will panic if there is a parse error. defer func() &#123; if e := recover(); e != nil &#123; regexp = nil // Clear return value. err = e.(Error) // Will re-panic if not a parse error. &#125; &#125;() return regexp.doParse(str), nil&#125; 顺便一提，这种重新触发Panic的惯用法会在产生实际错误时改变Panic的值。 然而，不管是原始的还是新的错误都会在崩溃报告中显示，因此问题的根源仍然是可见的。 这种简单的重新触发Panic的模型已经够用了，毕竟他只是一次崩溃。 但若你只想显示原始的值，也可以多写一点代码来过滤掉不需要的问题，然后用原始值再次触发Panic。 A web server让我们以一个完整的Go程序作为结束吧，一个Web服务器。该程序其实只是个Web服务器的重用。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport ( "flag" "html/template" "log" "net/http")var addr = flag.String("addr", ":1718", "http service address") // Q=17, R=18var templ = template.Must(template.New("qr").Parse(templateStr))func main() &#123; flag.Parse() http.Handle("/", http.HandlerFunc(QR)) err := http.ListenAndServe(*addr, nil) if err != nil &#123; log.Fatal("ListenAndServe:", err) &#125;&#125;func QR(w http.ResponseWriter, req *http.Request) &#123; templ.Execute(w, req.FormValue("s"))&#125;const templateStr = `&lt;html&gt;&lt;head&gt;&lt;title&gt;QR Link Generator&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&#123;&#123;if .&#125;&#125;&lt;img src="http://chart.apis.google.com/chart?chs=300x300&amp;cht=qr&amp;choe=UTF-8&amp;chl=&#123;&#123;.&#125;&#125;" /&gt;&lt;br&gt;&#123;&#123;.&#125;&#125;&lt;br&gt;&lt;br&gt;&#123;&#123;end&#125;&#125;&lt;form action="/" name=f method="GET"&gt; &lt;input maxLength=1024 size=70 name=s value="" title="Text to QR Encode"&gt; &lt;input type=submit value="Show QR" name=qr&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;` Go语言强大到能让很多事情以短小精悍的方式解决。 调试Diagnostics: https://golang.org/doc/diagnostics.html 总结工具和方法来诊断Go程序 介绍Go生态提供了一套API和工具来诊断go程序的逻辑和性能问题。本章总结了可用的工具，帮助用户去选择正确的工具来解决问题。 调试方案可分为一下几组： Profiling： 分析工具分析go程序的复杂性和成本，如内存使用和调用函数的频率，以确定go程序的昂贵的部分； Tracing： 追踪是分析整个延迟和调用或用户请求的生命周期的一种方法； Debugging： 调试可以让我们暂停go程序，检查并执行。程序的状态和流程可通过调试进行验证； Runtime statistics and events： 收集和分析运行时状态和事件，提供go程序运行状态的高度概括。 分析Profiling 对于识别昂贵的或频繁调用的代码部分，分析很有用。go runtime通过pprof可视化工具以格式化形式提供了分析数据。可通过go test或net/http/pprof包来收集分析数据。用户需要在代码顶级路径使用pprof工具来收集分析路径。 由runtime/pprof包预分析： cpu: cpu porfile，报告程序花费的CPU时间。 heap： heap profile，报告内存分配样本，监控当前和历史的内存使用，并检查内存泄漏。 threadcreate： thread profile，报告程序的操作系统的线程创建部分。 goroutine： goroutine profile，报告当前所有goroutine的栈追踪(stack trace)。 block： block profile，报告goroutine在哪里等待同步原语(synchronization primitives)阻塞。此功能默认关闭，使用runtime.SetBlockProfileRate开启。 mutex： mutex profile，报告锁的争用情况。当你认为由于互斥锁争用，CPU没有得到充分利用时，使用此功能。此功能默认关闭，使用runtime.SetMutexProfileFraction启用。 追踪Tracing 追踪是一种来分析整个调用链的生命周期的延迟的方法。go提供了golang.org/x/net/trace包作为每个go节点的最小化追踪后端，并使用一个简单的面板来提供一个小型的仪器库。go还提供了一个可执行的追踪程序在内部追踪运行时事件。 追踪使我们能够： 在go程序内工具和分析应用延迟。 衡量一个长链调用的特定调用的开销。 计算使用率和性能优化。 go的生态提供了多种追踪库。 调试Debugging 调试是识别一个程序行为不端的过程。调试器让我们了解程序的执行流程和当前状态。有几种调试风格，本章节将仅聚焦于一个调试器附加到一个程序和核心转储(core dump)调试。 go用户大多使用以下调试器： (Delve)[https://github.com/go-delve/delve]： Delve是一个go lang调试器。它支持go runtime和内建类型。它正努力成为一个go程序的全功能可靠的调试器。 (GDB)[https://golang.org/doc/gdb]： go通过标准的go编译器和Gccgo提供了GDB支持。尽管GDB可以用来调试go程序，但这不理想，可能导致混乱。 运行时统计数据和事件Runtime statistics and events 运行时(runtime)提供了统计信息和内部事件的报告，为用户在运行时级别诊断性能和利用率的问题。 用户可以监控这些数据，以便于更好地了解go程序的总体运行状况和性能。一些常用的监控统计数据和状态： runtime.ReadMemStats： 报告与堆分配(heap allocation)和垃圾回收(garbage collection)相关的指标。内存统计数据对监控进程消耗了多少内存资源是有用的，进程是否能很好地利用内存，并捕捉到内存泄漏。 debug.ReadGCStats： 阅读关于垃圾回收的统计数据。查看多少资源都花在了垃圾回收阶段也是很有用的。它还报告垃圾回收暂停和暂停事件百分数的时间线。 debug.Stack： 返回当前的栈追踪。栈追踪对于查看有多少goroutine正在运行，它们在做什么，它们是否阻塞很有用。 debug.WriteHeapDump： 中止所有goroutine的执行，并允许转存(dump)堆(heap)到文件。一个堆转存是go程序在特定时间内存的快照。它包含所有分配的对象，以及goroutine, finalizers… runtime.NumGoroutine： 返回当前的goroutine数量。该值可以被监测、以了解是否有足够的goroutine被利用，或检测goroutine泄漏。 执行追踪Execution tracer go使用runtime execution tracer来捕获广泛的运行时事件。调度、系统调用、垃圾回收、堆大小和其它收集的事件。执行追踪器是一个检测延迟和使用率问题的工具。你可以检查CPU如何利用，网络或系统调用时，抢占对goroutine的原因。 追踪器对这些有用： 理解你的goroutine如何执行 理解一些核心(core)的运行时事件，如垃圾回收 确定不佳的并行执行 然而，它不是很大用于识别热点（如分析内存溢出或CPU使用的原因）。使用分析工具而不是先定位它们。 详细信息查看go tool trace，来收集和分析运行时追踪。 GODEBUG如果GODEBUG环境变量相应地设置，运行时也会发出事件和信息。 GODEBUG=gctrace=1： 在每个收集中打印垃圾回收器事件，汇总内存收集量和停顿的长度。 GODEBUG=schedtrace=X： 每个x毫秒打印调度事件。 GODEBUG环境变量可用于在标准库和运行时中禁用指令集扩展。 GODEBUG=cpu.all=off： 禁止使用所有可选的扩展指令集。 GODEBUG=cpu.extension=off： 禁止从指定的指令集扩展中使用指令。 FAQdocs: https://golang.org/doc/faq 有关go的常见问答。 Go wikidocs: https://github.com/golang/go/wiki 由GO社区维护的wiki。 参考References 包Package Documentation: https://golang.org/pkg/ Go标准库文档。 命令Command Documentation: https://golang.org/doc/cmd Go工具文档。 语言规范Language Specification: https://golang.org/ref/spec 官方Go语言规范。 内存模型The Go Memory Model: https://golang.org/ref/mem]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible]]></title>
    <url>%2F2019%2F12%2F26%2FAnsible%2F</url>
    <content type="text"><![CDATA[参考: Ansible docs: https://docs.ansible.com 环境: RHELx86_64 Ansible v2.9 介绍About Ansible: https://docs.ansible.com/ansible/latest/index.html Ansible是一个IT自动化工具。它可以配置系统，部署软件和编排更先进的IT任务。Ansible的主要目标是简单和易于使用。它也专注于安全性和可靠性。 Ansible以无代理(agent-less)方式管理机器。Ansible是分散的，它依赖于现有操作系统的平局来控制访问到远程主机。如果需要，Ansible可以很容易地使用Kerberos, LDAP等集中认证管理系统连接。 词汇表Glossary Action动作(action)是任务的一部分，用于指定要运行的模块和传递给该模块的参数。每个任务只能有一个动作，但也可能有其它参数。 Ad Hoc指使用/usr/bin/ansible运行Ansible执行一些快速命令，而不是编排语言，即/usr/bin/ansible-play-book。ad hoc命令的示例可能是重新启动基础结构中的50台计算机。你可以通过编写playbook来完成你可以做的任何事情，而playbook也可以将许多其它操作粘合在一起。 Async指配置为在后台运行而不是等待完成的任务。如果你的进程时间长度超过了SSH超时时间，那么以异步(async)模式启动该任务是有意义的。异步模式可以每隔很多秒轮询完成，或者可配置为’fire and forget’，在这种情况下，Ansible甚至不会再次检查任务，它将开始并继续进行未来的步骤。异步模式使用/usr/bin/ansible和/usr/bin/ansible-playbook。 Callback Plugin指一些用户编写的代码，可拦截Ansible的结构并对它们执行某些操作。GitHub中提供的一些示例执行自定义日志记录，发送电子邮件… Check Mode值运行带有--check选项的Ansible，它不会对远程系统进行任何更改，但仅输出在没有此标志的情况下运行时才有可能发生的更改。 Connection Plugin默认情况下，Ansible通过pluggable libraries与远程计算机通信。Ansible支持原生OpenSSH或称为paramiko的Python实现。如果您使用的是最新版本，则首选OpenSSH，并启用Kerberos和jump host等功能。还有其它连接类型，如accelerate模式，必须通过一种基于SSH的连接类型进行引导，但速度非常快，而本地模式则作用于本地系统。用户还可以编写自己的连接插件。 Conditionals条件是一个表达式，其计算结果为true或false，用于决定给定任务是否在给定计算机上执行。 Declarative实现使用最终状态描述的任务的方法，而不是实现该状态所需的步骤序列的描述。对于真实世界的栗子，任务的声明规范将是: “put me in California”。根据你当前的位置，前往加州的步骤顺序可能会有所不同，如果你已在加州，则根本不需要做任何事情。Ansible的资源是声明性的；它确定了实现最终状态所需的步骤。它还可让你知道是否需要采取任何步骤才能到达最终状态。 Diff Mode将--diff标志传递给Ansible，以显示支持它的模块。 ExecutorAnsible的核心软件组件，它是/usr/bin/ansible背后的力量——并且对应于剧本中每个任务的调用。 Facts事实是发现的有关远程节点的事情。通过在远程节点上执行内部设置模块来运行，Ansible会自动发现事实。 Filter Plugin这允许创建新的Jinja2过滤器，这只适用于知道Jinja2过滤器的人。 ForkAnsible并行地与远程节点通信，并且可通过传递--forks或编辑配置文件中的默认值来设置并行级别。 Gather Facts (Boolean)有时，当运行多重playbook时，如果不需要利用任何这些值，则希望有一些不打扰事实计算的playbook。 Globbing通配符是一种选择大量主机，或它们所在组的名称的方法 Group一组主机 Group Vars这是将提供给指定组的变量，尤其是复杂的数据结构，这样这些变量就不必嵌入到库存文件或playbook中。 Handlers处理程序就像Ansible playbook中的常规任务，但只有在任务包含notify指定并且还指示它已更改某些内容时才会运行。 Host主机是Ansible管理的远程机器。 Host SpecifierAnsible中的每个play都将一系列任务映射到一组系统。每个play中的hosts:指令通常称为主机说明符。它可以选择一个或多个系统，一个或多个组，甚至一个组中的一些主机，而不是另一个组中的主机。 Host Vars主机变量类似与组变量。 Idempotency如果执行一次的结果与在没有任何干预动作的情况下重复执行它的结果完全相同，则操作是幂等的。 Includesplaybook文件可以包括其它play list，任务列表可以外部化其它文件中的任务列表，类似于处理程序。 Inventory用于描述Ansible中的主机和组的文件。 Inventory Script一个程序，用于查找主机，主机的组关系以及外部资源的变量信息——无论是SQL数据库，CMDB方案，还是LDAP等。 Jinja2Jinja2是Ansible模板模块的首选语言。它是一种非常简单的Python模板语言，可读且易于编写。 JSONAnsible使用JSON从远程模块返回数据。这允许用任何语言编写。 Lazy Evaluation通常，Ansible会在最后一秒评估playbook内容中的任何变量。 LibraryAnsible的模块集合。 Limit Groups通过将--limit somegroup传递给Ansible或ansible-playbook可以限制主机的子集。 Local Action针对远程计算机的playbook中的本地活动指令意味着给定的步骤实际上将在本地计算机上发生，但是可以传入变量以引用该步骤中引用的远程主机名。 Local Connection通过在playbook中使用connection: local，或将-c local传递给/usr/bin/ansible，这表明我们正在管理本地主机而不是远程主机。 Lookup Plugin查找插件是一种从外部获取数据到Ansible的方法。 Loops通常，Ansible不是一种编程语言。它更喜欢声明性，尽管循环这样的各种结构允许对列表中的多个项重复特定任务。 Modules模块是Ansible发送到远程机器的工作单元。 Multi-TierIT系统不是一次管理一个系统的概念，而是通过明确定义的订单中多个系统和系统组之间的交互。 Notify任务注册更改事件并通知处理程序任务需要在play结束时运行另一个操作的行为。 Orchestration许多软件自动化系统使用这个词来表示不同的东西。Ansible使用它作为编排的指挥。 paramiko默认情况下，Ansible通过SSH管理机器。Ansible默认使用的库是一个名为paramiko的Python驱动库。 Playbooksplaybook是Ansible编排，配置，管理或部署系统的语言。它被称为剧本，部分原因在于它是一种运动类比，并且使用它们应该很有趣。 PlaysA playbook is a list of plays。剧本最小是由主机说明符选择的一组主机之间的映射，以及在这些主机上运行定义这些系统将执行的角色的任务。 Pull Mode默认情况下，Ansible以push模式运行，这使得它可以在与每个系统进行通信时进行非常精细的控制。当你希望在特定计划时间点检查节点时，可以使用pull模式。 Push Mode Register Variable在Ansible中运行任何任务的结果可以存储在变量中，以便在模板或条件语句中使用。 Resource ModelAnsible模块在资源方面起作用。 Roles角色是Ansible的组织单位。 Rolling Update一次解决组中的多个节点的行为，以避免一次更新所有节点并使系统脱机。 Sudo SSH (Native) TagsAnsible允许使用任意关键字标记剧本中的资源，然后仅运行与这些关键字对应的剧本部分。 Task任务将操作(模块及其参数)与名称和可选的其他关键字(如循环指令)组合在一起。 TemplatesAnsible可以轻松地将文件传输到远程系统，但通常需要在其它文件中替换变量。 TransportAnsible使用term:连接插件来定以可用传输的类型。 When一个可选的条件语句。 Vars (Variables)与事实相反，变量是值的名称(int, bool, string)或复杂的数据(dict, hash, lists)。它是声明的东西，而不是从远程系统获取的东西。 YAMLAnsible不想强迫人们编写程序代码来自动化基础设施，因此使用YAML来定义剧本配置语言和变量文件。 安装指南Installtion Guide: https://docs.ansible.com/ansible/latest/installation_guide/index.html 安装AnsibleInstalling Ansible: https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html Ansible是一个默认通过SSH协议管理机器的无代理(agentless)的自动化工具。一旦安装，Ansible不添加数据库，并且不需要启动守护进程。你只需要在一台机器上安装它，它可以从该中心点管理远程所有机器。 先决条件Prerequisite 在控制节点上安装Ansible，然后使用SSH(默认)与管理的节点通信。 控制节点的依赖Control node requirements 目前，Ansible可以从任何安装了Python2.7或Python3.5+的机器上运行。不支持Windows。 被管理节点的依赖 Managed node requirements 在被管理的节点上，你需要一种方法来通信（通常是SSH）。 选择版本Selecting an Ansible version to install 选择自己需要的Ansible版本进行安装，可选择一下几种方式： 使用操作系统包管理器进行安装 使用pip进行安装 使用源码进行安装 在RHEL上安装Installing Ansible on RHEL, CentOS, or Fedora 123yum search ansiblesudo yum install ansible 使用pip安装Installing Ansible with pip 使用Python的包管理工具pip来安装Ansible。 12345# env# python -m virtualenv ansible# source ansible/bin/activatepip install --user ansiblepip install --user paramiko Ansible command shell completionAnsible 2.9的命令行工具由称为argcomplete的依赖提供。 12345sudo yum install epel-releasesudo yum install python-argcomplete# pip# pip install argcomplete 配置argcomplete 有两种方式来配置Ansible的命令行工具argcomplete： 全局(Globally) 12# Global completion requires bash 4.2.sudo activate-global-python-argcomplete 每个命令(Per command) 1234567891011# If you do not have bash 4.2, you must register each script independently.# 可将这些写入.profile里eval $(register-python-argcomplete ansible)eval $(register-python-argcomplete ansible-config)eval $(register-python-argcomplete ansible-console)eval $(register-python-argcomplete ansible-doc)eval $(register-python-argcomplete ansible-galaxy)eval $(register-python-argcomplete ansible-inventory)eval $(register-python-argcomplete ansible-playbook)eval $(register-python-argcomplete ansible-pull)eval $(register-python-argcomplete ansible-vault) 配置AnsibleConfiguring Ansible: https://docs.ansible.com/ansible/latest/installation_guide/intro_configuration.html 配置文件Configuration file Ansible将按照一下顺序搜索配置文件： ANSIBLE_CONFIG环境变量 ansible.cfg当前目录 ~/.ansible.cfg /etc/ansible/ansible.cfg Ansible配置参考 Ansible移植指南Ansible Porting Guides: https://docs.ansible.com/ansible/latest/porting_guides/porting_guides.html 用户指南User Guide: https://docs.ansible.com/ansible/latest/user_guide/index.html 本指南介绍如何使用Ansible工作，包括CLI, invetory, playbooks。 QuickstartAnsible Quickstart Guide: https://docs.ansible.com/ansible/latest/user_guide/quickstart.html 概念Ansible concepts: https://docs.ansible.com/ansible/latest/user_guide/basic_concepts.html Controle node：按照Ansible的任意机器。Windows机器无法作为控制节点。可以有多个控制节点。 Managed nodes：使用Ansible管理的网络设备。通常称为主机，Ansible未安装在管理节点上。 Inventory：一组管理节点的列表。清单文件有时称为主机文件(hostfile)。 Modules：Ansible执行代码单元。Ansible模块列表 Tasks：Ansible中的动作单元。可使用ad-hoc命令执行单一任务一次。 Playbooks：任务的有序列表。可按照顺序反复执行这些任务。剧本可以包含变量和任务。它以YAML格式编写。 入门Getting Started: https://docs.ansible.com/ansible/latest/user_guide/intro_getting_started.html 一个基本的Ansible命令或playbooks： 从清单中选择机器来执行 连接到这些机器（通常是SSH） 复制一个或多个模块到远程机器，并执行 Ansible可以做很多事。一旦你理解了Ansible是如何工作的，你可以阅读有关的ad-hoc命令的详细信息，使用清单组织你的基础架构，并利用Ansible强大的playbooks。 从清单选择机器Ansible从你的清单中读取管理的机器的信息。虽然你可以通过IP地址和ad-hoc命令，你也需要清单来增加Ansible的灵活性和重复性。 123456# 创建一个基本的清单# 在此文件中添加远程系统vim /etc/ansible/hosts192.0.2.50aserver.example.orgbserver.example.org 也可以使用别名(aliases)，主机变量(host vars)，组变量(group vars)。 连接到远程节点Ansible与远程机器通过SSH协议进行通信。默认情况下，Ansible使用原生的OpenSSH连接到远程机器。 确认用户名可使用SSH进行连接。如有必要，将SSH公钥添加到系统的authorized_keys文件。 复制和执行模块一旦建立连接，Ansible传输你的命令或剧本需要的模块到远程机器。 123456# 运行第一个ansible命令ansible all -m ping# 运行一个节点上的命令ansible all -a &quot;/bin/echo hell&quot; 如何构建清单How to build your inventory: https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html Ansible对多个被管理的节点使用被称为清单的列表或组列表。一旦清单定义，你可以选择主机或组来运行。 清单的默认位置是/etc/ansible/hosts。可以通过-i选项来指定不同的清单文件。也可以同时使用多个清单文件。从动态或云拉取清单。 清单基本formats, hosts, groups。 清单文件有多种形式。最常用的是INI和YAML。 123456789101112# INI格式mail.example.com# 组名[webservers]a.example.comb.example.com[dbserver]db1.example.comdb2.example.comdb3.example.com 1234567891011121314# YAML格式all: hosts: mail.example.com: children: webserver: hosts: a.example.com: b.example.com: dbservers: hosts: db1.example.com: db2.example.com: db3.example.com: 默认组(default groups)，有两个默认组。 all：包含每个主机 ungrouped：all中没有组的主机 在多个组中的主机(Hosts in multiple groups)。 1234567891011121314151617181920212223242526all: hosts: mail.example: children: webservers: hosts: f.example.com: b.example.com: dbservers: hosts: one.example.com: two.example.com: east: hosts: f.example.com: one.example.com: west: hosts: b.example.com: two.example.com: prod: children: east: test: hosts: b.example.com: 添加主机范围(Adding ranges of hosts)。如果有很多主机有一个类似的模式，可将其添加为一个范围，而不是单独列出每个主机名。 1234567... webservers: hosts: www[01:20].example.com: dbservers: hosts: db-[a:f].example.com 添加变量到清单Adding variables to inventory 可以在清单中存储涉及到特定主机或组的变量值。 主机变量Assigning a variable to one machine: host variables 1234567atlanta: hosts1: http_port: 80 maxRequestPerChild: 808 hosts2: http_port: 303 maxRequestPerChild: 909 清单别名(Inventory aliases)。在清单中定义别名： 12345... hosts: jumper: ansible_port: 5555 ansible_host: 192.0.2.50 组变量Assigning a variable to many machines: group variables 在一组的主机中共享变量值。 1234567atlanta: hosts: hosts1: host2: vars: ntp_server: ntp.atlanta.example.com proxy: proxy.atlanta.example.com 继承变量值(Inheriting variable values: group variables for groups of groups)。可使用children:(yaml)来构建组的组，同样，可使用vars:来构建组变量的组变量。 12345678910111213141516171819202122all: children: usa: children: southeast: children: atlanta: hosts: hosts1: hosts2: raleigh: hosts: hosts2: hosts3: vars: some_server: foo.southeast.example.com halon_system_timeout: 30 self_destruct_countdown: 60 escape_pods: 2 northeast: norethwest: southwest: 子组有几个属性的注意事项： 子组成员的任何主机自动成为父组的成员 子组的变量的优先级高于(覆盖)父组的变量 组可以有多个父亲和孩子 主机可以在多个组，但只会有一台主机实例，合并来自多个组的数据 组织主机和组变量Organizing host and group variables 尽管你可以将变量存储在清单文件，但存储独立的主机和组变量可以帮助您更轻松地阻止你的变量值。主机和组变量文件必须使用YAML语法。 Ansible通过搜索清单文件或剧本文件的路径来载入主机和组变量文件。 变量如何合并How variables are merged 默认情况下，在play运行前变量被合并到特定的主机。这使Ansible集中在主机和任务，因此组并没有真正生存在清单和主机匹配之外。Ansible覆盖变量的顺序： all group parent group child group host 默认情况下Ansible在相同的父/子级按字母顺序合并组，并在最后一组加载覆盖前面的组。你可以通过设置组变量ansible_group_priority来改变同级组合并顺序的行为。数字越大，优先级就越高。默认值是1。 123456# testvar == aa_group: testvar: a ansible_group_priority: 10b_group: testvar: b 使用多个清单源Using multiple inventory sources 可通过在命令行中或配置ANSIBLE_INVENTORY通过给定多个清单参数在同一时间目标多个清单源（目录，动态清单脚本，清单插件…）。 12# target 2 sourcesansible-playbook get_logs.yml -i staging -i production 以一个目录组合多个清单源(Aggregating inventory sources with a directory) 还可以通过一个目录下结合多个清单源和原类型来创建清单。这对于动静结合主机和管理它们为一体化清单很有用。 123456inventory/ openstack.yml # configure inventory plugin to get hosts from Openstack cloud dynamic-inventory.py # add additional hosts with dynamic inventory script static-inventory # add static hosts and groups group_vars/ all.yml # assign variables to all hosts 12# target inventoryansible-playbook example.yml -i inventory 清单参数Connecting to hosts: behavioral inventory parameters 以下变量控制与远程主机如何与Ansible相互作用。 清单配置样例Inventory setup examples 每个环境一个清单(One inventory per environment) 通过功能分组(Group by function) 通过地址分组(Group by location) 12345# Example: One inventory per environment# inventory_test[dbservers]db01.test.example.comdb02.test.example.com 12345678# Example: Group by function- hosts: dbservers tasks: - name: allow access from 10.0.0.1 iptables: chain: INPUT jump: ACCEPT source: 10.0.0.1 1234# Example: Group by location[dc1]db01.test.example.comapp01.test.example.com 动态清单Working with dynamic inventory: https://docs.ansible.com/ansible/latest/user_guide/intro_dynamic_inventory.html cobbler AWS ec2 OpenStack 其它清单脚本Other inventory scripts 模式Patterns: targeting hosts and groups: https://docs.ansible.com/ansible/latest/user_guide/intro_patterns.html 当你通过ad-hoc或playbook执行Ansible时，你必须选择要对哪些节点或组执行。模式可以让你针对清单中的特定主机或组执行。一个Ansible Pattern可以指定单个主机、IP地址、清单组、一组组、所有主机…模式非常灵活，可以排除需要的主机子集、使用通配符、正则表达式…Ansible将在包含在模式上的所有清单主机上执行。 模式使用Using patterns 123# ad-hoc# ansible &#123;pattern&#125; -m &#123;module_name&#125; -a "&#123;module_options&#125;"ansible webservers -m service -a "name=httpd state=restarted" 123456# palybook- name: &#123;play_name&#125; hosts: &#123;pattern&#125;- name: restart webservers hosts: webservers 常见模式Common patterns 描述 模式 目标 All hosts all(*) - One host host1 - Multiple hosts host1:host2(host1,host2) - One group g1 - Multiple groups g1:g2 all hosts in g1 and g2 Excluding groups g1:!g2 all hosts in g1 except those in g2 Intersection of groups g1:&amp;g2 g1和g2的交集 模式的局限性Limitations of patterns 模式依赖于清单。如果主机或组不在清单中，则不能使用模式来目标它。如果模式中包含清单中不存在的IP地址或主机名，会报错。模式必须匹配清单语法。 高级的模式选项Advanced pattern options 常用的模式将满足你的大部分需求，但Ansible提供了几种方法来定义你需要定位(target)的主机和组。 在模式中使用环境变量Using variables in patterns 12# playbookwebservers:!&#123;&#123; excluded &#125;&#125;:&amp;&#123;&#123; required &#125;&#125; 在模式中使用组位置Using group position in patterns 12345678910[g1]aabbccg1[0]g1[-1]g1[0:2]g1[1:] 在模式中使用正则Using regexes in patterns 以~符号开始使用模式的正则: ~(web|db).*\.example\.com playbook标志Patterns and ansible-playbook flags 可以使用命令行选项改变playbook中定义的行为。 1ansible-playbook site.yml --limit datacenter2 ad-hocIntroduction to ad-hoc commands: https://docs.ansible.com/ansible/latest/user_guide/intro_adhoc.html 一个Ansible的ad-hoc命令使用ansible命令行工具在一个或多个管理节点上执行单一任务。ad-hoc命令是快速和容易的，但却无法重复使用。那么为什么首先学习ad-hoc命令呢？它表明Ansible的简单和功能。在这学的内容可直接到playbook里。在执行前，请先阅读构建清单。 ansible命令行实用程序的默认模块是command module。 如果像重复一个命令，可使用playbook中的template module。 为什么使用它Why use ad-hoc commands? ad-hoc命令针对的是很少会重复的任务。 12# 栗子ansible [pattern] -m [module] -a "[module options]" 用例Use cases for ad-hoc tasks ad-hoc任务可用来重启服务器、复制文件、管理包和用户…可在ad-hoc任务中使用任意Ansible模块。Ad-hoc tasks与playbooks类似，使用一个声明模型，计算并执行以达到规定的最终状态所需的操作。 重启服务器 ad-hoc任务调用命令模块。在执行前，确保清单和SSH。 12345678910111213141516171819# rebooting serversansible host1 -a "/sbin/reboot"# 默认是5并发进程ansible host1 -a "/sbin/reboot" -f 10# ansible将默认为你的用户账户ansible host1 -a "/sbin/reboot" -f 10 -u username# 重启服务器可能需要特权提升，如从user到rootansible host1 -a "/sbin/reboot" -f 10 -u username --become [--ask-become-pass]# 使用不同的模块ansible host1 -m shell -a 'echo $&#123;TERM&#125;' 文件管理 ad-hoc可利用Ansible和scp的力量，并行传输文件到多台机器。 1234567# 复制文件ansible atlanta -m copy -a "src=/etc/hosts dest=/tmp/hosts"# file模块属主和权限，创建目录，递归删除ansible webservers -m file -a "dest=/srv/foo/b.txt mode=600 owner=mdehaan group=mdehaan"ansible webservers -m file -a "dest=/path/to/c mode=755 owner=mdehaan group=mdehaan state=directory"ansible webservers -m file -a "dest=/path/to/c state=absent" 包管理 使用ad-hoc任务使用包管理模块（如yum），来安装、升级、移除包。 Ansible有许多平台的许多包管理工具的模块，详情请看文档。 123456789101112# 安装了包不更新ansible webservers -m yum -a "name=acme state=present"# 特定包版本ansible webservers -m yum -a "name=acme-1.5 state=present"# 确认包是最新版ansible webservers -m yum -a "name=acme state=latest"# 确保未安装ansible webservers -m yum -a "name=acme state=absent" 管理用户和组 使用ad-hoc任务在管理的节点上创建、管理、移除用户账户。 123ansible all -m user -a "name=foo password=&#123;crypted password here&#125;"ansible all -m user -a "name=foo state=absent" 服务管理 12345678910# 确保服务已启动ansible webservers -m service -a "name=httpd state=started"# 重启服务ansible webservers -m service -a "name=httpd state=restarted"# 确保服务已停止ansible webservers -m service -a "name=httpd state=stopped" 收集事实 事实代表发现关于系统的变量。 12# 查看所有factsansible all -m setup 连接方法和详情Connection methods and details: https://docs.ansible.com/ansible/latest/user_guide/connection_details.html ControlPersist和paramiko默认情况下，Ansible使用原生的OpenSSH，因为它支持ControlPersist（一个性能特点），Kerberos，和~/.ssh/config中的配置。如果你的控制机使用的旧版本OpenSSH不支持ControlPersist，Ansible将回退到称为paramiko的一个Python实现的OpenSSH。 ssh-key配置SSH key setup 默认情况下，Ansible假定您使用SSH keys连接到远程主机。推荐使用key，但可使用--ask-pass选项来使用密码。使用--ask-become-pass选项来使用特权提升。 123# 建立ssh agent来避免输入密码ssh-agent bashssh-add ~/.ssh/id_rsa 本地运行Running against localhost 1ansible localhost -m ping -e 'ansible_python_interpreter="/usr/bin/env python"' 主机密钥检查Host key checking Ansible默认启用主机密钥检查。如果主机重装并在known_hosts中有不同的密钥，这将导致一个错误消息，知道纠正。 可在/etc/ansible/ansible.cfg或~/.ansible.cfg中禁用它: 12[defaults]host_key_checking = False 或设置环境变量: export ANSIBLE_HOST_KEY_CHECKING=False 其它连接方法Other connection methods 除了SSH之外，Ansible还可以使用许多连接方法。 命令行工具Working with command line tools: https://docs.ansible.com/ansible/latest/user_guide/command_line_tools.html 大多数用户对ansible和ansilbe-playbook比较熟悉，但它们不是Ansible提供的唯一实用工具。下面是完整的Ansible使用工具列表。 ansible: 在一组主机上定义和运行一个单任务playbook ansible-config: 查看Ansible配置信息 ansible-console: REPL控制台执行Ansible任务 ansible-doc: 插件文档工具 ansible-galaxy: 执行各种角色并收集相关的操作 ansible-invotory: 显示或转配置清单 ansible-playbook: 运行Ansible playbook ansible-pull: 从仓库拉playbook并为本地主机执行 ansible-valut: Ansible数据文件的加解密工具 playbookWorking With Playbooks: https://docs.ansible.com/ansible/latest/user_guide/playbooks.html Playbooks是Ansible的配置(configuration)、部署(deployment)和编排(orchestration)语言。它可以描述你希望你的远程系统强制执行的策略，或在IT流程的步骤。 在最基本的级别上，playbook可以被用来管理部署的配置到远程机器。在更高级的，它们可以序列进行涉及多层(mulit-tier)的滚动更新和回滚，并可以委托操作其它主机，与监控服务器进行交互和负载均衡。它有很多功能和信息，详情看文档。 playbook被设计为人类可读的和基于文本语言开发。有多种方式来组织playbook和它包含的文件。 你应该看一看Example Playbooks，并与playbook文档一起阅读。这些说明的最佳实践，以及如何把众多的各种概念混合在一起。 介绍Intro to Playbooks: https://docs.ansible.com/ansible/latest/user_guide/playbooks_intro.html playbook是比在ad-hoc任务执行模式下的一个完全不同的使用ansible的方式，并且特别强大。 简单来说，Playbook是一个非常基础的用于配置管理和多机部署系统，不同于任何已存在的，并且非常适合部署复杂的应用程序。 playbook可以声明配置，但它也可以通过编排任意手动排序进程的步骤，尽管不同的步骤必须来回在特定命令的机器之间。它可以同步(synchronously)或异步(asynchronously)发射任务。 虽然你为ad-hoc任务运行主要的/usr/bin/ansible程序，playbook更可能被保持在原控制和用于推送配置或保证远程系统上的配置。palybook example中有许多栗子，建议去看一看。 playbook languageplaybook以YAML语法格式表示，故意不设计成一种编程语言或脚本，而是过程或配置的模型。 每个playbooks由列表中的play组成。play的目标是映射一组主机到一些良好定义的角色(roles)，由ansible调用任务来表示。通过多个paly组成playbook，有可能协调多机部署，在某个组的所有机器上运行某些步骤…你可以由相当多的影响你的系统做不同事情的paly。 123456789101112131415161718192021222324252627# 仅包含一个paly的`verigy-apache.yml`的playbook的栗子---- hosts: webserver vars: http_port: 80 max_clients: 200 remote_user: root tasks: - name: ensure apache is at the latest version yum: name: httpd state: latest - name: write the apache config file template: src: /srv/httpd.j2 dest: /etc/httpd.conf notify: - restart apache - name: ensure apache is running service: name: httpd state: started handlers: - name: restart apache service: name: httpd state: restarted 123456789101112131415161718192021222324252627# 包含多个play的栗子---- hosts: webservers remote_user: root tasks: - name: ensure apache is at the lastest version yum: name: httpd state: latest - name: write the apache config file template: src: /srv/httpd.j2 dest: /etc/httpd.conf- hosts: databases remote_user: root tasks: - name: ensure pgsql is at the latest version yum: name: postgresql state: latest - name: ensure that postgresql is started service: name: postgresql state: started 基本Basics 主机和用户Hosts and Users 对于playbook中的每个play，你可以选择哪些机器在你的基础设施到目标，什么远程用户完成这些步骤。 12345678# hosts行是一个或多个主机或组的模式，以冒号分隔---- hosts: webservers remote_user: root tasks: - name: test ping: remote_user: username # 远程用户可在每个用户中定义 12345# 特权提升---- hosts: webservers remote_user: username become: yes 12345678910# 也可在每个paly中使用become---- hosts: g1 remote_user: uername tasks: - service: name: nginx state: started become: yes become_method: sudo 123456# 权限提升为特定用户---- hosts: g1 remote_user: username become: yes become_user: postgres 12345678# 控制运行顺序，默认是清单里面的顺序---- hosts: all order: sorted gather_facts: False tasks: - debug: var: inventory_hostname 任务列表Tasks list 每个play包含任务列表。任务在移动到下一个任务之前执行，一次一个，由模式匹配的所有主机。理解在一个play中，所用主机都将得到同样的任务指令是很重要的。这是play映射选择主机到任务的目的。 当运行playbook时，它从上到下运行，失败任务的主机被从playbook轮转中取出。如果事情失败，只是纠正playbook文件，然后重新运行。 每个任务的目标是执行带有特定参数的模块，变量可以在参数中传给模块。 123456# 一个任务的基本栗子tasks: - name: make sure apache is running service: name: httpd state: started 12345678# command, shell模块tasks: - name: enable selinux command: /sbin/setenfore 1tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand || /bin/true 12345tasks: - name: create a virtual host file for &#123;&#123; vhost&#125;&#125; template: src: somefile.j2 dest: /etc/httpd/conf.d/&#123;&#123; vhost&#125;&#125; action shorthand1234# Ansible prefers listing modules like this:template: src: template/foo.j2 dest: /etc/foo.conf 早期版本使用以下格式，仍旧有效: action: template src=templates/foo.j2 dest=/etc/foo.conf HandlersHandlers: Running Operations On Change 如前所述，当远程系统上做了改变时模块应该是幂等的和可以中继(relay)。playbook认识到了这一点，并有一个基本的事件系统用于应对改变。 这些play中的notify行动在任务的每个末尾块触发，即使被多个不同任务通知也只能被触发一次。 例如，多个资源可能表明Apache需要重启，因为配置文件发生了更改，但Apache将跳跃一次，以避免不必要的重启。 12345678# 当一个文件的内容更改时（仅此文件），重启两个服务的栗子- name: template configuration file template: src: template.j2 dest: /etc/foo.conf notify: - restart memcached - restart apache 在任务的notify中列出的事情的部分被称为处理程序(handlers)。 处理程序是任务列表，与常规的任务没什么区别，由一个全局唯一的名称进行引用，并通过通知程序(notifier)进行通知。如果没有事情通知一个处理程序，它将不会运行。不管有多少任务通知处理程序，它只能运行一次，在一个特定paly中的所有任务完成之后。 12345678910# handlers sectionhandlers: - name: restart memcached service: name: memcached state: restarted - name: restart apached service: name: apache state: restarted 你可能想让Ansible handlers使用变量。如果handlers name使用的变量不可用，则整个paly将失败。取而代之的是，在handlers的任务参数中使用变量。 123456789tasks: - name: Set host variables based on distribution include_vars: "&#123;&#123; ansible_facts.distribution&#125;&#125;.yml"handlers: - name: restart web service service: name: "&#123;&#123; web_service_name | default('httpd') &#125;&#125;" state: restarted Ansible 2.2，handlers可以监听(listen)通用话题(generic topics)，任务可以通知这些话题。以下这种使用使它更容易触发多个处理程序。它还从名称解耦处理程序，使得在playbook和roles之间更容易共享处理程序。（特别是当使用像Galaxy的第三方角色时） 12345678910111213141516handlers: - name: restart memcached service: name: memcached state: restarted listen: "restart web service" - name: restart apache service: name: apached state: restarted listen: "restart web services"tasks: - name: restart everything command: echo "this task will restart the web services" notify: "resstart web service" 注意:Notify handlers are always run in the same order they are defined, not in the order listed in the notify-statement. This is also the case for handlers using listen.Handler names and listen topics live in a global namespace.Handler names are templatable and listen topics are not.Use unique handler names. If you trigger more than one handler with the same name, the first one(s) get overwritten. Only the last one defined will run.You cannot notify a handler that is defined inside of an include. As of Ansible 2.1, this does work, however the include must be static. 角色(Roles)后面会说明，但它值得指出的是： handlers notified within pre_tasks, tasks, and post_tasks sections are automatically flushed in the end of section where they were notified handlers notified within roles section are automatically flushed in the end of tasks section, but before any tasks handlers handlers are play scoped and as such can be used outside of the role they are defined in 执行playbookExecuting A Playbook 1ansible-playbook playbook.yml -f 10 Ansible-Pull节点检查到重要位置，而不是推送配置给它们。ansilbe-pull是一个检查从git指令配置仓库的一个脚本，然后针对改内容运行ansible-playbook。 Linting playbooks你可以在执行前使用ansible-lint来检查playbook的运行情况。 1234ansible-lint verify-apache.yml[403] Package installs should not use latestverify-apache.yml:8Task/Handler: ensure apache is at the latest version 其它playbook验证项Other playbook verification options 查看验证playbook工具的详情列表，你可以使用它们来验证playbook。这里有些情况你应该考虑： 要检查playbook语法问题，使用ansible-playbook的--syntax-check标志。 要查看完整的输出信息，使用--verbose标志。 要查看playbook会影响哪些主机，可运行: ansible-playbook playbook.yml --list-hosts 可重复使用的playbookCreating Reusable Playbooks: https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse.html 虽然可以在一个非常大的文件里编写playbook，最终你会想重新使用文件和整理东西。在Ansible中，有三种方式可以做到这一点： includes imports roles includes和imports允许用户将大型playbook分解为小型文件，可跨多个parent playbook或设置多次在相同的playbook里。roles允许不仅仅是任务可以打包在一起，可以包括变量(variables)，处理程序(handlers)，甚至模块(modules)和其它插件(plugins)。不同于includes和imports，roles也可上传并经由Ansible Galaxy共享。 including和importingIncluding and Importing: https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_includes.html include和import语句相似，但Ansible执行引擎处理它们却非常不同。 import*语句在playbook被解析的时候进行预处理(pre-processed)。include*语句在playbook的执行过程中遇到才处理。 include和import语句可以在任意深度使用。 在一个master playbook内包含playbook： 12- import_playbook: a.yml- import_playbook: b.yml 每个playbook中列出的plays和tasks将以列出的顺序 执行，就好像它们已经在这里直接定义。 大型任务划分成不同的文件是组织复杂任务或重用它们的一种好方式。一个任务文件只包含简单的任务列表： 1234- name: aaa command: /bin/aaa- name: bbb command: /bin/bbb 可以使用import_tasks或include_tasks来执行在主任务列表中的文件的任务： 1234tasks:- import_tasks: aaa_tasks.yml# or- include_tasks: aaa_tasks.yml 你也可以传递变量到imports和includes： 12345678910tasks:- import_tasks: aaa.yaml vars: user: aaa- import_tasks: aaa.yml vars: user: bbb- import_tasks: aaa.yml vars: user: ccc include和import同样可以用于handlers:部分。栗子： 12345# more_handlers.yml- name: restart apache service: name: apache state: restarted 1234handlers:- include_tasks: more_handlers.yml# or- import_tasks: more_handlers.yml Rolesroles: https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_roles.html 角色(role)是基于已知的文件架构自动加载某些变量文件、任务和处理程序的方式。按角色分组的内容还可以方便地与其他用户共享。 角色目录结构Role Directory Structure 栗子： 12345678910111213141516site.ymlwebservers.ymlfooservers.ymlroles/ common/ tasks/ handlers/ files/ templates/ vars/ defaults/ meta/ webservers/ tasks/ defaults/ meta/ 角色在特定目录名下期待文件。角色必须包括这些目录中的至少一个，但它是完全没排除任何未使用。在使用时，每个目录必须包含一个main.yml文件，其中包含的相关内容： tasks：包含由角色执行的主任务列表 handlers：包含可通过此角色甚至此角色外的任何地方使用的处理程序 defaults：角色的默认变量 vars：角色的其它变量 files：通过此角色可以部署的文件 templates：通过此角色可以部署的模板 meta：为角色定义的元数据 其它YAML文件可能包含在特定目录。栗子： 123456# roles/example/tasks/main.yml- name: added in 2.4, previously you used include import_tasks: redhat.yml when: ansible_facts['os_family']|lower == 'redhat' import_tasks: debian.yml when: ansible_facts['os_family']|lower == 'debian' 1234# roles/example/tasks/redhat.yml- yum: name: "httpd" state: present 1234# roles/example/tasks/debian.yml- pat: name: "apache2" state: present 角色还可以包含模块和其它插件类型。 角色使用使用角色的原始的方式是在play中通过roles:： 12345---- hosts: webservers roles: - common - webservers 这将为每个角色(x)指定以下行为： 如果roles/x/tasks/main.yml存在，其中列出的任务将被添加到play； 如果roles/x/handlers/main.yml存在，其中列出的处理程序将被添加到play； 如果roles/x/vars/main.yml存在，其中列出的变量将被添加到play； 如果roles/x/defaults/main.yml存在，其中列出的变量将被添加到play； 如果roles/x/meta/main.yml存在，其中列出的任何角色的依赖都将被添加到角色列表； 角色中的任意copy, script, template, include tasks，可在roles/x/{files,templates,tasks}/dir进行引用，而不必关心它们的相对或绝对路径。 当以这种方式使用时，playbook的执行顺序如下： play中定义的任意pre_tasks 任意处理程序触发到目前为止将会运行 在roles中列出的每个角色将依次执行。在角色meta/main.yml中定义的任意角色依赖将首先运行，受标签过滤和条件 play中定义的任意tasks 任意处理程序触发到目前为止将会运行 play中定义的任意post_tasks 任意处理程序触发到目前为止将会运行 可使用import_role或include_role在其它任务中使用角色： 1234567891011---- hosts: webservers tasks: - debug: msg: "before we run our role" - import_role: name: example - include_role: name: example - debug: msg: "after we ran our role" 当角色在原始方式中定义，它们被视为静态导入和在playbook解析时进行处理。 角色的名称可是很简单，也可以是一个完全合格的路径： 1234---- hosts: webservers roles: - role: '/path/to/roles/common' 角色可以接受其它关键字： 123456789101112---- hosts: webservers tasks: - include_role: name: foo_app_instance when: "ansible_facts['os_family'] == 'RedHat'" vars: dir: '/opt/a' app_port: 5000 tags: - aaa - bbb 角色副本和扩展Role Duplication and Execution Ansible只允许一个角色执行一次，即使多次定义： 12345---- hosts: webservers roles: - foo - foo 上面给出的foo角色仅将运行一次。为了使角色多次运行，有两种选择： 每个角色传递不同的参数 添加allow_duplicates: true到meta/main.yml文件 12345678910# playbook.yml---- hosts: webservers roles: - foo - foo# roles/foo/meta/main.yml---allow_duplicates: true 角色默认变量Role Default Variables 角色的默认变量允许你为角色设定默认变量。在角色目录中添加defaults/main.yml文件。这些变量具有最低优先级，可以轻易被覆盖。 角色依赖Role Dependencies 角色依赖让你在其它角色使用角色时自动拉取。角色依赖存储在角色目录的meta/main.yml文件。此文件应包含角色和参数列表在指定角色之前插入： 12345678910111213# orles/myapp/meta/main.yml---dependencies: - role: common vars: come_parameter: 3 - role: apache vars: apache_port: 80 - role: postgres vars: dbname: blarg other_parameter: 12 角色中的嵌入模块和插件Embedding Modules and Plugins In Roles 角色搜索路径Ansible将按以下方式为角色搜索： 相对于playbook文件的roles/目录 默认情况下，在/etc/ansible/roles GalaxyAnsible Galaxy是一个用于查找、下载、评级、审查各种社区ansible roles的免费网站。 ansible-galaxy客户端包含在Ansible中。可使用它从Ansible Galaxy下载角色。 动态与静态Dynamic vs. Static Ansible有两种操作模式用于可重用内容：动态与静态。 如果你使用include*，它将是动态的。如果你使用import*，它是静态的。 动态与静态的区别 两种操作模式都非常简单： 动态包含在遇到任务运行时处理 静态导入在解析playbook前处理 当遇到tag或when： 动态包含仅适用于动态的任务，不会复制到子任务 静态导入，将被复制到所有子任务 两者比较使用include*与import*有一定的优势，权衡两者。 使用include*语句的最大优势是循环。当在include中使用循环，所包含的将在每个循环中执行。 tags仅在动态包含内存在 tasks仅在动态包含内存在 在动态包含内不能使用notify来触发处理程序 在动态包含内不能使用--start-at-task来开始执行 静态导入内循环不能使用 静态导入内不能从库存源使用变量 静态导入内当通知它们的名字时，使用处理程序将不会触发 使用变量Using Variables: https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html Ansible中使用变量可以更好地帮助处理各系统之间的差异。 创建有效的变量名Creating valid variable names 有效的变量名是很重要的。变量名应该是字母 、数字和下划线，且总是以字母开头。 YAML也支持映射键值对的字典： 123foo: field1: one field2: two 你可以使用中括号或点来引用特定字段的值: 12foo[&apos;field1&apos;]foo.field2 请注意，如果使用点来引用，它们属性和Python字典的方法相冲突可能会导致一些问题。如果你使用的键开始和结束有两个下划线，或它们是已知的公共属性，则你应该使用中括号来代替点使用。 12# 公共属性add, append, count, decode... 在清单中定义变量Defining variables in inventory 通常，你需要为单独的主机或组设置变量。你可以在清单文件(如hosts)中定义所需的变量： 1234west: host1: port: 80 maxRequest: 808 123456east: hosts: host1: xx host2: xxx vars: port: 80 在playbook中定义变量Defining variables in a playbook 你可以直接在playbook中定义变量： 123- hosts: xxx vars: port: 80 在文件和角色中定义变量Defining variables in included files and roles 12345678- hosts: xxx roles: - role: test vars: dir: '/opt/a' - role: test2 vars: dir: '/opt/b' 在Jinja2中使用变量Using variables with Jinja2 一旦你定义了变量，便可以在Jinja2的模板系统中引用它： 1Ma amp goes to &#123;&#123; max_amp_value &#125;&#125; 使用Jinja2过滤器转换变量Transforming variables with Jinja2 filters Jinja2 filters 让你在模板表达式内转换变量的值。如capitalize大写过滤器，to_yaml和to_json过滤器来转换成对应格式。 Jinja2包含了许多内置过滤器： https://jinja.palletsprojects.com/en/2.11.x/templates/#builtin-filtersAnsible也支持许多过滤器： https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#playbooks-filters YAML疑难杂症Hey wait, a YAML gotcha YAML语法要求，如果你使用值引用整行，它要确保你不是想开始一个YAML字典。所以记得使用双引号。 12345678# wrong...vars: path: &#123;&#123; dir &#125;&#125;/22# rightvars: path: "&#123;&#123; dir &#125;&#125;/22" 系统facts中的变量Variables discovered from systems: Facts facts是从远程系统获得的信息。你可以从ansible_facts变量中找到。 12# 查看factsansible hostname -m setup 12- debug: var: ansible_facts 1&#123;&#123; ansible_facts[&apos;devices&apos;][&apos;xvda&apos;][&apos;model&apos;]&#125;&#125; 禁用facts 如果你不需要fact数据，你可以禁用它。 12- hosts: xxx gather_facts: no Local facts(facts.d) facts通常都是由Ansible setup模块自动发现。用户也可以编写自定义的facts模块，请参考API指南。但是，如果你想要一个简单的方法来使用用户提供的数据，而不需要写一个facts模块。 facts.d是一种可让用户控制它们的系统是如果管理的某些方面的机制。 如果远程管理系统有/etc/ansible/facts.d目录，该目录中的所有.fact文件（JSON, INI…）。可使用fact_path paly 关键字作为可选目录。 注册变量Registering variables 另一个主要使用的变量是正在运行一个命令和将此命令的返回的结果注册为一个变量，供其它地方使用。 1234567- hosts: xxx tasks: - shell: /usr/bin/foo register: foo_result ignore_errors: True - shell: /usr/bin/bar when: foo_result.rc == 5 访问复杂的变量数据Accessing complex variable data 有些提供的facts，如网络信息，包含了复杂的嵌套结构。取值会稍微麻烦一些： 1234567&#123;&#123; ansible_facts[&apos;eth0&apos;][&apos;ipv4&apos;][&apos;address&apos;]&#125;&#125;# or&#123;&#123; ansible_facts.eth0.ipv4.address &#125;&#125;# 访问数组的第一个元素&#123;&#123; foo[0] &#125;&#125; 使用magic变量访问其它主机的信息Accessing information about other hosts with magic variables 无论你是否定义变量，你也可以利用特殊的Ansible变量访问有关主机的信息，包括magic, facts, connection变量。magic变量名称被保留，所以不要使用这些名称来设置变量。enviroment变量也同样被保留。 最常使用的魔术变量有：hostvars, groups, group_names, inventory_hostname。 host_vars允许你访问其它主机的变量，包括该主机的facts。你可以在playbook中的任意一点访问主机变量。即使你在playbook中并没有连接到此主机，你仍可以得到变量。groups是清单中所有组的列表。这可以用于枚举组内的所有主机。group_names是所有组中当前主机的列表或数组。inventory_hostname是清单主机文件中配置的主机名。使用inventory_hostname_short获取更简短的信息。ansible_play_hosts是当前play中仍然活跃的主机列表。ansible_play_batch是当前批量paly上可用的主机名列表。ansible_playbook_python是python执行调用ansible命令行工具的路径。role_path返回当前角色的路径名。这仅在角色里工作。 123456789&#123;&#123; hostvars[&apos;test.example.com&apos;][&apos;ansible_facts&apos;][&apos;distribution&apos;] &#125;&#125;&#123;% for host in groups[&apos;app_servers&apos;] %&#125; &#123;&#123; hostvars[host][&apos;ansible_facts&apos;][&apos;eth0&apos;][&apos;ipv4&apos;][&apos;address&apos;] &#125;&#125;&#123;% endfor %&#125;&#123;% if &apos;webserver&apos; in group_names %&#125; # xxx&#123;% endif %&#125; 在文件中定义变量Defining variables in files 让playbook使用版本控制是很好的想法，但你可能希望让playbook 源公开化，但同时又保证一定的重要的私有变量。 你可以通过一个外部变量文件来这么做： 1234567---- hosts: all ... vars: color: blue vars_files: - /vars/external_vars.yml 123# external_vars.ymluser: xxpassword: xxxx 这消除了分享playbook但避免分享数据的风险。 在命令行上传递参数Passing variables on the command line 可在命令行上使用--extra-vars参数来设置变量： 12345678# k:v格式ansible-playbook release.yml --extra-vars "version=1.23.45 other_variable=foo"# json格式ansible-playbook arcade.yml --extra-vars '&#123;"pacman":"mrs","ghosts":["inky","pinky","clyde","sue"]&#125;'# 文件ansible-playbook release.yml --extra-vars "@some_file.json" 变量的优先级：我应该把变量放在哪Variable precedence: Where should I put a variable? 同一名称的变量如果在多个地方被定义，则它们会以特定的顺序发生覆盖，所需需要知道Ansible变量的优先级，以及它们的放置位置。下面是从小到大的优先级： command line values role defaults inventory file or script group vars inventory group_vars/all playbook group_vars/all inventory group_vars/* playbook group_vars/* inventory file or script host vars inventory host_vars/* playbook host_vars/* host facts / cached set_facts play vars play vars_prompt play vars_files role vars (defined in role/vars/main.yml) block vars (only for tasks in block) task vars (only for the task) include_vars set_facts/registered vars role (and include_role) params include params extra vars (always win precedence) Jinja2模板Templating (Jinja2): https://docs.ansible.com/ansible/latest/user_guide/playbooks_templating.html Ansible使用Jinja2模板化来实现动态表达式和访问变量。Ansilbe大大扩展的filters和tests数量，以及新增了一个插件类型：lookups。 请注意，所有模板发生在Ansible控制器上，在任务发送和执行在目标主机之前。 FiltersFilters: https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html TestsTests: https://docs.ansible.com/ansible/latest/user_guide/playbooks_tests.html Jinja中的测试是评估模板表达式并返回True或False。许多内置测试: https://jinja.palletsprojects.com/en/2.11.x/templates/#builtin-tests 测试器和过滤器的主要区别是测试用于比较，而过滤去用于数据操作。测试同样可以在列表处理器中使用，如map()和select()在列表中选择项。 与所有模板一样，测试始终在Ansible控制器上执行，而不是任务的目标主机。除了这些Jinja2的测试，Ansible支持用户轻松创建自己的测试。 LookupsLookups: https://docs.ansible.com/ansible/latest/user_guide/playbooks_lookups.html 查找插件允许访问外部数据源。与所有模板一样，这些插件在Ansible控制器上进行评估，并且可以包括读取文件系统、对外联络网络数据存储和服务。这些数据使用Ansible标准模板系统提供。 注意查找发生在本地主机，而不是远程主机；它们在包含role或play的目录内执行，而不是与执行脚本的目录执行本地任务；可以传递wantlist=True给lookups来使用Jinja2中的for循环；查找是一个高级的功能，你应该对Ansible有足够的了解。 Python版本和模板Python Version and Templating: https://docs.ansible.com/ansible/latest/user_guide/playbooks_python_version.html Jinja2模板利用Python数据类型和标准函数。这使得可对数据进行丰富的操作。然而，这也意味着潜在的Python的某些细节对模板编写者可见。由于Ansible playbook使用Jinja2用于模板与变量，这意味着playbook作者需要了解这些细节。 除了这些，请注意在Python2和Python3上运行Ansible的不同。 条件语句Conditionals: https://docs.ansible.com/ansible/latest/user_guide/playbooks_conditionals.html 经常的一个play的结果可能依赖于一个变量的值，或之前的任务的结果。在某些情况下，变量的值可能依赖于其它变量。本主题介绍如何在playbook中使用条件语句。 When语句The When Statement 有时你会想在某个特定主机上跳过特定的步骤。 在Ansible中使用when子句很容易达到，它不包含Jinja2中的双花括号表达式。它非常简单： 123456tasks: - name: "shut down CentOS 6 systems" command: /sbin/shutdown -t now when: - ansible_facts['distribution'] == "CentOS" - ansible_facts['distribution_major_version'] == "6" 许多Jinja2的测试器和过滤器都可在when子句中使用，其中某些是由Ansible单独提供的。 1234567891011121314tasks: - command: /bin/false register: result ignore_errors: True - command: /bin/something when: result is failed # In older versions of ansible use ``success``, now both are valid but succeeded uses the correct tense. - command: /bin/something_else when: result is succeeded - command: /bin/still/something_else when: result is skipped 123tasks: - shell: echo "This certainly is epic!" when: epic or monumental|bool 123456tasks: - shell: echo "I've got '&#123;&#123; foo &#125;&#125;' and am not afraid to use it!" when: foo is defined - fail: msg="Bailing out. this play requires 'bar'" when: bar is undefined 循环和条件Loops and Conditionals when和loops结合使用，请注意when语句是根据每个项分别处理。 1234tasks: - command: echo &#123;&#123; item &#125;&#125; loop: [ 0, 2, 4, 6, 8, 10 ] when: item &gt; 5 在自定义facts中载入Loading in Custom Facts 如果你想提供自己的facts也很简单。要运行它们，只需要在任务顶部调用你自己定义的模块，这里返回的变量将能访问未来的任务： 12345tasks: - name: gather site specific fact data action: site_facts - command: /usr/bin/thingy when: my_custom_fact_just_retrieved_from_the_remote_system == '1234' Applying when to roles,imports,and includes在roles, imports, includes中使用when语句： 1234- hosts: webservers roles: - role: debian_stock_config when: ansible_facts['os_family'] == 'Debian' 有条件的导入Conditional Imports 一个剧本适用于多个平台和操作系统是很好的栗子。 123456789---- hosts: all remote_user: root vars_files: - "vars/common.yml" - [ "vars/&#123;&#123; ansible_facts['os_family'] &#125;&#125;.yml", "vars/os_defaults.yml" ] tasks: - name: make sure apache is started service: name=&#123;&#123; apache &#125;&#125; state=started 基于变量来选择文件和模板Selecting Files And Templates Based On Variables 基于不同的系统来生成不同的配置文件： 12345678910- name: template a file template: src: "&#123;&#123; item &#125;&#125;" dest: /etc/myapp/foo.conf loop: "&#123;&#123; query('first_found', &#123; 'files': myfiles, 'paths': mypaths&#125;) &#125;&#125;" vars: myfiles: - "&#123;&#123;ansible_facts['distribution']&#125;&#125;.conf" - default.conf mypaths: ['search_location_one/somedir/', '/opt/other_location/somedir/'] 注册变量Register Variables 存储一个给定命令的结果，以便后面来访问它，在playbook中可能很有用。 注意：即使当一个任务由于条件语句跳过，注册也会发生。 register关键字决定将结果保存哪个变量。 12345678910111213- name: check registered variable for emptiness hosts: all tasks: - name: list contents of directory command: ls mydir register: contents - name: check contents for emptiness debug: msg: "Directory is empty" when: contents.stdout == "" 常用factsCommonly Used Facts 12345ansible_facts[‘distribution’]ansible_facts[‘distribution_major_version’]ansible_facts[‘os_family’] 循环Loops: https://docs.ansible.com/ansible/latest/user_guide/playbooks_loops.html 常见的Ansible循环包括改变多个文件/目录的权限、创建多个用户、重复轮询…Ansible提供了两个关键字来创建循环： loop with_&lt;lookup&gt; 注意：We added loop in Ansible 2.5. It is not yet a full replacement for with_&lt;lookup&gt;, but we recommend it for most use cases.We have not deprecated the use of with_&lt;lookup&gt;We are looking to improve loop syntax 两者比较Comparing loop and with_* with_&lt;lookup&gt;关键字依赖于Lookup插件，即便items也是查找； loop关键字等于with_list，它是简单循环的最佳选择； loop关键字不接受字符串作为输入； 一般来说，任何在Migrating from with_X to loop中使用with_*可以更新为使用loop； 当更改with_items为loop时请小心，with_items执行单级的。你需要在loop中使用flatten(1)。栗子如下： 1234567with_items: - 1 - [2,3] - 4# you would needloop: "&#123;&#123; [1, [2,3] ,4] | flatten(1) &#125;&#125;" 标准循环Standard loops 遍历一个简单列表Iterating over a simple list 12345678- name: add several users user: name: "&#123;&#123; item &#125;&#125;" state: present groups: "wheel" loop: - testuser1 - testuser2 遍历一个散列列表Iterating over a list of hashes 12345678- name: add several users user: name: "&#123;&#123; item.name &#125;&#125;" state: present groups: "&#123;&#123; item.groups &#125;&#125;" loop: - &#123; name: 'testuser1', groups: 'wheel' &#125; - &#123; name: 'testuser2', groups: 'root' &#125; 遍历一个字典Iterating over a dictionary 使用dict2items字典过滤器来遍历字典： 12345678910- name: create a tag dictionary of non-empty tags set_fact: tags_dict: "&#123;&#123; (tags_dict|default(&#123;&#125;))|combine(&#123;item.key: item.value&#125;) &#125;&#125;" loop: "&#123;&#123; tags|dict2items &#125;&#125;" vars: tags: Environment: dev Application: payment Another: "&#123;&#123; doesnotexist|default() &#125;&#125;" when: item.value != "" 循环与注册变量Registering variables with a loop 你可以将循环的输出注册为变量： 12345- shell: "echo &#123;&#123; item &#125;&#125;" loop: - "one" - "two" register: echo 复杂循环Complex loops 遍历嵌套的列表Iterating over nested lists 你可以使用Jinja2的表达式来遍历复杂的列表： 1234567- name: give users access to multiple databases mysql_user: name: "&#123;&#123; item[0] &#125;&#125;" priv: "&#123;&#123; item[1] &#125;&#125;.*:ALL" append_privs: yes password: "foo" loop: "&#123;&#123; ['alice', 'bob'] |product(['clientdb', 'employeedb', 'providerdb'])|list &#125;&#125;" 重试任务直到满足条件Retrying a task until a condition is met 可以使用until关键字来重试任务直到满足特定条件： 12345- shell: /usr/bin/foo register: result until: result.stdout.find("all systems go") != -1 retries: 5 delay: 10 循环清单Looping over inventory 遍历资产清单： 1234567891011121314151617181920# show all the hosts in the inventory- debug: msg: "&#123;&#123; item &#125;&#125;" loop: "&#123;&#123; groups['all'] &#125;&#125;"# show all the hosts in the current play- debug: msg: "&#123;&#123; item &#125;&#125;" loop: "&#123;&#123; ansible_play_batch &#125;&#125;"# show all the hosts in the inventory- debug: msg: "&#123;&#123; item &#125;&#125;" loop: "&#123;&#123; query('inventory_hostnames', 'all') &#125;&#125;"# show all the hosts matching the pattern, ie all but the group www- debug: msg: "&#123;&#123; item &#125;&#125;" loop: "&#123;&#123; query('inventory_hostnames', 'all:!www') &#125;&#125;" query与lookuploop关键字需要一个列表作为输入，但是lookup关键字默认返回逗号分隔的值的字符串。 1234# same thingloop: "&#123;&#123; query('inventory_hostnames', 'all') &#125;&#125;"loop: "&#123;&#123; lookup('inventory_hostnames', 'all', wantlist=True) &#125;&#125;" 循环控制Adding controls to loops loop_control关键字让你可以以有效的方式管理自己的循环。 限制循环输出Limiting loop output with label 当遍历复杂的数据结构，你的任务的控制台输出可能是巨大的。为了限制显示的输出，在loop_control中使用label。 123456789101112131415# 此任务输出仅显示每项的name字段- name: create servers digital_ocean: name: "&#123;&#123; item.name &#125;&#125;" state: present loop: - name: server1 disks: 3gb ram: 15Gb network: nic01: 100Gb nic02: 10Gb ... loop_control: label: "&#123;&#123; item.name &#125;&#125;" 暂停循环Pausing within a loop 要控制每个项的执行之间的时间(seconds)，在loop_control中使用pause。 12345678910# main.yml- name: create servers, pause 3s before creating next digital_ocean: name: "&#123;&#123; item &#125;&#125;" state: present loop: - server1 - server2 loop_control: pause: 3 追踪流程Tracking progress through a loop with index_var 要追踪你在循环的位置，在loop_control中使用index_var。 123456789- name: count our fruit debug: msg: "&#123;&#123; item &#125;&#125; with index &#123;&#123; my_idx &#125;&#125;" loop: - apple - banana - pear loop_control: index_var: my_idx inner and outer variable namesDefining inner and outer variable names with loop_var 可使用include_tasks嵌套两个循环任务。然而，默认情况下Ansible为每个循环item设置循环变量。This means the inner, nested loop will overwrite the value of item from the outer loop.你可以在loop_control中使用loop_var来为每个循环指定变量名。 123456789101112131415- include_tasks: inner.yml loop: - 1 - 2 - 3 loop_control: loop_var: outer_item# inner.yml- debug: msg: "outer item=&#123;&#123; outer_item &#125;&#125; inner item=&#123;&#123; item &#125;&#125;" loop: - a - b - c 扩展的循环变量Extended loop variables 在循环控制中使用extended选项来获取扩展的循环信息： 12loop_control: extended: yes 1234567891011Variable Descriptionansible_loop.allitems The list of all items in the loopansible_loop.index The current iteration of the loop. (1 indexed)ansible_loop.index0 The current iteration of the loop. (0 indexed)ansible_loop.revindex The number of iterations from the end of the loop (1 indexed)ansible_loop.revindex0 The number of iterations from the end of the loop (0 indexed)ansible_loop.first True if first iterationansible_loop.last True if last iterationansible_loop.length The number of items in the loopansible_loop.previtem The item from the previous iteration of the loop. Undefined during the first iteration.ansible_loop.nextitem The item from the following iteration of the loop. Undefined during the last iteration. 从with_x迁移到loopMigrating from with_X to loop 从Ansible 2.5开始，执行循环的推荐的方式是使用新的loop关键字来取代with_x格式的循环。 在许多情况下，loop语法是使用过滤器的更好的表达，而不是更复杂的query或lookup。 1234567891011121314# with_list被loop替代- name: with_list debug: msg: "&#123;&#123; item &#125;&#125;" with_list: - one - two- name: with_list -&gt; loop debug: msg: "&#123;&#123; item &#125;&#125;" loop: - one - two 12345678910# with_items被loop和flatten过滤器替代- name: with_items debug: msg: "&#123;&#123; item &#125;&#125;" with_items: "&#123;&#123; items &#125;&#125;"- name: with_items -&gt; loop debug: msg: "&#123;&#123; item &#125;&#125;" loop: "&#123;&#123; items|flatten(levels=1) &#125;&#125;" 123456789101112# with_indexed_items被loop, flatten, loop_control.index_var替代- name: with_indexed_items debug: msg: "&#123;&#123; item.0 &#125;&#125; - &#123;&#123; item.1 &#125;&#125;" with_indexed_items: "&#123;&#123; items &#125;&#125;"- name: with_indexed_items -&gt; loop debug: msg: "&#123;&#123; index &#125;&#125; - &#123;&#123; item &#125;&#125;" loop: "&#123;&#123; items|flatten(levels=1) &#125;&#125;" loop_control: index_var: index 12345678910# with_flattened被loop和flatten替代- name: with_flattened debug: msg: "&#123;&#123; item &#125;&#125;" with_flattened: "&#123;&#123; items &#125;&#125;"- name: with_flattened -&gt; loop debug: msg: "&#123;&#123; item &#125;&#125;" loop: "&#123;&#123; items|flatten &#125;&#125;" 123456789101112# with_together被loop和zip替代- name: with_together debug: msg: "&#123;&#123; item.0 &#125;&#125; - &#123;&#123; item.1 &#125;&#125;" with_together: - "&#123;&#123; list_one &#125;&#125;" - "&#123;&#123; list_two &#125;&#125;"- name: with_together -&gt; loop debug: msg: "&#123;&#123; item.0 &#125;&#125; - &#123;&#123; item.1 &#125;&#125;" loop: "&#123;&#123; list_one|zip(list_two)|list &#125;&#125;" 123456789101112131415# with_dict可通过loop和 dictsort或dict2items替代- name: with_dict debug: msg: "&#123;&#123; item.key &#125;&#125; - &#123;&#123; item.value &#125;&#125;" with_dict: "&#123;&#123; dictionary &#125;&#125;"- name: with_dict -&gt; loop (option 1) debug: msg: "&#123;&#123; item.key &#125;&#125; - &#123;&#123; item.value &#125;&#125;" loop: "&#123;&#123; dictionary|dict2items &#125;&#125;"- name: with_dict -&gt; loop (option 2) debug: msg: "&#123;&#123; item.0 &#125;&#125; - &#123;&#123; item.1 &#125;&#125;" loop: "&#123;&#123; dictionary|dictsort &#125;&#125;" 1234567891011# with_sequence被loop, range, format替代- name: with_sequence debug: msg: "&#123;&#123; item &#125;&#125;" with_sequence: start=0 end=4 stride=2 format=testuser%02x- name: with_sequence -&gt; loop debug: msg: "&#123;&#123; 'testuser%02x' | format(item) &#125;&#125;" # range is exclusive of the end point loop: "&#123;&#123; range(0, 4 + 1, 2)|list &#125;&#125;" 123456789101112# with_subelements被loop, subelements替代- name: with_subelements debug: msg: "&#123;&#123; item.0.name &#125;&#125; - &#123;&#123; item.1 &#125;&#125;" with_subelements: - "&#123;&#123; users &#125;&#125;" - mysql.hosts- name: with_subelements -&gt; loop debug: msg: "&#123;&#123; item.0.name &#125;&#125; - &#123;&#123; item.1 &#125;&#125;" loop: "&#123;&#123; users|subelements('mysql.hosts') &#125;&#125;" 123456789101112# with_nested/with_cartesian被loop, product替代- name: with_nested debug: msg: "&#123;&#123; item.0 &#125;&#125; - &#123;&#123; item.1 &#125;&#125;" with_nested: - "&#123;&#123; list_one &#125;&#125;" - "&#123;&#123; list_two &#125;&#125;"- name: with_nested -&gt; loop debug: msg: "&#123;&#123; item.0 &#125;&#125; - &#123;&#123; item.1 &#125;&#125;" loop: "&#123;&#123; list_one|product(list_two)|list &#125;&#125;" 12345678910# with_random_choice被random替代- name: with_random_choice debug: msg: "&#123;&#123; item &#125;&#125;" with_random_choice: "&#123;&#123; my_list &#125;&#125;"- name: with_random_choice -&gt; loop (No loop is needed here) debug: msg: "&#123;&#123; my_list|random &#125;&#125;" tags: random BlockBlocks: https://docs.ansible.com/ansible/latest/user_guide/playbooks_blocks.html 块允许任务的逻辑分组，并在play中错误处理。大多数可以适用于单任务的也可适用于块(block)，这使得它很容易设置数据或常见指令到任务。这并不意味着该指令影响块自身，而是有一个块包围的任务继承。 1234567891011121314151617181920212223tasks: - name: Install, configure, and start Apache block: - name: install httpd and memcached yum: name: - httpd - memcached state: present - name: apply the foo config template template: src: templates/src.j2 dest: /etc/foo.conf - name: start service bar and enable it service: name: bar state: started enabled: True when: ansible_facts['distribution'] == 'CentOS' become: true become_user: root ignore_errors: yes 在上面的栗子中，块中3个任务中的每一个附加在when条件后，在任务上下文评估之后都将执行。 块中的任务名在Ansible 2.3时可用。建议在所有任务中使用名称，无论是块还是其它地方。 块错误处理Blocks error handling 块同样介绍了类似于大多数编程语言的异常处理的错误处理的方法。块仅处理任务的失败(failed)状态。一个糟糕的任务定义或主机不可达不是rescuable错误。 12345678910111213# block error handling exampletasks: - name: Handle the error block: - debug: msg: 'I execute normally' - name: i force a failure command: /bin/false - debug: msg: 'I never execute, due to the above task failing, :-(' rescue: - debug: msg: 'I caught an error, can do stuff here to fix it, :-)' always部分，无论什么任务状态都将会运行。 1234567891011- name: Always do X block: - debug: msg: 'I execute normally' - name: i force a failure command: /bin/false - debug: msg: 'I never execute :-(' always: - debug: msg: "This always executes, :-)" 高级的playbook功能Advanced Playbooks Features: https://docs.ansible.com/ansible/latest/user_guide/playbooks_special_topics.html 下面有许多playbook功能不需要每个人都去学习，但可以为特定应用提供有用的功能。浏览这些话题，因为你可能找有一些有用的技巧。 特权晋升 异步操作和轮询Asynchronous Actions and Polling: https://docs.ansible.com/ansible/latest/user_guide/playbooks_async.html 默认情况下，playbook块中的任务，直到任务在每个节点上完成后连接才会断开。这可能不总是可取的，或者你需要运行超过ssh timeout的操作。 限时后台操作(Time-limited background operations) 你可以在后台运行长时间运行的操作，之后再检查它们的状态。例如，异步地在后台执行long_running_operation： 123456# -B 超时时间， -p 轮询数ansible all -B 3600 -P 0 -a "/usr/bin/long_running_operation --do-stuff"# async_status模块 检查状态ansible web1.example.com -m async_status -a "jid=488359678239.2844" 轮询模式是智能的，所以在轮询将在任意机器上开始之前所有的工作都将启动。如果想要所有工作快速开始，请确保使用足够高的--forks。在超时之后，远程节点上的进程将会被终止。 通常，你只需在后台长时间运行shell命令或软件更新。后台复制模块不会进行文件传输。 为了避免阻塞或超时问题，你可以使用异步模式来一次运行你的所有任务，并轮询直到它们完成。 异步模式的行为依赖于poll值。 Avoid connection timeouts: poll &gt; 0 当poll是正值，playbook仍然会阻塞任务直到它完成、失败或超时。 要异步启动任务，请指定其最大运行实践和要轮询状态的频率。如果未指定poll，则默认由DEFAULT_POLL_INTERVAL设置。 12345678---- hosts: all remote_user: root tasks: - name: simulate long running op (15 sec), wait for up to 45 sec, poll every 5 sec command: /bin/sleep 15 async: 45 poll: 5 Concurrent tasks: poll=0 当poll为0时，Ansible将启动任务，并立即移动到下一个而不必等待结果。 从序列试图这点是异步编程：任务现在可以同时运行。playbook将结束而不检查异步返回。异步任务将执行根据async的值，直到它们完成、失败或超时。 12345678---- hosts: all remote_user: root tasks: - name: simulate long running op, allow to run for 45 sec, fire and forget command: /bin/sleep 15 async: 45 poll: 0 检查模式Check Mode: https://docs.ansible.com/ansible/latest/user_guide/playbooks_checkmode.html DebuggerPlaybook Debugger Ansible包含了debugger作为策略插件的一部分。此调试器允许你调试任务。你可以在任务的上下文中访问所有的调试器的功能，以帮助解决失败的问题。 有多种方式来调用调试器。 使用debugger关键字(Using the debugger keyword) 可在提供name属性的块中使用debugger关键字，如paly, role, block, task。debugger关键字接受下列值： always: 总是调用调试器 never: 绝不调用调试器 on_failed: 任务失败才调用调试器 on_skipped: 任务跳过才调用调试器 全局配置： 1234# on a task- name: execute a command command: false debugger: on_failed 12345678# on a play- name: play hosts: all debugger: on_skipped tasks: - name: Execute a command command: true when: False 在特定层级上： 1234567- name: Play hosts: all debugger: never tasks: - name: Execute a command command: false debugger: on_failed 配置或环境变量(Configuration or environment variable) 123# ansible.cfg[defaults]enable_task_debugger = True 12# environment variableANSIBLE_ENABLE_TASK_DEBUGGER=True ansible-playbook -i hosts site.yml 策略(As a Strategy) 要使用debug策略，改变strategy属性： 1234- hosts: test strategy: debug tasks: ... 123# ansible.cfg[defaults]strategy = debug 12# environment variableANSIBLE_STRATEGY=debug 可用命令(Available Commands) 打印值： 12345678910111213141516171819[192.0.2.10] TASK: install package (debug)&gt; p taskTASK: install package[192.0.2.10] TASK: install package (debug)&gt; p task.args&#123;u&apos;name&apos;: u&apos;&#123;&#123; pkg_name &#125;&#125;&apos;&#125;[192.0.2.10] TASK: install package (debug)&gt; p task_vars&#123;u&apos;ansible_all_ipv4_addresses&apos;: [u&apos;192.0.2.10&apos;], u&apos;ansible_architecture&apos;: u&apos;x86_64&apos;, ...&#125;[192.0.2.10] TASK: install package (debug)&gt; p task_vars[&apos;pkg_name&apos;]u&apos;bash&apos;[192.0.2.10] TASK: install package (debug)&gt; p host192.0.2.10[192.0.2.10] TASK: install package (debug)&gt; p result._result&#123;&apos;_ansible_no_log&apos;: False, &apos;changed&apos;: False, u&apos;failed&apos;: True, ... u&apos;msg&apos;: u&quot;No package matching &apos;not_exist&apos; is available&quot;&#125; 滚动升级Delegation, Rolling Updates, and Local Actions: https://docs.ansible.com/ansible/latest/user_guide/playbooks_delegation.html 设置环境Setting the Environment: https://docs.ansible.com/ansible/latest/user_guide/playbooks_environment.html environment关键字可以允许你为远程目标主机设置环境变量。例如，需要为http请求设置一个代理。获取其它工具需要的环境变量。 123456789- hosts: all remote_user: root tasks: - name: Install cobbler package: name: cobbler state: present environment: http_proxy: http://proxy.example.com:8080 也可以存储在一个变量里： 123456789101112- hosts: all remote_user: root # here we make a variable named "proxy_env" that is a dictionary vars: proxy_env: http_proxy: http://proxy.example.com:8080 tasks: - name: Install cobbler package: name: cobbler state: present environment: "&#123;&#123; proxy_env &#125;&#125;" 特定语言版本管理器Working With Language-Specific Version Managers 一些特定语言版本管理器(如nvm)要求，而这些工具在使用中都要求环境变量。挡手动使用这些工具，通常需要在配置文件中添加一些环境变量，在Ansible中，你可使用enviroment代替： 123456789101112131415161718192021222324252627282930313233---### A playbook demonstrating a common npm workflow:# - Check for package.json in the application directory# - If package.json exists:# * Run npm prune# * Run npm install- hosts: application become: false vars: node_app_dir: /var/local/my_node_app environment: NVM_DIR: /var/local/nvm PATH: /var/local/nvm/versions/node/v4.2.1/bin:&#123;&#123; ansible_env.PATH &#125;&#125; tasks: - name: check for package.json stat: path: &apos;&#123;&#123; node_app_dir &#125;&#125;/package.json&apos; register: packagejson - name: npm prune command: npm prune args: chdir: &apos;&#123;&#123; node_app_dir &#125;&#125;&apos; when: packagejson.stat.exists - name: npm install npm: path: &apos;&#123;&#123; node_app_dir &#125;&#125;&apos; when: packagejson.stat.exists 错误处理Error Handling In Playbooks: https://docs.ansible.com/ansible/latest/user_guide/playbooks_error_handling.html Ansible通常有默认值来确保检查命令和模块的返回码和是否失败，进行错误处理，除非你做了决定。 忽略错误命令(Ignoring Failed Commands) 一般来说，如果主机上有任务失败，playbook将停止执行。有时，你想让它继续进行： 123- name: this will not be counted as a failure command: /bin/false ignore_errors: yes 重置不可达的主机(Resetting Unreachable Hosts) 连接失败将设置主机为不可达(UNREACHABLE)，它将从运行活跃主机列表中删除。可以使用meta: clear_host_errors来设置。 处理程序和失败(Handlers and Failure) 当主机上的一个任务失败时，先前通知(notify)的处理程序(handler)将不会在此主机上运行。例如，任务更新配置文件并通知处理程序去重启服务。如果任务以后的同一个play失败，则服务不会重启尽管配置已经更改。 可以使用--force-handlers命令行选项来改变此行为。或在play中包含force_handlers: True，或在ansible配置中包含force_handlers = True。当处理程序被强制执行，无论任务成功与否它们都会执行。 控制如何定义失败(Controlling What Defines Failure) Ansible允许你使用filed_when条件来定义失败。栗子： 1234- name: Fail task when the command error output prints FAILED command: /usr/bin/example-command -x -y -z register: command_result failed_when: "'FAILED' in command_result.stderr" 覆盖改变的结果(Overriding The Changed Result) 当一个模块运行，它通常会基于机器状态是否被影响而报告changed状态。 有时候你知道，基于返回码或返回结果，它并没有发生改变，并希望去覆盖changed结果，使它不出现在报告输出里： 123456- command: /bin/fake_command register: result ignore_errors: True changed_when: - '"ERROR" in result.stderr' - result.rc == 2 终止play(Aborting the play) 有时需要终止失败的play，而不是为某主机跳过剩余任务。 any_errors_fatal选项将终止Play，并防止任何后续的plays运行。当遇到一个错误，当前批次的所有主机都有机会完成致命的任务，然后play的执行停止。any_errors_fatal可在play或block层级设置： 12345678910- hosts: somehosts any_errors_fatal: true roles: - myrole- hosts: somehosts tasks: - block: - include_tasks: mytasks.yml any_errors_fatal: true 使用块(blocks) 大多数可应用到单个任务的也可应用到块，这使得它更容易设置数据或指定到任务。块只处理任务的失败(failed)状态。 123456789101112tasks:- name: Handle the error block: - debug: msg: 'I execute normally' - name: i force a failure command: /bin/false - debug: msg: 'I never execute, due to the above task failing, :-(' rescue: - debug: msg: 'I caught an error, can do stuff here to fix it, :-)' 高级语法Advanced Syntax: https://docs.ansible.com/ansible/latest/user_guide/playbooks_advanced_syntax.html 高级的YANL语法可以给你在Ansible的YAML文件中更多控制数据的地方。你可以在PyYAML文档中找到等多Python特定化的YAML信息。 不安全和原生字符串Unsafe or Raw Strings Ansible提供了一个内部的数据类型，用来声明变量不安全(unsafe)。这意味着变量中保存的数据应为不安全，防止字符串被替换和披露。 Jinja2包含了转义，或告诉Jinja2不渲染数据，如...。 12# 使用 !unsafe 标签my_unsafe_variable: !unsafe &apos;this variable has &#123;&#123; characters that should not be treated as a jinja2 template&apos; 123456---hosts: allvars: my_unsafe_variable: !unsafe 'unsafe value'tasks: ... 锚和别名YAML anchors and aliases: sharing variable values YAML的锚(anchor)和别名(aliase)可以帮助你在灵活的方式中定义、维护和使用共享变量。使用&amp;定义一个锚，使用别名(*)指向它。 1234567891011121314# 锚内设置了3个变量，别名使用其它2个，并覆盖第3个---...vars: app1: jvm: &amp;jvm_opts opts: '-Xms1G -Xmx2G' port: 1000 path: /usr/lib/app1 app2: jvm: &lt;&lt;: *jvm_opts path: /usr/lib/app2... path的值由合并操作符(&lt;&lt;)所合并。 使用插件Working With Plugins: https://docs.ansible.com/ansible/latest/plugins/plugins.html 插件时扩展Ansible的核心功能。Ansible使用插件架构来实现丰富的、灵活的、可扩展的功能集。 Ansible ships附带了许多插件，你也可以自己编写。 Action Plugins Become Plugins Cache Plugins Callback Plugins Cliconf Plugins Connection Plugins Httpapi Plugins Inventory Plugins Lookup Plugins Netconf Plugins Shell Plugins Strategy Plugins Vars Plugins Filters Tests Plugin Filter Configuration 提示和输入Prompts: https://docs.ansible.com/ansible/latest/user_guide/playbooks_prompts.html 当运行playbook时，你可能希望提示某些用户输入信息，可使用vars_prompt来完成。一个常见的用途可能是要求输入敏感的数据，但不希望记录。 1234567891011---- hosts: all vars_prompt: - name: username prompt: "What is your username?" private: no - name: password prompt: "What is your password?" tasks: - debug: msg: 'Logging in as &#123;&#123; username &#125;&#125;' 标签Tags: https://docs.ansible.com/ansible/latest/user_guide/playbooks_tags.html 如果你有一个大型的playbook，它可能成为一个有用的能够运行playbook的一个特定部分，而不是playbook中的所有。Ansible支持使用标签(tags)来完成。 标签可应用于Ansible的许多结构，但最简单的方法是单个任务。 栗子： 1234567891011121314tasks:- yum: name: - httpd - memcached state: present tags: - packages- template: src: templates/src.j2 dest: /etc/foo.conf tags: - configuration 当你执行playbook，你可以用两种方法基于标签过滤任务： 在命令行使用--tags或--skip-tags选项； 在Ansible配置中，使用TAGS_RUN或TAGS_SKIP选项。 12345678# 仅执行某个标签ansible-playbook example.yml --tags &quot;configuration,packages&quot;# 跳过某个标签ansible-playbook example.yml --skip-tags &quot;packages&quot;# 产看标签执行情况ansible-playbook example.yml --tags &quot;configuration,packages&quot; --list-tasks 标签重用Tag Reuse 控制playbook执行Controlling playbook execution: strategies and more: https://docs.ansible.com/ansible/latest/user_guide/playbooks_strategies.html 默认情况下，Ansible在使用5forks任意主机上开始下一个任务之前在所有被play影响的主机上运行每个任务。如果你想要改变此默认的行为，你可以使用不同的策略插件，改变fork数，或应用几个play级别的关键字（如serial）。 选择策略Selecting a strategy linear strategy: https://docs.ansible.com/ansible/latest/plugins/strategy/linear.html#linear-strategy debug strategy: https://docs.ansible.com/ansible/latest/plugins/strategy/debug.html#debug-strategy free strategy: https://docs.ansible.com/ansible/latest/plugins/strategy/free.html#free-strategy 1234- hosts: all strategy: free tasks: ... 设置fork数Setting the number of forks 1234567# ansible.cfg[defaults]forks = 30# or cliansible-playbook -f 30 my_playbook.ym 使用关键字控制执行Using keywords to control execution play level的关键字会影响paly的执行。 最常见的是serial，还有throttle, ignore_errors, ignore_unreachable, any_errors_fatal。 最佳实践Best Practices: https://docs.ansible.com/ansible/latest/user_guide/playbooks_best_practices.html 使用Ansible和playbooks的一些技巧。 你可以在ansible-examples仓库中找到最佳用法。 内容组织Content Organization 下面将介绍组织Playbook内容的多种方式。你的ansible的使用应该适合你的需求，因此你可以按需组合各种方法。 组织ansible playbook内容的一个关键方式是role。你应该理解它。 目录布局Directory Layout 栗子： 1234567891011121314151617181920212223242526272829303132333435363738394041staging # inventory file for staging environmentgroup_vars/ group1.yml # here we assign variables to particular groups group2.ymlhost_vars/ hostname1.yml # here we assign variables to particular systems hostname2.ymllibrary/ # if any custom modules, put them here (optional)module_utils/ # if any custom module_utils to support modules, put them here (optional)filter_plugins/ # if any custom filter plugins, put them here (optional)site.yml # master playbookwebservers.yml # playbook for webserver tierdbservers.yml # playbook for dbserver tierroles/ common/ # this hierarchy represents a "role" tasks/ # main.yml # &lt;-- tasks file can include smaller files if warranted handlers/ # main.yml # &lt;-- handlers file templates/ # &lt;-- files for use with the template resource ntp.conf.j2 # &lt;------- templates end in .j2 files/ # bar.txt # &lt;-- files for use with the copy resource foo.sh # &lt;-- script files for use with the script resource vars/ # main.yml # &lt;-- variables associated with this role defaults/ # main.yml # &lt;-- default lower priority variables for this role meta/ # main.yml # &lt;-- role dependencies library/ # roles can also include custom modules module_utils/ # roles can also include custom module_utils lookup_plugins/ # or other types of plugins, like lookup in this case webtier/ # same kind of structure as "common" was above, done for the webtier role monitoring/ # "" fooapp/ # "" 可选的目录布局Alternative Directory Layout 此布局为大型环境提供了更多灵活性，栗子： 1234567891011121314151617181920212223242526272829303132inventories/ production/ hosts # inventory file for production servers group_vars/ group1.yml # here we assign variables to particular groups group2.yml host_vars/ hostname1.yml # here we assign variables to particular systems hostname2.yml staging/ hosts # inventory file for staging environment group_vars/ group1.yml # here we assign variables to particular groups group2.yml host_vars/ stagehost1.yml # here we assign variables to particular systems stagehost2.ymllibrary/module_utils/filter_plugins/site.ymlwebservers.ymldbservers.ymlroles/ common/ webtier/ monitoring/ fooapp/ 使用云动态资产Use Dynamic Inventory With Clouds 如果你使用云服务提供商，你不应该在静态文件中管理你的资产。请参考Working with dynamic inventory 如何区分测试与生产How to Differentiate Staging vs Production 如果管理静态清单，经常会问到如何区分不同类型的环境。下面的例子提供了一个好方法。分组的类似方法可以适用动态清单。 123456789101112131415161718192021222324252627282930313233343536# file: production[atlanta_webservers]www-atl-1.example.comwww-atl-2.example.com[boston_webservers]www-bos-1.example.comwww-bos-2.example.com[atlanta_dbservers]db-atl-1.example.comdb-atl-2.example.com[boston_dbservers]db-bos-1.example.com# webservers in all geos[webservers:children]atlanta_webserversboston_webservers# dbservers in all geos[dbservers:children]atlanta_dbserversboston_dbservers# everything in the atlanta geo[atlanta:children]atlanta_webserversatlanta_dbservers# everything in the boston geo[boston:children]boston_webserversboston_dbservers 组和主机变量Group And Host Variables 1234---# file: group_vars/atlantantp: ntp-atlanta.example.combackup: backup-atlanta.example.com 1234---# file: group_vars/webserversapacheMaxRequestsPerChild: 3000apacheMaxClients: 900 1234---# file: group_vars/allntp: ntp-boston.example.combackup: backup-boston.example.com 顶级playbook通过角色分离Top Level Playbooks Are Separated By Role 1234---# file: site.yml- import_playbook: webservers.yml- import_playbook: dbservers.yml 123456---# file: webservers.yml- hosts: webservers roles: - common - webtier 这里，我们可以选择运行site.yml来配置我们的整个基础架构，或者通过运行webservers.yml来只运行一个子集。类似于下面： 12ansible-playbook site.yml --limit webserversansible-playbook webservers.yml 角色的任务和处理程序组织Task And Handler Organization For A Role 下面解释一个NTP任务是如何工作： 12345678910111213141516171819202122# file: roles/common/tasks/main.yml- name: be sure ntp is installed yum: name: ntp state: present tags: ntp- name: be sure ntp is configured template: src: ntp.conf.j2 dest: /etc/ntp.conf notify: - restart ntpd tags: ntp- name: be sure ntpd is running and enabled service: name: ntpd state: started enabled: yes tags: ntp 这是一个处理程序(handler)文件栗子： 123456---# file: roles/common/handlers/main.yml- name: restart ntpd service: name: ntpd state: restarted 什么组织启用What This Organization Enables 123456789101112131415161718# 重新配置基础服务ansible-playbook -i production site.yml# 重新配置NTPansible-playbook -i production site.yml --tags ntp# 重新配置webserversansible-playbook -i production webservers.yml# bostonansible-playbook -i production webservers.yml --limit boston# boston first 10ansible-playbook -i production webservers.yml --limit boston[0:9]# ad-hocansible boston -i production -m command -a &apos;/sbin/reboot&apos; 部署于配置组织Deployment vs Configuration Organization 上面的配置模型是一个典型的配置拓扑。当进行多级部署中，会有一些额外的playbook（hop between tiers to roll out an application）。 测试与生产Staging vs Production 如上所述，让staging(testing)和production环境分离是为不同的环境使用单独的清单文件。你的环境不一定是相同的大小，你可以使用变量来控制它们。 滚动更新Rolling Updates 理解serial关键字。 注意状态Always Mention The State state参数对许多模块是可选的。如state=present或state=absent。 通过角色分组Group By Roles 一个系统可以在多个组。这使得playbook基于角色来选择目标主机。以及使用该组变量系统来分配角色特定的变量。 操作系统和发行版本Operating System and Distribution Variance 当在两个不同的操作系统之间处理一个参数时，处理它的一个好方法是使用group_by模块。 1234567891011121314--- - name: talk to all hosts just so we can learn about them hosts: all tasks: - name: Classify hosts depending on their OS distribution group_by: key: os_&#123;&#123; ansible_facts['distribution'] &#125;&#125; # now just on the CentOS hosts... - hosts: os_CentOS gather_facts: False tasks: - # tasks that only happen on CentOS go here 123456- hosts: all tasks: - name: Set OS distribution dependent variables include_vars: "os_&#123;&#123; ansible_facts['distribution'] &#125;&#125;.yml" - debug: var: asdf 使用playbook捆绑ansible模块Bundling Ansible Modules With Playbooks 如果playbook有相对于其它YAML文件的./library目录，此目录可以用来添加ansible module，它会自动在ansible模块路径。这是一个保持模块与playbook在一起的好方法。 空白和注释Whitespace and Comments 空白和注释有利于文件可读性，值得使用。 任务命名Always Name Tasks 给任务建立一个正在做什么的名称。在运行时，playbook显示此名称。 使它简单Keep It Simple 当你能够简单地做事，那就简单地做。不要为了达到使用所有ansible功能而一起使用它们。使用你需要的。把复杂的事情简单化。 版本控制Version Control 使用版本控制来管理playbook。 变量和拱顶Variables and Vaults 当运行playbook，Ansible在未加密的文件中查找变量，并且所有敏感的变量来自加密文件。 一个最佳实践方法是在组下开始一个group_vars子目录。在此子目录内，创建两个名为vars和vault的文件。vars文件内定义所有需要的变量，包括敏感的。接下来，复制所有的敏感变量到vault文件或以vault_开头的文件。你应该在vars文件内使用Jinja2语法调整变量指向匹配的vault_文件，并确保vault文件是vault encrypted。 持续交付和滚动更新Playbook Example: Continuous Delivery and Rolling Upgrades: https://docs.ansible.com/ansible/latest/user_guide/guide_rolling_upgrade.html 什么是持续交付What is continuous delivery Continuous delivery(CD)是指经常更新你的软件应用程序。 特权晋升Understanding privilege escalation: become: https://docs.ansible.com/ansible/latest/user_guide/become.html Ansible使用现有的权限升级系统来执行具有root或其它权限的任务。此功能允许你成为(become)其它用户，与登录到远程机器不同，我们称之为become。become关键字利用现有的权限提升工具（如sudo, su, pfexec, doas, pbrun, dzdo, ksu, runas）。 使用你可以在任务、连接变量、命令行等控制become的使用。如果你以多种方式设置了特权提升，请注意优先级。 所有become plugins完整的列表: https://docs.ansible.com/ansible/latest/plugins/become.html#become-plugin-list become 你可在play或task层设置become指令。你可以设置连接变量，从不同主机之间覆盖它们。 12345678# 激活特权提升become: yes# 默认rootbecome_user: xxx# 参考become plugins，可在ansible.cfg中配置。默认sudobecome_method: sudo# 为role或task执行特定标志become_flags: xxx 栗子： 1234567891011121314151617- name: Ensure the httpd is running become: yes service: name: httpd state: started- name: Run a command as the apache user command: somecommand become: yes become_user: apache- name: Run a command as nobody command: somecommand become: yes become_method: su become_user: nobody become_flags: &apos;-s /bin/sh&apos; 连接变量 Become connection variables 你可以定义不同的选型来管理node或group。你可以在资产中定义这些变量，或将其作为正常的变量使用。 1234567ansible_becomeansible_become_methodansible_become_useransible_become_password# 栗子webserver ansible_user=manager ansible_become=yes 命令行选项 1234--ask-become-pass, -K--become, -b--become-method=BECOME_METHOD--become-user=BECOME_USER 风险和局限性Risks and limitations of become 虽然权限提升是很直观的，但它如何工作也有一些限制。用户应该知道这些，以避免意外。 成为一个非特权用户的风险Risks of becoming an unprivileged user Ansible模块由第一个参数带入模块文件，然后将其复制到远程主机，最后在远程机器上执行它。 如果模块文件不使用become，当become_ueer为root时，或当远程机器被设置为root时，一切都好。在这些情况下，Ansible创建具有只允许由所述用户和root读取，或只允许由所述非特权用户切换到读取权限模块文件。 然而，当连接用户和become_user都不是特权用户，模块文件被写入需要由Ansible设置为用户可读。在这种情况下，Ansible使得模块文件世界可读的Ansible模块执行的持续时间。一旦模块执行完毕，Ansible删除临时文件。 不是所有连接插件都支持Not supported by all connection plugins 特权升级方法也必须由连接使用的插件支持。 每个主机只能启用一个方法Only one method may be enabled per host 特权提升必须通用Privilege escalation must be general 你不能限制权限提升某些命令的权限。 VaultAnsible Vault: https://docs.ansible.com/ansible/latest/user_guide/vault.html Ansible Vault是Ansible的一个功能，可以让你在加密的文件中保存敏感数据（如密码、密钥），而不是像普通文本或playbooks或roles中。这些vault文件可以分布或放置在版本控制中。 要启用此功能，使用命令行选型-ansible-vault，和--vault-password-file。 ModulesAnsible Modules: https://docs.ansible.com/ansible/latest/user_guide/modules.html Ansible包含了大量的模块(module library)，可以直接在远程主机或通过playbook执行。 用户也可以编写自己的模块。这些模块可以控制系统资源（服务、包、文件…），或执行系统命令。 模块介绍Introduction to modules: https://docs.ansible.com/ansible/latest/user_guide/modules_intro.html 12# adhocansible webservers -m service -a "name=httpd state=started" 12345# playbook- name: restart webserver service: name: httpd state: restarted 返回值Return Values: https://docs.ansible.com/ansible/latest/reference_appendices/common_return_values.html Ansible模块通常正常返回一个可以注册为一个变量的数据结构，或直接看到由ansible程序输出。每个模块都可选的记录自己唯一的返回值。 本章节包含的返回值适用于所有模块。 Common backup_file changed failed invocation msg rc results skipped stderr stderr_lines stdout stdout_lines Internal use ansible_facts exception warning deprecations 模块索引Module Index: https://docs.ansible.com/ansible/latest/modules/modules_by_category.html 插件Working With Plugins: https://docs.ansible.com/ansible/latest/plugins/plugins.html 插件是一段代码，可以扩充Ansible的核心功能。Ansible使用插件架构，以实现丰富的、灵活的、可扩展的功能集。 Ansible附带了一些方便的插件，你也可以很容易地编写自己的插件。 collectionscollections: https://docs.ansible.com/ansible/latest/user_guide/collections_using.html Collections是Ansible的内容分发格式，可以包括playbooks, roles, modules, plugins。你可以通过Ansible Galaxy安装和使用collections。 开发指南Developer Guide: https://docs.ansible.com/ansible/latest/dev_guide/index.html Ansible GalaxyAnsible Galaxy: https://docs.ansible.com/ansible/latest/galaxy/user_guide.html Ansible Galaxy是一个查找、分享、下载社区开发的roles的网站。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Ansible</tag>
        <tag>Automation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Prometheus]]></title>
    <url>%2F2018%2F09%2F11%2FPrometheus%2F</url>
    <content type="text"><![CDATA[参考： Prometheus文档： https://prometheus.io/docs GitHub: https://github.com/prometheus/ PrometheusAlert: https://github.com/feiyu563/PrometheusAlert 环境： CentOS7x86_64 Prometheus v2.14 介绍Introduction 概述 Prometheus是什么What is Prometheus? Prometheus是一个最初在SoundCloud上构建的开源监控系统和报警工具包。现在是一个独立的开源项目，由社区进行维护。 功能(Features)Prometheus的主要特点： 具有由度量名称(metric name)和键值对(key-value)标识的时间序列(time series)数据的多维(multi-dimensional)数据模型 灵活的查询语言，以利用此维度 不依赖分布式存储(distributed storage)，单个服务器节点是自治的(autonomous) 时间序列集合通过HTPP的pull model发生 push时间序列通过中间网关(intermediary gateway)的支持 通过服务发现或静态配置来发现目标 图形和仪表盘支持多种模式 组件(Components)Prometheus系统由多个组件构成，其中某些组件是可选的： 主要的Prometheus Server，用于存储时间序列数据 client libraries，用于检测应用程序代码 push gateway，用于支持短暂的(short-lived)工作 exporters，用于服务的特殊目的 alertmanager，用于处理报警 各种支持工具 架构(Architecture)Prometheus的体系结构和系统组件图： 什么时候适合When does it fit? Prometheus适用于记录任何纯数字时间序列。它既适用于以机器为中心的监控，也适用于高度动态的面向服务架构的监控。在微服务的世界中，它对多维数据收集和查询的支持是一种特殊的优势。Prometheus专为提高可靠性而设计，是你在断电期间可以快速诊断问题的系统。每个Prometheus Server都是独立的，不依赖于网络存储或其它远程服务。当基础架构其它部分损坏时，你仍可以依赖它，并且你不需要设置大量的基础架构来使用它。 什么时候不适合When does it not fit? Prometheus重视可靠性。即使在系统故障情况下，你也可以随时查看有关系统的可用统计信息。如果你需要100%的准确度，Prometheus不是一个好的选择，你可能需要使用其它系统。 第一步步骤： 下载 配置 运行 使用表达式浏览器 使用图形接口 监控其它目标 术语GLOSSARY Alert是Prometheus正在开火的警报规则的结果。警报从Prometheus发送到AlterManger。 Alertmanager接收警报，将它们聚合成组，删除重复数据，应用静音、限制，然后发送电子邮件等通知。 Bridge是一个从Client Library中获取样本并将它们暴露给 non-Prometheus 监控系统的组件。例如，Python、Java、Go…客户端可将指标导出到Graphite。 Client library是某种语言的库(Go, Java, Python…)，可以直接检测代码，编写自定义收集器以从其它系统中收集指标并将指标公开给Prometheus。 Collector是表示一组度量标准的 exporter 的一部分。如果它是直接检测的一部分，则可以是单个度量，如果是从另一个系统提取度量，则可以是许多度量。 Direct instrumentation作为源代码程序的一部分内联添加的检测。 Endpoint Exporter是一个公开Prometheus指标的程序，通常将 non-prometheus 格式的指标转换为 Prometheus 支持的格式。 Instance唯一标识作业中目标的标签 Job具有相同目的的目标集合 Notification代表一组多个警报 Promdash原生Prometheus仪表盘构建器。它已被弃用，并被 Grafana 取代 Prometheus通常指的是Prometheus System的核心程序，也可指整个监控系统。 PromQLPrometheus Query Language Pushgateway持续从批量作业中最新推出的指标 Remote Read允许从其它系统透明读取时间序列作为查询的一部分 Remote Read Adapter并非所有系统都支持远程读取。远程读取适配器便是用于此。 Remote Read EndpointPrometheus进行远程读取时的对象 Remote Write允许动态地将采集的样本发送到其它系统 Remote Write Adapter Remote Write Endpoint Sample时间序列中某个时间点的单个值，Prometheus中，每个样本都包含一个float64和ms精度的时间戳。 Silence防止报警 Target抓取对象的定义 FAQfaq: https://prometheus.io/docs/introduction/faq/ 概念CONCEPTS 数据模型Data model Prometheus从根本上将所有数据存储为时间序列(time series): 属于同一指标和同一标记维度的带时间戳值的流。除了存储时间序列，Prometheus还可以临时生成时间序列作为查询的结果。 指标名称和标签Metric names and labels 每个时间序列都是有指标名称(metric name)和一组键值对(也称为标签(label))来唯一标识。 指标名称： 可能包含ASCII字母，下划线，冒号。它必须匹配正则: [a-zA-Z_:][a-zA-Z0-9_:]*。标签启用Prometheus的维度数据模型： 指标类型metric types: https://prometheus.io/docs/concepts/metric_types/ Prometheus Client Library提供了四个核心指标类型。这些目前仅在客户端和在有线协议(wire protocol)中区分。Prometheus Server尚未使用的类型信息和所有数据合并为无类型(untyped)时间序列。这在未来可能改变。 Prometheus clinet使用文档: Go Java Python CounterCounter，只增不减的计数器。 Counter是一个累计指标，代表一个单调递增计数器，即只增不减，除非重启或被重置为0。例如，你可以使用counter来代表服务的请求数、已完成的任务数、错误的数量… 不要用counter来暴露一个可以减少的值。例如，不要对当前运行的进程数使用counter类型，使用gauge类型。 一般在定义counter类型指标的名称时，推荐使用xxx_total作为后缀名。（如http_request_total） 12345# 获取HTTP请求量的增长率rate(http_requests_total[5m])# 统计前十topk(10, http_requests_total) GaugeGauge，可以任意变化的仪表盘。 Gauge类型代表一个样本数据可以任意变化，即可增可减。通常用于像温度、内存使用率这种指标数据，也可表示能随时升降的计数（如当前的并发数）。 12345# 获取一段时间内的变化情况dalta(cpu_temp_celsius&#123;host=&quot;zeus&quot;&#125;[2h])# 简单线性回归，预测未来数据predict_linear(node_filesystem_free&#123;job=&quot;node&quot;&#125;[2h], 4 * 3600) &lt; 0 HistogramHistogram和Summary主用用于统计和分析样本的分布情况。 Histogram(直方图)在一段时间范围内对数据进行采样（通常是请求持续时间(request durations)和响应大小(response sizes)等），并将其计入可配置的存储桶(bucket)中，后续可通过指定区间筛选样本，也可以统计样本总数，最后一般将数据展示为直方图。 Histogram类型的样本会提供三种指标： 样本值分布在桶中的数量，命名为xxx_bucket{le=&quot;&lt;上边界&gt;&quot;}。标识指标值小于等于上边界所有样本数量。 所有样本值的大小总和，命名为xxx_sum。 样本总数，命名为xxx_count，值和xxx_bucket{le=&quot;+Inf}相同。 可使用histogram_quantile()函数来计算Histogram类型样本的分位数。 SummarySummary(摘要)与Histogram类似，表示一段时间内的数据采集结果（通常是请求持续时间或响应大小）。它直接存储了分位数，而不是通过区间来计算。 Summary类型的样本也提供了三种指标： 样本值的分位数分布情况，命名为xxx{quantile=&quot;&lt;φ&gt;&quot;}。 所有样本值的大小总和，命名为xxx_sum。 样本总数，命名为xxx_count。 作业和实例Job and Instance Prometheus配置文件中配置。 Prometheus 入门GETTING STARTED 本节介绍如何安装，配置，使用Prometheus的简单例子。你将在本地安装和运行Prometheus，将其配置为自我填充和示例应用程序，然后使用查询，规则和图表来使用收集的序列数据。 下载 下载地址: https://prometheus.io/download/ 123tar xvfz prometheus-*.tar.gzcd prometheus-* 配置和监控Prometheus通过在目标上通过HTTP endPoints来抓取指标，来收集受监控目标的指标。由于Prometheus也以相同的方式公开自身数据，它也可以获取和监测自身的健康状况。虽然Prometheus Server只收集有关自身的数据在实践中不是很有用，但它是一个很好的示例。如prometheus.yml示例配置文件： 12345678910111213141516171819global: scrape_interval: 15s # By default, scrape targets every 15 seconds. # Attach these labels to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: monitor: 'codelab-monitor'# A scrape configuration containing exactly one endpoint to scrape:# Here it's Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: 'prometheus' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:9090'] 启动启动后，可访问9090端口查看状态。可访问localhost:9090/metrics查看有关自身的相关指标。 12cd prometheus-2.3.2.linux-amd64./prometheus --config.file=&quot;prometheus.yml&quot; 使用表达式浏览器让我们看一下Prometheus收集的一些数据。要使用Prometheus的内建表达式浏览器(expression browser)，请跳转到http://localhost:9090/graph并选择Graph -&gt; Console，在其中输入表达式。绘制表达式图形同样在此操作。 12345678910#表达式prometheus_target_interval_length_seconds#表达式prometheus_target_interval_length_seconds&#123;quantile=&quot;0.99&quot;&#125;#计算返回的时间序列数count(prometheus_target_interval_length_seconds) 启动简单的目标启动一些示例目标让Prometheus获取。确保已安装Go表一起并设置了正常的GO PATH。 123456789101112131415161718mkdir ./sample &amp;&amp; cd samplegit clone https://github.com/prometheus/client_golang.gitcd client_golang/examples/randomgo get -dgo build# Start 3 example targets in separate terminals:./random -listen-address=:9091./random -listen-address=:9092./random -listen-address=:9093#访问http://localhost:9091/metriceshttp://localhost:9092/metriceshttp://localhost:9093/metrices 监控示例目标现在需要配置Prometheus来抓取目标。 1234567891011121314scrape_configs: - job_name: 'example-random' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:8080', 'localhost:8081'] labels: group: 'production' - targets: ['localhost:8082'] labels: group: 'canary' 重启Prometheus，检测rpc_durations_seconds metric来验证。 配置规则Configure rules for aggregating scraped data into new time series 聚合超过数千个时间序列的查询在计算ad-hoc时会变慢。为了提高效率，Prometheus允许你通过配置的规则将预录表达式预先记录到全新的持久时间序列中。 创建规则文件prometheus.rules.yml：123456#job_service:rpc_durations_seconds_count:avg_rate5mgroups:- name: example rules: - record: job_service:rpc_durations_seconds_count:avg_rate5m expr: avg(rate(rpc_durations_seconds_count[5m])) by (job, service) 要是Prometheus选择此新规则，需要修改Prometheus配置： 123456789101112131415161718192021222324252627282930313233global: scrape_interval: 15s # By default, scrape targets every 15 seconds. evaluation_interval: 15s # Evaluate rules every 15 seconds. # Attach these extra labels to all timeseries collected by this Prometheus instance. external_labels: monitor: &apos;codelab-monitor&apos;rule_files: - &apos;prometheus.rules.yml&apos;scrape_configs: - job_name: &apos;prometheus&apos; # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: [&apos;localhost:9090&apos;] - job_name: &apos;example-random&apos; # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: [&apos;localhost:8091&apos;, &apos;localhost:8092&apos;] labels: group: &apos;production&apos; - targets: [&apos;localhost:9093&apos;] labels: group: &apos;canary&apos; 重启Prometheus，使用job_service:rpc_durations_seconds_count:avg_rate5m metric验证。 安装 使用预编译的二进制文件 使用源码 使用Docker所有的Prometheus服务都可以作为 Docker image 来使用。Prometheus image 使用 volume 来存储实际的指标。对于生产部署，强烈建议使用 Data Volume Container 来升级数据的管理。 栗子： 123456#bind-mountdocker run -p 9090:9090 -v /tmp/prometheus.yml:/etc/prometheus.yml prom/prometheus#volumedocker run -p 9090:9090 -v /promethe-data prom/prometheus --config.file=/prometheus-data/prometheus.yml 自定义镜像 Dockerfile: 123FROM prom/prometheusADD prometheus.yml /etc/prometheus/xxx 构建： 1docker build -t my-prometheus . 使用配置管理系统 Ansible Chef Puppet SaltStack 配置Configuration Prometheus通过命令行标志(flag)和配置文件进行配置。使用./prometheus -h查看所有命令行标志。Prometheus可在运行时重新加载配置。 配置文件configuration file: https://prometheus.io/docs/prometheus/latest/configuration/configuration/ 使用--config.file标志指定配置文件。配置文件使用YAML格式。 一个配置文件栗子: 1234567891011121314151617181920212223242526272829303132333435363738global: # How frequently to scrape targets by default. [ scrape_interval: &lt;duration&gt; | default = 1m ] # How long until a scrape request times out. [ scrape_timeout: &lt;duration&gt; | default = 10s ] # How frequently to evaluate rules. [ evaluation_interval: &lt;duration&gt; | default = 1m ] # The labels to add to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: [ &lt;labelname&gt;: &lt;labelvalue&gt; ... ]# Rule files specifies a list of globs. Rules and alerts are read from# all matching files.rule_files: [ - &lt;filepath_glob&gt; ... ]# A list of scrape configurations.scrape_configs: [ - &lt;scrape_config&gt; ... ]# Alerting specifies settings related to the Alertmanager.alerting: alert_relabel_configs: [ - &lt;relabel_config&gt; ... ] alertmanagers: [ - &lt;alertmanager_config&gt; ... ]# Settings related to the remote write feature.remote_write: [ - &lt;remote_write&gt; ... ]# Settings related to the remote read feature.remote_read: [ - &lt;remote_read&gt; ... ] 各个配置项，详细详细请看文档: https://prometheus.io/docs/prometheus/latest/configuration/configuration/ scrape_config tls_config azure_sd_config consul_sd_config dns_sd_config ec2_sd_config openstack_sd_config file_sd_config gce_sd_config kubernetes_sd_config marathon_sd_config nerve_sd_config serverset_sd_config triton_sd_config static_config relabel_config metric_relabel_configs alert_relabel_configs alertmanager_config remote_write remote_read 记录规则Recording rules 配置规则Configuring rules Prometheus支持两种类型的可被配置的以规定的间隔进行评估的规则: recording rules alterting rules 要在Prometheus中包含规则，创建包含必要规则的语句并在Prometheus配置文件中通过rule_files字段配置并加载文件。规则使用YAML格式。 规则文件可在Prometheus运行通过发送SIGHUP到Prometheus来进行重载。只有在所有规则文件都是正确格式下才会应用更改。 语法检查规则Syntax-checking rules 要快速检查规则文件的语法是否正确，而无需启动Prometheus Server，可安装和运行Prometheus的promtool命令行工具: 123go get github.com/prometheus/prometheus/cmd/promtoolpromtool check rules /path/to/example.rules.yml 如果规则文件语法正确，会返回0状态码。如果语法错误，会返回错误信息和1状态码。 记录规则Recording rules 记录规则允许你预先计算经常需要或计算昂贵的表达式并保存它们的结果到一个新的时序集(set of time series)。查询预先计算的结果会比每次执行原始表达式快得多。这对Dashboard来说尤其有用，它经常刷新时间反复查询同样的表达式。 记录和告警规则位于一个规则组(rule group)。一个组内的规则在一个规定的间隔内依序运行。 规则文件语法: 12groups: [ - &lt;rule_group&gt; ] 栗子: 12345groups: - name: example relues: - record: job:http_inprogress_requests:sum expr: sum(http_inprogress_requests) by (job) 12345678# The name of the group. Must be unique within a file.name: &lt;string&gt;# How often rules in the group are evaluated.[ interval: &lt;duration&gt; | default = global.evaluation_interval ]rules: [ - &lt;rule&gt; ... ] 记录规则的语法: 1234567891011# The name of the time series to output to. Must be a valid metric name.record: &lt;string&gt;# The PromQL expression to evaluate. Every evaluation cycle this is# evaluated at the current time, and the result recorded as a new set of# time series with the metric name as given by 'record'.expr: &lt;string&gt;# Labels to add or overwrite before storing the result.labels: [ &lt;labelname&gt;: &lt;labelvalue&gt;] 告警规则的语法: 12345678910111213141516171819# The name of the alert. Must be a valid metric name.alert: &lt;string&gt;# The PromQL expression to evaluate. Every evaluation cycle this is# evaluated at the current time, and all resultant time series become# pending/firing alerts.expr: &lt;string&gt;# Alerts are considered firing once they have been returned for this long.# Alerts which have not yet fired for long enough are considered pending.[ for: &lt;duration&gt; | default = 0s ]# Labels to add or overwrite for each alert.labels: [ &lt;labelname&gt;: &lt;tmp_string&gt;]# Annotations to add to each alert.annotations: [ &lt;labelname&gt;: &lt;tmpl_string&gt; ] 告警规则Alerting rules 告警规则允许你根据Prometheus表达式语言来定义告警条件，并发送提醒到外部服务。每当告警表达式在给定的时间内导致一个或多个矢量元素，告警计数主动作为这些元素的标签集。 定义告警规则在Prometheus中，告警规则的配置与记录规则的配置一样。 栗子: 12345678910groups:- name: example rules: - alerts: HighRequestLatency expr: job:request_latency_seconds:mean5m&#123;job="myjob"&#125; &gt; 0.5 for: 10m labels: severity: page annotations: summary: High request latency 可选的for子句导致Prometheus等待在第一次遇到一个新的表达式输出矢量元素和计数的告警作为点燃的此元素的一定持续时间。在这个栗子中，Prometheus将检查在点燃告警之前的每个10分钟的警告持续激活。元素是活跃的，但未点燃，出于待定(pending)状态。 labels子句允许指定一组附加标签到告警。任何目前有冲突的标签将被覆盖。标签的值可以作为模板。 annotations子句指定的一组信息可用来存储更长的附加信息。注释的值可以作为模板。 模板Templating 标签和注释的值可以使用console template作为模板。$labels变量保存一个告警实例的k/v键值对。已配置的外部标签可通过$externalLabels变量进行访问。$value变量保存告警实例的评估值。 12345# To insert a firing element's label values:&#123;&#123; $labels.&lt;labelname&gt; &#125;&#125;# To insert the numeric expression value of the firing element:&#123;&#123; $value &#125;&#125; 栗子: 123456789101112131415161718192021groups:- name: example rules: # Alert for any instance that is unreachable for &gt;5 minutes. - alert: InstanceDown expr: up == 0 for: 5m labels: severity: page annotations: summary: "Instance &#123;&#123; $labels.instance &#125;&#125; down" description: "&#123;&#123; $labels.instance &#125;&#125; of job &#123;&#123; $labels.job &#125;&#125; has been down for more than 5 minutes." # Alert for any instance that has a median request latency &gt;1s. - alert: APIHighRequestLatency expr: api_http_request_latencies_second&#123;quantile="0.5"&#125; &gt; 1 for: 10m annotations: summary: "High request latency on &#123;&#123; $labels.instance &#125;&#125;" description: "&#123;&#123; $labels.instance &#125;&#125; has a median request latency above 1s (current value: &#123;&#123; $value &#125;&#125;)s" 运行时检查告警Inspecting alerts during runtime 要手动检查告警是否活跃(active)(pending或firing)，请浏览原生Prometheus的Alerts栏目项。这里将确切地显示标签集，每个定义的告警当前的状态。 对于pengding和firing的告警，Prometheus还存储合成ALERTS{alertname=&quot;&lt;alert name&gt;&quot;, alertstate=&quot;pending|firing&quot;, &lt;additional alert labels&gt;}形式的时间序列。只要该警告是在所指示的active(pending或firing)状态，样本值被设置为1。当不再是这样时，该系列被标记为stale。 发送告警通知Sending alert notifications Prometheus的告警规则善于盘算现在什么坏了(broken)，但是它不是一个成熟的通知解决方案。需要另一层添加汇总，通知速率限制，沉默和告警依赖于简单告警定义。在Prometheus的生态系统中，Alertmanager承担了这一角色。因此，Prometheus可以配置成定期发送关于告警状态信息到Alertmanager实例，然后采取调度权发送通知。Prometheus通过集成服务发现，可配置为自动发现可用的Alertmanager实例。 模板Template example Prometheus在alerts的annotations和labels中支持模板化，以及在控制台页面。模板要针对本地数据库运行查询、迭代数据，使用条件、格式数据等能力。Prometheus模板语言是基于Go template system。 简单告警字段模板12345678alert: InstanceDownexpr: up == 0for: 5mlabels: severity: pageannotations: summary: "Instance &#123;&#123;$labels.instance&#125;&#125; down" description: "&#123;&#123;$labels.instance&#125;&#125; of job &#123;&#123;$labels.job&#125;&#125; has been down for more than 5 minutes." 告警字段模板为每个点燃的告警在每一个规则迭代过程中执行，所以保持任意查询和模板的轻量化。如果你需要为告警编写更复杂的模板，建议链接到控制台。 简单迭代simple iteration 这显示的实例列表，以及它们是否up: 123&#123;&#123; range query "up" &#125;&#125; &#123;&#123; .Labels.instance &#125;&#125; &#123;&#123; .Value &#125;&#125;&#123;&#123; end &#125;&#125; 特殊的.变量包含对于每次循环迭代当前样本的值。 展示一个值123&#123;&#123; with query "some_metric&#123;instance='someinstance'&#125;" &#125;&#125; &#123;&#123; . | first | value | humanize &#125;&#123;&#123; end &#125;&#125; Go和Go的模板语言两者都是强类型，因此必须检查阳平返回，以避免执行错误。这里所包含的prom_query_drilldown模板处理，允许结果的格式，并链接到表达式浏览器。 使用控制台url参数Using console URL parameters 123&#123;&#123; with printf "node_memory_MemTotal&#123;job='node', instance='%s'&#125;" .Params.instance | query&#125;&#125; &#123;&#123; . | first | value | humanize1024 &#125;&#125;B&#123;&#123; end &#125;&#125; 如果作为console.html?instance=hostname访问, .Params.instance将评估hostname。 高级的迭代Advanced iteration 123456789101112&lt;table&gt;&#123;&#123; range printf "node_network_receive_bytes&#123;job='node',instance='%s',device!='lo'&#125;" .Params.instance | query | sortByLabel "device"&#125;&#125;&lt;tr&gt;&lt;th colspan=2&gt;&#123;&#123; .Labels.device &#125;&#125;&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;Received&lt;/td&gt; &lt;td&gt;&#123;&#123; with printf "rate(node_network_receive_bytes&#123;job='node',instance='%s',device='%s'&#125;[5m])" .Labels.instance .Labels.device | query &#125;&#125;&#123;&#123; . | first | value | humanize &#125;&#125;B/s&#123;&#123;end&#125;&#125;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;Transmitted&lt;/td&gt; &lt;td&gt;&#123;&#123; with printf "rate(node_network_transmit_bytes&#123;job='node',instance='%s',device='%s'&#125;[5m])" .Labels.instance .Labels.device | query &#125;&#125;&#123;&#123; . | first | value | humanize &#125;&#125;B/s&#123;&#123;end&#125;&#125;&lt;/td&gt; &lt;/tr&gt;&#123;&#123; end &#125;&#125;&lt;/table&gt; 这里，我们迭代了所有网络设备，并显示每个设备的网络流量。随着range动作不指定变量，.Params.instance循环内不可用，.现在是作为循环变量。 定义可重复使用的模板Defining reusable templates Prometheus支持定义可重复使用的模板。当与控制台库相结合时，使得可共享模板，这很有用。 1234567&#123;&#123; /* Define the template */ &#125;&#125;&#123;&#123;define "myTemplate"&#125;&#125; do something&#123;&#123; end &#125;&#125;&#123;&#123;/* Use the template */&#125;&#125;&#123;&#123;template "myTemplate"&#125;&#125; 模板仅限于一个参数。args函数可包装多个参数。 12345&#123;&#123;define "myMultiArgTemplate"&#125;&#125; First argument: &#123;&#123;.arg0&#125;&#125; Second argument: &#123;&#123;.arg1&#125;&#125;&#123;&#123; end &#125;&#125;&#123;&#123; template "myMultiArgTemplate" (args 1 2)&#125;&#125; 模板引用TEMPLATE REFERENCE 数据结构Data Structures 用于处理时间序列数据的主要数据结构栗子: 1234type sample struct &#123; Labels map[string]string Value float64&#125; 栗子的指标名称(metric)编码在Labelsmap的特殊的__name__标签里。[]sample表示实例列表。Go中的interface{}与C中的void pointer类似。 函数除了Go模板提供的默认函数，Prometheus为模板查询结果提供了更易处理的函数。如果函数在管道中使用，管道值将作为最后一个参数传递。 Queries Numbers Strings Others 模板类型差异Template type differences 每种类型的模板提供了可用于参数模板的不同信息，并有一些其它差异。 规则单元测试Unit Testing for Rules 你可使用promtool来测试你的规则。 查询Querying 查询PrometheusPrometheus提供了一个名为PromQL(Prometheus Query Language)功能化查询语言，让用户选择并实时汇总时间序列数据。表达式的结果可被显示为图形，可在Prometheus浏览器上查看，或通过HTTP API来获取。 表达式语言数据类型Expression language data types 在Prometheus表达式语言中，一个表达式或子表达式可以评估为四种类型中的一种: 瞬时向量(Instant vector): 包含每个时间序列的单个样品的一组时间序列，全部共享相同的时间戳 区间向量(Range vector): 包含随时间序列的范围的数据点的一组时间序列 标量(Scalar): 一个简单的数字浮点值 字符串(String): 一个简单的字符串值，当前未使用 根据不同的使用情况(graphing, displaying the output of an expression)，例如：瞬时向量表达式返回的数据类型是唯一可以直接绘制成图表的数据类型。 LiteralsString literals 字符串可以被指定为在单引号、双引号或反引号内的文字。 PromQL遵循Go的转义规则。不像Go，Prometheus不丢弃反引号里面的换行符。 123&quot;this is a string&quot;&apos;these are unescaped: \n \\ \t&apos;`these are not unescaped: \n &apos; &quot; \t`&quot;&apos;` Float literals 标量浮点值可被逐字地写为[-](digits)[.(digits)]数字形式。 1-2.43 时序选择器Time series Selectors Prometheus中的所有正则表达式使用RE2 syntax。 Instant vector selectors Instant vector selectors允许一组时间序列并为每个在给定的时间戳单一样品值的选择: 在最简单的格式中，只制定了一个指标名称。这导致了包含有该指标名称的所有时间序列的元素instant vector。 这个栗子将选择具有http_requests_total指标名称的所有时间序列: 1http_requests_total 有可能通过附加一组标签在大括号来匹配进一步过滤这些时间序列。 这个栗子只选择job label为prometheus和group lable为canary的http_requests_total指标名称。 1http_requests_total&#123;job=&quot;prometheus&quot;, group=&quot;canary&quot;&#125; 也可将标签值负匹配，或匹配正则表达式。下面的标签匹配操作符存在: =: 等于; != 不等于; =~: 正则匹配; !~: 非正则匹配. 举个栗子，以下匹配staging, testing, development环境变量和GET以外的HTTP方法的http_requests_total指标名称的所有时序。 1http_requests_total&#123;environment=~&quot;staging|testing|development&quot;, method!=&quot;GET&quot;&#125; 栗子: 123456&#123;job=~&quot;.*&quot;&#125; # Bad!&#123;job=~&quot;.+&quot;&#125; # Good!&#123;job=~&quot;.*&quot;,method=&quot;get&quot;&#125; # Good!&#123;__name__=~&quot;job:.*&quot;&#125; Range Vector Selectors Range vector literals与 instant vector literals类似，不同之处在于它选择了一个范围。时间序列放在方括号[]内。 时间范围被指定为一个数字，使用以下单位: s: 秒; m: 分; h: 时; d: 天; w: 周; y: 年。 栗子: 1http_requests_total&#123;job=&quot;prometheus&quot;&#125;[5m] Offset modifier offset修饰符允许为查询中的individual instant和range vectors改变时间偏移。 栗子: 1234567http_requests_total offset 5msum(http_requests_total&#123;method=&quot;GET&quot;&#125; offset 5m) // GOOD.sum(http_requests_total&#123;method=&quot;GET&quot;&#125;) offset 5m // INVALID.rate(http_requests_total[5m] offset 1w) 子查询Subquery 子查询允许你为一个给定的range和resolution运行一个即时查询(instant)。子查询的结果为range vector。 语法: 12# resolution可选。Default is the global evaluation interval.Syntax: &lt;instant_query&gt; &apos;[&apos; &lt;range&gt; &apos;:&apos; [&lt;resolution&gt;] &apos;]&apos; [ offset &lt;duration&gt; ] 操作符Operators: https://prometheus.io/docs/prometheus/latest/querying/operators/ 二元运算符Binary Operators Prometheus查询语言支持基本的逻辑和算数运算符。 Arithmetic binary operators Prometheus中存在以下二元算术运算符: + (addition) - (subtraction) * (multiplication) / (division) % (modulo) ^ (power/exponentiation) 二元运算符在下列之间定义: scalar/scalar vector/scalar vector/vector Comparison binary operators Prometheus中有以下二元比较符: == (equal) != (not-equal) &gt; (greater-than) &lt; (less-than) &gt;= (greater-or-equal) &lt;= (less-or-equal) 比较运算符在下列之间定义，默认情况下进行筛选。它们的行为可由运算符之后提供的bool进行修改，这将返回0或1而不是过滤。 scalar/scalar vector/scalar vector/vector Logical/set binary operators logical/set 二元运算符尽在instan vectors之间定义: and (intersection) or (union) unless (complement) 矢量匹配Vector matching 矢量之间的操作试图找到为左手侧的每个条目匹配右手侧的元素。有两种基本类型匹配的行为: One-to-one 和 many-to-one/one-to-many。 One-to-one vector matches 一对一从操作的每一侧查找唯一的一对条目。在默认情况下，操作遵循如下格式vector1 &lt;operator&gt; vector2。如果它们有完全相同的一组标签和相应的值，则两个条目匹配。ignoring关键字允许匹配忽略某些标签，on关键字允许降低考虑的标签集来提供列表: 12&lt;vector expr&gt; &lt;bin-op&gt; ignoring(&lt;label list&gt;) &lt;vector expr&gt;&lt;vector expr&gt; &lt;bin-op&gt; on(&lt;label list&gt;) &lt;vector expr&gt; 输入案例: 123456789method_code:http_errors:rate5m&#123;method=&quot;get&quot;, code=&quot;500&quot;&#125; 24method_code:http_errors:rate5m&#123;method=&quot;get&quot;, code=&quot;404&quot;&#125; 30method_code:http_errors:rate5m&#123;method=&quot;put&quot;, code=&quot;501&quot;&#125; 3method_code:http_errors:rate5m&#123;method=&quot;post&quot;, code=&quot;500&quot;&#125; 6method_code:http_errors:rate5m&#123;method=&quot;post&quot;, code=&quot;404&quot;&#125; 21method:http_requests:rate5m&#123;method=&quot;get&quot;&#125; 600method:http_requests:rate5m&#123;method=&quot;del&quot;&#125; 34method:http_requests:rate5m&#123;method=&quot;post&quot;&#125; 120 查询栗子: 1method_code:http_errors:rate5m&#123;code=&quot;500&quot;&#125; / ignoring(code) method:http_requests:rate5m Many-to-one and one-to-many vector matches 多对一或一对多匹配指的是一侧能够匹配多侧的多个元素。这明确要求必须使用group_left或group_right修饰符，其中左/右确定该矢量有更高的基数。 1234&lt;vector expr&gt; &lt;bin-op&gt; ignoring(&lt;label list&gt;) group_left(&lt;label list&gt;) &lt;vector expr&gt;&lt;vector expr&gt; &lt;bin-op&gt; ignoring(&lt;label list&gt;) group_right(&lt;label list&gt;) &lt;vector expr&gt;&lt;vector expr&gt; &lt;bin-op&gt; on(&lt;label list&gt;) group_left(&lt;label list&gt;) &lt;vector expr&gt;&lt;vector expr&gt; &lt;bin-op&gt; on(&lt;label list&gt;) group_right(&lt;label list&gt;) &lt;vector expr&gt; 查询案例: 1method_code:http_errors:rate5m / ignoring(code) group_left method:http_request:rate5m 1234&#123;method=&quot;get&quot;, code=&quot;500&quot;&#125; 0.04 // 24 / 600&#123;method=&quot;get&quot;, code=&quot;404&quot;&#125; 0.05 // 30 / 600&#123;method=&quot;post&quot;, code=&quot;500&quot;&#125; 0.05 // 6 / 120&#123;method=&quot;post&quot;, code=&quot;404&quot;&#125; 0.175 // 21 / 120 聚合运算符Aggregation operators Prometheus支持以下内置聚合运算符，可以用于聚合单一瞬间向量的元素: sum (calculate sum over dimensions) min (select minimum over dimensions) max (select maximum over dimensions) avg (calculate the average over dimensions) stddev (calculate population standard deviation over dimensions) stdvar (calculate population standard variance over dimensions) count (count number of elements in the vector) count_values (count number of elements with the same value) bottomk (smallest k elements by sample value) topk (largest k elements by sample value) quantile (calculate φ-quantile (0 ≤ φ ≤ 1) over dimensions) 栗子: 1234567891011&lt;aggr-op&gt; [without|by (&lt;label list&gt;)] ([parameter,] &lt;vector expression&gt;)&lt;aggr-op&gt;([parameter,] &lt;vector expression&gt;) [without|by (&lt;label list&gt;)]sum without (instance) (http_requests_total)sum by (application, group) (http_requests_total)count_values(&quot;version&quot;, build_version)topk(5, http_requests_total) 二元运算符优先级Binary operator precedence 以下优先级由高到低: ^ *, /, % +, - ==, !=, &lt;=, &lt;, &gt;=, &gt; and, unless or 函数Founctions: https://prometheus.io/docs/prometheus/latest/querying/functions/ 一些函数有默认的参数，如year(v=vector(time()) instant-vector)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208abs()abs(v instant-vector) 返回输入向量的所有样本的绝对值absent()absent(v instant-vector)，判断是否存在absent(nonexistent&#123;job=&quot;myjob&quot;&#125;)# =&gt; &#123;job=&quot;myjob&quot;&#125;absent(nonexistent&#123;job=&quot;myjob&quot;,instance=~&quot;.*&quot;&#125;)# =&gt; &#123;job=&quot;myjob&quot;&#125;absent(sum(nonexistent&#123;job=&quot;myjob&quot;&#125;))# =&gt; &#123;&#125;ceil()ceil(v instant-vector) 将v中所有元素的样本值向上四舍五入到最接近的整数floor()floor(v instant-vector) 与ceil()相反，将v中所有元素的样本值向下四舍五入到最接近的整数changes()changes(v range-vector) 输入一个区间向量，返回这个区间向量内每个样本数据值变化的次数（瞬时向量）。如果样本数据值没有发生变化，则返回结果为1clamp_max()clamp_max(v instant-vector, max scalar) 输入一个瞬时向量和最大值，样本数据值若大于max，则改为max，否则不变clamp_min()clamp_min(v instant-vector, min scalar) 输入一个瞬时向量和最小值，样本数据值若小于min，则改为min，否则不变day_of_month()day_of_month(v=vector(time()) instant-vector) 值范围为1-31day_of_week()day_of_week(v=vector(time()) instant-vector) 值范围为0-6days_in_month()days_in_month(v=vector(time()) instant-vector) 月份的天数，值范围为28-31minute()minute(v=vector(time()) instant-vector) 函数返回给定UTC时间当前小时的第多少分钟，范围为0-59month()month(v=vector(time()) instant-vector) 函数返回给定UTC时间当前属于第几个月，范围为1-12year()year(v=vector(time()) instant-vector) 返回被给定 UTC 时间的当前年份hour()hour(v=vector(time()) instant-vector) 值范围为0-23delta()delta(v range-vector) 它计算一个区间向量v的第一个元素和最后一个元素之间的差值，返回一个瞬时向量delta(cpu_temp_celsius&#123;host=&quot;zeus&quot;&#125;[2h]) # 现在和两小时前的CPU温度差idelta()idelta(v range-vector) 计算最后两个样本之间的差deriv()deriv(v range-vector) 使用简单的线性回归计算区间向量v中各个时间序列的导数exp()exp(v instant-vector) 输入一个瞬时向量，返回各个样本值的e的指数值histogram_quantile()histogram_quantile(φ float, b instant-vector)histogram_quantile(0.9, rate(http_request_duration_seconds_bucket[10m])) # 计算过去10分钟内请求持续在90%histogram_quantile(0.9, sum(rate(http_request_duration_seconds_bucket[10m])) by (job, le)) # 聚合holt_winters()holt_winters(v range-vector, sf scalar, tf scalar) 基于区间向量v，生成时间序列数据平滑值increase()increase(v range-vector) 获取区间向量中的第一个和最后一个样本并返回其增长量increase(http_requests_total&#123;job=&quot;api-server&quot;&#125;[5m]) # 区间向量中每个时间序列过去5分钟内HTTP请求数的增长数label_join()label_replace()ln()ln(v instant-vector) 计算瞬时向量v中所有样本数据的自然对数log2()log2(v instant-vector) 函数计算瞬时向量v中所有样本数据的二进制对数log10()log10(v instant-vector) 计算瞬时向量v中所有样本数据的十进制对数predict_linear()predict_linear(v range-vector, t scalar) 函数可以预测时间序列v在t秒后的值predict_linear(node_filesystem_free&#123;job=&quot;node&quot;&#125;[2h], 4 * 3600) &lt; 0 # 基于2小时的样本数据，来预测主机可用磁盘空间的是否在4个小时候被占满rate()rate(v range-vector) 直接计算区间向量 v 在时间窗口内平均增长速率rate(http_requests_total[5m]) 区间向量中每个时间序列过去5分钟内HTTP请求数的每秒增长率irate()irate(v range-vector) 用于计算区间向量的增长率，但是其反应出的是瞬时增长率。通过区间向量中最后两个两本数据来计算区间向量的增长速率。irate(http_requests_total&#123;job=&quot;api-server&quot;&#125;[5m]) # 区间向量中每个时间序列过去 5 分钟内最后两个样本数据的 HTTP 请求数的增长率resets()resets(v range-vector) 的参数是一个区间向量。对于每个时间序列，它都返回一个计数器重置的次数。两个连续样本之间的值的减少被认为是一次计数器重置。round()round(v instant-vector, to_nearest=1 scalar) 与ceil和floor函数类似，返回向量中所有样本值的最接近的整数scalar()scalar(v instant-vector) 函数的参数是一个单元素的瞬时向量,它返回其唯一的时间序列的值作为一个标量sort()sort(v instant-vector) 函数对向量按元素的值进行升序排序sort_desc()降序排列sqrt()sqrt(v instant-vector) 计算向量v 所有元素的平方根vector()vector(s scalar)&lt;aggregation&gt;_over_time()avg_over_time(range-vector) : 区间向量内每个度量指标的平均值。min_over_time(range-vector) : 区间向量内每个度量指标的最小值。max_over_time(range-vector) : 区间向量内每个度量指标的最大值。sum_over_time(range-vector) : 区间向量内每个度量指标的求和。count_over_time(range-vector) : 区间向量内每个度量指标的样本数据个数。quantile_over_time(scalar, range-vector) : 区间向量内每个度量指标的样本数据值分位数，φ-quantile (0 ≤ φ ≤ 1)。stddev_over_time(range-vector) : 区间向量内每个度量指标的总体标准差。stdvar_over_time(range-vector) : 区间向量内每个度量指标的总体标准方差。 查询栗子Query examples: https://prometheus.io/docs/prometheus/latest/querying/examples/ 简单时序选择返回指标http_requests_total的所有时间序列数据: 1http_requests_total 返回指标名为http_requests_total，给定标签job和handler: 1http_requests_total&#123;job=&quot;apiserver&quot;, handler=&quot;/api/comments&quot;&#125; 加上时间，5分钟内: 1http_requests_total&#123;job=&quot;apiserver&quot;, handler=&quot;/api/comments&quot;&#125;[5m] 使用正则: 1http_requests_total&#123;job=~&quot;.*server&quot;&#125; http状态码不为4xx: 1http_requests_total&#123;status!~&quot;4..&quot;&#125; 子查询Return the 5-minute rate of the http_requests_total metric for the past 30 minutes, with a resolution of 1 minute. 1rate(http_requests_total[5m])[30m:1m] 嵌套子查询: 1max_over_time(deriv(rate(distance_covered_total[5s])[30s:5s])[10m:]) 使用函数，运算符过去5分钟的平均值 1rate(http_requests_total[5m]) 过去5分钟平均值综合 123sum by (job) ( rate(http_requests_total[5m])) 如果两个指标具有相同维度的标签，我们可以使用二元操作符计算样本数据: 1234567(instance_memory_limit_bytes - instance_memory_usage_bytes) / 1024 / 1024# 同样的表达式，只不过通过应用相加sum by (app, proc) ( instance_memory_limit_bytes - instance_memory_usage_bytes) / 1024 / 1024 获取CPU使用最高的三个样本: 1topk(3, sum by (app, proc) (rate(instance_cpu_time_ns[5m]))) 假设一个服务实例只有一个时间序列数据，那么我们可以通过下面表达式统计出每个应用的实例数量: 1count(instance_cpu_time_ns) by (app) HTTP APIHTTP API: https://prometheus.io/docs/prometheus/latest/querying/api/ 目前稳定的HTTP API在Prometheus Server的/api/v1下。 格式API响应格式为JSON。每个成功的请求都返回2xx状态码。 到达API处理程序无效的请求返回一个错误的JSON对象和以下状态码之一: 400 Bad Request: 当参数错误或者缺失 422 Unprocessable Entity: 当表达式无法执行 503 Service Unavailable: 当请求超时或者被中断时 JSON响应包格式如下: 12345678910111213&#123; "status": "success" | "error", "data": &lt;data&gt;, // Only set if status is "error". The data field may still hold // additional data. "errorType": "&lt;string&gt;", "error": "&lt;string&gt;", // Only if there were warnings while executing the request. // There will still be data in the data field. "warnings": ["&lt;string&gt;"]&#125; 请求中输入的时间为RFC3339或Unix原子时间，输出时间戳总是Unix原子时间。 查询参数的名称可用中括号[]重复次数。 &lt;duration&gt;占位符指的是[0-9]+[smhdwy]形式的Prometheus 持续时间字符串。例如，5m表示5分钟的持续时间。 表达式查询查询语言表达式可在单个时刻或一定范围内进行评估。以下部分用于描述每个类型的表达式查询的API endpoint。 瞬时查询(Instant query) 端点: 12GET /api/v1/queryPOST /api/v1/query URL查询参数: 12345678# 表达式query=&lt;string&gt;# 时间戳，可选。默认使用当前系统时间time=&lt;rfc3339 | unix_timestamp&gt;# 超时，可选。默认使用全局的-query.timeout参数timeout=&lt;duration&gt; 查询结果的data部分格式如下: 1234&#123; &quot;resultType&quot;: &quot;matrix&quot; | &quot;vector&quot; | &quot;scalar&quot; | &quot;string&quot;, &quot;result&quot;: &lt;value&gt;&#125; 栗子: 12345678910111213141516171819202122232425$ curl &apos;http://localhost:9090/api/v1/query?query=up&amp;time=2015-07-01T20:10:51.781Z&apos;&#123; &quot;status&quot; : &quot;success&quot;, &quot;data&quot; : &#123; &quot;resultType&quot; : &quot;vector&quot;, &quot;result&quot; : [ &#123; &quot;metric&quot; : &#123; &quot;__name__&quot; : &quot;up&quot;, &quot;job&quot; : &quot;prometheus&quot;, &quot;instance&quot; : &quot;localhost:9090&quot; &#125;, &quot;value&quot;: [ 1435781451.781, &quot;1&quot; ] &#125;, &#123; &quot;metric&quot; : &#123; &quot;__name__&quot; : &quot;up&quot;, &quot;job&quot; : &quot;node&quot;, &quot;instance&quot; : &quot;localhost:9100&quot; &#125;, &quot;value&quot; : [ 1435781451.781, &quot;0&quot; ] &#125; ] &#125;&#125; 区间查询(range query) 端点: 12GET /api/v1/query_rangePOST /api/v1/query_range URL查询参数: 123456789101112# 表达式query=&lt;string&gt;# 时间戳start=&lt;rfc3339 | unix_timestamp&gt;end=&lt;rfc3339 | unix_timestamp&gt;# 查询时间步长，时间区间内每step秒执行一次step=&lt;duration | float&gt;# 超时，可选timeout=&lt;duration&gt; 查询结果的data部分格式如下: 1234&#123; &quot;resultType&quot;: &quot;matrix&quot;, &quot;result&quot;: &lt;value&gt;&#125; 栗子: 123456789101112131415161718192021222324252627282930313233$ curl &apos;http://localhost:9090/api/v1/query_range?query=up&amp;start=2015-07-01T20:10:30.781Z&amp;end=2015-07-01T20:11:00.781Z&amp;step=15s&apos;&#123; &quot;status&quot; : &quot;success&quot;, &quot;data&quot; : &#123; &quot;resultType&quot; : &quot;matrix&quot;, &quot;result&quot; : [ &#123; &quot;metric&quot; : &#123; &quot;__name__&quot; : &quot;up&quot;, &quot;job&quot; : &quot;prometheus&quot;, &quot;instance&quot; : &quot;localhost:9090&quot; &#125;, &quot;values&quot; : [ [ 1435781430.781, &quot;1&quot; ], [ 1435781445.781, &quot;1&quot; ], [ 1435781460.781, &quot;1&quot; ] ] &#125;, &#123; &quot;metric&quot; : &#123; &quot;__name__&quot; : &quot;up&quot;, &quot;job&quot; : &quot;node&quot;, &quot;instance&quot; : &quot;localhost:9091&quot; &#125;, &quot;values&quot; : [ [ 1435781430.781, &quot;0&quot; ], [ 1435781445.781, &quot;0&quot; ], [ 1435781460.781, &quot;1&quot; ] ] &#125; ] &#125;&#125; 查询元数据通过标签匹配器查找序列(Finding series by label matchers) 端点: 12GET /api/v1/seriesPOST /api/v1/series URL请求参数: 123456# 标签选择器是 series_selector。必须至少提供一个match[]参数match[]=&lt;series_selector&gt;# 时间戳start=&lt;rfc3339 | unix_timestamp&gt;end=&lt;rfc3339 | unix_timestamp&gt; 返回结果的data部分，由k/v键值对的对象列表组成。栗子: 123456789101112131415161718192021$ curl -g &apos;http://localhost:9090/api/v1/series?&apos; --data-urlencode=&apos;match[]=up&apos; --data-urlencode=&apos;match[]=process_start_time_seconds&#123;job=&quot;prometheus&quot;&#125;&apos;&#123; &quot;status&quot; : &quot;success&quot;, &quot;data&quot; : [ &#123; &quot;__name__&quot; : &quot;up&quot;, &quot;job&quot; : &quot;prometheus&quot;, &quot;instance&quot; : &quot;localhost:9090&quot; &#125;, &#123; &quot;__name__&quot; : &quot;up&quot;, &quot;job&quot; : &quot;node&quot;, &quot;instance&quot; : &quot;localhost:9091&quot; &#125;, &#123; &quot;__name__&quot; : &quot;process_start_time_seconds&quot;, &quot;job&quot; : &quot;prometheus&quot;, &quot;instance&quot; : &quot;localhost:9090&quot; &#125; ]&#125; 获取标签名(label) 端点: 12GET /api/v1/labelsPOST /api/v1/labels 返回结果的data部分是一个标签名字符串列表。栗子: 123456789101112131415161718192021222324252627$ curl &apos;localhost:9090/api/v1/labels&apos;&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: [ &quot;__name__&quot;, &quot;call&quot;, &quot;code&quot;, &quot;config&quot;, &quot;dialer_name&quot;, &quot;endpoint&quot;, &quot;event&quot;, &quot;goversion&quot;, &quot;handler&quot;, &quot;instance&quot;, &quot;interval&quot;, &quot;job&quot;, &quot;le&quot;, &quot;listener_name&quot;, &quot;name&quot;, &quot;quantile&quot;, &quot;reason&quot;, &quot;role&quot;, &quot;scrape_job&quot;, &quot;slice&quot;, &quot;version&quot; ]&#125; 查询标签值 请求如下端点: 1GET /api/v1/label/&lt;label_name&gt;/values JSON响应的data部分是标签值字符串列表。栗子: 12345678$ curl http://localhost:9090/api/v1/label/job/values&#123; &quot;status&quot; : &quot;success&quot;, &quot;data&quot; : [ &quot;node&quot;, &quot;prometheus&quot; ]&#125; 表达式查询结果的格式Expression query result formats 表达式查询结果可能会在data部分的result字段中返回以下响应值。 区间向量(range vectors) 区间向量返回matrix resultType。result的响应格式如下: 1234567[ &#123; &quot;metric&quot;: &#123; &quot;&lt;label_name&gt;&quot;: &quot;&lt;label_value&gt;&quot;, ... &#125;, &quot;values&quot;: [ [ &lt;unix_time&gt;, &quot;&lt;sample_value&gt;&quot; ], ... ] &#125;, ...] 瞬时向量(instant vectors) 瞬时向量返回vector resultType。result的响应格式如下: 1234567[ &#123; &quot;metric&quot;: &#123; &quot;&lt;label_name&gt;&quot;: &quot;&lt;label_value&gt;&quot;, ... &#125;, &quot;value&quot;: [ &lt;unix_time&gt;, &quot;&lt;sample_value&gt;&quot; ] &#125;, ...] 标量(Scalars) 标量返回scalar resultType。result的响应格式如下: 1[ &lt;unix_time&gt;, &quot;&lt;scalar_value&gt;&quot; ] 字符串(string) 字符串返回string resultType。result的响应格式如下: 1[ &lt;unix_time&gt;, &quot;&lt;string_value&gt;&quot; ] 目标Targets 以下端点返回Prometheus目标发现的当前状态的概述: 1GET /api/v1/targets 栗子: 12345678910111213141516171819202122232425262728293031323334curl http://localhost:9090/api/v1/targets&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: &#123; &quot;activeTargets&quot;: [ &#123; &quot;discoveredLabels&quot;: &#123; &quot;__address__&quot;: &quot;127.0.0.1:9090&quot;, &quot;__metrics_path__&quot;: &quot;/metrics&quot;, &quot;__scheme__&quot;: &quot;http&quot;, &quot;job&quot;: &quot;prometheus&quot; &#125;, &quot;labels&quot;: &#123; &quot;instance&quot;: &quot;127.0.0.1:9090&quot;, &quot;job&quot;: &quot;prometheus&quot; &#125;, &quot;scrapeUrl&quot;: &quot;http://127.0.0.1:9090/metrics&quot;, &quot;lastError&quot;: &quot;&quot;, &quot;lastScrape&quot;: &quot;2017-01-17T15:07:44.723715405+01:00&quot;, &quot;health&quot;: &quot;up&quot; &#125; ], &quot;droppedTargets&quot;: [ &#123; &quot;discoveredLabels&quot;: &#123; &quot;__address__&quot;: &quot;127.0.0.1:9100&quot;, &quot;__metrics_path__&quot;: &quot;/metrics&quot;, &quot;__scheme__&quot;: &quot;http&quot;, &quot;job&quot;: &quot;node&quot; &#125;, &#125; ] &#125;&#125; 规则Rules 此api端点返回当前载入的告警和记录规则的列表。此外，它还会返回由每个告警规则的Prometheus实例点燃的当前激活的告警。 1GET /api/v1/rules 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849curl http://localhost:9090/api/v1/rules&#123; &quot;data&quot;: &#123; &quot;groups&quot;: [ &#123; &quot;rules&quot;: [ &#123; &quot;alerts&quot;: [ &#123; &quot;activeAt&quot;: &quot;2018-07-04T20:27:12.60602144+02:00&quot;, &quot;annotations&quot;: &#123; &quot;summary&quot;: &quot;High request latency&quot; &#125;, &quot;labels&quot;: &#123; &quot;alertname&quot;: &quot;HighRequestLatency&quot;, &quot;severity&quot;: &quot;page&quot; &#125;, &quot;state&quot;: &quot;firing&quot;, &quot;value&quot;: &quot;1e+00&quot; &#125; ], &quot;annotations&quot;: &#123; &quot;summary&quot;: &quot;High request latency&quot; &#125;, &quot;duration&quot;: 600, &quot;health&quot;: &quot;ok&quot;, &quot;labels&quot;: &#123; &quot;severity&quot;: &quot;page&quot; &#125;, &quot;name&quot;: &quot;HighRequestLatency&quot;, &quot;query&quot;: &quot;job:request_latency_seconds:mean5m&#123;job=\&quot;myjob\&quot;&#125; &gt; 0.5&quot;, &quot;type&quot;: &quot;alerting&quot; &#125;, &#123; &quot;health&quot;: &quot;ok&quot;, &quot;name&quot;: &quot;job:http_inprogress_requests:sum&quot;, &quot;query&quot;: &quot;sum(http_inprogress_requests) by (job)&quot;, &quot;type&quot;: &quot;recording&quot; &#125; ], &quot;file&quot;: &quot;/rules.yaml&quot;, &quot;interval&quot;: 60, &quot;name&quot;: &quot;example&quot; &#125; ] &#125;, &quot;status&quot;: &quot;success&quot;&#125; 告警Alerts 此端点返回所有激活的告警的列表。 1GET /api/v1/alerts 123456789101112131415161718curl http://localhost:9090/api/v1/alerts&#123; &quot;data&quot;: &#123; &quot;alerts&quot;: [ &#123; &quot;activeAt&quot;: &quot;2018-07-04T20:27:12.60602144+02:00&quot;, &quot;annotations&quot;: &#123;&#125;, &quot;labels&quot;: &#123; &quot;alertname&quot;: &quot;my-alert&quot; &#125;, &quot;state&quot;: &quot;firing&quot;, &quot;value&quot;: &quot;1e+00&quot; &#125; ] &#125;, &quot;status&quot;: &quot;success&quot;&#125; 查询目标元数据Query target metadata 此段点返回目前由目标爬取的关于指标的元数据。这是实验性的，未来可能发生改变。 1GET /api/v1/targets/metadata URL查询参数: match_target=&lt;label_selectors&gt;: 标签选择器通过标签集匹配的目标。如果为空，则所有目标都被选中。 metics=&lt;string&gt;: 检索元数据的指标名称。如果为空，则所有指标元数据都被检索。 limit=&lt;number&gt;: 匹配的目标的最大数量。 栗子: 123456789101112131415161718192021222324252627curl -G http://localhost:9091/api/v1/targets/metadata \ --data-urlencode &apos;metric=go_goroutines&apos; \ --data-urlencode &apos;match_target=&#123;job=&quot;prometheus&quot;&#125;&apos; \ --data-urlencode &apos;limit=2&apos;&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: [ &#123; &quot;target&quot;: &#123; &quot;instance&quot;: &quot;127.0.0.1:9090&quot;, &quot;job&quot;: &quot;prometheus&quot; &#125;, &quot;type&quot;: &quot;gauge&quot;, &quot;help&quot;: &quot;Number of goroutines that currently exist.&quot;, &quot;unit&quot;: &quot;&quot; &#125;, &#123; &quot;target&quot;: &#123; &quot;instance&quot;: &quot;127.0.0.1:9091&quot;, &quot;job&quot;: &quot;prometheus&quot; &#125;, &quot;type&quot;: &quot;gauge&quot;, &quot;help&quot;: &quot;Number of goroutines that currently exist.&quot;, &quot;unit&quot;: &quot;&quot; &#125; ]&#125; 栗子: 1234567891011121314151617181920212223242526272829curl -G http://localhost:9091/api/v1/targets/metadata \ --data-urlencode &apos;match_target=&#123;instance=&quot;127.0.0.1:9090&quot;&#125;&apos;&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: [ // ... &#123; &quot;target&quot;: &#123; &quot;instance&quot;: &quot;127.0.0.1:9090&quot;, &quot;job&quot;: &quot;prometheus&quot; &#125;, &quot;metric&quot;: &quot;prometheus_treecache_zookeeper_failures_total&quot;, &quot;type&quot;: &quot;counter&quot;, &quot;help&quot;: &quot;The total number of ZooKeeper failures.&quot;, &quot;unit&quot;: &quot;&quot; &#125;, &#123; &quot;target&quot;: &#123; &quot;instance&quot;: &quot;127.0.0.1:9090&quot;, &quot;job&quot;: &quot;prometheus&quot; &#125;, &quot;metric&quot;: &quot;prometheus_tsdb_reloads_total&quot;, &quot;type&quot;: &quot;counter&quot;, &quot;help&quot;: &quot;Number of times the database reloaded block data from disk.&quot;, &quot;unit&quot;: &quot;&quot; &#125;, // ... ]&#125; 告警器AlertManagers 此端点返回Prometheus alertmanager discovery的当前状态的概述: 1GET /api/v1/alertmanagers active和dropped Alertmanagers都是响应的一部分: 12345678910111213141516curl http://localhost:9090/api/v1/alertmanagers&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: &#123; &quot;activeAlertmanagers&quot;: [ &#123; &quot;url&quot;: &quot;http://127.0.0.1:9090/api/v1/alerts&quot; &#125; ], &quot;droppedAlertmanagers&quot;: [ &#123; &quot;url&quot;: &quot;http://127.0.0.1:9093/api/v1/alerts&quot; &#125; ] &#125;&#125; 状态Status 以下状态端点暴露当前Prometheus配置。 Config 此端点返回当前加载的配置文件: 1GET /api/v1/status/config 配置返回为转存的YAML文件。由于YAML库的限制，YAML中不包含注释: 1234567curl http://localhost:9090/api/v1/status/config&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: &#123; &quot;yaml&quot;: &quot;&lt;content of the loaded config file in YAML&gt;&quot;, &#125;&#125; Flags 此端点返回Prometheus配置的标志值: 1GET /api/v1/status/flags 所有值的结果类型都是字符串: 123456789101112curl http://localhost:9090/api/v1/status/flags&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: &#123; &quot;alertmanager.notification-queue-capacity&quot;: &quot;10000&quot;, &quot;alertmanager.timeout&quot;: &quot;10s&quot;, &quot;log.level&quot;: &quot;info&quot;, &quot;query.lookback-delta&quot;: &quot;5m&quot;, &quot;query.max-concurrency&quot;: &quot;20&quot;, ... &#125;&#125; RunTime Information 此端点返回Prometheus Server的各种运行信息属性: 1GET /api/v1/status/runtimeinfo 根据运行属性，返回的值有两种类型: 123456789101112131415161718curl http://localhost:9090/api/v1/status/runtimeinfo&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: &#123; &quot;startTime&quot;: &quot;2019-11-02T17:23:59.301361365+01:00&quot;, &quot;CWD&quot;: &quot;/&quot;, &quot;reloadConfigSuccess&quot;: true, &quot;lastConfigTime&quot;: &quot;2019-11-02T17:23:59+01:00&quot;, &quot;chunkCount&quot;: 873, &quot;timeSeriesCount&quot;: 873, &quot;corruptionCount&quot;: 0, &quot;goroutineCount&quot;: 48, &quot;GOMAXPROCS&quot;: 4, &quot;GOGC&quot;: &quot;&quot;, &quot;GODEBUG&quot;: &quot;&quot;, &quot;storageRetention&quot;: &quot;15d&quot; &#125;&#125; Build Information 此端点返回各种关于Prometheus Server的构建信息属性: 1GET /api/v1/status/buildinfo 所有结果的值的类型都是字符串: 123456789101112curl http://localhost:9090/api/v1/status/buildinfo&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: &#123; &quot;version&quot;: &quot;2.13.1&quot;, &quot;revision&quot;: &quot;cb7cbad5f9a2823a622aaa668833ca04f50a0ea7&quot;, &quot;branch&quot;: &quot;master&quot;, &quot;buildUser&quot;: &quot;julius@desktop&quot;, &quot;buildDate&quot;: &quot;20191102-16:19:59&quot;, &quot;goVersion&quot;: &quot;go1.13.1&quot; &#125;&#125; TSDB Admin APIs这些都是为高级用户公开的数据库功能的API。除非设置--web.enable-admin-api，否则不启用这些API。 我们也公开了一个gRPC API。这是实验性的，未来可能会改变。 Snapshot 创建所有当前数据的快照snapshots/datetime-rand早TSDB的数据目录并返回目录作为响应。它将可选地跳过快照数据尽在头部块，并且未被压缩到磁盘。 12POST /api/v1/admin/tsdb/snapshotPUT /api/v1/admin/tsdb/snapshot URL查询参数: skip_head=&lt;bool&gt;: 跳过存在于头部块(head block)的数据，可选。 1234567curl -XPOST http://localhost:9090/api/v1/admin/tsdb/snapshot&#123; &quot;status&quot;: &quot;success&quot;, &quot;data&quot;: &#123; &quot;name&quot;: &quot;20171210T211224Z-2be650b6d019eb54&quot; &#125;&#125; 快照现在位于: &lt;data-dir&gt;/snapshots/20171210T211224Z-2be650b6d019eb54 Delete Series 删除在一个时间范围内选择的一些列数据。实际数据仍然存在于磁盘上，并在未来被清除或通过点击Clean Tombstones endpoint来明确清理。如果成功，返回204。 12POST /api/v1/admin/tsdb/delete_seriesPUT /api/v1/admin/tsdb/delete_series URL查询参数: match[]=&lt;series_selector&gt;: 至少必须提供一个 start=&lt;rfc3339 | unix_timestamp&gt; end=&lt;rfc3339 | unix_timestamp&gt; 未指定时间范围将删除匹配的所有数据。 1curl -X POST -g &apos;http://localhost:9090/api/v1/admin/tsdb/delete_series?match[]=up&amp;match[]=process_start_time_seconds&#123;job=&quot;prometheus&quot;&#125;&apos; Clean Tombstones 从磁盘中删除已删除的数据并清理现有的tombstones。这可在清理数据后腾出磁盘空间。 如果成功，返回204。 12POST /api/v1/admin/tsdb/clean_tombstonesPUT /api/v1/admin/tsdb/clean_tombstones 不需要任何参数或body: 1curl -XPOST http://localhost:9090/api/v1/admin/tsdb/clean_tombstones 存储Storage: https://prometheus.io/docs/prometheus/latest/storage/ Prometheus包含了一个本地磁盘上的时序数据库(time series database)，但是可选地与远程存储系统集成。 本地存储Local storage Prometheus本地时序数据库存储时序数据自定义格式存储到磁盘上。 On-disk layout Prometheus按两小时为一个时间窗口分组存储在一个块(block)中。每个块是一个单独地目录，里面包含该时间窗口内的所有样本数据(chunks)，元数据文件(meta.json)以及索引文件(index)。其中索引文件会将指标名称和标签索引到样板数据的时间序列中。此期间如果通过 API 删除时间序列，删除记录会保存在单独的逻辑文件tombstone当中。 当前样本数据所在的块会被直接保存在内存中，不会持久化到磁盘中。为了确保Prometheus发生崩溃或重启时能够恢复数据，Prometheus启动时会通过预写日志（write-ahead-log(WAL)）重新记录，从而恢复数据。预写日志文件保存在wal目录中，每个文件大小为128MB。wal 文件包括还没有被压缩的原始数据，所以比常规的块文件大得多。一般情况下，Prometheus 会保留三个 wal 文件，但如果有些高负载服务器需要保存两个小时以上的原始数据，wal文件的数量就会大于3个。 Prometheus块数据的目录结构如下所示: 1234567891011121314151617181920./data├── 01BKGV7JBM69T2G1BGBGM6KB12│ └── meta.json├── 01BKGTZQ1SYQJTR4PB43C8PD98│ ├── chunks│ │ └── 000001│ ├── tombstones│ ├── index│ └── meta.json├── 01BKGTZQ1HHWHV8FBJXW1Y3W0K│ └── meta.json├── 01BKGV7JC0RY8A6MACW02A2PJD│ ├── chunks│ │ └── 000001│ ├── tombstones│ ├── index│ └── meta.json└── wal ├── 00000002 └── checkpoint.000001 本地存储的局限性是它无法构建集群(clustered)或副本(replicated)。因此，如果本地磁盘或节点出现故障，存储将无法扩展和迁移。使用RAID用于磁盘的可用性，使用快照用于备份，容量规划…建议提高耐用性。如果你对数据持久化的要求不是很严格，可以使用本地磁盘存储多达数年的数据。 可替代地，外部存储可通过使用remote read/write APIs。仔细评估这些系统，因为它们在耐用性，性能和效率差异很大。 有关存储格式的详细信息，请参考 TSDB格式 Compaction最初两个小时的块最终会在后台被压缩成更长的块。 操作配置Prometheus提供了几个标志来允许配置本地存储。最重要的几个: 1234567891011121314# 数据存储路径，默认data/--storage.tsdb.path# 样本数据在存储中保存的时间。超过该时间限制的数据就会被删除。默认15d-storage.tsdb.retention.time# 每个块的最大字节数（不包括 wal 文件）。如果超过限制，最早的样本数据会被优先删除。支持的单位有 KB, MB, GB, PB。默认0，即为不限制--storage.tsdb.retention.size# 压缩wal--storage.tsdb.wal-compression 一般情况下，Prometheus中存储的每一个样本大概会占用1-2Byte。因此，如果需要对Prometheus Server的本地磁盘空间做容量规划，可通过以下公式计算: 1needed_disk_space = retention_time_seconds * ingested_samples_per_second * bytes_per_sample 从上面公式中可以看出在保留时间（retention_time_seconds）和样本大小（bytes_per_sample）不变的情况下，如果想减少本地磁盘的容量需求，只能通过减少每秒获取样本数（ingested_samples_per_second）的方式。因此有两种手段，一是减少时间序列的数量，二是增加采集样本的时间间隔。考虑到 Prometheus 会对时间序列进行压缩效率，减少时间序列的数量效果更明显。 可视化Visualization 表达式浏览器Expression browser 表达其浏览器在 Prometheus Server 的 /graph 处。对于图形，请使用 Grafana 或 Console template。 GrafanaGrafana: https://grafana.com/ Grafana，美丽的分析和监控的开放平台，时序分析的开源那软件。 Grafana 支持查询 Prometheus。如下是一个Grafana仪表盘，用于查询Prometheus的数据： 安装完整的安装说明，请查看Grafana Docs。 CentOSRPM 12#sudo yum install &lt;rpm package url&gt;sudo yum install https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-5.1.4-1.x86_64.rpm repo 1234567891011121314151617181920[grafana]name=grafanabaseurl=https://packagecloud.io/grafana/stable/el/7/$basearchrepo_gpgcheck=1enabled=1gpgcheck=1gpgkey=https://packagecloud.io/gpg.key https://grafanarel.s3.amazonaws.com/RPM-GPG-KEY-grafanasslverify=1sslcacert=/etc/pki/tls/certs/ca-bundle.crtsudo yum install -y grafana#启动systemctl start grafana-server#命令行工具grafana-cli 包详情 Installs binary to /usr/sbin/grafana-server Copies init.d script to /etc/init.d/grafana-server Installs default file (environment vars) to /etc/sysconfig/grafana-server Copies configuration file to /etc/grafana/grafana.ini Installs systemd service (if systemd is available) name grafana-server.service The default configuration uses a log file at /var/log/grafana/grafana.log The default configuration specifies an sqlite3 database at /var/lib/grafana/grafana.db 二进制tar文件 1234567# Download and unpack Grafana from binary tar (adjust version as appropriate).curl -L -O https://grafanarel.s3.amazonaws.com/builds/grafana-2.5.0.linux-x64.tar.gztar zxf grafana-2.5.0.linux-x64.tar.gz# Start Grafana.cd grafana-2.5.0/./bin/grafana-server web Docker123456789101112131415161718192021#基础栗子docker run -d -p 3000:3000 grafana/grafana#配置化docker run \ -d \ -p 3000:3000 \ --name=grafana \ -e &quot;GF_SERVER_ROOT_URL=http://grafana.server.name&quot; \ -e &quot;GF_SECURITY_ADMIN_PASSWORD=secret&quot; \ grafana/grafana:version#默认环境变量值GF_PATHS_CONFIG /etc/grafana/grafana.iniGF_PATHS_DATA /var/lib/grafanaGF_PATHS_HOME /usr/share/grafanaGF_PATHS_LOGS /var/log/grafanaGF_PATHS_PLUGINS /var/lib/grafana/pluginsGF_PATHS_PROVISIONING /etc/grafana/provisioning 使用默认情况下，访问http://localhost:3000来访问Grafana。默认登录的用户名和密码： admin/admin。 创建Prometheus数据源 创建Prometheus图表 Console template控制台模板允许使用Go templating language创建任意控制台。这些都是从Prometheus Server提供的。 示例配置由于prometheus自带的alertmanager对国内通知支持不够完善，因此使用PrometheusAlert做告警通知。 prometheus配置样例prometheus的配置示例: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# my global configglobal: scrape_interval: 1m # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 1m # Evaluate rules every 15 seconds. The default is every 1 minute. scrape_timeout: 1m # scrape_timeout is set to the global default (10s). # for thanos external_labels: region: ali # hw|tx replica: full# Alertmanager configurationalerting: alertmanagers: - static_configs: - targets: ["localhost:9093"]# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.rule_files: - "rules/*.yml" # 通用告警规则模板 - "rules/nodes/*.yml" # 各主机告警规则# A scrape configuration containing exactly one endpoint to scrape:# Here it's Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: node-process-exporter file_sd_configs: - files: - "discovery/exporter/*.yml" # metrics_path defaults to '/metrics' # scheme defaults to 'http'. - job_name: mongodb-exporter file_sd_configs: - files: - "discovery/mongodb/*.yml" - job_name: kafka-exporter file_sd_configs: - files: - "discovery/kafka/*.yml" - job_name: aliyun-exporter static_configs: - targets: ["localhost:9525", "localhost:9526", "localhost:9527", "localhost:9528", "localhost:9529"] - job_name: blackbox_exporter metrics_path: /probe file_sd_configs: - files: - "discovery/blackbox/*.yml" relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [module] target_label: __param_module - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: 127.0.0.1:9115 alertmanager配置样例alertmanager的配置示例: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# global configglobal: resolve_timeout: 5m # smtp config # slack config # wechat config # http config# templates configtemplates: []# route treeroute: receiver: 'web.hook.prometheusalert' group_by: - instanceId - hostname group_wait: 30s group_interval: 1m # notification again repeat_interval: 10m # continue config # match: [ &lt;labelname&gt;: &lt;labelvalue&gt;, ... ] # match_re: [ &lt;labelname&gt;: &lt;regex&gt;, ... ] routes: - match: severity: warning repeat_interval: 1h - match_re: severity: notice|info repeat_interval: 6h# receiver listsreceivers:- name: 'web.hook.prometheusalert' webhook_configs: - url: 'http://127.0.0.1:8080/prometheus/alert'# list of inhibit rulesinhibit_rules: # aliyun - source_match: severity: 'critical' target_match_re: severity: 'warning' # source_match_re # target_match_re # Labels that must have an equal value in the source and target equal: ['instance','job','instanceId','kind'] # nodes - source_match: severity: 'critical' target_match_re: severity: 'warning' equal: - instance - job - hostname - kind prometheus自动发现prometheus的文件自动发现示例: 123456- labels: hostname: localhost hostgroup: test targets: - "localhost:9100" # node-exporter - "localhost:9256" # process-exporter prometheus告警规则prometheus的告警规则示例: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258groups:- name: node-cpu rules: # cpu核数 - record: instance:node_cpus:count expr: count without (cpu, mode) (node_cpu_seconds_total&#123;mode="idle"&#125;) # 每个cpu使用率 - record: instance_cpu:node_cpu_seconds_not_idle:rate2m expr: sum without (mode) (1 - rate(node_cpu_seconds_total&#123;mode="idle"&#125;[2m])) # 总cpu使用率 - record: instance:node_cpu_utilization:ratio expr: avg without (cpu) (instance_cpu:node_cpu_seconds_not_idle:rate2m) - alert: cpu使用率大于85% ### expr: (1 - avg(irate(node_cpu_seconds_total&#123;mode="idle"&#125;[5m])) by(instance,hostname)) * 100 &gt; 85 expr: instance:node_cpu_utilization:ratio * 100 &gt; 85 for: 3m labels: severity: warning level: 2 kind: CpuUsage annotations: summary: "cpu使用率大于85%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125;的cpu使用率: &#123;&#123; $value | humanize &#125;&#125;%" - alert: cpu使用率大于90% ### expr: (1 - avg(irate(node_cpu_seconds_total&#123;mode="idle"&#125;[5m])) by(instance,hostname)) * 100 &gt; 90 expr: instance:node_cpu_utilization:ratio * 100 &gt; 90 for: 1m labels: severity: critical level: 3 kind: CpuUsage annotations: summary: "cpu使用率大于90%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125;的cpu使用率: &#123;&#123; $value | humanize &#125;&#125;%" wxurl: "xxx" - alert: cpu使用率一分钟内增长30%且大于70% expr: delta(instance:node_cpu_utilization:ratio[2m]) * 100 &gt; 30 and on(hostname) instance:node_cpu_utilization:ratio * 100 &gt; 70 labels: severity: warning level: 2 kind: CpuUsageDelta annotations: summary: "cpu使用率一分钟内增长30%且大于70%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125; 的cpu使用率一分钟内增长30%且大于70%，增长率: &#123;&#123; $value | humanize &#125;&#125;%" wxurl: "xxx" - alert: cpu使用率一分钟内增长40%且大于80% expr: delta(instance:node_cpu_utilization:ratio[2m]) * 100 &gt; 40 and on(hostname) instance:node_cpu_utilization:ratio * 100 &gt; 80 labels: severity: critical level: 3 kind: CpuUsageDelta annotations: summary: "cpu使用率一分钟内增长40%且大于80%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125; 的cpu使用率一分钟内增长40%且大于80%，增长率: &#123;&#123; $value | humanize &#125;&#125;%" - alert: cpu使用率一分钟内增长50% expr: delta(instance:node_cpu_utilization:ratio[2m]) * 100 &gt; 50 labels: severity: critical level: 3 annotations: summary: "cpu使用率一分钟内增长50%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125; 的cpu使用率一分钟内增长50%，增长率: &#123;&#123; $value | humanize &#125;&#125;%" - alert: cpu负载大于Cores ### expr: node_load1 &gt; count(node_cpu_seconds_total&#123;mode="idle"&#125;) without (cpu,mode) expr: node_load1 &gt; instance:node_cpus:count for: 3m labels: severity: warning level: 2 kind: CpuLoad annotations: summary: "cpu负载大于cpu核数: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125;的cpu负载: &#123;&#123; $value &#125;&#125;" - alert: cpu负载大于2Cores-2 ### expr: node_load1 &gt; 2 * (count(node_cpu_seconds_total&#123;mode="idle"&#125;) without (cpu,mode)) - 2 expr: node_load1 &gt; (instance:node_cpus:count * 2) - 2 for: 1m labels: severity: critical level: 3 kind: CpuLoad annotations: summary: "cpu负载大于2Cores-2: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125;的cpu负载: &#123;&#123; $value &#125;&#125;" - alert: 主机上下文切换忙 ### expr: (rate(node_context_switches_total[5m])) / (count without(cpu, mode) (node_cpu_seconds_total&#123;mode="idle"&#125;)) &gt; 2000 expr: (rate(node_context_switches_total[5m]) / instance:node_cpus:count) &gt; 2000 for: 5m labels: severity: warning level: 2 annotations: summary: "主机上下文切换忙: &#123;&#123; $labels.hostname &#125;&#125;" description: "主机&#123;&#123; $labels.hostname &#125;&#125;的上下文切换大于2000/s: &#123;&#123; $value | humanize &#125;&#125;/s"- name: node-memory rules: # 内存可用率 - record: instance:node_memory_available:ratio expr: &gt; ( node_memory_MemAvailable_bytes or ( node_memory_Buffers_bytes + node_memory_Cached_bytes + node_memory_MemFree_bytes + node_memory_Slab_bytes ) ) / node_memory_MemTotal_bytes # 内存使用率 - record: instance:node_memory_utilization:ratio expr: 1 - instance:node_memory_available:ratio - alert: 主机内存面临压力 expr: rate(node_vmstat_pgmajfault[1m]) &gt; 1000 for: 5m labels: severity: warning level: 2 annotations: summary: "主机内存面临压力: &#123;&#123; $labels.instance &#125;&#125;" description: "节点内存面临压力。High rate of major page faults: &#123;&#123; $value &#125;&#125;" - alert: 内存使用率大于85% ### expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 &gt; 85 expr: instance:node_memory_utilization:ratio * 100 &gt; 85 for: 3m labels: severity: warning level: 2 kind: MemoryUsage annotations: summary: "内存使用率超过85%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125;的内存使用率: &#123;&#123; $value | humanize &#125;&#125;%" - alert: 内存使用率大于90% ### expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 &gt; 90 expr: instance:node_memory_utilization:ratio * 100 &gt; 90 for: 1m labels: severity: critical level: 3 kind: MemoryUsage annotations: summary: "内存使用率超过90%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125;的内存使用率: &#123;&#123; $value | humanize &#125;&#125;%" - alert: 内存使用率一分钟内增长30%且大于70% expr: delta(instance:node_memory_utilization:ratio[2m]) * 100 &gt; 30 and on(hostname) instance:node_memory_utilization:ratio * 100 &gt; 70 labels: severity: warning level: 2 kind: MemoryUsageDelta annotations: summary: "内存使用率一分钟内增长30%且大于70%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125; 的内存使用率一分钟内增长30%且大于70%，增长率: &#123;&#123; $value | humanize &#125;&#125;%" - alert: 内存使用率一分钟内增长40%且大于80% expr: delta(instance:node_memory_utilization:ratio[2m]) * 100 &gt; 40 and on(hostname) instance:node_memory_utilization:ratio * 100 &gt; 80 labels: severity: critical level: 3 kind: MemoryUsageDelta annotations: summary: "内存使用率一分钟内增长40%且大于80%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125; 的内存使用率一分钟内增长40%且大于80%，增长率: &#123;&#123; $value | humanize &#125;&#125;%" - alert: 内存使用率一分钟内增长50% expr: delta(instance:node_memory_utilization:ratio[2m]) * 100 &gt; 50 labels: severity: critical level: 3 annotations: summary: "内存使用率一分钟内增长50%: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125; 的内存使用率一分钟内增长50%，增长率: &#123;&#123; $value | humanize &#125;&#125;%" - alert: 主机检测到oom kill expr: &gt; increase(node_vmstat_oom_kill[1h]) &gt; 2 or increase(syslog_oom_kills_total[1h]) &gt; 2 labels: severity: warning level: 2 annotations: summary: "主机检测到oom kill: &#123;&#123; $labels.hostname &#125;&#125;" description: "&#123;&#123; $labels.hostname &#125;&#125;检测到oom kill: &#123;&#123; $value &#125;&#125;"- name: node-filesystem rules: # 磁盘分区可用率 - record: instance:node_filesystem_avail:ratio expr: node_filesystem_avail_bytes&#123;device=~"(/dev/.+|tank/dataset)"&#125; / node_filesystem_size_bytes&#123;device=~"(/dev/.+|tank/dataset)"&#125; # 磁盘分区使用率 - record: instance:node_filesystem_utilization:ratio expr: 1 - instance:node_filesystem_avail:ratio # 分区inode可用率 - record: instance:node_filesystem_files_avail:ratio expr: node_filesystem_files_free / node_filesystem_files # 分区inode使用率 - record: instance:node_filesystem_files_utilization:ratio expr: 1 - instance:node_filesystem_files_avail:ratio - alert: 磁盘分区使用率大于85% ### expr: (1- (node_filesystem_avail_bytes&#123;fstype=~"ext4|xfs"&#125; / node_filesystem_size_bytes&#123;fstype=~"ext4|xfs"&#125;)) * 100 &gt; 85 expr: instance:node_filesystem_utilization:ratio&#123;fstype=~"(ext.|xfs|zfs)"&#125; * 100 &gt; 85 for: 10m labels: severity: warning level: 2 kind: "&#123;&#123; $labels.mountpoint &#125;&#125;" annotations: summary: "磁盘分区&#123;&#123; $labels.mountpoint&#125;&#125;使用率大于85%" description: "&#123;&#123; $labels.hostname &#125;&#125;的磁盘分区&#123;&#123; $labels.mountpoint &#125;&#125;使用率为: &#123;&#123; $value | humanize &#125;&#125;%" - alert: 磁盘分区使用率大于90% ### expr: (1- (node_filesystem_avail_bytes&#123;fstype=~"ext4|xfs"&#125; / node_filesystem_size_bytes&#123;fstype=~"ext4|xfs"&#125;)) * 100 &gt; 90 expr: instance:node_filesystem_utilization:ratio&#123;fstype=~"(ext.|xfs|zfs)"&#125; * 100 &gt; 90 for: 3m labels: severity: critical level: 3 kind: "&#123;&#123; $labels.mountpoint &#125;&#125;" annotations: summary: "磁盘分区&#123;&#123; $labels.mountpoint&#125;&#125;使用率大于90%" description: "&#123;&#123; $labels.hostname &#125;&#125;的磁盘分区&#123;&#123; $labels.mountpoint &#125;&#125;使用率为: &#123;&#123; $value | humanize &#125;&#125;%" - alert: 分区inode使用率大于70% ### expr: (1 - (node_filesystem_files_free&#123;fstype=~"ext4|xfs"&#125; / node_filesystem_files&#123;fstype=~"ext4|xfs"&#125;)) * 100 &gt; 70 expr: instance:node_filesystem_files_utilization:ratio&#123;fstype=~"(ext.|xfs)"&#125; * 100 &gt; 70 for: 3m labels: severity: info level: 1 annotations: summary: "磁盘分区&#123;&#123; $labels.mountpoint &#125;&#125;的inode使用率大于70%" description: "&#123;&#123; $labels.hostname &#125;&#125;的磁盘分区&#123;&#123; $labels.mountpoint &#125;&#125;的inode使用率: '&#123;&#123; $value | humanize &#125;&#125;%'" - alert: 分区inode使用率大于80% ### expr: (1 - (node_filesystem_files_free&#123;fstype=~"ext4|xfs"&#125; / node_filesystem_files&#123;fstype=~"ext4|xfs"&#125;)) * 100 &gt; 80 expr: instance:node_filesystem_files_utilization:ratio&#123;fstype=~"(ext.|xfs)"&#125; * 100 &gt; 80 for: 3m labels: severity: warning level: 2 annotations: summary: "磁盘分区&#123;&#123; $labels.mountpoint &#125;&#125;的inode使用率大于80%" description: "&#123;&#123; $labels.hostname &#125;&#125;的磁盘分区&#123;&#123; $labels.mountpoint &#125;&#125;的inode使用率: '&#123;&#123; $value | humanize &#125;&#125;%'" 进程探针配置process-exporter探针配置示例: 123456789101112131415# https://github.com/ncabatoff/process-exporter# /proc/&lt;pid&gt;/xxxprocess_names: # java - name: "&#123;&#123;.Matches&#125;&#125;" cmdline: - '.+/bin/java .+' - name: "&#123;&#123;.Matches&#125;&#125;" cmdline: - 'java .+' #匹配完整的运行命令 - name: "&#123;&#123;.Matches&#125;&#125;" #- name: "&#123;&#123;.Comm&#125;&#125;" cmdline: - '.+' 进程告警规则prometheus进程告警规则示例: 1234567891011121314151617181920212223242526groups:- name: 测试进程告警规则 rules: - alert: nginx进程不存在 expr: 'sum(namedprocess_namegroup_states&#123;groupname=~"map\\[:nginx: master process .+"&#125;) without(state) == 0' for: 1m labels: severity: critical level: 3 annotations: summary: "nginx进程不存在, 实例: &#123;&#123; $labels.instance &#125;&#125;" description: "主机: &#123;&#123; $labels.hostname &#125;&#125;, 进程不存在: &#123;&#123; $labels.groupname &#125;&#125;" wxurl: webhook1,webhook2 mobile: phone1,phone2 - alert: filebeat进程不存在 expr: sum without(state) (namedprocess_namegroup_states&#123;groupname=~"map\\[:/usr/share/filebeat/bin/filebeat -e -c .+", hostgroup="xxx"&#125;) == 0 for: 1m labels: severity: critical level: 3 annotations: summary: "filebeat进程不存在, 实例: &#123;&#123; $labels.instance &#125;&#125;" description: "主机: &#123;&#123; $labels.hostname &#125;&#125;, 进程不存在: &#123;&#123; $labels.groupname &#125;&#125;" wxurl: webhook1,webhook2 mobile: phone1,phone2 集成INSTRUMENTING 客户端库CLIENT LIBRARIES: https://prometheus.io/docs/instrumenting/clientlibs/ 在监控服务之前，您需要通过 Prometheus 客户端库在其代码中添加集成。 选择与你编程语言相匹配的prometheus client library。你可以通过你的应用程序实例的HTTP endpoint来定义和暴露内部指标数据。 当prometheus采集你实例的HTTP端点时，客户端库会将所有指标的当前状态发送给prometheus server。 编写客户端库WRITING CLIENT LIBRARIES: https://prometheus.io/docs/instrumenting/writing_clientlibs/ 本章涵盖了Prometheus client libraries应该提供的功能和API。支持10种编程语言，因此编写客户端有很好的感觉。 惯例Conventions 应该注意的事： 采取每门语言的优点 常见的使用情况应该很容易 做某事的正确方式应该是简单的方式 更复杂的用例应该是可能的 常见用例： Counters without labels spread liberally around libraries/applications Timing functions/blocks of code in Summaries/Histograms Gauges to track current states of things (and their limits) Monitoring of batch jobs 整体结构Overall structure 客户端必须在内部进行回调以进行写操作。客户端一般应该遵循如下描述的结构。 关键类是收集器(collector)。这有个方法(一般称为collect)，此方法返回0和更多指标和样本。Collectors get registered with a CollectorRegistry. 数据通过传递一个CollectorRegistry到一个bridge类/方法/函数来公开，返回的是Promehteus支持的格式指标。每次CollectorRegistry抓取它必须回调每个收集器的收集方法。 大多数用户交互的接口是Counter, Gauge, Summary, Histogram收集器。这些代表一个单一指标，并应涵盖绝大多数使用情况，其中用户集成自己的代码。 更高级的用户案例（如从其它监控系统进行代理）需要编写一个自定义收集器。有人可能还希望编写一个bridge，以一个格式不同的监控系统来产生CollectorRegistry和生成数据，允许用户只考虑一个集成系统。 CollectorRegistry应该提供register(), unregister()函数，并且一个收集器应该被允许注册到多个CollectorRegistrys。 客户端必须是线程安全的。 命名 Namming 客户端库应遵循此文档中提及的函数，方法，类名称，记住它们的命名规范。例如，set_to_current_time()是一个好的Python命名规范，SetToCurrentTime()是一个好的Go命名规范，setToCurrentTime()是一个好的Java命名规范。 指标Metrics Counter, Gauge, Summary, Histogram指标类型是用户的主要接口。 Counter和Gauge必须是客户端库的一部分。Summary和Histogram至少有一个必须提供。 这些应主要用于为静态文件变量(file-static variables)，也就是说，全局变量定义在同一个文件，因为他们集成代码。客户端库应该启用它。常用情况是集成一段整体代码，而不是一个对象的一个实例的上下文中的一段代码。用户不应该在代码中担心探测他们的指标，客户端库应该代劳。 必须有一个默认的CollectorRegistry，默认的标准指标必须隐式注册到它与该用户不需要的特殊工作。必须有一个方式来让指标不注册到默认CollectorRegistry，在批处理作业和单元测试。自定义收集器应该遵顼这一点。 究竟编程语言应该如何创建指标。对于一些(Java, Go)构建器方法是最好的，对于其它(Python)函数参数是足够丰富的。 Java样例客户端: 12345class YourClass &#123; static final Counter requests = Counter.build() .name("requests_total") .help("Requests.").register();&#125; Counter Counter是一个单调递增的计数器。它不允许值减少，但可能被重置为0（如服务器重启）。 计数器必须有以下方法： inc()：计数器递增1 inc(douvel v)：计数器由给定数增加（v&gt;=0） 计数器必须从0开始。 计数器建议有： 计算给定一段代码异常抛出/升起的方法，可选地仅特定异常类型 Gauge Gauge表示一个值可增可减。 测量必须有以下方法： inc()：测量递增1 inc(double v)：测量由给定数增加 dec()：测量递减1 dec(double v)：测量由戈丁数减少 set(double v)：测量被设置为给定值 测量必须从0开始，你也可以在启动时提供一个不同值。 测量应该有以下方法： set_to_current_time()：将测量设置为unixtime 测量建议有： 使用一个方法来追踪某条函数/代码正在进行的请求。在Python中是track_inprogress。 测试一段代码实践的一个方法和测试测量的持续时间。这对于批量作业很有用。 Summary Summary样例观察滑动时间窗，兵器提供分布、频率、和的瞬时观察。 摘要绝不允许用户设置quantile作为标签名，因为这是内部使用的指定摘要总数(summary quantiles)。摘要鼓励提供quantiles作为exports，但这些都布恩那个进行聚合，并趋于缓慢。摘要必须允许每个quantiles，如_count, _sum是非常有用的，这必须是默认的。 摘要_count, _sum必须从0开始。 摘要必须有的方法： observe(double v)：观察给定的量 摘要应该有的方法： 以秒为用户的时间码。在Python中是time()。不能提供除了秒之外的其它单位。 Histogram Histogram允许事件的可分布聚合，如请求的等待时间。 直方图绝不允许le作为用户设置的label，le用于内部指派桶。 直方图必须提供一个方式来手动选择桶。方式以linear(start, width, count)和exponential(start, factor, count)应该提供来设置桶。计数必须排除+Inf桶。 直方图应该有相同的默认桶作为其它客户端库。一旦创建了指标桶就不能改变。 直方图必须有的方法： observe(double v) 直方图应该有的方法： 以秒为用户的时间码。不能提供除了秒之外的其它单位。 标签 Labels 标签是Prometheus最强大的一个方面，但容易被滥用。因此客户端库必须在提供标签给用户时必须非常小心。 客户端库必须在任何情况下让用户为Gauge, Counter, Summary, Histogram或其它由库提供的任意收集器有不同的标签名。 自定义收集器指标应该总是具有一致的标签名。客户端不该对此进行验证。 虽然标签很强大，但多数指标没有标签。因此，API应该允许标签，而不是控制它。 一个客户端库必须允许在Gauge, Counter, Summary, Histogram创建时间指定任意标签名的列表。客户端库应该支持任意数量的标签名。客户端库必须验证标签名称符合文件要求。 提供访问指标的标记尺寸的一般方法是通过labels()方法，它可以以标签指列表或从标签名到标签执的映射，并返回一个child。通常是.inc(), .dec(), .observe()等等。方法可以在child上调用。 通过labels()返回的Child应该由用户缓存，以避免再次看到它。 有标签的指标应该支持有相同签名作为labels()的remove()方法，这将从指标中移除一个child并不再公开它，clear()方法将移除指标的所有孩子。 这应该有一个方法，来初始化一个带有默认值的孩子，通常只是调用labels()。不带标签的指标必须总是被初始化，以避免缺失指标问题。 指标名称 Metric names 指标名称必须遵循规范。正如指标名称，这必须满足Gauge, Counter, Summary, Histogram的用途，并与该库提供的任意收集器。 许多客户端库提供三个部分来设置名称：namespace_subsystem_name。 动态/生成 指标名称或指标名子部分必须阻止，当一个自定义收集器从其它监控系统代理时除外。动态的/生成的 指标名称是你要使用的标签而不是一个标志。 指标描述和帮助 Metric description and help Gauge/Counter/Summary/Histogram 必须要求提供指标描述和帮助。客户端库提供的任意自定义收集器必须在指标上有描述和帮助。 公开Exposition 客户端必须执行基于文本的公开格式，详细文档: https://prometheus.io/docs/instrumenting/exposition_formats/ 公开的指标的可再现的顺序是鼓励的（尤其是以人类可读的格式），如果它可在没有显著资源成本增加来实现。 标准和运行时收集器Standard and runtime collectors 客户端库应该在标准导出中提供些什么，下面将介绍。 这些应该被实现为自定义收集器，并在默认的CollectorRegistry默认注册。应该有方式来禁用这些。 进程指标 Process metrics 这有一些以process_为前缀的指标。如果获得必要的值是有问题的，或甚至根本无法使用语言，或运行时，客户端库应该留出相应的指标或特殊值(如NaN)。所有以字节的内存值，所有以unixtime/seconds的时间。 指标名 帮助字符串 单位 process_cpu_seconds_total Total user and system CPU time spent in seconds seconds process_open_fds Number of open file descriptors file descriptors process_max_fds Maximum number of open file descriptors file descriptors process_virtual_memory_bytes Virtual memory size in bytes bytes process_virtual_memory_max_bytes Maximum amount of virtual memory available in bytes bytes process_resident_memory_bytes Resident memory size in bytes bytes process_heap_bytes Process heap size in bytes bytes process_start_time_seconds Start time of the process since unix epoch in seconds seconds 运行时指标 Runtime metrics 此外，客户端库鼓励提供有意义的指标当语言运行时，如go_, hotspot_等等前缀开头的相关指标。 单元测试Unit tests 客户端库应该有覆盖核心集成库和公开的单元测试。 客户端库鼓励提供一个方式，使用户更容易进行单元测试。例如，在Python中有CollectorRegistry.get_sample_value。 打包和依赖Packaging and dependencies 理想情况下，客户端库可以被包括在任意应用程序中添加一些集成而不会破坏程序。因此，添加客户端库的依赖时请小心。 性能考虑Performance considerations 由于客户端库必须是线程安全的，需要某种形式的并发控制和考虑多核机器和应用程序的性能。 根据经验最少的高性能是互斥。处理器原子指令往往是在中间，并且一般是可接受的。 如上所述，labels()的结果应该是可缓存的。指标应该避免被阻塞当它们被递增或递减时。 推送指标PUSHING METRICS: https://prometheus.io/docs/instrumenting/pushing/ 偶尔，你需要监控不能被抓取的组件。Prometheus Pushgateway允许你推送指标。与Prometheus简单额基于文本格式相结合，这使得它很容易集成，甚至使用shell脚本而不需要客户端库。 探针和集成EXPORTERS AND INTEGRATIONS: https://prometheus.io/docs/instrumenting/exporters/ 有许多库和第三方系统可为Prometheus提供相应的指标。 第三方探针Third-party exporters 有一些探针是由Prometheus官方维护的，其它的是由第三方贡献和维护。 编写探针WRITING EXPORTERS: https://prometheus.io/docs/instrumenting/writing_exporters/ 如果你在集成自己的代码，那么Prometheus client library如何集成自己的代码的通用规则应该被遵守。当从另一个监控或集成系统采取指标时，事情往往并不是非黑即白。 当编写一个探针或自定义收集器时，此文档包含的事情你应该考虑。 可维护性和纯度Maintainability and purity 当你编写一个探针时，你需要做出的一个决定是有多少工作你愿意放在获得完美的指标上。 如果有问题的系统只有很少改变的指标的一小撮，然后让一切完美是一个容易的选择，一个好的样例是HAProxy exporter 在另一方面，当系统上有上百个指标是新版本经常变动的，如果你想试图把事情做完美，那么你已经给自己制造了许多正在进行的工作。MysQL exporter在这系列(spectrum)的末端。 node exporter是这些的混合。例如，mdadm收集器手动解析一个文件并公开为此收集器特定创建的指标。对于meminfo收集器，结果跨越不同内核版本，因此我们最终做足够的转换来创建有效的指标。 配置Configuration 当程序工作时，你的目标应该是探针不需要用户自定配置就可以运行。你可能还希望提供过滤某些指标的能力（用户定义只需要收集的指标，不需要收集所有指标），降低系统的开销。例如node exporter可让用户定义收集哪些指标，虽然我是全部收集。 当与其它监控系统一起工作时，框架和协议，你将提供额外的配置或自定义来生成适合Prometheus的指标。在最好的情况下，一个监控系统有类似的足够的Prometheus数据模型，你可以自动确定如何转换指标。如Cloudwatch, SNMP, collectd的情况。至多，我们需要让用户选择获取的那些指标。 也就是探针配置简单化，探针指标用户可选择。 在其它情况下，系统指标是不是十分标准的，这却决于系统和底层应用的使用情况。在这种情况下，用户必须告诉我们如何转换转换指标。JMX exporter是最明显的案例，与Graphite exporter和StatsD exporter也需要配置来提取标签。 确保探针出口开箱没有配置，以及提供需要转换的示例配置的选择，这是一个建议。 YAML是标准的Prometheus配置格式，所有配置默认都应该适应YAML。 指标Metrics 命名Naming 遵循指标命名的最佳实践。 指标名不应该由程序产生，除非在编写自定义收集器或探针时。 指标必须使用基础单位并让它们转换为更可读的图形工具。无论你使用了什么单位，指标名中的单位必须匹配在使用的单位。类似地，公开比率(ratios)，而不是百分比(percentages)。 指标名不应该包含导出的标签，如果标签被聚集将没有意义。Prometheus指标和标签名以snake_case编写。公开的指标不应包含冒号，这些被保留用于用户定义记录规则(recording rules)，当使用聚合时。 只有[a-zA-Z0-9:_]是有效的指标名。 _sum, _count, _bucket, _total后缀用于Summary, Histogram, Counter。_total是Counter的惯例，如果你使用COUNTER类型你应该使用它。 process_, scrape_前缀是保留的。 当你有一个successful request count和一个failed request count，最佳的方式是一个指标用于成功的请求，另一个指标用于失败的请求。这很容易计算出失败率。不要使用带success或failed标签的一个指标。同样，此规则也同样适用于其它指标。 一个带有原始名的HELP字符串可以提供大部分相同的好处。 标签Labels 避免将type作为标签名称，它过于笼统往往无意义。你应该尝试尽可能地避免发生冲突，如region, cluster等等。但是，如果这就是应用程序调用的一些资源，最好不要通过重命名来引起混乱。 因此要避免把东西放入一个指标，只是因为它们共享一个前缀。除非你确定一个指标是有意义的，多个指标是安全的。 le标签对于Histogram有特殊意义，quantile标签对于Summary有特殊意义。通常避免使用这些标签。write/read， send/receive最好划分为单独的指标，而不是一个指标。 经验法则是，当求和或求平均值时，一个指标应该是有意义的。 类型Type 你应该尝试匹配你的指标类型到Prometheus类型。这通常是counters和gauges。通常它不会很明显指标是什么类型，特别是如果你自动处理一组指标。一般UNTYPED是一个安全的默认值。 帮助字符串Help strings 当你转换指标时，它对用于能够追踪原来是什么样的有帮助，以及造成这种转换有什么规则。将收集器或探针名称、应用的任意规则的ID和名称和原始指标的详情写入帮助字符串将极大地帮助用户。 Prometheus不喜欢一个字段有不同的帮助字符串。 示例: 12345# HELP node_cooling_device_max_state Maximum throttle state of the cooling device# TYPE node_cooling_device_max_state gaugenode_cooling_device_max_state&#123;name=&quot;0&quot;,type=&quot;Processor&quot;&#125; 7node_cooling_device_max_state&#123;name=&quot;1&quot;,type=&quot;Processor&quot;&#125; 7node_cooling_device_max_state&#123;name=&quot;2&quot;,type=&quot;Processor&quot;&#125; 7 丢弃更少的有用信息Drop less useful statistics 有些集成系统公开了1m, 5m, 15m率、平均率，在应用程序启动的时候。 这些都应该被丢弃，因为它们不是很有用，并添加了混乱。Prometheus可以自己计算比率，并且通常作为公开的平均值呈指数衰减。 点字符串Dotted strings 许多监控系统没有标签，而是使用点: my.class.path.mymetric.labelvalue1.labelvalue2.labelvalue3 收集器Collectors 当为探针实现收集器时，你永远不应该使用通常的直接集成方法，并在每个抓取上更新指标。 每次创建新的指标。在Go的Collect()方法中使用MustNewConstMetric。Python请参考: https://github.com/prometheus/client_python#custom-collectors 原因有两方面。首先，两个抓取可能发生在同一时间，和直接集成使用的什么是文件级别的全局变量。其次，如果一个标签执消失，它仍然将公开。 关于抓取自身的指标Metrics about the scrape itself 有时你想导出关于抓取的指标，如处理了多少记录等。这应该被公开为gauges当它们关于事件时，通过探针名的指标名前缀，如jmx_scrape_duration_seconds。 机器和进程指标Machine and process metrics 许多系统，如ES，会公开机器指标（如cpu, memory, filesystem）等信息。Prometheus生态中的node exporter提供了这些信息，这些指标就应该被丢弃。 在Java世界里，许多集成框架公开了程序级别和JVM级别的统计信息，如CPU, GC等。Java客户端和JMX探针已包含这些，所以也应该丢弃。这同样也可用于其它类似的语言和框架。 部署Deployment 每个探针应该监控只有一个实例的应用程序，preferably sitting right beside it on the same machine。这意味着你运行没给一个HAProxy，你运行了一个haproxy_exporter进程。 调度Scheduling 当Prometheus抓取指标时，指标应该从应用处拉取，探针不应该基于自己的定时器执行抓取。也就是说，所有的抓取都应该是同步的(synchronous)。 因此，你不应该在公开的指标上设置时间戳，而让Prometheus来做。如果你认为需要时间戳，那么你可能需要使用pushgateway来代替。 如果检索指标特别昂贵，即超过了一分钟，可以接受的是缓存它(cache it)。这应该在注释在HELP字符串中。 Prometheus默认抓取的超时时间是10s。如果你的探针希望超过这一点，你应该在你的用户文档中明确的调用此。 推送Pushes 有些应用程序和监控系统只能推送指标(push metrics)，如StatsD, Graphite, collectd。有两方面的考虑： 首先，指标什么时候过期？其次，这些类型的系统倾向于允许你的用户发送变化量(deltas)或原始计数器(raw counter)。你应该尽可能依赖原生计数器，因为这一般是Prometheus model。 对于服务级别的指标，你应该有探针推送到Pushgateway，在事件而不是你自己处理状态之后退出。对于实例级别的指标，还没有明确模式。 抓取失败Failed scrapes 目前有两种模式的抓取失败，当应用程序不响应或其它问题时。 第一个就是返回5xx错误。 第二个是有一个myexporter_up，如haproxy_up，值是0还是1依赖于抓取工作。 后者更好，即使抓取失败，你还可以得到一些有用的指标。 抓取页面Landing page 访问地址，如http://expoter:port作为一个简单的包含探针名称的HTML页面，并有指向/metrics页面的链接。 端口号Port numbers 用户在一个机器上可能有多个探针和Prometheus组件，为了使得事情更简单每个需要有一个唯一的端口号。这个页面https://github.com/prometheus/prometheus/wiki/Default-port-allocations包含了Prometheus组件和探针目前使用的端口号。 为自己的探针分配一个合理的，没有使用的端口号。 宣布Announcing 一旦你准备向世界宣布你的探针，请在可用的探针列表提交一个PR。 最佳实践BEST PRACTICES 指标和标签命名METRIC AND LABEL NAMING: https://prometheus.io/docs/practices/naming/ 指标和标签的约定不需要使用Prometheus，但可以作为一个风格指南和最佳实践的集合。 指标名称Metric names 一个指标名称： 必须符合有效字符的数据模型 应该有一个应用程序(single-word)相关的指标所属前缀。如： prometheus_notifications_total process_cpu_seconds_total http_request_duration_seconds 必须有一个单一的单位（如秒，毫秒等） 应该使用基本单位（如seconds, bytes, meters，而不是milliseconds, megabytes, kilometers） 应该有一个描述单位的后缀。如： http_request_duration_seconds node_memory_usage_bytes http_requests_total process_cpu_seconds_total foobar_build_info should represent the same logical thing-being-measured across all label dimensions request duration bytes of data transfer instantaneous resource usage as a percentage 作为一个经验，在给定指标的所有尺寸上，无论是sum()还是avg()都应该是有意义的。如果没有意义，则将数据分裂成多个指标。 标签Labels 使用标签来区分被测量的事物的特点： api_http_requests_total，不同的请求类型：operation=&quot;create|update|delete&quot; api_request_duration_seconds，不同的请求阶段：stage=&quot;extract|transform|load&quot; 不要将标签名对应到指标名，如果相应的标签聚合了，这会冗余并造成混乱。 注意：请记住，标签键值对每一个独特的组合代表了一个新的时间序列，这可能会极大的提高存储的数据量。不要使用标签来存储高基数，如用户ID，邮件地址等。 基本单位Base units Prometheus没有硬编码任何单位。为了更好的兼容性，应该使用基本单位。以下是一些栗子： Family Base unit Remark Time seconds - Temperature celsius 摄氏度优于开尔文 Length meters - Bytes bytes - Bits bytes 为了避免混淆，通常使用bytes Percent ratio 0-1而不是0-100 Voltage volts - Electric current amperes - Energy joules - Mass grams 克优于千克 控制台和仪表盘CONSOLES AND DASHBOARDS: https://prometheus.io/docs/practices/consoles/ 可在仪表盘上显示尽可能多的数据，特别是像Prometheus这样的系统提供了集成你的应用程序的能力。 我们发现以下原则非常有效： 在一个控制台上不要超过五个图 每个图上不要超过五个线 当使用控制台提供的模板示例，请避免在右边表超过20-30项 集成INSTRUMENTATION: https://prometheus.io/docs/practices/instrumentation/ 本章提供了集成你的代码的一套指导方案。 如何集成How to instrument 简短的回答是集成一切。每个库、子系统和服务应该至少有几个指标来给你一个粗略的想法它是如何执行的。 服务的三种类型The three types of services 为了监控的目的，服务大致可以分为三类：在线服务(online-serving)，离线处理(offline-processing)，批处理作业(batch jobs)。它们之间有重叠，但每个服务往往很好地成为这些类别。 在线服务系统 Online-serving systems 一个在线服务系统期待立即响应。例如，大多数数据库和HTTP请求都属于这一类。这种系统的关键指标是执行的查询数，错误和延迟。 离线处理 Offline processing 对于离线处理，没有人正在等待响应。也可能有多个处理阶段。对于每一个阶段，跟踪进入的项目，有多少在处理，最后一次处理的事物，以及发送了多少事物。 批处理作业 Batch jobs 在离线处理和批处理作业之间有一些模糊线，离线处理也可在批处理作业中完成。批处理作业不连续运行，这使得它们难以区分。 批处理作业的关键指标是它最后一次成功。这对于追踪各个阶段的花费时间，整体运行和最后一次作业完成很有用。对于那些超过几分钟时间运行的批处理作业，使用基于Pull监控的数据抓取很有用。对于运行很频繁地批处理作业，你应该考虑将其转换为守护程序(daemons)，作为离线处理作业来处理它们。 子系统Subsystems 除了三种主要类型的服务，系统也应该监控子部分(sub-parts)。 库 Libraries 库应该提供无需用户额外配置的集成。 如果一个库经常访问进程外的资源（如网络、磁盘、IPC…），追踪整个查询计数，错误和延迟。 日志 Logging 作为一般规则，对与日志代码的每一行，你应该有一个递增的计数器(counter)。如果你发现一个有趣的日志信息，你要能过够看到它如何发生，而且持续多久。 失败 Failures 故障应该与日志有相似的处理。每次出现故障，计数器(counter)都应增加。不像日志，取决于你的代码结构，错误也可以丢到一个更普遍的错误计数器。当报告故障，你通常应该有一些其它指标来表示尝试的总数。这使得故障率很容易计算。 线程池 Threadpools 对于任何形式的线程池，关键指标是排队请求数，在使用的线程数，总线程数，处理的任务数，以及它们耗时多久。 缓存 Caches 缓存的关键指标是总查询、点击、总延时、查询数、错误和任何在线服务缓存前的延迟。 收集器 Collectors 当实现一个自定义指标收集器时，建议为收集花费的时间(s)导出为gauge，另一个是遇到的错误的数量。 要提防的事Things to watch out for 当做监控时，有些事需要注意，Prometheus-specific尤其如此。 使用标签Use labels 很少有监控系统有标签和表达式语言的来利用这些优点，所以需要一些时间来使用。当你有多个指标要添加/求平均值/求和，它们通常是带有标签的指标，而不是多个指标。 例如，创建一个带有code标签的http_responses_total指标，而不是http_responses_500_total，http_responses_403_total两个指标。 不要滥用标签Do not overuse labels 每个标签集(labelset)是具有RAM, CPU, disk, network开销的额外时间序列。通常情况下，开销可以忽略不计，但有很多机器和很多指标和很多标签的情况下，这可能会迅速增加。 作为一般原则，尽量保持指标的基础低于10。绝大多数的指标没有任何标签。如果你有一个有100多个基数的指标，调查替代解决方案。 为了让你对基数有一个更好的主意，让我们来看下node_exporter。节点探针公开每个挂载的文件系统的指标。如果你有10000台机器，有10000个node_filesystem_avail时间序列，这对于Prometheus处理很好。 如果你不确定，就不用标签，并随着时间的推移添加更多标签。 四种类型比较Counter vs. gauge, summary vs. histogram 对一个给定的指标用哪个四种主要的指标类型是很重要的。 在Counter和Gauge之间选择，有一个简单的经验法则：如果值可减少，这是一个Gauge。Counter只能增加，如累积的量。Gauge可以设置，增加或减少。 Summaries和Histograms是更复杂的指标类型。 时间戳Timestamps, not time since 如果你想追踪从某事发生时的时间量，导出在它发生时的Unix时间戳，而不是从它发生的时间。 导出了时间戳，可以使用time() - my_timestamp_metric表达式计算时间。 避免缺失指标Avoid missing metrics 时间序列，直到某事发生不存在难以应付，因为通常的简单操作不足以正确处理它们。为了避免这种情况，你事先知道可能存在的任何时间序列输出为0(或NaN)。 大多数Prometheus Client Libraries(go, java, python)会为没有标签的指标自动导出0。 Hisgogram和SummaryHISTOGRAMS AND SUMMARIES: https://prometheus.io/docs/practices/histograms/ 告警ALERTING: https://prometheus.io/docs/practices/alerting/ 请先阅读My Philosophy on Alerting 告警什么What to alert on 目标是告警越少越好，告警要有目的，别瞎告。告警应该很容易找到哪些部件的故障。 记录规则RECORDING RULES: https://prometheus.io/docs/practices/rules/ 记录规则的一致性命名方案，可以一目了然地理解规则的含义。本节可以正确聚合和建议命名规范。 命名和聚合Naming and aggregation 记录规则(recording rules)应该是这样的一般形式：level:metric:operations。level表示聚合级别和规则输出的标签；metric是指标名称并在使用rate()这些方法时应该保持不变；operations是一个应用到指标的操作列表。 保持指标名称不变，使得易于知道指标是什么和容易在代码库中找到它。 如一些常见的: sum, ratio, count这些。 示例1234567891011121314151617- record: instance_path:requests:rate5m expr: rate(requests_total&#123;job="myjob"&#125;[5m])- record: path:requests:rate5m expr: sum without (instance)(instance_path:requests:rate5m&#123;job="myjob"&#125;)- record: instance_path:request_failures:rate5m expr: rate(request_failures_total&#123;job="myjob"&#125;[5m])- record: instance_path:request_failures_per_requests:ratio_rate5m expr: |2 instance_path:request_failures:rate5m&#123;job="myjob"&#125; / instance_path:requests:rate5m&#123;job="myjob"&#125;- record: job:request_latency_seconds_count:avg_rate5m expr: avg without (instance, path)(instance:request_latency_seconds_count:rate5m&#123;job="myjob"&#125;) PushgatewayWHEN TO USE THE PUSHGATEWAY: https://prometheus.io/docs/practices/pushing/ Pushgateway是一个中间服务，允许你从无法抓取的作业处推送指标。更多详情，查看push metrics 应该使用Pushgateway吗Should I be using the Pushgateway? 我们只建议在某些有限的示例中使用Pushgateway。盲目地使用Pushgateway push来代替Prometheus pull有几个陷阱： 通过Pushgateway监控多个实例，Pushgateway成为单一的失败点和潜在的瓶颈。 你失去了Prometheus通过up自动检测实例健康。 Pushgateway永远不会忘记推送它，并公开它们给Prometheus，除非这些序列通过PushgatewayApi手动删除。 如果原始实例重命名或删除，实例的指标将保留在Pushgateway中。这是因为PushGateway作为指标缓存的生命周期与推送指标的进程的生命周期分开。与Prometheus pull方式对比时，当一个实例消失时，实例的指标将自动消失。使用Pushgateway时，不不是这种情况，你必须手动删除任何陈旧的指标，或自动执行生命周期同步。 通常，Pushgateway的唯一有效用例是用于捕获一个服务级别的批处理作业的结果(outcome)。一个服务级别的批处理作业是与特定机器或作业实例相关的。这样的作业的指标不应包含一个机器或实例标签，以将特定机器的生命周期与推送指标的实例分开。这降低了管理Pushgateway中的陈旧指标的负担。 替代策略Alternative strategies 如果入站防火墙和NAT阻止您从目标机器抓取指标，考虑将Prometheus Server移动到网络后面。我们通常建议在同一网络上运行Prometheus Server来作为监控实例。否则，考虑PushProx，它允许Prometheus跨过防火墙或NAT。 远程存储REMOTE WRITE TUNING: https://prometheus.io/docs/practices/remote_write/ Prometheus实现了合理的默认远程写，但许多用户有不同的要求，并希望优化远程设置。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Prometheus</tag>
        <tag>Monitor</tag>
        <tag>Alert</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker]]></title>
    <url>%2F2018%2F03%2F27%2FDocker%2F</url>
    <content type="text"><![CDATA[参考： Docker文档: https://docs.docker.com/ https://blog.csdn.net/sD7O95O/article/details/78623697 https://www.zhihu.com/question/22969309/answer/34030581 环境： CentOS7x86_64 Docker v18.03 概述Docker是一个开发、shipping、运行应用程序的开放平台。Docker使你能够将应用程序与基础架构(infrastructure)分离开，从而可以快速交付软件。借助Docker，你可以像管理应用程序一样管理基础架构。利用Docker的方法快速进行运输、测试和部署代码，可以显著缩短编写代码和在生存环境中运行代码之间的延迟。 Docker平台Docker提供了在称为容器的松散隔离(isolated)环境中 打包和运行应用程序的能力。隔离性和安全性允许你在给定的主机上同时运行多个容器。容器是轻量级(lightweight)的，因为它们不需要hypervisor的额外负载，而是直接使用主机的内核运行。这意味着，与使用虚拟机相比，你可以在给定的硬件组合上运行更多的容器。你甚至可以在虚拟主机中运行Docker容器。 Docker提供了工具和平台来管理容器的生命周期(lifecycle)： 使用容器开发应用程序及其支持组件 容器成为分发和测试你应用程序的单元 准备好后，将你的应用程序部署到生产环境中，作为容器协调服 Docker引擎Docker引擎是一个包含如下部件的client-server应用程序： Server是称为守护进程的dockerd REST API是指定程序可用于与守护进程进行通信并指示其执行操作的接口 Client是command line interface(CLI) Docker的开源许可协议是Apache2.0 能用Docker做什么快速、一致的交付应用程序 通过允许开发人员在 提供应用程序和服务的本地容器 的标准化环境 下工作，Docker简化了开发生命周期。容器非常适合持续集成(continuous intergration,CI)和持续交付(continuous deliver,CD)工作流程。 考虑如下示例场景： 开发者在本地编写代码，并使用Docker容器分享工作给他们的同事 使用Docker将应用程序push到测试环境，并自动执行和手动测试 当开发人员发现bug，他们能在开发环境中修复bug，并重新部署应用程序到测试环境进行测试和验证 测试完成后，向客户提供修补的应用程序 与将更新的image push到生产环境一样简单 响应式部署和伸缩 Docker的基于容器的平台支持高度可移植的工作负载。Docker container可以运行在笔记本、物理机、虚拟机、云平台… Docker的可移植性和轻量化特性也使得动态管理工作负载非常容易，可以近乎实时地按业务需求扩展或拆分应用程序和服务 在同一硬件上运行更多的工作负载 Docker轻量且快速。它为基于hypersior的虚拟机提供了一种可行、经济高效的替代方案，因此你可以使用更多计算容量来实现业务目标。Docker是高密度环境和中小型部署的理想选择，你需要用更小的资源做更多的事情。 Docker架构Docker使用了client-server的体系架构。客户端向守护进程发送消息，守护进程负责构建、运行和分发 Docker容器。客户端和守护进程可以在同一系统上运行，也可将客户端连接到远程的Docker守护进程。客户端和守护进程使用REST API，通过Unix socket或network interface进程通信。 Docker daemonDocker daemon(dockerd)，监听Docker API请求并管理Docker对象——image、container、network、volume。docker daemon还可与其它docker daemon通信来管理docker service。 Docker clientDocker client(docker)是许多Docker用户与Docker进行交互的主要方式。客户端将命令发送给守护进程，守护进程执行命令。Docker命令使用Docker API，Docker客户端可与多个守护进程进行通信。 Docker registryDocker registry存储Docker image。Docker Hub和Docker Cloud是任何人都可使用的public registry，你可以创建private registry。 docker pull或docker run需要的image便是从配置的registry中提取。docker push推送image到你配置的registry。 Docker对象当你使用Docker时，你会创建和使用 image、container、network、volume、plugin和其它对象。 image镜像是一个只读模板，带有创建Docker容器的说明。通常，镜像基于其它镜像，并具有一些额外的自定义功能。例如，你可构建基于Ubuntu镜像的镜像，但会按照ApacheWeb服务器和应用程序，以及应用程序所需的配置。 你可能创建自己的镜像，或使用由别人创建并推送到registry上的镜像。构建自己的镜像，需要使用简单的语法创建一个Dockerfile，以定义创建镜像并运行它所需的步骤。 container容器是镜像的可运行实例。可将容器连接到一个或多个网络，将存储器连接到它，还可根据当前状态创建新镜像。 默认情况下，容器与其它容器以及主机是相对隔离的。你可以控制容器的网络、存储、其它底层子系统与其它容器或主机的隔离程度。 容器由镜像定义，以及你在创建或启动时提供给它的任何配置选项。当一个容器被移除时，其未被存储在永久存储器中的状态会消失。 栗子： 123#运行一个Ubuntu镜像，交互地连接到本地命令会话docker run -i -t ubuntu /bin/bash 以上命令会发生如下步骤: 如果本地没有Ubuntu镜像，docker会从registry拉取，就好像你手动运行 docker pull ubuntu Docker创建一个新容器，就好像你手动执行docker container create Docker分配一个读写文件系统给容器，作为它的最后一层 如果你没有指定任何网络选项，Docker会创建一个网络接口将容器连接到默认网络。 Docker开启容器并执行/bin/bash 发送exit到/bin/bash，容器停止但并未被移除 service服务允许你伸缩多个Docker守护进程的容器，这些守护进程可以作为一个swarm与多个manager和worker一起工作。默认情况下，该服务在所有node之间进行负载均衡。 底层技术Docker使用GO编写，利用Linux内核的几个特性来提供其功能。 namespace Docker使用一个称为namespace的技术来提供称为容器的独立工作空间。当你运行一个容器时，Docker会为该容器创建一组命名空间。命名空间提供了一个隔离层。容器的每个方面都在单独namespace中运行，并且其访问权限仅限于该单独的namespace。 Docker引擎在Linux上使用如下namespace： pid namespace： 进程隔离 net namespace： 管理网络接口 ipc namespace： 管理对IPC(InterProcess Communication)资源的访问 mnt namespace： 管理文件系统挂载点 ust namespace： 隔离内核和版本标识符(Unix Timesharing System) control groups Linux上的Docker Engine也依赖与另一种称为控制组(cgroups)的技术。cgroup将应用程序限制为一组特定的资源。控制组允许Docker引擎将可用的硬件资源共享给容器，并可选地强制实施限制和约束。例如，你可限制特定容器的内存是CPU使用率等。 union file systems union file systems(UnionFS)，是通过创建layer进行操作的文件系统，使得它们非常轻量和快速。Docker引擎使用UnioFS为容器提供构建block。Docker引擎可以使用多种UnionFS变体，包括AUFS, brrfs, vfs, DeviceMapper… container format Docker引擎将namespace、cgroup、UnionFS组合成一个名为容器格式的包装器。默认的容器格式为libcontainer。 安装Docker有两个可获取的版本： Community Edition(CE) 适合开始使用Docker并尝试基于容器的应用程序的开发人员和小型团队 Enterprise Edition(EE) 专为企业开发和IT团队而设计，可以在生产规模上构建，发布和运行关键业务应用程序 CentOS7安装Docker CEOS要求 CentOS7.x centos-extras repository 推荐使用overlay2存储驱动 安装新版本Docker需卸载老版本Docker Docker CE包被称为docker-ce 安装Docker CE https://download.docker.com/ 多种安装方法： Docker’s repository RPM package scripts 使用repository安装： 12345678910111213141516171819202122232425262728 #安装依赖yum install -y yum-utils device-mapper-persistent-data lvm2 #设置repositoryyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo #安装Docker CEyum install -y docker-ce #Docker安装但未启动，docker group会被创建，但没有用户添加到组中 #在生产环境中，你可能需要安装特定版本的Docker CE，而不是最新版yum list docker-ce --showduplicates | sort -ryum search docker-ce --showduplicates #开启dockersystemctl start docker #测试dockerdocker run hello-world #此命令下载一个测试image并将其运行到container中 #Hello from Docker! 使用package安装： 1234567891011 #下载rpm包https://download.docker.com/linux/centos/7/x86_64/stable/Packages/ #安装yum install -y /path/docker-cexxx.rpmsystemctl start dockerdocker run hello-world 使用scripts安装： 123456curl -fsSL get.docker.com -o get-docker.shsh get-docker.sh #手动添加group合userusermod -aG docker your-user 卸载Docker CE123456yum remove docker-ce #默认文件rm -rf /var/lib/docker #你还需要手动删除其它配置文件 开始 关于DockerDocker文档会有如下讲解： 设置你的Docker环境 在一个容器(container)中构建并运行一个镜像 延伸你的APP以便在多个容器中运行 在整个集群中分配你的APP 通过添加后端数据库来堆栈服务 将应用部署到生产 Docker的概念Docker是开发人员，系统管理员使用容器来开发、部署和运行APP的平台。使用Linux容器来部署APP被称为集装箱化(containerzation) 集装箱受欢迎的几点原因： 灵活(flexible) 轻量(lightweight) 通用(Interchangeable) 可移植(portable) 延伸(scalable) 堆栈(stackable) 镜像和容器通过运行镜像(image)启动容器(container)。镜像是一个可执行包，包含运行APP所需的所有内容：代码，库，环境变量，配置文件… 容器是镜像的运行时(runtime)实例。在Linux上使用docker ps命令查看运行的容器列表。 容器和虚拟机容器在Linux本地上运行，并与其它容器共享主机Kernel。它是一个独立的进程，不占其它可执行文件内存，使其轻量化。 虚拟机(VM)运行一个完整的访客操作系统，通过虚拟机管理程序访问主机资源。一般来说，虚拟机比大多数应用程序需要的资源更多。 准备Docker环境Docker版本： CE: Docker Community Edition EE: Docker Enterprise Edition Install Docker 测试Docker12345678910111213141516171819202122docker --version#查看详细信息docker info#测试安装工作是否正常docker run hello-world#查看镜像docker image ls#列出容器docker container ls -all#docker命令dockerdocker container --help 小结集装箱化使得CI/CD无缝： 持续集成(Continuous integration, CI) 持续部署(continuous deployment, CD) APP无系统依赖 更新能够推送到分布式APP的任何部分 资源密度可以被优化 使用Docker，扩展APP的过程就是启动新的可执行文件，而不是运行繁重的VM主机。 容器Container 先决条件1docker run hello-world 介绍是时候使用Docker方式来构建一个APP了。 从应用程序的层次结构底部开始，这是一个容器(container) 在此级别之上，是一个服务(service)，它定义了容器在生产中的表现 最后，顶层是堆栈(stack)，定义所有服务的交互(interaction) Like this: Stack Service Container 新开发环境在过去，如果你要开始编写一个Python APP，你的第一要务是在你的机器运行时安装Python。但是，这会造成你的计算机上的环境，需要如预期般完美适合你的APP，并且还需要与你的生产环境相匹配。 使用Docker，你可以将一个可移植的Python运行时作为一个image，无需安装。接着，你的构建可以将基础Python image与APP代码一起包含在内，确保你的APP，依赖项…都构建一起。 使用Dockerfile定义一个容器Dockerfile定义了容器内环境中发生的事情。访问的网络接口(network interface)和磁盘驱动(disk driver)等资源是在此环境中虚拟化的(virtualized)，与系统其余部分隔离。因此你需要将端口映射(map port)到外部世界，并明确指定要将哪些文件复制到此环境中。但是，在完成这些后，你完全可以将它们看做一致 —— 在Dockerfile中定义的构建的APP的行为与它运行时的行为完全相同。 Dockerfile 创建一个空目录，并创建一个名叫Dockerfile的文件，复制以下内容： 1234567891011121314151617181920# Use an official Python runtime as a parent imageFROM python:2.7-slim# Set the working directory to /appWORKDIR /app# Copy the current directory contents into the container at /appADD . /app# Install any needed packages specified in requirements.txtRUN pip install --trusted-host pypi.python.org -r requirements.txt# Make port 80 available to the world outside this containerEXPOSE 80# Define environment variableENV NAME World# Run app.py when the container launchesCMD [&quot;python&quot;, &quot;app.py&quot;] 注意代理服务器会阻断你与APP的连接！ 这个Dockerfile引用了一些我们还没有创建的文件，分别是app.py和requirements.txt。接下来创建它们。 APP自身创建另外的文件，如上面的app.py和requirements.txt，并将它们与Dockerfile放置于同一目录下。这就完成了我们的APP，这看起来非常简单。当这个Dockerfile被构建成一个image时，由于Dockerfile的ADD命令，app.py和requirements.txt仍然存在，而且由于使用了EXPOSE命令，app.py的输出仍可以通过HTTP访问。 requirements.txt: 12FlaskRedis app.py: 123456789101112131415161718192021222324from flask import Flaskfrom redis import Redis, RedisErrorimport osimport socket# Connect to Redisredis = Redis(host=&quot;redis&quot;, db=0, socket_connect_timeout=2, socket_timeout=2)app = Flask(__name__)@app.route(&quot;/&quot;)def hello(): try: visits = redis.incr(&quot;counter&quot;) except RedisError: visits = &quot;&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;&quot; html = &quot;&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;&quot; \ &quot;&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;&quot; \ &quot;&lt;b&gt;Visits:&lt;/b&gt; &#123;visits&#125;&quot; return html.format(name=os.getenv(&quot;NAME&quot;, &quot;world&quot;), hostname=socket.gethostname(), visits=visits)if __name__ == &quot;__main__&quot;: app.run(host=&apos;0.0.0.0&apos;, port=80) 在容器内访问主机的名称将检索容器ID，这进程ID类似。 仅此而已，在你的系统中，你不需要任何Python或requirements.txt文件，也不需要在你的系统上安装 构建或运行的image。看起来你并没有真正用Python和Flask建立一个环境，但是你确实已经拥有了。 构建APP我们准备去构建(build)APP。确保你仍在目录的顶层。 123456789101112131415161718192021222324252627282930313233343536373839404142#查看是否还在顶层lsDockerfile app.py requirements.txt#在此目录运行build命令，这将创建一个Docker image，用 -t 命名docker build -t friendlyhello .#查看你build的imagedocker image lsREPOSITORY TAG IMAGE ID CREATED SIZEfriendlyhello latest b24e21d7645f 13 minutes ago 150MB#运行APPdocker run -p 4000:80 friendlyhello#测试curl http://localhost:4000links http://localhost:4000#在后台运行docker run -d -p 4000:80 friendlyhello#查看容器docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES146662dca737 friendlyhello &quot;python app.py&quot; 16 seconds ago Up 16 seconds 0.0.0.0:4000-&gt;80/tcp goofy_chaplygin#停止Ctrl + Cdocker container stop docker-IDdocker container stop 146662dca737 端口重映射4000:80是为了证明Dockerfile中的EXPOSE与使用docker run -p发布的内容之间的区别。在后续步骤中，我们只需将主机的80端口映射到容器的80端口就好。 分享你的image为了演示刚才创建的image的可移植性(portability)，让我们上传build的image并在其它地方run它。毕竟，当你需要将container部署到生产环境时，你需要知道如何push注册。 注册表(registry)是一个repository的集合，而repository是image的集合——有点类似于GitHub repository，但代码是已经构建了的。注册表上的账户可以创建许多repository。docker CLI 默认使用Docker’s public registry。你也可以选择其它注册表，或创建自己的注册表。 使用Docker ID登录： 如果没有Docker账户，请先注册 。 1234567891011121314151617docker logindocker login -u zhang21#时候docker login认证过后，会有~/.docker/config.json文件，里面包含了docker认证信息#k8s可使用此信息添加secretcat ~/.docker/config.json&#123; &quot;auths&quot;: &#123; &quot;https://index.docker.io/v1/&quot;: &#123; &quot;auth&quot;: &quot;base64encoding&quot; &#125; &#125;, &quot;HttpHeaders&quot;: &#123; &quot;User-Agent&quot;: &quot;Docker-Client/18.03.1-ce (linux)&quot; &#125; 标记image： 使用username/repository:tag将本地image与registry中的repository相关联。tag是可选的，但推荐使用tag。因为它是注册管理机构用于为Docker image提供版本的机制。为该内容提供一个有意义的repository和tag，例如get-started:part2。 12345678docker tag image username/repository:tag#例子docker tag friendlyhello zhang/test:tag-test#查看tagdocker images ls 发布image： 123456#上传你标记了的image到repositorydocker push username/repository:tagdocker push zhang21/test:tag-test#完成后，此image便可以公开获取 从远处repository拉取并运行image： 无论在哪里执行docker run，它都会将你的image以及Python和所有依赖关系一起拉取下来，并运行你的代码。 123docker run -p 4000:80 username/repository:tagdocker run -p 80:80 zhang21/test:tag-test 本节基础命令123456789101112131415161718192021222324252627282930313233343536373839404142434445#从Dockerfile创建imagedocker build -t image-name .#运行imagedocker run -p 4000:80 image-name#后台运行docker run -d -p 4000:80 image-name#列出运行的容器docker container ls#列出所有容器，包括未运行docker container ls -a#优雅停止容器docker container stop 容器ID#强制停止docker container kill 容器ID#删除容器docker container rm 容器ID#删除所有容器docker container rm $(docker container ls -a -q)#列出镜像docker image ls#列出所有镜像docker image ls -a#删除镜像docker image rm 镜像ID#删除所有镜像docker image rm $(docker image ls -a -q)#登录docker login#标记docker tag 镜像 username/repository:tag#上传到注册表docker push username/repository:tag#从注册表拉取docker run username/repository:tag 服务service 先决条件 安装Docker 获取Docker Compose 阅读Orientation 阅读Container 确保已发布friendlyhello image到你的registry 确保你的image工作为一个部署的container。docker run -p 80:80 username/repo:tag 介绍在此，我们扩展(scale)APP并启用负载均衡(load balancing)。要做到这样，我们必须在分布式(distributed)应用程序的层次结构中升一级: 服务 Stack Service Container 关于服务在分布式应用程序中，应用程序的不同部分称为服务(service)。 例如，一个视频共享站点。那么它可能包含： 用于将应用程序数据 存储到数据库中的服务 用户上传后的视频转码服务 前端服务 … 服务是真正的生产环境中的容器。一个service只运行一个image，但它可修改image的运行方式 —— 哪个端口、容器应该运行多少个副本以便于服务所需的容量等.伸缩服务会更改运行该软件的容器实例数量，从而为进程中的服务分配更多的计算资源。 在Docker平台上定义、运行和伸缩服务都是很简单的 —— 只需修改docker-compose.yml文件。 你的第一个docker-compose.yml文件docker-compose.yml是一个YAML文件，它定义了Docker container在生产中的行为方式。 docker-compose.yml： 将如下信息保存为docker-compose.yml，确保你已经pushed the image到registry，并通过修改.yml文件的image detail来替换username/repo:tag。 12345678910111213141516171819version: "3"services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 resources: limits: cpus: "0.1" memory: 50M restart_policy: condition: on-failure ports: - "80:80" networks: - webnetnetworks: webnet: docker-compose.yml文件告诉Docker之下如下操作： pull the image Run 5 instances of that image as a service called web 限制每个实例最多使用10%的CPU和50MB的RAM 如果一个失败，马上重启container 映射主机的80端口到web的80端口 指示web container通过称为webnet的负载均衡网络共享80端口 使用默认设置定义webnet网络 运行你的负载均衡APP12345678910111213141516171819202122232425262728293031323334docker swarm init#运行并设置APP名字docker stack -c docker-compose.yml app-namedocker stack -c docker-compose.yml LoadBalance#在一个主机上，单个服务栈通过部署的image运行5个container instance#获取service IDdocker service lsID NAME MODE REPLICAS IMAGE PORTS3d1a48yse0t4 LoabBalance_web replicated 5/5 zhang21/test:tag-test *:80-&gt;80/tcp#查看服务中的任务docker service ps app-name_webdocker container ls -q#5个容器IDc7ce0075890e52ba026bf28c6d4381be438fbd297a42e89d357b05cc38eb#访问的时候容器ID会在此5个负载中变化 在服务中运行的单个container称为任务(task)。任务是具有数字增量的唯一ID，最大数量是在docker-compose.yml中定义的副本数量。 伸缩APP通过修改docker-compose.yml中replicas的值，并重新运行docker stack deploy -c xxx app-name来伸缩APP。 Docker执行就地更新，不需要stack down或kill any containers. 卸下APP和swarm： 12345678#appdocker stack rm app-namedocker stack rm LoadBalance#swarmdocker swarm leave --force 使用Docker扩展APP非常简单。 本节命令1234567891011121314151617181920212223#列出栈或APPdocker stack ls#运行指定配置文件docker stack deploy -c &lt;composefile&gt; &lt;appname&gt;#列出与APP相关联的服务docker service ls#列出与APP相关联的任务docker service ps &lt;service&gt;#检查任务docker inspect &lt;task or container&gt;#列出容器IDdocker container ls -q#除掉APPdocker stack rm &lt;appname&gt;#从管理中除掉一个单一节点swarmdocker swarm leave --force swarm 先决条件 前面几个小节的内容 介绍前面你将一个服务运行在生产环境，并扩展为5个副本进程。 在此，你将APP部署到到集群上，并在多台机器上运行它。通过将多台主机连接到成为swarm的Dockerized集群，使得多容器、多主机应用成为可能。 理解swarm集群swarm是一组运行Docker并加入到集群中的机器。这样以后，你可以在集群的swarm manager上执行Docker命令。swarm中的机器可以是物理的或虚拟的，当他们加入swarm后，他们便被成为node。 swarm manager可以使用多种策略来运行容器，你可在compose file中指定相应的策略。 swarm manager是swarm中唯一可以执行命令、授权其他机器作为工作者加入swarm的机器。工作者(worker)只能在那提供能力(capacity)，并没有权力告诉任何机器能够做什么。 但目前为止，你已经在本机机器上以单主机(single host)模式使用Docker。但Docker也可以切换为swarm(集群)模式，这就是使用swarm的原因。立即启用swarm模式使得当前机器成为swarm manager。从此，Docker将运行在你管理的swarm上执行命令，而不仅仅是在当前机器上执行。 建立swarm一个swarm由多个节点组成，不管它是虚拟机还是物理机。 基本概念很简单，运行docker swarm init来开启swarm模式并使得当前机器成为swarm manager 在其它机器上运行docker swarm join使他们作为worker加入swarm 栗子：使用VM快速创建两台机器的集群，并将其变为swarm。 使用docker-machine创建一对VM: 123456789101112131415161718192021#CentOS7#安装VirtualBoxwget https://download.virtualbox.org/virtualbox/5.2.8/VirtualBox-5.2-5.2.8_121009_el7-1.x86_64.rpm &amp;&amp; yum install -y Virtual.xx.rpm#安装docker-machine curl -L https://github.com/docker/machine/releases/download/v0.14.0/docker-machine-`uname -s`-`uname -m` &gt;/tmp/docker-machine &amp;&amp; install /tmp/docker-machine /usr/local/bin/docker-machine#在BIOS中开启虚拟化支持#在VMware中开启虚拟化支持(如果是VM)docker-machine create --driver virtual myvm1docker-machine create --driver virtual myvm2#列出虚拟机docker-machine ls 初始化swarm并添加node 第一台机器作为swarm manager，执行命令和join认证，后面的机器作为worker。 你可以使用docker-machine ssh发送命令到VM。在swarm mananger上执行docker swarm init初始化： 12345678docker-machine ssh &lt;swarm manager&gt; &quot;docker swarm init --advertise-assr &lt;mananger-IP&gt;&quot;#add workerdocker swarm jion --toker &lt;token&gt; &lt;wroker-ip&gt;:&lt;port&gt;#添加managerdocker swarm join-token manaer 由于我的虚拟的无法使用VT，因此我用的两台机器两个Docker来做swarm。 123456789101112131415161718#初始化这台机器默认为managerdocker swarm init#作为worker加入，ip是manager的#以下信息会在manager初始化时生成#注意防火墙，可能会阻碍加入docker swarm join --toker &lt;toker&gt; &lt;ip:port&gt;docker swarm join --token SWMTKN-1-3vrbnuneu0hyu41evxlhbn5fp04ad5jvg9v5rzvdaedg2bghkt-e24mjnni3hu7782t3gkz0ny39 172.16.129.150:2377#查看swarmdocker node ls#离开swarmdocker swarm leave 在swarm集群上部署APP主需要记住，只有swarm manager才能执行docker命令，worker仅仅是容量(capacity)。 在swarm manager上使用docker-composr.yml和docker stack deploy命令来部署APP。使用docker service ps &lt;service name&gt;来验证部署。 123456789101112131415161718192021222324#在manager部署docker stack deploy -c ./docker-compose.yml LoadBalancedocker service lsdocker stack ls#注意node名docker stack ps LoadBalanceID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS6nrn4mwc6pvt LoadBalance_web.1 zhang21/test:tag-test zhang22 Running Preparing 2 minutes agobpssrnzesl7n LoadBalance_web.2 zhang21/test:tag-test zhang22 Running Preparing 2 minutes agokmhd8p5wkc12 LoadBalance_web.3 zhang21/test:tag-test zhang21 Running Running 2 minutes agoi0pkf4foms87 LoadBalance_web.4 zhang21/test:tag-test zhang22 Running Preparing 2 minutes agorvtpjk781frn LoadBalance_web.5 zhang21/test:tag-test zhang21 Running Running 2 minutes ago#分别访问个主机的IP#创建的网络在它们之间共享并负载均衡links ip1links ip2 两个IP地址工作的原因是集群中的节点参与入口(ingress)路由网络(routing mesh)。这可以确保部署在swarm中某个端口的服务始终将该端口保留给自己，而不管实际运行容器的节点是什么。 清理并重启1docker stack rm LoadBalance stack先决条件，已完成前面的步骤。 介绍你已到达分布式应用程序层次结构的顶端——stack。堆栈是一组相互关联的服务，它们可以共享依赖关系，并可以进行协调和缩放。单个堆栈能够定义和协调整个应用程序的功能(尽管非常复杂的应用程序可能需要使用多个堆栈)。 在前面使用的docker deploy——是运行在单主机上的单个服务堆栈，这通常不会发生在生产环境中。在这里，你会使用学到的东西使多个服务相互关联，并在多台机器上运行它们。 添加一个新服务并部署docker-compose2.yml 12345678910111213141516171819202122232425262728293031version: &quot;3&quot;services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 restart_policy: condition: on-failure resources: limits: cpus: &quot;0.1&quot; memory: 50M ports: - &quot;80:80&quot; networks: - webnet #可视化 visualizer: image: dockersamples/visualizer:stable ports: - &quot;8080:8080&quot; volumes: - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; deploy: placement: constraints: [node.role == manager] networks: - webnetnetworks: webnet: 新增的东西使web对等服务，称为visualizer。注意两个事： volumes: 给予visualizer访问主机Docker的socket文件 placement： 确保服务运行在manager而不是worker上 123456789docker stack deploy -c ./docker-compose2.yml stack-testCreating network stack-test_webnetCreating service stack-test_visualizerCreating service stack-test_web#查看visualizer，要等一会才能正常访问，别着急访问 IP:8080 持久化数据让我们再次通过相同的工作流程来添加用于存储应用程序数据的Redis数据库。 docker-compose3.yml，添加一个Redis服务器： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253version: &quot;3&quot;services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 restart_policy: condition: on-failure resources: limits: cpus: &quot;0.1&quot; memory: 50M ports: - &quot;80:80&quot; networks: - webnet visualizer: image: dockersamples/visualizer:stable ports: - &quot;8080:8080&quot; volumes: - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; deploy: placement: constraints: [node.role == manager] networks: - webnet redis: image: redis ports: - &quot;6379:6379&quot; volumes: - &quot;/home/docker/data:/data&quot; deploy: placement: constraints: [node.role == manager] command: redis-server --appendonly yes networks: - webnetnetworks: webnet:#部署docker stack deploy -c docker-compose3.yml redis-test#测试访问 IP:port Redis是一个Docker library中的官方image，并被授予redis镜像名称。 redis规范中有几件事使数据在这个堆栈的部署之间持续存在： redis运行在manager，所以它总是使用相同的文件系统 redis将数据存储在上面的目录 确保redis服务始终使用相同的主机 确保存储的数据的连续性 如果没有创建，redis会将数据存储在容器文件系统的/data中，如果该容器被重新部署，则数据将被清除。 部署APP先决条件为前面的操作步骤。 介绍compose file在生产环境中的效果与在您的计算机上的效果相同。 选择版本我安装的是社区版(ce)。如果你在生产环境中使用docker-ce，则可以使用Docker Cloud帮助管理你的应用程序，如AWS、Aliyun、腾讯云。docker cloud： , 可注册后建立、上传、管理自己的repo。 设置和部署： 连接Docker Cloud并授权它自动为你配置Dockerize VM 使用Docker Cloud创建你的计算资源和swarm 部署应用程序 连接DockerCloud你可以标准模式或swarm模式运行Docker Cloud。 AWS配置指南 Aliyun配置指南 腾讯云配置指南 创建swarm你可在Docker Cloud UI创建你的node，或docker swarm init|join命令。 在云提供商上部署应用程序 我觉得阿里云和腾讯云也有对应的平台。 运行部署命令: docker stack deploy -c xxx.yml &lt;cus_appname&gt;，现在你的APP就运行在云提供商上。 运行swarm命令来验证部署 12345docker node lsdocker service lsdocker service ps &lt;service&gt; 在云提供商开放端口 service type protocol port web http tcp 80 visualizer http tcp 8080 redis tcp tcp 6379 具体操作参见各云提供商。 迭代和清理 改变*.yml文件伸缩应用程序 使用docker stack deploy部署应用程序 push和pull image 使用docker stack rm &lt;name&gt;清除stack 修改Docker默认路径docker默认的目录为/var/lib/docker，但很多时候/var目录并没有单独挂载，可能导致空间不够。前提是你已经把源配置目录对应的文件拷贝到替换的目录。 方法1： 123456789101112131415systemctl stop dockercd /etc/dockervim daemon.json&#123; &quot;graph&quot;: &quot;/opt/docker&quot;&#125;systemctl start docker#systemctl reload docker#查看变更docker info 方法2: 123456789101112systemctl stop dockercd /etc/sysconfig/vim docker-storageDOCKER_STORAGE_OPTIONS=--graph=/opt/dockersystemctl start docker#查看变更docker info 容器服务自启动在运行docker容器时可以加如下参数来保证每次docker服务重启后容器也自动重启: 1234docker run --restart=always -d -p 80:80 &lt;container-id&gt;#对于已启动的容器服务，更新它docker update --restart=always &lt;container-id&gt; 交互式容器进入Docker容器以获得交互式体验。 123docker exec -it &lt;container&gt; /bin/bashdocker exec -it &lt;container&gt; /bin/sh 使用systemd默认情况下，容器是不直接支持使用systemd的。可在运行容器时添加选项来使用systemd。 12#centos:7docker run -dit --privileged --name=centos7-systemd centos:7 init 日志 docker服务日志： journalctl -u docker.service docker容器日志： &lt;docker-graph&gt;/containers/&lt;container-id&gt;/&lt;container-id&gt;-json.log 由于容器ID会变化，请注意提取容器ID 可使用ELK在此收集容器日志 更新镜像使用docker commit从改变的容器中生成一个新镜像。 更新镜像步骤： 备份镜像: docker tag 运行镜像 修改容器 生成新镜像: docker commit 推送镜像: docker push 动态映射端口如何给运行中的容器添加映射端口。有两种方法: 将运行的容器生成一个新镜像，之后有这个镜像重新映射端口 通过iptables 第一种方法就相当于重新启动一个镜像，在启动时重新映射端口。实在是麻烦。 由于docker 命令设置端口映射其实也就是下发 iptables 规则，所以我们可以直接创建 iptables 规则进行端口流量转发。 123456789#查看本机docker iptabels rulesiptables-save#我的一个hexo镜像#-A DOCKER -d 172.17.0.2/32 ! -i docker0 -o docker0 -p tcp -m tcp --dport 4000 -j ACCEPT#再它在添加一个端口iptables -t nat -A DOCKER ! -i dokcer0 -p tcp -m tcp --dport 56789 -j DNAT --to-destination 172.17.0.2:56789 备份与恢复 备份容器 docker commit: 生成新镜像 docker save： 生成本地tar包 1234567891011121314Usage: docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]docker commit -m &quot;Just a test&quot; -p $&#123;container-id&#125; Zhang21/test:01docker image lsdocker logindocker pushUsage: docker save [OPTIONS] IMAGE [IMAGE...] [flags]docker save -o /path/$&#123;image&#125;.tar $&#123;image&#125;ls /path 恢复容器 docker run ${image} docker load: 载入本地.tar镜像 1234Usage: docker load [OPTIONS]docker load -i /path/$&#123;image&#125;.tardocker image ls 应用场景与注意事项 应用场景 本地依赖 搭建环境 微服务 自动测试 部署过程 CI/CD 多租户环境 一台机器的多个APP 弹性伸缩 资源隔离 注意事项 一个进程，一个容器不推荐在Docker容器中运行多个进程！ 不要将数据存放到容器内所以请使用挂在卷的方式映射到本地磁盘目录 使用磁盘进行数据存储 容器通信每当一个Docker容器需要与另一个容器通信时，传递信息最好使用名称或环境变量。 以non-root用户运行Docker默认情况下，Docker容器以root用户身份运行，众所周知，以root用户运行的容器完全可以控制主机系统。 注意容器的体积选择一个容器的主要原因之一是它的体积小。但是，如果你把它做得更大，它的主要优势就没了。 制定控策略开发和部署Docker容器不是你的工作的结束。您需要持续监控已部署的容器以及整个系统的运行状况。选择合适的工具并制定一个策略来有效地监控您的Docker容器，以确保最短的停机时间，从而使客户满意。 安全问题安全补丁、防火墙… Dockerfile参考: https://docs.docker.com/engine/reference/builder/ https://yeasy.gitbooks.io/docker_practice/content/image/build.html 将镜像每一层的修改、安装、配置、操作的命令写入Dockerfile，并用它来构建、定制镜像，那么镜像构建透明性问题便会得到解决。 Dockerfile是一个文本文件，包含了一条条指令(instrction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 使用Dockerfile定制镜像 FROM所谓指定镜像，就是以一个镜像为基础，在其上进行定制。基础镜像必须指定，而FROM就是指定基础镜像，因此一个Dockerfile中FROM是必备的指令，并且必须是第一条指令。 只有有可能，请使用当前官方repo作为你的基础镜像。我们推荐使用Alpine镜像，因为它严格控制，体积小(只有5MB)，同时也是完整的Linux发行版。 Docker Hub中有很多常用的官方镜像——常用软件、常用语言和常用系统镜像。 12345FROM nginx#特殊镜像，scratch，空白镜像FROM scratch RUN在多行中使用反斜杠\或复杂的RUN语句，使Dockerfile更具可读性、易理解性和可维护性。 RUN指令是用来执行命令行命令的。有两种格式： shell格式 RUN &lt;CMD&gt;，就像直接在命令行中输入命令一样 exec格式 RUN [&quot;可执行文件&quot;, &quot;参数&quot;]，这更像函数调用中的格式 12345678910FROM debian:jessieRUN apt-get updateRUN apt-get install -y gcc libc6-dev makeRUN wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot;RUN mkdir -p /usr/src/redisRUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1RUN make -C /usr/src/redisRUN make -C /usr/src/redis install Dockerfile中的每一个指令都会建立一层，RUN也不例外。每一个RUN的行为，就和手工建立镜像的过程一样 —— 新建立一层，在其上执行这些命令，执行结束后，commit这一层的修改，构成新的镜像。 上面这种写法，创建了7层镜像，这是完全没有意义的，而且很多运行时不需要的东西都被装进了镜像里，比如编译环境和更新的软件包等。结果就会产生非常臃肿、非常多层的镜像，不仅增加了构建部署的时间，也容易出错。这是很多初学Docker的人常犯的一个错误。 UnionFS是Linux、FreeBSD的文件系统服务，UnionFS是有最大层数限制的。 修改后的Dockerfile： 1234567891011121314FROM debian:jessieRUN buildDeps=&apos;gcc libc6-dev make&apos; \ &amp;&amp; apt-get update \ &amp;&amp; apt-get install -y $buildDeps \ &amp;&amp; wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot; \ &amp;&amp; mkdir -p /usr/src/redis \ &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \ &amp;&amp; make -C /usr/src/redis \ &amp;&amp; make -C /usr/src/redis install \ &amp;&amp; rm -rf /var/lib/apt/lists/* \ &amp;&amp; rm redis.tar.gz \ &amp;&amp; rm -r /usr/src/redis \ &amp;&amp; apt-get purge -y --auto-remove $buildDeps 仅仅使用一个RUN指令，并使用&amp;&amp;将各指令串联起来。将之前的7层简化为1层。在编写Dockerfile时，要经常提醒自己，这并不是在写shell脚本，而是在定义每一层该如何构建。 Dockerfile支持shell类的换行\、注释#等格式，良好的格式，如换行、缩进、注释等，会让维护、排障更为容易，这也是一个好习惯。 此外，还可看到命令最后添加了清理工作的命令，删除了为编译构建所需要的软件，清理了所有下载文件。这很重要，镜像是多层存储，每一层的东西并不会在下一层被删除，会一直跟随镜像。因此，构建镜像时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。很多人初学docker制作出了很臃肿的镜像，原因之一就是顽疾了每一层构建的最后一定要清理无关文件。 构建镜像在Dockerfile目录下执行： 1234567#docker build [OPTIONS] PATH | URL | - [flags]#Build an image from a Dockerfile#-t指定镜像名称#.指的是上下文目录docker build -t nginx:test . 构建上下文(content) 上面的.是在指定上下文路径。 当我们在进行镜像构建的时候，并非所有的定制都会通过RUN指令完成，经常会需要一些本地文件复制进镜像，比如通过COPY, ADD指令。而docker build命令并非是在本地构建镜像，而是在服务端，也就是Docker引擎dockerd中构建的。那么在这种C/S架构中，如何才能让服务端获得本地文件呢？ 这就引进了上下文的概念。当构建的时候，用户会指定构建镜像的上下文的路径，docker build命令得知这个路径后，会将路径下的所有内容打包，然后上传给Docker引擎。这样Docker引擎收到这个上下文包后，展开就会获得构建镜像所需的一切文件。 12#复制上下文目录下的package.jsonCOPY ./package.json /app/ 因此COPY这类指令中的源文件的路径都是相对路径，因为绝对路径已经超出了上下文的范围，Docker引擎无法获取这些位置的文件。如果真需要这些文件，请将它们复制到上下文目录中去。 理解构建上下文对于镜像构建很重要，避免犯一些不应该的错误。 一般来说，应将Dockerfile置于一个空目录下，或者项目根目录下。如果该目录下没有所需文件，则应该把所需文件复制一份过来。如果目录下有些东西不希望构建时传给Docker引擎，可以写一个.dockerignore文件，用于剔除不需要作为上下文传递给Docker引擎的。 实际上，Dockerfile的文件名并不要求必须为Dockerfile，也并不要求必须位于上下文目录中。可使用-f指定某个文件为Dockerfile。 其它docker build的用法 直接使用Git repo进行构建 1234#docker build URLdocker build https://github.com/twang2218/gitlab-ce-zh.git#:8.14#docker会自己去clone、切换分支、并进入指定目录开始构建 使用给定tar压缩包构建 123docker build http://server/context.tar.gz#自动下载/解压缩 压缩包，以其作为上下文，开始构建 从标准输入中读取Dockerfile进行构建 1234567docker build - &lt; Dockerfilecat Dockerfile | docker build -docker build - &lt; context.tar.gz Dockerfile指令Dockerfile提供了十多个指令供我们操作。 LABLE你可以为你的镜像添加标签，以助于通过项目来组织镜像，记录相关信息。 123456# Set multiple labels at once, using line-continuation characters to break long linesLABEL vendor=ACME\ Incorporated \ com.example.is-beta= \ com.example.is-production="" \ com.example.version="0.0.1-beta" \ com.example.release-date="2015-02-12" COPY尽管ADD和COPY在功能上相似，但一般来说，COPY是首选，因为它比ADD更透明。COPY只支持将本地文件复制到容器中，而ADD具有一些功能(如提取tar文件和远程URL支持) COPY,复制文件。从构建上下文目录中&lt;源路径&gt;的文件/目录复制到新的一层的镜像内的&lt;目标路径&gt;位置。 源路径可以是多个，或通配符(需满足Go的规则)目标路径可是容器内的绝对路径，也可是相对于工作目录(WORKDIR)的相对路径。目标路径不需要事先创建。使用COPY指令，源文件的各种元数据都会保留 —— 如读、写、执行权限、文件变更时间… 12345678910111213141516COPY &lt;sourch&gt; &lt;destination&gt;#或COPY [&quot;&lt;source1&gt;&quot;, ... &quot;&lt;destination&gt;&quot;]#栗子COPY package.json /usr/src/app/COPY hom* /mydir/COPY hom?.txt /mydir/#目录COPY dir/ /dir/#复制目录的错误用法#COPY dir/* /dir/ ADDADD是更高级的复制文件。ADD和COPY的格式和性质基本一致，但增加了一些功能。ADD支持通过URL从远程服务器读取资源，但对远程的压缩包没有解压缩功能。尽可能的使用COPY，因为COPY的语义很明确，就是复制文件而已，而ADD则包含了更复杂的功能，其行为也不一定很清晰。最适合ADD的场合，就是所提及的需要自动解压缩的场合。 因此在COPY和ADD指令中选择的时候，可以遵循这样的原则，所有的文件复制均使用COPY指令，仅在需要自动解压缩或远程资源的场合使用ADD。 12345678FROM scratchADD ADD http://foo.com/bar.go /tmp/main.goADD abc.tar.gz / &amp;&amp; \ http://example.com/big.tar.xz /usr/src/things/ &amp;&amp; \RUN tar -xJf /usr/src/things/big.tar.xz -C /usr/src/thingsRUN make -C /usr/src/things all CMDCMD，容器启动命令。用于运行镜像中包含的软件以及任何参数。 也有两个格式： shell格式： CMD &lt;command&gt; shell格式，在实际中会被包装成sh -c的参数形式进行执行： 123456789CMD echo $HOME#转变为CMD[&quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot;]#-c string If the -c option is present, then commands are read from string.#这就是为什么我们可以使用环境变量的原因，因为这些环境变量会被 shell 进行解析处理 exec格式： CMD [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot; ...]CMD几乎总是以此格式使用。 Docker不是虚拟机，容器就是进程。既然是进程，那么在启动容器的时候，需要指定所运行的程序及参数。CMD指令就是用于指定默认的容器主进程的启动命令的。`` 对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。 ENTRYPOINTENTRYPOINT，入口点。指令格式同样分为shell格式和exec两种。 ENTRYPOINT和CMD一样，都是在指定容器启动程序及参数。当指定了ENTRYPOINT后，CMD的含义就发生了改变，不再是直接的运行其命令，而是将CMD的内容作为参数传给ENTRYPOINT指令。即变为如下模式： 1&lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; 有几大好处： 让镜像变成像命令一样使用 12345678910111213#可以从腾讯上拉取，快一些#ccr.ccs.tencentyun.com/qcloud/ubuntuFROM ubuntu:16.04RUN apt-get update \ &amp;&amp; apt-get install -y curl \ &amp;&amp; rm -rf /var/lib/apt/lists/*CMD [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://ip.cn&quot; ]docker build -t myipdocker run myip#当前 IP：182.150.x.xx 来自：四川省成都市 电信 不过命令总有参数，例如我想查看HTTP header，使用-i参数 1234567docker run myip -i#这样会报错，-i替换了CMD命令，而不是-s参数，然而-i并不是命令#重新完整输入命令docker run myip curl -s http://ip.cn -i#这样又太麻烦 这时便可以使用ENTRYPOINT解决这个问题。 1234567891011121314FROM ubuntu:16.04RUN apt-get update \ &amp;&amp; apt-get install -y curl \ &amp;&amp; rm -rf /var/lib/apt/lists/*ENTRYPOINT [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://ip.cn&quot; ]docker build it myipdocker run myip#当前 IP：182.150.x.xx 来自：四川省成都市 电信docker run myip -i#成功 当存在ENTRYPOINT后，CMD的内容将作为参数传递给ENTRYPOINT，而-i就是新的CMD，因此会作为参数传递给curl，从而达到预期效果。 应用运行前的准备工作 有时，在启动前需要做一些准备工作。 如MySQL，需要一些配置文件、初始化工作，这些工作需要在MySQL server运行前解决 避免使用root用户去启动服务，从而提高安全性 这些准备工作和CMD无关 ENVENV，设置环境变量。为了使新软件更容易运行，使用此命令为你的容器内安装的软件更新环境变量。 两种格式： ENV &lt;key&gt; &lt;value&gt; ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 123ENV PATH $PATH:/root/bin \ EMAIL abc@zhang21.cn \ NAME=&quot;Zhang21&quot; 下列指令可以支持环境变量展开： ADD, COPY, ENV, EXPOSE, LABEL, USER, WORKDIR, VOLUME, STOPGIGNAL, ONBUILD。 通过环境变量，我们可以让一份Dockerfile制作更多的镜像，只需使用不同的环境变量即可。 ARGARG，构建参数 格式： ARG &lt;参数名&gt;[=&lt;默认值&gt;] 构建参数和ENV的效果一样，都是设置环境变量。所不同的是，ARG所设置的构建环境的环境变量，在将来容器运行时是不会存在这些环境变量的。 VOLUMEVOLUME，定义匿名卷。用于显示有docker容器创建的任何数据库存储区域，配置存储或文件/文件夹。强烈建议将VOLUME用于镜像的任何可变部分和用户可用部分。 格式： VOLUME [&quot;&lt;路径1&gt;&quot;, &quot;&lt;路径2&gt;&quot;...] VOLUME &lt;路径&gt; 容器运行时应该尽量保持容器存储层不发生写操作，对于数据库类需要保存动态数据的应用，其数据库文件应该保存于卷(volume)中。为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在Dockerfile中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会像容器存储层写入大量数据。 123456#在运行时自动挂载为匿名卷VOLUME /data#覆盖挂载docker run -d -v mydata:/data xxx EXPOSEEXPOSE，声明容器监听连接的端口。 格式： EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...] EXPOSE指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在Dockerfile中写入这个声明有两个好处： 一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便映射 另一个用处则是在运行时使用随机端口映射(未定义时) 要将EXPOSE和在运行时使用-p &lt;宿主端口&gt;:&lt;容器端口&gt;区分开。EXPOSE仅仅声明容器打算使用哪些端口，并未包含端口映射。 WORKDIRWORKDIR，指定工作目录。为了清晰可靠，请使用绝对路径。 使用WORKDIR指令可以来指定工作目录，以后各层的当前目录就被改为指定的目录，如目录不存在，WORKDIR会帮你建立目录。如果需要改变Dockerfile各层的工作目录的位置，那么应该使用WORKDIR指令。 格式： WORKDIR &lt;工作目录&gt; USERUSER，指定当前用户。如果服务可以在非特权模式下运行，请使用USER将其改为non-root用户。首先在Dockerfile中创建相应的用户和组: 12RUN groupadd -r group &amp;&amp; \ useradd -r -g group group USER和WORKDIR相似，都是改变环境状态并影响以后的层。WORKDIR是改变工作目录，USER则是改变之后的层执行RUN, CMD, ENTRYPOINT这类命令的身份。这个用户必须存在。 格式： USER &lt;用户名&gt; 12USER redisRUN [&quot;redis-server&quot;] HEALTHCHECKHEALTHCHECK，健康检查HEALTHCHECK指令告诉docker应该如何进行判断容器的状态是否正常。 格式： HEALTHCHECK [选项] CMD &lt;命令&gt;， 设置检查容器健康状况的命令 HEALTHCHECK NONE， 如果基础镜像有健康检查，使用这行可以屏蔽其健康检查指令 当在一个镜像指定了HEALTHCHECK指令后，用其启动容器，初始状态会为starting，在HEALTHCHECK指令检查成功后变为healthy，如果连续一定次数失败，则会变为unhealthy。和CMD, ENTRYPOINT一样，HEALTHCHECK 只可以出现一次，如果写了多个，只有最后一个生效。 ONBUILDONBUILD，为他人做嫁衣。 ONBUILD是一个特殊的指令，它后面跟的是其它指令。而这些指令，在当前镜像构建时不会被执行。只有当以当前镜像为基础镜像(父镜像)，去构建下一级镜像(子镜像)的时候才会被执行。ONBUILD命令在子镜像的Dockerfile中任何命令之前执行。Dockerfile中的其它指令都是为了定制当前镜像而准备的，唯有ONBUILD是为了帮助别人定制自己而准备的。 格式： ONBUILD &lt;其它指令&gt; Dockerfile多阶段构建全部放入一个Dockerfile 将所有的构建过程包含在一个Dockerfile中，包括项目及其依赖库的编译、测试、打包等流程。这可能会带来一些问题： Dockerfile特别长，可维护性降低 镜像层次多，镜像体积较大，部署时间变长 源代码存在泄漏的风险 分散到多个Dockerfile 事先在一个Dockerfile将项目及其依赖库编译测试打包好后，再将其拷贝到运行环境中。这种方式需要编写两个Dockerfile和一些编译脚本才能将两个阶段自动整合起来。这种方式虽然可以很好避免全部写入一个Dockerfile的风险，但明显部署过程较复杂。 多阶段构建 使用多阶段构建我们就可以很容易解决前面提到的问题，并且只需要编写一个Dockerfile。 Dockerfile最佳实践 一般性建议 容器应该是短暂的 使用.dockerignore文件 使用多阶段构建减少镜像大小 避免安装不必要的包 一个镜像只运行一个进程 镜像层数尽可能少 将多行参数排序 构建缓存 Dockerfile指令 FROM LABEL RUN CMD EXPOSE ENV ADD COPY ENTRYPOINT VOLUME USER WORKDIR 多平台构建参考: buildx: https://docs.docker.com/buildx/working-with-buildx/ qemu-uer-static: https://github.com/multiarch/qemu-user-static 版本: 大于Docker 19.03 linux kernel: 5.x 使用Docker新功能buildx构建多平台的镜像。升级内核版本，不然使用qemu-user-static使会失败。 使用如下: 1234567891011121314151617# 开启此功能export DOCKER_CLI_EXPERIMENTAL=enabled# 需要使用qemu-user# 注意内核版本，升级到5.x的内核大版本docker run --rm --privileged multiarch/qemu-user-static --reset -p yesdocker buildx create --name builder --driver docker-container --usedocker buildx inspect --bootstrap# arm64，--load存放本地docker buildx build -t xxx:arm64-tag --load --platform linux/arm64 .# amd64，--push推送docker buildx build -t xxx:amd64-tag --push --platform linux/amd64 .# 多平台docker buildx build --platform linux/arm64,linux/amd64 -t user/test:latest --push . 多平台构建的镜像支持运行在各自的架构上，使用同一个tag。多平台构建只能使用--push, --load只能对应单个平台。 Compose file参考: https://docs.docker.com/compose/compose-file/ 使用Docker进行开发Develop with Docker 在Docker上开发应用程序Develop new apps on Docker Learn to build an image from a Dockerfile Use multistage builds to keep your images lean Manage application data using volumes and bind mounts Scale your app as a swarm service Define your app stack using a compose file General application development best practices 了解有关Docker上特定语言的开发： Java node.js Ruby on Rails .Net ASP.Net Docker开发最佳实践Docker development best practices 如下开发模式已被证明有助于人么使用Docker构建应用程序。 如何保持较小的镜像How to keep your images small 在启动容器或服务时，小图像可以更快速通过网络pull镜像并加载到内存中。有几条经验法则可保持较小的镜像： 从适当的基础镜像开始例如，如果需要JDK，请考虑官方镜像，而不是从一个通用的Ubuntu/Centos镜像并将Openjdk作为Dockerfile的一部分安装开始。 使用多阶段构建例如，你可以使用maven镜像构建java程序，然后重置到tomcat镜像，并将java构件复制到正确位置以部署应用程序，所有这些都位于相同的Dockerfile。这意味着你的最终镜像不包含构建时所引入的所有库和依赖项，仅包含运行它们所需的构件和环境。 如果你有多个共同的镜像，请考虑使用共享组件创建你的基本镜像，并在其上创建独特的镜像Docker只要家在一次通用层，然后便会缓存。 保持生产环境镜像精简但允许调试(degub)，请考虑使用生产环境镜像作为调试镜像的基本镜像 在构建镜像时，应该始终使用有用的标签对其进行标记，如(test, prod)。不要依赖自动创建的latest标签 何处以及如何持久化应用程序数据Where and how to persist application data 避免使用存储驱动(storge drivers)将应用程序的数据存储在容器的可写层(writeable layer)中与使用卷(volume)或绑定挂载(bound mounts)相比，这增加了容器的大小，并且从I/O角度来看效率较低 使用卷存储数据 适合使用绑定挂载的一种情况是在开发过程中，对于生产环境，请改用卷 对于生产环境，使用secerts来存储服务使用的敏感的应用程序数据，使用config来存储不敏感的数据(如配置文件) 尽可能使用swarm服务Use swarm services when possible 在可能的情况下，使用swarm服务进行伸缩的能力来设计你的应用程序 即使你只需运行单个实例，swarm服务也比standalone容器提供更多的优势 网络和卷可使用swarm服务连接和断开，并且docker可以以不中断的方式重新部署各个服务容器。standalone容器需要手动停止/移除/重新创建 一些功能仅适用于服务而不适用于standalone容器 让docker stack deploy处理任意镜像，而不是使用docker pull。通过这种方式，你的部署不会尝试从down的节点进行pull。此外，当新节点添加到集群时，镜像会自动pull 使用CI/CD进行测试和部署Use CI/CD for testing and deployment CI(Continuous integration) CD(continuous deployment) 当更新源码库或创建拉取请求时，请使用CI/CD pipeline 自动构建并标记Docker镜像，并对其进行测试。也可将测试过的应用程序直接部署到生产环境中 Develop images编写Dockerfile的最佳实践Best practices for writing Dockerfiles Docker通过读取Dockerfile(一个包含命令的文本文件)中的命令来自动构建镜像。Dockerfile reference: https://docs.docker.com/engine/reference/builder/ Dockerfile由read-only layer组成，每层代表一个Dockerfile指令。如: 1234FROM ubuntu:15.04COPY . /appRUN make /appCMD python /app/app.py 每个命令创建一个层: FROM从ubuntu:15.04 Docker image创建一个层 COPY从Docker client的当前目录添加文件 RUN使用make构建你的应用程序 CMD指定在容器内运行的命令 当你运行镜像并生成容器时，会在基础层的顶部添加一个可写层(writable layer)，也称容器层(container layer)。对正在运行的容器所做的所有更改(增删改文件)都会写入此可写容器层。 一般准则和建议General guidelines and recommendations 创建临时(ephemeral)容器 Create ephemeral containers由Dockerfile定义的镜像应该生成尽可能临时的容器。临时的意思为容器可以被停止(stop)和销毁(destroy)，然后重建(rebuild)并使用绝对最小化的设置和配置来替代。 理解构建上下文 Understand build context当你发出docker build命令时，当前的工作目录被称为构建上下文(build context)。默认情况下，假设Dockerfile位于此，但你也可以使用文件标志(-f)指定位置。无论Dockerfile位于何处，当前目录内的所有内容(除了.dockerignore中忽略的内容)都将作为构建上下文发送给Docker守护进程。 从stdin读取Dockerfile Pipe Dockerfile through stdin 12345678910111213#local build-contextdocker build -t . -f-&lt;&lt;EOFFROM busyboxRUN echo &quot;hello world&quot;COPY . /my-copied-filesEOF#remotedocker build -t foo https://github.com/thajeztah/pgadmin4-docker.git -f-&lt;&lt;EOFFROM busyboxCOPY LICENSE config_local.py /usr/local/lib/python2.7/site-packages/pgadmin4/EOF 使用.dockerignore排除文件 Exclude with .dockerignore要排除与构建无关的文件，请使用.dockerignore文件，这与.gitignore类似。 12345vim ./dockerignorefile1dir2... 使用多阶段构建 Use multi-stage builds多阶段构建允许你大幅缩减镜像大小，而不需要减少中间层和文件数。由于镜像是在构建过程的最后阶段构建的，因此可以通过利用构建缓存(build cache)来最小化镜像层 例如，如果你的版本博涵包含多个层，你可以从 不经常改动的版本到频繁改动的版本进行排序: 安装构建应用程序需要的工具 安装或更新依赖库 生成应用程序 A Dockerfile for Go application: 123456789101112131415161718192021222324FROM golang:1.9.2-alpine3.6 AS build# Install tools required for project# Run `docker build --no-cache .` to update dependenciesRUN apk add --no-cache gitRUN go get github.com/golang/dep/cmd/dep# List project dependencies with Gopkg.toml and Gopkg.lock# These layers are only re-built when Gopkg files are updatedCOPY Gopkg.lock Gopkg.toml /go/src/project/WORKDIR /go/src/project/# Install library dependenciesRUN dep ensure -vendor-only# Copy the entire project and build it# This layer is rebuilt when a file changes in the project directoryCOPY . /go/src/project/RUN go build -o /bin/project# This results in a single layer imageFROM scratchCOPY --from=build /bin/project /bin/projectENTRYPOINT [&quot;/bin/project&quot;]CMD [&quot;--help&quot;] 不要安装不必要的包 Don’t install unnecessary packages为了减少复杂性、依赖性，文件大小和构建时间，避免安装额外的或不不必要的软件包。 分离应用程序 Decouple applications每个容器应该只有一个问题。将应用程序分离到多个容器中可以更轻松地水平伸缩和重新使用容器。例如，Web应用程序堆栈可能有三个独立的容器组成，每个容器都有其独特的镜像，以分离的方式管理Web应用程序、数据库和内存缓存。 将每个容器限制为一个进程是一个很好的经验法则，但不是硬性规定。(想想高可用和负载均衡)。 尽你最大的努力使容器干净和模块化。如果容器相互依赖，则可以使用Docker container network来确保容器间可进行通信。 最小化层数 Minimize the number of layers在老版本的docker中，重要的是减少镜像的层数，以确保它们的性能。 对多行参数排序 Sort multi-line arguments只要有可能，通过按字母数字排序多行参数来简化修改。这有助于避免软件包重复，并使列表更容易更新。 123456RUN apt-get update &amp;&amp; apt-get install -y \ bzr \ cvs \ git \ mercurial \ subversion Leverage build cache 在构建镜像时，Docker安装Dockerfile中的指令逐步执行，并按指定的顺序执行每个镜像。在检查每条指令时，docker会在其缓存中查找可重用的现有镜像，而不是创建新的(重复)镜像。 如果你不想使用缓存，可在docker build命令中使用--no-cache=true选项。如果让Docker使用了缓存，那么了解何时可以 找到/找不到 匹配的图像就很重要了。 Docker遵循的基本规则如下: 从已经在缓存中的父镜像开始，将下一条指令与该基本镜像派生的所有子镜像进行比较，以查看是否使用完全相同的指令构建了其中的一条。否则，缓存失效。 大多数情况下，只需将Dockerfile中的指令与其中一个子镜像进行比较久够了。但是，某些说明需要更多的检查和解释。 对于ADD和COPY指令，将检查镜像文件中的内容，并为每个文件计算校验和。在缓存查找过程中，将检验和与现有镜像中的校验和进行比较，如果文件中由任何内容已更改，如内容和元数据，则缓存将失效。 除了ADD和COPY指令，缓存检查将不会查看容器中的文件已确定缓存。 一旦缓存失效，所有后续的Dockerfile命令将生产新的镜像，并且不会使用缓存。 Dockerfile instruction 请参考: Dockerfile 创建一个基镜像Create a base image 大多数Dockerfile从父镜像开始，如果需要完全控制镜像的内容，则可能需要创建基镜像(base image)。区别: 父镜像是镜像的所基于的镜像 基镜像的Dockerfile中没有FROM行 使用多阶段构建Use multi-stage builds 多阶段构建需要Docker v17.05及以上版本。多阶段构建对于优化Dockerfile来说非常有用，同时让它易读和维护。 构建之前构建镜像最具挑战的事情是保持镜像的大小。Dockerfile中的每条指令都会为镜像添加一层，在移动到下一层前清理不需要的任何构件。为了编写一个高效的Dockerfile，需要尽可能减小图层，并确保每个层都具有上一层需要的构件，而不是其它东西。 使用多阶段构建使用多阶段构建，你可以在Dockerfile中使用多个FROM语句。每条FROM命令可以使用不同的基镜像，并且每个指令都可是构建的新阶段。 1234567891011FROM golang:1.7.3WORKDIR /go/src/github.com/alexellis/href-counter/RUN go get -d -v golang.org/x/net/htmlCOPY app.go .RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .FROM alpine:latestRUN apk --no-cache add ca-certificatesWORKDIR /root/COPY --from=0 /go/src/github.com/alexellis/href-counter/app .CMD [&quot;./app&quot;] COPY --from=0将前面构建的工作复制到这个新阶段。Go SDK和任何中间工作件都被留下，并未保存在最终镜像中 命名你的构建阶段默认情况下，构建阶段没有命名。你可以通过它们的整数来引用它们，第一个指令FROM从0开始。但你可以命名它。 1234567891011FROM golang:1.7.3 as builderWORKDIR /go/src/github.com/alexellis/href-counter/RUN go get -d -v golang.org/x/net/htmlCOPY app.go .RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .FROM alpine:latestRUN apk --no-cache add ca-certificatesWORKDIR /root/COPY --from=builder /go/src/github.com/alexellis/href-counter/app .CMD [&quot;./app&quot;] 停止一个特定的构建阶段构建镜像时，不一定需要构建包含每个阶段的整个Dockerfile。如下的栗子停在名为builder的阶段: 1docker build --target builder -t alexellis2/href-counter:latest . 使用外部镜像用作一个阶段多阶段构架可使用COPY --from指令从单独的镜像中进行复制，可以使用本机镜像、远程Registry的镜像和标记的ID。 1COPY --from=nginx:latest /etc/nginx/nginx.conf /nginx.conf 使用Docker Engine SDKs和API进行开发Develop with Docker Engine SDKs and API 综述Docker提供了一个用于与Docker daemon(称为Docker Engine API)交互的API，以及用于Go和Python的SDK。 SDK允许你款速轻松地构建和扩展Docker APP。如果Go或Python不适合你，你可以直接使用Docker Engine API——它是由HTTP客户端(curl, wget)访问的RESTful API，或者是大多数现代编程语言的一部分HTTP库。 安装SDKsGo SDK Go SDK参考：https://godoc.org/github.com/docker/docker/client 1go get github.com/docker/docker/client Python SDK Python SDK参考: https://docker-py.readthedocs.io/en/stable/ 1pip install docker 快速开始SDK和APIPython: 运行一个容器 123import dockerclient = docker.from_env()print (client.containers.run(&quot;alpine&quot;, [&quot;echo&quot;, &quot;hello&quot;, &quot;world&quot;])) HTTP: 123456789101112$ curl --unix-socket /var/run/docker.sock -H &quot;Content-Type: application/json&quot; \ -d &apos;&#123;&quot;Image&quot;: &quot;alpine&quot;, &quot;Cmd&quot;: [&quot;echo&quot;, &quot;hello world&quot;]&#125;&apos; \ -X POST http:/v1.24/containers/create&#123;&quot;Id&quot;:&quot;1c6594faf5&quot;,&quot;Warnings&quot;:null&#125;$ curl --unix-socket /var/run/docker.sock -X POST http:/v1.24/containers/1c6594faf5/start$ curl --unix-socket /var/run/docker.sock -X POST http:/v1.24/containers/1c6594faf5/wait&#123;&quot;StatusCode&quot;:0&#125;$ curl --unix-socket /var/run/docker.sock &quot;http:/v1.24/containers/1c6594faf5/logs?stdout=1&quot;hello world SDK和API栗子链接: https://docs.docker.com/develop/sdk/examples/ 网络配置Configure networking 综述Docker容器和服务如此强大的原因之一是——你可以将它们连接在一起，或将它们连接到non-docker工作负载。Docker容器和服务甚至不需要知道它们是否部署在Docker上，或它们的对等端是否也是Docker工作负载。都可以使用Docker方式管理它们。 网络驱动Network drivers 使用驱动程序，Docker的网络子系统是可插拔的(pluggable)。 集中驱动程序: brige默认网络驱动。桥接网络通常用于你的应用程序运行在需要通信的独立容器中。 host对于独立容器，删除容器和Docker主机之间的网络隔离，并直接使用主机的网络。 overlayoverlay网络将多个docker daemon连接在一起，并使集群服务能够无相互通信。 macvlanmacvlan网络允许你为容器分配MAC地址，使其成为你网络上的物理设备。docker daemon通过其MAC地址将流量路由到容器。 none对于此容器，禁用所有网络。 network plugins你可在Docker上安装和使用第三方网络插件，从Docker Store获取: https://store.docker.com 网络驱动总结 User-defined bridge networks当你需要多个容器在同一个Docker主机上进行通信时 Host networks当网络堆栈不应与Docker主机隔离时，但希望容器的其它方面被隔离 Overlay networks当你需要运行在不同Docker主机上的容器进行通信时，或多个应用程序使用集群服务进行工作时 Macvlan networks当你从虚拟机迁移或需要你的容器看起来像物理主机时，每个都具有唯一的MAC地址 Third-party network plugins允许你将Docker与专用网络堆栈集成 bridge就网络而言，桥接网络是一种链路层设备，用于转发网段之间的流量。桥接可以是硬件设备，或在主机内核中运行的软件设备。就Docker而言，桥接网络允许连接到统一桥接网络的容器进行通信，同时提供与未连接到桥接网络的容器的隔离。Docker桥接驱动程序自动在主机上安装桥接规则，以便于不同桥接网络上的容器不能直接相互通信。 桥接网络适用于在同一个Docker daemon上运行的容器之间的通信。 当你启动Docker时，除非另有定义，否则将自动创建默认桥接网络，并且新启动的容器将连接到它。你也可以创建用户自定义的桥接网络。 bridge与user-defined bridgesDifferences between user-defined bridges and the default bridge 两者的差别： 用户自定义的桥接在集装箱化的应用程序之间提供了更好的隔离和互操作性 用户自定义的桥接提供了容器之间的自动DNS解析 容器可以在运行中与用户定义的网络进行连接(attach)和分离(detach) 每个用户定义的网络会创建一个可配置的桥接网络 在默认桥接网络上链接的容器共享环境变量 管理user-defined bridgeManage a user-defined bridge 1234567891011docker network create --help#创建一个用户自定义桥接网络#你还可以指定子网，范围，网关...docker network creat $&#123;name&#125;docker network creat my-net#删除docker network rm $&#123;name&#125; 连接到自定义桥接网络Connect a container to a user-defined bridge 当你创建一个新的容器时，你可以指定一个或多个--network标志。 12345678910111213#创建时docker create --name my-nginx \ --network my-net \ --publish 8080:80 \ nginx:latest#运行中的容器docker network connect my-net my-nginx#断开连接docker network disconnect my-net my-nginx 使用IPv6需要修改docker daemon的配置项以支持使用IPv6，在创建自定义网络是指定--ipv6标志。你不能有选择地禁用默认桥接网络上的IPv6支持。 启用容器转发Enable forwarding from Docker containers to the outside world 默认情况下，使用默认桥接网络的连接的容器的流量不会转发到外部世界。启用操作如下： 1234567#配置Linux内核sysctl net.ipv4.conf.all.forwarding=1#修改iptables FORWARD默认策略iptables -P FORWARD ACCEPT#重启后无效，请写入配置文件 默认桥接网络Use the default bridge network 默认桥接网络被视为Docker的遗留细节，不建议用于生产环境。 连接容器到默认桥接网络如果未指定网络，则默认使用默认桥接网络。 配置默认桥接网络指定并配置daemon.json文件 123456789&#123; &quot;bip&quot;: &quot;192.168.1.5/24&quot;, &quot;fixed-cidr&quot;: &quot;192.168.1.5/25&quot;, &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;, &quot;mtu&quot;: 1500, &quot;default-gateway&quot;: &quot;10.20.1.1&quot;, &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;, &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]&#125; 使用IPv6修改配置文件以支持IPv6，则默认桥接网络自动支持IPv6。 overlayoverlay网络驱动在多个docker daemon主机之间创建分布式网络。该网络位于特定主机网络之上，允许容器连接到此并安全地进行通信。 当初始化集群或将docker主机加入现有集群时，将在docker主机上创建两个新网络： 称为ingress的overlay网络处理与集群服务相关的控制和数据流量。当你创建集群服务并且不将其连接到用户自定义的网络时，它默认连接到ingress网络。 称为docker_gwbridge的桥接网络将单独的docker daemon连接到集群的其它docker daemon。 与创建自定义桥接网络类似，你也可以使用docker network create来创建自动以的overlay网络。服务或容器一次可连接到多个网络，但只能通过连接的网络进行通信。 尽管可以将集群服务和独立容器连接到overlay网络，但默认行为和配置是不同的。 所有overlay网络的操作Operations for all overlay networks 创建overlay网络Create an overlay network 先决条件 使用overlay网络的docker daemon的防火墙规则 2377(tcp): 集群通信管理 7946(tcp/udp)： 节点通信 4789(udp)： overlay网络流量 创建overlay网络前，需要初始化docker daemon集群 12345678docker network create -d overlay my-overlay#创建可供集群服务或独立容器与其它docker daemon上的独立容器进行通信docker network create -d overlay --attachable my-attachable-overlay#你可以指定IP地址范围，子网，网关... 加密overlay网络上的流量Encrypt traffic on an overlay network Overlay network encryption is not supported on Windows！ 所有集群服务管理流量默认都是加密的，在GCM模式下使用AES算法。要加密应用程序数据，在创建overlay网络时添加--opt encrypted。这种加密带来了不可忽视的性能问题，所以应该在生产环境使用前对其进行测试。当启用overlay加密时，docker会在节点间创建IPsec tunnel，在这些节点上调度连接到overlay网络的服务的任务。 12#SWARM MODE OVERLAY NETWORKS AND STANDALONE CONTAINERS docker network create --opt encrypted --driver overlay --attachable my-attachable-multi-host-network 自定义默认ingress网络如果自动选择的子网与已存在的网络冲突，或需要自定义其它低级网络设置(如MTU)，这次功能非常有用。 1234567891011121314#显示详细信息docker network inspect ingress#移除现有网络docker network rm ingress#创建新网络 --ingressdocker network create \ --driver overlay \ --ingress \ --subnet=10.11.0.0/16 \ --gateway=10.11.0.2 \ --opt com.docker.network.driver.mtu=1200 \ my-ingress 自定义docker_gwbridgedocker_gwbridge是一个虚拟桥接网络，它将overlay网路连接到单独的docker daemon的物理网络。当初始化集群或将主机加入集群时，docker会自动创建它，但它不是docker设备。啊存在于docker主机的内核之中。如果你需要自定义其设置，则必须在主机加入集群之前或将主机临时从集群中删除之后才执行此操作。 12345678910111213141516171. 停止docker2. 删除已存在的docker_gwbridgeip link set docker_gwbridge doenip link del dev docker_gwbridge3. 启动docker，但不加入或初始化集群4. 创建docker_gwbridgedocker network create \--subnet 10.11.0.0/16 \--opt com.docker.network.bridge.name=docker_gwbridge \--opt com.docker.network.bridge.enable_icc=false \--opt com.docker.network.bridge.enable_ip_masquerade=true \docker_gwbridge5. 集群初始化或加入集群 swarm服务的操作Operations for swarm services 在overlay网络上发布端口Publish ports on an overlay network 连接到同一overlay网络的集群服务可有效地将所有端口暴露给对方。要是端口可在服务外可访问，必须使用-p或--publish标志暴露此端口。 两种方法： 传统的冒号:分隔语法 较新的逗号,分隔语法 Flag value Description -p 8080:80 or -p published=8080,target=80 Map TCP port 80 on the service to port 8080 on the routing mesh -p 8080:80/udp or -p published=8080,target=80,protocol=udp Map UDP port 80 on the service to port 8080 on the routing mesh -p 8080:80/tcp -p 8080:80/udp or -p published=8080,target=80,protocol=tcp -p published=8080,target=80,protocol=udp Map TCP port 80 on the service to TCP port 8080 on the routing mesh, and map UDP port 80 on the service to UDP port 8080 on the routine mesh 绕过swarm的路由网格Bypass the routing mesh for a swarm service 默认情况下，发布端口的集群服务使用路由网格来发布。当你连接到任何swarm节点上已发布的端口时，都会透明地将你重定向到正在运行服务的工作。实际上，docker充当集群服务的负载均衡器(Load-Balancer)。使用路由网格的服务以虚拟IP(vip)模式运行。即使在每个节点上运行服务也使用路由网格。使用路由网格时，不能保证那个docker node处理客户端请求。 要绕过路由网格，可使用DNS Round Robin(DNSRR)模式启动——--endpoint-mode dnsrr。你必须在服务前运行负载均衡器。docker主机上DNS查询服务名称会返回运行该服务的节点的IP地址列表。配置你的负载均衡器使用此列表并平衡各节点间的流量。 分离控制流量和数据流量默认情况下，尽管集群控制流量是加密的，但集群管理和应用程序之间的控制流量运行在同一个网络上。你可以配置docker来使用单独的网络接口来处理来种不同类型的流量。 overlay网络上独立容器的操作Operations for standalone containers on overlay networks 将独立容器连接到overlay网络Attach a standalone container to an overlay network 独立容器连接到ingress网络需添加--attachable标志。这使得运行在不同docker daemon上的独立容器能够进行通信，而无需在各个docker daemon主机上设置路由。 发布端口Publish ports Flag value Desciption -p 8080:80 Map TCP port 80 in the container to port 8080 on the overlay network -p 8080:80/udp Map UDP port 80 in the container to port 8080 on the overlay network -p 8080:80/sctp Map SCTP port 80 in the container to port 8080 on the overlay network -p 8080:80/tcp -p 8080:80/udp Map TCP port 80 in the container to TCP port 8080 on the overlay network, and map UDP port 80 in the container to UDP port 8080 on the overlay network 容器发现Container discovery 对于大多数情况，应该连接到服务名称——它是负载均衡的，并支持服务的所有容器处理。要获取支持该服务的所有任务的列表，请执行DNS查找服务——tasks.&lt;service-name&gt;。 host如果你对容器使用host网络驱动，则该容器的网络堆栈将不与docker主机隔离。例如，如果运行一个绑定在80端口并使用host网络的容器，则该容器的应用程序将在主机IP地址的80端口上可用。 host网络驱动只能运行在Linux主机上。 Macvlan一些应用程序，尤其是需要监视网络流量的应用程序，希望连接到物理网络上。在这种情况下，你可以使用macvlan驱动为容器的虚拟网络接口分配MAC地址，使其看起来像是直接连接到物理网络的物理网络接口。在这种情况下，你需要指定Docker主机上的物理接口用于macvlan，以及macvlan的子网和网关。 创建一个macvaln网络macvlan网络可处于 bridge mode 或 802.1q trunk mode: 在桥接模式下，macvlan流量通过主机上的物理设备 在802.1q主干桥接模式下，流量通过Docker在运行中创建的802.1q子接口。这使你可以更细粒度地控制路由和过滤。 bridge mode 创建bridge macvlan: 123456789101112docker networkcreate --driver macvlan \ --subnet=172.16.86.0/24 \ --gateway=172.16.86.1 \ -o parent=eth0 pub_net#--aux-addresses排除IP地址docker networkcreate --driver macvlan \ --subnet=172.16.86.0/24 \ --gateway=172.16.86.1 \ --aux-address=&quot;my-router=192.168.32.129&quot; \ -o parent=eth0 pub_net 802.1q truk bridge mode 如果你指定了包含点.的接口名——如eth0.50，则Docker将其解释为eth0的子接口，并自动创建子接口。 1234docker network create --driver macvlan \ --subnet=192.168.50.0/24 \ --gateway=192.168.50.1 \ -o parent=eth0.50 macvlan50 使用ipvlan替换macvlan 123456docker network create -d ipvlan \ --subnet=192.168.210.0/24 \ --subnet=192.168.212.0/24 \ --gateway=192.168.210.254 \ --gateway=192.168.212.254 \ -o ipvlan_mode=l2 ipvlan210 IPv6 123456docker network create -d macvlan \ --subnet=192.168.216.0/24 --subnet=192.168.218.0/24 \ --gateway=192.168.216.1 --gateway=192.168.218.1 \ --subnet=2001:db8:abc8::/64 --gateway=2001:db8:abc8::10 \ -o parent=eth0.218 \ -o macvlan_mode=bridge macvlan216 禁用容器网络在启动容器时加上`—network none来禁用容器的网络堆栈，这样在容器内便仅仅创建loopback设备。 12345$ docker run --rm -dit \ --network none \ --name no-net-alpine \ alpine:latest \ ash 网络教程Networking tutorials bridge network default bridge network user-defined bridge network default bridge network 基本docker网络 12345docker network lsNETWORK ID NAME DRIVER SCOPE8d3b84bfe5a0 bridge bridge local3579d63da633 host host localf766b990db47 none null local 以上列出了默认的桥接网络，主机网络(启动直接连接到docker daemon的主机的网络堆栈的容器)，none(启动一个没有网络设备的容器)。 启动一个容器 1docker run -dit --name alpine1 alpine ash 由于启动时没有指定网络，所以默认为桥接网络。 Inspect the bridge network，以查看哪个容器连接到它 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748docker network inspect bridge[ &#123; &quot;Name&quot;: &quot;bridge&quot;, &quot;Id&quot;: &quot;8d3b84bfe5a034c65d043af80976a1e6127011fc1ab312446252f562e221d351&quot;, &quot;Created&quot;: &quot;2018-05-24T18:38:35.538308064+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.17.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;893903129d869f384bd78d63a382f1c9527d6979be0a6cf3c13ea4f45a1554d6&quot;: &#123; &quot;Name&quot;: &quot;hardcore_rosalind&quot;, &quot;EndpointID&quot;: &quot;515d1435470c9f72d3b07680515d9c503457b8eb5bcaaaa915bb53901eac9424&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.17.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;, &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;, &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 连接到容器 123456789101112131415161718docker attach alpine1/ # ip addr show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever506: eth0@if507: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever/ # ping -c 2 www.baidu.comPING www.baidu.com (119.75.216.20): 56 data bytes64 bytes from 119.75.216.20: seq=0 ttl=55 time=46.521 ms64 bytes from 119.75.216.20: seq=1 ttl=55 time=45.189 ms ping其它容器 1234/ # ping -c 2 172.17.0.2PING 172.17.0.2 (172.17.0.2): 56 data bytes64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.125 ms64 bytes from 172.17.0.2: seq=1 ttl=64 time=0.075 ms user-defined bridge networks 创建名为apline-net用户自定义网络当然，你可以手动指定子网，网关这些。 123456789docker network create --driver bridge alpine-netdocket network lsNETWORK ID NAME DRIVER SCOPE810fb1e02000 alpine-net bridge local8d3b84bfe5a0 bridge bridge local3579d63da633 host host localf766b990db47 none null local 查看alpine-net网络详情注意网关和子网发生了变化。 1234567891011121314151617181920212223242526272829303132docker network inspect alpine-net[ &#123; &quot;Name&quot;: &quot;alpine-net&quot;, &quot;Id&quot;: &quot;810fb1e020008c7c6598f3b830ca25896dde638b1190d383ee6a5214d284e77d&quot;, &quot;Created&quot;: &quot;2018-06-14T15:45:19.43941906+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123;&#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 创建两种网络的容器 12345#alpine-netdocker run -dit --name alpine1 --network alpine-net alpine ash#default bridgedocker run -dit --name alpine2 alpine ash 显示两种网络情况 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596docker network inspect bridge[ &#123; &quot;Name&quot;: &quot;bridge&quot;, &quot;Id&quot;: &quot;8d3b84bfe5a034c65d043af80976a1e6127011fc1ab312446252f562e221d351&quot;, &quot;Created&quot;: &quot;2018-05-24T18:38:35.538308064+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.17.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;893903129d869f384bd78d63a382f1c9527d6979be0a6cf3c13ea4f45a1554d6&quot;: &#123; &quot;Name&quot;: &quot;hardcore_rosalind&quot;, &quot;EndpointID&quot;: &quot;515d1435470c9f72d3b07680515d9c503457b8eb5bcaaaa915bb53901eac9424&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.17.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125;, &quot;e7472c3ddda5043bc03868f4bf7ed59562220f05772f02f57ff589d086630562&quot;: &#123; &quot;Name&quot;: &quot;alpine2&quot;, &quot;EndpointID&quot;: &quot;ba565a247e347feb59713c188eb38e184d781da0489ae80e26ecad6d24e165c2&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:03&quot;, &quot;IPv4Address&quot;: &quot;172.17.0.3/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;, &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;, &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;, &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;]docker network inspect alpine-net[ &#123; &quot;Name&quot;: &quot;alpine-net&quot;, &quot;Id&quot;: &quot;810fb1e020008c7c6598f3b830ca25896dde638b1190d383ee6a5214d284e77d&quot;, &quot;Created&quot;: &quot;2018-06-14T15:45:19.43941906+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;264ccde8b1d5198551d689f0dd49ffbfb612255e0bf76c9543325d7c2e588acb&quot;: &#123; &quot;Name&quot;: &quot;alpine1&quot;, &quot;EndpointID&quot;: &quot;563c48cc6b936bcd9d3f57e9bb5e162a8cb52a23c8980346f288d42cc9b0a8fc&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 连接到容器 12345678910111213141516171819docker container attach alpine1#网段内通/ # ping -c 2 172.18.0.3PING 172.18.0.1 (172.18.0.3): 56 data bytes64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.097 ms64 bytes from 172.18.0.3: seq=1 ttl=64 time=0.070 ms--- 172.18.0.1 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.070/0.083/0.097 ms#网段外不通/ # ping -c 2 172.17.0.2PING 172.17.0.2 (172.16.0.1): 56 data bytes--- 172.17.0.2 ping statistics ---2 packets transmitted, 0 packets received, 100% packet loss 使容器连接到default bridge这样，此容器便连接到了两个网络中。 1234567docker network connect bridge apline1/ # ping -c 2 172.17.0.2PING 172.17.0.2 (172.17.0.2): 56 data bytes64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.102 ms64 bytes from 172.17.0.2: seq=1 ttl=64 time=0.071 ms host networkhost网络不存在隔离问题。 12345678910111213141516171819202122232425262728293031323334353637383940414243#默认主机上的80端口docker run -rm -dit --network host --name my_nginx nginx#访问http://localhost:80Welcome to nginx!docker network inspect host[ &#123; &quot;Name&quot;: &quot;host&quot;, &quot;Id&quot;: &quot;3579d63da633adcc497417d39b8b1d270cf329a68b9222f6a75fae72086509d6&quot;, &quot;Created&quot;: &quot;2018-04-27T11:31:17.900886126+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;host&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: null, &quot;Config&quot;: [] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;f02a3b11fce7228ad6ee196771bd9cf0b64966bfc2aa7c27719bc120dbdc7189&quot;: &#123; &quot;Name&quot;: &quot;my_nginx&quot;, &quot;EndpointID&quot;: &quot;4ee67fb4d0a0c1a357b5fdd141f856a70c205fad5c49b1cb6a4f5245df0318a8&quot;, &quot;MacAddress&quot;: &quot;&quot;, &quot;IPv4Address&quot;: &quot;&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123;&#125; &#125;] overlay network default overlay network user-defined overlay network overlay network for standalone containers Communicate between a container and a swarm service default overlay依赖： swarm集群 集群节点 worker-1 worker-2 mananger 123456789docker network lsNETWORK ID NAME DRIVER SCOPE495c570066be bridge bridge local961c6cae9945 docker_gwbridge bridge localff35ceda3643 host host localtrtnl4tqnc3n ingress overlay swarmc8357deec9cb none null local 创建nginx-net的overlay的网络: 123456789docker network create -d overlay nginx-net$ docker service create \ --name my-nginx \ --publish target=80,published=80 \ --replicas=5 \ --network nginx-net \ nginx user-defined overlay123456789docker network create -d overlay my-overlay$ docker service create \ --name my-nginx \ --network my-overlay \ --replicas 1 \ --publish published=8080,target=80 \ nginx:latest overlay network for standalone containers Communicate between a container and a swarm service macvalan network假设主机网络接口为eth0。 bridge此模式下，流量通过eth0流动，docker使用其MAC地址就流量路由到容器。 创建名为my-macvlan-net的macvlan网络 12345$ docker network create -d macvlan \ --subnet=172.16.86.0/24 \ --gateway=172.16.86.1 \ -o parent=eth0 \ my-macvlan-net 查看网络 1234567docker network lsNETWORK ID NAME DRIVER SCOPE810fb1e02000 alpine-net bridge local8d3b84bfe5a0 bridge bridge local3579d63da633 host host local6be80655739d my-macvlan-net macvlan localf766b990db47 none null local 以此网络运行容器 12345$ docker run --rm -itd \ --network my-macvlan-net \ --name my-macvlan-alpine \ alpine:latest \ ash 查看my-macvlan-net 1234567891011121314151617181920212223242526272829303132333435363738394041docker network inspect my-macvlan-net[ &#123; &quot;Name&quot;: &quot;my-macvlan-net&quot;, &quot;Id&quot;: &quot;6be80655739deffe204e087d098f97fc75072d95f9818e129cfd7d5667ed01f3&quot;, &quot;Created&quot;: &quot;2018-06-14T16:52:30.507647877+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;macvlan&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.16.86.0/24&quot;, &quot;Gateway&quot;: &quot;172.16.86.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;8301b669b4b63afb20911b46243f11b70e5a9d0880beaafa922b52bcb8ab0477&quot;: &#123; &quot;Name&quot;: &quot;my-macvlan-alpine&quot;, &quot;EndpointID&quot;: &quot;4f2971ba4bd92c34e2a299d301f739867d2b1b65d35566aef07d7a26b079662c&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:10:56:02&quot;, &quot;IPv4Address&quot;: &quot;172.16.86.2/24&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;parent&quot;: &quot;ens160&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 查看容器网卡和路由 123456789docker exec my-macvlan-alpine ip addr show eth0517: eth0@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UNKNOWN link/ether 02:42:ac:10:56:02 brd ff:ff:ff:ff:ff:ff inet 172.16.86.2/24 brd 172.16.86.255 scope global eth0 valid_lft forever preferred_lft foreverdocker exec my-macvlan-alpine ip routedefault via 172.16.86.1 dev eth0172.16.86.0/24 dev eth0 scope link src 172.16.86.2 802.1q trunked bridge network此模式下，流量流经eth0的子接口(eth0.10)，docker使用其MAC地址将流量路由到容器。 创建名为my-8021q-macvlan-net的macvlan网络 12345docker network create -d macvlan \ --subnet=172.16.87.0/24 \ --gateway=172.16.87.1 \ -o parent=eth0.10 \ my-8021q-macvlan-net 查看此网络 123456789101112docker network lsNETWORK ID NAME DRIVER SCOPE2aeafd44fd67 my-8021q-macvlan-net macvlan local6be80655739d my-macvlan-net macvlan localifconfigeth0.10: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet6 fe80::20c:29ff:feaa:7e75 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:aa:7e:75 txqueuelen 0 (Ethernet) 用此网络启动一个容器 12345docker run --rm -itd \ --network my-8021q-macvlan-net \ --name my-second-macvlan-alpine \ alpine:latest \ ash 查看my-8021q-macvlan-net 1234567891011121314151617181920212223242526272829303132333435363738394041docker network inspect my-8021q-macvlan-net[ &#123; &quot;Name&quot;: &quot;my-8021q-macvlan-net&quot;, &quot;Id&quot;: &quot;2aeafd44fd67e6ee937c82788745b1d45fb291efd61f545537528eafdff94e3d&quot;, &quot;Created&quot;: &quot;2018-06-14T17:06:33.426800076+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;macvlan&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.16.87.0/24&quot;, &quot;Gateway&quot;: &quot;172.16.87.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;90103673d94915c3c7fb572eec8bd97b2aee1c3dab877c598d0a62e6d797b06d&quot;: &#123; &quot;Name&quot;: &quot;my-second-macvlan-alpine&quot;, &quot;EndpointID&quot;: &quot;5c93f2ea1d29150ee57f099d42fc8e04a571efd0d1273a4f6bed755dc34f2e54&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:10:57:02&quot;, &quot;IPv4Address&quot;: &quot;172.16.87.2/24&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123; &quot;parent&quot;: &quot;ens160.10&quot; &#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 查看容器网络接口 12345678910docker exec my-second-macvlan-alpine ip addr show eth0519: eth0@if518: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UNKNOWN link/ether 02:42:ac:10:57:02 brd ff:ff:ff:ff:ff:ff inet 172.16.87.2/24 brd 172.16.87.255 scope global eth0 valid_lft forever preferred_lft foreverdocker exec my-second-macvlan-alpine ip routedefault via 172.16.87.1 dev eth0172.16.87.0/24 dev eth0 scope link src 172.16.87.2 配置守护进程和容器启用IPv6启用IPv6前，请确保支持IPv6. 给docker daemon启用IPv6: 12345/etc/docker/daemon.json&#123; &quot;ipv6&quot;: true&#125; iptables所有Docker的iptables规则都被添加到DOKCER chain。不要手动操作此表。如果你需要添加Docker规则，请将其添加到DOCKER-USER chain 栗子： 1iptables -I DOCKER-USER -m iprange -i ext_if ! --src-range 192.168.1.1-192.168.1.3 -j DROP 容器网络容器使用的网络类型(无论是bridge，overlay，macvlan还是自定义网络)，在容器内都是透明的。从容器的角度来看，它有一个带有IP地址，网关，路由表，DNS服务和其它网络细节的网络接口。 publish port默认情况下，创建容器时，它不会将任何端口发布的外部世界。要是端口可用于docker之外的服务，请使用--publish或-p标志。 1234-p 8080:80-p 192.168.1.100:8080:80-p 8080:80/udp-p 8080:80/tcp -p 8080:80/udp ip add and hostname默认情况下，容器会为其连接的每个docker网络分配一个IP地址。IP地址是从分配给网络的地址池中分配的，因此docker daemon有效地充当了每个容器的DHCP服务器。每个网络也有一个默认的子网掩码和网关。同样，一个容器的主机名也有docker daemon指定。 12345678910111213141516#指定运行网络docker run xxx --network#运行的容器连接到其它网络docker network connect#--ip，指定IP地址docker network connect my-bridge --ip 172.18.0.111#--hostname，指定主机名docker run xxx --network xxx --hostname container-01docker network connect my-bridge --hostname container-02 DNS默认情况下，容器会继承docker daemon的DNS设置，包括/etc/hosts和/etc/resolv.conf。你也可以基于每个容器覆盖这些默认设置。 12345678910#DNS server--dns#DNS搜索域--dns-search#表示DNS选项值的键值对--dns-opt--hostname Docker使用代理服务器在启动docker容器的用户主目录下创建此文件： ~/.docker/config.json 12345678910&#123; &quot;proxies&quot;: &#123; &quot;default&quot;: &#123; &quot;httpProxy&quot;: &quot;http://127.0.0.1:3001&quot;, &quot;noProxy&quot;: &quot;*.test.example.com,.example2.com&quot; &#125; &#125;&#125; 应用程序数据Manage application data 存储综述Manage data in Docker 默认情况下，容器内创建的所有文件都被存储容器的可写层上： 当容器不在运行时，数据不是持续存在的。容器外的进程很难从容器中获取数据 容器的可写层与主机紧密耦合，你很难将数据移动到其他地方 向容器的可写入层写入数据，需要存储驱动(storage driver)管理文件系统才存储驱动使用Linux kernel来提供一个union filesystem。与直接写入主机文件系统的数据卷相比，这种额外的抽象会降低性能。 Docker容器有两种选项将文件存储到主机上，这样即使容器停止之后这些文件也会被保留: volumes bind mounts tmpfs mount(Docker on Linux) 选择正确的挂载方式Choose the right type of mount 无论你选用哪种挂载方式，数据在容器内看起来都是相同的。它被公开为容器文件系统中的目录或单个文件。 一个简单的方法——考虑数据在docker主机上的位置，可以看出volumes, bind mounts, temfs之间的差异： Volumesvolumes存储在由docker管理的主机文件系统的一部分中(如Linux上: /var/lib/docker/volumes/)。non-docker进程不应该修改这部分文件系统。Volume是Docker中保存数据的最佳方式。 Bind mountsbind mounts可存储在主机系统上的任何地方。它们可能是最要的系统文件或目录。docker主机或docker容器上的non-docker进程可以随时修改它们。 tmpfs仅存储在主机系统的内存中，不会写入主机系统的文件系统。 volumes的好栗子Good use cases for volumes Volemes是在docker容器和服务中持久化数据的首选方式: 在多个运行容器之间共享数据。如果你没有明确创建它，会在第一次挂载到容器时创建volume。当容器停止或删除时，volume仍然存在。多个容器可以挂载相同的volume，无论是read-write还是read-only。只有在你手动删除volume时它才会被删除。 当docker主机不能保证具有给定的目录或文件结构时，volume帮助你将docker主机的配置与运行时的容器进行分离。 当你想要将容器的数据存储在远程主机而不是本地的时候。 当你需要备份、还原或将数据从一台docker主机迁移到另一台时，volume时更好的选择。 bind mounts的好栗子一般来说，你应该尽量使用volumes。bind mounts适合以下案例： 从主机共享配置文件到容器这就是默认情况下，通过将主机的/etc/resolv.conf挂载到每个容器中，Docker为每个容器提供DNS解析。 在docker主机/容器的开发环境上共享源码或构建工件 当docker主机的文件或目录结构保证与容器所需的bind mounts一致时 tmpfs mounts的好栗子当你不希望数据在主机上或容器内持久存储时，tmpfs mounts最合适。这可能处于安全原因，或在应用于程序需要编写大量非持久性状态数据时保护容器的性能。 使用bind或volumes的提示如果你要使用bind mounts 或 volumes，牢记以下事项： 如果你挂载一个空卷(empty volume)到存在文件或目录的容器中的目录上，则会将这些文件或目录赋值到卷中。同样，如果你启动容器并制定了一个尚不存在的卷，则会为你创建一个空卷。 如果你挂载一个bind mount或non-empty volume到存在文件或目录的容器中的目录上，则这些文件或目录会被挂载所遮蔽。就像在Linux上挂载卷一样。 Volumesvolumes是持久化Docker数据的首选机制，卷由docker完全管理。另外，由于卷不会增加使用它的容器的大小，并且该卷的内容存在于给定容器的周期之外，因此卷通产是比将容器的可写入层中的数据持久化更好的选择。 1234567891011-v/--volume#此选项更详细和简单#如果你需要指定volume driver，请使用此flag--mountdocker service create \ --mount &apos;type=volume,src=&lt;VOLUME-NAME&gt;,dst=&lt;CONTAINER-PATH&gt;,volume-driver=local,volume-opt=type=nfs,volume-opt=device=&lt;nfs-server&gt;:&lt;nfs-path&gt;,&quot;volume-opt=o=addr=&lt;nfs-address&gt;,vers=4,soft,timeo=180,bg,tcp,rw&quot;&apos; --name myservice \ &lt;IMAGE&gt; --volume 由三个由冒号:分割的字段组成。这些字段必须按照正确的顺序排列，每个字段的含义并不明显。第一个字段是卷的名称，并且在给定主机上是唯一的。对于匿名卷，第一个字段被省略。第二个字段是文件或目录在容器中的挂载路径。第三个字段是可选的，是由一个逗号`,分隔的选项列表。 --mount 由多个键值对组成，以逗号,分隔。--mount的语法比--volume更冗长，但键的顺序并不重要，并且标志的值更易于理解。挂载的类型(type)有bind, volume, tmpfs。挂载的来源(source, src)为卷的名称，对于匿名卷该字段可被省略。目的地(destination, dst, target)的值是安装在容器中的文件或目录的路径。只读(readonly)选项将导致bind mount以只读方式挂载到容器中。volume-opt选项可以多次指定，它是由选项名称和值组成的键值对组成。 创建和管理卷1234567891011121314151617181920212223docker volume create my-voldocker volume lsDRIVER VOLUME NAMElocal my-voldocker volume inspect my-vol[ &#123; &quot;CreatedAt&quot;: &quot;2018-06-15T17:19:02+08:00&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: &#123;&#125;, &quot;Mountpoint&quot;: &quot;/opt/docker/volumes/my-vol/_data&quot;, &quot;Name&quot;: &quot;my-vol&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Scope&quot;: &quot;local&quot; &#125;]docker volume rm my-vol 启动用卷的容器Start a container with a volume 包括两种卷： 已存在的卷 未存在的卷会自动创建 123456789101112#--mountdocker run -d \ --name devtest \ --mount source=myvol2,target=/app \ nginx:latest#--volumedocker run -d \ --name devtest \ --volume myvol2:/app \ nginx:latest 1234567891011121314151617181920docker volume lsDRIVER VOLUME NAMElocal my-vollocal myvol2docker inspect devtest#找到挂载 &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;myvol2&quot;, &quot;Source&quot;: &quot;/opt/docker/volumes/myvol2/_data&quot;, &quot;Destination&quot;: &quot;/app&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;z&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; &#125; ] 启动用卷的服务Start a service with volumes docker服务不支持使用--volume标志，请使用--mount标志。 12345docker service create -d \ --replicas=4 \ --name devtest-service \ --mount source=myvol2,target=/app \ nginx:latest 在机器间共享数据Share data among machines 在构建容错应用程序时，可能需要配置同一服务的多个副本能访问相同的文件，而这些副本可能分布于不同的节点上。 卷驱动程序(volume driver)允许你从应用程序逻辑中抽象出底层存储系统。 使用卷驱动Use a volume driver 在创建卷或启动带卷的容器时，你可以指定卷驱动。如vieux/sshfs卷驱动程序。 初始化 1docker plugin install --grant-all-permissions vieux/sshfs 使用卷驱动创建卷 12345#操作node2docker volume create --driver vieux/sshfs \ -o sshcmd=test@node2:/home/test \ -o password=testpassword \ sshvolume 启动一个带用卷驱动程序创建的卷的容器 12345docker run -d \ --name sshfs-container \ --volume-driver vieux/sshfs \ --mount src=sshvolume,target=/app,volume-opt=sshcmd=test@node2:/home/test,volume-opt=password=testpassword \ nginx:latest 备份，还原或迁移数据卷 使用--volumes-from标志创建一个挂载该卷的新容器。 1234567#备份docker run --rm --volumes-from dbstore -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata#从备份还原docker run -v /dbdata --name dbstore2 ubuntu /bin/bashdocker run --rm --volumes-from dbstore2 -v $(pwd):/backup ubuntu bash -c &quot;cd /dbdata &amp;&amp; tar xvf /backup/backup.tar --strip 1&quot; bind mounts与volumes相比，bind mounts功能有限。当你使用bind mounts时，主机上的文件或目录(绝对路径或相对路径)被挂载到容器内。相比之下，当你使用volumes时，会在主机上的Docker存储目录中创建一个新目录，并且Docker会管理该目录的内容。该文件或目录不需要已经存在于Docker主机上。如果它尚未存在，它会根据需求创建。bind mounts非常高效，但是它们依赖于具有特定目录结构的主机文件系统。如果你正在开发新的Docker Application，请考虑使用volumes。你不能使用Docker CLI直接管理bind mounts。 你可以使用--volume或--mount(语法更详细)flag。具体区别参考volumes的介绍。 启动用bind mount的容器Start a container with a bind mount 1234567891011121314#--mountdocker run -d \ -it \ --name devtest \ --mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app \ nginx:latest#--volumedocker run -d \ -it \ --name devtest \ -v &quot;$(pwd)&quot;/target:/app \ nginx:latest 挂载到容器内非空目录如果挂载在容器内非空目录上，则该目录的已有内容将被隐藏。 1234567891011121314#--mountdocker run -d \ -it \ --name broken-container \ --mount type=bind,source=/tmp,target=/usr \ nginx:latest#--volumedocker run -d \ -it \ --name broken-container \ -v /tmp:/usr \ nginx:latest 只读bind mountUse a read-only bind mount 某些时候，容器可能只需要只读权限。 1234567891011121314#--mountdocker run -d \ -it \ --name devtest \ --mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app,readonly \ nginx:latest#--volumedocker run -d \ -it \ --name devtest \ -v &quot;$(pwd)&quot;/target:/app:ro \ nginx:latest bind propagation对于bind mounts和volumes，bind propagation(传播)默认为rprivate。它只能对Linux主机上的bind mounts进行配置。它是一个高级话题，许多用户并不需要配置它。 bind propagation(传播)是指在给定的bind-mounts或named volume中创建的挂载是否可以传播(propagation)到该挂载(mount)的副本(replicas)。考虑一个挂载点/mnt，挂载在/tmp上。传播设置控制/tmp/a上的挂载点是否也可用于/mnt/a。每个传播设置都有一个递归对应点。在递归的情况下，考虑/tmp/a也被挂载到/foo。传播设置控制是否存在/mnt/a和/tmp/a。 传播设置 描述 shared 原始mount的sub-mount会暴露给replica mounts，并且replica mounts的sub-mount同样传播给原始mount。也就是双向 slave 类似于shared，但仅限于单方向。 private 私有挂载 rshared 与shared相同，但传播也扩展到嵌套在任何原始或副本挂载点内的挂载点 rslave 与slave相同，但传播也扩展到嵌套在任何原始或副本挂载点内的挂载点 rprivate 默认值。与private相同，这意味着原始或副本挂载点内的任何位置的挂载点都不会沿任一方向传播 在设置bind propagation之前，主机文件系统需要已经支持bind propagatin: https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt 12345678910111213141516#--mountdocker run -d \ -it \ --name devtest \ --mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app \ --mount type=bind,source=&quot;$(pwd)&quot;/target,target=/app2,readonly,bind-propagation=rslave \ nginx:latest#--volumedocker run -d \ -it \ --name devtest \ -v &quot;$(pwd)&quot;/target:/app \ -v &quot;$(pwd)&quot;/target:/app2:ro,rslave \ nginx:latest selinux label如果你使用selinux，你可以添加z或Z选项来修改挂载到容器内的主机文件或目录的selinux标签。这户影响主机本身的文件或目录，并可能导致Docker范围之外的后果。 zbind mount的内容在多个容器之间共享。 Zbind mount的内容是私有和非共享的。 123456#不支持--mountdocker run -d \ -it \ --name devtest \ -v &quot;$(pwd)&quot;/target:/app:z \ nginx:latest tmpfs mountstmpfs: https://docs.docker.com/storage/tmpfs/#limitations-of-tmpfs-mountstmpfs mounts只支持运行在Linux上的Docker。 Troubleshoottroubleshoot: https://docs.docker.com/storage/troubleshooting_volume_errors/ 将数据存储到容器内Store data within containers 关于存储驱动为了有效地使用存储驱动(storage driver)，了解Docker如何构建和存储镜像，以及容器如何使用镜像是很重要的。你可以使用这些信息作出明智的选择，以便找到应用程序数据持久化的最佳方式，并避免出现性能问题。 存储驱动允许你在容器的可写入层创建数据。在容器停止后，这些文件将不会被保留，并且读写速度都很低。 镜像和层Images and layers Docker镜像由一系列层(layer)构建而成。每个层代表镜像的Dockerfile中的指令，除最后一层外的每个层都是只读的。 考虑如下Dockerfile: 1234FROM ubuntu:15.04COPY . /appRUN make /appCMD python /app/app.py 此Dockerfile包含4个命令，每个命令创建一个层。当你创建一个新容器时，你在底层之上添加了一个新的可写入层——它通常被称为容器层(container layer)。对运行中的容器所做的所有更改(增删改文件)都会写入此可写容器层。 存储驱动处理有关这些层相互交互的详细信息。有几个不同的驱动程序，在不同的情况下具有相应的优点和缺点。 容器和层Container and layers 容器和镜像之间的主要区别是最高的可写入层。当容器删除时，可写入层也被删除。但底层镜像保持不变。 由于每个容器都有自己的可写入容器层，并且所有的更改都存储在此容器中，因此多个容器可以共享相同的基础镜像的访问权限，并拥有自己的数据状态。 Docker使用存储驱动来管理镜像层和可写入容器层的内容。每个存储驱动程序都已不同方式实现，但所有驱动程序都是用可堆叠(stackable)的镜像层和写入时复制(copy-on-write)策略。 容器大小Container size on disk 使用docker ps -s(--size)命令查看正在运行的容器的大小。有两个大小: size每个容器的可写入层的数据量(在磁盘上的) virtual size容器使用的只读镜像的数据量加上容器可写入层大小 写入时复制The copy-on-write (CoW) strategy 写入时复制是一种共享和复制文件以实现最高效率的策略。如果文件或目录存在于镜像的较低层中，而另外的层(包括可写入层)需要对其进行读取访问，则它只是用已有文件。第一次需要修改文件时，该文件将被复制到该层并进行修改。这最大限度减少了每个后续层的I/O和大小。 共享促进了较小的容器Sharing promotes smaller images 当你创建和拉取镜像时，它们通常存储于本机的/var/lib/docker下。每层都存储在主机存储区内的特定目录下/var/lib/docker/&lt;storage-driver&gt;/layers。 123456ls /var/lib/docker/aufs/layers1d6674ff835b10f76e354806e16b950f91a191d3b471236609ab13a930275e245dbb0cbe0148cf447b9464a358c1587be586058d9a4c9ce079320265e2bb94e7bef7199f2ed8e86fa4ada1309cfad3089e0542fec8894690529e4c04a7ca2d73ebf814eccfe98f2704660ca1d844e4348db3b5ccc637eb905d4818fbfb00a06a 复制使容器高效Copying makes containers efficient 容器不会更改的任何文件都不会被复制到此可写入层中。这意味着可写入层尽可能小。 当容器中存在的文件被修改时，存储驱动之赐你个写入时复制操作(CoW)。涉及的具体步骤取决于具体的存储驱动。 aufs, overlay, overlay2存储驱动 遵循的基本顺序: 通过镜像层搜索要更新的文件 对找到的文件的第一个副本执行copy_up操作，将文件复制到容器的可写入层 任何修改应用于此复制的文件，并且该容器不能看到存在于较低层中的文件的只读副本 选择存储驱动Select a storage driver 理想情况下，将很少的数据写入容器的可写入层，并且使用Docker volume写入数据。但某些工作负载要求你能够写入容器的可写入层，这就是存储驱动进来的地方。 存储驱动控制镜像和容器在Docker主机上的存储和管理方式。 考虑三个高层次因素： 如果你的Kernel支持多个存储驱动，在没有指定存储驱动的情况下，Docker会列出要使用拿个存储驱动程序的优先级列表 如果可能，将使用配置最少的存储驱动。如brrfs, zfs 否则，请尝试在最常见的情况下使用具有最佳整体性能和稳定性的存储驱动程序 overlay2是首选(Docker CE的默认选择)，其次是overlay。这些都不需要额外的配置。 devicemapper居次，但需要direc-lvm用于生产环境，因为loopback-lvm的性能很差。 你的选择会受限于Docker版本、操作系统和发行版 某些存储驱动要求你为文件系统使用特定格式 你的选择还取决于工作负载和所需的稳定级别 Linux发行版支持的存储驱动Docker CE Linux distribution Recommended storage drivers Docker CE on Ubuntu aufs, devicemapper, overlay2 (Ubuntu 14.04.4 or later, 16.04 or later), overlay, zfs, vfs Docker CE on Debian aufs, devicemapper, overlay2 (Debian Stretch), overlay, vfs Docker CE on CentOS devicemapper, vfs Docker CE on Fedora devicemapper, overlay2 (Fedora 26 or later, experimental), overlay (experimental), vfs 存储驱动支持的文件系统 Storage driver Supported backing filesystems overlay, overlay2 ext4, xfs aufs ext4, xfs devicemapper direct-lvm btrfs btrfs zfs zfs 查看存储驱动12345docker infoServer Version: 18.03.1-ceStorage Driver: overlay2 AUFS存储驱动AUFS is a union filesystem. aufs存储驱动用于管理Ubuntu上Docker的镜像和层。 我的发行版是Centos，此驱动针对Ubuntu。注意 使用aufs存储驱动配置Docker 判断kernel是否支持aufs 1grep aufs /proc/filesystems 查看Docker存储驱动 1docker info 配置存储驱动 1234vim /etc/docker/daemon.json#或--storage-driver aufs存储驱动如何工作AUFS是一个联合文件系统，这意味着它在单个Linux主机上对多个目录进行分层并将它们呈现为单个目录。这些目录在AUFS术语中称为分支，在Docker术语中称为层。统一过程被称为联合安装。 容器如何使用aufs进行读写读取文件 Btrfs存储驱动Use the BTRFS storage driver Device Mapper存储驱动Use the Device Mapper storage driver Device Mapper是基于kernel的框架，支持Linux上的许多高级卷管理技术。Docker的devicemapper存储驱动利用此框架的精简配置和快照功能进行镜像和容器管理。 对于支持它的系统，devicemapper支持包含在Linux内核中。但是，需要特定配置才能将其用于Docker。devicemapper驱动使用专用于Docker的块设备，并在块级(block level)而不是文件级(file level)运行。这些设备可通过在Docker主机添加物理设备来扩展，并且它们比咋子操作系统级别使用文件系统更好。 依赖 Docker EE Docker CE 更改存储驱动会使已创建的容器在本地系统上都无法访问 配置devicemapper存储驱动 loop-lvm 1234567891011#loop-lvm模式/etc/docker/daemon.json&#123; &quot;storage-driver&quot;: &quot;devicemapper&quot;&#125;#查看docker info direct-lvm生产环境的devicemapper存储驱动必须使用direct-lvm模式。此模式使用块设备创建精简池。这比使用loopback设备更快，更高效地使用系统资源，并且块设备可以根据需求进行扩展。 Option Description Required Default Example dm.directlvm_device The path to the block device to configure for direct-lvm. Yes - dm.directlvm_device=”/dev/xvdf” dm.thinp_percent The percentage of space to use for storage from the passed in block device. No 95 dm.thinp_percent=95 dm.thinp_metapercent The percentage of space to for metadata storage from the passed-in block device. No 1 dm.thinp_metapercent=1 dm.thinp_autoextend_threshold The threshold for when lvm should automatically extend the thin pool as a percentage of the total storage space. No 80 dm.thinp_autoextend_threshold=80 dm.thinp_autoextend_percent The percentage to increase the thin pool by when an autoextend is triggered. No 20 dm.thinp_autoextend_percent=20 dm.directlvm_device_force Whether to format the block device even if a filesystem already exists on it. If set to false and a filesystem is present, an error is logged and the filesystem is left intact. No false dm.directlvm_device_force=true 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#安装依赖RHEL / CentOS: device-mapper-persistent-data, lvm2, and all dependenciesUbuntu / Debian: thin-provisioning-tools, lvm2, and all dependencies#创建物理卷(physical volume)pvcreate /dev/cvdf#创建卷组(volume group)vgcreat docker /dev/xvdf#创建逻辑卷(logical volume)lvcreate --wipesignatures y -n thinpool docker -l 95%VGlvcreate --wipesignatures y -n thinpoolmeta docker -l 1%VG#转换卷为精简池lvconvert -y \--zero n \-c 512K \--thinpool docker/thinpool \--poolmetadata docker/thinpoolmeta#配置lvm配置文件精简池自动扩展/etc/lvm/profile/docker-thinpool.profile#指定thin_pool_autoextend_threshold 和 thin_pool_autoextend_percent的值activation &#123; thin_pool_autoextend_threshold=80 thin_pool_autoextend_percent=20&#125;#应用LVM profilelvchange --metadataprofile docker-thinpool docker/thinpool#启用监控LVlvs -o+seg_monitor#配置devicemapper存储驱动/etc/docker/daemon.json&#123; &quot;storage-driver&quot;: &quot;devicemapper&quot;, &quot;storage-opts&quot;: [ &quot;dm.thinpooldev=/dev/mapper/docker-thinpool&quot;, &quot;dm.use_deferred_removal=true&quot;, &quot;dm.use_deferred_deletion=true&quot; ]&#125;#查看docker info 管理devicemapper1234567#查看LVM logsjournalctl -fu dm-event.servicepvdisplayvgdisplay/vgextendlvdisplay/lvextend/lvchange OverlayFS存储驱动Use the OverlayFS storage driver ZFS存储驱动Use the ZFS storage driver VFS存储驱动Use the VFS storage driver VFS存储驱动不是联合文件系统，相反，每层都是磁盘上的一个目录，它不支持CoW。要创建一个新层，先前的层会进行深层复制(deep copy)。与其它驱动相比，这导致磁盘性能下降和占用更多磁盘空间。但是，它强大，稳定，适用于各种环境。 配置VFS存储驱动 1234567891011121314151617vim /etc/docker/daemon.json&#123; &quot;storage-driver&quot;: &quot;vfs&quot;&#125;#控制大小&#123; &quot;storage-opts&quot;: [&quot;size=256M&quot;]&#125;#查看docker info 在生产环境运行应用程序Run your app in production 配置对象Configure all objects 自定义原数据Apply custom metadata to objects Docker object label标签(label)是一种将原数据(metadata)应用于docker object的机制，包含: image container local daemon volume network node service label key and value标签是一组键值对，以字符串形式存储。可以为对象指定多个标签，但每个键值对必须唯一。如果一个键有多个值，则最新写入的值会覆盖以前的值。 key格式建议label key是可能包含字母，数字，.，-组成的字符串。 第三方工具的作者给每个label key加上前缀域，如com.example.some-label 未经允许，不得使用他人域 com.docker.*, io.docker.*, org.dockerproject.*命名空间保留给Docker内部使用 以小写字母开头和结尾 用.分割命令空间字段 value 指南label value可以包含任何可表示为字符串的数据类型，包括JSON, XML, CSV, YAML…唯一的要求是，首先使用特定于结构类型的机制将该值序列化为字符串。 清理未使用的对象Prune unused Docker objects Docker采取保守的方法来清理未使用的对象(通常称为垃圾回收)，通常它不会删除这些对象，除非你明确要求Docker这样做。对于每个类型的对象，docker提供了prune命令。你也可以使用docker system prune命令一次清理多种类型的对象。 1234567891011121314151617#prune imagedocker image prune docker image prune -a --filter &quot;until=24h&quot;#prune containerdocker container prune#prune volumedocker volume prunedocker volume prune --filter &quot;label!=keep&quot;#prune everythingdocker system prunedocker system prune --volumes 格式化输出Format command and log output 1234567891011121314151617181920212223242526#joindocker inspect --format &apos;&#123;&#123;join .Args &quot; , &quot;&#125;&#125;&apos; container#jsondocker inspect --format &apos;&#123;&#123;json .Mounts&#125;&#125;&apos; container#lowerdocker inspect --format &quot;&#123;&#123;lower .Name&#125;&#125;&quot; container#splitdocker inspect --format &apos;&#123;&#123;split .Image &quot;:&quot;&#125;&#125;&apos;#titledocker inspect --format &quot;&#123;&#123;title .Name&#125;&#125;&quot; container#upperdocker inspect --format &quot;&#123;&#123;upper .Name&#125;&#125;&quot; container#printIndocker inspect --format=&apos;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;println .IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&apos; container 配置daemonConfigure the daemon 配置和运行Docker配置docker daemon 使用json配置文件 使用dockerd --flag 1234567891011121314151617/etc/docker/daemon.json&#123; &quot;debug&quot;: true, &quot;tls&quot;: true, &quot;tlscert&quot;: &quot;/var/docker/server.pem&quot;, &quot;tlskey&quot;: &quot;/var/docker/serverkey.pem&quot;, &quot;hosts&quot;: [&quot;tcp://192.168.59.3:2376&quot;]&#125;#或dockerd --debug \ --tls=true \ --tlscert=/var/docker/server.pem \ --tlskey=/var/docker/serverkey.pem \ --host tcp://192.168.59.3:2376 docker daemon目录docker daemon将所有数据保存在一个目录中。你可以手动修改它。 默认目录: Linux： /var/lib/docker Windows: C:\ProgramData\docker 使用systemd控制dockerControl Docker with systemd 123456cat /usr/lib/systemd/system/docker.service#orcat /etc/systemd/system/docker.servicesystemctl enable/start/stop/status docker 自定义docker daemon选项 123456vim /etc/docker/daemon.json&#123; &quot;data-root&quot;: &quot;/mnt/docker-data&quot;, &quot;storage-driver&quot;: &quot;overlay&quot;&#125; http/https proxyDocker daemon使用HTTP_PROXY，HTTPS_PROXY和NO_PROXY环境变量来配置代理行为。无法使用daemon.json文件来配置环境变量。 123456789101112131415mkdir -p /etc/systemd/system/docker.service.d#/etc/systemd/system/docker.service.d/http-proxy.conf[Service]Environment=&quot;HTTP_PROXY=http://proxy.example.com:80/&quot;#/etc/systemd/system/docker.service.d/https-proxy.conf[Service]Environment=&quot;HTTPS_PROXY=https://proxy.example.com:443/&quot;systemctl daemon-reloadsystemctl restart dockersystemctl show --property=Environment docker 收集Docker指标Collect Docker metrics with Prometheus Promethus: https://prometheus.io/Prometheus是一个开源的系统监控和报警工具包。你可以将Docker配置为Prometheus target。设置Prometheus作为Docker容器运行，并使用Prometheus监控Docker实例。 配置Docker配置docker daemon作为Prometheus target，你需要指定metrics-address。最佳方式是通过daemon.json。 1234&#123; &quot;metrics-addr&quot; : &quot;127.0.0.1:9323&quot;, &quot;experimental&quot; : true&#125; 配置和运行Prometheus 12345678910111213141516171819202122232425262728293031323334353637/tmp/prometheus.yml# my global configglobal: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Attach these labels to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: monitor: &apos;codelab-monitor&apos;# Load rules once and periodically evaluate them according to the global &apos;evaluation_interval&apos;.rule_files: # - &quot;first.rules&quot; # - &quot;second.rules&quot;# A scrape configuration containing exactly one endpoint to scrape:# Here it&apos;s Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: &apos;prometheus&apos; # metrics_path defaults to &apos;/metrics&apos; # scheme defaults to &apos;http&apos;. static_configs: - targets: [&apos;localhost:9090&apos;] - job_name: &apos;docker&apos; # metrics_path defaults to &apos;/metrics&apos; # scheme defaults to &apos;http&apos;. static_configs: - targets: [&apos;localhost:9323&apos;] 1234docker service create --replicas 1 --name my-prometheus \ --mount type=bind,source=/tmp/prometheus.yml,destination=/etc/prometheus/prometheus.yml \ --publish published=9090,target=9090,protocol=tcp \ prom/prometheus 访问: http://localhost:9090/targets/ 配置容器Configure containers 自动启动容器Start containers automatically Docker提供了重启策略，以控制容器在退出或重启时自动启动。重启策略可确保链接的容器以正确的书序启动。Docker建议你使用重启策略，并避免使用进程管理器(如supervisor)来启动容器。重启策略与docker xxx --live-restart标志不同，后者可以让你在Docker upgrage期间保持容器运行。 重启策略使用docker run xxx --restart标志来配置重启策略，--restart的值如下： 标志 描述 no 不要自动重启容器(默认值) on-failure 如果容器由于错误(非零退出码)退出，则重启容器 unless-stopped 除非明确停止或docker本身停止或重启，则重启容器 always 如果停止，则始终重启容器 12#栗子docker run -dit --restart unless-stopped redis 重启策略注意事项 重启策略尽在容器成功启动后才生效——这意味着容器已启动至少10s，并且Docker已开始监视它。这可以防止根本不启动的容器进入重启循环。 如果你手动停止容器(状态码为0)，则在重启Docker daemon或手动启动容器之前，其重启策略将会被忽略。这是另一个防止重启循环的尝试。 重启策略仅适用于容器。集群服务的重启策略与此不同。 在daemon停机期间保持容器活着Keep containers alive during daemon downtime 默认情况下，当Docker daemon终止时，它会关闭正在运行的容器。从Docker Engine 1.12开始，你可配置守护进程，以便在守护进程不可用时容器保持运行。这个功能被称为实时恢复(live restore)。它不支持Windows container。 实时恢复有两种方式来启用live restore，只启用其中一个就好。实时恢复仅适用于独立容器，不适用于集群服务。 修改配置文件 12345/etc/docker/daemon.json&#123; &quot;live-restore&quot;: true&#125; --live-restore标志不推荐 1dockerd xxx --live-restore 在一个容器中运行多个服务Run multiple services in a container 容器的主要运行进程是Dockerfile末尾的ENTRYPOINT或CMD指令。通常建议你通过每个容器运行一项服务来分割关注区域。这些服务可能会分成多个进程(如Nginx的worker processe)。你可以使用用户定义的network和shared volumes来连接多个容器。 容器的主进程负责管理它启动的所有进程。在某些情况下，主进程设计不好，在容器退出时无法正常处理停止子进程。如果你的进程属于这个类别，你可在容器运行时使用--init选型。--init标志将一个微小的inti-process作为主进程插入到容器中，并在容器退出时处理所有进程的停止。以这种方式处理这些进程优于使用完整的初始化进程。 如果你需要在一个容器中运行多个服务，则可通过几种不同方式来完成此操作。 将所有命令封装进一个脚本中，并附带测试和调试信息。以封装脚本作为你的CMD 1234567891011121314vim my_wrapper.sh#!/bin/bashxxxxxxxxvim DockerfileFROM ubuntu:latestCOPY my_first_process my_first_processCOPY my_second_process my_second_processCOPY my_wrapper_script.sh my_wrapper_script.shCMD ./my_wrapper_script.sh 使用如supervisord这样的进程管理器 1234567FROM ubuntu:latestRUN apt-get update &amp;&amp; apt-get install -y supervisorRUN mkdir -p /var/log/supervisorCOPY supervisord.conf /etc/supervisor/conf.d/supervisord.confCOPY my_first_process my_first_processCOPY my_second_process my_second_processCMD [&quot;/usr/bin/supervisord&quot;] 容器运行指标Container runtime metrics docker stats 12345docker stats redis1 redis2CONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/Oredis1 0.07% 796 KB / 64 MB 1.21% 788 B / 648 B 3.568 MB / 512 KBredis2 0.07% 2.746 MB / 64 MB 4.29% 1.266 KB / 648 B 12.4 MB / 0 B Control groups Linux Container依赖于control group，这些组不仅跟踪进程组，还公开有关CPU，mem，block I/O的使用情况和度量标准。你可以访问这些指标并判断容器运行状况。control group通过为文件系统(pseudo-fs)公开，你应该可在/proc/fs/cgroup中找到它。 查看cgroup子系统： 1234567891011121314151617181920212223grep cgroup /proc/mounts#ormount -l | grep cgroup#进程/proc/&lt;pid&gt;/cgroup#/表示进程尚未分配给groupcat /proc/1/cgroup11:devices:/10:cpuset:/9:hugetlb:/8:memory:/7:blkio:/6:net_prio,net_cls:/5:pids:/4:perf_event:/3:cpuacct,cpu:/2:freezer:/1:name=systemd:/ 查找给定容器的cgroup对于每个容器，每个层次结构中创建一个cgroup。 123456789101112131415161718192021222324252627282930313233343536373839/sys/fs/cgroup/memory/docker/&lt;docker-longid&gt;/cd /sys/fs/cgroup/memory/docker/893903129d869f384bd78d63a382f1c9527d6979be0a6cf3c13ea4f45a1554d6cat memory.statcache 36282368rss 196608rss_huge 0mapped_file 1077248swap 0pgpgin 212904pgpgout 205531pgfault 314692pgmajfault 204inactive_anon 131072active_anon 65536inactive_file 18223104active_file 18059264unevictable 0hierarchical_memory_limit 9223372036854771712hierarchical_memsw_limit 9223372036854771712total_cache 36282368total_rss 196608total_rss_huge 0total_mapped_file 1077248total_swap 0total_pgpgin 212904total_pgpgout 205531total_pgfault 314692total_pgmajfault 204total_inactive_anon 131072total_active_anon 65536total_inactive_file 18223104total_active_file 18059264total_unevictable 0#其它信息类似 限制容器的资源Limit a container’s resources 默认情况下，容器没有资源限制，可以使用主机内核调度程序允许给定的资源。Docker提供了一些方法来控制容器可以使用的CPU、memory、block I/O。 许多这些功能需要内核的支持。使用docker info命令检查是否支持。如果内核禁用了某功能，则可能会有如下警告: WARNING: No swap limit support memory你需要了解内存耗尽(out of memory)的风险不要让正在运行的容器消耗太多的主机内存，这很重要。在Linux主机上，如果内核检测到没有足够的内存来执行重要的系统功能，它会抛出一个OOME(out of memory exception)，并开始killing process以释放进程。任何进程都会是killing objects，包括Docker和其它重要应用程序。 docker尝试通过调整docker daemon的OOM优先级来降低这些风险，从而使其比系统上的其它进程更小(less)可能的被killing。容器的OOM优先级不进行调整，这使得单个容器被killing的可能性要大于docker或其它进程。你不应该给docker daemon的--oom-score-adj或container的--oom-kill-disable标志来绕过这些安全措施。 你可以通过以下方式减轻由OOM引起的系统不稳定的风险: 在上线之前，进行测试以了解应用程序的内存需求 确保应用程序仅在拥有足够资源的主机上运行 限制容器可使用的内存量 在主机上配置swap时请注意。swap比内存更慢，性能更低，但可以提供缓冲区以防系统内存耗尽 考虑将容器转换为服务，并使用服务级别约束和节点标签来确保应用程序仅在具有足够内存的主机上运行 限制容器对内存的Limit a container’s access to memory Docker可以强制hard limit，允许容器使用不超过给定数量的用户/系统内存，或soft limit。这允许容器使用尽可能多的内存。 如下这些选项具有这样一些效果，注意内存单位b, k, m, g： 选项 描述 -m/--memory= 容器可使用的最大内存量。如果你设置此选项，则允许的最小值为4m --memory-swap 容器允许使用的swap量。只有在--momery设置时才有意义 --memory-swappiness 默认情况下，容器可使用的主机内核可交换的匿名页面的百分比 --memory-reservation 允许你指定一个小于--memory的soft limit。当docker检测到内存不足时，此会被激活 --kernel-memory 容器可以使用的最大kernel memory。内核内存不能够被swap out，因此内核内存不足的容器可能会阻塞主机资源，这会对主机和其它容器产生副作用 --oom-kill-disable 默认情况下，如果发生内存溢出(OOM)，内核会杀死容器中的进程。使用此选项改变此行为 cpu默认情况下，每个容器对主机CPU周期的访问是无限制的。你可以设置各种约束来限制给定容器访问主机的CPU周期。 CFS schedulerCFS是用于普通Linux进程的Linux kernel CPU调度器，一些运行时标志用于配置容器的CPU资源访问量。 选项 描述 --cpu=&lt;value&gt; 指定容器可以使用的CPU资源，如--cpu=&quot;1.6&quot; --cpu-period=&lt;value&gt; 指定CFS调度器周期，它与--cpu-quota一起使用。默认100ms。Docker1.13以后，使用--cpus替代 --cpu-quota=&lt;value&gt; 在容器上条件CFS配额。在Docker1.13以后，使用--cpus替代 --cpuset-cpus 限制容器可以使用的特定CPU或CORE。如果有多个CPU，请使用逗号,分割。如0,2 --cpu-shares 将此标志设置为大于/小于1024(默认值)的值，以增加或减少容器的重量，并使其能够访问更大或更小比例的主机CPU周期。这仅在CPU周期受到限制时才会执行。 如果你只有1 CPU，如下命令可保证容器每秒最多有50%的CPU——docker run -it --cpus=&quot;.5&quot; xxx realtime scheduler 在Docker1.13及更高版本，对于无法使用CFS的任务，你可以使用realtime scheduler。在你配置docker daemon和container之前，请正确地配置主机内核。 注意： CPU调度和优先级是高级内核功能。大多数用户不需要修改它。错误地设置将导致主机系统不稳定或不可用。 配置主机内核通过运行zcat /proc/config.gz | grep CONFIG_RT_GROUP_SCHED或检查/sys/fs/cgroup/cpu.rt_runtime_us来验证内核是否启用了CONFIG_RT_GROUP_SCHED。有关配置内核实时调度器的指导，请参考相关文档。 配置docker daemon运行docker daemon时使用--cpu-rt-runtime标志设置每个运行时间段的实时任务保留的最大微秒数。可使用systemd的docker.service进行配置。 配置独立容器当使用docker run启动容器时，可以传递多个标志来控制容器CPU的优先级。 选项 描述 --cap-add=sys_nice 授予容器CAP_SYS_NICE功能，允许容器提升进程的nice值，设置实时调度策略，设置CPU关联和其它操作 --cpu-rt-runtime=&lt;value&gt; Docker实时调度器期间，容器可以以实时优先级运行的最大微秒数。需要--cap-add=sys_nice标志 --ulimit rtprio=&lt;value&gt; 容器允许的最大实时优先级，需要--cap-add=sys_nice标志 栗子： 1234docker run --it --cpu-rt-runtime=950000 \ --ulimit rtprio=99 \ --cap-add=sys_nice \ debian:jessie Logging查看容器日志记录的信息和日志格式取决于容器的端点命令。docker logs命令显示正在运行的容器记录的信息。docker service logs命令显示参与服务的所有容器记录的信息。在swarm模式下。 在某些情况下，docker logs可能不会显示有用的信息，除非你采取其它措施。 如果将日志发送到文件、主机、数据库或其它日志驱动程序，则docker logs可能不会显示有用的信息 如果你的镜像运行non-interactive进程(如数据库)，则该应用程序可能会将output发送到日志文件而不是stdout/stderr 配置日志驱动Configure logging drivers docker提供了多种日志记录机制(logging mechanisms)来帮助你从运行的容器和服务中获取信息。这些机制被称为日志驱动(logging driver)。每个docker daemon都有一个默认日志驱动，每个容器也默认使用该驱动。除非你给容器配置了其它日志驱动。除了使用docker附带日志驱动，在Docker v17.05之后，你还可以使用日志驱动插件(logging driver plugin)。 配置默认日志驱动默认的日志驱动是json-flie。可在daemon.json文件里通过log-driver选项匹配置日志驱动。 123456/etc/docker/daemon.json#设置为syslog&#123; &quot;log-driver&quot;: &quot;syslog&quot;&#125; 如果日志驱动存在可配置选项： 1234567891011121314/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;labels&quot;: &quot;production_status&quot;, &quot;env&quot;: &quot;os,customer&quot; &#125;&#125;#查看docker info | grep &apos;Loggin Driver&apos;Logging Driver: json-file 为容器配置日志驱动启动容器时，可使用--log-driver标志为其配置不同于docker daemon的日志驱动。 12345docker run -it --log-driver none alpine ash#查看容器日志驱动docker inspect -f &apos;&#123;&#123;.HostConfig.LogConfig.Type&#125;&#125;&apos; &lt;CONTAINER&gt; 配置从容器到日志驱动的log message的交付模式Docker为从容器到日志驱动的日志消息提供了两种交付(delivery）模式： 直接阻塞(blocking)从容器到驱动的交付(默认) 非阻塞交付(non-blocking)，将日志消息存储在中间每个容器的环形缓冲区中供驱动使用非阻塞消息交付模式可防止应用程序因日志反压而被阻塞。当STDERR或STDOUT流阻塞时，应用程序可能会以意想不到的方式失败。 注意：当缓冲区已满且新消息排入队列时，内存中最早的消息将被丢弃。丢弃消息通常首选阻止应用程序的日志写入过程。 1docker run -it --log-opt mode=non-blocking --log-opt max-buffer-size=4m alpine ping 127.0.0.1 日志驱动使用环境变量或label一些日志驱动将容器的--env/-e或--label标签的值添加到容器的日志中。 1docker run -dit --label production_status=testing -e os=ubuntu alpine sh 支持的日志驱动如下是受支持的日志驱动。 驱动 描述 none No logs are available for the container and docker logs does not return any output. json-file The logs are formatted as JSON. The default logging driver for Docker. syslog Writes logging messages to the syslog facility. The syslog daemon must be running on the host machine. journald Writes log messages to journald. The journald daemon must be running on the host machine. gelf Writes log messages to a Graylog Extended Log Format (GELF) endpoint such as Graylog or Logstash. fluentd Writes log messages to fluentd (forward input). The fluentd daemon must be running on the host machine. splunk Writes log messages to splunk using the HTTP Event Collector. logentries Writes log messages to Rapid7 Logentries. 云日志系统 各类云服务商提供的云日志系统 docker logs命令不适用于除json-file和journald之外的其它日志驱动。 日志驱动插件日志驱动插件允许你扩展和定制docker的日志记录功能，超越了内置的日志驱动的功能。 安装日志驱动插件 123docker plugin install &lt;org/image&gt;docker plugin ls 将插件配置为docker daemon默认日志驱动 12345/etc/docker/daemon.josn#or--loggin-driver 将插件配置为容器日志驱动 1docker run xxx --log-driver 定制日志驱动输出Customize log driver output 日志选项tag指定如何格式化表示容器日志消息。默认情况下，系统使用容器ID的前12个字符。你可以指定tag选项来覆盖此行为： 123docker run --log-driver=fluentd \ --log-opt fluentd-address=myhost.local:24224 \ --log-opt tag="mailer" 在指定tag时，Docker支持的一些特殊模板标记： 1234567891011121314151617181920212223242526&#123;&#123;.ID&#125;&#125;The first 12 characters of the container ID&#123;&#123;.FullID&#125;&#125;The full container ID&#123;&#123;.Name&#125;&#125;The container name&#123;&#123;.ImageID&#125;&#125;The first 12 characters of the container’s image ID&#123;&#123;.ImageFullID&#125;&#125;The container’s full image ID&#123;&#123;.ImageName&#125;&#125;The name of the image used by the container&#123;&#123;.DaemonName&#125;&#125;The name of the docker program (docker) 123--log-opt tag=&quot;&#123;&#123;.ImageName&#125;&#125;/&#123;&#123;.Name&#125;&#125;/&#123;&#123;.ID&#125;&#125;&quot;Aug 7 18:33:19 HOSTNAME hello-world/foobar/5790672ab6a0[9103]: Hello from Docker. 日志驱动介绍如下日志驱动！ LogentriesLogentries日志驱动将容器日志发送到Logentries server。 --log-opt: logentries-token: 指定Logentries log设置的token line-only: 仅发送原始有效载荷 docker daemon: 123dockerd --log-driver=logentries#可在docker.service中设置 docker container: 1docker run --log-driver=logentries ... 在使用此日志驱动之前，你需要在Logentries web界面中创建一个新的日志集，并将该日志集的令牌传递给docker： 1docker run --log-driver=logentries --log-opt logentries-token=abcd1234-12ab-34cd-5678-0123456789ab json file默认情况下，docker捕获所有容器的STDOUT和STDERR，并使用json格式将它们写入文件。每个文件包含仅包含一个容器的信息。 123456789101112131415161718/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;10m&quot; &#125;&#125;#ordocker run \ --log-driver json-file --log-opt max-size=10m \ alpine echo hello world#栗子docker run -it --log-opt max-size=10m --log-opt max-file=3 alpine ash json-file支持的日志选项： 选项 描述 栗子 max-size The maximum size of the log before it is rolled. A positive integer plus a modifier representing the unit of measure (k, m, or g). Defaults to -1 (unlimited). —log-opt max-size=10m max-file The maximum number of log files that can be present. If rolling the logs creates excess files, the oldest file is removed. Only effective when max-size is also set. A positive integer. Defaults to 1. —log-opt max-file=3 labels Applies when starting the Docker daemon. A comma-separated list of logging-related labels this daemon accepts. Used for advanced log tag options. —log-opt labels=production_status,geo env Applies when starting the Docker daemon. A comma-separated list of logging-related environment variables this daemon accepts. Used for advanced log tag options. —log-opt env=os,customer env-regex Similar to and compatible with env. A regular expression to match logging-related environment variables. Used for advanced log tag options. —log-opt env-regex=^(os或customer). Graylog Extended Format(gelf)gelf日志驱动是一种方便的格式，可被Graylog, Logstash, Fluentd等工具所理解。许多工具使用这种格式。 在GELF中，每条日志消息都是带有一下字段的字典： version host timestamp short and long version of the message 自定义的字段 12345678910111213141516171819/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;gelf&quot;, &quot;log-opts&quot;: &#123; &quot;gelf-address&quot;: &quot;udp://1.2.3.4:12201&quot; &#125;&#125;#ordockerd --log-driver gelf –-log-opt gelf-address=udp://1.2.3.4:12201#容器docker run \ --log-driver gelf –-log-opt gelf-address=udp://1.2.3.4:12201 \ alpine echo hello world GELF选项： Option Required Description Example gelf-address required GELF服务器地址(tcp/udp) --log-opt gelf-address=udp://192.168.0.42:12201 gelf-compression-type optional 仅限于UDP。类型有gzip(default),zlib,none --log-opt gelf-compression-type=gzip gelf-compression-level optional -1/0 - 9,-1/0(禁用压缩)，1(BestSpeed)，9(BestCompress) --log-opt gelf-compression-level=2 gelf-tcp-max-reconnect optional 仅TCP，连接断开尝试的最大重连次数，默认3 --log-opt gelf-tcp-max-reconnect=3 gelf-tcp-reconnect-delay optinal 仅TCP，重连等待的秒数，默认1s --log-opt gelf-tcp-reconnect-delay=1 tag optional 默认使用Docker容器ID的前12位 --log-opt tag=mailer labels optional 以逗号分隔的日志相关标签 --log-opt labels=production_status,geo env optional 以逗号分隔的日志相关的环境变量 --log-opt env=os,customer evn-regex optional 匹配日志相关环境变量的正则表达式 --log-opt env-regex=^(os l customer) Syslogsyslog日志驱动将日志路由到系统日志服务器。系统日志必须以特定方式格式化才能生效。从有效的消息中，接收者可以提取以下消息： priority日志级别，debug, info, warning, error… timestamp hostname facility记录消息的子系统 process name pid 12345678910111213141516/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;syslog&quot;, &quot;log-opts&quot;: &#123; &quot;syslog-address&quot;: &quot;udp://1.2.3.4:1111&quot; &#125;&#125;#or#syslog-address支持tcp和udpdocker run \ -–log-driver syslog –-log-opt syslog-address=udp://1.2.3.4:1111 \ alpine echo hello world syslog日志驱动选项： 选项 描述 栗子 syslog-address [tcp l udp l tcp+tls]:host:port, unixgram://path, unix://path --log-opt syslog-address=tcp+tls://192.168.1.3:514, --log-opt syslog-address=unix:///tmp/syslog.sock syslog-facility 子系统 --log-opt syslog-facility=daemon syslog-tls-ca-cert CA --log-opt syslog-tls-ca-cert=/etc/ca-certificates/custom/ca.pem syslog-tls-cert TLS certificate --log-opt syslog-tls-key=/etc/ca-certificates/custom/key.pem syslog-tls-skip-verify 跳过tls验证 --log-opt syslog-tls-skip-verify=true tag 如前 如前 syslog-format 日志格式 --log-opt syslog-format=rfc5424micro lables 如前 如前 env 如前 如前 env-regex 如前 如前 ETWETW日志驱动将容器日志转发为ETW事件。每个ETW时间都包含一条日志及其上下文信息的消息，然后客户端可以创建一个ETW监听器来监听这些事件。 Fluentdfluentd日志驱动将容器日志作为结构化日志数据发送到fluentd收集器。接着，用户便可以使用任意一种Fluentd output plugin将这些日志写入不同的目的地。 fluentd发送一下这些元数据： 字段 描述 container_id 完整的64位容器ID container_ame 启动时的容器名 source stdout or stderr log 容器日志 docker logs命令不可用于此日志驱动。 fluentd-address指定fluentd daemon地址 tag 1234567891011121314/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;fluentd&quot;, &quot;log-opts&quot;: &#123; &quot;fluentd-address&quot;: &quot;fluentdhost:24224&quot; &#125;&#125;#ordocker run --log-driver=fluentd --log-opt fluentd-address=fluentdhost:24224docker run --log-driver=fluentd --log-opt fluentd-address=tcp://fluentdhost:24224docker run --log-driver=fluentd --log-opt fluentd-address=unix:///path/to/fluentd.sock Journaldjournald 日志驱动将容器日志发送给 systemd journal。可以通过journalctl命令，journal API，docker logs来检索日志条目。 journald日志驱动还提供如下元数据： CONTAINER_ID CONTAINER_ID_FULL CONTAINER_NAME CONTAINER_TAG CONTAINER_PARTIAL_MESSAGE 123456789/etc/docker/daemon.json&#123; &quot;log-driver&quot;: &quot;journald&quot;&#125;#ordocker run --log-driver=journald ... 几个选项： tag label env env-regex 123456docker run --log-driver=journald \ --log-opt labels=location \ --log-opt env=TEST \ --env &quot;TEST=false&quot; \ --label location=west \ your/application 使用journalctl命令查看日志： 12journalctl CONTAINER_NAME=webserverjournalctl -o json CONTAINER_NAME=webserver 使用journal API： 123456789#pythonimport systemd.journalreader = systemd.journal.Reader()reader.add_match('CONTAINER_NAME=web')for msg in reader: print '&#123;CONTAINER_ID_FULL&#125;: &#123;MESSAGE&#125;'.format(**msg) Splunksplunk日志驱动将容器日志发送到Splunk Enterprise和Splunk Clound的HTTP Event Collector。 安全 CGroup参考: wiki DOCKER基础技术：LINUX CGROUP CGroup 介绍、应用实例及原理描述 linux cgroup 简介 Linux资源管理之cgroups简介 简介CGroup(Linux Control Groups)，是Linux内核的一个功能，用来限制、控制与分离一个进程组群的资源(CPU, Mem, Disk I/O…)。你可以监控你配置的CGroup，拒绝CGroup访问某些资源，甚至在运行的系统中动态配置CGroup。 CGroup的一个设计目标是为不同的应用情况提供统一的结构，从控制单一进程(nice)到操作系统层虚拟化(OpenVZ, Linux-VServer, LXC)。CGroup提供: 资源限制(Resource limitation)：限制资源使用； 优先级(Prioritization)：控制优先级； 结算(Accounting)：用来衡量系统确实把多少资源用到适合的目的上； 控制(Control)：冻结组或检查点和重启动。 使用CGroup，系统管理员可更具体地控制对系统资源的分配、优化顺序、拒绝、管理和监控。可更好地根据任务和用户分配硬件资源，提高总体效率。 核心概念CGroup需要考虑如何抽象进程和资源这两种概念，同时如何组织自己的结构。它有几个非常重要的核心概念: 任务(task)：系统中运行的实体，一般指进程； 子系统(subsystem)：具体的资源控制器，控制某个特定的资源使用； blkio(Block IO)：限制块设备的I/O速率； cpu：限制调度器分配的CPU使用率； cpuacct(CPU Accounting)：生成cgroup中任务使用CPU的报告； cpuset(CPU Set)：为cgroup中的进程分配单独的cpu节点或者内存节点，也就是哪些CPU和MEM上； devices：允许或者拒绝cgroup中任务对设备的访问； freezer：挂起或者恢复cgroup中的任务； hugetlb：主要针对于HugeTLB系统进行限制，这是一个大页文件系统； memory：限制cgroup中任务使用内存的量，并自动生成任务当前内存的使用情况报告； net_cls(Network Classifier)：为cgroup中的报文设置特定的classid标志，这样Linux流量控制(traffic control)程序可对其数据包进行控制； ns(namespace)：可使不同cgroups下面的进程使用不同的 namespace； net_prio(Network Priority)：对每个网络接口设置报文的优先级； perf_event：识别任务的 cgroup 成员，可以用来做性能分析； 控制组(CGroup)：一组任务和子系统的关联关系，表示对这些任务进行怎样的资源管理策略。 层级(hierarchy)：一系列CGroup组成的树形结构。每个节点都是一个CGroup，CGroup可以有多个子节点，子节点默认会继承父节点的属性。 相互关系: 每次在系统中创建新层级时，该系统中的所有任务都是那个层级的默认cgroup(称为根(root))的初始成员； 一个子系统最多只能附加到一个层级； 一个层级可以附加到多个子系统； 一个任务可以是多个CGroup的成员，但是这些CGroup必须在不同的层级； 系统中的进程(任务)创建子进程(任务)时，该子任务自动成为其父进程所在CGroup的程序，也就是继承。 文件系统Linux使用了多种数据结构在内核中实现了CGroup的配置，关联了进程和CGroups节点。CGroup提供了一个CGroup虚拟文件系统(VFS, Virtual File System)，作为进行分组管理和各子系统设置的用户接口。要使用CGroup，必须挂载CGroup文件系统。这时通过挂载选项指定使用哪个子系统。 VFS通用文件模型中包含的四中元数据结构: 超级块对象(superblock object)：用于存放已经注册的文件系统的信息。比如ext2，ext3等这些基础的磁盘文件系统，还有用于读写socket的socket文件系统，以及当前的用于读写cgroups配置信息的 cgroups 文件系统等； 索引节点对象(inode object)：用于存放具体文件的信息。对于一般的磁盘文件系统而言，inode 节点中一般会存放文件在硬盘中的存储块等信息；对于socket文件系统，inode会存放socket的相关属性，而对于cgroups这样的特殊文件系统，inode会存放与 cgroup 节点相关的属性信息。这里面比较重要的一个部分是一个叫做 inode_operations 的结构体，这个结构体定义了在具体文件系统中创建文件，删除文件等的具体实现； 文件对象(file object)：一个文件对象表示进程内打开的一个文件，文件对象是存放在进程的文件描述符表里面的。同样这个文件中比较重要的部分是一个叫 file_operations 的结构体，这个结构体描述了具体的文件系统的读写实现。当进程在某一个文件描述符上调用读写操作时，实际调用的是 file_operations 中定义的方法。 对于普通的磁盘文件系统，file_operations 中定义的就是普通的块设备读写操作；对于socket文件系统，file_operations 中定义的就是 socket 对应的 send/recv 等操作；而对于cgroups这样的特殊文件系统，file_operations中定义的就是操作 cgroup 结构体等具体的实现； 目录项对象(dentry object)：在每个文件系统中，内核在查找某一个路径中的文件时，会为内核路径上的每一个分量都生成一个目录项对象，通过目录项对象能够找到对应的 inode 对象，目录项对象一般会被缓存，从而提高内核查找速度。 CGroup支持的文件类型: 文件 R/W 用途 Release_agent RW 删除分组时执行的命令，这个文件只存在于根分组 Notify_on_release RW 设置是否执行release_agent，为1时执行 Tasks RW 属于分组的线程TID列表 Cgroup.procs R 属于分组的进程PID列表 Cgroup.event_control RW 监视状态变化和分组删除事件的配置文件 Namespace参考: docker 容器基础技术：linux namespace 简介 DOCKER基础技术：LINUX NAMESPACE 介绍Linux Namespace是Linux提供的一种内核级别环境(资源)隔离机制，用来让运行在同一个操作系统上的进程互相不会干扰。 Namespace的目的就是隔离。某个Namespace里面的进程就只能看到该Namespace的信息，无法看到该Namespace之外的信息，无法看到其它Namespace里面的信息。各个Namespace中的进程根本感觉不到对方的存在。 Linux内核提供的Namespace: Namespace clone()使用的flag 隔离的资源 CGroup CLONE_NEWCGROUP CGroup根目录 IPC CLONE_NEWIPC System V IPC，POSIX 消息队列 Network CLONE_NEWNET 网络设备、协议栈、端口等 Mount CLONE_NEWNS 挂载点 PID CLONE_NEWPID 进程 ID User CLONE_NEWUSER 用户和组 ID UTS CLONE_NEWUTS 主机名和域名 主要是三个子系统调用: clone()：实现线程的系统调用，用来创建一个新的进程，并可以通过设计上述参数达到隔离。 unshare()：使某进程脱离某个namespace setns()：把某进程加入到某个namespace 每个进程都有一个/proc/${pid}/ns目录，里面保存了该进程所在对应Namespace的链接。 12345678sudo ls -l /proc/8734/nstotal 0lrwxrwxrwx. 1 root root 0 4月 24 10:49 ipc -&gt; ipc:[4026531839]lrwxrwxrwx. 1 root root 0 4月 24 10:49 mnt -&gt; mnt:[4026531840]lrwxrwxrwx. 1 root root 0 4月 24 10:49 net -&gt; net:[4026531956]lrwxrwxrwx. 1 root root 0 4月 24 10:49 pid -&gt; pid:[4026531836]lrwxrwxrwx. 1 root root 0 4月 24 10:49 user -&gt; user:[4026531837]lrwxrwxrwx. 1 root root 0 4月 24 10:49 uts -&gt; uts:[4026531838] 每个文件对应于Namespace的文件描述符，方括号里的值是Namespace的inode。如果两个进程所在的Namespace一样，那么它们列出来的inode也是一样的。 inode是指在许多Unix-Like系统中的一种数据结构。每个inode保存了文件系统中的一个文件系统对象（包括文件、目录、设备文件、socket、管道, 等等）的元信息数据，但不包括数据内容或者文件名。inode这个命名的来源可能是文件系统的存储组织为一个扁平数组，分层目录信息使用一个数作为文件系统这个扁平数组的索引值（index）。]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
</search>
